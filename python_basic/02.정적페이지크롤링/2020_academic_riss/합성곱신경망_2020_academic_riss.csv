title,date,keywords,abstract,multilingual_abstract
합성곱신경망을 이용한 구조적 텍스처 분석연구,2020,"['Classification', 'CNN', 'Industrial applications', 'Partial image', 'Structural texture']","구조적인 텍스처는 텍스처를 구성하는 기본요소인 텍셀 (texel)이 규칙적으로 반복되는 형태로 정의된다. 구조적 텍스처 분석/인식은 직물류의 자동검사, 금속표면 자동테스트 및 마이크로 이미지의 자동 분석 등, 산업적인 응용이 다양하다. 본 논문에서는 구조적 텍스처 분석을 위한 합성곱신경망 (Convolution Neural Network, CNN) 기반의 시 스템을 제안한다. 제안한 방법은 합성곱신경망이 분류 대상 텍스처들의 구성 요소인 텍셀을 학습한다. 인식 단계에서는 입력되는 텍스처 영상에서 얻은 부분 영상을 이용하여 학습된 합성곱신경망이 텍스처를 인식하다. 실제 구현 및 실험을 통하여 제안된 방법의 우수성을 보인다.","The structural texture is defined as a form which a texel is regularly repeated in the texture. Structural texture analysis/recognition has various industrial applications, such as automatic inspection of textiles, automatic testing of metal surfaces, and automatic analysis of micro images. In this paper, we propose a Convolution Neural Network (CNN) based system for structural texture analysis. The proposed method learns texles, which are components of textures to be classified. Then, this trained CNN recognizes a structural texture using a partial image obtained from input texture. The experiment shows the superiority of the proposed system."
객체탐지와 합성곱신경망을 이용한 음식물 이물질 탐지,2020,"['객체탐지', '합성곱 신경망', '이물질 탐지', 'X-Ray 이미지']","음식물 내 이물질은 제조업체 및 유통업체에서 자주 수집되는 고객 불만사항으로 이를 방지하기 위해서는 제품 출고 전에 이물질 여부를 검사해야 한다. 음식물 내 이물질은 대부분 육안으로 확인이 어렵기 때문에 X-Ray 검사설비를 통해 음식물 내부를 확인할 수 있는 이미지 형태의 데이터를 얻어 이물질 여부를 판단한다. 하지만, 이 방식은 주로 수작업으로 진행되므로 많은 시간과 비용이 소요된다. 본 연구에서는 X-Ray 검사설비에서 촬영된 음식물 이미지를 대상으로 이물질 여부를 자동으로 탐지하는 방법을 개발하여 보다 빠르고 정확하게 이물질을 검출하고, 궁극적으로 기업과 고객의 피해를 감소시키고자 한다.실험 데이터는 컨베이어벨트에 여러 개의 대추가 흩뿌려져 있는 X-Ray 이미지이며, 대추 내의 씨를 이물질로 정의한다. 현장에서는 여러 종류의 대추가 존재하므로, 대추의 종류에 따른 특성을 반영하여 여러 종류에 모두 적용 가능한 이물질 탐지 방법을 개발해야 한다. 이를 위해서는 종류별로 다수의 대추이미지를 확보해야 하지만 이를 확보하기는 쉽지 않다. 따라서 본 연구는 적은 수량의 Labeling된 데이터를 다양한 방법(비틀기, 확대, 이동 등)을 사용하여 증식한 뒤, 합성곱 신경망을 사용하여 씨의 유무를 분류하는 방법을 제안한다. 또한 합성곱 신경망 분류기의 성능을 높이기 위하여 X-ray 이미지 상의 대추위치를 YOLO를 통해 탐지하고, 대추 부분의 이미지만 잘라내어 합성곱 신경망을 학습시키는 2단계 접근법을 제안한다. 제안된 방법의 성능을 검증하기 위하여 X-ray 검사설비 기업과 함께 사례연구를 수행하였다. 사례연구 결과, 여러 종류의 대추에 대해서 모두 높은 분류성능을 보여줌을 확인했다.",다국어 초록 정보 없음
합성곱신경망 모형 기반 통계적 소음지도 작성,2020,"['Statistical noise map(통계적 소음지도)', 'Urban form indicator(도시 구성 요소)', 'Road-traffic noie(도로교통소음)', 'Convolutional neural network(합성곱신경망)']",국문 초록 정보 없음,다국어 초록 정보 없음
운전자 감정 인식을 위한 Inverted Residual Bottleneck 기반의 합성곱신경망 모델 개발,2020,"['얼굴표정인식', '합성곱신경망', '딥러닝', '운전자감정인식']",국문 초록 정보 없음,다국어 초록 정보 없음
팽창된 잔차 합성곱신경망을 이용한 KOMPSAT-3A 위성영상의 융합 기법,2020,"['Convolutional Neural Network (CNN)', 'Dilated Residual Network', 'KOMPSAT-3A', 'Pansharpening', 'Spatial Correlation Coefficient']","본 논문에서는 CNN (Convolutional Neural Network) 기반의 영상융합 기법을 제안하고자 하였다. 딥러닝 구조의 성능을 향상시키기 위하여, CNN 기법에서 대표적인 합성곱(convolution) 방법으로 알려진 팽창된합성곱(dilated convolution) 모델을 활용하여 모델의 깊이와 복잡성을 증대시키고자 하였다. 팽창된 합성곱을 기반으로 하여 학습과정에서의 효율을 향상시키기 위하여 잔차 네트워크(residual network)도 활용하였다. 또한, 본 연구에서는 모델학습을 위하여 전통적인 L1 노름(norm) 기반의 손실함수와 함께, 공간 상관도를 활용하였다. 본 연구에서는 전정색 영상만을 이용하거나 전정색 영상과 다중분광 영상을 모두 활용하여 구조에 적용한 DRNet을 개발하여 실험을 수행하였다. KOMPSAT-3A를 활용한 전정색 영상과 다중분광 영상을 이용한DRNet은 융합영상의 분광특성에 과적합되는 결과를 나타냈으며, 전정색 영상만을 이용한 DRNet이 기존 기법들과 비교하여 융합영상의 공간적 특성을 효과적으로 반영함을 확인하였다.","In this manuscript, a new pansharpening model based on Convolutional Neural Network (CNN) was developed. Dilated convolution, which is one of the representative convolution technologies in CNN, was applied to the model by making it deep and complex to improve the performance of the deep learning architecture. Based on the dilated convolution, the residual network is used to enhance the efficiency of training process. In addition, we consider the spatial correlation coefficient in the loss function with traditional L1 norm. We experimented with Dilated Residual Networks (DRNet), which is applied to the structure using only a panchromatic (PAN) image and using both a PAN and multispectral (MS) image. In the experiments using KOMPSAT-3A, DRNet using both a PAN and MS image tended to overfit the spectral characteristics, and DRNet using only a PAN image showed a spatial resolution improvement over existing CNN-based models."
해경함정 영상정보에 합성곱신경망을 적용한 국적식별 전문가시스템 구축에 관한 연구,2020,"['Expert System', 'Convolution Neural Network', 'Identification of Coast Guard Ship', 'Maritime Surveillance', '전문가시스템', '합성곱신경망', '해경함정식별', '해상감시']","본 연구는 합성곱신경망(CNN, Convolution Neural Network) 활용하여 한국과 일본의 해경함정 국적 분류를 위한 전문가시스템 구축에 관한 연구이다. 일본과 영유권 갈등을 겪고 있는독도 해역은 군의 감시가 약한 해역으로 일본 해경의 출현이 빈번한 만큼 해상경계를 위한 대책이 필요하다. 현재는 독도 근무자와 출동한 한국 해경함정에서 사람의 육안 또는 무선 교신으로일본 해경함정 여부를 식별하고 있다. 이는 원거리에서 해경함정의 국적을 식별할 수 없는 단점이 있고 대응이 느리다. 따라서 본 연구에서는 이를 보강하기 위해 영상장비에서 얻은 영상정보에 CNN을 적용하여 한국 해경함정과 일본 해경함정을 식별하는 전문가시스템에 대해 연구하였다. 제안하는 전문가시스템은 CNN을 기반으로 구축되었고, 정확도는 훈련 및 검증 데이터에95%이상, 테스트 데이터에 86.25%를 보였다. 본 연구의 결과를 기초로 모델의 성능을 더욱향상시키면 독도 해역에 신속하고 정확한 해상경계의 향상이 있을 것으로 기대된다.","This study is about an expert system for nationality classification of coast guard ship in Korea or Japan using the convolution neural network (CNN). Dokdo Sea area, which is experiencing territorial disputes with Japan, is a sea area where military surveillance is weak, and the appearance of the Japan coast guard ships is frequent, it is necessary to improve maritime surveillance. Currently, dispatched with Dokdo workers, identifies coast guard ship by human or wireless communication.This has the disadvantage of not being able to discern the nationality of coast guard ship from a long distance, and the response is slow. Therefore, in this study, to reinforce this, we applied CNN to the image information obtained from the imaging equipment, and studied the construction of an expert system that identifies coast guard ship belonging to the Korean coast guard and the Japan coast guard.The proposed classification model was built based on CNN, and accuracy was 95% for training and verification data and 86.25% for test data. Based on the results of this study, if the performance of the model is further improved, it is expected that a fast and accurate maritime surveillance will be possible in Dokdo Sea area."
해상 이미지를 활용한 3D 합성곱 신경망과합성곱 장단기 메모리 신경망 기반의 유의 파고 추정,2020,"['Significant Wave Height', '3D Convolution', 'Convolutional LSTM', 'Image Processing']",국문 초록 정보 없음,"One of the most common measures implemented in the operation of large vessels is to find the route that takes the least fuel consumption based on marine conditions, such as wave height. The model that predicts wave height can roughly be categorized into two methods, namely, a numerical method that calculates by physical formula and a soft-computing method that collects weather information and learns the machine learning algorithm. These models are difficult to apply in the real world because of their high computational complexity and the use of expensive radar equipment. In this study, we propose to estimate the wave height in real time using the images of the ocean. We used the image data consisting of four consecutive images instead of a single image and applied the combination of convolutional LSTM and 3D CNN networks that can best handle the data structure as a regression model. In this way of prediction, existing methods are not only outperformed but are also more robust to outliers. We used data from the “Weather 1st” ship provided by Daewoo Shipbuilding & Marine Engineering and confirmed that the mean absolute error is 1.59 cm, and the mean absolute percentage error is as low as 1.61% based on the test set."
합성곱신경망 기반 WiFi 채널 상태 정보를 이용한 제스처 인식,2020,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱신경망(Convolutional Neural Network)을 이용한 매설배관 동적 응력 분석 방법 연구,2020,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱신경망을 활용한 관광사진 분류 및 관광활동 특성분석,2020,[],국문 초록 정보 없음,다국어 초록 정보 없음
가우시안 혼합 모델을 이용한 영상 전처리와 합성곱신경망을 이용한 화재감지에 관한 연구,2020,[],국문 초록 정보 없음,다국어 초록 정보 없음
얼굴인식 성능 향상을 위한 얼굴 전역 및 지역 특징 기반 앙상블 압축 심층합성곱신경망 모델 제안,2020,"['Face Recognition', 'Local Features', 'Global Features', 'Soft Target', 'Ensemble Neural Network', 'Knowledge Distillation', 'Deep Convolution Neural Network']",국문 초록 정보 없음,"In this paper, we propose a novel knowledge distillation algorithm to create an compressed deep ensemble network coupled with the combined use of local and global features of face images. In order to transfer the capability of high-level recognition performances of the ensemble deep networks to a single deep network, the probability for class prediction, which is the softmax output of the ensemble network, is used as soft target for training a single deep network. By applying the knowledge distillation algorithm, the local feature informations obtained by training the deep ensemble network using facial subregions of the face image as input are transmitted to a single deep network to create a so-called compressed ensemble DCNN. The experimental results demonstrate that our proposed compressed ensemble deep network can maintain the recognition performance of the complex ensemble deep networks and is superior to the recognition performance of a single deep network. In addition, our proposed method can significantly reduce the storage(memory) space and execution time, compared to the conventional ensemble deep networks developed for face recognition."
치매 진단을 위한 MRI 바이오마커 패치 영상 기반 3차원 심층합성곱신경망 분류 기술,2020,"['Alzheimer’s Disease', 'Biomarker', 'Hippocampus', 'Cerebrospinal Fluid', '3D Convolutional Neural Network', 'Score Fusion']",국문 초록 정보 없음,"The Alzheimer's disease (AD) is a neurodegenerative disease commonly found in the elderly individuals.It is one of the most common forms of dementia; patients with AD suffer from a degradation of cognitive abilities over time. To correctly diagnose AD, compuated-aided system equipped with automatic classification algorithm is of great importance. In this paper, we propose a novel deep learning based classification algorithm that takes advantage of MRI biomarker images including brain areas of hippocampus and cerebrospinal fluid for the purpose of improving the AD classification performance. In particular, we develop a new approach that effectively applies MRI biomarker patch images as input to 3D Deep Convolution Neural Network. To integrate multiple classification results from multiple biomarker patch images, we proposed the effective confidence score fusion that combine classification scores generated from soft-max layer. Experimental results show that AD classification performance can be considerably enhanced by using our proposed approach. Compared to the conventional AD classification approach relying on entire MRI input, our proposed method can improve AD classification performance of up to 10.57% thanks to using biomarker patch images. Moreover, the proposed method can attain better or comparable AD classification performances, compared to state-of-the-art methods"
합성곱 인공 신경망의 네트워크 종류에 따른 객체 인식 성능에 대한 실험적 고찰,2020,"['Object Detection(객체 인식)', 'Deep Neural Network(심층 신경망)', 'Convolution(합성곱)', 'Artificial Neural Network(인공신경망)']",본 논문은 인공신경망 종류 중 하나인 합성곱 인공신경망의 객체 인식 성능에 살펴보고자 한다. 현재의 합성곱 인공신경망은 인공지능의 부분기술로서 영상 기반의 객체인식에 널리 사용되고 있으며 신경망의 구조에 따른 다양한 합성곱 인공신경망의 네트워크가 존재한다. 본 논문을 통해 합성곱 인공신경망의 네트워크 종류와 환경 변수에 따른 객체 인식 성능을 비교 분석한다.,다국어 초록 정보 없음
합성곱 신경망을 이용한 온실 파프리카의 작물 생체중 추정,2020,"['artificial neural network', 'deep learning', 'image processing', 'machine learning', 'plant growth', '기계 학습', '딥 러닝', '식물 생장', '이미지 처리', '인공신경망']","작물의 생체중을 추정하기 위해 다양한 연구가 시도되었지만, 이미지를 활용하여 생체중을 추정한 예는 없었다. 최근 합성곱 신경망을 사용한 이미지 처리 연구가 늘고 있으며, 합성곱 신경망은 미가공 데이터를 그대로 사용할 수 있다. 본 연구에서는 합성곱 신경망을 이용하여 미가공 데이터 상태인 특정시점의 파프리카 이미지를 입력으로 작물의 생체중을 추정하도록 학습하였다. 실험은 파프리카(Capsicum annuum L.)를 재배하는 온실에서 수행하였다. 합성곱 신경망의 출력값인 생체중은 파괴조사를 통해 수집한 데이터를 기반으로 회귀 분석하였다. 학습된 합성곱 신경망의 결정 계수(R<SUP>2</SUP>)의 최고값은 0.95로 나타났다. 생체중 추정값은 실제 측정값과 매우 유사한 경향성을 보여주었다.","Various studies have been attempted to estimate and measure the fresh weight of crops. However, no studies have used raw images of sweet peppers to estimate fresh weight. Recently, image processing research using convolution neural network (CNN) that can use raw data is increasing. In this study, the crop fresh weight was estimated by using the images of sweet peppers as inputs of CNN. The experiment was performed in a greenhouse growing sweet pepper (Capsicum annuum L.). The fresh weight, the output of the CNN, was regressed based on the data collected through destructive investigation. The highest coefficient of determination (R<SUP>2</SUP>) of the trained CNN was 0.95. The estimated fresh weight showed a very similar trend to the actual measured value."
그래프 합성곱 신경망을 이용한 다중 관측소 기반 지진 이벤트 분류,2020,"['Earthquake event classification', 'Multi-site based classification', 'Convolution neural networks', 'Graph convolution networks', '지진 이벤트 분류', '다중 관측소 기반 분류', '합성곱 신경망', '그래프 합성곱 신경망']",본 논문은 다중 관측소에서 측정된 지진 신호를 이용한 그래프 합성곱 신경망 기반 지진 이벤트 분류 방법을제안한다. 기존의 딥러닝 기반 지진 이벤트 분류 방법은 대부분 단일 관측소에서 측정된 신호로부터 지진 이벤트를 분류한다. 지진 관측망에는 수많은 지진 관측소가 존재하며 하나의 관측소만 사용하는 방법보다 여러 관측소의 정보를동시에 활용하는 방법이 지진 이벤트 분류 성능 향상을 이끌 수 있다. 본 논문에서는 단일 관측소에서 측정된 지진 신호들에 합성곱 신경망을 적용해 임베딩 특징을 추출한 후 그래프 합성곱 신경망을 이용해 단일 관측소들 사이의 정보를융합하는 다중 관측소 기반 지진 이벤트 분류 구조를 제안한다. 관측소의 개수 변화 등 다양한 실험을 통해 제안한 모델의 성능 검증을 수행하였으며 실험 결과 제안하는 모델이 단일 관측소 기반 분류 모델보다 약 10 % 이상의 정확도와이벤트 재현율 성능 향상을 보여주었다.,"In this paper, we propose a multi-site based earthquake event classification method using graph convolution networks. In the traditional earthquake event classification methods using deep learning, they used single-site observation to estimate seismic event class. However, to achieve robust and accurate earthquake event classification on the seismic observation network, the method using the information from the multi-site observations is needed, instead of using only single-site data. Firstly, our proposed model employs convolution neural networks to extract informative embedding features from the single-site observation. Secondly, graph convolution networks are used to integrate the features from several stations. To evaluate our model, we explore the model structure and the number of stations for ablation study. Finally, our multi-site based model outperforms up to 10 % accuracy and event recall rate compared to single-site based model."
합성곱 순환 신경망 구조를 이용한 지진 이벤트 분류 기법,2020,"['Earthquake events classification', 'Convolutional Neural Network (CNN)', 'Recurrent Neural Network (RNN)', 'Convolutional Recurrent Neural Network (CRNN)', '지진 이벤트 분류', '합성곱 신경망', '순환 신경망', '합성 순환 신경망']","본 논문은 다양한 지진 이벤트 분류를 위해 지진 데이터의 정적인 특성과 동적인 특성을 동시에 반영할 수있는 합성곱 순환 신경망(Convolutional Recurrent Neural Net, CRNN) 구조를 제안한다. 중규모 지진뿐만 아니라미소 지진, 인공 지진을 포함한 지진 이벤트 분류 문제를 해결하려면 효과적인 특징 추출 및 분류 방법이 필요하다. 본논문에서는 먼저 주의 기반 합성곱 레이어를 통해 지진 데이터의 정적 특성을 추출 하게 된다. 추출된 특징은 다중 입력단일 출력 장단기메모리(Long Short-Term Memory, LSTM) 네트워크 구조에 순차적으로 입력되어 다양한 지진 이벤트 분류를 위한 동적 특성을 추출하게 되며 완전 연결 레이어와 소프트맥스 함수를 통해 지진 이벤트 분류를 수행한다. 국내외 지진을 이용한 모의 실험 결과 제안된 모델은 다양한 지진 이벤트 분류에 효과적인 모습을 보여 주었다.","This paper proposes a Convolutional Recurrent Neural Net (CRNN) structure that can simultaneously reflect both static and dynamic characteristics of seismic waveforms for various earthquake events classification. Addressing various earthquake events, including not only micro-earthquakes and artificial-earthquakes but also macro-earthquakes, requires both effective feature extraction and a classifier that can discriminate seismic waveform under noisy environment. First, we extract the static characteristics of seismic waveform through an attention-based convolution layer. Then, the extracted feature-map is sequentially injected as input to a multiinput single-output Long Short-Term Memory (LSTM) network structure to extract the dynamic characteristic for various seismic event classifications. Subsequently, we perform earthquake events classification through two fully connected layers and softmax function. Representative experimental results using domestic and foreign earthquake database show that the proposed model provides an effective structure for various earthquake events classification."
이미지로부터 피사계 심도 영역을 효율적으로 추출하기 위한 합성곱 신경망 기법,2020,"['합성곱 신경망(Convolutional neural network)', '피사계 심도(Depth of field)', '이미지 프로세싱(Image processing)', '인공 신경망(Artificial neural networks)']","본 논문에서는 카메라의 포커싱과 아웃포커싱에 의해 이미지에서 뿌옇게 표현되는 DoF(Depth of field, 피사계 심도) 영역을 합성곱 신경망을 통해 찾는 방법을 제안한다. 우리의 접근 방식은 RGB채널기반의 상호-상관 필터를 이용하여 DoF영역을 이미지로부터 효율적으로 분류하고, 합성곱 신경망 네트워크에 학습하기 위한 데이터를 구축하며, 이렇게 얻어진 데이터를 이용하여 이미지-DoF가중치 맵 데이터 쌍을 설정한다. 학습할 때 사용되는 데이터는 이미지와 상호-상관 필터 기반으로 추출된 DoF 가중치 맵을 이용하며, 네트워크 학습 단계에서 수렴률을 높이기 위해 스무딩을 과정을 한번 더 적용한 결과를 사용한다. 본 논문에서 제안하는 합성곱 신경망은 이미지로부터 포커싱과 아웃포커싱된 DoF영역을 자동으로 추출하는 과정을 학습시키기 위해 사용된다. 테스트 결과로 얻은 DoF 가중치 이미지는 입력 이미지에서 DoF영역을 빠른 시간 내에 찾아내며, 제안하는 방법은 DoF영역을 사용자의 ROI(Region of interest)로 활용하여 NPR렌더링, 객체 검출 등 다양한 곳에 활용이 가능하다.",다국어 초록 정보 없음
효율적인 옷감 모델링을 위한 경계 합성곱 신경망 기반의 이미지 슈퍼 해상도 기법,2020,"['합성곱 신경망(Convolutional neural network)', '이미지 슈퍼 해상도(Image super-resolution)', '옷감 시뮬레이션(Cloth simulation)', '물리 기반 시뮬레이션(Physics based simulation)']","본 논문에서는 경계 합성곱 신경망(Convolutional neural network, CNN)기반의 슈퍼 해상도 기법을 이용하여 저해상도 옷감 메쉬를 슈퍼 해상도로 노이즈 없이 안정적으로 표현할 수 있는 기법을 제안한다. 저해상도와 고해상도 메쉬들 간의 쌍은 옷감 시뮬레이션을 통해 얻을 수 있으며, 이렇게 얻어진 데이터를 이용하여 고해상도-저해상도 데이터 쌍을 설정한다. 학습할 때 사용되는 데이터는 옷감 메쉬를 지오메트리 이미지로 변환하여 사용한다. 우리가 제안하는 경계 합성곱 신경망은 저해상도 이미지를 고해상도 이미지로 업스케일링시키는 이미지 합성기를 학습시키기 위해 사용된다. 테스트 결과로 얻어진 고해상도 이미지가 고해상도 메쉬로 다시 변환되면, 저해상도 메쉬에 비해 주름이 잘 표현되며, 경계 부근에서 나타나는 노이즈 문제가 완화된다. 합성 결과에 대한 성능으로는 전통적인 물리 기반 시뮬레이션보다 약 10배 정도 빠른 성능을 보여준다.",다국어 초록 정보 없음
딥러닝 합성곱 신경망을 이용한 효율적인 홍채인식,2020,"['고차 국소 자동 상관함수', '역전파 신경망', '딥러닝', '합성곱 신경망', 'Higher Order Local Autocorrelation Function', 'Back-Propagation', 'Back-Propagation Neural Network', 'Deep Learning', 'Convolution Neural Network']",본 논문은 홍채영상의 이동불변의 특징값 을추출에 탁월한 고차 국소 자동 상관함수를 적용하여 25개의 특징 값을 입력 값으로 적용한 일반적인 HOLP 신경망에 특징 값 25개의 평균값을 추가한 개선된 HOLP 신경망을 구현하여 인식률을 확인하여 보았다. 종류가 상이한 딥러닝 구조들과 비교하였을 때 음성과 영상 분야에서 탁월한 성능을 보이는 Back-Propagation 신경망과 특징 추출기와 분류기를 통합한 합성 곱 신경망을 활용하여 홍채인식의 인식률을 비교하여 보았다.,"This paper presents an improved HOLP neural network that adds 25 average values to a typical HOLP neural network using 25 feature vector values as input values by applying high-order local autocorrelation function, which is excellent for extracting immutable feature values of iris images. Compared with deep learning structures with different types, we compared the recognition rate of iris recognition using Back-Propagation neural network, which shows excellent performance in voice and image field, and synthetic product neural network that integrates feature extractor and classifier."
다양한 합성곱 신경망 방식을 이용한 모바일 기기를 위한 시작 단어 검출의 성능 비교,2020,"['성능 비교', '시작 단어 검출', '합성곱 신경망', '인공지능 비서', 'Performance comparison', 'Wake-up-word detection', 'Convolutional neural network', 'Artificial Intelligence (AI) assistant']","음성인식 기능을 제공하는 인공지능 비서들은 정확도가 뛰어난 클라우드 기반의 음성인식을 통해 동작한다.클라우드 기반의 음성인식에서 시작 단어 인식은 대기 중인 기기를 활성화하는 데 중요한 역할을 한다. 본 논문에서는공개 데이터셋인 구글의 Speech Commands 데이터셋을 사용하여 스펙트로그램 및 멜-주파수 캡스트럼 계수 특징을입력으로 하여 모바일 기기에 대응한 저 연산 시작 단어 검출을 위한 합성곱 신경망의 성능을 비교한다. 본 논문에서사용한 합성곱 신경망은 다층 퍼셉트론, 일반적인 합성곱 신경망, VGG16, VGG19, ResNet50, ResNet101, ResNet152, MobileNet이며, MobileNet의 성능을 유지하면서 모델 크기를 1/25로 줄인 네트워크도 제안한다.","Artificial intelligence assistants that provide speech recognition operate through cloud-based voice recognition with high accuracy. In cloud-based speech recognition, Wake-Up-Word (WUW) detection plays an important role in activating devices on standby. In this paper, we compare the performance of Convolutional Neural Network (CNN)-based WUW detection models for mobile devices by using Google's speech commands dataset, using the spectrogram and mel-frequency cepstral coefficient features as inputs. The CNN models used in this paper are multi-layer perceptron, general convolutional neural network, VGG16, VGG19, ResNet50, ResNet101, ResNet152, MobileNet. We also propose network that reduces the model size to 1/25 while maintaining the performance of MobileNet is also proposed."
일차원 합성곱 신경망을 이용한 치매 환자의 뇌파 분류,2020,"['Electroencephalography(뇌파)', 'Dementia(치매)', 'Convolution Neural Network(합성곱 신경망)', 'Short-Time Fourier Transform(국소 푸리에 변환)', 'Dementia Diagnosis(치매 진단)']","대부분의 치매는 비가역적이기 때문에 조기 진단이 매우 중요하다. 하지만 현재 사용되고 있는 치매 진단 방법은 많은 한계점들을 가지고 있다. 이러한 문제를 해결하기 위해 치매와 정상인을 분류하기 위한 다양한 연구가 진행되어 왔다. 본 연구에서는 뇌파를 사용하여 정상인과 치매 환자를 분류하기 위해 신호 처리 방법과 일차원 합성곱 인공신경망 분류기를 제안한다. 치매 환자 13명과 정상인 115명의 뇌파 신호를 사용하였으며, 국소 푸리에 변환된 데이터셋으로 제안된 분류기의 성능을 교차 검증하였다. 제안된 인공신경망의 분류 성능은 두 개의 전극만으로 정확도 86.04%, 민감도 82.53%, 특이도 88.69%의 높은 성능을 나타내었다. 이를 통해 본 연구에서 제안된 일차원 합성곱 인공신경망 분류기와 신호 처리 방법이 정상인과 치매 환자의 뇌파를 높은 정확도로 분류할 수 있음을 확인하였다.","Since most dementia cases are irreversible, early diagnosis is critical. However, dementia diagnosis methods have several limitations. In this regard, numerous studies have tried to classify dementia patients and healthy persons. In this study, we propose a 1-dimensional (1D) convolution neural network classifier and signal processing methods to distinguish between dementia patients and healthy persons through electroencephalography (EEG). We used EEG data from 13 dementia patients and 115 healthy people. In addition, a dataset transformed by the short-time Fourier transform was used to cross-validate the proposed artificial neural network classifier. The performance of the proposed classifier was 86.04 % accuracy, 82.53 % sensitivity, and 88.69 % specificity. This is a remarkable performance for only two electrodes. These results confirmed that EEG of healthy persons and dementia patients can be classified accurately with the 1D convolution neural network classifier and the signal processing methods proposed in this study."
CCTV 영상과 합성곱 신경망을 활용한 해무 탐지 기법 연구,2020,"['해무', '해양 원격탐사', '기계 학습', '합성곱 신경망', 'Sea fog', 'Ocean Remote Sensing', 'CCTV', 'Machine Learning', 'Convolutional neural network']","본 논문에서는 합성곱 신경망을 기반으로 CCTV 이미지를 통한 해무 탐지 방법을 제안한다. 학습에 필요한 자료로 시정 1km 기준으로 총 11개의 항만 또는 해수욕장(부산항, 부산신항, 평택항, 인천항, 군산항, 대산항, 목포항, 여수광양항, 울산항, 포항항, 해운대해수욕장)에서 수집된 해무와 해무가 아닌 이미지 10004장을 랜덤 추출하였다. 전체 10004장의 데이터셋 중에 80%를 추출하여 합성곱 신경망 모델 학습에 사용하였다. 사용된 모델은 16개의 합성곱층과 3개의 완전 연결층을 가지고 있으며, 마지막 완전 연결층에서 Softmax 분류를 수행하는 합성곱 신경망을 활용하였다. 나머지 20%를 이용하여 모델 정확도 평가를 수행하였고 정확도 평가 결과 약 96%의 분류 정확도를 보였다.","In this paper, the method of detecting sea fog through CCTV image is proposed based on convolutional neural networks. The study data randomly extracted 1,0004 images, sea-fog and not sea-fog, from a total of 11 ports or beaches (Busan Port, Busan New Port, Pyeongtaek Port, Incheon Port, Gunsan Port, Daesan Port, Mokpo Port, Yeosu Gwangyang Port, Ulsan Port, Pohang Port, and Haeundae Beach) based on 1km of visibility. 80% of the total 1,0004 datasets were extracted and used for learning the convolutional neural network model. The model has 16 convolutional layers and 3 fully connected layers, and a convolutional neural network that performs Softmax classification in the last fully connected layer is used. Model accuracy evaluation was performed using the remaining 20%, and the accuracy evaluation result showed a classification accuracy of about 96%."
인지 무선 통신을 위한 합성곱 신경망 기반 스펙트럼 센싱 기법,2020,[],본 논문에서는 인지 무선 통신을 위한 새로운 합성곱 신경망 기반 스펙트럼 센싱 기법을 제안한다. 제안하는 기법은 주 사용자 신호에 대한 어떠한 사전 정보도 알지 못하는 상황에서 에너지 검출을 통해 주 사용자 신호 유무를 판단한다. 제안하는 기법은 센싱하고자 하는 전체 대역을 고려하여 수신신호를 고속으로 샘플링한다. 이후 신호의 FFT(fast Fourier transform)을 통해 주파수 스펙트럼으로 변환하고 연속적으로 이와 같은 스펙트럼을 쌓아서 2차원 신호를 만든다. 이렇게 만든 2차원 신호를 탐지하고자 하는 채널 대역폭 단위로 자르고 합성곱 신경망에 입력하여 채널이 사용 중인지 비어있는지 판단한다. 판단하고자 하는 분류의 종류가 두 가지이므로 이진 분류 합성곱 신경망을 사용한다. 제안하는 기법의 성능은 컴퓨터 모의실험과 실제 실내환경에서의 실험을 통해 검증하는데 이 결과에 따르면 제안하는 기법은 기존 문턱값 기반 기법보다 2 dB 이상 우수한 성능을 보인다.,다국어 초록 정보 없음
결측값을 포함한 센서 스트림에 대한 어텐션 메커니즘 및 합성곱 신경망 기반의 패턴 분류 기법,2020,"['IoT', '스트림 데이터', '딥러닝', '합성곱 신경망', '어텐션 메커니즘', 'IoT', 'Stream Data', 'Deep Learning', 'CNN', 'Attention Mechanism']","다양한 센서로부터 수집된 IoT 스트림 데이터 분석은 대표적인 비선형 분석 문제로, 최근 이러한 문제들의 해결에 합성곱 신경망(Convolutional Neural Network, CNN)을 비롯한 딥러닝 기법들을 다방면으로 적용하고 있다. 또한, IoT 센서 스트림 데이터는 그 수집 과정에서, 센서와 서버 간의 통신 장애 또는 센서의 하드웨어적 결함 등으로 인한 결측값 즉, 손실 데이터를 포함하는 경우가 많으며, 이러한 손실 데이터는 분석의 정확도를 감소시킨다. 한편, 다양한 센서 스트림 데이터 중, 루프 센서를 통해 수집된 교통량 데이터 분석은 도시 계획, 교통 공학, 다양한 교통 및 위치 기반 서비스의 구현 등에 활용된다. 그러나 루프 센서를 통한 교통량 데이터 수집 과정에서 결측값이 발생하는 경우가 많다. 본 논문에서는 이렇게 결측값이 포함된 센서 스트림 데이터의 패턴 분류 정확도를 높이기 위한 기법을 제안한다. 제안하는 기법은 합성곱 신경망 기반의 패턴 분류 모델에 어텐션 메커니즘(Attention Mechanism)을 도입하여 비손실 데이터에 대한 가중치를 부여함으로써 결측값으로 인한 정확도의 손실을 보완한다. 본 논문에서는 결측값의 발생이 잦은 루프 센서 기반의 교통량 데이터를 대상으로 제안하는 패턴 분류 기법을 적용하였고, 제안하는 기법이 결측값을 포함한 센서 스트림 데이터에 대한 패턴 분류 정확도를 향상시킬 수 있음을 실험을 통해 확인하였다.","Analysis for IoT stream data collected from various sensors is a typical non-linear analysis problem, and recently, deep learning techniques including convolutional neural networks have been applied to these problems in various ways. In addition, the IoT sensor stream data often includes missing data, that is, loss data due to a communication failure between the sensor and the server or a hardware defect of the sensor during the collection process, and such loss data reduces the accuracy of analysis. Meanwhile, among the various sensor stream data, the analysis of traffic volume data collected through the loop coil sensor is used for urban planning, traffic engineering, and implementation of various traffic and location-based services. However, during the process of collecting traffic data through the loop coil sensor, missing values ​​are often generated. In this paper, we propose a method to increase the accuracy of pattern classification of sensor stream data containing missing values. The proposed method compensates for the loss of accuracy due to missing values ​​assigning weights to non-loss data by applying attention mechanism to the pattern classification model based on the convolutional neural network. In this paper, the proposed pattern classification method is applied to traffic volume data measured by loop coil sensors that frequently generate missing values, and it was confirmed through experiments that the proposed method can improve the accuracy of pattern classification for sensor stream data including missing values."
주파수 변조 방송신호를 활용하는 수동형 바이스태틱 레이더에서의 합성곱 신경망 기반 표적 탐지 기법,2020,"['Passive bistatic radar', 'Constant false alarm rate detector', 'Convolutional neural network', 'Target detection']",국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 이용한 동결절편의 암세포 전이 여부 자동진단에 관한 예비연구,2020,[],"동결절편검사는 수술과 연계하여 암전이 여부를 판단하기 위한 응급한 병리검사가 필요할 때 이용된다. 합성곱 신경망은 이미지 분류에 뛰어난 성능을 보이는 딥러닝 기법으로 본 논문에서는 이를 이용하여 유방암 전이 여부를 자동적으로 진단하는 방법을 제안한다. 실험과정은 전처리, 학습, 후처리의 과정으로 구성되어 있으며, 합성곱 신경망으로는 Resnet-18 모델을 사용하였다. 실험 결과 예측 정확도 및 종양의 최대 길이 정합 여부를 점수로 환산하여 약 0.514 의 결과를 보였다.",다국어 초록 정보 없음
합성곱 신경망을 이용한 선체 표면의 청소 상태 분류,2020,"['청소 상태(Cleaning condition)', '분류(Classification)', '합성곱신경망(Convolutional neural network)', '선체표면(Hull surface)']",국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 이용한 작동 중 전달경로해석법의 입력 데이터 형태에 따른 경로 기여도 예측 및 비교,2020,"['Convolutional Neural Network(합성곱 신경망)', 'Operational Transfer Path Analysis(작동 중 전달경로해석)', 'Path Contribution(경로 기여도)']",국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 이용한 뇌파 해석 기법,2020,"['뇌-컴퓨터 인터페이스(Brain-computer interface)', '랜덤 필드(Random field)', '합성곱 신경망(Convolutional Neural Network)']",국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 이용한 헬기 피아식별 모형 연구,2020,"['CNN', 'Binary classification', 'Identification model of friend or foe', 'Feature-map', '합성곱 신경망', '이진 분류', '피아식별 모형']","각종 감시체계에서 육안에 의존하여 물체를 식별해내는 것은 어렵고 실수하기 쉬우므로 군 감시체계에서 자동식별능력의 필요성은 더욱 높아지고 있다. 사회에 발표되는 모형들은 군 무기체계에 대한 데이터가 반영되지 않아 군에 바로 적용하는 것은 제한된다. 본 연구는 군용 헬기의 이미지에 합성곱 신경망을 적용하여 피아식별 모형을 구축한 연구이다. 제안하는 모형은 우리나라에서 주로 사용하고 있는 헬기인 AH-64 기종과 공산권 국가에서 주로 사용하고 있는 헬기인 Mi-17 기종의 이미지를 통해 학습시켜 구축되었다. 제안하는 모형의 성능을 살펴보면, 평가척도를 이용하여 평가한 결과 97.8%의 정확도, 97.3%의 정밀도, 98.5% 재현율과 97.9%의 F-measure의 성능을 보임을 확인하였다. 이런 분류결과에 대해서 Feature-map을 통해 아군 헬기의 바퀴와 무장, 그리고 흡기구 주변이, 적군 헬기의 바퀴, 흡기구, 그리고 창문 부위가 피아식별 모형의 분류 기준임을 확인할 수 있었다. 본 연구는 CNN을 이용하여 군 무기체계 중 헬기의 영상정보에 대한 피아식별에 대한 분류를 처음으로 시도한 연구이며, 본 연구에서 제안하는 모형은 기존의 다른 무기체계에 대한 분류 모형보다 높은 정확도를 보인다.","There has been difficulties in identifying objects by relying on the naked eye in various surveillance systems. There is a growing need for automated surveillance systems to replace soldiers in the field of military surveillance operations. Even though the object detection technology is developing rapidly in the civilian domain, but the research applied to the military is insufficient due to a lack of data and interest. Thus, in this paper, we applied one of deep learning algorithms, Convolutional Neural Network-based binary classification to develop an autonomous identification model of both friend and foe helicopters (AH-64, Mi-17) among the military weapon systems, and evaluated the model performance by considering accuracy, precision, recall and F-measure. As the result, the identification model demonstrates 97.8%, 97.3%, 98.5%, and 97.8 for accuracy, precision, recall and F-measure, respectively. In addition, we analyzed the feature map on convolution layers of the identification model in order to check which area of imagery is highly weighted. In general, rotary shaft of rotating wing, wheels, and air-intake on both of ally and foe helicopters played a major role in the performance of the identification model. This is the first study to attempt to classify images of helicopters among military weapons systems using CNN, and the model proposed in this study shows higher accuracy than the existing classification model for other weapons systems."
합성곱 신경망을 이용한 주가방향 예측 : 상관관계 속성선택 방법을 중심으로,2020,"['합성곱신경망', '주가방향 예측', '머신러닝', '딥러닝', '속성선택', '앙상블', 'Convolutional Neural Network', 'Stock Price Direction Prediction', 'Machine Learning', 'Deep Learning', 'Feature Selection', 'Ensemble']",국문 초록 정보 없음,"Recently, deep learning has shown high performance in various applications such as pattern analysis and image classification. Especially known as a difficult task in the field of machine learning research, stock market forecasting is an area where the effectiveness of deep learning techniques is being verified by many researchers. This study proposed a deep learning Convolutional Neural Network (CNN) model to predict the direction of stock prices. We then used the feature selection method to improve the performance of the model. We compared the performance of machine learning classifiers against CNN. The classifiers used in this study are as follows: Logistic Regression, Decision Tree, Neural Network, Support Vector Machine, Adaboost, Bagging, and Random Forest. The results of this study confirmed that the CNN showed higher performancecompared with other classifiers in the case of feature selection. The results show that the CNN model effectively predicted the stock price direction by analyzing the embedded values of the financial data"
합성곱 신경망을 사용한 회전체 오일-휩 및 오일-휩 초기 상태 상태 진단 연구,2020,"['Rotating machine(회전기기)', 'Machine Learning(기계 학습)', 'Condition monitoring(상태 진단)', 'Oil whip(오일-휩)', 'Oil whip initial state(오일-휩 초기 상태)', 'Convolution Neural Network(합성곱 신경망)']",국문 초록 정보 없음,"Failure of a rotating machine can lead to not only loss of system performance but massive losses. Therefore, Condition monitoring technologies of rotating machine for detecting a failure has been actively applied in many industries. Recently, as many techniques were developed to collect and analysis of data, condition monitoring which machine learning technology is applied has been studied. In this paper, the machine learning method is used to detect oil whip phenomenon and classify the normal state, oil whip initial state and oil whip. Oil whip which cand lead to large amplitude of vibration is the most common fault cause of sub-synchronous instability in hydrodynamic journal bearings. Convolution neural network which is widely used in image dimensionality reduction is used to detect oil whip phenomenon. As the input data of the neural network, an orbital image which can represent the feature of the normal state, the oil-whip initial state, and the oil-whip is used."
합성곱 신경망을 이용한 전기 아크 신호 검출,2020,"['arc detection', 'convolutinoal neural network', '2-D transformation', 'data augmentation']","전기화재의 원인중의 하나는 직렬 아크이다. 최근까지 아크 신호를 검출하기 위해 다양한 기법들이 진행되고 있다. 시간 신호에 푸리에 변환, 웨이블릿 변환, 또는 통계적 특징 등을 활용하여 아크 검출을 하는 방법들이 소개되었지만, 변환 및 특징 추출은 부가적인 처리 시간이 요구되는 단점이 있다. 반면에 최근의 딥러닝 모델은 종단간 학습으로 특징 추출 과정없이 직접 원시 데이터를 활용한다. 따라서, 1-D 시간 신호를 직접 활용하여 아크를 검출하는 것이 좋은데, 인공신경망의 분류 성능이 저하되는 문제점이 있다. 본 논문에서는 연속 입력 1-D 신호를 2-D로 변환한 후에, 합성곱신경망으로 분류하는 방법을 제안한다. 실험 데이터에 적용한 결과 합성곱신경망의 사용이 인공신경망보다 약 8.6%의 아크 분류 성능을 향상시켰다. 또한 2-D 데이터의 부족을 보완하기 위해서 데이터증강을 이용하여, 14%의 분류 성능을 개선하였다.",다국어 초록 정보 없음
합성곱 신경망 기반 복합재료의 손상 위치 탐지 방법,2020,"['Convolutional Neural Network(합성곱 신경망)', 'Composite(복합재료)', 'Elastic wave(탄성파)']",국문 초록 정보 없음,다국어 초록 정보 없음
민첩한 활성함수를 이용한 합성곱 신경망의 성능 향상,2020,"['합성곱 신경망', '민첩한 활성함수', '역전파', '학습', 'Convolutional Neural Network', 'Agile Activation Function', 'Backpropagation', 'Learning']",국문 초록 정보 없음,"The convolutional neural network is composed of convolutional layers and fully connected layers. The nonlinear activation function is used in each layer of the convolutional layer and the fully connected layer. The activation function being used in a neural network is a function that simulates the method of transmitting information in a neuron that can transmit a signal and not send a signal if the input signal is above a certain criterion when transmitting a signal between neurons. The conventional activation function does not have a relationship with the loss function, so the process of finding the optimal solution is slow. In order to improve this, an agile activation function that generalizes the activation function is proposed. The agile activation function can improve the performance of the deep neural network in a way that selects the optimal agile parameter through the learning process using the primary differential coefficient of the loss function for the agile parameter in the backpropagation process. Through the MNIST classification problem, we have identified that agile activation functions have superior performance over conventional activation functions."
시계열 합성곱 신경망을 이용한 C-MAPSS 데이터의 기계 유효 수명 예측,2020,"['Remaining Useful Life', 'Temporal-Convolutional Network (시계열 합성곱신경망)', 'Recurrent Neural Network(순환 신경망)']",국문 초록 정보 없음,다국어 초록 정보 없음
심층 합성곱 신경망을 이용한 SAR 이미지 스페클 제거,2020,"['SAR(Synthetic Aperture Radar', '합성개구레이다)', 'De-speckle(스페클 제거)', 'Deep Convolutional Neural Network(심층 합성곱 신경망)']",국문 초록 정보 없음,다국어 초록 정보 없음
확장 합성곱 신경망과 자기 지도 순환 적대적 생성 신경망을 이용한 안개 제거 네트워크,2020,"['안개 제거', '순환 적대적 생성 신경망', '자기 지도 학습', '회전 손실 함수', '지각적 손실 함수', '확장합성곱 신경망', 'dehazing', 'cyclegan', 'self-supervised learning', 'rotation loss', 'perceptual loss', 'smoothed dilated convolution']","C/C++의 타입 캐스팅은 취약점을 유발하며 프로그램의 안정성을 저하시킨다. 이를 보완하기 위해 C++에서는 실행 중 객체의 타입을 확인하여 캐스팅하는 dynamic_cast를 지원하지만, 안전성이 높아지는 대신 실행 속도가 느려진다는 단점이 있다. 이러한 이유로 절충안인 런타임 오버헤드가 적은 static_cast가 사용된다. 그러나 static_cast는 컴파일시에 알려진 타입으로만 캐스팅을 제한하는 방법으로서, 취약점이 여전히 존재한다. 본 논문에서는 프로그램 재작성과 타입 시스템을 활용하여 기존의 C++ static_cast를 보완하여 런타임 오버헤드가 적으면서도 개발 단계에서 좀 더 안전한 코딩을 할 수 있도록 유도하는 방법을 제안한다.","The purpose of this study is to investigate methods restoring hazy images to haze-free images. Most dehazing studies have used datasets that consist of pairs of images, one hazy and one haze-free of the same scene, for training purposes. However, in the real world, it is almost impossible to acquire this kind of data where the hazy image and the haze-free image are perfectly matched except for the haze. Therefore, this paper aims to develop a network that removes haze using hazy images and images without haze that are not paired. The proposed model uses the CycleGAN architecture with this unpaired data. In order to improve the haze removal performance, we propose a dehazing model consisting of a smoothed dilated convolution, a perceptual loss function and a rotational loss function under self-supervised learning. For objective performance evaluation of the proposed techniques, we conducted experiments on the D-HAZY dataset and with real hazy images. The performance of the proposed method was demonstrated through qualitative and quantitative analysis."
딥러닝 기반의 합성곱 신경망을 이용한 화염 및 연기 감지 알고리즘에 관한 연구,2020,"['딥러닝', '기계학습', '영상전처리', '합성곱신경망', '감지기', '객체검출', 'Deeplearning', 'Machinelearning', 'Image Pre-processing', 'Convolutional Neural Network', 'Fire Detector', 'Object Detection']","2017년 제천 스포츠센터 화재와 2018년 밀양 세종병원 화재 등 최근 들어 대형화재의 발생이 증가하고 있는 추세이다. 따라서기존의 화재감지 기법보다 진보된 새로운 화재감지 기법의 필요성이 절실하다. 이에 본 연구에서는 영상전처리를 통해 영상내에서 관심영역을 검출하고 해당 관심영역에 대해 화재 여부를 딥러닝 기반의 합성곱 신경망을 통해 추론하게 된다. 이때데이터셋은 화염, 연기 뿐만 아니라 기존방법으로는 영상 내에서 객체검출의 어려움이 있는 연무형태의 실내 연기 형성여부 또한 검출할 수 있도록 연무데이터셋을 추가하여 학습을 진행하였고, 평가결과 평균 92.3%의 정확도와 93.5%의 정밀도로화재를 검출할 수 있었다.","Recently, cases of large-scale fires, such as those at Jecheon Sports Center in 2017 and Miryang Sejong Hospital in 2018, have been increasing. We require more advanced techniques than the existing approaches to better detect fires and avoid these situations. In this study, a procedure for the detection of fire in a region of interest in an image is presented using image pre-processing and the application of a convolutional neural network based on deep-learning. Data training based on the haze dataset is included in the process so that the generation of indoor haze smoke, which is difficult to recognize using conventional methods, is also detected along with flames and smoke. The results indicated that fires in images can be identified with an accuracy of 92.3% and a precision of 93.5%."
ADMM과 깊은 합성곱 신경망 잡음 제거기 이미지 Prior에 기반한 이미지 디블러링,2020,[],"오래 전부터 모델 기반 최적화 방법이 이미지 디블러링을 위해 널리 사용되어 왔고, 최근에는 학습 기반 기술이 영상 디블러링에서 좋은 성과를 보이고 있다. 본 논문은 ADMM과 깊은 합성곱 신경망 잡음 제거기 이미지 prior를 이용하여 모델 기반 최적화 방법의 장점과 학습 기반 방법의 장점을 모두 활용할 수 있는 방법을 제안한다. 본 방법을 이용하여 기존 방법보다 더 좋은 디블러링 성능을 얻을 수 있었다.",다국어 초록 정보 없음
형상 분산과 합성곱 신경망을 이용한 플랜트 배관 부품에 대한 3차원 점군의 분류,2020,"['Convolutional Neural Network(합성곱 신경망)', 'Deep Learning(딥러닝)', 'Piping Part(배관 부품)', 'Point Cloud(점군)', 'Shape Classification(형상 분류)', 'Shape Distribution(형상 분산)']","본 논문에서는 플랜트 배관 부품의 3차원 점군(point cloud)으로부터 부품을 분류하기 위해 합성곱신경망(convolutional neural network)을 이용하는 방법을 제안한다. 그러나 기존 연구들이 형상을 다중 뷰이미지 형태나 복셀(voxel) 모델로 표현한 반면, 본 연구에서는 점군 안에 있는 각 점들 간의 거리 분포를 1차원 히스토그램으로 표현한 형상 분산(shape distribution)으로 형상을 나타낸다. 형상 분산은 형상의 차원을 3차원에서 1차원으로 감소시킨다. 이로 인해 학습 데이터의 크기가 줄고, 학습 속도가 빨라진다. 또한 형상 분산은 형상의 크기, 자세 및 위치에 영향을 받지 않는다. 본 연구에서는 제안한 방법의 구현 및 실험을 통해 복셀 모델로 표현한 경우보다 학습 속도가 개선되는 것을 확인하였다. 그러나 차원 감소로 인해 정확도는 감소하였다.","In this study, we propose a method for classifying plant piping parts from 3-dimensional point clouds using a convolutional neural network. Whereas previous studies have represented a shape in the form of multi-view images or voxel models, this study uses a shape distribution that represents the distance distribution between each point pair as a one-dimensional histogram. Shape distribution can reduce the dimensions of a shape from three to one. Consequently, the size of the training data is reduced, and training speed increases. Also, a shape distribution is unaffected by the size, orientation, or position of a shape. Through the implementation and experimentation of the proposed method we verified that training speed improved with the use of a voxel model. However, accuracy decreased due to dimensional reduction."
탄성파 층서 구분을 위한 합성곱 신경망 기법 비교 연구,2020,"['머신 러닝', '합성곱신경망', '탄성파층서구분', '인코더-디코더 모델', '네덜란드 F3 block', 'Machine learning', 'Convolutional neural network', 'Seismic sequence identification', 'Encoder–decoder model', 'Netherlands F3 block']","머신 러닝 기술은 탄성파탐사 분야로 그 적용 범위를 확장하고 있다. 탄성파 해석에서 중요한 탄성파 층서 구분에 머신 러닝의 적용 가능성을 알아보았다. 이미지 분야에 탁월한 결과를 보여온 합성곱 신경망 기법 중 4가지 모델을 네덜란드 F3 block에 적용시켰다. 4가지 모델은 ResNet34 모델, 인코더-디코더 형태를 가지는 U-Net, Residual U-Net, FD U-Net이다. 예측된 이미지의 정성적 분석 수행 후 정량적 분석을 위해 pixel accuracy, mean class accuracy, mean intersection over union, frequency weighted IU의 수식을 활용하였다. 본 연구의 분석 결과 ResNet34의 정확도 결과가 가장 낮았고, 인코더-디코더 형태를 가지는 모델들이 높은 정확도를 보여주었다. 그리고 계산에 필요한 파라미터수와 학습시간을 고려 할 때 U-Net이 가장 효율적임을 확인할 수 있었다.","Application of the machine learning technique is expanding to the field of seismic exploration. For the purpose of feasibility assessment, we applied the machine learning technique to seismic sequence identification, which is important in seismic interpretation.From among the convolutional neural network techniques used in image analysis, we applied four models to seismic data obtained in the F3 block, offshore Netherlands, which have yielded remarkable results. One of the four models was ResNet34. The others were encoder– decoder models: U-Net, Residual U-Net, and FD U-Net. We first performed a qualitative analysis of the predicted images and then conducted quantitative analysis using pixel accuracy, mean class accuracy, mean intersection over union, and frequency weighted IU equations. The numerical results showed that ResNet34 had the lowest accuracy and that the encoder–decoder type models had higher accuracy. Considering the number of parameters required for calculation and the learning time, we confirmed that U-Net is the most efficient model."
약한 레이블을 이용한 확장 합성곱 신경망과 게이트 선형 유닛 기반 음향 이벤트 검출 및 태깅 알고리즘,2020,"['음향 태깅', '음향 이벤트 검출', '확장 합성곱 신경망', '게이트 선형 유닛', '시간-주파수 영역분할 맵', '약한레이블', 'Audio tagging', 'Sound event detection', 'Dilated convolution', 'Gated linear unit', 'T-f segmentation map', 'Weak label']","본 논문은 약한 레이블 기반 음향 이벤트 검출을 위한 시간-주파수 영역분할 맵 추출 모델에서 발생하는 희소성 및 수용영역 부족에 관한 문제를 완화 시키기 위해, 확장 게이트 선형 유닛(Dilated Convolution Gated Linear Unit, DCGLU)을 제안한다. 딥러닝 분야에서 음향 이벤트 검출을 위한 영역분할 맵 추출 기반 방법은 잡음 환경에서 좋은성능을 보여준다. 하지만, 이 방법은 영역분할 맵을 추출하기 위해 특징 맵의 크기를 유지해야 하므로 풀링 연산 없이모델을 구성하게 된다. 이로 인해 이 방법은 희소성과 수용영역의 부족으로 성능 저하를 보이게 된다. 이런 문제를 완화하기 위해, 본 논문에서는 정보의 흐름을 제어할 수 있는 게이트 선형 유닛과 추가의 파라미터 없이 수용영역을 넓혀줄 수 있는 확장 합성곱 신경망을 적용하였다. 실험을 위해 사용된 데이터는 URBAN-SED와 자체 제작한 조류 울음소리 데이터이며, 제안하는 DCGLU 모델이 기존 베이스라인 논문들보다 더 좋을 성능을 보였다. 특히, DCGLU 모델이자연 소리가 섞인 환경인 세 개의 Signal to Noise Ratio(SNR)(20 dB, 10 dB, 0 dB)에서 강인하다는 것을 확인하였다.","In this paper, we propose a Dilated Convolution Gate Linear Unit (DCGLU) to mitigate the lack of sparsity and small receptive field problems caused by the segmentation map extraction process in sound event detection with weak labels. In the advent of deep learning framework, segmentation map extraction approaches have shown improved performance in noisy environments. However, these methods are forced to maintain the size of the feature map to extract the segmentation map as the model would be constructed without a pooling operation.As a result, the performance of these methods is deteriorated with a lack of sparsity and a small receptive field.To mitigate these problems, we utilize GLU to control the flow of information and Dilated Convolutional Neural Networks (DCNNs) to increase the receptive field without additional learning parameters. For the performance evaluation, we employ a URBAN-SED and self-organized bird sound dataset. The relevant experiments show that our proposed DCGLU model outperforms over other baselines. In particular, our method is shown to exhibit robustness against nature sound noises with three Signal to Noise Ratio (SNR) levels (20 dB, 10 dB and 0 dB)."
MR 영상을 이용한 합성곱 신경망 기반의 상완골두 및 관절와 자동 분할,2020,"['인공지능', '딥러닝', '분할', '합성곱 신경망', '어깨 질환', 'Artificial Intelligence', 'Deep learning', 'Segmentation. Convolution Neural Network', 'Shoulder disease']","어깨 관련 질환에는 회전근개 손상, 관절와순손상, 어깨충돌증후군 및 습관성어깨탈구 등이 있다. 건강보험진료 통계에 따르면, 이러한 어깨병변으로 진료를 받은 환자수는 매년 증가하는 추세이다. 어깨 관련 질환을 진단하는 대표적인 방법으로 MRI(Magnetic Resonance Imaging,자기공명영상)가 있다. 본 논문에서는 합성곱 신경망 알고리즘인 U-net을 이용해 MR 영상에서 상완골두와 관절와 부위를 자동 분할함으로써 전문의가 관련 질환을 더욱 빠르게 진단하는 데 도움을 주는 연구를 진행하고자 한다. 81명 환자의 MR 영상 총 2251장을 수집하여 이를 훈련셋과 테스트셋으로 사용하였다. 427장 데이터로 검증한 U-net으로 훈련된 어깨뼈 분할 모델의 평가 결과로 민감도 89.32%, 특이도 99.78%, 정확도 99.44% 다이스 계수 92.02%를 보였다. 추후 영상처리 기법을 통해 어깨뼈의 경계영역의 모호성을 해결하고 추가 데이터 수집을 통해 관절와 영역을 충분히 훈련시킨다면 보다 높은 정확도를 얻어 전문의의 진단에 큰 도움을 줄 수 있을 것이라 기대한다.","Shoulder-related disorders include joint and labial injuries, shoulder impingement syndrome, habitual shoulder dislocation and slab lesions. According to health insurance statistics, the number of patients treated with these shoulder lesions is increasing every year. MRI (Magnetic Resonance Imaging) is a representative method of diagnosing such shoulder-related diseases. In this paper, we will use U-net, a convolution neural network algorithm, to automatically segment humeral heads, joints in MR images to help doctors diagnose related diseases more quickly. A total of 2251 MR images of 81 patients were collected and used as training set and test set. As a result of evaluation of U-net trained scapular segmentation model validated by chapter 427 data, sensitivity of 89.32%, specificity of 99.78%, accuracy of 99.44%, and die coefficient of 92.02%. In the future, image processing techniques will solve the ambiguity of the scapular border and collect additional data to fully train the joints and regions, which will provide a higher level of accuracy and help the diagnosis for doctors."
휴대용 및 웨어러블 측정기를 위한 ECG와 PPG 신호를 활용한 합성곱 신경망 알고리즘 기반의 비가압식 혈압 추정 방법,2020,"['비가압식 혈압 추정방법', '합성곱 신경망', '심전도 신호', '광전용맥파 신호', 'Cuff-less blood pressure estimation', 'Convolutional neural network', 'ECG', 'PPG']","본 논문에서는 시계열 심전도 (Electrocardiogram: ECG) 및 광전용맥파 측정센서(Photoplethysmography: PPG)을 이용하여 혈압을 추정하는 알고리즘을 제안한다. 혈압 (Blood pressure: BP)을 추정하기 위해 주기적 입력 신호를 생성하고 차동 및 임계값 방법에 따라 잡음을 제거한 다음 합성곱 신경망 알고리즘을 기반으로 하여 수축기 혈압과 이완기 혈압을 예측한다. 본 논문에서 사용된 데이터는 MIMIC 데이터베이스에서 총 3.1GB의 49명의 환자 데이터를 사용하였다. 실험 결과 수축기 혈압의 평균 제곱근 오차는 5.80mmHg, 이완기 혈압의 예측 오차는 2.78mmHg을 나타내었다. 또한, 영국 고혈압 협회가 제안한 혈압계 평가 방법을 적용하였을 때, 최고 성능인 등급 A를 만족함을 확인할 수 있었다.","In this paper, we propose an algorithm for estimating blood pressure using ECG (Electrocardiogram) and PPG (Photoplethysmography) signals. To estimate the BP (Blood pressure), we generate a periodic input signal, remove the noise according to the differential and threshold methods, and then estimate the systolic and diastolic blood pressures based on the convolutional neural network. We used 49 patient data of 3.1GB in the MIMIC database. As a result, it was found that the prediction error (RMSE) of systolic BP was 5.80mmHg, and the prediction error of diastolic BP was 2.78mmHg. This result confirms that the performance of class A is satisfied with the existing BP monitor evaluation method proposed by the British High Blood Pressure Association."
인쇄된 컬러 QR코드의 합성곱 신경망 알고리즘에 의한 진위 판정 시스템,2020,"['정품 인증', '컬러 QR코드', '스캔 복제', 'Authentic certification', 'Color QR code', 'Scan&amp', 'printing']","스마트폰의 대중적인 보급으로 인해 QR 코드는 세상에서 가장 보편적인 코드들 중의 하나가 되었다. 본 논문에서는 새로운 형태의 QR 코드를 제안하여 저장 용량을 증가시키고, 또한, 컬러 정보와 패턴 형태를 가변시켜서 개인 정보를 포함할 수 있게 한다. 이와 더불어, 제안된 QR 코드가 인쇄된 형태의 다양한 응용환경에 작용될 수 있도록 본 논문은 효과적인 진위 판정 시스템을 제안한다. 제안한 시스템은 기존의 합성곱 신경망 구조 즉 VGGNet으로 구현되며, 스마트 폰을 통해 손쉽게 진품 또는 가품을 판정하고, 진품으로 판정된 코드에 대해서는 삽입된 개인 정보를 추출하도록 설계된다. 인쇄된 QR 코드에 대한 실제의 다양한 실험을 통해 제안된 시스템은 진품 또는 가품을 거의 완벽하게 분류할 수 있음을 보이고 개인 정보를 효과적으로 추출할 수 있음을 확인한다.","With the widespread of smartphones, the Quick response (QR) code became one of the most popular codes. In this paper, a new type of QR code is proposed to increase the storage capacities and also to contain private information by changing the colors and the shape of patterns in the codes. Then, for a variety of applications of the printed QR codes, this paper proposes an efficient authentic certification system, which is built on an conventional CNN (Convolutional neural network) architecture – VGGNet and classifies authentic or counterfeit with smartphones, easily. For authentic codes, the proposed system extracts the embedded private information. Through practical experiments with a printed QR code, it is shown that the proposed system can classify authentic or counterfeit code, perfectly, and also, are useful for extracting private information."
Cascades 방법을 이용한 합성곱 신경망 기반 사용자 동작 추정 방법 연구,2020,[],"사용자 동작 추정이란 이미지 또는 비디오에서 사용자의 관절 위치를 추정하는 과정을 말한다. 기존의 연구들은 사용자의 몸에서 관절의 큰 부분(어깨, 무릎, 골반, 손, 발 등)만을 추정하거나 손의 세부 관절을 별도로 추정 했다. 하지만 특정 분야(수화, 댄스 등)에선 몸짓과 손을 함께 사용하기에 우리는 사용자 몸의 큰 관절과 손의 세부 관절을 같이 추정하는 방법에 대한 연구를 제안한다. 본 논문에서 제안하는 사용자 동작 추정 방법은 Cascades 방법을 이용한 합성곱 신경망 기반 회귀모델을 적용한 방식이다. 손의 관절들은 다른 큰 관절들(어깨, 무릎, 골반 등)보다 작아서 정밀한 추정을 요구하기에 Cascades 방법을 사용해 보다 정밀하게 추정할 수 있다.",다국어 초록 정보 없음
드론기반 초분광 이미지와 합성곱 신경망을 이용한 수계 내 유해조류 수직분포 예측,2020,"['드론기반 초분광 이미지', '유해조류 예측', '클로로필a', '피코시아닌', '합성곱 신경망']",국문 초록 정보 없음,다국어 초록 정보 없음
볼트의 소리 신호를 이용한 합성곱 신경망 기반 체결력 측정 방법,2020,"['Clamping Force(체결력)', 'Convolutional Neural Network(합성곱 신경망)', 'Bolt(볼트)', 'Sound Signal(소리신호)']",국문 초록 정보 없음,"This paper presents a novel method for measuring the clamping force using sound that occurs during bolt fastening. The resonance frequency of the bolt increases with the progress of the fastening process. This characteristic change is utilized as the feature analyzed by a convolutional neural network (CNN). The clamping force is measured using a load cell, and is then used during labeling for classification. To measure the radiated noise, a microphone is installed near the fastening part. In addition, a signal-processing method is proposed to apply the measurement to deep-learning classification and perform data augmentation. The CNN architecture was modeled, and the fastening force was determined using the classification method. The estimated value was compared with the actual load cell measurements."
정체수역 수질개선 및 합성곱 신경망 모델을 이용한 모니터링에 관한 연구,2020,"['ANN', 'CNN', 'Disolved Oxygen', 'Monitoring', 'Stagnation', '인공신경망', '합성곱층 신경망', '용존산소', '모니터링', '정체수역']",국문 초록 정보 없음,"In this study, the concentration of dissolved oxygen (DO) at different water depths in a small river connected to the Nakdong River was monitored with parallel jet streamer device to improve water quality. DO probes were installed in correspondence of the upper, middle, and lower sections of the river at the different depths and operated for 2 months. To determine the stagnation of water in the river, we produced DO graphs for different depth intervals. Overall, we prepared 343 graphs, identifying 7 intervals with characteristic dissolved oxygen concentrations, including a stagnant zone. We separately applied an artificial neural network (ANN) and a convolution neural network as learning models: in the first case, a correct answer rate of only 29.2% was obtained from the derived weight and bias, while in the second case it corresponded to 94.5%. The learning graphs were randomly selected from 40 to 300. The correct answer ratios were 94.8%, 91.3%, and 88.6% for 250, 200, and 50 graphs, respectively. By applying the control logic to the actual monitoring results, we decided to label as a “stagnant region” the depth interval characterized by correct answer ratios comprised between 84.9% and 83.5% (i.e., depths between 30 m and 60 m)."
유해 남조 분류를 위한 심층 합성곱 신경망 모델 적용,2020,"['Deep neural network', 'HABs', 'Image classification', 'Machine learning', 'Mask R-CNN']","유해 조류 대발생(Harmful Algae Blooms, HABs)은 수체 내에서 일어나는 부영양화 현상으로, 영양염류를 주 영양소로 삼는 조류(algae)가 급성장하는 것이 원인이다. 환경부는 하천 및 호소에서의 주요 HABs 원인인 남조 4속(Microcystis, Anabaena, Ocillatoria, Aphanizomenon)을 지속적으로 관리하고 있다. 현재 유해 남조의 동정은 현장에서 채취한 조류를 연구자가 광학현미경으로 직접 관찰하고, 분류학적 특성에 근거하여 분석한다. 하지만 수천, 수만 개에 달하는 조류 세포를 수작업으로 동정하는 것은 많은 노동과 긴 분석 시간이 요구되는데, 현미경 분석은 실험자들의 숙련도에 따른 실험 결과의 차이가 발생하기 때문에 결과의 정확성 및 신뢰성에 대한 문제도 지속적으로 제기되고 있다. 또한, 유해 조류의 정확한 분류 및 현존량 산정을 위해서는 고도의 전문성을 가진 연구자가 필요한데 이에 부합하는 인적 자원의 수도 부족한 실정이다. 따라서 본 연구에서는 심층 합성곱 신경망 기반 이미지 분류 기법의 일종인 Mask R-CNN을 이용하여 유해 남조를 분류할 수 있는 모델을 구축하였다. 분류 대상은 유해 남조 5종으로, Microcystis aeruginosa, Microcystis wesenbergii, Anabaena circinalis, Oscillatoria tenuis, Aphanizomenon flos-aquae가 포함된다. Mask R-CNN기반 모델을 구축하기 위해 광학현미경으로 촬영한 490개의 유해 남조 이미지를 입력자료로 사용하였고, 이 중 400개를 학습에, 90개를 테스트에 사용하였다. 테스트에 사용된 90개의 이미지는 학습에 사용된 이미지와 완전히 독립된 이미지로 선별하였다. 분류 결과에 대한 평가 기준은 bounding box와 mask를 모두 고려하여, 종의 형태를 정확하게 분류한 것과 그렇지 못한 것으로 나누었다. 연구 결과, 전체 중 약 91.43%의 이미지를 정확하게 분류하였다. 정확하게 분류한 이미지 중에서, 각각의 종에 대한 bounding box의 정확도는 모두 90% 이상이었고, 전체 종에 대한 mask 정확도는 85.49%였다. 전반적으로 볼 때 모델의 분류 성능은 양호한 수준이었다. 400개의 이미지를 학습하는데 소요된 시간은 100회 반복 기준 약 1시간 30분이었다. 전체적으로 Mask R-CNN을 이용한 유해 조류 분류 모델을 이용했을 때 연구자가 직접 분류하는 것과 비교해 시간과 비용적인 측면에서 효율적인 방법이 될 수 있음을 알 수 있었다. 또한, 측정 이미지를 추가로 학습시켜 성능 개선이 가능하다는 점을 통해 향후 분류 성능이 더욱 향상된 시스템으로 발전될 수 있음을 볼 수 있었다.",다국어 초록 정보 없음
"적은 수량, 불균형 문제를 가진 학습데이터를 위한 합성곱 신경망 기반의 웨이퍼 맵 불량패턴 분류",2020,"['웨이퍼 맵 분류', '불균형 데이터', '이미지 증식', '합성곱 신경망']","반도체 웨이퍼 맵은 반도체 제조 공정 중, wafer chip의 Probe test로 얻은 결과를 나타낸 것이다. 웨이퍼 맵 상에서 불량 칩의 군집 형태는 원, 스크래치, 링 등 다양한 패턴을 보이는데, 특정 불량 패턴에 따라 불량 원인을 파악하여 반도체 공정 개선이 가능하기 때문에 불량 패턴을 정확히 분류하는 것이 중요하다.분류 대상이 되는 실험 데이터는 국내 반도체 제조회사의 웨이퍼 맵이며, 분류된 웨이퍼 맵의 수가 많지 않고 불량패턴의 유무에 따른 불균형과, 불량 패턴 내 불균형 문제가 존재한다. 본 연구에서 사용하는 머신러닝 알고리즘은 일반적으로 각 클래스 별 데이터 분포가 비슷하다는 가정 하에 뛰어난 성능을 보이지만 현실은 일부 데이터에 편향되어 있고 오히려 소수에 해당되는 클래스가 데이터 마이닝 관점에서 더 중요한 경우가 많다. 이러한 불균형 문제로 알고리즘 학습에 어려움이 존재한다.이를 위해 본 연구는 소량의 정확히 분류된 웨이퍼 맵을 클래스가 변하지 않도록 상하좌우 반전 및 회전만을 랜덤 적용하여 데이터 증식을 수행한다. 증식된 데이터를 합성곱 신경망의 한 종류인 ResNet을 사용하여 학습하고 패턴 분류 시행 및 분류 모델의 정확성을 검증한다.",다국어 초록 정보 없음
유해 남조 분류를 위한 심층 합성곱 신경망 모델 적용,2020,"['Deep neural network', 'HABs', 'Image classification', 'Machine learning', 'Mask R-CNN']","유해 조류 대발생(Harmful Algae Blooms, HABs)은 수체 내에서 일어나는 부영양화 현상으로, 영양염류를 주 영양소로 삼는 조류(algae)가 급성장하는 것이 원인이다. 환경부는 하천 및 호소에서의 주요 HABs 원인인 남조 4속(Microcystis, Anabaena, Ocillatoria, Aphanizomenon)을 지속적으로 관리하고 있다. 현재 유해 남조의 동정은 현장에서 채취한 조류를 연구자가 광학현미경으로 직접 관찰하고, 분류학적 특성에 근거하여 분석한다. 하지만 수천, 수만 개에 달하는 조류 세포를 수작업으로 동정하는 것은 많은 노동과 긴 분석 시간이 요구되는데, 현미경 분석은 실험자들의 숙련도에 따른 실험 결과의 차이가 발생하기 때문에 결과의 정확성 및 신뢰성에 대한 문제도 지속적으로 제기되고 있다. 또한, 유해 조류의 정확한 분류 및 현존량 산정을 위해서는 고도의 전문성을 가진 연구자가 필요한데 이에 부합하는 인적 자원의 수도 부족한 실정이다. 따라서 본 연구에서는 심층 합성곱 신경망 기반 이미지 분류 기법의 일종인 Mask R-CNN을 이용하여 유해 남조를 분류할 수 있는 모델을 구축하였다. 분류 대상은 유해 남조 5종으로, Microcystis aeruginosa, Microcystis wesenbergii, Anabaena circinalis, Oscillatoria tenuis, Aphanizomenon flos-aquae가 포함된다. Mask R-CNN기반 모델을 구축하기 위해 광학현미경으로 촬영한 490개의 유해 남조 이미지를 입력자료로 사용하였고, 이 중 400개를 학습에, 90개를 테스트에 사용하였다. 테스트에 사용된 90개의 이미지는 학습에 사용된 이미지와 완전히 독립된 이미지로 선별하였다. 분류 결과에 대한 평가 기준은 bounding box와 mask를 모두 고려하여, 종의 형태를 정확하게 분류한 것과 그렇지 못한 것으로 나누었다. 연구 결과, 전체 중 약 91.43%의 이미지를 정확하게 분류하였다. 정확하게 분류한 이미지 중에서, 각각의 종에 대한 bounding box의 정확도는 모두 90% 이상이었고, 전체 종에 대한 mask 정확도는 85.49%였다. 전반적으로 볼 때 모델의 분류 성능은 양호한 수준이었다. 400개의 이미지를 학습하는데 소요된 시간은 100회 반복 기준 약 1시간 30분이었다. 전체적으로 Mask R-CNN을 이용한 유해 조류 분류 모델을 이용했을 때 연구자가 직접 분류하는 것과 비교해 시간과 비용적인 측면에서 효율적인 방법이 될 수 있음을 알 수 있었다. 또한, 측정 이미지를 추가로 학습시켜 성능 개선이 가능하다는 점을 통해 향후 분류 성능이 더욱 향상된 시스템으로 발전될 수 있음을 볼 수 있었다.",다국어 초록 정보 없음
보행 중 주의분산 사고 예방을 위한 합성곱 신경망 기반의 차도와 보도 인식 연구,2020,"['CNN', 'Image Recognition', 'Cautionary Dispersion', 'Smart Device', '합성곱 신경망', '영상 인식', '주의분산', '스마트 기기']","스마트기기의 보급 및 인터넷 발달로 인해 국내 전체 인구 중 90% 이상이 스마트폰을 사용하고 있으며, 이용시간도하루 평균 3시간으로 나타났다. 이와 더불어 보도에서 보행 중 스마트폰과 주변환경에 대한 주의분산으로 인해 61.7%의보행사고가 발생하였다. 본 논문에서는 CNN(Convolution Neural Networks, 합성곱 신경망)을 기반으로 차도와 보도 인식을통해 보행 중 스마트기기 사용으로 인한 주의분산 사고 예방을 위한 차도와 보도 인식 방안을 제시한다. 신경망 구조는 CNN 5-layer와 완전연결계층 2-layer로 구성한다. 학습을 위해 학습데이터 40,000장, 시험데이터 25,000장으로 총 65,000장의 데이터셋을 확보하였고 원활한 학습을 위해 OpenCV로 전처리한다. 학습한결과 98.72%라는 높은 인식률을 보였고, 검증데이터인식률의 경우 99%의 인식률을 보였다",다국어 초록 정보 없음
여러 신체 부위의 단일 IMU를 이용한 가변 윈도우와 합성곱 신경망 기반 보행 이벤트 추정,2020,"['보행이벤트탐지 (gait event detection)', '보행주파수 (gait frequency)', '윈도우사이즈 (window size)', '관성센서 (IMU)', '합성곱신경망 (CNN)', '웨어러블 (wearables)']",국문 초록 정보 없음,"Inertial sensor-based wearables attached to various upper body parts have limitations to detect the exact gait events. In this study, we used CNN models with varying window size determined by the step frequencies to detect and estimate gait events from a single IMU attached to various body parts under wide range of the walking speeds (0.7~1.6 m/s). Seventeen participants walked on the treadmill with four different walking speeds. Each IMU attached to the waist, left side of the head, and the left wrist measured the 6-axis kinematic data of each body part. Force plates and the optical motion capture system were used for the reference. The step frequencies were extracted from the spectrum amplitude of the IMU signals using FFT to determine the window size of each gait. CNN-based double support classification model and gait event estimation model detected and estimated gait events using discriminative features of the IMU signals. The double support phases were classified with F1 scores of 79~96 %, using window sizes of 0.22~0.33 s. HS and TO were estimated with MAE of 15~27 ms. These results imply that using CNN with frequency-based window size can detect the gait events from IMU sensors attached to various body parts under wide range of the walking speeds."
합성곱 신경망을 이용한 지하공동구 화재 감지기술 개발을 위한 영상 데이터 수집 및 적용,2020,"['딥러닝', '데이터 전처리', '지하공동구', '영상 인식', '오탐률']",국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 활용한 FFT 기반 GNSS 신호 검출기법,2020,"['GNSS', 'GPS', 'acquisition', 'FFT-based code phase - frequency search', 'supervised learning', 'convolution neural network']",국문 초록 정보 없음,"This study proposes a FFT(Fast Fourier Transform )-based GNSS(Global Navigation Satellite System ) signal detection scheme using a convolution neural network. The GNSS signal is mainly transmitted from the GNSS satellites orbiting the medium Earth orbit; hence, the Doppler effect is larger than that of the mobile communication signal. A typical GNSS receiver uses an FFT-based parallel code phase-serial frequency acquisition scheme. We propose herein a novel signal detection scheme using a convolution neural network with an excellent performance in image recognition using the FFT-based parallel code phase-serial frequency correlation value as a two-dimensional image. The results show that the proposed scheme can be used as an effective detector in a general GNSS signalreceiving environment."
합성곱 신경망에서의 신뢰도 보정,2020,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망 기반 향상된 GNSS 재밍 식별기법,2020,"['GNSS', 'Jamming', 'Jamming Classification', 'Machine Learning', 'Convolutional Neural Network', 'Confusion Matrix']",국문 초록 정보 없음,"In this paper, we propose an improved global navigation satellite system (GNSS) jamming classification scheme using a convolutional neural network that directly uses an intermediate frequency (IF) sampled GNSS received signal without pre-processing. The machine learning-based GNSS jamming classification scheme recently proposed in [17] requires a short-time Fourier transform (STFT) process and a binary black-and-white image processing process through image mapping of the obtained spectrogram. The average jamming classification accuracy of the conventional scheme is approximately 94.31%, where the maximum, average, and minimum classification accuracies for single frequency modulation (FM) jamming are as low as approximately 89.55%, 83.43%, and 77.61%, respectively. The major performance deterioration factor of the conventional scheme is information loss caused by the pre-processing for the designed machine learning technique. To tackle this problem, we construct a sophisticated convolutional neural network (CNN) that directly uses the IF sampled GNSS received signal without pre-processing the conventional scheme. To evaluate the performance of the proposed scheme, the confusion matrix of the jamming classification between the conventional and the proposed schemes is compared and analyzed by Monte-Carlo simulation using 106 test samples in five representative jamming environments with no jamming. As a result of the simulation, the average jamming classification accuracy of the proposed scheme is approximately 99.41%, which improves the classification accuracy by 5.1% compared with that achieved by the conventional scheme. Additionally, the average classification accuracy of 99.07% is dramatically improved by 15.64% compared with that achieved by the conventional scheme."
합성곱 신경망을 활용한 장미잎 병충해 분류 시스템 개발,2020,"['CNN', 'Disease Classification', 'Inception', 'Plant disease', 'Rose']",국문 초록 정보 없음,"The classification of plant disease by images has been studied over past decades. In this paper, convolutional neural network models were applied to perform rose leaf disease diagnosis using simple leaves images of healthy and diseased rose leaves, through deep learning methodologies. Training of the models was performed with the use of an open database of 13,125 images, containing field and laboratory images with five different disease and healthy leaves. Based on experiments, the precision and recall are 98.7% and 97.4% and the F1-score is 0.98. The significantly high success rate makes the model a very effective advisory or early warning tool, and an approach that could be further expanded to support an rose leaf disease identification system to operate in real cultivation conditions."
합성곱 신경망 기반의 헬기 기종 분류 모형 연구,2020,"['CNN', 'binary classification', 'types of helicopters', 'Performance results', 'feature map', '.']",국문 초록 정보 없음,.
합성곱 신경망을 이용하는 수퍼픽셀 기반 사과잎 병충해의 분류,2020,"['Disease classification', 'Superpixel', 'CNN', 'Apple leaf']",국문 초록 정보 없음,"The classification of plant diseases by images captured by a camera sensor has been studied over past decades. A method that has gained much interest is to use image segmentation, from which statistical features are derived and analyzed by machine learning. Recently, deep learning has been adopted in this area. However, image segmentation is still a difficult task to achieve stable performance due to a variety of environmental variations. The end-to-end learning in neural network has a demerit that train images may be different from real images acquired in outdoor fields. To solve these problems, we propose superpixel-based disease classification method using end-to-end CNN (convolutional neural network) learning. Based on experiments performed on PlantVillage apple images, the classification accuracy is 98.29% and 92.43% for full-image and superpixel. As well, the multivariate F1-score is (0.98, 0.93). Therefore we validate that the method of using superpixel is comparable to that of full-image."
합성곱 신경망(CNN)을 이용한 U-Net 기반의 인공지능 안면 정면화 모델,2020,[],"안면 인식은 Face ID를 비롯하여 미아 찾기, 범죄자 추적 등의 분야에 도입되고 있다. 안면 인식은 최근 딥러닝을 통해 인식률이 향상되었으나, 측면에서의 인식률은 정면에 비해 특징 추출이 어려우므로 비교적 낮다. 이런 문제는 해당 인물의 정면이 없고 측면만 존재할 경우 안면 인식을 통한 신원확인이 어려워 단점으로 작용될 수 있다. 본 논문에서는 측면 이미지를 바탕으로 정면을 생성함으로써 안면 인식을 적용할 수 있는 상황을 확장하는 인공지능 기반의 안면 정면화 모델을 구현한다. 모델의 안면 특징 추출을 위해 VGG-Face를 사용하며 특징 추출에서 생길 수 있는 정보 손실을 막기 위해 U-Net 구조를 사용한다.",다국어 초록 정보 없음
합성곱 신경망을 이용한 이미지 기반의 ME 공정제작 오류 검출,2020,"['소재 압출방식(material extrusion)', '이상검출(Anomaly Detection)', '딥러닝(Deep Learning)']",국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 통한 양자 회로 에러 보정 방법,2020,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 이용한 승용차의 작동중 전달 경로 해석법 개발,2020,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 이용한 반려동물 피부 병변 분류,2020,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 활용한 항공 영상에서의 소형 객체 인식 연구,2020,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 이용한 구글 어스에서의 녹지 비율 측정,2020,[],국문 초록 정보 없음,"The preliminary investigation to expand the green space requires a lot of cost and time. In this paper, we solve the problem by measuring the ratio of green space in a specific region through a convolutional neural network based the green space classification using Google Earth images. First, the proposed method collects various region images in Google Earth and learns them by using the convolutional neural network. The proposed method divides the image recursively to measure the green space ratio of the specific region, and it determines whether the divided image is green space using a trained convolutional neural network model, and then the green space ratio is calculated using the regions determined as the green space. Experimental results show that the proposed method shows high performance in measuring green space ratios in various regions."
합성곱 신경망에서의 점진적 학습 모델에 대한 성능 하락 요인 분석,2020,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망 기반 회귀기법을 이용한 드롭웨이트 시편의 취성파면율 예측,2020,"['Drop weight tear test', 'convolutional neural network', 'regression', 'brittle fracture ratio']",국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 통한 책 장르 인식 및 책 표지 추천 시스템,2020,"['Mahin Learning', 'Deep Learning', 'Computer Vision', 'Text', 'Image']",국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 활용한 단락흔 · 용융흔의 판별 기법 제안,2020,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망 기반 AM 재밍 검출기법,2020,"['GNSS', 'AM Jamming', 'CNN', 'JNR', 'Detection Probability']",국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망 기반 컬러 압축 이미지 다종 스테그어날리시스,2020,[],국문 초록 정보 없음,"JPEG steganalysis detects JPEG stego images with messages embedded by steganographic algorithms. In this paper, I propose the steganalysis model using transfer learning and an unpooled layer. The proposed model is effective in detecting low-level stego signals and achieve better performance with lower learnable parameters than the fine-tuned models without network structure enhancement."
합성곱 신경망에서 이미지 분류를 위한 하이퍼파라미터 최적화,2020,[],국문 초록 정보 없음,"In order to obtain high accuracy with an convolutional neural network(CNN), it is necessary to set the optimal hyperparameters. However, the exact value of the hyperparameter that can make high performance is not known, and the optimal hyperparameter value is different based on the type of the dataset, therefore, it is necessary to find it through various experiments. In addition, since the range of hyperparameter values is wide and the number of combinations is large, it is necessary to find the optimal values of the hyperparameters after the experimental design in order to save time and computational costs. In this paper, we suggest an algorithm that use the design of experiments and grid search algorithm to determine the optimal hyperparameters for a classification problem. This algorithm determines the optima values of the hyperparameters that yields high performance using the factorial design of experiments. It is shown that the amount of computational time can be efficiently reduced and the accuracy can be improved by performing a grid search after reducing the search range of each hyperparameter through the experimental design. Moreover, Based on the experimental results, it was shown that the learning rate is the only hyperparameter that has the greatest effect on the performance of the model."
합성곱 신경망 알고리즘을 이용한 행동기반 눈 움직임 이벤트 탐지,2020,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 이용한 딥러닝 기반의 프레임 동기 기법,2020,['2'],국문 초록 정보 없음,"This paper proposes a new frame synchronization technique based on convolutional neural network (CNN). The conventional frame synchronizers usually find the matching instance through correlation between the received signal and the preamble. The proposed method converts the 1-dimensional correlator ouput into a 2-dimensional matrix. The 2-dimensional matrix is input to a convolutional neural network, and the convolutional neural network finds the frame arrival time. Specifically, in additive white gaussian noise (AWGN) environments, the received signals are generated with random arrival times and they are used for training data of the CNN. Through computer simulation, the false detection probabilities in various signal-to-noise ratios are investigated and compared between the proposed CNN-based technique and the conventional one. According to the results, the proposed technique shows 2dB better performance than the conventional method."
1차원 합성곱 신경망과 적대적 생성 신경망을 활용한 실시간 이상 감지,2020,[],국문 초록 정보 없음,다국어 초록 정보 없음
깊은 합성곱 신경망 기반 초해상도 모델의 경량화 연구,2020,[],국문 초록 정보 없음,다국어 초록 정보 없음
1차원 합성곱 신경망에 기반한 부정맥 분류 시스템의 설계,2020,"['ECG', 'QRS', '1']",국문 초록 정보 없음,"Recently, many researches have been actively to diagnose symptoms of heart disease using ECG signal, which is an electrical signal measuring heart status. In particular, the electrocardiogram signal can be used to monitor and diagnose arrhythmias that indicates an abnormal heart status. In this paper, we proposed 1-D convolutional neural network for arrhythmias classification systems. The proposed model consists of deep 11 layers which can learn to extract features and classify 5 types of arrhythmias. The simulation results over MIT-BIH arrhythmia database show that the learned neural network has more than 99% classification accuracy. It is analyzed that the more the number of convolutional kernels the network has, the more detailed characteristics of ECG signal resulted in better performance. Moreover, we implemented a practical application based on the proposed one to classify arrythmias in real-time."
그래프 합성곱 신경망 인코더와 계층 구조 디코더를 이용한 키워드 생성,2020,[],국문 초록 정보 없음,다국어 초록 정보 없음
3차원 합성곱 신경망을 활용한 실시간 전략 게임 승패 예측,2020,"['3-Dimensional Convolutional Neural Networks', 'Game Artificial Intelligence', 'Real-Time Strategy Game', 'e-Sports', 'StarCraft II', 'Win-Lose Prediction Model', 'N']",국문 초록 정보 없음,"The game industry has been continually evolving under the name of e-sports. As various competitions are held, it is important to provide viewers with relevant game-related information. In particular, predicting the final outcome of a game based on certain situations is one of the players’ main interests. However, in strategy games such as StarCraft II, it is difficult to predict outcomes because of many factors including the various units, their combinations, and unit upgrades. Previous studies predicted win or loss using only partial information such as the image information of a specific time frame. In this study, we propose the win-lose prediction model using feature information of game images sequentially based on 3-dimensional convolutional neural networks."
확장 합성곱 신경망을 통한 이미지 분류,2020,"['Deep Learning', 'Convolution Neural Network', 'Computer Vision', 'Supervised Learning', 'Deep Neural Network']",국문 초록 정보 없음,다국어 초록 정보 없음
잔차 신경망과 팽창 합성곱 신경망을 이용한 라이트 필드 각 초해상도 기법,2020,[],국문 초록 정보 없음,"Light field image captured by a microlens array-based camera has many limitations in practical use due to its low spatial resolution and angular resolution. High spatial resolution images can be easily acquired with a single image super-resolution technique that has been studied a lot recently. But there is a problem in that high angular resolution images are distorted in the process of using disparity information inherent among images, and thus it is difficult to obtain a high-quality angular resolution image. In this paper, we propose light field angular super-resolution that extracts an initial feature map using an dilated convolutional neural network in order to effectively extract the view difference information inherent among images and generates target image using a residual neural network. The proposed network showed superior performance in PSNR and subjective image quality compared to existing angular super-resolution networks."
다상 합성곱 신경망의 정확도 향상을 위한 훈련 기법,2020,[],국문 초록 정보 없음,다국어 초록 정보 없음
순환 신경망과 합성곱 신경망을 이용한 뉴스 기사 편향도 분석,2020,[],국문 초록 정보 없음,"While search portals' 'Portal News' account for the largest portion of aggregated news outlet, its neutrality as an outlet is questionable. This is because news aggregation may lead to prejudiced information consumption by recommending biased news articles. In this paper we introduce a new method of measuring political bias of news articles by using deep learning. It can provide its readers with insights on critical thinking. For this method, we build the dataset for deep learning by analyzing articles' bias from keywords, sourced from the National Assembly proceedings, and assigning bias to said keywords. Based on these data, news article bias is calculated by applying deep learning with a combination of Convolution Neural Network and Recurrent Neural Network. Using this method, 95.6% of sentences are correctly distinguished as either conservative or progressive-biased; on the entire article, the accuracy is 46.0%. This enables analyzing any articles' bias between conservative and progressive unlike previous methods that were limited on article subjects."
X-선 영상과 합성곱 신경망을 이용한 육류 내의 바늘 검출,2020,"['X-ray Image', 'Convolutional Neural Network (CNN)', 'Foreign Object Detection', 'Needle', 'Hough Transform']",국문 초록 정보 없음,"The most lethal foreign body in meat is a needle, and X-ray images are used to detect it. However, because the difference in thickness and fat content is severe depending on the type of meat and the part of the meat, the shade difference and contrast appear severe. This problem causes difficulty in automatic classification. In this paper, we propose a method for generating training patterns by efficient preprocessing and classifying needles in meat using a convolution neural network. Approximately 24000 training patterns and 4000 test patterns were used to verify the proposed method, and an accuracy of 99.8% was achieved."
오차 기반 합성곱 신경망을 활용한 원형 플러그 아연 도금 불량 판별,2020,"['Error based learning', 'Zinc plating of circular plug', 'Convolutional deep learning', 'ResNet-50']",국문 초록 정보 없음,다국어 초록 정보 없음
무선랜 시스템에서 합성곱 신경망 기반의 반송파 주파수 오차 추정 기법,2020,[],국문 초록 정보 없음,다국어 초록 정보 없음
무선랜 시스템에서 합성곱 신경망을 이용한 시간 및 반송파 주파수 오차 동시 추정,2020,[],국문 초록 정보 없음,다국어 초록 정보 없음
데이터 불균형에 따른 합성곱 신경망의 항암치료반응 예측 연구,2020,[],국문 초록 정보 없음,다국어 초록 정보 없음
고주파 통과 필터와 합성곱 신경망을 이용한 동영상 촬영 장치 판별 알고리즘,2020,"['video capturing device identification', 'high-pass filter', 'convolutional neural network', 'video forensics']",국문 초록 정보 없음,"Advances in IT technology make it easy for anyone to access high performance but low-cost video capturing devices and produce videos. However, these videos cause many social problems due to illegal use, and thus video forensic technology is required. In this paper, as one of the video forensic technologies, we propose an algorithm for identifying a video capturing device using a high frequency filter and a convolutional neural network. Many previous studies have focused on image capturing devices not video capturing devices. In videos, there are differences from images in frame characteristics, compression method, compression rate, and huge capacity. Therefore, it is impossible to directly apply the technology targeting the images and hence we developed an optimized algorithm for the videos. In order to analyze the performance of the proposed algorithm, videos captured by 31 various capturing devices including the same brand and model were used and we achieved an 91.3% accuracy. Also, we showed that the proposed algorithm can identify the models of the same brand with 91.1% accuracy higher than the previous studies."
뇌파 신호에서 3 차원 합성곱 인공신경망을 활용한 작업기억용량 추정,2020,[],국문 초록 정보 없음,다국어 초록 정보 없음
D-PMU 데이터를 사용한 심층 합성곱 생성적 적대신경망(DCGAN) 기반 이벤트 감지 기법,2020,[],국문 초록 정보 없음,다국어 초록 정보 없음
시분할 특징 융합 합성곱 신경망을 이용한 스마트폰 사용자의 행동 검출,2020,[],국문 초록 정보 없음,"Since the spread of smart phones, interest in wearable devices has increased and diversified, and is closely related to the lives of users, and has been used as a method for providing personalized services. In this paper, we propose a method to detect the user's behavior by applying information from a 3-axis acceleration sensor and a 3-axis gyro sensor embedded in a smartphone to a convolutional neural network. Human behavior differs according to the size and range of motion, starting and ending time, including the duration of the signal data constituting the motion. Therefore, there is a performance problem for accuracy when applied to a convolutional neural network as it is. Therefore, we proposed a Time-Division Feature Fusion Convolutional Neural Network (TDFFCNN) that learns the characteristics of the sensor data segmented over time. The proposed method outperformed other classifiers such as SVM, IBk, convolutional neural network, and long-term memory circulatory neural network."
변수 간 교호작용을 반영한 합성곱 신경망 기반의 특질 추출 모델,2020,[],국문 초록 정보 없음,다국어 초록 정보 없음
음성 신호를 이용한 합성곱 신경망 기반 신원 확인 시스템,2020,[],국문 초록 정보 없음,다국어 초록 정보 없음
기계 결함 감지를 위한 합성곱 신경망 모델,2020,[],국문 초록 정보 없음,다국어 초록 정보 없음
협업 계층을 적용한 합성곱 신경망 기반의 이미지 라벨 예측 알고리즘,2020,"['Collaborative Filtering', 'Convolution Neural Network', 'Image Label Prediction']",국문 초록 정보 없음,"A typical algorithm used for image analysis is the Convolutional Neural Network(CNN). R-CNN, Fast R-CNN, Faster R-CNN, etc. have been studied to improve the performance of the CNN, but they essentially require large amounts of data and high algorithmic complexity., making them inappropriate for small and medium-sized services. Therefore, in this paper, the image label prediction algorithm based on CNN with collaborative layer with low complexity, high accuracy, and small amount of data was proposed. The proposed algorithm was designed to replace the part of the neural network that is performed to predict the final label in the existing deep learning algorithm by implementing collaborative filtering as a layer. It is expected that the proposed algorithm can contribute greatly to small and medium-sized content services that is unsuitable to apply the existing deep learning algorithm with high complexity and high server cost."
잔차 압축-자극 블록과 다중 스케일 합성곱 신경망을 이용한 잡음 제거 기술,2020,[],국문 초록 정보 없음,다국어 초록 정보 없음
타이어 품질 예측 및 원인 분석을 위한 합성곱 신경망,2020,"['Automobile', 'Tire Quality', 'Deep Learning', 'Convolutional Neural Networks', 'Class Activation Map']",국문 초록 정보 없음,"Recently, machine learning algorithms have been widely applied in the automotive industry. In particular, it is important to characterize tire quality that can determine the reliability of product design. However, the previous studies are insufficient to explain tire quality because they are based mainly on experimental design methods. In this study, we propose using convolutional neural networks (CNN) and class activation map (CAM) to predict tire quality and perform cause analysis. To properly reflect the location information of a car, we convert the structured data into the image data. We compare the proposed CNN+CAM with other machine learning methods including random forest, gradient boosting machine, adaboost, linear regression with feature selection, support vector regression, partial least square regression, and deep neural networks. The results indicate that the CNN+ CAM yields higher prediction accuracy than other methods. This implies that the proposed CNN+CAM can identify important variables that play an important role in predicting tire quality."
얼굴 감정 인식을 위한 경량 합성곱 신경망(CNN) 구조 연구,2020,[],국문 초록 정보 없음,다국어 초록 정보 없음
내시경의 위암과 위궤양 영상을 이용한 합성곱 신경망 기반의 자동 분류 모델,2020,"['Gastroscopy', 'Classification', 'ResNet-50', 'Gastric ulcer', 'Gastric cancer']",국문 초록 정보 없음,"Although benign gastric ulcers do not develop into gastric cancer, they are similar to early gastric cancer and difficult to distinguish. This may lead to misconsider early gastric cancer as gastric ulcer while diagnosing. Since gastric cancer does not have any special symptoms until discovered, it is important to detect gastric ulcers by early gastroscopy to prevent the gastric cancer. Therefore, we developed a Convolution Neural Network (CNN) model that can be helpful for endoscopy. 3,015 images of gastroscopy of patients undergoing endoscopy at Gachon University Gil Hospital were used in this study. Using ResNet-50, three models were developed to classify normal and gastric ulcers, normal and gastric cancer, and gastric ulcer and gastric cancer. We applied the data augmentation technique to increase the number of training data and examined the effect on accuracy by varying the multiples. The accuracy of each model with the highest performance are as follows. The accuracy of normal and gastric ulcer classification model was 95.11% when the data were increased 15 times, the accuracy of normal and gastric cancer classification model was 98.28% when 15 times increased likewise, and 5 times increased data in gastric ulcer and gastric cancer classification model yielded 87.89%. We will collect additional specific shape of gastric ulcer and cancer data and will apply various image processing techniques for visual enhancement. Models that classify normal and lesion, which showed relatively high accuracy, will be re-learned through optimal parameter search."
얼굴 감정인식을 위한 양자화된 경량 합성곱 신경망 구조 연구,2020,"['Face emotion recognition', 'Deep learning', 'Data augmentation', 'Lightweight CNN', 'Quantization']",국문 초록 정보 없음,다국어 초록 정보 없음
아동음성 검출에 활용 가능한 고속 지역 합성곱 신경망 기반의 음원 분류 기법에 관한 연구,2020,[],국문 초록 정보 없음,다국어 초록 정보 없음
"이미지 기반 기계 학습과 BIM을 활용한 자동화된 시공 진도 관리 - 합성곱 신경망 모델(CNN)과 실내측위기술, 4D BIM을 기반으로 -",2020,[],국문 초록 정보 없음,"A daily progress monitoring and further schedule management of a construction project have a significant impact on the construction manager's decision making in schedule change and controlling field operation. However, a current site monitoring method highly relies on the manually recorded daily-log book by the person in charge of the work. For this reason, it is difficult to take a detached view and sometimes human error such as omission of contents may occur. In order to resolve these problems, previous researches have developed automated site monitoring method with the object recognition-based visualization or BIM data creation. Despite of the research results along with the related technology development, there are limitations in application targeting the practical construction projects due to the constraints in the experimental methods that assume the fixed equipment at a specific location. To overcome these limitations, some smart devices carried by the field workers can be employed as a medium for data creation. Specifically, the extracted information from the site picture by object recognition technology of CNN model, and positional information by GIPS are applied to update 4D BIM data. A standard CNN model is developed and BIM data modification experiments are conducted with the collected data to validate the research suggestion. Based on the experimental results, it is confirmed that the methods and performance are applicable to the construction site management and further it is expected to contribute speedy and precise data creation with the application of automated progress monitoring methods."
"적외선 영상, 라이다 데이터 및 특성정보 융합 기반의 합성곱 인공신경망을 이용한 건물탐지",2020,"['Deep Learning', 'Haralick Feature', 'Multimodal Data', 'Detectron2', 'Instance Segmentation', '딥러닝', 'Haralick 특성', '다중 데이터', '객체분할']",국문 초록 정보 없음,다국어 초록 정보 없음
싱글숏 멀티박스 검출기에서 객체 검출을 위한 가속 회로 인지형 가지치기 기반 합성곱 신경망 기법,2020,"['Convolutional neural networks', 'Pruning', 'Object detection', 'Single-shot multibox detector']",국문 초록 정보 없음,"Convolutional neural networks (CNNs) show high performance in computer vision tasks including object detection, but a lot of weight storage and computation is required. In this paper, a pruning scheme is applied to CNNs for object detection, which can remove much amount of weights with a negligible performance degradation. Contrary to the previous ones, the pruning scheme applied in this paper considers the base accelerator architecture. With the consideration, the pruned CNNs can be efficiently performed on an ASIC or FPGA accelerator. Even with the constrained pruning, the resulting CNN shows a negligible degradation of detection performance, less-than-1% point degradation of mAP on VOD0712 test set. With the proposed scheme, CNNs can be applied to objection dtection efficiently."
i-FireNet: 에지 AI 환경에서 실시간 산불감지를 위해 일반화 성능을 향상한 경량형 합성곱 신경망,2020,"['Forest Fire Detection', 'Real-Time', 'Lightweight', 'CNN', 'Edge AI', 'Embedded Deep Learning', '.']",국문 초록 정보 없음,.
복합 노이즈 제거를 위한 전방위 잔여 학습 기반의 합성곱 신경망,2020,[],국문 초록 정보 없음,"Since most denoising algorithms only aim to remove Add White Gaussian Noise, it is difficult to remove multi type noises from real systems. In this paper, we propose multi type denoising based on the Residual Forward Subtracted Network. The key point of this network is Global, Local Residual Learning, and these technologies lead to the restoration of harmonious and perfect by maximizing the performance of image restoration."
심층 합성곱 생성적 적대 신경망을 이용한 전력 데이터 생성 및 정확도 측정,2020,[],국문 초록 정보 없음,다국어 초록 정보 없음
그래프신경망과 멀티 모달 장면 그래프 맥락 정보를 이용한 생성,2020,[],"본 논문에서는 입력 영상에 담긴 다양한 물체들과 그들 간의 관계를 효과적으로 탐지하여, 하나의 장면 그래프로 표현해내는 새로운 심층 신경망 모델을 제안한다. 제안 모델에서는 물체와 관계의 효과적인 탐지를 위해, 합성 곱 신경망 기반의 시각 맥락 특징들뿐만 아니라 언어 맥락 특징들을 포함 하는 다양한 멀티 모달 맥락 정보들을 활용한다. 또한, 제안 모델에서는 관계를 맺는 두 물체 간의 상호 의존성이 그래프 노드 특징값들에 충분히 반영되도록, 그래프 신경망을 이용해 맥락 정보를 임베딩한다. 본 논문에서는 Visual Genome 벤치마크 데이터 집합을 이용한 비교 실험들을 통해, 제안 모델의 효과와 성능을 입증한다.",다국어 초록 정보 없음
신경망의 시계열 특징 추출 기능과 개선된 해석 방안을 활용한 반도체 수율 예측 모델,2020,"['다변량 시계열 분석', '랜덤 포레스트', '반도체 공정', '합성곱 신경망', '해석 모델', 'Convolutional neural network', 'interpretable model', 'multivariate time series analysis', 'random forest', 'semiconductor']",본 논문은 시계열 형태인 다변량 설명변수를 이용하여 분류 예측 모델을 생성하고 해석하는 방안에 관한 것이다. 특히 예측 모델에 영향을 미친 주요 시계열 구간을 파악하는 방법을 소개하였다. 기존에는 시계열 데이터의 특징을 분석가가 직접 추출한 후 모델에 적용하여 예측 성능이 하락하거나 분석 비용이 높다는 문제가 있었다. 대안으로 신경망을 이용하여 특징을 스스로 학습하는 방안이 소개되었으나 결과에 대한 해석이 불가능하여 실용적 활용에 제한이 있었다. 우리는 신경망이 학습을 통해 추출한 각 특징에 대한 중요도를 계산하고 더 나아가 시계열 구간에 대한 중요도를 파악할 수 있도록 모델을 설계하고 해석하였다.,"Yield prediction models serve critical functions in semiconductor manufacturing. Generally, such models require a manual and knowledge-based feature engineering process. The engineered features are limited in use and susceptible to the new changes in production system. This paper focuses on developing a convolutional neural network (CNN) model that can automatically extract important features from multivariate time series data recorded during wafer production. The trained 1D-CNN model could accurately predict yield efficiency and class activation map (CAM) could point out regions of input that have significant influence on a prediction. In addition, the trained CNN model is ensembled with a random forest model to identify important convolution kernels and time series variables. CNN models show 96.1% accuracy in average and the average accuracy is increased by 1.8% when random forest model is trained with the features extracted by CNN model. CAM enables better interpretation of CNN prediction and ensemble method allow extended analyzation of multivariate time series data."
심층신경망의 더블 프루닝 기법의 적용 및 성능 분석에 관한 연구,2020,"['Model Compression', 'Model Light Weight', 'Deep Learning', 'Pruning', 'Network-Slimming', '모델압축', '모델 경량화', '딥러닝', '프루닝', '네트워크 간소화']","최근 인공지능 딥러닝 분야는 컴퓨팅 자원의 높은 연산량과 가격문제로 인해 상용화에 어려움이 존재했다. 본 논문은 더블 프루닝 기법을 적용하여 심층신경망 모델들과 다수의 데이터셋에서의 성능을 평가하고자 한다. 더블 프루닝은 기본의 네트워크 간소화(Network-Slimming)과 파라미터 프루닝(Parameter-Pruning)을 결합한다. 이는 기존의 학습에 중요하지 않는 매개변수를 절감하여 학습 정확도를 저해하지 않고 속도를 향상시킬 수 있다는 장점이 있다. 다양한 데이터셋 학습 이후에 프루닝 비율을 증가시켜, 모델의 사이즈를 감소시켰다. NetScore 성능 분석 결과 MobileNet-V3가 가장 성능이 높게 나타났다. 프루닝 이후의 성능은 Cifar 10 데이터셋에서 깊이 우선 합성곱 신경망으로 구성된 MobileNet-V3이 가장 성능이 높았고, 전통적인 합성곱 신경망으로 이루어진 VGGNet, ResNet또한 높은 폭으로 성능이 증가함을 확인하였다.","Recently, the artificial intelligence deep learning field has been hard to commercialize due to the high computing power and the price problem of computing resources. In this paper, we apply a double pruning techniques to evaluate the performance of the in-depth neural network and various datasets. Double pruning combines basic Network-slimming and Parameter-prunning. Our proposed technique has the advantage of reducing the parameters that are not important to the existing learning and improving the speed without compromising the learning accuracy. After training various datasets, the pruning ratio was increased to reduce the size of the model.We confirmed that MobileNet-V3 showed the highest performance as a result of NetScore performance analysis. We confirmed that the performance after pruning was the highest in MobileNet-V3 consisting of depthwise seperable convolution neural networks in the Cifar 10 dataset, and VGGNet and ResNet in traditional convolutional neural networks also increased significantly."
생성적 적대 신경망과 딥러닝을 활용한 이상거래탐지 시스템 모형,2020,"['이상거래탐지', '딥러닝', '생성적 적대 신경망', 'Fraud Detection System', 'Deep Neural Net', 'Convolutional Neural Net', 'Generative Adversarial Network']","인공지능이 다루기 어려운 개념에서 아주 익숙한 도구로 자리매김 하고 있다. 이와 더불어 금융권에서도 인공지능 기술을 도입하여 기존 시스템의 문제점을 개선하고자 하는 추세이며, 그 대표적인 예가 이상거래탐지 시스템(Fraud Detection System, FDS)이다. 결제 수단의 다양화 및 전자금융거래의 증가에 따라 치밀해져 가는 사이버 금융사기(Fraud)를 기존의 규칙기반 FDS로는 탐지하기 어려워지고 있다. 이를 극복하기 위해 딥러닝 기술을 적용하여 이상거래 탐지율을 향상시키고, 이상행위에 즉각 대응하며, 탐지 결과의 반영을 자동화하고자 하는 시도가 이루어지고 있다. 딥러닝 FDS 구축에서 핵심 문제는 데이터 불균형과 이상거래 패턴의 변동이다. 본 논문에서는 생성적 적대 신경망(Generative Adversarial Network, GAN)을 활용한 오버샘플링 기법을 통해 데이터 불균형 문제를 개선하고, 이상거래 분류기로써 심층 신경망(Deep Neural Network, DNN)과 합성곱 신경망(Convolutional Neural Network, CNN)을 적용하여 이러한 문제를 개선하고자 하였다. 실험 결과, GAN 오버샘플링이 이상거래 데이터의 불균형 문제를 개선하는데 효과를 보였으며, WGAN이 가장 높은 개선 효과가 있음을 확인하였다. 또한 제안 FDS 모형의 AUC가 0.9857로 랜덤포레스트 FDS 모형에 비해 약 6.5% 향상되어, 딥러닝이 이상거래 탐지에 뛰어난 성능을 가짐을 입증하였다. 더불어 딥러닝 모형 중 DNN은 CNN에 비해 오버샘플링의 효과를 더 잘 반영함을 확인하였다.",다국어 초록 정보 없음
청각 장애인용 홈 모니터링 시스템을 위한 다채널 다중 스케일 신경망 기반의 사운드 이벤트 검출,2020,"['Sound event detection', 'Multichannel audio features', 'Multi-scale neural networks', 'Bidirectional gated recurrent neural networks', '사운드 이벤트 검출', '다채널 오디오 특징 값', '다중 스케일 신경망', '양방향 게이트 순환 신경망']","본 논문에서는 청각 장애인을 위한 소리 감지 홈 모니터링을 위해 다채널 다중 스케일 신경망을 사용한 사운드이벤트 검출 방식을 제안한다. 제안하는 시스템에서는 홈 내의 여러 무선 마이크 센서들로부터 높은 신호 품질을 갖는두 개의 채널을 선택하고, 그 신호들로부터 도착신호 지연시간, 피치 범위, 그리고 다중 스케일 합성 곱 신경망을 로그멜 스펙트로그램에 적용하여 추출한 특징들을 양방향 게이트 순환 신경망 기반의 분류기에 적용함으로써 사운드 이벤트 검출의 성능을 더욱 향상시킨다. 검출된 사운드 이벤트 결과는 선택된 채널의 센서 위치와 함께 텍스트로 변환되어청각 장애인에게 제공된다. 실험결과는 제안한 시스템의 사운드 이벤트 검출 방식이 기존 방식보다 우수하며 청각 장애인에게 효과적으로 사운드 정보를 전달할 수 있음을 보인다.","In this paper, we propose a sound event detection method using a multi-channel multi-scale neural networks for sound sensing home monitoring for the hearing impaired. In the proposed system, two channels with high signal quality are selected from several wireless microphone sensors in home. The three features (time difference of arrival, pitch range, and outputs obtained by applying multi-scale convolutional neural network to log mel spectrogram) extracted from the sensor signals are applied to a classifier based on a bidirectional gated recurrent neural network to further improve the performance of sound event detection. The detected sound event result is converted into text along with the sensor position of the selected channel and provided to the hearing impaired. The experimental results show that the sound event detection method of the proposed system is superior to the existing method and can effectively deliver sound information to the hearing impaired."
인공신경망 기반 손영상 인식기술을 이용한 가위바위보 게임,2020,[],최근 코로나 19로 인한 사회적 거리 두기 확산에 따라 언택트 문화가 새로운 패러다임으로 등장해 사회 전반으로 확산되고 있다. 언택트 문화의 확산으로 컴퓨터를 사용할 때 직접적인 접촉이 있는 키보드나 마우스 같은 입력장치는 공공장소에서 여러 사람이 접촉할 경우 문제가 생길 수 있다. 본 논문에서는 웹캠을 통해 입력된 영상에서 손동작을 인식하는 합성곱 신경망을 학습하고 결과로 나온 추론 모델을 이용하여 비접촉 가위바위보 게임을 구현하였다.,다국어 초록 정보 없음
심층 신경망 기법을 이용한 고체 산화물 연료전지 스택의 성능 예측 모델,2020,"['고체 산화물 연료전지', '심층 학습', '합성곱 신경망', '성능 예측', '회귀', 'Solid oxide fuel cell', 'Deep learning', 'Convolutional neural network', 'Performance prediction', 'Regression']",국문 초록 정보 없음,"The performance prediction model of a solid oxide fuel cell stack has been developed using deep neural network technique, one of the machine learning methods. The machine learning has been received much interest in various fields, including energy system mo- deling. Using machine learning technique can save time and cost requried in developing an energy system model being compared to the conventional method, that is a combination of a mathematical modeling and an experimental validation. Results reveal that the mean average percent error, root mean square error, and coefficient of determination (R2) range 1.7515, 0.1342, 0.8597, repectively, in maximum. To improve the predictability of the model, the pre-processing is effective and interpolative machine learning and application is more accurate than the extrapolative cases."
이진화된 컨벌루션 신경망을 위한 낮은 복잡도의 추론 가속 프로세서,2020,"['BCNN', 'Inference accelerator', 'FPGA', 'Embedded system', 'Low complexity']","본 논문은 이진화된 컨벌루션 신경망의 추론을 가속하는 낮은 복잡도의 프로세서를 제안한다. 제안하는 프로세서에서는 전체 신경망을 컨벌루션, 이진화, 풀링으로 이루어진 블록 단위로 통합적으로 처리하고, 각 블록의 입출력은 모두 이진화되어, 블록의 내부 결과물을 임시 저장하기 위한 추가적인 버퍼를 제거하였다. 또한 1×1 컨벌루션을 기반으로 임의의 컨벌루션을 분해하여 처리하고 완전 연결 레이어에서의 행렬 곱도 같은 방식으로 처리한다. 제안하는 프로세서는 완전 합성 가능한 형태의 Softcore로 제작되었고, 이를 Cyclone V FPGA에서 구현한 결과, 1.05 K의 Adaptive Logic Module과 2304 Kbit의 메모리만으로 구현되었으며 최대 25.8 GOP/s의 속도를 보인다.","This paper proposes a low-complexity processor that accelerates the inference of the binarized convolutional neural networks. The proposed processor performs overall inference by the block, whose processing steps are convolution, binarization, and pooling. Each block is formulated to have a binary input and binary output, so that additional buffers to store inter-step temporary results can be eliminated effectively. The proposed processor processes each block by decomposing it to multiple 1×1 convolutions, thereby accelerates any blocks including convolutional layer and fully-connected layer, in a consistent way. It is implemented on Cyclone V FPGA with only 1.05 K adaptive logic module (ALM) and 2304 Kbit on-chip memory, showing the complexity efficiency of 22.514 GOP/s/KALM."
지진하중을 받는 구조물의 준실시간 모드해석 기반 손상평가를 위한 비지도 심층신경망 개발,2020,"['준실시간 손상평가', '구조 손상지수', '지진 응답', '심층신경망', '합성곱 변이형 오토인코더', '시간 영역 분해', '의사 국소 유연도법']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN-based Speech Emotion Recognition Model Applying Transfer Learning and Attention Mechanism,2020,"['음성 감정 인식', '멜-스펙트로그램', 'MFCC', '합성곱 신경망', '전이학습', '어텐션', 'speech emotion recognition', 'Mel-Spectrogram', 'CNN', 'transfer learning', 'attention']",국문 초록 정보 없음,다국어 초록 정보 없음
인지 무선 통신에서 전이 학습을 이용한 딥러닝 기반 변조 신호 센싱 기법,2020,"['Signal detection', 'Cognitive radio', 'Deep learning', 'Transfer Learning', 'Dynamic time warping']",국문 초록 정보 없음,다국어 초록 정보 없음
Super-resolution Convolutional Neural Network를 이용한 전산화단층상의 화질 평가,2020,"['초고해상도 합성곱 신경망', '초 매개 변수', '전산화단층촬영', '영상 화질', 'Super-resolution convolutional neural network', 'Hyperparameter', 'Computed tomography', 'Image quality']","고화질의 전산화단층촬영상을 통해 정확한 병변 검출과 진단을 할 수 있다. 이와 같은 장점 때문에 전산화단층촬영 시 방사선량을 줄이면서 영상 화질을 개선하기 위해 많은 연구가 수행되었다. 최근 전산화단층촬영상 화질을 향상시키기 위한 딥러닝 기반 기술이 개발되었고, 기존의 기술에 비해 우수한 성능을 보이고 있다. 본 연구에서는 전산화단층촬영상의 공간분해능을 향상시키기 위해 초고해상도 합성곱 신경망 모델을 사용하였으며, 초고해상도 합성곱 신경망 모델의 성능을 결정하는 초 매개 변수 변화에 따른 영상 화질을 평가하여 초고해상도 합성곱 신경망 모델에 대한 초 매개 변수의 효과를 검증하였다. Profile, 구조적 유사성 지수, 최대신호 대 잡음비 및 반치폭을 측정하여 초 매개 변수 변화에 따른 초고해상도 합성곱 신경망 모델의 성능을 평가하였다. 연구결과, 초고해상도 합성곱 신경망 모델의 성능은 epoch와 training set이 증가함에 따라 향상되었으며, 전산화단층촬영상 화질을 향상시키기 위해 learning rate 최적화가 필요하다는 사실을 확인하였다. 따라서 최적의 초 매개 변수와 함께 구현된 초고해상도 합성곱 신경망 모델은 전산화단층촬영상의 품질을 향상시킬 수 있다.","High-quality computed tomography (CT) images enable precise lesion detection and accurate diagnosis. A lot of studies have been performed to improve CT image quality while reducing radiation dose. Recently, deep learning-based techniques for improving CT image quality have been developed and show superior performance compared to conventional techniques. In this study, a super-resolution convolutional neural network (SRCNN) model was used to improve the spatial resolution of CT images, and image quality according to the hyperparameters, which determine the performance of the SRCNN model, was evaluated in order to verify the effect of hyperparameters on the SRCNN model. Profile, structural similarity (SSIM), peak signal-to-noise ratio (PSNR), and full-width at half-maximum (FWHM) were measured to evaluate the performance of the SRCNN model. The results showed that the performance of the SRCNN model was improved with an increase of the numbers of epochs and training sets, and the learning rate needed to be optimized for obtaining acceptable image quality. Therefore, the SRCNN model with optimal hyperparameters is able to improve CT image quality."
머신러닝을 사용한 단층 탐지 기술 연구 동향 분석,2020,"['단층 탐지', '기계 학습', '서포트벡터머신', '심층 신경망', '합성곱 신경망', 'fault detection', 'machine learning', 'support vector machine', 'deep neural networks', 'convolutional neural networks']","단층은 근원암에서 형성된 석유 가스 등의 탄화수소가 이동하는 통로이자 탄화수소를 가두는 덮개암의 역할을 할수 있는 지질구조로, 탄화수소가 축적된 저류층을 찾기 위한 탄성파 탐사의 주요 대상 중 하나이다. 하지만 기존의 유사성, 응집성, 분산, 기울기, 단층가능성 등 탄성파 자료의 측면 방향 불연속성을 활용하는 단층 감지 방법들은 전문지식을 갖춘 해석자가 많은 계산 비용과 시간을 투자해야 한다는 문제가 있다. 따라서 많은 연구자들이 단층 해석에필요한 계산 비용과 시간을 절약하기 위한 다양한 연구를 진행하고 있고, 최근에는 머신러닝 기술을 활용한 연구들이활발히 수행되고 있다. 단층 해석에는 다양한 머신러닝 기술들 중 서포트백터머신, 다층퍼셉트론, 심층 신경망, 합성곱 신경망 등의 알고리즘이 사용되고 있다. 특히 합성곱 신경망을 활용한 연구는 독자적인 구조의 모델을 사용한 연구뿐만 아니라, 이미지 처리 분야에서 성능이 검증된 모델을 활용한 연구 및 단층의 위치와 주향, 경사 등의 정보를함께 해석하는 연구도 활발히 진행되고 있다. 이 논문에서는 이러한 연구들을 조사하고 분석하여, 현재까지 단층 위치 및 단층 정보 해석에 가장 효과적인 기술은 영상 처리 분야에서 검증된 U-Net 구조를 바탕으로 한 합성곱 신경망인 것을 확인했다. 이러한 합성곱 신경망에 전이학습 및 데이터 증식 기법을 접목하면 앞으로 더욱 효과적인 단층감지 및 정보 해석이 가능할 것으로 기대된다.",다국어 초록 정보 없음
기계 학습을 활용한 이미지 결함 검출 모델 개발,2020,"['이미지 결함 검출', '서포트 벡터 머신', '다층 퍼셉트론', '합성곱 신경망', 'Image Defect Detection', 'Support Vector Machine', 'Multi-Layer Perceptron', 'Convolutional Neural Network']","최근 기계 학습을 활용한 비전 검사 시스템의 개발이 활발해지고 있다. 본 연구는 기계 학습을 활용한 결함 검사 모델을 개발하고자 한다. 이미지에 대한 결함 검출 문제는 기계 학습에 있어 지도 학습 방법인 분류 문제에 해당한다. 본 연구에서는 특징을 자동 추출하는 알고리즘과 특징을 추출하지 않는 알고리즘을 기반으로 결함 검출 모델을 개발한다. 특징을 자동 추출하는 알고리즘으로 1차원 합성곱 신경망과 2차원 합성곱 신경망을 활용하였으며, 특징을 추출하지 않는 알고리즘으로 다중 퍼셉트론, 서포트 벡터 머신을 활용하였다. 4가지 모델을 기반으로 결함 검출 모델을 개발하였고 이들의 정확도와 AUC를 기반으로 성능 비교하였다. 이미지 분류는 합성곱 신경망을 활용한 모델 개발이 일반적임에도, 본 연구에서 이미지의 화소를 RGB 값으로 변환하여 서포트 벡터 머신 모델을 개발할 때 높은 정확도와 AUC를 얻을 수 있었다.","Recently, the development of a vision inspection system using machine learning has become more active. This study seeks to develop a defect inspection model using machine learning. Defect detection problems for images correspond to classification problems, which are the method of supervised learning in machine learning. In this study, defect detection models are developed based on algorithms that automatically extract features and algorithms that do not extract features. One-dimensional CNN and two-dimensional CNN are used as algorithms for automatic extraction of features, and MLP and SVM are used as algorithms for non-extracting features. A defect detection model is developed based on four models and their accuracy and AUC compare based on AUC. Although image classification is common in the development of models using CNN, high accuracy and AUC is achieved when developing SVM models by converting pixels from images into RGB values in this study."
CNN 기반 토마토 질병 분류를 위한 DCGAN 이미지 데이터 확장 영향 평가,2020,"['합성곱 신경망', '심층 합성곱 생성적 적대 신경망', '데이터셋 불균형', '이미지 데이터 확장', '분류기', 'CNN', 'DCGAN', 'Unbalanced Dataset', 'Image Data Augmentation', 'Classifier']",국문 초록 정보 없음,"With the development of deep learning and the advent of CNN(Convolutional Neural Network), research on image data classification has been actively conducted. However, performance is deteriorated when an image dataset having an uneven distribution of classes is used for training a CNN classification model. In particular, diseases in plants occur aperiodically and unbalanced image data is provided. In this paper, we evaluate the impact of DCGAN(Deep Convolutional Generative Adversarial Network) image data augmentation to improve the performance of CNN-based tomato disease classifiers in situations where unbalanced image data is provided. DCGAN is a generation model specialized in image data, enabling stable learning and effectively extracting image features. For performance evaluation, the effect of DCGAN image data augmentation on a CNN-based tomato disease classifier was measured using a tomato disease image data set, and it was confirmed that the accuracy can be increased up to 30% through image data augmentation."
정확한 돼지 탐지를 위한 박스 레벨 후처리,2020,[],"합성곱 신경망(Convolutional Neural Network) 기반 객체 탐지기의 발전으로 돈사에서 돼지 모니터링이 가능하지만, 실제 농가에서 적용하기 위해서는 탐지기의 정확도를 개선해야 하는 문제가 여전히 남아있다. 본 연구에서는 합성곱 신경망 기반 돼지 탐지기의 출력인 박스들의 신뢰도 값을 평가하고 잘못된 박스들의 신뢰도 값을 보정하는 박스 레벨 후처리 방법을 제안한다. 즉, 신뢰도 값이 가짜 돼지인지 진짜 돼지인지 애매한 경우, 박스내 전경 픽셀 정보와 인접 박스의 정보를 이용하여 신뢰도 값을 낮추거나 높이는 보정 작업을 수행한다. 그리고 실제 돈사에서 취득한 11,308장의 영상 데이터로 실험한 결과, 제안 방법은 합성곱 신경망 기반 돼지 탐지기의 에러율을 4.4%에서 1.2%로 개선하는 효과가 있음을 확인하였다.",다국어 초록 정보 없음
딥러닝 알고리즘 기반의 차량번호 인식 프로그램 개발,2020,"['딥러닝', '합성곱 신경망', '앵커박스', '불법주정차', 'Deep Learning', 'Convolution Neural Network', 'Anchor Box', 'Illegal Parking']","최근 도심지 불법주정차 단속업무를 비롯하여 다양한 분야에서 CCTV 영상을 활용한 차량번호 인식에 관한 연구가 진행되고 있다. 본 연구에서는 합성곱 신경망 기반의 딥러닝 알고리즘을 활용하여 차량번호를 인식하는 프로그램을 개발하였다. 주요 연구 성과로서는 SSD 알고리즘을 활용하여 차량 및 번호판 영역을 검출하는 기술을 개발하였으며 학습데이터를 이용하여 훈련한 결과 약 99.5%의 높은 정확도를 확보할 수 있었다. 또한 기하학적 변형, 광학적 변형, 탄성학적 변형을 개선하는 데이터 확장 알고리즘을 개발하여 딥러닝 기반의 차량번호 인식에 활용되는 특징맵을 생성하였다. 그리고 앵커박스 및 딥러닝 기반의 합성곱 신경망 알고리즘을 적용한 결과 차량번호 인식 정확도가 98.5%로 매우 높게 나타남을 알 수 있었다. 본 연구에서는 실시간 차량 모니터링을 비롯하여 통계분석 그리고 차량번호를 실시간으로 인식할 수 있는 프로그램을 개발하였다. 개발한 프로그램을 활용하여 비트 레이트값의 변화에 따른 차량인식 정확도를 비교 평가하였으며, GS 인증을 위한 실험에서도 97% 이상의 높은 정확도를 확보할 수 있었다. 따라서 본 연구에서 개발한 차량번호 인식 프로그램은 불법주정차 단속업무를 비롯하여 체납차량 추적 등 다양한 분야에 활용될 수 있을 것으로 판단된다.","Recently, research has been conducted on the identification of vehicle numbers using CCTV images in various fields including illegal parking control in downtown areas. In this study, we developed a program that recognizes vehicle numbers using deep learning algorithms based on CNN. As a major research achievement, we developed a technology that detects the vehicle and license plate area using the SSD algorithm, and as a result of training using a learning date, a high accuracy of about 99.5% was secured. In addition, by developing a data expansion algorithm that improves geometric deformation, optical deformation, and elastic deformation, a feature map used for deep learning-based vehicle number recognition was generated. And as a result of applying CNN algorithm based on anchor box and deep learning, it was found that the vehicle number recognition accuracy was very high at 98.5%. In this study, we developed a program that can recognize real-time vehicle monitoring, statistical analysis, and vehicle number in real time. By using the developed program, vehicle recognition accuracy according to the change of the bit rate value was compared and evaluated, and in the experiment for GS certification, high accuracy of more than 97% was secured. Therefore, it is judged that the vehicle number recognition program developed in this study can be used in various fields such as illegal parking control and tracking overdue vehicles."
웨이퍼 맵 분석을 통한 불량 및 특이 웨이퍼 탐지,2020,"['웨이퍼 맵', '합성곱 신경망', '오토인코더', '이상치 탐지']","웨이퍼 맵(Wafer Bin Map, 이하 WBM)은 반도체 FAB 공정 수행 후 수행되는 다양한 전기적 테스트에 대한 결과를 시각화하여 보여주는 이미지로서 불량 웨이퍼 판별, 품질 이슈 관련 혐의 공정 파악 등의 다양한 품질 관리 활동에 사용되고 있다. 지금까지 WBM을 이용한 공정 관리는 숙련된 공정 엔지니어의 사전 지식에 크게 의존해서 수행되어 왔으며, 따라서 사전 지식이 다른 엔지니어들 사이에서는 같은 WBM이라도 해석과 개선의 방향이 다르게 설정되는 경우도 발생하였다. 본 연구에서는 딥러닝 기반의 합성곱 신경망 및 합성곱 신경망 오토인코더를 활용하여 과거 누적된 데이터 기반으로 개별 WBM에 대한 불량 탐지를 수행하고 불량 원인이 되는 영역을 규명해줄 수 있는 방법론을 제안하고 그 효과를 검증한다. 또한, 연속적으로 수행되는 반도체 공정에서 실시간으로 WBM을 모니터링하고 대부분의 WBM과는 다른 패턴을 보이는 이상치 WBM을 식별할 수 있는 방법론과 시각화 모듈을 구축하여 공정 관점에서의 특이사항을 신속하게 판별할 수 있는 시스템을 구축하였다.",다국어 초록 정보 없음
딥러닝 기반 얼굴 위변조 검출 기술 동향,2020,[],"최근 생체 정보를 이용한 사용자 인증 기술이 발전하면서 이를 모바일 기기에 적용하는 사례가 크게 증가하고 있다. 특히, 얼굴 기반 인증 방식은 비접촉식이며 사용이 편리하여 적용 범위가 점점 확대되고 있는 추세이다. 그러나, 사용자의 얼굴 사진이나 동영상 등을 이용한 위변조가 용이하기 때문에 모바일 기기 내 보안 유지에 어려움을 야기한다. 본 고에서는 이러한 문제를 해결하기 위해 최근 활발히 연구되고 있는 심층신경망 기반 얼굴 위변조 검출 연구의 최신 동향을 소개하고자 한다. 먼저, 기본 합성곱 신경망 구조부터 생성모델 기반의 위변조 검출 방법까지 다양한 신경망 구조를 이용한 위변조 검출 방법에 대해 설명한다. 또한, 심층신경망 학습을 위해 사용되는 얼굴 위변조 데이터셋에 대해서도 간략히 살펴보고자 한다.",다국어 초록 정보 없음
CNN기반의 학습모델을 활용한 거북목 증후군 자세 교정 시스템,2020,"['거북목증후군', '자세습관', '합성곱신경망', '스마트기기', '웹캠', '실시간', 'Turtle Neck Syndrome', 'Postural Habit', 'CNN', 'Smart Devices', 'Webcam', 'Real Time']","스마트 기기 사용의 증가와 함께 현대인들의 거북목 증후군 발병률이 증가했다. 거북목 증후군은 목의 앞 근육이 길어지고, 위쪽 근육이 짧아져 몸통에 비해 머리가 앞으로 나와 있는 자세이며, 수술이나 약물치료보다 평소의 자세 습관을 고치는 방법이 효과적이다. 따라서 본 논문에서는 실시간으로 거북목 증후군을 유발할 수 있는 자세를 감지하고 경고하는 시스템을 제안한다. 올바른 자세와 거북목 자세의 이미지 데이터들을 수집하여 합성곱 신경망기반의 학습모델을 만든다. 웹캠만을 이용하여 카메라에 들어오는 앉은 자세를 학습모델로 실시간 검증하고, 거북목 자세일 경우 경고음을 발생하여 바른 자세를 앉도록 유도한다. 이 시스템은 평소 자세 습관을 교정하도록 유도하여 거북목증후군을 치료하고 목 디스크와 같은 더 심각한 질병을 예방할 수 있다.","Along with the increased use of smart devices, the incidence of turtle neck syndrome among modern people has increased. Turtle neck syndrome is a posture in which the head is forward compared to the torso due to longer front muscles in the neck and shorter upper muscles, and it is more effective to fix the usual posture habits than surgery or medication. Thus, in this paper, a system is proposed to detect and warn posture that can cause turtle neck syndrome in real time. Image data of correct posture and turtle neck posture are collected to create a CNN-based learning model. Using only the webcam(Built-in camera), the sitting position that enters the camera is verified in real time through the learning model, and if it is a turtle neck position, it generates a warning sound and induces the correct posture. The system can induce people to correct their usual posture habits to treat turtle neck syndrome and prevent more serious diseases such as neck discs."
시각 정보를 활용한 딥러닝 기반 추천 시스템,2020,"['추천시스템', '딥러닝', '협업필터링', '시각정보', '합성곱신경망', 'Recommender Systems', 'Deep learning', 'Collaborative Filtering', 'Visual Information', 'Convolutional Neural Networks']","사용자의 정보 과부하 문제의 해결을 목표로 하는 추천 시스템은 개인의 선호를 추론하여 이에 부합하는 아이템을 필터링하여 제공한다. 추천 시스템 관련 기법 중 가장 성공적으로 알려져 있는 협업 필터링은 최근까지 다양한 성능 개선 시도가 이루어지고 있으며 여러 분야에 적용되고 있다. 본 연구에서는 이와 같은 협업 필터링의 성공에 기반하여 소비자의 구매 의사결정에 영향을 미칠 수 있는 시각 정보를 추천 시스템에 반영할 수 있는 VizNCS를 제안한다. 이를 위하여 먼저, 비정형 데이터인 시각 정보에서 특징을 추출하기 위해 합성곱 신경망을 사용하였다. 다음으로, 합성곱 신경망으로부터 도출된 이미지 특성 정보를 추천 시스템에 반영하기 위하여 기존의 딥러닝 기반의 추천 시스템 중 다른 정보로 확장이 용이한 NCF 기법을 응용하였다. 본 연구에서 제안한 VizNCS의 성능 비교 실험 결과 기본 NCF보다 더 높은 성능을 보였으며 카테고리별 성능 비교 실험을 통해 시각 정보에 영향을 받는 카테고리와 그렇지 않은 카테고리를 발견하였다. 결론적으로 본 연구에서 제안한 VizNCS는 시각정보를 개인화된 추천에 직접 활용함에 따라 시각 정보에 영향을 받는 소비자들의 구매의사결정 행태를 반영할 수 있어 추천 시스템 성능 향상에 기여하였다. 또한, 지금까지 활용이 미미했던 이미지 데이터로 추천 시스템의 원천 데이터 영역을 확장함에 따라 다양한 원천 데이터의 활용 방안을 제시하였다.",다국어 초록 정보 없음
CNN 및 모델 시각화 기법을 사용한 코팅 볼트 불량 판별,2020,"['풀림 방지 코팅 볼트', '합성곱 신경망', '클래스 활성화 맵', '그래드 캠', '관심 영역 지정', 'Anti-Loosening Coating Bolt', 'Convolutional Neural Networks', 'Class Activation Mapping', 'Gradient-Weighted Class Activation Mapping', 'Region of Interest']","자동차 부품은 대부분 볼트로 체결되며 풀림을 방지하기 위해 코팅 처리를 한다. 볼트 나사산에 코팅액 도포 시 용액의 점도 및 분사 속도로 불량 제품이 발생되어 비전 또는 수동으로 불량을 선별하나 시간 및 비용 문제로 자동화 공정이 필요하다. 이에 기존 연구는 서포트 벡터 머신(SVM)을 적용했으나, 데이터 크기에 따른 속도 저하 및 추가 학습 불가능으로 양산 적용이 어렵다. 문제점을 보완하고자 본 연구는 합성곱 신경망(CNN)으로 코팅 불량을 학습하고 향상된 볼트 불량 판별을 위해 시각화 기법을 사용한다. 코팅 불량 판별 알고리듬으로 사용된 CNN은 VGG-16이며, 97%의 정확도를 확보했다. 이는 시각화 기법을 적용해 풀림 방지 코팅 이외에 조명, 볼트 지그 등 주변 다른 요인의 영향 또한 포함함을 확인했다. 이를 개선하기 위해 이미지 전처리를 사용해 볼트 영역만을 표현했다. 재학습 모델은 97%의 정확도로 초기 모델과 비슷하지만, 코팅 불량만을 판단할 수 있다. 본 연구에서 적용한 CNN 시각화 기법을 통해 기존 알 수 없었던 불량의 판단 기준 및 위치를 정량적으로 정확히 판단할 수 있었다.","The loosening of bolts, as they are used in automotive, can be effectively prevented by an anti-loosening coating. Coating defects are often caused by inappropriate viscosity and dispensing speed of the coating solution. As bolts are mass produced, an automated defect detection process is crucial. Support vector machines, however, are unsuitable for mass production because of their slow detection speed and inability to learn. In this study a visualization technique is combined with a convolutional neural network (CNN) to learn the detection and categorization of coating defects. The CNN used is VGG-16, which provides a 97 % accuracy. Other influences, such as illumination and the color of the jig holding the bolt, are eliminated using image preprocessing to remove all areas except the bolt thread area. The relearning model is shown to have the same accuracy as the initial model (97 %), but bolt coating defects can now be detected. The proposed CNN visualization technique enables the quantitative and accurate determination of previously unknown defects and their locations."
인공지능 시대 예술의 패러다임 전환: 모더니즘 이후 매체 개념의 변화와 에이전트로서의 예술 매체 등장,2020,"['인공지능 예술(AI Art)', '신경망(Neural Network)', '머신러닝(Machine Learning)', '생성적 적대 신경망(GAN: Generative Adversarial Network)', '포스트미디엄(Post-medium)', '예술 매체(art medium)']","본 논문은 인공지능의 창작 논리와 예술 에이전트로서 개념적 해석을 시도하고 매체와 예술가의 관계에서 나타나는 패러다임 전환을 미술사적 견지에서 고찰한다. 예술 창작에 활용되고 있는 합성곱 신경망(CNN), 생성적 적대 신경망(GAN) 등 신경망 인공지능의 기본구조를 분석하고, 학습 데이터의 선택 과정이 미적 특성을 획득하기 위한 중요 과정임을 밝힌다. 더불어 이미지 생성 인공지능을 비디오 신시사이저와 비교해 봄으로써 인공지능의 창작 논리가 물리적 장치의 작동보다는 디지털 코드에 의한 언어적 지시에 있음을 알 수 있다. 이 점은 포스트미디엄 조건의 예술 매체의 패러다임인 기술적 지지체에서 인공 에이전트로의 전환을 의미한다. 로잘린드 크라우스의 확장된 매체의 도식에서 인공지능의 자리를 찾아보면서 그것을 매체 및 설치 개념과 연관시키고 미술 매체의 담론 안으로 끌어들이고자 했다. 크라우스의 아이디어는 인공지능 예술에 대한 해석과 평가에 대한 가능한 틀을 제공한다. 본 논문은 예술 수행의 관습과 관계하는 미술 매체에 대한 기억과 예술 작품에 새겨져서 상기되는 기억에 관한 것이 예술 매체로서 인공지능을 논의하는데 중요한 요소가 될 수 있음을 밝힌다.","This paper examines the role of artificial intelligence (AI) as an artistic agent through its creative logic, and looks into the AI-facilitated paradigm shift in the relation between medium and artist from the perspective of art history. It analyzes the basic structure of neural networks such as Convolutional Neural Network (CNN) and Generative Adversarial Network (GAN), which have often been used to generate creative images. It also notes that the training and evaluation of neural networks with proper sample datasets is a crucial step in selecting the aesthetic features that will compose the generated images. The comparison of deep neural networks with video synthesizers reveals that the creative logic of AI runs on digitally encoded linguistic instructions rather than functioning as a physical apparatus. This means that the paradigm of post-medium art, which has been supported by technological advances, would have to shift further to cover artificial agents. Through an attempt to locate AI in Rosalind Krauss’ diagram of the expanded medium, this paper shed light on the potential linkage of AI to the concepts of medium and installation, and brings AI into the realm of the discourse on art medium."
계량 측정을 위한 문자 인식 기술 구조,2020,"['계량 자동 측정', '광학 문자 인식', '합성곱 신경망', '합성곱 순환 신경망']",국문 초록 정보 없음,다국어 초록 정보 없음
KG_VCR: 지식 그래프를 이용하는 영상 기반 상식 추론 모델,2020,"['영상 기반 상식 추론', '심층 신경망', '그래프 합성곱 신경망', '지식 그래프 임베딩', 'Visual Commonsense Reasoning', 'Deep Neural Network', 'Graph Convolutional Network', 'Knowledge Graph Embedding']","기존의 영상 기반 질문-응답(VQA) 문제들과는 달리, 새로운 영상 기반 상식 추론(VCR) 문제들은 영상에 포함된 사물들 간의 관계 파악과 답변 근거 제시 등과 같이 추가적인 심층 상식 추론을 요구한다. 본 논문에서는 영상 기반 상식 추론 문제들을 위한 새로운 심층 신경망 모델인 KG_VCR을 제안한다. KG_VCR 모델은 입력 데이터(영상, 자연어 질문, 응답 리스트 등)에서 추출하는 사물들 간의 관계와 맥락 정보들을 이용할 뿐만 아니라, 외부 지식 베이스인 ConceptNet으로부터 구해내는 상식 임베딩을 함께 활용한다. 특히 제안 모델은 ConceptNet으로부터 검색해낸 연관 지식 그래프를 효과적으로 임베딩하기 위해 그래프 합성곱 신경망(GCN) 모듈을 채용한다. VCR 벤치마크 데이터 집합을 이용한 다양한 실험들을 통해, 본 논문에서는 제안 모델인 KG_VCR이 기존의 VQA 최고 모델과 R2C VCR 모델보다 더 높은 성능을 보인다는 것을 입증한다.",다국어 초록 정보 없음
진동수 영역의 분광학 스펙트럼 분석을 위한 심층 기계학습 모델 적용,2020,"['광전자 분광학', '기계 학습', '심층 신경망', 'Photoemission spectroscopy', 'Machine learning', 'Deep neural network']","최근 들어 학계 및 산업계에서는 데이터 사이언스를 이용한 물질 분석 및 신물질 디자인이 중요한 연구주제로 떠오르고 있으며, 이를 위한 필수 요소 중 하나는 실험적 분광학 결과 및 제일원리 전자구조계산결과에 대한 고속대량 데이터 스크리닝 작업이다. 이러한 작업에는 대량의 실험적 분광학 데이터와제일원리 전자구조계산 결과들로부터 유용한 정보들을 최소한의 인간의 개입만으로 추출할 수 있는기계학습 기반 방법론이 필수적이다. 이를 위하여, 본 연구에서는 1차원 진동수 영역에서의 광전자 분광학(photoemission spectroscopy, PES) 실험 결과들을 입력받아, 이로부터 전자의 여기 에너지, 여기 상태의수 및 각 PES 피크의 에너지 폭을 얻어 내는 심층 신경망 모델을 만들고 훈련시켜 보았다. 본 모델에서는1차원 합성곱 신경망(convolution neural network, CNN)을 완전연결 신경망(fully-connected layers, FCL)과 조합하여 사용하였으며, 훈련된 모델은 Poly(3-hexylthiophene) (P3HT) 분자 내 황의 2p 상태및 인듐 주석 산화물 내 산소의 1s 상태로부터의 PES 스펙트럼을 분석하는데 사용되었다. 마지막으로현재의 모델을 보다 개선하기 위한 방법에 대한 논의를 덧붙인다.","A data-driven study of material properties and functional materials design based on it requires high-throughput and comparative analyses of the results of experimental spectroscopy with those from first-principles electronic structure calculations. Hence, an efficient machine-learning-based computational tool to extract electronic structure information from experimental data without human intervention is in high demand. Here, we test the capability of deep neural network models to fit photoemission spectroscopy (PES) data in the frequency domain with unknown PES peak positions, numbers, and widths. A one-dimensional convolution neural network (CNN) was employed in combination with fully connected layers (FCL), and the trained model was applied to photoemission spectra for the sulfur 2p states in poly(3-hexylthiophene) (P3HT) molecules and oxygen 1s states in indium tin oxide (ITO). We conclude by further discussing potential ways to improve the performance of the model."
효과적인 신원확인을 위한 DCGANs 기반 치아 이미지 데이터 생성 모델 연구,2020,"['치아 이미지 생성', '심층학습', '심층 합성곱 생성적 적대 신경망', '신원 식별', 'Teeth Image Generation', 'Deep Learning', 'DCGANs', 'Identification']",오늘날 치아를 이용한 신원 확인은 예기치 못한 대형 사고와 사건들에서 효과적으로 사용되고 있다.그러나 기존의 방법은 전문가의 주관적인 기준으로 평가하여 전문가의 수준에 따라 상이한 결과가나올 수 있기에 객관성이 부족하다는 단점이 있다. 최근 심층학습 기술들의 발달로 이 기술들을 활용하여 이와 같은 문제를 해결하는 객관성 있는 자동 치아 분류 및 분석이 가능할 것이라는 기대가있다. 하지만 실제 치아 이미지의 경우 개인정보 문제로 인해 심층학습을 위한 충분한 양의 데이터를 획득하는데 어려운 문제에 직면해 있다. 본 논문에서는 심층 합성곱 생성적 적대 신경망을 이용하여 일부 확보된 소량의 실제 치아의 교합면 이미지를 이용하여 실제 치아 이미지와 유사한 다량의가상 치아 이미지를 효과적으로 생성하는 모델을 제안한다. 연구의 결과를 Fréchet Inception Distance(FID)를 이용하여 분석한 결과 생성되는 모든 이미지가 실제 치아와 유사하지는 않았기 때문에 그 성능은 비교적 낮았다. 그러나 생성된 이미지 중에는 실제 치아와 매우 유사한 이미지들이존재하는 것을 확인할 수 있었기에 이를 선별한다면 자동 치아 분류 및 분석을 위한 심층학습 기법들에 활용될 수 있을 것이다.,"Today, tooth identification is effectively used in large and unexpected accidents and incidents.However, this method has the disadvantage of lacking objectivity. Because it is evaluated based on the subjective criteria of experts, and different results may be produced depending on the ability of the experts. In recent years, with the development of deep learning technologies, there is an expectation that identification will be possible through objective automatic tooth classification and analysis that solves such problems using these technologies. However, there is a problem in that it is difficult to acquire a sufficient amount of data for deep learning because of the privacy of the real tooth image. In this paper, we propose a generation model of DCGANs (deep learning model deep convolutional generative adversarial networks)-based teeth image data for effective identification using a small amount of real tooth surface image. The performance of the study was analyzed using the Fréchet Inception Distance (FID), and the performance was relatively low because not all images were similar to the real teeth. However, among the generated images, there were images that were very similar to real teeth, so if they were selected, they could be used for deep learning techniques for automatic tooth classification and analysis."
교통 혼잡 원인과 영향을 분석하기 위한 시각적 분석 기술,2020,"['교통 혼잡 원인 분석', '시각적 분석', '교통 흐름 이론', '합성곱 신경망', 'traffic congestion causes', 'visual analytics', 'traffic flow theory', 'convolutional neural network']",본 논문에서는 교통 흐름 이론을 기반으로 교통 혼잡의 원인을 분석하는 기술을 제시한다. 우리는 GPS 궤적 및 차량 감지기 데이터(VD)와 같은 교통 데이터에서 차량의 흐름을 추출한다. 또한 우리는 교통 데이터에 정보이론의 엔트로피를 사용하여 차량의 흐름 변화를 식별한다. 그런 다음 혼잡 지역의 차량 흐름을 정량화할 수 있는 누적 차량 수 커브(N-curve)를 추출한다. 교통 흐름 이론에 따르면 혼잡 유형에 따라 고유한 N-curve 패턴을 관찰할 수 있다. 우리는 N-curve를 네 가지의 혼잡 패턴으로 분류할 수 있는 합성곱 신경망을 설계한다. 교통 혼잡의 원인과 영향을 분석하는 것은 어렵고 상당한 경험과 지식이 필요하다. 따라서 논문에서는 교통 혼잡의 원인과 영향을 분석하기 위한 일련의 프로세스를 효율적으로 수행할 수 있는 시각적 분석 시스템을 제시한다. 논문에서는 두 가지의 사례 연구를 통해 교통 혼잡의 원인을 분석할 수 있는 시스템을 평가한다.,"In this paper, we present a technique to analyze the causes of traffic congestion based on the traffic flow theory. We extracted vehicle flows from the traffic data, such as GPS trajectory and Vehicle Detector data. Also, vehicle flow changes were identified by utilizing the entropy from the information theory. Then, we extracted cumulative vehicle count curves (N-curve) that can quantify the vehicle flows in the congestion area. According to the traffic flow theory, unique N-curve patterns can be observed depending on the congestion type. We build a convolution neural network classifier that can classify N-curve into four different congestion patterns. Analyzing the cause and influence of congestion is difficult and requires considerable experience and knowledge. Apparently, we present a visual analytics system that can efficiently perform a series of processes to analyze the cause and influence of traffic congestion. Through case studies, we have evaluated our system that can analyze the cause of traffic congestion."
VGG16을 활용한 미학습 농작물의 효율적인 질병 진단 모델,2020,"['crop disease', 'convolutional neural network (CNN)', 'VGG16', '작물 질병', '합성곱신경망', 'VGG16']","농작물 질병에 대한 조기 진단은 질병의 확산을 억제하고 농업 생산성을 증대하는 데에 있어 중요한 역할을 하고 있다. 최근 합성곱신경망(convolutional neural network, CNN)과 같은 딥러닝 기법을 활용하여 농작물 잎사귀 이미지 데이터세트를 분석하여 농작물 질병을 진단하는 다수의 연구가 진행되었다. 이와 같은 연구를 통해 농작물 질병을 90% 이상의 정확도로 분류할 수 있지만, 사전 학습된 농작물 질병 외에는 진단할 수 없다는 한계를 갖는다. 본 연구에서는 미학습 농작물에 대해 효율적으로 질병 여부를 진단하는 모델을 제안한다. 이를 위해, 먼저 VGG16을 활용한 농작물 질병 분류기(CDC)를 구축하고 PlantVillage 데이터세트을 통해 학습하였다. 이어 미학습 농작물의 질병 진단이 가능하도록 수정된 질병 분류기(mCDC)의 구축방안을 제안하였다. 실험을 통해 본 연구에서 제안한 수정된 질병 분류기(mCDC)가 미학습 농작물의 질병 진단에 대해 기존 질병 분류기(CDC)보다 높은 성능을 보임을 확인하였다.","Early detection and classification of crop diseases play significant role to help farmers to reduce disease spread and to increase agricultural productivity. Recently, many researchers have used deep learning techniques like convolutional neural network (CNN) classifier for crop disease inspection with dataset of crop leaf images (e.g., PlantVillage dataset). These researches present over 90% of classification accuracy for crop diseases, but they have ability to detect only the pre-trained diseases. This paper proposes an efficient disease inspection CNN model for new crops not used in the pre-trained model. First, we present a benchmark crop disease classifier (CDC) for the crops in PlantVillage dataset using VGG16. Then we build a modified crop disease classifier (mCDC) to inspect diseases for untrained crops. The performance evaluation results show that the proposed model outperforms the benchmark classifier."
Bidirectional Convolutional LSTM을 이용한 Deepfake 탐지 방법,2020,"['Deepfake', 'LSTM', 'Attention module', 'Artificial intelligence', 'Time distribution']","최근 하드웨어의 성능과 인공지능 기술이 발달함에 따라 육안으로 구분하기 어려운 정교한 가짜 동영상들이 증가하고 있다. 인공지능을 이용한 얼굴 합성 기술을 딥페이크라고 하며 약간의 프로그래밍 능력과 딥러닝 지식만 있다면 누구든지 딥페이크를 이용하여 정교한 가짜 동영상을 제작할 수 있다. 이에 무분별한 가짜 동영상이 크게 증가하였으며 이는 개인 정보 침해, 가짜 뉴스, 사기 등에 문제로 이어질 수 있다. 따라서 사람의 눈으로도 진위를 가릴 수 없는 가짜 동영상을 탐지할 수 있는 방안이 필요하다. 이에 본 논문에서는 Bidirectional Convolutional LSTM과 어텐션 모듈(Attention module)을 적용한 딥페이크 탐지 모델을 제안한다. 본 논문에서 제안하는 모델은 어텐션 모듈과 신경곱 합성망 모델을 같이 사용되어 각 프레임의 특징을 추출하고 기존의 제안되어왔던 시간의 순방향만을 고려하는 LSTM과 달리 시간의 역방향도 고려하여 학습한다. 어텐션 모듈은 합성곱 신경망 모델과 같이 사용되어 각 프레임의 특징 추출에 이용한다. 실험을 통해 본 논문에서 제안하는 모델은 93.5%의 정확도를 갖고 기존 연구의 결과보다 AUC가 최대 50% 가량 높음을 보였다.","With the recent development of hardware performance and artificial intelligence technology, sophisticated fake videos that are difficult to distinguish with the human’s eye are increasing. Face synthesis technology using artificial intelligence is called Deepfake, and anyone with a little programming skill and deep learning knowledge can produce sophisticated fake videos using Deepfake. A number of indiscriminate fake videos has been increased significantly, which may lead to problems such as privacy violations, fake news and fraud. Therefore, it is necessary to detect fake video clips that cannot be discriminated by a human eyes. Thus, in this paper, we propose a deep-fake detection model applied with Bidirectional Convolution LSTM and Attention Module. Unlike LSTM, which considers only the forward sequential procedure, the model proposed in this paper uses the reverse order procedure. The Attention Module is used with a Convolutional neural network model to use the characteristics of each frame for extraction. Experiments have shown that the model proposed has 93.5% accuracy and AUC is up to 50% higher than the results of pre-existing studies."
기계학습 알고리즘 기반의 가스정압기 이상상태 진단에 대한 연구,2020,"['Fault Detection', 'Gas Pressure Regulator', 'Gradient Boosting', 'Long Short-Term Memory', '1D Convolutional Neural Networks', 'Over-Sampling', '이상 상태 진단', '정압기', '그레이디언트 부스팅', 'LSTM', '1차원 합성곱 신경망', '오버 샘플링']","본 논문에서는 정압기의 이상 상태 진단을 위한 기계학습 방법을 제안한다. 일반적으로 설비의 이상 상태 탐지를 위한 기계학습 모델 구현에는 관련 센서의 설치와 데이터 수집 과정이 동반되나, 정압기는 설비 특성상 안전문제에 매우 민감하여 추가적인 센서 설치가 매우 까다롭다. 이에 본 논문에서는 센서의 추가 설치 없이 정압기 설비에서 자체 수집되는 유량과 유압 데이터만을 가지고 정압기의 이상 상태를 조기에 판단하는 기계학습 모델을 제안한다. 본 논문에서는 정압기의 비정상데이터가 충분하지 않은 관계로, 모델 학습 시 오버 샘플링(Over-Sampling)을 적용하여 모델이 모든 클래스에 균형적으로 학습하도록 하였다. 또한, 그레이디언트 부스팅(Gradient Boosting), 1차원 합성곱 신경망(1D Convolutional Neural Networks), LSTM(Long Short-Term Memory)등의 기계학습 알고리즘을 적용하여 정압기의 이상 상태를 판단하는 분류모델을 구현하였고, 실험 결과 그레이디언트 부스팅 알고리즘이 정확도 99.975%로 가장 성능이 우수함을 확인하였다.","In this paper, we propose a machine learning method for diagnosing the failure of a gas pressure regulator. Originally, when implementing a machine learning model for detecting abnormal operation of a facility, it is common to install sensors to collect data. However, failure of a gas pressure regulator can lead to fatal safety problems, so that installing an additional sensor on a gas pressure regulator is not simple. In this paper, we propose various machine learning approach for diagnosing the abnormal operation of a gas pressure regulator with only the flow rate and gas pressure data collected from a gas pressure regulator itself. Since the fault data of a gas pressure regulator is not enough, the model is trained in all classes by applying the over-sampling method. The classification model was implemented using Gradient boosting, 1D Convolutional Neural Networks, and LSTM algorithm, and gradient boosting model showed the best performance among classification models with 99.975% accuracy."
딥러닝을 이용한 영화 흥행 예측과 주요 변수의 선택 연구 : 다변량 시계열 데이터 중심으로,2020,"['Box-office Prediction', 'Feature Selection', 'Multivariate Time Series Classification', 'Random Forest', 'Deep Learning', 'Multi-Layer Perceptron', 'Fully Convolutional Neural Networks', 'Residual Network', '박스 오피스 예측', '영화 흥행 예측', '주요 변수 선택', '다변량 시계열 데이터 분류', '랜덤 포레스트', '딥러닝', '다층 퍼셉트론', '완전 합성곱 신경망', '잔차 네트워크']","박스 오피스 예측은 영화 이해관계자들에게 중요하다. 따라서 정확한 박스 오피스 예측과 이에 영향을 미치는 주요 변수를 선별하는 것이 필요하다. 본 논문은 영화의 박스 오피스 예측 정확도 향상을위해 다변량 시계열 데이터 분류와 주요 변수 선택 방법을 제안한다. 연구 방법으로 한국 영화 일별데이터를 KOBIS와 NAVER에서 수집하였고, 랜덤 포레스트(Random Forest) 방법으로 주요 변수를 선별하였으며, 딥러닝(Deep Learning)으로 다변량 시계열을 예측하였다. 한국의 스크린 쿼터제(Screen Quota) 기준, 딥러닝을 이용하여 영화 개봉 73일째 흥행 예측 정확도를 주요 변수와 전체 변수로 비교하고통계적으로 유의한지 검정하였다. 딥러닝 모델은 다층 퍼셉트론(Multi-Layer Perceptron), 완전 합성곱신경망(Fully Convolutional Neural Networks), 잔차 네트워크(Residual Network)로 실험하였다. 결과적으로주요 변수를 잔차 네트워크에 사용했을 때 예측 정확도가 약 93%로 가장 높았다.","Box-office prediction is important to movie stakeholders. It is necessary to accurately predict box-office and select important variables. In this paper, we propose a multivariate time series classification and important variable selection method to improve accuracy of predicting the box-office. As a research method, we collected daily data from KOBIS and NAVER for South Korean movies, selected important variables using Random Forest and predicted multivariate time series using Deep Learning. Based on the Korean screen quota system, Deep Learning was used to compare the accuracy of box-office predictions on the 73rd day from movie release with the important variables and entire variables, and the results was tested whether they are statistically significant. As a Deep Learning model, Multi-Layer Perceptron, Fully Convolutional Neural Networks, and Residual Network were used. Among the Deep Learning models, the model using important variables and Residual Network had the highest prediction accuracy at 93%."
Assessment of Diagnostic Value for Femoral Neck Fracture Using Deep Neural Network Trained with Pelvic X-ray Films,2020,"['femoral neck fracture', 'deep learning', 'machine learning', 'convolutional neural network']","Introduction대퇴 경부 골절은 노인에서 흔한 골절로 X-ray를 통한 대퇴 경부 골절 진단의 민감도는 90 ~ 98%로 알려져 있다. 대퇴경부 골절의 진단이 늦어지게 되면 환자의 합병증 발생과 사망률은 수상 후 시간이 지남에 따라 증가한다. 대체 방법을 찾기 위해 우리 팀은 기계 학습을 통해 인공 지능에 의한 골절 감지를 평가하고자 하였다. 이 연구는 골반 X-ray 영상을 학습한 합성곱 신경망 (Convolutional neural network: CNN)을 사용하여 전위 및 비 전위성 골절을 포함한 대퇴 경부 골절을 판단 하고 내부 및 외부 검증을 통해 실제 임상 상황에서의 사용성이 있는 알고리즘을 개발하는 것을 목표로 했다. 또한 단일 병원에서 학습한 합성곱 신경망의 알고리즘을 다른 기관에 적용할 수 있는지 검증하고자 한다.Material & Method이 연구는 후향적 연구로써 CBAM++ (Convolutional Block Attention Module ++)을 삽입한 ResNet18 (Residual neural network 18)을 골반 및 고관절 X-ray 사진으로 학습시키고 이를 통해 X-ray 상의 대퇴 경부 골절을 판독을 수행하였다. 이 연구는 2020년 2월부터 2020년 5월까지 두 곳의 상급종합병원에서 수행되었으며 2005년 1월부터 2018년 12월까지의 데이터를 사용했다. 본 연구는 대퇴 경부 골절 X-ray를 학습한 심층신경망의 판독이 진단적 가치를 가질 수 있을 것이라는 가설 하 진행되었다. 이에 따른 결과를 AUC (area under the receiver operating characteristic curve), 정확도, Youden 지수, 민감도 및 특이도로 설명하였다.Result두 개의 병원에서 1,109개의 골절 이미지 (비 전위성 골절 332개 및 전위성 골절 777개) 와 3,080개의 비 골절 이미지로 총 4,189개의 이미지를 수집하였다. 단일 병원 데이터로 학습한 후 수행한 심층신경망의 내부 테스트 결과는 AUC 0.999, 정확 도 0.986, Youden 지수 0.960, 민감도 0.966 및 특이도 0.993으로 나타났다. 동일한 알고리즘을 통해 외부 병원 데이터를 사용한 외부 검증 결과는 각각 0.977, 0.971, 0.920, 0.939 및 0.982로 확인되었다. 두 개의 병원 자료를 병합하여 학습을 수행 한 후 시행한 테스트 결과는 각각 0.987, 0.983, 0.960, 0.973 및 0.987로 나타났다.Conclusion단일 병원에서 학습한 합성곱 신경망을 이용하여 다른 기관의 X-ray 상의 전위 골절뿐 아니라 비 전위 골절까지 선별할 수 있으며 골절 판독 정확도와 민감도는 유의미하게 높았다. 다른 병원 X-ray의 추가 학습 후에는 의료인의 정확도와 동등하거나 그 이상의 대퇴 경부 골절 판독의 정확성을 보였다.",다국어 초록 정보 없음
제스처 인식 기반의 인터랙티브 미디어 콘텐츠 제작 프레임워크 구현,2020,"['gesture recognition', 'interactive media', 'dynamic projection mapping', 'deep learning', 'convolutional neural network']","본 논문에서는 사용자의 제스처에 따라 반응하는 인터랙티브 미디어 콘텐츠를 프로그래밍 경험이 없는 사용자가 쉽게 제작할 수 있도록 하는 콘텐츠 제작 프레임워크를 제안한다. 제안 프레임워크에서 사용자는 사용하는 제스처와 이에 반응하는 미디어의 효과를 번호로 정의하고, 텍스트 기반의 구성 파일에서 이를 연결한다. 제안 프레임워크에서는 사용자의 제스처에 따라 반응하는 인터랙티브 미디어 콘텐츠를 사용자의 위치를 추적하여 프로젝션 시키기 위하여 동적 프로젝션 맵핑 모듈과 연결하였다. 또한, 제스처 인식을 위한 처리 속도와 메모리 부담을 줄이기 위하여 사용자의 움직임을 그레이 스케일(gray scale)의 모션 히스토리 이미지(Motion history image)로 표현하고, 이를 입력 데이터로 사용하는 제스처 인식을 위한 합성곱 신경망(Convolutional Neural Network) 모델을 설계하였다. 5가지 제스처를 인식하는 실험을 통하여 합성곱 신경망 모델의 계층수와 하이퍼파라미터를 결정하고 이를 제안 프레임워크에 적용하였다. 제스처 인식 실험에서 97.96%의 인식률과 12.04 FPS의 처리속도를 획득하였고, 3가지 파티클 효과와 연결한 실험에서 사용자의 움직임에 따라 의도하는 적절한 미디어 효과가 실시간으로 보임을 확인하였다.",다국어 초록 정보 없음
CNN 기반 철도차량 차체-대차 연결부의 결함 평가기법 연구,2020,"['Convolutional Neural Network', 'Railway Bogie', 'Damage', 'Weldment', 'Defect']","철도차량의 대차는 열차 주행을 위한 핵심적인 장치이다. 철도차량의 대차에서 피로결함은 운행 중 기대되지 않거나 과도한 하중, 용접결함, 재료 결함 등의 다양한 요인에 의해 발생할 수 있다. 철도차량의 사고를 방지하기 위해서 차체-대차연결부의 손상을 검출하고 발생 결함에 대한 정확한 평가가 요구된다. 이러한 철도차량의 차체-대차 연결부는 초음파 비파괴 검사를 통하여 건전성을 확보하고 있으나 결함 발생에 대한 학습기법을 이용한 판정방법이 필요하다.최근 미세한 결함이나 유사한 결함을 높은 인식율로 검출하기 위하여 딥러닝 기법에 관한 여러 연구가 진행되고 있다. 본 연구에서는 철도차량의 차체-대차 연결부의 결함 검출능력을 위하여 용접부의 인공결함 시편에 대하여 데이터베이스 구축하였으며. 웨지형 초음파 센서를 이용하여 차체-대차 연결부에 대한 비파괴 검사를 수행하였다. 부가적으로 인적 오류를 최소화하기 위하여 결함판단 학습기법인 합성곱 신경망기법(Convolutional Neural Network)을 적용하였다. 그 결과 합성곱 신경망기법 기법을 이용하여 철도차량의 차체-대차 연결 용접부의 균열을 99.98%이상 균열성 결함으로 판별할 수 있었으며 철도차량 차체-대차 연결부의 비파괴검사시 본 연구의 기술이 적용 가능함을 확인할 수 있었다.","The bogies of railway vehicles are one of the most critical components for service. Fatigue defects in the bogie can be initiated for various reasons, such as material imperfection, welding defects, and unpredictable and excessive overloads during operation. To prevent the derailment of a railway vehicle, it is necessary to evaluate and detect the defect of a connection weldment between the car body and bogie accurately. The safety of the bogie weldment was checked using an ultrasonic test, and it is necessary to determine the occurrence of defects using a learning method. Recently, studies on deep learning have been performed to identify defects with a high recognition rate with respect to a fine and similar defect. In this paper, the databases of weldment specimens with artificial defects were constructed to detect the defect of a bogie weldment. The ultrasonic inspection using the wedge angle was performed to understand the detection ability of fatigue cracks. In addition, the convolutional neural network was applied to minimize human error during the inspection. The results showed that the defects of connection weldment between the car body and bogie could be classified with more than 99.98% accuracy using CNN, and the effectiveness can be verified in the case of an inspection."
비디오 영상을 이용한 3차원 재구성 및 객체 인식 모델 개발,2020,"['합성곱 신경망', '3차원 재구성', '객체 인식 모델', '이미지 증강', 'SURF', 'CNN', '3D Reconstruction', 'Object Recognition Model', 'Image Augmentation']",국문 초록 정보 없음,"As the content industries developed, the scope of content used expanded from two to three dimensions, and not only experts but also ordinary users wanted to create and use this content. But handling three-dimensional information requires a lot of technology and time. Therefore, this study presents a simple three-dimensional reconstruction method using SfM. When users produce video images in a simple way, datasets are augmented and increased based on this, and then carry out three-dimensional reconstruction using the increased data. It also produces models that recognize three-dimensional objects through CNN learning. In other words, we produced two different results, one dataset and one information extraction process."
CNN 기반 몬테카를로 트리 탐색 및 강화학습을 이용한 인공지능 오델로 게임 에이전트,2020,"['합성곱 신경망', '몬테카를로 트리 탐색', '강화학습', '오델로 게임 에이전트', '가치 및 정책 네트워크', 'CNN', 'MCTS', 'Reinforcement Learning', 'Othello Game Agent', 'Valu eand Policy Function Network']",국문 초록 정보 없음,"In this paper, we propose an implementation of AI Othello game agent applying Monte Carlo tree search based on the neural network whose structure is expressed and learned by a single neural network. Neural network learning applied in this paper is carried out by using learning data generated through AI player's own playing, and learns CNN so that existing policy follows strong policy obtained through MCTS. To evaluate the performance of the proposed artificial intelligence Othello game agent, we compared the performances with the best existing Othello programs, Wzebra and Tothello, which use MPC search. We observed the performances according to the progress of learning through the playing with agents in the middle of the neural network learning progress"
강화학습과 몬테카를로 트리 탐색을 적용한 인공지능 인수분해 게임 에이전트에 관한 연구,2020,"['합성곱 신경망', '딥 러닝', '강화학습', '몬테카를로 트리 탐색', '인수분해 게임', 'Convolutional neural network', 'Deep learning', 'Reinforcement learning', 'Monte Carlo Tree Search', 'Factorization game']","본 논문에서는 수학적 개념인 인수분해를 이용하여 만든 수학 게임인 인수분해 게임을 소개 및 분석하였다. 또한, 인수분해 게임은 게임 보드 크기 n과 게임 값 p를 조절함으로써 게임의 상태 및 행동의 불확실성을 조절할 수 있다는 장점이 있다. 특히, 만일 n의 값이 커질 경우, 경우의 수가 기하급수적으로 증가함으로 인해 승리 전략이 불확실하다. 이를 강화학습 관점으로 보면 상태와 행동의 불확실성을 의미한다. 따라서 n을 6이하로 설정함으로써 불확실성을 조절한 인수분해 게임 에이전트를 만들었다. 본 논문에서는 강화학습 알고리즘인 Q-learning, Double DQN, 몬테카를로 트리 탐색을 인수분해 게임에 적용해보고, 승률 및 분석을 통하여 학습 진행됨을 보였다. 본 논문에서는 무작위 정책 에이전트와 강화학습을 적용한 인수분해 게임 에이전트와의 대결을 통해 학습 진행에 따른 승률 변화를 관찰하였다.","In this paper, we introduce and analyze the factorization game, which is a math game made using a mathematical concept, factorization. In addition, the factorization game have the advantage of controlling the uncertainty of the game state and action by adjusting the game board size n and game value p. In particular, if the value of n increases, the winning strategy is uncertain because the number of cases increases exponentially. Looking at this from the perspective of reinforcement learning, it means uncertainty in state and action. Accordingly, by setting the board size of n to 6 or less, a factorization game agent is created that adjusts the uncertainty. In this paper, we apply the reinforcement learning algorithms Q-learning, Double DQN, and Monte Carlo tree search to the factorization game, and show that learning progress through winning rate and analysis. In this paper, we observe the change in the winning rate according to the progress of learning through the competition between random policy agent and the factorization game agent applying reinforcement learning."
HMR method based on the deep CNN and sliding window label overlapping method,2020,"['심층 합성곱 신경망(Deep convolutional Neural Network)', '시계열데이터(Time series data)', '인체동작인식(Human motion recognition)', '착용형센서(Wearable sensor)', '슬라이딩 윈도우(Sliding window)']",국문 초록 정보 없음,다국어 초록 정보 없음
건물 에너지 분야의 인공지능 기반 연구 동향 분석 - 해외 저널 논문 중심으로 -,2020,"['건물에너지', '인공신경망', '합성곱 신경망', '순환 신경망', '장단기 메모리', 'Building Energy', 'Artificial Neural Network', 'Convolutional Neural Network', 'Recurrent Neural Network', 'Long-Short Term Memory']",국문 초록 정보 없음,"Purpose: Recently, there are many research projects conducted to achieve smart cities. Smart cities consist of smart buildings that include efficient energy supply and consumption systems. The Artificial Intelligence (AI) technologies became useful tools for this purpose due to their reliability of prediction accuracy and credibility. It is very important to better understand how the AI algorithms work and can be applied for specific areas of energy efficiency in buildings. This paper presents how AI technologies, such as Artificial Neural Network (ANN), Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), and Long Short-Term Memory (LSTM), are currently being utilized in the energy efficiency research in buildings. Method: International journal papers are reviewed especially for those utilizing ANN, CNN, RNN, and LSTM algorithms in building science and technologies. In-depth analyses are conducted comparing specific approaches, research outcomes, advantages, and disadvantages of key papers. Result: Findings show that the ANN, CNN, RNN, and LSTM algorithms are mainly used for the prediction of building energy loads and system energy uses. Compared to other AI algorithms, the LSTM algorithms have higher prediction accuracies due to the characteristics of LSTM structure."
트라우마 초기 진단을 위한 음성 기반 감정 분류 방법,2020,"['트라우마', '합성곱 신경망', '음성', '스펙트로그램', '감정', 'Trauma', 'Convolutional neural network', 'Audio', 'Spectrogram', 'Emotion']",국문 초록 정보 없음,다국어 초록 정보 없음
Evaluation of Classification and Accuracy in Chest X-ray Images using Deep Learning with Convolution Neural Network,2020,"['딥러닝', '합성곱 신경망 네트워크', '폐렴', '흉부 X-ray', 'Deep Learning', 'CNN', 'Pneumonia', 'Chest X-Ray']","본 연구에서는 CNN과 빅데이터 기술을 이용한 Deep Learning을 통해 흉부 X-ray 영상 분류 및 정확성 연구에 대하여 알아보고자 한다. 총 5,873장의 흉부 X-ray 영상에서 Normal 1,583장, Pneumonia 4,289장을 사용하였다. 데이터 분류는 train(88.8%), validation(0.2%), test(11%)로 분류하였다. Convolution Layer, Max pooling layer pool size 2×2, Flatten layer, Image Data Generator로 구성하였다. Convolution layer가 3일 때와 4일 때 각각 filter 수, filter size, drop out, epoch, batch size, 손실함수 값을 설정하였다. test 데이터로 Convolution layer가 4일 때, filter 수 64-128-128-128, filter size 3×3, drop out 0.25, epoch 5, batch size 15, 손실함수 RMSprop 으로 설정 시 정확도가 94.67%였다. 본 연구를 통해 높은 정확성으로 분류가 가능하였으며, 흉부 X-ray 영상뿐만 아니라 다른 의료영상에서도 많은 도움이 될 것으로 사료된다.","The purpose of this study was learning about chest X-ray image classification and accuracy research through Deep Learning using big data technology with Convolution Neural Network. Normal 1,583 and Pneumonia 4,289 were used in chest X-ray images. The data were classified as train (88.8%), validation (0.2%) and test (11%). Constructed as Convolution Layer, Max pooling layer size 2×2, Flatten layer, and Image Data Generator. The number of filters, filter size, drop out, epoch, batch size, and loss function values were set when the Convolution layer were 3 and 4 respectively. The test data verification results showed that the predicted accuracy was 94.67% when the number of filters was 64-128-128-128, filter size 3×3, drop out 0.25, epoch 5, batch size 15, and loss function RMSprop was 4. In this study, the classification of chest X-ray Normal and Pneumonia was predictable with high accuracy, and it is believed to be of great help not only to chest X-ray images but also to other medical images."
A Study on the Prediction of 2-Dimensional Airfoil Shape using CNN,2020,"['전산유체역학(CFD)', '합성곱 신경망(CNN)', '익형(Airfoil)']",국문 초록 정보 없음,다국어 초록 정보 없음
랜덤 포레스트와 딥러닝을 이용한 노인환자의 사망률 예측,2020,"['사망률 예측', '합성곱 신경망', '랜덤 포레스트', '자질 선택', '딥러닝', 'Mortality Prediction', 'Convolutional Neural Network', 'Random Forest', 'Feature Selection', 'Deep Learning']",국문 초록 정보 없음,"We predict the mortality of the elderly patients visiting the emergency department who are over 65 years old using Feed Forward Neural Network (FFNN) and Convolutional Neural Network (CNN) respectively. Medical data consist of 99 features including basic information such as sex, age, temperature, and heart rate as well as past history, various blood tests and culture tests, and etc. Among these, we used random forest to select features by measuring the importance of features in the prediction of mortality. As a result, using the top 80 features with high importance is best in the mortality prediction. The performance of the FFNN and CNN is compared by using the selected features for training each neural network. To train CNN with images, we convert medical data to fixed size images. We acquire better results with CNN than with FFNN. With CNN for mortality prediction, F1 score and the AUC for test data are 56.9 and 92.1 respectively."
사례 이미지에 기반한 설계안의 자동 시각화 기법,2020,"['사례 이미지', '합성곱 신경망', '마감재', '인테리어 설계', 'Case image', 'Convolutional neural network', 'Finishing material', 'Interior design']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝을 이용한 항공기 소음 판별 모델링,2020,"['항공기 소음', '합성곱신경망']",국문 초록 정보 없음,다국어 초록 정보 없음
복수의 엣지 디바이스에서의 CNN 모델 분산 처리를 위한 축소된 분류 모델 활용 기법,2020,"['기계 학습', '딥러닝', '합성곱 신경망', '엣지 컴퓨팅', '분산 컴퓨팅', 'machine learning', 'deep learning', 'convolutional neural networks', 'edge computing', 'distributed computing']","최근 클라우드 서버로 전송되는 막대한 양의 데이터로 인해 발생하는 네트워크 부하 등의 여러 문제로 인하여, 데이터의 수집이 이루어지는 네트워크의 말단에서 자체적으로 데이터를 처리하는 엣지 컴퓨팅에 대한 요구가 증가하고 있다. 그러나 네트워크 말단에 위치한 엣지 디바이스는 대부분 성능이 제한되어 있어 클라우드 서버에서 사용되는 딥러닝 응용을 그대로 사용하기에는 어려움이 있다. 이러한 문제를 극복하기 위해, 본 논문에서는 딥러닝 모델을 축소된 분류 모델들로 나누어 활용해 복수의 엣지 디바이스에서 공동으로 추론을 수행하는 분산 처리 기법을 제안하였다. 여기서 사용된 축소된 분류 모델은 경량화 된 모델 가중치를 가지며, 전체 분류 레이블 중 일부에 해당하는 레이블에 대해 추론을 진행한다. 성능 측정 결과 제안하는 축소된 분류 모델의 결과를 취합하는 분산 처리 기법의 정확도가 기존 모델 대비 더 적은 파라미터를 갖도록 경량화를 하여도 기존 모델과 유사한 수준을 유지할 수 있음을 확인하였다.","Recently, there have been increasing demands for edge computing that processes data at the end of the network wherein data is collected because of various problems such as network load caused by a large amount of data transfer to a cloud server. However, it is difficult for edge devices to use deep learning applications used in cloud servers because most edge devices at the end of the network have limited performance. To overcome these problems, this paper proposes a distributed processing method that uses reduced classification models to jointly perform inferences on multiple edge devices. The reduced classification models have compressed model weights, and perform inferences for some parts of the total classification labels. The experimental results confirmed that the accuracy of the result of the proposed distributed processing method is similar to the accuracy of the result of the original model, even if the proposed reduced classification models had much less parameters than those of the original model."
CNN 모델을 이용한 보행자 인식 및 신장 추정 방법,2020,"['단안카메라', '보행자', '딥러닝', '합성곱신경망 모델', '렌즈왜곡보상', 'Monocular Camera', 'Pedestrian', 'Deep Learning', 'CNN Model', 'LDC']",국문 초록 정보 없음,"In this paper, the convolutional neural network (CNN) model, which is an object-recognition technology based on deep learning, was applied to images acquired from a monocular camera to detect pedestrians. The detected image coordinates of the pedestrians were converted to map coordinates, and the height of the pedestrians was inferred using a proportional equation. For this, a monocular camera equipped with lens distortion compensation was installed at an altitude of 3.5 m, and the pitch and yaw angles were set to collimate pedestrians. That is how we proceed image capturing. In the CNN model, the image coordinates of the object were acquired in real-time using the bounding box. After converting the image coordinates of the acquired object to map coordinates, the height of pedestrians could be calculated using a proportional equation."
딥 러닝 기법을 활용한 이미지 내 한글 텍스트 인식에 관한 연구,2020,"['문자인식', '한글인식', '이미지분석', '딥러닝', '합성곱신경망', 'Character recognition', 'Korean Recognition', 'Image analysis', 'Deep learning', 'Convolution neural network']","본 연구에서는 컴퓨터 비전의 분야 중 하나인 문자 인식에 관한 연구를 수행했다. 대표적인 문자인식 기법 중 하나인 광학식 문자 판독 기법의 경우 일정한 규격과 서식에서 벗어나게 되면 인식률이 떨어진다는 한계점이 있다. 따라서 본 연구에서는 딥 러닝 기법을 적용해 이러한 문제점을 해결하고자 한다. 또한 기존의 문자 인식 연구의 경우 대부분 영어 및 숫자 인식에 국한되어 있다. 따라서 본 연구는 한글 인식을 위한 딥 러닝 기반 문자 인식 알고리즘을 제시한다. 알고리즘은 1-NED 평가 방법에서 0.841의 점수를 얻었으며, 이는 영어 인식 결과와 비슷한 수치이다. 본 연구를 통해 딥 러닝 기반 한글 인식 알고리즘의 성능을 확인할 수 있으며, 이를 통해 향후 연구방향에 대해 제시한다.",다국어 초록 정보 없음
인공지능 이용 타이어 소음 예측 기술 개발,2020,"['Convolutional Neural Network (합성곱 신경망)', 'Discrete wavelet transform(이산 웨이브렛 변환)', 'Tyre pattern noise (타이어 패턴소음)']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN 모델 평가를 위한 이미지 데이터 증강 도구 개발,2020,"['메타몰픽 테스팅', '데이터 어그멘테이션', '합성곱 신경망', '이미지 합성', 'Metamorphic Testing', 'Data Augmentation', 'CNN', 'Image Composition']","CNN 모델이 이미지 분류와 객체 탐지 등 여러 분야에 활용됨에 따라, 자율주행자동차와 같이 안전필수시스템에 사용되는 CNN 모델의 성능은 신뢰할 수 있어야 한다. 이에 CNN 모델이 다양한 환경에서도 성능을 유지하는지 평가하기 위해 배경을 변경한 이미지를 생성하는 이미지 데이터 증강 도구를 개발한다. 이미지 데이터 증강 도구에 객체가 존재하는 이미지를 입력하면, 해당 이미지로부터 객체 이미지를 추출한 후 수집한 배경 이미지 내에 객체 이미지를 합성하여 새로운 이미지를 생성한다. CNN 모델 성능 평가 방법으로 개발한 도구를 사용하여 기존 테스트 이미지로부터 새로운 테스트 이미지를 생성하고, 생성한 새로운 테스트 이미지로 CNN 모델을 평가한다. 사례 연구로 Pascal VOC2007 테스트 데이터로부터 새로운 테스트 이미지를 생성하고, 새로운 테스트 이미지로 YOLOv3 모델을 평가하였다. 그 결과 기존 테스트 이미지의 mAP보다 새로운 테스트 이미지의 mAP가 약 0.11 더 낮아지는 것을 확인하였다.","As CNN model is applied to various domains such as image classification and object detection, the performance of CNN model which is used to safety critical system like autonomous vehicles should be reliable. To evaluate that CNN model can sustain the performance in various environments, we developed an image data augmentation apparatus which generates images that is changed background. If an image which contains object is entered into the apparatus, it extracts an object image from the entered image and generate s composed images by synthesizing the object image with collected background images. As a method to evaluate a CNN model, the apparatus generate s new test images from original test images, and we evaluate the CNN model by the new test image. As a case study, we genera ted new test images from Pascal VOC2007 and evaluated a YOLOv3 model with the new images. As a result, it was detected that mAP of new test images is almost 0.11 lower than mAP of the original test images."
Automatic Sagittal Plane Detection for the Identification of the Mandibular Canal,2020,"['자동 평면 검출', '합성곱 신경망', '변환 최적화', '치아 임플란트 계획.', 'Automatic plane detection', 'Convolutional Neural Network', 'Transformation optimization', 'Dental implant planning.']",국문 초록 정보 없음,"Identification of the mandibular canal path in Computed Tomography (CT) scans is important in dental implantology. Typically, prior to the implant planning, dentists find a sagittal plane where the mandibular canal path is maximally observed, to manually identify the mandibular canal. However, this is time-consuming and requires extensive experience. In this paper, we propose a deep-learning-based framework to detect the desired sagittal plane automatically. This is accomplished by utilizing two main techniques: 1) a modified version of the iterative transformation network (ITN) method for obtaining initial planes, and 2) a fine searching method based on a convolutional neural network (CNN) classifier for detecting the desirable sagittal plane. This combination of techniques facilitates accurate plane detection, which is a limitation of the stand-alone ITN method. We have tested on a number of CT datasets to demonstrate that the proposed method can achieve more satisfactory results compared to the ITN method. This allows dentists to identify the mandibular canal path efficiently, providing a foundation for future research into more efficient, automatic mandibular canal detection methods."
인공지능 기반의 방출단층영상 분류 기법을 이용한 핵연료집합체 검증기술 개발,2020,"['몬테칼로 전산모사', '핵연료집합체', '딥러닝', '합성곱 신경망', '영상 분류']",국문 초록 정보 없음,다국어 초록 정보 없음
Residual Multi-Dilated Recurrent Convolutional U-Net을 이용한 전자동 심장 분할 모델 분석,2020,"['딥러닝', '인공지능', '심장분할', '알고리즘', '인공신경망', '합성곱신경망', 'Deep Learning', 'Artificial Intelligence', 'Heart Segmentation', 'Algorithm', 'ANN', 'CNN']","본 논문에서는 딥 러닝 기반의 전-자동 심장 분할 알고리즘을 제안한다. 본 논문에서 제안하는 딥 러닝 모델은 기존 U-Net에 residual recurrent convolutional block과 residual multi-dilated convolutional block을 삽입하여 성능을 개선한 모델이다. 모델의 성능은 테스트 데이터 세트를 전-자동 분할한 결과와 영상의학 전문가의 수동 분할 결과를 비교하여 분석하였다. CT 영상에서 평균 96.88%의 DSC, 95.60%의 precision과 97.00%의 recall 결과를 얻었다. 분할된 영상은 3차원 볼륨 렌더링 기법을 적용하여 시각화한 후 관찰하여 분석할 수 있었다. 실험 결과를 통해 제안된 알고리즘이 다양한 심장 하부 구조를 분할하기에 효과적인 것을 알 수 있었다. 본 논문에서 제안하는 알고리즘이 전문의 또는 방사선사의 임상적 보조역할을 수행할 수 있을 것으로 기대한다.","In this paper, we proposed that a fully automatic multi-class whole heart segmentation algorithm using deep learning. The proposed method is based on U-Net architecture which consist of recurrent convolutional block, residual multi-dilated convolutional block. The evaluation was accomplished by comparing automated analysis results of the test dataset to the manual assessment. We obtained the average DSC of 96.88%, precision of 95.60%, and recall of 97.00% with CT images. We were able to observe and analyze after visualizing segmented images using three-dimensional volume rendering method. Our experiment results show that proposed method effectively performed to segment in various heart structures. We expected that our method can help doctors and radiologist to make image reading and clinical decision."
장수말벌 이미지 퓨전 전처리를 통한 딥러닝 영상인식,2020,"['장수말벌', '이미지 퓨전', '심층 합성곱 신경망', 'Vespa mandarinia', 'Image Fusion', 'AlexNet', 'DCNN(Deep Convolutional Neural Networks)']",국문 초록 정보 없음,"The image fusion process is defined as gathering all the important information from multiple images to a single image. This single image is more informative and accurate than any single source image, and it consists of all the necessary information. It is important to acquire a high quality image for tracking and recognizing object. So, it is required to create a refined image by synthesizing or compensating the acquired image through image fusion. In this paper, we would like to present a fusion and recognition application method of the acquired image in order to increase the recognition rate of Vespa mandarinia. Generating a random area blurred source image in a Vespa mandarinia image, and synthesized through the PCA(principal component analysis) based image fusion, and measures the image fusion performance through RMSE, PFE, MAE, CORR, SNR, PSNR. In addition, using the AlexNet based on the DCNN(Deep Convolutional Neural Networks), it presents the recognition score and classification accuracy for the fused image."
실내 음환경 변화에 따른 폐렴 진단 알고리즘,2020,"['Pneumonia(폐렴)', 'Mel-specctrogram(멜-스펙트로그램)', 'CNN(합성곱 신경망)', 'Impulse response(임펄스응답)']",국문 초록 정보 없음,다국어 초록 정보 없음
드론 영상 기반 딥러닝 알고리즘을 이용한 불법 주정차 번호 인식 기술,2020,"['딥러닝 알고리즘', '불법 주정차', '드론 영상', '합성곱 신경망', 'Deep Learning Algorithm', 'Illegal Parking and Stopping', 'Drone Image', 'Convolution Neural Network']","최근 도시개발에 따른 불법 주정차 문제는 화재나 응급환자 발생시 교통 흐름을 방해하여 막대한 인명 및 재산피해를 가져오고 있다. 본 연구에서는 이러한 문제를 개선하기 위해 드론 영상 기반의 딥러닝 알고리즘을 이용하여 불법 주정차 번호를 인식하는 연구를 수행하였다. 먼저 50,232개의 차량 번호 학습자료를 구축하였으며 Single Shot Multi-Detector 알고리즘을 이용하여 차량 및 번호판 영역을 식별하였다. 또한 데이터 확장 알고리즘을 이용하여 경사지거나 비틀어진 번호판을 정형화시켰으며, 최종적으로 앵커박스 생성 및 딥러닝 기반의 차량번호 인식기술을 개발하였다. 본 연구에서는 불법 주정차 단속 업무를 효과적으로 지원하기 위해 Visual Studio 2017 환경에서 C++와 C# 언어를 이용하여 차량번호를 자동으로 인식할 수 있는 프로그램도 개발하였으며, 자체 테스트한 차량번호 인식 정확도는 99.4%로 매우 높게 나타났다. 불법 주정차 번호 인식을 위해 전주시 6개 노선을 선정하였으며 드론을 통해 해상도별 영상자료를 구축하였다. 딥러닝 알고리즘을 이용하여 차량 인식 정확도를 평가한 결과 불법 주정차된 64대의 차량 중 62대를 인식하여 96.9%의 높은 인식률을 확보할 수 있었다. 다만 전체 훈련자료 중 약 1.6%로 상대적으로 훈련자료가 부족한 세자리 숫자 번호판이 위치한 노선에서는 차량을 인식하지 못하는 한계를 보였으며, 향후 연구에서는 많은 학습자료 구축을 통해 정확도를 향상시킬 계획이다.","Recently, the problem of illegal parking and stopping caused by urban development has caused enormous human and property damage by obstructing the traffic flow in case of fire or emergency patients. In this study, in order to improve this problem, a study was conducted to recognize illegal parking car numbers using a deep learning algorithm based on drone images. First, 50,232 vehicle numbers of various types were constructed as learning data, and the vehicle and license plate areas were identified using the Single Shot Multi-Detector algorithm. In addition, we developed a data expansion algorithm that formalizes inclined or twisted license plates for optimal anchor box and deep learning algorithm application. And finally, an anchor box creation and deep learning-based vehicle number recognition technology were developed. In this study, a program that can automatically recognize vehicle numbers using C++ and C# languages in the Visual Studio 2017 environment was also developed to effectively support illegal parking and stopping enforcement work. In addition, the self-tested vehicle number recognition accuracy was very high at 99.4%. For the recognition of illegal parking and stop car numbers, six routes in Jeonju were selected as a representative. And image data by resolution were constructed through drone photography. As a result of analysis through a deep learning algorithm, 62 out of 64 illegally parked and stopped vehicles were recognized, ensuring a high accuracy of 96.9%. However, about 1.6% of the total training data showed a limitation in not being able to recognize vehicles on the route where the three-digit license plate was relatively insufficient. And in future studies, it is necessary to improve the accuracy by securing many learning materials."
The Cut Transition Detection Model Using the SSD Method,2020,"['샷 경계 검출', 'Cut transition', '3D 합성곱 신경망', 'Single Shot MultiBox Detector', 'shot boundary detection', '3D convolutional neural network']",국문 초록 정보 없음,다국어 초록 정보 없음
Convolutional Neural Network를 이용한 주차 차량 자세 추정,2020,"['Autonomous parking(자동 주차)', 'Convolutional Neural Network(합성곱 신경망)', 'Vehicle pose estimation(자세 추정)', 'Deep learning(딥러닝)', 'Image processing(영상 처리)']",국문 초록 정보 없음,"This paper proposes a technique based on Convolutional Neural Network(CNN) using rear view camera images to estimate the vehicle pose for the target point when parking. Identifying the vehicle’s pose for the target point in autonomous vehicles is a key technology in the automatic parking system. Generally, existing algorithm is used to recognize parking spaces with rear view camera images or rear view camera images and ultrasonic sensors to identify the vehicle’s poses for the target point. In this paper, we present feasibility of the network learned by CNN as AVM images to find out the pose of the vehicle simply. We show the performance that was observed when confirming the root mean squared error of the actual values and the predicted values."
주차장 Open Street Map을 활용한 CNN 기반 점유 Slot 판단 시스템,2020,"['Deep Learning(딥러닝)', 'Convolutional Neural Network(합성곱 신경망)', 'Parking Slot Occupancy Classification(주차장 점유 슬롯 판단)', 'Opens Street Map(오픈 스트리트 맵)']",국문 초록 정보 없음,다국어 초록 정보 없음
사용자 상호작용 기반의 시선 검출을 위한 비강압식 캘리브레이션,2020,"['시선 검출', '비강압식 캘리브레이션', '사용자 상호작용', '합성곱 신경망', 'gaze estimation', 'non-intrusive calibration', 'user interaction', 'convolutional neural network']","본 논문에서는 웹 페이지 탐색 시 지속해서 발생하는 사용자 상호작용 과정을 이용하여 시선 검출을 위한 캘리브레이션 데이터를 획득하고, 사용자의 시선을 검출하는 동안 자연스럽게 캘리브레이션을 수행하는 방법에 관하여 기술하였다. 제안된 비강압식 캘리브레이션은 획득한 캘리브레이션 데이터를 이용하여 미리 학습된 시선 검출 CNN 모델을 새로운 사용자에 적응하도록 보정하는 과정이다. 이를 위해 훈련을 통해서 시선을 검출하는 일반화된 모델을 만들고 캘리브레이션에서는 온라인 학습 과정을 통해 빠르게 새로운 사용자에 적응하도록 하였다. 실험을 통하여 다양한 사용자 상호작용의 조합으로 시선 검출 모델을 캘리브레이션 하여 성능을 비교하였으며, 기존 방법 대비 개선된 정확도를 얻을 수 있었다.",다국어 초록 정보 없음
경로점 생성을 위한 딥러닝 기반 3차원 포인트 클라우드에서의 빈 공간 검출 알고리즘,2020,"['Deep Learning(심층 학습)', 'Convolutional Neural Network(합성곱 신경망)', '3D Point Cloud(3차원 점 구름)', 'Empty Space(빈 공간)', 'Object Detection(객체 검출)']",국문 초록 정보 없음,다국어 초록 정보 없음
관심 문자열 인식 기술을 이용한 가스계량기 자동 검침 시스템,2020,"['가스계량기', '자동 검침', '선택적 문자 인식', '합성곱 신경망', '순환 신경망', '고속 병렬처리', 'Gasometer', 'automatic reading', 'selective optical character recognition', 'convolutional neural network', 'recurrent neural network', 'parallel processing']",국문 초록 정보 없음,"In this paper, we suggest an application system architecture which provides accurate, fast and efficient automatic gasometer reading function. The system captures gasometer image using mobile device camera, transmits the image to a cloud server on top of private LTE network, and analyzes the image to extract character information of device ID and gas usage amount by selective optical character recognition based on deep learning technology. In general, there are many types of character in an image and optical character recognition technology extracts all character information in an image. But some applications need to ignore non-of-interest types of character and only have to focus on some specific types of characters. For an example of the application, automatic gasometer reading system only need to extract device ID and gas usage amount character information from gasometer images to send bill to users. Non-of-interest character strings, such as device type, manufacturer, manufacturing date, specification and etc., are not valuable information to the application. Thus, the application have to analyze point of interest region and specific types of characters to extract valuable information only. We adopted CNN (Convolutional Neural Network) based object detection and CRNN (Convolutional Recurrent Neural Network) technology for selective optical character recognition which only analyze point of interest region for selective character information extraction. We build up 3 neural networks for the application system. The first is a convolutional neural network which detects point of interest region of gas usage amount and device ID information character strings, the second is another convolutional neural network which transforms spatial information of point of interest region to spatial sequential feature vectors, and the third is bi-directional long short term memory network which converts spatial sequential information to character strings using time-series analysis mapping from feature vectors to character strings. In this research, point of interest character strings are device ID and gas usage amount. Device ID consists of 12 arabic character strings and gas usage amount consists of 4 ~ 5 arabic character strings. All system components are implemented in Amazon Web Service Cloud with Intel Zeon E5-2686 v4 CPU and NVidia TESLA V100 GPU. The system architecture adopts master-lave processing structure for efficient and fast parallel processing coping with about 700,000 requests per day. Mobile device captures gasometer image and transmits to master process in AWS cloud. Master process runs on Intel Zeon CPU and pushes reading request from mobile device to an input queue with FIFO (First In First Out) structure. Slave process consists of 3 types of deep neural networks which conduct character recognition process and runs on NVidia GPU module. Slave process is always polling the input queue to get recognition request. If there are some requests from master process in the input queue, slave process converts the image in the input queue to device ID character string, gas usage amount character string and position information of the strings, returns the information to output queue, and switch to idle mode to poll the input queue. Master process gets final information form the output queue and delivers the information to the mobile device. We used total 27,120 gasometer images for training, validation and testing of 3 types of deep neural network. 22,985 images were used for training and validation, 4,135 images were used for testing. We randomly splitted 22,985 images with 8:2 ratio for training and validation respectively for each training epoch. 4,135 test image were categorized into 5 types (Normal, noise, reflex, scale and slant). Normal data is clean image data, noise means image with noise signal, relfex means image with light reflection in gasometer region, scale means images with small object size due to long-distance capturin"
CNN 및 등속도 모델 상대항법 기반 착륙 패드 탐지 및 자동착륙 연구,2020,"['Autonomous Landing(자동착륙)', 'Convolutional Neural Network(합성곱 신경망)', 'Pixhawk', 'ROS']",국문 초록 정보 없음,다국어 초록 정보 없음
불법 산양삼 검출을 위한 인공지능 기술에서의 산양삼과 인삼 이미지의 분류 기저화 연구,2020,"['산양삼', '인공지능', '기계학습', '이미지 분석', '합성곱 신경망', 'Mountain Ginseng', 'Artificial Intelligence', 'Machine Learning', 'Image Detection', 'CNN(Convolutional Neural Network)']","본 연구는 인삼과 산양삼에 대해 아무런 정보가 없는 초보 소비자가 인삼을 산양삼이라 여기는 사기 상황을 방지하는 차원에서 산양삼 형태에 대한 기저수준을 확립하려했다. 이를 위해 연구자들은 소비자가 스마트폰의 전용 APP으로 인삼을 촬영하면 그 사진이 원격으로 전송되어, 기계학습데이터를 기반으로 판별한 결과가 소비자에게 전송되는 서비스디자인을 고안했다. 연구과정에서의 데이터 셋과 소비자들이 스마트폰을 통해 촬영했을 때의 배경색, 산양삼의 위치, 크기, 조도, 색온도 등과의 차이를 최소화 하기 위해 소비자 용전용 촬영 박스를 디자인 했다. 이에 따라 산양삼 샘플 수집은 디자인된 박스와 동일한 통제된 환경과 세팅 하에서 이루어졌다. 이를 통해 기계학습에서 통상 필요한 것 보다 약 1/10이 적은 샘플을 사용해CNN(VGG16)모델에서 예측 확율 100%를 얻었다.",다국어 초록 정보 없음
SSD 알고리즘을 이용한 지능형 산불재난 인식 기술 개발,2020,"['R-CNN', 'SSD', 'YOLO', '산불', '합성곱 신경망']",국문 초록 정보 없음,다국어 초록 정보 없음
Convolutional neural network를 이용한 기류 토출 조건에 따른 실내 기류 온도 분포 예측,2020,"['전산유체역학(Computational Fluid Dynamics)', '에어컨(Air conditioner)', '합성곱 신경망(Convolutional Neural Network)']",국문 초록 정보 없음,"This study predicted the indoor airflow temperature distribution with discharge air-flow conditions using Convolutional Neural Network. The discharge temperature, velocity and angle were considered as main simulation parameters. Three values of discharge temperatures were considered in the range of 10℃≤T≤15℃ and five values were considered in the range of 1m/s≤ V ≤3m/s. The discharge angles were varied in the range of 0°≤ α ≤50°. Increasing the discharge angle mainly influenced the indoor temperature distributions. The Mean Square Error of validation and test set were 0.005696 and 0.00588 respectively. The temperature distribution was predicted using a Convolutional Neural Network. The predicted temperature distributions obtained from Convolutional Neural Network were matched well with the numerical data."
CNN-Based Novelty Detection with Effectively Incorporating Document-Level Information,2020,"['Deep Learning', 'CNN', 'Novelty Detection', '딥 러닝', '합성곱 신경망', '신규성 탐지']",국문 초록 정보 없음,"With a large number of documents appearing on the web, document-level novelty detection has become important since it can reduce the efforts of finding novel documents by discarding documents sharing redundant information already seen. A recent work proposed a convolutional neural network (CNN)-based novelty detection model with significant performance improvements. We observed that it has a restriction of using document-level information in determining novelty but assumed that the document-level information is more important. As a solution, this paper proposed two methods of effectively incorporating document-level information using a CNN-based novelty detection model. Our methods focus on constructing a feature vector of a target document to be classified by extracting relative information between the target document and source documents given as evidence. A series of experiments showed the superiority of our methods on a standard benchmark collection, TAP-DLND 1.0."
Study and Application of RSSI-based Wi-Fi Channel Detection Using CNN and Frequency Band Characteristics,2020,"['와이파이 스캔', '비면허 대역', '저전력 안테나', '딥 러닝', '합성곱 신경망', 'Wi-Fi scanning', 'ISM band', 'low power antenna', 'deep learning', 'convolution neural network']",국문 초록 정보 없음,다국어 초록 정보 없음
정비 자료 디지털 변환을 위한 영상 인식 알고리듬 : CNN and FCN,2020,"['Tabular Maintenance Data(정비 자료표)', 'Digitization(디지털화)', 'CNN(합성곱 신경망)', 'FCN(완전 연결망)']",국문 초록 정보 없음,"Tabulated data has been widely used to facilitate systematic and intuitive management. In particular, tabular images that contain a few simple symbols are useful for maintaining mechanical systems. Several companies have accumulated tabular images as their property. Although these images are valuable as they can be used to solve difficult problems using data-based methods, such as deep learning, they still remain unavailable because it is expensive to digitize them. For these reasons, we propose a model comprised of a convolutional neural network (CNN) and fully convolutional network (FCN) to digitize tabular images. We used some ResNet components as they are well-suited to the characteristics of tabular image data. A training set for each model was constructed by writing symbols in blank tables and then augmenting them. As a result, the trained CNN and FCN models exhibited 99.2 % and 97.7 % accuracy in 4.75 s and 0.132 s of inference time, respectively."
인공지능 기반 소방시설 설계 자동화를 위한 선행기술 분석,2020,"['Artificial Intelligence(인공지능)', 'Fire Protection System(화재 방호 설비)', 'Convolutional Neural Networks(합성곱 신경망)', 'Image Segmentation(이미지 분할)']",국문 초록 정보 없음,다국어 초록 정보 없음
규칙기반과 딥러닝을 동시에 활용한 앙상블 회전체 이상진단,2020,"['Ensemble(앙상블)', 'Rule-based(규칙기반)', 'Deep Learning(심층 학습)', 'CNN(합성곱 신경망)', 'Orbit Detection(궤도 추적)', 'Rotating Machine(회전체)', 'Machine Diagnostics(기계 진단)']",국문 초록 정보 없음,"Unlike the major equipment used in power plants, auxiliary equipment usually does not possess a real-time system to analyze the machine condition. Therefore, detecting the fault of such auxiliary equipment in advance is difficult. Thus, the diagnosis of auxiliary equipment at a less cost is important for minimizing the downtime due to the fault of the equipment. In this paper, we introduce a diagnosis method for auxiliary equipment in power plants using rule-based and deep-learning algorithms. First, we calculate the probability of cause of a fault from current symptoms by using the rule-based algorithm. The rule used in this algorithm is established based on expert experience. We then conduct orbit detection using a convolution neural network. This algorithm self-learns the filter to classify orbit images as normal, rubbing, and unbalanced. The weakness of the deep-learning algorithm can be compensated by combining the results of the aforementioned methods."
이미지 인식률 개선을 위한 CNN 기반 이미지 회전 보정 알고리즘,2020,"['Rotation Estimation', 'Deep Learning', 'CNN', 'Image Processing']","이미지 인식 및 영상처리, 컴퓨터 비전 등의 분야에서 합성곱 인공신경망 (Convolutional Neural Network, CNN)은 다양하게 응용되고 탁월한 성능을 내고 있다. 본 논문에서는 CNN을 활용한 이미지 인식 시스템에서 인식률을저하시키는 요인 중 하나인 이미지의 회전에 대한 해결책으로써 CNN 기반 이미지 회전 보정 알고리즘을 제안한다. 본논문에서는 Leeds Sports Pose 데이터셋을 활용하여 이미지를 임의의 각도만큼 회전시킨 학습데이터로 인공지능 모델을 학습시켜 출력으로 회전된 각도를 추정하도록 실험을 진행하였다. 학습된 인공지능 모델을 100장의 테스트 데이터이미지로 실험하여 mean absolute error (MAE) 성능지표를 기준으로 4.5951의 값을 얻었다.","Recently, convolutional neural network (CNN) have been showed outstanding performance in the field of image recognition, image processing and computer vision, etc. In this paper, we propose a CNN-based image rotation correction algorithm as a solution to image rotation problem, which is one of the factors that reduce the recognition rate in image recognition system using CNN. In this paper, we trained our deep learning model with Leeds Sports Pose dataset to extract the information of the rotated angle, which is randomly set in specific range. The trained model is evaluated with mean absolute error (MAE) value over 100 test data images, and it is obtained 4.5951."
머신러닝 기반 기업부도위험 예측모델 검증 및 정책적 제언: 스태킹 앙상블 모델을 통한 개선을 중심으로,2020,"['부도위험 예측', '스태킹 앙상블 모델', '머튼 모형', '랜덤 포레스트', '합성곱 신경망', 'Corporate default risk prediction', 'Merton model', 'Random forest', 'CNN']",국문 초록 정보 없음,"This study uses corporate data from 2012 to 2018 when K-IFRS was applied in earnest to predict default risks. The data used in the analysis totaled 10,545 rows, consisting of 160 columns including 38 in the statement of financial position, 26 in the statement of comprehensive income, 11 in the statement of cash flows, and 76 in the index of financial ratios. Unlike most previous prior studies used the default event as the basis for learning about default risk, this study calculated default risk using the market capitalization and stock price volatility of each company based on the Merton model. Through this, it was able to solve the problem of data imbalance due to the scarcity of default events, which had been pointed out as the limitation of the existing methodology, and the problem of reflecting the difference in default risk that exists within ordinary companies. Because learning was conducted only by using corporate information available to unlisted companies, default risks of unlisted companies without stock price information can be appropriately derived. Through this, it can provide stable default risk assessment services to unlisted companies that are difficult to determine proper default risk with traditional credit rating models such as small and medium-sized companies and startups. Although there has been an active study of predicting corporate default risks using machine learning recently, model bias issues exist because most studies are making predictions based on a single model. Stable and reliable valuation methodology is required for the calculation of default risk, given that the entitys default risk information is very widely utilized in the market and the sensitivity to the difference in default risk is high. Also, Strict standards are also required for methods of calculation. The credit rating method stipulated by the Financial Services Commission in the Financial Investment Regulations calls for the preparation of evaluation methods, including verification of the adequacy of evaluation methods, in consideration of past statistical data and experiences on credit ratings and changes in future market conditions. This study allowed the reduction of individual models bias by utilizing stacking ensemble techniques that synthesize various machine learning models. This allows us to capture complex nonlinear relationships between default risk and various corporate information and maximize the advantages of machine learning-based default risk prediction models that take less time to calculate. To calculate forecasts by sub model to be used as input data for the Stacking Ensemble model, training data were divided into seven pieces, and sub-models were trained in a divided set to produce forecasts. To compare the predictive power of the Stacking Ensemble model, Random Forest, MLP, and CNN models were trained with full training data, then the predictive power of each model was verified on the test set. The analysis showed that the Stacking Ensemble model exceeded the predictive power of the Random Forest model, which had the best performance on a single model. Next, to check for statistically significant differences between the Stacking Ensemble model and the forecasts for each individual model, the Pair between the Stacking Ensemble model and each individual model was constructed. Because the results of the Shapiro-wilk normality test also showed that all Pair did not follow normality, Using the nonparametric method wilcoxon rank sum test, we checked whether the two model forecasts that make up the Pair showed statistically significant differences. The analysis showed that the forecasts of the Staging Ensemble model showed statistically significant differences from those of the MLP model and CNN model. In addition, this study can provide a methodology that allows existing credit rating agencies to apply machine learning-based bankruptcy risk prediction methodologies, given that traditional credit rating models can a"
다시점 영상 집합을 활용한 선체 블록 분류를 위한 CNN 모델 성능 비교 연구,2020,"['Multi-view image set(다시점 영상 집합)', 'Convolutional Neural Network(CNN', '합성곱신경망)', 'Ship hull block(선체 블록)', 'Classification(분류)', 'Data augmentation(데이터 확장)', 'Transfer learning(전이학습)']",국문 초록 정보 없음,"It is important to identify the location of ship hull blocks with exact block identification number when scheduling the shipbuilding process. The wrong information on the location and identification number of some hull block can cause low productivity by spending time to find where the exact hull block is. In order to solve this problem, it is necessary to equip the system to track the location of the blocks and to identify the identification numbers of the blocks automatically. There were a lot of researches of location tracking system for the hull blocks on the stockyard. However there has been no research to identify the hull blocks on the stockyard. This study compares the performance of 5 Convolutional Neural Network (CNN) models with multi-view image set on the classification of the hull blocks to identify the blocks on the stockyard. The CNN models are open algorithms of ImageNet Large-Scale Visual Recognition Competition (ILSVRC). Four scaled hull block models are used to acquire the images of ship hull blocks. Learning and transfer learning of the CNN models with original training data and augmented data of the original training data were done. 20 tests and predictions in consideration of five CNN models and four cases of training conditions are performed. In order to compare the classification performance of the CNN models, accuracy and average F1-Score from confusion matrix are adopted as the performance measures. As a result of the comparison, Resnet-152v2 model shows the highest accuracy and average F1-Score with full block prediction image set and with cropped block prediction image set."
Automatic Target Recognition for Synthetic Aperture Radar Using Transfer Learning from EO/IR Images,2020,"['Automatic Target Recognition(자동 표적 인식)', 'Synthetic Aperture Radar(합성 개구 레이다)', 'Convolution Neural Network(합성곱 신경망)', 'Transfer Learning(전이학습)']",국문 초록 정보 없음,다국어 초록 정보 없음
BCI 제어를 위한 뇌신호 분류에서의 딥러닝 모델 개발,2020,"['뇌신호', '뇌-컴퓨터 인터페이스', '운동상상', '뇌신호 분류', '딥러닝', '합성곱신경망', 'Electroencephalography(EEG)', 'Brain-computer interface(BCI)', 'Motor imagery(MI)', 'EEG classification', 'deep learning', 'Convolutional neural network(CNN)']",국문 초록 정보 없음,다국어 초록 정보 없음
시각-언어 공동 임베딩과 지식 그래프 임베딩을 이용한 영상 기반 상식 추론,2020,"['영상 기반 상식 추론', '시각-언어 공동 임베딩', '지식 임베딩', '그래프 신경망', 'visual commonsense reasoning', 'vision-language co-embedding', 'knowledge embedding', 'graph neural network']","본 논문에서는 영상 기반 상식 추론(VCR) 작업을 위한 새로운 모델을 제안한다. 제안 모델에서는 영상과 자연어 질문, 답변 리스트 등과 같은 멀티 모달 입력 데이터들 간의 상호 정렬을 요구하는 시각적 접지 문제에 효과적으로 대응하기 위해, 사전 학습된 시각-언어 모델에 시각적 바인딩 모듈을 추가하여 이들을 함께 임베딩한다. 또한, 제안 모델은 영상 기반 상식 추론에 필요한 공통 개념지식들을 공개 지식 베이스인 ConceptNet에서 추출하여 그래프 합성곱 신경망(GCN)을 이용해 임베딩한다. 본 논문에서는 제안 모델인 VLKG_VCR의 세부 설계사항들을 소개하고, 증진된 VCR 벤치마크 데이터 집합을 이용한 다양한 실험들을 통해 제안 모델의 성능을 입증한다.","In this paper, we proposed a novel model for Visual Commonsense Reasoning (VCR).The proposed model co-embeds multi-modal input data together using a pre-trained vision-language model to effectively cope with the problem of visual grounding, which requires mutual alignment between an image, a natural language question, and the corresponding answer list. In addition, the proposed model extracts the common conceptual knowledge necessary for Visual Commonsense Reasoning from ConceptNet, an open knowledge base, and then embeds it using a Graph Convolutional neural Network (GCN). In this paper, we introduced the design details of the proposed model, VLKG_VCR, and verified the performance of the model through various experiments using an enhanced VCR benchmark data set.Keywords: visual commonsense reasoning"
Spectral Pooling: DFT 기반 풀링 계층이 보여주는 여러 가능성에 대한 연구,2020,[],"GPU의 발전과 함께 성장한 딥러닝(Deep Learning)은 영상 분류 문제에서 최고의 성능을 보이고 있다. 그러나 합성곱 신경망 기반의 모델을 깊게 쌓음에 따라 신경망의 표현력이 좋아짐과 동시에 때로는 학습이 잘되지 않고 성능이 저하되는 등의 부작용도 등장했다. 성능 향상을 방해하는 주요 요인 중 하나는, 차원감소 목적에 따라 필연적으로 정보 손실을 겪어야 하는 풀링 계층에 있다. 따라서 특성맵(Feature map)의 차원감소를 통해 얻게 되는 비용적 이득과 모델의 분류 성능 사이의 취사선택(Trade-off)이 존재한다. 그리고 이로부터 자유로워지기 위한 다양한 연구와 기법이 존재하는데 Spectral Pooling도 이 중 하나이다. 본 논문에서는 이산 푸리에 변환(Discrete Fourier Transform, DFT)을 이용한 Spectral Pooling에 대한 소개와, 해당 풀링의 성질을 통상적으로 사용되고 있는 Max Pooling과의 성능 비교를 통해 분석한다. 또한 영상 내 고주파수 부분에서 특히 더 강건하지 못하다는 맥스 풀링의 고질적인 문제점을, Spectral Pooling과의 하이브리드(Hybrid) 구조를 통해 어떻게 극복해나갈 것인지 그 가능성을 중심으로 실험을 수행했다.",다국어 초록 정보 없음
기계학습과 패턴인식을 적용한 작업모드 식별기법 연구,2020,"['Machine learning(기계학습)', 'Pattern recognition(패턴인식)', 'Dynamic time warping(동적 시간 굽힘)', 'Artificial neural network(인공신경망)', 'Convolution neural network(합성곱 신경망)', 'Hydraulic excavator(유압식 굴착기)']",국문 초록 정보 없음,다국어 초록 정보 없음
기계 학습 기반 탄성파 자료 단층 해석: 연구동향 및 기술,2020,"['machine learning', 'seismic exploration', 'fault interpretation', 'seismic attribute', 'convolutional neural network', '기계 학습', '탄성파 탐사', '단층 해석', '탄성파 속성', '합성곱 신경망']","최근 과학기술 및 공학 전 분야에서 기계 학습을 적용하는 연구들이 매우 활발하게 수행되고 있다. 탄성파 탐사분야 또한 해석, 처리, 취득 등 모든 영역에서 기계 학습을 적용한 연구들이 빠르게 증가하는 추세이다. 그 중 단층 해석은 탄성파 자료 해석 분야에 있어 가장 중요한 기술 중 하나이며, 기계 학습을 적용하기에 가장 적합한 분야이기도 하다.이 논문에서는 다양한 기계 학습 기법들에 대해 소개하고 단층 해석에 적합한 기법들과 그 이유를 기술하였다. 물리탐사분야의 저명한 국제 학술지에 게재된 논문과 국제 학술대회 발표 사례들을 조사하여 연도별, 분야별 연구 현황을 정리하였으며, 그 중 기계 학습을 사용한 단층 해석 연구들을 집중적으로 분석하였다. 단층 해석 기술은 입력 자료 및 기계 학습 모델의 형태에 따라 탄성파 속성 기반 기술, 탄성파 이미지 기반 기술, 원시자료 기반 기술로 나누어 그 장단점을 기술하였다.","Recently, many studies have been actively conducted on the application of machine learning in all branches of science and engineering. Studies applying machine learning are also rapidly increasing in all sectors of seismic exploration, including interpretation, processing, and acquisition. Among them, fault detection is a critical technology in seismic interpretation and also the most suitable area for applying machine learning. In this study, we introduced various machine learning techniques, described techniques suitable for fault detection, and discussed the reasons for their suitability. We collected papers published in renowned international journals and abstracts presented at international conferences, summarized the current status of the research by year and field, and intensively analyzed studies on fault detection using machine learning. Based on the type of input data and machine learning model, fault detection techniques were divided into seismic attribute-, image-, and raw data-based technologies; their pros and cons were also discussed."
YOLOv3을 이용한 과일표피 불량검출 모델: 복숭아 사례,2020,"['Peach', 'Defect Detection', 'Smart Farm', 'Region Convolutional Neural Network', 'YOLO', '복숭아', '불량검출', '스마트 팜', '영역기반 합성곱 신경망', 'YOLO']",국문 초록 정보 없음,"In the operation of farms, it is very important to evaluate the quality of harvested crops and to classify defective products. However, farmers have difficulty coping with the cost and time required for quality assessment due to insufficient capital and manpower. This study thus aims to detect defects by analyzing the epidermis of fruit using deep learning algorithm. We developed a model that can analyze the epidermis by applying YOLOv3 algorithm based on Region Convolutional Neural Network to video images of peach. A total of four classes were selected and trained. Through 97,600 epochs, a high performance detection model was obtained. The crop failure detection model proposed in this study can be used to automate the process of data collection, quality evaluation through analyzed data, and defect detection. In particular, we have developed an analytical model for peach, which is the most vulnerable to external wounds among crops, so it is expected to be applicable to other crops in farming."
"CCTV 영상으로부터 미세먼지 추정에서 학습영상조합, 기상변수 적용이 결과에 미치는 영향",2020,"['Deep Learning', 'PM Index', 'Support Vector Regression', 'SVR (Support Vector Regression)', 'CCTV', 'Convolutional Neural Network', '딥러닝', '미세먼지 지수', '합성곱 신경망']",국문 초록 정보 없음,다국어 초록 정보 없음
지능형 감시 정찰 시스템 구축을 위한 OpenPose와 Deep Learning 기술 적용방안 연구,2020,"['OpenPose', 'keypoints', 'deep neural networks', 'convolutional neural networks', 'long short-term memory', '오픈포즈', '키포인트', '심층 신경망', '합성곱 신경망', '장단기 기억 신경망']","본 연구에서는 국방 감시 정찰 시스템을 OpenPose와 DNN(Deep Neural Networks), CNN(Convolutional Neural Networks), LSTM(Long Short-Term Memory)과 같은 딥러닝 네트워크를 통해 구현하였다. 본 연구의 시스템은 기존의 감시 정찰 시스템과는 다른 방식의 거동수상자(target) 인식 방법을 제안하고 있으며, 제안하는 방법은 촬영되는 영상에서 사람들의 모션을 분류함으로써 일반인과 거동수상자를 구분하는 것이다. 이를 위해 OpenPose를 통해 영상 내의 대상의 skeleton 데이터를 추출한다. 이때, 추출되는 skeleton 데이터에 포함되는 keypoints를 DNN, CNN, LSTM에 입력하여 모션을 분류하게 된다. 분류되는 모션들은 사주경계와 같이 군에서 배울 수 있는 모션으로 선정하였다. 시스템이 모션을 분류하여 거동수상자를 인식하게 되면 지도에 이를 표시하고 추적을 한다. 추적 알고리즘에서는 프레임별로 OpenPose를 통해 추출된 keypoints 값의 변화를 계산하여 거동수상자의 이동방향을 계산하고 카메라에서 얻은 depth 정보를 활용하여 카메라 위치를 기반으로 거동수상자를 지도에 표시하도록 한다. 이와 같은 모든 연산은 전체 이미지가 아닌 skeleton 데이터를 활용하였기 때문에 전체적인 연산량을 감소시킬 수 있게 된다.","In this study, defense surveillance reconnaissance systems were implemented through deep learning networks such as OpenPose and deep neural networks (DNN), convolutional neural networks (CNN), and long short-term memory (LSTM). This study proposes a target recognition method which differs from the existing surveillance reconnaissance systems. This method consists in distinguishing between ordinary people and targets by classifying motions in the images being filmed. Thus, the skeleton data of the target in the image are extracted using OpenPose. Then, keypoints included in the extracted skeleton data are entered into DNN, CNN, and LSTM to classify the motion. The classified motions are selected as motions learned in the military, such as overall security. When the system classifies motions and recognizes targets, it identifies them on the map and tracks them. The tracking algorithm calculates the movement direction of the target by calculating the change in the values of keypoints extracted through OpenPose by frames. Finally, it uses the depth information obtained from the camera to display targets on the map based on the camera location. All these computations are based on the use of the skeleton data rather than the entire image, thus reducing the overall computation."
빗줄기 제거를 위한 구조 인식 잔차 네트워크,2020,"['rain removal', 'residual networks', 'filtering', 'convolutional neural networks', 'transfer learning']","본 논문에서는 입력 빗줄기 영상에서 빗줄기를 제거하고 텍스처의 선명도를 강화할 수 있는 빗줄기 제거기법을 제안한다. 최근 영상 복원 분야에서 큰 주목을 받고 있는 심층 합성곱 신경망 기법을 빗줄기 제거 분야에 적용할지라도 평탄 영역에서의 빗줄기 잔존 문제와 텍스처 선명도 저하 문제는 여전히 현안으로 남아 있다. 따라서 본 논문에서는 입력 빗줄기 영상에서 빗줄기를 효과적으로 제거하고 텍스처의 선명도를 강화할 수 있는 복원 기법을 제안하고자 한다. 특히 입력 빗줄기 영상으로부터 원본 영상의 라플라시안 필터링 결과인 에지 맵을 추정함으로써, 평탄 영역에서 빗줄기를 제거하고 디테일 영역에서 선명도를 강화할 수 있는 영상구조에 적응적인 구조 인식 잔차 네트워크를 소개하고자 한다. 또한 실험 평가를 통해, 제안한 구조 인식 잔차 네트워크가 소기의 목적을 성취할 수 있으며 기존의 최첨단 기법들보다 정량적 평가에서 더 우수한 성능을 달성할 수 있음을 보이고자 한다.","In this paper, rain streaks removal is proposed to remove rain streaks and to enhance the sharpness of textures from input rain images. Even though deep convolutional neural networks, which have recently attracted great attention in the field of image restoration, are applied to rain streaks removal, residual rain streaks on the flat areas and deterioration of texture sharpness in the texture areas remain current issues. Therefore, this paper proposes a restoration method that can effectively remove rain streaks and enhance texture’s sharpness from input rain images. In particular, by estimating the edge map, which is the result of Laplacian filtering applied to the original image, the structure-aware residual network that is able to adaptive to image structures is introduced to remove the rain streaks in the flat areas and enhance the sharpness in the detail areas. Moreover, through experimental evaluation, it is confirmed that the proposed structure-aware residual network can achieve the desired purpose and obtain better performance in quantitative evaluation than the existing state-of-the-art methods."
프로브 기반 공초점 현미경을 이용한 말초 신경의 실시간 변성 검출 연구,2020,"['Real-time Detection(실시간 검출)', 'Mosaicking(모자이킹)', 'Degeneration(변성)', 'Probe-Based Confocal Laser Endoscopy(프로브 기반 공초점 현미경)', 'Convolutional Neural Network(합성곱 신경망)']",국문 초록 정보 없음,다국어 초록 정보 없음
PointNet을 이용한 라이다 데이터의 지붕면 분할,2020,"['딥러닝', 'PonitNet', '라이다 데이터', '지붕면 분할']","딥러닝(DL)은 영상으로부터 객체를 인식하고 분류하는 컴퓨터비전 분야에서 연구가 활발히 진행되고 있다. 사진측량 분야에서는 주로 광학영상을 학습 데이터로 사용하는 합성곱 신경망(CNN; Convolutional Neural Network) 모델로 객체 분류를 수행하고 있다. 영상은 2차원 데이터이지만, 라이다 데이터는 3차원 좌표뿐 아니라 반사강도, 다중반사 정보 등 다양한 정보를 제공한다. 본 연구에서는 점군집 데이터 처리에 특화된 DL 모델인 PointNet을 이용하여 LiDAR 데이터로부터 건물 지붕면의 분할을 수행하고 결과를 분석하였다. 또한 신경망 모델 학습 과정에서 발생하는 과적합을 방지하기 위한 사전학습 모델을 생성하는 방안을 제시하였다.",다국어 초록 정보 없음
인공지능을 이용한 잣나무재 표면 옹이 분류 및 구획화,2020,[],"컴퓨터 이미지 분석 기술을 이용한 목재 표면 화상 분석은 목재 품질의 객관적인 평가와 이를 통한 목재 생산의 고속화를 위해 필요하다. 인공지능을 활용한 딥러닝(Deep Learning) 기술은 높은 정확도와 빠른 속도로 이미지 화상 분석 분야에서 높은 활용도를 보여주고 있다. 본 연구에서는 여러 딥러닝 기술 중 이미지 구획화에서 활용되는 합성곱 신경망(Convolutional Neural Network, CNN)을 이용하여 잣나무재 표면 옹이를 구획화하고, 그 종류를 분류하였다. 잣나무 각재에서 획득한 128개의 제재목 사진을 사용하였고, 이들 제재목 사진에서 추출한 227개의 옹이 이미지를 4가지 종류로 분류하였다. VGG Image Annotator를 이용하여 옹이의 위치와 종류에 대한 데이터베이스를 만들고, 이를 통해 제재목 표면의 옹이를 구획화하여 표시하고, 종류를 분류하는 알고리즘 모델 학습을 진행하였다. 또한, 색상으로 인한 분류 오차가 생길 수 있다고 판단하여 흑백으로 변환한 잣나무재 이미지에서도 옹이 구획화 및 분류를 진행하였다. 잣나무재 표면 옹이 구획화 및 분류 학습을 진행한 결과 옹이의 종류나 크기 등의 변수가 존재함에도 높은 정확도로 목재 표면 옹이를 탐지할 수 있었고, 옹이 종류 분류에서도 준수한 정확도를 보여주었다. 그리고 RGB 이미지보다 흑백으로 변환한 이미지를 분류할 때 조금 더 높은 정확도를 보였는데, 이를 통해 이미지 분류에서 색상으로 인한 변수가 존재함을 추론할 수 있었다. 옹이 종류에 따라 이미지 개수의 현저한 격차가 존재하여 분류 학습에 어려움이 있었는데, 이미지 개수가 적은 희귀 종류 옹이를 추가로 학습시킨다면 더 높은 정확도를 얻을 수 있을 것으로 기대된다.",다국어 초록 정보 없음
가속도 센서 데이터 기반의 행동 인식 모델 성능 향상 기법,2020,"['Human activity recognition', 'Deep learning', 'Convolutional Neural Networks', 'Recurrent Neural Networks', 'Time-series classification']","스마트 모바일 장치의 확산은 인간의 일상 행동 분석을 보다 일반적이고 간단하게 만들었다. 행동 분석은 이미 본인 인증, 감시, 건강 관리 등 많은 분야에서 사용 중이고 그 유용성이 증명되었다. 본 논문에서는 스마트폰의 가속도 센서 신호를 사용하여 효율적이고 정확하게 행동 인식을 수행하는 합성곱 신경망(모델 A)과 순환 신경망까지 적용한(모델 B) 심층 신경망 모델을 제시한다. 모델 A는 batch normalization과 같은 단순한 기법만 적용해도 이전의 결과보다 더 작은 모델로 더 높은 성능을 달성할 수 있다는 것을 보인다. 모델 B는 시계열 데이터 모델링에 주로 사용되는 LSTM 레이어를 추가하여 예측 정확도를 더욱 높일 수 있음을 보인다. 이 모델은 29명의 피실험자를 대상으로 수집한 벤치마크 데이트 세트에서 종합 예측 정확도 97.16%(모델 A), 99.50%(모델 B)를 달성했다.","With a widespread of sensor-rich mobile devices, the analysis of human activities becomes more general and simpler than ever before. In this paper, we propose two deep neural networks that efficiently and accurately perform human activity recognition (HAR) using tri-axial accelerometers. In combination with powerful modern deep learning techniques like batch normalization and LSTM networks, our model outperforms baseline approaches and establishes state-of-the-art results on WISDM dataset."
RGB영상 기반 시설오이 검출을 위한 딥러닝 객체검출 모델의 적용,2020,"['오이', '스마트팜', '검출', '딥러닝']","최근 계측, 인공지능, IOT 등 기술의 고도화와 스마트팜에 대한 이러한 기술들의 적용이 활발히 이루어지고 있다. 이러한 스마트팜 기술 중 대상 작물에 대한 영상 기반 인식 기술은 로봇 기반 수확 및 모니터링을 위하여 필수적이다. 특히 최근 합성곱신경망(Convolutional Neural Network, CNN) 기반의 딥러닝 모델들은 영상 분류, 분할, 검출 분야에서 기존 모델들 대비 높은 성능을 보이면서 스마트팜에 필요한 영상인식 기술에서 다양하게 적용되고 있다. 일반적으로 이러한 영상 인식 모델들은 모델들의 크기, 구조에 따라 속도와 성능의 차이가 존재한다. 시스템의 요구 속도와 성능에 따라서 다양한 모델들이 적용될 수 있으므로, 시스템 적용에 앞서 이러한 모델들의 최적 속도와 성능에 대한 비교평가가 필요하다. 본 연구에서는 RGB 영상 기반 스마트팜 내부 오이 과실에 대한 검출 기술을 개발하기 위하여 다양한 속도의 딥러닝 검출 모델을 적용해보고, 정확도 결과를 비교하였다.",다국어 초록 정보 없음
인공지능 기반 영상 화질 개선 최신 기술 동향,2020,[],"최근 모바일 기기를 위한 카메라 관련 기술이 발전하면서 취득할 수 있는 영상의 화질 또한 크게 향상되고 있다. 그러나, 일상 생활에서 빈번히 발생하는 다양한 실내외 불규칙한 조명 조건 및 저조도 환경은 여전히 영상 화질 저하를 야기한다. 본 고에서는 이러한 문제를 해결하기 위해 최근 널리 연구되고 있는 심층신경망 기반 영상 화질 개선 연구의 최신 동향을 소개하고자 한다. 먼저, 다양한 최적화 기법을 바탕으로 영상 내 조명 성분을 추정하고, 이를 개선하는 방법들에 대해 간략히 설명한다. 또한, 영상 인식, 객체 검출 등에서 뛰어난 성능을 입증한 합성곱 신경망 구조를 기반으로 영상의 잠재적 특징을 효과적으로 검출한 후 이를 바탕으로 개선된 영상을 생성하는 방법에 대해 설명한다. 다양한 데이터셋에 대한 실험 결과를 통해 인공지능 기반 영상 화질 개선의 우수성을 보인다.",다국어 초록 정보 없음
딥러닝 기반 지하공동구 화재 탐지 모델 개발 : 학습데이터 보강 및 편향 최적화,2020,"['Underground Utility Facility', 'Fire Detection', 'Deep Learning', 'Convolutional Neural Network', 'Bias Training']","화재는 높은 비정형성으로 인해 딥러닝 모델을 이용한 영상인식 분야에서도 좋은 성능을 내기가 어려운 대상 중 하나이다. 특히 지하공동구 내 화재는 딥러닝 모델의 학습을 위한 화재 데이터 확보가 어렵고 열약한 영상 조건 및 화재로 오인할 수 있는 객체가 많아 화재 검출이 어렵고 성능이 낮다. 이러한 이유로 본 연구는 딥러닝 기반의 지하공동구 내 화재 탐지 모델을 제안하고, 제안된 모델의 성능을 평가하였다. 기존 합성곱 인공신경망에 GoogleNet의 Inception block과 ResNet의 skip connection을 조합하여 어두운 환경에서 발생되는 화재 탐지를 위한 모델 구조를 제안하였으며, 제안된 모델을 효과적으로 학습시키기 위한 방법도 함께 제시하였다. 제안된 방법의 효과를 평가하기 위해 학습 후 모델을 지하공동구 및 유사환경 조건의 화재 문제와 화재로 오인할 수 있는 객체를 포함한 이미지에 적용해 결과를 분석하였다. 또한 기존 딥러닝 기반 화재 탐지 모델의 정밀도, 검출률 지표와 비교함으로써 모델의 화재 탐지성능을 정량적으로 평가하였다. 제안된 모델의 결과는 어두운 환경에서 발생되는 화재 문제에 대해 높은 정밀도와 검출률을 나타내었으며, 유사 화재 객체에 대해 낮은 오탐 및 미탐 성능을 가지고 있음을 보여주었다.","Fire is difficult to achieve good performance in image detection using deep learning because of its high irregularity. In particular, there is little data on fire detection in underground utility facilities, which have poor light conditions and many objects similar to fire. These make fire detection challenging and cause low performance of deep learning models. Therefore, this study proposed a fire detection model using deep learning and estimated the performance of the model. The proposed model was designed using a combination of a basic convolutional neural network, Inception block of GoogleNet, and Skip connection of ResNet to optimize the deep learning model for fire detection under underground utility facilities. In addition, a training technique for the model was proposed. To examine the effectiveness of the method, the trained model was applied to fire images, which included fire and non-fire (which can be misunderstood as a fire) objects under the underground facilities or similar conditions, and results were analyzed. Metrics, such as precision and recall from deep learning models of other studies, were compared with those of the proposed model to estimate the model performance qualitatively. The results showed that the proposed model has high precision and recall for fire detection under low light intensity and both low erroneous and missing detection capabilities for things similar to fire."
SE-ResNeXt 기반 위험 소리 분류에 관한 연구,2020,"['딥러닝', '위험 소리 분류', '청각장애인', 'SE-ResNeXt', 'Deep Learning', 'Hazardous Sound Classification', 'Deaf People']","청각장애인은 일상생활에서 위험 소리를 듣지 못하여 위험에 많이 노출되고 있으며, 이를 해결하기 위해서 위험 소리를 인지하여 청각장애인에게 알려주는 기술이 필요하다. 최근 딥러닝을 적용하여 음향 이벤트를 분류하는 기술에 대한 연구는 진행되고 있지만, 위험 소리에 특화된 데이터 셋이 존재하지 않아 위험 소리를 분류하는 기술은 연구가 많이 진행되고 있지 않다. 따라서 본 논문에서는 10개의 범주에 대하여 26시간 규모의 위험 소리 데이터 셋을 구축하였다. 그리고 최신 합성곱 신경망 모델인 SE-ResNeXt을 사용하는 위험 소리 분류 방법을 제안하였다. 마지막으로 본 연구에서 구축한 위험 소리 데이터 셋을 사용하여 기존의 방법과 제안 방법의 분류 성능을 분석하였으며, 본 논문에서 제안한 SE-ResNeXt 기반의 위험 소리 분류 방법이 기존의 방법보다 뛰어난 분류 성능을 가지는 것을 실험 결과로 확인하였다.","Deaf people are exposed to a lot of dangerous situations since they are unable to hear hazardous sounds in their daily lives. In order to solve this problem, it is required a method that classifies hazardous sounds accurately and notifies dangerous situations to deaf people. Although there are many researches on classifying acoustic events based on deep learning technology, only a little has been going on for classifying dangerous sounds because there are no datasets especially configured for dangerous environments. Therefore, in this paper, we built a 26-hour long dataset for 10 hazardous sound categories to assess the classification performance. In addition, we proposed the SE-ResNeXt, which is the state-of-the-art convolutional neural networks model, as a method for classification. Finally, we compared the performances of the proposed method with existing methods, using our hazardous sound dataset. From the result of our experiment, we found out that the classification accuracy of SE-ResNeXt model is superior to that of pre-existing methods."
자율 농작업을 위한 딥러닝 기반 작업영역 경계 검출,2020,"['자율주행', '딥러닝', '영역분할', '경계검출', '트랙터 경운']","본 연구에서는 무인 농업기계 개발의 기초 연구로써 2D 기계시각 및 딥러닝을 이용하여 농작업 시 작업 영역의 경계를 검출을 목적으로 하며 트랙터의 경운작업 시 정면영상 내 경작 전, 후 영역 검출 기술 개발 및 성능을 평가하였다. 딥러닝 기반 경계 검출을 위해 트랙터 경운 작업의 정면영상을 수집하였으며, 입력된 영상의 구역별 분류 기반 영역 군집화를 통해 경계를 검출하였다. 구역별 영상의 분류는 4개의 합성곱신경망과 1개의 완전연결망으로 구성된 인경신경망 모델을 이용하였으며, 분류기에서 출력되는 경작 후 부류의 확률값을 원 영상에서의 위치를 기준으로 결합하여 2차원의 확률맵이 생성하였다. 분할된 영역은 측면과 상단에서 각각의 경계를 가지고 있으며, 측면이 경작 전 영역과 맞닿아 있는 영역의 경계로, 허프변환을 이용하여 이를 대표직선으로 표현하였다. 성능평가 결과 학습모델의 분류 성능은 F1-score가 약 0.91, 경계 검출 성능은 경작 전, 후 영역의 위치에 따라 횡방향 오차 평균 11~12.6 cm, 각도 오차 평균 8.0~9.8°로 나타났다. 본 연구결과는 기존에 수행된 농업분야 자율주행 기술의 성능범위 수준을 보여주었으며, 저가의 2D 영상 시스템 및 딥러닝을 이용한 자율주행 농업기계 기술이라는 측면에서 기존 연구에 비해 높은 실용화 가능성 및 넓은 적용 범위의 장점이 있다고 판단된다.",다국어 초록 정보 없음
고령화 사회 원격 진료를 위한 확률론적 예측인공지능 연구,2020,"['aging society', 'shortage of medical personnel', 'elder care', 'artificial intelligence', 'prediction intelligence', 'neuromorphic device']","저출산 고령화 사회로의 진입은 대한민국뿐만 아니라 전 세계적으로 많은 사회 문제를 야기하고 있다. 그 중에서 고령 인구 증가로 인한 의료 수요 증가와 이를 뒷받침 할 의료인력 부족은 곧 다가올 사회문제이다. 4차 산업혁명으로 인해 다양한 사회문제에 대한 혁신적인 해법들이 제시되고 있는데, 본 기고문에서는 다가올 고령화 사회에서 의료인력 부족 등에 의한 해결법으로 원격의료 지원을 위한 인공지능 활용을 다루고자 한다. 병 진단 및 예측을 위한 여러 가지 인공지능 알고리즘은 이미 많이 개발 되어 있으나, 일반적으로 딥러닝에 많이 쓰이는 인공신경망 구조인 합성곱 뉴럴네트워크(convolution neural network)나 기존 퍼셉트론(perceptron) 구조에서 벗어나 확률론적 인공신경망 중에 하나인 베이지안 뉴럴네트워크(Bayesian neural network)를 다루고자 한다. 그중에서 연산효율적이며 뉴로모픽 하드웨어로 구현 가능성이 높고 실제 진단 예측(diagnosis prediction) 문제 해결에 강점을 보이는 알고리즘으로써 naive Bayes classifer를 활용한 연구를 소개하고자 한다.",다국어 초록 정보 없음
딥러닝 기반 음향 신호 대역 확장 시스템,2020,"['Audio', 'Bandwidth Extension', 'Deep Learning', 'Convolutional Neural Network', 'Autoencoder']","대역 확장(Bandwidth Extension)이란 채널 용량 부족 혹은 이동통신 기기에 탑재된 코덱의 특성으로 인해 부호화 및 복호화 과정에서 대역 제한(band limited)되거나 손상된 협대역 신호(NB, Narrow Band)를 복원, 확장하여 광대역 신호(WB, Wide Band)로 전환 시켜주는 것을 의미한다. 대역 확장 연구는 주로 음성 신호 위주로 대역 복제(SBR, Spectral Band Replication), IGF(Intelligent Gap Filling)과 같이 고대역을 주파수 영역으로 변환하여 복잡한 특징 추출 과정을 거쳐 이를 바탕으로 사라지거나 손상된 고대역을 복원한다. 본 논문에서는 딥러닝 모델 중 오토인코더(Autoencoder)를 바탕으로 1차원 합성곱 신경망(CNN, Convolutional Neural Network)들의 잔차 연결을 활용하여 복잡한 사전 전처리 과정 없이 일정한 길이의 시간 영역 신호를 입력시켜 대역 확장 시킨 음향 신호를 출력하는 모델을 제안한다. 또한 음성 영역에 제한되지 않는 음악을 포함한 여러 종류의 음원을 포함하는 데이터셋에 훈련시켜도 손상된 고대역을 복원할 수 있음을 확인하였다.","Bandwidth Extension refers to restoring and expanding a narrow band signal(NB) that is damaged or damaged in the encoding and decoding process due to the lack of channel capacity or the characteristics of the codec installed in the mobile communication device. It means converting to a wideband signal(WB). Bandwidth extension research mainly focuses on voice signals and converts high bands into frequency domains, such as SBR (Spectral Band Replication) and IGF (Intelligent Gap Filling), and restores disappeared or damaged high bands based on complex feature extraction processes. In this paper, we propose a model that outputs an bandwidth extended signal based on an autoencoder among deep learning models, using the residual connection of one-dimensional convolutional neural networks (CNN), the bandwidth is extended by inputting a time domain signal of a certain length without complicated pre-processing. In addition, it was confirmed that the damaged high band can be restored even by training on a dataset containing various types of sound sources including music that is not limited to the speech."
한국어 영상 데이터 감정 분류를 위한 멀티모달 딥러닝 모델,2020,"['multimodal', '3D convolution', 'MFCC', 'spectrogram', 'sentiment classification']","최근 인간의 감정을 분석하고 활용하려는 시도가 늘어남에 따라 다양한 데이터 분석 방법을 통해 이를 실현하고자 하고 있는 상황이다. 하지만 기존 감정 분석은 대부분 하나의 형태(unimodal)를 가진 데이터를 활용하여 인간의 감정을 분석하는 데 한계가 있다. 따라서 본 논문은 한국어 영rweCV X상 데이터를 이용하여 멀티모달(multimodal) 데이터 기반의 감정 분류 딥러닝 모델을 제안한다. 각각의 데이터 형태(modality)에 특화된 딥러닝 구조를 사용하여 사람을 표현하는 데이터가 가진 특징을 잘 추출할 수 있도록 모델을 구성하였다. 멀티모달 영상 데이터는 동영상, 음성 2가지로 분리하여 실험을 진행하였다. 첫째로 동영상 데이터는 3차원 데이터에 적합한 모델인 3D 합성곱 신경망(3D convolutional neural network)를 사용하여 특징을 뽑았다. 여기서 감정 분류에 중요한 역할을 하는 얼굴 부분만을 이용하여 효과적으로 특징을 추출할 수 있었다. 두번째로 음성 데이터는 관련 분야에서 가장 우수한 성능을 보이는 MFCC(Mel-frequency cepstral coefficient) 기법을 통해 음성 데이터를 스펙트로그램(spectrogram) 이미지로 만들었다. 최근 스펙트로그램 이미지 분석연구에서 좋은 성능을 보이는 VGG-M network를 본 제안방법론에 맞게 변형하여 특징을 추출하였다. 얻어진 특징벡터들을 합친 후 최종적으로 분류기를 통해 감정 분류를 예측하는 구조를 사용하였다. 제안 방법의 우수성을 입증하기 위해 단일 형태의 데이터와의 감정 분류 성능을 비교하였고 성능 향상을 확인하였다. 본 연구는 한국어 감성 분석 데이터에 멀티모달 구조를 적용하여 효과적으로 감정 분류를 해냈다는 점에서도 기여점을 가진다.",다국어 초록 정보 없음
실내 핑거프린트 측위를 위한 딥러닝 기반의 초고해상도 RF 맵 재구성 기법,2020,"['실내 위치 추정', '핑거프린트 측위', 'RF 맵 재구성', '딥러닝']",본 논문은 실내 핑거프린트 측위의 정확도를 향상시키기 위한 딥러닝 기반의 RF 맵 재구성 기법을 제안한다. 제안 기법은 합성곱 신경망 구조를 사용하여 희소 데이터와 정답 데이터와의 관계를 직접 학습함으로써 오프라인 단계에서 조사하지 않은 지역의 RF 맵을 고해상도로 복원한다. 실험 결과를 통해 제안 기법이 기존의 핑거프린트 측위보다 7.53m 향상된 측위 정확도를 가지며 다항식 보간법으로 RF 맵을 재구성하는 기법보다 0.92m의 추가적인 측위 정확도를 획득하였다.,"In this paper, we propose a deep learning-based radio frequency (RF) map reconstruction method to improve the accuracy of the indoor fingerprint positioning. The proposed scheme reconstructs the RF map in super-resolution using a convolutional neural network (CNN) by directly learning with sparse data and ground truth data in the offline phase. The simulation results show that the proposed method has 7.53m improved positioning accuracy than the conventional fingerprint positioning and 0.92m additional positioning accuracy than the bicubic interpolation method."
스타일러스 펜을 활용한 금융 거래에서의 본인 인증,2020,"['styluspen', 'acceleration sensor', 'signature', '2 Factor Authentication', 'Convolution Neural Network']","최근 신용카드의 사용 비중이 늘어나고 있으며 그에 따른 보안 위협이 증가하고 있다. 특히 신용카드 부정사용,명의 도용 등의 관련 범죄에 취약함에도 불구하고 카드 결제 시 이를 방지하기 위한 보안 장치가 없는 상황이다. 이러한 현재 신용카드 결제의 한계점을 보완하기 위해 본 논문에서는 기존 거래 방식에 가속도 센서가 내장된 스타일러스 펜을 활용하여 결제 서명을 하고, 합성곱 신경망을 통해 해당 서명의 이미지와 센서를 통해 측정한 서명 정보를 분류하여 상호 비교하는 과정을 추가한다. 이와 같이 스타일러스 펜의 소유 여부와 서명의 특징 값을 통해 본인인증과정을 수행함으로써 금융 거래에서의 보안성을 증진시키는 방법을 제안한다.","As the use of credit cards increases, security threats increase. In particular, despite being vulnerable to related crimes,such as fraudulent use of credit cards and theft of names, there are virtually no security procedures to authenticate thevalidity of user while paying with the credit card. In order to overcome these limitations of current credit card payments,we add a process of signing payment using a stylus pen with built-in acceleration sensor in the existing transaction method,and classifying and comparing the image of the signature and signature information measured by the sensor through theconvolutional neural network. we propose a method to improve security in financial transactions by performing the userauthentication process through the possession of the stylus pen and the characteristic values of the signature."
JPEG 확장자로 추출된 흉부 X선을 이용한 딥러닝 연구에서 대조도와 영상 처리가 기흉 분류에 미치는 영향,2020,"['Deep learning', 'X-ray', 'Machine learning']","IntroductionX선 영상은 장비, 환자의 체형, X선의 선량, 및 후 처리 과정 등에 따라 영상의 대조도와 픽셀 정보가 다를 수 있다. 흉부 X 선 영상을 이용한 딥러닝 연구에서 JPEG (Joint Photograph Experts Group) 혹은 PNG (Portable Network Graphics) 확장자로 추출한 이미지를 이용한 연구들이 있다. 이 연구는 JPEG로 추출된 흉부 X선 영상을 이용하여 대조도 (Contrast) 에 따른 학습 결과와 영상처리 (image processing)을 통한 개선 영향을 알아보고자 한다.Material & Method데이터는 2012년 1월부터 2020년 6월까지 기흉 진단을 받은 환자와 정상 소견을 보인 환자의 흉부 X선 영상들을 JPEG로 각각 1,089장과 2,100장(학습 70%, 내부검증 30%) 수집하였으며, 2020년 6월부터 9월까지 테스트를 위하여 각각 100장과 200장을 추가로 획득하였다. 수집된 자료를 매트랩(Matlab)을 이용하여 다섯 종류(기본 100%, 기본의 각각 50%, 75%, 125% 와 150%)의 밝기의 대조도로 변화시키고, 합성곱 신경망(Convolutional neural network, CNN) 중 Resnet 34로 학습을 진행하고 결과를 비교하였다. 영상 처리를 하지 않은 경우 (그룹 A)와 비교하여 정규화 (Normalization)와 평탄화 (Histogram)를 통한 영상처리 후 (그룹 B)에 학습 결과가 개선되는 지 실험을 하였다.Result영상 처리를 적용하지 않은 그룹 A 의 경우에는 학습 데이터와 같은 대조도의 영상을 테스트 한 결과는 모두 정확도 (Accuracy) 0.99, 유덴지수 (Youden index, Sensitivity+Specificity-1) 0.99 이상을 보였다. 하지만, 학습한 데이터와 다른 대조도의 테스트를 한 경우에는 정확도가 약 50%까지 감소하였다. 영상 처리를 적용한 그룹 B에서는 학습 데이터와 같은 대조도의 영상을 테스트 한 결과는 Group A와 같이 모두 정확도는 0.99, 유덴지수는 0.99 이상을 보였다. 학습한 데이터와 다른 대조도의 테스트를 한 경우에는 대조도가 150% 밝은 영상을 제외하고 나머지 경우에는 학습결과의 감소하지 않았다.ConclusionJPEG 확장자로 추출한 X선을 이용한 딥러닝 연구에서 대조도에 따라 학습 결과의 차이를 보일 수 있으며, 이러한 문제점은 영상 처리를 통해 성능을 개선을 시킬 수 있다.",다국어 초록 정보 없음
흉부 X선 딥러닝 기반 기흉 검출 연구에서 이미지 확장자가 미치는 영향,2020,"['Deep learning', 'Image format', 'Machine learning']","Introduction기흉 분류 딥러닝 선행 연구에 따르면 의료영상의 표준 방식의 DCM (Digital Image Communicating in Medicine) 영상을 JPEG(Joint Photograph Experts Group) 또는 PNG(Portable Network Graphics) 형태로 다운 샘플링 하여 딥러닝에 적용되는 연구들이 있다. 이에 본 연구에서 동일한 흉부 X선 영상 데이터를 DCM과 JPEG 확장자를 이용하여 각각 기흉 분류를 위한 딥러닝 알고리즘을 적용하고 확장자에 따른 차이를 알아보고자 한다.Material & Method데이터는 2012년 1월부터 2020년 9월까지 일개 대학병원 응급실로 내원한 18~80세 환자로써, 기흉 진단을 받은 환자와 정상 소견을 보인 환자의 흉부 X선 영상들을 16비트 DCM 확장자로 각각 1,189장과 2,300장을 획득하였다. 수집된 자료를 대조도 조절을 통해 다섯 종류(기본 100%, 기본의 각각 50%, 75%, 125% 와 150%)의 밝기의 대조도로 변화시키고 8비트 Jpeg형식으로 다운 샘플링 하였다. 그리고 Jpeg 확장자로 된 그룹(그룹 A)와, DCM 확장자로 된 그룹(그룹 B)를 각각 합성곱 신경망 (Convolutional Neural Network, CNN)으로 학습하고, 같은 데이터를 저장 방식에 따라 그룹 A(Jpeg)와 그룹 B(DCM)가 학습 결과의 차이를 보이는 지 실험을 하였다.ResultJpeg 확장자로 구성된 그룹 A의 경우에는 학습 데이터의 대조도와 같은 대조도의 영상을 테스트 한 결과는 모두 정확도 (accuracy) 0.99, 유덴지수 (Youden index, Sensitivity+Specificity-1) 0.99 이상을 보였다. 하지만, 학습한 데이터 대조도와 다른 밝기의 대조도의 테스트를 한 경우에는 영상의 밝기가 밝아지거나 어두워질수록 accuracy 및 Youden index가 낮아지는 현상을 보였다. 그룹 B에서는 영상의 밝기에 상관없이 모든 값이 accuracy 0.99, Youden index 0.99로 측정되었다.ConclusionDICOM은 JPEG와 달리 많은 정보를 내재하고 있고, 영상의 gray scale 도 넓어 의료영상의 표준 방식으로 쓰이고 있다. 하지만 영상의 용량이 JPEG에 비하여 크고, 사전 처리가 까다로워 딥러닝 연구에 많이 쓰이지 않았다. 본 연구를 통해 JPEG 데이터 기흉 분류를 위한 딥러닝 알고리즘 적용 결과에서 영상의 밝기 등 픽셀 값 변화에 딥러닝 결과가 민감하게 반응한다는 것을 알 수 있었다. 이러한 문제점은 DICOM 형식으로 딥러닝 연구에 적용하면 성능을 개선 시킬 수 있다.",다국어 초록 정보 없음
상처와 주름이 있는 지문 판별에 효율적인 심층 학습 비교연구,2020,"['딥러닝', '지문', '생체정보', '2D 합성 곱 신경망', '상처 지문 판별', '주름 지문 판별', 'Deep learning', 'Biometric information', '2D Convolutional Neural Network', 'discriminating of scar fingerprint', 'discriminating of wrinkle fingerprint']","인간의 특성과 관련된 측정 항목을 나타내는 생체정보는 도난이나 분실의 염려가 없으므로 높은 신뢰성을 가진 보안 기술로서큰 주목을 받고 있다. 이러한 생체정보 중 지문은 본인 인증, 신원 파악 등의 분야에 주로 사용된다. 신원을 파악할 때 지문 이미지에인증을 수행하기 어려운 상처, 주름, 습기 등의 문제가 있을 경우, 지문 전문가가 전처리단계를 통해 직접 지문에 어떠한 문제가 있는지 파악하고 문제에 맞는 영상처리 알고리즘을 적용해 문제를 해결한다. 이때 지문에 상처와 주름이 있는 지문 영상을 판별해주는인공지능 소프트웨어를 구현하면 손쉽게 상처나 주름의 여부를 확인할 수 있고, 알맞은 알고리즘을 선정해 쉽게 지문 이미지를 개선할 수 있다. 본 연구에서는 이러한 인공지능 소프트웨어의 개발을 위해 캄보디아 왕립대학교의 학생 1,010명, Sokoto 오픈 데이터셋 600명, 국내 학생 98명의 모든 손가락 지문을 취득해 총 17,080개의 지문 데이터베이스를 구축했다. 구축한 데이터베이스에서 상처나 주름이 있는 경우를 판별하기 위해 기준을 확립하고 전문가의 검증을 거쳐 데이터 어노테이션을 진행했다. 트레이닝 데이터셋과테스트 데이터셋은 캄보디아의 데이터, Sokoto 데이터로 구성하였으며 비율을 8:2로 설정했다. 그리고 국내 학생 98명의 데이터를검증 데이터 셋으로 설정했다, 구성된 데이터셋을 사용해 Classic CNN, AlexNet, VGG-16, Resnet50, Yolo v3 등의 다섯 가지 CNN 기반아키텍처를 구현해 학습을 진행했으며 지문의 상처와 주름 판독에서 가장 좋은 성능을 보이는 모델을 찾는 연구를 수행했다. 다섯가지 아키텍처 중 지문 영상에서 상처와 주름 여부를 가장 잘 판별할 수 있는 아키텍처는 ResNet50으로 검증 결과 81.51%로 가장좋은 성능을 보였다.","Biometric information indicating measurement items related to human characteristics has attracted great attention as security technology with high reliability since there is no fear of theft or loss. Among these biometric information, fingerprints are mainly used in fields such as identity verification and identification. If there is a problem such as a wound, wrinkle, or moisture that is difficult to authenticate to the fingerprint image when identifying the identity, the fingerprint expert can identify the problem with the fingerprint directly through the preprocessing step, and apply the image processing algorithm appropriate to the problem. Solve the problem. In this case, by implementing artificial intelligence software that distinguishes fingerprint images with cuts and wrinkles on the fingerprint, it is easy to check whether there are cuts or wrinkles, and by selecting an appropriate algorithm, the fingerprint image can be easily improved. In this study, we developed a total of 17,080 fingerprint databases by acquiring all finger prints of 1,010 students from the Royal University of Cambodia, 600 Sokoto open data sets, and 98 Korean students. In order to determine if there are any injuries or wrinkles in the built database, criteria were established, and the data were validated by experts. The training and test datasets consisted of Cambodian data and Sokoto data, and the ratio was set to 8: 2. The data of 98 Korean students were set up as a validation data set. Using the constructed data set, five CNN-based architectures such as Classic CNN, AlexNet, VGG-16, Resnet50, and Yolo v3 were implemented. A study was conducted to find the model that performed best on the readings. Among the five architectures, ResNet50 showed the best performance with 81.51%."
시간 축 주의집중 기반 동물 울음소리 분류,2020,"['Audio event classification', 'Convolution Neural Network (CNN)', 'Self-attention', 'Gated Linear Unit (GLU)', '음향이벤트 인식', '합성 곱 신경망', '자가주의집중', '게이트 선형유닛']","본 논문에서는 조류와 양서류 울음소리의 구별 정확도를 높이기 위해 게이트 선형유닛과 자가주의 집중 모듈을 활용해서 데이터의 중요한 부분을 중심으로 특징 추출 및 데이터 프레임의 중요도를 판별해 구별 정확도를 높인다.이를 위해 먼저 1차원의 음향 데이터를 로그 멜 스펙트럼으로 변환한다. 로그 멜 스펙트럼에서 배경잡음같이 중요하지않은 정보는 게이트 선형유닛을 거쳐 제거한다. 그러고 난 뒤 시간 축에 자가주의집중기법을 적용해 구별 정확도를 높인다. 사용한 데이터는 자연환경에서 멸종위기종을 포함한 조류 6종의 울음소리와 양서류 8종의 울음소리로 구성했다. 그 결과, 게이트 선형유닛 알고리즘과 시간 축에서 자가주의집중을 적용한 구조의 평균 정확도는 조류를 구분했을때 91 %, 양서류를 구분했을 때 93 %의 분류율을 보였다. 또한, 기존 알고리즘보다 약 6 % ~ 7 % 향상된 정확도를보이는 것을 확인했다.","In this paper, to improve the classification accuracy of bird and amphibian acoustic sound, we utilize GLU (Gated Linear Unit) and Self-attention that encourages the network to extract important features from data and discriminate relevant important frames from all the input sequences for further performance improvement. To utilize acoustic data, we convert 1-D acoustic data to a log-Mel spectrogram. Subsequently, undesirable component such as background noise in the log-Mel spectrogram is reduced by GLU. Then, we employ the proposed temporal self-attention to improve classification accuracy. The data consist of 6-species of birds, 8-species of amphibians including endangered species in the natural environment. As a result, our proposed method is shown to achieve an accuracy of 91 % with bird data and 93 % with amphibian data. Overall, an improvement of about 6 % ~ 7 % accuracy in performance is achieved compared to the existing algorithms."
