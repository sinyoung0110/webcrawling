title,date,keywords,abstract,multilingual_abstract
SSD-Mobilenet과 ResNet을 이용한 모바일 기기용 자동차 번호판 인식시스템,2020,"['Vehicle License Plate Recognition', 'Deep Learning', 'SSD-Mobilenet', 'ResNet', '자동차 번호판 인식 시스템', '딥러닝', 'SSD-Mobilenet', 'ResNet']","본 논문은 고성능의 서버 없이 안드로이드 스마트폰 단독으로 동작할 수 있도록 경량화 딥러닝 모델을 사용하여 구현한 자동차 번호판 인식 시스템을 제안한다. 자동차 번호판 인식시스템은 [번호판검출]-[문자영역 분할]-[문자인식]으로 3단계의 과정으로 구성되며, 번호판검출은 SSD-Mobilenet, 문자영역 분할은 ResNet에 localization을 추가하여 사용하였고 문자인식은 ResNet을 이용하여 구현하였다. 테스트한 기기는 삼성 갤럭시 S7, LG Q9이며 정확도는 약 85.3%, 실행속도는 약 1.1초가 소요된다.","This paper proposes a vehicle license plate recognition system using light weight deep learning models without high-end server. The proposed license plate recognition system consists of 3 steps: [license plate detection]-[character area segmentation]-[character recognition]. SSD-Mobilenet was used for license plate detection, ResNet with localization was used for character area segmentation, ResNet was used for character recognition. Experiemnts using Samsung Galaxy S7 and LG Q9, accuracy showed 85.3% accuracy and around 1.1 second running time."
ResNet 알고리즘을 이용한 가로수 객체의 폐색영역 검출 및 해결,2020,"['3D Spatial Information', 'Occlusion Area', 'Street Tree', 'Deep Learning', 'ResNet Algorithm']","국토를 효율적으로 관리하고 도시문제를 과학적으로 해결하기 위해 최근 스마트시티, 디지털트윈 등 3차원 공간정보 관련 기술이 급격하게 발전하고 있다. 이러한 3차원 공간정보 구축은 주로 영상정보를 이용하여 객체를 3차원 입체화하고 실감형 영상인 텍스처링 영상을 추출하여 객체벽면에 영상을 부여하는 방식으로 수행된다. 하지만 객체 주변의 다양한 요인으로 인해 텍스처링 영상에서는 필연적으로 폐색영역이 발생한다. 이에 본 연구에서는 최근 기술인 딥러닝 기술 중에서 ResNet 알고리즘을 이용하여 건물 폐색을 유발하는 가로수에 대한 데이터셋을 만들고 이에 대한 해결방안을 제시하고자 한다. 연구결과 ResNet 알고리즘의 공간정보 적용 가능성을 판단하고 이를 적용한 레이블링 생성 SW 개발하여 실제 가로수를 대상으로 데이터셋을 구축하였다. 구축된 데이터셋을 텍스처링 영상에 적용하여 정확도와 재현율로 검출능력을 분석하였다. 분석결과를 위해 딥러닝 분야에서 많이 사용되고 있는 정밀도와 재현율을 이용한 F값을 적용하였으며 가로수 단일 객체가 포함된 건물의 측면부 영상과 경사 영상에 대해서는 높은 F값을 도출하여 우수한 성과를 확인하였으나, 같은 해상도를 가진 건물 전면부 영상에서는 그림자 등의 요인으로 F값이 낮음을 확인하였다.","The technologies of 3D spatial information, such as Smart City and Digital Twins, are developing rapidly for managing land and solving urban problems scientifically. In this construction of 3D spatial information, an object using aerial photo images is built as a digital DB. Realistically, the task of extracting a texturing image, which is an actual image of the object wall, and attaching an image to the object wall are important. On the other hand, occluded areas occur in the texturing image. In this study, the ResNet algorithm in deep learning technologies was tested to solve these problems. A dataset was constructed, and the street tree was detected using the ResNet algorithm. The ability of the ResNet algorithm to detect the street tree was dependent on the brightness of the image. The ResNet algorithm can detect the street tree in an image with side and inclination angles."
ResNet 모델을 이용한 일상생활 소리 예측 및 알림 애 플리케이션,2020,[],본 논문에서는 청각 장애인이 가정에서 듣지 못해 발생하는 낭비와 위험을 미리 예방하기 위하여 가정에서 현재 발생하고 있는 소리를 알려주는 시스템을 구현하였다. 무지향성 마이크로 일상 소리 감지 후 음향 데이터에서 Mel-Spectogram 특징 벡터를 추출하여 Convolutional Neural Network (CNN) 모델의 Resnet 알고리즘을 진행한다. 서버에서 소리에 대한 분석을 진행한 후 그 결과를 안드로이드에서 실시간으로 5 초마다 확인하여 사용자에게 알림 서비스를 제공한다. 이를 통해 낭비를 줄이고 위험에 대처할 수 있게 한다. 청각 장애인의 소리에 대한 접근성을 다양한 측면으로 고려해야 한다는 사회적 인식을 확산시키고자 한다.,다국어 초록 정보 없음
Crack detection based on ResNet with spatial attention,2020,"['crack detection', 'attention mechanism', 'deep convolution neural network']",국문 초록 정보 없음,"Deep Convolution neural network (DCNN) has been widely used in the healthy maintenance of civil infrastructure. Using DCNN to improve crack detection performance has attracted many researchers’ attention. In this paper, a light-weight spatial attention network module is proposed to strengthen the representation capability of ResNet and improve the crack detection performance. It utilizes attention mechanism to strengthen the interested objects in global receptive field of ResNet convolution layers. Global average spatial information over all channels are used to construct an attention scalar. The scalar is combined with adaptive weighted sigmoid function to activate the output of each channel’s feature maps. Salient objects in feature maps are refined by the attention scalar. The proposed spatial attention module is stacked in ResNet50 to detect crack. Experiments results show that the proposed module can got significant performance improvement in crack detection."
ResNet과 YOLOv3를 이용한 일상생활 속 휴대폰 검출 딥러닝 모델,2020,[],국문 초록 정보 없음,다국어 초록 정보 없음
Comparison of accuracy on Cifar-10 datasets according to depth of ResNet network,2020,"['ResNet', 'Deep neural network', 'Vanishing gradient', 'Overfitting', 'Cifar-10']",국문 초록 정보 없음,다국어 초록 정보 없음
폐색영역 학습데이터 셋 생성을 위한 ResNet 알고리즘과 VGG 알고리즘 비교 분석,2020,"['3차원 모델링', '텍스처링', 'ResNet', '학습데이터 셋']",국문 초록 정보 없음,다국어 초록 정보 없음
Classroom Roll-Call System Based on ResNet Networks,2020,"['Face Recognition', 'Game', 'ResNet Networks']",국문 초록 정보 없음,"A convolution neural networks (CNNs) has demonstrated outstanding performance compared to otheralgorithms in the field of face recognition. Regarding the over-fitting problem of CNN, researchers haveproposed a residual network to ease the training for recognition accuracy improvement. In this study, a novelface recognition model based on game theory for call-over in the classroom was proposed. In the proposedscheme, an image with multiple faces was used as input, and the residual network identified each face with aconfidence score to form a list of student identities. Face tracking of the same identity or low confidence weredetermined to be the optimisation objective, with the game participants set formed from the student identitylist. Game theory optimises the authentication strategy according to the confidence value and identity set toimprove recognition accuracy. We observed that there exists an optimal mapping relation between face andidentity to avoid multiple faces associated with one identity in the proposed scheme and that the proposedgame-based scheme can reduce the error rate, as compared to the existing schemes with deeper neural network."
An Experimental Comparison of CNN-based Deep Learning Algorithms for Recognition of Beauty-related Skin Disease,2020,"['Deep Learning', 'CNN', 'Beauty-related Skin Disease Recognition', 'Image Recognition', 'Algorithm Comparison', 'Experimental Comparison', '딥러닝', '피부미용 질환 인식', '이미지 인식', '알고리즘 비교', '실험적 비교']","본 논문에서는 딥러닝 지도학습 알고리즘을 사용한 학습 모델을 대상으로 미용 관련 피부질환 인식의 효과성을 실험적으로 비교한다. 최근 딥러닝 기술을 산업, 교육, 의료 등 다양한 분야에 적용하고 있으며, 의료 분야에서는 중요 피부질환 중 하나인 피부암 식별의 수준을 전문가 수준으로 높인 성과를 보이고 있다. 그러나 아직 피부미용과 관련된 질환에 적용한 사례가 다양하지 못하다. 따라서 딥러닝 기반 이미지 분류에 활용도가 높은 CNN 알고리즘을 비롯하여 ResNet, SE-ResNet을 적용하여 실험적으로 정확도를 비교함으로써 미용 관련 피부질환을 판단하는 효과성을 평가한다. 각 알고리즘을 적용한 학습 모델을 실험한 결과에서 CNN의 경우 평균 71.5%, ResNet은 평균 90.6%, SE-ResNet은 평균 95.3%의 정확도를 보였다. 특히 학습 깊이를 다르게하여 비교한 결과 50개의 계층 구조를 갖는 SE-ResNet-50 모델이 평균 96.2%의 정확도로 미용 관련 피부질환 식별을 위해 가장 효과적인 결과를 보였다. 본 논문의 목적은 피부 미용과 관련된 질환의 판별을 고려하여 효과적인 딥러닝 알고리즘의 학습과 방법을 연구하기 위한 것으로 이를 통해 미용 관련 피부질환 개선을 위한 서비스 개발로 확장할 수 있을 것이다.","In this paper, we empirically compare the effectiveness of training models to recognize beauty-related skin disease using supervised deep learning algorithms. Recently, deep learning algorithms are being actively applied for various fields such as industry, education, and medical. For instance, in the medical field, the ability to diagnose cutaneous cancer using deep learning based artificial intelligence has improved to the experts level. However, there are still insufficient cases applied to disease related to skin beauty. This study experimentally compares the effectiveness of identifying beauty-related skin disease by applying deep learning algorithms, considering CNN, ResNet, and SE-ResNet. The experimental results using these training models show that the accuracy of CNN is 71.5% on average, ResNet is 90.6% on average, and SE-ResNet is 95.3% on average. In particular, the SE-ResNet-50 model, which is a SE-ResNet algorithm with 50 hierarchical structures, showed the most effective result for identifying beauty-related skin diseases with an average accuracy of 96.2%. The purpose of this paper is to study effective training and methods of deep learning algorithms in consideration of the identification for beauty-related skin disease. Thus, it will be able to contribute to the development of services used to treat and easy the skin disease."
다양한 합성곱 신경망 방식을 이용한 모바일 기기를 위한 시작 단어 검출의 성능 비교,2020,"['성능 비교', '시작 단어 검출', '합성곱 신경망', '인공지능 비서', 'Performance comparison', 'Wake-up-word detection', 'Convolutional neural network', 'Artificial Intelligence (AI) assistant']","음성인식 기능을 제공하는 인공지능 비서들은 정확도가 뛰어난 클라우드 기반의 음성인식을 통해 동작한다.클라우드 기반의 음성인식에서 시작 단어 인식은 대기 중인 기기를 활성화하는 데 중요한 역할을 한다. 본 논문에서는공개 데이터셋인 구글의 Speech Commands 데이터셋을 사용하여 스펙트로그램 및 멜-주파수 캡스트럼 계수 특징을입력으로 하여 모바일 기기에 대응한 저 연산 시작 단어 검출을 위한 합성곱 신경망의 성능을 비교한다. 본 논문에서사용한 합성곱 신경망은 다층 퍼셉트론, 일반적인 합성곱 신경망, VGG16, VGG19, ResNet50, ResNet101, ResNet152, MobileNet이며, MobileNet의 성능을 유지하면서 모델 크기를 1/25로 줄인 네트워크도 제안한다.","Artificial intelligence assistants that provide speech recognition operate through cloud-based voice recognition with high accuracy. In cloud-based speech recognition, Wake-Up-Word (WUW) detection plays an important role in activating devices on standby. In this paper, we compare the performance of Convolutional Neural Network (CNN)-based WUW detection models for mobile devices by using Google's speech commands dataset, using the spectrogram and mel-frequency cepstral coefficient features as inputs. The CNN models used in this paper are multi-layer perceptron, general convolutional neural network, VGG16, VGG19, ResNet50, ResNet101, ResNet152, MobileNet. We also propose network that reduces the model size to 1/25 while maintaining the performance of MobileNet is also proposed."
조류 울음소리를 이용한 조류 분류 딥러닝 시스템 개발,2020,"['Deep learning', 'Classification', 'Spectrogram', 'AI', 'Convolutional Neural Networks', 'ResNet', 'AlexNet']",국문 초록 정보 없음,"The activity and distribution of wild birds are biological indicators to evaluate biodiversity. In order to identify bird habitats, collecting and classifying sounds should have to do. Using the bird sound can make easier to distinguish location or type of wild birds. Recently, attempts to analyze bioacoustic data have been risen using the machine learning. We are going to classify the bird songs using deep learning. The bird songs convert into the spectrogram images. Spectrogram images are used for the input of convolutional neural network. In generally the bird song data set for classification contains a lot of noise. Even obtaining the data including noise is difficult. The data is about 200 bird sounds of 20 species. Based on transfer learning, ResNet34, ResNet50 and AlexNet of Convolutional Neural Network are used as the experiment. The experiment parameter is learning rate and epochs. As a result, the ResNet34 shows the highest accuracy of 99.7% and an average of 93% in the test. Therefore, In this paper, we are going to develop the deep learning system that classifies 20 kinds of bird song using ResNet34. By using this system, it can be helpful various activities such as the prevention of avian influenza."
변형된 잔차블록을 적용한 CNN,2020,"['CNN', 'Residual Learning', 'Bottleneck', 'ResNet']",국문 초록 정보 없음,"This paper proposes an image classification algorithm that transforms the number of convolution layers in the residual block of ResNet, CNN's representative method. The proposed method modified the structure of 34/50 layer of ResNet structure. First, we analyzed the performance of small and many convolution layers for the structure consisting of only shortcut and 3 × 3 convolution layers for 34 and 50 layers.And then the performance was analyzed in the case of small and many cases of convolutional layers for the bottleneck structure of 50 layers. By applying the results, the best classification method in the residual block was applied to construct a 34-layer simple structure and a 50-layer bottleneck image classification model. To evaluate the performance of the proposed image classification model, the results were analyzed by applying to the cifar10 dataset. The proposed 34-layer simple structure and 50-layer bottleneck showed improved performance over the ResNet-110 and Densnet-40 models"
Weather Recognition Based on 3C-CNN,2020,"['Weather recognition', 'deep learning', 'ResNet50', '3C-CNN', 'WeatherDataset-6']",국문 초록 정보 없음,"Human activities are often affected by weather conditions. Automatic weather recognition is meaningful to traffic alerting, driving assistance, and intelligent traffic. With the boost of deep learning and AI, deep convolutional neural networks (CNN) are utilized to identify weather situations. In this paper, a three-channel convolutional neural network (3C-CNN) model is proposed on the basis of ResNet50.The model extracts global weather features from the whole image through the ResNet50 branch, and extracts the sky and ground features from the top and bottom regions by two CNN5 branches. Then the global features and the local features are merged by the Concat function. Finally, the weather image is classified by Softmax classifier and the identification result is output. In addition, a medium-scale dataset containing 6,185 outdoor weather images named WeatherDataset-6 is established. 3C-CNN is used to train and test both on the Two-class Weather Images and WeatherDataset-6. The experimental results show that 3C-CNN achieves best on both datasets, with the average recognition accuracy up to 94.35% and 95.81% respectively, which is superior to other classic convolutional neural networks such as AlexNet, VGG16, and ResNet50. It is prospected that our method can also work well for images taken at night with further improvement."
탄성파 층서 구분을 위한 합성곱 신경망 기법 비교 연구,2020,"['머신 러닝', '합성곱신경망', '탄성파층서구분', '인코더-디코더 모델', '네덜란드 F3 block', 'Machine learning', 'Convolutional neural network', 'Seismic sequence identification', 'Encoder–decoder model', 'Netherlands F3 block']","머신 러닝 기술은 탄성파탐사 분야로 그 적용 범위를 확장하고 있다. 탄성파 해석에서 중요한 탄성파 층서 구분에 머신 러닝의 적용 가능성을 알아보았다. 이미지 분야에 탁월한 결과를 보여온 합성곱 신경망 기법 중 4가지 모델을 네덜란드 F3 block에 적용시켰다. 4가지 모델은 ResNet34 모델, 인코더-디코더 형태를 가지는 U-Net, Residual U-Net, FD U-Net이다. 예측된 이미지의 정성적 분석 수행 후 정량적 분석을 위해 pixel accuracy, mean class accuracy, mean intersection over union, frequency weighted IU의 수식을 활용하였다. 본 연구의 분석 결과 ResNet34의 정확도 결과가 가장 낮았고, 인코더-디코더 형태를 가지는 모델들이 높은 정확도를 보여주었다. 그리고 계산에 필요한 파라미터수와 학습시간을 고려 할 때 U-Net이 가장 효율적임을 확인할 수 있었다.","Application of the machine learning technique is expanding to the field of seismic exploration. For the purpose of feasibility assessment, we applied the machine learning technique to seismic sequence identification, which is important in seismic interpretation.From among the convolutional neural network techniques used in image analysis, we applied four models to seismic data obtained in the F3 block, offshore Netherlands, which have yielded remarkable results. One of the four models was ResNet34. The others were encoder– decoder models: U-Net, Residual U-Net, and FD U-Net. We first performed a qualitative analysis of the predicted images and then conducted quantitative analysis using pixel accuracy, mean class accuracy, mean intersection over union, and frequency weighted IU equations. The numerical results showed that ResNet34 had the lowest accuracy and that the encoder–decoder type models had higher accuracy. Considering the number of parameters required for calculation and the learning time, we confirmed that U-Net is the most efficient model."
사전 학습된 네트워크 모델을 이용한 심전도 신호 기반 개인 식별 성능 분석,2020,"['electrocardiogram signal', 'deep learning', 'convolutional neural network', 'personal identification']",국문 초록 정보 없음,"The existing personal identification method has a problem that is vulnerable to various crimes, and researches using biosignals, which are internal characteristics of the body, are being conducted to compensate for this. Among them, ECG signals are unique to each person according to the size and location of the heart, which makes them suitable for personal identification, and many studies are being conducted in conjunction with deep learning. In this paper, we analyze the performance of personal identification according to the pre-trained network model using 2-D ECG images. The pre-trained network model for training ECG data sets uses 11 networks of Inception and ResNet. The training data of the network uses 2-D image data using one period of the ECG signal, and the experiment is performed by changing the number of learning. Inception-ResNet-V2 is the highest in the Inception network with 96.18% performance, ResNet-V2-152 is the highest in the ResNet network with 99.12% performance."
상처와 주름이 있는 지문 판별에 효율적인 심층 학습 비교연구,2020,"['딥러닝', '지문', '생체정보', '2D 합성 곱 신경망', '상처 지문 판별', '주름 지문 판별', 'Deep learning', 'Biometric information', '2D Convolutional Neural Network', 'discriminating of scar fingerprint', 'discriminating of wrinkle fingerprint']","인간의 특성과 관련된 측정 항목을 나타내는 생체정보는 도난이나 분실의 염려가 없으므로 높은 신뢰성을 가진 보안 기술로서큰 주목을 받고 있다. 이러한 생체정보 중 지문은 본인 인증, 신원 파악 등의 분야에 주로 사용된다. 신원을 파악할 때 지문 이미지에인증을 수행하기 어려운 상처, 주름, 습기 등의 문제가 있을 경우, 지문 전문가가 전처리단계를 통해 직접 지문에 어떠한 문제가 있는지 파악하고 문제에 맞는 영상처리 알고리즘을 적용해 문제를 해결한다. 이때 지문에 상처와 주름이 있는 지문 영상을 판별해주는인공지능 소프트웨어를 구현하면 손쉽게 상처나 주름의 여부를 확인할 수 있고, 알맞은 알고리즘을 선정해 쉽게 지문 이미지를 개선할 수 있다. 본 연구에서는 이러한 인공지능 소프트웨어의 개발을 위해 캄보디아 왕립대학교의 학생 1,010명, Sokoto 오픈 데이터셋 600명, 국내 학생 98명의 모든 손가락 지문을 취득해 총 17,080개의 지문 데이터베이스를 구축했다. 구축한 데이터베이스에서 상처나 주름이 있는 경우를 판별하기 위해 기준을 확립하고 전문가의 검증을 거쳐 데이터 어노테이션을 진행했다. 트레이닝 데이터셋과테스트 데이터셋은 캄보디아의 데이터, Sokoto 데이터로 구성하였으며 비율을 8:2로 설정했다. 그리고 국내 학생 98명의 데이터를검증 데이터 셋으로 설정했다, 구성된 데이터셋을 사용해 Classic CNN, AlexNet, VGG-16, Resnet50, Yolo v3 등의 다섯 가지 CNN 기반아키텍처를 구현해 학습을 진행했으며 지문의 상처와 주름 판독에서 가장 좋은 성능을 보이는 모델을 찾는 연구를 수행했다. 다섯가지 아키텍처 중 지문 영상에서 상처와 주름 여부를 가장 잘 판별할 수 있는 아키텍처는 ResNet50으로 검증 결과 81.51%로 가장좋은 성능을 보였다.","Biometric information indicating measurement items related to human characteristics has attracted great attention as security technology with high reliability since there is no fear of theft or loss. Among these biometric information, fingerprints are mainly used in fields such as identity verification and identification. If there is a problem such as a wound, wrinkle, or moisture that is difficult to authenticate to the fingerprint image when identifying the identity, the fingerprint expert can identify the problem with the fingerprint directly through the preprocessing step, and apply the image processing algorithm appropriate to the problem. Solve the problem. In this case, by implementing artificial intelligence software that distinguishes fingerprint images with cuts and wrinkles on the fingerprint, it is easy to check whether there are cuts or wrinkles, and by selecting an appropriate algorithm, the fingerprint image can be easily improved. In this study, we developed a total of 17,080 fingerprint databases by acquiring all finger prints of 1,010 students from the Royal University of Cambodia, 600 Sokoto open data sets, and 98 Korean students. In order to determine if there are any injuries or wrinkles in the built database, criteria were established, and the data were validated by experts. The training and test datasets consisted of Cambodian data and Sokoto data, and the ratio was set to 8: 2. The data of 98 Korean students were set up as a validation data set. Using the constructed data set, five CNN-based architectures such as Classic CNN, AlexNet, VGG-16, Resnet50, and Yolo v3 were implemented. A study was conducted to find the model that performed best on the readings. Among the five architectures, ResNet50 showed the best performance with 81.51%."
콘크리트 균열 탐지를 위한 딥 러닝 기반 CNN 모델 비교,2020,"['균열 탐지', 'ILSVRC', '딥 러닝', 'CNN', '전이 학습', 'Crack Detection', 'Deep Learning', 'Transfer Learning']",국문 초록 정보 없음,"The purpose of this study is to compare the models of Deep Learning-based Convolution Neural Network(CNN) for concrete crack detection. The comparison models are AlexNet, GoogLeNet, VGG16, VGG19, ResNet-18, ResNet-50, ResNet-101, and SqueezeNet which won ImageNet Large Scale Visual Recognition Challenge(ILSVRC). To train, validate and test these models, we constructed 3000 training data and 12000 validation data with 256×256 pixel resolution consisting of cracked and non-cracked images, and constructed 5 test data with 4160×3120 pixel resolution consisting of concrete images with crack. In order to increase the efficiency of the training, transfer learning was performed by taking the weight from the pre-trained network supported by MATLAB. From the trained network, the validation data is classified into crack image and non-crack image, yielding True Positive (TP), True Negative (TN), False Positive (FP), False Negative (FN), and 6 performance indicators, False Negative Rate (FNR), False Positive Rate (FPR), Error Rate, Recall, Precision, Accuracy were calculated. The test image was scanned twice with a sliding window of 256×256 pixel resolution to classify the cracks, resulting in a crack map. From the comparison of the performance indicators and the crack map, it was concluded that VGG16 and VGG19 were the most suitable for detecting concrete cracks."
딥러닝 알고리즘을 이용한 토마토에서 발생하는 여러가지 병해충의 탐지와 식별에 대한 웹응용 플렛폼의 구축,2020,"['Agricultural Tomato Images', 'Plant Diseases and Pests', 'Deep Learning Algorithm', 'Faster R-CNN', 'Convolution Neural Network', 'Web Application Platform']",국문 초록 정보 없음,"Purpose: purpose of this study was to propose the web application platform which can be to detect and discriminate various diseases and pest of tomato plant based on the large amount of disease image data observed in the facility or the open field.Methods: The deep learning algorithms uesed at the web applivation platform are consisted as the combining form of Faster R-CNN with the pre-trained convolution neural network (CNN) models such as SSD_mobilenet v1, Inception v2, Resnet50 and Resnet101 models. To evaluate the superiority of the newly proposed web application platform, we collected 850 images of four diseases such as Bacterial cankers, Late blight, Leaf miners, and Powdery mildew that occur the most frequent in tomato plants. Of these, 750 were used to learn the algorithm, and the remaining 100 images were used to evaluate the algorithm.Results: From the experiments, the deep learning algorithm combining Faster R-CNN with SSD_mobilnet v1, Inception v2, Resnet50, and Restnet101 showed detection accuracy of 31.0%, 87.7%, 84.4%, and 90.8% respectively. Finally, we constructed a web application platform that can detect and discriminate various tomato deseases using best deep learning algorithm. If farmers uploaded image captured by their digital cameras such as smart phone camera or DSLR (Digital Single Lens Reflex) camera, then they can receive an information for detection, identification and disease control about captured tomato disease through the proposed web application platform.Conclusion: Incheon Port needs to act actively paying"
내시경의 위암과 위궤양 영상을 이용한 합성곱 신경망 기반의 자동 분류 모델,2020,"['Gastroscopy', 'Classification', 'ResNet-50', 'Gastric ulcer', 'Gastric cancer']",국문 초록 정보 없음,"Although benign gastric ulcers do not develop into gastric cancer, they are similar to early gastric cancer and difficult to distinguish. This may lead to misconsider early gastric cancer as gastric ulcer while diagnosing. Since gastric cancer does not have any special symptoms until discovered, it is important to detect gastric ulcers by early gastroscopy to prevent the gastric cancer. Therefore, we developed a Convolution Neural Network (CNN) model that can be helpful for endoscopy. 3,015 images of gastroscopy of patients undergoing endoscopy at Gachon University Gil Hospital were used in this study. Using ResNet-50, three models were developed to classify normal and gastric ulcers, normal and gastric cancer, and gastric ulcer and gastric cancer. We applied the data augmentation technique to increase the number of training data and examined the effect on accuracy by varying the multiples. The accuracy of each model with the highest performance are as follows. The accuracy of normal and gastric ulcer classification model was 95.11% when the data were increased 15 times, the accuracy of normal and gastric cancer classification model was 98.28% when 15 times increased likewise, and 5 times increased data in gastric ulcer and gastric cancer classification model yielded 87.89%. We will collect additional specific shape of gastric ulcer and cancer data and will apply various image processing techniques for visual enhancement. Models that classify normal and lesion, which showed relatively high accuracy, will be re-learned through optimal parameter search."
딥러닝을 활용한 실내 식물 이미지 분류 및 식물 정보 제공 웹 어플리케이션,2020,"['Indoor plant information', 'Deep learning', 'Transfer learning', 'ResNet', 'Fast.ai']",국문 초록 정보 없음,"Plants have good effects such as air purification and landscaping, but they have special ingredients to protect themselves. Ingredients made to protect the plant itself can harm people or animals. There are also accidents that are mistaken for other plants with similar plant features. We have implemented a program that can identify plants and display information about each plant. Using deep learning to classify images, we created a web application that predicts plant names and displays information that matches the predicted plants. We created a data set of 61 indoor plants using Google Image Search. The positive effects and negative toxicity of indoor plants are summarized in the database. Deep learning is implemented using fast.ai, a Pytorch-based framework. Through data Augmentation, we increased the number of images to learn. Indoor plant image data were trained using ResNet50, a pretrained model using various images. The accuracy of the model was about 97.5%, which predicted most plants accurately. The web application was implemented using flask, a Python-based web framework. Using the implemented image classification deep learning model, the plant name is predicted and the information corresponding to the predicted plant name is displayed on the web page. The web application can be optimized for mobile devices and used conveniently."
Masked cross self-attentive encoding based speaker embedding for speaker verification,2020,"['Speaker verification', '화자검증', 'Masked cross self-attentive encoding', 'Speaker embedding', 'ResNet', '마스킹된 교차 자기주의 인코딩', '화자 임베딩', '잔차 네트워크']",국문 초록 정보 없음,"Constructing speaker embeddings in speaker verification is an important issue. In general, a self-attention mechanism has been applied for speaker embedding encoding. Previous studies focused on training the self-attention in a high-level layer, such as the last pooling layer. In this case, the effect of low-level layers is not well represented in the speaker embedding encoding. In this study, we propose Masked Cross Self-Attentive Encoding (MCSAE) using ResNet. It focuses on training the features of both high-level and low-level layers.Based on multi-layer aggregation, the output features of each residual layer are used for the MCSAE. In the MCSAE, the interdependence of each input features is trained by cross self-attention module. A random masking regularization module is also applied to prevent overfitting problem. The MCSAE enhances the weight of frames representing the speaker information. Then, the output features are concatenated and encoded in the speaker embedding. Therefore, a more informative speaker embedding is encoded by using the MCSAE. The experimental results showed an equal error rate of 2.63 % using the VoxCeleb1 evaluation dataset. It improved performance compared with the previous self-attentive encoding and state-of-the-art methods."
Vision-based Object Classification using Deep Learning for Inventory Tracking in Automated Warehouse Environment,2020,"['Computer Vision', 'Deep Learning', 'Convolutional Neural Networks', 'Object Classification', 'ResNet-50', 'Warehouse Automation']",국문 초록 정보 없음,"To achieve automatic inventory management in warehouses, it is necessary to identify items. Barcodes and RFID tags are traditional approaches to solve this problem but both of them suffer from limitations. This research paper presents a vision-based method using a deep convolutional neural network to classify different items stored in a warehouse for the purpose of inventory management. The proposed method uses residual learning and employs ResNet-50 network architecture. It achieves a high accuracy of 98.94% on the dataset created by the authors consisting of 1450+ images of machine parts, by utilizing data augmentation and transfer learning. It runs at 4 frames per second (FPS), making it suitable for other real-time applications as well."
딥러닝 기반 소나무 재선충 피해목 탐색,2020,"['소나무 재선충', '드론', 'RGB 정사영상', '딥러닝 분류기', 'pine wilt disease', 'unmanned aviation vehicle', 'RGB ortho-image', 'deep learning-based classifier', 'heat map']","소나무 재선충은 한국과 일본, 중국을 포함한 동아시아 지역의 소나무산림에 막대한 피해를 주는 원인이며, 피해목의 조기 발견과 제거는 재선충 확산을 막는 효과적인 방법이다. 본 논문에서는 드론으로 촬영되고 처리된 RGB 정사영상을 딥러닝 분류에 의한 재선충 피해목 탐색방법을 제안한다. 제안된 방법은 학습영상 데이터가 많지 않다는 가정아래 ResNet18을 백본으로 하는 패치기반의 분류기를 구성하고 RGB 정사영상을 분류하고 그 결과를 heatmap 형태로 만든다. 제작된 정사영상의 heat map는 재선충 피해목의 분포를 알아내고 확산해가는 모습을 관찰할 수 있게 하며, 재선충 피해목 지역의 RGB 분포 특징을 추출해낼 수도 있다. 본 연구의 패치기반 분류기 성능은 94.7%의 정확도를 나타내었다.","Pine wilt disease is one of the reasons that results in huge damage on pine trees in east Asia including Korea, Japan, and China, and early finding and removing the diseased trees is an efficient way to prevent the forest from wide spreading. This paper proposes a searching method of the damaged pine trees from wilt disease in ortho-images corrected from RGB images, which are captured by unmanned aviation vehicles. The proposed method constructs patch-based classifier using ResNet18 backbone network, classifies the RGB ortho-image patches, and make the results as a heat map. The heat map can be used to find the distribution of diseased pine trees, to show the trend of spreading disease, and to extract the RGB distribution of the diseased areas in the image. The classifier in the work shows 94.7% of accuracy."
딥러닝 기반 지하공동구 화재 탐지 모델 개발 : 학습데이터 보강 및 편향 최적화,2020,"['Underground Utility Facility', 'Fire Detection', 'Deep Learning', 'Convolutional Neural Network', 'Bias Training']","화재는 높은 비정형성으로 인해 딥러닝 모델을 이용한 영상인식 분야에서도 좋은 성능을 내기가 어려운 대상 중 하나이다. 특히 지하공동구 내 화재는 딥러닝 모델의 학습을 위한 화재 데이터 확보가 어렵고 열약한 영상 조건 및 화재로 오인할 수 있는 객체가 많아 화재 검출이 어렵고 성능이 낮다. 이러한 이유로 본 연구는 딥러닝 기반의 지하공동구 내 화재 탐지 모델을 제안하고, 제안된 모델의 성능을 평가하였다. 기존 합성곱 인공신경망에 GoogleNet의 Inception block과 ResNet의 skip connection을 조합하여 어두운 환경에서 발생되는 화재 탐지를 위한 모델 구조를 제안하였으며, 제안된 모델을 효과적으로 학습시키기 위한 방법도 함께 제시하였다. 제안된 방법의 효과를 평가하기 위해 학습 후 모델을 지하공동구 및 유사환경 조건의 화재 문제와 화재로 오인할 수 있는 객체를 포함한 이미지에 적용해 결과를 분석하였다. 또한 기존 딥러닝 기반 화재 탐지 모델의 정밀도, 검출률 지표와 비교함으로써 모델의 화재 탐지성능을 정량적으로 평가하였다. 제안된 모델의 결과는 어두운 환경에서 발생되는 화재 문제에 대해 높은 정밀도와 검출률을 나타내었으며, 유사 화재 객체에 대해 낮은 오탐 및 미탐 성능을 가지고 있음을 보여주었다.","Fire is difficult to achieve good performance in image detection using deep learning because of its high irregularity. In particular, there is little data on fire detection in underground utility facilities, which have poor light conditions and many objects similar to fire. These make fire detection challenging and cause low performance of deep learning models. Therefore, this study proposed a fire detection model using deep learning and estimated the performance of the model. The proposed model was designed using a combination of a basic convolutional neural network, Inception block of GoogleNet, and Skip connection of ResNet to optimize the deep learning model for fire detection under underground utility facilities. In addition, a training technique for the model was proposed. To examine the effectiveness of the method, the trained model was applied to fire images, which included fire and non-fire (which can be misunderstood as a fire) objects under the underground facilities or similar conditions, and results were analyzed. Metrics, such as precision and recall from deep learning models of other studies, were compared with those of the proposed model to estimate the model performance qualitatively. The results showed that the proposed model has high precision and recall for fire detection under low light intensity and both low erroneous and missing detection capabilities for things similar to fire."
Inter-Layer Kernel Prediction: 프레임 간 Prediction에 기반한 컨볼루션 신경망 가중치 공유 및 모델 압축 방법,2020,[],본 논문에서는 최근 대두되고 있는 심층신경망 압축 연구에서 가중치 공유와 관련하여 심층신경망 모델 압축방법 Inter-Layer Kernel Prediction을 제안한다. 제안 방법은 영상 압축에서 사용되는 프레임 간 prediction 방법을 응용한 컨볼루션 신경망 가중치 공유 및 모델 압축 방법이다. 본 논문은 레이어 간 유사한 kernel들이 존재한다는 것을 발견하고 이를 기반으로 Inter-Layer Kernel Prediction을 사용하여 기존 모델 가중치를 보다 더 적은 비트로 표현하여 저장하는 방법을 제안한다. 제안 방법은 CIFAR10/100으로 학습된 ResNet에서 약 4.1 배의 압축률을 달성했으며 CIFAR10으로 학습된 ResNet110에서는 오히려 기존 Baseline 모델에 비해 0.04%의 성능 향상을 기록했다.,다국어 초록 정보 없음
템플릿 재사용을 통한 패러미터 효율적 신경망 네트워크,2020,"['Neural Network', 'Parameter Sharing', 'Layer Reuse', 'Parameter Efficiency', '신경망', '패러미터 공유', '레이어 재사용', '패러미터 효율']","최근 심층 신경망 (Deep Neural Networks, DNNs)는 모바일 및 임베디드 디바이스에 인간과 유사한 수준의 인공지능을 제공해 많은 응용에서 혁명을 가져왔다. 하지만, 이러한 DNN의 높은 추론 정확도는 큰 연산량을 요구하며, 따라서 기존의 사용되던 모델을 압축하거나 리소스가 제한적인 디바이스를 위해 작은 풋프린트를 가진 새로운 DNN 구조를 만드는 방법으로 DNN의 연산 오버헤드를 줄이기 위한 많은 노력들이 있어왔다. 이들 중 최근 작은 메모리 풋프린트를 갖는 모델 설계에서 주목받는 기법중 하나는 레이어 간에 패러미터를 공유하는 것이다. 하지만, 기존의 패러미터 공유 기법들은 ResNet과 같이 패러미터에 중복(redundancy)이 높은 것으로 알려진 깊은 심층 신경망에 적용되어왔다. 본 논문은 ShuffleNetV2와 같이 이미 패러미터 사용에 효율적인 구조를 갖는 소형 신경망에 적용할 수 있는 패러미터 공유 방법을 제안한다. 본 논문에서 제안하는 방법은 작은 크기의 템플릿과 레이어에 고유한 작은 패러미터를 결합하여 가중치를 생성한다. ImageNet과 CIFAR-100 데이터셋에 대한 우리의 실험 결과는 ShuffleNetV2의 패러미터를 15%-35% 감소시키면서도 기존의 패러미터 공유 방법과 pruning 방법에 대비 작은 정확도 감소만이 발생한다. 또한 우리는 제안된 방법이 최근의 임베디드 디바이스상에서 응답속도 및 에너지 소모량 측면에서 효율적임을 보여준다.","Recently, deep neural networks (DNNs) have brought revolutions to many mobile and embedded devices by providing human-level machine intelligence for various applications. However, high inference accuracy of such DNNs comes at high computational costs, and, hence, there have been significant efforts to reduce computational overheads of DNNs either by compressing off-the-shelf models or by designing a new small footprint DNN architecture tailored to resource constrained devices. One notable recent paradigm in designing small footprint DNN models is sharing parameters in several layers. However, in previous approaches, the parameter-sharing techniques have been applied to large deep networks, such as ResNet, that are known to have high redundancy. In this paper, we propose a parameter-sharing method for already parameter-efficient small networks such as ShuffleNetV2. In our approach, small templates are combined with small layer-specific parameters to generate weights. Our experiment results on ImageNet and CIFAR100 datasets show that our approach can reduce the size of parameters by 15%-35% of ShuffleNetV2 while achieving smaller drops in accuracies compared to previous parameter-sharing and pruning approaches. We further show that the proposed approach is efficient in terms of latency and energy consumption on modern embedded devices."
심층신경망의 더블 프루닝 기법의 적용 및 성능 분석에 관한 연구,2020,"['Model Compression', 'Model Light Weight', 'Deep Learning', 'Pruning', 'Network-Slimming', '모델압축', '모델 경량화', '딥러닝', '프루닝', '네트워크 간소화']","최근 인공지능 딥러닝 분야는 컴퓨팅 자원의 높은 연산량과 가격문제로 인해 상용화에 어려움이 존재했다. 본 논문은 더블 프루닝 기법을 적용하여 심층신경망 모델들과 다수의 데이터셋에서의 성능을 평가하고자 한다. 더블 프루닝은 기본의 네트워크 간소화(Network-Slimming)과 파라미터 프루닝(Parameter-Pruning)을 결합한다. 이는 기존의 학습에 중요하지 않는 매개변수를 절감하여 학습 정확도를 저해하지 않고 속도를 향상시킬 수 있다는 장점이 있다. 다양한 데이터셋 학습 이후에 프루닝 비율을 증가시켜, 모델의 사이즈를 감소시켰다. NetScore 성능 분석 결과 MobileNet-V3가 가장 성능이 높게 나타났다. 프루닝 이후의 성능은 Cifar 10 데이터셋에서 깊이 우선 합성곱 신경망으로 구성된 MobileNet-V3이 가장 성능이 높았고, 전통적인 합성곱 신경망으로 이루어진 VGGNet, ResNet또한 높은 폭으로 성능이 증가함을 확인하였다.","Recently, the artificial intelligence deep learning field has been hard to commercialize due to the high computing power and the price problem of computing resources. In this paper, we apply a double pruning techniques to evaluate the performance of the in-depth neural network and various datasets. Double pruning combines basic Network-slimming and Parameter-prunning. Our proposed technique has the advantage of reducing the parameters that are not important to the existing learning and improving the speed without compromising the learning accuracy. After training various datasets, the pruning ratio was increased to reduce the size of the model.We confirmed that MobileNet-V3 showed the highest performance as a result of NetScore performance analysis. We confirmed that the performance after pruning was the highest in MobileNet-V3 consisting of depthwise seperable convolution neural networks in the Cifar 10 dataset, and VGGNet and ResNet in traditional convolutional neural networks also increased significantly."
HS 코드 분류를 위한 CNN 기반의 추천 모델 개발,2020,['HS'],국문 초록 정보 없음,"The current tariff return system requires tax officials to calculate tax amount by themselves and pay the tax amount on their own responsibility. In other words, in principle, the duty and responsibility of reporting payment system are imposed only on the taxee who is required to calculate and pay the tax accurately. In case the tax payment system fails to fulfill the duty and responsibility, the additional tax is imposed on the taxee by collecting the tax shortfall and imposing the tax deduction on For this reason, item classifications, together with tariff assessments, are the most difficult and could pose a significant risk to entities if they are misclassified. For this reason, import reports are consigned to customs officials, who are customs experts, while paying a substantial fee. The purpose of this study is to classify HS items to be reported upon import declaration and to indicate HS codes to be recorded on import declaration. HS items were classified using the attached image in the case of item classification based on the case of the classification of items by the Korea Customs Service for classification of HS items. For image classification, CNN was used as a deep learning algorithm commonly used for image recognition and Vgg16, Vgg19, ResNet50 and Inception-V3 models were used among CNN models. To improve classification accuracy, two datasets were created. Dataset1 selected five types with the most HS code images, and Dataset2 was tested by dividing them into five types with 87 Chapter, the most among HS code 2 units. The classification accuracy was highest when HS item classification was performed by learning with dual database2, the corresponding model was Inception-V3, and the ResNet50 had the lowest classification accuracy. The study identified the possibility of HS item classification based on the first item image registered in the item classification determination case, and the second point of this study is that HS item classification, which has not been attempted before, was attempted through the CNN model."
수피 특징 추출을 위한 상용 DCNN 모델의 비교와 다층 퍼셉트론을 이용한 수종 인식,2020,"['Tree Species Identification', 'ResNet50', 'DCNN', 'MLP']",국문 초록 정보 없음,다국어 초록 정보 없음
전이학습을 활용한 매실 병충해 진단 어플리케이션 개발,2020,[],"매실의 병충해 이미지를 Tensorflow hub에서 제공하는 Resnet50모델에 Transfer Learning기법을 이용하여 학습시키고, 학습된 모델을 Flask를 이용하여 연동시킨다. 이렇게 완성된 웹앱은 사용자가 매실의 이미지를 업로드 하면, 어떤 병충해를 가지고 있는 지 알려주며, 사용자는 얻은 결과를 통해 육안으로 구분하기 어려운 병충해의 정보를 얻어 매실이 손상이 가는 것을 예방할 수 있다.",다국어 초록 정보 없음
엣지 디바이스 기반의 자세추정에 따른 데이터 입출력 인터페이스 개발,2020,"['Edge Device', 'PoseNet', 'Mobius server', 'MobileNet v1', 'Resnet50']",국문 초록 정보 없음,다국어 초록 정보 없음
Guided Grad-CAM 을 이용한 영상 내 송전설비 검출기법,2020,[],"본 논문에서 육안으로도 구별하기 힘든 송전선과 같은 객체가 포함된 송전설비를 효과적으로 검출하는 방법을 제안한다. 객체 인식 모델에 송전탑 데이터 셋을 학습시켜 송전설비 Region of Interest(ROI)를 추출한다. 송전선 데이터 셋을 ResNet50 에 학습하고, 추출된 ROI 영상을 Guided Grad-CAM 을 출력한다. 추출된 Guided Grad-CAM 에 노이즈 제거 후처리를 적용하여 송전설비를 추출한다. 본 논문에서 제안된 기법을 적용할 경우 드론 또는 UAV 헬기 등에서 촬영된 영상으로 송전설비 유지보수가 가능하다.",다국어 초록 정보 없음
YOLO 네트워크를 활용한 전이학습 기반 객체 탐지 알고리즘,2020,"['Object Detection', 'Transfer Learning', 'Deep Learning', 'Image Processing']",국문 초록 정보 없음,"To guarantee AI model's prominent recognition rate and recognition precision, obtaining the large number of data is essential. In this paper, we propose transfer learning-based object detection algorithm for maintaining outstanding performance even when the volume of training data is small. Also, we proposed a tranfer learning network combining Resnet-50 and YOLO(You Only Look Once) network. The transfer learning network uses the Leeds Sports Pose dataset to train the network that detects the person who occupies the largest part of each images. Simulation results yield to detection rate as 84% and detection precision as 97%."
합성곱 신경망을 이용한 동결절편의 암세포 전이 여부 자동진단에 관한 예비연구,2020,[],"동결절편검사는 수술과 연계하여 암전이 여부를 판단하기 위한 응급한 병리검사가 필요할 때 이용된다. 합성곱 신경망은 이미지 분류에 뛰어난 성능을 보이는 딥러닝 기법으로 본 논문에서는 이를 이용하여 유방암 전이 여부를 자동적으로 진단하는 방법을 제안한다. 실험과정은 전처리, 학습, 후처리의 과정으로 구성되어 있으며, 합성곱 신경망으로는 Resnet-18 모델을 사용하였다. 실험 결과 예측 정확도 및 종양의 최대 길이 정합 여부를 점수로 환산하여 약 0.514 의 결과를 보였다.",다국어 초록 정보 없음
핵의학 감마카메라 정도관리의 딥러닝 적용,2020,"['핵의학', '정도관리', '인공지능', '콘볼루션 신경망', '딥러닝', 'Nuclear medicine', 'Quality Control', 'AI', 'CNN', 'Deep Learning']",국문 초록 정보 없음,"In the field of nuclear medicine, errors are sometimes generated because the assessment of the uniformity of gamma cameras relies on the naked eye of the evaluator. To minimize these errors, we created an artificial intelligence model based on CNN algorithm and wanted to assess its usefulness. We produced 20,000 normal images and partial cold region images using Python, and conducted artificial intelligence training with Resnet18 models. The training results showed that accuracy, specificity and sensitivity were 95.01%, 92.30%, and 97.73%, respectively. According to the results of the evaluation of the confusion matrix of artificial intelligence and expert groups, artificial intelligence was accuracy, specificity and sensitivity of 94.00%, 91.50%, and 96.80%, respectively, and expert groups was accuracy, specificity and sensitivity of 69.00%, 64.00%, and 74.00%, respectively. The results showed that artificial intelligence was better than expert groups. In addition, by checking together with the radiological technologist and AI, errors that may occur during the quality control process can be reduced, providing a better examination environment for patients, providing convenience to radiologists, and improving work efficiency."
향상된 비트 평면 분할을 통한 다중 학습 통합 신경망 구축,2020,[],"본 논문에서는 직전 연구였던 비트 평면 분할과 디더링을 통한 다중 학습 통합 신경망 구축에서의 한계점을 분석하고, 향상시킨 방법을 제시한다. 통합 신경망을 구축하는 방법에 대해 최근까지 시도되었던 방법들은 신경망을 구성하는 가중치(weight)나 층(layer)를 공유하거나 태스크 별로 구분하는 것들이 있다. 이와 같은 선상에서 본 연구는 더 작은 단위인 가중치의 비트 평면을 태스크 별로 할당하여 보다 효율적인 통합 신경망을 구축한다. 실험은 이미지 분류 문제에 대해 수행하였다. 대중적인 신경망 구조인 ResNet18 에 대해 적용한 결과 데이터셋 CIFAR10 과 CIFAR100 에서 이론적인 압축률 50%를 달성하면서 성능 저하가 거의 발견되지 않았다.",다국어 초록 정보 없음
손목 관절 단순 방사선 영상에서 딥 러닝을 이용한 전후방 및 측면 영상 분류와 요골 영역 분할,2020,"['Distal radius fractures', 'Deep learning', 'Classification', 'Segmentation', 'X-rays']",국문 초록 정보 없음,"The purpose of this study was to present the models for classifying the wrist X-ray images by types and for segmenting the radius automatically in each image using deep learning and to verify the learned models. The data were a total of 904 wrist X-rays with the distal radius fracture, consisting of 472 anteroposterior (AP) and 432 lateral images. The learning model was the ResNet50 model for AP/lateral image classification, and the U-Net model for segmentation of the radius. In the model for AP/lateral image classification, 100.0% was showed in precision, recall, and F1 score and area under curve (AUC) was 1.0. The model for segmentation of the radius showed an accuracy of 99.46%, a sensitivity of 89.68%, a specificity of 99.72%, and a Dice similarity coefficient of 90.05% in AP images and an accuracy of 99.37%, a sensitivity of 88.65%, a specificity of 99.69%, and a Dice similarity coefficient of 86.05% in lateral images. The model for AP/lateral classification and the segmentation model of the radius learned through deep learning showed favorable performances to expect clinical application."
코로나바이러스 감염증19 데이터베이스에 기반을 둔 인공신경망 모델의 특성 평가,2020,"['알렉스넷', '흉부 방사선검사', '코로나바이러스감염증19', '심층학습', '인공신경망', 'AlexNet', 'Chest Radiography(CXR)', 'COVID-19', 'Deep-learning', 'Neural network']",국문 초록 정보 없음,"Coronavirus disease(COVID-19) is highly infectious disease that directly affects the lungs. To observe the clinical findings from these lungs, the Chest Radiography(CXR) can be used in a fast manner. However, the diagnostic performance via CXR needs to be improved, since the identifying these findings are highly time-consuming and prone to human error. Therefore, Artificial Intelligence(AI) based tool may be useful to aid the diagnosis of COVID-19 via CXR. In this study, we explored various Deep learning(DL) approach to classify COVID-19, other viral pneumonia and normal. For the original dataset and lung-segmented dataset, the pre-trained AlexNet, SqueezeNet, ResNet18, DenseNet201 were transfer- trained and validated for 3 class - COVID-19, viral pneumonia, normal. In the results, AlexNet showed the highest mean accuracy of 99.15±2.69% and fastest training time of 1.61±0.56 min among 4 pre-trained neural networks. In this study, we demonstrated the performance of 4 pre-trained neural networks in COVID-19 diagnosis with CXR images. Further, we plotted the class activation map(CAM) of each network and demonstrated that the lung-segmentation pre-processing improve the performance of COVID-19 classifier with CXR images by excluding background features."
Assessment of Diagnostic Value for Femoral Neck Fracture Using Deep Neural Network Trained with Pelvic X-ray Films,2020,"['femoral neck fracture', 'deep learning', 'machine learning', 'convolutional neural network']","Introduction대퇴 경부 골절은 노인에서 흔한 골절로 X-ray를 통한 대퇴 경부 골절 진단의 민감도는 90 ~ 98%로 알려져 있다. 대퇴경부 골절의 진단이 늦어지게 되면 환자의 합병증 발생과 사망률은 수상 후 시간이 지남에 따라 증가한다. 대체 방법을 찾기 위해 우리 팀은 기계 학습을 통해 인공 지능에 의한 골절 감지를 평가하고자 하였다. 이 연구는 골반 X-ray 영상을 학습한 합성곱 신경망 (Convolutional neural network: CNN)을 사용하여 전위 및 비 전위성 골절을 포함한 대퇴 경부 골절을 판단 하고 내부 및 외부 검증을 통해 실제 임상 상황에서의 사용성이 있는 알고리즘을 개발하는 것을 목표로 했다. 또한 단일 병원에서 학습한 합성곱 신경망의 알고리즘을 다른 기관에 적용할 수 있는지 검증하고자 한다.Material & Method이 연구는 후향적 연구로써 CBAM++ (Convolutional Block Attention Module ++)을 삽입한 ResNet18 (Residual neural network 18)을 골반 및 고관절 X-ray 사진으로 학습시키고 이를 통해 X-ray 상의 대퇴 경부 골절을 판독을 수행하였다. 이 연구는 2020년 2월부터 2020년 5월까지 두 곳의 상급종합병원에서 수행되었으며 2005년 1월부터 2018년 12월까지의 데이터를 사용했다. 본 연구는 대퇴 경부 골절 X-ray를 학습한 심층신경망의 판독이 진단적 가치를 가질 수 있을 것이라는 가설 하 진행되었다. 이에 따른 결과를 AUC (area under the receiver operating characteristic curve), 정확도, Youden 지수, 민감도 및 특이도로 설명하였다.Result두 개의 병원에서 1,109개의 골절 이미지 (비 전위성 골절 332개 및 전위성 골절 777개) 와 3,080개의 비 골절 이미지로 총 4,189개의 이미지를 수집하였다. 단일 병원 데이터로 학습한 후 수행한 심층신경망의 내부 테스트 결과는 AUC 0.999, 정확 도 0.986, Youden 지수 0.960, 민감도 0.966 및 특이도 0.993으로 나타났다. 동일한 알고리즘을 통해 외부 병원 데이터를 사용한 외부 검증 결과는 각각 0.977, 0.971, 0.920, 0.939 및 0.982로 확인되었다. 두 개의 병원 자료를 병합하여 학습을 수행 한 후 시행한 테스트 결과는 각각 0.987, 0.983, 0.960, 0.973 및 0.987로 나타났다.Conclusion단일 병원에서 학습한 합성곱 신경망을 이용하여 다른 기관의 X-ray 상의 전위 골절뿐 아니라 비 전위 골절까지 선별할 수 있으며 골절 판독 정확도와 민감도는 유의미하게 높았다. 다른 병원 X-ray의 추가 학습 후에는 의료인의 정확도와 동등하거나 그 이상의 대퇴 경부 골절 판독의 정확성을 보였다.",다국어 초록 정보 없음
Potato Detection and Segmentation Based on Mask R-CNN,2020,['Deep learning . Mask R-CNN . Potato detection . Potato segmentation'],국문 초록 정보 없음,"Purpose Potatoes are similar in color and size to soil and its clods. They are mostly irregular in the shape as well. Therefore, it is not easy to distinguish potatoes from the soil surface background only with machine vision. This study applied Mask R-CNN, one of the object recognition technologies using deep learning to detect potatoes. The size of object in pixel was obtained on individual potato, and they will be used to predict the yield of potatoes.Methods In order to collect the images needed for deep learning, potato images at the time of harvesting were obtained from potato farms. Annotation was entered for each irregular potato shape, where approximately 4500 potatoes were used. Resnet-101 was selected as the backbone of Mask R-CNN with a feature pyramid network. Transfer training was applied to shorten training time and limit the number of images needed to train the model. The classification performance evaluation was conducted to verify the trained model. The size of potato in pixel was obtained from the output image through the potato detection model by the segmentation algorithm using MATLAB.Results The total number of training for the potato detection model was 12,000, and the training loss of Mask R-CNN was less than 0.1%. The potato detection results from 69 randomly selected test images showed that the average detection precision was 90.8%, recall 93.0%, and F1 score 91.9%.Conclusions Potato detection model with Mask R-CNN can detect irregularly shaped potatoes on similar color soil surface. The size of the detected potato region can be extracted as well."
What Do Pedestrians See?: Visualizing Pedestrian-View Intersection Classification,2020,"['intersection classification', 'Class Activation Map visualization', 'deep convolution networks']",국문 초록 정보 없음,"Extensive research has been carried out on intersection classification to assist the navigation in autonomous maneuvering of aerial, road, and cave mining vehicles. In contrast, our work tackles intersection classification at pedestrian-view level to support navigation of the slower and smaller robots for which it is too dangerous to steer on a normal road along with the usual vehicles. Particularly, we focus on investigating the kind of features a network may exploit in order to classify intersection at pedestrian-view. To this end, two sets of experiments have been conducted using an ImageNet-pretrained ResNet-18 architecture fine-tuned on our image-level pedestrian-view intersection classification dataset. First, ablation study is performed on layer depth to evaluate the importance of high-level feature, which demonstrated superiority in using all of the layers by yielding 77.56% accuracy. Second, to further clarify the need of such high level features, Class Activation Map (CAM) is applied to visualize the parts of an image that affect the most on a given prediction. The visualization justifies the high accuracy of an all-layers network."
A Segmentation Guided Coarse to Fine Virtual Try-on Network for a new Clothing and Pose,2020,[],국문 초록 정보 없음,"Virtual try on is getting interested from researchers these days because its application in online shopping. But single pose virtual try on is not enough, customer may want to see themselves in different pose. Multiple pose virtual try on is getting input as customer image, an in-shop cloth and a target pose, it will try to generate realistic customer wearing the in-shop cloth with the target pose. We first generate the target segmentation layout using conditional generative network (cGAN), and then the in-shop cloth are warped to fit the customer body in target pose. Finally, all the result will be combine using a Resnet-like network. We experiment and show that our method outperforms stage of the art."
동적 필터 프루닝 기법을 이용한 심층 신경망 압축,2020,[],"최근 이미지 분류의 성능 향상을 위해 깊은 레이어와 넓은 채널을 가지는 모델들이 제안되어져 왔다. 높은 분류정확도를 보이는 모델을 제안하는 것은 과한 컴퓨팅 파워와 계산시간을 요구한다. 본 논문에서는 이미지 분류기법에서 사용되는 딥 뉴럴 네트워크 모델에 있어, 프루닝 방법을 통해 상대적으로 불필요한 가중치를 제거함과 동시에 분류 정확도 하락을 최소로 하는 동적 필터 프루닝 방법을 제시한다. 원샷 프루닝 기법, 정적 필터 프루닝 기법과 다르게 제거된 가중치에 대해서 소생 기회를 제공함으로써 더 좋은 성능을 보인다. 또한, 재학습이 필요하지 않기 때문에 빠른 계산 속도와 적은 컴퓨팅 파워를 보장한다. ResNet20 에서 CIFAR10 데이터셋에 대하여 실험한 결과 약 50%의 압축률에도 88.74%의 분류 정확도를 보였다.",다국어 초록 정보 없음
XAI 기반의 공공시설물 건전도 안전검사 평가시스템 연구,2020,[],"공공시설에 대한 안전점검은 공공시설의 노후화에 따라 정기적인 검사의 필요성이 요구되고 있다. 기존의 안전점검 방식은 대부분 육안으로 점검하는 것에 의존하는데 이는 점검자의 숙련도에 따라 결과의 품질이 달라지게 된다. 본 논문에서는 XAI 기반의 공공시설물 건전도 안전검사 평가시스템을 제안하며, 이는 점검자의 숙련도와 무관하게 항상 같은 결과를 도출해 내며 XAI 를 통해 사용자에게 안전점검에 대한 결과를 제시해준다. 공공시설물 중 터널 시설물의 안전검사 평가시스템을 기반으로 하는 연구를 진행하였으며 이는 수정없이 교량 시설물 등 다른 공공시설물에 적용이 가능하다. 본 논문은 5 가지로 구분된다. 1) 터널 이미지와 균열에 마스크를 적용한 이미지 두 가지의 데이터 셋을 448x448 로 생성한다. 2) UNet 과 Resnet152 의 두 모델을 적용한 혼합 모델을 이용하여 생성한 데이터 셋을 훈련시킨다. 3) 훈련된 혼합 모델에서 생성된 분할 이미지에 대해 노이즈 제거 과정을 진행한다. 4) 노이즈 제거가 끝난 이미지에 스켈레톤화(Skeletonization)를 적용시켜 균열 이미지의 뼈대를 구한다. 뼈대 이미지 기반으로 균열의 길이, 두께, 위치등의 정보를 얻는다. 5) XAI 부분에서는 뼈대 이미지의 정보를 토대로 균열의 위치, 두께, 길이 등에 대해 계산을 진행한 후 사용자에게 제시해준다.",다국어 초록 정보 없음
손글씨 인식 학습 모델 기반 수식 연산에 대한 연구,2020,"['딥러닝', '인식', '계산', 'Deep-Learning', 'Recognition', 'Calculation']","정보화 기술의 발달로 인해 문서 작성이나 브라우저 검색기능 같은 작업들이 모두 키보드 타이핑만으로 가능하게 되었다. 하지만 수학 계산식 같은 경우에는 키보드 타이핑으로 작성하기가 어려운 것을 알 수 있다. 계산식 같은 경우는 키보드가 아닌 아날로그 식으로 본인이 직접 수기하는 것이 시간도 절약되고 타이핑하는 것보다 오히려 편하다는 것을 알 수 있다. 그러기에 수학 계산식을 검색해서 답을 찾으려 할 때 사용자들은 불편함을 느끼게 된다.본 논문은 컴퓨터가 학습한 딥 러닝 모델로 수기로 작성된 수학 수식을 텍스트 형태로 바꿀 때, 더 정확하게 인식하는 모델의 종류가 무엇인지 제공한다. 숫자와 사칙 연산 기호뿐만 아니라 사용자가 정의한 연산자로도 정확한 인식이 가능한지를 확인한다. 이를 위해 DenseNet, ResNet과 같은 CNN 모델 이용하여 실험을 수행하였고, 실험을 통하여 그 중 가장 적합한 모델을 찾아내었다.",다국어 초록 정보 없음
결절성 폐암 검출을 위한 상용 및 맞춤형 CNN의 성능 비교,2020,"['Pulmonary Nodule', 'Computer Aided Detection', 'Deep Neural Network', 'Convolutional Neural Networ']",국문 초록 정보 없음,"Screening with low-dose spiral computed tomography (LDCT) has been shown to reduce lung cancer mortality by about 20% when compared to standard chest radiography. One of the problems arising from screening programs is that large amounts of CT image data must be interpreted by radiologists. To solve this problem, automated detection of pulmonary nodules is necessary; however, this is a challenging task because of the high number of false positive results. Here we demonstrate detection of pulmonary nodules using six off-the-shelf convolutional neural network (CNN) models after modification of the input/output layers and end-to-end training based on publicly databases for comparative evaluation. We used the well-known CNN models, LeNet-5, VGG-16, GoogLeNet Inception V3, ResNet-152, DensNet201, and NASNet. Most of the CNN models provided superior results to those of obtained using customized CNN models. It is more desirable to modify the proven off-the-shelf network model than to customize the network model to detect the pulmonary nodules."
임베디드 보드에서의 CNN 모델 압축 및 성능 검증,2020,"['CNN', 'Neural Network Compression', 'Pruning', 'Matrix Decomposition', 'Embedded Board']",국문 초록 정보 없음,"Recently, deep neural networks such as CNN are showing excellent performance in various fields such as image classification, object recognition, visual quality enhancement, etc. However, as the model size and computational complexity of deep learning models for most applications increases, it is hard to apply neural networks to IoT and mobile environments. Therefore, neural network compression algorithms for reducing the model size while keeping the performance have been being studied. In this paper, we apply few compression methods to CNN models and evaluate their performances in the embedded environment. For evaluate the performance, the classification performance and inference time of the original CNN models and the compressed CNN models on the image inputted by the camera are evaluated in the embedded board equipped with QCS605, which is a customized AI chip. In this paper, a few CNN models of MobileNetV2, ResNet50, and VGG-16 are compressed by applying the methods of pruning and matrix decomposition. The experimental results show that the compressed models give not only the model size reduction of 1.3~11.2 times at a classification performance loss of less than 2% compared to the original model, but also the inference time reduction of 1.2~2.21 times, and the memory reduction of 1.2~3.8 times in the embedded board."
기본 특징추출신경망에 따른 YOLO의 말벌인식 성능 평가,2020,"['Deep CNN', 'Vespa monitoring system', 'YOLOv2', 'Feature extraction layer', 'VGG19', 'Transfer learning']",국문 초록 정보 없음,"Real-time monitoring system for Vespa is necessary to reduce the damage to beekeeping farmers. In this paper, we compare and analyze the performance of the YOLO-based deep learning algorithms suitable for developing real-time automatic recognition and classification systems for Apis mellifera and five types of vespas such as V. velutina nigrithorax, V. mandarinia, V. ducalis, V. similima and V. crabro. YOLO has shown the best quality for real-time object detection due to its fast speed by replacing iterative object detection with once regression for an input image. However, the YOLO utilizes the conventional DCNN (deep convolutional neural network) algorithm to extract features from images thus, detection performance of the YOLO depends on the DCNN utilized. Therefore, we evaluate the object detection performance by changing the feature extraction layers of YOLOv2 with AlexNet, VGG19, GoogLeNet, and ResNet50 to find the best combination DCNN model for YOLO on the six bees above. The comparison results are as follows. In terms of the speed of detection and classification, the model in which YOLOv2 is combined with the AlexNet as a feature extraction layer showed the highest detection speed per second. This model can detect and classify 5 vespas and a bee from an average of 438 images per second, but has a relatively low accuracy of 71.7%. In terms of accuracy, the model that combines the feature extraction layer of VGG19 with YOLOv2 generated the highest accuracy, 83.2%. In addition, it can process an average of 135 images per second, enabling real-time processing of surveillance videos for wasps and bees. Therefore, we verified that the combined YOLO model with the VGG19 can be the best real-time monitoring system for the vespa detection."
"적은 수량, 불균형 문제를 가진 학습데이터를 위한 합성곱 신경망 기반의 웨이퍼 맵 불량패턴 분류",2020,"['웨이퍼 맵 분류', '불균형 데이터', '이미지 증식', '합성곱 신경망']","반도체 웨이퍼 맵은 반도체 제조 공정 중, wafer chip의 Probe test로 얻은 결과를 나타낸 것이다. 웨이퍼 맵 상에서 불량 칩의 군집 형태는 원, 스크래치, 링 등 다양한 패턴을 보이는데, 특정 불량 패턴에 따라 불량 원인을 파악하여 반도체 공정 개선이 가능하기 때문에 불량 패턴을 정확히 분류하는 것이 중요하다.분류 대상이 되는 실험 데이터는 국내 반도체 제조회사의 웨이퍼 맵이며, 분류된 웨이퍼 맵의 수가 많지 않고 불량패턴의 유무에 따른 불균형과, 불량 패턴 내 불균형 문제가 존재한다. 본 연구에서 사용하는 머신러닝 알고리즘은 일반적으로 각 클래스 별 데이터 분포가 비슷하다는 가정 하에 뛰어난 성능을 보이지만 현실은 일부 데이터에 편향되어 있고 오히려 소수에 해당되는 클래스가 데이터 마이닝 관점에서 더 중요한 경우가 많다. 이러한 불균형 문제로 알고리즘 학습에 어려움이 존재한다.이를 위해 본 연구는 소량의 정확히 분류된 웨이퍼 맵을 클래스가 변하지 않도록 상하좌우 반전 및 회전만을 랜덤 적용하여 데이터 증식을 수행한다. 증식된 데이터를 합성곱 신경망의 한 종류인 ResNet을 사용하여 학습하고 패턴 분류 시행 및 분류 모델의 정확성을 검증한다.",다국어 초록 정보 없음
Intra-Class Random Erasing (ICRE) augmentation for audio classification,2020,[],국문 초록 정보 없음,"Data augmentation has been helpful in improving the performance in deep learning, when we have a limited data and random erasing is one of the augmentation that have shown impressive performance in deep learning in multiple domains. But the main issue is that sometime it loses good features when randomly selected region is erased by some random values, that does not improve performance as it should. We target that problem in way that good features should not be lost and also want random erasing at the same time. For that purpose, we introduce new augmentation technique named Intra-Class Random Erasing (ICRE) that focused on data to learn robust features of the same class samples by randomly exchanging randomly seleted region. We perform multiple experiments by using different models including resnet18, VGG16 over variety of the datasets including ESC10, UrbanSound8K. Our approach has shown effectiveness over others methods including random erasing."
다시점 영상 집합을 활용한 선체 블록 분류를 위한 CNN 모델 성능 비교 연구,2020,"['Multi-view image set(다시점 영상 집합)', 'Convolutional Neural Network(CNN', '합성곱신경망)', 'Ship hull block(선체 블록)', 'Classification(분류)', 'Data augmentation(데이터 확장)', 'Transfer learning(전이학습)']",국문 초록 정보 없음,"It is important to identify the location of ship hull blocks with exact block identification number when scheduling the shipbuilding process. The wrong information on the location and identification number of some hull block can cause low productivity by spending time to find where the exact hull block is. In order to solve this problem, it is necessary to equip the system to track the location of the blocks and to identify the identification numbers of the blocks automatically. There were a lot of researches of location tracking system for the hull blocks on the stockyard. However there has been no research to identify the hull blocks on the stockyard. This study compares the performance of 5 Convolutional Neural Network (CNN) models with multi-view image set on the classification of the hull blocks to identify the blocks on the stockyard. The CNN models are open algorithms of ImageNet Large-Scale Visual Recognition Competition (ILSVRC). Four scaled hull block models are used to acquire the images of ship hull blocks. Learning and transfer learning of the CNN models with original training data and augmented data of the original training data were done. 20 tests and predictions in consideration of five CNN models and four cases of training conditions are performed. In order to compare the classification performance of the CNN models, accuracy and average F1-Score from confusion matrix are adopted as the performance measures. As a result of the comparison, Resnet-152v2 model shows the highest accuracy and average F1-Score with full block prediction image set and with cropped block prediction image set."
Empirical Comparison of Deep Learning Networks on Backbone Method of Human Pose Estimation,2020,"['Deep learning', 'human pose estimation', 'CNN', 'VGG', 'Resnet']",국문 초록 정보 없음,"Accurate estimation of human pose relies on backbone method in which its role is to extract feature map. Up to dated, the method of backbone feature extraction is conducted by the plain convolutional neural networks named by CNN and the residual neural networks named by Resnet, both of which have various architectures and performances. The CNN family network such as VGG which is well-known as a multiple stacked hidden layers architecture of deep learning methods, is base and simple while Resnet which is a bottleneck layers architecture yields fewer parameters and outperform. They have achieved inspired results as a backbone network in human pose estimation. However, they were used then followed by different pose estimation networks named by pose parsing module. Therefore, in this paper, we present a comparison between the plain CNN family network (VGG) and bottleneck network (Resnet) as a backbone method in the same pose parsing module. We investigate their performances such as number of parameters, loss score, precision and recall. We experiment them in the bottom-up method of human pose estimation system by adapted the pose parsing module of openpose. Our experimental results show that the backbone method using VGG network outperforms the Resent network with fewer parameter, lower loss score and higher accuracy of precision and recall."
A Feasibility Study on Application of a Deep Convolutional Neural Network for Automatic Rock Type Classification,2020,"['Rock type classification', 'Deep learning', 'ResNet', 'Rock sample image dataset', '암종 분류', '딥러닝', '레즈넷', '암석 샘플 이미지 데이터셋']","암종 분류은 현장의 지질학적 또는 지반공학적 특성 파악을 위해 요구되는 매우 기본적인 행위이나 암석의 성인, 지역, 지질학적 이력 특성에 따라 동일 암종이라 하여도 매우 다양한 형태와 색 조성을 보이므로 깊은 지질학적 학식과 경험 없이는 쉬운 일은 아니다. 또한, 다른 여러 분야의 분류 작업에서 딥러닝 영상처리 기법들이 성공적으로 적용되고 있으며, 지질학적 분류나 평가 분야에서도 딥러닝 기법의 적용에 대한 관심이 증대되고 있다. 따라서, 본 연구에서는 동일 암종임에도 다양한 형태와 색을 갖게 되는 실제 상황을 감안하여, 정확한 자동 암종 분류를 위한 딥러닝 기법의 적용 가능성에 대해 검토하였다. 이러한 기법은 향후에 현장 암종분류 작업을 수행하는 현장 기술자들을 지원할 수 있는 효과적인 툴로 활용 가능할 것이다. 본 연구에서 사용된 딥러닝 알고리즘은 매우 깊은 네트워크 구조로 객체 인식과 분류를 할 수 있는 것으로 잘 알려진 ’ResNet’ 계열의 딥러닝 알고리즘을 사용하였다. 적용된 딥러닝에서는 10개의 암종에 대한 다양한 암석 이미지들을 학습시켰으며, 학습 시키지 않은 암석 이미지들에 대하여 84% 수준 이상의 암종 분류 정확도를 보였다. 본 결과로 부터 다양한 성인과 지질학적 이력을 갖는 다양한 형태와 색의 암석들도 지질 전문가 수준으로 분류해 낼 수 있는 것으로 파악되었다. 나아가 다양한 지역과 현장에서 수집된 암석의 이미지와 지질학자들의 분류 결과가 학습데이터로 지속적으로 누적이 되어 재학습에 반영된다면 암종분류 성능은 자동으로 향상될 것이다.","Rock classification is fundamental discipline of exploring geological and geotechnical features in a site, which, however, may not be easy works because of high diversity of rock shape and color according to its origin, geological history and so on. With the great success of convolutional neural networks (CNN) in many different image-based classification tasks, there has been increasing interest in taking advantage of CNN to classify geological material. In this study, a feasibility of the deep CNN is investigated for automatically and accurately identifying rock types, focusing on the condition of various shapes and colors even in the same rock type. It can be further developed to a mobile application for assisting geologist in classifying rocks in fieldwork. The structure of CNN model used in this study is based on a deep residual neural network (ResNet), which is an ultra-deep CNN using in object detection and classification. The proposed CNN was trained on 10 typical rock types with an overall accuracy of 84% on the test set. The result demonstrates that the proposed approach is not only able to classify rock type using images, but also represents an improvement as taking highly diverse rock image dataset as input."
딥러닝을 이용한 컨베이어 시스템의 배출구 막힘 상태 판단 기술에 관한 연구,2020,"['컨베이어 시스템', '막힘 판단', '딥러닝', 'CNN', 'VGGNet', 'ResNet', 'DenseNet', 'NASNet', 'Conveyor Systems', 'Blockage Determination', 'Deep Learning', 'Convolutional Neural Network', 'Visual Geometry Group Network', 'Residual Network', 'Dense Network', 'Neural Architecture Search Network']","본 연구는 컨베이어 시스템에서 딥러닝을 이용한 배출구 막힘 판단 기술에 대하여 제안한다.제안 방법은 산업 현장의 CCTV에서 수집한 영상을 이용하여 배출구 막힘 판단을 위한 다양한CNN 모델들을 학습시키고, 성능이 가장 좋은 모델을 사용하여 실제 공정에 적용하는 것을 목적으로 한다. CNN 모델로는 잘 알려진 VGGNet, ResNet, DenseNet, 그리고 NASNet을 사용하였으며, 모델 학습과 성능 테스트를 위하여 CCTV에서 수집한 18,000장의 영상을 이용하였다. 다양한 모델에 대한 실험 결과, VGGNet은 99.89%의 정확도와 29.05ms의 처리 시간으로 가장 좋은 성능을 보였으며, 이로부터 배출구 막힘 판단 문제에 VGGNet이 가장 적합함을 확인하였다.","This study proposes a technique for the determination of outlet blockage using deep learning in a conveyor system. The proposed method aims to apply the best model to the actual process, where we train various CNN models for the determination of outlet blockage using images collected by CCTV in an industrial scene.We used the well-known CNN model such as VGGNet, ResNet, DenseNet and NASNet, and used 18,000 images collected by CCTV for model training and performance evaluation. As a experiment result with various models, VGGNet showed the best performance with 99.03% accuracy and 29.05ms processing time, and we confirmed that VGGNet is suitable for the determination of outlet blockage."
블록 계층별 재학습을 이용한 다중 힌트정보 기반 지식전이 학습,2020,"['Multiple hint information', 'Block-wise retraining', 'Knowledge transfer', 'Deep learning', 'Residual network']",국문 초록 정보 없음,"In this paper, we propose a stage-wise knowledge transfer method that uses block-wise retraining to transfer the useful knowledge of a pre-trained residual network (ResNet) in a teacher-student framework (TSF). First, multiple hint information transfer and block-wise supervised retraining of the information was alternatively performed between teacher and student ResNet models. Next, Softened output information-based knowledge transfer was additionally considered in the TSF. The results experimentally showed that the proposed method using multiple hint-based bottom-up knowledge transfer coupled with incremental block-wise retraining provided the improved student ResNet with higher accuracy than existing KD and hint-based knowledge transfer methods considered in this study."
Research on Crack Segmentation Method of Hydro-Junction Project Based on Target Detection Network,2020,"['Hydro-junction project', 'Faster-RCNN', 'Inception Resnet V2', 'Data augmentation', 'K-means']",국문 초록 정보 없음,"The defect detection is an important task for maintaining the hydro-junction project. A two-stage crack defect segmentation method based on target detection network is proposed to solve the problem of severe brightness imbalance and large noise in dam surface images. In the first stage, to improve the ability to locate crack areas, Inception Resnet V2 is used as feature extraction network to help Faster-RCNN extract more effective deep features, and the brightness, contrast of image is randomly adjusted before training. In the second segmentation stage, the crack areas are segmented at pixel-level using K-means. The experimental results on the self-made crack image dataset show that the location accuracy (AP) of the crack areas can be improved by 1.9%, reaching 96.8%, compared with other segmentation networks that do not locate crack areas, the intersection over union for segmentation of cracks (Iou) of the final segmentation results is at least 9.4% higher, reaching 52.7%. This method can provide effective technical support for inspection work of hydro-junction project."
머신러닝을 사용한 탄성파 자료 보간법 기술 연구 동향 분석,2020,"['탄성파 자료 보간', '머신러닝', '서포트 벡터 머신', '유넷', '잔차넷', '생성적 적대 신경망', 'seismic data interpolation', 'machine learning', 'support vector machine', 'U-Net', 'ResNet', 'GAN']","탄성파 탐사를 수행할 때 경제적, 환경적 제약 또는 탐사 장비의 문제 등에 의해 탄성파 자료의 일부가 규칙적또는 불규칙적으로 손실되는 경우가 발생하게 된다. 이러한 자료 손실은 탄성파 자료 처리와 해석 결과에 부정적인 영향을 주기 때문에 사라진 탄성파 자료를 복원할 필요가 있다. 탄성파 자료 복원을 위해 재탐사 또는 추가적인 탐사를 진행하는 경우 시간적, 경제적 비용이 발생하기 때문에, 많은 연구자들이 사라진 탄성파 자료를 정확히 복원하기 위한 보간 기법 연구를 진행해왔다. 최근에는 머신러닝 기술 발달에 따라 머신러닝 기법을 활용한 연구들이 진행되고 있고, 다양한 머신러닝 기술들 중에서도 서포트 벡터 회귀, 오토인코더, 유넷, 잔차넷, 생성적 적대 신경망 등의 알고리즘을 활용한 탄성파 자료의 보간 연구가 활발하게 진행되고 있다. 이 논문에서는 이러한 연구들을 조사하고 분석하여 복잡한 신경망 모델뿐 아니라 상대적으로 구조가 간단한 서포트 벡터 회귀 모델을 통해서도 뛰어난 보간 결과를 얻을 수 있다는 것을 확인했다. 추후 머신러닝 기법들을 사용하는 탄성파 자료 보간 연구들에서 오픈소스로 공개된 실제 자료를 이용하며 데이터증식, 전이학습, 기존 기법을 이용한 규제 등의 기술을 활용하면 탄성파 자료 보간 성능을 향상시킬 수 있을 것으로 기대된다.","We acquire seismic data with regularly or irregularly missing traces, due to economic, environmental, and mechanical problems. Since these missing data adversely affect the results of seismic data processing and analysis, we need to reconstruct the missing data before subsequent processing. However, there are economic and temporal burdens to conducting further exploration and reconstructing missing parts. Many researchers have been studying interpolation methods to accurately reconstruct missing data. Recently, various machine learning technologies such as support vector regression, autoencoder, U-Net, ResNet, and generative adversarial network (GAN) have been applied in seismic data interpolation. In this study, by reviewing these studies, we found that not only neural network models, but also support vector regression models that have relatively simple structures can interpolate missing parts of seismic data effectively.We expect that future research can improve the interpolation performance of these machine learning models by using open-source field data, data augmentation, transfer learning, and regularization based on conventional interpolation technologies."
ONNX기반 스파이킹 심층 신경망 변환 도구,2020,"['Deep neural network', 'ONNX', 'Spiking neural network']","스파이킹 신경망은 기존 신경망과 다른 메커니즘으로 동작한다. 기존 신경망은 신경망을 구성하는 뉴런으로 들어 오는 입력 값에 대해 생물학적 메커니즘을 고려하지 않은 활성화 함수를 거쳐 다음 뉴런으로 출력 값을 전달한다. 뿐만 아니라 VGGNet, ResNet, SSD, YOLO와 같은 심층 구조를 사용한 좋은 성과들이 있었다. 반면 스파이킹 신경망은 기존 활성화함수 보다 실제 뉴런의 생물학적 메커니즘과 유사하게 동작하는 방식이지만 스파이킹 뉴런을 사용한 심층 구조에 대한 연구는 기존 뉴런을 사용한 심층 신경망과 비교해 활발히 진행되지 않았다. 본 논문은 기존 뉴런으로 만들어 진 심층 신경망 모델을 변환 툴에 로드하여 기존 뉴런을 스파이킹 뉴런으로 대체하여 스파이킹 심층 신경망으로 변환하 는 방법에 대해 제안한다.","The spiking neural network operates in a different mechanism than the existing neural network. The existing neural network transfers the output value to the next neuron via an activation function that does not take into account the biological mechanism for the input value to the neuron that makes up the neural network. In addition, there have been good results using deep structures such as VGGNet, ResNet, SSD and YOLO. spiking neural networks, on the other hand, operate more like the biological mechanism of real neurons than the existing activation function, but studies of deep structures using spiking neurons have not been actively conducted compared to in-depth neural networks using conventional neurons. This paper proposes the method of loading an deep neural network model made from existing neurons into a conversion tool and converting it into a spiking deep neural network through the method of replacing an existing neuron with a spiking neuron."
Development of A Uniform And Casual Clothing Recognition System For Patient Care In Nursing Hospitals,2020,"['Nursing Hospital', 'Patient Uniform', 'Casual Clothing', 'Clothing Recognition', '요양병원', '환자복', '평상복', '의복 인식']","본 연구의 목적은 요양병원에서 발생할 수 있는 노인안전사고 발생률을 감소시키는 것이다. 즉, 위험지역으로 접근하는 인물이 노인(환자복) 그룹인지 실무자(평상복) 그룹인지를 CCTV에 나타나는 의복을 기준으로 구별하는 것이다. Web Crawling기법과 요양병원으로부터 지원을 받아 기초데이터를 수집하였다. 이후 Image Generator와 Labeling으로 모델 학습 데이터를 만들었다. CCTV의 제한된 성능 때문에 높은 정확도와 속도를 모두 갖춘 모델을 만드는 것은 어려웠다. 그러므로 정확성이 상대적으로 우수한 ResNet 모델, 속도에서 상대적으로 우수한 YOLO3 모델을 각각 구현했다. 그리고 요양병원이 자신의 실정에 맞는 모델을 고를 수 있게 하고자 했다. 연구 결과 환자복과 평상복을 적절한 정확도로 구별할 수 있는 모델을 구현하였다. 따라서 실제 사용처에서 노인들이 위험구역에 접근하지 못하도록 하여 요양병원 안전사고 감소에 이바지 할 것으로 평가된다.","The purpose of this paper is to reduce the ratio of the patient accidents that may occur in nursing hospitals. In other words, it determines whether the person approaching the dangerous area is a elderly (patient uniform) group or a practitioner(Casual Clothing) group, based on the clothing displayed by CCTV. We collected the basic learning data from web crawling techniques and nursing hospitals. Then model training data was created with Image Generator and Labeling program. Due to the limited performance of CCTV, it is difficult to create a good model with both high accuracy and speed. Therefore, we implemented the ResNet model with relatively excellent accuracy and the YOLO3 model with relatively excellent speed. Then we wanted to allow nursing hospitals to choose a model that they wanted. As a result of the study, we implemented a model that can distinguish patient and casual clothes with appropriate accuracy. Therefore, it is believed that it will contribute to the reduction of safety accidents in nursing hospitals by preventing the elderly from accessing the danger zone."
Enhancement of Tongue Segmentation by Using Data Augmentation,2020,"['Data augmentation', 'Deep Learning', 'Tongue segmentation', 'Transfer learning']","많은 양의 데이터는 딥 러닝 모델의 견고성을 향상시키고 과적합 문제를 방지할 수 있게 해준다. 자동 혀 분할에서, 혀 영상 데이터 세트를 실제로 수집하고 라벨링하는 데에는 많은 어려움이 수반되므로 많은 양의 혀 영상 데이터를 사용하기 쉽지 않다. 데이터 증강은 새로운 데이터를 수집하지 않고 레이블 보존 변환을 사용하여 학습 데이터 세트를 확장하고 학습 데이터의 다양성을 증가시킬 수 있다. 이 논문에서는 이미지 자르기, 회전, 뒤집기, 색상 변환과 같은 7 가지 데이터 증강 방법을 사용하여 확장된 혀 영상 학습 데이터 세트를 생성하였다. 데이터 증강 방법의 성능을 확인하기 위하여 InceptionV3, EfficientNet, ResNet, DenseNet 등과 같은 전이 학습 모델을 사용하였다. 실험 결과 데이터 증강 방법을 적용함으로써 혀 분할의 정확도를 5~20% 향상시켰으며 기하학적 변환이 색상 변환보다 더 많은 성능 향상을 가져올 수 있음을 보여주었다. 또한 기하학적 변환 및 색상 변환을 임의로 선형 조합한 방법이 다른 데이터 증강 방법보다 우수한 분할 성능을 제공하여 InveptionV3 모델을 사용한 경우에 94.98 %의 정확도를 보였다.","A large volume of data will improve the robustness of deep learning models and avoid overfitting problems. In automatic tongue segmentation, the availability of annotated tongue images is often limited because of the difficulty of collecting and labeling the tongue image datasets in reality. Data augmentation can expand the training dataset and increase the diversity of training data by using label-preserving transformations without collecting new data. In this paper, augmented tongue image datasets were developed using seven augmentation techniques such as image cropping, rotation, flipping，color transformations. Performance of the data augmentation techniques were studied using state-of-the-art transfer learning models, for instance, InceptionV3, EfficientNet, ResNet, DenseNet and etc. Our results show that geometric transformations can lead to more performance gains than color transformations and the segmentation accuracy can be increased by 5% to 20% compared with no augmentation. Furthermore, a random linear combination of geometric and color transformations augmentation dataset gives the superior segmentation performance than all other datasets and results in a better accuracy of 94.98% with InceptionV3 models."
인공신경망 모델 압축을 위한 적응적 양자화 기반 지식 증류 기법,2020,"['Adaptive quantization', 'Knowledge distillation', 'Model compression']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝 기반 교량 구성요소 자동 분류,2020,"['BIM', '교량 구성요소 분류', '딥러닝', 'CNN', 'BIM', 'Bridge component classification', 'Deep Learning', 'CNN']","최근 BIM (Building Information Modeling)이 건설 산업계에서 폭넓게 활용되고 있다. 하지만 과거에 시공이 된 구조물에 경우 대부분 BIM이 구축되어 있지 않다. BIM이 구축되지 않은 구조물의 경우, 카메라로부터 얻은 2D 이미지에 SfM (Structure from Motion) 기법을 활용하면 3D 모델의 점군 데이터(Point cloud)를 생성하고 BIM을 구축할 수 있다. 하지만 이렇게 생성된 점군 데이터는 의미론적 정보가 포함되어 있지 않기 때문에, 수작업으로 구조물의 어떤 요소인지 분류해 주어야 한다. 따라서 본 연구에서는 구조물 구성요소를 분류하는 과정을 자동화하기 위하여 딥러닝을 적용하였다. 딥러닝 네트워크 구축에는 CNN (Convolutional Neural Network) 구조의 Inception-ResNet-v2를 사용하였고, 전이학습을 통하여 교량 구조물의 구성요소를 학습하였다. 개발된 시스템을 검증하기 위하여 수집한 데이터를 이용하여 구성요소를 분류한 결과, 교량의 구성요소를 96.13 %의 정확도로 분류할 수 있었다.","Recently, BIM (Building Information Modeling) are widely being utilized in Construction industry. However, most structures that have been constructed in the past do not have BIM. For structures without BIM, the use of SfM (Structure from Motion) techniques in the 2D image obtained from the camera allows the generation of 3D model point cloud data and BIM to be established. However, since these generated point cloud data do not contain semantic information, it is necessary to manually classify what elements of the structure. Therefore, in this study, deep learning was applied to automate the process of classifying structural components. In the establishment of deep learning network, Inception-ResNet-v2 of CNN (Convolutional Neural Network) structure was used, and the components of bridge structure were learned through transfer learning. As a result of classifying components using the data collected to verify the developed system, the components of the bridge were classified with an accuracy of 96.13 %."
딥러닝을 활용한 도로 균열율 산정 및 상태등급 판정,2020,"['Deep Learning', 'ResNet', 'Segnet', 'Road Risk', 'Road Crack', 'MMS']",국문 초록 정보 없음,다국어 초록 정보 없음
심층 신경망 기반의 앙상블 방식을 이용한 토마토 작물의 질병 식별,2020,"['Crop Disease Classification', 'Ensemble Approach', 'Deep Neural Network']",국문 초록 정보 없음,다국어 초록 정보 없음
오차 기반 합성곱 신경망을 활용한 원형 플러그 아연 도금 불량 판별,2020,"['Error based learning', 'Zinc plating of circular plug', 'Convolutional deep learning', 'ResNet-50']",국문 초록 정보 없음,다국어 초록 정보 없음
변환 학습을 사용한 이미지 장면 분류,2020,"['multiclass image scene classification method', 'ImageNet', 'large image dataset', 'ResNet model']",국문 초록 정보 없음,다국어 초록 정보 없음
PET-CT 영상 알츠하이머 분류에서 유전 알고리즘 이용한 심층학습 모델 최적화,2020,"['Alzheimer’s Disease Classification', 'Genetic Algorithm', 'Deep Learning', 'ResNet']",국문 초록 정보 없음,다국어 초록 정보 없음
청각장애인용 자막방송 서비스를 위한 연쇄잔차 신경망 기반 음향 사건 분류 기법,2020,[],"본 논문에서는 청각장애인에게 자막방송을 제공하기 위하여 오디오 콘텐츠에 등장하는 음향 사건을 분류하는 기법을 제안한다. 제안된 기법은 복수의 잔차 신경망(ResNet)을 연결하는 연쇄잔차(concatenated residual) 신경망 구조를 갖는다. 신경망의 입력 특징을 위해 음성의 멜-주파수 켑스트럼 벡터를 다수의 프레임으로 결합하여 형성한 2 차원 이미지와 전체 프레임에 대한 멜-주파수 켑스트럼 벡터들로부터 얻은 1 차원의 통계 특징벡터를 얻는다. 각각의 입력은 2 차원 잔차 신경망과 1 차원 잔차 신경망으로 모델링되고, 두 개의 잔차 신경망을 연쇄연결(concatenation)하는 구조를 가진 연쇄잔차 신경망으로 구성된다. 성능평가를 위해 수집된 데이터셋으로부터 6-fold 교차검증을 통해 평가한 결과, 85.48%의 분류 정확도를 얻을 수 있었다.",다국어 초록 정보 없음
자율주행을 위한 딥러닝 기반의 차선 검출 방법에 관한 연구,2020,"['Deep learning', 'Faster R-CNN', 'Machine learning', 'Support vector machine', 'Unmanned vehicle']",국문 초록 정보 없음,"This study used the Deep Learning models used in previous studies, we selected the basic model. The selected model was selected as ZFNet among ZFNet, Googlenet and ResNet, and the object was detected using a ZFNet based FRCNN. In order to reduce the detection error rate of FRCNN, location of four types of objects detected inside the image was designed by SVM classifier and location-based filtering was applied. As simulation results, it showed similar performance to the lane marking classification method with conventional 경계 detection, with an average accuracy of about 88.8%. In addition, studies using the Linear-parabolic Model showed a processing speed of 165.65ms with a minimum resolution of 600 × 800, but in this study, the resolution was treated at about 33ms with an input resolution image of 1280 × 960, so it was possible to classify lane marking at a faster rate than the previous study by CNN-based End to End method."
Experiment on Intermediate Feature Coding for Object Detection and Segmentation,2020,"['Deep learning', 'intermediate features', 'video coding for machine', 'object detection', 'object segmentation']",국문 초록 정보 없음,"With the recent development of deep learning, most computer vision-related tasks are being solved with deep learning-based network technologies such as CNN and RNN. Computer vision tasks such as object detection or object segmentation use intermediate features extracted from the same backbone such as Resnet or FPN for training and inference for object detection and segmentation. In this paper, an experiment was conducted to find out the compression efficiency and the effect of encoding on task inference performance when the features extracted in the intermediate stage of CNN are encoded. The feature map that combines the features of 256 channels into one image and the original image were encoded in HEVC to compare and analyze the inference performance for object detection and segmentation. Since the intermediate feature map encodes the five levels of feature maps (P2 to P6), the image size and resolution are increased compared to the original image. However, when the degree of compression is weakened, the use of feature maps yields similar or better inference results to the inference performance of the original image."
링크넷을 이용한 뇌영상 악성 신경교종 분할,2020,[],국문 초록 정보 없음,"Malignant gliomas are one of the leading causes of cancer-related death. The grade of gliomas plays a crucial role in the diagnosis and prognosis of gliomas. Before making surgery-related decisions, it is essential to find out which tissues are abnormal. In this paper, we propose a 2D Linknet-based convolutional neural network to segment malignant gliomas using multi-modal brain magnetic resonance imaging. Our model employs the 34-layer ResNet as an encoding part. It achieves a Dice coefficient of 0.7728 in the test set. The result shows the effectiveness of the proposed model to relieve the burden of manual segmentation of brain tumors."
"CCTV 지능화를 위한 엣지컴퓨팅 기반 객체검출, 식별 및 PTZ 제어의 구현",2020,[],"CCTV 지능화를 위해 연구되어 온 영상분석 및 카메라 제어 방법은 각 기능별 구현에 대해서는 널리 알려져 있지만 HW 제약사항을 고려한 유기적 구동을 위한 최적 구현 방법 및 그 성능은 잘 알려져 있지 않았다. 이에 본 논문은 CCTV의 지능화를 위한 엣지 컴퓨팅 기반 객체검출, 식별 및 PTZ 제어기능의 구현방법을 다룬다. 먼저 제안된 구현방법은 ResNet back-bone 기반의 객체검출 모델 및 객체식별 모델을 학습한 후 이에 대한 가지치기 및 양자화를 통한 모델 경량화를 진행한다. 다음으로 PTZ 제어와 관련된 ONVIF 프로토콜 전송 라이브러리를 구현한다. 마지막으로 각 기능별 API 인터페이스를 응용 SW 계층에서 통합하여 추론 (객체검출 및 식별)과 동작 (PTZ 제어)를 목적에 맞게 연동시킨다. 제안된 시스템은 스쿨존 안전관리를 위한 지능형 PTZ 시스템으로 구현되었으며, 실험결과 85mAP의 객체검출 정확성과 21FPS의 처리 속도를 보이며 그 유효성을 입증하였다.",다국어 초록 정보 없음
임베디드 연산을 위한 잡음에서 음성추출 U-Net 설계,2020,"['Speech enhancement', 'Noise reduction', 'Deep noise suppression', 'Deep neural network', 'wav-U-Net']",국문 초록 정보 없음,"In this paper, we propose wav-U-Net to improve speech enhancement in heavy noisy environments, and it has implemented three principal techniques. First, as input data, we use 128 modified Mel-scale filter banks which can reduce computational burden instead of 512 frequency bins. Mel-scale aims to mimic the non-linear human ear perception of sound by being more discriminative at lower frequencies and less discriminative at higher frequencies. Therefore, Mel-scale is the suitable feature considering both performance and computing power because our proposed network focuses on speech signals. Second, we add a simple ResNet as pre-processing that helps our proposed network make estimated speech signals clear and suppress high-frequency noises. Finally, the proposed U-Net model shows significant performance regardless of the kinds of noise. Especially, despite using a single channel, we confirmed that it can well deal with non-stationary noises whose frequency properties are dynamically changed, and it is possible to estimate speech signals from noisy speech signals even in extremely noisy environments where noises are much lauder than speech (less than SNR 0dB).The performance on our proposed wav-U-Net was improved by about 200% on SDR and 460% on NSDR compared to the conventional Jansson’s wav-U-Net. Also, it was confirmed that the processing time of out wav-U-Net with 128 modified Mel-scale filter banks was about 2.7 times faster than the common wav-U-Net with 512 frequency bins as input values."
정비 자료 디지털 변환을 위한 영상 인식 알고리듬 : CNN and FCN,2020,"['Tabular Maintenance Data(정비 자료표)', 'Digitization(디지털화)', 'CNN(합성곱 신경망)', 'FCN(완전 연결망)']",국문 초록 정보 없음,"Tabulated data has been widely used to facilitate systematic and intuitive management. In particular, tabular images that contain a few simple symbols are useful for maintaining mechanical systems. Several companies have accumulated tabular images as their property. Although these images are valuable as they can be used to solve difficult problems using data-based methods, such as deep learning, they still remain unavailable because it is expensive to digitize them. For these reasons, we propose a model comprised of a convolutional neural network (CNN) and fully convolutional network (FCN) to digitize tabular images. We used some ResNet components as they are well-suited to the characteristics of tabular image data. A training set for each model was constructed by writing symbols in blank tables and then augmenting them. As a result, the trained CNN and FCN models exhibited 99.2 % and 97.7 % accuracy in 4.75 s and 0.132 s of inference time, respectively."
딥러닝 기반 가상공간에서의 손 제스처 인식,2020,"['딥러닝', '가상 공간', 'CNN', '손 제스쳐 인식', '사용자 인터페이스', 'Deep Learning', 'Virtual Space', 'Hand Gesture Recognition', 'User Interface']",국문 초록 정보 없음,"In this paper, we define static gestures and dynamic gestures to be used as a user interface in a virtual space, and propose a method to extract features using deep learning models and to recognize hand gestures input through RGB camera in order to improve the price and recognition speed of the existing virtual / augmented reality interface device. Through various deep learning models, we learned the data in various ways and extracted the features to recognize hand gestures. Deep learning models used are Faster-RCNN, ResNet, U-Net, and 3D-CNN. Since we recognize hand gestures in the virtual space and use them as user interfaces, we want to contribute to using virtual / augmented reality through high recognition rates and fast recognition speeds without the help of specific sensors or wearable devices."
딥러닝 표정 인식을 활용한 실시간 온라인 강의 이해도 분석,2020,"['Degree of Understanding', 'Real-time Analysis', 'Face Detection', 'Facial Expression Recognition', 'Deep Learning']",국문 초록 정보 없음,"Due to the spread of COVID-19, the online lecture has become more prevalent. However, it was found that a lot of students and professors are experiencing lack of communication. This study is therefore designed to improve interactive communication between professors and students in real-time online lectures. To do so, we explore deep learning approaches for automatic recognition of students' facial expressions and classification of their understanding into 3 classes (Understand / Neutral / Not Understand). We use 'BlazeFace' model for face detection and 'ResNet-GRU' model for facial expression recognition (FER). We name this entire process 'Degree of Understanding (DoU)' algorithm. DoU algorithm can analyze a multitude of students collectively and present the result in visualized statistics. To our knowledge, this study has great significance in that this is the first study offers the statistics of understanding in lectures using FER. As a result, the algorithm achieved rapid speed of 0.098sec/frame with high accuracy of 94.3% in CPU environment, demonstrating the potential to be applied to real-time online lectures. DoU Algorithm can be extended to various fields where facial expressions play important roles in communications such as interactions with hearing impaired people."
JPEG 확장자로 추출된 흉부 X선을 이용한 딥러닝 연구에서 대조도와 영상 처리가 기흉 분류에 미치는 영향,2020,"['Deep learning', 'X-ray', 'Machine learning']","IntroductionX선 영상은 장비, 환자의 체형, X선의 선량, 및 후 처리 과정 등에 따라 영상의 대조도와 픽셀 정보가 다를 수 있다. 흉부 X 선 영상을 이용한 딥러닝 연구에서 JPEG (Joint Photograph Experts Group) 혹은 PNG (Portable Network Graphics) 확장자로 추출한 이미지를 이용한 연구들이 있다. 이 연구는 JPEG로 추출된 흉부 X선 영상을 이용하여 대조도 (Contrast) 에 따른 학습 결과와 영상처리 (image processing)을 통한 개선 영향을 알아보고자 한다.Material & Method데이터는 2012년 1월부터 2020년 6월까지 기흉 진단을 받은 환자와 정상 소견을 보인 환자의 흉부 X선 영상들을 JPEG로 각각 1,089장과 2,100장(학습 70%, 내부검증 30%) 수집하였으며, 2020년 6월부터 9월까지 테스트를 위하여 각각 100장과 200장을 추가로 획득하였다. 수집된 자료를 매트랩(Matlab)을 이용하여 다섯 종류(기본 100%, 기본의 각각 50%, 75%, 125% 와 150%)의 밝기의 대조도로 변화시키고, 합성곱 신경망(Convolutional neural network, CNN) 중 Resnet 34로 학습을 진행하고 결과를 비교하였다. 영상 처리를 하지 않은 경우 (그룹 A)와 비교하여 정규화 (Normalization)와 평탄화 (Histogram)를 통한 영상처리 후 (그룹 B)에 학습 결과가 개선되는 지 실험을 하였다.Result영상 처리를 적용하지 않은 그룹 A 의 경우에는 학습 데이터와 같은 대조도의 영상을 테스트 한 결과는 모두 정확도 (Accuracy) 0.99, 유덴지수 (Youden index, Sensitivity+Specificity-1) 0.99 이상을 보였다. 하지만, 학습한 데이터와 다른 대조도의 테스트를 한 경우에는 정확도가 약 50%까지 감소하였다. 영상 처리를 적용한 그룹 B에서는 학습 데이터와 같은 대조도의 영상을 테스트 한 결과는 Group A와 같이 모두 정확도는 0.99, 유덴지수는 0.99 이상을 보였다. 학습한 데이터와 다른 대조도의 테스트를 한 경우에는 대조도가 150% 밝은 영상을 제외하고 나머지 경우에는 학습결과의 감소하지 않았다.ConclusionJPEG 확장자로 추출한 X선을 이용한 딥러닝 연구에서 대조도에 따라 학습 결과의 차이를 보일 수 있으며, 이러한 문제점은 영상 처리를 통해 성능을 개선을 시킬 수 있다.",다국어 초록 정보 없음
Automatic detection of periodontal compromised teeth in digital panoramic radiographs using faster regional convolutional neural networks,2020,"['Alveolar Bone Loss', 'Panoramic Radiography', 'Artificial Intelligence', 'Deep Learning']",국문 초록 정보 없음,"Purpose: Periodontal disease causes tooth loss and is associated with cardiovascular diseases, diabetes, and rheumatoid arthritis. The present study proposes using a deep learning-based object detection method to identify periodontally compromised teeth on digital panoramic radiographs. A faster regional convolutional neural network (faster R-CNN) which is a state-of-the-art deep detection network, was adapted from the natural image domain using a small annotated clinical data- set. Materials and Methods: In total, 100 digital panoramic radiographs of periodontally compromised patients were retrospectively collected from our hospital's information system and augmented. The periodontally compromised teeth found in each image were annotated by experts in periodontology to obtain the ground truth. The Keras library, which is written in Python, was used to train and test the model on a single NVidia 1080Ti GPU. The faster R-CNN model used a pretrained ResNet architecture. Results: The average precision rate of 0.81 demonstrated that there was a significant region of overlap between the predicted regions and the ground truth. The average recall rate of 0.80 showed that the periodontally compromised teeth regions generated by the detection method excluded healthiest teeth areas. In addition, the model achieved a sensitivity of 0.84, a specificity of 0.88 and an F-measure of 0.81. Conclusion: The faster R-CNN trained on a limited amount of labeled imaging data performed satisfactorily in detecting periodontally compromised teeth. The application of a faster R-CNN to assist in the detection of periodontally compromised teeth may reduce diagnostic effort by saving assessment time and allowing automated screening documentation."
Automatic detection of periodontal compromised teeth in digital panoramic radiographs using faster regional convolutional neural networks,2020,"['Alveolar Bone Loss', 'Panoramic Radiography', 'Artificial Intelligence', 'Deep Learning']",국문 초록 정보 없음,"Purpose: Periodontal disease causes tooth loss and is associated with cardiovascular diseases, diabetes, and rheumatoid arthritis. The present study proposes using a deep learning-based object detection method to identify periodontally compromised teeth on digital panoramic radiographs. A faster regional convolutional neural network (faster R-CNN) which is a state-of-the-art deep detection network, was adapted from the natural image domain using a small annotated clinical data- set.Materials and Methods: In total, 100 digital panoramic radiographs of periodontally compromised patients were retrospectively collected from our hospital’s information system and augmented. The periodontally compromised teeth found in each image were annotated by experts in periodontology to obtain the ground truth. The Keras library, which is written in Python, was used to train and test the model on a single NVidia 1080Ti GPU. The faster R-CNN model used a pretrained ResNet architecture.Results: The average precision rate of 0.81 demonstrated that there was a significant region of overlap between the predicted regions and the ground truth. The average recall rate of 0.80 showed that the periodontally compromised teeth regions generated by the detection method excluded healthiest teeth areas. In addition, the model achieved a sensitivity of 0.84, a specificity of 0.88 and an F-measure of 0.81.Conclusion: The faster R-CNN trained on a limited amount of labeled imaging data performed satisfactorily in detecting periodontally compromised teeth. The application of a faster R-CNN to assist in the detection of periodontally compromised teeth may reduce diagnostic effort by saving assessment time and allowing automated screening documentation."
딥러닝 기반 치과 의료영상 판독에 대한 문헌 분석,2020,"['Dentistry', 'Dental disease', 'Artificial intelligence', 'Convolutional neural network', 'Object detection', 'Segmentation']",국문 초록 정보 없음,"This study analyzes the papers, which studied to find the most adequate CNN based algorithms for segmentation, object detection in dentistry. According to our purpose, we created several keywords like “Dental+Object Detection+Neural+Network.” We searched articles in ‘PubMed’, ‘IEEE’, using created 34 keywords. We found 458 papers and excluded under a study-purpose provision. So This paper had categorized those 23 papers by 11 of segmentation of tooth structure with dental filling and FDI numbering, 12 of detecting dental caries, periodontitis, or multiple lesions. To compare the performance of models, we organized the results by DICE/IoU index and accuracy, precision, recall, etc.. Various dataset was used for analyzing. The most common dataset was dental panoramic image, then periapical, CBCT, NILT, and intra-oral image. The algorithms were used according to the purpose. For example, VGG16, 19 was used for object detection algorithms were used according to the purpose. For example, VGG16, 19 was used for object detection, U-Net, and Mask R-CNN used for segmentation by study purpose.For segmentation of teeth, Zhimming Cui(2019), used Mask R-CNN, and the accuracy was 0.9755. Vranck(2020) used ResNet for molar detection(IoU 0.9, precision 0.94, 0.93). To label the tooth numbering according to FDI rule, Tuzoff(2019) and Chen(2019), used Faster R-CNN, VGG16, and Faster R-CNN with DNN. Tuzoff’s index was slightly better than Chen’s. Casalegno(2019) investigated the detection of dental caries by using VGG16. The result was IoU 0.727. To find periodontitis, used VGG16 also, by Prajapaty(2017). And the accuracy was 0.8846. Using the Mask R-CNN, Jader(2018) could separate instances of multiple lesions, accuracy was 0.8846."
정규화 기법을 통한 안면 인식 알고리즘 성능 향상에 관한 연구,2020,"['Computer Vision', 'Deep Learning', 'Face Recognition', 'Safety Management']",국문 초록 정보 없음,"Through the combination of computer vision technology and artificial intelligence, facial recognition technology is drawing attention as a new means of personal authentication in the era of the fourth industry. Facial recognition technology uses imaging equipment to photograph a person""s face and extract characteristic data. The extracted data are matched against the facial features of the stored database. Facial recognition technology is a contactless technology compared to other biometric recognition technologies, which is used in various fields due to its high hygiene, convenience and security, and in particular, safety accidents in workplaces are closely related to life, and various studies related to workplace safety management using intelligent video information are being conducted in the manufacturing industry. In this paper, a study is conducted on the development of facial recognition algorithm using deep learning to control worker access in hazardous areas. The accuracy of the recognition of the proposed facial recognition algorithm (object detection algorithm (SSD) and object recognition algorithm (ResNet)) is closely related to the safety of the operator. Therefore, the goal is to analyze the relationship between various normalization techniques (Min-Max Scaler, MaxAbs Scaler, Standard Scaler) and the recognition rate of the proposed facial recognition algorithm to propose a high-accuracy facial recognition algorithm. In the future, we will conduct research on safety issues in the manufacturing industry based on facial recognition and image recognition technologies."
Effective Hand Gesture Recognition by Key Frame Selection and 3D Neural Network,2020,"['hand gesture recognition', 'dynamic hand gesture', 'key frame extraction', 'action recognition']",국문 초록 정보 없음,"This paper presents an approach for dynamic hand gesture recognition by using algorithm based on 3D Convolutional Neural Network (3D_CNN), which is later extended to 3D Residual Networks (3D_ResNet), and the neural network based key frame selection. Typically, 3D deep neural network is used to classify gestures from the input of image frames, randomly sampled from a video data. In this work, to improve the classification performance, we employ key frames which represent the overall video, as the input of the classification network. The key frames are extracted by SegNet instead of conventional clustering algorithms for video summarization (VSUMM) which require heavy computation. By using a deep neural network, key frame selection can be performed in a real-time system. Experiments are conducted using 3D convolutional kernels such as 3D_CNN, Inflated 3D_CNN (I3D) and 3D_ResNet for gesture classification. Our algorithm achieved up to 97.8% of classification accuracy on the Cambridge gesture dataset. The experimental results show that the proposed approach is efficient and outperforms existing methods."
