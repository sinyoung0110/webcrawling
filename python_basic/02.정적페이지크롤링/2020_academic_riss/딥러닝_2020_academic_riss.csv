title,date,keywords,abstract,multilingual_abstract
딥러닝 관련 발명의 특허법상 보호 방안에 대한 연구,2020,"['딥러닝', '발명의 성립성', '특허 적격성', '소프트웨어 관련 발명컴퓨터 관련 발명', 'Alice 판결', 'Deep learning', 'eligible subject matter as an invention', 'patent eligibility', 'software-related inventions', 'computer-related inventions', 'Alice Case']","딥러닝 기술은 컴퓨터가 사물 등을 구분하기 위한 개념을 가지기 위해 ‘학습’을 수행하며, ‘학습’을 수행하기 위한 학습 모델이 가지는 구조가 깊은 것을 특징으로 한다. 딥러닝 기술은 인간이 개념을 받아들이기 위한 신경적 구조와 활동을 컴퓨터 기술에 접목한 신경망 기술을 기반으로 한다. 최근 그래픽 카드 등 하드웨어의 연산처리 능력이 높아지고 신경망 기술의 이론적 뒷받침이 이루어지면서 딥러닝 기술의 성과가 두드러지게 나타나게 되었다.  본 논문에서는 딥러닝 기술이 가지는 특성을 파악하기 위해 딥러닝 기술에 관한 변천과 주요 딥러닝 기술에 대한 내용 및 이와 관련된 특허권들의 청구범위를 살펴보았다. 또한, 본 논문에서는 딥러닝 기술이 가지는 특성을 감안하여 딥러닝 모델 구조가 변경된 경우와 기존 딥러닝 모델이 특유 목적에 맞게 접목된 경우로 구분하여 딥러닝 관련 발명의 특허 등록 가능성 확보 방안을 검토하였으며, 특허 등록 후 침해 주장 시 입증 용이성을 확보하기 위한 실무적 방안에 대해 검토하였다.  딥러닝 기술과 관련한 발명의 경우 발명의 성립성과 진보성 요건 등 특허성 요건을 판단함에 있어서 컴퓨터 관련 발명의 일종으로 취급될 수 있다. 최근 컴퓨터 관련 발명의 특허 적격성 판단과 관련하여 미국에서의 Alice 판결 등 주요 판례가 주목받고 있고 이에 따라 미국과 우리나라에서의 심사기준에도 변동이 있어 본 논문에서는 컴퓨터 관련 발명의 특허 적격성 판단에 대한 미국 판례의 변천을 살펴본 후 우리나라의 특허법 규정 및 2019년 3월 개정된 특허청의 특허․실용신안 심사기준을 검토하였다.","Deep learning is a technology to perform “learning” so that computers can adopt concepts to distinguish objects and the like. Deep-learning technology is characterized in that the structures of learning models for performing “learning” are “deep”. Deep-learning technology is based on neural-network technology in which neural structures and activities that enable human beings to accommodate concepts are grafted onto the computer technology. Recently, neural network technology has been underpinned by theory owning to the increased operational processing capacity of hardware units such as graphics cards, and remarkable performance of deep-learning technology has been exhibited.  In order to understand the properties of deep-learning technology, changes in deep-learning technology, major aspects of deep-learning technology, and the claims of patented inventions relating to deep-learning technology are reviewed in this paper. Also, considering the properties of deep-learning technology, cases are divided into cases where deep-learning model structures are changed and cases where conventional deep-learning models are grafted onto deep-learning technology so as to comply with specific objectives. On this basis, how to secure the patentability of deep-learning-related inventions is reviewed in this paper, and how to easily demonstrate patent infringement after the deep-learning-related inventions are patented is also reviewed in practical terms.In the case of deep-learning-related inventions, they may be handled as a kind of computer-related inventions when the patentability requirements thereof are determined in terms of whether the subject matters thereof establishes inventions and they meet inventiveness requirements, etc.. Recently, with respect to the patent eligibility determination of computer-related inventions, important precedents including the Alice Corp. judgment in the United States have drawn attention, and examination guidelines in the United States and Korea have changed accordingly. In this regard, in this paper I review changes in US precedents on patent eligibility determination of computer-related inventions, and then review the Korean Patent Act and patent and utility model examination guidelines, which were revised in March 2019 by the Korean Intellectual Property Office."
딥러닝 모형을 활용한 공공자전거 대여량 예측에 관한 연구,2020,"['딥러닝', '자전거', '예측', 'LSTM', '수요', 'Deep learning', 'Bicycle', 'Forecasting', 'Long short-term memory', 'Demand']","본 연구는 공공자전거의 대여량을 예측하는 딥러닝 모형을 개발하였다. 이를 위하여 공공자전거 대여량 자료, 기상 자료, 그리고 지하철 이용량 자료를 수집하였다. 지수평활 모형, ARIMA 모형과 LSTM기반의 딥러닝 모형을 구축한 후 MSE와 MAE 평가 지표를 사용하여 예측 오차를 비교·평가하였다. 평가 결과, 지수평활 모형으로 MSE 348.74, MAE 14.15 값이 산출되었다. ARIMA 모형으로 MSE 170.10, MAE 9.30 값을 얻었다. 그리고 딥러닝 모형으로 MSE 120.22, MAE 6.76 값이 산출되었다. 지수평활 모형의 값과 비교하여 ARIMA 모형의 MSE는51%, MAE는 34% 감소하였다. 그리고 딥러닝 모형의 MSE는 66%, MAE는 52% 감소하여 딥러닝 모형의 오차가 가장 적은 것으로 파악되었다. 이러한 결과로부터 공공자전거 대여량 예측분야에서 딥러닝 모형의 적용시 예측 오차를 크게 감소시킬 수 있을 것으로 판단된다.","This study developed a deep learning model that predicts rental demand for public bicycles. For this, public bicycle rental data, weather data, and subway usage data were collected. After building an exponential smoothing model, ARIMA model and LSTM-based deep learning model, forecasting errors were compared and evaluated using MSE and MAE evaluation indicators. Based on the analysis results, MSE 348.74 and MAE 14.15 were calculated using the exponential smoothing model. The ARIMA model produced MSE 170.10 and MAE 9.30 values. In addition, MSE 120.22 and MAE 6.76 values were calculated using the deep learning model. Compared to the value of the exponential smoothing model, the MSE of the ARIMA model decreased by 51% and the MAE by 34%. In addition, the MSE of the deep learning model decreased by 66% and the MAE by 52%, which was found to have the least error in the deep learning model. These results show that the prediction error in public bicycle rental demand forecasting can be greatly reduced by applying the deep learning model."
딥러닝 CNN 알고리즘 기반의 충격 위치 분석,2020,"['NDT(비파괴 검사)', 'Impact Location(충격 위치)', 'Deep Learning(딥러닝)', 'Structural Health Monitoring(구조 건전성 감시)']","최근 금속 재료 등의 표면에 충격 현상이 발생할 때 충격 위치를 검출할 수 있는 다양한 연구 시도들이 이루어지고 있으며 이러한 시도들 중, 충격 시 발생하는 응력파의 도달 시간 차이를 이용하는 방법은 가장 일반화된 방법이다. 그러나 검사의 정확도를 높이기 위한 정확한 응력파 도달 시간 측정시 많은 어려움이 발생한다. 따라서 본 논문에서는 응력파 신호에서 응력파 도달 시간에 대한 정보를 별도로 추출하지 않고 PZT 센서로 측정한 응력파 신호의 이미지를 직접 딥러닝 기법으로 학습시켜 충격 위치에 따른 응력파의 신호 특성을 찾아내는 시도를 하였다. 이때 딥러닝 학습 변수인 에포크(epoch)의 변화에 따른 측정 정확도를 파악하였고 이를 바탕으로 1m×1m의 알루미늄 평판에서 발생하는 충격의 위치를 찾아낼 수 있는 딥러닝 학습 알고리즘을 제시하였다. 이를 통해, 딥러닝 기법을 활용한 이미지 기반 비파괴 검사 기법을 새롭게 제안하고 이를 성공적으로 검증하였다.","Recently, various studies have attempted to detect the locations of impacts on metal surfaces. The most generalized method uses the time difference between the generation of the stress wave during impact and its arrival at the surface. However, accurate measurement of the arrival time of a stress wave is fraught with difficulties. To address this issue, in this paper, we attempt to identify the signal characteristics of a stress wave corresponding to the impact location by learning the image of the stress wave signal, as measured by a Piezoelectric sensor, via deep learning without directly extracting information about the wave""s arrival time. To improve the accuracy of the measurement used in deep learning, we appropriately optimize the epoch variable and present a deep learning-based algorithm to measure the location of the impact on an aluminum plate of dimensions 1 m × 1 m. As a result, the proposed image-based NDT is successfully verified."
의료 영상에 최적화된 딥러닝 모델의 개발,2020,"['Deep Learning', 'Algorithms', 'Data Collection', 'Product Labeling', 'Diagnostic Imaging']","최근, 의료 영상 분야에서 딥러닝은 가장 활발하게 연구되고 있는 기술 중 하나이다. 충분한데이터와 최신의 딥러닝 알고리즘은 딥러닝 모델의 개발에 중요한 요소이다. 하지만 일반화된 최적의 딥러닝 모델을 개발하기 위해서는 데이터의 양과 최신의 딥러닝 알고리즘 외에도많은 것을 고려해야 한다. 데이터 수집부터 가공, 전처리, 모델의 학습 및 검증, 경량화까지 모든 과정이 딥러닝 모델의 성능에 영향을 미칠 수 있기 때문이다. 본 종설에서는 의료 영상에최적화된 딥러닝 모델을 위해 개발 과정 각각에서 고려해야 할 중요한 요소들을 살펴보고자한다.","Deep learning has recently become one of the most actively researched technologies in the field of medical imaging. The availability of sufficient data and the latest advances in algorithms are important factors that influence the development of deep learning models. However, several other factors should be considered in developing an optimal generalized deep learning model. All the steps, including data collection, labeling, and pre-processing and model training, validation, and complexity can affect the performance of deep learning models.Therefore, appropriate optimization methods should be considered for each step during the development of a deep learning model. In this review, we discuss the important factors to be considered for the optimal development of deep learning models."
digo: 생산성 향상을 위한 딥러닝 실험 관리 시스템,2020,"['기계학습', '시각화', '실험 관리', '협업', '자동 최적화', '딥러닝', 'Machine Learning', 'Visualization', 'Experiment Management', 'Auto Optimization', 'Deep Learning']","최근 인공지능을 활용한 서비스 고급화는 선택이 아닌 필수가 되었다. 그에 따라 인공지능의 연구도 가속화되어 효 율적인 인공지능 연구를 위한 방법 또한 주목 받고 있다. 대표적인 방법으로는 연구 과정에서 효과적으로 실험을 관 리할 수 있는 도구를 사용하는 것이다. 기존의 딥러닝 연구는 파편적인 작업 방식을 기반으로 한 협업과 학습 결과 최적화를 위한 반복 작업으로 인해 비효율적이었다. 본 연구는 이러한 문제점을 개선하기 위해 인공지능 분야 중 딥 러닝에 초점을 맞추어 편리하고 생산적인 연구 환경을 제공할 수 있는 협업 기반의 딥러닝 실험 관리 도구인 digo(dig와 go의 합성어로 반복적인 딥러닝 연구를 표현하는 단어를 조합)를 설계 및 구현하였다. 기계학습 연구자 들을 대상으로 실험 및 설문조사를 실시하여 딥러닝 실험 관리 도구의 성능을 검증하였고, 하이퍼 파라미터 자동 최 적화 및 학습 결과 시각화 기능의 편의성을 확인하였다.","Recently, advanced service using artificial intelligence has become a necessity, not an option. As a result, research on artificial intelligence has been accelerated, drawing attention to methods for efficient artificial intelligence research. A typical method is to use tools to effectively manage experiments in the course of the study. Existing deep learning studies have been inefficient due to collaboration based on fragmentary work methods and repetitive tasks for optimizing learning results. To improve these problems, this work designs and implements Digo(a combination of words that represent repetitive deep learning research as a compound word of dig and go), a collaborative-based deep learning experiment management tool that can provide a convenient and productive research environment, focusing on deep learning among artificial intelligence. Experiments and surveys were conducted on machine learning researchers to validate the performance of deep learning experimental management tools, and to confirm the convenience of hyperparameter automatic optimization and learning result visualization features."
시공간적 영향력을 반영한 딥러닝 기반의 통행속도 예측 모형 개발,2020,"['딥러닝', 'LSTM', '통행속도 예측', '빅데이터', '4차 산업혁명', 'Deep learning', 'LSTM', 'Travel speed prediction', 'Big data', 'The fourth industrial revolution']","4차 산업혁명 시대가 도래함에 따라 빅데이터를 활용하는 딥러닝에 대한 관심이 높아졌으며 다양한 분야에서 딥러닝을 이용한 연구가 활발하게 진행되고 있다. 교통 분야에서도 교통빅데이터를 많이 활용하는 만큼 딥러닝을 연구에 이용한다면 많은 이점이 있을 것이다. 본 연구에서는 통행속도를 예측하기 위하여 딥러닝 기법인 LSTM을 이용한 단기 통행속도 예측 모형을 구축하였다. 예측에 활용한 데이터인 통행속도 데이터가 시계열 데이터인 것을 고려하여시계열 예측에 적합한 LSTM 모델을 선택하였다. 통행속도를 보다 정확하게 예측하기 위하여시간적, 공간적 영향을 모두 반영하는 모형을 구축하였으며, 모형은 1시간 이후를 예측하는 단기 예측모형이다. 분석데이터는 서울시 교통정보센터에서 수집한 5분 단위 통행속도를 활용하였고 분석구간은 교통이 혼잡한 강남대로 일부구간으로 선정하여 연구를 수행하였다.","With the advent of the fourth industrial revolution era, there has been a growing interest in deep learning using big data, and studies using deep learning have been actively conducted in various fields. In the transportation sector, there are many advantages to using deep learning in research as much as using deep traffic big data. In this study, a short –term travel speed prediction model using LSTM, a deep learning technique, was constructed to predict the travel speed. The LSTM model suitable for time series prediction was selected considering that the travel speed data, which is used for prediction, is time series data. In order to predict the travel speed more precisely, we constructed a model that reflects both temporal and spatial effects. The model is a short-term prediction model that predicts after one hour. For the analysis data, the 5minute travel speed collected from the Seoul Transportation Information Center was used, and the analysis section was selected as a part of Gangnam where traffic was congested."
딥러닝을 이용한 주택 경매시장 예측에 관한 연구,2020,"['주택', '경매', 'GARCH 모형', '딥러닝', '예측.', 'Housing', 'Auction', 'Garch Model', 'Deep Learning', 'Prediction.']","본 연구는 주택 경매시장을 GARCH모형과 딥러닝 모형을 이용해 추정한 후 예측력의 우수성을 판별하고자 한다. 사용변수는 아파트경매낙찰가율, 아파트매매가격지수, 아파트 낙찰율, 회사채수익률, 소비자물가지수와 건축허가현황 주거용으로 하였고 공간적 범위는 서울시로, 시간적 범위는 2002년 1월부터 2019년 11월까지로 설정하여 분석하였다. 분석결 과, 딥러닝 모형의 평균오차(MSE)와 평균제곱근오차(RMSE)는 각각 38.095와 6.172로 나타 났고 GARCH모형의 평균오차(MSE)와 평균제곱근오차(RMSE)는 각각 42.867, 6.547로 나 타나 GARCH모형 보다 딥러닝 모형의 예측력이 더 우수한 것을 실증적으로 확인하였다. 또한, 아파트경매낙찰가율이 급격히 하락한 2019년 2월부터 2019년 3월에 딥러닝 모형의 예측력은 정확한 반면 GARCH모형으로 예측한 결과는 비교적 평활하게 나타났다.","The purpose of this study is to estimate the superiority of predictive power after estimating the housing auction market using GARCH model and deep learning model. The variables used were apartment auction bid rate, apartment sales price index, apartment bid rate, corporate bond yield, consumer price index, and building permit status. The spatial range was set to Seoul, and the time range was set from January 2002 to November 2019. The results showed that the mean error (MSE) and root mean square error (RMSE) of the deep learning model were 38.095 and 6.172, and the mean error (MSE) and mean root error (RMSE) of the GARCH model were 42.867 and 6.547. It is confirmed empirically that the deep learning RNN model has better predictive power than the GARCH model. In particular, from February 2019 to March 2019, when the apartment auction bid rate fell sharply, the deep learning model predicted accurate, while the GARCH model predicted relatively smooth results."
딥러닝 알고리즘 기반의 차량번호 인식 프로그램 개발,2020,"['딥러닝', '합성곱 신경망', '앵커박스', '불법주정차', 'Deep Learning', 'Convolution Neural Network', 'Anchor Box', 'Illegal Parking']","최근 도심지 불법주정차 단속업무를 비롯하여 다양한 분야에서 CCTV 영상을 활용한 차량번호 인식에 관한 연구가 진행되고 있다. 본 연구에서는 합성곱 신경망 기반의 딥러닝 알고리즘을 활용하여 차량번호를 인식하는 프로그램을 개발하였다. 주요 연구 성과로서는 SSD 알고리즘을 활용하여 차량 및 번호판 영역을 검출하는 기술을 개발하였으며 학습데이터를 이용하여 훈련한 결과 약 99.5%의 높은 정확도를 확보할 수 있었다. 또한 기하학적 변형, 광학적 변형, 탄성학적 변형을 개선하는 데이터 확장 알고리즘을 개발하여 딥러닝 기반의 차량번호 인식에 활용되는 특징맵을 생성하였다. 그리고 앵커박스 및 딥러닝 기반의 합성곱 신경망 알고리즘을 적용한 결과 차량번호 인식 정확도가 98.5%로 매우 높게 나타남을 알 수 있었다. 본 연구에서는 실시간 차량 모니터링을 비롯하여 통계분석 그리고 차량번호를 실시간으로 인식할 수 있는 프로그램을 개발하였다. 개발한 프로그램을 활용하여 비트 레이트값의 변화에 따른 차량인식 정확도를 비교 평가하였으며, GS 인증을 위한 실험에서도 97% 이상의 높은 정확도를 확보할 수 있었다. 따라서 본 연구에서 개발한 차량번호 인식 프로그램은 불법주정차 단속업무를 비롯하여 체납차량 추적 등 다양한 분야에 활용될 수 있을 것으로 판단된다.","Recently, research has been conducted on the identification of vehicle numbers using CCTV images in various fields including illegal parking control in downtown areas. In this study, we developed a program that recognizes vehicle numbers using deep learning algorithms based on CNN. As a major research achievement, we developed a technology that detects the vehicle and license plate area using the SSD algorithm, and as a result of training using a learning date, a high accuracy of about 99.5% was secured. In addition, by developing a data expansion algorithm that improves geometric deformation, optical deformation, and elastic deformation, a feature map used for deep learning-based vehicle number recognition was generated. And as a result of applying CNN algorithm based on anchor box and deep learning, it was found that the vehicle number recognition accuracy was very high at 98.5%. In this study, we developed a program that can recognize real-time vehicle monitoring, statistical analysis, and vehicle number in real time. By using the developed program, vehicle recognition accuracy according to the change of the bit rate value was compared and evaluated, and in the experiment for GS certification, high accuracy of more than 97% was secured. Therefore, it is judged that the vehicle number recognition program developed in this study can be used in various fields such as illegal parking control and tracking overdue vehicles."
퍼지자료를 이용한 딥러닝 분석,2020,"['딥러닝', '퍼지자료', '회귀분석', '퍼지딥러닝', 'Deep learning', 'Fuzzy data', 'Regression analysis', 'Fuzzy deep learning']","빅데이터 처리에 가장 많이 사용되는 인공지능 기법 중 하나는 딥러닝으로, 경험이나 새로 추가된 데이터로 분석과 패턴을 점점 더 잘 익히는 자기 적응형 알고리즘이다. 딥러닝에서는 주로 분류, 회귀분석, 클러스터링 등을 실시할 수 있는데, 빅데이터로 수집되는 자료 중에서도 애매한 정보를 가지고 있는 퍼지자료로 관찰되는 자료들이 매우 많다. 본 논문에서는 퍼지자료를 딥러닝으로 분석해보고 이를 해석하며 애매한 정보를 정보의 손실없이 최대한 활용하는 방법에 대해 알아본다.","One of the most commonly used artificial intelligence techniques in big data processing is deep learning, a self-adaptive algorithm that learns analysis and pattern better and better with experience or newly added data. In deep learning, classification, regression analysis, clustering, etc. can be carried out mainly, and among the data collected by big data, there are a lot of data that are observed as fuzzy materials with ambiguous information. In this paper, we analyze the fuzzy material with deep learning and interpret it and find out how to make the most of the ambiguous information without loss of information."
드론 영상 기반 딥러닝 알고리즘을 이용한 불법 주정차 번호 인식 기술,2020,"['딥러닝 알고리즘', '불법 주정차', '드론 영상', '합성곱 신경망', 'Deep Learning Algorithm', 'Illegal Parking and Stopping', 'Drone Image', 'Convolution Neural Network']","최근 도시개발에 따른 불법 주정차 문제는 화재나 응급환자 발생시 교통 흐름을 방해하여 막대한 인명 및 재산피해를 가져오고 있다. 본 연구에서는 이러한 문제를 개선하기 위해 드론 영상 기반의 딥러닝 알고리즘을 이용하여 불법 주정차 번호를 인식하는 연구를 수행하였다. 먼저 50,232개의 차량 번호 학습자료를 구축하였으며 Single Shot Multi-Detector 알고리즘을 이용하여 차량 및 번호판 영역을 식별하였다. 또한 데이터 확장 알고리즘을 이용하여 경사지거나 비틀어진 번호판을 정형화시켰으며, 최종적으로 앵커박스 생성 및 딥러닝 기반의 차량번호 인식기술을 개발하였다. 본 연구에서는 불법 주정차 단속 업무를 효과적으로 지원하기 위해 Visual Studio 2017 환경에서 C++와 C# 언어를 이용하여 차량번호를 자동으로 인식할 수 있는 프로그램도 개발하였으며, 자체 테스트한 차량번호 인식 정확도는 99.4%로 매우 높게 나타났다. 불법 주정차 번호 인식을 위해 전주시 6개 노선을 선정하였으며 드론을 통해 해상도별 영상자료를 구축하였다. 딥러닝 알고리즘을 이용하여 차량 인식 정확도를 평가한 결과 불법 주정차된 64대의 차량 중 62대를 인식하여 96.9%의 높은 인식률을 확보할 수 있었다. 다만 전체 훈련자료 중 약 1.6%로 상대적으로 훈련자료가 부족한 세자리 숫자 번호판이 위치한 노선에서는 차량을 인식하지 못하는 한계를 보였으며, 향후 연구에서는 많은 학습자료 구축을 통해 정확도를 향상시킬 계획이다.","Recently, the problem of illegal parking and stopping caused by urban development has caused enormous human and property damage by obstructing the traffic flow in case of fire or emergency patients. In this study, in order to improve this problem, a study was conducted to recognize illegal parking car numbers using a deep learning algorithm based on drone images. First, 50,232 vehicle numbers of various types were constructed as learning data, and the vehicle and license plate areas were identified using the Single Shot Multi-Detector algorithm. In addition, we developed a data expansion algorithm that formalizes inclined or twisted license plates for optimal anchor box and deep learning algorithm application. And finally, an anchor box creation and deep learning-based vehicle number recognition technology were developed. In this study, a program that can automatically recognize vehicle numbers using C++ and C# languages in the Visual Studio 2017 environment was also developed to effectively support illegal parking and stopping enforcement work. In addition, the self-tested vehicle number recognition accuracy was very high at 99.4%. For the recognition of illegal parking and stop car numbers, six routes in Jeonju were selected as a representative. And image data by resolution were constructed through drone photography. As a result of analysis through a deep learning algorithm, 62 out of 64 illegally parked and stopped vehicles were recognized, ensuring a high accuracy of 96.9%. However, about 1.6% of the total training data showed a limitation in not being able to recognize vehicles on the route where the three-digit license plate was relatively insufficient. And in future studies, it is necessary to improve the accuracy by securing many learning materials."
딥러닝을 활용한 정부 R&D 기업지원효과 예측 분석,2020,"['SME', 'R&D Support', 'Selection Model', 'Prediction', 'Deep Learning', '중소기업 R&D', '기업지원효과', '선정평가', '예측모형', '딥러닝']","정부 R&D 지원은 수혜기업의 평균적인 매출액 증가, 고용 증가, R&D 투자 증가 등에 있어 긍정적인 정책효과를가져오는 것으로 알려져 있다. 하지만 개별 기업 단위에서 살펴보면 기업의 특성에 따라 그 효과는 유의하지 않거나부(-)의 효과를 가지기도 한다. 즉, 기업 특성에 따른 수혜효과의 이질성이 나타나게 된다. 이러한 측면에서 각 기업지원에 대한 개별적 사전적 예측의 필요성이 제기되고 있다.본 연구에서는 국가연구개발사업 정보와 기업 정보를 바탕으로 기업지원 효과에 대해 사전 예측하는 딥러닝 모형의개발 가능성을 탐색하였다. 먼저 PSM 방법론을 활용하여 정부 R&D 미수혜기업 대비 수혜기업의 매출액, R&D투자, 고용 지표에 대한 정책효과를 산출하였으며, 이 분석 결과를 기반으로 딥러닝 모형을 학습시켜 기업지원 효과를예측하는 모형을 구현하였다.딥러닝 모형의 예측 성능 및 특징을 분석한 결과, 딥러닝 모형은 적절한 수혜기업 선정에 기여할 수 있는 성능 특성을 가진 것으로 나타났다. 정책효과를 양수와 음수로 구분하였을 때 테스트 데이터셋을 기준으로 60%~77% 가량의 예측 정확도를 가지는 것으로 나타났다. 로짓모형을 통한 분석과 비교하였을 때 예측 정확도 면에서 향상되었음을 확인하였다. 또한, 긍정편향적 예측 특성이 크게 개선되었으며 보다 넓은 기업군에 대해 예측을 수행 가능 한 것으로 나타났다. 딥러닝에 기반한 R&D 수혜기업 선정 모형은 적용 가능성과 효용성이 높다는 측면에서 향후 효율적이고 객관적인 선정 평가에 기여할 수 있을 것으로 보인다.","We explored the possibility of developing a deep learning model that predicts the effects of enterprise support based on national R&D project information and company information. As a result of applying the deep learning model, it was found that the deep learning has a performance characteristic that can contribute to improve the accuracy of proper company selection. When the policy effect is divided into positive and negative, it has a prediction accuracy of 60% ~ 77% based on test data not used for learning. As a result of this study, the R&D beneficiary selection model based on the deep learning technique has high operability and application necessity"
딥러닝 기반 지하공동구 화재 탐지 모델 개발 : 학습데이터 보강 및 편향 최적화,2020,"['Underground Utility Facility', 'Fire Detection', 'Deep Learning', 'Convolutional Neural Network', 'Bias Training']","화재는 높은 비정형성으로 인해 딥러닝 모델을 이용한 영상인식 분야에서도 좋은 성능을 내기가 어려운 대상 중 하나이다. 특히 지하공동구 내 화재는 딥러닝 모델의 학습을 위한 화재 데이터 확보가 어렵고 열약한 영상 조건 및 화재로 오인할 수 있는 객체가 많아 화재 검출이 어렵고 성능이 낮다. 이러한 이유로 본 연구는 딥러닝 기반의 지하공동구 내 화재 탐지 모델을 제안하고, 제안된 모델의 성능을 평가하였다. 기존 합성곱 인공신경망에 GoogleNet의 Inception block과 ResNet의 skip connection을 조합하여 어두운 환경에서 발생되는 화재 탐지를 위한 모델 구조를 제안하였으며, 제안된 모델을 효과적으로 학습시키기 위한 방법도 함께 제시하였다. 제안된 방법의 효과를 평가하기 위해 학습 후 모델을 지하공동구 및 유사환경 조건의 화재 문제와 화재로 오인할 수 있는 객체를 포함한 이미지에 적용해 결과를 분석하였다. 또한 기존 딥러닝 기반 화재 탐지 모델의 정밀도, 검출률 지표와 비교함으로써 모델의 화재 탐지성능을 정량적으로 평가하였다. 제안된 모델의 결과는 어두운 환경에서 발생되는 화재 문제에 대해 높은 정밀도와 검출률을 나타내었으며, 유사 화재 객체에 대해 낮은 오탐 및 미탐 성능을 가지고 있음을 보여주었다.","Fire is difficult to achieve good performance in image detection using deep learning because of its high irregularity. In particular, there is little data on fire detection in underground utility facilities, which have poor light conditions and many objects similar to fire. These make fire detection challenging and cause low performance of deep learning models. Therefore, this study proposed a fire detection model using deep learning and estimated the performance of the model. The proposed model was designed using a combination of a basic convolutional neural network, Inception block of GoogleNet, and Skip connection of ResNet to optimize the deep learning model for fire detection under underground utility facilities. In addition, a training technique for the model was proposed. To examine the effectiveness of the method, the trained model was applied to fire images, which included fire and non-fire (which can be misunderstood as a fire) objects under the underground facilities or similar conditions, and results were analyzed. Metrics, such as precision and recall from deep learning models of other studies, were compared with those of the proposed model to estimate the model performance qualitatively. The results showed that the proposed model has high precision and recall for fire detection under low light intensity and both low erroneous and missing detection capabilities for things similar to fire."
생성적 적대 신경망과 딥러닝을 활용한 이상거래탐지 시스템 모형,2020,"['이상거래탐지', '딥러닝', '생성적 적대 신경망', 'Fraud Detection System', 'Deep Neural Net', 'Convolutional Neural Net', 'Generative Adversarial Network']","인공지능이 다루기 어려운 개념에서 아주 익숙한 도구로 자리매김 하고 있다. 이와 더불어 금융권에서도 인공지능 기술을 도입하여 기존 시스템의 문제점을 개선하고자 하는 추세이며, 그 대표적인 예가 이상거래탐지 시스템(Fraud Detection System, FDS)이다. 결제 수단의 다양화 및 전자금융거래의 증가에 따라 치밀해져 가는 사이버 금융사기(Fraud)를 기존의 규칙기반 FDS로는 탐지하기 어려워지고 있다. 이를 극복하기 위해 딥러닝 기술을 적용하여 이상거래 탐지율을 향상시키고, 이상행위에 즉각 대응하며, 탐지 결과의 반영을 자동화하고자 하는 시도가 이루어지고 있다. 딥러닝 FDS 구축에서 핵심 문제는 데이터 불균형과 이상거래 패턴의 변동이다. 본 논문에서는 생성적 적대 신경망(Generative Adversarial Network, GAN)을 활용한 오버샘플링 기법을 통해 데이터 불균형 문제를 개선하고, 이상거래 분류기로써 심층 신경망(Deep Neural Network, DNN)과 합성곱 신경망(Convolutional Neural Network, CNN)을 적용하여 이러한 문제를 개선하고자 하였다. 실험 결과, GAN 오버샘플링이 이상거래 데이터의 불균형 문제를 개선하는데 효과를 보였으며, WGAN이 가장 높은 개선 효과가 있음을 확인하였다. 또한 제안 FDS 모형의 AUC가 0.9857로 랜덤포레스트 FDS 모형에 비해 약 6.5% 향상되어, 딥러닝이 이상거래 탐지에 뛰어난 성능을 가짐을 입증하였다. 더불어 딥러닝 모형 중 DNN은 CNN에 비해 오버샘플링의 효과를 더 잘 반영함을 확인하였다.",
장기체공형 태양광 드론과 딥러닝을 이용한 산불 감시 시스템 개발,2020,"['Solar Powered Drone', 'Deep Learning', 'Object Detection', 'Abnormal Signs', 'Realtime Georeferencing', '태양광 드론', '딥러닝', '객체탐지', '산불', '이상징후', '실시간 위치 결정']","매년 빈번하게 산불이 발생하고, 이로 인한 피해 규모도 지속해서 증가하고 있다. 최근 산불피해를 줄이기 위해 능동적 운영이 가능한 드론을 이용해 산불을 감시하려는 시도가 활발하게 이루어지고 있다. 본 연구의 목적은 넓은 영역을 장시간 관찰해야 하는 산불 감시 업무를 효율적으로 수행하기 위해 드론과 딥러닝 기반 산불 감시 시스템을 개발하고 이에 대한 실용성을 검증하는 것이다. 이를 위해 첫째, 태양광 드론에 임무 장비를 탑재하여 넓은 영역을 장시간 감시할 수 있는 산불 감시용 드론을 개발하였다. 둘째, 불, 연기 자동차, 빌딩, 사람, 무덤 등 6가지 산불 위험요소를 정의하고, 딥러닝을 통해 산불 위험요소를 탐지한 후 실시간 위치 결정 알고리즘을 적용하였다. 마지막으로 구현된 각 알고리즘을 통합된 시스템으로 구현하고 정확도를 측정하여 실용성을 검증하였다. 개발된 태양광 드론은 임무 장비를 탑재하고 12시간을 안정적으로 비행하였다. 딥러닝을 이용한 산불 발생 위험요소에 대한 평균 탐지 정확도는 50.1%로 측정되었으며, 탐지된 객체의 위치 결정 정확도는 25m로 측정되었다. 영상 촬영, 전송, 딥러닝 추론, 매핑, 가시화까지 걸린 평균시간은 4.7초로 측정되었다. 본 연구의 내용이 산불 예방 및 조기 감시와 같은 산불 감시의 신속성을 높일 수 있을 것으로 기대된다.","Forest fire has been occurred frequently every year and the damage is increasing continuously. Recently attempts have been made to monitor forest fires using drones that can be actively operated to reduce this damage. The aim of this study is to develop and verify a forest fire monitoring system based on a drone and deep learning to monitor vast forest areas for a long time. For this, first, we developed the forest fire monitoring drone that can fly for a long term over area using a solar powered drone with mission equipment. Second we defined fire, smoke, car, building, human, cemetery as risk factors of forest fire, trained deep learning model for these six classes and applied a realtime mapping algorithm. Finally we integrated these algorithms and verified practicality. As a result, the solar powered drone flied successfully for 12 hours. The detection accuracy of the trained deep learning model was 50.1% and the positioning accuracy was 25m. It takes 4.7 seconds to capture, transfer, inference and implement georeference. We expect that this study will improve the speed of forest fire monitoring, such as forest fire prevention and early monitoring."
지능형 클라우드 환경에서 지각된 가치 및 행동의도를 적용한 딥러닝 기반의 관광추천시스템 설계,2020,"['지능형 클라우드', '지각된 가치', '관광 행동의도', '와이드 앤 딥러닝', '관광추천 시스템', 'Intelligent cloud', 'perceived value', 'Tourism Behavior Intention', 'wide and deep learning', 'tourism recommendation system']","본 논문은 지각된 가치가 적용된 관광 행동의도 정보를 이용한 지능형 클라우드 환경에서의 관광추천시스템을 제안한다. 이 제안 시스템은 관광정보와 관광객의 지각적 가치가 행동의도에 반영되는 실증적 분석 정보를 와이드 앤 딥러닝 기술을 이용하여 관광추천시스템에 적용하였다. 본 제안 시스템은 다양하게 수집할 수 있는 관광 정보와 관광객이 평소에 지각하고 있던 가치와 사람의 행동에서 나타나는 의도를 수집 분석하여 관광 추천시스템에 적용하였다. 이는 기존에 활용되던 다양한 분야의 관광플랫 폼에 관광 정보, 지각된 가치 및 행동의도에 대한 연관성을 분석하고 매핑하여, 실증적 정보를 제공한 다. 그리고 관광정보와 관광객의 지각적 가치가 행동의도에 반영되는 실증적 분석 정보를 선형 모형 구성요소와 신경만 구성요소를 합께 학습하여 한 모형에서 암기 및 일반화 모두를 달성할 수 있는 와이드앤 딥러닝 기술을 이용한 관광추천 시스템을 제시하였고, 파이프라인 동작 방법을 제시하였다. 본 논문 에서 제시한 추천시스템은 와이드 앤 딥러닝 모형을 적용한 결과 관광관련 앱 스토어 방문 페이지 상의앱 가입률이 대조군 대비 3.9% 향상했고, 다른 1% 그룹에 변수는 동일하고 신경망 구조의 깊은 쪽만 사용한 모형을 적용하여 결과 와이드 앤 딥러닝 모형은 깊은 쪽만 사용한 모형 대비해서 가입률을 1% 증가하였다. 또한, 데이터셋에 대해 수신자 조작 특성 곡선 아래 면적(AUC)을 측정하여, 오프라인 AUC 또한 와이드 앤 딥러닝 모형이 다소 높지만 온라인 트래픽에서 영향력이 더 강하다는 것을 도출하였다.","This paper proposes a tourism recommendation system in intelligent cloud environment using information of tourist behavior applied with perceived value. This proposed system applied tourist information and empirical analysis information that reflected the perceptual value of tourists in their behavior to the tourism recommendation system using wide and deep learning technology. This proposal system was applied to the tourism recommendation system by collecting and analyzing various tourist information that can be collected and analyzing the values that tourists were usually aware of and the intentions of people's behavior. It provides empirical information by analyzing and mapping the association of tourism information, perceived value and behavior to tourism platforms in various fields that have been used. In addition, the tourism recommendation system using wide and deep learning technology, which can achieve both memorization and generalization in one model by learning linear model components and neural only components together, and the method of pipeline operation was presented. As a result of applying wide and deep learning model, the recommendation system presented in this paper showed that the app subscription rate on the visiting page of the tourismrelated app store increased by 3.9% compared to the control group, and the other 1% group applied a model using only the same variables and only the deep side of the neural network structure, resulting in a 1% increase in subscription rate compared to the model using only the deep side. In addition, by measuring the area (AUC) below the receiver operating characteristic curve for the dataset, offline AUC was also derived that the wideanddeep learning model was somewhat higher, but more influential in online traffic."
딥러닝 기반 제품에 대한 소비가치가 수용에 미치는 영향: 기독교적 종교성의 조절효과,2020,"['기독교적 종교성', '인공지능', 'GAN', '가치이론', '구매 의도', '추천 의도', 'Religiousness', 'Artificial Intelligence', 'Value Theory', 'Purchase Intention', 'Intention to Recommend']","최근 딥러닝 등 인공지능 기술이 발전함에 따라 판별적 기능 외에도 새로운 아이디어나 미디어를 창출하는 생성적 기능이 가능한 기술이 개발되어 제품 제작 등에 적용되기 시작하고 있어 새로운 제품에 대한 생산성 증대에 대한 기대가 커지고 있다. 하지만 아직 생성형 인공지능에 대해서는 딥페이크 등 그 활용 측면에서의 부정적인 시각도 있어 과연 이 기술이 안정적으로 수용될지는 미지수다. 더욱이 생성형 인공지능에 대한 기독교인의 평가와 수용이 비기독교인과 차이가 있을지도 그 흥미에 비해 거의 알려지지 않고 있다. 따라서 본 연구는 기독교적 종교성이 인공지능 제품의 수용에 미치는 연구의 후속연구로서 인공지능 중에서 생성형 인공지능인 cycleGAN 딥러닝 기술이 반영된 제품에 대한 평가에 기독교적 종교성이 미치는 영향을 검증하는 것이 목적이다. 특히 딥러닝 기반 제품에 대하여 소비자가 느끼는 소비 가치가 그 제품의 수용에 미치는 영향에서 기독교적 종교성이 조절 효과의 역할을 하는지를 실증 분석하려고 한다. 이를 위해 163명 20, 30대 소비자들에게 cycleGAN이라고 하는 딥러닝 기술이 제작한 의류 제품 평가에 대한 설문 결과 기독교인은 기능적 가치에서, 그리고 비기독교인은 사회적 가치와 감정적 가치에서 제품수용에 대해서 유의하게 영향을 주며, 추천 의도에 대해서는 기독교인의 경우 기능적 가치와 사회적 가치에서, 비기독교인은 감정적 가치에서 제품에 대한 추천 의도에 유의한 영향을 주는 것으로 밝혀졌다.","Recently, as artificial intelligence such as deep learning has developed, it is beginning to be applied to product production, such as creating new ideas or media. Correspondingly, the expectation for increasing productivity of new products is increasing. However, there is still a negative opinion on the use of deep learning such as deep fake, and it is still not obvious whether the technology will be accepted. In addition, little has been known about the interests of Christians in their evaluation and acceptance of deep learning-based products. As a follow-up study of religiousness on the acceptance of artificial intelligence products, the purpose of this study is to verify the moderating effect of christian religiousness on deep learning-based products. Especially, this paper empirically analyzes whether christian religiousness plays a moderating effect on the effect of consumer’s consumption value on its acceptance. To this end, we surveyed 163 consumers in their 20s and 30s about the appraisal of apparel products made by deep learning technology called cycleGAN. As a result, Christians significantly influenced product acceptance in functional values and non-Christian in social and emotional values. On the other hand, it was found that the intention of recommendation had a significant influence on the intention of recommendation for the product in the functional value and social value in the case of Christians and in the emotional value in the case of Christians."
딥러닝을 이용한 시퀀스 기반의 여행경로 추천시스템 : 제주도 사례,2020,"['딥러닝', '순환신경망', '추천시스템', '제주도', 'Deep learning', 'RNN(Recurrent Neural Network)', 'Recommendation systems', 'Jeju Island']","딥 러닝의 발전에 따라 추천시스템에서 딥 러닝 기반의 인공신경망을 활용한 연구가 활발히 진행되고 있다. 특히, RNN(Recurrent Neural Network)기반의 추천시스템은 데이터의 순차적 특성을 고려하기 때문에 추천시스템에서 좋은 성과를 보여주고 있다. 본 연구는 RNN기반의 알고리즘인 GRU(Gated Recurrent Unit)와 세션 기반 병렬 미니배치(Session Parallel mini-batch)기법을 활용한 여행경로 추천 시스템을 제안한다. 본 연구는 top1과 bpr(Bayesian personalized ranking) 오차함수의 앙상블을 통해 추천 성과를 향상시켰다. 또한, 데이터 내에 순차적인 특성을 고려한 RNN기반 추천 시스템은 여행경로에 내재된 여행지의 의미가 반영된 추천이 이루어진다는 것을 확인되었다.","With the development of deep learning, studies using artificial neural networks based on deep learning in recommendation systems are being actively conducted. Especially, the recommendation system based on RNN (Recurrent Neural Network) shows good performance because it considers the sequential characteristics of data. This study proposes a travel route recommendation system using GRU(Gated Recurrent Unit) and Session-based Parallel Mini-batch which are RNN-based algorithm. This study improved the recommendation performance through an ensemble of top1 and bpr(Bayesian personalized ranking) error functions. In addition, it was confirmed that the RNN-based recommendation system considering the sequential characteristics in the data makes a recommendation reflecting the meaning of the travel destination inherent in the travel route."
딥러닝을 이용한 영화 흥행 예측과 주요 변수의 선택 연구 : 다변량 시계열 데이터 중심으로,2020,"['Box-office Prediction', 'Feature Selection', 'Multivariate Time Series Classification', 'Random Forest', 'Deep Learning', 'Multi-Layer Perceptron', 'Fully Convolutional Neural Networks', 'Residual Network', '박스 오피스 예측', '영화 흥행 예측', '주요 변수 선택', '다변량 시계열 데이터 분류', '랜덤 포레스트', '딥러닝', '다층 퍼셉트론', '완전 합성곱 신경망', '잔차 네트워크']","박스 오피스 예측은 영화 이해관계자들에게 중요하다. 따라서 정확한 박스 오피스 예측과 이에 영향을 미치는 주요 변수를 선별하는 것이 필요하다. 본 논문은 영화의 박스 오피스 예측 정확도 향상을위해 다변량 시계열 데이터 분류와 주요 변수 선택 방법을 제안한다. 연구 방법으로 한국 영화 일별데이터를 KOBIS와 NAVER에서 수집하였고, 랜덤 포레스트(Random Forest) 방법으로 주요 변수를 선별하였으며, 딥러닝(Deep Learning)으로 다변량 시계열을 예측하였다. 한국의 스크린 쿼터제(Screen Quota) 기준, 딥러닝을 이용하여 영화 개봉 73일째 흥행 예측 정확도를 주요 변수와 전체 변수로 비교하고통계적으로 유의한지 검정하였다. 딥러닝 모델은 다층 퍼셉트론(Multi-Layer Perceptron), 완전 합성곱신경망(Fully Convolutional Neural Networks), 잔차 네트워크(Residual Network)로 실험하였다. 결과적으로주요 변수를 잔차 네트워크에 사용했을 때 예측 정확도가 약 93%로 가장 높았다.","Box-office prediction is important to movie stakeholders. It is necessary to accurately predict box-office and select important variables. In this paper, we propose a multivariate time series classification and important variable selection method to improve accuracy of predicting the box-office. As a research method, we collected daily data from KOBIS and NAVER for South Korean movies, selected important variables using Random Forest and predicted multivariate time series using Deep Learning. Based on the Korean screen quota system, Deep Learning was used to compare the accuracy of box-office predictions on the 73rd day from movie release with the important variables and entire variables, and the results was tested whether they are statistically significant. As a Deep Learning model, Multi-Layer Perceptron, Fully Convolutional Neural Networks, and Residual Network were used. Among the Deep Learning models, the model using important variables and Residual Network had the highest prediction accuracy at 93%."
딥러닝 기반 포즈인식을 이용한 체력측정 시스템,2020,"['체력측정', '딥러닝', '인공지능', '골격선 추출', '자세 가이드', 'Physical fitness measurement', 'deep learning', 'artificial intelligence', 'skeletal  line extraction', 'pose guide']",,
딥러닝에 의한 라이다 반사강도로부터 엄밀정사영상 생성,2020,"['LiDAR Intensity', 'True Orthoimage', 'Deep Learning', 'GAN', '라이다 반사강도', '엄밀정사영상', '딥러닝', '생성적 적대 신경망']","정사영상 생성을 위한 많은 연구들이 진행되어 왔다. 기존의 방법은 정사영상을 제작할 경우, 폐색지역을 탐지하고 복원하기 위해 항공영상의 외부표정요소와 정밀 3D 객체 모델링 데이터가 필요하며, 일련의 복잡한 과정을 자동화하는 것은 어렵다. 본 논문에서는 기존의 방법에서 탈피하여 딥러닝(DL)을 이용하여 엄밀정사영상을 제작하는 새로운 방법을 제안하였다. 딥러닝은 여러 분야에서 더욱 급속하게 활용되고 있으며, 최근 생성적 적대 신경망(GAN)은 영상처리 및 컴퓨터비전 분야에서 많은 관심의 대상이다. GAN을 구성하는 생성망은 실제 영상과 유사한 결과가 생성되도록 학습을 수행하고, 판별망은 생성망의 결과가 실제 영상으로 판단될 때까지 반복적으로 수행한다. 본 논문에서 독일 사진측량, 원격탐사 및 공간정보학회(DGPF)가 구축하고 국제 사진측량 및 원격탐사학회(ISPRS)가 제공하는 데이터 셋 중에서 라이다 반사강도 데이터와 적외선 정사영상을 GAN기반의 Pix2Pix 모델 학습에 사용하여 엄밀정사영상을 생성하는 두 가지 방법을 제안하였다. 첫 번째 방법은 라이다 반사강도영상을 입력하고 고해상도의 정사영상을 목적영상으로 사용하여 학습하는 방식이고, 두 번째 방법에서도 입력영상은 첫 번째 방법과 같이 라이다 반사강도영상이지만 목적영상은 라이다 점군집 데이터에 칼라를 지정한 저해상도의 영상을 이용하여 재귀적으로 학습하여 점진적으로 화질을 개선하는 방법이다. 두 가지 방법으로 생성된 정사영상을 FID (Fréchet Inception Distance)를 이용하여 정량적 수치로 비교하면 큰 차이는 없었지만, 입력영상과 목적영상의 품질이 유사할수록, 학습 수행 시 epoch를 증가시키면 우수한 결과를 얻을 수 있었다. 본 논문은 딥러닝으로 엄밀정사영상 생성 가능성을 확인하기 위한 초기단계의 실험적 연구로서 향후 보완 및 개선할 사항을 파악할 수 있었다.","During last decades numerous studies generating orthoimage have been carried out. Traditional methods require exterior orientation parameters of aerial images and precise 3D object modeling data and DTM (Digital Terrain Model) to detect and recover occlusion areas. Furthermore, it is challenging task to automate the complicated process. In this paper, we proposed a new concept of true orthoimage generation using DL (Deep Learning). DL is rapidly used in wide range of fields. In particular, GAN (Generative Adversarial Network) is one of the DL models for various tasks in imaging processing and computer vision. The generator tries to produce results similar to the real images, while discriminator judges fake and real images until the results are satisfied. Such mutually adversarial mechanism improves quality of the results. Experiments were performed using GAN-based Pix2Pix model by utilizing IR (Infrared) orthoimages, intensity from LiDAR data provided by the German Society for Photogrammetry, Remote Sensing and Geoinformation (DGPF) through the ISPRS (International Society for Photogrammetry and Remote Sensing). Two approaches were implemented: (1) One-step training with intensity data and high resolution orthoimages, (2) Recursive training with intensity data and color-coded low resolution intensity images for progressive enhancement of the results. Two methods provided similar quality based on FID (Fréchet Inception Distance) measures. However, if quality of the input data is close to the target image, better results could be obtained by increasing epoch. This paper is an early experimental study for feasibility of DL-based true orthoimage generation and further improvement would be necessary."
딥러닝 알고리즘을 이용한 머신 비전 기반 불량 검출 연구,2020,"['Deep Learning', 'AI', 'Machine vision', 'Defect detection', '딥러닝', '인공지능', '머신비전', '불량 검출']","최근 4차 산업혁명의 핵심기술인 딥러닝과 머신비전을 융합하여 제품의 불량을 검출하는 사례가 증가하고 있다. 본 논문에서는 케라스 (Keras) 오픈소스 라이브러리를 이용해 딥러닝 (Deap Learning)과 머신비전 (Machine vision) 기반의 불량 검출 소프트웨어를 개발하였고, 이를 이용해 정상품의 이미지를 기준으로 불량 유무를 판단하고 이후 불량 위치를 확률 분포로 찾아내도록 하였다. 또한 해당 소프트웨어의 성능을 검증 하기 위해, 이미지편집기로 제작한 이미지를 이용한 기본 검증실험과 실제 조립 블록을 이용한 검증실험 그리고 실제 전기 브레드 보드를 이용한 준 실제 적용실험으로 나누어 진행되었다. 이를 통해, 딥러닝 알고리 즘을 이용한 머신비전 기반의 불량 검출 시스템이 불량 유무와 불량 위치를 정확히 찾아낼 수 있음을 확인 하였다.","Currently, there are numerous methods for detecting product defects by combining deep learning and machine vision, which are the core technologies of the fourth industrial revolution. In this study, we have developed a software that can identify defects, based on deep learning and machine vision, using the Keras open source library. The software was used to determine the defect based on an image of the regular product, and then identify its location using probability distribution. In addition, three verification experiments were carried out, the first which is a basic verification experiment, using an image produced by an image editor, the second, using an assembly block; and finally, a semi-real application experiment using an electric bread-board. Through these experiments, it was confirmed that machine vision-based defect detection system using deep learning algorithm could idetify the defects and pinpoint their locations."
사용자 참여형 웨어러블 디바이스 데이터 전송 연계 및 딥러닝 대사증후군 예측 모델,2020,"['딥러닝', '웨어러블 디바이스', '디지털 헬스케어', '질병 예측', '유전자', '라이프 로그', 'Deep learning', 'Wearable device', 'Digital healthcare', 'Disease prediction', 'Genome', 'Life-log']","본 논문은 최근 다양한 종류의 웨어러블 디바이스가 헬스케어 도메인에 급증하여 사용되고 있는 상황에서 최신 첨단 기술이 실제 메디컬 환경에서 개인의 질병예측이라는 관점을 바라본다. 사용자 참여형 웨어러블 디바이스를 통하여 임상 데이터와 유전자 데이터, 라이프 로그 데이터를 병합하여 데이터를 수집, 처리, 전송하는 과정을 걸쳐 딥뉴럴 네트워크의 환경에서 학습모델의 제시와 피드백 모델을 연결하는 과정을 제시한다. 이러한 첨단 의료 현장에서 일어나는 메디컬 IT의 임상시험 절차를 걸친 실제 현장의 경우 대사 증후군에 의한 특정 유전자가 질병에 미치는 영향을 측정과 더불어 임상 정보와 라이프 로그 데이터를 병합하여 서로 각기 다른 이종 데이터를 처리하면서 질병의 특이점을 확인하게 된다. 즉, 이종 데이터의 딥뉴럴 네트워크의 객관적 적합성과 확실성을 증빙하게 되고 이를 통한 실제 딥러닝 환경에서의 노이즈에 따른 성능 평가를 실시한다. 이를 통해 자동 인코더의 경우의 1,000 EPOCH당 변화하는 정확도와 예측치가 변수의 증가 값에 수차례 선형적으로 변화하는 현상을 증명하였다.","This paper aims to look at the perspective that the latest cutting-edge technologies are predicting individual diseases in the actual medical environment in a situation where various types of wearable devices are rapidly increasing and used in the healthcare domain. Through the process of collecting, processing, and transmitting data by merging clinical data, genetic data, and life log data through a user-participating wearable device, it presents the process of connecting the learning model and the feedback model in the environment of the Deep Neural Network. In the case of the actual field that has undergone clinical trial procedures of medical IT occurring in such a high-tech medical field, the effect of a specific gene caused by metabolic syndrome on the disease is measured, and clinical information and life log data are merged to process different heterogeneous data. That is, it proves the objective suitability and certainty of the deep neural network of heterogeneous data, and through this, the performance evaluation according to the noise in the actual deep learning environment is performed. In the case of the automatic encoder, we proved that the accuracy and predicted value varying per 1,000 EPOCH are linearly changed several times with the increasing value of the variable."
딥러닝 기반 교량 구성요소 자동 분류,2020,"['BIM', '교량 구성요소 분류', '딥러닝', 'CNN', 'BIM', 'Bridge component classification', 'Deep Learning', 'CNN']","최근 BIM (Building Information Modeling)이 건설 산업계에서 폭넓게 활용되고 있다. 하지만 과거에 시공이 된 구조물에 경우 대부분 BIM이 구축되어 있지 않다. BIM이 구축되지 않은 구조물의 경우, 카메라로부터 얻은 2D 이미지에 SfM (Structure from Motion) 기법을 활용하면 3D 모델의 점군 데이터(Point cloud)를 생성하고 BIM을 구축할 수 있다. 하지만 이렇게 생성된 점군 데이터는 의미론적 정보가 포함되어 있지 않기 때문에, 수작업으로 구조물의 어떤 요소인지 분류해 주어야 한다. 따라서 본 연구에서는 구조물 구성요소를 분류하는 과정을 자동화하기 위하여 딥러닝을 적용하였다. 딥러닝 네트워크 구축에는 CNN (Convolutional Neural Network) 구조의 Inception-ResNet-v2를 사용하였고, 전이학습을 통하여 교량 구조물의 구성요소를 학습하였다. 개발된 시스템을 검증하기 위하여 수집한 데이터를 이용하여 구성요소를 분류한 결과, 교량의 구성요소를 96.13 %의 정확도로 분류할 수 있었다.","Recently, BIM (Building Information Modeling) are widely being utilized in Construction industry. However, most structures that have been constructed in the past do not have BIM. For structures without BIM, the use of SfM (Structure from Motion) techniques in the 2D image obtained from the camera allows the generation of 3D model point cloud data and BIM to be established. However, since these generated point cloud data do not contain semantic information, it is necessary to manually classify what elements of the structure. Therefore, in this study, deep learning was applied to automate the process of classifying structural components. In the establishment of deep learning network, Inception-ResNet-v2 of CNN (Convolutional Neural Network) structure was used, and the components of bridge structure were learned through transfer learning. As a result of classifying components using the data collected to verify the developed system, the components of the bridge were classified with an accuracy of 96.13 %."
딥러닝 기반 S-Box 설계정보 분석 방법 연구,2020,"['Cryptanalysis', 'Deep-learning', 'Symmetric key', 'S-box structure']","CRYPTO 2019에 발표된 Gohr의 연구결과는 딥러닝 기술이 암호분석에 활용될 수 있음을 보여주었다. 본 논문에서는 특정 구조를 가진 S-box를 딥러닝 기술이 식별할 수 있는지 실험한 결과를 제시한다. 이를 위해, 2가지 실험을 수행하였다. 첫 번째로는, 경량암호 설계에 주로 사용하는 Feistel 및 MISTY, SPN, multiplicative inverse 구조를 가진 S-box의 DDT 및 LAT로 학습 데이터를 구성하고 딥러닝 알고리즘으로 구조를 식별하는 실험을 수행하여 구조는 물론 라운드까지 식별할 수 있었다. 두 번째로는 Feistel 및 MISTY구조가 특정 라운드까지 의사난수성을 보이는지에 대한 실험을 통해 이론적으로 제시된 라운드 수 보다 많은 라운드 수에서 random 한함수와 구분할 수 있음을 확인하였다. 일반적으로, 군사용 등 고도의 기밀성 유지를 위해 사용되는 암호들은 공격이나 해독을 근본적으로 차단하기 위해 설계정보를 공개하지 않는 것이 원칙이다. 본 논문에서 제시된 방법은 딥러닝기술이 이처럼 공개되지 않은 설계정보를 분석하는 하나의 도구로 사용 가능하다는 것을 보여준다.","In CRYPTO 2019, Gohr presents that Deep-learning can be used for cryptanalysis. In this paper, we verify whetherDeep-learning can identify the structures of S-box. To this end, we conducted two experiments. First, we use DDT andLAT of S-boxes as the learning data, whose structure is one of mainly used S-box structures including Feistel , MISTY, SPN and multiplicative inverse. Surprisingly, our Deep-learning algorithms can identify not only the structures butalso the number of used rounds. The second application verifies the pseudo-randomness of and structures by increasing thenuber of rounds in each structure. Our Deep-learning algorithms outperform the theoretical distinguisher in terms of thenumber of rounds. In general, the design rationale of ciphers used for high level of confidentiality, such as for militarypurposes, tends to be concealed in order to interfere cryptanalysis. The methods presented in this paper show thatDeep-learning can be utilized as a tool for analyzing such undisclosed design rationale."
딥러닝 기반의 스크랩박스 적치 상태 측정 기술 개발,2020,"['Deep Learning', 'Accumulated status Measuring', 'CNN', 'Transfer Learning', 'Machine Learning', '딥러닝', '적치 상태 측정', '전이 학습', '머신 러닝']","본 논문에서는 금속스크랩이 쌓이는 스크랩박스의 적치 상태를 측정하는 알고리즘을 제안한다. 적치 상태 측정 문제를 다중 클래스 분류 문제로 정의하여, 딥러닝 기법을 이용해 스크랩박스 촬영 영상만으로 적치 상태를 구분하도록 하였다. Transfer Learning 방식으로 학습을 진행하였으며, 딥러닝 모델은 NASNet-A를 이용하였다. 더불어 분류 모델의 정확도를 높이기 위해 학습된 NASNet-A에 랜덤포레스트 분류기를 결합하였으며, 후처리를 통해 안전성을 높였다. 현장에서 수집된 4,195개의 데이터로 테스트한 결과 NASNet-A만 적용했을때 정확도 55%를 보였으며, 제안방식인 Random Forest를 결합한 NASNet은 88%로 향상된 정확도를 달성하였다.","In this paper, we propose an algorithm to measure the accumulated status of scrap boxes where metal scraps are accumulated. The accumulated status measuring is defined as a multi-class classification problem, and the method with deep learning classify the accumulated status using only the scrap box image. The learning was conducted by the Transfer Learning method, and the deep learning model was NASNet-A. In order to improve the accuracy of the model, we combined the Random Forest classifier with the trained NASNet-A and improved the model through post-processing. Testing with 4,195 data collected in the field showed 55% accuracy when only NASNet-A was applied, and the proposed method, NASNet with Random Forest, improved the accuracy by 88%."
딥러닝 기반의 돌출 객체 검출을 위한 Saliency Attention 방법,2020,"['Saliency Attention', '딥러닝', '객체 검출', '활성화 함수', '영상 처리', 'Saliency Attention', 'Deep learning', 'Object detection', 'Activation function', 'Image processing']","본 논문에서는 이미지에서 돌출되는 객체를 검출하기 위해 Saliency Attention을 이용한 딥러닝 기반의 검출 방법을 제안하였다. 돌출 객체 검출은 사람의 시선이 집중되는 물체를 배경으로부터 분리시키는 것이며, 이미지에서 관련성이 높은 부분을 결정한다. 객체 추적 및 검출, 인식 등의 다양한 분야에서 유용하게 사용된다. 기존의 딥러닝 기반 방법들은 대부분 오토인코더 구조로, 특징을 압축 및 추출하는 인코더와 추출된 특징을 복원 및 확장하는 디코더에서 많은 특징 손실이 발생한다. 이러한 손실로 돌출 객체 영역에 손실이 발생하거나 배경을 객체로 검출하는 문제가 있다. 제안하는 방법은 오토인코더 구조에서 특징 손실을 감소시키고 배경 영역을 억제하기 위해 Saliency Attention을 제안 하였다. ELU 활성화 함수를 이용해 특징 값의 영향력을 결정하며 각각 정규화된 음수 및 양수 영역의 특징값에 Attention을 진행하였다. 제안하는 Attention 기법을 통해 배경 영역을 억제하며 돌출 객체 영역을 강조하였다. 실험 결과에서는 제안하는 방법이 기존 방법과 비교하여 향상된 검출 결과를 보였다.","In this paper, we proposed a deep learning-based detection method using Saliency Attention to detect salient objects in images. The salient object detection separates the object where the human eye is focused from the background, and determines the highly relevant part of the image. It is usefully used in various fields such as object tracking, detection, and recognition. Existing deep learning-based methods are mostly Autoencoder structures, and many feature losses occur in encoders that compress and extract features and decoders that decompress and extend the extracted features. These losses cause the salient object area to be lost or detect the background as an object. In the proposed method, Saliency Attention is proposed to reduce the feature loss and suppress the background region in the Autoencoder structure. The influence of the feature values was determined using the ELU activation function, and Attention was performed on the feature values in the normalized negative and positive regions, respectively. Through this Attention method, the background area was suppressed and the projected object area was emphasized. Experimental results showed improved detection results compared to existing deep learning methods."
딥러닝-워드임베딩을 기반으로 한 말더듬 대상자의 읽기과제 비유창성 분석,2020,"['딥러닝', '워드임베딩', '코사인 유사도', '말더듬 읽기과제', '정상적 비유창성', '비정상적 비유창성', 'Deep learning', 'Word embedding', 'Cosine similarity', 'Stuttering reading task', 'Normal disfluencies', 'Abnormal disfluencies']","배경 및 목적: 최근의 딥러닝 자연어 처리는 언어단위를 수치 벡터로 변환하여 공간상에서 연산을 도모하는 임베딩 기술을 활용한다. 본 연구는 이 기법을 언어병리학 유창성장애 데이터에 적용하여 비유창성의 위치와 분포 특성을 파악하고자 하였다. 방법: 110명의 중학생 이상 청소년 및 말더듬 성인의 읽기발화(800음절) 데이터를 음소 단위로 분절한 뒤 수치 벡터로 변환하여 거리 연산을 수행하였다. Word2Vec을 활용하여 코사인 유사도를 측정하여 각 비유창성 유형 별 유사성을 도출하고, 또한 전체 데이터를 t-SNE 그림으로 모델을 시각화하여 제시하였다. 또한, 음소 환경을 분석하고자 파라다이스-유창성검사-II의 읽기발화와 세종 코퍼스 데이터를 비교 분석하였다. 결과: 첫 번째, 총 8개의 ND 유형(‘UR’, ‘I’, ‘H’, ‘R1’)과 AD 유형(‘URa’, ‘Ia’, ‘Ha’, ‘R1a’)은 .9 이상의 유사도로 근접하여 출현하였다. 두 번째, ND 유형과 AD 유형 간의 분포적 차이를 분석한 결과, 분포적 차이가 크지 않은 것으로 나타났다. 또한, AD 유형은 상당히 높은 유사도로 AD 유형 간에 발생 위치가 중첩되는 것으로 나타났고 ‘R2’와 ‘DP’는 다른 비유창성 유형과 다른 양상을 보였다. 마지막으로, 음소 환경에 따른 비유창성 출현 빈도는 ‘ㅁ’, ‘ㄷ’, ‘ㅈ’ 음소에서 비유창성 빈도가 비교적 높게 나타났다. 논의 및 결론: 본 연구는 딥러닝 기법을 활용하여 비유창성 유형들 간의 군집화 특성, 정상적 비유창성과 비정상적 비유창성 사이의 분포적 차이가 크지 않다는 것, 그리고 비유창성 출현 음소 등을 확인하였고 이러한 결과는 유창성장애 진단과 치료에 활용될 수 있을 것이다.","Objectives: Recent natural language processing systems employ embedding techniques, which convert linguistic expressions into numerical vectors in order to measure the geometric distance between expressions. Using skills and focusing on the reading tasks, the present study aims to reveal the distributional properties of disfluencies. Methods: The current work segmented the reading data of 110 adolescents and adults who stutter, transformed the data into a vector space, and then conducted the embedding calculation. Utilizing Word2Vec, the cosine similarity was measured so as to look at how the types of disfluencies were co-related to each other. Results: The eight ND (Normal disfluencies) and AD (Abnormal disfluencies) types, excluding the R2 (Repetition 2) and DP (Disrhythmic Phonation) types, were close to each other with respect to the cosine similarity (>.9). In particular, the AD types such as Ha (Abnormal hesitation), Ia (Abnormal interjection), URa (Abnormal unfinished/revision word), and R1a (Abnormal Repetition1) largely overlapped with each other. R2 and DP showed different distributional properties from other types of disfluencies. The results also indicated that each ND and AD pair seldom differed in their distributional properties. Finally, this study it found that several consonants tended to appear more often when the speakers produced disfluencies. Conclusion: This study draws the distributional patterns of fluency disorders in an automatic way using deep learning skills. The findings are of use for the diagnosis and treatment of the fluency disorders."
딥러닝을 활용한 경판 방각본 소설의 유형 고찰 -영웅소설과 애정소설 유형을 중심으로-,2020,"['유형', '영웅소설', '애정소설', '여성영웅소설', '딥러닝', '문체분석', '인공지능인문학', '디지털인문학', 'Novel Type', 'hero novel', 'affection novel', 'female hero novel', 'deep learning', 'stylistic analysis', 'artificial intelligence humanities', 'digital humanities']","본 연구는 딥러닝을 활용하여 경판 방각본 소설 중 영웅소설과 애정소설로 파악되는 작품들의 유형성을 분석하였다. <조웅전>, <소대성전>, <임장군전>의 영웅소설과 <숙향전>, <숙영낭자전>의 애정소설을 토대로 영웅소설과 애정소설을 분류하는 딥러닝 유형 학습 모델을 구축했다. 이를 토대로, 영웅소설로 분류되는 <금방울전>, <장백전>, <장풍운전>, <정수정전>, <현수문전>, <황운전> 6작품과 애정소설로 분류되는 <백학선전>, <쌍주기연>, <양산백전>, <옥주호연> 4작품의 유형성을 검증하였다.결과적으로 애정소설과 영웅소설 사이에서 이견이 존재했던 <백학선전>, <쌍주기연>, <양산백전> 등은 애정소설로 파악되었고, 영웅소설로 분류되던 <금방울전>, <장백전>, <장풍운전>, <현수문전> 등도 애정소설로 파악되었다. 영웅소설로 분류되던 <정수정전>, <황운전> 그리고 애정소설로 분류되던 <옥주호연>만이 영웅소설로 파악되었는데, 이 작품들은 모두 여성영웅소설이었다.이러한 결과는 문체적으로 <조웅전>, <소대성전> 등의 일반적인 영웅소설과 <정수정전>, <황운전> 등 여성영웅소설이 유형성을 공유하고 있고, <장백전>, <현수문전> 등 왕조교체형이라고 불리는 영웅소설이 이들과는 상이한 특징을 지니고 있음을 나타낸다.","This study analyzed the typology of works identified as hero novels and romantic novels using artificial intelligence deep learning. First, we built a deep learning type learning model based on hero novels such as Jowoongjeon, Sodaesungjeon, and Imjanggunjeon, and romantic novels such as Sukhyangjeon and Sookyoungnangjajeon. Through this, we verified six works of hero novels(Geumbanguljeon, Jangbaekjeon, Jangpungunjeon, Jungsujeongjeon, Hyunsumunjeon, and Hwangunjeon) and four works of romantic novels(Baekhaksunjeun, Ssangjugiyeon, YangsanBaekjeon, and Okjuhoyeon).As a result, Baekhaksunjeun, Ssangjugiyeon, and YangsanBaekjeon, which had a difference opinion between romantic novels and hero novels, were identified as romantic novels. Geumbanguljeon, Jangbaekjeon, Jangpungunjeon, and Hyunsumunjeon were also identified as romantic novels. Only Jungsujeongjeon, Hwangunjeon and Okjuhoyeon were classified as hero novels, all of which were female hero novels.In other words, the general hero novel and female hero novels such as Jungsujeongjeon, Hwangunjeon share the stylistic tangibility. Novels, such as Jangbaekjeon and Hyunsumunjeon, which feature heroes who cause the downfall of a dynasty, have different stylistic features."
딥러닝을 이용한 음악흥행 예측모델 개발 연구,2020,"['음악 흥행 예측', '음원차트', '딥러닝', '심층신경망', 'DNN', 'Music Box Office', 'Music Chart', 'Deep Learning', 'Deep Neural Network', 'DNN']","본 연구에서는 콘텐츠 산업 중 음악 분야 2차 산업데이터를 활용하여 딥러닝 기법을 이용한 흥행 예측모델 구축 가능성을 살펴보았다. 본 연구를 통해 구축한 딥러닝 예측 모델은 17개 독립변인 -가수 파워, 가수 영향력, 피처링 가수 파워, 피처링 가수 영향력, 참여 가수 수, 참여 가수의 성별, 작사가 역량, 작곡가 역량, 편곡가 역량, 제작사 역량, 유통사 역량, 앨범의 타이틀 여부, 음원 스트리밍 플랫폼 좋아요 수, 음원 스트리밍 플랫폼 코멘트 수, 사전 홍보 기사 수, 티저 영상 조회 수, 초기 흥행성과를 기반으로 음원 흥행성과 -음원이 차트 내 상주하는 기간을 예측하는 구조다. 추가적으로 본 연구가 딥러닝 기법을 콘텐츠 분야에 접목시킨 초기단계 연구임을 고려하여, 콘텐츠 흥행예측 선행연구에서 요인 추출을 위해 활용하는 선형회귀분석을 통해 변인 소거 후 구축한 DNN 예측모델과 예측률 비교를 진행하였다.","Among various contents industry, this study especially focused on music industry and tried to develop a prediction model for music box office using deep learning. The deep learning prediction model designed to predict music chart-in period based on 17 variables -singer power, singer influence, featuring singer power, featuring singer influence, number of participating singers, gender of participating singers, lyric writer power, composer power, arranger power, production agency power, distributing agency power, title track, LIKEs on streaming platform, comments on streaming platform, pre-promotion article, teaser-video view, first-week performance. Additionally we conducted a linear regression analysis to sort out factors, and tried to compare the prediction performance between the original DNN prediction model and the DNN model made of sorted out factors."
딥러닝을 활용한 전략물자 판정 지원도구 개발에 대한 연구,2020,"['Deep Learning', 'Classification', 'CNN', 'OCR', 'Dual-use Item']","전략물자관리 제도의 이행 확산에 따라 전략물자 판정의 중요성이 높아지고 있으나 전략물자 제도를 처음 접하는 수출기업은 전략물자의 개념을 이해하기 쉽지 않고, 전략물자를 통제하는 기준이 다양하여 전략물자 판정에 어려움이 따른다. 본 논문에서는 전략물자 제도를 처음 접하는 기업이나 전략물자 판정시스템 이용자에게 진입장벽을 낮추어 판정이라는 과정을 쉽게 접근할 수 있는 방법을 제안한다. 이용자가 전략물자 판정이라는 절차를 매뉴얼이나 카탈로그의 제공만으로 판정결과를 확인할 수 있게 된다면, 전략물자 판정 방법과 절차에 보다 편리하고 쉽게 다가설수 있을 것이다. 본 연구 목적을 달성하기 위해 이미지 인식 및 분류에서 연구되고 있는 딥러닝과 OCR(광학문자판독) 기술을 활용하고, 전략물자 판정 지원도구에 대한 개발과 연구를 통하여 우리 기업의 전략물자 판정에 도움이 되는 정보를 제공한다.","As the implementation of export controls is spreading, the importance of classifying strategic items is increasing, but Korean export companies that are new to export controls are not able to understand the concept of strategic items, and it is difficult to classifying strategic items due to various criteria for controlling strategic items. In this paper, we propose a method that can easily approach the process of classification by lowering the barrier to entry for users who are new to export controls or users who are using classification of strategic items. If the user can confirm the decision result by providing a manual or a catalog for the procedure of classifying strategic items, it will be more convenient and easy to approach the method and procedure for classfying strategic items. In order to achieve the purpose of this study, it utilizes deep learning, which are being studied in image recognition and classification, and OCR(optical character reader) technology. And through the research and development of the support tool, we provide information that is helpful for the classification of strategic items to our companies."
앙상블 딥러닝을 이용한 초음파 영상의 간병변증 분류 알고리즘,2020,"['Deep learning', 'Ensemble Model', 'CNN Model', 'ROC curve', 'Classification']",현재 의료 현장에서 초음파 진단은 과거 청진기와 같다고 할 수 있다. 그러나 초음파의 특성상 검사자의 숙련도에 따라 결과 예측이 불확실하다는 단점을 가진다. 따라서 본 논문에서는 이런 문제를 해결하기 위해 딥러닝 기술을 기반으 로 초음파 검사 중 간병변 탐지의 정확도를 높이고자 한다. 제안 논문에서는 CNN 모델과 앙상블 모델을 이용해 병변 분류의 정확도 비교 실험하였다. 실험결과 CNN 모델에서 분류 정확도는 평균 82.33%에서 앙상블모델의 경우 평균 89.9%로 약 7% 높은 것을 확인하였다. 또한 앙상블 모델이 평균 ROC커브에서도 0.97로 CNN모델보다 약 0.4정도 높은 것을 확인하였다.,"In the current medical field, ultrasound diagnosis can be said to be the same as a stethoscope in the past. However, due to the nature of ultrasound, it has the disadvantage that the prediction of results is uncertain depending on the skill level of the examiner. Therefore, this paper aims to improve the accuracy of liver lesion detection during ultrasound examination based on deep learning technology to solve this problem. In the proposed paper, we compared the accuracy of lesion classification using a CNN model and an ensemble model. As a result of the experiment, it was confirmed that the classification accuracy in the CNN model averaged 82.33% and the ensemble model averaged 89.9%, about 7% higher. Also, it was confirmed that the ensemble model was 0.97 in the average ROC curve, which is about 0.4 higher than the CNN model."
심볼마커를 사용한 딥러닝 기반 모바일 응용 UI 요소 인식,2020,"['Deep Learning', 'Symbol Marker', 'Widget Recognition']","최근 딥러닝을 사용하여 스케치이미지에 있는 GUI(Graphical User Interface) 요소를 인식하여 어플리케이션 구현에 필요한 코드를 자동 생성하는 연구 등이 있다. UI/UX 디자이너는 모바일 응용 프로그램 개발 시 스토리보드를 개발자와의 의사소통을 돕는 도구로 사용하나 모호한 위젯에 대해서는 UI/UX 디자이너의 의도와 다르게 구현되는 경우 가 종종 발생한다. 본 논문에서는 DNN(Deep Neural Network) 기반의 GUI 요소 식별의 정확성을 높이기 위해 심볼 마커를 사용하는 자동 GUI 요소 인식 기법을 제안한다. 심볼마커의 성능평가를 위해 심볼마커의 유무에 따라 실험을 진행하여 정확도를 평가하였고, 정확도 개선을 위해 원형과 괄호형으로 나누어 심볼마커 모양에 따른 결과를 분석하였 다. 심볼마커를 사용한다면 개발자에게 정확한 의사 전달이 가능해져 피드백이 줄면서 시간과 비용이 감소하고 스케치이 미지의 UI 요소 오탐률을 줄이고 정확성이 향상될 것으로 기대한다.","Recently, studies are being conducted to recognize a sketch image of a GUI (Graphical User Interface) based on a deep learning and to make it into a code implemented in an application. UI / UX designers can communicate with developers through storyboards when developing mobile applications. However, UI / UX designers can create different widgets for ambiguous widgets. In this paper, we propose an automatic UI detection method using symbol markers to improve the accuracy of DNN (Deep Neural Network) based UI identification. In order to evaluate the performance with or without the symbol markers, their accuracy is compared. In order to improve the accuracy according to of the symbol marker, the results are analyzed when the shape is a circle or a parenthesis. The use of symbol markers will reduce feedback between developer and designer, time and cost, and reduce sketch image UI false positives and improve accuracy."
포인트 클라우드에서 딥러닝을 이용한 객체 분류 및 변화 탐지,2020,"['인공지능', '딥러닝', '포인트 클라우드', '공간정보', '변화탐지', 'Artificial Intelligence', 'Deep Learning', 'Point Cloud', 'Spatial Information', 'Change Detection']","머신러닝과 딥러닝 기술의 발달로 인하여 도시의 변화탐지에 이러한 기술을 적용하려는 관심과 시도가 증가하고 있다. 그러나 기존의 변화탐지와 공간정보 구축방법은 여전히 사람에 의해 수작업으로 수행되는 경우가 많아 비용과 시간이 많이 소요되고 있다. 또한 도시지역에서 건축물의 변화탐지를 효율적으로 수행하기 위해서는 많은 인원이 필요한 실정이다. 따라서, 본 연구에서는 포인트 클라우드에서 딥러닝 기술을 적용하여 공간정보 분야에서 활용도가 높은 도로, 건물, 식생의 객체를 분류하고 변화탐지를 수행할 수 있는 방법을 제안하였다. 실험 결과 약 92% 이상의 정확도로 도로, 건물, 식생을 분류하였으며 이를 통해 객체의 속성정보를 자동으로 구축할 수 있었다. 또한, 시계열 데이터가 구축된다면 제안한 방법론을 통해서 변화를 탐지할 수 있고 기 구축된 수치지도의 속성을 검수할수 있을 것으로 판단된다.","With the development of machine learning and deep learning technologies, there has been increasing interest and attempt to apply these technologies to the detection of urban changes. However, the traditional methods of detecting changes and constructing spatial information are still often performed manually by humans, which is costly and time-consuming. Besides, a large number of people are needed to efficiently detect changes in buildings in urban areas. Therefore, in this study, a methodology that can detect changes by classifying road, building, and vegetation objects that are highly utilized in the geospatial information field was proposed by applying deep learning technology to point clouds. As a result of the experiment, roads, buildings, and vegetation were classified with an accuracy of 92% or more, and attributes information of the objects could be automatically constructed through this. In addition, if time-series data is constructed, it is thought that changes can be detected and attributes of existing digital maps can be inspected through the proposed methodology."
AWS Lambda Serverless Computing 기술을 활용한 효율적인 딥러닝 기반 이미지 인식 서비스 시스템,2020,"['Deep Learning', 'Serverless Computing', 'AWS Lambda Server', 'Cold Start Time', 'Capacity Limitation', '딥러닝', '서버리스 컴퓨팅', 'AWS 람다 서버', 'Cold Start Time', '용량제한']","최근 딥러닝(Deep Learning) 기술의 발전에 따라 컴퓨터 비전(Computer Vision) 분야의 이미지 인식 성능이 향상되고 있으며, 또한 Serverless Computing이 이벤트 기반의 클라우드 애플리케이션 개발 및 서비스를 위한 차세대 클라우드 컴퓨팅 기술로 각광받고 있어 딥러닝과 Serverless Computing 기술을 접목하여 실생활에 이미지 인식 서비스를 사용하고자 하는 시도가 증가하고 있다. 따라서 본 논문에서는 Serverless Computing 기술을 활용하여 효율적인 딥러닝 기반 이미지 인식 서비스 시스템 개발 방법을 기술한다. 제안하는 시스템은 Serverless Computing 기반 AWS Lambda Server를 이용하여 적은 비용으로 대형 신경망 모델을 사용자에게 서비스할 수 있는 방법을 제안한다. 또한 AWS Lambda Server의 단점인 Cold Start Time 문제와 용량제한 문제를 해결하여 효과적으로 대형 신경망 모델을 사용하는 Serverless Computing 시스템을 구축할 수 있음을 보인다. 실험을 통해 AWS Lambda Serverless Computing 기술을 활용하여 본 논문에서 제안한 시스템이 비용 절감뿐만 아니라 처리 시간 및 용량제한 문제를 해결하여 대형 신경망 모델을 서비스하기에 효율적인 성능을 보임을 확인하였다.","Recent advances in deep learning technology have improved image recognition performance in the field of computer vision, and serverless computing is emerging as the next generation cloud computing technology for event-based cloud application development and services. Attempts to use deep learning and serverless computing technology to increase the number of real-world image recognition services are increasing. Therefore, this paper describes how to develop an efficient deep learning based image recognition service system using serverless computing technology. The proposed system suggests a method that can serve large neural network model to users at low cost by using AWS Lambda Server based on serverless computing. We also show that we can effectively build a serverless computing system that uses a large neural network model by addressing the shortcomings of AWS Lambda Server, cold start time and capacity limitation. Through experiments, we confirmed that the proposed system, using AWS Lambda Serverless Computing technology, is efficient for servicing large neural network models by solving processing time and capacity limitations as well as cost reduction."
물체인식 딥러닝 모델 구성을 위한 파이썬 기반의 Annotation 툴 개발,2020,"['Annotation', 'GUI(Graphical User Interface)', 'Tkinter', 'Crawling', 'Retinanet', 'YOLO']","본 논문에서는 물체인식 딥러닝 모델을 구성하는데 필요한 데이터 레이블링 과정을 하나의 프로그램에서 사용할 수 있는 Annotation 툴을 개발했다. 프로그램의 인터페이스는 파이썬의 기본 GUI 라이브러리를 활용하였으며, 실시간으로 데이터 수집이 가능한 크롤러 기능을 구성하였다. 기존의 물체인식 딥러닝 모델인 Retinanet을 활용하여, 자동으로 Annotation 정보를 제공하는 기능을 구현했다. 또한, 다양한 물체인식 네트워크의 레이블링 형식에 맞추어 학습할 수 있도록 Pascal-VOC, YOLO, Retinanet 등 제각기 다른 학습 데이터 레이블링 형식을 저장하도록 했다. 제안하는 방식을 통해 국산 차량 이미지 데이터셋을 구축했으며, 기존의 물체인식 딥러닝 네트워크인 Retinanet과 YOLO 등에 학습하고, 정확도를 측정했다. 차량이 진입하는 영상에서 실시간으로 차량의 모델을 구별하는 정확성은 약 94%의 정확도를 기록했다.",
날씨를 고려한 딥러닝 기반의 개별 가구 에너지 사용 요금 예측,2020,"['Deep learning', 'Long-Short Term Memory(LSTM)', 'Household energy bills prediction']",,
감리업무 효율성 향상을 위한 딥러닝 기반 철근배근 디텍팅 기술 개발,2020,"['Deep Learning', 'Object Detection', 'YOLOv2', 'MATLAB', 'Building Supervision', 'Rebar', '딥러닝', '객체검출기술', 'YOLOv2', 'MATLAB', '건축감리', '철근']","연구의 목적은 딥러닝의 기술 중 객체검출기술을 이용하여 건축감리의 효율성 향상시킬 수 있는 감독 방법을 제안하는 것이다. 건축감리제도가 도입된 이후 제도적, 행정적인 면에서 개선, 발전 되었지만 감리를 수행하는 방법 면에서는 제도 도입 이래 개선된 점을 찾기 힘들다. 따라서 감리업무의 실행 방법에서 기둥의 철근 배근을 감지하여 자동으로 계수함으로써 효율성을 향상시킬 수 있는 방법을 제안하였다. 딥러닝의 객체검출기술을 활용하여 띠철근 검출 네트워크를 구축하였고 그 성능에 대해서는 학습에 사용한 비슷한 이미지에 대해서는 92.85%의 정확도를, 전혀 새로운 이미지에 대해서는 특정한 거리에서 90% 이상의 정확도를 확인할 수 있었으며, 검출된 띠철근을 짧은 시간 안에 계수할 수 있었다. 이러한 일련의 과정을 통해 철근 배근의 자동 검출 및 감리업무 효율성 향상 가능성을 확인하였다.","The purpose of this study is to suggest a supervisory way to improve the efficiency of Building Supervision using Deep Learning, especiallyobject detecting technology. Since the establishment of the Building Supervision system in Korea, it has been changed and improved manytimes systematically, but it is hard to find any improvement in terms of implementing methods. Therefore, the Supervision is until now thearea where a lot of money, time and manpower are needed. This might give a room for superficial, formal and documentary supervision thatcould lead to faulty construction. This study suggests a way of Building Supervision which is more automatic and effective so that it canlead to save the time, effort and money. And the way is to detect the hoop-bars of a column and count the number of it automatically. Forthis study, we made a hoop-bar detecting network by transfor learnning of YOLOv2 network through MATLAB. Among many trainingexperiments, relatively most accurate network was selected, and this network was able to detect rebar placement in building site pictures withthe accuracy of 92.85% for similar images to those used in trainings, and 90% or more for new images at specific distance. It was also ableto count the number of hoop-bars. The result showed the possibility of automatic Building Supervision and its efficiency improvement."
스테레오 CCTV 영상에서 딥러닝을 이용한 교통량 추정,2020,"['Artificial Intelligence', 'Deep Learning', 'CCTV', 'Traffic Volume', 'Affine Transformation', 'Fog', '인공지능', '딥러닝', 'CCTV', '교통량', '부등각사상변환', '안개']","교통량 산정은 주로 교통량조사시스템, 차량검지시스템, 통행료징수시스템 등과 같은 조사 장비와 CCTV를 통한 인력 조사를 병행하고 있으나 이는 많은 인력과 비용이 발생한다. 본 연구에서는 단일 CCTV의 경우 전체 차량을 탐지하지 못하는 한계를 극복하기 위해서, 딥러닝과 스테레오 CCTV를 이용하여 교통량을 산정하는 방법을 제안하였다. 차량을 탐지하기 위한 딥러닝 모델을 학습하기 위해 COCO 데이터셋을 사용하고, 실시간으로 좌우 CCTV 영상에서 각각 차량을 탐지하였다. 그리고 나서, 각 영상에서 추출하지 못한 차량을 부등각사상변환을 이용하여 추가적으로 차량을 탐지하여 교통량 산정의 정확도를 개선하였다. 실험은 평상시 도로 환경과 안개가 발생한 기상상황의 경우에 대해서 각각 수행하였다. 평상시 도로 환경의 경우 단일 CCTV 영상을 사용할 때보다 좌우 영상에서 각각 6.75%, 5.92%의 차량 탐지의 개선효과가 있었다. 또한, 안개가 발생한 도로 환경의 경우 좌우 영상에서 각각 10.79%, 12.88%의 차량 탐지의 개선효과가 있었다.","Traffic estimation mainly involves surveying equipment such as automatic vehicle classification, vehicle detection system, toll collection system, and personnel surveys through CCTV (Closed Circuit TeleVision), but this requires a lot of manpower and cost. In this study, we proposed a method of estimating traffic volume using deep learning and stereo CCTV to overcome the limitation of not detecting the entire vehicle in case of single CCTV. COCO (Common Objects in Context) dataset was used to train deep learning models to detect vehicles, and each vehicle was detected in left and right CCTV images in real time. Then, the vehicle that could not be detected from each image was additionally detected by using affine transformation to improve the accuracy of traffic volume. Experiments were conducted separately for the normal road environment and the case of weather conditions with fog. In the normal road environment, vehicle detection improved by 6.75% and 5.92% in left and right images, respectively, than in a single CCTV image. In addition, in the foggy road environment, vehicle detection was improved by 10.79% and 12.88% in the left and right images, respectively."
UAV를 활용한 실시간 교통량 분석을 위한 딥러닝 기법의 적용,2020,"['UAV(Unmanned Aerial Vehicle)', 'ITS(Intelligent Transportation System)', 'Traffic Analysis', 'Deep Learning', 'Object Detection', '무인항공기', '지능형 교통 체계', '교통량 분석', '딥러닝', '객체탐지']","급격한 도시화로 인해 출퇴근 시간의 차량 정체, 상시 정체지역 발생 등 다양한 교통문제들이 발생하고 있다. 이러한 교통문제들을 해결하기 위해서는 신속·정확한 교통량 예측 및 분석이 필요하다. ITS (Intelligent Transportation System)는 최신 ICT (Information and Communications Technology) 기술들을 활용하여 최적의 교통관리를 수행하는 시스템이며, 다양한 기법을 통해 신속·정확한 교통량을 분석하기 위한 많은 연구가 수행 되었다. 본 연구에서는 높은 정확도로 실시간 교통량 분석을 위해 UAV (Unmanned Aerial Vehicle) 동영상을 활용한 딥러닝(deep learning) 기반의 차량탐지기법을 제안하고자 한다. 이를 위해, UAV를 활용하여 다양한 차량이 통행하는 교차로에서 학습 및 검증에 필요한 정사 동영상 촬영을 수행하였으며, 승용차(sedan), 트럭(truck), 버스(bus)로 분류하여 차량을 학습시켰다. 딥러닝 알고리즘은 대표적인 객체탐지 알고리즘 중의 하나인 YOLOv3 (You Only Look Once V3)를 이용하였으며, 실험결과 전체 차량 검출율은 90.21%이며, 정확도와 재현율은 각각 95.10%와 85.79%이다. 본 연구를 통하여, 드론을 이용한 영상으로부터 차량 탐지를 통한 실시간 교통량 분석이 가능함을 확인하였다.","Due to the rapid urbanization, various traffic problems such as traffic jams during commute and regular traffic jams are occurring. In order to solve these traffic problems, it is necessary to quickly and accurately estimate and analyze traffic volume. ITS (Intelligent Transportation System) is a system that performs optimal traffic management by utilizing the latest ICT (Information and Communications Technology) technologies, and research has been conducted to analyze fast and accurate traffic volume through various techniques. In this study, we proposed a deep learning-based vehicle detection method using UAV (Unmanned Aerial Vehicle) video for real-time traffic analysis with high accuracy. The UAV was used to photograph orthogonal videos necessary for training and verification at intersections where various vehicles pass and trained vehicles by classifying them into sedan, truck, and bus. The experiment on UAV dataset was carried out using YOLOv3 (You Only Look Once V3), a deep learning-based object detection technique, and the experiments achieved the overall object detection rate of 90.21%, precision of 95.10% and the recall of 85.79%."
IoT 정보 수집을 위한 확률 기반의 딥러닝 클러스터링 모델,2020,"['사물인터넷', '정보 수집 및 추출', '확률 기반', '딥러닝', '클러스터링', 'Internet of Things', 'information collection and extraction', 'probability-based', 'deep learning', 'clustering']",,
철도 궤도의 이상상황 예방을 위한 영상처리와 딥러닝을 융합한 지능형 철도 레일 탐지 알고리즘,2020,"['Rapid-transit railway', 'railway', 'deep learning', 'fusion', '고속철도', '철도 레일', '전통적인 방식', '딥러닝', '융합']","고속철도의 출현과 함께 철도는 국내외에서 자주 사용하는 교통수단 중 하나이다. 또한, 환경적인 측면에서도 다른 교통수단에비해 이산화탄소 배출량도 적은 편이며 에너지 효율성은 높다. 철도에 관한 관심이 높아질 수록 철도의 안전과 관련된 문제는 중요한 관심사 중 하나이다. 그 중 시각적 이상현상은 철도 앞에 동물이나 사람 등 다양한 장애물이 갑자기 나타나 사고가 발생한다. 이러한 사고들을 예방하기 위해 철도 레일을 탐지하는 것은 기본적으로 탐지해야하는 영역 중 하나이다. 철도에 설치된 카메라를 통해영상을 수집할 수 있으며 철도 레일 탐지 방법은 전통적인 방식과 딥러닝 알고리즘을 이용한 방식이 있다. 전통적인 방식은 레일주변의 다양한 노이즈로 인해 정확한 탐지가 어려우며 딥러닝 알고리즘을 이용하면 정확도 높게 탐지할 수 있으며 두 알고리즘을융합하여 정확한 철도 레일을 탐지한다. 제안하는 알고리즘은 수집한 데이터를 기반으로 철도 레일 탐지에 대한 정확도를 판단한다.","With the advent of high-speed railways, railways are one of the most frequently used means of transportation at home and abroad.In addition, in terms of environment, carbon dioxide emissions are lower and energy efficiency is higher than other transportation. As the interest in railways increases, the issue related to railway safety is one of the important concerns. Among them, visual abnormalities occur when various obstacles such as animals and people suddenly appear in front of the railroad. To prevent these accidents, detecting rail tracks is one of the areas that must basically be detected. Images can be collected through cameras installed on railways, and the method of detecting railway rails has a traditional method and a method using deep learning algorithm. The traditional method is difficult to detect accurately due to the various noise around the rail, and using the deep learning algorithm, it can detect accurately, and it combines the two algorithms to detect the exact rail. The proposed algorithm determines the accuracy of railway rail detection based on the data collected."
딥러닝 알고리즘을 활용한 천식 환자 발생 예측에 대한 연구,2020,"['딥러닝', '천식', 'DNN', '질병', '대기', '대기오염', '보건정책', 'Deep Learning', 'Asthma', 'DNN', 'Disease', 'Atmosphere', 'Air Pollution', 'Public Health Policy']","최근 산업화 및 인구과밀화로 인해 대기오염에 대한 문제가 세계적 관심사로 대두되고 있다. 대기 오염은 인간의 건강에 다양한 악영향을 초래할 수 있는데, 그 중 본 연구에서 관심을 둔 천식과 같은 호흡계 질환은 직접적 영향을 받을 수 있다. 기존의 연구에서는 임상 데이터를 활용하여 상대적으로 적은 표본을 기반으로 천식과 같은 질환에 대기 오염 인자가 어떠한 영향을 미치는지를 파악하였다. 이는 수집 표본 별 일관성이 없는 결과를 초래할 소지가 다분하며, 의료계 종사자 이외에는 연구의 시도가 어렵다는 점에서 큰 한계를 가지고 있다. 본 연구에서는 정부에서 공개하는 대기 환경 데이터와 천식 발병 빈도 수에 대한 데이터를 기반으로, 실제 천식 발병 빈도를 예측하는 것에 연구의 주안점을 두었다. 본 연구는 시차를 적용한 피어슨 상관계수를 통해 각 대기오염 인자가 천식 발병에 어느 정도의 시차를 가지고 유의한 영향을 주는지를 검증하였다. 검증 결과를 기반으로 구축된 학습데이터는 딥러닝 알고리즘에 활용되며, 천식 발병 빈도의 예측에 최적화 된 모델을 설계하였다. 모델의 평균 대비 오차율은 약 11.86%로 타 머신러닝 기반의 알고리즘 대비 우수한 성능을 나타냄을 확인하였다. 제안한 모델은 국가 보험 체계 및 보건 예산 관리에서의 효율화 및 병원에서의 의료 인력 배치 및 수급에의 효율성 또한 제공할 수 있다. 또한 만성 천식 질환자에 대한 대기 환경별 발병 위험에 대한 조기 경보를 통해 국민 건강 증진에 기여할 수 있다.","Recently, the problem of air pollution has become a global concern due to industrialization and overcrowding. Air pollution can cause various adverse effects on human health, among which respiratory diseases such as asthma, which have been of interest in this study, can be directly affected. Previous studies have used clinical data to identify how air pollutant affect diseases such as asthma based on relatively small samples. This is high likely to result in inconsistent results for each collection samples, and has significant limitations in that research is difficult for anyone other than the medical profession. In this study, the main focus was on predicting the actual asthmatic occurrence, based on data on the atmospheric environment data released by the government and the frequency of asthma outbreaks. First of all, this study verified the significant effects of each air pollutant with a time lag on the outbreak of asthma through the time-lag Pearson Correlation Coefficient. Second, train data built on the basis of verification results are utilized in Deep Learning algorithms, and models optimized for predicting the asthmatic occurrence are designed. The average error rate of the model was about 11.86%, indicating superior performance compared to other machine learning-based algorithms. The proposed model can be used for efficiency in the national insurance system and health budget management, and can also provide efficiency in the deployment and supply of medical personnel in hospitals. And it can also contribute to the promotion of national health through early warning of the risk of outbreak by atmospheric environment for chronic asthma patients."
딥러닝을 활용한 다목적댐 유입량 예측,2020,"['딥러닝', 'LSTM', '다목적댐', '유량예측', 'Deep learning', 'LSTM', 'Multipurpose dam', 'Prediction of inflow']","최근 데이터 예측 방법으로 인공신경망(Artificial Neural Network, ANN)분야에 대한 관심이 높아졌으며, 그 중 시계열 데이터 예측에 특화된 LSTM(Long Short-Term Memory)모형은 수문 시계열자료의 예측방법으로도 활용되고 있다. 본 연구에서는 구글에서 제공하는 딥러닝 오픈소스 라이브러리인 텐서플로우(TensorFlow)를 활용하여 LSTM모형을 구축하고 금강 상류에 위치한 용담다목적댐의 유입량을 예측하였다. 분석 자료로는 WAMIS에서 제공하는 용담댐의 2006년부터 2018년까지의 시간당 유입량 자료를 사용하였으며, 예측된 유입량과 관측 유입량의 비교를 통하여 평균제곱오차(RMSE), 평균절대오차(MAE), 용적오차(VE)를 계산하고 모형의 학습변수에 따른 정확도를 평가하였다. 분석결과, 모든 모형이 고유량에서의 정확도가 낮은 것으로 나타났으며, 이와 같은 문제를 해결하기 위하여 용담댐 유역의 시간당 강수량 자료를 추가 학습 자료로 활용하여 분석한 결과, 고유량에 대한 예측의 정확도가 높아지는 것을 알 수 있었다.","Recently, Artificial Neural Network receives attention as a data prediction method. Among these, a Long Shot-term Memory (LSTM) model specialized for time-series data prediction was utilized as a prediction method of hydrological time series data. In this study, the LSTM model was constructed utilizing deep running open source library TensorFlow which provided by Google, to predict inflows of multipurpose dams. We predicted the inflow of the Yongdam Multipurpose Dam which is located in the upper stream of the Geumgang. The hourly flow data of Yongdam Dam from 2006 to 2018 provided by WAMIS was used as the analysis data. Predictive analysis was performed under various of variable condition in order to compare and analyze the prediction accuracy according to four learning parameters of the LSTM model. Root mean square error (RMSE), Mean absolute error (MAE) and Volume error (VE) were calculated and evaluated its accuracy through comparing the predicted and observed inflows. We found that all the models had lower accuracy at high inflow rate and hourly precipitation data (2006∼2018) of Yongdam Dam utilized as additional input variables to solve this problem. When the data of rainfall and inflow were utilized together, it was found that the accuracy of the prediction for the high flow rate is improved."
딥러닝을 이용한 리튬이온 배터리 잔여 유효수명 예측,2020,"['Deep Learning(딥러닝)', 'Lithium-ion Battery(배터리)', 'Remaining Useful Life(잔여 유효수명)', 'Prognostics and Health Management(고장예지 및 건전성 관리)', 'Machine Learning(기계학습)', 'Big Data(빅 데이터)']",,"Lithium-ion batteries are the heart of energy-storing devices and electric vehicles. Owing to their superior qualities, such as high capacity and energy efficiency, they have become quite popular, resulting in an increased demand for failure/damage prevention and useable life maximization. To prevent failure in Lithium-ion batteries, improve their reliability, and ensure productivity, prognosticative measures such as condition monitoring through sensors, condition assessment for failure detection, and remaining useful life prediction through data-driven prognostics and health management approaches have become important topics for research. In this study, the residual useful life of Lithium-ion batteries was predicted using two efficient artificial recurrent neural networks-long short-term memory (LSTM) and gated recurrent unit (GRU). The proposed approaches were compared for prognostics accuracy and cost-efficiency. It was determined that LSTM showed slightly higher accuracy, whereas GRUs have a computational advantage."
딥러닝 기반 가상공간에서의 손 제스처 인식,2020,"['딥러닝', '가상 공간', 'CNN', '손 제스쳐 인식', '사용자 인터페이스', 'Deep Learning', 'Virtual Space', 'Hand Gesture Recognition', 'User Interface']",,"In this paper, we define static gestures and dynamic gestures to be used as a user interface in a virtual space, and propose a method to extract features using deep learning models and to recognize hand gestures input through RGB camera in order to improve the price and recognition speed of the existing virtual / augmented reality interface device. Through various deep learning models, we learned the data in various ways and extracted the features to recognize hand gestures. Deep learning models used are Faster-RCNN, ResNet, U-Net, and 3D-CNN. Since we recognize hand gestures in the virtual space and use them as user interfaces, we want to contribute to using virtual / augmented reality through high recognition rates and fast recognition speeds without the help of specific sensors or wearable devices."
딥러닝 모델을 사용한 게임 봇 탐지 시스템에서 판단 근거 분석을 위한 기법,2020,"['Game Bot Detection', 'Online Game', 'XAI', 'Deep Learning', 'Machine Learning', '게임 봇 탐지', '온라인 게임', 'XAI', '딥러닝', '기계학습']","최근 온라인 게임 시장 규모가 급격히 성장하면서, 게임 내 재화를 획득하기 위한 부정행위가 빈번하게 발생하고 있다. 대표적인 부정행위 중 하나인 게임 봇 (game bot)은 게임 내 재화를 부정하게 수집하여, 게임 내 균형을 파괴하고 콘텐츠를 빠르게 고갈시켜 게임 수명을 단축시키는 문제를 야기한다. 본 논문에서는 사용자 행위 로그를 입력으로 하는 다층 퍼셉트론(Multi Layer Perceptron)을 적용하여 정상 사용자와 게임 봇을 분류하고, 각 행위가 분류에 영향을 끼친 정도를 수치화하여 판단 근거를 추론하는 모델을 제안한다. 제안한 모델을 ‘AION’ 게임의 실제 로그 데이터에 적용하여 10겹 교차 검증으로 테스트한 결과 약 98.4%의 정확도와 99.6%의 재현율을 보였다.","As the online game market has grown rapidly in recent years, cheating has frequently occurred to get items in the game. Game bots, which are one of the most representative cheating behaviors, collect items in the game unfairly, causing problems in the game by destroying the balance in the game and rapidly depleting the content to shorten the game life. In this paper, we propose a model that classifies normal users and game bots by applying a Multi-Layer Perceptron(MLP) with user action log as input, and infers the basis of judgment by quantifying the degree to which each action affects the classification. The proposed model was applied to the actual log data of the ‘AION’ game and tested with 10-fold cross-validation, showing an accuracy of about 98.4% and a recall of about 99.6%."
지터에 강건한 딥러닝 기반 프로파일링 부채널 분석 방안,2020,"['Side-Channel Analysis', 'Deep Learning', 'Jitter', 'Global Average Pooling', 'AES']","딥러닝 기반 프로파일링 부채널 분석은 신경망을 이용해 부채널 정보와 중간값의 관계를 파악하는 공격 방법이다. 신경망은 신호의 각 시점을 별도의 차원으로 해석하므로 차원별 가중치를 갖는 신경망은 지터가 있는 데이터의 분포를 학습하기 어렵다. 본 논문에서는 CNN(Convolutional Neural Network)의 완전연결 층을 GAP(Global Average Pooling)로 대체하면 태생적으로 지터에 강건한 신경망을 구성할 수 있음을 보인다. 이를 입증하기 위해 ChipWhisperer-Lite 전력 수집 보드에서 수집한 파형에 대해 실험한 결과 검증 데이터 집합에 대한 완전연결 층을 사용하는 CNN의 정확도는 최대 1.4%에 불과했으나, GAP를 사용하는 CNN의 정확도는 최대 41.7%로 매우 높게 나타났다.","Deep learning-based profiling side-channel analysis is a powerful analysis method that utilizes the neural network to profile the relationship between the side-channel information and the intermediate value. Since the neural network interprets each point of the signal in a different dimension, jitter makes it much hard that the neural network with dimension-wise weights learns the relationship. This paper shows that replacing the fully-connected layer of the traditional CNN (Convolutional Neural Network) with global average pooling (GAP) allows us to design the inherently robust neural network inherently for jitter. We experimented with the ChipWhisperer-Lite board to demonstrate the proposed method: as a result, the validation accuracy of the CNN with a fully-connected layer was only up to 1.4%; contrastively, the validation accuracy of the CNN with GAP was very high at up to 41.7%."
딥러닝 기반 음향 신호 대역 확장 시스템,2020,"['Audio', 'Bandwidth Extension', 'Deep Learning', 'Convolutional Neural Network', 'Autoencoder']","대역 확장(Bandwidth Extension)이란 채널 용량 부족 혹은 이동통신 기기에 탑재된 코덱의 특성으로 인해 부호화 및 복호화 과정에서 대역 제한(band limited)되거나 손상된 협대역 신호(NB, Narrow Band)를 복원, 확장하여 광대역 신호(WB, Wide Band)로 전환 시켜주는 것을 의미한다. 대역 확장 연구는 주로 음성 신호 위주로 대역 복제(SBR, Spectral Band Replication), IGF(Intelligent Gap Filling)과 같이 고대역을 주파수 영역으로 변환하여 복잡한 특징 추출 과정을 거쳐 이를 바탕으로 사라지거나 손상된 고대역을 복원한다. 본 논문에서는 딥러닝 모델 중 오토인코더(Autoencoder)를 바탕으로 1차원 합성곱 신경망(CNN, Convolutional Neural Network)들의 잔차 연결을 활용하여 복잡한 사전 전처리 과정 없이 일정한 길이의 시간 영역 신호를 입력시켜 대역 확장 시킨 음향 신호를 출력하는 모델을 제안한다. 또한 음성 영역에 제한되지 않는 음악을 포함한 여러 종류의 음원을 포함하는 데이터셋에 훈련시켜도 손상된 고대역을 복원할 수 있음을 확인하였다.","Bandwidth Extension refers to restoring and expanding a narrow band signal(NB) that is damaged or damaged in the encoding and decoding process due to the lack of channel capacity or the characteristics of the codec installed in the mobile communication device. It means converting to a wideband signal(WB). Bandwidth extension research mainly focuses on voice signals and converts high bands into frequency domains, such as SBR (Spectral Band Replication) and IGF (Intelligent Gap Filling), and restores disappeared or damaged high bands based on complex feature extraction processes. In this paper, we propose a model that outputs an bandwidth extended signal based on an autoencoder among deep learning models, using the residual connection of one-dimensional convolutional neural networks (CNN), the bandwidth is extended by inputting a time domain signal of a certain length without complicated pre-processing. In addition, it was confirmed that the damaged high band can be restored even by training on a dataset containing various types of sound sources including music that is not limited to the speech."
딥러닝을 이용한 경량혼합토의 일축압축강도 예측 시스템,2020,"['경량혼합토', '인공신경망', '심층신경망', '딥러닝', 'Lightweight Treated Soil(LTS)', 'Artificial Neural Network(ANN)', 'Deep Neural Network(DNN)', 'Deep Learning', 'Deep-LTS']",경량혼합토의 일축압축강도는 배합비에 크게 의존한다. 경량혼합토와 다양한 경량혼합토의 구성성분들의 관계를 특징짓기 위한 기존연구에서는 시험을 통한 회귀모델을 사용하여 정규화계수를 제안하였다. 그러나 실내시험에서 얻은 결과는 재료와 배합비사이의 관계가 복잡하기 때문에 일정한 예측의 정확도를 기대할 수 없다. 이 연구에서는 다양한 배합조건에서 수행된 실내시험결과를 바탕으로 심층신경망 모델을 적용함으로써 경량혼합토의 일축압축강도를 예측하였다. 제안된 심층신경망 모델을 사용함으로써 설계 배합조건으로 구성된 경량혼합토의 일축압축강도 값을 합리적으로 산정할 수 있다.,"The unconfined compressive strength of lightweight treated soils strongly depends on mixing ratio. To characterize the relation between various LTS components and the unconfined compressive strength of LTS, extensive studies have been conducted, proposing normalized factor using regression models based on their experimental results. However, these results obtained from laboratory experiments do not expect consistent prediction accuracy due to complicated relation between materials and mix proportions. In this study, deep neural network model(Deep-LTS), which was based on experimental test results performed on various mixing conditions, was applied to predict the unconfined compressive strength. It was found that the unconfined compressive strength LTS at a given mixing ratio could be resonable estimated using proposed Deep-LTS."
딥러닝 오픈소스 프레임워크의 사례연구를 통한 도입 전략 도출,2020,"['딥러닝 프레임워크', '딥러닝 오픈소스 소프트웨어', '오픈소스 소프트웨어 도입', '기술-조직-환경 프레임워크', 'Deep learning framework', 'Deep learning open source software', 'Adoption of open source software', 'technology-organization-environment framework']",,"Many companies on information and communication technology make public their own developed AI technology, for example, Googles TensorFlow, Facebooks PyTorch, Microsofts CNTK. By releasing deep learning open source software to the public, the relationship with the developer community and the artificial intelligence (AI) ecosystem can be strengthened, and users can perform experiment, implementation and improvement of it. Accordingly, the field of machine learning is growing rapidly, and developers are using and reproducing various learning algorithms in each field. Although various analysis of open source software has been made, there is a lack of studies to help develop or use deep learning open source software in the industry. This study thus attempts to derive a strategy for adopting the framework through case studies of a deep learning open source framework.  Based on the technology-organization-environment (TOE) framework and literature review related to the adoption of open source software, we employed the case study framework that includes technological factors as perceived relative advantage, perceived compatibility, perceived complexity, and perceived trialability, organizational factors as management support and knowledge & expertise, and environmental factors as availability of technology skills and services, and platform long term viability. We conducted a case study analysis of three companies adoption cases (two cases of success and one case of failure) and revealed that seven out of eight TOE factors and several factors regarding company, team and resource are significant for the adoption of deep learning open source framework. By organizing the case study analysis results, we provided five important success factors for adopting deep learning framework: the knowledge and expertise of developers in the team, hardware (GPU) environment, data enterprise cooperation system, deep learning framework platform, deep learning framework work tool service.  In order for an organization to successfully adopt a deep learning open source framework, at the stage of using the framework, first, the hardware (GPU) environment for AI R&D group must support the knowledge and expertise of the developers in the team. Second, it is necessary to support the use of deep learning frameworks by research developers through collecting and managing data inside and outside the company with a data enterprise cooperation system. Third, deep learning research expertise must be supplemented through cooperation with researchers from academic institutions such as universities and research institutes. Satisfying three procedures in the stage of using the deep learning framework, companies will increase the number of deep learning research developers, the ability to use the deep learning framework, and the support of GPU resource. In the proliferation stage of the deep learning framework, fourth, a company makes the deep learning framework platform that improves the research efficiency and effectiveness of the developers, for example, the optimization of the hardware (GPU) environment automatically. Fifth, the deep learning framework tool service team complements the developers expertise through sharing the information of the external deep learning open source framework community to the in-house community and activating developer retraining and seminars.  To implement the identified five success factors, a step-by-step enterprise procedure for adoption of the deep learning framework was proposed: defining the project problem, confirming whether the deep learning methodology is the right method, confirming whether the deep learning framework is the right tool, using the deep learning framework by the enterprise, spreading the framework of the enterprise. The first three steps (i.e. defining the project problem, confirming whether the deep learning methodology is the right method, and confirming whether the deep learning framewo"
딥러닝을 이용한 증강현실 기반 음료정보 시각화 및 공유 시스템,2020,"['영상인식', '증강현실', '딥러닝', '상품검색', '정보공유시스템', 'Image Recognition', 'Augmented Realty', 'Deep Learning', 'Product Search', 'Share system']",,"In this paper, we introduce a system that searches for commercial beverages and alcohol products using image recognition technology and visualizes the information of the products using augmented reality system. It also introduces the design and development of a system that allows users to register and share product taste information using a web-based mobile platform. For image recognition, learning data was generated through the data set construction and expansion technology of beverage images and CNN learning was conducted. For augmented reality visualization, the augmented reality system is designed to operate by immediately registering a marker after product recognition using a UDT marker . Lastly, we proposed a consumer-friendly sharing system applying the product recommendation technology developed by the multiple linear regression model. The proposed research is expected to make it easy for consumers to obtain product information through cameras and to be applied as a new business strategy in the information retrieval and sharing market."
딥러닝을 이용한 이미지 레이블 추출 기반 해시태그 추천 시스템 설계 및 구현,2020,"['소셜 미디어', '레이블 추출', '태그 추천', '딥 러닝', '인공 지능', 'Social Medea', 'Label Extraction', 'Tag Recommendation', 'Deep Learning', 'AI']","소셜 미디어에서 일반적으로 게시물을 올릴 때 이미지의 태그 정보를 사용하는데, 태그를 이용하여 주로 검색이 이루어지기 때문이다. 사용자는 태그를 게시물에 붙임으로써 게시물을 많은 사람들에게 노출시키길 원한다. 또한, 사용자는 게시물과 함께 태깅될 태그를 붙이는 행위를 번거롭게 여겨 태깅하지 않은 게시물도 올리게 된다. 본 논문에서는 입력 이미지와 유사한 이미지를 찾아 해당 이미지에 부착된 레이블을 추출하여 그 레이블이 태그로 존재하는 인스타그램의 게시물들을 찾아 게시물 속 존재하는 다른 태그들을 추천해주는 방법을 제안한다. 제안하는 방법에서는 CNN(Convolutional Neural Network) 딥러닝 기법의 모델을 통하여 이미지로부터 레이블을 추출하여 추출된 레이블로 인스타그램을 크롤링하여 레이블 외의 태그를 정렬하여 추천해준다. 추천된 태그를 이용하여 이미지를 게시하기도 편해지고, 검색의 노출을 높일 수 있고, 검색오류가 적어 높은 정확도를 도출할 수 있음을 알 수 있다.","In social media, when posting a post, tag information of an image is generally used because the search is mainly performed using a tag. Users want to expose the post to many people by attaching the tag to the post. Also, the user has trouble posting the tag to be tagged along with the post, and posts that have not been tagged are also posted. In this paper, we propose a method to find an image similar to the input image, extract the label attached to the image, find the posts on instagram, where the label exists as a tag, and recommend other tags in the post. In the proposed method, the label is extracted from the image through the model of the convolutional neural network (CNN) deep learning technique, and the instagram is crawled with the extracted label to sort and recommended tags other than the label. We can see that it is easy to post an image using the recommended tag, increase the exposure of the search, and derive high accuracy due to fewer search errors."
딥러닝을 이용한 파랑·풍속 상호자료의 예측 기법,2020,"['Deep learning(딥러닝)', 'Prediction technique(예측기법)', 'Wave(파랑)', 'Wind(바람)']",,"This study aims to predict wave and wind using deep learning technique. The data for training the deep learning model were used hourly data (41,693) observed from 2014 to 2018, and the trained deep learning model was applied to the prediction of wind and wave in 2019. To predict the significant wave height, we used wind speed, wind direction, and wave direction as input data. The model results showed similar variation patterns with observed and predicted values. The correlation coefficient was 0.83 and the mean absolute error was 0.283 m. In the wind speed prediction, significant wave height, wave direction, wave period, and wind direction were used as input data. The deep learning model results showed error coefficients of correlation coefficient (0.836) and mean absolute error (1.27 ㎧). Finally, the deep learning model reproduced the maximum wave height in good agreement with observations."
딥러닝 기법을 이용한 웹 카메라 입력 자동차 번호판 인식,2020,"['자동차 번호판', '딥러닝', 'CNN', 'YOLO', 'Faster R-CNN', 'License Plate', 'Deep Learning', 'CNN', 'YOLO', 'Faster R-CNN']",,
딥러닝 기반 의료영상 분석을 위한 데이터 증강 기법,2020,"['Deep Learning', 'Medical Imaging', 'Data Analysis']","영상처리 기반으로 의료영상을 분석하는 기법은 정상 환자와 비정상 환자를 분류, 병변 검출및 장기나 병변의 분할 등에 사용되고 있다. 최근 인공지능 기술의 비약적 발전으로 의료영상 분석 연구들이 딥러닝 기술을 활용하여 시도되고 있다. 의료영상은 학습에 필요한 데이터를 충분히 모으기 어렵고 클래스별 데이터 수의 차이 때문에, 딥러닝 모델의 성능을 올리는데어려움이 있다. 이러한 문제를 해결하기 위해 다양한 연구가 시도되고 있으며, 이 중 하나가학습 데이터를 증강하는 것이다. 본 종설에서는 회전, 역상, 밝기 변화 등과 같은 영상처리 기반의 데이터 증강, 적대적생성네트워크를 활용한 데이터 증강, 그리고 기존 영상의 속성들을섞는 등의 최신 데이터 증강 기법을 알아보고, 의료영상 연구에 적용된 사례들과 그 결과를조사해 보고자 한다. 끝으로 데이터 증강의 필요성을 고찰하고 앞으로의 방향을 짚어본다.","Medical image analyses have been widely used to differentiate normal and abnormal cases, detect lesions, segment organs, etc. Recently, owing to many breakthroughs in artificial intelligence techniques, medical image analyses based on deep learning have been actively studied.However, sufficient medical data are difficult to obtain, and data imbalance between classes hinder the improvement of deep learning performance. To resolve these issues, various studies have been performed, and data augmentation has been found to be a solution. In this review, we introduce data augmentation techniques, including image processing, such as rotation, shift, and intensity variation methods, generative adversarial network-based method, and image property mixing methods. Subsequently, we examine various deep learning studies based on data augmentation techniques. Finally, we discuss the necessity and future directions of data augmentation."
딥러닝을 사용하는 IoT빅데이터 인프라에 필요한 DNA 기술을 위한 분산 엣지 컴퓨팅기술 리뷰,2020,"['IoT', 'Deep Learning', 'Edge Computing', 'Distributed Training', 'DNA', '딥러닝', '엣지컴퓨팅', '분산훈련']",,"Nowadays, Data-Network-AI (DNA)-based intelligent services and applications have become a reality to provide a new dimension of services that improve the quality of life and productivity of businesses. Artificial intelligence (AI) can enhance the value of IoT data (data collected by IoT devices). The internet of things (IoT) promotes the learning and intelligence capability of AI. To extract insights from massive volume IoT data in real-time using deep learning, processing capability needs to happen in the IoT end devices where data is generated. However, deep learning requires a significant number of computational resources that may not be available at the IoT end devices. Such problems have been addressed by transporting bulks of data from the IoT end devices to the cloud datacenters for processing. But transferring IoT big data to the cloud incurs prohibitively high transmission delay and privacy issues which are a major concern. Edge computing, where distributed computing nodes are placed close to the IoT end devices, is a viable solution to meet the high computation and low-latency requirements and to preserve the privacy of users. This paper provides a comprehensive review of the current state of leveraging deep learning within edge computing to unleash the potential of IoT big data generated from IoT end devices. We believe that the revision will have a contribution to the development of DNA-based intelligent services and applications. It describes the different distributed training and inference architectures of deep learning models across multiple nodes of the edge computing platform. It also provides the different privacy-preserving approaches of deep learning on the edge computing environment and the various application domains where deep learning on the network edge can be useful. Finally, it discusses open issues and challenges leveraging deep learning within edge computing."
딥러닝(Deep learning) 기반 미술 학습 지원도구 개발: 생성 모델링(Generative modeling)을 활용하여,2020,"['deep learning', 'generating model', 'art education', 'artificial intelligence', '딥러닝', '생성 모델', '미술교육', '인공지능']",,"With the development of artificial intelligence in the 4th Industrial Revolution, changes are being made by applying artificial intelligence to various industrial fields. In the contemporary art world, there is an active consideration about the location of the art field in which artificial intelligence is involved. Since education is an open reflection in the demands and transition of the times, it can be seen that art education is naturally affected by the modern art world. Therefore, according to the change of the modern art world, art education using artificial intelligence is needed in schools. In this study, the art learning support tool based on deep learning were developed to support students’ art education activities. The art learning support tool used the neural transfer algorithm in deep learning generative models. The neural transfer algorithm can combine two images to create a single image. In order to develop the art learning support tool, researchers developed initial prototypes through literature research and needs analysis according to the design and development research methodology. The students’ satisfaction level with the tool was analyzed through class demonstrations. In the survey of the effects and perceptions of art learning support tools, learners were generally satisfied with it. In the future, it will be used in various expression education fields when the tool offers the user-centered guideline and students have a higher-ability for dealing with related software."
딥러닝을 활용한 산지습지 수위 예측 모형 개발,2020,"['딥러닝', '산지습지', '주성분분석', '인공신경망', 'Deep Learning', 'Mountain Wetland', 'Principal Component Analysis', 'Artificial Neural Network']",,"Wetlands play an important function and role in hydrological, environmental, and ecological, aspects of the watershed.Water level in wetlands is essential for various analysis such as for the determination of wetland function and its effects on the environment. Since several wetlands are ungauged, research on wetland water level prediction are uncommon.Therefore, this study developed a water level prediction model using multiple regression analysis, principal component regression analysis, artificial neural network, and DNN to predict wetland water level. Geumjeong-Mountain Wetland located in Yangsan-city, Gyeongsangnam-do province was selected as the target area, and the water level measurement data from April 2017 to July 2018 was used as the dependent variable. On the other hand, hydrological and meteorological data were used as independent variables in the study. As a result of evaluating the predictive power, the water level prediction model using DNN was selected as the final model as it showed an RMSE value of 6.359 and an NRMSE value of 18.91%. This research study is believed to be useful especially as a basic data for the development of wetland maintenance and management techniques using the water level of the existing unmeasured points."
딥러닝 합성곱 신경망을 이용한 효율적인 홍채인식,2020,"['고차 국소 자동 상관함수', '역전파 신경망', '딥러닝', '합성곱 신경망', 'Higher Order Local Autocorrelation Function', 'Back-Propagation', 'Back-Propagation Neural Network', 'Deep Learning', 'Convolution Neural Network']",본 논문은 홍채영상의 이동불변의 특징값 을추출에 탁월한 고차 국소 자동 상관함수를 적용하여 25개의 특징 값을 입력 값으로 적용한 일반적인 HOLP 신경망에 특징 값 25개의 평균값을 추가한 개선된 HOLP 신경망을 구현하여 인식률을 확인하여 보았다. 종류가 상이한 딥러닝 구조들과 비교하였을 때 음성과 영상 분야에서 탁월한 성능을 보이는 Back-Propagation 신경망과 특징 추출기와 분류기를 통합한 합성 곱 신경망을 활용하여 홍채인식의 인식률을 비교하여 보았다.,"This paper presents an improved HOLP neural network that adds 25 average values to a typical HOLP neural network using 25 feature vector values as input values by applying high-order local autocorrelation function, which is excellent for extracting immutable feature values of iris images. Compared with deep learning structures with different types, we compared the recognition rate of iris recognition using Back-Propagation neural network, which shows excellent performance in voice and image field, and synthetic product neural network that integrates feature extractor and classifier."
딥러닝 자연어처리(NLP)와 일반수사학 (General Rhetoric)과의 융합적 접점 분석 - 그룹 뮤(Groupe μ)의 『A General Rhetoric』을 중심으로,2020,"['수사학', '수사학적 공간', '자연어처리 데이터 셋', 'RNN 언어모델', '딥러닝', '메타볼', '메타볼 유형', '그룹 뮤', 'GPT-3', 'general rhetoric', 'rhetorical space', 'natural language processing', 'NLP data set', 'RNN language model', 'deep learning', 'the type of metaboles', 'Groupe μ', 'subunits']",,"In this article, I attempt to analyze the structural similarity between the semantic structure of poetry and rhetorical language on which Groupe μ is focusing and the RNN language model. The main focus of this article was concentrated on the type of ‘metaboles’ that categorizes the functions of poetry and rhetorical language. This type and its insight are considerably useful not only in connection with natural language processing technology but also a application field. In particular, the approach for the idea of ‘rhetorical space’ can be substantially an important concept in terms of connection with deep learning technology of NLP. In addition, this approach shows the fact that it is the paramount importance to prepare a precise language data set which has ‘Degree Zero’ and ‘Subunits’ of the linguistic code. Ultimately, through this convergence analysis, we realize that the trans-disciplinary attitude of the humanities and engineering is inevitably important."
전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론,2020,"['딥러닝', '전문성 이식', '전이 학습', '이미지 캡셔닝', '인공지능', 'Deep Learning', 'Expertise Transplant', 'Transfer-Learning', 'Image Captioning', 'Artificial Intelligence']",,"Recently, as deep learning has attracted attention, the use of deep learning is being considered as a method for solving problems in various fields. In particular, deep learning is known to have excellent performance when applied to applying unstructured data such as text, sound and images, and many studies have proven its effectiveness. Owing to the remarkable development of text and image deep learning technology, interests in image captioning technology and its application is rapidly increasing. Image captioning is a technique that automatically generates relevant captions for a given image by handling both image comprehension and text generation simultaneously. In spite of the high entry barrier of image captioning that analysts should be able to process both image and text data, image captioning has established itself as one of the key fields in the A.I. research owing to its various applicability. In addition, many researches have been conducted to improve the performance of image captioning in various aspects. Recent researches attempt to create advanced captions that can not only describe an image accurately, but also convey the information contained in the image more sophisticatedly.  Despite many recent efforts to improve the performance of image captioning, it is difficult to find any researches to interpret images from the perspective of domain experts in each field not from the perspective of the general public. Even for the same image, the part of interests may differ according to the professional field of the person who has encountered the image. Moreover, the way of interpreting and expressing the image also differs according to the level of expertise. The public tends to recognize the image from a holistic and general perspective, that is, from the perspective of identifying the image’s constituent objects and their relationships. On the contrary, the domain experts tend to recognize the image by focusing on some specific elements necessary to interpret the given image based on their expertise. It implies that meaningful parts of an image are mutually different depending on viewers perspective even for the same image. So, image captioning needs to implement this phenomenon.  Therefore, in this study, we propose a method to generate captions specialized in each domain for the image by utilizing the expertise of experts in the corresponding domain. Specifically, after performing pre-training on a large amount of general data, the expertise in the field is transplanted through transfer-learning with a small amount of expertise data. However, simple adaption of transfer learning using expertise data may invoke another type of problems. Simultaneous learning with captions of various characteristics may invoke so-called ‘inter-observation interference’ problem, which make it difficult to perform pure learning of each characteristic point of view. For learning with vast amount of data, most of this interference is self-purified and has little impact on learning results. On the contrary, in the case of fine-tuning where learning is performed on a small amount of data, the impact of such interference on learning can be relatively large. To solve this problem, therefore, we propose a novel ‘Character-Independent Transfer-learning’ that performs transfer learning independently for each character.  In order to confirm the feasibility of the proposed methodology, we performed experiments utilizing the results of pre-training on MSCOCO dataset which is comprised of 120,000 images and about 600,000 general captions. Additionally, according to the advice of an art therapist, about 300 pairs of ‘image / expertise captions’ were created, and the data was used for the experiments of expertise transplantation. As a result of the experiment, it was confirmed that the caption generated according to the proposed methodology generates captions from the perspective of implanted expertise whereas the caption generated thro"
딥러닝 기반 소나무 재선충 피해목 탐색,2020,"['소나무 재선충', '드론', 'RGB 정사영상', '딥러닝 분류기', 'pine wilt disease', 'unmanned aviation vehicle', 'RGB ortho-image', 'deep learning-based classifier', 'heat map']","소나무 재선충은 한국과 일본, 중국을 포함한 동아시아 지역의 소나무산림에 막대한 피해를 주는 원인이며, 피해목의 조기 발견과 제거는 재선충 확산을 막는 효과적인 방법이다. 본 논문에서는 드론으로 촬영되고 처리된 RGB 정사영상을 딥러닝 분류에 의한 재선충 피해목 탐색방법을 제안한다. 제안된 방법은 학습영상 데이터가 많지 않다는 가정아래 ResNet18을 백본으로 하는 패치기반의 분류기를 구성하고 RGB 정사영상을 분류하고 그 결과를 heatmap 형태로 만든다. 제작된 정사영상의 heat map는 재선충 피해목의 분포를 알아내고 확산해가는 모습을 관찰할 수 있게 하며, 재선충 피해목 지역의 RGB 분포 특징을 추출해낼 수도 있다. 본 연구의 패치기반 분류기 성능은 94.7%의 정확도를 나타내었다.","Pine wilt disease is one of the reasons that results in huge damage on pine trees in east Asia including Korea, Japan, and China, and early finding and removing the diseased trees is an efficient way to prevent the forest from wide spreading. This paper proposes a searching method of the damaged pine trees from wilt disease in ortho-images corrected from RGB images, which are captured by unmanned aviation vehicles. The proposed method constructs patch-based classifier using ResNet18 backbone network, classifies the RGB ortho-image patches, and make the results as a heat map. The heat map can be used to find the distribution of diseased pine trees, to show the trend of spreading disease, and to extract the RGB distribution of the diseased areas in the image. The classifier in the work shows 94.7% of accuracy."
딥러닝 기반 영상 분석 알고리즘을 이용한 실시간 작업자 안전관리 시스템 개발,2020,"['객체 검출', '딥러닝', '영상 분석', '실시간', 'Object detection', 'Deep learning', 'Video analysis', 'Real-time']","본 논문에서는 산업 시설에서 작업자의 안전을 실시간으로 감시하는 딥러닝 기반 영상 분석 시스템을 구현하는 데 목적을 둔다. 작업자의 복장을 안전모, 안전조끼, 안전벨트 착용 여부에 따라 총 여섯 가지의 클래스로 나누고, 총 5,307개의 영상을 학습데이터로 이용하였다. 실험은 속도와 정확도가 준수한 YOLO v4를 이용하였으며, 총 645장의 영상에 대해 학습 반복 수에 따른 가중치를 적용했을 때의 mAP를 비교함으로써 수행되었다. 학습 반복 수 6,000에서의 mAP가 60.13%로 제일 높았으며, 테스트셋이 가장 많은 클래스의 AP가 가장 높음을 확인하였다. 추후 데이터셋과 객체 검출 모델을 최적화함으로써, 정확도와 속도를 개선할 예정이다.","The purpose of this paper is to implement a deep learning-based real-time video analysis algorithm that monitors safety of workers in industrial facilities. The worker s clothes were divided into six classes according to whether workers are wearing a helmet, safety vest, and safety belt, and a total of 5,307 images were used as learning data. The experiment was performed by comparing the mAP when weight was applied according to the number of learning iterations for 645 images, using YOLO v4. It was confirmed that the mAP was the highest with 60.13% when the number of learning iterations was 6,000, and the AP with the most test sets was the highest. In the future, we plan to improve accuracy and speed by optimizing datasets and object detection model."
딥러닝 기반의 얼굴인증 시스템 설계 및 구현,2020,"['딥러닝', '얼굴인식', '영상처리', '결합베이시안', '능동적 형태 모델', 'deep learning', 'face authentication', 'image processing', 'joint bayesian', 'active shape model']",,"This paper proposes a face authentication system based on deep learning framework. The proposed system is consisted of face region detection and feature extraction using deep learning algorithm, and performed the face authentication using joint-bayesian matrix learning algorithm. The performance of proposed paper is evaluated by various face database , and the face image of one person consists of 2 images. The face authentication algorithm was performed by measuring similarity by applying 2048 dimension characteristic and combined Bayesian algorithm through Deep Neural network and calculating the same error rate that failed face certification. The result of proposed paper shows that the proposed system using deep learning and joint bayesian algorithms showed the equal error rate of 1.2%, and have a good performance compared to previous approach."
딥러닝을 활용한 대학생활 부적응자 조기 예측 프로그램 개발,2020,"['대학생활 부적응 예측', '딥 러닝', 'Predicting misfit students for college', 'Deep learning']",,
딥러닝을 이용한 조선소에서 쓰러진 작업자의 검출에 관한 연구,2020,"['Ship', 'Fallen', 'Deep learning', 'Image', 'Safety', '선박', '쓰러짐', '딥러닝', '이미지', '안전']","선박은 크고, 복잡한 구조로 되어 있기 때문에 다른 작업자의 위치를 알아내기 어려우며, 특히 작업자가 쓰러진 경우에는 발견하기가 쉽지 않아 신속한 대처가 어렵다. 그리하여, 신체에 디바이스를 부착하는 방법이나 카메라를 이용하여 쓰러짐을 검출하기 위한 연구가 진행되고 있다. 기존의 영상기반 쓰러짐 검출은 사람의 신체부위를 검출하여 쓰러짐을 판단하였으나, 조선소에서는 다양한 복장과 자세로 작업으로 인해 검출하기가 어렵다. 본 논문에서는 쓰러짐 영역 전체를 추출하여 딥러닝 학습으로 선박 작업자의 쓰러짐을 이미지 기반으로 검출하였다. 학습에 필요한 데이터는 조선소의 건조중인 선박에서 쓰러진 모습을 연출하여 획득하였으며, 이미지를 좌우대칭, 크기조절, 회전하여 학습 데이터의 수를 증가하였다. 성능평가는 정밀도, 재현율, 정확도 그리고 오차율로 평가하였으며, 데이터의 수가 많을수록 정밀도가 향상되었다. 다양한 데이터를 보강하면 카메라를 이용한 쓰러짐 검출 모델의 실효성이 향상됨으로서 안전 분야에 기여할 수 있을 것으로 사료된다.","In large ships with complex structures, it is difficult to locate workers. In particular, it is not easy to detect when a worker falls down, making it difficult to respond quickly. Thus, research is being conducted to detect fallen workers using a camera or by attaching a device to the body. Existing image-based fall detection systems have been designed to detect a person's body parts; hence, it is difficult to detect them in various ships and postures. In this study, the entire fall area was extracted and deep learning was used to detect the fallen shipworker based on the image. The data necessary for learning were obtained by recording falling states at the shipyard. The amount of learning data was augmented by flipping, resizing, and rotating the image. Performance evaluation was conducted with precision, reproducibility, accuracy, and a low error rate. The larger the amount of data, the better the precision. In the future, reinforcing various data is expected to improve the effectiveness of camera-based fall detection models, and thus improve safety."
딥러닝을 이용한 장기 파랑예측 가능성 연구,2020,"['Deep learning', 'Convolutional neural network', 'Wave prediction', 'Xception']",,"Numerical wave prediction models require a large amount of computational power to timely complete the required calculations. Artificial Neural Networks (ANN) have been introduced to perform predictions at a lesser computational cost and increased processing speed. Deep learning and specifically Convolutional Neural Networks (CNN) have become accepted for various image recognition applications. Motivation for the examination of wave prediction by deep learning came from the success of CNN in vision applications and the similarity of meteorological weather grid data to visual images. This study investigates a deep learning technique using the Japan Meteorological Agency’s Grid Point Value Mesoscale Model to predict wave height and period. In particular, this study uses the Xception deep learning architecture with depthwise separable convolution to obtain improved wave height and period prediction over artificial neural networks, and gets overall success results."
철도건설공사 세부공종별 공기예측을 위한 딥러닝 모델 적용성 연구,2020,"['딥러닝 알고리즘', '하이퍼 파라미터', '공기예측', '철도건설공사', 'Deep learning algorithm', 'Hyper parameter', 'Estimation of activity duration', 'Railway construction project']",,"Currently, as there are no prescribed regulations, construction activity duration for civil engineering project including railways is calculated by subjective judgment based on previous construction records or the experience of the construction manager. Since the method of estimating the activity duration can vary depending on the capabilities of the construction manager, it is difficult to appropriately calculate the construction duration. In this study, the authors propose a methodology for predicting the net construction duration for each activity by applying a deep learning algorithm that discovers patterns in large amounts of construction history already executed, self-learns, and provides comprehensive judgment and prediction for the calculation of net construction duration. For this, a deep learning application model that can be used for construction duration estimation was developed, and practical applicability was analyzed by comparing predicted and actual duration. Through this, it is considered possible to derive an objective construction duration more accurately than possible using existing estimation methods, and it is thought that utilization of deep learning in the construction management process will also increase."
딥러닝 기반의 얼굴과 제스처 인식을 활용한 원격 제어,2020,"['IoT', 'MQTT', 'Remote Control', 'Face Recognition', 'Gesture Recognition', 'Deep Learning']","IoT 기술과 이 확산됨에 따라 얼굴 인식을 활용하는 다양한 응용들이 등장하고 있다. 본 논문은 딥러닝 기반의 얼굴 인식과 손 제스처 인식을 활용하는 원격 제어 시스템을 설계 구현한 내용을 기술한다. 얼굴 인식을 활용하는 응용 시스템은 카메라로부터 실시간으로 영상을 촬영하는 부분과 영상으로부터 얼굴을 인식하는 부분, 그리고 인식된 결과를 활용하는 부분으로 구성된다. 영상을 실시간으로 촬영하기 위해서 어디서나 장착 가능한 싱글보드 컴퓨터인 라즈베리파 이를 이용하고, 서버 컴퓨터에는 FaceNet 모델을 활용하여 얼굴 인식 소프트웨어를 개발하고 OpenCV를 이용한 손 제스처 인식 소프트웨어도 개발하였다. 사용자를 알려진 사용자와 위험한 사용자 그리고 모르는 사용자의 3 그룹으로 구분하고, 얼굴 인식과 손 제스처가 모두 통과된 알려진 사용자에 대해서만 자동 도어락을 오픈하는 응용을 설계 구현하였다.","With the spread of IoT technology, various IoT applications using facial recognition are emerging. This paper describes the design and implementation of a remote control system using deep learning-based face recognition and hand gesture recognition. In general, an application system using face recognition consists of a part that takes an image in real time from a camera, a part that recognizes a face from the image, and a part that utilizes the recognized result. Raspberry PI, a single board computer that can be mounted anywhere, has been used to shoot images in real time, and face recognition software has been developed using tensorflow's FaceNet model for server computers and hand gesture recognition software using OpenCV. We classified users into three groups: Known users, Danger users, and Unknown users, and designed and implemented an application that opens automatic door locks only for Known users who have passed both face recognition and hand gestures."
딥러닝을 이용한 실시간 말벌 분류 시스템,2020,"['Hornet classification', 'Deep learning', 'Object Detection', 'Object labeling', 'Mish function', 'Spatial attention module']","말벌 종은 모양이 매우 유사하기 때문에 비전문가가 분류하기 어렵고, 객체의 크기가 작고 빠르게 움직이기 때문에 실시간으로 탐지하여 종을 분류하는 것은 더욱 어렵다. 본 논문에서는 바운딩 박스를 이용한 딥러닝 알고리즘을 기반으로 말벌 종을 실시간으로 분류하는 시스템을 개발하였다. 훈련 영상의 레이블링 작업 시 바운딩 박스 안에 포함되는 배경 영역을 최소화하기 위하여 말벌의 머리와 몸통 부분만을 선택하는 방법을 제안한다. 또한 실시간으로 말벌을 탐지하고 그 종을 분류할 수 있는 최선의 알고리즘을 찾기 위하여 기존의 바운딩 박스 기반 객체 인식 알고리즘들을 실험을 통하여 비교한다. 실험 결과 컨볼루션 레이어의 활성함수로 mish 함수를 적용하고, 객체 검출 블록 전에 공간집중모듈(Spatial Attention Module, SAM)을 적용한 YOLOv4 모델을 사용하여 말벌 영상을 테스트한 경우 평균 97.89%의 정밀도(Precision)와 98.69%의 재현율(Recall)을 나타내었다.","The hornet species are so similar in shape that they are difficult for non-experts to classify, and because the size of the objects is small and move fast, it is more difficult to detect and classify the species in real time. In this paper, we developed a system that classifies hornets species in real time based on a deep learning algorithm using a boundary box. In order to minimize the background area included in the bounding box when labeling the training image, we propose a method of selecting only the head and body of the hornet. It also experimentally compares existing boundary box-based object recognition algorithms to find the best algorithms that can detect wasps in real time and classify their species. As a result of the experiment, when the mish function was applied as the activation function of the convolution layer and the hornet images were tested using the YOLOv4 model with the Spatial Attention Module (SAM) applied before the object detection block, the average precision was 97.89% and the average recall was 98.69%."
딥러닝을 이용한 소규모 지역의 영상분류 적용성 분석 : UAV 영상을 이용한 농경지를 대상으로,2020,"['Deep Learning', 'UAV', 'Image Classification', 'Random Forest', 'Semantic Classification', '딥러닝', '무인항공기', '영상분류', '랜덤 포레스트', '의미론적 영상분류']",,
딥러닝과 지리변수를 결합한 농경지 토양특성의 공간적 분포 예측,2020,"['지리변수', '전자토양도 작성', '심층 신경망', '공간적 자기상관성', '스마트 농업', 'geographical variable', 'digital soil mapping', 'deep neural network', 'spatial autocorrelation', 'smart farm']","농경지에서 토양의 지리적 분포에 대한 이해는 토양 생태계서비스를 증진시키고 환경에 대한 부정적인 영향을 줄이는 데 필요하다. 본 연구는 농경지 토양특성의 지리적 분포를 파악하기 위해 비공간기법인 딥러닝과 토양특성의 공간적 자기상관성을 고려할 수 있는 지리변수를 결합한 방식을 적용하고자 한다. 결과로 첫째, 모든 토양특성에서 공통적으로 전체설명변수를 사용했을 때보다 나은 평가 결과를 보이는 변수조합이 있었다. 두 번째, 모든 토양특성에 대해 지리변수가 환경변수 기반 모형보다 항상 좋은 평가 결과를 보이지는 않았지만 토양예측에서 적극적으로 활용할 수 있는 가능성을 확인하였다. 마지막으로 환경변수와 지리변수를 함께 사용했던 방식도 항상 나은 결과를 보이지는 않았다. 토양특성의 지리적 분포를 살펴보면 유기물 함량과 토양 pH가 가장 낮은 지역은 석교천에 가까운 진도의 중앙에 위치한 지역이었다. 유효인산의경우 주로 농경지 중에서 상대적으로 고도가 높은 산록완사면 부분에 위치한 밭을 중심으로 함량이 높게 나타났다. 본 연구를 통해 지속가능한 농경지 토양 관리를 위해 필요한 전자토양도 알고리듬을 구축하는 데 도움이 될 수 있을 것이다.","Understanding the spatial distribution of soil in the agricultural landscape is essential for promoting soil ecosystem services and reducing negative impacts on the environment. The purpose of this study is to apply a method that combines deep learning, a non-spatial technique, and geographic variables that can take into account the spatial autocorrelation of soil properties in order to understand the spatial distribution of soil properties in an agricultural landscape. As a result, first, there were variable combinations that showed better assessment results than when using all variables in all soil properties. Second, for all soil properties, geographic variable-based models did not always show better the assessment results than environmental variablebased models, but it was confirmed that geographic variables can be actively used in soil prediction. Finally, the method of combining environmental and geographic variables did not always yield better results. When examining the spatial distribution of soil properties, the region with the lowest organic matter content and soil pH was the region located in the center of Jindo, close to Seokgyo river. In the case of available phosphorus, the content was high mainly in the fields located on the pediment with relatively high altitude among agricultural land. This study can help to build a digital soil map algorithm necessary for sustainable agricultural soil management."
딥러닝을 이용한 영상 기반의 화재 위치 감지,2020,"['CCTV Video Analysis', 'Convolution Neural Network', 'Deep Learning', 'Fire Detection']",,"To avoid the large scale of damage of fire occurred, it is necessary to have a system to detect the incident as soon as possible. Traditional sensors and vision based systems for fire detection is limited in indoors and need more computational time and memory, restricting its implementation. In this paper, we propose a video-based fire detection system using deep learning to solve these problems. To run real-time detection in video stream, the activity detection is performed within a single image frame and makes prediction with a single network evaluation. The object detection algorithm we applied can tell the location as well as the presence of fire. It allows us to analyze the cause of the fire through video and monitor extensive areas efficiently. The results of the proposed system showed 99% precision, 99% accuracy and 100% recall. Experimental results show that the proposed method has excellent fire detection performance."
딥러닝을 이용한 컨베이어 시스템의 배출구 막힘 상태 판단 기술에 관한 연구,2020,"['컨베이어 시스템', '막힘 판단', '딥러닝', 'CNN', 'VGGNet', 'ResNet', 'DenseNet', 'NASNet', 'Conveyor Systems', 'Blockage Determination', 'Deep Learning', 'Convolutional Neural Network', 'Visual Geometry Group Network', 'Residual Network', 'Dense Network', 'Neural Architecture Search Network']","본 연구는 컨베이어 시스템에서 딥러닝을 이용한 배출구 막힘 판단 기술에 대하여 제안한다.제안 방법은 산업 현장의 CCTV에서 수집한 영상을 이용하여 배출구 막힘 판단을 위한 다양한CNN 모델들을 학습시키고, 성능이 가장 좋은 모델을 사용하여 실제 공정에 적용하는 것을 목적으로 한다. CNN 모델로는 잘 알려진 VGGNet, ResNet, DenseNet, 그리고 NASNet을 사용하였으며, 모델 학습과 성능 테스트를 위하여 CCTV에서 수집한 18,000장의 영상을 이용하였다. 다양한 모델에 대한 실험 결과, VGGNet은 99.89%의 정확도와 29.05ms의 처리 시간으로 가장 좋은 성능을 보였으며, 이로부터 배출구 막힘 판단 문제에 VGGNet이 가장 적합함을 확인하였다.","This study proposes a technique for the determination of outlet blockage using deep learning in a conveyor system. The proposed method aims to apply the best model to the actual process, where we train various CNN models for the determination of outlet blockage using images collected by CCTV in an industrial scene.We used the well-known CNN model such as VGGNet, ResNet, DenseNet and NASNet, and used 18,000 images collected by CCTV for model training and performance evaluation. As a experiment result with various models, VGGNet showed the best performance with 99.03% accuracy and 29.05ms processing time, and we confirmed that VGGNet is suitable for the determination of outlet blockage."
딥러닝을 이용한 평판에서의 과도 전도 열전달에 대한 연구,2020,"['딥러닝', '컨볼루션 신경망', '전도 열전달', '온도 분포', 'Deep learning', 'Convolutional neural network', 'Conduction heat transfer', 'Temperature distribution']",,"The temperature distributions were numerically calculated for the two-dimensional transient conduction heat transfer problem of a square plate. The obtained temperature distributions were converted into colors to create images, and they were provided as learning and test data of CNN. Classification and regression networks were constructed to predict representative wall temperatures through CNN analysis. As results, the classification networks predicted the representative wall temperatures with an accuracy of 99.91% by erroneously predicting only 1 out of 1100 images. The regression networks predicted the representative wall temperatures within errors of C. From this fact, it was confirmed that the deep learning techniques are applicable to the transient conduction heat transfer problems."
딥러닝 기반의 장소이미지 수집기술 설계,2020,"['Deep Learning', 'Place Image', 'CNN(Convolutional Neural Network)', 'Image Collecting', 'Web Service', '딥러닝', '장소 이미지', '컨볼루셔널 뉴럴 네트워크', '이미지 수집', '웹 서비스']",본 연구에서는 딥러닝 처리기술을 이용한 이미지 분석을 통하여 위치정보가 없는 사진의 위치를 사용자에게 제공하는 장소이미지 수집기술을 설계하였다. 본 서비스는 사용자가 생활 중에 관심 있는 장소의 이미지 사진을 서비스에 업로드하면 해당 장소의 이름과 위치뿐만 아니라 관련 주변 정보를 확인 할 수 있는 서비스 개발을 목적으로 설계되었다. 본 연구는 이미지에 해당하는 정보를 제공하고 그 위치 정보를 기반으로 사용자가 관심 있는 주변정보를 제공할 수 있는 서비스의 기반기술이다. 이를 통하여 다양한 서비스에 활용이 가능하다.,"This research study designed a location image collecting technology. It provides the exact location information of an image which is not given in the photo to the user. Deep learning technology analysis and collects the images. The purpose of this service system is to provide the exact place name, location and the various information of the place such as nearby recommended attractions when the user upload the image photo to the service system. Suggested system has a deep learning model that has a size of 25.3MB, and the model repeats the learning process 50 times with a total of 15,266 data, performing 93.75% of the final accuracy. This system can also be linked with various services potentially for further development."
딥러닝 기반의 사용자인증을 활용한 어린이 버스에서 안전한 승차 및 하차 시스템 설계,2020,"['Safety system', 'Safety accidents prevention', 'Smart mirror', 'User authentication', 'IoT', '안전시스템', '안전사고방지', '스마트 미러', '사용자 인증', '사물인터넷']","최근 어린이 차량의 승하차 과정에서 어린이 안전사고가 발생한다. 차량 인솔 교사가 없는 경우 버스에서 하차하지 않은 어린이의 질식사나 차량 전후방의 사각지대의 어린이 안전사고가 빈번하게 발생한다. 딥러닝 기반의 얼굴인식기술을 스마트 미러에 적용하여 사용자인증의 활용시 안전사고 방지를 위한 서비스가 가능하다. 스마트미러는 어린이를 위한 도우미 역할이 가능하고, 운전기사나 선생님이 미처 발견하지 못해 발생 가능할 사고를 방지할 수 있다. 어린이의 얼굴을 사전에 등록하여 어린이의 승하차시에 사용자인증을 수행하여 누락되지 않고, 버스의 전후방에 근접센서 및 카메라를 통해 안전사고를 미연에 방지할 수 있다. 본 연구는 어린이의 버스 승하차 과정에서 누락여부를 확인하고, 차량 전후방의 사각지대를 줄일 수 있는 시스템을 설계하고, GPS 정보를 활용하여 다양한 서비스가 가능한 안전시스템을 제안한다.","Recently, many safety accidents involving children shuttle buses take place. Without a teacher for help, a safety accident occurs when the driver can’t see a child who is getting off in the blind spot of both frontside and backside. A deep learning-based smart mirror allows user authentication and provides various services. Especially, It can be a role of helper for children, and prevent accidents that can occur when drivers or assistant teachers do not see them. User authentication is carried out with children’s face registered in advance. Safety accidents can be prevented by an approximate sensor and a camera in frontside and backside of the bus. This study suggests a way of checking out whether children are missed in the process of getting in and out of the bus, designs a system that reduce blind spots in the front and back of the vehicle, and builds a safety system that provide various services using GPS"
딥러닝을 위한 경사하강법 비교,2020,"['Gradient Descent Method', 'Deep Learning', 'Neural Networks', 'MNIST', 'Softmax', 'Cross-Entropy']","본 논문에서는 신경망을 학습하는 데 가장 많이 사용되고 있는 경사하강법에 대해 분석하였다. 학습이란 손실함수가 최소값이 되도록 매개변수를 갱신하는 것이다. 손실함수는 실제값과 예측값의 차이를 수치화 해주는 함수이다. 경사하강법은 오차가 최소화되도록 매개변수를 갱신하는데 손실함수의 기울기를 사용하는 것으로 현재 최고의 딥러닝 학습알고리즘을 제공하는 라이브러리에서 사용되고 있다. 그러나 이 알고리즘들은 블랙박스형태로 제공되고 있어서 다양한 경사하강법들의 장단점을 파악하는 것이 쉽지 않다. 경사하강법에서 현재 대표적으로 사용되고 있는 확률적 경사하강법(Stochastic Gradient Descent method), 모멘텀법(Momentum method), AdaGrad법 그리고 Adadelta법의 특성에 대하여 분석하였다. 실험 데이터는 신경망을 검증하는 데 널리 사용되는 MNIST 데이터 셋을 사용하였다. 은닉층은 2개의 층으로 첫 번째 층은 500개 그리고 두 번째 층은 300개의 뉴런으로 구성하였다. 출력 층의 활성화함수는 소프트맥스함수이고 나머지 입력 층과 은닉 층의 활성화함수는 ReLu함수를 사용하였다. 그리고 손실함수는 교차 엔트로피 오차를 사용하였다.","This paper analyzes the gradient descent method, which is the one most used for learning neural networks. Learning means updating a parameter so the loss function is at its minimum. The loss function quantifies the difference between actual and predicted values. The gradient descent method uses the slope of the loss function to update the parameter to minimize error, and is currently used in libraries that provide the best deep learning algorithms. However, these algorithms are provided in the form of a black box, making it difficult to identify the advantages and disadvantages of various gradient descent methods. This paper analyzes the characteristics of the stochastic gradient descent method, the momentum method, the AdaGrad method, and the Adadelta method, which are currently used gradient descent methods. The experimental data used a modified National Institute of Standards and Technology (MNIST) data set that is widely used to verify neural networks. The hidden layer consists of two layers: the first with 500 neurons, and the second with 300. The activation function of the output layer is the softmax function, and the rectified linear unit function is used for the remaining input and hidden layers. The loss function uses cross-entropy error."
딥러닝 방식의 웨어러블 센서를 사용한 미국식 수화 인식 시스템,2020,"['미국식 수화', '딥러닝', '인간-컴퓨터 상호 작용', '수화', '웨어러블 센서', 'American Sign Language', 'Deep Learning', 'Human-Computer Interaction', 'Sign Language', 'Wearable Sensors']",수화는 청각 장애인이 다른 사람들과 의사소통할 수 있도록 설계된 것이다. 그러나 수화는 충분히 대중화되어 있지 않기 때문에 청각 장애인이 수화를 통해서 일반 사람들과 원활하게 의사소통하는 것은 쉽지 않은 문제이다. 이러한 문제점에 착안하여 본 논문에서는 웨어러블 컴퓨팅 및 딥러닝 기반 미국식 수화인식 시스템을 설계하고 구현하였다. 이를 위해서 본 연구에서는 손등과 손가락에 장착되는 총 6개의 IMUs(Inertial Measurement Unit) 센서로 구성된 시스템을 구현하고 이를 이용한 실험을 수행하여 156개 특징이 수집된 데이터 추출을 통해서 총 28개 단어에 대한 미국식 수화 인식 방법을 제안하였다. 특히 LSTM (Long Short-Term Memory) 알고리즘을 사용하여 최대 99.89%의 정확도를 달성할 수 있었고 향후 청각 장애인들의 의사소통에 큰 도움이 될 것으로 예상된다.,"Sign language was designed for the deaf and dumb people to allow them to communicate with others and connect to the society. However, sign language is uncommon to the rest of the society. The unresolved communication barrier had eventually isolated deaf and dumb people from the society. Hence, this study focused on design and implementation of a wearable sign language interpreter. 6 inertial measurement unit (IMU) were placed on back of hand palm and each fingertips to capture hand and finger movements and orientations. Total of 28 proposed word-based American Sign Language were collected during the experiment, while 156 features were extracted from the collected data for classification. With the used of the long short-term memory (LSTM) algorithm, this system achieved up to 99.89% of accuracy. The high accuracy system performance indicated that this proposed system has a great potential to serve the deaf and dumb communities and resolve the communication gap."
딥러닝 기반의 합성곱 신경망을 이용한 화염 및 연기 감지 알고리즘에 관한 연구,2020,"['딥러닝', '기계학습', '영상전처리', '합성곱신경망', '감지기', '객체검출', 'Deeplearning', 'Machinelearning', 'Image Pre-processing', 'Convolutional Neural Network', 'Fire Detector', 'Object Detection']","2017년 제천 스포츠센터 화재와 2018년 밀양 세종병원 화재 등 최근 들어 대형화재의 발생이 증가하고 있는 추세이다. 따라서기존의 화재감지 기법보다 진보된 새로운 화재감지 기법의 필요성이 절실하다. 이에 본 연구에서는 영상전처리를 통해 영상내에서 관심영역을 검출하고 해당 관심영역에 대해 화재 여부를 딥러닝 기반의 합성곱 신경망을 통해 추론하게 된다. 이때데이터셋은 화염, 연기 뿐만 아니라 기존방법으로는 영상 내에서 객체검출의 어려움이 있는 연무형태의 실내 연기 형성여부 또한 검출할 수 있도록 연무데이터셋을 추가하여 학습을 진행하였고, 평가결과 평균 92.3%의 정확도와 93.5%의 정밀도로화재를 검출할 수 있었다.","Recently, cases of large-scale fires, such as those at Jecheon Sports Center in 2017 and Miryang Sejong Hospital in 2018, have been increasing. We require more advanced techniques than the existing approaches to better detect fires and avoid these situations. In this study, a procedure for the detection of fire in a region of interest in an image is presented using image pre-processing and the application of a convolutional neural network based on deep-learning. Data training based on the haze dataset is included in the process so that the generation of indoor haze smoke, which is difficult to recognize using conventional methods, is also detected along with flames and smoke. The results indicated that fires in images can be identified with an accuracy of 92.3% and a precision of 93.5%."
딥러닝 객체 탐지 기술을 사용한 스마트 쇼핑카트의 구현,2020,"['Deep Learning', 'Real-time Object Detection', 'YOLO', 'Internet of Things', 'Smart Shopping Cart']","최근 다양한 쇼핑 환경에서 결제에 소요되는 시간을 줄이기 위한 많은 시도들이 이루어지고 있다. 또한 4차 산업혁명시대에 들어서면서 인공지능 기술이 고도화되고 있으며, IoT 장비들은 더욱 소형화되고 저렴해져서 이 두 가지 기술을 융합시킴으로써 사용자의 시간을 절약할, 인간을 대신하는 무인 환경을 구축하는 것에 대한 접근이 용이해졌다. 본 논문에서는 저가 IoT 장비들과 딥러닝 객체 탐지 기술을 기반으로 하는 스마트 쇼핑카트 시스템을 제안한다. 제안된 스마트 카트 시스템은 실시간 상품 인식을 위한 카메라와 라즈베리파이, 트리거 역할을 하는 초음파 센서, 상품이 쇼핑카트에 들어온 것인지 나간 것인지를 판단하기 위한 무게 센서, 가상의 장바구니에 대한 UI를 제공하는 스마트폰 어플리케이션, 학습된 데이터가 저장되는 딥러닝 서버로 구성된다. 각 모듈 간의 통신은 TCP/IP 네트워크 및 HTTP 네트워크로 이루어지며, 서버의 상품 인식을 위해서는 객체탐지 기술이 구현된 YOLO darknet 라이브러리를 사용한다. 사용자는 스마트폰의 앱을 통하여 스마트 카트에 넣은 물건들의 목록을 점검하고 자동으로 결제할 수 있다. 본 논문에서 제안된 스마트 카트 시스템은 가성비가 높은 무인 상점을 구현하는데 응용될 수 있다.","Recently, many attempts have been made to reduce the time required for payment in various shopping environments. In addition, for the Fourth Industrial Revolution era, artificial intelligence is advancing, and Internet of Things (IoT) devices are becoming more compact and cheaper. So, by integrating these two technologies, access to building an unmanned environment to save people time has become easier. In this paper, we propose a smart shopping cart system based on low-cost IoT equipment and deep-learning object-detection technology. The proposed smart cart system consists of a camera for real-time product detection, an ultrasonic sensor that acts as a trigger, a weight sensor to determine whether a product is put into or taken out of the shopping cart, an application for smartphones that provides a user interface for a virtual shopping cart, and a deep learning server where learned product data are stored. Communication between each module is through Transmission Control Protocol/Internet Protocol, a Hypertext Transmission Protocol network, a You Only Look Once darknet library, and an object detection system used by the server to recognize products. The user can check a list of items put into the smart cart via the smartphone app, and can automatically pay for them. The smart cart system proposed in this paper can be applied to unmanned stores with high cost-effectiveness."
딥러닝을 이용한 노동신문의 이념적 어휘 연구,2020,"['노동신문', '딥러닝', '단어임베딩', '워드투벡', '정치적 핵심어', '이념적 어휘', 'Rodong Sinmun', 'deep learning', 'word embedding', 'Word2Vec', 'political keywords', 'ideological words']",본 논문은 북한의 주요 언론 매체인 노동신문의 언어 자료를 정제하여 이념적 어휘를 추출하고 이념적 어휘의 사회문화적 양상을 살피고자 하였다. 대규모 언어 자료를 처리하기 위해 딥러닝 중에서 단어임베딩의 방법론으로 사용하여 워드투벡 모형으로 이념적 어휘의 빈도와 유사어를 추출하였다. 2012-2013년도와 2016-2017년으로 구분하여 김정은 정권의 북한 사회의 변화 양상을 고찰하였다. 김정은 정권은 북한식 사회주의 강성대국을 위해 대외적 인식을 담론화하고 대내적 체제 유지 전략을 꾀하는 것으로 파악되었다. 이념적 어휘를 통한 북한 사회문화의 변화 양상을 연구자 주관을 배제하여 객관적인 자료를 분석함으로써 살폈다는 데에 의의가 있다. 대규모 북한 언어 자료의 계량적 연구 방법론을 제시하였다는 점에서도 앞으로 북한 관련 연구에 여러 측면에서 기여하리라고 기대한다.,"This article addresses the ideological expressions manifested in Rodong Sinmun (i.e., the representative literature of North Korea). For this purpose, the current work makes use of the state-of-the-art skills in natural language processing, viz. word embedding under the umbrella of deep learning techniques. We chose the five-year data from the papers and created a language model of the texts by means of Word2Vec. Further, we divided them into two sections in order to look at how the politics and society in the era of Kim Jong-un had changed over the years. The methodological pipeline allows us to figure out what North Korea has tried to do outwardly as well as inwardly using the ideological words. The present quantitative study is an endeavor to analyze the texts of North Korea in a fully data-oriented method and on a comprehensive scale. We believe this is where the contribution of this study lies"
딥러닝 기반 이미지 특징 추출 모델을 이용한 유사 디자인 검출에 대한 연구,2020,"['디자인 유사성', '이미지 특징', '스피어만 상관계수', 'Design similarity', 'VGG-16', 'Feature of image', 'Spearman correlation coefficient']","디자인은 섬유패션 산업에서 제품의 경쟁력을 결정짓는 핵심요인이다. 무단복제를 방지하고 독창성을 확인하기 위하여 제시된 디자인의 유사도를 측정하는 것은 매우 중요하다. 본 연구에서는 딥러닝 기법을 이용하여 섬유 디자인의 이미지로 부터 특징(feature)을 수치화하고, 스피어만 상관계수를 이용하여 유사도를 측정하였다. 유사한 샘플이 실제로 검출되는지 검증하기 위하여 300장의 이미지를 임의로 회전 및 색상을 변경하였다. 유사도 수치가 높은 순으로 Top-3와 Top-5의 결과에 회전을 하거나 색상을 변경한 샘플이 존재하는지 측정하였다. 그 결과, AlexNet 보다 VGG-16 모델이 월등히 높은 성능을 기록하였다. VGG-16 모델의 성능은 회전 이미지의 경우에 유사도 결과값이 높은 Top-3와 Top-5에서 64%, 73.67%로 가장 높게 나타났다. 색상변경의 경우에는 Top-3와 Top-5에서 각각 86.33%, 90%로 가장 높게 나타났다.","Design is a key factor that determines the competitiveness of products in the textile and fashion industry. It is very important to measure the similarity of the proposed design in order to prevent unauthorized copying and to confirm the originality. In this study, a deep learning technique was used to quantify features from images of textile designs, and similarity was measured using Spearman correlation coefficients. To verify that similar samples were actually detected, 300 images were randomly rotated and color changed. The results of Top-3 and Top-5 in the order of similarity value were measured to see if samples that rotated or changed color were detected. As a result, the VGG-16 model recorded significantly higher performance than did AlexNet. The performance of the VGG-16 model was the highest at 64% and 73.67% in the Top-3 and Top-5, where similarity results were high in the case of the rotated image. appear. In the case of color change, the highest in Top-3 and Top-5 at 86.33% and 90%, respectively."
딥러닝의 이미지 인식에 근거한  베이지안 이미지 교수 모델,2020,"['Bayesian probabilistic model', 'Piaget', 'Theory of learning', 'Causality', 'Cognitive science', '베이즈주의', '베이지안 인지이론', '피아제 학습이론', '발생학적 인식론', '인과성', '확률 추론']","본고는 딥러닝의 이미지 인식 원리와 유아의 이미지 인식 원리를 종합하면서, 이미지-개념 학습을 위한 새로운 교수학습모델, 즉 “베이지안 구조구성주의 교수학습모델”(Bayesian Structure-constructivist Teaching-learning Model: BSTM)을 제안한다. 달리 말하면, 기계학습 원리와 인간학습 원리를 비교함으로써 얻게 되는 시너지 효과를 바탕으로, 유아들의 이미지-개념 학습을 위한 새로운 교수 모델을 구성하는 것을 목표로 한다. 이런 맥락에서 본고는 전체적으로 3가지 차원에서 논의된다. 첫째, 아동의 이미지 학습에 대한 역사적 중요 이론인 “대상 전체론적 가설”, “분류학적 가설”, “배타적 가설”, “기본 수준 범주 가설” 등을 역사 비판적 관점에서 검토한다. 둘째, 컴퓨터 공학에서 전개된 머신러닝의 이미지 학습 원리 및 그 구조의 역사적 변형들에 대해서 비판적으로 분석하면서, 특히 딥러닝의 교육 인식론적 의미를 도출한다. 셋째, 선행하는 논의들을 토대로 이미지와 개념을 연결시키는 학습, 즉 단어학습을 위한 필자의 고유한 이론인 구조구성주의 개념교수모델을 제안한다. 이때 필자는 피아제의 명제논리학적 학습 가설, 즉 논리-수학적 구조를 중시하는 기존의 피아제 학파의 학습 가설과 최근의 베이지안 학습 이론에서 강조된 확률론적 추론 가설, 특히 “교육학적 추론 가설”을 동시에 포함할 수 있는 교수학습모델의 구조 및 주요 지향점들을 제안한다.","This article tries to introduce a new teaching-learning model for image-conception, synthesizing a Bayesian framework for parsing images in machine learning and the important theories of children's word learning. In this context, this article consists of three parts. First, I try to analyze from the history-critical view point the important theories such as ""the whole object assumption"", ""taxonomic assumption"", ""mutual exclusivity assumption"", ""the basic level category assumption"" and ""associationist model"". Second, I try to analyze the structure and principle of parsing images in deep learning, elucidating the pedagogical-epistemological meaning of the Bayesian framework which works as a core algorithm. In conclusion, I try to describe the Bayesian teaching-learning model which is constructed on the one hand by linking the traditional theories of children's word learning and the machine learning, and on the other by synthesizing the various deductive assumption and the empirical assumption such as the associationist model about word learning."
딥러닝을 활용한 개인정보 처리방침 분석 기법 연구,2020,"['Privacy Policy', 'Text Mining', 'Decision Tree Model', 'Privacy Protect', 'Subject Right']","개인정보보호법에서는 정보 주체의 권리보장을 위해 개인정보보호 정책문서인 개인정보 처리방침을 공개하도록 규정하고 있고 공정거래위원회에서는 개인정보 처리방침을 약관으로 보고 약관규제법에 따라 불공정약관심사를 하고 있다. 그러나, 정보 주체는 개인정보 처리방침이 복잡하고 이해하기 어려워 읽지 않는 경향이 있다. 개인정보 처리방침의 내용을 간단하고 읽기 쉽게 한다면 온라인 거래에 참여할 확률이 증가하여 기업의 매출 증가에 기여하고, 사업자와 정보주체간의 정보 비대칭성 문제 해결에 기여할 것이다. 본 연구에서는 복잡한 개인정보 처리방침을 딥러닝을 이용하여 분석하여 정보주체로 하여금 가독성 높은 단순화된 개인정보처리 방침을 구현하기 위한 모델을 제시한다. 모델을 제시하기 위해 국내 258개 기업의 개인정보 처리방침을 데이터셋으로 구축하고 딥러닝 기술을 활용하여 분석하는 방안을 제안하였다.","The Privacy Act stipulates that the privacy policy document, which is a privacy statement, should be disclosed in order to guarantee the rights of the information subjects, and the Fair Trade Commission considers the privacy policy as a condition and conducts an unfair review of the terms and conditions under the Terms and Conditions Control Act. However, the information subjects tend not to read personal information because it is complicated and difficult to understand. Simple and legible information processing policies will increase the probability of participating in online transactions, contributing to the increase in corporate sales and resolving the problem of information asymmetry between operators and information entities. In this study, complex personal information processing policies are analyzed using deep learning, and models are presented for acquiring simplified personal information processing policies that are highly readable by the information subjects. To present the model, the personal information processing policies of 258 domestic companies were established as data sets and analyzed using deep learning technology."
딥러닝 기반의 의미론적 영상 분할을 이용한 주행 보조 시스템,2020,"['Lane Detection', 'Deep Learning', 'Semantic segmentation', 'Hough Transformation', 'Sliding Window']","기존의 차선 검출 방법들은 곡률과 날씨 변화가 큰 도로 환경에서 검출률이 낮다. 확률적 허프 변환을 이용한 방법은 에지와 직선의 각도를 이용해서 차선을 검출함으로 곡선과 악천후일 때 검출률이 낮다. 슬라이딩 윈도우 방법은 윈도우로 이미지를 분할해서 검출하기 때문에 곡선 형태의 차선도 검출하지만 어파인 변환을 사용하기 때문에 도로의 경사율에 영향을 받는다. 본 논문에서는 다양한 외부 환경에서도 차선을 강인하게 검출하고 장애물을 회피하기 위한 딥러닝 기반의 주행 보조 시스템을 제안한다. VGG-16기반의 SegNet으로 입력 영상을 의미론적으로 분할해서 차선을 검출한다. 검출한 차선과의 이격거리를 계산하고 안전범위를 산출해서 차량이 차선의 중앙을 주행하도록 제어한다. 또한, 전방의 미확인 물체와 충돌이 예상되면 운전자에게 경보를 주고 Adaptive-MPC로 차량을 제어해서 충돌을 회피하는 알고리즘도 제안한다. CARLA로 시뮬레이션한 결과 제안한 알고리즘은 곡률이 큰 차선과 다양한 환경에서도 강인하게 차선을 검출하고 전방의 안전범위를 계산하여 충돌을 회피하는 것을 볼 수 있다.","Conventional lane detection algorithms have problems in that the detection rate is lowered in road environments having a large change in curvature and illumination. The probabilistic Hough transform method has low lane detection rate since it exploits edges and restrictive angles. On the other hand, the method using a sliding window can detect a curved lane as the lane is detected by dividing the image into windows. However, the detection rate of this method is affected by road slopes because it uses affine transformation. In order to detect lanes robustly and avoid obstacles, we propose driving assist system using semantic segmentation based on deep learning. The architecture for segmentation is SegNet based on VGG-16. The semantic image segmentation feature can be used to calculate safety space and predict collisions so that we control a vehicle using adaptive-MPC to avoid objects and keep lanes. Simulation results with CARLA show that the proposed algorithm detects lanes robustly and avoids unknown obstacles in front of vehicle."
딥러닝을 이용한 3차원 사람모델형상 변형,2020,"['딥러닝', '온-사이트 학습', '형상 변형', '3차원 사람 모델', 'Deep learning', 'On-site learning', 'Shape deformation', '3D human model']","최근 가상현실 및 증강 현실 기술을 이용한 다양한 응용분야가 각광받으면서 빠르고 정확한 3차원 모델 생성이 요구되고 있다. 본 논문에서는 옷을 입은 3차원 사람 모델을 포인트 클라우드의 형상으로 변형하는 온-사이트 학습 (On-site learning) 기반 형상 변형 방법을 제안한다. 제안하는 알고리즘은 사전 학습과 온-사이트 학습 두 개의 파트로 구성되어 있으며, 각각의 학습은 인코더 네트워크, 템플릿 변형 네트워크, 디코더 네트워크로 구성된다. 딥러닝 네트워크 학습은 3차원 포인트 클라우드와 템플릿 정점 사이의 챔퍼 거리 (Chamfer distance)를 주요 손실 함수로 사용하는 비지도 학습을 적용한다. 입력된 포인트 클라우드 형태의 데이터에 대해 온-사이트 학습을 진행함으로써 추론의 결과물에 대한 높은 정확도를 얻을 수 있으며 이를 실험을 통해 제시한다.","Recently, rapid and accurate 3D models creation is required in various applications using virtual reality and augmented reality technology. In this paper, we propose an on-site learning based shape deformation method which transforms the clothed 3D human model into the shape of an input point cloud. The proposed algorithm consists of two main parts: one is pre-learning and the other is on-site learning. Each learning consists of encoder, template transformation and decoder network. The proposed network is learned by unsupervised method, which uses the Chamfer distance between the input point cloud form and the template vertices as the loss function. By performing on-site learning on the input point clouds during the inference process, the high accuracy of the inference results can be obtained and presented through experiments."
딥러닝 모델을 이용한 교육사회통념 가설검증 예측 시스템의 제안,2020,"['AI', 'Big data Analysis', 'Deep Learning', 'Python', 'Programming', 'RNN', '인공지능', '빅 데이터 분석', '딥 러닝', '파이썬', '프로그래밍', '순환신경망']","AI 기술은 법률, 특허, 금융, 국방의 의사결정지원 기술 형태로 발전하여 질병 진단과 법률 판정 등에 적용되고 있다. Deep Learning으로 실시간 정보를 검색하려면, Big data Analysis과 Deep Learning Algorithm이 필요하다. 본 논문에서는 Deep Learning 모델인 RNN(Recurrent Neural Network)을 이용하여 상위권 대학 진학률을 예측하고자 한다. 우선, 행정구역 사설학원 현황과 행정구역 연령별 학생 수를 분석하고 교육열이 높은 지역에 거주하는 학생이 상위권 대학 진학률이 높다는 사회 통념의 가설을 설정했다. 예측된 가설과 정부의 공공데이터를 활용하여 분석된 자료를 토대로 검증하고자 한다. 예측 모델은 2015년부터 2017년까지의 데이터를 활용하여 상위권 진학률을 예상하도록 학습하고, 학습된 모델은 2018년 상위권 진학률을 예측한다. 교육특구지역의 상위권 진학률을 Deep Learning 모델인 RNN을 이용하여 예측 실험을 수행했다. 본 논문은 교육열이 높은 지역의 사설학원 현황, 연령별 학생 수에 미치는 영향에 대해서 가구소득, 사교육의 참여 비율을 분석하여 상위권 진학률의 상관관계를 정의한다.","AI technology has developed in the form of decision support technology in law, patent, finance and national defense and is applied to disease diagnosis and legal judgment. To search real-time information with Deep Learning, Big data Analysis and Deep Learning Algorithm are required. In this paper, we try to predict the entrance rate to high-ranking universities using a Deep Learning model, RNN(Recurrent Neural Network). First, we analyzed the current status of private academies in administrative districts and the number of students by age in administrative districts, and established a socially accepted hypothesis that students residing in areas with a high educational fever have a high rate of enrollment in high-ranking universities. This is to verify based on the data analyzed using the predicted hypothesis and the government""s public data. The predictive model uses data from 2015 to 2017 to learn to predict the top enrollment rate, and the trained model predicts the top enrollment rate in 2018. A prediction experiment was performed using RNN, a Deep Learning model, for the high-ranking enrollment rate in the special education zone. In this paper, we define the correlation between the high-ranking enrollment rate by analyzing the household income and the participation rate of private education about the current status of private institutes in regions with high education fever and the effect on the number of students by age."
딥러닝 기반의 수중 IoT 네트워크 BER 예측 모델,2020,"['딥러닝', '링크 적응', 'AMC', 'MLP 분류 모델', '기계 학습', '수중 IoT 네트워크', 'Deep learning', 'Link adaptation', 'Adaptive Modulation and Coding', 'MLP Classification model', 'Machine learning', 'Underwater IoT network']","수중 IoT 네트워크에서 센서 노드는 지속적인 전력 공급이 어렵기 때문에 제한된 상황에서 소비 전력과 네트워크 처리량의 효율성이 매우 중요하다. 이를 위해 기존의 무선 네트워크에서는 SNR(Signal Noise Rate)과 BER(Bit Error Rate)의 높은 연관성을 기반으로 적응적으로 통신 파라미터를 선택하는 AMC(Adaptive Modulation and Coding) 기술을 적용한다. 하지만 본 논문의 실험 결과, 수중에서 SNR과 BER 사이의 상관 관계가 상대적으로 감소함을 확인하였다. 따라서 본 논문에서는 SNR과 함께 다중 파라미터를 동시에 사용하는 딥러닝 기반 BER 예측 모델(MLP, Multi-Layer Perceptron)을 적용한다. 제안하는 BER 예측 모델은 처리량이 가장 높은 통신 방법을 찾아낼 수 있고, 시뮬레이션 결과 85.2%의 높은 정확도와 네트워크 처리량은 기존 처리량보다 4.4배 높은 성능을 보여주는 우수한 성능을 확인하였다.","The sensor nodes in underwater IoT networks have practical limitations in power supply. Thus, the reduction of power consumption is one of the most important issues in underwater environments. In this regard, AMC(Adaptive Modulation and Coding) techniques are used by using the relation between SNR and BER. However, according to our hands-on experience, we observed that the relation between SNR and BER is not that tight in underwater environments. Therefore, we propose a deep learning based MLP classification model to reflect multiple underwater channel parameters at the same time. It correctly predicts BER with a high accuracy of 85.2%. The proposed model can choose the best parameters to have the highest throughput. Simulation results show that the throughput can be enhanced by 4.4 times higher than the conventionally measured results."
무인항공기와 딥러닝(UNet)을 이용한 소규모 농지의 밭작물 분류,2020,"['Unmanned Aerial Vehicle', 'Vegetation Index', 'Deep Learning', 'Upland Crops', 'Classification', '무인항공기', '식생지수', '딥러닝', '밭작물', '분류']",,
인공지능 기반 구글넷 딥러닝과 IoT를 이용한 의류 분류,2020,"['인공지능', '딥러닝', '구글넷', '사물인터넷', '라즈베리파이', 'Artificial Intelligent', 'Deep Learning', 'GoogLeNet', 'IoT', 'Raspberry Pi']","최근 4차 산업혁명 관련 IT기술 중에서 머신러닝과 딥러닝으로 대표되는 인공지능과 사물인터넷은 다양한 연구를 통해 여러 분야에서 우리 실생활에 적용되고 있다. 본 논문에서는 사물인터넷과 객체인식 기술을 활용한 인공지능을 적용하여 의류를 분류하고자 한다. 이를 위해 이미지 데이터셋은 웹캠과 라즈베리파이를 이용하여 의류를 촬영하고, 촬영된 이미지 데이터를 전이학습된 컨벌루션 뉴럴 네트워크 인공지능망인 구글넷에 적용하였다. 의류 이미지 데이터셋은 온전한 이미지 900개와 손상이 있는 이미지 900 그리고 총 1800개를 가지고 상하의 2개의 카테고리로 분류하였다. 분류 측정 결과는 온전한 의류 이미지에서는 약 97.78%의 정확도를 보였다. 결론적으로 이러한 측정결과와 향후 더 많은 이미지 데이터의 보완을 통해 사물인터넷 기반 플랫폼상에서 인공지능망을 활용한 여타 사물들의 객체 인식에 대한 적용 가능성을 확인하였다.","Recently, artificial intelligence (AI) and the Internet of things (IoT), which are represented by machine learning and deep learning among IT technologies related to the Fourth Industrial Revolution, are applied to our real life in various fields through various researches. In this paper, IoT and AI using object recognition technology are applied to classify clothing. For this purpose, the image dataset was taken using webcam and raspberry pi, and GoogLeNet, a convolutional neural network artificial intelligence network, was applied to transfer the photographed image data. The clothing image dataset was classified into two categories (shirtwaist, trousers): 900 clean images, 900 loss images, and total 1800 images. The classification measurement results showed that the accuracy of the clean clothing image was about 97.78%. In conclusion, the study confirmed the applicability of other objects using artificial intelligence networks on the Internet of Things based platform through the measurement results and the supplementation of more image data in the future."
시각 정보를 활용한 딥러닝 기반 추천 시스템,2020,"['추천시스템', '딥러닝', '협업필터링', '시각정보', '합성곱신경망', 'Recommender Systems', 'Deep learning', 'Collaborative Filtering', 'Visual Information', 'Convolutional Neural Networks']","사용자의 정보 과부하 문제의 해결을 목표로 하는 추천 시스템은 개인의 선호를 추론하여 이에 부합하는 아이템을 필터링하여 제공한다. 추천 시스템 관련 기법 중 가장 성공적으로 알려져 있는 협업 필터링은 최근까지 다양한 성능 개선 시도가 이루어지고 있으며 여러 분야에 적용되고 있다. 본 연구에서는 이와 같은 협업 필터링의 성공에 기반하여 소비자의 구매 의사결정에 영향을 미칠 수 있는 시각 정보를 추천 시스템에 반영할 수 있는 VizNCS를 제안한다. 이를 위하여 먼저, 비정형 데이터인 시각 정보에서 특징을 추출하기 위해 합성곱 신경망을 사용하였다. 다음으로, 합성곱 신경망으로부터 도출된 이미지 특성 정보를 추천 시스템에 반영하기 위하여 기존의 딥러닝 기반의 추천 시스템 중 다른 정보로 확장이 용이한 NCF 기법을 응용하였다. 본 연구에서 제안한 VizNCS의 성능 비교 실험 결과 기본 NCF보다 더 높은 성능을 보였으며 카테고리별 성능 비교 실험을 통해 시각 정보에 영향을 받는 카테고리와 그렇지 않은 카테고리를 발견하였다. 결론적으로 본 연구에서 제안한 VizNCS는 시각정보를 개인화된 추천에 직접 활용함에 따라 시각 정보에 영향을 받는 소비자들의 구매의사결정 행태를 반영할 수 있어 추천 시스템 성능 향상에 기여하였다. 또한, 지금까지 활용이 미미했던 이미지 데이터로 추천 시스템의 원천 데이터 영역을 확장함에 따라 다양한 원천 데이터의 활용 방안을 제시하였다.",
개인 성향 추출을 위한 딥러닝 기반 SNS 리뷰 분석 방법에 관한 연구,2020,"['SNS', '딥러닝', '감성분석', '객체 인식', 'YOLOv3', 'BiLSTM', 'SNS', 'Deep Learning', 'Opiniom Mining', 'Object Detection', 'YOLOv3', 'BiLSTM']",,"In this paper, we proposed an SNS review analysis method based on deep learning for user tendency. The existing SNS review analysis method has a problem that does not reflect a variety of opinions on various interests because most are processed based on the highest weight. To solve this problem, the proposed method is to extract the user’s personal tendency from the SNS review for food. It performs classification using the YOLOv3 model, and after performing a sentiment analysis through the BiLSTM model, it extracts various personal tendencies through a set algorithm. Experiments showed that the performance of Top-1 accuracy 88.61% and Top-5 90.13% for the YOLOv3 model, and 90.99% accuracy for the BiLSTM model. Also, it was shown that diversity of the individual tendencies in the SNS review classification through the heat map. In the future, it is expected to extract personal tendencies from various fields and be used for customized service or marketing."
컴퓨터 프로그래밍 교육을 위한 딥러닝 수업 설계,2020,"['인공지능', '딥러닝 교육', '파이썬', '텐서플로', '인공신경망', 'Artificial Intelligence', 'Deep Learning Education', 'Python', 'Tensorflow', 'Artificial Neural Network']",,"Artificial intelligence, a core technology in the era of the fourth industrial revolution, has recently become a basic learning competency for students to learn. Various educational studies for artificial intelligence are underway in the United States and the United Kingdom, and cases of artificial intelligence education research for elementary and secondary students are also beginning in Korea. In this study, a deep learning lecture was designed by deriving the learning competencies of computer programming education-centered classes for artificial intelligence education required for the 4th industrial revolution for computer major students. The deep learning lecture consisting of coding on Python, numpy, matplotlib and tensorflow, understanding artificial intelligence and deep learning, and implementing artificial and convolutional neural networks with tensorflow is applied to the actual class of D-university. In order to verify the effectiveness of learning competency of the class, a paired samples t-test was used. As a result of the analysis, there was significant differences in the pre- and post-test results of the learning competencies of deep learning proposed in this study."
효과적인 딥러닝 기반 비프로파일링 부채널 분석 모델 설계방안,2020,"['Side-Channel Analysis', 'Deep Learning', 'Multi Layer Perceptron', 'AES']","최근 딥러닝 기반 비프로파일링 부채널 분석이 제안됐다. 딥러닝 기반 비프로파일링 분석은 신경망 모델을 모든 추측키에 대해 학습시킨 뒤, 학습된 정도의 차이를 통해 올바른 비밀키를 찾아내는 기법이다. 이때, 신경망 학습모델 설계에 따라 비프로파일링 분석성능이 크게 달라지기 때문에 올바른 모델 설계의 기준이 필요하다. 본 논문은 학습모델 설계에 사용 가능한 2가지 loss 함수와 8가지 label 기법을 설명하고, 비프로파일링 분석과 소비전력모델 관점에서 각 label 기법의 분석성능을 예측했다. 해밍웨이트 소비전력모델을 가정했을 때의 비프로파일링 분석 특징을 고려해서 One-hot인코딩을 적용하지 않은 HW(Hamming Weight) label과 CO(Correlation Optimization) loss를 적용한 학습모델이 가장 좋은 분석성능을 가질 것으로 예측했다. 그리고 AES-128 1라운드 Subbytes 연산 부분 데이터 집합 3가지에 대해 실제 분석을 수행했다. 제시한 각 label 기법과 loss 함수를 적용한 총 16가지 MLP(Multi-Layer Perceptron)기반 학습모델로 두 데이터 집합을 비프로파일링 분석하여 예측에 대해 검증했다.","Recently, a deep learning-based non-profiling side-channel analysis was proposed. The deep learning-based non-profiling analysis is a technique that trains a neural network model for all guessed keys and then finds the correct secret key through the difference in the training metrics. As the performance of non-profiling analysis varies greatly depending on the neural network training model design, a correct model design criterion is required. This paper describes the two types of loss functions and eight labeling methods used in the training model design. It predicts the analysis performance of each labeling method in terms of non-profiling analysis and power consumption model. Considering the characteristics of non-profiling analysis and the HW (Hamming Weight) power consumption model is assumed, we predict that the learning model applying the HW label without One-hot encoding and the Correlation Optimization (CO) loss will have the best analysis performance. And we performed actual analysis on three data sets that are Subbytes operation part of AES-128 1 round. We verified our prediction by non-profiling analyzing two data sets with a total 16 of MLP-based model, which we describe."
전자입찰에서 딥러닝을 이용한 입찰 가격예측,2020,"['전자 입찰', '딥러닝', '머신 러닝', 'Deep learning', 'Electronic bidding', 'Machine Learning', 'MLP', 'RNN']","입찰프로그램은 민/관으로부터 고지되는 입찰 정보의 수집과 누적된 입찰결과의 통계적 분석방법을 사용하고 있지만 복수예가 추첨을 통한 낙찰방식으로 정확한 낙찰가를 예측하는 것은 쉽지 않다. 따라서 본 논문은 MLP, RNN 등의 방법을 이용하여 전자입찰 사이트인 전기넷에서 취득한 2015년 1월부터 2019년 8월까지 전기공사 낙찰현황 데이터의 정확도 등을 분석하고, 이를 통해 낙찰 하한가에 가장 근접하고 1순위 금액 사이의 금액을 예측하여 낙찰에 필요한 입찰금액을 예측하기 위한 기법을 제안한다.","The bidding program uses statistical analysis method of the collected bidding information and the accumulated bidding results from the public/private sector; however, it is not easy to predict the accurate bidding price by winning the bid method through multiple lottery. Therefore, this paper analyzes the accuracy of the current state data of the electric construction bid from January 2015 to August 2019 acquired from the electric net, which is an electronic bidding site, We use MLP and RNN method, and proposes a technique to predict the bidding amount necessary for the winning bid by predicting the amount between the first and the lowest bidder."
거시지표와 딥러닝 알고리즘을 이용한 자동화된 주식 매매 연구,2020,"['Stock analysis', 'Big data', 'Text mining', 'AI', 'Prediction', '주가분석', '빅데이터', '텍스트마이닝', '인공지능', '예측 시스템']","거시경제는 한 나라 경제 전체의 움직임을 보여주기 때문에 주식을 분석할 때 선행되어 분석되는 지표 중 하나이다. 실업률, 이자율, 물가, 국민소득, 환율, 통화량, 국제수지 등 국가차원의 경제 상황 전반은 주식시장에 직접적인 영향을 미치고, 경제 지표는 개별 주가와의 상관관계가 있기 때문에 주식을 예측하기 위해 많은 증권사 애널리스트들이 관심 있게 지켜보고, 개별 주가에 영향을 고려하여 매수와 매도를 판단하는 주요한 근거자료가 되고 있다. 주가에 영향을 미치는 경제 지표를 선행지표로 분석하고, 주가예측을 딥러닝 기반의 예측을 통하여 예측 후 실제 주가를 비교하여 차이가 발생하면 거시지표에 대한 가중치를 조절하여 지속적인 반복학습을 통하여 주식의 매수와 매도를 판단한다면, 주식은 더 이상 도박과 같은 투기가 아닌 건전한 투자가 될 수 있다. 따라서 본 연구는 거시지표와 인공지능의 딥러닝 알고리즘방식을 이용하여 자동화된 주식매매가 가능하도록 연구를 수행하였다.","Macroeconomics are one of the indicators that are preceded and analyzed when analyzing stocks because it shows the movement of a country's economy as a whole. The overall economic situation at the national level, such as national income, inflation, unemployment, exchange rates, currency, interest rates, and balance of payments, has a great affect on the stock market, and economic indicators are actually correlated with stock prices. It is the main source of data for analysts to watch with interest and to determine buy and sell considering the impact on individual stock prices. Therefore, economic indicators that impact on the stock price are analyzed as leading indicators, and the stock price prediction is predicted through deep learning-based prediction, after that the actual stock price is compared. If you decide to buy or sell stocks by analysis of stock prediction, then stocks can be investments, not gambling. Therefore, this research was conducted to enable automated stock trading by using macro-indicators and deep learning algorithms in artificial intelligence."
비콘과 딥러닝 기술을 활용한 전자출입명부 자동등록시스템,2020,"['COVID-19', 'infectious disease', 'electronic access system', 'beacon', 'deep-learning', '코로나19', '감염병', '전자출입명부', '비콘', '딥러닝']","전 세계적으로 감염이 확산되고 있는 코로나19 바이러스의 확산 방지 및 효과적인 추적 관리를 위해 정부에서는 공공시설에 대한 전자출입명부 시스템 도입을 의무화하고 있다. 초기에는 수기로 명부를 작성하는 불편함이 컸으나, 최근에는 QR 코드를 활용한 전자출입명부 작성 시스템이 주로 사용되고 있다. 하지만, QR 코드 생성을 위한 절차가 다소 번거로운 측면이 있다. 본 논문에서는 QR 코드 생성이 불필요한 새로운 방식의 전자출입명부 작성 시스템을 제안한다. 제안된 시스템에서는 딥러닝 기술로 구현된 마스크 착용 판별기와 비접촉 온도계를 활용하여 감염 의심방문자를 효과적으로 통제한다. 또한 근거리 무선통신 기술인 비콘과 방문자의 스마트폰 앱을 연동하여 시설 출입자의 기본 정보를 서버를 통해 질병관리청에 자동 등록되도록 한다. 한편, 개인정보 보호를 위해 서버에 등록된 방문자출입 정보는 암호화되어 보관되며, 최대 4주 후 자동 폐기된다. 제안된 시스템은 전 세계적으로 높은 확산세를 기록하고 있는 코로나 바이러스에 대한 대응은 물론 기타 신종감염병 확산 방지 및 대응에도 매우 효과적으로 활용될 수있을 것으로 기대된다.","In order to prevent the national wide spread of the COVID-19 virus, the government enforces to use an electronic access registration system for public facilities to effectively track and manage the spread. Initially, there was a lot of hassle to write a directory, but recently a system for creating an electronic access list using QR codes, what is called KI-Pass, is mainly used. However, the procedure for generating a QR code is somewhat cumbersome. In this paper, we propose a new electronic access registration system that does not require QR code. This system effectively controls the suspicious visitor by using a mask wearing discriminator which has been implemented using deep learning technology, and a non-contact thermometer package. In addition, by linking the beacon, a short-range wireless communication technology, and the visitor's smartphone application, basic information of the facility visitor is automatically registered to KDCA through the server. On the other hand, the user access information registered in the server is encrypted and stored, and is automatically destroyed after up to 4 weeks. This system is expected to be very effective in preventing the spread of other new infectious diseases as well as responding to the coronavirus which is recording a high spread worldwide."
SVM과 딥러닝에서 불완전한 데이터를 처리하기 위한 알고리즘,2020,"['SVM', '엔트로피', 'UChoo', '확장된 데이터 표현', '불완전한 데이터', '딥러닝', 'SVM', 'Entropy', 'UChoo', 'Extended data expression', 'Incomplete data', 'Deep learning']","본 논문은 불완전한 데이터를 처리하기 위해 2가지의 서로 다른 기법과 이를 학습하는 알고리즘을 소개한다. 첫째방법은 손실변수가 가질 수 있는 균등한 확률로 손실값을 할당하여 불완전한 데이터를 처리하고, SVM 알고리즘으 로 이 데이터를 학습하는 것이다. 이 기법은 임의의 변수에 손실 값의 빈도가 높을수록 엔트로피가 높도록 하여 이 변수 가 결정트리에서 선택되지 않도록 하는 것이다. 이 방법은 손실 변수에 남아있는 정보를 모두 무시하고 새로운 값을 할당한다는 특징이 있다. 이에 반해 새로운 방법은 손실 값을 제외하고 남아있는 정보로 엔트로피 확률을 구하고 이를 손실 변수의 추정 값으로 사용하는 것이다. 즉, 불완전한 학습데이터로부터 소실되지 않은 많은 정보들을 이용해 소실된 일부 정보를 복구하고 딥러닝을 이용해 학습한다. 이 2가지 방법은 학습데이터에서 차례로 변수 하나를 선택하고, 이 변수에 손실된 데이터의 비율을 달리하면서 서로 다른 측정값들의 결과들과 반복적으로 비교함으로써 성능을 측정한다.","This paper introduces two different techniques for dealing with incomplete data and algorithms for learning this data. The first method is to process the incomplete data by assigning the missing value with equal probability that the missing variable can have, and learn this data with the SVM. This technique ensures that the higher the frequency of missing for any variable, the higher the entropy so that it is not selected in the decision tree. This method is characterized by ignoring all remaining information in the missing variable and assigning a new value. On the other hand, the new method is to calculate the entropy probability from the remaining information except the missing value and use it as an estimate of the missing variable. In other words, using a lot of information that is not lost from incomplete learning data to recover some missing information and learn using deep learning. These two methods measure performance by selecting one variable in turn from the training data and iteratively comparing the results of different measurements with varying proportions of data lost in the variable."
열화상 카메라를 활용한 딥러닝 기반의 1·3종 차량 분류,2020,"['차종분류', '열화상이미지', '딥러닝', 'CNN', '도로교통량', 'Vehicle classification', 'Thermal image', 'Deep learning', 'CNN', 'Traffic monitoring']",,
RGB 영상에서 딥러닝 기반 동공 중심점을 이용한 홍채 검출,2020,"['iris localization', 'pupil detection', 'iris recognition', 'deep learning', 'hough transform', '홍채 검출', '동공 검출', '홍채인식', '딥러닝', '허프 변환']",,"In this paper, we describe the iris localization method in RGB images. Most of the iris localization methods are developed for infrared images, thus an iris localization method in RGB images is required for various applications. The proposed method consists of four stages: i) detection of the candidate irises using circular Hough transform (CHT) from an input image, ii) detection of a pupil center based on deep learning, iii) determine the iris using the pupil center, and iv) correction of the iris region. The candidate irises are detected in the order of the number of intersections of the center point candidates after generating the Hough space, and the iris in the candidates is determined based on the detected pupil center. Also, the error due to distortion of the iris shape is corrected by finding a new boundary point based on the detected iris center. In experiments, the proposed method has an improved accuracy about 27.4% compared to the CHT method."
NTIS 시스템에서 딥러닝과 형태소 분석 기반의 대화형 검색 서비스 설계 및 구현,2020,"['대화형 검색 서비스', '딥러닝', '인공지능', '지능형 서비스', '형태소 분석기', 'Comunication Search Service', 'Deep Learning', 'AI', 'Intelligence Service', 'Morpheme Analyze']",,
빅데이터를 사용한 온라인 육아 커뮤니티 영유아 부모의 자녀양육 고민 분석: 딥러닝 기법의 적용,2020,"['빅데이터', '온라인 육아 커뮤니티', '자녀양육 고민', '딥러닝', '계층적 주의 네트워크(hierarchical attention networks: HAN)', 'Big data', 'Online parenting communities', 'Child-rearing concerns', 'Deep learning', 'Hierarchical Attention Networks (HAN)']","본 연구는 딥러닝 기법인 계층적 주의 네트워크(hierarchical attention networks: HAN)를 사용하여 온라인 육아 커뮤니티에 게시된 영유아 부모의 자녀양육 고민에 대한 빅데이터 분석을 수행하였다. 빅데이터 분석을 위해 2010년부터2018년까지 9년간 온라인 육아 커뮤니티에 게시된 데이터를 수집하였다. 분석 결과, 영유아 부모의 자녀양육 고민유형 중 가장 높은 빈도를 보인 것은 놀이 및 교육 관련 고민이었고, 이 유형은 2010년부터 2018년까지 줄곧 가장높은 점유율을 유지하였다. 자녀양육 고민 게시글은 만 0세 영아의 부모가 압도적으로 많이 올리는 것으로 나타났는데, 자녀가 만 1세가 된 이후에는 부모들이 올리는 게시글의 빈도가 급격히 감소하였다. 영유아 부모의 자녀양육 고민유형은 자녀연령에 따라 달라 만 0세 때는 영양 관련 고민이 가장 많았으나 만 1세가 되면 놀이 및 교육 관련 고민이가장 높은 순위로 올라선 후 만 6세 때까지 유지되었다. 자녀연령에 따라 자녀양육 관련 고민의 유형이 어떻게 달라지는지살펴본 결과, 놀이 및 교육 관련 고민만 자녀가 성장하면서 전체 고민에서 차지하는 비율이 계속 높아지는 것으로나타났다. 다른 유형의 고민이 차지하는 비율은 자녀가 성장하면서 점차 감소하거나 큰 변화가 없이 안정적 상태를유지하였다.","We conducted big data analysis on child-rearing concerns posted by parents of infants and toddlers on online childcare communities using hierarchical attention networks (HAN), one of deep learning techniques. For big data analysis, we collected data posted on online parenting communities over a nine-year period from 2010 to 2018. Results showed that parenting concerns of the highest frequency among parents of infants and toddlers were those related to play and education, which maintained the highest share from 2010 to 2018. Parents of 0-year-old infants overwhelmingly posted postings on child-rearing concerns, and the frequency of posts posted by parents sharply decreased once their child reached the age of 1. The type of child-rearing concerns of parents of infants and toddlers tends to vary by the child's age. While nutrition-related concerns were the most common at the age of 0, concerns related to play and education rose to the highest ranking at the age of 1, and remained so until the age of 6. It was found that only play and education related concerns continued to increase as children grew up.The proportion of other types of child-rearing concerns gradually decreased as the children grew up or remained stable without significant changes."
컴퓨터 비전과 딥러닝을 이용한 철도 시설 접근자 실시간 모니터링 시스템,2020,"['침입자 통제', '철도 보안', '딥러닝', '컴퓨터 화상', '실시간 감시', 'Intruder control', 'Railway security', 'Deep learning', 'Computer vision', 'Real-time monitoring']",,"The task of securing safety from terrorist attacks, which have recently been aimed at multiple civilian use facilities overseas, is drawing attention. This paper proposes a real-time intruder monitoring system that protects critical equipment and facilities of the railway system, which transports 37 million tons of cargo and 3.8 billion passengers per year. In integrating and testing the system, TensorFlow, OpenCV, and Amazon Web Service (AWS) IoT SDK were set up for the device part using Raspberry Pi, AWS IoT, and the Twilio API, which is based on AWS Lambda and installed at the AWS cloud on the server part. TensorFlow is applied with SSD+MobileNetV1, which learned with the COCO Dataset to detect the presence of intruders from a surveillance camera view of the secure area. In the event of intruder occurrence, SMS informs the security manager or safety manager of the area and assists their follow-up measures so that security threats by intruders can be prevented and damage minimized in the event of an emergency. In tests using plastic dummies, the system showed a 1.05 s response speed and less than 50% accuracy, in recognizing intruders; however, tests based on actual human bodies showed better recognition accuracy of 80% or more in a range about 10m from the camera."
피부진단을 위한 딥러닝 기반 피부 영상에서의 자동 주름 추출,2020,"['Winkles detection', 'Skin diagnosis', 'Illumination correction', 'Convolutional neural networks', 'Deep learning.']","주름은 피부의 노화도를 알 수 있는 주요한 특징 중의 하나이다. 기존의 영상처리기반 주름검출은 다양한 피부 영상에 효과적으로 대처하기 어렵다. 특히, 주름이 선명하지 않고 주변 피부와 유사한 경우 주름추출 성능은 급격히 떨어진다. 본 논문에서는 현미경 피부 영상에서 주름추출을 위해 딥러닝을 적용한다. 일반적으로 현미경 영상은 광각렌즈를 탑재하므로 영상 가장자리 영역의 밝기가 어둡다. 본 논문에서는 이를 해결하기 위해 피부 영상의 밝기를 추정하여 보정 한다. 또한, 주름추출에 적합한 의미분할 네트워크의 구조를 적용한다. 제안방법은 연구실에서 수집한 피부 영상에 대한 테스트 실험에서 99.6%의 정확도를 획득하였다.","Wrinkles are one of the main features of skin aging. Conventional image processing-based wrinkle detection is difficult to effectively cope with various skin images. In particular, Wrinkle extraction performance is significantly decreased when the wrinkles are not strong and similar to the surrounding skin. In this paper, deep learning is applied to extract wrinkles from microscopic skin images. In general, the microscope image is equipped with a wide-angle lens, so the brightness at the boundary area of the image is dark. In this paper, to solve this problem, the brightness of the skin image is estimated and corrected. In addition, We apply the structure of semantic segmentation network suitable for wrinkle extraction. The proposed method obtained an accuracy of 99.6% in test experiments on skin images collected in our laboratory."
랜덤 포레스트와 딥러닝을 이용한 노인환자의 사망률 예측,2020,"['사망률 예측', '합성곱 신경망', '랜덤 포레스트', '자질 선택', '딥러닝', 'Mortality Prediction', 'Convolutional Neural Network', 'Random Forest', 'Feature Selection', 'Deep Learning']",,"We predict the mortality of the elderly patients visiting the emergency department who are over 65 years old using Feed Forward Neural Network (FFNN) and Convolutional Neural Network (CNN) respectively. Medical data consist of 99 features including basic information such as sex, age, temperature, and heart rate as well as past history, various blood tests and culture tests, and etc. Among these, we used random forest to select features by measuring the importance of features in the prediction of mortality. As a result, using the top 80 features with high importance is best in the mortality prediction. The performance of the FFNN and CNN is compared by using the selected features for training each neural network. To train CNN with images, we convert medical data to fixed size images. We acquire better results with CNN than with FFNN. With CNN for mortality prediction, F1 score and the AUC for test data are 56.9 and 92.1 respectively."
한국어 TTS 시스템에서 딥러닝 기반 최첨단 보코더 기술 성능 비교,2020,"['심층 신경망', 'Text-to-Speech(TTS)', '보코더', 'deep learning', 'text-to-speech(TTS)', 'vocoder']","기존의 TTS 시스템은 텍스트 전처리, 구문 분석, 발음표기 변환, 경계 분석, 운율 조절, 음향 모델에 의한 음향 특징 생성, 합성음 생성 등 여러 모듈로 구성되어 있다. 그러나 딥러닝 기반 TTS 시스템은 텍스트에서 스펙트로그램을 생성하는 Text2Mel 과정과 스펙트로그램에서 음성신호을 합성하는 보코더로 구성된다. 본 논문에서는 최적의 한국어 TTS 시스템 구성을 위해 Tex2Mel 과정에는 Tacotron2를 적용하고, 보코더로는 WaveNet, WaveRNN, WaveGlow를 소개하고 이를 구현하여 성능을 비교 검증한다. 실험 결과, WaveNet은 MOS가 가장 높으며 학습 모델 크기가 수백 MB이고 합성시간이 실시간의 50배 정도라는 결과가 나왔다. WaveRNN은 WaveNet과 유사한 MOS 성능을 보여주며 모델 크기가 수십 MB 단위이고 실시간 처리는 어렵다는 결과가 도출됐다. WaveGlow는 실시간 처리가 가능한 방법이며 모델 크기가 수 GB이고 MOS가 세 방식 중에서 가장 떨어진다는 결과를 보여주었다. 본 논문에서는 이러한 연구 결과로부터 TTS 시스템을 적용하는 분야의 하드웨어 환경에 맞춰 적합한 방식을 선정할 수 있는 참고 기준을 제시한다.","The conventional TTS system consists of several modules, including text preprocessing, parsing analysis, grapheme-to-phoneme conversion, boundary analysis, prosody control, acoustic feature generation by acoustic model, and synthesized speech generation. But TTS system with deep learning is composed of Text2Mel process that generates spectrogram from text, and vocoder that synthesizes speech signals from spectrogram. In this paper, for the optimal Korean TTS system construction we apply Tacotron2 to Tex2Mel process, and as a vocoder we introduce the methods such as WaveNet, WaveRNN, and WaveGlow, and implement them to verify and compare their performance. Experimental results show that WaveNet has the highest MOS and the trained model is hundreds of megabytes in size, but the synthesis time is about 50 times the real time. WaveRNN shows MOS performance similar to that of WaveNet and the model size is several tens of megabytes, but this method also cannot be processed in real time. WaveGlow can handle real-time processing, but the model is several GB in size and MOS is the worst of the three vocoders. From the results of this study, the reference criteria for selecting the appropriate method according to the hardware environment in the field of applying the TTS system are presented in this paper."
실내 핑거프린트 측위를 위한 딥러닝 기반의 초고해상도 RF 맵 재구성 기법,2020,"['실내 위치 추정', '핑거프린트 측위', 'RF 맵 재구성', '딥러닝']",본 논문은 실내 핑거프린트 측위의 정확도를 향상시키기 위한 딥러닝 기반의 RF 맵 재구성 기법을 제안한다. 제안 기법은 합성곱 신경망 구조를 사용하여 희소 데이터와 정답 데이터와의 관계를 직접 학습함으로써 오프라인 단계에서 조사하지 않은 지역의 RF 맵을 고해상도로 복원한다. 실험 결과를 통해 제안 기법이 기존의 핑거프린트 측위보다 7.53m 향상된 측위 정확도를 가지며 다항식 보간법으로 RF 맵을 재구성하는 기법보다 0.92m의 추가적인 측위 정확도를 획득하였다.,"In this paper, we propose a deep learning-based radio frequency (RF) map reconstruction method to improve the accuracy of the indoor fingerprint positioning. The proposed scheme reconstructs the RF map in super-resolution using a convolutional neural network (CNN) by directly learning with sparse data and ground truth data in the offline phase. The simulation results show that the proposed method has 7.53m improved positioning accuracy than the conventional fingerprint positioning and 0.92m additional positioning accuracy than the bicubic interpolation method."
치매 환자를 위한 딥러닝 기반 이상 행동 탐지 시스템,2020,"['Abnomaly detection', 'Deep-learning', 'AutoEncoder', 'Long Short-Term Memory models', '이상 행동 감지', '딥러닝', '오토인코더', '장·단기 기억 모형']","고령화로 인해 증가하는 노인 비율만큼이나 치매를 앓는 노인 수 또한 빠르게 늘고 있는데 이는 사회적, 경제적 부담을 발생시킨다. 특히, 간병인의 근무 시간 손실 및 간호 부담으로 인한 의료 비용 증가와 같은 간접비용을 포함하는 치매 관리 비용은 수년에걸쳐 기하급수적으로 증가하고 있다. 이러한 비용을 줄이기 위해 치매 환자를 돌보기 위한 관리 시스템 도입이 시급하다. 따라서 본연구는 항상 치매 환자를 돌볼 수 없는 환경이나 독거노인을 관리하기 위한 센서 기반 이상 행동 탐지 시스템을 제안한다. 기존 연구들은 단지 행동을 인지하거나 정상 행동 여부를 평가하는 정도였고 센서로부터 받은 데이터가 아닌 이미지를 처리하여 행동을 인지한 연구도 있었다. 본 연구에서는 실데이터 수집에 한계가 있음을 인지하여 비지도 학습 모델인 오토인코더와 지도 학습 모델인 장· 단기 기억 모형을 동시에 사용했다. 비지도 학습 모델인 오토인코더는 정상 행동 데이터를 학습하여 정상적인 행동에 대한 패턴을학습시켰고 장·단기 기억 모형은 센서로 인지 가능한 행동을 학습시켜 분류를 좀 더 세분화했다. 테스트 결과 각각의 모델은 약 96%, 98% 이상의 정확도를 도출하였고 오토인코더의 이상치가 3% 이상을 갖는 경우 장·단기 기억 모형을 통과하도록 설계했다. 이 시스템을 통해 혼자 사는 노인이나 치매 환자를 효율적으로 관리할 수 있으며 돌보기 위한 비용 또한 절감할 수 있을 것으로 전망된다.","The number of elderly people with dementia is increasing as fast as the proportion of older people due to aging, which creates a social and economic burden. In particular, dementia care costs, including indirect costs such as increased care costs due to lost caregiver hours and caregivers, have grown exponentially over the years. In order to reduce these costs, it is urgent to introduce a management system to care for dementia patients. Therefore, this study proposes a sensor-based abnormal behavior detection system to manage dementia patients who live alone or in an environment where they cannot always take care of dementia patients. Existing studies were merely evaluating behavior or evaluating normal behavior, and there were studies that perceived behavior by processing images, not data from sensors. In this study, we recognized the limitation of real data collection and used both the auto-encoder, the unsupervised learning model, and the LSTM, the supervised learning model. Autoencoder, an unsupervised learning model, trained normal behavioral data to learn patterns for normal behavior, and LSTM further refined classification by learning behaviors that could be perceived by sensors. The test results show that each model has about 96% and 98% accuracy and is designed to pass the LSTM model when the autoencoder outlier has more than 3%. The system is expected to effectively manage the elderly and dementia patients who live alone and reduce the cost of caring."
레이저 열화상 기법과 CNN 딥러닝을 이용한 용접부 표면의 자동 균열 검출 기술 개발,2020,"['CNN', '레이저 열화상', '비파괴검사', '용접 균열 진단', 'Laser active thermography', 'Nondestructive testing', 'Welding crack diagnosis']","본 연구에서는 레이저 열화상 시스템과 균열 검출 알고리즘 개발을 통해 용접부에서 균열을 자동검출하는 기술을 연구하였다. 레이저 열화상 시스템은 레이저 가진으로 인해 균열부에서 발생하는 열파 집중현상을 관측하도록 구성되었다. 균열 검출 알고리즘은 (1) 온도 분포 특성을 이용한 열화상 이미지 병합으로 균열을 가시화하고, (2) 과적합을 방지하는 input 이미지 생성과 (3) CNN 딥러닝을 통해 균열부의 특징을 분석, 분류하여, (4) 원본 열화상 이미지에 균열의 위치를 Masking 한다. SUS 시험편 2개로 개발 기술을 검증하였고, 현미경과 액체침투법으로 확인한 실제 균열 정보와 비교하였다. 시험편 #1의 균열 이미지 618 개와 정상 이미지 1834개로 CNN 을 훈련시켰다. 시험편 #1과 #2의 총 9개 영역을 각 300개의 Test 이미지로 나눠 훈련된 알고리즘 성능을 검증해본 결과, 총 균열 14개 중 13개를 검출하였고, 정상 이미지 4개가 과검출되었다. 따라서 개발된 알고리즘은 용접부에서 용접의 복잡한 패턴과 구별하여 균열을 검출할 수 있다.","In this study, automatic crack detection for welded surfaces was studied through the development of a laser active thermography system and a crack detection algorithm. The laser active thermography system observes thermal wave concentrations in the crack while exciting the surface of the weld. The crack detection algorithm (1) visualizes the cracks by merging the infrared (IR) images using the temperature distribution characteristics; (2) employs input image generation with a specific method to prevent overfitting; (3) analyzes and classifies the characteristics of the cracks using a deep learning convolutional neural network (CNN); and (4) marks the location of the cracks in the original IR image. The system and algorithm were verified using two SUS specimens (#1 and #2) and compared with actual crack data obtained by microscopy and penetration test. The CNN was trained with 618 images of cracks and 1834 images of intact specimen #1. For performance verification, a total of nine areas of specimens #1 and #2 were divided into 300 test images; 13 out of 14 cracks were detected while four intact images were overdetected. Thus, the developed algorithm can detect cracks in welded surfaces by distinuishing them from complex patterns of welding."
국민청원 주제 분석 및 딥러닝 기반 답변 가능 청원 예측,2020,"['National Petition', 'Topic Analysis', 'Topic Modeling', 'K-means Clustering', 'LSTM', 'Deep Learning', '국민청원', '주제 분석', '토픽 모델링', 'K-means 클러스터링', 'LSTM', '딥러닝']",,"Since the opening of the national petition site, it has attracted much attention. In this paper, we perform topic analysis of the national petition site and propose a prediction model for answerable petitions based on deep learning. First, 1,500 petitions are collected, topics are extracted based on the petitions’ contents. Main subjects are defined using K-means clustering algorithm, and detailed subjects are defined using topic modeling of petitions belonging to the main subjects. Also, long short-term memory (LSTM) is used for prediction of answerable petitions. Not only title and contents but also categories, length of text, and ratio of part of speech such as noun, adjective, adverb, verb are also used for the proposed model. Our experimental results show that the type 2 model using other features such as ratio of part of speech, length of text, and categories outperforms the type 1 model without other features."
구글맵 API를 이용한 딥러닝 기반의 드론 자동 착륙 기법 설계,2020,"['지상관제 소프트웨어', 'GPS', '딥러닝', '구글맵 API', '자동 착륙', '이미지매칭', 'Ground control software', 'GPS', 'Deep learning', 'Google Maps API', 'Automatic landing', 'Image matching']","최근 원격조종과 자율조종이 가능한 무인항공기(RPAS:Remotely Piloted Aircraft System)가 택배 드론, 소방드론, 구급 드론, 농업용 드론, 예술 드론, 드론 택시 등 각 산업 분야와 공공기관에서의 관심과 활용이 높아지고 있다. 자율조종이 가능한 무인드론의 안정성 문제는 앞으로 드론 산업의 발달과 함께 진화하면서 해결해야 할 가장 큰 과제이기도 하다. 드론은 자율비행제어 시스템이 지정한 경로로 비행하고 목적지에 정확하게 자동 착륙을 수행할 수 있어야 한다. 본 연구는 드론의 센서와 GPS의 위치 정보의 오류를 보완하는 방법으로서 착륙지점 영상을 통해 드론의 도착 여부를 확인하고 정확한 위치에서의 착륙을 제어하는 기법을 제안한다. 서버에서 도착지 영상을 구글맵 API로부터 수신받아 딥러닝으로 학습하고, 드론에 NAVIO2와 라즈베리파이, 카메라를 장착하여 착륙지점의 이미지를 촬영한 다음 이미지를 서버에 전송한다. Deep Learning으로 학습된 결과와 비교하여 임계치에 맞게 드론의 위치를 조정한 후 착륙지점에 자동으로 착륙할 수 있다.","Recently, the RPAS(Remote Piloted Aircraft System), by remote control and autonomous navigation, has been increasing in interest and utilization in various industries and public organizations along with delivery drones, fire drones, ambulances, agricultural drones, and others. The problems of the stability of unmanned drones, which can be self-controlled, are also the biggest challenge to be solved along the development of the drone industry. drones should be able to fly in the specified path the autonomous flight control system sets, and perform automatically an accurate landing at the destination. This study proposes a technique to check arrival by landing point images and control landing at the correct point, compensating for errors in location data of the drone sensors and GPS. Receiving from the Google Map API and learning from the destination video, taking images of the landing point with a drone equipped with a NAVIO2 and Raspberry Pi, camera, sending them to the server, adjusting the location of the drone in line with threshold, Drones can automatically land at the landing point."
K-평균 군집화 알고리즘 및 딥러닝 기반 군중 집계를 이용한 전염병 확진자 접촉 가능성 여부 판단 모니터링 시스템 제안,2020,"['전염병', 'K-평균 군집화', '군중 계수', '모니터링 시스템', '전염병 예방', 'Infectious Diseases', 'K-means Clustering', 'Crowd Counting', 'Monitoring System', 'Pandemic Prevention']","전 세계적으로 무증상의 코로나바이러스 감염증-19 감염자가 자신이 감염된 것을 모르고 주변인들에게 전파할 수 있다는 가능성은 국민이 전염병 확산에 대한 불안과 두려움에서 벗어나지 못하고 있다는 점에서 여전히 매우 중요한 이슈이다. 본 논문에서는 K-평균 군집화 알고리즘 및 딥러닝 기반 군중 집계를 이용한 전염병 확진자 접촉 가능성 여부 판단 모니터링 시스템을 제안하였다. 모든 입력 학습 영상에 대해 300회 반복 학습한 결과, PSNR값은 21.51, 전체 데이터 셋에 대한 최종 MAE값은 67.984였다. 이는 확진자와 주변인과의 거리와 감염률 산출, 잠재적 환자 동선 주변 인원의 위험도 순 그룹 및 감염률 예측에 대한 영상 속 화질 정보, 관측치 간의 평균 절대 오차를 의미하며 각 CCTV 장면에서 군중의 수가 4,000명 이하일 때에는 평균 절대 오차 값이 0에 가까움을 증명하였다.","The possibility that an asymptotic coronavirus-19 infected person around the world is not aware of his infection and can spread it to people around him is still a very important issue in that the public is not free from anxiety and fear over the spread of the epidemic. In this paper, the K-means clustering algorithm and deep learning-based crowd aggregation were proposed to determine the possibility of contact with confirmed cases of infectious diseases. As a result of 300 iterations of all input learning images, the PSNR value was 21.51, and the final MAE value for the entire data set was 67.984. This means the average absolute error between observations and the average absolute error of fewer than 4,000 people in each CCTV scene, including the calculation of the distance and infection rate from the confirmed patient and the surrounding persons, the net group of potential patient movements, and the prediction of the infection rate."
Gaofen-1 WFV 영상을 이용한 딥러닝 기반 대형 부유조류 분류,2020,"['Deep learning', 'Transfer learning', 'AlexNet', 'Green and Golden tide', 'Gaofen-1 WFV']","매년 황해와 동중국해에서는 대형 부유조류인 녹조와 갈조가 대량으로 발생하고 있다. 이러한 대형 부유조류는 연안의 양식 시설물이나 해변으로 유입되며, 제거하는데 막대한 경제적 손실을 발생시킨다. 현재는 연안으로 유입되는 대형 부유조류를 탐지하기 위해 원격탐사 방법이 활발하게 사용되고 있다. 그러나 대형 부유조류는 해양의 다양한 대상들과 중첩되는 파장이 존재하기에 이를 정확하게 탐지하는데 한계가 있다. 더욱이 녹조와 갈조는 유사한 스펙트럼 특성을 보이기 때문에 원격탐사 자료를 이용한 구분을 더욱 어렵게 만든다. 따라서 본 연구에서는 위성 영상에 딥러닝 기법을 적용하여 녹조와 갈조를 효과적으로 구분하고자 하였다. 이를 위한 네트워크를 결정하기 위해 최적의 학습 조건을 찾아 AlexNet 신경망을 전이 학습하였으며, 학습과 검증을 위해 Gaofen-1 WFV 영상을 이용하여 데이터셋을 구성하였다. 최적의 학습 조건으로 학습된 네트워크를 이용하여 실험 데이터에 대한 결과를 확인하였다. 그 결과 실험 데이터에 대한 정확도는 88.89%를 보였으며, 녹조와 갈조에 대해 각각 66.67%와 100%의 정밀도로 구분이 가능하였다. 이는 전이 학습된 AlexNet 신경망이 녹조와 갈조의 미세한 차이를 구분할 수 있는 것으로 해석된다. 본 연구를 통해 해양의 다양한 대상으로부터 녹조와 갈조를 효과적으로 분류하고 각각 구분할 수 있을 것으로 기대된다.",
Imaginary Soundscape 기반의 딥러닝을 활용한 회화와 음악의 매칭 및 다중 감각을 이용한 융합적 평가 방법,2020,"['Matching of Painting and Music', 'Deep Learning', 'Multimodal Evaluation', 'Auditory Interaction', 'Multisensory Experience', 'Soundscape', '회회와 음악의 매칭', '딥러닝', '멀티모달 평가', '청각 인터랙션', '다중감각 경험', '사운드스케이프']","본 연구에서는 회화 감상에 도움이 되는 사운드스케이프를 구성하기 위해 딥러닝 기술을 활용하여 클래식 음악을 매칭하는 기술을 소개하고 회화와 음악 매칭이 얼마나 잘 되었는지에 대해 평가할 수 있는 평가 지표를 제안한다. 평가 지표는 리커드 5점 척도를 통한 적합도 평가와 멀티모달 측면의 평가로 진행하였다. 회화와 음악 매칭에 대해 13명의 실험 참가자의 적합도 평가의 점수는 3.74/5.0 이었고, 또한 13명의 실험 참가자의 멀티모달 평가에서 회화와 음악 매칭의 코사인 유사도의 평균은 0.79였다. 멀티모달적 평가는 새로운 사용자 경험을 측정할 수 있는 평가 지표가 될 것으로 기대된다. 또한 본 연구를 통해 시각과 청각의 인터랙션을 제안함으로써 다중감각 예술작품 경험을 향상시키고자 하였다. 본 연구에서 제안된 회화와 음악 매칭이 다중감각 예술작품 전시에서 활용되며 더 나아가 이는 시각 장애인들의 예술작품 감상에 대한 접근성을 높일 수 있을 것이라 기대한다.","In this study, we introduced the technique of matching classical music using deep learning to design soundscape that can help the viewer appreciate painting and proposed an evaluation index to evaluate how well matching painting and music. The evaluation index was conducted with suitability evaluation through the Likeard 5-point scale and evaluation in a multimodal aspect. The suitability evaluation score of the 13 test participants for the deep learning based best match between painting and music was 3.74/5.0 and band the average cosine similarity of the multimodal evaluation of 13 participants was 0.79. We expect multimodal evaluation to be an evaluation index that can measure a new user experience. In addition, this study aims to improve the experience of multisensory artworks by proposing the interaction between visual and auditory. The proposed matching of painting and music method can be used in multisensory artwork exhibition and furthermore it will increase the accessibility of visually impaired people to appreciate artworks."
노인코호트 DB를 이용한 딥러닝 기반의 뇌졸중 질환 예측 모델,2020,"['뇌졸중', '질환 예측', '딥러닝', 'CNN', '뇌졸중 심층 분석', 'Stroke', 'Disease Prediction', 'Deep Learning', 'Convolution Neural Network', 'Stroke In-depth Analysis']",,"Stroke is the leading cause of death worldwide after cancer and heart disease. According to a statistical analysis of deaths by Statistics Korea, about 70 deaths occur every day. By 2030, the incidence of stroke disease is expected to surge more than three times due to an aging population. Therefore, research is required to reduce the burden of death and medical expenses and minimize social loss due to stroke disease. In this paper, we designed and implemented a new model that enables CNN-based stroke disease prediction. The model for predicting stroke disease was verified by using data from 558,147 elderly over the age of 60 published by the NHIS(national health insurance service). Through this experiment, we confirmed the accuracy of the model and the prediction of stroke disease for the Korean elderly."
핵의학 감마카메라 정도관리의 딥러닝 적용,2020,"['핵의학', '정도관리', '인공지능', '콘볼루션 신경망', '딥러닝', 'Nuclear medicine', 'Quality Control', 'AI', 'CNN', 'Deep Learning']",,"In the field of nuclear medicine, errors are sometimes generated because the assessment of the uniformity of gamma cameras relies on the naked eye of the evaluator. To minimize these errors, we created an artificial intelligence model based on CNN algorithm and wanted to assess its usefulness. We produced 20,000 normal images and partial cold region images using Python, and conducted artificial intelligence training with Resnet18 models. The training results showed that accuracy, specificity and sensitivity were 95.01%, 92.30%, and 97.73%, respectively. According to the results of the evaluation of the confusion matrix of artificial intelligence and expert groups, artificial intelligence was accuracy, specificity and sensitivity of 94.00%, 91.50%, and 96.80%, respectively, and expert groups was accuracy, specificity and sensitivity of 69.00%, 64.00%, and 74.00%, respectively. The results showed that artificial intelligence was better than expert groups. In addition, by checking together with the radiological technologist and AI, errors that may occur during the quality control process can be reduced, providing a better examination environment for patients, providing convenience to radiologists, and improving work efficiency."
무인항공기 영상 및 딥러닝 기반 객체인식 알고리즘을 활용한 해안표착 폐기물 탐지 기법 연구,2020,"['해안 표착 폐기물', '원격 탐사', '객체 탐지', '기계 학습', '무인 항공기', 'Coastal Debris', 'Remote Sensing', 'Object Detection', 'Machine Learning', 'UAV']","본 연구에서는 무인항공기 원격탐사 기법과 딥러닝 기반 객체인식 알고리즘을 활용한 해안표착폐기물 탐지 기법을 제안한다. 항공영상 내에 존재하는 해안표착폐기물을 탐지하기 위해 심층신경망 기반 객체 인식 알고리즘을 제안하였다. PET, 스티로폼, 기타 플라스틱의 3가지 클래스의 이미지 데이터셋으로 심층신경망 모델을 훈련시켰으며, 각 클래스별 탐지 정확도를 Darknet-53과 비교하였다. 이를 통해 해안표착 폐기물을 무인항공기를 통해 성상별 모니터링할 수 있었으며, 향후 본 연구에서 제안하는 방법이 적용될 경우 해변 전체에 대한 성상별 전수조사가 가능하며, 이를 통해 해양환경 감시 분야의 효율성 증대에 기여할 수 있을 것으로 판단된다.","In this study, we propose a method for detecting coastal surface wastes using an UAV(Unmanned Aerial Vehicle) remote sensing method and an object detection algorithm based on deep learning. An object detection algorithm based on deep neural networks was proposed to detect coastal debris in aerial images. A deep neural network model was trained with image datasets of three classes: PET, Styrofoam, and plastics. And the detection accuracy of each class was compared with Darknet-53. Through this, it was possible to monitor the wastes landing on the shore by type through unmanned aerial vehicles. In the future, if the method proposed in this study is applied, a complete enumeration of the whole beach will be possible. Through this, it is believed that it can contribute to increase the efficiency of the marine environment monitoring field."
가상 3D 라이다 기반 객체 분류 딥러닝 학습 데이터셋 구축 방법에 관한 연구,2020,"['Autonomous drivng(자율주행)', 'Lidar sensor(라이다 센서)', 'Deep learning(딥러닝)', 'Training dataset(학습 데이터셋)', 'Object classification(객체 분류)']",,
엣지 디바이스인 소셜 로봇에서의 영상 딥러닝을 위한 모듈 교체형 인공지능 서버 설계 및 개발,2020,"['AI server', 'Artificial Intelligence Server', 'Image Processing', 'Robot Interaction', 'Robot Platform']","본 논문에서는 인공지능 블록을 구동할 수 있도록 Edge Device와 서버를 분리하는 영상 딥러닝용 모듈 교체형 인공지능 서버의 설계와 데이터 송수신 방법을 제시한다. 영상 딥러닝용 모듈 교체형 인공지능 서버를 통해 소셜 로봇과 로봇의 플랫폼이 구동될 Edge Device 간의 종속성을 줄여 구동 안정성을 향상할 수 있다. 사용자가 소셜 로봇과의 상호작용을 위해서 인공지능 서버에 기능을 요청하면 모듈화된 기능들을 이용해 결과만을 반환받을 수 있다. 인공지능 서버에서 모듈화되어있는 기능들은 서버 관리자에 의해 모듈별로 유지 보수 및 변경이 쉽게 가능하다. 기존 서버 시스템과 비교했을 때 모듈 교체형 인공지능 서버는 수행되는 프로그램의 규모 차이와 서버 유지 보수 면에서 더 효율적인 성능을 낸다. 이를 통해 사람-로봇 간의 상호작용이 가능한 로봇 시나리오에 더 다양한 영상 딥러닝을 포함 시킬 수 있으며, 로봇 플랫폼 외에 영상 딥러닝을 위한 인공지능 서버에 적용할 때 더 효율적인 성능을 낼 수 있다.","In this paper, we present the design of modular replaceable AI server for image deep learning that separates the server from the Edge Device so as to drive the AI block and the method of data transmission and reception. The modular replaceable AI server for image deep learning can reduce the dependency between social robots and edge devices where the robot""s platform will be operated to improve drive stability. When a user requests a function from an AI server for interaction with a social robot, modular functions can be used to return only the results. Modular functions in AI servers can be easily maintained and changed by each module by the server manager. Compared to existing server systems, modular replaceable AI servers produce more efficient performance in terms of server maintenance and scale differences in the programs performed. Through this, more diverse image deep learning can be included in robot scenarios that allow human-robot interaction, and more efficient performance can be achieved when applied to AI servers for image deep learning in addition to robot platforms."
대장 통과 시간 측정을 위한 딥러닝 기반 방사선 비투과성 표지자 자동 탐지 기법,2020,"['만성 변비', '대장 통과 시간', '방사선 비투과성 표지자', '딥러닝', '의료 딥러닝', 'Chronic Constipation', 'Colon Transit Time', 'Radiopaque Marker', 'Deep Learning', 'Medical Deep Learning']",,
인지 무선 통신망의 자동 변조 분류를 위한 딥러닝 모델 설계,2020,"['Deep Learning', 'Convolutional Neural Networks', 'Automatic Modulation Classification', 'CognitiveRadio Network', 'Predicted Accuracy']",,
BCI 제어를 위한 뇌신호 분류에서의 딥러닝 모델 개발,2020,"['뇌신호', '뇌-컴퓨터 인터페이스', '운동상상', '뇌신호 분류', '딥러닝', '합성곱신경망', 'Electroencephalography(EEG)', 'Brain-computer interface(BCI)', 'Motor imagery(MI)', 'EEG classification', 'deep learning', 'Convolutional neural network(CNN)']",,
"영상, 음성, 활동, 먼지 센서를 융합한 딥러닝 기반 사용자 이상 징후 탐지 알고리즘",2020,"['영상', '음성', '활동', '먼지', '센서', '딥러닝', '이상 징후', '패턴', 'Vision', 'audio', 'activity', 'dust', 'sensors', 'deep learning', 'abnormal event', 'patterns']","최근 다양한 질병 때문에 사람들은 집 안에서 많은 시간을 보내고 있다. 집 안에서 다치거나 질병에 감염되어 타인의 도움이 필요한 1인 가구의 경우 타인에게 도움을 요청하기 어렵다. 본 연구에서는 1인 가구가 집 안에서 부상이나 질병 감염 등 타인의 도움이 필요로 하는 상황인 이상 징후를 탐지하기 위한 알고리즘을 제안한다. 홈 CCTV를 이용한 영상 패턴 탐지 알고리즘과 인공지능 스피커 등을 이용한 음성 패턴 탐지 알고리즘, 스마트폰의 가속도 센서를 이용한 활동 패턴 탐지 알고리즘, 공기청정기 등을 이용한 먼지패턴 탐지 알고리즘을 제안한다. 하지만, 홈 CCTV의 보안 문제로 사용하기 어려울 경우 음성, 활동, 먼지 패턴 센서를 결합한 융합방식을 제안한다. 각 알고리즘은 유튜브와 실험을 통해 데이터를 수집하여 정확도를 측정했다.","Recently, people are spending a lot of time inside their homes because of various diseases. It is difficult to ask others for help in the case of a single-person household that is injured in the house or infected with a disease and needs help from others. In this study, an algorithm is proposed to detect emergency event, which are situations in which single-person households need help from others, such as injuries or disease infections, in their homes. It proposes vision pattern detection algorithms using home CCTVs, audio pattern detection algorithms using artificial intelligence speakers, activity pattern detection algorithms using acceleration sensors in smartphones, and dust pattern detection algorithms using air purifiers. However, if it is difficult to use due to security issues of home CCTVs, it proposes a fusion method combining audio, activity and dust pattern sensors. Each algorithm collected data through YouTube and experiments to measure accuracy."
해상 객체 검출 고속 처리를 위한 영상 전처리 알고리즘 설계와 딥러닝 기반의 통합 시스템,2020,"['Ship Detection', 'Deep Learning', 'Image Processing', 'Binarization', 'Horizon Detection', 'Multi Connected-component Labeling', '선박 인식', '딥러닝', '영상 처리', '이진화', '수평선 검출', '다중 연결 요소 라벨링']","해상 객체 인식은 자율운항선박(MASS)의 지능형 보조 시스템으로써, 선장이 육안으로 해상 주변의 충돌 위험성이 있는 부유물을확인하던 정보를 컴퓨터를 통해 자동으로 인식하여 사람이 확인하는 방법과 유사한 정확도로 인지하는 방법을 말한다. 선박 주변의물체를 인식하는 방법으로 기존에는 레이더나 소나와 같은 장치로부터 수집된 정보를 통해 확인하였지만, 인공지능의 기술이 발달하면서 선박 지능형 CCTV를 통해 운항 항로에 있는 다양한 부유물을 인식하는 것이 가능하다. 하지만, 자율 선박의 다양한 요구사항과복잡성 때문에 영상 데이터의 처리속도가 느려지게 된다면 원활한 서비스 지원은 물론 안전성도 보장할 수 없게 된다. 이러한 문제를 해결하고자 본 논문에서는 해상 객체를 검출하는 데 있어 영상 데이터의 연산량을 최소화하여 처리속도를 높이기 위한 연구를진행하였다. 해상 객체 인식의 관심 영역을 확보하기 위해서는 일반적으로 수평선을 찾는데 기존 연구들은 허프 변환 알고리즘을활용하지만 본 논문에서는 속도를 개선하기 위해 이진화 알고리즘을 최적화하여 실제 객체의 위치와 유사한 영역을 찾는 새로운 방법을 제안한다. 또한, 제안하는 방법의 유용성을 증명하기 위해 딥러닝 CNN을 활용하여 해상 객체 인식 시스템을 구현함으로써 알고리즘의 성능을 평가하였다. 제안하는 알고리즘은 기존 방법의 인식 정확도를 유지하면서 약 4배 이상의 빠른 성능을 얻을 수 있었다.","A maritime object detection system is an intelligent assistance system to maritime autonomous surface ship(MASS). It detects automatically floating debris, which has a clash risk with objects in the surrounding water and used to be checked by a captain with a naked eye, at a similar level of accuracy to the human check method. It is used to detect objects around a ship. In the past, they were detected with information gathered from radars or sonar devices. With the development of artificial intelligence technology, intelligent CCTV installed in a ship are used to detect various types of floating debris on the course of sailing. If the speed of processing video data slows down due to the various requirements and complexity of MASS, however, there is no guarantee for safety as well as smooth service support. Trying to solve this issue, this study conducted research on the minimization of computation volumes for video data and the increased speed of data processing to detect maritime objects. Unlike previous studies that used the Hough transform algorithm to find the horizon and secure the areas of interest for the concerned objects, the present study proposed a new method of optimizing a binarization algorithm and finding areas whose locations were similar to actual objects in order to improve the speed. A maritime object detection system was materialized based on deep learning CNN to demonstrate the usefulness of the proposed method and assess the performance of the algorithm. The proposed algorithm performed at a speed that was 4 times faster than the old method while keeping the detection accuracy of the old method."
터널 발파 진동 저감을 위한 대구경 무장약공 천공 장비의 최적 세팅조건 산정을 위한 딥러닝 적용에 관한 연구,2020,"['Blast vibration reduction', 'Center-cut method', 'Large-diameter horizontal boring', 'machine setting optimization', 'Deep learning', '발파 진동 저감', '심발 공법', '대구경 수평 천공', '장비 세팅 최적화', '딥러닝']",,"Multi-setting smart-investigation of the ground and large uncharged hole boring (MSP) method to reduce the blast-induced vibration in a tunnel excavation is carried out over 50m of long-distance boring in a horizontal direction and thus has been accompanied by deviations in boring alignment because of the heavy and one-directional rotation of the rod. Therefore, the deviation has been adjusted through the boring machine’s variable setting rely on the previous construction records and expert’s experience. However, the geological characteristics, machine conditions, and inexperienced workers have caused significant deviation from the target alignment. The excessive deviation from the boring target may cause a delay in the construction schedule and economic losses. A deep learning-based prediction model has been developed to discover an ideal initial setting of the MSP machine. Dropout, early stopping, pre-training techniques have been employed to prevent overfitting in the training phase and, significantly improved the prediction results. These results showed the high possibility of developing the model to suggest the boring machine’s optimum initial setting. We expect that optimized setting guidelines can be further developed through the continuous addition of the data and the additional consideration of the other factors."
딥러닝을 이용한 소외계층 아동의 스포츠 재활치료를 통한 정신 건강에 대한 변화,2020,"['머신 러닝', '서포트 벡터 머신', '결정 트리', '다중 퍼셉트론', '재귀 신경망', '중기 단기 기억', 'Machine learning', 'Support vector machine', 'Decision tree', 'Multi-perceptron', 'Recurent Neural Network', 'Long Short Term Memory']","본 논문은 소외계층 아동의 운동학습프로그램에서 체력 활동 중 나를 잘 따른다(0-9), 마음의 결정을 내리는데 많은 시간이 걸린다(0-9), 맥빠진(0-9) 등을 변수로 사용하여 성별 , 체육교실 , 나이의 상중하 를 분류하고 스포츠 재활치료를 통한 자아 탄력(ego-resiliency)과 자아 통제(self-control)의 변화를 관찰하여 정신 건강 변화를 알아본다. 이를 위해 취득한 데이터를 병합하고 Label encoder와 One-hot encoding을 사용하여 숫자의 크고 작음의 특성을 제거한 후 MLP, SVM, Dicesion tree, RNN, LSTM의 각각의 알고리즘을 적용하여 성능을 평가하기 위해 Train, Test 데이터를 75%, 25% 스플릿 한 뒤 Train 데이터로 알고리즘을 학습하고 Test 데이터로 알고리즘의 정확성을 측정한다. 측정 결과 성별에서는 LSTM, 체육 교실은 MLP와 LSTM, 나이는 SVM이 가장 우수한 결과를 보임을 확인하였다.","This paper uses variables following as : to follow me well(0-9), it takes a lot of time to make a decision (0-9), lethargy(0-9) during physical activity in the exercise learning program of the children in the marginalized class. This paper classifies gender , physical education classroom , and upper, middle and lower of age, and observe changes in ego-resiliency and self-control through sports rehabilitation therapy to find out changes in mental health. To achieve this, the data acquired was merged and the characteristics of large and small numbers were removed using the Label encoder and One-hot encoding. Then, to evaluate the performance by applying each algorithm of MLP, SVM, Dicesion tree, RNN, and LSTM, the train and test data were divided by 75% and 25%, and then the algorithm was learned with train data and the accuracy of the algorithm was measured with the Test data. As a result of the measurement, LSTM was the most effective in sex, MLP and LSTM in physical education classroom, and SVM was the most effective in age."
딥러닝을 이용한 캠 열처리 공정 자동화에 관한 연구,2020,"['Heat treatment', 'FA', 'Deep Learning']",,"In this paper, we propose a control method to solve the surface hardness non-uniformity due to flow non-uniformity occurring in the heat treatment process of marine CAM. In the water cooling method including the decarbonization method, an automation device for deformation control has been developed and applied. LSTM was used to estimate the water cooling conditions, and the proposed method was found to be meaningful by improving the prototype results."
딥러닝 기반 사물 검출을 활용한 우선순위 사물 중심의 영상 스티칭,2020,"['Image Stitching', 'Parallax Distortion', 'Seam Optimization', 'Object Detection', 'Priority Object']",,"Recently, the use of immersive media contents representing Panorama and 360° video is increasing. Since the viewing angle is limited to generate the content through a general camera, image stitching is mainly used to combine images taken with multiple cameras into one image having a wide field of view. However, if the parallax between the cameras is large, parallax distortion may occur in the stitched image, which disturbs the users content immersion, thus an image stitching overcoming parallax distortion is required. The existing Seam Optimization based image stitching method to overcome parallax distortion uses energy function or object segment information to reflect the location information of objects, but the initial seam generation location, background information, performance of the object detector, and placement of objects may limit application. Therefore, in this paper, we propose an image stitching method that can overcome the limitations of the existing method by adding a weight value set differently according to the type of object to the energy value using object detection based on deep learning."
딥러닝 기반 벵골어 수기 문자 인식 : Kaggle Bengali.AI 대회를 중심으로,2020,"['Deep learning', 'handwritten character classification', 'CNN', 'data augmentation']",,
딥러닝 기법을 활용한 가구 부자재 주문 수요예측,2020,"['가구 부자재', '수요예측', '재고관리', '1D-CNN', 'Furniture Component', 'Oer demand Forecast', 'Inventory Control', 'ARIMA', 'LSTM', '1D-CNN F']",,"Despite the recent economic contraction caused by the Corona 19 incident, interest in the residential environment is growing as more people live at home due to the increase in telecommuting, thereby increasing demand for remodeling. In addition, the government’s real estate policy is also expected to have a visible impact on the sales of the interior and furniture industries as it shifts from regulatory policy to the expansion of housing supply. Accurate demand forecasting is a problem directly related to inventory management, and a good demand forecast can reduce logistics and inventory costs due to overproduction by eliminating the need to have unnecessary inventory. However, it is a difficult problem to predict accurate demand because external factors such as constantly changing economic trends, market trends, and social issues must be taken into account. In this study, LSTM model and 1D-CNN model were compared and analyzed by artificial intelligence-based time series analysis method to produce reliable results for manufacturers producing furniture components."
딥러닝 표정 인식을 활용한 실시간 온라인 강의 이해도 분석,2020,"['Degree of Understanding', 'Real-time Analysis', 'Face Detection', 'Facial Expression Recognition', 'Deep Learning']",,"Due to the spread of COVID-19, the online lecture has become more prevalent. However, it was found that a lot of students and professors are experiencing lack of communication. This study is therefore designed to improve interactive communication between professors and students in real-time online lectures. To do so, we explore deep learning approaches for automatic recognition of students' facial expressions and classification of their understanding into 3 classes (Understand / Neutral / Not Understand). We use 'BlazeFace' model for face detection and 'ResNet-GRU' model for facial expression recognition (FER). We name this entire process 'Degree of Understanding (DoU)' algorithm. DoU algorithm can analyze a multitude of students collectively and present the result in visualized statistics. To our knowledge, this study has great significance in that this is the first study offers the statistics of understanding in lectures using FER. As a result, the algorithm achieved rapid speed of 0.098sec/frame with high accuracy of 94.3% in CPU environment, demonstrating the potential to be applied to real-time online lectures. DoU Algorithm can be extended to various fields where facial expressions play important roles in communications such as interactions with hearing impaired people."
딥러닝을 이용한 쿼드콥터의 호버링 제어,2020,"['Quadcopter', 'Image Processing', 'Deep Learning']",,"In this paper, In this paper, we describe the UAV system using image processing for autonomous quadcopters, where they can apply logistics, rescue work etc.  we propose high-speed hovering height and posture control method based on state feedback control with CNN from camera because we can get image of the information only every 30ms. Finally, we show the advantages of proposed method by simulations and experiments."
딥러닝 스타일 전이 기반의 무대 탐방 콘텐츠 생성 기법,2020,,,"Recently, as interest in non-face-to-face experiences and services increases, the demand for web video contents that can be easily consumed using mobile devices such as smartphones or tablets is rapidly increasing. To cope with these requirements, in this paper we propose a technique to efficiently produce video contents that can provide experience of visiting famous places (i.e., stage tour) in animation or movies. To this end, an image dataset was established by collecting images of stage areas using Google Maps and Google Street View APIs. Afterwards, a deep learning-based style transfer method to apply the unique style of animation videos to the collected street view images and generate the video contents from the style-transferred images was presented. Finally, we showed that the proposed method could produce more interesting stage-tour video contents through various experiments."
딥러닝 기반의 이종 선생 네트워크를 지원하는 주요 파라미터 최적화 흐름정보 전이학습 기술,2020,"['deep learning', 'machine learning', 'transfer learning', 'flow of solution procedure', 'Baysian optimization']",,"In this paper, we propose a flow-based transfer learning (TL) algorithm with a faster learning speed while supporting the hetero teacher network. First, the proposed technique has a similar accuracy and performance compared to the previous TL using flow information and has been identified as having lower complexity. Next, the proposed scheme through Bayesian optimization obtained 0.1% to 0.3% more accuracy than the existing technology and showed learning results that were 230,000 to 250,000 seconds faster. Therefore, it is expected that the proposed scheme can be used as deep Learning-based transfer learning technology, which achieves similar or higher accuracy compared to the existing technology."
딥러닝 예측 기반의 OLED 재료 분자구조 가상 스크리닝,2020,"['Deep-learning', 'Prediction', 'Property', 'Molecular structure', 'Virtual screening']",,"A system that uses deep-learning techniques to predict properties from molecular structures has been developed to apply to chemical, biological and material studies. Based on the database where molecular structure and property information are accumulated, a deep-learning model looking for the relationship between the structure and the property can eventually provide a property prediction for the new molecular structure. In addition, experiments on the actual properties of the selected molecular structure will be carried out in parallel to carry out continuous verification and model updates. This allows for the screening of high-quality molecular structures from large quantities of molecular structures within a short period of time, and increases the efficiency and success rate of research. In this paper, we would like to introduce the overall composition of the materiality prediction system using deep-learning and the cases applied in the actual excavation of new structures in LG Chem."
딥러닝을 이용한 웨이퍼 빈 맵 신규 패턴 검출,2020,"['Semiconductor', 'Wafer Bin Map', 'Convolution Neural Networks', 'Classification', 'New Defect Pattern Detection', 'N']",,"Wafer bin map (WBM) represents defect information of semiconductor chips in wafers produced in semiconductor manufacturing processes. The locally generated defect patterns in WBM are often used to detect the cause of defects because these patterns can explain the characteristics of a specific process. Recently, many studies have been conducted to classify defect patterns generated in WBM due to the development of deep learning models. However, it is impossible to classify newly generated bad patterns because existing researches classify only defined bad patterns. In this paper, we propose a methodology to classify newly generated defect patterns and to classify defect patterns in wafers using probability information for each defect pattern in the classification model. As a result of the evaluation using the actual WBM data, it was confirmed that the classification of the defective pattern with the excellent performance and the classification of the newly generated defective pattern which was impossible in the existing model were possible."
딥러닝 학습을 이용한 한글 글꼴 자동 제작 시스템에서 글자 쌍의 매핑 기준 평가,2020,"['Automated Hangul Font Generation System', 'Font Generation Using CycleGAN', 'Evaluation of Mapping Characters', 'Completeness of Generated Characters', 'Similarity of Characters Style']",,"Hangul is a language that is composed of initial, medial, and final syllables. It has 11,172 characters.For this reason, the current method of designing all the characters by hand is very expensive and time-consuming. In order to solve the problem, this paper proposes an automatic Hangul font generation system and evaluates the standards for mapping Hangul characters to produce an effective automated Hangul font generation system. The system was implemented using character generation engine based on deep learning CycleGAN. In order to evaluate the criteria when mapping characters in pairs, each criterion was designed based on Hangul structure and character shape, and the quality of the generated characters was evaluated. As a result of the evaluation, the standards designed based on the Hangul structure did not affect the quality of the automated Hangul font generation system. On the other hand, when tried with similar characters, the standards made based on the shape of Hangul characters produced better quality characters than when tried with less similar characters. As a result, it is better to generate automated Hangul font by designing a learning method based on mapping characters in pairs that have similar character shapes"
딥러닝을 활용한 감정 분석 과정에서 필요한 데이터 전처리 및 형태 변형,2020,"['data preprocessing', 'transformation', 'sentiment analysis', 'deep learning']",,"This study examined how to preprocess and transform data efficiently in order to use deep learning techniques in analyzing linguistic data. Researchers’ interests in deep learning techniques have explosively increased worldwide; however, it is not easy for them to link linguistics to deep learning techniques or algorithms because linguists do not know how and where to begin in using them. Thus, this study provides the general procedure to train data using deep learning algorithms in practice. In particular, for instance, we focused on how to preprocess and transform Tweet data for a sentiment analysis by using deep learning techniques. In addition, we introduced the latest deep learning algorithm, so-called BERT, in the data preprocessing and transformation procedure. The data preprocessing is particularly important because the result from deep learning can significantly vary depending on it. Even though the data preprocessing procedure can differ according to the aim of research, this study tries to introduce the general way that advanced researchers frequently use for deep learning algorithms. This study is expected to lower the barriers in applying deep learning techniques to linguistic data and make it easier for researchers to conduct deep learning research related to linguistics."
딥-러닝을 활용한 안드로이드 플랫폼에서의 이미지 시맨틱 분할 구현,2020,"['Image Segmentation', 'Semantic Segmentation', 'Object Detection', 'Deep Learning', 'Tensorflow']",,"Image segmentation is the task of partitioning an image into multiple sets of pixels based on some characteristics. The objective is to simplify the image into a representation that is more meaningful and easier to analyze. In this paper, we apply deep-learning to pre-train the learning model, and implement an algorithm that performs image segmentation in real time by extracting frames for the stream input from the Android device. Based on the open source of DeepLab-v3+ implemented in Tensorflow, some convolution filters are modified to improve real-time operation on the Android platform."
딥러닝 기반 표고버섯 병해충 이미지 분석에 관한 연구,2020,"['Pests', 'Disease', 'Deep Learning', 'CNN', 'Alexnet', 'Shiitake']",,"The work that detection and elimination to disease and pest have important in agricultural field because it is directly related to the production of the crops, early detection and treatment of the disease insects. Image classification technology based on traditional computer vision have not been applied in part such as disease and pest because that is falling a accuracy to extraction and classification of feature. In this paper, we proposed model that determine to disease and pest of shiitake based on deep-CNN which have high image recognition performance than exist study. For performance evaluation, we compare evaluation with Alexnet to a proposed deep learning evaluation model. We were compared a proposed model with test data and extend test data. The result, we were confirmed that the proposed model had high performance than Alexnet which approximately 48% and 72% such as test data, approximately 62% and 81% such as extend test data."
딥러닝 신경망을 이용한 문자 및 단어 단위의 영문 차량 번호판 인식,2020,"['License Plate Recognition', 'Deep-learning Neural Network', 'Malaysia LPR']",,"Vehicle license plate recognition system is not generalized in Malaysia due to the loose character layout rule and the varying number of characters as well as the mixed capital English characters and italic English words. Because the italic English word is hard to segmentation, a separate method is required to recognize in Malaysian license plate. In this paper, we propose a mixed character level and word level English license plate recognition algorithm using deep learning neural networks. The difference of Gaussian method is used to segment character and word by generating a black and white image with emphasized character strokes and separated touching characters. The proposed deep learning neural networks are implemented on the LPR system at the gate of a building in Kuala-Lumpur for the collection of database and the evaluation of algorithm performance. The evaluation results show that the proposed Malaysian English LPR can be used in commercial market with 98.01% accuracy."
딥러닝을 이용한 광학적 프린지 패턴의 생성,2020,,,"In this paper, we discuss a data balancing method for learning a neural network that generates digital holograms using a deep neural network (DNN). Deep neural networks are based on deep learning (DL) technology and use a generative adversarial network (GAN) series. The fringe pattern, which is the basic unit of a hologram to be created through a deep neural network, has very different data types depending on the hologram plane and the position of the object. However, because the criteria for classifying the data are not clear, an imbalance in the training data may occur. The imbalance of learning data acts as a factor of instability in learning. Therefore, it presents a method for classifying and balancing data for which the classification criteria are not clear. And it shows that learning is stabilized through this."
딥러닝 기술을 활용한 차별 및 혐오 표현 탐지 : 어텐션 기반 다중 채널 CNN 모델링,2020,,,"Online defamation incidents such as Internet news comments on portal sites, SNS, and community sites are increasing in recent years. Bias and hate expressions threaten online service users in various forms, such as invasion of privacy and personal attacks, and defamation issues. In the past few years, academia and industry have been approaching in various ways to solve this problem The purpose of this study is to build a dataset and experiment with deep learning classification modeling for detecting various bias expressions as well as hate expressions. The dataset was annotated 7 labels that 10 personnel cross-checked. In this study, each of the 7 classes in a dataset of about 137,111 Korean internet news comments is binary classified and analyzed through deep learning techniques. The Proposed technique used in this study is multi-channel CNN model with attention. As a result of the experiment, the weighted average f1 score was 70.32% of performance."
딥러닝을 하드웨어 가속기를 위한 저전력 BSPE Core 구현,2020,"['Deep Learning', 'quantization', 'BSPE', 'LOA', 'Overlapping Computation']","본 논문에서 BSPE는 전력이 많이 소모되는 기존의 곱셈 알고리즘을 대체했다. Bit-serial Multiplier를 이용해 하드웨어 자원을 줄였으며, 메모리 사용량을 줄이기 위해 가변적인 정수 형태의 데이터를 사용한다. 또한, 부분 합을 더하는 MOA(MultiOperand Adder)에 LOA(Lower-part OR Approximation)를 적용해서 MOA의 자원 사용량 및 전력사용량을 줄였다. 따라서기존 MBS(Multiplication by Barrel Shifter)보다 하드웨어 자원과 전력이 각각 44%와 42%가 감소했다. 또한, BSPE Core를위한 hardware architecture design을 제안한다.","In this paper, BSPE replaced the existing multiplication algorithm that consumes a lot of power. Hardware resourcesare reduced by using a bit-serial multiplier, and variable integer data is used to reduce memory usage. In addition, MOAresource usage and power usage were reduced by applying LOA (Lower-part OR Approximation) to MOA (MultiOperand Adder) used to add partial sums. Therefore, compared to the existing MBS (Multiplication by Barrel Shifter),hardware resource reduction of 44% and power consumption of 42% were reduced. Also, we propose a hardwarearchitecture design for BSPE Core."
딥러닝 알고리즘을 이용한 토마토에서 발생하는 여러가지 병해충의 탐지와 식별에 대한 웹응용 플렛폼의 구축,2020,"['Agricultural Tomato Images', 'Plant Diseases and Pests', 'Deep Learning Algorithm', 'Faster R-CNN', 'Convolution Neural Network', 'Web Application Platform']",,"Purpose: purpose of this study was to propose the web application platform which can be to detect and discriminate various diseases and pest of tomato plant based on the large amount of disease image data observed in the facility or the open field.Methods: The deep learning algorithms uesed at the web applivation platform are consisted as the combining form of Faster R-CNN with the pre-trained convolution neural network (CNN) models such as SSD_mobilenet v1, Inception v2, Resnet50 and Resnet101 models. To evaluate the superiority of the newly proposed web application platform, we collected 850 images of four diseases such as Bacterial cankers, Late blight, Leaf miners, and Powdery mildew that occur the most frequent in tomato plants. Of these, 750 were used to learn the algorithm, and the remaining 100 images were used to evaluate the algorithm.Results: From the experiments, the deep learning algorithm combining Faster R-CNN with SSD_mobilnet v1, Inception v2, Resnet50, and Restnet101 showed detection accuracy of 31.0%, 87.7%, 84.4%, and 90.8% respectively. Finally, we constructed a web application platform that can detect and discriminate various tomato deseases using best deep learning algorithm. If farmers uploaded image captured by their digital cameras such as smart phone camera or DSLR (Digital Single Lens Reflex) camera, then they can receive an information for detection, identification and disease control about captured tomato disease through the proposed web application platform.Conclusion: Incheon Port needs to act actively paying"
딥러닝을 활용한 영상기반 교통사고 예방 안전시스템,2020,"['Accident prevention system', 'Deep learning', 'Depth Camera', 'Lanes', 'Pedestrians', 'YOLOv2-tiny']",,
딥러닝 기반 치과 의료영상 판독에 대한 문헌 분석,2020,"['Dentistry', 'Dental disease', 'Artificial intelligence', 'Convolutional neural network', 'Object detection', 'Segmentation']",,"This study analyzes the papers, which studied to find the most adequate CNN based algorithms for segmentation, object detection in dentistry. According to our purpose, we created several keywords like “Dental+Object Detection+Neural+Network.” We searched articles in ‘PubMed’, ‘IEEE’, using created 34 keywords. We found 458 papers and excluded under a study-purpose provision. So This paper had categorized those 23 papers by 11 of segmentation of tooth structure with dental filling and FDI numbering, 12 of detecting dental caries, periodontitis, or multiple lesions. To compare the performance of models, we organized the results by DICE/IoU index and accuracy, precision, recall, etc.. Various dataset was used for analyzing. The most common dataset was dental panoramic image, then periapical, CBCT, NILT, and intra-oral image. The algorithms were used according to the purpose. For example, VGG16, 19 was used for object detection algorithms were used according to the purpose. For example, VGG16, 19 was used for object detection, U-Net, and Mask R-CNN used for segmentation by study purpose.For segmentation of teeth, Zhimming Cui(2019), used Mask R-CNN, and the accuracy was 0.9755. Vranck(2020) used ResNet for molar detection(IoU 0.9, precision 0.94, 0.93). To label the tooth numbering according to FDI rule, Tuzoff(2019) and Chen(2019), used Faster R-CNN, VGG16, and Faster R-CNN with DNN. Tuzoff’s index was slightly better than Chen’s. Casalegno(2019) investigated the detection of dental caries by using VGG16. The result was IoU 0.727. To find periodontitis, used VGG16 also, by Prajapaty(2017). And the accuracy was 0.8846. Using the Mask R-CNN, Jader(2018) could separate instances of multiple lesions, accuracy was 0.8846."
딥러닝 및 참고 이미지를 이용한 항공사진 누락오류탐지 및 영역 복원,2020,"['공간정보', '항공사진', '누락오류', '인페인팅', '부분 합성 곱', 'Spatial Information', 'Aerial Photography', 'Missing Error', 'Inpainting', 'Partial Convolution']","최근 공간정보 수집 환경 및 활용 도메인 다양화에 따라 공간정보의 중요성은 커지고 있다. 그중 항공사진은 공간정보 중에서 다양한 수요처에 사용되는데, 가시화 기반자료로 시뮬레이션과 3차원 공간정보 오픈 플랫폼 서비스에 사용될 뿐만 아니라 연구기반자료로 객체 검출 및 식생, 환경 조사에 사용된다. 하지만 항공사진은 수집과정 및 서비스 전처리 단계에 데이터 품질이 고르지 못한 문제가 있고, 이를 분석 및 재수집하기엔 많은 양의 데이터, 시간, 지역과 비용 문제 때문에 제한요소가 많다. 이런 문제점을 해결하고자 본 연구에선 합성 곱 신경 네트워크 모델을 이용해 항공사진에 나타날 수 있는 누락오류를 탐지하고, 누락오류가 있는 항공사진과 관련된 참고 이미지와 부분 합성 곱 기법을 이용하여 누락오류 영역을 복원하는 수행하는 시스템을 제작했다. 제작된 시스템의 에러 탐지 및 분류는 90.41% 정확도를 보였다. 다양한 에러 유형에 대한 복원은 유-네트워크, 가변 오토인코더 복원 결과와 비교하였고 사각형 누락 에러 유형에 좋은 복구 성능을 보였다.","Recently, the importance of spatial information has been increasing due to the diversification of spatial information collection and utilization. Among them, aerial photography is used in various sources of demand among spatial data, which is used as a simulation, 3D spatial information open platform, a research infrastructure. However, aerial photography has problems with uneven data quality during the collection process and preprocessing of services, and there are many limitations to analyzing and re-collecting them due to large amounts of data, time, area and cost issues. To solve this problem, we present a system that detects missing parts in the aerial photographs using convolution neural network models and performs inpainting using Partial Convolution. Error detection and classification of this systems showed 90.41% accuracy. Restores for various error types were compared with U-Net and Variable Auto Encoder recovery results and showed good recovery performance for square missing error types."
딥러닝 기반 토마토 병충해 분류 시스템 연구,2020,"['Deep learning', 'Inception V3', 'Plant disease', 'Tomato']",,"The early detection of plant disease is important in that it enhances the quality and productivity of crops. A large amount of research has considered machine learning classifiers to protect tomato plants from diseases, but the reliability of early disease diagnoses in this way remains uncertain due to the use of small datasets. Therefore, to enhance the dependability of them, this study examined a tomato disease classification system based on a deep learning using a dataset containing 17,063 images of tomato leaves infected with eight diseases. The deep learning model used in this classifier consisted of symmetric and asymmetric building blocks including convolutions, average pooling, max pooling, concats, dropouts, and fully connected layers. The obtained result indicated a high degree of accuracy (98.9%) which is high enough to be used as a proper diagnosis tool for farmers who lack professional knowledge of tomato diseases."
딥러닝을 활용한 실내 식물 이미지 분류 및 식물 정보 제공 웹 어플리케이션,2020,"['Indoor plant information', 'Deep learning', 'Transfer learning', 'ResNet', 'Fast.ai']",,"Plants have good effects such as air purification and landscaping, but they have special ingredients to protect themselves. Ingredients made to protect the plant itself can harm people or animals. There are also accidents that are mistaken for other plants with similar plant features. We have implemented a program that can identify plants and display information about each plant. Using deep learning to classify images, we created a web application that predicts plant names and displays information that matches the predicted plants. We created a data set of 61 indoor plants using Google Image Search. The positive effects and negative toxicity of indoor plants are summarized in the database. Deep learning is implemented using fast.ai, a Pytorch-based framework. Through data Augmentation, we increased the number of images to learn. Indoor plant image data were trained using ResNet50, a pretrained model using various images. The accuracy of the model was about 97.5%, which predicted most plants accurately. The web application was implemented using flask, a Python-based web framework. Using the implemented image classification deep learning model, the plant name is predicted and the information corresponding to the predicted plant name is displayed on the web page. The web application can be optimized for mobile devices and used conveniently."
딥러닝을 이용한 시각적 의류 분석 기술: 서베이,2020,"['Visual Fashion Analysis', 'Deep-learning', 'Fashion Recognition', 'Fashion Retrieval']",,
딥러닝을 활용한 다국적 군함 탐지 및 분류모형 연구,2020,"['Object detection', 'Detection of warships', 'Deep learning', 'Classification of nationality of warships', 'EOTS', 'YOLO v4']",,"This study uses object detection of deep learning to make models that detect warships in the video equipment (EOTS) of warships and classify nationalities. When you encounter warships from other countries during an operation at sea, the nationality is verified through a communication or visually, and thus a method of performing this through deep learning is suggested. The warships that are the subject of the study are more than 500 tons of surface warships operated in five countries, Korea, the United States, Japan, China, and Russia, and a total of 3,433 images were collected for use in the study. In addition, for research that can be used in an actual environment, a black and white image was input based on the specifications of the EOTS mounted on a warship, and a study was conducted to detect the warship and to classify the nationality of them. In particular, 10,299 images, which are three times the amount of the original image, were created through pre-processing of images such as blurring and noise addition, consid- ering that images entered into EOTS vary depending on weather conditions such as clear, fog, and rain.YOLO v4 was used as an algorithm to make a model, and four models were trained while changing the size of the input image. The model was evaluated with the IoU and mAP and found to have an average performance of 82.04% of the IoU and 98.43% of the mAP."
딥러닝 기반 적외선 영상내 전력선 유무 검출 방법,2020,"['infrared image', 'power line existence recognition']",,
딥러닝을 이용한 소리 분류 시 방해음의 영향 분석,2020,"['Environmental sound classification', 'Noise', 'CNN', 'VGG16', 'UrbanSound8K', 'Signal to noise ratio']",,"Environmental sound classification is an area that automatically classifies sounds in our surroundings. It can be applied to home automation, security, and surveillance. Recently, the deep learning approaches have been adopted as a classifier for increasing performance. In this method, a deep neural network is trained using many sound data, and after the learning is completed, the microphone pickup sound is applied for classification. However, during this stage, the ambient noise can be put into the microphone along with the sound to be identified. And the sound cannot be properly classified due to this disturbing noise. The recognition rate of the deep neural network decreases as the loudness of the disturbing sound increases, but the analysis about the noise effect on the classification have been limited. In this paper, we present the effect of the disturbing noise on the classification rate. For this purpose, UrbanSound8K, which is composed of 10 types of urban environmental sounds, is used for training and test data. And the VGG16-based CNN which shows good performance in image classification was adopted as a baseline model. For the disturbing noise, we use three types of sounds that are consist of daily noises (hairdryer, vacuum cleaner, faucet water, and hammer), voices(male, female, and synthesized sound), and music(cello, piano, and trumpet). In the experiment, these disturbing noises are mixed with the clean sounds so that the signal-to-noise ratio is in the range of -50dB to 50dB. Then the mixed sound was applied to a deep neural network to obtain a relative recognition rate when compared to the clean cases. The results show that the recognition rate is more than 90% compared to the clean sound cases when the SNR is between 10 and 15 dB, and 95% or more when the SNR is greater than 20 dB, regardless of the type of the disturbing sound."
규칙기반과 딥러닝을 동시에 활용한 앙상블 회전체 이상진단,2020,"['Ensemble(앙상블)', 'Rule-based(규칙기반)', 'Deep Learning(심층 학습)', 'CNN(합성곱 신경망)', 'Orbit Detection(궤도 추적)', 'Rotating Machine(회전체)', 'Machine Diagnostics(기계 진단)']",,"Unlike the major equipment used in power plants, auxiliary equipment usually does not possess a real-time system to analyze the machine condition. Therefore, detecting the fault of such auxiliary equipment in advance is difficult. Thus, the diagnosis of auxiliary equipment at a less cost is important for minimizing the downtime due to the fault of the equipment. In this paper, we introduce a diagnosis method for auxiliary equipment in power plants using rule-based and deep-learning algorithms. First, we calculate the probability of cause of a fault from current symptoms by using the rule-based algorithm. The rule used in this algorithm is established based on expert experience. We then conduct orbit detection using a convolution neural network. This algorithm self-learns the filter to classify orbit images as normal, rubbing, and unbalanced. The weakness of the deep-learning algorithm can be compensated by combining the results of the aforementioned methods."
코퍼스와 딥러닝 언어 모델을 활용한 문장 처리의 예측성과 행동 반응 시간과의 관계 연구,2020,"['predictabililty', 'surprisal', 'corpus-based language model', 'deep-learning-based language model']",,"This study examined whether the predictability is associated with the behavioral reaction times in sentence processing. The information complexity measures have been proposed to quantify the predictability for word-by-word human sentence processing. The most traditional information complexity measure is known as surprisal, which calculates relative unexpectedness at each word in a sentence (Hale 2001, Levy 2005, 2008). The most traditional information complexity measure is known as surprisal, which calculates relative unexpectedness at each word in a sentence (Hale 2001, Levy 2005, 2008), and some studies suggested that surprisal and reading times are positively correlated (Monsalve, Frank and Vigliocco 2012, Smith and Levy 2013). In order to calculate surprisal, the previous studies used one of two ways: Corpus based language models and deep learning based language models. This study, however, used both of them to analyze human reading times, comparing surprisal calculated from corpus-based language models with that calculated from deep-learning-based language models. Many studies partially investigated either of them. In this study, human reading times were analyzed by comparing surprisal calculated from corpus-based language models with that calculated from deep-learning-based language models. The results showed that surprisal calculated from corpus-based language models is more suitable to explain the behavioral reaction time data. Although the deep learning technology performs very well in the field of natural language processing, it does not seem to be human-like processing. Nonetheless, this study can contribute to the development of deep learning technology as well as computational psycholinguistic research in that it tried to compare the outcomes of corpus and deep learning technology with human behavioral responses."
CNN기반 딥러닝을 이용한 Kuzushiji-MNIST/49 분류의 정확도 향상을 위한 학습 방안,2020,,,"In this paper, we propose a deep learning training method for accurately classifying Kuzushiji-MNIST and Kuzushiji-49 datasets for ancient and medieval Japanese characters. We analyze the latest convolutional neural network networks through experiments to select the most suitable network, and then use the networks to select the number of training to classify Kuzushiji-MNIST and Kuzushiji-49 datasets. In addition, the training is conducted with high accuracy by applying learning methods such as Mixup and Random Erase. As a result of the training, the accuracy of the proposed method can be shown to be high by 99.75% for MNIST, 99.07% for Kuzushiji-MNIST, and 97.56% for Kuzushiji-49. Through this deep learning-based technology, it is thought to provide a good research base for various researchers who study East Asian and Western history, literature, and culture."
자율주행을 위한 딥러닝 기반의 차선 검출 방법에 관한 연구,2020,"['Deep learning', 'Faster R-CNN', 'Machine learning', 'Support vector machine', 'Unmanned vehicle']",,"This study used the Deep Learning models used in previous studies, we selected the basic model. The selected model was selected as ZFNet among ZFNet, Googlenet and ResNet, and the object was detected using a ZFNet based FRCNN. In order to reduce the detection error rate of FRCNN, location of four types of objects detected inside the image was designed by SVM classifier and location-based filtering was applied. As simulation results, it showed similar performance to the lane marking classification method with conventional 경계 detection, with an average accuracy of about 88.8%. In addition, studies using the Linear-parabolic Model showed a processing speed of 165.65ms with a minimum resolution of 600 × 800, but in this study, the resolution was treated at about 33ms with an input resolution image of 1280 × 960, so it was possible to classify lane marking at a faster rate than the previous study by CNN-based End to End method."
CNN 기반 딥러닝을 이용한 임베디드 리눅스 양각 문자 인식 시스템 구현,2020,"['Artificial Intelligence', 'Embedded Linux', 'Deep learning', 'CNN Algorithm', 'TensorFlow', 'Keras']",,"Over the past several years, deep learning has been widely used for feature extraction in image and video for various applications such as object classification and facial recognition. This paper introduces an implantation of embedded Linux system for embossed digits recognition using CNN based deep learning methods. For this purpose, we implemented a coin recognition system based on deep learning with the Keras open source library on Raspberry PI. The performance evaluation has been made with the success rate of coin classification using the images captured with ultra-wide angle camera on Raspberry PI. The simulation result shows 98% of the success rate on average."
자율주행 환경에서 딥러닝 기법의 객체검출과 속도 성능 최적화,2020,"['Autonomous Driving', 'Object Detection', 'Deep Learning Model Optimization']",,
카메라 영상과 딥러닝을 이용한 의수로봇 제어 시스템과 파지대상 선정,2020,"['robotic prosthetic hand', 'grasping', 'deep learning', 'object detection', 'robot control', 'vision']",,"Robotic prosthetic hands are a device that helps to improve the quality of life for patients without hands. Recently, robotic prosthetic hands can perform various grasping patterns because of improvement of bioengineering and robotics. The research that automatically selects the appropriate operation according to the situation is important. Many previous studies have used EMG signals. However, EMG signals are difficult to generalize because EMG signals vary depending on the position of the muscle. In this study, we developed a system for controlling robotic prosthetic hands using images and deep learning to facilitate generalization. We also proposed a method for selecting a grasping target to be held in the image. These results will help to improve the quality of life of the robotic prosthetic hand user."
엣지 디바이스에서의 딥러닝 기반 차량 인식 및 속도 추정을 통한 스마트 횡단보도 시스템의 설계 및 구현,2020,,,"Recently, the number of traffic accidents has also increased with the increase in the penetration rate of cars in Korea. In particular, not only inter-vehicle accidents but also human accidents near crosswalks are increasing, so that more attention to traffic safety around crosswalks are required. In this paper, we propose a system for predicting the safety level around the crosswalk by recognizing an approaching vehicle and estimating the speed of the vehicle using NVIDIA Jetson Nano-class edge devices. To this end, various machine learning models are trained with the information obtained from deep learning-based vehicle detection to predict the degree of risk according to the speed of an approaching vehicle. Finally, based on experiments using actual driving images and web simulation, the performance and the feasibility of the proposed system are validated."
상부위장관 질환의 딥러닝 적용,2020,"['Artificial intelligence', 'Neural networks', 'computer', 'Deep learning', 'Gastroenterology', 'Endoscopy']",,"Artificial intelligence using deep learning has been applied to gastrointestinal disorders for the detection, classification, and delin­eation of various lesion images. With the accumulation of enormous medical records, the evolution of computation power with graphic processing units, and the widespread use of open-source libraries in large-scale machine learning processes, medical artificial intelligence is overcoming its traditional limitations. This paper explains the basic concepts of deep learning model estab­lishment and summarizes previous studies on upper gastrointestinal disorders. The limitations and perspectives on future devel­opment are also discussed."
CSI를 활용한 딥러닝 기반의 실내 사람 수 추정 기법,2020,,,"People estimation is important to provide IoT services. Most people counting technologies use camera or sensor data. However, the conventional technologies have the disadvantages of invasion of privacy and the need to install extra infrastructure. This paper proposes a method for estimating the number of people using a Wi-Fi AP. We use channel state information of Wi-Fi and analyze that using deep learning technology. It can be achieved by pre-installed Wi-Fi infrastructure that reduce cost for people estimation and privacy infringement. The proposed algorithm uses a k-binding data for pre-processing process and a 1D-CNN learning model. Two APs were installed to analyze the estimation results of six people. The result of the accurate number estimation was 64.8%, but the result of classifying the number of people into classes showed a high result of 84.5%. This algorithm is expected to be applicable to estimate the density of people in a small space."
시각장애인을 위한 딥러닝과 이미지인식을 이용한 스마트 옷장,2020,"['Smart appliance', 'CNN', 'Keras', 'Blind', 'Image Recognition', 'Deep learning']","시각장애인의 대다수는 독립적인 의생활을 하는데 어려움을 겪는다. 최근 스마트 가전 시장의 성장으로 가구나 가전에 인공지능이나 IoT를 추가하는 제품이 늘어나고 있다. 본 논문에서는 시각장애인의 독립적인 의생활을 지원하기 위해 옷장 내부를 관리하는 기능, 음성 대화를 통해 정보를 요청하는 음성인식 기능 그리고 CNN 알고리즘을 이용한 옷 정보에 대한 인식 기능을 가진 스마트 옷장을 제안한다. 본 논문에서는 옷을 인식하는 과정에서 정확도를 높이기 위해 모델의 층 개수를 변경하고 Maxpooling을 조정하여 모델을 생성하였다. 모델 생성 시 Early Stopping Callback 옵션을 적용하여 학습 정확도를 보장해주었다. 과적합을 방지해주기 위하여 Dropout을 추가했다. 이러한 과정으로 만 들어진 최종 모델은 옷 인식 정확도가 80%가 되는 것을 확인할 수 있다.","The blind people have difficulty living an independent clothing life. The furniture and home appliance are adding AI or IoT with the recent growth of the smart appliance market. To support the independent clothing life of the blind, this paper suggests a smart wardrobe with closet control function, voice recognition function and clothes information recognition using CNN algorithm. The number of layers of the model was changed and Maxpooling was adjusted to create the model to increase accuracy in the process of recognizing clothes. Early Stopping Callback option is applied to ensure learning accuracy when creating a model. We added Dropout to prevent overfitting. The final model created by this process can be found to have 80 percent accuracy in clothing recognition."
비전 센서 및 딥러닝 기반 선박 접안을 위한 어라운드뷰 모니터링 시스템,2020,"['Around view monitoring', 'Deep learning', 'Docking assist system', 'Ship berthing aid system', 'Vision sensor']",,"This paper proposes vision sensors and deep learning-based around view monitoring system for ship berthing. Ship berthing to the port requires precise relative position and relative speed information between the mooring facility and the ship. For ships of Handysize or higher, the vesselships must be docked with the help of pilots and tugboats. In the case of ships handling dangerous cargo, tug boats push the ship and dock it in the port, using the distance and velocity information receiving from the berthing aid system (BAS). However, the existing BAS is very expensive and there is a limit on the size of the vessel that can be measured. Also, there is a limitation that it is difficult to measure distance and speed when there are obstacles near the port. This paper proposes a relative distance and speed estimation system that can be used as a ship berthing assist system. The proposed system is verified by comparing the performance with the existing laser-based distance and speed measurement system through the field tests at the actual port."
IEEE 802.11ac 변조 방식의 딥러닝 기반 분류,2020,"['IEEE 802.11ac', 'Deep Learning', 'Modulation Classification', 'Decoding']",,"This paper is focused on the modulation scheme detection of the IEEE 802.11 standard. In the IEEE 802.11ac standard, the information of the modulation scheme is indicated by the modulation coding scheme (MCS) included in the VHT-SIG-A of the preamble field. Transmitting end determines the MCS index suitable for the low signal to noise ratio (SNR) situation and transmits the data accordingly. Since data field decoding can take place only when the receiving end acquires the MCS index information of the frame. Therefore, accurate MCS detection must be guaranteed before data field decoding. However, since the MCS index information is the information obtained through preamble field decoding, the detection rate can be affected significantly in a low SNR situation. In this paper, we propose a relatively robust modulation classification method based on deep learning to solve the low detection rate problem with a conventional method caused by a low SNR."
보행자 자세 정보를 활용한 딥러닝 기반 보행자 궤적 추적 프레임워크,2020,"['Body posture', 'Deep learning model', 'Moving trajectory', 'OpenPose', 'Pedestrian tracking', 'Tracking error']",,"This paper presents a deep learning based (human) pedestrian position tracking methodology from a video. In a manufacturing shop floor, the moving trajectories of pedestrians can be utilized for various applications, such as layout optimization of facilities, and material flow analysis. To improve the accuracy of the proposed human tracking method, we make use of the body posture information of workers. The body posture information is extracted by using the ‘Open- Pose’ library which represents the first real-time multi-person system to jointly detect human body, hand, facial, and foot key points on single images. The proposed methodology consists of four major steps; 1) Pedestrian recognition from a video, 2) Pedestrian tracking by using the posture information, 3) correction of potential tracking errors, and 4) finding the moving trajectories of pedestrians. The proposed methodology has been implemented and test with various examples."
다중 분광영상을 이용한 딥러닝 기반 소나무 재선충 피해목 탐색,2020,"['pine wilt disease', 'unmanned aviation vehicle', 'multispectral ortho-image', 'deep learning-based classifier', 'heat map']",,
다중 모달 생체신호를 이용한 딥러닝 기반 감정 분류,2020,"['Bio-signal', 'Deep Learning', 'Emotion']",,"Negative emotion causes stress and lack of attention concentration. The classification of negative emotion is important to recognize risk factors. To classify emotion status, various methods such as questionnaires and interview are used and it could be changed by personal thinking. To solve the problem, we acquire multi modal bio-signals such as electrocardiogram (ECG), skin temperature (ST), galvanic skin response (GSR) and extract features. The neural network (NN), the deep neural network (DNN), and the deep belief network (DBN) is designed using the multi modal bio-signals to analyze emotion status. As a result, the DBN based on features extracted from ECG, ST and GSR shows the highest accuracy (93.8%). It is 5.7% higher than compared to the NN and 1.4% higher than compared to the DNN. It shows 12.2% higher accuracy than using only single bio-signal (GSR). The multi modal bio-signal acquisition and the deep learning classifier play an important role to classify emotion."
악성코드의 이미지 기반 딥러닝을 위한 전처리 방법 설계 및 개발,2020,"['Deep Learning', 'Visualization', 'Data pre-processing', 'Malware', 'Classification']",,"The rapid growth of internet users and faster network speed are driving the new ICT services. ICT Technology has improved our way of thinking and style of life, but it has created security problems such as malware, ransomware, and so on. Therefore, we should research against the increase of malware and the emergence of malicious code. For this, it is necessary to accurately and quickly detect and classify malware family. In this paper, we analyzed and classified visualization technology, which is a preprocessing technology used for deep learning-based malware classification. The first method is to convert each byte into one pixel of the image to produce a grayscale image. The second method is to convert 2bytes of the binary to create a pair of coordinates. The third method is the method using LSH. We proposed improving the technique of using the entire existing malicious code file for visualization, extracting only the areas where important information is expected to exist and then visualizing it. As a result of experimenting in the method we proposed, it shows that selecting and visualizing important information and then classifying it, rather than containing all the information in malicious code, can produce better learning results."
VR/AR 환경의 협업 딥러닝을 적용한 맞춤형 조종사 훈련 플랫폼,2020,"['Customized Platform', 'Pilot Training', 'Deep Learning', 'Recommendation']",,"Aviation ICT technology is a convergence technology between aviation and electronics, and has a wide variety of applications, including navigation and education. Among them, in the field of aerial pilot training, there are many problems such as the possibility of accidents during training and the lack of coping skills for various situations. This raises the need for a simulated pilot training system similar to actual training. In this paper, pilot training data were collected in pilot training system using VR/AR to increase immersion in flight training, and Customized Pilot Training Platform with Collaborative Deep Learning in VR/AR Environment that can recommend effective training courses to pilots is proposed.To verify the accuracy of the recommendation, the performance of the proposed collaborative deep learning algorithm with the existing recommendation algorithm was evaluated, and the flight test score was measured based on the pilot's training data base, and the deviations of each result were compared. The proposed service platform can expect more reliable recommendation results than previous studies, and the user survey for verification showed high satisfaction"
컬러 자궁경부 영상에서 딥러닝 기법에서의 영상영역 처리 방법에 따른 성능 비교 연구,2020,"['Artificial Intelligence', 'Deep Learning', 'Image Processing', 'Cervix Cancer', 'Classification']",,"Cervical cancer is the second most common female cancer in the world. In Korea, cervical cancer accounts for 13 percent of female cancers and 4,200 cases occur annually[1]. The purpose of this study is to use a deep learning model to identify the possibility of lesions in the cervix and to evaluate the efficient image preprocessing in order to diagnose diverse types of cervix in form. The study used 4,107 normal photographs of uterine cervix and 6,285 abnormal photographs of uterine cervix. Two types of image preprocessing were resized to square. The methods are cropping based on height and filling the space up and down with black images. In addition, all images were resampled to 256×256. The average accuracy of cropped cases is 94.15%. The average accuracy of the filled cases is 93.41%. According to the study, the model performance of cropped data was slightly better. But there were several images that were not accurately classified. Therefore, the additional experiment with pre-treatment process based on cropping is needed to cover images of the cervix in more detail."
RSU 통신 및 딥러닝 기반 최적화 차량 라우팅 시스템 설계,2020,"['Autonomous vehicles', 'driving directions', 'deep neural networks', 'road side units', 'road information']","현재 자율주행 차량 시장은 3레벨 자율주행 차량의 상용화를 넘어 4레벨 자율주행 차량을 연구, 개발하고 있다. 4레벨 자율주행 차량에서 가장 주목되는 부분은 차량의 안정성이다. 3레벨과 다르게 4레벨의 자율주행 차량은 긴급상황을 차량이 직접 대처해야 하기 때문이다. 본 논문에서는 긴급상황에서의 즉각적인 반응보다는 차량의 목적지가 정해진 순간 사고 가능성이 가장 낮은 경로를 결정하는 Optimized Vehicle Routing System (OVRS)을 제안한다. OVRS는 RSU 통신으로 수집한 도로와 주변 차량 정보를 분석하여 도로의 위험성을 예측하여 주행 중인 차량이 더 안전하고 빠른 길로 주행할 수 있도록 경로를 설정한다. OVRS는 네트워크 라우팅 방식처럼 도로에 있는 RSU를 통하여 도로 상황에 따른 경로 안내를 실행하기 때문에 차량의 안정성을 더욱 높일 수 있다. 실험 결과, OVRS모듈 중 하나인 ASICM의 RPNN은 CNN보다 약 17%, LSTM보다 약 40% 더 좋은 연산 시간을 보였다. 그러나 해당 연구가 PC를 이용한 가상환경에서 실행되었기 때문에, VPDM의 사고 가능성을 실제로 검증하지 못했다. 따라서 향후 사고 데이터 수집으로 인한 VPDM의 정확도 높은 실험과 실제 차량 및 RSU에서 실제 도로를 대상으로 한 실험이 진행되어야 한다.","Currently, The autonomous vehicle market is researching and developing four-level autonomous vehicles beyond the commercialization of three-level autonomous vehicles. Because unlike the level 3, the level 4 autonomous vehicle has to deal with an emergency directly, the most important aspect of a four-level autonomous vehicle is its stability. In this paper, we propose an Optimized Vehicle Routing System (OVRS) that determines the route with the lowest probability of an accident at the destination of the vehicle rather than an immediate response in an emergency. The OVRS analyzes road and surrounding vehicle information collected by The RSU communication to predict road hazards, and sets the route for the safer and faster road. The OVRS can improve the stability of the vehicle by executing the route guidance according to the road situation through the RSU on the road like the network routing method. As a result, the RPNN of the ASICM, one of the OVRS modules, was about 17% better than the CNN and 40% better than the LSTM. However, because the study was conducted in a virtual environment using a PC, the possibility of accident of the VPDM was not actually verified. Therefore, in the future, experiments with high accuracy on VPDM due to the collection of accident data and actual roads should be conducted in real vehicles and RSUs."
UAV환경에서 스테레오 비전을 활용한 딥러닝 기반 시차맵 추정,2020,"['Stereo vision', 'UAV', 'Semi-supervised learning', 'Disparity map', 'Obstacle detection']",,"Recently, UAVs(Unmanned Aerial Vehicles) are used in various industries such as military, transportation, agriculture and reconnaissance. However, it is very likely to cause an accident such as a collision or fall, due to external environmental factors, and research is needed to increase safety. To prevent such risks, UAVs are often equipped with sensors such as laser scanners or cameras. But laser scanners are very heavy and consume high power. Stereo cameras are much lighter and use less power than laser scanners, making them ideal for use in small UAV environments. Therefore, in this paper, we introduce a method for estimating the disparity map using a stereo camera and deep learning without using a LiDAR(Lighting Detection And Ranging). The proposed method constructs semi-supervision based neural network to estimate disparity maps. This algorithm can estimate more precise disparity maps than existing matching algorithms."
열처리 장비의 Safety를 위한 딥러닝 기반 영상처리 시스템,2020,"['Iot Middle Ware', 'Ppuri Industry', 'Deep Learning', 'Thermal', 'Heat Treatment', 'Object Detecting']",열처리 시설은 뿌리산업 중에서 고열에 의한 열악한 환경과 긴 근로시간 등으로 원격 IOT 시스템의 적용 범위가 확대되는 상황이다. 이러한 열처리 공정 환경에서 IOT 미들웨어는 사물인터넷 기기(센서 등)의 데이터 정보를 해석하고 관리하며 제어할 수 있는 중추적 역할이 요구된다. 그간 열처리 원격에서 제어하는 시스템은 현장 상황에 대한 전반적 감시 없이 작업자의 일괄 시스템 명령으로 운영되었다. 하지만 열처리 시설의 안전성과 정밀한 제어를 위해서는 다양한 센서 컨트롤과 주변 작업환경 인지가 필요하다. 본 논문에서 제시한 열처리 안전지원 시스템은 그에 대한 해결책으로 열화상 감지를 통해 열처리로의 작업인력 접근을 파악하고 원격에서 작업 가동 시 열처리 장비의 Safety를 위한 지원시 스템을 제안하였다. 또한 일반적인 고정된 열점 감시 기반 열화상 분석보다 더욱 빠르고 정확한 인식을 위해 DNN 딥러 닝 네트워크를 활용한 OPEN CV 기반 열화상 분석 시스템을 구성하였다. 이를 통해 열처리 산업에 특성화된 안전관리 지원과 향후 열처리 환경에서 범용적으로 활용 할 수 있는 시스템을 제안하고자 한다.,"The heat treatment facility is in a situation where the scope of application of the remote IOT system is expanding due to the harsh environment caused by high heat and long working hours among the root industries. In this heat treatment process environment, the IOT middleware is required to play a pivotal role in interpreting, managing and controlling data information of IoT devices (sensors, etc.). Until now, the system controlled by the heat treatment remotely was operated with the command of the operator's batch system without overall monitoring of the site situation. However, for the safety and precise control of the heat treatment facility, it is necessary to control various sensors and recognize the surrounding work environment. As a solution to this, the heat treatment safety support system presented in this paper proposes a support system that can detect the access of the work manpower to the heat treatment furnace through thermal image detection and operate safely when ordering work from a remote location. In addition, an OPEN CV-based deterioration analysis system using DNN deep learning network was constructed for faster and more accurate recognition than general fixed hot spot monitoring-based thermal image analysis. Through this, we would like to propose a system that can be used universally in the heat treatment environment and support the safety management specialized in the heat treatment industry."
영상 정보 분야의 딥러닝 기반 적대적 공격과 방어 기술 동향 분석 및 국방 분야 적용 방안,2020,"['Deep Learning', 'Computer Vision', 'Adversarial Attack and Defense', 'Surveillance and Reconnaissance System', 'Mosaic Warfare']",,"Recently, the development of information technology using artificial intelligence and deep learning has become deeply involved in our lives. Therefore, many attempts have been made to incorporate deep learning technology to handle high-quality information in real-time detection of military systems where decision-makings and value judgments are crucial. At the same time, the vulnerability to adversarial attacks that induces deep learning models to make wrong decisions has been exposed. In this study, we classify and analyze the cutting-edge technology of adversarial attack and defense targeting the deep learning in the surveillance and reconnaissance system. Through this study, we identify the significance, major issues and recent trends of ongoing research and development. Consequences of the research will promote and activate new research which can prevent all other potential threats to defense industry, including computer security, voice, and text domain inspired by the adversarial attacks and defenses in the computer vision. Finally, we suggest the application of the analyzed adversarial attack and defense strategies as a customized defense strategy that creatively connects and combines them according to the situations in the sense of Mosaic Warfare."
배 과수원 대상 딥러닝 기반 지능형 방제 시스템: 예비실험 결과,2020,"['agricultural robot', 'deep learning', 'orchard', 'intelligent spraying', '.']",,.
암호화폐 가격 예측을 위한 딥러닝 앙상블 모델링 : Deep 4-LSTM Ensemble Model,2020,"['Deep Learning', 'Ensemble Modeling', 'Cryptocurrency', 'Design Science', 'Price Prediction']",,"As the blockchain technology attracts attention, interest in cryptocurrency that is received as a reward is also increasing. Currently, investments and transactions are continuing with the expectation and increasing value of cryptocurrency. Accordingly, prediction for cryptocurrency price has been attempted through artificial intelligence technology and social sentiment analysis. The purpose of this paper is to develop a deep learning ensemble model for predicting the price fluctuations and one-day lag price of cryptocurrency based on the design science research method. This paper intends to perform predictive modeling on Ethereum among cryptocurrencies to make predictions more efficiently and accurately than existing models. Therefore, it collects data for five years related to Ethereum price and performs pre-processing through customized functions. In the model development stage, four LSTM models, which are efficient for time series data processing, are utilized to build an ensemble model with the optimal combination of hyperparameters found in the experimental process. Then, based on the performance evaluation scale, the superiority of the model is evaluated through comparison with other deep learning models. The results of this paper have a practical contribution that can be used as a model that shows high performance and predictive rate for cryptocurrency price prediction and price fluctuations. Besides, it shows academic contribution in that it improves the quality of research by following scientific design research procedures that solve scientific problems and create and evaluate new and innovative products in the field of information systems"
결함 검출을 위한 임베디드 딥러닝 시스템,2020,"['Defects detection', 'Convolutional neural network', 'Network Reduction', 'Embedded System', 'YOLOv2', 'YOLOv3', 'YOLOv2-tiny']",,"A machine vision based industrial inspection requires little computation time and localizing defects robustly with high accuracy. Recent mobile and embedded systems require computationally efficient machine intelligence with a deep learning model. In order to improve detection performance and processing time, various network modification methods are proposed. The experiments for defect detection on the metal surfaces data are executed using the various YOLO networks on embedded GPU system Nvidia Tx-1. The results for detection performance and inspection time are compared and analysed. Among them, modified YOLOv2-tiny model shows a better performance in both detection rate and fps."
합성곱 신경망을 이용한 딥러닝 기반의 프레임 동기 기법,2020,['2'],,"This paper proposes a new frame synchronization technique based on convolutional neural network (CNN). The conventional frame synchronizers usually find the matching instance through correlation between the received signal and the preamble. The proposed method converts the 1-dimensional correlator ouput into a 2-dimensional matrix. The 2-dimensional matrix is input to a convolutional neural network, and the convolutional neural network finds the frame arrival time. Specifically, in additive white gaussian noise (AWGN) environments, the received signals are generated with random arrival times and they are used for training data of the CNN. Through computer simulation, the false detection probabilities in various signal-to-noise ratios are investigated and compared between the proposed CNN-based technique and the conventional one. According to the results, the proposed technique shows 2dB better performance than the conventional method."
위상 홀로그램을 위한 딥러닝 기반의 초고해상도,2020,"['hologram', 'deep learning', 'super resolution', 'convolutional neural network', 'image processing']",,"In this paper, we propose a method using deep learning for high-resolution display of phase holograms. If a general interpolation method is used, the brightness of the reconstruction result is lowered, and noise and afterimages occur. To solve this problem, a hologram was trained with a neural network structure that showed good performance in the single-image super resolution (SISR). As a result, it was possible to improve the problem that occurred in the reconstruction result and increase the resolution. In addition, by adjusting the number of channels to increase performance, the result increased by more than 0.3dB in same training."
데이터 수집방법에 따른 딥러닝 기반 산림수종 자동분류 정확도 변화에 관한 연구,2020,"['deep learning', 'image detection', 'classification', 'identification', 'tree species']",,"The use of increased computing power, machine learning, and deep learning techniques have dramatically increased in various sectors. In particular, image detection algorithms are broadly used in forestry and remote sensing areas to identify forest types and tree species. However, in South Korea, machine learning has rarely, if ever, been applied in forestry image detection, especially to classify tree species. This study integrates the application of machine learning and forest image detection; specifically, we compared the ability of two machine learning data collection methods, namely image data captured by forest experts (D1) and web-crawling (D2), to automate the classification of five trees species. In addition, two methods of characterization to train/test the system were investigated. The results indicated a significant difference in classification accuracy between D1 and D2: the classification accuracy of D1 was higher than that of D2. In order to increase the classification accuracy of D2, additional data filtering techniques were required to reduce the noise of uncensored image data."
나카가미 페이딩 채널에서 딥러닝 기반 송신 전력 제어 기법을 이용하는 무선통신 시스템에 대한 성능 분석,2020,,,"In this paper, we propose a deep learning based transmit power control (TPC) scheme to improve the spectral and energy efficiency of wireless communication systems. In the wireless communication system, the positions of multiple transceivers follow a uniform distribution, and the performances of spectral and energy efficiency for the proposed TPC scheme are analyzed assuming the Nakagami fading channels. The proposed TPC scheme uses batch normalization to improve spectral and energy efficiency in deep learning based training. Through simulation, we compare the results of the spectral and energy efficiency of the proposed TPC scheme and the conventional one for various area sizes that limit the position range of the transceivers and Nakagami fading factors. Comparing the performance results, we verify that the proposed scheme provides better performance than the conventional one."
잘피 서식지 모니터링을 위한 딥러닝 기반의 드론 영상 의미론적 분할,2020,"['Seagrass habitat', 'Drone', 'Semantic segmentation', 'Deep learning', 'Convolutional neural network', 'U-Net']",,"A seagrass that is marine vascular plants plays an important role in the marine ecosystem, so periodic monitoring ofseagrass habitatsis being performed. Recently, the use of dronesthat can easily acquire very high-resolution imagery is increasing to efficiently monitor seagrass habitats. And deep learning based on a convolutional neural network has shown excellent performance in semantic segmentation. So, studies applied to deep learning models have been actively conducted in remote sensing. However, the segmentation accuracy was different due to the hyperparameter, various deep learning models and imagery. And the normalization of the image and the tile and batch size are also not standardized. So,seagrass habitats were segmented from drone-borne imagery using a deep learning that shows excellent performance in this study. And it compared and analyzed the results focused on normalization and tile size. For comparison of the results according to the normalization, tile and batch size, a grayscale image and grayscale imagery converted to Z-score and Min-Max normalization methods were used. And the tile size isincreased at a specific interval while the batch size is allowed the memory size to be used as much as possible. As a result, IoU was 0.26 ~ 0.4 higher than that of Z-score normalized imagery than other imagery. Also, it wasfound that the difference to 0.09 depending on the tile and batch size. The results were different according to the normalization, tile and batch. Therefore, this experiment found that these factors should have a suitable decision process."
독소 조항 분류를 위한 딥러닝 기반 텍스트 분류 모델,2020,"['text classification', 'ALBERT', 'class embedding layer', 'gate layer', '텍스트 분류', 'ALBERT', '클래스 임베딩 계층', '게이트 계층']","여러 기업들은 과제를 수행하기에 앞서 계약서를 바탕으로 계약을 체결한다. 하지만 계약을 체결하기 전에 계약서 내의 독소 조항을 발견하지 못하고 계약을 진행하게 될 경우 여러 문제가 발생할 수 있다. 이를 방지하기 위하여 전문가를 통해 계약서를 검토하는 과정이 수행되지만 많은 시간과 비용을 요구한다. 만약 계약서의 사전 검토를 통해 독소 조항을 판별 할 수 있는 시스템이 존재한다면, 계약서를 검토하는 과정에서 발생하는 높은 비용과 시간을 절약할 수 있다. 따라서 본 논문에서는 계약서 내의 각 단락을 입력으로 하여 독소 조항 여부를 분류하는 텍스트 분류 모델을 제안한다. 제안 모델의 분류 성능을 높이기 위하여 단락 내 문장과 분류할 클래스 사이의 유사도 정보를 바탕으로 문장 별 중요도를 계산하고 이를 각 문장에 반영하여 분류를 수행한다. 제안 모델은 실제 계약서 데이터를 사용한 실험에서 F1 점수 84.51%p의 성능을 보였으며 기존 텍스트 분류 모델과의 성능 비교를 위해 WOS-5736 데이터셋을 이용한 실험에서 F1 점수 93.64%p로 가장 높은 성능을 보였다.","Most companies sign contracts based on the contract prior to executing the task.However, several problems can occur if the poisonous clauses are not identified before the contract is concluded. To prevent this problem, companies have an expert review the contract, but the service requires much time and money. If there is a system in which the poisonous clauses can be identified through prior review of the contract, the high cost and time incurred in reviewing the contract can be mitigated. Thus, this paper proposes a text classification model that identifies any poisonous clause in the contract by inputing each paragraph in the contract. To improve the classification performance of the proposed model, the importance of each sentence is calculated based on the relationship information between the sentence in the paragraph and the class to be classified, and classification is performed by reflecting it in each sentence. The proposed model showed the performance of the F1 score 84.51%p in experiments using actual contract data and the highest performance with the F1 score 93.64%p in experiments using the WOS-5736 dataset for the performance comparison with the existing text classification models."
실시간 스트리밍을 위한 딥러닝 기반의 얼굴마스킹 시스템,2020,"['face recognition', 'face masking', 'real-time broadcasting', 'portrait rights', '.']",,.
상관관계 정렬 전이학습을 통한 딥러닝 기반 가상계측 모델링,2020,"['Deep Learning', 'Machine Learning', 'Semiconductor', 'Transfer Learning', 'Virtual Metrology', 'N']",,"The shrinkage of circuit line width, which is a key technology for semiconductor processes, has caused problems that small changes in process parameters result to affect in product quality. The metrology process is operated to figure out the quality problems in advance. However, virtual metrology study was conducted because monitoring of all products is impossible. In the virtual metrology study, the lack of learning data of new equipment, it is difficult to obtain an accurate prediction model. Therefore, transfer learning was also study to solve it. However, in case of transfer learning, the prediction accuracy is low when the existing equipment and the new equipment are not similar. In this paper, we propose a method of transfer learning with virtual metrology model by performing preprocessing using correlation alignment method for more accurate prediction of new equipment. The experimental study confirmed that the proposed approach shows superior performance in the results."
차량용 카메라 센서를 이용한 딥러닝 기반의 자율주행 주행가능영역 검출 개발,2020,"['autonomous driving', 'driving area segmentation', 'image recognition', 'deep learning', 'Berkeley Deep Drive', '.']",,.
AR 기반의 특징점 추출과 딥러닝을 통한 부정맥 분류,2020,['RR'],,"Legacy studies for classifying arrhythmia have been studied in order to improve the accuracy of classification, Neural Network, Fuzzy, Machine Learning, etc. In particular, deep learning is most frequently used for arrhythmia classification using error backpropagation algorithm by solving the limit of hidden layer number, which is a problem of neural network. In order to apply a deep learning model to an ECG signal, it is necessary to select an optimal model and parameters. In this paper, we propose parameter extraction based on AR and arrhythmia classification through a deep learning. For this purpose, the R-wave is detected in the ECG signal from which noise has been removed, QRS and RR interval is modelled. And then, the weights were learned by supervised learning method through deep learning and the model was evaluated by the verification data. The classification rate of PVC is evaluated through MIT-BIH arrhythmia database. The achieved scores indicate arrhythmia classification rate of over 97%."
수 환경 분야에서의 딥러닝 모델 적용사례,2020,,,"Deep learning models, which imitate the function of human brain, have drawn attention from many engineering fields (mechanical, agricultural, and computer engineering etc). The major advantages of deep learning in engineering fields can be summarized by objects detection, classification, and time-series prediction. As well, it has been applied into environmental science and engineering fields. Here, we compiled our previous attempts to apply deep learning models in water-environment field and presented the future opportunities."
가상 데이터 생성을 통한 딥러닝 기반 문자인식 시스템 제안,2020,"['YOLO', 'Virtual Data Generation', 'Object Detection', 'Text Recognition']",,"In this paper, we proposed a deep learning based character recognition system through virtual data generation. In order to secure the learning data that takes the largest weight in supervised learning, virtual data was created. Also, after creating virtual data, data generalization was performed to cope with various data by using augmentation parameter. Finally, the learning data composition generated data by assigning various values to augmentation parameter and font parameter. Test data for measuring the character recognition performance was constructed by cropping the text area from the actual image data. The test data was augmented considering the image distortion that may occur in real environment. Deep learning algorithm uses YOLO v3 which performs detection in real time. Inference result outputs the final detection result through post-processing."
고기 신선도 측정 데이터의 딥러닝 기반 분석,2020,"['meat freshness', 'deep learning', 'multi-sensor', 'robustness']","축산 판매장에서 판매하는 고기들의 신선도 측정은 소비자의 건강을 위해 필요한 기술이다. 신선도 측정을 목적으로 다양한 센서가 연구 개발되고 있다. 센서는 다양한 고기의 신선도 상태 때문에 측정 오류가 발생한다. 따라서 강인성을 가지는 센서를 검증한 후에, 사용하는 과정이 필요하다. 본 논문에서는 10개의 고기 신선도 측정 센서로 얻은 데이터의 분석을 통해서, 각 측정 센서의 성능을 심층신경망을 이용하여 조사한다. 고기 종류로는 소고기, 돼지고기, 닭고기를 대상으로 검증한다. 또한 토리미터보다 성능이 우수한 다중 센서를 찾기 위해서 PCA를 이용하여 3개의 센서를 찾는다. 실험에서는 심층신경망으로 3개의 센서가 토리미터보다 우수함을 증명하였다.",
다양한 이미지 향상 기법을 사용한 전립선 병리영상 딥러닝 이진 분류 연구,2020,"['Deep Learning', 'Convolutional Neural Network', 'VGGNet', 'Prostate Cancer', 'Image Enhancement', 'Contrast Enhancement']",,
흉부 디지털 영상의 병변 유무 판단을 위한 딥러닝 모델,2020,,,"There are dozens of different types of lesions that can be diagnosed through chest X-ray images, including Atelectasis, Cardiomegaly, Mass, Pneumothorax, and Effusion. Computed tomography(CT) test is generally necessary to determine the exact diagnosis and location and size of thoracic lesions, however computed tomography has disadvantages such as expensive cost and a lot of radiation exposure. Therefore, in this paper, we propose a deep learning algorithm for judging the presence or absence of lesions in chest X-ray images as the primary screening tool for the diagnosis of thoracic lesions. The proposed algorithm was designed by comparing various configuration methods to optimize the judgment of presence of lesions from chest X-ray. As a result, the evaluation rate of lesion presence of the proposed algorithm is about 1% better than the existing algorithm."
CPU 환경에서의 실시간 동작을 위한 딥러닝 기반 다중 객체 추적 시스템,2020,"['multi object tracking', 'data association', 'real time object tracking']",,"Recently, the utilization of the object tracking algorithm based on the deep learning model is increasing. A system for tracking multiple objects in an image is typically composed of a chain form of an object detection algorithm and an object tracking algorithm. However, chain-type systems composed of several modules require a high performance computing environment and have limitations in their application to actual applications. In this paper, we propose a method that enables real-time operation in low-performance computing environment by adjusting the computational process of object detection module in the object detection-tracking chain type system."
적록색맹 모사 영상 데이터를 이용한 딥러닝 기반의 위장군인 객체 인식 성능 향상,2020,,,"The camouflage pattern was difficult to distinguish from the surrounding background, so it was difficult to classify the object and the background image when the color image is used as the training data of deep-learning. In this paper, we proposed a red-green color blindness image transformation method using the principle that people of red-green blindness distinguish green color better than ordinary people. Experimental results show that the camouflage soldier's recognition performance improved by proposed a deep learning model of the ensemble technique using the imitated red-green-blind image data and the original color image data."
재무 보고서의 키워드 검출 기반 딥러닝 감성분석 기법,2020,"['Deep learning', 'Keyword Detection', 'Financial report', 'Sentiment Analysis', 'Text mining']",,"Recent advances in artificial intelligence have allowed for easier sentiment analysis (e.g. positive or negative forecast) of documents such as a finance reports. In this paper, we investigate a method to apply text mining techniques to extract in the financial report using deep learning, and propose an accounting model for the effects of sentiment values in financial information. For sentiment analysis with keyword detection in the financial report, we suggest the input layer with extracted keywords, hidden layers by learned weights, and the output layer in terms of sentiment scores. Our approaches can help more effective strategy for potential investors as a professional guideline using sentiment values."
위성영상을 활용한 토지피복 분류 항목별 딥러닝 최적화 연구,2020,"['Land cover', 'Classification', 'Deep learning', 'Kompsat', 'Semantic segmentation']",,"This study is a study on classifying land cover by applying high-resolution satellite images to deep learning algorithms and verifying the performance of algorithms for each spatial object. For this, the Fully Convolutional Network-based algorithm was selected, and a dataset was constructed using Kompasat-3 satellite images, land cover maps, and forest maps. By applying the constructed data set to the algorithm, each optimal hyperparameter was calculated. Final classification was performed after hyperparameter optimization, and the overall accuracy of DeeplabV3+ was calculated the highest at 81.7%. However, when looking at the accuracy of each category, SegNet showed the best performance in roads and buildings, and U-Net showed the highest accuracy in hardwood trees and discussion items. In the case of Deeplab V3+, it performed better than the other two models in fields, facility cultivation, and grassland. Through the results, the limitations of applying one algorithm for land cover classification were confirmed, and if an appropriate algorithm for each spatial object is applied in the future, it is expected that high quality land cover classification results can be produced."
도심 Micro 셀 시나리오에서 밀리미터파 시스템을 위한 딥러닝 기반 안테나 선택 기법,2020,"['Antenna selection', 'Deep learning', 'DNN', 'Massive MIMO', 'Millimeter wave']",,"The millimeter wave that uses the spectrum in the 30GHz~300GHz band has a shorter wavelength due to its high carrier frequency, so it is suitable for Massive MIMO systems because more antennas can be equipped in the base station. However, since an RF chain is required per antenna, hardware cost and power consumption increase as the number of antennas increases. Therefore, in this paper, we investigate antenna selection schemes to solve this problem. In order to solve the problem of high computational complexity in the exhaustive search based antenna selection scheme, we propose a approach of applying deep learning technology. An best antenna combination is predicted using a DNN model capable of classifying multi-classes. By simulation tests, we compare and evaluate the existing antenna selection schemes and the proposed deep learning-based antenna selection scheme."
회전익 드론 접촉식 충전스테이션 도킹을 위한 딥러닝 기반 자동착륙시스템 구현,2020,"['drone', 'drone charging station', 'automatic landing', 'object detection', 'return-to-launch mode']",,"Rotary wing drones (RWDs), which are a kind of unmanned aerial vehicles, have been researched and developed to employ various fields, such as logistics transport, observation, surveillance, and measurement, because drones are able to overcome most restrictions resulted from constructions, roads, and geographical features of ground. However, RWDs have a short flight time caused battery issues, and the flight time becomes a major setback for those work. To relieve battery issues of RWDs, various charging stations and its management for RWDs have been proposed. Therefore, this paper proposes and implements a precise automatic landing system in order to accurately dock on a charging port in contact type charging stations for accomplishing missions of RWDs. The implemented automatic landing system uses FC-HarDNet based object detection algorithm and pixel-based distance computation for real-time recognition and tracking of the drone charging stations, and helps exact auto-landing for charging battery of drones. In experimental results, the landing distance error of proposed automatic landing system decreased by around 54.59% as compared with previous researches."
기업이질성에 근거한 수출 참여 예측: 딥러닝을 이용한 시계열 분류,2020,"['Export Participation', 'Firm Heterogeneity', 'Time Series Classification', 'Deep Learning']",,"Purpose: This study is to predict firms’ export participation based on firm heterogeneity, considering the situation where many countries around the world try to promote firms’ entry to export markets from the perspective of heterogeneous firm trade framework these days.Research design, data, and methodology: We used the 13-year time series data from the business activity survey produced by the Statistics Korea. Total factor productivity, financial leverage, and R&D expenditure were used as input variables and export participation was used as an output variable for time series classification with deep learning. We have trained and compared the three deep learning models for time series classification: multi layer perceptron, fully convolutional network, and residual network. We implemented the models using the open source deep learning library Keras with the Tensorflow back-end. The models’ performance was evaluated using the mean of accuracy, precision, recall, and F1-score over the 10 runs on the testing data set.Results: The results showed that the fully convolutional network (FCN) architecture performs best for the time series classification task and the recall is higher than the precision. The accuracy of the best model is 0.86, the precision is 0.64, the recall is 0.80, and the F1-score is 0.71.Conclusions: This study contributes to promoting the understanding of deep learning approach to prediction of export participation in the context of heterogenous firm trade theory. The prediction focuses on the selection of non-exporting firms, from the perspective of policy orientation for excavating and making firms without exporting start exporting. We propose to be able to utilize the FCN for enhancing the effectiveness and efficiency of export promotion policies, in particular focused on increase in firms’ export participation, by interpreting three of the indicators being used for model evaluation, precision, recall, and F1-score, in the context of such policy."
양방향 LSTM과 데이터 조합탐색 및 딥러닝 관련 기법을 활용한 철근 가격 단기예측에 관한 실험적 연구,2020,"['Rebar Price', 'Bidirectional LSTM', 'Data Combination', 'Hyperparameter Random Search', 'Price Prediction', 'Dropout', '철근 가격', '양방향 순환신경망', '데이터 조합', '하이퍼 파라미터 무작위 탐색', '가격예측', 'Dropout']",,"This study presents a systematic procedure for developing a short-term prediction deep learning model of rebar price using bidirectional LSTM, Random Search, data combination, Dropout. In general, users intuitively determine these values, making it time-consuming and repetitive attempts to explore results with good predictive performance, and the results found by these attempts cannot be guaranteed to be excellent. With the proposed approach presented in this study, the average accuracy of short-term price forecasts is approximately 98.32%. In addition, this approach could be used as basic data to produce good predictive results in a study that predicts prices with time series data based on statistics, including building materials other than rebars."
장수말벌 이미지 퓨전 전처리를 통한 딥러닝 영상인식,2020,"['장수말벌', '이미지 퓨전', '심층 합성곱 신경망', 'Vespa mandarinia', 'Image Fusion', 'AlexNet', 'DCNN(Deep Convolutional Neural Networks)']",,"The image fusion process is defined as gathering all the important information from multiple images to a single image. This single image is more informative and accurate than any single source image, and it consists of all the necessary information. It is important to acquire a high quality image for tracking and recognizing object. So, it is required to create a refined image by synthesizing or compensating the acquired image through image fusion. In this paper, we would like to present a fusion and recognition application method of the acquired image in order to increase the recognition rate of Vespa mandarinia. Generating a random area blurred source image in a Vespa mandarinia image, and synthesized through the PCA(principal component analysis) based image fusion, and measures the image fusion performance through RMSE, PFE, MAE, CORR, SNR, PSNR. In addition, using the AlexNet based on the DCNN(Deep Convolutional Neural Networks), it presents the recognition score and classification accuracy for the fused image."
조류 울음소리를 이용한 조류 분류 딥러닝 시스템 개발,2020,"['Deep learning', 'Classification', 'Spectrogram', 'AI', 'Convolutional Neural Networks', 'ResNet', 'AlexNet']",,"The activity and distribution of wild birds are biological indicators to evaluate biodiversity. In order to identify bird habitats, collecting and classifying sounds should have to do. Using the bird sound can make easier to distinguish location or type of wild birds. Recently, attempts to analyze bioacoustic data have been risen using the machine learning. We are going to classify the bird songs using deep learning. The bird songs convert into the spectrogram images. Spectrogram images are used for the input of convolutional neural network. In generally the bird song data set for classification contains a lot of noise. Even obtaining the data including noise is difficult. The data is about 200 bird sounds of 20 species. Based on transfer learning, ResNet34, ResNet50 and AlexNet of Convolutional Neural Network are used as the experiment. The experiment parameter is learning rate and epochs. As a result, the ResNet34 shows the highest accuracy of 99.7% and an average of 93% in the test. Therefore, In this paper, we are going to develop the deep learning system that classifies 20 kinds of bird song using ResNet34. By using this system, it can be helpful various activities such as the prevention of avian influenza."
정적 변형률 데이터를 사용한 CNN 딥러닝 기반 PSC 교량 손상위치 추정,2020,['PSC'],,"As the number of aging bridges increases, more studies are being conducted on developing effective and reliable methods for the assessment and maintenance of bridges. With the advancement in new sensing systems and data learning techniques through AI technology, there is growing interests in how to evaluate bridges using these advanced techniques. This paper presents a CNN(Convolution Neural Network) deep learning based technique for evaluating the damage existence and for estimating the damage location in PSC bridges using static strain data. Simulation studies were conducted to investigate the proposed method with error analysis. Damage was simulated as the reduction in the stiffness of a finite element. A data learning model was constructed by applying the CNN technique as a type of deep learning. The damage status and its location were estimated using data set built through simulation. It was assumed that the strain gauges were installed in a regular interval under the PSC bridge girders. In order to increase the accuracy in evaluating damage, the squared error between the intact and measured strains are computed and applied for training the data model. Considering the damage occurring near the supports, the results of error analysis were compared according to whether strain data near the supports were included."
생성적 적대 신경망(GAN)을 이용한 딥러닝 음악 장르 분류 시스템 모델 개선,2020,,,"Music markets have entered the era of streaming. In order to select and propose music that suits the taste of music consumers, there is an active demand and research on an automatic music genre classification system. We propose a method to improve the accuracy of genre unclassified songs, which was a lack of the previous system, by using a generative adversarial network (GAN) to further develop the automatic voting system for deep learning music genre using Softmax proposed in the previous paper. In the previous study, if the spectrogram of the song was ambiguous to grasp the genre of the song, it was forced to leave it as an unclassified song. In this paper, we proposed a system that increases the accuracy of genre classification of unclassified songs by converting the spectrogram of unclassified songs into an easy-to-read spectrogram using GAN. And the result of the experiment was able to derive an excellent result compared to the existing method."
시계열 예측을 위한 LSTM 기반 딥러닝: 기업 신용평점 예측 사례,2020,"['KIS credit score', 'machine learning', 'deep learning', 'time series forecasting', 'sliding window technique']",,"PurposeVarious machine learning techniques are used to implement for predicting corporate credit. However, previous research doesn't utilize time series input features and has a limited prediction timing. Furthermore, in the case of corporate bond credit rating forecast, corporate sample is limited because only large companies are selected for corporate bond credit rating. To address limitations of prior research, this study attempts to implement a predictive model with more sample companies, which can adjust the forecasting point at the present time by using the credit score information and corporate information in time series.Design/methodology/approachTo implement this forecasting model, this study uses the sample of 2,191 companies with KIS credit scores for 18 years from 2000 to 2017. For improving the performance of the predictive model, various financial and non-financial features are applied as input variables in a time series through a sliding window technique. In addition, this research also tests various machine learning techniques that were traditionally used to increase the validity of analysis results, and the deep learning technique that is being actively researched of late.FindingsRNN-based stateful LSTM model shows good performance in credit rating prediction. By extending the forecasting time point, we find how the performance of the predictive model changes over time and evaluate the feature groups in the short and long terms. In comparison with other studies, the results of 5 classification prediction through label reclassification show good performance relatively. In addition, about 90% accuracy is found in the bad credit forecasts."
MIMO 기반의 IoT 통신 잡음을 최소화하기 위해서 딥러닝을 활용한 비밀키 차원 분배 메커니즘,2020,['IoT'],,"As IoT devices increase exponentially, minimizing MIMO interference and increasing transmission capacity for sending and receiving IoT information through multiple antennas remain the biggest issues. In this paper, secret key-level distribution mechanism using deep learning is proposed to minimize MIMO-based IoT communication noise. The proposed mechanism minimizes resource loss during transmission and reception process by dispersing IoT information sent and received through multiple antennas in batches using deep learning. In addition, the proposed mechanism applied a multidimensional key distribution processing process to maximize capacity through multiple antenna multiple stream transmission at base stations without direct interference between the APs. In addition, the proposed mechanism synchronizes IoT information by deep learning the frequency of use of secret keys according to the number of IoT information by applying the method of distributing secret keys in dimension according to the number of frequency channels of IoT information in order to make the most of the multiple antenna technology."
주 객체 위치 검출을 위한 Grad-CAM 기반의 딥러닝 네트워크,2020,,,"In this paper, we propose an optimal deep learning network architecture for main object location detection through weak supervised learning. The proposed network adds convolution blocks for improving the localization accuracy of the main object through weakly-supervised learning. The additional deep learning network consists of five additional blocks that add a composite product layer based on VGG-16. And the proposed network was trained by the method of weakly-supervised learning that does not require real location information for objects. In addition, Grad-CAM to compensate for the weakness of GAP in CAM, which is one of weak supervised learning methods, was used. The proposed network was tested through the CUB-200-2011 data set, we could obtain 50.13% in top-1 localization error. Also, the proposed network shows higher accuracy in detecting the main object than the existing method."
인지 무선 통신에서 전이 학습을 이용한 딥러닝 기반 변조 신호 센싱 기법,2020,"['Signal detection', 'Cognitive radio', 'Deep learning', 'Transfer Learning', 'Dynamic time warping']",,
표면 결함 분류를 위한 적정 규모의 딥러닝 모델,2020,"['Deep learning', 'Convolutional neural network', 'Appropriate Scaled Model', 'Surface Defects Detection']",,"In this paper, we propose a method of surface defect image classification for metal cases using a Convolutional Neural Network (CNN) deep learning model. We show the feasibility and effectiveness of our appropriate scaled CNN model using real-word data on metal case images with and without defects under different surface and lighting conditions. In addition, we analyze learning behaviors on three different data sets. The results of our work in this study have the potential to have a significant impact on the manufacturing industry"
거울 과제에 대한 자기조절 과정의 fNIRS 두뇌 활성 규명과 딥러닝 기반 예측 모델 탐색,2020,"['Self-regulation', 'mirror task', 'assimilation', 'accommodation', 'fNIRS', 'OFC', 'DLPFC', 'deep learning']",,"Self-regulation is one of important cognitive processes in learning to change the learner s schema by itself. However, its definition and process have yet been clearly clarified and no strategies that can be systematically measured have been proposed. In this study, we tried to find out the neural characteristics of self-regulation process consisting of assimilation, conflict and accommodation by analyzing subject’s brain activity using fNIRS. In addition to the brain activity, a deep learning model was also developed for the process prediction of self-regulation. Forty-six high-school students were administered to take a mirror task inducing self-regulation, and their brain activities were measured and analyzed using fNIRS. As a result, the activities of both OFC and left DLPFC were found in the entire process of self-regulation. It can be seen that the process of self-regulation is mainly based on monitoring and evaluation of one s performance. In addition, the activities of FP and VLPFC were additionally shown in the accommodation phase. These results are presumably proposed that the goal-oriented multitasking and clarification using language might be two of major players in this process. In addition, a predictive model was developed through a deep learning process with an accuracy of 72.8% and a loss value of 0.309. These results are possibly suggested to know the characteristics of the brain level in self-regulation process and provided a basic information for the development and improvement of self-regulation. In addition, it can be used as a basis for developing a system capable of fast and accurate diagnosis and treatment for self-regulation."
스마트 헬스 시티 구현을 위한 얼굴 영상기반 심박수 추출 딥러닝 모델 최적화,2020,"['Heartrate', 'semantic segmentation', 'video stabilize', 'BOHB', 'CNN']",,
서울 관악구 도심지역 미세먼지(PM<sub>10</sub>) 관측 값을 활용한 딥러닝 기반의 농도변동 예측,2020,"['fine dust ( $PM_{10}$)', 'precursor', 'deep learning', 'convolutional neural network', 'recurrent neural network', 'prediction']",,"Since fine dust (PM<sub>10</sub>) has a significant influence on soil and groundwater composition during dry and wet deposition processes, it is of a vital importance to understand the fate and transport of aerosol in geological environments. Fine dust is formed after the chemical reaction of several precursors, typically observed in short intervals within a few hours. In this study, deep learning approach was applied to predict the fate of fine dust in an urban area. Deep learning training was performed by combining convolutional neural network (CNN) and recurrent neural network (RNN) techniques. The PM<sub>10</sub> concentration after 1 hour was predicted based on three-hour data by setting SO<sub>2</sub>, CO, O<sub>3</sub>, NO<sub>2</sub>, and PM<sub>10</sub> as training data. The obtained coefficient of determination value, R<sup>2</sup>, was 0.8973 between predicted and measured values for the entire concentration range of PM<sub>10</sub>, suggesting deep learning method can be developed into a reliable and viable tool for prediction of fine dust concentration."
온라인 스트리밍 채팅 내 이모트가 포함된 혐오 표현 탐지: 딥러닝 모델을 기반으로,2020,"['visual hate speech', 'live streaming', 'bidirectional long short-term memory', 'algorithmic moderation', 'Twitch', '시각적 혐오 표현', '실시간 방송', '탐지', '양방향 장단기 메모리', '알고리즘 기반 조정', '트위치']","자연 언어 처리의 발전을 통해 혐오 표현 탐지를 위한 인공지능 또한 성장하게 되었다. 하지만 악성 유저는 지속해서 기계에 의해 식별되지 않는 새로운 형태의 혐오 표현을 생성해낸다. 다양한 유형 중 하나는 텍스트와 이모트의 혼합으로, 인간에 의해서는 쉽게 검출되지만, 규칙 기반 탐지로는 쉽게 검출할 수 없다. 이 연구는 가장 큰 온라인 스트리밍 서비스 중 하나인 트위치(Twitch.tv)의 채팅 데이터를 분석하여 이러한 유형을 파악한다. 혐오 표현에서 사용되는 이모트와 방송을 진행하고 있는 스트리머 인종 간의 비교를 진행한다. 또한 새로운 혐오 표현 유형을 탐지하기 위해 양방향 장단기 메모리 모델을 활용한 새로운 방법을 제시한다. 약 1,500만 개의 채팅 중에서, 이 연구에서 제안된 기법을 통해 F1-score 0.745의 성능으로 혐오 표현을 추가로 검출할 수 있었다.","Through the development of the natural language processing, artificial intelligence for the detection of hate speech has also grown. However, malicious users continuously produce new forms of hate speech not identified by the machine. Of the various types is a mixture of text and emotes, easily distinguishable by humans but not by rule-based detection. This study analyzes chat data of Twitch.tv, a popular online streaming service, to identify types of a mixture of text and emotes.We compared the emotes usage in the hate speech and the race of the streamer. Besides, a new method using the bidirectional long short-term memory model is proposed to detect new hate speech types. Among approximately 15 million chats, the proposed method could identify additional hate speech with an F1-score of 0.745."
"‘인공지능’, ‘기계학습’, ‘딥 러닝’ 분야의 국내 논문 동향 분석",2020,"['Artificial Intelligence', 'Deep Learning', 'Machine Learning', 'Paper trend', 'Semantic Network', 'Topic Modeling', 'Word Count Analysis']","4차 산업혁명의 대표적인 이미지 중 하나인 인공지능은 2016년 알파고 이후에 인공지능 인식이 매우 높아져 있다. 본 논문은 학국교육학술정보원에서 제공하는 국내 논문 중 ‘인공지능’, ‘기계학습’, ‘딥 러닝’으로 검색된 국내 발표 논문에 대해서 분석하였다. 검색된 논문은 약 1만여건이며 논문 동향을 파악하기 위해 빈도분석과 토픽 모델링, 의미 연결망을 이용하였다. 추출된 논문을 분석한 결과, 2015년에 비해 2016년에는 인공지능 분야는 600%, 기계학습은 176%, 딥 러닝 분야는 316% 증가하여 알파고 이후에 인공지능 분야의 연구가 활발히 진행됨을 확인할 수 있었다. 또한, 2018년 부터는 기계학습보다 딥 러닝 분야가 더 많이 연구 발표되고 있다. 기계학습에서는 서포트 벡터 머신 모델이, 딥 러닝에서는 텐서플로우를 이용한 컨볼루션 신경망이 많이 활용되고 있음을 알 수 있었다. 본 논문은 ‘인공지능’, ‘기계학습’, ‘딥 러닝’ 분야의 향후 연구 방향을 설정하는 도움을 제공할 수 있다.","Artificial intelligence, which is one of the representative images of the 4th industrial revolution, has been highly recognized since 2016. This paper analyzed domestic paper trends for ‘Artificial Intelligence’, ‘Machine Learning’, and ‘Deep Learning’ among the domestic papers provided by the Korea Academic Education and Information Service. There are approximately 10,000 searched papers, and word count analysis, topic modeling and semantic network is used to analyze paper's trends. As a result of analyzing the extracted papers, compared to 2015, in 2016, it increased 600% in the field of artificial intelligence, 176% in machine learning, and 316% in the field of deep learning. In machine learning, a support vector machine model has been studied, and in deep learning, convolutional neural networks using TensorFlow are widely used in deep learning. This paper can provide help in setting future research directions in the fields of ‘artificial intelligence’, ‘machine learning', and ‘deep learning'."
딥 러닝 기법을 활용한 이미지 내 한글 텍스트 인식에 관한 연구,2020,"['문자인식', '한글인식', '이미지분석', '딥러닝', '합성곱신경망', 'Character recognition', 'Korean Recognition', 'Image analysis', 'Deep learning', 'Convolution neural network']","본 연구에서는 컴퓨터 비전의 분야 중 하나인 문자 인식에 관한 연구를 수행했다. 대표적인 문자인식 기법 중 하나인 광학식 문자 판독 기법의 경우 일정한 규격과 서식에서 벗어나게 되면 인식률이 떨어진다는 한계점이 있다. 따라서 본 연구에서는 딥 러닝 기법을 적용해 이러한 문제점을 해결하고자 한다. 또한 기존의 문자 인식 연구의 경우 대부분 영어 및 숫자 인식에 국한되어 있다. 따라서 본 연구는 한글 인식을 위한 딥 러닝 기반 문자 인식 알고리즘을 제시한다. 알고리즘은 1-NED 평가 방법에서 0.841의 점수를 얻었으며, 이는 영어 인식 결과와 비슷한 수치이다. 본 연구를 통해 딥 러닝 기반 한글 인식 알고리즘의 성능을 확인할 수 있으며, 이를 통해 향후 연구방향에 대해 제시한다.",
BRT 구간 딥 러닝을 활용한 버스우선 신호도입 방안에 관한 연구,2020,"['Deep learning', 'Smart intersection', 'BRT (Bus Rapid Transit)', 'Bus priority signal', '딥러닝', '스마트교차로', '간선급행버스체계', '버스우선신호']","본 연구는 딥러닝 기술을 적용한 스마트교차로의 부산 해운대로 BRT 구간 버스정류장 유형을 대상으로 교통신호 프로그램인 LISA를 통해 네트워크 구축 및 알고리즘 설계 효과분석을 통해 버스정류장 유형별로 적합한 알고리즘을 제시하였다. 교차로 통과 전 정류장은 Phase insert 기법, 교차로 통과 후 정류장은 Early green 기법, 미드블럭형 정류장은 Extend green 기법이 가장 효과적인 것으로 분석되었고, 버스 및 일반차량과 보행자 현시로 구성하였기 때문에 Extend green 기법으로만 분석하였다. 교차로 통과 전 정류장은 교차로의 전체 통행시간은 57.8초, 지체시간은 33.2초, BRT 상ㆍ하행 평균 통행시간 85.3초, 지체시간 31.1초, 통과대수는 28대로 분석되었고, 교차로 통과 후 정류장은 교차로의 전체 통행시간은 58.2초, 지체시간은 31.8초 BRT 상ㆍ하행 평균 통행시간 102.2초, 지체시간 42.5초, 통과대수 26대로 분석되었다. 미드블럭형 정류장은 교차로의 전체 통행시간은 42.5초, 지체시간은 11.2초, BRT 상ㆍ하행 평균 통행시간 74.2초, 지체시간 17.0초, 통과대수 28대로 분석되었다. 분석결과를 토대로 버스우선 신호시범도입, 보행자 시거확보를 위한 계단식정지선, 속도감속을 위한 고원식횡단보도, 딥러닝 기술을 활용한 무단횡단금지 경고 벨 및 VMS 설치 등으로 BRT 구간에서의 교통사고 감소 효과가 기대되며, 이를 확대 도입할 필요가 있다.","In this study, a suitable algorithm for each BRT stop type is presented through the network construction and algorithm design effect analysis through the LISA, a traffic signal program, for the BRT stop type in the BRT Design Guidelines, Ministry of Land, Transportand Maritime Affairs, 2010.6. It was. The phase insert technique is the most effective method for the stop before passing the intersection, the early green technique for the stop after the intersection, and the extend green technique for the mid-block type stop. The extension green technique is used only because it consists of BRT vehicles, general vehicles and pedestrians. Analyzed. After passing through the intersection, the stop was analyzed as 56.4 seconds for the total crossing time and 29.8 seconds for the delay time. In the mid-block typestop, the total travel time of the intersection was 40.5 seconds, the delay time was 9.6 seconds, the average travel time of up and downBRT was 70.2 seconds, the delay time was 14.0 seconds, and the number of passages was 29."
딥 러닝을 이용한 실감형 콘텐츠 특징점 인식률 향상 방법,2020,"['Immersive Content', 'Deep Learning', 'Feature Point Extracting and Matching', 'Piracy Judgment', 'OMAF']","4차 산업의 주요 기술로 주목받고 있는 실감형 360 동영상 콘텐츠의 시장 규모는 매년 증가하고 있다. 하지만 대부분의 영상이 DRM 해제 후 토렌트 등의 불법 유통망을 통해 유통되고 있어 불법복제로 인한 피해 또한 증가하고 있다. 이러한 이슈에 대응하는 기술로 필터링 기술을 사용하고 있으나 대부분의 불법 저작물 필터링 기술은 2D 영상의 불법 복제 여부를 판단하는 기술에 국한되고 있으며, 이를 실감형 360 동영상에 적용하기 위해서는 4K UHD 이상의 초고화질에 따른 특징 데이터량 증가와 이에 따른 처리 속도 문제와 같은 기술적 한계를 극복해야 하는 과제가 남는다. 본 논문에서는 이러한 문제를 해결하기 위하여 딥 러닝 기술을 이용한 실감형 360도 동영상 내 특징 데이터 인식률 개선 방법을 제안한다.","The market size of immersive 360-degree video contents, which are noted as one of the main technology of the fourth industry, increases every year. However, since most of the images are distributed through illegal distribution networks such as Torrent after the DRM gets lifted, the damage caused by illegal copying is also increasing. Although filtering technology is used as a technology to respond to these issues in 2D videos, most of those filtering technology has issues in that it has to overcome the technical limitation such as huge feature-point data volume and the related processing capacity due to ultra high resolution such as 4K UHD or higher in order to apply the existing technology to immersive 360° videos. To solve these problems, this paper proposes a feature-point recognition ratio improvement method for immersive 360-degree videos using deep learning technology."
딥 러닝을 이용한 인터네트워크 토폴로지 내 네트워크 경계의 악성 패킷 필터링 스킴,2020,"['악성 패킷', '딥 러닝', '악성코드 탐지', '네트워크 보안', '정보 보호', '패킷 필터링', 'Malicious packet', 'Deep learning', 'Malware Detection', 'Network security', 'Information security', 'Packet filtering']",,
딥 러닝을 이용한 실감형 콘텐츠 특징점 추출 및 식별 방법,2020,"['Immersive Content', 'Deep Learning', 'Feature Point Extracting and Matching', 'Piracy Judgment', 'OMAF']","4차 산업의 주요 기술로 실감형 360도 영상 콘텐츠가 주목받고 있다. 전 세계 실감형 360도 영상 콘텐츠의 시장 규모는 2018년 67억 달러에서 2020년 약 700억 달러까지 증가될 것이라고 전망하고 있다. 하지만 대부분 실감형 360도 영상 콘텐츠가 웹하드, 토렌트 등의 불법 유통망을 통해 유통되고 있어 불법복제로 인한 피해가 증가하고 있다. 이러한 불법 유통을 막기 위하여 기존 2D 영상은 불법저작물 필터링 기술을 사용하고 있다. 그러나 초고화질을 지원하고 두 대 이상의 카메라를 통해 촬영된 영상을 하나의 영상에 담는 실감형 360도 영상 콘텐츠의 특징 때문에 왜곡 영역이 존재하여 기존 2D 영상에 적용된 기술을 그대로 사용하기엔 다소 무리가 있다. 또한, 초고화질에 따른 특징점 데이터량 증가와 이에 따른 처리 속도 문제와 같은 기술적 한계가 존재한다. 본 논문에서는 이러한 문제를 해결하기 위하여 왜곡이 심한 영역을 제외한 객체 식별 영역을 선정하고, 식별 영역에서 딥 러닝 기술을 이용하여 객체를 인식하고 인식된 객체의 정보를 이용하여 특징 벡터를 추출하는 특징점 추출 및 식별 방법을 제안한다. 제안한 방법은 기존에 제안 되었던 스티칭 영역을 이용한 실감형 콘텐츠 특징점 추출방법과 비교하여 성능의 우수성을 보였다.","As the main technology of the 4th industrial revolution, immersive 360-degree video contents are drawing attention. The market size of immersive 360-degree video contents worldwide is projected to increase from $6.7 billion in 2018 to approximately $70 billion in 2020. However, most of the immersive 360-degree video contents are distributed through illegal distribution networks such as Webhard and Torrent, and the damage caused by illegal reproduction is increasing. Existing 2D video industry uses copyright filtering technology to prevent such illegal distribution. The technical difficulties dealing with immersive 360-degree videos arise in that they require ultra-high quality pictures and have the characteristics containing images captured by two or more cameras merged in one image, which results in the creation of distortion regions. There are also technical limitations such as an increase in the amount of feature point data due to the ultra-high definition and the processing speed requirement. These consideration makes it difficult to use the same 2D filtering technology for 360-degree videos. To solve this problem, this paper suggests a feature point extraction and identification technique that select object identification areas excluding regions with severe distortion, recognize objects using deep learning technology in the identification areas, extract feature points using the identified object information. Compared with the previously proposed method of extracting feature points using stitching area for immersive contents, the proposed technique shows excellent performance gain."
스켈레톤 조인트 매핑을 이용한 딥 러닝 기반 행동 인식,2020,"['Action recognition', 'Deep learning', 'CNN', 'End-to-end skeleton joints mapping.']","최근 컴퓨터 비전과 딥러닝 기술의 발전으로 비디오 분석, 영상 감시, 인터렉티브 멀티미디어 및 인간 기계 상호작용 응용을 위해 인간 행동 인식에 관한 연구가 활발히 진행되고 있다. 많은 연구자에 의해 RGB 영상, 깊이 영상, 스켈레톤 및 관성 데이터를 사용하여 인간 행동 인식 및 분류를 위해 다양한 기술이 도입되었다. 그러나 스켈레톤 기반 행동 인식은 여전히 인간 기계 상호작용 분야에서 도전적인 연구 주제이다. 본 논문에서는 동적 이미지라 불리는 시공간 이미지를 생성하기 위해 동작의 종단간 스켈레톤 조인트 매핑 기법을 제안한다. 행동 클래스 간의 분류를 수행하기 위해 효율적인 심층 컨볼루션 신경망이 고안된다. 제안된 기법의 성능을 평가하기 위해 공개적으로 액세스 가능한 UTD-MHAD 스켈레톤 데이터 세트를 사용하였다. 실험 결과 제안된 시스템이 97.45 %의 높은 정확도로 기존 방법보다 성능이 우수함을 보였다.","Recently, with the development of computer vision and deep learning technology, research on human action recognition has been actively conducted for video analysis, video surveillance, interactive multimedia, and human machine interaction applications. Diverse techniques have been introduced for human action understanding and classification by many researchers using RGB image, depth image, skeleton and inertial data. However, skeleton-based action discrimination is still a challenging research topic for human machine-interaction. In this paper, we propose an end-to-end skeleton joints mapping of action for generating spatio-temporal image so-called dynamic image. Then, an efficient deep convolution neural network is devised to perform the classification among the action classes. We use publicly accessible UTD-MHAD skeleton dataset for evaluating the performance of the proposed method. As a result of the experiment, the proposed system shows better performance than the existing methods with high accuracy of 97.45%."
딥 러닝과 파노라마 영상 스티칭 기법을 이용한 송전선 늘어짐 모니터링 시스템,2020,"['Object detection', 'Panoramic video stitching', 'Power line deflection monitoring system', 'Fault diagnosis']",한국에는 전력 분배를 위하여 약 9백만 개의 전신주와 1.3백만 킬로미터의 송전선이 있다. 이러한 많은 전력 설비의 유지보수를 위해서는 많은 인력과 시간이 소요된다. 최근 인공지능을 사용한 여러 고장진단 기술들이 연구되어 오고 있기 때문에 본 논문에서는 송전선의 여러 요인으로 인한 늘어짐을 감지하기 위해 기존의 현장에서의 검증 방법이 아닌 카메라 시스템으로 촬영한 영상에서의 인공지능 기술을 활용한 송전선 늘어짐 감지 시스템을 제안한다. 제안하는 시스템은 (i) 객체 탐지 시스템을 이용한 송전탑 감지 (ii) 동영상 촬영 데이터의 화질 저하 문제를 해결하기 위한 히스토그램 평활화 기법 (iii) 송전선 전체를 파악하기 위한 파노라마 영상 스티칭 (iv) 송전선 탐지 알고리즘 적용 후 파노라마 영상 스티칭 기술을 이용한 늘어짐 판단 과정으로 진행된다. 본 논문에서는 각각의 과정들에 대한 설명 및 실험 결과를 보인다.,
손목 관절 단순 방사선 영상에서 딥 러닝을 이용한 전후방 및 측면 영상 분류와 요골 영역 분할,2020,"['Distal radius fractures', 'Deep learning', 'Classification', 'Segmentation', 'X-rays']",,"The purpose of this study was to present the models for classifying the wrist X-ray images by types and for segmenting the radius automatically in each image using deep learning and to verify the learned models. The data were a total of 904 wrist X-rays with the distal radius fracture, consisting of 472 anteroposterior (AP) and 432 lateral images. The learning model was the ResNet50 model for AP/lateral image classification, and the U-Net model for segmentation of the radius. In the model for AP/lateral image classification, 100.0% was showed in precision, recall, and F1 score and area under curve (AUC) was 1.0. The model for segmentation of the radius showed an accuracy of 99.46%, a sensitivity of 89.68%, a specificity of 99.72%, and a Dice similarity coefficient of 90.05% in AP images and an accuracy of 99.37%, a sensitivity of 88.65%, a specificity of 99.69%, and a Dice similarity coefficient of 86.05% in lateral images. The model for AP/lateral classification and the segmentation model of the radius learned through deep learning showed favorable performances to expect clinical application."
이종 프로세서 환경에서의 복수의 딥 러닝 어플리케이션 스케줄링 기법,2020,"['임베디드 시스템', '딥 러닝', '이종 프로세서', '스케줄링', '휴리스틱', 'embedded system', 'deep learning', 'heterogeneous processors', 'scheduling', 'heuristic']","이종 프로세서 환경에서의 복수의 딥 러닝 어플리케이션 스케줄링은 기본적으로 NP-난해 (NP-Hard) 문제에 속하여 매우 큰 문제 공간을 가진다. 그래서 일반적으로 유전 알고리즘(GA, Genetic Algorithm)과 같은 메타 휴리스틱이 적용될 수 있지만 이는 수행 시간이 길어서 런타임에 적용하기 어렵다는 단점을 지닌다. 따라서 본 연구에서는 이러한 단점을 보완하면서 성능 또한 크게 떨어지지 않는 새로운 기법의 스케줄링 휴리스틱을 제안하였다. 제안하는 휴리스틱은 복수 응용 스케줄링의 스케줄 가능성 문제를 고려하지 못 하는 기존의 리스트 스케줄링 방식 휴리스틱들의 한계를 극복하여 ‘합성과 반복 개선’ 이라는 새로운 방식을 도입하였다. 그리하여 CPU, GPU, NPU로 구성되는 이종 프로세서 환경에서 여러 딥 러닝 네트워크들을 대상으로 하는 성능 비교 실험을 통해 제안하는 휴리스틱이 빠른 시간 내에 좋은 스케줄링을 생성함을 확인하였다.","The scheduling of multiple deep learning applications on heterogeneous processors is basically an NP-hard problem with a very large problem space. Meta-heuristics such as GAs (Genetic Algorithms) may be applied, but these have the disadvantage of having too long an execution time to be applied at run time. Therefore, this study proposes a new scheduling heuristic, which complements this shortcoming and does not significantly degrade scheduling performance. The proposed heuristic overcomes the limitations of traditional list scheduling techniques that fail to take into account the schedulability issue in the scheduling of multiple applications and introduces a new approach called ‘synthesis and iterative improvement’. It is confirmed through experiments with different deep learning networks on heterogeneous processors (including CPUs, GPUs, and NPUs) that the proposed heuristic produces good scheduling results that are sufficiently fast to apply at run time."
딥 러닝 기반 코로나19 흉부 X선 판독 기법,2020,"['코로나19', '흉부 X선', 'StackGAN++', '설명 가능한 인공지능', '이진 분류', 'COVID-19', 'Chest X-ray', 'StackGAN++', 'XAI', 'Binary Classification']","전 세계적으로 유행하는 코로나19로 인해 많은 사망자가 보고되고 있다. 코로나19의 추가 확산을 막기 위해서는 의심 환자에 대해 신속하고 정확한 영상판독을 한 후, 적절한 조치를 취해야 한다. 이를 위해 본 논문은 환자의감염 여부를 의료진에게 제공해 영상판독을 보조할 수 있는 딥 러닝 기반 코로나19 흉부 X선 판독 기법을 소개한다.우선 판독모델을 학습하기 위해서는 충분한 데이터셋이 확보되어야 하는데, 현재 제공하는 코로나19 오픈 데이터셋은학습의 정확도를 보장하기에 그 영상 데이터 수가 충분하지 않다. 따라서 누적 적대적 생성 신경망(StackGAN++)을사용해 인공지능 학습 성능을 저하하는 영상 데이터 수적 불균형 문제를 해결하였다. 다음으로 판독모델 개발을 위해증강된 데이터셋을 사용하여 DenseNet 기반 분류모델 학습을 진행하였다. 해당 분류모델은 정상 흉부 X선과 코로나19 흉부 X선 영상을 이진 분류하는 모델로, 실제 영상 데이터 일부를 테스트데이터로 사용하여 모델의 성능을 평가하였다. 마지막으로 설명 가능한 인공지능(eXplainable AI, XAI) 중 하나인 Grad-CAM을 사용해 입력 영상의 질환유무를 판단하는 근거를 제시하여 모델의 신뢰성을 확보하였다.","Many deaths have been reported due to the worldwide pandemic of COVID-19. In order to prevent the further spread of COVID-19, it is necessary to quickly and accurately read images of suspected patients and take appropriate measures. To this end, this paper introduces a deep learning-based COVID-19 chest X-ray reading technique that can assist in image reading by providing medical staff whether a patient is infected. First of all, in order to learn the reading model, a sufficient dataset must be secured, but the currently provided COVID-19 open dataset does not have enough image data to ensure the accuracy of learning. Therefore, we solved the image data number imbalance problem that degrades AI learning performance by using a Stacked Generative Adversarial Network(StackGAN++). Next, the DenseNet-based classification model was trained using the augmented data set to develop the reading model. This classification model is a model for binary classification of normal chest X-ray and COVID-19 chest X-ray, and the performance of the model was evaluated using part of the actual image data as test data. Finally, the reliability of the model was secured by presenting the basis for judging the presence or absence of disease in the input image using Grad-CAM, one of the explainable artificial intelligence called XAI."
콘크리트 균열 탐지를 위한 딥 러닝 기반 CNN 모델 비교,2020,"['균열 탐지', 'ILSVRC', '딥 러닝', 'CNN', '전이 학습', 'Crack Detection', 'Deep Learning', 'Transfer Learning']",,"The purpose of this study is to compare the models of Deep Learning-based Convolution Neural Network(CNN) for concrete crack detection. The comparison models are AlexNet, GoogLeNet, VGG16, VGG19, ResNet-18, ResNet-50, ResNet-101, and SqueezeNet which won ImageNet Large Scale Visual Recognition Challenge(ILSVRC). To train, validate and test these models, we constructed 3000 training data and 12000 validation data with 256×256 pixel resolution consisting of cracked and non-cracked images, and constructed 5 test data with 4160×3120 pixel resolution consisting of concrete images with crack. In order to increase the efficiency of the training, transfer learning was performed by taking the weight from the pre-trained network supported by MATLAB. From the trained network, the validation data is classified into crack image and non-crack image, yielding True Positive (TP), True Negative (TN), False Positive (FP), False Negative (FN), and 6 performance indicators, False Negative Rate (FNR), False Positive Rate (FPR), Error Rate, Recall, Precision, Accuracy were calculated. The test image was scanned twice with a sliding window of 256×256 pixel resolution to classify the cracks, resulting in a crack map. From the comparison of the performance indicators and the crack map, it was concluded that VGG16 and VGG19 were the most suitable for detecting concrete cracks."
채널 강조와 공간 강조의 결합을 이용한 딥 러닝 기반의 초해상도 방법,2020,"['초해상도', 'CNN', 'Residual Block', 'Channel Attention', 'Spatial Attention', 'Super Resolution', 'CNN', 'Residual Block', 'Channel Attention', 'Spatial Attention']","본 논문은 채널 강조(Channel Attentin)와 공간 강조(Spatial Attention) 방법을 결합한 딥 러닝 기반의 초해상 도 방법을 제안하였다. 초해상도 과정에서 질감, 특징과 같은 주변 픽셀의 변화량이 큰 고주파 성분의 복원이 중요하다. 채널 강조와 공간 강조를 결합한 특징 강조를 이용한 초해상도 방법을 제안하였다. 기존의 CNN(Convolutional Neural Network) 기반의 초해상도 방법은 깊은 네트워크의 학습이 어려우며, 고주파 성분의 강조가 부족하여 윤곽선 이 흐려지거나 왜곡이 발생한다. 문제를 해결하기 위해 스킵-커넥션(Skip Connection)을 적용한 채널 강조와 공간 강조를 결합한 강조 블록과 잔차 블록(Residual Block)을 사용하였다. 방법으로 추출한 강조된 특징 맵을 부-픽셀 컨볼 루션(Sub-pixel Convolution)을 통해 특징맵을 확장하여 초해상도를 진행하였다. 이를 통해 기존의 SRCNN과 비교 하여 약 PSNR는 5%, SSIM은 3% 향상되었으며 VDSR과 비교를 통해 약 PSNR는 2%, SSIM은 1% 향상된 결과를 보였다.","In this paper, we proposed a deep learning based super-resolution method that combines Channel Attention and Spatial Attention feature enhancement methods. It is important to restore high-frequency components, such as texture and features, that have large changes in surrounding pixels during super-resolution processing. We proposed a super-resolution method using feature enhancement that combines Channel Attention and Spatial Attention. The existing CNN (Convolutional Neural Network) based super-resolution method has difficulty in deep network learning and lacks emphasis on high frequency components, resulting in blurry contours and distortion. In order to solve the problem, we used an emphasis block that combines Channel Attention and Spatial Attention to which Skip Connection was applied, and a Residual Block. The emphasized feature map extracted by the method was extended through Sub-pixel Convolution to obtain the super resolution. As a result, about PSNR improved by 5%, SSIM improved by 3% compared with the conventional SRCNN, and by comparison with VDSR, about PSNR improved by 2% and SSIM improved by 1%."
"딥 러닝(Deep learning)기반 동영상 처리 알고리즘을 통한 19대 대선 TV토론 영상분석 : 후보자들의 등장빈도, 표정, 응시방향에 대한 분석",2020,"['Presidential TV debate', 'Artificial intelligence video analysis', 'Mixed model analysis', 'Facial expression classification algorithm', 'Politicians direction of gaze', '대선 TV토론', '인공지능 영상분석', '다층모형분석', '표정분류 알고리즘', '정치인의 응시방향']",,"This study analyzed the frequency of appearance and nonverbal messages of political candidates in the television debates for the 19th presidential election held in 2017. To analyze nonverbal messages, facial expressions (angry, irritated, satisfied, and neutral) and the direction of gaze in the six televison debates, a classification network was constructed using deep learning technology. For this analysis, videos of six television debates held for 120 minutes per episode were collected, and image data was extracted at the rate of 30 frames per second as a frame, which resulted in image data of approximately 1.25 million frames. After that, this study built an image-analyzing system through deep learning, which automatically recognizes and classifies candidates appearing in videos, and then analyzes video frames by their facial expressions and direction of gaze. Then, the system counts how often each candidate appeared during all television debates in seconds, and analyzes the proportion of facial expressions of the candidates during the entire television debates. The results showed that Sang-Jung Shim appeared the most over three debates, followed by Chul-soo Ahn in two debates and Jae-in Moon in one. The least appeared candidate was Jun-pyo Hong. As for the facial expression, Moon showed the most satisfactory facial expressions, and Seung-min Yoo expressed his emotion the least. Hong showed the irritated expression the most, indicating that he had difficulty managing his facial expression. Additionally, this study conducted a multi-level analysis combining the image data with a panel survey, which measured respondents preference of candidates before and after the presidential campaign, and the number of times they watched the debates. The multi-level analysis confirmed that the preferences of the candidates changed depending on the exposure to the facial expressions made by the candidates in the actual televison debates. As for the satisfactory expression and the expressionless face, the candidates were evaluated more positively as the expression exposure increased. In the case of the angry expression, the degree of candidate favorability decreased after the exposure. These results suggest that the viewers’ evaluations of the candidates changed substantially according to the candidates facial expressions in the debate. In an era where communication scholars are expanding their research areas by converging with new disciplines such as media engineering and data science, this study suggests a new research direction. We hope that this study lays the groundwork for the research on media analysis using algorithms and deep learning."
딥 러닝 기반의 영상분할 알고리즘을 이용한 의료영상 3차원 시각화에 관한 연구,2020,"['Augmented Reality', 'Deep Neural Network', 'Medical Training', 'Virtual Surgery Simulation']",,
딥 러닝 기반 실시간 센서 고장 검출 기법,2020,"['Sensor fault diagnosis', 'Convolution neural network', 'Inverted residual block', 'Raspberry pi']","최근 4차 산업혁명의 핵심기술인 인공지능, 빅데이터, 사물인터넷의 발전으로 산업 현장에서 가동되는 기계의자동화 및 무인화에 대한 연구가 활발히 진행되고 있다. 이러한 공정 기계들은 부착된 다양한 센서들로부터 수집된 데이터를 기반으로 제어되고 이를 통해 공정이 관리된다. 만약 센서에 고장이 발생한다면 센서 데이터 이상으로 인해 자동화기계들이 오작동함으로써 공정 손실 발생뿐만 아니라 인명피해로도 이어질 수 있다. 전문가가 센서의 이상 여부를 주기적으로 확인하여 관리하고 있으나 산업 현장의 여러 가지 환경요인 및 상황으로 인하여 고장점검 시기를 놓치거나 고장을 발견하지 못하여 센서 고장으로 인한 피해를 막지 못하는 경우가 발생하고 있다. 또한 고장이 발생하여도 즉각 감지하지 못함으로써 공정 손실을 더욱 악화시키고 있는 실정이다. 따라서 이러한 돌발적인 센서 고장으로 인한 피해를 막기위해 자체적으로 임베디드 시스템에서 센서의 고장 유무를 실시간으로 파악하고 빠른 대응을 위해 고장 진단 및 유형을판별하는 것이 필요하다. 본 논문에서는 대표적인 센서 고장 유형인 erratic fault, hard-over fault, spike fault, stuck fault를 분류하기 위해 딥 뉴럴 네트워크 기반의 고장 진단 시스템을 설계하고 라즈베리 파이를 활용하여 구현하였다. 센서 고장 진단을 위해 구글이 제안한 MobilieNetV2의 Inverted residual block 구조를 사용하여 네트워크를구성하였다. 본 논문에서 제안하는 방식은 기존 CNN 기법을 사용한 경우보다 메모리 사용량이 줄고 성능이 향상되며, 입력 신호에 대해 구간별로 센서 고장을 분류하여 산업 현장에서 효과적으로 사용될 것으로 기대된다.","Recently, research on automation and unmanned operation of machines in the industrial field has been conducted with the advent of AI, Big data, and the IoT, which are the core technologies of the Fourth Industrial Revolution. The machines for these automation processes are controlled based on the data collected from the sensors attached to them, and further, the processes are managed.Conventionally, the abnormalities of sensors are periodically checked and managed. However, due to various environmental factors and situations in the industrial field, there are cases where the inspection due to the failure is not missed or failures are not detected to prevent damage due to sensor failure.In addition, even if a failure occurs, it is not immediately detected, which worsens the process loss.Therefore, in order to prevent damage caused by such a sudden sensor failure, it is necessary to identify the failure of the sensor in an embedded system in real-time and to diagnose the failure and determine the type for a quick response. In this paper, a deep neural network-based fault diagnosis system is designed and implemented using Raspberry Pi to classify typical sensor fault types such as erratic fault, hard-over fault, spike fault, and stuck fault. In order to diagnose sensor failure, the network is constructed using Google's proposed Inverted residual block structure of MobilieNetV2. The proposed scheme reduces memory usage and improves the performance of the conventional CNN technique to classify sensor faults."
딥 러닝 기반의 초해상도 이미지 복원 기법 성능 분석,2020,"['Single image super-resolution', 'Deep learning', 'Wavelet transforms']",,"Convolutional Neural Networks (CNN) have been used extensively in recent times to solve image classification and segmentation problems. However, the use of CNNs in image super-resolution problems remains largely unexploited. Filter interpolation and prediction model methods are the most commonly used algorithms in super-resolution algorithm implementations. The major limitation in the above named methods is that images become totally blurred and a lot of the edge information are lost. In this paper, we analyze super resolution based on CNN and the wavelet transform super resolution method. We compare and analyze the performance according to the number of layers and the training data of the CNN."
하이브리드 피처 생성 및 딥 러닝 기반 박테리아 세포의 세분화,2020,"['Bio-cell Informatics', 'Bacterial Cell Segmentation', 'Autoencoder', 'Hybrid Feature', 'Artificial Neural Network', 'Deep Learning']",,"We present in this work a segmentation method of E. coli bacterial images generated via phase contrast microscopy using a deep learning based hybrid feature generation. Unlike conventional machine learning methods that use the hand-crafted features, we adopt the denoising autoencoder in order to generate a precise and accurate representation of the pixels. We first construct a hybrid vector that combines original image, difference of Gaussians and image gradients. The created hybrid features are then given to a deep autoencoder that learns the pixels’ internal dependencies and the cells’ shape and boundary information. The latent representations learned by the autoencoder are used as the inputs of a softmax classification layer and the direct outputs from the classifier represent the coarse segmentation mask.Finally, the classifier’s outputs are used as prior information for a graph partitioning based fine segmentation. We demonstrate that the proposed hybrid vector representation manages to preserve the global shape and boundary information of the cells, allowing to retrieve the majority of the cellular patterns without the need of any post-processing."
채널 상태 정보를 이용한 딥 러닝 기반 실내 위치 확인 시스템,2020,"['Indoor Positioning System', 'Channel State Information', 'Non-line-of-sight', 'Hybrid Deep Neural Network', 'Multiple Fingerprints']",,"Over the past few years, Wi-Fi signal based indoor positioning system (IPS) has been researched extensively because of its low expenses of infrastructure deployment. There are two major aspects of location-related information contained in Wi-Fi signals. One is channel state information (CSI), and one is received signal strength indicator (RSSI). Compared to the RSSI, the CSI has been widely utilized because it is able to reveal fine-grained information related to locations. However, the conventional IPS that employs a single access point (AP) does not exhibit decent performance especially in the environment of non-line-of-sight (NLOS) situations due to the reliability degeneration of signals caused by multipath fading effect. In order to address this problem, in this paper, we propose a novel method that utilizes multiple APs instead of a single AP to enhance the robustness of the IPS. In our proposed method, a hybrid neural network is applied to the CSIs collected from multiple APs. By relying more on the fingerprint constructed by the CSI collected from an AP that is less affected by the NLOS, we find that the performance of the IPS is significantly improved."
지능형 헤드헌팅 서비스를 위한 협업 딥 러닝 기반의 중개 채용 서비스 시스템 설계 및 구현,2020,"['Intelligent Recruitment', 'Headhunting', 'Filtering', 'Deep Learning', 'Recommendation']",,"In the era of the Fourth Industrial Revolution in the digital revolution is taking place, various attempts have been made to provide various contents in a digital environment. In this paper, agent-recruitment service system based on collaborative deep learning is proposed for the intelligent head hunting service. The service system is improved from previous research [7] using collaborative deep learning for more reliable recommendation results. The Collaborative deep learning is a hybrid recommendation algorithm using “Recurrent Neural Network(RNN)” specialized for exponential calculation, “collaborative filtering” which is traditional recommendation filtering methods, and “KNN-Clustering” for similar user analysis. The proposed service system can expect more reliable recommendation results than previous research and showed high satisfaction in user survey for verification."
워터마크 및 해상도 적응적인 영상 워터마킹을 위한 딥 러닝 프레임워크,2020,"['convolutional neural network', 'deep learning', 'robust blind watermarking', 'invisibility', 'watermark-adaptive', 'resolution-adaptive']",,"Recently, application fields for processing and using digital image contents in various forms and types are rapidly increasing. Since image content is high value-added content, the intellectual property rights of this content must be protected in order to activate the production and use of the digital image content. In this paper, we propose a deep learning based watermark embedding and extraction network. The proposed method is to maximize the robustness of the watermark against malicious/non-malicious attacks while preserving the invisibility of the host image. This network consists of a preprocessing network that changes the watermark to have the same resolution as the host image, a watermark embedding network that embeds watermark data while maintaining the resolution of the host image by three-dimensionally concatenating the changed host image and the watermark information, and a watermark extraction network that reduces the resolution and extracts watermarks. This network verifies the invisibility and robustness of the proposed method by experimenting with various pixel value change attacks and geometric attacks against various watermark data and host images with various resolutions, and shows that this method is universal and practical."
행정-정책 의사결정에서 머신러닝(machine learning) 방법론 도입의 정책적 함의: 기계의 한계와 증거기반 의사결정(evidence-based decision-making),2020,"['machine learning', 'evidence-based decision-making', 'rational model of decision-making', '머신러닝', '증거기반 의사결정', '합리적 의사결정']","머신러닝과 딥러닝 등 인공지능 기술의 급속한 발전은 행정-정책 분야에도 영향을 확대하고 있다. 이 연구는 전통적 행정-정책 의사결정 모형인 합리적 모형의 이론적 이상과 현실적 한계에 대한 검토를 바탕으로 최근 연구가 활발히 진행중인 머신러닝 기반 의사결정 사례를 행정-정책 의사결정 관점에서 분석함으로써 인공지능 기술의 행정-정책 분야 도입이 가져올 변화를 논의하고 다음과 같은 두 가지 함의를 도출하였다. 첫째, 분석 대상과 목표가 사전에 잘 수립된 구조화된 문제(structured problems)에서는 기계가 인간의 의사결정에 비해 훨씬 나은 성과를 보이는 것으로 나타나 합리적 의사결정의 구현 가능성이 높아지고 있다. 둘째, 미래를 위한 전략적 의사결정이나 지금까지 경험하지 못한 새로운 환경 변화에 대한 대처 등 기계가 학습할 데이터가 부족하거나 목표가 모호한 비구조화된 문제(unstructured problems)의 경우 인간의 메타(meta) 의사결정이 여전히 중요하다. 따라서 머신러닝 등 인공지능 기술을 행정-정책분야에 성공적으로 도입하려면 다음과 같은 세 가지 사항을 고려해야 한다. 첫째, 해당 분야가 머신러닝으로 구현해도 될 구조화된 문제 영역인지 혹은 인간의 판단이 필수적인 메타(meta) 의사결정 영역인지에 대한 구분이 선행해야 한다. 둘째, 구조화된 문제 영역으로 판단될 경우에도 어떠한 행정-정책 기준(예: 책임성, 효과성, 효율성)으로 알고리즘을 구현할 것인지에 대한 인간의 메타 의사결정이 필요하다. 셋째, 메타 의사결정의 질을 향상하기 위해 의사결정자는 일화적 경험(anecdotal experience)에 의존하는 대신 체계적(systematic)인 의사결정을 내릴 수 있도록 증거기반 의사결정(evidence-based decision-making)을 이해하고 실천해야 한다.","The present study explores the policy implications of the introduction of machine learning into public administration. We first briefly overview the theoretical implications and practical limitations of a rational decision-making perspective, focusing on its unrealistic assumptions. We then discuss the capability of machine learning–based decision-making that may overcome the limitations of human decision-making by reviewing recent research comparing the decision performance of machine learning algorithms with human decisions in the context of crowdlending. Our findings demonstrate that machine learning algorithms may outperform human decisions in structured problems, whereas human decisions are critical in unstructured problems such as meta-decisions(e.g., what to decide and how to decide). We draw three policy implications for the introduction of machine learning into public administration. First, public administrators and policymakers should determine the nature of the decision task; i.e., whether it is a structured problem or an unstructured problem that may require meta-decisions. Second, meta-decisions regarding the decision criteria (e.g., accountability, effectiveness) are required for machine learning algorithms aiming to resolve structured problems. Third, public administrators and policymakers should develop the ability and skills to implement evidence-based decision-making in order to make a high-quality meta-decision for unstructured problems."
크라우드센싱 시스템에서 머신러닝을 이용한 이상데이터 탐지,2020,"['Crowdsensing', 'Machine Learning', 'AutoML', 'Autoencoder', 'Anomaly Data Detection']","최근, 별도의 센서를 설치하지 않고 센서가 포함된 사용자의 기기로부터 제공되는 실시간 센싱 데이터를 가지고 새로운 센싱 서비스를 제공하는 크라우드센싱(Crowdsensing) 시스템이 주목받고 있다. 크라우드센싱 시스템에서는 사용자의 조작실수나 통신 문제로 인해 의미 없는 데이터가 제공되거나 보상을 얻기 위해 거짓 데이터를 제공할 수 있어 해당 이상 데이터의 탐지 및 제거가 크라우드센싱 서비스의 질을 결정짓는다. 이러한 이상데이터를 탐지하기 위해 제안되었던 방법들은 크라우드센싱의 빠른 변화 환경에 효율적이지 않다. 본 논문은 머신러닝 기술을 활용하여 지속적이고 빠르게 변화하는 센싱 데이터의 특징을 추출하고 적절한 알고리즘을 통해 모델링하여 이상데이터를 탐지하는 방법을 제안한다. 지도학습의 딥러닝 이진분류 모델과 비지도학습의 오토인코더 모델을 사용하여 제안 시스템의 성능 및 실현 가능성을 보인다.","Recently, a crowdsensing system that provides a new sensing service with real-time sensing data provided from a user’s device including a sensor without installing a separate sensor has attracted attention. In the crowdsensing system, meaningless data may be provided due to a user’s operation error or communication problem, or false data may be provided to obtain compensation. Therefore, the detection and removal of the abnormal data determines the quality of the crowdsensing service. The proposed methods in the past to detect these anomalies are not efficient for the fast-changing environment of crowdsensing. This paper proposes an anomaly data detection method by extracting the characteristics of continuously and rapidly changing sensing data environment by using machine learning technology and modeling it with an appropriate algorithm. We show the performance and feasibility of the proposed system using deep learning binary classification model of supervised learning and autoencoder model of unsupervised learning."
수요 패턴 별 최적 머신러닝 수요예측 모델 성능 비교,2020,"['장비수요예측', '군집화', '수요패턴분석', 'Repair Parts Demand Forecasting', 'Clustering', 'Demand Pattern Analysis']","수요예측은 제품에 대한 수요량을 예측해 자원을 관리하기 위한 방법으로, 기업의 노동력과 예산 관리에 영향을 미 친다. 이러한 이유로 수요예측 모델의 성능 향상을 위한 연구가 주목을 받고 있다. 본 연구에서는 수요예측 성능 향 상을 위해 품목의 수요 패턴을 분석해 4가지 유형으로 구분하고, 각 유형에 적합한 모델을 제안한다. 성능 비교를 위해 사용한 데이터는 대한민국 공군 T-50 단일 기종의 수리 부속 품목의 분기 별 수요 데이터이다. 품목의 수요 패턴은 수요발생구간(average demand interval, ADI)과 변동 계수(coefficient of variation, CV)를 사용해 네 가지 smooth, lumpy, intermittent, erratic으로 구분하며 다양한 알고리즘으로 구현한 수요예측 모델의 성 능을 비교하기 위해 5가지 기계학습 알고리즘과 2 가지 딥러닝 알고리즘을 사용해 수요예측 모델을 구현한다. 기계 학습 알고리즘 중에는 앙상블 알고리즘인 random forest regression, adaboost, extra trees regression, bagging, gradient boosting regression 과 딥러닝 알고리즘인 long-short term memory(LSTM), deep neural network(DNN)을 사용한다. 수요 패턴에 따른 네 가지 유형에 적합한 모델을 선정해 수요예측 결과를 도 출한 경우가 일관된 모델을 사용한 경우에 비해 품목 정확도가 0.61%, 수량 정확도가 0.09 우수한 것을 확인할 수 있다. 제안하는 모델을 적용한다면 전문가의 효율적인 수요 관리가 이루어질 수 있을 것으로 기대한다.","Demand forecasting is a way to manage resources by forecasting demands for products, so it has direct impacts on corporate resources and budget management. Based on these reasons, research on improving forecasting performances of demand forecasting models. In this research, 4 demand patterns for items were analyzed to improve demand prediction performance, and the optimal model was proposed. The data used to compare the performance were the demand data from each quarter for maintenance items for a T-50 aircraft of Republic of Korea air force. First, the demand patterns for the items adopted average demand interval(ADI) and coefficient of variation(CV) and were categorized into smooth, lumpy, intermittent, and erratic items. In this research, to compare the performance of demand forecasting models derived from different algorithms, 5 types of machine learning algorithms and 2 types of deep learning algorithms were used to construct demand forecasting models. In machine learning algorithms, there are ensemble learning such as random forest regression, adaboost, extra trees regression, bagging, gradient boosting regression and deep learning algorithm such as long-short term memory(LSTM) and deep neural network(DNN). We can confirm that item accuracy is 0.61% and quantity accuracy is 0.09% better than that of consistent models when the demand forecast results are derived by selecting models suitable for four types according to demand patterns. We expect that efficient demand management by experts will be achieved if the application of the proposed model."
안드로이드 악성코드 탐지를 위한 머신러닝 기술 활용 동향 및 권한정보를 활용한 악성코드 탐지,2020,"['Malware detection', 'Android application', 'Deep artificial neural network', '악성코드 탐지', '안드로이드', '딥러닝']","최근 스마트폰 시장이 증가함에 따라 모바일 악성코드에 대한 침해사고 탐지 건수가 지속해서 증가하고 있다. 사용자의 개인정보 탈취 목적 외에도 고도화된 스마트폰의 자원 점유를 목적으로 하는 악성코드가 출현하고 있으며 이에 따라 다양한 종류의 악성코드를 탐지하기 위한 기법이 요구되고 있다. 하지만 PC와 달리 모바일은 다양한 제약이 존재한다. 이는 악성코드가 활동하기 힘들게 만듦과 동시에 탐지 또한 어려워짐에 따라 한정된 자원을 사용한 효율적인 악성코드 탐지 기법이 개발되고 있다. 주된 악성코드 탐지 기법에는 시그니처 기반과 빅데이터를 기반으로 하는 클라우드 서버 기반의 탐지 방법이 존재한다. 하지만 이러한 악성코드 탐지 기법은 신종 및 변종 악성코드에 대한 신속한 대응이 어렵다는 한계점이 존재하며 권한 상승 공격을 통해 탐지 기법을 방해하거나 제거해버릴 위험성이 존재한다. 또한, 네트워크 통신의 문제로 잘못된 분석 결과를 응답받을 수도 있다. 이러한 이유로 최근에는 머신러닝 기반의 차세대 휴리스틱 탐지 기법에 대한 연구가 증가하고 있다. 본 논문에서는 2012년~2020년에 개발된 다양한 안드로이드 기반 악성코드 탐지 기법을 소개하며, 탐지에 사용한 알고리즘의 변화추세를 분석한다. 또한, 머신러닝에 학습을 위해 사용하는 데이터를 분류하고, 학습에 적합한 알고리즘들에 대한 특징을 정리하였으며 마지막으로 심층 인공신경망 및 권한 기반을 활용해 악성코드를 탐지한 결과를 제시한다.","With the recent increase in the smartphone market, the number of detections of infringement accidents against mobile malwares continues to increase. In addition to the purpose of stealing personal information, malwares for occupying resources of smartphones are emerging, and accordingly, techniques for detecting various types of malwares are required. However, unlike PC, mobile has various limitations. This makes it difficult for malwares to act and detection, thus efficient malware detection techniques using limited resources are being developed. The malware detection techniques include signature-based and cloud server-based methods. However, such a malware detection has a limitation in that it is difficult to quickly detect variants of known malwares or new ones, and there is a risk of interfering with or removing the detection method through an elevation attack. In addition, a result in incorrect analysis may be received due to a network communication problem. For this reason, research on next-generation heuristic detection techniques based on machine learning is increasing in recent years. This paper introduces various Android-based malware detection techniques developed from 2012 to 2020, and analyzes the trend of changes in algorithms used for detection. In addition, it classifies the data used for learning in machine learning, organizes the features of algorithms suitable for learning, and finally presents the result of detecting malwares using a deep artificial neural network and authority."
러닝의 가중치 초기화와 갱신에 의한 네트워크 침입탐지의 성능 개선에 대한 접근,2020,"['네트워크 침입 탐지', '딥러닝', '가중치 갱신', '가중치 초기화', 'Network Intrusion Detection', 'Deep Learning', 'Weight Update', 'Weight Initialization']","인터넷이 대중화되기 시작하면서 해킹 및 시스템과 네트워크에 대한 공격이 있어 왔고, 날로 그 기법들이 진화되면서 기업 및 사회에 위험과 부담감을 주었다. 그러한 위험과 부담감을 덜기 위해서는 조기에 해킹 및 공격을 탐지하여 적절하게 대응해야 하는데, 그에 앞서 반드시 네트워크 침입탐지의 신뢰성을 높일 필요가 있다. 본 연구에서는 네트워크 침입탐지 정확도를 향상시키기 위해 가중치 초기화와 가중치 최적화를 KDD’99 데이터셋에 적용하는 연구를 하였다. 가중치 초기화는 Xavier와 He 방법처럼 가중치 학습 구조와 관련된 초기화 방법이 정확도에 영향을 준다는 것을 실험을 통해 알 수 있었다. 또한 가중치 최적화는 현재 가중치를 학습률에 반영할 수 있도록 한 RMSProp와 이전 변화를 반영한 Momentum의 장점을 결합한 Adam 알고리즘이 정확도면에서 단연 돋보임을 네트워크 침입탐지 데이터셋의 실험을 통해 확인하였다.","As the Internet began to become popular, there have been hacking and attacks on networks including systems, and as the techniques evolved day by day, it put risks and burdens on companies and society. In order to alleviate that risk and burden, it is necessary to detect hacking and attacks early and respond appropriately. Prior to that, it is necessary to increase the reliability in detecting network intrusion. This study was conducted on applying weight initialization and weight optimization to the KDD’99 dataset to improve the accuracy of detecting network intrusion. As for the weight initialization, it was found through experiments that the initialization method related to the weight learning structure, like Xavier and He method, affects the accuracy. In addition, the weight optimization was confirmed through the experiment of the network intrusion detection dataset that the Adam algorithm, which combines the advantages of the Momentum reflecting the previous change and RMSProp, which allows the current weight to be reflected in the learning rate, stands out in terms of accuracy."
머신러닝을 이용한 철광석 가격 예측에 대한 연구,2020,"['머신러닝', '철광석 가격', '그레인저 인과관계', '시계열 예측', 'Machine learning', 'Price of iron ore', 'Granger causality', 'Time-series forecasting']","철광석의 가격은 여러 국가와 기업들의 수요와 공급에 따라서 높은 변동성이 지속되고 있다. 이러한 비즈니스 환경에서 철광석의 가격을 예측하는 것은 중요해졌다. 본 연구는 머신러닝 기법을 이용하여 철광석이 거래되는 시점으로부터 한 달 전에 철광석 거래가격을 미리 예측하는 모형을 개발하고자 하였다. 예측 모형은 시계열 데이터를 활용한 예측 방법론으로 많이 활용되고 있는 시차 분포 모형과 다층신경망 (Multi-layer perceptron), 순환신경망 (Recurrent neural network), 그리고 장단기 기억 네트워크 (Long short-term memory)와 같은 딥 러닝(Deep Learning) 모형을 사용하였다. 측정지표를 통해 개별 모형을 비교한 결과에 따르면, LSTM 모형이 예측 오차가 가장 낮은 것으로 나타났다. 또한, 앙상블 기법을 적용한 모형들을 비교한 결과, 시차분포와 LSTM의 앙상블 모형이 예측 오차가 가장 낮은 것으로 나타났다.","The price of iron ore has continued to fluctuate with high demand and supply from many countries and companies. In this business environment, forecasting the price of iron ore has become important. This study developed the machine learning model forecasting the price of iron ore a one month after the trading events. The forecasting model used distributed lag model and deep learning models such as MLP (Multi-layer perceptron), RNN (Recurrent neural network) and LSTM (Long short-term memory). According to the results of comparing individual models through metrics, LSTM showed the lowest predictive error. Also, as a result of comparing the models using the ensemble technique, the distributed lag and LSTM ensemble model showed the lowest prediction error."
Deep Learning-Based Object Detection and Target Selection for Image-Based Grasping Motion Control,2020,"['Deep learning (딥러닝)', 'Object detection (물체검출)', 'Grasping (파지)', 'Robotic prosthetic hand (로봇의수)']",,
고차원 빅데이터 분석을 위한 통계모형 개발,2020,"['고차원 자료', '딥러닝', '벌점회귀', '변수선택', 'Deep learning', 'high-dimensional data', 'penalized regression', 'variable selection']",고차원 자료는 관측값의 개수보다 변수의 개수가 과다하게 많은 것이 특징이다. 예측분석에서는 회귀분석 시 설명변수 사이의 다증공선성 문제 및 최소제곱추정량의 계산 문제를 해결하기 위하여 전통적인 변수선택 방법이나 벌점회귀를 주로 사용한다. 본 연구에서는 고차원 자료에 대한 딥러닝 회귀 및 분류문제에서 이러한 변수선택 방법이나 벌점회귀를 사용하는 것이 모형 평가 측도 및 학습 수행 완료 시간에 어떠한 영향을 주는지를 평가하였다.,"High-dimensional data is characterized by an excessive number of variables than the number of observations. In predictive analysis, traditional variable-selection method or penalized regression is mainly used to solve the problem of multi-collinearity among explanatory variables and of calculation of least-squares estimators in regression analysis. In this paper, we evaluated how the variable selection method or penalized regression affects the model evaluation measures and the completion time of learning in deep learning regression and classification problems for high-dimensional data."
LSTM을 활용한 부산항 컨테이너 물동량 예측,2020,"['container volumes forecasting', 'deep learning', 'LSTM', '컨테이너 물동량 예측', '딥러닝']","해운항만물류산업은 세계 경제활동과 밀접한 관계를 가지고 있으며, 특히 무역의존도가 높은 우리나라의 항만 시설은 중요한 사회간접자본시설이다. 부산항은 우리나라 최대의 항만으로 우리나라 컨테이너 운송의 75%가 부산항을 통해 운송되고 있으며, 국가 경쟁력 측면에서 그 중요성은 매우 크다. 항만 물동량 예측은 항만 개발 및 운영 전략에 영향을 미치며, 정확도 높은 컨테이너 물동량 예측은 필수적이다. 하지만 오늘날 해운항만물류산업 환경의 급격한 변화로 인해 기존 시계열 예측 방법으로는 예측 정확도 향상에 어려움이 있다. 본 연구에서는 부산항 컨테이너 물동량 예측 정확도 향상을 위해 딥러닝 모형 중 LSTM 모형을 활용하여 컨테이너 물동량을 예측한다. 모형의 성능 평가를 위해서 SARIMA 모형과 LSTM 모형의 예측 정확도를 비교한다. 그 결과 LSTM 모형이 SARIMA 모형보다 예측 정확도가 높게 나타났으며, 예측치가 실측치의 특성을 반영하여 잘 나타나고 있음을 확인하였다.","The maritime and port logistics industry is closely related to global trade and economic activity, especially for Korea, which is highly dependent on trade. As the largest port in Korea, Busan Port processes 75% of the country’s container cargo; the port is therefore extremely important in terms of the country’s national competitiveness. Port container cargo volume forecasts influence port development and operation strategies, and therefore require a high level of accuracy. However, due to unexpected and sudden changes in the port and maritime transportation industry, it is difficult to increase the accuracy of container volume forecasting using existing time series models. Among deep learning models, this study uses the LSTM model to enhance the accuracy of container cargo volume forecasting for Busan Port. To evaluate the model’s performance, the forecasting accuracies of the SARIMA and LSTM models are compared. The findings reveal that the forecasting accuracy of the LSTM model is higher than that of the SARIMA model, confirming that the forecasted figures fully reflect the actual measurement figures."
비정형 문서에서 감정과 상황 정보를 이용한 감성 예측,2020,"['감성 예측', '오피니언 마이닝', '상황 정보', '딥러닝', '자연어 처리', 'Sentiment Prediction', 'Opinion Mining', 'Context Information', 'Deep Learning', 'NLP']",,
LSTM 오토인코더를 이용한 라디에이터 고장진단 사례연구,2020,"['오토인코더', 'LSTM', '고장진단', '이상치 탐색', '고장 예지 및 건전성관리', '딥러닝', '진동', 'Autoencoder', 'LSTM', 'Fault Diagnosis', 'Anomaly detection', 'Prognostics and Health Management', 'Deep learning', 'Vibration']","본 논문에서는 LSTM 오토인코더를 이용하여 라디에이터의 고장진단을 수행하였다. 먼저 라디에이터의 내구연한 랜덤 가진 시험에서 진동 신호를 취득하였으며, Raw data에 10초 단위로 Window를 씌워 시간영역 통계적 특징 을 추출하여 변수로 설정하고 Sliding 기법으로 데이터를 증강하였다. 데이터는 4개의 Stage로 구분되며, Stage 1(정상)만을 훈련 데이터로 사용하고 Stage 2, 4(정상, 비정상) 데이터를 이용하여 모델 최적화 및 평가를 수행하 였다. LSTM 오토인코더 모델의 은닉층과 은닉층 노드의 수, Dropout 비율 및 L2 정규화 파라미터를 최적화하고 평가 결과, ROC 곡선에서 AUC 가 0.9942로 우수한 성능을 확인하였다. 그리고 레이블이 없는 Stage 3의 상세 고장시점을 LSTM 오토인코더로 진단할 수 있었다. 또한 임계점을 조정하여 LSTM 오토인코더의 재구성오차가 임 계점을 초과할 때 고장을 진단할 시, 고장 발생 시점보다 조기에 라디에이터 고장을 예측 진단할 수 있었다.","In this paper, a fault diagnosis of the radiator was performed using the LSTM autoencoder. At first, the vibration signal of radiator were acquired in the random vibration durability test. And the time domain statistical features were extracted from data with 10 seconds window augmented by the sliding technique. The data is divided into 4 stages, and stage 1 (normal) is used as a training data. In addition, the LSTM autoencoder model is optimized and evaluated using stage 2, 4 (normal, abnormal) data. The number of hidden layers and nodes, dropout rate and L2 regularization parameters of the LSTM autoencoder model have been optimized. As a result, the area under the ROC curve was 0.9942 confirming excellent performance. Then the detailed failure point of unlabeled stage 3 was diagnosed using LSTM autoencoder. In addition, fault diagnosis was performed when the reconstruction error of the LSTM autoencoder exceeds the adjusted threshold. As a result, the radiator failure could be predicted earlier than before a failure occurs."
센서 융합을 통한 물체 거리 측정 및 인식 시스템,2020,"['YOLOv3', 'Vision', 'Radar', 'Senser fution', 'FMCW', 'radar']","본 논문에서는 자율주행 자동차에 물체를 인식하고 거리를 측정하는데 효율적인 센서 융합을 제안한다. 자율주행 자동차에 사용되는 대표적인 센서는 레이더, 라이다, 카메라이다. 이 중 라이다 센서는 차량 주변의 맵을 만드는 역할을 한다. 하지만 날씨 조건에 성능이 하락하고 센서의 가격이 매우 비싸다는 단점 있다. 본 논문에서는 이러한 단점을 보완하고자 비교적 저렴하고 눈, 비, 안개에 지장 없는 레이더 센서로 거리를 측정하며 차량 주변을 관찰한다. 물체 인식률이 뛰어난 카메라 센서를 융합하여 물체 인식 및 거리를 측정한다. 융합된 영상은 IP서버를 통해 실시간으로 스마트폰에 전송되어 현재 차량의 상황을 내부, 외부에서 판단하는 자율주행 보조 시스템에 사용될 수 있다.","In this paper, we propose an efficient sensor fusion method for autonomous vehicle recognition and distance measurement. Typical sensors used in autonomous vehicles are radar, lidar and camera. Among these, the lidar sensor is used to create a map around the vehicle. This has the disadvantage, however, of poor performance in weather conditions and the high cost of the sensor. In this paper, to compensate for these shortcomings, the distance is measured with a radar sensor that is relatively inexpensive and free of snow, rain and fog. The camera sensor with excellent object recognition rate is fused to measure object distance. The converged video is transmitted to a smartphone in real time through an IP server and can be used for an autonomous driving assistance system that determines the current vehicle situation from inside and outside."
초고해상도 기반 비대면 저해상도 영상의 얼굴 인식 시스템,2020,"['Super-resolution', 'Face Recognition', 'Feature Extraction']",,
CNN 잡음 감쇠기에서 커널 사이즈의 최적화,2020,"['잡음 감쇠', '심층학습', '커널 크기', 'CNN', 'Noise reduction', 'Deep learning', 'Convolutional neural network', 'Kernel size']","본 논문은 음향잡음감쇠기에서 CNN(Convolutional Neural Network) 계층의 커널 사이즈가 성능에 미치는 영향을 위한 연구하였다 이 시스템은 기존의 적응필터를 이용하는 대신 신경망 적응예측필터를 이용한 심층학습 알고리즘으로 잡음감쇠 성능을 개선한다. 100-neuron, 16-filter CNN 필터와 오차 역전파(back propagation) 알고리즘을 이용하여 잡음이 포함된 단일입력 음성신호로부터 음성을 추정한다. 이는 음성신호가 갖는 유성음 구간에서의 준주기적 성질을 이용하는 것이다. 본 연구에서 커널 사이즈에 대한 잡음감쇠기의 성능을 검증하기 위하여 Tensorflow와 Keras 라이브러리를 사용한 시뮬레이션 프로그램을 작성하고 모의실험을 수행하였다. 모의실험 결과, 커널 사이즈가 16 정도일 때 MSE 및 MAE 값이 가장 작은 것으로 나타났으며 사이즈가 이보다 더 작거나 커지면 MSE 및 MAE 값이 증가하는 것을 볼 수 있다. 이는 음성신호의 경우 커널 사이즈가 16 정도일 때 특성을 가장 잘 포집할 수 있음을 알 수 있다.","In this paper, we studied the effect of kernel size of CNN(Convolutional Neural Network) layer on performance in acoustic noise attenuators. This system uses a deep learning algorithm using a neural network adaptive prediction filter instead of using the existing adaptive filter. Speech is estimated from a single input speech signal containing noise using a 100-neuron, 16-filter CNN filter and an error back propagation algorithm. This is to use the quasi-periodic property in the voiced sound section of the voice signal. In this study, a simulation program using Tensorflow and Keras libraries was written and a simulation was performed to verify the performance of the noise attenuator for the kernel size. As a result of the simulation, when the kernel size is about 16, the MSE and MAE values are the smallest, and when the size is smaller or larger than this, the MSE and MAE values increase. It can be seen that in the case of an speech signal, features can be best captured when the kernel size is about 16."
인공지능 기반의 자동차사고 감지 시스템 적용 사례 분석,2020,"['Automobile Accident Prevention System', 'Artificial Intelligence', 'Machine Learning', 'Deep Learning', 'e-Call Service']",,
AI 의료영상 분석의 개요 및 연구 현황에 대한 고찰,2020,"['인공지능', '의료영상', '딥 러닝', '인공신경망', 'Artificial Intelligence', 'Medical Imaging', 'Deep Learning', 'Artificial Neural Network']",,"Artificial intelligence(AI) is a field of computer science that is defined as allowing computers to imitate human intellectual behavior, even though AI s performance is to imitate humans. It is grafted across software-based fields with the advantages of high accuracy and speed of processing that surpasses humans. Indeed, the AI based technology has become a key technology in the medical field that will lead the development of medical image analysis. Therefore, this article introduces and discusses the concept of deep learning-based medical imaging analysis using the principle of algorithms for convolutional neural network(CNN) and back propagation. The research cases application of the AI based medical imaging analysis is used to classify the various disease(such as chest disease, coronary artery disease, and cerebrovascular disease), and the performance estimation comparing between AI based medical imaging classifier and human experts."
Inception V3를 이용한 흉부촬영 X선 영상의 폐렴 진단 분류,2020,"['폐렴', '인공지능', '딥러닝', '폐렴 검출', '흉부 X선 촬영영상', 'Pneumonia', 'Artificial Intelligence', 'Deep learning', 'Pneumonia Detection', 'Chest X-ray image']","4차 산업의 발전으로 의학·보건·바이오 등 여러 과학기술 분야에서는 질병을 예방하고 질병에 대한 피해를 줄이기 위한 연구가 이루어지고 있으며, 최근에는 ICT 기술의 발전과 더불어 인공지능 기술이 급부상하고 그 효용성이 입증되면서 영상의학 검사의 영상 분석에 인공지능 기술이 도입되어 연구되고 있다. 본 논문에서는 흉부 X선 영상을 이용하여 폐렴의 분류와 검출에 대한 딥러닝 모델을 직접 적용해보고 실제로 Inception 계열의 딥러닝 모델이 폐렴 검출에 있어 유용한 모델인지 평가하고자 한다. 실험재료는 캐글(Kaggle)에서 무료로 제공 및 공유하는 흉부 X선 영상 데이터 세트를 사용하였으며 전체 3,470개의 흉부 X선 영상 데이터 중 학습 데이터 세트 1,870개, 검증 데이터 세트 1,100개, 테스트 데이터 세트 500개로 분류하였다. 실험결과 Inception V3 딥러닝 모델의 Metric 평가에 대한 결과값은 정확도는 94.80%, 정밀도는 97.24%, 재현율은 94.00%, F1 스코어는 95.59의 결과값을 나타내었다. 그리고 흉부 X선 영상의 페렴 검출 및 분류에 대하여 Inception V3 딥러닝 모델링에 대한 최종 에포크의 정확도는 학습 모델링의 경우 94.91%, 검증 모델링은 89.68%의 정확도를 나타내었다. 손실함수 값의 평가는 학습 모델링은 1.127%, 검증 모델링은 4.603%의 손실함수 값을 나타내었다. 이러한 결과로 Inception V3 딥러닝 모델은 흉부영상 데이터의 특징 추출 및 분류에 있어 매우 우수한 딥러닝 모델이며 학습상태 또한 매우 우수하다고 평가하였다. 테스트 모델링에 대한 매트릭스 정확도 평가 결과 정상 흉부 X선 영상 데이터의 경우 96% ,폐렴 흉부 X선 영상 데이터의 경우 97%의 정확도가 입증되었다. Inception 계열의 딥러닝 모델의 경우 흉부 질환의 분류에 있어 유용한 딥러닝 모델이 될 것이라고 판단되며 인력의 보조적인 역할 또한 수행할 수 있을 것이라고 기대되어 부족한 의료인력 문제에도 해결점이 될 것이라고 사료된다. 향후 딥러닝을 이용한 폐렴의 진단에 대한 유사 연구 시 본 연구는 유사 연구의 기초자료로 제시될 것이라고 기대된다.","With the development of the 4th industrial, research is being conducted to prevent diseases and reduce damage in various fields of science and technology such as medicine, health, and bio. As a result, artificial intelligence technology has been introduced and researched for image analysis of radiological examinations. In this paper, we will directly apply a deep learning model for classification and detection of pneumonia using chest X-ray images, and evaluate whether the deep learning model of the Inception series is a useful model for detecting pneumonia. As the experimental material, a chest X-ray image data set provided and shared free of charge by Kaggle was used, and out of the total 3,470 chest X-ray image data, it was classified into 1,870 training data sets, 1,100 validation data sets, and 500 test data sets. I did. As a result of the experiment, the result of metric evaluation of the Inception V3 deep learning model was 94.80% for accuracy, 97.24% for precision, 94.00% for recall, and 95.59 for F1 score. In addition, the accuracy of the final epoch for Inception V3 deep learning modeling was 94.91% for learning modeling and 89.68% for verification modeling for pneumonia detection and classification of chest X-ray images. For the evaluation of the loss function value, the learning modeling was 1.127% and the validation modeling was 4.603%. As a result, it was evaluated that the Inception V3 deep learning model is a very excellent deep learning model in extracting and classifying features of chest image data, and its learning state is also very good. As a result of matrix accuracy evaluation for test modeling, the accuracy of 96% for normal chest X-ray image data and 97% for pneumonia chest X-ray image data was proven. The deep learning model of the Inception series is considered to be a useful deep learning model for classification of chest diseases, and it is expected that it can also play an auxiliary role of human resources, so it is considered that it will be a solution to the problem of insufficient medical personnel. In the future, this study is expected to be presented as basic data for similar studies in the case of similar studies on the diagnosis of pneumonia using deep learning."
인공지능 기술 기반 OTT 사용자 분석 방안,2020,"['OTT', '사용자 분석', '머신러닝', '딥러닝', 'OTT', 'Consumer Analysis', 'Machine Learning', 'Deep Learning']","OTT 사용이 급증하면서 관련 시장이 급변하고 있다. 특히 네트워크 사업자들의 경우 OTT로 인한 트래픽이 급증하면 서, 요금제 책정, 인프라 투자 등에 있어 소비자들의 OTT 트래픽을 분석하는 것이 필수적이다. 또한, OTT를 제공하는 업체 역시 사용자의 정확한 소비패턴 분석이 자체 독점 콘텐츠 제공, 네트워크망 이용료 지불 등 경영전략 수립에 도움이 된다. 본 연구에서는 OTT 사용자들의 트래픽을 분석하여 사용자를 분석하는 방법을 제안한다. 사용자 분류를 위해 널리 활용되는 머신러닝 기법들을 기반으로 분석을 해보았다. 또한, 다양한 분야에서 주목받고 있는 딥러닝 기법을 통한 분석 방법도 제안하였다. 머신러닝을 활용할 경우 높은 정확도를 보이면서 비교적 빠른시간에 분석이 가능함을 확인할 수 있었다. 딥러닝을 활용하여 분석할 시, 기존 머신러닝 기법 대비 정확도가 높게 나타난다. 본 연구에서 제안하는 기법을 통해 사업자는 OTT 사용자를 분석함으로써 맞춤형 요금제 책정, 효율적인 인프라 투자, 경쟁력 있는 콘텐츠 발굴 등이 가능하다. 또한, 딥러닝을 통해 OTT 사용자 분석이 가능함을 확인하였기에 정확한 분석이 필요할 때 딥러닝을 활용할 수 있을 것이다.","As the use of OTT such as YouTube and Netflix is increasing rapidly, the media and network market is also changing rapidly. In particular in the case of network operators, as the traffic caused by OTT increases rapidly, it has become essential to analyze the OTT traffic of consumers in pricing plans and infrastructure investment. In addition, companies that provide OTT also help establish management strategies such as providing their own proprietary content and paying network usage fees for OTT users. In this study, we propose a method to analyze users by analyzing the traffic of OTT users. First of all, we classified users based on machine learning techniques that are traditionally used for user classification. In addition, a method for classifying OTT users through deep learning techniques, which has recently attracted attention in various fields, has also been proposed. When analyzing users based on machine learning, it was confirmed that analysis was possible in a relatively fast time while showing high accuracy. When analyzing OTT users using deep learning, it can be seen that the accuracy is higher than that of existing machine learning techniques. The techniques proposed in this study enable network operators and OTT operators to more accurately classify OTT users, enabling them to set customized plans, invest in efficient infrastructure and discover competitive content. In addition, it has been confirmed that OTT user analysis is possible through deep learning, so many operators will be able to use deep learning when accurate analysis is required."
Variational Autoencoder를 이용한 교량 손상 위치 추정방법,2020,"['교량 손상 위치 추정', 'Variational Autoencoder (VAE)', '딥러닝', '비지도학습', 'Bridge damage localization', 'Variational Autoencoder (VAE)', 'Deep learning', 'Unsupervised learning']","구조물 건전도 모니터링 시스템을 기반하는 교량 딥러닝 손상 추정 기법들은 대부분 지도학습을 기반으로 하고 있다. 지도학습의 특성상 손상 위치 추정 딥러닝 모델의 학습을 위해 교량의 손상 위치를 나타내는 라벨(Label) 데이터와 이에 따른 교량의 거동 데이터가 필요하다. 하지만 실제현장에서 손상 위치 라벨 데이터를 정확히 얻어내는 것은 매우 어려운 일이므로, 지도학습 기반 딥러닝은 현장 적용성이 떨어진다는 한계가 있다. 반면에, 비지도학습 기반 딥러닝은 이러한 라벨 데이터 없이도 학습이 가능하다는 장점이 있다. 이러한 점에 착안하여 본 연구에서는 비지도 학습의 대표적인 딥러닝 기법인 Variational Autoencoder를 활용한 교량 손상 위치 추정의 방법을 제안하고 검증하였으며, 그 결과, 교량 손상위치 추정을 위한 VAE의 적용 가능성을 보였다.","Most deep learning (DL) approaches for bridge damage localization based on a structural health monitoring system commonly use supervised learning-based DL models. The supervised learning-based DL model requires the response data obtained from sensors on the bridge and also the label which indicates the damaged state of the bridge. However, it is impractical to accurately obtain the label data in fields, thus, the supervised learning-based DL model has a limitation in that it is not easily applicable in practice. On the other hand, an unsupervised learning-based DL model has the merit of being able to train without label data. Considering this advantage, thisstudy aims to propose and theoretically validate a damage localization approach for bridges using a variational autoencoder, a representative unsupervised learning-based DL network: as a result, this study indicated the feasibility of VAE for damage localization"
A Feasibility Study on Application of a Deep Convolutional Neural Network for Automatic Rock Type Classification,2020,"['Rock type classification', 'Deep learning', 'ResNet', 'Rock sample image dataset', '암종 분류', '딥러닝', '레즈넷', '암석 샘플 이미지 데이터셋']","암종 분류은 현장의 지질학적 또는 지반공학적 특성 파악을 위해 요구되는 매우 기본적인 행위이나 암석의 성인, 지역, 지질학적 이력 특성에 따라 동일 암종이라 하여도 매우 다양한 형태와 색 조성을 보이므로 깊은 지질학적 학식과 경험 없이는 쉬운 일은 아니다. 또한, 다른 여러 분야의 분류 작업에서 딥러닝 영상처리 기법들이 성공적으로 적용되고 있으며, 지질학적 분류나 평가 분야에서도 딥러닝 기법의 적용에 대한 관심이 증대되고 있다. 따라서, 본 연구에서는 동일 암종임에도 다양한 형태와 색을 갖게 되는 실제 상황을 감안하여, 정확한 자동 암종 분류를 위한 딥러닝 기법의 적용 가능성에 대해 검토하였다. 이러한 기법은 향후에 현장 암종분류 작업을 수행하는 현장 기술자들을 지원할 수 있는 효과적인 툴로 활용 가능할 것이다. 본 연구에서 사용된 딥러닝 알고리즘은 매우 깊은 네트워크 구조로 객체 인식과 분류를 할 수 있는 것으로 잘 알려진 ’ResNet’ 계열의 딥러닝 알고리즘을 사용하였다. 적용된 딥러닝에서는 10개의 암종에 대한 다양한 암석 이미지들을 학습시켰으며, 학습 시키지 않은 암석 이미지들에 대하여 84% 수준 이상의 암종 분류 정확도를 보였다. 본 결과로 부터 다양한 성인과 지질학적 이력을 갖는 다양한 형태와 색의 암석들도 지질 전문가 수준으로 분류해 낼 수 있는 것으로 파악되었다. 나아가 다양한 지역과 현장에서 수집된 암석의 이미지와 지질학자들의 분류 결과가 학습데이터로 지속적으로 누적이 되어 재학습에 반영된다면 암종분류 성능은 자동으로 향상될 것이다.","Rock classification is fundamental discipline of exploring geological and geotechnical features in a site, which, however, may not be easy works because of high diversity of rock shape and color according to its origin, geological history and so on. With the great success of convolutional neural networks (CNN) in many different image-based classification tasks, there has been increasing interest in taking advantage of CNN to classify geological material. In this study, a feasibility of the deep CNN is investigated for automatically and accurately identifying rock types, focusing on the condition of various shapes and colors even in the same rock type. It can be further developed to a mobile application for assisting geologist in classifying rocks in fieldwork. The structure of CNN model used in this study is based on a deep residual neural network (ResNet), which is an ultra-deep CNN using in object detection and classification. The proposed CNN was trained on 10 typical rock types with an overall accuracy of 84% on the test set. The result demonstrates that the proposed approach is not only able to classify rock type using images, but also represents an improvement as taking highly diverse rock image dataset as input."
An Experimental Comparison of CNN-based Deep Learning Algorithms for Recognition of Beauty-related Skin Disease,2020,"['Deep Learning', 'CNN', 'Beauty-related Skin Disease Recognition', 'Image Recognition', 'Algorithm Comparison', 'Experimental Comparison', '딥러닝', '피부미용 질환 인식', '이미지 인식', '알고리즘 비교', '실험적 비교']","본 논문에서는 딥러닝 지도학습 알고리즘을 사용한 학습 모델을 대상으로 미용 관련 피부질환 인식의 효과성을 실험적으로 비교한다. 최근 딥러닝 기술을 산업, 교육, 의료 등 다양한 분야에 적용하고 있으며, 의료 분야에서는 중요 피부질환 중 하나인 피부암 식별의 수준을 전문가 수준으로 높인 성과를 보이고 있다. 그러나 아직 피부미용과 관련된 질환에 적용한 사례가 다양하지 못하다. 따라서 딥러닝 기반 이미지 분류에 활용도가 높은 CNN 알고리즘을 비롯하여 ResNet, SE-ResNet을 적용하여 실험적으로 정확도를 비교함으로써 미용 관련 피부질환을 판단하는 효과성을 평가한다. 각 알고리즘을 적용한 학습 모델을 실험한 결과에서 CNN의 경우 평균 71.5%, ResNet은 평균 90.6%, SE-ResNet은 평균 95.3%의 정확도를 보였다. 특히 학습 깊이를 다르게하여 비교한 결과 50개의 계층 구조를 갖는 SE-ResNet-50 모델이 평균 96.2%의 정확도로 미용 관련 피부질환 식별을 위해 가장 효과적인 결과를 보였다. 본 논문의 목적은 피부 미용과 관련된 질환의 판별을 고려하여 효과적인 딥러닝 알고리즘의 학습과 방법을 연구하기 위한 것으로 이를 통해 미용 관련 피부질환 개선을 위한 서비스 개발로 확장할 수 있을 것이다.","In this paper, we empirically compare the effectiveness of training models to recognize beauty-related skin disease using supervised deep learning algorithms. Recently, deep learning algorithms are being actively applied for various fields such as industry, education, and medical. For instance, in the medical field, the ability to diagnose cutaneous cancer using deep learning based artificial intelligence has improved to the experts level. However, there are still insufficient cases applied to disease related to skin beauty. This study experimentally compares the effectiveness of identifying beauty-related skin disease by applying deep learning algorithms, considering CNN, ResNet, and SE-ResNet. The experimental results using these training models show that the accuracy of CNN is 71.5% on average, ResNet is 90.6% on average, and SE-ResNet is 95.3% on average. In particular, the SE-ResNet-50 model, which is a SE-ResNet algorithm with 50 hierarchical structures, showed the most effective result for identifying beauty-related skin diseases with an average accuracy of 96.2%. The purpose of this paper is to study effective training and methods of deep learning algorithms in consideration of the identification for beauty-related skin disease. Thus, it will be able to contribute to the development of services used to treat and easy the skin disease."
석유가스 개발사업의 인공지능기술 활용 현황 및 전망,2020,"['인공지능', '석유가스 개발사업', '디지털 전환', '머신러닝', '딥러닝', 'Artificial Intelligence', 'Oil and Gas E&P Business', 'Digital Transformation', 'Machine Learning', 'Deep Learning']","이 연구는 디지털 전환의 시대를 맞이하여 석유가스 개발사업의 인공지능기술 활용 현황과 전망을 살펴본다. 인공지능, 머신러닝, 딥러닝에 대한 간략한 소개를 시작으로 석유가스 개발사업에서 인공지능이 어떻게 활용되는지, 다양한 인공지능기술 중 최근 석유가스 개발사업에서 각광받는 딥러닝 기술의 종류에 대한 소개, 국내외 석유가스개발사업의 딥러닝 기술 활용 현황과 전망, 고찰, 그리고 맺음말로 구성하였다. 이를 토대로 디지털 전환의 시대에서석유가스 개발사업이 대처하고 나아가야 할 방안에 대하여 논하고자 한다.","This study reviewed the current status and prospects of using artificial intelligence (AI) technology in oil and gas exploration and production (E&P) in facing the era of digital transformation. Beginning with a brief introduction to artificial intelligence, machine learning (ML), and deep learning (DL), this manuscript discusses the following: the use artificial intelligence in E&P projects, an introduction to the state-of-the-art deep learning techniques highlighted in recent E&P projects, an analysis of the trends in global and domestic E&P business, relevant considerations, and concluding remarks. Thus, how the oil and gas E&P business is encouraged to cope with and move forward in the era of digital transformation is examined in detail."
심층강화학습을 이용한 Convolutional Network 기반 전산화단층영상 잡음 저감 기술 개발,2020,"['심층강화학습', '잡음저감', '전산화단층영상', '영상품질', 'Deep reinforcement learning', 'Denoising', 'Computed tomography', 'Image quality']","전산화단층영상 품질 개선을 위해 사용되는 지도학습 기반의 딥러닝 기술은 사전 학습을 위해 많은 양의 데이터를 필요로 하는 단점이 있다. 또한 지도학습 기반의 딥러닝 기술은 학습에 사용된 영상의 특징과 학습된 모델에 입력된 영상의 특징이 다른 경우 영상 내부 구조적 왜곡이 유발되는 한계점이 있다. 본 연구에서는 기존 지도학습 기반 딥러닝 기술의 단점을 보완하고 전산화단층영상의 잡음을 감소시킬 수 있는 심층강화학습 기반 영상화 모델을 개발하였다. 심층강화학습 기반 영상화 모델은 shared, value 및 policy 네트워크로 구성하였으며, 영상 잡음 특징 추출 및 모델의 성능 향상을 위해 합성곱, rectified linear unit(ReLU) 활성화 함수, dilation factor 및 게이트순환유닛을 사용하였다. 또한 기존 지도학습 기반 딥러닝 기술을 통해 획득한 영상의 영상품질 비교를 통해 본 연구에서 개발한 영상화 모델의 성능을 평가하였다. 연구결과 기존 기술에 비해 본 연구에서 개발한 영상화 모델 적용 시 전산화단층영상의 정량적 정확도는 큰 폭으로 향상, 잡음은 큰 폭으로 감소함을 확인하였다. 또한 영상화 모델 학습 시 사용한 영상과 구조적 특징이 다른 영상에 대해서도 잡음 감소 효과를 확인하였다. 따라서 본 연구에서 개발한 심층강화학습 기반 영상화 모델을 통해 전산화단층영상의 구조적 특징을 보전함과 동시에 잡음을 감소시킬 수 있다.","Supervised deep learning technologies for improving the image quality of computed tomography (CT) need a lot of training data. When input images have different characteristics with training images, the technologies cause structural distortion in output images. In this study, an imaging model based on the deep reinforcement learning (DRL) was developed for overcoming the drawbacks of the supervised deep learning technologies and reducing noise in CT images. The DRL model was consisted of shared, value and policy networks, and the networks included convolutional layers, rectified linear unit (ReLU), dilation factors and gate rotation unit (GRU) in order to extract noise features from CT images and improve the performance of the DRL model. Also, the quality of the CT images obtained by using the DRL model was compared to that obtained by using the supervised deep learning model. The results showed that the image accuracy for the DRL model was higher than that for the supervised deep learning model, and the image noise for the DRL model was smaller than that for the supervised deep learning model. Also, the DRL model reduced the noise of the CT images, which had different characteristics with training images. Therefore, the DRL model is able to reduce image noise as well as maintain the structural information of CT images."
심층신경망 모형을 활용한 대중교통 이용자의 환승시간 추정에 관한 연구,2020,"['Transfer Time', 'Deep Learning', 'Deep Neural Network', 'Regression', 'Smart Card Data', '환승시간', '딥러닝', '심층신경망', '회귀모형', '교통카드데이터']","환승시간은 대중교통계획 및 정책 수립에 있어서 중요한 요소이다. 이에 본 연구에서는 교통카드 이용자료를 활용하여 대중교통 이용자의 환승시간 영향요인을 규명하고, 딥러닝 기법인 심층신경망 모형을 이용한 환승시간을 추정하였으며 이를 전통적인 회귀모형과 비교 분석하였다. 먼저 환승시간 영향요인의 경우, 주변 버스의 배차간격과 버스 정류장까지의 거리가버스 환승시간에 양의 영향을 주었으며, 버스 노선수는 반대로 음의 영향을 주었다. 또한 지하철역이 속해있는 자치구에 따라서도 환승시간에 영향을 주는 것으로 나타났다. 도출된 환승시간 영향요인을 통해 딥러닝 모형을 구축하고 성능을 비교한 결과, 회귀모형보다 딥러닝 모형의 성능이 보다 우수하였다. 본 연구의 결과는 지역별 환승허용시간의 차등 적용 등 대중교통환승정책의 기초 자료로 활용될 수 있을 것으로 판단된다.","The transfer time is an important factor in establishing public transportation planning and policy. Therefore, in this study, the influencing factors of the transfer time for transit users were identified using smart card data, and the estimation results for the transfer time using the deep learning method such as deep neural network models were compared with traditional regression models. First, the intervals and the distance to the bus stop had positive effects on the subway-to-bus transfer time, and the number of bus routes had a negative effect. This also showed that the transfer time is affected by the area in which the subway station exists. Based on the influencing factors of the transfer time, the deep learning models were developed and their estimation results were compared with the regression model. For model performance, the deep learning models were better than those of the regression models. These results can be used as basic data for transfer policies such as the differential application of transit allowance times according to region."
Framework for Efficient Web Page Prediction using Deep Learning,2020,"['Deep learning', 'Framework', 'Web page prediction', 'Web log', 'Log preprocessing', 'MapReduce model', '딥러닝', '프레임워크', '웹 페이지 예측', '웹 로그', '로그 전처리', '맵/리듀스 모델']",웹에서 접근하는 정보의 폭발적인 증가에 따라 사용자의 다음 웹 페이지 사용을 예측하는 문제의 중요성이 증가되었다. 사용자의 다음 웹 페이지 접근을 예측하는 방법 중 하나가 딥 러닝 기법이다. 웹 페이지 예측 절차는 데이터 전처리 과정을 통해 웹 로그 정보들을 분석하고 딥 러닝기법을 이용하여 분석된 웹 로그 결과를 가지고 사용자가 접근할 다음 웹 페이지를 예측한다. 본 논문에서는 웹 페이지 예측을 위한 효율적인 웹 로그 전처리 작업과 분석을 위해 딥 러닝 기법을 사용하는 웹 페이지 예측 프레임워크를 제안한다. 대용량 웹 로그 정보의 전처리 작업 속도를 높이기 위하여 Hadoop 기반 맵/리듀스(MapReduce) 프로그래밍 모델을 사용한다. 또한 웹 로그 정보의 전처리 결과를 이용한 학습과 예측을 위한 딥 러닝 기반 웹 예측 시스템을 제안한다. 실험을 통해 논문에서 제안한 방법이 기존의 방법과 비교하여 성능 개선이 있다는 사실을 보였고 아울러 다음 페이지 예측의 정확성을 보였다.,"Recently, due to exponential growth of access information on the web, the importance of predicting a user’s next web page use has been increasing. One of the methods that can be used for predicting user’s next web page is deep learning. To predict next web page, web logs are analyzed by data preprocessing and then a user’s next web page is predicted on the output of the analyzed web logs using a deep learning algorithm. In this paper, we propose a framework for web page prediction that includes methods for web log preprocessing followed by deep learning techniques for web prediction. To increase the speed of preprocessing of large web log, a Hadoop based MapReduce programming model is used. In addition, we present a web prediction system that uses an efficient deep learning technique on the output of web log preprocessing for training and prediction. Through experiment, we show the performance improvement of our proposed method over traditional methods. We also show the accuracy of our prediction."
OpenFaaS 기반 AI 분석 서비스 시스템 구축,2020,"['AIaaS', 'OpenFaaS', 'Docker', 'Deep Learning', 'Data Analysis', 'AIaaS', 'OpenFaaS', '도커', '딥러닝', '데이터 분석']","5G 네트워크와 사물인터넷 기술의 빠른 발전과 보급으로 빅 데이터 분석 기술 및 서비스 시스템에 대한 요구가 증가하고 있다. 특히, AI 기술 활용에 대한 폭발적인 수요 증가로 수집된 데이터에서 새로운 의미를 추출할 수 있는 머신/딥러닝 모델의 활용을 위한 경쟁이 치열해 지고 있다. 다양한 분야에서 AI 기술을 도입하기 위해서는 고성능 GPU를 탑재한 시스템을 구축하고 딥러닝 모델을 실행하기 위한 복잡한 설정을 할 필요가 있다. AI 기술을 활용하기 위해 소요되는 노력을 줄이기 위해, AIaaS 플랫폼은 사전준비과정 및 운영을 위한 복잡함을 클라우드 인프라에 감추고, AI 연구개발자들이 고성능 AI 분석기술을 쉽게 활용할 수 있게 하는 온라인 서비스로써 큰 주목을 끌고 있다. 본 논문에서는 딥 러닝 모델 등록부터 온라인 서비스 운영에 이르기까지 Docker 및 OpenFaaS 기반 AI 서비스 생성을 지원할 수 있는 새로운 AIaaS 시스템을 제안한다. 또한 제안 시스템에서 AI 서비스를 쉽게 생성, 활용하는 방법을 보여주는 사례 연구도 설명한다.","Due to the rapid development and dissemination of 5G communication and IoT technologies, there are increasing demands for big data analysis techniques and service systems. In particular, explosively growing demands on AI technology adoption are also causing high competitions to take advantages of machine/deep-learning models to extract novel values from enormously collected data. In order to adopt AI technology to various research and application domains, it is necessary to prepare high-performance GPU-equipped systems and perform complicated settings to utilze deep learning models. To relieve the efforts and lower the barrier to utilize AI techniques, AIaaS(AI as a service) platform is attracting a great deal of attention as a promising on-line service, where the complexity of preparation and operation can be hidden behind the cloud side and service developers only need to utilize the high-level AI services easily. In this paper, we propose an AIaaS system which can support the creation of AI services based on Docker and OpenFaaS from the registration of models to the on-line operation. We also describe a case study to show how AI services can be easily generated by the proposed system."
디지털 분석 기법을 활용한 시조 연구 방법 탐색 -『한국시조대사전』 수록 단형시조를 중심으로-,2020,"['Artificial Intelligence Humanities', 'Digital Humanites', 'Digital Analysis Technique', 'hierarchy analysis', 'similarity analysis', 'deep learning', 'semantic search', 'sijo', 'Korean Sijo Dictionary', '인공지능인문학', '디지털인문학', '디지털 분석 기법', '계층 분석', '유사도 분석', '딥러닝', '의미 검색', '시조', '한국시조대사전']","인류는 이른바 제4차 산업혁명으로 일컬어지는 급격한 변화를 마주하고 있다. 이는 인류의 삶에 커다란 변화를 주고 있고, 문학 연구 또한 예외가 아니다. 본고는 이러한 변화에 부합하여, 변화하는 시대에 맞는 새로운 고전문학 연구 방법론을 디지털 분석 기법의 활용이라는 측면에서 탐색해 보고자한 시도이다. 이를 위하여 『한국시조대사전』(박을수 편저, 서울, 아세아문화사, 1992)에 수록된 4,736수의 시조 작품 중에서 장형시조를 제외한 4,127수를 대상으로 하여 계층 분석과 딥러닝을 활용한 디지털 분석 작업을 진행하였다.  먼저 계층 분석을 통해서 수록 편수가 30수 이상인 13명의 작가에 대한 작가별 시조 유사도 분석을 실시하였으며, 그 결과로 어휘와 어휘의 조합 양태가 유사한 4개의 그룹을 추출할 수 있었다. 다음으로는 딥러닝을 통하여 1600~1800년대까지의 작품을 대상으로 시조 창작 연대를 예측할 수 있는 모델을 구현해 보았다. 시기별로 예측의 정확도가 동일하지는 않았으나, 향후 작가 미상의 작품들이 창작된 연대를 예측하고, 연대별 작품의 특성을 살필 수 있는 가능성을 확인할 수 있었다. 끝으로, 기존에 형태소가 일치되는 시조만을 검색할 수 있었던 전통적인 검색 방법에서 한 걸음 나아가, 시조에 대한 딥러닝 의미 검색을 구현해 보았다. 이를 통하여 검색하고자 하는 키워드나 문장(Query)과 형태소가 일치하지 않더라도 내용적으로 유사한 의미를 지닌 작품을 유사도가 높은 순으로 추출할 수 있었다. 이는 방대한 분량의 시조작품을 주제별, 혹은 키워드 별로 분류하고 분석하는 작업에 소요되는 시간을 대폭 줄일 수 있다는 점에서 그 의미를 찾을 수 있을 것으로 생각한다.  이상에서 살펴본 디지털 분석 기법을 활용한 연구 방법이 오롯이 전통적인 연구방법을 대체할 수는 없겠지만, 새로운 시대의 흐름에 부합하는 새로운 연구 방법의 모색과 시도라는 점에서 나름의 의의를 확보할 수 있기를 기대한다.","Humanity is facing a drastic change called the Fourth Industrial Revolution. This is changing human life, and literary research is no exception. In line with these changes, this paper is an attempt to explore new classical research methodologies for the changing times in terms of the use of digital analysis techniques. For this purpose, out of 4,736 sijo works contained in the “Korean Sijo Dictionary” (Park Eul-Su, Asiaculturehistory publishing house, 1992), 4,127 sijo works were conducted, with the exception of janghyeong sijo, to conduct digital analysis using hierarchical analysis and deep learning.  First of all, through hierarchical analysis, 13 writers with more than 30 episodes were analyzed for the similarity of the progenitor, and as a result, four groups with similar vocabulary and vocabulary combinations were extracted. Next, through deep learning, we have implemented a model that can predict the age of creation of sijo for works from 1600 to 1800s. Although the accuracy of the predictions was not the same for each period, it was possible to predict the date in which the unknown works of the artist were created in the future and to examine the characteristics of the works by regiment. Finally, we took a step further from the traditional search method in which only the morphemes were able to search for matching sijos, and implemented deep learning semantic search for sijo. This enabled the extraction of works with similar meaning in content in order of high similarity, even if the keywords or sentences that were to be searched and the morphemes did not match. I think this will be meaningful in that it will significantly reduce the time required to classify and analyze vast amounts of sijo works by subject or keyword.  Although research methods using digital analysis techniques discussed above may not replace traditional research methods, it is hoped that they will be able to secure their own significance in that they are seeking and attempting new research methods in line with the trend of the new era."
소멸위기 언어 보존을 위한 VUI 기반 서비스의 활용 가능성 연구 - 제주방언의 번역 서비스를 중심으로 -,2020,"['Deep learning', 'Dead Language', 'Tongue', 'Translation', 'TTS']","소멸위기 언어는 언어 구사의 빈도가 줄어들면서 소멸되는 언어체계를 뜻한다. 이러한 소멸위기 언어가 완전히 사라지면 사어가 된다. 사어가 되면 언어를 다시 활성화하는 것은 어렵다. 따라서, 언어가 사어가 되지 않도록 보존하는 것은 문화보존 측면에서 중요한 일이다. 본 연구는 소멸위기 언어로서 지정된 제주도 방언을 보존할 수 있는서비스를 제안한다. 이는 딥러닝으로 구현되는 TTS 기반의 VUI 서비스이다. 최근에 등장한 딥러닝 TTS는 약 40분의 녹음으로 특정 인물에 대한 언어적 버릇을 그대로 구현할 수 있게 되었다. 이에 따라, 현재 기업에서는 사용자자신의 목소리를 다양하게 활용할 수 있는 딥러닝 TTS 서비스를 제시하고 있다. 이러한 상황을 바탕으로, 본 연구는제주도 사투리를 딥러닝으로 학습한 TTS를 통해서 언어 구사의 빈도를 줄어들지 않게 하는 방향을 제시하고자 한다.이를 위해서, 본 연구는 제주도 방언의 번역 서비스를 제시한다. 연구 결과, 제주도 출신과 수도권 출신은 제주도 방언 기반의 VUI 서비스에 긍정적 평가를 하였다. 또한, 출신의 차이에 따른 조절효과는 무의미하였다. 이를 통해, 전세계적으로 소멸위기 언어를 보존하면서 활용할 수 있는 딥러닝 기반의 TTS 서비스의 활용 가능성을 확인하였다.","In order to provide a satisfactory experience of use in mobile simple payment services, it is necessary to consider how to be safe and easy. After analyzing domestic simple payment services in this study, there were six stages of payment process in common, and the methods for each stage were provided differently for each service. These types were manufactured in prototypes to analyze, experienced by subjects, and then surveyed on simplicity, security and preferences. Studies have shown meaningful differences in ease of use, security, and preference for each type. While simplicity has a greater impact on preferences throughout the payment process, some of the steps close to personal information have been found to have a greater impact on security. We hope that the results of this study, which analyzed the simplicity and security of simple payment, will contribute to the development of the user experience of simple payment services."
메모리 효과를 갖는 시계열 데이터에서 다수의 노이즈 클리닝에 대한 연구,2020,"['Deep Learning', 'Time Series', 'Preprocessing', 'Noise', 'Data Cleaning', '딥러닝', '시계열', '전처리기', '노이즈', '데이터 클리닝']","딥러닝의 개발 프로세스는 대량의 수작업이 요구되는 반복적인 작업으로 그 중 학습 데이터 전처리는 매우 큰 비용이 요구되며 학습 결과에 중요한 영향을 주는 단계이다. AI의 알고리즘 연구초기에는 주로 데이터 과학자들에 의해 완벽하게 정리하여 제공된 공개 DB형태의 학습데이터를 주로 사용하였다. 실제 환경에서 수집된 학습 데이터는 주로 센서들의 운영 데이터이며 필연적으로 노이즈가 많이 발생할 수 있다. 따라서 노이즈를 제거하기 위한 다양한 데이터 클리닝 프레임워크와 방법들이 연구되었다. 본 논문에서는 IoT환경에서 발생 될 수 있는 센서 데이터와 같은 시계열 데이터에서 노이즈를 감지하고 제거하는 방법을 제안하였다. 이 방법은 선형회귀 방법을 사용하여 시스템이 반복적으로 노이즈를 찾아내고, 이를 대체할 수 있는 데이터를 제공하여 학습데이터를 클리닝한다. 제안된 방법의 효과를 검증하기 위해서 본 연구에서 시뮬레이션을 수행하여, 최적의 클리닝 결과를 얻을 수 있는 인자들의 결정 방법을 확인하였다.","The development process of deep learning is an iterative task that requires a lot of manual work. Among the steps in the development process, pre-processing of learning data is a very costly task, and is a step that significantly affects the learning results. In the early days of AI’s algorithm research, learning data in the form of public DB provided mainly by data scientists were used. The learning data collected in the real environment is mostly the operational data of the sensors and inevitably contains various noises. Accordingly, various data cleaning frameworks and methods for removing noises have been studied. In this paper, we proposed a method for detecting and removing noises from time-series data, such as sensor data, that can occur in the IoT environment. In this method, the linear regression method is used so that the system repeatedly finds noises and provides data that can replace them to clean the learning data. In order to verify the effectiveness of the proposed method, a simulation method was proposed, and a method of determining factors for obtaining optimal cleaning results was proposed."
가중치 오차함수를 통한 콘크리트 균열 감지 모델 학습 개선,2020,"['딥러닝', '콘크리트 균열', '균열 검출', '오차 함수', 'U-Net', 'Deep Learning', 'Concrete Crack', 'Crack Detection', 'Loss Function', 'U-Net']","본 연구에서는 가중치 오차 함수를 적용하여, 미세한 콘크리트 균열을 감지하는 U-Net 모델을만들 수 있도록 개선 방안을 제안한다. 콘크리트 균열은 안전을 위협하는 요소이기 때문에 그 상태를 주기적으로 파악하고 신속하게 초기 대응을 하는 것이 중요하다. 하지만 현재는 점검자가직접 육안으로 검사하고 평가하는 외관 검사법이 주로 사용되고 있다. 이는 정확성뿐만 아니라비용과 시간, 안전성 측면에서도 한계점을 가진다. 이에 콘크리트 구조물에 생성되는 미세한 균열을 신속하고 정밀하게 탐지할 수 있도록 딥러닝을 활용한 기술들이 연구되고 있다. 본 연구에서U-Net을 활용한 균열 탐지를 시도한 결과, 미세한 균열을 탐지하지 못하는 것을 확인하였다. 이에제시한 가중치 오차 함수를 적용하여 학습한 모델에 대해 성능을 검증한 결과, 정확도(Accuracy) 99% 이상, 조화평균(F1_Score) 89%에서 92%의 신뢰성 높은 수치를 도출해내었고, 미세한 균열을정확하고 선명하게 탐지한 결과를 통해 학습 개선 방안의 성능을 검증하였다.","In this study, we propose an improvement method that can create U-Net model which detect fine concrete cracks by applying a weighted loss function. Because cracks in concrete are a factor that threatens safety, it is important to periodically check the condition and take prompt initial measures. However, currently, the visual inspection is mainly used in which the inspector directly inspects and evaluates with naked eyes. This has limitations not only in terms of accuracy, but also in terms of cost, time and safety. Accordingly, technologies using deep learning is being researched so that minute cracks generated in concrete structures can be detected quickly and accurately. As a result of attempting crack detection using U-Net in this study, it was confirmed that it could not detect minute cracks. Accordingly, as a result of verifying the performance of the model trained by applying the suggested weighted loss function, a highly reliable value (Accuracy) of 99% or higher and a harmonic average (F1_Score) of 89% to 92% was derived. The performance of the learning improvement plan was verified through the results of accurately and clearly detecting cracks."
객체 탐지 모델을 활용한 전기 아크 위험성 예측 시스템 개발,2020,"['머신러닝', '전기 아크', '딥러닝', '예측 시스템', 'machine learning', 'electric arc', 'deep learning', 'prediction system']",전기에너지에 대한 높은 의존도 때문에 국내에서 발생하는 화재 중 전기화재가 상당한 비중을 차지한다. 국내에서 발생하는 전기화재 4건 중 3건이 전선의 단락이나 접촉 불량에 의한 전기 아크에 의해 발생했다. 전기 아크란 절연체 사이에서 발생하는 전기적 전류의 방전 현상으로 순간적으로 상당한 열을 내뿜는다. 아크에 의한 전기 화재를 줄이기 위해서 본 연구에서는 전기 아크 위험성 예측을 목표로 한다. 아크 감지기에서 아크 데이터를 수집하고 시간순대로의 아크 데이터를 기반으로 그래프로 변환하였다. 머신 러닝의 데이터 학습에 서로 다른 시계열 데이터의 수로 변환한 그래프들을 사용하였다. 생성된 학습 모델의 성능을 측정하기 위해서 테스트 데이터를 기반으로 평가를 진행하였다. 결과에서 예측 시 사용하는 시계열 아크 데이터의 수가 20개일 때 예측률이 86%로 우수함을 확인하였다.,"Due to the high dependence on electric energy, electric fires make up a significant portion of fires in Korea. Electric arcs by short circuits or poor contact cause three of four electrical fires. An electric arc is a discharge phenomenon of electrical current between the insulators, which instantaneously produces high temperature. In order to reduce the fire due to electric arc, this study aims to predict the electric arc risk. We collected arc data from the arc detectors and converted into graphs based on temporal arc data. We used machine learning for training converted graph with different number of temporal arc data. To measure the performance of the learning model, we use the test data. In the results, when the number of temporal arc data was 20, the prediction rate was high as 86%."
Deformable convolutional network를 기반으로 한 Mask R-CNN,2020,"['딥러닝', 'deformable convolutional network', 'mask R-CNN', '객체탐색', 'Deep learning', 'object detection']","객체 탐색은 자율 주행, 실시간 보안, 건설 자동화에서 활용될 수 있는 기술로서 각광 받고 있는 컴퓨터 비전 응용 기술이다. 최근 딥러닝을 기반으로 한 객체 탐색 모델이 등장하였고 딥러닝 기술의 발전과 함께 빠른 속도로 객체 탐색 모델들도 발전하고 있다. 객체 탐색 모델들은 대용량 크기의 입력값인 이미지를 처리하기 위해 공통적으로 CNN (convolutional neural network)를 사용한다. 하지만 CNN은 객체의 크기에 상관없이 공통된 필터를 사용하는 문제점이 있다. 본 연구에서는 오프셋 (offset)을 이용해 객체에 대응하는 필터를 만드는 Deformable convolutional network를 Mask R-CNN에 적용해 합성곱 네트워크의 문제점을 해결하고 객체 탐색 알고리즘의 정확도를 높이는 방법을 제안하고자 한다. 제안된 방법은 Pascal VOC와 COCO 데이터를 이용해 성능실험을 수행하였고, 기존의 Mask R-CNN 방법보다 성능이 개선되는 결과를 보였다.","Object detection is a computer vision application technology that is in spotlight as a technology that can be used in autonomous driving, real-time security and construction automation. Recently, object detection models based on deep learning has appeared, and object detection models are also developing at a rapid pace with the development of deep learning technology. Object detection models commonly use convolution neural network (CNN) to process a large size of image data. However, CNN has a problem of using a common filter regardless of the size of the object. In this paper, we propose a method to solve the problem of the CNN and improve the accuracy of objection detection algorithm by applying a deformable convolutional network that creates a filter corresponding to an object using an offset to Mask R-CNN. The proposed method is evaluated by an experiment using Pascal VOC and COCO data, and it can be shown that the proposed method outperforms the existing Mask R-CNN method."
Residual Multi-Dilated Recurrent Convolutional U-Net을 이용한 전자동 심장 분할 모델 분석,2020,"['딥러닝', '인공지능', '심장분할', '알고리즘', '인공신경망', '합성곱신경망', 'Deep Learning', 'Artificial Intelligence', 'Heart Segmentation', 'Algorithm', 'ANN', 'CNN']","본 논문에서는 딥 러닝 기반의 전-자동 심장 분할 알고리즘을 제안한다. 본 논문에서 제안하는 딥 러닝 모델은 기존 U-Net에 residual recurrent convolutional block과 residual multi-dilated convolutional block을 삽입하여 성능을 개선한 모델이다. 모델의 성능은 테스트 데이터 세트를 전-자동 분할한 결과와 영상의학 전문가의 수동 분할 결과를 비교하여 분석하였다. CT 영상에서 평균 96.88%의 DSC, 95.60%의 precision과 97.00%의 recall 결과를 얻었다. 분할된 영상은 3차원 볼륨 렌더링 기법을 적용하여 시각화한 후 관찰하여 분석할 수 있었다. 실험 결과를 통해 제안된 알고리즘이 다양한 심장 하부 구조를 분할하기에 효과적인 것을 알 수 있었다. 본 논문에서 제안하는 알고리즘이 전문의 또는 방사선사의 임상적 보조역할을 수행할 수 있을 것으로 기대한다.","In this paper, we proposed that a fully automatic multi-class whole heart segmentation algorithm using deep learning. The proposed method is based on U-Net architecture which consist of recurrent convolutional block, residual multi-dilated convolutional block. The evaluation was accomplished by comparing automated analysis results of the test dataset to the manual assessment. We obtained the average DSC of 96.88%, precision of 95.60%, and recall of 97.00% with CT images. We were able to observe and analyze after visualizing segmented images using three-dimensional volume rendering method. Our experiment results show that proposed method effectively performed to segment in various heart structures. We expected that our method can help doctors and radiologist to make image reading and clinical decision."
딥러닝기반의 금융회사 고객이탈 예측모형에 관한 연구 : 중소기업 금융에 대한 시사점 도출,2020,"['딥러닝', '고객이탈', '로지스틱', '의사결정나무', '신경망', '오토인코더', 'Deep Learning', 'Customer Leakage', 'Logistic Regression', 'Decision Tree', 'Neural Networks', 'AutoEncoder']","4차 산업혁명의 핵심은 빅데이터, 인공지능, 로봇공학, 사물인터넷, 무인 운송 수단, 3차원 인쇄, 나노 기술과 같은 분야에서 새로운 기술 혁신이다. 이에 따른 국내 금융환경은 급변하고 있으며, 디지털 전자금융 규제를 새로운 패러다임으로 제시함으로써 금융기관간의 경쟁은 심화되고 있다. 경쟁의 심화와 정보기술의 발달은 기업의 고객과 경쟁자 및 새로운 비즈니스 모델을 만들기 위한 방대한 규모의 데이터 베이스를 구축하여 왔으며 효율적 의사결정을 위한 대량의 데이터를 효과적으로 분석 및 정보화하고자 하는 노력이 증대되고 있다.고객의 이탈로 인한 기업의 재무적 성과측면에서는 음(-)의 영향을 미치고 있으며 기존 고객관리와 신규 고객유치를 위한 고객만족경영이 미래경영전략의 핵심요소가 되고 있다.최근 빅데이터 연구 분야에서는 활용되는 인공지능 기법을 활용한 딥러닝 기반 고객의 활동 유형등 측정 가능한 변수로 계량화 하는 방법을 적용하고 있으며, 최근 금융개방화와 자율화를 비롯한 금융계의 환경변화로 효과적이고 실질적인 생존전략이 필요한 시점이다.본 연구에서는 고객이탈 예측을 위한 데이터마이닝 기법중 로지스틱 회귀분석(Logistic regression), 의사결정나무(Decision Tree), 신경망 모형(Neural Networks)의 각 방법론별 결과분석을 통한 최적의 모형 평가를 진행하였으며, 세 모형 모두 양호한 예측률을 보였지만, 신경망모형의 예측률이 가장 정확하다는 결론을 얻었다. 또한, 오토인코더를 통하여 원인에 대한 결과를 분석하였다.향후 본 연구에서 적용한 방법론을 정책금융 수요예측 및 중소기업 분야에 적용시킬 필요가 있을 것으로 판단된다.",
다중 스케일 주의기반 네트워크을 통한 의료영상 분할,2020,"['의료 영상 분할', '딥러닝', '주의 네트워크', 'Medical Image Segmentation', 'Deep Learning', 'Attention Network']","딥러닝 기반 방법이 의료 이미지 분할에서 우수한 성능을 달성했지만 이러한 방법은 여전히 몇 가지 단점이 있다. 첫째, U-Net과 같은 인코더 디코더 구조에서 건너뛰는 연결을 사용할 경우 중복되는 특징과 불필요한 저수준 특징 정보를 다층의 스케일로 전달될 수 있다. 둘째, 이전 방법은 장거리 종속성을 수집 할 수 없으므로 특징 맵을 적절하 게 재구성하지 못한다. 이러한 문제를 완화하기 위해 본 논문에서는 서로 다른 수준에서 전체 상관 관계를 적응적으 로 탐지하고 주의 메커니즘을 활용하는 구조를 제안한다. 이 접근 방법은 지역 특징을 다른 수준으로 통합하고 노이 즈 및 원치 않는 정보를 억제하여 필수적인 특징을 강조한다. 제안하는 구조의 평가를 위해 Kvasir-SEG와 세포핵 분할 등의 두 가지 데이터셋을 이용하여 평가를 한다. 실험 결과에서 제안하는 모델의 정확도가 향상되고 기존의 방 법보다 우수한 성능을 보인다.","Even though deep learning(DL) based methods have been achieving superior performance in medical image segmentation, such methods still have some downsides. First, the use of skipconnections in encoder-decoder architecture like U-Net allows transferring redundant and superfluous low-level features information at multiple scales. Second, prior methods cannot capture long-range dependencies and hence fail to reconstruct the feature maps adeptly. To subdue these problems, we propose an architecture that adaptively captures global correlations from different scales and utilizes the attention mechanism. This approach integrates the local-features at different scales and underlines the essential features by suppressing noises and unwanted information. We evaluate the proposed architecture in the context of medical image segmentation on two different datasets: Kvasir-SEG and nuclei segmentation. Experimental results show that the proposed model yields better accuracy and outperforms previous methods."
SE-ResNeXt 기반 위험 소리 분류에 관한 연구,2020,"['딥러닝', '위험 소리 분류', '청각장애인', 'SE-ResNeXt', 'Deep Learning', 'Hazardous Sound Classification', 'Deaf People']","청각장애인은 일상생활에서 위험 소리를 듣지 못하여 위험에 많이 노출되고 있으며, 이를 해결하기 위해서 위험 소리를 인지하여 청각장애인에게 알려주는 기술이 필요하다. 최근 딥러닝을 적용하여 음향 이벤트를 분류하는 기술에 대한 연구는 진행되고 있지만, 위험 소리에 특화된 데이터 셋이 존재하지 않아 위험 소리를 분류하는 기술은 연구가 많이 진행되고 있지 않다. 따라서 본 논문에서는 10개의 범주에 대하여 26시간 규모의 위험 소리 데이터 셋을 구축하였다. 그리고 최신 합성곱 신경망 모델인 SE-ResNeXt을 사용하는 위험 소리 분류 방법을 제안하였다. 마지막으로 본 연구에서 구축한 위험 소리 데이터 셋을 사용하여 기존의 방법과 제안 방법의 분류 성능을 분석하였으며, 본 논문에서 제안한 SE-ResNeXt 기반의 위험 소리 분류 방법이 기존의 방법보다 뛰어난 분류 성능을 가지는 것을 실험 결과로 확인하였다.","Deaf people are exposed to a lot of dangerous situations since they are unable to hear hazardous sounds in their daily lives. In order to solve this problem, it is required a method that classifies hazardous sounds accurately and notifies dangerous situations to deaf people. Although there are many researches on classifying acoustic events based on deep learning technology, only a little has been going on for classifying dangerous sounds because there are no datasets especially configured for dangerous environments. Therefore, in this paper, we built a 26-hour long dataset for 10 hazardous sound categories to assess the classification performance. In addition, we proposed the SE-ResNeXt, which is the state-of-the-art convolutional neural networks model, as a method for classification. Finally, we compared the performances of the proposed method with existing methods, using our hazardous sound dataset. From the result of our experiment, we found out that the classification accuracy of SE-ResNeXt model is superior to that of pre-existing methods."
손글씨 인식 학습 모델 기반 수식 연산에 대한 연구,2020,"['딥러닝', '인식', '계산', 'Deep-Learning', 'Recognition', 'Calculation']","정보화 기술의 발달로 인해 문서 작성이나 브라우저 검색기능 같은 작업들이 모두 키보드 타이핑만으로 가능하게 되었다. 하지만 수학 계산식 같은 경우에는 키보드 타이핑으로 작성하기가 어려운 것을 알 수 있다. 계산식 같은 경우는 키보드가 아닌 아날로그 식으로 본인이 직접 수기하는 것이 시간도 절약되고 타이핑하는 것보다 오히려 편하다는 것을 알 수 있다. 그러기에 수학 계산식을 검색해서 답을 찾으려 할 때 사용자들은 불편함을 느끼게 된다.본 논문은 컴퓨터가 학습한 딥 러닝 모델로 수기로 작성된 수학 수식을 텍스트 형태로 바꿀 때, 더 정확하게 인식하는 모델의 종류가 무엇인지 제공한다. 숫자와 사칙 연산 기호뿐만 아니라 사용자가 정의한 연산자로도 정확한 인식이 가능한지를 확인한다. 이를 위해 DenseNet, ResNet과 같은 CNN 모델 이용하여 실험을 수행하였고, 실험을 통하여 그 중 가장 적합한 모델을 찾아내었다.",
인공지능에 대한 사용자 관점의 이해와 이를 응용한 이미지 효과 및 영상 편집 프로그램에 대한 고찰,2020,"['인공지능', '머신러닝', '딥러닝', '이미지 합성', '영상 편집', '애니메이션', 'AI', 'machine learning', 'deep learning', 'image compositing', 'video editing', 'animation']",2016년 알파고의 바둑 대국은 일반인도 인공지능이라는 단어를 인식하는 계기가 되었다. 인공지능은 애니메이션의 소재이기도 하지만 이미 생활 속에서 다양하게 사용 중이다. 어도비 포토샵은 2014년부터 머신러닝을 적용한 기능을 추가하였으며 현재는 이미지 합성과 영상 편집을 비롯한 다양한 분야에서 머신러닝을 적용한 소프트웨어들이 출시되고 있다. 오늘날 애니메이션 제작 공정은 거의 모든 과정에서 컴퓨터를 사용하므로 개발자 측면이 아닌 사용자 측면에서 인공지능의 개념을 이해하고 이를 활용한 소프트웨어의 기능이 어떤 것들이 있는지 살피고 정리해야할 필요성을 느꼈다. 이에 연구자는 인공지능에 대하여 직접 만든 이미지와 개념도를 활용하여 일반인 수준에서 이해할 수 있도록 기초적인 내용을 정리하고 어떻게 소프트웨어에 적용되는지 고찰하였다.연구 결과 이미지 합성 분야에서 어도비 포토샵은 AI기능을 사용한 여러 소프트웨어의 기능을 대부분 포함하고 있었으나 영상 편집 분야에서 프리미어는 아직 다른 AI기반 영상편집 프로그램들과는 전혀 다른 기능을 볼 수 있다. 이는 여러 AI기반 영상편집 프로그램들이 텍스트나 음악에 맞추어 영상을 선별하여 일반인들이 쉽게 만드는 것을 목적으로 하는 것과 달리 프리미어는 범용 툴로서 전문적인 영상 편집과 이미지 보정이 목적이기 때문이다.애니메이션은 청소년들과 젊은이들이 좋아하는 매력적인 영상물이자 빠른 시대를 그려 내는 창의적인 텍스트로서 애니메이션 종사자들은 열린 마음으로 새로움을 줄 수 모든 것을 기획에서부터 제작 전반에 적용하고자 노력하는 자세를 가져야 한다. 앞으로 AI를 기반으로 쉽고 재미있게 창작을 할 수 있는 어플리케이션이나 플랫폼이 더 많이 등장할 것으로 예상한다. 그러므로 지금까지 애니메이션 제작에서 스토리텔링 영상 콘텐츠를 목표로 하였다면 앞으로는 기획능력과 제작기술을 바탕으로 머신러닝 개발자들과 함께 퍼즐형 스토리 창작이나 템플릿을 이용한 캐릭터 애니메이션과 같이 누구나 쉽게 즐길 수 있는 창작도구 형태의 콘텐츠를 개발하는 것과 같이 더 넓은 시야를 가질 필요가 있다. 이러한 새로운 작업을 할 수 있는 기본 지식을 가르치고 배우는데 본 연구내용이 도움이 되기를 기대한다.,"In 2016, AlphaGo had a historical Go match with one of the best Go masters, and it created a chance for the general public to recognize the expression artificial intelligence(AI). AI is one of the materials in animation, but it already serves various uses in human life. Adobe Photoshop added machine learning-applied functions in 2014. Today there are many software programs applying machine learning in various fields including image synthesis and video editing. The computer is used in almost every stage of the animation production process these days, which raised a need to understand the concept of AI and examine and arrange AI-based software functions in the viewpoint of users instead of developers. The investigator thus arranged the basics and examined the ways that they were applied to software by making use of the images and concept diagrams made by himself so that any people could understand them.The findings show that Adobe Photoshop encompassed most of the various software functions based on AI in the field of image synthesis. In the field of video editing, Premiere featured completely different functions not found in other AI-based video editing programs. Unlike other AI-based video editing programs designed to select videos according to given texts or music and make it easy for common people to use them for creative purposes, Premiere has a goal of professional video editing and image correction as a universal tool.Animation is an attractive work of video that adolescents and youths like, providing creative texts to depict the fast-evolving times. Those who are involved in the field of animation need to have an open mind and attitude to make efforts to apply something new to the entire process from planning to production. It is expected that more applications and platforms will be created capable of easy and fun creation based on AI. The production of animation has pursued the goal of creating storytelling video content. In the future, it will be important to employ a broader viewpoint to develop content in the forms of creative tools that anyone can enjoy including machine learning developers based on the planning abilities and production skills. The findings of the present study will hopefully contribute to the efforts to teach and learn the basic knowledge for these new works."
한국어 기술문서 분석을 위한 BERT 기반의 분류모델,2020,"['문서분류', '딥러닝', '단어 임베딩', 'BERT', 'Document Classification', 'Deep Learning']","최근 들어 기술개발 현황, 신규기술 분야 출현, 기술융합과 학제 공동연구, 기술의 트렌드 변화 등을 파악하기 위해 R&D 과제정보, 특허와 같은 기술문서의 분류정보가 많이 활용되고 있다. 이러한 기술문서를 분류하기 위해 주로 텍스트마이닝 기법들이 활용되어 왔다. 그러나 기존 텍스트마이닝 방법들로 기술문서를 분류하기 위해서는 기술문서들을 대표하는 특징들을 직접 추출해야 하는 한계점이 있다. 따라서 본 연구에서는 딥러닝 기반의 BERT모델을 활용하여 기술문서들로부터 자동적으로 문서 특징들을 추출한 후, 이를 문서 분류에 직접 활용하는 모델을 제안하고, 이에 대한 성능을 검증하고자 한다. 이를 위해 텍스트 기반의 국가 R&D 과제 정보를 활용하여 BERT 기반 국가 R&D 과제의 중분류코드 예측 모델을 생성하고 이에 대한 성능을 평가한다.","It is necessary to classify technical documents such as patents, R&D project reports in order to understand the trends of technology convergence and interdisciplinary joint research, technology development and so on. Text mining techniques have been mainly used to classify these technical documents. However, in the case of classifying technical documents by text mining algorithms, there is a disadvantage that the features representing technical documents must be directly extracted. In this study, we propose a BERT-based document classification model to automatically extract document features from text information of national R&D projects and to classify them. Then, we verify the applicability and performance of the proposed model for classifying documents."
다중 스케일 영상을 이용한 GAN 기반 영상 간 변환 기법,2020,"['GAN', '딥러닝', 'GcGAN', '영상 간 변환', '다중 스케일', 'GAN', 'deep learning', 'GcGAN', 'image-to-image translation', 'multi-scale']","GcGAN은 기하학적 일관성을 유지하며 영상 간 스타일을 변환하는 딥러닝 모델이다. 그러나 GcGAN은 회전이나 반전(flip) 등의 한정적인 기하 변환으로 영상의 형태를 보존하기 때문에 영상의 세밀한 형태 정보를 제대로 유지하지 못하는 단점을 가지고 있다. 그래서 본 연구에서는 이런 단점을 개선한 새로운 영상 간 변환 기법인MSGcGAN(Multi-Scale GcGAN)을 제안한다. MSGcGAN은 GcGAN을 확장한 모델로서, 다중 스케일의 영상을 동시에 학습하여 스케일 불변 특징을 추출함으로써, 영상의 의미적 왜곡을 줄이고 세밀한 정보를 유지하는 방향으로 영상 간 스타일 변환을 수행한다. 실험 결과에 의하면 MSGcGAN은 GcGAN보다 정량적 정성적 측면에서 모두 우수하였고, 영상의 전체적인 형태 정보를 잘 유지하면서 스타일을 자연스럽게 변환함을 확인할 수 있었다.","GcGAN is a deep learning model to translate styles between images under geometric consistency constraint. However, GcGAN has a disadvantage that it does not properly maintain detailed content of an image, since it preserves the content of the image through limited geometric transformation such as rotation or flip.Therefore, in this study, we propose a new image-to-image translation method, MSGcGAN(Multi-Scale GcGAN), which improves this disadvantage. MSGcGAN, an extended model of GcGAN, performs style translation between images in a direction to reduce semantic distortion of images and maintain detailed content by learning multi-scale images simultaneously and extracting scale-invariant features. The experimental results showed that MSGcGAN was better than GcGAN in both quantitative and qualitative aspects, and it translated the style more naturally while maintaining the overall content of the image."
이미지를 사용한 가상의상착용을 위한 개선된 알고리즘,2020,"['가상착용', '딥러닝', '인간 표현', '성능 개선', '비용 함수', 'Virtual-try-on', 'Deep-learning', 'Human representation', 'Quality improvement', 'Loss function']","최근 이미지를 사용한 가상착용기술 (Virtual try-on: VTON)에 대한 일련의 연구들이 발표되었다. 이에 의상과 사용자 이미지를 사용한 대표적 방식 (SCMM 기반의 비-딥러닝 방식, 딥러닝 기반 VITON 과 CP-VITON)에 대해 인물의 자세 및 체형, 의상의 가려짐 정도, 의상의 특성 등에 따라 분석한 연구가 보고되었다. 본 논문에서는 이중 가장 좋은 성능을 보이는 CP-VTON의 문제점을 살펴보고 이에 따른 해결책을 제시한다. 구체적으로 대상인물의 분할 표현 문제, 교체 대상이 아닌 영역이 유지되지 못하는 문제, 합성 마스크 생성네트워크의 학습에 사용되는 비용함수 문제, 합성 네트워크의 마스크 문제를 지적하고 이를 개선하는 알고리즘을 제안하였다. 그 결과 SSIM 등에서 5%내외의 주관적으로는 상당한 개선을 보였다.","Recently, a series of studies on virtual try-on (VTON) using images have been published. A comparison study analyzed representative methods, SCMM-based non-deep learning method, deep learning based VITON and CP-VITON, using costumes and user images according to the posture and body type of the person, the degree of occlusion of the clothes, and the characteristics of the clothes. In this paper, we tackle the problems observed in the best performing CP-VTON. The issues tackled are the problem of segmentation of the subject, pixel generation of un-intended area, missing warped cloth mask and the cost function used in the learning, and limited the algorithm to improve it. The results show some improvement in SSIM, and significantly in subjective evaluation."
LSTM을 이용한 주가예측 모델의 학습방법에 따른 성능분석,2020,"['LSTM', '딥러닝', '주가', '하이퍼파라미터', '예측 모델', 'LSTM', 'Stock Price', 'Deep Learning', 'Hyper-parameter', 'Prediction Model']","과거 인공지능 분야에서는 지식 기반의 전문가 시스템 및 머신러닝 알고리즘들을 금융 분야에 적용하는 연구가 꾸준하게 수행되어 왔다. 특히 주식에 대한 지식 기반의 시스템 트레이딩은 이제 보편화되었고, 최근에는 대용량 데이터에 기반한 딥러닝 기술을 주가 예측에 적용하기 시작했다. 이중 LSTM은 시계열 데이터에 대한 검증된 모델로서 주가 예측에도 적용되고 있다. 본 논문에서는 주가 예측 모델로서 LSTM을 적용할 때 성능향상을 위해 고려해야 할 복잡한 매개변수 설정과 적용 함수들에 대해 적합한 조합 방법을 제안하도록 한다. 크게 가중치와 바이어스에 대한 초기화 대상과 설정 방법, 과적합을 피하기 위한 정규화 적용 대상과 설정 방법, 활성화 함수 적용 방법, 최적화 알고리즘 선택 등을 제시한다. 이 때 나스닥 상장사들에 대한 대용량 데이터를 바탕으로 각각의 방법들을 적용하여 정확도를 비교하면서 평가한다. 이를 통해 주가 예측을 위한 LSTM 적용 시 최적의 모델링 방법을 실증적인 형태로 제안하여 현실적인 시사점을 갖도록 한다. 향후에는 입력 데이터의 포맷과 길이, 하이퍼파라미터들에 대한 성능평가를 추가 수행하여 주요 설정 항목들의 조합에 대한 일반화 연구를 수행하고자 한다.","Many developments have been steadily carried out by researchers with applying knowledge-based expert system or machine learning algorithms to the financial field. In particular, it is now common to perform knowledge based system trading in using stock prices. Recently, deep learning technologies have been applied to real fields of stock trading marketplace as GPU performance and large scaled data have been supported enough. Especially, LSTM has been tried to apply to stock price prediction because of its compatibility for time series data. In this paper, we implement stock price prediction using LSTM. In modeling of LSTM, we propose a fitness combination of model parameters and activation functions for best performance. Specifically, we propose suitable selection methods of initializers of weights and bias, regularizers to avoid over-fitting, activation functions and optimization methods. We also compare model performances according to the different selections of the above important modeling considering factors on the real-world stock price data of global major companies. Finally, our experimental work brings a fitness method of applying LSTM model to stock price prediction."
Research on Stock price prediction system based on BLSTM,2020,"['BLSTM', '딥러닝', '인공지능 주가분석', '빅데이터', '예측 시스템', 'BLSTM', 'Deep Learning', 'AI Stock Prediction', 'Big Data', 'Prediction System']","4차산업혁명의 핵심인 인공지능 기술은 인간의 능력을 뛰어넘어 주식예측에도 적용하고 있으면 예측이 불가능 한 것을 딥러닝 기법과 머신러닝을 통하여 지능화된 판단을 내리고 있는 실정이다. 미국의 펀드매니지먼트 회사에서는 증시 에널리스트의 역할을 인공지능이 대신하고 있으며, 이 분야의 연구가 활발히 진행 중에 있다. 본 연구에서는 BLSTM을 이용하여 기존의 LSTM방식의 단방향 예측에서 발생하는 오류를 줄이고, 양방향으로 예측하여 예측에 대한 오류를 줄이고, 주식 가격에 영향을 미치는 거시 지표, 즉 경제성장률, 경제지표, 이자율, 무역수지, 환율, 통화량을 분 석한다. 거시 지표 분석 후에 개별 주식에 대한 PBR, BPS, ROE 예측과 가장 주식 가격에 영향을 미치는 외국인, 기관, 연기금 등 매수와 매도 물량을 분석하여 주식의 목표주가를 정확히 예측하여 주식 투자에 도움을 주기 위해 본 연구를 수행했다.","Artificial intelligence technology, which is the core of the 4th industrial revolution, is making intelligent judgments through deep learning techniques and machine learning that it is impossible to predict if it is applied to stock prediction beyond human capabilities. In US fund management companies, artificial intelligence is replacing the role of stock market analyst, and research in this field is actively underway. In this study, we use BLSTM to reduce errors that occur in unidirectional prediction of the existing LSTM method, reduce errors in predictions by predicting in both directions, and macroscopic indicators that affect stock prices, namely, economic growth rate, economic indicators, interest rate, analyze the trade balance, exchange rate, and volume of currency. To help stock investment by accurately predicting the target price of stocks by analyzing the PBR, BPS, and ROE of individual stocks after analyzing macro-indicators, and by analyzing the purchase and sale quantities of foreigners, institutions, pension funds, etc., which have the most influence on stock prices."
도메인 적응을 이용한 단일 파노라마 깊이 추정,2020,"['깊이 추정', '딥러닝', '도메인 적응', '구형 파노라마', '단일 이미지', 'depth estimation', 'deep learning', 'domain adaptation', 'spherical panorama', 'single image']","본 연구에서는 360 ◦ 파노라마의 깊이 영상을 추정하는 딥러닝 구조를 제안한다. 이전 연구들에서는 딥러닝 네트워크를 학습시키기 위해 렌더링된 360 ◦ 파노라마 데이터 셋을 사용했다. 하지만, 렌더링된 파노라마 데이터 셋은 실제로 촬영된 파노라마데이터 셋과 다르기 때문에, 이전 연구들의 네트워크는 실제로 촬영된 파노라마에 대해선 깊이 영상을 정확히 추정할 수가없었다. 이 문제를 해결하기 위해 본 연구에서는 도메인 적응을 사용해서 렌더링된 파노라마와 실제로 촬영된 파노라마가 공유하는 특징들을 네트워크가 학습하게 했다. 실험을 통해 우리의 방식이 렌더링된 파노라마에 대해선 우수한 성능을 유지하면서 실제로 촬영된 파노라마에 대해서도 정확한 깊이 영상을 추정하는 것을 볼 수 있다.","In this paper, we propose a deep learning framework for predicting a depth map of a 360 ◦ panorama image. Previous works use synthetic 360 ◦ panorama datasets to train networks due to the lack of realistic datasets. However, the synthetic nature of the datasets induces features extracted by the networks to differ from those of real 360 ◦ panorama images, which inevitably leads previous methods to fail in depth prediction of real 360 ◦ panorama images. To address this gap, we use domain adaptation to learn features shared by real and synthetic panorama images. Experimental results show that our approach can greatly improve the accuracy of depth estimation on real panorama images while achieving the state-of-the-art performance on synthetic images."
복수의 엣지 디바이스에서의 CNN 모델 분산 처리를 위한 축소된 분류 모델 활용 기법,2020,"['기계 학습', '딥러닝', '합성곱 신경망', '엣지 컴퓨팅', '분산 컴퓨팅', 'machine learning', 'deep learning', 'convolutional neural networks', 'edge computing', 'distributed computing']","최근 클라우드 서버로 전송되는 막대한 양의 데이터로 인해 발생하는 네트워크 부하 등의 여러 문제로 인하여, 데이터의 수집이 이루어지는 네트워크의 말단에서 자체적으로 데이터를 처리하는 엣지 컴퓨팅에 대한 요구가 증가하고 있다. 그러나 네트워크 말단에 위치한 엣지 디바이스는 대부분 성능이 제한되어 있어 클라우드 서버에서 사용되는 딥러닝 응용을 그대로 사용하기에는 어려움이 있다. 이러한 문제를 극복하기 위해, 본 논문에서는 딥러닝 모델을 축소된 분류 모델들로 나누어 활용해 복수의 엣지 디바이스에서 공동으로 추론을 수행하는 분산 처리 기법을 제안하였다. 여기서 사용된 축소된 분류 모델은 경량화 된 모델 가중치를 가지며, 전체 분류 레이블 중 일부에 해당하는 레이블에 대해 추론을 진행한다. 성능 측정 결과 제안하는 축소된 분류 모델의 결과를 취합하는 분산 처리 기법의 정확도가 기존 모델 대비 더 적은 파라미터를 갖도록 경량화를 하여도 기존 모델과 유사한 수준을 유지할 수 있음을 확인하였다.","Recently, there have been increasing demands for edge computing that processes data at the end of the network wherein data is collected because of various problems such as network load caused by a large amount of data transfer to a cloud server. However, it is difficult for edge devices to use deep learning applications used in cloud servers because most edge devices at the end of the network have limited performance. To overcome these problems, this paper proposes a distributed processing method that uses reduced classification models to jointly perform inferences on multiple edge devices. The reduced classification models have compressed model weights, and perform inferences for some parts of the total classification labels. The experimental results confirmed that the accuracy of the result of the proposed distributed processing method is similar to the accuracy of the result of the original model, even if the proposed reduced classification models had much less parameters than those of the original model."
인공지능 학습과정에서 저작물의 이용에 관한 소고,2020,"['인공지능', '빅데이터', '머신러닝', '딥러닝', '저작권', '공정이용', '비표현적 이용행위', 'AI', 'big data', 'machine learning', 'deep learning', 'copyright', 'fair use', 'non-expressive use']","인공지능기술의 발전은 저작권법에도 새로운 문제를 제시하고 있다. 인공지능이 오로지 인간만이 가능하였던 창작의 영역에 새로운 창작자로서 부상하고 있고, 기존의 저작권법 체제 내에서 인공지능이 행하는 일련의 과정들, 인간처럼 학습하고 그 학습을 통해 생산해 내는 결과물에 대하여 어떻게 다루는 것이 바람직한 것인가 등 기존 저작권법의 법리로 해결할 수 없는 새로운 문제들이 생겨나고 있다.이 연구는 인공지능의 한 분야인 머신러닝(machine learning, 기계학습)이 저작물을 이용하는 것과 관련하여 어떻게 평가되고 규제되어야 하는지 저작권법의 목적과 취지에 따라 검토해 보고자 한다. 현재의 인공지능과 관련된 논의는 주로 인공지능이 학습의 결과로 만들어낸 산출물(output)에 대하여 이것을 저작물로 인정할 수 있을 것인가, 인정한다면 누가 저작자인가 등에 관한 논의에 집중되어 있는 것 같다. 그러나 인공지능이 학습하는 과정에서 개인의 창작물을 허락 없이 사용하고 이를 ‘표현적’으로 이용하고 있다면, 이는 저작권 침해의 소지가 있는 것으로 검토해 볼 가치가 있다. 여기서는 인공지능의 학습과정에서 발생할 수 잇는 저작권 침해 문제에 대하여 검토해 보고자 한다.본 연구는 인공지능이 머신러닝과 같은 학습과정에서 기존의 인간이 만든 저작물을 어떠한 법적 근거로 이용하고 있으며, 이때 발생하는 저작권 침해가 과연 산업발전이라는 목적 때문에 면책될 수 있을 것인가에 대해 고찰해 보았다. 특히 저작재산권 제한의 일반적 조항인 공정이용원칙 하에서 고도로 지적인(sophisticated) 인공지능의 학습이 허용될 수 있을 것인지에 대하여 살펴보고자 하였다.Ⅱ장에서는 인공지능을 둘러싼 기술적 개념에 대해 살펴보고, Ⅲ장에서는 인공지능 학습과정에서 발생할 수 있는 저작권 침해에 관하여 사례를 들어 검토한다. Ⅳ장에서는 인공지능 학습과정에서 저작권 침해가 공정이용원칙 하에서 면책될 수 있는지, 고도로 지적인(sophisticated) 인공지능의 학습과 창작이라는 새로운 상황 속에서 기존의 공정이용원칙을 고수할 수 있는지 여부에 대해 검토한다. 결론적으로 인간창작자의 보호와 기술 산업 보호라는 저작권법의 목적을 실현하기 위해  전통적인 저작권법 이론이 얼마나 유용할 수 있는지 살펴보고, 공정이용원칙의 역할에 대한 재정립이 필요함을 주장한다.","The 4th Industrial Revolution Committee, which was launched in September 2017, defined the 4th Industrial Revolution as “a hyper-connected intelligent revolution that is triggered by digital technologies such as artificial intelligence and big data..” With the advent of new tools of innovation, they conflict with or integrate with existing legal order, bringing greater development on the one hand and greater concern on the other. In particular, the next-generation industries represented by artificial intelligence (AI) are presenting a future of unpredictable forms that have no historical origin.When countries are busy with social and institutional rearrangements for technological innovation in order to survive the Fourth Industrial Revolution, it is necessary to discuss what problems the copyright sector has and how to solve it. It is emerging as a new creator in the realm of creation that only artificial human beings could do, and it is about a series of processes performed by artificial intelligence within the existing copyright law system, and the result produced by learning like human beings. I think it's because we need a philosophical, legal and economic analysis of how it is desirable to deal with it.This study examines how the field of artificial intelligence, machine learning, should be evaluated and regulated in relation to the use of copyrighted works in accordance with the purpose and intent of copyright law. The current discussion on artificial intelligence seems to focus on the discussion of whether AI can recognize this as a work for the output produced as a result of learning, and if so, who is the author.This study considered how artificial intelligence uses existing human-created works as a legal basis in the learning process such as machine learning, and whether copyright infringement can be indemnified for the purpose of industrial development. In particular, I would like to examine whether the study of highly intelligent AI can be permitted under the principle of fair use, which is a general provision of copyright restrictions.The fair use doctrine is to recognize the protection of 'expression of human creators' first and to use it as a tool to practice it, so that the alienation of human creators can be prevented by the development of technology. I think that continuous research should be done to balance between human creators and the technology industry to protect the purpose of copyright law."
준 지도 학습 ADDA 신경망을 활용한 PCB 불량검출,2020,"['심층신경망', '준 지도 학습', 'PCB 불량검출', 'deep neural network', 'domain adaptation', 'semi-supervised learning', 'PCB inspection']","최근 심층신경망 학습기술(딥러닝)의 발전으로 기존의 규칙기반 PCB 불량검출에 이를 도입하려는 시도가 활발하다. 그러나 딥러닝을 위한 충분한 PCB 데이터 확보가 어렵고, 단일 공정의 학습 데이터를 확보하여 모델을 학습하여도 해당 모델을 타 공정의 PCB 불량검출에 그대로 적용하기 어렵다. 이러한 문제를 해결하기 위해, 본 논문에서는 데이터 확보가 비교적 용이한 공정에서 기 학습된 모델을 사용하여 성능을 높이는 준 지도 학습이 도입된 형태의 Domain Adaptation 기법을 제안한다. 제안하는 기법을 벤치마크 데이터를 이용해 성능을 검증하고, 기존의 방식들과 비교하여 범용적인 상황에서도 효과적임을 증명한다. 또한 제안 기법을 실제 PCB 이미지로 성능 검증을 함으로써, 실 데이터에도 적용이 가능함을 확인한다.","With the recent development of deep neural network learning (deep learning), efforts to introduce the deep learning into the conventional rule-based PCB inspection are actively being pursued. However, it is difficult to obtain sufficient labeled PCB data to train deep neural networks. Additionally, although deep neural networks are trained by labeled data from a PCB inspection process (source domain), it is difficult to apply the trained networks to other PCB inspection processes (target domain). To solve these problems, we propose an advanced framework for domain adaptation to increase defect detection performances by exploiting source and target domain knowledge. Experimental results using public datasets demonstrate that the proposed method outperforms state-of-the-art methods and is promising for defect detection with the real PCB data."
온라인 퀴즈 시스템의 문제은행 구축 자동화를 위한 Deep Quiz Cropping 기술 개발,2020,"['온라인 퀴즈 시스템', '딥러닝 기반 물체 인식', '문제영역 검출', 'Deep Quiz Cropping', 'Box Coupling', 'Online Quiz System', 'Deep Learning-based Object Detection']","본 논문은 온라인 퀴즈 시스템에서 핵심인 문제은행 구축 자동화를 위한 Deep Quiz Cropping 기법을 제시했다. 이것은 문제지의 스캔된 그림 파일에서 개별문제에 대한 질문영역과 선다영역을 딥러닝 기반 검출기를 통해 검출하는 것과, 문제생성을 위해 질문영역과 선다영역을 짝지우고 영역오류를 수정하는 Box Coupling으로 이루어졌다. 문제지 및 시험지를 스캔한 영상파일에 Deep Quiz Coupling 기법을 적용한 다수의 실험에서 질의영역과 선다영역을 검출하는데 있어서 성공적인 결과를 도출했다.","We presented a method of deep quiz cropping for automatic construction of quiz pool in online quiz systems. The method detects question boxes and sunda boxes in images captured from test papers by a deep learning-based object detector, and makes pairs of a question box and a sunda box by the box coupling. We applied the deep quiz cropping to images captured from test papers and achieved successful results."
영상에서 convolutional denoising autoencoder 모형을 이용한 영상복원,2020,"['convolutional denoising autoencoder (CDAE)', '딥러닝', '영상복원', '잡음영상', 'deep learning', 'image restoration', 'noise reduction']","디지털 영상은 획득, 전송, 처리하는 과정에서 다양한 잡음 (noise)에 의해 훼손되어 이에 따른 영상 복원 (image restoration)의 필요성이 대두되고 있다. 지금까지 영상에서 잡음을 제거하는 방법은 특정분포 하에서 설계된 고유한 필터를 사용하였는데 이 경우 분포의 특성을 만족하지 않는 경우 성능이 현저히 떨어지는 영향이 있다. 본 논문에서는 딥러닝의 convolutional denoising autoencoder (CDAE) 모형을 이용하여 잡음을 제거하고자 한다. CDAE 모형은 CNN (convolutional neural network) 모형과 DAE (denoising autoencoder) 모형의 결합 형태로서 영상의 잡음 분포에 관계없이 적용 가능한 방법이다. 본 논문에서 제안된 CDAE 모형을 평가하기 위해 다양한 잡음 즉, 가우시안 잡음 (gaussian noise), 임펄스 잡음 (impulse noise) 그리고 스펙클 잡음 (speckle noise) 에 의해 훼손된 영상을 고려하였으며, 성능실험결과, CDAE 모형은 기존의 CNN 모형 및 전통적인 필터 즉, Mean 필터, Median 필터 그리고 Lee 필터 보다 좋은 복원 영상을 낳았고 또한, PSNR (peak signal-to-noise ratio)와 MAE (mean absolute error) 면에서 좋은 수치를 보였다.","Digital images have been compromised by various noise in the process of acquisition, transmission and processing, resulting in the need for image restoration. Until now, methods of removing noise from images have used unique filters designed under certain distributions, which tend to be significantly less effective if the characteristics of the distribution are not met. In this paper, we are going to use the convolutional denoising autoencoder (CDAE) model of deep learning to eliminate noise. The CDAE model is a combination of the CNN (convolutional neural network) model and the DAE (denoising autoencoder) model, which is an applicable method regardless of the noise distribution of images. In order to evaluate the CDAE model proposed in this paper, we considered images damaged by various noises, Gaussian noise, impulse noise and speckle noise. We compared our CDAE model with CNN and traditional filters such as Mean filter, Median filter and Lee filter. Experimental results on several images show that the CDAE model yields significantly superior image quality and better PSNR (peak signal-to- noise ratio) and MAE (mean absolute error)."
결측값을 포함한 센서 스트림에 대한 어텐션 메커니즘 및 합성곱 신경망 기반의 패턴 분류 기법,2020,"['IoT', '스트림 데이터', '딥러닝', '합성곱 신경망', '어텐션 메커니즘', 'IoT', 'Stream Data', 'Deep Learning', 'CNN', 'Attention Mechanism']","다양한 센서로부터 수집된 IoT 스트림 데이터 분석은 대표적인 비선형 분석 문제로, 최근 이러한 문제들의 해결에 합성곱 신경망(Convolutional Neural Network, CNN)을 비롯한 딥러닝 기법들을 다방면으로 적용하고 있다. 또한, IoT 센서 스트림 데이터는 그 수집 과정에서, 센서와 서버 간의 통신 장애 또는 센서의 하드웨어적 결함 등으로 인한 결측값 즉, 손실 데이터를 포함하는 경우가 많으며, 이러한 손실 데이터는 분석의 정확도를 감소시킨다. 한편, 다양한 센서 스트림 데이터 중, 루프 센서를 통해 수집된 교통량 데이터 분석은 도시 계획, 교통 공학, 다양한 교통 및 위치 기반 서비스의 구현 등에 활용된다. 그러나 루프 센서를 통한 교통량 데이터 수집 과정에서 결측값이 발생하는 경우가 많다. 본 논문에서는 이렇게 결측값이 포함된 센서 스트림 데이터의 패턴 분류 정확도를 높이기 위한 기법을 제안한다. 제안하는 기법은 합성곱 신경망 기반의 패턴 분류 모델에 어텐션 메커니즘(Attention Mechanism)을 도입하여 비손실 데이터에 대한 가중치를 부여함으로써 결측값으로 인한 정확도의 손실을 보완한다. 본 논문에서는 결측값의 발생이 잦은 루프 센서 기반의 교통량 데이터를 대상으로 제안하는 패턴 분류 기법을 적용하였고, 제안하는 기법이 결측값을 포함한 센서 스트림 데이터에 대한 패턴 분류 정확도를 향상시킬 수 있음을 실험을 통해 확인하였다.","Analysis for IoT stream data collected from various sensors is a typical non-linear analysis problem, and recently, deep learning techniques including convolutional neural networks have been applied to these problems in various ways. In addition, the IoT sensor stream data often includes missing data, that is, loss data due to a communication failure between the sensor and the server or a hardware defect of the sensor during the collection process, and such loss data reduces the accuracy of analysis. Meanwhile, among the various sensor stream data, the analysis of traffic volume data collected through the loop coil sensor is used for urban planning, traffic engineering, and implementation of various traffic and location-based services. However, during the process of collecting traffic data through the loop coil sensor, missing values ​​are often generated. In this paper, we propose a method to increase the accuracy of pattern classification of sensor stream data containing missing values. The proposed method compensates for the loss of accuracy due to missing values ​​assigning weights to non-loss data by applying attention mechanism to the pattern classification model based on the convolutional neural network. In this paper, the proposed pattern classification method is applied to traffic volume data measured by loop coil sensors that frequently generate missing values, and it was confirmed through experiments that the proposed method can improve the accuracy of pattern classification for sensor stream data including missing values."
임베딩 교체에 따른 구어체 텍스트 탐지 모델 성능 비교,2020,"['구어체 텍스트', '텍스트 기반 딥러닝 모델', '텍스트 임베딩', '욕설 탐지', 'Spoken language', 'Text-based deep learning model', 'Text embedding', 'Abuse detection']","딥러닝 기반 욕설 탐지 모델은 구어체의 오탈자 및 띄어쓰기 오류로 인해 정확도 향상에 많은 제약이 있다. 특히, 구어체는 학습 데이터 생성을 위한 형태소 분석에서 단어 의미 파악을 방해하는 형태소가 빈번하게 생성되는 문제점이 있으며, 이는 탐지 모델의 정확도를 떨어뜨리는 가장 큰 요인이다. 본 논문에서는 이러한 한국어 구어체의 문제점을 극복하기 위해, 임베딩에 따른 탐지 모델을 설계 및 구현하고, 이를 기반으로 욕설 탐지 정확도를 비교한다. 탐지에는 Word2Vec, fastText, SKT-KoBERT, KoELECTRA의 총 네 가지 임베딩 모델을 사용하며, 실험을 통해 각 임베딩 기반 욕설 탐지 모델 성능을 비교 및 평가한다. 실험 결과, 사용 문자 단위에 따른 실험은 Word2Vec과 fastText 모두 90% 이상의 정확도를 보였고, 중의성 판단 여부에 따른 실험에서는 SKT-KoBERT가 fastText에 비해 월등히 높은 성능을 보이는 것으로 나타났다. 마지막으로, 사전 학습 방법에 따른 실험 또한 SKT-KoBERT가 KoELECTRA에 비해 높은 성능을 보이는 것으로 나타났다. 본 논문의 실험 결과를 통해, 다양한 구어체 기반 딥러닝 서비스에 보다 효과적인 임베딩 기술을 적용할 수 있을 것으로 사료된다.","Deep learning-based abuse detection model is limited in accuracy due to frequent typos and spacing errors in Korean text. Particularly, in the process of morphological analysis of spoken language for generating learning data, there is a problem in morphemes that make it difficult to grasp the meaning of words are frequently extracted. This is the biggest cause of degrading the accuracy of the abuse detection model. In this paper, to overcome the problem of Korean spoken language, we design and implement a detection model based on embedding, and compare the accuracy of abuse detection We use four embedding models: Word2Vec, fastText, SKT-KoBERT, and KoELECTRA for detection, and we compare and evaluate the performance of each embedding-based abuse detection model through experiments. As a result of the experiment, the character unit-based experiments showed more than 90% accuracy in both Word2Vec and fastText, and in the experiment according to the determination of ambiguity, SKT-KoBERT showed significantly higher performance than fastText. Finally, the experiment according to the pre-learning method also showed higher performance of SKT-KoBERT than KoELECTRA. Through the experimental results of this paper, it is considered that more effective embedding technology can be applied to various spoken language-based deep learning services."
인공창의적 인공지능 회화 연구,2020,"['4th Industrial Revolution', 'algorism', 'Artificial creative', 'Artificial Intelligence', 'Artificial Intelligence painting', 'Deep Learning', '4차 산업', '딥러닝', '알고리즘', '인공지능', '인공창의', '인공지능 회화']","4차 산업을 주도하고 있는 인공지능(AI)은 딥러닝을 통해 인간이 창조성을 발휘하는 예술세계를 넘나들며 기계의 영역을 넓히고 있다. 이미지 생성분야에서 탁월한 성과를 발휘하는 인공지능은 화가의 면모를 지니고 있어, 21세기의 회화는 새로운 국면을 맞이하게 되었다. 이전에는 없었던 기술혁신을 통해 사진예술이 창조되었듯이 오늘날의 회화는 변혁을 통해 새로운 세계를 열었다. 차세대 표현도구로 예술적 영감을 주는 인공지능은 다양한 이미지 생성기술을 통해 기존의 예술을 새롭게 변화시키고 다채로운 형식의 신예술을 창출하고 있다. 이에 본고는 예술 창의에 영감을 주는 인공지능이 지닌 예술적 의미와 가치에 대해 다양한 시각으로 고찰하고자 한다. 이를 위해 인공지능의 체계와 구조에 대해 살펴보고, 이를 활용하여 표현되고 있는 딥러닝 기반의 AI 회화에 대해 논의하겠다.","Artificial Intelligence (AI), the leading element of the 4thindustrial revolution, has made inroads into the art world as deep learning broadened the influence of robotics and machinery in a field generally reserved for human creativity. Art in the 21st century has already entered a new phase of existence with AI being successfully implemented in image synthesis. Similar to how fine-art photography was born via technological advancements never seen prior to 1827, which is a good example of how constant evolutionshaped modern art as we know now, AI has expanded the confines of today’s art through various techniques in image synthesis. And by doing so, AI has emerged as atool of artistic expression, inspiring a new form of art to the general public.As such, I will examine the merit of AI as a tool of artistic expression, as well as the effective utilization of AI in different aspects of society. To do so, I will research the various types of paintings developed with AI, and discuss the creation of artistic algorism provided by collaboration between man and machine."
Automatic Metallic Surface Defect Detection using ShuffleDefectNet,2020,"['Defect detection', 'Deep Learning', 'ShuffleNet', 'Light-weight modules', '결함탐지', '딥러닝', '셔플넷', '라이트웨이 모듈']","일반적으로 품질 관리는 많은 제조 공정, 특히 주조 또는 용접과 관련된 공정의 기본 구성 요소가 된다. 그러나 사람이 일일이 수동으로 품질 관리 절차를 하는 것은 종종 시간이 걸리고 오류가 발생하기 쉽다. 최근 고품질 제품에 대한 요구를 만족시키기 위해 지능형 육안 검사 시스템의 사용이 생산 라인에서 필수적이 되고 있다. 본 논문에서는 이를 위해 딥 러닝 기반의 ShuffleDefectNet 결함 감지 시스템을 제안하고자 한다. 제안된 결함 검출 시스템은 NEU 데이터 세트의 결함 검출에 대한 여러 최신 성능들보다 높은 평균 정확도 99.75% 정도를 얻는다. 이 논문에서 여러 다른 트레이닝 데이터로부터 최상의 성능을 탐지하고 탐지 성능을 관찰하였다. 그 결과 ShuffleDefectNet의 전체 아키텍처를 사용할 때 정확성과 속도가 크게 향상됨을 알 수 있었다.","Steel production requires high-quality surfaces with minimal defects. Therefore, the detection algorithms for the surface defects of steel strip should have good generalization performance. To meet the growing demand for high-quality products, the use of intelligent visual inspection systems is becoming essential in production lines. In this paper, we proposed a ShuffleDefectNet defect detection system based on deep learning. The proposed defect detection system exceeds state-of-the-art performance for defect detection on the Northeastern University (NEU) dataset obtaining a mean average accuracy of 99.75%. We train the best performing detection with different amounts of training data and observe the performance of detection. We notice that accuracy and speed improve significantly when use the overall architecture of ShuffleDefectNet."
고해상도로 찍은 이미지에서의 손가락 지문 채취 방지에 관한 연구,2020,"['손 관절 인식', '지문 해킹 방지', '이미지 보안', '고해상도 기술 문제점', '딥러닝', 'Detecting Finger Joints', 'Fingerprinting Prevent', 'Images Security', 'High Resolution Image Problems', 'Deep Learning']","본 연구에서는 나날이 발전하는 카메라의 해상도 기술과 SNS의 이미지 공유를 통해서 고해상도로 찍은 이미지를 손쉽게 구할 수 있고, 이미지를 통해서 사람의 손가락 지문을 손쉽게 채취하여 이를 악용할 수 있다는 가능성을 고려해 이를 방지하는 기술을 제시한다. 이 기술을 개발하기 위해서는 Python 언어를 이용한 Opencv와 opencv안의 Blur 처리를 해주는 라이브러리 등을 사용한다. 우선 이미지에서 손을 찾아주기 위해서 딥러닝 기반의 학습된 Hand Key point Detection 알고리즘을 사용한다. 이 알고리즘을 이용해 손가락 마디를 찾아 이 마디의 좌표를 이용해 이미지에서의 손가락 지문 부위만을 따로 blur 처리를 해줌으로써 원본 이미지에서의 손상을 최소화하면서 손가락 지문을 보호할 수 있다. 향후 정확한 손가락 추적 알고리즘의 개발로 스마트폰 카메라 app의 내부 옵션으로 사용하여 고해상도의 이미지에서의 지문을 보호할 수 있을 것이다.","In this study, Developing high resolution camera and Social Network Service sharing image can be easily getting images, it cause about taking fingerprints to easy from images. So I present solution about prevent to taking fingerprints. this technology is develop python using to opencv, blur libraries. First of all ‘Hand Key point Detection’ algorithm is used to locate the hand in the image. Using this algorithm can be find finger joints that can be protected while minimizing damage in the original image by using the coordinates of separate blurring the area of fingerprints in the image. from now on the development of accurate finger tracking algorithms, fingerprints will be protected by using technology as an internal option for smartphone camera apps from high resolution images."
변형된 MFCC를 이용한 위험 음향 감지시스템,2020,"['MFCC', 'Modified MFCC', 'LSTM', 'Deep Learning', 'MFCC', '변형 MFCC', 'LSTM', '딥러닝']","본 논문에서는 스마트 홈 연구의 일환으로 가정 내의 위험 음향 감지를 위한 새로운 시스템을 제안한다. 제안하는 위험음향 감지 시스템에서는 음향 신호의 특징추출을 위해 변형 MFCC(Mel- Frequency Cepstral Coefficient)을 이용한다. 변형MFCC는 기존 MFCC에서 DCT(Discrete Cosine Transform)를 제거하고 Wiener필터를 추가한 변형된 필터뱅크를 사용한다.Wiener필터는 잡음(Noise) 제거 기능을 하고, 필터뱅크의 변형은 배경음 제거 및 위험 음향데이터의 인식률 향상을 위해적용된다. 기존 MFCC와의 성능을 비교하기 위해 딥러닝 분류기로 시계열 데이터에 적합한 LSTM(Long short-Term Memory)을이용하여 학습 정확도와 인식률 실험을 하였다. 실험 결과, 변형 MFCC가 기존 MFCC에 비해 학습 정확도 개선 및 인식률향상이 가능함을 확인하였다.",
인공지능 기반 개체명 인식 모델의 보이스피싱 여죄 분석 활용에 관한 연구,2020,"['보이스피싱', '여죄 추적', '수사기법', '범죄정보 추출', '자연어 처리', '개체명 인식(NER)', '딥러닝', 'LSTM', 'voice phishing', 'tracking of additional crimes', 'investigation technique', 'criminal information extraction', 'natural language processing', 'named entity registration(NER)', 'deep learning']","최근 데이터가 급격히 늘어나고 이를 처리할 기술과 수단이 발달함에 따라, 다양한 분야에서 빅데이터와 인공지능을 활용하는 것에 대한 관심이 증가하고 있다. 이러한 맥락에서 범죄의 예방과 수사의 측면에서 적절한 대응을 하기 위해 대용량 비정형 텍스트 데이터 내에서 정보추출(Information Extraction)하는 기술을 활용하는 것도 경찰의 주된 관심사 중 하나이다. 본 연구는 보이스피싱 수법으로 분류된 범죄사실 비정형 텍스트에, 딥러닝 기술의 발달로 최근 정확도가 크게 향상된 자연어 처리의 응용 분야인 개체명 인식(Named Entity Recognition, NER) 모델을 적용하여 사칭기관, 사칭이름, 사칭직급, 범행이용계좌 은행명 등의 정보를 자동으로 추출하는 실험을 수행하였다. 이와 같은 인공지능 기술을 활용한 비정형 텍스트 분석을 통해, 본 연구는 현재 보이스피싱 수사의 피의자 여죄 추적에 즉각적인 도움을 주고자 하였다. 실험을 위해 개체명 인식에 정확도가 높다고 알려진 Bidirectional LSTM-CRF 신경망 모델을 적용한 결과, micro-avg f1 스코어가 88.6%로 도출되고 micro-avg precision 스코어와 micro-avg recall 스코어는 각각 90%, 88%로 나타나, 적은 수의 데이터에 대해서도 높은 정확도로 개체명이 인식되고 있음을 확인하였다. 본 연구는 범죄 수사 분야에서 개체명 인식 모델의 생성을 최초로 제안하였으며, 연구의 결과는 향후 수사 데이터에 대한 정보검색 시스템의 성능 향상과, 챗봇, 질의응답 등 범죄 예방 및 수사 실무에 도움을 줄 것으로 예상되는 여러 자연어 처리 기반 시스템 개발에 필요한 선행연구로 활용될 수 있을 것이다.","With the recent rapid increase in data and the development of technologies and means to deal with it, interest in utilizing big data and artificial intelligence in various fields is increasing. In this context, one of the main concerns of the police is the use of information extraction technology within large unstructured text data to make appropriate responses in terms of crime prevention and investigation. This study carried out an experiment in which information such as fake agencies, names used by impostors, fake positions, and bank name of crime-used accounts was automatically extracted by applying Named Entity Registration(NER) model, which is an application of natural language processing that greatly improved accuracy through the development of deep learning technology. By using this unstructured text analysis using artificial intelligence technology, this study was intended to provide immediate help in tracking down the suspect""s other crimes in the voice phishing investigation currently in progress. As a result of applying the Bidirectional LSTM-CRF neural network model, which is known to have high accuracy in named entity recognition for experimentation, the micro-avg f1 score was derived at 88.6%, and the micro-avg precision score and micro-avg recall score were shown at 90% and 88%, respectively, confirming that the entity name was also recognized with high accuracy for a small number of data. This study was the first to propose the creation of an NER model in the field of criminal investigation, and the results of the study could be used as a preliminary study necessary for the development of various natural language processing-based systems that are expected to help crime prevention and investigation practices by improving performance of information retrieval system, chatbot and Q&A for police data in the future."
교통 영상 빅데이터 처리를 위한 Yolo 기반 광원 객체 탐지,2020,"['Traffic Safety', 'Deep Learning', 'Object Detection', 'Light Source Object', 'Image Processing', '교통안전', '딥러닝', '객체 탐지', '광원 객체', '이미지 처리']",교통안전에 대한 관심이 높아짐에 따라 교통사고의 발생률을 줄이는 자율 주행에 대한 연구가 지속적으로 진행되고 있다. 객체의 인식과 탐지는 자율 주행을 위한 필수적인 요소이다. 때문에 도로 상황을 판단하기 위하여 교통 영상 빅데이터에서 객체 인식 및 탐지에 대한 연구가 활발히 진행 중이다. 하지만 기존 연구들은 대부분 주간 데이터만 사용하기 때문에 야간 도로에서 객체 인식이 어렵다. 특히 광원 객체의 경우 빛 번짐과 백화 현상으로 인해 주간의 특징을 그대로 사용하기 어렵다. 따라서 본 연구에서는 교통 영상 빅데이터 처리를 위한 Yolo 기반 광원 객체 탐지를 제안한다. 제안하는 방법은 야간 교통 영상을 대상으로 색상 모델 변화를 적용하여 이미지 처리를 수행한다. 이미지 처리를 통해서 객체의 특징을 추출하여 객체의 후보군을 결정한다. 후보군 데이터를 활용하여 딥러닝 모델을 통해 야간 도로에서 광원 객체 탐지의 인식률을 높이는 것이 가능하다.,"As interest in traffic safety increases, research on autonomous driving, which reduces the incidence of traffic accidents, is increased. Object recognition and detection are essential for autonomous driving. Therefore, research on object recognition and detection through traffic image big data is being actively conducted to determine the road conditions. However, because most existing studies use only daytime data, it is difficult to recognize objects on night roads. Particularly, in the case of a light source object, it is difficult to use the features of the daytime as it is due to light smudging and whitening. Therefore, this study proposes Yolo based light source object detection for traffic image big data processing. The proposed method performs image processing by applying color model transitions to night traffic image. The object group is determined by extracting the characteristics of the object through image processing. It is possible to increase the recognition rate of light source object detection on a night road through a deep learning model using candidate group data."
CNN 모델을 활용한 항공기 ISAR 영상 데이터베이스 구축에 관한 연구,2020,"['NCTR', 'ISAR', 'Deep-learning', 'CNN model', 'Image classification', '비협조적 표적식별', '역합성개구레이다 영상', '딥러닝', 'CNN 모델', '영상 식별']","비협조적 표적식별(NCTR, Non-Cooperative Target Recognition)은 전자정보 등 다른 체계의 지원 없이 레이다 자체적으로 표적을 식별하는 기능을 말한다. 이를 구현하기 위한 대표적인 방법 중 하나인 역합성개구레이다(ISAR) 영상은 표적의 기동 및 위치에 따라 크게 변하기 때문에 기종을 판단할 수 있는 데이터베이스 없이 이를 자동으로 식별하기란 매우 어렵다. 본 연구에서는 실측 영상이 부족한 상황에서도 ISAR 영상 시뮬레이션 및 딥러닝 기법을 활용한 식별 데이터베이스 구축 방안에 대해 논한다. 다양한 레이다 운용 환경에 따라 변화하는 ISAR 영상을 모사하기 위해 ‘완전 산란체’, ‘결손 산란체’, ‘JEM 잡음’으로 명명한 영상 형성 과정을 거쳐 이를 학습하는 모델을 제안한다. 이 모델의 학습 결과를 통해 유사한 형상의 시뮬레이션 영상은 물론 처음 입력된 실측 ISAR 영상도 식별할 수 있음을 확인하였다.","NCTR(Non-Cooperative Target Recognition) refers to the function of radar to identify target on its own without support from other systems such as ELINT(ELectronic INTelligence). ISAR(Inverse Synthetic Aperture Radar) image is one of the representative methods of NCTR, but it is difficult to automatically classify the target without an identification database due to the significant changes in the image depending on the target’s maneuver and location. In this study, we discuss how to build an identification database using simulation and deep-learning technique even when actual images are insufficient. To simulate ISAR images changing with various radar operating environment, A model that generates and learns images through the process named ‘Perfect scattering image,’ ‘Lost scattering image’ and ‘JEM noise added image’ is proposed. And the learning outcomes of this model show that not only simulation images of similar shapes but also actual ISAR images that were first entered can be classified."
U-Net에 기반한 이미지 복원 기법을 이용한 콘크리트 균열 탐지 방안,2020,"['Deep Learning', 'Concrete Crack', 'Crack Detection', 'Anomaly Detection', 'U-Net', 'Unsupervised Learning', '딥러닝', '콘크리트 균열', '균열 검출', '이상 탐지', 'U-Net', '비지도 학습']","본 연구에서는 비지도 이상 탐지 방법을 변형한 U-Net 기반의 이미지 복원 기법을 통해 한정적인데이터를 활용한 균열 탐지 방안을 제안한다. 콘크리트 균열은 다양한 원인으로 인해 발생하며, 장기적으로 구조물의 심각한 손상을 초래할 수 있는 요소이다. 일반적으로 균열 조사는 검사원의 육안으로판단하는 외관 검사법을 사용하는데, 이는 판단에 객관성이 떨어지며 인적 오류 발생 가능성이 크다.따라서 객관적이고 정확한 이미지 분석 처리를 통한 방법이 요구된다. 최근에는 균열을 신속하고 정밀하게 탐지할 수 있도록 딥러닝을 활용한 기술들이 연구되고 있다. 하지만 일반적인 균열자료에 비해점검 대상물에 대한 데이터는 한정적이므로 이를 활용한 기존 균열 탐지 모델의 성능은 제한적인 경우가많다. 따라서 본 연구에서는 비지도 이상 탐지 방법을 사용해 점검 대상물에 대한 데이터를 증강하여해당 데이터를 사용하여 학습한 결과, 정확도 98.78%, 조화평균(F1_Score) 82.67%의 성능을 확인하였다.","In this study, we propose a crack detection method using limited data with a U-Net based image inpainting technique that is a modified unsupervised anomaly detection method. Concrete cracking occurs due to a variety of causes and is a factor that can cause serious damage to the structure in the long term.In general, crack investigation uses an inspector’s visual inspection on the concrete surfaces, which is less objective in judgment and has a high possibility of human error. Therefore, a method with objective and accurate image analysis processing is required. In recent years, the methods using deep learning have been studied to detect cracks quickly and accurately. However, when the amount of crack data on the building or infrastructure to be inspected is small, existing crack detection models using it often show a limited performance. Therefore, in this study, an unsupervised anomaly detection method was used to augment the data on the object to be inspected, and as a result of learning using the data, we confirmed the performance of 98.78% of accuracy and 82.67% of harmonic average (F1_Score)."
심층신경망의 더블 프루닝 기법의 적용 및 성능 분석에 관한 연구,2020,"['Model Compression', 'Model Light Weight', 'Deep Learning', 'Pruning', 'Network-Slimming', '모델압축', '모델 경량화', '딥러닝', '프루닝', '네트워크 간소화']","최근 인공지능 딥러닝 분야는 컴퓨팅 자원의 높은 연산량과 가격문제로 인해 상용화에 어려움이 존재했다. 본 논문은 더블 프루닝 기법을 적용하여 심층신경망 모델들과 다수의 데이터셋에서의 성능을 평가하고자 한다. 더블 프루닝은 기본의 네트워크 간소화(Network-Slimming)과 파라미터 프루닝(Parameter-Pruning)을 결합한다. 이는 기존의 학습에 중요하지 않는 매개변수를 절감하여 학습 정확도를 저해하지 않고 속도를 향상시킬 수 있다는 장점이 있다. 다양한 데이터셋 학습 이후에 프루닝 비율을 증가시켜, 모델의 사이즈를 감소시켰다. NetScore 성능 분석 결과 MobileNet-V3가 가장 성능이 높게 나타났다. 프루닝 이후의 성능은 Cifar 10 데이터셋에서 깊이 우선 합성곱 신경망으로 구성된 MobileNet-V3이 가장 성능이 높았고, 전통적인 합성곱 신경망으로 이루어진 VGGNet, ResNet또한 높은 폭으로 성능이 증가함을 확인하였다.","Recently, the artificial intelligence deep learning field has been hard to commercialize due to the high computing power and the price problem of computing resources. In this paper, we apply a double pruning techniques to evaluate the performance of the in-depth neural network and various datasets. Double pruning combines basic Network-slimming and Parameter-prunning. Our proposed technique has the advantage of reducing the parameters that are not important to the existing learning and improving the speed without compromising the learning accuracy. After training various datasets, the pruning ratio was increased to reduce the size of the model.We confirmed that MobileNet-V3 showed the highest performance as a result of NetScore performance analysis. We confirmed that the performance after pruning was the highest in MobileNet-V3 consisting of depthwise seperable convolution neural networks in the Cifar 10 dataset, and VGGNet and ResNet in traditional convolutional neural networks also increased significantly."
디지털 행정서비스 혁신을 위한 지능형 자동차 환경관리 정책 연구,2020,"['Eco-friendly Grade Label for Vehicle', 'Machine Learning', 'Deep Learning', '자동차 배출가스 등급제', '머신러닝', '딥러닝']","대기환경 문제는 국민의 생활에 직접 관련이 있고, 국민들은 미세먼지와 관련하여 많은 우려를하고 있다. 미세먼지 오염원 중에 가장 큰 비중을 차지하는 것이 자동차 배출가스이기 때문에, 정부에서는 자동차 배출가스 등급제를 시행하여 대기환경을 개선하고자 노력하고 있다. 하지만, 자동차 정기검사와 불법 및 부실검사소 단속은 사전예방이 어렵고 검사 및 단속 이후에 조치가 되는 한계점이 있다. 본 연구에서는 지능정보기술을 활용하여 모든 대상을 검사 및 단속하지 않고도 사전 예측하여 선제적인 정책수행이 가능한 방안을 제시한다. 또한, 이상징후의 즉각적인 파악을 통해 실시간적인 정책수행이 가능하다. 딥러닝을 활용하면 분류되지 않은 특성에 대해서도 패턴인식을 통해 유사한 것들을분류할 수 있게 되어 사전예측이 가능하다. 정책의 수행을 위한 구체적인 데이터 모델 및 알고리즘은추가적인 연구가 필요하다. 향후 연구를 통해 실제 자동차 검사결과와 부실 및 불법 검사소 정보를 활용하여 사전예측 모델을 만들어 시험하고 결과를 분석할 계획이다.","The air environment problem is directly related to the lives of the people, and the people are concerned about fine dust. Since automobile emissions account for the largest proportion of particulate matter pollutants, the government is trying to improve the air environment by implementing a rating system for automobile emissions. However, regular vehicle inspections and crackdowns at illegal and insolvent inspection centers are difficult to prevent in advance, and there are limitations in that measures are taken after inspections and crackdowns. This study proposes a plan that enables preemptive policy implementation by using intelligent information technology to predict in advance without inspecting and cracking down on all targets. In addition, real-time policy execution is possible through immediate identification of abnormal symptoms. Using deep learning, it is possible to classify similar things through pattern recognition even for unclassified features, allowing for advance prediction. Detailed data models and algorithms for policy implementation need additional research. Through future research, we plan to test and analyze the results by creating a predictive model using actual vehicle inspection results and information on insolvent and illegal inspection sites."
베이지안 최적화를 이용한 암상 분류 모델의 하이퍼 파라미터 탐색,2020,"['facies classification', 'Bayesian optimization', 'random search', 'autoML', 'k-fold cross validation', '암상 분류', '베이지안 최적화', '랜덤탐색', '자동머신러닝', 'k겹 교차검증']","최근 인공지능 기술의 발전과 함께 물리탐사의 다양한 분야에서도 인공지능의 핵심 기술인 머신러닝의 활용도가증가하고 있다. 또한 머신러닝 및 딥러닝을 활용한 연구는 이미지, 비디오, 음성, 자연어 등 다양한 태스크의 추론 정확도를 높이기 위해 복잡한 알고리즘들이 개발되고 있고, 더 나아가 자료의 특성, 알고리즘 구조 및 하이퍼 파라미터의 최적화를 위한 자동 머신러닝(AutoML) 분야로 그 폭을 넓혀가고 있다. 본 연구에서는 AutoML 분야 중에서도 하이퍼 파라미터(hyperparameter) 자동 탐색을 위한 베이지안 최적화 기술에 중점을 두었으며, 본 기술을 물리탐사 분야에서도 암상 분류(facies classification) 문제에 적용했다. Vincent field의 현장 물리검층 및 탄성파 자료를 이용하여 암상 및 공극유체를 분류하는 지도학습 기반 모델에 적용하였고, 랜덤 탐색 기법의 결과와 비교하여 베이지안 최적화 기반 예측 프레임워크의 효율성을 검증하였다.","With the recent advancement of computer hardware and the contribution of open source libraries to facilitate access to artificial intelligence technology, the use of machine learning (ML) and deep learning (DL) technologies in various fields of exploration geophysics has increased. In addition, ML researchers have developed complex algorithms to improve the inference accuracy of various tasks such as image, video, voice, and natural language processing, and now they are expanding their interests into the field of automatic machine learning (AutoML). AutoML can be divided into three areas: feature engineering, architecture search, and hyperparameter search. Among them, this paper focuses on hyperparamter search with Bayesian optimization, and applies it to the problem of facies classification using seismic data and well logs. The effectiveness of the Bayesian optimization technique has been demonstrated using Vincent field data by comparing with the results of the random search technique."
SSD-Mobilenet과 ResNet을 이용한 모바일 기기용 자동차 번호판 인식시스템,2020,"['Vehicle License Plate Recognition', 'Deep Learning', 'SSD-Mobilenet', 'ResNet', '자동차 번호판 인식 시스템', '딥러닝', 'SSD-Mobilenet', 'ResNet']","본 논문은 고성능의 서버 없이 안드로이드 스마트폰 단독으로 동작할 수 있도록 경량화 딥러닝 모델을 사용하여 구현한 자동차 번호판 인식 시스템을 제안한다. 자동차 번호판 인식시스템은 [번호판검출]-[문자영역 분할]-[문자인식]으로 3단계의 과정으로 구성되며, 번호판검출은 SSD-Mobilenet, 문자영역 분할은 ResNet에 localization을 추가하여 사용하였고 문자인식은 ResNet을 이용하여 구현하였다. 테스트한 기기는 삼성 갤럭시 S7, LG Q9이며 정확도는 약 85.3%, 실행속도는 약 1.1초가 소요된다.","This paper proposes a vehicle license plate recognition system using light weight deep learning models without high-end server. The proposed license plate recognition system consists of 3 steps: [license plate detection]-[character area segmentation]-[character recognition]. SSD-Mobilenet was used for license plate detection, ResNet with localization was used for character area segmentation, ResNet was used for character recognition. Experiemnts using Samsung Galaxy S7 and LG Q9, accuracy showed 85.3% accuracy and around 1.1 second running time."
MLP와 ANFIS를 이용한 입찰가격 예측,2020,"['Electronic bidding', 'MLP', 'ANFIS', 'Deep learning', 'bid prediction', '전자입찰', '다층퍼셉트론', '적응 신경 퍼지 추론시스템', '딥러닝', '입찰 예측']","우리나라에서는 입찰에서 2002년부터 전자 입찰시스템을 기본으로 사용하고 있다. 전자 입찰은 기존입찰방식의 번거로움을 간소화하고, 발주처와 조달 업체 간 대면접촉에 의한 부정 입찰을 방지할수 있다는 장점이 있다. 현재 입찰에서 복수 예비가격 추첨을 통한 낙찰 방식이 주로 사용하고 있다. 하지만 낙찰 방식의 특성상(난수 체계) 낙찰가격을 정확히 예측하기란 쉽지 않다. 본 논문은 전자 입찰에 적용할 수 있는 딥러닝을 이용한 입찰프로그램을 제안한다. 딥러닝 알고리즘인 다층퍼셉트론(MLP; multi layer perceptron)과 적응 신경 퍼지 추론시스템(ANFIS; adaptive neural fuzzy inference system)을 이용하여 기존의 낙찰데이터를 분석하고 낙찰가를 예측하여 두 알고리즘을 비교한 후 우수한 알고리즘을 이용한 예측 모델을 구성하고자 한다","In Korea, we have been using electronic bidding system as the basis for bidding since 2002.Electronic bidding has the advantage of simplifying the hassle of the existing bidding method and preventing fraudulent bidding by face-to-face contact between the ordering company and the procurement company. The bid method through multiple preliminary price lottery is mainly used in the current bid, but it is not easy to accurately predict the winning bid price due to the nature of the winning bid method(random number system). This paper proposes a bid program using deep learning that can be applied to electronic bidding. The purpose of this study is to analyze the existing winning bid data using the deep learning algorithms, Multi layer perceptron(MLP) and adaptive neural fuzzy inference system (ANFIS), predict the winning bid price, compare the two algorithms, and construct a prediction model using excellent algorithms."
클라우드 환경에서 IoT 정보 오류를 고려한 지형 정보 기반의 키 관리 기법,2020,"['Cloud', 'Internet of Things', 'terrain information', 'key management', 'deep learning', 'probability-based', 'clustering', '클라우드', '사물인터넷', '지형 정보', '키 관리', '딥러닝', '확률 기반', '클러스터링']","클라우드 환경에서는 센서 및 웨어러블 장치를 이용한 IoT 기기가 다양한 환경에서 응용되고 있으며 그에 따른 IoT 기기에서 생성되는 정보를 정확하게 판별하는 기술들이 활발하게 연구되고 있다. 그러나, 전력 및 보안과 같은 IoT 환경의 제약사항으로 인하여 IoT 장치에서 발생하는 정보가 매우 취약하기 때문에 금전 피해 및 인명 피해가 증가하고 있다. 본 논문에서는 IoT 정보를 정확하게 수집⋅분석하기 위해서 IoT 정보 오류를 고려한 지형 정보 기반의 키 관리 기법을 제안한다. 제안 기법은 IoT 장치를 클라우드 환경에서 임의로 배치할 경우 IoT 장치의 연결성을 확보하기 위해서 IoT 배치 오류를 허용하는 동시에 지형 정보를 개의 그룹으로 그룹핑 하도록 한다. 특히, 각 그룹핑 된 지형 정보에는 전체 키 풀에서 랜덤하게 선택된 임의의 키를 할당한 후 IoT 정보에 포함된 지형 정보의 키와 확률적으로 높은 키 값을 IoT 장치의 연결성으로 확보할 수 있도록 한다. 특히, 제안 기법은 확률적 딥러닝을 이용하여 IoT 지형 정보의 키를 시드로 추출하기 때문에 IoT 장치에 대한 정보 오류를 낮출수 있다.","In the cloud environment, IoT devices using sensors and wearable devices are being applied in various environments, and technologies that accurately determine the information generated by IoT devices are being actively studied. However, due to limitations in the IoT environment such as power and security, information generated by IoT devices is very weak, so financial damage and human casualties are increasing. To accurately collect and analyze IoT information, this paper proposes a topographic information-based key management technique that considers IoT information errors. The proposed technique allows IoT layout errors and groups topographic information into groups of dogs in order to secure connectivity of IoT devices in the event of arbitrary deployment of IoT devices in the cloud environment. In particular, each grouped terrain information is assigned random selected keys from the entire key pool, and the key of the terrain information contained in the IoT information and the probability-high key values are secured with the connectivity of the IoT device. In particular, the proposed technique can reduce information errors about IoT devices because the key of IoT terrain information is extracted by seed using probabilistic deep learning."
인공신경망 기반 드론 광학영상 및 LiDAR 자료를 활용한 임분단위 식생층위구조 추정,2020,"['Vegetation structure', 'Drone image', 'Artificial Neural Networks (ANNs)', 'Sustainable forest development']","지속가능한 산림 발전을 위해 식생층위구조를 파악하는 것은 산림 자원 관리에 중요한 요소이다. 최근기술의 발달로 드론, 딥러닝 등 신기술을 산림 부문에 접목한 활용이 늘어났으며, 이를 이용한 식생층위구조추정이 가능해졌다. 본 연구에서는 드론-광학 및 LiDAR 영상을 융합하여 공주, 삼척, 서귀포 지역에 대해 식생층위구조를 파악하였으며, 각 92.62%(Kappa value: 0.59), 91.57%(Kappa value: 0.53), 86.00%(Kappa value: 0.63)의정확도를 확인하였다. 딥러닝을 활용한 식생층위구조 분석 기술은 광학 및 LiDAR의 정보량이 많아질수록 모델의 성능을 높일 수 있을 것으로 기대된다. 향후, 식생의 다양한 특성이 반영될 수 있는 복잡도 높은 모델과 충분한 샘플링을 통한 학습자료 구축이 동반되어 모델의 완성도가 높아진다면, 전국단위의 식생층위구조 지도를 구축하여 우리나라 정책·제도의 참고자료로 활용될 수 있을 것이다.","Understanding the vegetation structure is important to manage forest resources for sustainable forest development. With the recent development of technology, it is possible to apply new technologies such as drones and deep learning to forests and use it to estimate the vegetation structure. In this study, the vegetation structure of Gongju, Samchuk, and Seoguipo area was identified by fusion of drone-optical images and LiDAR data using Artificial Neural Networks (ANNs) with the accuracy of 92.62% (Kappa value: 0.59), 91.57% (Kappa value: 0.53), and 86.00% (Kappa value: 0.63), respectively. The vegetation structure analysis technology using deep learning is expected to increase the performance of the model as the amount of information in the optical and LiDAR increases. In the future, if the model is developed with a high-complexity that can reflect various characteristics of vegetation and sufficient sampling, it would be a material that can be used as a reference data to Korea’s policies and regulations by constructing a country-level vegetation structure map."
제한 볼츠만 기계를 이용한 협력필터링 기반 추천 시스템,2020,"['Collaborative Filtering', 'Recommender System', 'Deep Learning', 'Neural Network', 'Restricted Boltzmann Machine', '협력 필터링', '추천 시스템', '딥러닝', '신경망', '제한 볼츠만 기계']","추천 시스템은 전자 상거래 시에 고객들의 상품 선택의 편의를 제공하므로 반드시 구비되어야 할 기능이다. 협력 필터링은 다른 사용자들이 선호하였던 상품이나 현 사용자가 과거 선호하였던 상품들을 위주로 추천 리스트를 제공하는 기법으로서, 가장 널리 활용되는 대표적 기법이다. 최근 딥러닝 인공지능 기술을 활용하여 추천 시스템의 성능 향상을 달성하는 연구가 활발히 진행되고 있다. 본 연구에서는 사용자가 부여한 평가등급만을 이용하여 딥러닝 기술의 일종인 제한 볼츠만 기계 학습을 통해 협력 필터링 기반의 추천 시스템을 개발한다. 또한 학습의 효율성과 성능을 위하여 학습 파라미터 변경 알고리즘을 제시한다. 제안 시스템의 성능 평가를 위하여 실험 분석을 통해 기존의 다양한 전통적 협력 필터링 기법들과 비교 분석을 실시하였으며, 제안 알고리즘은 기본적인 제한 볼츠만 기계 모델보다 우수한 성능을 가져오는 것으로 확인되었다.","Recommender system is a must-have feature of e-commerce, since it provides customers with convenience in selecting products. Collaborative filtering is a widely-used and representative technique, where it gives recommendation lists of products preferred by other users or preferred by the current user in the past. Recently, researches on the recommendation system using deep learning artificial intelligence technologies are actively being conducted to achieve performance improvement. This study develops a collaborative filtering based recommender system using restricted Boltzmann machines of the deep learning technology by utilizing user ratings. Moreover, a learning parameter update algorithm is proposed for learning efficiency and performance. Performance evaluation of the proposed system is made through experimental analysis and comparison with conventional collaborative filtering methods. It is found that the proposed algorithm yields superior performance than the basic restricted Boltzmann machines."
Triplet CNN과 학습 데이터 합성 기반 비디오 안정화기 연구,2020,"['video stabilization', 'convolutional neural network', 'wobbling distortion']","영상 내 흔들림은 비디오의 가시성을 떨어뜨리고 영상처리나 영상압축의 효율을 저하시킨다. 최근 디지털 영상처리 분야에 딥러닝이 본격 적용되고 있으나, 비디오 안정화 분야에 딥러닝 적용은 아직 초기 단계이다. 본 논문에서는 Wobbling 왜곡 경감을 위한 triplet 형태의 CNN 기반 비디오 안정화기 구조를 제안하고, 비디오 안정화기 학습을 위한 학습데이터 합성 방법을 제안한다. 제안한 CNN 기반 비디오 안정화기는 기존 딥러닝 기반 비디오 안정화기와 비교되었으며, Wobbling 왜곡은 감소하고 더 안정적인 학습이 이루어지는 결과를 얻었다.",
BERT를 활용한 뉴스 감성분석과 거시경제지표 조합을 이용한 주가지수 예측,2020,"['Natural Language', 'Sentiment Analysis', 'Stock Prediction', 'Macro Economy Index', 'Deep learning', '자연어처리', '감성분석', '주가예측', '거시경제지표', '딥러닝']","주가지수는 한 국가의 경제 지표뿐만 아니라 투자판단의 지표로도 활용되므로 이를 예측하는 연구가지속해서 진행되고 있다. 주가지수 예측을 하는 작업은 기술적, 경제적 및 심리적 요인 등이 반영된것으로 예측의 정확도를 위해서는 복합적 요인을 고려해야 한다. 따라서 지수의 변동에 영향을 미치는요인들을 선별하여 반영한 주가지수 예측모델연구가 필요하다. 이와 관련한 기존 연구에서는 시장의변동을 만들어 내는 뉴스 정보 또는 거시 경제 지표를 각각 이용하거나, 몇 가지의 지표 조합만을반영한 예측 연구가 대부분이었다. 따라서 본 연구에서는 미국 다우존스지수 예측을 위해 뉴스 정보의감성 분석과 다양한 거시경제지표를 고려하여 효과적인 지표 조합을 제시하고자 한다. 뉴스 정보의감성 분석은 최신 자연어처리 기법인 BERT와 NLTK VADER를 사용하고, 예측모델은 주가예측모델로적합하다고 알려진 딥러닝 예측모델 LSTM을 적용하여 가장 효과적인 지표 조합을 제시했다.","The stock index is used not only as an economic indicator for a country, but also as an indicator for investment judgment, which is why research into predicting the stock index is ongoing. The task of predicting the stock price index involves technical, basic, and psychological factors, and it is also necessary to consider complex factors for prediction accuracy. Therefore, it is necessary to study the model for predicting the stock price index by selecting and reflecting technical and auxiliary factors that affect the fluctuation of the stock price according to the stock price. Most of the existing studies related to this are forecasting studies that use news information or macroeconomic indicators that create market fluctuations, or reflect only a few combinations of indicators. In this paper, this we propose to present an effective combination of the news information sentiment analysis and various macroeconomic indicators in order to predict the US Dow Jones Index. After Crawling more than 93,000 business news from the New York Times for two years, the sentiment results analyzed using the latest natural language processing techniques BERT and NLTK, along with five macroeconomic indicators, gold prices, oil prices, and five foreign exchange rates affecting the US economy Combination was applied to the prediction algorithm LSTM, which is known to be the most suitable for combining numeric and text information. As a result of experimenting with various combinations, the combination of DJI, NLTK, BERT, OIL, GOLD, and EURUSD in the DJI index prediction yielded the smallest MSE value."
Bidirectional Convolutional LSTM을 이용한 Deepfake 탐지 방법,2020,"['Deepfake', 'LSTM', 'Attention module', 'Artificial intelligence', 'Time distribution']","최근 하드웨어의 성능과 인공지능 기술이 발달함에 따라 육안으로 구분하기 어려운 정교한 가짜 동영상들이 증가하고 있다. 인공지능을 이용한 얼굴 합성 기술을 딥페이크라고 하며 약간의 프로그래밍 능력과 딥러닝 지식만 있다면 누구든지 딥페이크를 이용하여 정교한 가짜 동영상을 제작할 수 있다. 이에 무분별한 가짜 동영상이 크게 증가하였으며 이는 개인 정보 침해, 가짜 뉴스, 사기 등에 문제로 이어질 수 있다. 따라서 사람의 눈으로도 진위를 가릴 수 없는 가짜 동영상을 탐지할 수 있는 방안이 필요하다. 이에 본 논문에서는 Bidirectional Convolutional LSTM과 어텐션 모듈(Attention module)을 적용한 딥페이크 탐지 모델을 제안한다. 본 논문에서 제안하는 모델은 어텐션 모듈과 신경곱 합성망 모델을 같이 사용되어 각 프레임의 특징을 추출하고 기존의 제안되어왔던 시간의 순방향만을 고려하는 LSTM과 달리 시간의 역방향도 고려하여 학습한다. 어텐션 모듈은 합성곱 신경망 모델과 같이 사용되어 각 프레임의 특징 추출에 이용한다. 실험을 통해 본 논문에서 제안하는 모델은 93.5%의 정확도를 갖고 기존 연구의 결과보다 AUC가 최대 50% 가량 높음을 보였다.","With the recent development of hardware performance and artificial intelligence technology, sophisticated fake videos that are difficult to distinguish with the human’s eye are increasing. Face synthesis technology using artificial intelligence is called Deepfake, and anyone with a little programming skill and deep learning knowledge can produce sophisticated fake videos using Deepfake. A number of indiscriminate fake videos has been increased significantly, which may lead to problems such as privacy violations, fake news and fraud. Therefore, it is necessary to detect fake video clips that cannot be discriminated by a human eyes. Thus, in this paper, we propose a deep-fake detection model applied with Bidirectional Convolution LSTM and Attention Module. Unlike LSTM, which considers only the forward sequential procedure, the model proposed in this paper uses the reverse order procedure. The Attention Module is used with a Convolutional neural network model to use the characteristics of each frame for extraction. Experiments have shown that the model proposed has 93.5% accuracy and AUC is up to 50% higher than the results of pre-existing studies."
CNN을 이용한 소비 전력 파형 기반 명령어 수준 역어셈블러 구현,2020,"['Side-Channel Attack', 'Power Analysis', 'Deep Learning', 'Convolutional Neural Network(CNN)', 'Disassembler']","정보보호용 디바이스의 부채널 정보인 소비 전력 파형을 이용하면 내장된 비밀 키 뿐만 아니라 동작 명령어를 복구할 수 있음이 밝혀졌다. 최근에는 MLP 등과 같은 딥러닝 모델을 이용한 프로파일링 기반의 부채널 공격들이 연구되고 있다. 본 논문에서는 마이크로 컨트롤러 AVR XMEGA128-D4가 사용하는 명령어에 대한 역어셈블러를 구현하였다. 명령어에 대한 템플릿 파형을 수집하고 전처리하는 과정을 자동화하였으며 CNN 딥러닝 모델을 사용하여 명령-코드를 분류하였다. 실험 결과, 전체 명령어는 약 87.5%의 정확도로, 사용 빈도가 높은 주요 명령어는 99.6%의 정확도로 분류될 수 있음을 확인하였다.","It has been found that an attacker can extract the secret key embedded in a security device and recover the operation instruction using power consumption traces which are some kind of side channel information. Many profiling-based side channel attacks based on a deep learning model such as MLP(Multi-Layer Perceptron) method are recently researched. In this paper, we implemented a disassembler for operation instruction set used in the micro-controller AVR XMEGA128-D4. After measuring the template traces on each instruction, we automatically made the pre-processing process and classified the operation instruction set using a deep learning model CNN. As an experimental result, we showed that all instructions are classified with 87.5% accuracy and some core instructions used frequently in device operation are with 99.6% respectively."
비지도학습 오토 엔코더를 활용한 네트워크 이상 검출 기술,2020,"['Network Anomaly Detection', 'NSL-KDD Data Set', 'AutoEncoder', 'Unsupervised Learning']","인터넷 컴퓨팅 환경의 변화, 새로운 서비스 출현, 그리고 지능화되어 가는 해커들의 다양한 공격으로 인한 규칙 기반 침입탐지시스템의 한계점을 극복하기 위해 기계학습 및 딥러닝 기술을 활용한 네트워크 이상 검출(NAD: Network Anomaly Detection)에 대한 관심이 집중되고 있다. NAD를 위한 대부분의 기존 기계학습 및 딥러닝 기술은 ‘정상’과 ‘공격’으로 레이블링된 훈련용 데이터 셋을 학습하는 지도학습 방법을 사용한다. 본 논문에서는 공격의 징후가 없는 일상의 네트워크에서 수집할 수 있는 레이블링이 필요 없는 데이터 셋을 이용하는 비지도학습 오토 엔코더(AE: AutoEncoder)를 활용한 NAD 적용 가능성을 제시한다. AE 성능을 검증하기 위해 NSL-KDD 훈련 및 시험 데이터 셋을 사용해 정확도, 정밀도, 재현율, f1-점수, 그리고 ROC AUC (Receiver Operating Characteristic Area Under Curve) 값을 보인다. 특히 이들 성능지표를 대상으로 AE의 층수, 규제 강도, 그리고 디노이징 효과 등을 분석하여 레퍼런스 모델을 제시하였다. AE의 훈련 데이터 셋에 대한 재생오류 82-th 백분위 수를 기준 값으로 KDDTest+와 KDDTest-21 시험 데이터 셋에 대해 90.4%와 89% f1-점수를 각각 보였다.","In order to overcome the limitations of the rule-based intrusion detection system due to changes in Internet computing environments, the emergence of new services, and creativity of attackers, network anomaly detection (NAD) using machine learning and deep learning technologies has received much attention. Most of these existing machine learning and deep learning technologies for NAD use supervised learning methods to learn a set of training data set labeled ‘normal’ and ‘attack’. This paper presents the feasibility of the unsupervised learning AutoEncoder(AE) to NAD from data sets collecting of secured network traffic without labeled responses. To verify the performance of the proposed AE mode, we present the experimental results in terms of accuracy, precision, recall, f1-score, and ROC AUC value on the NSL-KDD training and test data sets. In particular, we model a reference AE through the deep analysis of diverse AEs varying hyper-parameters such as the number of layers as well as considering the regularization and denoising effects. The reference model shows the f1-scores 90.4% and 89% of binary classification on the KDDTest+ and KDDTest-21 test data sets based on the threshold of the 82-th percentile of the AE reconstruction error of the training data set."
이미지의 질과 왜곡을 고려한 적대적 생성 신경망과 이를 이용한 비정상 검출,2020,"['Anomaly Detection', 'Unsupervised learning', 'Generative Adversarial Network', 'Variational Autoencoder']","최근 연구 결과에 따르면, 컨볼루션 신경 회로망은 이미지 분류, 객체 검출, 이미지 생성 등의 문제에서 최고의 성능을 보여주고 있다. 비전 카메라를 사용한 결함 검사는 다른 결함 검사보다 경제적이기 때문에 공장 자동화에 있어서 아주 중요하고, 딥러닝의 지도학습은 전통 기계학습 방식의 결함 검사 성능을 월등히 뛰어넘었다. 하지만, 딥러닝의 지도 학습은 엄청난 양의 데이터 주석 작업을 요구하기 때문에, 이를 실제 산업 현장에 적용하는 것은 효율적이지 않다. 따라 서 본 연구는 최근 이미지 생성 과업에서 큰 성공을 보여주고 있는 변분 오토인코더와 적대적 생성 신경망을 활용하여 비지도 방식의 비정상 검출을 위한 신경망 회로 구조를 제안하였고, 이를 MNIST, 용접 결함 데이터에 적용하여 비정상 검출 성능을 검증하였다.","Recently, studies have shown that convolution neural networks are achieving the best performance in image classification, object detection, and image generation. Vision based defect inspection which is more economical than other defect inspection, is a very important for a factory automation. Although supervised anomaly detection algorithm has far exceeded the performance of traditional machine learning based method, it is inefficient for real industrial field due to its tedious annotation work, In this paper, we propose ADGAN, a unsupervised anomaly detection architecture using the variational autoencoder and the generative adversarial network which give great results in image generation task, and demonstrate whether the proposed network architecture identifies anomalous images well on MNIST benchmark dataset as well as our own welding defect dataset"
지능형 객체 인식 기술을 이용한 실시간 동영상 검색시스템,2020,"['Costume', 'Deep Learning', 'YOLO', 'Human Object Detection', 'OpenCV', 'Video Search']","최근 범죄예방과 안전문제 등으로 CCTV와 같은 영상장비가 다양하게 활용되고 있다. 영상기기들은 대부분 24시 간 작동되기 때문에 경비 인력을 절감할 수 있지만, 녹화된 영상에서 특정 인물과 같은 객체를 검색하는 업무는 여전히 수동으로 이루어지고 있어, 실시간 검색이 요구되는 상황에서는 정확하고 빠른 대처가 미흡하다. 본 논문에서는 최신 딥러닝 기술과 OpenCV 라이브러리를 이용하여 사용자의 의해 입력된 의상정보를 바탕으로 특정인물을 영상에서 빠르 게 검색하고, 그 결과를 실시간으로 전송하는 기술을 제안한다. 개발된 시스템은 YOLO 라이브러리를 이용하여 실시간 으로 인물객체를 탐지한 후, 딥러닝 기술을 이용하여 인간의 의상을 상/하의로 구분하고 OpenCV 라이브러리를 통해 색을 검출하여 특정 인물객체를 자동으로 인식하도록 구현하였다. 본 논문에서 개발한 시스템은 특정 의상을 갖춘 인물 객체를 정확하고 빠르게 인식할 뿐만 아니라 기타 객체 인식에도 활용할 수 있는 확장성을 갖추고 있어 다양한 용도의 영상감시시스템에 활용될 수 있을 것으로 기대된다.","Recently, video-taping equipment such as CCTV have been seeing more use for crime prevention and general safety concerns. Since these video-taping equipment operates all throughout the day, the need for security personnel is lessened, and naturally costs incurred from managing such manpower should also decrease. However, technology currently used predominantly lacks self-sufficiency when given the task of searching for a specific object in the recorded video such as a person, and has to be done manually; current security-based video equipment is insufficient in an environment where real-time information retrieval is required. In this paper, we propose a technology that uses the latest deep-learning technology and OpenCV library to quickly search for a specific person in a video; the search is based on the clothing information that is inputted by the user and transmits the result in real time. We implemented our system to automatically recognize specific human objects in real time by using the YOLO library, whilst deep learning technology is used to classify human clothes into top/bottom clothes. Colors are also detected through the OpenCV library which are then all combined to identify the requested object. The system presented in this paper not only accurately and quickly recognizes a person object with a specific clothing, but also has a potential extensibility that can be used for other types of object recognition in a video surveillance system for various purposes."
라즈베리파이를 이용한 Modbus TCP 기반 태양광 발전소 모니터링 시스템,2020,"['Modbus TCP protocol', 'Inverter', 'Raspberrypi', 'Monitoring system', 'Deep learning']","본 연구는 IOT 장비인 라즈베리파이를 마스터(master)로 이용하고 인버터를 슬레이브(slave)로 하여 모드버스 TCP 통신을 기반한 태양광 발전 모니터링 시스템을 제안하였다. 본 모델은 라즈베리파이에 다양한 센서를 추가하여 태양광 발전소의 모니터링에 필요한 정보를 추가하였으며, 실시간 발전량 예측을 통해 발전량 예측과 모니터링 정보를 스마트 폰으로 송신하였다. 또한, 서버에 태양광 발전소에서 지속해서 생성되는 정보를 빅데이터로 구축하였으며, 발전량 예측을 위한 딥러닝 모델을 학습하여 갱신하였다. 연구 결과로서 인버터에서 라즈베리파이로 모드버스 TCP 기반으로 안정적인 통신이 가능하였고, 라즈베리파이에서 학습된 딥러닝 모델로 실시간 예측이 가능하였다. 서버는 빅데이터로 다양한 딥러닝 모델 학습이 가능하였으며, LSTM이 학습 오차 0.0069, 테스트 오차 0.0075, RMSE 0.0866 등으로 가장 좋은 오차를 보임을 확인하였다. 본 모델은 다양한 제조사의 인버터에 대해서 보다 간단하고 편리하며 발전량을 예측할 수 있는 실시간 모니터링 시스템 구현이 가능함을 제시하였다.","This research propose and simulate a solar power generation system monitoring system based on Modbus TCP communication using RaspberryPi, an IOT equipment, as a master and an inverter as a slave. In this model, various sensors are added to the RaspberryPi to add necessary information for monitoring solar power plants, and power generation prediction and monitoring information are transmitted to the smart phone through real-time power generation prediction. In addition, information that is continuously generated by the solar power plant is built on the server as big data, and a deep learning model for predicting power generation is trained and updated. As a result of the study, stable communication was possible based on Modbus TCP with the Raspberry Pi in the inverter, and real-time prediction was possible with the deep learning model learned in the Raspberry Pi. The server was able to train various deep learning models with big data, and it was confirmed that LSTM showed the best error with a learning error of 0.0069, a test error of 0.0075, and an RMSE of 0.0866. This model suggested that it is possible to implement a real-time monitoring system that is simpler, more convenient, and can predict the amount of power generation for inverters of various manufacturers."
멜트다운 취약점을 이용한 인공신경망 추출 공격,2020,"['Meltdown', 'neural network stealing', 'cloud computing', 'deep learning']","클라우드 컴퓨팅 환경에서 기계학습 서비스를 제공하는 Machine-Learning-as-a-Service(MLaaS) 등이 활발히 개발됨에 따라 보다 다양한 분야에서 인공지능 기술을 손쉽고 효과적인 방법으로 활용할 수 있게 되었다. 클라우드 환경에서는 가상화 기술을 통해 각 사용자에게 논리적으로 독립된 컴퓨팅 공간을 제공하는데, 최근 시스템의 취약점을 이용해 클라우드 테넌트(tenant) 사이에 다양한 부채널이 존재할 수 있다는 연구 결과가 발표되고 있다. 본 논문에서는 이러한 멀티-테넌시(multi-tenancy) 환경에서 멜트다운 취약점을 이용하여 딥러닝 모델의 내부 정보를 추출할 수 있는 현실적인 공격 시나리오를 제시한다. 이후 TensorFlow 딥러닝 서비스에 대한 실험을 통해 92.875%의 정확도와 1.325kB/s의 속도로 인공신경망의 모든 정보를 추출할 수 있음을 보인다.","Cloud computing technology plays an important role in the deep learning industry as deep learning services are deployed frequently on top of cloud infrastructures. In such cloud environment, virtualization technology provides logically independent and isolated computing space for each tenant. However, recent studies demonstrate that by leveraging vulnerabilities of virtualization techniques and shared processor architectures in the cloud system, various side-channels can be established between cloud tenants. In this paper, we propose a novel attack scenario that can steal internal information of deep learning models by exploiting the Meltdown vulnerability in a multi-tenant system environment. On the basis of our experiment, the proposed attack method could extract internal information of a TensorFlow deep-learning service with 92.875% accuracy and 1.325kB/s extraction speed."
저해상도 이미지 분류를 위한 고해상도 이미지로부터의 Self-Attention 정보 추출 네트워크,2020,"['저해상도 이미지', '이미지 분류', '정보 전달 기법', 'Self-Attention Map', 'low resolution image', 'image classification', 'knowledge distillation', 'self-attention map']","기존의 딥러닝 모델들은 고화질의 이미지들을 활용하여 연구 개발되었으며, 화질이 낮아질수록 급격히 성능이 낮아진다. 본 연구는 저화질 이미지에도 효과적으로 대응할 수 있는 딥러닝 모델을 개발하고자, 고화질의 이미지로부터 효과적으로 분류를 할 수 있는 정보를 Attention Map의 형태로 추출했다. 이후 Knowledge Distillation 기법을 활용하여 고화질 이미지상에서 추출한 Attention Map을 저해상도 이미지 모델에 전달하는 네트워크를 제안했으며, 16×16의 저해상도 CIFAR100　이미지를 분류했을 때 에러율을 2.94% 낮출 수 있었다. 이는 32×32에서 16×16으로 이미지 해상도를 낮췄을 때 에러 감소율의 38.43%에 해당하는 수치로, 본 네트워크의 우수성을 입증할 수 있었다.","Traditional deep-learning models have been developed using high-quality images.However, when the low resolution images are rendered, the performances of the model drop drastically.To develop a deep-learning model that can respond effectively to low-resolution images, we extracted the information from the model, which uses high-resolution images as input, in the form of the Attention Map. Using the knowledge distillation technique, the information delivering Attention Map, extracted from the high-resolution images to low-resolution image models, could reduce the error rate by 2.94%, when classifying the low-resolution CIFAR images of 16×16 resolution. This was at 38.43% of the error reduction rate when the image resolution was lowered from 32×32 to 16×16, which could demonstrate excellence in this network."
Deep Convolution Neural Networks 이용하여 결함 검출을 위한 결함이 있는 철도선로표면 디지털영상 재 생성,2020,"['철도표면', '생성적 적대적 네트워크', '영상 생성', '조건부 생성모델', '검출 모델', 'Railroad surface', 'Generative Adversarial Network', 'Image Representation', 'Conditional generation model', 'Detection Model']","본 연구는 철도표면상에 발생하는 노후 현상 중 하나인 결함 검출을 위해 학습데이터를 생성함으로써 결함 검출 모델에서 더 높은 점수를 얻기 위해 진행되었다. 철도표면에서 결함은 선로결속장치 및 선로와 차량의 마찰 등 다양한 원인에 의해 발생하고 선로 파손[14] 등의 사고를 유발할 수 있기 때문에 결함에 대한 철도 유지관리가 필요 하다. 그래서 철도 유지관리의 자동화 및 비용절감을 위해 철도 표면 영상에 영상처리 또는 기계학습을 활용한 결함 검출 및 검사에 대한 다양한 연구가 진행되고 있다. 일반적으로 영상처리 분석기법 및 기계학습 기술의 성능은 데이터의 수량과 품질에 의존한다. 그렇기 때문에 일부 연구는 일반적이고 다양한 철도표면영상의 데이터베이스를 확보하기위해 등간격으로 선로표면을 촬영하는 장치 또는 탑재된 차량이 필요로 하였다[15, 16]. 본연구는 이러한 기계적인 영상획득 장치의 운용비용을 감소시키고 보완하기 위해 대표적인 영상생성관련 딥러닝 모델인 생성적 적대적 네트워크[1]의 기본 구성에서 여러 관련연구에서 제시된 방법을 응용, 결함이 있는 철도 표면 재생성모델을 구성하여, 전용 데이터베이스가 구축되지 않은 철도 표면 영상에 대해서도 결함 검출을 진행할 수 있도록 하였다. 구성한 모델은 상이한 철도 표면 텍스처들을 반영한 철도 표면 생성을 학습하고 여러 임의의 결함의 위치에 대한 Ground-Truth들을 만족하는 다양한 결함을 재 생성하도록 설계하였다. 재생성된 철도 표면의 영상들을 결함 검출 딥러닝 모델[2]에 학습데이터로 사용한다. 재생성모델의 유효성을 검증하기 위해 철도표면데이터를 3가지의 하위집합으로 군집화 하여 하나의 집합세트를 원본 영상으로 정의하고, 다른 두개의 나머지 하위집합들의 몇가지의 선로표면영상을 텍스처 영상으로 사용하여 새로운 철도 표면 영상을 생성한다. 그리고 결함 검출 모델에서 학습데이터로 생성된 새로운 철도 표면 영상을 사용하였을 때와, 생성된 철도 표면 영상이 없는 원본 영상을 사용하였을 때를 나누어 검증한다. 앞서 분류했던 하위집합들 중에서 원본영상으로 사용된 집합세트를 제외한 두 개의 하위집합들은 각각의 환경에서 학습된 결함 검출 모델에서 검증하여 출력인 픽셀단위 분류지도 영상을 얻는다. 이 픽셀단위 분류지도영상들과 실제 결함의 위치에 대한 원본결함지도(Ground-Truth)들의 IoU(Intersection over Union) 및 F1-score로 평가하여 성능을 계산하였다. 결과적으로 두개의 하위집합의 텍스처 영상을 이용한 재생성된 학습데이터를 학습한 결함 검출모델의 점수는 원본 영상만을 학습하였을 때의 점수보다 약 IoU 및 F1-score가 10~15% 증가하였다. 이는 전용 학습 데이터가 구축되지 않은 철도표면 영상에 대해서도 기존 데이터를 이용하여 결함 검출이 상당히 가능함을 증명하는 것이다.","This study was carried out to generate various images of railroad surfaces with random defects as training data to be better at the detection of defects. Defects on the surface of railroads are caused by various factors such as friction between track binding devices and adjacent tracks and can cause accidents such as broken rails [14], so railroad maintenance for defects is necessary. Therefore, various researches on defect detection and inspection using image processing or machine learning on railway surface images have been conducted to automate railroad inspection and to reduce railroad maintenance costs. In general, the performance of the image processing analysis method and machine learning technology is affected by the quantity and quality of data. For this reason, some researches require specific devices or vehicles to acquire images of the track surface at regular intervals to obtain a database of various railway surface images [15, 16]. On the contrary, in this study, in order to reduce and improve the operating cost of image acquisition, we constructed the 'Defective Railroad Surface Regeneration Model' by applying the methods presented in the related studies of the Generative Adversarial Network (GAN) [1]. Thus, we aimed to detect defects on railroad surface even without a dedicated database. This constructed model is designed to learn to generate the railroad surface combining the different railroad surface textures and the original surface, considering the ground truth of the railroad defects. The generated images of the railroad surface were used as training data in defect detection network [2], which is based on Fully Convolutional Network (FCN) [3]. To validate its performance, we clustered and divided the railroad data into three subsets, one subset as original railroad texture images and the remaining two subsets as another railroad surface texture images. In the first experiment, we used only original texture images for training sets in the defect detection model. And in the second experiment, we trained the generated images that were generated by combining the original images with a few railroad textures of the other images. Each defect detection model was evaluated in terms of 'intersection of union(IoU)' and F1-score measures with ground truths. As a result, the scores increased by about 10~15% when the generated images were used, compared to the case that only the original images were used. This proves that it is possible to detect defects by using the existing data and a few different texture images, even for the railroad surface images in which dedicated training database is not constructed."
손실함수의 특성에 따른 UNet++ 모델에 의한 변화탐지 결과 분석,2020,"['Deep learning', 'Change detection', 'UNet++', 'Loss function', 'Training data']","본 논문에서는 의미론적 분할을 위한 딥러닝 기술 중의 하나인 UNet++ 모델을 이용하여 다시기 위성영상의 변화지역을 탐지하고자 하였다. 다양한 손실함수에 대한 학습결과를 분석하기 위하여, 이진 교차 엔트로피, 자카드 변수에 의하여 학습된 UNet++ 모델에 의한 변화탐지 결과를 평가하였다. 또한, 딥러닝 모델의 결과는 WorldView-3 위성영상을 활용하여 기존의 화소기반 변화탐지 기법의 결과와 비교하여 평가하였다. 실험결과, 손실함수의 특성에 따라서 딥러닝 모델의 성능이 달라질 수 있음을 확인하였으나, 기존 기법들과 비교하여 우수한 결과를 나타내는 것도 확인하였다.","In this manuscript, the UNet++ model, which is one of the representative deep learning techniques for semantic segmentation, was used to detect changes in temporal satellite images. To analyze the learning results according to various loss functions, we evaluated the change detection results using trained UNet++ models by binary cross entropy and the Jaccard coefficient. In addition, the learning results of the deep learning model were analyzed compared to existing pixel-based change detection algorithms by using WorldView-3 images. In the experiment, it was confirmed that the performance of the deep learning model could be determined depending on the characteristics of the loss function, but it showed better results compared to the existing techniques."
RapidEye 위성영상을 이용한 작물재배지역 추정을 위한 FC-DenseNet의 활용성 평가,2020,"['Crop cultivation area', 'Deep learning', 'RapidEye satellite imagery', 'FC-DenseNet', 'Cadastral Map']","안정적인 작물 생산을 위하여 국내 농업지역에 대한 효과적인 작황 모니터링 기법의 요구가 증대되고있다. 본 연구에서는 작물 재배지역 추출을 위하여 딥러닝 기법을 이용한 분류 모델을 개발하고, 이를 위성영상에 적용하고자 하였다. 이를 위하여, 식생분석에 유용한 blue, green, red, red-edge, NIR 밴드를 포함하고 있는RapidEye 위성영상을 이용하여 작물 재배지역에 대한 훈련자료를 구축하고, 이를 활용하여 국내 양파 및 마늘 작물에 대한 재배면적을 추정하고자 하였다. 대기보정된 RapidEye 위성영상을 활용하여 훈련자료를 구축하였으며, 작물지역의 분류를 위하여 대표적인 의미론적 분할을 위한 딥러닝 모델인 FC-DenseNet을 이용하여딥러닝 모델을 생성하였다. 최종적인 작물 재배지역은 지적도와의 결합을 통하여 객체 기반의 자료로 생성하였다. 실험결과, 대기보정된 훈련자료를 이용하여 학습된 FC-DenseNet 모델은 훈련에 사용되지 않은 타 지역의 작물 재배지역을 효과적으로 검출할 수 있음을 확인하였다.","In order to stably produce crops, there is an increasing demand for effective crop monitoring techniques in domestic agricultural areas. In this manuscript, a cultivation area extraction method by using deep learning model is developed, and then, applied to satellite imagery. Training dataset for crop cultivation areas were generated using RapidEye satellite images that include blue, green, red, red-edge, and NIR bands useful for vegetation and environmental analysis, and using this, we tried to estimate the crop cultivation area of onion and garlic by deep learning model. In order to training the model, atmospheric-corrected RapidEye satellite images were used, and then, a deep learning model using FCDenseNet, which is one of the representative deep learning models for semantic segmentation, was created. The final crop cultivation area was determined as object-based data through combination with cadastral maps. As a result of the experiment, it was confirmed that the FC-DenseNet model learned using atmospheric-corrected training data can effectively detect crop cultivation areas."
CNN Mobile Net 기반 악성코드 탐지 모델에서의 학습 데이터 크기와 검출 정확도의 상관관계 분석,2020,"['CNN Mobile Net', 'Malware Detection Algoritm', 'Machine Learning', 'Security Data Analysis', 'Network Event']",현재 4차 산업혁명을 맞이하여 머신러닝과 인공지능 기술이 급속도로 발전하고 있으며 보안 분야에서도 머신러닝 기술을 응용하려는 움직임이 있다. 많은 악성코드가 생성됨에 따라 사람의 힘으로는 모든 악성코드를 탐지하기 어려워지고 있기 때문이다. 이에 따라 학계와 산업계에서는 머신러닝을 통해 악성코드나 네트워크 침입 이벤트를 탐지하는 것에 관한 연구가 활발히 진행되고 있으며 국제 학회와 저널에서는 머신러닝의 한 분야인 딥러닝을 이용한 보안데이터 분석 연구가 논문 발표되고 있다. 그러나 해당 논문들은 검출 정확도에 초점이 맞추어져 있고 검출 정확도를 높이기 위해 여러 파라미터들을 수정하지만 Dataset의 개수를 고려하지 않고 있다. 따라서 본 논문에서는 CNN Mobile net 기반 악성코드 탐지 모델에서 가장 높은 검출 정확도를 도출할 수 있는 Dataset의 개수을 찾아내어 많은 머신러닝 연구 진행에 비용과 리소스를 줄이고자 한다.,"At the present stage of the fourth industrial revolution, machine learning and artificial intelligence technologies are rapidly developing, and there is a movement to apply machine learning technology in the security field. Malicious code, including new and transformed, generates an average of 390,000 a day worldwide. Statistics show that security companies ignore or miss 31 percent of alarms. As many malicious codes are generated, it is becoming difficult for humans to detect all malicious codes. As a result, research on the detection of malware and network intrusion events through machine learning is being actively conducted in academia and industry. In international conferences and journals, research on security data analysis using deep learning, a field of machine learning, is presented. have. However, these papers focus on detection accuracy and modify several parameters to improve detection accuracy but do not consider the ratio of dataset. Therefore, this paper aims to reduce the cost and resources of many machine learning research by finding the ratio of dataset that can derive the highest detection accuracy in CNN Mobile net-based malware detection model."
어텐션 기법 및 의료 영상에의 적용에 관한 최신 동향,2020,"['Deep Learning', 'Artificial Intelligence', 'Medical Imaging', 'Attention']","딥러닝 기술은 빅데이터 및 컴퓨팅 파워를 기반으로 최근 영상의학 분야의 연구에서 괄목할만한 성과를 이루어 내고 있다. 하지만 성능 향상을 위해 딥러닝 네트워크가 깊어질수록 그내부의 계산 과정을 해석하기 어려워졌는데, 이는 환자의 생명과 직결되는 의료분야의 의사결정 과정에서는 매우 심각한 문제이다. 이를 해결하기 위해 “설명 가능한 인공지능 기술”이연구되고 있으며, 그중 하나로 개발된 것이 바로 어텐션(attention) 기법이다. 본 종설에서는이미 학습이 완료된 네트워크를 분석하기 위한 Post-hoc attention과, 네트워크 성능의 추가적인 향상을 위한 Trainable attention 두 종류의 기법에 대해 각각의 방법 및 의료 영상 연구에 적용된 사례, 그리고 향후 전망 등에 대해 자세히 다루고자 한다.","Deep learning has recently achieved remarkable results in the field of medical imaging. However, as a deep learning network becomes deeper to improve its performance, it becomes more difficult to interpret the processes within. This can especially be a critical problem in medical fields where diagnostic decisions are directly related to a patient's survival. In order to solve this, explainable artificial intelligence techniques are being widely studied, and an attention mechanism was developed as part of this approach. In this paper, attention techniques are divided into two types: post hoc attention, which aims to analyze a network that has already been trained, and trainable attention, which further improves network performance. Detailed comparisons of each method, examples of applications in medical imaging, and future perspectives will be covered."
데이터 균형화 알고리즘을 이용한 CNN 기반 피부질환 이미지 분류기의 성능 분석,2020,"['imbalanced class', 'deep learning', 'dermoscopic image', 'cross validation']","본 연구에서는 클래스 불균형을 가진 피부질환 이미지 데이터셋을 딥러닝 모델을 이용하여 분류하는 문제에 있어서, 다수 클래스에 편향되지 않으면서, 희소 클래스의 분류 민감도를 높이기 위한 데이터 균형화 알고리즘을 딥러닝 학습에 적용하고 성능을 분석하였다. 이를 위해 불균형 데이터셋인 HAM10000에 데이터 균형화 알고리즘(ROS, SMOTE, ADASYN, BSMOTE, SVMSMOTE)을 적용하여 학습한 모델과 그렇지 않은 모델의 정확도, 민감도, 정밀도, F1 점수를 측정하여 분류 성능을 비교하고, 교차 검증(5-fold cross-validation)을 통해 그 효과를 분석하였다. 실험에 사용한 HAM100000 데이터셋은 7종 피부질환에 대해 총 10,015장의 피부경 이미지로 구성되며, 해상도는 600×450이다. 실험을 통해, 데이터 균형화 알고리즘 적용 후 피부질환 이미지 분류기의 민감도(3.1%∼6.6%), 정밀도(2.2%∼7.5%), F1 점수(2.7%∼6.6%)가 유의미하게 증가하였다(p<0.05). 이를 통해 데이터 균형화 알고리즘이 불균형 학습데이터의 분류 성능 향상에 기여할 수 있음을 확인하였다.","In order to improve the sensitivity of the minority class without being biased to the majority class, the data balancing algorithms such as ROS, SMOTE, ADASYN, BSMOTE and SVMSMOTE, were applied to imbalanced dataset, HAM10000. It consists of a total of 10,015 dermoscopic images for 7 classes of skin disease with a resolution of 600×450. Then, their performances with and without the data balancing algorithms, including accuracies, sensitivities, precisions, F1-scores. were measured, respectively, and the effect of the data balancing algorithm was verified through 5-fold cross-validation test. Consequently, with applying the data balancing algorithms, the average values of the sensitivities(3.1%∼6.6%), precisions(2.2%∼7.5%) and F1-scores(2.7%∼6.6%) increased significantly (p<0.05). It was shown that they can contribute to the improvement of the performance of the classification of an imbalanced dataset using deep learning model."
인조 데이터를 활용한 차량 번호판 인식 시스템,2020,"['YOLO', 'LPR(License Plate Recognition)', 'Synthetic Data', 'Object Detection']","딥러닝 분야에서 학습 데이터는 네트워크의 성능을 결정하고 다양하고 많은 양의 학습 데이터로부터 네트워크의 성능을 높일 수 있다. 그러나 학습 데이터 수집과 라벨링 작업은 상당히 많은 시간과 인력이 필요하다. 마찬가지로 딥러닝 기반의 차량 번호판 문자 인식을 위해 다양한 종류의 차량 번호판 데이터와 문자 라벨링 작업이 필요하다. 본 논문에서는 실제 번호판 데이터 수집과 라벨링 작업에 많은 시간이 소요되는 문제를 해결하기 위해 인조 번호판 데이터 생성 프로그램을 개발하였다. 제안하는 차량 번호판 인식 시스템은 드론 환경에서 촬영한 영상이기 때문에 차량 번호판 문자 인식이 어려운 조건이다. 불리한 환경에서 차량 번호판 문자를 인식하기 위해 인조 번호판에 크기 변환, 밝기 변환, 회전, 배경 추가, 잡음 및 블러 추가 등과 같은 방법을 적용하여 열악한 환경의 학습 데이터를 생성하였다. 인조 번호판 데이터의 학습 결과를 평가하기 위해 자체적으로 실제 차량 번호판 사진 1,000장을 수집하여 테스트셋을 구성하였다. 결과적으로 실제 번호판 데이터 없이 1.5M개의 인조 번호판 데이터를 사용하여 전체 문자 인식 정확도 85%, 개별 문자 인식 정확도 94%를 기록하였다. 이후 후처리 알고리즘을 통해 88, 96% 정확도를 기록하였다.","In deep learning, training data can determine the performance of the network and increase the performance of the network from a diverse training data. However, gathering and labeling training data requires significant time and personnel. Likewise, various types of license plates and text labeling are required for deep learning based license plate character recognition. In this paper, we developed an synthetic license plate data generation program to solve the problem of time-consuming data collection and labeling. The proposed license plate recognition system is an image taken in a drone environment, which makes it difficult to recognize the license plate character. In order to recognize the license plate character in the adverse environment, we applied the methods such as scale transform, brightness conversion, rotation, background addition, noise and blur addition to the synthetic license plate to generate the training data in the harsh environment. To evaluate the training results of the synthetic license plate data, we collected 1,000 real license plates and constructed a test set. As a result, the total character recognition accuracy was 85% and the individual character recognition accuracy was 94% using 1.5M synthetic license plate data without the real license plate data. After that, 88, 96% accuracy was recorded through the post-processing algorithm."
프로세스 분석을 위한 설명 가능한 인공지능 기법 비교 연구,2020,"['Process mining', 'Process analysis automation', 'Machine learning', 'eXplainable AI']","프로세스 마이닝에 인공지능 기술을 적용하려는 시도는 여러 차례 있었으나 대부분이 프로세스 마이닝의 핵심 목적인 원인 분석이 아니라 프로세스 예측에 초점이 맞춰져 있었다. 이러한 예측모델에 설명 가능한 인공지능을 활용할 경우 전문가의 개인 역량과 상관없이 업무 프로세스상의 이슈와 그 원인을 분석할 수 있다. 그러나 아직까지 설명 가능한 인공지능은 활발한 연구가 진행 중인 분야로 다양한 기법들이 혼재하여 프로세스 원인 분석 자동화에 가장 적합한 방법론과 알고리즘이 정리되지 못하였다. 본 논문에서는 프로세스 원인 분석 자동화를 위해 딥러닝을 포함한 다양한 머신러닝 모델과 LIME, SHAP, LRP 등 여러 설명 가능한 인공지능 알고리즘들을 적용해보고 각각의 알고리즘들의 특징과 장단점을 비교하여 프로세스 이슈 원인 분석을 위한 최적의 방법을 제시하였다. 제시된 머신러닝 기법과 설명 가능한 인공지능 알고리즘을 활용한다면 프로세스 마이닝을 통한 비즈니스 이슈 원인 분석을 알고리즘 기반으로 정량적이고 쉽게 자동화할 수 있을 것이다.","There have been several attempts to apply artificial intelligence to process mining, but the focus is on process prediction, not on the causal analysis, which is the core purpose of process mining. If we use Explainable AI (XAI) to find issues in business processes and their causes, we can analyze the causes of the issues regardless of the expert's personal capabilities. However, the XAI technology is still in development, and various methods are mixed, so that the methodology and algorithm most suitable for automating of the process causal analysis have not been organized. In this paper, we thus apply various machine learning models including deep learning and various XAI algorithms such as LIME, SHAP and LRP to process analysis automation, and compare the characteristics and advantages of each algorithm to find the optimal process analysis automation methodology. If the proposed machine learning technique and XAI algorithm are used, it will be possible to automatically and quantitatively and easily analyze the cause of business issues through process mining based on an algorithm."
SegNet과 U-Net을 활용한 동남아시아 지역 홍수탐지,2020,"['SegNet', 'U-Net', 'Sentinel-1 A/B', 'Flooded area extraction', 'Deep Learning', 'Semantic Segmentation']","홍수 발생 시 위성영상을 활용하여 침수된 지역을 추출하는 것은 홍수 발생 기간 내의 위성영상 취득과영상에 나타난 침수구역의 정확한 분류 등에서 많은 어려움이 존재한다. 딥러닝은 전통적인 영상분류기법들에 비해 보다 정확도가 높은 위성영상분류기법으로 주목받고 있지만, 광학영상에 비해 홍수 발생 시 위성영상의 취득이 용이한 SAR 영상의 분류 잠재력은 아직 명확히 규명되지 않았다. 본 연구는 대표적인 의미론적 영상 분할을 위한 딥러닝 모델인 SegNet과 U-Net을 활용하여 동남아시아의 라오스, 태국, 필리핀의 대표적인 홍수 발생지역인 코랏 유역(Khorat basin), 메콩강 유역(Mekong river basin), 카가얀강 유역(Cagayan river basin)에대해 Sentinel-1 A/B 위성영상으로부터 침수지역 추출을 실시하였다. 분석결과 침수지역 탐지에서 SegNet의 Global Accuracy, Mean IoU, Mean BF Score는 각각 0.9847, 0.6016, 0.6467로 나타났으며, U-Net의Global Accuracy, Mean IoU, Mean BF Score는 각각 0.9937, 0.7022, 0.7125로 나타났다. 국지적 분류결과 확인을 위한 육안검증에서 U-Net이 SegNet에 비해 보다 높은 분류 정확도를 보여주었지만, 모델의 훈련에 필요한 시간은 67분 17초와187분 19초가 각각 소요되어 SegNet이 U-Net에 비해 약 3배 정도 빠른 처리속도를 보여주었다. 본 연구의 결과는 향후 딥러닝 기법을 활용한 SAR 영상기반의 홍수탐지 모델과 실무적으로 활용이 가능한 자동화된 딥러닝기반의 수계탐지 기법의 제시를 위한 중요한 참고자료로 활용될 수 있을 것으로 판단된다.","Flood monitoring using satellite data has been constrained by obtaining satellite images for flood peak and accurately extracting flooded areas from satellite data. Deep learning is a promising method for satellite image classification, yet the potential of deep learning-based flooded area extraction using SAR data remained uncertain, which has advantages in obtaining data, comparing to optical satellite data. This research explores the performance of SegNet and U-Net on image segmentation by extracting flooded areas in the Khorat basin, Mekong river basin, and Cagayan river basin in Thailand, Laos, and the Philippines from Sentinel-1 A/B satellite data. Results show that Global Accuracy, Mean IoU, and Mean BF Score of SegNet are 0.9847, 0.6016, and 0.6467 respectively, whereas those of U-Net are 0.9937, 0.7022, 0.7125. Visual interpretation shows that the classification accuracy of U-Net is higher than SegNet, but overall processing time of SegNet is around three times faster than that of U-Net. It is anticipated that the results of this research could be used when developing deep learning-based flood monitoring models and presenting fully automated flooded area extraction models."
ResNet 알고리즘을 이용한 가로수 객체의 폐색영역 검출 및 해결,2020,"['3D Spatial Information', 'Occlusion Area', 'Street Tree', 'Deep Learning', 'ResNet Algorithm']","국토를 효율적으로 관리하고 도시문제를 과학적으로 해결하기 위해 최근 스마트시티, 디지털트윈 등 3차원 공간정보 관련 기술이 급격하게 발전하고 있다. 이러한 3차원 공간정보 구축은 주로 영상정보를 이용하여 객체를 3차원 입체화하고 실감형 영상인 텍스처링 영상을 추출하여 객체벽면에 영상을 부여하는 방식으로 수행된다. 하지만 객체 주변의 다양한 요인으로 인해 텍스처링 영상에서는 필연적으로 폐색영역이 발생한다. 이에 본 연구에서는 최근 기술인 딥러닝 기술 중에서 ResNet 알고리즘을 이용하여 건물 폐색을 유발하는 가로수에 대한 데이터셋을 만들고 이에 대한 해결방안을 제시하고자 한다. 연구결과 ResNet 알고리즘의 공간정보 적용 가능성을 판단하고 이를 적용한 레이블링 생성 SW 개발하여 실제 가로수를 대상으로 데이터셋을 구축하였다. 구축된 데이터셋을 텍스처링 영상에 적용하여 정확도와 재현율로 검출능력을 분석하였다. 분석결과를 위해 딥러닝 분야에서 많이 사용되고 있는 정밀도와 재현율을 이용한 F값을 적용하였으며 가로수 단일 객체가 포함된 건물의 측면부 영상과 경사 영상에 대해서는 높은 F값을 도출하여 우수한 성과를 확인하였으나, 같은 해상도를 가진 건물 전면부 영상에서는 그림자 등의 요인으로 F값이 낮음을 확인하였다.","The technologies of 3D spatial information, such as Smart City and Digital Twins, are developing rapidly for managing land and solving urban problems scientifically. In this construction of 3D spatial information, an object using aerial photo images is built as a digital DB. Realistically, the task of extracting a texturing image, which is an actual image of the object wall, and attaching an image to the object wall are important. On the other hand, occluded areas occur in the texturing image. In this study, the ResNet algorithm in deep learning technologies was tested to solve these problems. A dataset was constructed, and the street tree was detected using the ResNet algorithm. The ability of the ResNet algorithm to detect the street tree was dependent on the brightness of the image. The ResNet algorithm can detect the street tree in an image with side and inclination angles."
데이터 사이언스를 활용한 사회안전망 강화: 의료보장제도 가입자의 위험 예측 모형 구축,2020,"['Data science', 'Artificial intelligence', 'Big data', 'Social safety net', '데이터 사이언스', '인공지능', '빅데이터', '사회안전망']","본 연구의 목표는 데이터 사이언스를 활용하여 공적의료보장제도 가입자의 위험률을 예측하는 모델을 구축하는 것이다. 이를 위해 먼저 본고는 데이터 사이언스적 접근의 개념과 최근 연구 추세를 살펴보았다. 다음으로는 이러한 논의를 적용하여 미국 공적의료보장제도 보험가입자의 입원율을 예측하는 모형을 구축하였다. 전통적 회귀모형, 일반 기계 학습모형, 딥러닝 모형을 포함한 6개의 모형을 비교했을 때, 딥러닝 모형들이 가장 재현율이 높았다. 특히 전방향 다중 신경망 모델은 사회 인구학적 정보를 통해 80%의 정확도로 환자의 재원 여부를 예측할 수 있었다. 결론에서는 모형의 예측력을 높일 수 있는 방안과 함께, 고위험 대상자에 대한 예방적 개입을 실시함에 있어 시사점을 논의하였다. 이러한 논의는 인공지능 기술을 이용하여 사회안전망을 강화하고 사회복지 재원이 위기 가정 및 개인에게 적절히 전달될 수 있도록 하기 위한 학술 및 정책 연구의 일환으로 기여할 수 있을 것이다.","This paper explores how data science can be used to strengthen the social safety net. As one such approach, the paper develops a model to predict the likelihood of hospital admission for Medicare and Medicaid insurers in the U.S. The analysis draws from the health insurance claims data of 45,000 patients with 939 features, spanning eight quarters from 2014 and 2015. Six models are adopted to predict patients' hospital admissions in 2016, based on their sociodemographic and health-related characteristics. The paper presents the rationale, processes, and results of analysis from logistic regression, Decision Tree, Random Forest, Support Vector Machine, feed-forward Multi-layer Perceptron (MLP), Convolution Neural Network, and Recurrent Neural Network. The best performing model, evaluated against recall and precision scores, is the MPL. This simple deep learning model was correct about 80% of the time for patient admissions to hospital. Additionally, tree-based algorithms provide important features related to hospital admission, such as medical risk scores. As a policy implication, the paper discusses predictive risk modeling to provide preventive care for at-risk populations. The paper concludes by suggesting strategies for using the data science approach in the allocation of social welfare programs and services."
시계열 기계학습을 이용한 한반도 남해 해수면 온도 예측 및 고수온 탐지,2020,"['sea surface temperature', 'prediction', 'ocean heatwave', 'Korea peninsula', 'machine learning', 'time-series']","해수면 온도는 전 세계 해양, 기상 현상에 영향을 주고 해양 환경 변화와 생물에게 영향을 주는 중요한요소이다. 특히, 우리나라 남해안을 비롯한 연안 지역의 경우 어업 및 양식업 등의 수산업이 많이 발달하여, 매년 고수온 현상으로 인한 사회·경제적 피해가 발생하고 있다. 따라서 위성 자료와 같은 광범위한 지역을 감시할 수 있는 자료를 활용한 해수면 온도 및 공간적 분포의 예측기술 개발을 통하여 피해를 예방할 수 있는 시스템을 구축할 필요가 있다. 해수면 온도 예측은 기존의 수치 모델을 통해서 예측을 진행하였지만, 다수의 역학적 요인들을 사용하여 예측 결과 산출 시 복잡함이 존재한다. 최근 기계학습 및 딥러닝 기법이 발달함에 따라해양 분야의 예측에 적용하는 연구가 진행되고 있다. 본 연구는 그 중 시·공간적인 일관성 및 정확도가 높은장단기 기억(Long Short Term Memory, LSTM)과 합성곱 장단기 기억(Convolutional Long Short Term Memory, ConvLSTM) 딥러닝 기법을 사용하여 남해지역의 해수면온도 예측 및 2017년부터 2019년까지의 고수온 발생건에 대해서 예측 결과의 공간 분포와 공간 분포와 예측 가능성에 대해 분석을 하였다. 1일 예측 모델의 정확도는 RMSE 기준으로 ConvLSTM(전체: 0.33°C, 봄: 0.34°C, 여름: 0.27°C, 가을: 0.32°C, 겨울: 0.36°C)이 LSTM 기반의 예측 모델(전체: 0.40°C, 봄: 0.40°C, 여름: 0.48°C, 가을: 0.39°C, 겨울: 0.34°C)보다 우수한 성능을 보였다. 2017 년 고수온 발생 사례에 대해 해수면 온도 예측과 고수온 탐지 성능에서 ConvLSTM은 5일까지 경보를 탐지하였지만, LSTM의 경우 2일 예측 이후 해수면 온도를 과소 추정하는 경향이 커짐에 따라 탐지하지 못하였다. 시공간적인 해수면 온도 예측 시 ConvLSTM이 LSTM에 비해 적절한 모델로 판단된다.","Sea Surface Temperature (SST) is an important environmental indicator that affects climate coupling systems around the world. In particular, coastal regions suffer from abnormal SST resulting in huge socio-economic damage. This study used Long Short Term Memory (LSTM) and Convolutional Long Short Term Memory (ConvLSTM) to predict SST up to 7 days in the south sea region in South Korea. The results showed that the ConvLSTM model outperformed the LSTM model, resulting in a root mean square error (RMSE) of 0.33℃ and a mean difference of -0.0098℃. Seasonal comparison also showed the superiority of ConvLSTM to LSTM for all seasons. However, in summer, the prediction accuracy for both models with all lead times dramatically decreased, resulting in RMSEs of 0.48℃ and 0.27℃ for LSTM and ConvLSTM, respectively. This study also examined the prediction of abnormally high SST based on three ocean heatwave categories (i.e., warning, caution, and attention) with the lead time from one to seven days for an ocean heatwave case in summer 2017. ConvLSTM was able to successfully predict ocean heatwave five days in advance."
LSTM 모형과 로지스틱 회귀를 통한 도시 침수 범위의 예측,2020,"['도시 홍수 분석', '침수 예측', 'LSTM 모형', '로지스틱 회귀', 'Flood prediction', 'Urban runoff analysis', 'LSTM model', 'Logistic regression']","기후변화의 영향으로 국지성 및 집중호우에 대한 발생 가능성이 높아지는 시점에서 과거에 침수피해를 입은 도시 유역에 대하여 실제 호우에 대한 침수 양상을 예측하는 것은 중요하다. 이에 수치해석 기반 프로그램과 함께 기계학습을 이용한 홍수 분석에 대한 연구가 증가하고 있다. 본 연구에서 적용한 LSTM 신경망은 일련의 자료를 분석하는데 유용하지만, 딥 러닝을 수행하기 위하여 충분한 양의 자료를 필요로 한다. 그러나 단일 도시유역에 홍수를 일으킬 강우가 매년 일어나지 않기에 많은 홍수 자료를 수집하기에는 어려움이 있다. 이에 본 연구에서는 대상 유역에서관측되는 강우 외에 전국 단위의 실제 호우를 예측 모형에 반영하였다. LSTM (Long Short-Term Memory) 신경망은 강우에 대한 총 월류량을 예측하기 위하여 사용되었으며, 목표값으로 SWMM (Storm Water Management Model)의 유출 모의 결과를 사용하였다. 침수 범위 예측을위해서는 로지스틱 회귀를 사용하였으며, 로지스틱 회귀 모형의 독립 변수는 총 월류량이며 종속 변수는 격자 별 침수 발생 유무이다. 침수 범위자료는 SWMM의 유출 결과를 바탕으로 수행된 2차원 침수해석 모의 결과를 통해 수집하였다. LSTM의 매개변수 조건에 따라 총 월류량 예측결과를 비교하였다. 매개변수 설정에 따른 4가지의 LSTM 모형을 사용하였는데, 검증과 테스트 단계에 대한 평균 RMSE (Root Mean SquareError)는 1.4279 , 1.0079 으로 산정되었다. 최소 RMSE는 검증과 테스트에 대하여 각각 1.1656 , 0.8797 으로 산정되었으며, SWMM모의 결과를 적절히 재현할 수 있음을 확인하였다. LSTM 신경망의 결과와 로지스틱 회귀를 연계하여 침수 범위 예측을 수행하였으며, 침수심 0.5m 이상을 고려하였을 때에 최대 침수면적 적합도가 97.33 %으로 나타났다. 본 연구에서 제시된 방법론은 딥 러닝에 기반하여 도시 홍수 대응능력을 향상 시키는데 도움이 될 것으로 판단된다.","Because of climate change, the occurrence of localized and heavy rainfall is increasing. It is important to predict floods in urban areasthat have suffered inundation in the past. For flood prediction, not only numerical analysis models but also machine learning–basedmodels can be applied. The LSTM (Long Short-Term Memory) neural network used in this study is appropriate for sequence data, butit demands a lot of data. However, rainfall that causes flooding does not appear every year in a single urban basin, meaning it is difficultto collect enough data for deep learning. Therefore, in addition to the rainfall observed in the study area, the observed rainfall in anotherurban basin was applied in the predictive model. The LSTM neural network was used for predicting the total overflow, and the resultof the SWMM (Storm Water Management Model) was applied as target data. The prediction of the inundation map was performed byusing logistic regression; the independent variable was the total overflow and the dependent variable was the presence or absence offlooding in each grid. The dependent variable of logistic regression was collected through the simulation results of a two-dimensionalflood model. The input data of the two-dimensional flood model were the overflow at each manhole calculated by the SWMM.According to the LSTM neural network parameters, the prediction results of total overflow were compared. Four predictive models wereused in this study depending on the parameter of the LSTM. The average RMSE (Root Mean Square Error) for verification and testingwas 1.4279 , 1.0079  for the four LSTM models. The minimum RMSE of the verification and testing was calculated as 1.1655 and 0.8797 . It was confirmed that the total overflow can be predicted similarly to the SWMM simulation results. Theprediction of inundation extent was performed by linking the logistic regression with the results of the LSTM neural network, and themaximum area fitness was 97.33 % when more than 0.5  depth was considered. The methodology presented in this study would behelpful in improving urban flood response based on deep learning methodology."
상처와 주름이 있는 지문 판별에 효율적인 심층 학습 비교연구,2020,"['딥러닝', '지문', '생체정보', '2D 합성 곱 신경망', '상처 지문 판별', '주름 지문 판별', 'Deep learning', 'Biometric information', '2D Convolutional Neural Network', 'discriminating of scar fingerprint', 'discriminating of wrinkle fingerprint']","인간의 특성과 관련된 측정 항목을 나타내는 생체정보는 도난이나 분실의 염려가 없으므로 높은 신뢰성을 가진 보안 기술로서큰 주목을 받고 있다. 이러한 생체정보 중 지문은 본인 인증, 신원 파악 등의 분야에 주로 사용된다. 신원을 파악할 때 지문 이미지에인증을 수행하기 어려운 상처, 주름, 습기 등의 문제가 있을 경우, 지문 전문가가 전처리단계를 통해 직접 지문에 어떠한 문제가 있는지 파악하고 문제에 맞는 영상처리 알고리즘을 적용해 문제를 해결한다. 이때 지문에 상처와 주름이 있는 지문 영상을 판별해주는인공지능 소프트웨어를 구현하면 손쉽게 상처나 주름의 여부를 확인할 수 있고, 알맞은 알고리즘을 선정해 쉽게 지문 이미지를 개선할 수 있다. 본 연구에서는 이러한 인공지능 소프트웨어의 개발을 위해 캄보디아 왕립대학교의 학생 1,010명, Sokoto 오픈 데이터셋 600명, 국내 학생 98명의 모든 손가락 지문을 취득해 총 17,080개의 지문 데이터베이스를 구축했다. 구축한 데이터베이스에서 상처나 주름이 있는 경우를 판별하기 위해 기준을 확립하고 전문가의 검증을 거쳐 데이터 어노테이션을 진행했다. 트레이닝 데이터셋과테스트 데이터셋은 캄보디아의 데이터, Sokoto 데이터로 구성하였으며 비율을 8:2로 설정했다. 그리고 국내 학생 98명의 데이터를검증 데이터 셋으로 설정했다, 구성된 데이터셋을 사용해 Classic CNN, AlexNet, VGG-16, Resnet50, Yolo v3 등의 다섯 가지 CNN 기반아키텍처를 구현해 학습을 진행했으며 지문의 상처와 주름 판독에서 가장 좋은 성능을 보이는 모델을 찾는 연구를 수행했다. 다섯가지 아키텍처 중 지문 영상에서 상처와 주름 여부를 가장 잘 판별할 수 있는 아키텍처는 ResNet50으로 검증 결과 81.51%로 가장좋은 성능을 보였다.","Biometric information indicating measurement items related to human characteristics has attracted great attention as security technology with high reliability since there is no fear of theft or loss. Among these biometric information, fingerprints are mainly used in fields such as identity verification and identification. If there is a problem such as a wound, wrinkle, or moisture that is difficult to authenticate to the fingerprint image when identifying the identity, the fingerprint expert can identify the problem with the fingerprint directly through the preprocessing step, and apply the image processing algorithm appropriate to the problem. Solve the problem. In this case, by implementing artificial intelligence software that distinguishes fingerprint images with cuts and wrinkles on the fingerprint, it is easy to check whether there are cuts or wrinkles, and by selecting an appropriate algorithm, the fingerprint image can be easily improved. In this study, we developed a total of 17,080 fingerprint databases by acquiring all finger prints of 1,010 students from the Royal University of Cambodia, 600 Sokoto open data sets, and 98 Korean students. In order to determine if there are any injuries or wrinkles in the built database, criteria were established, and the data were validated by experts. The training and test datasets consisted of Cambodian data and Sokoto data, and the ratio was set to 8: 2. The data of 98 Korean students were set up as a validation data set. Using the constructed data set, five CNN-based architectures such as Classic CNN, AlexNet, VGG-16, Resnet50, and Yolo v3 were implemented. A study was conducted to find the model that performed best on the readings. Among the five architectures, ResNet50 showed the best performance with 81.51%."
자율주행 환경에서 이미지 객체 분할을 위한 강화된 DFCN 알고리즘 성능연구,2020,"['딥 풀리 컨벌루셔널 네트워크', '객체 분할', '자율주행', '유넷', '도로상황', 'Deep Fully Convolutional Network', 'Object Segmentation', 'Autonomous driving', 'U-net', 'Road Situation']","최근 이미지 분할(Image Segmentation)에 관련되어 스마트 공장 산업과 의료 분야 등에 접목하려는 연구가 다수 진행되고 있다. 특히 딥러닝 알고리즘을 사용한 이미지 분할 시스템들은 대용량의 데이터를 높은 정확도로 학습할 만큼 발전되었다. 자율주행 분야에서도 이미지 분할을 이용하기 위해선 대용량의 데이터들에 대한 충분한 학습량이 필요하며, 실시간으로 운전자의 데이터를 처리하는 스트리밍 환경은 고속도로, 어린이보호구역 등으로 안전운행에 대한 정확도가 중요하다. 따라서 본 논문에서는 다양한 도로환경에 적용할 수 있는 기존 FCN(Fully Convoulutional Network) 알고리즘을 강화한 DFCN 알고리즘을 제안하였으며, DFCN 알고리즘의 성능이 FCN 알고리즘과 비교하여 손실 값 측면에서 1.3% 개선하였음을 증명하였으며, 기존 U-Net 알고리즘에 DFCN 알고리즘을 적용하여 이미지 내의 주파수의 정보를 유지하여 더 좋은 결과치를 도출함으로써 결과적으로 자율주행 환경에서 DFCN 알고리즘이 FCN 알고리즘보다 성능이 향상되었다는 것을 증명하였다.","Recently, various studies are being conducted to integrate Image Segmentation into smart factory industries and autonomous driving fields. In particular, Image Segmentation systems using deep learning algorithms have been researched and developed enough to learn from large volumes of data with higher accuracy. In order to use image segmentation in the autonomous driving sector, sufficient amount of learning is needed with large amounts of data and the streaming environment that processes drivers data in real time is important for the accuracy of safe operation through highways and child protection zones. Therefore, we proposed a novel DFCN algorithm that enhanced existing FCN algorithms that could be applied to various road environments, demonstrated that the performance of the DFCN algorithm improved 1.3% in terms of loss value compared to the previous FCN algorithms. Moreover, the proposed DFCN algorithm was applied to the existing U-Net algorithm to maintain the information of frequencies in the image to produce better results, resulting in a better performance than the classical FCN algorithm in the autonomous environment."
행동기반 사물 감지를 통한 위급상황 확인 시스템 개발,2020,"['딥러닝', 'SSD 모델', 'UDP 소켓', '객체 감지', 'OpenCV', 'Deep Learning', 'SSD Model', 'UDP Socket', 'Object Detection', 'OpenCV']",기존의 방범 시스템은 피해자가 직접 구조를 요청하거나 인근 제 3자에 의해 도움을 받아야 하는 구조이기 때문에 신속하게 대응이 불가능한 상황에서는 경우에 따라 적절한 도움을 받기 힘들다. 본 연구에서는 Deep Learning과 OpenCV를 활용한 자동 구조 요청 모델을 제안하고 시스템을 개발하였다. 본 연구는 사용자의 안전을 보장할 수 있어야 하기 때문에 신속히 정확한 결과를 도출할 수 있어야 한다는 전제 조건이 밑바탕 되어 객체의 정확성은 약 99% 이상을 확인할 수 있었으며 모든 알고리즘이 종료되는 데까지의 소요 시간을 약 3초까지 단축시킬 수 있었다. 다양한 위협 요소와 예측 불가능한 특수한 경우 등 모든 위험 상황을 인식하기 위해 다양한 종류의 위협 요소와 많은 양의 데이터를 수집하여 예기치 못한 상황에도 대처할 수 있도록 강화하여야 할 것이다.,"Since the current crime prevention systems have a standard mechanism that victims request for help by themselves or ask for help from a third party nearby, it is difficult to obtain appropriate help in situations where a prompt response is not possible. In this study, we proposed and developed an automatic rescue request model and system using Deep Learning and OpenCV. This study is based on the prerequisite that immediate and precise threat detection is essential to ensure the user’s safety. We validated and verified that the system identified by more than 99% of the object’s accuracy to ensure the user’s safety, and it took only three seconds to complete all necessary algorithms. We plan to collect various types of threats and a large amount of data to reinforce the system’s capabilities so that the system can recognize and deal with all dangerous situations, including various threats and unpredictable cases."
End-to-end Bone Tumor Segmentation and Classification from X-ray Images by Using Multi-level Seg-Unet Model,2020,"['딥러닝', '무릎 골 종양', '의료 영상 분할', 'unet', 'segnet', 'dice loss', 'deep learning', 'knee bone tumor', 'medical image segmentation']",,"Knee bone tumor detection plays an essential role in assisting the clinical diagnosis process. To the best of our knowledge, there is no method to integrate end-to-end segmentation and classification for this problem. In this paper, we propose a multi-task deep learning architecture for classification and segmentation of the tumor regions in the knee bone. Also, we introduce multi-level distance masks from the distance transform of tumor region, and these multi-level distance masks have a role as a guided filter in enabling the network to capture semantic data around tumor regions. Besides, the architecture has a regularizing effect on the learning process between segmentation and classification. Our model was evaluated on the Chonnam National University Hospital dataset and achieved good performance compared to other methods."
Hybrid CNN-LSTM 알고리즘을 활용한 도시철도 내 피플 카운팅 연구,2020,"['딥러닝', '피플 카운팅', '메트로 서비스 CNN-LSTM', '사물인터넷(IoT)', '빅데이터', '센서', '스마트시티', 'Deep Learning', 'People Counting', 'Metro service', 'CNN-LSTM', 'IoT', 'Sensor', 'Smart city']",,"In line with the trend of industrial innovation, IoT technology utilized in a variety of fields is emerging as a key element in creation of new business models and the provision of user-friendly services through the combination of big data. The accumulated data from devices with the Internet-of-Things (IoT) is being used in many ways to build a convenience-based smart system as it can provide customized intelligent systems through user environment and pattern analysis. Recently, it has been applied to innovation in the public domain and has been using it for smart city and smart transportation, such as solving traffic and crime problems using CCTV. In particular, it is necessary to comprehensively consider the easiness of securing real-time service data and the stability of security when planning underground services or establishing movement amount control information system to enhance citizens or commuters’ convenience in circumstances with the congestion of public transportation such as subways, urban railways, etc. However, previous studies that utilize image data have limitations in reducing the performance of object detection under private issue and abnormal conditions.  The IoT device-based sensor data used in this study is free from private issue because it does not require identification for individuals, and can be effectively utilized to build intelligent public services for unspecified people. Especially, sensor data stored by the IoT device need not be identified to an individual, and can be effectively utilized for constructing intelligent public services for many and unspecified people as data free form private issue.  We utilize the IoT-based infrared sensor devices for an intelligent pedestrian tracking system in metro service which many people use on a daily basis and temperature data measured by sensors are therein transmitted in real time. The experimental environment for collecting data detected in real time from sensors was established for the equally-spaced midpoints of 4x4 upper parts in the ceiling of subway entrances where the actual movement amount of passengers is high, and it measured the temperature change for objects entering and leaving the detection spots. The measured data have gone through a preprocessing in which the reference values for 16 different areas are set and the difference values between the temperatures in 16 distinct areas and their reference values per unit of time are calculated. This corresponds to the methodology that maximizes movement within the detection area. In addition, the size of the data was increased by 10 times in order to more sensitively reflect the difference in temperature by area. For example, if the temperature data collected from the sensor at a given time were 28.5°C, the data analysis was conducted by changing the value to 285. As above, the data collected from sensors have the characteristics of time series data and image data with 4x4 resolution. Reflecting the characteristics of the measured, preprocessed data, we finally propose a hybrid algorithm that combines CNN in superior performance for image classification and LSTM, especially suitable for analyzing time series data, as referred to CNN-LSTM (Convolutional Neural Network-Long Short Term Memory).  In the study, the CNN-LSTM algorithm is used to predict the number of passing persons in one of 4x4 detection areas. We verified the validation of the proposed model by taking performance comparison with other artificial intelligence algorithms such as Multi-Layer Perceptron (MLP), Long Short Term Memory (LSTM) and RNN-LSTM (Recurrent Neural Network-Long Short Term Memory). As a result of the experiment, proposed CNN-LSTM hybrid model compared to MLP, LSTM and RNN-LSTM has the best predictive performance. By utilizing the proposed devices and models, it is expected various metro services will be provided with no illegal issue about the personal information such as real-time monitoring of publi"
시간적 행동 검출: 서베이,2020,"['딥러닝', '시간적 행동 검출', '오프라인 행동 검출', '온라인 행동 검출', 'deep learning', 'temporal action detection', 'offline action detection', 'online action detection']",,
Long-distant Coreference Resolution by Clustering-extended BERT for Korean and English Document,2020,"['딥러닝', '자연언어처리', '상호참조해결', 'deep learning', 'natural language processing', 'coreference resolution', 'BERT']",,
Evaluation of Classification and Accuracy in Chest X-ray Images using Deep Learning with Convolution Neural Network,2020,"['딥러닝', '합성곱 신경망 네트워크', '폐렴', '흉부 X-ray', 'Deep Learning', 'CNN', 'Pneumonia', 'Chest X-Ray']","본 연구에서는 CNN과 빅데이터 기술을 이용한 Deep Learning을 통해 흉부 X-ray 영상 분류 및 정확성 연구에 대하여 알아보고자 한다. 총 5,873장의 흉부 X-ray 영상에서 Normal 1,583장, Pneumonia 4,289장을 사용하였다. 데이터 분류는 train(88.8%), validation(0.2%), test(11%)로 분류하였다. Convolution Layer, Max pooling layer pool size 2×2, Flatten layer, Image Data Generator로 구성하였다. Convolution layer가 3일 때와 4일 때 각각 filter 수, filter size, drop out, epoch, batch size, 손실함수 값을 설정하였다. test 데이터로 Convolution layer가 4일 때, filter 수 64-128-128-128, filter size 3×3, drop out 0.25, epoch 5, batch size 15, 손실함수 RMSprop 으로 설정 시 정확도가 94.67%였다. 본 연구를 통해 높은 정확성으로 분류가 가능하였으며, 흉부 X-ray 영상뿐만 아니라 다른 의료영상에서도 많은 도움이 될 것으로 사료된다.","The purpose of this study was learning about chest X-ray image classification and accuracy research through Deep Learning using big data technology with Convolution Neural Network. Normal 1,583 and Pneumonia 4,289 were used in chest X-ray images. The data were classified as train (88.8%), validation (0.2%) and test (11%). Constructed as Convolution Layer, Max pooling layer size 2×2, Flatten layer, and Image Data Generator. The number of filters, filter size, drop out, epoch, batch size, and loss function values were set when the Convolution layer were 3 and 4 respectively. The test data verification results showed that the predicted accuracy was 94.67% when the number of filters was 64-128-128-128, filter size 3×3, drop out 0.25, epoch 5, batch size 15, and loss function RMSprop was 4. In this study, the classification of chest X-ray Normal and Pneumonia was predictable with high accuracy, and it is believed to be of great help not only to chest X-ray images but also to other medical images."
인공지능을 적용한 소형 모바일 로봇을 위한 물체 및 환경 인식 연구,2020,"['딥러닝', '욜로', '휠-레그 모바일 로봇', '험지극복', '환경인식', 'Deep Learning', 'YOLO', 'Wheel-Leg Mobile Robot', 'Obstacle Overcoming', 'Environment Recognition']",,"In this research we study artificial intelligence-based environment recognition for autonomous navigation of a small mobile robot with limited hardware resources. Toward this goal, we designed a wheel-leg mobile robot that could transform its circular wheel configuration into wheel-leg configuration for rugged terrain locomotion. Size of a wheel-leg can be increased up to 2.5 times larger when compared to circular wheel configuration applying gear-driven mechanisms. A web camera and less expensive embedded board integrated with a GPU are used in the case. We used YOLOv3 as a deep learning model to recognize obstacles in real time. Performance of learned model is verified using mAP and GIoU. Our proposed object recognition algorithm is implemented in the real wheel-leg mobile robot and its performance is verified in unstructured environments."
A Deep Learning LSTM Framework for Urban Traffic Flow and Fine Dust Prediction,2020,"['딥러닝', '장단기 메모리', '교통흐름 예측', '도심지 미세먼지 예측', 'deep learning', 'long short term memory', 'traffic flow prediction', 'fine dust prediction']",,
마취용 처치 추천을 위한 설명 가능한 딥뉴럴 네트워크,2020,"['딥러닝', '설명 가능한 인공지능', '마취 처치 추천', '정형 데이터', 'deep learning', 'explainable AI', 'anesthetic treatment recommendation', 'structured data']","본 논문에서는 수술 중 환자에 대한 17개의 생체정보(Vital sing)에 대응하여 주어진 처치 후보 중 최적의 처치 방법을 추천하는 마취용 처치 추천 모델 구축 방법을 제안한다. 의학 분야 시스템의 결과는 최종적으로 사람에게 적용되기 때문에 모델의 결과에 대한 신뢰성 확보가 중요하다. 제안 모델은 가중치 곱에서 이루어지는 합 연산을 max-pooling으로 대체해 각 입력 자질에 대한 가중치를 독립적으로 계산한다. 따라서 모델은 gradient descent를 이용하여 학습될 수 있으며, 추천된 결과에 대한 근거를 제시할 수 있다. 양산부산대병원의 데이터를 이용한 예비 실험을 통해 가능성을 보이며, 추가로 수집한 정형데이터에 적용하여 효용성을 확인하였다.","In this paper, we propose a method for constructing an anesthesia treatment recommendation model that suggests an optimal treatment among given treatment candidates in response to 17 vital information regarding a patient during surgery. Since the results of the model in the medical field are finally applied to humans, it is crucial to ensure the reliability of the model results. The proposed model replaces the summation with max-pooling to independently calculate the weights for each input feature. Thus, the model can be trained using gradient descent and can provide a basis for the recommended results. We show the possibility through preliminary experiments using data from Pusan National University Yangsan Hospital, and apply the method to the additional collected structured data to confirm its effectiveness."
게임데이터를 이용한 승패예측 및 세분화된 변수 중요도 도출 기법,2020,"['딥러닝', '게임데이터', '빅데이터', '앙상블', 'Deep Learning', 'Game Data', 'AOS', 'Aeon Of Srtife', 'Big Data', 'XGboost', 'Ensemble']",,"With the development in the IT industry and the growth in the game industry, user’s game data is recorded in seconds according to various plays and options, and a vast amount of game data can be analyzed based on Bigdata. Combined with business, Bigdata is used to discover new values for profit creation in various fields, but it is utilized in the game industry in insufficient ways. In this study, considering the characteristics of the subdivided lines, we constructed a win-loss prediction model for each line using the game data of League of Legends, and derived the importance of variables. This study can contribute to planning of strategies for general game users to get information about team members in advance and increase the win rate by using the record search sites."
순환신경망(RNN)을 활용한 개별 학생 학업성취도의 종단적 예측,2020,"['머신러닝', '딥러닝', '심층신경망', '순환신경망', '학업성취 예측', 'Artificial neural network', 'deep learning', 'machine learning', 'prediction of academic performance', 'recurrent neural network']","학생들이 학교교육을 통해 기초학력을 갖추도록 돕는 것은 공교육이 담당해야 할 중요한 책무이다. 기초학력에 도달하지 못한 상태에서 다음 학년에 진입하게 되면 기초학력 미달이 장기화할 수 있고 결과적으로 학업적 실패로 이어질 수 있기 때문이다. 따라서 학생의 미래 성취 수준을 조기에 예측하고 적시에 개입하는 것은 매우 중요하다. 이에 본 연구에서는 개별 학생의 학업성취 수준을 예측하기 위한 방법으로서, 최근 다양한 분야에서 활용되고 있는 순환신경망(RNN)을 국가수준 학업성취도평가 자료에 적용함으로써, 교육 종단 자료를 바탕으로 미래의 학업 성취를 예측할 수 있는 방안을 탐색하였다. 본 연구에서는 2011년 초등 6학년부터 2016년 고등 2학년까지 세 시점의 국가수준 학업성취도평가 자료를 사용하였으며, RNN을 적용하여 미래 시점의 기초 이하 여부를 예측한 결과를 HGLM 모형 적용 결과와 비교하였다. 두 모형은 대체로 유사한 예측 성능을 보였으며, HGLM으로는 결과 산출이 어려운 구조에서도 RNN을 적용하여 기초 이하 여부를 예측할 수 있었다. 본 연구 결과를 토대로 학업성취의 조기예측과 관련한 순환신경망의 장점과 제한점에 대해 제안하였다.","Helping students to meet the national standards of academic performance is very important in that failure to meeting the standards can have a detrimental effect on learning and can lead to long-term learning deficits. It is important to understand the state of individual student s academic achievement and identify students with potential academic failure, so that timely intervention can be made to prevent student failure. In this study, an artificial neural network (ANN) was applied to the National Assessment of Educational Achievement data to predict performance of a student in his/her 11th grade based on various information related to academic performance collected in the 6th and 9th grades. The recurrent neural network (RNN) was employed as a promising model for longitudinal prediction, and the performance of the RNN was compared with a traditional approach, the hierarchical general linear model (HGLM). The results showed that both RNN and HGLM models showed similar performances in the data collection designs to which both models can be applied. In addition, the RNN had advantages over the HGLM in that it can be also applied to situations where application of the HGLM is not feasible. Based on the results of this study, the advantages and disadvantages of the RNN in longitudinal prediction of educational data was discussed."
인공지능 모델에 따른 한국 프로야구의 승패 예측 분석에 관한 연구,2020,"['머신러닝 모델', 'KNN과 AdaBoost', '딥러닝 모델', '프로야구', '승패 예측', 'Machine Learning Model', 'KNN and AdaBoost', 'Deep Learning Model', 'Professional Baseball', 'Win-Loss Prediction']",,"In this study, we conducted a study on the win-loss predicton analysis of korean professional baseball by artificial intelligence models. Based on the model, we predicted the winner as well as each team’s final rank in the league. Additionally, we developed a website for viewers’ understanding. In each game’s first, third, and fifth inning, we analyze to select the best model that performs the highest accuracy and minimizes errors. Based on the result, we generate the rankings. We used the predicted data started from May 5, the season’s opening day, to August 30, 2020 to generate the rankings. In the games which Kia Tigers did not play, however, we used actual games’ results in the data. KNN and AdaBoost selected the most optimized machine learning model. As a result, we observe a decreasing trend of the predicted results’ ranking error as the season progresses. The deep learning model recorded 89% of the model accuracy. It provides the same result of decreasing ranking error trends of the predicted results that we observe in the machine learning model. We estimate that this study’s result applies to future KBO predictions as well as other fields. We expect broadcasting enhancements by posting the predicted winning percentage per inning which is generated by AI algorism. We expect this will bring new interest to the KBO fans. Furthermore, the prediction generated at each inning would provide insights to teams so that they can analyze data and come up with successful strategies."
미국에 있어서 AI발명의 특허적격성 판단과 동향분석,2020,"['AI발명', '딥러닝', '특허적격성', '알고리즘', '특허심사', 'AI invention', 'Deep Learning', 'patent eligibility', 'algorithm', 'patent examination']","AI발명은 지능형 인간과 같은 의사결정을 내릴 수 있는 컴퓨터기반 장치에 중점을 둔 것으로 넓은 의미로 SW발명의 유형에 해당한다. 다만 인간이 만들어 놓은 AI기술을 이용하여 특정 학습용데이터 구조를 학습프로그램에 의하여 반복학습함으로써 최적의 목적을 달성한다는 AI의 지능 및 그 구현수단에 대해서도 특허적격성이 있다고 볼 것인지가 쟁점이 되고 있다.이와 관련하여 미국특허청(USPTO)은 2019년 1월부터 시행하여 오던 특허적격성 판단 가이던스를 개정하여 동년 10월 17일자로 시행하고 있다. 그리고 2020년 4월 23일에는 동 가이던스를 적용한 특허적격성 판단의 효과에 대한 분석 리포트를 발표하였다. 동 리포트에 의하면, 동 가이던스를 발표･적용한 후의 1년간 특허적격성을 충족하지 않는다는 취지의 거절이유를 포함하는 최초 거절이유통지서(FA)가 특허출원인에게 통지될 확률이 25%감소되었고, 특허적격성 판단에 관한 심사의 불확실성이 44% 감소한 것을 알 수 있었다.그럼에도 불구하고 본 가이던스만으로 AI발명의 특허적격성을 판단함에 있어서 다른 문제가 없는 것인지에 대해 논란이 있었고, USPTO는 세계 각국 기관들로부터 미국의 법제도의 특허적격성에 대해 의견청취를 하고 그 결과를 2020년 3월 18일에 공개하였다. 공개된 의견서에는 AI발명과 관련한 현행 미국의 법제도 및 심사에 관한 다양한 내용들이 개진되어 있다.이러한 다양한 의견을 미국의 법제도에 어떻게 반영될 것인지, 특히 AI발명의 특허적격성 판단기준이 어떻게 변화할 것인지는 앞으로 매우 중요한 쟁점이 될 것이다. 이러한 미국의 AI발명의 특허적격성 판단기준은 우리나라에도 많은 영향을 미칠 수 있는 중요한 내용으로, 향후 미국의 제도변화를 깊이 분석하여 대처할 필요가 있다.","The AI invention puts emphasis on the computer-based device which can determine such as the intelligent human and corresponds to the type of SW invention in a broad sense. With respect to the intelligence of the AI which achieves the best purpose by repetitively learning a specific learning data structure by the learning program using the AI technology made by the human, and the realizing means thereof, it has become an issue to have the patent eligibility.In relation therewith, the USPTO revises the patent eligibility determination guideline which had been executed from January 2019 to execute as of October 17, 2019. Especially the analyzing report on the effect of the patent eligibility determination which applies this guideline was issued on April 23, 2020. By this report, it can be known that during one year after issuing/applying this guideline, the probability of noticing the first action including the rejection of the purpose not satisfying the patent eligibility to the applicant has been reduced by 25% and also the uncertainty of the examination relating to the patent eligibility determination has been reduced by 44%.Nevertheless the USPTO receives opinions on the patent eligibility from the various organizations of the world with respect to the question whether there is a problem to determine the patent eligibility in the AI invention only by this guideline, and the US law system, and discloses results thereof on March 18, 2020. In the disclosed written opinion, the various contents regarding the current US law system and examination related to the AI invention are described.It is a matter of interest how to reflect from now on such a various opinion to the US law system to accept the patent eligibility of the AI invention, Since such a patent eligibility determination of the AI invention in US would have a lot of effect on our country, it is needed to deeply analyze te system change in US to cope therewith."
MR 영상을 이용한 합성곱 신경망 기반의 상완골두 및 관절와 자동 분할,2020,"['인공지능', '딥러닝', '분할', '합성곱 신경망', '어깨 질환', 'Artificial Intelligence', 'Deep learning', 'Segmentation. Convolution Neural Network', 'Shoulder disease']","어깨 관련 질환에는 회전근개 손상, 관절와순손상, 어깨충돌증후군 및 습관성어깨탈구 등이 있다. 건강보험진료 통계에 따르면, 이러한 어깨병변으로 진료를 받은 환자수는 매년 증가하는 추세이다. 어깨 관련 질환을 진단하는 대표적인 방법으로 MRI(Magnetic Resonance Imaging,자기공명영상)가 있다. 본 논문에서는 합성곱 신경망 알고리즘인 U-net을 이용해 MR 영상에서 상완골두와 관절와 부위를 자동 분할함으로써 전문의가 관련 질환을 더욱 빠르게 진단하는 데 도움을 주는 연구를 진행하고자 한다. 81명 환자의 MR 영상 총 2251장을 수집하여 이를 훈련셋과 테스트셋으로 사용하였다. 427장 데이터로 검증한 U-net으로 훈련된 어깨뼈 분할 모델의 평가 결과로 민감도 89.32%, 특이도 99.78%, 정확도 99.44% 다이스 계수 92.02%를 보였다. 추후 영상처리 기법을 통해 어깨뼈의 경계영역의 모호성을 해결하고 추가 데이터 수집을 통해 관절와 영역을 충분히 훈련시킨다면 보다 높은 정확도를 얻어 전문의의 진단에 큰 도움을 줄 수 있을 것이라 기대한다.","Shoulder-related disorders include joint and labial injuries, shoulder impingement syndrome, habitual shoulder dislocation and slab lesions. According to health insurance statistics, the number of patients treated with these shoulder lesions is increasing every year. MRI (Magnetic Resonance Imaging) is a representative method of diagnosing such shoulder-related diseases. In this paper, we will use U-net, a convolution neural network algorithm, to automatically segment humeral heads, joints in MR images to help doctors diagnose related diseases more quickly. A total of 2251 MR images of 81 patients were collected and used as training set and test set. As a result of evaluation of U-net trained scapular segmentation model validated by chapter 427 data, sensitivity of 89.32%, specificity of 99.78%, accuracy of 99.44%, and die coefficient of 92.02%. In the future, image processing techniques will solve the ambiguity of the scapular border and collect additional data to fully train the joints and regions, which will provide a higher level of accuracy and help the diagnosis for doctors."
LEXAI : 설명 가능한 인공지능을 이용한 법률 문서 유사도 분석 서비스,2020,"['설명 가능한 인공지능', '트랜스포머', '딥 네트워크 학습', '문서 분류', '유사도', 'explainable AI', 'transformer', 'deep neural network', 'deep learning', 'document classification', 'similarity']","최근 딥러닝 학습의 성능이 향상됨에 따라, 전문적인 분야에서 이 방법을 사용하려는 연구가 다양해지고 있다. 유사한 논리적 의미를 가진 법률 문서의 검색은 법률 분야에서 매우 중요한 부분이지만, 관련 분야의 전문적인 지식을 요구하기 때문에 전문가 시스템을 사용한 서비스에서 벗어나기 어려운 실정이다. 또한, 전문가 시스템을 구성하는 데는 전문 인력의 비용이 과다하게 발생하므로 자동화된 유사 법률 문서 검색환경을 구축하기에 어려운 점이 있다. 기존의 유사 문서 검색 서비스가 전문가 시스템과 통계적 시스템에 기반하는 환경을 제공하는데 비하여, 제안하는 방법은 분류 작업을 위한 뉴럴 네트워크를 학습하고 이를 사용하는 방법을 채택하였다. 우리는 설명 가능한 뉴럴 네트워크를 이용하여 의미적 유사도가 높은 법률 문서간의 검색을 제공하는 데이터베이스 시스템 구조를 제안하였다. 이러한 제안 기법의 특징은 유사 문서들 간의 의미적 관련성에 대한 시각적 유사도 평가 방법을 마련하고 이를 검증하는 성과를 보여준다.","Recently, in keeping with the improvement of deep learning, studies on using deep learning a specialized field have diversified. Semantic searching for legal documents is an essential part of the legal field. However, it is difficult to function outside of the service using the expert system because it requires professional knowledge in the relevant field. It is also challenging to establish an automated, semantically similar legal document retrieval environment because the cost of hiring professional human resources is high. While existing retrieval services provide an environment based on expert systems and statistical systems, the proposed method adopts the deep learning method with a classification task. We propose a database system structure that provides searching for legal documents with high semantic similarity using an explainable neural network. The features of these proposed methods show the performance of developing and verifying visual similarity assessment methods for semantic relevance among similar documents."
기계 번역에 대한 몇 가지 오해,2020,"['기계번역', '딥러닝', '코퍼스', '기술', '인공지능', 'Machine translation', 'deep learning', 'corpus', 'technology', 'artificial intelligence']",,
RGB-csb를 활용한 제한된 CNN에서의 정확도 분석 및 비교,2020,"['정확도', '딥러닝', '커널', '레이어', '학습 시간', 'Accuracy', 'CNN(Convolution Neural Network)', 'Deep Learning', 'Kernel', 'Layer', 'Learning Time']","본 논문은 대부분의 변형된 CNN(: Convolution Neural Networks)에서 사용하지 않는 첫 번째 컨볼루션 층(convolution layer)을 사용해 정확도 향상을 노리는 방법을 소개한다. GoogLeNet, DenseNet과 같은 CNN에서 첫 번째 컨볼루션 층에서는 기존방식(3x3 컨볼루션연산 및 배규정규화, 활성화함수)만을 사용하는데 이 부분을 RGB-csb(: RGB channel separation block)로 대체한다. 이를 통해 RGB값을 특징 맵에 적용시켜 정확성을 향상시킬 수 있는 선행연구 결과에 추가적으로, 기존 CNN과 제한된 영상 개수를 사용하여 정확도를 비교한다. 본 논문에서 제안한 방법은 영상의 개수가 적을수록 학습 정확도 편차가 커 불안정하지만 기존 CNN에 비해 정확도가 평균적으로 높음을 알 수 있다. 영상의 개수가 적을수록 평균적으로 약 2.3% 높은 정확도를 보였으나 정확도 편차는 5% 정도로 크게 나타났다. 반대로 영상의 개수가 많아질수록 기존 CNN과의 평균 정확도의 차이는 약 1%로 줄어들고, 각 학습 결과의 정확도 편차 또한 줄어든다.","This paper introduces a method for improving accuracy using the first convolution layer, which is not used in most modified CNN(: Convolution Neural Networks). In CNN, such as GoogLeNet and DenseNet, the first convolution layer uses only the traditional methods(3x3 convolutional computation, batch normalization, and activation functions), replacing this with RGB-csb. In addition to the results of preceding studies that can improve accuracy by applying RGB values to feature maps, the accuracy is compared with existing CNN using a limited number of images. The method proposed in this paper shows that the smaller the number of images, the greater the learning accuracy deviation, the more unstable, but the higher the accuracy on average compared to the existing CNN. As the number of images increases, the difference in accuracy between the existing CNN and the proposed method decreases, and the proposed method does not seem to have a significant effect."
전이학습을 활용한 소규모 비정형 정책데이터 감성분석 모델,2020,"['감성분석', '딥러닝', '소규모 데이터', '빅데이터 분석', '전시학습', '정책평가', 'Big data analysis', 'Deep learning', 'Policy evaluation', 'Sentiment analysis', 'Small-scale data', 'Transfer learning']",최근 빅데이터 기술의 발전에도 불구하고 정책분야에서는 텍스트 등 비정형 데이터의 부족으로 감성분석 연구에 제한이 많았다. 이에 본 연구에서는 전이학습을 기반으로 소규모 비정형 정책 데이터를 활용한 감성분석 모델을 제안한다. 이를 위해 네이버 영화리뷰 20만 건의 댓글로 CNN 모델을 생성하고 지역 리뷰 1만 건의 댓글을 이용하여 전이학습을 수행하였다. 분석결과 본 연구에서 제안한 전이학습 모델은 소규모 데이터만으로 생성된 모델보다 약 10%의 정확도 향상과 1epoch당 1000ms의 학습지간 단축을 보였다. 본 연구의 공헌도로 학술적으로는 한글 텍스트 감성분석에 전이학습을 처음으로 적용하여 향후 소규모 데이터의 감성분석 연구에 활용할 수 있는 이론적 기반을 제공하였다는 점이다. 실무적으로는 데이터가 부족하여 시도하기 어려웠던 정책 분야의 감성분석을 통해 정부사업의 성공여부를 판별할 수 있는 기초자료로 활용할 수 있다.,"Despite the recent development in big data technologies, the research on sentiment analysis is still facing many limitations due to the lack of unstructured data, including texts, in the policy field. Thus, this study proposes a sentiment analysis model for small-scale unstructured policy data based on transfer learning. As a result, the proposed transfer learning model achieved about 10% better accuracy and a shorter training time of 1000 ms per epoch than the model generated only by using small-scale data. As an academic contribution, this study, which is the first application of transfer learning to Korean text sentiment analysis, provides a theoretical basis for future research on sentiment analysis using small-scale data. For practicality, this study can serve as basic data in determining the success or failure of government projects through sentiment analysis in the policy field, which was difficult to determine previously given the lack of data. the detailed feature of sea/land breeze at each site is closely associated with the local shape of coastline."
의료 인공지능에 대한 형법적 고찰 -왓슨(Watson)을 중심으로-,2020,"['Legal Personhood', 'Watson', 'Medical Malpractice', 'Medical Practice', 'Artificial Intelligence', 'Criminal Ability of Artificial Intelligence', 'Criminal Responsibiliyt of Artificial Intelligence', 'The fourth Industrial Revolution', 'Product Liability Act', 'Diagnostics', '법적 인격', '왓슨', '의료과실', '의료행위', '인공지능', '인공지능의 범죄능력', '인공지능의 형사책임능력', '제4차 산업혁명', '제조물책임법', '진단']","인공지능은 머신러닝이나 딥러닝을 통하여 빠르게 발전하고 있으며, 사회 전반에 걸쳐 영향을 미치고 있다. 이러한 인공지능은 의료계에서도 그 활용이 활발하게 진행되고 있다. 그러나 의료영역에서 인공지능을 이용한 의료행위는 다른 산업영역에 비하여 직접 환자의 생명과 신체에 영향을 미치기 때문에 신중한 접근이 필요하다. 인공지능을 이용한 의료행위가 기계 작동의 오류나 오작동 등에 의하여 의료사고가 발생한 경우 이에 대한 책임은 인공지능과 의료영역에 활용되는 인공지능에 대한 기초적 이해와 그와 관련된 법률의 검토가 선행되어야 한다. 이와 더불어 현행법상 의료 인공지능은 과연 의료행위의 주체가 될 수 있는지 검토할 필요가 있다. 우리 형사사법 체계는 기본적으로 인간을 중심으로 하고 있다. 그러나 의료 인공지능에게 법인격을 부여할 수 있는가라는 논의를 하게 되면 또 다른 결론에 이를 수도 있다. 이와 같은 논의도 현재 구현되고 있는 ‘약한 인공지능’과 현재는 구현되지 않은 ‘강한 인공지능’으로 구분하여 검토해야 한다. 또한 인공지능을 활용하는 과정에서 이에 관여된 다양한 이들에 대한 책임도 검토해야 한다. 이처럼 의료 인공지능이 행한 의료행위에 대한 책임의 문제는 의료 현장에서 활용되는 과정 중 이에 관여하는 사람들을 중심으로 세분화하고 이에 따라 분석하여야 한다. 예를 들면 의료인이 의료 인공지능을 활용하는 과정에서 의료과실이나 의료사고가 발생하는 경우나 의료 인공지능을 초기 설정하는 과정에서 오류가 발생하는 경우 등을 들 수 있다. 또한 현재 활용되고 있는 의료 인공지능인 왓슨은 의료영역에서 어떠한 역할을 수행하고 있는지 고찰할 필요가 있다. 즉 왓슨은 현재 방대한 양의 의료정보데이터를 학습하고 이를 기반으로 하여 적정한 치료법 권고뿐만 아니라 치료법에 대하여 3단계로 분류하여 치료 권고안을 추천해 준다. 이러한 행위가 의사에게 의료적 의사결정이나 의료행위로 볼 수 있지 않는가라는 문제제기가 가능하다. 또한 인공지능의 행위능력과 책임능력 존재 여부에 대한 논의로 여전히 찬반이 갈리고 있는 만큼 세밀한 검토가 필요한 부분이기도 하다.","Artificial intelligence is developing fast through machine learning or deep learning, and is affecting the whole society. This artificial intelligence is also being used a lot in the medical field. However, medical practices using artificial intelligence in the medical field have a direct influences on patients’ life and bodies more compared to other industries, so they need to be approached more carefully.Regarding medical practices using artificial intelligence, when medical accidents occur due to malfunctions or errors of machines, in order to discuss their responsibility, the basic understanding of artificial intelligence and that used in the medical field and legal consideration should precede it. In addition, it needs to be examined whether medical artificial intelligence can be the main agent of medical practices under the current law or not. Korean criminal justice system is basically centered around humans. Yet, the discussion over whether medical artificial intelligence can be granted legal personality or not can lead to a different conclusion.‘Weak artificial intelligence’ that is being realized nowadays and ‘strong artificial intelligence’ that hasn’t been realized yet must be separated to investigate the discussion. Moreover, the responsibilities for those involved in the process of the use of artificial intelligence have to be examined, too. Likewise, the matter of responsibility for the medical practices by medical artificial intelligence should be subdivided and analyzed centered around the people involved in the application process of artificial intelligence. The occurrence of malpractices or medical accidents in the process of a medical practioner’s using medical artificial intelligence, or the occurrence of an error in the process of the initial setting of medical artificial intelligence can be the examples.Moreover, it needs to be investigated what roles Watson, the medical artificial intelligence in use currently, is playing in the medical area. That is, Watson now learns a great deal of medical information and data, and based on that, recommends not only appropriate treatments but also desirable remedies divided into three stages. The problem that these actions can be seen as a doctor’s medical decision making or medical practices can be raised. In addition, there is still controversy over whether artificial intelligence has the ability to act and to take responsibility or not, so it requires close examination."
인공지능 기반 건물화재 예측모델 연구,2020,"['화재예측', '딥러닝', '인공지능', '텐서플로', '공간정보', 'Fire Prediction', 'Deep Learning', 'AI', 'Tensorflow', 'Spatial Data']",,
대규모 외생 변수 및 Deep Neural Network 기반 금융 시장 예측 및 성능 향상,2020,"['시장예측', '딥러닝', '오토인코더', '전이 학습', '시계열 정규화', 'Market prediction', 'Deep learning', 'AutoEncoder', 'Trainsfer learning', 'Time series normalization']","미래의 주가를 예측하기 위한 시도는 과거부터 꾸준히 연구되어왔다. 그러나 일반적인 시계열 데이터와 달리 금융 시계열 비정상성(non-stationarity)과 장기 의존성(long-term dependency), 비선형성(non-linearity) 등 예측을 하는 것에 있어서 여러 가지 방해 요인이 존재한다. 또한, 광범위한 데이터의 변수는 기존에 사람이 직접 선택하는 것에 한계가 있으며 모델이 변수를 자동으로 잘 추출할 수 있도록 하여야 한다. 본 논문에서는 비정상성 데이터를 정규화할 수 있는 슬라이딩 타임스텝 정규화(sliding time step normalization) 방법과 LSTM 형태의 오토인코더(AutoEncoder)를 사용하여 모든 변수로부터 압축된 변수로 미래 주가를 예측하는 방법, 기간을 나누어 전이 학습을 하는 이동 전이 학습(moving transfer learning)을 제안한다. 또한, 실험을 통하여 100개의 주요 금융 변수들만을 사용하는 것보다 뉴럴 네트워크를 통해서 가능한 많은 변수를 사용하였을 때 성능이 우수함을 보이며, 슬라이딩 타임스텝 정규화 방법을 사용하여 모든 구간에서 데이터의 비정상성에 대해 정규화를 수행함으로써 성능 향상에 효과적임을 보인다. 이동 전이 학습 방법은 스텝 별 테스트 구간에서 모델의 성능을 평가하고 전이학습을 함으로써 긴 테스트 구간에서 성능 향상에 효과적임을 보인다.","Attempts to predict future stock prices have been studied steadily since the past. However, unlike general time-series data, financial time-series data has various obstacles to making predictions such as non-stationarity, long-term dependence, and non-linearity. In addition, variables of a wide range of data have limitations in the selection by humans, and the model should be able to automatically extract variables well. In this paper, we propose a ‘sliding time step normalization’ method that can normalize non-stationary data and LSTM autoencoder to compress variables from all variables. and ‘moving transfer learning’, which divides periods and performs transfer learning. In addition, the experiment shows that the performance is superior when using as many variables as possible through the neural network rather than using only 100 major financial variables and by using sliding time step normalization to normalize the non-stationarity of data in all sections, it is shown to be effective in improving performance. moving transfer learning shows that it is effective in improving the performance in long test intervals by evaluating the performance of the model and performing transfer learning in the test interval for each step."
제한된 학습 데이터를 사용하는 End-to-End 음성 인식 모델,2020,"['speech recognition', 'end-to-end model', 'small-data speech recognition', '음성 인식', '종단간 음성 인식', '적은 데이터 음성 인식']","음성 인식은 딥러닝 및 머신러닝 분야에서 활발히 상용화 되고 있는 분야 중 하나이다. 그러나, 현재 개발되고 있는 음성 인식 시스템은 대부분 성인 남녀를 대상으로 인식이 잘 되는 실정이다. 이것은 음성 인식 모델이 대부분 성인남녀 음성 데이터베이스를 학습하여 구축된 모델이기 때문이다. 따라서, 노인, 어린이 및 사투리를 갖는 화자의 음성을 인식하는데 문제를 일으키는 경향이 있다. 노인과 어린이의 음성을 잘 인식하기 위해서는 빅데이터를 구축하는 방법과 성인 대상 음성 인식 엔진을 노인 및 어린이 데이터로 적응하는 방법 등이 있을 수 있지만, 본 논문에서는 음향적 데이터 증강에 기반한 재귀적 인코더와 언어적 예측이 가능한 transformer 디코더로 구성된 새로운 end-to-end 모델을 제안한다. 제한된 데이터셋으로 구성된 한국어 노인 및 어린이 음성 인식을 통해 제안된 방법의 성능을 평가한다.","Speech recognition is one of the areas actively commercialized using deep learning and machine learning techniques. However, the majority of speech recognition systems on the market are developed on data with limited diversity of speakers and tend to perform well on typical adult speakers only. This is because most of the speech recognition models are generally learned using a speech database obtained from adult males and females. This tends to cause problems in recognizing the speech of the elderly, children and people with dialects well. To solve these problems, it may be necessary to retain big database or to collect a data for applying a speaker adaptation. However, this paper proposes that a new end-to-end speech recognition method consists of an acoustic augmented recurrent encoder and a transformer decoder with linguistic prediction. The proposed method can bring about the reliable performance of acoustic and language models in limited data conditions. The proposed method was evaluated to recognize Korean elderly and children speech with limited amount of training data and showed the better performance compared of a conventional method."
Defect Classification of Cross-section of Additive Manufacturing Using Image-Labeling,2020,"['Deep Learning(딥러닝)', 'CNN(순환 신경망)', 'Data Augmentation(데이터 증폭)', 'Image Labeling(이미지 라벨링)', 'Additive Manufacturing(적층제조)']",,"Recently, the fourth industrial revolution has been presented as a new paradigm and additive manufacturing (AM) has become one of the most important topics. For this reason, process monitoring for each cross-sectional layer of additive metal manufacturing is important. Particularly, deep learning can train a machine to analyze, optimize, and repair defects. In this paper, image classification is proposed by learning images of defects in the metal cross sections using the convolution neural network (CNN) image labeling algorithm. Defects were classified into three categories: crack, porosity, and hole. To overcome a lack-of-data problem, the amount of learning data was augmented using a data augmentation algorithm. This augmentation algorithm can transform an image to 180 images, increasing the learning accuracy. The number of training and validation images was 25,920 (80 %) and 6,480 (20 %), respectively. An optimized case with a combination of fully connected layers, an optimizer, and a loss function, showed that the model accuracy was 99.7 % and had a success rate of 97.8 % for 180 test images. In conclusion, image labeling was successfully performed and it is expected to be applied to automated AM process inspection and repair systems in the future."
TensorRT와 SSD를 이용한 실시간 얼굴 검출방법,2020,"['텐서플로우', '텐서알티', '딥러닝', '에스에스디', '객체 검출', 'Tensorflow', 'TensorRT', 'Deep Learning', 'SSD', 'Object Detection']",,"Recently, new approaches that significantly improve performance in object detection and recognition using deep learning technology have been proposed quickly. Of the various techniques for object detection, especially facial object detection (Faster R-CNN, R-CNN, YOLO, SSD, etc), SSD is superior in accuracy and speed to other techniques. At the same time, multiple object detection networks are also readily available. In this paper, among object detection networks, Mobilenet v2 network is used, models combined with SSDs are trained, and methods for detecting objects at a rate of four times or more than conventional performance are proposed using TensorRT engine, and the performance is verified through experiments. Facial object detector was created as an application to verify the performance of the proposed method, and its behavior and performance were tested in various situations."
화자 인식을 위한 적대학습 기반 음성 분리 프레임워크에 대한 연구 A,2020,"['화자 임베딩', '정보 분리', '다중작업', '판별기', 'Speaker embedding', 'Disentanglement', 'Multi-task', 'Discriminator']","본 논문은 딥러닝 기법을 활용하여 음성신호로부터 효율적인 화자 벡터를 추출하는 시스템을 제안한다. 음성신호에는 발화내용, 감정, 배경잡음 등과 같이 화자의 특징과는 관련이 없는 정보들이 포함되어 있다는 점에 착안하여제안 방법에서는 추출된 화자 벡터에 화자의 특징과 관련된 정보는 가능한 많이 포함되고, 그렇지 않은 비화자 정보는최소화될 수 있도록 학습을 진행한다. 특히, 오토-인코더 구조의 부호화 기가 두 개의 임베딩 벡터를 추정하도록 하고, 효과적인 손실 함수 조건을 두어 각 임베딩이 화자 및 비화자 특징만 각각 포함할 수 있도록 하는 효과적인 화자 정보분리(disentanglement)방법을 제안한다. 또한, 화자 정보를 유지하는데 도움이 되는 생성적 적대 신경망(Generative Adversarial Network, GAN)에서 활용되는 판별기 구조를 도입함으로써, 디코더의 성능을 향상시킴으로써 화자 인식 성능을 보다 향상시킨다. 제안된 방법에 대한 적절성과 효율성은 벤치마크 데이터로 사용되고 있는 Voxceleb1에대한 동일오류율(Equal Error Rate, EER) 개선 실험을 통하여 규명하였다.","In this paper, we propose a system to extract effective speaker representations from a speech signal using a deep learning method. Based on the fact that speech signal contains identity unrelated information such as text content, emotion, background noise, and so on, we perform a training such that the extracted features only represent speaker-related information but do not represent speaker-unrelated information. Specifically, we propose an auto-encoder based disentanglement method that outputs both speaker-related and speaker-unrelated embeddings using effective loss functions. To further improve the reconstruction performance in the decoding process, we also introduce a discriminator popularly used in Generative Adversarial Network (GAN) structure.Since improving the decoding capability is helpful for preserving speaker information and disentanglement, it results in the improvement of speaker verification performance. Experimental results demonstrate the effectiveness of our proposed method by improving Equal Error Rate (EER) on benchmark dataset, Voxceleb1."
실내 이미지를 사용하여 문을 중심으로 한 설계도면 추정 방법,2020,"['실내위치 인식', '딥러닝', '영상 처리', '사영 기하학', 'indoor localization', 'deep learning', 'image processing', 'projective geometry']","기존의 실내위치 인식 기술은 WLAN, GPS, Bluetooth, 또는 자기장 기술을 사용하는 것이 일반적이다. 하지만 이러한 기술은 실내 환경에서는 수신 신호 세기로 인해 오차를 발생시킬 수 있다. 센서를 사용하지 않는 실내위치 인식 방법으로 3D 건물 모델을 참조하는 방법이 있다. 본 논문은 3D 건물 모델을 참조하기 위하여 설계도면을 추정 하는 방법을 제안한다. 제안된 방법은 이미지를 사용하여 이미지 안의 문과 같은 건물 안의 영구적인 정적 물체를 인식, 사용하여 정적 물체와 정적 물체 간의 실제 거리 비율을 예측, 계산한다. 계산한 정적 물체 간의 실제 거리 비율을 사용하여 이미지 안의 정적 물체를 재배열하여 설계도면을 모델링한다. 본 논문의 설계도면 모델링 방법을 사용하여 실내위치 인식을 하면 특별한 인프라나 센서 없이도 이미지 한 장으로 값싸게 실내위치 인식을 할 수 있을 것으로 기대된다.","In the conventional indoor location recognition technology, WLAN, GPS, and Bluetooth technologies are generally used. However, this technique may cause an error in the indoor environment due to the received signal strength. There is a method of reference from 3D building model as a method of recognizing indoor location without a sensor. This paper proposes a method for modeling blueprint to refer to a 3D building model, which is one of the methods of indoor location recognition. The proposed method uses images to recognize static objects in buildings, such as doors in images, to predict and calculate the real-world distance ratio between static objects and static objects. Then our system model the blueprint by rearranging the static objects in the image using the calculated ratio of actual distances between static objects. It is expected that the indoor location recognition using the design drawing modeling method of this paper will be able to recognize the indoor location inexpensively with a single image without special infrastructure or sensor."
가상 데이터를 활용한 번호판 문자 인식 및 차종 인식 시스템 제안,2020,"['YOLO', 'Synthetic Data Generation', 'Object Detection', 'Text Recognition']","본 논문에서는 딥러닝을 이용한 차종 인식과 자동차 번호판 문자 인식 시스템을 제안한다. 기존 시스템에서는 영상처리를 통한 번호판 영역 추출과 DNN을 이용한 문자 인식 방법을 사용하였다. 이러한 시스템은 환경이 변화되면 인식률이 하락되는 문제가 있다. 따라서, 제안하는 시스템은 실시간 검출과 환경 변화에 따른 정확도 하락에 초점을 맞춰 1-stage 객체 검출 방법인 YOLO v3를 사용하였으며, RGB 카메라 한 대로 실시간 차종 및 번호판 문자 인식이 가능하다. 학습데이터는 차종 인식과 자동차 번호판 영역 검출의 경우 실제 데이터를 사용하며, 자동차 번호판 문자 인식의 경우 가상 데이터만을 사용하였다. 각 모듈별 정확도는 차종 검출은 96.39%, 번호판 검출은 99.94%, 번호판 검출은 79.06%를 기록하였다. 이외에도 YOLO v3의 경량화 네트워크인 YOLO v3 tiny를 이용하여 정확도를 측정하였다.",
CNN 모델을 이용한 보행자 인식 및 신장 추정 방법,2020,"['단안카메라', '보행자', '딥러닝', '합성곱신경망 모델', '렌즈왜곡보상', 'Monocular Camera', 'Pedestrian', 'Deep Learning', 'CNN Model', 'LDC']",,"In this paper, the convolutional neural network (CNN) model, which is an object-recognition technology based on deep learning, was applied to images acquired from a monocular camera to detect pedestrians. The detected image coordinates of the pedestrians were converted to map coordinates, and the height of the pedestrians was inferred using a proportional equation. For this, a monocular camera equipped with lens distortion compensation was installed at an altitude of 3.5 m, and the pitch and yaw angles were set to collimate pedestrians. That is how we proceed image capturing. In the CNN model, the image coordinates of the object were acquired in real-time using the bounding box. After converting the image coordinates of the acquired object to map coordinates, the height of pedestrians could be calculated using a proportional equation."
CNN/ANNOY 기술을 이용한 의류 이미지 유사도 분석,2020,"['CNN', 'ANNOY', '딥러닝', 'AI', '빅데이터', '이미지 유사도', 'CNN', 'ANNOY', 'Deep Learning', 'AI', 'Big Data', 'Image Similarities']",,
KorQuAD 2.0: Korean QA Dataset for Web Document Machine Comprehension,2020,"['코쿼드', '자연어처리', '딥러닝', '기계독해', '질의응답', 'KorQuAD', 'NLP', 'deep learning', 'MRC', 'QA']",,
지능형 소프트웨어의 안전성 확보를 위한 정책적 개선 방안,2020,"['지능형 소프트웨어', '딥러닝', '소프트웨어 안전성', '소프트웨어 안전성 정책', '인공지능', 'Intelligent software', 'Deep learning', 'Software safety', 'Software satety policy', 'Artificial intelligence']",,"This paper studied the safety of intelligent software focused on the weak artificial intelligence and proposed considerations to build up government based policies. The existing related papers and reports explained the software safety by dividing the software development process into four steps - design, development, test and operation. However, we extracted various aspects of safety issues on intelligent softwares from deep learning algorithms and related reports. Then we also analyzed existing worldwide policies by issues and scrutinized the appropriateness of them. Based on the analysis, some useful political proposals are suggested and some missing policies are pointed out. In addition, ten recommendations for the use and development of safe intelligent software are proposed in order to summarize the whole content of the paper."
AI특허의 권리행사 및 관련 쟁점에 관한 연구,2020,"['인공지능', '사물인터넷', '딥러닝', '공동실시', '알고리즘', 'artificial intelligence', 'internet of things', 'deep learning', 'joint practice', 'algorithm']",,"By the development in the current information and communication technologies (ICT) and deep learning technology, the AI does the learning by the combination of the IoT or the big data and by this learning, finds the problem by itself to be able to create the best model(contents) for solving the problem. Since such a creation by the AI is the result leaned by the human intervention, by regarding that the AI is not the inventor but the human(natural person) would be the inventor, in all countries of the world including our country the AI patent has been granted.The human creates the algorithm so that the AI not the human artificial action can find the problem for solving the specific purpose and the solution thereto, and if it is described in the specification that by the algorithm the AI does the learning to derive the creation, the patent can be obtained. Since the realizing method and the system of such a AI patent has been executed by the deep learning of the AI and through the network, it is very difficult to interpret the scope of rights and to determine whether the third party violates.As described in the AI patent, since there are many cases where the realizing method by the AI and the system are made through the network, there is a large number of implementers and users, Thereby it cannot be known who is the implementer and it is not easy to determine whether the partial action of the implementer and the user violates to the patent right. Accordingly for the description of claims and interpretation thereof in the AI invention and the determination to the violation of the action by the combination of the implementers and users, it is needed to review to include the joint practice in the enforcement regulation of the Patent Law and the joint practice in the indirect infringement regulation of the Patent Law."
뇌파를 이용한 디지털 치료제(Digital Therapeutics) XR 콘텐츠 제작 방법 연구,2020,"['디지털 치료제', '딥러닝', '인공지능', '언리얼 엔진', '헬스케어', 'XR', '가상공간', 'digital therapy', 'deep learning', 'artificial intelligence', 'Unreal Engine', 'healthcare', 'virtual space']","나날이 다양해지는 사회구조와 다양한 질병으로 인한 팬데믹(pandemic), 많은 양의 업무 및 학업, 사람관계에서 오는 어려움 등으로 인하여 사람들은 스트레스를 경험하면 삶을 살아가고 있다. 스트레스를 오랫동안 받아오면서 마지막 단계인 탈진에 빠지게 된다. 이로 인해 신체적·정신적 병으로 발전할 수 있다는 연구결과도 있다. 정신건강을 관리하기란 쉽지 않은 실정에 있다. 정신의학과에서 진단을 받는 것이 사회적으로 편견이 있어 정신의학과에서 진단받기란 많은 부담으로 다가오고 있다. 정신건강을 부담 없이 쉽게 진단받고 치료받는 것이 필요하다. 본 연구 기술은 뇌파 측정 데이터를 분석하여 현재의 뇌 건강 상태를 파악하고 진단하는 알고리즘이다. 현재 XR 가상공간 및 게임을 통해 정신건강을 치료할 디지털 신약이 필요하다. 정신건강의 치료를 위해 스마트기기와 IT 기술을 기반으로 학생들 또는 일반인의 수준에 맞는 디지털 신약을 제공하여 학생들 또는 일반인이 쉽게 치료하고, 휴대성(portability)이 좋은 장비들을 기반으로 개인에게 최적화(personally customized)된 다양한 콘텐츠와 플랫폼 환경 속에 치료할 수 있도록 하는 것이다. 많은 학생이 우울증에 힘들어하고 있으며 노령화 사회에 들어서면서 치매 환자들이 증가하고 있다. 그에 따른 뇌파에 관련하여 연구가 더욱 필요한 상태이다.","The social structure and disease are becoming increasingly complex. Pandemic, excessive work and study, Because of the difficulties that come from interpersonal relationships, modern people live when everyone experiences stress. When the stressor persists for a long time and falls into the final stage, the exhaustion reaction, Research has shown that it can lead to physical and mental illness. Managing your mental health. It is not easy. Getting diagnosed in psychiatry is socially prejudiced Getting diagnosed in a psychiatric department comes with a lot of pressure. Mental health easily It is necessary to be diagnosed and treated. This research technology measures brain waves and analyzes. It is an algorithm that detects and diagnoses the current brain health condition, and through XR virtual space and games. We need a digital new drug to treat mental health. In the treatment of mental health, based on smart devices and IT technology, or by providing new drugs that are suitable for the level of digital or general people, or based on devices that are suitable for easy treatment and mobility (portability) for the general population, It can be cured in content and platform environments. Many students are struggling with depression, and dementia patients are increasing as they enter an aging society. Further research is required regarding the resulting brain waves."
기계번역 사후교정(Automatic Post Editing) 연구,2020,"['기계번역', '기계번역 사후교정', '딥러닝', '인공신경망 기계번역', '트랜스포머', 'Machine Translation', 'Automatic Post Editing', 'Deep Learning', 'Neural Machine Translation', 'Transformer']",기계번역이란 소스문장(Source Sentence)을 타겟문장(Target Sentence)으로 컴퓨터가 번역하는 시스템을 의미한다. 기계번역에는 다양한 하위분야가 존재하며 APE(Automatic Post Editing)이란 기계번역 시스템의 결과물을 교정하여 더 나은 번역문을 만들어내는 기계번역의 하위분야이다. 즉 기계번역 시스템이 생성한 번역문에 포함되어 있는 오류를 수정하여 교정문을 만드는 과정을 의미한다. 기계번역 모델을 변경하는 것이 아닌 기계번역 시스템의 결과 문장을 교정하여 번역품질을 높이는 연구분야이다. 2015년부터 WMT 공동 캠페인 과제로 선정되었으며 성능 평가는 TER(Translation Error Rate)을 이용한다. 이로 인해 최근 APE에 모델에 대한 다양한 연구들이 발표되고 있으며 이에 본 논문은 APE 분야의 최신 동향에 대해서 다루게 된다.,"Machine translation refers to a system where a computer translates a source sentence into a target sentence. There are various subfields of machine translation. APE (Automatic Post Editing) is a subfield of machine translation that produces better translations by editing the output of machine translation systems. In other words, it means the process of correcting errors included in the translations generated by the machine translation system to make proofreading. Rather than changing the machine translation model, this is a research field to improve the translation quality by correcting the result sentence of the machine translation system. Since 2015, APE has been selected for the WMT Shaed Task. and the performance evaluation uses TER (Translation Error Rate). Due to this, various studies on the APE model have been published recently, and this paper deals with the latest research trends in the field of APE."
합성곱 신경망을 이용한 주가방향 예측 : 상관관계 속성선택 방법을 중심으로,2020,"['합성곱신경망', '주가방향 예측', '머신러닝', '딥러닝', '속성선택', '앙상블', 'Convolutional Neural Network', 'Stock Price Direction Prediction', 'Machine Learning', 'Deep Learning', 'Feature Selection', 'Ensemble']",,"Recently, deep learning has shown high performance in various applications such as pattern analysis and image classification. Especially known as a difficult task in the field of machine learning research, stock market forecasting is an area where the effectiveness of deep learning techniques is being verified by many researchers. This study proposed a deep learning Convolutional Neural Network (CNN) model to predict the direction of stock prices. We then used the feature selection method to improve the performance of the model. We compared the performance of machine learning classifiers against CNN. The classifiers used in this study are as follows: Logistic Regression, Decision Tree, Neural Network, Support Vector Machine, Adaboost, Bagging, and Random Forest. The results of this study confirmed that the CNN showed higher performancecompared with other classifiers in the case of feature selection. The results show that the CNN model effectively predicted the stock price direction by analyzing the embedded values of the financial data"
YONI : 객체 탐지를 위한 개선된 합동 훈련,2020,"['합동 훈련', '객체 탐지', '딥러닝', 'YONI', '박스 주석', 'Joint Training', 'Object Detection', 'Deep Learning', 'box annotation']",,"The object recognition method using deep learning has been evolving day by day, showing very high speed and performance. To fully train such a deep learning model, however, a significant amount of data is required, which is inappropriate for individuals to use as small capital. In the past, various methods have been proposed to solve the dataset shortage problem, but it has been difficult to drastically reduce costs or improve performance. In this paper, we propose YONI method for learning two types of data sets to improve the performance of the existing methods. First, the method learns the common categories of the categories we want to learn using existing well-known datasets. Next, the trained model performs box annotation on the dataset created by the user. Finally, it uses the user dataset to learn the categories we want to learn. While this learning method omits expensive box annotation work like the existing method, it shows better performance than existing method by improving performance loss caused by not using box annotation information."
BERT 기반 한국어 개방형 정보 추출,2020,"['BERT', '개방형 정보 추출', '딥러닝', 'Sequence Labeling', 'open information extraction', 'deep learning', 'sequence labeling']","개방형 정보 추출은 자연어로 된 문장에서 구조화된 정보인 트리플을 추출하는 기술이다. 기존의 개방형 정보 추출은 입력 문장에서 관계 정보를 추출해야 하는 특성 때문에 품사 패턴, 의존 구문 분석 정보, 의미역 결정 정보 등을 이용한 복잡한 방법을 사용하였다. 본 논문에서는 한국어 개방형 정보 추출을 순차열 분류 문제로 보고 사전학습 된 BERT 모델을 적용하는 방법을 제안한다. 실험 결과 본 논문에서 제안한 모델이 정답이 아닌 자동으로 구축된 학습데이터 만을 사용했음에도 기존의 규칙기반의 방법 보다 F-1 measure 2～3% 정도의 성능향상을 보였다.","Open information extraction is a difficult technique for extracting triples, which are structured information from natural language sentences. Because the open information extraction task has the feature of extracting complex relation information from input sentences, traditionary open information extraction embraces a complicated method using parts-of-speech pattern information, dependency parsing information, and semantic role labeling information. In this paper, we propose a method to apply the pre-trained BERT model to the Korean open information extraction as a sequence labeling problem. The proposed model shows the F-1 measure 2% - 3% better than the rule-based method even though it uses only automatically constructed noisy training data."
얼굴 속성 편집을 위한 마스크 정보를 활용한 개선된 STGAN,2020,"['얼굴 속성 편집', 'GAN', '딥러닝', '마스크', 'STGAN', 'Facial attribute editing', 'GAN', 'Deep learning', 'Mask', 'STGAN']","본 논문에서는 머리카락과 모자 영역의 마스크 정보를 활용하여 더 자연스러운 얼굴 속성 편집(facial attribute editing)을 수행하는 모델을 제안한다. 최신 얼굴 속성 편집 연구인 STGAN은 다중얼굴 속성을 자연스럽게 편집하는 성과를 보였다. 그러나 머리카락과 관련된 속성을 편집할 때부자연스러운 결과를 생성할 수 있다. 제안하는 방법의 핵심 아이디어는 기존 모델에서 부족했던얼굴 영역의 정보를 모델에 추가로 반영하는 것이다. 이를 위해 세 가지 아이디어를 적용한다. 첫째로 마스크를 통해 머리카락 면적 속성을 추가하여 머리카락 정보를 보완한다. 둘째로 순환 일관성 손실(cycle consistency loss)을 추가하여 영상의 불필요한 변화를 억제한다. 셋째로 모자 분할신경망을 추가하여 모자 영역 왜곡을 방지한다. 정성적 평가를 통해 제안하는 방법 적용 여부에따른 유효성을 평가 및 분석한다. 실험 결과에서 제안하는 방법이 머리카락 및 얼굴 영역을 더자연스럽게 생성하고, 모자 영역의 왜곡을 성공적으로 방지했다.","In this paper, we propose a model that performs more natural facial attribute editing by utilizing mask information in the hair and hat region. STGAN, one of state-of-the-art research of facial attribute editing, has shown results of naturally editing multiple facial attributes. However, editing hair-related attributes can produce unnatural results. The key idea of the proposed method is to additionally utilize information on the face regions that was lacking in the existing model. To do this, we apply three ideas. First, hair information is supplemented by adding hair ratio attributes through masks. Second, unnecessary changes in the image are suppressed by adding cycle consistency loss. Third, a hat segmentation network is added to prevent hat region distortion. Through qualitative evaluation, the effectiveness of the proposed method is evaluated and analyzed. The method proposed in the experimental results generated hair and face regions more naturally and successfully prevented the distortion of the hat region."
빅데이터 기반의 딸기 생육환경 의사결정 시스템,2020,"['비닐하우스', '빅데이터', '데이터 분석', '딥러닝', '기상정보', 'An orchard', 'Big-Data', 'Data analysis', 'Deep-learning', 'Weather information']",,
드론 영상 분석과 자료 증가 방법을 통한 건설 자재 수량 측정,2020,"['드론', '무인항공기', 'RCNN', '딥러닝', '수량 측정', '건축 자재', 'Drone', 'UAV', 'RCNN', 'Deep Learning', 'Counting Number', 'Construction Material']",,"This paper proposes a technique for counting construction materials by analyzing an image acquired by a Drone. The proposed technique use drone log which includes drone and camera information, RCNN for predicting construction material type, dummy area and Photogrammetry for counting the number of construction material. The existing research has large error ranges for predicting construction material detection and material dummy area, because of a lack of training data. To reduce the error ranges and improve prediction stability, this paper increases the training data with a method of data augmentation, but only uses rotated training data for data augmentation to prevent overfitting of the training model. For the quantity calculation, we use a drone log containing drones and camera information such as Yaw and FOV, RCNN model to find the pile of building materials in the image and to predict the type. And we synthesize all the information and apply it to the formula suggested in the paper to calculate the actual quantity of material pile. The superiority of the proposed method is demonstrated through experiments."
Data-Driven Approach to Identify Research Topics for Science and Technology Diplomacy,2020,"['과학계량학', '추천시스템', '계량서지학', '딥러닝', '과학외교', 'Scientometrics', 'Recommender System', 'Bibliometrics', 'Deep Learnining', 'Science for Diplomacy']",,"In science and technology diplomacy, major countries actively utilize their capabilities in science and technology for public diplomacy, especially for promoting diplomatic relations with politically sensitive regions and countries. Recently, with an increase in the influence of science and technology on national development, interest in science and technology diplomacy has increased. So far, science and technology diplomacy has relied on experts to find research topics that are of common interest to both the countries. However, this method has various problems such as the bias arising from the subjective judgment of experts, the attribution of the halo effect to famous researchers, and the use of different criteria for different experts. This paper presents an objective data-based approach to identify and recommend research topics to support science and technology diplomacy without relying on the expert-based approach. The proposed approach is based on big data analysis that uses deep-learning techniques and bibliometric methods. The Scopus database is used to find proper topics for collaborative research between two countries. This approach has been used to support science and technology diplomacy between Korea and Hungary and has raised expectations of policy makers. This paper finally discusses aspects that should be focused on to improve the system in the future."
얼굴 합성과 추천 시스템을 이용한 사용자 친화적 한국어 회화 학습 앱 개발,2020,"['회화 앱(어플)', '딥러닝', '얼굴 합성', '아이템 기반 협업 필터링', '추천 시스템', 'Conversation application(app)', 'deep learning', 'face swapping', 'item based collaborative filtering', 'recommender system']",,"As interest in the Korean Wave has recently increased, the number of ordinary people interested in Korean language through Korean culture is rapidly increasing. However, compared to English conversation apps, Korean conversation apps that can be learned with a smartphone have not been actively developed. In this paper, we propose a user-friendly application for learning Korean conversation through a smart phone. The proposed application provides learning videos in which a Korean conversation instructors face is swapped with the users favorite celebrity face by deep learning. In addition, the application recommends conversation scripts that fit the users learning level using fuzzy logic based on the users age and duration of stay in Korea, and then recommends scripts that fit the users interests using item-based collaboration filtering."
자동화된 실험계획법과 다층 퍼셉트론 기법을 이용한 영구자석형 동기전동기의 형상 최적설계,2020,"['최적화', '영구자석형 동기전동기', '메타모델링', '딥러닝', '유한요소해석', 'Optimization', 'PMSM', 'Metamodeling', 'Deep learning', 'Finite element analysis']",,
A Suggestion on the Ethics in Artificial Intelligence,2020,"['인공지능', '인공지능 윤리', '딥러닝', '알고리즘', '윤리적 가이드라인', '블랙박스 신경시스템', '자율주행 자동차. 스마트 팩토리', 'Artificial Intelligence', 'AI Ethics', 'Deep Learning', 'Algorithm', 'Regulatory Guidelines', 'Black Box Neural System', 'Autonomous Car', 'Smart Factory']",,"Now and in the future, AI is inevitable and necessary for our lives in almost every respect. There are many aspects and consequences our use of AI and the AI itself (as an independent actor in the future) generate, some of which are good, valuable as intended and desired by us human beings, but some of which are bad, harmful, or dangerous whether it is intended or not.Ever since AI was started to be used, there has been a variety of discussions on the ethics which may work as guidelines for the regulation of its development and use. Some of the ethics have not yet become enforceable norm and some others exist already as a part of regulation enforceable under the power of governments. The designers or developers of such ethics are diverse from an individual to international organizations.Almost all of the AI Ethics are not sufficiently satisfying the requirements, needs, and hopes of the society members not only local level, but, national or international level. They lack something in ensuring to make all the stake-holders’ participation in developing the ethics and to achieve such key objectives as the accountability, explainability, traceability, no-bias, and privacy protection in the development, use, and improvement of AI.Based upon the review and analysis of the currently available AI Ethics, this article tries to find and suggest a method to design, develop, and improve continuously the AI Ethics through the National AI Ethics Platform where all the relevant stake-holders participate and exchange ideas and opinions together with the AI itself as a device to help, with its great capacity to deal with big data, all the processing and operation of the ethics through simulations utilizing all the input data provided by the participants and the situations surrounding the participants not in a static mode but a dynamic continuing mode."
토픽모델링과 LSTM기반 텍스트 분석을 통한 부산방문 외국인 관광객의 선호관광지 및 관광매력요인 분석,2020,"['소셜네트워크서비스', '텍스트마이닝', '토픽모델링', '딥러닝', 'LSTM', '플리커', 'social network service', 'text mining', 'topic modeling', 'deep learning', 'LSTM', 'Flickr']",,"This study attempted to analyze the preferred tourist destinations and keywords of tourist destinations of foreign tourists visiting Busan through Flickr data analysis among social network services. Recently, with the widespread use of SNS, studies using data such as location information, time and text are increasing. In particular, travel-related postings reveal the needs and preferences of tourists, so they are highly useful for analyzing travel trends and attractive factors. In this study, a travel category was created through topic modelling based on photos posted in Busan and tagged text data. By using the deep learning model LSTM, text is classified by travel category. Through the DBSCAN technique, preferred tourist destinations were derived for each travel category, and attractive factors for each tourist destination were analyzed. As a result of analysis, nine travel categories were created through topic modeling including markets/food streets, cultural heritage/historic attractions, prospects/viewing attractions, cultural/festival attractions, parks/natural scenery attractions, religious places, shopping/city scenery attractions, coastal scenery attractions, cultural villages. The accuracy of the text classification model is about 94%, which is relatively well classified. The attractive factors were identified for each travel category in Busan."
지식 그래프 임베딩 및 적응형 클러스터링을 활용한 오류 트리플 검출,2020,"['지식 그래프', '임베딩', '클러스터링', '딥러닝', 'knowledge graphs', 'embedding', 'clustering', 'deep learning']","최근 인터넷의 발전으로 정보의 양이 늘어나면서 대용량 지식 그래프를 이용한 연구가 활발히 이루어지고 있다. 또한 지식 그래프가 다양한 연구와 서비스에 활용됨에 따라 양질의 지식 그래프를 확보해야 하는 필요성이 대두되고 있다. 하지만 양질의 지식 그래프를 얻기 위해 지식 그래프 내 오류를 검출하는 연구가 부족하다. 오류 트리플 검출을 위해 임베딩과 클러스터링을 사용한 이전 연구가 좋은 성능을 나타냈다. 하지만 클러스터 최적화 과정에서 일괄적으로 동일한 임계값을 사용하여 각 클러스터의 특성을 고려하지 못하는 문제가 존재하였다. 본 논문에서는 이러한 문제를 해결하고자 지식 그래프 내 오류 트리플 검출을 위해 지식 그래프에 대한 임베딩과 함께 각 클러스터에 대한 최적의 Threshold를 찾아 적용함으로써 클러스터링을 진행하는 적응형 클러스터링 모델을 제안한다. 본 논문에서 제안하는 방법의 성능을 평가하기 위해 DBpeida, Freebase와 WiseKB 세 가지 데이터셋을 대상으로 기존 오류 트리플 검출 연구와 비교 실험을 진행하였으며 F1-Score를 기준으로 평균 5.3% 높은 성능을 확인하였다.","Recently, with the increase in the amount of information from the development of the Internet, research using large-capacity knowledge graphs is being actively conducted. Additionally, as knowledge graphs are used for various research and services, there is a need to secure quality knowledge graphs. However, there is a lack of research to detect errors within the knowledge graphs to obtain quality knowledge graphs. Previous studies using the embedding and clustering for error triple detection showed good performance. However, in the process of the cluster optimization, there was a problem that the characteristics of each cluster could not be factored using the same threshold collectively. In this paper, to resolve these problems, we propose an adaptive clustering model in which clustering is conducted by finding and applying the optimum threshold for each cluster with the embedding for knowledge graph for error triple detection in the knowledge graph. To evaluate the performance of the method proposed in this paper, the existing error triple detection studies and comparative experiments were conducted on three datasets, DBpeida, Frebase and WiseKB, and the high performance was confirmed by an average of 5.3% based on the F1-Score."
EV 충전소의 일별 최대전력부하 예측을 위한 LSTM 신경망 모델,2020,"['전기차', '최대전력부하', '부하예측', '딥러닝', 'LSTM', 'EV', 'Peak electric load', 'Load forecasting', 'Deep learning']","국내 전기차 (EV: Electric Vehicle) 시장이 성장함에 따라, 빠르게 증가하는 EV 충전 수요에 대응하기 위한 충전설비의 확충이 요구되고 있다. 이와 관련하여, 종합적인 설비 계획을 수립하기 위해서는 미래 시점의 충전 수요량을 예측하고 이를 바탕으로 전력설비부하에 미치는 영향을 체계적으로 분석하는 것이 필요하다. 본 논문에서는 한국전력공사의 EV 충전 데이터를 이용하여 충전소 단위의 일별최대부하를 예측하는 LSTM(Long Short-Term Memory) 신경망 모델을 설계 및 개발한다. 이를 위해, 먼저 데이터 전처리 및 이상치 제거를 통해 정제된 데이터를 얻는다. 다음으로, 충전소 단위의 일별 특징들을 추출하여 훈련 데이터 집합을 구성하여 일별 최대 전력부하 예측 모델을 학습시킨다. 마지막으로 충전소 유형 별 테스트 집합을 이용한 성능 분석을 통해 예측 모델을 검증하고 이의 한계점을 논의한다.","As the electric vehicle (EV) market in South Korea grows, it is required to expand charging facilities to respond to rapidly increasing EV charging demand. In order to conduct a comprehensive facility planning, it is necessary to forecast future demand for electricity and systematically analyze the impact on the load capacity of facilities based on this. In this paper, we design and develop a Long Short-Term Memory (LSTM) neural network model that predicts the daily peak electric load at each charging station using the EV charging data of KEPCO. First, we obtain refined data through data preprocessing and outlier removal. Next, our model is trained by extracting daily features per charging station and constructing a training set. Finally, our model is verified through performance analysis using a test set for each charging station type, and the limitations of our model are discussed."
클릭률 예측 성능 향상을 위한 다중 배열 CNN 모형 설계,2020,"['클릭률', 'CNN', '특징 생성', '딥러닝', 'CTR', 'Feature Generation', 'Deep Learning']","클릭률(CTR) 예측은 사용자가 주어진 항목을 클릭할 확률을 추정하는 것으로 온라인 광고 수익 극대화를 위한 전략 결정에 중요한 역할을 한다. 최근 CTR 예측을 위해 CNN을 활용하는 시도가 이루어지고 있다. CTR 데이터는 특징 정보가 연관성 측면에서 의미 있는 순서를 갖지 않기 때문에, 임의의 순서로 배열될 수 있다. 하지만 CNN은 필터 사이즈에 의해 제한된 로컬 정보만을 학습하기 때문에 데이터 배열이 성능에 큰 영향을 줄 수 있다. 이 논문에서는 CNN이 수집할 수 있는 모든 로컬 특징 정보를 추출할 수 있는 데이터 배열 집합을 생성하고 생성된 배열들에 대하여 개별 CNN 모듈들이 특징들을 학습할 수 있는 다중 배열 CNN 모델을 제안한다. 대규모 데이터 세트에 대한 실험 결과에 따르면 제안된 모델은 기존 CNN 대비 AUC의 RI에서 22.6% 상승 효과를, 제안된 배열 생성 방법은 임의 생성 방법보다 3.87% 성능 향상을 달성하였다.","Click-through rate (CTR) prediction is an estimate of the probability that a user will click on a given item and plays an important role in determining strategies for maximizing online ad revenue. Recently, research has been performed to utilize CNN for CTR prediction. Since the CTR data does not have a meaningful order in terms of correlation, the CTR data may be arranged in any order. However, because CNN only learns local information limited by filter size, data arrays can have a significant impact on performance. In this paper, we propose a multi-array CNN model that generates a data array set that can extract all local feature information that CNN can collect, and learns features through individual CNN modules. Experimental results for large data sets show that the proposed model achieves a 22.6% synergy with RI in AUC compared to the existing CNN, and the proposed array generation method achieves 3.87% performance improvement over the random generation method."
의사결정 자동화에 대한 대응으로서의 인공지능윤리 교육,2020,"['인공지능', '인공지능윤리', '자율지능시스템', '딥러닝', '알고리즘 편향', 'Artificial intelligence', 'AI ethics', 'autonomous intelligent system', 'deep learning', 'algorithm bias']","인공지능 시대에 인공지능윤리 교육은 윤리교육에 어떤 새로운 의미와 기회로 작용할 것인가? 인공지능윤리는 기존의 공학윤리와 어떤 내용이 다르며, 어떤 교육내용을 필요로 하는가? 이 논문은 이에 대해 인공지능윤리는 산업현장과 밀접하게 연관되어 있으며 인공지능 설계 과정에 내장된 방식으로 윤리적 요소가 역할을 한다는 점을 제시한다. 이 점은 각 기업과 기관들이 인공지능윤리 지침을 채택하는 점에서 잘 드러난다. 인공지능윤리 지침에 공통적으로 등장하는 알고리즘 편향, 투명성, 설명가능성, 공평성 등은 기존의 공학윤리에서 다루는 주제와는 다른 내용으로 새로운 교과로 구성될 필연성을 보여준다. 이는 각국에서 운영되는 인공지능윤리 교과의 내용에서 보여진다. 결론적으로, 인공지능윤리 교과는 공학윤리와 다른 차원의 내용을 가지며 이를 통해 보다 외연이 넓은 시민교육이 가능하다.","In the age of artificial intelligence, what new meaning and opportunity will the education of AI ethics serve? How does AI ethics differ from conventional engineering ethics and what training content does it require? In response, this paper suggests that AI ethics are closely related to industrial sites and that ethical factors play a role in the way they are built into the artificial intelligence design process. This is illustrated by the fact that each company and institution adopts artificial intelligence ethics guidelines. Algorithm bias, transparency, explainability and fairness, which are common to artificial intelligence ethics guidelines, show the inevitability of forming a new subject with different themes from those covered by conventional engineering ethics. This is shown in the contents of the AI ethics curriculum, which is educated in several countries. In conclusion, AI ethics classes have different levels of engineering ethics, which enable broader civil education."
액티비티별 특징 정규화를 적용한 LSTM 기반 비즈니스 프로세스 잔여시간 예측 모델,2020,"['예측적 프로세스 모니터링', '잔여시간 예측', 'LSTM 모델', '딥러닝', '프로세스 마이닝', 'predictive process monitoring', 'remaining time prediction', 'LSTM model', 'deep learning', 'process mining']","최근에 많은 기업 및 조직들이 비즈니스 프로세스 모델의 효율적 운용을 위해 예측적 프로세스 모니터링에 관심이 높아지고 있다. 기존의 프로세스 모니터링은 특정 프로세스 인스턴스의 경과된 실행상태에 초점을 두었다. 반면, 예측적 프로세스 모니터링은특정 프로세스 인스턴스의 미래의 실행상태에 대한 예측에 초점을 둔다. 본 논문에서는 예측적 프로세스 모니터링 기능 중 하나인비즈니스 프로세스 인스턴스 실행 잔여시간 예측기능을 구현한다. 잔여시간을 효과적으로 모델링하기 위해 액티비티별 속성에 따른시간특징 값 분포 차이를 고려하여 액티비티별 특징 정규화를 제안하고 예측모델에 적용한다. 본 논문에서 제안된 모델의 예측성능우수성을 입증하기 위해서 4TU.Centre for Research Data에서 제공하는 실제 기업의 이벤트 로그 데이터를 통해 선행연구들과 비교평가 한다.","Recently, many companies and organizations are interested in predictive process monitoring for the efficient operation of business process models. Traditional process monitoring focused on the elapsed execution state of a particular process instance. On the other hand, predictive process monitoring focuses on predicting the future execution status of a particular process instance. In this paper, we implement the function of the business process remaining time prediction, which is one of the predictive process monitoring functions. In order to effectively model the remaining time, normalization by activity is proposed and applied to the predictive model by taking into account the difference in the distribution of time feature values according to the properties of each activity. In order to demonstrate the superiority of the predictive performance of the proposed model in this paper, it is compared with previous studies through event log data of actual companies provided by 4TU.Centre for Research Data."
Approach for Managing Multiple Class Membership in Knowledge Graph Completion Using Bi-LSTM,2020,"['지식 그래프', '지식 완성', '링크 예측', '임베딩', '딥러닝', 'knowledge graph', 'knowledge completion', 'link prediction', 'embedding', 'deep learning']",,
블록체인 기반의 연합학습 구현,2020,"['블록체인', '인공지능', '연합학습', '스마트 컨트랙트', '디앱', 'Blockchain', 'Artificial intelligence', 'Fedrated Learning', 'Smart Contract', 'dApp']","인공신경망(artficial neural networks)를 활용한 딥러닝은 최근 이미지인식, 빅데이터 및 데이터분석 등다양한 분야에서 연구되고 개발이 진행되고 있다. 하지만 데이터 프라이버시 침해 이슈와 학습을 많이 할수록 소모 비용과 시간이 증가하는 문제점이 있어서 이를 해결하기 위해 연합학습(Federated Learning) 이 연구되었다. 연합학습에서는 프라이버시 문제를 완화하면서, 분산 처리 시스템의 이점을 가져오는 학습기법을 제시하였다. 하지만 여전히 연합학습에서도 프라이버시 및 보안 문제가 존재한다. 그래서 우리는 연합학습의 서버에 해당하는 부분을 블록체인으로 대체하여 연합학습의 문제점인 프라이버시 문제 와 보안 문제를 해결하였다. 또한 사용자가 제출하는 데이터에 대한 보상을 지급하여서 동기를 부여하고, 기존 성능은 유지하면서도 더 적은 비용의 유지비를 필요로 하는 시스템을 연구하였다. 본 논문에서는 우리가 개발한 시스템의의 타당성을 보이기 위해 실험결과를 제시하면서 기존 연합학습과 연구한 블록체인 기반의 연합학습 결과를 비교한다. 또한 향후 연구로 보안문제에 대한 해법과 와 적용 가능한 비즈니스 분야를 제시를 보여주면서 논문을 마무리 하였다.",
형상 분산과 합성곱 신경망을 이용한 플랜트 배관 부품에 대한 3차원 점군의 분류,2020,"['Convolutional Neural Network(합성곱 신경망)', 'Deep Learning(딥러닝)', 'Piping Part(배관 부품)', 'Point Cloud(점군)', 'Shape Classification(형상 분류)', 'Shape Distribution(형상 분산)']","본 논문에서는 플랜트 배관 부품의 3차원 점군(point cloud)으로부터 부품을 분류하기 위해 합성곱신경망(convolutional neural network)을 이용하는 방법을 제안한다. 그러나 기존 연구들이 형상을 다중 뷰이미지 형태나 복셀(voxel) 모델로 표현한 반면, 본 연구에서는 점군 안에 있는 각 점들 간의 거리 분포를 1차원 히스토그램으로 표현한 형상 분산(shape distribution)으로 형상을 나타낸다. 형상 분산은 형상의 차원을 3차원에서 1차원으로 감소시킨다. 이로 인해 학습 데이터의 크기가 줄고, 학습 속도가 빨라진다. 또한 형상 분산은 형상의 크기, 자세 및 위치에 영향을 받지 않는다. 본 연구에서는 제안한 방법의 구현 및 실험을 통해 복셀 모델로 표현한 경우보다 학습 속도가 개선되는 것을 확인하였다. 그러나 차원 감소로 인해 정확도는 감소하였다.","In this study, we propose a method for classifying plant piping parts from 3-dimensional point clouds using a convolutional neural network. Whereas previous studies have represented a shape in the form of multi-view images or voxel models, this study uses a shape distribution that represents the distance distribution between each point pair as a one-dimensional histogram. Shape distribution can reduce the dimensions of a shape from three to one. Consequently, the size of the training data is reduced, and training speed increases. Also, a shape distribution is unaffected by the size, orientation, or position of a shape. Through the implementation and experimentation of the proposed method we verified that training speed improved with the use of a voxel model. However, accuracy decreased due to dimensional reduction."
프레임 레벨 비디오 이상탐지를 위한 단일 클래스 적대학습 방법,2020,"['오토인코더', '잠재공간', '이상 탐지', '적대학습', '딥러닝', 'autoencoder', 'latent space', 'anomaly detection', 'adversarial learning', 'deep learning']","이상탐지분야에서는 이상치의 수가 매우 적어 지도학습 방법을 이용하면 데이터 불균형 및 새로운 이상치 탐지에 문제가 발생한다. 따라서 비지도 방식의 단일 클래스 분류기는 효율적으로 사용될 수 있다. 본 논문에서는 단일 클래스 적대방법을 통해 정상데이터만의 분포를 따르는 잠재공간을 학습하여 이상치를 탐지할 수 있는 모델을 제안한다. 이것은 인코더, 디코더 및 분류기의 3가지 모듈로 이루어진다. 인코더와 디코더는 입력데이터를 압축하여 잠재공간에 전사하고 전사된 데이터를 복원하는 오토인코더 구조를 가진다. 분류기는 전사된 데이터를 입력받아 왜곡된 정상 데이터인지 기존 정상 데이터인지 판단하도록 학습된다. 인코더는 왜곡된 정상 데이터가 전사된 값도 분류기를 통해 기존으로 분류되도록 적대학습하며 정상 데이터에 대한 분포를 정교하게 학습한다. 우리의 모델은 이상탐지분야에서 많이 사용되는 Modified National Institute of Standards and Technology (MNIST)와 University of California San Diego (UCSD) Pedestrian (Ped) 2 데이터를 사용하여 각각 Area Under the Curve (AUC) 0.91 및 0.72의 탐지 성능을 보여준다.","In the video anomaly detection field, the number of outlier data is very small, which leads to problems of data imbalance and inability to detect unseen outliers. Thus, an unsupervised one-class classifier can be effectively used in anomaly detection. In this paper, to resolve this problem, we propose a model that can detect abnormal data by learning latent space along the distribution of normal data through one-class adversarial learning. It comprises three modules: an encoder, a decoder, and a classifier. The encoder and decoder have an autoencoder structure that compresses the input data to be transferred to the latent space and restores them to the original. The classifier is trained to determine if the standard or distorted normal data are transferred by inputting the transferred data. The encoder learns the distribution of the normal data more precisely by training it with the classifier in adversarial learning so that the distorted normal data is also classified as the standard normal data by the classifier.Our proposed model shows the detection performance of area under the ROC curve 0.91 and 0.72 using the MNIST and the UCSD Ped2 datasets, well-known benchmark datasets in anomaly detection."
R 매핑을 이용한 인공지능의 교육적 활용 탐색 - 국외 문헌 분석을 중심으로 -,2020,"['인공지능', '교육', '연구 동향', 'R 매핑', 'Bibliometrix', 'Artificial Intelligence', 'Education', 'Research Trends', 'R mapping', 'Bibliometrix']","최근의 혁신적 기술 진보를 배경으로 지능정보사회의 핵심기술인 머신러닝, 딥러닝을 비롯한 인공지능 기술이 비약적으로 발전하면서 인공지능의 교육적 활용에 대한 관심과 필요성이 높아지고 있다. 이에 교육부에서도 인 공지능 기술에 기반한 지능정보사회를 대비하여 인공지능 역량 강화 교육을 교육 현장에 도입하는 제 1차 정보 교육 종합계획을 발표하였다. 이에 본 연구에서는 인공지능의 교육적 활용 가능성을 탐색하기 위해 Web of Science(WoS)에서 인공지능의 교육적 활용과 관련된 국외 논문 416편의 자료를 수집하였다. 수집한 자료를 대 상으로 R 프로그램의 bibliometrix 패키지를 활용하여 국가별 연구현황과 연구 주제, 인용횟수, 저자 등록 키워 드 네트워크 분석을 실시하였다. 이를 통해 현재 해외에서 이루어지는 있는 인공지능의 교육적 활용에 대한 연 구 동향을 알 수 있었다. 본 연구의 결과를 토대로 인공지능 역량 강화 교육을 위한 정보교육 과정에서 연구되 어야 할 주제와 방향성에 대한 시사점 얻을 수 있을 것으로 보인다.","There is a growing interest and need for the educational use of artificial intelligence as artificial intelligence technologies such as machine learning and deep learning, the core technologies of the intelligent information society, owing to the recent innovative technological advances. Consequently, the Ministry of Education announced the First Information Education Comprehensive Plan for introducing artificial intelligence competence enhancing education into the education field in preparation for the intelligent information society based on artificial intelligence technologies. Therefore, this study collected 416 overseas papers related to the educational use of artificial intelligence from the Web of Science (WoS) in order to explore the potential for using artificial intelligence educationally. This study analyzed the research status and research topic by country, citation counts, network analysis on keywords of the collected data by using the bibliometrix package of R program. Through this, it was possible to identify the research trend on the educational use of artificial intelligence, currently being conducted in foreign countries. It is believed that it will be possible to obtain implications for the topics and directions to be studied in the information education for strengthening artificial intelligence education based on the results of this study."
"적외선 영상, 라이다 데이터 및 특성정보 융합 기반의 합성곱 인공신경망을 이용한 건물탐지",2020,"['Deep Learning', 'Haralick Feature', 'Multimodal Data', 'Detectron2', 'Instance Segmentation', '딥러닝', 'Haralick 특성', '다중 데이터', '객체분할']",,
원격 탐사 영상을 활용한 CNN 기반의 초해상화 기법 연구,2020,"['SISR', 'remote sensing image', 'super resolution', 'edge loss', 'DPID']","초해상화 기법은 저해상도 영상을 고해상도 영상으로 변환하는 기법이다. 최근에는 딥러닝 기술을 활용한 초해상화 방법이 주류를 이루고 있으며, 원격 탐사 분야에서도 이를 응용한 연구가 증가하고 있다. 본 연구에서는 위성 영상의 4배 해상도 향상을 위하여 deep back-projection network (DBPN) 네트워크에 기반한 초해상화 기법을 제안하였다. 또한, 복원된 영상의 디테일 및 윤곽선 부분에서의 고품질 영상 획득을 위해 윤곽선 손실 함수를 제안하고, 효과적이고 안정적인 학습을 위하여 Wasserstein distance 손실 함수를 사용한 GAN 기법을 적용하였다. 또한, 자연스러운 저해상도 훈련 영상을 획득하기 위한 detail preserving image down-scaling (DPID) 기법을 적용하였다. 마지막으로 전정 영상의 특징을 추출하여 훈련의 마지막 단계에 적용 시킴으로써 출력 영상의 세부적인 특징을 효과적으로 생성하였다. 그 결과 실험에 사용된 WorldView-3 영상 및KOMPSAT-2 영상에서 해상도 향상 효과를 확인하였고, 다른 초해상화 모델에 대비하여 윤곽선 보존력이나영상의 선명도가 향상 되었음을 확인하였다.","Super-resolution is a technique used to reconstruct an image with low-resolution into that of high-resolution. Recently, deep-learning based super resolution has become the mainstream, and applications of these methods are widely used in the remote sensing field. In this paper, we propose a super-resolution method based on the deep back-projection network model to improve the satellite image resolution by the factor of four. In the process, we customized the loss function with the edge loss to result in a more detailed feature of the boundary of each object and to improve the stability of the model training using generative adversarial network based on Wasserstein distance loss. Also, we have applied the detail preserving image down-scaling method to enhance the naturalness of the training output.Finally, by including the modified-residual learning with a panchromatic feature in the final step of the training process. Our proposed method is able to reconstruct fine features and high frequency information.Comparing the results of our method with that of the others, we propose that the super-resolution method improves the sharpness and the clarity of WorldView-3 and KOMPSAT-2 images."
데이터 마이닝을 이용한 유튜브 인기 동영상 콘텐츠 분석,2020,"['데이터 마이닝', '빅데이터', '유튜브', '상관 분석', '회귀 분석', '딥러닝', 'Data Mining', 'Big Data', 'YouTube', 'Correlation Analysis', 'Regression Analysis', 'Deep Learning']",,"As the activities of creators based on Youtube are vigorously activating, video content market is also expanding in recently. In this paper, I analyze several popular YouTube contents using data mining technique, and figure out concepts and correlation going through those popular video elements. The process of data mining was done using the library provided by python. The data was collected, purified, loaded, analyzed, and visualized. First, I collected data based on popular video content on YouTube and then refined and clarified the data by extracting elements such as keywords, views, the number of likes and dislikes of videos, and the number of comments. After analyzing those refined factors by collecting the words repeatly appearing to popular videos and menus on Youtube, the result shows that the videos including the burning issues and news of the day occupy the top ranks at youtube platform. Also the result of correlation analysis, using python-based library on the loaded big data, shows positive correlation. In this paper, big data loaded by data mining based on popular YouTube video content is expected to be used for artificial intelligence service for predicting YouTube profit by executing deep learning based on regression analysis."
LSTM 모형을 이용한 하천 고탁수 발생 예측 연구,2020,"['Deep learning', 'Machine learning', 'Monitoring', 'Water quality', 'Information and communications technology(ICT)', '딥러닝', '머신러닝', '모니터링', '수질', '정보통신기술(ICT)']",,"Turbidity has various effects on the water quality and ecosystem of a river. High turbidity during floods increases the operation cost of a drinking water supply system. Thus, the management of turbidity is essential for providing safe water to the public. There have been various efforts to estimate turbidity in river systems for proper management and early warning of high turbidity in the water supply process. Advanced data analysis technology using machine learning has been increasingly used in water quality management processes. Artificial neural networks(ANNs) is one of the first algorithms applied, where the overfitting of a model to observed data and vanishing gradient in the backpropagation process limit the wide application of ANNs in practice. In recent years, deep learning, which overcomes the limitations of ANNs, has been applied in water quality management. LSTM is one of novel deep learning algorithms that is widely used in the analysis of time series data.In this study, LSTM is used for the prediction of high turbidity(>30 NTU) in a river from the relationship of turbidity to discharge, which enables early warning of high turbidity in a drinking water supply system. The model showed 0.98, 0.99, 0.98 and 0.99 for precision, recall, F1-score and accuracy respectively, for the prediction of high turbidity in a river with 2 hour frequency data. The sensitivity of the model to the observation intervals of data is also compared with time periods of 2 hour, 8 hour, 1 day and 2 days. The model shows higher precision with shorter observation intervals, which underscores the importance of collecting high frequency data for better management of water resources in the future."
국내 지자체 사진 기록물의 효율적 관리를 위한 메타데이터 설계 및 기계학습 기반 자동 인덱싱 방법 연구,2020,"['Image Archive', 'Metadata', 'OCR', 'Deep Learning', 'Automatic Indexing', '사진 기록물', '메타데이터', '딥러닝', '자동 인덱싱']","국내의 많은 지방자치단체에서는 지역에서 발생하는 사건들에 대한 시청각 기록물을 사람들이 쉽게 열람할 수 있도록 온라인 서비스를 제공하고 있다. 그러나 지자체들의 현재 사진 기록물 관리 방식은 표준적인 메타데이터가 부재하고 사진의 정보를 활용하지 않기 때문에 지자체 간 호환성과 검색 편의성이 낮은 문제점을 가진다. 이와 같은 문제점을 개선하기 위해, 본 논문에서는 국내 지자체 사진 기록물의 효율적 관리를 위한 메타데이터 설계와 기계학습 기반 자동 인덱싱 기술을 제안한다. 먼저, 본 논문에서는 국내 지자체 사진 기록물에 특화된 메타데이터를 설계하여 지자체 간 사진 기록물의 호환성을 높이고, 사진의 기본 정보와 특성을 나타낼 수 있는 요소들을 메타데이터 항목에 포함함으로써 사진 기록물의 효율적인 관리를 가능하게 한다. 또한, 기계학습 기술을 기반으로 사진의 사건과 카테고리를 반영하는 정보인 사진 속 텍스트와 객체를 자동 인덱싱하여, 사진 기록물 검색 시 사용자 검색의 편의성을 높인다. 마지막으로, 본 논문에서는 제안한 방법을 사용하여 국내 지자체 사진 기록물에서 텍스트와 객체를 자동으로 추출하고, 추출한 내용과 기본 정보를 본 논문에서 설계한 사진 기록물 메타데이터 항목에 저장하는 프로그램을 개발하였다.","Many local governments in Korea provide online services for people to easily access the audio-visual archives of events occurring in the area. However, the current method of managing these archives of the local governments has several problems in terms of compatibility with other organizations and convenience for searching of the archives because of the lack of standard metadata and the low utilization of image information. To solve these problems, we propose the metadata design and machine learning-based automatic indexing technology for the efficient management of the image archives of local governments in Korea. Moreover, we design metadata items specialized for the image archives of local governments to improve the compatibility and include the elements that can represent the basic information and characteristics of images into the metadata items, enabling efficient management. In addition, the text and objects in images, which include pieces of information that reflect events and categories, are automatically indexed based on the machine learning technology, enhancing users’ search convenience. Lastly, we developed the program that automatically extracts text and objects from image archives using the proposed method, and stores the extracted contents and basic information in the metadata items we designed."
제조업 전력량 예측 정확성 향상을 위한 Double Encoder-Decoder 모델,2020,"['Time-Series Forecasting', 'Deep Learning', 'Machine Learning', '시계열 예측', '딥러닝', '머신러닝']",,"This paper investigated methods to improve the forecasting accuracy of the electricity consumption prediction model. Currently, the demand for electricity has continuously been rising more than ever. Since the industrial sector uses more electricity than any other sectors, the importance of a more precise forecasting model for manufacturing sites has been highlighted to lower the excess energy production. We propose a double encoder-decoder model, which uses two separate encoders and one decoder, in order to adapt both long-term and short-term data for better forecasts. We evaluated our proposed model on our electricity power consumption dataset, which was collected in a manufacturing site of Sehong from January 1st, 2019 to June 30th, 2019 with 1 minute time interval. From the experiment, the double encoder-decoder model marked about 10% reduction in mean absolute error percentage compared to a conventional encoder-decoder model. This result indicates that the proposed model forecasts electricity consumption more accurately on manufacturing sites compared to an encoder-decoder model."
[응용논문] 차량간 상호작용이 고려된 멀티-헤드 어텐션 구조 기반 주변 차량 주행 경로 예측 알고리즘,2020,"['Trajectory prediction(경로 예측)', 'Learning based model(학습 기반 모델)', 'Deep learning(딥러닝)', 'Interaction(상호 작용)', 'Supervised learning(지도 학습)']",,
스마트 팩토리에서 그리드 분류 시스템의 협력적 다중 에이전트 강화 학습 기반 행동 제어,2020,"['Deep Learning', 'Reinforcement Learning', 'Sortation System', 'Cooperative Multi-Agent', '딥러닝', '강화 학습', '분류 시스템', '협력적 다중 에이전트']","스마트 팩토리는 설계, 개발, 제조 및 유통 등 생산과정 전반이 디지털 자동화 솔루션으로 이루어져 있으며, 내부 설비와 기계에 사물인터넷(IoT)을 설치해 공정 데이터를 실시간으로 수집하고 이를 분석해 스스로 제어할 수 있게 하는 지능형 공장이다. 스마트 팩토리의 장비들은 게임과 같이 가상의 캐릭터가 하나의 객체 단위로 구동되는 것이 아니라 수많은 하드웨어가 물리적으로 조합되어 연동한다. 즉, 특정한 공동의 목표를 위해 다수의 장치가 개별적인 행동을 동시다발적으로 수행해야 한다. 공정 데이터를 실시간으로 수집할 수 있는 스마트 팩토리의 장점을 활용하여, 일반적인 기계 학습이 아닌 강화 학습을 사용하면 미리 요구되는 훈련 데이터 없이 행동 제어를 할 수 있다. 하지만, 현실 세계에서는 물리적 마모, 시간적 문제 등으로 인해 수천만 번 이상의 반복 학습이 불가능하다. 따라서, 본 논문에서는 시뮬레이터를 활용해 스마트 팩토리 분야에서 복잡한 환경 중 하나인 이송 설비에 초점을 둔 그리드 분류 시스템을 개발하고 협력적 다중 에이전트 기반의 강화 학습을 설계하여 효율적인 행동 제어가 가능함을 입증한다.","Smart Factory consists of digital automation solutions throughout the production process, including design, development, manufacturing and distribution, and it is an intelligent factory that installs IoT in its internal facilities and machines to collect process data in real time and analyze them so that it can control itself. The smart factory's equipment works in a physical combination of numerous hardware, rather than a virtual character being driven by a single object, such as a game. In other words, for a specific common goal, multiple devices must perform individual actions simultaneously. By taking advantage of the smart factory, which can collect process data in real time, if reinforcement learning is used instead of general machine learning, behavior control can be performed without the required training data. However, in the real world, it is impossible to learn more than tens of millions of iterations due to physical wear and time. Thus, this paper uses simulators to develop grid sortation systems focusing on transport facilities, one of the complex environments in smart factory field, and design cooperative multi-agent-based reinforcement learning to demonstrate efficient behavior control."
인공지능과 자유의지,2020,"['인공지능', '자유의지', '정보처리지스템', '창발성', '복잡계', '보상원리', '욕구', '동기', '머신러닝', '딥러닝', '법인격', 'Artificial intelligence', 'Free will', 'Information processing system', 'Emergence', 'complex system', 'Motivation-decision model', 'Desire', 'machine learning', 'Deep learning']",,"Human beings have dignity and are responsible for their actions because they have free will.The human brain and artificial intelligence have in common that they are information processing systems that process the information from outside and output the result. The relationship between humans and AI is legally important, as there are views that artificial intelligence needs to be recognized as a legal entity and that artificial intelligence needs to be held accountable for its action just like humans. If artificial intelligence has free will, there is no reason to treat AI differently from humans.In order to examine whether AI can have free will, it is necessary to define the concept of free will. Free will can be divided into freedom and will. Freedom means being free from physical causes, but the definition of freedom in this way cannot explain the fact that the brain is governed by the laws of physics. To avoid this inconsistency, freedom can be defined as unpredictability and the unknownness of causes. In reality, we can not distinguish the unknownness of causes from nonexistence of causes. In this respect, the human brain is free, because the causes of the brain's judgment can not be physically identified. Will means a mental state that is motivated to achieve a certain purpose. Motivation means desire and dread, or the pursuit of pleasure and the avoidance of pain. The desire can be divided into first order desire which is directly related to survival or reproduction and second order desire such as curiosity, desire of power, and the pursuit of wealth. Among these two types of desire, only the second order desire is related to the will. In order to recognize the free will of AI, the information processing of AI should be unpredictable and AI should have second order desires. It is impossible to determine the cause of the AI output value. Therefore, information processing of AI is as free as the human brain. However, the activity of the human brain is more difficult to predict than AI because metacognition and self-awareness, or high level awareness is the key attributes of human mind. It is unclear whether high-level awareness of AI based on metacognition is possible. If high-level thinking of AI is impossible, AI is less free than humans.In order for AI to have a will, it must have desire or dread. While desire and dread are motivations for humans, it is not clear how these motivations are working in the brain's information processing. Therefore, in order to make the algorithm of motivations such as desire and dread, we must first reveal the secrets of the human brain. Unlocking the secrets of the brain eventually means unlocking the secret of the beginning of life, which seems to be difficult in the near future. Even if we reveal the secrets of the brain, it is not certain that the algorithm of motivation can be technically developed. Considering these points, it is difficult for AI to have a will. As a result, AI cannot have free will because it has a lower level of freedom than humans, and it is difficult to have will."
Methodology for Identifying Key Factors in Sentiment Analysis by Customer Characteristics Using Attention Mechanism,2020,"['Attention Mechanism', 'Big Data', 'Deep Learning', 'Review Analysis', 'Text Analytics', '딥러닝', '빅데이터', '리뷰 분석', '어텐션', '텍스트 분석']","최근 온라인 리뷰의 증가와 분석 기술의 발달로 인해 온라인 리뷰 분석에 대한 관심과 수요가 지속적으로 증가하고 있다. 하지만 리뷰 분석을 다룬 기존의 연구는 동일한 어휘라도 각 어휘에 담긴 감정은 리뷰어에 따라 서로 다를 수 있다는 점을 반영하지 못했다는 한계를 갖는다. 따라서 본 연구에서는 고객의 등급에 따라 고객군을 분류하고, 각 고객군별로 리뷰 분석을 수행하여 그 차이를 분석한 결과를 제시하였다. 의류 전문 쇼핑몰인 ""M""사의 리뷰에 대한 분석을 수행한 결과, 쇼핑몰 사용도가 높은 고객의 경우 가격적인 요소가, 쇼핑몰 사용도가 낮은 고객의 경우 쇼핑몰에 소개된 내용과 실제 제품의 일치 정도가 제품의 긍/부정 평가에 크게 영향을 미치는 것으로 파악되었다. 제안 방법론은 고객군별로 제품 평가에 중요하게 영향을 미치는 요소를 식별함으로써, 차별화된 마케팅 전략을 수립하는 데에 효과적으로 활용될 수 있을 것으로 기대한다.","Recently, due to the increase of online reviews and the development of analysis technology, the interest and demand for online review analysis continues to increase. However, previous studies have not considered the emotions contained in each vocabulary may differ from one reviewer to another. Therefore, this study first classifies the customer group according to the customer""s grade, and presents the result of analyzing the difference by performing review analysis for each customer group. We found that the price factor had a significant influence on the evaluation of products for customers with high ratings. On the contrary, in the case of low-grade customers, the degree of correspondence between the contents introduced in the mall and the actual product significantly influenced the evaluation of the product. We expect that the proposed methodology can be effectively used to establish differentiated marketing strategies by identifying factors that affect product evaluation by customer group."
물리교육에서의 인공지능의 활용 방안에 대한 논의,2020,"['Artificial intelligence', 'Deep learning', 'Machine learning', 'Adaptive learning', 'Predictive learning analytics', '인공지능', '딥러닝', '머신러닝', '적응 학습', '학습 성과 예측']","본 연구는 최근 주목받고 있는 인공지능에 관한 기술과 방법을 현재 또는 가까운 미래에 물리교육에서어떻게 활용할 수 있는지 제안하고자 하였다. 이에 본 연구에서는 판별 예측과 적응 학습, 자연어 처리, 컴퓨터 비전을 토대로 물리교수학습에서 겪는 어려움을 해소할 수 있는 방안을 제시하였다. 판별 예측을활용한 물리학습 성과에 대한 사전 진단은 잠재적으로 물리 학습에 어려움을 겪는 학생들을 미리 파악해서대처할 수 있으며, 물리학습에 영향을 미치는 다양한 요인 중 무엇이 더 큰 효과를 미치는지 파악할수 있다. 유전 알고리즘을 기초로 여러 방법을 혼합한 적응 학습은 우수한 학생 뿐만 아니라 물리학의기초가 부족한 학생에게 대응할 수 있도록 함으로써 학습 격차 문제를 해소하는 데에 도움을 줄 수 있다.자연어 처리를 활용한 학습자의 응답에 대한 분석은 선다형 문제가 가지는 학습자의 이해와 사고의제한적 평가 문제를 해결하고, 과정 중심 평가가 보다 현장 속에서 자리잡을 수 있게 하는 데에 도움을줄 수 있다. 컴퓨터 비전과 시뮬레이션을 활용한 교육은 온라인에서의 주의결핍이나 집중력 저하 문제를 해결하고, 중고등학교에서의 실험 부족과 추상적 물리 개념 이해를 돕는 새로운 대안으로 제시될 수 있다.","This study aims at discussing how technologies related to artificial intelligence can be applied to physics education in the near future. Thus, this study concentrates on prevailing technologies such as classification/regression, adaptive learning, natural language processing, and computer vision to resolve contemporary issues in physics education. The precautionary diagnose using predictive analytics enables us to cope with forthcoming student problems and to determine the influential factors among the various features. Adaptive learning based on genetic algorithms allow us to meet various demands on physics learning so that we can teach a variety of students with different learning outcomes. Natural language processing can be useful to overcome the limitations of multiple-choice items and to analyze the diverse responses to teaching and learning in physics. Computer vision and simulation are beneficial to detect student loss of motivation and to make the invisible visible, which are good ways to learn abstract concepts in physics."
범용 서버 프로세서에서의 FLsched 스케줄러 성능 고찰,2020,"['운영체제', '스케줄러', '성능', 'operating system', 'scheduler', 'performance']","프로세서 구조가 매니코어 형태로 발전하고 있고, 한 프로세서에 집적되는 코어의 수는 지속적으로 증가하고 있다. 급속히 증가하는 인공지능과 딥러닝 워크로드는 급속히 증가하고 있고, 계산 집약적이고 매우 큰 병렬성을 요구하는 워크로드 또한 이러한 추세를 가중시키고 있다. 반면, 운영체제에서 매니코어를 지원하기 위한 스케줄러의 발전은 하드웨어 발전 속도를 따라가지 못하고 있지만, 최근 리눅스 운영체제에서 매니코어 프로세서를 고려하여 최적화된 FLsched가 제안된 바 있다. FLsched는 Xeon Phi 프로세서를 고려하여, lockless 디자인과 context switch의 수를 최소화함으로써 성능의 향상을 이루고자 한다. 본 연구에서는 FLsched가 범용 서버급 프로세서에서도 타당성을 가지는지, 성능 향상이 가능한지 분석하고 고찰해 본다. 다수의 서버급 워크로드와 벤치마크를 이용한 성능평가 결과, CFS 대비하여 FLsched가 우수한 성능을 나타내었으며, Xeon Phi에서 보다 그 성능의 향상 정도가 더 큰 것으로 나타났다. 주요한 이유로 FLsched의 lockless 디자인이 주요한 것으로 분석된다.","The processor structure has evolved into a manycore processor, and the number of cores integrated into a processor has been continuously increasing. Rapidly increasing AI and deep learning workloads, that are computation-intensive and highly parallel, are also accelerating this trend. Conversely, the development of the OS scheduler to support manycore processors cannot match with the speed of hardware development. But recently, FLsched has been proposed which considers manycore processors in the Linux operating system. FLsched aims the Xeon Phi processor and focuses on improving the scheduler performance by removing the internal locks and by minimizing the number of context switches. In this paper, we analyze and study if FLsched is feasible in general-purpose server-class processors and if the performance can be improved. As a result of a performance evaluation using many server-class workloads and benchmarks, FLsched showed superior performance compared to CFS, and the degree of improvement in the performance was greater than in the Xeon Phi. The lockless design of FLsched is the main reason."
인공지능과 빅데이터 분석 기반 통합보안관제시스템 구축방안에 관한 연구,2020,"['보안관제', '융합보안', '인공지능', '보안빅데이터', '통합보안관제시스템', 'Convergence Security', 'Artificial Intelligence', 'Big Data Analysis', 'Machine Learning', 'Enterprise Security Management System']","국내외 보안시장은 4차 산업혁명(The Fourth Industrial Revolution)의 핵심원천기술인 인공지능(artificial intelligence), 사물인터넷(internet of things), 딥러닝(deep learning), 빅데이터(big data), 자율주행(automatic driving) 등이 물리보안 및 사이버보안과 결합되어 새로운 융합보안시장을 창출하고 있다. 4차 산업혁명 시대에는 물리 · 정보 · 융합보안을 포괄하는 통합보안관제의 중요성이 날로 강조되고 있다. 글로벌 보안기업들은 인공지능 역량과 사이버위협 인텔리전스(cyber threat intelligence)가 집약된 융복합 관제 인프라를 구축해 나가고 있다. 본 연구에서는 인공지능과 빅데이터 기술을 적용한 통합보안관제시스템 구축에 필요한 기술적, 제도적인 요소를 제시하였다. 연구결과, (1) 글로벌 사이버 위협정보를 실시간 수집 · 공유하여 보안빅데이터 구축과 통합 플랫폼으로 위협 탐지 · 대응해야 함 (2) 머신러닝 기반의 인공지능 기술 적용과 빅데이터 분석고도화가 필요함 (3) 클라우드와 블록체인 기술을 융합한 통합보안관제센터 구축 필요함 (4) 지능형 영상 관제기술 및 지능형 선별관제 고도화 필요함 (5) SOAR 플랫폼 구축 및 보안운영 자동화 대비 (6) 보안관제체계의 통합과 융합보안 핵심인재양성 필요성 등의 제도적 · 기술적인 요소들을 통합보안관제시스템 구축에 필요한 실천과제로 제시하였다.","The security market is the core source technologies of the Fourth Industrial Revolution, artificial intelligence (AI), Internet of Things (IoT), deep learning, Big Data, automatic driving, etc. Combined with this physical security and cyber security, it creates a new convergence security market. In the era of the fourth industrial revolution, the importance of integrated security covering physical, information and convergence security is emphasized. Global security companies are building a converged control infrastructure that incorporates AI capabilities and cyber threat intelligence. In this study, we presented the technical and institutional elements necessary for the construction of an enterprise security management system (ESMS) using AI and Big Data technology. The results of this study, we suggested six institutional and technical factors required to establish ESMS including: (1) global cyber threat information must be collected and shared in real time, and security Big Data must be built and integrated to detect and respond to threats, (2) the need to upgrade and apply AI technology based on machine learning and Big Data analysis, (3) the need to build a cloud security command center (CSCC) that combines cloud and block-chain technology, (4) improvement of technologies for intelligent video control and intelligent screening control, (5) development of security orchestration, automation and response (SOAR) operation automation, (6) the need to integrate security control systems and foster core talents for convergence security."
스테레오 카메라를 이용한 판류형 간판의 규격 판별,2020,"['Signboard', 'Stereo Camera', 'Calibration', 'Flat-Type', 'Deep Learning', 'Interior Orientation', 'Relative Orientation', '간판', '스테레오 카메라', '캘리브레이션', '판류형', '딥러닝', '내부표정', '상호표정']",,
인공 소통과 귀속의 문제,2020,"['인공 소통', '인공 지능', '인공 감정', '소통과 행위', '귀속', '인격', '이중의 우연성', '가상 우연성', '딥러닝 알고리즘', '엘레나 에스포지토', 'artificial communication', 'artificial intelligence', 'artificial emotions', 'communication and action', 'attribution', 'person', 'double contingency', 'virtual contingency', 'deep learning algorithm', 'Elena Esposito']",,
DPESS: 임베딩 공간 통계를 이용한 주간 위성 이미지 기반의 인구 통계학적 속성 예측,2020,"['atellite imagery', 'deep learning', 'embedding', 'demographics', 'principle component analysis', 'urbanization', '위성 이미지', '위성영상', '딥러닝', '임베딩', '인구통계', '주성분분석', '도시화']","위성 이미지를 이용하여 사회 경제적 지표로 활용되는 인구 통계를 예측하거나 분석하는 연구가 활발히 진행되고 있다. 본 연구에서는 심층 신경망 모델을 기반으로 주간 위성 이미지를 이용하여 특정 지역의 인구 통계학적 속성 값을 예측하기 위한 새로운 접근법을 제시한다. 총 4단계로 이루어진 DPESS 모델은 정보의 손실 없이 많은 수의 입력 위성 이미지를 고정 길이의 벡터로 요약한다. 이는 전이 학습 및 임베딩 공간 통계와 같은 고유한 기술로 인해 가능하다. 연구 결과, 인구 밀도(R²=0.94), 15-29세 그룹 인구수(0.80), 고등학교 졸업 인구수(0.79), 가구당 총 구매력(0.80)과 같은 다양한 인구 통계학적 요소 값을 위성 이미지만으로도 효과적으로 예측할 수 있다. 한편, 본 연구를 다른 국가에 적용하기 위해서는 추가적인 연구가 필요할 것으로 사료된다.","Studies are being actively conducted to predict or analyze demographics used as socioeconomic factors using satellite images. We present a new approach, called DPESS, for estimating demographic attributes from daytime satellite imagery based on a deep neural network model. The four steps of the DPESS summarize any number of input images into a fixed-length embedded vector without a considerable loss of information, which is possible because of its unique structure and technique like transfer learning and embedded spatial statistics. Our extensive validation demonstrates that the DPESS model can predict various advanced demographics such as population density (R²=0.94), population count by age group (0.80), population count by education degree (0.79), and total purchase amount per household (0.80). We discuss future applications of this method in terms of applying our algorithm to other countries."
가로주택 정비사업에서 인공지능의 활용에 대한 연구: 의정부시의 현황을 사례로,2020,"['Block-unit Renewal project', 'artificial intelligence', 'machine learning', 'deep learning', 'autonomous construction.', '가로주택정비사업', '인공지능', '머신러닝', '딥러닝', '자율건축']","가로주택정비사업은 기존정비사업과 비해 소규모로 정비구역의 지정없이 많은 절차가 간소화되어 진행되는 사업이라 규모의 경제가 달성하기 어려워 검토비용의 제약과 시간상의 제약이 존재한다. 인공지능을 활용해서 그러한 제약을 극복하는 상황이 현재 진행되고 있다.LH공사, SH공사, 경기주택도시공사, 기타 관련 공기업에서 이미 인공지능을 사용하여 사업요건의 적합성검토, 건축법규에 적합한 건축설계, 종전 자산의 가치 추정과 신규 건물의 가치 추정 등이 이미 현장에서 활용되고 있다. 그리고 이에 대한 이론적, 기술적 고찰을 진행하였다.의정부시의 사례를 분석한 결과 경기주택도시공사에서 업체에 의뢰해 인공지능으로 사업성검토를 한다는 것이 별로 알려져 있지 않아 18곳의 가로주택정비사업의 사업 중에서 4곳만 사업성검토를 받아 이에 대한 홍보가 필요할 것으로 보인다. 또 경기주택도시공사를 통해서 업체에 의뢰를 해서 일방적으로 결과나 보고서를 통보받는 것 보다는 사업조건의 변화에 대한 민감도분석 등에 대한 피드백과 상호작용이 있으면 더 활용이 극대화될 것이다. 또한 더 적극적으로는 시나 공사와 같은 공공부문에서 가로주택정비사업의 요건을 갖춘 곳을 인공지능을 통해 발굴하여 추진하는 것도 고려할 필요가 있다.더 나아가 향후 자동화가 더 진행되어 웹상에서 바로 사업요건분석, 사업성분석 등이 가능해 지면 시의 차원에서 인접해서 추진하고 있는 가로주택정비구역을 묶어서 추진하여 기반시설개선효과가 더 높아지는 등의 개선책도 실행할 필요가 있다.","The Block-unit Renewal Project is small compared to the existing maintenance project, and it is a project in which many procedures are simplified without designation of a maintenance zone. Therefore, it is difficult to achieve economies of scale, so cost and time constraints exist. There are already situations in which artificial intelligence is used to overcome such limitations.LH Corporation, SH Corporation, Gyeonggi Housing and Urban Corporation, and other related public enterprises have already used artificial intelligence to review the suitability of business requirements, architectural design conforming to building regulations, and estimate the value of previous assets and estimate the value of new buildings. It is being utilized.As a result of analyzing the case of Uijeongbu City, it is not known that the Gyeonggi Housing and Urban Corporation commissioned a company to review the business feasibility with artificial intelligence, so only four of the 18 Block-unit Renewal projects received a feasibility review and thus need to be promoted. Seems to be. In addition, rather than requesting a company through Gyeonggi Housing and Urban Corporation to receive results or reports unilaterally, the use will be maximized if there is an interaction such as sensitivity analysis for changes such as changes in conditions. In addition, it is also necessary to consider proactively discovering and promoting places that meet the requirements of Block-unit Renewal projects in public sectors such as city and public sector through artificial intelligence.In the future, when more automation is carried out and it becomes possible to analyze business requirements and feasibility directly on the web, it is necessary to prepare for situations such as increasing the effect of improving infrastructure by grouping and promoting adjacent areas."
"인공지능 창작물의 저작물성에 관한 중국 판례 검토 - 페이린, 드림라이터 사건을 중심으로 -",2020,"['인공지능', '인공지능 창작물', '저작권법', '권리 주체', '보호 요건', 'Artificial Intelligence', 'Artificial Intelligence Creation', 'Copyright Law', 'Subject of Rights', 'Protection Requirement']","인공지능이 처음 등장하였을 때는 창작물을 만들기 위한 하나 의 도구로 활용되는 것에 불과하였다. 그러나 지금은 딥러닝, 머신러닝 방식을 통해 인공지능이 대량의 정보를 인식해 스스 로 분석하고 학습함으로써 인간의 추가적 명령 없이도 스스로 창작물을 완성할 수 있는 단계에 도달할 정도로 발전하였다. 따 라서 인공지능이 창작한 창작물에 대한 법적 대응을 어떻게 할 것인지에 대해 국가마다 논의가 활발하다. 최근 중국 법원에서 인공지능이 창작한 창작물에 대한 2건의 법원 판결이 있었으며 1건은 최종심까지 내려졌다. 인공지능이 창작한 창작물에 대한 저작권 침해 소송에 대해 법원이 판결하 였다는 점에서 큰 의미가 있다. 따라서, 본 논문은 인공지능 창 작물에 대한 중국 법원 판결인 페이린 사건과 드림라이터 사건 을 중심으로 관련 판례를 소개하고, 중국 저작권법상 저작물의 성립 요건 및 저작자 지위에 관한 법적 검토를 통해 인공지능 창작물에 대한 중국의 태도를 살펴보았다. 2건의 판례에 등장한 인공지능은 약한 인공지능 단계로 최종 결과물이 생성될 때 인간의 참여가 들어간다는 것을 전제로 중 국 법원은 인공지능 창작물의 주체성은 부정하고, 법인 저작물 로써 창작물의 저작물성을 긍정하였다. 그러나 강한 인공지능이 등장할 경우 지금의 중국 법원 판결만으로는 여전히 그 답을 내릴 수는 없다. 저작권법상 인공지능 창작물에 대한 검토가 어 렵다면 오히려 부정경쟁방지법의 보호 대상이 계속 확대되고 있는 상황에서 부정경쟁행위 유형의 하나인 ‘상당한 투자나 노 력으로 만들어진 성과’로 접근하여 인공지능 창작물에 대한 해 결 방법도 고민할 수 있지 않을까 생각한다.","When artificial intelligence first appeared, it was only used as a tool to create creations. But now, artificial intelligence has become so advanced without additional human commands through deep learning and machine learning that it can recognize a large amount of information, analyze and learn on its own. Therefore, there are active discussions among countries on how to take legal action against creations created by artificial intelligence. There have been two recent court cases in Chinese courts on creations created by artificial intelligence. One of them had a final decision. It is significant in that the court ruled against a copyright infringement lawsuit against a creation created by artificial intelligence. Therefore, this paper introduces relevant precedents focusing on the Feilin case and Dreamwriter case, which are Chinese court cases on artificial intelligence creations. We examined China's attitude toward artificial intelligence creations through a legal review of the requirements for the establishment of works and the status of authors under the Chinese Copyright Law. AI, which appeared in the two cases, was an weak artificial intelligence stage, based on the assumption that human participation was involved when the final results were produced. The Chinese court denied the identity of the artificial intelligence creation, but recognized it as a work. However, if strong artificial intelligence appears, the current Chinese court cases alone will still not give the answer. If it is difficult to review artificial intelligence creations under the copyright law, the solution to artificial intelligence creations should also be considered in terms of performance made with considerable investment or effort one of the types of anti-unfair competition action."
"CCTV 영상으로부터 미세먼지 추정에서 학습영상조합, 기상변수 적용이 결과에 미치는 영향",2020,"['Deep Learning', 'PM Index', 'Support Vector Regression', 'SVR (Support Vector Regression)', 'CCTV', 'Convolutional Neural Network', '딥러닝', '미세먼지 지수', '합성곱 신경망']",,
"순환신경망, GRU를 이용한 자세 추정 기반 낙상 감지 기법",2020,"['Human Pose Estimation', 'Skeleton', 'Fall Detection', 'Deep Learning', 'GRU', '사람 자세 추정', '스켈레톤', '낙상 감지', '딥러닝', 'GRU']","낙상은 65세 이상의 노년층의 부상 또는 사망의 주요 원인으로 사회적 비용의 발생요인이다. 또한 산업현장에서 종종 발생하는 낙상 및 추락도 정확한 낙상 여부를 판단과 신속한 조치가 요구 된다. 다양한 낙상 감지 기법이 소개 되었으나 기존 센서기반 낙상 감지 장치는 사용자의 불편과 응답 시간이나 제한된 하드웨어 리소스로 인해 여전히 효과가 낮았다. 그러나 RNN (Recurrent Neural Network)은 순차적 입력을 분석하는 문제에서 뛰어난 정확성을 제공하므로 논 논문은 2D RGB 저가 카메라에서 얻은 스켈레톤 데이터를 기반으로 하는 낙상 감지 기법을 제안한다. 특히 GRU를 이용한 낙상 감지 정확도 향상을 위한 특징 추출 및 분류 방법을 제안하였다. 특징 추출을 위한 학습을 위해 공개 데이터 셋을 사용하였고, 높은 분류 정확도를 달성하기 위한 특징 추출 방법을 찾기 위한 시험 결과, 제안된 방법은 원시 골격 데이터 사용보다 낙상탐지에 효과적이다.",
전쟁의 본질로 바라본 인공지능의 군사적 활용 - 지휘결심 지원체계의 적용을 중심으로 -,2020,"['Artificial Intelligence', 'The nature of War', 'Command decision', 'support system', 'Deep-learning', 'Big data', '인공지능', '전쟁의 본질', '지휘결심 지원체계', '딥러닝', '빅데이터']","제4차 산업혁명의 시대적 흐름에 따라 첨단 과학기술을 효율적으로 적용하는 것은 국가적 차원의 관심사이며, 군도 인공지능 기술을 적용하여 첨단과학기술군으로 거듭나고자 실질적인 노력을 경주하고 있다. 이러한 노력을 통합하기 위해 전담조직이 구성되어 역할을 하고 있으며, 이미 인공지능 기술이 차후 전쟁의 양상과 전투에서 어떻게 영향을 미치게 될지에 관한 연구들이 진행되어 기술적, 제도적 차원에서 고려해야 할 사항들이 도출되었다. 본 연구는 기술적 관점에서 벗어나 전쟁의 변하지 않는 본질적 특성이 과학기술이 전장에서 활용될 때 어떠한 영향을 미치게 되는지, 우리가 인공지능을 전장환경에서 활용할 때 어떠한 것들을 고려해야 하는지 도출하고자 하였다.다른 산업분야의 사례들을 고려하여 전쟁이라는 분야에서도 인공지능은 인간의 영역(특히, 의사결정 분야)을 대체할 수 있는 것인가? 어디까지 인간의 영역을 대체할 수 있으며, 활용시 고려해야 할 사항은 무엇인가? 에 대한 근본적인 질문에 답하기 위해서 현재 군사분야에 적용이 추진되고 있는 인공지능의 기술적 한계와 전쟁의 본질을 이론적으로 검토하고, 이론적 검토의 결과로 도출된 특징을 기준으로 하여 기존의 문헌연구와 과거 사례를 통해 인공지능 활용시 고려사항들을 제시하였다.우리가 활용하고자 하는 인공지능은 충분하고 신뢰도 높은 빅데이터와 학습 알고리즘을 필요로 하고, 그런 조건들이 충족되어 개발되더라도 다양한 기술적 한계를 가지게 된다. 그리고 이것이 활용되는 전쟁의 영역이 가지는 본질적 특성들은 인공지능의 기술적 한계가 더욱 취약점으로 두드러지게 하는 조건을 형성한다. 즉, 다른 산업분야와 달리 전장환경은 인공지능이 능력을 발휘하기에는 쉽지 않은 환경이다.이러한 제한을 극복하고 성공적인 인공지능의 개발과 적용을 위해 전쟁의 불확실성, 딜레마 극복, 치명성과 불가역성, 적의 존재, 기타 기술적 문제 등의 차원에서 고려사항과 현재의 문제점 등을 제시하고 현실적인 해결방안을 논함으로써 실질적인 전력개발에 도움이 되고자 하였다.","The purpose of this study was to figure out how the unchanging essential characteristics of war will affect science and technology when used on the battlefield, and what to consider when using AI in military field.In the field of war, can AI replace the human realm (especially decision-making)? How far can we replace the human realm, and what should be considered when using it? In order to answer these fundamental questions, the technological features of AI , and the nature of war are reviewed theoretically.And based on features derived as a result of theoretical reviews, the considerations when using AI were presented through studies of existing literature and past cases.The result of this study shows that the essential characteristics of war form unfavorable conditions which make the technological limits of AI more prominent as vulnerabilities. For the successful utilization of AI in the battlefield, current and expected problems were discussed. And then, practical solutions were suggested in terms of uncertainty of war, overcoming dilemma, fatality and irreversibility, enemy existence, and other technical problems."
Fast Super-Resolution GAN 기반 자동차 번호판 검출 및 인식 성능 고도화 기법,2020,"['객체 검출', '고해상도', '적대적 생성망', '번호판 검출', '번호판 인식', 'Object Detection', 'Super-Resolution', 'Generative Adversarial Network', 'License Plate Detection', 'License Plate Recognition']","자동차 번호판 인식 기술은 도로의 교통상황 통제, 과속차량 단속, 도주 차량의 추적 등 현대 교통 시설 및 교통 안전망을 책임지고 있는 핵심 기술 중 하나이다. 이 기법은 과거에도 연구되었던 분야였으나 최근 딥러닝 기술의 발전으로 다양한 기법들을 적용하여 향상된 성능을 보이는 분야이며, 크게 자동차 번호판 검출과 번호판 인식으로 나뉜다. 본 연구에서는 다양한 객체 검출 모델과 WPOD-Net(Warped Planar Object Detection Network) 모델을 활용하여 자동차 번호판 검출 성능을 향상시키기 위한 실험을 진행하였으며, 객체 검출 모델을 활용하여 번호판을 검출하는 기존 방식들 대신 차량을 검출한 다음 번호판을 검출하는 방식을 택하여 정확도를 높였다. 특히 Super-Resolution 기법 중 하나인 Fast-SRGAN 모델을 활용하여 이미지 내에 존재하는 노이즈를 제거하는 처리를 통해 최종 성능을 향상시켰다. 결과적으로 92.38%에서 96.72%로 선행 연구 대비 평균 4.34% 향상된 성능이 실험을 통해 확인되었다.","Vehicle License Plate Recognition is one of the approaches for transportation and traffic safety networks, such as traffic control, speed limit enforcement and runaway vehicle tracking. Although it has been studied for decades, it is attracting more and more attention due to the recent development of deep learning and improved performance. Also, it is largely divided into license plate detection and recognition. In this study, experiments were conducted to improve license plate detection performance by utilizing various object detection methods and WPOD-Net(Warped Planar Object Detection Network) model. The accuracy was improved by selecting the method of detecting the vehicle(s) and then detecting the license plate(s) instead of the conventional method of detecting the license plate using the object detection model. In particular, the final performance was improved through the process of removing noise existing in the image by using the Fast-SRGAN model, one of the Super-Resolution methods. As a result, this experiment showed the performance has improved an average of 4.34% from 92.38% to 96.72% compared to previous studies."
OCR 엔진 기반 분류기 애드온 결합을 통한 이미지 내부 텍스트 인식 성능 향상,2020,"['Scene text recognition (STR)', 'Optical character recognition (OCR)', 'Text detection', 'Deep learning', 'Machine learning']","일상 환경에서 동작하는 자율 에이전트를 구현하기 위해서는 이미지나 객체에 존재하는 텍스트를 인식하는 기능이 필수적이다. 주어진 이미지에 입력 변환, 특성 인식, 워드 예측을 적용하여 인식된 텍스트에 존재하는 워드를 출력하는 과정에 다양한 딥러닝 모델이 활용되고 있으며, 딥뉴럴넷의 놀라운 객체 인식 능력으로 인식 성능이 매우 향상되었지만 실제 환경에 적용하기에는 아직 부족한 점이 많다. 본 논문에서는 인식 성능 향상을 위하여 텍스트 존재 영역 감지, 텍스트 인식, 워드 예측의 파이프라인에 OCR 엔진과 분류기로 구성된 애드온을 추가하여 기존 파이프라인이 인식하지 못한 텍스트의 인식을 시도하는 접근법을 제안한다. IC13, IC15의 데이터 셋에 제안 방법을 적용한 결과, 문자 단위에서 기존 파이프라인이 인식하는데 실패한 문자의 최대 10.92%를 인식함을 확인하였다.","An autonomous agent for real world should be able to recognize text in scenes. With the advancement of deep learning, various DNN models have been utilized for transformation, feature extraction, and predictions. However, the existing state-of-the art STR (Scene Text Recognition) engines do not achieve the performance required for real world applications. In this paper, we introduce a performance-improvement method through an add-on composed of an OCR (Optical Character Recognition) engine and a classifier for STR engines. On instances from IC13 and IC15 datasets which a STR engine failed to recognize, our method recognizes 10.92% of unrecognized characters."
BERT 임베딩과 선택적 OOV 복사 방법을 사용한 문서요약,2020,"['BERT', 'random masked OOV', 'morpheme-to-sentence converter', 'text summarization', 'recognition of unknown word', 'deep-learning', 'generative summarization', 'BERT', 'OOV 랜덤 마스킹', '형태소-문장 변환기', '문서요약', '미등록 단어 인식', '딥러닝', '생성요약']","문서 자동 요약은 주어진 문서로부터 주요 내용을 추출하거나 생성하는 방식으로 짧게 줄이는 작업이다. 생성 요약은 미리 생성된 워드 임베딩 정보를 사용한다. 하지만, 전문 용어와 같이 저빈도 핵심 어휘는 임베딩 사전에서 누락되는 문제가 발생한다. 문서 자동 요약에서 미등록 어휘의 출현은 요약 성능을 저하시킨다. 본 논문은 Selectively Pointing OOV(Out of Vocabulary) 모델에 BERT(Bidirectional Encoder Representations from Transformers) 형태소 임베딩, Masked OOV, 형태소-to-문장 변환기를 적용하여 미등록 어휘에 대한 선택적 복사 및 요약 성능을 높였다. 기존 연구와 달리 정확한 포인팅 정보와 선택적 복사 지시 정보를 명시적으로 제공하는 선택적 OOV 포인팅 복사 방법과 함께 BERT 임베딩과 OOV 랜덤 마스킹, 형태소-문장 변환기를 추가하였다. 제안한 OOV 모델을 통해서 자동 생성 요약을 수행한 결과 단어 재현 기반의 ROUGE-1이 54.97 나타났으며, 또한 어순 기반의 ROUGE-L이 39.23으로 향상되었다.","Automatic text summarization is a process of shortening a text document via extraction or abstraction. Abstractive text summarization involves using pre-generated word embedding information. Low-frequency but salient words such as terminologies are seldom included in dictionaries, that are so called, out-of-vocabulary (OOV) problems. OOV deteriorates the performance of the encoder-decoder model in the neural network. To address OOV words in abstractive text summarization, we propose a copy mechanism to facilitate copying new words in the target document and generating summary sentences. Different from previous studies, the proposed approach combines accurately pointing information, selective copy mechanism, embedded by BERT, randomly masking OOV, and converting sentences from morpheme. Additionally, the neural network gate model to estimate the generation probability and the loss function to optimize the entire abstraction model was applied. Experimental results demonstrate that ROUGE-1 (based on word recall) and ROUGE-L (longest used common subsequence) of the proposed encoding-decoding model have been improved at 54.97 and 39.23, respectively."
학습자의 서술어 판단에 영향을 미치는 요인 연구,2020,"['Sentence component education', 'Sentence structure education', 'Grammar textbook', 'Predicate education Misconception', 'Regression analysis', 'Deep Learning', '문장 성분 교육', '문장 구조 교육', '문법 교과서', '서술어 교육', '오개념', '회귀분석', '딥러닝']",,"Purpose：This research was to analyze the student’s predicate judgment, and based on the factors of composition of sentences that affect learners’ judgment of the predicate and their individual influence. Methods：In order to accomplish this purpose, we have selected 10 factors assumed to affect the learner’s judgment of the predicate, and created a test for determining predicates in sentences based on the system of school grammar and prior research. A survey was conducted on 302 high school sophomores. Analysis of survey results was conducted through open coding, regression analysis, and deep learning using deep neural networks(DNNs). Results：It showed that 1) learners who had misconceptions about the predicate, paying attention to the form, the product line, and the location in the sentence. 2) The influence of the 10 factors was found to be large in the order of ‘the way the predicate is formed’, ‘Whether or not a auxiliary word’ and so on 3) We found the questions that show a difference between learners’ difficulty recognition rate and the actual correct answer rate. Conclusion：It is necessary to improve predicate education in consideration of the difficulties learners face in judging predicates and the sentence composition factors that affect them."
LSTM을 활용한 고위험성 조류인플루엔자(HPAI) 확산 경로 예측,2020,"['Long Short-Term Memory', 'Call Detailed Record', 'HPAI', 'LSTM', 'CDR', '고위험성 조류인플루엔자']","이 연구는 2018년도 정부(농림축산식품부)의 재원으로 농림식품기술기획평가원 지원을 받아 수행된 연구 1) 이다. 최근 시계열 및 텍스트 마이닝에서 활발히 사용되는 모델은 딥러닝(Deep Learning) 모델 구조를 활용한 LSTM(Long Short-Term Memory models) 모델이다. LSTM 모델은 RNN의 BPTT(Backpropagation Through Time) 과정에서 발생하는 Long-Term Dependency Problem을 해결하기 위해 등장한 모델이다.LSTM 모델은 가변적인 Sequence data를 활용하여 예측하는 문제를 굉장히 잘 해결했고, 지금도 널리 사용되고 있다.본 논문 연구에서는 KT가 제공하는 CDR(Call Detailed Record) 데이터를 활용하여 바이러스와 밀접한 관계가 있을 것으로 예측되는 사람의 이동 경로를 파악하였다. 해당 사람의 경로를 활용하여 LSTM 모델을 학습시켜 이동 경로를 예측한 결과를 소개한다. 본 연구 결과를 활용하여 HPAI가 전파되는 경로를 예측하여 방역에 중점을 둘 경로 또는 지역을 선정해 HPAI 확산을 줄이는 데 이용될 수 있을 것이다.",
심층신경망 모형을 이용한 서울시 도시공원 및 녹지공간의 열섬저감효과 분석,2020,"['Urban Heat Island Effect', 'Urban Park and Green Space', 'Landsat', 'Land Surface Temperature', 'Deep Learning', '도시열섬현상', '도시공원 및 녹지', '위성영상', '지표면온도', '딥러닝']","도시화로 인한 도시열섬현상(Urban Heat Island)이 심화되면서 도시차원의 열 관리가 중요한 이슈로 다뤄지고, 도시열섬현완화 방안으로 녹지사업과 환경정책이 시행되고 있고, 도시공원 및 녹지와 열의 관계를 분석하는 다수의 연구가 수행되었다. 하지만 열이라는 특성은 다수의 요인이 복합적으로 얽혀있어 선형적 상관관계를 통한 해석에 한계가 있다. 본 연구는 변수요인들이 다양하고 데이터의 양이 방대하여 기존의 통계분석방식으로는 분석하기 어려운 분야에서 강점을 갖는 심층신경망 모형 방법론을 사용하여 여름철 서울지역의 공원 및 녹지의 열섬저감효과를 평가하는 것을 목표로 연구를 진행하였다. 이를 위해서 Landsat 8 인공위성영상을 활용하여 동시간의 광역적인 데이터를 취득하였고, ArcGis 10.7을 이용하여 서울시를 30m×30m 그리드로 격자화하여, 각 격자에 열섬저감을 측정할 수 있는 환경변수를 구축하였다. Python 3.7과 Keras를 이용하여 심층신경망 모형을 생성하여 지표면 온도와 변수 간의 관계를 분석하였다. 분석 결과, 인공신경망 모형은 높은 설명력을 가지는 것을 확인하였다. 또한 일반적인 연구 결과와 마찬가지로 인접 녹지와의 거리가 가까울수록, 공원면적이 커질수록, 공원의 식생활력도가 높을수록 지표면 온도가 낮아짐을 확인하였다. 식생활력도에 의한 냉각효과가 많이 있는 것을 확인하였고, 일부 선행연구에서 녹지에 인접할수록 0.3℃ ~ 2.3℃ 저감될 수 있는 특성이 나타나고, 공원의 크기가 크면 2℃~3℃ 저감효과가 나타난다는 결과를 보이고 있는데, 본 연구결과와 비교해 보면 도출된 효과가 과대평가되었을 가능성을 확인하였다. 본 연구의 결과는 향후 도시열섬현상 완화를 위해 새로운 도시녹지를 조성시 효과적인 녹지 구성을 위한 정보로 활용될 수 있다.","The Urban Heat Island (UHI) Effect has intensified due to urbanization and heat management at the urban level is treated as an important issue. Green space improvement projects and environmental policies are being implemented as a way to alleviate Urban Heat Islands. Several studies have been conducted to analyze the correlation between urban green areas and heat with linear regression models. However, linear regression models have limitations explaining the correlation between heat and the multitude of variables as heat is a result of a combination of non-linear factors. This study evaluated the Heat Island alleviating effects in Seoul during the summer by using a deep neural network model methodology, which has strengths in areas where it is difficult to analyze data with existing statistical analysis methods due to variable factors and a large amount of data. Wide-area data was acquired using Landsat 8. Seoul was divided into a grid (30m x 30m) and the heat island reduction variables were enter in each grid space to create a data structure that is needed for the construction of a deep neural network using ArcGIS 10.7 and Python3.7 with Keras. This deep neural network was used to analyze the correlation between land surface temperature and the variables. We confirmed that the deep neural network model has high explanatory accuracy. It was found that the cooling effect by NDVI was the greatest, and cooling effects due to the park size and green space proximity were also shown. Previous studies showed that the cooling effects related to park size was 2℃-3℃, and the proximity effect was found to lower the temperature 0.3℃-2.3℃. There is a possibility of overestimation of the results of previous studies. The results of this study can provide objective information for the justification and more effective formation of new urban green areas to alleviate the Urban Heat Island phenomenon in the future."
창의성을 통해 살펴보는 인공지능문학의 가능성과 한계: 셰익스피어 VS. AI-셰익스피어,2020,"['Artificial Intelligence Literature', 'Creativity', 'Shakespeare', 'AI-Shakespeare', 'Sonnet', 'Iambic Pentameter', 'Rhyme Scheme', '인공지능문학', '창의성', '셰익스피어', 'AI-셰익스피어', '소네트', '약강 5음보', '각운 구조']","이 논문은 창의성의 측면에서 인공지능문학이 갖는 가능성과 한계를 고찰하고자 한다. 이를 위해 창의성이 발현되는 세 가지 방식인 조합적 창의성, 탐색적 창의성, 변형적 창의성을 검토한다. 그 후에 셰익스피어의 소네트 중 잘 알려진 소네트 18번 “Shall I compare thee to a summer’s day?”와 인공지능 알고리듬이 딥러닝 방식에 의해 산출한 소네트 결과물을 분석하여 비교한다. 셰익스피어의 소네트는 창의성의 세 가지 특성을 모두 잘 보여준다. 그러나 인공지능 셰익스피어가 산출한 소네트들은 탐색적 방식과 변형적 방식을 보여준다는 점에서 소네트의 형식은 잘 포착해 냈지만, 조합적 방식에 의한 감정 혹은 의미와 가독성에서는 결함을 보임을 발견할 수 있다. AI-셰익스피어는 약강 5음보와 독특한 각운구조라는 형식은 만족시킨다는 점에서 창의성에 대한 가능성을 보여준다. 그러나 문학의 핵심적 요소인 감정과 가독성에 있어서 결함을 보인다는 한계를 갖는다. 이 사실을 통해 우리는 인공지능을 훈련하는데 있어 감정의 기능을 그만큼 더 강조해야 한다는 또 다른 결론을 얻을 수 있다.",
스펙트로그램 이미지를 이용한 CNN 기반 자동화 기계 고장 진단 기법,2020,,"소리 기반 기계 고장 진단은 기계의 음향 방출 신호에서 비정상적인 소리를 자동으로 감지하는 것이다. 수학적 모델을 사용하는 기존의 방법은 기계 시스템의 복잡성과 잡음과 같은 비선형 요인이 존재하기 때문에 기계 고장 진단이 어려웠다. 따라서 기계 고장 진단의 문제를 딥러닝 기반 이미지 분류 문제로 해결하고자 한다. 본 논문에서 스펙트로그램 이미지를 이용한 CNN 기반 자동화 기계 고장 진단 기법을 제안한다. 제안한 방법은 기계의 결함 시 발생하는 주파수상의 특징 벡터를 효과적으로 추출하기 위해 STFT를 사용하였으며, STFT에 의해 검출된 특징 벡터들은 스펙트로그램 이미지로 변환하여 CNN을 이용해 기계의 상태별로 분류한다. 그 결과는 제안한 방법은 효과적으로 결함을 탐지할 뿐만 아니라 소리 기반의 다양한 자동 진단 시스템에도 효과적으로 활용될 수 있다.",
인공지능 알고리즘을 활용한 전문(추천) 서비스 제공의 법적 성격에 관한 연구,2020,"['Specialized (Recommendation) Services Using Artificial Intelligence Algorithms', 'Robo Advisor', 'Service Contracts', 'Professional Responsibilities', 'Duty to Explain', 'Burden of Proof', 'Information Asymmetry', '인공지능 전문 추천 서비스', '서비스 계약', '전문가 책임', '설명의무', '증명책임', '정보비대칭성', '로보어드바이저']","추천시스템은 사용자를 행(row)에, 항목을 열(column)에 각각 놓은 행렬(matrix)의 비어있는 칸에 들어갈 값을 예측하는 엔지니어링이다. 다양한 행렬 계산과 통계학 방법을 동원하여 발전을 거듭해온 추천시스템은 최근 신경망(neural network)과 딥러닝(deep learning)을 등에 업고 계산 측면에서 한층 정확해졌다.이와 같은 추천시스템은 일상적인 서비스를 넘어 로보어드바이저(Robo-Advisor)와 같은 전문적 서비스로 그 영역을 확장해 갈 것으로 예상된다. 인공지능 알고리즘을 활용한 전문적 추천 서비스는 금융, 의료 및 법률 분야에서 이미 활용되고 있으며 더욱 고도화 되고 있다. 전문적 추천 서비스는 전문가의 전문적 지식과 결합되어 새로운 서비스를 개척할 것으로 예상되며 그에 따른 법적 문제도 다양할 것으로 예측된다.기존의 계약법 체계는 ‘주는 채무’인 물건의 인도를 기초로 주된 이론 구성이 이루어졌다. 하지만 현대 사회는 다양한 무형적 서비스의 제공을 목적으로 ‘하는 채무’ 기반의 서비스 제공으로 주된 급부의 대상이 옮겨지고 있으며 그 유형과 내용이 다양하고 복잡해지고 있다. 본 연구는 인공지능 기반의 전문 추천 서비스 제공 행위를 ‘서비스 계약’의 한 유형으로 파악하고 이를 토대로 관련 특징을 분석하였다.특히 전문가 책임을 기반으로 한 ‘서비스 계약’의 경우 개별 전문 서비스의 유형과 특징을 기반으로 한 피해자 구제에 초점을 맞추어야 된다는 점이 중요하다. 이러한 특수한 유형의 서비스는 정보의 비대칭성에 따른 설명의무의 중요성과 계약 관계에서 언제든지 일탈할 수 있는 계약해지권의 중요성이 대두될 수 있다. 또한 증명책임의 분배에 있어 인공지능 전문가 시스템을 활용한 전문가의 책임 범위를 증명할 때 전문가 시스템이 제공한 정보와 지식이 최적의 것이며 이의 제공에 있어 과실이나 오류가 없었다는 사실까지 증명책임의 범위를 확대해야 할 것이다.",
적층 콘볼루션 오토엔코더를 활용한 악성코드 탐지 기법,2020,"['auto encoder', 'convolution', 'malicious code detection']","악성코드는 탐지 프로그램을 피해 기기들에게 피해를 유발한다. 기존의 악성코드 탐지 기법으로 이러한 새로운 악성코드를 탐지하는데 어려움을 겪는 이유는 서명 기반의 탐지 기법을 사용하기 때문이다. 이 기법은 기존 악성코드들 은 효과적으로 탐지하지만, 새로운 악성코드에 대해서는 탐지가 어렵다. 이러한 문제점을 인식하여, 휴리스틱 기법을 추 가적으로 사용한다. 이 논문에서는 딥러닝을 활용하여 악성코드를 탐지하는 기술에 대해 소개하여 새로운 악성코드를 탐지하는 기술에 대해서 제안한다. 또한, 악성코드를 탐지한다는 것은, 기기에서 실행 가능한 파일의 개수는 무수히 많으 므로, 지도학습 방식(Supervisor Learning)으로는 분명한 한계가 존재한다. 그렇기 때문에, 준지도 학습으로 알려진 SCAE(Stacked Convolution AutoEncoder)를 활용한다, 파일들의 바이트 정보들을 추출하여, 이미지화를 진행하고, 이 이미지들을 학습을 시켜, 학습 시키지 않은 10,869개의 악성코드, 3,442개의 비악성코드를 모델에 추론한 결과 정확 도를 98.84%을 달성하였다.","Malicious codes cause damage to equipments while avoiding detection programs(vaccines). The reason why it is difficult to detect such these new malwares using the existing vaccines is that they use “signature-based” detection techniques. these techniques effectively detect already known malicious codes, however, they have problems about detecting new malicious codes. Therefore, most of vaccines have recognized these drawbacks and additionally make use of “heuristic” techniques. This paper proposes a technology to detecting unknown malicious code using deep learning. In addition, detecting malware skill using Supervisor Learning approach has a clear limitation. This is because, there are countless files that can be run on the devices. Thus, this paper utilizes Stacked Convolution AutoEncoder(SCAE) known as Semi-Supervisor Learning. To be specific, byte information of file was extracted, imaging was carried out, and these images were learned to model. Finally, Accuracy of 98.84% was achieved as a result of inferring unlearned malicious and non-malicious codes to the model."
합성곱 신경망을 이용한 전기 아크 신호 검출,2020,"['arc detection', 'convolutinoal neural network', '2-D transformation', 'data augmentation']","전기화재의 원인중의 하나는 직렬 아크이다. 최근까지 아크 신호를 검출하기 위해 다양한 기법들이 진행되고 있다. 시간 신호에 푸리에 변환, 웨이블릿 변환, 또는 통계적 특징 등을 활용하여 아크 검출을 하는 방법들이 소개되었지만, 변환 및 특징 추출은 부가적인 처리 시간이 요구되는 단점이 있다. 반면에 최근의 딥러닝 모델은 종단간 학습으로 특징 추출 과정없이 직접 원시 데이터를 활용한다. 따라서, 1-D 시간 신호를 직접 활용하여 아크를 검출하는 것이 좋은데, 인공신경망의 분류 성능이 저하되는 문제점이 있다. 본 논문에서는 연속 입력 1-D 신호를 2-D로 변환한 후에, 합성곱신경망으로 분류하는 방법을 제안한다. 실험 데이터에 적용한 결과 합성곱신경망의 사용이 인공신경망보다 약 8.6%의 아크 분류 성능을 향상시켰다. 또한 2-D 데이터의 부족을 보완하기 위해서 데이터증강을 이용하여, 14%의 분류 성능을 개선하였다.",
공연로봇을 위한 인간자세 추정방법 개선에 관한 연구,2020,"['Pose estimation', 'bottom-up', 'top-down', 'One-class Classification']","공연에 사용하는 로봇이 인간과의 상호작용하기 위한 기본 성능 중 하나는 인간의 행동을 빠르고 정확하게 파악하는 것이다. 따라서 로봇이 인간의 자세를 추정할 때 자세 인식의 정확도를 높임과 동시에 가능한 빠른 속도로 인식할 수 있어야 한다. 그러나 현재 인공지능 기술의 대표적인 방식인 딥 러닝을 사용하여 인간의 자세를 추정할 경우, 인식의 정확도와 속도라는 두 가지 성능을 동시에 만족하지 못하고 있다. 따라서 사용 목적에 따라 추론정확도가 높은 하향식 자세추정과 처리속도가 빠른 상향식 자세추정 중 하나를 선택해서 사용하는 것이 일반적이다. 본 논문에서는 앞서 언급한 두 가지 방식이 가진 장점을 모두 포함하면서 단점을 보완한 두 가지 방식을 제안한다. 첫 번째는 다중 그래픽 처리 장치를 활용해 상향식 자세추정과 물체검출을 병렬로 사용하는 방식이고, 두 번째는 상향식 자세추정과 단항분류를 융합하는 방식이다. 실험을 통해 두 가지 방식 모두 속도가 개선됨을 증명했다. 공연로봇에 이 두 가지 방식 중 하나를 사용한다면, 관객과 신뢰도 높으며 보다 빠른 상호작용을 수행할 수 있을 것으로 기대된다.",
기계학습을 활용한 부적합 열화상 이미지 판별 시스템,2020,"['Wearable Medical Device', '3D Printer', 'Inappropriate Thermal Image Detection', 'Support Vector Machine', 'Deep Learning']","본 연구에서는 기계학습을 활용하여 열화상 이미지 데이터 셋에 대한 부적합 이미지 판별 시스템을 구현하였다. 해당 시스템은 재활 환자용 맞춤형 웨어러블 의료기기 제품을 제작하는 3D프린터 설비의 이상을 미연에 방지하기 위한 이상 진단 자동화 시스템의 전처리단계에 필수적으로 활용된다. 이를 위해 먼저 FLIR (Forward Looking Infrared) 열화상 카메라를 통해 얻은 비디오 데이터를 열의 온도 정보를 포함하는 PNG (Portable Network Graphics)포맷의 이미지 형태로 추출해내는 프로세스를 개발하였고, 이 이미지 데이터셋을 기반으로 기계학습 모델인 SVM (Support Vector Machine)과 딥러닝(Deep Learning) Network를 훈련시키고 각각의 성능을 비교하였다. 연구를 위한 데이터 셋은 열이 발생되는 각종 기계설비 12개를 대상으로 수집하였다.","In this paper, we implemented an inappropriate image detection system for thermal image dataset using machine learning. This system is essential for the preprocessing stage in constructing an automatic diagnosis system for abnormal diagnosis to prevent abnormalities in 3D printer equipment for manufacturing wearable medical device products for rehabilitation patients. To conduct the research, we developed a process to extract video data from FLIR thermal imaging cameras into an image in png format that includes thermal temperature information. Based on this image dataset, we trained the machine learning models Support Vector Machine and Deep Learning Network and compared their performance. The dataset for the system collected 12 heat-generating facilitys."
눈 영상비를 이용한 운전자 상태 경고 시스템,2020,"['눈 영상비', '객체 검출', '경고 시스템', 'Eye Aspect Ratio', 'Object Detection', 'Waring System']","본 논문은 교통사고 방지를 위한 운전자의 눈 영상비를 이용한 상태 경고시스템의 설계에 대해 소개하고 있다. 제안하는 운전자 상태 경고 시스템은 눈 인식을 위한 카메라, 카메라를 통해 들어오는 정보를 처리하는 라즈베리파이, 그리고 그 정보를 통해 운전자에게 경고를 줄 때 필요한 부저와 진동기로 구성되어 있다. 운전자의 눈을 인식하기 위해서 기울기 방향성 히스토그램 기술과 딥러닝 기반의 얼굴 표지점 추정 기법을 사용하였다. 동작을 시작하면, 시스템은 눈 주변의 6개의 좌표를 통해 눈 영상비를 계산한다. 그리고 눈을 뜬 상태와 감은 상태의 눈 영상비를 각각 계산한 후 이 두 값으로부터 눈의 상태를 판단하는데 사용하는 문턱 값을 설정한다. 문턱 값이 운전자의 눈 크기에 적응하면서 설정되기 때문에 시스템은 최적의 문턱 값을 사용하여 운전자의 상태를 판단할 수 있다. 또한 낮은 조도에서도 눈을 인식할 수 있도록 회색조 변환 이미지와 LAB모델 이미지를 합성하여 사용하였다.","This paper introduces the implementation of a driver’s condition warning system using eye aspect ratio to prevent a car accident. The proposed driver’s condition warning system using eye aspect ratio consists of a camera, that is required to detect eyes, the Raspberrypie that processes information on eyes from the camera, buzzer and vibrator, that are required to warn the driver. In order to detect and recognize driver’s eyes, the histogram of oriented gradients and face landmark estimation based on deep-learning are used. Initially the system calculates the eye aspect ratio of the driver from 6 coordinates around the eye and then gets each eye aspect ratio values when the eyes are opened and closed. These two different eye aspect ratio values are used to calculate the threshold value that is necessary to determine the eye state. Because the threshold value is adaptively determined according to the driver’s eye aspect ratio, the system can use the optimal threshold value to determine the driver’s condition. In addition, the system synthesizes an input image from the gray-scaled and LAB model images to operate in low lighting conditions."
실감형 360도 미디어의 RGB 벡터 및 객체 특징정보를 이용한 대표 프레임 선정 방법,2020,"['Immersive 360° Media', 'Reference Frame', 'RGB Vector', 'Object Feature Information', 'Filtering']","실감형 360도 미디어는 기존 영상보다 고품질, 초대용량으로 영상의 크기가 크며, 다양한 렌더링 방식을 사용하여 기존방식으로 이미지 처리할 경우 영상인식 속도가 느려지는 문제가 있다. 또한, 실감형 360도 미디어의 특성상 특정 장소에서 카메라를 고정시켜 한 장면만 촬영하는 경우가 대부분이기 때문에, 모든 영상에서 특징정보를 추출할 필요가 없다. 본 논문에서는 실감형 360 미디어의 프레임 추출과정, 프레임 다운사이징, 구형 형태의 렌더링 과정을 거치고, 렌더링 과정에서 영상을 16개 프레임으로 분할 캡처하여 캡처된 프레임에서 객체 정보가 많은 중앙 부분에서 픽셀당 RGB 벡터와 딥 러닝을 이용하여 객체를 추출한 뒤, 객체 특징정보를 이용하여 대표 프레임을 선정하는 방법을 제안한다.","Immersive 360-degree media has a problem of slowing down the video recognition speed when the video is processed by the conventional method using a variety of rendering methods, and the video size becomes larger with higher quality and extra-large volume than the existing video. In addition, in most cases, only one scene is captured by fixing the camera in a specific place due to the characteristics of the immersive 360-degree media, it is not necessary to extract feature information from all scenes. In this paper, we propose a reference frame selection method for immersive 360-degree media and describe its application process to copyright protection technology. In the proposed method, three pre-processing processes such as frame extraction of immersive 360 media, frame downsizing, and spherical form rendering are performed. In the rendering process, the video is divided into 16 frames and captured. In the central part where there is much object information, an object is extracted using an RGB vector per pixel and deep learning, and a reference frame is selected using object feature information."
불법복제물 고속검색 및 Heavy Uploader 프로파일링 분석기술 연구,2020,"['Copyright protection technology', 'Pirated contents search', 'heavy uploader profiling']","인터넷 기술의 발달함에 따라 많은 콘텐츠가 생산되고 그 수요가 증가하고 있다. 이에 따라 유통되고 있는 콘텐츠수가 증가하였고, 반면에 저작권을 침해하는 불법복제물을 유포하는 건수도 증가하고 있다. 한국저작권보호원은 문자열 매칭 기반 불법복제물 추적관리시스템을 운영하고 있으며, 이를 우회하기 위해 다수의 노이즈를 삽입하므로 정확한 검색이 어려운 현실이다. 최근, 노이즈를 제거하기 위한 자연어 처리, AI 딥러닝 기술을 이용한 연구와 저작권보호를 위한 다양한 블록체인 기술이 연구되어 있으나 한계가 있다. 본 논문에서는 온라인에서 수집한 데이터에 노이즈를 제거하고, 키워드 기반 불법복제물을 검색한다. 또한, heavy uploader 대상 프로파일링 분석을 통해 동일 heavy uploader를 추정해 간다. 향후, 불법복제물 검색기술과 heavy uploader 대상 프로파일링 분석 결과를 바탕으로 차단 및 대응기술이 결합하면 저작권 피해를 최소화할 것으로 기대한다.","With the development of internet technology, a lot of content is produced, and the demand for it is increasing. Accordingly, the number of contents in circulation is increasing, while the number of distributing illegal copies that infringe on copyright is also increasing. The Korea Copyright Protection Agency operates a illegal content obstruction program based on substring matching, and it is difficult to accurately search because a large number of noises are inserted to bypass this. Recently, researches using natural language processing and AI deep learning technologies to remove noise and various blockchain technologies for copyright protection are being studied, but there are limitations. In this paper, noise is removed from data collected online, and keyword-based illegal copies are searched. In addition, the same heavy uploader is estimated through profiling analysis for heavy uploaders. In the future, it is expected that copyright damage will be minimized if the illegal copy search technology and blocking and response technology are combined based on the results of profiling analysis for heavy uploaders."
NARX 신경망 최적화를 통한 주가 예측 및 영향 요인에 관한 연구,2020,"['Deep Learning', 'Artificial Intelligence', 'Stock Prediction', 'NARX', 'MATLAB']","주식 시장은 기업 실적 및 경기 상황뿐만 아니라 정치, 사회, 자연재해 등 예기치 못한 요소들에 영향을 받는다. 이런 요소들을 고려한 정확한 예측을 위해서 다양한 기법들이 사용된다. 최근 인공지능 기술이 화두가 되면서 이를 활용한 주가 예측 시도 또한 이루어지고 있다. 본 논문은 단순히 주식 관련 데이터뿐만 아닌, 거시 경제적 지표 등을 활용한 여러 종류의 데이터를 이용하여 주가에 영향을 미치는 요소에 관한 연구를 제안한다. KOSDAQ을 대상으로 1년 치 종가, 외국인 비율, 금리, 환율 데이터를 다양하게 조합한 후에 딥러닝의 Nonlinear AutoRegressive with eXternal input (NARX) 모델을 활용한다. 이 모델을 통해 1달 치 데이터를 생성하고 각 데이터 조합을 통해 만들어진 예측값을 RMSE를 통해 실제값과 비교, 분석한다. 또한, 은닉층에서 뉴런의 수, 지연 시간을 다양하게 설정하여 RMSE를 비교한다. 분석 결과 뉴런은 10개, 지연 시간은 2로 설정하고, 데이터는 미국, 중국, 유럽, 일본 환율의 조합을 사용할 때 RMSE 0.08을 보이며 가장 낮은 오차를 기록하였다. 본 연구는 환율이 주식에 가장 영향을 많이 미친다는 점과 종가 데이터만 사용했을 때의 RMSE 값인 0.589에서 오차를 낮췄다는 점에 의의가 있다.","The stock market is affected by unexpected factors, such as politics, society, and natural disasters, as well as by corporate performance and economic conditions. In recent days, artificial intelligence has become popular, and many researchers have tried to conduct experiments with that. Our study proposes an experiment using not only stock-related data but also other various economic data. We acquired a year""s worth of data on stock prices, the percentage of foreigners, interest rates, and exchange rates, and combined them in various ways. Thus, our input data became diversified, and we put the combined input data into a nonlinear autoregressive network with exogenous inputs (NARX) model. With the input data in the NARX model, we analyze and compare them to the original data. As a result, the model exhibits a root mean square error (RMSE) of 0.08 as being the most accurate when we set 10 neurons and two delays with a combination of stock prices and exchange rates from the U.S., China, Europe, and Japan. This study is meaningful in that the exchange rate has the greatest influence on stock prices, lowering the error from RMSE 0.589 when only closing data are used."
영화 평점 자료를 이용한 추천 시스템 성능 비교 연구,2020,"['영화 평점', '추천 시스템', '협업 필터링', 'MovieLens', 'Collaborative filtering', 'movie rating', 'recommender system']","최근 전자 상업, 영화, 음원 스트리밍 서비스 등 많은 분야에서 개인화 추천을 통한 매출 증진을 위하여 추천 시스템을 활용하고 있다. 추천 시스템의 일종인 협업 필터링은 사용자의 구매 이력에 기록된 평점과 같은 상호작용을 통해서 사용자의 선호나 취향을 학습하고, 학습된 사용자의 선호 구조에 따라 항목을 추천할 수 있는 특징을 가지고 있어 활발히 이용되고 있다. 본 논문은 대표적인 협업 필터링 기반 추천 시스템 모형과 추천 시스템의 추천 성능을 평가하기 위한 평가 방법을 소개한다. 유사도, 행렬 분해, 그리고 딥러닝 기반의 알고리즘 등을 고려하였으며, 영화 평점 자료인 MovieLens 100K 및 1M을 통해 평점 기반 및 순위 목록 기반의 평가를 수행하였다.","Recommender systems have become commonplace in various fields such as e-commerce and VOD services. Collaborative filtering, one of the most popular recommender systems, learns user preferences from interactions between users and items such search, purchase and rating histories. After learning, the collaborative filtering suggests several items based on the learned user preference structure. In this paper, we introduce widely used collaborative filtering algorithms such as similarity-, matrix factorization- and deep learning-based algorithms. To compare performance of the algorithms, we introduce rating- and ranked list-based evaluation measures and conduct comparisons through MovieLens 100K and 1M datasets."
오토인코더를 이용한 데이터 비식별화,2020,"['데이터 비식별화', '정보손실', '오토인코더', '개인정보', '데이터 잡음', 'Data de-identification', 'information loss', 'autoencoder', 'privacy', 'data noise']","비식별 처리된 개인정보를 포함한 데이터를 제3자에게 제공하는 것이 본격적으로 가능하게 된 데이터법이 국회를 통과하면서 비식별 처리에 대한 중요성이 더욱 증가하고 있다. 비식별 처리는 기본적으로 데이터에서 특정 개인을 식별할 수 있는 가능성을 일정 수준 이하로 낮추는 방법인데 익명성, 다양성, 근접성 등에 기반한 모형을 사용한 마스킹과 범위 변환 방법이 널리 사용된다. 이 방법들은 이해가 쉬운 장점이 있으나 정보손실을 작게 유지하면서 데이터를 변환시키는 데에는 어려움이 있다. 마스킹, 범위화 이외에도 다양한 비식별화 방법에 대한 연구가 이루어지고 있다. 본 논문에서는 오토인코더 딥러닝을 사용하여 원자료에 대한 식별성을 낮추어 개인정보를 최대한 보호하면서 동시에 정보손실은 최소화할 수 있는 데이터 비식별화 방법을 제안한다. UCI 기계학습 데이터를 이용하여 제안 방법의 성능평가를 수행한다.","The importance of de-identification processing is increasing as the data law, which made it possible to provide data including de-identified personal information to third parties, passed the National Assembly. De-identification processing is basically a method of reducing the possibility of identifying a specific person in data below a certain level. Masking and range conversion methods based on anonymity, diversity, and proximity have been widely used. These methods have the advantage of being easy to understand, but have difficulty in converting data while keeping information loss small. In addition to masking and categorization, various methods of de-identification have been researched. In this paper, we propose a data de-identification method that can protect personal information as much as possible while minimizing the identity of the original data by using autoencoder deep learning. To verify the performance of the proposed method, we make experiments using UCI machine learning data."
인공지능(AI) 기반 산업보안 사고 프로파일링 시뮬레이터 도입 방안,2020,"['Industrial security', 'Profiling', 'Simulator', 'Artificial intelligence', 'Pandemic (Corona19) etc.']","이 연구는 산업보안 사고 대응 역량을 강화하기 위하여, 각종 산업보안 범죄이론과 범죄행동분석기법 융합 및 최신 ICT 기술을 적용한 인공지능(AI) 기반 시뮬레이터 도입 필요성과 구축 방향을 제안하는데 목적이 있다. 이에 문헌 및 사례연구를 중심으로 진행되었으며 먼저, 범죄학 분야는 기존 산업보안범죄 특성 및 수사면담이론, 피조사자 특성과 관련된 행동 촉발형 질문과 범죄행동 분석의 언어·비언어적반응에 대한 국내외 문헌과 사례를 분석하였고 ICT 분야는 대화형 인공지능, 가상현실, 딥러닝 안면인식, 햅틱 기술 등 ICT 기술을 융합 차원에서 살펴보았다. 특히, 질적 연구방법 일환인 시나리오 기법을 적용하여 실제 사례를 기초로 주요 상황을 가정하여 전개 과정을 기본조사 및 심층조사기법으로 나누어 제시하였다. 향후 이러한 방식에 기반하여 아바타로 표현되는 인공지능 피조사자를 통한 시뮬레이터 방식 프로파일링 훈련방식이 도입되어 기업 및 국가에서 활용된다면 산업보안 조사와 관련된 프로파일링 역량증대를위한 시스템 개발이 가능할 것이고, 기관별 최적의 맞춤식 역량교육이 제공될 수 있을 것이다.",
CNN 기반 공조 덕트 청소 로봇의 교차점 검출 알고리듬 개발,2020,"['Air Duct', 'Autonomous', 'Convolutional Neural Networks', 'Duct Cleaning', 'Deep Learning']","건물 내부 공기 순환을 위한 공조 덕트는 장기간 사용 시 오염물질이 내부에 쌓여 인력 또는 로봇이 투입되어 청소가 주기적으로 수행된다. 청소는 작업시간과 인건비 문제를 해결하기 위해 최근 원격 조정으로 로봇을 작동시키는 방법이 사용되고 있다. 하지만 완전 자동화가 아니라 인력 의존적이며 청소 시간 단축에도 한계가 있다. 본 연구는 공조덕트 청소 로봇 자율 주행을 위해 교차점 검출 알고리듬 개발에 대한 것이다. 자율 주행은 청소 로봇에 장착된 카메라 영상에서 교차점 검출 알고리듬을 통해 추출된 점과 중심점 사이의 거리 및 각도를 계산하여 로봇을 제어하도록 구성된다. 교차점 검출을 위한 데이터는 3D CAD 프로그램을 이용한 공조 덕트 내부 이미지를 Python을 이용해 교차점 좌표 및 두 경계선 각도를 추출하여 생성했다. 검출 알고리듬은 딥러닝 중 CNN 모델이 학습에 사용됐으며 학습 모델은 입력이미지에서 교차점 정보를 추출하며 학습 모델 정확도는 면적과 거리를 이용해 판단했다. 알고리듬 검증을 위해 청소로봇을 제작했으며 로봇은 몸체, Raspberry Pi, 카메라 및 초음파 센서를 포함한 제어부, 모터와 바퀴를 포함한 구동부로 구성된다. 알고리듬을 탑재한 로봇 청소기 주행 영상을 통해 알고리듬을 검증했다. 향후 공조 덕트뿐만 아니라 에스컬레이터 등 다양한 환경에서 적용 가능할 것으로 기대된다.","Air ducts installed for ventilation inside buildings accumulate contaminants during their service life. Robots are installed to clean the air duct at low cost, but they are still not fully automated and depend on manpower. In this study, an intersection detection algorithm for autonomous driving was applied to an air duct cleaning robot. Autonomous driving of the robot was achieved by calculating the distance and angle between the extracted point and the center point through the intersection detection algorithm from the camera image mounted on the robot. The training data consisted of CAD images of the duct interior as well as the cross-point coordinates and angles between the two boundary lines. The deep learning-based CNN model was applied as a detection algorithm. For training, the cross-point coordinates were obtained from CAD images. The accuracy was determined based on the differences in the actual and predicted areas and distances. A cleaning robot prototype was designed, consisting of a frame, a Raspberry Pi computer, a control unit and a drive unit. The algorithm was validated by video imagery of the robot in operation. The algorithm can be applied to vehicles operating in similar environments."
뇌종양 영상의 현재와 미래,2020,"['Brain Neoplasm', 'Magnetic Resonance Imaging', 'Diffusion', 'Perfusion', 'Machine Learning']","뇌종양의 진단 및 치료 반응 평가의 기본이 되는 영상기법은 해부학적 영상이다. 현재 임상에서 사용 가능한 영상기법들 중 확산 강조 영상 및 관류 영상이 추가적인 정보를 제공하고있다. 최근에는 종양의 유전체 변이와 이질성 평가가 중요해지면서 라디오믹스와 딥러닝을이용한 영상분석기법의 임상 응용이 기대되고 있다. 본 종설에서는 뇌종양 영상 임상 적용에서 여전히 중요한 해부학적 영상을 중심으로 한 자기공명영상 촬영 권고안, 최신 영상기법중 확산 강조 영상 및 관류 영상의 기본 원리, 병태생리학적 배경 및 임상응용, 마지막으로 최근 컴퓨터 기술의 발전으로 많이 연구되고 있는 라디오믹스와 딥러닝의 뇌종양에서의 향후활용가치에 대해 기술하고자 한다.","Anatomical imaging is the basis of the diagnosis and treatment response assessment of brain tumors. Among the existing imaging techniques currently available in clinical practice, diffusion- weighted imaging and perfusion imaging provide additional information. Recently, with the increasing importance of evaluation of the genomic variation and heterogeneity of tumors, clinical application of imaging techniques using radiomics and deep learning is expected. In this review, we will describe recommendations for magnetic resonance imaging protocols focusing on anatomical images that are still important in the clinical application of brain tumor imaging, and the basic principles of diffusion-weighted imaging and perfusion imaging among the advanced imaging techniques, as well as their pathophysiological background and clinical application. Finally, we will review the future perspectives of radiomics and deep learning applications in brain tumor imaging, which have been studied to a great extent due to the development of computer technology."
SNS 사진에 나타난 사용자 선호 기반의 장소추천,2020,"['추천시스템', '위치기반 소셜 네트워크', '사진 기반 사용자 선호 분석', '사용자-ROA 평점 매트릭스', 'Recommender System', 'Location Based SNS', 'Photo-Based User Preference Analysis', 'User-Roa Rating Matrix']","최근 모바일 기반의 커뮤니케이션과 위치정보 획득 기술의 발달로, 장소에 기반한 다양한 정보들이 취합되면서, 위치에 기반한 예측이나 추천 알고리즘도 빠르게 발전하고 있다. 위치기반 소셜 네트워크(location-based social network)의 대표적 사례 중 하나인 플리커(Flickr) 데이터는 위치기반 추천시스템에서 다양하게 활용되어왔다. 그러나 사진을 공유하는 social networking service(SNS)임에도 불구하고, 사진 속성을 분석하여 사용자 선호를 파악하고 이를 기반으로 한 추천시스템에 관한 연구는 미미하였다. 본 연구에서는 SNS 사용자가 게시한 사진 속성을 기반으로 사용자의 선호도를 분석하고, 이를 가장 잘 반영하는 추천 알고리즘을 찾고자 하였다. 한국을 방문한 관광객이 게시한 플리커 사진을 딥러닝 모델로 훈련하여 74개의 카테고리로 분류하였다. 서울을 대상으로 57개의 주요 region of attraction(ROA)를 도출하였고, 사진 기반 사용자 선호 분석 결과를 반영한 사용자-ROA 평점 매트릭스를 구축하였다. 이후 사용자-ROA 평점 매트릭스 구축방법과 사용자 그룹핑 적용 여부에 따른 4가지 모델을 구축하였고, 최종적으로 모델의 성능을 비교하였다. 본 연구는 사용자가 게시한 사진에 나타난 선호를 어떤 방식으로 추천 시스템에 반영할 수 있는지를 체계적으로 연구하였다는 점에 의의가 있다.","With the recent development of mobile-based communication technology and location information acquisition, a variety of location-based data has been collected, enabling the rapid development of algorithms making recommendations or predictions based on location. Flickr, a representative example of a location-based social network, has provided data that have been used in various studies on location-based recommender systems. However, Despite being a social media that shares photos, there is little work on the analysis of user preference based on photo attributes and the development of a recommendation system based on this analysis. This paper aims to analyze user preferences based on the attributes of each user""s photos, and to find a recommendation algorithm that best reflects them. a deep-learning model was trained to classify Flickr photos posted by tourists in Korea into 74 different categories. We drew 57 key ROA in Seoul and built a user-ROA rating matrix that reflects the user preferences shown in the photos. Then, We created four models that differ in the user-ROA rating matrix building method and whether or not the user grouping was applied. Finally, the performances of the models were compared. This paper is a systematic study of how preferences shown in user-posted photos can be reflected in a recommender system."
AI 도덕성 신화와 그 실제: 기계의 인간 도덕 능력 모델링 가능성과 한계,2020,"['인공지능', '인공 도덕행위자', '뇌신경과학', '도덕판단', '도덕정서', 'Artificial Intelligent', 'Artificial Moral Agent', 'Neuroscience', 'Moral Judgement', 'Moral Emotion']","인공 도덕행위자(AMA) 설계 문제는 법적, 사회적 규범을 준수하는 도덕적 행위 주체로서의 AI 실현 가능성과 직결된다. AMA 구현을 위해 프로그래밍 설계 능력 확보보다 선결되어야 할 문제는 도덕성에 대한 철학적, 심리학적, 뇌신경과학적 이해이다. 도덕적 판단은 고차원 수준의 정신 능력을 요구하기에 기억, 논리 추론과 같은 인간의 인지 능력을 재현하는 것만으로 AI의 도덕적 의사결정 능력을 확보했다고 단정하기 어렵다. AI 도덕성은 인간의 도덕성, 도덕판단을 모델로하기에 도덕적 행위자로서 AMA 구현을 위해 도덕적 경험의 축적, 도덕적 감정의 구현, 도덕성이 지닌 복잡성 확보, 도덕성의 관계성 측면을 모두 고려할 필요가 있다. AI 신화를 극복하고 이상적인 도덕적 행위자로서 AMA 제작을 위해 인류에게 남겨진 최대 과제는 ‘어떠한’ 도덕성을 구현해야 하는가에 대한 깊은 천착이다. 이를 바탕으로 도덕적 인격을 갖춘 컴퓨터가 딥러닝에 의해 접근 가능한가의 기술적 문제에 대한 고려가 필요하다. 도덕적인 로봇은 행복과 같은 인간의 뿌리 깊은 감정적 목표뿐만 아니라 도덕적 판단을 둘러싼 도덕적 인지, 정서, 의지, 직관, 통찰, 실천력 등을 갖출 것이 요구된다. AMA의 실현을 위해 컴퓨터공학자, 윤리학자, 뇌신경과학자의 도덕성 이해가 상호 참조되어야 한다. AI를 통해 인간만큼이나 다양한 도덕적 인격을 창출해 낼 것인지 아니면 인류가 추구해야 할 최상의 도덕적 인간상을 구현할 것인가의 문제 또한 우리에게 남아있다. AI 도덕성은 신경 신화와 같이 AI 신화를 만들어 내며 인류에게 도덕성의 접근에 있어 보다 도덕철학적이고 윤리학적인 동시에 뇌신경과학적, 신경윤리학적인 탐구를 요구한다. 이는 인공지능 도덕행위자 제작 기술자들에게 도덕적 의사결정에 있어 감정 컴퓨팅, 감성 지능의 역할을 설명하는 자료를 제공하기 위해서는 상호이타주의와 공정성 같은 특정한 도덕 원칙에 대한 도덕철학, 윤리학의 고려뿐만 아니라 도덕심리학, 신경윤리학에서 얻은 통찰력을 결합해야 할 것을 요청한다.","The issue of Artificial Moral Agent(AMA) design is directly related to the feasibility of AI as a moral agent that complies with legal and social norms. The problem that should be pre-determined rather than securing programming design ability for AMA implementation is the philosophical, psychological and neurological understanding of morality. Since moral judgment requires a high level of mental ability, it is hard to conclude that AI's moral decision-making ability has been secured just by reproducing human cognitive abilities such as memory and logic reasoning. AI morality is modeled on human morality and moral judgment, so as a moral agent, it is necessary to consider all aspects of the morality, including the accumulation of moral experience, moral emotion, the securing of the complexity of morality, and the relationship. The biggest task left for mankind to overcome AI myths and produce AMA as an ideal moral agent is a deep sarcasm about what kind of morality should be implemented. Based on this, it is necessary to consider the technical question of whether computers with this moral character are accessible by deep learning. Moral robots are required not only to have deep-rooted human emotional goals such as happiness, but also to have moral awareness, emotion, will, intuition, insight and practical skills surrounding moral judgment. For the realization of AMA, an understanding of the morality of computer engineer, ethicist and neuroscience should be cross-referenced. The question remains whether AI will create as diverse moral character as humans or realize the best moral human image that mankind should pursue. AI morality creates AI myths like neuromyths and demands more moral philosophy and ethical exploration of human beings in their approach to morality, as well as neuropsychological and neurological exploration. This calls for combining insights from moral psychology and neuroscience as well as moral philosophy and ethical considerations of certain moral principles, such as reciprocity and fairness, in order to provide engineers with data explaining the role of emotional computing and emotional intelligence in moral decision making."
전산학적 스토리 자동 생성 연구에 대한 고찰,2020,"['Computational Narrative Generation', 'Story Authoring', 'Authoring Support', 'Narratology']",소설부터 영화 시나리오에 이르기까지 다양한 장르의 스토리 자동 생성(story generation)이 큰 주목을 받고 있다. 현재 일기예보나 스포츠 기사와 같은 정보 전달을 위한 텍스트는 점점 로봇에 의해 대체되고 있다. 하지만 스토리는 인간의 상상력과 창의성이 가장 잘 발현되는 고차원적 인지 영역이기 때문에 스토리 자동 생성은 인공지능과 자연어생성(Natural Language Generation) 분야에서 매우 도전적인 연구 분야이다. 이에 본 논문은 컴퓨터의 스토리 창작의 기술적 변화를 살펴보는 것을 목적으로 하였다. 이를 위해 먼저 스토리 자동 생성에 이론적 토대를 제공한 중요한 서사(narrative)이론을 기술하고 서사 이론에 근거한 스토리 저작 도구의 원리와 기능을 소개하였다. 그리고 현재 딥러닝(deep learning) 기술을 이용한 스토리 자동 생성의 구체적 연구 사례를 통해 과거의 저작 도구와의 차이점을 제시하고 컴퓨터의 스토리 창작이 갖는 철학적 쟁점을 고찰하였다.,"The computational narrative generation studies have got attention in various genres and media from novels to movie scripts. Recently, robots are replacing humans in writing informative and straightforward texts. However, generating narratives is still challenging since it requires high-level perceptions, including imagination and creativity. This study aims to review technological advances in the computational narrative generation. We first introduce narratology theories that are foundations of this research area. Then, we show the existing narrative generation tools, which are based on narratology theories. Also, there are generation tools based on deep learning techniques. We compare them with conventional methods and present their limitations. Finally, we suggest further research directions in the computational narrative generation."
맞춤형 여행 콘텐츠 개발을 위한 OCR 기법을 활용한 영화 속 촬영지 정보 추출 방안 제시,2020,"['Customized Travel Content', 'Movie-Induced Tourism', 'Filming Location', 'OCR', 'Image Preprocessing', 'OpenCV', '맞춤형 여행 콘텐츠', '영화 관광', '영화 촬영지', 'OCR', '이미지 전처리', 'OpenCV']","목적사회 전반적으로 퍼진 개인의 취향에 대해 존중하는 분위기는 소비 트렌드를 바꾸었다. 그에 따라 여행 산업에서도 소비자 개인의 취향을 반영하는 맞춤형 여행이 새로운 트렌드로 주목받고 있다. 특히 여행 산업 분야 중 하나인 ‘영화 관광’에 대한 관심이 커지고 있음에 주목하였다. 영화를 시청하며 발생하는 개인의 여행 동기를 맞춤형 여행 제안으로 충족시키고자 하며, 이는 ‘영화 관광 산업’의 지속적 발전의 촉진제가 될 것으로 기대한다.설계/방법론/접근본 연구에서는 시청자가 실제로 방문하고 싶은 영화 속 촬영지 정보를 ‘OCR’을 통해 추출, 제안하는 방법론을 구현하였다. 먼저, 실시간 이미지 프로세싱 라이브러리인 ‘OpenCV’를 활용하여 사용자가 선택한 영화속 장면을 추출 받는다. 또한, 딥러닝 기반의 텍스트 영역 탐지모델인 ‘EAST 모델’을 활용하여 해당 장면 이미지에서 문자가 위치한 곳을 탐지하여 검출한다. 검출한 이미지는 ‘OpenCV 내장 함수’를 사용해 전처리하여 인식의 정확도를 높인다. 마지막으로 광학 문자 인식 엔진인 ‘Tesseract’를 사용하여 이미지속 문자를 인식 가능한 텍스트로 변환한 후, ‘Google Map API’를 통해 실제 위치 정보를 반환한다.의의본 연구는 기존의 영화 관광에서 나아가, 4차 산업 기술을 활용한 개인 맞춤 관광 콘텐츠를 제공해준다는 점에서 큰 의의가 있다. 이는 앞으로 여행사와 함께 영화 관광 패키지 상품 개발에 활용될 수 있다. 또한 국내에서 해외로의 유입뿐만 아니라, 해외에서 국내로의 유입에 활용될 가능성 역시 내포하고 있다.",
Airbnb 숙소 유형에 따른 호스트의 자기소개 텍스트가 공유성과에 미치는 영향,2020,"['공유경제', '자기소개', '특성추출', '텍스트마이닝', '비지도학습', 'Sharing economy', 'Self-presentation', 'Aspect extraction', 'Text-mining', 'Unsupervised learning']","최근 빠르게 성장하고 있는 숙박 공유경제 시장에서 품질에 대한 불확실성은 사용자의 만족도에 영향을 미치는 위험 요소지만, 이는 시설 제공자가 공개하는 정보를 통해 완화될 수 있다. 그 중 시설 제공자의 본인에 대한 자기소개는 사용자와의 정서적 교류를 통해 심리적 거리를 제거함으로써 공유 성과에 긍정적 영향을 미친다. 본 연구는 대표적인 숙박 공유경제 플랫폼인 Airbnb에서 호스트의 자기소개가 포함하는 정보의 종류에 따라 공유성과에 미치는 영향을 분석하고, Airbnb의 숙소 유형에 따라 차이를 분석하였다. 이를 위해 호스트가 공개하는 자기소개 텍스트를 문장별로 분리하고 비지도 학습기반의 딥러닝 방법인 Attention-Based Aspect Extraction 방법을 활용하여 각 문장이 포함하는 의미를 추출하였다. 추출된 의미를 토대로 자기소개 텍스트가 포함하는 의미가 공유성과에 미치는 영향과 숙소 유형에 따른 교호작용 효과를 분석하였다. 연구결과, 숙소 유형별로 호스트의 특정 성향이 공유성과에 긍정적인 영향을 미치는 것을 확인하였고, 이를 통해 숙소 유형에 따라 공유성과를 극대화하기 위한 마케팅 전략에 대한 실증적인 함의를 제공한다.","In accommodation sharing economy, customers take a risk of uncertainty about product quality, which is an important factor affecting users' satisfaction. This risk can be lowered by the information disclosed by the facility provider. Self-presentation of the hosts can make a positive effect on listing performance by eliminating psychological distance through emotional interaction with users. This paper analyzed the self-presentation text provided by Airbnb hosts and found key aspects in the text. In order to extract the aspects from the text, host descriptions were separated into sentences and applied the Attention-Based Aspect Extraction method, an unsupervised neural attention model. Then, we investigated the relationship between aspects in the host description and the listing performance via linear regression models. In order to compare their impact between the three facility types(Entire home/apt, Private rooms, and Shared rooms), the interaction effects between the facility types and the aspect summaries were included in the model. We found that specific aspects had positive effects on the performance for each facility type, and provided implication on the marketing strategy to maximize the performance of the shared economy."
DeNERT: DQN과 BERT를 이용한 개체명 인식 모델,2020,"['Natural language processing', 'Named entity recognition', 'Reinforcement learning', 'BERT', 'DQN', 'Language model', '자연어처리', '개체명 인식', '강화학습', '언어모델']","본 논문에서는 새로운 구조의 개체명 인식 DeNERT 모델을 제안한다. 최근 자연어처리 분야는 방대한 양의 말뭉치로 사전 학습된 언어 표현 모델을 활용하는 연구가 활발하다. 특히 자연어처리 분야 중 하나인 개체명인식은 대부분 지도학습 방식을 사용하는데, 충분히 많은 양의 학습 데이터 세트와 학습 연산량이 필요하다는 단점이 있다. 강화학습은 초기 데이터 없이 시행착오 경험을 통해 학습하는 방식으로 다른 기계학습 방법론보다 조금 더 사람이 학습하는 과정에 가까운 알고리즘으로 아직 자연어처리 분야에는 많이 적용되지 않은 분야이다. 아타리 게임이나 알파고 등 시뮬레이션 가능한 게임 환경에서 많이 사용된다. BERT는 대량의 말뭉치와 연산량으로 학습된 구글에서 개발한 범용 언어 모델이다. 최근 자연어 처리 연구 분야에서 높은 성능을 보이고 있는 언어 모델이며 많은 자연어처리 하위분야에서도 높은 정확도를 나타낸다. 본 논문에서는 이러한 DQN, BERT 두가지 딥러닝 모델을 이용한 새로운 구조의 개체명 인식 DeNERT 모델을 제안한다. 제안하는 모델은 범용 언어 모델의 장점인 언어 표현력을 기반으로 강화학습 모델의 학습 환경을 만드는 방법으로 학습된다. 이러한 방식으로 학습된 DeNERT 모델은 적은 양의 학습 데이터세트로 더욱 빠른 추론시간과 높은 성능을 갖는 모델이다. 마지막으로 제안하는 모델의 개체명 인식 성능평가를 위해 실험을 통해서 검증한다.","In this paper, we propose a new structured entity recognition DeNERT model. Recently, the field of natural language processing has been actively researched using pre-trained language representation models with a large amount of corpus. In particular, the named entity recognition, which is one of the fields of natural language processing, uses a supervised learning method, which requires a large amount of training dataset and computation. Reinforcement learning is a method that learns through trial and error experience without initial data and is closer to the process of human learning than other machine learning methodologies and is not much applied to the field of natural language processing yet. It is often used in simulation environments such as Atari games and AlphaGo. BERT is a general-purpose language model developed by Google that is pre-trained on large corpus and computational quantities. Recently, it is a language model that shows high performance in the field of natural language processing research and shows high accuracy in many downstream tasks of natural language processing. In this paper, we propose a new named entity recognition DeNERT model using two deep learning models, DQN and BERT. The proposed model is trained by creating a learning environment of reinforcement learning model based on language expression which is the advantage of the general language model. The DeNERT model trained in this way is a faster inference time and higher performance model with a small amount of training dataset. Also, we validate the performance of our model’s named entity recognition performance through experiments."
Transformer 네트워크를 이용한 음성신호 변환,2020,"['voice conversion', 'transformer network', 'signal-to-signal conversion', '음성 변환', '트랜스포머 네트워크', '신호 대 신호 변환']","음성 변환은 다양한 음성 처리 응용에 적용될 수 있으며, 음성 인식을 위한 학습 데이터 증강에도 중요한 역할을 할 수 있다. 기존의 방법은 음성 합성을 이용하여 음성 변환을 수행하는 구조를 사용하여 멜 필터뱅크가 중요한 파라미터로 활용된다. 멜 필터뱅크는 뉴럴 네트워크 학습의 편리성 및 빠른 연산 속도를 제공하지만, 자연스러운 음성파형을 생성하기 위해서는 보코더를 필요로 한다. 또한, 이 방법은 음성 인식을 위한 다양한 데이터를 얻는데 효과적이지 않다. 이 문제를 해결하기 위해 본 논문은 원형 스펙트럼을 사용하여 음성 신호 자체의 변환을 시도하였고, 어텐션 메커니즘으로 스펙트럼 성분 사이의 관계를 효율적으로 찾아내어 변환을 위한 자질을 학습할 수 있는 transformer 네트워크 기반 딥러닝 구조를 제안하였다. 영어 숫자로 구성된 TIDIGITS 데이터를 사용하여 개별 숫자변환 모델을 학습하였고, 연속 숫자 음성 변환 디코더를 통한 결과를 평가하였다. 30명의 청취 평가자를 모집하여 변환된 음성의 자연성과 유사성에 대해 평가를 진행하였고, 자연성 3.52±0.22 및 유사성 3.89±0.19 품질의 성능을 얻었다.","Voice conversion can be applied to various voice processing applications. It can also play an important role in data augmentation for speech recognition. The conventional method uses the architecture of voice conversion with speech synthesis, with Mel filter bank as the main parameter. Mel filter bank is well-suited for quick computation of neural networks but cannot be converted into a high-quality waveform without the aid of a vocoder. Further, it is not effective in terms of obtaining data for speech recognition. In this paper, we focus on performing voice-to-voice conversion using only the raw spectrum. We propose a deep learning model based on the transformer network, which quickly learns the voice conversion properties using an attention mechanism between source and target spectral components. The experiments were performed on TIDIGITS data, a series of numbers spoken by an English speaker. The conversion voices were evaluated for naturalness and similarity using mean opinion score (MOS) obtained from 30 participants. Our final results yielded 3.52±0.22 for naturalness and 3.89±0.19 for similarity."
스크린무용예술 관련 국내 연구동향을 통해 바라본 스크린무용 예술의 방향성,2020,"['스크린무용예술', '학위논문', '학술지논문', '연구동향', '방향성', 'screen dance art', 'thesis', 'academic journal', 'research trend', 'direction']","본 연구는 스크린무용예술 관련 국내 연구동향을 통해 스크린무용예술의 방향성을 제안하는데 연구의 목적이 있 다. 이에 한국교육학술정보원(riss)과 한국학술정보원(kiss) 및 DBpia에서 2000년부터 2018년까지의 국내 학위논 문 및 학술지논문을 분석대상으로 선정, 발표연도 및 발표형태, 학문분야, 연구방법, 연구주제별로 동향을 분석한 후 스크린무용예술의 방향성을 제안하였다. 그 결과, 첫째, 2000년부터 급속히 발전되는 사회현상으로 스크린무용 예술 연구가 증가하였으며, 무용학분야에서 주로 진행되었고, 그 중 문헌연구방법과 사례연구방법이 주로 적용되 었다. 또한 융합적 표현 관련 연구주제가 많았는데 움직임 표현과 게임을 통한 여가적 접근 등 무용예술의 다양성 과 확장성이 시도됨을 확인하였다. 둘째, 스크린무용예술의 방향성은 VR 접목을 통해 공연의 장기화는 물론 현장 성과 생동성, 몰입감 및 접근성을 강화해야 한다. 또한 스크린무용예술 창작과정에서 동작을 데이터화하고 컴퓨터 가 스스로 인식, 학습하여 새로운 동작을 만들어낼 수 있도록 딥러닝을 적용함으로써 안무가의 창작력을 돕는데 활용해야 한다. 마지막으로 다양한 스마트폰 앱 구축을 통해 휴대할 수 있는 홀로그램 등의 콘텐츠를 개발해 장소 에 구애받지 않는 작품 창작과 시·공간을 구애받지 않는 관람 등 창작과 관람 문화의 다양화를 시도해야 한다. 이 러한 노력은 새로운 스크린무용예술을 구축하고 창작, 유통, 향유하는데 있어 기초자료로 제공될 것으로 기대한다.","The purpose of this study is to suggest the direction of screen dance art through domestic research trends related to screen dance art. For this reason, the domestic academic dissertations and academic journals from 2000 to 2018 were selected for analysis by the Korea Educational Academic Information Service (riss), the Korean Academic Information Service (kiss), and DBpia. After analyzing trends by topic, the direction of screen dance art was suggested. As a result, first, research on screen dance arts has increased due to rapidly developing social phe-nomena since 2000, and it has been mainly conducted in the field of dance, among which the literature research method and the case study method are mainly applied. In addition, there were many research topics related to convergence expression, and it was confirmed that diversity and expandability of dance arts such as movement expression and leisure approaches through games were attempted. Second, the direction of screen dance art should be strengthened in the field of performance, vitality, immersion and accessibility as well as long-term performance through VR grafting. In addition, it should be used to help the choreographer's creative power by applying deep learning to data movement in the creative process of screen dance art, and allowing computers to recognize and learn for themselves to create new movements. Lastly, through the construction of various smartphone apps, contents such as holograms that can be carried out should be developed to try to diversify creation and viewing culture, such as creating works regardless of location and viewing regardless of time and space. It is expected that these efforts will be provided as a basic material in establishing, creating, and enjoying new screen dance arts."
얼굴 인식 기술을 활용한 실감형 인터랙티브 콘텐츠의 구현 - (르네마그리트 특별전) AR포토존을 중심으로,2020,"['Face Recognition', 'Immersive Interactive Content', 'Image Processing', '얼굴 인식', '실감형 인터랙티브 콘텐츠', '영상처리']","딥러닝의 발전에 따른 생체 인식 기술은 새로운 형태의 콘텐츠를 생산해 낼 수 있게 하였다. 특히 얼굴 인식 기술의 경우 편의성·비강제성 면에서 몰입감을 줄 수 있지만, 대부분의 상용 콘텐츠는 어플리케이션 영역에만 그치는 한계성을 가진다. 따라서 본 논문은 이를 극복하여 실시간 비디오 피드를 기반으로 얼굴 인식 기술을 활용할 수 있는 실감형 인터렉티브 콘텐츠를 구현하고자 한다. 고해상도의 그래픽을 위해 Unity 엔진을 사용하여 제작되었고 그 과정에서 얼굴인식 성능 저하와 프레임 드랍(Frame Drop) 현상이 발생하여 추가적으로 Dlib 툴킷을 사용하고, 얼굴인식 이미지의 해상도를 조절함으로 해당 문제를 해결했다.","Biometric technology with the advance of deep learning enabled the new types of content. Especially, face recognition can provide immersion in terms of convenience and non-compulsiveness, but most commercial content has limitations that are limited to application areas. In this paper, we attempted to overcome these limitations, implement content that can utilize face recognition technology based on realtime video feed. We used Unity engine for high quality graphics, but performance degradation and frame drop occurred. To solve them, we augmented Dlib toolkit and adjusted the resolution image."
성범죄 사건에 대한 포털 뉴스 기사 및 사용자 의견 데이터 분석: n번방 사건을 중심으로,2020,"['n번방', '성범죄', '빅데이터', 'word2vec', '댓글 분석', 'Nth room sex crime case', 'Big Data', 'word2vec']","인터넷과 휴대용 디지털 기기의 기술이 고도화됨에 따라 네티즌들은 익명성 아래 자유롭게 개인 의견을 온라인상에 표출하고 있다. 이러한 현상은 코로나 확산으로 인한 비대면 활동 증가에 따라 더욱 강화되었고, 이제 기존 오프라인에서 이뤄지던 국민 여론의 확산은 온라인으로 그 무대가 바뀌었다고 할 수 있다.이러한 이유로 국민 여론은 그 어느 때보다 온라인에서 빠르게 변화하고 있지만, 경찰의 수사와 정부의 대응 속도는 이를 쫓아가지 못하고 있다. 이에 2016년 ‘강남역 살인’, 2018년 ‘불편한 진실’ 혜화역 시위 등 온라인에서 먼저 대중의 불만이 표출된 후 오프라인의 집단행동으로 이어졌다. 즉, 온라인에서의 여론 추이의 분석과 대응이 중요하다고 할 수 있다.특히 ‘n번방 사건’은 기존과는 다른 수법의 디지털 성범죄로 국민의 여론이 급격하게 형성되고 변화했던 사건이다.이에 본 연구는 ‘n번방 사건’ 관련 약 128만 개의 인터넷 뉴스 댓글을 웹 크롤링으로 수집하고 인공신경망 딥러닝 기술인 word2vec을 활용하여 국민 여론을 분석하였다. 분석 결과, 온라인 댓글이 국민 여론을 형성하고, 정부는 이에 응답하는 형태로 성범죄 사건의 수사 방향성 결정 및 국민의 법 감정을 반영하는 법을 제정하는 등의 과정이 이뤄지는 것을 확인할 수 있었다. 결론적으로 ‘국민 여론’은 신뢰받는 경찰로 거듭나기 위해 반드시 고려해야 하는 매우 중요한 요소로 자리매김하고 있음을 알 수 있었다.",
다중 스태킹을 가진 새로운 앙상블 학습 기법,2020,"['자동분류', '기계학습', '앙상블', '스태킹', 'Classification', 'Ensemble', 'Machine Learning', 'Stacking']","기계학습(machine learning)이란 주어진 데이터에 대한 일반화 과정으로부터 특정 문제를 해결할 수 있는 모델(model) 생성 기술을 의미한다. 우수한 성능의 모델을 생성하기 위해서는 양질의 학습데이터와 일반화 과정을 위한 학습 알고리즘이 준비되어야 한다. 성능 개선을 위한 한 가지 방법으로서 앙상블(Ensemble) 기법은 단일 모델(single model)을 생성하기보다 다중모델을 생성하며, 이는 배깅(Bagging), 부스팅(Boosting), 스태킹(Stacking) 학습 기법을 포함한다. 본 논문은 기존 스태킹 기법을 개선한 다중 스태킹 앙상블(Multiple Stacking Ensemble) 학습기법을 제안한다. 다중 스태킹 앙상블 기법의 학습 구조는 딥러닝 구조와 유사하고 각 레이어가 스태킹 모델의 조합으로 구성되며 계층의 수를 증가시켜 각 계층의 오분류율을 최소화하여 성능을 개선한다. 4가지 유형의 데이터셋을 이용한 실험을 통해 제안 기법이 기존 기법에 비해 분류 성능이 우수함을 보인다.","Machine learning refers to a model generation technique that can solve specific problems from the generalization process for given data. In order to generate a high performance model, high quality training data and learning algorithms for generalization process should be prepared. As one way of improving the performance of model to be learned, the Ensemble technique generates multiple models rather than a single model, which includes bagging, boosting, and stacking learning techniques. This paper proposes a new Ensemble technique with multiple stacking that outperforms the conventional stacking technique. The learning structure of multiple stacking ensemble technique is similar to the structure of deep learning, in which each layer is composed of a combination of stacking models, and the number of layers get increased so as to minimize the misclassification rate of each layer. Through experiments using four types of datasets, we have showed that the proposed method outperforms the exiting ones."
시계열 분석을 이용한 진동만의 용존산소량 예측,2020,"['Oxygen depleted water', 'Prediction', 'A.I. (Artificial Intelligence)', 'ARIMA', 'LSTM', '빈산소 수괴', '예측', '인공지능', 'ARIMA', 'LSTM']","본 연구에서는 인공지능기법을 이용하여 진동만의 용존산소량 예측을 하였다. 관측자료에 존재하는 결측 구간을 보간하기 위해 양방향재귀신경망(BRITS, Bidirectional Recurrent Imputation for Time Series) 딥러닝 알고리즘을 이용하였고, 대표적 시계열 예측 선형모델인 ARIMA(Auto-Regressive Integrated Moving Average)과 비선형모델 중 가장 많이 이용되고 있는 LSTM(Long Short-Term Memory) 모델을 이용하여 진동만의 용존산소량을 예측하고 그 성능을 평가했다. 결측 구간 보정 실험은 표층에서 높은 정확도로 보정이 가능했으나, 저층에서는 그 정확도가 낮았으며, 중층에서는 실험조건에 따라 정확도가 불안정하게 나타났다. 실험조건에 따라 정확도가 불안정하게 나타났다. 결과로부터 LSTM 모델이 중층과 저층에서 ARIMA 모델보다 우세한 정확도를 보였으나, 표층에서는 ARIMA모델의 정확도가 약간 높은 것으로 나타났다.","In this study, we used artificial intelligence algorithms for the prediction of dissolved oxygen in Jindong Bay. To determine missing values in the observational data, we used the Bidirectional Recurrent Imputation for Time Series (BRITS) deep learning algorithm, Auto-Regressive Integrated Moving Average (ARIMA), a widely used time series analysis method, and the Long Short-Term Memory (LSTM) deep learning method were used to predict the dissolved oxygen. We also compared accuracy of ARIMA and LSTM. The missing values were determined with high accuracy by BRITS in the surface layer; however, the accuracy was low in the lower layers. The accuracy of BRITS was unstable due to the experimental conditions in the middle layer. In the middle and bottom layers, the LSTM model showed higher accuracy than the ARIMA model, whereas the ARIMA model showed superior performance in the surface layer."
통사문법적 지식이 ‘독서기계’의 음성출력에 미치는 영향과 중요성,2020,"['자연언어처리 (NLP)', '통사문법적 구조', '문해 (parsing)', '내재적 언어', '통사구조와 음성부의 접합면', 'natural language processing', 'I-language', 'auxiliaryhood', 'syntactic category', 'faculty of language']","인공지능, 그리고 딥러닝/머신러닝 등이 괄목할만한 발전을 이루면서 2016년경부터 100여개 언어의 기계발음번역기인 Google Translate도 자연언어처리 분야와 외국어 학습 등 언어활용분야에 독보적인 역할을 하고 있다. 본 논문은 이런 기계발음번역기, Google Translate에 있어서, 모국어화자가 가진 통사문법적-범주적 지식의 중요성과 그 영향력에 대해 살펴보고자 한다. Jackendoff (LSA, 1999)는 맹인을 위한 독서기계 (Reading Machine)등을 구축하려면 통사구조적 지식과 문법적 분해력이 매우 중요하고, 적어도 현재의 기계는 엄청난 일을 하기는 하나 인간의 두뇌를 따라갈 수 없다는 결론을 내렸다. Jackendoff가 논의했던 몇 가지 어휘항목과 통사구조적 중의성을 활용하여, Google Translate 기계발음번역기를 통해 그의 주장을 확인하는 실험을 실시하고, 그 결과를 분석하는 것이 이 논문의 목표이다. 이 연구는 Jackendoff의 주장처럼 L1화자가 내재화한 통사문법적, 범주-구조적 지식은 NLP, 혹은 “독서기계”등의 구축에서 중요하며, 이는 Chomsky (1986, 2005)등에서 논의된 내재적언어 (I-language)의 핵심이라는 점을 시사한다.","This paper highlights the influence and the importance of the syntactic-grammatical knowledge on “the reading machine”, appeared in Jackendoff (LSA, 1999). Due to the lack of the detailed testing and implementation in his research, this paper tests more extensive data using a component of Google Translate, currently available freely and most widely used on the internet. Although outdated, Jackendoff’s paper, “Why can’t Computers use English?”, argues that syntactic-grammatical knowledge plays a key role in the outputs of computers and computer-based reading machines. The current research has implemented some testings of his thought-provoking examples, in order to find out whether Google Translate can handle the same problems after two decades or so. As a result, it is argued that in the field of NLP, I-language in the sense of Chomsky (1986, 1995 etc) is real and the syntactic, grammatical, and categorial knowledge is essential in the faculty of language. Therefore, it is reassured in this paper that when it comes to human language, even the most advanced “machine” still has room for the sytactic-grammatical knowledge."
그래프 합성곱 신경망을 이용한 다중 관측소 기반 지진 이벤트 분류,2020,"['Earthquake event classification', 'Multi-site based classification', 'Convolution neural networks', 'Graph convolution networks', '지진 이벤트 분류', '다중 관측소 기반 분류', '합성곱 신경망', '그래프 합성곱 신경망']",본 논문은 다중 관측소에서 측정된 지진 신호를 이용한 그래프 합성곱 신경망 기반 지진 이벤트 분류 방법을제안한다. 기존의 딥러닝 기반 지진 이벤트 분류 방법은 대부분 단일 관측소에서 측정된 신호로부터 지진 이벤트를 분류한다. 지진 관측망에는 수많은 지진 관측소가 존재하며 하나의 관측소만 사용하는 방법보다 여러 관측소의 정보를동시에 활용하는 방법이 지진 이벤트 분류 성능 향상을 이끌 수 있다. 본 논문에서는 단일 관측소에서 측정된 지진 신호들에 합성곱 신경망을 적용해 임베딩 특징을 추출한 후 그래프 합성곱 신경망을 이용해 단일 관측소들 사이의 정보를융합하는 다중 관측소 기반 지진 이벤트 분류 구조를 제안한다. 관측소의 개수 변화 등 다양한 실험을 통해 제안한 모델의 성능 검증을 수행하였으며 실험 결과 제안하는 모델이 단일 관측소 기반 분류 모델보다 약 10 % 이상의 정확도와이벤트 재현율 성능 향상을 보여주었다.,"In this paper, we propose a multi-site based earthquake event classification method using graph convolution networks. In the traditional earthquake event classification methods using deep learning, they used single-site observation to estimate seismic event class. However, to achieve robust and accurate earthquake event classification on the seismic observation network, the method using the information from the multi-site observations is needed, instead of using only single-site data. Firstly, our proposed model employs convolution neural networks to extract informative embedding features from the single-site observation. Secondly, graph convolution networks are used to integrate the features from several stations. To evaluate our model, we explore the model structure and the number of stations for ablation study. Finally, our multi-site based model outperforms up to 10 % accuracy and event recall rate compared to single-site based model."
저연산량의 효율적인 콘볼루션 신경망,2020,"['MobileNet', 'CNN', 'GPU', 'computation complexity', 'Accuracy']","휴대용 기기나 에지 단말을 위한 CNN인 MobileNet V2를 기반으로 연산량을 크게 줄이면서도 정확도는 증가시킨 효율적인 인공신경망 네트워크 구조를 제안한다. 제안하는 구조는 Bottleneck 층 구조를 유지하면서 확장 계수를 증가시키고 일부층을 제거하는 등의 변화를 통해 연산량을 절반 이하로 줄였다. 설계한 네트워크는 ImageNet100 데이터셋을 이용하여 분류정확도와 CPU 및 GPU에서의 연산 시간을 측정하여 그 성능을 검증 하였다. 또한, 현재 딥러닝 가속기로 널리 이용하는GPU에서 네트워크 구조에 따라 동작 성능이 달라짐도 보였다.","We propose an efficient convolutional neural network with much lower computational complexity and higher accuracybased on MobileNet V2 for mobile or edge devices. The proposed network consists of bottleneck layers with largerexpansion factors and adjusted number of channels, and excludes a few layers, and therefore, the computationalcomplexity is reduced by half. The performance the proposed network is verified by measuring the accuracy andexecution times by CPU and GPU using ImageNet100 dataset. In addition, the execution time on GPU depends on theCNN architecture."
Caffe를 이용한 얼굴 인식 파이프라인 모델 구현,2020,"['Face detection', 'Face alignment', 'Embedding vector', 'Face recognition', 'Caffe']","제안 모델은 얼굴 검출과 랜드마크 및 얼굴 인식 알고리즘을 이용하여 인공신경망으로 학습을 통해 얼굴 예측률과 인식률을 향상하는 모델을 구현하였다. 제안 모델은 특정 인물의 얼굴 영상에서 랜드마킹을 한 후, 기존에 학습된 Caffe 모델을 이용하여 얼굴검출과 임베딩 벡터 128D를 추출하였다. 학습은 기계학습 알고리즘인 SVM (support vector machine)과 DNN (deep neural network)을 구축하여 학습하였다. 얼굴인식은 학습된 모델을 이용하여 학습된 인물 중 다른 얼굴 영상으로 테스트하였다. 실험 결과, SVM보다는 DNN으로 학습한 결과가 우수한 예측률과 인식률을 보였다. DNN의 중간층을 증가하게 되면 예측률은 높아지나 인식률이 감소하는 현상이 발생하였다. 이것은 인식하고자 하는 대상이 적음으로써 발생하는 과적합으로 판단된다. 제안 모델은 명확한 얼굴 영상을 추가하여 학 습한 결과, 높은 예측률과 인식률의 결과를 얻을 수 있음을 확인할 수 있었다. 본 연구는 좀 더 많은 얼굴 영상 데이터를 이용함으로써 보다 효과적인 딥러닝 구축을 통해 보다 향상된 인식률과 예측률을 얻을 수 있을 것이다.","The proposed model implements a model that improves the face prediction rate and recognition rate through learning with an artificial neural network using face detection, landmark and face recognition algorithms. After landmarking in the face images of a specific person, the proposed model use the previously learned Caffe model to extract face detection and embedding vector 128D. The learning is learned by building machine learning algorithms such as support vector machine (SVM) and deep neural network (DNN). Face recognition is tested with a face image different from the learned figure using the learned model. As a result of the experiment, the result of learning with DNN rather than SVM showed better prediction rate and recognition rate. However, when the hidden layer of DNN is increased, the prediction rate increases but the recognition rate decreases. This is judged as overfitting caused by a small number of objects to be recognized. As a result of learning by adding a clear face image to the proposed model, it is confirmed that the result of high prediction rate and recognition rate can be obtained. This research will be able to obtain better recognition and prediction rates through effective deep learning establishment by utilizing more face image data."
VGG16을 활용한 미학습 농작물의 효율적인 질병 진단 모델,2020,"['crop disease', 'convolutional neural network (CNN)', 'VGG16', '작물 질병', '합성곱신경망', 'VGG16']","농작물 질병에 대한 조기 진단은 질병의 확산을 억제하고 농업 생산성을 증대하는 데에 있어 중요한 역할을 하고 있다. 최근 합성곱신경망(convolutional neural network, CNN)과 같은 딥러닝 기법을 활용하여 농작물 잎사귀 이미지 데이터세트를 분석하여 농작물 질병을 진단하는 다수의 연구가 진행되었다. 이와 같은 연구를 통해 농작물 질병을 90% 이상의 정확도로 분류할 수 있지만, 사전 학습된 농작물 질병 외에는 진단할 수 없다는 한계를 갖는다. 본 연구에서는 미학습 농작물에 대해 효율적으로 질병 여부를 진단하는 모델을 제안한다. 이를 위해, 먼저 VGG16을 활용한 농작물 질병 분류기(CDC)를 구축하고 PlantVillage 데이터세트을 통해 학습하였다. 이어 미학습 농작물의 질병 진단이 가능하도록 수정된 질병 분류기(mCDC)의 구축방안을 제안하였다. 실험을 통해 본 연구에서 제안한 수정된 질병 분류기(mCDC)가 미학습 농작물의 질병 진단에 대해 기존 질병 분류기(CDC)보다 높은 성능을 보임을 확인하였다.","Early detection and classification of crop diseases play significant role to help farmers to reduce disease spread and to increase agricultural productivity. Recently, many researchers have used deep learning techniques like convolutional neural network (CNN) classifier for crop disease inspection with dataset of crop leaf images (e.g., PlantVillage dataset). These researches present over 90% of classification accuracy for crop diseases, but they have ability to detect only the pre-trained diseases. This paper proposes an efficient disease inspection CNN model for new crops not used in the pre-trained model. First, we present a benchmark crop disease classifier (CDC) for the crops in PlantVillage dataset using VGG16. Then we build a modified crop disease classifier (mCDC) to inspect diseases for untrained crops. The performance evaluation results show that the proposed model outperforms the benchmark classifier."
돌발상황 검지를 위한 교통 CCTV 기반 통행속도 추정 모델,2020,"['Travel speed', 'CCTV', 'Data fusion', 'Traffic information', 'Incident detection', '통행속도', 'CCTV', '자료융합', '교통정보', '돌발상황 검지']","통행속도는 도로의 교통상황을 측정하고, 교통사고와 같은 돌발상황 발생을 검지하는데 활용되는 중요한 정보이다. 본 논문에서 영상처리 기술을 활용하여 도로구간의 통행속도를 정확하게 측정하는 모델을 제안하였다. 제안 모델은 교통 CCTV 영상에서 차량 객체를 추출하고, 딥러닝 기술 등을 활용하여 차량을 추적하여, 도로구간의 통행속도 및 교통량 등과 같은 교통정보를 수집한다. 또한, 새로운 모델은 데이터 융합기술을 활용하여 정확한 구간통행속도를 수집하여 사용자에게 제공하는 것이 가능하다. 제안 모델을 서울시 오금교에서 현장실험한 결과, 기존 교통정보센터 통행속도 정확도(62.8%)보다 새 모델의 정확도가 높은 것(83.6%)을 확인하였다.","Travel speed is an important parameter for measuring road traffic and incident detection system. In this paper I suggests a model developed for estimating reliable and accurate average roadway link travel speeds using image processing sensor. This method extracts the vehicles from the video image from CCTV, tracks the moving vehicles using deep neural network, and extracts traffic information such as link travel speeds and volume. The algorithm estimates link travel speeds using a robust data-fusion procedure to provide accurate link travel speeds and traffic information to the public. In the field tests, the new model performed better than existing methods."
오디오 전처리 방법에 따른 콘벌루션 신경망의 환경음 분류 성능 비교,2020,"['환경음 분류', '콘볼루션 신경망', '오디오 특징 추출', '오디오 전처리', 'Environmental sound classification', 'Convolutional neural networks', 'Audio feature extraction', 'Audio preprocessing']","본 논문에서는 딥러닝(deep learning)을 이용하여 환경음 분류 시 전처리 단계에서 사용하는 특징 추출 방법이 콘볼루션 신경망의 분류 성능에 미치는 영향에 대해서 다루었다. 이를 위해 환경음 분류 연구에서 많이 사용되는 UrbanSound8K 데이터셋에서 멜 스펙트로그램(mel spectrogram), 로그 멜 스펙트로그램(log mel spectrogram), Mel Frequency Cepstral Coefficient(MFCC), 그리고 delta MFCC를 추출하고 각각을 3가지 분포로 스케일링하였 다. 이 데이터를 이용하여 4 종의 콘볼루션 신경망과 이미지넷에서 좋은 성능을 보였던 VGG16과 MobileNetV2 신경 망을 학습시킨 다음 오디오 특징과 스케일링 방법에 따른 인식률을 구하였다. 그 결과 인식률은 스케일링하지 않은 로 그 멜 스펙트럼을 사용했을 때 가장 우수한 것으로 나타났다. 도출된 결과를 모든 오디오 인식 문제로 일반화하기는 힘들지만, Urbansound8K의 환경음이 포함된 오디오를 분류할 때는 유용하게 적용될 수 있을 것이다.","This paper presents the effect of the feature extraction methods used in the audio preprocessing on the classification performance of the Convolutional Neural Networks (CNN). We extract mel spectrogram, log mel spectrogram, Mel Frequency Cepstral Coefficient (MFCC), and delta MFCC from the UrbanSound8K dataset, which is widely used in environmental sound classification studies. Then we scale the data to 3 distributions. Using the data, we test four CNNs, VGG16, and MobileNetV2 networks for performance assessment according to the audio features and scaling. The highest recognition rate is achieved when using the unscaled log mel spectrum as the audio features. Although this result is not appropriate for all audio recognition problems but is useful for classifying the environmental sounds included in the Urbansound8K."
팽창된 잔차 합성곱신경망을 이용한 KOMPSAT-3A 위성영상의 융합 기법,2020,"['Convolutional Neural Network (CNN)', 'Dilated Residual Network', 'KOMPSAT-3A', 'Pansharpening', 'Spatial Correlation Coefficient']","본 논문에서는 CNN (Convolutional Neural Network) 기반의 영상융합 기법을 제안하고자 하였다. 딥러닝 구조의 성능을 향상시키기 위하여, CNN 기법에서 대표적인 합성곱(convolution) 방법으로 알려진 팽창된합성곱(dilated convolution) 모델을 활용하여 모델의 깊이와 복잡성을 증대시키고자 하였다. 팽창된 합성곱을 기반으로 하여 학습과정에서의 효율을 향상시키기 위하여 잔차 네트워크(residual network)도 활용하였다. 또한, 본 연구에서는 모델학습을 위하여 전통적인 L1 노름(norm) 기반의 손실함수와 함께, 공간 상관도를 활용하였다. 본 연구에서는 전정색 영상만을 이용하거나 전정색 영상과 다중분광 영상을 모두 활용하여 구조에 적용한 DRNet을 개발하여 실험을 수행하였다. KOMPSAT-3A를 활용한 전정색 영상과 다중분광 영상을 이용한DRNet은 융합영상의 분광특성에 과적합되는 결과를 나타냈으며, 전정색 영상만을 이용한 DRNet이 기존 기법들과 비교하여 융합영상의 공간적 특성을 효과적으로 반영함을 확인하였다.","In this manuscript, a new pansharpening model based on Convolutional Neural Network (CNN) was developed. Dilated convolution, which is one of the representative convolution technologies in CNN, was applied to the model by making it deep and complex to improve the performance of the deep learning architecture. Based on the dilated convolution, the residual network is used to enhance the efficiency of training process. In addition, we consider the spatial correlation coefficient in the loss function with traditional L1 norm. We experimented with Dilated Residual Networks (DRNet), which is applied to the structure using only a panchromatic (PAN) image and using both a PAN and multispectral (MS) image. In the experiments using KOMPSAT-3A, DRNet using both a PAN and MS image tended to overfit the spectral characteristics, and DRNet using only a PAN image showed a spatial resolution improvement over existing CNN-based models."
온-디바이스 엣지 컴퓨터 기반 설비예지보존 솔루션 구축에 관한 연구,2020,"['Smart Factory', 'Edge Computing', 'On-Device', 'Distributed Computing', 'Equipment Predictive Maintenance', 'Productivity', '스마트 팩토리', '에지 컴퓨팅', '온-디바이스', '분산 컴퓨팅', '설비 예지 보전', '생산성']","본 연구에서는 현재 일반적인 스마트 팩토리에서 데이터 전송에 사용하는 중앙 집중형 시스템에서 발생하는 데이터를 중앙의 센터까지 전송, 처리할 때 발셍하는 전송 지연 등의 문제 해결을 위하여 필요한 곳에 연산과 저장 장치를 도입하는 분산 컴퓨팅 패러다임 (Distributed Computing Paradigm)인 온-디바이스 (On-Device) 기반 에지 컴퓨팅 (Edge Computing) 기술과 빅데이터 분석 기술 및 활용 방법의 연구를 통하여 설비 고장 등을 예지하여 가동율을 높일 수 있는 산업현장의 설비관리에 활용되는 솔루션을 제안한다. 그러나 에지 컴퓨팅 기반의 기술이 실제 적용되더라도 네트워크 에지에서 장치의 증가는 많은 양의 데이터가 데이터 센터로 전달되어 네트워크 대역이 한계치에 이르게 되어 네트워크 기술의 향상에도 데이터 센터는 수많은 응용에서 중요한 요건이 되는 수용 가능한 전송 속도와 응답 시간을 보장하지 못하게 된다. 이와 같은 요구조건을 수용할 수 있는 일체형 하드웨어 기술과 공장관리 및 제어 기술을 적용한 설비보존 및 스마트 팩토리 산업 분야에 적용할 수 있는 연구를 통하여 생산성 증대를 지원할 수 있는 지능적 설비관리를 지원하도록 하여 추후 빅데이터에 적합한 딥러닝을 적용할 수 있는 인공지능 기반 설비 예지 보전 분석 도구로 발전할 수 있는 기반을 제공한다.","In this paper we propose an uses on-device-based edge computing technology and big data analysis methods through the use of on-device-based edge computing technology and analysis of big data, which are distributed computing paradigms that introduce computations and storage devices where necessary to solve problems such as transmission delays that occur when data is transmitted to central centers and processed in current general smart factories. However, even if edge computing-based technology is applied in practice, the increase in devices on the network edge will result in large amounts of data being transferred to the data center, resulting in the network band reaching its limits, which, despite the improvement of network technology, does not guarantee acceptable transfer speeds and response times, which are critical requirements for many applications. It provides the basis for developing into an AI-based facility prediction conservation analysis tool that can apply deep learning suitable for big data in the future by supporting intelligent facility management that can support productivity growth through research that can be applied to the field of facility preservation and smart factory industry with integrated hardware technology that can accommodate these requirements and factory management and control technology."
시스템 자원 관리를 통한 객체 인식 성능 저하 방지,2020,"['Deep neural network', 'Object detection', 'System resource management', 'Mixed-criticality system']",최근 딥러닝 기술의 빠른 발전 속도로 인하여 자율주행 자동차의 객체 인식 기능에서 인공 신경망의 사용이 보편화되고 있다. 더불어 높은 인식 정확도를 나타내기 위해 인공 신경망 연산의 복잡도와 데이터 요구량은 급속하게 늘고 있다. 인공 신경망의 연산을 클라우드 서버에서 수행 시 네트워크 지연으로 인한 응답특성이 떨어지거나 보안 문제의 여지가 있어서 자율주행 자동차 내부의 임베디드 시스템에서 수행한다. 최근 고 성능 멀티코어 기반 SoC(System on Chip) 기술 발전으로 신경망을 임베디드 환경에서 연산할 수 있게 되었다. 하지만 이러한 환경에서는 CPU나 메모리와 같은 시스템 자원을 다른 응용과 공유하기 때문에 객체 인식과 같은 안전에 민감한 기능이 수행될 때 성능 저하가 발생할 수 있다. 본 논문에서는 객체 인식 응용이 시작된 후 성능 간섭이 나타나면 객체 인식 응용에 관련된 모든 태스크들을 찾아내어 더 많은 시스템 자원 사용율을 부여하고 종료되면 원래 상태로 복귀되는 운영체제 수준의 솔루션을 제시한다. 제안된 기법을 Jetson AGX Xavier에 탑재 후 실험한 결과 객체 인식 성능이 SPEC CPU2017 벤치마크 프로그램들에게 성능 간섭을 받는 환경에서 적용 전 대비 13.5%∼33% 향상되었다.,"Recently, due to the rapid development of deep learning technology, the use of deep neural networks in the object detection of autonomous vehicles is becoming prevalent. Besides, the complexity and data requirements of deep neural network operations are rapidly increasing to show high recognition accuracy. When deep neural network computation is performed in cloud server, response characteristics due to network delay is inferior or there is a possibility of security problem. Recent advances in high-performance, multicore-based System on Chip (SoC) technologies enable neural networks to be computed in embedded environments. However, in this environment, system resources such as CPU and memory are shared with other applications, which can cause performance degradation when safety-sensitive functions such as object detection are performed. In this paper, we propose an operating system level solution that finds all tasks related to object detection, gives more system resource utilization if the performance interference occurs after the object detection is started, and returns to the original state when finished. The proposed solution is running on top of Jetson AGX Xavier, and the experimental results show that the performance of object detection is improved by 13.5%∼33% compared to before, under the performance interference of SPEC CPU2017 benchmark programs."
지하구조물 콘크리트 균열 탐지를 위한 semi-supervised 의미론적 분할 기반의 적대적 학습 기법 연구,2020,"['적대적 학습', '균열 탐지', '의미론적 분할', '상태 점검', '영상처리', 'Adversarial learning', 'Crack detection', 'Semantic segmentation', 'Health monitoring', 'Image processing']","통상적으로 콘크리트 지하 구조물은 수십 년 이상 사용할 수 있도록 설계되지만 최근 들어 구조물 중 상당수가 당초의 기대 수명에 근접하고 있는 실정이다. 그 결과 구조물 고유의 기능이 상실되고 다양한 문제가 야기될 수 있어 신속한 점검과 보수가 요구되고 있다. 이를 위해 지금까지는 지하 구조물 유지관리를 위하여 인력 기반의 점검과 보수가 진행되었으나 최근에는 인공지능과 영상 기술의 융합을 통한 객관적인 점검 기술 개발이 활발하게 이루어지고 있다. 특히 딥러닝을 활용한 영상 인식 기술을 적용하여 지도학습 기반의 콘크리트 균열 탐지 알고리즘 개발에 관한 연구가 다양하게 진행되고있다. 이러한 연구들은 대부분 지도학습 형태 영상 인식 기술로 많은 양의 데이터를 바탕으로 개발이 되는데, 그 중에도 많은 수의 라벨 영상(Label image)이 요구된다. 이를 확보하기 위해서는 현실적으로 많은 시간과 노동력이 필요한 실정이다. 본 논문에서는 이와 같은 문제를 개선하고자 적대적 학습 기법을 적용하여 균열 영역 탐지 정확도를 평균적으로 0.25% 향상시키는 방법을 기술하고자 한다. 이 적대적 학습은 분할(Segmentation) 신경망과 판별자(Discriminator) 신경망으로 구성되어 있고, 가상의 라벨 영상을 경쟁적인 구조로 생성하여 인식 성능을 높이는 알고리즘이다. 본 논문에서는 이 같은 방법을 활용하여 효율적인 심층 신경망 학습 방법을 제시하였고, 향후에 정확한 균열 탐지에 활용될 것으로 기대한다.","Underground concrete structures are usually designed to be used for decades, but in recent years, many of them are nearing their original life expectancy. As a result, it is necessary to promptly inspect and repair the structure, since it can cause lost of fundamental functions and bring unexpected problems. Therefore, personnel-based inspections and repairs have been underway for maintenance of underground structures, but nowadays, objective inspection technologies have been actively developed through the fusion of deep learning and image process. In particular, various researches have been conducted on developing a concrete crack detection algorithm based on supervised learning. Most of these studies requires a large amount of image data, especially, label images. In order to secure those images, it takes a lot of time and labor in reality. To resolve this problem, we introduce a method to increase the accuracy of crack area detection, improved by 0.25% on average by applying adversarial learning in this paper. The adversarial learning consists of a segmentation neural network and a discriminator neural network, and it is an algorithm that improves recognition performance by generating a virtual label image in a competitive"
이미지 인식 기술의 산업 적용 동향 연구,2020,"['인공지능', '이미지 인식기술', '컴퓨터 비전기술', '이미지 분류', '이미지 찾기', 'Artificial Intelligence', 'Image Recognition Technology', 'Computer Vision Technology', 'Image Classification', 'Image Localization']","본 연구는 이미지 인식기술 서비스의 산업 적용 사례를 기반으로 인공지능이 이미지 인식기술에 어떠한 역할을 하고 있는지 살펴보았다. 이미지 인식 기술을 사용하여 위성사진을 인공지능으로 분석해 특정 국가의 원유 저장탱크의 산출 내역을 밝혀내거나, 사용자가 촬영하거나 다운로드한 이미지와 유사한 이미지나 제품을 검색해주기도 하며, 과일의 산출량을 정렬한다거나 식물의 질병을 탐지해 낼 수도 있다. 딥러닝과 신경망 알고리즘을 기반으로 사람의 나이, 성별, 기분까지도 인식할 수 있어 이미지 인식 기술이 다양한 산업에서 적용되고 있음을 확인하였다. 본 연구에서는 국내 및 해외의 이미지 인식 기술의 활용 사례를 살펴보는 것 뿐 아니라, 어떠한 형태로 산업에 적용되고 있는지 확인을 할 수 있다. 또한, 본 연구를 통하여 여러 산업에서 이미지 인식기술을 구현하고 적용하여 발전시킨 여러 성공 사례들을 중심으로 향후 연구의 방향성을 제시했으며, 향 후 국내 이미지 인식 기술이 나아가야 할 방향을 고찰해 볼 수 있다.","Based on the use cases of image recognition technology, this study looked at how artificial intelligence plays a role in image recognition technology. Through image recognition technology, satellite images can be analyzed with artificial intelligence to reveal the calculation of oil storage tanks in certain countries. And image recognition technology makes it possible for searching images or products similar to images taken or downloaded by users, as well as arranging fruit yields, or detecting plant diseases. Based on deep learning and neural network algorithms, we can recognize people's age, gender, and mood, confirming that image recognition technology is being applied in various industries. In this study, we can look at the use cases of domestic and overseas image recognition technology, as well as see which methods are being applied to the industry. In addition, through this study, the direction of future research was presented, focusing on various successful cases in which image recognition technology was implemented and applied in various industries. At the conclusion, it can be considered that the direction in which domestic image recognition technology should move forward in the future."
인공지능 시대의 글로벌 역사 관점,2020,"['인공지능', '글로벌 역사', '4차 산업혁명', '인간 생활', '진화', 'artificial intelligence', 'global history', 'fourth industrial revolution', 'human life', 'evolution']","이 글은 인공지능의 진화에 따른 인간 생활의 변화를 조망하는 논지를 담고 있다. 4차 산업혁명은 이전과는 다른 글로벌 역사 관점을 현실세계에 재현하고 있다. 이전의 산업혁명 과정은인간의 물리적 힘을 증강하거나 대체하여 인간 생활의 편의성을 증진하는 것이었다. 하지만 4차산업혁명은 이에 더하여 인간의 정신적 영혼까지 관여하는 초지능형 인공지능을 가능하게 한다는 점에서 차원을 달리한다. 인공지능은 딥러닝이라는 혁신적인 기술을 바탕으로 연결형, 융합형을 거쳐 자율형 기계지능을 갖춘 초지능형으로 발전하여 왔다. 글로벌 역사의 관점에서 주목할만한 변환 가능성이 나타났다는 점에서 인공지능의 게임 체인저로서의 역할에 대한 기대와 우려가교차되는 시점이 도래한 것이다. 인간친화적인 인공지능은 아무런 문제가 없다. 그러나 초지능형범용 인공지능기술이 자율적 판단 능력을 갖고 인간을 대체하거나 능가하는 경우는 인간의 존엄성이 침해되는 상황이 나타날 수도 있다. 이런 점에서 통제 가능한 자율형 인공지능이 인간의육체와 영혼을 자유롭고 평등하고 풍요롭게 하도록 디자인하는 것은 매우 중대하고도 필수적인 과제이다.","This paper includes a change of human life according to artificial intelligence evolution. The fourth industrial revolution represents a new global history perspectives to real world than before ages. The first to third industrial revolution is proceeded for human life efficiency in aspects of human physical power and simple knowledge. But contemporary transformation of history is related to human mind and soul through super artificial intelligence. This is a different change than before civilizations. Artificial intelligence is developed as an autonomous machine or super intelligence based on deep learning technologies. In this respect, the role of artificial intelligence is a game changer in global history perspectives and has a possibility and concern for a planet future. The most important task for a free and equal human life is a human-friendly artificial intelligence evolution. This is a very pivotal point to human view."
Residual U-Net을 이용한 토지피복지도 자동 제작 연구,2020,"['항공정사영상', 'Landsat 8', 'Residual U-Net', '토지피복지도 자동 제작', 'Aerial ortho photo', 'Landsat 8', 'Residual U-Net', 'Automatic land cover map generation']","환경부에서는 위성영상과 항공영상을 이용하여 토지피복지도를 1998년부터 제작하여 배포하고 있으나, 권역별 제작 주기가 달라 활용성이 저하된다. 이에, 본 연구에서는 항공정사영상과 Landsat 8 위성영상을 이용하여, 토지피복지도를 자동으로 생성하기 위한 연구를 수행하였다. 토지피복지도를 자동적으로 제작하기 위하여 딥러닝 기반 세그먼테이션 방법의 하나인 Residual U-Net을 활용하였다. 토지피복지도의 제작 시기와 가장 근접한 시기의 항공 및 위성영상을 신경망을 통하여 학습하고, 학습결과를 3가지 실험군으로 나누어 토지피복지도와 비교하여 정확도 평가를 수행하였다. 첫 번째 군으로 대분류 7개 전체를 활용한 결과의 경우, 선행연구에서 대분류 4개에만 적용된 결과보다도 향상된 86.6 % 의 분류 정확도를 나타내었다. 중분류를 일부 포함한 2개의 실험군의 경우에는 71 %의 정확도를 나타내었다. 본 연구 결과를 바탕으로 신경망을 활용한 대분류 항목에 대한 자동 분류 가능성을 제시하였으며, 중분류 및 세분류에 대한 기초연구로 활용이 가능할 것으로 판단된다","Land cover maps are derived from satellite and aerial images by the Ministry of Environment for the entire Korea since 1998. Even with their wide application in many sectors, their usage in research community is limited. The main reason for this is the map compilation cycle varies too much over the different regions. The situation requires us a new and quicker methodology for generating land cover maps. This study was conducted to automatically generate land cover map using aerial ortho-images and Landsat 8 satellite images. The input aerial and Landsat 8 image data were trained by Residual U-Net, one of the deep learning-based segmentation techniques. Study was carried out by dividing three groups. First and second group include part of level-II (medium) categories and third uses group level-III (large) classification category defined in land cover map. In the first group, the results using all 7 classes showed 86.6 % of classification accuracy The other two groups, which include level-II class, showed 71 % of classification accuracy. Based on the results of the study, the deep learning-based research for generating automatic level-III classification was presented."
한국어 특성 기반의 STT 엔진 정확도를 위한 정량적 평가방법 연구,2020,"['Speech To Text', 'Text To Speech', 'Evaluation', 'Measure', 'Korean Characteristics']","딥러닝 기술의 발전으로 STT(Speech To Text), TTS(Text To Speech), 챗봇(ChatBOT), 인공지능 비서 등 다양한 분야에 음성처리 관련 기술이 적용되고 있다. 특히, STT는 음성 기반 관련 서비스의 기반이며, 인간의 언어를 텍스트로 변환시키기 때문에 IT관련 서비스에 대한 다양한 응용을 할 수 있다. 따라서 최근 일반 사기업, 공공기관 등 여러 수요처에서 관련 기술에 대한 도입을 시도하고 있다. 하지만 정량적으로 수준을 평가할 수 있는 일반적인 IT 솔루션과는 달리 STT엔진에 대한 정확성을 평가하는 기준과 방법이 모호하며 한국어의 특성을 고려하지 않기 때문에 정량적인 평가 기준 적용이 어렵다. 따라서 본 연구에서는 한국어의 특성에 기반한 STT엔진 변환 성능 평가에 대한 가이드를 제공함으로써 엔진제작사는 한국어 특성에 기반한 STT변환을 수행 할 수 있으며, 수요처에서는 더 정확한 평가를 수행할 수 있다. 실험 데이터에서 기존 방식에 비해 35% 더 정확한 평가를 수행할 수 있다.","With the development of deep learning technology, voice processing-related technology is applied to various areas, such as STT (Speech To Text), TTS (Text To Speech), ChatBOT, and intelligent personal assistant. In particular, the STT is a voice-based, relevant service that changes human languages to text, so it can be applied to various IT related services. Recently, many places, such as general private enterprises and public institutions, are attempting to introduce the relevant technology. On the other hand, in contrast to the general IT solution that can be evaluated quantitatively, the standard and methods of evaluating the accuracy of the STT engine are ambiguous, and they do not consider the characteristics of the Korean language. Therefore, it is difficult to apply the quantitative evaluation standard. This study aims to provide a guide to an evaluation of the STT engine conversion performance based on the characteristics of the Korean language, so that engine manufacturers can perform the STT conversion based on the characteristics of the Korean language, while the market could perform a more accurate evaluation. In the experiment, a 35% more accurate evaluation could be performed compared to the existing methods."
포즈 추적을 이용한 증강현실 리프팅 플레이어 생성,2020,"['증강 현실', '인공 지능', '심층 신경망', '자세 추적', '영상 합성', 'Augmented Reality', 'Artificial Intelligence', 'Deep Neural Networks', 'Posture Tracking', 'Video Synthesis']","본 논문에서는 다양한 사용자의 영상을 이용하여 축구공 리프팅과 같은 묘기 장면을 만들 수있는 프레임워크를 제안한다. 제안된 방법은 핸드폰 등으로 촬영된 일반적인 사용자의 영상이라면 수 초 이내에 원하는 결과를 생성할 수 있다. 본 논문의 프레임워크는 크게 세 부분으로 나누어진다. 첫 번째는 사용자의 영상을 입력받아 자세를 분석하는 것이다. 이를 위해서는 딥러닝 기법으로 영상을 분석하여 사용자의 포즈를 계산하고, 원하는 신체 부위의 움직임을 추적할 수 있다. 두 번째는 지정된 신체부위의 이동 궤적을 분석하여 물체를 타격하는 위치와 시간을 계산하는 것이다. 마지막으로 분석된 타격 정보를 이용하여 물체의 이동 궤적을 생성하는 것이다. 그러면 입력된 사용자 영상과 동기화되는 자연스러운 물체 리프팅 장면을 생성할 수 있다. 사실적인물체의 움직임을 생성하기 위해 물리 기반 최적화를 사용하였다. 본 논문의 프레임워크를 이용하면 다양한 증강현실 어플리케이션을 제작할 수 있다.","This paper proposes a framework for creating acrobatic scenes such as soccer ball lifting using various users' videos. The proposed method can generate a desired result within a few seconds using a general video of user recorded with a mobile phone. The framework of this paper is largely divided into three parts. The first is to analyze the posture by receiving the user's video. To do this, the user can calculate the pose of the user by analyzing the video using a deep learning technique, and track the movement of a selected body part. The second is to analyze the movement trajectory of the selected body part and calculate the location and time of hitting the object. Finally, the trajectory of the object is generated using the analyzed hitting information. Then, a natural object lifting scenes synchronized with the input user's video can be generated. Physical-based optimization was used to generate a realistic moving object. Using the method of this paper, we can produce various augmented reality applications."
약한 레이블을 이용한 확장 합성곱 신경망과 게이트 선형 유닛 기반 음향 이벤트 검출 및 태깅 알고리즘,2020,"['음향 태깅', '음향 이벤트 검출', '확장 합성곱 신경망', '게이트 선형 유닛', '시간-주파수 영역분할 맵', '약한레이블', 'Audio tagging', 'Sound event detection', 'Dilated convolution', 'Gated linear unit', 'T-f segmentation map', 'Weak label']","본 논문은 약한 레이블 기반 음향 이벤트 검출을 위한 시간-주파수 영역분할 맵 추출 모델에서 발생하는 희소성 및 수용영역 부족에 관한 문제를 완화 시키기 위해, 확장 게이트 선형 유닛(Dilated Convolution Gated Linear Unit, DCGLU)을 제안한다. 딥러닝 분야에서 음향 이벤트 검출을 위한 영역분할 맵 추출 기반 방법은 잡음 환경에서 좋은성능을 보여준다. 하지만, 이 방법은 영역분할 맵을 추출하기 위해 특징 맵의 크기를 유지해야 하므로 풀링 연산 없이모델을 구성하게 된다. 이로 인해 이 방법은 희소성과 수용영역의 부족으로 성능 저하를 보이게 된다. 이런 문제를 완화하기 위해, 본 논문에서는 정보의 흐름을 제어할 수 있는 게이트 선형 유닛과 추가의 파라미터 없이 수용영역을 넓혀줄 수 있는 확장 합성곱 신경망을 적용하였다. 실험을 위해 사용된 데이터는 URBAN-SED와 자체 제작한 조류 울음소리 데이터이며, 제안하는 DCGLU 모델이 기존 베이스라인 논문들보다 더 좋을 성능을 보였다. 특히, DCGLU 모델이자연 소리가 섞인 환경인 세 개의 Signal to Noise Ratio(SNR)(20 dB, 10 dB, 0 dB)에서 강인하다는 것을 확인하였다.","In this paper, we propose a Dilated Convolution Gate Linear Unit (DCGLU) to mitigate the lack of sparsity and small receptive field problems caused by the segmentation map extraction process in sound event detection with weak labels. In the advent of deep learning framework, segmentation map extraction approaches have shown improved performance in noisy environments. However, these methods are forced to maintain the size of the feature map to extract the segmentation map as the model would be constructed without a pooling operation.As a result, the performance of these methods is deteriorated with a lack of sparsity and a small receptive field.To mitigate these problems, we utilize GLU to control the flow of information and Dilated Convolutional Neural Networks (DCNNs) to increase the receptive field without additional learning parameters. For the performance evaluation, we employ a URBAN-SED and self-organized bird sound dataset. The relevant experiments show that our proposed DCGLU model outperforms over other baselines. In particular, our method is shown to exhibit robustness against nature sound noises with three Signal to Noise Ratio (SNR) levels (20 dB, 10 dB and 0 dB)."
R2와 어텐션을 적용한 유넷 기반의 영상 간 변환에 관한 연구,2020,"['Image-to-Image Translation', 'conditional GAN', 'U-Net', '영상 간 변환', '조건 적대적 생성 신경망', '유넷']","영상 처리 및 컴퓨터 비전 분야에서 하나의 영상을 통해 다른 영상으로 재구성하거나 새로운 영상을 생성하는 문제는 하드웨어의발전에 따라 꾸준히 주목받고 있다. 그러나 컴퓨터를 통해 생성한 이미지를 사람의 눈으로 바라봤을 때 자연스럽지 않다는 문제 또한 계속해서 대두되고 있다. 최근 딥러닝 분야에 대한 연구가 활발히 진행됨에 따라 이를 활용한 영상 생성 및 개선 문제 또한 활발히 연구되고 있으며 그 중에서도 적대적 생성 신경망(Generative Adversarial Network)이라는 네트워크가 영상 생성 분야에 있어 좋은결과를 보이고 있다. 적대적 생성 신경망이 제안된 이후 이를 기반으로 하는 다양한 네트워크가 제시됨에 따라 영상 생성 분야에서더 자연스러운 영상을 생성하는 것이 가능해졌다. 그 중 pix2pix은 조건 적대적 생성 신경망 모델로 다양한 데이터셋에서도 좋은 성능을보이는 범용적인 네트워크이다. pix2pix는 U-Net을 기반으로 두고 있으나 U-Net을 기반으로 하는 네트워크 중에서는 더 좋은 성능을 보이는 네트워크가 다수 존재한다. 때문에 본 연구에서는 pix2pix의 U-Net에 다양한 네트워크를 적용해 영상을 생성하고 그 결과를 상호비교 평가한다. 각 네트워크를 통해 생성된 영상을 통해 기존의 U-Net을 사용한 pix2pix 모델보다 어텐션, R2, 어텐션-R2 네트워크를 적용한 pix2pix 모델이 더 좋은 성능을 보이는 것을 확인하고 그 중 가장 성능이 뛰어난 네트워크의 한계점을 향후 연구로 제시한다.","In the Image processing and computer vision, the problem of reconstructing from one image to another or generating a new image has been steadily drawing attention as hardware advances. However, the problem of computer-generated images also continues to emerge when viewed with human eyes because it is not natural. Due to the recent active research in deep learning, image generating and improvement problem using it are also actively being studied, and among them, the network called Generative Adversarial Network(GAN) is doing well in the image generating. Various models of GAN have been presented since the proposed GAN, allowing for the generation of more natural images compared to the results of research in the image generating. Among them, pix2pix is a conditional GAN model, which is a general-purpose network that shows good performance in various datasets. pix2pix is based on U-Net, but there are many networks that show better performance among U-Net based networks. Therefore, in this study, images are generated by applying various networks to U-Net of pix2pix, and the results are compared and evaluated. The images generated through each network confirm that the pix2pix model with Attention, R2, and Attention-R2 networks shows better performance than the existing pix2pix model using U-Net, and check the limitations of the most powerful network. It is suggested as a future study"
지능형 감시 정찰 시스템 구축을 위한 OpenPose와 Deep Learning 기술 적용방안 연구,2020,"['OpenPose', 'keypoints', 'deep neural networks', 'convolutional neural networks', 'long short-term memory', '오픈포즈', '키포인트', '심층 신경망', '합성곱 신경망', '장단기 기억 신경망']","본 연구에서는 국방 감시 정찰 시스템을 OpenPose와 DNN(Deep Neural Networks), CNN(Convolutional Neural Networks), LSTM(Long Short-Term Memory)과 같은 딥러닝 네트워크를 통해 구현하였다. 본 연구의 시스템은 기존의 감시 정찰 시스템과는 다른 방식의 거동수상자(target) 인식 방법을 제안하고 있으며, 제안하는 방법은 촬영되는 영상에서 사람들의 모션을 분류함으로써 일반인과 거동수상자를 구분하는 것이다. 이를 위해 OpenPose를 통해 영상 내의 대상의 skeleton 데이터를 추출한다. 이때, 추출되는 skeleton 데이터에 포함되는 keypoints를 DNN, CNN, LSTM에 입력하여 모션을 분류하게 된다. 분류되는 모션들은 사주경계와 같이 군에서 배울 수 있는 모션으로 선정하였다. 시스템이 모션을 분류하여 거동수상자를 인식하게 되면 지도에 이를 표시하고 추적을 한다. 추적 알고리즘에서는 프레임별로 OpenPose를 통해 추출된 keypoints 값의 변화를 계산하여 거동수상자의 이동방향을 계산하고 카메라에서 얻은 depth 정보를 활용하여 카메라 위치를 기반으로 거동수상자를 지도에 표시하도록 한다. 이와 같은 모든 연산은 전체 이미지가 아닌 skeleton 데이터를 활용하였기 때문에 전체적인 연산량을 감소시킬 수 있게 된다.","In this study, defense surveillance reconnaissance systems were implemented through deep learning networks such as OpenPose and deep neural networks (DNN), convolutional neural networks (CNN), and long short-term memory (LSTM). This study proposes a target recognition method which differs from the existing surveillance reconnaissance systems. This method consists in distinguishing between ordinary people and targets by classifying motions in the images being filmed. Thus, the skeleton data of the target in the image are extracted using OpenPose. Then, keypoints included in the extracted skeleton data are entered into DNN, CNN, and LSTM to classify the motion. The classified motions are selected as motions learned in the military, such as overall security. When the system classifies motions and recognizes targets, it identifies them on the map and tracks them. The tracking algorithm calculates the movement direction of the target by calculating the change in the values of keypoints extracted through OpenPose by frames. Finally, it uses the depth information obtained from the camera to display targets on the map based on the camera location. All these computations are based on the use of the skeleton data rather than the entire image, thus reducing the overall computation."
추가 정보를 고려한 상품 리뷰 요약 기법,2020,"['document summarization', 'sequence-to-sequence model', 'attention mechanism', 'memory network', 'artificial neural network', '문서 요약', '시퀀스-투-시퀀스 모델', '주의 집중 메커니즘', '메모리 네트워크', '인공 신경망']","문서 요약은 주어진 문서로부터 특정 사용자나 작업에 적합한 형태로 축약한 문서를 생성하는 것을 의미한다. 인터넷 사용이 증가함에 따라, 텍스트를 포함한 다양한 데이터들이 폭발적으로 증가하고 있고, 문서 요약 기술이 지니는 가치는 증대되고 있다. 최신 딥러닝 기반 모델들이 좋은 요약 성능을 보이지만, 학습 데이터들의 양과 질에 따라 성능이 좌우되는 문제점이 있다. 예를 들어, 온라인 쇼핑몰의 상품 리뷰 데이터의 경우, 오탈자와 비문법적인 텍스트 특징 때문에 기존 모델로 좋은 요약을 생성하기 힘들다. 이러한 문제를 해결하려고 온라인 쇼핑몰과 포탈 서비스가 많은 노력을 하고 있다. 따라서 본 연구에서는 리뷰 학습 데이터의 양과 질이 열악하더라도 적절한 문서 요약을 생성하기 위해, 주어진 상품 리뷰의 추가 정보를 이용해서 상품 리뷰 요약을 생성하는 모델을 제안한다. 더불어, 실험을 통해 제안한 기법의 문서 요약이 기존 기법보다 요약의 관련성과 가독성 측면에서 향상되었음을 보였다.","Automatic document summarization is a task that generates the document in a suitable form from an existing document for a certain user or occasion. As use of the Internet increases, the various data including texts are exploding and the value of document summarization technology is growing. While the latest deep learning-based models show reliable performance in document summarization, the problem is that performance depends on the quantity and quality of the training data. For example, it is difficult to generate reliable summarization with existing models from the product review text of online shopping malls because of typing errors and grammatically wrong sentences. Online malls and portal web services are struggling to solve this problem. Thus, to generate an appropriate document summary in poor condition relative to quality and quantity of the product review learning data, this study proposes a model that generates product review summaries with additional information. We found through experiments that this model showed improved performances in terms of relevance and readability than the existing model for product review summaries."
CNN 기반 철도차량 차체-대차 연결부의 결함 평가기법 연구,2020,"['Convolutional Neural Network', 'Railway Bogie', 'Damage', 'Weldment', 'Defect']","철도차량의 대차는 열차 주행을 위한 핵심적인 장치이다. 철도차량의 대차에서 피로결함은 운행 중 기대되지 않거나 과도한 하중, 용접결함, 재료 결함 등의 다양한 요인에 의해 발생할 수 있다. 철도차량의 사고를 방지하기 위해서 차체-대차연결부의 손상을 검출하고 발생 결함에 대한 정확한 평가가 요구된다. 이러한 철도차량의 차체-대차 연결부는 초음파 비파괴 검사를 통하여 건전성을 확보하고 있으나 결함 발생에 대한 학습기법을 이용한 판정방법이 필요하다.최근 미세한 결함이나 유사한 결함을 높은 인식율로 검출하기 위하여 딥러닝 기법에 관한 여러 연구가 진행되고 있다. 본 연구에서는 철도차량의 차체-대차 연결부의 결함 검출능력을 위하여 용접부의 인공결함 시편에 대하여 데이터베이스 구축하였으며. 웨지형 초음파 센서를 이용하여 차체-대차 연결부에 대한 비파괴 검사를 수행하였다. 부가적으로 인적 오류를 최소화하기 위하여 결함판단 학습기법인 합성곱 신경망기법(Convolutional Neural Network)을 적용하였다. 그 결과 합성곱 신경망기법 기법을 이용하여 철도차량의 차체-대차 연결 용접부의 균열을 99.98%이상 균열성 결함으로 판별할 수 있었으며 철도차량 차체-대차 연결부의 비파괴검사시 본 연구의 기술이 적용 가능함을 확인할 수 있었다.","The bogies of railway vehicles are one of the most critical components for service. Fatigue defects in the bogie can be initiated for various reasons, such as material imperfection, welding defects, and unpredictable and excessive overloads during operation. To prevent the derailment of a railway vehicle, it is necessary to evaluate and detect the defect of a connection weldment between the car body and bogie accurately. The safety of the bogie weldment was checked using an ultrasonic test, and it is necessary to determine the occurrence of defects using a learning method. Recently, studies on deep learning have been performed to identify defects with a high recognition rate with respect to a fine and similar defect. In this paper, the databases of weldment specimens with artificial defects were constructed to detect the defect of a bogie weldment. The ultrasonic inspection using the wedge angle was performed to understand the detection ability of fatigue cracks. In addition, the convolutional neural network was applied to minimize human error during the inspection. The results showed that the defects of connection weldment between the car body and bogie could be classified with more than 99.98% accuracy using CNN, and the effectiveness can be verified in the case of an inspection."
텍스트마이닝을 이용한 한국 대통령의 해양관에 관한 연구,2020,"['Text Mining', 'Speech', 'Topic Model', 'Content Analysis', '텍스트마이닝', '연설문', '토픽모델', '내용분석']",대통령 중심제의 정치체제에서는 대통령의 언어가 국가정책의 형성과 의사결정 과정에 지대한 영향을미치게 된다. 대통령의 이념과 중심가치에 따라 정책우선순위가 결정되고 그 우선순위에 따라 다양한정책이 수립되고 집행된다. 그래서 대통령의 연설문을 내용분석하는 연구가 관심의 대상이 되고 있다.대통령의 연설문은 언어 자료이기 때문에 비정형이면서 비구조화 된 텍스트를 분석하기 위해서는 기계학습과 딥러닝의 방법을 통해 빅데이터 분석이 이루어지고 있다. 본 연구에서는 1996년부터 24년간에걸쳐 “바다의 날” 기념식의 대통령 연설문을 확보하여 텍스트마이닝 방법의 일종인 토픽모델링의 방법으로 분석하였다.분석결과 역대 대통령은 모두 자신의 국정운영 방향에 부합되는 해양관을 가지고 연설문을 발표하였다는 것을 확인하였다. 해양의 고유가치인 해양-산업-자원 토픽은 훼손되지 않고 지속적으로 역대 대통령이 모두 강조하고 있음을 확인하였다.,"In the presidential political system, the word of the president has great influence on the formation of national policy and the decision-making process. Policy priorities are determined according to the president's ideology and core values, and various policies are established and executed according to the priorities. Therefore, this paper analyzes the contents of the president's speech.Since the president's speech is a semantic datum, in order to analyze unstructured text, big data analysis is conducted through the methods of machine learning and deep learning. In this study, the president's speech at the “National Sea Day” commemoration was obtained 1996 onwards and analyzed using topic modeling.As a result of the analysis, all the presidents’ speeches were delivered with a view of the ocean that was consistent with the direction of their administration. It was confirmed that the ocean-industry-resource topics, which are the intrinsic values of the ocean, were not damaged and consistently emphasized by all presidents."
자연어 기술 기반 한의 증상명 추천 시스템 (소화기계 질환 버전),2020,"['CDSS', 'Text mining', 'Text classification', 'Korean medicine', 'Symptom recommendation']","최근 다양한 정보통신 및 인공지능 기술들이 의료 서비스의 수준을 향상시기기 위해 연구되고 있다. 한의학 분야에서도 관련 연구자들이 다양한 연구를 수행하고 있다. 임상 한의사는 망문문절을 통해서 얻어진 환자의 정보와 다년간의 진료 경험을 통합해서 환자 변증을 특정하고 환자 상태에 맞는 처방을 결정한다. 이를 모사하여 알고리즘에 기반한 병증의 탐색 및 치료 추천을 위한 다양한 모델이 제안되어왔다. 증상특정-처방추천으로 이어지는 모델은 가장 널리 연구되어오던 접근 방법 중 하나이다. 그러나 한의 용어는 매우 광범위하고 한의 학파마다 사용하는 용어에 차이가 있기에 개발된 시스템의 원활한 이용에 한계가 있다. 따라서 우리는 환자의 상태와 관련한 자연어 기술로 부터 관련성이 높은 한의 증상명을 추천해주는 시스템을 개발했다. 이를 위해서 소화기계 질환을 가진 환자를 모집하고 환자의 상태를 자연어로 기술한 데이터를 만들었다. 한의 학파별 한의사들은 환자의 질병과 연관성이 큰 증상들을 선별하고 그 증상의 근거가 되는 자연어 기술 부분을 태깅해주었다. 이 데이터는 한글 형태소 분석 및 Multi-level support vector machine (SVM) 모델에 기반한 시스템의 입력 데이터로 활용되었다. 모델 성능 평가를 위해 5-fold cross validation 사용되었고 한의사들이 설정한 증상명이 학습 모델에서 어느정도 우선순위로 예측되었는지를 바탕으로 Area under curve (AUC) 값으로 계산했다. 전반적인 성능은, 사상체질의학회의 경우 93%의 AUC값을 보였고 대한형상의학회의 경우 94%의 AUC값을 보였다. 대한상한금궤의학회의 경우 85%의 AUC값을 보였다. 우리의 자연어 기반 증상명 추천 시스템은 한의 증상명 탐색의 편의성을 증진시켜 한의사들의 시스템 접근성을 도울 수 있다. SVM 모델을 바탕으로 만들어진 우리의 시스템은 이후 딥러닝에 기반한 고수준의 모델로 확장하여 성능의 향상을 도모하거나 다양한 질환들로 확장될 수 있다.",
Super-resolution Convolutional Neural Network를 이용한 전산화단층상의 화질 평가,2020,"['초고해상도 합성곱 신경망', '초 매개 변수', '전산화단층촬영', '영상 화질', 'Super-resolution convolutional neural network', 'Hyperparameter', 'Computed tomography', 'Image quality']","고화질의 전산화단층촬영상을 통해 정확한 병변 검출과 진단을 할 수 있다. 이와 같은 장점 때문에 전산화단층촬영 시 방사선량을 줄이면서 영상 화질을 개선하기 위해 많은 연구가 수행되었다. 최근 전산화단층촬영상 화질을 향상시키기 위한 딥러닝 기반 기술이 개발되었고, 기존의 기술에 비해 우수한 성능을 보이고 있다. 본 연구에서는 전산화단층촬영상의 공간분해능을 향상시키기 위해 초고해상도 합성곱 신경망 모델을 사용하였으며, 초고해상도 합성곱 신경망 모델의 성능을 결정하는 초 매개 변수 변화에 따른 영상 화질을 평가하여 초고해상도 합성곱 신경망 모델에 대한 초 매개 변수의 효과를 검증하였다. Profile, 구조적 유사성 지수, 최대신호 대 잡음비 및 반치폭을 측정하여 초 매개 변수 변화에 따른 초고해상도 합성곱 신경망 모델의 성능을 평가하였다. 연구결과, 초고해상도 합성곱 신경망 모델의 성능은 epoch와 training set이 증가함에 따라 향상되었으며, 전산화단층촬영상 화질을 향상시키기 위해 learning rate 최적화가 필요하다는 사실을 확인하였다. 따라서 최적의 초 매개 변수와 함께 구현된 초고해상도 합성곱 신경망 모델은 전산화단층촬영상의 품질을 향상시킬 수 있다.","High-quality computed tomography (CT) images enable precise lesion detection and accurate diagnosis. A lot of studies have been performed to improve CT image quality while reducing radiation dose. Recently, deep learning-based techniques for improving CT image quality have been developed and show superior performance compared to conventional techniques. In this study, a super-resolution convolutional neural network (SRCNN) model was used to improve the spatial resolution of CT images, and image quality according to the hyperparameters, which determine the performance of the SRCNN model, was evaluated in order to verify the effect of hyperparameters on the SRCNN model. Profile, structural similarity (SSIM), peak signal-to-noise ratio (PSNR), and full-width at half-maximum (FWHM) were measured to evaluate the performance of the SRCNN model. The results showed that the performance of the SRCNN model was improved with an increase of the numbers of epochs and training sets, and the learning rate needed to be optimized for obtaining acceptable image quality. Therefore, the SRCNN model with optimal hyperparameters is able to improve CT image quality."
CCTV 동영상 이벤트 태깅을 위한 HTML 5 웹 브라우저 기반 메타데이터 저작도구 개발,2020,"['CCTV', 'event', 'video summary', 'HTML5', 'meta-data', 'tagging tool', 'CCTV', '이벤트', '비디오 요약', 'HTML5', '메타데이터', '저작도구']","최근 범죄예방, 교통안전 등의 다양한 목적으로 감시 카메라가 보급되고 있으며, 그에 따라 CCTV를 통해 생성되는 비디오 데이터의 양이 기하급수적으로 증가하고 있다. 이 CCTV 비디오 데이터를 다양한 이벤트를 자동으로 감지하도록 훈련된 딥러닝 모델의 학습 데이터로 활용하기 위해서 이벤트 타임 스탬프와 클래스 레이블을 기술한 메타데이터를 CCTV 비디오 데이터에 첨부해야 한다. 그러나, 이러한 메타데이터를 수동으로 CCTV 영상에 첨부하는 것은 많은 시간 비용이 요구되기 때문에, 사용하기 쉽고 효율적으로 메타데이터를 생성할 수 있는 저작도구가 필요하다. 본 논문은 사용자가 이벤트가 발생한 구간을 신속하게 찾을 수 있도록 CCTV 비디오의 원하는 구간의 비디오 요약을 제공하며, 그리고 오류의 여지가 있는 모듈[1,2]을 통해 자동으로 생성되는 메타데이터를 수정하여 CCTV 비디오의 메타데이터를 효과적으로 생성하는 HTML5 웹 브라우저 기반의 메타데이터 저작도구를 제안한다.","Recently, surveillance cameras are distributed for various purposes such as for crime prevention and traffic safety, and as a result, the volume of video data generated through CCTV is increasing exponentially. In order to use this CCTV video data as the training data of deep learning that is trained to detect various events automatically, the meta-data describing the time stamp and class label of event should be attached to CCTV video data. However, attaching these meta-data to CCTV video manually is a very time-consuming tasks, so that an easy-to-use meta-data tagging tool is required to generate the meta-data for CCTV video events efficiently. This paper proposes a meta-data tagging tool running on HTML5-enabled Web browser that provides a video summary of the desired section of the CCTV video so that authors can quickly find the section of CCTV video where the event is occurred, and effectively generate the metadata of the CCTV video by modifying the meta-data that are automatically generated by some analysis modules [1,2] that may have errors."
"약물 부작용, 오남용 방지를 위한 의약품 정보 어플리케이션 디자인 분석 및 제언 -‘약학정보원’ 어플리케이션 중심으로-",2020,"['Mobile Application (모바일 어플리케이션)', 'Medicine Application Design (의약품 어플리케이션 디자인)', 'UI Design(UI 디자인)', 'Drug Side Effects (약물 부작용)', 'Drug Abuse(약물 오남용)']","‘안전상비의약품’의 판매 이후 약물 복용에 대한 통제의 어려움과 약물 부작용, 오남용의 문제가 늘어가고 있는 현실에서 본 연구는 이를 해결하기 위한 의약품의 효율적인 구매와 안전한 복약, 정확한 정보 전달을 위한 ‘약학정보원’의 UI/UX 어플리케이션 디자인 방안을 제시하는 것을 목적으로 한다. 연구범위는 IOS, 안드로이드 환경의 5가지 국내 의약품 어플리케이션을 선정, 디자인과 사용자경험, 목표 약품에 대한 검색 및 검색결과에 대한 UI/UX 항목이다. 연구 방법으로는 실증 사례분석과 제이콥 닐슨(Jakob Nielsen)의 ‘사용성 평가’, 사용자동향 평가 방식을 활용하였다. 그중 의약품 어플리케이션의 주요 기능인 의약품검색-결과에 대한 반응 효과를 이용하였다.  연구결과는 다음과 같다. 의약품 어플리케이션은 가시성, 직관성, 정확성, 일관성이 중요한 요소임을 알 수 있었고 대부분의 어플리케이션이 소비자의 복용 약 이력을 관리하는 회원체계가 부족했으며, 주 기능인 의약품검색에서 약품명을 모르는 사용자를 위한 이미지검색 기능 디자인이 부족했다. 또한 대부분이 푸른색–무채색의 컬러를 사용하고 있음을 알 수 있다. ‘약학정보원’에서의 미흡한 점은 아이콘의 디자인적 결함, 내비게이션 바의 미흡(가시성 부족), 에러 창의 부재, 주 사용메뉴 등록기능 부재(효율성 부족), Main Page의 불필요한 요소 사용(심미성 부족), 페이지 전환 버튼의 미흡, 사용 가이드의 부재가 있다. 이로 인한 디자인 방향 제언은 첫째, 이해성이 높고 통일감 있는 시각적 아이콘의 리디자인이 필요하다. 둘째, 약제검색 페이지에서의 다양하고 통일된 검색기능을 이용하여 사용자의 편의를 도와야 한다. 추가로 인공지능의 딥러닝 기술을 이용한 ‘사진검색’ 기능을 추가하기를 제언한다. 셋째, 약제설명 페이지에서 정보 제공과 동시에 페이지 레이아웃에 집중하여 가독성을 높여야 한다. 넷째, 복약지도에 있어, 가독성을 위한 ‘인포그래픽’ 사용을 제안한다. 다섯째, 사용자의 복약 이력 관리가 가능한 회원체계로 변경해야 한다. 본 연구를 통해 사용자의 안전한 의약품 복용 생활에 도움을 주는 것에 본 논문의 의의가 있다.","Pharmaceuticals are an important medium for maintaining the health and wellbeing for mankind. However, inappropriate administration and knowledge may result in risk of adverse reaction. As there are now ‘Safety Emergency Drugs’ sold outside the pharmacy for convenience of the consumers, it is difficult to control the drug administration, which is leading to more issues of adverse drug reaction and drug abuse. The purpose of this study is to provide the UI and UX design method to ‘Korea Pharmaceutical Information Center’ for efficient purchase of the drugs, safe administration and accurate delivery of information by using the application with good accessibility for the consumer to reduce the adverse drug reaction and drug abuse. For the scope of this study, 5 Korean pharmaceutical applications in IOS and Android environment were selected, and the design, user experience, search on target drug, and UI and UX items on the search results are included.  Empirical case analysis, ‘Usability Evaluation’ by Jakob Nielsen and trend evaluation method were used as the study method. Among these methods, the reaction effect on drug search-result which is the main function of the pharmaceutical application was used.  The results of this study are shown as follows. It was verified that the significant factors of pharmaceutical application were visibility, accuracy and consistency, and most of the applications lacked the membership system of managing the history of drugs administered by the consumers. In addition, the main function of drug search lacked the design on the image search function for users that do not know the drug name. Moreover, most of the applications were using blue-achromatic color. Insufficient matters in the ‘Korea Pharmaceutical Information Center’ included design fault on the icon, absence of navigation bar (poor visibility), error window and frequent menu registration function (poor efficiency), use of unnecessary elements on the main page (poor aesthetic impression), poor page conversion button and absence of use guide. Regarding the suggestion on the design direction, first, the re-design of an icon that is visible, highly understandable and with unity is required. Second, various search functions shall be used on the drug search page to support the convenience of the users. Additionally, the use of AI deep learning technology to add the ‘Image Search’ function is suggested. Third, the drug description page shall provide not only the information on the drug, but also be focused on the page layout to enhance the legibility. Fourth, the use of ‘Infographic’ is suggested for legibility on the medication counseling. Fifth, the application shall be changed to the membership system to enable mediation history management of the users. The significance of this study is to help the safe administration of drugs by the users."
순환인공신경망을 활용한 터널굴착면 전방 Q값 예측에 관한 연구,2020,"['Rock mass classification', 'Q-value', 'Recurrent neural network', 'Tunnel ahead prediction', '암반분류', 'Q값', '순환인공신경망', '터널굴착면 전방예측']","터널 굴착 시 정확한 암반 분류는 적합한 지보패턴을 설치하는 데 도움을 준다. 암반의 분류를 위해 주로 RMR (Rock Mass Ration)과 Q값을 산정하여 수행되며, 페이스 매핑(face mapping)을 바탕으로 산정된다. 점보드릴 및 프로브드릴의 기계 데이터을 활용하거나 딥러닝을 활용한 굴착면 사진 분석 등의 방법이 암반등급 분류를 예측하기 위해 사용되고 있으나, 분석 시 오랜 시간이 소요되거나, 굴착면 전방의 암반등급을 파악할 수 없다는 점에서 한계를 갖는다. 본 연구에서는 순환인공신경망(Recurrent neural network, RNN)을 활용하여 굴착면 전방의 Q값을 예측하는 방법을 개발하였고 페이스 매핑으로부터 획득한 Q값과 비교/검증하였다. 4,600여개의 굴착면 데이터 중 70%를 학습에 활용하였고, 나머지 30%는 검증에 사용하였다. 학습의 횟수와 학습에 활용한 이전굴착면의 개수를 변경하여 학습을 수행하였다. 예측된 Q값과 실제 Q값의 유사도는 RMSE (root mean square error)를 기준으로 비교하였다. 현재 굴착면과 바로 직전의 굴착면의 Q값을 활용하여 600회 학습하여 예측한 Q값의 RMSE값이 가장 작은 것을 확인하였다. 본 연구의 결과는 학습에 사용한 데이터 값 등이 변화하는 경우 변화할 수 있으나 터널에서의 이전 지반상태가 앞으로의 지반상태에 영향을 미치는 시스템을 이해하고, 이를 통해 터널 굴착면 전방의 Q값의 예측이 가능할 것으로 판단된다.","Exact rock classification helps suitable support patterns to be installed. Face mapping is usually conducted to classify the rock mass using RMR (Rock Mass Ration) or Q values. There have been several attempts to predict the grade of rock mass using mechanical data of jumbo drills or probe drills and photographs of excavation surfaces by using deep learning. However, they took long time, or had a limitation that it is impossible to grasp the rock grade in ahead of the tunnel surface. In this study, a method to predict the Q value ahead of excavation surface is developed using recurrent neural network (RNN) technique and it is compared with the Q values from face mapping for verification. Among Q values from over 4,600 tunnel faces, 70% of data was used for learning, and the rests were used for verification. Repeated learnings were performed in different number of learning and number of previous excavation surfaces utilized for learning. The coincidence between the predicted and actual Q values was compared with the root mean square error (RMSE). RMSE value from 600 times repeated learning with 2 prior excavation faces gives a lowest values. The results from this study can vary with the input data sets, the results can help to understand how the past ground conditions affect the future ground conditions and to predict the Q value ahead of the tunnel excavation face."
신경망을 이용한 세일링 요트 리제너레이션 시스템의 배터리 충전 예측,2020,"['신경망', '완전연결구조', '데이터 예측', '배터리 충전', '세일링 요트', '해양레저', 'Neural network', 'Fully connected', 'Data prediction', 'Battery charge', 'Sailing yacht', 'Marine leisure']","본 논문에서는 해양 전기추진 시스템과 딥러닝 알고리즘을 융합하여 전기추진 리제너레이션 시스템에서 DC/DC 컨버터 출력 전류 예측 및 리제너레이션 수행 시 배터리 충전량을 예측하기 위해 신경망 모델을 제안한다. 제안 된 신경망을 실험하기 위해 PCM의 입력 전압과 전류를 측정하고 시제품 PCM 보드의 출력 결과를 통해 데이터 세트를 구성하였다. 또한 불충분 한 데이터 세트에서 학습 결과를 향상시키기 위해 기존 데이터 세트를 데이터 피팅하여 학습을 진행하였다. 학습 후 신경망 모델의 데이터 예측 결과와 실제 측정 데이터의 차이를 그래프를 통해 확인하였다. 제안한 신경망 모델은 입력 전압과 전류 변화에 따른 배터리 충전량 예측을 효율적으로 보여주었다. 또한, DC/DC 컨버터를 구성하는 아날로그 회로의 특성변화를 신경망을 통하여 예측함으로써, 리제너레이션 시스템의 설계 시, 아날로그 회로의 특성을 고려해야 할 것으로 판단된다.","In this paper, we propose a neural network model to converge the marine electric propulsion system and deep learning algorithm to predict the DC/DC converter output current in the electric propulsion regeneration system and to predict the battery charge during regeneration. In order to experiment with the proposed neural network, the input voltage and current of the PCM were measured and the data set was secured on the prototype PCM board. In addition, in order to improve the learning results in the insufficient data set, the scale of the data set was increased through data fitting and its learning was executed further. After learning, the difference between the data prediction result of the neural network model and the actual measurement data was compared. The proposed neural network model effectively showed the prediction of battery charge according to changes in input voltage and current. In addition, by predicting the characteristic change of the analog circuit constituting the DC/DC converter through a neural network, it is determined that the characteristics of the analog circuit should be considered when designing the regeneration system."
이동 객체 검출을 통한 승객 인원 개수에 대한 연구,2020,"['Moving Object Detection', 'Object Contours Detection', 'Bus Passenger Counting', '이동 객체 검출', '객체 윤곽선 검출', '버스 승객 개수']",영상 처리 기법을 이용한 영상 인식 분야는 버스 승차 및 하차 시에 승객을 움직이는 객체로 검출하고 개수하는 방법이 연구되고 있다. 이러한 기술 중에는 인공지능 기법의 하나인 딥러닝 기법이 사용되고 있다. 또 다른 방법으로 스테레오 비전 카메라를 이용하여 객체를 검출하는 방법도 사용되고 있다. 그러나 이러한 방법들은 객체를 검출할 때 사용되는 장비의 연산량이 많이 들어 고가의 하드웨어 장비가 필요하다. 그러나 대중교통 중 하나인 버스 승객을 검출하기 위해 상대적으로 연산량이 적은 기법을 이용하여 다양한 장비에 맞는 영상 처리 기술이 필요하다. 이에 본 논문에서는 다양한 장비에 맞는 이동 객체 검출 기법 중 배경 제거를 통한 객체의 윤곽선을 검출하여 대중교통 중의 하나인 버스에 탑승객의 수를 효율적으로 획득 할 수 있는 기법을 제안한다. 실험 결과 스테레오 비전을 장착한 장비보다 더 저사양의 장비에서 약 70%의 정확도로 승객을 개수하였다.,"In the field of image processing, a method of detecting and counting passengers as moving objects when getting on and off the bus has been studied. Among these technologies, one of the artificial intelligence techniques, the deep learning technique is used.As another method, a method of detecting an object using a stereo vision camera is also used. However, these techniques require expensive hardware equipment because of the computational complexity of used to detect objects. However, most video equipments have a significant decrease in computational processing power, and thus, in order to detect passengers on the bus, there is a need for an image processing technology suitable for various equipment using a relatively low computational technique. Therefore, in this paper, we propose a technique that can efficiently obtain the number of passengers on the bus by detecting the contour of the object through the background subtraction suitable for low-cost equipment. Experiments have shown that passengers were counted with approximately 70% accuracy on lower-end machines than those equipped with stereo vision camera."
비직교 다중변조 방식을 이용한 고속 가시광통신 시스템에 대한 연구,2020,"['가시광통신', '융합기술', '고속전송', '무선광통신', '비직교전송', 'Visible light communication', 'Convergence technology', 'High speed transmission', 'Wireless optical communication', 'Non-orthogonal transmission']","본 논문에서는 가시광 통신시스템에서 고속 전송을 위한 변조 기법에 대해서 분석하고, 최적의 비직교 다중 전송을 위한 Dimming level 및 송신 전력 비율에 대해서 연구하였다. 기존의 가시광 통신은 전송 속도를 높이기 위한 멀티전송이 어렵다는 단점이 있다. 송신단에서 고속 전송을 위해서는 반드시 다중 전송기법이 필요한데, 일반적인 가시광 통신은 다중 전송에 한계가 있기 때문에 고속 전송을 위한 다양한 연구가 진행되고 있다. 최근에는 이미지 센서인 Optical Camera Communication(OCC)을 가시광 통신에 적용한 VLC-OCC가 연구되어 기존 가시광 통신이 가지는 다중 전송의 한계를 극복하였다. 그러나 VLC-OCC 방식은 외부 조도의 영향을 더 많이 받고, 수신단에서 검출이 어렵다는 단점이 있다. 또한, 다중 전송을 위한 LED 매트릭스의 위치 인식과 딥러닝을 위한 데이터 셋 신호처리를 위한 Processing-time이 필요하기 때문에 시스템의 복잡도가 증가하게 된다. 이러한 문제를 해결하기 위해 본 논문에서는 비직교 다중 전송 방식을 적용한 고속 가시광 통신을 위한 다중 변조 방식과 그에 따른 향후 연구 방향을 제안하였다.","In this paper, we analyze the modulation scheme for high speed transmission in visible light communication system, and study non-orthogonal multiplexing, dimming level and transmission power ratio. Conventional visible light communication has a disadvantage in that it is difficult to multi-transmit to increase the transmission speed. Multi-transmission technique is necessary for high-speed transmission at the transmitter. Since general visible light communication has a limitation in multiple transmission, various researches for high-speed transmission have been conducted. In order to solve this problem, this paper proposes a multiple modulation scheme for high-speed visible light communication using non-orthogonal multiplex transmission scheme and a future research direction."
인공지능 기반의 데이터 분석을 적용한 건강검진 지식 베이스 구축 모델링 연구,2020,"['Health medical examination', 'Knowledge base', 'Artificial intelligence', 'Data analysis', 'Healthcare platform', '건강검진', '지식베이스', '인공지능', '데이터분석', '헬스케어 플랫폼']","미래 사회로 접어들면서, 건강한 삶의 증대를 위한 노력은 현대인들의 주요 관심 분야이다. 특히, ICT 기술과 경쟁력 있는 의료산업 환경을 융합하여 건강한 삶을 위한 기술 개발은 차세대 성장 동력으로 자리잡고 있다. 따라서, 본 논문에서는 건강 검진 프로세스에서 검진 결과에 대한 인공지능 기반의 데이터 분석을 적용하여 종합 판정의 신뢰성을 향상시킬 수 있는 지식 베이스 모델링을 구축하는 연구를 수행하였다. 이를 위해, 딥러닝 분석을 통한 알고리즘을 설계하여 검사 결과지수를 산출, 검증하고, 판정 지식을 통한 종합 검진 정보를 제공하는 모델링을 연구하였다. 제안한 모델링의 적용을 통해, 국민 건강에 대한 빅데이터 분석, 활용이 가능하여 의료비 절감 및 건강 증대의 효과를 기대할 수 있다.","As we enter the society of the future, efforts to increase healthy living are a major area of concern for modern people. In particular, the development of technology for a healthy life that combines ICT technology with a competitive healthcare industry environment is becoming the next growth engine. Therefore, in this paper, artificial intelligence-based data analysis of the examination results was applied in the health examination process. Through this, a research was conducted to build a knowledge base modeling that can improve the reliability of the overall judgment. To this end, an algorithm was designed through deep learning analysis to calculate and verify the test result index. Then, the modeling that provides comprehensive examination information through judgment knowledge was studied. Through the application of the proposed modeling, it is possible to analyze and utilize big data on national health, so it can be expected to reduce medical expenses and increase health."
발달장애인을 위한 커뮤니케이션과 언어 학습 증진을 위한 인공지능 서비스,2020,"['Augmentative and Alternative Communication', 'Pictogram', 'Grammar Error Correction', 'Developmental disabilities', 'Natural Language Processing', '보완대체 의사소통', '픽토그램', '영문법교정', '언어발달 장애', '자연어처리']","언어발달 장애를 가진 아동들은 일상생활 및 사회생활에서 많은 어려움을 겪으며 이는 생애 전반을 걸쳐 지속된다. 언어발달 장애 아동들은 의사소통 수단인 언어를 이해하거나 사용하는 데에 어려움을 겪기 때문에 종종 사회적 활동에 참여할 기회를 박탈당하곤 한다. 이와 관련해서 Augmentative and Alternative Communication(AAC, 보완대체 의사소통)는 언어장애를 앓는 이들에게 실직적인 의사소통 수단으로 사용될 수 있다. 본 논문은 픽토그램을 AAC의 수단으로써 최대한 활용하여 언어발달 장애 아동이 타인과 의사소통하고 언어 이해 능력을 향상시킬 수 있도록 돕는 딥러닝 기반 인공지능 서비스를 제안한다. 본 서비스를 통해 언어 문제를 겪고 있는 이들이 자신의 의도 혹은 욕구를 보다 수월하게 표현하여 삶의 질이 향상 될 수 있을 것으로 기대한다.","Children with language developmental disabilities often struggle through their lives from a lot of challenges in everyday life and social activities. They’re often easily deprived of the opportunity to engage in social activities, because they find difficulty in understanding or using language, a core means of communication. With regard to this issue, AAC(Augmentative and Alternative Communication) can be an effective communication tool for children who are suffering from language disabilities. In this paper, we propose a deep learning-based AI service to make full use of the pictogram as an AAC tool for children with language developmental disabilities to improve not only the ability to interact with others but the capacity to understand language. Using this service, we strive to help these children to more effectively communicate their intention or desire and enhance the quality of life."
자율주행자동차와 제조물 책임에 관한 연구 - 최근 자동차관리법 일부 개정에 즈음하여 -,2020,"['제조물책임', '자율주행자동차', '자율주행시스템', '설계상의 결함', '표시상의결함', '자동차관리법', 'The Product Liability Act', 'self-driving cars', 'self-driving system', 'the Automobile Management Act', 'design defects', 'warning defects.']","본고에서는 자율주행자동차 사고의 경우 제조물책임법의 실효성을 보장하기 위한 방안을 마련하기 위하여 동법상의 결함의 유형과 문제점 등을살펴보고, 이와 관련하여 자동차관리법, 자동차규칙, 부분 자율주행시스템의 안전기준 및 자동차관리법 일부 개정안 등을 검토하면서 자율주행자동차의 결함에 대한 자동차제작자의 책임 추궁을 위한 제도적 보완의 필요성과 몇 가지 대안을 제시하였다.첫째, 자율주행자동차 사고의 경우에는 제조물책임법상의 “결함추정” 규정만으로는 피해자가 동 자동차의 결함을 입증하는 데는 한계가 있으므로아예 입증책임을 전환하여 자동차제작자가 자율주행시스템 상에 결함이없었다는 점을 입증하도록 함으로써 자동차제작자의 책임을 강화할 필요가 있다고 보았다. 동 자동차의 결함은 대부분이 자율주행시스템의 오작동에 의하여 발생하고, 특별한 사정이 없는 한 자동차제작자의 실질적 지배영역에 있다는 점을 고려하면 이것이 특히 동 자동차제작자에게 불합리하다고 볼 수 없을 것이다. 둘째, 자동차관리법 제31조 제1항은 자동차 및자동차부품에 결함이 있는 경우에 시정조치를 하도록 규정하고 있으나 자율주행자동차의 자율주행시스템에 대한 업데이트는 동 시스템의 결함여부와 상관없이 지속적으로 이루어져야 할 것이므로 이를 의무화할 필요가있다고 보았다. 자율주행시스템은 기계학습(machine learning)을 의하여새로운 운행환경에 대한 데이터를 추가적으로 학습함으로써 자동차를 안전하게 운행하도록 설계되어 있으므로 동 시스템의 성능개선과 안전성 확보를 위하여 지속적인 업데이트가 필수적으로 요구되기 때문이다. 셋째, 제조물의 결함을 입증하기 위한 자료가 대부분 제조업자의 수중에 있다는점을 고려하면 제조업자나 제조업자를 위하여 문서를 소지하고 있는 자는원고 측의 문서제출요구를 정당한 이유 없이 거절하지 못하도록 할 필요가 있다고 보았다. 자동차관리법 일부 개정안은 원고와 법원에게 자동차의성능시험대행자에 대한 정보제출요구권을 인정하고 있으나 아예 제조물책임법에 문서제출명령의 실효성 확보를 위한 규정을 도입하는 것이 바람직하다고 할 것이다. 넷째, 자율주행시스템의 결함을 조사하기 위한 전문조사기관의 설립할 필요성이 있다고 보았다. 자율주행시스템의 소프트웨어는 기계학습과 딥러닝 기술에 의하여 자동차를 최적 상태로 운행하기 위한 값을 도출하므로 동 분야의 고도의 지식을 가진 전문가가 아닌 한, 동시스템의 결함여부를 밝혀내는 것이 거의 불가능하기 때문이다. 다섯 째, 자율주행자동차 사고에 대하여 제조물책임범의 적용 가능성에 대하여 논란이 되는 이유가 동 자동차 사고의 원인을 밝히는 것이 쉽지 않다는 데있다는 점을 고려하면 동 자동차 사고 전후의 기록은 동 자동차 사고의원인을 밝히는 데에 중요한 자료가 될 수 있으므로 자율주행자동차의 경우에는 “사고기록장치”의 장착을 의무화할 필요가 있다고 보았다.","The Product Liability Act is designed to protect victims and promote the safety of users’ lives by stipulating that manufacturers and others are responsible for damages caused by defects in their products.Accordingly, the law should be able to protect the victim by assigning the manufacturer appropriate liability for damages such as life, body or property resulting from defects in manufacturing products. The law should be applied to damage caused by defects of self-driving cars.However, since the law was not enacted with the introduction of engineering machines with a high level of thinking or judgment ability as that of humans, it is very difficult for victims to ask manufacturers of self-driving cars to be responsible for manufacturing defects. Among other things, this is because it is not easy for victims to prove that the damage was caused by the defects of the cars.Therefore, in order to ensure the effectiveness of the Product Liability Act for self-driving car accidents, in this regard, this paper examines the present Product Liability Act and the Rules on the Performance and Standards of the Automobile and Auto Parts, the safety standards of the partial self-driving system, and then tries to present the need for and alternatives to hold a manufacturer accountable for the defects of self-driving cars."
국가 과학기술 표준분류 체계 기반 연구보고서 문서의 자동 분류 연구,2020,"['Deep Learning', 'Text Classification', 'Research Report', 'Preprocessing', 'NTIS']","과학기술 분야의 연구·개발 결과는 연구보고서 형태로 국가과학기술정보서비스(NTIS)에 제출된다. 각 연구보고서는 국가과학기술 표준 분류체계 (K-NSCC)에 따른 분류코드를 가지고 있는데, 보고서 작성자가 제출 시에 수동으로 입력하게끔 되어있다. 하지만 2000여 개가 넘는 세분류를 가지고 있기에, 분류체계에 대한 정확한 이해가 없이는 부정확한 분류코드를 선택하기 십상이다. 새로이 수집되는 연구보고서의 양과 다양성을 고려해 볼 때, 이들을 기계적으로 보다 정확하게 분류할 수 있다면 보고서 제출자의 수고를 덜어줄 수 있을 뿐만 아니라, 다른 부가 가치적인 분석 서비스들과의 연계가 수월할 것이다. 하지만, 국내에서 과학기술표준 분류체계에 기반을 둔 문서 자동 분류 연구 사례는 거의 없으며 공개된 학습데이터도 전무하다. 본 연구는 KISTI가 보유하고 있는 최근 5년간 (2013년~2017년) NTIS 연구보고서 메타정보를 활용한 최초의 시도로써, 방대한 과학기술표준 분류체계를 기반으로 하는 국내 연구보고서들을 대상으로 높은 성능을 보이는 문서 자동 분류기법을 도출하는 연구를 진행하였다. 이를 위해, 과학기술 표준분류 체계에서 과학기술 분야의 연구보고서를 분류하기에 적합한 중분류 210여 개를 선별하였으며, 연구보고서 메타 데이터의 특성을 고려한 전처리를 진행하였다. 특히, 가장 영향력 있는 필드인 과제명(제목)과 키워드만을 이용한 TK_CNN 기반의 딥러닝 기법을 제안한다. 제안 모델은 텍스트 분류에서 좋은 성능을 보이고 있는 기계학습법들 (예, Linear SVC, CNN, GRU등)과 비교하였으며, Top-3 F1점수 기준으로 1~7%에 이르는 성능 우위를 확인하였다.","In South Korea, the results of R&D in science and technology are submitted to the National Science and Technology Information Service (NTIS) in reports that have Korea national science and technology standard classification codes (K-NSCC). However, considering there are more than 2000 sub-categories, it is non-trivial to choose correct classification codes without a clear understanding of the K-NSCC. In addition, there are few cases of automatic document classification research based on the K-NSCC, and there are no training data in the public domain. To the best of our knowledge, this study is the first attempt to build a highly performing K-NSCC classification system based on NTIS report meta-information from the last five years (2013-2017). To this end, about 210 mid-level categories were selected, and we conducted preprocessing considering the characteristics of research report metadata. More specifically, we propose a convolutional neural network (CNN) technique using only task names and keywords, which are the most influential fields. The proposed model is compared with several machine learning methods (e.g., the linear support vector classifier, CNN, gated recurrent unit, etc.) that show good performance in text classification, and that have a performance advantage of 1% to 7% based on a top-three F1 score."
"인플루언서의 ‘뒷광고’ 논란 전,후에 대한 댓글 비교 분석:LDA와 Word2vec을 중심으로",2020,"['인플루언서', '뒷광고', '댓글', 'LDA', 'word2vec', 'Influencer', 'Back Advertising', 'Comment', 'LDA', 'Word2vec']","최근 유명 유튜버들이 간접광고(PPL)등 협찬, 광고를 받은 영상을 제작, 방영하면서 유료광고라고 밝히지 않은 일명 ‘뒷광고’ 논란이 이어지며 유명 유튜버뿐만 아니라 연예인들까지 논란 속에 속해 있어 진실성에 대한 대중들의 혼란을 야기시키고 있다. 본 연구는 유튜버들의 ‘뒷광고’ 논란의 전과 후의 대중들의 반응을 댓글 분석을 통해 알아보고자 한다. 구체적으로 R 프로그램을 활용한 텍스트 분석 중 워드 클라우드, LDA, 딥러닝 기법 word2vec 분석과 같은 다양한 방식으로 분석하고자 한다. 분석 대상은 ‘뒷광고’ 유튜버 논란에 속해 있고 ‘사과 영상’을 업로드한 3명의 유튜버 채널을 분석해 보기로 했다. 가장 먼저 논란되었던 슈스스 TV의 한혜연 스타일리스트와 콘텐츠 성향이 비슷하면서 100만 명이 넘는 구독자 수를 보유한 먹방 유튜버 문복희와 다양한 콘텐츠를 선보인 유튜버 양팡의 가장 최신 영상 5개(2020년 08월 09일 기준)와 처음에 올린 영상 5개를 기준으로 댓글을 분석하였다. 연구결과 논란 전에는 대부분 긍정적인 반응을 보인 댓글들이 대부분이었으나, 논란 후에는 부정적인 반응이 대부분을 차지하였고, 예전의 논란까지 같이 나타나고 있음을 볼 수 있었다. 따라서 본 연구는 R프로그램을 이용한 다양한 분석을 통해 ‘뒷광고’ 논란 이후에 인플루언서에 대한 대중들의 변화 정도를 댓글을 통해 알아봄과 동시에 앞으로는 인플루언서들의 뒷광고가 발생하지 않도록 다양한 방안을 제시하는데 그 의의가 있다.","Recently, as famous YouTubers produce and broadcast videos that receive sponsorship and advertising such as indirect advertising (PPL), a so-called 'back advertising' controversy continues, and not only famous YouTubers but also entertainers are caught up in the issue. It is causing confusion among the public in Korea. This study attempts to find out the public's reaction before and after the controversy of 'back advertising' by YouTubers through comment analysis. Specifically, among text analysis using R programs, we intend to analyze the issue through various methods such as word cloud, qgraph analysis, LDA, and word2vec analysis, a deep learning technique. The target of the analysis was to analyze the channels of three YouTubers who belonged to the controversy of the 'back advertising' YouTuber and uploaded the 'Apology video'. The 5 most recent videos of Muk-bang YouTuber Moon Bok-hee, who has a similar content disposition to SussTV's Han Hye-yeon stylist, which was controversial, and Yang Pang, a YouTuber who showed various contents (August 09, 2020) Criterion and her first 5 videos uploaded were reviewed. As a result of the study, most of the comments that showed positive reactions before the controversy ,but after the controversy, it was found that negative reactions accounted for most of the comments. Therefore, this study examines the degree of change of the public about influencers through comments after the controversy over 'back advertising' through various analysis using R program. This research also devises various measures to prevent the occurrence of back advertising of influencers in the future."
정지궤도 기상위성 및 수치예보모델 융합을 통한 Multi-task Learning 기반 태풍 강도 실시간 추정 및 예측,2020,"['Tropical cyclone', 'Intensity forecasting', 'Multi-task learning', 'Convolutional Neural Networks', 'Geostationary satellite', 'Numerical forecasting model']","최근 기후변화로 인해 강도가 높은 태풍의 빈도가 높아짐에 따라 태풍 예측의 중요성이 강조되고 있는데, 태풍경로예측에 비해 태풍강도예측에 대한 연구는 미비한 상황이다. 이에 본 연구에서는 딥러닝 모델인Multi-task learning (MTL) 기법을 활용하여 정지궤도기상위성을 활용한 관측자료와 수치예보모델을 융합한 실시간 추정 및 6시간, 12시간 후의 태풍강도예측 모델을 제안하고자 한다. 본 연구에서는 2011년에서 2016년까지 북서태평양에서 발생한 총 142개의 태풍을 대상으로 강도 예측 연구를 시행하였다. 한국 최초의 기상위성인 Communication, Ocean and Meteorological Satellite (COMS) Meteorological Imager (MI)를 활용하여 태풍의 관측영상을 추출하였고, National Center of Environmental Prediction (NCEP)에서 제공하는 Climate Forecast System version 2 (CFSv2)를 활용하여 6시간, 12시간 후의 태풍 주변 대기 및 해양 예측변수를 추출하였다. 본 연구에서는 각 입력자료의 활용성을 정량화 하기 위하여, 위성 기반 태풍관측영상만을 활용한 MTL 모델(Scheme 1)과수치예보모델을 융합적으로 활용한 MTL 모델(Scheme 2)을 구축하고, 각 모델의 훈련 및 검증 성능을 정량적으로 비교하였다. 실시간 강도 추정의 결과 scheme 1과 scheme 2에서 비슷한 성능을 보이는 반면, 6시간, 12시간 후 태풍강도예측의 경우 scheme 2에서 각각 13%, 16% 개선된 결과를 보였다. 태풍 단계별 예측성능에 대한분석을 시행한 결과, 저강도 태풍일수록 낮은 평균제곱근오차를 보인 반면, 대부분의 강도 단계에서 평균제곱근편차비는 30% 미만의 값을 보이며 유의미한 검증 결과를 보였다. 이에 본 연구에서 제시한 두가지 모델을 기반으로 2014년 발생한 태풍 HALONG의 시계열검증을 시행하였다. 그 결과, scheme 1의 경우 태풍 초기발달단계에서 태풍의 강도를 약 20 kts가량 과대 추정하는 경향을 보이는데, 환경예측자료를 융합한 scheme 2에서는오차가 약 5 kts가량으로 과대 추정 경향이 줄어들었다. 본 연구에서 제시하는 현재, 6시간, 12시간 후 강도를 동시에 추출하는MTL 모델은 Single-tasking model 대비 약 300%의 시간 효율을 보이며, 향후 신속한 태풍 예보 정보 추출에 큰 기여를 할 수 있을 것으로 기대된다.","The accurate monitoring and forecasting of the intensity of tropical cyclones (TCs) are able to effectively reduce the overall costs of disaster management. In this study, we proposed a multi-task learning (MTL) based deep learning model for real-time TC intensity estimation and forecasting with the lead time of 6-12 hours following the event, based on the fusion of geostationary satellite images and numerical forecast model output. A total of 142 TCs which developed in the Northwest Pacific from 2011 to 2016 were used in this study. The Communications system, the Ocean and Meteorological Satellite (COMS) Meteorological Imager (MI) data were used to extract the images of typhoons, and the Climate Forecast System version 2 (CFSv2) provided by the National Center of Environmental Prediction (NCEP) was employed to extract air and ocean forecasting data. This study suggested two schemes with different input variables to the MTL models. Scheme 1 used only satellite-based input data while scheme 2 used both satellite images and numerical forecast modeling. As a result of real-time TC intensity estimation, Both schemes exhibited similar performance. For TC intensity forecasting with the lead time of 6 and 12 hours, scheme 2 improved the performance by 13% and 16%, respectively, in terms of the root mean squared error (RMSE) when compared to scheme 1. Relative root mean squared errors (rRMSE) for most intensity levels were less than 30%. The lower mean absolute error (MAE) and RMSE were found for the lower intensity levels of TCs. In the test results of the typhoon HALONG in 2014, scheme 1 tended to overestimate the intensity by about 20 kts at the early development stage. Scheme 2 slightly reduced the error, resulting in an overestimation by about 5 kts. The MTL models reduced the computational cost about 300% when compared to the single-tasking model, which suggested the feasibility of the rapid production of TC intensity forecasts."
음성특징의 거리에 기반한 한국어 발음의 시각화,2020,"['Feature Clustering', 'Korean Pronunciation', 'SOM-VAE', 'Speech Processing', 'Speech Visualization']","한국어는 자음과 모음과 같은 음소 단위의 발음은 고정되어 있고 표기에 대응하는 발음은 변하지 않기 때문에 외국인 학습자가 쉽게 접근할 수 있다. 그러나 단어와 어구, 문장을 말할 때는 음절과 음절의 경계에서 소리의 변동이 다양하고 복잡하며 표기와 발음이 일치하지 않기 때문에 외국어로서의 한국어 표준 발음 학습은 어려운 면이 있다. 그러나 영어 같은 다른 언어와 달리 한국어의 표기와 발음의 관계는 논리적인 원리에 따라 예외 없이 규칙화 할 수 있는 장점이 있으므로 발음 오류에 대해 체계적인 분석이 가능한 것으로 여겨진다. 본 연구에서는 오류 발음과 표준 발음의 차이를 컴퓨터 화면상의 상대적 거리로 표현하여 시각화하는 모델을 제시한다. 기존 연구에서는 발음의 특징을 단지 컬러 또는 3차원 그래픽으로 표현하거나 입과 구강의 변화하는 형태를 애니메이션으로 보여 주는 방식에 머물러 있으며 추출하는 음성의 특징도 구간의 평균과 같은 점 데이터를 이용하는데 그치고 있다. 본 연구에서는 시계열로 표현되는 음성데이터의 특성 및 구조를 요약하거나 변형하지 않고 직접 이용하는 방법을 제시한다. 이를 위해서 딥러닝 기법을 토대로 자기조직화 알고리즘과 variational autoencoder(VAE) 모델 및 마코브 확률모델을 결합한 확률적 SOM-VAE 기법을 사용하여 클러스터링 성능을 향상시켰다.","Korean language has the characteristics that the pronunciation of phoneme units such as vowels and consonants are fixed and the pronunciation associated with a notation does not change, so that foreign learners can approach rather easily Korean language. However, when one pronounces words, phrases, or sentences, the pronunciation changes in a manner of a wide variation and complexity at the boundaries of syllables, and the association of notation and pronunciation does not hold any more. Consequently, it is very difficult for foreign learners to study Korean standard pronunciations. Despite these difficulties, it is believed that systematic analysis of pronunciation errors for Korean words is possible according to the advantageous observations that the relationship between Korean notations and pronunciations can be described as a set of firm rules without exceptions unlike other languages including English. In this paper, we propose a visualization framework which shows the differences between standard pronunciations and erratic ones as quantitative measures on the computer screen. Previous researches only show color representation and 3D graphics of speech properties, or an animated view of changing shapes of lips and mouth cavity. Moreover, the features used in the analysis are only point data such as the average of a speech range. In this study, we propose a method which can directly use the time-series data instead of using summary or distorted data. This was realized by using the deep learning-based technique which combines Self-organizing map, variational autoencoder model, and Markov model, and we achieved a superior performance enhancement compared to the method using the point-based data."
비디오에서 인간 행동 인식을 위한 주의 모델 기반 잔류 주의 네트워크,2020,"['Deep Learning', 'Convolution Neural Network', 'Attention Mechanism', 'Video Processing', 'Action Recognition', '딥 러닝', '컨볼루션 신경망', '주의 메커니즘', '비디오 프로세싱', '행동 인식']","딥 러닝 기술의 발전과 컴퓨팅 파워 등의 개선으로 인해 비디오 기반 연구는 최근 많은 관심을 얻고 있다. 비디오 데이터가 이미지 데이터와 비교하여 가장 큰 차이는 비디오 데이터에는 많은 양의 시간적, 공간적 정보가 포함되어 있다는 점이다. 이처럼 비디오에 포함된 많은 양의 데이터로 인해 컴퓨터 비전 연구에 있어서 행동 인식은 중요한 연구 과제 중 하나이지만, 비디오와 같이 움직임이 있는 환경에서 인간의 행동 인식은 매우 복잡하고 도전적인 과제이다. 인간에 대한 여러 연구를 바탕으로 인공지능에서는 인간과 유사한 주의(attention)메커니즘이 효율적인 인식 모델이라는 것을 알게 되었다. 이 효율적인 모델은 이미지 정보와 복잡한 연속 비디오 정보를 처리하는 데 이상적이다. 본 논문에서는 이러한 연구배경을 기반으로, 비디오에서 인간의 행동을 효율적으로 인식하기 위해 먼저 인간의 행동에 주목한 후 비디오 행동 인식에 주의메커니즘을 도입하고자 한다. 논문의 주요내용은 두 가지 주의 메카니즘을 기반으로 컨볼루션 신경망을 이용한 새로운 3D 잔류 주의 네트워크를 제안함으로써 비디오에서 인간의 행동을 식별하고자 한다. 제안 모델의 평가 결과 최대 90.7%정도의 정확도를 보였다.","With the development of deep learning technology and advances in computing power, video-based research is now gaining more and more attention. Video data contains a large amount of temporal and spatial information, which is the biggest difference compared with image data. It has a larger amount of data. It has attracted intense attention in computer vision. Among them, motion recognition is one of the research focuses. However, the action recognition of human in the video is extremely complex and challenging subject. Based on many research in human beings, we have found that artificial intelligence-like attention mechanisms are an efficient model for cognition. This efficient model is ideal for processing image information and complex continuous video information. We introduce this attention mechanism into video action recognition, paying attention to human actions in video and effectively improving recognition efficiency. In this paper, we propose a new 3D residual attention network using convolutional neural network based on two attention models to identify human action behavior in the video. An evaluation result of our model showed up to 90.7% accuracy."
Self-Supervised Document Representation Method,2020,"['Deep Learning', 'Document Embedding', 'Pre-Trained Language Model', 'Self-Supervised Learning', 'Text Mining', '딥 러닝', '문서 임베딩', '사전 학습 언어 모델', '자기 지도 학습', '텍스트 마이닝']","최근 신경망 기반의 학습 알고리즘인 딥 러닝 기술의 발전으로 인해 텍스트의 문맥을 고려한문서 임베딩 모델이 다양하게 고안되었으며, 특히 대량의 텍스트 데이터를 사용하여 학습을 수행한 사전 학습 언어 모델을 사용하여 분석 문서의 벡터를 추론하는 방식의 임베딩이 활발하게 연구되고 있다. 하지만 기존의 사전 학습 언어 모델을 사용하여 새로운 텍스트에 대한 임베딩을 수행할 경우 해당 텍스트가 가진 고유한 정보를 충분히 활용하지 못한다는 한계를 가지며, 이는 특히 텍스트가 가진 토큰의 수에 큰 영향을 받는 것으로 알려져 있다. 이에 본 연구에서는 다수의토큰을 포함한 장문 텍스트의 정보를 최대한 활용하여 해당 텍스트의 벡터를 도출할 수 있는 자기 지도 학습 기반의 사전 학습 언어 모델 미세 조정 방법을 제안한다. 또한, 제안 방법론을 실제뉴스 기사에 적용하여 문서 벡터를 도출하고 이를 활용하여 뉴스의 카테고리 분류 실험을 수행하는 외부적인 임베딩 평가를 수행함으로써, 제안 방법론과 기존 문서 임베딩 모델과의 성능을 평가하였다. 그 결과 제안 방법론을 통해 도출된 벡터가 텍스트의 고유 정보를 충분히 활용함으로써, 문서의 특성을 더욱 정확하게 표현할 수 있음을 확인하였다.","Recently, various methods of text embedding using deep learning algorithms have been proposed.Especially, the way of using pre-trained language model which uses tremendous amount of text data in training is mainly applied for embedding new text data. However, traditional pre-trained language model has some limitations that it is hard to understand unique context of new text data when the text has too many tokens. In this paper, we propose self-supervised learning-based fine tuning method for pre-trained language model to infer vectors of long-text. Also, we applied our method to news articles and classified them into categories and compared classification accuracy with traditional models. As a result, it was confirmed that the vector generated by the proposed model more accurately expresses the inherent characteristics of the document than the vectors generated by the traditional models."
BERT 기반 End-to-end 신경망을 이용한 한국어 상호참조해결,2020,"['딥 러닝', '상호참조해결', 'BERT', '자연어처리', 'deep learning', 'coreference resolution', 'BERT', 'natural language processing']","상호참조해결은 주어진 문서에서 상호참조해결 대상이 되는 멘션(mention)을 식별하고, 같은 개체(entity)를 의미하는 멘션을 찾아 그룹화하는 자연어처리 태스크이다. 한국어 상호참조해결에서는 멘션 탐지와 상호참조해결을 동시에 진행하는 end-to-end 모델과 포인터 네트워크 모델을 이용한 방법이 연구되었다. 구글에서 공개한 BERT 모델은 자연어처리 태스크에 적용되어 많은 성능 향상을 보였다. 본 논문에서는 한국어 상호참조해결을 위한 BERT 기반 end-to-end 신경망 모델을 제안하고, 한국어 데이터로 사전 학습된 KorBERT를 이용하고, 한국어의 구조적, 의미적 특징을 반영하기 위하여 의존구문분석 자질과 개체명 자질을 적용한다. 실험 결과, ETRI 질의응답 도메인 상호참조해결 데이터 셋에서 CoNLL F1 (DEV) 71.00%, (TEST) 69.01%의 성능을 보여 기존 연구들에 비하여 높은 성능을 보였다.","Coreference resolution is a natural language task that identifies a mention that is a coreference resolution in a given document and finds and clusters the mention of the same entity. In the Korean coreference resolution, a method using the end-to-end model that simultaneously performs mention detection and mention clustering, and another method pointer network using the encoder-decoder model were used. The BERT model released by Google has been applied to natural language processing tasks and has demonstrated many performance improvements. In this paper, we propose a Korean end-to-end neural coreference resolution with BERT. This model uses the KorBERT pre-trained with the Korean data and applies dependency parsing results and the named entity recognition feature to reflect the structural and semantic characteristics of the Korean language.Experimental results show that the performance of the CoNLL F1 (DEV) 71.00% and (TEST) 69.01% in the ETRI Q & A domain data set was higher than the previous studies."
CNN 가속기의 효율적인 데이터 전송을 위한 메모리 데이터 레이아웃 및 DMA 전송기법 연구,2020,"['CNN', 'memory data layout', 'Loop-tiling', 'Accelerator', 'Scatter-Gather DMA']","딥 러닝 알고리즘 중 하나인 CNN 인공지능 어플리케이션은 하드웨어 측면에서 컨벌루션 레이어의 많은 데이터들을 저장하기 위해 오프 칩 메모리를 사용 하고, DMA를 사용하여 매 데이터 전송 시 프로세서의 부하를 줄여 성능을 향상 시킬 수 있다. 또한 컨벌루션 레이어의 데이터를 가속기의 글로벌 버퍼에 전송되는 순서를 다르게 하여 어플리케이션의 성능의 저하를 줄일 수 있다. 불 연속된 메모리 주소를 가지고 있는 베이직 레이아웃의 경우 SG-DMA를 사용 할 때 ordinary DMA를 사용할 때보다 DMA를 사전 설정하는 부분에서 약 3.4배의 성능향상을 보였고 연속적인 메모리 주소를 가지고 있는 아이디얼 레이아웃의 경우 ordinary DMA 와 SG-DMA를 사용하는 두가지 경우 모두 1396 사이클 정도의 오버헤드를 가졌다. 가장 효율적인 메모리 데이터 레이아웃과 DMA의 조합은 프로세서의 DMA 사전 설정 부하를 약 86 퍼센트까지 감소할 수 있음을 실험을 통해 확인했다.","One of the deep-running algorithms, CNN’s artificial intelligence application uses off-chip memory to store data on the Convolution Layer. DMA can reduce processor load at every data transfer. It can also reduce application performance degradation by varying the order in which data from the Convolution layer is transmitted to the global buffer of the accelerator. For basic layouts with continuous memory addresses, SG-DMA showed about 3.4 times performance improvement in pre-setting DMA compared to using ordinaly DMA, and for Ideal layouts with discontinuous memory addresses, the ordinal DMA was about 1396 cycles faster than SG-DMA. Experiments have shown that a combination of memory data layout and DMA can reduce the DMA preset load by about 86 percent."
표현체 연구를 위한 심화학습 기반 벼 종자 분할,2020,"['딥 러닝', '종자 영상분할', '객체 검출', '표현형', 'Deep learning', 'Seed segmentation', 'Object detection', 'Phenotype']","농업진흥청 국립농업과학원에서는 다양한 종류의 농작물에 대해 우량 종자 확보를 위한 생육환경 모니터링 및 수확된 종자의 분석과 같은 다양한 연구를 진행하고 있다. 본 논문에서는 농업진흥청에서 보유하고 있는 다양한 종류의 농작물 씨앗을 분석하기 위해 종자 객체 검출 방법을 제안한다. 제안된 방법은 Mask-RCNN을 이용한 전이학습을 수행하며 주어진 특정 환경 (일정한 조도, 흰색 배경)에서 촬영한 입력 영상을 종자 객체 인식을 위한 적절한 매개 변수 적합 (Tuning) 과정 및 영상 분할 작업을 진행한다. 제안된 방법으로 종자 객체 검출에 대한 실험결과로 벼 이삭 영상의 경우 82%와 단순한 볍씨 영상의 경우 97%의 정확도로 벼 낱알을 검출하였다. 향후 연구로 복잡한 상황의 종자 영상 분할을 위한 심화학습 기반의 접근법 및 검출된 종자 객체로부터 길이, 폭, 두께와 같은 정밀한 데이터 분석을 통하여 우량 종자 연구를 계획하고 있다.","The National Institute of Agricultural Sciences of the Rural Developement Administration (NAS, RDA) is conducting various studies on various crops, such as monitoring the cultivation environment and analyzing harvested seeds for high-throughput phenotyping. In this paper, we propose a deep learning-based rice seed segmentation method to analyze the seeds of various crops owned by the NAS. Using Mask-RCNN deep learning model, we perform the rice seed segmentation from manually taken images under specific environment (constant lighting, white background) for analyzing the seed characteristics. For this purpose, we perform the parameter tuning process of the Mask-RCNN model. By the proposed method, the results of the test on seed object detection showed that the accuracy was 82% for rice stem image and 97% for rice grain image, respectively. As a future study, we are planning to researches of more reliable seeds extraction from cluttered seed images by a deep learning-based approach and selection of high-throughput phenotype through precise data analysis such as length, width, and thickness from the detected seed objects."
Multi-Tasking U-net 기반 파프리카 병해충 진단,2020,"['멀티테스킹 학습', '딥 러닝', '파프리카 병해충', '분류', 'Multi-Tasking Learning', 'Deep Learning', 'Segmentation', 'Diagnosis of Paprika Diseases', 'Classification']","본 연구에서는 Multi-Tasking U-net를 사용하여 영역 세분화 작업(Segmentation) 과 분류 작업(Classification) 이 동시에 수행되게 함으로써 파프리카 병과 충 진단을 수행하였다. 시설 농장의 파프리카에는 병의 종류가 다양하지 않다. 이 연구에서는 비교적 발생빈도가 높은 흰가루병과 응애에 의한 피해, 정상 잎 3개의 클래스에 대해서만 진단 할 수 있도록 하였다. 이를 위한 중추 모델로는 U-net을 사용하였다. 또, 이 모델의 Encoder와 Decoder의 최종 단을 활용하여 분류 작업과 영역 세분화 작업이 각 각 수행되게하여, U-net의 Encoder가 분류작업과 영역 세분화 작업에 공유되도록 하였다. 학습 데이터로는 정상 잎 680장, 응애에 의한 피해 잎 450장, 흰가루병 370장을 사용하였다. 테스트 데이터로는 정상 잎 130장, 응애에 의한 피해 잎 100장, 흰가루병 90장을 사용하였고, 이를 통한 테스트 결과로는 89%의 인식률을 얻었다.","In this study, a neural network method performing both Detection and Classification of diseases and insects in paprika is proposed with Multi-Tasking U-net. Paprika on farms does not have a wide variety of diseases in this study, only two classes such as powdery mildew and mite, which occur relatively frequently are made as the targets. Aiming to this, a U-net is used as a backbone network, and the last layers of the encoder and the decoder of the U-net are utilized for classification and segmentation, respectively. As the result, the encoder of the U-net is shared for both of detection and classification. The training data are composed of 680 normal leaves, 450 mite-damaged leaves, and 370 powdery mildews. The test data are 130 normal leaves, 100 mite-damaged leaves, and 90 powdery mildews. Its test results shows 89% of recognition accuracy."
시각장애인을 위한 인공지능 관련 연구 동향 : 1993-2020년 국내·외 연구를 중심으로,2020,"['시각장애인', '인공지능', '머신러닝', '딥 러닝', '연구 동향', 'The Visually Impaired', 'AI', 'Artificial Intelligence', 'Machine Learning', 'Deep Learning', 'Research Trend']","본 연구는 시각장애인 대상의 인공지능 관련 연구 동향을 살펴보기 위해 1993년부터 2020년 8월까지 국내·외 논문 총 68편을 선정하여 연도별 논문 게재 수, 연구방법, 연구주제, 키워드 분석 현황, 연구유형, 구현방법별 비교·분석하였다. 연구결과, 연구기간 내 논문 편수는 꾸준히 증가하는 것처럼 보였으나 국내 연구의 경우에는 2016년도 이후에 활발해진 것을 알 수 있었다. 연구방법으로는 국내·외 연구 모두 개발연구가 89.7%를 차지했고, 키워드는 국내 연구에서는 Visually impaired, Deep learning, Assistive device 순이였으며 국외 연구에서는 Visually impaired, Deep learning, Artificial intelligence 순으로 단어 빈도순에서 차이를 보였다. 연구유형은 국내·외 모두 설계, 개발, 구현이 대부분을 차지했으며 구현방법으로는 국내 연구의 구현방법으로는 System 13.2%, Solution 7.4%, App. 4.4% 순이였으며 국외 연구의 구현방법으로는 System 32.4%, App.13.2%, Device 7.4%로 다소 차이를 보였다. 구현방법의 적용 기술로는 국내 연구는 YOLO 2.7%, TTS 2.1%, Tensorflow 2.1% 순이였으며 국외 연구에서는 CNN 8.0%, TTS 5.3%, MS-COCO 4.3% 순으로 사용횟수가 높았다. 본 연구는 시각장애인 대상의 인공지능 관련 연구 동향을 비교·분석하여 국내·외 연구의 현주소를 바로 알고 앞으로 시각장애인을 위한 인공지능 연구의 방향을 제시하고자 하였다.","In this study, a total of 68 domestic and international papers were selected from 1993 to August 2020 in order to examine the research trends related to artificial intelligence for the visually impaired. The papers were compared and analyzed by the number of papers published by year, research method, research topic, keyword analysis status, research type, and implementation method. As a result of the study, the number of papers during the study period seemed to increase steadily. But in the case of domestic research, It can be seen that it has become active since 2016. As for research methods, development research accounted for 89.7% of both domestic and foreign research. Keywords was in Visually Impaired, Deep Learning, and Assistive Device order in domestic research. And it was in Visually Impaired, Deep learning, Artificial intelligence order in foreign research. There was a difference in the frequency of words. Research type were Design, development and implementation both in domestic and foreign. Implementation method were in System 13.2%, Solution 7.4%, App. 4.4% order in domestic research, and it was in System 32.4%, App. 13.2%, Device 7.4% order in foreign research. As for the applied technology of the implementation method, were in YOLO 2.7%, TTS 2.1%, Tensorflow 2.1% order in domestic research, and it was used in CNN 8.0%, TTS 5.3%, MS-COCO 4.3% order in foreign research. The purpose of this study was to compare and analyze the trends of artificial intelligence-related research targeting the visually impaired, to immediately know the current status of domestic and foreign research, and to present the direction of artificial intelligence research for the visually impaired in the future."
강화학습과 몬테카를로 트리 탐색을 적용한 인공지능 인수분해 게임 에이전트에 관한 연구,2020,"['합성곱 신경망', '딥 러닝', '강화학습', '몬테카를로 트리 탐색', '인수분해 게임', 'Convolutional neural network', 'Deep learning', 'Reinforcement learning', 'Monte Carlo Tree Search', 'Factorization game']","본 논문에서는 수학적 개념인 인수분해를 이용하여 만든 수학 게임인 인수분해 게임을 소개 및 분석하였다. 또한, 인수분해 게임은 게임 보드 크기 n과 게임 값 p를 조절함으로써 게임의 상태 및 행동의 불확실성을 조절할 수 있다는 장점이 있다. 특히, 만일 n의 값이 커질 경우, 경우의 수가 기하급수적으로 증가함으로 인해 승리 전략이 불확실하다. 이를 강화학습 관점으로 보면 상태와 행동의 불확실성을 의미한다. 따라서 n을 6이하로 설정함으로써 불확실성을 조절한 인수분해 게임 에이전트를 만들었다. 본 논문에서는 강화학습 알고리즘인 Q-learning, Double DQN, 몬테카를로 트리 탐색을 인수분해 게임에 적용해보고, 승률 및 분석을 통하여 학습 진행됨을 보였다. 본 논문에서는 무작위 정책 에이전트와 강화학습을 적용한 인수분해 게임 에이전트와의 대결을 통해 학습 진행에 따른 승률 변화를 관찰하였다.","In this paper, we introduce and analyze the factorization game, which is a math game made using a mathematical concept, factorization. In addition, the factorization game have the advantage of controlling the uncertainty of the game state and action by adjusting the game board size n and game value p. In particular, if the value of n increases, the winning strategy is uncertain because the number of cases increases exponentially. Looking at this from the perspective of reinforcement learning, it means uncertainty in state and action. Accordingly, by setting the board size of n to 6 or less, a factorization game agent is created that adjusts the uncertainty. In this paper, we apply the reinforcement learning algorithms Q-learning, Double DQN, and Monte Carlo tree search to the factorization game, and show that learning progress through winning rate and analysis. In this paper, we observe the change in the winning rate according to the progress of learning through the competition between random policy agent and the factorization game agent applying reinforcement learning."
Prediction of Blood Glucose in Diabetic Inpatients Using LSTM Neural Network,2020,"['당뇨병', '혈당예측', '딥 러닝', 'diabetes', 'blood glucose prediction', 'deep-learning', 'LSTM']",,
오프 폴리시 강화학습에서 몬테 칼로와 시간차 학습의 균형을 사용한 적은 샘플 복잡도,2020,"['온- 앤 오프-폴리시', '시간차 학습', '몬테 칼로 학습', '강화학습', '분산과 편차의 균형', 'Deep Q-Network', 'Temporal Difference', 'Monte Carlo', 'Reinforcement Learning', 'Variation and Bias Balance']","강화학습에서 근사함수로써 사용되는 딥 인공 신경망은 이론적으로도 실제와 같은 근접한 결과를 나타낸다. 다양한 실질적인 성공 사례에서 시간차 학습(TD) 은 몬테-칼로 학습(MC) 보다 더 나은 결과를 보여주고 있다. 하지만, 일부 선행 연구 중에서 리워드가 매우 드문드문 발생하는 환경이거나, 딜레이가 생기는 경우, MC 가 TD 보다 더 나음을 보여주고 있다. 또한, 에이전트가 환경으로부터 받는 정보가 부분적일 때에, MC가 TD보다 우수함을 나타낸다. 이러한 환경들은 대부분 5-스텝 큐-러닝이나 20-스텝 큐-러닝으로 볼 수 있는데, 이러한 환경들은 성능-퇴보를 낮추는데 도움 되는 긴 롤-아웃 없이도 실험이 계속 진행될 수 있는 환경들이다. 즉, 긴롤-아웃에 상관없는 노이지가 있는 네트웍이 대표적인데, 이때에는 TD 보다는 시간적 에러에 견고한 MC 이거나 MC와 거의 동일한 학습이 더 나은 결과를 보여주고 있다. 이러한 해당 선행 연구들은 TD가 MC보다 낫다고 하는 기존의 통념에 위배되는 것이다. 다시 말하면, 해당 연구들은 TD만의 사용이 아니라, MC와 TD의 병합된 사용이 더 나음을 이론적이기 보다 경험적 예시로써 보여주고 있다. 따라서, 본 연구에서는 선행 연구들에서 보여준 결과를 바탕으로 하고, 해당 연구들에서 사용했던 특별한 리워드에 의한 복잡한 함수 없이, MC와 TD의 밸런스를 랜덤하게 맞추는 좀 더 간단한 방법으로 MC와 TD를 병합하고자 한다. 본 연구의 MC와 TD의 랜덤병합에 의한 DQN과 TD-학습만을 사용한 이미 잘 알려진 DQN과 비교하여, 본 연구에서 제안한 MC와 TD의 랜덤 병합이 우수한 학습방법임을 OpenAI Gym의 시뮬레이션을 통하여 증명하였다.","Deep neural networks(DNN), which are used as approximation functions in reinforcement learning (RN), theoretically can be attributed to realistic results. In empirical benchmark works, time difference learning (TD) shows better results than Monte-Carlo learning (MC). However, among some previous works show that MC is better than TD when the reward is very rare or delayed. Also, another recent research shows when the information observed by the agent from the environment is partial on complex control works, it indicates that the MC prediction is superior to the TD-based methods. Most of these environments can be regarded as 5-step Q-learning or 20-step Q-learning, where the experiment continues without long roll-outs for alleviating reduce performance degradation. In other words, for networks with a noise, a representative network that is regardless of the controlled roll-outs, it is better to learn MC, which is robust to noisy rewards than TD, or almost identical to MC. These studies provide a break with that TD is better than MC. These recent research results show that the way combining MC and TD is better than the theoretical one. Therefore, in this study, based on the results shown in previous studies, we attempt to exploit a random balance with a mixture of TD and MC in RL without any complicated formulas by rewards used in those studies do. Compared to the DQN using the MC and TD random mixture and the well-known DQN using only the TD-based learning, we demonstrate that a well-performed TD learning are also granted special favor of the mixture of TD and MC through an experiments in OpenAI Gym."
Enhancement of Tongue Segmentation by Using Data Augmentation,2020,"['Data augmentation', 'Deep Learning', 'Tongue segmentation', 'Transfer learning']","많은 양의 데이터는 딥 러닝 모델의 견고성을 향상시키고 과적합 문제를 방지할 수 있게 해준다. 자동 혀 분할에서, 혀 영상 데이터 세트를 실제로 수집하고 라벨링하는 데에는 많은 어려움이 수반되므로 많은 양의 혀 영상 데이터를 사용하기 쉽지 않다. 데이터 증강은 새로운 데이터를 수집하지 않고 레이블 보존 변환을 사용하여 학습 데이터 세트를 확장하고 학습 데이터의 다양성을 증가시킬 수 있다. 이 논문에서는 이미지 자르기, 회전, 뒤집기, 색상 변환과 같은 7 가지 데이터 증강 방법을 사용하여 확장된 혀 영상 학습 데이터 세트를 생성하였다. 데이터 증강 방법의 성능을 확인하기 위하여 InceptionV3, EfficientNet, ResNet, DenseNet 등과 같은 전이 학습 모델을 사용하였다. 실험 결과 데이터 증강 방법을 적용함으로써 혀 분할의 정확도를 5~20% 향상시켰으며 기하학적 변환이 색상 변환보다 더 많은 성능 향상을 가져올 수 있음을 보여주었다. 또한 기하학적 변환 및 색상 변환을 임의로 선형 조합한 방법이 다른 데이터 증강 방법보다 우수한 분할 성능을 제공하여 InveptionV3 모델을 사용한 경우에 94.98 %의 정확도를 보였다.","A large volume of data will improve the robustness of deep learning models and avoid overfitting problems. In automatic tongue segmentation, the availability of annotated tongue images is often limited because of the difficulty of collecting and labeling the tongue image datasets in reality. Data augmentation can expand the training dataset and increase the diversity of training data by using label-preserving transformations without collecting new data. In this paper, augmented tongue image datasets were developed using seven augmentation techniques such as image cropping, rotation, flipping，color transformations. Performance of the data augmentation techniques were studied using state-of-the-art transfer learning models, for instance, InceptionV3, EfficientNet, ResNet, DenseNet and etc. Our results show that geometric transformations can lead to more performance gains than color transformations and the segmentation accuracy can be increased by 5% to 20% compared with no augmentation. Furthermore, a random linear combination of geometric and color transformations augmentation dataset gives the superior segmentation performance than all other datasets and results in a better accuracy of 94.98% with InceptionV3 models."
Hierarchical Attention Network를 이용한 복합 장애 발생 예측 시스템 개발,2020,"['이상 탐지', '계층적 구조', '딥 러닝', '복합 장애 예측', '어탠션', 'Anomaly Detection', 'Hierarchical Structure', 'Deep Learning', 'Complex Failure Prediction', 'Attention']",,"The data center is a physical environment facility for accommodating computer systems and related components, and is an essential foundation technology for next-generation core industries such as big data, smart factories, wearables, and smart homes. In particular, with the growth of cloud computing, the proportional expansion of the data center infrastructure is inevitable. Monitoring the health of these data center facilities is a way to maintain and manage the system and prevent failure. If a failure occurs in some elements of the facility, it may affect not only the relevant equipment but also other connected equipment, and may cause enormous damage. In particular, IT facilities are irregular due to interdependence and it is difficult to know the cause.  In the previous study predicting failure in data center, failure was predicted by looking at a single server as a single state without assuming that the devices were mixed. Therefore, in this study, data center failures were classified into failures occurring inside the server (Outage A) and failures occurring outside the server (Outage B), and focused on analyzing complex failures occurring within the server. Server external failures include power, cooling, user errors, etc. Since such failures can be prevented in the early stages of data center facility construction, various solutions are being developed. On the other hand, the cause of the failure occurring in the server is difficult to determine, and adequate prevention has not yet been achieved. In particular, this is the reason why server failures do not occur singularly, cause other server failures, or receive something that causes failures from other servers. In other words, while the existing studies assumed that it was a single server that did not affect the servers and analyzed the failure, in this study, the failure occurred on the assumption that it had an effect between servers.  In order to define the complex failure situation in the data center, failure history data for each equipment existing in the data center was used. There are four major failures considered in this study: Network Node Down, Server Down, Windows Activation Services Down, and Database Management System Service Down. The failures that occur for each device are sorted in chronological order, and when a failure occurs in a specific equipment, if a failure occurs in a specific equipment within 5 minutes from the time of occurrence, it is defined that the failure occurs simultaneously. After configuring the sequence for the devices that have failed at the same time, 5 devices that frequently occur simultaneously within the configured sequence were selected, and the case where the selected devices failed at the same time was confirmed through visualization.  Since the server resource information collected for failure analysis is in units of time series and has flow, we used Long Short-term Memory (LSTM), a deep learning algorithm that can predict the next state through the previous state. In addition, unlike a single server, the Hierarchical Attention Network deep learning model structure was used in consideration of the fact that the level of multiple failures for each server is different. This algorithm is a method of increasing the prediction accuracy by giving weight to the server as the impact on the failure increases. The study began with defining the type of failure and selecting the analysis target. In the first experiment, the same collected data was assumed as a single server state and a multiple server state, and compared and analyzed. The second experiment improved the prediction accuracy in the case of a complex server by optimizing each server threshold.  In the first experiment, which assumed each of a single server and multiple servers, in the case of a single server, it was predicted that three of the five servers did not have a failure even though the actual failure occurred. However, assuming multiple servers"
도시조직이 생활도로 보행자 교통사고에 미치는 영향 : 서울시 생활도로 내 보행자 교통사고 다발구간을 중심으로,2020,"['보행자 교통사고', '도시조직', '생활도로', '딥 러닝', '도시설계', 'Pedestrian Traffic Accidents', 'Urban Tissue', 'Living Roads', 'Deep Learnning', 'Urban Design']",,
Study and Application of RSSI-based Wi-Fi Channel Detection Using CNN and Frequency Band Characteristics,2020,"['와이파이 스캔', '비면허 대역', '저전력 안테나', '딥 러닝', '합성곱 신경망', 'Wi-Fi scanning', 'ISM band', 'low power antenna', 'deep learning', 'convolution neural network']",,
Tool Condition Monitoring Using Deep Learning in Machining Process,2020,"['Continuous wavelet transform (연속웨이블릿)', 'Deep learning (딥 러닝)', 'Milling (밀링)', 'Short time Fourier transform (단시간 푸리에 변환)', 'Tool condition monitoring (공구 상태진단)']",,
CNN-Based Novelty Detection with Effectively Incorporating Document-Level Information,2020,"['Deep Learning', 'CNN', 'Novelty Detection', '딥 러닝', '합성곱 신경망', '신규성 탐지']",,"With a large number of documents appearing on the web, document-level novelty detection has become important since it can reduce the efforts of finding novel documents by discarding documents sharing redundant information already seen. A recent work proposed a convolutional neural network (CNN)-based novelty detection model with significant performance improvements. We observed that it has a restriction of using document-level information in determining novelty but assumed that the document-level information is more important. As a solution, this paper proposed two methods of effectively incorporating document-level information using a CNN-based novelty detection model. Our methods focus on constructing a feature vector of a target document to be classified by extracting relative information between the target document and source documents given as evidence. A series of experiments showed the superiority of our methods on a standard benchmark collection, TAP-DLND 1.0."
마스크를 착용한 얼굴 인식을 위한 방법 연구,2020,"['Deep Learning', 'Face Detection', 'Face Recognition', '딥 러닝', '얼굴 탐지', '얼굴 인식']",,"Recently, face recognition with occlusions has a problem in that the recognition rate is decreased. This paper proposes a method of matching two faces with high similarity by measuring the similarity by a distance after making an image with a mosaic on the lower part of the face to increase the recognition rate of a face wearing a mask. The proposed method shows a similar recognition rate as when the mask is not worn, and in the group of 100 people, the mask shows 12% improvement in Rank-1 and 18.8% improvement in matching accuracy."
인공지능시대에 알고리즘에 의한 행위조종과 가상적 행정행위에 관한 소고,2020,"['디지털화', '전자정부', '관료제비용', '가상적 행정행위', '인공지능', '알고리즘 알고리즘에 의한 행위조종', '머신러닝', '딥 러닝', '리걸 테크', '온라이프', '디지털에 의한 행정의 변모', '완전자동화된 행정행위', '전자적 행정행위', 'Digitalisierung', 'E-Government', 'Burokratiekosten', 'Der virtuelle Verwaltungsakt', 'AI(Kunstliche Intelligenz)', 'Algorithms', 'Verhaltenssteuerung durch Algorithmen', 'machine learning', 'deep learning', 'Legal Technology', 'onlife', 'Transformation der Verwaltung durch Digitalisierung', 'Der vollstandig automatisierte Verwaltungsakt', 'Der elektronische Verwaltungsakt']","시대적 트렌드인 제4차 산업혁명에서 디지털화로 인해 행정의 변모는 가속화되고 있다. 인공지능(Artificial Intelligence: AI, Künstliche Intelligenz:KI)이 시대적 화두가 되고 있다. Max Weber가 100년 전에 창안한 관료제 행정 자체가 행정의 디지털화로 인해 특히 인공지능을 기반으로 한 공공 사물인터넷을 통해 기계 자체에 의해 운용되는 극적인 상황을 맞이하고 있다. 어느 듯 기술적 법칙으로서의 알고리즘은 공공분야를 넘어서 우리네 일상과 현실을 형성한다. 사이버공간을 규율하는 소프트웨어와 하드웨어와 같은 코드(Code)가 기왕의 법을 넘어서 또 다른 법이 되었다. 행위조정의 측면에서 코드나 알고리즘은 급속하게 법에 비견한 존재가 되어 법을 지지, 수정하거나 그 효력을 좌절시킬 수 있다. 법의 지배가 아닌, 코드나 알고리즘에 의한 지배가 통용될 수 있다. 이런 인공지능의 알고리즘의 발전의 급속한 진전과 현재의 합리화압력에 즈음하여, 국가는 질서시스템으로서 자신의 내적, 외적 상태를 이런 기술적 혁신도입에 맞춰야 한다. 그렇지 않으면, 국가는 시민의 디지털화된 생활세계와 기능세계에 대해 긴밀한 관계를 상실할 위험이 있다. 그러나 현하의 논의상황은 제4차 산업혁명 시대를 선도하기는커녕 전혀 그것과 호흡을 하지 못하고 있다. 디지털화의 기본인 알고리즘에 의한 행위조종의 전반에 관한 심도 있는 논의를 바탕으로 가상적 행정행위를 우리 법제에 안착시키기 위한 방안을 모색하고자 한다.",
Word2Vec을 활용한 문법 탐구의 핵심 어휘 탐색 연구,2020,"['grammar inquiry', 'deep learning', 'word embedding', 'Word2Vec', 'k-means clustering', '문법 탐구', '딥 러닝', '단어 임베딩', '워드투벡', 'k-평균 군집화']","본 연구는 그간 이루어져 온 문법 탐구 논의들을 바탕으로 문법 탐구의 개념 및 속성을 탐색하고자 하였다. 이를 위하여 국내 학술지에 실린 논문 중 키워드가 ‘탐구’인 것들을 추출하고, 이 중 ‘문법 교육’과 직접적으로 관련이 있는 것들을 선별하여 총 77개의 논문을 연구 대상으로 삼았다. 이후 이들을 모두 전사하여 말뭉치를 구축하고, 파이선 패키지 KoNLPy의 Mecab 분석기를 이용하여 형태소 분석을 실시하였으며, 텍스트의 의미 구성에 영향을 미치지 않는 불필요한 단어들을 불용어로 선정하여 제외하는 등 말뭉치를 정제하는 작업을 거쳤다.이렇게 정제된 말뭉치에 대하여 Word2Vec 분석을 실시하였는데, 이는 Word2Vec이 분포 가설에 입각하기 때문에 단어 간 관계를 잘 보여 줄 수 있다고 판단하였기 때문이다. Word2Vec을 통해 구축된 워드벡터에서 ‘탐구’와 코사인 유사도가 높은 단어 상위 132개를 추출하고 그중 문법 탐구와 보다 관련이 깊은 단어들을 포착하기 위하여 군집화를 실시하였다. 총 6개의 군집 중 문법 탐구와 가장 관련이 깊다고 추정되는 하나의 군집을 최종적으로 선정하여 질적 해석을 시도하였다. 그 결과, ‘사고’, ‘발산’, ‘고차’, ‘고차원’은 문법 탐구와 관련되는 사고들을 보여 주는 단어로서, ‘분석력’, ‘비판력’, ‘관찰력’, ‘(문제) 해결력’은 문법 탐구 능력과 관련되는 단어로서 범주화되었다. 또한, ‘기쁨’, ‘성취감’, ‘즐거움’은 문법 탐구의 정의적 측면에서의 긍정적 효과를, ‘안내’, ‘해결’, ‘순환’은 문법 탐구의 과정적 속성을, ‘경험’, ‘과제’는 문법 탐구를 바라보는 관점의 차이를 보여 주었다. 이러한 단어들은 문법 탐구와 주요하게 관련되는 단어들로서, 앞으로 문법 탐구 논의에서 관심 있게 다루어져야 하는 대상으로 볼 수 있다.","This study aimed to explore the concepts and attributes of grammar inquiry based on existing research. Accordingly, articles with the keyword “inquiry” were extracted from domestic journals, and overall, 77 papers directly related to “grammar education” were selected as research subjects. All these papers were transcribed to build a corpus and morphemic analysis was conducted using Mecab in the Python package KoNLPy. The corpus was further refined by excluding “unnecessary words” that did not affect composition of the meaning of the text.Word2Vec analysis was conducted on the refined corpus, since it is based on the distribution hypothesis which can demonstrate the relationship between words well. The top 132 words with high cosine similarity to “inquiry” were extracted from the word vector constructed through Word2Vec, and clustering was conducted to capture words more relevant to grammar inquiry. Subsequently, from a total of six clusters, one cluster presumed to be the most relevant to grammar inquiry was finally selected and a qualitative interpretation of the selected cluster was organized. Words such as thinking, divergence, high dimensional, etc. are primarily related to grammar inquiry, and should be noted in future grammar inquiry discussions."
앵커 프리 방법을 이용한 다중 크기 얼굴 검출기,2020,"['얼굴 검출', '앵커 프리 방법', '다중 크기 검출', '딥 러닝', '특징 피라미드 학습', 'Face detection', 'Anchor free method', 'Multi-scale detection', 'Deep learning', 'Feature pyramid learning']",본 논문에서는 앵커 프리 방법을 이용한 FCN(Fully Convolutional Network)기반의 1단계 다중 크기 얼굴 검출기를 제안한다. 최근 대부분의 연구들은 사전 정의된 앵커를 사용하여 얼굴이 있을만한 위치를 예측한다. 그러나 사전 정의 앵커를 이용함으로써 학습 시 하이퍼 파라미터의 설정과 추가적인 계산이 필요하다. 제안하는 방법의 핵심 아이디어는 앵커 프리 방법을 사용하여 하이퍼 파라미터를 없애고 여러 개의 특징 맵을 사용함으로써 클래스 내 불균형 문제를 완화하는것이다. 이 방법들은 다음과 같은 효과가 있다. 첫째로 사전정의 앵커를 없앰으로써 앵커와 관련된 하이퍼 파라미터와 추가적인 계산을 피한다. 둘째로 클래스 내 불균형을 완화하기 위해 여러개의 특징 맵으로부터 얼굴을 예측한다. 정량적 평가를 통해 제안하는 방법에 따른 검출 성능을평가 및 분석한다. FDDB(Face Detection Dataset & Benchmark) 데이터 셋의 실험 결과에서 제안하는 방법이 효과가 있음을 증명했다.,"In this paper, we propose one stage multi-scale face detector based Fully Convolution Network using anchor free method. Recently almost all state-of-the-art face detectors which predict location of faces using anchor-based methods rely on pre-defined anchor boxes. However this face detectors need to hyper-parameters and additional computation in training. The key idea of the proposed method is to eliminate hyper-parameters and additional computation using anchor free method. To do this, we apply two ideas. First, by eliminating the pre-defined set of anchor boxes, we avoid the additional computation and hyper-parameters related to anchor boxes. Second, our detector predicts location of faces using multi-feature maps to reduce foreground/background imbalance issue. Through Quantitative evaluation, the performance of the proposed method is evaluated and analyzed. Experimental results on the FDDB dataset demonstrate the effective of our proposed method."
합성곱 신경망을 이용한 온실 파프리카의 작물 생체중 추정,2020,"['artificial neural network', 'deep learning', 'image processing', 'machine learning', 'plant growth', '기계 학습', '딥 러닝', '식물 생장', '이미지 처리', '인공신경망']","작물의 생체중을 추정하기 위해 다양한 연구가 시도되었지만, 이미지를 활용하여 생체중을 추정한 예는 없었다. 최근 합성곱 신경망을 사용한 이미지 처리 연구가 늘고 있으며, 합성곱 신경망은 미가공 데이터를 그대로 사용할 수 있다. 본 연구에서는 합성곱 신경망을 이용하여 미가공 데이터 상태인 특정시점의 파프리카 이미지를 입력으로 작물의 생체중을 추정하도록 학습하였다. 실험은 파프리카(Capsicum annuum L.)를 재배하는 온실에서 수행하였다. 합성곱 신경망의 출력값인 생체중은 파괴조사를 통해 수집한 데이터를 기반으로 회귀 분석하였다. 학습된 합성곱 신경망의 결정 계수(R<SUP>2</SUP>)의 최고값은 0.95로 나타났다. 생체중 추정값은 실제 측정값과 매우 유사한 경향성을 보여주었다.","Various studies have been attempted to estimate and measure the fresh weight of crops. However, no studies have used raw images of sweet peppers to estimate fresh weight. Recently, image processing research using convolution neural network (CNN) that can use raw data is increasing. In this study, the crop fresh weight was estimated by using the images of sweet peppers as inputs of CNN. The experiment was performed in a greenhouse growing sweet pepper (Capsicum annuum L.). The fresh weight, the output of the CNN, was regressed based on the data collected through destructive investigation. The highest coefficient of determination (R<SUP>2</SUP>) of the trained CNN was 0.95. The estimated fresh weight showed a very similar trend to the actual measured value."
인공지능이 인간 같은 행위자가 될 수 있나?,2020,"['인공지능', '인간 지능', '진정성', '행위자', '정체성', '자의식', 'artificial intelligence', 'human intelligence', 'authenticity', 'agent', 'identity', 'self-awareness']","이 글은 인공지능과 인간 지능의 차이가 무엇인지 논의함으로써 인공지능의 존재론적 지위와 인간의 특징이 무엇인지 밝히고자 한다. 최근 알파고의 등장에서처럼 인공지능은 컴퓨터가 상호 연계되며 빅 데이터 기술과 딥 러닝 기술까지 포함하는 형태로 발전하였고 계산의 영역뿐만 아니라 감성의 영역까지 포함하는 것으로 발전하고 있다. 그러나 인공지능은 인간의 감성을 흉내낼 뿐이다. 왜냐하면 감정이나 정서의 영역은 진정성이 중요하게 작동하는 영역으로서 감정을 표출하는 자의 주체성과 총체적 인격성이 전제되어야 하기 때문이다. 또한 인간의 뇌가 수행한 기능은 생존을 위한 것이다. 지능 역시 생존을 위한 문제해결능력으로 정의될 수 있다. 이런 점에서 인공지능은 진정한 지능이라 여길 수 없다. 인공지능이 인간과 같은 진정한 지능을 갖추기 위해서는 인공지능이 자신이 처한 환경에서 생존하려는 문제해결능력의 발휘로서 지능을 사용해야 하기 때문이다. 그러나 인공지능이 생존하려는 욕구를 지니고 있다고 판단하기는 아직 이르다. 게다가 인공지능이 인간과 같은 자의식이라는 고도의 지능을 지니고 있다거나 지닐 것이라고 보기도 어렵다. 인간의 자의식은 생물체로서의 유한성을 인식하고 다른 인간과의 연대와 협력을 통해 자아정체성과 함께 타자성을 인식하는 매우 고차원적인 지능 활동이다. 이와 같이 인간 지능과 인공지능의 차이는 인공지능이 의도를 지닌 행위자로 인식되기 어렵다는 판단에 이르게 하며, 도덕적 행위자로 인식되기는 더욱 어렵다고 본다. 인공지능을 인간처럼 여기는 태도나 기획은 오히려 인간이 인공지능과 어떻게 다른지를 보여주고 있다.","This paper aims to clarify the ontological status of artificial intelligence and features of human intelligence by dealing with the difference between them. Recently, as AlphaGo shows, artificial intelligence has the network of computers and adopts deep learning technology with big data. Further, artificial intelligence is introduced to the scope of emotion as well as to that of calculation. However, artificial intelligence just imitates human emotion because subjectivity and holistic personality of emotion exposer must be presupposed and because emotion plays a role with authenticity. the function of human brain is to make a human being survive. Human intelligence can be defined as a problem-solving capacity for survival. Thus, artificial intelligence is not the same as human intelligence. In order for artificial intelligence to be an human intelligence, it uses its intelligence for its problem-solving for survival. But it is hard to say that artificial intelligence has a desire to survive. In addition, it is also hard to say that artificial intelligence has or will have self-awareness like human being’s. Human self-awareness is a very high level of intelligence activity in which a human being recognizes one’s finitude as a biological organism and one’s self identity as well as otherness through the cooperation with others. The difference between artificial intelligence and human one leads us to think that an artificial intelligence cannot become an agent with intention and not even moral agent. The attitude or project to consider artificial intelligence to be an human intelligence is only to show that there are big differences between them."
소프트웨어-정의 네트워크에서 CNN 모델을 이용한 DDoS 공격 탐지 기술,2020,"['CNN', 'Deep Learning', 'DDoS Attack', 'Permutation Importance Algorithm', 'Software Defined Network']","소프트웨어 정의 네트워크가 확장성, 유연성, 네트워크상 프로그래밍이 가능한 특징으로 네트워크 관리에서 표준으로 자리잡아 가고 있지만 많은 장점에도 불구하고 하나의 컨트롤러에 대한 사이버 공격이 전체 네트워크를 영향을 주는 문제점을 가지고 있다. 특히, 컨트롤러에 대한 DDoS 공격이 대표적인 사례로서 다양한 공격 탐지 기술에 대한 연구가 진행되고 있다. 본 논문에서는 최초로 84개 DDoS 공격 Feature 데이터셋을 Kaggle에서 획득한 후 Permutation Feature Importance 알고리즘을 이용하여 상위 20의 중요도를 갖는 Feature를 선택하여 딥 러닝 기반의 CNN 모델에서 학습과 검증을 수행하였다. 이를 통해, 최적의 공격 탐지율을 갖는 상위 13개의 DDoS Feature 선택이 DDoS 공격 탐지율 96%을 유지하면서 적정한 공격 탐지 시간, 정확성 등에서 매우 우수한 결과를 제시하였다.","Software Defined Networking (SDN) is setting the standard for the management of networks due to its scalability, flexibility and functionality to program the network. The Distributed Denial of Service (DDoS) attack is most widely used to attack the SDN controller to bring down the network. Different methodologies have been utilized to detect DDoS attack previously. In this paper, first the dataset is obtained by Kaggle with 84 features, and then according to the rank, the 20 highest rank features are selected using Permutation Importance Algorithm. Then, the datasets are trained and tested with Convolution Neural Network (CNN) classifier model by utilizing deep learning techniques. Our proposed solution has achieved the best results, which will allow the critical systems which need more security to adopt and take full advantage of the SDN paradigm without compromising their security."
독일 AI 국가전략의 지향점이 한국의 정책 방향에 주는 시사점,2020,"['독일 인공지능 국가전략', '한국 인공지능 정책', '인공지능 기술', '인간중심 인공지능 전략', '인공지능 윤리', 'Nationale Strategie in Deutschland zur Künstliche Intelligenz', 'Politik von KI in Korea', 'KI Technik', 'Menschenorientiere AI Stragegie', 'AI Ethik']","이 논문은 한국 독어독문학 분야에서 연구와 교육의 지평을 지역학으로 넓혀서 정체성의 외연을 확대하고 사회 발전에 기여해야 한다는 입장에서 출발한다. 현대 사회에서 AI는 시대의 화두가 되고 있으며, 독일은 2018년 11월에 한국은 2019년 12월에 AI 국가전략을 각각 제시한 바 있다. 이 논문의 연구목적은 독일 AI 국가전략의 특징 및 지향점을 살펴보고 한국의 해당 정책 방향 설정에 활용 가능한 정보를 제공하는 것이다. 이를 위해 관련기관에서 제공하는 자료와 정보를 인용하는 방식으로 기술하였다. 먼저 AI 관련 용어와 관련 기술에 대해 인공지능, 증강지능, 기계학습, 인공신경망, 딥 러닝 등을 중심으로 정리하였다. 독일에서는 경제에너지부, 교육연구부, 노동사회부 등 3개 부처가 중심이 되어 국가전략을 수립하고 정책을 실행하고 있다. AI 기술을 경제적 측면에서 적극 수용하면서도 교육연구부가 주도하여 인간을 중심에 두는 전략을 수립하고 있는 점이 독일 AI 국가전략에서 특징 중의 하나이다. 독일에서는 다양한 집단의 참여와 대화를 기반으로 인간의 행복과 사회의 공익을 위한 AI 기술 개발을 지향하고 있다. 한국의 AI 국가전략 수립에 대부분의 관련 부처가 참여하고 있다. 한국에서도 인간 중심의 정책을 언급하고 있으나 구체적인 내용에서는 부족한 측면이 있다. 한국은 경쟁 지향적이고 독일은 목표 지향적이라는 차이도 보여준다. 따라서 독일의 사례를 면밀히 검토하여 정책 방향 수립에 활용할 수 있을 것이다. 특히 한국의 AI 전략에서는 인간 중심 AI 전략에 관한 아젠다와 세부과제를 보완할 필요가 있다. AI 윤리와 같은 이슈들이 중요하기 때문에 교육부의 역할이 중요하다. 여기서 제시된 내용이 관련 교과목 수업에 활용되거나 국가의 AI 정책과 전략 수립 및 실행에 일부라도 기여할 수 있기를 기대한다.","In der modernen Gesellschaft gilt Künstliche Intelligenz (KI) als eminentes Thema. Deutschland präsentierte im November 2018 eine entsprechende nationale Strategie, Korea tat im Dezember 2019 das gleiche. Das Ziel der vorliegenden Arbeit ist es, die deutsche KI-Strategie vorzustellen und daraus mögliche Implikationen für die Strategie Koreas abzuleiten. Das untersuchte Informationsmaterial stammt aus den Quellen der zuständigen Behörden.Zuerst wird die einschlägige Fachterminologie (z. B. Künstliche Intelligenz, Erweiterte Intelligenz, Mechanisches Lernen, Künstliches Nervennetzwerk und Tiefes Lernen) diskutiert. Danach kommt es zur Gegenüberstellung der zwei nationalen KI-Strategien. Charakteristisch für Deutschland ist es, dass die Bundesregierung die KI-Technologie zwar für die Ökonomie nutzbar machen möchte, aber gleichzeitig den Menschen in den Mittelpunkt stellt. Diese Orientierung am Menschen trifft ebenfalls auf Korea, doch dessen strategischen Vorgaben lesen sich vergleichsweise abstrakt. Während Deutschland zielorientiert wirkt, scheint Korea wettbewerbsorientiert zu planen. Es wäre wünschenswert, dass Korea bei einigen Punkten dem Beispiel der deutschen KI-Strategie folgt."
블록 암호 SM4에 대한 부채널 공격 및 마스킹 기반 대응기법 분석,2020,"['Side-Channel Analysis', 'Power Analysis Attack', 'DPA', 'CPA', 'Data Masking', 'MLP']","본 논문에서는 중국 표준 블록 암호 알고리즘인 SM4가 부채널 공격에 취약함을 보이고 그에 대한 대응책을 제안하고자 한다. 먼저, SM4는 차분 전력 분석(DPA)과 상관 전력 분석(CPA)에 기반한 공격에 의해 쉽게 비밀 키가노출됨을 확인하였다. 논문에서는 공격 취약 요소를 분석하고 데이터 마스킹에 기반한 전력 분석 공격 대응 기법을설계하였다. 제안한 SM4에 대한 1차 마스킹 기법은 딥 러닝 기반의 다층 퍼셉트론(MLP) 모델을 이용한 공격 프로파일링(profiling) 기반 공격에는 여전히 취약하지만, 차분 전력 분석이나 상관 전력 분석과 같은 비프로파일링(non-profiling) 공격에는 충분히 대응할 수 있음을 확인하였다.","In this paper, we show that the Chinese standard block cipher SM4 is vulnerable to the side channel attacks and presenta countermeasure to resist them. We firstly validate that the secret key of SM4 can be recovered by differential poweranalysis(DPA) and correlation power analysis(CPA) attacks. Therefore we analyze the vulnerable element caused by powerattack and propose a first order masking-based countermeasure to defeat DPA and CPA attacks. Although the proposedcountermeasure unfortunately is still vulnerable to the profiling power attacks such as deep learning-based multi layerperceptron(MLP), it can sufficiently overcome the non-profiling attacks such as DPA and CPA."
