title,date,keywords,abstract,multilingual_abstract
RGB-csb를 활용한 제한된 CNN에서의 정확도 분석 및 비교,2020,"['정확도', '딥러닝', '커널', '레이어', '학습 시간', 'Accuracy', 'CNN(Convolution Neural Network)', 'Deep Learning', 'Kernel', 'Layer', 'Learning Time']","본 논문은 대부분의 변형된 CNN(: Convolution Neural Networks)에서 사용하지 않는 첫 번째 컨볼루션 층(convolution layer)을 사용해 정확도 향상을 노리는 방법을 소개한다. GoogLeNet, DenseNet과 같은 CNN에서 첫 번째 컨볼루션 층에서는 기존방식(3x3 컨볼루션연산 및 배규정규화, 활성화함수)만을 사용하는데 이 부분을 RGB-csb(: RGB channel separation block)로 대체한다. 이를 통해 RGB값을 특징 맵에 적용시켜 정확성을 향상시킬 수 있는 선행연구 결과에 추가적으로, 기존 CNN과 제한된 영상 개수를 사용하여 정확도를 비교한다. 본 논문에서 제안한 방법은 영상의 개수가 적을수록 학습 정확도 편차가 커 불안정하지만 기존 CNN에 비해 정확도가 평균적으로 높음을 알 수 있다. 영상의 개수가 적을수록 평균적으로 약 2.3% 높은 정확도를 보였으나 정확도 편차는 5% 정도로 크게 나타났다. 반대로 영상의 개수가 많아질수록 기존 CNN과의 평균 정확도의 차이는 약 1%로 줄어들고, 각 학습 결과의 정확도 편차 또한 줄어든다.","This paper introduces a method for improving accuracy using the first convolution layer, which is not used in most modified CNN(: Convolution Neural Networks). In CNN, such as GoogLeNet and DenseNet, the first convolution layer uses only the traditional methods(3x3 convolutional computation, batch normalization, and activation functions), replacing this with RGB-csb. In addition to the results of preceding studies that can improve accuracy by applying RGB values to feature maps, the accuracy is compared with existing CNN using a limited number of images. The method proposed in this paper shows that the smaller the number of images, the greater the learning accuracy deviation, the more unstable, but the higher the accuracy on average compared to the existing CNN. As the number of images increases, the difference in accuracy between the existing CNN and the proposed method decreases, and the proposed method does not seem to have a significant effect."
이미지 인식률 개선을 위한 CNN 기반 이미지 회전 보정 알고리즘,2020,"['Rotation Estimation', 'Deep Learning', 'CNN', 'Image Processing']","이미지 인식 및 영상처리, 컴퓨터 비전 등의 분야에서 합성곱 인공신경망 (Convolutional Neural Network, CNN)은 다양하게 응용되고 탁월한 성능을 내고 있다. 본 논문에서는 CNN을 활용한 이미지 인식 시스템에서 인식률을저하시키는 요인 중 하나인 이미지의 회전에 대한 해결책으로써 CNN 기반 이미지 회전 보정 알고리즘을 제안한다. 본논문에서는 Leeds Sports Pose 데이터셋을 활용하여 이미지를 임의의 각도만큼 회전시킨 학습데이터로 인공지능 모델을 학습시켜 출력으로 회전된 각도를 추정하도록 실험을 진행하였다. 학습된 인공지능 모델을 100장의 테스트 데이터이미지로 실험하여 mean absolute error (MAE) 성능지표를 기준으로 4.5951의 값을 얻었다.","Recently, convolutional neural network (CNN) have been showed outstanding performance in the field of image recognition, image processing and computer vision, etc. In this paper, we propose a CNN-based image rotation correction algorithm as a solution to image rotation problem, which is one of the factors that reduce the recognition rate in image recognition system using CNN. In this paper, we trained our deep learning model with Leeds Sports Pose dataset to extract the information of the rotated angle, which is randomly set in specific range. The trained model is evaluated with mean absolute error (MAE) value over 100 test data images, and it is obtained 4.5951."
CNN 및 모델 시각화 기법을 사용한 코팅 볼트 불량 판별,2020,"['풀림 방지 코팅 볼트', '합성곱 신경망', '클래스 활성화 맵', '그래드 캠', '관심 영역 지정', 'Anti-Loosening Coating Bolt', 'Convolutional Neural Networks', 'Class Activation Mapping', 'Gradient-Weighted Class Activation Mapping', 'Region of Interest']","자동차 부품은 대부분 볼트로 체결되며 풀림을 방지하기 위해 코팅 처리를 한다. 볼트 나사산에 코팅액 도포 시 용액의 점도 및 분사 속도로 불량 제품이 발생되어 비전 또는 수동으로 불량을 선별하나 시간 및 비용 문제로 자동화 공정이 필요하다. 이에 기존 연구는 서포트 벡터 머신(SVM)을 적용했으나, 데이터 크기에 따른 속도 저하 및 추가 학습 불가능으로 양산 적용이 어렵다. 문제점을 보완하고자 본 연구는 합성곱 신경망(CNN)으로 코팅 불량을 학습하고 향상된 볼트 불량 판별을 위해 시각화 기법을 사용한다. 코팅 불량 판별 알고리듬으로 사용된 CNN은 VGG-16이며, 97%의 정확도를 확보했다. 이는 시각화 기법을 적용해 풀림 방지 코팅 이외에 조명, 볼트 지그 등 주변 다른 요인의 영향 또한 포함함을 확인했다. 이를 개선하기 위해 이미지 전처리를 사용해 볼트 영역만을 표현했다. 재학습 모델은 97%의 정확도로 초기 모델과 비슷하지만, 코팅 불량만을 판단할 수 있다. 본 연구에서 적용한 CNN 시각화 기법을 통해 기존 알 수 없었던 불량의 판단 기준 및 위치를 정량적으로 정확히 판단할 수 있었다.","The loosening of bolts, as they are used in automotive, can be effectively prevented by an anti-loosening coating. Coating defects are often caused by inappropriate viscosity and dispensing speed of the coating solution. As bolts are mass produced, an automated defect detection process is crucial. Support vector machines, however, are unsuitable for mass production because of their slow detection speed and inability to learn. In this study a visualization technique is combined with a convolutional neural network (CNN) to learn the detection and categorization of coating defects. The CNN used is VGG-16, which provides a 97 % accuracy. Other influences, such as illumination and the color of the jig holding the bolt, are eliminated using image preprocessing to remove all areas except the bolt thread area. The relearning model is shown to have the same accuracy as the initial model (97 %), but bolt coating defects can now be detected. The proposed CNN visualization technique enables the quantitative and accurate determination of previously unknown defects and their locations."
Weather Recognition Based on 3C-CNN,2020,"['Weather recognition', 'deep learning', 'ResNet50', '3C-CNN', 'WeatherDataset-6']",,"Human activities are often affected by weather conditions. Automatic weather recognition is meaningful to traffic alerting, driving assistance, and intelligent traffic. With the boost of deep learning and AI, deep convolutional neural networks (CNN) are utilized to identify weather situations. In this paper, a three-channel convolutional neural network (3C-CNN) model is proposed on the basis of ResNet50.The model extracts global weather features from the whole image through the ResNet50 branch, and extracts the sky and ground features from the top and bottom regions by two CNN5 branches. Then the global features and the local features are merged by the Concat function. Finally, the weather image is classified by Softmax classifier and the identification result is output. In addition, a medium-scale dataset containing 6,185 outdoor weather images named WeatherDataset-6 is established. 3C-CNN is used to train and test both on the Two-class Weather Images and WeatherDataset-6. The experimental results show that 3C-CNN achieves best on both datasets, with the average recognition accuracy up to 94.35% and 95.81% respectively, which is superior to other classic convolutional neural networks such as AlexNet, VGG16, and ResNet50. It is prospected that our method can also work well for images taken at night with further improvement."
CNN기초로 세 가지 방법을 이용한 감정 표정 비교분석,2020,"['Deep Learning', 'Emotion Recognition', 'CNN', 'Batch Normalization', 'Dropout']",,"CNN's technologies that represent emotional detection include primitive CNN algorithms, deployment normalization, and drop-off. We present the methods and data of the three experiments in this paper. The training database and the test database are set up differently. The first experiment is to extract emotions using Batch Normalization, which complemented the shortcomings of distribution. The second experiment is to extract emotions using Dropout, which is used for rapid computation. The third experiment uses CNN using convolution and maxpooling. All three results show a low detection rate, To supplement these problems, We will develop a deep learning algorithm using feature extraction method specialized in image processing field."
압축된 영상 복원을 위한 양자화된 CNN 기반 초해상화 기법,2020,"['Super-Resolution', 'CNN', 'Deep Learning', 'Degradation Model', 'Compressed Image']",,"In this paper, we propose a super-resolution method that reconstructs compressed low-resolution images into high-resolution images. We propose a CNN model with a small number of parameters, and even if quantization is applied to the proposed model, super-resolution can be implemented without deteriorating the image quality. To further improve the quality of the compressed low-resolution image, a new degradation model was proposed instead of the existing bicubic degradation model. The proposed degradation model is used only in the training process and can be applied by changing only the parameter values to the original CNN model. In the super-resolution image applying the proposed degradation model, visual artifacts caused by image compression were effectively removed. As a result, our proposed method generates higher PSNR values at compressed images and shows better visual quality, compared to conventional CNN-based SR methods."
Deep CNN based Pilot Allocation Scheme in Massive MIMO systems,2020,"['Deep Learning', 'CNN', 'MLP', 'pilot contamination', 'pilot assignment', 'massive MIMO', 'SIR']",,"This paper introduces a pilot allocation scheme for massive MIMO systems based on deep convolutional neural network (CNN) learning. This work is an extension of a prior work on the basic deep learning framework of the pilot assignment problem, the application of which to a high-user density nature is difficult owing to the factorial increase in both input features and output layers. To solve this problem, by adopting the advantages of CNN in learning image data, we design input features that represent users’ locations in all the cells as image data with a two-dimensional fixed-size matrix. Furthermore, using a sorting mechanism for applying proper rule, we construct output layers with a linear space complexity according to the number of users. We also develop a theoretical framework for the network capacity model of the massive MIMO systems and apply it to the training process. Finally, we implement the proposed deep CNN-based pilot assignment scheme using a commercial vanilla CNN, which takes into account shift invariant characteristics. Through extensive simulation, we demonstrate that the proposed work realizes about a 98% theoretical upper-bound performance and an elapsed time of 0.842 ms with low complexity in the case of a high-user-density condition."
RGB-D 이미지를 활용한 CNN 기반 실시간 파지점 탐색,2020,"['grasping point detection', 'grasp planning', 'grasping', 'grasp detection', 'CNN', 'picking', '파지점 탐색', '물체 파지', 'grasping', 'grasp detection', 'CNN', '물체 피킹']","본 논문에서는 RGB-D 이미지를 활용한 CNN 기반의 실시간 파지점 탐색 알고리즘을 제안한다. 파지점 탐색이란 로봇의 손으로 물체의 어느 지점을 잡았을 때 안정적으로 물체를 들어 올릴 수 있는 지 결정하는 기술로 단순한 이미지 내의 물체 탐지 기법과는 차이가 있다. 파지의 위치가 불안정할 경우 로봇의 손으로 물체를 들어 올리는 과정 중 물체를 떨어뜨리거나 동작을 수행할 수 없는 경우가 발생하기에 정확하고 안정적인 파지점 탐색이 필요하다. 인식된 물체의 사전 정보 없이 주어진 RGB-D 영상으로부터 파지점을 탐색하며, 파지점 탐색 알고리즘의 정량적인 평가를 위해 빠른 Rectangle Metric 측정 알고리즘을 제안한다. 본 논문에서 제안하는 알고리즘은 통해 이미지 처리가 아닌 학습을 통한 인경신경망 모델을 사용함으로서 단순한 형태의 물체뿐만이 아닌 복잡한 형태의 물체의 파지점 탐색까지도 가능하다.","In this paper, we propose a CNN-based real-time grasping point detection algorithm using RGB-D images. Grasping point detection is a technique that determines where and how a robot should grab an object to lift it stably, this makes it quite unlike simple object detection. If the grasp is unstable, due to a poor choice of location, it is easy to drop the object when the robot lifts it and therefore the robot may fail to complete the requested task. As such, accurate and stable grasping point detection is essential for the robotics industry. Also, we introduce a fast measurement algorithm based on the rectangle metric for the quantitative evaluation of the grasping point detection technique.The proposed algorithm is able to search for grasping points on objects with complex shapes as well as simple ones by using neural network learning rather than simple image processing."
HS 코드 분류를 위한 CNN 기반의 추천 모델 개발,2020,['HS'],,"The current tariff return system requires tax officials to calculate tax amount by themselves and pay the tax amount on their own responsibility. In other words, in principle, the duty and responsibility of reporting payment system are imposed only on the taxee who is required to calculate and pay the tax accurately. In case the tax payment system fails to fulfill the duty and responsibility, the additional tax is imposed on the taxee by collecting the tax shortfall and imposing the tax deduction on For this reason, item classifications, together with tariff assessments, are the most difficult and could pose a significant risk to entities if they are misclassified. For this reason, import reports are consigned to customs officials, who are customs experts, while paying a substantial fee. The purpose of this study is to classify HS items to be reported upon import declaration and to indicate HS codes to be recorded on import declaration. HS items were classified using the attached image in the case of item classification based on the case of the classification of items by the Korea Customs Service for classification of HS items. For image classification, CNN was used as a deep learning algorithm commonly used for image recognition and Vgg16, Vgg19, ResNet50 and Inception-V3 models were used among CNN models. To improve classification accuracy, two datasets were created. Dataset1 selected five types with the most HS code images, and Dataset2 was tested by dividing them into five types with 87 Chapter, the most among HS code 2 units. The classification accuracy was highest when HS item classification was performed by learning with dual database2, the corresponding model was Inception-V3, and the ResNet50 had the lowest classification accuracy. The study identified the possibility of HS item classification based on the first item image registered in the item classification determination case, and the second point of this study is that HS item classification, which has not been attempted before, was attempted through the CNN model."
MFCC와 CNN을 이용한 저고도 초소형 무인기 탐지 및 분류에 대한 연구,2020,[],,"This paper is related to detection and classification for micro-sized aircraft that flies at low-altitude. The deep-learning based method using sounds coming from the micro-sized aircraft is proposed to detect and identify them efficiently. We use MFCC as sound features and CNN as a detector and classifier. We've proved that each micro-drones have their own distinguishable MFCC feature and confirmed that we can apply CNN as a detector and classifier even though drone sound has time-related sequence. Typically many papers deal with RNN for time-related features, but we prove that if the number of frame in the MFCC features are enough to contain the time-related information, we can classify those features with CNN. With this approach, we've achieved high detection and classification ratio with low-computation power at the same time using the data set which consists of four different drone sounds. So, this paper presents the simple and effecive method of detection and classification method for micro-sized aircraft."
객체 검출을 위한 CNN과 YOLO 성능 비교 실험,2020,"['Object Detection', 'CNN (Convolutional Neural Networks)', 'YOLO (You Only Look Once)', 'Computer Vision']",,"Object detection plays a critical role in the field of computer vision, and various researches have rapidly increased along with applying convolutional neural network and its modified structures since 2012. There are representative object detection algorithms, which are convolutional neural networks and YOLO. This paper presents two representative algorithm series, based on CNN and YOLO which solves the problem of CNN bounding box. We compare the performance of algorithm series in terms of accuracy, speed and cost. Compared with the latest advanced solution, YOLO v3 achieves a good trade-off between speed and accuracy."
도플러 레이다 및 음성 센서를 활용한CNN 기반 HMI 시스템 설계 및 구현,2020,"['accelerator', 'convolutional neural network', 'FPGA', 'human machine interface', 'sensor fusion']","본 논문에서는 도플러 레이다와 음성 센서를 이용한 CNN 기반 HMI 시스템을 제안하고, 가속을 위한 하드웨어 설계 및구현 결과를 제시한다. 단일 센서 모니터링의 한계를 극복하기 위해 제안된 HMI 시스템은 두 센서의 데이터를 융합 처리하여 분류 성능을 개선했다. 제안된 시스템은 다양한 노이즈 환경에서 단일 레이다 및 음성 센서 기반 분류기에 비해 3.5% 및12% 향상된 성능을 나타냈다. 또한, CNN의 복잡한 연산부를 가속하기 위해 설계된 하드웨어를 FPGA 디바이스 상에서 구현 및 검증하였다. 성능 평가 결과, 제안된 HMI 가속 플랫폼은 단일 소프트웨어 기반 구조에 비해 연산 시간을 95% 단축가능한 것을 확인하였다.","In this paper, we propose CNN-based HMI system using Doppler radar and voice sensor, and present hardware designand implementation results. To overcome the limitation of single sensor monitoring, the proposed HMI system combinesdata from two sensors to improve performance. The proposed system exhibits improved performance by 3.5% and 12%compared to a single radar and voice sensor-based classifier in noisy environment. In addition, hardware to accelerate thecomplex computational unit of CNN is implemented and verified on the FPGA test system. As a result of performanceevaluation, the proposed HMI acceleration platform can be processed with 95% reduction in computation time comparedto a single software-based design."
결절성 폐암 검출을 위한 상용 및 맞춤형 CNN의 성능 비교,2020,"['Pulmonary Nodule', 'Computer Aided Detection', 'Deep Neural Network', 'Convolutional Neural Networ']",,"Screening with low-dose spiral computed tomography (LDCT) has been shown to reduce lung cancer mortality by about 20% when compared to standard chest radiography. One of the problems arising from screening programs is that large amounts of CT image data must be interpreted by radiologists. To solve this problem, automated detection of pulmonary nodules is necessary; however, this is a challenging task because of the high number of false positive results. Here we demonstrate detection of pulmonary nodules using six off-the-shelf convolutional neural network (CNN) models after modification of the input/output layers and end-to-end training based on publicly databases for comparative evaluation. We used the well-known CNN models, LeNet-5, VGG-16, GoogLeNet Inception V3, ResNet-152, DensNet201, and NASNet. Most of the CNN models provided superior results to those of obtained using customized CNN models. It is more desirable to modify the proven off-the-shelf network model than to customize the network model to detect the pulmonary nodules."
이미지 잡음에 강인한 CNN 기반 건물 인식 방법,2020,[],,"The ability to extract useful information from an image, such as the human eye, is an interface technology essential for AI computer implementation. The building recognition technology has a lower recognition rate than other image recognition technologies due to the various building shapes, the ambient noise images according to the season, and the distortion by angle and distance. The computer vision based building recognition algorithms presented so far has limitations in discernment and expandability due to manual definition of building characteristics. This paper introduces the deep learning CNN (Convolutional Neural Network) model, and proposes new method to improve the recognition rate even by changes of building images caused by season, illumination, angle and perspective. This paper introduces the partial images that characterize the building, such as windows or wall images, and executes the training with whole building images. Experimental results show that the building recognition rate is improved by about 14% compared to the general CNN model."
CNN을 이용한 뇌전증 발작예측에 관한 연구,2020,"['EEG', 'Epilepsy EEG', 'interictal', 'preictal', 'seizure', 'CNN', 'LSTM']",,"In this paper, the new architecture of seizure prediction using CNN and LSTM and DWT was presented. In the proposed architecture, EEG data was labeled into a preictal and interictal section, and DWT was adopted to the preprocessing process to apply the characteristics of the time and frequency domain of the processed EEG signal. Also, CNN was applied to extract the spatial characteristics of each electrode used for EEG measurement, and LSTM neural network was applied to verify the logical order of the preictal section. The learning of the proposed architecture utilizes the CHB-MIT Scalp EEG dataset, and the sliding window technique is applied to balance the dataset between the number of interictal sections and the number of preictal sections. As a result of the simulation of the proposed architecture, a sensitivity of 81.22% and an FPR of 0.174 were obtained."
CNN Mobile Net 기반 악성코드 탐지 모델에서의 학습 데이터 크기와 검출 정확도의 상관관계 분석,2020,"['CNN Mobile Net', 'Malware Detection Algoritm', 'Machine Learning', 'Security Data Analysis', 'Network Event']",현재 4차 산업혁명을 맞이하여 머신러닝과 인공지능 기술이 급속도로 발전하고 있으며 보안 분야에서도 머신러닝 기술을 응용하려는 움직임이 있다. 많은 악성코드가 생성됨에 따라 사람의 힘으로는 모든 악성코드를 탐지하기 어려워지고 있기 때문이다. 이에 따라 학계와 산업계에서는 머신러닝을 통해 악성코드나 네트워크 침입 이벤트를 탐지하는 것에 관한 연구가 활발히 진행되고 있으며 국제 학회와 저널에서는 머신러닝의 한 분야인 딥러닝을 이용한 보안데이터 분석 연구가 논문 발표되고 있다. 그러나 해당 논문들은 검출 정확도에 초점이 맞추어져 있고 검출 정확도를 높이기 위해 여러 파라미터들을 수정하지만 Dataset의 개수를 고려하지 않고 있다. 따라서 본 논문에서는 CNN Mobile net 기반 악성코드 탐지 모델에서 가장 높은 검출 정확도를 도출할 수 있는 Dataset의 개수을 찾아내어 많은 머신러닝 연구 진행에 비용과 리소스를 줄이고자 한다.,"At the present stage of the fourth industrial revolution, machine learning and artificial intelligence technologies are rapidly developing, and there is a movement to apply machine learning technology in the security field. Malicious code, including new and transformed, generates an average of 390,000 a day worldwide. Statistics show that security companies ignore or miss 31 percent of alarms. As many malicious codes are generated, it is becoming difficult for humans to detect all malicious codes. As a result, research on the detection of malware and network intrusion events through machine learning is being actively conducted in academia and industry. In international conferences and journals, research on security data analysis using deep learning, a field of machine learning, is presented. have. However, these papers focus on detection accuracy and modify several parameters to improve detection accuracy but do not consider the ratio of dataset. Therefore, this paper aims to reduce the cost and resources of many machine learning research by finding the ratio of dataset that can derive the highest detection accuracy in CNN Mobile net-based malware detection model."
미세먼지 예측 성능 개선을 위한 CNN-LSTM 결합 방법,2020,[],,"Recently, due to the proliferation of IoT sensors, the development of big data and artificial intelligence, time series prediction research on fine dust pollution is actively conducted. However, because the data representing fine dust contamination changes rapidly, traditional time series prediction methods do not provide a level of accuracy that can be used in the field. In this paper, we propose a method that reflects the classification results of environmental conditions through CNN when predicting micro dust contamination using LSTM. Although LSTM and CNN are independent, they are integrated into one network through the interface, so this method is easier to understand than the application LSTM. In the verification experiments of the proposed method using Beijing PM2.5 data, the prediction accuracy and predictive power for the timing of change were consistently improved in various experimental cases."
스펙트로그램 이미지를 이용한 CNN 기반 자동화 기계 고장 진단 기법,2020,[],"소리 기반 기계 고장 진단은 기계의 음향 방출 신호에서 비정상적인 소리를 자동으로 감지하는 것이다. 수학적 모델을 사용하는 기존의 방법은 기계 시스템의 복잡성과 잡음과 같은 비선형 요인이 존재하기 때문에 기계 고장 진단이 어려웠다. 따라서 기계 고장 진단의 문제를 딥러닝 기반 이미지 분류 문제로 해결하고자 한다. 본 논문에서 스펙트로그램 이미지를 이용한 CNN 기반 자동화 기계 고장 진단 기법을 제안한다. 제안한 방법은 기계의 결함 시 발생하는 주파수상의 특징 벡터를 효과적으로 추출하기 위해 STFT를 사용하였으며, STFT에 의해 검출된 특징 벡터들은 스펙트로그램 이미지로 변환하여 CNN을 이용해 기계의 상태별로 분류한다. 그 결과는 제안한 방법은 효과적으로 결함을 탐지할 뿐만 아니라 소리 기반의 다양한 자동 진단 시스템에도 효과적으로 활용될 수 있다.",
변형된 잔차블록을 적용한 CNN,2020,"['CNN', 'Residual Learning', 'Bottleneck', 'ResNet']",,"This paper proposes an image classification algorithm that transforms the number of convolution layers in the residual block of ResNet, CNN's representative method. The proposed method modified the structure of 34/50 layer of ResNet structure. First, we analyzed the performance of small and many convolution layers for the structure consisting of only shortcut and 3 × 3 convolution layers for 34 and 50 layers.And then the performance was analyzed in the case of small and many cases of convolutional layers for the bottleneck structure of 50 layers. By applying the results, the best classification method in the residual block was applied to construct a 34-layer simple structure and a 50-layer bottleneck image classification model. To evaluate the performance of the proposed image classification model, the results were analyzed by applying to the cifar10 dataset. The proposed 34-layer simple structure and 50-layer bottleneck showed improved performance over the ResNet-110 and Densnet-40 models"
CNN기반의 학습모델을 활용한 거북목 증후군 자세 교정 시스템,2020,"['거북목증후군', '자세습관', '합성곱신경망', '스마트기기', '웹캠', '실시간', 'Turtle Neck Syndrome', 'Postural Habit', 'CNN', 'Smart Devices', 'Webcam', 'Real Time']","스마트 기기 사용의 증가와 함께 현대인들의 거북목 증후군 발병률이 증가했다. 거북목 증후군은 목의 앞 근육이 길어지고, 위쪽 근육이 짧아져 몸통에 비해 머리가 앞으로 나와 있는 자세이며, 수술이나 약물치료보다 평소의 자세 습관을 고치는 방법이 효과적이다. 따라서 본 논문에서는 실시간으로 거북목 증후군을 유발할 수 있는 자세를 감지하고 경고하는 시스템을 제안한다. 올바른 자세와 거북목 자세의 이미지 데이터들을 수집하여 합성곱 신경망기반의 학습모델을 만든다. 웹캠만을 이용하여 카메라에 들어오는 앉은 자세를 학습모델로 실시간 검증하고, 거북목 자세일 경우 경고음을 발생하여 바른 자세를 앉도록 유도한다. 이 시스템은 평소 자세 습관을 교정하도록 유도하여 거북목증후군을 치료하고 목 디스크와 같은 더 심각한 질병을 예방할 수 있다.","Along with the increased use of smart devices, the incidence of turtle neck syndrome among modern people has increased. Turtle neck syndrome is a posture in which the head is forward compared to the torso due to longer front muscles in the neck and shorter upper muscles, and it is more effective to fix the usual posture habits than surgery or medication. Thus, in this paper, a system is proposed to detect and warn posture that can cause turtle neck syndrome in real time. Image data of correct posture and turtle neck posture are collected to create a CNN-based learning model. Using only the webcam(Built-in camera), the sitting position that enters the camera is verified in real time through the learning model, and if it is a turtle neck position, it generates a warning sound and induces the correct posture. The system can induce people to correct their usual posture habits to treat turtle neck syndrome and prevent more serious diseases such as neck discs."
CNN을 이용한 자율주행차 조향 제어,2020,[],,"Among the autonomous driving systems based on visual sensors, the control method using a vanishing point is the most general method for autonomous driving. However, if the lane is lost or does not exist, it is very difficult to detect this and estimate the vanishing point. In this paper, we predict the vanishing point of the road and the vanishing point lines on the left and right sides using CNN for the camera image and design the steering controller for autonomous driving from the predicted results. As a result of the simulation, it was confirmed that the proposed method well tracked the center of the road regardless of the presence or absence of a solid lane, and was superior to the control method using a general method using the vanishing point."
CNN 기반 위장관 랜드마크 분류기를 이용한 위장관 교차점 추정,2020,"['Capsule Endoscopy(CE)', 'Convolutional Neural Network(CNN)', 'Gastrointestinal Location Tracking', '캡슐내시경', '컨볼루션 신경망', '위장관 위치 추적']",,"Since the performance of deep learning techniques has recently been proven in the field of image processing, there are many attempts to perform classification, analysis, and detection of images using such techniques in various fields. Among them, the expectation of medical image analysis software, which can serve as a medical diagnostic assistant, is increasing. In this study, we are attention to the capsule endoscope image, which has a large data set and takes a long time to judge. The purpose of this paper is to distinguish the gastrointestinal landmarks and to estimate the gastrointestinal transition location that are common to all patients in the judging of capsule endoscopy and take a lot of time. To do this, we designed CNN-based Classifier that can identify gastrointestinal landmarks, and used it to estimate the gastrointestinal transition location by filtering the results. Then, we estimate gastrointestinal transition location about seven of eight patients entered the suspected gastrointestinal transition area. In the case of change from the stomach to the small intestine(pylorus), and change from the small intestine to the large intestine(ileocecal valve), we can check all eight patients were found to be in the suspected gastrointestinal transition area. we can found suspected gastrointestinal transition area in the range of 100 frames, and if the reader plays images at 10 frames per second, the gastrointestinal transition could be found in 10 seconds."
CNN기반 정규화 리사주 도형을 이용한 전자식 밸브 고장진단알고리즘,2020,"['Convolutional Neural Network', 'Electronic Valve', 'Fault Diagnosis', 'Lissajous', 'Normalization']",,"Currently, the K-Water uses various valves that can be remotely controlled for optimal water management. Valve system fault can be classified into rotor defects, stator defects, bearing defects, and gear defects of induction motors. If the valve cannot be operated due to a gear fault, the water management operation can be greatly affected. For effective water management, there is an urgent need for preemptive repairs to determine whether gear is damaged through failure prediction diagnosis.. Recently, deep learning algorithms are being applied for valve failure diagnosis. However, the method currently applied has a disadvantage of attaching a vibration sensor to the valve. In this paper, propose a new algorithm to determine whether a fault exists using a convolutional neural network (CNN) based on the voltage and current information of the valve without additional sensor mounting. In particular, a normalized Lisasjous diagram was used to maximize the fault classification performance in the CNN-based diagnostic system."
Triplet CNN과 학습 데이터 합성 기반 비디오 안정화기 연구,2020,"['video stabilization', 'convolutional neural network', 'wobbling distortion']","영상 내 흔들림은 비디오의 가시성을 떨어뜨리고 영상처리나 영상압축의 효율을 저하시킨다. 최근 디지털 영상처리 분야에 딥러닝이 본격 적용되고 있으나, 비디오 안정화 분야에 딥러닝 적용은 아직 초기 단계이다. 본 논문에서는 Wobbling 왜곡 경감을 위한 triplet 형태의 CNN 기반 비디오 안정화기 구조를 제안하고, 비디오 안정화기 학습을 위한 학습데이터 합성 방법을 제안한다. 제안한 CNN 기반 비디오 안정화기는 기존 딥러닝 기반 비디오 안정화기와 비교되었으며, Wobbling 왜곡은 감소하고 더 안정적인 학습이 이루어지는 결과를 얻었다.",
CNN 기반 독성 식물 판별 시스템,2020,[],,"The technology of interiors is currently developing around the world. According to various studies, the use of plants to create an environment in the home interior is increasing. However, households using furniture are designed as environment-friendly environment interiors, and in Korea and abroad, plants are used for home interiors. Unexpected accidents are occurring. As a result, there were books and broadcasts about the dangers of specific plants, but until now, accidents continue to occur because they do not properly recognize the dangers of specific plants. Therefore, in this paper, we propose a toxic plant identification system based on a multiplicative neural network model that identifies common toxic plants commonly found in Korea. We propose a high efficiency model. Through this, toxic plants can be identified with higher accuracy and safety accidents caused by toxic plants."
CNN을 이용한 혀 영역 분할과 설열 검출,2020,"['Tongue diagnosis', 'Tongue crack', 'Segmentation of tongue area', 'U-Net', 'Adaptive threshold technique', '설진', '설열', '혀 영역 분할', 'U-Net', '적응이진화']","설진은 동양의학에서 신체의 현재 상태를 판단하는 중요한 기법 중에 하나다. 본 논문은 CNN과 영상처리 기법을 이용하여, 설진의 요소 중에 하나인 설열의 검출에 관한 것이다. 먼저 촬영된 영상에서 U-Net을 이용하여 혀 영역을 분할하는데, 입술의 색상과 패턴은 혀와 유사하기 때문에 혀 영역의 완벽한 분할이 쉽지 않다. 본 연구에서는 후처리를 이용하여 잘못 분할된 부분을 제거한다. 그리고 난 후, 분리된 혀 영상을 적응이진화 기법으로 정상적인 맛봉오리와 형태가 다른 객체들을 검출한다. 검출된 것에는 설열 뿐만 아니라 설반, 설문도 포함되어 있기 때문에, 후처리를 통하여 설열이외의 객체를 제거한다. 검출된 설열은 혀의 각 부위와 대응되는 장기의 이상 유무를 판단하는데활용될 수 있다.","Tongue diagnosis is one of the important techniques for examining the body condition in oriental medicine. In this paper, we have studied the detection of tongue cracks for tongue diagnosis using convolutional neural networks and image processing techniques. First, a tongue region is segmented from a image using the U-Net. Because the color and pattern of the lips are similar to the tongue, it is not easy to segment the tongue area perfectly. In this study, incorrectly segmented areas were removed using post-processing. Then, objects with different shapes from normal taste buds are detected using an adaptive thresholding technique in the image. Since the detected objects include not only the tongue cracks but also the tongue spots and patterns, Objects other than tongue cracks are removed through post-processing. The detected tongue cracks can be used to examine whether there are abnormalities in the organ corresponding to each part of the tongue"
수중에서의 특징점 매칭을 위한 CNN기반 Opti-Acoustic변환,2020,"['Sonar', 'Deep Learning', 'Underwater', 'Feature Matching']",,"In this paper, we introduce the methodology that utilizes deep learning-based front-end to enhance underwater feature matching. Both optical camera and sonar are widely applicable sensors in underwater research, however, each sensor has its own weaknesses, such as light condition and turbidity for the optic camera, and noise for sonar. To overcome the problems, we proposed the opti-acoustic transformation method. Since feature detection in sonar image is challenging, we converted the sonar image to an optic style image. Maintaining the main contents in the sonar image, CNN-based style transfer method changed the style of the image that facilitates feature detection. Finally, we verified our result using cosine similarity comparison and feature matching against the original optic image."
대용량 이미지넷 인식을 위한 CNN 기반 Weighted 앙상블 기법,2020,"['Deep learning', 'ImageNet', 'ILSVRC', 'Ensemble', 'Weighted ensemble', 'Image classification', 'Data augmentation']",,"The ImageNet dataset is a large scale dataset and contains various natural scene images. In this paper, we propose a convolutional neural network (CNN)-based weighted ensemble technique for the ImageNet classification task. First, in order to fuse several models, our technique uses weights for each model, unlike the existing average-based ensemble technique. Then we propose an algorithm that automatically finds the coefficients used in later ensemble process. Our algorithm sequentially selects the model with the best performance of the validation set, and then obtains a weight that improves performance when combined with existing selected models. We applied the proposed algorithm to a total of 13 heterogeneous models, and as a result, 5 models were selected. These selected models were combined with weights, and we achieved 3.297% Top-5 error rate on the ImageNet test dataset."
CNN기반 딥러닝을 이용한 Kuzushiji-MNIST/49 분류의 정확도 향상을 위한 학습 방안,2020,[],,"In this paper, we propose a deep learning training method for accurately classifying Kuzushiji-MNIST and Kuzushiji-49 datasets for ancient and medieval Japanese characters. We analyze the latest convolutional neural network networks through experiments to select the most suitable network, and then use the networks to select the number of training to classify Kuzushiji-MNIST and Kuzushiji-49 datasets. In addition, the training is conducted with high accuracy by applying learning methods such as Mixup and Random Erase. As a result of the training, the accuracy of the proposed method can be shown to be high by 99.75% for MNIST, 99.07% for Kuzushiji-MNIST, and 97.56% for Kuzushiji-49. Through this deep learning-based technology, it is thought to provide a good research base for various researchers who study East Asian and Western history, literature, and culture."
CNN-based Gesture Recognition using Motion History Image,2020,"['Gesture recognition', 'neural network', 'convolutional neural network', 'motion history image']",,"In this paper, we present a CNN-based gesture recognition approach which reduces the memory burden of input data. Most of the neural network-based gesture recognition methods have used a sequence of frame images as input data, which cause a memory burden problem. We use a motion history image in order to define a meaningful gesture. The motion history image is a grayscale image into which the temporal motion information is collapsed by synthesizing silhouette images of a user during the period of one meaningful gesture. In this paper, we first summarize the previous traditional approaches and neural network-based approaches for gesture recognition. Then we explain the data preprocessing procedure for making the motion history image and the neural network architecture with three convolution layers for recognizing the meaningful gestures. In the experiments, we trained five types of gestures, namely those for charging power, shooting left,shooting right, kicking left, and kicking right. The accuracy of gesture recognition was measured by adjusting the number of filters in each layer in the proposed network. We use a grayscale image with 240 x 320 resolution which defines one meaningful gesture and achieved a gesture recognition accuracy of 98.24%."
CNN을 이용한 태양전지 불량 검출,2020,"['solar cell', 'defects detection', 'convolutional neural network', 'deep learning', '.']",,"The efficiency of solar panel power production is greatly influenced by the state of the panel. Therefore, it can be said that it is an important factor to check whether a solar cell is damaged in managing solar power. Existing solar cell damage detection technology detects whether the solar cell is damaged by an electroluminescence phenomenon or by checking the degree of scattering by shining a laser. In this study, we attempt to detect the damage of the solar cell by using the deep learning method and taking the surface image of the solar cell without additional measuring device. When using the existing electroluminescence phenomenon, a separate device must be configured to check for damage, and there is a disadvantage in that the use of the connected cell must be stopped to confirm a part. The method of checking the degree of scattering by illuminating the laser has a disadvantage that many areas cannot be seen at once. To improve this, this paper presents a detection method based on deep learning. We present an algorithm that is based on CNN (Convolutional Neural Network). Experimental results according to model size and data augmentation are given to show the feasibility of proposed method."
Lightweight CNN-based Expression Recognition on Humanoid Robot,2020,"['Humanoid Robot', 'Human-machine interaction', 'CNN', 'Emotion Recognition']",,"The human expression contains a lot of information that can be used to detect complex conditions such as pain and fatigue. After deep learning became the mainstream method, the traditional feature extraction method no longer has advantages. However, in order to achieve higher accuracy, researchers continue to stack the number of layers of the neural network, which makes the real-time performance of the model weak. Therefore, this paper proposed an expression recognition framework based on densely concatenated convolutional neural networks to balance accuracy and latency and apply it to humanoid robots. The techniques of feature reuse and parameter compression in the framework improved the learning ability of the model and greatly reduced the parameters. Experiments showed that the proposed model can reduce tens of times the parameters at the expense of little accuracy."
데이터 균형화 알고리즘을 이용한 CNN 기반 피부질환 이미지 분류기의 성능 분석,2020,"['imbalanced class', 'deep learning', 'dermoscopic image', 'cross validation']","본 연구에서는 클래스 불균형을 가진 피부질환 이미지 데이터셋을 딥러닝 모델을 이용하여 분류하는 문제에 있어서, 다수 클래스에 편향되지 않으면서, 희소 클래스의 분류 민감도를 높이기 위한 데이터 균형화 알고리즘을 딥러닝 학습에 적용하고 성능을 분석하였다. 이를 위해 불균형 데이터셋인 HAM10000에 데이터 균형화 알고리즘(ROS, SMOTE, ADASYN, BSMOTE, SVMSMOTE)을 적용하여 학습한 모델과 그렇지 않은 모델의 정확도, 민감도, 정밀도, F1 점수를 측정하여 분류 성능을 비교하고, 교차 검증(5-fold cross-validation)을 통해 그 효과를 분석하였다. 실험에 사용한 HAM100000 데이터셋은 7종 피부질환에 대해 총 10,015장의 피부경 이미지로 구성되며, 해상도는 600×450이다. 실험을 통해, 데이터 균형화 알고리즘 적용 후 피부질환 이미지 분류기의 민감도(3.1%∼6.6%), 정밀도(2.2%∼7.5%), F1 점수(2.7%∼6.6%)가 유의미하게 증가하였다(p<0.05). 이를 통해 데이터 균형화 알고리즘이 불균형 학습데이터의 분류 성능 향상에 기여할 수 있음을 확인하였다.","In order to improve the sensitivity of the minority class without being biased to the majority class, the data balancing algorithms such as ROS, SMOTE, ADASYN, BSMOTE and SVMSMOTE, were applied to imbalanced dataset, HAM10000. It consists of a total of 10,015 dermoscopic images for 7 classes of skin disease with a resolution of 600×450. Then, their performances with and without the data balancing algorithms, including accuracies, sensitivities, precisions, F1-scores. were measured, respectively, and the effect of the data balancing algorithm was verified through 5-fold cross-validation test. Consequently, with applying the data balancing algorithms, the average values of the sensitivities(3.1%∼6.6%), precisions(2.2%∼7.5%) and F1-scores(2.7%∼6.6%) increased significantly (p<0.05). It was shown that they can contribute to the improvement of the performance of the classification of an imbalanced dataset using deep learning model."
원격 탐사 영상을 활용한 CNN 기반의 초해상화 기법 연구,2020,"['SISR', 'remote sensing image', 'super resolution', 'edge loss', 'DPID']","초해상화 기법은 저해상도 영상을 고해상도 영상으로 변환하는 기법이다. 최근에는 딥러닝 기술을 활용한 초해상화 방법이 주류를 이루고 있으며, 원격 탐사 분야에서도 이를 응용한 연구가 증가하고 있다. 본 연구에서는 위성 영상의 4배 해상도 향상을 위하여 deep back-projection network (DBPN) 네트워크에 기반한 초해상화 기법을 제안하였다. 또한, 복원된 영상의 디테일 및 윤곽선 부분에서의 고품질 영상 획득을 위해 윤곽선 손실 함수를 제안하고, 효과적이고 안정적인 학습을 위하여 Wasserstein distance 손실 함수를 사용한 GAN 기법을 적용하였다. 또한, 자연스러운 저해상도 훈련 영상을 획득하기 위한 detail preserving image down-scaling (DPID) 기법을 적용하였다. 마지막으로 전정 영상의 특징을 추출하여 훈련의 마지막 단계에 적용 시킴으로써 출력 영상의 세부적인 특징을 효과적으로 생성하였다. 그 결과 실험에 사용된 WorldView-3 영상 및KOMPSAT-2 영상에서 해상도 향상 효과를 확인하였고, 다른 초해상화 모델에 대비하여 윤곽선 보존력이나영상의 선명도가 향상 되었음을 확인하였다.","Super-resolution is a technique used to reconstruct an image with low-resolution into that of high-resolution. Recently, deep-learning based super resolution has become the mainstream, and applications of these methods are widely used in the remote sensing field. In this paper, we propose a super-resolution method based on the deep back-projection network model to improve the satellite image resolution by the factor of four. In the process, we customized the loss function with the edge loss to result in a more detailed feature of the boundary of each object and to improve the stability of the model training using generative adversarial network based on Wasserstein distance loss. Also, we have applied the detail preserving image down-scaling method to enhance the naturalness of the training output.Finally, by including the modified-residual learning with a panchromatic feature in the final step of the training process. Our proposed method is able to reconstruct fine features and high frequency information.Comparing the results of our method with that of the others, we propose that the super-resolution method improves the sharpness and the clarity of WorldView-3 and KOMPSAT-2 images."
위성영상 내 항공기 식별 시 오탐률 감소를 위한 결합된 CNN 알고리즘,2020,"['CNN', 'YOLO', 'Mask R_CNN', 'Satellite Image', 'Aircraft Detection', 'CNN', 'YOLO', 'Mask R_CNN', '위성영상', '항공기 식별']","현재 영상 처리에 활발히 사용되고 있는 CNN 알고리즘은 고해상도/대규모 위성사진을 직접 처리하지 못한다. 이 문제를 해결하기 위해, 많은 연구에서 인공 신경망에 다양한 기술을 결합하려고 노력해왔다. 그러나 물체 식별과 검출에 영향을 미치는 여러 가지 요인에 의해 만족스러운 성과를 거두지 못하고 있는 실정이다. 특히 항공기 탐지의 경우 탑승구, 건물, 공항 내 교차로 등 항공기와 유사한 물체를 잘못된 탐지하는 문제가 제대로 해결되지 않았다. 본 논문은 이러한 오탐을 줄이기 위해 Mask R_CNN 알고리즘과 YOLO 알고리즘을 결합한 CNN 알고리즘을 제안한다. 제안된 접근방식의 성과를 평가하기 위해, 항공기와 유사한 물체가 다수 포함된 공항의 위성 영상에 대해 항공기 탐지 실험을 실시하였고, 그 결과 오탐이 상당히 감소함을 확인하였다.","CNN algorithms, which are currently actively used for image processing, do not process high resolution/large-scale satellite images directly. To address this problem, many researchers have tried to combine various techniques into the artificial neural networks. However, many studies have not achieved satisfactory performance due to various factors affecting object identification and detection. Especially in the case of aircraft detection, the false detection of objects similar to aircraft, such as boarding gates, buildings, and intersections within the airport, is not solved properly. This paper proposes a coupled CNN algorithm that combines the Mask R_CNN algorithm with the YOLO algorithm to reduce such false detection. To evaluate the performance of the proposed approach, we conduct the aircraft detection test was conducted on satellite images of airports containing a number of objects similar to aircraft."
CNN 잡음 감쇠기에서 커널 사이즈의 최적화,2020,"['잡음 감쇠', '심층학습', '커널 크기', 'CNN', 'Noise reduction', 'Deep learning', 'Convolutional neural network', 'Kernel size']","본 논문은 음향잡음감쇠기에서 CNN(Convolutional Neural Network) 계층의 커널 사이즈가 성능에 미치는 영향을 위한 연구하였다 이 시스템은 기존의 적응필터를 이용하는 대신 신경망 적응예측필터를 이용한 심층학습 알고리즘으로 잡음감쇠 성능을 개선한다. 100-neuron, 16-filter CNN 필터와 오차 역전파(back propagation) 알고리즘을 이용하여 잡음이 포함된 단일입력 음성신호로부터 음성을 추정한다. 이는 음성신호가 갖는 유성음 구간에서의 준주기적 성질을 이용하는 것이다. 본 연구에서 커널 사이즈에 대한 잡음감쇠기의 성능을 검증하기 위하여 Tensorflow와 Keras 라이브러리를 사용한 시뮬레이션 프로그램을 작성하고 모의실험을 수행하였다. 모의실험 결과, 커널 사이즈가 16 정도일 때 MSE 및 MAE 값이 가장 작은 것으로 나타났으며 사이즈가 이보다 더 작거나 커지면 MSE 및 MAE 값이 증가하는 것을 볼 수 있다. 이는 음성신호의 경우 커널 사이즈가 16 정도일 때 특성을 가장 잘 포집할 수 있음을 알 수 있다.","In this paper, we studied the effect of kernel size of CNN(Convolutional Neural Network) layer on performance in acoustic noise attenuators. This system uses a deep learning algorithm using a neural network adaptive prediction filter instead of using the existing adaptive filter. Speech is estimated from a single input speech signal containing noise using a 100-neuron, 16-filter CNN filter and an error back propagation algorithm. This is to use the quasi-periodic property in the voiced sound section of the voice signal. In this study, a simulation program using Tensorflow and Keras libraries was written and a simulation was performed to verify the performance of the noise attenuator for the kernel size. As a result of the simulation, when the kernel size is about 16, the MSE and MAE values are the smallest, and when the size is smaller or larger than this, the MSE and MAE values increase. It can be seen that in the case of an speech signal, features can be best captured when the kernel size is about 16."
Faster R-CNN 학습데이터 구축과 모델을 이용한 안전모 탐지 연구,2020,"['건설안전관리', '인공지능', '객체 탐지', 'Construction Safety Management', 'Artificial Intelligence', 'Faster R-CNN', 'Object Detection']","우리나라의 산업재해 중 건설 분야의 경우 전체의 28.55%의 고위험분야에 해당한다. 이러한 산업재해를 저감하기 위한활발하게 진행되고 있지만, 건설 안전분야 적용 연구는 아직 미비한 실정이다. 본 연구에서는 건설 안전분야의 안전 보호구착용 판별에 대한 최신 인공지능 R-CNN 알고리즘을 활용하여 한국형 데이터 학습모델 구축 연구를 수행하였고, 실시간영상 접목이 가능한 객체 탐지 솔루션을 구현하여 검증하였다. 본 연구수행 결과, 신규 한국형 안전모 착용 여부에 대한판별 데이터 학습모델은 평균 정밀도(mean Average Precision) 0.82의 우수한 결과로 건설 안전분야의 산업재해 저감을 이룰것으로 판단된다.","Among the industrial accidents occurring in Korea, the construction sector accounts for 28.55% of theaccidents associated with this high-risk sector. Although active progress is being made to reduce such industrial accidents, studies concerning the applications to construction site safety are currently insufficient. In this study, research is conducted on the development of a Korean data learning model using the latest in artificial intelligence algorithms, R-CNN, for the identification of safety protection equipmentworn by workers in the field. As a result of this study, the discriminant data learning model concerning the donning of a new Korean safety hard hat provided excellent results with a mean average precision of 0.82. This advancement is expected to reduce industrial accidents in the field of construction and improve safety."
다중 압력분포 기반의 착석 자세 분류를 위한 CNN 모델 구현,2020,[],,"Musculoskeletal disease is often caused by sitting down for long period's time or by bad posture habits. In order to prevent musculoskeletal disease in daily life, it is the most important to correct the bad sitting posture to the right one through real-time monitoring. In this study, to detect the sitting information of user's without any constraints, we propose posture measurement system based on multi-channel pressure sensor and CNN model for classifying sitting posture types. The proposed CNN model can analyze 5 types of sitting postures based on sitting posture information. For the performance assessment of posture classification CNN model through field test, the accuracy, recall, precision, and F1 of the classification results were checked with 10 subjects. As the experiment results, 99.84% of accuracy, 99.6% of recall, 99.6% of precision, and 99.6% of F1 were verified."
전투기용 레이다 기반 SAR 영상 자동표적분류 기능 구조 및 CNN 앙상블 모델을 이용한 표적분류 정확도 향상 방안 연구,2020,"['Auto Target Recognition', 'SAR', 'Radar', 'CNN']",,"The fighter pilot uses radar mounted on the fighter to obtain high-resolution SAR (Synthetic Aperture Radar) images for a specific area of distance, and then the pilot visually classifies targets within the image. However, the target configuration captured in the SAR image is relatively small in size, and distortion of that type occurs depending on the depression angle, making it difficult for pilot to classify the type of target. Also, being present with various types of clutters, there should be errors in target classification and pilots should be even worse if tasks such as navigation and situational awareness are carried out simultaneously. In this paper, the concept of operation and functional structure of radar system for fighter jets were presented to transfer the SAR image target classification task of fighter pilots to radar system, and the method of target classification with high accuracy was studied using the CNN ensemble model to archive higher classification accuracy than single CNN model."
정적 변형률 데이터를 사용한 CNN 딥러닝 기반 PSC 교량 손상위치 추정,2020,['PSC'],,"As the number of aging bridges increases, more studies are being conducted on developing effective and reliable methods for the assessment and maintenance of bridges. With the advancement in new sensing systems and data learning techniques through AI technology, there is growing interests in how to evaluate bridges using these advanced techniques. This paper presents a CNN(Convolution Neural Network) deep learning based technique for evaluating the damage existence and for estimating the damage location in PSC bridges using static strain data. Simulation studies were conducted to investigate the proposed method with error analysis. Damage was simulated as the reduction in the stiffness of a finite element. A data learning model was constructed by applying the CNN technique as a type of deep learning. The damage status and its location were estimated using data set built through simulation. It was assumed that the strain gauges were installed in a regular interval under the PSC bridge girders. In order to increase the accuracy in evaluating damage, the squared error between the intact and measured strains are computed and applied for training the data model. Considering the damage occurring near the supports, the results of error analysis were compared according to whether strain data near the supports were included."
Comparison of Different CNN Models in Tuberculosis Detecting,2020,"['Tuberculosis', 'CNN', 'sigmoid', 'binary cross entropy', 'SGD']",,"Tuberculosis is a chronic and delayed infection which is easily experienced by young people. According to the statistics of the World Health Organization (WHO), there are nearly ten million fell ill with tuberculosis and a total of 1.5 million people died from tuberculosis in 2018 (including 251000 people with HIV). Tuberculosis is the largest single infectious pathogen that leads to death. In order to help doctors with tuberculosis diagnosis, we compare the tuberculosis classification abilities of six popular convolutional neural network (CNN) models in the same data set to find the best model. Before training, we optimize three parts of CNN to achieve better results. We employ sigmoid function to replace the step function as the activation function. What’s more, we use binary cross entropy function as the cost function to replace traditional quadratic cost function. Finally, we choose stochastic gradient descent (SGD) as gradient descent algorithm. From the results of our experiments, we find that Densenet121 is most suitable for tuberculosis diagnosis and achieve a highest accuracy of 0.835. The optimization and expansion depend on the increase of data set and the improvements of Densenet121."
Mask R-CNN을 활용한 반도체 공정 검사,2020,"['Semiconductor Photo Lithography Inspection', 'Object Segmentation', 'Instance Segmentation', 'Digital Image Processing', 'Computer Vision System', 'Deep Learning', 'Convolutional Neural Network']",,"In semiconductor manufacturing, defect detection is critical to maintain high yield. Currently, computer vision systems used in semiconductor photo lithography still have adopt to digital image processing algorithm, which often occur inspection faults due to sensitivity to external environment. Thus, we intend to handle this problem by means of using Mask R-CNN instead of digital image processing algorithm. Additionally, Mask R-CNN can be trained with image dataset pre-processed by means of the specific designed digital image filter to extract the enhanced feature map of Convolutional Neural Network (CNN). Our approach converged advantage of digital image processing and instance segmentation with deep learning yields more efficient semiconductor photo lithography inspection system than conventional system."
"이미지 기반 기계 학습과 BIM을 활용한 자동화된 시공 진도 관리 - 합성곱 신경망 모델(CNN)과 실내측위기술, 4D BIM을 기반으로 -",2020,[],,"A daily progress monitoring and further schedule management of a construction project have a significant impact on the construction manager's decision making in schedule change and controlling field operation. However, a current site monitoring method highly relies on the manually recorded daily-log book by the person in charge of the work. For this reason, it is difficult to take a detached view and sometimes human error such as omission of contents may occur. In order to resolve these problems, previous researches have developed automated site monitoring method with the object recognition-based visualization or BIM data creation. Despite of the research results along with the related technology development, there are limitations in application targeting the practical construction projects due to the constraints in the experimental methods that assume the fixed equipment at a specific location. To overcome these limitations, some smart devices carried by the field workers can be employed as a medium for data creation. Specifically, the extracted information from the site picture by object recognition technology of CNN model, and positional information by GIPS are applied to update 4D BIM data. A standard CNN model is developed and BIM data modification experiments are conducted with the collected data to validate the research suggestion. Based on the experimental results, it is confirmed that the methods and performance are applicable to the construction site management and further it is expected to contribute speedy and precise data creation with the application of automated progress monitoring methods."
CNN 기반 몬테카를로 트리 탐색 및 강화학습을 이용한 인공지능 오델로 게임 에이전트,2020,"['합성곱 신경망', '몬테카를로 트리 탐색', '강화학습', '오델로 게임 에이전트', '가치 및 정책 네트워크', 'CNN', 'MCTS', 'Reinforcement Learning', 'Othello Game Agent', 'Valu eand Policy Function Network']",,"In this paper, we propose an implementation of AI Othello game agent applying Monte Carlo tree search based on the neural network whose structure is expressed and learned by a single neural network. Neural network learning applied in this paper is carried out by using learning data generated through AI player's own playing, and learns CNN so that existing policy follows strong policy obtained through MCTS. To evaluate the performance of the proposed artificial intelligence Othello game agent, we compared the performances with the best existing Othello programs, Wzebra and Tothello, which use MPC search. We observed the performances according to the progress of learning through the playing with agents in the middle of the neural network learning progress"
A Method of License Plate Location and Character Recognition based on CNN,2020,"['CNN', 'YOLO', 'character recognition', 'license plate recognition', 'target detection']",,"At the present time, the economy continues to flourish, and private cars have become the means of choice for most people. Therefore, the license plate recognition technology has become an indispensable part of intelligent transportation, with research and application value. In recent years，the convolution neural network for image classification is an application of deep learning on image processing. This paper proposes a strategy to improve the YOLO model by studying the deep learning convolutional neural network (CNN) and related target detection methods, and combines the OpenCV and TensorFlow frameworks to achieve efficient recognition of license plate characters. The experimental results show that target detection method based on YOLO is beneficial to shorten the training process and achieve a good level of accuracy."
CNN 기반의 IEEE 802.11 WLAN 프레임 포맷 검출,2020,"['IEEE 802.11', 'Format Detection', 'Deep Learning', 'CNN']",,"Backward compatibility is one of the key issues for radio equipment supporting IEEE 802.11, the typical wireless local area networks (WLANs) communication protocol. For a successful packet decoding with the backward compatibility, the frame format detection is a core precondition. This paper presents a novel frame format detection method based on a deep learning procedure for WLANs affiliated with IEEE 802.11. Considering that the detection performance of conventional methods is degraded mainly due to the poor performances in the symbol synchronization and/or channel estimation in low signal-to-noise-ratio environments, we propose a novel detection method based on convolutional neural network (CNN) that replaces the entire conventional detection procedures. The proposed deep learning network provides a robust detection directly from the receive data. Through extensive computer simulations performed in the multipath fading channel environments (modeled by Project IEEE 802.11 Task Group ac), the proposed method exhibits superb improvement in the frame format detection compared to the conventional method."
멀티로터 UAV 환경에서의 CNN 기반 복소 스펙트로그램 향상 기법,2020,[],멀티로터 UAV(Unmanned Aerial Vehicle)를 이용해서 수집한 음향 데이터는 모터나 프로펠러에서 발생하는 자체 소음이나 비행 중 발생하는 바람 소리 등으로 인해 음향 품질이 크게 손상되는 문제가 발생한다. 멀티로터 UAV 환경에서는 목표 음향의 크기뿐만 아니라 위상도 크게 손상되기 때문에 크기와 위상을 모두 고려해서 음향을 향상시킬 필요가 있다. 하지만 위상은 크기와 달리 구조적인 특징이 잘 나타나지 않으므로 향상시키는 것이 쉽지 않다. 따라서 본 연구에서는 크기와 위상을 모두 표현할 수 있는 복소 스펙트로그램을 기초로 잡음을 제거해서 목표 음향의 품질을 향상시키는 CNN 기반 복소 스펙트로그램 향상 방법을 제안한다.,
CNN 기반 딥러닝을 이용한 임베디드 리눅스 양각 문자 인식 시스템 구현,2020,"['Artificial Intelligence', 'Embedded Linux', 'Deep learning', 'CNN Algorithm', 'TensorFlow', 'Keras']",,"Over the past several years, deep learning has been widely used for feature extraction in image and video for various applications such as object classification and facial recognition. This paper introduces an implantation of embedded Linux system for embossed digits recognition using CNN based deep learning methods. For this purpose, we implemented a coin recognition system based on deep learning with the Keras open source library on Raspberry PI. The performance evaluation has been made with the success rate of coin classification using the images captured with ultra-wide angle camera on Raspberry PI. The simulation result shows 98% of the success rate on average."
Visual Object Tracking Fusing CNN and Color Histogram based Tracker and Depth Estimation for Automatic Immersive Audio Mixing,2020,"['Immersive Audio', 'GOTURN', 'Mean-Shift', 'CNN', 'Color Histogram', 'Depth Estimation']",,"We propose a robust visual object tracking algorithm fusing a convolutional neural network tracker trained offline from a large number of video repositories and a color histogram based tracker to track objects for mixing immersive audio. Our algorithm addresses the problem of occlusion and large movements of the CNN based GOTURN generic object tracker. The key idea is the offline training of a binary classifier with the color histogram similarity values estimated via both trackers used in this method to opt appropriate tracker for target tracking and update both trackers with the predicted bounding box position of the target to continue tracking. Furthermore, a histogram similarity constraint is applied before updating the trackers to maximize the tracking accuracy. Finally, we compute the depth(z) of the target object by one of the prominent unsupervised monocular depth estimation algorithms to ensure the necessary 3D position of the tracked object to mix the immersive audio into that object. Our proposed algorithm demonstrates about 2% improved accuracy over the outperforming GOTURN algorithm in the existing VOT2014 tracking benchmark. Additionally, our tracker also works well to track multiple objects utilizing the concept of single object tracker but no demonstrations on any MOT benchmark."
자기애자의 유지 관리를 위한 CNN 기법을 이용한 이미지 분석,2020,"['Convolution neural network', 'Image deep learning', 'Porcelain insulator', 'Maintenance', 'Augmentation']",,"This study examines the feasibility of the image deep learning method using convolution neural networks (CNNs) to maintain a porcelain insulator. Data augmentation is performed to prevent over-fitting, and the classification performance is evaluated by training the age, material, region, and pollution level of the insulator using image data in which the background and labelling are removed. Based on the results, it was difficult to predict the age, but it was possible to classify 76% of the materials, 60% of the pollution level, and more than 90% of the regions. From the results of this study, we identified the potential and limitations of the CNN classification for the four groups currently classified. However, it was possible to detect discoloration of the porcelain insulator resulting from physical, chemical, and climatic factors. Based on this, it will be possible to estimate the corrosion of the cap and discoloration of the porcelain caused by environmental deterioration, abnormal voltage, and lightning."
하이웨이 네트워크 기반 CNN 모델링 및 사전 외 어휘 처리 기술을 활용한 악성 댓글 분류 연구,2020,"['deep learning', 'Highway Network', 'CNN', 'OOV', 'toxic comments']",,"Purpose: Recently, various issues related to toxic comments on web portal sites and SNS are becoming a major social problem. Toxic comments can threaten Internet users in the type of defamation, personal attacks, and invasion of privacy. Over past few years, academia and industry have been conducting research in various ways to solve this problem. The purpose of this study is to develop the deep learning modeling for toxic comments classification.Design/methodology/approach: This study analyzed 7,878 internet news comments through CNN classification modeling based on Highway Network and OOV process.Findings: The bias and hate expressions of toxic comments were classified into three classes, and achieved 67.49% of the weighted f1 score. In terms of weighted f1 score performance level, this was superior to approximate 50~60% of the previous studies."
딥러닝 기술을 활용한 차별 및 혐오 표현 탐지 : 어텐션 기반 다중 채널 CNN 모델링,2020,[],,"Online defamation incidents such as Internet news comments on portal sites, SNS, and community sites are increasing in recent years. Bias and hate expressions threaten online service users in various forms, such as invasion of privacy and personal attacks, and defamation issues. In the past few years, academia and industry have been approaching in various ways to solve this problem The purpose of this study is to build a dataset and experiment with deep learning classification modeling for detecting various bias expressions as well as hate expressions. The dataset was annotated 7 labels that 10 personnel cross-checked. In this study, each of the 7 classes in a dataset of about 137,111 Korean internet news comments is binary classified and analyzed through deep learning techniques. The Proposed technique used in this study is multi-channel CNN model with attention. As a result of the experiment, the weighted average f1 score was 70.32% of performance."
"해외 웰니스(Wellness) 공간의 특성에 관한 연구 - CNN Travel(2014, 2017, 2019)에 선정된 해외 휴양리조트와 호텔의 사례를 중심으로",2020,"['Wellness', 'Spatial characteristics', '웰니스', '공간특성']","현대사회는 생활수준이 향상 되고 여가활동, 건강, 미(美), 휴식 등에 대한 관심이 증대 되면서 삶의자연성을 회복하며 자신을 정화하고 치유하는 진정한 쉼을 찾고자 하는 목적으로 웰니스 프로그램을갖춘 해외 휴양 리조트와 호텔들이 주목 받고 있다. 이에 본 연구에서는 해외 웰니스 프로그램의 유형과 공간은 어떻게 환경 조성이 이루어지고 있는지에 대한 분석과 해외 웰니스 공간의 특성을 연구하는데 목적이 있다. 연구방법으로는 웰니스에 대한 선행 연구를 바탕으로 공간 분석요소를 추출하여 사례분석표를 제시하고 적용사례들을 분석한다. 연구의 대상적 범위는 CNN Travel “The best Wellness retreats for 2014, 2017, 2019”에 선정된 리조트와 호텔의 사례로 한정하여 분석한다. 그결과 공간 구조적 요소(형태성, 경관성, 전통성)가 모두 강하게 평가 되었고, 프로그램 컨텐츠 요소(합목적성, 자연성, 인위성)와 환경적 요소(물리적, 심리적, 문화적)에서 강함과 보통의 평가가 공존하였다. 웰니스프로그램의 유형은 명상·치유, 전통·지역, Beauty, Fitness, Private, 교육·기타의 유형으로 분류하였는데, 그 결과 프로그램의 연결과 공간 요소가 잘 부합되어 커뮤니티 공간을 확장시키고있었다. 웰니스 공간의 특성은 첫째, 지리학적으로 자연환경과 밀접한 관계를 갖고 있다. 둘째, 현대의료서비스와 전통적인 프로그램들의 융합으로 구성된 독창적이고 특화되어 있는 공간들이다. 셋째, 현대인의 라이프 스타일과 시대성을 반영한 호텔과 리조트의 전통성과 접목되는 프로그램의 변화이다. 따라서 본 연구는 생명의 근원인 자연과 웰니스를 추구하는 모든 요소들이 조화를 이루는 다양한웰니스 프로그램의 개발과 웰니스 연구를 위한 기초자료로 활용되기를 기대한다.","Overseas resorts and hotels equipped with wellness programs are drawing attention from people who aim to restore naturalness in life and pursue quality rest to purify and heal oneself, as living standards improve and interest in leisure activities, health, beauty, and relaxation increases in modern society. The purpose of this study is to analyze the types of overseas wellness programs and how their spaces are composed, as well as to derive specific elements from the ‘well-being spaces’ of overseas resorts and hotels. The research method of this study extracts elements from spatial analysis, presents a case analysis table, and analyzes applied cases, based on prior research on wellness. The range of this research is from CNN Travel, and is analyzed limiting the resorts and hotels which were selected as “The best Wellness retreats for 2014, 2017, 2019”. As a result, all spatial structural factors (formality, landscape, traditionality) were strongly evaluated, and strong and ordinary evaluation coexisted in program content elements (purpose, nature, and artificiality) and environmental factors (physical, psychological, and cultural). The types of wellness programs were categorized into meditation, healing, tradition, locality, beauty, fitness, private, education, and other types. As a result, the program's connection and space elements were well matched to expand the community space. The characteristics of wellness space are, firstly, geographically closely related to the natural environment. Secondly, these are original and specialized spaces composed of the convergence of modern medical services and traditional programs. Thirdly, it is a change of programs combined with the traditionality of hotels and resorts that reflects the lifestyle and era of modern people.Therefore, this study is expected to be used as the basic data for the study of wellness and the development of various wellness programs in which all factors pursuing well-being, nature and wellness, are harmonized."
다중 트레이닝 기법을 이용한 MASK R-CNN의 초음파 DDH 각도 측정 진단 시스템 연구,2020,[],,"Recently, the number of hip dysplasia (DDH) that occurs during infant and child growth has been increasing. DDH should be detected and treated as early as possible because it hinders infant growth and causes many other side effects In this study, two modelling techniques were used for multiple training techniques. Based on the results after the first transformation, the training was designed to be possible even with a small amount of data. The vertical flip, rotation, width and height shift functions were used to improve the efficiency of the model. Adam optimization was applied for parameter learning with the learning parameter initially set at 2.0 x 10e-4. Training was stopped when the validation loss was at the minimum. respectively A novel image overlay system using 3D laser scanner and a non-rigid registration method is implemented and its accuracy is evaluated. By using the proposed system, we successfully related the preoperative images with an open organ in the operating room"
복수의 엣지 디바이스에서의 CNN 모델 분산 처리를 위한 축소된 분류 모델 활용 기법,2020,"['기계 학습', '딥러닝', '합성곱 신경망', '엣지 컴퓨팅', '분산 컴퓨팅', 'machine learning', 'deep learning', 'convolutional neural networks', 'edge computing', 'distributed computing']","최근 클라우드 서버로 전송되는 막대한 양의 데이터로 인해 발생하는 네트워크 부하 등의 여러 문제로 인하여, 데이터의 수집이 이루어지는 네트워크의 말단에서 자체적으로 데이터를 처리하는 엣지 컴퓨팅에 대한 요구가 증가하고 있다. 그러나 네트워크 말단에 위치한 엣지 디바이스는 대부분 성능이 제한되어 있어 클라우드 서버에서 사용되는 딥러닝 응용을 그대로 사용하기에는 어려움이 있다. 이러한 문제를 극복하기 위해, 본 논문에서는 딥러닝 모델을 축소된 분류 모델들로 나누어 활용해 복수의 엣지 디바이스에서 공동으로 추론을 수행하는 분산 처리 기법을 제안하였다. 여기서 사용된 축소된 분류 모델은 경량화 된 모델 가중치를 가지며, 전체 분류 레이블 중 일부에 해당하는 레이블에 대해 추론을 진행한다. 성능 측정 결과 제안하는 축소된 분류 모델의 결과를 취합하는 분산 처리 기법의 정확도가 기존 모델 대비 더 적은 파라미터를 갖도록 경량화를 하여도 기존 모델과 유사한 수준을 유지할 수 있음을 확인하였다.","Recently, there have been increasing demands for edge computing that processes data at the end of the network wherein data is collected because of various problems such as network load caused by a large amount of data transfer to a cloud server. However, it is difficult for edge devices to use deep learning applications used in cloud servers because most edge devices at the end of the network have limited performance. To overcome these problems, this paper proposes a distributed processing method that uses reduced classification models to jointly perform inferences on multiple edge devices. The reduced classification models have compressed model weights, and perform inferences for some parts of the total classification labels. The experimental results confirmed that the accuracy of the result of the proposed distributed processing method is similar to the accuracy of the result of the original model, even if the proposed reduced classification models had much less parameters than those of the original model."
합성 이미지를 이용한 Mask R-CNN 기반 한국 번호판 검출,2020,"['license plate', 'license plate detection', 'deep learning', 'convolutional neural networks', '.']",,.
글꼴 유사도 판단을 위한 Faster R-CNN 기반 한글 글꼴 획 요소 자동 추출,2020,"['Characteristics of Hangul Shape', 'Object Detection of Stroke Element', 'Automatic Extraction of Object Deletion', 'Hangul Font Similarity']",,"Ever since media contents took over the world, the importance of typography has increased, and the influence of fonts has be n recognized. Nevertheles , the cur ent Hangul font system is very poor and is provided pas ively, so it is practical y impos ible to understand and utilize al the shape characteristics of more than six thousand Hangul fonts. In this paper, the characteristics of Hangul font shapes were selected based on the Hangul structure of similar fonts. The stroke element detection training was performed by fine tuning Faster R-CNN Inception v2, one of the de p learning object detection models.We also propose a system that automatical y extracts the stroke element characteristics from characters by introducing an automatic extraction algorithm. In comparison to the previous research which showed poor ac uracy while using SVM(Support Vector Machine) and Sliding Window Algorithm, the proposed system in this paper has shown the result of 10 % ac uracy to properly detect and extract stroke elements from various fonts. In conclusion, if the stroke element characteristics based on the Hangul structural information extracted through the system are used for similar clas ification, problems such as copyright wil be solved in an era when typography’s competitivenes becomes stronger, and an automated proces wil be provided to users for more convenience"
클릭률 예측 성능 향상을 위한 다중 배열 CNN 모형 설계,2020,"['클릭률', 'CNN', '특징 생성', '딥러닝', 'CTR', 'Feature Generation', 'Deep Learning']","클릭률(CTR) 예측은 사용자가 주어진 항목을 클릭할 확률을 추정하는 것으로 온라인 광고 수익 극대화를 위한 전략 결정에 중요한 역할을 한다. 최근 CTR 예측을 위해 CNN을 활용하는 시도가 이루어지고 있다. CTR 데이터는 특징 정보가 연관성 측면에서 의미 있는 순서를 갖지 않기 때문에, 임의의 순서로 배열될 수 있다. 하지만 CNN은 필터 사이즈에 의해 제한된 로컬 정보만을 학습하기 때문에 데이터 배열이 성능에 큰 영향을 줄 수 있다. 이 논문에서는 CNN이 수집할 수 있는 모든 로컬 특징 정보를 추출할 수 있는 데이터 배열 집합을 생성하고 생성된 배열들에 대하여 개별 CNN 모듈들이 특징들을 학습할 수 있는 다중 배열 CNN 모델을 제안한다. 대규모 데이터 세트에 대한 실험 결과에 따르면 제안된 모델은 기존 CNN 대비 AUC의 RI에서 22.6% 상승 효과를, 제안된 배열 생성 방법은 임의 생성 방법보다 3.87% 성능 향상을 달성하였다.","Click-through rate (CTR) prediction is an estimate of the probability that a user will click on a given item and plays an important role in determining strategies for maximizing online ad revenue. Recently, research has been performed to utilize CNN for CTR prediction. Since the CTR data does not have a meaningful order in terms of correlation, the CTR data may be arranged in any order. However, because CNN only learns local information limited by filter size, data arrays can have a significant impact on performance. In this paper, we propose a multi-array CNN model that generates a data array set that can extract all local feature information that CNN can collect, and learns features through individual CNN modules. Experimental results for large data sets show that the proposed model achieves a 22.6% synergy with RI in AUC compared to the existing CNN, and the proposed array generation method achieves 3.87% performance improvement over the random generation method."
정수 연산만을 사용하는 하드웨어 친화적인 양자화된 CNN 구현,2020,"['Deep learning', 'Image classification', 'Quantization', 'Integer arithmetic', 'Hardware-friendly']",,
Deformable convolutional network를 기반으로 한 Mask R-CNN,2020,"['딥러닝', 'deformable convolutional network', 'mask R-CNN', '객체탐색', 'Deep learning', 'object detection']","객체 탐색은 자율 주행, 실시간 보안, 건설 자동화에서 활용될 수 있는 기술로서 각광 받고 있는 컴퓨터 비전 응용 기술이다. 최근 딥러닝을 기반으로 한 객체 탐색 모델이 등장하였고 딥러닝 기술의 발전과 함께 빠른 속도로 객체 탐색 모델들도 발전하고 있다. 객체 탐색 모델들은 대용량 크기의 입력값인 이미지를 처리하기 위해 공통적으로 CNN (convolutional neural network)를 사용한다. 하지만 CNN은 객체의 크기에 상관없이 공통된 필터를 사용하는 문제점이 있다. 본 연구에서는 오프셋 (offset)을 이용해 객체에 대응하는 필터를 만드는 Deformable convolutional network를 Mask R-CNN에 적용해 합성곱 네트워크의 문제점을 해결하고 객체 탐색 알고리즘의 정확도를 높이는 방법을 제안하고자 한다. 제안된 방법은 Pascal VOC와 COCO 데이터를 이용해 성능실험을 수행하였고, 기존의 Mask R-CNN 방법보다 성능이 개선되는 결과를 보였다.","Object detection is a computer vision application technology that is in spotlight as a technology that can be used in autonomous driving, real-time security and construction automation. Recently, object detection models based on deep learning has appeared, and object detection models are also developing at a rapid pace with the development of deep learning technology. Object detection models commonly use convolution neural network (CNN) to process a large size of image data. However, CNN has a problem of using a common filter regardless of the size of the object. In this paper, we propose a method to solve the problem of the CNN and improve the accuracy of objection detection algorithm by applying a deformable convolutional network that creates a filter corresponding to an object using an offset to Mask R-CNN. The proposed method is evaluated by an experiment using Pascal VOC and COCO data, and it can be shown that the proposed method outperforms the existing Mask R-CNN method."
CNN 모형을 이용한 서울 아파트 가격 예측과 그 요인,2020,"['convolutional neural networks', 'image data', 'spatial data', 'apartment price', 'CNN모형', '이미지데이터', '공간데이터', '아파트가격']","본 연구는 이미지 데이터에 대한 예측 모형으로 뛰어난 성능을 보여온 convolutional neural networks (CNN) 모형을 이용하여 서울 아파트 가격의 예측과 서울 각 지역 아파트들의 가격결정요인들을 연구한다. 이를 위해 강, 녹지, 고도와 같은 자연환경요인, 버스정류장, 지하철역, 상권, 학교 등과 같은 기반시설요소, 일자리수, 범죄율 등의 사회경제요소들을 설명변수로 고려하고, CNN 모형이 이미지 데이터에 좋은 성능을 보여온 것을 기반으로 이 설명변수들의 값들을 CNN 모형 입력층으로써 이미지 채널의 픽셀값과 같은 역할을 하도록 변환하여 아파트 가격의 예측과 가격결정요인에 대한 해석을 시도한다. 덧붙여 본 연구에서 사용된 CNN 모형은 자연환경요인과 기반시설요인 변수들을 각 아파트를 중심으로 하는 각 입력층의 채널에 이진의 이미지로 표현함으로써 각 아파트의 공간적인 특성을 고려할 수 있다.","This study focuses on the prediction and factors of apartment prices in Seoul using a convolutional neural networks (CNN) model that has shown excellent performance as a predictive model of image data. To do this, we consider natural environmental factors, infrastructure factors, and social economic factors of the apartments as input variables of the CNN model. The natural environmental factors include rivers, green areas, and altitudes of apartments. The infrastructure factors have bus stops, subway stations, commercial districts, schools, and the social economic factors are the number of jobs and criminal rates, etc. We predict apartment prices and interpret the factors for the prices by converting the values of these input variables to play the same role as pixel values of image channels for the input layer in the CNN model. In addition, the CNN model used in this study takes into account the spatial characteristics of each apartment by describing the natural environmental and infrastructure factors variables as binary images centered on each apartment in each input layer."
손 제스처 인식을 위한 특징 강화 CNN 알고리즘과 사용자 의사 결정 판단,2020,"['Covolutional neural network', '손 제스처 인식', 'Kinect', 'Sensor fusion', '손 특징 강화', '세선화']",,
CNN 방식과 전통적 방식의 스테레오 매칭 알고리즘 비교,2020,"['Computer vision', 'CNN-based stereo matching', 'ill-posed regions', 'traditional stereo matching']",,"CNN has been widely used in computer vision. In particular, CNN has been applied in stereo matching, which involves finding pixels corresponding to each other in a pair of images that capture a scene at the same time. This paper focuses on analyzing stereo matching methods based on CNN, and compares them with a traditional stereo matching method. CNN-based methods produced good matching results for ill-posed areas, including textureless areas, repeated patterns and highly reflective surfaces. By contrast, traditional stereo matching methods could not produce good matching results for such ill-posed regions. Therefore, in this paper, we demonstrate how good CNN-based methods could produce matching results for both indoor and outdoor images."
Hybrid CNN-LSTM 알고리즘을 활용한 도시철도 내 피플 카운팅 연구,2020,"['딥러닝', '피플 카운팅', '메트로 서비스 CNN-LSTM', '사물인터넷(IoT)', '빅데이터', '센서', '스마트시티', 'Deep Learning', 'People Counting', 'Metro service', 'CNN-LSTM', 'IoT', 'Sensor', 'Smart city']",,"In line with the trend of industrial innovation, IoT technology utilized in a variety of fields is emerging as a key element in creation of new business models and the provision of user-friendly services through the combination of big data. The accumulated data from devices with the Internet-of-Things (IoT) is being used in many ways to build a convenience-based smart system as it can provide customized intelligent systems through user environment and pattern analysis. Recently, it has been applied to innovation in the public domain and has been using it for smart city and smart transportation, such as solving traffic and crime problems using CCTV. In particular, it is necessary to comprehensively consider the easiness of securing real-time service data and the stability of security when planning underground services or establishing movement amount control information system to enhance citizens or commuters’ convenience in circumstances with the congestion of public transportation such as subways, urban railways, etc. However, previous studies that utilize image data have limitations in reducing the performance of object detection under private issue and abnormal conditions.  The IoT device-based sensor data used in this study is free from private issue because it does not require identification for individuals, and can be effectively utilized to build intelligent public services for unspecified people. Especially, sensor data stored by the IoT device need not be identified to an individual, and can be effectively utilized for constructing intelligent public services for many and unspecified people as data free form private issue.  We utilize the IoT-based infrared sensor devices for an intelligent pedestrian tracking system in metro service which many people use on a daily basis and temperature data measured by sensors are therein transmitted in real time. The experimental environment for collecting data detected in real time from sensors was established for the equally-spaced midpoints of 4x4 upper parts in the ceiling of subway entrances where the actual movement amount of passengers is high, and it measured the temperature change for objects entering and leaving the detection spots. The measured data have gone through a preprocessing in which the reference values for 16 different areas are set and the difference values between the temperatures in 16 distinct areas and their reference values per unit of time are calculated. This corresponds to the methodology that maximizes movement within the detection area. In addition, the size of the data was increased by 10 times in order to more sensitively reflect the difference in temperature by area. For example, if the temperature data collected from the sensor at a given time were 28.5°C, the data analysis was conducted by changing the value to 285. As above, the data collected from sensors have the characteristics of time series data and image data with 4x4 resolution. Reflecting the characteristics of the measured, preprocessed data, we finally propose a hybrid algorithm that combines CNN in superior performance for image classification and LSTM, especially suitable for analyzing time series data, as referred to CNN-LSTM (Convolutional Neural Network-Long Short Term Memory).  In the study, the CNN-LSTM algorithm is used to predict the number of passing persons in one of 4x4 detection areas. We verified the validation of the proposed model by taking performance comparison with other artificial intelligence algorithms such as Multi-Layer Perceptron (MLP), Long Short Term Memory (LSTM) and RNN-LSTM (Recurrent Neural Network-Long Short Term Memory). As a result of the experiment, proposed CNN-LSTM hybrid model compared to MLP, LSTM and RNN-LSTM has the best predictive performance. By utilizing the proposed devices and models, it is expected various metro services will be provided with no illegal issue about the personal information such as real-time monitoring of publi"
과도유동 해석을 위한 CNN에서의 이미지 변환방법,2020,"['볼루션 신경망', '열유체문제', '이미지 변환', '압력분포', 'CNN', 'Thermal fluid problem', 'Image conversion', 'Pressure distribution']",,"To apply CNN to a fluid problem, we need a method to effectively convert the physical quantities of fluid into an image. The performance of CNN was evaluated using the image transformation method using the minimum and maximum values of the pressure distribution data and the image transformation methods using the normal distribution of the pressure distribution data. Through the performance evaluation of the learned CNN, the image transformation methods of Method 4 and Method 5, which applied the normal distribution of representative pressure distribution data, were very effective. In particular, Method 5 includes the initial and final pressure distribution data to include overall pressure distribution data, thereby improving the resolution of the color map to improve classification performance."
Park’s Vector 패턴과 CNN을 이용한 유도전동기고정자 고장진단방법,2020,"['3-Phase Induction Motor', 'Fault Diagnosis', 'ITSC', 'CNN', 'PVA']","본 논문에서는 CNN(Convolution Neural Network)을 이용한 유도전동기 고정자 고장진단에 PV(Park’s Vector)패턴을 특징으로 활용하는 방법을 제안하였다. 기존의 CNN을 이용한 유도전동기 고장진단 방법은 3상 전류를 이미지화하여 진단을수행하였으나, 이 방법은 인위적으로 전류의 시작점, 위상 등을 맞춰 정규화를 수행해야하는 번거러움이 존재하나, PV패턴을이용할 경우 일정 원의 패턴을 나타내기 때문에 정규화의 문제를 해결 할 수 있었다. 또한 PV패턴을 이용할 경우, 특징벡터가 자동적으로 정규화됨에 따라 기존의 전류데이터를 이미지화한 결과보다 CNN의 정확도 측면에서 18.18[%] 우수함을 실험을 통해 확인할 수 있었다.","In this paper, we propose a method to use PV(Park’s Vector) pattern for inductive motor stator fault diagnosis usingCNN(Convolution Neural Network). The conventional CNN based fault diagnosis method was performed by imagingthree-phase currents, but this method was troublesome to perform normalization by artificially setting the starting pointand phase of current. However, when using PV pattern, the problem of normalization could be solved because the3-phase current shows a certain circular pattern. In addition, the proposed method is proved to be superior in theaccuracy of CNN by 18.18[%] compared to the previous current data image due to the autonomic normalization."
Estimation of gender and age using CNN-based face recognition algorithm,2020,"['gender estimation', 'age estimation', 'face recognition', 'CNN']",,"This study proposes a method for estimating gender and age that is robust to various external environment changes by applying deep learning-based learning. To improve the accuracy of the proposed algorithm, an improved CNN network structure and learning method are described, and the performance of the algorithm is also evaluated. In this study, in order to improve the learning method based on CNN composed of 6 layers of hidden layers, a network using GoogLeNet's inception module was constructed. As a result of the experiment, the age estimation accuracy of 5,328 images for the performance test of the age estimation method is about 85%, and the gender estimation accuracy is about 98%. It is expected that real-time age recognition will be possible beyond feature extraction of face images if studies on the construction of a larger data set, pre-processing methods, and various network structures and activation functions have been made to classify the age classes that are further subdivided according to age."
CNN 기반 토마토 질병 분류를 위한 DCGAN 이미지 데이터 확장 영향 평가,2020,"['합성곱 신경망', '심층 합성곱 생성적 적대 신경망', '데이터셋 불균형', '이미지 데이터 확장', '분류기', 'CNN', 'DCGAN', 'Unbalanced Dataset', 'Image Data Augmentation', 'Classifier']",,"With the development of deep learning and the advent of CNN(Convolutional Neural Network), research on image data classification has been actively conducted. However, performance is deteriorated when an image dataset having an uneven distribution of classes is used for training a CNN classification model. In particular, diseases in plants occur aperiodically and unbalanced image data is provided. In this paper, we evaluate the impact of DCGAN(Deep Convolutional Generative Adversarial Network) image data augmentation to improve the performance of CNN-based tomato disease classifiers in situations where unbalanced image data is provided. DCGAN is a generation model specialized in image data, enabling stable learning and effectively extracting image features. For performance evaluation, the effect of DCGAN image data augmentation on a CNN-based tomato disease classifier was measured using a tomato disease image data set, and it was confirmed that the accuracy can be increased up to 30% through image data augmentation."
CNN/ANNOY 기술을 이용한 의류 이미지 유사도 분석,2020,"['CNN', 'ANNOY', '딥러닝', 'AI', '빅데이터', '이미지 유사도', 'CNN', 'ANNOY', 'Deep Learning', 'AI', 'Big Data', 'Image Similarities']",,
K-Means와 CNN을 이용한 변화된 환경에서의 전동기 고장 진단,2020,"['deep learning', 'K-means', 'CNN', 'diagnosis']",,"The most commonly used data for diagnosing the mechanical failure of a motor is vibration data. This vibration data is also used to diagnose motor failures in machine learning. However, there are many types of electric motors used in the industry, and the environment can vary according to the proposed use. To diagnose motor failure, data must be collected, labeled, and learned. In this way, it is very difficult to collect and label vibration data in consideration of all situations. For example, in identical situations, even if only the sensor changes, the CNN-only algorithm can fail to classify the data. In this paper, a method of learning CNN with learning data created by automatically classifying and labeling data using K-means is proposed. To apply K-means to fault diagnosis, FFT data was divided by frequency. For each frequency, the K-means algorithm was applied to calculate the centroid. The training data was used to calculate the similarity and distance to the centroid of the classified clusters. Using the calculated results, the centroid classified as the K-means was reclassified as normal or fault. This method using the K-menas could classify data, even if various data were entered. Finally, CNN was trained using the generated training data. Using this process, the existing CNN-only algorithm failed to classify the data when the sensor was altered, but the proposed algorithm classified the data and showed high accuracy."
An Experimental Comparison of CNN-based Deep Learning Algorithms for Recognition of Beauty-related Skin Disease,2020,"['Deep Learning', 'CNN', 'Beauty-related Skin Disease Recognition', 'Image Recognition', 'Algorithm Comparison', 'Experimental Comparison', '딥러닝', '피부미용 질환 인식', '이미지 인식', '알고리즘 비교', '실험적 비교']","본 논문에서는 딥러닝 지도학습 알고리즘을 사용한 학습 모델을 대상으로 미용 관련 피부질환 인식의 효과성을 실험적으로 비교한다. 최근 딥러닝 기술을 산업, 교육, 의료 등 다양한 분야에 적용하고 있으며, 의료 분야에서는 중요 피부질환 중 하나인 피부암 식별의 수준을 전문가 수준으로 높인 성과를 보이고 있다. 그러나 아직 피부미용과 관련된 질환에 적용한 사례가 다양하지 못하다. 따라서 딥러닝 기반 이미지 분류에 활용도가 높은 CNN 알고리즘을 비롯하여 ResNet, SE-ResNet을 적용하여 실험적으로 정확도를 비교함으로써 미용 관련 피부질환을 판단하는 효과성을 평가한다. 각 알고리즘을 적용한 학습 모델을 실험한 결과에서 CNN의 경우 평균 71.5%, ResNet은 평균 90.6%, SE-ResNet은 평균 95.3%의 정확도를 보였다. 특히 학습 깊이를 다르게하여 비교한 결과 50개의 계층 구조를 갖는 SE-ResNet-50 모델이 평균 96.2%의 정확도로 미용 관련 피부질환 식별을 위해 가장 효과적인 결과를 보였다. 본 논문의 목적은 피부 미용과 관련된 질환의 판별을 고려하여 효과적인 딥러닝 알고리즘의 학습과 방법을 연구하기 위한 것으로 이를 통해 미용 관련 피부질환 개선을 위한 서비스 개발로 확장할 수 있을 것이다.","In this paper, we empirically compare the effectiveness of training models to recognize beauty-related skin disease using supervised deep learning algorithms. Recently, deep learning algorithms are being actively applied for various fields such as industry, education, and medical. For instance, in the medical field, the ability to diagnose cutaneous cancer using deep learning based artificial intelligence has improved to the experts level. However, there are still insufficient cases applied to disease related to skin beauty. This study experimentally compares the effectiveness of identifying beauty-related skin disease by applying deep learning algorithms, considering CNN, ResNet, and SE-ResNet. The experimental results using these training models show that the accuracy of CNN is 71.5% on average, ResNet is 90.6% on average, and SE-ResNet is 95.3% on average. In particular, the SE-ResNet-50 model, which is a SE-ResNet algorithm with 50 hierarchical structures, showed the most effective result for identifying beauty-related skin diseases with an average accuracy of 96.2%. The purpose of this paper is to study effective training and methods of deep learning algorithms in consideration of the identification for beauty-related skin disease. Thus, it will be able to contribute to the development of services used to treat and easy the skin disease."
CNN을 사용한 노면 크랙의 위치 검출과 분류,2020,"['Road surface crack', 'Pothole', 'Image classification', 'Convolutional neural network', 'Sementic segmentation']","본 논문에서는 CNN을 사용하여 도로의 노면에 나타나는 크랙을 촬영한 영상으로부터 크랙의 위치와 모양을 검출하고 크랙의 종류를 분류하는 방법을 제안한다. CNN 기법을 물체의 세그멘테이션을 위해 사용한 의미론적 세그멘테이션 방법을 크랙의 검출을 위해 사용하였고, 검출된 결과 영상으로부터 크랙의 종류를 구분할 수 있는 신경망을 사용하였다. 신경망의 학습을 위해 지도학습 방법을 사용하였으며, 주행 중인 차량에 설치된 카메라를 통해 촬영한 도로 영상과 이 영상의 크랙 위치를 세그멘테이션한 결과, 크랙 분류 결과를 학습데이터로 사용하였다. 실제 도로 영상에 적용해 본 결과, 크랙의 위치를 효과적으로 검출하였고 크랙의 위치와 모양으로부터 크랙의 종류를 분류할 수 있었음을 확인하였다. 이 방법은 도로의 노면 관리에 효율적으로 사용될 수 있을 것으로 생각된다.","In this paper, we propose a method using CNN for detecting the location and shape of cracks and classifying the types of cracks from the crack images appearing on the road surface. The semantic segmentation method using CNN technique for object segmentation was used for the detection of cracks and a neural network capable of distinguishing the type of crack was applied to the detected crack image. Supervised learning method was used for training neural networks and a road image taken through a camera installed in a driving vehicle, the image of segmented area corresponding to crack position and the crack classification result was used as training data. As a result of deploying it to the real road image, the location of the crack was effectively detected and it was confirmed that the type of crack could be classified based on the location and shape of the crack. It is thought that this method can be used for efficient management of road surfaces."
CNN Architecture Predicting Movie Rating from Audience’s Reviews Written in Korean,2020,"['NLP', 'CNN', 'Movie Rating', 'Un-Normalized Text Data', '자연어처리', 'CNN', '영화 평점', '비정제 문자 데이터']",,"In this paper, we present a movie rating prediction architecture based on a convolutional neural network (CNN). Our prediction architecture extends TextCNN, a popular CNN-based architecture for sentence classification, in three aspects. First, character embeddings are utilized to cover many variants of words since reviews are short and not well-written linguistically. Second, the attention mechanism (i.e., squeeze-and-excitation) is adopted to focus on important features. Third, a scoring function is proposed to convert the output of an activation function to a review score in a certain range (1-10). We evaluated our prediction architecture on a movie review dataset and achieved a low MSE (e.g., 3.3841) compared with an existing method. It showed the superiority of our movie rating prediction architecture."
CNN 가속기의 효율적인 데이터 전송을 위한 메모리 데이터 레이아웃 및 DMA 전송기법 연구,2020,"['CNN', 'memory data layout', 'Loop-tiling', 'Accelerator', 'Scatter-Gather DMA']","딥 러닝 알고리즘 중 하나인 CNN 인공지능 어플리케이션은 하드웨어 측면에서 컨벌루션 레이어의 많은 데이터들을 저장하기 위해 오프 칩 메모리를 사용 하고, DMA를 사용하여 매 데이터 전송 시 프로세서의 부하를 줄여 성능을 향상 시킬 수 있다. 또한 컨벌루션 레이어의 데이터를 가속기의 글로벌 버퍼에 전송되는 순서를 다르게 하여 어플리케이션의 성능의 저하를 줄일 수 있다. 불 연속된 메모리 주소를 가지고 있는 베이직 레이아웃의 경우 SG-DMA를 사용 할 때 ordinary DMA를 사용할 때보다 DMA를 사전 설정하는 부분에서 약 3.4배의 성능향상을 보였고 연속적인 메모리 주소를 가지고 있는 아이디얼 레이아웃의 경우 ordinary DMA 와 SG-DMA를 사용하는 두가지 경우 모두 1396 사이클 정도의 오버헤드를 가졌다. 가장 효율적인 메모리 데이터 레이아웃과 DMA의 조합은 프로세서의 DMA 사전 설정 부하를 약 86 퍼센트까지 감소할 수 있음을 실험을 통해 확인했다.","One of the deep-running algorithms, CNN’s artificial intelligence application uses off-chip memory to store data on the Convolution Layer. DMA can reduce processor load at every data transfer. It can also reduce application performance degradation by varying the order in which data from the Convolution layer is transmitted to the global buffer of the accelerator. For basic layouts with continuous memory addresses, SG-DMA showed about 3.4 times performance improvement in pre-setting DMA compared to using ordinaly DMA, and for Ideal layouts with discontinuous memory addresses, the ordinal DMA was about 1396 cycles faster than SG-DMA. Experiments have shown that a combination of memory data layout and DMA can reduce the DMA preset load by about 86 percent."
CNN-Based Novelty Detection with Effectively Incorporating Document-Level Information,2020,"['Deep Learning', 'CNN', 'Novelty Detection', '딥 러닝', '합성곱 신경망', '신규성 탐지']",,"With a large number of documents appearing on the web, document-level novelty detection has become important since it can reduce the efforts of finding novel documents by discarding documents sharing redundant information already seen. A recent work proposed a convolutional neural network (CNN)-based novelty detection model with significant performance improvements. We observed that it has a restriction of using document-level information in determining novelty but assumed that the document-level information is more important. As a solution, this paper proposed two methods of effectively incorporating document-level information using a CNN-based novelty detection model. Our methods focus on constructing a feature vector of a target document to be classified by extracting relative information between the target document and source documents given as evidence. A series of experiments showed the superiority of our methods on a standard benchmark collection, TAP-DLND 1.0."
CNN을 이용한 소비 전력 파형 기반 명령어 수준 역어셈블러 구현,2020,"['Side-Channel Attack', 'Power Analysis', 'Deep Learning', 'Convolutional Neural Network(CNN)', 'Disassembler']","정보보호용 디바이스의 부채널 정보인 소비 전력 파형을 이용하면 내장된 비밀 키 뿐만 아니라 동작 명령어를 복구할 수 있음이 밝혀졌다. 최근에는 MLP 등과 같은 딥러닝 모델을 이용한 프로파일링 기반의 부채널 공격들이 연구되고 있다. 본 논문에서는 마이크로 컨트롤러 AVR XMEGA128-D4가 사용하는 명령어에 대한 역어셈블러를 구현하였다. 명령어에 대한 템플릿 파형을 수집하고 전처리하는 과정을 자동화하였으며 CNN 딥러닝 모델을 사용하여 명령-코드를 분류하였다. 실험 결과, 전체 명령어는 약 87.5%의 정확도로, 사용 빈도가 높은 주요 명령어는 99.6%의 정확도로 분류될 수 있음을 확인하였다.","It has been found that an attacker can extract the secret key embedded in a security device and recover the operation instruction using power consumption traces which are some kind of side channel information. Many profiling-based side channel attacks based on a deep learning model such as MLP(Multi-Layer Perceptron) method are recently researched. In this paper, we implemented a disassembler for operation instruction set used in the micro-controller AVR XMEGA128-D4. After measuring the template traces on each instruction, we automatically made the pre-processing process and classified the operation instruction set using a deep learning model CNN. As an experimental result, we showed that all instructions are classified with 87.5% accuracy and some core instructions used frequently in device operation are with 99.6% respectively."
CNN을 이용한 전방위 영상의 워터마크 추출 방법,2020,"['virtual reality', 'watermark', 'CNN', 'omnidirectional image']",,"In this paper, we propose a watermark extraction method of omnidirectional images using CNN (Convolutional Neural Network) to improve the extracted watermark accuracy of the previous deterministic method that based on algorithm. This CNN consists of a restoration process of extracting watermarks by correcting distortion during omnidirectional image generation and/or malicious attacks, and a classification process of classifying which watermarks are extracted watermarks. Experiments with various attacks confirm that the extracted watermarks are more accurate than the previous methods."
A CNN-LSTM neural network for recognition of puffing in smoking episodes using wearable sensors,2020,"['Cigarette smoking', 'CNN', 'Deep learning', 'Puff', 'Respiration', 'PACT', 'IMU', 'LSTM']",,"A detailed assessment of smoking behavior under free-living conditions is a key challenge for health behavior research. Anumber of methods using wearable sensors and puff topography devices have been developed for smoking and individualpuff detection. In this paper, we propose a novel algorithm for automatic detection of puff s in smoking episodes by using acombination of Respiratory Inductance Plethysmography and Inertial Measurement Unit sensors. The detection of puff s wasperformed by using a deep network containing convolutional and recurrent neural networks. Convolutional neural networks(CNN) were utilized to automate feature learning from raw sensor streams. Long Short Term Memory (LSTM) network layerswere utilized to obtain the temporal dynamics of sensor signals and classify sequence of time segmented sensor streams. Anevaluation was performed by using a large, challenging dataset containing 467 smoking events from 40 participants underfree-living conditions. The proposed approach achieved an F1-score of 78% in leave-one-subject-out cross-validation. Theresults suggest that CNN-LSTM based neural network architecture suffi ciently detect puffi ng episodes in free-living condition.The proposed model be used as a detection tool for smoking cessation programs and scientifi c research."
Efficient Data Acquisition and CNN Design for Fish Species Classification in Inland Waters,2020,"['Convolutional neural network', 'Data acquisition', 'Efficient classification', 'Exotic invasive fish species']",,"We propose appropriate criteria for obtaining fish species data and number of learning data, as well as for selecting the most appropriate convolutional neural network (CNN) to efficiently classify exotic invasive fish species for their extermination. The acquisition of large amounts of fish species data for CNN learning is subject to several constraints. To solve these problems, we acquired a large number of fish images for various fish species in a laboratory environment, rather than a natural environment.We then converted the obtained fish images into fish images acquired in different natural environments through simple image synthesis to obtain the image data of the fish species. We used the images of largemouth bass and bluegill captured at a pond as test data to confirm the effectiveness of the proposed method. In addition, to classify the exotic invasive fish species accurately, we evaluated the trained CNNs in terms of classification performance, processing time, and the number of data; consequently, we proposed a method to select the most effective CNN."
비관계형 데이터베이스 환경에서 CNN과 RNN을 활용한 NoSQL 삽입 공격 탐지 모델,2020,"['NoSQL injection', 'Deep Learning', 'Convolutional Neural Network(CNN)', 'Recurrent Neural Network(RNN)']","데이터 활용의 다양성이 높아짐에 따라 비관계형 데이터베이스 사용이 증가했으며, 이에 대한 NoSQL 삽입 공격또한 증가했다. 전통적으로 NoSQL 삽입 공격을 탐지하기 위해 규칙 기반 탐지 방법론이 제안돼왔으나, 이 방식은규칙의 범위를 벗어나 발생하는 삽입 공격에의 대응이 어렵다는 한계점이 있다. 이에 본 논문에서는 CNN 알고리즘을 이용해 특징을 추출하고, RNN 알고리즘을 활용해 NoSQL 삽입 공격을 탐지하는 기법을 제시한다. 또한, 실험을 통하여 본 논문에서 제시한 모델이 기존의 지도학습을 이용한 가장 우수한 모델보다 정확도는 10%, 정밀도는4%, 재현율은 14%, F2-score는 0.082만큼 더 높은 비율로 NoSQL 삽입 공격을 탐지함을 보인다.","With a variety of data types and high utilization of data, non-relational databases are a popular data storage because itsupports better availability and scalability. The increasing use of this technology also brings the risk of NoSQL injectionattacks. Existing works mostly discuss the rule-based detection of NoSQL injection attacks that it is hard to deal withNoSQL queries beyond the coverage of the rules. In this paper, we propose a model for detecting NoSQL injection attacks.Our model is based on deep learning algorithms that select features from NoSQL queries using CNN, and classify NoSQLqueries using RNN. Also, we experiment the proposed model to compare with existing models, and find that our modeloutperforms traditional models in terms of detection rate."
Estimation of gender and age using CNN-based face recognition algorithm,2020,"['gender estimation', 'age estimation', 'face recognition', 'CNN']",,"This study proposes a method for estimating gender and age that is robust to various external environment changes by applying deep learning-based learning. To improve the accuracy of the proposed algorithm, an improved CNN network structure and learning method are described, and the performance of the algorithm is also evaluated. In this study, in order to improve the learning method based on CNN composed of 6 layers of hidden layers, a network using GoogLeNet's inception module was constructed. As a result of the experiment, the age estimation accuracy of 5,328 images for the performance test of the age estimation method is about 85%, and the gender estimation accuracy is about 98%. It is expected that real-time age recognition will be possible beyond feature extraction of face images if studies on the construction of a larger data set, pre-processing methods, and various network structures and activation functions have been made to classify the age classes that are further subdivided according to age."
CNN-Based Recognition Algorithm for Four Classes of Roads,2020,"['CNN', 'Image recognition', 'Walking environment', 'Cautionary dispersion']",,"In recent years, location-based augmented reality games have become popular globally. Consequently, the risk of collisions or accidents while walking with mobile devices has increased. Using smartphones while walking can distract pedestrians and can lead to negative consequences for traffic safety. In addition, a survey of visually impaired people revealed that they found border recognition inconvenient due to the lowered jaws between the driveway and sidewalks. In this study, an accident prevention system is proposed based on a convolutional neural network by segregating the walking environments into four classes (sidewalks, driveways, crosswalks, and braille blocks). A total of 3,200 datasets (3,000 for training and 200 for test) were used in our study. We show that the proposed system has the accuracy of 90% for validation data, and the recognition rate of 90% or above for test data."
Rayleigh 페이딩에서 CNN을 이용한 주파수 도약 신호 탐지 방법 연구,2020,"['Frequency-hopping', 'Detection', 'Deep learning', 'CNN', 'Rayleigh fading']",,
Ontology and CNN-based Inference of the Threat Relationship Between UAVs and Surrounding Objects,2020,"['무인기', '관계 추론', '온톨로지', 'CNN', '그리드 맵', 'UAVs', 'relationship inference', 'ontology', 'grid map']",,
CNN-based Reduced Complexity Decision Confidence Estimation for Imbalanced Web Application Attack Detection,2020,"['몬테카를로배치정규화', '불확실성', '신뢰성', '컨볼루션 신경망', '클래스 불균형', '웹 어플리케이션', 'Monte-Carlo batch normalization', 'uncertainty', 'confidence', 'convolutional neural network', 'class imbalance', 'web application']",,
CNN-based Speech Emotion Recognition Model Applying Transfer Learning and Attention Mechanism,2020,"['음성 감정 인식', '멜-스펙트로그램', 'MFCC', '합성곱 신경망', '전이학습', '어텐션', 'speech emotion recognition', 'Mel-Spectrogram', 'CNN', 'transfer learning', 'attention']",,
CNN을 이용한 대기차량 카운팅 알고리즘 구조에 관한 연구,2020,"['Convolutional neural network', 'Vehicle counting', 'Sensitivity analysis', 'Classification']",,"Increased computing power and advanced deep learning technology have enabled computers to effectively deal with problems that cannot be solved by ordinary people. Many attempts have been made to utilize deep learning technology to analyze road images and efficiently control crossroad vehicle flow. In this research, a new methodology is proposed for identifying the number of vehicles on the road using CNN (convolution neural network), deep learning technology that specializes in image classification. Unlike previous studies that used regression methods and video frames as input, this study determined the number of vehicles using real-time photographic images and classification methods for one lane. An experiment was conducted to find the optimal combination of variables using sensitivity analysis. The optimal network determined the number of vehicles on one lane with a high accuracy of 98.31%."
Estimation of Slag Removal Path using CNN-based Path Probability of Ladle Image Blocks,2020,"['Backward tracing', 'convolutional neural network', 'direction probability', 'image block', 'slag removal.']",,"De-slagging is a task of removing slag on the surface of molten metals, such as steel, in a ladle. In this paper, we propose a method of slag removal path estimation using CNN (Convolution Neural Network) to automate de-slagging task using a robotic machine. From a sequence of images captured from the top of the ladle, we first extract the 2-dimensional trajectory of the slag removal motion of an experienced human operator. Then several image blocks are obtained at sample points along the removal trajectory to train a neural network. The output of the network consists of four labels which represent the probability of four different removal directions of an input image block. To test the trained neural network, we uniformly divide a test ladle image to a fixed-size block with a given stride value. All image blocks are tested and the probability of the four directions are determined and recorded by the trained network. By multiplying the slag probability with the removal direction probability, joint probability of slag removal direction (JPSRD) is introduced. Finally, a slag removal path is estimated by applying the backward tracing method from the endpoint of the ladle so that the estimated path yields the highest JPSRD. A curve fitting is then applied to make smooth slag removal path. The path decision accuracy of an image block is about 90%. We also compare the estimated a slag removal path with that of the experienced operator."
Study and Application of RSSI-based Wi-Fi Channel Detection Using CNN and Frequency Band Characteristics,2020,"['와이파이 스캔', '비면허 대역', '저전력 안테나', '딥 러닝', '합성곱 신경망', 'Wi-Fi scanning', 'ISM band', 'low power antenna', 'deep learning', 'convolution neural network']",,
CNN을 활용한 방송 뉴스의 감정 분석,2020,[],,"In Korea, video-based news broadcasters are primarily classified into terrestrial broadcasters, general programming cable broadcasters and YouTube broadcasters. Recently, news broadcasters get subjective while targeting the desired specific audience. This violates normative expectations of impartiality and neutrality on journalism from its audience. This phenomenon may have a negative impact on audience perceptions of issues. This study examined whether broadcast news reporting conveys emotions and if so, how news broadcasters differ according to emotion type. Emotion types were classified into neutrality, happiness, sadness and anger using a convolutional neural network which is a class of deep neural networks. Results showed that news anchors or reporters tend to express their emotions during TV broadcasts regardless of broadcast systems. This study provides the first quantative investigation of emotions in broadcasting news. In addition, this study is the first deep learning-based approach to emotion analysis of broadcasting news."
필터 분해 기법을 이용한 에너지 효율적 재구성형 CNN 가속기 구조,2020,"['Convolutional neural network', 'accelerator', 'energy efficiency', 'filter decompositon', 'RS dataflow']",,
CNN 알고리즘의 개선을 통한 대형 이미지에서의 객체식별,2020,"['AI', 'Transfer Learning', 'CNN', 'Hi-resolution Large Image', 'Object Detection', '인공지능', '전환학습', '고해상도 대형 이미지', '객체인식']","기존의 CNN 알고리즘은 위성영상과 같은 대형 이미지에서 소형 객체를 식별하는 것이 불가능하다는 문제점을 가지고 있었다. 본 연구에서는 이러한 문제를 해결하기 위해 관심영역 설정 및 이미지 분할기법을 적용한 CNN 알고리즘 개선방안을 제시하였다. 실험은 비행장 및 항공기 데이터셋으로 전환학습한 YOLOv3 / Faster R-CNN 알고리즘과 테스트용 대형 이미지를 이용하여 진행하였으며, 우선 대형 이미지에서 관심영역을 식별하고 이를 순차적으로 분할해 나가며 CNN 알고리즘의 객체식별 결과를 비교하였다. 분할 이미지의 크기는 실험을 통해 최소 분할로 최대의 식별률을 얻을 수 있는 최적의 이미지 조각 크기를 도출하여 적용하였다. 실험 결과, 본 연구에서 제시한 방안을 통해 CNN 알고리즘으로 대형 이미지에서의 소형 객체를 식별하는 것이 충분히 가능함을 검증하였다.","Conventional Convolutional Neural Network(CNN) algorithms have limitations in detecting small objects in large image. In this paper, we propose an improved model which is based on Region Of Interest(ROI) selection and image dividing technique. We prepared YOLOv3 / Faster R-CNN algorithms which are transfer-learned by airfield and aircraft datasets. Also we prepared large images for testing. In order to verify our model, we selected airfield area from large image as ROI first and divided it in two power n orders. Then we compared the aircraft detection rates by number of divisions. We could get the best size of divided image pieces for efficient small object detection derived from the comparison of aircraft detection rates. As a result, we could verify that the improved CNN algorithm can detect small object in large images."
Voting and Ensemble Schemes Based on CNN Models for Photo-Based Gender Prediction,2020,"['Majority Voting', 'Softmaxbased Voting', 'Ensemble Scheme', 'Gender Prediction', 'CNN models']",,"Gender prediction accuracy increases as convolutional neural network (CNN) architecture evolves. This paper compares voting and ensemble schemes to utilize the already trained five CNN models to further improve gender prediction accuracy. The majority voting usually requires oddnumbered models while the proposedsoftmaxbased voting can utilize any number of models to improve accuracy. The ensemble of CNN models combined with one more fullyconnected layer requires further tuning or training of the models combined. With experiments, it is observed that the voting or ensemble of CNN models leads to further improvement of genderprediction accuracy and that especially softmaxbased voters always show better gender prediction accuracy than majority voters. Also, compared with softmaxbased voters, ensemble models show a slightly better or similar accuracy with added training of the combined CNN models. Softmaxbased voting can be a fast andefficient way to get better accuracy without further training since the selection of the top accuracy models among available CNN pretrained models usually leads to similar accuracy to that of the corresponding ensemble models."
임베디드 보드에서의 CNN 모델 압축 및 성능 검증,2020,"['CNN', 'Neural Network Compression', 'Pruning', 'Matrix Decomposition', 'Embedded Board']",,"Recently, deep neural networks such as CNN are showing excellent performance in various fields such as image classification, object recognition, visual quality enhancement, etc. However, as the model size and computational complexity of deep learning models for most applications increases, it is hard to apply neural networks to IoT and mobile environments. Therefore, neural network compression algorithms for reducing the model size while keeping the performance have been being studied. In this paper, we apply few compression methods to CNN models and evaluate their performances in the embedded environment. For evaluate the performance, the classification performance and inference time of the original CNN models and the compressed CNN models on the image inputted by the camera are evaluated in the embedded board equipped with QCS605, which is a customized AI chip. In this paper, a few CNN models of MobileNetV2, ResNet50, and VGG-16 are compressed by applying the methods of pruning and matrix decomposition. The experimental results show that the compressed models give not only the model size reduction of 1.3~11.2 times at a classification performance loss of less than 2% compared to the original model, but also the inference time reduction of 1.2~2.21 times, and the memory reduction of 1.2~3.8 times in the embedded board."
챗봇의 의도 예문 자동 입력을 위한 Text-CNN 기반 의도 분류 방법,2020,"['chatbot framework', 'natural language processing', 'intent classification', 'CNN', 'increase the inference rate', 'text']",,"In this paper, we propose how to automatically categorize and generate examples of given intents using Text-CNN in order to increase the inference rate of the existing chatbot framework. The Intent Classification System uses Text-CNN to learn data consisting of word vectors and position vectors for each prepared sentence through the preprocessing process. The proposed Text-CNN structure has a construction layer, a max pooling layer, and a fully connected soft max layer as its output. In addition, dropout is applied to perform regularization.  For the experiment, a total of 9,000 sentences were collected using webscraping. An experiment showed that the accuracy obtained from Text-CNN’s learning of kitchen intents was about 94%. The rest of the sentences, not labeled with the model produced by Text-CNN, were grouped and 63 cases of cooking were extracted in total and the sentences were input in Chatbot."
다시점 영상 집합을 활용한 선체 블록 분류를 위한 CNN 모델 성능 비교 연구,2020,"['Multi-view image set(다시점 영상 집합)', 'Convolutional Neural Network(CNN', '합성곱신경망)', 'Ship hull block(선체 블록)', 'Classification(분류)', 'Data augmentation(데이터 확장)', 'Transfer learning(전이학습)']",,"It is important to identify the location of ship hull blocks with exact block identification number when scheduling the shipbuilding process. The wrong information on the location and identification number of some hull block can cause low productivity by spending time to find where the exact hull block is. In order to solve this problem, it is necessary to equip the system to track the location of the blocks and to identify the identification numbers of the blocks automatically. There were a lot of researches of location tracking system for the hull blocks on the stockyard. However there has been no research to identify the hull blocks on the stockyard. This study compares the performance of 5 Convolutional Neural Network (CNN) models with multi-view image set on the classification of the hull blocks to identify the blocks on the stockyard. The CNN models are open algorithms of ImageNet Large-Scale Visual Recognition Competition (ILSVRC). Four scaled hull block models are used to acquire the images of ship hull blocks. Learning and transfer learning of the CNN models with original training data and augmented data of the original training data were done. 20 tests and predictions in consideration of five CNN models and four cases of training conditions are performed. In order to compare the classification performance of the CNN models, accuracy and average F1-Score from confusion matrix are adopted as the performance measures. As a result of the comparison, Resnet-152v2 model shows the highest accuracy and average F1-Score with full block prediction image set and with cropped block prediction image set."
CNN based Sound Event Detection Method using NMF Preprocessing in  Background Noise Environment,2020,"['Non-negative matrix', 'CNN', 'artificial neural networks', 'Sound Event Detection', 'Signal to Noise Ratio.']",,"Sound event detection in real-world environments suffers from the interference of non-stationary and time-varying noise. This paper presents an adaptive noise reduction method for sound event detection based on non-negative matrix factorization (NMF). In this paper, we proposed a deep learning model that integrates Convolution Neural Network (CNN) with Non-Negative Matrix Factorization (NMF). To improve the separation quality of the NMF, it includes noise update technique that learns and adapts the characteristics of the current noise in real time. The noise update technique analyzes the sparsity and activity of the noise bias at the present time and decides the update training based on the noise candidate group obtained every frame in the previous noise reduction stage. Noise bias ranks selected as candidates for update training are updated in real time with discrimination NMF training. This NMF was applied to CNN and Hidden Markov Model(HMM) to achieve improvement for performance of sound event detection. Since CNN has a more obvious performance improvement effect, it can be widely used in sound source based CNN algorithm."
CNN 기법을 활용한 운전자 시선 사각지대 보조 시스템 설계 및 구현 연구,2020,"['AI', 'CNN', 'Driver Assistance System']","한국도로교통공단은 교통사고분석시스템(TAAS)을 활용하여 2015년부터 발생한 교통사고 원인을 분석한 통계를 제공하고 있다. 교통사고 발생 주요 원인으로, 2018년 한해 전체 교통사고 발생원인 중 전방주시 부주의가 대부분의 원인임을 TAAS를 통해 발표했다. 교통사고 원인에 대한 통계자료의 세부항목으로 운전 중 스마트폰 사용, DMB 시청 등의 안전운전 불이행 51.2%와 안전거리 미확보 14%, 보행자 보호의무 위반 3.6% 등으로, 전체적으로 68.8%의 비율을 보여준다. 본 논문에서는 Deep Learning의 알고리듬 중 CNN(Convolutional Neural Network)를 활용하여 첨단 운 전자 보조 시스템 ADAS(Advanced Driver Assistance Systems)을 개선한 시스템을 제안하고자 한다. 제안된 시스템 은 영상처리에 주로 사용되는 Conv2D 기법을 사용하여 운전자의 얼굴과 눈동자의 조향을 분류하는 모델을 학습하고, 차량 전방에 부착된 카메라로 자동차의 주변 object를 인지 및 검출하여 주행환경을 인지한다. 그 후, 학습된 시선 조향 모델과 주행환경 데이터를 사용하여 운전자의 시선과 주행환경에 따라, 위험요소를 3단계로 분류하고 검출하여 운전자 의 전방 및 사각지대 보조한다.","The Korea Highway Traffic Authority provides statistics that analyze the causes of traffic accidents that occurred since 2015 using the Traffic Accident Analysis System (TAAS). it was reported Through TAAS that the driver's forward carelessness was the main cause of traffic accidents in 2018. As statistics on the cause of traffic accidents, 51.2 percent used mobile phones and watched DMB while driving, 14 percent did not secure safe distance, and 3.6 percent violated their duty to protect pedestrians, representing a total of 68.8 percent. In this paper, we propose a system that has improved the advanced driver assistance system ADAS (Advanced Driver Assistance Systems) by utilizing CNN (Convolutional Neural Network) among the algorithms of Deep Learning. The proposed system learns a model that classifies the movement of the driver's face and eyes using Conv2D techniques which are mainly used for Image processing, while recognizing and detecting objects around the vehicle with cameras attached to the front of the vehicle to recognize the driving environment. Then, using the learned visual steering model and driving environment data, the hazard is classified and detected in three stages, depending on the driver's view and driving environment to assist the driver with the forward and blind spots."
CNN based Sound Event Detection Method using NMF Preprocessing in Background Noise Environment,2020,"['Non-negative matrix', 'CNN', 'artificial neural networks', 'Sound Event Detection', 'Signal to Noise Ratio']",,"Sound event detection in real-world environments suffers from the interference of non-stationary and time-varying noise. This paper presents an adaptive noise reduction method for sound event detection based on non-negative matrix factorization (NMF). In this paper, we proposed a deep learning model that integrates Convolution Neural Network (CNN) with Non-Negative Matrix Factorization (NMF). To improve the separation quality of the NMF, it includes noise update technique that learns and adapts the characteristics of the current noise in real time. The noise update technique analyzes the sparsity and activity of the noise bias at the present time and decides the update training based on the noise candidate group obtained every frame in the previous noise reduction stage. Noise bias ranks selected as candidates for update training are updated in real time with discrimination NMF training. This NMF was applied to CNN and Hidden Markov Model(HMM) to achieve improvement for performance of sound event detection. Since CNN has a more obvious performance improvement effect, it can be widely used in sound source based CNN algorithm."
레이저 열화상 기법과 CNN 딥러닝을 이용한 용접부 표면의 자동 균열 검출 기술 개발,2020,"['CNN', '레이저 열화상', '비파괴검사', '용접 균열 진단', 'Laser active thermography', 'Nondestructive testing', 'Welding crack diagnosis']","본 연구에서는 레이저 열화상 시스템과 균열 검출 알고리즘 개발을 통해 용접부에서 균열을 자동검출하는 기술을 연구하였다. 레이저 열화상 시스템은 레이저 가진으로 인해 균열부에서 발생하는 열파 집중현상을 관측하도록 구성되었다. 균열 검출 알고리즘은 (1) 온도 분포 특성을 이용한 열화상 이미지 병합으로 균열을 가시화하고, (2) 과적합을 방지하는 input 이미지 생성과 (3) CNN 딥러닝을 통해 균열부의 특징을 분석, 분류하여, (4) 원본 열화상 이미지에 균열의 위치를 Masking 한다. SUS 시험편 2개로 개발 기술을 검증하였고, 현미경과 액체침투법으로 확인한 실제 균열 정보와 비교하였다. 시험편 #1의 균열 이미지 618 개와 정상 이미지 1834개로 CNN 을 훈련시켰다. 시험편 #1과 #2의 총 9개 영역을 각 300개의 Test 이미지로 나눠 훈련된 알고리즘 성능을 검증해본 결과, 총 균열 14개 중 13개를 검출하였고, 정상 이미지 4개가 과검출되었다. 따라서 개발된 알고리즘은 용접부에서 용접의 복잡한 패턴과 구별하여 균열을 검출할 수 있다.","In this study, automatic crack detection for welded surfaces was studied through the development of a laser active thermography system and a crack detection algorithm. The laser active thermography system observes thermal wave concentrations in the crack while exciting the surface of the weld. The crack detection algorithm (1) visualizes the cracks by merging the infrared (IR) images using the temperature distribution characteristics; (2) employs input image generation with a specific method to prevent overfitting; (3) analyzes and classifies the characteristics of the cracks using a deep learning convolutional neural network (CNN); and (4) marks the location of the cracks in the original IR image. The system and algorithm were verified using two SUS specimens (#1 and #2) and compared with actual crack data obtained by microscopy and penetration test. The CNN was trained with 618 images of cracks and 1834 images of intact specimen #1. For performance verification, a total of nine areas of specimens #1 and #2 were divided into 300 test images; 13 out of 14 cracks were detected while four intact images were overdetected. Thus, the developed algorithm can detect cracks in welded surfaces by distinuishing them from complex patterns of welding."
코로나19 관련 CNN 뉴스 영상분석: ‘타자’의 질병에서 ‘우리’의 질병으로,2020,"['코로나19', 'CNN', '뉴스 영상분석', '질병 타자화', '가시화', 'COVID-19', 'News Visual Analysis', 'Othering of Diseases', 'Visualization']","2020년 전 세계를 강타한 코로나19는 질병보건학적 측면뿐 아니라 문명사적으로도 큰 전환점이 될 것이라는 전망이다. 특히 중국을 넘어선 미국과 유럽에서의 심각한 코로나19 확산은 기존의 서구 우월주의적 질병 세계관에 큰 균열을 가져왔다. 이 연구는 코로나19가 글로벌 팬데믹으로 확산되면서 글로벌 뉴스매체의 영상 보도 패턴이 어떻게 변화했는지를 살펴보기 위해 CNN International의 뉴스 영상에 대한 양적, 질적 분석을 실시하였다. 코로나19 확산 단계별, 대상 국가별 영상 보도의 변화를 살펴보기 위해 2020년 1월부터 3월까지 방송된 CNN 월드 뉴스 가운데 대표성을 띠는 8개의 뉴스 아이템을 분석대상으로 선정하였다. 각 뉴스 아이템의 1) 구조적 요소(structural element), 2) 시각적 주제 프레임(visual thematic frame), 3) 표현 스타일(style)에 대한 샷(shot) 단위 내용분석과 질적 텍스트 분석이 이뤄졌다. 분석결과, 초기 중국을 대상으로 한 영상 보도에는 ‘응급현장’ ‘문화적 스테레오타이프’ 주제 유형이 주로 나타났으며, ‘타자화’된 질병의 내러티브가 중심이 되었다. 반면 미국과 유럽 확산 이후의 코로나19는 ‘우리’의 질병으로 재현되면서, 이에 대한 ‘과학적 통제’와 ‘질병 시각화’가 주요한 주제 유형으로 나타났다. 마지막으로 이러한 글로벌 뉴스매체의 영상 보도의 변화가 갖고 있는 사회문화적 함의를 논의하였다.","The COVID-19 from 2019 to 2010 is a global crisis what would change the modern history of human beings in terms of global public health and human civilization. As the coronavirus from China unprecedentedly attacked the European countries and the U.S., the existing disease worldview based on the West supremacy and ‘Orientalism’ has been seriously unsettled. This study attempts to examine how the visual coverage of the global news media has been changed as the Chinese outbreaks expanding to the ‘global pandemic’ and the serious Western disease crisis. For this purpose, this study analysed the news items of CNNI(CNN International) focusing on the visual aspects. Using both the quantitative and qualitative methods, this study closely examines 1) the structural elements, 2) visual thematic frame, 3) visual expressive style of 8 CNN world news items from 2020. 1.1 to 3.31. Research findings show that the coverage of Chinese Wuhan’s outbreak employs the narratives of disease ‘othering’ with the visual thematic frame of ‘emergency,’ and ‘cultural stereotypes’ On the other hand, the coverage of the U.S and Italy tends to use the narrative of ‘our disease’ using the visual frames of the ‘scientific control’ and ‘visualization of virus’ The social cultural implication of research findings are discussed."
Cellular V2X 시스템을 위한 CNN 기반 채널 추정기법,2020,"['V2X', 'CNN', 'Channel Estimation', 'C-V2X', 'Sidelink']",,
Concept Drift Based on CNN Probability Vector in Data Stream Environment,2020,"['Convolution Neural Network Algorithm (CNN)', 'Concept Drift', 'Data Stream', 'Probability Vector']",,"In this paper, we propose a method to detect concept drift by applying Convolutional Neural Network (CNN) in a data stream environment. Since the conventional method compares only the final output value of the CNN and detects it as a concept drift if there is a difference, there is a problem in that the actual input value of the data stream reacts sensitively even if there is no significant difference and is incorrectly detected as a concept drift. Therefore, in this paper, in order to reduce such errors, not only the output value of CNN but also the probability vector are used. First, the data entered into the data stream is patterned to learn from the neural network model, and the difference between the output value and probability vector of the current data and the historical data of these learned neural network models is compared to detect the concept drift. The proposed method confirmed that only CNN output values could be used to reduce detection errors compared to how concept drift were detected."
Potato Detection and Segmentation Based on Mask R-CNN,2020,['Deep learning . Mask R-CNN . Potato detection . Potato segmentation'],,"Purpose Potatoes are similar in color and size to soil and its clods. They are mostly irregular in the shape as well. Therefore, it is not easy to distinguish potatoes from the soil surface background only with machine vision. This study applied Mask R-CNN, one of the object recognition technologies using deep learning to detect potatoes. The size of object in pixel was obtained on individual potato, and they will be used to predict the yield of potatoes.Methods In order to collect the images needed for deep learning, potato images at the time of harvesting were obtained from potato farms. Annotation was entered for each irregular potato shape, where approximately 4500 potatoes were used. Resnet-101 was selected as the backbone of Mask R-CNN with a feature pyramid network. Transfer training was applied to shorten training time and limit the number of images needed to train the model. The classification performance evaluation was conducted to verify the trained model. The size of potato in pixel was obtained from the output image through the potato detection model by the segmentation algorithm using MATLAB.Results The total number of training for the potato detection model was 12,000, and the training loss of Mask R-CNN was less than 0.1%. The potato detection results from 69 randomly selected test images showed that the average detection precision was 90.8%, recall 93.0%, and F1 score 91.9%.Conclusions Potato detection model with Mask R-CNN can detect irregularly shaped potatoes on similar color soil surface. The size of the detected potato region can be extracted as well."
소프트웨어-정의 네트워크에서 CNN 모델을 이용한 DDoS 공격 탐지 기술,2020,"['CNN', 'Deep Learning', 'DDoS Attack', 'Permutation Importance Algorithm', 'Software Defined Network']","소프트웨어 정의 네트워크가 확장성, 유연성, 네트워크상 프로그래밍이 가능한 특징으로 네트워크 관리에서 표준으로 자리잡아 가고 있지만 많은 장점에도 불구하고 하나의 컨트롤러에 대한 사이버 공격이 전체 네트워크를 영향을 주는 문제점을 가지고 있다. 특히, 컨트롤러에 대한 DDoS 공격이 대표적인 사례로서 다양한 공격 탐지 기술에 대한 연구가 진행되고 있다. 본 논문에서는 최초로 84개 DDoS 공격 Feature 데이터셋을 Kaggle에서 획득한 후 Permutation Feature Importance 알고리즘을 이용하여 상위 20의 중요도를 갖는 Feature를 선택하여 딥 러닝 기반의 CNN 모델에서 학습과 검증을 수행하였다. 이를 통해, 최적의 공격 탐지율을 갖는 상위 13개의 DDoS Feature 선택이 DDoS 공격 탐지율 96%을 유지하면서 적정한 공격 탐지 시간, 정확성 등에서 매우 우수한 결과를 제시하였다.","Software Defined Networking (SDN) is setting the standard for the management of networks due to its scalability, flexibility and functionality to program the network. The Distributed Denial of Service (DDoS) attack is most widely used to attack the SDN controller to bring down the network. Different methodologies have been utilized to detect DDoS attack previously. In this paper, first the dataset is obtained by Kaggle with 84 features, and then according to the rank, the 20 highest rank features are selected using Permutation Importance Algorithm. Then, the datasets are trained and tested with Convolution Neural Network (CNN) classifier model by utilizing deep learning techniques. Our proposed solution has achieved the best results, which will allow the critical systems which need more security to adopt and take full advantage of the SDN paradigm without compromising their security."
New Method of Internal Type-2 Fuzzy-Based CNN for Image Classification,2020,"['CNN', 'FCNN', 'Fuzzy logic', 'Interval type-2 fuzzy logic', 'Feature extraction', 'Computer vision', 'Image classification']",,"In the last two decades, neural networks and fuzzy logic have been successfully implemented in intelligent systems. The fuzzy neural network (FNN) system framework infers the union of fuzzy logic and neural network system framework thoughts, which consolidates their advantages. The FNN system is applied in several scientific and engineering areas. Wherever there is uncertainty associated with the data, fuzzy logic places a vital rule. The fuzzy set can effectively represent and handle uncertain information. The main objective of the FNN system is to achieve a high level of accuracy by including the fuzzy logic in either the neural network structures, activation functions, or learning algorithms. In computer vision and intelligent systems, convolutional neural networks (CNNs) have more popular architectures, and their performance is excellent in many applications. In this paper, fuzzy-based CNN image classification methods are analyzed, and an interval type-2 fuzzy-based CNN is proposed. The experimental results indicated that the performance of the proposed method was good."
Predicting Stock Prices Based on Online News Content and Technical Indicators by Combinatorial Analysis Using CNN and LSTM with Self-attention,2020,"['Stock Price Prediction', 'Online News', 'CNN', 'LSTM', 'Technical Indicators']",,
CNN 모델을 이용한 보행자 인식 및 신장 추정 방법,2020,"['단안카메라', '보행자', '딥러닝', '합성곱신경망 모델', '렌즈왜곡보상', 'Monocular Camera', 'Pedestrian', 'Deep Learning', 'CNN Model', 'LDC']",,"In this paper, the convolutional neural network (CNN) model, which is an object-recognition technology based on deep learning, was applied to images acquired from a monocular camera to detect pedestrians. The detected image coordinates of the pedestrians were converted to map coordinates, and the height of the pedestrians was inferred using a proportional equation. For this, a monocular camera equipped with lens distortion compensation was installed at an altitude of 3.5 m, and the pitch and yaw angles were set to collimate pedestrians. That is how we proceed image capturing. In the CNN model, the image coordinates of the object were acquired in real-time using the bounding box. After converting the image coordinates of the acquired object to map coordinates, the height of pedestrians could be calculated using a proportional equation."
영상처리기법을 이용한 CNN 기반 리눅스 악성코드 분류 연구,2020,"['Linux Malware', 'Machine Learning', 'CNN', 'LBP', 'Median Filter', 'Majority Voting Classifiers']","사물인터넷(IoT) 기기의 확산으로 인해 다양한 아키텍처가 존재하는 Linux 운영체제의 활용이 증가하였다. 이에 따라 Linux 기반의 IoT 기기에 대한 보안 위협이 증가하고 있으며 기존 악성코드를 기반으로 한 변종 악성코드도 꾸준히 등장하고 있다. 본 논문에서는 시각화한 ELF(Executable and Linkable Format) 파일의 바이너리 데이터를 영상처리 기법 중 LBP(Local Binary Pattern)와 Median Filter를 적용하여 CNN(Convolutional Neural Network)모델로 악성코드를 분류하는 시스템을 제안한다. 실험 결과 원본 이미지의 경우 98.77%의 점수로 가장 높은 정확도와 F1-score를 보였으며 재현율도 98.55%의 가장 높은 점수를 보였다. Median Filter의 경우 99.19%로 가장 높은 정밀도와 0.008%의 가장 낮은 위양성률을 확인하였으며 LBP의 경우 전반적으로 원본과 Median Filter보다 낮은 결과를 보였음을 확인하였다. 원본과 영상처리기법별 분류 결과를 다수결로 분류했을 경우 원본과 Median Filter의 결과보다 정확도, 정밀도, F1-score, 위양성률이 전반적으로 좋아졌음을 확인하였다. 향후 악성코드 패밀리 분류에 활용하거나 다른 영상처리기법을 추가하여 다수결 분류의 정확도를 높이는 연구를 진행할 예정이다.","With the proliferation of Internet of Things (IoT) devices, using the Linux operating system in various architectures has increased. Also, security threats against Linux-based IoT devices are increasing, and malware variants based on existing malware are constantly appearing. In this paper, we propose a system where the binary data of a visualized Executable and Linkable Format (ELF) file is applied to Local Binary Pattern (LBP) image processing techniques and a median filter to classify malware in a Convolutional Neural Network (CNN). As a result, the original image showed the highest accuracy and F1-score at 98.77%, and reproducibility also showed the highest score at 98.55%. For the median filter, the highest precision was 99.19%, and the lowest false positive rate was 0.008%. Using the LBP technique confirmed that the overall result was lower than putting the original ELF file through the median filter. When the results of putting the original file through image processing techniques were classified by majority, it was confirmed that the accuracy, precision, F1-score, and false positive rate were better than putting the original file through the median filter. In the future, the proposed system will be used to classify malware families or add other image processing techniques to improve the accuracy of majority vote classification. Or maybe we mean ""the use of Linux O/S distributions for various architectures has increased"" instead? If not, please rephrase as intended."
Real-time Smoke Detection Research with False Positive Reduction using Spatial and Temporal Features based on Faster R-CNN,2020,"['deep learning', 'wavelet transform', 'smoke detection', 'false positive', 'temporal and spatial features']",,"Fire must be extinguished as quickly as possible because they cause a lot of economic loss and take away precious human lives. Especially, the detection of smoke, which tends to be found first in fire, is of great importance. Smoke detection based on image has many difficulties in algorithm research due to the irregular shape of smoke. In this study, we introduce a new real-time smoke detection algorithm that reduces the detection of false positives generated by irregular smoke shape based on faster r-cnn of factory-installed surveillance cameras. First, we compute the global frame similarity and mean squared error (MSE) to detect the movement of smoke from the input surveillance camera. Second, we use deep learning algorithm (Faster r-cnn) to extract deferred candidate regions. Third, the extracted candidate areas for acting are finally determined using space and temporal features as smoke area. In this study, we proposed a new algorithm using the space and temporal features of global and local frames, which are well-proposed object information, to reduce false positives based on deep learning techniques. The experimental results confirmed that the proposed algorithm has excellent performance by reducing false positives of about 99.0% while maintaining smoke detection performance."
정비 자료 디지털 변환을 위한 영상 인식 알고리듬 : CNN and FCN,2020,"['Tabular Maintenance Data(정비 자료표)', 'Digitization(디지털화)', 'CNN(합성곱 신경망)', 'FCN(완전 연결망)']",,"Tabulated data has been widely used to facilitate systematic and intuitive management. In particular, tabular images that contain a few simple symbols are useful for maintaining mechanical systems. Several companies have accumulated tabular images as their property. Although these images are valuable as they can be used to solve difficult problems using data-based methods, such as deep learning, they still remain unavailable because it is expensive to digitize them. For these reasons, we propose a model comprised of a convolutional neural network (CNN) and fully convolutional network (FCN) to digitize tabular images. We used some ResNet components as they are well-suited to the characteristics of tabular image data. A training set for each model was constructed by writing symbols in blank tables and then augmenting them. As a result, the trained CNN and FCN models exhibited 99.2 % and 97.7 % accuracy in 4.75 s and 0.132 s of inference time, respectively."
Drivable Area Detection with Region-based CNN Models to Support Autonomous Driving,2020,"['Detection of drivable areas', 'Region-based CNN', 'BDD dataset', 'Autonomous driving software']",,"In autonomous driving, object recognition based on machine learning is one of the core software technologies. In particular, the object recognition using deep learning becomes an essential element for autonomous driving software to operate. In this paper, we introduce a drivable area detection method based on Region-based CNN model to support autonomous driving. To effectively detect the drivable area, we used the BDD dataset for model training and demonstrated its effectiveness. As a result, our R-CNN model using BDD datasets showed interesting results in training and testing for detection of drivable areas."
Surface Parameter Measurement of Braided Composite Preform Based on Faster R-CNN,2020,"['Braided composite preform', 'Pitch length', 'Surface braiding angle', 'Deep learning', 'Faster R-CNN']",,"Pitch length and surface braiding angle are two important parameters of braided composite preforms. In this paper,a method based on Faster R-CNN is proposed to measure the two parameters. First, after image acquisition, a fabric imagedatabase including initial cropped images, augmented images, and target images is established. Then, the target images areclassified into four categories according to the gray change characteristics. Third, a Faster R-CNN fabric detection model istrained on the fabric image database. Fourth, targets are detected by the trained network, and corners are detected based onthe detected targets. Finally, pitch lengths and surface braiding angles are measured based on the detected corners.Experimental results show that the proposed method achieves the automatic measurement of pitch lengths and surfacebraiding angles of 2D and 3D braided composite preforms with high accuracy."
CNN 기반 공조 덕트 청소 로봇의 교차점 검출 알고리듬 개발,2020,"['Air Duct', 'Autonomous', 'Convolutional Neural Networks', 'Duct Cleaning', 'Deep Learning']","건물 내부 공기 순환을 위한 공조 덕트는 장기간 사용 시 오염물질이 내부에 쌓여 인력 또는 로봇이 투입되어 청소가 주기적으로 수행된다. 청소는 작업시간과 인건비 문제를 해결하기 위해 최근 원격 조정으로 로봇을 작동시키는 방법이 사용되고 있다. 하지만 완전 자동화가 아니라 인력 의존적이며 청소 시간 단축에도 한계가 있다. 본 연구는 공조덕트 청소 로봇 자율 주행을 위해 교차점 검출 알고리듬 개발에 대한 것이다. 자율 주행은 청소 로봇에 장착된 카메라 영상에서 교차점 검출 알고리듬을 통해 추출된 점과 중심점 사이의 거리 및 각도를 계산하여 로봇을 제어하도록 구성된다. 교차점 검출을 위한 데이터는 3D CAD 프로그램을 이용한 공조 덕트 내부 이미지를 Python을 이용해 교차점 좌표 및 두 경계선 각도를 추출하여 생성했다. 검출 알고리듬은 딥러닝 중 CNN 모델이 학습에 사용됐으며 학습 모델은 입력이미지에서 교차점 정보를 추출하며 학습 모델 정확도는 면적과 거리를 이용해 판단했다. 알고리듬 검증을 위해 청소로봇을 제작했으며 로봇은 몸체, Raspberry Pi, 카메라 및 초음파 센서를 포함한 제어부, 모터와 바퀴를 포함한 구동부로 구성된다. 알고리듬을 탑재한 로봇 청소기 주행 영상을 통해 알고리듬을 검증했다. 향후 공조 덕트뿐만 아니라 에스컬레이터 등 다양한 환경에서 적용 가능할 것으로 기대된다.","Air ducts installed for ventilation inside buildings accumulate contaminants during their service life. Robots are installed to clean the air duct at low cost, but they are still not fully automated and depend on manpower. In this study, an intersection detection algorithm for autonomous driving was applied to an air duct cleaning robot. Autonomous driving of the robot was achieved by calculating the distance and angle between the extracted point and the center point through the intersection detection algorithm from the camera image mounted on the robot. The training data consisted of CAD images of the duct interior as well as the cross-point coordinates and angles between the two boundary lines. The deep learning-based CNN model was applied as a detection algorithm. For training, the cross-point coordinates were obtained from CAD images. The accuracy was determined based on the differences in the actual and predicted areas and distances. A cleaning robot prototype was designed, consisting of a frame, a Raspberry Pi computer, a control unit and a drive unit. The algorithm was validated by video imagery of the robot in operation. The algorithm can be applied to vehicles operating in similar environments."
CNN 모델을 활용한 항공기 ISAR 영상 데이터베이스 구축에 관한 연구,2020,"['NCTR', 'ISAR', 'Deep-learning', 'CNN model', 'Image classification', '비협조적 표적식별', '역합성개구레이다 영상', '딥러닝', 'CNN 모델', '영상 식별']","비협조적 표적식별(NCTR, Non-Cooperative Target Recognition)은 전자정보 등 다른 체계의 지원 없이 레이다 자체적으로 표적을 식별하는 기능을 말한다. 이를 구현하기 위한 대표적인 방법 중 하나인 역합성개구레이다(ISAR) 영상은 표적의 기동 및 위치에 따라 크게 변하기 때문에 기종을 판단할 수 있는 데이터베이스 없이 이를 자동으로 식별하기란 매우 어렵다. 본 연구에서는 실측 영상이 부족한 상황에서도 ISAR 영상 시뮬레이션 및 딥러닝 기법을 활용한 식별 데이터베이스 구축 방안에 대해 논한다. 다양한 레이다 운용 환경에 따라 변화하는 ISAR 영상을 모사하기 위해 ‘완전 산란체’, ‘결손 산란체’, ‘JEM 잡음’으로 명명한 영상 형성 과정을 거쳐 이를 학습하는 모델을 제안한다. 이 모델의 학습 결과를 통해 유사한 형상의 시뮬레이션 영상은 물론 처음 입력된 실측 ISAR 영상도 식별할 수 있음을 확인하였다.","NCTR(Non-Cooperative Target Recognition) refers to the function of radar to identify target on its own without support from other systems such as ELINT(ELectronic INTelligence). ISAR(Inverse Synthetic Aperture Radar) image is one of the representative methods of NCTR, but it is difficult to automatically classify the target without an identification database due to the significant changes in the image depending on the target’s maneuver and location. In this study, we discuss how to build an identification database using simulation and deep-learning technique even when actual images are insufficient. To simulate ISAR images changing with various radar operating environment, A model that generates and learns images through the process named ‘Perfect scattering image,’ ‘Lost scattering image’ and ‘JEM noise added image’ is proposed. And the learning outcomes of this model show that not only simulation images of similar shapes but also actual ISAR images that were first entered can be classified."
이상치 데이터를 고려한 DT-CNN 기반의 전동기 고장 예측,2020,"['Deep learning', 'Open-set recognition', 'DT-CNN', 'Motor fault prediction', 'Machine learning theory']",,"One of the major problems with the existing motor failure prediction system is to assume that all motors with the same fault condition have the same or a similar signal. This is a problem that arises because it is impossible to measure all the countless types of motors and data of driving conditions and failures. It is difficult to implement a general-purpose failure prediction system with an existing system having limited data and limited output. Data that have a large difference because they do not exist in the existing system are called outlier data. In previous studies, the problem arising from the outlier data has not been considered. To solve this problem, a system designed by separating the failure diagnosis model and the failure prediction model is proposed. The diagnostic model of the proposed system can detect data that are not inside big data using a decision-tree convolution neural network (DT-CNN). By using the diagnostic model and the predictive model in series, it is possible to analyze data in a non-measured state more efficiently. Additionally, a method for averaging the outputs of the diagnostic and predictive models is proposed. Through this, the deep learning algorithm can obtain in effect of applying the filter. Furthermore, the average values can be used to confirm the long-term signal change trend. The proposed system improves the problems of the existing failure prediction and enables more practical failure prediction."
Gait Recognition Based on GF-CNN and Metric Learning,2020,"['Convolutional Neural Network', 'Gait Recognition', 'Metric Learning', 'k-Nearest Neighbors']",,"Gait recognition, as a promising biometric, can be used in video-based surveillance and other security systems.However, due to the complexity of leg movement and the difference of external sampling conditions, gaitrecognition still faces many problems to be addressed. In this paper, an improved convolutional neural network(CNN) based on Gabor filter is therefore proposed to achieve gait recognition. Firstly, a gait feature extractionlayer based on Gabor filter is inserted into the traditional CNNs, which is used to extract gait features from gaitsilhouette images. Then, in the process of gait classification, using the output of CNN as input, we utilize metriclearning techniques to calculate distance between two gaits and achieve gait classification by k-nearestneighbors classifiers. Finally, several experiments are conducted on two open-accessed gait datasets anddemonstrate that our method reaches state-of-the-art performances in terms of correct recognition rate on theOULP and CASIA-B datasets."
주의 모듈 기반 Mask R-CNN 경량화 모델을 이용한 도로 환경 내 객체 검출 방법,2020,"['object detection', 'deep convolutional neural networks', 'lightweight model', 'attention module', 'road environment']",,"Object detection plays a crucial role in a self-driving system. With the advances of image recognition based on deep convolutional neural networks, researches on object detection have been actively explored. In this paper, we proposed a lightweight model of the mask R-CNN, which has been most widely used for object detection, to efficiently predict location and shape of various objects on the road environment. Furthermore, feature maps are adaptively re-calibrated to improve the detection performance by applying an attention module to the neural network layer that plays different roles within the mask R-CNN. Various experimental results for real driving scenes demonstrate that the proposed method is able to maintain the high detection performance with significantly reduced network parameters."
Real-time Depth Estimation Using Recurrent CNN with Sparse Depth Cues for SLAM System,2020,"['Deep learning', 'depth estimation', 'geometry recovery', 'SLAM', 'vision based navigation']",,"Depth map has been utilized for refinement of geometric information in a variety of fields such as 3D reconstruction and pose estimation in SLAM system where ill-posed problems are occurred. Currently, as learning-based approaches are successfully introduced throughout many problems of vision-based fields, several depth estimation algorithms based on CNN are suggested, which only conduct training of spatial information. Since an image sequence or video used for SLAM system tends to have temporal information, this paper proposes a recurrent CNN architecture for SLAM system to estimate depth map by exploring not only spatial but also temporal information by using convolutional GRU cell, which is constructed to remember weights of past convolutional layers. Furthermore, this paper proposes using additional layers that preserve structure of scenes by utilizing sparse depth cues obtained from SLAM system. The sparse depth cues are produced by projecting reconstructed 3D map into each camera frame, and the sparse cues help to predict accurate depth map avoiding ambiguity of depth map generation of untrained structures in latent space. Despite accuracy of depth cues according to monocular SLAM system degrades than stereo SLAM system, the proposed masking approach, which takes the confidence of depth cues with regard to a relative camera pose between current frame and previous frame, retains the performance of the proposed system with the proposed adaptive regularization in loss function. In the training phase, by preprocessing exponential quantization of ground-truth depth map to eliminate the ill-effects of the captured large distances, the depth map prediction of the proposed system improves more than other baseline methods with accomplishment of real-time system. We expect that this proposed system can be used in SLAM system to refine geometric information for more accurate 3D reconstruction and pose estimation, which are essential parts for robust navigation system of robots."
콘크리트 균열 탐지를 위한 딥 러닝 기반 CNN 모델 비교,2020,"['균열 탐지', 'ILSVRC', '딥 러닝', 'CNN', '전이 학습', 'Crack Detection', 'Deep Learning', 'Transfer Learning']",,"The purpose of this study is to compare the models of Deep Learning-based Convolution Neural Network(CNN) for concrete crack detection. The comparison models are AlexNet, GoogLeNet, VGG16, VGG19, ResNet-18, ResNet-50, ResNet-101, and SqueezeNet which won ImageNet Large Scale Visual Recognition Challenge(ILSVRC). To train, validate and test these models, we constructed 3000 training data and 12000 validation data with 256×256 pixel resolution consisting of cracked and non-cracked images, and constructed 5 test data with 4160×3120 pixel resolution consisting of concrete images with crack. In order to increase the efficiency of the training, transfer learning was performed by taking the weight from the pre-trained network supported by MATLAB. From the trained network, the validation data is classified into crack image and non-crack image, yielding True Positive (TP), True Negative (TN), False Positive (FP), False Negative (FN), and 6 performance indicators, False Negative Rate (FNR), False Positive Rate (FPR), Error Rate, Recall, Precision, Accuracy were calculated. The test image was scanned twice with a sliding window of 256×256 pixel resolution to classify the cracks, resulting in a crack map. From the comparison of the performance indicators and the crack map, it was concluded that VGG16 and VGG19 were the most suitable for detecting concrete cracks."
CNN 기반 철도차량 차체-대차 연결부의 결함 평가기법 연구,2020,"['Convolutional Neural Network', 'Railway Bogie', 'Damage', 'Weldment', 'Defect']","철도차량의 대차는 열차 주행을 위한 핵심적인 장치이다. 철도차량의 대차에서 피로결함은 운행 중 기대되지 않거나 과도한 하중, 용접결함, 재료 결함 등의 다양한 요인에 의해 발생할 수 있다. 철도차량의 사고를 방지하기 위해서 차체-대차연결부의 손상을 검출하고 발생 결함에 대한 정확한 평가가 요구된다. 이러한 철도차량의 차체-대차 연결부는 초음파 비파괴 검사를 통하여 건전성을 확보하고 있으나 결함 발생에 대한 학습기법을 이용한 판정방법이 필요하다.최근 미세한 결함이나 유사한 결함을 높은 인식율로 검출하기 위하여 딥러닝 기법에 관한 여러 연구가 진행되고 있다. 본 연구에서는 철도차량의 차체-대차 연결부의 결함 검출능력을 위하여 용접부의 인공결함 시편에 대하여 데이터베이스 구축하였으며. 웨지형 초음파 센서를 이용하여 차체-대차 연결부에 대한 비파괴 검사를 수행하였다. 부가적으로 인적 오류를 최소화하기 위하여 결함판단 학습기법인 합성곱 신경망기법(Convolutional Neural Network)을 적용하였다. 그 결과 합성곱 신경망기법 기법을 이용하여 철도차량의 차체-대차 연결 용접부의 균열을 99.98%이상 균열성 결함으로 판별할 수 있었으며 철도차량 차체-대차 연결부의 비파괴검사시 본 연구의 기술이 적용 가능함을 확인할 수 있었다.","The bogies of railway vehicles are one of the most critical components for service. Fatigue defects in the bogie can be initiated for various reasons, such as material imperfection, welding defects, and unpredictable and excessive overloads during operation. To prevent the derailment of a railway vehicle, it is necessary to evaluate and detect the defect of a connection weldment between the car body and bogie accurately. The safety of the bogie weldment was checked using an ultrasonic test, and it is necessary to determine the occurrence of defects using a learning method. Recently, studies on deep learning have been performed to identify defects with a high recognition rate with respect to a fine and similar defect. In this paper, the databases of weldment specimens with artificial defects were constructed to detect the defect of a bogie weldment. The ultrasonic inspection using the wedge angle was performed to understand the detection ability of fatigue cracks. In addition, the convolutional neural network was applied to minimize human error during the inspection. The results showed that the defects of connection weldment between the car body and bogie could be classified with more than 99.98% accuracy using CNN, and the effectiveness can be verified in the case of an inspection."
CNN 기반의 물고기 탐지 알고리즘 구현,2020,"['Fish Detection', 'Object Tracking', 'Deep Learning', 'Convolutional Neural Networks']",,"Autonomous underwater vehicle makes attracts to many researchers. This paper proposes a convolutional neural network (CNN) based fish detection method. Since there are not enough data sets in the process of training, overfitting problem can be occurred in deep learning. To solve the problem, we apply the dropout algorithm to simplify the model. Experimental result showed that the implemented method is promising, and the effectiveness of identification by dropout approach is highly enhanced."
CNN training for age group prediction in an illumination condition,2020,['Age group predictionCNN trainingAdded illumination condition'],,"CNN models trained with the given training dataset usually appear to show good accuracy in the testing with no added illumination. In this paper, we show that age group prediction in an added illumination condition results in a significant drop in accuracy. Our testing was performed on the color printed test photos captured through camera under office lighting condition. We also show the results of applying several possible training options to alleviate the accuracy drop such as using Grayscale or RGB images, severity of jitters of contrast and brightness on images, and the augmentation of training data."
A CNN Image Classification Analysis for ‘Clean-Coast Detector’ as Tourism Service Distribution,2020,"['Marine Debris', 'Clean Coast Detector', 'Convolution Neural Network', 'Tourism Application', 'Environmental Management']",,"Purpose: This study is to analyze the image classification using Convolution Neural Network and Transfer Learning for Jeju Island and to suggest related implications. As the biggest tourist destination in Korea, Jeju Island encounters environmental issues frequently caused by marine debris along the seaside. The ever-increasing volume of plastic waste requires multidirectional management and protection. Research design, data and methodology: In this study, the deep learning CNN algorithm was used to train a number of images from Jeju clean and polluted beaches. In the process of validating and testing pre-processed images, we attempted to explore their applicability to coastal tourism applications through probabilities of classifying images and predicting clean shores. Results: We transformed and augmented 194 small image dataset into 3,880 image data. The results of the pre-trained test set were 85%, 70% and 86%, and then its accuracy has increased through the process. We finally obtained a rapid convergence of 97.73% and 100% (20/20) in the actual training and validation sets. Conclusions: The tested algorithms are expected to implement in applications for tourism service distribution aimed at reducing coastal waste or in CCTVs as a detector or indicator for residents and tourists to protect clean beaches on Jeju Island."
An Accurate Weight Binarization Scheme for CNN Object Detectors with Two Scaling Factors,2020,"['YOLO hardware', 'Binary weight', 'Binarization', 'Quantization', 'Object detector']",,"Recently, convolutional neural network (CNN)-based object detectors such as You Only Look Once (YOLO) have been intensively studied for applications in robotics, drones, and autonomous driving. Although YOLO can run in real time by using a graphics processing unit, the YOLO hardware implementation has received a great deal of interest due to its power efficiency and the potential for massive chip production. However, extensive memory access and high computation complexity are widely known as bottlenecks in YOLO hardware implementation. A common and intuitive approach is to apply quantization, especially binarization, to object detectors. However, the existing binarization methods suffer from substantial degradation in detection performance. To address the problem, this study proposes an accurate weight binarization scheme using two scaling factors. Specifically, a new binary weight optimization problem is formulated, and an analytical solution is derived. Experimental results with well-known PASCAL Visual Object Classes show that the proposed method reduces the detection accuracy degradation by up to 32.18% while meeting the memory and computation requirements of state-of-the-art methods."
뇌신호 주파수 특성을 이용한 CNN 기반 BCI 성능 예측,2020,"['Electroencephalograpy', 'Brain Computer Interface', 'Convolution Neural Network', 'Lasso']",,"In the research of brain computer interface (BCI) technology, one of the big problems encountered is how to deal with some people as called the BCI-illiteracy group who could not control the BCI system. To approach this problem efficiently, we investigated a kind of spectral EEG characteristics in the prior resting state in association with BCI performance in the following BCI tasks. First, spectral powers of EEG signals in the resting state with both eyes-open and eyes-closed conditions were respectively extracted. Second, a convolution neural network (CNN) based binary classifier discriminated the binary motor imagery intention in the BCI task. Both the linear correlation and binary prediction methods confirmed that the spectral EEG characteristics in the prior resting state were highly related to the BCI performance in the following BCI task. Linear regression analysis demonstrated that the relative ratio of the 13 Hz below and above the spectral power in the resting state with only eyes-open, not eyes-closed condition, were significantly correlated with the quantified metrics of the BCI performance (r=0.544). A binary classifier based on the linear regression with L1 regularization method was able to discriminate the high-performance group and low-performance group in the following BCI task by using the spectral-based EEG features in the precedent resting state (AUC=0.817). These results strongly support that the spectral EEG characteristics in the frontal regions during the resting state with eyes-open condition should be used as a good predictor of the following BCI task performance."
Quantitative Metallographic Analysis of GCr15 Microstructure Using Mask R-CNN,2020,"['GCr15', 'Carbide particle', 'Mask R-CNN']",,
Polarized Discourse in Reporting the US Sanctions against Iran on CNN and Press TV News Websites,2020,"['polarization', 'quotation', 'lexicalization', 'news websites', 'CDA', 'ideological square']",,"The purpose of this research is to study the polarized discourse as encoded in the ideological structures of reports by the two Iranian and American news websites: CNN and Press TV. The researcher analyzes online news texts on the US sanctions against Iran from the randomly selected news during a specific period of time. The study of these news reports is implemented in the framework of Critical Discourse Analysis. The ideological characteristics of the polarization are found in the quotation patterns and labeling. Therefore, this research draws an inference at how the two news websites represent a distinction between ‘us’ versus ‘them’ by emphasizing the in-groups and de-emphasizing the out-groups. Moreover, it is proved that the news texts of each website devalue statements by the ‘other’ who is not present and, in this regard, direct quotations are avoided."
딥러닝 CNN 알고리즘 기반의 충격 위치 분석,2020,"['NDT(비파괴 검사)', 'Impact Location(충격 위치)', 'Deep Learning(딥러닝)', 'Structural Health Monitoring(구조 건전성 감시)']","최근 금속 재료 등의 표면에 충격 현상이 발생할 때 충격 위치를 검출할 수 있는 다양한 연구 시도들이 이루어지고 있으며 이러한 시도들 중, 충격 시 발생하는 응력파의 도달 시간 차이를 이용하는 방법은 가장 일반화된 방법이다. 그러나 검사의 정확도를 높이기 위한 정확한 응력파 도달 시간 측정시 많은 어려움이 발생한다. 따라서 본 논문에서는 응력파 신호에서 응력파 도달 시간에 대한 정보를 별도로 추출하지 않고 PZT 센서로 측정한 응력파 신호의 이미지를 직접 딥러닝 기법으로 학습시켜 충격 위치에 따른 응력파의 신호 특성을 찾아내는 시도를 하였다. 이때 딥러닝 학습 변수인 에포크(epoch)의 변화에 따른 측정 정확도를 파악하였고 이를 바탕으로 1m×1m의 알루미늄 평판에서 발생하는 충격의 위치를 찾아낼 수 있는 딥러닝 학습 알고리즘을 제시하였다. 이를 통해, 딥러닝 기법을 활용한 이미지 기반 비파괴 검사 기법을 새롭게 제안하고 이를 성공적으로 검증하였다.","Recently, various studies have attempted to detect the locations of impacts on metal surfaces. The most generalized method uses the time difference between the generation of the stress wave during impact and its arrival at the surface. However, accurate measurement of the arrival time of a stress wave is fraught with difficulties. To address this issue, in this paper, we attempt to identify the signal characteristics of a stress wave corresponding to the impact location by learning the image of the stress wave signal, as measured by a Piezoelectric sensor, via deep learning without directly extracting information about the wave""s arrival time. To improve the accuracy of the measurement used in deep learning, we appropriately optimize the epoch variable and present a deep learning-based algorithm to measure the location of the impact on an aluminum plate of dimensions 1 m × 1 m. As a result, the proposed image-based NDT is successfully verified."
보행 중 주의분산 사고 예방을 위한 합성곱 신경망 기반의 차도와 보도 인식 연구,2020,"['CNN', 'Image Recognition', 'Cautionary Dispersion', 'Smart Device', '합성곱 신경망', '영상 인식', '주의분산', '스마트 기기']","스마트기기의 보급 및 인터넷 발달로 인해 국내 전체 인구 중 90% 이상이 스마트폰을 사용하고 있으며, 이용시간도하루 평균 3시간으로 나타났다. 이와 더불어 보도에서 보행 중 스마트폰과 주변환경에 대한 주의분산으로 인해 61.7%의보행사고가 발생하였다. 본 논문에서는 CNN(Convolution Neural Networks, 합성곱 신경망)을 기반으로 차도와 보도 인식을통해 보행 중 스마트기기 사용으로 인한 주의분산 사고 예방을 위한 차도와 보도 인식 방안을 제시한다. 신경망 구조는 CNN 5-layer와 완전연결계층 2-layer로 구성한다. 학습을 위해 학습데이터 40,000장, 시험데이터 25,000장으로 총 65,000장의 데이터셋을 확보하였고 원활한 학습을 위해 OpenCV로 전처리한다. 학습한결과 98.72%라는 높은 인식률을 보였고, 검증데이터인식률의 경우 99%의 인식률을 보였다",
i-FireNet: 에지 AI 환경에서 실시간 산불감지를 위해 일반화 성능을 향상한 경량형 합성곱 신경망,2020,"['Forest Fire Detection', 'Real-Time', 'Lightweight', 'CNN', 'Edge AI', 'Embedded Deep Learning', '.']",,.
합성곱 신경망 기반의 헬기 기종 분류 모형 연구,2020,"['CNN', 'binary classification', 'types of helicopters', 'Performance results', 'feature map', '.']",,.
경로 추종 시뮬레이티드 운전 차량의 영상 기반 행동 학습을 위한 심층신경망 모델,2020,"['AutoPilot', 'Artificial Neural Network', 'Deep Learning', 'CNN']",,"In this paper, the driving behavior of autonomous driving algorithm is modeled by artificial neural network. Autonomous driving algorithms is determine the best behavior for a destination by entering all the information in the simulator. Thus, the behavior of the autonomous driving algorithm ensures the assumption of the best behavioral decision in each state. In the CARLA autonomous driving simulator, we study the neural network that controls vehicles by applying deep learning. we study the driving behavior of AutoPilot, the autonomous driving algorithm of CARLA simulator, through artificial neural network. We specified a target route for the AutoPilot vehicle and reconstructed the driving data from driving into training data. There are two methods of learning. The first method consists of the position, direction, and driving behavior of the AutoPilot vehicle. In the second method, the neural network learning of the CNN and ANN structure was conducted by constructing the driving image, position, direction, and driving behavior of the vehicle. The artificial neural network selects an action corresponding to each state and drives a path through the selected action. In this study, the experiment analyzed the difference between the driving route of AutoPilot and the driving trajectory of the learned artificial neural network."
결측값을 포함한 센서 스트림에 대한 어텐션 메커니즘 및 합성곱 신경망 기반의 패턴 분류 기법,2020,"['IoT', '스트림 데이터', '딥러닝', '합성곱 신경망', '어텐션 메커니즘', 'IoT', 'Stream Data', 'Deep Learning', 'CNN', 'Attention Mechanism']","다양한 센서로부터 수집된 IoT 스트림 데이터 분석은 대표적인 비선형 분석 문제로, 최근 이러한 문제들의 해결에 합성곱 신경망(Convolutional Neural Network, CNN)을 비롯한 딥러닝 기법들을 다방면으로 적용하고 있다. 또한, IoT 센서 스트림 데이터는 그 수집 과정에서, 센서와 서버 간의 통신 장애 또는 센서의 하드웨어적 결함 등으로 인한 결측값 즉, 손실 데이터를 포함하는 경우가 많으며, 이러한 손실 데이터는 분석의 정확도를 감소시킨다. 한편, 다양한 센서 스트림 데이터 중, 루프 센서를 통해 수집된 교통량 데이터 분석은 도시 계획, 교통 공학, 다양한 교통 및 위치 기반 서비스의 구현 등에 활용된다. 그러나 루프 센서를 통한 교통량 데이터 수집 과정에서 결측값이 발생하는 경우가 많다. 본 논문에서는 이렇게 결측값이 포함된 센서 스트림 데이터의 패턴 분류 정확도를 높이기 위한 기법을 제안한다. 제안하는 기법은 합성곱 신경망 기반의 패턴 분류 모델에 어텐션 메커니즘(Attention Mechanism)을 도입하여 비손실 데이터에 대한 가중치를 부여함으로써 결측값으로 인한 정확도의 손실을 보완한다. 본 논문에서는 결측값의 발생이 잦은 루프 센서 기반의 교통량 데이터를 대상으로 제안하는 패턴 분류 기법을 적용하였고, 제안하는 기법이 결측값을 포함한 센서 스트림 데이터에 대한 패턴 분류 정확도를 향상시킬 수 있음을 실험을 통해 확인하였다.","Analysis for IoT stream data collected from various sensors is a typical non-linear analysis problem, and recently, deep learning techniques including convolutional neural networks have been applied to these problems in various ways. In addition, the IoT sensor stream data often includes missing data, that is, loss data due to a communication failure between the sensor and the server or a hardware defect of the sensor during the collection process, and such loss data reduces the accuracy of analysis. Meanwhile, among the various sensor stream data, the analysis of traffic volume data collected through the loop coil sensor is used for urban planning, traffic engineering, and implementation of various traffic and location-based services. However, during the process of collecting traffic data through the loop coil sensor, missing values ​​are often generated. In this paper, we propose a method to increase the accuracy of pattern classification of sensor stream data containing missing values. The proposed method compensates for the loss of accuracy due to missing values ​​assigning weights to non-loss data by applying attention mechanism to the pattern classification model based on the convolutional neural network. In this paper, the proposed pattern classification method is applied to traffic volume data measured by loop coil sensors that frequently generate missing values, and it was confirmed through experiments that the proposed method can improve the accuracy of pattern classification for sensor stream data including missing values."
시뮬레이티드 자율주행 자동차의 주행행동 학습을 위한 기반 강화학습,2020,"['Self-Driving', 'Driving behavior learning', 'Reinforcement learning', 'DDPG', 'CNN']",,"This paper proposes a self-learning method for autonomous vehicle driving behavior using reinforcement learning without considering the dynamic model of the vehicle. In order to make decision needed for determine the optimal driving behavior (steering, throttle, brake) to achieve a given driving purpose in each state by using state information of the vehicle, such as vehicle movement speed, direction, degree of deviation from the center of the track, and distance to the edge of the track, we propose a method of applying the reinforcement learning by the DDPG structure and further using the driving image to improve driving performance. In this paper, we propose structures of an action decision network(Actor) and an action value evaluation network(Critic) to implement the DDPG learning model. We also propose a prediction model for predict the next state driving image based on the current driving image to improve driving performance in the corner path and a corner classifier for classifying the driving track type. The method proposed in this paper was implemented in a TORCS simulator environment, and the performance of the target driving behavior was evaluated through applying the learning model to driving agent."
인지 무선 통신을 위한 합성곱 신경망 기반 스펙트럼 센싱 기법,2020,[],본 논문에서는 인지 무선 통신을 위한 새로운 합성곱 신경망 기반 스펙트럼 센싱 기법을 제안한다. 제안하는 기법은 주 사용자 신호에 대한 어떠한 사전 정보도 알지 못하는 상황에서 에너지 검출을 통해 주 사용자 신호 유무를 판단한다. 제안하는 기법은 센싱하고자 하는 전체 대역을 고려하여 수신신호를 고속으로 샘플링한다. 이후 신호의 FFT(fast Fourier transform)을 통해 주파수 스펙트럼으로 변환하고 연속적으로 이와 같은 스펙트럼을 쌓아서 2차원 신호를 만든다. 이렇게 만든 2차원 신호를 탐지하고자 하는 채널 대역폭 단위로 자르고 합성곱 신경망에 입력하여 채널이 사용 중인지 비어있는지 판단한다. 판단하고자 하는 분류의 종류가 두 가지이므로 이진 분류 합성곱 신경망을 사용한다. 제안하는 기법의 성능은 컴퓨터 모의실험과 실제 실내환경에서의 실험을 통해 검증하는데 이 결과에 따르면 제안하는 기법은 기존 문턱값 기반 기법보다 2 dB 이상 우수한 성능을 보인다.,
순환 신경망과 합성곱 신경망을 이용한 뉴스 기사 편향도 분석,2020,[],,"While search portals' 'Portal News' account for the largest portion of aggregated news outlet, its neutrality as an outlet is questionable. This is because news aggregation may lead to prejudiced information consumption by recommending biased news articles. In this paper we introduce a new method of measuring political bias of news articles by using deep learning. It can provide its readers with insights on critical thinking. For this method, we build the dataset for deep learning by analyzing articles' bias from keywords, sourced from the National Assembly proceedings, and assigning bias to said keywords. Based on these data, news article bias is calculated by applying deep learning with a combination of Convolution Neural Network and Recurrent Neural Network. Using this method, 95.6% of sentences are correctly distinguished as either conservative or progressive-biased; on the entire article, the accuracy is 46.0%. This enables analyzing any articles' bias between conservative and progressive unlike previous methods that were limited on article subjects."
얼굴 감정인식을 위한 양자화된 경량 합성곱 신경망 구조 연구,2020,"['Face emotion recognition', 'Deep learning', 'Data augmentation', 'Lightweight CNN', 'Quantization']",,
앙상블 딥러닝을 이용한 초음파 영상의 간병변증 분류 알고리즘,2020,"['Deep learning', 'Ensemble Model', 'CNN Model', 'ROC curve', 'Classification']",현재 의료 현장에서 초음파 진단은 과거 청진기와 같다고 할 수 있다. 그러나 초음파의 특성상 검사자의 숙련도에 따라 결과 예측이 불확실하다는 단점을 가진다. 따라서 본 논문에서는 이런 문제를 해결하기 위해 딥러닝 기술을 기반으 로 초음파 검사 중 간병변 탐지의 정확도를 높이고자 한다. 제안 논문에서는 CNN 모델과 앙상블 모델을 이용해 병변 분류의 정확도 비교 실험하였다. 실험결과 CNN 모델에서 분류 정확도는 평균 82.33%에서 앙상블모델의 경우 평균 89.9%로 약 7% 높은 것을 확인하였다. 또한 앙상블 모델이 평균 ROC커브에서도 0.97로 CNN모델보다 약 0.4정도 높은 것을 확인하였다.,"In the current medical field, ultrasound diagnosis can be said to be the same as a stethoscope in the past. However, due to the nature of ultrasound, it has the disadvantage that the prediction of results is uncertain depending on the skill level of the examiner. Therefore, this paper aims to improve the accuracy of liver lesion detection during ultrasound examination based on deep learning technology to solve this problem. In the proposed paper, we compared the accuracy of lesion classification using a CNN model and an ensemble model. As a result of the experiment, it was confirmed that the classification accuracy in the CNN model averaged 82.33% and the ensemble model averaged 89.9%, about 7% higher. Also, it was confirmed that the ensemble model was 0.97 in the average ROC curve, which is about 0.4 higher than the CNN model."
팽창된 잔차 합성곱신경망을 이용한 KOMPSAT-3A 위성영상의 융합 기법,2020,"['Convolutional Neural Network (CNN)', 'Dilated Residual Network', 'KOMPSAT-3A', 'Pansharpening', 'Spatial Correlation Coefficient']","본 논문에서는 CNN (Convolutional Neural Network) 기반의 영상융합 기법을 제안하고자 하였다. 딥러닝 구조의 성능을 향상시키기 위하여, CNN 기법에서 대표적인 합성곱(convolution) 방법으로 알려진 팽창된합성곱(dilated convolution) 모델을 활용하여 모델의 깊이와 복잡성을 증대시키고자 하였다. 팽창된 합성곱을 기반으로 하여 학습과정에서의 효율을 향상시키기 위하여 잔차 네트워크(residual network)도 활용하였다. 또한, 본 연구에서는 모델학습을 위하여 전통적인 L1 노름(norm) 기반의 손실함수와 함께, 공간 상관도를 활용하였다. 본 연구에서는 전정색 영상만을 이용하거나 전정색 영상과 다중분광 영상을 모두 활용하여 구조에 적용한 DRNet을 개발하여 실험을 수행하였다. KOMPSAT-3A를 활용한 전정색 영상과 다중분광 영상을 이용한DRNet은 융합영상의 분광특성에 과적합되는 결과를 나타냈으며, 전정색 영상만을 이용한 DRNet이 기존 기법들과 비교하여 융합영상의 공간적 특성을 효과적으로 반영함을 확인하였다.","In this manuscript, a new pansharpening model based on Convolutional Neural Network (CNN) was developed. Dilated convolution, which is one of the representative convolution technologies in CNN, was applied to the model by making it deep and complex to improve the performance of the deep learning architecture. Based on the dilated convolution, the residual network is used to enhance the efficiency of training process. In addition, we consider the spatial correlation coefficient in the loss function with traditional L1 norm. We experimented with Dilated Residual Networks (DRNet), which is applied to the structure using only a panchromatic (PAN) image and using both a PAN and multispectral (MS) image. In the experiments using KOMPSAT-3A, DRNet using both a PAN and MS image tended to overfit the spectral characteristics, and DRNet using only a PAN image showed a spatial resolution improvement over existing CNN-based models."
해경함정 영상정보에 합성곱신경망을 적용한 국적식별 전문가시스템 구축에 관한 연구,2020,"['Expert System', 'Convolution Neural Network', 'Identification of Coast Guard Ship', 'Maritime Surveillance', '전문가시스템', '합성곱신경망', '해경함정식별', '해상감시']","본 연구는 합성곱신경망(CNN, Convolution Neural Network) 활용하여 한국과 일본의 해경함정 국적 분류를 위한 전문가시스템 구축에 관한 연구이다. 일본과 영유권 갈등을 겪고 있는독도 해역은 군의 감시가 약한 해역으로 일본 해경의 출현이 빈번한 만큼 해상경계를 위한 대책이 필요하다. 현재는 독도 근무자와 출동한 한국 해경함정에서 사람의 육안 또는 무선 교신으로일본 해경함정 여부를 식별하고 있다. 이는 원거리에서 해경함정의 국적을 식별할 수 없는 단점이 있고 대응이 느리다. 따라서 본 연구에서는 이를 보강하기 위해 영상장비에서 얻은 영상정보에 CNN을 적용하여 한국 해경함정과 일본 해경함정을 식별하는 전문가시스템에 대해 연구하였다. 제안하는 전문가시스템은 CNN을 기반으로 구축되었고, 정확도는 훈련 및 검증 데이터에95%이상, 테스트 데이터에 86.25%를 보였다. 본 연구의 결과를 기초로 모델의 성능을 더욱향상시키면 독도 해역에 신속하고 정확한 해상경계의 향상이 있을 것으로 기대된다.","This study is about an expert system for nationality classification of coast guard ship in Korea or Japan using the convolution neural network (CNN). Dokdo Sea area, which is experiencing territorial disputes with Japan, is a sea area where military surveillance is weak, and the appearance of the Japan coast guard ships is frequent, it is necessary to improve maritime surveillance. Currently, dispatched with Dokdo workers, identifies coast guard ship by human or wireless communication.This has the disadvantage of not being able to discern the nationality of coast guard ship from a long distance, and the response is slow. Therefore, in this study, to reinforce this, we applied CNN to the image information obtained from the imaging equipment, and studied the construction of an expert system that identifies coast guard ship belonging to the Korean coast guard and the Japan coast guard.The proposed classification model was built based on CNN, and accuracy was 95% for training and verification data and 86.25% for test data. Based on the results of this study, if the performance of the model is further improved, it is expected that a fast and accurate maritime surveillance will be possible in Dokdo Sea area."
지터에 강건한 딥러닝 기반 프로파일링 부채널 분석 방안,2020,"['Side-Channel Analysis', 'Deep Learning', 'Jitter', 'Global Average Pooling', 'AES']","딥러닝 기반 프로파일링 부채널 분석은 신경망을 이용해 부채널 정보와 중간값의 관계를 파악하는 공격 방법이다. 신경망은 신호의 각 시점을 별도의 차원으로 해석하므로 차원별 가중치를 갖는 신경망은 지터가 있는 데이터의 분포를 학습하기 어렵다. 본 논문에서는 CNN(Convolutional Neural Network)의 완전연결 층을 GAP(Global Average Pooling)로 대체하면 태생적으로 지터에 강건한 신경망을 구성할 수 있음을 보인다. 이를 입증하기 위해 ChipWhisperer-Lite 전력 수집 보드에서 수집한 파형에 대해 실험한 결과 검증 데이터 집합에 대한 완전연결 층을 사용하는 CNN의 정확도는 최대 1.4%에 불과했으나, GAP를 사용하는 CNN의 정확도는 최대 41.7%로 매우 높게 나타났다.","Deep learning-based profiling side-channel analysis is a powerful analysis method that utilizes the neural network to profile the relationship between the side-channel information and the intermediate value. Since the neural network interprets each point of the signal in a different dimension, jitter makes it much hard that the neural network with dimension-wise weights learns the relationship. This paper shows that replacing the fully-connected layer of the traditional CNN (Convolutional Neural Network) with global average pooling (GAP) allows us to design the inherently robust neural network inherently for jitter. We experimented with the ChipWhisperer-Lite board to demonstrate the proposed method: as a result, the validation accuracy of the CNN with a fully-connected layer was only up to 1.4%; contrastively, the validation accuracy of the CNN with GAP was very high at up to 41.7%."
경로 임베딩 기반 지식 그래프 완성 방식,2020,"['knowledge graph completion', 'link prediction', 'path-based reasoning', 'low-dimensional embedding', 'question answering', '지식 그래프 완성', '링크 예측', '경로 기반 추론', '저차원의 임베딩']","지식 그래프는 질의응답 또는 추천시스템과 같은 지능형 시스템을 구성하는데 많이 사용된다. 그러나 지식 그래프에는 대부분의 엔티티들 사이에 관계 링크가 누락되어 있는 문제가 존재한다. 이런 문제를 해결하기 위해 본 논문에서 BLSTM(Bidirectional LSTM) 및 CNN(Convolutional Neural Network)을 결합한 새로운 지식 그래프 완성 방법을 제안한다. 우선, 후보 관계와 두개의 대상 엔티티가 주어지면 BLSTM 및 Convolution 연산을 사용하여 엔티티들을 연결하는 경로들을 저차원 공간으로 임베딩한다. 그리고 어텐션(attention) 모델을 통해 두 개의 엔티티를 표현하는 여러 경로들을 하나의 벡터로 만든다. 벡터와 추론할 후보 관계 사이의 연관성을 통해 후보 관계가 엔티티들과 연결될 수 있는지에 대한 가능성을 예측한다. 제안하는 방법은 CNN을 이용해서 주어진 엔티티들의 관계를 추론하기에 가장 중요한 지역특징(local feature)을 엔티티 사이에 있는 경로에서 추출하고 BLSTM을 이용해서 추출한 지역특징의 순서 관계에 대해 학습한다. 이를 통해 저차원 경로 특징을 효과적으로 학습 하는 것이 가능했으며, 학습된 특징들을 이용해 엔티티 사이의 관계를 예측하였다. 여러 지식 그래프를 대상으로 링크 예측(link prediction) 실험을 진행했으며, 제안하는 방법이 최신 연구 결과보다 높은 성능을 보였다.","Knowledge graphs are widely used in question answering systems. However, in these circumstances most of the relations between the entities in the knowledge graph tend to be missing.To solve this issue, we propose a CNN(Convolutional Neural Network) + BiLSTM(Bidirectional LSTM) based approach to infer missing links in the knowledge graphs. Our method embeds paths connecting two entities into a low-dimensional space via CNN + BiLSTM. Then, an attention operation is used to attentively combine path embeddings to represent two entities. Finally, we measure the similarity between the target relation and representation of the entities to predict whether or not the relation connects those entities. By combining a CNN and BiLSTM, we are able to take advantage of the CNN’s ability to recognize local patterns and the LSTM’s ability to produce entity and relation ordering. In this way, it is possible to effectively identify low-dimensional path features and predict the relationships between entities using the learned features. In our experiments, we performed link prediction tasks on 4 different knowledge graphs and showed that our method achieves comparable results to state-of-the-art methods."
A Sketch-based 3D Object Retrieval Approach for Augmented Reality Models Using Deep Learning,2020,"['Convolutional Neural Network', 'object retrieval', 'Deep Learning', 'Sketch-based 3D object retrieval', 'Augmented Reality']",,"Retrieving a 3D model from a 3D database and augmenting the retrieved model in the Augmented Reality system simultaneously became an issue in developing the plausible AR environments in a convenient fashion. It is considered that the sketch-based 3D object retrieval is an intuitive way for searching 3D objects based on human-drawn sketches as query. In this paper, we propose a novel deep learning based approach of retrieving a sketch-based 3D object as for an Augmented Reality Model. For this work, we introduce a new method which uses Sketch CNN, Wasserstein CNN and Wasserstein center loss for retrieving a sketch-based 3D object. Especially, Wasserstein center loss is used for learning the center of each object category and reducing the Wasserstein distance between center and features of the same category. The proposed 3D object retrieval and augmentation consist of three major steps as follows. Firstly, Wasserstein CNN extracts 2D images taken from various directions of 3D object using CNN, and extracts features of 3D data by computing the Wasserstein barycenters of features of each image. Secondly, the features of the sketch are extracted using a separate Sketch CNN. Finally, we adopt sketch-based object matching method to localize the natural marker of the images to register a 3D virtual object in AR system. Using the detected marker, the retrieved 3D virtual object is augmented in AR system automatically. By the experiments, we prove that the proposed method is efficiency for retrieving and augmenting objects."
네트워크 트래픽 이미지화를 통한 안드로이드 악성코드 탐지,2020,"['CNN(Convolution Neural Network)', 'Android', 'malware', 'classification', 'image', 'CNN(Convolution Neural Network)', '안드로이드', '악성코드', '분류', '이미지화']","안드로이드 운영체제의 점유율이 지난 몇 년간 지속 증가함에 따라 안드로이드 운영체제를 대상으로 하는 악성코드의 수와 변종도 크게 증가하였다. 또한, 악성코드 탐지 솔루션을 회피하기 위한 기술들이 진화를 거듭하면서 기존 시그니쳐 기반 악성코드 탐지기법들은 한계에 직면하고 있다. 이에 본 논문에서는 모바일 네트워크 트래픽 정보의 이미지화를 통하여 CNN을 기반으로 안드로이드 악성코드를 효율적으로 탐지할 수 있는 방안을 제안한다. 제안된 탐지방안을 CICAndMal2017 데이터 셋을 대상으로 실험한 결과, ‘benign’과 ‘malware’ 이진 분류는 모든 성능평가 지표에서 99.9% 이상, 악성코드만을 대상으로 한 다중 클래스 분류에서는 95% 이상, 알려지지 않은 악성코드 카테고리에 대한 이진 분류는 99.9% 이상의 탐지 성능을 확인할 수 있었다.","As the Android OS market share has continued to grow over the past few years, the number and variety of malware targeting Android OS have also increased significantly. Additionally, as various technologies to avoid the detection of anti-malware solutions have evolved continuously, existing signature-based anti-malware solutions face limitations. Thus, this paper proposes an efficient CNN-based Android malware detection scheme through the conversion of mobile network traffic data to images. We evaluated our approach using the CICAndMal2017 datasets. The results showed that our proposed approach can correctly distinguish malware from benign in the case of the binary classification with an F1-Score of 99.97%, a precision of 99.97% and a FPR(false positive rate) of 0.1%.In the case of the multi-class classification and the binary classification for the unknown malware category, all performance assessment metrics were 95% or more and 99.9% or more, respectively."
A Study of Video-Based Abnormal Behavior Recognition Model Using Deep Learning,2020,"['Behavior Recognition', 'Deep Learning', 'CNN-LSTM', '3D CNN', 'I3D']",,"Recently, CCTV installations are rapidly increasing in the public and private sectors to prevent various crimes. In accordance with the increasing number of CCTVs, video-based abnormal behavior detection in control systems is one of the key technologies for safety. This is because it is difficult for the surveillance personnel who control multiple CCTVs to manually monitor all abnormal behaviors in the video. In order to solve this problem, research to recognize abnormal behavior using deep learning is being actively conducted. In this paper, we propose a model for detecting abnormal behavior based on the deep learning model that is currently widely used. Based on the abnormal behavior video data provided by AI Hub, we performed a comparative experiment to detect anomalous behavior through violence learning and fainting in videos using 2D CNN-LSTM, 3D CNN, and I3D models. We hope that the experimental results of this abnormal behavior learning model will be helpful in developing intelligent CCTV."
행동 인식을 위한 시공간 앙상블 기법,2020,"['Action Recognition', '3D CNN', 'Deep Learning']",,"As deep learning technology has been developed and applied to various fields, it is gradually changing from an existing single image based application to a video based application having a time base in order to recognize human behavior. However, unlike 2D CNN in a single image, 3D CNN in a video has a very high amount of computation and parameter increase due to the addition of a time axis, so improving accuracy in action recognition technology is more difficult than in a single image. To solve this problem, we investigate and analyze various techniques to improve performance in 3D CNN-based image recognition without additional training time and parameter increase. We propose a time base ensemble using the time axis that exists only in the videos and an ensemble in the input frame. We have achieved an accuracy improvement of up to 7.1% compared to the existing performance with a combination of techniques. It also revealed the trade-off relationship between computational and accuracy."
A Study of Video-Based Abnormal Behavior Recognition Model Using Deep Learning,2020,"['Behavior Recognition', 'Deep Learning', 'CNN-LSTM', '3D CNN', 'I3D']",,"Recently, CCTV installations are rapidly increasing in the public and private sectors to prevent various crimes. In accordance with the increasing number of CCTVs, video-based abnormal behavior detection in control systems is one of the key technologies for safety. This is because it is difficult for the surveillance personnel who control multiple CCTVs to manually monitor all abnormal behaviors in the video. In order to solve this problem, research to recognize abnormal behavior using deep learning is being actively conducted. In this paper, we propose a model for detecting abnormal behavior based on the deep learning model that is currently widely used. Based on the abnormal behavior video data provided by AI Hub, we performed a comparative experiment to detect anomalous behavior through violence learning and fainting in videos using 2D CNN-LSTM, 3D CNN, and I3D models. We hope that the experimental results of this abnormal behavior learning model will be helpful in developing intelligent CCTV."
"북한 관련 가짜뉴스: 유형, 유통과 대응 방안",2020,"['North Korea', 'fake news', 'type', 'Chosun ilbo', 'CNN', 'government', 'maneuver', 'role', '북한', '가짜뉴스', '유형', '조선일보', 'CNN', '정부', '대응', '역할']","본 연구의 목적은 북한 관련 가짜뉴스의 유형과 유통과정을 분석하고 이로 인해 발생 가능한 국가적 손실을 막기 위한 대응방안을 모색하는 것이다. 연구 시기는 2012년 이후 김정은 정권 시기이다. 연구 방법은 언론보도 등 문헌 분석에 집중한다.북한 관련 가짜뉴스의 유형은 최고지도자의 신변이상형, 로열패밀리 신변이상형, 최고지도자 측근 숙청형, 기타형 등 네 가지이며, 유통과정은생산, 유포, 재생산, 가짜 확인 등 4단계로 진행된다.가짜뉴스의 생산과 소비는 사람의 심리에 기인한다. 북한 관련 가짜뉴스도 사람의 심리를 파고드는 메커니즘이 있다. 가짜뉴스가 국가안보나 경제, 사회 안전 등과 관련될 경우 그 피해는 무차별적이다. 미국의 CNN이‘김정은 위중’을 보도했을 당시 주가는 한때 2.99%로 떨어지고 원-달러환율은 9.2원 급등했다.가짜뉴스 대응에 대해서는 언론의 역할이 크다. 가짜뉴스 미디어의 삼진아웃제와 시민단체와 언학이 함께하는 가짜뉴스 모니터링 도입이 검토되어야 한다. 정치인과 전문가는 가짜뉴스의 생산자가 아니라 가짜뉴스를검증하고 확산을 막아야 할 주체이다. 21대 국회에서는 가짜뉴스를 근절하기 위한 ‘결의안’ 혹은 ‘법률안’ 제정이 있기를 기대한다.","This study analyzes the type and distribution process of fake news related to North Korea, its damage to the nation, and further seeks countermeasures to eliminate fake news. Methodologically, the study analyzes the literature including press reports spanning the era of the Kim Jong Un regime since 2012. Fake news is categorized into four types: news about 1) health or personal danger of the supreme leader, 2) personal danger to the Kim family, 3) purging of the leader’s close aides, and 4) other types. The distribution process of fake news is identified as being carried out in four stages: production, distribution, reproduction, and verification. The production and consumption of fake news relate to human psychology. Such news also attempts to embed itself into people’s minds. If fake news is related to national security, economy, or social safety, the damage can be indiscriminate. For example, when CNN reported that Kim Jong Un’s condition was “critical,” stock prices fell to 2.99 percent at one point and the won-dollar exchange rate soared 9.2 won. The media plays a big role in responding to fake news. Hence, the introduction of a ‘strikeout system’ for perpetrators of fake news and monitoring by civic groups, media, and academia should be considered. Politicians and experts should not be the producers of fake news but those who verify and prevent its spread, and South Korea should consider enacting legislation in its 21st National Assembly as a means to eliminate fake news."
Optimal vibration image size determination for convolutional neural network based fluid-film rotor-bearing system diagnosis,2020,['· Convolutional neural network · Filter size · Fluid-film rotor-bearing system · Hyper-parameter · Image gradient · Optimal image size'],,"This paper suggests an image gradient based method that determines the optimal image size for convolutional neural network (CNN)-based diagnosis of fluid-film rotorbearing systems. As distinct patterns improve the diagnosis performance, a criterion is defined to measure the intensity of patterns in an image. The proposed criterion is derived by segmenting an image by the size of the CNN filter and evaluating each segment through the use of image gradient analysis. Vibration signals from a testbed are used to demonstrate the proposed method. First, the signals are transformed into vibration images by using an omnidirectional regeneration technique. Then, vibration images of four different health states are analyzed using the suggested criterion. The analyzed results are compared to the performance of CNN based diagnosis. The results indicate that the proposed criterion can determine the optimal size range of the vibration image that gives the best performance for CNN-based diagnosis."
합성곱 신경망을 이용한 주가방향 예측 : 상관관계 속성선택 방법을 중심으로,2020,"['합성곱신경망', '주가방향 예측', '머신러닝', '딥러닝', '속성선택', '앙상블', 'Convolutional Neural Network', 'Stock Price Direction Prediction', 'Machine Learning', 'Deep Learning', 'Feature Selection', 'Ensemble']",,"Recently, deep learning has shown high performance in various applications such as pattern analysis and image classification. Especially known as a difficult task in the field of machine learning research, stock market forecasting is an area where the effectiveness of deep learning techniques is being verified by many researchers. This study proposed a deep learning Convolutional Neural Network (CNN) model to predict the direction of stock prices. We then used the feature selection method to improve the performance of the model. We compared the performance of machine learning classifiers against CNN. The classifiers used in this study are as follows: Logistic Regression, Decision Tree, Neural Network, Support Vector Machine, Adaboost, Bagging, and Random Forest. The results of this study confirmed that the CNN showed higher performancecompared with other classifiers in the case of feature selection. The results show that the CNN model effectively predicted the stock price direction by analyzing the embedded values of the financial data"
합성곱 신경망을 이용한 온실 파프리카의 작물 생체중 추정,2020,"['artificial neural network', 'deep learning', 'image processing', 'machine learning', 'plant growth', '기계 학습', '딥 러닝', '식물 생장', '이미지 처리', '인공신경망']","작물의 생체중을 추정하기 위해 다양한 연구가 시도되었지만, 이미지를 활용하여 생체중을 추정한 예는 없었다. 최근 합성곱 신경망을 사용한 이미지 처리 연구가 늘고 있으며, 합성곱 신경망은 미가공 데이터를 그대로 사용할 수 있다. 본 연구에서는 합성곱 신경망을 이용하여 미가공 데이터 상태인 특정시점의 파프리카 이미지를 입력으로 작물의 생체중을 추정하도록 학습하였다. 실험은 파프리카(Capsicum annuum L.)를 재배하는 온실에서 수행하였다. 합성곱 신경망의 출력값인 생체중은 파괴조사를 통해 수집한 데이터를 기반으로 회귀 분석하였다. 학습된 합성곱 신경망의 결정 계수(R<SUP>2</SUP>)의 최고값은 0.95로 나타났다. 생체중 추정값은 실제 측정값과 매우 유사한 경향성을 보여주었다.","Various studies have been attempted to estimate and measure the fresh weight of crops. However, no studies have used raw images of sweet peppers to estimate fresh weight. Recently, image processing research using convolution neural network (CNN) that can use raw data is increasing. In this study, the crop fresh weight was estimated by using the images of sweet peppers as inputs of CNN. The experiment was performed in a greenhouse growing sweet pepper (Capsicum annuum L.). The fresh weight, the output of the CNN, was regressed based on the data collected through destructive investigation. The highest coefficient of determination (R<SUP>2</SUP>) of the trained CNN was 0.95. The estimated fresh weight showed a very similar trend to the actual measured value."
상처와 주름이 있는 지문 판별에 효율적인 심층 학습 비교연구,2020,"['딥러닝', '지문', '생체정보', '2D 합성 곱 신경망', '상처 지문 판별', '주름 지문 판별', 'Deep learning', 'Biometric information', '2D Convolutional Neural Network', 'discriminating of scar fingerprint', 'discriminating of wrinkle fingerprint']","인간의 특성과 관련된 측정 항목을 나타내는 생체정보는 도난이나 분실의 염려가 없으므로 높은 신뢰성을 가진 보안 기술로서큰 주목을 받고 있다. 이러한 생체정보 중 지문은 본인 인증, 신원 파악 등의 분야에 주로 사용된다. 신원을 파악할 때 지문 이미지에인증을 수행하기 어려운 상처, 주름, 습기 등의 문제가 있을 경우, 지문 전문가가 전처리단계를 통해 직접 지문에 어떠한 문제가 있는지 파악하고 문제에 맞는 영상처리 알고리즘을 적용해 문제를 해결한다. 이때 지문에 상처와 주름이 있는 지문 영상을 판별해주는인공지능 소프트웨어를 구현하면 손쉽게 상처나 주름의 여부를 확인할 수 있고, 알맞은 알고리즘을 선정해 쉽게 지문 이미지를 개선할 수 있다. 본 연구에서는 이러한 인공지능 소프트웨어의 개발을 위해 캄보디아 왕립대학교의 학생 1,010명, Sokoto 오픈 데이터셋 600명, 국내 학생 98명의 모든 손가락 지문을 취득해 총 17,080개의 지문 데이터베이스를 구축했다. 구축한 데이터베이스에서 상처나 주름이 있는 경우를 판별하기 위해 기준을 확립하고 전문가의 검증을 거쳐 데이터 어노테이션을 진행했다. 트레이닝 데이터셋과테스트 데이터셋은 캄보디아의 데이터, Sokoto 데이터로 구성하였으며 비율을 8:2로 설정했다. 그리고 국내 학생 98명의 데이터를검증 데이터 셋으로 설정했다, 구성된 데이터셋을 사용해 Classic CNN, AlexNet, VGG-16, Resnet50, Yolo v3 등의 다섯 가지 CNN 기반아키텍처를 구현해 학습을 진행했으며 지문의 상처와 주름 판독에서 가장 좋은 성능을 보이는 모델을 찾는 연구를 수행했다. 다섯가지 아키텍처 중 지문 영상에서 상처와 주름 여부를 가장 잘 판별할 수 있는 아키텍처는 ResNet50으로 검증 결과 81.51%로 가장좋은 성능을 보였다.","Biometric information indicating measurement items related to human characteristics has attracted great attention as security technology with high reliability since there is no fear of theft or loss. Among these biometric information, fingerprints are mainly used in fields such as identity verification and identification. If there is a problem such as a wound, wrinkle, or moisture that is difficult to authenticate to the fingerprint image when identifying the identity, the fingerprint expert can identify the problem with the fingerprint directly through the preprocessing step, and apply the image processing algorithm appropriate to the problem. Solve the problem. In this case, by implementing artificial intelligence software that distinguishes fingerprint images with cuts and wrinkles on the fingerprint, it is easy to check whether there are cuts or wrinkles, and by selecting an appropriate algorithm, the fingerprint image can be easily improved. In this study, we developed a total of 17,080 fingerprint databases by acquiring all finger prints of 1,010 students from the Royal University of Cambodia, 600 Sokoto open data sets, and 98 Korean students. In order to determine if there are any injuries or wrinkles in the built database, criteria were established, and the data were validated by experts. The training and test datasets consisted of Cambodian data and Sokoto data, and the ratio was set to 8: 2. The data of 98 Korean students were set up as a validation data set. Using the constructed data set, five CNN-based architectures such as Classic CNN, AlexNet, VGG-16, Resnet50, and Yolo v3 were implemented. A study was conducted to find the model that performed best on the readings. Among the five architectures, ResNet50 showed the best performance with 81.51%."
합성곱 신경망을 이용한 헬기 피아식별 모형 연구,2020,"['CNN', 'Binary classification', 'Identification model of friend or foe', 'Feature-map', '합성곱 신경망', '이진 분류', '피아식별 모형']","각종 감시체계에서 육안에 의존하여 물체를 식별해내는 것은 어렵고 실수하기 쉬우므로 군 감시체계에서 자동식별능력의 필요성은 더욱 높아지고 있다. 사회에 발표되는 모형들은 군 무기체계에 대한 데이터가 반영되지 않아 군에 바로 적용하는 것은 제한된다. 본 연구는 군용 헬기의 이미지에 합성곱 신경망을 적용하여 피아식별 모형을 구축한 연구이다. 제안하는 모형은 우리나라에서 주로 사용하고 있는 헬기인 AH-64 기종과 공산권 국가에서 주로 사용하고 있는 헬기인 Mi-17 기종의 이미지를 통해 학습시켜 구축되었다. 제안하는 모형의 성능을 살펴보면, 평가척도를 이용하여 평가한 결과 97.8%의 정확도, 97.3%의 정밀도, 98.5% 재현율과 97.9%의 F-measure의 성능을 보임을 확인하였다. 이런 분류결과에 대해서 Feature-map을 통해 아군 헬기의 바퀴와 무장, 그리고 흡기구 주변이, 적군 헬기의 바퀴, 흡기구, 그리고 창문 부위가 피아식별 모형의 분류 기준임을 확인할 수 있었다. 본 연구는 CNN을 이용하여 군 무기체계 중 헬기의 영상정보에 대한 피아식별에 대한 분류를 처음으로 시도한 연구이며, 본 연구에서 제안하는 모형은 기존의 다른 무기체계에 대한 분류 모형보다 높은 정확도를 보인다.","There has been difficulties in identifying objects by relying on the naked eye in various surveillance systems. There is a growing need for automated surveillance systems to replace soldiers in the field of military surveillance operations. Even though the object detection technology is developing rapidly in the civilian domain, but the research applied to the military is insufficient due to a lack of data and interest. Thus, in this paper, we applied one of deep learning algorithms, Convolutional Neural Network-based binary classification to develop an autonomous identification model of both friend and foe helicopters (AH-64, Mi-17) among the military weapon systems, and evaluated the model performance by considering accuracy, precision, recall and F-measure. As the result, the identification model demonstrates 97.8%, 97.3%, 98.5%, and 97.8 for accuracy, precision, recall and F-measure, respectively. In addition, we analyzed the feature map on convolution layers of the identification model in order to check which area of imagery is highly weighted. In general, rotary shaft of rotating wing, wheels, and air-intake on both of ally and foe helicopters played a major role in the performance of the identification model. This is the first study to attempt to classify images of helicopters among military weapons systems using CNN, and the model proposed in this study shows higher accuracy than the existing classification model for other weapons systems."
Compressed Video Restoration Using a Generative Adversarial Network for Subjective Quality Enhancement,2020,"['Deep neural network', 'CNN', 'GAN', 'Compressed video restoration', 'High efficiency video coding']",,"High Efficiency Video Coding (HEVC) is a widely used video compression standard that minimizes the sacrifice in visual quality. Convolutional neural networks (CNNs) are being used as a post-processing tool for video restoration degraded by compression. Improving on CNN-based video restoration, this paper attempts a new generative adversarial network (GAN)-based video restoration called a compressed video restoration generative adversarial network (CVRGAN). Although a GAN is widely used for perceptual image enhancement in super-resolution and noise reduction, it is not yet used for compressed video restoration. The proposed CVRGAN is the first attempt to utilize a GAN to create the texture of a degraded image, and consequently, to generate detailed textures that were lost due to compression. In order to avoid the side effect of a GAN boosting the blocking and ringing artifacts incurred by compression, the CVRGAN employs a new content loss that is a combination of VGG feature difference, which represents a perceptual loss, and an objective loss, such as mean squared error (MSE) or mean absolute error (MAE). The new loss function is effective in the enhancement of subjective image quality while suppressing artifact boosting. An extensive mean opinion score (MOS) test shows that the CVRGAN achieves an improvement in perceptual quality over previous CNN-based video restoration."
딥 러닝 기반의 초해상도 이미지 복원 기법 성능 분석,2020,"['Single image super-resolution', 'Deep learning', 'Wavelet transforms']",,"Convolutional Neural Networks (CNN) have been used extensively in recent times to solve image classification and segmentation problems. However, the use of CNNs in image super-resolution problems remains largely unexploited. Filter interpolation and prediction model methods are the most commonly used algorithms in super-resolution algorithm implementations. The major limitation in the above named methods is that images become totally blurred and a lot of the edge information are lost. In this paper, we analyze super resolution based on CNN and the wavelet transform super resolution method. We compare and analyze the performance according to the number of layers and the training data of the CNN."
작물 생산률 향상을 위한 생장 환경 변화 탐지 CCMS(Crop Classification Management System),2020,"['Agricultural', 'Analysis System', 'Artificial Intelligence System', 'CNN', 'Smart Farm', 'Nelson Rules']","논문에서는 작물의 생산 비율 향상을 위하여 생장 환경 변화를 탐지하는 CCMS(Crop Classification Management System)를 제안한다. CCMS는 첫째, CNN을 이용하여 이미지를 통해 작물의 종류를 구분하는 Crop Classification Module(CCM)과 둘째, 농장의 누적 데이터를 비교하여 농작물의 이상을 탐지하는 FADM(Farm Anomaly Detection Module)로 구성된다. CCMS의 CCM은 잎 이미지를 통하여 현재 농장에서 재배되는 작물을 인식하고 FADM에 전송하고, FADM은 해당 작물을 재배하는 농장의 과거부터 현재까지 기상데이터를 선택하여 그것을 넬슨 규칙에 적용한다. FADM은 넬슨 규칙을 통하여 이상이 발생한 기상데이터를 찾아내고, IoT 디바이스를 통하여 농장의 환경을 조절한다. CCMS의 성능분석 결과 CCMS의 CCM은 약 90%의 작물 분류 정확도를 갖고, FADM은 예측 수확량을 최대 약 30%가량 향상시키는 것으로 나타났다. 즉, CCMS를 통해 농장을 관리하는 것이 스마트 팜의 수확량 증가에 도움을 줄 수 있다.","In this paper, we propose the Crop Classification Management System (CCMS) that detects changes in growth environment to improve crop production rate. The CCMS consists of two modules. First, the Crop Classification Module (CCM) classifies crops through CNN. Second, the Farm Anomaly Detection Module (FADM) detects abnormal crops by comparing accumulated data of farms. The CCM recognizes crops currently grown on farms and sends them to the FADM, and the FADM picks up the weather data from the past to the present day of the farm growing the crops and applies them to the Nelson rules. The FADM uses the Nelson rules to find out weather data that has occurred and adjust farm conditions through IoT devices. The performance analysis of CCMS showed that the CCM had a crop classification accuracy of about 90%, and the FADM improved the estimated yield by up to about 30%. In other words, managing farms through the CCMS can help increase the yield of smart farms."
합성곱 신경망을 이용한 딥러닝 기반의 프레임 동기 기법,2020,['2'],,"This paper proposes a new frame synchronization technique based on convolutional neural network (CNN). The conventional frame synchronizers usually find the matching instance through correlation between the received signal and the preamble. The proposed method converts the 1-dimensional correlator ouput into a 2-dimensional matrix. The 2-dimensional matrix is input to a convolutional neural network, and the convolutional neural network finds the frame arrival time. Specifically, in additive white gaussian noise (AWGN) environments, the received signals are generated with random arrival times and they are used for training data of the CNN. Through computer simulation, the false detection probabilities in various signal-to-noise ratios are investigated and compared between the proposed CNN-based technique and the conventional one. According to the results, the proposed technique shows 2dB better performance than the conventional method."
Detection of Arrhythmia using 1D Convolution Neural Network with LSTM Model,2020,"['Arrhythmia', 'Heartbeat detection', 'Deep learning']",,"Considering the high death rate from cardiovascular diseases, it is important to detect an irregular heart rhythm in order to prevent potential tragedy. The purpose of this paper is to present automatic detection of arrhythmia based on electrocardiography. We suggest a one-dimensional convolutional neural network (1D CNN) with long short-term memory (LSTM). The suggested architecture is compared with two other deep learning methods: the 1D CNN and the multi-layer perceptron (MLP) model. To evaluate performance, we measured the overall accuracy, macroaveraged precision, and macro-averaged recall of our proposed method as being 92.03%, 90.98%, and 86.15%, respectively. The results demonstrate that the 1D CNN-with-LSTM model outperforms the two other models."
A Damage Localization Approach for Rahmen Bridge Based on Convolutional Neural Network,2020,"['Convolutional neural network', 'Damage localization', 'Damage detection', 'Structural health monitoring', 'Deep learning']",,"Damage localization is the process of detecting the location of damage using a structural health monitoring system. However, existing damage localization methods cannot be used for localizing the damage of bridges in real time because of their slow testing speed. Thus, in this study a damage localization approach was developed using a convolutional neural network (CNN). To develop the CNN model for damage localization, simulation data was generated through a numerical model of a reinforced concrete Rahmen bridge with static loading conditions. The proposed CNN-based approach aims to identify 12 single damage locations or no damage. The approach was trained and tested with three different data set generated with three damage severities, and it was possible to estimate the damage location with an accuracy of 87.3% when the damage severity in the bridge is serious. The results showed that the deep learning has the potential to overcome the limitations of existing damage localization techniques."
저연산량의 효율적인 콘볼루션 신경망,2020,"['MobileNet', 'CNN', 'GPU', 'computation complexity', 'Accuracy']","휴대용 기기나 에지 단말을 위한 CNN인 MobileNet V2를 기반으로 연산량을 크게 줄이면서도 정확도는 증가시킨 효율적인 인공신경망 네트워크 구조를 제안한다. 제안하는 구조는 Bottleneck 층 구조를 유지하면서 확장 계수를 증가시키고 일부층을 제거하는 등의 변화를 통해 연산량을 절반 이하로 줄였다. 설계한 네트워크는 ImageNet100 데이터셋을 이용하여 분류정확도와 CPU 및 GPU에서의 연산 시간을 측정하여 그 성능을 검증 하였다. 또한, 현재 딥러닝 가속기로 널리 이용하는GPU에서 네트워크 구조에 따라 동작 성능이 달라짐도 보였다.","We propose an efficient convolutional neural network with much lower computational complexity and higher accuracybased on MobileNet V2 for mobile or edge devices. The proposed network consists of bottleneck layers with largerexpansion factors and adjusted number of channels, and excludes a few layers, and therefore, the computationalcomplexity is reduced by half. The performance the proposed network is verified by measuring the accuracy andexecution times by CPU and GPU using ImageNet100 dataset. In addition, the execution time on GPU depends on theCNN architecture."
Evaluation of Classification and Accuracy in Chest X-ray Images using Deep Learning with Convolution Neural Network,2020,"['딥러닝', '합성곱 신경망 네트워크', '폐렴', '흉부 X-ray', 'Deep Learning', 'CNN', 'Pneumonia', 'Chest X-Ray']","본 연구에서는 CNN과 빅데이터 기술을 이용한 Deep Learning을 통해 흉부 X-ray 영상 분류 및 정확성 연구에 대하여 알아보고자 한다. 총 5,873장의 흉부 X-ray 영상에서 Normal 1,583장, Pneumonia 4,289장을 사용하였다. 데이터 분류는 train(88.8%), validation(0.2%), test(11%)로 분류하였다. Convolution Layer, Max pooling layer pool size 2×2, Flatten layer, Image Data Generator로 구성하였다. Convolution layer가 3일 때와 4일 때 각각 filter 수, filter size, drop out, epoch, batch size, 손실함수 값을 설정하였다. test 데이터로 Convolution layer가 4일 때, filter 수 64-128-128-128, filter size 3×3, drop out 0.25, epoch 5, batch size 15, 손실함수 RMSprop 으로 설정 시 정확도가 94.67%였다. 본 연구를 통해 높은 정확성으로 분류가 가능하였으며, 흉부 X-ray 영상뿐만 아니라 다른 의료영상에서도 많은 도움이 될 것으로 사료된다.","The purpose of this study was learning about chest X-ray image classification and accuracy research through Deep Learning using big data technology with Convolution Neural Network. Normal 1,583 and Pneumonia 4,289 were used in chest X-ray images. The data were classified as train (88.8%), validation (0.2%) and test (11%). Constructed as Convolution Layer, Max pooling layer size 2×2, Flatten layer, and Image Data Generator. The number of filters, filter size, drop out, epoch, batch size, and loss function values were set when the Convolution layer were 3 and 4 respectively. The test data verification results showed that the predicted accuracy was 94.67% when the number of filters was 64-128-128-128, filter size 3×3, drop out 0.25, epoch 5, batch size 15, and loss function RMSprop was 4. In this study, the classification of chest X-ray Normal and Pneumonia was predictable with high accuracy, and it is believed to be of great help not only to chest X-ray images but also to other medical images."
자율주행을 위한 딥러닝 기반의 차선 검출 방법에 관한 연구,2020,"['Deep learning', 'Faster R-CNN', 'Machine learning', 'Support vector machine', 'Unmanned vehicle']",,"This study used the Deep Learning models used in previous studies, we selected the basic model. The selected model was selected as ZFNet among ZFNet, Googlenet and ResNet, and the object was detected using a ZFNet based FRCNN. In order to reduce the detection error rate of FRCNN, location of four types of objects detected inside the image was designed by SVM classifier and location-based filtering was applied. As simulation results, it showed similar performance to the lane marking classification method with conventional 경계 detection, with an average accuracy of about 88.8%. In addition, studies using the Linear-parabolic Model showed a processing speed of 165.65ms with a minimum resolution of 600 × 800, but in this study, the resolution was treated at about 33ms with an input resolution image of 1280 × 960, so it was possible to classify lane marking at a faster rate than the previous study by CNN-based End to End method."
노인코호트 DB를 이용한 딥러닝 기반의 뇌졸중 질환 예측 모델,2020,"['뇌졸중', '질환 예측', '딥러닝', 'CNN', '뇌졸중 심층 분석', 'Stroke', 'Disease Prediction', 'Deep Learning', 'Convolution Neural Network', 'Stroke In-depth Analysis']",,"Stroke is the leading cause of death worldwide after cancer and heart disease. According to a statistical analysis of deaths by Statistics Korea, about 70 deaths occur every day. By 2030, the incidence of stroke disease is expected to surge more than three times due to an aging population. Therefore, research is required to reduce the burden of death and medical expenses and minimize social loss due to stroke disease. In this paper, we designed and implemented a new model that enables CNN-based stroke disease prediction. The model for predicting stroke disease was verified by using data from 558,147 elderly over the age of 60 published by the NHIS(national health insurance service). Through this experiment, we confirmed the accuracy of the model and the prediction of stroke disease for the Korean elderly."
송전철탑 및 전력설비 자동검출을 위한 영상 분석 알고리즘 개발,2020,"['Drone Diagnosis', 'Transmission Towers & Facilities Detection', 'Deep Learning', 'CNN', 'YOLO v2']",,"Over the past few decades the capacity of the power transmission system is growing more and more rapidly, and the power systems have also been expanding in line with continuous expansion of infrastructure. Efficient maintenance of the transmission infrastructure is critical for stable power system operation. However, since the transmission infrastructure is installed at a high location from the ground, the maintenance and diagnosis on transmission towers always involves the possibility of the safety accident of workers.Since 2016, Korea Electric Power Corporation has been developing technologies for monitoring and diagnosis of power lines using drones and has verified the usefulness of technologies through on-site demonstration. 3GBytes of video will be acquired by one flight. And video analysis is performed by below process. A worker finds an image frame that includes a transmission tower and ① power facilities, and expands the area of interest in the image, finally the visually observes the facilities and determines ② ③ whether defects are. These process requires the concentration of the operator and causes very high fatigue. To solve these problems, it is necessary to develop an image analysis algorithm for automatic detection of transmission towers and power facilities to automatically find image frames containing facilities and automatically enlarge the area of interest in the frame to provide diagnosis operator. In this paper describes the process of building a learning and testing image database for detecting transmission towers and facilities carried out for the development of these algorithms and the process of developing algorithms using deep learning CNN-YOLO v2(Convolutional Neural Network - You Only Look Once v2) and the improvement of performance aspects including accuracy and speed with existing algorithms. The recall and precision rate of YOLO v2 for detecting transmission infrastructure is 96.30% and 95.65% respectively, which is more accurate and faster than YOLO v1."
뉴스보도의 현재완료에 대한 연구,2020,"['원거리 직시의 시제', '분포', '뉴스', '현재완료', '근거리 직시의 시제', 'distal deictic tense', 'distribution', 'news', 'present perfect', 'proximal deictic tense']",,"We analyzed the distribution pattern and the tense connection pattern of the present perfect used in news reports, and found the following results. First, in the distribution research, the percentages (CNN: 8.12%, YHN: 8.65%) of the present perfect were higher than those in other genres, confirming that the present perfect is rather frequently used in the news report genre. Second, the present perfect was used not only in the Lead text for introducing hot news, but also in the middle for further explanation and in the end for conclusion. Third, in the research of the tense connection, although the present perfect was linked to various tenses, the present perfect was found to be connected most frequently to a tense specifically corresponding to the GPT (Given Primary Time) of each data set. In the CNN data, the present perfect was most frequently connected to its GPT, the simple present, highlighting on-site communications and immediateness of reporting more appropriately as a proximal deictic tense. In the Yonhap News data, the present perfect was connected most often to its GPT, the simple past, conveying more distance, formality, and objectivity of reporting as a distal deictic tense. Thus, the present perfect seems to be connected most frequently to a specific tense that is pragmatically chosen as GPT according to the reporting strategy of each news agency."
음악 유사도 비교를 위한 Siamese 네트워크 기반 그래프 임베딩의 개선,2020,"['오디오 컨텐츠', '그래프 임베딩', '그래프 콘볼루셔널 네트워크', 'Siamese 네트워크', 'audio content', 'graph embedding', 'graph convolutional network', 'Siamese network']","음악 시장의 성장에 따라 사용자는 일부 음악에 국한되어 노출되고 선택하게 된다. 많은 서비스는 메타데이터로 라이브러리를 구성하여 검색 및 추천 문제에 접근하고 있다. 이때, 새로 나오거나 인지도가 없는 음악의 경우 결과에서 제외될 수 있다. 일반적으로 사용되는 오디오 피처는 해상도에 따른 차원의 변화 폭이 크기 때문에 CNN의 입력으로 사용하기에 어려움이 있다. 본 논문에서는 음악 그래프 피처를 추출하고 임베딩하여 유사도를 비교할 수 있는 모델을 제안한다. 모델은 피처 추출과 Siamese 네트워크로 구성된다. 피처 추출에서는 각 음악 신호를 오디오 피처로 변환하고, 각 음악의 그래프 피처를 구성한다. 이후, Siamese 네트워크에서 각 그래프 피처를 GCN과 어텐션 기법을 활용하여 잠재 공간으로 임베딩하고, NTN을 통해 서로 다른 두 벡터의 유사도를 도출한다. 마지막으로 실험을 통해 음악 신호의 유사도 비교를 위한 오디오 피처의 그래프 피처 추출이 효과적인 방식임을 입증하였다.","As the music market grows, people are exposed to and provided with selective music.Many services use metadata for building music libraries. In this situation, songs from independent labels and new artists that do not have previous information are still excluded from the result of searches and recommendations. In this paper, we focus on making the music scoring model for calculating the similarity score of two music signals. The model comprises the Siamese network and the scoring layer. The Siamese network embeds audios to small latent vectors and passes them to the scoring layer. The audio feature is difficult to use as an input to the CNN because of the dimensionality problem. Our approach is compared to previous works because it retains the sequence information of the peak frequencies in the spectrogram by transforming it into a graph. The effectiveness of the graphical approach is shown as the result of the experiment."
딥러닝을 이용한 평판에서의 과도 전도 열전달에 대한 연구,2020,"['딥러닝', '컨볼루션 신경망', '전도 열전달', '온도 분포', 'Deep learning', 'Convolutional neural network', 'Conduction heat transfer', 'Temperature distribution']",,"The temperature distributions were numerically calculated for the two-dimensional transient conduction heat transfer problem of a square plate. The obtained temperature distributions were converted into colors to create images, and they were provided as learning and test data of CNN. Classification and regression networks were constructed to predict representative wall temperatures through CNN analysis. As results, the classification networks predicted the representative wall temperatures with an accuracy of 99.91% by erroneously predicting only 1 out of 1100 images. The regression networks predicted the representative wall temperatures within errors of C. From this fact, it was confirmed that the deep learning techniques are applicable to the transient conduction heat transfer problems."
SNS감성 분석을 이용한 주가 방향성 예측: 네이버 주식토론방 데이터를 이용하여,2020,"['High-Frequency Financial Data', 'Text Mining', 'Sentimental Analysis', 'Deep Neural Networks', '고빈도 금융 데이터', '텍스트 마이닝', '감성 분석', '딥뉴럴네트워크']","주식의 가격을 이해하고 예측하기 위해서 활용되는 데이터의 범위는 기존의 정형화된 데이터에서 비정형화된 다양한 종류의 데이터로 확대되고 있다. 본 연구는 SNS에서 수집된 댓글 데이터가 주식의 미래 가격의 변동에 영향을 미치는지를 조사한다. 가장 많은 주식투자자가 참여하는 커뮤니티인 네이버 주식토론방에서 20개 종목에 대한 6개월 간의 댓글 데이터를 수집하여, 이들 데이터가 1시간 후의 가격 변동의 방향과 가격 변동의 폭에 대한 예측력을 가지는지 조사한다. 예측 관계는 LSTM과 CNN등의 딥뉴럴네트워크 기법을 활용하여 모델링 하였다. 20개 종목에 대해 조사하여 13개 종목에서 미래의 주가 이동 방향을 50% 이상의 정확도로 예측할 수 있다는 결과를 얻었고, 16개 종목에서 미래의 주가 변동폭을 0% 이상의 정확도로 예측할 수 있다는 결과를 얻었다. 본 연구는 네이버 주식토론방과 같은 SNS에서 형성된 여론이 주식 종목의 수급에 영향을 주어 가격의 변동 요인으로도 작용할 수 있다는 점을 확인한다.","The scope of data for understanding or predicting stock prices has been continuously widened from traditional structured format data to unstructured data. This study investigates whether commentary data collected from SNS may affect future stock prices. From “Stock Discussion Room” in Naver, we collect 20 stocks’ commentary data for six months, and test whether this data have prediction power with respect to one-hour ahead price direction and price range. Deep neural network such as LSTM and CNN methods are employed to model the predictive relationship. Among the 20 stocks, we find that future price direction can be predicted with higher than the accuracy of 50% in 13 stocks. Also, the future price range can be predicted with higher than the accuracy of 50% in 16 stocks. This study validate that the investors’ sentiment reflected in SNS community such as Naver’s “Stock Discussion Room” may affect the demand and supply of stocks, thus driving the stock prices."
생성적 적대 신경망과 딥러닝을 활용한 이상거래탐지 시스템 모형,2020,"['이상거래탐지', '딥러닝', '생성적 적대 신경망', 'Fraud Detection System', 'Deep Neural Net', 'Convolutional Neural Net', 'Generative Adversarial Network']","인공지능이 다루기 어려운 개념에서 아주 익숙한 도구로 자리매김 하고 있다. 이와 더불어 금융권에서도 인공지능 기술을 도입하여 기존 시스템의 문제점을 개선하고자 하는 추세이며, 그 대표적인 예가 이상거래탐지 시스템(Fraud Detection System, FDS)이다. 결제 수단의 다양화 및 전자금융거래의 증가에 따라 치밀해져 가는 사이버 금융사기(Fraud)를 기존의 규칙기반 FDS로는 탐지하기 어려워지고 있다. 이를 극복하기 위해 딥러닝 기술을 적용하여 이상거래 탐지율을 향상시키고, 이상행위에 즉각 대응하며, 탐지 결과의 반영을 자동화하고자 하는 시도가 이루어지고 있다. 딥러닝 FDS 구축에서 핵심 문제는 데이터 불균형과 이상거래 패턴의 변동이다. 본 논문에서는 생성적 적대 신경망(Generative Adversarial Network, GAN)을 활용한 오버샘플링 기법을 통해 데이터 불균형 문제를 개선하고, 이상거래 분류기로써 심층 신경망(Deep Neural Network, DNN)과 합성곱 신경망(Convolutional Neural Network, CNN)을 적용하여 이러한 문제를 개선하고자 하였다. 실험 결과, GAN 오버샘플링이 이상거래 데이터의 불균형 문제를 개선하는데 효과를 보였으며, WGAN이 가장 높은 개선 효과가 있음을 확인하였다. 또한 제안 FDS 모형의 AUC가 0.9857로 랜덤포레스트 FDS 모형에 비해 약 6.5% 향상되어, 딥러닝이 이상거래 탐지에 뛰어난 성능을 가짐을 입증하였다. 더불어 딥러닝 모형 중 DNN은 CNN에 비해 오버샘플링의 효과를 더 잘 반영함을 확인하였다.",
RSU 통신 및 딥러닝 기반 최적화 차량 라우팅 시스템 설계,2020,"['Autonomous vehicles', 'driving directions', 'deep neural networks', 'road side units', 'road information']","현재 자율주행 차량 시장은 3레벨 자율주행 차량의 상용화를 넘어 4레벨 자율주행 차량을 연구, 개발하고 있다. 4레벨 자율주행 차량에서 가장 주목되는 부분은 차량의 안정성이다. 3레벨과 다르게 4레벨의 자율주행 차량은 긴급상황을 차량이 직접 대처해야 하기 때문이다. 본 논문에서는 긴급상황에서의 즉각적인 반응보다는 차량의 목적지가 정해진 순간 사고 가능성이 가장 낮은 경로를 결정하는 Optimized Vehicle Routing System (OVRS)을 제안한다. OVRS는 RSU 통신으로 수집한 도로와 주변 차량 정보를 분석하여 도로의 위험성을 예측하여 주행 중인 차량이 더 안전하고 빠른 길로 주행할 수 있도록 경로를 설정한다. OVRS는 네트워크 라우팅 방식처럼 도로에 있는 RSU를 통하여 도로 상황에 따른 경로 안내를 실행하기 때문에 차량의 안정성을 더욱 높일 수 있다. 실험 결과, OVRS모듈 중 하나인 ASICM의 RPNN은 CNN보다 약 17%, LSTM보다 약 40% 더 좋은 연산 시간을 보였다. 그러나 해당 연구가 PC를 이용한 가상환경에서 실행되었기 때문에, VPDM의 사고 가능성을 실제로 검증하지 못했다. 따라서 향후 사고 데이터 수집으로 인한 VPDM의 정확도 높은 실험과 실제 차량 및 RSU에서 실제 도로를 대상으로 한 실험이 진행되어야 한다.","Currently, The autonomous vehicle market is researching and developing four-level autonomous vehicles beyond the commercialization of three-level autonomous vehicles. Because unlike the level 3, the level 4 autonomous vehicle has to deal with an emergency directly, the most important aspect of a four-level autonomous vehicle is its stability. In this paper, we propose an Optimized Vehicle Routing System (OVRS) that determines the route with the lowest probability of an accident at the destination of the vehicle rather than an immediate response in an emergency. The OVRS analyzes road and surrounding vehicle information collected by The RSU communication to predict road hazards, and sets the route for the safer and faster road. The OVRS can improve the stability of the vehicle by executing the route guidance according to the road situation through the RSU on the road like the network routing method. As a result, the RPNN of the ASICM, one of the OVRS modules, was about 17% better than the CNN and 40% better than the LSTM. However, because the study was conducted in a virtual environment using a PC, the possibility of accident of the VPDM was not actually verified. Therefore, in the future, experiments with high accuracy on VPDM due to the collection of accident data and actual roads should be conducted in real vehicles and RSUs."
네트워크 침입 탐지를 위한 데이터의 시각화에 대한 연구,2020,"['Network Intrusion', 'Attact', 'Detection', 'Visualization', 'Convolutional Neural Network']",최근 국가 간 또는 기업 간 첨단 ICT 기술 경쟁이 매우 심화되고 있으며 운영 중인 서버와 네트워크에 대한 다양한 해킹과 공격도 증가하고 있는 추세이다. 이러한 문제를 해결하기 위해 네트워크 침입 탐지 기술은 가장 기본적이며 핵심적인 부분이다. 그러나 현재 사용되고 있는 대부분의 침입탐지 시스템들은 이전에 탐지 되었던 침입 또는 공격 유형을 기반으로 그 특징이 일치하는 침입 또는 공격 데이터에 대해서만 차단하는 구조이다. 이것은 새로운 유형의 침입 또는 공격에 대해 심각한 보안 상의 문제를 일으킬 수 있는 단점을 갖고 있다. 따라서 새로운 유형의 네트워크 침입 또는 공격 데이터의 특징을 정확히 분석하고 추출하는 과정이 필요하다. 본 논문에서는 머신러닝 기반의 악성코드 분류 모델 연구에서 일부 사용되고 있는 데이터의 시각화 방법을 네트워크 침입 또는 공격 데이터를 이미지화 하는데 사용하였다. 또한 데이터의 특징을 선택하고 신뢰성 있는 침입 탐지를 위해 CNN을 사용하여 실험 및 분석을 하였다.,"In recent years, competition for advanced ICT technologies between countries or companies is intensifying, and various hackings and attacks on servers and networks in operation are also increasing. To solve this problem, network intrusion detection technology is the most basic and essential part. However, most of the intrusion detection systems currently in use are structured to block only intrusion or attack data with matching characteristics based on the type of intrusion or attack previously detected. This has the disadvantage of causing serious security problems for new types of intrusions or attacks. In this paper, the visualization method of some data used in machine learning-based malicious code classification model research was used to image network invasion or attack data.Also, the characteristics of the data were selected and experimented and analyzed using CNN for reliable intrusion detection."
딥러닝 알고리즘 기반의 차량번호 인식 프로그램 개발,2020,"['딥러닝', '합성곱 신경망', '앵커박스', '불법주정차', 'Deep Learning', 'Convolution Neural Network', 'Anchor Box', 'Illegal Parking']","최근 도심지 불법주정차 단속업무를 비롯하여 다양한 분야에서 CCTV 영상을 활용한 차량번호 인식에 관한 연구가 진행되고 있다. 본 연구에서는 합성곱 신경망 기반의 딥러닝 알고리즘을 활용하여 차량번호를 인식하는 프로그램을 개발하였다. 주요 연구 성과로서는 SSD 알고리즘을 활용하여 차량 및 번호판 영역을 검출하는 기술을 개발하였으며 학습데이터를 이용하여 훈련한 결과 약 99.5%의 높은 정확도를 확보할 수 있었다. 또한 기하학적 변형, 광학적 변형, 탄성학적 변형을 개선하는 데이터 확장 알고리즘을 개발하여 딥러닝 기반의 차량번호 인식에 활용되는 특징맵을 생성하였다. 그리고 앵커박스 및 딥러닝 기반의 합성곱 신경망 알고리즘을 적용한 결과 차량번호 인식 정확도가 98.5%로 매우 높게 나타남을 알 수 있었다. 본 연구에서는 실시간 차량 모니터링을 비롯하여 통계분석 그리고 차량번호를 실시간으로 인식할 수 있는 프로그램을 개발하였다. 개발한 프로그램을 활용하여 비트 레이트값의 변화에 따른 차량인식 정확도를 비교 평가하였으며, GS 인증을 위한 실험에서도 97% 이상의 높은 정확도를 확보할 수 있었다. 따라서 본 연구에서 개발한 차량번호 인식 프로그램은 불법주정차 단속업무를 비롯하여 체납차량 추적 등 다양한 분야에 활용될 수 있을 것으로 판단된다.","Recently, research has been conducted on the identification of vehicle numbers using CCTV images in various fields including illegal parking control in downtown areas. In this study, we developed a program that recognizes vehicle numbers using deep learning algorithms based on CNN. As a major research achievement, we developed a technology that detects the vehicle and license plate area using the SSD algorithm, and as a result of training using a learning date, a high accuracy of about 99.5% was secured. In addition, by developing a data expansion algorithm that improves geometric deformation, optical deformation, and elastic deformation, a feature map used for deep learning-based vehicle number recognition was generated. And as a result of applying CNN algorithm based on anchor box and deep learning, it was found that the vehicle number recognition accuracy was very high at 98.5%. In this study, we developed a program that can recognize real-time vehicle monitoring, statistical analysis, and vehicle number in real time. By using the developed program, vehicle recognition accuracy according to the change of the bit rate value was compared and evaluated, and in the experiment for GS certification, high accuracy of more than 97% was secured. Therefore, it is judged that the vehicle number recognition program developed in this study can be used in various fields such as illegal parking control and tracking overdue vehicles."
해상 객체 검출 고속 처리를 위한 영상 전처리 알고리즘 설계와 딥러닝 기반의 통합 시스템,2020,"['Ship Detection', 'Deep Learning', 'Image Processing', 'Binarization', 'Horizon Detection', 'Multi Connected-component Labeling', '선박 인식', '딥러닝', '영상 처리', '이진화', '수평선 검출', '다중 연결 요소 라벨링']","해상 객체 인식은 자율운항선박(MASS)의 지능형 보조 시스템으로써, 선장이 육안으로 해상 주변의 충돌 위험성이 있는 부유물을확인하던 정보를 컴퓨터를 통해 자동으로 인식하여 사람이 확인하는 방법과 유사한 정확도로 인지하는 방법을 말한다. 선박 주변의물체를 인식하는 방법으로 기존에는 레이더나 소나와 같은 장치로부터 수집된 정보를 통해 확인하였지만, 인공지능의 기술이 발달하면서 선박 지능형 CCTV를 통해 운항 항로에 있는 다양한 부유물을 인식하는 것이 가능하다. 하지만, 자율 선박의 다양한 요구사항과복잡성 때문에 영상 데이터의 처리속도가 느려지게 된다면 원활한 서비스 지원은 물론 안전성도 보장할 수 없게 된다. 이러한 문제를 해결하고자 본 논문에서는 해상 객체를 검출하는 데 있어 영상 데이터의 연산량을 최소화하여 처리속도를 높이기 위한 연구를진행하였다. 해상 객체 인식의 관심 영역을 확보하기 위해서는 일반적으로 수평선을 찾는데 기존 연구들은 허프 변환 알고리즘을활용하지만 본 논문에서는 속도를 개선하기 위해 이진화 알고리즘을 최적화하여 실제 객체의 위치와 유사한 영역을 찾는 새로운 방법을 제안한다. 또한, 제안하는 방법의 유용성을 증명하기 위해 딥러닝 CNN을 활용하여 해상 객체 인식 시스템을 구현함으로써 알고리즘의 성능을 평가하였다. 제안하는 알고리즘은 기존 방법의 인식 정확도를 유지하면서 약 4배 이상의 빠른 성능을 얻을 수 있었다.","A maritime object detection system is an intelligent assistance system to maritime autonomous surface ship(MASS). It detects automatically floating debris, which has a clash risk with objects in the surrounding water and used to be checked by a captain with a naked eye, at a similar level of accuracy to the human check method. It is used to detect objects around a ship. In the past, they were detected with information gathered from radars or sonar devices. With the development of artificial intelligence technology, intelligent CCTV installed in a ship are used to detect various types of floating debris on the course of sailing. If the speed of processing video data slows down due to the various requirements and complexity of MASS, however, there is no guarantee for safety as well as smooth service support. Trying to solve this issue, this study conducted research on the minimization of computation volumes for video data and the increased speed of data processing to detect maritime objects. Unlike previous studies that used the Hough transform algorithm to find the horizon and secure the areas of interest for the concerned objects, the present study proposed a new method of optimizing a binarization algorithm and finding areas whose locations were similar to actual objects in order to improve the speed. A maritime object detection system was materialized based on deep learning CNN to demonstrate the usefulness of the proposed method and assess the performance of the algorithm. The proposed algorithm performed at a speed that was 4 times faster than the old method while keeping the detection accuracy of the old method."
1b-16b Variable Bit Precision DNN Processor for Emotional HRI System in Mobile Devices,2020,"['Deep learning', 'Deep learning ASIC', 'Deep neural network', 'Emotion recognition', 'Mobile deep learning']",,"We propose an energy-efficient DNN processor with the proposed look-up-table-based processing engine (LPE) and near-zero skipper. A CNN-based facial emotion recognition model and an RNN-based emotional dialogue generation model are integrated for the natural human-robot interaction (HRI) system, and it is evaluated by the proposed processor. LPE supports 1 to 16 bit variable weight bit precision, and it achieves 57.6% and 28.5% lower energy consumption than the conventional multiplier-accumulator (MAC) units in 1-16 bit weight precision. Furthermore, the near-zero skipper reduces 36% of MAC operations and consumes 28% lower energy consumption in facial emotion recognition tasks. Implemented in 65 nm CMOS process, the proposed processor occupies 1784×1784 μm2 areas and dissipates 0.28 mW and 34.4 mW at 1 frame-per-second (fps) and 30 fps facial emotion recognition tasks."
Tracing the origins of rendang and its development,2020,"['Rendang', 'Origins', 'Malay', 'West Sumatra', 'Minangkabau']",,"One of the most Indonesian popular food is rendang. In recent years, the popularity of this food goes upward to foreign countries after CNN’s polling in 2011, and 2017 placed rendang at the first number of the most delicious food in the world. Along this time, rendang is often associated with the culture of Malay and Minangkabau.Nevertheless, this research tries to trace the historicity of rendang and also the possibility of foreign culinary influences which shapes this Minangkabau’s food heritage. By employing the historical method supported with the reading of various primary sources, this article traces the trail of rendang and resulted fact findings related to foreign culinary influences in West Sumatra and also its development in becoming an Indonesian national food."
열화상 이미지를 이용한 배전 설비 검출 및 진단,2020,"['Power distribution supply facility', 'Thermal image', 'Object detection']",,
Synthetic image augmentation with generative adversarial network for enhanced performance in protein classifi cation,2020,['Image enhancement · Generative adversarial network · Protein Image classifi cation · Convolutional neural network · Transfer learning'],,"Proteins are complex macromolecules accountable for the biological processes in the cell. In biomedical research, the imagesof protein are extensively used in medicine. The rate at which these images are produced makes it diffi cult to evaluate themmanually and hence there exists a need to automate the system. The quality of images is still a major issue. In this paper, wepresent the use of diff erent image enhancement techniques that improves the contrast of these images. Besides the qualityof images, the challenge of gathering such datasets in the fi eld of medicine persists. We use generative adversarial networksfor generating synthetic samples to ameliorate the results of CNN. The performance of the synthetic data augmentationwas compared with the classic data augmentation on the classifi cation task, an increase of 2.7% in Macro F1 and 2.64%in Micro F1 score was observed. Our best results were obtained by the pretrained Inception V4 model that gave a fi vefoldcross-validated macro F1 of 0.603. The achieved results are contrasted with the existing work and comparisons show thatthe proposed method outperformed."
움직이는 모양 연산자를 이용한 입술 명령어 인식,2020,"['lip reading', 'lip commands', 'sequential shape descriptor', 'lip motion']",,"Voice-based commands are affected by the surrounding environment or noise. In this paper, we proposed an SSD(sequential shape descriptor) operator that tracks motion by shape rather than the sound of lips and recognizes a given command. To do this, the TCD operator expressing the shape of the lips was used, and their continuous movement was made to recognize commands using the SSD operator. The SSD operator can express the shape of the lips as outlined in the frequency domain, so it can recognize regardless of size, position, and rotation. As a result of experimenting with CNN-based deep learning using five commonly used machine instructions, a high recognition rate of 96.3% was obtained. Therefore, in the case of an environment sensitive to sound, it was confirmed that the recognition using the proposed SSD operator can be used as a sound substitute."
Joint Hierarchical Semantic Clipping and Sentence Extraction for Document Summarization,2020,"['Extractive Summarization', 'Hierarchical Selective Encoding', 'Redundant Information Clipping']",,"Extractive document summarization aims to select a few sentences while preserving its main information on a given document, but the current extractive methods do not consider the sentenceinformation repeat problem especially for news document summarization. In view of the importance and redundancy of news text information,in this paper, we propose a neural extractive summarization approach with joint sentence semantic clipping and selection, which can effectively solve the problem of news text summary sentence repetition. Specifically, a hierarchical selective encoding network is constructed for both sentencelevel and documentlevel document representations, and data containing important information is extracted on news text; a sentence extractor strategy is then adopted for joint scoring and redundant information clipping. This way, our model strikes a balance between important information extraction and redundant information filtering. Experimentalresults on both CNN/Daily Mail dataset and Court Public Opinion News dataset we built are presented to show the effectiveness of our proposed approach in terms of ROUGE metrics, especially for redundant information filtering."
스크린 사용 여부 및 사용 디바이스 감지를 위한 머신러닝 모델 성능 비교,2020,[],,"Long-term use of digital screens in daily life can lead to computer vision syndrome including symptoms such as eye strain, dry eyes, and headaches. To prevent computer vision syndrome, it is important to limit screen usage time and take frequent breaks. There are a variety of applications that can help users know the screen usage time. However, these apps are limited because users see various screens such as desktops, laptops, and tablets as well as smartphone screens. In this paper, we propose and evaluate machine learning-based models that detect the screen device in use using color, IMU and lidar sensor data. Our evaluation shows that neural network-based models show relatively high F1 scores compared to traditional machine learning models. Among neural network-based models, the MLP and CNN-based models have higher scores than the LSTM-based model. The RF model shows the best result among the traditional machine learning models, followed by the SVM model."
협업 계층을 적용한 합성곱 신경망 기반의 이미지 라벨 예측 알고리즘,2020,"['Collaborative Filtering', 'Convolution Neural Network', 'Image Label Prediction']",,"A typical algorithm used for image analysis is the Convolutional Neural Network(CNN). R-CNN, Fast R-CNN, Faster R-CNN, etc. have been studied to improve the performance of the CNN, but they essentially require large amounts of data and high algorithmic complexity., making them inappropriate for small and medium-sized services. Therefore, in this paper, the image label prediction algorithm based on CNN with collaborative layer with low complexity, high accuracy, and small amount of data was proposed. The proposed algorithm was designed to replace the part of the neural network that is performed to predict the final label in the existing deep learning algorithm by implementing collaborative filtering as a layer. It is expected that the proposed algorithm can contribute greatly to small and medium-sized content services that is unsuitable to apply the existing deep learning algorithm with high complexity and high server cost."
딥러닝 기반 치과 의료영상 판독에 대한 문헌 분석,2020,"['Dentistry', 'Dental disease', 'Artificial intelligence', 'Convolutional neural network', 'Object detection', 'Segmentation']",,"This study analyzes the papers, which studied to find the most adequate CNN based algorithms for segmentation, object detection in dentistry. According to our purpose, we created several keywords like “Dental+Object Detection+Neural+Network.” We searched articles in ‘PubMed’, ‘IEEE’, using created 34 keywords. We found 458 papers and excluded under a study-purpose provision. So This paper had categorized those 23 papers by 11 of segmentation of tooth structure with dental filling and FDI numbering, 12 of detecting dental caries, periodontitis, or multiple lesions. To compare the performance of models, we organized the results by DICE/IoU index and accuracy, precision, recall, etc.. Various dataset was used for analyzing. The most common dataset was dental panoramic image, then periapical, CBCT, NILT, and intra-oral image. The algorithms were used according to the purpose. For example, VGG16, 19 was used for object detection algorithms were used according to the purpose. For example, VGG16, 19 was used for object detection, U-Net, and Mask R-CNN used for segmentation by study purpose.For segmentation of teeth, Zhimming Cui(2019), used Mask R-CNN, and the accuracy was 0.9755. Vranck(2020) used ResNet for molar detection(IoU 0.9, precision 0.94, 0.93). To label the tooth numbering according to FDI rule, Tuzoff(2019) and Chen(2019), used Faster R-CNN, VGG16, and Faster R-CNN with DNN. Tuzoff’s index was slightly better than Chen’s. Casalegno(2019) investigated the detection of dental caries by using VGG16. The result was IoU 0.727. To find periodontitis, used VGG16 also, by Prajapaty(2017). And the accuracy was 0.8846. Using the Mask R-CNN, Jader(2018) could separate instances of multiple lesions, accuracy was 0.8846."
"흉부 방사선영상의 좌, 우 반전 발생 여부 컨벌루션 신경망 기반 정확도 평가",2020,"['흉부검사(Chest projection)', '방사선영상(X-ray image)', '방향반전(Orientation reversal)', '규칙기반 시스템(Rule-based system)', '컨벌루션 신경망(Convolutional neural network)']",,"PA(postero-anterior) and AP(antero-posterior) chest projections are the most sought-after types of all kinds of projections. But if a radiological technologist puts wrong information about the position in the computer, the orientation of left and right side of an image would be reversed. In order to solve this problem, we utilized CNN(convolutional neural network) which has recently utilized a lot for studies of medical imaging technology and rule-based system. 70% of 111,622 chest images were used for training, 20% of them were used for testing and 10% of them were used for validation set in the CNN experiment. The same amount of images which were used for testing in the CNN experiment were used in rule-based system. Python 3.7 version and Tensorflow r1.14 were utilized for data environment. As a result, rule-based system had 66% accuracy on evaluating whether the orientation reversal on chest x-ray image. But the CNN had 97.9% accuracy on that. Being overcome limitations by CNN which had been shown on rule-based system and shown the high accuracy can be considered as a meaningful result. If some problems which can occur for tasks of the radiological technologist can be separated by utilizing CNN, It can contribute a lot to optimize workflow."
Autoregressive Model-Based Structural Damage Identification and Localization Using Convolutional Neural Networks,2020,"['Autoregressive model', 'Time series', 'Convolutional neural network', 'Damage identification', 'Damage localization']",,"Traditional autoregressive (AR) model-based damage identification methods construct structural damage sensitive features by trial and error, which are time-consuming, laborious and may lead to poor recognition effect. This study applies convolutional neural networks (CNNs) to quickly and automatically extract high-dimensional features of autoregressive model coefficients (ARMCs). In this research, AR model was utilized to fit the acceleration time series. The input matrices marked with damage location were produced by ARMCs, and then those matrices were sent to the proposed CNN for training. The trained CNN was employed for damage identification and localization. The effectiveness of the proposed method was verified by the damage identification and localization of a three-storied frame structure. The performance of the proposed CNN was compared with multilayer perception (MLP), random forest, and support vector machine (SVM). Meanwhile, the prediction results from different sample types were also discussed. Furthermore, parametric study in relation to the number of accelerometers and ARMCs used is conducted. These analyses demonstrate that the accuracy of CNN tests results reach 100%, 6.67%, 20%, and 25% higher than that of MLP, random forest, and SVM, respectively. Besides, other metrics calculated in this paper (e.g., precision, recall) further indicate that the proposed CNN performs well. The combination of AR and CNN does show excellent performance in damage identification and localization, which seems to be able to resist external excitation changes and accurately identify the multi-location damage and minor damage using limited accelerometers and ARMCs."
신경망의 시계열 특징 추출 기능과 개선된 해석 방안을 활용한 반도체 수율 예측 모델,2020,"['다변량 시계열 분석', '랜덤 포레스트', '반도체 공정', '합성곱 신경망', '해석 모델', 'Convolutional neural network', 'interpretable model', 'multivariate time series analysis', 'random forest', 'semiconductor']",본 논문은 시계열 형태인 다변량 설명변수를 이용하여 분류 예측 모델을 생성하고 해석하는 방안에 관한 것이다. 특히 예측 모델에 영향을 미친 주요 시계열 구간을 파악하는 방법을 소개하였다. 기존에는 시계열 데이터의 특징을 분석가가 직접 추출한 후 모델에 적용하여 예측 성능이 하락하거나 분석 비용이 높다는 문제가 있었다. 대안으로 신경망을 이용하여 특징을 스스로 학습하는 방안이 소개되었으나 결과에 대한 해석이 불가능하여 실용적 활용에 제한이 있었다. 우리는 신경망이 학습을 통해 추출한 각 특징에 대한 중요도를 계산하고 더 나아가 시계열 구간에 대한 중요도를 파악할 수 있도록 모델을 설계하고 해석하였다.,"Yield prediction models serve critical functions in semiconductor manufacturing. Generally, such models require a manual and knowledge-based feature engineering process. The engineered features are limited in use and susceptible to the new changes in production system. This paper focuses on developing a convolutional neural network (CNN) model that can automatically extract important features from multivariate time series data recorded during wafer production. The trained 1D-CNN model could accurately predict yield efficiency and class activation map (CAM) could point out regions of input that have significant influence on a prediction. In addition, the trained CNN model is ensembled with a random forest model to identify important convolution kernels and time series variables. CNN models show 96.1% accuracy in average and the average accuracy is increased by 1.8% when random forest model is trained with the features extracted by CNN model. CAM enables better interpretation of CNN prediction and ensemble method allow extended analyzation of multivariate time series data."
A Feasibility Study on Application of a Deep Convolutional Neural Network for Automatic Rock Type Classification,2020,"['Rock type classification', 'Deep learning', 'ResNet', 'Rock sample image dataset', '암종 분류', '딥러닝', '레즈넷', '암석 샘플 이미지 데이터셋']","암종 분류은 현장의 지질학적 또는 지반공학적 특성 파악을 위해 요구되는 매우 기본적인 행위이나 암석의 성인, 지역, 지질학적 이력 특성에 따라 동일 암종이라 하여도 매우 다양한 형태와 색 조성을 보이므로 깊은 지질학적 학식과 경험 없이는 쉬운 일은 아니다. 또한, 다른 여러 분야의 분류 작업에서 딥러닝 영상처리 기법들이 성공적으로 적용되고 있으며, 지질학적 분류나 평가 분야에서도 딥러닝 기법의 적용에 대한 관심이 증대되고 있다. 따라서, 본 연구에서는 동일 암종임에도 다양한 형태와 색을 갖게 되는 실제 상황을 감안하여, 정확한 자동 암종 분류를 위한 딥러닝 기법의 적용 가능성에 대해 검토하였다. 이러한 기법은 향후에 현장 암종분류 작업을 수행하는 현장 기술자들을 지원할 수 있는 효과적인 툴로 활용 가능할 것이다. 본 연구에서 사용된 딥러닝 알고리즘은 매우 깊은 네트워크 구조로 객체 인식과 분류를 할 수 있는 것으로 잘 알려진 ’ResNet’ 계열의 딥러닝 알고리즘을 사용하였다. 적용된 딥러닝에서는 10개의 암종에 대한 다양한 암석 이미지들을 학습시켰으며, 학습 시키지 않은 암석 이미지들에 대하여 84% 수준 이상의 암종 분류 정확도를 보였다. 본 결과로 부터 다양한 성인과 지질학적 이력을 갖는 다양한 형태와 색의 암석들도 지질 전문가 수준으로 분류해 낼 수 있는 것으로 파악되었다. 나아가 다양한 지역과 현장에서 수집된 암석의 이미지와 지질학자들의 분류 결과가 학습데이터로 지속적으로 누적이 되어 재학습에 반영된다면 암종분류 성능은 자동으로 향상될 것이다.","Rock classification is fundamental discipline of exploring geological and geotechnical features in a site, which, however, may not be easy works because of high diversity of rock shape and color according to its origin, geological history and so on. With the great success of convolutional neural networks (CNN) in many different image-based classification tasks, there has been increasing interest in taking advantage of CNN to classify geological material. In this study, a feasibility of the deep CNN is investigated for automatically and accurately identifying rock types, focusing on the condition of various shapes and colors even in the same rock type. It can be further developed to a mobile application for assisting geologist in classifying rocks in fieldwork. The structure of CNN model used in this study is based on a deep residual neural network (ResNet), which is an ultra-deep CNN using in object detection and classification. The proposed CNN was trained on 10 typical rock types with an overall accuracy of 84% on the test set. The result demonstrates that the proposed approach is not only able to classify rock type using images, but also represents an improvement as taking highly diverse rock image dataset as input."
딥러닝을 이용한 컨베이어 시스템의 배출구 막힘 상태 판단 기술에 관한 연구,2020,"['컨베이어 시스템', '막힘 판단', '딥러닝', 'CNN', 'VGGNet', 'ResNet', 'DenseNet', 'NASNet', 'Conveyor Systems', 'Blockage Determination', 'Deep Learning', 'Convolutional Neural Network', 'Visual Geometry Group Network', 'Residual Network', 'Dense Network', 'Neural Architecture Search Network']","본 연구는 컨베이어 시스템에서 딥러닝을 이용한 배출구 막힘 판단 기술에 대하여 제안한다.제안 방법은 산업 현장의 CCTV에서 수집한 영상을 이용하여 배출구 막힘 판단을 위한 다양한CNN 모델들을 학습시키고, 성능이 가장 좋은 모델을 사용하여 실제 공정에 적용하는 것을 목적으로 한다. CNN 모델로는 잘 알려진 VGGNet, ResNet, DenseNet, 그리고 NASNet을 사용하였으며, 모델 학습과 성능 테스트를 위하여 CCTV에서 수집한 18,000장의 영상을 이용하였다. 다양한 모델에 대한 실험 결과, VGGNet은 99.89%의 정확도와 29.05ms의 처리 시간으로 가장 좋은 성능을 보였으며, 이로부터 배출구 막힘 판단 문제에 VGGNet이 가장 적합함을 확인하였다.","This study proposes a technique for the determination of outlet blockage using deep learning in a conveyor system. The proposed method aims to apply the best model to the actual process, where we train various CNN models for the determination of outlet blockage using images collected by CCTV in an industrial scene.We used the well-known CNN model such as VGGNet, ResNet, DenseNet and NASNet, and used 18,000 images collected by CCTV for model training and performance evaluation. As a experiment result with various models, VGGNet showed the best performance with 99.03% accuracy and 29.05ms processing time, and we confirmed that VGGNet is suitable for the determination of outlet blockage."
One Step Measurements of hippocampal Pure Volumes from MRI Data Using an Ensemble Model of 3-D Convolutional Neural Network,2020,"['Hippocampus', 'Pure Volume', 'MRI', '3-D Patch', '3-D CNN', ""Alzheimer's Disease""]",,"The hippocampal volume atrophy is known to be linked with neuro-degenerative disorders and it is also one of the most important early biomarkers for Alzheimer's disease detection. The measurements of hippocampal pure volumes from Magnetic Resonance Imaging (MRI) is a crucial task and state-of-the-art methods require a large amount of time. In addition, the structural brain development is investigated using MRI data, where brain morphometry (e.g. cortical thickness, volume, surface area etc.) study is one of the significant parts of the analysis. In this study, we have proposed a patch-based ensemble model of 3-D convolutional neural network (CNN) to measure the hippocampal pure volume from MRI data. The 3-D patches were extracted from the volumetric MRI scans to train the proposed 3-D CNN models. The trained models are used to construct the ensemble 3-D CNN model and the aggregated model predicts the pure volume in one-step in the test phase. Our approach takes only 5 seconds to estimate the volumes from an MRI scan. The average errors for the proposed ensemble 3-D CNN model are 11.7±8.8 (error%±STD) and 12.5±12.8 (error%±STD) for the left and right hippocampi of 65 test MRI scans, respectively. The quantitative study on the predicted volumes over the ground truth volumes shows that the proposed approach can be used as a proxy"
Robust URL Phishing Detection Based on Deep Learning,2020,"['Phishing Detection', 'Machine Learning', 'Deep Learning', 'Convolutional Neural Network', 'CNN', 'Cyber Security']",,"Phishing websites can have devastating effects on governmental, financial, and social services, as well as on individual privacy. Currently, many phishing detection solutions are evaluated using small datasets and, thus, are prone to sampling issues, such as representing legitimate websites by only high-ranking websites, which could make their evaluation less relevant in practice. Phishing detection solutions which depend only on the URL are attractive, as they can be used in limited systems, such as with firewalls. In this paper, we present a URL-only phishing detection solution based on a convolutional neural network (CNN) model. The proposed CNN takes the URL as the input, rather than using predetermined features such as URL length. For training and evaluation, we have collected over two million URLs in a massive URL phishing detection (MUPD) dataset. We split MUPD into training, validation and testing datasets. The proposed CNN achieves approximately 96% accuracy on the testing dataset; this accuracy is achieved with URL schemes (such as HTTP and HTTPS) removed from the URL. Our proposed solution achieved better accuracy compared to an existing state-of-the-art URL-only model on a published dataset. Finally, the results of our experiment suggest keeping the CNN up-to-date for better results in practice."
랜덤 포레스트와 딥러닝을 이용한 노인환자의 사망률 예측,2020,"['사망률 예측', '합성곱 신경망', '랜덤 포레스트', '자질 선택', '딥러닝', 'Mortality Prediction', 'Convolutional Neural Network', 'Random Forest', 'Feature Selection', 'Deep Learning']",,"We predict the mortality of the elderly patients visiting the emergency department who are over 65 years old using Feed Forward Neural Network (FFNN) and Convolutional Neural Network (CNN) respectively. Medical data consist of 99 features including basic information such as sex, age, temperature, and heart rate as well as past history, various blood tests and culture tests, and etc. Among these, we used random forest to select features by measuring the importance of features in the prediction of mortality. As a result, using the top 80 features with high importance is best in the mortality prediction. The performance of the FFNN and CNN is compared by using the selected features for training each neural network. To train CNN with images, we convert medical data to fixed size images. We acquire better results with CNN than with FFNN. With CNN for mortality prediction, F1 score and the AUC for test data are 56.9 and 92.1 respectively."
Prediction Method of Periodic Limb Movements Based on Deep Learning Using ECG Signal,2020,"['Periodic limb movement disorder', 'Convolutional neural network', 'Deep learning', 'Electrocardiogram']",,"In this study, we demonstrated a novel method to predict a patient with periodic limb movements (PLMs) based on a deep learning model using an electrocardiogram (ECG) signal. A convolutional neural network (CNN) model was used to distinguish between the PLM and control subjects through morphological analysis of an ECG signal. The constructed CNN model consisted of convolutional, pooling, and fully connected layers. For this study, polysomnography (PSG) data that were measured from 14 subjects at the Samsung Medical Center were used. The subjects were divided into control group (4 males, 3 females) and PLM group (4 males, 3 females). To train and evaluate the CNN model, the ECG dataset was collected during the PSG study, and it was normalized and segmented at a duration of 10 s. The training and test sets consisted of 30,324 and 7,582 segments, respectively. The CNN model presented a prediction performance with an F1-score of 100.0% for the test sets. We obtained robust results that demonstrated the possibility of the automatic screening of PLM patients using the CNN model with an ECG signal."
The Impact of Transforming Unstructured Data into Structured Data on a Churn Prediction Model for Loan Customers,2020,"['Churn Prediction Model', 'Text Mining', 'Unstructured Data', 'Voice of Customer', 'Convolutional Neural Network']",,"With various structured data, such as the company size, loan balance, and savings accounts, the voice of customer (VOC), which is text data containing contact history and counseling details was analyzed in this study. To analyze unstructured data, the term frequency-inverse document frequency (TF-IDF) analysis, semantic network analysis, sentiment analysis, and a convolutional neural network (CNN) were implemented. A performance comparison of the models revealed that the predictive model using the CNN provided the best performance with regard to predictive power, followed by the model using the TF-IDF, and then the model using semantic network analysis. In particular, a character-level CNN and a word-level CNN were developed separately, and the character-level CNN exhibited better performance, according to an analysis for the Korean language. Moreover, a systematic selection model for optimal text mining techniques was proposed, suggesting which analytical technique is appropriate for analyzing text data depending on the context. This study also provides evidence that the results of previous studies, indicating that individual customers leave when their loyalty and switching cost are low, are also applicable to corporate customers and suggests that VOC data indicating customers’ needs are very effective for predicting their behavior."
합성곱신경망을 이용한 구조적 텍스처 분석연구,2020,"['Classification', 'CNN', 'Industrial applications', 'Partial image', 'Structural texture']","구조적인 텍스처는 텍스처를 구성하는 기본요소인 텍셀 (texel)이 규칙적으로 반복되는 형태로 정의된다. 구조적 텍스처 분석/인식은 직물류의 자동검사, 금속표면 자동테스트 및 마이크로 이미지의 자동 분석 등, 산업적인 응용이 다양하다. 본 논문에서는 구조적 텍스처 분석을 위한 합성곱신경망 (Convolution Neural Network, CNN) 기반의 시 스템을 제안한다. 제안한 방법은 합성곱신경망이 분류 대상 텍스처들의 구성 요소인 텍셀을 학습한다. 인식 단계에서는 입력되는 텍스처 영상에서 얻은 부분 영상을 이용하여 학습된 합성곱신경망이 텍스처를 인식하다. 실제 구현 및 실험을 통하여 제안된 방법의 우수성을 보인다.","The structural texture is defined as a form which a texel is regularly repeated in the texture. Structural texture analysis/recognition has various industrial applications, such as automatic inspection of textiles, automatic testing of metal surfaces, and automatic analysis of micro images. In this paper, we propose a Convolution Neural Network (CNN) based system for structural texture analysis. The proposed method learns texles, which are components of textures to be classified. Then, this trained CNN recognizes a structural texture using a partial image obtained from input texture. The experiment shows the superiority of the proposed system."
채널 강조와 공간 강조의 결합을 이용한 딥 러닝 기반의 초해상도 방법,2020,"['초해상도', 'CNN', 'Residual Block', 'Channel Attention', 'Spatial Attention', 'Super Resolution', 'CNN', 'Residual Block', 'Channel Attention', 'Spatial Attention']","본 논문은 채널 강조(Channel Attentin)와 공간 강조(Spatial Attention) 방법을 결합한 딥 러닝 기반의 초해상 도 방법을 제안하였다. 초해상도 과정에서 질감, 특징과 같은 주변 픽셀의 변화량이 큰 고주파 성분의 복원이 중요하다. 채널 강조와 공간 강조를 결합한 특징 강조를 이용한 초해상도 방법을 제안하였다. 기존의 CNN(Convolutional Neural Network) 기반의 초해상도 방법은 깊은 네트워크의 학습이 어려우며, 고주파 성분의 강조가 부족하여 윤곽선 이 흐려지거나 왜곡이 발생한다. 문제를 해결하기 위해 스킵-커넥션(Skip Connection)을 적용한 채널 강조와 공간 강조를 결합한 강조 블록과 잔차 블록(Residual Block)을 사용하였다. 방법으로 추출한 강조된 특징 맵을 부-픽셀 컨볼 루션(Sub-pixel Convolution)을 통해 특징맵을 확장하여 초해상도를 진행하였다. 이를 통해 기존의 SRCNN과 비교 하여 약 PSNR는 5%, SSIM은 3% 향상되었으며 VDSR과 비교를 통해 약 PSNR는 2%, SSIM은 1% 향상된 결과를 보였다.","In this paper, we proposed a deep learning based super-resolution method that combines Channel Attention and Spatial Attention feature enhancement methods. It is important to restore high-frequency components, such as texture and features, that have large changes in surrounding pixels during super-resolution processing. We proposed a super-resolution method using feature enhancement that combines Channel Attention and Spatial Attention. The existing CNN (Convolutional Neural Network) based super-resolution method has difficulty in deep network learning and lacks emphasis on high frequency components, resulting in blurry contours and distortion. In order to solve the problem, we used an emphasis block that combines Channel Attention and Spatial Attention to which Skip Connection was applied, and a Residual Block. The emphasized feature map extracted by the method was extended through Sub-pixel Convolution to obtain the super resolution. As a result, about PSNR improved by 5%, SSIM improved by 3% compared with the conventional SRCNN, and by comparison with VDSR, about PSNR improved by 2% and SSIM improved by 1%."
랜덤 변환에 대한 컨볼루션 뉴럴 네트워크를 이용한 특징 추출,2020,"['Image recognition', 'CNN', 'Deep learning', 'MNIST. Image processing']",,"Deep learning methods have been effectively used to provide great improvement in various research fields such as machine learning, image processing and computer vision. One of the most frequently used deep learning methods in image processing is the convolutional neural networks. Compared to the traditional artificial neural networks, convolutional neural networks do not use the predefined kernels, but instead they learn data specific kernels. This property makes them to be used as feature extractors as well. In this study, we compared the quality of CNN features for traditional texture feature extraction methods. Experimental results demonstrate the superiority of the CNN features. Additionally, the recognition process and result of a pioneering CNN on MNIST database are presented."
딥러닝 기법을 이용한 웹 카메라 입력 자동차 번호판 인식,2020,"['자동차 번호판', '딥러닝', 'CNN', 'YOLO', 'Faster R-CNN', 'License Plate', 'Deep Learning', 'CNN', 'YOLO', 'Faster R-CNN']",,
전이학습을 이용한 비전기반 결함 탐지 알고리즘 개발,2020,"['Artificial intelligent', 'Convolutional Neural Network', 'Deep Learning', 'Imbalanced data', 'Surface defect detection', 'Transfer Learning']",,"The Convolutional Neural Network (CNN) has already shown better performance in image classification than human nowadays. This capability gives many potential usages in manufacturing industry. In particular, the development of defect detection based on image classification in products has received much attention from industrial sites. Conventionally, defect detection methods have been developed using rule-based feature extraction. The rule-based method requires specialized knowledge and hard to respond frequent design modification of products quickly. Therefore, the usefulness of feature extraction by rule-based method is limited. To cover this limitation, this paper provides a framework to detect defect using CNN model. This framework can be extended to be a part of smart factory technologies. In the proposed framework, the image preprocessing method is applied to remove noise added by the surrounding environment (lighting, accuracy of machine, etc.) at the time of data collection. The enhancement of defect feature in image and the data augmentation method are also included. For the classification model of defect detection, CNN model is applied and transfer learning is also used. The trained CNN model performs well on real data."
Comparison of Artificial Neural Networks for Low-Power ECG-Classification System,2020,"['ECG', 'ANNs- MLP', 'CNN', 'SNN', 'Low-Power']",,"Electrocardiogram (ECG) classification has become an essential task of modern day wearable devices, and can be used to detect cardiovascular diseases. State-of-the-art Artificial Intelligence (AI)-based ECG classifiers have been designed using various artificial neural networks (ANNs). Despite their high accuracy, ANNs require significant computational resources and power. Herein, three different ANNs have been compared: multilayer perceptron (MLP), convolutional neural network (CNN), and spiking neural network (SNN) only for the ECG classification. The ANN model has been developed in Python and Theano, trained on a central processing unit (CPU) platform, and deployed on a PYNQ-Z2 FPGA board to validate the model using a Jupyter notebook. Meanwhile, the hardware accelerator is designed with Overlay, which is a hardware library on PYNQ. For classification, the MIT-BIH dataset obtained from the Physionet library is used. The resulting ANN system can accurately classify four ECG types: normal, atrial premature contraction, left bundle branch block, and premature ventricular contraction. The performance of the ECG classifier models is evaluated based on accuracy and power. Among the three AI algorithms, the SNN requires the lowest power consumption of 0.226 W on-chip, followed by MLP (1.677 W), and CNN (2.266 W). However, the highest accuracy is achieved by the CNN (95%), followed by MLP (76%) and SNN (90%)."
열화상 카메라를 활용한 딥러닝 기반의 1·3종 차량 분류,2020,"['차종분류', '열화상이미지', '딥러닝', 'CNN', '도로교통량', 'Vehicle classification', 'Thermal image', 'Deep learning', 'CNN', 'Traffic monitoring']",,
VGG16을 활용한 미학습 농작물의 효율적인 질병 진단 모델,2020,"['crop disease', 'convolutional neural network (CNN)', 'VGG16', '작물 질병', '합성곱신경망', 'VGG16']","농작물 질병에 대한 조기 진단은 질병의 확산을 억제하고 농업 생산성을 증대하는 데에 있어 중요한 역할을 하고 있다. 최근 합성곱신경망(convolutional neural network, CNN)과 같은 딥러닝 기법을 활용하여 농작물 잎사귀 이미지 데이터세트를 분석하여 농작물 질병을 진단하는 다수의 연구가 진행되었다. 이와 같은 연구를 통해 농작물 질병을 90% 이상의 정확도로 분류할 수 있지만, 사전 학습된 농작물 질병 외에는 진단할 수 없다는 한계를 갖는다. 본 연구에서는 미학습 농작물에 대해 효율적으로 질병 여부를 진단하는 모델을 제안한다. 이를 위해, 먼저 VGG16을 활용한 농작물 질병 분류기(CDC)를 구축하고 PlantVillage 데이터세트을 통해 학습하였다. 이어 미학습 농작물의 질병 진단이 가능하도록 수정된 질병 분류기(mCDC)의 구축방안을 제안하였다. 실험을 통해 본 연구에서 제안한 수정된 질병 분류기(mCDC)가 미학습 농작물의 질병 진단에 대해 기존 질병 분류기(CDC)보다 높은 성능을 보임을 확인하였다.","Early detection and classification of crop diseases play significant role to help farmers to reduce disease spread and to increase agricultural productivity. Recently, many researchers have used deep learning techniques like convolutional neural network (CNN) classifier for crop disease inspection with dataset of crop leaf images (e.g., PlantVillage dataset). These researches present over 90% of classification accuracy for crop diseases, but they have ability to detect only the pre-trained diseases. This paper proposes an efficient disease inspection CNN model for new crops not used in the pre-trained model. First, we present a benchmark crop disease classifier (CDC) for the crops in PlantVillage dataset using VGG16. Then we build a modified crop disease classifier (mCDC) to inspect diseases for untrained crops. The performance evaluation results show that the proposed model outperforms the benchmark classifier."
딥러닝 기반 교량 구성요소 자동 분류,2020,"['BIM', '교량 구성요소 분류', '딥러닝', 'CNN', 'BIM', 'Bridge component classification', 'Deep Learning', 'CNN']","최근 BIM (Building Information Modeling)이 건설 산업계에서 폭넓게 활용되고 있다. 하지만 과거에 시공이 된 구조물에 경우 대부분 BIM이 구축되어 있지 않다. BIM이 구축되지 않은 구조물의 경우, 카메라로부터 얻은 2D 이미지에 SfM (Structure from Motion) 기법을 활용하면 3D 모델의 점군 데이터(Point cloud)를 생성하고 BIM을 구축할 수 있다. 하지만 이렇게 생성된 점군 데이터는 의미론적 정보가 포함되어 있지 않기 때문에, 수작업으로 구조물의 어떤 요소인지 분류해 주어야 한다. 따라서 본 연구에서는 구조물 구성요소를 분류하는 과정을 자동화하기 위하여 딥러닝을 적용하였다. 딥러닝 네트워크 구축에는 CNN (Convolutional Neural Network) 구조의 Inception-ResNet-v2를 사용하였고, 전이학습을 통하여 교량 구조물의 구성요소를 학습하였다. 개발된 시스템을 검증하기 위하여 수집한 데이터를 이용하여 구성요소를 분류한 결과, 교량의 구성요소를 96.13 %의 정확도로 분류할 수 있었다.","Recently, BIM (Building Information Modeling) are widely being utilized in Construction industry. However, most structures that have been constructed in the past do not have BIM. For structures without BIM, the use of SfM (Structure from Motion) techniques in the 2D image obtained from the camera allows the generation of 3D model point cloud data and BIM to be established. However, since these generated point cloud data do not contain semantic information, it is necessary to manually classify what elements of the structure. Therefore, in this study, deep learning was applied to automate the process of classifying structural components. In the establishment of deep learning network, Inception-ResNet-v2 of CNN (Convolutional Neural Network) structure was used, and the components of bridge structure were learned through transfer learning. As a result of classifying components using the data collected to verify the developed system, the components of the bridge were classified with an accuracy of 96.13 %."
Empirical Comparison of Deep Learning Networks on Backbone Method of Human Pose Estimation,2020,"['Deep learning', 'human pose estimation', 'CNN', 'VGG', 'Resnet']",,"Accurate estimation of human pose relies on backbone method in which its role is to extract feature map. Up to dated, the method of backbone feature extraction is conducted by the plain convolutional neural networks named by CNN and the residual neural networks named by Resnet, both of which have various architectures and performances. The CNN family network such as VGG which is well-known as a multiple stacked hidden layers architecture of deep learning methods, is base and simple while Resnet which is a bottleneck layers architecture yields fewer parameters and outperform. They have achieved inspired results as a backbone network in human pose estimation. However, they were used then followed by different pose estimation networks named by pose parsing module. Therefore, in this paper, we present a comparison between the plain CNN family network (VGG) and bottleneck network (Resnet) as a backbone method in the same pose parsing module. We investigate their performances such as number of parameters, loss score, precision and recall. We experiment them in the bottom-up method of human pose estimation system by adapted the pose parsing module of openpose. Our experimental results show that the backbone method using VGG network outperforms the Resent network with fewer parameter, lower loss score and higher accuracy of precision and recall."
DeepCleanNet: Training Deep Convolutional Neural Network with Extremely Noisy Labels,2020,"['Image Classification', 'Noisy Labels', 'Corrupted Labels', 'CNN.']",,"In recent years, Convolutional Neural Networks (CNNs) have been successfully implemented in different tasks of computer vision. Since CNN models are the representatives of supervised learning algorithms, they demand large amount of data in order to train the classifiers. Thus, obtaining data with correct labels is imperative to attain the state-of-the-art performance of the CNN models. However, labelling datasets is quite tedious and expensive process, therefore real-life datasets often exhibit incorrect labels. Although the issue of poorly labelled datasets has been studied before, we have noticed that the methods are very complex and hard to reproduce. Therefore, in this research work, we propose Deep CleanNet - a considerably simple system that achieves competitive results when compared to the existing methods. We use K-means clustering algorithm for selecting data with correct labels and train the new dataset using a deep CNN model. The technique achieves competitive results in both training and validation stages. We conducted experiments using MNIST database of handwritten digits with 50% corrupted labels and achieved up to 10 and 20% increase in training and validation sets accuracy scores, respectively."
무게중심을 활용한 모션 생성 기술,2020,"['Center of mass', 'Convolutional Neural Network(CNN)', 'Character animation', '무게 중심', 'Convolutional Neural Network(CNN)', '캐릭터 애니메이션']","캐릭터의 자세가 변할 때 마다 캐릭터의 무게 중심(COM) 위치도 변하게 된다. 이 때 무게 중심의 위치 변화는 걷기, 뛰기, 쭈그려 앉기 등 다양한 동작 각각에 대응되는 독자적인 패턴을 가지므로 이를 이용하면 원래 동작의 정보를 알아낼 수 있다. 본논문에서는캐릭터의무게중심의위치변화를토대로동작을예측하는모션생성기법을제안한다.이방법을이용하면무게중심 정보를 통해 원래 동작의 유형에 대한 별도의 label 없이도 다양한 동작을 생성할 수 있다. 그러므로 네트워크의 학습 및실행을 위한 데이터셋을 만들 때 사람의 손을 거칠 필요 없이 전처리를 비롯한 모든 과정을 자동으로 진행할 수 있다. 본 논문에서 제안하는 신경망 모델은 캐릭터의 모션 history 정보와 무게 중심 정보들을 입력 받아 현재 프레임에서의 포즈 정보를출력하며, 연속적인 시계열 모션 데이터를 다루기 위해 1D Convolution을 수행하는 Convolutional Neural Network(CNN)를사용하여 학습되었다. 이 모델을 통해 캐릭터의 동작을 만드는데 무게 중심 정보를 활용하는 것이 유용하다는 것을 보인다.","When a character’s pose changes, its center of mass(COM) also changes. The change of COM has distinctive patterns corresponding to various motion type like walking, running or sitting. Thus the motion type can be predicted by using COM movement. We propose a motion generator that uses character’s center of mass information. This generator can generate various motions without annotated action type labels. Thus dataset for training and running can be generated full-automatically. Our neural network model takes the motion history of the character and its center of mass information as inputs and generate a full-body pose for the current frame, and is trained using Convolutional Neural Network(CNN) performs 1D convolution to deal with time-series motion data.We demonstrate the usefulness of using center of mass information for generating character motions using our method."
드론과 이미지 학습을 이용한 생태계 교란 식물 분포도 구축 방안 연구,2020,"['Invasive alien plant', 'Image learning', 'CNN (Convolution Neural Network)', 'Drone', 'Spatial DBMS (Database Management System)', '생태계 교란 식물', '이미지 학습', 'CNN(Convolution Neural Network)', '드론', '공간 DBMS(Database Management System)']","생태계 교란 식물은 생태적･경제적･공중보건적 피해를 입힌다. 또한 생태계 교란 식물은 번식력이 강하기 때문에 발생 초기에 대응해야 한다. 이에 본 연구에서는 생태계 교란 식물의 발생 초기 대응을 위해 드론과 CNN(Convolution Neural Network) 기반의 이미지 학습 기반 생태계 교란 식물 분포도 구축 체계를 제시하고자 했다. 이러한 체계의 적용 가능성을 검토하기 위해 공간 DBMS(Database Management System)의 활용을 검토했으며, 생태계 교란 식물 중 가시박을 대상으로 실험했다. 실험을 위해 대전 일대 중 가시박이 서식하는 2곳을 선정했으며, 해당지역에 대해 드론을 이용하여 촬영하고 정사영상을 구축했다. 이미지 학습 실험을 수행하기 위해 첫 번째 실험에서는 실험지역 ⓑ에서 촬영한 영상만을 활용한 이미지 학습과 분류 테스트를 진행하였고, 두 번째 실험에서는 실험지역 ⓑ에서 촬영한 영상을 이용한 학습을 수행하고 실험지역 a의 촬영 지역을 대상으로 분류를 수행하였으며, 마지막 실험에서는 실험지역 ⓑ에서 촬영한 영상과 웹상에 있는 가시박 이미지를 이용하여 학습을 수행하고 실험지역 ⓐ를 대상으로 분류를 수행하였다. 분석결과 첫 번째 실험에서는 평균 95%, 두 번째 실험에서는 평균 45%, 마지막 실험에서는 약 61%의 분류 정확도를 보였다. 이러한 실험 결과를 바탕으로 정확도 높은 생태계 교란 식물 분포도를 구축하기 위해서는 다양한 생태계 교란 식물이 포함된 정사영상의 메타테이블을 참조해야 할 것으로 판단된다. 그리고 추후 신규 생태계 교란 식물의 확장성을 고려하여 생태계 교란 식물 검색 대상에 대한 추가적인 정보도 공간 DBMS 기반의 관리 및 다양한 생태계 교란 식물의 자동화된 분류를 수행할 수 있을 것이라 판단되며, 이러한 분석 체계를 활용한다면 생태계 교란 식물의 방제에 큰 도움을 줄 수 있을 것이라 판단된다.","The invasive alien plants that cause ecological, economic, and public health disturbances are highly reproductive and thus must be controlled at the early stage of development. This study is intended to establish the system to construct the invasive alien plant distribution map based on spatial DBMS (Database Management System), obtain ortho-images using drones, classify invasive alien plants using CNN (Convolution Neural Network)-based image learning, and present how to generate the invasive alien plant distribution map using them. We obtained ortho-images by photographing the area where Sicyos angulatus, one of the invasive alien plants, inhabited in two test areas of Daejeon to examine the applicability of this system. In the first experiment, we conducted the image learning and classification using only the images photographed in test area a. In the second experiment, we conducted the image learning using the image photographed in test area a and classified the images photographed in test area b. In the last experiment, we conducted learning using the images photographed in test area a and the imagse of Sicyos angulatus on web sites and classified the image photographed in test area b. The analysis results showed the average classification accuracy of 95%, 45%, and 61% in the first experiment, the second experiment, and the third experiment, respectively. Construction of the distribution map of invasive alien plants requires the metatable of the ortho-images that contain various invasive alien plants. Additional information on the search targets of invasive alien plants in consideration of the expansion of new invasive alien plants can help to manage them with the spatial DBMS and carry out the automated classification of various invasive alien plants and to manage various ecosystem disturbances. Using them in the analysis system would help control invasive alien plants."
Object detection technology trend and development direction using deep learning,2020,"['Deep-learning', 'Object-detection', 'Image processing', 'Classification', 'Computer vision']",,"Object detection is an important field of computer vision and is applied to applications such as security, autonomous driving, and face recognition. Recently, as the application of artificial intelligence technology including deep learning has been applied in various fields, it has become a more powerful tool that can learn meaningful high-level, deeper features, solving difficult problems that have not been solved. Therefore, deep learning techniques are also being studied in the field of object detection, and algorithms with excellent performance are being introduced. In this paper, a deep learning-based object detection algorithm used to detect multiple objects in an image is investigated, and future development directions are presented."
딥러닝 알고리즘을 이용한 토마토에서 발생하는 여러가지 병해충의 탐지와 식별에 대한 웹응용 플렛폼의 구축,2020,"['Agricultural Tomato Images', 'Plant Diseases and Pests', 'Deep Learning Algorithm', 'Faster R-CNN', 'Convolution Neural Network', 'Web Application Platform']",,"Purpose: purpose of this study was to propose the web application platform which can be to detect and discriminate various diseases and pest of tomato plant based on the large amount of disease image data observed in the facility or the open field.Methods: The deep learning algorithms uesed at the web applivation platform are consisted as the combining form of Faster R-CNN with the pre-trained convolution neural network (CNN) models such as SSD_mobilenet v1, Inception v2, Resnet50 and Resnet101 models. To evaluate the superiority of the newly proposed web application platform, we collected 850 images of four diseases such as Bacterial cankers, Late blight, Leaf miners, and Powdery mildew that occur the most frequent in tomato plants. Of these, 750 were used to learn the algorithm, and the remaining 100 images were used to evaluate the algorithm.Results: From the experiments, the deep learning algorithm combining Faster R-CNN with SSD_mobilnet v1, Inception v2, Resnet50, and Restnet101 showed detection accuracy of 31.0%, 87.7%, 84.4%, and 90.8% respectively. Finally, we constructed a web application platform that can detect and discriminate various tomato deseases using best deep learning algorithm. If farmers uploaded image captured by their digital cameras such as smart phone camera or DSLR (Digital Single Lens Reflex) camera, then they can receive an information for detection, identification and disease control about captured tomato disease through the proposed web application platform.Conclusion: Incheon Port needs to act actively paying"
지능형 감시 정찰 시스템 구축을 위한 OpenPose와 Deep Learning 기술 적용방안 연구,2020,"['OpenPose', 'keypoints', 'deep neural networks', 'convolutional neural networks', 'long short-term memory', '오픈포즈', '키포인트', '심층 신경망', '합성곱 신경망', '장단기 기억 신경망']","본 연구에서는 국방 감시 정찰 시스템을 OpenPose와 DNN(Deep Neural Networks), CNN(Convolutional Neural Networks), LSTM(Long Short-Term Memory)과 같은 딥러닝 네트워크를 통해 구현하였다. 본 연구의 시스템은 기존의 감시 정찰 시스템과는 다른 방식의 거동수상자(target) 인식 방법을 제안하고 있으며, 제안하는 방법은 촬영되는 영상에서 사람들의 모션을 분류함으로써 일반인과 거동수상자를 구분하는 것이다. 이를 위해 OpenPose를 통해 영상 내의 대상의 skeleton 데이터를 추출한다. 이때, 추출되는 skeleton 데이터에 포함되는 keypoints를 DNN, CNN, LSTM에 입력하여 모션을 분류하게 된다. 분류되는 모션들은 사주경계와 같이 군에서 배울 수 있는 모션으로 선정하였다. 시스템이 모션을 분류하여 거동수상자를 인식하게 되면 지도에 이를 표시하고 추적을 한다. 추적 알고리즘에서는 프레임별로 OpenPose를 통해 추출된 keypoints 값의 변화를 계산하여 거동수상자의 이동방향을 계산하고 카메라에서 얻은 depth 정보를 활용하여 카메라 위치를 기반으로 거동수상자를 지도에 표시하도록 한다. 이와 같은 모든 연산은 전체 이미지가 아닌 skeleton 데이터를 활용하였기 때문에 전체적인 연산량을 감소시킬 수 있게 된다.","In this study, defense surveillance reconnaissance systems were implemented through deep learning networks such as OpenPose and deep neural networks (DNN), convolutional neural networks (CNN), and long short-term memory (LSTM). This study proposes a target recognition method which differs from the existing surveillance reconnaissance systems. This method consists in distinguishing between ordinary people and targets by classifying motions in the images being filmed. Thus, the skeleton data of the target in the image are extracted using OpenPose. Then, keypoints included in the extracted skeleton data are entered into DNN, CNN, and LSTM to classify the motion. The classified motions are selected as motions learned in the military, such as overall security. When the system classifies motions and recognizes targets, it identifies them on the map and tracks them. The tracking algorithm calculates the movement direction of the target by calculating the change in the values of keypoints extracted through OpenPose by frames. Finally, it uses the depth information obtained from the camera to display targets on the map based on the camera location. All these computations are based on the use of the skeleton data rather than the entire image, thus reducing the overall computation."
Curve Number 및 Convolution Neural Network를 이용한 유출모형의 적용성 평가,2020,[],,"Despite the various artificial neural networks that have been developed, most of the discharge models in previous studies have been developed using deep neural networks. This study aimed to develop a discharge model using a convolution neural network (CNN), which was used to solve classification problems. Furthermore, the applicability of CNN was evaluated. The photographs (pictures or images) for input data to CNN could not clearly show the characteristics of the study area as well as precipitation. Hence, the model employed in this study had to use numerical images. To solve the problem, the CN of NRCS was used to generate images as input data for the model. The generated images showed a good possibility of applicability as input data. Moreover, a new application of CN, which had been used only for discharge prediction, was proposed in this study. As a result of CNN training, the model was trained and generalized stably. Comparison between the actual and predicted values had an R<sup>2</sup> of 0.79, which was relatively high. The model showed good performance in terms of the Pearson correlation coefficient (0.84), the Nash-Sutcliffe efficiency (NSE) (0.63), and the root mean square error (24.54 ㎥/s)."
EER-ASSL: Combining Rollback Learning and Deep Learning for Rapid Adaptive Object Detection,2020,"['Object Detection', 'Active Learning', 'Semi-Supervised Learning', 'Convolutional Neural Network']",,"We propose a rapid adaptive learning framework for streaming object detection, called EER-ASSL. The method combines the expected error reduction (EER) dependent rollback learning and the active semi-supervised learning (ASSL) for a rapid adaptive CNN detector. Most CNN object detectors are built on the assumption of static data distribution. However, images are often noisy and biased, and the data distribution is imbalanced in a real world environment. The proposed method consists of collaborative sampling and EER-ASSL. The EER-ASSL utilizes the active learning (AL) and rollback based semi-supervised learning (SSL). The AL allows us to select more informative and representative samples measuring uncertainty and diversity. The SSL divides the selected streaming image samples into the bins and each bin repeatedly transfers the discriminative knowledge of the EER and CNN models to the next bin until convergence and incorporation with the EER rollback learning algorithm is achieved. The EER models provide a rapid short-term myopic adaptation and the CNN models an incremental long-term performance improvement. EER-ASSL can overcome noisy and biased labels in varying data distribution. Extensive experiments shows that EER-ASSL obtained 70.9 mAP compared to state-of-the-art technology such as Faster RCNN, SSD300, and YOLOv2."
영상에서 convolutional denoising autoencoder 모형을 이용한 영상복원,2020,"['convolutional denoising autoencoder (CDAE)', '딥러닝', '영상복원', '잡음영상', 'deep learning', 'image restoration', 'noise reduction']","디지털 영상은 획득, 전송, 처리하는 과정에서 다양한 잡음 (noise)에 의해 훼손되어 이에 따른 영상 복원 (image restoration)의 필요성이 대두되고 있다. 지금까지 영상에서 잡음을 제거하는 방법은 특정분포 하에서 설계된 고유한 필터를 사용하였는데 이 경우 분포의 특성을 만족하지 않는 경우 성능이 현저히 떨어지는 영향이 있다. 본 논문에서는 딥러닝의 convolutional denoising autoencoder (CDAE) 모형을 이용하여 잡음을 제거하고자 한다. CDAE 모형은 CNN (convolutional neural network) 모형과 DAE (denoising autoencoder) 모형의 결합 형태로서 영상의 잡음 분포에 관계없이 적용 가능한 방법이다. 본 논문에서 제안된 CDAE 모형을 평가하기 위해 다양한 잡음 즉, 가우시안 잡음 (gaussian noise), 임펄스 잡음 (impulse noise) 그리고 스펙클 잡음 (speckle noise) 에 의해 훼손된 영상을 고려하였으며, 성능실험결과, CDAE 모형은 기존의 CNN 모형 및 전통적인 필터 즉, Mean 필터, Median 필터 그리고 Lee 필터 보다 좋은 복원 영상을 낳았고 또한, PSNR (peak signal-to-noise ratio)와 MAE (mean absolute error) 면에서 좋은 수치를 보였다.","Digital images have been compromised by various noise in the process of acquisition, transmission and processing, resulting in the need for image restoration. Until now, methods of removing noise from images have used unique filters designed under certain distributions, which tend to be significantly less effective if the characteristics of the distribution are not met. In this paper, we are going to use the convolutional denoising autoencoder (CDAE) model of deep learning to eliminate noise. The CDAE model is a combination of the CNN (convolutional neural network) model and the DAE (denoising autoencoder) model, which is an applicable method regardless of the noise distribution of images. In order to evaluate the CDAE model proposed in this paper, we considered images damaged by various noises, Gaussian noise, impulse noise and speckle noise. We compared our CDAE model with CNN and traditional filters such as Mean filter, Median filter and Lee filter. Experimental results on several images show that the CDAE model yields significantly superior image quality and better PSNR (peak signal-to- noise ratio) and MAE (mean absolute error)."
밀리미터파의 손동작 인식 알고리즘에 관한 연구,2020,"['Millimeter Wave', 'Gesture Recognition', 'K-Means', 'Smoothing', 'Deep Learning']",본 논문에서는 77GHz를 사용하는 밀리미터파 레이더 센서의 반향 신호를 이용하여 손동작의 움직임을 추적한 후 얻어진 데이터로 0부터 9까지의 숫자들을 인식하는 알고리즘을 개발하였다. 손동작을 감지하여 레이더 센서로부터 얻어진 반향 신호들은 산란 단면적의 차이 등에 의해 불규칙한 점들의 군집형태를 보인다. 이들로부터 유효한 중심점을 얻기 위해 3차원 좌푯값들을 이용해 K-Means 알고리즘을 적용하였다. 그리고 얻어진 중심점들을 연결하여 숫자 형태의 이미지를 생성하였다. 얻어진 이미지와 스무딩 기법을 적용해 사람의 손글씨 형태와 유사하게 만든 이미지를 MNIST(Modified National Institute of Standards and Technology database)로 훈련된 CNN(Convolutional Neural Network) 모델에 입력하여 인식률을 비교하였다. 실험은 두 가지 방법으로 진행되었다. 먼저 스무딩 기법을 적용한 이미지와 적용하지 않은 이미지를 사용한 인식 실험에서는 각각 평균 77.0%와 81.0%의 인식률을 얻었다. 그리고 학습데이터를 확장(augmentation)한 CNN 모델의 실험에서는 스무딩 기법을 적용한 이미지와 적용하지 않은 이미지를 사용한 인식 실험에서 각각 평균 97.5%와 평균 99.0%의 인식률을 얻었다. 본 연구는 레이더 센서를 이용한 다양한 비접촉 인식기술에 응용이 가능할 것으로 판단된다.,"In this study, an algorithm that recognizes numbers from 0 to 9 was developed using the data obtained after tracking hand movements using the echo signal of a millimeter-wave radar sensor at 77 GHz. The echo signals obtained from the radar sensor by detecting the motion of a hand gesture revealed a cluster of irregular dots due to the difference in scattering cross-sectional area. A valid center point was obtained from them by applying a K-Means algorithm using 3D coordinate values. In addition, the obtained center points were connected to produce a numeric image. The recognition rate was compared by inputting the obtained image and an image similar to human handwriting by applying the smoothing technique to a CNN (Convolutional Neural Network) model trained with MNIST (Modified National Institute of Standards and Technology database). The experiment was conducted in two ways. First, in the recognition experiments using images with and without smoothing, average recognition rates of 77.0% and 81.0% were obtained, respectively. In the experiment of the CNN model with augmentation of learning data, a recognition rate of 97.5% and 99.0% on average was obtained in the recognition experiment using the image with and without smoothing technique, respectively. This study can be applied to various non-contact recognition technologies using radar sensors."
Prediction of Nonlinear Stiffness of Automotive Bushings by Artificial Neural Network Models Trained by Data from Finite Element Analysis,2020,"['Bushing', 'Rubber', 'Finite Element Analysis', 'Stiffness', 'Artificial Neural Network', 'Multilayer Perceptron', 'Convolutional Neural Network']",,"Due to the nonlinear behavior of rubber for bushings, the prediction of mechanical properties of the bushing requires nonlinear finite element analysis (FEA) techniques and a lot of computation time. Therefore, we propose a method to efficiently predict the stiffness of bushings using an Artificial Neural Network (ANN) model trained by data from FEA. First, FEA was performed for the designed 3D and 2D bushing models. Based on the relationship between the bushing shape design variables and the stiffness values predicted by the FEA, we trained the Multilayer Perceptron (MLP) and the Convolutional Neural Network (CNN) models among the ANN models. Given the shape design variables of the bushing model, the stiffness values were predicted by the MLP model. Given the image of the bushing model, the stiffness values were predicted by the CNN model. The stiffness prediction results showed that both models can be used to predict the stiffness of the bushings, and that the CNN model is slightly more accurate than the MLP model. In particular, it is expected that designers can easily estimate stiffness values by taking advantage of the CNN model which can use photographic images of real parts as inputs."
국가 과학기술 표준분류 체계 기반 연구보고서 문서의 자동 분류 연구,2020,"['Deep Learning', 'Text Classification', 'Research Report', 'Preprocessing', 'NTIS']","과학기술 분야의 연구·개발 결과는 연구보고서 형태로 국가과학기술정보서비스(NTIS)에 제출된다. 각 연구보고서는 국가과학기술 표준 분류체계 (K-NSCC)에 따른 분류코드를 가지고 있는데, 보고서 작성자가 제출 시에 수동으로 입력하게끔 되어있다. 하지만 2000여 개가 넘는 세분류를 가지고 있기에, 분류체계에 대한 정확한 이해가 없이는 부정확한 분류코드를 선택하기 십상이다. 새로이 수집되는 연구보고서의 양과 다양성을 고려해 볼 때, 이들을 기계적으로 보다 정확하게 분류할 수 있다면 보고서 제출자의 수고를 덜어줄 수 있을 뿐만 아니라, 다른 부가 가치적인 분석 서비스들과의 연계가 수월할 것이다. 하지만, 국내에서 과학기술표준 분류체계에 기반을 둔 문서 자동 분류 연구 사례는 거의 없으며 공개된 학습데이터도 전무하다. 본 연구는 KISTI가 보유하고 있는 최근 5년간 (2013년~2017년) NTIS 연구보고서 메타정보를 활용한 최초의 시도로써, 방대한 과학기술표준 분류체계를 기반으로 하는 국내 연구보고서들을 대상으로 높은 성능을 보이는 문서 자동 분류기법을 도출하는 연구를 진행하였다. 이를 위해, 과학기술 표준분류 체계에서 과학기술 분야의 연구보고서를 분류하기에 적합한 중분류 210여 개를 선별하였으며, 연구보고서 메타 데이터의 특성을 고려한 전처리를 진행하였다. 특히, 가장 영향력 있는 필드인 과제명(제목)과 키워드만을 이용한 TK_CNN 기반의 딥러닝 기법을 제안한다. 제안 모델은 텍스트 분류에서 좋은 성능을 보이고 있는 기계학습법들 (예, Linear SVC, CNN, GRU등)과 비교하였으며, Top-3 F1점수 기준으로 1~7%에 이르는 성능 우위를 확인하였다.","In South Korea, the results of R&D in science and technology are submitted to the National Science and Technology Information Service (NTIS) in reports that have Korea national science and technology standard classification codes (K-NSCC). However, considering there are more than 2000 sub-categories, it is non-trivial to choose correct classification codes without a clear understanding of the K-NSCC. In addition, there are few cases of automatic document classification research based on the K-NSCC, and there are no training data in the public domain. To the best of our knowledge, this study is the first attempt to build a highly performing K-NSCC classification system based on NTIS report meta-information from the last five years (2013-2017). To this end, about 210 mid-level categories were selected, and we conducted preprocessing considering the characteristics of research report metadata. More specifically, we propose a convolutional neural network (CNN) technique using only task names and keywords, which are the most influential fields. The proposed model is compared with several machine learning methods (e.g., the linear support vector classifier, CNN, gated recurrent unit, etc.) that show good performance in text classification, and that have a performance advantage of 1% to 7% based on a top-three F1 score."
딥스택 구조를 이용한 대형 함정의 단기 전력 부하 예측,2020,"['CNN', 'Deep Stacking Network Architecture', 'LSTM', 'Short-Term Power Load Forecasting', 'Vessel']",,"The power load prediction in vessel is an important factor in determining the capacity and number of generators, and in particular the consumption of fuel oil which determines the number of days that can be sailed. In addition, short-term load forecasting is important for the capacity and scheduling of the ESS that will be applied in the future vessel. In this paper, we present a deep stack neural network for short-term load prediction in large vessels. The network is constructed using Convolutional Neural Network (CNN), Bidirectional Long-Short Term Memory (Bi-LSTM), and Long-Short Term Memory (LSTM). CNN is used for spatial feature extraction and Bi-LSTM is used to utilize information at both pre and post stages. Finally, LSTM is used to extract temporal characteristics. The voyage data of the Mokpo National Maritime University training ship was used for the short-term load prediction, and the predicted results are verified by the Mean Squared Error (MSE) and Mean Absolute Error (MAE)."
바이트 평균의 Gray-Scale화를 통한 Signature가 존재하지 않는 멀티미디어 데이터 조각 파일 타입 분류 연구,2020,"['CNN', 'Digital Forensics', 'Data Fragment Classification']","일반적으로 시그니처와 파일 메타정보가 없는 파편화된 파일은 복구가 어렵다. 특히 멀티미디어 파일은 파편화 가능성이 크고 높은 엔트로피를 가지고 있으므로 현재 시그니처 기반의 카빙으로는 복구하는 것이 거의 불가능하다. 이러한 문제를 해결하기 위해 파편화된 파일에 대한 연구가 진행되고 있지만 멀티미디어 파일에 대한 연구는 부족한 실정이다. 본 논문은 시그니처(Signature)와 파일 메타정보가 없는 파편화된 멀티미디어 파일의 타입을 분류하는 연구이다. 파일 타입에 따라 특정 바이트 값의 빈도 차이를 통해 각 파일 타입의 특징값을 추출하며, 그에 맞는 Gray-Scale 테이블을 설계하고 CNN(Convolutional Neural Networks) 모델을 이용하여 JPG, PNG, H.264, WAV 총 4가지 멀티미디어의 파일 타입을 분류하는 방법을 제시한다. 본 논문을 통해 시그니처와 파일 메타정보가 없는 파편화된 파일 타입의 분류 연구를 촉진하여 다양한 파일의 복구 가능성을 높일 수 있을 것으로 기대된다.","In general, fragmented files without signatures and file meta-information are difficult to recover. Multimedia files, in particular, are highly fragmented and have high entropy, making it almost impossible to recover with signature-based carving at present. To solve this problem, research on fragmented files is underway, but research on multimedia files is lacking. This paper is a study that classifies the types of fragmented multimedia files without signature and file meta-information. Extracts the characteristic values of each file type through the frequency differences of specific byte values according to the file type, and presents a method of designing the corresponding Gray-Scale table and classifying the file types of a total of four multimedia types, JPG, PNG, H.264 and WAV, using the CNN (Convolutional Natural Networks) model. It is expected that this paper will promote the study of classification of fragmented file types without signature and file meta-information, thereby increasing the possibility of recovery of various files."
Instance Segmentation Guided by Weight Map with Application to Tooth Boundary Detection,2020,"['Mask R-CNN', 'Boundary recognition', 'Border separation', 'Teeth image']",,"In this paper, we propose a method based on a weight map to improve the performance of instance segmentation and demonstrate the method using a simple application. A weight map is a set of pixel-wise losses, each of which has a different value depending on whether the pixel is located on the border of the image. Importantly, the losses of pixels on the border have a relatively higher value than the other pixels so that they can impose heavy penalties in the training stage. We verified the effectiveness of our method by assessing its performance when processing clinical dental images. Because teeth have similar image features (e.g., color, shape), and as they are arranged side by side, it is appropriate to evaluate the effect of using a weight map. With reference to the weight map, Mask R-CNN, our baseline model, learns very small, narrow boundaries to distinguish different instances that were recognized as one instance before. The improvement is evident both quantitatively and qualitatively. The Average Precision and Recall were found to have increased by 4.4% and 7.3%, respectively, with weight map learning. Thus, the proposed method was demonstrated to effectively enhance the ability to detect subtle boundaries. This finding is expected to make it possible to utilize a variety of existing models to their fullest potential."
시각장애인을 위한 딥러닝과 이미지인식을 이용한 스마트 옷장,2020,"['Smart appliance', 'CNN', 'Keras', 'Blind', 'Image Recognition', 'Deep learning']","시각장애인의 대다수는 독립적인 의생활을 하는데 어려움을 겪는다. 최근 스마트 가전 시장의 성장으로 가구나 가전에 인공지능이나 IoT를 추가하는 제품이 늘어나고 있다. 본 논문에서는 시각장애인의 독립적인 의생활을 지원하기 위해 옷장 내부를 관리하는 기능, 음성 대화를 통해 정보를 요청하는 음성인식 기능 그리고 CNN 알고리즘을 이용한 옷 정보에 대한 인식 기능을 가진 스마트 옷장을 제안한다. 본 논문에서는 옷을 인식하는 과정에서 정확도를 높이기 위해 모델의 층 개수를 변경하고 Maxpooling을 조정하여 모델을 생성하였다. 모델 생성 시 Early Stopping Callback 옵션을 적용하여 학습 정확도를 보장해주었다. 과적합을 방지해주기 위하여 Dropout을 추가했다. 이러한 과정으로 만 들어진 최종 모델은 옷 인식 정확도가 80%가 되는 것을 확인할 수 있다.","The blind people have difficulty living an independent clothing life. The furniture and home appliance are adding AI or IoT with the recent growth of the smart appliance market. To support the independent clothing life of the blind, this paper suggests a smart wardrobe with closet control function, voice recognition function and clothes information recognition using CNN algorithm. The number of layers of the model was changed and Maxpooling was adjusted to create the model to increase accuracy in the process of recognizing clothes. Early Stopping Callback option is applied to ensure learning accuracy when creating a model. We added Dropout to prevent overfitting. The final model created by this process can be found to have 80 percent accuracy in clothing recognition."
인공지능 기반의 자세 추정에 따른 모바일 헬스케어 동작 연구,2020,"['AI', 'Deep Learning', 'CNN', 'Fitness', 'PoseNet']",스마트폰의 디바이스를 활용하여 개인의 건강을 실시간 관리하는 트렌드 확산과 헬스케어 관련 디바이스가 많은 관심을 받고 있지만 아직은 실제 시장으로 확산하기에는 쉽지 않을 것 같다. 현재는 사용자가 비디오 콘덴츠나 휘트니스 앱을 통한 강사 따라하기형에 많이 의존하고 있다. 본 연구에서는 LSP(Leeds Sports Pose) 데이터셋에서 사용되는 데이터를 기반으로 인공지능(Artificial Intelligence: AI) 합성신경망(Convolutional Neural Network: CNN)의 PoseNet을 활용하여 자세 추정 학습 및 인체 좌표를 분석하여 그 결과값으로 손뼉치기를 구현하고자 한다. 개발 언어는 Node.js 프로그램을 사용하여 최종 운동량 결과를 모바일 헬스케어로 구현하고자 한다. 이를 통해 자세 추정에 대한 동작 결과가 직관과 오류의 의존성에서 벗어나는 동기가 마련된다. 인체 좌표를 통한 보다 정량적이고 신속한 자세 추정에 근거한 동작 분석이 가능하게 되었다. 이런 점에서 PoseNet은 헬스케어 플랫폼의 많은 기능 중 하나로 서비스 되는 개인 휘트니스 프로그램을 개발하고자 하는 우리의 목적에 상당히 부합하는 모델이다.,"Trends in managing personal health using smartphone devices and healthcare-related devices are receiving a lot of attention, but it is not easy to spread them to the real market for some time. Currently, users rely heavily on instructor training through video content or fitness applications. In this study, we use PoseNet of artificial intelligence(AI) convolutional neural network(CNN) based on the data used in the Leeds Sports Pose(LSP) dataset to analyze pose estimation and analyze human coordinates, and to applaud the result as a clap. The development language uses the Node.js program to implement the final momentum results into mobile healthcare. This provides motivation for the behavioral results of pose estimation to deviate from the dependency of intuition and error. Motion analysis based on more quantitative and faster pose estimation through body coordinates is now possible. In this regard, PoseNet can be a model that fits our purpose of developing a personal fitness program, being served as one of the many features of the healthcare platform."
Defect Classification of Cross-section of Additive Manufacturing Using Image-Labeling,2020,"['Deep Learning(딥러닝)', 'CNN(순환 신경망)', 'Data Augmentation(데이터 증폭)', 'Image Labeling(이미지 라벨링)', 'Additive Manufacturing(적층제조)']",,"Recently, the fourth industrial revolution has been presented as a new paradigm and additive manufacturing (AM) has become one of the most important topics. For this reason, process monitoring for each cross-sectional layer of additive metal manufacturing is important. Particularly, deep learning can train a machine to analyze, optimize, and repair defects. In this paper, image classification is proposed by learning images of defects in the metal cross sections using the convolution neural network (CNN) image labeling algorithm. Defects were classified into three categories: crack, porosity, and hole. To overcome a lack-of-data problem, the amount of learning data was augmented using a data augmentation algorithm. This augmentation algorithm can transform an image to 180 images, increasing the learning accuracy. The number of training and validation images was 25,920 (80 %) and 6,480 (20 %), respectively. An optimized case with a combination of fully connected layers, an optimizer, and a loss function, showed that the model accuracy was 99.7 % and had a success rate of 97.8 % for 180 test images. In conclusion, image labeling was successfully performed and it is expected to be applied to automated AM process inspection and repair systems in the future."
딥러닝 기법을 활용한 가구 부자재 주문 수요예측,2020,"['가구 부자재', '수요예측', '재고관리', '1D-CNN', 'Furniture Component', 'Oer demand Forecast', 'Inventory Control', 'ARIMA', 'LSTM', '1D-CNN F']",,"Despite the recent economic contraction caused by the Corona 19 incident, interest in the residential environment is growing as more people live at home due to the increase in telecommuting, thereby increasing demand for remodeling. In addition, the government’s real estate policy is also expected to have a visible impact on the sales of the interior and furniture industries as it shifts from regulatory policy to the expansion of housing supply. Accurate demand forecasting is a problem directly related to inventory management, and a good demand forecast can reduce logistics and inventory costs due to overproduction by eliminating the need to have unnecessary inventory. However, it is a difficult problem to predict accurate demand because external factors such as constantly changing economic trends, market trends, and social issues must be taken into account. In this study, LSTM model and 1D-CNN model were compared and analyzed by artificial intelligence-based time series analysis method to produce reliable results for manufacturers producing furniture components."
자연어처리 모델을 이용한 이커머스 데이터 기반 감성 분석 모델 구축,2020,"['NLP', 'BERT', 'KoBERT', 'ELMo', 'LSTM', 'CNN', '자연어처리', '감성 분석', '이커머스', '워드 임베딩', '센텐스 임베딩', '전이학습']","자연어 처리 분야에서 번역, 형태소 태깅, 질의응답, 감성 분석등 다양한 영역의 연구가 활발히 진행되고 있다. 감성 분석 분야는 Pretrained Model을 전이 학습하여 단일 도메인 영어 데이터셋에 대해 높은 분류 정확도를 보여주고 있다. 본 연구에서는 다양한 도메인 속성을 가지고 있는 이커머스 한글 상품평 데이터를 이용하고 단어 빈도 기반의 BOW(Bag Of Word), LSTM[1], Attention, CNN[2], ELMo[3], KoBERT[4] 모델을 구현하여 분류 성능을 비교하였다. 같은 단어를 동일하게 임베딩하는 모델에 비해 문맥에 따라 다르게 임베딩하는 전이학습 모델이 높은 정확도를 낸다는 것을 확인하였고, 17개 카테고리 별, 모델 성능 결과를 분석하여 실제 이커머스 산업에서 적용할 수 있는 감성 분석 모델 구성을 제안한다. 그리고 모델별 용량에 따른 추론 속도를 비교하여 실시간 서비스가 가능할 수 있는 모델 연구 방향을 제시한다.","In the field of Natural Language Processing, Various research such as Translation, POS Tagging, Q&A, and Sentiment Analysis are globally being carried out. Sentiment Analysis shows high classification performance for English single-domain datasets by pretrained sentence embedding models. In this thesis, the classification performance is compared by Korean E-commerce online dataset with various domain attributes and 6 Neural-Net models are built as BOW (Bag Of Word), LSTM[1], Attention, CNN[2], ELMo[3], and BERT(KoBERT)[4]. It has been confirmed that the performance of pretrained sentence embedding models are higher than word embedding models. In addition, practical Neural-Net model composition is proposed after comparing classification performance on dataset with 17 categories. Furthermore, the way of compressing sentence embedding model is mentioned as future work, considering inference time against model capacity on real-time service."
Multi-Task FaceBoxes: A Lightweight Face Detector Based on Channel Attention and Context Information,2020,"['Multi-Task FaceBoxes', 'Feature Fusion', 'Attention', 'Landmark Detection']",,"In recent years, convolutional neural network (CNN) has become the primary method for face detection. But its shortcomings are obvious, such as expensive calculation, heavy model, etc. This makes CNN difficult to use on the mobile devices which have limited computing and storage capabilities. Therefore, the design of lightweight CNN for face detection is becoming more and more important with the popularity of smartphones and mobile Internet. Based on the CPU real-time face detector FaceBoxes, we propose a multi-task lightweight face detector, which has low computing cost and higher detection precision. First, to improve the detection capability, the squeeze and excitation modules are used to extract attention between channels. Then, the textual and semantic information are extracted by shallow networks and deep networks respectively to get rich features. Finally, the landmark detection module is used to improve the detection performance for small faces and provide landmark data for face alignment. Experiments on AFW, FDDB, PASCAL, and WIDER FACE datasets show that our algorithm has achieved significant improvement in the mean average precision. Especially, on the WIDER FACE hard validation set, our algorithm outperforms the mean average precision of FaceBoxes by 7.2%. For VGA-resolution images, the running speed of our algorithm can reach 23FPS on a CPU device."
Automatic Detection and Classification of Rib Fractures on Thoracic CT Using Convolutional Neural Network: Accuracy and Feasibility,2020,"['Rib fractures', 'Convolutional neural networks', 'Deep learning', 'Artificial intelligence', 'Multidetector computed tomography', 'Structured report']",,"Objective: To evaluate the performance of a convolutional neural network (CNN) model that can automatically detect and classify rib fractures, and output structured reports from computed tomography (CT) images.Materials and Methods: This study included 1079 patients (median age, 55 years; men, 718) from three hospitals, between January 2011 and January 2019, who were divided into a monocentric training set (n = 876; median age, 55 years; men, 582), five multicenter/multiparameter validation sets (n = 173; median age, 59 years; men, 118) with different slice thicknesses and image pixels, and a normal control set (n = 30; median age, 53 years; men, 18). Three classifications (fresh, healing, and old fracture) combined with fracture location (corresponding CT layers) were detected automatically and delivered in a structured report. Precision, recall, and F1-score were selected as metrics to measure the optimum CNN model. Detection/diagnosis time, precision, and sensitivity were employed to compare the diagnostic efficiency of the structured report and that of experienced radiologists.Results: A total of 25054 annotations (fresh fracture, 10089; healing fracture, 10922; old fracture, 4043) were labelled for training (18584) and validation (6470). The detection efficiency was higher for fresh fractures and healing fractures than for old fractures (F1-scores, 0.849, 0.856, 0.770, respectively, p = 0.023 for each), and the robustness of the model was good in the five multicenter/multiparameter validation sets (all mean F1-scores > 0.8 except validation set 5 [512 x 512 pixels; F1-score = 0.757]). The precision of the five radiologists improved from 80.3% to 91.1%, and the sensitivity increased from 62.4% to 86.3% with artificial intelligence-assisted diagnosis. On average, the diagnosis time of the radiologists was reduced by 73.9 seconds.Conclusion: Our CNN model for automatic rib fracture detection could assist radiologists in improving diagnostic efficiency, reducing diagnosis time and radiologists’ workload."
Deep-Learning Study of the 21-cm Differential Brightness Temperature During the Epoch of Reionization,2020,"['Epoch of reionization', 'Deep learning']",,"We propose a deep learning analysis technique with a convolutional neural network (CNN) to predict the evolutionary track of the Epoch of Reionization (EoR) from the 21-cm differential brightness temperature tomography images.We use 21cmFAST, a fast semi-numerical cosmological 21-cm signal simulator, to produce mock 21-cm maps between z=6 ~ 13.We then apply two observational effects, such as instrumental noise and limit of (spatial and depth) resolution somewhat suitable for realistic choices of the Square Kilometre Array (SKA), into the 21-cm maps.We design our deep learning model with CNN to predict the sliced-averaged neutral hydrogen fraction from the given 21-cm map.The estimated neutral fraction from our CNN model has great agreement with the true value even after coarsely smoothing with broad beam size and frequency bandwidth and heavily covered by noise with narrow beam size and frequency bandwidth.Our results show that the deep learning analyzing method has the potential to reconstruct the EoR history efficiently from the 21-cm tomography surveys in future."
머신러닝 기법을 활용한 대용량 시계열 데이터 이상 시점탐지 방법론 : 발전기 부품신호 사례 중심,2020,"['Anomaly Detection', 'Convolution Neural Network', 'LASSO', 'Machine Learning', 'Principal Components Analysis']",,"Anomaly detection of Machine Learning such as PCA anomaly detection and CNN image classification has been focused on cross-sectional data. In this paper, two approaches has been suggested to apply ML techniques for identifying the failure time of big time series data. PCA anomaly detection to identify time rows as normal or abnormal was suggested by converting subjects identification problem to time domain. CNN image classification was suggested to identify the failure time by re-structuring of time series data, which computed the correlation matrix of one minute data and converted to tiff image format. Also, LASSO, one of feature selection methods, was applied to select the most affecting variables which could identify the failure status. For the empirical study, time series data was collected in seconds from a power generator of 214 components for 25 minutes including 20 minutes before the failure time. The failure time was predicted and detected 9 minutes 17 seconds before the failure time by PCA anomaly detection, but was not detected by the combination of LASSO and PCA because the target variable was binary variable which was assigned on the base of the failure time. CNN image classification with the train data of 10 normal status image and 5 failure status images detected just one minute before."
머신러닝 기반 기업부도위험 예측모델 검증 및 정책적 제언: 스태킹 앙상블 모델을 통한 개선을 중심으로,2020,"['부도위험 예측', '스태킹 앙상블 모델', '머튼 모형', '랜덤 포레스트', '합성곱 신경망', 'Corporate default risk prediction', 'Merton model', 'Random forest', 'CNN']",,"This study uses corporate data from 2012 to 2018 when K-IFRS was applied in earnest to predict default risks. The data used in the analysis totaled 10,545 rows, consisting of 160 columns including 38 in the statement of financial position, 26 in the statement of comprehensive income, 11 in the statement of cash flows, and 76 in the index of financial ratios. Unlike most previous prior studies used the default event as the basis for learning about default risk, this study calculated default risk using the market capitalization and stock price volatility of each company based on the Merton model. Through this, it was able to solve the problem of data imbalance due to the scarcity of default events, which had been pointed out as the limitation of the existing methodology, and the problem of reflecting the difference in default risk that exists within ordinary companies. Because learning was conducted only by using corporate information available to unlisted companies, default risks of unlisted companies without stock price information can be appropriately derived. Through this, it can provide stable default risk assessment services to unlisted companies that are difficult to determine proper default risk with traditional credit rating models such as small and medium-sized companies and startups. Although there has been an active study of predicting corporate default risks using machine learning recently, model bias issues exist because most studies are making predictions based on a single model. Stable and reliable valuation methodology is required for the calculation of default risk, given that the entitys default risk information is very widely utilized in the market and the sensitivity to the difference in default risk is high. Also, Strict standards are also required for methods of calculation. The credit rating method stipulated by the Financial Services Commission in the Financial Investment Regulations calls for the preparation of evaluation methods, including verification of the adequacy of evaluation methods, in consideration of past statistical data and experiences on credit ratings and changes in future market conditions. This study allowed the reduction of individual models bias by utilizing stacking ensemble techniques that synthesize various machine learning models. This allows us to capture complex nonlinear relationships between default risk and various corporate information and maximize the advantages of machine learning-based default risk prediction models that take less time to calculate. To calculate forecasts by sub model to be used as input data for the Stacking Ensemble model, training data were divided into seven pieces, and sub-models were trained in a divided set to produce forecasts. To compare the predictive power of the Stacking Ensemble model, Random Forest, MLP, and CNN models were trained with full training data, then the predictive power of each model was verified on the test set. The analysis showed that the Stacking Ensemble model exceeded the predictive power of the Random Forest model, which had the best performance on a single model. Next, to check for statistically significant differences between the Stacking Ensemble model and the forecasts for each individual model, the Pair between the Stacking Ensemble model and each individual model was constructed. Because the results of the Shapiro-wilk normality test also showed that all Pair did not follow normality, Using the nonparametric method wilcoxon rank sum test, we checked whether the two model forecasts that make up the Pair showed statistically significant differences. The analysis showed that the forecasts of the Staging Ensemble model showed statistically significant differences from those of the MLP model and CNN model. In addition, this study can provide a methodology that allows existing credit rating agencies to apply machine learning-based bankruptcy risk prediction methodologies, given that traditional credit rating models can a"
불법 산양삼 검출을 위한 인공지능 기술에서의 산양삼과 인삼 이미지의 분류 기저화 연구,2020,"['산양삼', '인공지능', '기계학습', '이미지 분석', '합성곱 신경망', 'Mountain Ginseng', 'Artificial Intelligence', 'Machine Learning', 'Image Detection', 'CNN(Convolutional Neural Network)']","본 연구는 인삼과 산양삼에 대해 아무런 정보가 없는 초보 소비자가 인삼을 산양삼이라 여기는 사기 상황을 방지하는 차원에서 산양삼 형태에 대한 기저수준을 확립하려했다. 이를 위해 연구자들은 소비자가 스마트폰의 전용 APP으로 인삼을 촬영하면 그 사진이 원격으로 전송되어, 기계학습데이터를 기반으로 판별한 결과가 소비자에게 전송되는 서비스디자인을 고안했다. 연구과정에서의 데이터 셋과 소비자들이 스마트폰을 통해 촬영했을 때의 배경색, 산양삼의 위치, 크기, 조도, 색온도 등과의 차이를 최소화 하기 위해 소비자 용전용 촬영 박스를 디자인 했다. 이에 따라 산양삼 샘플 수집은 디자인된 박스와 동일한 통제된 환경과 세팅 하에서 이루어졌다. 이를 통해 기계학습에서 통상 필요한 것 보다 약 1/10이 적은 샘플을 사용해CNN(VGG16)모델에서 예측 확율 100%를 얻었다.",
Lesion-Based Convolutional Neural Network in Diagnosis of Early Gastric Cancer,2020,"['Artificial intelligence', 'Convolutional neural networks', 'Early gastric cancer', 'Endoscopy', 'Invasion depth']",,"Diagnosis and evaluation of early gastric cancer (EGC) using endoscopic images is significantly important; however, it has somelimitations. In several studies, the application of convolutional neural network (CNN) greatly enhanced the effectiveness of endoscopy.To maximize clinical usefulness, it is important to determine the optimal method of applying CNN for each organ and disease. LesionbasedCNN is a type of deep learning model designed to learn the entire lesion from endoscopic images. This review describes theapplication of lesion-based CNN technology in diagnosis of EGC."
A Study on Applying the SRCNN Model and Bicubic Interpolation to Enhance Low-Resolution Weeds Images for Weeds Classification,2020,"['super-resolution', 'weeds classification', 'convolutional neural network', 'deep learning']",,"In the image object classification problem, low-resolution images may have a negative impact on the classification result, especially when the classification method, such as a convolutional neural network (CNN) model, is trained on a high-resolution (HR) image dataset. In this paper, we analyze the behavior of applying a classical super-resolution (SR) method such as bicubic interpolation, and a deep CNN model such as SRCNN to enhance low-resolution (LR) weeds images used for classification. Using an HR dataset, we first train a CNN model for weeds image classification with a default input size of 128×128. Then, given an LR weeds image, we rescale to default input size by applying the bicubic interpolation or the SRCNN model. We analyze these two approaches on the Chonnam National University (CNU) weeds dataset and find that SRCNN is suitable for the image size is smaller than 80×80, while bicubic interpolation is convenient for a larger image."
캡슐네트워크 기반 3차원 자세 예측,2020,"['deep learning', 'capsule network', 'pose estimation', '.']",,.
건물 에너지 분야의 인공지능 기반 연구 동향 분석 - 해외 저널 논문 중심으로 -,2020,"['건물에너지', '인공신경망', '합성곱 신경망', '순환 신경망', '장단기 메모리', 'Building Energy', 'Artificial Neural Network', 'Convolutional Neural Network', 'Recurrent Neural Network', 'Long-Short Term Memory']",,"Purpose: Recently, there are many research projects conducted to achieve smart cities. Smart cities consist of smart buildings that include efficient energy supply and consumption systems. The Artificial Intelligence (AI) technologies became useful tools for this purpose due to their reliability of prediction accuracy and credibility. It is very important to better understand how the AI algorithms work and can be applied for specific areas of energy efficiency in buildings. This paper presents how AI technologies, such as Artificial Neural Network (ANN), Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), and Long Short-Term Memory (LSTM), are currently being utilized in the energy efficiency research in buildings. Method: International journal papers are reviewed especially for those utilizing ANN, CNN, RNN, and LSTM algorithms in building science and technologies. In-depth analyses are conducted comparing specific approaches, research outcomes, advantages, and disadvantages of key papers. Result: Findings show that the ANN, CNN, RNN, and LSTM algorithms are mainly used for the prediction of building energy loads and system energy uses. Compared to other AI algorithms, the LSTM algorithms have higher prediction accuracies due to the characteristics of LSTM structure."
A Study on Wearable Airbag System Applied with Convolutional Neural Networks for Safety of Motorcycle,2020,['Convolutional neural network · IMU · Air bag · Machine learning · Motorcycle · Artifcial intelligence'],,"Injuries to the head and the neck are the most frequent in the event of motorcycle accidents. But enough research has not been done to protect the neck. This paper presents an airbag system that recognizes the accident situation with Artifcial Intelligence to protect the driver’s neck area from motorcycle accident situations when driving. In some papers with similar themes, most of them are judged based on a critical point. However, in the case of an accident judgment using the critical point, a malfunction may occur such that the airbag operates when a similar operation is performed, or the airbag does not operate due to failing to pass the critical point at the time of an accident. Artifcial intelligence was used to avoid malfunctions and inconveniences. Artifcial intelligence can solve the problem of malfunction that occurs when it is judged as a critical point and can solve the inconvenience of commercialized products. The CNN presented in this paper can solve these two problems, and the accuracy of accident judgment is as high as 95.75%. Through the MPU 6050 sensor, it operates the airbag by determining the accident situation using the Artifcial Intelligence that was learned in advance through the information on acceleration and angular velocity of the driver’s movements that were measured in real time. To make Artifcial Intelligence learn, the data were collected by dividing several types of accidents on motorcycles. In this paper, the Artifcial Intelligence made by Convolutional Neural Networks (CNN) method and the Artifcial Intelligence made by Neural Networks (NN) method is compared, and it is confrmed that the performance such as Test Accuracy or Train Accuracy of CNN is better."
기계 학습을 활용한 이미지 결함 검출 모델 개발,2020,"['이미지 결함 검출', '서포트 벡터 머신', '다층 퍼셉트론', '합성곱 신경망', 'Image Defect Detection', 'Support Vector Machine', 'Multi-Layer Perceptron', 'Convolutional Neural Network']","최근 기계 학습을 활용한 비전 검사 시스템의 개발이 활발해지고 있다. 본 연구는 기계 학습을 활용한 결함 검사 모델을 개발하고자 한다. 이미지에 대한 결함 검출 문제는 기계 학습에 있어 지도 학습 방법인 분류 문제에 해당한다. 본 연구에서는 특징을 자동 추출하는 알고리즘과 특징을 추출하지 않는 알고리즘을 기반으로 결함 검출 모델을 개발한다. 특징을 자동 추출하는 알고리즘으로 1차원 합성곱 신경망과 2차원 합성곱 신경망을 활용하였으며, 특징을 추출하지 않는 알고리즘으로 다중 퍼셉트론, 서포트 벡터 머신을 활용하였다. 4가지 모델을 기반으로 결함 검출 모델을 개발하였고 이들의 정확도와 AUC를 기반으로 성능 비교하였다. 이미지 분류는 합성곱 신경망을 활용한 모델 개발이 일반적임에도, 본 연구에서 이미지의 화소를 RGB 값으로 변환하여 서포트 벡터 머신 모델을 개발할 때 높은 정확도와 AUC를 얻을 수 있었다.","Recently, the development of a vision inspection system using machine learning has become more active. This study seeks to develop a defect inspection model using machine learning. Defect detection problems for images correspond to classification problems, which are the method of supervised learning in machine learning. In this study, defect detection models are developed based on algorithms that automatically extract features and algorithms that do not extract features. One-dimensional CNN and two-dimensional CNN are used as algorithms for automatic extraction of features, and MLP and SVM are used as algorithms for non-extracting features. A defect detection model is developed based on four models and their accuracy and AUC compare based on AUC. Although image classification is common in the development of models using CNN, high accuracy and AUC is achieved when developing SVM models by converting pixels from images into RGB values in this study."
특징 맵 가중치 변경에 따른 MNIST 숫자인식 학습속도 개선에 관한 연구,2020,"['CNN', 'convolution', 'deep learning', 'feature map', 'weight']",,"In this paper, the redundant effects of feature maps after the use of CNN Consolidation filters were analyzed, and the following three methods were studied to improve the learning speed of MNIST cursive numbers. First, we studied changes in recognition rate when the external side with less overlap of features was heavily weighted, secondly the degree of improvement in learning speed when reducing the number of filters with a large weighting on the external side, and thirdly, the external line with less redundant impact was studied for improvement in learning speed when excluding computations. As a result, the numerical recognition rate improvement was minimal when the external line with less feature-point redundancy was weighted, and the processing speed was improved by about 12% when the filter count was halved under the same weight and there was no change in the recognition rate. And when the external with less feature-point redundancy are excluded from the computational processing, the learning speed has proven to be improved by about 25% without a decrease in recognition rate."
A Hierarchical deep model for food classification from photographs,2020,"['CNN', 'DenseNet', 'classification', 'food', 'dietetics']",,"Recognizing food from photographs presents many applications for machine learning, computer vision and dietetics, etc. Recent progress of deep learning techniques accelerates the recognition of food in a great scale. We build a hierarchical structure composed of deep CNN to recognize and classify food from photographs. We build a dataset for Korean food of 18 classes, which are further categorized in 4 major classes. Our hierarchical recognizer classifies foods into four major classes in the first step. Each food in the major classes is further classified into the exact class in the second step. We employ DenseNet structure for the baseline of our recognizer. The hierarchical structure provides higher accuracy and F1 score than those from the single-structured recognizer."
Comparison of Neural Network Techniques for Text Data Analysis,2020,"['1d-CNN', 'C-LSTM', 'Cross-validation', 'LSTM', 'RNN', 'Sequential data.']",,"Generally, sequential data refers to data having continuity. Text data, which is a representative type of unstructured data, is also sequential data in that it is necessary to know the meaning of the preceding word in order to know the meaning of the following word or context. So far, many techniques for analyzing sequential data such as text data have been proposed. In this paper, four methods of 1d-CNN, LSTM, BiLSTM, and CLSTM are introduced, focusing on neural network techniques. In addition, by using this, IMDb movie review data was classified into two classes to compare the performance of the techniques in terms of accuracy and analysis time."
딥러닝 기반 가상공간에서의 손 제스처 인식,2020,"['딥러닝', '가상 공간', 'CNN', '손 제스쳐 인식', '사용자 인터페이스', 'Deep Learning', 'Virtual Space', 'Hand Gesture Recognition', 'User Interface']",,"In this paper, we define static gestures and dynamic gestures to be used as a user interface in a virtual space, and propose a method to extract features using deep learning models and to recognize hand gestures input through RGB camera in order to improve the price and recognition speed of the existing virtual / augmented reality interface device. Through various deep learning models, we learned the data in various ways and extracted the features to recognize hand gestures. Deep learning models used are Faster-RCNN, ResNet, U-Net, and 3D-CNN. Since we recognize hand gestures in the virtual space and use them as user interfaces, we want to contribute to using virtual / augmented reality through high recognition rates and fast recognition speeds without the help of specific sensors or wearable devices."
합성곱 신경망을 이용하는 수퍼픽셀 기반 사과잎 병충해의 분류,2020,"['Disease classification', 'Superpixel', 'CNN', 'Apple leaf']",,"The classification of plant diseases by images captured by a camera sensor has been studied over past decades. A method that has gained much interest is to use image segmentation, from which statistical features are derived and analyzed by machine learning. Recently, deep learning has been adopted in this area. However, image segmentation is still a difficult task to achieve stable performance due to a variety of environmental variations. The end-to-end learning in neural network has a demerit that train images may be different from real images acquired in outdoor fields. To solve these problems, we propose superpixel-based disease classification method using end-to-end CNN (convolutional neural network) learning. Based on experiments performed on PlantVillage apple images, the classification accuracy is 98.29% and 92.43% for full-image and superpixel. As well, the multivariate F1-score is (0.98, 0.93). Therefore we validate that the method of using superpixel is comparable to that of full-image."
딥러닝을 활용한 전략물자 판정 지원도구 개발에 대한 연구,2020,"['Deep Learning', 'Classification', 'CNN', 'OCR', 'Dual-use Item']","전략물자관리 제도의 이행 확산에 따라 전략물자 판정의 중요성이 높아지고 있으나 전략물자 제도를 처음 접하는 수출기업은 전략물자의 개념을 이해하기 쉽지 않고, 전략물자를 통제하는 기준이 다양하여 전략물자 판정에 어려움이 따른다. 본 논문에서는 전략물자 제도를 처음 접하는 기업이나 전략물자 판정시스템 이용자에게 진입장벽을 낮추어 판정이라는 과정을 쉽게 접근할 수 있는 방법을 제안한다. 이용자가 전략물자 판정이라는 절차를 매뉴얼이나 카탈로그의 제공만으로 판정결과를 확인할 수 있게 된다면, 전략물자 판정 방법과 절차에 보다 편리하고 쉽게 다가설수 있을 것이다. 본 연구 목적을 달성하기 위해 이미지 인식 및 분류에서 연구되고 있는 딥러닝과 OCR(광학문자판독) 기술을 활용하고, 전략물자 판정 지원도구에 대한 개발과 연구를 통하여 우리 기업의 전략물자 판정에 도움이 되는 정보를 제공한다.","As the implementation of export controls is spreading, the importance of classifying strategic items is increasing, but Korean export companies that are new to export controls are not able to understand the concept of strategic items, and it is difficult to classifying strategic items due to various criteria for controlling strategic items. In this paper, we propose a method that can easily approach the process of classification by lowering the barrier to entry for users who are new to export controls or users who are using classification of strategic items. If the user can confirm the decision result by providing a manual or a catalog for the procedure of classifying strategic items, it will be more convenient and easy to approach the method and procedure for classfying strategic items. In order to achieve the purpose of this study, it utilizes deep learning, which are being studied in image recognition and classification, and OCR(optical character reader) technology. And through the research and development of the support tool, we provide information that is helpful for the classification of strategic items to our companies."
딥러닝 기반 표고버섯 병해충 이미지 분석에 관한 연구,2020,"['Pests', 'Disease', 'Deep Learning', 'CNN', 'Alexnet', 'Shiitake']",,"The work that detection and elimination to disease and pest have important in agricultural field because it is directly related to the production of the crops, early detection and treatment of the disease insects. Image classification technology based on traditional computer vision have not been applied in part such as disease and pest because that is falling a accuracy to extraction and classification of feature. In this paper, we proposed model that determine to disease and pest of shiitake based on deep-CNN which have high image recognition performance than exist study. For performance evaluation, we compare evaluation with Alexnet to a proposed deep learning evaluation model. We were compared a proposed model with test data and extend test data. The result, we were confirmed that the proposed model had high performance than Alexnet which approximately 48% and 72% such as test data, approximately 62% and 81% such as extend test data."
딥러닝을 이용한 소리 분류 시 방해음의 영향 분석,2020,"['Environmental sound classification', 'Noise', 'CNN', 'VGG16', 'UrbanSound8K', 'Signal to noise ratio']",,"Environmental sound classification is an area that automatically classifies sounds in our surroundings. It can be applied to home automation, security, and surveillance. Recently, the deep learning approaches have been adopted as a classifier for increasing performance. In this method, a deep neural network is trained using many sound data, and after the learning is completed, the microphone pickup sound is applied for classification. However, during this stage, the ambient noise can be put into the microphone along with the sound to be identified. And the sound cannot be properly classified due to this disturbing noise. The recognition rate of the deep neural network decreases as the loudness of the disturbing sound increases, but the analysis about the noise effect on the classification have been limited. In this paper, we present the effect of the disturbing noise on the classification rate. For this purpose, UrbanSound8K, which is composed of 10 types of urban environmental sounds, is used for training and test data. And the VGG16-based CNN which shows good performance in image classification was adopted as a baseline model. For the disturbing noise, we use three types of sounds that are consist of daily noises (hairdryer, vacuum cleaner, faucet water, and hammer), voices(male, female, and synthesized sound), and music(cello, piano, and trumpet). In the experiment, these disturbing noises are mixed with the clean sounds so that the signal-to-noise ratio is in the range of -50dB to 50dB. Then the mixed sound was applied to a deep neural network to obtain a relative recognition rate when compared to the clean cases. The results show that the recognition rate is more than 90% compared to the clean sound cases when the SNR is between 10 and 15 dB, and 95% or more when the SNR is greater than 20 dB, regardless of the type of the disturbing sound."
Tracking a Sea Turtle by an AUV with a Multibeam Imaging Sonar: Toward Robotic Observation of Marine Life,2020,"['Autonomous underwater vehicles', 'CNN', 'field robotics', 'imaging sonar', 'sea turtle.']",,"This paper proposes a method for autonomous underwater vehicles to chase sea turtles without attaching any tag to them, toward efficient and long-term observation of marine life. The method uses a multibeam imaging sonar as the main sensor to detect sea turtles. The method utilizes convolutional neural network (CNN) for detecting a sea turtle in sonar imagery. Surge and yaw movements of the vehicle are controlled to maintain the relative distance and direction to the detected target. The proposed method was implemented in the AUV HATTORI. The AUV succeeded in tracking a sea turtle in natural condition for 270 seconds in shallow sea."
A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis,2020,"['Deep reinforcement learning', 'Deep learning', 'Complex images', 'CNN', 'DQN']",,"The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information."
Wavelet 기법을 이용한 하수관거 영상의 균열인식,2020,"['wavelet', 'sewer', 'crack detection', 'low resolution image', 'CNN', '웨이블릿', '하수관거', '균열 탐지', '저해상도']",,"In this study, the wavelet technique was used to detect cracks in low-resolution sewage pipes. A parameter study was conducted using four variables, and the validity was verified by comparing the results of the wavelet technique with those of the currently used CNN technique. The results show that, even if only the default values of the parameter variables presented in this study are used, the accuracy is 97.2%, is not jagged, and shows stability. As such, the wavelet technique can be used to recognize defects like cracks in structures. Future research should seek a complementary method that uses the deep learning technique."
Isolated Spoken Word Recognition Using One-Dimensional Convolutional Neural Network,2020,"['Feature extraction', 'Classification', 'One-dimensional CNN']",,"Isolated uttered word recognition has many applications in human–computer interfaces. Feature extraction in speech represents a vital and challenging step for speech-based classification. In this work, we propose a one-dimensional convolutional neural network (CNN) that extracts learned features and classifies them based on a multilayer perceptron. The proposed models are tested on a designed dataset of 119 speakers uttering Kurdish digits (0-9). The results show that both speaker-dependent (average accuracy of 98.5%) and speaker-independent (average accuracy of 97.3%) models achieve convincing results. The analysis of the results shows that 9 of the speakers have a bias characteristic, and their results are outliers compared to the other 110 speakers."
Split-Attention 백본 네트워크를 활용한 차선 인식에 관한 연구,2020,[],,"This paper proposes a lane recognition CNN network using split-attention network as a backbone to extract feature. Split-attention is a method of assigning weight to each channel of a feature map in the CNN feature extraction process; it can reliably extract the features of an image during the rapidly changing driving environment of a vehicle. The proposed deep neural networks in this paper were trained and evaluated using the Tusimple data set. The change in performance according to the number of layers of the backbone network was compared and analyzed. A result comparable to the latest research was obtained with an accuracy of up to 96.26, and FN showed the best result. Therefore, even in the driving environment of an actual vehicle, stable lane recognition is possible without misrecognition using the model proposed in this study."
A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis,2020,"['Deep reinforcement learning', 'Deep learning', 'Complex images', 'CNN', 'DQN']",,"The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information."
핵의학 감마카메라 정도관리의 딥러닝 적용,2020,"['핵의학', '정도관리', '인공지능', '콘볼루션 신경망', '딥러닝', 'Nuclear medicine', 'Quality Control', 'AI', 'CNN', 'Deep Learning']",,"In the field of nuclear medicine, errors are sometimes generated because the assessment of the uniformity of gamma cameras relies on the naked eye of the evaluator. To minimize these errors, we created an artificial intelligence model based on CNN algorithm and wanted to assess its usefulness. We produced 20,000 normal images and partial cold region images using Python, and conducted artificial intelligence training with Resnet18 models. The training results showed that accuracy, specificity and sensitivity were 95.01%, 92.30%, and 97.73%, respectively. According to the results of the evaluation of the confusion matrix of artificial intelligence and expert groups, artificial intelligence was accuracy, specificity and sensitivity of 94.00%, 91.50%, and 96.80%, respectively, and expert groups was accuracy, specificity and sensitivity of 69.00%, 64.00%, and 74.00%, respectively. The results showed that artificial intelligence was better than expert groups. In addition, by checking together with the radiological technologist and AI, errors that may occur during the quality control process can be reduced, providing a better examination environment for patients, providing convenience to radiologists, and improving work efficiency."
Semi-supervised based Unknown Attack Detection in EDR Environment,2020,"['Endpoint Security', 'EDR', 'Unknown Attack Detection', 'AutoEncoder', '1D CNN']",,"Cyberattacks penetrate the server and perform various malicious acts such as stealing confidential information, destroying systems, and exposing personal information. To achieve this, attackers perform various malicious actions by infecting endpoints and accessing the internal network. However, the current countermeasures are only anti-viruses that operate in a signature or pattern manner, allowing initial unknown attacks. Endpoint Detection and Response (EDR) technology is focused on providing visibility, and strong countermeasures are lacking. If you fail to respond to the initial attack, it is difficult to respond additionally because malicious behavior like Advanced Persistent Threat (APT) attack does not occur immediately, but occurs over a long period of time. In this paper, we propose a technique that detects an unknown attack using an event log without prior knowledge, although the initial response failed with anti-virus. The proposed technology uses a combination of AutoEncoder and 1D CNN (1-Dimention Convolutional Neural Network) based on semi-supervised learning. The experiment trained a dataset collected over a month in a real-world commercial endpoint environment, and tested the data collected over the next month. As a result of the experiment, 37 unknown attacks were detected in the event log collected for one month in the actual commercial endpoint environment, and 26 of them were verified as malicious through VirusTotal (VT). In the future, it is expected that the proposed model will be applied to EDR technology to form a secure endpoint environment and reduce time and labor costs to effectively detect unknown attacks."
비디오 영상을 이용한 3차원 재구성 및 객체 인식 모델 개발,2020,"['합성곱 신경망', '3차원 재구성', '객체 인식 모델', '이미지 증강', 'SURF', 'CNN', '3D Reconstruction', 'Object Recognition Model', 'Image Augmentation']",,"As the content industries developed, the scope of content used expanded from two to three dimensions, and not only experts but also ordinary users wanted to create and use this content. But handling three-dimensional information requires a lot of technology and time. Therefore, this study presents a simple three-dimensional reconstruction method using SfM. When users produce video images in a simple way, datasets are augmented and increased based on this, and then carry out three-dimensional reconstruction using the increased data. It also produces models that recognize three-dimensional objects through CNN learning. In other words, we produced two different results, one dataset and one information extraction process."
Adaptive Importance Channel Selection for Perceptual Image Compression,2020,"['Image compression', 'Auto-encoder', 'Perceptual loss', 'Bit-allocate strategy', 'Importance map']",,"Recently, auto-encoder has emerged as the most popular method in convolutional neural network (CNN) based image compression and has achieved impressive performance. In the traditional auto-encoder based image compression model, the encoder simply sends the features of last layer to the decoder, which cannot allocate bits over different spatial regions in an efficient way. Besides, these methods do not fully exploit the contextual information under different receptive fields for better reconstruction performance. In this paper, to solve these issues, a novel auto-encoder model is designed for image compression, which can effectively transmit the hierarchical features of the encoder to the decoder. Specifically, we first propose an adaptive bit-allocation strategy, which can adaptively select an importance channel. Then, we conduct the multiply operation on the generated importance mask and the features of the last layer in our proposed encoder to achieve efficient bit allocation. Moreover, we present an additional novel perceptual loss function for more accurate image details. Extensive experiments demonstrated that the proposed model can achieve significant superiority compared with JPEG and JPEG2000 both in both subjective and objective quality. Besides, our model shows better performance than the state-of-the-art convolutional neural network (CNN)-based image compression methods in terms of PSNR."
인공지능 시대 예술의 패러다임 전환: 모더니즘 이후 매체 개념의 변화와 에이전트로서의 예술 매체 등장,2020,"['인공지능 예술(AI Art)', '신경망(Neural Network)', '머신러닝(Machine Learning)', '생성적 적대 신경망(GAN: Generative Adversarial Network)', '포스트미디엄(Post-medium)', '예술 매체(art medium)']","본 논문은 인공지능의 창작 논리와 예술 에이전트로서 개념적 해석을 시도하고 매체와 예술가의 관계에서 나타나는 패러다임 전환을 미술사적 견지에서 고찰한다. 예술 창작에 활용되고 있는 합성곱 신경망(CNN), 생성적 적대 신경망(GAN) 등 신경망 인공지능의 기본구조를 분석하고, 학습 데이터의 선택 과정이 미적 특성을 획득하기 위한 중요 과정임을 밝힌다. 더불어 이미지 생성 인공지능을 비디오 신시사이저와 비교해 봄으로써 인공지능의 창작 논리가 물리적 장치의 작동보다는 디지털 코드에 의한 언어적 지시에 있음을 알 수 있다. 이 점은 포스트미디엄 조건의 예술 매체의 패러다임인 기술적 지지체에서 인공 에이전트로의 전환을 의미한다. 로잘린드 크라우스의 확장된 매체의 도식에서 인공지능의 자리를 찾아보면서 그것을 매체 및 설치 개념과 연관시키고 미술 매체의 담론 안으로 끌어들이고자 했다. 크라우스의 아이디어는 인공지능 예술에 대한 해석과 평가에 대한 가능한 틀을 제공한다. 본 논문은 예술 수행의 관습과 관계하는 미술 매체에 대한 기억과 예술 작품에 새겨져서 상기되는 기억에 관한 것이 예술 매체로서 인공지능을 논의하는데 중요한 요소가 될 수 있음을 밝힌다.","This paper examines the role of artificial intelligence (AI) as an artistic agent through its creative logic, and looks into the AI-facilitated paradigm shift in the relation between medium and artist from the perspective of art history. It analyzes the basic structure of neural networks such as Convolutional Neural Network (CNN) and Generative Adversarial Network (GAN), which have often been used to generate creative images. It also notes that the training and evaluation of neural networks with proper sample datasets is a crucial step in selecting the aesthetic features that will compose the generated images. The comparison of deep neural networks with video synthesizers reveals that the creative logic of AI runs on digitally encoded linguistic instructions rather than functioning as a physical apparatus. This means that the paradigm of post-medium art, which has been supported by technological advances, would have to shift further to cover artificial agents. Through an attempt to locate AI in Rosalind Krauss’ diagram of the expanded medium, this paper shed light on the potential linkage of AI to the concepts of medium and installation, and brings AI into the realm of the discourse on art medium."
Identification of Sleep Apnea Severity Based on Deep Learning from a Short-term Normal ECG,2020,"['Automatic Prediction', 'Sleep Apnea', 'Short-term Normal ECG', 'Convolutional Neural Network', 'Deep Learning']",,"Background: This paper proposes a novel method for automatically identifying sleep apnea (SA) severity based on deep learning from a short-term normal electrocardiography (ECG) signal.Methods: A convolutional neural network (CNN) was used as an identification model and implemented using a one-dimensional convolutional, pooling, and fully connected layer.An optimal architecture is incorporated into the CNN model for the precise identification of SA severity. A total of 144 subjects were studied. The nocturnal single-lead ECG signal was collected, and the short-term normal ECG was extracted from them. The short-term normal ECG was segmented for a duration of 30 seconds and divided into two datasets for training and evaluation. The training set consists of 82,952 segments (66,360 training set, 16,592 validation set) from 117 subjects, while the test set has 20,738 segments from 27 subjects.Results: F1-score of 98.0% was obtained from the test set. Mild and moderate SA can be identified with an accuracy of 99.0%.Conclusion: The results showed the possibility of automatically identifying SA severity based on a short-term normal ECG signal."
표면 결함 분류를 위한 적정 규모의 딥러닝 모델,2020,"['Deep learning', 'Convolutional neural network', 'Appropriate Scaled Model', 'Surface Defects Detection']",,"In this paper, we propose a method of surface defect image classification for metal cases using a Convolutional Neural Network (CNN) deep learning model. We show the feasibility and effectiveness of our appropriate scaled CNN model using real-word data on metal case images with and without defects under different surface and lighting conditions. In addition, we analyze learning behaviors on three different data sets. The results of our work in this study have the potential to have a significant impact on the manufacturing industry"
Experiment on Intermediate Feature Coding for Object Detection and Segmentation,2020,"['Deep learning', 'intermediate features', 'video coding for machine', 'object detection', 'object segmentation']",,"With the recent development of deep learning, most computer vision-related tasks are being solved with deep learning-based network technologies such as CNN and RNN. Computer vision tasks such as object detection or object segmentation use intermediate features extracted from the same backbone such as Resnet or FPN for training and inference for object detection and segmentation. In this paper, an experiment was conducted to find out the compression efficiency and the effect of encoding on task inference performance when the features extracted in the intermediate stage of CNN are encoded. The feature map that combines the features of 256 channels into one image and the original image were encoded in HEVC to compare and analyze the inference performance for object detection and segmentation. Since the intermediate feature map encodes the five levels of feature maps (P2 to P6), the image size and resolution are increased compared to the original image. However, when the degree of compression is weakened, the use of feature maps yields similar or better inference results to the inference performance of the original image."
Staff-line Removal for Music Score Images using U-net,2020,"['악보영상', '심층뉴럴네트워크', 'U-net', '오선제거', 'music score image', 'deep neural network', 'staff line removal']",악보영상의 오선제거는 악보 인식의 향후 과정에 영향을 미치므로 중요한 문제이다. 본 논문에서는 두가지 단계로 구성된 악보영상의 오선제거에 대한 새로운 방법을 제시한다. 먼저 super-resolution을 이용하여 입력영상의 화질을 개선한다. 오선제거 성능은 많은 경우 입력영상의 화질에 좌우된다. 그리고 나서 전통적인 심층학습네트워크인 CNN 대신 U-net을 이용하여 오선제거를 시도한다. U-net은 객체분할에 좋은 성능을 보이는 심층신경망으로 알려져 있으며 본 논문에서는 이러한 객체추출 및 분할성능에 탁월한 U-net을 활용함으로써 성능을 개선하고자 한다. 제안된 방법은 ICDAR/GREC 자료셋에 대하여 실험을 수행하였으며 기존방법보다 우수한 결과를 생성하였다.,"Staff- line removal from the music score images is important because it directly influences the subsequent procedures for music score recognition. We propose a novel technique for staff-line removal in music score images, which is is composed of two steps. Firstly, a super-resolution method to enhance the quality of music photos is is used as a preprocessing step. The performance of the staff- line removal task is often dependent on the quality of the original music score image, hence, the preprocessing can enhance the staff- line removal performance. Then, a modified U-net model is is used, instead of conventional Convolutional Neural Network (CNN), to remove staff lines from previously enhanced images. U-net has been proved proven to be an effective deep neural network model, particularly in object image segmentation, which has been adopted for staff-line extraction and removal. The proposed approach is is evaluated on the ICDAR/GREC dataset and the experiment showss an improved results than compared to existing methods."
딥러닝을 이용한 장기 파랑예측 가능성 연구,2020,"['Deep learning', 'Convolutional neural network', 'Wave prediction', 'Xception']",,"Numerical wave prediction models require a large amount of computational power to timely complete the required calculations. Artificial Neural Networks (ANN) have been introduced to perform predictions at a lesser computational cost and increased processing speed. Deep learning and specifically Convolutional Neural Networks (CNN) have become accepted for various image recognition applications. Motivation for the examination of wave prediction by deep learning came from the success of CNN in vision applications and the similarity of meteorological weather grid data to visual images. This study investigates a deep learning technique using the Japan Meteorological Agency’s Grid Point Value Mesoscale Model to predict wave height and period. In particular, this study uses the Xception deep learning architecture with depthwise separable convolution to obtain improved wave height and period prediction over artificial neural networks, and gets overall success results."
볼트의 소리 신호를 이용한 합성곱 신경망 기반 체결력 측정 방법,2020,"['Clamping Force(체결력)', 'Convolutional Neural Network(합성곱 신경망)', 'Bolt(볼트)', 'Sound Signal(소리신호)']",,"This paper presents a novel method for measuring the clamping force using sound that occurs during bolt fastening. The resonance frequency of the bolt increases with the progress of the fastening process. This characteristic change is utilized as the feature analyzed by a convolutional neural network (CNN). The clamping force is measured using a load cell, and is then used during labeling for classification. To measure the radiated noise, a microphone is installed near the fastening part. In addition, a signal-processing method is proposed to apply the measurement to deep-learning classification and perform data augmentation. The CNN architecture was modeled, and the fastening force was determined using the classification method. The estimated value was compared with the actual load cell measurements."
인공지능 기반의 스마트 헬스케어 운동관리를 위한 애플리케이션 구현,2020,"['AI', 'Deep Learning', 'PoseNet', 'Fitness', 'Healthcare']","스마트폰을 활용하여 개인의 건강을 실시간 관리하는 트렌드의 확산과 더불어 헬스케어 관련 디바이스가 많은 관심을 받고 있지만, 현재는 사용자가 비디오 콘텐츠나 피트니스 앱을 통한 강사 따라하기형에 많이 의존하고 있다. 본 연구에서는 인공지능(Artificial Intelligence:AI) 합성신경망(Convolutional Neural Network:CNN) 모델인 PoseNet을 활용하여 자세 추정 학습을 하고 이를 통한 인체 좌표를 분석하여 동작의 일환으로 손뼉치기를 구현하며, 그 결과값을 신진대사 해당치(Metabolic Equivalent of Task, MET)로 환산하여 보여주는 스마트 헬스케어 운동관리 시스템을 애플리케이션으로 구현하고자 한다. 특히, PoseNet은 카메라 기능이 지원되는 디바이스가 있다면 언제 어디서든 브라우저를 통해 실시간 자세 추정을 통한 동작 분석으로 MET를 활용한 사용자의 운동 칼로리 소모량을 파악하는 도구로서 효과적이며, 헬스케어 플랫폼의 많은 기능 중 스마트 헬스케어 서비스를 개발하고자 하는 목적에 상당히 부합하는 모델이라 그 활용성이 매우 클 것으로 판단된다.","With the spread of the trend of real-time management of personal health using smartphones, and healthcare-related devices are receiving a lot of attention, users are now relying heavily on following the instructor through video content or fitness apps. In this study, the Artificial Intelligence (AI) Convolutional Neural Network (CNN) model, PoseNet, is used to learn pose estimation, analyze human coordinates through this, and implement clapping as part of the motion. We intend to convert the value into the Metabolic Equivalent of Task (MET) and it is also intended to be implemented as a smart healthcare exercise management system application. In particular, PoseNet is effective as a method for determining the calorie consumption of a user's exercise using MET for the motion analysis of real-time pose estimation through a browser, whenever and wherever a device with a camera function is supported. Thus, PoseNet can be considered to be very useful, since it is a model that satisfies the purpose of developing smart healthcare services."
다양한 합성곱 신경망 방식을 이용한 모바일 기기를 위한 시작 단어 검출의 성능 비교,2020,"['성능 비교', '시작 단어 검출', '합성곱 신경망', '인공지능 비서', 'Performance comparison', 'Wake-up-word detection', 'Convolutional neural network', 'Artificial Intelligence (AI) assistant']","음성인식 기능을 제공하는 인공지능 비서들은 정확도가 뛰어난 클라우드 기반의 음성인식을 통해 동작한다.클라우드 기반의 음성인식에서 시작 단어 인식은 대기 중인 기기를 활성화하는 데 중요한 역할을 한다. 본 논문에서는공개 데이터셋인 구글의 Speech Commands 데이터셋을 사용하여 스펙트로그램 및 멜-주파수 캡스트럼 계수 특징을입력으로 하여 모바일 기기에 대응한 저 연산 시작 단어 검출을 위한 합성곱 신경망의 성능을 비교한다. 본 논문에서사용한 합성곱 신경망은 다층 퍼셉트론, 일반적인 합성곱 신경망, VGG16, VGG19, ResNet50, ResNet101, ResNet152, MobileNet이며, MobileNet의 성능을 유지하면서 모델 크기를 1/25로 줄인 네트워크도 제안한다.","Artificial intelligence assistants that provide speech recognition operate through cloud-based voice recognition with high accuracy. In cloud-based speech recognition, Wake-Up-Word (WUW) detection plays an important role in activating devices on standby. In this paper, we compare the performance of Convolutional Neural Network (CNN)-based WUW detection models for mobile devices by using Google's speech commands dataset, using the spectrogram and mel-frequency cepstral coefficient features as inputs. The CNN models used in this paper are multi-layer perceptron, general convolutional neural network, VGG16, VGG19, ResNet50, ResNet101, ResNet152, MobileNet. We also propose network that reduces the model size to 1/25 while maintaining the performance of MobileNet is also proposed."
딥러닝을 이용한 이미지 레이블 추출 기반 해시태그 추천 시스템 설계 및 구현,2020,"['소셜 미디어', '레이블 추출', '태그 추천', '딥 러닝', '인공 지능', 'Social Medea', 'Label Extraction', 'Tag Recommendation', 'Deep Learning', 'AI']","소셜 미디어에서 일반적으로 게시물을 올릴 때 이미지의 태그 정보를 사용하는데, 태그를 이용하여 주로 검색이 이루어지기 때문이다. 사용자는 태그를 게시물에 붙임으로써 게시물을 많은 사람들에게 노출시키길 원한다. 또한, 사용자는 게시물과 함께 태깅될 태그를 붙이는 행위를 번거롭게 여겨 태깅하지 않은 게시물도 올리게 된다. 본 논문에서는 입력 이미지와 유사한 이미지를 찾아 해당 이미지에 부착된 레이블을 추출하여 그 레이블이 태그로 존재하는 인스타그램의 게시물들을 찾아 게시물 속 존재하는 다른 태그들을 추천해주는 방법을 제안한다. 제안하는 방법에서는 CNN(Convolutional Neural Network) 딥러닝 기법의 모델을 통하여 이미지로부터 레이블을 추출하여 추출된 레이블로 인스타그램을 크롤링하여 레이블 외의 태그를 정렬하여 추천해준다. 추천된 태그를 이용하여 이미지를 게시하기도 편해지고, 검색의 노출을 높일 수 있고, 검색오류가 적어 높은 정확도를 도출할 수 있음을 알 수 있다.","In social media, when posting a post, tag information of an image is generally used because the search is mainly performed using a tag. Users want to expose the post to many people by attaching the tag to the post. Also, the user has trouble posting the tag to be tagged along with the post, and posts that have not been tagged are also posted. In this paper, we propose a method to find an image similar to the input image, extract the label attached to the image, find the posts on instagram, where the label exists as a tag, and recommend other tags in the post. In the proposed method, the label is extracted from the image through the model of the convolutional neural network (CNN) deep learning technique, and the instagram is crawled with the extracted label to sort and recommended tags other than the label. We can see that it is easy to post an image using the recommended tag, increase the exposure of the search, and derive high accuracy due to fewer search errors."
소스코드 취약성 분류를 위한 기계학습 기법의 적용,2020,"['Secure Coding', 'Static Analysis', 'Machine Learning']","시큐어코딩은 악의적인 공격 혹은 예상치 못한 오류에 대한 강인함을 제공해줄 수 있는 안전한 코딩 기법으로 정적분석도구의 지원을 통해 취약한 패턴을 찾아내거나 오염 데이터의 유입 가능성을 발견한다. 시큐어코딩은 정적기법을 적극적으로 활용하는 만큼 룰셋에 의존적이라는 단점을 가지며, 정적분석 도구의 복잡성이 높아지는 만큼 정확한 진단이 어렵다는 문제점을 안고 있다. 본 논문은 시큐어코딩을 지원하는 목적으로 기계학습 기법 중 DNN과 CNN, RNN 신경망을 이용하여 개발보안가이드 상의 주요 보안약점에 해당하는 패턴을 학습시키고 분류하는 모델을 개발하며 학습 결과를 분석한다. 이를 통해 기계학습 기법이 정적분석과 더불어 보안약점 탐지에 도움을 줄 수 있을 것으로 기대한다.","Secure coding is a technique that detects malicious attack or unexpected errors to make software systems resilient against such circumstances. In many cases secure coding relies on static analysis tools to find vulnerable patterns and contaminated data in advance. However, secure coding has the disadvantage of being dependent on rule-sets, and accurate diagnosis is difficult as the complexity of static analysis tools increases. In order to support secure coding, we apply machine learning techniques, such as DNN, CNN and RNN to investigate into finding major weakness patterns shown in secure development coding guides and present machine learning models and experimental results. We believe that machine learning techniques can support detecting security weakness along with static analysis techniques."
수정된 MobileNet을 이용한 과일의 결점 분류 알고리즘,2020,"['fruit quality', 'defect classification', 'camera', 'MobileNet', 'deep learning']",,"The presence of one or a few defective fruits in a fruit package reduces the commercial value of the fruit. Currently, defected fruits are being sorted by naked eyes. However, the lack of objectivity by the conventional sort method and decrease in farming population are becoming problems. Various image processing methods have been introduced to overcome these problems. The convolutional neural network (CNN), an enhanced image processing method, provides an efficient solution for sorting the defective fruits. Recently, MobileNet has been proposed to incorporate CNN in a device with low arithmetic performance. Nevertheless, when it is used to sort defective fruits, there is a possibility of identifying good fruits as defected ones. Therefore, the thesis proposes a revised MobileNet algorithm that can be applied to a high-speed fruit sort machine that is being used in the industry as of now. Moreover, it is to prove the usefulness of the proposed algorithm through a performance evaluation."
Estimation and Comparison of Cortical Thickness Index and Canal‑to‑Calcar Ratio Using Manual Method and Deep Learning Method,2020,['Dorr classifcation · Canal-to-Calcar ratio · Cortical Thickness Index · Total hip arthroplasty · Deep learning'],,"Manual calculation of the cortical thickness index (CI) and canal-to-calcar ratio (CC) using radiographs has been widely used. The purpose of this study was to investigate the diference between manual gold standard and automatic calculation based on deep convolutional neural networks (CNNs) of the proximal femur. We obtained institutional review board approval to utilize previous radiographs for the study and the radiograph images were used to train CNN architecture. The calculation experiment of a dataset of 136 images of the proximal femur to estimate CI and CC was performed using a trained CNN architecture (Automatic). Also, manual segmentation method (Manual) to calculate CI and CC was conducted using the standard protocol by two experts as a reference for the results comparison. The mean values of the Manual and Automatic calculation of CI for the proximal femur were 0.56 and 0.54, respectively, showing a statistically signifcant diference (p=0.035).Signifcant diference (p<0.001) was also seen in the calculation of CC by Manual and Automatic method resulting in 0.42 and 0.47, respectively. In addition, the automatic method showed far better results in terms of calculation speed (less than 30 s per single image). Therefore, we suggest that the manual method be carefully considered while planning a surgery."
충실도 높은 기침 소리 생성을 위한 개선된 GAN,2020,"['Generative Adversarial Network', 'generative model', 'sound data', 'cough sound', 'high-fidelity', '생성적 적대 신경망', '생성 모델', '소리 데이터', '기침 소리', '높은 충실도']","GAN(Generative Adversarial Network)은 컴퓨터 비전 분야에서 큰 인기를 얻었고, 이미지 생성 작업에널리 사용되고 있다. 그리고 최근, GAN 연구자들은 GAN을 사용하여 소리 데이터를 생성하기 시작했다. 파형은 이미지와 다르게 이산 값으로 구성된 신호이므로, 이미지 학습에 주로 사용하는 CNN(Convolutional Neural Network)을 활용하여 파형을 학습하기 어렵다. 이를 극복하기 위하여, GAN 연구자들은 기존 이미지생성 GAN을 재사용하여 파형 대신 시간-주파수 표현을 학습하는 접근을 제안했다. 이러한 접근을 따라서, 본 논문은 생성된 파형의 충실도(fidelity)를 개선하기 위한 개선된 소리 생성 GAN을 제안한다. 개선된 GAN 은 HPSS(Harmonic Percussive Source Separation)를 사용해 시간에 따른 스펙트럼의 특징을 추출하고, 점진적으로 성장하는 네트워크를 통해 생성되는 파형의 품질을 개선하는 특징이 있다. 본 논문에서는 공개된 기침데이터세트를 사용해 제안한 GAN을 학습시키고, 충실도와 다양성(diversity) 측면에서 성능을 평가한다.","Generative Adversarial Networks (GANs) have gained tremendous popularity in computer vision, and have been widely used for image generation tasks. Recently, GAN researchers have started generating sound data by using GANs. Unlike images, a waveform is a sampled signal consisting of discrete samples, so it is not easy to learn the waveform by utilizing Convolutional Neural Network (CNN), which is mainly trained on natural images. To overcome this difficulty, GAN researchers proposed an approach employing time-frequency representations instead of time-series waveforms to reuse existing image-generating GANs. Following this approach, we propose an improved sound-generating GAN to improve the fidelity of generated waveforms. We designed a network that first uses Harmonic Percussive Source Separation (HPSS) to extract spectral features over time and then improves the quality of generated waveforms by applying progressively-growing networks. In this paper, we train our GAN on a public cough dataset and evaluate the performances in terms of the fidelity and diversity of generated waveforms."
Lip-reading System based on Bayesian Classifier,2020,"['베이지안 분류', '독순술', '모음 인식', '얼굴 랜드마크', '기계 학습', 'Bayesian classifier', 'Lip-reading', 'Recognition of vowel pronunciation', 'Facial landmark', 'Machine learning']","음성 정보를 배제하고 영상 정보만을 이용한 발음 인식 시스템은 다양한 맞춤형 서비스에 적용될 수 있다. 본 논문에서는 베이지안 분류기를 기반으로 입술 모양을 인식하여 한글 모음을 구분하는 시스템을 개발한다. 얼굴 이미지의 입술 모양에서 특징 벡터를 추출하고 설계된 기계 학습 모델을 적용하여 실험한 결과 ‘ㅏ’ 발음의 경우 94%의 인식률을 보였으며, 평균 인식률은 약 84%를 나타내었다. 또한 비교군으로 실험한 CNN 환경에서의 인식률보다 높은 결과를 보였다. 이를 통해서 입술 영역의 랜드 마크로 설계된 특징 값을 사용하는 베이지안 분류 기법이 적은 수의 훈련 데이터에서 보다 효율적일 수 있음을 알 수 있다. 따라서 모바일 디바이스와 같은 제한적 하드웨어에서 응용 가능한 어플리케이션 개발에 활용할 수 있다.","Pronunciation recognition systems that use only video information and ignore voice information can be applied to various customized services. In this paper, we develop a system that applies a Bayesian classifier to distinguish Korean vowels via lip shapes in images. We extract feature vectors from the lip shapes of facial images and apply them to the designed machine learning model. Our experiments show that the system’s recognition rate is 94% for the pronunciation of ‘A’, and the system’s average recognition rate is approximately 84%, which is higher than that of the CNN tested for comparison. Our results show that our Bayesian classification method with feature values from lip region landmarks is efficient on a small training set. Therefore, it can be used for application development on limited hardware such as mobile devices."
Low-Quality Banknote Serial Number Recognition Based on Deep Neural Network,2020,"['Banknote Recognition', 'Convolutional Neural Network', 'Machine Learning', 'Optical Character Recognition', 'Serial Number Recognition']",,"Recognition of banknote serial number is one of the important functions for intelligent banknote counterimplementation and can be used for various purposes. However, the previous character recognition method islimited to use due to the font type of the banknote serial number, the variation problem by the solid status, andthe recognition speed issue. In this paper, we propose an aspect ratio based character region segmentation anda convolutional neural network (CNN) based banknote serial number recognition method. In order to detect thecharacter region, the character area is determined based on the aspect ratio of each character in the serial numbercandidate area after the banknote area detection and de-skewing process is performed. Then, we designed andcompared four types of CNN models and determined the best model for serial number recognition.Experimental results showed that the recognition accuracy of each character was 99.85%. In addition, it wasconfirmed that the recognition performance is improved as a result of performing data augmentation. Thebanknote used in the experiment is Indian rupee, which is badly soiled and the font of characters is unusual,therefore it can be regarded to have good performance. Recognition speed was also enough to run in real timeon a device that counts 800 banknotes per minute."
Automated Detection of Surface Cracks and Numerical Correlation with Thermal‑Structural Behaviors of Fire Damaged Concrete Beams,2020,"['fire', 'crack', 'RC beam', 'deep learning', 'convolutional neural network', 'edge detection']",,"There are two specific aims in this study; first is to develop and validate an automated crack detection technique for the fire damaged beam. Second is to investigate whether the detected crack information and thermal-structural behaviors can be numerically related. To fulfill the aims, fire tests and residual strength tests are conducted on RC beams having different fire exposure time periods and sustained load levels. To detect the automated cracks, surface images of the fire damaged beam surfaces are taken with digital cameras and an automatic crack detection method is developed using a convolutional neural network (CNN) which is a deep learning technique primarily used for analyzing intricate structures of high-dimensional data [such as high definition (HD) images and videos]. The quantity of cracks detected using the proposed CNN changes depending on the test variables, and the changing trends are similar to those of the crack lengths obtained from the optical observation. Additionally, it is found that the quantity of the automatically detected cracks is numerically related to the temperatures inside the beams as well as the stiffnesses obtained from the residual strength tests."
진동수 영역의 분광학 스펙트럼 분석을 위한 심층 기계학습 모델 적용,2020,"['광전자 분광학', '기계 학습', '심층 신경망', 'Photoemission spectroscopy', 'Machine learning', 'Deep neural network']","최근 들어 학계 및 산업계에서는 데이터 사이언스를 이용한 물질 분석 및 신물질 디자인이 중요한 연구주제로 떠오르고 있으며, 이를 위한 필수 요소 중 하나는 실험적 분광학 결과 및 제일원리 전자구조계산결과에 대한 고속대량 데이터 스크리닝 작업이다. 이러한 작업에는 대량의 실험적 분광학 데이터와제일원리 전자구조계산 결과들로부터 유용한 정보들을 최소한의 인간의 개입만으로 추출할 수 있는기계학습 기반 방법론이 필수적이다. 이를 위하여, 본 연구에서는 1차원 진동수 영역에서의 광전자 분광학(photoemission spectroscopy, PES) 실험 결과들을 입력받아, 이로부터 전자의 여기 에너지, 여기 상태의수 및 각 PES 피크의 에너지 폭을 얻어 내는 심층 신경망 모델을 만들고 훈련시켜 보았다. 본 모델에서는1차원 합성곱 신경망(convolution neural network, CNN)을 완전연결 신경망(fully-connected layers, FCL)과 조합하여 사용하였으며, 훈련된 모델은 Poly(3-hexylthiophene) (P3HT) 분자 내 황의 2p 상태및 인듐 주석 산화물 내 산소의 1s 상태로부터의 PES 스펙트럼을 분석하는데 사용되었다. 마지막으로현재의 모델을 보다 개선하기 위한 방법에 대한 논의를 덧붙인다.","A data-driven study of material properties and functional materials design based on it requires high-throughput and comparative analyses of the results of experimental spectroscopy with those from first-principles electronic structure calculations. Hence, an efficient machine-learning-based computational tool to extract electronic structure information from experimental data without human intervention is in high demand. Here, we test the capability of deep neural network models to fit photoemission spectroscopy (PES) data in the frequency domain with unknown PES peak positions, numbers, and widths. A one-dimensional convolution neural network (CNN) was employed in combination with fully connected layers (FCL), and the trained model was applied to photoemission spectra for the sulfur 2p states in poly(3-hexylthiophene) (P3HT) molecules and oxygen 1s states in indium tin oxide (ITO). We conclude by further discussing potential ways to improve the performance of the model."
딥러닝 기반 음향 신호 대역 확장 시스템,2020,"['Audio', 'Bandwidth Extension', 'Deep Learning', 'Convolutional Neural Network', 'Autoencoder']","대역 확장(Bandwidth Extension)이란 채널 용량 부족 혹은 이동통신 기기에 탑재된 코덱의 특성으로 인해 부호화 및 복호화 과정에서 대역 제한(band limited)되거나 손상된 협대역 신호(NB, Narrow Band)를 복원, 확장하여 광대역 신호(WB, Wide Band)로 전환 시켜주는 것을 의미한다. 대역 확장 연구는 주로 음성 신호 위주로 대역 복제(SBR, Spectral Band Replication), IGF(Intelligent Gap Filling)과 같이 고대역을 주파수 영역으로 변환하여 복잡한 특징 추출 과정을 거쳐 이를 바탕으로 사라지거나 손상된 고대역을 복원한다. 본 논문에서는 딥러닝 모델 중 오토인코더(Autoencoder)를 바탕으로 1차원 합성곱 신경망(CNN, Convolutional Neural Network)들의 잔차 연결을 활용하여 복잡한 사전 전처리 과정 없이 일정한 길이의 시간 영역 신호를 입력시켜 대역 확장 시킨 음향 신호를 출력하는 모델을 제안한다. 또한 음성 영역에 제한되지 않는 음악을 포함한 여러 종류의 음원을 포함하는 데이터셋에 훈련시켜도 손상된 고대역을 복원할 수 있음을 확인하였다.","Bandwidth Extension refers to restoring and expanding a narrow band signal(NB) that is damaged or damaged in the encoding and decoding process due to the lack of channel capacity or the characteristics of the codec installed in the mobile communication device. It means converting to a wideband signal(WB). Bandwidth extension research mainly focuses on voice signals and converts high bands into frequency domains, such as SBR (Spectral Band Replication) and IGF (Intelligent Gap Filling), and restores disappeared or damaged high bands based on complex feature extraction processes. In this paper, we propose a model that outputs an bandwidth extended signal based on an autoencoder among deep learning models, using the residual connection of one-dimensional convolutional neural networks (CNN), the bandwidth is extended by inputting a time domain signal of a certain length without complicated pre-processing. In addition, it was confirmed that the damaged high band can be restored even by training on a dataset containing various types of sound sources including music that is not limited to the speech."
U-net을 이용한 악보영상의 오선제거,2020,"['music score image', 'deep neural network', 'U-net', 'staff line removal', '악보영상', '심층뉴럴네트워크', 'U-net', '오선제거']",악보영상의 오선제거는 악보 인식의 향후 과정에 영향을 미치므로 중요한 문제이다. 본 논문에서는 두가지 단계로 구성된 악보영상의 오선제거에 대한 새로운 방법을 제시한다. 먼저 super-resolution 을 이용하여 입력영상의 화질을 개선한다. 오선제거 성능은 많은 경우 입력영상의 화질에 좌우된다. 그리고 나서 전통적인 심층학습네트워크인 CNN 대신 U-net을 이용하여 오선제거를 시도한다. U-net은 객체분할에 좋은 성능을 보이는 심층신경망으로 알려져 있으며 본 논문에서는 이러한 객체추출 및 분할성능에 탁월한 U-net을 활용함으로써 성능을 개선하고자 한다. 제안된 방법은 ICDAR/GREC 자료셋에 대하여 실험을 수행하였으며 기존방법보다 우수한 결과를 생성하였다.,"Staff- line removal from the music score images is important because it directly influences the subsequent procedures for music score recognition. We propose a novel technique for staffline removal in music score images, which is is composed of two steps. Firstly, a super-resolution method to enhance the quality of music photos is is used as a preprocessing step. The performance of the staff- line removal task is often dependent on the quality of the original music score image, hence, the preprocessing can enhance the staff- line removal performance. Then, a modified U-net model is is used, instead of conventional Convolutional Neural Network (CNN), to remove staff lines from previously enhanced images. U-net has been proved proven to be an effective deep neural network model, particularly in object image segmentation, which has been adopted for staff-line extraction and removal. The proposed approach is is evaluated on the ICDAR/GREC dataset and the experiment showss an improved results than compared to existing methods."
모션 인식을 위한 2D 자세 추정 알고리듬의 이미지 전처리 및 얼굴 가림에 대한 영향도 분석,2020,"['Pose Estimation', 'OpenPose', 'Image Preprocessing', 'Image Filtering', 'Face Covering']","제조 산업에서 인력은 로봇으로 대체되지만 전문 기술은 데이터 변환이 어려워 산업용 로봇에 적용이 불가능하다. 이는 비전 기반의 모션 인식 방법으로 데이터 확보가 가능하나 이미지 데이터에 따라 판단 값이 달라질 수 있다. 따라서 본 연구는 비전 방법을 사용해 사람의 자세를 추정 시 영향을 미치는 인자를 고려해 정확성 향상 방법을 찾고자 한다. 비전 방법 중 OpenPose의 3가지 모델 MPII, COCO 및 COCO + foot을 사용했으며, CNN(Convolutional Neural Networks)을 사용한 OpenPose 구조에서 얼굴 가림 및 이미지 전처리에 미치는 영향을 확인하고자 액세서리의 유무, 이미지 크기 및 필터링을 매개 변수로 설정했다. 각 매개 변수 별 이미지 데이터를 3 가지 모델에 적용해 실제 값과 예측 값 사이 거리 오차와 PCK (Percentage of correct Keypoint)로 영향도를 판단했다. 그 결과 COCO + foot 모델은 3 가지 매개 변수에 대한 민감도가 가장 낮았다. 또한 이미지 크기는 50% (원본 3024 × 4032에서 1512 × 2016로 축소) 이상 비율이 가장 적절하며, MPII 모델만 emboss 필터링을 적용할 때 거리 오차 평균이 최대 60pixel 감소되어 향상된 결과를 얻었다.","In manufacturing, humans are being replaced with robots, but expert skills remain difficult to convert to data, making them difficult to apply to industrial robots. One method is by visual motion recognition, but physical features may be judged differently depending on the image data. This study aimed to improve the accuracy of vision methods for estimating the posture of humans. Three OpenPose vision models were applied: MPII, COCO, and COCO+foot. To identify the effects of face-covering accessories and image preprocessing on the Convolutional Neural Network (CNN) structure, the presence/non-presence of accessories, image size, and filtering were set as the parameters affecting the identification of a human's posture. For each parameter, image data were applied to the three models, and the errors between the actual and predicted values, as well as the percentage correct keypoints (PCK), were calculated. The COCO+foot model showed the lowest sensitivity to all three parameters. A <50% (from 3024×4032 to 1512×2016 pixels) reduction in image size was considered acceptable. Emboss filtering, in combination with MPII, provided the best results (reduced error of <60 pixels)."
인지 무선 통신을 위한 순환 신경망 기반 스펙트럼 센싱 기법,2020,[],,"This paper proposes a new Recurrent neural network (RNN) based spectrum sensing technique for cognitive radio communications. The proposed technique determines the existence of primary user's signal without any prior information of the primary users. The method performs high-speed sampling by considering the whole sensing bandwidth and then converts the signal into frequency spectrum via fast Fourier transform (FFT). This spectrum signal is cut in sensing channel bandwidth and entered into the RNN to determine the channel vacancy. The performance of the proposed technique is verified through computer simulations. According to the results, the proposed one is superior to more than 2 [dB] than the existing threshold-based technique and has similar performance to that of the existing Convolutional neural network (CNN) based method. In addition, experiments are carried out in indoor environments and the results show that the proposed technique performs more than 4 [dB] better than both the conventional threshold-based and the CNN based methods."
시각장애인을 위한 인공지능 관련 연구 동향 : 1993-2020년 국내·외 연구를 중심으로,2020,"['시각장애인', '인공지능', '머신러닝', '딥 러닝', '연구 동향', 'The Visually Impaired', 'AI', 'Artificial Intelligence', 'Machine Learning', 'Deep Learning', 'Research Trend']","본 연구는 시각장애인 대상의 인공지능 관련 연구 동향을 살펴보기 위해 1993년부터 2020년 8월까지 국내·외 논문 총 68편을 선정하여 연도별 논문 게재 수, 연구방법, 연구주제, 키워드 분석 현황, 연구유형, 구현방법별 비교·분석하였다. 연구결과, 연구기간 내 논문 편수는 꾸준히 증가하는 것처럼 보였으나 국내 연구의 경우에는 2016년도 이후에 활발해진 것을 알 수 있었다. 연구방법으로는 국내·외 연구 모두 개발연구가 89.7%를 차지했고, 키워드는 국내 연구에서는 Visually impaired, Deep learning, Assistive device 순이였으며 국외 연구에서는 Visually impaired, Deep learning, Artificial intelligence 순으로 단어 빈도순에서 차이를 보였다. 연구유형은 국내·외 모두 설계, 개발, 구현이 대부분을 차지했으며 구현방법으로는 국내 연구의 구현방법으로는 System 13.2%, Solution 7.4%, App. 4.4% 순이였으며 국외 연구의 구현방법으로는 System 32.4%, App.13.2%, Device 7.4%로 다소 차이를 보였다. 구현방법의 적용 기술로는 국내 연구는 YOLO 2.7%, TTS 2.1%, Tensorflow 2.1% 순이였으며 국외 연구에서는 CNN 8.0%, TTS 5.3%, MS-COCO 4.3% 순으로 사용횟수가 높았다. 본 연구는 시각장애인 대상의 인공지능 관련 연구 동향을 비교·분석하여 국내·외 연구의 현주소를 바로 알고 앞으로 시각장애인을 위한 인공지능 연구의 방향을 제시하고자 하였다.","In this study, a total of 68 domestic and international papers were selected from 1993 to August 2020 in order to examine the research trends related to artificial intelligence for the visually impaired. The papers were compared and analyzed by the number of papers published by year, research method, research topic, keyword analysis status, research type, and implementation method. As a result of the study, the number of papers during the study period seemed to increase steadily. But in the case of domestic research, It can be seen that it has become active since 2016. As for research methods, development research accounted for 89.7% of both domestic and foreign research. Keywords was in Visually Impaired, Deep Learning, and Assistive Device order in domestic research. And it was in Visually Impaired, Deep learning, Artificial intelligence order in foreign research. There was a difference in the frequency of words. Research type were Design, development and implementation both in domestic and foreign. Implementation method were in System 13.2%, Solution 7.4%, App. 4.4% order in domestic research, and it was in System 32.4%, App. 13.2%, Device 7.4% order in foreign research. As for the applied technology of the implementation method, were in YOLO 2.7%, TTS 2.1%, Tensorflow 2.1% order in domestic research, and it was used in CNN 8.0%, TTS 5.3%, MS-COCO 4.3% order in foreign research. The purpose of this study was to compare and analyze the trends of artificial intelligence-related research targeting the visually impaired, to immediately know the current status of domestic and foreign research, and to present the direction of artificial intelligence research for the visually impaired in the future."
딥 러닝 기반 실시간 센서 고장 검출 기법,2020,"['Sensor fault diagnosis', 'Convolution neural network', 'Inverted residual block', 'Raspberry pi']","최근 4차 산업혁명의 핵심기술인 인공지능, 빅데이터, 사물인터넷의 발전으로 산업 현장에서 가동되는 기계의자동화 및 무인화에 대한 연구가 활발히 진행되고 있다. 이러한 공정 기계들은 부착된 다양한 센서들로부터 수집된 데이터를 기반으로 제어되고 이를 통해 공정이 관리된다. 만약 센서에 고장이 발생한다면 센서 데이터 이상으로 인해 자동화기계들이 오작동함으로써 공정 손실 발생뿐만 아니라 인명피해로도 이어질 수 있다. 전문가가 센서의 이상 여부를 주기적으로 확인하여 관리하고 있으나 산업 현장의 여러 가지 환경요인 및 상황으로 인하여 고장점검 시기를 놓치거나 고장을 발견하지 못하여 센서 고장으로 인한 피해를 막지 못하는 경우가 발생하고 있다. 또한 고장이 발생하여도 즉각 감지하지 못함으로써 공정 손실을 더욱 악화시키고 있는 실정이다. 따라서 이러한 돌발적인 센서 고장으로 인한 피해를 막기위해 자체적으로 임베디드 시스템에서 센서의 고장 유무를 실시간으로 파악하고 빠른 대응을 위해 고장 진단 및 유형을판별하는 것이 필요하다. 본 논문에서는 대표적인 센서 고장 유형인 erratic fault, hard-over fault, spike fault, stuck fault를 분류하기 위해 딥 뉴럴 네트워크 기반의 고장 진단 시스템을 설계하고 라즈베리 파이를 활용하여 구현하였다. 센서 고장 진단을 위해 구글이 제안한 MobilieNetV2의 Inverted residual block 구조를 사용하여 네트워크를구성하였다. 본 논문에서 제안하는 방식은 기존 CNN 기법을 사용한 경우보다 메모리 사용량이 줄고 성능이 향상되며, 입력 신호에 대해 구간별로 센서 고장을 분류하여 산업 현장에서 효과적으로 사용될 것으로 기대된다.","Recently, research on automation and unmanned operation of machines in the industrial field has been conducted with the advent of AI, Big data, and the IoT, which are the core technologies of the Fourth Industrial Revolution. The machines for these automation processes are controlled based on the data collected from the sensors attached to them, and further, the processes are managed.Conventionally, the abnormalities of sensors are periodically checked and managed. However, due to various environmental factors and situations in the industrial field, there are cases where the inspection due to the failure is not missed or failures are not detected to prevent damage due to sensor failure.In addition, even if a failure occurs, it is not immediately detected, which worsens the process loss.Therefore, in order to prevent damage caused by such a sudden sensor failure, it is necessary to identify the failure of the sensor in an embedded system in real-time and to diagnose the failure and determine the type for a quick response. In this paper, a deep neural network-based fault diagnosis system is designed and implemented using Raspberry Pi to classify typical sensor fault types such as erratic fault, hard-over fault, spike fault, and stuck fault. In order to diagnose sensor failure, the network is constructed using Google's proposed Inverted residual block structure of MobilieNetV2. The proposed scheme reduces memory usage and improves the performance of the conventional CNN technique to classify sensor faults."
합성곱 신경망을 활용한 장미잎 병충해 분류 시스템 개발,2020,"['CNN', 'Disease Classification', 'Inception', 'Plant disease', 'Rose']",,"The classification of plant disease by images has been studied over past decades. In this paper, convolutional neural network models were applied to perform rose leaf disease diagnosis using simple leaves images of healthy and diseased rose leaves, through deep learning methodologies. Training of the models was performed with the use of an open database of 13,125 images, containing field and laboratory images with five different disease and healthy leaves. Based on experiments, the precision and recall are 98.7% and 97.4% and the F1-score is 0.98. The significantly high success rate makes the model a very effective advisory or early warning tool, and an approach that could be further expanded to support an rose leaf disease identification system to operate in real cultivation conditions."
SSD와 규칙기반 방식의 결합을 통한 야간 도로상의 전방 차량 검출,2020,"['CNN-based object detection', 'light-blob paring', 'nighttime vehicle detection', 'vehicle candidate generation and verification', '.']",,.
기본 특징추출신경망에 따른 YOLO의 말벌인식 성능 평가,2020,"['Deep CNN', 'Vespa monitoring system', 'YOLOv2', 'Feature extraction layer', 'VGG19', 'Transfer learning']",,"Real-time monitoring system for Vespa is necessary to reduce the damage to beekeeping farmers. In this paper, we compare and analyze the performance of the YOLO-based deep learning algorithms suitable for developing real-time automatic recognition and classification systems for Apis mellifera and five types of vespas such as V. velutina nigrithorax, V. mandarinia, V. ducalis, V. similima and V. crabro. YOLO has shown the best quality for real-time object detection due to its fast speed by replacing iterative object detection with once regression for an input image. However, the YOLO utilizes the conventional DCNN (deep convolutional neural network) algorithm to extract features from images thus, detection performance of the YOLO depends on the DCNN utilized. Therefore, we evaluate the object detection performance by changing the feature extraction layers of YOLOv2 with AlexNet, VGG19, GoogLeNet, and ResNet50 to find the best combination DCNN model for YOLO on the six bees above. The comparison results are as follows. In terms of the speed of detection and classification, the model in which YOLOv2 is combined with the AlexNet as a feature extraction layer showed the highest detection speed per second. This model can detect and classify 5 vespas and a bee from an average of 438 images per second, but has a relatively low accuracy of 71.7%. In terms of accuracy, the model that combines the feature extraction layer of VGG19 with YOLOv2 generated the highest accuracy, 83.2%. In addition, it can process an average of 135 images per second, enabling real-time processing of surveillance videos for wasps and bees. Therefore, we verified that the combined YOLO model with the VGG19 can be the best real-time monitoring system for the vespa detection."
정체수역 수질개선 및 합성곱 신경망 모델을 이용한 모니터링에 관한 연구,2020,"['ANN', 'CNN', 'Disolved Oxygen', 'Monitoring', 'Stagnation', '인공신경망', '합성곱층 신경망', '용존산소', '모니터링', '정체수역']",,"In this study, the concentration of dissolved oxygen (DO) at different water depths in a small river connected to the Nakdong River was monitored with parallel jet streamer device to improve water quality. DO probes were installed in correspondence of the upper, middle, and lower sections of the river at the different depths and operated for 2 months. To determine the stagnation of water in the river, we produced DO graphs for different depth intervals. Overall, we prepared 343 graphs, identifying 7 intervals with characteristic dissolved oxygen concentrations, including a stagnant zone. We separately applied an artificial neural network (ANN) and a convolution neural network as learning models: in the first case, a correct answer rate of only 29.2% was obtained from the derived weight and bias, while in the second case it corresponded to 94.5%. The learning graphs were randomly selected from 40 to 300. The correct answer ratios were 94.8%, 91.3%, and 88.6% for 250, 200, and 50 graphs, respectively. By applying the control logic to the actual monitoring results, we decided to label as a “stagnant region” the depth interval characterized by correct answer ratios comprised between 84.9% and 83.5% (i.e., depths between 30 m and 60 m)."
Deep convolutional neural network with new training method and transfer learning for structural fault classification of vehicle instrument panel structure,2020,['· 2D CNN · Structural fault classification · Spatial information of input data · Transfer learning'],,"Structural defect have been detected by attaching sensors to all possible defect locations. A new method is proposed to enable the identification of structural defect locations with minimal data collection points using a deep convolutional neural network. Transfer learning was used to improve the accuracy of a hard-to-classify task by using a pre-trained model from an easy-to-classify task. To reduce the number of data collection points, it is necessary to learn the spatial information of the structure. To this end, a structure fault classification-deep convolutional neural network (SFC-DCNN) is proposed. It is an end-to-end convolutional neural network. The time-domain input data and convolutional neural network filter have 2 dimensions.With the proposed method, the accuracy of classifying the location of structural defects in a vehicle’s instrument panel structure was verified with a single vibration measurement point where the location is independent of the structural fault location."
Image Visual Description Model,2020,"['Computer vision', 'CNN', 'Deep learning', 'GRU', 'Image context', 'Image captioning', 'Visual description', 'Validity measures']",,"Image captioning is a keen area of interest for many researchers. With the evolution of machine learning and deep learning, different models are being applied to improve the accuracy and time complexity of the model. However, further improvement in terms of accuracy and time complexity is still an open research challenge. This paper’s contribution is twofold. First, we propose an image captioning model (ImgCap) using a VGG16 Convolution Neural Network and Gated Recurrent Unit (GRU) to generate the captions. Next, a similarity metric (SimM) is proposed in order to compare the generated captions with the expected ones. Furthermore, the proposed model is compared with an existing Long Short-Term Memory (LSTM)-based model. We observe that the proposed model outperforms the existing one in terms of both accuracy and time complexity."
Segmentation of Multi‑Modal MRI Brain Tumor Sub‑Regions Using Deep Learning,2020,['Automatic brain tumor segmentation · CNN · Deep learning · Enhancing tumor · MRI brain tumor image processing · Sub regions of brain tumor segmentation'],,"In medical imaging, extraction of brain tumor region in the magnetic resonance image (MRI) is not sufcient, but fnding the tumor extension is necessary to plan best treatment to improve the survival rate as it depends on tumor’s size, location, and patient’s age. Manually extracting the brain tumor sub-regions from MRI volume is tedious, time consuming and the inherently complex brain tumor images requires a profcient radiologist. Thus, a reliable multi-modal deep learning models are proposed for automatic segmentation to extract the sub-regions like enhancing tumor (ET), tumor core (TC), and whole tumor (WT). These models are constructed on the basis of U-net and VGG16 architectures. The whole tumor is obtained by segmenting T2-weighted images and cross-check the edema’s extension in T2 fuid attenuated inversion recovery (FLAIR).ET and TC are both extracted by evaluating the hyper-intensities in T1-weighted contrast enhanced images. The proposed method has produced better results in terms of dice similarity index, Jaccard similarity index, accuracy, specifcity, and sensitivity for segmented sub regions. The experimental results on BraTS 2018 database shows the proposed DL model outperforms with average dice coefcients of 0.91521, 0.92811, 0.96702, and Jaccard coefcients of 0.84715, 0.88357, 0.93741 for ET, TC, and WT respectively"
TBCNN 기반 코드 클론 유형 분류,2020,"['clone detection', 'clone classification', 'CNN', 'machine learning']",,"In software development, code clone can significantly reduce costs and speed up the development process. However, indiscreet use of the clone not only lowers the quality of the code but also adds extra cost and time to fix the bugs. Due to this problem, many researchers have been trying to detect clones. However, the existing clone detection techniques are limited to detect clones that are fully identical or only with modified identifiers and they dont give information about clone type. This paper proposes a TBCNN(Tree-Based Convolution Neural Network)-based clone classification technique for detecting variety types of clones as well as their automatic classification. The experimental is performed using BigCloneBench, a well known and wildly adopted data set for clone detection. As a result, with 78% recall and precision, the proposed technique was able to classify four types of code clones."
스켈레톤 조인트 매핑을 이용한 딥 러닝 기반 행동 인식,2020,"['Action recognition', 'Deep learning', 'CNN', 'End-to-end skeleton joints mapping.']","최근 컴퓨터 비전과 딥러닝 기술의 발전으로 비디오 분석, 영상 감시, 인터렉티브 멀티미디어 및 인간 기계 상호작용 응용을 위해 인간 행동 인식에 관한 연구가 활발히 진행되고 있다. 많은 연구자에 의해 RGB 영상, 깊이 영상, 스켈레톤 및 관성 데이터를 사용하여 인간 행동 인식 및 분류를 위해 다양한 기술이 도입되었다. 그러나 스켈레톤 기반 행동 인식은 여전히 인간 기계 상호작용 분야에서 도전적인 연구 주제이다. 본 논문에서는 동적 이미지라 불리는 시공간 이미지를 생성하기 위해 동작의 종단간 스켈레톤 조인트 매핑 기법을 제안한다. 행동 클래스 간의 분류를 수행하기 위해 효율적인 심층 컨볼루션 신경망이 고안된다. 제안된 기법의 성능을 평가하기 위해 공개적으로 액세스 가능한 UTD-MHAD 스켈레톤 데이터 세트를 사용하였다. 실험 결과 제안된 시스템이 97.45 %의 높은 정확도로 기존 방법보다 성능이 우수함을 보였다.","Recently, with the development of computer vision and deep learning technology, research on human action recognition has been actively conducted for video analysis, video surveillance, interactive multimedia, and human machine interaction applications. Diverse techniques have been introduced for human action understanding and classification by many researchers using RGB image, depth image, skeleton and inertial data. However, skeleton-based action discrimination is still a challenging research topic for human machine-interaction. In this paper, we propose an end-to-end skeleton joints mapping of action for generating spatio-temporal image so-called dynamic image. Then, an efficient deep convolution neural network is devised to perform the classification among the action classes. We use publicly accessible UTD-MHAD skeleton dataset for evaluating the performance of the proposed method. As a result of the experiment, the proposed system shows better performance than the existing methods with high accuracy of 97.45%."
열화상을 사용한 인체감지 시스템 신뢰성 향상 연구,2020,"['thermal image', 'deep learning', 'CNN', 'single shot multiBox detector', 'human sensing', 'storage']",,"The existing system using the human body detection has the problem of detecting photographs and models as the human body. It is expected that the accuracy and stability will be improved by improving the reliability of the system if human and model can be excluded from the sensing object by using the thermal image. In this paper, we propose a surveillance system that solves the problem of degrading the reliability of the system with unnecessary data by detecting all the pictures and models with the human body using a thermal imaging camera. By comparing the results of the human body detection measurements using general cameras, infrared cameras and proposed thermal imaging cameras, it was confirmed that the surveillance system using thermal imaging cameras was about 98% reliable than other cameras. The storage capacity also takes about 66.6% less than the infrared camera, which increases the storage efficiency."
딥러닝 기반의 장소이미지 수집기술 설계,2020,"['Deep Learning', 'Place Image', 'CNN(Convolutional Neural Network)', 'Image Collecting', 'Web Service', '딥러닝', '장소 이미지', '컨볼루셔널 뉴럴 네트워크', '이미지 수집', '웹 서비스']",본 연구에서는 딥러닝 처리기술을 이용한 이미지 분석을 통하여 위치정보가 없는 사진의 위치를 사용자에게 제공하는 장소이미지 수집기술을 설계하였다. 본 서비스는 사용자가 생활 중에 관심 있는 장소의 이미지 사진을 서비스에 업로드하면 해당 장소의 이름과 위치뿐만 아니라 관련 주변 정보를 확인 할 수 있는 서비스 개발을 목적으로 설계되었다. 본 연구는 이미지에 해당하는 정보를 제공하고 그 위치 정보를 기반으로 사용자가 관심 있는 주변정보를 제공할 수 있는 서비스의 기반기술이다. 이를 통하여 다양한 서비스에 활용이 가능하다.,"This research study designed a location image collecting technology. It provides the exact location information of an image which is not given in the photo to the user. Deep learning technology analysis and collects the images. The purpose of this service system is to provide the exact place name, location and the various information of the place such as nearby recommended attractions when the user upload the image photo to the service system. Suggested system has a deep learning model that has a size of 25.3MB, and the model repeats the learning process 50 times with a total of 15,266 data, performing 93.75% of the final accuracy. This system can also be linked with various services potentially for further development."
합성곱 신경망 기반 AM 재밍 검출기법,2020,"['GNSS', 'AM Jamming', 'CNN', 'JNR', 'Detection Probability']",,
회전한 상표 이미지의 진위 결정을 위한 기계 학습 데이터 확장 방법,2020,"['Machine Learning', 'Rotated', 'trademark', 'CNN', 'training data', 'ConvNN']",,
Deep Learning을 기반으로 한 Feature Extraction 알고리즘의 분석,2020,"['Deep Learning', 'Feature Extraction', 'CNN', 'RBM']",,"Recently, artificial intelligence related technologies including machine learning are being applied to various fields, and the demand is also increasing. In particular, with the development of AR, VR, and MR technologies related to image processing, the utilization of computer vision based on deep learning has increased. The algorithms for object recognition and detection based on deep learning required for image processing are diversified and advanced. Accordingly, problems that were difficult to solve with the existing methodology were solved more simply and easily by using deep learning. This paper introduces various deep learning-based object recognition and extraction algorithms used to detect and recognize various objects in an image and analyzes the technologies that attract attention."
시간 축 주의집중 기반 동물 울음소리 분류,2020,"['Audio event classification', 'Convolution Neural Network (CNN)', 'Self-attention', 'Gated Linear Unit (GLU)', '음향이벤트 인식', '합성 곱 신경망', '자가주의집중', '게이트 선형유닛']","본 논문에서는 조류와 양서류 울음소리의 구별 정확도를 높이기 위해 게이트 선형유닛과 자가주의 집중 모듈을 활용해서 데이터의 중요한 부분을 중심으로 특징 추출 및 데이터 프레임의 중요도를 판별해 구별 정확도를 높인다.이를 위해 먼저 1차원의 음향 데이터를 로그 멜 스펙트럼으로 변환한다. 로그 멜 스펙트럼에서 배경잡음같이 중요하지않은 정보는 게이트 선형유닛을 거쳐 제거한다. 그러고 난 뒤 시간 축에 자가주의집중기법을 적용해 구별 정확도를 높인다. 사용한 데이터는 자연환경에서 멸종위기종을 포함한 조류 6종의 울음소리와 양서류 8종의 울음소리로 구성했다. 그 결과, 게이트 선형유닛 알고리즘과 시간 축에서 자가주의집중을 적용한 구조의 평균 정확도는 조류를 구분했을때 91 %, 양서류를 구분했을 때 93 %의 분류율을 보였다. 또한, 기존 알고리즘보다 약 6 % ~ 7 % 향상된 정확도를보이는 것을 확인했다.","In this paper, to improve the classification accuracy of bird and amphibian acoustic sound, we utilize GLU (Gated Linear Unit) and Self-attention that encourages the network to extract important features from data and discriminate relevant important frames from all the input sequences for further performance improvement. To utilize acoustic data, we convert 1-D acoustic data to a log-Mel spectrogram. Subsequently, undesirable component such as background noise in the log-Mel spectrogram is reduced by GLU. Then, we employ the proposed temporal self-attention to improve classification accuracy. The data consist of 6-species of birds, 8-species of amphibians including endangered species in the natural environment. As a result, our proposed method is shown to achieve an accuracy of 91 % with bird data and 93 % with amphibian data. Overall, an improvement of about 6 % ~ 7 % accuracy in performance is achieved compared to the existing algorithms."
큐브인공위성과 인공지능을 융합한 북한군 이동식무기체계의 탐지 및 추적에 대한 연구,2020,"['TEL', 'Cube Satellite', 'Kill-Chain', 'CNN']",,"This paper studies the priority given to real-time monitoring and tracking of mobile weapons systems, including transporter erector launchers, which are a major danger to the military of the Republic of Korea. Also, it aims to present economic and effective measures for observation of the North Korean military by combining artificial intelligence technology with Cube satellites. A large number of Cube satellites were launched into their target orbit and operated. Then the data collected was used to determine how to enable real-time monitoring and tracking of mobile weapons systems, including transporter erector launchers and mobile weapons, of the North Korean military. Besides, the paper describes the process of identifying in actual satellite imagery the weapons, positions, and bases of the North Korean military and conducting virtual experiments with the “Vance AI” and “Google Cloud Platform” tools."
딥러닝 기반 벵골어 수기 문자 인식 : Kaggle Bengali.AI 대회를 중심으로,2020,"['Deep learning', 'handwritten character classification', 'CNN', 'data augmentation']",,
Deep Contour Recovery: Repairing Breaks in Detected Contours using Deep Learning,2020,"['Contour recovery', 'Contour detection', 'Deep learning', 'CNN', 'Residual connections training']",,"We present a contour recovery framework based on a deep learning model to connect broken contours (breaks) produced by contour detection methods. The idea is that the convolutional neural network iteratively predicts vectors that can grow along the direction of the true contour from the end points of the breaks. For this prediction, we use residual connections training, which models continuous predictions from the previous inference. However, conventional residual connections training is prone to gradually accumulating errors at each inference step. In this work, we propose a ground truth selection algorithm and sub-iteration training to efficiently and reliably train a deep learning model. The ground truth selection extracts a small set of coordinates to represent an actual contour. The sub-iteration training creates the next input that is predicted by additional training of a network replicated from the main network. Our experimental results demonstrate that the ground truth selection creates a ground truth suitable for contour recovery. Moreover, our approach improves the performance of contour detection when applied to the results of existing representative contour detection methods."
스마트 헬스 시티 구현을 위한 얼굴 영상기반 심박수 추출 딥러닝 모델 최적화,2020,"['Heartrate', 'semantic segmentation', 'video stabilize', 'BOHB', 'CNN']",,
반부패경영시스템 인증(ISO 37001)에 대한 국내 기업의 기대 및 인지도 연구,2020,"['IEEE 802.11', 'Format Detection', 'Deep Learning', 'CNN']",,"Bribery is one of the world’s most destructive and challenging issues. Yet despite efforts on national and international levels to tackle bribery, it remains a significant issue. Recognizing this, ISO has developed a new standard to help organizations fight bribery and promote an ethical business culture, which is “ISO 37001 – Anti-bribery Management Systems” in 2016. ISO 37001 can provide the tools and systems to greatly reduce the risk and help organizations deal with it effectively if it does arise. It is a flexible tool, which can be adapted according to the size and nature of the organization and the bribery risk it faces.After enforcing the Improper Solicitation and Graft Act, Korean government standardized ISO 37001, one of the Business Ethics of Global Standard, harmonizing International Standards into Korean Industrial Standards (KS) in 2017. It is meaningful in that Korean companies have localized regulation which applies to global standard anti-bribery management systems. Only about 100 organizations, however, have adopted ISO 37001 so far. The primary purpose of this paper is to examine the expectation and awareness of ISO 37001. Results show that still many organizations lack of awareness of ISO 37001 and it is implicated that much promotion and education will be necessary. This study has originality and value in that it can provide the guidelines for activation of ISO 37001."
합성곱 순환 신경망 구조를 이용한 지진 이벤트 분류 기법,2020,"['Earthquake events classification', 'Convolutional Neural Network (CNN)', 'Recurrent Neural Network (RNN)', 'Convolutional Recurrent Neural Network (CRNN)', '지진 이벤트 분류', '합성곱 신경망', '순환 신경망', '합성 순환 신경망']","본 논문은 다양한 지진 이벤트 분류를 위해 지진 데이터의 정적인 특성과 동적인 특성을 동시에 반영할 수있는 합성곱 순환 신경망(Convolutional Recurrent Neural Net, CRNN) 구조를 제안한다. 중규모 지진뿐만 아니라미소 지진, 인공 지진을 포함한 지진 이벤트 분류 문제를 해결하려면 효과적인 특징 추출 및 분류 방법이 필요하다. 본논문에서는 먼저 주의 기반 합성곱 레이어를 통해 지진 데이터의 정적 특성을 추출 하게 된다. 추출된 특징은 다중 입력단일 출력 장단기메모리(Long Short-Term Memory, LSTM) 네트워크 구조에 순차적으로 입력되어 다양한 지진 이벤트 분류를 위한 동적 특성을 추출하게 되며 완전 연결 레이어와 소프트맥스 함수를 통해 지진 이벤트 분류를 수행한다. 국내외 지진을 이용한 모의 실험 결과 제안된 모델은 다양한 지진 이벤트 분류에 효과적인 모습을 보여 주었다.","This paper proposes a Convolutional Recurrent Neural Net (CRNN) structure that can simultaneously reflect both static and dynamic characteristics of seismic waveforms for various earthquake events classification. Addressing various earthquake events, including not only micro-earthquakes and artificial-earthquakes but also macro-earthquakes, requires both effective feature extraction and a classifier that can discriminate seismic waveform under noisy environment. First, we extract the static characteristics of seismic waveform through an attention-based convolution layer. Then, the extracted feature-map is sequentially injected as input to a multiinput single-output Long Short-Term Memory (LSTM) network structure to extract the dynamic characteristic for various seismic event classifications. Subsequently, we perform earthquake events classification through two fully connected layers and softmax function. Representative experimental results using domestic and foreign earthquake database show that the proposed model provides an effective structure for various earthquake events classification."
딥러닝 기반의 스크랩박스 적치 상태 측정 기술 개발,2020,"['Deep Learning', 'Accumulated status Measuring', 'CNN', 'Transfer Learning', 'Machine Learning', '딥러닝', '적치 상태 측정', '전이 학습', '머신 러닝']","본 논문에서는 금속스크랩이 쌓이는 스크랩박스의 적치 상태를 측정하는 알고리즘을 제안한다. 적치 상태 측정 문제를 다중 클래스 분류 문제로 정의하여, 딥러닝 기법을 이용해 스크랩박스 촬영 영상만으로 적치 상태를 구분하도록 하였다. Transfer Learning 방식으로 학습을 진행하였으며, 딥러닝 모델은 NASNet-A를 이용하였다. 더불어 분류 모델의 정확도를 높이기 위해 학습된 NASNet-A에 랜덤포레스트 분류기를 결합하였으며, 후처리를 통해 안전성을 높였다. 현장에서 수집된 4,195개의 데이터로 테스트한 결과 NASNet-A만 적용했을때 정확도 55%를 보였으며, 제안방식인 Random Forest를 결합한 NASNet은 88%로 향상된 정확도를 달성하였다.","In this paper, we propose an algorithm to measure the accumulated status of scrap boxes where metal scraps are accumulated. The accumulated status measuring is defined as a multi-class classification problem, and the method with deep learning classify the accumulated status using only the scrap box image. The learning was conducted by the Transfer Learning method, and the deep learning model was NASNet-A. In order to improve the accuracy of the model, we combined the Random Forest classifier with the trained NASNet-A and improved the model through post-processing. Testing with 4,195 data collected in the field showed 55% accuracy when only NASNet-A was applied, and the proposed method, NASNet with Random Forest, improved the accuracy by 88%."
Feasibility Study of Deep Learning Tumor Segmentation for a Merged Tumor Dataset: Head & Neck and Limbs,2020,"['Deep learning (DL)', 'Convolutional neural network (CNN)', 'Tumor segmentation']",,"The aim of this study is to evaluate the feasibility of a deep learning tumor segmentation network trained by merged tumor dataset. PET-CT datasets for head-and-neck (H&N) and limb tumors were used to train three different networks: H\&N, Limb, and merged (H&N + Limb). Dice similarity coefficient (DSC) of the merged network (0.89) in limb tumors was the same as that of the Limb network. In H&N tumor, DSC of the merged network (0.72) was higher than that of the H&N network (0.69). We found that the merged network could be applied simultaneously in H&N and limb tumor segmentation."
X-선 영상과 합성곱 신경망을 이용한 육류 내의 바늘 검출,2020,"['X-ray Image', 'Convolutional Neural Network (CNN)', 'Foreign Object Detection', 'Needle', 'Hough Transform']",,"The most lethal foreign body in meat is a needle, and X-ray images are used to detect it. However, because the difference in thickness and fat content is severe depending on the type of meat and the part of the meat, the shade difference and contrast appear severe. This problem causes difficulty in automatic classification. In this paper, we propose a method for generating training patterns by efficient preprocessing and classifying needles in meat using a convolution neural network. Approximately 24000 training patterns and 4000 test patterns were used to verify the proposed method, and an accuracy of 99.8% was achieved."
합성 샴 신경망을 이용한 화자 인식,2020,"['Speaker Recognition', 'Siamese Networks', 'Convolutional Neural Netowork(CNN)', 'MFCC']",,"Recently, machine learning has been applied in a variety of fields. Speaker recognition is one of attractive applications of machine learning. In this paper, we propose a convolutional Siamese neural network for speaker recognition. The proposed model generates feature vectors through the identical two convolutional neural networks for speech data of two speakers. The similarity is measured by calculating the Euclidean distance of two output feature vectors. If the calculated similarity is less than the threshold, it is judged that two speakers are the same. The experimental result of the proposed speaker recognition based on the convolutional Siamese neural network showed its accuracy was achieved up to 96%. The accuracy of one-shot classification using the trained convolutional Siamese neural network was evaluated also. For the evaluation, the 10-way one-shot classification for 10 speakers not used for learning stages were tested, resulting in 92% accuracy."
다개체 협력 시스템 기반 AI 로봇 오목 플랫폼 개발,2020,"['Gomoku', 'OpenCV', 'Vision-system', 'DOBOT', 'Python', 'AI', 'CNN']",,"Artificial Intelligence (AI) has become a hot topic since 2016 when Lee Se-dol and AlphaGo became a big hit. However, AlphaGo's computational results were made through the hand of a substitute driver in the game. It predicted that if there was hardware that matched advanced software, viewers would be more immersed in the Go game and that AlphaGo and Lee Se-dol would be clearly visible as AI and human. Therefore, in this paper, we want to design the combination between software and hardware using vision system and Robot for user immersion and real-time interactive communication with AI. In particular, unlike previous experiments in which only one robot was previously treated as a single robot and conducted only in a limited area, it induces higher user interaction through parallel processing in two. The implementation of the vision system took place in the Python environment of Zet Brains, and two robots are used. In fact, when a user starts a concave egg on a board of go, the starting point of the concave AI is calculated through the vision system, and the launch of the board is carried out through the robot. In conclusion, the proposed AI robotic omok platform based on multi-robot cooperative system proves its effectiveness and will be available in areas such as education for children with developmental disabilities."
Map Detection using Deep Learning,2020,"['geographic map', 'object detection', 'deep learning', 'Faster R-CNN']",,
An Enhanced Deep Neural Network-Based Architecture for Joint Extraction of Entity Mentions and Relations,2020,"['Entity classification', 'Relation extraction', 'Joint model', 'LSTM-RNN', 'CNN', 'NLP']",,"Named entity recognition and relation extraction are two principal tasks in most natural language processing systems. The majority of methods used in the field implement these two issues independently, thus leading to possible problems such as error propagation from one component (entity detection) to another (relation extraction). To solve such problems, we propose a new architecture for joint identification of entity mentions and their relation by employing a deep neural network framework. The model not only overcomes the error propagation challenge but also improves the detection results of both tasks owing to the cooperation with each other. Experiments on publicly available sources demonstrate that our joint model surpasses competitors in terms of accuracy. The results highlight the improvement achieved by the proposed deep neural network framework for the entity mention and relation classification tasks. Furthermore, we tested the effect of increasing the sentence length and demonstrated its negative influence on the performance."
자율차량의 주행을 보조하기 위한 탑승객 탐지 및 공유 시스템 개발,2020,"['Passenger Reconstruction', 'Autonomous Vehicles', 'V2V Communication', 'Vehicle Information Sharing', 'CNN']","현재 자율주행 차량 연구들은 긴급상황이 대처 가능한 4레벨의 자율주행 차량을 개발하기 위해 매진하고 있다. 차량이 긴급상황에 유연하게 대처하기 위해서는 피해를 최소화하는 방향으로 움직여야 하는데, 이는 주변 보행자, 도로 상태, 주변 차량의 상태 등 주행 중인 도로의 모든 상태를 판단하여 진행되어야 한다. 따라서 본 논문에서는 자율차량 내부의 탑승객 상황을 탐지하고, 그것을 V2V로 주변 차량에 공유하여 이 긴급상황에서 주행을 결정하는 데 도움을 줄 수 있는 자율차량의 주행을 보조하기 위한 탑승객 탐지 및 공유 시스템을 제안한다. 탑승객 탐지 및 공유 시스템은 현재 차량에서 탑승객을 인식하는 무게 측정 방식을 개선하여 정확하게 차량 내부의 승객 위치를 식별할 수 있고, 각 차량의 승객 위치를 주변의 다른 차량과 공유하기 때문에 긴급상황이 발생할 때 차량의 주행 결정에 도움을 줄 수 있다. 실험 결과, 탑승객 인식 서브 모듈에 적용된 체압 센서는 기존의 공진형 센서보다 약 8%, 압전형 센서보다 약 17% 높은 정확도를 보였다.","Currently, an autonomous vehicle studies are working to develop a four-level autonomous vehicle that can cope with emergencies. In order to flexibly respond to an emergency, the autonomous vehicle must move in a direction to minimize the damage, which must be conducted by judging all the states of the road, such as the surrounding pedestrians, road conditions, and surrounding vehicle conditions. Therefore, in this paper, we suggest a passenger detection and sharing system to detect the passenger situation inside the autonomous vehicle and share it with V2V to the surrounding vehicles to assist in the operation of the autonomous vehicle. Passenger detection and sharing system improve the weighting method that recognizes passengers in the current vehicle to identify the passenger""s position accurately inside the vehicle, and shares the passenger""s position of each vehicle with other vehicles around it in case of emergency. So, it can help determine the driving of a vehicle. As a result of the experiment, the body pressure sensor applied to the passenger recognition sub-module showed about 8% higher accuracy than the conventional resonant sensor and about 17% higher than the piezoelectric sensor."
Syllable-based Korean named entity recognition using convolutional neural network,2020,"['Named entity recognition', 'Deep learning', 'Bi-LSTM-CRFs', 'CNN-CRFs']",,
합성곱 신경망에서 이미지 분류를 위한 하이퍼파라미터 최적화,2020,[],,"In order to obtain high accuracy with an convolutional neural network(CNN), it is necessary to set the optimal hyperparameters. However, the exact value of the hyperparameter that can make high performance is not known, and the optimal hyperparameter value is different based on the type of the dataset, therefore, it is necessary to find it through various experiments. In addition, since the range of hyperparameter values is wide and the number of combinations is large, it is necessary to find the optimal values of the hyperparameters after the experimental design in order to save time and computational costs. In this paper, we suggest an algorithm that use the design of experiments and grid search algorithm to determine the optimal hyperparameters for a classification problem. This algorithm determines the optima values of the hyperparameters that yields high performance using the factorial design of experiments. It is shown that the amount of computational time can be efficiently reduced and the accuracy can be improved by performing a grid search after reducing the search range of each hyperparameter through the experimental design. Moreover, Based on the experimental results, it was shown that the learning rate is the only hyperparameter that has the greatest effect on the performance of the model."
기계학습을 이용한 소스코드 정적 분석 개선에 관한 연구,2020,"['Static analysis', 'Secure Coding', 'Deep Learning', 'Convolutional Neural Networks(CNN)']","소스코드에 대한 정적 분석은 광범위한 소스코드에 대해서 잔존하는 보안약점을 찾는 것으로 정적 분석 도구를 활용하여 점검을 하고, 그 결과에 대해서 정적 분석 전문가가 정탐 및 오탐 분석을 한다. 이 과정에서 분석양이 많고 오탐의 비율이 높아 많은 시간과 노력이 들어가게 되어 효율적으로 분석하는 방안이 요구되고 있다. 또한 전문가들은 정 · 오탐 분석을 할 때 결함이 발생한 라인의 소스코드만 보고 분석을 하는 경우는 드물다. 결함의 유형에 따라서 주변의 소스코드를 같이 분석하고 최종 분석 결과를 내리게 된다. 이러한 정적 분석 도구를 사용하여 전문가가 정 · 오탐을 판별하는 어려움을 해결하기 위해서 본 논문에서는 정적 분석 도구가 찾은 보안약점이 정탐인지 아닌지를 전문가가 아닌 인공지능을 통해 판별하는 방법을 제안한다. 또한 이러한 기계학습에 사용되는 학습 데이터(결함주변 소스코드)의 크기가 성능에 어떤 영향을 미치는지 실험을 통해 최적의 크기를 확인하였다. 이 결과를 통해 정적 분석 후 정 · 오탐을 분류하는 정적 분석 전문가의 업무에 도움을 줄 것으로 기대한다.","The static analysis of the source code is to find the remaining security weaknesses for a wide range of source codes. The static analysis tool is used to check the result, and the static analysis expert performs spying and false detection analysis on the result. In this process, the amount of analysis is large and the rate of false positives is high, so a lot of time and effort is required, and a method of efficient analysis is required. In addition, it is rare for experts to analyze only the source code of the line where the defect occurred when performing positive/false detection analysis. Depending on the type of defect, the surrounding source code is analyzed together and the final analysis result is delivered. In order to solve the difficulty of experts discriminating positive and false positives using these static analysis tools, this paper proposes a method of determining whether or not the security weakness found by the static analysis tools is a spy detection through artificial intelligence rather than an expert. In addition, the optimal size was confirmed through an experiment to see how the size of the training data (source code around the defects) used for such machine learning affects the performance. This result is expected to help the static analysis expert""s job of classifying positive and false positives after static analysis."
결함 검출을 위한 임베디드 딥러닝 시스템,2020,"['Defects detection', 'Convolutional neural network', 'Network Reduction', 'Embedded System', 'YOLOv2', 'YOLOv3', 'YOLOv2-tiny']",,"A machine vision based industrial inspection requires little computation time and localizing defects robustly with high accuracy. Recent mobile and embedded systems require computationally efficient machine intelligence with a deep learning model. In order to improve detection performance and processing time, various network modification methods are proposed. The experiments for defect detection on the metal surfaces data are executed using the various YOLO networks on embedded GPU system Nvidia Tx-1. The results for detection performance and inspection time are compared and analysed. Among them, modified YOLOv2-tiny model shows a better performance in both detection rate and fps."
규칙기반과 딥러닝을 동시에 활용한 앙상블 회전체 이상진단,2020,"['Ensemble(앙상블)', 'Rule-based(규칙기반)', 'Deep Learning(심층 학습)', 'CNN(합성곱 신경망)', 'Orbit Detection(궤도 추적)', 'Rotating Machine(회전체)', 'Machine Diagnostics(기계 진단)']",,"Unlike the major equipment used in power plants, auxiliary equipment usually does not possess a real-time system to analyze the machine condition. Therefore, detecting the fault of such auxiliary equipment in advance is difficult. Thus, the diagnosis of auxiliary equipment at a less cost is important for minimizing the downtime due to the fault of the equipment. In this paper, we introduce a diagnosis method for auxiliary equipment in power plants using rule-based and deep-learning algorithms. First, we calculate the probability of cause of a fault from current symptoms by using the rule-based algorithm. The rule used in this algorithm is established based on expert experience. We then conduct orbit detection using a convolution neural network. This algorithm self-learns the filter to classify orbit images as normal, rubbing, and unbalanced. The weakness of the deep-learning algorithm can be compensated by combining the results of the aforementioned methods."
Implementation of Cough Detection System Using IoT Sensor in Respirator,2020,"['COVID-19', 'Smart Sensor', 'IoT', 'Non-Powered Hood Respirator', 'Mel-Spectrogram', 'Deep Learning', 'CNN']",,"Worldwide, the number of corona virus disease 2019 (COVID-19) confirmed cases is rapidly increasing. Although vaccines and treatments for COVID-19 are being developed, the disease is unlikely to disappear completely. By attaching a smart sensor to the respirator worn by medical staff, Internet of Things (IoT) technology and artificial intelligence (AI) technology can be used to automatically detect the medical staff's infection symptoms. In the case of medical staff showing symptoms of the disease, appropriate medical treatment can be provided to protect the staff from the greater risk. In this study, we design and develop a system that detects cough, a typical symptom of respiratory infectious diseases, by applying IoT technology and artificial technology to respiratory protection. Because the cough sound is distorted within the respirator, it is difficult to guarantee accuracy in the AI model learned from the general cough sound. Therefore, coughing and non-coughing sounds were recorded using a sensor attached to a respirator, and AI models were trained and performance evaluated with this data. Mel-spectrogram conversion method was used to efficiently classify sound data, and the developed cough recognition system had a sensitivity of 95.12% and a specificity of 100%, and an overall accuracy of 97.94%."
LSTM Network with Tracking Association for Multi-Object Tracking,2020,"['Deep Learning', 'Object Tracking', 'LSTM Network', 'RNN', 'Object Detection', 'Multi-Object Tracking', 'MOT', 'CNN', 'Keras', 'Dense Layer', 'Neural Network']",,"In a most recent object tracking research work, applying Convolutional Neural Network and Recurrent Neural Network-based strategies become relevant for resolving the noticeable challenges in it, like, occlusion, motion, object, and camera viewpoint variations, changing several targets, lighting variations. In this paper, the LSTM Network-based Tracking association method has proposed where the technique capable of real-time multi-object tracking by creating one of the useful LSTM networks that associated with tracking, which supports the long term tracking along with solving challenges. The LSTM network is a different neural network defined in Keras as a sequence of layers, where the Sequential classes would be a container for these layers. This purposing network structure builds with the integration of tracking association on Keras neural-network library. The tracking process has been associated with the LSTM Network feature learning output and obtained outstanding real-time detection and tracking performance. In this work, the main focus was learning trackable objects locations, appearance, and motion details, then predicting the feature location of objects on boxes according to their initial position. The performance of the joint object tracking system has shown that the LSTM network is more powerful and capable of working on a real-time multi-object tracking process."
Residual Multi-Dilated Recurrent Convolutional U-Net을 이용한 전자동 심장 분할 모델 분석,2020,"['딥러닝', '인공지능', '심장분할', '알고리즘', '인공신경망', '합성곱신경망', 'Deep Learning', 'Artificial Intelligence', 'Heart Segmentation', 'Algorithm', 'ANN', 'CNN']","본 논문에서는 딥 러닝 기반의 전-자동 심장 분할 알고리즘을 제안한다. 본 논문에서 제안하는 딥 러닝 모델은 기존 U-Net에 residual recurrent convolutional block과 residual multi-dilated convolutional block을 삽입하여 성능을 개선한 모델이다. 모델의 성능은 테스트 데이터 세트를 전-자동 분할한 결과와 영상의학 전문가의 수동 분할 결과를 비교하여 분석하였다. CT 영상에서 평균 96.88%의 DSC, 95.60%의 precision과 97.00%의 recall 결과를 얻었다. 분할된 영상은 3차원 볼륨 렌더링 기법을 적용하여 시각화한 후 관찰하여 분석할 수 있었다. 실험 결과를 통해 제안된 알고리즘이 다양한 심장 하부 구조를 분할하기에 효과적인 것을 알 수 있었다. 본 논문에서 제안하는 알고리즘이 전문의 또는 방사선사의 임상적 보조역할을 수행할 수 있을 것으로 기대한다.","In this paper, we proposed that a fully automatic multi-class whole heart segmentation algorithm using deep learning. The proposed method is based on U-Net architecture which consist of recurrent convolutional block, residual multi-dilated convolutional block. The evaluation was accomplished by comparing automated analysis results of the test dataset to the manual assessment. We obtained the average DSC of 96.88%, precision of 95.60%, and recall of 97.00% with CT images. We were able to observe and analyze after visualizing segmented images using three-dimensional volume rendering method. Our experiment results show that proposed method effectively performed to segment in various heart structures. We expected that our method can help doctors and radiologist to make image reading and clinical decision."
Implementation of Cough Detection System Using IoT Sensor in Respirator,2020,"['COVID-19', 'Smart Sensor', 'IoT', 'Non-Powered Hood Respirator', 'Mel-Spectrogram', 'Deep Learning', 'CNN']",,"Worldwide, the number of corona virus disease 2019 (COVID-19) confirmed cases is rapidly increasing. Although vaccines and treatments for COVID-19 are being developed, the disease is unlikely to disappear completely. By attaching a smart sensor to the respirator worn by medical staff, Internet of Things (IoT) technology and artificial intelligence (AI) technology can be used to automatically detect the medical staff's infection symptoms. In the case of medical staff showing symptoms of the disease, appropriate medical treatment can be provided to protect the staff from the greater risk. In this study, we design and develop a system that detects cough, a typical symptom of respiratory infectious diseases, by applying IoT technology and artificial technology to respiratory protection. Because the cough sound is distorted within the respirator, it is difficult to guarantee accuracy in the AI model learned from the general cough sound. Therefore, coughing and non-coughing sounds were recorded using a sensor attached to a respirator, and AI models were trained and performance evaluated with this data. Mel-spectrogram conversion method was used to efficiently classify sound data, and the developed cough recognition system had a sensitivity of 95.12% and a specificity of 100%, and an overall accuracy of 97.94%."
LSTM Network with Tracking Association for Multi-Object Tracking,2020,"['Deep Learning', 'Object Tracking', 'LSTM Network', 'RNN', 'Object Detection', 'Multi-Object Tracking', 'MOT', 'CNN', 'Keras', 'Dense Layer', 'Neural Network']",,
오디오 전처리 방법에 따른 콘벌루션 신경망의 환경음 분류 성능 비교,2020,"['환경음 분류', '콘볼루션 신경망', '오디오 특징 추출', '오디오 전처리', 'Environmental sound classification', 'Convolutional neural networks', 'Audio feature extraction', 'Audio preprocessing']","본 논문에서는 딥러닝(deep learning)을 이용하여 환경음 분류 시 전처리 단계에서 사용하는 특징 추출 방법이 콘볼루션 신경망의 분류 성능에 미치는 영향에 대해서 다루었다. 이를 위해 환경음 분류 연구에서 많이 사용되는 UrbanSound8K 데이터셋에서 멜 스펙트로그램(mel spectrogram), 로그 멜 스펙트로그램(log mel spectrogram), Mel Frequency Cepstral Coefficient(MFCC), 그리고 delta MFCC를 추출하고 각각을 3가지 분포로 스케일링하였 다. 이 데이터를 이용하여 4 종의 콘볼루션 신경망과 이미지넷에서 좋은 성능을 보였던 VGG16과 MobileNetV2 신경 망을 학습시킨 다음 오디오 특징과 스케일링 방법에 따른 인식률을 구하였다. 그 결과 인식률은 스케일링하지 않은 로 그 멜 스펙트럼을 사용했을 때 가장 우수한 것으로 나타났다. 도출된 결과를 모든 오디오 인식 문제로 일반화하기는 힘들지만, Urbansound8K의 환경음이 포함된 오디오를 분류할 때는 유용하게 적용될 수 있을 것이다.","This paper presents the effect of the feature extraction methods used in the audio preprocessing on the classification performance of the Convolutional Neural Networks (CNN). We extract mel spectrogram, log mel spectrogram, Mel Frequency Cepstral Coefficient (MFCC), and delta MFCC from the UrbanSound8K dataset, which is widely used in environmental sound classification studies. Then we scale the data to 3 distributions. Using the data, we test four CNNs, VGG16, and MobileNetV2 networks for performance assessment according to the audio features and scaling. The highest recognition rate is achieved when using the unscaled log mel spectrum as the audio features. Although this result is not appropriate for all audio recognition problems but is useful for classifying the environmental sounds included in the Urbansound8K."
BCI 제어를 위한 뇌신호 분류에서의 딥러닝 모델 개발,2020,"['뇌신호', '뇌-컴퓨터 인터페이스', '운동상상', '뇌신호 분류', '딥러닝', '합성곱신경망', 'Electroencephalography(EEG)', 'Brain-computer interface(BCI)', 'Motor imagery(MI)', 'EEG classification', 'deep learning', 'Convolutional neural network(CNN)']",,
Balance Control for the First-order Inverted Pendulum Based on the Advantage Actor-critic Algorithm,2020,"['Actor critic', 'deep Q network(DQN)', 'inverted pendulum', 'PID', 'reinforcement learning.']",,"In this paper, a control algorithm based on Advantage Actor-Critic for the classical inverted pendulum system has been proposed. To enrich the observed states which are used to control, a CNN feature-based state is proposed. The direct control and the indirect control algorithms are introduced to address different control situations, such as the situation which only physical states like angle, velocity, etc. provided or the situation which only the indirect states provided like images, etc. A comparison experiment between the direct control and the indirect control algorithms based on the Advantage Actor-Critic has been evaluated. Besides, the comparison experiment with the Deep Q-Network algorithm has been performed. The experiment results show that the proposed method achieves comparable performance with the PID control algorithm and better than the Deep Q-Network based algorithm."
데이터의 불균형성을 제거한 네트워크 침입 탐지 모델 비교 분석,2020,"['Random Oversampling', 'Machine Learning Decision Tree(DT)', 'Random Forest(RF)', 'Support Vector machine(SVM)', 'LongShort Term Memory(LSTM)', 'Multi-Encoder', 'Convolutional Neural Network(CNN)']","컴퓨팅 환경의 발전에 따라 IT 기술이 의료, 산업, 통신, 문화 등의 분야에서 사람들에게 제공해주는 혜택이 늘어나 삶의 질도 향상되고 있다. 그에 따라 발전된 네트워크 환경을 노리는 다양한 악의적인 공격이 존재한다. 이러한 공격들을 사전에 탐지하기 위해 방화벽, 침입 탐지 시스템 등이 존재하지만, 나날이 진화하는 악성 공격들을 탐지하는 데에는 한계가 있다. 이를 해결하기 위해 기계 학습을 이용한 침입 탐지 연구가 활발히 진행되고 있지만, 학습 데이터셋의 불균형으로 인한 오탐 및 미탐이 발생하고 있다. 본 논문에서는 네트워크 침입 탐지에 사용되는 UNSW-NB15 데이터셋의 불균형성 문제를 해결하기 위해 랜덤 오버샘플링 방법을 사용했다. 실험을 통해 모델들의 accuracy, precision, recall, F1-score, 학습 및 예측 시간, 하드웨어 자원 소모량을 비교 분석했다. 나아가 본 연구를 기반으로 랜덤 오버샘플링 방법 이외에 불균형한 데이터 문제를 해결할 수 있는 다른 방법들과 성능이 높은 모델들을 이용하여 좀 더 효율적인 네트워크 침입 탐지 모델 연구로 발전시키고자 한다.","With the development of the virtual community, the benefits that IT technology provides to people in fields such as healthcare, industry, communication, and culture are increasing, and the quality of life is also improving. Accordingly, there are various malicious attacks targeting the developed network environment. Firewalls and intrusion detection systems exist to detect these attacks in advance, but there is a limit to detecting malicious attacks that are evolving day by day. In order to solve this problem, intrusion detection research using machine learning is being actively conducted, but false positives and false negatives are occurring due to imbalance of the learning dataset. In this paper, a Random Oversampling method is used to solve the unbalance problem of the UNSW-NB15 dataset used for network intrusion detection. And through experiments, we compared and analyzed the accuracy, precision, recall, F1-score, training and prediction time, and hardware resource consumption of the models. Based on this study using the Random Oversampling method, we develop a more efficient network intrusion detection model study using other methods and high-performance models that can solve the unbalanced data problem."
Classroom Roll-Call System Based on ResNet Networks,2020,"['Face Recognition', 'Game', 'ResNet Networks']",,"A convolution neural networks (CNNs) has demonstrated outstanding performance compared to otheralgorithms in the field of face recognition. Regarding the over-fitting problem of CNN, researchers haveproposed a residual network to ease the training for recognition accuracy improvement. In this study, a novelface recognition model based on game theory for call-over in the classroom was proposed. In the proposedscheme, an image with multiple faces was used as input, and the residual network identified each face with aconfidence score to form a list of student identities. Face tracking of the same identity or low confidence weredetermined to be the optimisation objective, with the game participants set formed from the student identitylist. Game theory optimises the authentication strategy according to the confidence value and identity set toimprove recognition accuracy. We observed that there exists an optimal mapping relation between face andidentity to avoid multiple faces associated with one identity in the proposed scheme and that the proposedgame-based scheme can reduce the error rate, as compared to the existing schemes with deeper neural network."
Understanding recurrent neural network for texts using English-Korean corpora,2020,"['RNN', 'NLP', 'Seq2Seq', 'Neural Machine Translation', 'Keras']",,"Deep Learning is the most important key to the development of Artificial Intelligence (AI). There are several distinguishable architectures of neural networks such as MLP, CNN, and RNN. Among them, we try to understand one of the main architectures called Recurrent Neural Network (RNN) that differs from other networks in handling sequential data, including time series and texts. As one of the main tasks recently in Natural Language Processing (NLP), we consider Neural Machine Translation (NMT) using RNNs. We also summarize fundamental structures of the recurrent networks, and some topics of representing natural words to reasonable numeric vectors. We organize topics to understand estimation procedures from representing input source sequences to predict target translated sequences. In addition, we apply multiple translation models with Gated Recurrent Unites (GRUs) in Keras on English-Korean sentences that contain about 26,000 pairwise sequences in total from two different corpora, colloquialism and news. We verified some crucial factors that influence the quality of training. We found that loss decreases with more recurrent dimensions and using bidirectional RNN in the encoder when dealing with short sequences. We also computed BLEU scores which are the main measures of the translation performance, and compared them with the score from Google Translate using the same test sentences. We sum up some difficulties when training a proper translation model as well as dealing with Korean language. The use of Keras in Python for overall tasks from processing raw texts to evaluating the translation model also allows us to include some useful functions and vocabulary libraries as well."
전이학습을 활용한 소규모 비정형 정책데이터 감성분석 모델,2020,"['감성분석', '딥러닝', '소규모 데이터', '빅데이터 분석', '전시학습', '정책평가', 'Big data analysis', 'Deep learning', 'Policy evaluation', 'Sentiment analysis', 'Small-scale data', 'Transfer learning']",최근 빅데이터 기술의 발전에도 불구하고 정책분야에서는 텍스트 등 비정형 데이터의 부족으로 감성분석 연구에 제한이 많았다. 이에 본 연구에서는 전이학습을 기반으로 소규모 비정형 정책 데이터를 활용한 감성분석 모델을 제안한다. 이를 위해 네이버 영화리뷰 20만 건의 댓글로 CNN 모델을 생성하고 지역 리뷰 1만 건의 댓글을 이용하여 전이학습을 수행하였다. 분석결과 본 연구에서 제안한 전이학습 모델은 소규모 데이터만으로 생성된 모델보다 약 10%의 정확도 향상과 1epoch당 1000ms의 학습지간 단축을 보였다. 본 연구의 공헌도로 학술적으로는 한글 텍스트 감성분석에 전이학습을 처음으로 적용하여 향후 소규모 데이터의 감성분석 연구에 활용할 수 있는 이론적 기반을 제공하였다는 점이다. 실무적으로는 데이터가 부족하여 시도하기 어려웠던 정책 분야의 감성분석을 통해 정부사업의 성공여부를 판별할 수 있는 기초자료로 활용할 수 있다.,"Despite the recent development in big data technologies, the research on sentiment analysis is still facing many limitations due to the lack of unstructured data, including texts, in the policy field. Thus, this study proposes a sentiment analysis model for small-scale unstructured policy data based on transfer learning. As a result, the proposed transfer learning model achieved about 10% better accuracy and a shorter training time of 1000 ms per epoch than the model generated only by using small-scale data. As an academic contribution, this study, which is the first application of transfer learning to Korean text sentiment analysis, provides a theoretical basis for future research on sentiment analysis using small-scale data. For practicality, this study can serve as basic data in determining the success or failure of government projects through sentiment analysis in the policy field, which was difficult to determine previously given the lack of data. the detailed feature of sea/land breeze at each site is closely associated with the local shape of coastline."
Aerial Object Detection and Tracking based on Fusion of Vision and Lidar Sensors using Kalman Filter for UAV,2020,"['Vision Sensor', 'LiDAR', 'Sensor fusion', 'Kalman filter', 'Object detection', 'Position estimation']",,"In this paper, we study on aerial objects detection and position estimation algorithm for the safety of UAV that flight in BVLOS. We use the vision sensor and LiDAR to detect objects. We use YOLOv2 architecture based on CNN to detect objects on a 2D image. Additionally we use a clustering method to detect objects on point cloud data acquired from LiDAR. When a single sensor used, detection rate can be degraded in a specific situation depending on the characteristics of sensor. If the result of the detection algorithm using a single sensor is absent or false, we need to complement the detection accuracy. In order to complement the accuracy of detection algorithm based on a single sensor, we use the Kalman filter. And we fused the results of a single sensor to improve detection accuracy. We estimate the 3D position of the object using the pixel position of the object and distance measured to LiDAR. We verified the performance of proposed fusion algorithm by performing the simulation using the Gazebo simulator."
실내 핑거프린트 측위를 위한 딥러닝 기반의 초고해상도 RF 맵 재구성 기법,2020,"['실내 위치 추정', '핑거프린트 측위', 'RF 맵 재구성', '딥러닝']",본 논문은 실내 핑거프린트 측위의 정확도를 향상시키기 위한 딥러닝 기반의 RF 맵 재구성 기법을 제안한다. 제안 기법은 합성곱 신경망 구조를 사용하여 희소 데이터와 정답 데이터와의 관계를 직접 학습함으로써 오프라인 단계에서 조사하지 않은 지역의 RF 맵을 고해상도로 복원한다. 실험 결과를 통해 제안 기법이 기존의 핑거프린트 측위보다 7.53m 향상된 측위 정확도를 가지며 다항식 보간법으로 RF 맵을 재구성하는 기법보다 0.92m의 추가적인 측위 정확도를 획득하였다.,"In this paper, we propose a deep learning-based radio frequency (RF) map reconstruction method to improve the accuracy of the indoor fingerprint positioning. The proposed scheme reconstructs the RF map in super-resolution using a convolutional neural network (CNN) by directly learning with sparse data and ground truth data in the offline phase. The simulation results show that the proposed method has 7.53m improved positioning accuracy than the conventional fingerprint positioning and 0.92m additional positioning accuracy than the bicubic interpolation method."
화재방호 설비 설계 자동화를 위한 선행연구 및 기술 분석,2020,[],,"This paper presents the recent research developments identified through a review of literature on the application of artificial intelligence in developing automated designs of fire protection facilities. The literature review covered research related to image recognition and applicable neural networks. Firstly, it was found that convolutional neural network (CNN) may be applied to the development of automating the design of fire protection facilities. It requires a high level of object detection accuracy necessitating the classification of each object making up the image. Secondly, to ensure accurate object detection and building information, the data need to be pulled from architectural drawings. Thirdly, by applying image recognition and classification, this can be done by extracting wall and surface information using dimension lines and pixels. All combined, the current review of literature strongly indicates that it is possible to develop automated designs for fire protection utilizing artificial intelligence."
딥러닝을 이용한 쿼드콥터의 호버링 제어,2020,"['Quadcopter', 'Image Processing', 'Deep Learning']",,"In this paper, In this paper, we describe the UAV system using image processing for autonomous quadcopters, where they can apply logistics, rescue work etc.  we propose high-speed hovering height and posture control method based on state feedback control with CNN from camera because we can get image of the information only every 30ms. Finally, we show the advantages of proposed method by simulations and experiments."
Aerial Object Detection and Tracking based on Fusion of Vision and Lidar Sensors using Kalman Filter for UAV,2020,"['Vision Sensor', 'LiDAR', 'Sensor fusion', 'Kalman filter', 'Object detection', 'Position estimation']",,"In this paper, we study on aerial objects detection and position estimation algorithm for the safety of UAV that flight in BVLOS. We use the vision sensor and LiDAR to detect objects. We use YOLOv2 architecture based on CNN to detect objects on a 2D image. Additionally we use a clustering method to detect objects on point cloud data acquired from LiDAR. When a single sensor used, detection rate can be degraded in a specific situation depending on the characteristics of sensor. If the result of the detection algorithm using a single sensor is absent or false, we need to complement the detection accuracy. In order to complement the accuracy of detection algorithm based on a single sensor, we use the Kalman filter. And we fused the results of a single sensor to improve detection accuracy. We estimate the 3D position of the object using the pixel position of the object and distance measured to LiDAR. We verified the performance of proposed fusion algorithm by performing the simulation using the Gazebo simulator."
사용자 상호작용 기반의 시선 검출을 위한 비강압식 캘리브레이션,2020,"['시선 검출', '비강압식 캘리브레이션', '사용자 상호작용', '합성곱 신경망', 'gaze estimation', 'non-intrusive calibration', 'user interaction', 'convolutional neural network']","본 논문에서는 웹 페이지 탐색 시 지속해서 발생하는 사용자 상호작용 과정을 이용하여 시선 검출을 위한 캘리브레이션 데이터를 획득하고, 사용자의 시선을 검출하는 동안 자연스럽게 캘리브레이션을 수행하는 방법에 관하여 기술하였다. 제안된 비강압식 캘리브레이션은 획득한 캘리브레이션 데이터를 이용하여 미리 학습된 시선 검출 CNN 모델을 새로운 사용자에 적응하도록 보정하는 과정이다. 이를 위해 훈련을 통해서 시선을 검출하는 일반화된 모델을 만들고 캘리브레이션에서는 온라인 학습 과정을 통해 빠르게 새로운 사용자에 적응하도록 하였다. 실험을 통하여 다양한 사용자 상호작용의 조합으로 시선 검출 모델을 캘리브레이션 하여 성능을 비교하였으며, 기존 방법 대비 개선된 정확도를 얻을 수 있었다.",
Video Saliency Detection Using Bi-directional LSTM,2020,"['Visual saliency', 'Computer Graphics Deep learning', 'Deep two-way long-term short memory', 'Convolutional neural network']",,"Significant detection of video can more rationally allocate computing resources and reduce the amount of computation to improve accuracy. Deep learning can extract the edge features of the image, providing technical support for video saliency. This paper proposes a new detection method. We combine the Convolutional Neural Network (CNN) and the Deep Bidirectional LSTM Network (DB-LSTM) to learn the spatio-temporal features by exploring the object motion information and object motion information to generate video. A continuous frame of significant images. We also analyzed the sample database and found that human attention and significant conversion are time-dependent, so we also considered the significance detection of video cross-frame. Finally, experiments show that our method is superior to other advanced methods."
A Parallel Deep Convolutional Neural Network for Alzheimer’s disease classification on PET/CT brain images,2020,"['Computer vision', 'Deep learning', 'Convolutional neural networks', 'Parallel model', 'Image classification', 'Alzheimer’s disease']",,"In this paper, a parallel deep learning model using a convolutional neural network and a dilated convolutional neural network is proposed to classify Alzheimer’s disease with high accuracy in PET/CT images. The developed model consists of two pipelines, a conventional CNN pipeline, and a dilated convolution pipeline. An input image is sent through both pipelines, and at the end of both pipelines, extracted features are concatenated and used for classifying Alzheimer’s disease. Complimentary abilities of both networks provide better overall accuracy than single conventional CNNs in the dataset. Moreover, instead of performing binary classification, the proposed model performs three-class classification being Alzheimer’s disease, mild cognitive impairment, and normal control. Using the data received from Dong-a University, the model performs classification detecting Alzheimer’s disease with an accuracy of up to 95.51%."
Error Improvement in Visual Odometry Using Super-resolution,2020,"['Robust Visual Odometry', 'super-resolution', 'visual odometry', 'visual SLAM.']",,"Visual odometry (VO), a method that estimates odometry using visual sensors, is hard to operate successfully with the low-resolution and noisy image sequences. To address this problem, a super-resolution technique is applied to input data before performing VO. Since most conventional super-resolution literature mainly deals with the resolution increment, we present a novel deep neural super-resolution network, which can remove noises as well. The execution time is also taken into account by adjusting the number of CNN layers for a real-time VO. By applying the proposed super-resolution approach, the resolution increases and noises disappear with a suitable speed, hence VO can be performed successfully. Experimental results show that the proposed method improves the VO performance compared with the conventional VO which uses low-resolution and noisy image sequences."
Scheme of a Classic Control-Based Program Model with Non-Symmetric Deep Auto-Encoder of Actor-Critic,2020,"['actor-critic', 'program model', 'OpenAI gym', 'non-symmetric deep auto-encoder', 'reinforcement learning']",,"Reinforcement learning (RL), particularly Actor-Critic (A2C), one of policy gradient (PG) algorithms becomes a mainstream. A design of a classic control-based program model requires domain-indicated experience knowledge based on a neural network for incorporating into the model strategy, which becomes A2C-powered. There are some research studies on the program model using general Artificial Intelligence (AI) techniques, in other words, A2C and neural networks. The previous well-known algorithms can proceed from a simple Convolutional Neural Network (CNN), to attempting an experiment with more complicated additions, such as LSTM (Long Short-Term Memory models). However, there are concerns about the requirements of the current experimental environment when faced with the demands of significant computational powers. Therefore, we employ a definition of Actor-Critic with non-symmetric deep auto-encoder to find an optimal behavior strategy for the agent to obtain optimal rewards with the bottommost environmental resources. Algorithm comparisons show that our proposed model demonstrates improvements of optimal rewards with the minimum limit over the developed deep neural network combined Actor-Critic."
심층학습 기반 표정인식을 통한 학습 평가 보조 방법 연구,2020,"['Process-based evaluation', 'Deep learning', 'Convolutional neural network', 'Evaluation', 'Face expression']",,"This paper proposes the approaches to the evaluation of learning using concepts of artificial intelligence. Among various techniques, deep learning algorithm is employed to achieve quantitative results of evaluation. In particular, this paper focuses on the process-based evaluation instead of the result-based one using face expression. The expression is simply acquired by digital camera that records face expression when students solve sample test problems. Face expressions are trained using convolutional neural network (CNN) model followed by classification of expression data into three categories, i.e., easy, neutral, difficult. To substantiate the proposed approach, the simulation results show promising results, and this work is expected to open opportunities for intelligent evaluation system in the future."
스킵 연결 형태 기반의 손 관절 2D 및 3D 검출 기법,2020,['-'],,"Traditional pose estimation methods include using special devices or images through image processing. The disadvantage of using a device is that the environment in which the device can be used is limited and costly. The use of cameras and image processing has the advantage of reducing environmental constraints and costs, but the performance is lower. CNN(Convolutional Neural Networks) were studied for pose estimation just using only camera without these disadvantage. Various techniques were proposed to increase cognitive performance. In this paper, the effect of the skip connection on the network was experimented by using various skip connections on the joint recognition of the hand. Experiments have confirmed that the presence of additional skip connections other than the basic skip connections has a better effect on performance, but the network with downward skip connections is the best performance."
단안 카메라와 심층강화학습을 이용한소형 무인기 실내 충돌 회피 시스템,2020,"['collision avoidance', 'deep reinforcement learning', 'D3QN', 'depth estimation', 'monocular camera', '.']",,.
딥러닝을 이용한 증강현실 기반 음료정보 시각화 및 공유 시스템,2020,"['영상인식', '증강현실', '딥러닝', '상품검색', '정보공유시스템', 'Image Recognition', 'Augmented Realty', 'Deep Learning', 'Product Search', 'Share system']",,"In this paper, we introduce a system that searches for commercial beverages and alcohol products using image recognition technology and visualizes the information of the products using augmented reality system. It also introduces the design and development of a system that allows users to register and share product taste information using a web-based mobile platform. For image recognition, learning data was generated through the data set construction and expansion technology of beverage images and CNN learning was conducted. For augmented reality visualization, the augmented reality system is designed to operate by immediately registering a marker after product recognition using a UDT marker . Lastly, we proposed a consumer-friendly sharing system applying the product recommendation technology developed by the multiple linear regression model. The proposed research is expected to make it easy for consumers to obtain product information through cameras and to be applied as a new business strategy in the information retrieval and sharing market."
A study on the condition based maintenance evaluation system of smart plant device using convolutional neural network,2020,['· CBM · Convolutional neural network · Defect classification · Smart plant maintenance system'],,"There are two main causes of plant accidents: poor maintenance management and human error. In this study, we implemented a smart plant maintenance system that can reduce human errors based on the conditional based maintenance (CBM) concept. Unlike smart plant technology, which focuses on existing technology, we interviewed actual engineers and implemented a system reflecting their needs. First, we implemented three methods for learning defective images using convolutional neural network (CNN) and found that blob detection processing improves learning accuracy. Second, the fitness for service API (FFS API) methodology used in the actual pitting corrosion maintenance evaluation method was used to implement the CBM system. Finally, we verified the reliability of this system by conducting validation through actual case study."
내시경의 위암과 위궤양 영상을 이용한 합성곱 신경망 기반의 자동 분류 모델,2020,"['Gastroscopy', 'Classification', 'ResNet-50', 'Gastric ulcer', 'Gastric cancer']",,"Although benign gastric ulcers do not develop into gastric cancer, they are similar to early gastric cancer and difficult to distinguish. This may lead to misconsider early gastric cancer as gastric ulcer while diagnosing. Since gastric cancer does not have any special symptoms until discovered, it is important to detect gastric ulcers by early gastroscopy to prevent the gastric cancer. Therefore, we developed a Convolution Neural Network (CNN) model that can be helpful for endoscopy. 3,015 images of gastroscopy of patients undergoing endoscopy at Gachon University Gil Hospital were used in this study. Using ResNet-50, three models were developed to classify normal and gastric ulcers, normal and gastric cancer, and gastric ulcer and gastric cancer. We applied the data augmentation technique to increase the number of training data and examined the effect on accuracy by varying the multiples. The accuracy of each model with the highest performance are as follows. The accuracy of normal and gastric ulcer classification model was 95.11% when the data were increased 15 times, the accuracy of normal and gastric cancer classification model was 98.28% when 15 times increased likewise, and 5 times increased data in gastric ulcer and gastric cancer classification model yielded 87.89%. We will collect additional specific shape of gastric ulcer and cancer data and will apply various image processing techniques for visual enhancement. Models that classify normal and lesion, which showed relatively high accuracy, will be re-learned through optimal parameter search."
MICE산업을 활용한 인천지역 섬 관광 콘텐츠 홍보방안,2020,"['MICE industry', 'MICE 산업', 'Incheon areas', '인천지역', 'island tourism contents', '섬 관광 콘텐츠', 'tourism advertisements', '관광광고', 'plan to promote', '홍보방안', 'new media', '뉴미디어', 'mega events', '메가 이벤트']",,"This study reviewed the literature to effectively promote the tourism contents of islands in the Incheon area by utilizing the MICE industry. In particular, this study has significance in that it promoted tourism on the islands of Incheon in connection with the tourism promotion and MICE industry with the characteristics of the new media, which has been in the spotlight recently. In March 2012, CNN, the largest media outlet in the United States, selected 33 beautiful islands from around the world. Five Incheon Islands-Seonjaedo Island(1st place), Deokjeokdo Island(6th place), Ganghwado Island(8th place), Baeknyeongdo Island(21st place) and Palmido Island(29th place) were selected. This means that Incheon’s islands have abundant tourism contents. In terms of having some of the world's top tidal flats, outstanding natural scenery, and historical and culturally important assets, the potential for tourism development in Incheon is quite high. Therefore, this study revisited the value of 168 islands in the Incheon area and devised a plan to promote sustainable island tourism based on the various resources and characteristics of the islands. To this end, a plan to utilize the MICE industry, which is rapidly growing as a new medium, has been proposed as a publicity plan for tourism contents on the islands in the Incheon area. As a result, first, it was proposed to hold an island tourism promotion MICE that utilizes information and communication technologies of the fourth industrial revolution such as hybrid MICE, Blockchain MICE, and VR/AR/MR MICE. Second, publicity was presented through the exhibition and expo events related to Incheon’s islands’ tourism contents. Third, a plan to promote the tourism contents of the islands linked to the MICE industry by using the off-season of the island area was suggested. Through this, the city of Incheon also presented contents for attracting tourists to the islands of Incheon and promoting the convenience to tourists while also promoting general island tourism in the locale. It was suggested that the MICE industry should be used based on the broad concept of tourism, including tourism advertisements, personal sales, tourism publicity, tourism sales promotion activities, and island tourism content guide services provided to them. This pointed out that it is necessary to promote the tourism of islands in Incheon for each characteristic by utilizing the island tourism exhibition and expo, incentive tours, international conferences, and mega events."
부시즘 또는 인지상의 말실수?—유튜브 자료에 기반한 기초 연구—,2020,"['Slips of the Tongue', 'Bushism', 'Speech Errors', 'George W. Bush', '(Intersemiotic) Translation']",,"This research aims to implement a preliminary analysis of the peculiar speech data called Bushism (presumably including the verbal slips produced by the former U.S. President George W. Bush). In order to compare the notion and phenomenon of Bushism with the actual SOTs, keyword-based online searches are conducted on Google and YouTube. In this pilot study using 6 YouTube videos available in the 6 major broadcasting companies"" online archives (e.g., AP, CBS, CNN, NBC, Reuters, and SKY News), 42 samples are collected upon the screening process. By adopting the systematic typology and criteria of Jaeger (2005), it turns out that (a) a lot of Bushism-based online videos contain more controversial (yet less relevant) episodes including nonverbal icebreaking acts and (b) there are many examples that are copied, reuploaded, and requoted. When it comes to the authentic SOT examples (27 out of 42: 64.28%), the selected examples suggest a natural and understandable degree/ boundary of psycholinguistic regularity and productivity in human language production by exhibiting regular and predictable patterns in terms of the form and directionality of the constituents involved. Moreover, unlike the old belief that slips of the tongue are generally synonymous with spoonerism and malapropism, a variety of speech error patterns are equally observed on general linguistic levels (throughout the phonetic, phonemic, phonological, morphological, lexical, syntactic, and pragmatic levels). Such general taxonomy, distribution, constraints, and principles seem to be closely related to the question of (inter-) semiotic iconicity in the brain-language-to-verbal-language translation processes, even though the target text/domain and the arrival text/domain may have failed to match up, particularly, owing to the intrinsic conditions of human cognition and speech production. In conclusion, Bushism and President Bush""s SOTs should be distinguished more carefully. In addition, it is important to note that the SOTs and pragmatic errors can be systematically and adequately explained by their contexts as well as by the speaker""s self repairs. Such results imply the significance of metasemiotic, metatranslative, metalinguistic, and metacognitive scrutinization, especially, in addressing and decoding the ‘surname + -ism’ method/ phenomenon."
Oil Pipeline Weld Defect Identification System Based on Convolutional Neural Network,2020,"['pipeline x-ray welding image', 'automatic identification', 'feature extraction', 'convolution neural network', 'convolution operation']",,"The automatic identification and classification of image-based weld defects is a difficult task due to the complex texture of the X-ray images of the weld defect. Several depth learning methods for automatically identifying welds were proposed and tested. In this work, four different depth convolutional neural networks were evaluated and compared on the 1631 image set. The concavity, undercut, bar defects, circular defects, unfused defects and incomplete penetration in the weld image 6 different types of defects are classified. Another contribution of this paper is to train a CNN model ""RayNet"" for the dataset from scratch. In the experiment part, the parameters of convolution operation are compared and analyzed, in which the experimental part performs a comparative analysis of various parameters in the convolution operation, compares the size of the input image, gives the classification results for each defect, and finally shows the partial feature map during feature extraction with the classification accuracy reaching 96.5%, which is 6.6% higher than the classification accuracy of other existing fine-tuned models, and even improves the classification accuracy compared with the traditional image processing methods, and also proves that the model trained from scratch also has a good performance on small-scale data sets. Our proposed method can assist the evaluators in classifying pipeline welding defects."
싱글숏 멀티박스 검출기에서 객체 검출을 위한 가속 회로 인지형 가지치기 기반 합성곱 신경망 기법,2020,"['Convolutional neural networks', 'Pruning', 'Object detection', 'Single-shot multibox detector']",,"Convolutional neural networks (CNNs) show high performance in computer vision tasks including object detection, but a lot of weight storage and computation is required. In this paper, a pruning scheme is applied to CNNs for object detection, which can remove much amount of weights with a negligible performance degradation. Contrary to the previous ones, the pruning scheme applied in this paper considers the base accelerator architecture. With the consideration, the pruned CNNs can be efficiently performed on an ASIC or FPGA accelerator. Even with the constrained pruning, the resulting CNN shows a negligible degradation of detection performance, less-than-1% point degradation of mAP on VOD0712 test set. With the proposed scheme, CNNs can be applied to objection dtection efficiently."
An Exploratory Study on the 2018 North Korea-U.S. Summit News and Singapore’s Place Branding,2020,"['North Korea-US Summit', '‘Trump-Kim’ Summit', 'Singapore', 'Place Branding']",,"The purpose of this paper is to examine how mainstream international media cover a major political event like the 2018 North Korea-U.S. Summit and how place branding effect is manifested on the Internet. A quantitative content analysis was conducted. A total of 1,990 relevant Internet news stories were collected from May 9 to June 17, 2018 and the types of media mentions Singapore as country and brand received were analyzed. As expected, Singapore garnered worldwide media coverage which in turn helped promote the island-nation’s brand. International media reported on Singapore as a Summit location while also highlighting it as an important and attractive, cultural, historical destination. The study’s findings indicate that global broadcasters such as CNN and BBC played the biggest role during the Summit in disseminating images of Singapore and landmarks as attractive places. Finally, the visual aspect of the event coverage also served as a formidable marketing instrument in bolstering the nation’s brand."
감시 비디오에서 등록 및 미등록 물체의 실시간 도난 탐지,2020,[],,"Recently, the smart video surveillance research, which has been receiving increasing attention, has mainly focused on the intruder detection and tracking, and abandoned object detection. On the other hand, research on real-time detection of stolen objects is relatively insufficient compared to its importance. Considering various smart surveillance video application environments, this paper presents two different types of stolen object detection algorithms. We first propose an algorithm that detects theft of statically and dynamically registered surveillance objects using a dual background subtraction model. In addition, we propose another algorithm that detects theft of general surveillance objects by applying the dual background subtraction model and Mask R-CNN-based object segmentation technology. The former algorithm can provide economical theft detection service for pre-registered surveillance objects in low computational power environments, and the latter algorithm can be applied to the theft detection of a wider range of general surveillance objects in environments capable of providing sufficient computational power."
서울 관악구 도심지역 미세먼지(PM<sub>10</sub>) 관측 값을 활용한 딥러닝 기반의 농도변동 예측,2020,"['fine dust ( $PM_{10}$)', 'precursor', 'deep learning', 'convolutional neural network', 'recurrent neural network', 'prediction']",,"Since fine dust (PM<sub>10</sub>) has a significant influence on soil and groundwater composition during dry and wet deposition processes, it is of a vital importance to understand the fate and transport of aerosol in geological environments. Fine dust is formed after the chemical reaction of several precursors, typically observed in short intervals within a few hours. In this study, deep learning approach was applied to predict the fate of fine dust in an urban area. Deep learning training was performed by combining convolutional neural network (CNN) and recurrent neural network (RNN) techniques. The PM<sub>10</sub> concentration after 1 hour was predicted based on three-hour data by setting SO<sub>2</sub>, CO, O<sub>3</sub>, NO<sub>2</sub>, and PM<sub>10</sub> as training data. The obtained coefficient of determination value, R<sup>2</sup>, was 0.8973 between predicted and measured values for the entire concentration range of PM<sub>10</sub>, suggesting deep learning method can be developed into a reliable and viable tool for prediction of fine dust concentration."
AI 의료영상 분석의 개요 및 연구 현황에 대한 고찰,2020,"['인공지능', '의료영상', '딥 러닝', '인공신경망', 'Artificial Intelligence', 'Medical Imaging', 'Deep Learning', 'Artificial Neural Network']",,"Artificial intelligence(AI) is a field of computer science that is defined as allowing computers to imitate human intellectual behavior, even though AI s performance is to imitate humans. It is grafted across software-based fields with the advantages of high accuracy and speed of processing that surpasses humans. Indeed, the AI based technology has become a key technology in the medical field that will lead the development of medical image analysis. Therefore, this article introduces and discusses the concept of deep learning-based medical imaging analysis using the principle of algorithms for convolutional neural network(CNN) and back propagation. The research cases application of the AI based medical imaging analysis is used to classify the various disease(such as chest disease, coronary artery disease, and cerebrovascular disease), and the performance estimation comparing between AI based medical imaging classifier and human experts."
Automatic Sagittal Plane Detection for the Identification of the Mandibular Canal,2020,"['자동 평면 검출', '합성곱 신경망', '변환 최적화', '치아 임플란트 계획.', 'Automatic plane detection', 'Convolutional Neural Network', 'Transformation optimization', 'Dental implant planning.']",,"Identification of the mandibular canal path in Computed Tomography (CT) scans is important in dental implantology. Typically, prior to the implant planning, dentists find a sagittal plane where the mandibular canal path is maximally observed, to manually identify the mandibular canal. However, this is time-consuming and requires extensive experience. In this paper, we propose a deep-learning-based framework to detect the desired sagittal plane automatically. This is accomplished by utilizing two main techniques: 1) a modified version of the iterative transformation network (ITN) method for obtaining initial planes, and 2) a fine searching method based on a convolutional neural network (CNN) classifier for detecting the desirable sagittal plane. This combination of techniques facilitates accurate plane detection, which is a limitation of the stand-alone ITN method. We have tested on a number of CT datasets to demonstrate that the proposed method can achieve more satisfactory results compared to the ITN method. This allows dentists to identify the mandibular canal path efficiently, providing a foundation for future research into more efficient, automatic mandibular canal detection methods."
Fuzzy Sliding Mode Control of Nonparallel-ground-track Imaging Satellite with High Precision,2020,"['Fuzzy systems', 'neural networks', 'satellite', 'sliding mode control.']",,"In this paper, a high-precision attitude tracking controller is proposed for the next-generation intelligent optical satellite with nonparallel-ground-track imaging (NPGTI) mode, where imaging targets and sub-satellite track are not parallel. First, the specific method of attitude steering for NPGTI mode is investigated to obtain the desired attitude and angular velocity. Then a nonsingular fast terminal sliding mode controller (NFTSMC) is designed based on the tracking error dynamics and kinematics described by unit error-quaternion to guarantee the tracking of the desired attitude. Accounting for the disadvantage of the chattering, a Chebyshev neural network (CNN), whose basis functions are implemented using only desired signals is then introduced to enhance the control precision by estimating the total perturbation of the system. Finally, numerical simulations are performed to testify the effectiveness of the control scheme in the presence of environmental disturbances and parameter uncertainties, and the results show that the proposed control scheme can meet the stringent requirements of control precision for the intelligent optical satellite with fast convergence speed, good robustness, and easy engineering implementation."
Deep Learning: High-quality Imaging through Multicore Fiber,2020,"['Deep learning', 'Multi-core fiber', 'Imaging']",,"Imaging through multicore fiber (MCF) is of great significance in the biomedical domain. Although several techniques have been developed to image an object from a signal passing through MCF, these methods are strongly dependent on the surroundings, such as vibration and the temperature fluctuation of the fiber’s environment. In this paper, we apply a new, strong technique called deep learning to reconstruct the phase image through a MCF in which each core is multimode. To evaluate the network, we employ the binary cross-entropy as the loss function of a convolutional neural network (CNN) with improved U-net structure. The high-quality reconstruction of input objects upon spatial light modulation (SLM) can be realized from the speckle patterns of intensity that contain the information about the objects.Moreover, we study the effect of MCF length on image recovery. It is shown that the shorter the fiber, the better the imaging quality. Based on our findings, MCF may have applications in fields such as endoscopic imaging and optical communication."
자동차용 강판의 스폿용접 전극수명예측 알고리즘 개발,2020,"['스폿 용접', '전극 수명', '아연도금강판', '동저항', '이미지 데이터', 'Spot welding', 'Electrode life', 'Galvanized steel plate', 'Dynamic resistance', 'Image data']",,"Spot welding is a representative process in automotive welding and the application of intelligent systems is accelerating. In particular, in the case of welding electrode management, the timing of electrode wear and dressing was determined by continuous spot welding evaluation, however there is concerned that errors in welding equipment or processes may work in a complex manner. In this study, a dynamic resistance waveform sensing and image measurement system that greatly affects the nugget formation, which is important to the quality of spot welding, was fabricated and used. Based on the experimental data of the galvanized steel sheet, an electrode life prediction algorithm for electrode wear was derived through CNN(Convolutional Neural Network) model of machine learning training."
손글씨 인식 학습 모델 기반 수식 연산에 대한 연구,2020,"['딥러닝', '인식', '계산', 'Deep-Learning', 'Recognition', 'Calculation']","정보화 기술의 발달로 인해 문서 작성이나 브라우저 검색기능 같은 작업들이 모두 키보드 타이핑만으로 가능하게 되었다. 하지만 수학 계산식 같은 경우에는 키보드 타이핑으로 작성하기가 어려운 것을 알 수 있다. 계산식 같은 경우는 키보드가 아닌 아날로그 식으로 본인이 직접 수기하는 것이 시간도 절약되고 타이핑하는 것보다 오히려 편하다는 것을 알 수 있다. 그러기에 수학 계산식을 검색해서 답을 찾으려 할 때 사용자들은 불편함을 느끼게 된다.본 논문은 컴퓨터가 학습한 딥 러닝 모델로 수기로 작성된 수학 수식을 텍스트 형태로 바꿀 때, 더 정확하게 인식하는 모델의 종류가 무엇인지 제공한다. 숫자와 사칙 연산 기호뿐만 아니라 사용자가 정의한 연산자로도 정확한 인식이 가능한지를 확인한다. 이를 위해 DenseNet, ResNet과 같은 CNN 모델 이용하여 실험을 수행하였고, 실험을 통하여 그 중 가장 적합한 모델을 찾아내었다.",
심층 신경회로망 앙상블을 이용한 걸음걸이 인식에 대한 연구,2020,"['Gait Recognition', 'deep neural network', 'deep neural network ensemble', 'Gait Energy Image (GEI)', 'Motion Silhouette Image (MSI)']",,"The recognition of a person from his (her) gait has been a recent focus in computer vision because of its unique advantages such as non-invasive and human friendly. Gait recognition, however, has the weakness that it is not reliable compared with other biometrics.In this paper, we applied deep neural network ensemble to the gait recognition problem. The deep neural network ensemble is a learning paradigm where a collection of deep neural networks is trained for the same task. Generally, the ensemble shows better generalization performance than a single deep neural network such as convolution neural network and recurrent neural network. To increase reliability of the gait recognition, gait energy image (GEI) and Motion silhouette image (MSI) are extracted for gait features and convolution and recurrent neural network ensemble are used for classifier. Experiments are performed with the NLPR and SOTON databases to show the efficiency of the proposed algorithm. The performance of proposed method is 4.55%, 4.85%, 2.5% and 2.43% better than single CNN, respectively in two databases. As a result we can create a recognition system with accuracy of 100%, 100%, and 94% in the NLPR database and 97.35% in the SOTON database."
Feature Selection for Abnormal Driving Behavior Recognition Based on Variance Distribution of Power Spectral Density,2020,"['Abnormal driving', 'Machine learning', 'Spectrogram', 'Variance', 'Smartphone sensor']",,"The detection and recognition of abnormal driving becomes crucial for achieving safety in Intelligent Transportation Systems (ITS). This paper presents a feature extraction method based on spectral data to train a neural network model for driving behavior recognition. The proposed method uses a two stage signal processing approach to derive time-saving and efficient feature vectors. For the first stage, the feature vector set is obtained by calculating variances from each frequency bin containing the power spectrum data. The feature set is further reduced in the second stage where an intersection method is used to select more significant features that are finally applied for training a neural network model. A stream of live signals are fed to the trained model which recognizes the abnormal driving behaviors. The driving behaviors considered in this study are weaving, sudden braking and normal driving. The effectiveness of the proposed method is demonstrated by comparing with existing methods, which are Particle Swarm Optimization (PSO) and Convolution Neural Network (CNN). The experiments show that theproposed approach achieves satisfactory results with less computational complexity."
Feature Selection for Abnormal Driving Behavior Recognition Based on Variance Distribution of Power Spectral Density,2020,"['Abnormal driving', 'Machine learning', 'Spectrogram', 'Variance', 'Smartphone sensor']",,"The detection and recognition of abnormal driving becomes crucial for achieving safety in Intelligent Transportation Systems (ITS). This paper presents a feature extraction method based on spectral data to train a neural network model for driving behavior recognition. The proposed method uses a two stage signal processing approach to derive time-saving and efficient feature vectors. For the first stage, the feature vector set is obtained by calculating variances from each frequency bin containing the power spectrum data. The feature set is further reduced in the second stage where an intersection method is used to select more significant features that are finally applied for training a neural network model. A stream of live signals are fed to the trained model which recognizes the abnormal driving behaviors. The driving behaviors considered in this study are weaving, sudden braking and normal driving. The effectiveness of the proposed method is demonstrated by comparing with existing methods, which are Particle Swarm Optimization (PSO) and Convolution Neural Network (CNN). The experiments show that the proposed approach achieves satisfactory results with less computational complexity."
원형 구조 알고리즘을 이용한 근전도 패턴 인식 및 분류,2020,"['Electromyography', 'Pattern Recognition', 'Classification', 'Deep Learning']",,"This paper proposes a pattern recognition and classification algorithm based on a circular structure that can reflect the characteristics of the sEMG (surface electromyogram) signal measured in the arm without putting the placement limitation of electrodes. In order to recognize the same pattern at all times despite the electrode locations, the data acquisition of the circular structure is proposed so that all sEMG channels can be connected to one another. For the performance verification of the sEMG pattern recognition and classification using the developed algorithm, several experiments are conducted. First, although there are no differences in the sEMG signals themselves, the similar patterns are much better identified in the case of the circular structure algorithm than that of conventional linear ones. Second, a comparative analysis is shown with the supervised learning schemes such as MLP, CNN, and LSTM. In the results, the classification recognition accuracy of the circular structure is above 98% in all postures. It is much higher than the results obtained when the linear structure is used. The recognition difference between the circular and linear structures was the biggest with about 4% when the MLP network was used."
해상 이미지를 활용한 3D 합성곱 신경망과합성곱 장단기 메모리 신경망 기반의 유의 파고 추정,2020,"['Significant Wave Height', '3D Convolution', 'Convolutional LSTM', 'Image Processing']",,"One of the most common measures implemented in the operation of large vessels is to find the route that takes the least fuel consumption based on marine conditions, such as wave height. The model that predicts wave height can roughly be categorized into two methods, namely, a numerical method that calculates by physical formula and a soft-computing method that collects weather information and learns the machine learning algorithm. These models are difficult to apply in the real world because of their high computational complexity and the use of expensive radar equipment. In this study, we propose to estimate the wave height in real time using the images of the ocean. We used the image data consisting of four consecutive images instead of a single image and applied the combination of convolutional LSTM and 3D CNN networks that can best handle the data structure as a regression model. In this way of prediction, existing methods are not only outperformed but are also more robust to outliers. We used data from the “Weather 1st” ship provided by Daewoo Shipbuilding & Marine Engineering and confirmed that the mean absolute error is 1.59 cm, and the mean absolute percentage error is as low as 1.61% based on the test set."
A study on selective dehazing system based on haze detection network,2020,"['Image processing', 'Deep neural network', 'Dehazing', 'Haze detection']",,"Image dehazing, which aims to recover a clear image solely from a hazy or foggy image, is a particularly challenging task. Many studies have recently been conducted to improve the performance of image dehazing using deep neural networks. However, existing approaches do not consider changes in haze density, and thus even if a clear image is input, distortions such as sharpening may occur. In addition, because the number of datasets available in deep learning, whose contents are image pairs of hazy and corresponding haze-free (ground truth) indoor images, is quite limited, the haze removal performance may be reduced. To solve this problem, in this paper, a selective dehazing system is proposed that combines a haze detection network and a dehazing network. The proposed haze detection network is designed using a CNN structure to determine the haze density of the input image, and the use of the dehazing network is determined. The proposed dehazing network uses the U-Net model to efficiently learn only a limited number of datasets. To evaluate the performance of the proposed network, only 45 O-Hazes were used. The result of haze detection shows that the proba-bility of detecting a haze image is more than 99% and the probability of detecting a haze-free image is 97.9%. Dehazing evaluation results improved the PSNR and SSIM by more than 10% compared to existing networks."
A Study of Machine Learning based Face Recognition for User Authentication,2020,"['Machine Learning', 'Deep Learning', 'Neural Network', 'Authentication', 'Face Recognition']",,"According to brilliant development of smart devices, many related services are being devised. And, almost every service is designed to provide user-centric services based on personal information. In this situation, to prevent unintentional leakage of personal information is essential. Conventionally, ID and Password system is used for the user authentication. This is a convenient method, but it has a vulnerability that can cause problems due to information leakage. To overcome these problem, many methods related to face recognition is being researched. Through this paper, we investigated the trend of user authentication through biometrics and a representative model for face recognition techniques. One is DeepFace of FaceBook and another is FaceNet of Google. Each model is based on the concept of Deep Learning and Distance Metric Learning, respectively. And also, they are based on Convolutional Neural Network (CNN) model. In the future, further research is needed on the equipment configuration requirements for practical applications and ways to provide actual personalized services."
A Computer-Aided Diagnosis of Brain Tumors Using a Fine-Tuned YOLO-based Model with Transfer Learning,2020,"['Brain Tumors', 'Computer-Aided Diagnosis', 'Deep Learning', 'Medical Image Analysis', 'Object Detection']",,"This paper proposes transfer learning and fine-tuning techniques for a deep learning model to detect three distinct brain tumors from Magnetic Resonance Imaging (MRI) scans. In this work, the recent YOLOv4 model trained using a collection of 3064 T1-weighted Contrast-Enhanced (CE)-MRI scans that were pre-processed and labeled for the task. This work trained with the partial 29-layer YOLOv4-Tiny and fine-tuned to work optimally and run efficiently in most platforms with reliable performance. With the help of transfer learning, the model had initial leverage to train faster with pre-trained weights from the COCO dataset, generating a robust set of features required for brain tumor detection. The results yielded the highest mean average precision of 93.14%, a 90.34% precision, 88.58% recall, and 89.45% F1-Score outperforming other previous versions of the YOLO detection models and other studies that used bounding box detections for the same task like Faster R-CNN. As concluded, the YOLOv4-Tiny can work efficiently to detect brain tumors automatically at a rapid phase with the help of proper fine-tuning and transfer learning. This work contributes mainly to assist medical experts in the diagnostic process of brain tumors."
자동 잔향 편집을 위한 컬러 및 깊이 정보 기반 실내 장면 분류,2020,[],,"The reverberation effect on the sound when producing movies or VR contents is a very important factor in the realism and liveliness. The reverberation time depending the space is recommended in a standard called RT60(Reverberation Time 60 dB). In this paper, we propose a scene recognition technique for automatic reverberation editing. To this end, we devised a classification model that independently trains color images and predicted depth images in the same model. Indoor scene classification is limited only by training color information because of the similarity of internal structure. Deep learning based depth information extraction technology is used to use spatial depth information. Based on RT60, 10 scene classes were constructed and model training and evaluation were conducted. Finally, the proposed SCR + DNet (Scene Classification for Reverb + Depth Net) classifier achieves higher performance than conventional CNN classifiers with 92.4% accuracy."
A Study of Machine Learning based Face Recognition for User Authentication,2020,"['Machine Learning', 'Deep Learning', 'Neural Network', 'Authentication', 'Face Recognition']",,"According to brilliant development of smart devices, many related services are being devised. And, almost every service is designed to provide user-centric services based on personal information. In this situation, to prevent unintentional leakage of personal information is essential. Conventionally, ID and Password system is used for the user authentication. This is a convenient method, but it has a vulnerability that can cause problems due to information leakage. To overcome these problem, many methods related to face recognition is being researched. Through this paper, we investigated the trend of user authentication through biometrics and a representative model for face recognition techniques. One is DeepFace of FaceBook and another is FaceNet of Google. Each model is based on the concept of Deep Learning and Distance Metric Learning, respectively. And also, they are based on Convolutional Neural Network (CNN) model. In the future, further research is needed on the equipment configuration requirements for practical applications and ways to provide actual personalized services."
인쇄된 컬러 QR코드의 합성곱 신경망 알고리즘에 의한 진위 판정 시스템,2020,"['정품 인증', '컬러 QR코드', '스캔 복제', 'Authentic certification', 'Color QR code', 'Scan&amp', 'printing']","스마트폰의 대중적인 보급으로 인해 QR 코드는 세상에서 가장 보편적인 코드들 중의 하나가 되었다. 본 논문에서는 새로운 형태의 QR 코드를 제안하여 저장 용량을 증가시키고, 또한, 컬러 정보와 패턴 형태를 가변시켜서 개인 정보를 포함할 수 있게 한다. 이와 더불어, 제안된 QR 코드가 인쇄된 형태의 다양한 응용환경에 작용될 수 있도록 본 논문은 효과적인 진위 판정 시스템을 제안한다. 제안한 시스템은 기존의 합성곱 신경망 구조 즉 VGGNet으로 구현되며, 스마트 폰을 통해 손쉽게 진품 또는 가품을 판정하고, 진품으로 판정된 코드에 대해서는 삽입된 개인 정보를 추출하도록 설계된다. 인쇄된 QR 코드에 대한 실제의 다양한 실험을 통해 제안된 시스템은 진품 또는 가품을 거의 완벽하게 분류할 수 있음을 보이고 개인 정보를 효과적으로 추출할 수 있음을 확인한다.","With the widespread of smartphones, the Quick response (QR) code became one of the most popular codes. In this paper, a new type of QR code is proposed to increase the storage capacities and also to contain private information by changing the colors and the shape of patterns in the codes. Then, for a variety of applications of the printed QR codes, this paper proposes an efficient authentic certification system, which is built on an conventional CNN (Convolutional neural network) architecture – VGGNet and classifies authentic or counterfeit with smartphones, easily. For authentic codes, the proposed system extracts the embedded private information. Through practical experiments with a printed QR code, it is shown that the proposed system can classify authentic or counterfeit code, perfectly, and also, are useful for extracting private information."
Research on Interactive Storytelling Method Using Artificial Intelligence and Physics Engine,2020,"['Advanced Sub-unit Interaction', 'Interactive storytelling', 'Generation method', 'Artificial intelligence', 'Physics engine']",,"Computer games with the digital characteristics of a non-linear approach have implemented interactive storytelling from the beginning, and today, with high game engine performance, users lead the story with minimal control, and there is an interactive movie genre that allows users to enjoy real-time stories such as movies. Appeared. It requires a lot of manpower and time to produce 3D resources that meet the increased expectations, and a more effective method than the existing production method of predicting, directing, producing, and recording users' needs is needed. Therefore, an advanced sub-unit interaction method was proposed as a way to realize interaction in various situations while reducing the amount of game engine resource production. This is a generation method that actively applies the improved physics engine and artificial intelligence reinforced by deep learning to make the character's movement, dialogue, and natural environment effects in real time in the game engine. As free deep learning libraries such as TensorFlow are activated and GAN learning methods along with CNN and RNN learning methods become generalized, the results of artificial intelligence show a quality that is indistinguishable from the original. In addition, by actively applying the improved physics engine, it is possible to create detailed movements of surrounding objects. The contents considered in the study are technologies that are still implemented, and if they are introduced, 3D resources can be created in real time without directly producing them, and the context setting and dialogue can induce users to naturally follow the flow of the main story. There will be"
적혈구 용적률 간섭 보정을 위한 혈당 측정 기기의 설계 및 구현,2020,"['Blood-glucose meter', 'Hematocrit interference', 'Red blood', 'In vitro diagnostics']",,"The detection and recognition of abnormal driving becomes crucial for achieving safety in Intelligent Transportation Systems (ITS). This paper presents a feature extraction method based on spectral data to train a neural network model for driving behavior recognition. The proposed method uses a two stage signal processing approach to derive time-saving and efficient feature vectors. For the first stage, the feature vector set is obtained by calculating variances from each frequency bin containing the power spectrum data. The feature set is further reduced in the second stage where an intersection method is used to select more significant features that are finally applied for training a neural network model. A stream of live signals are fed to the trained model which recognizes the abnormal driving behaviors. The driving behaviors considered in this study are weaving, sudden braking and normal driving. The effectiveness of the proposed method is demonstrated by comparing with existing methods, which are Particle Swarm Optimization (PSO) and Convolution Neural Network (CNN). The experiments show that the proposed approach achieves satisfactory results with less computational complexity."
합성곱 신경망 기반 향상된 GNSS 재밍 식별기법,2020,"['GNSS', 'Jamming', 'Jamming Classification', 'Machine Learning', 'Convolutional Neural Network', 'Confusion Matrix']",,"In this paper, we propose an improved global navigation satellite system (GNSS) jamming classification scheme using a convolutional neural network that directly uses an intermediate frequency (IF) sampled GNSS received signal without pre-processing. The machine learning-based GNSS jamming classification scheme recently proposed in [17] requires a short-time Fourier transform (STFT) process and a binary black-and-white image processing process through image mapping of the obtained spectrogram. The average jamming classification accuracy of the conventional scheme is approximately 94.31%, where the maximum, average, and minimum classification accuracies for single frequency modulation (FM) jamming are as low as approximately 89.55%, 83.43%, and 77.61%, respectively. The major performance deterioration factor of the conventional scheme is information loss caused by the pre-processing for the designed machine learning technique. To tackle this problem, we construct a sophisticated convolutional neural network (CNN) that directly uses the IF sampled GNSS received signal without pre-processing the conventional scheme. To evaluate the performance of the proposed scheme, the confusion matrix of the jamming classification between the conventional and the proposed schemes is compared and analyzed by Monte-Carlo simulation using 106 test samples in five representative jamming environments with no jamming. As a result of the simulation, the average jamming classification accuracy of the proposed scheme is approximately 99.41%, which improves the classification accuracy by 5.1% compared with that achieved by the conventional scheme. Additionally, the average classification accuracy of 99.07% is dramatically improved by 15.64% compared with that achieved by the conventional scheme."
심층 신경회로망 앙상블을 이용한 걸음걸이 인식에 대한 연구,2020,"['Gait Recognition', 'deep neural network', 'deep neural network ensemble', 'Gait Energy Image (GEI)', 'Motion Silhouette Image (MSI)']",,"The recognition of a person from his (her) gait has been a recent focus in computer vision because of its unique advantages such as non-invasive and human friendly. Gait recognition, however, has the weakness that it is not reliable compared with other biometrics. In this paper, we applied deep neural network ensemble to the gait recognition problem. The deep neural network ensemble is a learning paradigm where a collection of deep neural networks is trained for the same task. Generally, the ensemble shows better generalization performance than a single deep neural network such as convolution neural network and recurrent neural network. To increase reliability of the gait recognition, gait energy image (GEI) and Motion silhouette image (MSI) are extracted for gait features and convolution and recurrent neural network ensemble are used for classifier. Experiments are performed with the NLPR and SOTON databases to show the efficiency of the proposed algorithm. The performance of proposed method is 4.55%, 4.85%, 2.5% and 2.43% better than single CNN, respectively in two databases. As a result we can create a recognition system with accuracy of 100%, 100%, and 94% in the NLPR database and 97.35% in the SOTON database."
관심 문자열 인식 기술을 이용한 가스계량기 자동 검침 시스템,2020,"['가스계량기', '자동 검침', '선택적 문자 인식', '합성곱 신경망', '순환 신경망', '고속 병렬처리', 'Gasometer', 'automatic reading', 'selective optical character recognition', 'convolutional neural network', 'recurrent neural network', 'parallel processing']",,"In this paper, we suggest an application system architecture which provides accurate, fast and efficient automatic gasometer reading function. The system captures gasometer image using mobile device camera, transmits the image to a cloud server on top of private LTE network, and analyzes the image to extract character information of device ID and gas usage amount by selective optical character recognition based on deep learning technology. In general, there are many types of character in an image and optical character recognition technology extracts all character information in an image. But some applications need to ignore non-of-interest types of character and only have to focus on some specific types of characters. For an example of the application, automatic gasometer reading system only need to extract device ID and gas usage amount character information from gasometer images to send bill to users. Non-of-interest character strings, such as device type, manufacturer, manufacturing date, specification and etc., are not valuable information to the application. Thus, the application have to analyze point of interest region and specific types of characters to extract valuable information only. We adopted CNN (Convolutional Neural Network) based object detection and CRNN (Convolutional Recurrent Neural Network) technology for selective optical character recognition which only analyze point of interest region for selective character information extraction. We build up 3 neural networks for the application system. The first is a convolutional neural network which detects point of interest region of gas usage amount and device ID information character strings, the second is another convolutional neural network which transforms spatial information of point of interest region to spatial sequential feature vectors, and the third is bi-directional long short term memory network which converts spatial sequential information to character strings using time-series analysis mapping from feature vectors to character strings. In this research, point of interest character strings are device ID and gas usage amount. Device ID consists of 12 arabic character strings and gas usage amount consists of 4 ~ 5 arabic character strings. All system components are implemented in Amazon Web Service Cloud with Intel Zeon E5-2686 v4 CPU and NVidia TESLA V100 GPU. The system architecture adopts master-lave processing structure for efficient and fast parallel processing coping with about 700,000 requests per day. Mobile device captures gasometer image and transmits to master process in AWS cloud. Master process runs on Intel Zeon CPU and pushes reading request from mobile device to an input queue with FIFO (First In First Out) structure. Slave process consists of 3 types of deep neural networks which conduct character recognition process and runs on NVidia GPU module. Slave process is always polling the input queue to get recognition request. If there are some requests from master process in the input queue, slave process converts the image in the input queue to device ID character string, gas usage amount character string and position information of the strings, returns the information to output queue, and switch to idle mode to poll the input queue. Master process gets final information form the output queue and delivers the information to the mobile device. We used total 27,120 gasometer images for training, validation and testing of 3 types of deep neural network. 22,985 images were used for training and validation, 4,135 images were used for testing. We randomly splitted 22,985 images with 8:2 ratio for training and validation respectively for each training epoch. 4,135 test image were categorized into 5 types (Normal, noise, reflex, scale and slant). Normal data is clean image data, noise means image with noise signal, relfex means image with light reflection in gasometer region, scale means images with small object size due to long-distance capturin"
PD+SMC Quadrotor Control for Altitude and Crack Recognition using Deep Learning,2020,"['Deep learning', 'embedded control system', 'inspection', 'quadrotor aircraft', 'robust altitude control', 'UAV.']",,"Building inspection is a vital task because infrastructure damage puts people at risk or causes economic losses. Thanks to the technological breakthroughs in regard to Unmanned Aerial Vehicles (UAVs) and intelligent systems, there is a real possibility to implement an inspection by means of these technologies. UAVs allow reaching difficult places and, depending on the hardware carried onboard, take data or compute algorithms to understand the environment. This paper proposes a real-time robust altitude control strategy for a quadrotor aircraft, also a convolutional neuronal network for crack recognition is developed. The main idea of this proposal is to lay the background for an autonomous system for the inspection of structures using a UAV. For the robust control, a combination of two control actions, one linear (PD) and another nonlinear (Sliding Mode) is used. The combination of these control actions allows increasing the system’s performance. To verify the satisfactory performance ofproposed control law, simulations and experimental results with a quadrotor, in the presence of disturbances, are presented. For crack recognition in images, several experiments were carried out validating the proposed model. For CNN training, a database of cracks was built from images taken from the internet."
IoT Open-Source and AI based Automatic Door Lock Access Control Solution,2020,"['IoT', 'Open Source Light Controller', 'AI', 'Access Control Solution', 'VLC', 'OCC', 'Smart Building']",,"Recently, there was an increasing demand for an integrated access control system which is capable of user recognition, door control, and facility operations control for smart buildings automation. The market available door lock access control solutions need to be improved from the current level security of door locks operations where security is compromised when a password or digital keys are exposed to the strangers. At present, the access control system solution providers focusing on developing an automatic access control system using (RF) based technologies like bluetooth, WiFi, etc. All the existing automatic door access control technologies required an additional hardware interface and always vulnerable security threads. This paper proposes the user identification and authentication solution for automatic door lock control operations using camera based visible light communication (VLC) technology. This proposed approach use the cameras installed in building facility, user smart devices and IoT open source controller based LED light sensors installed in buildings infrastructure. The building facility installed IoT LED light sensors transmit the authorized user and facility information color grid code and the smart device camera decode the user informations and verify with stored user information then indicate the authentication status to the user and send authentication acknowledgement to facility door lock integrated camera to control the door lock operations. The camera based VLC receiver uses the artificial intelligence (AI) methods to decode VLC data to improve the VLC performance. This paper implements the testbed model using IoT open-source based LED light sensor with CCTV camera and user smartphone devices. The experiment results are verified with custom made convolutional neural network (CNN) based AI techniques for VLC deciding method on smart devices and PC based CCTV monitoring solutions. The archived experiment results confirm that proposed door access control solution is effective and robust for automatic door access control."
마켓 인사이트를 위한 상품 리뷰의 다차원 분석 방안,2020,"['연관분석', '감성분석', '이커머스', '워드임베딩', '텍스트마이닝', '극성탐지', 'Association Analysis', 'Sentiment Analysis', 'E-Commerce', 'Word embedding', 'Text Mining', 'Polarity Detection']",,"With the development of the Internet, consumers have had an opportunity to check product information easily through E-Commerce. Product reviews used in the process of purchasing goods are based on user experience, allowing consumers to engage as producers of information as well as refer to information. This can be a way to increase the efficiency of purchasing decisions from the perspective of consumers, and from the sellers point of view, it can help develop products and strengthen their competitiveness. However, it takes a lot of time and effort to understand the overall assessment and assessment dimensions of the products that I think are important in reading the vast amount of product reviews offered by E-Commerce for the products consumers want to compare. This is because product reviews are unstructured information and it is difficult to read sentiment of reviews and assessment dimension immediately. For example, consumers who want to purchase a laptop would like to check the assessment of comparative products at each dimension, such as performance, weight, delivery, speed, and design.  Therefore, in this paper, we would like to propose a method to automatically generate multi-dimensional product assessment scores in product reviews that we would like to compare. The methods presented in this study consist largely of two phases. One is the pre-preparation phase and the second is the individual product scoring phase. In the pre-preparation phase, a dimensioned classification model and a sentiment analysis model are created based on a review of the large category product group review. By combining word embedding and association analysis, the dimensioned classification model complements the limitation that word embedding methods for finding relevance between dimensions and words in existing studies see only the distance of words in sentences. Sentiment analysis models generate CNN models by organizing learning data tagged with positives and negatives on a phrase unit for accurate polarity detection. Through this, the individual product scoring phase applies the models pre-prepared for the phrase unit review. Multi-dimensional assessment scores can be obtained by aggregating them by assessment dimension according to the proportion of reviews organized like this, which are grouped among those that are judged to describe a specific dimension for each phrase.  In the experiment of this paper, approximately 260,000 reviews of the large category product group are collected to form a dimensioned classification model and a sentiment analysis model. In addition, reviews of the laptops of S and L companies selling at E-Commerce are collected and used as experimental data, respectively. The dimensioned classification model classified individual product reviews broken down into phrases into six assessment dimensions and combined the existing word embedding method with an association analysis indicating frequency between words and dimensions. As a result of combining word embedding and association analysis, the accuracy of the model increased by 13.7%. The sentiment analysis models could be seen to closely analyze the assessment when they were taught in a phrase unit rather than in sentences. As a result, it was confirmed that the accuracy was 29.4% higher than the sentence-based model. Through this study, both sellers and consumers can expect efficient decision making in purchasing and product development, given that they can make multi-dimensional comparisons of products. In addition, text reviews, which are unstructured data, were transformed into objective values such as frequency and morpheme, and they were analysed together using word embedding and association analysis to improve the objectivity aspects of more precise multi-dimensional analysis and research. This will be an attractive analysis model in terms of not only enabling more effective service deployment during the evolving E-Commerce market and fierce competitio"
Automatic detection of periodontal compromised teeth in digital panoramic radiographs using faster regional convolutional neural networks,2020,"['Alveolar Bone Loss', 'Panoramic Radiography', 'Artificial Intelligence', 'Deep Learning']",,"Purpose: Periodontal disease causes tooth loss and is associated with cardiovascular diseases, diabetes, and rheumatoid arthritis. The present study proposes using a deep learning-based object detection method to identify periodontally compromised teeth on digital panoramic radiographs. A faster regional convolutional neural network (faster R-CNN) which is a state-of-the-art deep detection network, was adapted from the natural image domain using a small annotated clinical data- set.Materials and Methods: In total, 100 digital panoramic radiographs of periodontally compromised patients were retrospectively collected from our hospital’s information system and augmented. The periodontally compromised teeth found in each image were annotated by experts in periodontology to obtain the ground truth. The Keras library, which is written in Python, was used to train and test the model on a single NVidia 1080Ti GPU. The faster R-CNN model used a pretrained ResNet architecture.Results: The average precision rate of 0.81 demonstrated that there was a significant region of overlap between the predicted regions and the ground truth. The average recall rate of 0.80 showed that the periodontally compromised teeth regions generated by the detection method excluded healthiest teeth areas. In addition, the model achieved a sensitivity of 0.84, a specificity of 0.88 and an F-measure of 0.81.Conclusion: The faster R-CNN trained on a limited amount of labeled imaging data performed satisfactorily in detecting periodontally compromised teeth. The application of a faster R-CNN to assist in the detection of periodontally compromised teeth may reduce diagnostic effort by saving assessment time and allowing automated screening documentation."
Automatic detection of periodontal compromised teeth in digital panoramic radiographs using faster regional convolutional neural networks,2020,"['Alveolar Bone Loss', 'Panoramic Radiography', 'Artificial Intelligence', 'Deep Learning']",,"Purpose: Periodontal disease causes tooth loss and is associated with cardiovascular diseases, diabetes, and rheumatoid arthritis. The present study proposes using a deep learning-based object detection method to identify periodontally compromised teeth on digital panoramic radiographs. A faster regional convolutional neural network (faster R-CNN) which is a state-of-the-art deep detection network, was adapted from the natural image domain using a small annotated clinical data- set. Materials and Methods: In total, 100 digital panoramic radiographs of periodontally compromised patients were retrospectively collected from our hospital's information system and augmented. The periodontally compromised teeth found in each image were annotated by experts in periodontology to obtain the ground truth. The Keras library, which is written in Python, was used to train and test the model on a single NVidia 1080Ti GPU. The faster R-CNN model used a pretrained ResNet architecture. Results: The average precision rate of 0.81 demonstrated that there was a significant region of overlap between the predicted regions and the ground truth. The average recall rate of 0.80 showed that the periodontally compromised teeth regions generated by the detection method excluded healthiest teeth areas. In addition, the model achieved a sensitivity of 0.84, a specificity of 0.88 and an F-measure of 0.81. Conclusion: The faster R-CNN trained on a limited amount of labeled imaging data performed satisfactorily in detecting periodontally compromised teeth. The application of a faster R-CNN to assist in the detection of periodontally compromised teeth may reduce diagnostic effort by saving assessment time and allowing automated screening documentation."
Effective Hand Gesture Recognition by Key Frame Selection and 3D Neural Network,2020,"['hand gesture recognition', 'dynamic hand gesture', 'key frame extraction', 'action recognition']",,"This paper presents an approach for dynamic hand gesture recognition by using algorithm based on 3D Convolutional Neural Network (3D_CNN), which is later extended to 3D Residual Networks (3D_ResNet), and the neural network based key frame selection. Typically, 3D deep neural network is used to classify gestures from the input of image frames, randomly sampled from a video data. In this work, to improve the classification performance, we employ key frames which represent the overall video, as the input of the classification network. The key frames are extracted by SegNet instead of conventional clustering algorithms for video summarization (VSUMM) which require heavy computation. By using a deep neural network, key frame selection can be performed in a real-time system. Experiments are conducted using 3D convolutional kernels such as 3D_CNN, Inflated 3D_CNN (I3D) and 3D_ResNet for gesture classification. Our algorithm achieved up to 97.8% of classification accuracy on the Cambridge gesture dataset. The experimental results show that the proposed approach is efficient and outperforms existing methods."
TensorRT와 SSD를 이용한 실시간 얼굴 검출방법,2020,"['텐서플로우', '텐서알티', '딥러닝', '에스에스디', '객체 검출', 'Tensorflow', 'TensorRT', 'Deep Learning', 'SSD', 'Object Detection']",,"Recently, new approaches that significantly improve performance in object detection and recognition using deep learning technology have been proposed quickly. Of the various techniques for object detection, especially facial object detection (Faster R-CNN, R-CNN, YOLO, SSD, etc), SSD is superior in accuracy and speed to other techniques. At the same time, multiple object detection networks are also readily available. In this paper, among object detection networks, Mobilenet v2 network is used, models combined with SSDs are trained, and methods for detecting objects at a rate of four times or more than conventional performance are proposed using TensorRT engine, and the performance is verified through experiments. Facial object detector was created as an application to verify the performance of the proposed method, and its behavior and performance were tested in various situations."
Fall Situation Recognition by Body Centerline Detection using Deep Learning,2020,"['Mask-RCNN', 'Body Fall', 'Color Video', 'Action Recognition']",,"In this paper, a method of detecting the emergency situations such as body fall is proposed by using color images. We detect body areas and key parts of a body through a pre-learned Mask R-CNN in the images captured by a camera. Then we find the centerline of the body through the joint points of both shoulders and feet. Also, we calculate an angle to the center line and then calculate the amount of change in the angle per hour. If the angle change is more than a certain value, then it is decided as a suspected fall. Also, if the suspected fall state persists for more than a certain frame, then it is determined as a fall situation. Simulation results show that the proposed method can detect body fall situation accurately."
CSI를 활용한 딥러닝 기반의 실내 사람 수 추정 기법,2020,[],,"People estimation is important to provide IoT services. Most people counting technologies use camera or sensor data. However, the conventional technologies have the disadvantages of invasion of privacy and the need to install extra infrastructure. This paper proposes a method for estimating the number of people using a Wi-Fi AP. We use channel state information of Wi-Fi and analyze that using deep learning technology. It can be achieved by pre-installed Wi-Fi infrastructure that reduce cost for people estimation and privacy infringement. The proposed algorithm uses a k-binding data for pre-processing process and a 1D-CNN learning model. Two APs were installed to analyze the estimation results of six people. The result of the accurate number estimation was 64.8%, but the result of classifying the number of people into classes showed a high result of 84.5%. This algorithm is expected to be applicable to estimate the density of people in a small space."
Deep Window Detection in Street Scenes,2020,"['Window dataset', 'window detection', 'regular distribution', 'context enhancement', 'convolutional neural network']",,"Windows are key components of building facades. Detecting windows, crucial to 3D semantic reconstruction and scene parsing, is a challenging task in computer vision. Early methods try to solve window detection by using hand-crafted features and traditional classifiers. However, these methods are unable to handle the diversity of window instances in real scenes and suffer from heavy computational costs. Recently, convolutional neural networks based object detection algorithms attract much attention due to their good performances. Unfortunately, directly training them for challenging window detection cannot achieve satisfying results. In this paper, we propose an approach for window detection. It involves an improved Faster R-CNN architecture for window detection, featuring in a window region proposal network, an RoI feature fusion and a context enhancement module. Besides, a post optimization process is designed by the regular distribution of windows to refine detection results obtained by the improved deep architecture. Furthermore, we present a newly collected dataset which is the largest one for window detection in real street scenes to date. Experimental results on both existing datasets and the new dataset show that the proposed method has outstanding performance."
오토인코더를 이용한 기어박스 진동신호의잡음 제거 방법에 관한 연구,2020,"['Rotating machine', 'Denoising', 'AutoEncoder', 'Anomaly Detection', 'Failure mode Classification', '회전설비', '디노이징', '오토인코더', '이상탐지', '결함모드 분류']",,"Because the vibration signal of the rotating facility is interfered by the surrounding environment, the vibration signal collected in the laboratory environment differs greatly from the situation of the actual industrial site, and if abnormal detection and fault classification are performed by analyzing the signal without processing it, it is not only impossible to guarantee its predictive performance, but it can also cause distortion in the result analysis. Therefore, the process of removing noise must be accompanied at the pre-processing stage of the vibration signal.In this paper, instead of the signal processing filter traditionally used for noise removal, an artificial intelligence-based prediction maintenance system is proposed, which applies a dinoing model that eliminates noise of signals by using an autocoder model based on 1D-CNN, a deep learning non-instructor learning, and classifies abnormal signals and fault modes for signals with which noise has been removed."
A Statistical Data-Filtering Method Proposed for Short-Term Load Forecasting Models,2020,['ARIMA · Confi dence level · Data fi ltering · Neural network · Long short-term memory · And short-term load forecasting'],,"Reliability assessment of the SCADA-system based load data is necessary for improving accuracy of short-term load forecasting (STLF) methods in a distribution network (DN). Specifi cally, the reliability evaluation of the load data is to properly eliminate noise/outliers caused by random power consumption behaviors or the sudden change in load demand from industrial and residential customers in the DN. Thus, this paper proposes a novel statistical data-fi ltering method, working at an input data pre-processing stage, which will evaluate the reliability of input load data by analyzing all possible data confi dence levels in order to fi lter-out the noise/outliers for accuracy improvement of diff erent short-term load forecasting models. The proposed statistical data-fi ltering method is also compared to other existing data-fi ltering methods (such as Kalman Filter, Density-Based Spatial Clustering of Applications with Noise (DBSCAN), Discrete Wavelet Transform (DWT) and Singular Spectrum Analysis (SSA)). Moreover, several case studies of short-term load forecasting for a typical 22 kV distribution network in Vietnam are conducted with an Artifi cial Neural Network (ANN) model, a Long Short-Term Memory Recurrent Neural Network (LSTM-RNN) model, a combined model of Long Short-Term Memory Network and Convolutional Neural Network (LSTM-CNN), and a conventional Autoregressive Integrated Moving Average (ARIMA) model to validate the statistical data-fi ltering method proposed. The achieved results demonstrate which the STLF using ANN, LSTM-RNN, LSTMCNN, and ARIMA models with the statistical data-fi ltering method can all outperform those with the existing data-fi ltering methods. Additionally, the numerical results also indicate that in case the SCADA-based load data is normally distributed, time-series forecasting models should be more preferred than neural network models; otherwise, when the SCADA-based load data contains multiple normally distributed sub-datasets, neural network-based prediction models are highly recommended."
