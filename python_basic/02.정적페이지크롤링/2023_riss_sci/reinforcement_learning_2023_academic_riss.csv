title,date,keywords,abstract,multilingual_abstract
Reinforcement learning-based virtual network embedding: A comprehensive survey,2023,['Virtual network embeddingDeep reinforcement learningGraph neural networkArtificial intelligence'],,"Virtual network embedding plays a vital role in network virtualization, as it determines the deployment and connection of virtual networks to the physical network in the 5G and beyond. An efficient virtual network embedding algorithm is essential to ensure that virtual networks are embedded in a way that meets the performance, security, and resource requirements of the virtual networks and their users. The integration of reinforcement learning with virtual network embedding can lead to more intelligent and efficient network management, which can enhance the performance of large-scale networked systems. Reinforcement learning has the potential to improve and overcome some limitations of traditional algorithms, such as the need for prior knowledge of network conditions and the difficulty in dealing with non-linear and dynamic network environments. Therefore, we conducted this survey to provide a comprehensive overview and examine potential future directions for the optimal reinforcement learning-based virtual network embedding solutions. However, applying reinforcement learning directly to virtual network embedding is a challenging task that requires further research and study. Additionally, it encourages researchers to examine the potential of reinforcement learning in virtual network embedding, identify the challenges for its application, and cover various factors related to the reinforcement learning application in virtual network embedding, including motivations, performance metrics, and challenges."
Deep Reinforcement Learning based Tourism Experience Path Finding,2023,"['Reinforcement Learning', 'Path Finding', 'Tour Planning', 'Smart Tourism', 'Digital twin']",,"In this paper, we introduce a reinforcement learning-based algorithm for personalized tourist path recommendations. The algorithm employs a reinforcement learning agent to explore tourist regions and identify optimal paths that are expected to enhance tourism experiences. The concept of tourism experience is defined through points of interest (POI) located along tourist paths within the tourist area. These metrics are quantified through aggregated evaluation scores derived from reviews submitted by past visitors. In the experimental setup, the foundational learning model used to find tour paths is the Deep Q-Network (DQN). Despite the limited availability of historical tourist behavior data, the agent adeptly learns travel paths by incorporating preference scores of tourist POIs and spatial information of the travel area."
Reinforcement learning-based control with application to the once-through steam generator system,2023,"['LSTM', 'PPO algorithm', 'Pretraining', 'Once-through steam generator']",,"A reinforcement learning framework is proposed for the control problem of outlet steam pressure of the once-through steam generator(OTSG) in this paper. The double-layer controller using Proximal Policy Optimization(PPO) algorithm is applied in the control structure of the OTSG. The PPO algorithm can train the neural networks continuously according to the process of interaction with the environment and then the trained controller can realize better control for the OTSG. Meanwhile, reinforcement learning has the characteristic of difficult application in real-world objects, this paper proposes an innovative pretraining method to solve this problem. The difficulty in the application of reinforcement learning lies in training.The optimal strategy of each step is summed up through trial and error, and the training cost is very high.In this paper, the LSTM model is adopted as the training environment for pretraining, which saves training time and improves efficiency. The experimental results show that this method can realize the self-adjustment of control parameters under various working conditions, and the control effect has the advantages of small overshoot, fast stabilization speed, and strong adaptive ability."
Learning Multiple-Gait Quadrupedal Locomotion via Hierarchical Reinforcement Learning,2023,"['Quadruped robot', 'Reinforcement learning', 'Gait patterns', 'Machine learning in locomotion']",,"Over long periods of evolution, legged animals have developed the capability to use a variety of gaits to move efficiently and flexibly at different speeds. To enable quadruped robots to acquire this ability, this study proposes a two-stage training hierarchical framework that can have quadruped robots generate energy-efficient multiple-gait locomotion, consisting of a gait selection policy module and a react controller module. The parameters of both modules are optimized using reinforcement learning. The experimental results in the simulation demonstrate that the proposed method can generate energy-efficient multiple-gait quadrupedal locomotion compared to previous methods. To validate the robustness and effectiveness of the method, we constructed a closed-chain quadruped robot and deployed the controller trained by the method to the robot. The experimental results in the real world suggest that the controller can enable the robot to move stably and efficiently in different gaits. The main contribution of this paper is that the authors propose a novel hierarchical framework, which makes quadruped robots use an optimal gait at a specific speed and smoothly switch to another one after getting a different speed command. These behaviors are automatically produced through simulation training, eliminating the need for the tedious work of designing gaits and modulating controllers. Experimental results showcase that the proposed method has significant advantages compared to previous methods."
Deep reinforcement learning-based model-free path planning and collision avoidance for UAVs: A soft actor–critic with hindsight experience replay approach,2023,['Deep reinforcement learningSoft actor–criticHindsight experience replayUAV path planningCollision avoidance and control'],,"In this paper, we propose a soft actor–critic (SAC) algorithm with hindsight experience replay (HER), called SACHER, which is a class of deep reinforcement learning (DRL) algorithm. SAC is an off-policy model-free DRL algorithm that outperforms earlier DRL algorithms in terms of exploration and robustness. However, in SAC, maximizing the entropy-augmented objective degrades the optimality of learning outcomes. We propose SACHER to improve the learning performance of SAC. We apply SACHER to the path planning and collision avoidance control of unmanned aerial vehicles (UAVs). We demonstrate the effectiveness of SACHER in terms of the success rate, learning speed, and collision avoidance performance of UAV operation."
Reward-based participant selection for improving federated reinforcement learning,2023,['Federated learningReinforcement learningFederated reinforcement learningParticipant selection'],,"Federated reinforcement learning (FRL) has recently received a lot of attention in various fields. In FRL systems, the concept of performing more proper actions with better experiences exists, and we focused on this unique characteristic. Motivated by such inherent property of FRL, in this paper, we propose the reward-based participant selection scheme for improving FRL. The FRL system with the proposed scheme performs learning effectively by putting a priority on utilizing better experiences of agents performing outstanding actions. We conducted various experiments, and the results show that it is possible to accelerate learning and require fewer agents when using the proposed scheme, which means that the proposed scheme improves the performance and efficiency of learning."
Supervised pre-training for improved stability in deep reinforcement learning,2023,"['Deep reinforcement learning', 'Pre-training', 'Supervised learning', 'Maximum entropy', 'Stability']",,"Deep reinforcement learning (DRL) technology has been actively studied with the recent advances in deep learning. As a result, the researchers are continuously improving performance and expanding the applications. However, recent literature reports that the performance of DRL is sensitive to the various design choices, e.g., the neural network initialization. Accordingly, it makes DRL hard to obtain a stable performance, which degrades reproducibility. Therefore, we propose a supervised pre-training method for both policy and value networks to improve stability. We pre-train the policy network to maximize the initial entropy and pre-train the value network to bias the distribution to a specific value. The experiments are conducted on tasks with discrete action space where it is hard to control the initial entropy. Through the experiments, the effectiveness of the proposed method in terms of stability and performance is validated."
Safe Reinforcement Learning-based Driving Policy Design for Autonomous Vehicles on Highways,2023,"['Autonomous vehicles', 'collision avoidance', 'decision-making', 'finite state machine', 'safe reinforcement learning.']",,"Safe decision-making strategy of autonomous vehicles (AVs) plays a critical role in avoiding accidents. This study develops a safe reinforcement learning (safe-RL)-based driving policy for AVs on highways. The hierarchical framework is considered for the proposed safe-RL, where an upper layer executes a safe explorationexploitation by modifying the exploring process of the ε-greedy algorithm, and a lower layer utilizes a finite state machine (FSM) approach to establish the safe conditions for state transitions. The proposed safe-RL-based driving policy improves the vehicle’s safe driving ability using a Q-table that stores the values corresponding to each action state. Moreover, owing to the trade-off between the ε-greedy values and safe distance threshold, the simulation results demonstrate the superior performance of the proposed approach compared to other alternative RL approaches, such as the ε-greedy Q-learning (GQL) and decaying ε-greedy Q-learning (DGQL), in an uncertain traffic environment. This study’s contributions are twofold: it improves the autonomous vehicle’s exploration-exploitation and safe driving ability while utilizing the advantages of FSM when surrounding cars are inside safe-driving zones, and it analyzes the impact of safe-RL parameters in exploring the environment safely."
Application of reinforcement learning based on curriculum learning for the pipe auto-routing of ships,2023,"['pipe auto-routing', 'path finding algorithm', 'reinforcement learning', 'curriculum learning']",,"The pipe routing of ships has been manually performed by experts, and the design quality depends on the competence of the experts. Therefore, studies on pipe-routing automation and optimization are required. In addition, the pipe-routing task in a ship that requires frequent pipe-routing modifications requires a long time to be optimized. In this study, we developed a methodology that enables a rapid response in situations where frequent pipe-routing modifications are required by applying curriculum learning that can be stably learned by gradually solving easy-to-complex problems. In addition, this study aimed to minimize the length of the pipe and number of bends as an objective function. Finally, the proposed methodology was verified by comparing it with existing studies that used the A*, jump point search, and reinforcement-learning algorithms to determine the search speed, number of bends, and length of the path."
Decision-making for Connected and Automated Vehicles in Chanllenging Traffic Conditions Using Imitation and Deep Reinforcement Learning,2023,"['Connected and automated vehicles (CAVs)', 'Traffic safety', 'Decision-making', 'Imitation learning', 'Deep reinforcement learning']",,"Decision-making is the “brain” of connected and automated vehicles (CAVs) and is vitally critical to the safety of CAVs. The most of driving data used to train the decision-making algorithms is collected in general traffic conditions. Existing decision-making methods are difficult to guarantee safety in challenging traffic conditions, namely severe congestion and accident ahead. In this context, a semi-supervised decision-making algorithm is proposed to improve the safety of CAVs in challenging traffic conditions. To be specific, we proposed the expert-generative adversarial imitation learning (E-GAIL) that integrates imitation learning and deep reinforcement learning. The proposed E-GAIL is deployed in roadside unit (RSU). In the first stage, the decision-making knowledge of the expert is imitated using the real-world data collected in general traffic conditions. In the second stage, the generator of E-GAIL is further reinforced and achieves self-learn decision-making in the simulator with challenging traffic conditions. The E-GAIL is tested in general and challenging traffic conditions. By comparing the evaluation metrics of time to collision (TTC), deceleration to avoid a crash (DRAC), space gap (SGAP) and time gap (TGAP), the E-GAIL greatly outperforms the state-of-the-art decision-making algorithms. Experimental results show that the E-GAIL not only make-decision for CAVs in general traffic conditions but also successfully enhances the safety of CAVs in challenging traffic conditions."
Navigation of Mobile Robots Based on Deep Reinforcement Learning: Reward Function Optimization and Knowledge Transfer,2023,"['Deep reinforcement learning (DRL)', 'knowledge transfer', 'mobile robot', 'navigation', 'reward function.']",,"This paper presents an end-to-end online learning navigation method based on deep reinforcement learning (DRL) for mobile robots, whose objective is that mobile robots can avoid obstacles to reach the target point in an unknown environment. Specifically, double deep Q-networks (Double DQN), dueling deep Q-networks (Dueling DQN) and prioritized experience replay (PER) are combined to form prioritized experience replay-double dueling deep Q-networks (PER-D3QN) algorithm to realize high-efficiency navigation of mobile robots. Moreover, considering the problem of sparse reward in the traditional reward function, an artificial potential field is introduced into the reward function to guide robots to fulfill the navigation task through the change of potential energy. Furthermore, in order to accelerate the training of mobile robots in complex environment, a knowledge transfer training method is proposed, which migrates the knowledge from simple to complex environment, and quickly learns on the basis of the priori knowledge. Finally, the performance is validated based on a three-dimensional simulator, which shows that the mobile robot can obtain higher rewards and achieve higher success rates and less time for navigation, indicating that the proposed approaches are feasible and efficient."
Robust Near-optimal Control for Constrained Nonlinear System via Integral Reinforcement Learning,2023,"['Constrained nonlinear system', 'integral reinforcement learning', 'optimal control', 'robust control.']",,"This paper proposes a robust near-optimal control algorithm for uncertain nonlinear systems with state constraints and input saturation. By incorporating a barrier function and a non-quadratic term, the robust stabilization problem with constraints and uncertainties is converted into an unconstrained optimal control problem of the nominal system, which requires the solution of the Hamilton-Jacobi-Bellman (HJB) equation. The proposed integral reinforcement learning (IRL)-based method can obtain the approximate solution of the HJB equation without requiring any knowledge of system drift dynamics. An online gain-adjustable update law of the actor-critic architecture is developed to relax the persistence of excitation (PE) condition and ensure the closed-loop system stability throughout learning. The uniform ultimate boundedness of the closed-loop system is verified using Lyapunov’s direct method. Simulation results demonstrate the effectiveness and feasibility of the proposed method."
Comparison of value-based Reinforcement Learning Algorithms in Cart-Pole Environment,2023,"['Reinforcement learning', 'deep reinforcement learning', 'FNN', 'CNN', 'SARSA', 'Q-learning.']",,"Reinforcement learning can be applied to a wide variety of problems. However, the fundamental limitation of reinforcement learning is that it is difficult to derive an answer within a given time because the problems in the real world are too complex. Then, with the development of neural network technology, research on deep reinforcement learning that combines deep learning with reinforcement learning is receiving lots of attention.In this paper, two types of neural networks are combined with reinforcement learning and their characteristics were compared and analyzed with existing value-based reinforcement learning algorithms. Two types of neural networks are FNN and CNN, and existing reinforcement learning algorithms are SARSA and Qlearning"
Robot Subgoal-guided Navigation in Dynamic Crowded Environments with Hierarchical Deep Reinforcement Learning,2023,"['Collision avoidance', 'graph attention networks', 'hierarchical deep reinforcement learning', 'robot navigation.']",,"Although deep reinforcement learning has recently achieved some successes in robot navigation, there are still unsolved problems. Particularly, a robot guided by a distant ultimate goal is easy to get stuck in danger or encounter collisions in dynamic crowded environments due to the lack of long-term perspectives. In this paper, a novel subgoal-guided approach based on two-level hierarchical deep reinforcement learning with spatial-temporal graph attention networks (ST-GANets), called SG-HDRL, is proposed for a robot navigating in a dynamic crowded environment with autonomous obstacles, e.g., crowd. Specifically, the high-level policy, that models the spatialtemporal relation between the robot and the obstacles using the obstacles’ trajectories by the designed high-level ST-GANet, generates intermediate subgoals from a longer-term perspective over higher temporal scales. The subgoals give a favorable and collision-free direction to avoid encountering danger or collisions while approaching the ultimate goal. The low-level policy, that similarly implements the designed low-level ST-GANet to implicitly predict the obstacles’ motions, takes the subgoals as short-term guidance through an intrinsic reward incentive to generate primitive actions for the robot. Simulation results demonstrate that SG-HDRL using ST-GANets has better performances compared with state-of-the-art baselines. Furthermore, the proposed SG-HDRL is deployed to an experimental platform based on omnidirectional cars, and experiment results validate the effectiveness and practicability of the proposed SG-HDRL."
An autonomous radiation source detection policy based on deep reinforcement learning with generalized ability in unknown environments,2023,"['Radiation source detection', 'Deep reinforcement learning', 'Hierarchical learning']",,"Autonomous radiation source detection has long been studied for radiation emergencies. Compared to conventional data-driven or path planning methods, deep reinforcement learning shows a strong capacity in source detection while still lacking the generalized ability to the geometry in unknown environments.In this work, the detection task is decomposed into two subtasks: exploration and localization.A hierarchical control policy (HC) is proposed to perform the subtasks at different stages. The low-level controller learns how to execute the individual subtasks by deep reinforcement learning, and the highlevel controller determines which subtasks should be executed at the current stage. In experimental tests under different geometrical conditions, HC achieves the best performance among the autonomous decision policies. The robustness and generalized ability of the hierarchy have been demonstrated"
Sustainable Smart City Building-energy Management Based on Reinforcement Learning and Sales of ESS Power,2023,"['AI', 'Big Data', 'Building-energy Management', 'Energy Storage System', 'Reinforcement Learning', 'Renewable Energy', 'Smart City']",,"In South Korea, there have been many studies on efficient building-energy management using renewable energy facilities in single zero-energy houses or buildings. However, such management was limited due to spatial and economic problems. To realize a smart zero-energy city, studying efficient energy integration for the entire city, not just for a single house or building, is necessary. Therefore, this study was conducted in the eco-friendly energy town of Chungbuk Innovation City. Chungbuk successfully realized energy independence by converging new and renewable energy facilities for the first time in South Korea. This study analyzes energy data collected from public buildings in that town every minute for a year. We propose a smart city building-energy management model based on the results that combine various renewable energy sources with grid power. Supervised learning can determine when it is best to sell surplus electricity, or unsupervised learning can be used if there is a particular pattern or rule for energy use. However, it is more appropriate to use reinforcement learning to maximize rewards in an environment with numerous variables that change every moment. Therefore, we propose a power distribution algorithm based on reinforcement learning that considers the sales of Energy Storage System power from surplus renewable energy. Finally, we confirm through economic analysis that a 10% saving is possible from this efficiency."
Distributed Multi-agent Target Search and Tracking With Gaussian Process and Reinforcement Learning,2023,"['Distributed system', 'Gaussian process', 'multi-agent reinforcement learning', 'target search and tracking.']",,"Deploying multiple robots for target search and tracking has many practical applications, yet the challenge of planning over unknown or partially known targets remains difficult to address. With recent advances in deep learning, intelligent control techniques such as reinforcement learning have enabled agents to learn autonomously from environment interactions with little to no prior knowledge. Such methods can address the explorationexploitation tradeoff of planning over unknown targets in a data-driven manner, streamlining the decision-making pipeline with end-to-end training. In this paper, we propose a multi-agent reinforcement learning technique (MARL) with target map building based on distributed Gaussian process (GP). We leverage the distributed GP to encode belief over the target locations in a scalable manner and incorporate it into centralized training with decentralized execution MARL framework to efficiently plan over unknown targets. We evaluate the performance and transferability of the trained policy in simulation and demonstrate the method on a swarm of micro unmanned aerial vehicles with hardware experiments."
Impact of network settings on reinforcement learning based caching policy in cooperative edge networks,2023,['Edge cachingDeep reinforcement learningCooperative cachingNetwork setting'],,"Reinforcement learning (RL) has been used in combination with cooperative caching to deal with growing traffic in mobile networks, but the performance of RL based caching policies depends heavily on network settings. This paper investigates the impact of access delays within network infrastructures and popularity and similarity properties of the contents requested on network performance. A deep Q-network based caching framework is established in both basic and extended cooperative edge networks. Our simulation results reveal explicit relationships between the performance and influential parameters, which can provide a guidance and benchmark for the design of effective caching polices with RL and cooperation technologies."
The Robotic Arm Velocity Planning Based on Reinforcement Learning,2023,"['Reinforcement learning', 'Velocity planning', 'Robotic arm', 'Industrial robot manipulator']",,"In order to improve the performance of the robotic arm effectively, this study established a robotic arm velocity planning model developed by artificial intelligence in the simulation system. The model not only considered the dynamic factors of the robotic arm but was also able to set different customized conditions such as machining accuracy and rotation angle. The study could be divided into three parts. First, the simulation environment was constructed with the ABB IRB140 six axes multipurpose industrial robot. To be consistent with real-world situations, a Vortex physics engine was applied to the simulation supplying varying locomotion parameters. In this research, friction, kinematics, and inertia were considered. Second, artificial intelligence was imported into the robotic arm through the establishment of connecting V-rep and Python. The proposed model was developed in the Python environment by deep deterministic policy gradients. Eventually, a design of the appropriate reward function governing the ultimate results was presented. Compared with traditional velocity planning, the proposed method can decline moving error by 0.05 degrees under the considerations involving dynamic factors in a robotic arm. Besides, the proposed velocity planning strategy could be obtained after taking the training time of one hour which can meet the demand for the time cost of the industry."
Deep-reinforcement-learning-based range-adaptive distributed power control for cellular-V2X,2023,['C-V2XDistributed congestion controlDeep reinforcement learningPacket delivery ratioPower control'],,"A distributed congestion control must be adaptable to varying target communication ranges as cellular V2X (C-V2X) is evolving to support flexible coverage suitable for various service scenarios. This study proposes range-adaptive distributed power control (Ra-DPC) based on deep reinforcement learning (DRL) with the Monte Carlo policy gradient algorithm. A key finding is that the agents learn Ra-DPC more effectively when the cumulative interference power of the subchannels is adopted as the state of the DRL model, rather than the channel busy ratio. The proposed Ra-DPC algorithm performs better in energy efficiency and packet delivery ratio than the existing technologies."
A reinforcement learning approach for widest path routing in software-defined networks,2023,['Reinforcement learning Software-defined networks Reward function Q-WPRA Widest path'],,"In this paper, a routing method based on reinforcement learning (RL) under software-defined networks (SDN), namely the Q-learning widest-path routing algorithm (Q-WPRA), is proposed. This algorithm processes the reward function according to the link bandwidth in the execution environment to find the optimal (i.e., widest) transmission path with the maximum bandwidth between the source and the destination through RL. The experimental results reveal that the Q-WPRA is outperformance than Dijkstra’s algorithm and Dijkstra’s widest-path algorithm to find the widest transmission path in SDN environment under different bandwidths, loss rates, and background traffic."
Reinforcement Learning for Input Constrained Sub-optimal Tracking Control in Discrete-time Two-time-scale Systems,2023,"['Convex optimization', 'input constrained', 'reinforcement learning', 'sub-optimal tracking control', 'twotime-scale system.']",,"Two-time-scale (TTS) systems were proposed to describe accurately complex systems that include multiple variables running on two-time scales. Different response speeds of variables and incomplete model information affect the tracking performance of TTS systems. For tracking control of an unknown model, the practicability of reinforcement learning (RL) has been subject to criticism, as the method requires a stable initial policy. Based on singular perturbation theory (SPT), a composite sub-optimal tracking policy is investigated combining model information with measured data. Besides, a selection criterion for the initial stabilizing policy is presented by considering the policy as an input constraint. The proposed method integrating RL technique with convex optimization improves the tracking performance and practicability effectively. Finally, an emulation experiment in F-8 aircraft is given to demonstrate the validity of the developed method."
Hierarchical reinforcement learning from competitive self-play for dual-aircraft formation air combat,2023,"['aircraft', 'air combat', 'soft actor-critic', 'reinforcement learning technique', 'Nash equilibrium', 'symmetry']",,"The recent development of technology helps in the revolutionary war and it controls the war which is influenced by brilliant planning. The maneuver aircraft of intelligent algorithm aids the pilot to decide the particular position on the battlefield. Nowadays the hardware components of radar and missiles are widely used and the beyond visual range is the most popular method applied in air combat. The introduction of close-range air combat maneuver decisions generates the attention of researchers in artificial intelligence. Most of the existing methods are based on autonomous aircraft focused in air combat scenario but manual air combats are widely applied in dual aircraft. Based on the factors mentioned above, a novel hierarchical maneuver decision architecture is applied to a dual-aircraft close-range air combat scenario. Subsequently, the soft actor-critic algorithm is merged with competitive self-play which integrates the knowledge of sub-strategies. Further, the reinforcement learning technique is employed to achieve an approximate Nash equilibrium master strategy. The experimental results show that the hierarchical architecture exhibits good performance, symmetry, and robustness. The research generates a solution for intelligent formation of air combat in the future and guidance for manned or unmanned aircraft cooperative combat."
Deep reinforcement learning for a multi-objective operation in a nuclear power plant,2023,"['Nuclear power plant', 'Automation', 'Deep reinforcement learning', 'Soft actor-critic', 'Hindsight experience replay']",,"Nuclear power plant (NPP) operations with multiple objectives and devices are still performed manually by operators despite the potential for human error. These operations could be automated to reduce the burden on operators; however, classical approaches may not be suitable for these multi-objective tasks.An alternative approach is deep reinforcement learning (DRL), which has been successful in automating various complex tasks and has been applied in automation of certain operations in NPPs. But despite the recent progress, previous studies using DRL for NPP operations have limitations to handle complex multi-objective operations with multiple devices efficiently. This study proposes a novel DRL-based approach that addresses these limitations by employing a continuous action space and straightforward binary rewards supported by the adoption of a soft actor-critic and hindsight experience replay. The feasibility of the proposed approach was evaluated for controlling the pressure and volume of the reactor coolant while heating the coolant during NPP startup. The results show that the proposed approach can train the agent with a proper strategy for effectively achieving multiple objectives through the control of multiple devices. Moreover, hands-on testing results demonstrate that the trained agent is capable of handling untrained objectives, such as cooldown, with substantial success"
A dual-experience pool deep reinforcement learning method and its application in fault diagnosis of rolling bearing with unbalanced data,2023,['· Deep reinforcement learning · Dual-experience pool · Unbalanced data · Rolling bearing · Fault diagnosis'],,"A dual-experience pool deep reinforcement learning (DEPDRL) model is proposed for rolling bearing fault diagnosis with unbalanced data. In this method, a dualexperience pool structure is designed to store the sample data of majority and minority classes.A parallel double residual network model is established to extract deep features of the majority and minority input samples, respectively. In the process of training, the proposed balanced cross-sampling technique is used to randomly select samples from dual-experience pool in a certain proportion to realize the training of a double residual network model. We show the effectiveness of our method on three standard data sets, and compared with Resnet18, DCNN, DQN and DQNimb methods, the results show that DEPDRL has the best performance. Finally, with wavelet time-frequency graph as input, DEPDRL is applied to rolling bearing fault diagnosis with unbalanced test data. The results show that on a variety of unbalanced data sets, both the diagnostic accuracy and the G-means value of the DEPDRL are more than 5 % higher than other algorithms, which fully indicates that the DEPDRL has a very high fault diagnosis ability of rolling bearing with unbalanced data."
FUEL-SAVING CONTROL STRATEGY FOR FUEL VEHICLES WITH DEEP REINFORCEMENT LEARNING AND COMPUTER VISION,2023,"['Deep reinforcement learning (DRL)', 'Computer vision', 'Continuously variable transmission (CVT)', 'Fuel economy']",,"This study uses deep reinforcement learning (DRL) combined with computer vision technology to investigate vehicle fuel economy. In a driving cycle with car-following and traffic light scenarios, the vehicle fuel-saving control strategy based on DRL can realize the cooperative control of the engine and continuously variable transmission. The visual processing method of the convolutional neural network is used to extract available visual information from an on-board camera, and other types of information are obtained through the vehicle’s inherent sensor. The various detected types of information are further used as the state of DRL, and the fuel-saving control strategy is built. A Carla–Simulink co-simulation model is established to evaluate the proposed strategy. An urban road driving cycle and highway road driving cycle model with visual information is built in Carla, and the vehicle power system is constructed in Simulink. Results show that the fuel-saving control strategy based on DRL and computer vision achieves improved fuel economy. In addition, in the Carla–Simulink co-simulation model, the fuel-saving control strategy based on DRL and computer vision consumes an average time of 17.55 ms to output control actions, indicating its potential for use in real-time applications."
Deep reinforcement learning based edge computing for video processing,2023,['Edge computingReinforcement learningVideo processing'],,"In many of 5G applications, end devices with lack of computing power often need to carry out heavy computations involving multimedia data. Edge computing has emerged as a promising solution to circumvent scarce resources at end devices, with moderate delays compared to cloud computing. In this work, we study the problem of offloading video processing tasks to edge servers. To this end, we develop a deep reinforcement learning based method for selecting either local or edge server to process video frames. We demonstrate the performance of our method through experiments with video frame transform tasks."
Generating Controller of GR(1) Synthesis and Reinforcement Learning in Game-Solving,2023,"['gr(1) synthesis', 'reinforcement learning', 'controller synthesis', 'formal method', 'artificial intelligence']",,
Heave reduction of payload through crane control based on deep reinforcement learning using dual offshore cranes,2023,"['deep deterministic policy gradient', 'reinforcement learning', 'ocean environment', 'offshore crane', 'crane control']",,"Offshore operation causes the dynamic motion of offshore cranes and payload by the ocean environment. The motion of the payload lowers the safety and efficiency of the work, which may increase the working time or cause accidents. Therefore, we design a control method for the crane using artificial intelligence to minimize the heave motion of the payload. Herein, reinforcement learning (RL), which calculates actions according to states, is applied. Furthermore, the deep deterministic policy gradient (DDPG) algorithm is used because the actions need to be determined in a continuous state. In the DDPG algorithm, the state is defined as the motion of the crane and speed of the wire rope, and the action is defined as the speed of the wire rope. In addition, the reward is calculated using the motion of the payload. In this study, the heave motion of the payload was reduced by developing an agent suitable for adjusting the length of the wire rope. The heave motion of the payload was compared in between the non-learning condition of the RL-based control and proportional integral differential (PID) control; and an average payload reduction rate of 30% was observed under RL-based control. The RL-based control performed better than the PID control under learned conditions."
MODEL PREDICTIVE ADAPTIVE CRUISE CONTROL OF INTELLIGENT ELECTRIC VEHICLES BASED ON DEEP REINFORCEMENT LEARNING ALGORITHM FWOR DRIVER CHARACTERISTICS,2023,"['Intelligent electric vehicles', 'Adaptive cruise control', 'Deep reinforcement learning algorithm', 'Naturalistic driving data', 'Driver model']",,"This paper presents a novel model predictive adaptive cruise control strategy of intelligent electric vehicles based on deep reinforcement learning algorithm for driver characteristics. Firstly, the influence mechanism of factors such as inter-vehicle distance, relative speed and time headway (THW) on the driver’s behavior in the process of car following is analyzed by the correlation coefficient method. Then, the driver behavior in the process of car following is learned from the natural driving data, the car following model is established by the deep deterministic policy gradient (DDPG) algorithm, and the output acceleration of the DDPG model is used as the reference trajectory of the ego vehicle’s acceleration. Next, in order to reflect the driver behavior and achieve multi performance objective optimization of adaptive cruise control of intelligent electric vehicles, the model predictive controller (MPC) is designed and used for tracking the desired acceleration produced by the car following DDPG model. Finally, the performance of the proposed adaptive cruise control strategy is evaluated by the experimental tests, and the results demonstrate the effectiveness of proposed control strategy."
Optimal Incremental-containment Control of Two-order Swarm System Based on Reinforcement Learning,2023,"['Backstepping', 'Lypunov function', 'optimal incremental-containment control', 'reinforcement learning', 'swarm system.']",,"In this paper, the optimal incremental-containment control of two-order swarm system based on reinforcement learning (RL) is proposed to avoid the dilemma that the number of agents in a swarm system is immutable, which is essential for a swarm system that cannot meet the containment demands and need more agents to expand the containment range. Notably, the number of agents in a swarm system with a traditional containment controller is immutable, which limits the containment range that the swarm system can achieve. Besides, in traditional optimal control theory, it is obtained by solving the Hamilton-Jacobi-Bellman (HJB) equation, which is difficult to solve due to the unknown nonlinearity. To overcome these problems, several contributions are made in this paper. Firstly, in order to overcome the dilemma that the number of agents in the swarm system is immutable, the incremental-containment control is proposed. Secondly, considering the error and control input as the optimization goal, the optimal cost function is introduced and the optimal incremental-containment control is proposed to reduce resource waste and increase hardware service life. Furthermore, based on the proposed optimal incrementalcontainment control, the controller is designed by a new RL based on the backstepping method. The Lyapunov function is used to prove the stability of controller. The simulation show the efficiency of the proposed controller."
Compensated Motion and Position Estimation of a Cable-driven Parallel Robot Based on Deep Reinforcement Learning,2023,"['Cable-driven parallel robot', 'deep reinforcement learning', 'motion control.']",,"Unlike conventional rigid-link parallel robots, cable-driven parallel robots (CDPRs) have distinct advantages, including lower inertia, higher payload-to-weight ratio, cost-efficiency, and larger workspaces. However, because of the complexity of the cable configuration and redundant actuation, model-based forward kinematics and motion control necessitate high effort and computation. This study overcomes these challenges by introducing deep reinforcement learning (DRL) into the cable robot and achieves compensated motion control by estimating the actual position of the end-effector. We used a random behavior strategy on a CDPR to explore the environment, collect data, and train neural networks. We then apply the trained network to the CDPR and verify its efficacy. We also addressed the problem of asynchronous state observation and action execution by delaying the action execution time in one cycle and adding this action to be executed to match the motion control command. Finally, we implemented the proposed control method to a high payload cable robot system and verified the feasibility through simulations and experiments. The results demonstrate that the end-effector position estimation accuracy can be improved compared with the numerical model-based forward kinematics solution and the position control error can be reduced compared with the conventional open-loop control and the open-loop control with tension distribution form."
Exploring the Effectiveness of GAN-based Approach and Reinforcement Learning in Character Boxing Task,2023,"['Character Animation', 'Physics-based Simulation', 'Reinforcement Learning', 'GAN', '캐릭터 애니메이션', '물리기반 시뮬레이션', '강화학습', 'GAN']",,"For decades, creating a desired locomotive motion in a goal-oriented manner has been a challenge in character animation. Datadriven methods using generative models have demonstrated efficient ways of predicting long sequences of motions without the need for explicit conditioning. While these methods produce high-quality long-term motions, they can be limited when it comes to synthesizing motion for challenging novel scenarios, such as punching a random target. A state-of-the-art solution to overcome this limitation is by using a GAN Discriminator to imitate motion data clips and incorporating reinforcement learning to compose goaloriented motions. In this paper, our research aims to create characters performing combat sports such as boxing, using a novel reward design in conjunction with existing GAN-based approaches. We experimentally demonstrate that both the Adversarial Motion Prior [3] and Adversarial Skill Embeddings [4] methods are capable of generating viable motions for a character punching a random target, even in the absence of mocap data that specifically captures the transition between punching and locomotion. Also, with a single learned policy, multiple task controllers can be constructed through the TimeChamber framework."
Applying multi-agent deep reinforcement learning for contention window optimization to enhance wireless network performance,2023,['CW optimizationCW thresholdSETL-DQN multi-agentSystem throughput'],,"This paper investigates the Contention Window (CW) optimization problem in multi-agent scenarios, where the fully cooperative among mobile stations is considered. A partially observable environment is employed to model and analyze the CW optimization problem, and Smart Exponential-Threshold-Linear with Deep Q-learning Network (SETL-DQN) Multi-Agent (MA) algorithm is proposed to obtain the optimal system throughput through the CW Threshold optimization. In the determined scenarios, SETL-DQN(MA) can effectively cope with the mutual interaction among mobile stations. The simulation results show that our proposed method is superior from both static and dynamic scenarios and has the highest optimum packet transmission efficiency."
강한 Data Augmentation과 Contrastive Learning을 통한 이미지 기반 강화학습  일반화 성능 향상 연구,2023,"['Deep learning', 'Reinforcement learning', 'Data augmentation', 'Generalization', 'Contrastive learning', 'Self-supervised learning', '딥러닝', '강화학습', '데이터증강', '일반화', '대조학습', '자기지도학습']",,"In this paper, we are proposing a convolutional contrastive learning method that can improve the generalization performance of image-based reinforcement learning. To do this, methods on augmenting input images were mainly used.However, strong augmentation hinders the stability of reinforcement learning. Thus, by gradually increasing the random image mixing ratio during training, a reinforcement learning agent is not affected by strong data augmentation. At the same time, the effect on generalization performance is maximized. Experiments on DM Control test environments have shown that the proposed method outperforms the existing studies on the generalization of image-based reinforcement learning."
Q-learning을 이용한 우선순위 기반 Adaptive Slotted ALOHA 기법,2023,"['Reinforcement learning', 'Q-learning', 'Slotted ALOHA', '5G cellular network', 'Machine Type Communication']","본 논문에서는 기존 slotted ALOHA 기법에 Q-learning과 우선순위를 적용하는 Priority based Adaptive slotted ALOHA(PAS-ALOHA)를 제안한다. PAS-ALOHA 기법은 각 디바이스의 값에 따라 이전 상태에서 데이터 패킷의 전송 성공 횟수가 많은 디바이스에 우선 순위를 지정한다. 다음으로, 남은 데이터 패킷을 전송할 때 다른 디바이스의 제약을 받지 않기 때문에 성공 비율을 높이고, 충돌 비율을 감소시킨다. 또한, Jain’s Fairness Index를 적용하여 음의 보상에 따라 각 디바이스의 공정성을 비교한다. 실험 결과 기존 slotted ALOHA 기법에 비해 성공비율은 약 69% 증가하며 충돌 비율은 최대 30% 감소함을 보였다. 따라서, 5G MTC 환경에서 디바이스 개수가증가하더라도 채널 상태에 적응하여 데이터 패킷을 성공적이고, 공평하게 전송할 수 있을 것으로 기대된다.",
딥러닝(Deep Learning)모델을 활용한 범죄사실 구성요소 자동 추출 방안 연구,2023,"['Deep Learning', 'Natural Language Processing', 'Crime Facts', 'Key Information', 'Information Extraction.', '딥러닝', '자연어처리', '범죄사실', '구성요건', '정보추출']","2021년 검경수사권 조정에 따라 경찰기관은 독립성을 확보하였고, 이에 따라 경찰은 국민의 신뢰를 확보하기 위해 국가수사본부 신설 등 수사 전문성을 강화시키고 투명성을 제고시키는 데 노력을 기울이고 있다. 한편, 최근 법률 분야에 AI가 도입되면서 판결문 검색, 계약서 관리 그리고 법률 문서 번역 등 AI 모델을 통해 많은 도움을 받고 있다. 하지만 수사 문서를 자동으로 분석하고 보고서를 작성해주는 AI 기술은 국내에 없는 거의 실정이다.따라서 본 연구에서는 수사 및 법률 문서에서 주요 정보를 자동으로 추출하여 수사결과보고서 작성에 도움을 줄 수 있는 딥러닝 모델을 개발하고자 한다. 본 연구를 통해 형사 1심 살인 판결문에서 추출할 수 있는 범죄사실 구성요소를 정의하였다. 또한 최근 자연어분야에서 높은 관심을 받고 있는 GPT-3.5 API의 한계점을 살펴보았고 이를 보완한 BERT 기반 모델을 개발하였다. 또한 개발된 모델을 사용하여 범죄사실에서 단어 단위의 정보와 구절 단위의 정보를 17개 추출하였다.그 결과, 단어 단위 정보는 F1-score 83.85%, 구절 단위 정보는 F1-score 64.2%의 성능을 내었다. 결과 분석을 통해 성능을 향상 시킬 수 있는 방안을 모색하였다. 본 연구에서 개발된 AI 모델을 수사 환경에 적용하면 수사결과보고서 작성을 지원하고, 유사 판례를 검색하는 등 수사관이 투명하고 객관적인 수사를 할 수 있도록 도와줄 수 있을 것이다. 또한 본 연구의 결과가 딥러닝 모델이 법률 분야에서 발전할 수 있는 기반이 될 수 있을 것을 기대한다.","In accordance with the adjustment of investigative and prosecutorial powers in 2021, police agencies have been working to enhance their independence, while also aiming to secure the public's trust through initiatives such as the establishment of a National Investigation Headquarters. These efforts are geared towards reinforcing the investigative expertise and improving transparency. Meanwhile, with the recent integration of AI in legal domain, AI models have provided significant assistance in tasks like searching for legal judgments, managing contracts, and translating legal documents. However, there is no AI technology available to automatically analyze investigation documents and generate reports. Therefore, the purpose of this study is to develop a deep learning model that can automatically extract key information from crime investigation and legal documents, aiming to assist in generating investigation reports. Through this study, we defined key informations related to crime facts that can be automatically extracted from the Court Decision of murder case. We also examined the limitations of GPT-3.5 and developed a BERT-based model to address these limitations. Additionally, the developed model was utilized to extract 17 information, both at the word and phrase levels, from crime facts.As a result, the word-level information achieved a performance of F1-score 83.85%, while the phrase-level information achieved a performance of F1-score 64.2%. If the AI model developed in this study is applied in the investigative environment, it would enable to generate investigation reports and enable the search for similar legal precedents. This could assist investigators in conducting transparent and objective investigations."
A Study on the Implementation of Crawling Robot using Q-Learning,2023,"['Q-Learning', 'Machine Learning', 'Reinforcement learning', 'Markov-Modeling']",,"Machine learning is comprised of supervised learning, unsupervised learning and reinforcement learning as the type of data and processing mechanism. In this paper, as input and output are unclear and it is difficult to apply the concrete modeling mathematically , reinforcement learning method are applied for crawling robot in this paper. Especially, Q-Learning is the most effective learning technique in model free reinforcement learning. This paper presents a method to implement a crawling robot that is operated by finding the most optimal crawling method through trial and error in a dynamic environment using a Q-learning algorithm. The goal is to perform reinforcement learning to find the optimal two motor angle for the best performance, and finally to maintain the most mature and stable motion about EV3 Crawling robot. In this paper, for the production of the crawling robot, it was produced using Lego Mindstorms with two motors, an ultrasonic sensor, a brick and switches ,and EV3 Classroom SW are used for this implementation. By repeating 3 times learning, total 60 data are acquired, and two motor angles vs. crawling distance graph are plotted for the more understanding. Applying the Q-learning reinforcement learning algorithm, it was confirmed that the crawling robot found the optimal motor angle and operated with trained learning, and learn to know the direction for the future research."
A Bayesian Network-based Machine-learning Algorithm for Enhancing Performance in Typical Scenarios,2023,"['Machine-learning', 'Bayesian', 'Automation', 'CASH', 'Artificial intelligence']",,"Automated machine-learning technology can achieve the automation, efficiency, and intelligence of machine learning. This technology can lower the application threshold of artificial intelligence (AI) and has attracted academic attention. Therefore, taking a typical classification problem as an example, this study proposes a framework of a machine-learning pipeline automation design algorithm combining a Bayesian algorithm and reinforcement learning. Aiming at the CASH problem, the study divides the machine-learning pipeline design problem into two sub-problems. One is to realize a machine-learning pipeline structure search based on reinforcement learning. The other is to realize machine-learning pipeline hyperparameter optimization configurations based on the Bayesian network model. The experimental results showed that when the time budget was four hours, the average balanced accuracy of Auto-PLD(Ed note: You need to define what these are in the abstract.) was 0.003 higher than that of Auto-PLD-random and 0.001 higher than that of Auto-sklearn. The success rate of the Auto-PLD machine-learning pipeline evaluation on various datasets exceeded 92%. Based on the Bayesian model and reinforcement learning, the machine-learning pipeline automation design algorithm framework can also play a good role in practical applications. Moreover, it can promote the development of artificial intelligence technology."
Recent Progress in Learning Algorithms Applied in Energy Management of Hybrid Vehicles: A Comprehensive Review,2023,"['Hybrid vehicle', 'Energy management strategy', 'Reinforcement learning', 'Deep reinforcement learning', 'Recent progress']",,"Hybrid vehicles (HVs) that equip at least two different energy sources have been proven to be one of effective and promising solutions to mitigate the issues of energy crisis and environmental pollution. For HVs, one of the core supervisory control problems is the power distribution among multiple power sources, and for this problem, energy management strategies (EMSs) have been studied to save energy and extend the service life of HVs. In recent years, with the rapid development of artificial intelligence and computer technologies, learning algorithms have been gradually applied to the EMS field and shortly become a novel research hotspot. Although there are some brief reviews on the learning-based (LB) EMSs for HVs in recent years, a state-of-the-art and thorough review related to the applications of learning algorithms in HV EMSs still lacks. In this paper, learning algorithms applied in HV EMSs are categorized and reviewed in terms of the reinforcement learning algorithms and deep reinforcement learning algorithms. Apart from presenting the recent progress of learning algorithms applied in HV EMSs, advantages and disadvantages of different learning algorithms and LB EMSs are also discussed. Finally, a brief outlook related to the further applications of learning algorithms in HV EMSs, such as the integration towards autonomous driving and intelligent transportation system, is presented."
Learning-based client selection for multiple federated learning services with constrained monetary budgets,2023,['Multiple federated learning servicesClient selectionBudget constraintsMulti-agent deep reinforcement learning'],,"We investigate a data quality-aware dynamic client selection problem for multiple federated learning (FL) services in a wireless network, where each client offers dynamic datasets for the simultaneous training of multiple FL services, and each FL service demander has to pay for the clients under constrained monetary budgets. The problem is formalized as a non-cooperative Markov game over the training rounds. A multi-agent hybrid deep reinforcement learning-based algorithm is proposed to optimize the joint client selection and payment actions, while avoiding action conflicts. Simulation results indicate that our proposed algorithm can significantly improve training performance."
Next-Generation Chatbots for Adaptive Learning: A proposed Framework,2023,"['Adaptive Learning', 'Learning Attributes', 'ChatGPT', 'Educational Technology', 'Human-Computer Interaction Analysis']",,"Adaptive has gained significant attention in Education Technology (EdTech), with personalized learning experiences becoming increasingly important. Next-generation chatbots, including models like ChatGPT, are emerging in the field of education. These advanced tools show great potential for delivering personalized and adaptive learning experiences. This paper reviews previous research on adaptive learning and the role of chatbots in education. Based on this, the paper explores current and future chatbot technologies to propose a framework for using ChatGPT or similar chatbots in adaptive learning. The framework includes personalized design, targeted resources and feedback, multi-turn dialogue models, reinforcement learning, and fine-tuning. The proposed framework also considers learning attributes such as age, gender, cognitive ability, prior knowledge, pacing, level of questions, interaction strategies, and learner control. However, the proposed framework has yet to be evaluated for its usability or effectiveness in practice, and the applicability of the framework may vary depending on the specific field of study. Through proposing this framework, we hope to encourage learners to more actively leverage current technologies, and likewise, inspire educators to integrate these technologies more proactively into their curricula. Future research should evaluate the proposed framework through actual implementation and explore how it can be adapted to different domains of study to provide a more comprehensive understanding of its potential applications in adaptive learning."
The role of artificial neural network and machine learning in utilizing spatial information,2023,"['Machine learning', 'Artificial neural networks', 'Satellite communication', 'Deep learning', 'Spatial information', 'Multimedia applications']",,"In this age of the fourth industrial revolution 4.0, the digital world has a plethora of data, including the internet of things, mobile, cybersecurity, social media, forecasts, health data, and so on. The expertise of machine learning and artificial intelligence (AI) is required to soundly evaluate the data and develop related smart and automated applications, These fields use a variety of machine learning techniques including supervised, unsupervised, and reinforcement learning. The objective of the study is to present the role of artificial neural networks and machine learning in utilizing spatial information. Machine learning and AI play an increasingly important role in disaster risk reduction from hazard mapping and forecasting severe occurrences to real-time event detection, situational awareness, and decision assistance. Some of the applications employed in the study to analyze the various ANN domains included weather forecasting, medical diagnosis, aerospace, facial recognition, stock market, social media, signature verification, forensics, robotics, electronics hardware, defense, and seismic data gathering. Machine learning determines the many prediction models for problems involving classification, regression, and clustering using known variables and locations from the training dataset, spatial data that is based on tabular data creates different observations that are geographically related to one another for unknown factors and places. The study presents that the Recurrent neural network and convolutional neural network are the best method in spatial information processing, healthcare, and weather forecasting with greater than 90% accuracy."
Slicing-Based Resource Optimization in Multi-Access Edge Network Using Ensemble Learning Aided DDPG Algorithm,2023,"['Content caching', 'deep reinforcement learning', 'ensemble learning', 'multi-access edge computing', 'network slicing.']",,"Recently, the technological development in edgecomputing and content caching can provide high-quality servicesfor users in the wireless communication networks. As a promisingtechnology, multi-access edge computing (MEC) can offload tasksto the nearby edge servers, which alleviates the pressure ofusers. However, various services and dynamic wireless channelconditions make effective resource allocation challenging. Inaddition, network slicing can create a logical virtual networkand allocate resources flexibly among multiple tenants. In thispaper, we construct an integrated architecture of communication,computing and caching to solve the joint optimization problem oftask scheduling and resource allocation. In order to coordinatenetwork functions and dynamically allocate limited resources,this paper adopts an improved deep reinforcement learning(DRL) method, which fully jointly considers the diversity of userrequest services and the dynamic wireless channel conditions toobtain the mobile virtual network operator (MVNO) maximalprofit function. Considering the slow convergence speed of theDRL algorithm, this paper combines DRL and ensemble learning.The simulation result shows that the resource allocation schemeinspired by DRL is significantly better than the other comparedstrategies. The output of the result of DRL algorithm combinedwith ensemble learning is faster and more cost-effective."
Determination of Optimal Adhesion Conditions for FDM Type 3D Printer Using Machine Learning,2023,"['3D Printing defect', '3D Printing condition', 'Adhesion force', 'Machine learning', 'Optimization']",,"In this study, optimal adhesion conditions to alleviate defects caused by heat shrinkage with FDM type 3D printers with machinelearning are researched. Machine learning is one of the “statistical methods of extracting the law from data” and can be classified assupervised learning, unsupervised learning and reinforcement learning. Among them, a function model for adhesion between the bedand the output is presented using supervised learning specialized for optimization, which can be expected to reduce output defectswith FDM type 3D printers by deriving conditions for optimum adhesion between the bed and the output. Machine learning codesprepared using Python generate a function model that predicts the effect of operating variables on adhesion using data obtainedthrough adhesion testing. The adhesion prediction data and verification data have been shown to be very consistent, and the potentialof this method is explained by conclusions."
Q Learning Based Adaptive Protocol Parameters for WSNs,2023,"['Adaptive  protocol  parameters', 'Q  learning', 'WSN.']",,"Wireless sensor networks (WSN) are widely used formulti-disciplinary applications. According to the requirementsand the goal of the application, the network is designed andthe protocol is tuned to obtain the best performance of theWSN. In real world applications, all nodes in the networkhave a common protocol parameter set, irrespective of theirposition in the network. In several experiments with multihopsensor networks, we observed that individual nodes performdifferently depending on the protocol parameter values. With theobservation the question was raised whether the performanceof the network can be improved by using tuned parametersets for each individual node in the network. Tuning protocolparameters for each node manually is tedious and may not bepractical for large number of nodes. As a solution, adaptiveprotocol parameters are introduced using reinforcement learning.The learning algorithm gradually approaches an optimal set ofprotocol parameter values for each and every node during theruntime resulting in average improved network performance with13.44% and 29.41% compared to networks with static commonparameter sets in a network of 20 and 30 nodes respectivelyin simulation environment. The performance of the adaptiveprotocol is validated using real testbed with 10 nodes andthe performance improvement is 16.21%. With the simulationresults it was observed that networks with higher number ofnodes obtain more performance gain using the adaptive protocolalgorithm compared to networks with lower of nodes."
Two tales of platoon intelligence for autonomous mobility control: Enabling deep learning recipes,2023,"['auction', 'autonomous mobility control', 'deep learning', 'platoon', 'reinforcement learning']",,"This paper surveys recent multiagent reinforcement learning and neural Myerson auction deep learning efforts to improve mobility control and resource management in autonomous ground and aerial vehicles. The multiagent reinforcement learning communication network (CommNet) was introduced to enable multiple agents to perform actions in a distributed manner to achieve shared goals by training all agents' states and actions in a single neural  network. Additionally, the Myerson auction method guarantees trustworthiness among multiple agents to optimize rewards in highly dynamic systems. Our findings suggest that the integration of MARL CommNet and Myerson techniques is very much needed for improved efficiency and trustworthiness."
Q-Learning based Collision Avoidance for 802.11 Stations with Maximum Requirements,2023,"['802.11 WLAN', 'Q-learning', 'Backoff algorithm', 'Contention window', 'Resource allocation']",,"The IEEE 802.11 WLAN adopts a random backoff algorithm for its collision avoidance mechanism, and it is well known that the contention-based algorithm may suffer from performance degradation especially in congested networks. In this paper, we design an efficient backoff algorithm that utilizes a reinforcement learning method to determine optimal values of backoffs. The mobile nodes share a common contention window (CW) in our scheme, and using a Q-learning algorithm, they can avoid collisions by finding and implicitly reserving their optimal time slot(s). In addition, we introduce Frame Size Control (FSC) algorithm to minimize the possible degradation of aggregate throughput when the number of nodes exceeds the CW size. Our simulation shows that the proposed backoff algorithm with FSC method outperforms the 802.11 protocol regardless of the traffic conditions, and an analytical modeling proves that our mechanism has a unique operating point that is fair and stable."
Dynamic Computation Offloading Based on Q-Learning for UAV-Based Mobile Edge Computing,2023,"['Computation offloading', 'energy efficiency', 'mobile edge computing', 'Q-learning', 'reinforcement learning']",,"Emerging mobile edge computing (MEC) can be used in battery-constrained Internet of things (IoT). The execution latency of IoT applications can be improved by offloading computation-intensive tasks to an MEC server. Recently, the popularity of unmanned aerial vehicles (UAVs) has increased rapidly, and UAV-based MEC systems are receiving considerable attention. In this paper, we propose a dynamic computation offloading paradigm for UAV-based MEC systems, in which a UAV flies over an urban environment and provides edge services to IoT devices on the ground. Since most IoT devices are energy-constrained, we formulate our problem as a Markov decision process considering the energy level of the battery of each IoT device. We also use model-free Q-learning for time-critical tasks to maximize the system utility. According to our performance study, the proposed scheme can achieve desirable convergence properties and make intelligent offloading decisions."
Leveraging Visibility-Based Rewards in DRL-based Worker Travel Path Simulation for Improving the Learning Performance,2023,"['Construction Worker', 'Site Layout Planning', 'Pathfinding', 'Deep Reinforcement Learning', 'Travel Path']",,"Optimization of Construction Site Layout Planning (CSLP) heavily relies on workers' travel paths. However, traditional path generation approaches predominantly focus on the shortest path, often neglecting critical variables such as individual wayfinding tendencies, the spatial arrangement of site objects, and potential hazards. These oversights can lead to compromised path simulations, resulting in less reliable site layout plans. While Deep Reinforcement Learning (DRL) has been proposed as a potential alternative to address these issues, it has shown limitations. Despite presenting more realistic travel paths by considering these variables, DRL often struggles with efficiency in complex environments, leading to extended learning times and potential failures. To overcome these challenges, this study introduces a refined model that enhances spatial navigation capabilities and learning performance by integrating workers' visibility into the reward functions. The proposed model demonstrated a 12.47% increase in the pathfinding success rate and notable improvements in the other two performance measures compared to the existing DRL framework. The adoption of this model could greatly enhance the reliability of the results, ultimately improving site operational efficiency and safety management such as by reducing site congestion and accidents. Future research could expand this study by simulating travel paths in dynamic, multi-agent environments that represent different stages of construction."
Enhancing Service Availability in Multi-Access Edge Computing with Deep Q-Learning,2023,"['Edge Computing', 'Service Mobility', 'Service Availability', 'Beyond 5G', 'Deep Reinforcement Learning']",,"The Multi-access Edge Computing (MEC) paradigm equips network edge telecommunication infrastructure with cloud computing resources. It seeks to transform the edge into an IT services platform for hosting resource-intensive and delay-stringent services for mobile users, thereby significantly enhancing perceived service quality of experience. However, erratic user mobility impedes seamless service continuity as well as satisfying delay-stringent service requirements, especially as users roam farther away from the serving MEC resource, which deteriorates quality of experience. This work proposes a deep reinforcement learning based service mobility management approach for ensuring seamless migration of service instances along user mobility. The proposed approach focuses on the problem of selecting the optimal MEC resource to host services for high mobility users, thereby reducing service migration rejection rate and enhancing service availability. Efficacy of the proposed approach is confirmed through simulation experiments, where results show that on average, the proposed scheme reduces service delay by 8%, task computing time by 36%, and migration rejection rate by more than 90%, when comparing to a baseline scheme."
Monitoring in a reinforced concrete structure for storing low and intermediate level radioactive waste. Lessons learnt after 25 years,2023,"['Steel reinforced concrete', 'Potential parameters', 'Monitoring', 'Sensor']",,"Where concrete structures are designed to have a service life of over 100 years, their performance must be monitored, for the prediction models available are fraught with uncertainties that need to be elim- inated. The present study was conducted to meet that need by monitoring a pilot structure for low and intermediate radioactive waste storage. Long-term operation of the sensors was observed to be adequate to determine the value of the parameters that characterise structural durability, such as corrosion current density. The parameters analysed were correlated to calculate their reciprocal impact: where applied in conjunction with artificial intelligence tools, temperature, for instance, was found suitable for finding activation energy and expansion coefficients and detecting outliers. The results showed the pilot structure to perform satisfactorily."
RLECN—A learning based dynamic threshold control of ECN,2023,['TCPECNSDNReinforcement learningRL'],,"Explicit congestion notification (ECN) enables the network routers to mark packets instead of dropping them. When the queue size reaches a certain threshold, the queued packets are marked to indicate predicted congestion. However, an optimal value of the ECN threshold is not defined. A pre-decided value is chosen either by estimation or by hit and trial and therefore, it does not generalize well under a wide range of network scenarios. We propose a reinforcement learning (RL)-based ECN mechanism that utilizes software-defined networks (SDN) to address this problem. Our solution enables the routers to keep a dynamic ECN threshold according to the current network conditions. SDN provides the network visibility and reach to train the RL model and to dynamically adjust the ECN threshold. We show through experimental results that our proposed model outperforms the current state of the art."
Physics-informed neural networks for learning fluid flows with symmetry,2023,"['Physics-informed Machine Learning', 'Network Architecture', 'Power-law Fluid', 'Pressure-driven Flow', 'Inverse Problem']",,"We suggest symmetric variational physics-informed neural networks (symmetric VPINN) to learn the symmetric fluid flow and physical properties of fluids from a limited set of data. Symmetric VPINN is based on the VPINN framework and guarantees the symmetry of the solutions by modifying the network architecture. The effectiveness of the symmetric VPINN is demonstrated by predicting the velocity profiles and power-law fluid properties in the Poiseuille flow of a parallel channel. Symmetric VPINN models robustly and accurately learn power-law fluid flow in both forward and inverse problems. We demonstrate that the symmetric VPINN can be particularly useful when the power-law index is small and the data are extremely limited. The modified network architecture in the symmetric VPINN guides the neural network towards an exact solution by reinforcing symmetry. We show that symmetric VPINN is effective in obtaining unknown physical properties in practical experiments where data are scarce, suggesting the possibility of introducing known conditions of the system directly into the network structure to improve the accuracy of the network."
Performance-based drift prediction of reinforced concrete shear wall using bagging ensemble method,2023,"['Reinforced concrete shear wall', 'Damage limit state', 'Machine-learning models', 'Bagging ensemble method']",,"Reinforced Concrete (RC) shear walls are one of the civil structures in nuclear power plants to resist lateral loads such as earthquakes and wind loads effectively. Risk-informed and performance-based regulation in the nuclear industry requires considering possible accidents and determining desirable performance on structures. As a result, rather than predicting only the ultimate capacity of structures, the prediction of performances on structures depending on different damage states or various accident scenarios have increasingly needed. This study aims to develop machine-learning models predicting drifts of the RC shear walls according to the damage limit states. The damage limit states are divided into four categories: the onset of cracking, yielding of rebars, crushing of concrete, and structural failure. The data on the drift of shear walls at each damage state are collected from the existing studies, and four regression machine-learning models are used to train the datasets. In addition, the bagging ensemble method is applied to improve the accuracy of the individual machine-learning models. The developed models are to predict the drifts of shear walls consisting of various cross-sections based on designated damage limit states in advance and help to determine the repairing methods according to damage levels to shear walls"
Reinforced quantum-behaved particle swarm-optimized neural network for cross-sectional distortion prediction of novel variable-diameter-die-formed metal bent tubes,2023,"['metal bent tube', 'variable diameter die', 'cross-sectional distortion', 'quantum-behaved particle swarm optimization', 'back-propagation neural network']",,"With light weight, high strength, and high performance, metal bent tubes have attracted increasing applications in aeronautics. However, the growing demand for customized tubular parts has led to a significant increase in the cost of conventional tube-bending processes, as they can only process tubes of a specific diameter. To this end, this paper proposes a variable diameter die (VDD) scheme which can bend tubes with a specific range of diameters. To investigate the formability of VDD-processed tubes for practical VDD applications, an accurate and reliable prediction method of cross-sectional distortion is imperative. Hence, we pioneer a novel intelligent model based on quantum-behaved particle swarm optimization (QPSO)-optimized back-propagation neural network (BPNN) to predict a rational cross-sectional distortion characterization index: average distortion rate. The adaptive adjustment of coefficients and the Gaussian distributed random vector are introduced to QPSO, which balance the search and enhance the diversity of the population, respectively. For further improvement in optimization performance, the informed initialization strategy is applied to QPSO. The efficiency of the proposed reinforced QPSO (RQPSO)-optimized BPNN model is evaluated by comparing the results with those of the BPNN, BPNN with Xavier initialization, several different particle swarm optimization variants-optimized BPNN models, and variants of popular machine learning models. The results indicated the superiority of RQPSO over other methods in terms of the coefficient of determination (${R}^2$), variance account for, root mean square error (MSE), mean absolute error, and standard deviation of MSE. Thus, the proposed novel algorithm could be employed as a reliable and accurate technique to predict the cross-sectional distortion of VDD-processed tubes."
Ensemble techniques and hybrid intelligence algorithms for shear strength prediction of squat reinforced concrete walls,2023,"['ensemble learning methods', 'optimization algorithm', 'shear strength', 'squat reinforced concrete wall']",,"Squat reinforced concrete (SRC) shear walls are a critical part of the structure for both office/residential buildings and nuclear structures due to their significant role in withstanding seismic loads. Despite this, empirical formulae in current design standards and published studies demonstrate a considerable disparity in predicting SRC wall shear strength. The goal of this research is to develop and evaluate hybrid and ensemble artificial neural network (ANN) models. State-of-the-art population-based algorithms are used in this research for hybrid intelligence algorithms. Six models are developed, including Honey Badger Algorithm (HBA) with ANN (HBA-ANN), Hunger Games Search with ANN (HGS-ANN), fitness-distance balance coyote optimization algorithm (FDB-COA) with ANN (FDB-COA-ANN), Averaging Ensemble (AE) neural network, Snapshot Ensemble (SE) neural network, and Stacked Generalization (SG) ensemble neural network. A total of 434 test results of SRC walls is utilized to train and assess the models. The results reveal that the SG model not only minimizes prediction variance but also produces predictions (with R<sup>2</sup>= 0.99) that are superior to other models."
"Inclusive Crisis Communication During COVID-19: Lessons Learned from the Experiences of Persons with Disabilities in Makassar, Indonesia",2023,"['disabilities', 'crisis communication', 'inclusive', 'pandemic', 'COVID-19', 'Indonesia']",,"Persons with disabilities (PwD) are believed to be a group that had a greater risk during the pandemic. While PwD are vulnerable to the spread of COVID-19 due to their high dependence on physical contact, a series of policies restricting public movement during the pandemic had the potential to place PwD in increasingly marginalized situations. This situation reinforces the urgency of crisis communication as one of the critical parts of the COVID-19 response to ensure that all levels and groups of society can accept and understand the flow of information. Using a qualitative approach, this research was conducted through in-depth interviews with PwD age 17-50 in the city of Makassar, Indonesia. The results of this study suggest that crisis communication during the pandemic should involve participatory communication, which focuses on collaboration with empowerment. The PwD communities need to be actively engaged during the communication process of a pandemic crisis to ensure that inclusiveness is always taken into account. During the distribution of information, the relevant health officers or the government at the regional level need to carry out more frequent socialization and special services for PwD based on the characteristics of their disabilities."
실용적 강화학습 기술 동향: 모방학습부터 오프라인 강화학습까지,2023,"['심층 강화학습', '오프라인 강화학습', '모방학습', 'Deep Reinforcement Learning', 'Offline Reinforcement Learning', 'Imitation Learning']",,"The reinforcement learning paradigm has shifted from online to offline recently. Such a change is to overcome the impracticality of online reinforcement learning, which is limited to simulation-based game tasks (e.g., Go, Chess, Atari, and so on). This paper reviews an offline reinforcement learning approach that builds a policy by leveraging previously collected fixed datasets. To elaborate, we deal with the state-of-the-art offline reinforcement learning algorithms, which have been proposed to mitigate the distributional shift. Lastly, we discuss the open problems and limitations of current offline reinforcement learning."
확정적 네트워크에서의 동적 처리순위를 활용한 강화학습 기반 스케줄러,2023,"['reinforcement learning', 'deep learning', 'deterministic networking', 'Q-learning', 'double deep Q-network', 'precedence']","스마트 인더스트리, 메타버스, 디지털 트윈, 군사용 어플리케이션 등에서 확정적 데이터 전달을 요구하고 있다.본 논문은 일반적으로 통용되는 플로우들의 클래스 혹은 우선순위와는 별도로, 네트워크 상황과 중요도에 따라 플로우 별로 동적으로 처리순위(precedence)를 할당하고, 이에 따라 스케줄링 알고리즘을 결정하는 강화학습 기반의스케줄링 프레임워크를 제안한다. 이를 실증하기 위해서 두 개의 처리순위 큐가 존재하는 환경을 상정하여, 강화학습 에이전트가 지정된 기준에 따라 플로우들의 처리순위를 지정하며 스케줄링 알고리즘을 선택하는 두 가지의행동(action)을 취한다. 네트워크 특성에 따라 다양한 기준으로 처리순위를 결정할 수 있다. 본 연구에서는 플로우가 요구하는 마감기한(deadline)을 처리순위 결정의 중요한 기준으로 사용하였다. 딥러닝 기반의 강화학습 모델인DDQN(Double Deep Q-Network)을 활용하여, 고정된 길이의 결정 주기마다 네트워크의 상태(state)를 관측하고행동을 선택함으로써 처리순위를 결정한다. 본 연구의 환경에 맞게 개발한 네트워크 시뮬레이터를 통해 DDQN 에이전트가 여러 휴리스틱 알고리즘과 비교하여 높은 성능을 보이는 것을 확인하였다.","Smart industry, metaverse, digital-twin, and military applications require deterministic data delivery in large scale networks. This paper proposes reinforcement learning-based scheduling that assigns dynamically different precedences to the flows, in addition to the flow's class or priority, and determines the scheduling algorithm according to the flow's precedence. In the proposed reinforcement learning-based scheduling algorithm with two precedence queues, the reinforcement learning agent takes two actions that assigns the precedence of flows according to a specified criterion and selects a scheduling algorithm. Depending on the purpose of the network, any factor with high importance could be a criterion for determining the precedence. In this study, the deadline required by the flow is designated as the major factor for precedence decision. By utilizing DDQN (Double Deep Q-Network), a deep learning-based reinforcement learning model, the precedence and the scheduling algorithm are determined by observing the state of the network and selecting an action at each decision period with a fixed length. In the network simulator developed for the study, it was confirmed that the DDQN agent showed better performance than various heuristic algorithms."
강화학습을 이용한 대전 슈팅 게임의 플랫폼 형태에 따른 레벨 디자인 영향 분석,2023,"['Multi-agent reinforcement learning', 'Level design', 'Platform design', 'Play experience']",,"As multi-agent reinforcement learning advance, it has been utilized for level design in game with multiple players and complex interactive environments. Despite the significant impact that the platform's design has on game level design, player-related metrics including behavior, skill level, and skill composition have been the primary focus of most reinforcement learning studies. In this paper, we study the impact of platform design on playing experience by utilizing multi-agent reinforcement learning. we use the Unity Engine to create various platform designs based on a 2vs2 shooting game and visual sensor visibility and structural complexity are taken into consideration for analysis. With Unity ML-Agents Toolkit, we construct a reinforcement learning environment based on the MA-POCA algorithm and the self-play method. Though the agent, we analyze changes in play experience with win rate, the number of episode, draw rate, and the Elo rating value. With the study, we figure out that visibility and complexity of platform design exhibit minimal impact on win rate balance in self-play method, but does influence the total number of episodes, draw rate, and the increase in Elo rating value."
커리큘럼을 이용한 투서클 기반 항공기 헤드온 공중 교전 강화학습 기법 연구,2023,,,"Recently, AI pilots using reinforcement learning are developing to a level that is more flexible than rule-based methods and can replace human pilots. In this paper, a curriculum was used to help head-on combat with reinforcement learning. It is not easy to learn head-on with a reinforcement learning method without a curriculum, but in this paper, through the two circle-based head-on air combat learning technique, ownship gradually increase the difficulty and become good at head-on combat. On the two-circle, the ATA angle between the ownship and target gradually increased and the AA angle gradually decreased while learning was conducted. By performing reinforcement learning with and w/o curriculum, it was engaged with the rule-based model. And as the win ratio of the curriculum based model increased to close to 100 %, it was confirmed that the performance was superior."
강화학습 기반 제어 알고리즘을 통한 시간 지연을 갖는 구조물의 진동 제어 연구,2023,"['강화학습', '심층 결정론적 정책 경사', '진동제어', 'Reinforcement Learning', 'Deep Deterministic Policy Gradient', 'Vibration Control']",,"The vibration control of a one-degree-of-freedom system was performed in this study using Deep Deterministic Policy Gradient (DDPG), a reinforcement learning method. A delayed control force compared to the target control force is applied to the system due to the dynamic characteristics of an actuator, such as a pneumatic spring. Reinforcement learning is a learning method that finds better behavior by learning by itself according to a reward function that is directly related to the learning goal without using a complex mathematical model for the system. Since the accelerometer is the most commonly used sensor in vibration measurement, we proposed a suitable learning excitation force and compensation function based on the acceleration data. The final learned policy was used to simulate the superior performance of the control force for various external forces. It was found from the numerical simulation that the vibration control based on the DDPG and reinforced learning is effective in suppressing vibrations."
Sim-to-Real 강화학습 기법을 활용한 Recovery 특성을 갖는 2단 도립진자 제어,2023,"['Reinforcement Learning', 'Double Inverted Pendulum', 'Sim-to-Real Learning', 'Recovery Property']",,"In recent years with the rapid advancement of artificial intelligence, there has been extensive research to address control problems, which was previously unsolvable with traditional control techniques, using reinforcement learning-based controllers. This paper discusses a challenge in controlling a double inverted pendulum system. With the commonly used 2-DOF control technique, once the swing-up control is performed and a strong disturbance is applied, the system becomes uncontrollable and fails to perform another swing-up. However, the reinforcement learning-based controller proposed in this paper overcomes this limitation using the Sim-to-Real learning technique. To ensure successful application of Sim-to-Real learning, this paper proposes a design method for the real-world system that minimizes the reality gap, a chronic issue with the Sim-to-Real technique. Utilizing these techniques, we introduce a characteristic termed 'recovery property' denoting the ability to recover from strong disturbances, a feature difficult to achieve with traditional control methods. We design a controller with this characteristic and validate its successful operation in a real-world system."
DQN 강화학습을 이용한 회전형 미로 탐색 행동 정책 학습,2023,"['Reinforcement learning', 'Deep Q-Network', 'Navigation policy', 'Rotational maze', '강화학습', '심층 Q-네크워크', '탐색 정책', '회전형 미로']",본 논문에서는 회전형 미로의 경로를 탐색하는 행동 정책을 학습하기 위해 강화학습을 적용하는 방법을 제안하였다. 본 논문에서는 격자 미로 환경에서 기존의 방법처럼 에이전트를미로 내에서 움직이는 대상이 아닌 미로 자체를 회전시키는 주체로 설정하여 DQN 강화학습을 이용해 미로를 최소 횟수로 회전시켜 공을 출발 지점에서 목표 지점까지 도달할 수 있도록 하는 학습 방법을 제안하였다. 이를 위하여 에이전트가 주행하는 미로 환경과 에이전트의 위치 관계를 나타내기 위해 상태의 표현을 정의하고 행동 가치 함수를 근사화하기 위한 Q-Network 구조를 제안하였으며 DQN 모델의 강화학습에 필요한 에이전트의 행동에 대한 보상 방법을 제안하였다. 본 논문에서는 Q-Network 구조와 보상 설계 방식에 따른 학습성능의 차이를 실험을 통해 비교하고 결과를 제시하였다.,"This paper proposes a method of applying reinforcement learning to learn abehavioral policy for navigating a rotating maze. In this paper, in a grid mazeenvironment, the agent is set as the subject of rotating the maze itself rather thanan object moving within the maze as in the existing method, and the ball is reachedfrom the starting point to the goal point by rotating the maze the minimum numberof times using DQN reinforcement learning. We proposed a learning method thatwould allow us to do so. To this end, we defined a state expression to representthe positional relationship between the maze environment in which the agent runsand the agent, proposed a Q-Network structure to approximate the action valuefunction, and compensated for the agent's behavior required for reinforcementlearning of the DQN model. A method was proposed. In this paper, the differencesin learning performance according to the Q-Network structure and compensationdesign method were compared through experiments and the results were presented."
네트워크 공격 시뮬레이터를 이용한 강화학습 기반 사이버 공격 예측 연구,2023,"['Reinforcement Learning', 'Network Attack Simulator', 'Cyber-attack', 'Security', 'Markov Decision Process', 'Deep-Q-Network']",,"As technology advances, the need for enhanced preparedness against cyber-attacks becomes an increasingly critical problem. Therefore, it is imperative to consider various circumstances and to prepare for cyber-attack strategic technology. This paper proposes a method to solve network security problems by applying reinforcement learning to cyber-security. In general, traditional static cyber-security methods have difficulty effectively responding to modern dynamic attack patterns. To address this, we implement cyber-attack scenarios such as 'Tiny Alpha' and 'Small Alpha’ and evaluate the performance of various reinforcement learning methods using Network Attack Simulator, which is a cyber-attack simulation environment based on the gymnasium (formerly Open AI gym) interface. In addition, we experimented with different RL algorithms such as value-based methods (Q-Learning, Deep-Q-Network, and Double Deep-Q-Network) and policy-based methods (Actor-Critic). As a result, we observed that value-based methods with discrete action spaces consistently outperformed policy-based methods with continuous action spaces, demonstrating a performance difference ranging from a minimum of 20.9% to a maximum of 53.2%. This result shows that the scheme not only suggests opportunities for enhancing cybersecurity strategies, but also indicates potential applications in cyber-security education and system validation across a large number of domains such as military, government, and corporate sectors."
근골격 모델과 참조 모션을 이용한 이족보행 강화학습,2023,"['musculoskeletal model', 'two-legged walking', 'metabolic energy', 'motion imitation', 'reinforcement learning', '근골격 모델', '이족보행', '메타볼릭 에너지', '모션 모방', '강화학습']","본 논문은 강화학습을 통해 이족보행에 대한 모션 캡처를 통해 참조 모션의 데이터들을 기반으로 근골격 캐릭터의시뮬레이션을 적은 비용으로 높은 품질의 결과를 얻을 방법을 소개한다. 우리는 참조 모션 데이터를 캐릭터 모델이 수행할수 있게끔 재설정을 한 후, 강화학습을 통해 해당 모션을 학습하도록 훈련시킨다. 참조 모션 모방과 근육에 대한 최소한의메타볼릭 에너지를 결합하여 원하는 방향으로 근골격 모델이 이족보행을 수행하게끔 학습한다. 이러한 방법으로 근골격모델은 기존의 수동으로 설계된 컨트롤러보다 적은 비용으로 학습할 수 있으며 높은 품질의 이족보행을 수행할 수 있게 된다.","In this paper, we introduce a method to obtain high-quality results at a low cost for simulating musculoskeletal characters based on data from the reference motion through motion capture on two-legged walking through reinforcement learning. We reset the motion data of the reference motion to allow the character model to perform, and then train the corresponding motion to be learned through reinforcement learning. We combine motion imitation of the reference model with minimal metabolic energy for the muscles to learn to allow the musculoskeletal model to perform two-legged walking in the desired direction. In this way, the musculoskeletal model can learn at a lower cost than conventional manually designed controllers and perform high-quality bipedal walking."
신뢰성 있는 지구 저궤도 위성 통신망 최적화를 위한 강화학습 기반 동적 라우팅 알고리즘,2023,"['심층 강화학습', '지구 제궤도 위성', '라우팅', 'Deep Reinforcement Learning', 'Low Earth Orbit (LEO)', 'Routing']",,"Recently, satellite communication has garnered significant attention as a novel industry capable of providing global internet access in conjunction with the next-generation communication system, 6G. Notably, low-Earth orbit satellites, operating at comparatively lower altitudes, offer an advantage in communication system configuration due to their closer proximity to Earth. The inherent characteristics of LEO satellites, such as their high orbital speed and deployment of numerous satellites in the same orbit, necessitate research into inter-satellite routing technology for enhanced communication performance. Consequently, this study presents a routing algorithm aimed at optimizing the LEO satellite communication network by employing reinforcement learning, a machine learning technique. By applying various reinforcement learning algorithms to satellite topologies that may arise in space environments, the superiority of the algorithm is assessed, and simultaneously, the feasibility of implementing inter-satellite routing in space is demonstrated."
강화학습 기반 3D 객체복원 데이터 획득 시뮬레이션 설계,2023,"['Unity3D', 'ML-Agents', 'Point Cloud', 'Reinforcement Learning', 'Bot', 'Autonomous Driving', '유니티', 'ML-Agents', '포인트 클라우드', '강화학습', '봇', '자율주행']","물체나 공간을 디지털화하는 기술인 3D 복원은 주로 포인트 클라우드 데이터를 활용한다. 본 논문은 강화학습을활용하여 주어진 환경에서 포인트 클라우드의 획득을 목표로 한다. 이를 위해 시뮬레이션 환경은 유니티를 이용하여구성하고, 강화학습은 유니티 패키지인 ML-Agents를 활용한다. 포인트 클라우드 획득 과정은 먼저 목표를 설정하고, 목표 주변을 순회할 수 있는 경로를 계산한다. 순회 경로는 일정 비율로 분할하여 각 스텝마다 보상한다. 이때 에이전트의 경로 이탈을 방지하기 위해 보상을 증가시킨다. 에이전트가 순회하는 동안 목표를 응시할 때마다 보상을 부여하여각 순회 스텝에서 포인트 클라우드의 획득 시점을 학습하도록 한다. 실험결과, 순회 경로가 가변적이지만 상대적으로정확한 포인트 클라우드를 획득할 수 있었다.","The technology of 3D reconstruction, primarily relying on point cloud data, is essential for digitizing objects or spaces. This paper aims to utilize reinforcement learning to achieve the acquisition of point clouds in a given environment. To accomplish this, a simulation environment is constructed using Unity, and reinforcement learning is implemented using the Unity package known as ML-Agents.The process of point cloud acquisition involves initially setting a goal and calculating a traversable path around the goal. The traversal path is segmented at regular intervals, with rewards assigned at each step. To prevent the agent from deviating from the path, rewards are increased. Additionally, rewards are granted each time the agent fixates on the goal during traversal, facilitating the learning of optimal points for point cloud acquisition at each traversal step. Experimental results demonstrate that despite the variability in traversal paths, the approach enables the acquisition of relatively accurate point clouds."
실시간 계층적 심층강화학습 기반 드론 궤적 생성 알고리즘 파라미터 제어,2023,"['Drone Autonomous Flight', 'Drone Trajectory Generation Algorithm', 'Hierarchical Deep Reinforcement Learning']",,"With the increasing use of drones, research on drone trajectory generation algorithms has gained significant momentum. These algorithms aim to generate real-time trajectories while considering obstacle avoidance. Recent advancements have shown promising results in generating safe and efficient trajectories in complex dynamic environments, such as forests, as well as controlling multiple drones simultaneously. However, most existing drone trajectory generation algorithms impose limitations on the maximum speed and acceleration parameters to ensure drone stability. These restrictions on speed-related parameters hinder the efficiency and practicality of drones. In this paper, we propose a novel approach called “Hierarchical Deep Reinforcement Learning-Based Active Parameter Control Algorithm” that addresses this limitation. This algorithm dynamically sets the maximum speed and acceleration parameters of a drone based on the real-time environment using a hierarchical reinforcement learning framework. The upper layer agent in the hierarchy is responsible for adjusting the maximum speed and acceleration parameters considering the current environmental conditions. The lower layer agent then utilizes these parameters to generate a real-time trajectory. Notably, this approach can be applied to all drone trajectory generation algorithms that involve setting maximum speed and maximum acceleration. Through extensive simulations, we demonstrate that applying the proposed algorithm to drone trajectory generation algorithms results in superior performance in terms of speed, path length, and path smoothness. These improvements showcase the potential of our approach in enhancing the efficiency and overall capabilities of drones operating in complex and dynamic environments."
쿠버네티스 환경에서의  강화학습 기반 자원 고갈 탐지 및 대응 기술에 관한 연구,2023,,"쿠버네티스는 컨테이너 통합 관리를 위한 대표적인 오픈소스 기반 소프트웨어로, 컨테이너에 할당된 자원을 모니터링하고 관리하는 핵심적인 역할을 한다. 컨테이너 환경이 보편화됨에 따라 컨테이너를 대상으로 한 보안 위협이 지속적으로 증가하고 있으며, 대표적인 공격으로는 자원 고갈 공격이 있다. 이는 악성 크립토마이닝 소프트웨어를 컨테이너 형태로 배포하여 자원을 탈취함으로써, 자원을 공유하는 호스트 및 다른 컨테이너의 동작에 영향을 끼친다. 선행 연구는 자원 고갈 공격의 탐지에 초점이 맞춰져 있어 공격 발생 시 대응하는 기술은 부족한 실정이다. 본 논문은 쿠버네티스 환경에서 구동되는 컨테이너를 대상으로 한 자원 고갈 공격 및 악성 컨테이너를 탐지하고 대응하기 위한 강화학습 기반 동적 자원 관리 프레임워크를 제안한다. 이를 위해, 자원 고갈 공격 대응 관점에서의 강화학습 적용을 위한 환경의 상태, 행동, 보상을 정의하였다. 제안한 방법론을 통해, 컨테이너 환경에서의 자원 고갈 공격에 강인한 환경을 구축하는 데 기여할 것으로 기대한다.","Kubernetes is a representative open-source software for container orchestration, playing a crucial role in monitoring and managing resources allocated to containers. As container environments become prevalent, security threats targeting containers continue to rise, with resource exhaustion attacks being a prominent example. These attacks involve distributing malicious crypto-mining software in containerized form to hijack computing resources, thereby affecting the operation of the host and other containers that share resources. Previous research has focused on detecting resource depletion attacks, so technology to respond when attacks occur is lacking. This paper proposes a reinforcement learning-based dynamic resource management framework for detecting and responding to resource exhaustion attacks and malicious containers running in Kubernetes environments. To achieve this, we define the environment's state, actions, and rewards from the perspective of responding to resource exhaustion attacks using reinforcement learning. It is expected that the proposed methodology will contribute to establishing a robust defense against resource exhaustion attacks in container environments"
가상발전소 최적 운영을 위한 강화학습 기반 에너지 저장장치 제어,2023,"['Deep Q-Network', 'Markov Decision Process', 'Energy Storage System', 'Reinforcement Learning', 'Virtual Power Plant']",,"In this paper, we design a framework of the energy storage system (ESS) controller in virtual power plant (VPP) that maximize the profit. We consider the VPP that includes photovoltaics, wind turbines and demand along with ESSs and describe the environment based on Markov decision process (MDP). To find the best policy for ESS charging and discharging control, we implement a deep Q-network (DQN) method that trains a neural network which estimates Q-function values for each possible discrete actions. In the numerical test utilizing real-world data of Namgwangju Station, ERCOT and US government, we train the DQN and demonstrate that the proposed algorithm converges. Through the test with the trained policy, we showcase that the policy functions effectively in the scenario with uncertainty from renewable generations and load, as it responds adaptively to electricity prices."
에너지 효율 증대를 위한 강화학습 기반 태양광 패널 장착형 이동 기지국 경로 최적화,2023,"['UAV 기지국', '무선통신', '강화학습', '에너지 수확', 'UAV base station', 'wireless communication', 'reinforcement learning', 'energy harvesting']",5G와 B5G 무선 통신 시스템에서는 사용자의 요구사항을 만족하기 위해 mm-Wave와 같은 높은 주파수를 갖는 대역을 사용한다. 이는 기존의 주파수 대역보다 낮은 회절과 투과율 그리고 강한 직진성으로 인한 제약들이 존재한다. 이 제약을 해결하기 위해 Unmanned Aerial Vehicle(UAV)의 지원을 받는 셀룰러 통신 패러다임은 기존 지상 기지국 보다 통신 서비스를 보다 유연하게 해준다. 하지만 UAV는 제한된 배터리 용량을 가지고 있어서 통신 서비스의 수명에 영향을 준다. 이를 해결하기 위해 본 논문에서는 태양광 패널이 장착된 UAV를 고려한다. UAV의 태양광으로 인한 에너지 생성과 유저 평균 Data rate를 최대화를 위한 UAV의 움직임은 많은 에너지를 소모한다. 에너지 생성 및 유저 평균 Data rate 최대화와 에너지 소모는 트레이드오프 관계를 갖는다. 이에 본 연구에서는 강화 학습 알고리즘 ‘Proximal Policy Optimization(PPO)’을 사용하여 학습한 에이전트를 이용하여 위 트레이드오프 관계를 최적화하는 UAV의 경로를 찾는 시스템을 제안하고 에너지 소모를 고려하지 않은 것과 본 논문에서 제안한 시스템을 비교하였고 에너지 소모까지 고려한 시스템이 더 UAV의 에너지 제약에서 뛰어난 성능을 보이는 것을 확인되었다.,
5G 특화망내 심층강화학습 기반 네트워크 캐싱,2023,"['Local 5G', 'Private 5G', 'Deep reinforcement learning', 'Network cache', '5G 특화망', '심층강화학습', '네트워크 캐싱']",,"Although the demands for local 5G network has increase along with the 4th industrial revolution, current network operation techniques and systems cannot efficiently manage local 5G networks, and suitable system for those networks are necessary. Therefore, we propose a deep reinforcement learning based caching system to reduce backhaul overload and increase user QoS in local 5G for efficient network resource utilization in eMBB targeted local 5G networks. The proposed system considers replacement policies in the stage of cache allocation, and its performance is compared with existing caching strategies combined with cache allocation algorithm and cache replacement policy. The simulation result shows the proposed system has 20% higher performance in both cache hit ratio and average network latency than conventional systems."
실시간 차량 밀도에 대응하는 심층강화학습기반 C-V2X 분산혼잡제어,2023,"['Cellular-V2X', 'Distributed Congestion Control', 'Deep Reinforcement Learning', 'Quality of Service', 'Microscopic Simulator']",,"Distributed congestion control (DCC) is a technology that mitigates channel congestion and improves communicationperformance in high-density vehicular networks. Traditional DCC techniques operate to reduce channel congestionwithout considering quality of service (QoS) requirements. Such design of DCC algorithms can lead to excessiveDCC actions, potentially degrading other aspects of QoS. To address this issue, we propose a deep reinforcementlearning-based QoS-adaptive DCC algorithm. The simulation was conducted using a quasi-real environment simulator,generating dynamic vehicular densities for evaluation. The simulation results indicate that our proposed DCCalgorithm achieves results closer to the targeted QoS compared to existing DCC algorithms."
LW-RCP를 이용한 실물 시스템에 대한 강화학습 기반의 제어기 개발 환경,2023,"['LW-RCP', 'reinforcement learning', 'development environment', 'single inverted pendulum']",,"In recent years, reinforcement learning (RL)-based controller design methods have emerged as a powerful alternatives to traditional methods, providing a novel paradigm that overcomes limitations associated with the need for accurate model information. In this paper, we propose a development environment for RL-based controllers in real-world systems by integrating MATLAB/Simulink, Python, and the LW-RCP (Light-weight Rapid Control Prototyping) system developed by the authors’ laboratory. The proposed development environment utilizes LW-RCP’s library block in a Simulink-based RL controller model, enabling real-time experiments on real-world systems, and stores state information data in MATLAB’s workspace. Python obtains this data through the Python API after each episode and uses it to iteratively enhance the RL agent’s policy by using RL algorithms. Updated parameter values for the agent’s policy neural network are then sent back to MATLAB's workspace, enabling convenient updates to the deep neural network-based policy controller block in Simulink. This development environment greatly reduces the time and trial and error in configuring real-time system controllers by providing LW-RCP with all necessary functions. Moreover, the efficient data acquisition and integration between MATLAB and Python workspaces facilitate the learning process and reflection of results in Simulink-based controllers. We demonstrate the effectiveness and convenience of the proposed environment through its successful application to the swing-up control problem of a single inverted pendulum."
강화학습을 활용한 취약 호스트 식별 방법,2023,"['Software-Defined Networking(SDN)', 'Emulation', 'Reinforcement Learning', 'Deep Q-Network(DQN)']",사이버 공격이 점차 고도화되고 복잡해짐에 따라 방어 기법들 또한 다양하고 유연한 형태로 변화하고 있다. 최근 발생하고 있는 대부분의 공격은 랜섬웨어 또는 APT과 같은 복합적이고 예측 불가능한 양상을 보인다. 기존 EDR과 같은 정적인 룰 기반 솔루션으로는 이러한 공격들에 효과적으로 대응할 수 없다. 특히 과도한 대응은 가용성을 감소시켜 업무를 어렵게 만드는 부작용이 발생한다. 사이버 공격에 효과적으로 대응하기 위해서는 공격이 일어날 것으로 추정되는 적절한 호스트를 선별하여 대응을 수행하는 것이 필요하다. 본 논문에서는 지능형 대응 기술에 대해서 소개하고 이러한 대응 기법 개발을 위한 SDN 기반의 에뮬레이션 테스트 베드 환경과 사이버 공격상황에서 딥러닝 기반의 강화학습을 활용한 취약 호스트 식별 방법을 제안한다.,"As cyber attacks become more sophisticated and complex, defense techniques are also changing in various and flexible forms. Most recent attacks show complex and unpredictable patterns such as Ransomware and APT. In particular, excessive response to cyberattacks reduces the availability of the environment, resulting in side effects that make work difficult. In order to effectively respond to cyberattacks, it is necessary to select an appropriate host for which an attack is tracked to occur and perform a response. This paper introduces intelligent response technology and proposes a method of identifying vulnerable hosts using deep learning-based reinforcement learning in SDN emulation testbed environments and cyberattack situations to develop these response techniques."
강화학습 기반 다차원 배낭 문제 해결에 대한 일반화 성능 향상 접근법,2023,"['심층학습', '강화학습', '조합 최적화 문제', '배낭 문제', '어텐션 메커니즘', 'Deep Learning', 'Reinforcement Learning', 'Combinatorial Optimization Problem', 'Knapsack Problem', 'Attention Mechanism']","조합 최적화 문제 중 하나인 배낭 문제는 NP-hard 문제로서 다항 시간 내에 최적해를 구하는 방법이 알려지지않은 문제이다. 이러한 배낭 문제에 대한 해결책은 물류 및 창고 관리, 제조 및 생산 계획, 자원 할당 및 스케줄링 등 여러 분야에서 활용될 수 있다. 최근 배낭 문제를 강화학습을 통해 해결하려는 시도가 있다. 하지만 여러연구가 배낭 문제의 물건 개수에 종속적인 방법들을 제안하여 주어진 물건의 개수가 바뀔 때마다 개별적으로 모델을 학습해야 한다는 단점을 가졌다. 본 논문은 배낭 문제가 가지는 규모 불변 특성을 활용하여 물건의 개수와무관한 마르코프 결정 과정과 신경망 구조를 제안한다. 결과적으로 배낭 문제를 확장한 문제인 다차원 배낭 문제를 물건의 개수와 관련 없이 학습 및 사용 가능한 방법을 제안하고 실험을 통해 성능을 테스트한다. 추가적으로제안하는 방법의 강점인 일반화 성능을 테스트하여 해당 방법이 확장성, 재사용성, 일반성을 가지는 것을 보인다.",
밀리미터파 통합 엑세스 백홀 네트워크에서 심층 강화학습 기반의 대역 할당 기법,2023,"['mmWave', 'Integrated Access and Backhaul', 'Reinforcement Learning', 'Double Deep Q-Network', 'Spectrum Allocation', '밀리미터파', '통합 엑세스 백홀', '강화학습', '이중 심층 Q-망', '대역 할당']",,"As mmWave has been utilized on fifth-generation mobile communication networks for a high data rate, network densification is in progress. Under the circumstances, interest in an integrated access and backhaul network is increasing. The integrated access and backhaul network replaces a traditional wired backhaul link with a wireless backhaul link reducing financial burden. However, inter-link interference gets harsher as access and backhaul link shares the same bandwidth. Consequently, spectrum allocation optimization is required for network efficiency. In this paper, we formulate a problem maximizing network capacity through backhaul spectrum allocation when the access spectrum is allocated uniformly to users. Then, propose deep reinforcement learning-based backhaul spectrum strategy which can solve the problem."
항만 물류 환경에서 다중 에이전트 강화학습 기반 최적 배차 모델링 방법,2023,"['port logistics', 'dispatch', 'vehicle routing problem', 'reinforcement learning', 'multi-agent system', 'double deep q network']",,"In a port logistics environment, dispatchers carry out dispatching tasks that match container cargo registered by shippers with freight forwarders. However, there is a problem in that it is difficult for a person to allocate vehicles while considering all of the various complex factors in the port logistics environment. In order to solve this problem, a vehicle routing problem (VRP) that determines the driver, route, and order to be input has been studied, and various types of problems according to various constraints have been studied. In this study, among various types of VRP, a study was conducted to minimize the tolerance distance, which is the distance that a transport driver moves without loading a container, considering the location of the container driver and the location of loading or unloading the container. In addition, in order to facilitate the addition of constraints for the expansion of this study, we propose a reinforcement learning-based optimal allocation modeling method and present the analysis results."
심층 강화학습 기반 조세 및 경제 활동 에이전트 정책 최적화 시뮬레이션 환경 분석 및 실험,2023,"['Tax Policy Optimization', 'Economic Simulation Analaysis', 'Reinforcement', '조세 정책 최적화', '경제 시뮬레이션 분석', '강화학습']","4차 산업 혁명으로 AI가 사회 전반에 걸쳐 상용화되고 꾸준히 발전하고 있지만, 경제 분야는 여전히 데이터 부족, 다양한 환경, 변수 등으로 AI 적용이 어렵다. 실제 사회 경제적 문제를 해결하기 위해선 경제 주체 간 다양한 환경과상호작용 요인들을 확인하며 경제 활동 및 정책 수립 과정을 설계하고 테스트해야 하지만, 경제 관련 데이터가 부족하고, 실제 정책을 실험하기 위한 환경 구성이 어렵다. 본 논문에서는 Salesforce 팀의 AI 기반 경제 시뮬레이션 환경인 AI Economist를 활용하여 심층강화학습 기반 조세 및 경제 활동 에이전트 정책 최적화 실험 및 분석을 진행하였다.",
3차원 셀룰러 네트워크기법에서 분산 심층강화학습 기반 에너지 효율 최대화,2023,"['무인항공기', '심층 큐-네트워크', 'UAV 제어', '공중-지상 채널', '에너지 효율 극대화', 'UAV', 'Deep Q-Network', 'UAV Control', 'Air-to-Ground Channel', 'Energy Efficiency Maximization']","본 논문에서는 이동성을 지닌 지상 사용자에게 안정적인 공중-지상 통신 커버리지를 제공하기 위한 다중 unmanned aerial vehicle-base station(UBS) 기반 3차원 셀룰러 네트워크를 고려한다. 특히, UBS 네트워크의 매우 짧은 네트워크라이프타임 문제를 해결하기 위해서, 네트워크 전체 에너지 효율을 극대화할 수 있도록 UBS의 이동성 및 전송전력을제어하고자 한다. 하지만, 지상 사용자가 움직이는 동적 환경 문제를 기존 반복 및 최적화 기법으로 풀어내기에 그어려움이 존재한다. 따라서, 본 논문에서는 분산 deep Q-network(DQN) 기반 UBS 제어 방안을 제안한다. 그리고 분산학습의 강점을 보이기 위해, 두 가지 중앙집중형 학습 방안을 소개하고, 이 기법들과 다중-에이전트 분산 큐-러닝(multi-agent distributed Q-learning, MD-QL) 그리고 탐욕적 행동(greedy action, GA)을 비교방안으로 고려한다. 결과적으로, 제안 방안이 UBS의 수와 사용자 이동속도에 따라 기존 알고리즘보다 그 성능이 강건하고 우수함을 보인다.",
의료능력을 고려한 대량전상자 환자분류 강화학습 모델,2023,"['대량전상자', '환자분류', '의료능력', '인공지능', '강화학습', 'Mass casualty', 'Triage', 'Medical capability', 'Artificial intelligence', 'Reinforcement learning']","연구목적: 대량전상자 발생시 신속하고 정확한 환자분류가 진행되어야 최대한 많은 환자를 회복시켜 전장으로 돌려보낼 수 있다. 그러나 복잡한 전투현장에서 적은 의료인력으로 대량전상자의 환자분류를 시행하기란 임무는 과다하고 환경은 불확실하다. 따라서, 전투현장에서 의료인력을 보조하고 대체할 수 있는 인공지능 모델에 대해 논의하고자 한다. 연구방법: 인공지능의 한 분야인 강화학습을 활용하여 환자분류 모델을 제시한다. 모델의 학습은 무작위로 설정된 환자의 상태와 병원시설의 의료능력을 고려하여 최대 다수의 환자가 치료 받을 수 있는 정책을 찾도록 진행된다. 연구결과: 강화학습 모델이 정상적으로 학습되었음은 누적 보상값 등을 통하여 확인하였고, 학습된 모델이 정확하게 환자를 분류하는 것은 생존자 수를 통해 확인하였다. 또한, 규칙기반 모델과 비교하여 성능을 검증하였으며, 강화학습 모델이 규칙기반 모델에 비해 10%만큼 더 많은 환자를 생존시킬 수 있었다. 결론: 강화학습을 이용한 환자분류 모델은 의료인력의 대량전상자 환자분류 의사결정을 보조하고 대체하는 대안으로 활용이 가능하다.","Purpose: In the event of mass casualties, triage must be done promptly and accurately so that as many patients as possible can be recovered and returned to the battlefield. However, medical personnel have received many tasks with less manpower, and the battlefield for classifying patients is too complex and uncertain. Therefore, we studied an artificial intelligence model that can assist and replace medical personnel on the battlefield. Method: The triage model is presented using reinforcement learning, a field of artificial intelligence. The learning of the model is conducted to find a policy that allows as many patients as possible to be treated, taking into account the condition of randomly set patients and the medical capability of the military hospital. Result: Whether the reinforcement learning model progressed well was confirmed through statistical graphs such as cumulative reward values. In addition, it was confirmed through the number of survivors whether the triage of the learned model was accurate. As a result of comparing the performance with the rule-based model, the reinforcement learning model was able to rescue 10% more patients than the rule-based model. Conclusion: Through this study, it was found that the triage model using reinforcement learning can be used as an alternative to assisting and replacing triage decision-making of medical personnel in the case of mass casualties."
자율무기체계 지능화를 위한 시뮬레이션 기반 강화학습,2023,"['자율무기체계', '정찰드론', '시뮬레이션 기반 학습', '강화학습', '지도학습', 'Autonomous Weapon System(AWS)', 'Reconnaissance Drone', 'Simulation Based Learning', 'Reinforcement Learning', 'Supervised Learning']","자율무기체계(AWS)의 막강한 군사적 파급력에도 불구하고 체계의 지능화와 관련된 실증연구는 부족한 것이 현실이다. 본 연구는 공학적인 관점에서 드론의 정찰 임무를 지능화하는데 필요한 개념에 대해 논의하고, 이를 구현하는데 필요한 기술들을 구체적으로 제시하고 실증한다. 이를 위해, 시뮬레이션 기반 학습의 프레임워크, 시뮬레이션 환경에서 지도학습과 강화학습의 연계, 항공 이미지 데이터를 이용한 비전기반 학습 등을 논의한다. 본 연구를 통해 자율무기체계의 지능화를 위한 시뮬레이션 기반 학습의 중요성과 가능성을 확인하였다. 본 연구는 AI 과학기술 강군 건설을 위한 기초연구로서 가치와 기여점이 있다.","Despite its strong military impact, there is a lack of empirical research related to the intelligence of Autonomous Weapon Systems (AWS). This study discusses the necessary concepts for intelligent reconnaissance missions of drones from an engineering perspective and provides concrete proposals for the required technologies to implement them. Specifically, the study explores Simulation-Based Learning frameworks, the integration of Supervised Learning and Reinforcement Learning in simulation environments, and Vision-Based Learning using aerial image data. Through this study, the importance and potential of Simulation-Based Learning for the intelligence behavior of AWS have been confirmed. This research holds value and contributes as foundational research for advanced AI technology in the military."
강화학습을 사용한 영상회의 시뮬레이션 환경 구현 및 분석,2023,"['Deep Reinforcement Learning', 'Video Conferencing', 'Selective Forwarding', 'Simulation']","강화학습은 다양한 현실 세계의 문제를 해결하기 위해 사용된다. 하지만 시간 혹은 자원 이슈, 실제 시스템에 줄 수 있는 영향 때문에 시뮬레이션 환경에서 먼저 테스트를 수행한 후 적용하는 것이 필요하다. 만약 시뮬레이션 환경이 실제 환경과 유사하게 구현된다면 하이퍼파라미터 튜닝, 최적화와 같은 필수적인 과정들을 쉽게 수행할 수 있다는 장점이 있다. 따라서 본 논문에서는 영상회의에서 강화학습을 사용할 때 빠른 최적화와 튜닝을 위한 영상회의 시뮬레이션 환경을 구현한다. 이를 위해 영상회의 트래픽을 모방하기 위한 트래픽 예측기를 개발하고, 이를 영상회의 시뮬레이션에 사용하여 실제 영상회의와 통신하지 않아도 네트워크 데이터를 얻을 수 있도록 한다. 구현한 시뮬레이션 환경은 처리량, 지연 시간, 손실률, 지터, 훈련 속도 면에서 실제 환경과 비교하며, 이에 대한 분석 및 한계점, 향후 연구를 제시한다.","Reinforcement learning is used to solve various real world problems. However, it is often essential to test and apply in a simulation environment first because of time or resource issues or the impact it may have on the actual system. If the simulation environment is implemented similarly to the real environment, it has the advantage of being able to easily perform necessary processes such as hyperparameter tuning and optimization. Therefore, in this paper, we implement a video conferencing simulation environment for fast optimization and tuning when reinforcement learning is used in video conferencing. First, we develop a traffic predictor to imitate video conferencing traffic, and use this to develop a video conferencing simulation environment that does not communicate with actual video conferencing. We also evaluated and analyzed how much performance the simulation environment shows compared to the real environment in terms of throughput, delay, loss rate, jitter, and training speed."
강화학습 상태 텐서 차원에 따른 학습 효과도,2023,"['Feature extraction', 'Reinforcement learning', 'Tactics simulation']",,"In reinforcement learning, an agent takes actions in an environment, which is interpreted into a reward and a “representation of the state”. It is well known that the performance of the reinforcement learning is dependent on the “data model representing the state” of a given environment. This paper proposes a data model representing the state which is suitable for a FPS (First Person Shooting) game, a military tactics simulator that changes state extremely and needs decision making quickly. The proposed data model consists of matrix (multi-dimensional tensors) for spatial features and vectors for non-spatial features. To prove the usefulness of the proposed data model, this paper shows experimental results for a FPS game."
다중 에이전트 강화학습을 이용한 RC보 최적설계 기술개발,2023,"['Multi-Agent reinforcement learning', 'Deep Q-Network', 'Optimal structural design', 'Reinforced concrete beam']",,"Reinforcement learning (RL) is widely applied to various engineering fields. Especially, RL has shown successful performance for control problems, such as vehicles, robotics, and active structural control system. However, little research on application of RL to optimal structural design has conducted to date. In this study, the possibility of application of RL to structural design of reinforced concrete (RC) beam was investigated. The example of RC beam structural design problem introduced in previous study was used for comparative study. Deep q-network (DQN) is a famous RL algorithm presenting good performance in the discrete action space and thus it was used in this study. The action of DQN agent is required to represent design variables of RC beam. However, the number of design variables of RC beam is too many to represent by the action of conventional DQN. To solve this problem, multi-agent DQN was used in this study. For more effective reinforcement learning process, DDQN (Double Q-Learning) that is an advanced version of a conventional DQN was employed. The multi-agent of DDQN was trained for optimal structural design of RC beam to satisfy American Concrete Institute (318) without any hand-labeled dataset. Five agents of DDQN provides actions for beam with, beam depth, main rebar size, number of main rebar, and shear stirrup size, respectively. Five agents of DDQN were trained for 10,000 episodes and the performance of the multi-agent of DDQN was evaluated with 100 test design cases. This study shows that the multi-agent DDQN algorithm can provide successfully structural design results of RC beam."
버퍼 활용 무작위 빈 패킹 문제를 위한 강화학습-휴리스틱 결합 모델,2023,"['버퍼 활용 빈 패킹', '강화학습', '휴리스틱', '가치 측정', '불확실성 제어', 'Buffer-utilized bin packing', 'Reinforcement learning', 'Heuristics', 'Value estimation', 'Uncertainty handling']",,"In this paper, we propose a reinforcement learning algorithm combined with heuristics to solve the bin packing problem (BPP) where the objects are randomly given and once placed objects cannot be moved, but the small load buffer can be utilized. This setting resembles the loading problem which has not been resolved despite of logistics automation. Since heuristics can be rapidly optimized by human intuition, and reinforcement learning is highly responsive to the environment, the combined method is highly available in the real-world industries. When the model learned through reinforcement learning determines the optimal object among the new object and objects in the buffer, then defined heuristics find optimal position and orientation for placement of the selected object. Through experiments, we verified the effectiveness by comparing the loading efficiency between the heuristic-only system and the combined system presented in this study."
강화학습 기반 HVAC 제어 및 시뮬레이션 기법,2023,"['Reinforcement learning', 'Machine learning', 'HVAC', 'Air conditioner', 'DQN']",,"HVAC(Heating, Ventilation, and Air Conditioning: 공기조화기기) 시스템은 전력 소모가 크기에, 최소의 전력으로 지정된 실내온도를 유지하도록 운전하는 것이 중요한 문제이다. 최근 HVAC 전력 최소화 문제에 대한 기계학습 기법들의 응용 시도가 증가하고 있으나 기계학습 기반 전력 HVAC 운전 기법의 개발을 위해 사용할 수 있는 시뮬레이션 환경은 매우 찾기가 어려운 실정이다. 본 논문에서는 MATLAB/Simulink 기반의 시뮬레이션 환경을 소개 및 공개하고 이를 바탕으로 개발된 강화학습 기반의 에어컨 자동 운전 알고리즘의 성능을 평가한다. 시뮬레이션 및 학습 관련 코드는 (https://github.com/intplatlab/hvac_sim.git)에서 다운로드 받을 수 있다."
멀티 에이전트 강화학습에서의 게이트 기반 메시지 교환,2023,"['multi-agent reinforcement learning', 'communication', 'representation learning']",,"An environment is a complex space in which numerous agents and objects interact. In this environment, rational agents act to maximize utility, and their actions are learned through reinforcement learning algorithms using deep neural networks. Since most environments are non-stationary, a single agent cannot solely achieve maximum utility through its observations and inferences using a network. However, when multiple agents can communicate with each other, a single agent can access richer information about the state of the environment simply by receiving messages from other agents. Nonetheless, the inferred information from other agents is generated by a neural network, which can be vulnerable or incorporate the personal perspective of the agents processing the information. For example, even when presented with a single observation, two agents can encode significantly different messages due to variations in their parameter modules. Therefore, it is crucial to consider the subjectivity of messages in multi-agent reinforcement learning (MARL). Building on the assumption that the encoded information is inherently subjective and reflects the agent that encodes it, we address the challenge of objective and subjective information in MARL. One limitation is that the information processed by a neural network is often challenging to interpret. In the initial phases of addressing this subjectivity concern, we focus on a relatively minor challenge: determining whether subjective information surpasses objective information in utility. Consequently, we compare the usefulness of messages exchanged between agents in two forms: raw observation and the output of a neural network."
3D-Pinball 게임 기반 강화학습 알고리즘 및 모델 성능 분석,2023,"['강화학습', '인공지능', '딥러닝', '게임', '전처리', 'Reinforcement Learning', 'Artificial Intelligence', 'Deep Learning', '3D-Pinball', 'Preprocessing']",,"Game research applying reinforcement learning has demonstrated that AI can outperform humans. In this study, we extend this approach to '3D-Pinball', a game similar to 'Video Pinball' but with greater complexity. Three reinforcement learning algorithms - DQN, Double DQN, and Dueling Double DQN - are applied to both CNN-based models using visual data and MLP-based models extracting appropriate features from high-dimensional data. These are then evaluated in '3D-Pinball'. Restrictions on gameplay time and lives were implemented for efficient experimentation. Results showed that the Dueling Double DQN algorithm applied to the MLP-based model yielded the highest performance increase and game scores, underscoring the superior performance of simpler models in restricted environments. Consequently, it appears that model development considering constraints is required for superior performance in learning and game environments."
향상된 유닛 생산과 게임 플레이 경험을 위한 스타크래프트 II 강화학습 AI,2023,"['Game artificial intelligence', 'Reinforcement learning', 'StarCraft II', 'Flexible strategy']",,"The built-in AI in StarCraft II follows a predefined pattern of behavior patterns. This makes it easy for users to understand the AI's strategy without spending a lot of time, posing a challenge in maintaining user interest. To solve this problem, reinforcement learning AI has been developed for StarCraft II. But since theses studies focus on the win rate to train the agent, it provides monotonous strategies and misses the fun of the game. In this paper, we propose a player-like AI to improve the fun of the game by producing various units and adaptive strategies. To achieve this, we use reinforcement learning to train the agent the official counter list of StarCraft II and reward it based on the information of the opponent's scouting to make the agent change its strategy flexibly. The training is based on the ""Zerg"" race on the Simple64 map, and the opponent is the ""Protoss"" race. Based on the trained data, we evaluated the diversity of unit production, strategic unit production, etc. In addition, we had users play with the AI of existing work and the proposed AI, respectively. We then evaluated the fun and difficulty of the AI and its similarity to the player using a questionnaire. As a result, users rated the proposed AI higher than the fixed-strategy AI fin terms of fun, difficulty, and similarity."
딥러닝과 강화학습의 연구 동향 분석,2023,"['KeyBERT', 'topic extraction', 'trend analysis', 'deep learning', 'natural language processing', 'KeyBERT', '토픽 추출', '동향 분석', '딥러닝', '자연어 처리']",,"In this paper, we apply KeyBERT(Keyword extraction with Bidirectional Encoder Representations of Transformers) algorithm-driven topic extraction and topic frequency analysis to deep learning and reinforcement learning research to discover the rapidly changing trends in them. First, we crawled abstracts of research papers on deep learning and reinforcement learning, and temporally divided them into two groups.After pre-processing the crawled data, we extracted topics using KeyBERT algorithm, and then analyzed the extracted topics in terms of topic occurrence frequency. This analysis reveals that there are distinct trends in research work of all analyzed algorithms and applications, and we can clearly tell which topics are gaining more interest. The analysis also proves the effectiveness of the utilized topic extraction and topic frequency analysis in research trend analysis, and this trend analysis scheme is expected to be used for research trend analysis in other research fields. In addition, the analysis can provide insight into how deep learning will evolve in the near future, and provide guidance for select research topics and methodologies by informing researchers of research topics and methodologies which are recently attracting attention."
멀티 에이전트 강화학습을 활용한 유무인 협업 임무 수행 연구,2023,"['MUM-T', 'MA-POCA', 'Unity ML-Agents', '유무인 복합 운용 체계', 'MA-POCA', 'Unity ML-Agents']",무인기가 수행 가능한 임무의 범위가 확대되어 유무인 복합운용 MUM-T (Manned Unmanned Teaming)라는 개념이 대두되었다. 유무인 복합운용은 유인기가 다수 무인기의 운용 및 통제를 담당하기 때문에 조종사의 임무 부하도 감소를 위한 다수 무인기 자동 경로 생성 기법 연구가 필수적이다. 본 논문은 다수 무인기 자동 경로 생성 기법으로 멀티 에이전트 강화 학습 기법 적용을 제안한다. 멀티 에이전트 강화학습 기법은 기존의 싱글에이전트 강화학습 기법과 비교하여 유무인 복합운용 환경과 같이 공동의 목표를 가지는 다수의 에이전트가 존재하는 환경에 적용하기 유리하다. 따라서 본 논문은 Unity ML-Agents에서 제공하는 MA-POCA 알고리즘을 활용하여 유무인 복합운용 임무를 수행연구를 진행하였으며 시뮬레이션을 통해 임무 성공확률을 분석하였다.,"The scope of missions that drones can perform has expanded, and the concept of MUM-T(Manned Unmanned Teaning) has emerged. Since the manned aircraft is responsible for the operation and control of many drones, it I essential to study the automatic path generation technique for multiple drones to reduce the pilot’s mission load. This paper proposes the application of multi-agent reinforcement learning techniques as multiple drone automatic path generation techniques. Compared to single agent reinforcement learning, multi-agent reinforcement learning is advantageous to apply to environments where multiple agents with common goals, such as MUM-T environments. So in this paper, we conducted a study on the performance of a complex operation mission with a MA-POCA algorithm provided by Unity ML-Agent, and analyzed the probability of mission success through simulation."
심층강화학습 기반 자율주행차량의 차로변경 방법론,2023,"['Autonomous driving', 'Path planning', 'Lane-Change', 'Deep Q-Learning', '자율주행', '경로계획', '차로변경', 'Deep Q-Learning']","현재 국내에서는 자율주행차량의 상용화를 목표로 다양한 노력을 기울이고 있으며 자율주행차량이 운영 가이드라인에 따라 안전하고 신속하게 주행할 수 있는 연구들이 대두되고 있다. 본 연구는 자율주행차량의 경로탐색을 미시적인 관점으로 바라보며 Deep Q-Learning을 통해 자율주행차량의 차로변경을 학습시켜 효율성을 입증하고자 한다. 이를 위해 SUMO를 사용하였으며, 시나리오는 출발지에서 랜덤 차로로 출발하여 목적지의 3차로까지 차로변경을 통해우회전하는 것으로 설정하였다. 연구 결과 시뮬레이션 기반의 차로변경과 Deep Q-Learning을적용한 시뮬레이션 기반의 차로변경으로 구분하여 분석하였다. 평균 통행 속도는 Deep Q-Learning을 적용한 시뮬레이션의 경우가 적용하지 않은 경우에 비해 약 40% 향상되었으며평균 대기 시간은 약 2초, 평균 대기 행렬 길이는 약 2.3대 감소하였다.","Several efforts in Korea are currently underway with the goal of commercializing autonomous vehicles. Hence, various studies are emerging on autonomous vehicles that drive safely and quickly according to operating guidelines. The current study examines the path search of an autonomous vehicle from a microscopic viewpoint and tries to prove the efficiency required by learning the lane change of an autonomous vehicle through Deep Q-Learning. A SUMO was used to achieve this purpose. The scenario was set to start with a random lane at the starting point and make a right turn through a lane change to the third lane at the destination. As a result of the study, the analysis was divided into simulation-based lane change and simulation-based lane change applied with Deep Q-Learning. The average traffic speed was improved by about 40% in the case of simulation with Deep Q-Learning applied, compared to the case without application, and the average waiting time was reduced by about 2 seconds and the average queue length by about 2.3 vehicles."
강화학습 기반 차량 냉방 제어 알고리즘 개발,2023,"['Reinforcement learning', 'Energy efficiency', 'Air-conditioner', 'Optimal  control', 'Electric vehicle', '강화학습', '에너지 효율', '에어컨', '최적제어', '전기자동차']",,"To increase an electric vehicle’s mileage, the energy efficiency of vehicles grows in importance every day. To this end, this study proposes an automotive air conditioner control system based on DQN(Deep Q-Learning), a reinforcement learning algorithm. This control system aims to reduce energy consumption with equivalent temperature error by controlling the compressor RPM and blower output. Also, the control system must improve its performance if there is a change in vehicle velocity profile. For this purpose, the state signals are designed to include thermal information and driving velocity, and the reward function is designed to reduce temperature error and power consumption and to suppress the undesirable behavior of the compressor. Training results show an improvement in energy efficiency when simulating with trained driving velocity profiles and other driving velocity profiles compared to the target A/C system."
강화 학습 모델의 안전성 평가 방법: 자율 주행 사례 연구,2023,"['reinforcement learning', 'safety', 'hazard analysis', 'behavior driven development', '.']",,"Reinforcement Learning(RL) finds application in diverse fields such as healthcare and autonomous driving. However, due to its inherent complexity in agent decision-making and the inability to measure outcomes with the same precision as in supervised learning, there is a pressing need for research into assessing the safety of RL systems. Therefore, this paper introduces a method for evaluating the safety of RL models by combining behavior-driven development techniques with risk analysis. When applied to a driving simulation environment, the proposed approach reveals variations in the frequency of safety constraint violations among RL models, even when their average rewards are similar. The outcomes of safety assessment are anticipated to contribute to the improvement of model safety through thorough analysis and iterative enhancements across various aspects."
인간-AGV 충돌 위험을 고려한 강화학습 기반의 출하대기장 내 AGV 운영 최적화,2023,"['Reinforcement learning', 'Automated Guided Vehicle', 'Dispatch area', 'Human-AGV Collision']",,"Automated guided vehicles (AGV) are a crucial component to achieve automation in logistics. AGVs can autonomously transport heavy pallets with the pre-designed rules, hence reducing the need for human resources in the logistics area. However, since AGVs cannot completely replace human workers doing maintenance tasks, inspections, etc., AGVs sometimes share operating areas with human workers. As such an example, we optimize the operation of an AGV in the dispatch area which has a human operator for final inspections. While most previous studies focus on efficient operation of AGVs, this study considers the possibility of human-AGV collisions as well as efficient operation. We also propose a PPO-R algorithm to prevent conservative behaviors of AGV when introducing a collision penalty. Numerical experiments show that PPO-R can maintain throughput while reducing the number of potential collisions."
충전소에서의 대기시간을 고려한 전기차량의 경로 최적화 문제에서 강화학습 기법의 적용 방안 연구,2023,"['Electric Vehicle', 'VRP', 'Charging Station', 'Markov Decision Process', 'Reinforcement Learning']",,"There are several technical obstacles to Electric Vehicles (EVs) adoption such as limited battery capacity, long charging time and low accessibility to EV charging stations. We extend the conventional EVRP (Electric Vehicle Routing Problem) by including charging station visits in the routing decisions. Unlike the literature, the proposed model particularly decides which charging station to visit based on the information of charging station complexity, which is specified by arrival and service rates at each charging stations. We formulated the routing optimization problem as an MDP (Markov Decision Problem) model and used a deep reinforcement learning approach (i.e., DQN; Deep Q-Network) to optimize the route including charging station visits. Numerical analysis shows that the proposed model outperforms two other benchmarks such as nearest station choice and random choice in terms of the total travel time. Moreover, we show that the charging station complexity and the resulting waiting time have significant impact on the performance."
분포 강화학습을 위한 위험도 스케줄링 기반의 낙천적 탐색 방법,2023,"['distributional reinforcement learning', 'multi-agent system', 'exploration', 'risk-scheduling', '분포 강화학습', '다중 에이전트 시스템', '탐색', '위험도 스케줄링']","분포 강화학습은 행동 공간을 탐색하는데 사용될 수 있는 분산과 위험도(risk)의 특징을 통해 연속 및 이산 제어에서 괄목할 성능을 보이고 있다. 하지만, 위험도의 성질을 활용해서 탐색하는 방법은 분산을 활용한 탐색 방법에 대한 연구에 비해 발전되지 못했다. 이와 같은 한계를 극복하기 위해 이 논문에서는 분포 강화학습의 특징인 위험도를 활용하여 위험도 스케줄링(risk-scheduling) 방법을 제안한다. 위험도 스케줄링 방법은 학습하는 에이전트가 다양한 위험도를 경험하게 하고, 낙천적인 (optimistic) 행동을 선택하도록 도움으로써 성능을 개선시킬 수 있다. 다중 에이전트 시스템에서의 분포 강화학습 알고리즘인 DMIX, DDN, DIQL에 위험도 스케줄링을 적용했을 때 성능이 크게 향상되는 것을 확인하였다.",
강화학습을 이용한 초정밀 가공기용 챔버의 온도 제어,2023,"['Temperature control', 'Reinforcement learning', 'Artificial intelligence', 'Ultra-precision machines', 'Chamber', 'DQN algorithm', '온도 제어', '강화학습', '인공 지능', '초정밀 가공기', '챔버', 'DQN 알고리즘']",,"Deep reinforcement learning (RL) has attracted research interest in the manufacturing area in recent years, but real implemented applications are rarely found. This is because agents have to explore the given environments many times until they learn how to maximize the rewards for actions, which they provide to the environments. While training, random actions or exploration from agents may be disastrous in many real-world applications, and thus, people usually use computer generated simulation environments to train agents. In this paper, we present a RL experiment applied to temperature control of a chamber for ultra-precision machines. The RL agent was built in Python and PyTorch framework using a Deep Q-Network (DQN) algorithm and its action commands were sent to National Instruments (NI) hardware, which ran C codes with a sampling rate of 1 Hz. For communication between the agent and the NI data acquisition unit, a data pipeline was constructed from the subprocess module and Popen class. The agent was forced to learn temperature control while reducing the energy consumption through a reward function, which considers both temperature bounds and energy savings. Effectiveness of the RL approach to a multi-objective temperature control problem was demonstrated in this research."
자율적인 UAM 시스템의 효율적인 무인 정보수집 및 감시를 위한 멀티 에이전트 기반 심층 강화학습,2023,"['Deep Reinforcement Learning', 'Multi-Agent', 'UAM', 'CCTV', 'CommNet', '심층 강화학습', '멀티 에이전트', 'UAM', 'CCTV']","멀티 에이전트 심층 강화학습은 여러 에이전트 간의 통신을 통해 에이전트들이 협력적으로 공동의 목표를 달성하는 기계학습이다. 이러한 심층 강화학습 기술을 통해서, 도심 환경에서 교통정보 수집 및 보안을 위해 필수적인CCTV의 감시 역할을 여러 개의 도심 항공 모빌리티 (UAM, Urban Air Mobility)가 대체할 수 있다. 기존의CCTV는 고정된 위치에서 한정적인 시각 정보를 제공할 수 있지만, UAM을 통한 자율적인 CCTV 시스템을 구축하면 실시간으로 추적할 대상의 위치에 따라 유연하고 신뢰성 있는 시각 정보를 제공할 수 있다. 따라서, 본 논문은 에이전트 간 통신 임무를 수행하는 CommNet 알고리즘을 통해 여러 UAM들이 효율적으로 정보수집 및 감시가 가능한 시스템을 구축하는 기법을 제안한다.",
심층 강화학습 기반의 대학 전공과목 추천 시스템,2023,"['Deep Reinforcement Learning', 'Deep Q-Network', 'Dueling Deep Q-Network', 'Markov Decision Process', 'Recommendation System']",,"Existing simple statistics-based recommendation systems rely solely on students' course enrollment history data, making it difficult to identify classes that match students' preferences. To address this issue, this study proposes a personalized major subject recommendation system based on deep reinforcement learning (DRL). This system gauges the similarity between students based on structured data, such as the student's department, grade level, and course history. Based on this information, it recommends the most suitable major subjects by comprehensively considering information about each available major subject and evaluations of the student's courses. We confirmed that this DRL-based recommendation system provides useful insights for university students while selecting their major subjects, and our simulation results indicate that it outperforms conventional statistics-based recommendation systems by approximately 20%. In light of these results, we propose a new system that offers personalized subject recommendations by incorporating students' course evaluations. This system is expected to assist students significantly in finding major subjects that align with their preferences and academic goals"
심층 강화학습 기반 적응적 SAR 이미지 필터링 알고리즘 설계,2023,"['Low Earth Orbit (LEO)', 'Synthetic Aperture Radar (SAR)', 'Speckle Image Filtering', 'Deep Reinforcement Learning (DRL)', 'Buffer State']",,"Low Earth orbit (LEO) satellite synthetic aperture radar (SAR) is an efficient technology for Earth observation, and a lot of research is in progress.However, due to the time-limited property of LEO satellites, research on time-efficient SAR image processing is essential. In this paper, we propose an adaptive speckle noise filtering algorithm based on deep reinforcement learning for efficient processing of LEO SAR images. The proposed algorithm adaptively selects the filter size according to the buffer state to derive the maximum image resolution in a limited time. As a result of the simulation, the proposed algorithm selects the filter size more efficiently according to the buffer state than the method of conventional algorithm."
다중 에이전트 강화학습 기반 상품 추천 모델 개발 연구,2023,"['Multi-agent reinforcement learning', 'Product recommendation model', 'Reinforcement learning algorithm', 'Recommendation accuracy', 'Complexity']","본 연구는 다중 에이전트 강화학습을 활용하여 상품 추천 모델을 개발하는 것을 목표로 한다. 기존의 상품 추천 시스템은 개인의 취향과 상호작용을 충분히 반영하지 못하고, 상호작용의 복잡성을 처리하는 데 어려움이 있음을 확인하였다. 이에 본 논문에서는 다중 에이전트 강화학습을 도입하여 복잡한 상호작용을 처리하고 효과적인 추천을 제공하는 모델을 개발한다. 연구에서는 UCI에서 제공하는 Online Retail 데이터셋을 활용하여 개발을 진행하며, 다중 에이전트 강화학습을 기반으로 한 상품 추천 모델의 아키텍처와 알고리즘을 기반으로 개발한다. 상품 추천 모델은 고객의 구매 내역을 고려하여 추천 모델을 개발한다. 실험 결과, 다중 에이전트 강화학습 기반 상품 추천 모델은 기존의 추천 기법들보다 향상된 추천 정확성을 나타내었다. 본 연구는 다중 에이전트 강화학습을 활용한 상품 추천 모델의 개발과 응용에 실무적인 적용 가능성을 제시한다. 상품 추천 시스템의 실무적인 적용에 기여할 수 있는 중요한 결과를 도출하였으며, 향후 연구 방향과 모델의 실제 서비스 적용을 위한 고려 사항에 대해 검토하였다. 이러한 결과들은 다중 에이전트 강화학습을 활용한 상품 추천 분야에 기반을 제공하며, 산업계에서의 활용을 기대할 수 있을 것이다.",
강화학습을 활용한 고정밀측위를 위한 기지국배치 기법,2023,"['BS placement', 'reinforcement learning']",,"Although location-based services (LBS) are available in various applications, achieving higher positioning performance is crucial, especially in an unmanned robot environment. Base station (BS) placement is a fundamental factor that significantly affects positioning performance. This study introduces a BS placement technique using a deep deterministic policy gradient (DDPG). We implemented symmetrical initial BS placement within the designated environment. In addition, we developed a value function based on the received signal strength indicator and dilution of precision for DDPG. Thus, our findings indicate an enhancement in positioning performance by approximately 12.5%."
이종 병렬설비에서 총납기지연 최소화를 위한 강화학습 기반 일정계획 알고리즘,2023,"['Machine scheduling', 'Unrelated parallel machine Scheduling', 'Total tardiness', 'Reinforcement learning']",,"This paper proposes an algorithm for the Unrelated Parallel Machine Scheduling Problem(UPMSP) without setup times, aiming to minimize total tardiness. As an NP-hard problem, the UPMSP is hard to get an optimal solution. Consequently, practical scenarios are solved by relying on operator's experiences or simple heuristic approaches. The proposed algorithm has adapted two methods: a policy network method, based on Transformer to compute the correlation between individual jobs and machines, and another method to train the network with a reinforcement learning algorithm based on the REINFORCE with Baseline algorithm. The proposed algorithm was evaluated on randomly generated problems and the results were compared with those obtained using CPLEX, as well as three scheduling algorithms. This paper confirms that the proposed algorithm outperforms the comparison algorithms, as evidenced by the test results."
강화학습 모델을 활용한 디지털 롤모델 트윈 연구,2023,"['강화학습', '딥-Q 러닝', '추천시스템', '디지털 트윈', '롤모델', 'Reinforcement learning', 'Deep Q-Learning', 'Recommendation system', 'Digital twin', 'Role model']","대중들이 모사하고자 하는 인물을 ‘롤모델’이라고 할 때, 우리는 롤모델에 대한 가치판단 정보를 예측하여 제공할 수 있는 시스템을 디지털 롤모델 트윈으로 정의한다. 본 논문에서는 강화학습 기법을 사용하여 디지털 롤모델트윈을 생성하고, 생성된 롤모델 트윈을 사용자의 가치판단에 활용할 수 있는 시스템을 제안한다. 구체적으로 디지털 롤모델 트윈 생성과정에서는 현재 상황에 대한 맥락 정보와 의사결정 문제를 롤모델에게 제공하고, 각 의사결정 문제에 대한 롤모델의 선택과 행동을 기반으로 롤모델에 관한 정보와 선호 네트워크를 학습하여 디지털 롤모델 트윈을 생성한다. 사용자는 생성된 디지털 롤모델 트윈을 사용하여, 자신의 상황에 대한 정보와 롤모델에 관한 정보를 바탕으로 주어진 의사결정 문제들에 대한 롤모델의 선호도 정보를 얻을 수 있다. 실험을 통해 디지털롤모델 트윈이 롤모델의 선호도를 적절히 학습하여 롤모델의 선호도 정보를 효과적으로 모사하는 것을 보인다.",
저궤도 인공위성에 적용되는 심층강화학습 기술 동향,2023,"['저궤도 위성', '심층 강화학습', '에지 컴퓨팅', '최적화', 'SAGIN', 'LEO Satellite', 'Deep Reinforcement Learning', 'Edge Computing', 'Optimization', 'SAGIN']","빠른 통신기술의 발전으로, 최근 차세대 이동통신에서 저궤도 위성을 사용하는 연구가 활발히 이루어지고 있다.저궤도 위성통신에서는 자원 관리, 핸드오버 문제 등 복잡한 문제가 발생하는데, 심층강화학습을 통해 기존의 방법으로 풀기 어려웠던 문제들을 해결할 수 있다. 본 논문에서는 위성통신에서 심층강화학습이 사용된 기술에 대해살펴본다. 크게 Task의 순서를 배정하는 문제인 Scheduling problem, 한정된 자원을 효율적으로 관리하기 위한 문제인 Resource Allocation, 위성 사용자들의 연결을 원활하게 만들거나 사용자들을 적절하게 분배하기 위한 문제인 User Access Control, 그리고 그 외의 문제로 분류하였다.",
작물 생산량 예측을 위한 심층강화학습 성능 분석,2023,"['작물 수확량 예측', '심층강화학습', '심층Q-네트워크', '이중 DQN', 'Crop Yield Prediction', 'Deep Reinforcement Learning', 'Deep Q Networks(DQN)', 'Double DQN', 'Dueling DQN']","최근 딥러닝 기술을 활용하여 작물 생산량 예측 연구가 많이 진행되고 있다. 딥러닝 알고리즘은 입력 데이터 세트와 작물 예측 결과에 대한 선형 맵을 구성하는데 어려움이 있다. 또한, 알고리즘 구현은 획득한 속성의 비율에 긍정적으로 의존한다. 심층강화학습을 작물 생산량 예측 응용에 적용한다면 이러한 한계점을 보완할 수 있다. 본 논문은 작물 생산량 예측을 개선하기 위해 DQN, Double DQN 및 Dueling DQN 의 성능을 분석한다. DQN 알고리즘은 과대 평가 문제가 제기되지만, Double DQN은 과대 평가를 줄이고 더 나은 결과를 얻을 수 있다. 본 논문에서 제안된 모델은 거짓 판정을 줄이고 예측 정확도를 높이는 것으로 나타났다.","Recently, many studies on crop yield prediction using deep learning technology have been conducted. These algorithms have difficulty constructing a linear map between input data sets and crop prediction results. Furthermore, implementation of these algorithms positively depends on the rate of acquired attributes. Deep reinforcement learning can overcome these limitations. This paper analyzes the performance of DQN, Double DQN and Dueling DQN to improve crop yield prediction. The DQN algorithm retains the overestimation problem. Whereas, Double DQN declines the over-estimations and leads to getting better results. The proposed models achieves these by reducing the falsehood and increasing the prediction exactness."
V2X 환경에서 교통 혼잡 방지를 위한 심층 강화학습 기반 자율주행,2023,"['Autonomous vehicle', 'V2X', 'PPO', 'Deep Reinforcement Learning', 'Speed control']",,"In this letter, traffic congestion was prevented using autonomous vehicles and traffic light control based on the PPO algorithm in the V2X environment. The average speed of vehicles was compared and analyzed through simulations."
강화학습의 트리 탐색 기반 종단간 소프트 Q러닝,2023,"['몬테카를로 트리 탐색', '볼츠만 희소 샘플링', 'soft Q 학습', 'Monte Carlo tree search', 'Boltzmann guided sparse sampling', 'soft Q-learning']","강화학습을 다루는 환경 중에서도 희소 보상(sparse reward) 환경 체계에서 특히 기존의 시간 차이 학습 (temporal difference learning, TD) 기반 탐험법의 경우 보상을 주는 상태-행동 쌍을 발견하기힘들 뿐만 아니라, 발견하더라도 해당 궤적에 있는상태-행동 쌍에 대한 가치 함수에 반영이 빠르게 되지 못한다. 본 논문에서는 희소 보상체계 궤적에서얻어지는 보상 값의 합이 종단 간 학습 과정에서 효율적으로 학습될 수 있는 Boltzmann guided sparse sampling (BGSS) 기법을 제안한다. 실험결과에서도BGSS가 기존의 트리 탐색법과 시간 차이 학습법 모두 비교했을 때 훨씬 빠른 속도로 학습됨을 보였다.",
강화학습을 이용한 RPG 자동전투 시스템 설계 및 구현,2023,"['게임', '강화학습', '자동전투 시스템', '유니티', '알피지', 'RPG', 'Unity', 'Reinforcement Learning', 'ML Agents', 'Auto Play']","국내 모바일 게임 시장 발전과 함께 Role Playing Game(RPG) 장르의 인기는 2022년까지도 계속되고있다. 대부분 RPG에서 자동전투 시스템을 사용하고있으며 하나의 재미 요소로 자리를 잡을 만큼 자동전투 시스템은 중요해졌다. 자동전투 시스템의 인공지능으로 많이 활용하는 유한 상태 기계(Finite State Machine)의 경우 유지보수와 행동이 비효율적이다. 이러한 비효율적 부분 해결을 위해 알파고, 알파스타 등 복잡한 문제를 해결하기 위해 사용이 되었던 강화학습(Reinforcement Learning)을연구 방법으로 제안한다.본 연구에서는 자동전투 시스템 인공지능 두 가지를 설계 및 구현하여 효율성을 검증하였다. 자동전투시스템을 유한 상태 기계로 설계 및 구현과 유니티엔진의 머신러닝 툴킷 ML_Agents를 활용하여 강화학습으로 설계 및 구현 하였다. 후 강화학습의 학습 과정 분석을 진행하였고 강화학습과 유한 상태 기계로구현된 두 인공지능을 에피소드를 완료하는 시간을비교하는 방식과 연산속도 비교로 효율성 검증을 진행하였다.구현된 강화학습 자동전투 시스템의 경우 인공지능이 의도한 대로 학습과 작동을 진행하였으며 유한상태 기계로 구현된 자동 전투 시스템보다 효율적행동을 보여주었지만 더 많은 연산과 리소스를 필요했다. 또한 구현된 강화학습 인공지능을 빌드하여 PC 와 Android 플랫폼에서 정상 작동을 확인하였다.",
강화학습 기반 무인항공기 이동성 모델에 관한 연구,2023,"['Deep-Q Network', 'Flying Ad-hoc Network', 'Fourier Basis', 'Reinforcement Learning', 'Q-learning']","최근 비행 애드-훅 네트워크(Flying Ad-hoc Network) 환경에서 강화학습을 이용한 통신 성능 개선과 이동성 모델 설계에 관한 연구가 진행되고 있다. 무인항공기(UAV)에서의 이동성 모델은 움직임을 예측하고 제어하기 위한 핵심 요소로 주목받고 있다. 본 논문에서는 무인항공기가 운용되는 3차원 가상 환경을 구현하고, 무인항공기의 경로 최적화를 위해 푸리에 기저 함수 근사를 적용한 Q-learning과 DQN 두 가지 강화학습 알고리즘을 적용하여 모델을 설계 및 성능을 분석하였다. 실험 결과를 통해 3차원 가상 환경에서 DQN 모델이 Q-learning 모델 대비 최적의 경로 탐색에 적합한 것을 확인하였다.",
입력강화를 이용한 교수법이 일본어 수동태 습득에 미치는 영향 ―한국인 학습자의 모어 및 인지체계 특성을 중심으로―,2023,"['日本語の受動態', '母語の特性', '認知体系，教授法，入力強化', 'The Passive Form of Japanese', 'Mother tongue Characteristics', 'Cognitive System，Teaching Method，Input Enhancement']",,"This study aims to clarify the particular features of Korean learners’ acquisition of the passive form of Japanese, a grammatical element that presents difficulties for learners of Japanese, and to determine how learning input materials and input reinforcement teaching methods can affect Korean learners’ learning of Japanese. This study found that to help earners properly acquire the Japanese passive form, in which objects affected by actions are the subject of sentences, input data reflecting the characteristics of Japanese, as well as Text Enhancement or Input Flood teaching methods, are useful for conveying the cognitive requirements of the Japanese form."
강화학습과 회전 반경 게인을 활용한 4륜 독립 조향 EV의 경로 추종 전략,2023,"['자율주행 셔틀', '4륜 독립 조향', '경로 추종 알고리즘', '강화학습', '회전 반경 게인', 'Autonomous driving shuttle', '4-Wheel independent steering', 'Path tracking algorithm', 'Reinforcement learning', 'Turning radius gain']",,"Recent developments in the automobile industry include the introduction of e-Corner modules, which incorporate driving, braking, steering, and suspension systems within each wheel of a vehicle. Accordingly, research on the control strategy of a four-wheel independent drive and steering EV is actively underway. This paper proposes a path-tracking controller by applying PPO reinforcement learning in four-wheel independent steering vehicles. An algorithm for switching the steering mode of a four-wheel independent steering vehicle was used with the turning radius gain variable. Then, a learning environment was developed and evaluated by using a vehicle dynamics simulator with repeated low and high curvature paths. Next, the learned agents compared performance with commonly used lateral controllers, namely, Pure Pursuit and Stanley. The proposed controller’s lateral path offset error performance was less than 30 cm in the low-curvature scenario, while, in the high-curvature scenario, the paths following performance and stability were better than those of Pure Pursuit and Stanley."
멀티에이전트 심층강화학습을 이용한 포트폴리오 설계 및 구현,2023,"['금융 인공지능', '비즈니스 애널리틱스', '핀테크', '다이렉트 인덱싱', '계량금융', 'AI in finance', 'Business analytics', 'FinTech', 'Direct indexing', 'Quantitative finance']","투자 포트폴리오는 현대 포트폴리오 이론에 근거하여 해리 마코위츠가 제안한 계량 모델로서 비체계적 위험을 감소시키는 것을 목표로 삼는 이론 체계이다. 현대 사회를 급진전시킨 컴퓨팅 환경하에서 최근 통계나 기계학습 기법을 기반으로 한 포트폴리오 전략 수립이 지배적 현상으로 나타나고 있다. 특히, 기계학습 기법 중 강화학습을 적용한 투자 포트폴리오 구축이 주목받으면서 이에 관한 국내 연구도 수행된 바 있다. 하지만 투자 포트폴리오에 강화학습을 적용한 연구는 활성화되지 못한 채 여전히 미흡한 수준에 머물러 있는 것으로 보인다. 본 연구는 자산 선택과 강화학습이 통합된 포트폴리오를 위험조정 수익 극대화 측면에서 벤치마크 지수와 비교·분석하였다. 주요 실증분석 결과는 다음과 같다. 첫째, 제안한 모든 포트폴리오들은 위험 대비 높은 투자 성능을 비교해 보면 벤치마크 지수에 비해 상대적으로 높은 누적 수익 성과를 보여 주었다. 더불어 포트폴리오 모형 1은 모든 기간에서 정(+)의 샤프비율을 보였는데, 이러한 결과는 동작 확률 분포에 입각해 동작 선택 후 보상의 획득을 가능케 하고, 이것을 상태 가치와 비교해 이익 계산을 실행함으로써 최적 정책의 학습 확률이 증진되었다고 판단된다. 둘째, 제안한 포트폴리오들의 평균 최대손실폭도 벤치마크 지수보다 낮거나 비슷하게 나타났다. 이로 인해 수익 기회의 온전성 유지 및 변동성 감소를 동시에 추구할 수 있는 것이다. 이를 통해 제안한 통합된 포트폴리오가 적정히 잘 작동되고 있음이 실증되었다. 이런 맥락에서 자산 선택과 강화학습이 통합된 포트폴리오에 관한 연구는 학문적 측면에서 핵심 연구 주제가 될 뿐만 아니라 현업의 다이렉트 인덱싱 고도화에 있어서도 근원적 탐구 대상이 된다.",
강화학습 기반 고속도로 갓길차로제 운영 알고리즘 개발 연구,2023,"['고속도로', '갓길차로제', '강화학습', 'DQN', '미시교통시뮬레이션', 'Expressway', 'Hard shoulder running', 'Einforcement learning', 'DQN', 'Microscopic simulation']","본 연구는 고속도로 상의 반복적인 교통 혼잡 문제를 해결하기 위한 현실적인 대안 중 하나인 고속도로 갓길차로제를 효과적으로 운영하기 위해 강화학습 기법을 적용하고자 하였다. 강화학습의 DQN을 활용한 갓길차로제 운영 알고리즘을 개발하였고 미시교통시뮬레이션 프로그램 VISSIM을 활용하여 경부선 기흥IC-수원IC 구간의 데이터를 활용하여 강화학습 에이전트를학습시켰고 그 효과를 평가하였다. 효과평가는 크게 이동성과 안전성의 두 가지 측면에서 진행하였다. 분석 결과 DQN 기반 갓길차로제 운영을 통해 시간당 최대 26km/h의 속도 개선 효과가 발생하였으며, DQN 에이전트는 기존 운영 기준인 60km/h 보다 약 10km/h 높은 속도로 갓길차로제를 운영하였다. 안전성 효과의 경우 기존 운영 방식과 DQN 기반 운영을 통해 발생되는차량 간 상충건수를 비교하였고 산출된 상충건수의 차이가 크지 않아 10km/h의 운영 기준 속도의 차이가 큰 영향을 주지 않은 것으로 판단하였다. 이러한 결과를 종합적으로 고려할 때강화학습 기반 고속도로 갓길차로제 운영은 이동성 측면에서는 분명한 효과가 존재하였고 현재 운영 기준 속도의 조정을 고려해볼 필요가 있을 것으로 판단된다.",
MEC 산업용 IoT 환경에서 경매 이론과 강화 학습 기반의하이브리드 오프로딩 기법,2023,"['이동 엣지 컴퓨팅', 'D2D(Device to Device) 오프로딩', '산업용 IoT', 'McAfee’s 이중 경매', '멀티 암드 밴딧', 'Mobile Edge Computing(MEC)', 'Device-to-Device(D2D) Offloading', 'Industrial Internet of Things(IIoT)', 'McAfee’s Double Auction', 'Multi-Armed Bandit(MAB)']","산업용 IoT는 대규모 연결을 통해 데이터 수집, 교환, 분석과 함께 산업 분야의 생산 효율성 개선에 중요한 요소이다. 그러나 최근 산업용 IoT의확산으로 인해 트래픽이 폭발적으로 증가함에 따라 트래픽을 효율적으로 처리해줄 할당 기법이 필요하다. 본 논문에서는 산업용 IoT 환경에서성공적인 태스크 처리율을 높이기 위한 2단계 태스크 오프로딩 결정 기법을 제안한다. 또한, 컴퓨팅 집약적인 태스크를 셀룰러 링크를 통해 이동엣지 컴퓨팅(Mobile Edge Computing: MEC) 서버로 오프로드 하거나 D2D(Device to Device) 링크를 통해 근처의 산업용 IoT 장치로 오프로드할 수 있는 하이브리드 오프로딩(Hybrid-offloading) 시스템을 고려한다. 먼저 1단계는 태스크 오프로딩에 참여하는 기기들이 이기적으로 행동하여태스크 처리율 향상에 어려움을 주는 것을 방지하기 위해 인센티브 메커니즘을 설계한다. 메커니즘 디자인 중 McAfee’s 메커니즘을 사용하여 태스크를 처리해주는 기기들의 이기적인 행동을 제어하고 전체 시스템 처리율을 높일 수 있도록 한다. 그 후 2단계에서는 산업용 IoT 장치의 불규칙한움직임을 고려하여 비정상성(Non-stationary) 환경에서 멀티 암드 밴딧(Multi-Armed Bandit: MAB) 기반 태스크 오프로딩 결정 기법을 제안한다.실험 결과로 제안된 기법이 기존의 다른 기법에 비해 전체 시스템 처리율, 통신 실패율, 후회 측면에서 더 나은 성능을 달성할 수 있음을 보인다.","Industrial Internet of Things (IIoT) is an important factor in increasing production efficiency in industrial sectors, along with datacollection, exchange and analysis through large-scale connectivity. However, as traffic increases explosively due to the recent spreadof IIoT, an allocation method that can efficiently process traffic is required. In this thesis, I propose a two-stage task offloading decisionmethod to increase successful task throughput in an IIoT environment. In addition, I consider a hybrid offloading system that can offloadcompute-intensive tasks to a mobile edge computing server via a cellular link or to a nearby IIoT device via a Device to Device (D2D)link. The first stage is to design an incentive mechanism to prevent devices participating in task offloading from acting selfishly andgiving difficulties in improving task throughput. Among the mechanism design, McAfee's mechanism is used to control the selfish behaviorof the devices that process the task and to increase the overall system throughput. After that, in stage 2, I propose a multi-armed bandit(MAB)-based task offloading decision method in a non-stationary environment by considering the irregular movement of the IIoT device.Experimental results show that the proposed method can obtain better performance in terms of overall system throughput, communicationfailure rate and regret compared to other existing methods."
분기된 일화기억 기반의 자기지도적 정책 학습 방법,2023,"['일화기억', '행동-대조학습', '보상기억', '부정기억', '자기지도학습', '강화학습', 'episodic memory', 'action-contrastive learning', 'rewarding memory', 'penalty memory', 'self-supervised learning', 'reinforcement learning']",,"Episodic memory which is mainly controlled by the hippocampus contains personal experience and enables learning-by-experience. Episodic memories are divided into rewarding or penalty memories according to the provoked emotion. Each memory goes through the rewarding or penalty circuit intersection near the basolateral amygdala and is stored. In this paper, based on the aforementioned biological rationale, we present an action-contrastive learning which trains policy based on the diverged episodic memories. In action-contrastive learning, rewarding and penalty memory storing is diverged according to the reward property, and the policy is trained by reinforcing and weakening the actions taken in the reward memory and penalty memory, respectively.Experiments have shown that the policy trained with our proposed method tends to obtain rewards in MNIST and Atari Pong environments. Furthermore, saliency map analysis confirmed the validity of evidence of action the learned policy took."
합성곱 신경망 기반의 딥러닝을 이용한 섬유 강화 복합재료의 적층 각도 예측,2023,"['합성곱 신경망', 'Convolutional neural network', '적층 각도', 'Stacking angle', '섬유 강화 복합재료', 'Fiber-reinforced composite materials', '딥러닝', 'Deep learning']",,"Fiber-reinforced composites have anisotropic material properties, so the mechanical properties of composite structures can vary depending on the stacking sequence. Therefore, it is essential to design the proper stacking sequence of composite structures according to the functional requirements. However, depending on the manufacturing condition or the shape of the structure, there are many cases where the designed stacking angle is out of range, which can affect structural performance. Accordingly, it is important to analyze the stacking angle in order to confirm that the composite structure is correctly fabricated as designed. In this study, the stacking angle was predicted from real cross-sectional images of fiber-reinforced composites using convolutional neural network (CNN)-based deep learning. Carbon fiber-reinforced composite specimens with several stacking angles were fabricated and their cross-sections were photographed on a micro-scale using an optical microscope. The training was performed for a CNN-based deep learning model using the cross-sectional image data of the composite specimens. As a result, the stacking angle can be predicted from the actual cross-sectional image of the fiber-reinforced composite with high accuracy."
전이학습 기반의 휴머노이드 로봇 HRI- Vision 모델에 관한 연구,2023,"['Robot industry', 'Humanoid robot', 'HRI', 'Deep learning', 'Transfer learning']",,"With the development of artificial intelligence many changes are taking place in various fields and service robots equipped with machine learning and industrial cooperative robots are also appearing in the robot field. However the intuitive and empathic intelligence of artificial intelligence has not yet fully permeated service robots and surpassed humans. Therefore it can be said that it is difficult for robots to perform complex services independently and robots and humans must reinforce each other to provide quality services to customers. Recently HRI a convergence technology for natural communication between humans and robots and smooth interaction are attracting attention. HRI research can be divided into user-centered and robot-centered interactions. The robot-vision technology recognizes the environment and objects, recognizes a human face to identify a target, recognizes emotions and plays the role of a recognition unit that can infer intentions based on motion. Robots are now so widespread that humans consider them to be their colleagues and friends. Therefore, there is a need for a small robot incorporating object recognition technology. In this paper, we propose an HRI vision object recognition system using a transfer learning-based object detection algorithm in a small PC of a humanoid robot. The proposed system applies robot vision technology that can replace the visual functions of low-spec small humanoid robots and allows the humanoid robot to perform pre-programmed motions through face recognition."
중학교 학생선수의 학습권 보장에 대한 인식과 인식 형성에 미치는 영향에 관한 탐색적 연구,2023,"['student-athletes', 'consideration regarding right for learning', 'formation of consideration', 'factor']",,"Purpose: The purpose of this study is to investigate the perceptions of student-athletes regarding the guarantee of their right to study, and to identify the factors that have influenced their perception formation.Through this, we intend to find the fundamental data necessaryto construct an institutional policy to reinforce and/or improve the student-athletes’ consideration of the right to study.Method: In this study, using purposeful sampling, six male student-ahtletes with different characteristics were selected from the student players who belong to the baseblla club of a middle school located in th e Chungcheong province. For data collection, various qualitatived ata were collected and analyzed through in-depth interviews, personal documents from open questionnaires, and focus group interviews. In orde r to analyze the collected data, inductive category analysis was performed through constant comparison, following the procedures of open coding, axial coding, and selective coding. In order to ensure the accuracy of the collected data and to enhance the validity of the resuinltg research findings, triangulation was conducted using various data sources, including individual in-depth interviews, personal documents, and focus group interviews. Also, among the strategies to increase the vliadity suggested by Merriam (1998), various techniques, such as peer review and member check, were employed.Results:　The results of this study were classified into three major categories: ‘the meaning of study for me,’ ‘my view on learning,’ , and ‘factors affecting the formation of considerations of the right to study’. In the ‘meaning of studying for me’ classified into the first broad category, both positive and negative perceptions about guaranteeing the right to study appeared. In the second major category, ‘my view on learning’, the participation attitudes in the period approaching the competition and the off-season period were different. It is likely that it does not occur in normal classes. Third, ‘factors related to educational context’ and ‘factors related to the educational system’ appeared in ‘factors affecting the formation of consideration of the right to study’. In the factors related to the educational context, parents and instructors had a positive effect, while in the factors related to the educational system, the minimum academic achievement system and e-school system had a negative effect.Conclusion: There is a need for the interest of parents and instructors and more effective institutional improvement to help student athletes form awareness of the significance of right for learning."
딥러닝을 활용한 도시가스배관의 전기방식( Cathodic Protection) 정류기 제어에 관한 연구,2023,"['.', 'AI(artificial intelligence)', 'CP(cathodic protection)', 'DRL(deep reinforcement learning)', 'Q-learning']","4차 산업혁명으로 인공지능(AI, Artificial Intelligence) 관련 기술이 고도로 성장함에 따라 여러 분야에서AI를 접목하는 사례가 증가하고 있다. 주요 원인은 정보통신기술이 발달됨에 따라 기하급수적으로 증가하는데이터를 사람이 직접 처리 분석하는데 현실적인 한계가 있고, 새로운 기술을 적용하여 휴먼 에러에 대한리스크도 감소시킬 수 있기 때문이다. 이번 연구에서는 ‘원격 전위 측정용터미널(T/B, Test Box)’로부터 수신된 데이터와 해당시점의 ‘원격 정류기’ 출력을 수집 후, AI가 학습하도록 하였다. AI의 학습 데이터는 최초수집된 데이터의 회기분석을 통한 데이터 전처리로 확보하였고, 학습모델은 심층 강화학습(DRL, Deep Reinforce-ment Learning) 알고리즘 中 Value기반의 Q-Learning모델이 적용하였다. 데이터 학습이 완료된 AI는 실제 도시가스 공급지역에 투입하여, 수신된 원격T/B 데이터를 기반으로 AI가 적절하게 대응하는지 검증하고, 이를 통해 향후 AI가 전기방식 관리에 적합한 수단으로 활용될 수 있는지 검증하고자 한다.",
ARCS모델 기반 히라가나 학습에 있어서의 연상법의 수업흥미도와 효과에 관한 분석 ― S대학 교양일본어 수업 수강생을 대상으로 ―,2023,"['연상법', '히라가나 학습', '수업흥미도', '읽기성취도', 'ARCS모델', 'associative method', 'hiragana learning', 'class interest', 'reading achievement', 'ARCS model']",,"The aim of this study is to analyze the effectiveness of using the video associative method in hiragana classes and its effect on class interest for Korean university students learning Japanese. In conventional hiragana learning, classes are rarely designed with the aim of motivating learners. Therefore, Keller’s ARCS model, a teaching design model based on the theory of motivation, was used to design an associative method for hiragana learning. The study involved 48 students who had never studied Japanese before among the participants in the “Introduction to Japanese” course at S University in Chungcheongnam-do province, Korea. The study tested whether there were differences in levels of class interest and achievement in reading hiragana depending on the use of the video associative method. A t-test was used for verification and the survey results were as follows: first, there was a significant difference in class interest in relation to the sub-domains of attention and relevance with the multimedia-type materials, which are the sub-contributing factors; second, there was a significant difference in students’ level of achievement in the primary examination conducted immediately after the class; and third, there was no significant difference in the level of achievement in the secondary examination conducted in the seventh week. Based on these results, the study proposes the following three points: 1) It is necessary to actively utilize multimedia-type teaching materials and design classes based on teaching design theory to enhance students’ confidence and satisfaction; 2) It is required to make efforts to continuously improve the associative method; and 3) To reinforce hiragana learning, it is required to improve maintenance rehearsal and retrieval activities that consider the learning environment of adult learners."
딥러닝을 이용한 객체검출과 비평탄 지형 보행을 위한 4족 로봇,2023,['4'],고성능의 보행 로봇에 관한 연구가 활발하게 이루어지고 있으며 4족 보행 로봇은 비평탄 지형에서 이동성과 적응력이 뛰어나 많은 관심을 받고 있지만 높은 비용으로 도입과 활용성에 어려움이 있다. 본 논문에서는 저비용의 4족 로봇에 지능적 기능을 적용하여 활용도를 높이기 위해 임베디드 보드에 IMU와 강화학습을 탑재하여 비평탄 지형 극복능력을 개선하고 카메라와 딥러닝을 이용하여 객체를 자동으로 검출하는 방법을 제시한다. 로봇은 4족 포유류 동물의 다리 형태로 구성되고 각 다리는 3 자유도를 가진다. 설계된 3D 모델로 시뮬레이션 환경에서 복잡한 지형을 학습시키고 실제 로봇에 적용한다. 본 연구방법의 적용을 통해 평탄 지형과 비평탄 지형의 보행 능력에 크게 차이가 나지 않음을 확인하였으며 제한된 실험조건에서 실시간으로 사람 검출을 수행하는 동작을 확인하였다.,"Research on high-performance walking robots is being actively conducted, and quadruped walking robots are receiving a lot of attention due to their excellent mobility and adaptability on uneven terrain, but they are difficult to introduce and utilize due to high cost. In this paper, to increase utilization by applying intelligent functions to a low-cost quadruped robot, we present a method of improving uneven terrain overcoming ability by mounting IMU and reinforcement learning on embedded board and automatically detecting objects using camera and deep learning. The robot consists of the legs of a quadruped mammal, and each leg has three degrees of freedom. We train complex terrain in simulation environments with designed 3D model and apply it to real robot. Through the application of this research method, it was confirmed that there was no significant difference in walking ability between flat and non-flat terrain, and the behavior of performing person detection in real time under limited experimental conditions was confirmed."
저성취 고등학생의 이차함수 학습 지원을 위한 비계설정 사례 연구,2023,"['비계설정', '인지적 비계', '정의적 비계', '저성취 학생', '이차함수', 'scaffolding', 'analytic scaffolding', 'affective scaffolding', 'low-achieving students', 'quadratic function']","본 연구에서는 저성취 고등학생의 이차함수 학습을 지원하기 위해 수학 교사가 사용하는 비계설정 전략을 식별하고, 인지적, 정의적관점에서 교사가 형성한 비계의 특징을 탐색하였다. 인지적 관점에서 교사가 형성한 비계의 특징은 다음과 같다. 첫째, 초기 상호작용에서 인지적 비계설정의 주요 전략으로 방향 설정과 시범을 함께 사용하였다. 둘째, 방향 설정 전략을 활용하여 이차함수 학습과관련된 절차적 유창성 함양을 지원하였다. 셋째, 학습자의 수학적 오류에 반응하여 피드백을 제공함으로써 학습자가 자신의 오류를감지하고 잘못된 지식 구조를 수정할 수 있도록 지원하였으며, 이를 위해 다양한 정의적 비계설정 전략을 함께 활용하였다. 정의적관점에서 교사가 형성한 비계의 특징은 다음과 같다. 첫째, 저성취 학생의 수학 학습 참여를 촉진하기 위해 보충 전략을 지속적으로활용하였다. 둘째, 저성취 학생이 경험할 수 있는 잠재적인 좌절을 최소화하기 위해 좌절 조절 전략을 활용하였다. 셋째, 학습자의부분적인 성공 경험에도 반응하며 피드백과 더불어 인정과 칭찬 등의 사회적 강화를 제공하였다. 교사가 형성한 비계가 저성취학생의 이차함수 학습에 미친 영향을 알아보기 위해 수행한 학습 과정 분석 및 과제 기반 인터뷰 결과, 비계설정을 통한 교수-학습에서 일부 이차함수 관련 지식에 대한 독립성의 이양이 일어났음을 확인하였다. 연구 결과로부터 저성취 학생들을 대상으로 한 비계설정과 관련된 시사점에 대해서 논의하고, 후속 연구를 제안하였다.","In this study, we identified a mathematics teacher’s scaffolding strategies to support a low-achieving high school students’ quadratic function learning and explored the characteristics of scaffolding used by the teacher from analytic and affective perspectives. From analytic perspective, the characteristics of scaffolding used by the teacher are as follows. First, direction setting and demonstration were used together as the main strategies of analytic scaffolding in early interactions. Second, the direction setting strategy was used to support the development of procedural fluency related to quadratic function learning. Third, by providing feedback in response to the learner's mathematical errors, the learner was able to detect his errors and correct wrong knowledge structures, and for this purpose, various affective scaffolding strategies were used together. From affective perspective, the characteristics of scaffolding used by the teacher are as follows. First, recruitment strategies were continuously used to promote the participation of the low-achieving student in mathematics learning. Second, frustration control strategies were used to minimize potential frustrations experienced by the low-achieving student. Third, it responded to the learner's partial success experience and provided social reinforcement such as recognition and praise along with feedback. As a result of learning process analysis and task-based interview conducted to find out the effect of teacher scaffolding on quadratic function learning of low-achieving student, it was confirmed that some knowledge related to quadratic function were handed over in scaffolding. From the results of the study, implications related to scaffolding for low-achieving students were discussed, and follow-up studies were proposed."
"문제중심학습 연계 시뮬레이션교육을 이수한 간호대학생의 메타인지, 회복탄력성이 임상추론능력에 미치는 영향",2023,"['간호대학생', '메타인지', '회복탄력성', '임상추론', '시뮬레이션', 'Nursing student', 'Meta-cognition', 'Resilience', 'Clinical reasoning', 'Simulation']",,"This study is a descriptive research to examine the effects of meta-cognition and resilience on clinical reasoning ability of nursing students who have completed the simulation education integrated with problem based learning. The study subjects were senior nursing students who had experienced SIM-PBL education, and data was collected by using a structured questionnaire from September to December 2021. The collected data was analyzed employing descriptive statistics, correlation, and hierarchical regression analysis using the SPSS program. The results demonstrated that meta-cognition and resilience had a significant positive correlation with clinical reasoning ability. The chief factors influencing on the clinical reasoning ability of nursing students were as follows: confidence in participating in the SIM-PBL education, meta-cognition, and resilience. In addition, the three factors explained the clinical reasoning ability at a high level of 75%. The clinical reasoning ability of nursing students may be cultivated by applying internal reinforcers of self-confidence, meta-cognition, and resilience into a SIM-PBL simulation."
베트남인 한국어 학습자의 학습전략과 자기주도학습능력 간 관계에서 학습불안의 조절효과 검증,2023,"['자기주도학습능력', '학습전략', '학습불안', '베트남인 한국어 학습자', '한국어 학습', 'Self-directed learning ability', 'Learning strategies', 'Learning anxiety', 'Vietnamese Korean language learners', 'Learning Korean as Foreign language']","목적: 본 연구는 베트남인 한국어 학습자를 대상으로 이들의 학습전략과 자기주도학습능력 간 관계에서 학습불안의 조절효과를 검증하는 데 목적이 있다. 방법: 이를 위해 자기주도학습능력, 학습전략, 학습불안에 관해 그간 보편적으로 활용되어 온 표준화된 척도로 설문지 제작 후 설문조사를 통해 125명의 연구 대상자를 표집해 조절효과분석 등을 실시하였다. 결과: 베트남인 한국어 학습자의 학습전략을 기억전략, 인지전략, 보상전략, 상위인지전략, 사회적 전략으로 구분해 자기주도학습능력과의 상관성을 실증한 결과, 모두 자기주도학습능력과 정(+)적 상관관계를 형성하고 있었다. 또한 이들 변수 간의 모든 관계에서 학습불안은 유의한 조절효과를 가졌고, 그 조절효과의 성격은 강화효과로 밝혀졌다. 결론: 본 연구의 실증 결과를 토대로 논의 수행 후 다음의 시사점을 제시했다. 첫째, 자기주도학습능력 증진을 위한 학습전략 관련 지원 체계가 구조화되어 제공될 필요가 있다. 둘째, 한국어 학습 시 학습불안 조절이 학습전략 구축에 우선될 필요가 있다. 셋째, 자기주도학습능력의 증진을 위해 학습불안을 학습 활동에 긍정적으로 활용하려는 인식 변화가 필요하다.","Purpose: The purpose of this study is to verify the moderating effect of learning anxiety in the relationship between learning strategies and self-directed learning ability of Vietnamese Korean language learners. Methods: In order to accomplish this study purpose, a questionnaire was created using a standardized scale that has been commonly used for self-directed learning ability, learning strategy, and learning anxiety, and then 125 research subjects were sampled through a questionnaire survey to analyze the moderation effect analysis. Results: Vietnamese Korean language learners’ learning strategies were classified into memory strategy, cognitive strategy, reward strategy, meta-cognitive strategy, and social strategy, and as a result of demonstrating correlation with self-directed learning ability, all of them had a positive correlation with self-directed learning ability. In addition, in all relationships between these variables, learning anxiety had a significant moderating effect, and the nature of the moderating effect was found to be a reinforcing effect. Conclusion: This study presented the following implications: First, it is necessary to provide a structured support system related to learning strategies to enhance self-directed learning ability. Second, when learning Korean, controlling learning anxiety needs to be prioritized in establishing a learning strategy. Third, it is necessary to change the perception to positively utilize learning anxiety in learning activities to enhance self-directed learning ability."
기계학습을 이용한 염화물 확산계수 예측모델 개발,2023,"['Multi-Agent reinforcement learning', 'Deep Q-Network', 'Optimal structural design', 'Reinforced concrete beam']",,"Chloride is one of the most common threats to reinforced concrete (RC) durability. Alkaline environment of concrete makes a passive layer on the surface of reinforcement bars that prevents the bar from corrosion. However, when the chloride concentration amount at the reinforcement bar reaches a certain level, deterioration of the passive protection layer occurs, causing corrosion and ultimately reducing the structure’s safety and durability. Therefore, understanding the chloride diffusion and its prediction are important to evaluate the safety and durability of RC structure. In this study, the chloride diffusion coefficient is predicted by machine learning techniques. Various machine learning techniques such as multiple linear regression, decision tree, random forest, support vector machine, artificial neural networks, extreme gradient boosting annd k-nearest neighbor were used and accuracy of there models were compared. In order to evaluate the accuracy, root mean square error (RMSE), mean square error (MSE), mean absolute error (MAE) and coefficient of determination (R2 ) were used as prediction performance indices. The k-fold cross-validation procedure was used to estimate the performance of machine learning models when making predictions on data not used during training. Grid search was applied to hyperparameter optimization. It has been shown from numerical simulation that ensemble learning methods such as random forest and extreme gradient boosting successfully predicted the chloride diffusion coefficient and artificial neural networks also provided accurate result."
피부미용전공 대학생들의 국가직무능력표준(NCS)교육에서  학습 만족도 및 자기효능감이 직무문제해결자신감에 미치는 영향,2023,"['Job problem-solving confidence', 'Learning satisfaction', 'National Competency Standards (NCS) education', 'Self-efficacy']",,"To examine whether NCS education is practically applied to the skin care major students who take the NCS curriculum, this study was identified and verified the factors affecting on job-problem-solving such as the actual state of NCS-based operation and perception, learning satisfaction, self-efficacy, and the factors affected on confidence in job problem-solving was analyzed. The composition of the survey consisted of a total of 41 questions in 4 areas: general characteristics (4 questions), NCS-based operation status and perception (9 questions), learning satisfaction and self-efficacy (16 questions), and career selection (6 questions). After verifying the reliability and validity of the measurement tool, questionnaire was composed. To analyze the data, 4 analysis as following frequency, reliability, factor, and multiple regression were applied using the SPSS 22.0 program. The module for identifying skin conditions in the learning module of the NCS-based operation practices out of NCS curriculum has an effect on increase confidence of the college students being able to solve a job problem after choosing a job and the improvement of professional knowledge such as skin condition identification can prevent from getting out of job. In the learning satisfaction field of NCS curriculum, the higher the skill improvement the skin beauty technic and the possibility of completion of a task through NCS curriculum, the higher the job problem-solving confidence, and In skin beauty college students' self-directed learning participation, the basic knowledge should be encouraged to build up by inducing technical knowledge and interest. In the self-efficacy field of the NCS curriculum, it was found that the more you try to think deeply about skin beauty, recognize the lack of self-skills through NCS education, and feel the need for education reinforcement, the more confident you are in solving job problems. In addition, among the deficient factors in academic performance at the university education level using NCS curriculum, class engagement and academic self-efficacy can act as factors that increase academic achievement. When job problems arise, the application of knowledge and skills acquired through NCS education is expected to affect job problem-solving confidence that can overcome obstacles arising after job choice. The NCS education of college students majoring in skin care was exposed to be a positive factor that improves job problem-solving confidence after employment by increasing learning satisfaction and self-efficacy."
디지털 리터리시 기반 수업을 위한 상보적 교수-학습모형 개발 및 타당화,2023,"['reciprocal teaching and learning', 'digital literacy', 'smart learning environment', '디지털 리터러시', '스마트교육환경', '상보적 교수-학습모형']",,"The purpose of this study was to develop a reciprocal teaching-learning model for digital literacy-based classes that reinforces the digital literacy of instructors and learners and fosters learners' metacognitive learning strategies. The model development process of this study proceeded in the development stage, verification stage, and completion stage.First, in the development stage, a draft of the research model was developed through analysis of previous studies and literature review. Second, in the verification stage, the first and second content validity verification was conducted. Thirteen participants in the study for content validity verification were 4 content experts and 9 field experts from elementary schools, middle schools, high schools, and universities. Content validity was confirmed by calculating the mean, standard deviation, CVI (content validity index), and IRA (inter-rater agreement). Third, in the completion stage, after the second content validity survey was completed, the final model was finalized by reflecting expert opinions. The components of the finalized research model are digital literacy reinforcement support, reciprocal teaching-learning, and performance sharing. Supporting subcomponents of digital literacy reinforcement are digital media check, digital application class environment check, and digital literacy check element check. Reciprocal teaching-learning is largely divided into complementary classes, teacher role, and learner role. The components of reciprocal instruction are teacher demonstration, teacher-learner interaction, gradual transfer of class responsibility from instructor to learner, learner's agent, and learner-learner interaction. The components of the instructor's role are planning, implementation, evaluation, It is feedback, and the components of the learner role are prior self-examination, planning, performance, self-assessment, and reflection. The subcomponents of performance sharing are outcome presentation and feedback from individuals and groups.In conclusion, the reciprocal teaching-learning model for digital literacy-based classes developed in this study promotes interaction between instructors and learners and between learners and learners by strengthening digital literacy and utilizing digital media in class. In addition, learners will be able to solve creative problems by cultivating metacognitive learning strategies through reciprocal class activities."
머신러닝 및 딥러닝 기법을 활용한 유리섬유 직물 강화 복합재 적층판형 Circuit Analog 전파 흡수구조 설계에 대한 연구,2023,"['복합재료', 'Composite Materials', '머신러닝', 'Machine Learning', '딥러닝', 'Deep Learning', '전자파 흡수 구조', 'Radar Absorbing Structure', '유리섬유 직물 강화 복합재', 'Glass Fiber Reinforced Plastic']",,"In this paper, a machine learning and deep learning model for the design of circuit analog (CA) radar absorbing structure with a cross-dipole pattern on a glass fiber fabric reinforced plastic is presented. The proposed model can directly calculate reflection loss in the Ku-band (12-18 GHz) without three-dimensional electromagnetic numerical analysis based on the geometry of the Cross-Dipole pattern. For this purpose, the optimal learning model was derived by applying various machine learning and deep learning techniques, and the results calculated by the learning model were compared with the electromagnetic wave absorption characteristics obtained by 3D electromagnetic wave numerical analysis to evaluate the comparative advantages of each model. Most of the implemented models showed similar calculated results to the numerical results, but it was found that the Fully- Connected model could provide the most similar calculated results."
학생의 영어 자기 효능감이 인지적 학습 정도와 학습 성과에 미치는 영향: 교사 리더십의 조절 효과와 학습 동기부여의 매개 영향,2023,"['transformational leadership', 'English self-efficacy', 'intrinsic motivation', 'English learning performance', 'moderating effects', 'mediating impact', '변혁적 리더십', '영어 자기 효능감', '내적 동기부여', '영어 학습 성과', '조절 영향', '매개영향']",,"This research examined the roles of transformational leadership in the perspective of English education methodology. This study investigated the impact of a transformational leadership on the reinforcement of the student’s English self-efficacy, and the moderating effects of a transformational leadership on the relationships between the student’s English self-efficacy and the student’s intrinsic motivation to learn English. This study also examined the relationships among the student’s English self-efficacy, the student’s intrinsic motivation, and the student’s English education performance. The empirical questionnaires data were collected form first and second grade high school students in Daegu city. Finally, 192 questionnaires data were collected. The empirical results showed that consideration and influence, and intellectual stimulation, which were the dimensions of a transformational leadership, have a positive impact on the reinforcement of the student’s English self-efficacy. The positive effects of the English self-efficacy on the student’s intrinsic motivation were also confirmed. The moderating effects of a transformational leadership on the relationships between the student’s English self-efficacy and the intrinsic motivation to learn English were generally demonstrated. It was found that the student’s intrinsic motivation positively affects the student’s English education performance. The positive relationships among English self-efficacy, intrinsic motivation, and English education performance were empirically confirmed. Therefore, to improve the student’s English learning performance, various tools, which reinforce the student’s English self-efficacy, and realize the strong desire to learn English, were required in school."
"대학 행정관리자의 온정적 합리주의 리더십과  행정직원의 학습문화 수준, 자기효능감, 팔로워십 및  조직효과성 간의 구조적 관계",2023,"['대학행정', '온정적 합리주의 리더십', '조직효과성', '학습문화 수준', '자기효능감', '팔로워십', 'university administration', 'compassionate rationalism leadership', 'organizational effectiveness', 'level of learning culture', 'self-efficacy', 'followership']","본 연구의 목적은 대학 행정관리자의 온정적 합리주의 리더십과 행정직원의 학습문화 수준, 자기효능감, 팔로워십 및 조직효과성 간의 구조적 관계를 분석하는 것이다. 연구 목적을 달성하기 위해 전국 33개 대학의 행정직원을 대상으로 785개의 표본을 추출하였고 연구모델의 통계적 검증을 위하여 SPSS 26.0, AMOS 22.0 프로그램을 이용하여 구조방정식 등의 분석 방법을 활용하였다. 연구 분석 결과는 다음과 같다. 대학 행정관리자의 온정적 합리주의 리더십은 조직효과성에 직접적인 영향을 미쳤고 행정직원의 학습문화 수준, 자기효능감, 팔로워십을 매개하여 조직효과성에 이르는 경로도 영향을 미쳤다. 둘째, 대학 행정관리자의 온정적 합리주의 리더십은 행정직원의 팔로워십에 직접적인 영향을 미쳤고, 행정직원의 자기효능감 매개하는 경로와 학습문화 수준, 자기효능감을 거쳐 팔로워십 매개하는 경로도 간접적인 영향을 미쳤다. 셋째, 대학 행정관리자의 온정적 합리주의 리더십은 행정직원의 자기효능감에 직접적인 영향을 미쳤고, 학습문화 수준을 매개하여 자기효능감에 간접효과를 보였다. 넷째, 대학 행정관리자의 온정적 합리주의 리더십은 행정직원의 학습문화 수준에 직접효과를 미쳤다는 것이 확인되었다. 연구 결과를 통해 대학 행정의 조직효과성 향상을 위해서는 행정관리자의 온정적 합리주의 리더십을 강화할 필요가 있으며 행정직원의 학습문화 형성 및 지원을 통해 조직효과성을 개선할 수 있음을 확인하였다.","The purpose of this research was to identify and analyze the structural relationships between administrators’ compassionate rationalism leadership, administrative staff’s level of learning culture, self-efficacy, followership and organizational effectiveness in South Korean universities. To accomplish this research purpose, valid 785 data were extracted, as one sample, from a survey of administrative staff working at 33 universities in South Korea and the data analyses were performed, using SPSS Statistics 26.0 and SPSS AMOS 22.0 for the structural equation modeling(SEM). The research results were as follows. First, compassionate rationalism leadership had a effect on organizational effectiveness in a direct pathway and had a effect on organizational effectiveness in indirect pathways through parameters of administrative staff’s level of learning culture, self-efficacy and followership. Second, compassionate rationalism leadership had a directly effect on staff’s followership and had an indirectly effect on staff’s followership through a parameter of self-efficacy and through parameters of staff’s level of learning culture and self-efficacy. Third, compassionate rationalism leadership showed a effect on self-efficacy directly and a effect on self-efficacy mediated by a parameter of staff’s level of learning culture. Fourth, compassionate rationalism leadership was identified to affect staff’s level of learning culture positively and directly. the research results were drawn as follows. improve organizational effectiveness, it was considered that university administrators need to reinforce compassionate rationalism leadership for staff, it was identified that organizational effectiveness can be improved through forming and supporting learning culture for staff."
예술 중심 프로젝트 기반 학습(A-PBL)으로서 그림책 창작의 가능성 탐구,2023,"['프로젝트기반학습(PBL)', '예술중심 프로젝트기반학습', '그림책 창작', '미술과 교수학습', 'project based learning(PBL)', 'art centered project based learning(A-PBL)', 'teaching and learning in art education']","목적  그림책을 ‘삶 속의 예술’의 종합체로 간주하며, 예술로서의 그림책의 가치와 그림책을 창작하는 과정을 프로젝트기반 학습에 적용하여 실천한 사례를 탐구하고 그 가능성을 제안한다.방법  본 실행연구는 예술로서의 그림책 창작과정과 성찰보고서, 교수자의 피드백을 기반으로 분석하였으며 그림책이 지닌 미술작품으로서의 가치와 예술중심 프로젝트 기반학습으로서의 가능성과 시사점을 제시한다.결과  연구참여자들과 함께 예술중심 프로젝트기반학습(A-PBL)을 진행하였으며, 프로젝트 계획, 프로젝트 탐구, 프로젝트 제작, 프로젝트 발표의 과정을 통해 그림책이 최종 창작물로 나왔다.결론  본 연구는 예술중심 프로젝트 기반 학습의 가능성을 탐구하였다. 학습자들이 부담감 없이 도전적인 예술 창작에 몰두할 수 있도록 돕고, 협동학습을 하면서도 학습자들의 자기주도적 학습 및 창작능력을 함양할 수 있다는 면에서 유의미한 학습활동이 될 수 있다. 프로젝트기반학습의 경험은 팀워크를 개발하고 협동학습을 강화한다, 학습자가 주도적으로 교육과정을 구성하게한다. 교수자도 수행 중 맥락을 반영하여 프로젝트를 재구성한다. 학습자는 학습동기가 강화될 뿐 아니라 성찰의 자세를 배운다.","Objectives  In this study, Considering picture books as a synthesis of ‘art in life’, the value of picture books as art and the process of creating picture books as an art are applied to project-based learning to explore practical cases and suggest their possibilities.Methods  This action research analyzed based on the process of creating picture books as art, reflection reports, and feedback from the instructor.Results  Art centered project-based learning (A-PBL) was conducted with the research participants, and a picture book came out as a final creation through the process of project planning, project exploration, project production, and project presentation.Conclusions  The experience of project-based learning develops teamwork and reinforces cooperative learning, allowing learners to take the initiative in constructing the curriculum. The instructor also reconstructs the project by reflecting the context during execution. The learner not only strengthens the learning motivation but also learns an attitude of reflection."
주민주도 마을지향복지관 적용방안 연구,2023,"['지역 조직화', '주민 조직화', '주민주도', '마을지향복지관', '학습동아리', 'Local Organization', 'Resident Organization', 'Resident Initiative', 'Village-Oriented Welfare Center', 'Learning Club']","본 연구는 기존의 학습동아리와 차별화된 주민주도의 마을지향복지관이 운영되기 위해 필요한 요소, 명확한 리더십과 철학 정립, 주민역량 강화 양상 및 지속적 학습동아리 필요 요소를 분석함으로써 사회복지관에 적합한 학습동아리 모형을 제시하는데 목적이 있다. 분석 방법은 질적 조사의 사례분석이며, 연구자가 근무하였던 복지관에서 2년 동안 학습동아리에 참여한 5명을 연구 대상으로 비대면과 대면 방식의 인터뷰를 진행하였으며 그 결과는 다음과 같다.명확한 리더십과 철학 정립을 위해선 관장, 직원, 주민들까지 마을 지향의 철학과 방향성을 이해하고 공유해야 하며, 주민역량 강화는 책 읽기와 토론 등의 학습활동을 통해 서로의 차이점에 대한 성찰 및 이해와 지역사회 안에서의 작은 실천 등으로 나타나고 있으며, 지속적 학습동아리 필요요소로는 동아리 운영을 위한 지속적 예산지원, 다양한 연령층(특히 젊은 층)의 참여 확산, 자유로운 학습 분위기 등으로 나타났다.","This study analyzes the elements necessary to operate a resident-led village-oriented welfare center that is differentiated from existing learning clubs, the establishment of clear leadership and philosophy, the aspects of strengthening residents' capabilities, and the elements necessary for continuous learning clubs to develop a learning club model suitable for social welfare centers. The purpose is to present The analysis method is a case study of qualitative research, and non-face-to-face and face-to-face interviews were conducted with five people who participated in a learning club for two years at the welfare center where the researcher worked. The results are as follows.In order to establish clear leadership and philosophy, the director, staff, and residents need to understand and share the village-oriented philosophy and direction. Reinforcement of residents' capacity is shown through reflection and understanding of each other's differences through learning activities such as reading books and discussions, and small practices in the community. Elements necessary for continuous learning clubs include continuous budget support for club operation, expansion of participation of various age groups (especially young people), and free learning atmosphere."
모델 프리 강화학습 정책을 적용한 호기심 기반 TD-MPC,2023,"['Deep Reinforcement Learning', 'Model-based Reinforcement Learning', 'Model Predictive Control', 'Precise Control']","최근 모델 기반 강화학습 알고리즘 중 가장 높은 성능을 가지고 있는 TD-MPC는 학습 과정에서 모델 예측 제어와 DDPG 에이전트로부터 행동을 추출한다. 하지만 DDPG 에이전트는 추출된 행동은 환경에 적용되지 않고, 모델 예측 제어로부터 추출된 행동만 환경에 적용한다. 본 논문에서는 TD-MPC가 가지고 있는 DDPG 에이전트와 모델 예측 제어를 모두 고려하여 환경에 적용하는 이중 정책을 활용한 향상된 TD-MPC를 제안한다. 또한, 호기심 기반으로 탐험을 장려하여 이중 정책 사이에서 행동을 선택할 때 발생할 수 있는 활용의 편향을 해결하였다.DeepMind Control Suite의 여러 환경에서 제안하는 알고리즘이 기존의 TD-MPC보다 높은 샘플 효율성과 높은성능을 가지고 있음을 확인한다.",
물리교육을 위한 블럭코딩 기반의 기계학습 프로그래밍 기초,2023,"['Machine Learning', 'Block Coding', 'AI', '기계학습', '블럭코딩', '인공지능']","AI의 적용이 확대되면서 많은 영역에서 이를 활용하기 위한 노력이 활발하게 이루어지고 있으나, 상대적으로 학습해야 할 기초 이론의 분량과 프로그래밍의 복잡성으로 인하여 특히 물리교육 영역에서 학생들에게 AI의 기초를 이해시키기 위한 교육적 도입은 쉽지 않다. 이를 극복하기 위한 대안으로 최근 초중등교육에서 많이 사용되고 있는 블럭 코딩 기법을 이용하여, 기계학습 프로그래밍 이론의 기초가 되는 제곱 오차해석에 대한 쉬운 접근 방법을 제시하고 이를 바탕으로 간단한 게임 제작을 통하여 기계학습을 구성하는 과정에 대한 기초를 학생들이 스스로 형성하게 하여 AI를 물리학 연구 및 물리 교육에 활용하는데 필요한 이해를 높이는데 기여하는 것이 본 연구의 목표이다.","As the application of artiﬁcial intelligence (AI) gains popularity, its applications in various areas are actively explored. However, the introduction of AI to education in physics presents a challenge because of its many diﬃculties. To overcome these diﬃculties, we suggest an easy approach for square error analysis, which is the basis of machine learning programming theory that uses block coding techniques that have recently been widely used in elementary and secondary education. On this basis, the manner of introducing reinforced learning through simple game production can be presented. This study aims to contribute to the enhanced understanding required for the application of machine learning in physics research and education by helping students form the basis of understanding AI using the block coding method."
콘크리트 탄산화 및 열효과에 의한 경년열화 예측을 위한 기계학습 모델의 정확성 검토,2023,"['Machine learning', 'Concrete carbonation', 'Concrete high temperature', 'Compressive strength', 'Carbonation depth']",,"Numerous factors contribute to the deterioration of reinforced concrete structures. Elevated temperatures significantly alter the composition of the concrete ingredients, consequently diminishing the concrete's strength properties. With the escalation of global CO2 levels, the carbonation of concrete structures has emerged as a critical challenge, substantially affecting concrete durability research. Assessing and predicting concrete degradation due to thermal effects and carbonation are crucial yet intricate tasks. To address this, multiple prediction models for concrete carbonation and compressive strength under thermal impact have been developed. This study employs seven machine learning algorithms—specifically, multiple linear regression, decision trees, random forest, support vector machines, k-nearest neighbors, artificial neural networks, and extreme gradient boosting algorithms—to formulate predictive models for concrete carbonation and thermal impact. Two distinct datasets, derived from reported experimental studies, were utilized for training these predictive models. Performance evaluation relied on metrics like root mean square error, mean square error, mean absolute error, and coefficient of determination. The optimization of hyperparameters was achieved through k-fold cross-validation and grid search techniques. The analytical outcomes demonstrate that neural networks and extreme gradient boosting algorithms outshine the remaining five machine learning approaches, showcasing outstanding predictive performance for concrete carbonation and thermal effect modeling."
시각탐색에서 시간적 맥락에 따른 위치 확률 학습,2023,"['temporal context', 'location probability learning', 'spatial attentional bias', 'visual search', '시간적 맥락', '위치 확률 학습', '공간 주의 편향', '시각탐색']","위치 확률 학습(Location probability learning) 효과란 시각탐색 시 표적이 특정 위치에 빈번하게 출현할 때 해당 위치로의 공간 주의가 편향됨으로써 탐색이 빨라지는 현상을 일컫는다(Jiang et al., 2013). 본 연구는 결합(conjunction) 탐색에서 시간적 맥락에 따라 공간 주의가 유연하게 편향되는지 알아보고자 수행되었다. 실험 1에서 표적은 응시점 이후 시간적 맥락(300 ms / 1300 ms)에 따라 두 개의 특정 사분면에서 높은 빈도로 출현하였다. 실험 1의 결과, 맥락과 상관없이 공간 주의가 두 개의 고빈도 사분면으로 편향되었다. 실험 2에서는 시간적 맥락을 강화하여 표적이 첫 번째 또는 두 번째 탐색 화면부터 제시되었으며 그 결과, 맥락 특정적인 공간 주의 편향이 관찰되었다. 실험 3은 실험 2에 혼입되어있는 순서와 길이의 효과 크기 비교를 통해 순서의 영향력을 재확인하였다. 본 결과는 위치 확률 학습에서 탐색 화면이 시간적 순서(temporal order) 정보를 지닐 때 강력한 시간적 맥락으로 사용되며, 시공간이 존재하는 역동적 환경에서 인간의 학습 기전에 시간적 맥락이 작동하는 방식에 대한 새로운 통찰을 제공하고 있다.","The location probability learning effect refers to the phenomenon where spatial attention is biased towards a specific location, resulting in faster visual search, when a target appears frequently at that location (Jiang et al., 2013). This study aimed to investigate whether spatial attention is flexibly biased by temporal context in conjunction search. In Experiment 1, the target appeared with high frequency in two specific quadrants depending on the temporal context (300 ms / 1300 ms) after fixation. The results of Experiment 1 showed that spatial attention was biased towards the two high-frequency quadrants regardless of the temporal context. In Experiment 2, by reinforcing the temporal context, the target was presented from either the first or second search display depending on the context, and the results showed that context-specific spatial attention bias occurred. Experiment 3 reaffirmed the influence of the order to investigate specifically the effect sizes of the temporal order and duration confounded in Experiment 2. These results imply that the search display with temporal order information is used as a powerful temporal context in location probability learning, and provide new insights into the way temporal context operates in the human learning mechanism in dynamic environments where space and time coexist."
U-net 딥러닝 기법을 활용한 PVA 섬유 보강 시멘트 복합체의 섬유 분리,2023,"['섬유 보강 시멘트 복합체', '미세구조', '이미지 분리', '딥러닝', 'U-net', 'fiber-reinforced cementitious composite', 'microstructures', 'image segmentation', 'deep learning', 'U-net']","PVA 섬유 보강 시멘트 복합체는 매우 복잡한 미세구조를 가지고 있으며, 재료의 거동을 정확히 평가하기 위해서는 미세구조 특성을 반영하여 실제 실험과 시너지효과를 내며 효율적인 재료 설계를 가능하게 하는 해석 모델의 개발이 중요하다. PVA 섬유 보강 시멘트 복합체의 역학적 성능은 PVA 섬유의 방향성에 큰 영향을 받는다. 그러나 마이크로-CT 이미지로부터 얻은 PVA 섬유의 회색조 값을 인접한 상과 구분하기 어려워, 섬유 분리 과정에 많은 시간이 소요된다. 본 연구에서는 섬유의 3차원 분포를 얻기 위하여 0.65μm3의 복셀 크기를 가지는 마이크로-CT 이미지 촬영을 수행하였다. 학습에 사용될 학습 데이터를 생성하기 위해 히스토그램, 형상, 그리고 구배 기반 상 분리 방법을 적용하였다. 본 연구에서 제안된 U-net 모델을 활용하여 PVA 섬유 보강 시멘트 복합체의 마이크로- CT이미지로부터 섬유를 분리하는 학습을 수행하였다. 훈련의 정확도를 높이기 위해 데이터 증강을 적용하였으며, 총 1024개의 이미지를 훈련 데이터로 사용하였다. 모델의 성능은 정확도, 정밀도, 재현율, F1 스코어를 평가하였으며, 학습된 모델의 섬유 분리 성능이 매우 높고 효율적이며, 다른 시편에도 적용될 수 있음을 확인하였다.","The development of an analysis model that reflects the microstructure characteristics of polyvinyl alcohol (PVA) fiber-reinforced cementitious composites, which have a highly complex microstructure, enables synergy between efficient material design and real experiments. PVA fiber orientations are an important factor that influences the mechanical behavior of PVA fiber-reinforced cementitious composites. Owing to the difficulty in distinguishing the gray level value obtained from micro-CT images of PVA fibers from adjacent phases, fiber segmentation is time-consuming work. In this study, a micro-CT test with a voxel size of 0.65 μm3 was performed to investigate the three-dimensional distribution of fibers. To segment the fibers and generate training data, histogram, morphology, and gradient-based phase-segmentation methods were used. A U-net model was proposed to segment fibers from micro-CT images of PVA fiber-reinforced cementitious composites. Data augmentation was applied to increase the accuracy of the training, using a total of 1024 images as training data. The performance of the model was evaluated using accuracy, precision, recall, and F1 score. The trained model achieved a high fiber segmentation performance and efficiency, and the approach can be applied to other specimens as well."
핵심역량 기반 교양교육의 만족도 및 학습성과와 대학생의핵심역량 간의 연계성 분석: D 대학을 중심으로,2023,"['Core competency', 'Satisfaction with liberal arts education', 'Learning outcomes of liberal arts education', 'IPA(Importance performance analysis)', '핵심역량', '교양교육 만족도', '교양교육 학습성과', 'IPA']","본 연구는 대학에서 설정한 핵심역량 기반 교양교육에 대해 대학생이 얼마나 만족하는지의 정도와 자신이 지각한 학습성과 수준이 이들의 핵심역량 수준과 연계된 정도를 상관, 회귀 및 IPA 분석을 통해 살펴보고자 하였다. 이를 위해 D 대학 학생을 대상으로, DEU 교양교육의 만족도 및 학습성과 문항과 DEU-CCDS(핵심역량 척도)를 활용하여 응답하도록 하였다. 그 결과, ‘민주적의사소통’핵심역량 구성요소를 제외한 모든 변수에서 유의미한 상관관계를 보였다. 또한, 교양교육의 만족도및 학습성과가 ‘민주적의사소통’을 제외한 모든 핵심역량을 유의미하게 설명하는 것으로 나타났다.한편, IPA 분석 결과, 교양교육의 만족도와 관련된 핵심역량 구성요소들은 유지강화(5개), 지속유지(1개) 및 점진개선(4개) 영역에 분포하였으며, 교양교육의 학습성과와 관련된 핵심역량 구성요소들은 유지강화(5개), 지속유지(1개), 점진개선(3개) 및 중점개선(1개) 영역에 분포하는 것으로 나타났다. 이는 교양교육의 만족도 및 학습성과를 통해 교양교육의 질적 수준을 확인함과 동시에 교양교육의 질적 향상을 위한 핵심역량 구성요소를 살펴보았다는 점에서의 의의가 있다.","This study attempted to examine the degree to which college students’ satisfaction with liberalarts education based on core competencies set for each university and perceived learningperformance level are related to the core competency level(correlation, regression, and IPA). Tothis end, students at D university were asked to respond using DEU liberal arts educationsatisfaction and learning outcomes questions and the DEU-CCDS(core competency scale). As aresult, there was a significant correlation between all variables except for 'democraticcommunication' of core competencies. In addition, it was found that the satisfaction andlearning outcomes of liberal arts education significantly explained all core competencies exceptfor ‘democratic communication’. On the other hand, as a result of IPA analysis, the corecompetency components related to the satisfaction of liberal arts education were distributed inthe areas of maintenance reinforcement(5), continuity maintenance(1), and progressimprovement(1). In addition, the core competency components related to the learning outcomesof education were distributed in the areas of maintenance reinforcement(5), continuitymaintenance(1), progressive improvement(3), and focus improvement(1). This is significant inthat the quality level of liberal arts education was confirmed through the satisfaction andlearning outcomes of liberal arts education, and at the same time the core competencycomponents for enhancing the quality of liberal arts education were examined."
온라인 교육환경에서 교수에 대한 신뢰가 학습몰입 및 수강지속의사에 미치는 영향: 항공·관광계열 전공 대학생을 대상으로,2023,"['Online Education', 'Trust in Professors', 'Learning Engagement', 'Intention of Course continuity', '온라인 교육', '교수신뢰', '학습몰입', '수강지속의사']",,"Purpose This study aims to identify the impact of trust in professors on the willingness to engage in learning and continue attending classes for college students who have experienced non-face-to-face online classes at universities. Through this, this study is expected to identify the importance of trust in professors and help reinforce online education as well as enhance its quality.Methods Survey were distributed a total of 275 copies, with 250 copies used as data for final analysis and excluding those invalids. For statistical analysis, frequency analysis, reliability analysis, factor analysis and regression analysis were performed using SPSS 26.0 and process macro v4.2.Results The result of the analysis showed that, first, trust in professors has a significant effect on learning engagement; second, learners’ trust in the faculty exerts a substantial influence on the intention of course continuity; and thirdly, learning engagement has a considerable impact on the intention to continue taking classes.Conclusion The importance of online classes in universities is becoming increasingly emphasized, and a strong sense of faculty trust, especially in non-face-to-face online classes, is emerging as an important factor in the success or failure of online education. Therefore, in order for students to increase their confidence in the professor, it is necessary for lecturers to have expertise in the subject of major, fairness in grading practices, and constant interest and interaction with students."
뇌 발달 이론 및 뇌 기반 학습 관점에서 살펴본  영유아학교의 교육 실천 방향 탐색,2023,"['뇌 발달', '뇌 기반 학습', '교육 실천', '영유아학교', 'Brain Development', 'Brain-based Learning', 'Educational Practice', 'Early Childhood School']","본 연구의 목적은 모든 영유아의 출발선 평등과 유아교육과 보육의 공공성 강화를 위해 우리나라에서 유보통합 정책이 논의되고 있는 시점에서 뇌 발달 이론과 뇌 기반 학습 관점에 근거하여 영유아학교의 교육 실천 방향을 제안하는 것이다. 이를 위해 뇌 발달 이론 및 뇌 기반학습 관련 문헌을 고찰한 후 영유아학교의 교육 실천 방향으로 중요하게 다뤄야 할 점을 살펴보았다. 주요 연구 결과는 다음과 같다. 첫째, 영유아의 뇌 발달 특성을 고려한 교육과정 운영을 제안하였다. 둘째, 정서적 안정감과 원활한 상호작용을 풍부하게 지원할 수 있는 교수 환경을 제안하였다. 셋째, 뇌 발달 이론에서 강조하고 있는 영양, 운동, 수면을 고려한 일과 운영을제안하였다. 마지막으로 뇌 기반 학습 실천을 위한 교사와 부모의 역량 제고를 제안하였다.","This research aims at suggesting the direction to practice education in the early childhood schools based on brain development theories and brain-based learning viewpoints. It attempts to reflect the current Korean policy discussions to integrate early childhood education and childcare for the equality of all infants’ starting line and for the reinforcement of early public childhood education and childcare. For this purpose, brain development theories and the literature related to brain-based learning were examined. Important issues for the direction to practice the education in the early childhood schools were addressed. As the study results, first, the curriculum in which the characteristics of young children's brain development was considered was indicated. Second, the teaching environment where emotional stability and interaction can be supported was proposed. Third, the daily schedule taking nutrition, exercise and sleeping into consideration, which are emphasized by the brain development theories, was suggested. Finally, for the practice of brain-based learning, the improvement of teachers’ and parents’ competencies for the practice of brain-based learning was suggested."
전이학습을 활용한 군집제어용 강화학습의 효율 향상 방안에 관한 연구,2023,,,"Swarm has recently become a critical component of offensive and defensive systems. Multi-agent reinforcement learning(MARL) empowers swarm systems to handle a wide range of scenarios. However, the main challenge lies in MARL's scalability issue - as the number of agents increases, the performance of the learning decreases. In this study, transfer learning is applied to advanced MARL algorithm to resolve the scalability issue. Validation results show that the training efficiency has significantly improved, reducing computational time by 31 %."
멀티 에이전트 심층 강화학습 기반 CSMA/CA 프로토콜,2023,"['CSMA/CA protocol', 'MAC protocol', 'Multi Agent', 'Deep Reinforcement Learning', 'MADDPG']",본 논문은 CSMA/CA 프로토콜에 멀티 에이전트강화학습을 적용하여 성능을 비교 분석한다. 기존CSMA/CA 프로토콜은 랜덤 백오프 방식을 사용하여백오프 값이 0인 단말들만 패킷 전송을 시도하여 채널에 접속 중인 단말의 수가 많을수록 패킷 충돌수가증가하여 성능이 저하되는 문제가 있었다. 본 논문에서는 채널에 접속한 각각의 단말들을 하나의 에이전트로 설정하고 채널에 존재하는 모든 에이전트가 채널 상태를 관찰한 후 채널 상태에 맞춰 전송 성공률이 높은 Contention Window(CW)를 결정하여 성능을개선 한다.,
3D 아바타를 사용한 영어수업의 교육적 기대 효과 연구:  학습 동기 중심으로,2023,"['English education', 'Motivation', 'Metaverse', '3D Avatars', 'ARCS theory']",,"The newly revised 2022 curriculum by Korean ministry of education suggested adoption of digital textbook and emphasized updated digital tools in public education in general. As a move in synch, the goal of our action research is to investigate the effectiveness of 3D Avatar as a metaverse digital tool in English education. We adopted theoretical framework of Keller’s ARCS (attention, relevance, confidence, and satisfaction) and applied Keller’s Course Interest Survey(CIS) model as a pre-test and post-test in our research. To see the actual effectiveness of 3D AVATAR model in English class, we taught eight periods of 45 min. middle school English ZOOM classes for two months in January and February 2023. The survey showed the following five positive points: the remarkable concentration in class participation, increase of problem-solving ability, reinforcement of digital refinement, authenticity of students’ social participation in digital world, and creative self-expression techniques. Therefore, we suggest this type of 3D metaverse edu-tech is quite applicable and effective in upcoming English education."
강화학습을 이용한 실내 자율주행 시스템,2023,"['Autonomous Driving', 'Lidar', 'Reinforcement Learning', 'Mobile Vehicles', 'Image Sensor']","자율주행은 미래 이동체의 핵심 기술 중 하나로 강화학습은 주행 에이전트가 환경과 상호작용하며 최적의 행동을 학습하는 데 유용한 도구이다. 본 논문은 실내 환경에서 강화학습을 이용하여 자율주행을 구현하는 방법으로, 실시간으로 변화하는 실내 자율주행 환경을 인식하고 주변 사물의 출현에 대응하여 회피하며 사전 설정된 다수의 목적지에 도달하기 위한 방법을 제안한다. 이 기술은 라이다 센서와 영상 센서를 탑재한 이동체가 실내를 반복적으로 순회하면서 강화학습 모듈이 지형과 지물을 학습함으로써 실내 환경을 스스로 인지한다. 우선, 주행 환경을 2D 시뮬레이션으로 모델링 하고, 주행 경로와 장애물을 정확하게 표현하며, 강화학습 주행 에이전트는 강화학습 알고리즘을 사용하여 환경에서 행동을 수행하고 보상을 받는다. 에이전트는 자율주행을 위한 최적 정책을 학습하고, 에피소드를 반복하면서 환경에서 행동을 수행하고 보상을 최대화하기 위한 정책을 학습한다. 실제 강화학습 모듈을 탑재한 자율주행 차량은 실내 주행을 수행하며 환경의 변화에 적응한다. 연구 결과, 강화학습을 통해 자율주행 시스템이 동적 환경에서 안정적이고 효율적으로 작동할 수 있음을 입증하였다. 이러한 연구는 자율주행 기술의 발전과 미래 도시 모빌리티에 기여할 것으로 기대된다.","Autonomous driving is one of the key technologies for future mobile vehicles, and reinforcement learning is a useful tool for driving agents interacting with the environment and learning optimal behavior. This paper presents a method of applying reinforcement learning to autonomous driving in an indoor environment. It recognizes an indoor autonomous driving environment that changes in real time; it deals with the unexpected appearances of objects, and returns to a number of preset destinations. We suggest a method to reach. This technology uses reinforcement learning in which a mobile device, equipped with a lidar sensor and an image sensor, is programmed to recognize the indoor environment on its own by repeatedly traveling around the room to learn the layout and features. First, the driving environment is modeled in a 2D simulation; the driving path and obstacles are accurately expressed, and the reinforcement learning driving agent uses a reinforcement learning algorithm to perform actions in the environment and get rewards. The agent learns the optimal policy for autonomous driving, performs actions in the environment through repeated episodes, and learns a policy to maximize rewards. The final model is deployed in an actual autonomous vehicle to drive indoors and adapt to changes in the environment. Results demonstrate that this autonomous driving system can operate stably and efficiently in a dynamic environment through reinforcement learning. This research is expected to contribute to the development of autonomous driving technology and future urban mobility."
강화학습을 이용해 개발한 준능동 제어알고리즘의 성능평가,2023,"['Semi-Active Control Algorithm', 'Reinforcement Learning', 'Seismic Response Control', 'Semi-Active Mid-Story Isolation System', 'Skyhook', 'Groundhook']",강화학습은 최근까지 다양한 능동제어 문제에 적용되어 우수한 제어성능을 보여 왔다. 그러나 강화학습을 이용하여 개발한 준능동 제어알고리즘에 대한 연구는 현재까지 거의 수행된 바 없다. 따라서 본 연구에서는 강화학습을 이용하여 준능동 제어알고리즘을 개발하였다. 강화학습은 주어진 환경과 상호작용을 하는 에이전트가 현재의 상태에서 어떤 행동을 취하는 것이 최고의 보상을 받는지 학습하여 누적 보상을 최대화 하는 방향으로 학습이 진행된다. 이러한 강화학습을 적용할 예제 건물로는 MR 감쇠기를 이용하여 구성된 준능동 중간층 면진 시스템이 적용된 26층 빌딩 구조물을 사용하였다. 수치해석을 위해서 인공 지진하중을 생성하였다. 생성된 예제 구조물과 지진하중을 사용해서 강화학습의 환경을 생성하였다. 생성된 환경과 상호작용을 할 에이전트는 준능동 제어알고리즘으로 설정하였다. 강화학습의 보상은 최대 층간변위와 면진층 층간변위를 저감시킬 수 있도록 설계하였다. 스카이훅 (Skyhook)과 그라운드훅 (Groundhook) 제어알고리즘을 이용해서 제어성능을 비교 및 검토 하였다. 수치해석 결과 제안된 제어알고리즘은 준능동 중간층 면진시스템이 설치된 예제구조물의 지진응답을 효과적으로 저감시킬 수 있는 것을 본 연구를 통해서 확인할 수 있었다.,"Reinforcement learning has shown good control performance for various active control problems. However, research has rarely been conducted on a semi-active control algorithm developed using reinforcement learning. In the reinforcement learning process, an agent is trained by interacting with a given environment and learns what actions receive the most rewards in its current state to maximize the sum of the rewards. In this study, a semi-active control algorithm was developed using reinforcement learning. In order to apply reinforcement learning, a 26-story building structure was constructed as an example by using a semi-active mid-story isolation system with a magnetorheological damper. Artificial ground motions were generated for numerical simulation. The example building structure and seismic excitation were used to make an environment for reinforcement learning. An agent interacting with the constructed environment was set as a semi-active control algorithm. The reward of reinforcement learning was designed to reduce the peak story drift and the isolation story drift. Skyhook and groundhook control algorithms were used for comparative study. Based on numerical results, this paper shows that the proposed control algorithm can effectively reduce the seismic responses of building structures with a semi-active mid-story isolation system."
강화학습을 활용한 작업 분할이 가능하고 설비 제약이 존재하는 동종 병렬 시스템의 총 납기 지연 최소화,2023,"['Scheduling', 'Reinforcement Learning', 'Job Split', 'Machine Eligibility Constraint', 'Minimizing Total Tardiness', 'Machine Learning']",,"Machine scheduling problems are one of the important issues in manufacturing systems. In particular, in complex conditions such as job split and machine eligibility constraint, it becomes challenging to obtain appropriate solutions and it has been proven as a NP-hard problem. Previously, heuristic and metaheuristic techniques were mainly used to solve machine scheduling problems. Recently, applying reinforcement learning to scheduling problems to overcome the limitations of the two techniques has been receiving attention. In this study, we propose a methodology to minimize total tardiness by using pointer network-based reinforcement learning. Job sequences are determined through reinforcement learning. Machine selection and job split is determined with heuristic methods to reduce the solution space while effectively minimizing total tardiness. The methodology of this study showed higher performance than COVERT, ATCS, GA, and it is expected to be more versatile than existing reinforcement learning methods because it does not require re-learning according to the changes in task lengths."
32Bit 전용 클라이언트 게임의 AI 모델을 위한 ALNN기반 강화학습 프레임워크: 오목 게임 중심으로,2023,"['Reinforcement Learning(강화학습)', 'Game AI', 'Deep Learning(딥러닝)', 'Gomoku(오목)']","DQN이 Atari 게임들을 성공적으로 플레이한 사례는, 게임에 딥러닝을 적용할 수 있다는 희망을 보여 준다. 게임 자체 내에 딥러닝 기반 AI 모델을 적용하기 위해서는 64Bit 클라이언트 게임으로 개발되어야 한다. 게임 회사에서는 장기간에 걸쳐 32Bit 클라이언트 게임을 64bit 클라이언트 게임으로 바꾸고 있지만, 그 사이, 사용자들에게 발전된 NPC를 제공하기 위해서는 32Bit 클라이언트 게임에서도 사용할 수 있는 강화학습 방법이 필요하다. 본 논문에서는 강화학습의 보상 방식을 ALNN 알고리즘에 적용하여 32Bit 클라이언트 게임에서도 강화학습을 할 수 있는 프레임워크를 제안한다. 제안된 프레임워크는 32Bit 클라이언트 오목 게임에 적용하여 성능을 검증한다.","The successful play of Atari games by DQN shows the hope of applying deep learning to the game. In order to apply a deep learning-based AI model within the game itself, it must be developed as a 64Bit client game. Game companies are changing 32-bit client games to 64-bit client games over the long term. However, in the meantime, reinforcement learning methods that can be used in 32-bit client games are needed to provide advanced NPCs to users. This paper proposes framework that can perform reinforcement learning even in 32-Bit client games by applying the compensation method of reinforcement learning to the ALNN algorithm. The probability of the next action is adjusted through compensation."
심층 강화학습을 이용한 단순 가공 형상의 설계이력 재구성,2023,"['Deep Reinforcement Learning(심층 강화학습)', 'Design History(설계이력)', 'Reconstruction(재구성)']",,"When CAD models are saved to the files in standard file formats using commercial CAD programs, the design history is not saved with them. This lack of design history causes the difficulties in modifying the CAD models, resulting in increased industrial costs. To address this problem, a novel method was proposed for reconstructing the design history from three-dimensional CAD models that do not have the design history, using deep reinforcement learning. Deep reinforcement learning is a form of machine learning that combines reinforcement learning and deep learning techniques. To achieve this, we define the states, actions, and rewards, and determine the optimal policy using a combination of soft actor-critic (SAC) and multi-layer perceptron (MLP). To verify the proposed method, we implement it and present the experimental results."
강화학습의 신속한 학습을 위한 변이형 오토인코더 기반의 조립 특징 추출 네트워크,2023,"['Robotic Assembly', 'Reinforcement Learning', 'Deep Learning']",,"Since robotic assembly in an unstructured environment is very difficult with existing control methods, studies using artificial intelligence such as reinforcement learning have been conducted. However, since long-time operation of a robot for learning in the real environment adversely affects the robot, so a method to shorten the learning time is needed. To this end, a method based on a pre-trained neural network was proposed in this study. This method showed a learning speed about 3 times than the existing methods, and the stability of reward during learning was also increased. Furthermore, it can generate a more optimal policy than not using a pre-trained neural network. Using the proposed reinforcement learning-based assembly trajectory generator, 100 attempts were made to assemble the power connector within a random error of 4.53 mm in width and 3.13 mm in length, resulting in 100 successes."
심층강화학습 기반의 경기순환 주기별 효율적 자산 배분 모델  연구,2023,"['Portfolio Theory', 'Deep Reinforcement Learning', 'Business Cycle', 'Asset Allocation']",,"Purpose: This study presents a research approach that utilizes deep reinforcement learning to construct optimalportfolios based on the business cycle for stocks and other assets. The objective is to develop effectiveinvestment strategies that adapt to the varying returns of assets in accordance with the business cycle.Methods: In this study, a diverse set of time series data, including stocks, is collected and utilized to traina deep reinforcement learning model. The proposed approach optimizes asset allocation based on the businesscycle, particularly by gathering data for different states such as prosperity, recession, depression, and recoveryand constructing portfolios optimized for each phase.Results: Experimental results confirm the effectiveness of the proposed deep reinforcement learning-basedapproach in constructing optimal portfolios tailored to the business cycle. The utility of optimizing portfolioinvestment strategies for each phase of the business cycle is demonstrated.Conclusion: This paper contributes to the construction of optimal portfolios based on the business cycle usinga deep reinforcement learning approach, providing investors with effective investment strategies that simultaneouslyseek stability and profitability. As a result, investors can adopt stable and profitable investment strategiesthat adapt to business cycle volatility."
강화학습 기반의 위성통신 빔호핑 최적화 기법,2023,"['satellite communications', 'beam-hopping', 'reinforcement learning', 'regret minimization']",,"In this paper, we suggest a reinforcement learning algorithm in satellite-aided communication system. Satellite-aided communication are drawing attention because it can increase stability and robustness of wireless communication. To improve the efficiency of satellite-aided communication, beamhopping method is introduced. In beamhopping, satellite beams are divided and operated in time-based system. The actual efficiency of beamhopping can be depend on the hopping pattern. To determine beamhopping pattern, we introduced multiplay Thompson sampling which is a family of reinforcement learning. We mathematically modeled the features of satellite communication and then applied reinforcement learning. By means of simulations, the performances of proposed learning were analyzed in terms of capacity and regret."
강화학습을 이용한 생성형 한글 공감 대화 챗봇 연구,2023,"['우울증', '강화학습', '자연어처리', '언어모델', '공감 대화', 'Depression', 'Reinforcement Learning', 'NLP', 'Language model', 'Empathetic Dialogue']","본 연구는 목적 지향 대화, 생성형 언어 모델, 강화학습을 기반으로 한국어 공감 대화에 특화된 챗봇의 개발을 목적으로 한다. 본 연구는 웰니스 공감 대화 데이터셋과 ChatGPT API를 통해 자체 생성한 데이터셋을 활용하여 언어 모델의 파인튜닝을 진행하였다. 이후 답변 생성과 human feedback을 이용한 Reward 라벨링을 통해 강화학습에 사용할 데이터셋을 생성하였다. 강화학습을 통해 언어 모델의 파라미터 튜닝을 진행하여 챗봇의 성능을 개선하였다. 실험 결과, 강화학습을 통한 언어 모델 파라미터 튜닝은 공감 대화에서 효과적으로 활용될 수 있음을 보여주며, 감정적인 지원이 필요한 사용자에게 공감적인 대화를 제공하는 능력을 갖춘 챗봇의 성능을 향상시킴이 확인되었다.","This study aims to develop a chatbot specialized for Korean empathy conversation based on task-oriented dialogue, generative language model, and reinforcement learning. This study fine-tuned the language model using the wellness dataset and the self-generated dataset through the ChatGPT API. After that, we created a dataset for reinforcement learning using human feedback. The performance of the chatbot was improved by tuning parameter through reinforcement learning. Experiments have shown that tuning language models parameter through reinforcement learning can be effectively used in empathy conversations. It has also been shown that the improvement of the performance of chatbots provides empathetic dialogue to users who need emotional support."
유니티를 이용한 스마트 면진제어 시스템의 강화학습 환경개발,2023,"['Smart Base Isolation System', 'Unity Game Engine', 'Structural Control Algorithm', 'Reinforcement Learning', 'Seismic Response Control']",근래에 강화학습을 이용해서 구조제어시스템의 제어알고리즘을 개발하고자하는 다양한 연구가 수행되고 있다. 강화학습은 주어진 외부 환경과 상호작용을 하는 에이전트가 현재의 상태에서 어떤 행동을 취하는 것이 최적인지 학습한다. 본 연구에서는 최근 여러 공학 분야에 활용되기 시작한 유니티 게임엔진을 활용해서 구조제어시스템의 강화학습 환경을 구성하고 구조제어분야에서 활용 가능성을 검토해보았다. 이를 위해서 본 연구에서는 스마트 면진제어 시스템을 유니티 물리엔진을 이용해서 구성하고 이를 제어하는 알고리즘을 에이전트로 개발하였다. 에이전트의 행동으로는 스마트 면진제어시스템을 제어할 명령전압으로 하였고 면진된 구조물의 응답이 저감되면 높은 보상을 받을 수 있도록 설계하였다. 유니티 환경에서 구성된 진동대에 인공지진하중을 가하여 시뮬레이션을 수행하였다. 개발된 시스템을 검토한 결과 유니티를 이용해서 개발한 환경을 사용하여 스마트 면진제어시스템의 제어알고리즘을 강화학습을 이용해서 개발할 수 있음을 확인할 수 있었다.,"Recently, various research has been conducted to develop a control algorithm for a structural control system using reinforcement learning. Reinforcement learning trains an agent to take an optimal action in its current state by interacting with a given environment. The Unity game engine has recently been used in various engineering fields. In this study, it was used to construct a reinforcement learning environment for a structural control system, and the possibility of its application to structural control was evaluated. To this end, a smart base isolation control system was constructed using the Unity physical engine, and a control algorithm for an agent was developed. The agent provides a command voltage to control a smart base isolation control system. The reward was designed to be increased when the response of the isolated structure was reduced. An artificial earthquake was applied to a shaking table modeled in the Unity environment for simulation. The results show that a control algorithm for a smart base isolation control system can be developed using reinforcement learning based on the Unity environment."
DRL-based intersection traffic efficiency enhancement utilizing 5G-NR-V2I data,2023,['Deep reinforcement learning5G-NR-V2X5G-NR-V2ITraffic light controlTraffic efficiency'],,"Recent research on reinforcement learning (RL) based traffic management shows promising results, yet it is a significant issue due to increasing volume of traffic and lack of real time traffic information. Improvements of RL algorithms and vehicle-to-everything (V2X) communications technologies are creating new prospects to achieve better traffic efficiency. This paper proposes a new method, namely Vehicle-to-Infrastructure based Traffic Signal Control (V2I-TSC), to capture realistic traffic state using vehicle-to-infrastructure (V2I) communications under 5G-NR-V2X paradigm. It uses single agent RL framework to optimize a traffic signal control which is trained and evaluated through Simulation of Urban MObility (SUMO) simulator. The experimental results show that our proposed method enhances traffic efficiency at the intersection compared to the general traffic control method."
목표 기반 시각적 이동 작업을 위한 시각적 맥락정보 임베딩과 교착상태 처리,2023,"['Visual navigation', 'Deep reinforcement learning', 'Visual context', 'Reward shaping', 'Deadlock recovery']",,"In this paper, we propose a novel deep neural network-based agent model, (VCENet), for performing target-driven visual navigation tasks. Most recent agent models for visual navigation try to recognize the real-time task context by using only objects and their relationships detected from RGB input images. However, such object-oriented visual context does not contain detailed information about the background scene, which is important for ground navigation. Moreover, it may result in a misrecognized context due tobecause of errors inof the object and relation detectors. To overcome these problems, the proposed VCENet model represents the real-time task context by using as the appearance and geometric features of the background scene extracted from RGB-D input images well as the object relation features derived through from graph embedding. Many existing models, which learn an action policiesy based upon on reinforcement, learning, do not provide any reward functions to avoid deadlocks ahead during of navigation or any effective deadlock recovery policyy learning mechanisms to escape the deadlocks. To address these problems, the proposed VCENet model provides not only reward functions for deadlock avoidance and recovery, but also a deadlock recovery policy based on imitation learning. Conducting a variety ofvarious experiments in photo-realistic virtual indoor environments provided by the 3D simulator AI2THOR, we made sure ofdemonstrated the superiority of the proposed VCENet model."
동적 저궤도 위성 네트워크에서 실시간 라우팅을 위한 FPGA 기반 컨볼루션층 추론 병렬화 기술,2023,"['LEO satellite network routing', 'deep reinforcement learning', 'FPGA', 'parallelization', '.']",,"This paper addresses the real-time routing problem in Low Earth Orbit (LEO) satellite networks. Existing routing algorithms have been found to struggle to adapt effectively to dynamic satellite network environments. As such, this study proposes a reinforcement learning-based routing approach and implements it using a dueling deep Q-network model. However, the inference process on satellites faces challenges in meeting real-time requirements due to limited computational capabilities. To resolve this, we propose an approach that accelerates inference speed by parallelizing the convolutional layer's inference process. Experimental results show that our proposed method has reduced the computation time of the convolutional layer by 90.2% and the total algorithm execution time by 29.0% compared to the existing methods."
DDQN을 활용한 강화학습 기반의 다기능 레이더 임무 스케줄링 방법,2023,"['Multi-Function Radar', 'Radar Resource Management', 'Reinforcement Learning', 'Double Deep Q Network', 'Task Scheduling']","다기능 레이더(MFR, Multi-Function Radar)의 발전으로 한정된 자원을 가진 환경에서 효율적으로 레이더의 성능을 향상시키기 위한 레이더 자원관리 방법은 지속적으로 연구되는 분야이다. 레이더 임무 스케줄링은 자원관리 방법 중 핵심적인 요소로서 이를 해결하기 위한 다양한 알고리즘이 연구되고 있다. 하지만 기존 알고리즘은 성능 최적화의 어려움 혹은 다양한 환경 반영의 어려움 등 한계점을 가지고 있다. 본 연구에서는 다양한 파라미터를 가진 레이더 임무환경을 정의하고, 레이더 임무 스케줄링 문제를 해결하기 위해 심층 강화학습인 DDQN(Double Deep Q-Network)을 활용한 스케줄링 모델을 구현하였다. 스케줄링 임무의 수를 다르게 하여 전체 타임라인 대비 저부하 상황에서부터 과부하 상황까지 다양한 시나리오에 대한 시뮬레이션을 진행하였다. 시뮬레이션 결과 본 연구에서 제안한 DDQN 기반 스케줄링 기법은 모든 시나리오에서 휴리스틱기반의 스케줄링 기법보다 더 낮은 임무 드랍 수와 비용를 보여주며 스케줄링 최적화 측면에서 우수한 성능을 보여주었다. 또한 학습과정에서 보상값이 빠르게 수렴되어 기존 DQN(Deep Q-Network) 모델보다 레이더 임무 스케줄링 문제에서 안정적인 학습이 가능함을 보여주었다. 본 연구를 통해 다양한 레이더 환경에서 우수한 스케줄링 성능을 가지는 심층 강화학습 기반 스케줄링 기법의 적용 가능성을 확인하였다.","With the advances in multi-function radar, radar resource management to enhance radar performance efficiently in an environment with limited resources is an active area. Radar task scheduling is a key factor in radar resource management, and various algorithms have been studied to solve it. On the other hand, existing algorithms have limitations, such as difficulty in optimizing the performance or reflecting various environments. In this study, a radar task environment with various parameters is defined. A scheduler model utilizing a deep reinforcement learning-based agent called Double Deep Q-Network (DDQN) is proposed to solve the scheduling problem. Numerical simulations are constructed to evaluate the proposed scenarios ranging from underloaded to overloaded situations by varying the number of scheduling tasks. The simulations showed that the DDQN-based scheduling method proposed in this study provides a lower dropped ratio and cost compared to heuristic-based scheduling methods in all scenarios, demonstrating superior performance in terms of scheduling optimization. Furthermore, the convergence rate of the DDQN model during training is faster than the Deep Q-Network (DQN) model, suggesting that stable learning is possible in radar task scheduling problems. In this study, it is expected that deep reinforcement learning-based scheduling methods with superior performance can be applied in various radar operating environments."
다중 로봇 제조 물류 작업을 위한 안전성과 효율성 학습,2023,"['Smart Factory', 'Multi-Robot Logistics', 'Logic Rule Learning', 'Relational Reinforcement Learning', 'Domain Knowledge']",,"With the recent increase of multiple robots cooperating in smart manufacturing logistics environments, it has become very important how to predict the safety and efficiency of the individual tasks and dynamically assign them to the best one of available robots. In this paper, we propose a novel task policy learner based on deep relational reinforcement learning for predicting the safety and efficiency of tasks in a multi-robot manufacturing logistics environment. To reduce learning complexity, the proposed system divides the entire safety/efficiency prediction process into two distinct steps: the policy parameter estimation and the rule-based policy inference. It also makes full use of domain-specific knowledge for policy rule learning. Through experiments conducted with virtual dynamic manufacturing logistics environments using NVIDIA’s Isaac simulator, we show the effectiveness and superiority of the proposed system."
철근콘크리트 손상 특성 추출을 위한 최적 컨볼루션 신경망 백본 연구,2023,"['철근콘크리트 손상 이미지', '무인항공기', '특성 추출', '컨볼루션 신경망', '모바일', 'Reinforced concrete damage image', 'Unmanned aerial vehicle', 'Feature extraction', 'Convolution neural network', 'MobileNets']","철근콘크리트 손상 감지를 위한 무인항공기와 딥러닝 연계에 대한 연구가 활발히 진행 중이다. 컨볼루션 신경망은 객체 분류, 검출, 분할 모델의 백본으로 모델 성능에 높은 영향을 준다. 사전학습 컨볼루션 신경망인 모바일넷은 적은 연산량으로 충분한 정확도가 확보 될 수 있어 무인항공기 기반 실시간 손상 감지 백본으로 효율적이다. 바닐라 컨볼루션 신경망과 모바일넷을 분석 한 결과 모바일넷이 바닐라 컨볼루션 신경망의 15.9~22.9% 수준의 낮은 연산량으로도 6.0~9.0% 높은 검증 정확도를 가지는 것으로 평가 되었다. 모바일넷V2, 모바일넷V3Large, 모바일넷 V3Small은 거의 동일한 최대 검증 정확도를 가지는 것으로 나타났으며 모바일넷의 철근콘트리트 손상 이미지 특성 추출 최적 조건은 옵티마이 저 RMSprop, 드롭아웃 미적용, 평균풀링인 것으로 분석되었다. 본 연구에서 도출된 모바일넷V2 기반 7가지 손상 감지 최대 검증 정확도 75.49%는 이미지 축적과 지속적 학습으로 향상 될 수 있다.","'Research on the integration of unmanned aerial vehicles and deep learning for reinforced concrete damage detection is actively underway. Convolutional neural networks have a high impact on the performance of image classification, detection, and segmentation as backbones. The MobileNet, a pre-trained convolutional neural network, is efficient as a backbone for an unmanned aerial vehicle-based damage detection model because it can achieve sufficient accuracy with low computational complexity. Analyzing vanilla convolutional neural networks and MobileNet under various conditions, MobileNet was evaluated to have a verification accuracy 6.0~9.0% higher than vanilla convolutional neural networks with 15.9~22.9% lower computational complexity. MobileNetV2, MobileNetV3Large and MobileNetV3Small showed almost identical maximum verification accuracy, and the optimal conditions for MobileNet's reinforced concrete damage image feature extraction were analyzed to be the optimizer RMSprop, no dropout, and average pooling. The maximum validation accuracy of 75.49% for 7 types of damage detection based on MobilenetV2 derived in this study can be improved by image accumulation and continuous learning."
Preservice Teachers' Beliefs about Integrating Artificial Intelligence in Mathematics Education: A Scale Development Study,2023,"['artificial intelligence', 'teacher beliefs', 'preservice teachers', 'scale development']",,"Recently, AI has become a crucial tool in mathematics education due to advances in machine learning and deep learning. Considering the importance of AI, examining teachers’ beliefs about AI in mathematics education (AIME) is crucial, as these beliefs affect their instruction and student learning experiences. The present study developed a scale to measure preservice teachers’ (PST) beliefs about AIME through factor analysis and rigorous reliability and validity analyses. The study analyzed 202 PST’s data and developed a scale comprising three factors and 11 items. The first factor gauges PSTs' beliefs regarding their roles in using AI for mathematics education (4 items), the second factor assesses PSTs' beliefs about using AI for mathematics teaching (3 items), and the third factor explores PSTs' beliefs about AI for mathematics learning (4 items). Moreover, the outcomes of confirmatory factor analysis affirm that the three-factor model outperforms other models (a one-factor or a two-factor model). These findings are in line with previous scales examining mathematics teacher beliefs, reinforcing the notion that such beliefs are multifaceted and developed through diverse experiences. Descriptive analysis reveals that overall PSTs exhibit positive beliefs about AIME. However, they show relatively lower levels of beliefs about their roles in using AI for mathematics education. Practical and theoretical implications are discussed."
우울증 진단 및 치료를 위한 챗봇 연구 동향 분석,2023,"['우울증 진단', '우울증 치료', '챗봇', '멀티턴', '강화학습', 'Depression Detection', 'Depression Treatment', 'Chatbot', 'Multi-turn', 'Reinforcement Learning']","대한민국은 우울증과 같은 정신적인 질환의 발병률이 OECD 국가 중 최고 수준이다. 신체적인 질환과 같이 정신적인 질환 역시 초기에 발병 유무를 파악하고, 증세가 더 심해지지 않도록 치료하는 것이 중요하다. 하지만 이와 반대로 아직 대한민국 내에서 정신적인 질환에 대한 인식은 다소 부정적인 편이다. 따라서, 시설에 방문하지 않더라도, 언제 어디에서든지 전자기기로 정신질환의 초기 증상을 진단하고 이를 치료할 수 있도록 하는 시스템을 구축하는 것이 중요하다. 따라서 본 연구에서는 정신질환 중 특히 우울증과 관련하여 현재 우울증 진단 기준 및 우울증 관련 챗봇에 대한 동향 분석을 진행하였다. 추가로 초기 우울증을 앓거나 우울증 진단 기준에서 기준선 근처에 위치하는 한국인을 위해, 우울증 진단 및 치료를 위한 챗봇 구조를 멀티턴 대화 데이터셋과 강화학습을 기반으로 하여 제안한다.","South Korea has the highest incidence of mental diseases such as depression among OECD countries. It is important to identify the presence of mental diseases in the early stages, and to treat them so that the symptoms do not get worse, such as physical diseases. However, on the contrary the perception of mental illness in Korea is still somewhat negative. Therefore, it is important to establish a system that allows people to diagnose and treat initial symptoms of mental illness with electronic devices anytime, anywhere, even if they do not visit any facility. Therefore, in this study, the current criteria for diagnosis of depression and trends in chatbots related to depression were analyzed in relation to mental illness, especially depression. Additionally, a chatbot structure for diagnosis and treatment of depression for Koreans suffering from early depression of locating near the baseline in the diagnostic criteria for depression is proposed based on multi-turn conversation dataset and reinforcement learning."
신화를 활용한 한국문화 교육 방안 -<삼성신화를 중심으로>-,2023,"['한국 언어문화 교육', '한국어 교재', '삼성신화', '다층적 피드백 강화 모형', '활동 중심 학습', 'Korean Language Culture Education', 'Korean Textbook', 'Samseong-shinhwa', 'Multi-layered Feedback Reinforcement Model', 'Activity-Based Learning']",,"This study aims to enhance the value of Korean cultural education for general purposed Korean learners through the Jeju <Samseong-shinhwa>. We analyzed the aspects of classical literature in Korean textbooks and selected the <Samseong-shinhwa> through various mythological works. which is not included in the textbooks, and then reconstructed the contents and proposed a plan for Korean cultural education. Learners can learn a variety of vocabulary related to marriage and have a broad understanding of Korean marriage culture. We divided the activity-based learning area of 'content understanding, goal-oriented, and applied learning', and gave learners group activity time and allowed them to compare marriage cultures between Korean and their own country, thereby proposed that Korean cultural education is effectively carried out. In this process, learners can actively participate in the class through group-type jigsaw activities, and through the 'multi-layered feedback reinforcement model', they can receive feedback on multiple layers, thereby accurately understanding the educational content, and correcting errors to strengthen knowledge."
초등학생들의 일반적 특성에 따른 생존수영교육의 수업만족과 수영지속의도에 미치는 영향,2023,"['생존수영', '수업만족', '수영지속의도', 'survival swimming', 'class satisfaction', 'intention to continue swimming']","목적: 본 연구의 목적은 초등학생들의 성별, 학년, 수영 학습경험에 따른 생존수영 교육이 수업만족과 수중관련 운동 활동을 지속하는데, 어떠한 영향을 미치는지를 연구하여 생존수영교육 활동에 있어서 초등학생에게 실효성 있는 기초자료를 제공하는 데 있다.방법: 본 연구의 대상은 충청남도에 소재하고 있는 초등학교에서 실시하는 생존수영에 참여하고 있는 학생들을 모집단으로 설정하고 표본은 5곳의 3~6학년 학생들로 하였으며, 표본추출은 편의표본추출방법으로 총343부를 최종 분석에 활용하였다.결과: 본 연구 결과 첫째, 성별에 따른 분석 결과, 남자는 수업만족의 심리만족이 수영지속의도의 경향성, 가능성에 공통되게 영향을 미쳤으며, 신체만족이 가능성, 강화성에 공통되게 영향을 미치는 것으로 나타났다. 반면, 여자는 수업만족의 신체적, 심리적, 사회적 만족 모두 운동지속의 경향성에 영향을 미쳤으며, 신체적 만족은 가능성에영향을 미쳤으며, 사회적 만족은 강화성에 영향을 미치는 것으로 나타났다. 둘째, 학년에 따른 분석 결과, 수업만족이 수영지속의도에 영향을 미치는 것으로 나타났으며, 특히 학년이 높아질수록 수업만족의 심리적 만족이 수영지속의도의 경향성, 가능성, 강화성에 모두에 영향을 미치는 것으로 나타났다. 셋째, 수영 학습경험에 따른 분석 결과, 수영학습 유경험은 수업만족의 신체적, 심리적, 사회적 만족 모두 수영지속의도의 경향성에 영향을 미쳤으며, 신체적 만족은 가능성에 영향을 미쳤으며, 심리적 만족은 강화성에 영향을 미치는 것으로 나타났다. 반면, 수영학습 무경험은 수업만족의 심리적 만족만 수영지속의도 경향성, 가능성 요인에 영향을 미치는 것으로 나타났다.","Purpose: The purpose of this study is to investigate the effect of survival swimming education according to the gender, grade, and swimming learning experience of elementary school students on class satisfaction and continuing aquatic-related exercise activities, to determine the effectiveness of survival swimming education activities for elementary school students.It is to provide basic data.Methods: The subjects of this study were students participating in survival swimming held at an elementary school located in Chungcheongnam-do as the population, and the sample was 3rd to 6th grade students in 5 places. It was used in the final analysis.Results: As a result of this study, first, as a result of analysis according to gender, it was found that the psychological satisfaction of class satisfaction had a common effect on the tendency and possibility of swimming continuation intention in males, and the physical satisfaction had a common effect on possibility and reinforcement. On the other hand, for women, physical, psychological, and social satisfaction of class satisfaction all affected the tendency of exercise continuation, physical satisfaction affected the possibility, and social satisfaction affected the reinforcement. Second, as a result of the analysis by grade, it was found that class satisfaction has an effect on the intention to continue swimming. appeared to affect Third, as a result of analysis according to swimming learning experience, swimming learning experience influenced the tendency of swimming continuation intention for all physical, psychological and social satisfaction of class satisfaction, physical satisfaction influenced the possibility, and psychological satisfaction strengthened. has been shown to have an effect on gender. On the other hand, it was found that only the psychological satisfaction of class satisfaction had an effect on the tendency and likelihood factors of swimming continuation intention."
동적 저궤도 위성 네트워크를 위한 Dueling DQN 기반 라우팅 기법,2023,"['Dueling DQN', 'Low-earth-orbit satellite network (LEO-SN)', 'Routing algorithm']",,"This paper deals with a routing algorithm which can find the best communication route to a desired point considering disconnected links in the LEO (low earth orbit) satellite networks. If the LEO satellite networks are dynamic, the number and distribution of the disconnected links are varying, which makes the routing problem challenging. To solve the problem, in this paper, we propose a routing method based on Dueling DQN which is one of the reinforcement learning algorithms. The proposed method was successfully conducted and verified by showing improved performance by reducing convergence times and converging more stably compared to other existing reinforcement learning-based routing algorithms."
대학 교양 수업에서의 효과적인 소집단활동 운영 방안,2023,"['group activity', 'team activity', 'peer evaluation', 'collaborative learning', 'perception survey', '소집단활동', '팀 활동', '동료평가', '협동학습', '인식 조사']","2010년대 들어서 대학은 강의 중심 수업 방식의 한계를 인식하고 학생들이 학습에 능동적으로 참여하는 교육 방식을 확대해 가고 있다. 의사소통능력, 문제해결능력, 대인관계능력 향상 등 소집단활동의교육적 효과가 입증되었지만, 학습자들은 이와 같은 수업 방식에 대한 불만이 적지 않다.이 연구에서는 학습자들이 수업과 함께 병행되는 소집단활동에 대해 어떻게 인식하고 있는가를 살펴보고 대학 교양 수업에서 소집단활동을 효과적으로 운영하기 위한 방안을 모색하고자 한다. 이를 위해 S대학교 교양 수업 <사고와 표현> 교과목을 수강한 학생들을 대상으로 소집단활동을 어떻게 인식하고 있는지에 대한 설문조사를 실시하였다. 조사 결과 학생들은 소집단활동이 필요하다고 인지하고 있기는 하지만 낯선 동료와 의사소통을 하면서 과제를 수행해야 한다는 부담감과 불성실한 동료로 인해 피해를 볼 것에 대한 불안감으로 인해 소집단활동을 꺼린다는 것을 알 수 있었다.따라서 이 논문에서는 대학 교양 수업에서 소집단활동을 효과적으로 운영하기 위한 방안으로 소집단활동에 대한 동기 부여 강화, 동료평가의 기능 강화, 효율적인 교수 피드백 제공 등을 제안한다. 이러한 방법을 통해 학생들로 하여금 소집단활동에 대한 부정적 인식을 줄이면서 협업의 의미와 가치를 인지하고 의사소통능력과 문제해결능력 향상과 같은 학습 효과를 거두는 데 기여하고자 한다.","In the 2010s, universities recognized the limitations of lecture-oriented teaching methods and are expanding the educational method in which students actively participate in learning. Although the educational effects of small group activities such as improving one’s communication ability, one’s problem-solving ability, and one’s interpersonal competency have been proven, learners have many complaints about such teaching methods.This study intends to investigate how learners perceive group activities that are conducted in parallel with the class and to find ways to effectively operate group activities in college liberal arts classes. To this end, this study conducted a survey on how group activities are perceived by students who took the liberal arts classes as <Thought and Expression> courses in S University. According to the survey, students recognize that group activities are necessary but are reluctant to do small group activities because of the burden of carrying out a class assignment while communicating with unfamiliar schoolmates, as well as the anxiety they feel about having to work with schoolmates that are not diligent.Therefore, this study suggests that we strengthen the motivation for group activities, to reinforce the function of peer evaluation, and to provide effective feedback as professors regarding group activities as ways to effectively operate small group activities in college liberal arts classes. Through these methods, it is expected that students will be able to reduce their negative perception of group activities, recognize the meaning and value of collaboration, and be able to achieve learning effects such as improving their communication and problem-solving abilities."
Assessing English Major Students’ Perceptions  of Digital Literacy Training,2023,"['digital literacy training', 'prospect English teacher', 'perception', 'coding', 'higher education']",,"In the era of artificial intelligence with rapid digital advancements, integrating digital literacy training  into  higher  education  has  become  both  essential  and  challenging.  As  educational institutions respond to this demand, digital tools aligned with the contemporary landscape gain prominence also in language teaching and learning. In line with this digital transformation, this study examines two key aspects: students’ perceptions of digital literacy training in English education or language majors and potential variations in their awareness. Analyzing surveys from 159 students illuminates their understanding of digital literacy, its importance for future careers, and the challenges of acquiring digital skills in the current educational context. Our findings indicate that students acknowledge both the advantages and challenges of acquiring digital literacy skills in the present educational context. Furthermore, English education majors demonstrate a heightened awareness of the role of digital literacy in enhancing their pedagogical strategies. This study emphasizes the need for tailored digital education programs, reinforcing the importance of robust digital literacy training and preparing future language educators with essential digital competencies. (170 words)"
TextRank 알고리즘 및 인공지능을 활용한 브레인스토밍,2023,"['Reactive web', 'TextRank algorithms', 'Softmax', 'Mini-GPT', 'REST API', 'Mind-map']",,"The reactive web service provides a related word recommendation system using the TextRank algorithm and a word-based ideageneration service selected by the user. In the related word recommendation system, the method of weighting each word using theTextRank algorithm and the probability output method using SoftMax are discussed. The idea generation service discusses the ideageneration method and the artificial intelligence reinforce-learning method using mini-GPT. The reactive web discusses the linkageprocess between React, Spring Boot, and Flask, and describes the overall operation method. When the user enters the desired topic,it provides the associated word. The user constructs a mind map by selecting a related word or adding a desired word. When a userselects a word to combine from a constructed mind-map, it provides newly generated ideas and related patents. This web service canshare generated ideas with other users, and improves artificial intelligence by receiving user feedback as a horoscope."
리스트 스케줄링 시뮬레이터를 이용한 인스트럭션 우선도 함수 성능 분석,2023,"['컴파일러 최적화', '스케줄링 문제', '리스트 스케줄링', '우선도 함수', 'compiler optimization', 'scheduling problem', 'list scheduling', 'priority function']",,"Instruction scheduling is an important compiler optimization technique, for reducing the execution time of a program by parallel processing. However, existing scheduling techniques show limited performance, because they rely on heuristics. This study examines the effect of instruction priority functions on list scheduling, through simulation. As a result, using a priority function based on the overall structure of the dependency graph can reduce schedule length by up to 4%, compared to using a priority function based on the original instruction order. Furthermore, the result gives a direction on which input features should be used when implementing a reinforcement learning-based scheduling model."
인공지능(AI)을 활용한 드론방어체계 성능향상 방안에 관한 연구,2023,"['Artificial Intelligence', 'Anti-Drone', 'Anti-Drone System', 'Counter Drone', 'Drone Detection', 'Drone Identification']",,"Drones are emerging as a new security threat, and the world is working to reduce them. Detection and identification are the most difficult and important parts of the anti-drone systems. Existing detection and identification methods each have their strengths and weaknesses, so complementary operations are required. Detection and identification performance in anti-drone systems can be improved through the use of artificial intelligence. This is because artificial intelligence can quickly analyze differences smaller than humans. There are three ways to utilize artificial intelligence. Through reinforcement learning-based physical control, noise and blur generated when the optical camera tracks the drone may be reduced, and tracking stability may be improved. The latest NeRF algorithm can be used to solve the problem of lack of enemy drone data. It is necessary to build a data network to utilize artificial intelligence. Through this, data can be efficiently collected and managed. In addition, model performance can be improved by regularly generating artificial intelligence learning data."
2022 개정 초등학교 교육과정에서의 안전교육 반영 양상 분석,2023,"['Safety education', '2022 revised national curriculum', 'elementary school', '7 standards for safety education in school', '안전교육', '2022 개정 교육과정', '초등학교', '학교안전교육 7대 표준안']",,"This study aims to investigate how to strengthen safety education in elementary schools by examining its integration in the revised 2022 national curriculum. Content analysis of the revised national curriculum document reveals that the updated general guidelines now include statements that solidify the support for safety education within the school system. Additionally, the revised general guideline places emphasis on experience-based safety education and the integration of safety education with subject areas and Creative Experiential Activities. Notably, the revised curriculum presents Creative Experiential Activities as ""guidelines"" for teachers to follow or as an ""example"" to refer to, rather than establishing them as an independent ""area"" as in the 2015 revised national curriculum. There has been a reduction in the number of ""achievement standards"" directly addressing safety-related content across most subject areas, while safety-related content is presented as the ""context"" or the ""ways"" for teachers to incorporate standards into their curriculum. Furthermore, the revised curriculum highlights safety education during experiments, practical activities, and in overcrowded areas as essential aspects of teaching and learning. Additionally, safety and health are newly included as learning content. The findings indicate that the incorporation of safety education into the curriculum has become more diverse. However, caution is needed to prevent a decline in safety education within schools as a result of the reduction of achievement standards. The study proposes policy recommendations to reinforce and validate safety education in elementary schools"
Guest Editorial: The 38th ICROS Annual Conference (ICROS 2023),2023,,,"This special issue is dedicated to the papers that are extended from those originally submitted to the 38th ICROS Annual Conference (ICROS 2023), held in Sol Beach Hotel & Resort, Gangwon, Korea, from June 21 to 23, 2023. The objective is to establish a connection between the conference and IJCAS so that strong results from the annual conference can be published in IJCAS in a timely manner. Prof. Hyo-Sung Ahn, the Editor-in-Chief of IJCAS brought this idea to the organizing committee of ICROS.Motivated by Prof. Ahn’s idea, the organizing committee developed detailed guidelines. Call for paper for this special issue was announced in April 2023 and the interested authors are asked to contact the guest editor before the submission deadline to the conference. The authors are informed that their papers will undergo the standard review process of IJCAS and that they have four weeks to prepare the revision. The guest editors received 20 applications, and 15 papers have been received before the conference took place. The papers were handled by three associate editors who committed to make the review process fast without sacrificing the high standard of the journal. At the end of review process, the following seven papers were chosen for publication:1. “Compensated Motion and Position Estimation of a Cable-driven Parallel Robot Based on Deep Reinforcement Learning” by Huaishu Chen, Min-Cheol Kim, Yeongoh Ko, and Chang-Sei Kim*.2. “Design of Humanoid Robot Foot to Absorb Ground Reaction Force by Mimicking Longitudinal Arch and Transverse Arch of Human Foot” by Jindeok Lee and Hyun-Min Joe*.3. “Enhancing Low-light Images for Monocular Visual Odometry in Challenging Lighting Conditions” by Donggil You, Jihoon Jung, and Junghyun Oh*.4. “Safe Trajectory Path Planning Algorithm Based on RRT* While Maintaining Moderate Margin From Obstacles” by Subin Lim and Sangrok Jin*.5. “Connection Loss Detection Algorithm of Parallel-connected Cells Based on Change of Battery SOC” by Byeonggwan Jang, Hyoseo Choi, Wooyong Kim*, and Kyung-Soo Kim*.6. “A Current Sensor Fault-detecting Method for Onboard Battery Management Systems of Electric Vehicles Based on Disturbance Observer and Normalized Residuals” by Wooyong Kim, Kunwoo Na, and Kyunghwan Choi*.7. “Design and Verification of Early Unstable Stage Control Scheme for High-speed Underwater Launched AUV” by Chul Hyun.The guest editors would like to recommend that the editorial board of IJCAS continues to offer authors the opportunity for increased exposure by linking the upcoming annual conferences of ICROS with IJCAS."
한국 EFL 중급 대학생의 디지털 도구를 활용한 영어 에세이쓰기에 대한 동료제안 연구,2023,"['Peer review', 'digital tools', 'process writing', 'intermediate EFL college students', 'students’ perception', '동료제안', '디지털 도구', '과정쓰기', '외국어로써의 영어학습자인 중급 대학생', '학생들의 인식']",,"This study explores intermediate Korean EFL college students’ peer reviews of essay writing with digital tools. Twenty-one freshman students from Academic English Ⅱ participated in a writing project. The findings from the survey in quantitative data showed that the participants used these eight digital tools: Grammarly, Google Docs and Microsoft Words, PBworks, Google Drawing, Zoom, Padlet, Lextutor, and Copykiller. The participants dealt with Grammarly the most and Copykiller the least. During the writing project, there was a statistically significant difference in language proficiency in the C-test results. Based on the open-ended written questionnaires in qualitative data, students focused more on grammar, were able to conveniently provide peer review comments, connected with their peers, and organized their thoughts while adopting digital tools in peer review writing. As a result, the participants showed a more positive perspective towards peer review, reported that they recognized strengths and weaknesses in their writings, and felt reduced the anxiety about writing after the writing project. With the help of others, they felt comfortable writing an essay in English. As they had  opportunities to scaffold and interact, the participants could exercised their thinking and were able to take an active role in their learning. The writing experience let participants reinforce their agency in English writing and digital tools for writing."
인공지능 이미지 생성 과정에서의 심미적 경험 고찰,2023,"['생성형 AI', '예술교육', '챗GPT', '심미적 경험', 'Generating AI', 'Art education', 'ChatGPT', 'Aesthetic experience']","오늘날 예술은 인공지능 기술의 발달로 경제적 효율성이라는 측면에서 대중적으로 확장되고 인간의 노동력과 시간을 매우 효율적으로 대체해 준 것처럼 일반인들에게 그 창작의 기회를 열어주고 있다. 인공지능기술의 획기적 발전에 따른 경제적 이익 이면에 인공지능으로 생성되는 이미지에 저작권과 실행 주체에 대한 관심이 고조되고 있는 상황에서 이 연구는 연구자가 직접 실제 그림을 그릴 때와 AI 프로그램을 통해 이미지를 생성할 때의 심미적 경험의 차이를 고찰하였다.인공지능이 챗GPT의 개발로 언어와 이미지 간의 데이터 정보처리 기술이 새로운 예술 창작의 지평을 열어주는 가운데 기존 예술교육과 차별화된 방향성 측면에서 이 연구를 통해 얻은 시사점은 세 가지 차원에서 언급될 수 있다. 첫째, 지식의 축적과 오랜 경험 학습의 산물로 이루어질 수 있는 사유를 통한 창의력을 개발하는 것과 관련하여 인공지능으로 생성되는 이미지 창작은 인문학적 사유의 과정이 결여되어 있어 이에 대한 학습의 측면에서 강화될 필요가 있다. 둘째, 주체성과 실행력에 관한 문제로 예술 AI 활용기술을 공학분야에서 가르쳐야 하는가, 아니면 예술계열 분야에 가르쳐야 하는가에 대한 그 활용 주체에 대한 논의를 통해 전문적인 인공지능 이미지 생성과 관련한 교육의 대상과 그 대상에 따른 교육 내용과 방향 설정이 요구된다. 마지막으로, 예술교육에서 인공지능은 인지과학과 교육학 이론들과 방법들에서 어떤 종류의 교수법이 효과적이고 어떤 콘셉트들이 AI 학습에 요구되는지를 재고해 봐야 한다.결론적으로 단순한 인공지능 기술만을 익히는 것이 아니라 인문학적이고 사회학적이며, 공학적인 결합을 가능하게 하는 교양교육으로서의 예술교육의 새로운 지평을 강구해야 함을 알 수 있다.","Today, art is expanding in terms of economic efficiency with the development of artificial intelligence(AI) technology and opening up opportunities for creation to the general public, just as it has very effi ciently replaced human labor and time. Amid growing interest in copyright and execution subjects in images generated by AI behind the economic benefi ts of the breakthrough development of artificial intelligence technology, this study examines the difference between the aesthetic experience when the researcher drew an actual picture himself and when creating images through AI programs.With the development of ChatGPT utilizing AI, data information processing technology between language and images opens the horizon for new art creation. The implications of this study can be presented in three dimensions in terms of diff erentiated directions from existing art education. First, in relation to developing creativity through thought that can be made up of accumulation of knowledge and long experiential learning, image creation by AI lacks a process of humanistic thinking and needs to be reinforced in terms of learning. Second, the subject of education related to the creation of professional AI images and the setting of educational content and direction according to the subject are required through discussions on whether art AI utilization technology should be taught in engineering fi elds or in art fi elds as a matter of subjectivity and execution power. Finally, in art education, AI should drive a reconsideration of what kind of teaching methods are eff ective and what concepts are required for AI learning in cognitive science and pedagogical theories and methods.In conclusion;with the development of ChatGPT;artificial intelligence opens up the horizon for new art creation through data information processing between language and images;and the purpose and meaning of traditional art education need to accommodate this change and transform in the practice of liberal arts education at a time when the development of these technologies is required. The implications of this study show that by identifying the unique attributes of art regardless of the major area;understanding the functions of valuable works;and providing aesthetic experiences;a new horizon must be devised for liberal arts education that enables humanities;sociological;and engineering combinations as well as simple artificial intelligence technologies."
2022 개정 사회과 교육과정의 개발 과정 및 특징 분석:  초등학교 일반사회 영역을 중심으로,2023,"['Optimizing the amount of learning', 'Democratic citizenship education', 'Media literacy', 'Labor human rights education', 'Student-led inquiry', 'Practice in conjunction with life', '학습량의 적정화', '민주시민교육', '미디어 리터러시', '노동인권 교육', '학생 주도 탐구', '삶과 연계한 실천']",,"The purpose of this study is to analyze the development process and characteristics of the 2022 social studies national curriculum for elementary school, focusing on the social sciences area and to explore future tasks. As a result of reviewing the development process of the 2022 revised social studies curriculum, the main issues are as follows. First, it was an problem of excessive learning content and quantity. Second, it was the realization of teaching and learning methods that can be realized in the school field. Third, it was an issue about close connection between social studies’learning contents and students’life. Fourth, it is a matter of reflecting the opinions presented at the public hearing. The characteristics of the 2022 revised social studies curriculum developed by reflecting these matters are as follows. First, it was intended to optimize the amount of learning by reducing the number of achievement standards. The number of achievement standards was reduced, and learning elements that were judged to be difficult for overlapping content or elementary school students' cognitive level were deleted. The second was the simplification of the content structure. In order to increase the freedom of textbook authors to write and the autonomy of teachers to reorganize the curriculum, the content strcuture was roughly stated. Third, it is the strengthening of democratic citizenship education. The contents of democratic citizenship education were newly established or added. Fourth, it is the strengthening of media literacy education. The content of developing the ability to critically analyze and utilize media by reflecting the needs of the digital society was newly established in the 5th to 6th grade curriculum. Fifth, it was the strengthening of labor human rights education. Reflecting the social demand to guarantee workers' basic rights, a new content to explore workers' rights was added to the 5th to 6th grade curriculum. Sixth, it is the reinforcement of student-led inquiry. Student-led inquiry was reinforced by reflecting the flow of future education. Seventh, it is the reinforcement of practice and participation in connection with the life of students. The connection between social studies knowledge and student life was strengthened to understand the main concepts or principles in the cases of daily life experienced by students."
프레스 공정을 위한 품질 예측 모델,2023,"['GAN', 'Manufacturing Data', 'Data Analysis', 'Reinforcement Learning', 'DNN']","제조업 분야에서의 품질 관리는 핵심적인 과제 중 하나로, 프레스 공정 데이터의 효율적인 활용은 제품 품질 향상과 생산 프로세스 최적화에 중요한 역할을 수행한다. 제조업체에서 품질 향상과 불량품 검출의 매우 중요하지만, 기존의 판별 방법은 불량품의 다양한 형태와 패턴을 효과적으로 처리하지 못하는 한계가 있었다. 특히 데이터 부족 문제와 불균형한 데이터 분포로 인해 품질 관리 모델의 성능 향상이 어려웠다. 본 논문에서는 적대적 생성 망을 활용하여 프레스 공정 데이터를 증강하고, 품질 관리 모델의 정확도와 일반화 능력을 향상시키는 접근 방법을 제안한다. 적대적 생성 망의 생성자에 강화학습 모델, 판별자에 심층신경망 모델을 적용하여 데이터 생성 및 불량품 판별을 수행한다. 특히 GAN(Generative Adversarial Networks) 모델에 강화학습을 도입하여 생성자의 성능을 개선하였다. 강화학습은 불균형한 클래스 분포와 다양한 불량 패턴에 대해서도 강건한 성능을 보여줌으로써 실제 공정 환경에서의 적용 가능성을 높인다. AI 모델 개발과 제조공정의 적용 및 검증을 통하여 실질적인 품질 및 비용 절감 개선에 기여한다.","Quality management is one of the key challenges in the manufacturing sector, and the efficient use of press process data plays an important role in improving product quality and optimizing production processes. Although quality improvement and defect detection are very important for manufacturers, methods of discrimination have limitations in not being able to effectively handle various forms and patterns of defective products. In particular, improvement of the performance of the quality management model is difficult due to a lack of data and unbalanced data distribution. In this paper, we propose a new approach that enhances press process data by utilizing adversarial generation networks and improves the accuracy and generalization ability of quality management models. Data generation and defect determination are performed by applying a reinforcement learning model to the creator of the adversarial generation network and a deep neural network model to the discriminator. Reinforcement learning was introduced in generative adversarial networks (GANs) model to improve the performance of the generator. Reinforcement learning also improved its applicability in real manufacturing environments by showing robust performance against unbalanced class distributions or various defective patterns. It could contribute to substantial quality and cost reduction improvement through the development of AI models and the application and verification of manufacturing processes."
DQN을 이용한 수요응답형 대중교통 차량 최적 경로 탐색,2023,"['심층강화학습', '강화학습 환경', '수요응답형 대중교통', '경로생성', '공유자전거', 'deep reinforcement learning', 'reinforcement learning environment', 'demand response public transit', 'path planning', 'shared bicycle']","수요응답형 대중교통은 개별 승객의 호출수요에 따라 운행되는 대중교통 서비스를 의미한다. 일반적인 대중교통 수단인 버스, 지하철과는 달리 최근에는 카카오, 우버 택시와 같이 출발지와 목적지를 설정하면 실시간 호출을 통해 호출한 승객의 현재 위치로 태우는 유연한 운영을 통해 교통취약지역에서 탄력적 운행이 가능하게 되었으며, 동적으로 경유지를 변경하여 승객 맞춤형 서비스를 제공하고 있다. 이용객의 수요기반으로 다양한 최적의 경로 탐색방법 개발 및 연구가 진행되고 있다. 본 연구에서는 Deep Reinforcement Learning 알고리즘 중 하나인 Deep Q Network 알고리즘 기반 차량 최적경로 알고리즘 시뮬레이터를 통해 테스트베드 대상지를 검증 분석하였다.","Demand-responsive transit (DRT) refers to public transport services that operate considering real-time passenger demand. In contrast to conventional public transport like buses and subways, recent advancements in DRT have enabled flexible operations in response to passenger requests by setting origin and destination points, allowing real-time pickup at the passengers’ locations, and dynamically adjusting routes to provide customized service. Various route optimization methods are being developed and studied in the literature. In this study, a vehicle route optimization algorithm for DRT based on the Deep Reinforcement Learning (DRL) machine learning method, referred to as a Deep Q Network, was developed and tested on a simulator to validate its performance using test-bed demand data."
MAML 기반 차량/화물 운송 매칭 알고리즘 성능 분석,2023,"['Vehicle/cargo dispatch system', 'Transportation matching algorithm', 'MAML']","항만물류 환경에서 차량/화물 간의 효율적인 배차를 위해서는 배차 공정성/일관성 및 도로상황, 날씨 등과 같은 환경 요소를 고려할 필요가 있다. 이러한 환경 요소들은 지속적으로 변화하고 있으며, 화물을 운송하는 차량 및 운전자에게 영향을 미칠 수 있다. 메타 강화학습은 인공 신경망의 최적화 과정을 학습을 통해 효과적으로 진행하는 기법이며, 새로운 환경이나 데이터에 대하여 모델을 잘 학습할 수 있는 장점을 가지고 있다. 본 논문에서는 다양한 환경 및 데이터의 변화에 효율적으로 배차 업무를 수행하기 위해 메타 강화학습 알고리즘인 MAML(model-agnostic meta learning)을 적용한 차량/화물 운송 매칭 알고리즘을 제안한다. 모의실험을 통해 다양한 운송 환경에 따른 차량과 화물의 운송 매칭 알고리즘의 배차 성능을 분석한다. 모의실험 결과는 제안한 알고리즘이 차량과 화물을 자동으로 신속하게 배차할 수 있는 성능을 가짐을 보인다.","In the port logistics environment, it is necessary to consider environmental factors such as fairness/consistency, road conditions, and weather for efficient vehicle/cargo dispatch. These environmental factors have constantly changed and can affect the vehicles transporting cargo and the drivers. Meta-reinforcement learning is a technique that effectively proceeds the optimization process of artificial neural networks through learning and has the advantage of learning models well for new environments or data. In this paper, we propose a vehicle/cargo transportation matching algorithm that applies model-agnostic meta learning (MAML), a meta reinforcement learning algorithm, to efficiently dispatch vehicles in various environments and data changes. Through simulations, we analyze the performance of vehicle and cargo transportation matching algorithms according to various transportation environments. Simulation results show that the proposed algorithm can automatically and quickly distribute vehicles and cargo."
Configuration Path Control,2023,"['Biped', 'configuration path control', 'reinforcement learning', 'stability', 'virtual constraints', 'zero dynamics.']",,"Reinforcement learning methods often produce brittle policies – policies that perform well during training, but generalize poorly beyond their direct training experience, thus becoming unstable under small disturbances. To address this issue, we propose a method for stabilizing a control policy in the space of configuration paths. It is applied post-training and relies purely on the data produced during training, as well as on an instantaneous control-matrix estimation. The approach is evaluated empirically on a planar bipedal walker subjected to a variety of perturbations. The control policies obtained via reinforcement learning are compared against their stabilized counterparts. Across different experiments, we find two- to four-fold increase in stability, when measured in terms of the perturbation amplitudes. We also provide a zero-dynamics interpretation of our approach."
C형 고리 타입 Patience Cube의 플래닝 관점 문제 정의,2023,"['Reinforcement Learning', 'Dexterous Manipulation', 'Kinodynamic Path Planning']","정확한 힘과 방향을 요구하는 작업이 주어졌을 때, 사람은 강화학습과 유사한 휴리스틱 방법론을 통해 작업을 수행한다. 따라서, 이러한 사람의 의사결정-조작의 과정을 강화학습으로 구현하여 로봇에게 적용하여준다면 정교한 손동작이 요구되는 작업을 성공적으로 수행할 수 있을 것으로 기대할 수 있다. 본 논문은 사람의 정교한 손놀림이 요구되는 C형 고리 patiencecube를 로봇으로 해결하기 위한 강화학습 기반 플래너 설계 기법을 제안한다. 먼저 두 축을기준으로 회전하는 평평한 판과 그 위에서 구르는 공에 대한 운동 방정식을 구하였다. 이후,C형 고리 patience cube 문제를 C형 고리의 입구로 공을 가져오는 플래닝 문제와 그 영역으로부터 공을 고리 안으로 넣는 플래닝 문제로 구성하였다. 이어서, 각 플래닝 문제를 해결하기 위한 마르코프 의사 결정(MDP) 튜플(상태, 행동, 보상)을 정의하였다. 에이전트(플래너)는가상환경에서 강화학습 알고리즘(PPO)을 통해 학습되었다. 결과적으로, 가상환경에서 학습된에이전트가 가상환경에서 C형 고리 patience cube문제를 잘 해결할 수 있음을 확인하였다.또한, 실제 환경의 양팔 로봇에 이식하였을 때도 주어진 C형 고리 patience cube 문제를 해결할 수 있음을 확인하였다. 이를 통해, 본 논문에서 제안된 방법론으로, 다양한 정교한 손동작문제를 kinodynamic 플래닝 문제로 정의하여 해결할 수 있는 가능성을 보였다.","Given dexterous manipulation tasks, human-being performs the tasks with heuristicapproach similar to reinforcement learning(RL). Accordingly, we can expect roboticsystems to complete the given tasks successfully by applying the RL being inspired by ahuman decision making-manipulation process. This paper proposed the RL-based plannerdesign method to solve a C-type patience cube, which could be considered as adexterous manipulation task, using the robot. First, we derived the equations of motionfor a ball rolling on the rotating flat plane along two axes. Next, we defined the C-typepatience cube as two-stage path planning problems in which the one RL agent bringsthe ball to the vicinity of the entrance of the C-shaped ring and the other RL agentguides the ball into the ring. Afterward, we formulated the Markov decision process(MDP) problem; namely, we defined a state set, an action set, and a reward function foreach MDP problem. Finally, the RL agents, which plays a role of planner for ourproblem, were trained under proximal policy optimization in a virtual environment.Experimental results showed that trained RL agent could successfully solve the C-typepatience cube problem by being transferred into a robotic manipulator. This studysubstantiated the feasibility of the proposed method to be extended to various dexterousmanipulation tasks by defining them as kinodynamic planning problems."
MEC를 활용한 커넥티드 홈의 DRL 기반 태스크 오프로딩 기법,2023,"['Deep Reinforcement Learning', 'Deep Q-Network', 'Deep Deterministic Policy Gradient', 'Markov Decision Process', 'Connected home']",,"The rise of 5G and the proliferation of smart devices have underscored the significance of multi-access edge computing (MEC). Amidst this trend, interest in effectively processing computation-intensive and latency-sensitive applications has increased. This study investigated a novel task offloading strategy considering the probabilistic MEC environment to address these challenges. Initially, we considered the frequency of dynamic task requests and the unstable conditions of wireless channels to propose a method for minimizing vehicle power consumption and latency. Subsequently, our research delved into a deep reinforcement learning (DRL) based offloading technique, offering a way to achieve equilibrium between local computation and offloading transmission power. We analyzed the power consumption and queuing latency of vehicles using the deep deterministic policy gradient (DDPG) and deep Q-network (DQN) techniques. Finally, we derived and validated the optimal performance enhancement strategy in a vehicle based MEC environment."
Performance Improvement of Fuzzy C-Means Clustering Algorithm by Optimized Early Stopping for Inhomogeneous Datasets,2023,"['Deep reinforcement learning', 'Early stopping', 'Neural network', 'Overfitting']",,"Responding to changes in artificial intelligence models and the data environment is crucial for increasing data-learning accuracyand inference stability of industrial applications. A learning model that is overfitted to specific training data leads to poorlearning performance and a deterioration in flexibility. Therefore, an early stopping technique is used to stop learning at anappropriate time. However, this technique does not consider the homogeneity and independence of the data collected byheterogeneous nodes in a differential network environment, thus resulting in low learning accuracy and degradation of systemperformance. In this study, the generalization performance of neural networks is maximized, whereas the effect of thehomogeneity of datasets is minimized by achieving an accuracy of 99.7%. This corresponds to a decrease in delay time by afactor of 2.33 and improvement in performance by a factor of 2.5 compared with the conventional method."
DRL-based Multi-UAV trajectory optimization for ultra-dense small cells,2023,['6GMultiagent deep reinforcement learning (DRL)Multitarget trackingUnmanned aerial vehicle'],,"In this paper, we propose a deep reinforcement learning (DRL) based unmanned aerial vehicles (UAV)-assisted trajectory optimization for ultra-dense small cell networks. We assume that each UAV is equipped with a sensing radio to obtain distance information to the UEs and other UAVs in the network which are used to update the UAV’s trajectory. The proposed DRL-based system selects the optimal joint control actions for the UAVs that maximizes the system sum-rate. The simulation results show that the proposed DRL-based UAV controller provides fast UAV placement in the network with a high system performance when compared with the benchmark schemes."
On Collaborative Multi-UAV Trajectory Planning for Data Collection,2023,"['collaborative UAVs', 'deep reenforcement learning', 'IoT data collection', 'trajectory planning']",,"This paper investigates the scenario of Internet of things (IoT) data collection via multiple unmanned aerial vehicles (UAVs), where a novel Collaborative Multi-agent Trajectory planning and Data collection (CMA-TD) algorithm is introduced for on-line obtaining the trajectories of the multiple UAVs without any prior knowledge of the sensor locations. We first provide two integer linear programs (ILPs) for the considered system by taking the coverage and the total power usage as the optimization targets. As a complement to the ILPs for avoiding the intractable computation, the proposed CMA-TD algorithm can effectively solve the formulated problem via a deep reinforcement learning (DRL) process on a double deep Q-learning network (DDQN). Extensive simulations are conducted to verify the performance of the proposed CMA-TD algorithm and compare it with a couple of state-of-the-art counterparts in terms of the amount of served IoT nodes, energy consumption, and utilization rates."
전통문화와 인공지능의 융합 - 인공지능 기반 한문 고서 번역 -,2023,"['Corpus', 'artificial intelligence', 'reinforcement learning algorithm', 'human evaluation', '코퍼스', '인공지능', '강화학습 알고리즘', '휴먼 평가']",,"The purpose of this study is to share the results of the “development of the open technology that supports translation and interpretation of the classics written in Chinese” project such as extraction of corpus, AI translation and human evaluation and present the direction of AI translation of the classics in the future. The extraction of corpus this time focused on improving the accuracy of AI-based automatic translation of geography books.Corpus is a sentence that presents original Chinese text and the corresponding translated text 1:1 in parallel. The development of artificial intelligence reinforcement learning has improved the accuracy of AI-based translation compared to the past and increased the accuracy of AI-based machine translation to over 80% in this project. The extraction of at least 1 million corpora is required in order to perform AI-based machine translation specialized in geography books in the future. In addition, the extraction of high quality corpus is required in more diverse fields including poetry, education, protocols and diplomacy in addition to geography."
이중 심층 Q 네트워크 기반 장애물 회피 경로 계획,2023,"['심층 강화 학습', '이중 심층 Q 네트워크', '자동 경로 계획', '장애물 회피', 'DRL', 'DDQN', 'Automatic Path Planning', 'Obstacle Avoidance']",심층 강화 학습(Deep Reinforcement Learning)을 사용한 경로 계획에서 장애물을 자동으로 회피하기 위해 로봇을 학습시키는 일은 쉬운 일이 아니다. 많은 연구자가 DRL을 사용하여 주어진 환경에서 로봇 학습을 통해 장애물 회피하여 경로 계획을 수립하려는 가능성을 시도하였다. 그러나 다양한 환경에서 로봇과 장착된 센서의 오는 다양한 요인 때문에 주어진 시나리오에서 로봇이 모든 장애물을 완전히 회피하여 이동하는 것을 실현하는 일은 흔치 않다. 이러한 문제 해결의 가능성과 장애물을 회피 경로 계획 실험을 위해 테스트베드를 만들었고 로봇에 카메라를 장착하였다. 이 로봇의 목표는 가능한 한 빨리 벽과 장애물을 피해 시작점에서 끝점까지 도달하는 것이다. 본 논문에서는 벽과 장애물을 회피하기 위한 DRL의 가능성을 검증하기 위해 이중 심층 Q 네트워크(DDQN)를 제안하였다. 실험에 사용된 로봇은 Jetbot이며 자동화된 경로 계획에서 장애물 회피가 필요한 일부 로봇 작업 시나리오에 적용할 수 있을 것이다.,"It remains a challenge for robots to learn avoiding obstacles automatically in path planning using deep reinforcement learning (DRL). More and more researchers use DRL to train a robot in a simulated environment and verify the possibility of DRL to achieve automatic obstacle avoidance. Due to the influence factors of different environments robots and sensors, it is rare to realize automatic obstacle avoidance of robots in real scenarios. In order to learn automatic path planning by avoiding obstacles in the actual scene we designed a simple Testbed with the wall and the obstacle and had a camera on the robot. The robot's goal is to get from the start point to the end point without hitting the wall as soon as possible. For the robot to learn to avoid the wall and obstacle we propose to use the double deep Q networks (DDQN) to verify the possibility of DRL in automatic obstacle avoidance. In the experiment the robot used is Jetbot, and it can be applied to some robot task scenarios that require obstacle avoidance in automated path planning."
‘건반화성’ 교과목의 온라인 활용 수업 사례 연구,2023,"['Online classes', 'online learning tools', 'hands-on activities by team', 'online learning counseling', 'learner satisfaction survey', '온라인수업', '온라인학습도구', '팀별실습활동', '온라인학습상담', '학습자만족도조사']",,"Objectives This study sought to explore effective teaching directions through the case of using non-face-to-face online class Zoom in a keyboard subject class that combines theory and practice. At the same time, the purpose is to analyze the satisfaction of learners by conducting various questionnaires, and according to the results, to present a model of music lessons in which theory and practice are combined in the future.Methods In conducting the 2021-1 Keyboard Hwaseong subject class at S University in Seoul, we tried non-face-to-face online classes using various lesson methods centered on learners, and analyzed the results of three types of questionnaires and final lecture evaluations among 14 students for these teaching methods.Results First, the disadvantages of face-to-face classes have been solved through online classes. Second, we designed online classes such as flip learning and discussion discussions that learners can actively participate in.Third, the use of various online learning tools such as paddlelets and quiz anne attracted the interest of learners.Fourth, through individual and team practice activities online, self-coaching, peer coaching, and instructor coaching were carried out. Fifth, learners' opinions were collected through online learning counseling and fully reflected in the next class. Sixth, it was found through surveys and final lecture evaluations that if various teaching methods are used in online classes, the satisfaction of learners can be high enough.Conclusions By reinforcing the shortcomings of face-to-face classes in subjects that combine theory and practice, and by trying various methods of teaching cases that utilize the strengths of non-face-to-face classes, it was possible to suggest an efficient non-face-to-face class direction that can increase learners' participation and lecture satisfaction."
The principles of artificial intelligence and its applications in dentistry,2023,"['Artificial intelligence', 'Supervised learning', 'Unsupervised learning', 'Reinforcement learning']",,"Digital dentistry has witnessed significant advancements in recent years, driven by extensive research following theintroduction of cutting-edge technologies such as CAD/CAM and 3D oral scanners. Until now, 2D images obtained viax-ray or CT scans were critical to detect anomalies and for decision-making. This review describes the main principlesand applications of supervised, unsupervised, and reinforcement learning in medical applications. In this context,we present a diverse range of artificial intelligence networks with potential applications in dentistry, accompanied byexisting results in the field."
옴니채널에서 온라인 주문이행을 위한 “Ship-from-Store” 전략에 대한 연구,2023,"['옴니채널', '매장배송', '강화학습', 'Omnichannel', 'Ship-from-Store', 'Reinforcement Learning']","최근 유통 산업에서는 전자상거래 기술의 발전과 모바일 기기의 대중화로 인하여 많은 유통 기업이 옴니채널 전략을 구축하고 있다. 이들 유통 기업이 채택하는 대표적인 옴니채널 전략 중 하나인 Buy-Online-Ship-from-Store (BOSS) 전략의 경우 오프라인 매장의 재고를 이용하여 온라인 주문을 처리하는 방식으로 빠른 배송, 고객 만족도 증가 등의 장점이 있다. 본 연구는 해당 전략을 수행하는 즉, 온라인 주문과 오프라인 매장을 운영하며 각 채널에서 재고를 보유하고 있는 유통업체를 가정한다. 이때, 오프라인 주문은 오프라인에서 처리하며, 온라인 주문의 경우 풀필먼트 센터 또는 오프라인 매장에서 배송되거나 주문을 거절할 수 있다. 본 연구에서는 이러한 가정 아래 온라인 주문이 발생 시 총이익을 최대화하는 것을 목적으로, 주문 수락 여부와 어느 채널을 통해 배송할지 결정하는 의사결정 문제에 대한 마르코프 의사결정 모형을 제안하고, 강화학습의 Deep Q-Network (DQN) 기법을 활용하여 최적 정책의 학습을 수행하고 결과를 도출하였다. 그 결과 오프라인 재고가 남는 경우 발생하는 잔존재고 비용을 고려해서 오프라인 재고를 활용하여 온라인 주문을 이행하는 것을 확인하였다.","In recent years, advances in e-commerce technology and the popularity of mobile devices have driven many retailers to create omnichannel strategies. One of the most common omnichannel strategies adopted by these retailers is the Buy-Online-Ship-from-Store (BOSS) strategy, which uses inventory from offline stores to fulfill online orders, resulting in faster delivery and higher customer satisfaction. This paper assume a retailer that operates online/offline stores, and holds inventory in each channel. In this case, offline orders are fulfilled offline, and online orders can be shipped from a fulfillment center or a offline store, or the order can be declined. This paper propose a Markov decision model for the decision problem of deciding whether to accept an order and which channel to ship it through, with the aim of maximizing the total profit when an online order is placed, and use the Deep Q-Network (DQN) technique of reinforcement learning to learn the optimal policy and obtain the results. The results show that the optimal policy utilizes offline inventory for online fulfillment due to the inventory costs incurred when offline inventory remains."
Real-time RL-based 5G Network Slicing Design and Traffic Model Distribution: Implementation for V2X and eMBB Services,2023,"['network model characteristic', 'RAN slicing', 'reinforcement learning (RL)', 'vehicle-to-everything (V2X)', 'enhanced mobile broadband (eMBB).']",,"As 5G mobile systems carry multiple services and applications, numerous user, and application types with varying quality of service requirements inside a single physical network infrastructure are the primary problem in constructing 5G networks. Radio Access Network (RAN) slicing is introduced as a way to solve these challenges. This research focuses on optimizing RAN slices within a singular physical cell for vehicle-to-everything (V2X) and enhanced mobile broadband (eMBB) UEs, highlighting the importance of adept resource management and allocation for the evolving landscape of 5G services. We put forth two unique strategies: one being offline network slicing, also referred to as standard network slicing, and the other being Online reinforcement learning (RL) network slicing. Both strategies aim to maximize network efficiency by gathering network model characteristics and augmenting radio resources for eMBB and V2X UEs. When compared to traditional network slicing, RL network slicing shows greater performance in the allocation and utilization of UE resources. These steps are taken to adapt to fluctuating traffic loads using RL strategies, with the ultimate objective of bolstering the efficiency of generic 5G services."
우선적 경험 재생 방식을 이용한 병목 구간 통과 자율주행 정책 연구,2023,"['Autonomous driving system', 'Bottleneck traffic', 'Deep reinforcement learning', 'Partially observable Markov decision process', 'Twin delayed deep deterministic policy gradient', 'Prioritized experience replay']","인공지능을 활용한 자율주행 연구가 가속화됨에 따라, 도로 정체와 같은 복잡한 환경에서 주행 가능한 자율주행 기술에 대한 수요가 증가하고 있다. 이에 고차원의 상태정보에 즉각적인 의사결정이 가능한 심층강화학습(deep reinforcement learning) 기반의 자율주행 연구가 주목을 받고 있다. 본 연구에서는 교통 정체가 빈번히 발생하는병목구간의 성공적인 통과를 위한 부분 관측가능한 마르코프 의사결정과정(Partially Observable Markov Decision Process; POMDP)을 제안한다. 정책 학습에는 Twin Delayed Deep Deterministic Policy Gradient(TD3) 알고리즘을 사용하며, 우선적 경험 재생(prioritized experience replay) 기반의 샘플링 방식을 사용한다. 결과적으로 우선적경험 재생 기반의 자율주행차량이 무작위(random) 경험 재생 기반 개체보다 복잡한 도로에서 우수한 성능을 보임을 확인하였다.",
심층 강화학습을 이용한 휠-다리 로봇의 3차원 장애물극복 고속 모션 계획 방법,2023,"['Wheel-Legged Robot', 'Motion Planning', 'Obstacle Crossing', 'Reinforcement Learning', 'Behavioral Cloning']",,"In this study, a fast motion planning method for the swing motion of a 6x6 wheel-legged robot to traverse large obstacles and gaps is proposed. The motion planning method presented in the previous paper, which was based on trajectory optimization, took up to tens of seconds and was limited to two-dimensional, structured vertical obstacles and trenches. A deep neural network based on one-dimensional Convolutional Neural Network (CNN) is introduced to generate keyframes, which are then used to represent smooth reference commands for the six leg angles along the robot’s path. The network is initially trained using the behavioral cloning method with a dataset gathered from previous simulation results of the trajectory optimization. Its performance is then improved through reinforcement learning, using a one-step REINFORCE algorithm. The trained model has increased the speed of motion planning by up to 820 times and improved the success rates of obstacle crossing under harsh conditions, such as low friction and high roughness."
Research on Developing a Conversational AI Callbot Solution for Medical Counselling,2023,"['Shared bikes', 'Demand forecasts', 'Linear regression', 'Machine learning', 'AI']",,"In this study, we explored the potential of integrating interactive AI callbot technology into the medical consultation domain as part of a broader service development initiative. Aimed at enhancing patient satisfaction, the AI callbot was designed to efficiently address queries from hospitals' primary users, especially the elderly and those using phone services. By incorporating an AI-driven callbot into the hospital's customer service center, routine tasks such as appointment modifications and cancellations were efficiently managed by the AI Callbot Agent. On the other hand, tasks requiring more detailed attention or specialization were addressed by Human Agents, ensuring a balanced and collaborative approach. The deep learning model for voice recognition for this study was based on the Transformer model and fine-tuned to fit the medical field using a pre-trained model. Existing recording files were converted into learning data to perform SSL(self-supervised learning) Model was implemented. The ANN (Artificial neural network) neural network model was used to analyze voice signals and interpret them as text, and after actual application, the intent was enriched through reinforcement learning to continuously improve accuracy. In the case of TTS(Text To Speech), the Transformer model was applied to Text Analysis, Acoustic model, and Vocoder, and Google's Natural Language API was applied to recognize intent. As the research progresses, there are challenges to solve, such as interconnection issues between various EMR providers, problems with doctor's time slots, problems with two or more hospital appointments, and problems with patient use. However, there are specialized problems that are easy to make reservations. Implementation of the callbot service in hospitals appears to be applicable immediately."
일반고 학생의 영어 학습부진 실태와 기초학력 증진을 위한 지원 방안 연구,2023,"['Basic Academic Ability', 'Low Achievement', 'Basic Education Guarantee', 'Learning Deficits', 'Learning Support Education', 'Remediation', '기초학력', '학습부진', '기초학력 보장', '학습결손', '학습지원교육', '보정교육']","모든 학생의 기초학력을 보장하는 국가 교육책임제를 위한 ｢기초학력 보장법｣과 ｢기초학력 보장법 시행령｣이 제정되면서 교과 학습부진학생의 학습 지원을위한 맞춤형 교수학습 방안에 대한 관심이 높아지고 있다. 본 연구의 목적은 영어학습에 어려움을 겪고 있으며 정규 영어 수업을 따라가기 거의 불가능한 학습부진학생의 교수학습 실태와 요구를 분석하고 이를 바탕으로 지원 방안을 제안하는 것이다.실태와 요구 조사는 영어 학습에 어려움을 느낀 시기와 원인, 적극적으로 참여한 수업방식, 도움이 되는 학습방식, 영어 학습에 대한 태도 등에 대하여 학생과 교사 대상설문조사와 심층면담, 수업관찰을 통해 이루어졌다. 수집된 자료 분석 결과를 토대로초⋅중⋅고등학교급 간 연계된 단위 학교 교육과정 편성 및 운영, 기초 영어 학습에도움이 되는 교과목 편성⋅운영, 부진 학생 중심의 영어 수업, 원어민 또는 보조교사를활용한 즉각적 학습 지원, 시청각 자료나 멀티미디어를 활용한 반복 학습 지원, 영어에대한 외재적 가치를 활용한 학습 동기 및 흥미 유발 지원 방안을 제안한다.","This research aims to propose educational policies and strategies to support low achievers in English subject at general high schools. Data was gathered from student and teacher questionnaires, interviews, and classroom observations to identify issues and support areas. The triangulated analysis of the collated data reveals that the causes of low achievement in learning English are frustration and giving up, a lack of educational support customized to individual student's needs, no effective study skills, a negative learning experience, and a gap between the curriculum and students' needs. Potentials for improvement in English include developing a strong external motivation to learn, helping students cope with difficulties, promoting shared growth through learning in cooperation, self-reflection on current study skills and efforts to change, and providing sustainable support. Support strategies are proposed in areas of perceptions about low achievers, basic standards in curriculum, a liaison system to support low achievers to set up the management system to prevent subject learning deficits at primary and middle schools, introducing subject learning counselors to schools, implementing programs to reinforce study skills, and to support low achievers in a liaison with comprehensive study clinic centers."
전송률 분할 다중 접속 기술을 활용한비면허 대역의 트래픽과 공정성 최대화 기법,2023,"['5G Network', 'Rate Splitting Multiple Access', 'Unlicensed Band', 'Game Theory', 'Bargaining Solution', 'Reinforcement Learning', '5G 네트워크', '전송률 분할 다중 접속', '비면허 대역', '게임이론', '협상 해법', '강화 학습']","다양한 서비스가 등장으로 인해 스펙트럼 부족 문제가 가속하됨에 따라, 면허 대역에서 통신하던 사용자들을 비면허 대역에서 통신하는NR-U(New Radio-Unlicensed)가 등장하였다. 하지만 NR-U 네트워크 사용자로 인해 동일한 비면허 대역에서 통신하는 Wi-Fi 네트워크 사용자의성능이 감소하게 된다. 본 논문에서는 NR-U 네트워크 사용자와 WiFi 네트워크 사용자가 공존해있는 비면허 대역의 처리량과 비면허 대역의 사용에대한 공평성을 동시에 최대화하는 것을 목표로 한다. 먼저 비면허 대역에서 전송률 분할 다중 접속 기술을 활용한 NR-U 네트워크의 합-전송 속도(Sum of Rate)를 최대화하기 위해 강화 학습의 몬테 카를로 정책 하강법(Monte Carlo Policy Gradient)을 활용한 최적의 전력 할당 기법을 제안하였다. 그 뒤, 동일한 비면허 대역에서 NR-U 네트워크와 WiFi 네트워크의 공존을 위해 시스템 처리량과 공정성을 동시에 최대화할 수 있는 게임이론의 순차적 라이파 협상 해법(Sequential Raiffa Bargaining Solution)을 활용한 채널 점유 시간 분할 알고리즘을 제안하였다. 시뮬레이션 결과에서 동일한 전력 할당 기법을 사용하였을 때, 본 논문에서 제안한 전송률 분할 다중 접속 기술이 기존의 다중 접속 기술들보다 더 빠른 합-전송속도를보임을 확인하였다. 또한 비면허 대역 네트워크의 전송량과 공평성을 비교해본 결과 본 논문의 순차적 라이파 협상 해법을 활용한 채널 점유 시간분할 알고리즘이 타 알고리즘보다 처리량과 공정성을 동시에 만족함을 입증하였다.","As the spectrum shortage problem has accelerated by the emergence of various services, New Radio-Unlicensed (NR-U) has appeared,allowing users who communicated in licensed bands to communicate in unlicensed bands. However, NR-U network users reduce theperformance of Wi-Fi network users who communicate in the same unlicensed band. In this paper, we aim to simultaneously maximizethe fairness and throughput of the unlicensed band, where the NR-U network users and the WiFi network users coexist. First, we proposean optimal power allocation scheme based on Monte Carlo Policy Gradient of reinforcement learning to maximize the sum of rates ofNR-U networks utilizing rate-splitting multiple access in unlicensed bands. Then, we propose a channel occupancy time division algorithmbased on sequential Raiffa bargaining solution of game theory that can simultaneously maximize system throughput and fairness for thecoexistence of NR-U and WiFi networks in the same unlicensed band. Simulation results show that the rate splitting multiple access showsbetter performance than the conventional multiple access technology by comparing the sum-rate when the result value is finally convergedunder the same transmission power. In addition, we compare the data transfer amount and fairness of NR-U network users, WiFi networkusers, and total system, and prove that the channel occupancy time division algorithm based on sequential Raiffa bargaining solutionof this paper satisfies throughput and fairness at the same time than other algorithms."
초등학생의 동기 강화 자기조절전략개발(SRSD) 쓰기 프로그램 효과,2023,"['elementary school student', 'self-regulation', 'motivational regulation strategy', 'writing performance', 'learning motivation', 'self-regulated strategy development(SRSD)', '초등학교 고학년 학생', '자기조절', '동기조절 전략', '학습동기', 'SRSD쓰기 교수']",,"The purpose of this study was to develop a program to reinforce students' writing performance and learning motivation through writing and to test the effectiveness of the program. We developed「POW+TREEPLUS」, a motivation-enhancing self-regulated strategy development (SRSD) writing program. During effectiveness testing, the program, was applied to three groups motivation-enhancing SRSD writing group, an SRSD writing group, and a control group. The participants were 53 sixth-grade elementary school students from three classes. The results of the effectiveness testing of the motivation-enhancing SRSD writing program「POW+TREEPLUS」were as follows. We found that「POW+TREEPLUS」improved writing quality and self-efficacy for writing among the students. In addition,「POW+TREEPLUS」had a positive effect on the identified regulation and promoted the use of environmental control strategies. Finally, we found that the effect of the program on writing quality was different depending on the level of prior achievement in writing. This study found the need to teach explicitly motivational regulation strategies. In addition, this study is meaningful in that we developed a writing program that is easy to apply in the classroom and enhances student' writing performance and learning motivation.Educational Impact and Implications : This study suggests that: for the program to be applicable and easily implemented in the field, it should be developed based on systematic procedures. This study also suggests that it is an effective strategy to internalize the usefulness and instrumentality of writing when learning to write. In addition, this study suggests the need for educational interventions that motivate students with low achievement in writing along with providing effective learning strategies."
A Study on Ship Route Generation with Deep Q Network and Route Following Control,2023,"['ship route generation', 'coastal navigation', 'route following control', 'deep Q network', 'reinforcement learning']",,"Ships need to ensure safety during their navigation, which makes route determination highly important. It must be accompanied by a route following controller that can accurately follow the route. This study proposes a method for automatically generating the ship route based on deep reinforcement learning algorithm and following it using a route following controller. To generate a ship route, under keel clearance was applied to secure the ship's safety and navigation chart information was used to apply ship navigation related regulations. For the experiment, a target ship with a draft of 8.23 m was designated. The target route in this study was to depart from Busan port and arrive at the pilot boarding place of the Ulsan port. As a route following controller, a velocity type fuzzy PID controller that could compensate for the limitation of a linear controller was applied. As a result of using the deep Q network, a route with a total distance of 62.22 km and 81 waypoints was generated. To simplify the route, the Douglas-Peucker algorithm was introduced to reduce the total distance to 55.67 m and the number of way points to 3. After that, an experiment was conducted to follow the path generated by the target ship. Experiment results revealed that the velocity type fuzzy PID controller had less overshoot and fast settling time. In addition, it had the advantage of reducing the energy loss of the ship because the change in rudder angle was smooth. This study can be used as a basic study of route automatic generation. It suggests a method of combining ship route generation with the route following control."
혁신적 학교풍토 및 교육성과 변화에 관한 사례연구- 특성화고 혁신지원사업을 중심으로,2023,"['혁신적 학교풍토', '교육성과', '특성화고 혁신지원사업', '학습조직이론', '사례연구', 'Innovative School Climate', 'Educational Performance', 'Specialized High School Innovation Support Project', 'Learning Organization Theory', 'Case Study']",,"This study aims to reveal the process of achieving innovative school climate and educational outcomes, and limitations in the process of the Specialized High School Innovation Support Project using the learning organization theory by applying a case study method. For this, the cases of three schools that operated the Innovation Support Project and the Attractive Vocational High School Project were investigated, and a teacher or principal in charge of the project were interviewed.The main results and implications of the study are presented as follows. First, case schools experienced changes in the innovative school climate, and a principal or teacher played an important role in the change. The 'reinforcement process', in which vision sharing, teacher competency development, and spatial innovation acted as a driving force, manifested the school climate and the educational performance. The reinforcement conditions were the autonomy of budget utilization, the leadership of principals, and the mind innovation of teachers. Whereas, constraints for change include excessive work load, climate of non-cooperation, lack of support from the principal, and COVID-19, which can lead to the operation of a 'balanced process' that is difficult to sustain a positive impact on the project. The result of this study confirmed that the Innovation Support Project can have a positive impact on the climate and performance of schools. As a result, this study suggests that the innovation climate as intangible school capital through school-level education policies can induce positive outcomes."
보안등급 기반 분산신원증명을 활용한 지능형 접근 제어 시스템,2023,"['분산신원증명', '데이터 접근 제어', '보안등급', '강화학습', '보안 시스템', 'decentralized identity', 'data access control', 'security level', 'reinforcement learning', 'security system']","최근 데이터의 폭증과 시스템의 복잡성 증가로 데이터 유출 문제에 직면하고 있다. 데이터 유출 대응을 위한 평균 비용의 상승으로 기업은 데이터 접근 제어의 중요성을 보다 크게 인식하고 있다. 그러나 기존 데이터 접근 제어 시스템은 사용자의 데이터 접근 및 사용을 제한하고 있으며, 접근하기 위해서는 자격증명을 제출하여 특정 권한을 획득해야 한다. 이러한 경우 개인의 자격증명은 타인에 의해 관리되며, 외부 상황에 신속하게 대처하기 힘든 한계가 존재한다. 이에 본 논문에서는 보안등급 기반 분산신원증명을 활용한 지능형 접근 제어 시스템을 제안한다. 본 시스템을 통해 사용자는 본인이 직접 자격증명을 관리하며, 외부 변화로 인한새로운 권한 필요 시 강화학습 모델을 통해 필요한 자격증명을 자동으로 선택할 수 있다. 또한 본 시스템은검증 가능한 자격증명 및 프레젠테이션을 통해 기밀성, 무결성, 부인방지의 보안 요구사항을 충족한다. 향후강화학습 뿐만 아닌 새로운 인공지능 모델을 적용하여 분산신원증명 기술을 고도화할 수 있다.","Facing the recent surge in data volume and increasing complexity of systems, organizations are confronted with data security challenges. The average cost of data breaches has risen, leading businesses to recognize the heightened importance of data access control. However, existing data access control systems restrict users' access and require the submission of credentials to obtain specific permissions. In such cases, individuals' credentials are managed by others, posing limitations in promptly adapting to external changes. In this paper, we propose a intelligent access control system using security level-based decentralized identity (DID). Through this system, users directly manage their credentials, and in the event of new authorization requirements due to external changes, the reinforcement learning model automatically selects the necessary credentials. Furthermore, the proposed system meets security requirements, including confidentiality, integrity, and non-repudiation, through verifiable credentials and presentations. Future advancements can be achieved by applying not only reinforcement learning but also incorporating novel artificial intelligence models to enhance decentralized identity technology."
베이비부머 세대의 평생교육 참여동기가 성공적노화에 미치는 영향: 학습몰입의 매개효과,2023,"['베이비부머', '성공적노화', '평생교육 참여동기', '학습몰입', '고령사회', 'Baby Boomers', 'Successful Aging', 'Motivation to Participate in Life-long Education', 'Learning Commitment', 'Aging Society']","본 연구는 베이비부머 세대의 성공적인 노화에 관한 연구로, 베이비부머 세대의 평생교육 참여동기가 성공적노화에 미치는 영향을 알아보고, 이들 간 관계에서 학습몰입이 매개효과를 보이는지 구조적으로 검증하는데 목적이 있다. 본 연구의 결과는 다음과 같다. 첫째, 베이비부머 세대의 평생교육 참여동기는 성공적노화에 직접적인 영향을 미치는 것으로 나타났다. 둘째, 베이비부머 세대의 평생교육 참여동기는 학습몰입에 직접적인 영향을 미치는 것으로 나타났다. 셋째, 베이비부머 세대의 학습몰입은 성공적노화에 직접적인 영향을 미치는 것으로 나타났다. 넷째, 베이비부머 세대의 평생교육 참여동기와 성공적노화의 관계에서 학습몰입은 통계적으로 유의미한 매개효과가 있는 것으로 나타났다. 이와 같은 연구결과를 바탕으로 베이비부머 세대의 성공적노화에 미치는 영향에서 평생교육 참여동기의 중요성을 확인하였고, 학습몰입과 같은 역량을 강화할 필요가 있음을 확인하였다. 따라서 베이비부머 세대는 초고령사회에 접어는 시점에서 핵심적인 인력으로 부가될 것이기 때문에 국가차원에서 베이비부머 세대 교육의 운용방안에 대한 연구를 강화하고, 고령사회에 노인의 성공적노화를 향상시키기 위해서는 적극적이고 체계적으로 교육적 관점에서 접근해야 할 것이다.","The purpose of this study, which concerns the successful aging of the baby boomers, is to examine the impact of the motivation for baby boomers to participate in life-long education in their successful aging and structurally verify whether learning engagement show a mediating effect in their relationship. The results of this study are as follows. First, it was found that the baby boomer generations motivation to participate in life-long education has a direct effect on successful aging. Second, the baby boomer generations motivation to participate in life-long education has a direct effect on learning engagement. Third, learning engagement of the baby boomer generation has a direct effect on successful aging. Forth, it was found that learning engagement had a statistically significant mediating effect in the relationship between motivation to participate in life-long education and successful aging of the baby boomer generation. As such, this study showed the importance of the motivation to participate in lifelong learning in the impact upon the successful aging of baby boomers, while confirming that capacities such as learning engagement need to be enhanced. Since baby boomers will be added as key personnel at the point of entering a super-aged society, more active and systematized educational view should be used as approaching method to reinforce the study on national level baby boomers education plan and to improve the successful aging of the elderly. In addition, as we become a super-aged society, baby boomers will be recognized as an importance workforce."
"AI 활용 역량 강화 교육 프로그램이 중등 과학 예비교사들의 AI 이해, AI 효능감  및 AI 활용에 대한 인식 개선에 미친 효과 분석",2023,"['AI competence', 'AI understanding', 'AI efficacy', 'perception of AI utilization', 'secondary science pre-service teachers', 'AI 역량', 'AI 이해', 'AI 효능감', 'AI 활용에 대한 인식', '중등과학 예비교사']","이 연구에서는 중등 과학 예비교사들의 AI 활용 역량 강화를 위하여, 구글의 티쳐블머신을 활용하여 예비교사들이 ‘AI 기반 분자구조맞춤형 학습 지원 도구’를 직접 생성해 보는 프로젝트 활동을 개발및 적용하였다. 이를 위하여, 충청북도 소재 H 대학교 화학교육과에재학 중인 3학년 예비교사 26명을 대상으로 비교과 활동 시간에 개발된 프로그램을 14차시 동안 적용하였고, ‘AI의 작동 원리 이해’, ‘과학수업에서 AI 활용에 대한 효능감’, ‘과학 수업에서 AI 활용 방안’에대한 인식을 살펴보았다. 연구 결과, 본 연구에서 개발한 프로그램은예비교사들에게 머신러닝에 대한 AI 기술의 작동 원리를 기초적 수준에서 이해시키고, 그 사용법을 익히는 데 효과가 있는 것으로 나타났다. 또한 본 연구에서 개발한 프로그램은 과학 수업에서 AI 활용에대한 예비교사들의 효능감을 높이는 데에도 효과가 있는 것으로 나타났다. 그리고 예비교사들은 학생들의 과학 개념 이해를 도울 수 있는새로운 교수학습 전략이자 도구로서 AI 기술의 활용 방안 측면을인식한 것으로 나타났다. 이에 본 연구에서 개발한 프로그램은 기초적 수준에서 예비교사들의 AI 활용 역량 강화 및 인식 개선 등에긍정적 영향을 미쳤음을 알 수 있었다. 이에 대한 시사점에 대해 논의하였다.","In this study, in order to strengthen the AI utilization competency of pre-service secondary science teachers, a project activity in which pre-service teachers directly create an ‘AI-based molecular structure customized learning support tool’ by using Google’s teachable machine was developed and applied. To this end, the program developed for 26 third-grade pre-service teachers enrolled in the Department of Chemistry Education at H University in Chungcheongbuk-do was applied for 14 sessions during extracurricular activities. Then, the perceptions of ‘understanding how AI works’, ‘efficacy of using AI in science classes’, and ‘plans to utilize AI in science classes’ were investigated. As a result of the study, it was found that the program developed in this study was effective in helping pre-service teachers understand the operating principle of AI technology for machine learning at a basic level and learning how to use it.In addition, the program developed in this study was found to be effective in increasing the efficacy of pre-service teachers for the use of AI in science classes. And it was also found that pre-service teachers recognized the aspect of using AI technology as a new teaching⋅learning strategy and tool that can help students understand science concepts. Accordingly, it was found that the program developed in this study had a positive impact on pre-service teachers’ AI utilization competency reinforcement and perception improvement at the basic level. Implications of this were discussed."
기초 문식성 함양을 위한 한글책임교육 정책의 성과와 지향점,2023,"['Responsible Hangul Education', 'basic literacy', 'early literacy', 'Korean language acquisition', 'Korean language acquisition diagnosis', 'Hangul', '한글책임교육', '기초 문식성', '초기 문식성', '한글 해득', '한글해득 진단', '한글 또박또박']",,"The purpose of this study is to diagnose the achievements of the Responsible Hangul Education policy, and to explore the necessary policy supplements or future directions to support the cultivation of basic literacy. In order to diagnose the achievements of the Responsible Hangul Education policy, the progress and major achievements so far were analyzed by dividing them into national-regional-school aspects and ground conditions for Responsible Hangul Education-diagnosis tools-teaching and learning materials.First of all, I divide the results of responsible Hangul education into national- regional-school aspects, at the national level, the continuous expansion of Hangul education hours, reinforcement of Hangul education contents, development and dissemination of materials(Hangul Tobaktobak, chanchan Hangul) for Hangul responsible education, development of distance learning contents for teachers, dissemination of high-quality reading materials, etc. At the local level, there are various plans for and support for students who do not understand Korean, the preparation of curriculum considering local conditions, and training for teachers in cities and provinces. At the school level, there are various approaches to reduce the burden of learning Korean for students, the operation of small-scale supplementary guidance programs, and the operation of customized curriculum for 1st and 2nd graders.Next, it was possible to explore some complementary points to improve the completeness of the Responsible Hangul Education education policy. At the national level, it is necessary to promote the quality of Responsible Hangul Education, upgrade diagnostic tools for learning Hangul, and systematize training to strengthen the Responsible Hangul Education competency of prospective teachers. At the local level, in order to establish and promote a regionally specialized implementation plan, collect practical data on Hangul education, improve support measures for Responsible Hangul Education for schools, and overall trends such as the flow of talent development and the latest training techniques to strengthen local teachers’ Hangul education competency. Attention should be paid to trend identification and training.At the school level, efforts must be made to improve the operation of school and class curriculum for Responsible Hangul Education, support proper time Hangul Education, and strengthen school-family linkages for Hangul education."
AR 카드를 이용한 영어 단어 및 문장 구조 교육 콘텐츠 개발,2023,"['Augmented reality', 'AR card', 'Unity', 'Education contents', 'English education', '증강 현실', '증강현실 카드', '유니티', '교육 콘텐츠', '영어 교육']",,"Augmented reality (AR) technology can inspire fun and interest in users. If applied to the educational field, it can give joy to learners, thereby maximizing the efficiency of education. Based on this augmented reality technology, we develop English word and sentence structure education contents using AR cards. The content may proceed with English learning by selecting one of the learning modes and an evaluation mode. When learning mode is selected, the animal card is recognized first to reinforce the animal. Augmented animals allow learners to choose English words. If an English word is selected, the augmented animal changes to match the word. When all choices are completed, an augmented animal animation is presented, combining and transforming words to match the sentence structure to create and read the right sentence. In the evaluation mode, the learner looks at the augmented animal in the background and makes it the same as the augmented animal specified in the English word, using methods such as the learning mode. Through this process, we intend to create English sentence learning content that combines visual and auditory elements."
DQN기반 차량배차 자동화 모델,2023,"['Reinforcement Learning', 'DQN', 'Automation', 'Vehicle Dispatch', 'Scheduling Optimization']","우리나라의 인구 부족은 대표적인 사회적 문제이며, 그에 따른 대응 수단으로 자동화가 제시되고 있다. 자동화는인공지능을 적용하여 더욱 확대되고 있으며 군에서도 감시정찰, 지휘통제 분야뿐 아니라 행정업무에 대해서도 자동화가추진되고 있다. 본 연구에서는 군의 행정업무 분야 중 일일 단위로 반복되며 많은 시간이 소모되는 차량배차 업무에대하여 다루었다. 군의 차량배차 업무는 배차신청이 접수되면 가용자원(차량, 운전병)을 편성해주는 것이다. 본 연구는이러한 차량배차 업무를 대체 할 수 있는 차량배차 자동화 모델을 만들기 위하여 진행하였다. 연구에서 활용한 모델은스케줄링 문제에 강점이 있는 강화학습을 선정하였으며, 그중에서도 기본 모델인 Q-learning을 개선하여 더욱 복잡한환경에도 뛰어난 성능을 보이는 DQN(Deep Q-Network)을 활용하였다. DQN기반의 차량배차 자동화 모델은 가용차량, 가용 운전병, 배차신청 내역을 바탕으로 차량배차 편성 수를 최대화하도록 모델링하고 학습을 진행하였다. 이후모델의 성능이 사람을 대체할 수 있는 수준인지 판단하기 위해 사람과 모델을 대상으로 차량배차 편성실험을 진행하였으며, 그 결과 모델의 차량배차 편성량은 사람이 편성하는 것 대비 95.63%의 성능을 보였으며, 배차편성 시간과 편성오류측면에서는 모델이 더 높은 성능을 보였다. 본 연구를 시작으로 향후 군 차량배차 업무의 자동화 및 효율성 증대가 이루어지길 기대한다.",
조선소 병렬 기계 공정에서의 납기 지연 및 셋업 변경 최소화를 위한 강화학습 기반의 생산라인 투입순서 결정,2023,"['Reinforcement learning(강화학습)', 'Dynamic scheduling(동적 스케줄링)', 'Parallel machine scheduling problem(병렬 기계 스케줄링)', 'Tardiness(납기 지연)', 'Set-up(셋업)']",,
DQN 강화학습 기반 최대 효율 구동 가능한 최적 IPT 코일 턴 수 설계 연구,2023,"['Reinforcement learning(RL)', 'WPT(Wireless Power Transfer)', 'Inductive Power Transfer(IPT)', 'DQN(Deep Q-learning network)', 'ε-greedy process']",,
A tutorial on the art of dynamic programming for some issues concerning Bellman’s principle of optimality,2023,['Dynamic programmingPrinciple of optimalityState descriptionCommon sense'],,"Reinforcement learning (RL) is fundamental to current artificial intelligence (AI). Since dynamic programming, which is based on Richard Bellman’s principle of optimality, is the basis of RL (and other AI disciplines such as A* search), it is important to apply that principle correctly and artfully. This tutorial uses examples, many from published articles, to examine both the artful and occasionally erroneous application of Bellman’s principle. Our contribution is twofold. First, we emphasize the necessity of a general thought experiment by asking what we call “consultant questions” to determine the proper state space for DP formulation to be established by Bellman’s optimality principle. Second, we convey the role of art based on common sense and effortful cleverness in designing efficient DP. Since Bellman’s principle is intuitive based on common sense, it is sometimes misunderstood. For illustrative purposes, given a directed acyclic graph (DAG), we consider four deterministic minimum-cost path network problems (found in the literature), each bringing up some validity issue concerning Bellman’s principle on a different criterion. We approach them consistently by the conventional wisdom of state augmentation (on top of the physical system state space). As a result, we show that our artful choice of state description not only renders the principle valid in each problem, but also makes each DP as efficient as the standard DP that solves a shortest-path problem in the same DAG, circumventing successfully the so-called curse of dimensionality, a price to be paid frequently by state enlargement. After that, we discuss the potential importance of the treated type of path network problems for practical applications (e.g., communications network)."
방어 자산의 가용성 상태를 활용한 강화학습 기반 APT 공격 대응 기법,2023,"['Machine Learning', 'Reinforcement Learning', 'MITRE ATT&amp', 'CK', 'CTI', 'Cyber Simulator']",,
Strategy to coordinate actions through a plant parameter prediction model during startup operation of a nuclear power plant,2023,"['Autonomous operation Reinforcement learning Soft actor-critic', 'Long short-term memory', 'Parameter prediction', 'Nuclear power plants']",,"The development of automation technology to reduce human error by minimizing human intervention is accelerating with artificial intelligence and big data processing technology, even in the nuclear field.Among nuclear power plant operation modes, the startup and shutdown operations are still performed manually and thus have the potential for human error. As part of the development of an autonomous operation system for startup operation, this paper proposes an action coordinating strategy to obtain the optimal actions. The lower level of the system consists of operating blocks that are created by analyzing the operation tasks to achieve local goals through soft actor-critic algorithms. However, when multiple agents try to perform conflicting actions, a method is needed to coordinate them, and for this, an action coordination strategy was developed in this work as the upper level of the system. Three quantification methods were compared and evaluated based on the future plant state predicted by plant parameter prediction models using long short-term memory networks. Results confirmed that the optimal action to satisfy the limiting conditions for operation can be selected by coordinating the action sets. It is expected that this methodology can be generalized through future research."
하나로 노심 내 영상기반 기포발생 및 중성자 핵변환도핑 동작상태  감시 시스템 개발,2023,"['Artificial Intelligence', 'Deep Learning', 'HANARO Reactor', 'Air Bubble', 'Neutron Transmutation Doping', 'Monitoring System', 'Object Detection', 'Image Processing', '인공지능', '딥러닝', '하나로 원자로', '기포', '중성자 핵변환 도핑', '감시 시스템', '객체검출', '이미지 처리']","본 연구는 한국원자력연구원에서 운영 중인 하나로 연구용 원자로의 노심 내 영상기반 감시 시스템개발을 다루고 있다. 이 시스템은 하나로 원자로의 심층방어능력을 강화하기 위해 딥러닝 기반의 영상 감시기술을 도입하였다. 원자로 노심 근처에 설치된 CCTV를 통해 원자로 노심의 이미지를 분석하여 기포와 중성자 핵변환 도핑 장치의 상태를 감시한다. 이 과정에서 Faster R-CNN 알고리즘 기반으로 실시간 객체 탐지를 구현하였으며, 경량화된 백본 모델과 하이퍼파라미터 최적화를 통해 높은 정확도를 유지하면서도 실시간처리가 가능하도록 시스템을 개선했다. 이 시스템 도입으로 운전원의 작업 부담 감소와 원자로의 안정적 운영에 기여할 것으로 기대한다.","This paper describes the development of a monitoring system for the HANARO reactor core operated by the Korea Atomic Energy Research Institute (KAERI). This system employs a deep-learning-based video monitoring technology to reinforce the defense-in-depth capability of the HANARO reactor. The system analyzes imagery captured by CCTV cameras installed near the reactor core to detect air bubbles and monitor the status of the neutron transmutation doping device. During this process, the system performs real-time object detection by applying the Faster R-CNN algorithm while maintaining a high accuracy through a lightweight backbone model and hyperparameter optimization. The implementation of this system is expected to reduce the workload of operators and contribute to the stable operation of the reactor."
모바일 엣지컴퓨팅의 서비스 마이그레이션을 위한 최적 경로 알고리즘에 관한 연구,2023,"['MEC', 'Migration', 'Handoff', 'Reinforcement Learning', 'DQN', '모바일 엣지 컴퓨팅', '마이그레이션', '핸드오버', '강화학습', '딥큐네트워크']","MEC(Mobile Edge Computing)에서 사용자의 이동성 지원 및 서비스의 연속성 보장은 중요한 요소이다. 특히 다양한 네트워크와 이기종의 서비스가 혼재하는 IoT(Internet of Things) 환경에서의 마이그레이션 경로 결정 문제는 더욱 복잡하다. 본 연구에서는 이기종의 다양한 서비스가 혼재하는 환경에서 UE(User Equipment)의 이동에도 끊김없이 서비스를 제공해 사용자의 QoS(Quality of Service)를 높이고자 한다. 이동성 지원을 위해 마이그레이션 비용과 전송비용, 에너지 소비량을 고려한 총비용을 계산하고, UE별 가중치를 설정하여 마이그레이션 여부 및 최적의 경로를 결정한다. NS3로 이기종 서비스가 혼재하는 네트워크 환경을 구축하며, DQN(Deep Q-Network) 알고리즘에 가중치를 설정한 보상의 합으로 성능을 확인한다. 실험을 통해 제안하는 weight-DQN 알고리즘이 다양한 서비스가 혼재하는 환경에서 QoS를 더욱 향상시키는 것을 확인한다.","In MEC(Mobile Edge Computing), user mobility support and service continuity guarantee are important factors. In particular, the problem of determining a migration path in an IoT(Internet of Things) environment in which various networks and heterogeneous services coexist is more complicated. In this study, we intend to improve the QoS(Quality of Service) of users by providing services without interruption even when UE(User Equipment) moves in an environment where heterogeneous and various services coexist. To support mobility, the total cost considering the migration cost, transmission cost, and energy consumption is calculated, and weights are set for each UE to determine migration and the optimal path. With NS3, a network environment in which heterogeneous services coexist is established, and performance is confirmed by the sum of compensations with weights set in the DQN(Deep Q-Network) algorithm. Experiments confirm that the proposed algorithm further improves QoS in an environment where various services coexist."
동적 저궤도 위성 네트워크에서 온보드 강화학습 기반 라우팅을 위한 이종 프로세서 기반 추론 병렬화 기술,2023,"['heterogeneous processors', 'parallelization', 'deep reinforcement learning']",,
STPA-RL: 강화학습을 이용한 STPA에서 손실 시나리오 분석,2023,"['loss scenario', 'STPA', 'reinforcement learning', 'hazard analysis', 'process industry system']",,
Efficient End-to-End Failure Probing Matrix Construction in Data Center Networks,2023,"['Data center network', 'deep reinforcement learn- ing', 'failure detection', 'probing matrix construction.']",,"Data centers play an essential role in the functioningof modern society. However, failures are unavoidable in datacenter networks (DCN) and will lead to negative impact on allapplications. Therefore, researchers are interested in the rapiddetection and localization of failures in DCNs.In this paper, we present a theoretical model to analyze theend-to-end failure detection methods in data center networks.Our numerical results verify that the proposed theoretical modelis accurate. In addition, we propose an algorithm to constructprobing matrices based on an enhanced probing path selectionindicator. We also introduce deep reinforcement learning (DRL)method to solve the problem and propose a DRL-based probingmatrix construction algorithm. Our experimental results showthat both of the proposed algorithms for constructing probingmatrices achieve better performance in detection accuracy thanexisting methods. We discussed different scenarios that thealgorithms are applicable to that can improve detection accuracyor construction speed performance."
하모니 서치 알고리즘을 이용한 심층 강화학습 하이퍼파라미터 최적화,2023,"['Hyperparameter tuning', 'Optimization', 'Reinforcement learning']",,
PPO 알고리즘을 이용한 능동위상배열안테나적응형 고속 보정 방법,2023,"['Phased Array Antennas', 'Far-field Calibration', 'Reinforcement Learning', 'Radar', 'Communication']","본 논문에서는 원전계 환경에서 위상배열안테나를 고속 보정하는 방법이 제안되었다. 원전계에서 수신된 전력만을 통해 각 안테나 요소를 보정하는 기존 rotating-element electric-field vector (REV) 방법을 간소화 한 최대값 보정 방법과, 각 안테나 요소가아닌 부배열 단위로 묶어서 보정하는 방법이 제안되었다. PPO 알고리즘을 이용하여 위상배열안테나의 분포에 최적화된 파티셔닝을찾고, 그에 따른 부배열 단위로 보정하여 기존 방법 대비 더 빠른 보정이 가능한 적응형 최대값 보정 방법이 제안 및 시뮬레이션검증되었다. 보정이 이루어지는 동안 위상배열안테나의 이득이 더 높을 뿐 아니라, 형성되는 빔 패턴이 기존 방법보다 이상적인 빔패턴에 더 가깝다",
산업용 사물 인터넷을 위한 프라이버시 보존 연합학습 기반 심층 강화학습 모델,2023,"['Data optimization', 'Deep neural networks', 'Deep reinforcement learning', 'Federated learning']",,
ChatGPT을 활용한 디지털회로 설계 능력에 대한 비교 분석,2023,"['ChatGPT(Generative Pre-trained Transformer)', 'RLHF(Reinforcement Learning from Human           Feedback)', 'Verilog HDL(Hardware Description Languge)', 'Synthesis', 'FSM(Finite State Machine)', '챗GPT', '인간 피드백형 강화 학습', '베릴로그 HDL', '합성', '유한상태머신']",,"Recently, a variety of AI-based platform services are available, and one of them is ChatGPT that processes a large quantity of data in the natural language and generates an answer after self-learning. ChatGPT can perform various tasks including software programming in the IT sector. Particularly, it may help generate a simple program and correct errors using C Language, which is a major programming language. Accordingly, it is expected that ChatGPT is capable of effectively using Verilog HDL, which is a hardware language created in C Language. Verilog HDL synthesis, however, is to generate imperative sentences in a logical circuit form and thus it needs to be verified whether the products are executed properly. In this paper, we aim to select small-scale logical circuits for ease of experimentation and to verify the results of circuits generated by ChatGPT and human-designed circuits. As to experimental environments, Xilinx ISE 14.7 was used for module modeling, and the xc3s1000 FPGA chip was used for module embodiment. Comparative analysis was performed on the use area and processing time of FPGA to compare the performance of ChatGPT products and Verilog HDL products."
다중 스펙트럼 채널 접근을 위한 강화학습 알고리즘 연구,2023,"['강화학습', '다중 스펙트럼 채널 접근', 'Reinforcement Learning', '802.11ax', 'Multi-Spectrum Channel Access', 'DDPG']",,
안정적인 베팅게임 운영을 위한 우선순위 기반의 MCTS 기법 연구,2023,"['MLPT', 'MCTS', '강화학습', '섰다', 'AI', 'MLPT', 'MCTS', 'Reinforcement Learning', 'Seotda', 'AI']","게임 AI에 사용되는 알고리즘 중 MCTS를 적용하는 방법이 널리 사용된다. 그중 Tree Policy로 UCT 알고리즘을 활용하는 방법이 존재하지만, 변동성이 많은 불완전 정보 게임에서는 좋은 성능을 보장할 수 없는 단점이 있다. 본 논문에서는 불완전 정보 게임에서의 성능 보장을 위해 각 노드의 우선순위를 활용한 MLPT(Multi Level Priority List) 알고리즘을 Tree Policy로 사용하는 방식을 제안하였다. MLPT는 자식 노드 중 최상위 레벨의 선택 가능한 첫 노드를 선택하여 실행한다. 선택한 노드의 승패에 우선순위가 조정된다. 따라서  MLPT는 베팅 시작 금액이 보유 금액의 2%였을 시 단일 게임에 대한 평균 보상비율은 101.237%, 표준편차는 0.0815, 승률은 51.739%가 나왔다. 파산까지 진행 시 승률은 97.8%, 이긴 경우 판수는 47.7판, 졌을 경우 판수는 60.2판으로 측정되었다. 다른 Tree Policy에 비해 가장 안정적인 수익을 냈으며, 그로 인해 안정적으로 베팅하여 판수가 많은 것을 알 수 있다. 따라서 제안하는 MLPT는 안정적인 베팅을 하여 기존의 방식보다 성능을 개선함을 보여준다.","The MCTS algorithm is frequently used in game AI. The commonly used tree policy is the UCT algorithm. In this paper, we propose the use of MLPT (Multi-Level Priority List) algorithm as a tree policy to ensure performance and optimize it for different game fields. MLPT selects the first available node from the top-level children of the node and adjusts its priority based on the outcome. As a result, when starting bet was 2% of the current amount, the average reward ratio was 101.237%, standard deviation was 0.0815, and winning rate was 51.739%. In games played until bankruptcy, the winning rate was 97.8% with 47.7 wins and 60.2 losses. MLPT provided the most stable profits compared to other tree policies and showed that it was a stable bet with a higher number of wins. The proposed MLPT algorithm outperforms existing methods by providing stable bets."
다양한 채널 혼잡도에 적응하는 셀룰러 V2X의 DQN 기반 분산혼잡제어,2023,"['cellular vehicle-to-everything mode 4', 'decentralized congestion control', 'reinforcement learning', 'deep Q-network', '.']",,"In a 3GPP LTE cellular vehicle-to-everything(C-V2X) mode 4, each vehicle user equipment(VUE) independently selects available radio resources using the sensing-based semi-persistent scheduling(SB-SPS) algorithm. As the density of VUEs increases, packet collisions increase, which leads to performance deterioration. This paper has proposed an enhanced DQN(Deep Q-Network)-based distributed congestion control(DCC) to adaptively control the transmission time interval according to densities of VUE(Vehicle User Equipment)s by training a DQN agent for various densities of VUE. Simulation results show that the enhanced DQN based DCC outperforms in environments of various VUE densities."
초등학교 5학년 학생들의 소수 개념 이해,2023,"['Elementary math education', 'Decimals', 'Decimal fraction', 'Decimal digit value', '초등 수학 교육', '소수', '십진분수', '자릿값']",,"This study examined fifth-grade elementary school student knowledge of the decimal concepts learned from national textbooks. A test that asked students to compare decimal sizes was conducted on two fifth-grade elementary school classes in A-si, Gyeonggi-do. Most students compared the decimals well; however, some students thought that the longer decimals were larger. There was also a higher incorrect answer rate when there were zeros in the decimal places, with many finding it difficult to explain the reason for this. In the decimal conceptualization tests, the students often used fractions to describe the decimals, and of the three representative decimal models, they found the base ten model to be the most comfortable. In the question that tested their understanding of decimal concepts, the incorrect answer rate was high for problems that connected fractions to decimals, asked about digit values, and when there were zeros in the decimal places. It was concluded that educational reinforcement was needed so that student could better understand decimal digit values, decimal numbers with zero as a digit, and the differences between fractions and decimals."
농업에서의 ICT 와 인공지능을 활용한 연구 개발 현황 조사,2023,"['ICT', 'AI', 'Big Data', 'Computer Vision', 'CNN', 'RNN', 'Reinforcement Learning', 'Smart Farm']",,"Agriculture plays an industrial and economic role, as well as an environmental and ecological conservation role, group harmony and the inheritance of traditional culture. However, no matter how advanced the industry is, the basic food necessary for human life can only be produced through the photosynthesis of plants with natural resources such as the sun, water, and air. The Food and Agriculture Organization of the United Nations (FAO) predicts that the world's population will increase by another 2 billion people by 2050, and it faces a myriad of complex and diverse factors to consider, including climate change, food security concerns, and global ecosystems and political factors. In particular, in order to solve problems such as increasing productivity and production of agricultural products, improving quality, and saving energy, it is difficult to solve them with traditional farming methods. Recently, with the wind of the 4th industrial revolution, ICT convergence technology and artificial intelligence have been rapidly developing in many fields, but it is also true that the application of new technologies is somewhat delayed due to the unique characteristics of agriculture. However, in recent years, as ICT and artificial intelligence utilization technologies have been developed and applied by many researchers, a revolution is also taking place in agriculture. This paper summarizes the current state of research so far in four categories of agriculture, namely crop cultivation environment management, soil management, pest management, and irrigation management, and smart farm research data that has recently been actively developed around the world."
텍스트 기반 생성형 인공지능의 이해와 과학교육에서의 활용에 대한 논의,2023,"['generative artificial intelligence', 'conversational artificial intelligence', 'natural language processing', 'adaptive learning', 'connectivism', '생성형 인공지능', '대화형 인공지능', '자연어 처리', '적응 학습', '연결주의']","본 연구는 최근 주목받고 있는 텍스트 기반 생성형 인공지능에대해 관심과 활용이 증가함에 따라 과학교육적 측면에서의 활용을위해 생성형 인공지능의 주요 개념과 원리를 설명하고, 이를 효과적으로 활용할 수 있는 방안과 그 한계를 지적하며 이를 토대로 과학교육의 실행과 연구의 측면에서 시사점을 제공하는 것을 목적으로 한다.최근 들어 증가하고 있는 생성형 인공지능은 대체로 인코더와 디코더로 이뤄진 트랜스포머 모델을 기반으로 하고 있으며, 인간의 피드백을 활용한 강화학습과 보상 모델에 대한 최적화, 문맥에 대한 이해등을 통해 놀라운 발전을 이루고 있다. 특히, 다양한 사용자의 질문이나 의도를 이해하는 능력과 이를 바탕으로 한 글쓰기, 요약, 제시어추출, 평가와 피드백 등 다양한 기능을 수행할 수 있다. 또한 교수자가제시하는 예를 토대로 주어진 응답을 평가하거나 질문과 적절한 답변을 생성하는 등 학습자에 대한 진단과 실질적 교육내용의 구성 등많은 유용성을 가지고 있다. 그러나 생성형 인공지능이 가지고 있는한계로 인해 정확한 사실이나 지식에 대한 잘못된 전달, 과도한 확신으로 인한 편향, 사용자의 태도나 감정 등에 미칠 영향의 불확실성등에 대한 문제 등에 대해 해가 없는지 검토가 필요하다. 특히, 생성형인공지능이 제공하는 응답은 많은 사람들의 응답 데이터를 기반으로한 확률적 접근이므로 매우 거리가 멀거나 새로운 관점을 제시하는통찰적 사고나 혁신적 사고를 제한할 우려도 있다. 이에 따라 본 연구는 과학교수학습을 위해 인공지능의 긍정적 활용을 위한 여러 실천적제언을 제시하였다.","This study aims to explain the key concepts and principles of text-based generative artificial intelligence (AI) that has been receiving increasing interest and utilization, focusing on its application in science education. It also highlights the potential and limitations of utilizing generative AI in science education, providing insights for its implementation and research aspects. Recent advancements in generative AI, predominantly based on transformer models consisting of encoders and decoders, have shown remarkable progress through optimization of reinforcement learning and reward models using human feedback, as well as understanding context. Particularly, it can perform various functions such as writing, summarizing, keyword extraction, evaluation, and feedback based on the ability to understand various user questions and intents. It also offers practical utility in diagnosing learners and structuring educational content based on provided examples by educators. However, it is necessary to examine the concerns regarding the limitations of generative AI, including the potential for conveying inaccurate facts or knowledge, bias resulting from overconfidence, and uncertainties regarding its impact on user attitudes or emotions.Moreover, the responses provided by generative AI are probabilistic based on response data from many individuals, which raises concerns about limiting insightful and innovative thinking that may offer different perspectives or ideas. In light of these considerations, this study provides practical suggestions for the positive utilization of AI in science education."
다자유도 갠트리형 용접로봇 시스템의 최적모션 생성을 위한 벡터 방정식 알고리즘 기초 연구,2023,"['multi-D.O.F', 'gantry-type welding robot system', 'optimization', 'path planning', 'reinforcement learning', 'vector equations']",,
Asynchronous Advantage Actor Critic 기반 그룹 임의접속 제어기술,2023,"['Internet of Things', 'Group Random Access', 'Access Class Barring', 'Reinforcement Learning', 'Early Preamble Collision Detection', '사물인터넷', '그룹 임의접속', '제어 정보', '강화 학습', '빠른 프리앰블 충돌 검출 방식']","본 논문은 대규모 그룹 IoT 기기들이 임의접속을 동시에 시도했을 때 발생하는 접속 과부하 문제를 해결하기위해 Asynchronous Advantage Actor Critic (A3C) 기반의 임의접속 제어 기법을 제안한다. 기존 연구에서는 강화학습 기법인 DQN을 이용하여 접속 제어기술을 구현하던 것과는 달리, 본 연구에서는 강화학습 기법 중 A3C를사용하는 접속제어 기술을 제안한다. 제안하는 A3C 기반의 그룹 임의접속 제어기술은 그룹의 모든 단말이 임의접속에 성공하는데 걸리는 시간 측면에서 최적 학습을 통해 일반적인 프리앰블 충돌 검출 방식과 빠른 프리앰블 충돌 검출 방식에 따른 이론적인 제어 성능에 도달함을 보여준다.",
"Application of artificial intelligence chatbots, including ChatGPT, in education, scholarly work, programming, and content generation and its prospects: a narrative review",2023,"['Artificial intelligence', 'Literacy', 'Reproducibility of results', 'Search engine', 'Writing']",,"This study aims to explore ChatGPT’s (GPT-3.5 version) functionalities, including reinforcement learning, diverse applications, and limitations. ChatGPT is an artificial intelligence (AI) chatbot powered by OpenAI’s Generative Pre-trained Transformer (GPT) model. The chatbot’s applications span education, programming, content generation, and more, demonstrating its versatility. ChatGPT can improve education by creating assignments and offering personalized feedback, as shown by its notable performance in medical exams and the United States Medical Licensing Exam. However, concerns include plagiarism, reliability, and educational disparities. It aids in various research tasks, from design to writing, and has shown proficiency in summarizing and suggesting titles. Its use in scientific writing and language translation is promising, but professional oversight is needed for accuracy and originality. It assists in programming tasks like writing code, debugging, and guiding installation and updates. It offers diverse applications, from cheering up individuals to generating creative content like essays, news articles, and business plans. Unlike search engines, ChatGPT provides interactive, generative responses and understands context, making it more akin to human conversation, in contrast to conventional search engines’ keyword-based, non-interactive nature. ChatGPT has limitations, such as potential bias, dependence on outdated data, and revenue generation challenges. Nonetheless, ChatGPT is considered to be a transformative AI tool poised to redefine the future of generative technology. In conclusion, advancements in AI, such as ChatGPT, are altering how knowledge is acquired and applied, marking a shift from search engines to creativity engines. This transformation highlights the increasing importance of AI literacy and the ability to effectively utilize AI in various domains of life."
항만 물류 환경에서 강화학습 기반 컨테이너 다단 적재 모델링 방법,2023,"['port logistics', 'container yard', 'container loading', 'optimizing container handling', 'reinforcement learning']",,
강화학습을 이용한 감성지향 에이전트 - 아트 게임 <MOMaI>(2022)를 중심으로 -,2023,"['아트 게임', '강화학습', '지능형 에이전트', '감성 표현', '뉴미디어 아트', 'Art game', 'Reinforcement learning', 'Intelligent agent', 'Expression of emotion', 'New media art']",,
"가족친화 조직지원 및 가족친화 상사지원이 직무소진에 미치는  영향: 번영감의 매개효과, 직업소명의식의 조절효과",2023,"['Family Friendly Organizational Support', 'Family Friendly Supervisor Support', 'Thriving at Work(Vitality', 'Learning)', 'Job Calling', 'Job Burnout', '가족친화 조직지원', '가족친화 상사지원', '직무소진', '번영감', '직업소명의식']","본 연구는 일-삶의 균형 차원에서 가족친화 조직지원과 가족친화 상사지원이 직무소진에 미치는 영향을규명하려는 목적에서 수행되었다. 또한 번영감과 직업소명의식을 반영하여 어떠한 과정을 통해 가족친화 조직지원, 상사지원이 직무소진에 영향력이 나타나는지 그리고 어떠한 맥락 하에서 영향력이 강화 또는 완충되는지를살펴보았다. 번영감을 매개변수로, 직업소명의식을 조절변수로 설정하였다. 설문의 대상은 병원이며 간호사와의료기사에게 설문을 실시하여 연구가설을 검증하였다. 동일방법편의 문제를 해결하기 위해 설문은 시차를 두고2회 진행하였으며 1차 설문에서는 가족친화 조직지원과 상사지원, 직업소명의식을 측정하였으며, 2차에서는번영감과 직무소진을 측정하였다. 설문의 최종분석은 1차와 2차 동일한 응답자로 확인된 설문을 활용하였으며불성실응답 5부를 제외한 249부를 활용하였다. 분석결과를 살펴보면 첫째, 가족친화 상사지원은 번영감을 높이고있었다. 가족친화 조직지원의 영향력은 나타나지 않았다. 둘째, 번영감은 직무소진을 낮추고 있었다. 셋째, 번영감은가족친화 상사지원과 직무소진과의 관계를 매개하고 있었다. 반면에 가족친화 조직지원과 직무소진과의 관계는매개하지 못하는 것으로 나타났다. 넷째, 직업소명의식은 번영감과 직무소진과의 관계를 조절하고 있었다.직업소명의식이 높은 경우 번영감이 직무소진을 낮추는 영향력은 더욱 확대되고 있었다. 마지막으로 조절된매개효과도 살펴보았는데 직업소명의식이 높은 경우 가족친화 상사지원과 직무소진과의 관계에 번영감의매개효과는 더욱 강하게 나타나고 있었다. 본 연구의 결과를 통해 병원의 주요 인력인 간호사, 의료기사의 일-삶의균형을 위하여 가족친화를 위한 상사의 역할이 중요하다는 점을 확인하였다. 이론적 측면에서 자원보존이론을 통해직무소진을 낮추는데 가족친화를 위한 상사의 지원 뿐만 아니라 번영감이 중요하다는 것을 알 수 있었다. 또한실무적 측면에서 간호사 또는 의료기사들의 직무소진을 줄이는 것이 중요하다는 점에서 가족친화를 위한 조직의노력도 의미가 있지만 상사의 노력이 더욱 필요하다는 것을 규명하였다는 점에서 의의를 가지고 있다.","Balancing work and life demands has become an established area of research and practice have been carried out on work-life-balance(hereafter WLB) to understand the impact this concept has on individuals (employees) and their capacity to manage work and aspect of their lives. WLB defined ‘the extent to which an individual is equally engaged in-and equally satisfied with-his or her work role and family role. Based on WLB, we drawing the organization and supervisor’s effort to enhancing WLB reflected perceived family-friendly organizational support and family-friendly supervisor support concepts. This study examined the effects of family-friendly organizational support and family-friendly supervisor support on job burnout in hospitals who are nurses and medical technicians. By examining the processes through which family-friendly organizational support and supervisor support influence on job burnout, as well as the process and contexts in which the reinforced or buffered. We used thriving at work(vitality, learning) as a mediator and job calling as a moderator. After literature review, we set the direct, mediate, moderate and moderated mediation of research hypotheses. The survey was conducted in hospitals, and nurses and medical technicians who provide medical services to test the research hypotheses. To solve the problem of the common method bias, the survey was conducted twice with a time difference, and the first survey measured family-friendly organizational support, supervisor support, and job calling, and the second survey measured thriving at work and job burn out. The final analysis of the survey used the same respondents from the first and second surveys, excluding five non-responses, and used 249 questionnaires. The results of the analysis showed that, first, family-friendly supervisor support increased thriving at work. There was no effect of family-friendly organizational support. Second, thriving at work decreased job burnout. Third, thriving at work mediated the relationship between family-friendly supervisor support and job burnout. However, it did not mediate the relationship between family-friendly organizational support and job burnout. Fourth, job calling moderated the relationship between thriving at work and job burnout. The effect of thriving at work on job burnout was magnified if high on job calling. Finally, we examined moderated mediation effect, and found that the mediating effect of thriving at work on the relationship between family-friendly supervisor support and burnout was stronger for those with high on job calling. The results of this study confirm the importance of family-friendly supervisor support for the work-life balance of female nurses and medical technicians, who make up the majority of the hospital workforce. In the theoretical aspect, the resource conservation theory suggests that not only the support of family-friendly supervisors but also thriving at work are important in reducing job burnout. In the practical aspect, it is significant that the efforts of family-friendly supervisors are necessary to reduce job burnout among nurses and medical technicians."
과정 중심 평가 결과로써 영어과 교과세특 기재 내실화를 위한 연수 모형 개발 및 적용,2023,"['과정 중심 평가', '교사 연수', '교과세특', 'Process-oriented evaluation', 'teacher training', 'subject-specific abilities and specialties']",,"The purpose of this study was to explore the necessary elements for the description of process-oriented evaluation and to derive implications by developing and applying a training model. A total of 6 expert group interviews were conducted with 7 teachers and education researchers at each level of elementary school, middle school, and high school. The training model developed in this process was applied to a total of 51 teachers, and implications were derived based on their learning experiences. It is suggested that the training course be designed in a hands-on way so that participants can discuss with other participants and write down their own records, and that each group has 5 to 6 participants. In addition, a facilitator is required for each division, and a composition in which group members circulate in each training course was proposed to discuss with various people and develop ideas. The composition of each training course is a total of 8 sessions, and the 1st and 2nd sessions included lecture-type class that helps basic understanding of course-oriented evaluation. In addition, it was suggested that participants practice and discuss the six examples during each session. Lastly, it was suggested that the training course be flexibly performed according to the learner's capacity in the form of presenting specific data or writing examples although the basic training course was provided."
예비 교원의 원격 수업 역량 요인 탐색 및 요구도 분석,2023,"['원격 수업', '원격 수업 역량', 'Borich 요구도 분석', '예비 교사 교육', '비대면 수업', 'Distance learning', 'distance instruction competency', 'Borich Needs Assessment', 'pre-teacher training', 'non-face-to-face']","원격 수업은 다양한 상황에서 적용 가능한 대안적 교육 방식으로 부각되고 있다. 이러한 상황에서 원격 수업의 질은 교수자의 원격 수업의 역량에 따라 달라질 수 있기 때문에 수업을 운영하는 교사의 역량이 중요해지고 있다. 이에 본 연구에서는 예비 교사의 원격 수업 역량을 증대할 수 있는 시사점을 도출하기 위해 현재 온라인 수업 역량과 앞으로 교사로서 필요한 온라인 수업 역량에 대한 조사를 통해 예비 교사에게 필요한 온라인 수업 역량에 대한 우선순위와 시사점을 도출하였다. 그 결과 예비 교원들의 온라인 수업 역량에 대한 현재 수준과 향후 갖추어야 할 역량 수준에 대한 조사 결과 모든 역량군의 역량 항목에서 유의미한 차이가 있었으며, 온라인 수업 역량 강화를 위한 Borich 요구도 분석 결과 수업 설계 역량군과 수업 실행 역량군에서의 요구도가 높은 것을 확인하였다. 또한 예비 교원들이 실제 수업을 실행하는데 필요한 다양한 역량을 함양할 수 있는 교육이 필요하다고 인식하는 것으로 판단된다.","Distance learning is emerging as an alternative education method that can be applied in various situations. Therefore, in this study, implications for increasing the remote teaching competency of prospective teachers were derived. For this purpose, the current online class competency and the online class competency required as a teacher in the future were investigated. Through this, priorities and implications for online class competency required for preservice teachers were derived. As a result, there was a significant difference in the competency items of all competency groups. As a result of the analysis of Borich's needs for online class competency reinforcement, it was confirmed that the demands were high in the class design competency group and the class execution competency group. In addition, it is recognized that there is a need for education that can cultivate various competencies necessary for conducting actual classes for prospective teachers."
초등영어 CLIL 수업을 위한 비계 지원 전략,2023,"['내용 언어 통합 교육', '초등영어', '비계', '수업 전략', '과학 통합', 'content language integration', 'elementary English', 'scaffolding', 'CLIL', 'science integration']","목적  본 연구는 초등영어 학습자들을 위한 내용 언어 통합 수업(Content and language Integrate Instruction, CLIL)에서 입력 강화를 위한 비계 유형이 무엇인지 알아보고 비계 지원을 위한 구체적인 방법과 전략을 탐색해보고자 한다. 또한 연구에서 도출된 비계 전략을 초등 과학 내용 통합 수업에 적용하여 적절한 비계 전략을 제시한다.방법  연구 목적을 위해 비계의 개념, 국내외 CLIL 연구를 문헌 분석하여 비계의 개념 정의, 비계의 범주와 유형을 설정하였다. 비계의 세부 전략 목록을 개발하기 위해 선행연구에서 나온 전략 목록 간 상호 교차 점검을 하고 상위 전략의 기능과 특징에 맞는 하위 전략들을 배치하였다.결과  CLIL 비계 전략은 교사, 동료 학습자, 교재, 테크놀러지 4개의 비계 지원자와 교수적, 정의적, 인지적 비계 전략으로 크게 구분되었다. 각, 비계 전략별로 실제 CLIL 수업에 적용할 수 있는 하위 비계 전략이 확인되었다. 또한 초등 3학년 과학 내용인 동물 분류하기 CLIL 수업을 예로 들어 비계 전략을 적용해보았다.결론  본 연구에서 확인된 비계 전략은 교사가 사전에 계획 할 수 있는 고정형 비계 전략 중심이었다. 후속 연구로 수업 중 학생들의 반응과 수준에 따라 적극적으로 지원하는 반응형 비계 전략에 대한 연구도 필요하다. 또한 교사 지원 중심의 비계 전략이 일반적이지만 디지털 기술 환경의 발달로 학습자의 자기 주도적 학습 능력을 개발시키기 위한 비계 지원도 이루어져야 할 것이다. 본 연구에서는 이해 가능한 입력언어 제시를 위한 비계 전략 중심으로 연구가 이루어져, CLIL 수업을 진행하는데 필요한 교사의 언어 사용 전략은 연구에 반영 되지않았다. 본 연구는 문헌연구 고찰을 기반으로 이루어져 연구 결과를 실제 수업에 적용함으로써 비계 전략의 효과성을 탐색할 필요가 있다.","Objectives  This study aims to find out what scaffolding types are for input reinforcement in CLIL (Content and language Integrate Instruction, CLIL) for elementary English learners and explore specific methods and strategies for scaffolding support. Derived from the study By applying the scaffolding strategy described in this study to elementary science content integration classes, an appropriate scaffolding strategy is presented.Methods  For the purpose of the method study, the concept of scaffolding, the definition of scaffolding, and the categories and types of scaffolding were established by analyzing the literature on the concept of scaffolding and CLIL studies at home and abroad. In order to develop a list of detailed strategies for scaffolding, the strategy lists from previous studies were cross-occupied and sub-strategies that fit the functions and characteristics of the upper strategy were placed.Results  The CLIL scaffolding strategy was largely divided into four scaffolding supporters: teachers, fellow learners, textbooks, and technology, and instructional, affective, and cognitive weights. For each emptying strategy, a list of scaffolding strategies that can be applied to actual CLIL classes was identified. In addition, the scaffolding strategy was applied by taking the CLIL class, the science content of the 3rd grade of elementary school, as an example.Conclusions  The scaffolding strategy derived from this study is a fixed scaffolding strategy that teachers can plan in advance, and it is also necessary to study a responsive scaffolding strategy that actively supports according to the response and level of students during sign language. In addition, scaffolding strategies centered on teacher support are common, but with the development of the digital technology environment, scaffolding support that develops learners' self-directed learning ability should also be established. The language use strategy for the class operating language of the CLIL class is also necessary for the scaffolding support strategy, and follow-up research on this is required."
Search for Medical Information and Treatment Options for Musculoskeletal Disorders through an Artificial Intelligence Chatbot: Focusing on Shoulder Impingement Syndrome,2023,"['Artificial intelligence', 'ChatGPT', 'Medical information', 'Musculoskeletal disorders', 'Shoulder impingement syndrome']",,"Background The ChatGPT is an artificial intelligence chatbot that processes natural language text learned through reinforcement learning based on the GPT-3.5 architecture, a large-scale language model. Natural language processing models are being used in various fields and are gradually expanding their use in the medical field.Purpose This study aimed to investigate the medical information and treatment options that ChatGPT can provide for shoulder impingement syndrome (SIS).Study design Descriptive study.Methods Using ChatGPT, which is provided as a free beta test, messages related to SIS were entered, and responses to medical information and treatment options were received and analyzed.Results ChatGPT not only provided answers to the definition, prevalence, and risk factors of SIS, but also symptoms, diseases with similar symptoms, and orthopedic tests according to the messages input. Additionally, a list of treatment options and exercises were provided.Conclusions ChatGPT will be able to provide overall useful medical information and treatment options to patients unfamiliar with SIS. However, caution is required as it contains content that may be biased or inappropriate information for patients with SIS. Nevertheless, if natural language processing technology develops further, it is expected to be able to express more detailed medical information and treatment options."
지능형 로봇 개발을 위한 로봇 시뮬레이터 기술 동향: 리뷰,2023,"['로봇 시뮬레이터', 'GPU 기반 로봇 시뮬레이션', '심층강화학습', 'Robot Simulator', 'GPU-based Robotic Simulation', 'Deep Reinforcement Learning', 'Isaac Sim']",,
小蠹 鄭河源의 生涯와 太極動靜에 대한 蘆沙學 繼承性 一攷,2023,"['정하원(鄭河源)', '노사학(蘆沙學)', '태극도(太極圖)', '태극(太極)', '동정(動靜)', '음양(陰陽) 리(理)', '기(氣)', '선(善)', '악(惡)', '얼자(孼子).', 'Jeong Hah-won', 'Gi Jeong-jin', 'Philosophy of Nosa', 'Taegeukdo', 'Taegeu', 'Yin-Yang', 'TaeGeukDongJeong', 'Li', 'Gi', 'goodness', 'evilness.']","19세기 조선은 내우외환으로 매우 혼란하여 전통적 가치체계가 크게 흔들렸다. 그 시대 유학자들은 위기의식을 느끼고 정통론(正統論)을 내세우며 외세에 대처하였다. 당시 활약한 노사학파(蘆沙學派)는 위정척사(衛正斥邪)라는 대의명분을 통해 나라를 지키고 국권을 강화하고자 하였다. 그 학파의 성리학 이론체계는 리(理) 일원론에 따른 그 주재성을 중시하였다.본 논문은 노사(蘆沙) 기정진(奇正鎭)의 직전제자 정하원(鄭河源)의 삶과 저술, 그리고 태극동정론(太極動靜論)을 다루었다. 정하원은 가학을 계승하다가 17세 때 기정진에게 나아가 학문을 익히며 동문과 타학파의 학인들과 서로 교류하였다. 과거를 포기하고 향리에서 학문 연찬에 힘쓴 정하원은 강직한 성품과 출중한 학덕을 지닌 정여창(鄭汝昌)의 ｢악양(岳陽)｣이란 시를 애송하며 그의 호 일두(一蠹)를 차용하여 자신의 호를 소두(小蠹)로 하였다. 정여창의 행의를 조금이나 본받고자 함이었을 것이다. 더욱이 그는 서세동점의 시대에 다양한 시문을 지었는데 그 내용은 주로 향리를 교화시키며 국시(國是)를 바로잡고자 한 것이었다.정하원은 42세 때 ｢태극도｣ 두 번째 그림의 음정양동 속에 내재한 태극의 동정성을 스승과 문답하였다. 이는 노사학에서 악을 선의 얼자(孼子)로 표현한 의미를 탐구하기 위한 것이었다. 스승과 담론한 것을 기초로 ｢태극동정론｣을 지었는데, ‘태극의 오묘함’을 동정으로 간주하여 태극에 동정이 있음을 주장하였다. 그에 의하면 현상의 음정양동 속에 존재하는 태극은 순선하지만, 그 태극이 동정할 때 그렇게 될 수밖에 없는 곧 나누어 차지할 수밖에 없는 것을 악의 원인자로 규정하였다. 이러한 논지는 ｢태극도｣를 통한 태극동정의 참다운 의미, 그리고 노사학파의 사유양상 속에서 선의 얼자로서의 악을 규정하고 있음을 엿볼 수 있도록 한 것이다. 나아가 노사학파의 리 일원적 사상의 특징도 살펴볼 수 있는 계기도 될 것이다.","In the 19th century when the traditional value system was fluctuating in Korea under domestic crisis and foreign powers’ suppression, Losa Confucian School(蘆沙學派) tried to protect the country, reinforce the national power and handle the foreign power based on such justification as WiJeongCheokSa(衛正斥邪: to repulse the foreign power by keeping the tradition).This article deals with TaeGeukDongJeong(太極動靜: the Confucian issue of the birth principle of universe) studied by Jeong Hah-won, a member of Losa Confucian School, his life and his written works. He had succeeded the learning in his family tradition but went to Losa Ki Jeong-jin to study under Losa when he was 17. Since then, he had communicated with other schools’ scholars as well as with his alumni. Resolving not to take the national exam for government official, he devoted himself to learning and to educating people of traditional values in his local area, and tried to correct the national ideology by writing the articles to overcome the social problems.At his 42, he wrote TaeGeukDongJeongRon(太極動靜論: the theory of the Confucian issue of the birth principle of universe) after discussing with his teacher about TaeGeukDongJeong inherent in EumJeongYangDong(陰靜陽動: Yin is static while Yang is dynamic) of the second picture of TaeGeukDo(太極圖: picture of the birth principle of the universe) maybe because the Losa Confucian School mentioned the evilness of the syndrome revealed by DongJeong(being dynamic and being static) as a child of the concubine from the lowest class. In his TaeGeukDongJeongRon, he regarded ‘the subtlety of TaeGeuk’ as ‘DongJeong’ to advocate that there is DongJeong in TaeGeuk. He considered TaeGeuk existing amid EumJeongYangDong of the syndrome that is pure but he defined what comes out of DongJeong of TaeGeuk as the cause of badness, the child of the goodness’s concubine from the lowest class. Such thoughts of his would help understanding the true meaning of TaeGeukDongJeong and looking into the characteristics of Li(理) unitary ideology of the Losa Confucian School."
멀티모달 맥락정보 융합에 기초한다중 물체 목표 시각적 탐색 이동,2023,"['다중 물체 목표 시각적 탐색 이동 작업', '심층 강화학습', '멀티모달 맥락정보 융합', '전역 지도 작성', 'Multi-Object Goal Visual Navigation', 'Deep Reinforcement Learning', 'Multimodal Context Fusion', 'Global Mapping']",,"The Multi-Object Goal Visual Navigation(MultiOn) is a visual navigation task in which an agent must visit to multiple object goalsin an unknown indoor environment in a given order. Existing models for the MultiOn task suffer from the limitation that they cannotutilize an integrated view of multimodal context because use only a unimodal context map. To overcome this limitation, in this paper,we propose a novel deep neural network-based agent model for MultiOn task. The proposed model, MCFMO, uses a multimodal contextmap, containing visual appearance features, semantic features of environmental objects, and goal object features. Moreover, the proposedmodel effectively fuses these three heterogeneous features into a global multimodal context map by using a point-wise convolutionalneural network module. Lastly, the proposed model adopts an auxiliary task learning module to predict the observation status, goal directionand the goal distance, which can guide to learn the navigational policy efficiently. Conducting various quantitative and qualitativeexperiments using the Habitat-Matterport3D simulation environment and scene dataset, we demonstrate the superiority of the proposedmodel."
자율이동체의 주행 시험을 위한 선분과 원호로 이루어진경로 자동 생성 방법,2023,"['Dubins path', 'distance calculation', 'collision detection', 'path planning', 'mobile robot', 'circular arc']","자율주행 자동차 또는 자율주행 로봇의 개발을 위해서는 경로 주행 시험이 필요하다. 이러한 시험은 실제 환경뿐만 아니라 시뮬레이션 환경에서도 수행되고 있다. 특히 강화학습과 딥러닝을 이용한 개발을 위해서 다양한 환경의 데이터가 필요한 경우에 시뮬레이터를 통한 개발도 이루어지고 있다. 이를 위해서는 수작업으로 설계된 경로뿐만 아니라 무작위로 자동으로 설계된 다양한 경로의활용이 필요하다. 이러한 시험장 설계는 실제 건설, 제작에도 활용할 수 있다. 본 논문에서는 원호와 선분의 조합으로 이루어진 주행시험 경로를 무작위로 생성하는 방법을 소개한다. 이는 원호와 선분의 거리를 구하여 충돌 여부를 판별하는 방법과 경로를 계속해서이어 나가는 것이 불가능할 경우 경로 일부를 삭제하고 적절한 경로를 다시 만들어 나가는 알고리듬으로 이루어진다.","Path driving tests are necessary for the development of self-driving cars or robots. These tests are beingconducted in simulation as well as real environments. In particular, for development using reinforcement learningand deep learning, development through simulators is also being carried out when data of various environmentsare needed. To this end, it is necessary to utilize not only manually designed paths but also various randomly andautomatically designed paths. This test site design can be used for actual construction and manufacturing. In thispaper, we introduce a method for randomly generating a driving test path consisting of a combination of arcs andsegments. This consists of a method of determining whether there is a collision by obtaining the distance betweenan arc and a line segment, and an algorithm that deletes part of the path and recreates an appropriate path if itis impossible to continue the path."
Conscious Discipline as a Resilient System for Positive Early Childhood Classroom Management and Children’s Social and Emotional Competences,2023,"['Conscious Discipline', 'positive classroom management', 'social and emotional competencies', '의식적 규율(Conscious Discipline)', '긍정적 학급운영', '사회정서적 능력']",,"Classroom management is a considerable challenge for teachers and teacher retention. This research aims for early childhood teachers to reflect on classroom management transferring from the teacher-centered operant conditioning approach stressing reinforcement and token systems to the approach emphasizing children’s internal brain state where they self-regulate their own emotions, thoughts, feelings, and actions, and problem-solve, which empowers both teachers and children. Conscious Discipline is proposed in this research for teachers’ and children’s safety, social and emotional learning, self-regulation, conflict-resolution, and problem-solving to establish a positive classroom climate and enhance children’s social and emotional competences. This research is essential to improve early childhood teachers’ implementations of classroom management program through qualitative participatory action research (PAR) approach with the practical knowledge and reflective practices of an early childhood teacher implementing Conscious Discipline in her teaching on a daily basis."
5G 및 B5G 네트워크에서 그래프 신경망 및 강화학습 기반 최적의 VNE 기법,2023,"['5G 네트워크', '가상 네트워크', '가상 네트워크 임베딩', '그래프 신경망', '강화학습', '5G Network', 'Virtual Network', 'Virtual Network Embedding', 'Graph Neural Network', 'Reinforcement Learning']",,"With the advent of 5G and B5G (Beyond 5G) networks, network virtualization technology that can overcome the limitations of existing networks is attracting attention. The purpose of network virtualization is to provide solutions for efficient network resource utilization and various services. Existing heuristic-based VNE (Virtual Network Embedding) techniques have been studied, but the flexibility is limited. Therefore, in this paper, we propose a GNN-based network slicing classification scheme to meet various service requirements and a RL-based VNE scheme for optimal resource allocation. The proposed method performs optimal VNE using an Actor-Critic network. Finally, to evaluate the performance of the proposed technique, we compare it with Node Rank, MCST-VNE, and GCN-VNE techniques. Through performance analysis, it was shown that the GNN and RL-based VNE techniques are better than the existing techniques in terms of acceptance rate and resource efficiency."
New Possible Approach to the Korea-Southeast Asian Development Assistance Works,2023,"['Communication for Development (C4D)', 'ODA', 'Korea-ASEAN Cooperation', 'Southeast Asia', 'ASEAN']",,"Korea and Southeast Asia have expanded their development assistance projects in many fields. The assistance works are based on the good relationship among the partners and they can be reinforced by building the future directions and strategies with new areas. Among many types of approaches to the directions and strategies, the C4D concept based on the importance of communication and participation among the partners is applicable to the recent Korea-Southeast Asian development assistance projects especially after the COVID-19. Facing the new normal condition for the international assistance works after the pandemic, the partners must use new communication tools for more efficient results in various project fields. C4D can play for increasing effectiveness in public health development cooperation works. TV programs of health information contents will help prevent spread of diseases and fatality if they are distributed by ICT such as SNS or mobile devices and are used together with supply of vaccine, medicine or other hardware assistance. In education development cooperation works, C4D including the use of media based education contents, real-time remote learning, TV or internet based education will be more effective particularly for non-contact education when it is combined with other hardware development cooperation works, Development cooperation works in refugees and other neglected class of people may also be a possible field for C4D. Collection, reflection and spread of the opinions of such people will be more effective when they are used together with housing and other humanitarian assistance, or NGO support projects."
Cooper의 다차원 모형을 통한 그린스마트스쿨 정책 분석 - 사전기획단계를 중심으로,2023,"['그린스마트스쿨', 'Cooper의 다차원모형', '사전기획단계', '미래교육', '미래교육정책', 'Green Smart School', 'Cooper’s Multi-Dimensional Model', 'Pre-Planning Stage', 'Future Education', 'Education Policy']",,"The ""Green Smart School"" program is a strategic initiative designed to revamp aging educational facilities into schools of the future, equipped with eco-friendly and intelligent systems. This initiative focuses on educational innovation, encompassing the transformation of learning spaces, the establishment of smart classrooms, the promotion of environmental education, and the reinforcement of community links, alongside the physical redesign of school infrastructures.A notable aspect of the Green Smart School initiative is its incorporation of a pre-planning phase. Despite the critical importance of this stage, there is a notable paucity of research in this area. This study seeks to address this gap by applying Cooper's multi-dimensional policy framework to scrutinize and evaluate the challenges and dynamics of stakeholder relationships and conflicts encountered during the pre-planning phase of the Green Smart School program.To achieve this, the study methodically analyzes the situations that arose in the pre-planning stage across various dimensions: normative, structural, compositional, and technical. This analysis is underpinned by an exhaustive review of pertinent literature, data from the Ministry of Education, and media reports. Additionally, it includes in-depth interviews with stakeholders who have firsthand experience with the Green Smart School initiative or who are involved in related functions.Drawing from these comprehensive analyses, the study sheds light on the operational characteristics, challenges, and stakeholder conflicts during the pre-planning phase of the Green Smart School initiative and proposes potential avenues for improvement."
챗GPT 프롬프트 엔지니어링을 활용한 상식 추론결과에서 나타난 언어 자질들 분석,2023,"['ChatGPT', 'common sense inference', 'questions', 'formal semantics', 'argument structure', 'linguistic features', 'prompt engineering']",,"The purpose of this paper is how linguistic features operate prompt engineering in common sense inference using OpenAI ChatGPT. The operation of AI based on the Large Language Models is widely known as prompt engineering, which induces the common sense inferences of GPT via reinforcement learning from human feedback. Prompt engineering per se is a query to induce desired responses from the generative AIs. It is essential in creating better services and results from generative power of AI tools. In this paper, we analyze what aspect of linguistic features bring out better performance queries for the common sense inference. We deeply look into the features based on the theoretical linguistics."
챗GPT 프롬프트 엔지니어링을 활용한 상식 추론결과에서 나타난 언어 자질들 분석,2023,"['ChatGPT', 'common sense inference', 'questions', 'formal semantics', 'argument structure', 'linguistic features', 'prompt engineering']",,"The purpose of this paper is how linguistic features operate prompt engineering in common sense inference using OpenAI ChatGPT. The operation of AI based on the Large Language Models is widely known as prompt engineering, which induces the common sense inferences of GPT via reinforcement learning from human feedback. Prompt engineering per se is a query to induce desired responses from the generative AIs. It is essential in creating better services and results from generative power of AI tools. In this paper, we analyze what aspect of linguistic features bring out better performance queries for the common sense inference. We deeply look into the features based on the theoretical linguistics."
챗지피티의 국어 교육적 활용:  그 의의와 시사점,2023,"['ChatGPT', 'critical thinking skills', 'discussion', 'implications', '챗지피티', '비판적 사고능력', '토론', '시사점']",,"In this article, we explored the meaning, implications and coexistence methods of using ChatGPT in Korean Language Education. Here is a summary of what we explored. First, we discussed ‘securing reliable raw materials, overcoming bias, recognizing the importance of reinforcement learning in terms of contents, ‘centralization, production and indiscriminate communication of false information, abuse, monopoly of information, asking correct questions in terms of communication and problems of plagiarism and creation questions’ in terms of ethics. Second, the importance of acknowledging that ‘ChatGPT is powerful in language production skills as a coexistence method and understanding the way and limitations of artificial intelligence’  was discussed.  Third, it was discussed that education that enhances critical thinking skills through education that links reading, discussion, and writing is important, and to this end, discussion activities linked to ChatGPT should be actively used."
Task-Based Language Teaching: An Empirical Study of EFL Pronunciation Acquisition,2023,"['task-based language teaching', 'TBLT', 'English pronunciation', 'English consonant', 'Korean EFL tertiary context']",,"The present study examined Korean EFL college learners’ understanding of English consonantal contrasts in liquid [l, r] through TBLT class and student perceptions of the implementation of TBLT. In total, 31 intermediate-level students participated in the study. The findings of the study revealed a significant difference between the TBLT and non-TBLT groups in the post-test, indicating that the TBLT group showed significant improvement in learning the target sounds (t=2.498, p=0.041, p<.05). Moreover, the results of the Likert-scale questionnaire and interview demonstrated that most students considered the TBLT class interesting, motivated, and effective to learn confusing English consonantal contrasts. However, the interview findings reported important sociocultural gaps in implementing the westernized TBLT, involving the teacher’s implicit explanation and indirect feedback. Thus, to implement successful TBLT in the future Korean tertiary context, teachers’ active role as facilitators and input providers is encouraged. Simultaneously, it should be considered that the teacher’s initial input to the target consonantal features be reinforced in the pre-task stage to implement a successfully localized TBLT."
A Behavior-based Adaptive Dynamic Programming Method for Multiple Mobile Manipulators Coordination Control,2023,"['Adaptive dynamic programming', 'behavioral control', 'multi-objective mission', 'UGVMs.']",,"In this work, a behavior-based adaptive dynamic programming (BADP) method is proposed for the coordination control of unmanned ground vehicle-manipulator systems (UGVMs). Through a null-space-based behavioral control (NSBC) framework, the multi-objective coordination control is transformed into a single-objective tracking control at the mission layer. Since cost functions and control constraints are simplified at the control layer, the complexity of controller design is reduced. Then, an identifier-actor-critic reinforcement learning algorithm framework is introduced to learn the optimal control policy by balancing the control performance and consumption. Simulation results show that control costs are reduced by around 13.5% per sampling period compared to existing multiple objective control methods. Finally, the BADP method is experimentally validated using four real UGVMs."
한국어의 음운변동과 음소배열제약의 관계 탐구,2023,"['음소배열제약', '음운변동', '비범주적 적형성', '최대 엔트로피 문법', 'phonotactics', 'phonological alternation', 'gradient well-formedness', 'Maximum Entropy Grammar']",,"This study aims to investigate the relationship between phonological alternation and morpheme-internal phonotactics. Drawing from discussions in recent literature regarding the matches and mismatches between phonological alternation and phonotactics, the study explores  the influence of phonotactics on phonological alternation in two ways. First, phonotactic constraints are extracted from the Korean monomorphemic lexicon via the ‘Maximum Entropy Phonotactic Learning Model.’ Using the resulting grammar, I evaluate the well-formedness of forms subjected to phonological alternations compared to those unaffected. Results indicate a significant relationship between phonotactic constraints and phonological alternations. Specifically, obstruent nasalization and obstruent tensification are reinforced by robust morpheme-internal phonotactics, while phenomena such as t-palatalization, lateral nasalization, lateralization, and glide formation appear to be inhibited by weaker morpheme-internal phonotactics. Furthermore, focusing on nasalization, lateralization and glide formation, for which frequency data is available, this study statistically tests and assesses if the well-formedness of applied and unapplied forms influence the realization rate of phonological alternations. Secondly,  I explore how the morpheme-internal phonotactic constraints interact with other constraints, such as faithfulness constraints, during the realization of phonological alternations at morpheme boundaries. The analysis reveals that certain morpheme-internal phonotactic constraints are weighted and, thus interact with other constraints, influencing the realization of phonological alternations. Nevertheless, the realization rate of glide formation is not fully captured by the ill-formedness scores assigned by the phonotactic constraints, highlighting the necessity for constraints reflecting morpheme information. In summary, this research illuminates the relationship between Korean phonological alternations and phonotactic constraints."
초거대 언어 모델을 기반으로 한 AI 대화 인터페이스 -AI 대화 모델의 현황과 언어적 연구의 모색-,2023,"['Large Language Models', 'Linguistic Artificial Intelligence', 'Dialogue Interface', 'ChatGPT', 'Prompt Engineering', '초거대 언어 모델', '언어 인공지능', '대화 인터페이스', '챗지피티', '프롬프트엔지니어링']","이글은 초거대 언어 모델과 ‘인공지능’이라는 말이 학문 분야 및 여러 전문 분야에 화두가 되어 있는 시점에, 특히, 기계와 사람간의 언어적 상호작용인 대화형 인터페이스를 갖춘 인공지능의 한 유형으로서 대화 모델을 살피고 언어적 연구 방향에 대한 모색을 한다. 초거대 언어 모델이 언어 인공지능 개발에 획기적인 기준점이 되었고 이에 기반한 대화 모델도 큰 성장을 하고 있다. 대화 시스템은 인간과 기계간의 상호작용을 실행해온 만큼 그 개발의 방향도 멀티모달을 더고려하고 상호작용을 더 잘 할 수 있는 방향으로 가고 있다. 대화 시스템의 보다자연스러운 대화를 위해서는 여전히 대화 분석적, 대화 맥락에 관련된 언어적 주제를 딥러닝 방법론을 활용하여 발전시켜야 할 부분이 많다. 초거대 언어모델 기반의 대화 인터페이스인 챗지피티의 핵심 방법론은 인간피드백강화학습(RLHF:Reinforcement Learning from Human Feedback)이다. 이와 관련하여 초거대 언어 모델을 자원으로 하여 대화 맥락 분석에 활용할 기법으로 프롬프트 엔지니어링을 소개한다.",
Dynamic service function chain placement with instance reuse in Fog–Cloud​ Computing,2023,['FCCNNFVVNFSFCDRLA3C'],,"The advent of Network Function Virtualization (NFV) technology has brought flexible provisioning to Fog–Cloud Computing-based Networks (FCCNs) for enterprises to outsource their network functions to data center networks. Service Function Chaining (SFC) is a networking concept in NFV by which traffic is steered through an ordered set of Virtual Network Functions (VNFs) composing an end-to-end service. When hundreds of users outsource their network functions to FCCN, the optimal placement of VNFs in the network becomes important for assembling SFCs with the aim of resource utilization efficiency. Motivated by the scalability shortcomings of existing schemes, we propose Deep Reinforcement Learning (DRL)-based approaches by simultaneously considering parallelized SFC and reuse of VNFs to solve this problem, i.e., Asynchronous Advantage Actor–Critic (A3C). A parallelized SFC consists of several sub-SFCs, which can reduce delay and guarantee availability. Also, reuse of preliminary VNFs in SFC placement can improve computation acceleration. The proposed scheme pursues the maximization of the long-term cumulative reward for the trade-off between Quality of Service (QoS) and service cost. The results of the experiments show that the proposed scheme performs better than the state-of-the-art methods."
Energy-Efficient RL-Based Aerial Network Deployment Testbed for Disaster Areas,2023,"['Ad-hoc', 'aerial  network', 'energy-efficient', 'MavLink', 'QoS', 'SDN.']",,"Rapid deployment of wireless devices with 5G andbeyond enabled a connected world. However, an immediatedemand increase right after a disaster paralyzes network in-frastructure temporarily. The continuous flow of information iscrucial during disaster times to coordinate rescue operations andidentify the survivors.Communication infrastructures built for users of disaster areasshould satisfy rapid deployment, increased coverage, and avail-ability. Unmanned air vehicles (UAV) provide a potential solutionfor rapid deployment as they are not affected by traffic jamsand physical road damage during a disaster. In addition, ad-hocWiFi communication allows the generation of broadcast domainswithin a clear channel which eases one-to-many communications.Moreover, using reinforcement learning (RL) helps reduce thecomputational cost and increases the accuracy of the NP-hardproblem of aerial network deployment.To this end, a novel flying WiFi ad-hoc network managementmodel is proposed in this paper. The model utilizes deep-Q-learning to maintain quality-of-service (QoS), increase userequipment (UE) coverage, and optimize power efficiency. Fur-thermore, a testbed is deployed on Istanbul Technical Univer-sity (ITU) campus to train the developed model. Training resultsof the model using testbed accumulates over 90% packet deliveryratio as QoS, over 97% coverage for the users in flow tables, and0.28 KJ/Bit average power consumption."
2015 개정 교육과정 고등학교 기술·가정 교과서의 부모됨의  준비에 관한 내용분석: 청소년 대상 예비부모교육에 대한 함의,2023,"['preparing for parenthood', 'high-school technology and home economics textbook', 'goals of pre-parent education', 'adolescents']",,"This study aimed to identify ways to implement pre-parent education for adolescents in regular classes at school. This was achieved by investigating whether the contents of the 2015 revised curriculum high-school technology and home economics textbooks reflected the goals of pre-parent education. The main texts and activities of chapters with ‘preparing for parenthood’ in the title from 12 high-school technology and home economics education textbooks were analyzed with respect to the three pre-parent education goals of developing perceptions and attitudes toward parenthood, learning parenting knowledge and skills, and reinforcing parental capacity. The results were as follows. First, textbook contents and activities reflected the three goals of pre-parent education in a balanced manner. Second, both the contents and activities of textbooks tried to motivate students to perceive parenthood and parenting through reflection on their relationship with their own parents. Third, because the textbooks encouraged students to consider parenthood and parenting, they acknowledged the importance of undertaking pre-parent education to reinforce their parental capacities. Using such textbooks in regular technology and home economics classes is expected to provide students with an opportunity to consider parenthood and shape their perceptions and attitudes accordingly, thereby allowing adolescents to prepare themselves for parenthood and become good parents."
DRL-based Resource Management in Network Slicing for Vehicular Applications,2023,['5G network slicingResource allocationReal-time resource managementVehicular networksActor–critic DRL'],,"Network Slicing (NS) was proposed as a viable solution in Release 15 of Third Generation Partnership Project (3GPP) to allocate the limited resources among different service types for improving their Quality-of-Service (QoS). However, the advanced vehicular applications such as autonomous driving, platooning, remote driving, etc. have stringent QoS demands and the standard NS architecture is not sustainable for these services. Therefore, we propose a solution compatible with the standard 3GPP NS architecture that implements an Actor-Critic based Deep Reinforcement Learning (DRL) algorithm in the Network Slice Subnet Management Function (NSSMF). The algorithm allocates and manages the limited resources among different slices based on their real-time traffic demands. We generate real-time traffic for each service type and train the algorithm to improve the QoS of each service type in the network. The proposed method is evaluated for the training performance of the proposed algorithm as well as the Service level agreement Satisfaction Ratio (SSR) of each slice. The results exhibit that the proposed method not only improves SSR of each slice, but also performs well in case of increased node density in the network."
TRPO(Trust Region Policy Optimization) 및 PPO(Proximal Policy Optimization)를 활용한 PID 제어 상수 탐색,2023,"['TRPO', 'PPO', 'PID', '건물에너지', 'HVAC 제어']",,"In traditional HVAC systems, the PID gains (Kp, Ki, Kd) for control have been determined by experts or through classic PID tuning methods based on system estimation as linear systems. This approach aims to optimize the PID gain values through control to enhance thermal comfort in buildings while reducing energy consumption. However, limitations exist in linear system estimation due to variations in control response time, diverse climate conditions, and challenges in predicting occupant behavior, which are contingent on building characteristics. In this study, we propose a method to discover PID gain values (Kp, Ki, Kd) for HVAC systems using reinforcement learning algorithms i.e., Trust Region Policy Optimization (TRPO) and Proximal Policy Optimization (PPO). Through this approach, we have achieved a significant energy savings compared to conventional methods, and we plan to further validate this method across various building types and diverse climatic conditions."
중앙집중형 DQN 기반 다중 로봇의 최적 이동 경로 제어 기법,2023,"['최적 경로 제어', '심층 큐 네트워크', '스마트 공장', 'Optimal path control', 'deep Q-network', 'smart factory']","최근 4차 산업혁명 시대의 도래와 함께, 스마트 공장 환경에서 자동화/지능화 로봇의 활용에 대한 연구가 매우활발히 이루어지고 있다. 하지만 기존의 무인 운반 차량 (automatic guided vehicle, AGV)은 단일화된 경로에 국한된 이동성을 가지기 때문에, 높은 인프라 구축 비용과 경로 수정의 어려움 등 많은 문제점을 가지고 있다. 이를위해, 본 논문에서는 다중 로봇들이 서로 간의 충돌을 최소화하며, 각자의 목적지까지 최단 경로로 이동할 수 있도록 중앙집중형 심층 큐 네트워크 (centralized deep Q-network, DQN) 기반 물류 로봇 최적 이동 경로 제어 방안을 제안한다. 구체적으로, 현실의 간이 공장 물류 창고와 유사한 시뮬레이션 환경을 구축하고, 해당 환경에서 물류 로봇들에 대한 오프라인 학습을 수행한다. 학습된 모델을 이용하여, 스마트 공장 환경에서 물류 로봇들을 각자의 최적의 경로로 다중 목적지에 도착하도록 실시간으로 로봇을 제어하는 데에 활용함으로써 그 성능의 우수성을보인다. 하드웨어로 구현하고 이를 기반으로 한 테스트를 통해 다중 물류 로봇이 0.1% 미만의 낮은 충돌율을 가지면서 각자의 다중 목적지에 최적의 경로로 도착함을 보인다.","With the recent advent of the 4th Industrial Revolution era, research on the use of autonomous and intelligent robots in a smart factory has been actively investigated. However, existing automatic guided vehicles (AGVs) still have many problems, such as the cost of infrastructure installation and difficulty in route modification, because of their significantly limited mobility. Therefore, we herein propose an optimal logistics robot control scheme based on a centralized deep Q-network (DQN) so that multiple robots can minimize collisions and get to their desired destinations in the shortest path. Specifically, a simulation environment similar to a simplified factory logistics warehouse is considered, and offline reinforcement learning of logistics robots is conducted in this environment. In addition, we demonstrate the performance excellency of the proposed DQN model so that the robots can arrive at their destinations by the optimal routes. Through the test based on hardware implementation, we show that multiple logistics robots can arrive at their desired destinations along optimal paths while minimizing collisions."
기후변화에 대응하는 자연지리 교육의 방향 - 초등 자연지리 교육을 중심으로 -,2023,"['Climate Change', 'Natural Sensitivity', 'Physical Environment', 'Physical Geography Education', 'Geography Education', '기후변화', '자연 감수성', '자연환경', '자연지리교육', '지리교육']",,"Today, the demands of the times to respond to climate change, which has become a global issue, and the need for ecological transition efforts, require changes in the school curriculum. This study focuses on the direction of physical geography education in response to climate change based on awareness of the physical environment of the country and the world, understanding the harmonious relationship between humans and the environment based on this, and cultivating perspectives and practical skills on environmental ethics for ecological transition and presented the necessity and direction of strengthening physical geography education in elementary education. The challenges of physical geography education for this study were presented. First, education to cultivate sensitivity to nature, second, reinforcement of the contents of the physical environment itself, third, active reflection of the formation process of the physical environment and changes, fourth, field-oriented exploratory learning where active contact and interaction with nature can be achieved was proposed."
Research on Space Design to Improve Visitor Comfort : Focused on the Design of Science and Technology Museum,2023,"['관광객의 편안함', '공간 디자인', '과학 기술 박물관', '전시 방식', '상호작용 체험', '전시품 선택', 'Visitor comfort', 'Space design', 'Technology museum', 'Display methods', 'Interactive experience', 'Exhibit selection']",,"This paper presents a comprehensive study of the spatial design of science and technology museums, with an objective to enhance visitor comfort and experience. Employing comparative case study methodology, the study analyses the spatial layout of prominent technology museums across South Korea, the United States, China, Britain, and Japan. The research investigates how improved signage orientation, multimedia services, and accessible design can enhance visitor experience.A detailed exploration of exhibition methods and interactive experiences is also conducted. The research underscores how leveraging modern technology can bolster visitor engagement and learning experience. The paper also emphasizes the importance of thoughtfully selecting exhibits that cater to visitor needs and interests, offering a strategic approach towards exhibit selection.The case studies provide insightful revelations about the unique spatial layout, interactive experience, and exhibit selection of museums around the world, demonstrating diverse design methodologies that contribute to visitor comfort and engagement. The findings depict that the integration of these elements significantly enriches the educational value of the museums, while aligning with their practical applications.The study offers valuable insights and practical guidance for the design of technology museums, contributing to improving visitor comfort in public spaces. The conclusions drawn highlight the crucial role of strategic spatial design in enhancing visitor experience, thereby reinforcing the relevance and significance of science and technology museums in public education."
전쟁의 위기와 유럽통합: 유럽석탄철강공동체(ECSC) 창설 배경,2023,"['Crisis of EU', 'EU', 'Jean Monnet', 'ECSC', 'Supranationalism', '유럽연합의 위기', '유럽연합', '장 모네', '유럽석탄철강공동체', '초국가주의']",,"The European Union (EU), which guaranteed peace and prosperity in Europe after the two World Wars, has faced a series of consecutive crises and challenges since the late 2000s. Some analysts have even diagnosed a pessimistic outlook for the future of Europe due to this continuous string of crises. Such a reality has prompted inquiries into the continuity of the EU itself. Is the EU genuinely sustainable? If it endures, can it evolve into a more robust political integration body? Enduring amidst the prevailing ascendancy of nationalism and external pressures, can the EU steadfastly preserve unity within diversity? This study, which discusses the relationship between the crisis of war and the development of European integration, primarily aims to find insights into the current future of the EU and the correlation between crises and the development of European integration.Throughout the past 70 years of European integration, Europe has faced numerous crises. In 1954, with the failure of the European Defense Community (EDC) treaty, journalists questioned the uncertain future of integration. Jean Monnet, in response, asserted that Europe would learn about integration through crises. Moreover, the development of the European Coal and Steel Community (ECSC), the first institution of European integration, is closely linked to the crises in Europe during the 20th century, including the World Wars and the Cold War. Therefore, Monnet explained that Europe was born out of crises. This study will explore the origins of the ECSC and the significance of supranational European integration methods, examining how crises of war can strongly reinforce the necessity for integration."
전직지원전문가로의 경력전환 경험에 대한 질적 사례연구,2023,"['career transition', 'career change', 'outplacement', 'self-renewal', 'midlife', '경력전환', '진로전환', '전직지원', '중장년', '자기갱신']",,"As the global population ages and individuals stay longer in the workforce, successfully managing a late or second career after retirement from their primary job is becoming an increasingly important challenge for middle-aged people. To derive the stages, characteristics, and implications of the career transition experience, this study looked closely at the process of change that occurred when middle-aged individuals switched from their former positions in different jobs to outplacement expert. The study was designed by adopting a qualitative case study methodology based on the purpose of the study. In-depth interviews were conducted with four people who have been working in jobs related to outplacement for more than three years following their career transition. As a result of the study, the process of change revealed in the participants’ career transition experiences was conceptualized into three main stages. Additionally, the characteristics and implications revealed in the participants’ career transition experiences were largely categorized into three themes. The results imply that the career transition experience of the middle-aged research participants to outplacement expert was a learning and growth process that changed one’s familiar life course, discovered and reinforced vocational values and calling, and was ultimately a special process of change such as self-renewal or self-reformation."
Evaluating the Performance of ChatGPT on the Secondary School English Teacher Hiring Examination,2023,"['챗GPT', '대용량 언어 모델', '수행 분석', '교원 임용 시험', 'ChatGPT', 'large language model', 'performance analysis', 'teacher hiring examination']",,"The purpose of the present study is to conduct a comprehensive evaluation and analysis of the performance of OpenAI’s ChatGPT, a language model based on GPT-4 architecture, on the Secondary School English Teacher Hiring Examination. For this purpose, the current study employed ChatGPT-4, the most recent model as its primary research instrument. A total of 23 questions from the 2023 hiring exam were fed into ChatGPT for response generation. The responses elicited from ChatGPT were then analyzed by a panel of five experts according to their respective fields of expertise. The results of the analyses highlighted both the potential and limitations of ChatGPT as a pedagogical tool. The results also identified the AI’s propensity to simplify complex or abstract human knowledge into narrower or more technical concepts. These observations underscore the limitations of current AI in fully emulating human comprehension and its capacity to interpret nuances in knowledge. Nonetheless, these findings also suggest a direction for future AI development and reinforce the idea of AI as a supplementary learning tool rather than a complete replacement of human teachers."
인공지능법 제정안과 설명가능한 인공지능(XAI)의 기본원칙에 관한 연구,2023,"['XAI (eXplainable Artificial Intelligence)', 'Artificial intelligence basic law', 'Artificial intelligence act', 'Transparency', 'Accountability']",,"XAI (eXplainable Artificial Intelligence) is a technology that explains the process by which a result is created so that the user understands and correctly interprets the operation and final result of an artificial intelligence system. The Black Box, the limit of artificial intelligence, increases opacity and complexity, and XAI was proposed as a way to compensate for this. It is time to clearly understand the contents and effects of artificial intelligence technology and need an XAI system based on concrete and effective norms, not an artificial intelligence industry that relies on autonomy. In addition, it is time for a unified artificial intelligence legal system (legal framework) of artificial intelligence basic law and artificial intelligence legislation to protect the health of artificial intelligence market and public interest. Deep learning and reinforcement learning, which have recently been actively used in various industries, can make incomprehensible judgments, so consumers (users) do not understand the conclusions of the models, resulting in a problem of lack of trust. The ultimate goal of XAI is to create reliable artificial intelligence, and the understandability of the algorithm and the explainability of the output must be guaranteed. Based on the discussion above, this study proposed five basic principles of XAI: Transparency, Accountability, Fairness, Reliability, and Result Demonstrability based on the Artificial Intelligence White Paper and the Artificial Intelligence Act enactment. The basic principles of XAI presented in this study are expected to contribute to the establishment of human-centered artificial intelligence and a reliable artificial intelligence ecosystem."
문화지능과 문화적 편견: 상호문화적 자기효능감을 중심으로,2023,"['cultural diversity', 'cultural intelligence', 'cultural bias', 'intercultural competence', 'self-efficacy', '문화다양성', '문화지능', '문화적 편견', '상호문화능력', '자기효능감']",본고에서는 우선 문화지능 이론의 바탕이 되고 있는 지능이론에 대해 살펴보고자 한다. IQ로부터 시작된 인간 지능이론에 대한 연구는 시간을 거듭하며 연구영역과 깊이가 확대 심화되며 지능 본질을 탐구해 왔다. 문화지능 이론은 이러한 지능연구 내용과 체계를 차용하고 있는데 그에 대해 알아보고자 한다. 특히 지능이론이 말해주고 있는 지능에 대한 후천적 요인의 중요성에 주목하고자 한다. 문화적 다양성의 상황에 필요한 인간 지능으로서의 문화지능 이론은 방해요소로서의 편견 문제를 중요하게 보고 있다. 이에 인간이 성장하며 학습하는 범주화 과정과 그로 인한 범주 편향에 대해 고찰해보겠다. 다음으로는 범주 편향에 직간접적으로 영향을 주고 있는 문자와 미디어에 대해 살펴보고자 한다. 명사로 대표되는 문자와 영상으로 대표되는 미디어가 편견과 고정관념을 어떻게 강화시킬 수 있는지를 생각해 보고자 한다. 마지막은 인간 편향과 관련해 그간 이루어진 심리학적 연구 성과들을 분석해 보았다. 백여 개 이상의 이론들이 긴 시간 연구 결과로 축적되어 왔다. 이 중에서 문화지능 이론과 관련해 매우 중요하다고 판단되는 이론들을 추려 살펴보았는데 인간 개인에게 방점이 들어간 형태의 편견과 집단 간 발생하는 편견 형태를 구분지어 고찰하고자 한다.,"In this paper, we will first examine the intelligence theory, which is the basis of the cultural intelligence theory. Research on the theory of human intelligence, which began with IQ, has expanded and deepened the scope and depth of research over time, exploring the essence of intelligence. The cultural intelligence theory borrows these intelligence research contents and systems, and we want to find out about them. In particular, we would like to pay attention to the importance of acquired factors for intelligence that the intelligence theory tells us. The theory of cultural intelligence as a human intelligence necessary in the context of cultural diversity considers the problem of prejudice as an obstacle important. Therefore, we will examine the categorization process that humans learn while growing up and the category bias resulting from it. Next, we will examine texts and media that directly or indirectly affect category bias. We would like to think about how texts represented by nouns and media represented by images can reinforce prejudices and stereotypes. Lastly, we analyzed the psychological research achievements that have been made in relation to human bias. More than one hundred theories have been accumulated as a result of long time research. Among them, theories that are judged to be very important in relation to the theory of cultural intelligence have been selected and examined, and the prejudice in the form of emphasizing the human individual and the form of prejudice that occurs between groups are classified and considered."
자폐 범주성 장애 영유아의 모방 증진 관련 국외 중재연구 분석,2023,"['Young children with autism spectrum disorder', 'imitation', 'literature review', '자폐 범주성 장애 영유아', '모방', '문헌연구']","본 연구에서는 자폐 범주성 장애 영유아가 어려움을 보이는 모방 증진 관련 중재연구를 분석하여 모방 중재의 방향 및 과제에 대한 시사점을 모색하고자 하였다. 이를 위해 논문 선정 기준에 따라 2022년까지 국외에 발표된 총 31편의 모방 증진 관련 중재연구를 선정하였고, 개괄적인 분석 및 중재의 구체적인 내용을 분석하였다. 연구 결과는 다음과 같다. 첫째, 자폐 범주성 장애 영유아의 모방 증진 관련 중재연구는 주로 단일대상연구를 사용하여 37개월 이상의 유아를 대상으로 연구자 혹은 부모가 가정에서 실시한 연구가 많았다. 둘째, 자폐 범주성 장애 영유아의 모방 능력을 증진하기 위해서 사물모방, 동작모방, 몸짓모방, 얼굴모방, 음성모방 등 다양한 모방 영역을 대상으로 중재가 이루어졌으며, 교수 전략으로는 강화, 촉진, 비디오 모델링 등 증거 기반의 실제가 폭넓게 활용되었고, 교수 맥락은 놀이 기반 삽입을 활용한 연구가 가장 많은 것을 알 수 있었다. 본 연구의 결과를 기반으로 자폐 범주성 장애 영유아의 모방 증진을 위한 중재연구에 대한 시사점과 후속연구의 방향에 대하여 논의하였다.","This study was to analyze the intervention on imitation in young children with Autism Spectrum Disorder (ASD) who exhibit difficulties in imitation, and to explore the direction and tasks of further studies. A total of 31 studies were selected until the year 2022 according to the selection criteria and their general analysis and specific intervention contents were examined. The results of the study are as follows. First, imitation intervention studies mainly used single subject research and most of the studies were conducted by researchers or parents in their homes with children over 37 months of age. Second, interventions were conducted targeting various range of imitation domains such as object imitation, action imitation, gesture imitation, face imitation and voice imitation to enhance the imitation ability of young children with ASD. Evidence-based practices such as reinforcement, prompting, and video modeling were widely used as teaching strategies and teaching contexts were mainly a play-based embedded learning opportunities. Based on the findings of this study, the implications and directions for further studies on imitation intervention for young children with ASD were discussed."
고전텍스트의 표점標點과 현토懸吐에 관한 비교 분석 —『대학大學』과 『중용中庸』을 중심으로,2023,"['표점', '현토', '관본', '율곡본', '대학', '중용', 'Chinese punctuation marks', 'Korean punctuation marks', 'a government-produced book', 'a Yulgok’s book', '<Daxue', '大學>', '<Zhongyong', '中庸>']",,"In order to organize and translate classical texts, it is very necessary to understand ‘Chinese punctuation marks’ and ‘Korean punctuation marks’ when training next-generation experts in Korea. In addition, it is important to accurately understand and utilize Chinese punctuation marks and Korean punctuation marks when providing Korean classical text to overseas.The advantage of Chinese punctuation marks lies in standardization and unification. Where the difference in Chinese punctuation marks of <Daxue,大學> & <Zhongyong,中庸> occurs, a classical text organization policy should be presented clearly to resolve the confusion.The advantage of Korean punctuation marks lies in specificity and convenience. Comparing Korean punctuation marks of <Daxue,大學> & <Zhongyong,中庸> in the government-produced books and the Yulgok’s books, it can be seen that as Korean punctuation marks of the government- produced books evolve into marks of the Yulgok’s books. The Yulgok’s books are reinforcing simplicity and simplicity.With reference to these good examples, it is necessary to improve Korean punctuation marks based on medieval korean languages and reorganize it into Korean punctuation marks based on modern korean languages.Next-generation experts should learn the advantages of Chinese punctuation marks and Korean punctuation marks well. So when we organize classical texts, we have to produce efficient performance."
도덕과의 환경교육 연구 동향 분석,2023,"['ecological transformation education', 'environmental ethics education', 'moral education', 'environmental education', 'ecological citizenship', '2022 curriculum', '생태전환교육', '환경윤리교육', '도덕교육', '환경교육', '연구 동향', '2022 교육과정']",,"In the 2022 curriculum, ‘ecological transformation education’ was announced as part of competency-based education that aims to respond to major changes in the future society. In line with this announcement, this study analyzes the trend of academic research related to environmental issues in moral education with the purpose of putting together the research results of moral education and deriving implications for future research and ecological transformation education of moral education. I selected 129 research papers on environmental issues published in academic journals of ethics and moral education and analyzed them by using the meta-analysis method. I provided a summary of the contents, trends of sub-themes, and research methods of the journals. Based on the results of the analysis, I demonstrated the role of moral education in ecological transformation education can be‘establishing the right relationship between humans and nature’, ‘providing an ethical approach to environmental issues’, ‘providing useful teaching and learning methods’, and ‘reinforcement of communication and cooperation skills’."
생성형 AI와 편향성,2023,"['Generative Artificial Intelligence', 'bias', 'unrepresentative data', 'halucinations', 'fairness', 'transparency', 'accountability', 'inclusivity.', '생성형 인공지능', '편향성', '환각', '차별', '대표성 없는 데이터', '공정성', '투명성', '설명가능성', '포용성']","ChatGPT나 Midjourney와 같은 생성형 인공지능(AI) 시스템이 차세대 기술로 떠오르면서 AI가 생성한 창작물에 편견과 편향성이 드러나 논란에 직면하고 있다. 이러한 AI 시스템은 딥러닝과 강화 학습을 통해 사람들이 만든 방대한 양의 책, 블로그, 이미지, 소셜 미디어를 교과서로 삼아 패턴과 관계를 학습하여 과거의 데이타를 기반으로 새로운 콘텐츠를 만들거나 결과를 예측한다. 그러나 편향되거나 대표성이 없는 데이터로 사전 학습된 경우, 생성형 AI 모델은 오해의 소지가 있거나 잘못된 출력을 생성할 수 있다. 가령 AI 시스템이 성별 고정관념에 기반한 가정을 학습하거나 특정 인종이나 민족에 대한 편견을 가질 수 있는데, 생성형 AI가 고용, 금융, 교육, 공공 서비스 등 다양한 분야에 스며들면서 최근 편향성에 대한 우려가 제기되고 있다.오늘날 책임감 있고 공평한 기술 사용을 위해 생성형 AI의 편향성을 해결하는 것은 어렵지만 매우 중요하다. AI 편향성 문제 해결에는 기술적 솔루션뿐만 아니라 공정성, 투명성, 책임성, 포용성과 같은 윤리적 고려사항도 포함된다. 데이터 관리 개선, 모니터링, 공정성 인식 알고리즘 개발, 효과적인 법적 및 정책적 대응을 통해 이해관계자들은 보다 공정하고 포용적인 사회를 만드는 데 일조할 수 있다. 또한 AI 시스템의 개발과 배포에 있어 편향성을 해결하기 위한 국가 및 국제적 차원의 노력이 필요하다. AI 기술이 계속 발전하고 사회에 더욱 통합됨에 따라 정부, 업계, 학계가 협력하여 책임감 있는 AI 개발과 사용을 보장하는 포괄적인 법적 프레임워크와 윤리적 지침을 수립하는 것이 요구된다. 이러한 전략의 조합을 통하여 편견을 최소화하고 AI 시스템의 공정성을 개선하는 데 의미 있는 진전을 이룰 수 있을 것이다.","As generative Artificial Intelligence (AI) systems, such as ChatGPT or Midjourney, emerge as next-generation technologies, they face controversy due to exposed prejudice and bias in AI-generated works. These AI systems create new content or predict outcomes based on input data, relying on deep learning and reinforcement to learn patterns and relationships from extensive historical data. However, if pre-trained on biased, incomplete, or unrepresentative data, generative AI models may produce misleading or false outputs. The training data often reflects societal biases or perpetuates past prejudices, such as gender, race, age, and socio-economic biases. AI systems may learn to make assumptions based on gender stereotypes, develop biases against certain racial or ethnic groups, reveal distorted views related to socio-economic factors, or exhibit biases based on age, geography, language, political beliefs, culture, or religion, leading to discrimination. As these systems permeate various sectors, including employment, finance, education, and public services, concerns about biases have recently emerged.Addressing bias in generative AI is challenging but critical for responsible and equitable technology usage nowadays. Addressing AI bias involves not only technical solutions but also ethical considerations, such as fairness, transparency, accountability, and inclusivity. By improving data management, monitoring, developing fairness-aware algorithms, and implementing effective legal and policy responses, stakeholders can promote a more just and inclusive society. National and international level’s commitment to addressing AI bias and other ethical concerns in the development and deployment of AI systems is needed. As AI technologies continue to advance and become more integrated into society, it is crucial for governments, industries, and academia to collaborate in establishing comprehensive legal frameworks and ethical guidelines that ensure responsible AI development and usage. A combination of these strategies can help make meaningful progress in minimizing bias and improving the fairness of AI systems."
인간의 자유의지에 과학기술의 도전과 현행 법체계의 향방,2023,"['Artificial Intelligence', 'Free Will', 'Science and Technology', 'Legal Personhood', 'Human Dignity and Worth', '인공지능', '자유의사', '과학기술', '법인격', '인간의 존엄과 가치']","최근 급속도로 발전하고 있는 과학기술은 분명 인간의 자유의지를 전제로 하는 현행 법체계에 대한 심각한 도전이 아닐 수 없다. 과거에는 인간의 자유의지를 부정하는 주장이 철학적 차원에서 제기되는데 그쳤으나, 이제는 과학적 지식과 연구성과를 토대로 한 주장들이 제기되고 있다. 그리고 최근 급속도로 발전한 인공지능 기술로 인해 인공지능이 인간에 준하거나 또는 인간 이상의 지능을 갖진 인공지능의 출현에 대한 기대가 커짐으로써, 자유의지는 더 이상 인간의 전유물이 아니라는 생각을 갖게 만들다. 이러한 최근의 변화들로 인해 자유의지를 바탕으로 하는 인간의 존엄과 가치 그리고 그것을 전제로 하여 구축된 현행 법체계를 유지하는 것이 점점 더 어려워지고 있다.과연 인공지능이 현재의 예상대로 인간 못지않은 또는 인간을 능가하는 존재로 거듭날 수 있을지 현재로서는 여전히 의문이 아닐 수 없다. 우리는 인공지능이라는 브레이크 없는 기술 앞에서 지구상에서 자유의지를 가진 유일한 존재라는 지위를 인공지능에게 양보해야 할지, 아니면 아무리 똑똑하다고 하더라도 결국 인간이 만들어낸 기계에 지나지 않은 인공지능에 대해 인간이 주인으로 남아야 할지는 결국 자유의지를 갖고 있다고 믿고 있는 우리가 판단하고 결정해야 할 과제이다.본 논문은 우리의 법체계가 과연 인간의 자유의지를 전제로 하여 구축되어 있다고 할 수 있는지 그리고 인간의 자유의지 부정론 내지는 회의론의 주장에 대해 검토해 보고, 인간의 자유의지를 바탕으로 하는 현행 법체계의 향방을 가늠해 보았다.","Free will is the foundation of modern law and constitutes the framework of all laws, including the Constitution, criminal law, and civil law. However belief in free will is constantly being challenged due to the development of science and technology such as evolutionary psychology and brain science. And with the recent rapid development of computer and information technology, the argument that free will is no longer the exclusive property of humans is growing stronger.Artificial intelligence is developing rapidly as machine learning, which began in the 1950s, and reinforcement learning, developed in the 1980s, advanced in the 2000s. Scholars call the moment when artificial intelligence develops dramatically and surpasses human intelligence as the ‘singularity,’ and many artificial intelligence scholars and futurists predict that the singularity will occur around 2029.Contrary to the rosy outlook on artificial intelligence, many people point out its limitations. The realistic problem with artificial intelligence is that it can cause various harm to humans. And the range of harm to humans is very wide, from the smallest issues at the level of social norms to life.In the face of unbreakable technology called artificial intelligence, it is questionable whether we should give up our status as the only being on earth with free will to artificial intelligence. No matter how smart it is, whether humans should remain the masters of artificial intelligence, which is ultimately nothing more than a machine created by humans, is a task that we who believe in free will must decide.[Key Words] Artificial Intelligence, Free Will, Science and Technology, Legal Personhood, Human Dignity and Worth."
1950년대 여성국극에 참여한 여성들의 판소리-여성국극 인식과 구도,2023,"['Female kukkŭk', ""ch'anggŭk"", ""p'ansori"", 'Hwarang Female kukkŭk Troupe', 'Pak Gwi-hŭi', ""Im Ch'un-aeng"", 'Cho Yŏng-suk', '여성국극', '창극', '판소리', '화랑 여성국악단', '박귀희', '임춘앵', '조영숙']","본 논문에서는 1950년대 여성국극에 참여한 세 부류의 여성들이 보여준 판소리-여성국극 인식이 1960년대 이후 판소리의 무형문화재 제도 편입과 더불어 더욱 본격화된 ‘남성-정통-판소리/혼성창극’과 ‘여성-변종-여성국극’의 판소리-여성국극 구도의 형성에 미친 영향을 고찰하여 보았다.1950년대, 여성국극에 참여했던 여성들의 부류와 그들이 보여준 판소리-여성국극 인식은 다음과 같다. 첫째, 판소리에 연원을 두고 있는 전문 판소리 창자 부류로, 김소희, 박귀희, 박록주, 박초월 등이 여기 속한다. 이미 판소리 영역에서의 확고한 지위를 확보하고 있었던 만큼 여성국극에서의 소리도 그 근간을 판소리에 온전히 두었다. 둘째, 역시 판소리에 연원을 두고 있는 전문 판소리 창자이나, 첫째 부류와 비교해 당시 판소리 영역에서의 확고한 지위를 확보하고 있지는 못 했던 조농옥, 임춘앵, 임유앵 등이다. 첫째 부류의 여성들이 판소리에 근간을 두고 여성국극의 초기 양식을 정립했다면, 둘째 부류의 여성들은 오히려 조금 더 자유롭게 기존의 여성국극 양식을 변화하거나 새롭게 구축하는 데 기여했다. 셋째, 여성국극 참여 이전에 소리를 따로 배우지 않은 부류로, 신극 계열의 연극 배우 출신도 여기 속한다. 김진진, 김경수, 김혜리, 조영숙 등은 판소리 명창 가계 후손이었음에도 ‘아버지’ 세계의 소리인 판소리를 접할 기회를 얻지 못했거나 스스로 거부했다. 첫째 부류의 여성들에게 여성국극의 중심은 마땅히 ‘아버지’ 세계의 소리인 판소리여야 했고, 둘째 부류의 여성들에게 판소리는 여성국극을 이루는 여러 토대 가운데 하나였으며, 셋째 부류의 여성들에게 판소리는 여성국극과 가깝지만 그만큼 거리도 분명한 별개의 것이었다.1955년, 첫째 부류의 대표 주자들이 조직한 화랑 여성국악단은 판소리 중심의 ‘옳은’ 여성국극을 선보이고자 하였다. 그러나 여성국극 내부의 이러한 ‘구분 짓기’는 남성 창극인 또는 문화재 권력과 유사한 어조를 띠었던 데서, 그 애초의 의도와 달리 결과적으로는 1960년대 ‘남성-정통-판소리/혼성창극’과 ‘여성-변종-여성국극’의 구도를 강화하였다. 판소리와의 접점이 좁거나 존재하지 않았던 둘째 부류 또는 셋째 부류의 여성들의 목소리는 기존의 구도를 부정하거나 변화시키기에는 역부족이었으며, 그 차이에 대한 인정마저 기존의 구도를 고착화하는 길이 되었다.","This article examines how the perceptions of p'ansori and Female kukkŭk by three groups of women who participated in Female kukkŭk in the 1950s influenced the formation of p'ansori and Female kukkŭk in the 1960s, when p'ansori was incorporated into the intangible cultural property system, and the formation of the p'ansori and Female kukkŭk categories of 'male-authentic-p'ansori/mixed-gender ch'anggŭk' and 'female-variant-Female kukkŭk' became more prominent.The groups of women who participated in Female kukkŭk in the 1950s and their perceptions of p'ansori and Female kukkŭk were as follows: First, there was the group of professional p'ansori singers with roots in p'ansori, such as Kim So-hŭi, Pak Gwi-hŭi, Pak Rok-ju, and Pak Ch'o-wŏl. Since they already had a strong position in the field of p'ansori, the music of Female kukkŭk was also based entirely on p'ansori. Second, there were professional p'ansori singers who also had their roots in p'ansori, such as Cho Nong-ok, Im Ch'un-aeng, and Im Yu-ang, who did not have the same established position in the p'ansori field as the first group. While the first group of women established the initial form of Female kukkŭk based on p'ansori, the second group of women had more freedom to change or build new forms of Female kukkŭk. Third, there was a group of women who did not learn p'ansori before joining Female kukkŭk, including actresses from the new theatre. Kim Jin-jin, Kim Kyung-soo, Kim Hye-ri, Cho Yŏng-suk, and others were either descendants of famous p'ansori master singer families but did not have the opportunity to learn the “father's” world of p'ansori or deliberately rejected it. For the first group of women, p'ansori, as the sound of their “father's” world, was the centerpiece of Female kukkŭk; for the second group of women, p'ansori was one of the various foundations that constituted Female kukkŭk; and for the third group of women, p'ansori was closely related to Female kukkŭk but was distinctly separate.In 1955, the Hwarang Female kukkŭk Troupe, organized by representatives of the first group, aimed to present an “authentic” Female kukkŭk centered on p'ansori. However, this internal “classification” within Female kukkŭk had a similar tone to that of male p'ansori singers or the authority of cultural heritage, and as a result, contrary to its original intentions, it ultimately reinforced the paradigm of 'male-authentic- p'ansori/mixed-gender ch'anggŭk' and 'female-variant-Female kukkŭk' in the 1960s. The voices of women from the second or third groups, whose contact with p'ansori was limited or non-existent, were insufficient to deny or change the existing structure, and even the acknowledgment of their differences became a way to solidify the existing structure."
파이썬 이용 코퍼스 분석 기반 아동용 이솝우화 분석 및  초등영어교육 자료로의 활용,2023,"['코퍼스', '아동용 이솝우화', '어휘 다양성', '워드클라우드', '감성분석', '파이썬', 'corpus', ""Aesop's Fables for children"", 'lexical diversity', 'word cloud', 'sentiment analysis', 'Python']","본 연구는 이솝우화 전편 147개 이야기를 대상으로 하여 초등학교 영어교육에서 교사가 영어교육 계획을 수립하면서 고려할 수 있는 세 가지 유용한 코퍼스 분석 방법을 제시한다. 문학 작품과 같은 교과서 이외의 자료를 사용하여 영어교육 자료로 활용할 때 어휘 다양성 분석과 감성분석을 통하여 교사는 수업 때 사용할 자료를 정할 때 도움을 받는다. 교사가 준비한 학생들의 코퍼스 자료에 대하여 학습자의 어휘 능력 향상을 도모하기 위하여 파이썬 컴퓨터 언어를 사용하여 워드클라우드 생성을 활요하는 방안을 제시한다. 교사가 파이썬 컴퓨터 언어를 적절하게 활용한다면 교육 계획 수립 전에 코퍼스 분석을 통하여 학생들의 수준에 맞는 교육 자료를 다양하게 준비할 수 있고 교사가 개입하여 강화할 교육 내용을 미리 예측할 수 있기 때문에 여러 방면에서 도움이 된다. 또한, 학습자는  영어학습과 컴퓨터 언어 운용을 통한 영어학습을 하면서 융복합적 사고를 증진한다. 감성분석에 기초를 두고 학습활동에 코퍼스 자료를 활용함으로써 긍정문과 부정문에 대한 감각을 자연스럽게 키우는 것을 기대할 수 있고, 워드클라우드를 사용함으로써 창의적 학습과 어휘 습득을 용이하게 돕는다.","This study focuses on 147 stories from Aesop's Fables for elementary English education and proposes three useful corpus analysis methods that teachers can consider when planning English education. When using materials other than textbooks designed for elementary school, such as literary works, for English education, teachers can benefit from the analysis of lexical diversity and sentiment analysis when selecting materials for lessons. The study suggests using Python computer language to create word clouds to enhance learners' vocabulary skills based on the corpus data prepared by teachers. If teachers appropriately utilize the Python computer language, they can prepare a variety of educational materials tailored to students' levels through corpus analysis before planning English education. This enables teachers to predict and reinforce education content in advance, providing various forms of assistance. Furthermore, learners can enhance their integrative thinking through English learning and computer language operation. Based on sentiment analysis, we can expect learners to naturally develop sensitivity to positive and negative sentences while using corpus data in learning activities. Word clouds also facilitate creative learning and vocabulary acquisition."
김해 봉황토성 성격 연구,2023,"['가야성곽', '봉황토성', '축조수법', '축조공정', '공간구조. 왕성', '축성배경', 'Gaya Fortress', 'Bonghwangtoseong', 'Construction Method', 'Construction Process', 'Pit-house', 'Political Castle', 'Royal Castle', 'Context of Fortification']","고대국가에서 성곽은 정치, 경제, 사회, 군사 활동의 중심지로 축성 주체 및 목적을 살피는 것이 중요한 과제로 인식되고 있다. 최근 여러 지역에서 조사되는 성곽 유적 중 가야성곽에 대한 조사 및 연구가 이루어지면서 점차 가야성곽에 대한 접근이 어느 정도 이루어지고 있다. 이러한 연구성과에 힘입어 본고에서는 김해 봉황대 유적을 중심으로 확인되는 봉황토성의 축조수법과 성곽 추정선, 내․외부 공간구조를 가야권역의 여러 토성들과 비교 분석함으로써 봉황토성의 성격과 축성 배경에 대하여 검토하는 것이 주요 목적이다.최근의 조사 과정중 봉황토성의 남쪽과 서쪽 구간에서 다양한 토목공법이 적용된 토성 체성부가 확인됨으로써 북동쪽에서부터 남쪽과 서쪽으로 연결되는 토성 구조임을 확인할 수 있었다. 봉황토성에서 확인되는 축조공정은 크게 8차례 공정으로 이루어진다.Ⅰ공정은 정지작업을 통한 부지 조성 및 제의용 토기 매납, Ⅱ공정은 지정주 설치, Ⅲ공정은 지정주 상부에 토제 구축, Ⅳ공정은 토제 내외면부에 목주를 2중 종렬로 박은 뒤 내부에 황갈색점토괴로 보강하여 벽 설치, Ⅴ공정은 토제를 기준으로 양벽 목주+점토벽 높이까지 층첩을 하여 토심 축조, Ⅵ공정은 토심 내․외벽부에 경사다짐, Ⅶ공정은 내․외벽부 경사다짐토 상부에 석축 보강, Ⅷ공정은 황갈색+패각혼입 점질토로 근피보강(토심석축근피)을 하는 것으로 초축 체성부를 완공한 것으로 보인다. 토성 내부에서 출토되는 토기의 형식 및 상대연대로 보았을 때, 4세기􄠕5세기 중반까지 지속적인 개축 및 보수가 이루어지다가 5세기 후반􄠕6세기 이후에는 토성의 기능이 정지된 것으로 보인다. 토성 잔존구간을 통한 토성추정선의 재검토를 한 결과, 기존 남쪽과 서쪽 구간은 봉황대길의 안쪽으로 더 들어가면서 회현리 패총의 남쪽 경계과 인접하게 돌아가는 것으로 판단된다. 이러한 추정선을 바탕으로 봉황토성은 봉황대 구릉과 북동쪽의 저구릉 평탄지대의 지배층 생활공간 및 생산․창고시설 등을 방어․관리하는 용도의 토성임을 확인할 수 있었다. 따라서 봉황토성은 4􄠕5세기대 금관가야 지배층이 거주하면서 김해지역 일대의 정치․경제(교역 및 생산 활동)․사회업무 전반을 관장하는 치소성의 기능을 수행하였던 성곽으로 도성(都城)보다는 그 규모나 범위가 작은 왕성(王城) 정도의 성곽으로 파악된다.","In ancient countries, the fortress was the center of political, economic, social and national affairs, and it is recognized as an important task to study the subject and purpose of the castle. Recently, as investigations and studies on Gaya fortresses have been carried out among the castle ruins investigated in various regions, access to the Gaya fortresses is gradually being made to some extent. Based on these researches, this paper compares and analyzes the construction method, fortification line, and internal and external spatial structure of Bonghwangtoseong, which are confirmed around the remains of Bonghwangdae in Gimhae, with those of various earthen fortresses in the Gaya region, in order to learn the character and construction background of Bonghwangtoseong.Recent investigations have confirmed that the earthen structure connected from the northeast to the south and west was proved by confirming the body parts where various construction methods were used in the southern and western parts of the Bonghwangtoseong Fortress. The construction process found at Bonghwangtoseong consists of eight main steps. Process Ⅰ is the preparation of the site through ground work and earthenware for ritual use, Process Ⅱ is the installation of beams, Process Ⅲ is the construction of an earthwork on designated pole, and process Ⅳ is the installation of a wall by embedding wooden beams in double rows on the inside and outside of the earthwork and reinforcing them with brown clay lumps inside, Ⅴ Process constructed the earth core by similarly constructing a double-walled wooden beam + clay wall to the height of the earth core, Ⅵ Process sloping the inner and outer walls of the earth core and Ⅶ Process reinforced the stone shaft on top of the sloped clay in the inner and outer walls, and step Ⅷ is to reinforce the root skin with clay soil mixed with yellow-brownish + shell ingredients, and it seems that the superaxial body part has been completed. Judging by the shape and relative age of the pottery excavated from the interior of the earthen fortress, it seems that the earthen fortress was continuously renovated and repaired from the 4th to the mid-5th century, but ceased to function after the late 5th to 6th century. As a result of re-examining the line of the earthen fortification through the remaining section of the fortification, it is judged that the existing southern and western sections continue inside Bonghwangdae-gil and return adjacent to the southern boundary of the Hoehyeon-ri mound. Based on this estimation line of reasoning, it was confirmed that the Bonghwangtoseong was used to defend and manage the residential, production, and storage facilities of the ruling class in the hills of Bonghwangdae and the lowlands of the northeast. Therefore, Bonghwangtoseong is a fortress where the ruling class of Geumgwan Gaya lived in the 4th and 5th centuries and performed the function of a political castle, overseeing politics, economy (trade and production), and social affairs in the Gimhae area. It is in the context of fortification that we should understand this fortified city, which is about the size of a small royal castle."
예비초등교사의 장애학생 체육 지도 경험 탐색,2023,"['예비초등교사. 장애학생', '체육 지도 경험', 'Pre-Primary School Teacher', 'Students with Disabilities', 'Physical education coaching experience']","본 연구는 예비초등교사의 장애학생 체육 지도 경험의 의미를 탐색하는 것을 목적으로 하였다. 연구 참여자는 S교육대학교에 재학 중이면서 장애학생 체육교실에서 체육활동을 지도하는 예비초등교사이며, 총 7명으로 구성하였다. 이들을 대상으로 반구조화된 질문지를 통한 심층면담 자료와 체육 지도 후에 작성한 반성적 저널을 통해 장애학생 체육교실의 시행 과정에서 예비초등교사가 지각하는 체육활동 지도의 의미를 질적 사례연구를 통해 면밀히 살펴보고 분석하였다. 이상의 과정을 토대로 도출된 이 연구의 결론은 다음과 같다. 첫째, 예비초등교사들은 장애학생 및 체육 지도와 관련된 경험과 장애학생에 대한 이해의 부족으로 인하여 장애학생 체육 지도에 부담과 어려움을 느끼고 있었다. 둘째, 예비체육교사들은 체육 지도능력의 한계를 실감하고 체육의 이론과 실제의 간극을 확인하며 좌절과 갈등의 시간을 보냈다. 셋째, 적절한 지도방법의 방향을 찾는 오류를 겪고, 장애학생에 대한 편견을 버리게 되었으며, 비장애학생과 장애학생의 체육 지도가 다르지 않음을 알게 되고, 변화해 가는 자신과 아이들의 성장하는 모습을 발견하는 시행착오-도전-적응의 단계를 거쳤다. 넷째, 아동에 대한 관찰 능력 향상, 체육 지도법과 효능감 향상, 동료 및 교수 피드백을 통한 발전, 장애학생에 대한 관심과 책임감 증가와 문제해결능력의 향상을 통하여 성장하며 교사가 되어가고 있었다. 마지막으로, 내․외적 강화를 통해 보람을 얻고 있었으며, 장애학생 체육교실에서의 체육활동 지도가 통합교육 실행 의지를 높이는 의미 있는 활동, 안정감을 제공하는 경험, 예비교사에게 필수적인 활동, 장애학생의 성장을 돕는 단순한 봉사활동 이상의 활동이라는 의미를 부여하고 있었다.","The purpose of this study was to explore the meaning of pre-primary school teachers' experience of teaching physical education to students with disabilities. The study participants were pre-primary school teachers who are students at S National University of Education and teach physical education activities in the physical education class for students with disabilities, and a total of 7 people were composed. Through in-depth interviews through semi-structured questionnaires and reflective journals written after physical education instruction, the meaning of physical education activity instruction perceived by pre-primary school teachers in the implementation process of physical education classes for students with disabilities was carefully examined and analyzed through qualitative case studies. The conclusions of this study, based on the above process, are as follows. First, pre-service elementary school teachers felt burdened and difficult in teaching physical education for students with disabilities due to their lack of experience and understanding of students with disabilities and physical education. Second, pre-primary school teachers realized the limitations of their physical education teaching ability and spent a time of frustration and conflict identifying the gap between the theory and practice of physical education. Third, they went through the stage of trial-error-challenge-adaptation in which they made the mistake of finding the direction of appropriate teaching methods, abandoned their prejudice against students with disabilities, learned that physical education instruction for non-disabled students and students with disabilities was no different, and discovered the growth of themselves and their children as they changed. Fourth, they were growing up and becoming teachers by improving their observation skills, physical education instruction and efficacy, improving their peer and professor feedback, and improving their interest and responsibility for students with disabilities and their problem-solving skills. Lastly, it was rewarding through internal and external reinforcement, and the guidance of physical education activities in the physical education classroom for students with disabilities was given meaning as a meaningful activity that increases the will to implement inclusive education, an experience that provides a sense of stability, an essential activity for pre-service teachers, and an activity beyond simple volunteer activities to help the growth of students with disabilities."
유가식 비유와 연상 과정 분석 ― “繪事後素”와 “禮後” 문구를 중심으로,2023,"['유가', '비유', '연상', '素', '禮', '繪', '後', '재구조화', 'Confucian', 'parables', 'associative', 'Su(素)', 'Li(禮)', 'Hui(繪)', 'Hou(後)', 'restructuring']",,"Previous studies have analyzed Kongzi's analogy and Zixia's association only in meaning, such as ""Wenzhi(文質) theory"" or ""Renyi(仁義) theory"", and do not pay much attention to the trigger and process. Almost all stop at naming the phrase metaphor and association. This paper first traces the relationship between the key terms Qiao(巧), Mei(美), Su(素), Xuan(絢), and Hui(繪) in the phrase ""a mysterious smiley mouth is pretty and beautiful eyes are clear. It's decorated with Su(素)(巧笑倩兮, 美目盼兮, 素以爲絢兮)"" and “Decoration is done after the foundation(繪事後素)”, and analyzed the analogy process through it. Next, the link was explored in search of the connection between the preceding vocabulary and Zixia's association with Li(禮) and Hou(後).In the phrase of a poem, Qiao(巧), Mei(美), and Xuan(絢) are given the positivity by the Su(素). Kongzi here compares the phrase ""素以爲絢,"" which was controversial at the time, by restructuring it by adding ""繪事,"" which is all the usual act of decorating, and “Hou(後)” which means completion in Confucianism, to eliminate the conflict that the colorless Su(素) and colorful Xuan(絢) are the same. This is intended to define the existing terms and concepts in a Confucian manner through the analogy of ""繪事後素"". This analogy of Kongzi eventually stimulates Zixia to recall the Su(素) embodied in clothes and accessories discussed in the discourse of Li(禮). In this process, it was effective to interpret it as a Hui(繪) that is morphologically adjacent to Su(素) and Xuan(絢), which consists of Mi(糸). Based on this, Zixia linked Su(素) such as ""素服"", ""素衣"", ""素裳"", ""素冠"", ""素韠"", and ""素積"" mentioned in specific etiquette, and highlighted the word ""Hou(後)"" to reinforce the meaning of acquired learning and discipline, thereby being reminiscent of ""禮後"". In short, Kongzi's metaphor of ""繪事後素"" itself was already in contact with everyday Li(禮)-related vocabulary, which encouraged Zixia to recall the use and role of Su(素) in Li(禮). This is clearly differentiated from other ideas, especially Taoism's reference to Su(素) as an abstract concept. It was confirmed that the metaphors and associations of Kongzi and Zixia revealed the thought process of Confucianism, which emphasizes manners in everyday life."
임실지역의 蘆沙 奇正鎭 學脈 一攷,2023,"['기정진', '奇正鎭', '임실', '任實', '직전문인', '재전문인', '삼전문인', '유학', '항일의지', 'Gi Jeong-jin', 'Imsil', 'Confucianism', 'academic genealogy', 'Japanese imperialism']","노사(蘆沙) 기정진(奇正鎭)과 그 학파는 근현대 호남에서 크게 활약하였다. 기정진 사후, 그의 손자 기우만을 비롯한 여러 문인은 강학에 힘쓰며 문인을 양성하였다. 특히 노사하파는 서세동점의 시기에 ‘위정척사(衛正斥邪)’의 사상을 적극 실현하려는 의지를 보였고,, 또한 여러 지역의 학인들에게 정신적 영향을 주었다. 임실지역 학인들도 직간접으로 영향을 받았다.임실지역 기정진 학맥의 문인을 조사한 바, 총 86명에 이른다. 이 가운데 기정진의 직전문인은 6명, 재전문인은 56명, 삼전문인은 24명이다. 이들은 스승의 학문적 영향, 그리고 전승되는 학문을 연찬하는데 힘쓰면서 일제치하에 당면한 현실을 극복하려 하였고 또한 지역사회에서 전통문화를 지키는데 큰 힘을 보태었다. 직전문인은 스승의 학문을 배양하는 데 힘썼다. 타지역에서 강학하는 기정진의 직전문인을 찾아 수학한 재전문인은 의리를 지향하는 학문적 경향을 접하며 항일의지를 불태우기도 하였다. 더욱이 삼전문인은 근현대 급격한 사회 변화 속에서 전통의 유학을 정립하고 향촌의 역사적 사료를 정립하고자 노력하였다. 1960년대 이후 도회지로 떠나지 않은 향촌의 유림들은 시대의 조류에서 멀어진 유교를 회복시키기 위해 향촌에 배향된 선현의 원우(院宇)를 정비하고 전통의 학문과 문화를 지키며 학문적 동질성을 강화시키기도 하였다.호남에서 큰 발자취를 남긴 노사학파는 리를 실재로, 또는 절대적 가치로 여기는 사유이므로 그 실천성이 강하다. 이러한 학문 경향은 향촌사회의 학인들에게 정신적 지주로 작용하였다. 때문에 임실지역 기정진 학맥의 문인은 일제의 통치하에 그 당면 과제를 의리로 항거하면서도 광복 이후 전통의 학문, 그리고 향촌문화와 역사를 확립하는 데 노력하였다.","Noh-sah(蘆沙) Gi Jeong-jin(奇正鎭) and his school played a big role in West-Southern region of Korea during the modern time. Since the death of Gi Jeong-jin, his grandson Song-sah(松沙) Gi Woo-man(奇宇萬) had extended the lectures of Gi Jeong-jin’s studies to more people and many scholars had gathered for such lectures with strong will to positively realize the thoughts of WiJeongCheokSa(衛正斥邪: a movement to keep Neo-Confucianism based tradition while rejecting the Catholicism based European idea late in Joseon dynasty) during the era of national crisis. The study of Noh-sah was spiritually guiding a number of scholars in that period because it was playing the role to positively solve the urgent issue of that period with intelligible resistant will against Japanese imperialism. It influenced also the scholars in Yimsil region in both direct and indirect ways.According to an investigation on how many scholars who were on Gi Jeong-jin’s academic genealogy, there were totally 86 scholars: 6 taught directly by Gi Jeong-jin, 56 taught by Gi Jeong-jin’s students and 24 taught by Gi Jeong-jin’s students’ students. Such 6 directly taught by Gi Jeong-jin seemed to make their efforts to cultivate Gi Jeong-jin’s studies. Such 56 scholars went to various local areas to meet the scholars directly taught by Gi Jeong-jin so that they could learn Gi Jeong-jin’s studies. Learning the academic trend of going for Confucian justice, they also devoted themselves to protesting against Japanese imperialism. Such 24 scholars taught by Gi Jeong-jin’s students’ students systematically collected history data of their local regions and tradition of Confucianism in the society that was rapidly changing during the modern time, and furthermore they tried to restore Confucianism getting apart from the people under the periodic changes. Especially repairing and maintaining the local Confucian learning facilities, they protected the learning and culture of tradition and reinforced academic identity of Confucianism based society.In conclusion, Gi Jeong-jin’s academic genealogy led to Confucian fidelity that recognized the resistance against Japanese imperialism as the urgent issue of the time and went for aggressive protest, and was further upgraded to establishment of the local culture and history in the region of Iimsil."
초등 시교육에서 ‘감각 이미지’ 수용의 변화 탐색 - 2015 개정 교육과정과 2022 개정 교육과정  비교를 중심으로 -,2023,"['【Key   words】Elementary   Poetry   Education', 'Sensory   Image', 'Sensory Expression', 'Image', 'Literary Shape', '주요어: 초등 시교육', '감각 이미지', '감각적 표현', '이미지', '문학적 형상성']","본 연구의 목적은 2015 개정 국어과 교육과정과 2022 개정 국어과 교육과정에서 감각 이미지의 수용 양상을 비교 검토하여 감각 이미지 수용의 변화를 살피는 데 있다.시교육에서 감각 이미지는 크게 두 가지로 의미로 구분된다. 하나는 감각 기관(오감)에의해 대상에 대한 감각적인 모습이나 느낌이 마음속에 떠오르는 심상적 차원이고, 다른하나는 감각 이미지를 통하여 시의 주제나 사상을 구체화하는 문학적 형상성 차원이다.그간 초등 시교육에서는 감각 이미지 교육 내용을 심상에 중점을 두고 한정적으로 접근해왔다. 이는 감각 이미지를 작품의 구성 요소로 인식하여 감각적 속성을 지나치게 강조한 결과이다. 이에 대한 반성으로 감각 이미지 교육이 심상을 통해 문학적 형상성으로 나아가야 한다고 주장하지만, 여전히 심상적 차원에 머무르는 수준이었다.본 연구에서는 그간 심상적 차원에 치중된 감각 이미지 교육 내용의 수용에 대한변화를 살펴보고자 2015 개정 국어과 교육과정과 2022 개정 국어과 교육과정을 비교검토하였다. 그 결과, 2022 개정 국어과 교육과정은 심상에 치중되었던 교육 내용이일부분 해소되고 문학적 형상성에 대한 교육 내용을 보강하는 변화를 찾을 수 있을 수있었다. 특히 3∼4학년군에서 성취기준, 성취기준 해설 모두에서 문학적 형상성으로서의 비중이 확대된 점을 확인할 수 있었다. 이러한 변화가 교육적 실효성을 거두기 위해서는 감각 이미지 교육에서 학습자의 심리 작용에 주목하여 문학적 형상성을 구현하는활동이 구안될 필요가 있다.","The purpose of this study is to compare and examine the patterns of sensory image acceptance in the 2015 and 2022 revised curriculums to examine the changes in sensory image acceptance in the 2022 revised curriculum.In poetry education, sensory images are largely divided into two meanings. One is an image dimension in which a sensory appearance or feeling of an object arises in the mind by a sensory organ (five senses), and the other is a literary form dimension  that  embodies  the  subject  or  idea  of  a  poem  through  sensory  images.Until now, elementary school education has taken a limited approach that focuses on images of sensory image education. This is the result of over-emphasizing the sensory properties  by  recognizing  the  sensory  image  as  a  component  of  the  work.  In reflection on this, it was argued that sensory image education should move toward literary formality through imagery, but it was still at the level of image.In  this  study,  the  2015  and  2015  revised  Korean  language  curriculum  were compared and reviewed to see if there has been any change in the acceptance of sensory image education content that has been focused on the image dimension. As a  result,  the  2022  revised  Korean  language  curriculum  partially  resolved  the educational content that had been focused on image and reinforced the content of literary  form.  In  particular,  in  the  3rd  and  4th  grades,  the  proportion  of  literary formality  in  both  achievement  standards  and  achievement  standard  commentary showed an expanded change.In  order  for  these  changes  to  be  educational  effective,  activities  that  focus  on learner psychological action rather than learning about sensory images themselves in sensory image education need to be devised."
Assessment of strategies to enhance the online presence of the Mozambican government website on tourism destination marketing,2023,"['Tourism', 'Strategies', 'Online presence', 'Marketing', 'Government website', 'INATUR']",,"The purpose of the present paper was to explore the best practices of destination management in promoting tourist destinations through the Mozambique government website (INATUR) and identify strategies that enhance its visibility and online presence. This was only possible by (1) exploring if people are aware of the government website’s existence; (2) examining the existence of indicators of the engagement behaviors for the web-users (visitors) in their searching process on the government website; (3) exploring if the engagement behavior and website features have influence on the government website visitors’ satisfaction and (4) providing measures to enhance the popularity of the government website at INATUR.The study combined a qualitative and quantitative methodological approach from the primary data collected via an online questionnaire survey of 269 random respondents, and the selected data was analyzed and processed using Stata 13 with the descriptive statistic and ANOVA [Analysis of Variance (an econometric model)] technique. The data was collected from secondary sources and from the interview, a strengths, weaknesses, opportunities, and threats (SWOT) analysis was applied with an interpretive approach.The government website presents the minimum of relevant information to respond to the users’ needs and expectations. There is little knowledge regarding the existence of the government website for tourism destination marketing. Few respondents were surprised about this website’s existence. The optimistic side of responses came from those peple who used the website and it helped their expectation. The correlation analysis showed a significant positive relationship between the government website features and the visitors’ searching satisfaction; the interview outputs noted that the shortage of staff at INATUR with knowledge of digital marketing engagement plays a role in solving the problem of the visibility and online presence of the website.One of the apparent limitations of this research was the world pandemic situation (Covid-19), which influenced to make abrupt arrangements in conducting the questionnaire survey and interview compared to the planned schedule. The interview was supposed to be a field research to have direct contact with her respondents and collect nonverbal information through the respondents’ body language, but unfortunately, it was not possible. Improvising was one of the solutions and had to design an online questionnaire survey for national and international tourist respondents and an emailed interview with INATUR director. Because of that, the results showed a very significant gap between African nationals and international respondents in number of 264 and 5, respectively (about in 98,14%) caused by the lockdown and traveling limitation.The adoption of the contents in “Recommendations for policy and decision-making” can help in synergizing an integrative marketing communication strategy that enables all actors to maximize local economic benefits without spending many financial resources, and support sustainability, different tourist destination suppliers, authorities and local communities’ development. Ensuring effective and efficient communication, and above all, enhancing the provision of reliable information. Reinforce the importance of the practical teaching and learning of digital platforms in tourism schools and universities; offer a thematic tool to serve as an analytical basis in future studies, encouraging continuous scientific research on the subject under study.Raising the awareness of the government website among tourist consumers; promoting Mozambique as a reference destination and its tourist diversity through the use of the government website; capitalizing tourists’ enterprises for communities’ development; improving the competitiveness of destinations through greater exposure of tourism products and services on the government website boosts the economic gain..."
