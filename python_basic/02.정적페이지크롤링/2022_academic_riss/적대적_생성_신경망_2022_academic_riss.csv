title,date,keywords,abstract,multilingual_abstract
태스크 점진 학습에서의 적대적 생성 신경망과 베이지안 신경망을 활용한 모델 재생성,2022,"['neural networks parameter regeneration', 'generative adversarial networks', 'Bayesian neural networks', 'continual learning', 'task-incremental learning', '신경망 파라미터 재생성', '적대적 생성 신경망', '베이지안 신경망', '지속 학습', '태스크 지속 학습']","지속적인 학습이 가능한 인간과는 대조적으로 딥러닝 모델은 학습하는 태스크가 점진적으로 들어오는 상황에서 기존의 성능을 유지하는데 상당한 어려움을 갖는다. 본 논문에서는 신경망 재생성 기반의 새로운 태스크 점진 학습 방법인 ParameterGAN을 제안한다. 제안된 방법은 적대적 생성 학습을 활용하여 사전 학습한 베이지안 신경망의 파라미터와 유사한 분포를 가지는 신경망 자체를 재생성하고, 유사 리허설(pseudo-rehearsal) 방식을 통해 치명적 망각 없이 과거 모든 시점의 신경망을 재생성하여 지속학습을 가능하게 한다. 다양한 실험을 통해 재생성한 파라미터로 구성된 합성 모델의 성능이 사전 학습된 모델의 성능에 준함을 확인하고, 태스크 점진 학습 상황인 Split-MNIST, Permuted-MNIST 벤치마크 실험에서 제안 방법이 기존의 다른 방법보다 더욱 우수한 성능을 보임을 확인한다.","In contrast to the human ability of continual learning, deep learning models have considerable difficulty maintaining their original performance when the model learns a series of incrementally arriving tasks. In this paper, we propose ParameterGAN, a novel task-incremental learning approach based on model synthesis. The proposed method leverages adversarial generative learning to regenerate neural networks themselves which have a parameter distribution similar to that of a pre-trained Bayesian network. Also, using pseudo-rehearsal methods, ParameterGAN enables continual learning by regenerating the networks of all previous tasks without catastrophic forgetting.Our experiment showed that the accuracy of the synthetic model composed of regenerated parameters was comparable to that of the pre-trained model, and the proposed method outperformed the other SOTA methods in the comparative experiments using the popular task-incremental learning benchmarks Split-MNIST and Permuted-MNIST."
객체 탐지를 위한 객체 복사 기반의 적대적 생성 신경망 활용 이미지 데이터 증강 기법,2022,"['합성곱 신경망', '적대적 생성 신경망', '이미지 데이터 증강', '객체 탐지', 'convolution neural network (CNN)', 'generative adversarial network (GAN)', 'image data augmentation', 'object detection']","컴퓨터 비전 분야에서는 양질의 이미지 데이터가 합성곱 신경망(CNN) 모델의 성능에 중요한 영향을 미친다. 하지만 실제 도메인에서는 충분한 양질의 데이터를 구하는 것이 어렵기 때문에 이미지 데이터의 증강 기법에 대한 연구가 계속해서 이루어지고 있다. 본 논문에서는 기존에 연구되던 적대적 생성 신경망(GAN)과 객체 복사(Copy-Paste) 기반의 증강 기법을 결합하여 더 다양한 이미지 데이터를 생성할 수 있는 이미지 데이터 증강 기법을 제안한다. 경계 상자(bounding box)가 아닌 객체 경계를 잘라내고, 적대적 생성 신경망을 사용하여 객체를 변형함으로써 기존의 픽셀 단위, 이미지 단위에서 벗어난 객체 단위의 이미지 데이터 증강을 보인다.","In the field of computer vision, massive well-annotated image data are essential to achieve good performance of a convolutional neural network (CNN) model. However, in real world applications, gathering massive well-annotated data is a difficult and time-consuming job. Thus, image data augmentation has been continually studied. In this paper, we proposed an image data augmentation method that could generate more diverse image data by combining generative adversarial network (GAN) and copy-paste based augmentation. The proposed method generated not pixel-level or image-level augmentation, but object-level augmentation by cutting off segmentation boundaries(mask) instead of bounding boxes. It then applyied GAN to transform objects."
순환 적대적 생성 신경망을 이용한 안면 교체를 위한 새로운 이미지 처리 기법,2022,"['Face swapping', 'face translation', 'cycle generative adversarial network (cycleGAN)', 'landmarks', 'dataset', '안면 교체', '안면 변환', '순환 적대적 생성 신경망', '특이점', '데이터셋']","최근 모바일 단말기 및 개인형 컴퓨터의 비약적인 발전과 신경망 기술의 등장으로 영상을 활용한 실시간 안면 교체가 가능해졌다. 특히, 순환 적대적 생성 신경망은 상호 연관성이 없는 이미지 데이터를 활용한 안면 교체가 가능하게 만들었다. 본 논문에서는 적은 학습 데이터와 시간으로 안면 교체의 품질을 높일 수 있는 입력 데이터 처리 기법을 제안한다. 제안 방식은 사전에 학습된 신경망을 통해서 추출된 안면의 특이점 정보와 안면의 구조와 표정에 영향을 미치는 주요 이미지 정보를 결합함으로써 안면 표정과 구조를 보존하면서 이미지 품질을 향상시킬 수 있다. 인공지능 기반의 무참조 품질 메트릭 중의 하나인 blind/referenceless image spatial quality evaluator (BRISQUE) 점수를 활용하여 제안 방식의 성능을 정량적으로 분석하고 기존 방식과 비교한다. 성능 분석 결과에 따르면 제안 방식은 기존 방식 대비 약 4.6%~14.6% 개선된 BRISQUE 점수를 나타내었다.","With the recent rapid development of mobile terminals and personal computers and the advent of neural network technology, real-time face swapping using images has become possible. In particular, the cycle generative adversarial network made it possible to replace faces using uncorrelated image data. In this paper, we propose an input data processing scheme that can improve the quality of face swapping with less training data and time. The proposed scheme can improve the image quality while preserving facial structure and expression information by combining facial landmarks extracted through a pre-trained neural network with major information that affects the structure and expression of the face. Using the blind/referenceless image spatial quality evaluator (BRISQUE) score, which is one of the AI-based non-reference quality metrics, we quantitatively analyze the performance of the proposed scheme and compare it to the conventional schemes. According to the numerical results, the proposed scheme obtained BRISQUE scores improved by about 4.6% to 14.6%, compared to the conventional schemes."
적대적 생성 신경망을 통한 얼굴 비디오 스타일 합성 연구,2022,"['적대적 생성 네트워크', '비디오 생성', '스타일 변환', '스타일 합성 네트워크', '동영상 합성 네트워크', 'Generative Adversarial Network', 'Video Generation', 'Style Transfer', 'Style Synthesis Network', 'Video Synthesis Network']",국문 초록 정보 없음,"In this paper, the style synthesis network is trained to generate style-synthesized video through the style synthesis through trainingStylegan and the video synthesis network for video synthesis. In order to improve the point that the gaze or expression does not transferstably, 3D face restoration technology is applied to control important features such as the pose, gaze, and expression of the head using3D face information. In addition, by training the discriminators for the dynamics, mouth shape, image, and gaze of the Head2head network,it is possible to create a stable style synthesis video that maintains more probabilities and consistency. Using the FaceForensic datasetand the MetFace dataset, it was confirmed that the performance was increased by converting one video into another video while maintainingthe consistent movement of the target face, and generating natural data through video synthesis using 3D face information from thesource video’s face."
적대적 생성 신경망을 이용한 조직병리학 영상 초해상화,2022,"['Deep learning', 'CNN', 'Super-resolution', 'Histopathology', 'Medical image']","이미지 디지털화 기술이 발전을 이루면서 기존 현미경으로 진행하던 조직 검사는 슬라이드 스캐너를 통해 디지털 이미지로 촬영 및 저장된다. 슬라이드 스캐너는 수 기가 바이트의 고해상도 이미지로 촬영하기 때문에 조직병리학 영상 촬영에 긴 시간이 소요되며 또한 이를 저장하기 위한 많은 메모리 공간이 필요하다. 이를 해결하기 위해 낮은 해상도로 저장하고, 후에 복원하는 초해상화 기법을 조직병리학 영상에 적용한 연구들이 등장하였다. 본 논문에서는 Bicubic Interpolation으로 된 이미지 위에 적대적 생성 신경망을 이용해 만든 잔차 이미지를 더하는 방법으로 원본에 가까우면서도 시각적으로 자연스러운 초해상화 된 조직병리학 영상을 생성하였다. 실험 결과 4x 확대하였을 때, PSNR 29.24dB을 달성하였으며, 정성적으로도 원본에 가까운 이미지를 생성할 수 있음을 보여주었다.",다국어 초록 정보 없음
적대적 생성 신경망을 활용한 비지도 학습 기반의 대기 자료 이상 탐지 알고리즘 연구,2022,"['대기질', '머신러닝', '딥러닝', '비지도 학습', '이상탐지', 'Air Quality', 'Machine Learning', 'Deep Learning', 'Unsupervised Learning', 'Anomaly Detection']",국문 초록 정보 없음,다국어 초록 정보 없음
적대적 생성 신경망의 금융 시계열 특성 학습 능력에 대한 고찰,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
적대적 생성 신경망을 통한 기후별 현실적 지형 생성,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
적대적 생성 신경망의 금융 시계열 특성 학습 능력에 대한 고찰,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
적대적 생성 신경망 기반의 과대표집을 활용한 설비 상태 프레임 워크,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성 신경망 재생성을 위한 적대적 생성 신경망,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
판별자를 활용한 적대적 생성 신경망 프루닝,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
커널 어텐션을 활용한 적대적 생성 신경망,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
적대적 시계열 생성 신경망을 이용한 지대지 미사일 궤적 생성,2022,"['Surface-to-Surface Missile(지대지 미사일)', 'Time-Series Generative Adversarial Network(적대적 시계열 생성 신경망)', 'Supervised Learning(지도학습)']",국문 초록 정보 없음,다국어 초록 정보 없음
적대적 공격의 전이성 향상을 위한 이미지 왜곡 기법,2022,"['Adversarial attack', 'Transfer-based attack', 'Transferability', 'Image warping', 'Elastic transformation']","합성곱 신경망은 컴퓨터 비전 분야에서 뛰어난 성능을 보이고 있지만 눈에 띄지 않는 잡음이 추가된 적대적 예제에 취약하다. 적대적 예제에 대한 취약성은 보안, 안전이 중요한 분야에서 심각한 문제를 일으킬 수 있다. 따라서 신경망이 상용화되기 전 취약성을 확인하여 위협에 대비하기 위해 적대적 공격에 대한 연구가 활발히 진행되고 있다. 타겟 모델의 내부 구조가 숨겨져 있는 상황에서는 공격자가 자신이 가지고 있는 소스 모델을 사용하여 적대적 예제를 생성하고, 그 이미지가 타겟 모델도 교란하기를 기대하는 전이성 기반 공격을 수행할 수 있다. 이러한 공격의 전이성을 향상시키기 위해 지금까지 제안된 입력 다변화 방법은 모든 픽셀에 같은 변환을 가하여 상대적으로 적은 전이성 향상을 보인다. 이에 본 논문은 입력 이미지의 각 픽셀을 재배치하여 전이성이 높은 적대적 예제를 생성하는 방법을 제안한다. 좀 더 상세히 말하면, 다양한 방향의 왜곡을 표현할 수 있는 탄성 변환을 사용하여 입력의 다양성을 확대하고 적대적 예제가 소스 모델에 과적합되는 것을 피한다. 우리는 이미지넷 기반 여러 분류 모델에 대한 적대적 공격 실험을 통해 탄성 변환을 사용하여 적대적 예제를 생성하는 방법이 전이성을 높이는 효과적인 방법임을 보인다.",다국어 초록 정보 없음
가우시안혼합모델을 이용한 IPM 로터 최적이미지 생성에 관한 연구,2022,"['GMM(Gaussian Mixture Model', '가우시안혼합모델)', 'IPM(Interior Permanent Magnet Synchronous Motor', '내부영구자석 동기모터)', 'THD(Total Harmonic Distortion', '전고조파 왜율)', 'DCGAN(Deep Convolution Generative Adversarial Network', '심층합성곱적대적생성신경망)', 'K-means clustering(K평균군집화)']",국문 초록 정보 없음,다국어 초록 정보 없음
이미지 생성 및 지도학습을 통한 전통 건축 도면 노이즈 제거,2022,"['건축 문화재 도면', '노이즈 제거', '머신러닝', 'CycleGAN', '이미지 합성', 'Architectural heritage drawing', 'Denoising', 'Machine Learning', 'CycleGAN', 'Image Fusion']","전통 목조 건축물은 시간이 지남에 따라 변형이 발생하고, 화재나 지진 등에 취약하다. 따라서 전통 목조 건축물은 지속적인 관리와 보수가 필요하며, 보수, 복원을 위해 건축 도면의 확보는 필수적이다. 하지만 전통 목조 건축물 도면은 현대화된 CAD 도면과 달리 손으로 그린 도면을 스캔하여 보관하고 있으며, 이 과정에서 도면 자체의 훼손 및 풍화로 인해 많은 노이즈를 포함하고 있다. 이러한 도면은 디지털화되었으나 노이즈로 인해 활용도가 떨어지고, 전통 목조 건축물의 체계적 관리에 어려움을 가중시키고 있다. 기존 알고리즘에 의한 노이즈 제거는 노이즈 특성에 따라 적용할 수 있는 도면이 한정적이고, 같은 도면 내에서도 그 성능이 균일하지 않다. 본 연구에서는 인공 신경망 기반의 건축 도면에 대한 노이즈 제거를 제안한다. 전통 건축물 중에서 주심포 양식에 해당하는 국보 및 보물 급 목조 건축물의 정면, 측면, 평면도에 대한 도면이 대상으로 고려되었다. 건축 도면의 노이즈 특성을 순환 적대적 생성 모델과 휴리스틱 이미지 융합 방법을 통해 학습하여, 인공 신경망 기반 노이즈 제거 학습을 위한 훈련 데이터셋을 제작했다. 노이즈 제거 네트워크는 딥 네트워크 모델을 사용하여 준비된 훈련 세트를 이용한 지도 학습을 통해 훈련되었다. 평가 데이터 세트는 노이즈가 있는 이미지에 대해 포토샵을 이용해, 수작업으로 노이즈가 없는 이미지를 제작하여 노이즈 제거 네트워크의 성능을 평가했다. 제안된 방법은 건축 도면의 미세한 선을 악화시키지 않고 노이즈를 효과적으로 제거할 수 있으며 구겨짐, 찢어짐 등 다양한 노이즈 형태에 대해서 좋은 성능을 보였다.",다국어 초록 정보 없음
인공지능 모델로 식별 가능한 비식별 이미지 생성 방법,2022,"['비식별', '얼굴식별', '적대적공격', 'CCTV', 'DNN', 'CNN', 'De-identification', 'face identification', 'Adversary attack', 'CCTV', 'DNN', 'CNN']","최근 어디에서나 흔하게 볼 수 있는 CCTV는 사생활 침해의 논란이 있다. 심층신경망은 기반 이미지 인식, 패턴 분석과 같은 여러 유용한 서비스에 적용되었다. 한편, 적대적 예제는 심층신경망 보안에 큰 위협이 된다. 예로, 이미지에 약간의 노이즈를 추가하여 만들어진 얼굴 적대적 예제는 얼굴 인식 시스템에서 오인식이 발생 할 수 있다. 하지만 비식별화한 이미지를 재식별이 필요한 일부 상황에서는 적대적 예제가 유용할 수 있다. 이 논문에서는 우리는 재식별 가능한 얼굴 비식별화 방법을 제안한다. 제안하는 기법은 사람의 시각으로 식별할 수 없는 얼굴 식별 모델은 식별을 가능하게 한다. 비식별화 방법은 가우시안 블러와 적대적공격 기법인 C.W 공격을 사용하였다. 그리고 동영상을 이용한 실험으로 이 기법이 작동한다는 것을 보여주었다.",다국어 초록 정보 없음
강화학습을 이용하여 인공신경망에 대한 adversarial attack을 방어하는 affine transformer에 관한 연구,2022,[],본 논문은 사전훈련된 이미지 인식 모델의 adversarial attack을 방어하기 위해서 이미지가 모델의 입력되기 전에 강화학습을 통해 선정된 매개 변수를 이용하여 affine transform하여 적대적 공격에 대해 방어하는 이미지를 생성하는 알고리즘을 제안하였다. MNIST 데이터셋에 대해 정확도가 기존 98.5%에서 15.94%까지 떨어지게하는 FGSM 방식의 adversarial attack에 대해 본 논문의 알고리즘을 적용했을 때 68.12%까지 방어하는데 성공하였다.,다국어 초록 정보 없음
미디어 인공지능  : 컴퓨터 비전 관련 딥러닝 모델의 미디어 동영상 분야 적용 가능성에 관한 연구,2022,"['deep learning', 'computer vision', 'convolutional neural networks(CNN)', 'recurrent neural networks (RNNs)', 'generative adversarial network (GANs)', 'media AI(media artificial intelligence)', 'video analytics', '딥러닝', '컴퓨터 비전', '합성곱 신경망', '순환 신경망', '적대적 신경망', '미디어 인공지능', '동영상 내용분석']","미디어 동영상 분야는 컴퓨터 비전 관련 딥러닝 모델을 활용해 연구 차원에서는 동영상의 자동화된 내용분석을 수행하고 실무 차원에서는 미디어 분야의 디지털 전환을 통해 서비스를 개선할 여지가 큰 영역이다. 이 논문에서는 미디어 동영상의 분석과 생성에 활용도가 높은 비전 관련 딥러닝 기반 모델을 검토했다. 우선 다양한 모델의 기축이 되는 알고리즘으로서 분류 모델로 널리 사용되는 합성곱 신경망(CNN)과 순환 신경망(RNN), 생성 모델로 사용되는 적대적 생성 신경망(GAN)과 오토인코더(AE), 사전 훈련 모델을 활용하는 전이학습을 살펴보았다. 다음으로 미디어 동영상 영역에서 활용도가 높은 과업을 객체탐지, 행동인식, 사건탐지, 동영상 요약, 동영상 분류 등 5개 대분류와 객체탐지, 안면인식, 표정인식, 랜드마크 인식, 상품인식, 행동인식, 자세추정, 이상탐지, 상황인식, 동영상 요약, 동영상 분류 등 11개 소분류로 제시했다. 이어 각 과업별 SOTA(state-of-the-art)와 벤치마크 데이터셋을 소개했다. 끝으로 이러한 모델의 학문적, 실무적 활용 가능성을 제시해보았다. 본 논문은 수식이나 프로그래밍에 대한 지식이 없이 미디어 연구자나 미디어 서비스 기획자가 비전 분야 딥러닝의 큰 흐름을 파악하고 관련 모델을 직접 활용하거나 컴퓨터공학 분야의 연구자 또는 개발자와 협업할 때 배경지식을 제공할 것으로 기대한다. 또한 비전 관련 딥러닝이 발전함에 따라 미디어 인공지능 기반 동영상 빅데이터 분석 시스템의 개발 가능성도 높아질 것이다.","Recently, media researchers employ deep learning models related to computer vision to perform automated content analysis of videos. Understanding deep learning models is also essential to AI(artificial intelligence) driven digital transformation in the media industry. In this paper, we reviewed computer vision-related deep learning models that are widely used for video analytics and generation. First, we looked at convolutional neural networks (CNNs) and recurrent neural networks (RNNs), which are widely used for classification, as well as generative adversarial network (GANs) and autoencoders (AEs) as generation models, and transfer learning using pre-training models. Following that, we proposed tasks in five major categories for which AI could be highly useful: object detection, action recognition, event detection, video summarization, and video classification. Then, for subtasks such as object detection, face recognition, facial expression recognition, landmark recognition, product recognition, pose estimation, anomaly detection, context recognition, video summarization, and video classification, we introduced state-of-the-arts (SOTAs) and benchmark datasets. Finally, the potential academic and practical applications of these models were discussed. We anticipate that media researchers or media service providers will understand the major trend of deep learning in computer vision and will be able to get knowledge when using deep learning models independently or collaborating with programmers."
GAN을 활용한 결함 영상 데이터 증강,2022,"['Deep learning', 'GAN augmentation', 'Transfer learning', 'Classification']","다양한 산업 분야에서는 생산 효율성을 높이기 위해 제조 공정을 자동화하고 있으며, 그 중 딥러닝을 이용한 결함 감지 자동화 기술은 스마트 팩토리 구축을 위한 단계 중 하나이다. 이러한 기술에는 많은 양의 학습 데이터가 필요하다. 그러나, 일반적으로 제조 공정에서 수집되는 데이터는 양품에 비하여 발생하는 불량품의 수가 적기 때문에 불균형한 양상을 보인다. 이로 인해 모델의 성능에 중요한 영향을 끼치는 충분한 데이터를 구축하는 것이 쉽지 않은 상황이다. 본 논문은 앞서 언급한 문제점을 극복하고자 적대적 생성 신경망(GAN) 기반 모델을 사용하여 결함 영상 데이터 증강 방안을 제시한다. 제안하는 기법은 실제 제조 영상 데이터를 사용하여 생성 모델 훈련을 수행하며, 이를 통해 보다 사실적이고 다양한 결함 데이터를 생성하여 기존의 불균형 문제를 해결한다. 제안하는 기법의 생성 결과와 다른 모델과의 비교를 통해 정량 및 정성적으로 우수함을 보이며, 더 나아가 생성한 데이터를 학습 데이터에 포함시킴으로써, 결함 분류 모델의 성능을 13.23% 향상시키는 효과를 증명한다.",다국어 초록 정보 없음
GAN기반 아바타의 detail 조절 기법,2022,"['아바타', '자동생성', '몰입도', '사생활보호', '생성적적대적신경망']",국문 초록 정보 없음,다국어 초록 정보 없음
"대조적 표현 학습을 통하여 그룹, 유저, 아이템의 구조를 활용하는 추천",2022,"['그룹 추천', '신경망 기반 협업 필터링', '대조적 표현 학습', '데이터 희소성', '적대적 학습', 'group recommendation', 'neural collaborative filtering', 'contrastive representation learning', 'data sparsity', 'adversarial training']","그룹 추천 시스템은 복수의 유저로 이루어진 그룹에게 아이템을 추천하는 시스템이다. 기존의 그룹 추천 시스템은 그룹-아이템 상호작용이 부족한 상황에서도 정확한 추천을 하기 위해 그룹의 임베딩과 해당 그룹의 구성원의 임베딩 사이의 상호 정보량을 최대화하여 아이템을 추천한다. 그러나 그룹-아이템 상호작용과 유저-아이템 상호작용이 모두 부족한 상황에서는 추천 성능이 떨어진다는 단점이 있다. 이를 해결하기 위하여 그룹과 유저에 대한 대조적 표현 학습뿐만 아니라 그룹과 아이템에 대한 대조적 표현 학습을 사용하는 연구가 진행되었다. 이 논문에서는 적대적 생성 신경망을 적용한 협업 필터링을 사용하여 유저-아이템 상호작용 데이터를 증강시키는 방법을 제시한다. 또한, 실험을 통하여 제안하는 방식이 그룹과 아이템, 유저와 아이템 간의 상호작용들이 부족한 상황에서도 추천 성능을 향상시킴을 확인한다.","A group recommendation system is a system for recommending items to a group consisting of several users. Existing group recommendation systems recommend items by maximizing the mutual information between the embedding of the group and the embedding of the members of the group in order to make an accurate recommendation even in a situation where group-item interactions are sparse. However, a key weakness is that the recommendation performance is poor when both group-item interactions and user-item interactions are sparse. To solve this problem, a method using contrastive representation learning for groups and items as well as for groups and users was proposed. In this paper, we propose a method to augment user-item interaction data using a collaborative filtering method based on a generative adversarial network. Our experimental results show that the proposed method improves recommendation performance even when interactions between groups and items and between users and items are both sparse."
Pix2Pix의 수용 영역 조절을 통한 전통 고궁 이미지 복원 연구,2022,"['Discriminator', 'GAN', 'Pix2Pix', 'Receptive field', 'Restoring photo']",본 논문은 흑백 사진으로만 남아 있는 한국의 전통 고궁 사진을 적대적 생성 신경망 기법의 하나인 Pix2Pix를 활용하여 컬러 사진으로 복원하기 위한 학습 모델 구조를 제시한다. Pix2Pix는 합성 이미지를 생성기와 합성 여부를 판정하는 판별기의 학습 모델 조합으로 구성된다. 본 논문은 판별기의 수용 영역을 조절하여 인공지능 모델을 학습하고 그 결과를 고궁 사진이 가지는 특성을 고려하여 분석하는 내용을 다룬다. 기존에 흑백 사진 복원에 사용하는 Pix2Pix의 수용 영역은 주로 고정된 크기로 사용하였으나 이미지의 변화가 다양한 고궁 사진을 복원함에 있어서는 고정된 수용 영역을 일률적으로 적용하기에 적합하지 않다. 본 논문에서는 고궁의 특성을 반영할 수 있는 판별기의 수용 영역을 확인하기 위해 기존의 고정된 수용 영역의 크기를 변화시켜 나타나는 결과를 관찰하였다. 실험은 사전에 준비한 고궁 사진을 기반으로 판별기의 수용 영역을 조정하고 모델의 학습을 진행하였다. 판별기의 수용 영역 변화에 따른 모델의 손실을 측정하고 최종 학습한 학습 모델을 복원 대상 흑백 사진에 대입하여 복원 결과를 확인한다.,"This paper presents a AI model structure for restoring Korean traditional palace photographs, which remain only black-and-white photographs, to color photographs using Pix2Pix, one of the adversarial generative neural network techniques. Pix2Pix consists of a combination of a synthetic image generator model and a discriminator model that determines whether a synthetic image is real or fake. This paper deals with an artificial intelligence model by adjusting a receptive field of the discriminator, and analyzes the results by considering the characteristics of the ancient palace photograph. The receptive field of Pix2Pix, which is used to restore black-and-white photographs, was commonly used in a fixed size, but a fixed size of receptive field is not suitable for a photograph which consisting with various change in an image. This paper observed the result of changing the size of the existing fixed a receptive field to identify the proper size of the discriminator that could reflect the characteristics of ancient palaces. In this experiment, the receptive field of the discriminator was adjusted based on the prepared ancient palace photos. This paper measure a loss of the model according to the change in a receptive field of the discriminator and check the results of restored photos using a well trained AI model from experiments."
CycleGAN을 활용한 야간 도로환경 Segmentation 성능 향상,2022,"['Curb segmentation(연석 검출)', 'Computer vision(컴퓨터 비전)', 'Lidar(라이다)', 'Sensor Fusion(센서 퓨전)', 'GAN(적대적 생성신경망)']",국문 초록 정보 없음,다국어 초록 정보 없음
영상의 구조적 왜곡억제를 위한 희소 그라디언트 가이드 주의집중 및 웨이블릿 손실을 활용한 초해상화,2022,"['super resolution', 'generative adversarial network', 'self attention', 'gradient', 'wavelet transform', '.']","적대적 생성망 기반의 초해상화 모델은 인지적 측면에서 만족할만한 우수한 영상 화질을 제공할 수 있지만 텍스처 영역에서 구조적인 왜곡 문제를 일으킨다. 이를 개선하기 위해, 생성자에 그라디언트 부신경망과 그라디언트 손실함수를 통합함으로써 텍스처 왜곡을 완화할 수 있지만, 여전히 텍스처 왜곡 문제는 현안으로 남아있다. 따라서 본 논문에서는 텍스처 왜곡이 보정된 초해상화 영상 복원을 위해 희소 그라디언트 가이드 주의집중 및 웨이블릿 손실함수 기반 초해상화 딥러닝 모델을 제시하고자 한다. 특히, 특징 간의 전역적 상호의존성을 모델링할 수 있는 희소 그라디언트 가이드 주의집중 모듈을 고안하여 텍스처 복원력을 제고하고자 한다. 또한, 텍스처 왜곡을 억제하기 위한 웨이블릿 기반 손실 모델을 제안하고자 한다. 실험 결과를 통해 제안된 초해상화 모델이 기존의 최신식 초해상화 모델에 비해, 텍스처 복원력을 개선하고 더 선명한 초해상화 영상을 생성할 수 있음을 보이고자 한다.","Even though SR(Super-Resolution) models based on Generative Adversarial Networks(GANs) can recover perceptually pleasant image quality, they cause structural distortions in the texture area. To address this problem, gradient subnetwork and gradient-based loss model are incorporated into the generator to alleviate the image structure distortion, however textural distortions still remain a pending issue. Therefore, this paper proposes the SR deep learning model based on the sparse gradient-guided attention and wavelet loss that corrects the texture distortions for better SR image restoration. In particularly, a sparse gradient-guided self-attention to model global interdependency between features is designed, thereby increasing the power of structural reconstruction. In addition, a wavelet-based loss model that more strongly suppresses the textural distortions is presented. Through the experimental results, it is confirmed that the proposed SR model improves the power of texture reconstruction and generates much clearer SR images, compared to the state-of-the-art conventional SR methods."
공간 적응적 비정규화 방식 기반 단일 영상 내 그림자 제거 기법,2022,"['조건부 적대적 생성 신경망', '정규화 층', '그림자 감지', '공간 적응적 비 정규화', '그림자 제거', 'Conditional generative adversarial networks', 'Normalization layers', 'Shadow detection', 'Spatially adaptive de-normalization', 'Shadow removal']","단일 영상 내 그림자 제거는 영상 처리 및 많은 컴퓨터 시각 분야에서 중요한 문제이다. 이 논문에서는 이러한그림자를 제거하기 위하여, 추가적인 그림자 감지를 필요로 하지 않는 조건부 적대적 생성 신경망 기반의 새로운신경망 구조를 제안한다. 제안하는 구조에서는, 신경망 내 다양하게 존재하는 정규화층으로 인해 발생되는, 입력영상 데이터의 정보 손실 문제를 방지하기 위해 공간 적응적 비정규화 방식을 활용하였고, 그림자 제거와 관련된공인 데이터 세트를 활용한 다양한 실험들로부터, 제안된 기법이 기존의 신경망 기반의 최신 방법론들과 비교하여적어도 5dB 높은 PSNR 성능을 가지는 것을 확인할 수 있다.","Shadow removal from a single-image has been a significant issue in image processing and many computer vision areas. This paper proposes a novel network based on the conditional generative adversarial network scheme without requiring additional shadow detection process to remove shadows. The proposed structure also utilizes a spatially adaptive de-normalization method to prevent the input image information loss caused by various normalization layers in the neural network. From the various experiments related to shadow removal using authorized datasets, it is confirmed that the proposed network shows at least 5dB higher performance in PSNR, compared to the state of the arts neural network based methodologies."
Pix2Pix의 활용성을 위한 학습이미지 전처리 모델연계방안 연구,2022,"['Discriminator', 'Generator', 'GAN', 'Pix2Pix', 'Homomorphic Filter']",본 논문은 적대적 생성 신경망 기법의 하나인 Pix2Pix를 활용하여 컬러색상을 입히는 경우 학습된 이미지의 빛 반사 정도에 따라 예측결과가 손상되어 나오는 부분에 집중하여 Pix2Pix 모델 적용 전 이미지 전처리 프로세스 및 모델 최적화를 위한 파라미터 테이블을 구성한다. 기존 논문에 나온 Pix2Pix 모델을 활용하여 실생활에 적용하기 위해서는 해상도에 대한 확장성을 고려해야한다. 학습 및 예측결과 이미지 해상도를 키우기 위해서는 동시에 모델의 커널 사이즈 등을 같이 맞춰주는 부분을 수정해줘야 하는데 이부분은 파라미터로 튜닝 가능하도록 설계했다. 또한 본 논문에서는 예측결과가 빛 반사에 의해 손상된 부분만 별도 처리하는 로직을 같이 구성하여 예측결과를 왜곡시키지 않는 전처리 로직을 구성하였다. 따라서 활용성을 개선하기 위하여 Pix2Pix 모델의 학습이미지에 공통적인 빛반사 튜닝 필터를 적용하는 부분과 파라미터 구성부분을 추가하여 모델 정확도를 개선하였다.,다국어 초록 정보 없음
CycleGAN기반 데이터 증대 방법을 활용한 도로 노면 인식,2022,"['road surface detection(도로 노면 인식)', 'data augmentation(데이터 증대)', 'CycleGAN(순환 적대적 생성 신경망)', 'semantic image segmentation(의미론적 이미지 분할)', 'image-to-image translation(이미지 변환)']",국문 초록 정보 없음,다국어 초록 정보 없음
GAN 오버샘플링 기법과 CNN-BLSTM 결합 모델을 이용한 부정맥 분류,2022,"['Arrhythmia', 'CNN', 'GAN', 'BLSTM', 'MIT-BIH', '부정맥', '합성곱 신경망', '적대적 생성 신경망', '양방향 장단기 기억 신경망', 'MIT-BIH']","부정맥이란 심장이 불규칙한 리듬이나 비정상적인 심박동수를 갖는 것을 말하며, 뇌졸중, 심정지 등을 유발하거나 사망에도 이를 수 있는 만큼, 조기 진단과 관리가 무엇보다 중요하다.본 연구에서는 심전도 신호의 QRS 특징 추출에 적합한 CNN과 기존 LSTM의 직전 패턴의 수렴 한계를 해결할 수 있는 BLSTM을 연결한 CNN-BLSTM 결합 모델을 이용한 부정맥 분류 방법을 제안한다. 이를 위해 먼저 전처리 과정을 통해 잡음을 제거한 심전도 신호에서 QRS 특징점을 검출하고 단일 비트 세그먼트를 추출하였다. 이때 데이터의 불균형 문제를 해결하기 위해 GAN 오버샘플링 기법을 적용하였다. 이 후 합성곱 계층을 통해 부정맥 신호의 패턴을 정밀하게 추출하도록 구성하고 이를 BLSTM의 입력으로 사용한 후 매개변수를 학습시키고 검증 데이터로 학습 모델을 평가한 후 부정맥 분류의 정확도를 확인하였다. 제안한 방법의 우수성을 입증하기 위해 MIT-BIH 부정맥 데이터베이스를 이용하여 분류의 정확도, 정밀도, 재현율, F1-score를 비교하였다. 성능평가 결과 각각 99.30%, 98.70%, 97.50%, 98.06%로 우수한 분류율을 나타내는 것을 확인할 수 있었다.","Arrhythmia is a condition in which the heart has an irregular rhythm or abnormal heart rate, early diagnosis and management is very important because it can cause stroke, cardiac arrest, or even death.In this paper, we propose arrhythmia classification using hybrid combination model of CNN-BLSTM. For this purpose, the QRS features are detected from noise removed signal through pre-processing and a single bit segment was extracted. In this case, the GAN oversampling technique is applied to solve the data imbalance problem. It consisted of CNN layers to extract the patterns of the arrhythmia precisely, used them as the input of the BLSTM. The weights were learned through deep learning and the learning model was evaluated by the validation data. To evaluate the performance of the proposed method, classification accuracy, precision, recall, and F1-score were compared by using the MIT-BIH arrhythmia database. The achieved scores indicate 99.30%, 98.70%, 97.50%, 98.06% in terms of the accuracy, precision, recall, F1 score, respectively."
딥러닝 기술을 이용한 넙치의 질병 예측 연구,2022,"['Fish Disease Prediction', 'Behavior Pattern Recognition', 'Smart Aquaculture', 'GAN', 'Image Processing', '어류 질병 예측', '행동 패턴 인식', '스마트 양식장', '적대적 생성 신경망', '영상처리']",수산 양식장 질병 감염의 확산을 사전에 차단을 위해서는 양식장의 수질 환경 및 생육 어류의 상태를 실시간모니터링하면서 어류의 질병을 예측하는 시스템이 필요하다. 어류 질병 예측의 기존 연구는 이미지 처리 기법이 대부분이었으나 최근에는 딥러닝 기법을 통한 질병 예측방법의 연구가 활발히 진행되고 있다. 본 논문에서는 수산 양식장에서 발생할 수 있는 넙치의 질병을 딥러닝 기술로 예측하는 방법에 대한 연구결과를 소개하고자 한다. 이 방법은 양식장에서 수집된 카메라 영상에 데이터 증강과 전처리 포함하여 질병 인식률의 성능을 높인다. 이것을 통해 질병 어류를 조기 발견으로 양식 어업에서 어류 집단 폐사 등 어업 재해를 예방하고 지역 수산 양식장으로 어류의 질병 확산 피해를 줄여 매출액 감소 차단될 것으로 기대한다.,"To prevent the spread of disease in aquaculture, it is a need for a system to predict fish diseases while monitoring the water quality environment and the status of growing fish in real time. The existing research in predicting fish disease were image processing techniques. Recently, there have been more studies on disease prediction methods through deep learning techniques. This paper introduces the research results on how to predict diseases of Paralichthys Olivaceus with deep learning technology in aquaculture. The method enhances the performance of disease detection rates by including data augmentation and pre-processing in camera images collected from aquaculture. In this method, it is expected that early detection of disease fish will prevent fishery disasters such as mass closure of fish in aquaculture and reduce the damage of the spread of diseases to local aquaculture to prevent the decline in sales."
