title,date,keywords,abstract,multilingual_abstract
재구성 가능한 모듈 기반 CNN 가속기 구현,2022,"['CNN accelerator', 'module-based architecture', 'FPGA', 'Verilog-HDL', '.']","본 논문에서는 CNN(Convolutional Neural Network)을 구성하는 주요 연산 모듈을 모듈 제어 명령어를 통해 구동함으로써 네트워크를 구현할 수 있는 CNN 가속기를 제안한다. 모듈 기반 CNN 가속기는 합성곱(Convolution), 풀링(Pooling) 등 CNN의 주요 연산 모듈로 구성되어 있으며, 프로세서에서 모듈 제어 명령어를 통해 네트워크 구성에 필요한 연산 모듈을 선택 및 내부 파라미터를 설정 할 수 있다. 본 논문에서 제안하는 모듈 기반 CNN 가속기를 사용하여 Xilinx SoC형 FPGA에 ResNet-18을 구현하였으며 CNN 프레임워크 모델인 PyTorch와 C 기반 검증 모델을 사용하여 출력 결과를 비교 검증하였다. 실험결과, CNN 가속기의 추론 결과는 92.87%의 정확도를 보였다.","In this paper, we propose a CNN(convolution neural network) accelerator that can implement a network by driving main computation modules constituting the CNN through module control commands. The module-based CNN accelerator consists of CNN's main computation modules such as convolution and pooling, and the processor can select the computation module required for network configuration and set internal parameters through module control commands. In this paper, ResNet-18 was implemented on a Xilinx SoC-type FPGA using the proposed module-based CNN accelerator, and the output results were compared and verified using PyTorch, a CNN framework model, and a C-based verification model. As a result of the experiment, the inference result of the CNN accelerator showed an accuracy of 92.87%."
CNN 기반 딥러닝을 이용한 베어링 고장 진단의 정확도 및 계산 복잡도 분석,2022,"['Fault Diagnosis', 'Fault Detection', 'Bearing', 'Deep Learning', 'Complexity', '고장 진단', '고장 검출', '베어링', '딥러닝', '복잡도']","산업 현장에서 사용되는 기계 설비 고장의 상당 부분을 베어링의 고장이 차지하고 있는 상황에서, 베어링 고장으로 인해 발생하는 경제적/시간적 손실을 최소화하기 위해서는 빠르고 정확한 베어링 고장 진단 시스템 구축이 요구된다. 본 논문에서는 베어링의 상태 정보를 담고 있는 음향 방출 신호를 시간-주파수 영역의 스펙트로그램 이미지로 변환한 후에, CNN 기반 딥러닝을 적용하여 베어링의 상태를 정확하게 판단할 수 있는 베어링 고장 진단 기법을 제안한다. 제안된 고장 진단 기법을 다양한 CNN 모델을 활용하여 구현함으로써 CNN 모델에 따른 딥러닝 기반 베어링 고장 진단의 정확성을 평가하고자 한다. 또한, 실제 산업 현장에서의 실시간 고장 진단 가능성을 판단하기 위해 CNN 모델에 따른 고장 진단 계산 복잡도를 분석한다. 이를 위해, 적용되는 CNN 모델에 따른 고장 진단 연산의 Multiply-Accumulate 복잡도를 구하고 실제 현장 적용에 적합할 것으로 판단되는 CNN 모델을 선택한 후, 해당 CNN 모델이 적용된 고장 진단을 라즈베리파이보드에서 동작시켜 봄으로써 산업 현장에 적용 가능한 임베디드시스템에서의 실시간 진단 가능성을 확인하고자 한다. 실험 결과, 기존의 신호 처리를 기반으로 하는 베어링 고장 진단 기법들이 약 80%의 정확도를 보여주는 반면 제안하는 딥러닝을 적용한 베어링 고장 진단 기법은 100%에 가까운 높은 진단 정확도를 제공한다. 하지만, 가장 낮은 계산 복잡도를 요구하는 ShuffleNet을 적용하는 제안 기법의 경우에도 라즈베리파이보드에서 진단을 수행하는데 24,270ms를 소요하여, 산업 현장에서 사용되기 위해서는 계산 복잡도를 더욱 낮출 수 있는 방안이 개발되어야 함을 알 수 있다.","Bearing faults account for a large portion of machine faults in real industrial sites. To minimize the damages caused by bearing faults, it is necessary to provide an accurate real-time bearing faults diagnosis system. In this work, we propose a new bearing fault diagnosis method using deep learning with various CNN models, where acoustic emission signals from working bearings are used to analyze the status of bearings. In the proposed method, the acoustic emission signals acquired from the bearings are converted into spectrogram images in the time-frequency domain, and then the status of bearings can be diagnosed through deep learning with various CNN models. Traditional signal processing based bearing fault diagnosis methods show the accuracy of about 80%, while our proposed deep learning based method provides very high fault diagnosis accuracy of about 100%. We also apply the proposed deep learning based fault diagnosis method to Raspberry Pi to test the availability for the working conditions in real industrial sites. We measured the multiply-accumulate complexity of the fault diagnosis process with various CNN models to find the CNN model suitable for real working conditions, and then the selected ShuffleNet CNN model was implanted and operated in Raspberry Pi to check the possibility of real-time bearing fault diagnosis."
CNN을 이용한 건축적 형상에 대한 선호 추정,2022,"['형태', 'CNN', 'ANN', '선호', '딥러닝', 'Form', 'CNN', 'ANN', 'Preference', 'Deep Learning']","본 연구의 목적은 인공신경망을 이용한 형태에 대한 선호도 파악의 가능성을 탐구하는 것이다. 이를 위해서 본 연구에서는 첫 번째 단계에서 사람들에게 형태에 대한 일관성있는 선호도가 존재하는지를 검토하였다. 첫 번째 단계의 연구 결과, 개인들에게는 형태에 대한 일관성있는 선호가 존재함을 확인하였다. 두 번째 단계에서는 인공신경망을 이용한 형태에 대한 선호도 파악의 가능성을 검토하였다. 첫 번째 단계에서 사용한 동일한 데이터를 이용하여 인공신경망을 학습시켜 분류 모델을 도출하였다. 이 분류 모델을 이용하여 분류 정확도를 평가하는 테스트를 실시하였다. 테스트 결과 75.7% 라는 높은 분류 정확도를 나타내었다. 이러한 높은 분류 정확도를 통해 인공신경망을 이용한 형태에 대한 선호도 파악의 가능성이 확인되었다고 주장할 수 있을 것이다.","This study aims to explore the possibility that artificial intelligence can identify human preferences through images using the convolutional neural network (CNN). To determine if people had a consistent preference for form, experiment participants were asked to select the preferred images among 200 images twice, which were automatically generated in dynamo. In the two consecutive image selection processes, ten participants repeatedly selected the same images at a rate of 79 percent. These results confirmed that there is a consistent preference for form. Next, the possibility of identifying the preference for form using CNN was investigated. Data for each experiment participant was divided into two sets. The preferred and non-preferred images were included in each set at a certain percentage. A classification model was produced by conducting supervised learning using CNN with one of the two sets. The classification accuracy was measured by applying this classification model to the other set. As a result of these tests, the classification model created by CNN could classify the preferred and non-preferred images with 82.7 percent accuracy. In random selection, the probability of correctly classifying the preferred and non-preferred images with more than 82.7 percent accuracy was 6.5 x 10-12 percent. Therefore, 82.7 percent reflects a fairly high classification accuracy. Based on this high accuracy, it was possible to identify human preferences for form using CNN"
Multi-channel CNN 기반 온라인 리뷰 유용성 예측 모델 개발에 관한 연구,2022,"['Online Reviews', 'Review Helpfulness', 'Review Text', 'Multi-channel CNN', '라인 리뷰', '리뷰 유용성', '리뷰 텍스트', 'multi-channel CNN']","온라인 리뷰는 소비자의 구매 의사결정 과정에서 중요한 역할을 담당하고 있으므로 소비자에게 유용하고 신뢰성이 있 는리뷰를제공하는것이중요하다. 기존의온라인리뷰유용성예측관련연구는주로온라인리뷰의텍스트와평점정 보 간의 일관성을 바탕으로 리뷰 유용성을 예측하였다. 그러나 기존 연구는 평점 정보를 스칼라로 표현했기 때문에 표현 수용력이 제한적이거나 평점 정보와 리뷰 텍스트 정보와의 상호작용을 제한적으로 학습하는 한계가 존재한다. 본 연구에 서는 기존 연구의 한계점을 보완하기 위해 리뷰 텍스트와 평점 정보 간의 상호작용을 효과적으로 학습할 수 있는 CNN-RHP(CNN based Review Helpfulness Prediction) 모델을 제안하였다. 먼저, 리뷰 텍스트의 의미론적 특성을 추출하 기 위해 multi-channel CNN을 적용하였다. 다음으로, 평점 정보는 텍스트 특성과 동일한 차원을 나타내는 독립된 고차원 임베딩 특성 벡터로 변환하였다. 최종적으로 요소별(Element-wise) 연산을 통해 리뷰 텍스트와 평점 정보 간의 일관성을 학습하였다. 본 연구에서는 제안된 CNN-RHP 모델의 성능을 평가하기 위해 Amazom.com에서 수집된 온라인 소비자 리 뷰를 사용하였다. 실험 결과, 본 연구에서 제안한 CNN-RHP 모델이 기존 연구에서 제안된 여러 모델과 비교했을 때 우수 한 예측 성능을 나타내는 것을 확인하였다. 본 연구의 결과는 온라인 전자상거래 플랫폼에서 소비자들에게 리뷰 유용성 예측 서비스를 제공할 때 유의미한 시사점을 제공할 수 있다.",다국어 초록 정보 없음
금속탐지를 위한 CNN 및 RNN 네트워크 개발에 관한 연구,2022,"['컨벌류션', '딥러닝', '전자파유도', '전자기유도 센서', '순환신경 망네트워크', 'CNN', 'Deep Learning', 'Electromagnetic Induction', 'MI Sensor', 'RNN']","본 논문은 다중 MI 센서에서 얻은 데이터에 대한 딥 러닝을 이용한 신호 처리 필터링 방법과 금속 탐지 방법의효율성에 관한 연구이다. MI 센서는 자기장의 변화를 감지하는 원리로 금속 물체를 감지하는 수동형 센서입니다.다만, 금속 물체를 검출할 경우, 금속에 의한 자기장의 변화량이 적기 때문에 검출 가능한 거리에 한계가 있다. 이를효과적으로 감지하고 분석하기 위해 딥러닝을 활용한 방법이 적용됐다. 또한 신호처리 필터링 방법을 이용하여 딥러닝 모델의 성능을 비교 분석하였다. 본 논문에서는 자기 임피던스 센서에서 추출한 데이터에서 CNN과 RNN 네트워크의 탐지 성능을 비교 분석하였다. RNN 모델은 CNN 모델보다 더 높은 성능을 보였다. 그러나 얕은 단계에서는CNN 모델이 RNN 모델보다 더 높은 성능을 보였다.","This paper is a study on the efficiency of the filtering method of signal processing and the metal detection method using deep learning for data obtained from multiple MI sensors. The MI sensor is a principle that detects changes in magnetic field and is a passive sensor that detects metal objects. However, when detecting a metal object, the amount of change in the magnetic field caused by the metal is small, so there is a limit to the detectable distance. In order to effectively detect and analyze this, a method using deep learning was applied. In addition, the performance of the deep learning model was compared and analyzed using the filtering method of signal processing. In this paper, the detection performance of CNN and RNN networks was compared and analyzed from the data extracted from the self-impedance sensor. The RNN model showed higher performance than the CNN model. However, in the shallow stage, the CNN model showed higher performance than the RNN model."
비정형 패션 이미지 검색을 위한 MASK R-CNN 선형처리 기반 CNN 분류 학습모델 구현,2022,"['비정형 데이터', '이미지 분류', '신경망', 'Mask R-CNN', 'Unstructured Data', 'Image Classification', 'Neural Network', 'Mask R-CNN']","본 논문에서는 패션 분야의 비정형 데이터 검색을 위한 패션 아이템별 세부 컨포넌트 이미지 분류 알고리즘을 제안한다. 코로나-19 환경으로 인하여 최근 AI 기반 쇼핑몰이 증가하는 추세이다. 하지만 기존의 키워드 검색과 사용자 서핑 행위 기반 개인 맞춤형 스타일 추천으로는 정확한 비정형 데이터 검색에는 한계가 있다. 본 연구는 다양한 온라인 쇼핑 사이트에서 크롤링한 이미지를 사용하여 Mask R-CNN을 활용한 전처리를 진행한 후, CNN을 통해 패션 아이템별 컴포넌트에 대한 분류를 진행하였다. 셔츠의 카라 및 패턴과 청바지의 핏, 워싱 및 컬러에 대한 분류를 진행하였으며, 다양한 전이학습 모델을 비교 분석한 후 가장 높은 정확도가 나온 Densenet121모델을 사용하여 셔츠의 카라는 93.28%, 셔츠의 패턴은 98.10%의 정확도를 도달하였으며, 청바지의 핏은 Notched, Spread, Straight 3가지의 클래스의 경우 91.73%, Regular 핏을 추가한 4가지의 클래스의 경우 81.59%, 청바지의 색상은 93.91%, 청바지의 Washing은 91.20%, 청바지의 Demgae는 92.96%의 정확도를 도출하였다.",다국어 초록 정보 없음
소나무 재선충 탐지를 위한 U-NET모델과 Mask R-CNN모델의 정사영상 비교분석,2022,"['Pine Wilt', 'U-NET Model', 'Mask R-CNN Model', 'Orthophoto Imagery', 'Training Data', '소나무재선충', 'U-NET모델', 'Mask R-CNN모델', '정사영상', '학습데이터']","본 연구는 소나무재선충 탐지를 위해 딥러닝 모델인 U-NET 모델과 Mask R-CNN 모델을 이용하여 소나무 재선충 피해지역을 분석한 후 탐지능력을 비교해 보았다. 이를 위해 먼저 소나무재선충 피해대상지를 선정하고 드론 촬영 후 정사영상을 획득하였다. 딥러닝을 위한 학습데이터로는 시계열별 2,123개의 소나무재선충 정사영상 자료를 사용하였다. 검증을 위한 참값자료는 연구대상지의 고사목 제거 위치데이터를 사용하였다. 분석 결과 U-NET 모델은 재현율 96.6% 정밀도 80.2%를 얻었으며, Mask R-CNN 모델은 재현율 86.4% 정밀도 75.0%를 얻었다. 이것은 영상의 해상도 차이, 블러닝과 비네팅 현상, 수목 종류, 계절에 따른 단풍과 잎사귀의 갈변 등으로 인한 것이며, 각 지역별 수목의 특징과 산림환경에 적합한 다양한 학습데이터를 학습시킨다면 딥러닝의 탐지능력은 향상될 것이라 판단된다.","This study compared the detection capabilities of the two deep learning models (U-NET model and the Mask R-CNN model) in Pine wilt disease damaged area through image analysis on the basis of orthophoto imagery. To this end, we obtained the 2,123 time-series imageries of damaged pine trees by Pine wilt disease for training data. The location data of cleared pine trees in the study site was used as the reference data to verify models. As a result of the analysis, the U-NET model obtained a recall rate of 96.6% and an accuracy of 80.2%, and the Mask R-CNN model obtained a recall rate of 86.4% and an accuracy of 75.0%. This is due to differences in image resolution, browning and vignette phenomena, tree types, seasonal autumn leaves and browning of leaves, etc., and learning various learning data suitable for the characteristics of trees and forest environment in each region. Then, it is judged that the detection ability of deep learning is improved."
CNN 아키텍쳐 기반 인공 고관절 판독 모델 성능 비교 연구,2022,"['THRA', 'Medical image processing field', 'Patient information', 'Anonymization', 'Binarization work', 'CNN-based architecture']","최근, 고관절 전치환술의 진행에 있어, 제조사마다 규격이 다른 인공관절의 특성으로 인해 과거에 삽입했던 제품과 호환되는 제품을 반드시 사용해야 하는 고질적인 문제점이 있다. 이런 문제를 해결하기 위해 집도의는 수술에 들어가기 전에 X-Ray이미지를 보고 경험치료를 바탕으로 가장 비슷한 인공 보철물을 준비한다. 이러한 준비 과정은 의사의 경험에 따라 오차가 발생할 위험이 있다. 이에 따라 전 세계의 많은 고관절 인공 보철물 제조사는 자사의 데이터를 활용하여 인공 보철물 제품군의 이미지 판독 시스템의 개발이 활발히 이루어지고 있는 추세이다. 따라서 본 연구는 의료영상처리분야에서 시각 정보에 기반한 고차원적 추상화를 통한 병변 진단 및 예후 예측에 뛰어나 성능을 보이는 CNN(Convolutional Neural Network)기반의 다양한 아키텍처 모델들의 성능을 비교한다. 연구방법은 다음과 같다. 국내 유일의 인공고관절 제조업체인 ㈜코렌텍에서 제공한 자사 제품이 사용된 X-Ray 이미지와 Kaggle 데이터셋 ‘Aseptic Loose Hip Implant X-Ray Database’을 활용한다. 이때 사용되는 X-Ray 이미지는 환자 정보에 대한 비식별화가 된 상태이다. 습득한 X-Ray 이미지는 인공 보철물이 나타난 부분을 뜯어내 배경을 제거한 후 이진화 작업, 특정 영역 외 객체 제거, 이미지 반전 등 데이터 전처리 작업을 거치고, 전처리된 데이터셋을 이진 분류모델에 맞게 변환한다. 이후 CNN기반의 다양한 아키텍처 모델에 적용하여 각 모델에 대한 성능을 비교한다. 성능비교에 사용한 CNN기반 모델은 CNN, VGG16, GoogLe Net/Inception Net, Xception Net, Mobile Net, ResNet 총 6개이며, 각 모델에 대한 특징과 연결점에 대해 설명한다.",다국어 초록 정보 없음
CNN을 이용한 Al 6061 압출재의 표면 결함 분류 연구,2022,"['Convolution Neural Network', 'Surface Defect', 'Aluminum alloy', 'Extrusion', 'Deep Learning', 'Data Augmentation']",국문 초록 정보 없음,"Convolution Neural Network(CNN) is a class of deep learning algorithms and can be used for image analysis. In particular, it has excellent performance in finding the pattern of images. Therefore, CNN is commonly applied for recognizing, learning and classifying images. In this study, the surface defect classification performance of Al 6061 extruded material using CNN-based algorithms were compared and evaluated. First, the data collection criteria were suggested and a total of 2,024 datasets were prepared. And they were randomly classified into 1,417 learning data and 607 evaluation data. After that, the size and quality of the training data set were improved using data augmentation techniques to increase the performance of deep learning. The CNN-based algorithms used in this study were VGGNet-16, VGGNet-19, ResNet-50 and DenseNet-121. The evaluation of the defect classification performance was made by comparing the accuracy, loss, and learning speed using verification data. The DenseNet-121 algorithm showed better performance than other algorithms with an accuracy of 99.13% and a loss value of 0.037. This was due to the structural characteristics of the DenseNet model, and the information loss was reduced by acquiring information from all previous layers for image identification in this algorithm. Based on the above results, the possibility of machine vision application of CNN-based model for the surface defect classification of Al extruded materials was also discussed."
CNN 은닉층 증가에 따른 인공지능 정확도 평가: 뇌출혈 CT 데이터,2022,"['인공지능', '컨볼루션 신경망', '은닉층', '전산화단층촬영', '뇌출혈', 'AI', 'CNN', 'hidden layer', 'Computed Tomography', 'Cerebral Hemorrhage']",딥러닝은 다량의 데이터 속에서 핵심적인 내용을 요약해 학습하는 알고리즘의 집합으로 의료영상 분야에서 병변을 진단하는 목적으로 사용되기 위해 발전하고 있다. 본 논문에서는 뇌출혈 진단 정확성을 평가하기 위해 CNN을 이용해 뇌실질 CT 영상과 뇌출혈이 의심되는 뇌실질 CT의 진단 정확도를 도출하였다. 은닉층 수에 따른 정확도를 비교한 결과 은닉층이 증가할수록 정확도가 높아졌다. 본 연구에서 도출된 CT 뇌출혈 유무 분석 결과는 앞으로 의료영상 분야와 인공지능 접목에 관한 연구에서 기초 자료로 사용될 것으로 사료된다.,"Deep learning is a collection of algorithms that enable learning by summarizing the key contents of large amounts of data; it is being developed to diagnose lesions in the medical imaging field. To evaluate the accuracy of the cerebral hemorrhage diagnosis, we used a convolutional neural network (CNN) to derive the diagnostic accuracy of cerebral parenchyma computed tomography (CT) images and the cerebral parenchyma CT images of areas where cerebral hemorrhages are suspected of having occurred. We compared the accuracy of CNN with different numbers of hidden layers and discovered that CNN with more hidden layers resulted in higher accuracy. The analysis results of the derived CT images used in this study to determine the presence of cerebral hemorrhages are expected to be used as foundation data in studies related to the application of artificial intelligence in the medical imaging industry."
CNN-LSTM 합성모델에 의한 하수관거 균열 예측모델,2022,"['CNN', 'LSTM', 'Hybrid model', 'Sewer pipe']",국문 초록 정보 없음,"In this paper, we propose a GoogleNet transfer learning and CNN-LSTM combination method to improve the time-series prediction performance for crack detection using crack data captured inside the sewer pipes. LSTM can solve the long-term dependency problem of CNN, so spatial and temporal characteristics can be considered at the same time. The predictive performance of the proposed method is excellent in all test variables as a result of comparing the RMSE(Root Mean Square Error) for time series sections using the crack data inside the sewer pipe. In addition, as a result of examining the prediction performance at the time of data generation, the proposed method was verified that it is effective in predicting crack detection by comparing with the existing CNN-only model. If the proposed method and experimental results obtained through this study are utilized, it can be applied in various fields such as the environment and humanities where time series data occurs frequently as well as crack data of concrete structures."
CNN을 활용한 OLED 디스플레이 결함 검출 시스템 구현,2022,"['machine learning', 'mura', 'AOI', 'CNN', '.']",최근에는 머신러닝 기술이 발전함에 따라 다양한 산업에서 이를 적용한 기술들이 개발되고 있다. 하지만 패널을 생산하는 공정에서는 아직 머신러닝을 결합하여 Mura를 검출하는 방법이 보편화되어 있지 않다. 현재 생산 공정에서 주로 사용되고 있는 AOI(Automated Optical Inspection) 기법은 사전에 입력된 Mura를 검출하는데 효과적이지만 새로운 Mura가 입력되면 검출하지 못하는 문제가 발생한다. 본 논문에서는 이러한  문제를 해결하기 위해 CNN(Convolutional Neural Networks)을 이용한 Mura 검출 시스템을 구현하였다. 패널의 이미지 데이터들은 29M 카메라와 Frame Grabber를 이용하여 수집하고 총 5단계로 구성된 데이터 가공 기법을 적용하여 정형화된 데이터를 생성하였다. 이후 생성된 데이터들을 CNN 모델의 입력으로 사용하여 Mura 검출을 수행하였다. 실험 결과 50개의 테스트 데이터에서 100%의 정확도를 얻을 수 있었다.,"Recently, as machine learning technology develops, technologies applying it are being developed in various industries. However, in the process of producing panels, Mura detecting method using machine learning is not yet common. The AOI(Automated Optical Inspection) technique, which is mainly used in the current production process, is effective in detecting typical mura pattern, but has a problem not detecting when a new mura pattern. In this paper, we implemented a mura detection system using CNN(Convolutional Neural Networks) to solve this problem. The image data of the panel was collected using a 29M camera and a frame grabber, and standardized data was generated by applying a data processing technique consisting of a total of 5 steps. Then, This generated data is used for CNN model for Mura detection. As a result, we confirmed the 100% accuacy Mura detection for 50 test data."
CNN 기반 지문분류 연구 동향,2022,"['Fingerprint Classification', 'Pattern Recognition', 'Feature Extraction', 'CNN', 'Deep Learning', '지문분류', '패턴 인식', '특징추출', '합성곱 신경망', '딥러닝']",국문 초록 정보 없음,"Recently, various researches have been made on a fingerprint classification method using Convolutional Neural Networks (CNN), which is widely used for multidimensional and complex pattern recognition such as images. The CNN-based fingerprint classification method can be executed by integrating the two-step process, which is generally divided into feature extraction and classification steps. Therefore, since the CNN-based methods can automatically extract features of fingerprint images, they have an advantage of shortening the process. In addition, since they can learn various features of incomplete or low-quality fingerprints, they have flexibility for feature extraction in exceptional situations. In this paper, we intend to identify the research trends of CNN-based fingerprint classification and discuss future direction of research through the analysis of experimental methods and results."
단백질 기능 예측 문제에서 시퀀스 패턴 추출을 위한 작은 CNN-RNN 접목 모델 연구,2022,"['PSSM', 'Deep learning', 'Protein Function Prediction', 'Feature Engraft Model', 'Overlapped R', 'PSSM', '딥러닝', '단백질 기능 예측', '특징 접목 모델', '중첩 RNN']","본 논문에서는 2020년 기준 단백질 서열을 이용한 기능과 구조 예측 분야에서 가장 많이 사용되고있는 딥러닝 모델인 CNN과 LSTM/GRU 모델을 동일한 조건 하에 비교 평가한 연구를 토대로 새로운효소 기능 예측 모델인 PSCREM을 설계하였다. CNN 합성곱 시 누락되는 세부 패턴을 보존하기 위하여서열 진화정보를 이용하였으며 중첩 RNN을 통해 기능적으로 중요한 의미를 가지는 아미노산 간의관계 정보를 추출하고 특징 맵 제작에 참조하였다. 사용된 RNN 계열의 알고리즘은 LSTM과 GRU로보통 stacked RNN 기법으로 100 units 이상 2~3회 쌓는 것이 일반적이나 본 논문에서는 10, 20 unit으로구성한 뒤 중첩시켜서 특징 맵 제작에 사용하였다. 모델에 들어가는 데이터는 단백질 서열 데이터로PSSM profile로 가공한 뒤 사용되었다. 실험 결과 효소 번호 첫 번째 자리를 예측하는 문제에 대해86.4%의 정확도를 나타냄을 입증하였고, 효소 번호 3번째 자리까지 예측 정확도 84.4%의 성능을 내는것을 확인하였다. PSCREM은 Overlapped RNN을 통해 단백질 기능에 관련된 고유 패턴을 더 잘 파악하며Overlapped RNN은 단백질 기능 및 구조 예측 추출 분야에 새로운 방법론으로서 제안된다.","In this paper, we designed a new enzyme function prediction model PSCREM based on a study that compared and evaluated CNN and LSTM/GRU models, which are the most widely used deep learning models in the field of predicting functions and structures using protein sequences in 2020, under the same conditions. Sequence evolution information was used to preserve detailed patterns which would miss in CNN convolution, and the relationship information between amino acids with functional significance was extracted through overlapping RNNs. It was referenced to feature map production. The RNN family of algorithms used in small CNN-RNN models are LSTM algorithms and GRU algorithms, which are usually stacked two to three times over 100 units, but in this paper, small RNNs consisting of 10 and 20 units are overlapped. The model used the PSSM profile, which is transformed from protein sequence data. The experiment proved 86.4% the performance for the problem of predicting the main classes of enzyme number, and it was confirmed that the performance was 84.4% accurate up to the sub-sub classes of enzyme number. Thus, PSCREM better identifies unique patterns related to protein function through overlapped RNN, and Overlapped RNN is proposed as a novel methodology for protein function and structure prediction extraction."
GAN 오버샘플링 기법과 CNN-BLSTM 결합 모델을 이용한 부정맥 분류,2022,"['Arrhythmia', 'CNN', 'GAN', 'BLSTM', 'MIT-BIH', '부정맥', '합성곱 신경망', '적대적 생성 신경망', '양방향 장단기 기억 신경망', 'MIT-BIH']","부정맥이란 심장이 불규칙한 리듬이나 비정상적인 심박동수를 갖는 것을 말하며, 뇌졸중, 심정지 등을 유발하거나 사망에도 이를 수 있는 만큼, 조기 진단과 관리가 무엇보다 중요하다.본 연구에서는 심전도 신호의 QRS 특징 추출에 적합한 CNN과 기존 LSTM의 직전 패턴의 수렴 한계를 해결할 수 있는 BLSTM을 연결한 CNN-BLSTM 결합 모델을 이용한 부정맥 분류 방법을 제안한다. 이를 위해 먼저 전처리 과정을 통해 잡음을 제거한 심전도 신호에서 QRS 특징점을 검출하고 단일 비트 세그먼트를 추출하였다. 이때 데이터의 불균형 문제를 해결하기 위해 GAN 오버샘플링 기법을 적용하였다. 이 후 합성곱 계층을 통해 부정맥 신호의 패턴을 정밀하게 추출하도록 구성하고 이를 BLSTM의 입력으로 사용한 후 매개변수를 학습시키고 검증 데이터로 학습 모델을 평가한 후 부정맥 분류의 정확도를 확인하였다. 제안한 방법의 우수성을 입증하기 위해 MIT-BIH 부정맥 데이터베이스를 이용하여 분류의 정확도, 정밀도, 재현율, F1-score를 비교하였다. 성능평가 결과 각각 99.30%, 98.70%, 97.50%, 98.06%로 우수한 분류율을 나타내는 것을 확인할 수 있었다.","Arrhythmia is a condition in which the heart has an irregular rhythm or abnormal heart rate, early diagnosis and management is very important because it can cause stroke, cardiac arrest, or even death.In this paper, we propose arrhythmia classification using hybrid combination model of CNN-BLSTM. For this purpose, the QRS features are detected from noise removed signal through pre-processing and a single bit segment was extracted. In this case, the GAN oversampling technique is applied to solve the data imbalance problem. It consisted of CNN layers to extract the patterns of the arrhythmia precisely, used them as the input of the BLSTM. The weights were learned through deep learning and the learning model was evaluated by the validation data. To evaluate the performance of the proposed method, classification accuracy, precision, recall, and F1-score were compared by using the MIT-BIH arrhythmia database. The achieved scores indicate 99.30%, 98.70%, 97.50%, 98.06% in terms of the accuracy, precision, recall, F1 score, respectively."
생산 공정에서 CNN을 이용한 음향 PSD 영상 기반 공구 상태 진단 기법,2022,"['공구 상태 진단', '전력스펙트럼밀도', '합성곱신경망', '가공 공정', '음향 신호', 'Tool Condition Monitoring', 'PSD(Power Spectral Density)', 'CNN(Convolution Neural Network)', 'Machining Process', 'Sound Signal']","정보통신기술(ICT)를 적용한 스마트팩토리로 불리는 지능형 생산 공장은 각종 센서를 통해 공정 데이터를 실시간으로 수집하고 있다. 이렇게 수집된 데이터를 효과적으로 활용하는 연구가 많이 진행되고 있는데, 본 논문에서는 생산 공정에서 발생되는 음향 신호를 기반으로 공구 상태를 진단하는 기법을 제안한다. 첫 번째로 결함이 있는 공구를 감지할 뿐만 아니라 공회전 및 공정 운용에 따른 다양한 공구 상태를 제시한다. 두 번째로 푸리에 분석을 이용하여 사운드의 전력스펙트럼을 영상으로 표현하고, 데이터에 숨겨진 건강한 패턴을 드러내고, 강조하기 위해 일부 변형을 적용한다. 마지막으로 이렇게 획득한 대비 강화된 PSD 영상은 CNN을 이용해 상태별로 진단한다. 그 결과 제안한 음향 PSD 영상 + CNN 방법은 데이터의 차별화된 특징이 잘 반영되어 공구 상태에 따른 높은 진단 결과를 보여준다.","The intelligent production plant called smart factories that apply information and communication technology (ICT) are collecting data in real time through various sensors. Recently, researches that effectively applying to these collected data have gained a lot of attention. This paper proposes a method for the tool condition monitoring based on the sound signal generated in machining process. First, it not only detects a fault tool, but also presents various tool states according to idle and active operation. The second, it's to represent the power spectrum of the sounds as images and apply some transformations on them in order to reveal, expose, and emphasize the health patterns that are hidden inside them. Finally, the contrast-enhanced PSD image obtained is diagnosed by using CNN. The results of the experiments demonstrate the high discrimination potential afforded by the proposed sound PSD image + CNN and show high diagnostic results according to the tool status."
GAN 오버샘플링 기법과 CNN-BLSTM 결합 모델을 이용한 부정맥 분류,2022,[],"부정맥이란 심장이 불규칙한 리듬이나 비정상적인 심박동수를 갖는 것을 말하며, 뇌졸중, 심정지 등을 유발하거나 사망에도 이를 수 있는 만큼, 조기 진단과 관리가 무엇보다 중요하다. 본 연구에서는 심전도 신호의 QRS 특징 추출에 적합한 CNN과 기존 LSTM의 직전 패턴의 수렴 한계를 해결할 수 있는 BLSTM을 연결한 CNN-BLSTM 결합 모델을 이용한 부정맥 분류 방법을 제안한다. 이를 위해 먼저 전처리 과정을 통해 잡음을 제거한 심전도 신호에서 QRS 특징점을 검출하고 단일 비트 세그먼트를 추출하였다. 이때 데이터의 불균형 문제를 해결하기 위해 GAN 오버샘플링 기법을 적용하였다. 이 후 합성곱 계층을 통해 부정맥 신호의 패턴을 정밀하게 추출하도록 구성하고 이를 BLSTM의 입력으로 사용한 후 매개변수를 학습시키고 검증 데이터로 학습 모델을 평가한 후 부정맥 분류의 정확도를 확인하였다. 제안한 방법의 우수성을 입증하기 위해 MIT-BIH 부정맥 데이터베이스를 이용하여 분류의 정확도, 정밀도, 재현율, F1-score를 비교하였다. 성능평가 결과 각각 99.30%, 98.70%, 97.50%, 98.06%로 우수한 분류율을 나타내는 것을 확인할 수 있었다.","Arrhythmia is a condition in which the heart has an irregular rhythm or abnormal heart rate, early diagnosis and management is very important because it can cause stroke, cardiac arrest, or even death. In this paper, we propose arrhythmia classification using hybrid combination model of CNN-BLSTM. For this purpose, the QRS features are detected from noise removed signal through pre-processing and a single bit segment was extracted. In this case, the GAN oversampling technique is applied to solve the data imbalance problem. It consisted of CNN layers to extract the patterns of the arrhythmia precisely, used them as the input of the BLSTM. The weights were learned through deep learning and the learning model was evaluated by the validation data. To evaluate the performance of the proposed method, classification accuracy, precision, recall, and F1-score were compared by using the MIT-BIH arrhythmia database. The achieved scores indicate 99.30%, 98.70%, 97.50%, 98.06% in terms of the accuracy, precision, recall, F1 score, respectively."
EMD-CNN-LSTM을 이용한 하이브리드 방식의 리튬 이온 배터리 잔여 수명 예측,2022,"['Remaining useful life', 'Deep learning', 'Convolution neural network', 'Long short term memory', 'Empirical mode decomposition']",국문 초록 정보 없음,"This paper proposes a battery remaining useful life (RUL) prediction method using a deep learning-based EMD–CNN–LSTM hybrid method. The proposed method pre-processes capacity data by applying empirical mode decomposition (EMD) and predicts the remaining useful life using CNN-LSTM. CNN–LSTM is a hybrid method that combines convolution neural network (CNN), which analyzes spatial features, and long short term memory (LSTM), which is a deep learning technique that processes time series data analysis. The performance of the proposed remaining useful life prediction method is verified using the battery aging experiment data provided by the NASA Ames Prognostics Center of Excellence and shows higher accuracy than does the conventional method."
CNN에서 입력 최댓값을 이용한 SoftMax 연산 기법,2022,"['CNN', 'SoftMax', 'Accelerator', 'Exponential function']",국문 초록 정보 없음,"A convolutional neural network(CNN) is widely used in the computer vision tasks, but its computing power requirement needs a design of a special circuit. Most of the computations in a CNN can be implemented efficiently in a digital circuit, but the SoftMax layer has operations unsuitable for circuit implementation, which are exponential and logarithmic functions. This paper proposes a new method to integrate the exponential and logarithmic tables of the conventional circuits into a single table. The proposed structure accesses a look-up table (LUT) only with a few maximum values, and the LUT has the result value directly. Our proposed method significantly reduces the space complexity of the SoftMax layer circuit implementation. But our resulting circuit is comparable to the original baseline with small degradation in precision."
CNN을 이용한 실내가구 인테리어배치 AR알고리즘 모델링에 대한 연구,2022,"['3D Scanning', 'AR Labeling', 'Interior', 'Furniture', 'CNN', '3D 스캐닝(Scanning)', 'AR 레이블링(Labeling)', '인테리어(Interior)', '가구(Furniture)', 'CNN']","본 논문에서는 증강현실 기술을 적용하여 실내 가구 인테리어를 배치하는데 작업의 효율성을 높일수 있는 모델을 연구하였다. 현재 증강현실을 적용한 기존 시스템에서는 가구의 이미지를 출력할 때기업 제품의 규모와 성격 등에 따라 정보가 제한적으로 제공되는 문제가 있다. 이러한 문제점을 해결하기위해 본 논문에서는 AR 레이블링 알고리즘을 제시하였다. AR 레이블링 알고리즘은 촬영된 이미지에서특징점을 추출하고 실내 위치 정보를 포함한 데이터베이스를 구축하였다. CNN 기법을 활용하여 실내공간에서 가구의 위치 데이터를 검출해 학습시키는 방법을 채택하였다. 학습한 결과를 통해 실내 위치와학습시켜 나타낸 위치와의 오차를 현저히 낮출 수 있다는 것을 확인한다. 또한 가구의 정확한 이미지추출과 함께 가구에 대한 상세한 정보를 받아 사용자가 원하는 가구들을 증강현실을 통해 쉽게 배치할수 있도록 하는 연구를 진행하였다. 연구 결과 모델의 정확도와 손실률이 99%, 0.026으로 나타나 신뢰성을확보하여 본 연구가 유의미함을 알 수 있었다. 본 연구 결과는 AR 레이블의 설계, 구현을 통해 원하는가구들을 실내에 정확히 배치하여 소비자의 만족도와 구매 욕구를 충족시킬 수 있을 것으로 기대된다.","In this paper, a model that can increase the efficiency of work in arranging interior furniture by applying augmented reality technology was studied. In the existing system to which augmented reality is currently applied, there is a problem in that information is limitedly provided depending on the size and nature of the company's product when outputting the image of furniture. To solve this problem, this paper presents an AR labeling algorithm. The AR labeling algorithm extracts feature points from the captured images and builds a database including indoor location information. A method of detecting and learning the location data of furniture in an indoor space was adopted using the CNN technique. Through the learned result, it is confirmed that the error between the indoor location and the location shown by learning can be significantly reduced. In addition, a study was conducted to allow users to easily place desired furniture through augmented reality by receiving detailed information about furniture along with accurate image extraction of furniture. As a result of the study, the accuracy and loss rate of the model were found to be 99% and 0.026, indicating the significance of this study by securing reliability. The results of this study are expected to satisfy consumers' satisfaction and purchase desires by accurately arranging desired furniture indoors through the design and implementation of AR labels."
홍수 위험도 판별을 위한 CNN 기반의 분류 모델 구현,2022,"['DNN', 'K-Means Clustering', '시계열 데이터', '위험도 판별', '홍수', 'DNN', 'K-Means Clustering', 'Time series data', 'Flood Risk Determination', 'Flood']","지구온난화 및 이상 기후로 인해 홍수의 빈도 및 피해 규모가 늘어나고 있으며,  홍수 취약 지역에 노출된 사람이 2000년도에 비하여 25% 증가하였다. 홍수는 막대한 금전적, 인명적 손실을 유발하며, 홍수로 인한 손실을 줄이기 위해 홍수를 미리 예측하고 빠른 대피를 결정해야 한다. 본 논문은 홍수 예측을 위한 핵심 데이터인 강우량과 수위 데이터를 활용하여 시기적절한 대피 결정이 이루어질 수 있도록 CNN기반 분류 모델을 활용하여 홍수 위험도 판별 모델을 제안한다. 본 논문에서 제안한 CNN 기반 분류 모델과 DNN 기반의 분류 모델의 결과를 비교하여 더 좋은 성능을 보이는 것을 확인하였다. 이를 통해 홍수의 위험도를 판별하여, 대피 여부 판단하며 최적의 시기에 대피 결정을 내릴 수 있도록 하는 초기 연구로서 활용할 수 있을 것으로 사료된다.","Due to global warming and abnormal climate, the frequency and damage of floods are increasing, and the number of people exposed to flood-prone areas has increased by 25% compared to 2000. Floods cause huge financial and human losses, and in order to reduce the losses caused by floods, it is necessary to predict the flood in advance and decide to evacuate quickly. This paper proposes a flood risk determination model using a CNN-based classification model so that timely evacuation decisions can be made using rainfall and water level data, which are key data for flood prediction. By comparing the results of the CNN-based classification model proposed in this paper and the DNN-based classification model, it was confirmed that it showed better performance. Through this, it is considered that it can be used as an initial study to determine the risk of flooding, determine whether to evacuate, and make an evacuation decision at the optimal time."
UAV 영상 기반의 Faster R-CNN 기법을 활용한 샌드위치패널 지붕탐색,2022,"['무인항공기', 'Faster R-CNN', '샌드위치패널', '객체 탐지 알고리즘', 'UAV Image', 'Faster R-CNN', 'Sandwich Panel', 'Object Detection Algorithms']","우리나라 건축물 중 샌드위치패널(조립식판넬) 건축물은 건축시장에서 선호되지만 화재에 취약한 건축자재로 분류된다. 샌드위치패널(조립식판넬) 건물의 화재는 화재의 빠른 확산으로 인해 짧은 시간에 대형 화재로 이어질 가능성이 높으며, 다른 건물에 비해 인명 및 재산 피해의 주요 원인이 되는 건물 붕괴 위험이 높다. 화재로 인한 인명 및 재산 피해를 방지하기 위해서는 화재에 취약한 건축물에 대한 관리가 절실히 필요한 실정이다. 따라서 본 연구에서는 항공사진보다 영상 획득이 용이한 무인항공기(UAV)와 최근 활발히 활용되고 있는 CNN의 객체 탐지 알고리즘을 결합하여 화재에 취약 건물의 지붕을 탐색하고 분류하는 방법을 제안하였다. 구체적으로, UAV로 촬영한 영상에서 화재가 발생하기 쉬운 지붕을 탐색 및 분류할 때 다양한 촬영 고도에서 촬영한  UAV 영상을 제작하여 학습 데이터로 활용하고, 또 다른 학습 데이터와 비교하여 화재 취약 건물 지붕을 감지하기 위한 최적의 조건을 찾는 것이다.","Among the buildings in Korea, sandwich panel buildings are classified as building materials that are preferred in the building market but vulnerable to fire. The fire in the sandwich panel building is likely to lead to large fires in a short time due to the fast spread of fire and the risk of building collapse is considerable compared to other buildings, which is the main cause of human and property damage. In order to prevent human and property damage from fire, management of buildings vulnerable to fire is desperately needed. Therefore, in this work, we proposed a method to explore and classify the roofs of vulnerable buildings in fire by combining unmanned aerial vehicles (UAV) that are easier to obtain images than aerial photographs and CNN's recently actively utilized object detection algorithms. Specifically, when exploring and classifying fire-prone roofs from images taken with UAV, the objective is to build and use images taken at various shoot elevations as learning data, and to find optimal conditions for detecting roofs of buildings by comparing results when another learning data is added to learning data."
웨이블릿 변환 기반 CNN을 활용한 무선 신호 분류,2022,"['Convolutional neural network', 'Signal classification', 'F1-score', 'Transfer learning', 'Wavelet transform', '합성곱 신경망', '신호 분류', 'F1-스코어', '전이 학습', '웨이블릿 변환']","다양한 변조 기법을 사용하여 저피탐 능력을 갖춘 신호원들이 증가하면서, 신호의 변조 방식을 분류하는 연구가 꾸준히 진행되고 있다. 최근 신호 간섭이나 잡음 환경에서 수신 신호 분류의 성능 개선을 위하여 전처리 과정으로 FFT를 이용하는 CNN(Convolutional Neural Network) 딥러닝 기법이 제안되었다. 하지만 윈도우가 고정되는 FFT의 특성상 탐지 신호의 시간에 따른 변화를 정확히 분류해내지 못한다. 따라서 본 논문에서는 시간 영역과 주파수 영역에서 높은 해상도를 가지고 또한 다양한 유형의 신호를 시간 및 주파수 영역에서 동시에 표현할 수 있는 웨이블릿 변환(wavelet transform)을 전처리 과정으로 사용하는 CNN 모델을 제안한다. 시뮬레이션을 통해 제안하는 웨이블릿 변환 방식이 FFT 변환 방식에 비해 정확도와 학습 속도 측면에서 SNR 변화에 무관하게 우수한 성능을 보이고, 특히 낮은 SNR일 때 더욱 큰 차이를 보임을 입증하였다.","As the number of signal sources with low detectability by using various modulation techniques increases, research to classify signal modulation methods is steadily progressing. Recently, a Convolutional Neural Network (CNN) deep learning technique using FFT as a preprocessing process has been proposed to improve the performance of received signal classification in signal interference or noise environments. However, due to the characteristics of the FFT in which the window is fixed, it is not possible to accurately classify the change over time of the detection signal. Therefore, in this paper, we propose a CNN model that has high resolution in the time domain and frequency domain and uses wavelet transform as a preprocessing process that can express various types of signals simultaneously in time and frequency domains. It has been demonstrated that the proposed wavelet transform method through simulation shows superior performance regardless of the SNR change in terms of accuracy and learning speed compared to the FFT transform method, and shows a greater difference, especially when the SNR is low."
CNN을 사용한 공간 데이터 분류 방법,2022,"['CNN', 'spatial data', 'shapefile', 'VGG16', 'transfer learning', '.']","본 논문에서는 모바일 환경, 디지털 트윈 등의 기반 기술로서 중요성이 증대되고 있는 공간 데이터를 딥러닝 기술을 사용하여 분류하기 위한 방법을 제안한다. 공간 데이터 분류를 위한 딥러닝 기술로는 CNN을 사용한다. 학습을 위한 데이터셋은 공간 데이터를 전처리하여 구축한다. 데이터셋을 훈련 및 검증하기 위한 학습 모델은 컨볼루션 레이어와 완전 연결 레이어로 구성한다. 컨볼루션 레이어는 VGG16의 컨볼루션 레이어를 채택하고 전이 학습을 사용한다. 완전 연결 레이어는 Flatten 레이어, ReLU 함수, Dropout 레이어, Softmax 함수로 구성한다. 본 논문에서 제안한 공간 데이터 분류 방법을 연속수치지형도에 대해 적용한 실험을 수행하여 99.1%의 검증 정확도를 확인할 수 있었다.","This paper proposes a method for classifying spatial data, which is increasingly important as a base technology for mobile environments and digital twins, using deep learning technology. CNN is used as a deep learning technology for spatial data classification. A dataset for learning is constructed by preprocessing spatial data. The learning model for training and validating the dataset consists of a convolution layer and a fully connected layer. The convolution layer adopts the convolution layer of VGG16 and uses transfer learning. The fully connected layer consists of a Flatten layer, a ReLU function, a Dropout layer, and a Softmax function. An experiment in which the spatial data classification method proposed in this paper was applied to Korea national map was performed, and verification accuracy of 99.1% was obtained."
CNN을 활용한 MMTIC 성격분석 예측,2022,[],"청소년의 성격유형을 분석할 때 소셜미디어 데이터를 활용하여 텍스트 처리로 분석하는 연구는 많이 알려져 있다. 그러나 이미지를 사용하여 성격유형을 분석한 연구는 미비하다. 본 연구는 청소년의 발테그 그림검사로 표현된 이미지를 데이터로 사용하고, CNN을 활용하여 MMTIC의 16가지 청소년의 성격유형을 예측한다. 연구 대상은 중학교 재학생을 대상으로 한다. MMTIC에서 U-band를 제외한 340명의 학생으로 2012년 4월부터 2013년 3월까지 조사하였다. 연구 결과 CNN을 사용하였을 때 21.6% 예측율을 보였으며, CNN Ensemble을 적용하였을 때 23.1%로 2.5%가 증가한다.",다국어 초록 정보 없음
Opcode 빈도수 기반 악성코드 이미지를 활용한 CNN 기반 악성코드 탐지 기법,2022,"['Machine Learning', 'Convolution Neural Network', 'Clustering', 'Malware Detection']","인터넷이 발달하고 컴퓨터 이용률이 높아짐에 따라 악성코드로 인한 위협 또한 함께 증가하고 있다. 매년 발견되는 악성코드의 수는 급격히 증가하여 자동으로 대량의 악성코드를 분석하기 위한 시스템이 필요한 상황이다. 본 논문에서는 딥러닝 알고리즘을 활용한 악성코드 자동 분석 기법을 소개한다. CNN(Convolutional Neural Network)라는 이미지 분류에 활용도가 높은 알고리즘을 이용하여 악성코드의 특징을 이미지화한 데이터를 분석한다. 제안하는 방법은 악성코드의 Semantic한 정보를 탐지에 활용하기 위하여 단순 바이너리 바이트를 기반으로 생성한 이미지가 아닌, 바이너리의 명령어 빈도수를 기반으로 생성한 이미지를 CNN으로 분석한다. 악성코드 10,000개 정상코드 10,000개로 구성된 대량의 데이터 셋을 활용하여 탐지 성능을 확인한 결과, 제안하는 방법은 91%의 정확도로 악성코드를 탐지할 수 있음이 확인되었다.","As the Internet develops and the utilization rate of computers increases, the threats posed by malware keep increasing. This leads to the demand for a system to automatically analyzes a large amount of malware. In this paper, an automatic malware analysis technique using a deep learning algorithm is introduced. Our proposed method uses CNN (Convolutional Neural Network) to analyze the malicious features represented as images. To reflect semantic information of malware for detection, our method uses the opcode frequency data of binary for image generation, rather than using bytes of binary. As a result of the experiments using the datasets consisting of 20,000 samples, it was found that the proposed method can detect malicious codes with 91% accuracy."
CNN을 활용한 웨이퍼 불량 원인 인자 파악에 관한 연구 : 반도체 전공정 중심으로,2022,"['인공지능', 'CNN머신러닝', '불량 웨이퍼', 'AI', 'CNN', 'Machine learning', 'Defected Wafer']","본 연구는 반도체 제조공정에서의 웨이퍼 불량 원인을 조기 감지하고, 예측하는 시스템 구축을 통한 생산성 향상을 목적으로 한다. 연구 방법으로서 파라미터 탐색을 위해 랜덤 포레스트와 라쏘 알고리즘을 사용하였고, 불량 웨이퍼의 원인 공정 학습에는 CNN 알고리즘을 사용했다. 이번 연구에 적용된 신경망 구조는 de-sampling layer 1개, convolution layer 5개, full connected layer 3개, 8개 layer로 최적화하여 적용하였다. 랜덤 포래스트와 라쏘 알고리즘을 통해 Average와 Standard Deviation 차이가 불량 웨이퍼 원인이 되는 파라미터 후보군을 랭킹에 따라 추출하여 중첩되는 파라미터를 주요 원인으로 도출하였다.본 연구의 실증적 성과로는 첫째. 기존의 연구가 단순히 웨이퍼의 불량 패턴에 대한 분류가 대부분이었다면 이번 연구는 반도체 제조공정의 데이터를 사용하여, 적합한 모델 알고리즘 연구를 통하여 전공정에서의 실제 불량의 근본적인 원인이 되는 파라미터를 식별할 수 있었다. 둘째, 원인 공정 및 파라미터를 확보하여 불량 유형의 대상 공정 및 파라미터 축소를 통하여 모델의 학습지능의 정확도가 향상되고, 불량 유형에 대한 추가로 확보한 학습데이터를 가지고 재학습한 결과 학습지능이 향상되는 것을 확인하였다.",다국어 초록 정보 없음
CNN에서 입력 최댓값을 이용한 SoftMax 연산 기법,2022,"['CNN', 'SoftMax', 'Accelerator', 'Exponential function']",국문 초록 정보 없음,"A convolutional neural network(CNN) is widely used in the computer vision tasks, but its computing power requirement needs a design of a special circuit. Most of the computations in a CNN can be implemented efficiently in a digital circuit, but the SoftMax layer has operations unsuitable for circuit implementation, which are exponential and logarithmic functions. This paper proposes a new method to integrate the exponential and logarithmic tables of the conventional circuits into a single table. The proposed structure accesses a look-up table (LUT) only with a few maximum values, and the LUT has the result value directly. Our proposed method significantly reduces the space complexity of the SoftMax layer circuit implementation. But our resulting circuit is comparable to the original baseline with small degradation in precision."
CNN-LSTM 혼합모델을 이용한 비행상태 예측 기법,2022,"['UAV(무인항공기)', 'UAM(도심형 항공 이동 수단)', 'CNN(합성곱 신경망)', 'LSTM(장단기 메모리)']","최근 차세대 운송시스템으로 주목받고 있는 UAM 분야에서 무인항공기 활용을 위한 기술 개발이 활발히 진행되고 있다. 이러한 기술이 적용된 무인항공기는 주로 도심에서 운용되기 때문에 추락사고를 예방하는 것이 중요하다. 그러나 충돌이 발생되는 무인항공기는 비선형성이 강하기 때문에 비정상 비행 상태를 예측하는 것은 쉽지 않은 일이다. 본 논문에서는 CNN-LSTM 혼합모델을 이용하여 무인항공기의 비행상태를 예측하는 방법을 제안한다. 제안 모델은 비행 데이터간의 시간적, 공간적 특징을 추출하는 CNN 모델과 추출된 특징의 장단기 시간 의존성을 추출하는 LSTM 모델을 결합하여 미래의 특정 시점에서 비행 상태변수를 예측한다. 모의 실험은 제안하는 방법이 기존 인공신경망 모델에 기반한 예측 방법보다 우수한 성능을 보인다.",다국어 초록 정보 없음
다양한 CNN모델을 사용한 컬러 콘택트렌즈 불량 검출,2022,"['컬러 콘택트렌즈', '딥러닝', 'ResNet', 'GoogLeNet', 'DenseNet', 'MobileNet', 'Contact Lens', 'Deep Learning', 'ResNet', 'GoogLeNet', 'DenseNet', 'MobileNet']","4차 산업혁명과 함께 디지털 전환(Digital Transformation, DX) 기술이 중요해지고 있다. 이와 함께 인공지능을 통한 생산공정에서의 불량 검출 및 분류에 대한 연구가 활발히 이루어지고 있다. 본 논문에서는 다양한 CNN 모델을 사용하여 컬러 콘택트렌즈 생산공정에서 발생하는 불량 검출을 효과적으로 수행하는 모델을 선정하고자 하며, 이를 통해 생산 및 품질의 향상을 이루어, 자원의 낭비와 소비자의 안전을 확보하고자 한다. 이를 위해 컬러 콘택트렌즈 영상에 대한 전처리와 증강을 통해 학습 및 검증  데이터를 생성하였으며, RGB 및 HSV 채널 영상에 대해 ResNet101, GoogLeNet V2, GoogLeNet V4, DenseNet121, MobileNet의 CNN 기법을 활용하여 RGB와 HSV 채널별로 불량 탐지율 비교 분석하였다. 위 모델의 정확도는 순서대로 각각 89.74%, 84.46%, 95.43%, 82.80%, 89.74%로, RGB 채널의 GoogLeNet V4가 가장 높은 불량 검출 정확도를 얻었으며, 대부분의 모델에서 RGB 채널이 HSV 채널보다 더 좋은 결과를 얻어냄을 알 수 있었다.","The importance of Digital Transformation (DX) technology has increased with the Fourth Industrial Revolution. At the same time, research on defect detection and classification in the production process through artificial intelligence has been actively applied. In this paper, we select a model that effectively detects defects that occur in the production process of color contact lenses using various models, secure reducing resource waste and consumer safety by improving production and quality. For this purpose, data for training and validation were generated through preprocessing and augmentation of color contact lens images, using CNN technologies such as ResNet101, GoogLeNet V2, GoogLeNet V4, DenseNet121, MobileNet compared and analyzed the defect detection rate for each RGB channel and HSV channel. The accuracies of the above models are 89.74%, 84.46%, 95.43%, 82.80%, and 89.74% respectively, with GoogLeNet V4 on the RGB channel having the highest defect detection accuracy, and in most models, the RGB channel is higher than the HSV channel."
1D CNN을 이용한 이미지 기반의 진동 신호 측정 및 보정,2022,"['Image Processing', 'Camera', 'Quadcopter', 'Vibration Signal', 'Convolution Neural Networks', '영상 처리', '카메라', '쿼드콥터', '진동 신호', '합성곱 신경망']","가속도 센서 기반의 진동 모니터링은 과거부터 구조물의 안전 측정 용도로 널리 사용되어 왔다. 최근 비접촉 촬영 카메라 기반의 진동 모니터링 기술이 연구되고 있지만 센서의 추가 설치 비용 문제와 외란이 가해지지 않는 위치의 필요성이 존재한다. 본 연구에서는 앞선 문제들을 해결하기 위해 접촉 촬영 카메라 기반의 진동 신호 추출과 오차 보정을 위한 합성곱 신경망(CNN: convoliution neural network)을 결합한 방법을 제시한다. 접촉 촬영 방식의 카메라를 통해 새로운 카메라의 추가 없이 기존의 카메라를 활용할 수 있도록 한다. 또한, 접촉 촬영 방식의 카메라가 가지고 있는 정확도에 대한 한계점을 오차 보정을 위한 CNN을 통해 해결한다. 제안된 방법론은 쿼드콥터(quadcopter)를 이용한 실험 데이터를 통해 실제 센서에 대해 비교하여 정확도와 성능을 검증하였다.","Vibration monitoring based on an accelerometer has been used in the past to monitor structural health. Recently, vibration monitoring technology based on non-contact shooting cameras have been studied. However, there are certain issues, such as the additional cost for more sensor attachment and the need for a location without disturbance. This study presents a method for solving such problems by combining signal extraction based on a contact shooting camera with a convolution neural network (CNN) for error calibration. Using the contact shooting method, the existing camera can be reused without adding new ones. Additionally, this also makes it possible to overcome the accuracy limits of the contact shooting camera. The suggested methodology was verified by determining the accuracy and performance of a real sensor using the data from the quadcopter experiment."
Real-time sound monitoring using 2D convolutional neural network (CNN) for pig diseases symptoms detection in pig farm,2022,"['Pig', 'smart farming', 'diseases detection', 'sound recognition', 'CNN']",국문 초록 정보 없음,"Monitoring and preventing diseases in livestock is essential for modern farming, and an early warning system may significantly reduce the economic impact of diseased events. Manual monitoring of pigs in a pig farm is time consuming and labor intensive. Automatic monitoring for pig diseases may help to control the spread of infections. The purpose of this research was to identify the signs of sickness in pigs using acoustic monitoring in real-time. Two microphones were installed in the pig farm for automatic sound acquisition. The sound signals were converted into spectrograms by fast fourier transform (FFT) and mel-frequency cepstral coefficients (MFCC) as a characteristic parameter. Using a 2D convolutional neural network (CNN) and features extracted from the spectrogram, we presented a classification approach for real-time application. The conversion of sound inputs into spectrograms made it possible to recognize by the use of CNN. For the real-time detection, the proposed algorithm showed the ability to recognize the sounds of cough, sneezing, scream, and crushing with an overall recognition accuracy of 75.8%, 69.5%, 72.4%, and 71.6%, respectively, and an average F1-score of 81.2%. Future work is needed to enhance sound detection robustness."
정확도 향상을 위한 CNN-LSTM 기반 풍력발전 예측 시스템,2022,"['CNN', 'LSTM', 'Wind power prediction', '풍력발전예측', 'Machine learning', '기계학습']",국문 초록 정보 없음,"In this study, we propose a wind power generation prediction system that applies machine learning and data mining to predict wind power generation. This system increases the utilization rate of new and renewable energy sources. For time-series data, the data set was established by measuring wind speed, wind generation, and environmental factors influencing the wind speed. The data set was pre-processed so that it could be applied appropriately to the model. The prediction system applied the CNN (Convolutional Neural Network) to the data mining process and then used the LSTM (Long Short-Term Memory) to learn and make predictions. The preciseness of the proposed system is verified by comparing the prediction data with the actual data, according to the presence or absence of data mining in the model of the prediction system."
CNN을 이용한 차량용 카메라 이미지센서의 고장진단,2022,"['Machine Learning', 'Image Sensor', 'Failure Diagnostics', 'Failure Mode and Effect Analysis', 'Prognostics and Health Management']","최근 자율주행 기술 개발과 함께 차량 내 카메라 모듈 수가 확대되며 활용 기술이 다양해지고 있다. 차량용 카메라는 여러 가지 노출 환경으로 인해 다양한 종류의 고장이 발생하여 높은 신뢰성이 요구되며, 그중 주변 환경을 영상으로 출력하는 이미지센서의 역할이 중요하다. 전자장비에 PHM을 적용하는 경우 상태를 관찰할 수 있는 센서를 부착하는 과정이 어려워 전기적인 신호 출력 값들을 추출하기가 쉽지 않다. 따라서, 본 연구에서는 차량용 카메라에 대해 FMEA를 적용하여 기능별 잠재적 결함을 분석하고, 센서 부착으로 인해 회로기판에 영향을 주지 않기 위해 이미지를 통해 이미지센서의 상태를 진단하는 딥러닝 모델을 제작하였다. 동영상을 프레임마다 분류해야 하므로 단위 시간당 많은 연산을 처리할 수 있는 CNN의 주요 모델 중 VGGNet을 기반으로 학습을 진행하였고, 전체 데이터를 50%, 25%, 25%로 나누어 각각 Training, Validating, Testing데이터로 사용하였다. 이미지 손상 정도에 따라 고장진단분류 학습결과 Precision, Recall, F1-Score 및 Accuracy는 평균 92.6%의 성능을 확인하였으며, Grad-CAM을 사용하여 모델이 정확하게 학습되었는지 검증하였다. 본 실험에서 사용된 시편의 수가 적어 가속수명시험 적용이 제한되었으며, 충분한 시편의 수와 가속성 검증을 고려한 가속수명시험을 통해 데이터를 수집하면 정확한 수명예측도 가능할 것으로 기대된다.","With the recent development of autonomous driving technology, the number of camera modules in the vehicle is expanding, and the technology to utilize is diversifying. Vehicle cameras require high reliability because of various failures caused by various exposure environments. Among them, the role of an image sensor that outputs the surrounding environment as an image is important. When PHM is applied to electronic devices, extracting the electrical signal output value is problematic because it is difficult to attach a sensor that can observe the state. Therefore, this study applied FMEA to a vehicle camera to analyze potential defects by function. A deep learning model was developed to diagnose the state of the image sensor through images so that the sensor attachment does not affect the circuit board. Because videos have to be classified for each frame, training was conducted based on VGGNet among the main models of CNN that can process many operations per unit of time. The total data was divided into 50%, 25%, and 25% and used as training, validating, and testing data, respectively. As a result of learning the fault diagnosis classification according to the degree of image damage, the performance of precision, recall, F1-Score, and accuracy was 92.6% on average, and the model was verified using Grad-CAM. As the number of samples used in this experiment was small, there was a limit to the application of the accelerated life test. Accurate life prediction may be possible if data are collected through the accelerated life test considering the sufficient number of samples and acceleration verification."
다수 조명의 채널별 융합을 이용한 CNN 기반 머신 비전 분류기,2022,"['Semiconductor', 'Auto Visual Inspection', 'Deep Learning', 'CNN', '.']",국문 초록 정보 없음,.
CNN 기반 온도 변화 예측 모델의 실시간 예측 성능 평가,2022,"['온실', 'CNN', '온도 예측', '실시간 예측']","온실은 작물 재배를 위해 적절한 환경을 조성해 줄 수 있다는 장점이 있지만 이상적인 재배환경을 만들기 위해서는 세심한 관리가 필요하다. 특히 지구 온난화로 인해 폭염이나 폭설과 같은 기상이변이 많이 생기면서 외부 기상변화에 발빠르게 대처를 할 수 있는 온실 제어의 필요성이 증가하고 있다. 최근 인공지능을 이용하여 온실 내외부 기상 데이터를 이용하여 온실 내부 온도 변화를 예측하는 연구들이 제시되어 왔다. 본 연구는 급격하게 변하는 외부기상에 대응하여 온실을 제어하기 위해 온실 내부 온도 변화를 예측하고자 하였다. 인공신경망의 기법중 하나인 convolutional neural network (CNN)을 이용하여 내부온도, 내부습도, 내부 CO2 농도, 외부온도, 외부습도, 일사량, 풍향, 풍속 총 8가지 요인들을 입력으로 하여 30분뒤 온실 내부온도를 예측하는 모델을 개발하였다. 예측모델은 수원에 위치한 서울대학교 부속 농장의 단동형 비닐온실에서 관측된 4월, 11월, 1월의 계절별 데이터를 사용하여 개발하였다. 이후 개발된 모델의 적용성 평가를 위해 2월16일부터 2월21일까지 총 5일동안 실시간으로 예측 성능을 검증하였다. 5일간 예측 모델을 통해 온실 내부 온도를 예측한 결과 실제 온도 측정 값과의 평균제곱근편차(RMSE)의 정확도는 2.2℃의 결과를 보였다. 본 연구에서는 급격하게 변하는 외부기상에 대응하여 온실을 제어하고자 인공신경망 기반의 온실 내부 온도 변화 예측 모델을 개발하였고 실시간 예측 성능을 검토하였다. 추후 연구에서는 예측된 온도를 온실 작동기 제어에 반영한다면 외부기상에 대응하는 온실 제어가 가능할 것으로 예상된다.",다국어 초록 정보 없음
Skeleton Keypoints를 활용한 CNN3D 기반의  버스 승객 승하차 예측모델,2022,"['Pose estimation', 'Action recognition', '자세 추정', '행동 인식']","버스는 대중적으로 많이 이용되는 교통수단이다. 그만큼 승객의 안전관리를 위해 철저한 대비가 필요하다. 하지만 2018년 승차하기 위해 접근하는 노인을 인지하지 못하고 버스가 출발하면서 사망사고가 발생하는 등 안전 시스템이 미흡한 상황이다. 기존에 뒷문 계단 쪽 센서를 통해 끼임 사고를 방지하는 안전 시스템은 있지만, 이러한 시스템은 위 사고처럼 승하차하려는 과정에서 발생하는 사고를 예방하진 못한다. 버스 승객의 승하차 의도를 예측할 수 있다면, 위와 같은 사고를 예방하는 안전 시스템 개발에 도움이 될 것이다. 그러나 승객의 승하차 의도를 예측하는 연구는 부족한 상태이다. 따라서 본 논문에서는 버스에 부착된 카메라 영상에서 UDP-Pose를 통해 승객의 skeleton keypoints를 추출하고, 이를 활용한 1x1 CNN3D 기반의 버스 승객 승하차 의도를 예측하는 모델을 제안한다. 제안한 모델은 승객의 승하차 의도를 예측하는 부분에서 RNN, LSTM 모델보다 약 1~2% 높은 정확도를 보여준다.","Buses are a popular means of transportation. As such, thorough preparation is needed for passenger safety management. However, the safety system is insufficient because there are accidents such as a death accident occurred when the bus departed without recognizing the elderly approaching to get on in 2018. There is a safety system that prevents pinching accidents through sensors on the back door stairs, but such a system does not prevent accidents that occur in the process of getting on and off like the above accident. If it is possible to predict the intention of bus passengers to get on and off, it will help to develop a safety system to prevent such accidents. However, studies predicting the intention of passengers to get on and off are insufficient. Therefore, in this paper, we propose a 1x1 CNN3D-based getting on and off intention prediction model using skeleton keypoints of passengers extracted from the camera image attached to the bus through UDP-Pose. The proposed model shows approximately 1~2% higher accuracy than the RNN and LSTM models in predicting passenger’s getting on and off intentions."
어텐션임베딩과 다채널 CNN 기반 반시민성 검출 알고리즘,2022,[],"온라인 포털 플랫폼은 뉴스 기사와 온라인 댓글을 제공하고 있으나, 온라인 댓글의 익명성은 반시민적 표현을 증가시켜 사회적 문제점으로 간주되고 있다. 댓글의 반시민성 검출 연구가 많이 이루어진 국외와 달리, 국내에서는 비시민성을 세분화한 한국어 데이터셋이 구현되지 않아 심도있는 연구가 이루어지지 못하였다. 본 연구에서는 댓글의 반시민성에 대한 라벨링을 총 13가지 항목으로 시행하였으며 반시민적 표현으로 요약하였다. 또한 어텐션 알고리즘을 이중으로 적용하여 임베딩 벡터를 추출하였고 이후 2-d CNN으로 반시민성 항목을 분류하였다. 그 결과, 제안한 알고리즘이 무례한 호칭 및 공격적 어조 등의 반시민성 검출에 유용하다는 것을 보여주었다. 본 연구는 민주적 담론을 저해하는 반시민적 댓글들을 탐지함으로써 건전한 온라인 댓글 문화 형성에 기여할 것으로 기대된다.",다국어 초록 정보 없음
GPR 영상에서 CNN을 이용한 지뢰 식별 연구,2022,"['Mine Detection', 'Gound Penetrating Radar', 'Deep Learning', 'Convolutional Neural Network', 'Accuracy']","우리나라의 지뢰지대는 여의도 면적의 44배인 128㎢이며, 매설량은 최소 82만 8천개에 달한다. 지표투과레이다는 기존 지뢰탐지기로 찾아내지 못했던 목함과 발목 지뢰 등 비금속 지뢰까지 탐지가 가능하고, 탐지된 지뢰를 영상으로 확인할 수 있다는 점에서 탐지율은 월등히 높아지고 오경보율은 저하되는 등 지뢰 탐지 성능이 기존 금속탐지기보다 매우 향상되었다. 최근에는 영상 식별 성능을 강화하기 위하여 레이다 신호에 인공지능을 접목한 연구가 증가하고 있으나, 군사보안 상의 이유로 실제 지뢰의 GPR 데이터는 민간에서 연구가 진행되기가 어려웠다. 본 논문에서는 실제 군에서 사용 예정인 지뢰탐지기-II의 GPR 영상 데이터를 기반으로 CNN(Convolutional Neural Network) 모델에 적용하여 99.5%의 정확도를 확인하였으며, 시뮬레이션을 통한 연구와 비교하여 실제 데이터를 학습한 모델의 성능이 우수함을 확인하였다. 또한 토양별로 실험을 진행하여 사양토, 부엽토, 수풀에서 각각 100%, 99%, 98.9%의 정확도를 보임을 확인하였다. 앞으로 실제 야전에서 지뢰탐지기-II를 운용하며 지속적으로 데이터를 구축해 나간다면 정확도는 더욱 높아질 것으로 기대된다. 향후 지뢰 유사물질의 파형에 대한 개별 학습을 통해 오경보율을 줄여 나가는 연구를 수행할 예정이다.","The landmine zone in the Republic of Korea is 128㎢ and the landmines buried total at least 828,000 units. Ground penetrating radar (GPR) has improved mine detection performance, compared to metal detection, in that it can detect non-metallic landmines not found by conventional detectors. Also, GPR can check the detected landmines via video, increasing the detection rate and lowering the false alarm rate. Even though many studies on artificial intelligence with radar signals have been discussed to enhance the performance of image identification, private-level research based on actual GPR data has been difficult to conduct owing to military security. This paper confirmed 99.5% accuracy by applying a Convolutional Neural Network (CNN) model based on GPR data from Mine Detector II, scheduled for use by the army, which is more accurate than in previous studies. In addition, we conducted experiments based on three soil types and confirmed accuracies of 100%, 99%, and 98.9%. We expect accuracy will increase further with the accumulation of data from field operations. In the future, research will be conducted to reduce the false alarm rate by learning the waveforms of mine-like substances."
가야 토기의 편년 추정을 위한 딥러닝 CNN-DBSCAN 기반 굽다리 접시 유형 예측 모형 개발,2022,"['Gaya artifacts', 'Typology', 'Image Classification', 'Artificial Intelligence', 'Prediction of chronological age', '가야유물', '형식학', '이미지 분류', '인공지능', '편년추정']",국문 초록 정보 없음,"The aims of this study is to propose a new typology classification methodology for estimating the chronological age of Gaya pottery (excavated from Changnyeong area) using artificial intelligence image classification technology based on archaeological formalism. In order to achieve the purpose, 1) image data collection, processing and DB establishment of Gobae (grilled plate), which has a large number of excavations and sensitive changes in properties over time, 2) deep learning CNN image feature extraction and DBSCAN Class classification model development and estimation, 3) The differences and similarities between the existing classification and AI classification are considered. As a result, in the classification of people, the width of the plate and the height of the leg was recognized as the main characteristic, but in the classification of CNN-DBSCAN, the machine had differences by type in the open shape of the lid, the depth of the plate, and the open shape of the legs. The results of this study are expected to provide new insights into the classification system of artifacts with complex properties."
사과 병해충 분류를 위한 CNN 기반 모델 비교,2022,[],"세계에서 가장 중요한 온대 과일 작물 중 하나인 사과의 생산성과 품질은 병해충 여부에 큰 영향을 받는다. 이를 진단하기 위해서는 효율적이고 많은 전문 지식과 상당한 시간이 필요하다. 그러므로 이를 해결하기 위해 효율적이고 정확하게 다양한 병해충을 진단하는 시스템이 필요하다. 본 논문에서는 이미지 분석에 큰 효율을 보인 딥러닝 기반 CNN 들을 비교 분석하여 사과의 병해충 여부를 판별하고 최적의 모델을 제시한다. 딥러닝 기반 CNN 구조를 가진 AlexNet, VGGNet, Inception-ResNet-v2, DenseNet 을 채택해 사과 병해충 분류 성능 평가를 진행했다. 그 결과 DenseNet 이 가장 우수한 성능을 보여주었다.",다국어 초록 정보 없음
CNN과 LSTM 및 GRU 기반 연구 논문 분류 시스템의 설계 및 구현,2022,[],"최근 딥러닝 기술은 자연어처리에서 기본적이고 필수적인 기법으로 자연어처리에 필요한 복잡한 비선형 관계를 모델링할 수 있다. 본 논문에서는 LSTM(Long Short-Term Memory)과 GRU(Gated Recurrent Unit) 딥러닝 기술을 연구 논문 분류에 적용하며, CNN(Convolutional Neural Network)에 LSTM과 GRU을 각각 결합하여 특정 분야의 연구 논문을 분류하고 연구 논문을 추천하는 기법을 제안한다. 워드 임베딩과 딥러닝 기법을 연구 논문 분류에 적용하여 관심이 있는 단어와 단어 주변의 단어들 사이의 유사성과 성능을 비교 분석한다.",다국어 초록 정보 없음
CNN 기반 전이학습을 이용한 뼈 전이가 존재하는 뼈 스캔 영상 분류,2022,"['Deep Learning', 'Computer Vision', 'CNN', 'Transfer Learning', 'Medical Image', 'Bone Scan']",국문 초록 정보 없음,"Whole body bone scan is the most frequently performed nuclear medicine imaging to evaluate bone metastasis in cancer patients. We evaluated the performance of a VGG16-based transfer learning classifier for bone scan images in which metastatic bone lesion was present. A total of 1,000 bone scans in 1,000 cancer patients (500 patients with bone metastasis, 500 patients without bone metastasis) were evaluated. Bone scans were labeled with abnormal/normal for bone metastasis using medical reports and image review. Subsequently, gradient-weighted class activation maps (Grad-CAMs) were generated for explainable AI. The proposed model showed AUROC 0.96 and F1-Score 0.90, indicating that it outperforms to VGG16, ResNet50, Xception, DenseNet121 and InceptionV3. Grad-CAM visualized that the proposed model focuses on hot uptakes, which are indicating active bone lesions, for classification of whole body bone scan images with bone metastases."
멀티 테스크 CNN의 경량화 모델을 이용한 차량 및 차선의 동시 검출,2022,"['Shared backbone', 'Multi-Task CNN', 'Object detection', 'Lane detection', '자율주행', '백본 공유 모델', '차량 검출', '차선 검출']",국문 초록 정보 없음,"As deep learning-based autonomous driving technology develops, artificial intelligence models for various purposes have been studied. Based on these studies, several models were used simultaneously to develop autonomous driving systems. It can occur by increasing hardware resource consumption. We propose a multi-tasks model using a shared backbone to solve this problem. This can solve the increase in the number of backbones for using AI models. As a result, in the proposed lightweight model, the model parameters could be reduced by more than 50% compared to the existing model, and the speed could be improved. In addition, each lane can be classified through lane detection using the instance segmentation method. However, further research is needed on the decrease in accuracy compared to the existing model."
위성 영상을 위한 경량화된 CNN 기반의 보간 기술 연구,2022,"['Interpolation', 'Super-resolution', 'Remote sensing', 'Satellite images']",국문 초록 정보 없음,"In order to obtain satellite image products using the image transmitted to the ground station after capturing the satellite images, many image pre/post-processing steps are involved. During the pre/post-processing, when converting from level 1R images to level 1G images, geometric correction is essential. An interpolation method necessary for geometric correction is inevitably used, and the quality of the level 1G images is determined according to the accuracy of the interpolation method. Also, it is crucial to speed up the interpolation algorithm by the level processor. In this paper, we proposed a lightweight CNN-based interpolation method required for geometric correction when converting from level 1R to level 1G. The proposed method doubles the resolution of satellite images and constructs a deep learning network with a lightweight deep convolutional neural network for fast processing speed. In addition, a feature map fusion method capable of improving the image quality of multispectral (MS) bands using panchromatic (PAN) band information was proposed. The images obtained through the proposed interpolation method improved by about 0.4 dB for the PAN image and about 4.9 dB for the MS image in the quantitative peak signal-to-noise ratio (PSNR) index compared to the existing deep learning-based interpolation methods. In addition, it was confirmed that the time required to acquire an image that is twice the resolution of the 36,500×36,500 input image based on the PAN image size is improved by about 1.6 times compared to the existing deep learning-based interpolation method."
CNN 기반 생활폐기물 분류 시스템의 설계,2022,[],"코로나 19 장기화로 비대면, 원격 수업, 재택 근무 등 생활 형태가 변하면서 일회용품 쓰레기도 증가했다. 분리배출 표시제도가 자주 변경되어 가정에서 판단시 어려움을 느낄 수 있다. 이에 본 연구에서는 재활용 가능 여부를 알려주고, 생활폐기물의 수거 기준에 맞는 처리방법을 알 수 있도록 돕는 분류 시스템을 개발하고 평가한다.",다국어 초록 정보 없음
마스크 R-CNN과 랜덤 포레스트 방법을 이용한 당뇨병성 망막병증 분류,2022,"['Diabetic Retinopathy', 'Random Forest Classifier', 'Mask R-CNN', 'Data Augmentation', '당뇨병성 망막병증', '랜덤포레스트 분류기', 'Mask R-CNN', 'Data Augmentation', 'Image Processing']","본 논문에서는 딥러닝 기법의 하나인 Mask R-CNN과 랜덤포레스트 분류기를 이용해 당뇨병성 망막병증의 병리학적인 특징을 검출하고 분석하여 자동 진단하는 시스템을 연구하였다. 당뇨병성 망막병증은 특수장비로 촬영한 안저영상을 통해 진단할 수 있는데 밝기, 색조 및 명암은 장치에 따라다를 수 있으며 안과 전문의의 의료적 판단을 도울 인공지능을 이용한 자동진단 시스템 연구와 개발이 가능하다. 이 시스템은 미세혈관류와 망막출혈을 Mask R-CNN 기법으로 검출하고, 후처리 과정을거쳐 랜덤포레스트 분류기를 이용하여 안구의 정상과 비정상 상태를 진단한다. Mask R-CNN 알고리즘의 검출 성능 향상을 위해 이미지 증강 작업을 실시하여 학습을 진행하였으며 검출 정확도 측정을위한 평가지표로는 다이스 유사계수와 Mean Accuracy를 사용하였다. 비교군으로는 Faster R-CNN 기법을 사용하였고 본 연구를 통한 검출 성능은 평균 90%의 다이스 계수를 통한 정확도를 나타내었으며 Mean Accuracy의 경우 91% 정확도의 검출 성능을 보였다. 검출된 병리증상을 토대로 랜덤포레스트 분류기를 학습하여 당뇨병성 망막 병증을 진단한 경우 99%의 정확도를 보였다.","In this paper, we studied a system that detects and analyzes the pathological features of diabetic retinopathy using Mask R-CNN and a Random Forest classifier. Those are one of the deep learning techniques and automatically diagnoses diabetic retinopathy. Diabetic retinopathy can be diagnosed through fundus images taken with special equipment. Brightness, color tone, and contrast may vary depending on the device. Research and development of an automatic diagnosis system using artificial intelligence to help ophthalmologists make medical judgments possible. This system detects pathological features such as microvascular perfusion and retinal hemorrhage using the Mask R-CNN technique. It also diagnoses normal and abnormal conditions of the eye by using a Random Forest classifier after pre-processing. In order to improve the detection performance of the Mask R-CNN algorithm, image augmentation was performed and learning procedure was conducted.Dice similarity coefficients and mean accuracy were used as evaluation indicators to measure detection accuracy.The Faster R-CNN method was used as a control group, and the detection performance of the Mask R-CNN method through this study showed an average of 90% accuracy through Dice coefficients. In the case of mean accuracy it showed 91% accuracy. When diabetic retinopathy was diagnosed by learning a Random Forest classifier based on the detected pathological symptoms, the accuracy was 99%."
초등학생을 위한 모듈형 CNN 핵심 원리 교육 프로그램 개발,2022,"['인공지능교육', 'CNN', '합성곱', '스트라이드', '패딩', '풀링', 'Artificial   intelligence   education', 'CNN', 'Convolution', 'Stride', 'Padding', 'Pooling']","인공지능 교육의 방향과 깊이에 대한 논의가 계속되고 있는 오늘날, 본 논문에서는 ｢초· 중 등 인공지능 교육 내용기준｣의 고등학교 과정에서 도입되는 CNN( 합성곱 신경망) 에 대하여 초등학생을 대상으로 교육하는 프로그램을 제안한다. CNN 알고리즘의 핵심인 합성곱 연산은 곱셈과 덧셈의 연속적인 혼합계산이라는 점에서 수학과교육과정과의 융합을 모색 할 수 있다. 제안된 CNN 교육 프로그램에 서 교수자는 합성곱, 스트라이드, 패딩, 풀링이라는 4개 모듈을 합리적으로 조합하고 학습자의 학년 수준에서 다룰 수 있는 수 체계와 연산을 접목할 수 있다.권장되는 모듈의 조합은 6 가지이며, 초등학 교 2 학년부터 6학년 학습자까지 학습의 범위와 깊이에 차이를 둔다. 향후 현장 수업을 통해 교육 프로그램의 효과성을 검증할 필요가 있다.","This paper proposes a program to educate elementary school students ab out Convolutional Neural Netw ork ( CNN) . This algorithm introduced in the high school course of the “Elementary and Secondary AI Education Content Standards” . Convolutions, the core of CNN algorithms, are continuous mix ed computations of multiplication and addition, so convergence with elementary mathematics curriculum can be sought. In the proposed CNN education program, instructors can comb ine 4 modules: convolution, stride, padding, and pooling, and incorporate mathematical systems and operations related with the learners' grades. There are 6 recommended comb inations of modules, and there are differences in the scope and depth of learning from 2nd to 6th graders. It is necessary to verify the effectiveness of the program through field classes in the future."
경량 CNN 가속기를 위한 Radix-2 Booth 기반 가변 정밀도 곱셈기,2022,[],"엣지 디바이스에서 딥러닝을 활용하기 위하여 CNN 경량화 연구들이 진행되고 있다. 경량 CNN 은 대부분 고정 소수점을 사용하며, 계층에 따라 정밀도는 달라진다. 본 논문에서는 경량 CNN 을 지원하기 위하여, 사용 계층에 따라 정밀도를 선택할 수 있는 가변 정밀도 곱셈기를 제안한다. 제안하는 가변 정밀도 곱셈기는 낮은 정밀도 곱셈기를 병합하는 구조로, 정밀도가 낮을 때는 병렬 처리를 통해 효율을 높인다. 제안하는 곱셈기를 Verilog HDL로 설계하고 ModelSim 에서 동작을 확인하였다. 설계된 곱셈기는 계층별로 정밀도가 다른 CNN 가속기에서 효율적으로 적용될 것으로 기대된다.",다국어 초록 정보 없음
1-D CNN 기반 자동차 휠 너트 풀림 상태 예측 기법 개발,2022,"['1-D 합성곱 신경망', '휠 너트 풀림', '가속도계', '실시간 예측', '데이터기반 고장진단', '1-D Convolutional Neural Network', 'Wheel Nut Loosening', 'Accelerometer', 'Real-time Prediction', 'Data-based Fault Diagnosis']",국문 초록 정보 없음,"To predict the loosening state of a ehicle wheel nuts, a prediction algorithm featuring a 1-D convolutional neural network (CNN) has been proposed. After the acceleration of unsprung mass is measured, a feature matrix is obtained. Based on the feature matrix, the training stage of the 1-D CNN is conducted. Then, it is implemented using MATLAB/Simulink post data preprocessing, learning, and verification. To evaluate the prediction performance of the proposed model, we compared it with a 2-D CNN model. In addition, the robustness of the 1-D CNN model under various types of sensor noise has been analyzed."
2차원 변환과 CNN 딥러닝 기반 음향 인식 시스템에 관한 연구,2022,"['음향 데이터', 'CNN', '2차원 이미지', '증강', '앙상블 학습', 'Sound Data Set', 'CNN', '2-D data', 'Augmentation', 'Ensemble Learning']","본 논문은 일상생활에서 흔히 들을 수 있는 소리(비명소리, 박수 소리, 여러 명의 박수 소리, 자동차 지나가는 소리, 배경음 등)를 감지하는 음향 인식을 위하여, 신호처리 및 딥러닝을 적용하는 연구에 관한 것이다. 제안된 음향 인식에서는, 인식 정확도의 향상을 위해서 음향 파형의 스펙트럼, 음향 데이터의 증강, 2차원(2-D) 이미지 변환에 관한 기술들이 사용되었고, 예측의 정확도를 향상을 위한 앙상블 학습, Convolution Neural Network(CNN) 딥러닝 기술들이 적용된다. 제안된 음향 인식 기술은 실험을 통해 다양한 음향을 정확하게 인식할 수 있음을 보여준다.","This paper proposes a study on applying signal processing and deep learning for sound recognition that detects sounds commonly heard in daily life (Screaming, Clapping, Crowd_clapping, Car_passing_by and Back_ground, etc.). In the proposed sound recognition, several techniques related to the spectrum of sound waves, augmentation of sound data, ensemble learning for various predictions, convolutional neural networks (CNN) deep learning, and two-dimensional (2-D) data are used for improving the recognition accuracy. The proposed sound recognition technology shows that it can accurately recognize various sounds through experiments."
지적재조사사업에서의 무인비행장치와 Mask R-CNN을 이용한 건축물 현황 취득 방안 연구,2022,"['Cadastral Resurvey Project', 'Unmanned Aerial Vehicle', 'Deep Learning', 'Mask R-CNN', 'Building Boundary', '지적재조사사업', '무인비행장치', '딥러닝', 'Mask R-CNN', '건축물 현황']","지적재조사사업에서 건축물의 현황 파악은 지적재조사지역 측량조사 시에 수행한다. 이는 지적재조사 측량 시에 건축물 현황 조사를 추가적으로 수행해야 되므로 시간, 비용 손실이 발생하게 된다. 이를 감소하기 위해 무인비행장치 영상과 딥러닝의 Mask R-CNN 알고리즘을 적용하여 건축물에 대한 현황 추출을 진행하였다. 추출된 객체와 지상측량의 경계점 성과를 비교하였다. 비교 결과 RMSE X=0.072m, Y=0.062m로 지적재조사사업에 적용 가능한 값을 도출하였다. 하지만 건축물 현황 추출률이 약 50%이며 추출된 객체의 정확도가 낮은 건축물도 발생하였다. 이는 훈련데이터의 부족 등으로 건축물 명확하게 인식하지 못한 것으로 판단된다. 향후 데이터의 축적과 딥러닝 알고리즘의 발전으로 추출률이 더욱 높아진다면 향후 지적재조사사업 등 지적 분야에 적용이 가능할 것으로 판단된다.","In the cadastral re survey project, the current status of buildings is assessed during the survey of the cadastral re survey area. This results in loss of time and cost because it is necessary to additionally conduct a building status survey during the cadastral re survey. To reduce this, we applied the unmanned aerial vehicle image and the Mask R-CNN algorithm of deep learning to extract the current status of the building. The performance of the extracted object and the boundary point of the ground survey was compared. As a result of comparison, RMSE X = 0.072m, Y = 0.062m, a value applicable to the cadastral resurvey project was derived. However, the extraction rate of the building status was about 50%, and there were also buildings with low accuracy of the extracted objects. It is judged that the building was not clearly recognized due to the lack of training data. If the extraction rate is further increased due to the accumulation of data and the development of deep learning algorithms in the future, it is judged that it can be applied to cadastral fields such as cadastral resurvey project in the future."
현장 안전사고 예방을 위한 패스터 R-CNN 기반 작업자와 기계 상호간섭 범위탐지 모델 제안 및 검증,2022,"['머신러닝', '건설 안전 관리', '딥 러닝', '패스터 R-CNN', '시각 검사 모델', '이미지 분석', 'Machine Learning', 'Construction Safety Management', 'Deep Learning', 'Faster R-CNN', 'Visual Inspection Model', 'Image Analysis']","건설공사의 안전관리는 공사 일정 및 현장 실시에 큰 영향을 미친다. 그러나 현재 현장 안전감시 방법은 육체노동 의존도가 높다. 따라서 내용 누락과 같은 인적 오류가 발생할 수 있다. 이러한 문제를 해결하기 위해 본 연구는 기계학습 시각 감지 알고리즘을 적용하여 건설 현장 작업자의 위험 행동을 식별함으로써 근로자의 외부 모니터링을 강화하고 안전사고 발생을 어느 정도 줄일 수 있다. 본 논문은 객체 감지 알고리즘과 공간 위치 파악 관계 정의를 결합한 방법을 제안한다. 건설 현장의 기계와 작업자만 정확하게 감지하면 되고, 공간 위치 관계의 정의를 활용해 위험한 행동을 파악할 수 있다. 첫째, 본 연구에 적합한 모니터링 네트워크 프레임워크는 건설 현장의 환경 특성 및 이미지 특성에 맞게 구축되었다. 그런 다음 건설 현장의 시각 탐지 데이터를 얻기 위해 컴퓨터가 Faster R-CNN 알고리즘을 기반으로 한 건설 이미지에서 기계와 작업자를 탐지한다. 마지막으로 이미지에서 기계와 작업자의 위치 관계를 결정하기 위해 세 가지 공간 개념이 정의된다. 그리고 건설 현장에서 감지된 기계 및 작업자의 위치정보와 결합하여 시각화된 형태로 제시한다. 연구의 결과를 바탕으로 건설 안전관리 사업의 정보화, 지능화에 새로운 기술 지원되기를 바란다.","Safety management of construction projects have a significant impact on the construction project’s schedule and the control carried out on site. Current site safety monitoring methods are highly dependent on manual labor; human errors can occur through missing content. This study aims to resolve these issues by applying machine learning visual detection algorithms to identify unsafe behaviors of workers at construction sites, to enhance external monitoring of workers and to relatively reduce the occurrence of safety accidents. A proposed method combines an object detection algorithm and spatial localization relationship definition. Only the machinery and workers at the construction site need to be accurately detected and the definition of spatial location relationship can be used to identify dangerous behaviors. A monitoring network framework suitable for this study was constructed with the environmental characteristics and image features of a construction site. The machines and workers were detected from construction images based on the Faster R-CNN algorithm for a computer to obtain the visual detection data from the construction site. Three spatial concepts were defined to determine the position relationships of machines and workers in these images. The detected location information of machines and workers at the construction site were combined and presented in a visualized form. Based on the results of this research, it confirmed that the method and performance were suitable for construction site safety management, which is expected to contribute to the speed, level of accuracy and risk warning with the application of automated progress monitoring methods."
CNN 알고리즘을 이용한 의료 영상 데이터 크기에 따른 정확성 분석,2022,"['인공지능', 'CNN', '영상', '정확성분석', 'AI', 'CNN', 'Image', 'Accuracy analysis']",최근 인공지능에 대한 관심과 활용이 증가하면서 의료 산업의 패러다임도 치료나 병원중심의 이용에서 예방과 이용자 중심으로 변화되고 있다. 이와 관련된 기술발전은 의료 빅데이터 구축과 활용을 통한 서비스 향상 및 발전으로 이어지는 사례들로 많이 구축 활용되고 있다. 이에 본 연구에서는9천여 장의 의료 영상 데이터를 기반으로 입력 영상 크기 및 훈련 회수에 따라 정확성 값을 비교하여높은 결과 값을 갖는 입력 영상 데이터 조건을 찾는다. 이렇게 함으로써 소규모 의료 영상 데이터를이용하여 높은 정확성을 확보함으로써 적은 비용으로도 질병 유무 판단에 활용할 수 있을 것이다. 이를 위해 2차원 영상 데이터 학습과 정확성 분석에 효과적인 CNN 알고리즘을 사용하여 진행한다.,다국어 초록 정보 없음
CNN 모델을 활용한 콘크리트 균열 검출 및 시각화 방법,2022,"['콘크리트 균열', '딥러닝', '시각화', 'concrete crack', 'deep learning', 'visualization']",국문 초록 정보 없음,"Concrete structures occupy the largest proportion of modern infrastructure, and concrete structures often have cracking problems. Existing concrete crack diagnosis methods have limitations in crack evaluation because they rely on expert visual inspection. Therefore, in this study, we design a deep learning model that detects, visualizes, and outputs cracks on the surface of RC structures based on image data by using a CNN (Convolution Neural Networks) model that can process two- and three-dimensional data such as video and image data. do. An experimental study was conducted on an algorithm to automatically detect concrete cracks and visualize them using a CNN model. For the three deep learning models used for algorithm learning in this study, the concrete crack prediction accuracy satisfies 90%, and in particular, the ‘InceptionV3’-based CNN model showed the highest accuracy. In the case of the crack detection visualization model, it showed high crack detection prediction accuracy of more than 95% on average for data with crack width of 0.2 mm or more."
CNN 기반 MS Office 악성 문서 탐지,2022,"['MS Office', 'malicious', 'detection', 'CNN', 'deep learning']",국문 초록 정보 없음,"Document-type malicious codes are being actively distributed using attachments on websites or e-mails. Document-type malicious code is relatively easy to bypass security programs because the executable file is not executed directly. Therefore, document-type malicious code should be detected and prevented in advance. To detect document-type malicious code, we identified the document structure and selected keywords suspected of being malicious. We then created a dataset by converting the stream data in the document to ASCII code values. We specified the location of malicious keywords in the document stream data, and classified the stream as malicious by recognizing the adjacent information of the malicious keywords. As a result of detecting malicious codes by applying the CNN model, we derived accuracies of 0.97 and 0.92 in stream units and file units, respectively."
MFCCs를 이용한 입력 변환과 CNN 학습에 기반한운영 환경 변화에 강건한 베어링 결함 진단 방법,2022,"['Bearing Fault Diagnosis', 'Deep Learning', 'Distribution Difference', 'MFCCs', 'CNN', '베어링 결함 진단', '딥러닝', '분포 차이', 'MFCCs', 'CNN']",국문 초록 정보 없음,"There have been many successful researches on a bearing fault diagnosis based on Deep Learning, but there is still a critical issueof the data distribution difference between training data and test data from their different working conditions causing performancedegradation in applying those methods to the machines in the field. As a solution, a data adaptation method has been proposed andshowed a good result, but each and every approach is strictly limited to a specific applying scenario or presupposition, which makesit still difficult to be used as a real-world application. Therefore, in this study, we have proposed a method that, using a data transformationwith MFCCs and a simple CNN architecture, can perform a robust diagnosis on a target domain data without an additional learningor tuning on the model generated from a source domain data and conducted an experiment and analysis on the proposed method withthe CWRU bearing dataset, which is one of the representative datasests for bearing fault diagnosis. The experimental results showedthat our method achieved an equal performance to those of transfer learning based methods and a better performance by at least 15%compared to that of an input transformation based baseline method."
동작 인식을 위한 교사-학생 구조 기반 CNN,2022,"['양 스트림', '교사-학생 아키텍처', 'CNN', '광학 흐름', '동작 인식', 'Two-Stream Network', 'Teacher-Student Architecture', 'CNN', 'Optical Flow', 'Action Recognition']","대부분 첨단 동작 인식 컨볼루션 네트워크는 RGB 스트림과 광학 흐름 스트림, 양 스트림 아키텍처를 기반으로 하고 있다. RGB 프레임 스트림은모양 특성을 나타내고 광학 흐름 스트림은 동작 특성을 해석한다. 그러나 광학 흐름은 계산 비용이 매우 높기 때문에 동작 인식 시간에 지연을초래한다. 이에 양 스트림 네트워크와 교사-학생 아키텍처에서 영감을 받아 행동 인식을 위한 새로운 네트워크 디자인을 개발하였다. 제안 신경망은두 개의 하위 네트워크로 구성되어있다. 즉, 교사 역할을 하는 광학 흐름 하위 네트워크와 학생 역할을 하는 RGB 프레임 하위 네트워크를 연결하였다.훈련 단계에서 광학 흐름의 특징을 추출하고 교사 서브 네트워크를 훈련시킨 다음 그 특징을 학생 서브 네트워크를 훈련시키기 위한 기준선으로지정하여 학생 서브 네트워크에 전송한다. 테스트 단계에서는 광학 흐름을 계산하지 않고 대기 시간이 줄어들도록 학생 네트워크만 사용한다.제안 네트워크는 실험을 통하여 정확도 면에서 일반 이중 스트림 아키텍처에 비해 높은 정확도를 보여주는 것을 확인하였다.","Convolutional neural network (CNN) generally uses two-stream architecture RGB and optical flow stream for its action recognitionfunction. RGB frames stream display appearance and optical flow stream interprets its action. However, the standard method of usingoptical flow is costly in its computational time and latency associated with increased action recognition. The purpose of the study wasto evaluate a novel way to create a two sub-networks in neural networks. The optical flow sub-network was assigned as a teacher andthe RGB frames as a student. In the training stage, the optical flow sub-network extracts features through the teacher sub-network andtransmits the information to student sub-network for baseline training. In the test stage, only student sub-network was operational withdecreased in latency without computing optical flow. Experimental results shows that our network fed only by RGB stream gets a competitiveaccuracy of 54.5% on HMDB51, which is 1.5 times better than that on R3D-18."
모바일 디바이스를 위한 소형 CNN 가속기의 마이크로코드 기반 컨트롤러,2022,"['Microcode', 'Convolution Neural Network Accelerator', 'SoC', 'FPGA', '마이크로코드', '컨볼루션 뉴럴 네트워크 가속기', 'SoC', 'FPGA']","본 논문은 프로그램 가능한 구조를 사용하여 재구성이 가능하고 저 전력 초소형의 장점을 모두 제공하는 인공지능 가속기를 위한 마이크로코드 기반 뉴럴 네트워크 가속기 컨트롤러를 제안한다. 대상 가속기가 다양한 뉴럴 네트워크 모델을 지원하도록 마이크로코드 컴파일러를 통해 뉴럴 네트워크 모델을 마이크로코드로 변환하여 가속기의 메모리 접근과 모든 연산기를 제어할 수 있다. 200MHz의 System Clock을 기준으로 설계하였으며, YOLOv2-Tiny CNN model을 구동하도록 컨트롤러를 구현하였다. 객체 감지를 위한 VOC 2012 dataset 추론용 컨트롤러를 구현할 경우 137.9ms/image, mask 착용 여부 감지를 위한 mask detection dataset 추론용으로 구현할 경우 99.5ms/image의 detection speed를 달성하였다. 제안된 컨트롤러를 탑재한 가속기를 실리콘칩으로 구현할 때 게이트 카운트는 618,388이며, 이는 CPU core로서 RISC-V (U5-MC2)를 탑재할 경우 대비 약 65.5% 감소한 칩 면적을 제공한다.","This paper proposes a microcode-based neural network accelerator controller for artificial intelligence accelerators that can be reconstructed using a programmable architecture and provide the advantages of low-power and ultra-small chip size. In order for the target accelerator to support various neural network models, the neural network model can be converted into microcode through microcode compiler and mounted on accelerator to control the operators of the accelerator such as datapath and memory access. While the proposed controller and accelerator can run various CNN models, in this paper, we tested them using the YOLOv2-Tiny CNN model. Using a system clock of 200 MHz, the Controller and accelerator achieved an inference time of 137.9 ms/image for VOC 2012 dataset to detect object, 99.5ms/image for mask detection dataset to detect wearing mask. When implementing an accelerator equipped with the proposed controller as a silicon chip, the gate count is 618,388, which corresponds to 65.5% reduction in chip area compared with an accelerator employing a CPU-based controller (RISC-V)."
비소세포폐암 환자의 재발 예측을 위한 흉부 CT 영상 패치 기반 CNN 분류 및 시각화,2022,"['Non-Small Cell Lung Cancer(NSCLC)', 'Recurrence Prediction', 'Deep Learning', 'Classification', 'Ensemble Learning', 'Convolutional Neural Network(CNN)1', '비소세포폐암', '재발 예측', '딥러닝', '분류', '앙상블 학습', '합성곱 신경망']","비소세포폐암(NSCLC)은 전체 폐암 중 85%의 높은 비중을 차지하며 사망률(22.7%)이 다른 암에 비해 현저히 높은 암으로비소세포폐암 환자의 수술 후 예후에 대한 예측은 매우 중요하다. 본 연구에서는 종양을 관심영역으로 갖는 비소세포폐암환자의 수술 전 흉부 CT 영상 패치의 종류를 종양 관련 정보에 따라 총 다섯 가지로 다양화하고, 이를 입력데이터로 갖는사전 학습 된 ResNet 과 EfficientNet CNN 네트워크를 사용하여 단일 모델과 간접 투표 방식을 이용한 앙상블 모델, 그리고3 개의 입력 채널을 활용한 앙상블 모델에서의 실험 결과 및 성능을 오분류의 사례와 Grad-CAM 시각화를 통해 비교분석한다. 실험 결과, 종양 주변부 패치를 학습한 ResNet152 단일 모델과 EfficientNet-b7 단일 모델은 각각 87.93%와81.03%의 정확도를 보였다. 또한 ResNet152 에서 총 3 개의 입력 채널에 각각 영상 패치, 종양 주변부 패치, 형상 집중 종양내부 패치를 넣어 앙상블 모델을 구성한 경우에는 정확도 87.93%를, EfficientNet-b7 에서 간접 투표 방식으로 영상 패치와종양 주변부 패치 학습 모델을 앙상블 한 경우에는 정확도 84.48%를 도출하며 안정적인 성능을 보였다.","Non-small cell lung cancer (NSCLC) accounts for a high proportion of 85% among all lung cancer and has a significantly higher mortality rate (22.7%) compared to other cancers. Therefore, it is very important to predict the prognosis after surgery in patients with non-small cell lung cancer. In this study, the types of preoperative chest CT image patches for non-small cell lung cancer patients with tumor as a region of interest are diversified into five types according to tumor-related information, and performance of single classifier model, ensemble classifier model with soft-voting method, and ensemble classifier model using 3 input channels for combination of three different patches using pre-trained ResNet and EfficientNet CNN networks are analyzed through misclassification cases and Grad-CAM visualization. As a result of the experiment, the ResNet152 single model and the EfficientNet-b7 single model trained on the peritumoral patch showed accuracy of 87.93% and 81.03%, respectively. In addition, ResNet152 ensemble model using the image, peritumoral, and shape-focused intratumoral patches which were placed in each input channels showed stable performance with an accuracy of 87.93%. Also, EfficientNet-b7 ensemble classifier model with soft-voting method using the image and peritumoral patches showed accuracy of 84.48%."
XAI Grad-CAM 기반 궤양병 감귤 이미지 분류 CNN 모델의 점검,2022,"['딥러닝', '비정형 데이터', '설명 가능한 인공지능', 'CNN', 'Grad-CAM', 'deep learning', 'unstructured data', 'XAI']","하드웨어의 성능 및 정보처리 기술이 급격히 발전하면서 비정형 데이터의 처리 및 가치 창출에 관한 관심이 증가하고 있다. 이를 위한 다양한 인공지능 아키텍처들이 개발되고 있으며, 모델의 의사결정 분기점이 기하급수적으로 늘어나면서 큰 성능의 개선이 이루어지고 있다. 그러나복잡한 모델 구조는 연구자의 결과 해석 용이성을 저해하는 주요한 원인이 되며, 모델 성능의발전 속도와는 달리 설명 능력에 대해서는 진척이 더딘 실정이다. 설명 가능한 인공지능, 이하XAI(eXplainable Artificial Intelligence)는 위와 같은 문제를 해결하기 위해 등장하였으며, 모델의블랙박스를 이해 가능한 수준으로 분해하여 해석 가능성 및 신뢰도 제고에 도움을 준다. 본 연구에서는 CNN(Convolutional Neural Network) 모델을 사용하여 궤양병 감귤 이미지 분류 문제에접근하였으며, 최종적으로 설계한 모델은 약 97% 수준의 정확도를 보였다. 이후 모델의 신뢰성제고 및 개선 방향 판단을 위해 XAI 기법 중 하나인 Grad-CAM(Gradient-weighted Class Activation Mapping)을 적용하였으며, 이를 통해 구축한 모델이 최종적인 판단을 내리는데 중요한 역할을한 이미지의 특정 영역을 파악하는 과정을 진행하였다. 점검 결과 이미지 외곽의 형태가 객체와구분이 되지 않아 영향을 크게 받는 경우 및 특정 객체의 고유한 형태가 오분류 원인으로 감지되었다.","By the rapid development of hardware performance and information processing technology, interest in processing unstructured data and creating value is increasing. Various types of AI architectures are being developed and as the decision-making junction of the model increased exponentially, the performance is being improved. However, complex model structure is a major cause of hindering researchers' ease of interpret results and unlike the speed of development of model performance, the progress is slow on explanatory ability.Explainable artificial intelligence (XAI) has emerged to solve this problem and decomposes the model's black box to an understandable level to help improve interpretability and reliability. In this research, we approach the ucler disease citrus image classification problem by using CNN model, and the final model showed approximately 97% accuracy. After that, to improve the reliability of the model and to determine the specific area of the image that played a major role in making the final judgment, Gradient-weighted Class Activation Mapping (Grad-CAM), one of the XAI techniques was applied. As a result of the inspection, it was detected that the shape outside the image wasn't distinguished from the object which was greatly affected. So, the unique shape of a specific object was the main cause of misclassification."
"fNIRS 실험자료 기반 비즈니스 문제해결창의성 (BPSC)를 예측하기 위한 뉴로사이언스 마이닝 적용에 관한 연구: CNN, BiLSTM, 어텐션네트워크 결합을 중심으로",2022,"['Neuroscience mining (NSM)', 'Business problem-solving creativity (BPSC)', 'fNIRS', 'CNN', 'BiLSTM', 'Attention mechanism', '뉴로사이언스 마이닝', '비즈니스 문제 해결 창의성', '기능성 근적외선 분광법', '합성곱 신경망', '양방향 장단기기억 신경망', '어텐션 메커니즘']","인공지능 기술이 발달하면서 뉴로사이언스 마이닝(NSM: NeuroScience Mining)과 AI를 접목하려는 시도가 증가하고 있다. 나아가 NSM은 뉴로사이언스와 비즈니스 애널리틱스의 결합으로 인해 연구범위가 확장되고 있다. 본 연구에서는 fNIRS 실험을 통해 확보한 뉴로 데이터를 분석하여 비즈니스 문제 해결 창의성(BPSC: business problem-solving creativity)을 예측하고 이를 통해 NSM의 잠재력을 조사한다. BPSC는 비즈니스에서 차별성을 가지게 하는 중요한 요소이지만, 인지적 자원의 하나인 BPSC의 측정 및 예측에는한계가 존재한다. 본 논문에서는 BPSC 예측 성능을 높이는 방안으로 CNN, BiLSTM 그리고 어텐션 네트워크를 결합한 새로운 NSM 기법을 제안한다. 제안된 NSM 기법을 15만 개 이상의 fNIRS 데이터를 활용하여 유효성을 입증하였다. 연구 결과, 본 논문에서 제안하는 NSM 방법이 벤치마킹한 알고리즘(CNN, BiLSTM)에 비하여 우수한 성능을 가지는 것으로 나타났다.",다국어 초록 정보 없음
"CNN 모델을 활용한 작물, 잡초 인식 알고리즘 연구",2022,"['작물 인식', 'CNN', '잡초 분류', '딥러닝']","잡초 제거는 작물의 정상적인 생육과 수확량에 크게 영향을 주는 농작업 중 하나로 수시로 잡초 제거가 진행되어야 한다. 하지만 잡초 제거 시 예초기 및 농기구 사용 미숙에 따른 사고, 근골격계 질환, 농약에 중독되는 등 크고 작은 피해가 발생하고 있다. 이러한 작업자의 안전사고 방지와 투입되는 노동력 감소를 위해 자동화 및 무인화 시스템에 관한 연구가 활발하게 진행되고 있다. 본 연구에서는 밭에서 발견되는 잡초를 작물과 구분하는 알고리즘을 개발해 스마트 농업기술 발전에 활용하고자 했다. 재배 중인 콩(전라남도 나주)과 콩 주위의 잡초를 함께 촬영하여 영상 데이터를 획득했다. 출현기부터 1주일 간격으로 7주 동안 주기적으로 획득하여 인식 모델 개발을 위한 학습 데이터를 구축했다. 작물과 잡초의 인식을 위해 CNN 기반의 모델을 활용했다. 인식 모델의 과적합을 방지하기 위해 Accuracy와 loss가 일정 값에 수렴하는지 확인하고, 학습 모델의 깊이와 학습 수를 설정했다. 작물과 잡초의 인식 결과에서 유의미한 결과를 도출했으며, 본 연구에서 개발된 인식 모델을 활용하면 선택적 잡초 제거에 활용될 수 있음을 확인했다. 추후 연구에서 데이터 다양성 확보, 대상 작물 확대 및 인식 알고리즘 최적화를 통해 인식 정확도를 높일 예정이다.",다국어 초록 정보 없음
"CNN 모델을 활용한 작물, 잡초 인식 알고리즘 연구",2022,"['작물 인식', 'CNN', '잡초 분류', '딥러닝']","잡초 제거는 작물의 정상적인 생육과 수확량에 크게 영향을 주는 농작업 중 하나로 수시로 잡초 제거가 진행되어야 한다. 하지만 잡초 제거 시 예초기 및 농기구 사용 미숙에 따른 사고, 근골격계 질환, 농약에 중독되는 등 크고 작은 피해가 발생하고 있다. 이러한 작업자의 안전사고 방지와 투입되는 노동력 감소를 위해 자동화 및 무인화 시스템에 관한 연구가 활발하게 진행되고 있다. 본 연구에서는 밭에서 발견되는 잡초를 작물과 구분하는 알고리즘을 개발해 스마트 농업기술 발전에 활용하고자 했다. 재배 중인 콩(전라남도 나주)과 콩 주위의 잡초를 함께 촬영하여 영상 데이터를 획득했다. 출현기부터 1주일 간격으로 7주 동안 주기적으로 획득하여 인식 모델 개발을 위한 학습 데이터를 구축했다. 작물과 잡초의 인식을 위해 CNN 기반의 모델을 활용했다. 인식 모델의 과적합을 방지하기 위해 Accuracy와 loss가 일정 값에 수렴하는지 확인하고, 학습 모델의 깊이와 학습 수를 설정했다. 작물과 잡초의 인식 결과에서 유의미한 결과를 도출했으며, 본 연구에서 개발된 인식 모델을 활용하면 선택적 잡초 제거에 활용될 수 있음을 확인했다. 추후 연구에서 데이터 다양성 확보, 대상 작물 확대 및 인식 알고리즘 최적화를 통해 인식 정확도를 높일 예정이다.",다국어 초록 정보 없음
CNN 모델 기반의 소아 ADHD 분류 기법,2022,[],국문 초록 정보 없음,"ADHD is a disorder showing inattentiveness and hyperactivity. Since symptoms diagnosed in childhood continue to the adulthood, it is important to diagnose ADHD and start treatments in early stages. However, it has the problems to acquire enough and accurate data for the diagnosis because the mental state of children is immature using the self-diagnosis method or the computerized test. In this paper, we present the classification method based on the CNN model and execute experiment using the EEG data to improve the objectiveness and the accuracy of ADHD diagnosis. For the experiment, we build the 3D convolutional networks model and exploit the 5-folds cross validation method. The result shows the 97% accuracy on average."
합성곱신경망(CNN)을 활용하여 국내 해양레저관광지 사진 분류 및 해양레저관광 행태를 분석할 수 있는가?,2022,"['해양레저관광지', '해수욕장', '이미지 분류', '딥러닝', 'CNN', 'Marine Tourism', 'Beach', 'Image Classification', 'Deep-learning', 'Convolutional Neural Network']",국문 초록 정보 없음,"In order to quickly respond to changes in marine tourism trends and to establish effective policies, it is necessary to prepare a reliable method for collecting data on visits. The purpose of this study is to conduct an exploratory study on the behavior of marine leisure tourism users by using images, which are unstructured data of public data and social media data, in order to analyze the characteristics of domestic marine tourism. As a research method, the possibility was proposed as a new research method by using the convolutional neural network(CNN) algorithm used for image classification based on deep learning. Supervised learning was performed by classifying behaviors based on theories based on public data and images collected through SNS. As a result of the study, the behaviors of beach users were largely classified into landscape-based and activity-based. As the supervised learning of this study did not show satisfactory results, it is necessary to classify marine leisure tourism behavior by applying the photo classification algorithm for future research. In addition, a management plan for public data was proposed for continuous research use."
악성코드 이미지 분류를 위한 CNN 모델 성능 비교,2022,[],"최근 IT 산업의 지속적인 발전으로 사용자들을 위협하는 악성코드, 피싱, 랜섬웨어와 같은 사이버 공격 또한 계속해서 발전하고 더 지능화되고 있으며 변종 악성코드도 기하급수적으로 늘어나고 있다. 지금까지의 시그니처 패턴 기반의 탐지법으로는 이러한 방대한 양의 알려지지 않은 악성코드를 탐지할 수 없다. 따라서 CNN(Convolutional Neural Network)을 활용하여 악성코드를 탐지하는 기법들이 제안되고 있다. 이에 본 논문에서는 CNN 모델 중 낮은 인식 오류율을 지닌 모델을 선정하여 정확도(Accuracy)와 F1-score 평가 지표를 통해 비교하고자 한다. 두 가지의 악성코드 이미지화 방법을 사용하였으며, 2015 년 이후 ILSVRC 에서 우승을 차지한 모델들과, 추가로 2019 년에 발표된 EfficientNet 을 사용하여 악성코드 이미지를 분류하였다. 그 결과 2 바이트를 한 쌍의 좌표로 변환하여 생성한 256 * 256 크기의 악성코드 이미지를 ResNet-152 모델을 이용해 분류하는 것이 우수한 성능을 보임을 실험적으로 확인하였다.",다국어 초록 정보 없음
"순차적 추천에서의 RNN, CNN 및 GAN 모델 비교 연구",2022,"['recommender system', 'rnn', 'cnn', 'gan', 'deep learning', 'sequence modeling', '추천 시스템', '순환 신경망', '합성곱 신경망', '생성적 적대 신경망', '순차적 모델링']","최근 추천 시스템은 영화, 음악, 온라인 쇼핑 및 SNS 등 다양한 분야들에서 광범위하게 활용되고 있으며, 추천 시스템 분야에서 1세대 모델이라고 할수 있는 Apriori 모델을 통한 연관분석부터 최근 많은 주목을 받는 딥러닝 기반 모델들까지 많은 모델들이 제안되어왔다. 추천 시스템에서 기본 모델들은 협업 필터링(Collaborative filtering) 방법, 콘텐츠 기반 필터링(Content-based filtering) 방법, 그리고 이 두 방법을 통합적으로 사용하는 하이브리드 필터링(Hybrid filtering) 방법으로 분류될 수 있다. 하지만 이러한 모델들은 최근 점점 빠르게 변화하는 사용자-아이템 간의 상호관계와 빅데이터의 발전과 같은 내외 변화 요인들에 적응하지 못하면서 점점 분야 내 방법론으로써의 지위를 잃어가고 있다. 반면, 추천 시스템 내에서 딥러닝 기반 모델들은 비선형 변환, 표현학습, 순차적 모델링, 그리고 유연성과 같은 장점들 때문에 그 비중이 높아지고 있는 추세이다. 본 논문에서는 딥러닝 기반 추천 모델들 중에서도 사용자-아이템 간의 상호작용에 대해 보다 정확하고, 유연성 있게 분석이 가능한 순차적 모델링에 적합한 순환 신경망, 합성곱 신경망, 그리고 생성적 적대 신경망 중심 기반 모델로 분류하여 비교 및 분석한다.","Recently, the recommender system has been widely used in various fields such as movies, music, online shopping, and social media, and in the meantime, the recommender model has been developed from correlation analysis through the Apriori model, which can be said to be the first-generation model in the recommender system field. In 2005, many models have been proposed, including deep learning-based models, which are receiving a lot of attention within the recommender model. The recommender model can be classified into a collaborative filtering method, a content-based method, and a hybrid method that uses these two methods integrally. However, these basic methods are gradually losing their status as methodologies in the field as they fail to adapt to internal and external changing factors such as the rapidly changing user-item interaction and the development of big data. On the other hand, the importance of deep learning methodologies in recommender systems is increasing because of its advantages such as nonlinear transformation, representation learning, sequence modeling, and flexibility. In this paper, among deep learning methodologies, RNN, CNN, and GAN-based models suitable for sequential modeling that can accurately and flexibly analyze user-item interactions are classified, compared, and analyzed."
야구 경기 승패 예측을 위한 합성곱 신경망(CNN) 최적화 연구,2022,"['인공지능', '딥러닝', '빅데이터', '인공신경망', '경기분석', 'Artificial Intelligence(AI)', 'Deep Learning(DL)', 'bigdata', 'artificial neural network', 'performance analysis']","최근 야구 종목의 인공지능 기반의 승패 예측 연구는 점진적인 발전을 보이며, 머신러닝에서 딥러닝까지 다각도의 연구가 진행되고 있다. 인공지능의 학습 성능은 설계된 모델의 하이퍼 파라미터에 값에 영향을 받으며, 최적의 하이퍼 파라미터 값을 찾는 것은 인공지능 모델 설계에서 필수적인 과정이다. 이 연구는 야구 경기의 승패 예측을 위한 합성곱 신경망(CNN)의 최적화 모델을 개발하는 연구로, 성능 최적화를 위해 하이퍼 파라미터 튜닝 방법을 적용하였다. 연구의 목적 달성을 위해 이 연구는 크게 세 단계로 구분된다. 첫 번째 단계는, Sequential 기반의 합성곱 신경망 모델을 1차 개발하는 단계이다. 두 번째 단계는 첫 번째 단계에서 개발한 모델의 하이퍼 파라미터 항목을 조절하여 성능을 비교하는 실험을 10회 진행하여, 최적의 하이퍼 파라미터 값을 찾는 단계이다. 실험결과 최적 성능의 하이퍼 파라미터는 필터(커널) 크기 ‘3*3’, 학습비 ‘8:2’, 배치 사이즈 ‘32’, 에포크 ‘10’으로 결정하였다. 마지막 단계는, 결정한 하이퍼 파라미터를 적용하여 최적의 야구 승패 예측을 위한 합성곱 신경망 모델을 개발하는 단계로, 최종 모델의 성능은 정확도 '84.79', 정밀도 ‘84.84’, 재현율 ‘84.58’, F1 score ‘84.78’로 확인되었다.","Recently, artificial intelligence-based win-loss prediction study in baseball is gradual development from machine learning to deep learning. The training performance of artificial intelligence is affected by the values of the hyper parameter of the designed model. Therefore, finding optimal hyper parameter values is essential in artificial intelligence model design. This study is to develop an optimization model of a Convolutional Neural Network(CNN) for predicting the win/loss of a baseball game, and the hyper parameter tuning method was applied for performance optimization. This study consists of three steps. The first step is to develop the Sequential-based Convolutional Neural Network model. The second step is to find the optimal hyper parameter value by conducting 10 experiments to compare the performance by adjusting the hyper parameter values of the model developed in the first step. As a result of the experiments to compare, the optimal performance hyper parameter values were determined as filter (kernel) size ‘3*3’, learning ratio ‘8:2’, batch size ‘32’, and epoch ‘10’. The last step is to develop a Convolutional Neural Network model for optimal win/loss prediction by applying the determined hyper parameter values. The performance of the final model was confirmed with accuracy ‘84.79’, precision ‘84.84’, recall ‘84.58', and F1 score ‘84.78’."
한국과 미국 방송사의 코로나19 뉴스에 대해 CNN 기반 정량적 음성 감정 양상 비교 분석,2022,"['코로나19', '뉴스 영상', '음성 감정 분석', 'CNN', 'Covid-19', 'News videos', 'Vocal emotion detection', 'CNN']","전례 없는 코로나19 팬데믹 상황에서 대중의 정보에의 요구는 과도한 코로나19 뉴스 소비를 조장하였다. 뉴스는 대중의 심리적 안녕에도 영향을 미치기에 뉴스 보도 양태에 대한 각별한 주의가 요구된다. 이에 본 연구는 한국과 미국의 주요 뉴스 미디어의 코로나19 관련 뉴스의 음성 감정 양상을 합성곱 신경망에 기반하여 분석하였다. 분석 결과, 대부분의 뉴스 미디어에서 중립이 탐지되었으나 슬픔과 분노도 탐지되었다. 이러한 양상은한국의 뉴스 미디어에서 두드러진 반면 미국 뉴스 미디어에서는 나타나지 않았다. 본 연구는 코로나19 뉴스의 첫 음성 감정 분석 연구로, 뉴스의 감정 분석에 있어 새로운 방향을 제시할 뿐 아니라 팬데믹에 대한 이해 증진에 있어 광범위한 함의를 지닌다.","During the unprecedented COVID-19 outbreak, the public’s information needs created an environment where they overwhelmingly consume information on the chronic disease. Given that news media affect the public’s emotional well-being, the pandemic situation highlights the importance of paying particular attention to how news stories frame their coverage. In this study, COVID-19 news speech emotion from mainstream broadcasters in South Korea and the United States (US) were analyzed using convolutional neural networks. Results showed that neutrality was detected across broadcasters. However, emotions such as sadness and anger were also detected. This was evident in Korean broadcasters, whereas those emotions were not detected in the US broadcasters. This is the first quantitative vocal emotion analysis of COVID-19 news speech. Overall, our findings provide new insight into news emotion analysis and have broad implications for better understanding of the COVID-19 pandemic."
R-CNN에 기반한 블랙 스크린의 위치 추정,2022,[],"블랙 스크린은 비디오 월 컨트롤러의 멀티스크린에 정상적인 영상이 아닌 블랙 스크린이 표출되는 현상이다. 비디오 월 컨트롤러에서 블랙 스크린이 발생하는 빈도는 높지 않지만, 운용 중에 발생하게 되면 모니터링 업무를 수행할 수 없게 되므로 치명적인 오류라고 할 수 있다. 따라서 블랙 스크린을 감지하기 위한 시스템이 개발되고 있지만, 거짓 양성의 비율이 높고 블랙 스크린이 발생한 위치를 추정하지 못하는 단점이 있다. 이에 본 논문에서는 R-CNN을 이용하여 감지 성능을 향상시키고 블랙 스크린이 발생한 위치를 추정하는 모델을 제안한다.",다국어 초록 정보 없음
R-CNN에 기반한 블랙 스크린의 위치 추정,2022,[],"블랙 스크린은 비디오 월 컨트롤러의 멀티스크린에 정상적인 영상이 아닌 블랙 스크린이 표출되는 현상이다. 비디오 월 컨트롤러에서 블랙 스크린이 발생하는 빈도는 높지 않지만, 운용 중에 발생하게 되면 모니터링 업무를 수행할 수 없게 되므로 치명적인 오류라고 할 수 있다. 따라서 블랙 스크린을 감지하기 위한 시스템이 개발되고 있지만, 거짓 양성의 비율이 높고 블랙 스크린이 발생한 위치를 추정하지 못하는 단점이 있다. 이에 본 논문에서는 R-CNN을 이용하여 감지 성능을 향상시키고 블랙 스크린이 발생한 위치를 추정하는 모델을 제안한다.",다국어 초록 정보 없음
ARL-CNN50 기반 피부병변 분류진단,2022,[],국문 초록 정보 없음,"With the advent of the era of artificial intelligence, more and more fields have begun to use artificial intelligence technology, especially the medical field. Cancer is one of the biggest problems in the medical field. [1] If it can be detected early and treated early, the possibility of cure will be greatly increased. Malignant skin cancer, as one of the types of cancer with the highest fatality rate in recent years has problems such as relying on the experience of doctors and being unable to be detected and detected in time. Therefore, if artificial intelligence technology can be used to help doctors in early detection of skin cancer, or to allow everyone to detect skin lesions or spots anytime, anywhere, it will have great practical significance. In this paper we used attention residual learning convolutional neural network (ARL-CNN) model [2] to classify skin cancer pictures."
OpenCV 를 활용한 졸음인식 CNN 모델 제작,2022,[],"본 논문에서는 비대면 교육 상황이 확대되는 시점에서 자율 학습에 유용하게 사용할 수 있는 학습자의 졸음을 인식하여 알려주는 모델을 설계하여 구현하였다. 기계학습의 CNN 알고리즘을 활용하여 공부상태와 졸음상태를 판별하는 모델을 만들고, Opencv 을 사용하여 일정 횟수 이상 졸음상태가 반복되면 알람을 울려 사용자를 잠에서 깨운다. 이 프로그램은 자기 관리 및 독립적인 학습을 수행하는 데에 도움을 줄 수 있다.",다국어 초록 정보 없음
컨볼루션 신경망(CNN)을 이용한 폭발물 성분 용량별 분류 성능 평가에 관한 연구,2022,[],국문 초록 정보 없음,"This paper is a study to evaluate the performance when classifying explosive components by capacity using a convolutional neural network (CNN). Among the existing explosive classification methods, the IMS steam detector method determines the presence or absence of an explosive only when the explosive concentration exceeds the threshold set by the user. The IMS steam detector has a problem of determining that even if an explosive exists, the explosive does not exist in an amount that does not exceed the threshold. Therefore, it is necessary to detect the explosive component even when the concentration of the explosive component does not exceed the threshold. Accordingly, in this paper, after imaging explosive time series data with the Gramian Angular Field (GAF) algorithm, it is possible to determine whether there are explosive components and the amount of explosive components even when the concentration of explosive components does not exceed a threshold."
Attention-CNN을 이용한 유도탄 비행데이터의 이상성 검출 기법 연구,2022,"['Monte-Carlo simulation', 'anomaly detection', 'transformer', 'attention score', 'convolutional neural networks', 'data analytics', '.']",국문 초록 정보 없음,.
압축 왜곡 감소를 위한 CNN 기반 이미지 화질개선 알고리즘,2022,"['Computer Vision', 'Deep Learning', 'Convolutional Neural Network', 'Image Processing', 'Image Restoration', 'Image Artifacts Reduction']",국문 초록 정보 없음,"As realistic media are widespread in various image processing areas, image or video compression is one of the key technologies to enable real-time applications with limited network bandwidth. Generally, image or video compression cause the unnecessary compression artifacts, such as blocking artifacts and ringing effects. In this study, we propose a Deep Residual Channel-attention Network, so called DRCAN, which consists of an input layer, a feature extractor and an output layer. Experimental results showed that the proposed DRCAN can reduced the total memory size and the inference time by as low as 47% and 59%, respectively. In addition, DRCAN can achieve a better peak signal-to-noise ratio and structural similarity index measure for compressed images compared to the previous methods."
MAPPO 기반 CNN 하이퍼 파라미터 최적화,2022,[],대부분의 머신러닝 및 딥러닝 모델의 경우 하이퍼 파라미터 선택은 모델의 성능에 큰 영향을 미친다. 따라서 전문가들은 작업을 수행하기 위해 모델을 구축할 때 하이퍼 파라미터 튜닝을 수행하는 데상당한 시간을 소비해야 한다. Hyperparameter Optimization(HPO)을 해결하기 위한 알고리즘은 많지만 대부분의 방법은 검색을 수행하기 위해 각 epoch에서 실제 실험 결과를 필요로 한다. 따라서 HPO 검색을 위한 시간과 계산 지원을 줄이기 위해 본 논문에서는 Multi-agent Proximal Policy Optimization(MAPPO) 강화 학습 알고리즘을 제안한다. 2개의 이미지 분류 데이터 세트에 대한 실험결과는 우리의 모델이 속도와 정확성에서 다른 기존 방법보다 우수하다는 것을 보여준다.,다국어 초록 정보 없음
합성곱 신경망(CNN) 기반 실시간 월파 감지 및 처오름 높이 산정,2022,"['artificial intelligence', 'wave-overtopping detection', 'convolutional neural networks', 'filtering algorithm', '인공지능', '월파 감지', '영상분석', '합성곱 신경망', '여과 알고리즘']","본 연구에서는 인공지능을 활용한 영상분석 기술을 통해 영상 내의 월파를 실시간으로 감지하고 처오름 높이를 산정하는 기술을 제안하였다. 본 연구에서 제안한 월파 감지 시스템은 실시간으로 악기상 및 야간에도 월파를 감지할 수 있음을 확인하였다. 특히, 합성곱 신경망을 적용하여 실시간으로 CCTV 영상에서 파랑의 처오름을 감지하고 월파 여부를 판단하는 여과 알고리즘을 적용하여 월파의 발생 감지에 대한 정확성을 향상시켰다. AP50을 통해 월파 감지 결과의 정확도는 59.6%로 산정되었으며, 월파 감지 모델의 속도는 GPU 기준 70fps로 실시간 감지에 적합한 정확도와 속도를 보임을 확인하였다.","The purpose of this study was to propose technology to detect the wave in the image in real-time, and calculate the height of the wave-overtopping through image analysis using artificial intelligence. It was confirmed that the proposed wave overtopping detection system proposed in this study could detect the occurring of wave overtopping, even in severe weather and at night in real-time. In particular, a filtering algorithm for determining if the wave overtopping event was used, to improve the accuracy of detecting the occurrence of wave overtopping, based on a convolutional neural networks to catch the wave overtopping in CCTV images in real-time. As a result, the accuracy of the wave overtopping detection through AP50 was reviewed as 59.6%, and the speed of the overtaking detection model was 70fps based on GPU, confirming that accuracy and speed are suitable for real-time wave overtopping detection."
2D-CNN 모델을 이용한 메타-전이학습 기반 부정맥 분류,2022,[],"최근 사물인터넷(IoT) 기기가 활성화됨에 따라 웨어러블 장치 환경에서 장기간 모니터링 및 수집이 가능해짐에 따라 생체 신호 처리 및 ECG 분석 연구가 활성화되고 있다. 그러나, ECG 데이터는 부정맥 비트의 불규칙적인 발생으로 인한 클래스 불균형 문제와 근육의 떨림 및 신호의 미약등과 같은 잡음으로 인해 낮은 신호 품질이 발생할 수 있으며 훈련용 공개데이터 세트가 작다는 특징을 갖는다. 이 논문에서는 ECG 1D 신호를 2D 스펙트로그램 이미지로 변환하여 잡음의 영향을 최소화하고 전이학습과 메타학습의 장점을 결합하여 클래스 불균형 문제와 소수의 데이터에서도 빠른 학습이 가능하다는 특징을 갖는다. 따라서, 이 논문에서는 ECG 스펙트럼 이미지를 사용하여 2D-CNN 메타-전이 학습 기반 부정맥 분류 기법을 제안한다.",다국어 초록 정보 없음
Using Faster-R-CNN to Improve the Detection Efficiency of Workpiece Irregular Defects,2022,[],국문 초록 정보 없음,"In the construction and development of modern industrial production technology, the traditional technology management mode is faced with many problems such as low qualification rates and high application costs. In the research, an improved workpiece defect detection method based on deep learning is proposed, which can control the application cost and improve the detection efficiency of irregular defects. Based on the research of the current situation of deep learning applications, this paper uses the improved Faster R-CNN network structure model as the core detection algorithm to automatically locate and classify the defect areas of the workpiece. Firstly, the robustness of the model was improved by appropriately changing the depth and the number of channels of the backbone network, and the hyperparameters of the improved model were adjusted. Then the deformable convolution is added to improve the detection ability of irregular defects. The final experimental results show that this method's average detection accuracy (mAP) is 4.5% higher than that of other methods. The model with anchor size and aspect ratio (65,129,257,519) and (0.2,0.5，1，1) has the highest defect recognition rate, and the detection accuracy reaches 93.88%."
Real-time Fruit Cluster Spatial Coordinates Extraction and Instance Segmentation based on Depth Mask R-CNN,2022,"['Instance segmentation', 'Fruit cluster', 'Fruit thinning']",국문 초록 정보 없음,"Fruit thinning is a key process to ensure fruit quality and yield, but manual thinning is inefficient and costly. Artificial intelligence-based agriculture can be a promising solution to this issue. In this study, we proposed a method for extracting spatial 3D coordinates and size analysis of small fruits. The method utilizes Mask R-CNN algorithm to obtain the instance segmentation information of the small fruit and fuses the depth values from the depth camera to obtain its spatial 3D coordinates. The optimal fruit was selected by comparing and analyzing the segmented area of small fruit instances. The training results of three thousand rounds showed that the small fruit detection accuracy and localization loss were 0.951 and 0.02, respectively. This method can be cooperated with arm robots to realize unmanned fruit thinning task, which can realize the intelligence and precision of agriculture."
“이거 어디서 사?” - Mask R-CNN 기반 객체 분할을 활용한 패션 아이템 검색 시스템,2022,[],국문 초록 정보 없음,"Mobile phones have become an essential item nowadays since it provides access to online platform and service fast and easy. Coming to these platforms such as Social Network Service (SNS) for shopping have been a go-to option for many people. However, searching for a specific fashion item in the picture is challenging, where users need to try multiple searches by combining appropriate search keywords. To tackle this problem, we propose a system that could provide immediate access to websites related to fashion items. In the framework, we also propose a deep learning model for an automatic analysis of image contexts using instance segmentation. We use transfer learning by utilizing Deep fashion 2 to maximize our model accuracy. After segmenting all the fashion item objects in the image, the related search information is retrieved when the object is clicked. Furthermore, we successfully deploy our system so that it could be assessable using any web browser. We prove that deep learning could be a promising tool not only for scientific purpose but also applicable to commercial shopping."
모노 카메라를 사용하는 머신 비전 시스템에서 비정형 결함을 검사하는 CNN을 훈련하기 위한 데이터 증식 방법,2022,"['Machine Vision(머신 비전)', 'Convolutional Neural Networks(합성곱 신경망)', 'Data Augmentation (데이터 증식)', 'Image Segmentation(이미지 영역 분할)']",최근 합성곱 신경망(CNN)을 머신 비전에 적용함으로써 비정형 결함의 검사에서 우수한 검사 성능을 보이고 있다. 그러나 머신 비전 시스템에서 CNN을 훈련하기 위해 충분한 양의 데이터를 모으고 정리하는 것은 상당한 시간이 필요하다. 이 문제를 해결하기 위해 본 연구는 모노 카메라를 사용하는 머신 비전 시스템에서 CNN을 사용하여 비정형 결함을 검사할 때 사용할 수 있는 데이터 증식 방법을 제안한다. 임의의 패턴에서 비정형의 결함을 검출하기 위해 제작된 DAGM 2007 데이터 중 1번 하위 클래스 데이터를 실험 데이터로 사용하였다. 결함 검출을 위한 CNN은 Mask R-CNN ResNet 50을 사용하였다. 제안하는 방법을 통해 증식한 데이터로 훈련한 CNN이 원본 회색조 이미지로 검증을 수행했을 때 원본 데이터로 훈련한 CNN에 비해 Mask mAP@0.5:0.95 기준 평균 16.73%p 높은 61.38%의 정확도를 보이는 것을 확인했다. 본 연구에서 적용한 데이터 증식 방법을 통해 모노 카메라를 활용하는 머신 비전시스템에서 우수한 성능을 가진 CNN을 훈련할 수 있다.,"Applying convolutional neural networks (CNN) to machine vision has recently exhibited excellent performance in amorphous defect inspection. However, collecting and annotating sufficient amounts of data to train CNNs in machine vision systems take considerable time. In this study, a data augmentation method is proposed that can be used to inspect amorphous defects using CNNs in machine vision systems using mono cameras. Class 1 subdata of the DAGM 2007 dataset produced to detect defects in arbitrary patterns were used as experimental data. We trained Mask R-CNN ResNet 50 for defect inspection. Through the proposed method, we found that the CNN trained with the augmented data exhibited an average accuracy of 61.38%, which is 16.73%p higher based on Mask mAP@0.5:0.95 compared to the CNN trained with the original data when validation was performed with original grayscale images. By using the data augmentation method applied in this study, CNNs in the machine vision systems using mono cameras can achieve higher inspection performance."
Hybrid CNN-SVM Based Seed Purity Identification and Classification System,2022,"['Convolutional Neural Networks (CNNs)', 'Support Vector Machines (SVM)', 'Seed Purity classification']",국문 초록 정보 없음,"Manual seed classification challenges can be overcome using a reliable and autonomous seed purity identification and classification technique. It is a highly practical and commercially important requirement of the agricultural industry. Researchers can create a new data mining method with improved accuracy using current machine learning and artificial intelligence approaches. Seed classification can help with quality making, seed quality controller, and impurity identification. Seeds have traditionally been classified based on characteristics such as colour, shape, and texture. Generally, this is done by experts by visually examining each model, which is a very time-consuming and tedious task. This approach is simple to automate, making seed sorting far more efficient than manually inspecting them. Computer vision technologies based on machine learning (ML), symmetry, and, more specifically, convolutional neural networks (CNNs) have been widely used in related fields, resulting in greater labour efficiency in many cases. To sort a sample of 3000 seeds, KNN, SVM, CNN and CNN-SVM hybrid classification algorithms were used. A model that uses advanced deep learning techniques to categorise some well-known seeds is included in the proposed hybrid system. In most cases, the CNN-SVM model outperformed the comparable SVM and CNN models, demonstrating the effectiveness of utilising CNN-SVM to evaluate data. The findings of this research revealed that CNN-SVM could be used to analyse data with promising results. Future study should look into more seed kinds to expand the use of CNN-SVMs in data processing."
Enhanced CNN Model for Brain Tumor Classification,2022,"['Multi-classification', 'CNN model', 'Grid search technic', 'Hyper parameter optimization']",국문 초록 정보 없음,"Brain tumor classification is an important process that allows doctors to plan treatment for patients based on the stages of the tumor. To improve classification performance, various CNN-based architectures are used for brain tumor classification. Existing methods for brain tumor segmentation suffer from overfitting and poor efficiency when dealing with large datasets. The enhanced CNN architecture proposed in this study is based on U-Net for brain tumor segmentation, RefineNet for pattern analysis, and SegNet architecture for brain tumor classification. The brain tumor benchmark dataset was used to evaluate the enhanced CNN model's efficiency. Based on the local and context information of the MRI image, the U-Net provides good segmentation. SegNet selects the most important features for classification while also reducing the trainable parameters. In the classification of brain tumors, the enhanced CNN method outperforms the existing methods. The enhanced CNN model has an accuracy of 96.85 percent, while the existing CNN with transfer learning has an accuracy of 94.82 percent."
A Novel Framework Based on CNN-LSTM Neural Network for Prediction of Missing Values in Electricity Consumption Time-Series Datasets,2022,"['CNN-LSTM Neural Network', 'Electricity Consumption Prediction', 'Large Gaps of Missing Values', 'Prediction of Missing Values in Time-Series Data', 'Smart Home System']",국문 초록 정보 없음,"Adopting Internet of Things (IoT)-based technologies in smart homes helps users analyze home applianceselectricity consumption for better overall cost monitoring. The IoT application like smart home system (SHS)could suffer from large missing values gaps due to several factors such as security attacks, sensor faults, orconnection errors. In this paper, a novel framework has been proposed to predict large gaps of missing valuesfrom the SHS home appliances electricity consumption time-series datasets. The framework follows a series ofsteps to detect, predict and reconstruct the input time-series datasets of missing values. A hybrid convolutionalneural network-long short term memory (CNN-LSTM) neural network used to forecast large missing valuesgaps. A comparative experiment has been conducted to evaluate the performance of hybrid CNN-LSTM withits single variant CNN and LSTM in forecasting missing values. The experimental results indicate a performancesuperiority of the CNN-LSTM model over the single CNN and LSTM neural networks."
백혈병 진단을 위한 CNN 모델 비교 분석,2022,"['Acute lymphoblastic leukemia', 'Machine Learning', 'CNN', 'InceptionV3', 'DenseNet']","급성 림프모구성 백혈병은 골수 내 미성숙 림프구 과다증식으로 인해 골수 기능이 억제되어 발생하는 급성 백혈병이다. 성인 급성 백혈병의 30% 비율을 차지하고 있으며, 소아는 항암화학요법으로 80% 이상의 완치율을 보이는 반면, 성인은 20%~50%로 저조한 생존율을 보이고 있다. 그러나 급성 림프모구성 백혈병 진단을 위한 의료영상 데이터 기반 머신러닝 알고리즘에 관한 연구가 초동 단계이다. 본 논문에서는 신속하고 정확한 진단을 위해 CNN 알고리즘모델들을 비교분석한다. 네 가지 모델을 사용하여 급성 림프모구성 백혈병 진단 모델들을 비교분석하기 위한 실험 환경을 구축하고 주어진 의료영상 데이터에 대해 정확도가 가장 우수한 알고리즘을 선택하였다. 실험 결과에 따르면 네 가지의 CNN 모델들 중에서 InceptionV3모델이 98.9%의 정확도로 가장 우수한 성능을 보였다.","Acute lymphoblastic leukemia is an acute leukemia caused by suppression of bone marrow function due to overgrowth of immature lymphocytes in the bone marrow. It accounts for 30% of acute leukemia in adults, and children show a cure rate of over 80% with chemotherapy, while adults show a low survival rate of 20% to 50%. However, research on a machine learning algorithm based on medical image data for the diagnosis of acute lymphoblastic leukemia is in the initial stage. In this paper, we compare and analyze CNN algorithm models for quick and accurate diagnosis. Using four models, an experimental environment for comparative analysis of acute lymphoblastic leukemia diagnostic models was established, and the algorithm with the best accuracy was selected for the given medical image data. According to the experimental results, among the four CNN models, the InceptionV3 model showed the best performance with an accuracy of 98.9%."
이미지 분류를 위한 딥러닝 기반 CNN모델 전이 학습 비교 분석,2022,"['Deep learning framework', 'transfer learning', 'CNN model']","최근 Tensorflow,나 Pytorch, Keras 같은 여러가지의 딥러닝 프레임워크 모델들이 나왔다. 또한 이미지 인식에 Tensorflow, Pytorch, Keras 같은 프레임 워크를 이용하여 CNN(Convolutional Neural Network)을 적용시켜 이미지 분류에서의 최적화 모델을 주로 이용한다. 본 논문에서는 딥러닝 이미지 인식분야에서 가장 많이 사용하고 있는 파이토치와 텐서플로우의 프레임 워크를 CNN모델에 학습을 시킨 결과를 토대로 두 프레임 워크를 비교 분석하여 이미지 분석할 때 최적화 된 프레임워크를 도출하였다.","Recently, various deep learning framework models such as Tensorflow, Pytorch, Keras, etc. have appeared. In addition, CNN (Convolution Neural Network) is applied to image recognition using frameworks such as Tensorflow, Pytorch, and Keras, and the optimization model in image classification is mainly used. In this paper, based on the results of training the CNN model with the Paitotchi and tensor flow frameworks most often used in the field of deep learning image recognition, the two frameworks are compared and analyzed for image analysis. Derived an optimized framework."
LIF/IF Model을 활용한 SNN/CNN Accumulator의 H/W 구현,2022,"['SNN', 'IF', 'LIF', 'FPGA']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 영상기반 토지이용현황조사에 관한 연구,2022,"['CNN(Convlutional Neural Network)', '토지이용현황', '영상기반 토지이용현황조사', '조사의 자동화', '조사항목 체계 재분류', 'CNN(Convolutional Neural Network)', 'Land Use Status', 'Image-based Land Use Status Survey', 'Automation of survey', 'Reclassification of survey items system']","본 연구의 목적은 효율적인 토지이용현황조사를 위해 현재 수행 중인 토지이용현황과 관련된 조사들을 분석하여 조사항목의 중복성을 검토하고 실증분석을 통해 조사항목의 자동화 방안을 제시하는 것이다. 이러한 연구의 목적을 달성하기 위하여 조사항목의 중복성과 조사의 자동화 측면으로 한정하여 수행하였다. 현행 토지이용현황과 관련된 조사들은 서로 중복된 조사항목을 개별적으로 수행하고 있어 행정력이 낭비되는 비효율적인 형태를 보이고 있다. 또한, 조사하는 방법도 직접 현장에 방문하는 방식과 위성이나 항공, 드론으로 얻어진 영상을 기반으로 하는 방식 등 각기 다른 방식으로 수행되고 있어 조사유형에 따라 상이한 결과가 나타날 수 있는 불안요소를 지니고 있으며, 특히 현장조사 방식의 경우 접근이 어려운 지역에 대한 정확한 조사가 진행되기 어렵다. 따라서 본 연구의 실험결과와 마찬가지로 중복조사 항목을 재분류하여, 하나의 조사항목 체계로 통합하고 연계 및 공유할 수 있는 환경을 구축해야 한다. 또한, 효율적인 조사 수행을 위해 영상기반의 조사가 활성화되어야 한다. 영상기반 토지이용현황조사가 이루어진다면 유사한 패턴을 보이는 조사항목에 대해 CNN(Convolutional Neural Network) 기법을 활용하여 자동으로 조사할 수 있는 방안도 함께 고려할 수 있을 것이다.","This study aims to analyze the surveys related to the current land use status for an efficient land use status survey, review the redundancy of survey items, and suggest a method for automating survey items through empirical analysis. In order to achieve the purpose of this study, it was carried out by limiting the redundancy of the survey items and the aspect of automation of the survey. Surveys related to the current state of land use show an inefficient form of wasting administrative power as they individually perform overlapping survey items. In addition, since the method of survey is carried out in different ways, such as a method of visiting the site directly and a method based on images obtained by satellite, air, or drone, there is an anxiety factor that may result in different results depending on the type of survey, In particular, in the case of an on-site survey method, it is challenging to conduct an accurate survey in an area where access is difficult. Therefore, as with the experimental results, it is necessary to reclassify the duplicated survey items to establish an environment that can be integrated, linked, and shared into a single survey item system. In addition, the image-based survey should be activated for an efficient survey. For example, suppose an image-based land use status survey is conducted, Then, a method for automatically surveying items showing a similar pattern using CNN(convolutional neural network) method may be considered."
CNN을 이용한 EES 유효성 검증에 관한 연구,2022,"['CNN(Convolutional Neural Network)', 'Delta-V', 'EES(Energy Equivalent Speed)', 'PC-Crash']",국문 초록 정보 없음,다국어 초록 정보 없음
초해상화 기반 CNN을 이용한 군사용 SAR 자동표적인식 모델 연구,2022,"['Convolutional Neural Network', 'Automatic Target Recognition', 'Synthetic Aperture Radar', 'Super-Resolution']",국문 초록 정보 없음,"Herein, we propose employing the super-resolution-based convolutional neural network (CNN) to design the automatic target recognition (ATR) of military synthetic aperture radar (SAR) images. Previous SAR ATR methods showed a good recognition performance with a low depression angle, but poor performance with a high depression angle. In a warfighting environment, good recognition performance is required even with a high depression angle. To address this issue, we combine the super-resolution method and the CNN. In comparison with the conventional VGGnet with a high depression angle, the proposed super-resolution-based CNN showed a 3%-4% improvement in accuracy. The MSTAR SAR dataset was utilized for validation."
MFCC 기반 환경음 분류 CNN에서 커널 사이즈와 풀링 레이어에 의한 성능분석,2022,"['인공지능', '딥러닝', '합성곱 신경망', '파이썬', '소리 분류', 'Artificial Intelligence', 'Deep Learning', 'Convolution Neural Network', 'Python', 'Sound classification']",국문 초록 정보 없음,"Research on audio classification is being actively conducted for the improved life of the deaf and elderly, and for the development of audio-related industries. CNN(Convolutional Neural Network) is one of the neural networks used for audio classification, and is mainly used to classify images by learning the characteristics of input data on its own. Kernel size and pooling are important variables that affect the setting of the number of parameters in the CNN. This paper extracts MFCC from UrbanSound8K which is an audio dataset widely used in environmental sound classification studies and makes it learn on CNN. Under three CNN scenarios, we changed the kernel size and the number of pooling layers in each scenario, and tried to find out the relationship between the accuracy and parameter number. Through experiments, it was confirmed that both accuracy and parameters improved as the kernel size and the number of pooling layers increased."
근전도 신호 기반 Multi-Stream CNN 및 경험적 모드 분해를 이용한 사용자 인식,2022,"['electromyogram signal', 'personal recognition', 'empirical mode decomposition', 'multi-stream convolutional neural network']",국문 초록 정보 없음,"The Electromyogram(EMG) signal is a biosignal generated during contraction of the skeletal muscle, and different signal waveforms are generated according to the performed motion. Accordingly, it is possible to solve the problem that the registration information of the existing personal recognition method cannot be changed. In this paper, we propose a personal recognition method using EMG signal-based Empirical Mode Decomposition(EMD) and multi-stream CNN. The proposed method decomposes the EMG signal into an Intrinsic Mode Function(IMF) using EMD for increase feature data. The decomposed IMF 1-4 is used as input data to the designed multi-stream CNN to perform personal recognition. As a result of the experiment using Ninapro DB2, which is benchmarking EMG data, the method using the multi-stream CNN and the IMF showed an accuracy of 98.3%, which was 1% higher than the existing study using CNN."
TANFIS Classifier Integrated Efficacious Aassistance System for Heart Disease Prediction using CNN-MDRP,2022,"['Convolution neural network (CNN)', 'TANFIS', 'CNN-MDRP', 'Heart disease prediction', 'Accuracy', 'Clinical data analysis', 'data mining']",국문 초록 정보 없음,"A dramatic rise in the number of people dying from heart disease has prompted efforts to find a way to identify it sooner using efficient approaches. A variety of variables contribute to the condition and even hereditary factors. The current estimate approaches use an automated diagnostic system that fails to attain a high level of accuracy because it includes irrelevant dataset information. This paper presents an effective neural network with convolutional layers for classifying clinical data that is highly class-imbalanced. Traditional approaches rely on massive amounts of data rather than precise predictions. Data must be picked carefully in order to achieve an earlier prediction process. It's a setback for analysis if the data obtained is just partially complete. However, feature extraction is a major challenge in classification and prediction since increased data increases the training time of traditional machine learning classifiers. The work integrates the CNN-MDRP classifier (convolutional neural network (CNN)-based efficient multimodal disease risk prediction with TANFIS (tuned adaptive neuro-fuzzy inference system) for earlier accurate prediction. Perform data cleaning by transforming partial data to informative data from the dataset in this project. The recommended TANFIS tuning parameters are then improved using a Laplace Gaussian mutation-based grasshopper and moth flame optimization approach (LGM<sup>2</sup>G). The proposed approach yields a prediction accuracy of 98.40 percent when compared to current algorithms."
CNN 모델을 이용한 동영상 프레임 화질 판단,2022,"['Video Frame', 'Quality Estimation', 'CNN', 'Deep Learning']",동영상의 프레임 화질 판단을 통하여 동영상 촬영 장치의 성능과 품질을 추정하거나 동영상 촬영 시점의 환경을 유추해 볼 수 있다. 본 논문에서는 CNN 기반의 딥 러닝 모델을 이용해 동영상 프레임에 대해서 고품질 및 저품질의 화질을 판단하는 알고리즘을 제안한다. OpenCV를 이용하여 동영상으로부터 학습과 평가를 위한 프레임을 추출하였고 실험을 수행하였다. 이를 통하여 제안한 알고리즘이 99.29%의 높은 정확도를 갖고 프레임 화질을 판단하는 것을 보였다.,"Estimating the frame quality of a video can be used to measure the performance and quality of a video recording devices or to infer the environment at the time of recording the video. In this paper, we propose an algorithm to estimate the high or low quality of video frames using a CNN-based deep learning model. Experiments are performed using frames extracted using OpenCV for learning and evaluation. The results show that the proposed algorithm can estimate frame quality with a high accuracy of 99.29%."
CNN-based Adaptive K for Improving Positioning Accuracy in W-kNN-based LTE Fingerprint Positioning,2022,"['LTE fingerprint positioning', 'RSRP measurement', 'W-kNN', 'CNN', 'adaptive K']",국문 초록 정보 없음,"In order to provide a location-based services regardless of indoor or outdoor space, it is important to provide position information of the terminal regardless of location. Among the wireless/mobile communication resources used for this purpose, Long Term Evolution (LTE) signal is a representative infrastructure that can overcome spatial limitations, but the positioning method based on the location of the base station has a disadvantage in that the accuracy is low. Therefore, a fingerprinting technique, which is a pattern recognition technology, has been widely used. The simplest yet widely applied algorithm among Fingerprint positioning technologies is k-Nearest Neighbors (kNN). However, in the kNN algorithm, it is difficult to find the optimal K value with the lowest positioning error for each location to be estimated, so it is generally fixed to an appropriate K value and used. Since the optimal K value cannot be applied to each estimated location, therefore, there is a problem in that the accuracy of the overall estimated location information is lowered. Considering this problem, this paper proposes a technique for adaptively varying the K value by using a Convolutional Neural Network (CNN) model among Artificial Neural Network (ANN) techniques. First, by using the signal information of the measured values obtained in the service area, an image is created according to the Physical Cell Identity (PCI) and Band combination, and an answer label for supervised learning is created. Then, the structure of the CNN is modeled to classify K values through the image information of the measurements. The performance of the proposed technique is verified based on actual data measured in the testbed. As a result, it can be seen that the proposed technique improves the positioning performance compared to using a fixed K value."
CNN-based Approach for Source Localization of an Engineering-scale Radioactive Waste Disposal Concrete,2022,"['Source localization', 'Radioactive waste disposal concrete', 'Convolutional neural network', 'Acoustic emission']",국문 초록 정보 없음,"Source localization technique using acoustic emission (AE) has been widely used to track the accurate location of the damaged structure. The principle of localization is based on signal velocity and the time difference of arrival (TDOF) obtained from different signals for the specific source. However, signal velocity changes depending on the frequency domain of signals. In addition, the TDOF is dependent on the signal threshold which affects the prediction accuracy. In this study, a convolutional neural network (CNN)-based approach is used to overcome the existing problem. The concrete block corresponding to 1.3×1.3×1.3 m size is prepared according to the mixing ratio of Wolseong low-to-intermediate level radioactive waste disposal concrete materials. The source is excited using an impact hammer, and signals were acquired through eight AE sensors attached to the concrete block and a multi-channel AE measurement system. The different signals for a specific source are time-synchronized to obtain TDOF information and are transformed into a time-frequency domain using continuous wavelet transform (CWT) for consideration of various frequencies. The developed CNN model is compared with the conventional TDOF-based method using the testing dataset. The result suggests that the CNN-based method can contribute to the improvement of localization performance."
듀얼 스트림 CNN-LSTM 아키텍처를 사용한 태양광 발전 예측,2022,"['Solar power prediction', 'CNN', 'LSTM', 'Dual stream network']",국문 초록 정보 없음,"The integration of solar energy with a power system brings great economic and environmental benefits. However, the high penetration of solar power challenges the operation and planning of the existing power system owing to the intermittence and randomicity of solar power generation. Achieving accurate prediction for power generation is important to provide balanced electric energy for end-users. Therefore, in this paper, we introduce a deep learning-based dual stream Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) network to learn spatial patterns using CNN and temporal features via the LSTM network. These features are then fused via a concatenation layer and then feed forward to Dense layers for optimal features selection and future solar power prediction. The performance of the proposed model is evaluated on benchmark datasets and achieved a new state-of-the-art on these datasets."
Snoring Sound Classification Using 1D-CNN Model Based on Multi-Feature Extraction,2022,"['Sound recognition', 'Snoring sound', 'CNN', 'Multi-feature extraction']",국문 초록 정보 없음,"Sound is an essential element of human relationships and communication. The sound recognition process involves three phases: signal preprocessing, feature extraction, and classification. This paper describes research on the classification of snoring data used to determine the importance of sleep health in humans. However, current sound classification methods using deep learning approaches do not yield desirable results for building good models. This is because some of the salient features required to sufficiently discriminate sounds and improve the accuracy of the classification are poorly captured during training. In this study, we propose a new convolutional neural network (CNN) model for sound classification using multi-feature extraction. The extracted features were used to form a new dataset that was used as the input to the CNN. Experiments were conducted on snoring and non-snoring datasets. The accuracy of the proposed model was 99.7% for snoring sounds, demonstrating an almost perfect classification and superior results compared to existing methods."
Detection of fake news using deep learning CNN–RNN based methods,2022,"['Fake news detection', 'Deep learning', 'CNN', 'Bidirectional LSTM', 'ResNet']",국문 초록 정보 없음,"Fake news is inaccurate information that is intentionally disseminated for a specific purpose. If allowed to spread, fake news can harm the political and social spheres, so several studies are conducted to detect fake news. This study uses a deep learning method with several architectures such as CNN, Bidirectional LSTM, and ResNet, combined with pre-trained word embedding, trained using four different datasets. Each data goes through a data augmentation process using the back-translation method to reduce data imbalances between classes. The results showed that the Bidirectional LSTM architecture outperformed CNN and ResNet on all tested datasets."
Intelligent identification of mortar void in ballastless slab track using the wheelset acceleration combined with CNN-SVM,2022,"['Ballastless slab track', 'Mortar void identification', 'Local mean decomposition', 'Hybrid CNN-SVM classifier']",국문 초록 정보 없음,"Mortar void is a hidden defect in ballastless slab track difficult to be efficiently identified by traditional detection methods. This paper is dedicated to proposing a new detection method to identify the mortar void position and length using the vehicle response combined with the hybrid convolutional neural network-support vector machine (CNN-SVM) classifier. The vertical wheelset accelerations with different mortar void conditions are collected from a vehicle-track coupled dynamics simulation model. The first components decomposed from wheelset accelerations by local mean decomposition and their envelopes are utilized as the training data due to their sensitivity to mortar void. To improve the identification precision, the scope descent method is proposed to determine the range influenced by mortar void (IMVR) and samples are labeled according to IMVR. Meanwhile, identification results are post processed based on the mortar void characteristics. The results show that over 90 % mortar void conditions with the length of 0.65 m are detected correctly and the identification has a higher precision with the mortar void length greater than 0.95 m. The proposed technology of mortar void detection using the wheelset accelerations with the hybrid CNN-SVM classifier provides reference for engineering application, which is of great significance to relieve the pressure of health monitoring of railway track."
CNN 기반 사과의 품질 등급 분류를 위한 영향력 있는 색상 채널 탐색,2022,"['딥러닝', '사과', '품질 등급', '분류', 'Deep Learning', 'Convolution Neural Network', 'Apple', 'Quality Grade', 'Classification', 'CNN']",국문 초록 정보 없음,"During the distribution process until the sale of agricultural products, the process of determining the appearance quality of agricultural products is mainly conducted with the naked eye, resulting in uneven quality problems. In order to reduce the decline in merchantability and economic loss due to quality problems, it was intended to reduce errors in the classification process among the quality discrimination processes. To this end, a CNN-based quality grade classification study was conducted on Fuji apples, and a single color that determines the classification of quality grades among color images consisting of three channels (Red, Green, and Blue) was sought. In order to check the influence of each color, eight model structures with different numbers of layers and convolution filters were set, and experiments were conducted on five channels (RGB, Red, Green, Blue and Gray). Through this study, it was confirmed that the Blue channel is the most stable color and influential color channel in the classification of apple quality grades."
CNN-based fire detection method on autonomous ships using composite channels composed of RGB and IR data,2022,"['Autonomous ship Fire safety', 'Fire detection', 'RGB-IR', 'CNN', 'Composite channel data']",국문 초록 정보 없음,"Since fires grow exponentially after an outbreak, it is crucial to extinguish them quickly. In the case of fires occurring on commercial ships and naval vessels, smoke and heat in the narrow enclosed compartments of the ships make it difficult to extinguish fires, threatening human safety, and causing massive property damage. So-called autonomous ships are operated without crew members in charge of fire suppression. Therefore, it is crucial to improve the performance and reliability of the automatic fire detection and suppression system. However, the standard fire detection system installed on ships is not adequate for the level of fire risk. Existing fire detection methods still have false alarm problems, and it takes a long time for heat and smoke from the fire to reach the detector. In this study, the use of combined channel data (RGB-IR) is proposed as an image-based fire detection method applicable to ships. In nature, many animals obtain multiple wavelength information, which is advantageous for hunting or risk preparedness in a wild environment. In this way, it is assumed that both the characteristics of RGB data in the visible area and IR data in the infrared area may be utilized through the combined channel data. A fire detection model with composite channel data input was built using deep learning with a Convolution Neural Network (CNN), a fire detection model using composite channel data input was constructed, and hyper-parameters were tuned during the training process to determine the optimal model and compare it with the existing RGB and IR models, respectively. Compared with the model using only conventional RGB or IR data, the fire detection accuracy of the model using RGB-IR combined channel data increased and the false detection rate decreased."
CNN-32DC: An improved radar-based drone recognition system based on Convolutional Neural Network,2022,"['Constant false alarm rate', 'Doppler effect', 'Drone detection', 'Micro-doppler signal processing', 'Radar']",국문 초록 정보 없음,"This paper proposed a system that will guard infrastructures against incoming threats from drones by detecting it with the use of a radar device-based detection scheme. The database acquired, named Real Doppler RAD-DAR (Radar with Digital Array Receiver) is constructed by a Microwave and Radar Group. The radar used uses a Frequency Modulated Continuous Wave (FMCW) on an 8.75 GHz based frequency band with a BW of 500 MHz. The proposed Convolutional Neural Network (CNN), CNN-32DC is varied with different number of filters, combination layers, and number of feature extraction blocks, the preference that will give the most accurate result was selected and compared with different machine learning and classification learning algorithms gained an accuracy that exceeds other networks with less processing time."
긍정과 부정 이미지 기반 데이터 편향에 따른 CNN모델의 차이 연구,2022,"['CNN models', 'CNN visualization', 'Data bias', 'Emotional face detection']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN-Based Traffic Classification in SDN-IIoT,2022,"['Convolutional Neural Network (CNN)', 'SDN', 'Traffic Classification']",국문 초록 정보 없음,"The numerous of Industrial Internet of Things (IIoT) devices with varying QoS requirements needed accurate traffic classification to help improve their work efficiency and quality of service. The centralized architecture of SDN help in simplifying network management. Applying traffic classification in SDN architecture help manage and improve the performance network. This paper proposes a traffic classification model using CNN, which could perform in the imbalanced dataset and employ feature selection to improve the performance. The simulation work is verified based on ”ISCX VPN-nonVPN” dataset. The simulation result showed that the proposed algorithm achieves an accuracy of 98.34% and 0.048 ms of computing time."
CNN 기반 동물상 인식 모델 구현,2022,[],"최근 딥러닝 기반의 이미지 분류는 다양한 산업과 서비스에서 활용되고 있으며, 이미지 인식을 통한 다양한 테스트가 SNS를 통해 인기를 끌고 있다. CNN은 대표적인 이미지 분류를 위한 신경망 모델로 본 연구에서는 사진속의 얼굴에 대해 동물상 인식을 위하여 동물 얼굴 이미지 및 각 동물상을 대표하는 연예인의 이미지를 수집하고, CNN 기반의 동물상 인식 모델을 구현하였다.",다국어 초록 정보 없음
CNN-based Human Recognition and Extended Kalman Filter-based Position Tracking Using 360° LiDAR,2022,"['LiDAR (라이다)', 'CNN machine learning (CNN 머신러닝)', 'Extended kalman filter (확장 칼만 필터)', 'Occupied grid map (점유 격자 지도)']",국문 초록 정보 없음,다국어 초록 정보 없음
Using CNN- VGG 16 to detect the tennis motion tracking by information entropy and unascertained measurement theory,2022,"['computer vision science', 'deep learning (DP)', 'information entropy', 'unascertained measurement theory']",국문 초록 정보 없음,"Object detection has always been to pursue objects with particular properties or representations and to predict details on objects including the positions, sizes and angle of rotation in the current picture. This was a very important subject of computer vision science. While vision-based object tracking strategies for the analysis of competitive videos have been developed, it is still difficult to accurately identify and position a speedy small ball. In this study, deep learning (DP) network was developed to face these obstacles in the study of tennis motion tracking from a complex perspective to understand the performance of athletes. This research has used CNN-VGG 16 to tracking the tennis ball from broadcasting videos while their images are distorted, thin and often invisible not only to identify the image of the ball from a single frame, but also to learn patterns from consecutive frames, then VGG 16 takes images with 640 to 360 sizes to locate the ball and obtain high accuracy in public videos. VGG 16 tests 99.6%, 96.63%, and 99.5%, respectively, of accuracy. In order to avoid overfitting, 9 additional videos and a subset of the previous dataset are partly labelled for the 10-fold cross-validation. The results show that CNN-VGG 16 outperforms the standard approach by a wide margin and provides excellent ball tracking performance."
KNN과 CNN을 이용한 UWB CIR 신호 LOS/NLOS 분류에 대한 연구,2022,[],본 논문은 UWB CIR을 이용하여 LOS 신호와 NLOS 신호를 분류하는 모델을 제안한다. KNN과 CNN 알고리즘을 사용한 4가지 모델을 이용하여 LOS 신호와 NLOS 신호를 분류한다. 시뮬레이션을 통해 각 모델의 분류 정확도(Accuracy)를 비교한다. UWB CIR 데이터는 주파수 해석에 용이한 Morlet Wavelet Transform을 이용하여 2차원 이미지로 변환 후 사용된다. KNN을 사용한 일부 모델에서는 PCA와 t-SNE 차원 축소 기법을 활용하였다. 4가지 모델을 비교해본 결과 CNN과 KNN을 결합한 분류 모델이 분류 성능이 80.05%로 가장 높은 것을 확인하였다.,다국어 초록 정보 없음
A Multi-CNN Model Interacting Contents and Ratings for Predicting Review Helpfulness,2022,"['Review helpfulness prediction', 'online review', 'star ratings', 'content-rating interaction']",국문 초록 정보 없음,"With the growth of the e-commerce industry, online consumer reviews significantly impact the consumer purchase decision process. Since the consistently increasing number of reviews, the consumer can face an information overload problem. Thus, the consumers have a challenge exploring the information they need. Thus, we argue that predicting the review helpfulness becomes significant. When predicting review helpfulness, since the review contents and star ratings are information written from the same consumer experience, the consistency of the review contents and star ratings is essential. Previous studies predict review helpfulness by considering review content and star ratings simultaneously. However, such an approach has limitations in the representation capacity of star ratings and the capture of the interaction between review content and star ratings. The current study proposed a CNN-CRI mechanism to address the limitations of the previous study. To evaluate the proposed methodology, we utilized real-world online review data from Amazon.com. The results show that our study model indicates better performance than the state-of-the-art approach."
SpeedyCNet : 계층적 학습기의 통과 및 단계적 분류를 통한 CNN 모델의 훈련속도 향상,2022,"['딥러닝', 'CNN모델', '훈련속도 향상', '이미지 분류', '모델 아키텍처', 'Deep learning', 'CNN Model', 'Acceleration of training time', 'Classification', 'Architecture']",국문 초록 정보 없음,다국어 초록 정보 없음
미국 미디어들의 미래 뉴스 전쟁… 우리의 미래는? - 팩트 뉴스로 회귀한 CNN과 뉴미디어 뉴스 포맷 개발에 올인하는 NBC뉴스 -,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
Normal data based rotating machine anomaly detection using CNN with self-labeling,2022,"['anomaly detection', 'convolutional neural network', 'deep learning', 'pretext task', 'self-labeling']",국문 초록 정보 없음,"To train deep learning algorithms, a sufficient number of data are required. However, in most engineering systems, the acquisition of fault data is difficult or sometimes not feasible, while normal data are secured. The dearth of data is one of the major challenges to developing deep learning models, and fault diagnosis in particular cannot be made in the absence of fault data. With this context, this paper proposes an anomaly detection methodology for rotating machines using only normal data with self-labeling. Since only normal data are used for anomaly detection, a self-labeling method is used to generate a new labeled dataset. The overall procedure includes the following three steps: (1) transformation of normal data to self-labeled data based on a pretext task, (2) training the convolutional neural networks (CNN), and (3) anomaly detection using defined anomaly score based on the softmax output of the trained CNN. The softmax value of the abnormal sample shows different behavior from the normal softmax values. To verify the proposed method, four case studies were conducted, on the Case Western Reserve University (CWRU) bearing dataset, IEEE PHM 2012 data challenge dataset, PHMAP 2021 data challenge dataset, and laboratory bearing testbed; and the results were compared to those of existing machine learning and deep learning methods. The results showed that the proposed algorithm could detect faults in the bearing testbed and compressor with over 99.7% accuracy.In particular, it was possible to detect not only bearing faults but also structural faults such as unbalance and belt looseness with very high accuracy. Compared with the existing GAN, the autoencoder-based anomaly detection algorithm, the proposed method showed high anomaly detection performance."
CNN을 이용한 eVTOL Tiltrotor 항공기의 Flight Phase 식별,2022,"['CNN(합성곱 신경망)', 'Data Imagification(데이터 이미지화)', 'Tiltrotor(틸트로터)', 'Flight Phase Identification(비행 단계 식별)']",국문 초록 정보 없음,다국어 초록 정보 없음
고무제품 혼련 공정에서의 CNN기반 품질 지표 예측 모델 개발,2022,"['CNN', 'Mixing Process', 'Quality Indicator Prediction', 'Time Series Data']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN-LSTM 기반 낙상 감지 시스템 구현,2022,"['Deep learning', 'CNN', 'RNN', 'LSTM', 'Fall Detection']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 안저 영상의 녹내장 검출,2022,"['Deep Learning', 'CNN', 'Pattern Recognition', 'Fundus Image Recognition']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN의 기초와 응용,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN-TDA Net: Enhancing Convolutional Neural Networks for Classification of Transient and Bogus Using Topological Data Analysis,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
연령별 학습 데이터와 CNN의 감정 분류 정확도,2022,"['CNN architecture', 'Emotional classification', 'Kid emotions', 'Adult emotions']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 익형 공력특성 예측,2022,"['전산유체역학(CFD)', '심층학습(Deep Learning)', '합성곱 신경망(CNN)', '익형(airfoil)', '공력특성(Aerodynamics characteristics)']",국문 초록 정보 없음,"Research on airfoils has been steadily studied in various fields from the aerospace to renewable energy. An interest in the marine energy has been enhanced related to the renewable energy, and among them the design of offshore wind turbines has been attracting attention. The optimized design of airfoils is essential to increase the performance and efficiency of wind turbines. The aerodynamic characteristics of airfoils at a low angle of attack (AoA) can be obtained from airfoil database, but results of that near the stall with large AoA show large deviation. Hence, it is needed to perform repetitive analysis of various shapes near the stall, which results to high cost and time. To overcome this, the artificial intelligence is used and combined with numerical simulations. In this study, three types of airfoils are chosen, which are S809, S822, and SD7062 used in wind turbines. As a Convolutional Neural Network model, we propose a neural network model that combines VGG16 and U-Net. Learning data are constructed by extracting pressure fields and aerodynamic characteristics through numerical analysis of the two-dimensional shape for the proper shape. The number of constructed datasets used in the present study is 5187. The pressure field for a new airfoil is predicted using the proposed model, and the lift and drag coefficients of this airfoil are predicted."
CNN-TDA Net : Construction of Training Image Sets for Real/bogus Object Classification with Artificial Intelligence,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN기반 스마트홈 엣지디바이스 사운드 품질 분류 기술연구,2022,"['Smart-Home', 'Edge Device', 'Sound classification', 'deep-learning', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
"CNN, LSTM기반 오토인코더를 이용한 공정 사이클 이상 패턴 탐지",2022,[],현재 공정에서의 이미지 이상 탐지는 프레임 1개의 단위로 실시된다. 실제 제조 현장에서는 PLC의 Tag data를 통해 전체 공정 영상을 사이클 단위로 수집할 수 있다. 따라서 본 논문에서는 한 개의 프레임에 대한 이상 탐지보단 프레임 집합체인 사이클을 하나의 데이터 단위로 보아 사이클에 대한 이상 탐지를 하고자 한다. CNN을 이용하여 사이클에 포함된 사진들의 특징을 추출하였으며 이후 LSTM Autoencoder 통해 사이클의 이상 패턴을 탐지할 수 있었다. 이러한 결과가 이후 공정에서 예상하지 못한 문제를 파악하는데 기여하길 기대한다.,다국어 초록 정보 없음
CNN기반 딥러닝을 통한 터보펌프 내 이익 인듀서 캐비테이션 불안정성 진단,2022,"['Turbo Pump Inducer(터보 펌프 인듀서)', 'Cavitation Instability(캐비테이션 불안정성)', 'Deep Learning(딥러닝)', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN-LSTM을 사용한 긴 주기 펄스 레이다 신호 속성 분류,2022,"['Radar Signal Classification', 'CNN', 'LSTM', 'Pulsed Radar Signal Attributes']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN기반 Anomaly Detection 기법을 적용한 항공기 기체표면 스크류 Lightning 탐지 모델 개발,2022,"['Anomaly Detection(이상 탐지)', 'Lightning Damage(낙뢰 손상)', 'CNN(Convolutional Neural Network', '합성곱 신경망)', 'Normality Score(정상 지수)']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 익형 공력특성 예측,2022,"['전산유체역학(CFD)', '심층학습(Deep Learning)', '합성곱 신경망(CNN)', '익형(airfoil)', '공력특성(Aerodynamics characteristics)']",국문 초록 정보 없음,"Research on airfoils has been steadily studied in various fields from the aerospace to renewable energy. An interest in the marine energy has been enhanced related to the renewable energy, and among them the design of offshore wind turbines has been attracting attention. The optimized design of airfoils is essential to increase the performance and efficiency of wind turbines. The aerodynamic characteristics of airfoils at a low angle of attack (AoA) can be obtained from airfoil database, but results of that near the stall with large AoA show large deviation. Hence, it is needed to perform repetitive analysis of various shapes near the stall, which results to high cost and time. To overcome this, the artificial intelligence is used and combined with numerical simulations. In this study, three types of airfoils are chosen, which are S809, S822, and SD7062 used in wind turbines. As a Convolutional Neural Network model, we propose a neural network model that combines VGG16 and U-Net. Learning data are constructed by extracting pressure fields and aerodynamic characteristics through numerical analysis of the two-dimensional shape for the proper shape. The number of constructed datasets used in the present study is 5187. The pressure field for a new airfoil is predicted using the proposed model, and the lift and drag coefficients of this airfoil are predicted."
CNN을 활용한 램프 점등 이미지 균일도 정량화 방안 연구,2022,"['Lamp(램프)', 'Unifomiity(균일도)', 'Deep Learning(딥러닝)', 'Convolutional Neural Network(합성곱 신경망)']",국문 초록 정보 없음,"The lighting image of a car lamp is one of the important factors influencing the exterior design of a car, but it is difficult to find an evaluation method for quantitatively evaluating the lighting image. If there is a method of quantitatively evaluating how uniform the lighting image of the lamp is, it will be easy to manage the quality of the lighting image. This study attempted to determine whether it is possible to quantitatively evaluate the lighting image data of a car lamp using a deep learning algorithm that learned a good lighting image and a poor lighting image of a car lamp using deep learning of image data. CNN algorithms were used for deep learning of image data, and learning was conducted using images of various automobile position and tail lamp lighting. The learned algorithm classified good lighting images and poor lighting image data with a probability of more than 90% for the new lighting image data, and was able to provide lighting uniformity scores for the image data. The method of learning deep learning algorithms could help develop evaluation methods that are difficult to develop in conventional ways or quantitative evaluation methods for complex data."
Mask R-CNN을 활용한 패션 아이템 분류 모델구현에 관한 연구,2022,[],"본 논문에서는 패션디자이너를 위한 빠르게 변화하는 트렌드 분석을 위한 패션 아이템별 세부 컨포넌트 이미지 분류 알고리즘을 제안한다. COVID-19 환경으로 인하여 AI 기반 쇼핑몰에 대한 연구가 활발하게 진행중이다. 하지만 기존의 키워드 검색과 사용자 서핑 행위 기반 개인 맞춤형 스타일 추천으로는 트렌드 분석에 한계가 있다. 본 연구는 다양한 전처리 방식을 비교분석하여 선정한 MASK-RCNN을 사용하여 객체를 추출하고, CNN모델을 통해 분류하는 모델을 개발하였으며 세부적으로 다양한 패션 아이템에 대한 세부 컨포넌트 단위의 분류를 진행하였고, 예측 모델을 이용한 검증을 통해 구현모델의 성능을 분석하였다.",다국어 초록 정보 없음
걸음걸이와 CNN을 활용한 스마트폰 인증 시스템,2022,"['human gait', 'convolutional neural network', 'authentication']",국문 초록 정보 없음,"In a society centered on hyper-connectivity, as important as information sharing is that each piece of information must be viewed only by legitimate users. In this study, we propose a smartphone authentication system based on human gait, breaking away from the traditional authentication method. After learning human gait with CNN, it is mounted on a smartphone to determine whether the user is a legitimate user by walking for 7 seconds while carrying the smartphone. Accuracy, precision, recall, F1-score, and EER were applied as evaluation indicators of the model proposed in this study. As a result, accuracy, precision, recall, and F1-score all achieved an average of 95% or more, and the average EER was 0.048. What the system analysis results show is that the system proposed in this study has high reliability and low error rate. As a result, this study showed the possibility that human gait could be used as a new user authentication method."
Multi-Input CNN을 활용한 UDP 기반의 암호화 트래픽 분류,2022,[],"최근 네트워크 기술의 발전과 네트워크 내 발생하는 여러 가지의 보안 이슈로 인해 다양한 응용에서 암호화 트래픽을 사용하는 추세이다. 암호화 기술은 SSL 프로토콜 개발을 시작으로 꾸준히 발전하였으며, 현재는 TLS 1.2가 가장 널리 사용되고 있다. 하지만 기존의 암호화 기술은 특정 공격에 대하여 보안이 취약하며, 연결 속도가 느리다는 문제점이 있다. 이러한 문제점을 해결하기 위해서 구글은 기존의 TCP 기반의 암호화 프로토콜 대신 UDP 기반의 암호화 프로토콜인 QUIC을 개발하여 사용하고 있다. 암호화 트래픽에 대한 연구는 이전부터 활발하게 진행되었지만, 대부분의 연구는 TCP 기반의 암호화 트래픽을 대상으로 수행되어왔다. 따라서 본 논문에서는 TCP 기반의 아닌 UDP 기반의 QUIC를 대상으로 CNN을 활용한 암호화트래픽 분류 모델을 설계한다. 또한, 설계된 모델을 실제로 수집한 QUIC 트래픽에 적용하여 해당 방법론의 타당성을 검증한다.",다국어 초록 정보 없음
시분할 CNN-LSTM 기반의 시계열 진동 데이터를 이용한 회전체 기계 설비의 이상 진단,2022,"['Anomaly Detection', 'Fault Diagnosis', 'CNN-LSTM']",국문 초록 정보 없음,다국어 초록 정보 없음
A 1D CNN-LSTM using Wav2vec 2.0 for Violent Scene Discrimination,2022,"['Violent scene discrimination', 'Wav2vec 2.0', 'Audio signal processing']",국문 초록 정보 없음,"In this paper, an effective system for discriminating violent scenes in movies from audio signals alone is proposed. The technology for automatic discrimination of violent scenes is one of the most crucial aspects of media filtering, protecting users from undesired media. Previous studies have conducted violent scene discrimination using a mel spectrogram and 2D convolutional neural networks (CNNs); however, the mel spectrogram cannot extract mutual information from audio, and 2D CNNs are unsuitable for audio. Therefore, these models do not yield good performance. The system proposed in this paper extracts audio features by using Wav2vec 2.0, which can extract mutual information from audio. The features of the extracted audio are inputted to a 1D CNN and long short-term memory (LSTM), which are algorithms suitable for audio, and violent scenes are discriminated through fully connected and softmax layers. To evaluate the proposed system, violent scenes are discriminated using the Violent Movie Scenes Dataset (VMD). As a result, the accuracy of the proposed system when discriminating violent scenes is 96.25%, providing better performance than in previous studies."
실제 로드뷰 이미지에서 Faster R-CNN과 Scene Text Detection CNN을 이용한 간판 영역 검출 방법,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
손사보 악보의 광학음악인식을 위한 CNN기반의 보표 및 마디 인식,2022,"['Convolutional Neural Network', 'Handwritten music sheet', 'Measure detection', 'Staff-line detection']",국문 초록 정보 없음,"With the development of computer music notation programs, when drawing sheet music, it is often drawn using a computer. However, there are still many use of hand-written notations for educational purposes or to quickly draw sheet music such as listening and dictating. In previous studies, OMR focused on recognizing the printed music sheet made by music notation program. the result of handwritten OMR with camera is poor because different people have different writing methods, and lens distortion. In this study, as a pre-processing process for recognizing handwritten music sheet, we propose a method for recognizing a staff using linear regression and a method for recognizing a bar using CNN. F1 scores of staff recognition and barline detection are 99.09% and 95.48%, respectively. This methodologies are expected to contribute to improving the accuracy of handwriting."
[응용논문] 음향신호를 이용한 모터 기어 박스 모듈의 CNN기반 2단계 불량 검출 기법,2022,"['Fault detection(불량진단)', 'CNN(합성곱 신경망)', 'Audio classification(오디오 분류)', 'Mel-spectrogram(멜 스펙트로그램)', 'Motor gear box(모터 기어 박스)']",국문 초록 정보 없음,다국어 초록 정보 없음
악성트래픽의 실시간 탐지를 위한 CNN기반 분류 모델 비교 및 분석,2022,[],"네트워크 환경이 성장함에 따라 네트워크 환경을 위협하는 악성 트래픽도 성장하고 있다. 정보 보호의 중요성이 증가하면서 악성트래픽 탐지 및 분류가 보안 분야에서 지속적으로 연구가 이루어지고 있다. 악성 트래픽을 분석하는 방법으로 포트 기반, 페이로드 기반, 통계 기반의 시그니처를 정의하여 악성 트래픽을 탐지하고 분석하는 연구들이 진행되었지만, 최근 암호화된 데이터의 전송으로 암호화된 트래픽이 늘어남에 따라 악성 트래픽도 암호화된 상태로 침입하여 공격하는 경향을 보이고 있다. 이에 따라 시그니처 기반의 악성 트래픽 탐지보다 머신 러닝 및 딥 러닝을 이용한 악성 트래픽 탐지 및 분류에 대한 연구가 활발하게 이루어지고 있다. 머신러닝 및 딥 러닝 기반의 악성 트래픽 탐지는 탐지 정확도에 중점을 두고 있으며, 마찬가지로 트래픽 분류에서도 분류 정확도에 중점을 두고 있다. 트래픽을 분류한다는 측면에서 분류 정확도도 중요하지만 네트워크 트래픽의 실시간성을 고려하면 분류 정확도뿐만 아니라 빠르게 탐지할 수 있는 방법도 중요하다. 본 논문에서는 CNN 및 LSTM기반의 악성 트래픽 분류 방법을 사용하여 분류 정확도 및 분류 시간을 비교하였다.",다국어 초록 정보 없음
Multilevel Feature Extraction-Based CNN-LSTM Network for Detection of Children’s Abnormal Respiratory Sound,2022,"['Respiratory Sound', 'Multilevel Feature', 'CNN', 'LSTM']",국문 초록 정보 없음,다국어 초록 정보 없음
타이어 가속도 신호와 1D CNN을 활용한 노면 상태 추정,2022,"['Road surface classification(노면 상태 분류)', 'Tire-road friction estimation(타이어-노면 마찰 추정)', '1D CNN(1차원 합성곱 신경망)', 'Tire sensor(타이어 센서)', 'Time series data augmentation(시계열 데이터 증강)']",국문 초록 정보 없음,다국어 초록 정보 없음
하수도 IoT 센싱 데이터에 기반한 CNN-LSTM 침수예측 모델 개발 -인천 미추홀구에서의 적용-,2022,"['IoT 센싱 데이터', '침수예측', '전처리 알고리즘', 'CNN-LSTM']",국문 초록 정보 없음,다국어 초록 정보 없음
고점도 지르코니아 레진용 PP타입 3D프린터의 CNN기반 도포면 이상 검출,2022,"['Ceramic printer', 'Photopolymerization printer', 'DLP printer', 'Machine learning', 'Deep learning', 'CNN', 'defect detection']",국문 초록 정보 없음,다국어 초록 정보 없음
V형 맞대기 GMA 초층용접에서 파형을 이용한 완전용입 예측 CNN모델 최적화,2022,"['Gas metal arc welding (GMAW)', 'V-Groove', 'CNN', 'Prediction', 'Full penetration']",국문 초록 정보 없음,다국어 초록 정보 없음
DFU_SPNet: A stacked parallel convolution layers based CNN to improve Diabetic Foot Ulcer classification,2022,"['Diabetic Foot Ulcer', 'Parallel convolution', 'Convolutional neural network', 'Classification']",국문 초록 정보 없음,"Diabetic Foot Ulcer (DFU) is a complication of diabetes that causes lower limb amputation. In this work, a unique stacked parallel convolution layers-based network (DFU_SPNet) is proposed to perform DFU vs. normal skin classification. The main objective of this work is to design an effective CNN-based classification model, along with proper fine-tuning of optimizer settings. DFU_SPNet consists of 3 blocks of parallel convolution layers with multiple kernel sizes, for local and global feature abstractions. The proposed DFU_SPNet, trained using SGD (with momentum) optimizer with learning rate on the DFUNet dataset, outperformed the current state-of-the-art results with an AUC of 0.974."
CNN-Siamese Networks를 활용한 문자 상표 발음 유사성 탐지,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN-LSTM 기반 시계열 데이터의 이상치 분류를 위한 이미지 인코딩 방법 비교 분석,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 활용하는 X-Band Radar Image 기반 유의파고 예측,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN-LSTM 기반의 전이학습을 이용한 캠퍼스 건물의 피크시간 전력 부하량 예측 모델,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 부유형 풍력 블레이드의 회전상태 구분,2022,"['floating wind turbine', 'short time Fourier transform', 'spectrogram', 'convolutional neural network']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 족저압 기반의 무릎관절 각도 예측 및 정확도 향상에 대한 연구,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 불가사리 인식,2022,"['North-pacific sea star', 'Bat sea star', 'Detection', 'Unmanned underwater vehicle', 'Deep neural network', '아무르 불가사리', '별 불가사리', '검출', '수중드론', '심층신경망']","불가사리는 우리나라의 패류 양식업에 많은 피해를 주고 있다. 불가사리는 놀라운 재생력과생존력이 있어서 퇴치를 하기 위해서는 포획을 하는 것이 가장 좋은 방법이다. 본 연구는 수중드론을 이용하여 포획한다는 것을 가정하였다. 수중드론이 유영하면서 촬영한 해저의 바닥의 영상에서 비스듬하게 보이는 불가사리를 전이학습된 YOLOv5를 이용하여 검출한 후, 접근하여 위에서 불가사리를 내려다 보면서 포획한다. 거제, 통영 앞바다에서 촬영된 영상을전처리 없이 학습시켰음에도 아무르 불가사리를 91.5%, 별불가사리는 81.0%의 비교적 높은검출 정밀도를 보였다.","Sea stars give a lot of damage to the shellfish aquaculture industry in Korea. Sea stars have amazing regenerative and survivability, so catching them is the best way to get rid of them. In this study, it was assumed that capture using an underwater drone. In the images of the bottom of the sea floor taken by an underwater drone swimming, oblique sea stars are detected using the transfer-learned YOLOv5, then approaches and captures the sea stars while looking down at them from above.Even though the images taken off the coast of Geoje and Tongyeong were trained without pre-processing, 91.5% for North-pacific sea stars and 81.0% for bat sea stars showed relatively high detection accuracy."
CNN을 이용한 모터 베어링 고장 진단,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN-based Driving Lane Recognition for Vehicle Localization on Highways,2022,"['Driving lane recognition', 'vehicle localization', 'deep learning', 'convolutional neural network', 'advanced driver assistance system (ADAS)']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 BLE RSSI 환경에서의 핑거프린팅 기반 실내 위치 인식,2022,[],"다양한 실내 편의 시설이 등장하면서 사람들의 실내 활동 시간이 늘어남에 따라 실내 위치 기반 서비스의 수요 또한 함께 증가하였다. 수요가 증가하면서 실내 공간에서의 정확한 위치 측위를 위한 다양한 연구가 진행되고 있는데, 그중 BLE(Bluetooth Low Energy)를 이용한 방식은 저렴한 비용과 전력 소모량이 적어 쉽게 이용이 가능해 많은 관심을 받고 있다. 본 논문에서는 기존의 Wi-Fi 기반 핑거프린팅 기법이 아닌 BLE(Bluetooth Low Energy)를 이용한 핑거프린팅 기법을 기반으로 Beacon을 이용하여 RSSI 데이터를 수집하고, 수집된 데이터를 이용하여 서버에서 실내 측위 모델을 학습시킨 후, Jestson Nano 환경에 포팅시켜 실제 좌표와 예측 좌표간의 오차와 실시간 예측의 정확도를 확인해 보았다.",다국어 초록 정보 없음
CNN-Siamese Networks를 활용한 문자 상표 발음 유사성 탐지,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN과 비전 트랜스포머 기반 차선 검출 모델,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 반도체 SEM 해상도 향상 기법에 Slanted edge를 활용한 화질 평가,2022,"['Deep learning', 'Image processing', 'Semiconductor', 'Scanning electron microscope', 'Modulation transfer function']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN과 분류기의 결합을 이용한 피부질환 분류모델 구축,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 활용한 교내 커뮤니티 게시글 분류 알고리즘 설계,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 공정 신호 기반의 SPR 접합 품질 예측 모델 개발,2022,"['Convolution Neural Network', 'Classification', 'Self-Piercing Rivet', 'Acoustic', 'Prediction']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 활용한 레이저 초음파 기반 배관 국부 손상 검출 능력 향상,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 Al 6061 표면 결함 분류,2022,"['Convolution Neural Network', 'Al 6061', 'Surface Defect', 'Deep Learning', 'Machine Vision']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN-LSTM 기반의 잠재요인 특징 추출을 활용한 효과적인 불규칙 경향 예측 기법,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN-based Fraud Account Classification for Ethereum Blockchain’s Accounts,2022,"['Blockchain', 'Deep Learning', 'Ethereum', 'Fraud Detection']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN으로 생성된 Image는 Pixel 안에 흔적을 남기는가?,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
AI CNN을 이용한 마이크로 PMU 데이터 분류에 대한 연구,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
3D CNN을 이용한 미래 프레임 예측을 통한 비디오 이상 감지,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
Residual CNN을 위한 효율적인 메모리 사용 하드웨어 구조,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
양자 CNN의 레이어 적층에 따른 성능 연구,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
Transformer와 CNN을 활용한 딥러닝 기반 의료 영상 분할 방법,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
Efficient CNN-based Fault Classification for FDM 3D Printer using Embedded Device,2022,"['Anomaly Detection', '3D Printer', 'Deep Learning']",국문 초록 정보 없음,다국어 초록 정보 없음
위성 통신용 CNN기반 객체 검출,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
다중 웨이블릿 CNN을 이용한 가우시안 노이즈 제거,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
압입 변형장과 CNN을 통한 재료물성 및 비등가 양축 잔류응력 평가,2022,"['Indentation', 'FEA', 'Digital image correlation', 'residual stress', 'material property']",국문 초록 정보 없음,다국어 초록 정보 없음
웨이블릿 변환과 CNN을 활용한 코로트코프 음의 인식,2022,"['혈압측정(Blood pressure measurement)', '청음법(Auscultatory method)', '웨이블릿 변환(Wavelet transform)', '기계학습(Machine learning)']",국문 초록 정보 없음,다국어 초록 정보 없음
오토인코더 기반 CNN-LSTM 졸음운전 탐지모델 및 YOLOv7(5) 도로 전방객체 인식을 활용한 안전운전시스템,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
웨이블릿 변환과 CNN을 활용한 코로트코프 음의 인식,2022,"['혈압측정(Blood pressure measurement)', '청음법(Auscultatory method)', '웨이블릿 변환(Wavelet transform)', '기계학습(Machine learning)']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝 기반의 CNN을 이용한 풍력발전 출력 예측모형에 관한 연구,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
An Attention-Based CNN-BiLSTM Model for Korean Voice Phishing Detection,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
고출력 영구자석 동기전동기의 CNN을 활용한 고장 진단,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
라즈베리 파이 피코를 이용한 CNN기반 성별 분류기 설계,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
사람 자세 추정을 위한 CNN-Vision Transformer 기반 결합 모델,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
SPSNet: 단순한 구조를 가진 CNN을 통한 구성요소 분할,2022,"['Part segmentation (구성요소 분할)', 'Deep learning (심층학습)']",국문 초록 정보 없음,다국어 초록 정보 없음
[논문 요약_최우수상 (KAI CEO상)] CNN을 활용한 이미지 데이터 기반의 충격파 구조 및 표면 압력 예측에 대한 연구,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
RR 간격을 통한 CNN-LSTM 기반의 심방세동 검출,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
멀티프레임 MRI를 위한 CNN의 설계 및 성능 평가,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
적층제조 공정에서의 불량 탐지를 위한 CNN기반 다중 원천 전이학습 모델 개발,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
적층제조 공정에서의 불량 탐지를 위한 CNN기반 다중 원천 전이학습 모델 개발,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
A Convolutional Neural Network and Long Short-Term Memory (CNN-LSTM) Method for Classifying Harmful Content,2022,"['Content classification', 'convolutional neural network', 'long short-term memory']",국문 초록 정보 없음,"The development of social media is beneficial for users to quickly access various types of information online. However, this can be a risky for teenagers under the age of 18 years because they may become exposed to information that is unsuitable for them. Some social media platforms have established age-restricted content policies to prevent teenagers from being exposed to bad information. However, unsuitable content that has not been marked as age-restricted still exists online as a result of the enormous volume of information provided on the Internet and the inability to identify it immediately, among other factors. It is important to classify restricted and unrestricted content to protect teenagers’ online safety because teenagers are more likely to be negatively affected by biased and harmful content than adults are. We suggest a strategy for classifying restricted and unrestricted content in this study by examining content comments. We collected and cleaned comments obtained from two datasets (each containing restricted and unrestricted content comments, respectively) from YouTube. Word2vec was used to display comments as vectors, and the classifier was established using convolutional neural network and long short-term memory. Through our findings, we hope make the social media environment more secure to protect the physical and mental health of teenagers."
A Convolutional Neural Network and Long Short-Term Memory (CNN-LSTM) Method for Classifying Harmful Content,2022,"['Content classification', 'convolutional neural network', 'long short-term memory']",국문 초록 정보 없음,다국어 초록 정보 없음
소음에 견고한 코골이 소리 분류를 위한 특징 추출 기반의 CNN-LSTM 모델,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
Histopathology Image Enhancement of Lung Cancer using Deep CNN-based Image Denoising Methods,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
Classification of Restricted and Unrestricted Content based on Convolutional Neural Network and Long Short-Term Memory (CNN-LSTM) Method,2022,"['Content classification', 'convolutional neural network', 'long short-term memory']",국문 초록 정보 없음,"The development of social media is beneficial for users to quickly access various types of information online. However, this can be a risky for teenagers under the age of 18 years because they may become exposed to information that is unsuitable for them. It is important to classify restricted and unrestricted content to protect teenagers’ online safety because teenagers are more likely to be negatively affected by biased and harmful content than adults are. We suggest a strategy for classifying restricted and unrestricted content in this study by examining content comments. We collected and cleaned comments obtained from YouTube. Word2vec was used to display comments as vectors, and the classifier was established using convolutional neural network and long short-term memory. Through our findings, we hope make the social media environment more secure to protect the physical and mental health of teenagers."
"전처리 되지 않은 진동 신호로 플랭크 웨어 예측하는 1D-CNN, 2D-CNN과 LSTM로 구성된 인공지능 네트워크",2022,"['툴 상태 감시', '합성곱 신경망', '장단기 메모리', '플랭크웨어', '1차원 CNN', '2차원 CNN', 'Tool Condition Monitoring', 'Convolutional Neural Network', 'Long Short Term Memories', 'Frack wear', '1D-CNN', '2D-CNN']",국문 초록 정보 없음,"Turning processing machines have been widely employed due to their precision and versatility. As the number of cycles increases, the performance of these devices generally degrades owing to tool wear. Therefore, real-time tool condition monitoring (TCM) that utilizes statistical or machine learning methods has gained significant attention in both academia and industry. However, these methods necessitate sufficient data pre-processing, requiring a high degree of academic understanding as well as significant amount of time. Therefore, this research proposes an advanced artificial intelligence network to monitor a wide range of tools by utilizing raw signals without pre-processing. This study first developed a method consisting of 1D and 2D multi filters convolution neural networks (CNNs) and stacked long short term memories (LSTM). To activate the LSTM in a stable manner, the CNN plays a crucial role in dimensionality reduction. Accordingly, two dimensionality reduction approaches were proposed. These were layer normalized 1D&2D-CNN Multi filters. Then, following multi filters, the stacked LSTM was used to extract the sequential features. Next, the performance of the proposed network using the NASA milling dataset was observed and compared between the 1D/2D-CNN without Flank wear information, pre-processing, and previous research network inclusion. Consequently, although the 1D-CNN method did not have them, it achieved a similar level of accuracy as the present method using past Flank wear input."
Mask R-CNN-based Occlusion Anomaly Detection Considering Orientation in Manufacturing Process Data,2022,"['Manufacturing process', 'Orientation', 'Object detection', 'Mask R-CNN', 'Anomaly detection']",국문 초록 정보 없음,"In a manufacturing process, data analysis is conducted to identify defective products in real time to lower their massive production and improve the rate of efficient production. In the production process, it is difficult to find defective products mixed with normal products. Therefore, it is necessary to detect defective products generated in the production process and reduce the risk of their production. Consequently, this study proposes the Mask R-CNN-based occlusion anomaly detection method in consideration of the orientation of manufacturing process data. The proposed method uses Mask R-CNN to find abnormal objects, such as occluded objects, in a manufacturing process line. In the manufacturing process, some products are hidden. Accordingly, preprocessing in consideration of multiple orientations is applied to generate data. The generated data is performed to detect occlusions and anomalies using Mask R-CNN. The mean of IoU was compared to evaluate the detection accuracy of YOLO and Mask R-CNN. YOLO showed excellent performance when there was a constant distance and orientation and no occluded object. However, Mask R-CNN performed excellently when there was any occluded object and the orientation was considered. Therefore, for occlusion anomaly detection in a manufacturing process, Mask R-CNN can reduce the production rate of defective products."
Multi-Class Classification Framework for Brain Tumor MR Image Classification by Using Deep CNN with Grid-Search Hyper Parameter Optimization Algorithm,2022,"['Multi-classification', 'CNN model', 'Grid search technic', 'Hyper parameter optimization']",국문 초록 정보 없음,"Histopathological analysis of biopsy specimens is still used for diagnosis and classifying the brain tumors today. The available procedures are intrusive, time consuming, and inclined to human error. To overcome these disadvantages, need of implementing a fully automated deep learning-based model to classify brain tumor into multiple classes. The proposed CNN model with an accuracy of 92.98 % for categorizing tumors into five classes such as normal tumor, glioma tumor, meningioma tumor, pituitary tumor, and metastatic tumor. Using the grid search optimization approach, all of the critical hyper parameters of suggested CNN framework were instantly assigned. Alex Net, Inception v3, Res Net -50, VGG -16, and Google - Net are all examples of cutting-edge CNN models that are compared to the suggested CNN model. Using huge, publicly available clinical datasets, satisfactory classification results were produced. Physicians and radiologists can use the suggested CNN model to confirm their first screening for brain tumor Multi-classification."
CNN 기반의 이미지 특징과 객체 정보를 결합한 내용 기반 이미지 검색 기법,2022,"['image retrieval', 'CNN', 'object recognition', 'image feature']",국문 초록 정보 없음,"Contents-based image retrieval (CBIR) method is to find an similar image to the query image among the image database. Recently, the methods extracting the image features using a deep neural network such as the Convolution Neural Network (CNN) have been proposed. These methods can retrieve similar images by comparing the global deep features of images, but it is difficult to retrieval images using specific object information in the image. In this paper, we proposes a new image feature extraction method that combines the CNN based image features and recognized objects’ information. In addition, a new similarity metric combining RBF(Radial Basis Function) and Jaccard Distance for the proposed image feature extraction method. In order to show the superiority of the proposed method, we perform experiments comparing the proposed method and the CNN based CBIR method. Through the experiments, it is shown that the accuracy of the proposed method is more than twice as much as CNN based CBIR method."
자율주행 안전을 위한 Mask R-CNN 기반 폐색 영역 검출,2022,"['Autonomous Driving Safety', 'Long Short-Term Memory', 'Occlusion Area', 'Occlusion Area Detection']","자율주행 자동차의 비전 분야에서의 폐색 영역 검출은 보완해야 할 기술 결함의 중점이다. 본 연구에서는 자율주행 안전을 위한 Mask R-CNN 기반 폐색 영역 검출을 제안한다. 제안하는 방법은 Mask R-CNN 모델에 학습된 데이터를 기반으로 객체를 인식한다. 또한, 교통수단을 종류별로 분류하여 세부적으로 이미지 분할을 진행한다. 객체가 가려지거나 겹쳐졌을 때 객체 추적률을 높일 수 있다. 인식한 객체의 고유한 라벨을 기반으로 LSTM을 이용 시계열 데이터를 이용한 객체 탐지 기반 폐색 영역 검출을 제안한다. 제안하는 방법은 시간의 흐름에 따른 객체 탐지 정확도를 높이고, 이를 활용함으로써 자율주행의 안전성을 향상시킨다.","Detection of occluded areas in the vision field of autonomous vehicles is the focus of technical defects to be supplemented. In this paper, we proposes the Mask R-CNN based occlusion area detection in the autonomous driving safety. The proposed method recognizes objects based on data learned in the Mask R-CNN model. In addition, transportation is classified by type and image division is carried out in detail. It is possible to increase the object tracking rate when the object is covered or overlapped. Based on the unique label of the recognized object, we propose object detection-based occluded area detection using time series data using LSTM. The proposed method improves the accuracy of object detection over time and improves the autonomous driving safety by utilizing it."
A Read Disturbance Tolerant Phase Change Memory System for CNN Inference Workloads,2022,"['Phase-change memory', 'read disturbance error', 'CNN inference', 'non-volatile memory', 'reliability']",국문 초록 정보 없음,"Phase-change memory (PCM) garners attention as the most promising nonvolatile memory (NVM). In particular, PCM is suitable for applications that are not memory intensive, and the convolutional neural network (CNN) inference is widely known as a representative computation- intensive model. Therefore, CNN inference seems to be very suitable for a PCM-based system. However, the PCM suffers from the characteristic of being vulnerable to disturbance errors. In particular, read disturbance error (RDE) becomes a serious problem for workloads involving a large number of zeros, and unfortunately, matrices in CNN are sparse, which inevitably incurs a significant amount of RDEs. In this paper, we present an RDE-tolerant PCM-based system for CNN inference workloads. The proposed method restores vulnerable data words by leveraging a dedicated SRAM-based table. Furthermore, we also propose a replacement policy, which detects non-urgent entries, by utilizing the contents (i.e., counters) in the table. As a result, the proposed method significantly reduces RDEs with minor speed degradation."
Extraction of Worker Behavior at Manufacturing Site using Mask R-CNN and Dense-Net,2022,"['Manufacturing Site', 'Worker Behavior', 'Object Detection', 'Mask R-CNN', 'Dense-Net']","본 논문은 작업자와 객체들이 서로 혼재되어 있는 제조 현장에서 Mask R-CNN을 이용해 객체들을 탐지한 후 이를 Dense-Net을 통해 객체 형상을 자동으로 추출하는 기술을 담고 있다. 이는 맞춤형 공장 데이터 세트를 기반으로 하며, 대상이 되는 개체는 작업자, 기계, 도구, 컨트롤 박스 및 제품들이다. Mask R-CNN은 이미 잘 알려진 객체 인식 방식으로서 다중 객체 인식을 지원하며, Dense-Net은 중첩된 객체들로부터 개별 객체를 추출하는 데 탁월한 효과를 보여준다. 이러한 두 가지 기술을 이용한 기초 구현 결과 제조 현장 모습에서 객체들을 정상적으로 추출해 이미지를 설명할 수 있으며, 향후 객체에 대한 레이블링과 객체 간의 상호 관계를 추가해 작업자의 이상 행동을 감지하는 용도로 활용할 계획이다.","This paper reports a technique that automatically extracts object shapes through Dense-Net, and subsequently, detects the objects using Mask R-CNN in a manufacturing site, in which workers and objects are mixed. It is based on the customized factory dataset by targeting workers, machines, tools, control boxes, and products as the objects. Mask R-CNN supports multi-object recognition as a well-known object recognition method, while Dense-Net effectively extracts a feature from multiple and overlapping objects. After immediate implementation using the two technologies, the object is naturally extracted from a still image of the manufacturing site to describe image. Afterwards, the result is planned to be used to detect workers’ abnormal behavior by adding a label on the objects."
Contactless User Identification System using Multi-channel Palm Images Facilitated by Triple Attention U-Net and CNN Classifier Ensemble Models,2022,"['Palm-based Identification', 'Contactless Identification System', 'Multi-channel image', 'Attention U-Net', 'Ensemble of Pre-trained CNN Models', '손바닥 기반 신원 인식', '비접촉식 신원 인식 시스템', '멀티채널 영상', '어텐션 유넷', 'CNN 모델 앙상블']","본 논문에서는 기존의 스마트폰 카메라 센서를 사용하여 비접촉식 손바닥 기반 사용자 식별 시스템을 구축하기 위해 Attention U-Net 모델과 사전 훈련된 컨볼루션 신경망(CNN)이 있는 다채널 손바닥 이미지를 이용한 앙상블 모델을 제안한다. Attention U-Net 모델은 손바닥(손가락 포함), 손바닥(손바닥 미포함) 및 손금을 포함한 관심 영역을 추출하는 데 사용되며, 이는 앙상블 분류기로 입력되는 멀티채널 이미지를 생성하기 위해 결합 된다. 생성된 데이터는 제안된 손바닥 정보 기반 사용자 식별 시스템에 입력되며 사전 훈련된 CNN 모델 3개를 앙상블 한 분류기를 사용하여 클래스를 예측한다. 제안된 모델은 각각 98.60%, 98.61%, 98.61%, 98.61%의 분류 정확도, 정밀도, 재현율, F1-Score를 달성할 수 있음을 입증하며, 이는 저렴한 이미지 센서를 사용하고 있음에도 불구하고 제안된 모델이 효과적이라는 것을 나타낸다. 본 논문에서 제안하는 모델은 COVID-19 펜데믹 상황에서 기존 시스템에 비하여 높은 안전성과 신뢰성으로 대안이 될 수 있다.","In this paper, we propose an ensemble model facilitated by multi-channel palm images with attention U-Net models and pretrained convolutional neural networks (CNNs) for establishing a contactless palm-based user identification system using conventional inexpensive camera sensors. Attention U-Net models are used to extract the areas of interest including hands (i.e., with fingers), palms (i.e., without fingers) and palm lines, which are combined to generate three channels being ped into the ensemble classifier. Then, the proposed palm information-based user identification system predicts the class using the classifier ensemble with three outperforming pre-trained CNN models. The proposed model demonstrates that the proposed model could achieve the classification accuracy, precision, recall, F1-score of 98.60%, 98.61%, 98.61%, 98.61% respectively, which indicate that the proposed model is effective even though we are using very cheap and inexpensive image sensors. We believe that in this COVID-19 pandemic circumstances, the proposed palm-based contactless user identification system can be an alternative, with high safety and reliability, compared with currently overwhelming contact-based systems."
Mask R-CNN에 의한 자동차 탐지에서 학습 영상 화면 축척과 촬영계절이 정확도에 미치는 영향 분석,2022,"['딥러닝', 'Mask R-CNN', '원격탐사', '객체탐지', 'Deep Learning', 'Mask R-CNN', 'Remote Sensing', 'Object Detection']","본 연구에서는 딥러닝 객체탐지 기법의 정확도 향상을 위해 항공사진과 드론 영상을 대상으로 확대율 조건과 계 절요인이 탐지정확도에 미치는 영향을 실험을 통해 분석하였다. 딥러닝 객체탐지기법 중 빠른 학습 속도와 높은 정 확도를 나타내는 Mask R-CNN을 사용하여 탐지대상인 자동차를 픽셀 단위로 탐지하고자 하였다. ‘서울시 항공사 진서비스’를 통해 화면 확대 레벨을 달리하며 학습 영상을 캡처하고 각각을 학습하여 정확도를 분석하였다. 실험결 과에 따르면 확대 레벨이 높아질수록 mAP 평균이 60%, 67%, 75%로 높아졌다. 데이터 세트의 train, test 데이터의 확대율을 엇갈려서 배치한 경우에는 확대율이 매우 낮은 경우를 제외하고 저배율의 데이터를 train 데이터로, 고배 율의 데이터를 test 데이터로 배치하였을 때 높은 mAP로 반대의 경우보다 20% 이상 차이를 보였다. 그리고 4개월 의 시차로 계절적 차이를 두고 촬영한 드론 영상의 경우, 같은 시기 영상자료 학습결과가 평균 93%로 높은 정확도 를 나타내어 계절적 차이도 학습에 영향을 주는 것을 확인되었다.","In order to improve the accuracy of the deep learning object detection technique, the effect of magnification rate conditions and seasonal factors on detection accuracy in aerial photographs and drone images was analyzed through experiments. Among the deep learning object detection techniques, Mask R-CNN, which shows fast learning speed and high accuracy, was used to detect the vehicle to be detected in pixel units. Through Seoul's aerial photo service, learning images were captured at different screen magnifications, and the accuracy was analyzed by learning each. According to the experimental results, the higher the magnification level, the higher the mAP average to 60%, 67%, and 75%. When the magnification rates of train and test data of the data set were alternately arranged, low magnification data was arranged as train data, and high magnification data was arranged as test data, showing a difference of more than 20% compared to the opposite case. And in the case of drone images with a seasonal difference with a time difference of 4 months, the results of learning the image data at the same period showed high accuracy with an average of 93%, confirming that seasonal differences also affect learning."
Performance evaluation of mask R-CNN for lung segmentation using computed tomographic images,2022,"['Mask R-CNN', 'Segmentation', 'Network architecture', 'Optimizer', 'Computed tomography']",국문 초록 정보 없음,"Image segmentation techniques based on machine learning are able to improve diagnostic and therapeutic accuracy by localizing target areas. The accuracy and efciency of these techniques are dependent on network architecture and loss minimization method because the performance of a machine learning model is determined by training strategies. In this study, the lung segmentation based on computed tomographic images was performed by using mask regional convolutional neural networks (R-CNNs) with various feature extraction networks and optimizers. The efects of the feature extraction networks and optimizers on the trained mask R-CNNs were evaluated in terms of total training loss, segmentation accuracy and training time. The results showed that the convergence of total loss values during network training was afected by the architectures of the feature extraction networks as well as the optimizers. The lung segmentation accuracy and training time of the mask R-CNN were mainly dependent on the optimizer and network architecture, respectively. Among the various optimizers, the ASGD optimizer maximized lung segmentation accuracy, and the training time was reduced by the feature extraction network including general convolution layers and feature pyramid network (FPN). In conclusion, it is important to apply the optimal network architecture and optimizer to the mask R-CNN for maximizing its performance, and the optimized mask R-CNN can be potentially used for improving diagnostic and therapeutic accuracy."
Smartphone based Indoor Localization Technology using 1D CNN -BLSTM,2022,"['Indoor Localization', 'Deep Learning', 'CNN', 'BLSTM']",국문 초록 정보 없음,"The study of indoor localization technology using smart phone has been continuously studied. Fingerprinting is a representative indoor positioning technology. This technology estimates the location by comparing Radio Signal Strength (RSS) information received in one-shot at a specific location with the previously constructed Radio Map. Since the RSS received in one-shot is used, the ability to discriminate signals according to space is low. To solve this problem, the use of RSS spatial patterns based on Pedestrian Dead Reckoning (PDR) improves signal discrimination according to space and increases accuracy. However, since PDR is used, there is a problem that it is difficult to use a spatial pattern if PDR distortion occurs due to a heading drift error and a change motion. We propose an indoor positioning technology using 1D Convolutional Neural Network (CNN) and Bi-directional Long Short Term Memory (BLSTM). We estimated the position by learning the 1D RSS pattern. In order to generate a large amount of data, we used the pre-built Radio Map. We use a model that combines 1D CNN and BLSTM. 1D CNN is used to extract RSS patterns, and BLSTM is used to learn the relationship of sequential data in both directions. Through this, it is possible to estimate the position using only the RSS. To verify the proposed technology, we compared it with the previous technology. As a result, the previous technology showed 2.19m error and the proposed technology showed 4.663m error. However, the calculation speed is 30 times faster than the proposed technology. It was confirmed that indoor positioning technology using deep learning technology can provide position information with only 1D RSS pattern."
Comparison of Multi-Label U-Net and Mask R-CNN for panoramic radiograph segmentation to detect periodontitis,2022,"['Radiography', 'Panoramic', 'Deep Learning', 'Periodontitis', 'Tooth']",국문 초록 정보 없음,"Purpose: Periodontitis, the most prevalent chronic inflammatory condition affecting teeth-supporting tissues, is diagnosed and classified through clinical and radiographic examinations. The staging of periodontitis using panoramic radiographs provides information for designing computer-assisted diagnostic systems. Performing image segmentation in periodontitis is required for image processing in diagnostic applications. This study evaluated image segmentation for periodontitis staging based on deep learning approaches. Materials and Methods: Multi-Label U-Net and Mask R-CNN models were compared for image segmentation to detect periodontitis using 100 digital panoramic radiographs. Normal conditions and 4 stages of periodontitis were annotated on these panoramic radiographs. A total of 1100 original and augmented images were then randomly divided into a training (75%) dataset to produce segmentation models and a testing (25%) dataset to determine the evaluation metrics of the segmentation models. Results: The performance of the segmentation models against the radiographic diagnosis of periodontitis conducted by a dentist was described by evaluation metrics(i.e., dice coefficient and intersection-over-union [IoU] score). MultiLabel U-Net achieved a dice coefficient of 0.96 and an IoU score of 0.97. Meanwhile, Mask R-CNN attained a dice coefficient of 0.87 and an IoU score of 0.74. U-Net showed the characteristic of semantic segmentation, and Mask R-CNN performed instance segmentation with accuracy, precision, recall, and F1-score values of 95%, 85.6%, 88.2%, and 86.6%, respectively. Conclusion: Multi-Label U-Net produced superior image segmentation to that of Mask R-CNN. The authors recommend integrating it with other techniques to develop hybrid models for automatic periodontitis detection."
Comparison of Multi-Label U-Net and Mask R-CNN for panoramic radiograph segmentation to detect periodontitis,2022,"['Radiography', 'Panoramic', 'Deep Learning', 'Periodontitis', 'Tooth']",국문 초록 정보 없음,"Purpose: Periodontitis, the most prevalent chronic inflammatory condition affecting teeth-supporting tissues, is diagnosed and classified through clinical and radiographic examinations. The staging of periodontitis using panoramic radiographs provides information for designing computer-assisted diagnostic systems. Performing image segmentation in periodontitis is required for image processing in diagnostic applications. This study evaluated image segmentation for periodontitis staging based on deep learning approaches.Materials and Methods: Multi-Label U-Net and Mask R-CNN models were compared for image segmentation to detect periodontitis using 100 digital panoramic radiographs. Normal conditions and 4 stages of periodontitis were annotated on these panoramic radiographs. A total of 1100 original and augmented images were then randomly divided into a training (75%) dataset to produce segmentation models and a testing (25%) dataset to determine the evaluation metrics of the segmentation models.Results: The performance of the segmentation models against the radiographic diagnosis of periodontitis conducted by a dentist was described by evaluation metrics (i.e., dice coefficient and intersection-over-union [IoU] score). Multi- Label U-Net achieved a dice coefficient of 0.96 and an IoU score of 0.97. Meanwhile, Mask R-CNN attained a dice coefficient of 0.87 and an IoU score of 0.74. U-Net showed the characteristic of semantic segmentation, and Mask R-CNN performed instance segmentation with accuracy, precision, recall, and F1-score values of 95%, 85.6%, 88.2%, and 86.6%, respectively.Conclusion: Multi-Label U-Net produced superior image segmentation to that of Mask R-CNN. The authors recommend integrating it with other techniques to develop hybrid models for automatic periodontitis detection."
CNN 기반 CCTV 동영상 내 보행자 응급 상황 자동 감지 기술 연구,2022,"['응급상황', '영상인식', 'Deep Learning', 'YOLO', 'Emergency', 'Image Recognition', 'CCTV', '딥러닝']",국문 초록 정보 없음,"Since most medical emergencies including cardiac arrest and stroke happen unexpectedly, it is critical to recognize and respond to the situations immediately. In this paper, we propose an AI-based system which recognizes automatically medical emergencies where pedestrians fall unexpectedly due to their health problems captured in real-time video clips from CCTVs and locates the geometric position on a map on a web page to provide with prompt first aids. To this end, we extend the YOLO (You Only Look Once) network, a variant of the Convolutional Neural Network (CNN) which is suitable for 2D still images, not video. Though many researchers have studied on the methods dedicated to recognize objects in video, with a belief that CNN is not enough to recognize motions, we show that it is possible to build a robust but simple medical emergency detection system by extending the YOLO network - a variant of CNN - that only handles 2D images. Also, we report the performance of the proposed system in four performance measures in this paper."
CNN 기반 절삭공구 상태 및 학습 분석에 관한 연구,2022,"['convolutional neural network', 'shape from focus', 'artificial nural ntwork', 'depth estimation', 'focus measure']","정밀 금속 가공 분야에서 공구의 상태는 제품의 품질, 불량률에 주요한 영향을 주며 공구 마모에 따른 교체주기 파악은 제품 생산계획, 생산성 향상에도 필수적이다. 숙련공들의 경우, 가공시 발생하는 소음으로 교체주기를 판단하며 이 외에 공구 마모에 따른 부하량 측정, 가공 완료 후 표면 상태 육안검사 등으로 파악한다. 본 논문에서는 가속도 센서를 활용하여 가청음대역에서의 미세한 진동변화를 분석하여 CNN(Convolutional Neural Network)로 패턴을 분류, 교체시기를 가늠할 수 있는 알고리즘을 연구하였다.","In the field of precision metal processing, the condition of tools has a major factor on product quality and defect rate, and understanding the replacement cycle according to tool wear is essential for product production planning and productivity improvement. In the case of skilled workers, the replacement cycle is determined by the noise generated during machining, and in addition, the load is measured according to tool wear, and the surface condition after machining is visually inspected. In this paper, an algorithm for classifying patterns using a Convolutional Neural Network (CNN) was studied by analyzing minute vibration changes in the audible band using an acceleration sensor."
A Painting Style System using an Improved CNN Algorithm,2022,"['CNN', 'Style rendering', 'Artificial neural network', 'Artistic style']",국문 초록 정보 없음,"The rapid development of deep learning technology allows ordinary people to create artwork that imitates the style of paintings by famous masters through an algorithm. To create such works with artistic style, this research proposes an artificial neural network algorithm based on an improved convolutional neural network (CNN). First, a fast style-rendering model based on the improved CNN is constructed, and then, a server front end is built with the Bootstrap framework. The server-side back end of the system is built by combining a Python algorithm and a web framework, and finally, a complete model of the front-end and back-end network of the style rendering system is constructed. The model proposed in this paper is compared with two other models to verify its performance. The results show that information entropy of the model constructed is the highest at 5.58, which is higher than information entropy of the other two models. The average gradient value and the peak signal-to-noise ratio under the constructed model are 22.54 and 27.81, respectively, which are also higher than the other two models. Mutual information and the structural similarity index between rendered images and sample images under all three models were compared. Mutual information and structural similarity index of the model constructed by this research are 1.19 and 0.56, respectively, with much larger data sizes than the two comparison models."
심혈관 상태 식별을 위한 CNN Block 구조를 적용한 고성능 ECG 데이터 분석시스템,2022,"['CNN block structure', 'ECG data analysis scheme', 'ResNeXt', 'MIT-BIH database', 'F1-score']",국문 초록 정보 없음,다국어 초록 정보 없음
A study on road damage detection for safe driving of autonomous vehicles based on OpenCV and CNN,2022,"['OpenCV', 'CNN', 'Data augmentation', 'Histogram Equalization', 'Object accuracy.']",국문 초록 정보 없음,"For safe driving of autonomous vehicles, road damage detection is very important to lower the potential risk. In order to ensure safety while an autonomous vehicle is driving on the road, technology that can cope with various obstacles is required. Among them, technology that recognizes static obstacles such as poor road conditions as well as dynamic obstacles that may be encountered while driving, such as crosswalks, manholes, hollows, and speed bumps, is a priority. In this paper, we propose a method to extract similarity of images and find damaged road images using OpenCV image processing and CNN algorithm. To implement this, we trained a CNN model using 280 training datasheets and 70 test datasheets out of 350 image data. As a result of training, the object recognition processing speed and recognition speed of 100 images were tested, and the average processing speed was 45.9 ms, the average recognition speed was 66.78 ms, and the average object accuracy was 92%. In the future, it is expected that the driving safety of autonomous vehicles will be improved by using technology that detects road obstacles encountered while driving."
Mask R-CNN 기반 심층학습을 이용한 개체영상의 인공지능 학습데이터 구축,2022,"['어노테이션', '학습데이터', '인스턴스 분할', '개체영상', 'Mask R-CNN', 'Annotation', 'Learning Data', 'Instance Segmentation', 'Object Image']","본 논문에서는 심층학습을 이용한 개체영상의 인공지능 학습데이터 구축을 제안한다. 이를 위해 전이학습의 Mask R-CNN 모델을 이용하여 영상의 개체들을 각각 인스턴스 분할하고, 분할된 개체를 대상으로 경계상자 좌표와 인스턴스를 이용하여 배경을 제거한 개체영역만을 추출한 후 데이터베이스를 구축한다. 여기서 인스턴스 분할은 동일한 클래스 내의 개체들을 분할하기 위함이고, 배경의 제거는 순수 개체영역만으로 구성된 학습데이터를 얻기 위함이다. 제안된 방법을 임의의 크기를 가진 시설작물 RGB 딸기영상 40장과 DermQuest 피부병변 영상 82장을 대상으로 잎과 병변의 개체로 구성된 학습데이터 구축에 적용하여 실험한다. 실험의 결과, 평균 정확도와 평균 재현율에서 우수한 성능을 가진 학습데이터의 구축이 가능함을 알 수 있다. 또한 각 개체의 추출을 자동화함으로써 어노테이션에 소요되는 시간을 크게 줄일 수 있다. 특히 딸기영상의 경우 여러 개의 잎들이 중첩된 경우에도 개체의 분할성능이 우수하여 데이터의 추출이 잘 이루어짐을 확인하였다.","In this paper, we propose the construction of artificial intelligence learning data of object images using deep learning. To this end, each instance of the image objects is segmented using the Mask R-CNN model of transfer learning, and only the object area from which the background has been removed using the bounding box coordinates and instances of the segmented object is constructed, and then the database is built. Here, the instance segmentation is to divide objects within the same class, and the background removal is to obtain learning data composed only of the pure object area. The proposed method is applied to construct learning data composed of leaves and lesions for 40 RGB strawberry images of facility crops and 82 DermQuest skin lesion images with the arbitrary size, respectively. The experiment results show that it is possible to construct training data with excellent performance in average accuracy and average recall. By automating the extraction of each object, the time spent on annotations can be significantly reduced. Especially, in the case of strawberry image, it was confirmed that data extraction was performed well because the segmentation performance of the individual was excellent even when several leaves were overlapped."
Comparison of Performance According to Preprocessing Methods in Estimating %IMF of Hanwoo Using CNN in Ultrasound Images,2022,"['Preprocessing', 'Hanwoo', 'Ultrasound Images', 'CNN', '%IMF(Intramuscular Fat Percentage)']",국문 초록 정보 없음,"There have been various studies in Korea to develop a %IMF(Intramuscular Fat Percentage) estimation method suitable for Hanwoo. Recently, a %IMF estimation method using a convolutional neural network (CNN), a kind of deep learning method among artificial intelligence methods, has been studied. In this study, we performed a performance comparison when various preprocessing methods were applied to the %IMF estimation of ultrasound images using CNN as mentioned above. The preprocessing methods used in this study are normalization, histogram equalization, edge enhancement, and a method combining normalization and edge enhancement. When estimating the %IMF of Hanwoo by the conventional method that did not apply preprocessing in the experiment, the accuracy was 98.2%. The other hand, we found that the accuracy improved to 99.5% when using preprocessing with histogram equalization alone or combined regularization and edge enhancement."
Comparison of Performance According to Preprocessing Methods in Estimating %IMF of Hanwoo Using CNN in Ultrasound Images,2022,"['Preprocessing', 'Hanwoo', 'Ultrasound Images', 'CNN', '%IMF(Intramuscular Fat Percentage)']",국문 초록 정보 없음,"There have been various studies in Korea to develop a %IMF(Intramuscular Fat Percentage) estimation method suitable for Hanwoo. Recently, a %IMF estimation method using a convolutional neural network (CNN), a kind of deep learning method among artificial intelligence methods, has been studied. In this study, we performed a performance comparison when various preprocessing methods were applied to the %IMF estimation of ultrasound images using CNN as mentioned above. The preprocessing methods used in this study are normalization, histogram equalization, edge enhancement, and a method combining normalization and edge enhancement. When estimating the %IMF of Hanwoo by the conventional method that did not apply preprocessing in the experiment, the accuracy was 98.2%. The other hand, we found that the accuracy improved to 99.5% when using preprocessing with histogram equalization alone or combined regularization and edge enhancement."
FPGA 기반 임베디드 시스템에서의 CNN 모델의 레이어 연산 성능 향상에 관한 연구,2022,[],"지능형 IoT, AR/VR, 자율 주행 자동차 등 전력 및 컴퓨팅 자원이 제한적인 임베디드 엣지 시스템에서 인공지능을 활용한 어플리케이션이 적용되면서, CNN 추론 엔진을 포팅하는 것은 필수적이다. 이에 따라 CNN 의 효율적인 처리를 위한 연구가 활발하게 진행되고 있으며, FPGA 제조사인 Xilinx, Intel 등 에서도 Acceleration 솔루션을 제공하며 지속적으로 업데이트 하고있다. 본 논문에서는 FPGA 기반의 임베디드 시스템에서 타겟 어플리케이션에 최적화된 CNN 모델의 각 Layer 를 분산하여 연산하는 각 Logic 을 설계하고 Xilinx Vitis HLS 를 이용하여 시뮬레이션을 통해 연산성능에 대한 실험을 하였다. 실험을 통해 기존 GPU 기반의 임베디드 시스템 대비 38% 향상된 성능을 확인할 수 있었다.",다국어 초록 정보 없음
Smart Cities’ Automatic Image-Based Waste Segregation through an Intelligent Agent Using CNN,2022,"['Domestic waste', 'Waste segregation', 'Convolutional Neural Network (CNN).']",국문 초록 정보 없음,"Rapidly growing innovative technologies enabled human beings to enjoy smart city services despite the development of such cities are still facing several challenges needed to be addressed. The waste management in smart cities particularly its segregation by smart methods is one of the primary concerns as the amount of waste generated every day by citizens is increasing. A comprehensive intelligent waste management system is direly needed to address the situation. This article aims to segregate recyclable and non-recyclable types of garbage collected from smart cities using the Intelligent Agent proposed and developed so far. The expected smart solution should provide the best level of accuracy at the lowest possible cost. Our study proposed a model to differentiate and segregate waste into recyclable and organic objects based on Intelligent Agent developed using a Convolutional Neural Network (CNN). The model proposed comprises of Intelligent Agent developed and the existing CNN model which is commonly used for transfer learning. The classification accuracy achieved is up to 93.27% which is better than the already published results of different models discussed in the recent past research studies. Furthermore, how can recyclable and organic waste be utilized in the future is part of our ongoing study. The findings may be of interest to practitioners and the researchers’ community working in the relevant field."
Mask Region-Based Convolutional Neural Network (R-CNN) Based Image Segmentation of Rays in Softwoods,2022,"['instance segmentation', 'Mask region-based convolutional neural network (R-CNN)', 'rays', 'quantitative wood anatomy']",국문 초록 정보 없음,"The current study aimed to verify the image segmentation ability of rays in tangential thin sections of conifers using artificial intelligence technology. The applied model was Mask region-based convolutional neural network (Mask R-CNN) and softwoods (viz. Picea jezoensis, Larix gmelinii, Abies nephrolepis, Abies koreana, Ginkgo biloba, Taxus cuspidata, Cryptomeria japonica, Cedrus deodara, Pinus koraiensis) were selected for the study. To take digital pictures, thin sections of thickness 10–15 μm were cut using a microtome, and then stained using a 1:1 mixture of 0.5% astra blue and 1% safranin. In the digital images, rays were selected as detection objects, and Computer Vision Annotation Tool was used to annotate the rays in the training images taken from the tangential sections of the woods. The performance of the Mask R-CNN applied to select rays was as high as 0.837 mean average precision and saving the time more than half of that required for Ground Truth. During the image analysis process, however, division of the rays into two or more rays occurred. This caused some errors in the measurement of the ray height. To improve the image processing algorithms, further work on combining the fragments of a ray into one ray segment, and increasing the precision of the boundary between rays and the neighboring tissues is required."
Long term 시계열 주행 데이터를 위한 CNN 기반 운전자 식별 기법,2022,[],"최근 차량 원격 시동, 스마트키 등 차량이 전동화됨에 따라 차량 해킹 및 도난 사고가 빈번히 일어나고 있다. 특히 차량 대여 사업이 늘어나면서 대여 차량 내 운전자의 식별은 중요한 요소가 되었다. 본 논문은 운전 시뮬레이터를 통해 운전자 7인에 대한 차량 센서 데이터를 수집한다. 주행 데이터와 같이 길이가 긴 시계열 데이터는 시간 축에 따라 나누어 사용함에 따라 전처리 과정에서 많은 연산을 요구하는 단점이 있다. 본 논문은 나누어진 주행 데이터의 식별 결과를 voting 하여 데이터 전체에 대해 결과를 예측하는 CNN 기반의 운전자 식별 모델을 제안한다. 6개의 차량 센서 데이터를 제안하는 모델과 일반적인 CNN 모델로 학습하여 각 모델의 정확도를 비교한다. 운전자 3인과 7인 식별에 대해 비교 모델의 정확도는 75.8%와 56.5%였으며, 제안한 모델의 정확도는 91.1%와 75%로 CNN 모델보다 평균적으로 19.94%의 정확도가 향상되었다.",다국어 초록 정보 없음
Binary Classification of Hypertensive Retinopathy Using Deep Dense CNN Learning,2022,"['Retinography images', 'Hypertensive-retinopathy', 'deep-neural network', 'Transfer learning', 'convolutional neural network']",국문 초록 정보 없음,"A condition of the retina known as hypertensive retinopathy (HR) is connected to high blood pressure. The severity and persistence of hypertension are directly correlated with the incidence of HR. To avoid blindness, it is essential to recognize and assess HR as soon as possible. Few computer-aided systems are currently available that can diagnose HR issues. On the other hand, those systems focused on gathering characteristics from a variety of retinopathy-related HR lesions and categorizing them using conventional machine-learning algorithms. Consequently, for limited applications, significant and complicated image processing methods are necessary. As seen in recent similar systems, the preciseness of classification is likewise lacking. To address these issues, a new CAD HR-diagnosis system employing the advanced Deep Dense CNN Learning (DD-CNN) technology is being developed to early identify HR. The HR-diagnosis system utilized a convolutional neural network that was previously trained as a feature extractor. The statistical investigation of more than 1400 retinography images is undertaken to assess the accuracy of the implemented system using several performance metrics such as specificity (SP), sensitivity (SE), area under the receiver operating curve (AUC), and accuracy (ACC). On average, we achieved a SE of 97%, ACC of 98%, SP of 99%, and AUC of 0.98. These results indicate that the proposed DD-CNN classifier is used to diagnose hypertensive retinopathy."
Use of deep learning in nano image processing through the CNN model,2022,"['convolutional neural network', 'CT image', 'deep learning', 'image processing', 'lung cancer']",국문 초록 정보 없음,"Deep learning is another field of artificial intelligence (AI) utilized for computer aided diagnosis (CAD) and image processing in scientific research. Considering numerous mechanical repetitive tasks, reading image slices need time and improper with geographical limits, so the counting of image information is hard due to its strong subjectivity that raise the error ratio in misdiagnosis. Regarding the highest mortality rate of Lung cancer, there is a need for biopsy for determining its class for additional treatment. Deep learning has recently given strong tools in diagnose of lung cancer and making therapeutic regimen. However, identifying the pathological lung cancer's class by CT images in beginning phase because of the absence of powerful AI models and public training data set is difficult. Convolutional Neural Network (CNN) was proposed with its essential function in recognizing the pathological CT images. 472 patients subjected to staging FDG-PET/CT were selected in 2 months prior to surgery or biopsy. CNN was developed and showed the accuracy of 87%, 69%, and 69% in training, validation, and test sets, respectively, for T1-T2 and T3-T4 lung cancer classification. Subsequently, CNN (or deep learning) could improve the CT images' data set, indicating that the application of classifiers is adequate to accomplish better exactness in distinguishing pathological CT images that performs better than few deep learning models, such as ResNet-34, Alex Net, and Dense Net with or without Soft max weights."
ShortcutFusion++: Optimizing an End-to-End CNN Accelerator for High PE Utilization,2022,"['CNN accelerator', 'Processing element', 'Hardware utilization', 'FPGA', 'YOLO-v3']",국문 초록 정보 없음,"ShorcutFusion [1] is an end-to-end framework that effectively maps many well-known deep neural networks (DNNs), such as MobileNet-v2, EfficientNet-B0, ResNet-50, and YOLO-v3, to a generic CNN accelerator on FPGA. Nevertheless, its processing elements are not fully utilized when supporting various networks, leading to relatively low hardware utilization (e.g., 68.42% for YOLO-v3). This study aimed to enhance the performance of ShortcutFusion and introduce ShortcutFusion++ by proposing two simple but effective techniques for eliminating unnecessary stalls in conventional design. First, the prefetching scheme was re-designed to avoid bubble cycles when feeding data to the PE array. Second, the output buffer was reconstructed to pipeline the operations of PEs and the process of writing output feature maps to off-chip memory. The experimental results show that ShortcutFusion++ achieves a PE utilization of 80.95% for the wellknown object detection network YOLO-v3, outperforming its baseline by 12.53%."
CNN 기반 선박 형광 도막 두께 측정,2022,"['Painting thickness measurement', 'Deep learning', 'Smart shipyard']",국문 초록 정보 없음,"To reduce the number of ship painting inspections in shipyards, there are trials to use visible fluorescent paint with a thickness of paint that can be visually inspected. However, due to the problem that the paint color varies depending on the illuminance and the type of light source, the reliability of the visual inspection is not consistent depending on the inspectors. Therefore, this study proposes a painting inspection method using machine learning technique instead of visual inspection. We propose automation of paint measurements using CNN model to find color variations in captured images according to the illuminance of paint. The actual thickness value of the paint was obtained from the specimen using a contact thickness measuring device. The color model was used to create a deep learning model suitable for the thickness characteristics of the image data. As a result, the proposed CNN model can measure the thickness of the paint within ±20 μm."
CNN based data anomaly detection using multi-channel imagery for structural health monitoring,2022,"['convolutional neural network (CNN)', 'data anomaly detection', 'sensor-fault identification', 'structural health monitoring']",국문 초록 정보 없음,"Data-driven structural health monitoring (SHM) of civil infrastructure can be used to continuously assess the state of a structure, allowing preemptive safety measures to be carried out. Long-term monitoring of large-scale civil infrastructure often involves data-collection using a network of numerous sensors of various types. Malfunctioning sensors in the network are common, which can disrupt the condition assessment and even lead to false-negative indications of damage. The overwhelming size of the data collected renders manual approaches to ensure data quality intractable. The task of detecting and classifying an anomaly in the raw data is non-trivial. We propose an approach to automate this task, improving upon the previously developed technique of image-based pre-processing on one-dimensional (1D) data by enriching the features of the neural network input data with multiple channels. In particular, feature engineering is employed to convert the measured time histories into a 3-channel image comprised of (i) the time history, (ii) the spectrogram, and (iii) the probability density function representation of the signal. To demonstrate this approach, a CNN model is designed and trained on a dataset consisting of acceleration records of sensors installed on a long-span bridge, with the goal of fault detection and classification. The effect of imbalance in anomaly patterns observed is studied to better account for unseen test cases. The proposed framework achieves high overall accuracy and recall even when tested on an unseen dataset that is much larger than the samples used for training, offering a viable solution for implementation on full-scale structures where limited labeled-training data is available."
Faster R-CNN을 활용한 공유 전동킥보드 불법주차 사전예방 방안 연구,2022,"['Shared Electric Scooter', 'Object Detecting', 'Illegal Parking', 'Faster R-CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
An   Improved   CNN   VGG19   Architecture   for   Detection   and Classification   of   Electric   Fire   Short-Circuit   Marks,2022,"['VGG19', 'CNN', 'Electric   Fire', 'Arc-beads    data', 'VGG19', '합성곱신경망', '전기화재', '용융흔']",국문 초록 정보 없음,"In this paper, the VGG19 algorithm was used by applying the transfer learning for the classification of molten traces of electric fire arc-beads data which is one of the most used models in convolutional neural network(CNN) computer vision tasks. The most essential basis for detecting direct indications of electric fires is the melting traces of wires that occur at the site of an electric fire, depending on the severity and shape of the melting. The proposed VGG19 method was altered and used such that it could detect molten traces, and the molten trace data of the wires required for learning were created in the lab. The final validation accuracy result was 96.31% with validation loss of 0.1169. Through the result of securing such high accuracy, the possibility of using the melting trace detection algorithm to verify the presence or absence of an electric fire was shown."
Faster R-CNN을 이용한 갓길 차로 위반 차량 검출,2022,"['위반 차량 검지', '객체분류', '딥러닝', '기계 학습', 'Traffic violoation detection', 'Object classification', 'Deep learning', 'Machine learning']",국문 초록 정보 없음,다국어 초록 정보 없음
Feature Extraction of Non-proliferative Diabetic Retinopathy Using Faster R-CNN and Automatic Severity Classification System Using Random Forest Method,2022,"['Faster R-CNN', 'Classification', 'Machine Learning', 'Non-proliferative Diabetic Retinopathy', 'Random Forest']",국문 초록 정보 없음,"Non-proliferative diabetic retinopathy is a representative complication of diabetic patients and is known to bea major cause of impaired vision and blindness. There has been ongoing research on automatic detection ofdiabetic retinopathy, however, there is also a growing need for research on an automatic severity classificationsystem. This study proposes an automatic detection system for pathological symptoms of diabetic retinopathysuch as microaneurysms, retinal hemorrhage, and hard exudate by applying the Faster R-CNN technique. Anautomatic severity classification system was devised by training and testing a Random Forest classifier basedon the data obtained through preprocessing of detected features. An experiment of classifying 228 test fundusimages with the proposed classification system showed 97.8% accuracy."
E-Scooter Detection Dataset Construction and Its Evaluation Using CNN Models,2022,"['e-scooter', 'kickboard', 'detection', 'CNN']",국문 초록 정보 없음,"Recently, as e-scooter rental services are growing, e-scooter is considered as one of the most convenient and inexpensive means of transportation. As the use of e-scooters has soared in recent years, traffic accidents between vehicles and e-scooters riders have also increased. Therefore, there is also a need for the development of deep learning techniques for detecting e-scooters and riders. However, there is no large dataset labeled for e-scooters on the road captured by dash cameras on vehicles. In this paper, a new e-scooter dataset has been constructed using vehicles’ dashcam views to address this problem. This dataset consists of running e-scooters, parked e-scooters, e-scooter riders, and pedestrians. This paper also presents a CNN model for detecting e-scooters and riders, and analyzes the detection performance using our e-scooter dataset."
스펙트럼 전처리와 합성곱 신경망(CNN) 모델 기반 과수재배포장의 토양유기탄소 함량 예측,2022,"['토양유기탄소', 'SOC', '근적외선분광기술', '스펙트럼전처리', '과수재배포장', 'Convolution Neural Network']","토양유기탄소(SOC)는 질소, 인, 황 등의 영양소를 공급하기 때문에 토양 비옥도 및 작물 생산성 유지하기 위한 중요한 수단 중 하나이다. 토양유기탄소 함량은 기후 조건, 토지 사용 방법, 농업 시스템 및 농업 활동 등에 따라 변화하기 때문에 토양 내 유기탄소 함량을 적절하게 유지하기 위해서는 유기탄소 함량을 예측할 필요가 있다. 본 연구에서는 토양유기탄소함량을 비파괴적으로 측정하기 위해 근적외선 분광기술을 이용한 딥러닝 모델을 개발하였다. 실험에 사용된 토양 시료는 토성이 서로 다른 과수 재배 포장 418 지역에서 수집하였다. 토양 시료들의 스펙트럼은 USB4000 Fiber Optic Spectrometer (Ocean Optics, Inc., USA)을 사용하여 가시광-근적외선 영역인 500 nm-1100 nm에서 측정하였다. 토양 시료당 3회 반복 측정하여 1,254개의 스펙트럼을 획득하였다. 예측 성능을 향상시키기 위해 스펙트럼 전처리들을 적용한 합성곱 신경망(Convolution Neural Network; CNN) 모델 개발하였다. 스펙트럼 전처리 방법으로 평활화, 1차 미분, 2차 미분, 정규화, SNV 등을 적용하다. 작물별 토양유기탄소 예측 CNN 모델을 개발하고 결정계수(R2)와 평균 제곱근 오차(RMSE)를 사용하여 성능을 평가하였다. 그 결과, 작물 재배 포장별 유기탄소 예측 모델이 우수한 성능을 보였다. 근적외선 분광 기반 딥러닝 기술은 추후 작물 재배포장의 토양 관리에 활용될 것으로 기대된다.",다국어 초록 정보 없음
Comparing U-Net convolutional network with mask R-CNN in Nuclei Segmentation,2022,"['U-Net', 'Mask R-CNN', 'Nuclei Segmentation']",국문 초록 정보 없음,"Deep Learning is used nowadays in Nuclei segmentation. While recent developments in theory and open-source software have made these tools easier to implement, expert knowledge is still required to choose the exemplary model architecture and training setup. We compare two popular segmentation frameworks, U-Net and Mask-RCNN, in the nuclei segmentation task and find that they have different strengths and failures. we compared both models aiming for the best nuclei segmentation performance. Experimental Results of Nuclei Medical Images Segmentation using U-NET algorithm Outperform Mask R-CNN Algorithm."
2D DCT를 활용한 CNN 모델의 압축 기법,2022,[],"최근 객체 인식을 위한 컨볼루션 신경망(Convolutional Neural Network, CNN) 모델의 압축에 관한 연구가 활발히 이루어지고 있다. 그중 모델을 구성하는 가중치의 크기를 낮추는 방법인 양자화가 대표적인 예시이다. 양자화를 수행하는 방법은 다양하며, 본 논문에서는 CNN 모델의 가중치 정보를 압축하기 위해 도메인 변환 기법인 2D DCT(2D Discrete Cosine Transform) 양자화를 활용하였다. 컨볼루션 계층 (Convolutional Layer) 및 완전연결 계층 (Fully Connected Layer)을 구성하는 가중치의 값을 주파수 영역으로 변환한 뒤 특정 양자화 계수를 적용하여 양자화하였으며, 이후 허프만 코딩 (Huffman Coding)을 통해 비트스트림을 생성하였다. 이를 기반으로 본 논문에서는 데이터 손실에 따른 모델 정확도의 변화를 나타낸다.",다국어 초록 정보 없음
Comparison of vibration visualization methods for classification of chaos based on CNN,2022,"['Vibration', 'Chaos', 'Classification', 'CNN', 'Visualization method']",국문 초록 정보 없음,"This study assessed methods for visualizing the vibrations for chaotic systems using a time series, fast Fourier transform (FFT), threshold recurrence plot, and unthresholded recurrence plot. The image classification was then performed using CNN, and the accuracy of each visualization method was compared and analyzed. The nonlinear behavior of chaotic systems was examined using the commonly known Van der pol, Rossler, and Duffing equations. The Lyapunov exponent was calculated for each model parameter change to determine the chaos. The classification accuracy was examined for the chaotic signal in each visualization method of the proposed architecture based on VGG 16 using the determined label and image.The classification accuracy for the chaos of each visualization method is the result of signals mixed randomly five times. FFT analysis showed the highest evaluation result."
개인 인증을 위한 CNN 기반 보행 패턴 식별,2022,"['gait analysis', 'convolutional neural network', 'personal authentication', '.']","최신의 보행 분석 연구에서 사람의 걸음걸이가 지닌 고유한 특징을 사용자 인증 수단으로 활용하려는 노력이 진행 중이다. 본 논문에서는 관성 센서로 획득한 인간의 걸음걸이 데이터를 CNN 모델로 학습하여 보행자가 누구인지 식별하는 것을 연구한다. 학습 모델의 평가지표로 흔히 사용하는 정확도, 정밀도, 재현율, F1-score, ROC Curve, AUC와 생체인증 평가지표인 FAR, FRR, EER을 활용하여 본 논문에서 제안한 모델을 평가하였다. 그 결과, 정확도, 정밀도, 재현율, F1-score 모두 99% 이상의 결과를 얻었다. 또한, 평균 AUC는 0.99, 평균 EER은 0.0009로 연구에서 제안된 모델이 높은 신뢰성을 가지고 사람의 걸음걸이를 식별할 수 있으며 사용자 인증을 위한 수단으로 사용 가능하다는 결론에 도달했다.","Efforts are underway to utilize the unique characteristics of human gait as a tool for user authentication in the latest gait analysis study. In this paper, we study the identification of pedestrians by learning human gait data acquired by an inertial sensor with a CNN model. The model proposed in this paper is evaluated using accuracy, precision, recall, F1-score, ROC Curve, AUC, which are used as general evaluation indicators, and FAR, FRR, and EER, which are biometric evaluation matrices. As a result, the accuracy, precision, recall, and F1-score are all over 99%. In addition, the average AUC is 0.99, and the average EER is 0.0009, which leads to the conclusion that the model proposed in the study can identify human gait with high reliability and can be used as a method for user authentication."
보행주기를 이용한 개인식별 CNN 모델,2022,"['gait cycle', 'convolutional neural network', 'personal identification']",국문 초록 정보 없음,"Various studies exist to identify individuals. Personal identification research based on inertial data, that is, acceleration and angular velocity acquired with an inertial sensor, is also one of these efforts. In fact, when learning inertial data with CNN, individuals can be identified with high accuracy. However, the individual identification model using inertial data significantly lowers the identification performance when the shoes worn by the individual change. This paper deals with improving this problem by using gait cycle data extracted from inertia data. First, the CNN model using the gait cycle was implemented, and then the model was evaluated using the representative performance evaluation indicators, such as accuracy, precision, recall, and F1-score. As a result, it was confirmed that the proposed model can identify individuals with more than 90% accuracy even when the shoes worn are different."
Fast Pedestrian Action Classification Based on Multi-head CNN,2022,"['pedestrian action recognition', 'pedestrian attribute  recognition', 'multi-task model', 'data imbalance', 'data balancing']",국문 초록 정보 없음,"Recently, research on pedestrian action recognition from the vehicle’s viewpoint is being studied in many ways. The information about pedestrian action classification is very important for autonomous driving to determine safe path planning and avoid accidents. To provide a computationally efficient solution to pedestrian action recognition, this paper proposes a multi-head CNN model to currently extract multi-actions of pedestrians from the unified model. This model consists of one pre-trained backbone network and two head networks. One head network classifies Gait (walking/standing) and the second classifies Attention (looking/non-looking) of pedestrians. The proposed model offers a lighter model with smaller memory, faster processing speed, and alleviates data imbalance problem – a common problem found in most of dataset – leading to improved accuracy."
노후 설비배관 진단을 위한 열화상이미지 기반 CNN 모델 Hyperparameter 최적설계,2022,"['이상현상 진단', '건물 설비배관', '열화상이미지', 'CNN 모델', '하이퍼파라미터', 'Fault diagnosis', 'Building plumbing', 'Thermal image', 'CNN model', 'Hyperparameter']",국문 초록 정보 없음,다국어 초록 정보 없음
Denoising on Low-Dose CT Image Using Deep CNN,2022,"['Low-dose CT Image', 'Convolutional Neural Network', 'Deep CNN', 'Mish Activation']",국문 초록 정보 없음,"Computed Tomography (CT) scans are widely used in Japan, and they contribute to public health. On the other hand, there is also a risk of radiation exposure. To solve this problem, attempts are being made to reduce the radiation dose during imaging. However, reducing the radiation dose causes noise and degrades image quality. In this paper, we propose an image analysis method that efficiently removes noise by changing the activation function of Deep Convolutional Neural Network (Deep CNN). Experimental tests using full-body slice CT images of pigs and phantom CT images of lungs with Poisson noise show that the proposed method is helpful by comparing them with normal-dose CT images and evaluating image quality using peak signal-to-noise ratio (PSNR)."
Masked Face Recognition via a Combined SIFT and DLBP Features Trained in CNN Model,2022,"['Face recognition', 'masked face', 'scale invariant features', 'image segmentation', 'local binary pattern', 'CNN model']",국문 초록 정보 없음,"The latest global COVID-19 pandemic has made the use of facial masks an important aspect of our lives. People are advised to cover their faces in public spaces to discourage illness from spreading. Using these face masks posed a significant concern about the exactness of the face identification method used to search and unlock telephones at the school/office. Many companies have already built the requisite data in-house to incorporate such a scheme, using face recognition as an authentication. Unfortunately, veiled faces hinder the detection and acknowledgment of these facial identity schemes and seek to invalidate the internal data collection. Biometric systems that use the face as authentication cause problems with detection or recognition (face or persons). In this research, a novel model has been developed to detect and recognize faces and persons for authentication using scale invariant features (SIFT) for the whole segmented face with an efficient local binary texture features (DLBP) in region of eyes in the masked face. The Fuzzy C means is utilized to segment the image. These mixed features are trained significantly in a convolution neural network (CNN) model. The main advantage of this model is that can detect and recognizing faces by assigning weights to the selected features aimed to grant or provoke permissions with high accuracy."
The Evaluation of Deep Learning Using Convolutional Neural Network (CNN) Approach for Identifying Arabica and Robusta Coffee Plants,2022,"['Leaf classification', 'Robusta coffee', 'Arabica coffee', 'Convolutional neural network', 'Coffee species', 'Precision agriculture']",국문 초록 정보 없음,"Purpose Arabica and Robusta coffee plants are physically distinctive as manifested in their leaves, leaf shape, color, and size.However, for ordinary people or those who have just begun their business in coffee cultivation, identifying the type of coffee plant can be challenging. In this study, we incorporated and evaluated deep learning technology to identify the types of coffee based on leaf image identification.Methods In this study, we designed a deep learning architecture and compared it with the well-known approaches, including LeNet, AlexNet, ResNet-50, and GoogleNet. A total of 19,980 image datasets were split into training and testing data, consisting of 15,984 images and 3,996 images, respectively.Results The hyperparameters were taken into account where the use of 100 epoch and 0.0001 learning rate provided the highest accuracy. In addition, 10-fold cross-validation and ROC were used for evaluating the proposed architectures. The results show that the developed convolutional neural network (CNN) generated the highest accuracy of 97.67% compared to LeNet, AlexNet, ResNet-50, and GoogleNet with an accuracy rate of 97.20%, 95.10%, 72.35%, and 82,16%, respectively.Conclusions The modified-CNN algorithm had satisfactory accuracy in identifying different types of coffee. The underlying principles of such classification draw specific attention to the leaf shape, size, and color of Arabica and Robusta coffee. For future works, it is a potential method that can be used to rapidly identify diverse varieties of Robusta and Arabica coffee plants based on leaf tissue and above canopy characteristics."
Data anomaly detection for structural health monitoring using a combination network of GANomaly and CNN,2022,"['convolutional neural network', 'data anomaly detection', 'generative adversarial network', 'Gramian angular field', 'long-span bridge', 'structural health monitoring']",국문 초록 정보 없음,"The deployment of advanced structural health monitoring (SHM) systems in large-scale civil structures collects large amounts of data. Note that these data may contain multiple types of anomalies (e.g., missing, minor, outlier, etc.) caused by harsh environment, sensor faults, transfer omission and other factors. These anomalies seriously affect the evaluation of structural performance. Therefore, the effective analysis and mining of SHM data is an extremely important task. Inspired by the deep learning paradigm, this study develops a novel generative adversarial network (GAN) and convolutional neural network (CNN)-based data anomaly detection approach for SHM. The framework of the proposed approach includes three modules : (a) A three-channel input is established based on fast Fourier transform (FFT) and Gramian angular field (GAF) method; (b) A GANomaly is introduced and trained to extract features from normal samples alone for class-imbalanced problems; (c) Based on the output of GANomaly, a CNN is employed to distinguish the types of anomalies. In addition, a dataset-oriented method (i.e., multistage sampling) is adopted to obtain the optimal sampling ratios between all different samples. The proposed approach is tested with acceleration data from an SHM system of a long-span bridge. The results show that the proposed approach has a higher accuracy in detecting the multi-pattern anomalies of SHM data."
CNN 이미지 분류 모델을 위한 메타모픽 테스트 케이스 생성 기법,2022,"['CNN', '메타모픽 테스팅', '테스트 케이스 생성', '머신러닝 테스팅', 'metamorphic testing', 'test case generation', 'machine learning testing']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN 및 Grad-CAM 기반의 궤양병 감귤 이미지 분류모델 구축 및 점검,2022,"['CNN', 'Grad-CAM', 'XAI']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반 일반과 멸균 종이팩 분류기 개발,2022,[],국문 초록 정보 없음,"In order to increase the recycling rate of pack-type paper wastes, it is important to classify them into general and the inner coated sterilized type. Existing waste separation and collection systems cannot distinguish between these two types. This paper proposes a system classifying pack-type paper waste into general or sterilization type utilizing CNN(Convolutional Neural Network). Our neural network based on VGG16 is trained by transfer learning and its model size is reduced using pruning and weight clustering for use in embedded systems. As a result, the accuracy is measured at 99.8%. While the accuracy maintains, pruning and weight clustering is confirmed to reduce the model size upto 1/3 and 1/14 of the original model size, respectively."
LSTM-CNN 모델 기반 실시간 시뮬레이션 응용 단기 풍력발전예측 시스템 방안,2022,"['LSTM(장단기 메모리)', 'CNN(합성곱 신경망)', 'RTDS(실시간 디지털 시뮬레이터)']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반 위성 이미지를 활용한 격자단위 인구추정,2022,"['북한 센서스', '위성 이미지', 'CNN', '격자인구', 'Land Viewer']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN 모델을 이용한 위해 식품 알림 애플리케이션의 개발,2022,"['Hazard Food', 'CNN', 'Crawling', 'Real-time Reasoning', 'Model Quantization']",국문 초록 정보 없음,다국어 초록 정보 없음
드롭아웃 기법이 CNN 기반 숫자지화 인식 성능에 미치는 영향,2022,"['CNN', 'time series sEMG signals', 'dropout', 'sEMG pre-processing', 'finger number recognition']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반 불법 복제 영상 검출 시스템 설계,2022,[],"언제(Anytime), 어디서나(Anywhere), 어떤 기기(Anydevice)로도 원하는 영상을 자유롭게 이용할 수 있는 미디어 환경으로 변화함에 따라 디지털 콘텐츠의 저작권 침해가 빈번하게 발생하고 있다. 또한 불법 복제 영상이 실시간으로 국내외 불법 다운로드 사이트뿐만 아니라 모바일 메신저, 특정 커뮤니티 등을 통한 불법 유포가 이루어지고 있다. 본 논문에서는 CNN(Convolutional Neural Network) 기반 불법 복제 영상 검출 시스템을 제안한다. 제안된 시스템은 세그먼트 단위 특징값을 이용하여 실시간으로 입력된 영상이 불법 복제 영상인지 판단하는 기능을 수행한다.",다국어 초록 정보 없음
CNN 기반 아보카도 숙성도 분류,2022,[],국문 초록 정보 없음,"Avocado, which is used in various diet foods, has been listed in the Guinness Book of World Records as the most nutritious fruit in the world as well as teenage superfoods. Avocado is a fruit that requires post-aging, so it was often difficult for consumers to know if post-aging was completed. Previously, research has been conducted to determine the maturity of avocados using electrodes. However, in this study, the goal is to implement an algorithm that determines whether avocados have matured when consumers photograph them using a camera. The dataset was actually collected by taking about 2600 photos of avocados in the categories of ripe, unripe, and rotten, and a convolutional neural network (CNN) based network was trained. As a result, it was confirmed that about 72% of the accuracy was shown."
RNN/CNN 을 활용한 FTN 기반의 긴급신호 간섭제거 및 복조 기술 설계 및 성능 분석,2022,[],"FTN 전송기법은 주파수 대역폭에 의해 주어지는 펄스 성형 형태는 그대로 유지하면서 Nyquist 전송 주기보다 더 빠르게 신호를 전송하여 동일 대역폭에서 Nyquist 전송 방식 보다 더 높은 전송 효율을 가지는 전송방식이다. 따라서 FTN 전송방식은 송신 펄스 중첩에 의한 심볼간 간섭이 필연적으로 발생한다. 이러한 FTN 방식을 활용하여 긴급신호를 전송하는 경우 주파수 효율은 향상시킬 수 있지만, 심볼간 중첩에 의한 간섭의 정확한 제거가 매우 중요하다. 본 논문에서는 상기 FTN 시그널링을 활용하여 전송되는 긴급신호를 수신하여 딥러닝 기반의 RNN 과 CNN 방식으로 간섭을 제거하고 복조하는 기술을 제안한다. 제안된 기술은 낮는 SNR 에서는 복잡도가 매우 높은 기존의 BCJR 간섭제거 기법보다 우수한 성능을 제공하는 것이 가능하다.",다국어 초록 정보 없음
GWO-CNN 기법을 이용한 리튬-이온 배터리 건전성 예측성능 향상에 대한 연구,2022,"['Lithium-ion battery', 'SOH', 'GWO', 'CNN', '데이터기반 모델']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN 모델을 이용한 자막 프레임 검출 알고리즘,2022,"['Captioned frame detection', 'video editing', 'CNN', 'deep learning']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반 모델들을 활용한 버섯 이미지 분류 연구,2022,[],"본 논문에서는 버섯 이미지의 분류를 위하여 CNN 기반 모델(LeNet, ResNet50, ResNet152, MobileNet)을 사용하였다. 본 연구에 사용된 데이터는 Kaggle에 데이터 세트를 이용하였다. 정확도를 높이기 위해 데이터 전처리 작업과 4개 정도의 모델들을 활용해 보았다. 여러 모델들을 이용하여 학습하였을 때, 분류 예측 정확도는 ResNet, MobileNet에서 75% 정도가 나온 것을 확인할 수 있었다. 더 나아가 이렇게 학습된 분류 모델을 활용하여 독버섯으로 인한 사고가 방지되길 기대한다.",다국어 초록 정보 없음
Lightweight CNN Model For Real Time Recognition of Miniaturize Fleet of UAVs,2022,"['Drone', 'detection', 'deep learning', 'CNN', 'UAV']",국문 초록 정보 없음,"The accelerating deployment of UAVs in different sectors of life is a plausible contribution in today’s technologically driven world. However, there is also a corresponding increase in UAVs misapplications resulting to economic losses. Therefore, the need to design an efficient anti-drone system in the optimal recognition of drones so as to prevent them from gaining access to restricted areas is a constant strive of researchers. This paper proposes a vision based anti-drone model for optimal detection of miniaturized fleet of drones even in clustered environments. Validation of the proposed model was achieved using 1000 samples of three different drones and birds on several weather scenarios of cloudy, clumsy and sunny conditions. Performance of the proposed model was compared with three other state-of-the-art models based on Precision, Recall and F1-score. Result of simulation shows the superiority of the proposed model in achieving F1-score of 97%, Recall and Precision values of 100% and 94.3% respectively."
Comparison of Performance of 1D CNN and LSTM Models for Multi-Channel Time Series Data Discrimination,2022,"['1D CNN', 'LSTM', 'deep learning', 'time series data', 'sensor array']",국문 초록 정보 없음,다국어 초록 정보 없음
합성곱신경망(CNN)을 활용하여 국내 해양레저관광지 사진 분류 및 해양레저관광 행태를 분석할 수 있는가?,2022,"['해양레저관광지(Marine Tourism)', '해수욕장(Beach)', '이미지 분류(Image Classification)', '딥러닝(Deep-learning)', 'CNN(Convolutional Neural Network)']",국문 초록 정보 없음,다국어 초록 정보 없음
Comparison of Performance of 1D CNN and LSTM Models for Multi-Channel Time Series Data Discrimination,2022,"['1D CNN', 'LSTM', 'deep learning', 'time series data', 'sensor array']",국문 초록 정보 없음,다국어 초록 정보 없음
이미지 처리와 CNN 을 활용한 딥러닝 기반 초소형 배터리 레이저 용접 공정 분류,2022,"['Vision inspect', 'Deep learning', 'Small battery', 'Tensile strength', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
압축센싱이 Mask R-CNN 기반의 객체검출에 미치는 영향 분석,2022,"['Mask R-CNN', 'Object Detection', 'Compressed Sensing', 'Instance Segmentation', 'Internet of Things']",국문 초록 정보 없음,다국어 초록 정보 없음
Face Recognition Resear ch Based on Multi-Layer s Residual Unit CNN Model,2022,"['Face Recognition', 'CNN Model', 'Deep Learning', 'Generative Adversarial Network']",국문 초록 정보 없음,다국어 초록 정보 없음
예측 민감도평가를 위한 3D-CNN기반의 예보장 예측모델 개발,2022,"['예측 민감도', '관측 영향', '예보장 예측', '시계열 분석', '3D-CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
Classification of Short-Circuit Marks in Electric Fire through Transfer Learning and Fine-Tuning the CNN Algorithm,2022,"['Short-Circuit', 'Deep CNN', 'Vgg16', 'Electric fire', 'Melton traces of wires']",국문 초록 정보 없음,다국어 초록 정보 없음
비정형 금융 데이터에 관한 인공지능 CNN 활용 빅데이터 연구,2022,"['Unstructured Data', 'Artificial Intelligence', 'CNN (Convolution Neural Network) Algorithm', 'Machine Learning', 'Deep Learning']",국문 초록 정보 없음,다국어 초록 정보 없음
관개용수로 CCTV 이미지를 이용한 CNN 딥러닝 이미지 모델 적용,2022,"['Image classification', 'image segmentation', 'CCTV images', 'irrigation canal']",국문 초록 정보 없음,"A more accurate understanding of the irrigation water supply is necessary for efficient agricultural water management. Although we measure water levelsin an irrigation canal using ultrasonic water level gauges, some errors occur due to malfunctions or the surrounding environment. This study aims toapply CNN (Convolutional Neural Network) Deep-learning-based image classification and segmentation models to the irrigation canal’s CCTV(Closed-Circuit Television) images. The CCTV images were acquired from the irrigation canal of the agricultural reservoir in Cheorwon-gun,Gangwon-do. We used the ResNet-50 model for the image classification model and the U-Net model for the image segmentation model. Using theNatural Breaks algorithm, we divided water level data into 2, 4, and 8 groups for image classification models. The classification models of 2, 4, and8 groups showed the accuracy of 1.000, 0.987, and 0.634, respectively. The image segmentation model showed a Dice score of 0.998 and predictedwater levels showed R2of 0.97 and MAE (Mean Absolute Error) of 0.02 m. The image classification models can be applied to the automaticgate-controller at four divisions of water levels. Also, the image segmentation model results can be applied to the alternative measurement for ultrasonicwater gauges. We expect that the results of this study can provide a more scientific and efficient approach for agricultural water management."
전류 신호를 이용한 1D CNN 기반 전기 분무 모드 감지,2022,"['Electrospray(전기분무)', 'Spray mode(분무 모드)', 'CNN(컨볼루션 신경망)']",국문 초록 정보 없음,다국어 초록 정보 없음
방향 정규화 및 CNN 딥러닝 기반 차량 번호판 인식에 관한 연구,2022,"['Licence plate recognition', 'Character segmentation', 'Character recognition', 'Direction normalization', 'Mask R-CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
의류 검색 프로그램을 위한 CNN 기반 의류 분류 모델,2022,[],"본 논문은 소비자들이 2D 이미지로 직접 상품을 검색할 수 있는 프로그램을 구현하기 위해서 기존 데이터 셋인 Fashion MNIST를 데이터 셋으로 사용하는 CNN(Convolutional Neural Network) 기반의 의류 분류 모델을 제안한다. 이러한 기술의 효과로는 소비자들이 텍스트로 상품을 검색하지 않아도 2D 이미지로 직접 검색해서 관련된 상품을 찾을 수 있는 편의성이다. 딥러닝 모델의 실행 결과 훈련 데이터에 대한 학습 정확도는 97.82%, 검증 데이터에 대한 학습 정확도는 91.84%를 도출할 수 있었다. 이러한 점을 통해 개인의 소비와 패션 욕구를 해소할 수 있는 효과적인 인공지능 프로그램이 될 것이라고 기대한다.",다국어 초록 정보 없음
360° LiDAR를 이용한 CNN 기반 사람 인식 및 확장 칼만 필터 기반 위치 추적 방법,2022,"['Smart factory', 'LiDAR', 'CNN machine learning', 'Extended kalman filter', 'Occupied grid map']",국문 초록 정보 없음,다국어 초록 정보 없음
Integrated YOLO and CNN algorithms for Evaluating Degree of Walkway Breakage,2022,"['Walkway', 'YOLO algorithm', 'Image deep learning', 'Breakage detection', 'Walking environment assessment', 'Pedestrian safety', 'Evaluation indicators']",국문 초록 정보 없음,"The focus of policymaking in Korea has changed from vehicle-centric road environments to people-centric environments. As the importance of walking has increased, the construction of pedestrian paths and interest in pedestrian environments have also increased. However, problem recognition and resolution require considerable time in the event of a problem in a pedestrian path. People with reduced mobility tend to resist changes in roads that they use. Thus, damaged pedestrian paths and obstacles pose a considerable risk and economic loss to transportation. In this study, we aimed to minimize the time and cost required for the evaluation of pedestrian paths by developing an automatic system for determining damage using integrated You Only Look Once (YOLO) and convolutional neural network (CNN) image deep learning algorithms. We constructed a model using image deep learning by dividing the steps into walkway breakage detection and score evaluation according to the degree of breakage. The accuracy of the model was determined to be 92%. In the future, the evaluation of pedestrian path damage is expected to be automated using images and videos, thereby reducing the time required for the detection and restoration of damage."
GAN based Data Augmentation with vehicle color change for training  vehicle detection CNN,2022,"['Convolutional Neural Network (CNN)', 'Generative Adversarial Network  (GAN)', 'Data Augmentation', 'Generative models']",국문 초록 정보 없음,"While recent convolutional neural networks (CNNs) for object detection have been substantially improved, they require a large amount of annotated data to further improve their accuracy to the level of human. Such annotated data is scarce. The generation of ground truth to annotate training data is a time consuming and resource expensive process. Researchers use traditional data augmentation techniques to increase the amount of training data. Recently, generative models are being employed to augment data which produces diverse training data. This leads to an increase in model performance. This paper presents a method to train a GAN network and generate augmented data of any domain of interest with the least compromise in the quality of generated images. The proposed method trains a GAN with vehicles images of different colors. Then it can change the color of vehicles in any given vehicle dataset to a set of specified colors."
굴착복구 후 도로 포장 상태 분류를 위한 전이학습용 CNN 기초 연구,2022,"['도로 포장', '상태 분류', '딥러닝', 'CNN', '전이학습']",국문 초록 정보 없음,다국어 초록 정보 없음
Audio-Based Hate Speech Detection for the Metaverse using CNN,2022,"['metaverse', 'hate speech', 'speech recognition', 'CNN', 'audio speech']",국문 초록 정보 없음,다국어 초록 정보 없음
Improved real-time power analysis attack using CPA and CNN,2022,"['Side Channel Attack', 'AES', 'CPA', 'CNN', 'ATmega328', 'Oscilloscope', '부채널 공격', '고급 암호화 표준', '차분 전력 공격', '합성곱 신경망', '오실로스코프']",국문 초록 정보 없음,다국어 초록 정보 없음
FCPNet : A novel model to predict forward collision based-upon CNN,2022,"['unmanned aerial vehicle', 'convolutional neural network', 'collision prediction', 'Raspberry Pi']",국문 초록 정보 없음,"Predicting real-time collisions in unknown environments is a challenge especially for autonomous vehicles to avoid obstacles during missions. In this paper, we propose a novel approach called FCPNet which is a model based on Convolutional Neural Network (CNN) for a fast collision prediction. FCPNet is designed to run on CPU and embedded in an autonomous Unmanned Aerial Vehicle (UAV). Inspired by DroNet, FCPNet is composed of a ResNet-8 with three residual blocks, a dropout layer, and one output layer. Training and validation data are the Zurich images collected in an unstructured outdoor environment such as a city. This dataset consists of 31, 972 color images in two classes: collision and no collision. FCPNet is compared to VGG-16, ResNet50V2, and MobileNetV2 models on CPU. The proposed model achieves the best F1-score and execution time on Raspberry Pi 4 thanks to the optimized parameters and class weights initialization to deal with an imbalanced dataset. The collision prediction probabilities as an alternative approach to ultrasonic sensors are presented in terms of confusion matrix showing the outstanding performance of FCPNet. We plan to use the proposed model with an obstacle avoidance policy to build robust and fast autonomous aerial vehicles."
Development of Temporal Subtraction Technique for Phalanges CR Image using Geometric-matching CNN,2022,"['Computer-Aided Diagnosis', 'Image Registration', 'Temporal Subtraction', 'Rheumatoid Arthritis']",국문 초록 정보 없음,"We are developing a computer-aided diagnosis system for rheumatoid arthritis. X-rays images are widely used to diagnose the rheumatoid arthritis. However, it is difficult for physicians to read minute changes from the images. Therefore, we propose a method to visualize lesions in the phalangeal region by comparing past and current images of the same subject using a temporal subtraction technique. The proposed method consists of three steps: segmentation of phalanges, registration, and generation of subtraction images. First, the phalangeal region is extracted from the hand CR image using DeepLabv3+. Next, the past and current phalangeal region images are aligned by geometric-matching based on a CNN (convolutional neural networks) with instance-specific optimization. Finally, we apply the temporal subtraction technique to those images. We confirmed the effectiveness of the proposed registration method in an experiment using synthetic data. Also, the proposed method was applied to a pair of past and current image sets on same subject to generate a subtraction image. As a result, we confirmed that the proposed method can visualize changes between past and current images."
"CNN, LSTM기반 오토인코더를 이용한 공정 사이클 이상 패턴 탐지",2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반 비디오 단위 특징값 추출 및 영상 검출 시스템 설계,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반 부유식 해중터널 계류선 손상탐지 기술 연구,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 모델을 이용한 CCB-OCC 패킷 동기화 성능 개선,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 알고리즘을 이용한 성인 검출 시스템 개발,2022,"['Clothe information', 'Artificial intelligence', 'Adults', 'Detecting system']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반 부분방전 패턴분석의 정합성 향상에 대한 연구,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN(convolutional neural network) model development for analysis of acetaminophen or 1-naphthyl Isothiocyanate-induced liver necrosis in mouse,2022,"['Artificial intelligence', 'Acetaminophen', '1-naphthyl isothiocyanate', 'Liver necrosis', 'Model accuracy']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반 이미지 분류 모델 훈련 시 병렬 처리 기술이 학습 속도에 미치는 영향,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반의 학습 네트워크를 활용한 음성 감정 인식 기법,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반의 전이 학습을 이용한 다수 전동기에서 취득한 고장 진단 데이터 분석,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반 침입 탐지 시스템의 입력 모형 최적화,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반 배달용기 오염도 분류,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반 해충 판별 시스템 설계,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반 차량 밑면 중심점 검출을 통한 차량 위치 추정 정확도 개선,2022,"['Vehicle position estimation(차량 위치 추정)', 'Bottom face center(밑면 중심점)', 'Deep neural network(딥뉴럴네트워크)', 'Vehicle-to-infrastructure communication(V2I 통신)', 'Surveillance camera(감시 카메라)']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN 을 통한 신선도 기반 과실 분류 모델 설계,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반 안면 상태 감지 모델을 통한 비대면 학습자 강의 집중도 분석 알고리즘,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 전이학습을 적용한 RVM 종이팩 검사 기능 개발,2022,"['Liquid Packaging Carton', 'Recycling', 'Reverse Vending Machine', 'Artificial Intelligence', 'Convolutional Neural Networks', 'Transfer Learning']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN ‘한국 방산 4강론’ 집중 조명,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 분류 프로그램을 이용한 쓰레기 분류 장치에 대한 연구,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
1D-CNN을 이용한 항만내 선박 이동시간 예측,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반 네일 아트 컬러 자동 분류기,2022,[],"본 논문에서는 네일 아트를 한 손 이미지가 주어졌을 때 손톱에 있는 네일 아트의 컬러를 자동으로 분류해주기 위한 시스템을 제안한다. 네일 아트 컬러 자동 분류기는 Object Detection 모델을 이용하여 인풋으로 들어오는 손 이미지에서 손톱 영역을 찾고, 각 손톱에 대하여 13 가지 컬러 중 하나로 분류한 결과를 아웃풋으로 반환한다. 본 프로젝트에서는 사용자가 요청하는 네일 아트 손 이미지에 대하여 컬러 라벨링 결과를 반환해주는 API 형태의 서비스를 제안하며, 반응형 웹을 통해 시연 가능하도록 시스템을 설계 및 구현하였다.",다국어 초록 정보 없음
"CNN, KTS, RNN과 강화학습을 이용한 비디오 요약",2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
인공신경망(CNN)을 활용한 남해일대 적조발생 예측에 관한 연구,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
Dlib과 CNN 머신러닝을 활용한 눈 깜빡임 탐지,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
Mask R-CNN을 이용한 FPCB의 컨포멀 코팅 영역 검출,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱신경망(CNN)을 이용한 SA 용접부 결함 검출,2022,"['잠호 용접 (Submerged Arc Welding)', '기계 학습 (Machine Learning)', '합성곱신경망 (Convolutional Neural Network)', '분류 (Classification)']",국문 초록 정보 없음,다국어 초록 정보 없음
합성곱신경망(CNN)을 이용한 SA 용접부 결함 검출,2022,"['잠호 용접 (Submerged Arc Welding)', '기계 학습 (Machine Learning)', '합성곱신경망 (Convolutional Neural Network)', '분류 (Classification)']",국문 초록 정보 없음,다국어 초록 정보 없음
합성곱신경망(CNN) 기반의 선박 객체 인식 기술 개발,2022,"['자율운항선박', '객체 인식 알고리즘', 'YOLO', '라벨링', 'Maritime Autonomous Surface Ship', 'Object Detection Algorthm', 'YOLO', 'Labeling']",국문 초록 정보 없음,다국어 초록 정보 없음
A CNN and LSTM based model for modification prediction of RNA 5-Hydroxymethylcytosine,2022,"['RNA 5-hydroxymethylcytosine', 'sequence analysis', 'convolutional neural network', 'long short-term memory', 'deep learning']",국문 초록 정보 없음,다국어 초록 정보 없음
Using CNN to predict 6mA methylation in the Rice genome,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
여러 CNN 애플리케이션에서 Systolic Array 성능의 해석적 모델링,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
시계열적 특성이 CNN 기반 네트워크 이상치 탐지에 미치는 영향 및 이상치 탐지 방법에 대한 연구,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
[특집 4 CNN 기자를 통해 듣는 전쟁 취재 환경] 외신들은 어떻게 전쟁을 보도하고 있는가,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
FPGA를 활용한 CNN 가속기 하드웨어 설계,2022,"['FPGA', 'Convolution Neural Nework', 'Hardware Accelerator']",국문 초록 정보 없음,다국어 초록 정보 없음
웨이블릿 스칼로그램을 활용한 CNN 기반 연마효과 예측모델,2022,"['Acoustic Eission(음향방출)', 'Scalogram(스칼로그램)', 'Convolutional Neural Network(합성곱신경망)', 'Wavelet Transform(웨이블릿 변환)']",국문 초록 정보 없음,다국어 초록 정보 없음
Tensorflow API 기반 CNN 모델을 적용한 베어링 고장감지,2022,"['Convolution Neural Network', 'Fault Classification', 'Multi-Layer Perceptron', 'Machine Learning']",국문 초록 정보 없음,다국어 초록 정보 없음
이미지 전처리를 이용한 CNN 기반 모델들에서 해상 열화상 선박 이미지 분류 성능 비교,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
Predicting cosmological parameters using CNN and ViT from large scale simulation,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
Xilinx DPU를 이용한 CNN 기반 초해상화 하드웨어 구현,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
2D 스펙트로그램을 이용한 멀티스트림 CNN 기반 운전자 식별 시스템,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
전류 신호를 이용한 1D CNN 기반 전기 분무 모드 감지,2022,"['Electrospray', 'Electrostatic', '1D convolution neural network', 'Class activation map']",국문 초록 정보 없음,다국어 초록 정보 없음
깊이 정보의 활용에 따른 CNN 기반 의미론적 영상 분할 성능 분석,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
Integration of Segmentation and CNN for Skin Lesion Classification,2022,"['convolutional neural network', 'skin lesion', 'accuracy', 'dermos copy', 'gaussian distribution']",국문 초록 정보 없음,다국어 초록 정보 없음
Video Deepfake Detection using CNN and Vision Transformer,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
음식 이미지 분류를 위한 CNN 모델 일반화 방법 적용 및 분석,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
입력 데이터 형태에 따른 CNN 기반 변조 분류 성능 비교,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
Pose Estimation 과 CNN 을 이용한 실시간 손 제스처 인식,2022,"['RGB-D Sensor', 'Pose estimation', 'Hand gesture recognition', 'Convolutional Neural Network', 'Human-Computer-Interaction']",국문 초록 정보 없음,다국어 초록 정보 없음
세포 형태 정보를 활용한 CNN 기반 순환 종양 세포 분류,2022,"['cancer classification', 'shape analysis', 'artificial nueral network', 'cell images', 'liquid biopsy']",암 진단의 새로운 방법인 ‘액체 생체검사’는 기존의 ‘조직 생체검사‘와는 달리 비침습적인 특성과 검사의 효율성으로 인해 주목받고 있으며 이와 인공지능을 결합한 예측 모델 연구 역시 활발히 이루어지고 있다. ‘액체 생체검사’에서 사용되는 바이오 마커의 염색 강도는 예측 모델의 분류 결과의 주요 변수 역할을 한다. 하지만 아직 표준화되지 않은 액체 생체검사 및 진단 기준에 의해 염색 강도는 이를 시행하는 전문가에 따라 달라 활용성이 떨어진다. 따라서 이를 보완하기 위한 세포의 형태 정보만을 활용하여 혈액 내 세포의 순환 종양 세포를 예측하였다.,"‘Liquid biopsy’, a new method of cancer diagnosis, is attracting attention due to its non-invasive characteristics and efficiency of examination, unlike the existing ‘tissue biopsy’, and research on predictive models that combine this with artificial intelligence is also being actively conducted. The staining intensity of the biomarker used in ‘liquid biopsy’ serves as a major variable in the classification result of the predictive model. However, due to liquid biopsy and diagnostic criteria that have not yet been standardized, the staining intensity varies depending on the expert performing it, making it less useful. Therefore, circulating tumor cells of cells in the blood were predicted using only cell shape information to compensate for this."
신호데이터 분류를 위한 1D 및 2D CNN 패턴분류기 설계: 비교분석,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
효율적인 Keyword Spotting을 위한 Open-Set Error 기반 CNN 학습 기법,2022,[],국문 초록 정보 없음,"The convolutional neural networks have been implemented and demonstrated on embedded devices for keyword spotting applications. In this paper, an open-set error based convolutional neural networks learning method is proposed for efficient keyword spotting. The pre-processing and training method to convert speech data to neural network data is also proposed. The experimental results by implementing in embedded SoC Products and GPU show that the proposed method achieves higher accuracy than conventional method."
베어링 고장진단을 위한 진동신호 스펙트럼 기반 1D CNN 모델 연구,2022,"['고장 진단(Fault Diagnosis)', '베어링 고장(Bearing Fault)', '1-D 합성곱 신경망(1-D Convolutional Neural Network)', '진동 신호 스펙트럼 (vibration spectrum)']",국문 초록 정보 없음,다국어 초록 정보 없음
W-kNN 기반 Fingerprint 측위 시스템의 성능향상을 위한 CNN 기반 가변 K 설정 알고리즘,2022,"['Fingerprinting', 'Long Term Evolution', 'Convolutional Neural Network', 'Weighted K-Nearest Neighbors']",국문 초록 정보 없음,다국어 초록 정보 없음
배전계통 고저항 사고 판별을 위한 CNN 모델링,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
다양한 데이터플로우 매핑과 입력 희소성 활용을 지원하는 CNN 가속기의 설계,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
Multivariate time series classification using multi channel CNN classifier,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
회전체 볼 베어링 결함 진단을 위한 CNN 모델 설계와 Grad-Cam을 이용한 진단결과 해석 연구,2022,"['Ball Bearing(볼 베어링)', 'Wavelet Transform(웨이블렛 변환)', 'Convolutional Neural Network(합성곱 신경망)', 'Fault Classification(결함 분류)', 'Grad-cam']",국문 초록 정보 없음,다국어 초록 정보 없음
블록 부동 소수점 기반 시스톨릭 어레이를 활용한 CNN 가속기,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
가스사고조사 업무 자동화를 위한 YOLO 및 CNN 기반 로봇비젼 알고리즘 개발,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
베어링 고장진단을 위한 진동신호 스펙트럼 기반 1D CNN 모델 연구,2022,"['고장 진단(Fault Diagnosis)', '베어링 고장(Bearing Fault)', '1-D 합성곱 신경망(1-D Convolutional Neural Network)', '진동 신호 스펙트럼 (vibration spectrum)']",국문 초록 정보 없음,다국어 초록 정보 없음
Self-Supervised Training Method of Vehicle Detection CNN Models,2022,"['convolutional neural network', 'detector', 'labeled data', 'self-supervised  learning']",국문 초록 정보 없음,"Autonomous driving relies on an accurate perception system that provides knowledge about surroundings and ensures safe driving performance. Usually, the perception system takes input information from onboard sensors (camera, LIDAR, RADAR, etc.) and then uses it to perform object detection tasks to accurately determine objects such as pedestrians, vehicles, traffic signs, and road barriers located around the ego vehicle. In order to have a safe trip and maneuver on the road, a vehicle detection algorithm should constantly improve the accuracy of vehicle detection. Since most of the conventional deep learning methods for vehicle or object detection rely on offline training with human-labeled large datasets, the conventional training methods have serious limitations in developing a breakthrough technique for gradual improvement in the detection accuracy of deep learning models. Thus, we propose a self-supervised training (SST) scheme that can gradually enhance detection accuracy with pseudo labeling."
환경 조건에 강인한 금속 표면 검사를 위한 CNN 기반 분류기 개발,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
SAR 이미지 반전잡음 제거 가속화를 위한 디노이징 CNN 아키텍처 개선,2022,"['SAR Image Despeckling', 'DeNoise Convolutional Neural Network', 'Synthetic Aperture Radar']",국문 초록 정보 없음,"Synthetic Aperture Radar (SAR) images are affected by noise called speckle, which is very severe and may hinder image exploitation. Despeckling is an important task that aims to remove such noise so as to improve the accuracy of all downstream image processing tasks. Many different schemes have been proposed for the restoration of SAR images. Among the different possible approaches, methods based on convolutional neural networks(CNNs) have recently shown to reach state-of-the-art performance for SAR image restoration. DnCNN(DeNoising Convolutional Neural Network) is one of the most widely used neural network architecture embedded in baseline SAR image despeckling methods. In military applications of SAR satellite image, fast processing is the most critical factor except the precision rate of the recognition. In this paper, we propose an improved DnCNN architecture for faster SAR image despeckling. The experimental results on real-world SAR images show that our proposed method takes faster processing time than the original DnCNN architecture without despeckling performance downgrade. Subjective visual inspection demonstrates that the proposed method has great potential in preserving the image signal details and suppressing speckle noise."
볼 베어링 결함 분류를 위한 CNN 알고리즘의 활성화 함수,2022,"['Activation Function(활성화 함수)', 'Ball Bearing(볼 베어링)', 'Convolutional Neural Network(합성곱 신경망)', 'Fault Classification(결함 분류)', 'Neural Network Learning(신경망 학습)']",국문 초록 정보 없음,다국어 초록 정보 없음
Multivariate time series classification using multi channel CNN classifier,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
The Harmony of Heterogeneous Computing Units in CNN Inference,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
영상 압축률을 이용한 네트워크 상태에 적응적인 MEC 기반 객체 검출 CNN 모델에 대한 성능 평가,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
Estimating Remaining Useful Life of Turbofan Engines Using Denoising CNN for Multivariate Time-Series Data,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
Estimating Remaining Useful Life of Turbofan Engines Using Denoising CNN for Multivariate Time-Series Data,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
Image Retrieval Based on the Weighted and Regional Integration of CNN Features,2022,"['Image retrieval', 'Weighting feature', 'Global feature', 'Convolutional neural network', 'Regional integration']",국문 초록 정보 없음,"The features extracted by convolutional neural networks are more descriptive of images than traditional features, and their convolutional layers are more suitable for retrieving images than are fully connected layers. The convolutional layer features will consume considerable time and memory if used directly to match an image. Therefore, this paper proposes a feature weighting and region integration method for convolutional layer features to form global feature vectors and subsequently use them for image matching. First, the 3D feature of the last convolutional layer is extracted, and the convolutional feature is subsequently weighted again to highlight the edge information and position information of the image. Next, we integrate several regional eigenvectors that are processed by sliding windows into a global eigenvector. Finally, the initial ranking of the retrieval is obtained by measuring the similarity of the query image and the test image using the cosine distance, and the final mean Average Precision (mAP) is obtained by using the extended query method for rearrangement. We conduct experiments using the Oxford5k and Paris6k datasets and their extended datasets, Paris106k and Oxford105k. These experimental results indicate that the global feature extracted by the new method can better describe an image."
A study on the malware detection using Deep Learning(CNN) with Similarity Hashing Scheme,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
3D-CNN Method over Shifted Patch Tokenization for MRI-Based Diagnosis of Alzheimer’s Disease Using Segmented Hippocampus,2022,"['Alzheimer’s Disease', 'Shifted Patch Tokenization', 'Convolutional Neural Network', 'Hippocampus Image Classification.']",국문 초록 정보 없음,"The application of a potential deep learning algorithm to the diagnosis of various neuropathic diseases such as AD (Alzheimer's disease) is attracting attention. This paper describes the implementation of a potential 3D-CNN (3D-convolutional neural network) network-based method for predicting hippocampal atrophy by applying deep learning technology to magnetic resonance imaging of Alzheimer's diseaserelated patients. The proposed method is implemented by applying the HippMapp3r algorithm for hippocampal MRI (magnetic resonance image) segmentation from the original image and applying the EfficientNet tool to help determine AD. To increase the accuracy of judgment in this process, the shifted patch tokenization (SPT) method was proposed and also implemented. The proposed framework can be very helpful in diagnosing AD by showing 94% and 96% accuracy in training and test sets, respectively."
Faster AR-CNN (Faster contrast-based Augmented R-CNN)을 활용한 Semi-supervised 학습 기반의 원형관 X-ray 결함 탐지,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
Faster AR-CNN (Faster contrast-based Augmented R-CNN)을 활용한 Semi-supervised 학습 기반의 원형관 X-ray 결함 탐지,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
Vehicle Damage Volume and Traffic Accident Types Recognition Algorithm based on Mask Regional-CNN,2022,[],국문 초록 정보 없음,"This paper proposed a recognition algorithm that can automate the car insurance claim process that can predict and recognize the volume of car damage and traffic accident types based on a mask region-based convolutional neural network (Mask R-CNN). The algorithm was proposed based on two functions such as vehicle damage volume recognition function and traffic accident types recognition function. As a result of the experiment, the average accuracy of vehicle damage volume recognition function at all levels was 73%, and the average accuracy of traffic accident types recognition function in all collisions was 86%."
화학 구조 문서 합성 데이터셋 제안 및 Mask R-CNN 기반의 화학 구조 인식,2022,[],"최근 인공지능 신경망에 대한 활발한 연구를 바탕으로 다양한 분야에서의 적용에 대해 많은 시도들이 이루어지고 있다. 이러한 흐름에 맞추어 화학 문서에서 화학 구조를 인식하는 문제 또한 딥러닝을 이용하여 해결하려는 시도들이 생겨나고 있다. 본 논문에서는 화학 문서에서 화학 구조를 인식하는 모델을 학습시키기 위한 합성 데이터셋을 제안하였다. 문서의 구조를 이용하여 정교하게 화학 구조들을 문서에 합성하여 데이터셋을 생성하였고, 이를 최신 딥러닝 모델 중 하나인 Mask R-CNN[7]에 학습시켜 제안한 데이터셋을 이용하여 문서에서 화학 구조를 인식할 수 있음을 보였다.",다국어 초록 정보 없음
A Tuberculosis Detection Method Using Attention and Sparse R-CNN,2022,"['Tuberculosis', 'Chest X-ray', 'Computer-aided diagnosis', 'Object detection', 'Attention']",국문 초록 정보 없음,"To achieve accurate detection of tuberculosis (TB) areas in chest radiographs, we design a chest X-ray TB area detection algorithm. The algorithm consists of two stages: the chest X-ray TB classification network (CXTCNet) and the chest X-ray TB area detection network (CXTDNet). CXTCNet is used to judge the presence or absence of TB areas in chest X-ray images, thereby excluding the influence of other lung diseases on the detection of TB areas. It can reduce false positives in the detection network and improve the accuracy of detection results. In CXTCNet, we propose a channel attention mechanism (CAM) module and combine it with DenseNet. This module enables the network to learn more spatial and channel features information about chest X-ray images, thereby improving network performance. CXTDNet is a design based on a sparse object detection algorithm (Sparse R-CNN). A group of fixed learnable proposal boxes and learnable proposal features are using for classification and location. The predictions of the algorithm are output directly without non-maximal suppression post-processing. Furthermore, we use CLAHE to reduce image noise and improve image quality for data preprocessing. Experiments on dataset TBX11K show that the accuracy of the proposed CXTCNet is up to 99.10%, which is better than most current TB classification algorithms. Finally, our proposed chest X-ray TB detection algorithm could achieve AP of 45.35% and AP50 of 74.20%. We also establish a chest X-ray TB dataset with 304 sheets. And experiments on this dataset showed that the accuracy of the diagnosis was comparable to that of radiologists. We hope that our proposed algorithm and established dataset will advance the field of TB detection."
SNN/CNN Hybrid SoC 플랫폼을 위한 프레임워크 구현,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
1D-CNN 기반 전파흡수체를 적용한 표적 분류,2022,"['1차원 합성곱 신경망(One-dimensional convolutional neural network)', '레이더 반사면적(Radar cross section)', '분류(Classification)', '전파흡수체(Radar absorber material)', '완전 전기 도체(Perfect electric conductor)']",국문 초록 정보 없음,다국어 초록 정보 없음
1D-CNN 기반 전파흡수체를 적용한 표적 분류,2022,"['1차원 합성곱 신경망(One-dimensional convolutional neural network)', '레이더 반사면적(Radar cross section)', '분류(Classification)', '전파흡수체(Radar absorber material)', '완전 전기 도체(Perfect electric conductor)']",국문 초록 정보 없음,다국어 초록 정보 없음
DSP R-CNN : Direct Set Prediction Region with Convolutional Neuron Networks features,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
Mask R-CNN 기반 Aspect Ratio를 활용한 이상행동 검출 및 영역화 방법,2022,"['딥러닝(deep learning)', '이상 행동(Anomaly Behavior)', 'Semantic segmentation']",국문 초록 정보 없음,다국어 초록 정보 없음
단기간 심전도를 사용한 1D-CNN 기반 심방세동 환자 평가,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
객체 추적을 위한 보틀넥 기반 Siam-CNN 알고리즘,2022,"['Deep Learning', 'Computer Vision', 'Object Tracking', 'Convolutional Neural Networks', 'Siamese Network']",국문 초록 정보 없음,다국어 초록 정보 없음
모바일 환경에서의 실시간 손동작 인식을 위한 경량화된 3D-CNN,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
[PC-0002] 블루베리 잎의 초분광 반사 스펙트럼과 1차원 합성곱 신경망(1D-CNN)을 이용한 멀칭 효과 분석연구,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
A Table and Chart Detection Method based on the Cascade R-CNN,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
"PDF 문서에서 텍스트, 이미지 및 도표를 자동으로 추출하기 위한 조건 기반 규칙과 Faster R-CNN 모델의 통합 적용 방안 연구",2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
데이터별 딥러닝 학습 모델의 정확도 향상을 위한 외곽선 특징 적용방안 연구,2022,"['CNN', 'Contour detection', 'Data augmentation']","CNN은 딥러닝의 한 종류로 이미지나 영상 데이터를 처리할 때 사용하는 신경망이다. 필터가 이미지를 순회하며이미지의 특징을 추출하여 이미지를 구분한다. 딥러닝은 데이터가 많을수록 좋은 모델을 만들 수 있는 특징이 있고, CNN에서는 적은 데이터의 약점을 보완하기 위해 회전, 확대, 이동, 뒤집기 같은 방법의 데이터 증강이라는 기법으로데이터의 양을 인위적으로 늘리는 방법을 사용한다. 외곽선 이미지 학습은 이미지 데이터에서 외곽선에 해당하는 영역을추출하는 것이다. CNN 학습 시, 외곽선 이미지 학습이 기존의 데이터 증강기법과 비교하여 성능 향상의 도움이 되는지확인하고자 한다.","CNN is a type of deep learning and is a neural network used to process images or image data.The filter traverses the image and extracts features of the image to distinguish the image. Deep learning has the characteristic that the more data, the better models can be made, and CNN uses a method of artificially increasing the amount of data by means of data augmentation such as rotation, zoom, shift, and flip to compensate for the weakness of less data. When learning CNN, we would like to check whether outline image learning is helpful in improving performance compared to conventional data augmentation techniques."
합성곱-장단기 기억 신경망의 하이브리드 결합 모델을 이용한 부정맥 분류,2022,"['Arrhythmia', 'CNN', 'LSTM', 'Deep learning', 'MIT-BIH', '부정맥', '합성곱 신경망', '장단기 기억 신경망', '심층 신경망', 'MIT-BIH']","부정맥은 심장 박동이 비정상 혹은 불규칙하게 뛰고 있는 상태를 말하며, 실신이나 심장돌연사 등과 같은 위험한 상황을 유발할 수 있기 때문에 이의 조기 검출은 매우 중요하다.하지만 심전도 신호의 개인차로 인해 분류 시 성능하락이 나타날 수밖에 없다. 본 연구에서는 CNN-LSTM 하이브리드 결합 모델을 이용한 부정맥 분류 방법을 제안한다. 이를 위해 먼저 잡음을 제거한 ECG 신호에서 R파를 검출하고 단일 비트 세그먼트를 추출하였다. 이후 부정맥 신호의 특징을 세밀하게 추출하도록 8개의 합성곱 계층으로 구성하고 이를 LSTM의 입력으로 사용한 후 가중치를 학습시키고 검증 데이터로 모델을 평가한 후 정상 및 부정맥 분류의 변화를 확인하였다. 제안한 방법의 타당성 검증을 위해 MIT-BIH 부정맥 데이터베이스를 사용하여 정확도(accuracy), 정밀도(precision), 재현율(recall), F1 스코어가 사용되었다. 성능평가 결과, 정확도, 정밀도, 재현율, F1 스코어는 각각 92.3%, 90.98%, 92.20%, 90.72%의 우수한 분류율을 나타내었다.","Arrhythmia is a condition in which the heart beats abnormally or irregularly, early detection is very important because it can cause dangerous situations such as fainting or sudden cardiac death. However, performance degradation occurs due to personalized differences in ECG signals.In this paper, we propose arrhythmia classification using hybrid combination model of CNN-LSTM. For this purpose, the R wave is detected from noise removed signal and a single bit segment was extracted. It consisted of eight convolutional layers to extract the features of the arrhythmia in detail, used them as the input of the LSTM. The weights were learned through deep learning and the model was evaluated by the verification data.The performance was compared in terms of the accuracy, precision, recall, F1 score through MIT-BIH arrhythmia database. The achieved scores indicate 92.3%, 90.98%, 92.20%, 90.72% in terms of the accuracy, precision, recall, F1 score, respectively."
소규모 합성곱 신경망을 사용한 연령 및 성별 분류,2022,"['Age Classification', 'Gender classification', 'Unfiltered Image Recognition', 'Imbalanced Classification Problems', '나이 분류', '성별 분류', '필터링되지 않은 영상 인식', '불균형 분류 문제']","인공지능은 놀라운 이점으로 우리 삶의 중요한 부분을 차지하고 있다. 기계는 이미지에서 물체를 인식하는 것, 특히 사람들을 정확한 나이와 성별 그룹으로 분류하는 것에 있어서 인간을 능가하고 있다. 이러한 측면에서 나이와 성별 분류는 최근 수십 년 동안 컴퓨터 비전 연구자들 사이에서 뜨거운 주제 중 하나였다. 심층 합성곱 신경망(CNN) 모델의 배포는 최첨단 성능을 달성했다. 그러나 대부분의 CNN 기반 아키텍처는 수십 개의 훈련 매개 변수로 매우 복잡하기 때문에 많은 계산 시간과 자원이 필요하다. 이러한 이유로 기존 방법에 비해 훈련 매개 변수와 훈련 시간이 현저히 적은 새로운 CNN기반 분류 알고리즘을 제안한다. 덜 복잡함에도 불구하고 우리 모델은 UTKFace 데이터 세트에서 연령 및 성별 분류의 더 나은 정확도를 보여준다.",다국어 초록 정보 없음
합성곱 신경망 기반의 인공지능 FPGA 칩 구현,2022,"['합성곱 신경망', '인공지능', 'FPGA (Field Programmable Gate Array)', 'CNN (Convolution Neural Vetwork)', 'AI (Artificial Intelligence)']","최근 인공지능 분야는 자율주행, 로봇 및 스마트 통신등 다양한 분야에 응용되고 있다. 현재의 인공지능 응용분야는 파이썬을 기반으로 한 tensor flow를 이용하는 소프트웨어 방식을 이용하고 있으며, 프로세서로는 PC의 그래픽 카드 내부에 존재하는 GPU (Graphics Processing Unit)를 이용하고 있다. 그러나 GPU 기반의 소프트웨어 방식은 하드웨어를 변경할 수 없다는 문제점을 가지고 있다. 이러한 문제점으로 인해 높은 수준의 판단이나 작업을 요구하는 경우에는 이에 적합한 높은 사양의 GPU가 필요하며, 이러한 경우에는 인공지능 작업을 처리하는 그래픽 카드로 교체해야 한다. 이러한 문제점을 해결하기 위해 본 연구에서는 HDL (Hardware Description Language)을 이용하여 반도체 내부의 회로를 변경할 수 있는 FPGA (Field Programmable Gate Array)를 기반으로 한 신경망 회로를 이용하여 합성곱 신경망 기반의인공지능 시스템을 구현하고자 한다.","Recently, AI (Artificial Intelligence) has been applied to various technologies such as automatic driving, robot and smart communication. Currently, AI system is developed by software-based method using tensor flow, and GPU (Graphic Processing Unit) is employed for processing unit. However, if software-based method employing GPU is used for AI applications, there is a problem that we can not change the internal circuit of processing unit. In this method, if high-level jobs are required for AI system, we need high-performance GPU, therefore, we have to change GPU or graphic card to perform the jobs. In this work, we developed a CNN-based FPGA (Field Programmable Gate Array) chip to solve this problem."
합성곱 신경망 및 영상처리 기법을 활용한피부 모공 등급 예측 시스템,2022,"['Skin', 'Pore', 'Image processing', 'CNN', 'Prediction']","본 논문은 사용자들에 의해 촬영된 피부이미지를 가공하여 데이터 세트를 구축하고, 제안한 영상처리 기법에 의해 모공 특징이미지를 생성하여, CNN(Convolution Neural Network) 모델 기반의 모공 상태 등급 예측 시스템을 구현한다. 본 논문에서 활용하는피부이미지 데이터 세트는, 피부미용 전문가의 육안 분류 기준에 근거하여, 모공 특징에 대한 등급을 라벨링 하였다. 제안한 영상처리 기법을 적용하여 피부이미지로 부터 모공 특징 이미지를 생성하고, 모공 특징 등급을 예측하는 CNN 모델의 학습을 진행하였다.제안한 CNN 모델에 의한 모공 특징은 전문가의 육안 분류 결과와 유사한 예측 결과를 얻었으며, 비교 모델(Resnet-50)에 의한 결과보다 적은 학습시간과 높은 예측결과를 얻었다. 본 논문의 본론에서는 제안한 영상처리 기법과 CNN 적용의 결과에 대해 서술하며, 결론에서는 제안한 방법에 대한 결과와 향후 연구방안에 대해 서술한다.","In this paper, we propose a prediction system for skin pore labeling based on a CNN(Convolution NeuralNetwork) model, where a data set is constructed by processing skin images taken by users, and a pore featureimage is generated by the proposed image processing algorithm. The skin image data set was labeled for porecharacteristics based on the visual classification criteria of skin beauty experts. The proposed image processingalgorithm was applied to generate pore feature images from skin images and to train a CNN model that predictspore feature ratings. The prediction results with pore features by the proposed CNN model is similar to expertsvisual classification results, where less learning time and higher prediction results were obtained than the resultsby the comparison model (Resnet-50). In this paper, we describe the proposed image processing algorithm andCNN model, the results of the prediction system and future research plans."
합성곱신경망 모델에 따른 침엽수재 수종식별 성능 비교 및 최적 모델 개발,2022,[],국문 초록 정보 없음,"The four convolutional neural network(CNN) architectures such as GoogLeNet, ResNet50, VGG16, and modified CNN were analyzed for investigating the effect of environmental variables on the accuracy of species identification like focused position, epochs, data augmentation and optimizer. Totally 5,535 cross-section images including 1,535 images of low-magnification(40X), 2,000 images of earlywood focused image(200X), and 2,000 images of latewood focused image(200X) were prepared for the dataset establishment. After the preparation, each dataset was randomly separated into 80% of the training group and 20% of the verification group. Data augmentation was applied only in training group for verifying the effectiveness of the dataset amount. As a result of training and verification process, the GoogLeNet architecture increased classification accuracy in proportion to the number of training epochs, and its classification accuracy achieved 99.0% at training process and 98.1% at verification process when applied non-augmented latewood dataset. In augmented latewood dataset, classification accuracy achieved 91.1% and 91.6% at training and verification process, respectively. In contrast, the best classification accuracy of ResNet50 architecture was 87.7% at training process and 71.3% at verification process. VGG16 architecture showed poor performance with around 10% accuracy at both training and verification processes under all conditions. The modified CNN architecture showed excellent classification accuracy with 95.9~99.8% at training process and 95.1~96.9% at verification process when using the earlywood dataset with 100 epochs condition. Moreover, the latewood dataset with 100 epochs condition also makes remarkable results as 96.2~99.2% at training process and 96.5~96.7% at verification process. Based on the results, data augmentation was not significantly affected to classification accuracy of CNN based softwood identification system in this research. In contrast, classification accuracy showed the increased tendency with an increment of training epochs and adoption of the latewood dataset."
합성곱 신경망과 인코더-디코더 모델들을 이용한 익형의 유체력 계수와 유동장 예측,2022,"['합성곱 신경망', '인코더-디코더', '심층학습', '익형', '전산유체역학', 'Convolutional Neural Network', 'Encoder-Decoder', 'Deep Learning', 'Airfoil', 'Computational Fluid Dynamic']",국문 초록 정보 없음,"The evaluation of the drag and lift as the aerodynamic performance of airfoils is essential.In addition, the analysis of the velocity and pressure fields is needed to support the physical mechanism of the force coefficients of the airfoil. Thus, the present study aims at establishing two different deep learning models to predict force coefficients and flow fields of the airfoil. One is the convolutional neural network (CNN) model to predict drag and lift coefficients of airfoil. Another is the Encoder-Decoder (ED) model to predict pressure distribution and velocity vector field. The images of airfoil section are applied as the input data of both models. Thus, the computational fluid dynamics (CFD) is adopted to form the dataset to training and test of both CNN models. The models are established by the convergence performance for the various hyperparameters. The prediction capability of the established CNN model and ED model is evaluated for the various NACA sections by comparing the true results obtained by the CFD, resulting in the high accurate prediction. It is noted that the predicted results near the leading edge, where the velocity has sharp gradient, reveal relatively lower accuracies. Therefore, the more and high resolved dataset are required to improve the highly nonlinear flow fields."
Scalogram과 Switchable 정규화 기반 합성곱 신경망을활용한베이링 결함탐지,2022,"['Bearjng fault detecaon', 'deep learnjng', 'C鬪U dataset', 'swjtchable normaJjzatjon', 'scalogram', 'convoluaonaJ neural network']","베어링은 기계가 작동할때 중요한 역할을 한댜 때문에, 베어링에 결함이 발생하면 기계전체의 치명적인 결함을 발생시킨다. 그러 므로 베어링 결함은 조기에 발견되어야한댜 본 논문에서는 연속 웨이불릿 변환과 Switchable 정규회를 기반으로 한 합성곱 신경망 (SN-CNN)을 이용한 방법을 베어링 결함 감지 모델에 대해 설명한다. 모델의 정확도는 Case Western Reserve University (CWRU) 베어링 데이터 집합을 사용히여 측정되었다. 또한 배치 정규희{BN, Batch Normalization)[l] 방법과 스펙트로그램 이미 지가 모델 성능의 비교를 위해 시용되었댜","Bearing plays an important role in the operation of most machinery, Therefore, when a defect occurs in the bearing, a fatal defect throughout the machine is generated. In this reason, bearing defects should be detected early. In this paper, we describe a method using Convolutional Neural Networks (SN-CNNs) based on continuous wavelet transformations and Switchable normalization for bearing defect detection models. The accuracy of the model was measured using the Case Western Reserve University (CWRU) bearing dataset. In addition, batch normalization methods and spectrogram images are used to compare model performance. The proposed model achieved over 99% testing accuracy in CWRU dataset."
한국지능정보사회진흥원 인공지능 학습용 개방 데이터(NIA AI HUB)를 이용한 합성곱 신경망 기반의 국내 주요 밭작물의 분류 연구,2022,"['작물 분류', '딥러닝', '합성곱신경망', 'CNN', 'NIA AI HUB', '드론']","경작지에서 위치별, 시기별로 작물과 재배환경을 측정하고 필요 자재를 선택적으로 투입하는 정밀농업을 실현하기 위해서는 재배 중인 작물의 종류를 파악하는 것이 중요하다. 전국 각 지역의 작물 재배 종류 현황을 파악하는 것은 각 작물의 재배면적을 산출하여 작물의 수확량을 예측할 수 있게 한다. 하지만 인력으로 조사를 시행하는 것은 비용적, 시간적 측면에서 매우 비효율적이다. 농업 분야에서 드론은 비교적 저고도로 비행하며 촬영의 자유도가 높고 자동 비행 기술과 영상처리 소프트웨어의 발전에 힘입어 넓은 면적을 다양한 센서로 촬영하고 영상 데이터를 누적하는 것이 쉬워졌다. 따라서 드론을 통해 대단위 농경지에 대한 정보를 한 번에 획득하고 재배 현황을 파악할 수 있다. 본 연구에서는 한국지능정보사회진흥원에서 제공하는 인공지능 학습용 개방 데이터(NIA AI HUB)를 사용하여 한국의 주요 밭작물을 분류하고자 하였다. NIA AI HUB는 과 학기술정보통신부와 한국지능정보사회진흥원의 지능정보산업인프라 조성 사업의 일환으로 구축되어 다양한 분야에서 영리적, 비영리적 연구와 개발 목적으로 활용될 수 있으며, AI HUB 데이터를 활용한 AI 모델 등의 결과물에 대한 권리와 저작권은 한국지능정보사회진흥원에 있다. 본 연구에서는 무, 배추, 양파, 마늘 등의 주요 밭작물을 대상으로 구축된 드론 기반 고해상도 RGB 영상을 사용하였다. RGB 영상 원천 데이터를 가공하여 작물의 종류와 위치가 픽셀 단위로 표시된 어노테이션 파일을 제작하여 딥러닝용 학습 데이터를 구축하였다. 구축된 작물 분류용 학습 데이터를 사용하여 합성곱 신경망(Convolutional Neural Network) 기반의 의미론적 분할(Semantic Segmentation) 모델을 개발하였다. 의미론적 분할 모델을 통해 픽셀 단위로 작물을 분류함과 동시에 위치를 표시하고 분류 성능을 평가하였다.",다국어 초록 정보 없음
변전소 불량애자 검출을 위한 드론 EO/IR 영상 기반의 경량화 객체탐지 모델 응용 연구,2022,"['Defect Insulator', 'Light-weight deep learning', 'Real-Time Object Detection', 'Drone Surveillance', 'EO/IR Image', 'Embedded GPU']",국문 초록 정보 없음,"This paper proposes a monitoring system of defected substation insulators based on drone EO/IR images and a light-weight deep learning model. The defected substation insulators generate corona discharge and excessive heating. Thus, this study used RGB-thermal blended images from drone EO/IR cameras to monitor insulator failures, which is not visible to naked eyes. Also, this paper compared several light-weighted object detection models to select the most suitable model to deploy on the embedded processor of drones. The applied compressed CNN model, YOLOv4 backbone with group convolution and channel shuffle operations, is sufficiently fast and light-weighted for an embedded GPU processor. Experiments with mockup insulators with corona discharge showed that the proposed system resulted 99.50% mAP, 5.9fps on embedded GPU(Jetson Nano), and has 3.9MB memory that is 37.99 times lighter than YOLOv4."
시공간 특성을 고려한 딥러닝 기반 교통 속도 예측 모델,2022,"['traffic predidction', 'deep learning', 'CNN', 'RNN', 'Attention', '.']","교통량과 속도는 지능형 교통 시스템을 구축하기 위해 필요한 가장 중요한 교통 정보이다. 최근 사물인터넷, 빅데이터, 인공지능 등의 기술 발전에 따라 다양한 딥러닝 기술들이 교통 정보 예측에 많이 활용되고 있다. 본 논문에서는 도로의 공간적 특징과 시간에 따른 속도 변화 특징을 반영하기 위하여 3개의 모델을 결합한 CNN-RNN-Attention 속도 예측 모델을 제안한다. 컨볼루션 신경망(CNN)과 순환신경망(RNN)을 활용하여 도로의 공간적 특성과 시계열 특성을 각각 학습하고, 학습된 결과에 어텐션(Attention) 기법을 적용하여 가중치를 부여함으로써 성능을 향상시켰다. 제안된 모델은 한국도로공사 링크 통행속도 데이터를 활용하여 실험을 진행하였으며, CNN 단일 모델, GRU 단일 모델 그리고 CNN과 GRU을 결합한 모델 대비 성능이 우수함을 증명하였다.","The volume and the speed of traffic are the key factors for establishing an intelligent traffic system. The latest technical accomplishments such as Internet on Things, big data and artificial intelligence made various deep learning technologies possible to be used for predicting traffic conditions. In this Paper, we propose a CNN-RNN-Attention prediction model combines three models to reflect the spatial-temporal characteristics. Convolutional Neural Network(CNN) and Recurrent Neural Network(RNN) are used to learn spatial and temporal characteristics of roads, respectively. Then we go through the attention model which improves the performance of our model by calculating the weights of CNN-RNN results. The proposed model was tested using the link speed data of Korea Expressway Corporation, and it was proved that the performance result was superior to that of the CNN single model, the RNN single model and the model which are combines CNN with RNN."
송아지 질병 결정 지원 모델,2022,[],"송아지 질병 진단을 위해 사용되는 여러 데이터 중에서 분변은 질병 진단의 중요한 역할을 한다. 송아지 분변 이미지에서 형태, 색상, 질감으로 건강 상태를 알 수 있다. 건강 상태를 파악할 수 있는 분변 이미지는 분변 상태에 따라 정상 송아지 207개와 설사증 송아지 158개의 데이터를 전처리하여 사용하였다. 본 논문에서는 수집된 송아지 데이터 중에서 분변 변수의 이미지를 탐지하고 합성곱 네트워크 기술을 활용하여 질병 증상을 포함하고 있는 데이터 세트에 대해 CNN과 GLCM의 속성을 결합한 GLCM-CNN을 적용하여 이미지를 학습시켰다. CNN의 89.9% 정확도와 GLCM-CNN는 91.7%의 정확도를 보이는 GLCM-CNN는 1.8%의 높은 정확도를 나타내는 유의미한 차이가 있었다.","Among the data used for the diagnosis of calf disease, feces play an important role in disease diagnosis. In the image of calf feces, the health status can be known by the shape, color, and texture. For the fecal image that can identify the health status, data of 207 normal calves and 158 calves with diarrhea were pre-processed according to fecal status and used. In this paper, images of fecal variables are detected among the collected calf data and images are trained by applying GLCM-CNN, which combines the properties of CNN and GLCM, on a dataset containing disease symptoms using convolutional network technology. There was a significant difference between CNN's 89.9% accuracy and GLCM-CNN, which showed 91.7% accuracy, and GLCM-CNN showed a high accuracy of 1.8%."
선박용 밸브의 내부 누설 진단을 위한 음향방출신호의 머신러닝 기법 적용 연구,2022,"['밸브', '분류', '서포트 벡터 머신', '합성곱 신경망', '머신러닝', '딥러닝', 'Valve', 'Classification', 'Support Vector Machine (SVM)', 'Convolutional neural network (CNN)', 'Machine learning', 'Deep learning']","밸브의 내부 누설 현상은 밸브의 내부 부품의 손상에 의해 발생하며 배관 시스템의 사고와 운전정지를 일으키는 주요 요인이다. 본 연구는 버터플라이형 밸브의 내부 누설에 따라 배관계에서 발생하는 음향방출 신호를 이용하여 배관 가동 중 실시간 누설 진단의 가능성을 검토하였다. 이를 위해 밸브의 작동 모드별로 측정한 시간영역의 AE 원시신호를 취득하였으며 이로부터 구축한 데이터셋은 데이터 기반의 인공지능 알고리즘에 적용하여 밸브의 내부 누설 유무를 진단하는 모델을 생성하였다. 누설 유무진단을 분류의 문제로 정의하여 SVM 기반의 머신러닝과 CNN 기반의 딥러닝 분류 알고리즘을 적용하였다. 데이터의 특징 추출에 기반한 SVM 분류 모델의 경우, 이진분류 모델에서 구축된 모델에 따라 83~90%의 정확도를 나타냈으며, 다중 클래스인 경우 분류 정확도가 66%로 감소하였다. 반면, CNN 기반의 다중 클래스 분류 모델의 경우 99.85%의 분류 정확도를 얻을 수 있었다. 결론적으로 밸브 내부 누설 진단을 위한 SVM 분류모델은 다중 클래스의 정확도 향상을 위해 적절한 특징 추출이 필요하며, CNN 기반의 분류모델은 프로세서의 성능 저하만 없다면 누설진단과 밸브 개도 분류에 효율적인 접근방법임을 확인하였다.","Valve internal leakage is caused by damage to the internal parts of the valve, resulting in accidents and shutdowns of the piping system. This study investigated the possibility of a real-time leak detection method using the acoustic emission (AE) signal generated from the piping system during the internal leakage of a butterfly valve. Datasets of raw time-domain AE signals were collected and postprocessed for each operation mode of the valve in a systematic manner to develop a data-driven model for the detection and classification of internal leakage, by applying machine learning algorithms. The aim of this study was to determine whether it is possible to treat leak detection as a classification problem by applying two classification algorithms: support vector machine (SVM) and convolutional neural network (CNN). The results showed different performances for the algorithms and datasets used. The SVM-based binary classification models, based on feature extraction of data, achieved an overall accuracy of 83% to 90%, while in the case of a multiple classification model, the accuracy was reduced to 66%. By contrast, the CNN-based classification model achieved an accuracy of 99.85%, which is superior to those of any other models based on the SVM algorithm. The results revealed that the SVM classification model requires effective feature extraction of the AE signals to improve the accuracy of multi-class classification. Moreover, the CNN-based classification can be a promising approach to detect both leakage and valve opening as long as the performance of the processor does not degrade."
합성곱 신경망을 적용한 볼 베어링의 결함 분류,2022,"['Ball Bearing(볼 베어링)', 'Convolutional Neural Network(합성곱 신경망)', 'Fault Classification(결함 분류)', 'Machine Learning(기계학습)', 'Multi-Layer Perceptron(다층 지각)']","볼 베어링은 회전 기계의 성능을 결정하는 주요 구성 요소 중 하나로 볼과 내·외륜 사이의 구름접촉으로 다양한 결함이 발생하며, 이는 회전 기계에서 발생하는 고장의 주요 원인이다. 이를 사전에 방지하기 위하여 다양한 기계학습 알고리즘을 적용한 볼 베어링의 결함 분류 모델에 대한 연구가 이루어지고 있다. 하지만 정확도가 높은 결함 분류 모델을 구축하기 위하여 충분한 데이터를 수집하는 데에는 어려움이 따른다. 본 연구에서는 데이터가 충분하지 않은 환경에서 결함 분류를 위해 합성곱 신경망(CNN: convolution neural network)이 적용된 결함 분류 모델을 제안하였으며, 정상상태 및 5가지 결함 데이터를 대상으로 분류 모델의 학습을 수행하고 결함 분류의 정확도를 평가하였다. 또한, 다층 지각(multi-layer perceptron)과 장단기 메모리(long short-term memory) 알고리즘이 적용된 기존의 결함 분류 모델과 CNN 모델의 결함 분류 정확도를 비교하였다. 이를 통해 데이터가 충분하지 않은 환경에서 볼 베어링 결함 상태를 분류하는 데 있어 CNN 모델의 적용이 적합함을 확인하였다.","A ball bearing is one of the main components that play an important role in the performance of rotating machinery. Faults occur frequently owing to concentrated loads on the contact areas between balls and race tracks, which directly affect operation of the rotating machinery. To prevent such issues in advance, studies on the fault classification models have been carried out, for which various machine learning algorithms were considered. To attain a high accuracy fault classification model, even though sufficient collected fault data are needed, there are still limit and restriction on this purpose. In the present study, a fault classification model for a ball bearing was proposed, in which CNN (convolution neural network) algorithm was applied to classify faults with a high accuracy even for insufficient collected fault data. The CNN model was constructed after training with the vibration signals acquired from operating ball bearing including normal condition and five fault types. In addition, other fault classification models were prepared using conventional machine learning algorithms, such as MLP (multi-layer perceptron) and LSTM (long short-term memory). The obtained results were compared with those of the CNN algorithm. Subsequently, the availability of the CNN model was verified with insufficient collected fault data."
단백질 기능 예측 모델의 주요 딥러닝 모델 비교 실험,2022,"['CNN', 'LSTM', 'GRU', '결합 모델', '단백질 서열', 'CNN', 'LSTM', 'GRU', 'Combined Model', 'Protein Sequence']",국문 초록 정보 없음,"Proteins are the basic unit of all life activities, and understanding them is essential for studying life phenomena. Since the emergenceof the machine learning methodology using artificial neural networks, many researchers have tried to predict the function of proteinsusing only protein sequences. Many combinations of deep learning models have been reported to academia, but the methods are differentand there is no formal methodology, and they are tailored to different data, so there has never been a direct comparative analysis ofwhich algorithms are more suitable for handling protein data. In this paper, the single model performance of each algorithm was comparedand evaluated based on accuracy and speed by applying the same data to CNN, LSTM, and GRU models, which are the most frequentlyused representative algorithms in the convergence research field of predicting protein functions, and the final evaluation scale is presentedas Micro Precision, Recall, and F1-score. The combined models CNN-LSTM and CNN-GRU models also were evaluated in the same way.Through this study, it was confirmed that the performance of LSTM as a single model is good in simple classification problems, overlappingCNN was suitable as a single model in complex classification problems, and the CNN-LSTM was relatively better as a combination model."
소셜미디어 사진 게시물의 딥러닝을 활용한 도시공원 이용자 활동 이미지 분류모델 개발,2022,"['Convolutional Neural Network (CNN)', 'Computer Vision', 'Urban Park Evaluation', 'Patterns of Urban Park Use', '합성곱신경망(CNN)', '컴퓨터 비전', '도시공원 평가', '도시공원 이용패턴']","본 연구의 목적은 인공지능의 딥러닝을 활용하여 소셜미디어에서 공유되는 도시공원 이용자 활동사진을 분류하는 기초 모델을 만드는 것이다. 소셜미디어 데이터는 네이버 검색을 통해 수집된 도시공원 관련 사진들을 수집하여 분류모델에 활용하였다. 도시공원 특성 평가에 활용할 수 있는 지표인 자연성(naturalness), 잠재적 매력성(potential attraction), 활동(activity)을 기반으로 최종 21개의 분류 항목체계를 만들고, 항목별로 네이버에서 공유되는 실제 도시공원 사진을 수집하여 주석이 달린 데이터 세트를 구축했다. 수집한 사진 데이터 세트에 대해 커스텀(cuntom) CNN 모델과 사전 훈련된 CNN의 전이학습 모델을 설계하고 분석하였다. 연구결과, 가장 우수한 성능을 보였던 Xception 전이학습 모델이 최종적으로 도시공원 이용자 활동 이미지 분류모델로 선정되었으며, 그 외 다양한 평가 지표를 통해 모델을 평가했다. 본 연구는 소셜미디어에 공유되는 이용자 사진을 활용하여 도시공원 특성을 평가할 수 있는 지표로서 AI를 구축한 것에 의의가 있다. 딥러닝을 활용한 분류모델은 수동분류에 대한 한계를 보완하고, 대량의 도시공원 사진을 효율적으로 분류할 수 있어서 향후 도시공원의 모니터링 및 관리에 활용할 수 있는 유용한 방법이라고 할 수 있다.","This study aims to create a basic model for classifying the activity photos that urban park users shared on social media using Deep Learning through Artificial Intelligence. Regarding the social media data, photos related to urban parks were collected through a Naver search, were collected, and used for the classification model. Based on the indicators of Naturalness, Potential Attraction, and Activity, which can be used to evaluate the characteristics of urban parks, 21 classification categories were created.  Urban park photos shared on Naver were collected by category, and annotated datasets were created. A custom CNN model and a transfer learning model utilizing a CNN pre-trained on the collected photo datasets were designed and subsequently analyzed. As a result of the study, the Xception transfer learning model, which demonstrated the best performance, was selected as the urban park user activity image classification model and evaluated through several evaluation indicators. This study is meaningful in that it has built AI as an index that can evaluate the characteristics of urban parks by using user-shared photos on social media. The classification model using Deep Learning mitigates the limitations of manual classification, and it can efficiently classify large amounts of urban park photos. So, it can be said to be a useful method that can be used for the monitoring and management of city parks in the future."
딥러닝을 이용한 병징에 최적화된 딸기 병충해 검출 기법,2022,"['데이터 증강', '빅데이터', '스마트팜', 'CNN', 'YOLO', 'big data', 'CNN', 'data augmentation', 'smart farm', 'YOLO']",본 논문은 딥러닝 알고리즘을 이용하여 딸기 영상 데이터의 병충해 존재 여부를 자동으로 검출할 수 있는 서비스 모델을 제안한다. 또한 병징에 특화된 분할 이미지 데이터 세트를 제안하여 딥러닝 모델의 병충해 검출 성능을 향상한다. 딥러닝모델은 CNN 기반 YOLO를 선정하여 기존의 R-CNN 기반 모델의 느린 학습속도와 추론속도를 개선하였다. 병충해 검출 모델을 학습하기 위해 일반적인 데이터 세트와 제안하는 분할 이미지 데이터 세트를 구축하였다. 딥러닝 모델이 일반적인 학습 데이터 세트를 학습했을 때 병충해 검출률은 81.35%이며 병충해 검출 신뢰도는 73.35%이다. 반면 딥러닝 모델이 분할 이미지 학습 데이터 세트를 학습했을 때 병충해 검출률은 91.93%이며 병충해 검출 신뢰도는 83.41%이다. 따라서 분할 이미지 데이터를 학습한 딥러닝 모델의 성능이 우수하다는 것을 증명할 수 있었다.,"This study aimed to develop a service model that uses a deep learning algorithm for detecting diseases and pests in strawberries through image data. In addition, the pest detection performance of deep learning models was further improved by proposing segmented image data sets specialized in disease and pest symptoms. The CNN-based YOLO deep learning model was selected to enhance the existing R-CNN-based model's slow learning speed and inference speed. A general image data set and a proposed segmented image dataset was prepared to train the pest and disease detection model. When the deep learning model was trained with the general training data set, the pest detection rate was 81.35%, and the pest detection reliability was 73.35%. On the other hand, when the deep learning model was trained with the segmented image dataset, the pest detection rate increased to 91.93%, and detection reliability was increased to 83.41%. This study concludes with the possibility of improving the performance of the deep learning model by using a segmented image dataset instead of a general image dataset."
GIS를 이용한 토양정보 기반의 배추 생산량 예측 수정모델 개발,2022,"['딥러닝', '농산물 생산량 예측', 'CNN', 'RNN', 'LSTM', '하이퍼파라미터 최적화', 'Deep Learning', 'Crop Yield Prediction', 'CNN', 'RNN', 'LSTM', 'Hyperparameter Optimization']","본 연구는 GIS를 통해 토양정보를 수집하고 가공하여 농산물 생산량을 예측하는 모델을 제안한다. 농산물 생산 량 예측 딥러닝 알고리즘은 공개된 CNN-RNN 농산물 생산량 예측 모델 구조를 변경하여 국내 농산물 자료 환경에 적합하도록 새롭게 구축하다. 기존모델은 두 가지 특징을 가지고 있는데 첫 번째는 농산물의 생산량을 해당 필지 값이 아닌 당해 평균값으로 대체한다는 것이고 두 번째는 예측하는 연도의 데이터까지 학습한다는 것이다. 새로운 모델은 해당 필지의 값을 그대로 사용하여 데이터의 정확성을 확보하고 예측하고자 하는 연도 이전의 데이터만 가지 고 학습할 수 있도록 네트워크 구조를 개선하다. 제안한 CNN-RNN 모델은 1980년부터 2020년까지의 기상정보, 토양정보, 토양적성도, 생산량 데이터를 학습하여 김장용 가을배추의 지역별 단위면적당 생산량을 예측한다. 2018 년부터 2021년까지 4개 연도별 자료에 대하여 계산하고 생산량을 예측한 결과, 테스트 데이터셋에 대한 오차백분율 이 약 10% 내외로 실제값과 비교하여 정확도 높은 생산량 예측이 가능했고, 특히 전체 생산량 비중이 큰 지역에서의 생산량은 비교적 근접하게 예측하는 것으로 분석되었다. 또한 제안모델과 기존모델은 모두 학습자료 연도 수가 증가 할수록 점점 오차가 작아지므로 학습데이터가 많아질수록 범용 성능은 향상되는 결과를 나타낸다.","This study proposes a deep learning algorithm to predict crop yield using GIS (Geographic Information System) to extract soil properties from Soilgrids and soil suitability class maps. The proposed model modified the structure of a published CNN-RNN (Convolutional Neural Network-Recurrent Neural Network) based crop yield prediction model suitable for the domestic crop environment. The existing model has two characteristics. The first is that it replaces the original yield with the average yield of the year, and the second is that it trains the data of the predicted year. The new model uses the original field value to ensure accuracy, and the network structure has been improved so that it can train only with data prior to the year to be predicted. The proposed model predicted the yield per unit area of autumn cabbage for kimchi by region based on weather, soil, soil suitability classes, and yield data from 1980 to 2020. As a result of computing and predicting data for each of the four years from 2018 to 2021, the error amount for the test data set was about 10%, enabling accurate yield prediction, especially in regions with a large proportion of total yield. In addition, both the proposed model and the existing model show that the error gradually decreases as the number of years of training data increases, resulting in improved general-purpose performance as the number of training data increases."
인공지능 기반 IBD Scoring System,2022,"['Inflammatory bowel disease', 'ulcerative colitis', 'endoscopic score', 'scoring system', 'R-CNN', '염증성 장질환', '궤양성 대장염', '내시경 점수', '점수 시스템', '영역 기반 합성곱 신경망']","염증성 장질환은 크론병과 궤양성 대장염으로 구성되어 있다. 최근 궤양성 대장염 환자의 내시경 수요가 급격하게 증가하고 있으며, 궤양성 대장염은 일생동안 호전과 악화를 반복하는 염증성 장질환 이기 때문에 꾸준한 관리가 필요하다. 궤양성 대장염의 내시경적 질병 활성도를 평가하는 지표로 MES를 주로 사용한다. 본 논문에서는 정확도가 우수한 MES 평가 지표를 인공지능 기술을 통해 자동 분석하여 스코어링 해 주는 시스템을 제안한다. 스코어링 자동 분석을 위해 Faster R-CNN 알고리즘을 개선하여 적용하였다. 인공지능 알고리즘의 정확도를 평가하기 위해 MLP, SVM, CNN모델과 본 논문에서 제안하는 방법에 대한 정확도를 비교 평가 하였다. 비교 평가 결과 평균 88%의 정확도를 도출하여 성능을 증명하였다. 이러한 시스템은 임상 현장에서 내시경 시술에 보조적인 수단으로 활용될 수 있다. 내시경 영상을 활용한 본 연구의 성과물은 염증성 장질환 중 하나인 궤양성 대장염의 진료에서 인공지능을 활용하여 진료의 질 향상을 높이는 계기가 될 수 있다. 향후 연구로 다기관 데이터 수집을 통한 데이터의 확장을 통해 정확도를 개선하고자 한다.","Inflammatory bowel disease consists of Crohn's disease and ulcerative colitis. Recently, the demand for endoscopy from ulcerative colitis patients is rapidly increasing, and since ulcerative colitis is an inflammatory bowel disease that repeats improvement and worsening throughout life, continuous management is required. MES is mainly used as an index to evaluate the endoscopic disease activity of ulcerative colitis. In this paper, we propose a system that automatically analyzes and scores MES evaluation indicators with excellent accuracy through artificial intelligence technology. Faster R-CNN algorithm was improved and applied for automatic scoring analysis. In order to evaluate the accuracy of the artificial intelligence algorithm, the accuracy of the MLP, SVM, and CNN models and the method proposed in this paper were compared and evaluated. As a result of comparative evaluation, an average accuracy of 88% was derived to prove the performance. Such a system can be used as an auxiliary means for endoscopic procedures in the clinical field. The results of this study using endoscopic imaging can serve as an opportunity to improve the quality of care by using artificial intelligence in the treatment of ulcerative colitis, one of the inflammatory bowel diseases. Future research aims to improve accuracy through data expansion through multi-institutional data collection."
플라스틱 덕트 내부의 공동 조사를 위한 Impact-Echo 실험과 딥러닝 모델 적용 연구,2022,"['충격공진법', '딥러닝', '합성곱 신경망', '장단기 기억 신경망', '플라스틱 덕트', 'Impact-Echo', 'deep learning', 'CNN', 'LSTM', 'plastic duct']","PSC 교량은 미리 콘크리트에 프리스트레스트를 도입시킨 교량구조이다. PSC 교량에서 덕트 내 공극은 강연선 부식을 발생시키기 때문에 PSC 교량 덕트 내 공극을 조사하는 것이 중요하다. 최근 연구들에서는 PSC 교량 덕트 내 공극을 조사하기 위해 비파괴검사 방법인 Impact-Echo(IE)에 딥러닝 모델을 적용하여 평가한 연구가 진행되었다. 하지만 원형 플라스틱 덕트 내부에 위치한 공극을 찾기 위해 LSTM 모델과 일차원 CNN 모델을 적용한 연구는 많이 수행되지 않았다. 따라서 이 연구는 IE 실험을 하여 수집된 데이터를 LSTM 모델과 CNN 모델 그리고 CNN 모델과 LSTM 모델을 조합한 모델에 적용하였고 모델들의 공극 여부의 정확도를 평가하였다. 실험 결과, CNN-LSTM 모델이 3개의 딥러닝 모델 중에서 93 %의 정확도로 가장 정확도가 높은 딥러닝 모델로 평가되었다.",다국어 초록 정보 없음
Wavelet 변환과 결합한 잔차 학습을 이용한 희박뷰 전산화단층영상의 인공물 감소,2022,"['Wavelet transformation', 'Residual learning', 'Sparse-view', 'Artifact reduction', 'Wavelet 변환', '잔차 학습', '희박뷰', '인공물 제거']","희박뷰 전산화단층촬영(computed tomography; CT) 영상화 기술은 피폭 방사선량을 감소시킬 수 있을 뿐만 아니라 획득한 투영상의 균일성을 유지하고 잡음을 감소시킬 수 있는 장점이 있다. 하지만 재구성 영상 내 인공물 발생으로 인하여 화질 및 피사체 구조가 왜곡되는 단점이 있다. 본 연구에서는 희박뷰 CT 영상의 인공물 감소를 위해 wavelet 변환과 잔차 학습(residual learning)을 적용한 콘볼루션 신경망(convolutional neural network; CNN) 기반 영상화 모델을 개발하고, 개발한 모델을 통한 희박뷰 CT 영상의 인공물 감소 정도를 정량적으로 분석하였다. CNN은 wavelet 변환 층, 콘볼루션 층 및 역 wavelet 변환 층으로 구성하였으며, 희박뷰 CT 영상과 잔차 영상을 각각 입출력 영상으로 설정하여 영상화 모델 학습을 진행하였다. 영상화 모델 학습을 위해 평균제곱오차(mean squared error; MSE)를 손실함수로, Adam 함수를 최적화 함수로 사용하였다. 학습된 모델을 통해 입력 희박뷰 CT 영상에 대한 예측 잔차 영상을 획득하고, 두 영상간의 감산을 통해 최종 결과 영상을 획득하였다. 또한 최종 결과 영상에 대한 시각적 특성, 최대신호대잡음비(peak signal-to- noise ratio; PSNR) 및 구조적유사성지수(structural similarity; SSIM)를 측정하였다. 연구결과 본 연구에서 개발한 영상화 모델을 통해 희박뷰 CT 영상의 인공물이 효과적으로 제거되며, 공간분해능이 향상되는 결과를 확인하였다. 또한 wavelet 변환과 잔차 학습을 미적용한 영상화 모델에 비해 본 연구에서 개발한 영상화 모델은 결과 영상의 PSNR 및 SSIM을 각각 8.18% 및 19.71% 향상시킬 수 있음을 확인하였다. 따라서 본 연구에서 개발한 영상화 모델을 이용하여 희박뷰 CT 영상의 인공물 제거는 물론 공간분해능 향상 및 정량적 정확도 향상 효과를 획득할 수 있다.","Sparse-view computed tomography (CT) imaging technique is able to reduce radiation dose, ensure the uniformity of image characteristics among projections and suppress noise. However, the reconstructed images obtained by the sparse-view CT imaging technique suffer from severe artifacts, resulting in the distortion of image quality and internal structures. In this study, we proposed a convolutional neural network (CNN) with wavelet transformation and residual learning for reducing artifacts in sparse-view CT image, and the performance of the trained model was quantitatively analyzed. The CNN consisted of wavelet transformation, convolutional and inverse wavelet transformation layers, and input and output images were configured as sparse-view CT images and residual images, respectively. For training the CNN, the loss function was calculated by using mean squared error (MSE), and the Adam function was used as an optimizer. Result images were obtained by subtracting the residual images, which were predicted by the trained model, from sparse-view CT images. The quantitative accuracy of the result images were measured in terms of peak signal-to-noise ratio (PSNR) and structural similarity (SSIM). The results showed that the trained model is able to improve the spatial resolution of the result images as well as reduce artifacts in sparse-view CT images effectively. Also, the trained model increased the PSNR and SSIM by 8.18% and 19.71% in comparison to the imaging model trained without wavelet transformation and residual learning, respectively. Therefore, the imaging model proposed in this study can restore the image quality of sparse-view CT image by reducing artifacts, improving spatial resolution and quantitative accuracy."
이물질 구별을 통한 음식물쓰레기 배출시스템 개선에 관한 연구,2022,"['AI', 'CNN', 'food waste', 'Machine learning', 'RFID']","산업화의 발전으로 음식물 및 쓰레기 배출량이 급격히 증가하고 있다. 이에 정부도 심각성을 인지하고 이를 줄이고자 다방면으로 노력을 하고 있다. 그 일환으로 음식물 종량제을 도입을 하였고 도입 초기 여러 시행착오가 있었지만20 ~ 30%의 감량 효과를 보여주고 있다. 이러한 실적은 음식물 종량제가 정착이 되고 있음을 암시하고 있다.하지만1차 수거에서 2차 수거과정을 통해 집하장으로 모여서 자원 순환을 과정에서 이물질로 인한 폐해가 발생하고 있다. 이에본 연구에서는 이러한 문제점을 근본적으로 해결하고자 인공지능을 적용하여 개선하고자 한다. 음식물쓰레기 특성상 많은 이미지를 구하는데는 한계가 있어 CNN을 기반으로 한 여러 모델을 비교하여 이를 이상 데이터 분류 즉, CNN 기반모델들에 여러 유형의 이물질에 대한 학습을 시킨 후 그 중 정확도가 놓은 모델을 적용하여 설비 보호와 이물질 구분을위해 투입되는 인력 등 유지보수에 대한 개선책을 마련하고자 한다.","With the development of industrialization, the amount of food and waste is rapidly increasing.Accordingly, the government is aware of the seriousness and is making efforts in various ways to reduce it. As a part of that, the volume-based food system was introduced, and although there were several trials and errors at the beginning of the introduction, it shows a reduction effect of 20 to 30%. These results suggest that the volume-based food system is being established. However, the waste is caused by foreign substances in the process of recycling resources by collecting them from the 1st collection to the 2nd collection process. Therefore, in this study, to solve these problems fundamentally, artificial intelligence is applied to classify foreign substances and improve them. Due to the nature of food waste, there is a limit to obtaining many images, so we compare several models based on CNNs and classify them as abnormal data, that is, CNN-based models are trained on various types of foreign substances, and then models with high accuracy are selected. We intend to prepare improvement measures for maintenance, such as manpower input to protect equipment and classify foreign substances by applying it."
Jetson Nano와 3D프린터를 이용한 인공지능 교육용 키트 제작,2022,"['인공지능', '딥러닝', 'CNN', 'OpenCV', 'IoT', 'AI', 'Deep learning', 'CNN', 'OpenCV', 'IoT']","본 논문에서는 인공지능교육의 어려움을 해결하기 위하여 인공지능 교육에 활용이 가능한 교육용 키트를 개발하였다. 이를 통하여 이론 중심에서 실무 위주의 경험을 학습하기 위한 CNN과 OpenCV를 이용하여 컴퓨터 비전 기술을 이용한 사람 인식(Object Detection and Person Detection in Computer Vision)과 특정 오브젝트를 학습시키고 인식시키는 사용자 이미지인식(Your Own Image Recognition), 사용자 객체 분류(Segmentation) 및 세분화(Classification Datasets), 학습된 타켓을 공격하는 IoT하드웨어 제어와 인공지능 보드인 Jetson Nano GPIO를 제어함으로써 효과적인 인공지능 학습에 도움이 되는 교재를 개발하여 활용할 수 있도록 하였다.","In this paper, an educational kit that can be used in AI education was developed to solve the difficulties of AI education. Through this, object detection and person detection in computer vision using CNN and OpenCV to learn practical-oriented experiences from theory-centered and user image recognition (Your Own) that learns and recognizes specific objects Image Recognition), user object classification (Segmentation) and segmentation (Classification Datasets), IoT hardware control that attacks the learned target, and Jetson Nano GPIO, an AI board, are developed and utilized to develop and utilize textbooks that help effective AI learning made it possible."
부분 지문 이미지를 이용한 개인 식별 방법,2022,"['부분 지문', '딥러닝', '개인 식별', 'CNN', '데이터 증식', 'Partial Fingerprint', 'Deep Learning', 'Identification', 'CNN', 'Data Augmentation']",국문 초록 정보 없음,다국어 초록 정보 없음
지리적 인접성을 이용한 아파트 가격변화율 예측 모델 개발,2022,"['서울시 아파트 가격변화율', '지리적 인접성', '예측 모델', 'CNN', 'rate of change in apartment prices in Seoul', 'geographical adjacency', 'predictive model', 'CNN']","최근 들어 금관구, 노도강, 마용성 등 주택가격이 권역별로 변동하는 탈동조화 현상이 심화하고 있다. 해당 현상의 특징은 각 권역이 지리적으로 가까운 구들로 구성되어 있다는 것이다. 본 논문은 서울시의 인접한 자치구들 사이에는 가격이 상호 동조한다고 보고 가격 변동이 인접 지역에 의한 것임을 확인하고자 한다. 가설 검증에는 아파트 가격변화율, 거시경제지표 및 사교육 지표가 사용되며 이는 3차원(시간, 거리, 속성)의 데이터로 조립되고 CNN으로 학습된다. 조립 방식에 따라 모델은 3가지 하위 모델(타깃 지역만 고려(I), 원거리 지역 고려(II), 이웃 수 변경(III))로 세분되며 성능은 MAE와 MDA로 측정된다. 실험 결과, 이웃을 사용한 모델은 영속성 모델과 XGBoost 보다 좋은 성능을 보였고 하위 모델은 모델 III(이웃 수 3인 경우), II, I 순으로 좋은 성능을 보였다. 이를 통해 ‘이웃’이 타깃 지역의 아파트 가격변화율에 영향을 미친다는 것을 알 수 있었다.","Recently, in the real estate market, decoupling in which housing prices fluctuate by the region has been escalating. This phenomenon implies that each region is composed of districts that are adjacent to one another. This thesis confirms that the prices of a district change in synchronization with that of the adjacent districts and proves that the fluctuations in apartment prices in the districts within Seoul are due to the neighbors. The rate of change in apartment prices, macroeconomic indicators, and private education indicators are used to test the hypothesis with a 3D (time, distance, and attribute) model, which is further deciphered using CNN. The model considers the situation of neighbors and is subdivided into the following three sub-models: consideration only for the target area (I), consideration for long-distance areas (II), and change in the number of neighbors (III). The metrics used are mean absolute error and mean directional accuracy. It was observed that the model with neighbors performed better than the persistence model and XGBoost. Furthermore, its sub-models showed good performance in the order of model III (with 3 neighbors), II, and I. This study clearly exhibits that the factor “neighbor” affects the rate of change in apartment prices."
INTERIOR WIND NOISE PREDICTION AND VISUAL EXPLANATION SYSTEM FOR EXTERIOR VEHICLE DESIGN USING COMBINED CONVOLUTION NEURAL NETWORKS,2022,"['Wind noise prediction', 'Image regression', 'Convolutional neural networks (CNN)', 'Gradient-weighted class activation map (Grad-CAM)']",국문 초록 정보 없음,"An analytical model configuration, in addition to air pressure analysis and post-processing, was conducted to measure the interior wind noise by changing the exterior vehicular design. Although wind noise can be calculated accurately through the current process, it requires three to five days for each design. In this study, a convolutional neural network (CNN), which is a class of deep neural networks designed for processing image data, was applied to predict the wind noise with vehicle design images from four different views. Feature maps were extracted from the CNN models trained with images of each view and concatenated to flow through a sequence of fully connected (FC) layers to predict the wind noise. Moreover, visualization of the significant vehicle parts for wind noise prediction was provided using a gradient-weighted class activation map (Grad- CAM). Finally, we compared the performance of various CNN-based models, such as ResNet, DenseNet, and EfficientNet, in addition to the architecture of the FC layers. The proposed method can predict the wind noise using vehicle images from different views with a root-mean-square error (RMSE) value of 0.206, substantially reducing the time and cost required for interior wind noise estimation."
딥 러닝 기반의 무손실 영상압축 방법,2022,[],"최근 딥러닝 방법의 발전하면서 영상처리 및 컴퓨터 비전의 다양한 분야에서 딥러닝 기반의 알고리즘들이 그 이전의 방법들에 비하여 큰 성능 향상을 보이고 있다. 손실 영상 압축의 경우 최근 encoder-decoder 형태의 네트웍이 영상 압축에서 사용되는 transform을 대체하고 있고, transform 결과들의 엔트로피 코딩을 위한 추가적인 encoder-decoder 네트웍을 사용하여 HEVC 수준에 버금가는 성능을 내고 있다. 무손실 압축의 경우에도 매 픽셀 예측을 CNN으로 수행하는 경우, 기존의 예측방법들에 비하여 예측성능이 크게 향상되어 JPEG-2000 Lossless, FLIF, JEPG-XL 등의 딥러닝을 사용하지 않는 방법들에 비하여 우수한 성능을 내는 것으로 보고되고 있다. 그러나 모든 픽셀에 대하여 예측값을 CNN을 통하여 계산하는 방법은, 영상의 픽셀 수만큼 CNN을 수행해야 하므로 HD 크기 영상에 대하여 지금까지 알려진 가장 빠른 방법이 한 시간 이상 소요되는 등 비현실적인 것으로 알려져 있다. 따라서 최근에는 성능은 이보다 떨어지지만 속도를 현실적으로 줄인 방법들이 제안되고 있다. 이러한 방법들은 초기에는 FLIF나 JPEG-XL에 비하여 성능이 떨어져서, GPU를 사용하면서도 기존의 방법보다 좋지 않은 성능을 보인다는 면에서 여전히 비현실적이었다. 최근에는 신호의 특성을 더 잘 활용하는 방법들이 제안되면서 매 픽셀마다 CNN을 수행하는 방법 보다는 성능이 떨어지지만, 짧은 시간 내에 FLIF나 JPEG-XL보다는 좋은 성능을 내는 현실적인 방법들이 제안되었다. 본 연구에서는 이러한 최근의 몇 가지 방법들을 살펴보고 이들보다 성능을 더 좋게 할 수 있는 보조적인 방법들과 raw image에 대한 성능을 평가한다.",다국어 초록 정보 없음
Prediction of Solar Photovoltaic Power Generation by Weather Using LSTM,2022,"['딥러닝', '예측', '기상', '태양광 발전', 'LSTM', 'deep learning', 'prediction', 'weather', 'solar photovoltaic power generation', 'LSTM']","딥러닝은 주가 및 농산물 가격 예측과 같이 데이터를 분석해 일련의 규칙을 발견하고 미래를예상해 우리의 삶에서 다양한 도움을 주고 있다. 본 연구는 태양광 에너지 사용의 중요성이 늘어나는 상황에서 기상에 따른 태양광 발전 실적을 딥러닝을 통해 분석하고 발전량을 예측한다. 본연구에서는 시계열 데이터 예측에서 두각을 나타내고 있는 LSTM(Long Short Term Memory network)을 사용한 모델을 제안하며 이미지를 비롯한 다양한 차원의 데이터를 분석할 때 사용되는CNN(Convolutional Neural Network)과 두 모델을 결합한 CNN-LSTM과의 성능을 비교한다. 세 가지모델의 성능은 태양광 발전 실적의 실제값과 딥러닝을 통해 예측한 값으로 MSE, RMSE, 결정계수를 계산하여 비교하였고 그 결과 LSTM 모델의 성능이 가장 우수한 것으로 나타났다. 따라서본 연구는 LSTM을 사용한 태양광 발전량 예측을 제안한다.","Deep learning analyzes data to discover a series of rules and anticipates the future, helping us in various ways in our lives. For example, prediction of stock prices and agricultural prices. In this research, the results of solar photovoltaic power generation accompanied by weather are analyzed through deep learning in situations where the importance of solar energy use increases, and the amount of power generation is predicted. In this research, we propose a model using LSTM(Long Short Term Memory network) that stand out in time series data prediction. And we compare LSTM’s performance with CNN(Convolutional Neural Network), which is used to analyze various dimensions of data, including images, and CNN-LSTM, which combines the two models. The performance of the three models was compared by calculating the MSE, RMSE, R-Squared with the actual value of the solar photovoltaic power generation performance and the predicted value. As a result, it was found that the performance of the LSTM model was the best. Therefor, this research proposes predicting solar photovoltaic power generation using LSTM."
딥러닝 유사도 기반 현품 영상과 도면 영상의 1:1 매칭 방법,2022,"['Deep Learning', 'CNN(Convolutional Neural Network)', 'Drawing Image', 'Real Product Image', 'Siamese Network', '1:1 Verification', '심층학습', '합성인공신경망', '도면 영상', '현품 영상', '샴신경망', '1:1 검증']","본 논문은 주어진 현품 영상과 도면 영상의 유사도를 비교하여 1:1 검증을 위한 방법을 제시한 것으로, CNN(Convolutional Neural Network) 기반의 딥러닝 모델을 두 개로 결합하여 Siamese Net을 구성하고현품 영상과 도면 영상(정면도, 좌우 측면도, 평면도 등)을 같은 제품이면 1로 다른 제품이면 0으로학습하며, 추론은 현품 영상과 도면 영상을 쌍으로 질의하여 해당 쌍이 같은 제품인지 아닌지를 판별하는 딥러닝 모델을 제안한다. 현품 영상과 도면 영상과의 유사도가 문턱 값(Threshold: 0.5) 이상이면동일한 제품이고, 문턱 값 미만이면 다른 제품이라고 판별한다. 본 연구에서는 질의 쌍으로 동일제품의현품 영상과 도면 영상이 주어졌을 때(긍정 : 긍정) “동일제품”으로 판별할 정확도는 약 71.8%로 나타났고, 질의 쌍으로 다른 현품 영상과 도면 영상이 주어졌을 때(긍정: 부정) “다른제품”으로 판별할 정확도는 약 83..1%를 나타내었다. 향후 제안한 모델에 파라미터 최적화 연구를 접목하고 데이터 정제 등의과정을 추가하여 현품 영상과 도면 영상의 매칭 정확도를 높이는 연구를 진행할 예정이다.","This paper presents a method for 1:1 verification by comparing the similarity between the given real product image and the drawing image. The proposed method combines two existing CNN-based deep learning models to construct a Siamese Network. After extracting the feature vector of the image through the FC (Fully Connected) Layer of each network and comparing the similarity, if the real product image and the drawing image (front view, left and right side view, top view, etc) are the same product, the similarity is set to 1 for learning and, if it is a different product, the similarity is set to 0. The test (inference) model is a deep learning model that queries the real product image and the drawing image in pairs to determine whether the pair is the same product or not. In the proposed model, through a comparison of the similarity between the real product image and the drawing image, if the similarity is greater than or equal to a threshold value (Threshold: 0.5), it is determined that the product is the same, and if it is less than or equal to, it is determined that the product is a different product. The proposed model showed an accuracy of about 71.8% for a query to a product (positive: positive) with the same drawing as the real product, and an accuracy of about 83.1% for a query to a different product (positive: negative). In the future, we plan to conduct a study to improve the matching accuracy between the real product image and the drawing image by combining the parameter optimization study with the proposed model and adding processes such as data purification."
ViT 기반 모델의 강건성 연구동향,2022,[],컴퓨터 비전 분야에서 오랫동안 사용되었던 CNN(Convolution Neural Network)은 오분류를 일으키기 위해 악의적으로 추가된 섭동에 매우 취약하다. ViT(Vision Transformer)는 입력 이미지의 전체적인 특징을 탐색하는 어텐션 구조를 적용함으로 CNN의 국소적 특징 탐색보다 특성 픽셀에 섭동을 추가하는 적대적 공격에 강건한 특성을 보이지만 최근 어텐션 구조에 대한 강건성 분석과 다양한 공격 기법의 발달로 보안 취약성 문제가 제기되고 있다. 본 논문은 ViT가 CNN 대비 강건성을 가지는 구조적인 특징을 분석하는 연구와 어텐션 구조에 대한 최신 공격기법을 소개함으로 향후 등장할 ViT 파생 모델의 강건성을 유지하기 위해 중점적으로 다루어야 할 부분이 무엇인지 소개한다.,다국어 초록 정보 없음
이동통신 가입해지 고객 예측모델 비교연구,2022,"['이동통신 서비스', '가입해지 예측모델', '1D CNN', 'AdaBoost', 'MLP']","한국은 2019년 4월 5G 기반의 초고속, 초저지연, 초연결 서비스를 시작하였다. 세계 최초 5G 상용화라는 타이틀과 함께 상용화 10개월 만에 이동통신 가입자 500만 명을 넘어섰으며 대중화 시대를 위해 나아가고 있었다. 그러나 빠른 가입자 증가에도 불구하고 서비스에 대한 사용자 불만족은 끊임없이 제기되었다. 이에 본 연구를 통해 정확한 이탈 요인을 파악하고 이를 통해 사용자의 이탈을 예측을 5G, LTE, 3G 가입자별 모델의 성능 비교를 통해 높은 우수성을 나타내는 모델을 제안하고자 한다. 본 연구는 이동통신 가입자 가입, 해지에 대한 고객 이탈 예측을 6개 모델 Decision Tree, K-Nearest Neighbor, AdaBoost, Gaussian Naive Bayes, MLP, 1D-CNN 모델을 이용하여 성능을 비교하여 어느 모델에서 높은 성능이 도출되는지 연구하였다. 이동통신 가입자에 고객 730,522건의 5G, LTE, 3G 이동통신 가입자의 가입과 해지 데이터를 수집하였고, 이탈 예측 실험은 이동통신 세대, 성별, MNO, MVNO, 선불고객, 후불 고객, 나이대별로 구분하였다. 이동통신 이탈 예측 실험 결과는 총 99개의 실험 요소 중 1D CNN에서 31개, AdaBoost 모델에서 26개, MLP 모델에서 17개 우수성을 나타냈다.",다국어 초록 정보 없음
음각 정보를 이용한 딥러닝 기반의 알약 식별 알고리즘 연구,2022,"['Pill identification', 'Deep learning', 'Imprinted text', 'Keras OCR', 'CNN']",국문 초록 정보 없음,"In this paper, we propose a pill identification model using engraved text feature and image feature such as shape and color, and compare it with an identification model that does not use engraved text feature to verify the possibility of improving identification performance by improving recognition rate of the engraved text. The data con- sisted of 100 classes and used 10 images per class. The engraved text feature was acquired through Keras OCR based on deep learning and 1D CNN, and the image feature was acquired through 2D CNN. According to the identification results, the accuracy of the text recognition model was 90%. The accuracy of the comparative model and the proposed model was 91.9% and 97.6%. The accuracy, precision, recall, and F1-score of the proposed model were better than those of the comparative model in terms of statistical significance. As a result, we confirmed that the expansion of the range of feature improved the performance of the identification model."
Detection and Weak Segmentation of Masses in Gray-Scale Breast Mammogram Images Using Deep Learning,2022,"['Breast mammogram', 'detection lesion of mass', 'deep learning', 'convolutional neural network', 'data normalization']",국문 초록 정보 없음,"Purpose: In this paper, we propose deep-learning methodology with which to enhance the mass differentiation performance of convolutional neural network (CNN)-based architecture.Materials and Methods: We differentiated breast mass lesions from gray-scale X-ray mammography images based on regions of interest (ROIs). Our dataset comprised breast mammogram images for 150 cases of malignant masses from which we extracted the mass ROI, and we composed a CNN-based deep learning model trained on this dataset to identify ROI mass lesions. The test dataset was created by shifting some of the training data images. Thus, although both datasets were different, they retained a deep structural similarity. We then applied our trained deep-learning model to detect masses on 8-bit mammogram images containing malignant masses. The input images were preprocessed by applying a scaling parameter of intensity before being used to train the CNN model for mass differentiation.Results: The highest area under the receiver operating characteristic curve was 0.897 (Î 20).Conclusion: Our results indicated that the proposed patch-wise detection method can be utilized as a mass detection and segmentation tool."
Analysis of JPEG Image Compression Effect on Convolutional Neural Network-Based Cat and Dog Classification,2022,[],국문 초록 정보 없음,"The process of deep learning usually needs to deal with massive data which has greatly limited the development of deep learning technologies today. Convolutional Neural Network (CNN) structure is often used to solve image classification problems. However, a large number of images may be required in order to train an image in CNN, which is a heavy burden for existing computer systems to handle. If the image data can be compressed under the premise that the computer hardware system remains unchanged, it is possible to train more datasets in deep learning. However, image compression usually adopts the form of lossy compression, which will lose part of the image information. If the lost information is key information, it may affect learning performance. In this paper, we will analyze the effect of image compression on deep learning performance on CNN-based cat and dog classification. Through the experiment results, we conclude that the compression of images does not have a significant impact on the accuracy of deep learning."
실도로 주행 데이터를 이용한 도로 인프라 센서 기반 차선 변경 거동 검출 네트워크 연구,2022,"['차선 변경', '거동 검출', '인프라 센서', '데이터 증강', '확장성', 'Lane change', 'Maneuver classification', 'Roadside sensor', 'Data augmentation', 'Scalability']",국문 초록 정보 없음,"In this paper, a classification algorithm of lane change maneuver based on roadside sensors on highway is proposed. Data augmentation using field operational test data is also considered for scalability. The maneuver classification is composed of semantic maps and convolution neural network(CNN). The semantic map aims to represent a bird’s eye view of both vehicle and road geometry, and the corresponding trajectory of the vehicle. The CNN is used to classify a lane change maneuver of multiple vehicles. While good performance of maneuver classification is shown with respect to a well-known dataset called highD, it is still necessary to consider scalability. Thus, the data augmentation is suggested to build a semantic map based on field operational test data. Despite different sensor characteristics of two datasets, it is demonstrated how the performance of CNN-based maneuver classification is improved in terms of scalability is demonstrated."
산림복원 대상 후보지 추출을 위한 딥러닝 접근법,2022,"['딥러닝', '분할', '산림복원', '항공사진', 'Aerial photo', 'Deep learning', 'Forest restoration', 'Segmentation']","이미지 인식에 특화된 CNN (Convolutional Neural Network) 기반의 딥러닝 기법은 영상의 항목별 분류가 필요한 다양한 연구에 적용되고있다. 본 연구는 건물, 도로, 논, 밭, 산림, 나지의 6가지 항목을 산림복원 대상 후보지로 정의하고 CNN 기반의 산림복원 대상 후보지 추출 및분류의 최적 방법론을 탐색하였다. 6,640개의 데이터셋을 75:25의 비율로 훈련(4,980개) 및 검증(1,660개)로 구분하여 구축하고 학습에 활용하였다.모델별 정확도는 픽셀정확도(PA), 평균 교차 겹침 결합(Mean IoU)을 이용하여 평가하였다. 픽셀정확도는 90.6%, 평균 교차 겹침 결합은 80.8%로산정되어 Inception-Resnet-v2 모델이 세 모델 중 가장 산림복원 대상 후보지 추출에 뛰어난 정확도를 보였다. 이 결과는 기존의 산림복원 대상후보지 현장조사 혹은 항공사진을 활용한 조사에 비해 시공간적 이점을 가지며, 향후 산림복원 대상지 선정 자료로 적용 가능성이 있다고 판단된다.","Many studies using aerial photography and deep learning are increasing for efficient monitoring of the forest resources. We defined six semantic classes of buildings, roads, paddy fields, fields, forests, and barren as forest restoration target sites and explored the optimal methodology for extracting and classifying target sites for forest restoration based on CNN. The datasets (6,640) were divided at a ratio of 75:25 into training (4,980) and validation datasets (1,660). The accuracy of each model was evaluated using pixel accuracy (PA) and Mean Intersection over union (Mean IoU). PA was calculated as 90.6% and Mean IoU was 80.8%, and the Inception-Resnet-v2 model showed excellent accuracy in extracting target sites for forest restoration among the three models. This result has a Spatio-temporal advantage over the existing field survey for forest restoration sites or surveys using aerial photographs by manually. This study will be able to contribute to the classification of forest restoration sites efficiently and support forest restoration."
온라인 키워드 검색량과 합성곱 신경망을 이용한 암호화폐 가격 등락 예측,2022,[],"블록체인 기술이 적용되어 있는 암호화폐인 비트코인은 높은 가격 변동성을 가지며 투자자 및 일반 대중으로부터 큰 관심을 받아왔다. 본 연구에서는 암호화폐 가격 예측모형의 성과를 향상시키기 위해 금융투자상품의 가치평가에 활용되는 기술적 지표들과 함께 투자자의 사회적 관심도를 반영할 수 있는 구글 키워드 검색량 데이터를 사용했으며, 최근 금융시계열 분야에서 예측성과의 우수성을 인정받고 있는 LSTM(Long Short Term Memory)과 CNN(Convolutional Neural Networks)을 활용해 예측 모형을 구축했다. 실증 연구에서 기술적 지표(technical indicators)와 bitcoin을 검색어로 하는 구글 검색량 데이터에 딥러닝을 적용해 일주일 후 가격 등락 예측모형을 구축하였고, 그 예측성과를 ANN(Artificial Neural Networks), SVM(Support Vector Machines)을 적용한 모형들과 비교하였다. 분석 결과 LSTM과 CNN을 활용해 구축한 모형들이 높은 예측성능을 보였고, 같은 예측 기법을 활용했을 때 구글 검색량 변수를 함께 활용한 경우 더 높은 예측성과를 보일 수 있음을 확인했다. 본 연구는 암호화폐 가격 등락예측에 있어 전통적으로 시계열 예측에 우수한 성과를 인정받고 있던 LSTM뿐만 아니라 이미지 분류에 높은 예측성과를 인정받고 있는 딥러닝 기법인 CNN 또한 우수한 예측성능을 보일 수 있으며, 대중의 심리를 반영하는 정보 중 하나인 구글 검색량을 활용해 예측 성과를 향상시킬 수 있다는 것을 확인했다는 점에서 의의가 있다.",다국어 초록 정보 없음
Comparison and optimization of deep learning-based radiosensitivity prediction models using gene expression profiling in National Cancer Institute-60 cancer cell line,2022,"['Radiosensitivity', 'Prediction', 'Deep learning', 'Model comparison', 'Gene expression', 'Survival fraction at 2Gy']",국문 초록 정보 없음,"Background: In this study, various types of deep-learning models for predicting in vitro radiosensitivity from gene-expression profiling were compared.Methods: The clonogenic surviving fractions at 2 Gy from previous publications and microarray geneexpression data from the National Cancer Institute-60 cell lines were used to measure the radiosensitivity. Seven different prediction models including three distinct multi-layered perceptrons (MLP), four different convolutional neural networks (CNN) were compared. Folded cross-validation was applied to train and evaluate model performance. The criteria for correct prediction were absolute error < 0.02 or relative error < 10%. The models were compared in terms of prediction accuracy, training time per epoch, training fluctuations, and required calculation resources.Results: The strength of MLP-based models was their fast initial convergence and short training time per epoch. They represented significantly different prediction accuracy depending on the model configuration. The CNN-based models showed relatively high prediction accuracy, low training fluctuations, and a relatively small increase in the memory requirement as the model deepens.Conclusion: Our findings suggest that a CNN-based model with moderate depth would be appropriate when the prediction accuracy is important, and a shallow MLP-based model can be recommended when either the training resources or time are limited"
고속 푸리에 합성곱을 이용한 파지 조건에 강인한 촉각센서 기반 물체 인식 방법,2022,"['Tactile Sensor', 'Gripper', 'Object Recognition', 'Fast Fourier Convolution (FFC)']",국문 초록 정보 없음,"The accurate object recognition is important for the precise and accurate manipulation. To enhance the recognition performance, we can use various types of sensors. In general, acquired data from sensors have a high sampling rate. So, in the past, the RNN-based model is commonly used to handle and analyze the time-series sensor data. However, the RNN-based model has limitations of excessive parameters. CNN-based model also can be used to analyze time-series input data. However, CNN-based model also has limitations of the small receptive field in early layers. For this reason, when we use a CNN-based model, model architecture should be deeper and heavier to extract useful global features.Thus, traditional methods like RN N -based and CN N -based model needs huge amount of learning parameters. Recently studied result shows that Fast Fourier Convolution (FFC) can overcome the limitations of traditional methods. This operator can extract global features from the first hidden layer, so it can be effectively used for feature extracting of sensor data that have a high sampling rate. In this paper, we propose the algorithm to recognize objects using tactile sensor data and the FFC model. The data was acquired from 11 types of objects to verify our posed model. We collected pressure, current, position data when the gripper grasps the objects by random force. As a result, the accuracy is enhanced from 84.66% to 91.43% when we use the proposed FFC-based model instead of the traditional model."
Convolutional Neural Network-Based Target Detector Using Maxpooling and Hadamard Division Layers in FM-Band Passive Coherent Location,2022,"['Constant False Alarm Rate', 'Convolutional Neural Network', 'Passive Coherent Location', 'Target Detection']",국문 초록 정보 없음,"The constant false alarm rate (CFAR) has been widely used in radar systems to detect target echo signals because of its simplicity. With the recent development of different types of neural networks (NNs), NN architecture-based target detection methods are also being considered. Several studies related to NN-based target detectors have introduced multi-layer perceptron-based and convolutional neural network (CNN)-based structures. In this paper, we propose a CNN-based target detection method in frequency modulation (FM)-band passive coherent location (PCL). We improved the detection performance using a maxpooling layer and a Hadamard division layer, which are parallelly placed with a CNN layer. Moreover, in our method there is no need to determine the specific cell configuration (e.g., cell under test, reference cells, and guard cells) because the proposed method obtains the trained kernels by end-to-end learning. We show that the trained kernels help in the extraction of either signal or noise components. Through the simulations, we also prove that the proposed method can yield an improved receiver operating characteristic compared to that of a cell-averaging CFAR detector for FM-band PCL in a homogeneous environment."
Methodology to classify hazardous compounds via deep learning based on convolutional neural networks,2022,"['Hazardous compounds', 'Classification', 'Deep learning', 'Artificial intelligence', 'MSDS', 'GHS']",국문 초록 정보 없음,"Compounds information such as Chemical Abstracts Service (CAS) registry number, hazards, and properties have been provided through Globally Harmonized System (GHS) based Material Safety Data Sheet (MSDS). This information can help users avoid hazardous compounds and handle chemicals in proper way. GHS specifies that hazards of compounds are categorized through animal testing (or in vivo testing) , in vitro testing, epidemiological surveillance, and clinical trials. In this study, artificial intelligence (AI) is used to replace traditional approaches in predicting the toxicity of chemicals. A database of hazardous compounds is generated by data provided by the Ministry of Environment (ME), training and learning based on convolutional neural network (CNN) are carried out following data featurization. As a result, 90% of accuracy for CNN-based model is obtained using the image dataset. In contrast to the previous methods, the classification method based on CNN-based model in this study allows for the efficient discrimination of hazard chemicals without any additional tests."
Graph neural network based multiple accident diagnosis in nuclear power plants: Data optimization to represent the system configuration,2022,"['Multiple accident', 'Nuclear power plant', 'Graph', 'Graph neural network']",국문 초록 정보 없음,"Because nuclear power plants (NPPs) are safety-critical infrastructure, it is essential to increase their safety and minimize risk. To reduce human error and support decision-making by operators, several artificial-intelligence-based diagnosis methods have been proposed. However, because of the nature of data-driven methods, conventional artificial intelligence requires large amount of measurement values to train and achieve enough diagnosis resolution.We propose a graph neural network (GNN) based accident diagnosis algorithm to achieve high diagnosis resolution with limited measurements. The proposed algorithm is trained with both the knowledge about physical correlation between components and measurement values. To validate the proposed methodology has a sufficiently high diagnostic resolution with limited measurement values, the diagnosis of multiple accidents was performed with limited measurement values and also, the performance was compared with convolution neural network (CNN). In case of the experiment that requires low diagnostic resolution, both CNN and GNN showed good results. However, for the tests that requires high diagnostic resolution, GNN greatly outperformed the CNN."
이미지를 소리로 들려주는 인공지능 프로그램의 구현,2022,"['이미지 캡셔닝', 'CNN', 'RNN', '기계번역']","이 연구는 이미지 캡셔닝을 통해 그림 속 내용을 인식하고, 이를 한국어로 번역하여 음성으로 들려주는 인공지능 프로그램을 구현하는 것을 목표로 한다. 이를 위해 COCO 데이터셋에서 무작위 2000개를 추출하여 문장 속 단어를 토큰화하여 전처리하고 CNN과 RNN을 연결하여 이미지 캡셔닝을 위한 모델을 구현하였다. 만들어진 모델을 한국어로 번역하고 소리로 출력하는 프로그램을 완성하였다. 테스트 이미지를 입력하여 구현한 프로그램의 성능을 평가한 결과 이미지의 주요 객체를 추출하여 문장을 생성하였으나 배경은 인식율이 떨어졌다. 본 연구는 기계가 그림을 보고 내용을 인식하여 소리로 전해줄 수 있다는데 의의가 있다.",다국어 초록 정보 없음
Real-time work intensity estimation algorithm based on deep learning using heart rate and skin temperature,2022,"['Work intensity estimation', '1D CNN', 'LSTM', 'Deep learning']",국문 초록 정보 없음,"In harsh environments where high-intensity work is performed, predicting the work intensity based on the vital signs of a worker can be useful in preventing accidents. Considering existing worker management systems are analyzed using set thresholds, they cannot resolve variables caused by individual differences. Therefore, we propose an algorithm to estimate the work intensity of workers based on their heart rate and body temperature using a deep learning-based 1D CNN-LSTM model. The proposed algorithm uses time-series signals of 60 s to accurately estimate the work intensity by considering the time-series characteristics. In addition, the proposed algorithm considers the individual differences in bio-signals by extracting and using data from the exercise and rest states of workers. To verify the performance of the proposed algorithm, we compared estimation performance factors such as model accuracy, precision, recall, and F1 score with those of various models; the results showed a high estimation accuracy of 99.96%. We believe the proposed algorithm can help minimize damage by preemptively responding to unexpected accidents that may occur at work sites by accurately estimating the work intensity based on the individual differences among workers."
A Study on Image Labeling Technique for Deep-Learning-Based Multinational Tanks Detection Model,2022,"['Convolutional Neural Network (CNN)', 'Computer Vision', 'Deep Learning', 'YOLO Network']",국문 초록 정보 없음,"Recently, the improvement of computational processing ability due to the rapid development of computing technology has greatly advanced the field of artificial intelligence, and research to apply it in various domains is active. In particular, in the national defense field, attention is paid to intelligent recognition among machine learning techniques, and efforts are being made to develop object identification and monitoring systems using artificial intelligence. To this end, various image processing technologies and object identification algorithms are applied to create a model that can identify friendly and enemy weapon systems and personnel in real-time. In this paper, we conducted image processing and object identification focused on tanks among various weapon systems. We initially conducted processing the tanks' image using a convolutional neural network, a deep learning technique. The feature map was examined and the important characteristics of the tanks crucial for learning were derived. Then, using YOLOv5 Network, a CNN-based object detection network, a model trained by labeling the entire tank and a model trained by labeling only the turret of the tank were created and the results were compared. The model and labeling technique we proposed in this paper can more accurately identify the type of tank and contribute to the intelligent recognition system to be developed in the future."
Random Swin Transformer,2022,"['Transformer', 'Swin transformer', 'Deep learning', 'Classification']",국문 초록 정보 없음,"After deep learning appeared, the convolutional neural network (CNN) dominated various applications of image classification, object detection, and semantic segmentation. Recently, a transformer based on various attention mechanisms performed better than the CNN. But, the transformer requires a large amount of memory for full attention among tokens. Recently, a Swin transformer has been proposed to solve that memory issue. It applies the attention per sub-regions on an image. Also, it solves a problem caused by not using full attention on an image by shifting window that guarantees more tokens are involved in attention. In this paper, we investigate a method of randomly selecting tokens in Swin transformer. We randomly choose tokens within a certain range rather than using a fixed shift value in the Swin transformer. Experimental results show the feasibility of the proposed method."
컨벌루션 신경망을 사용한 다중 차선 인식,2022,"['Multi-lanes detection(다중 차선 인식)', 'Convolutional neural network(컨벌루션 신경망)', 'fifth-order polynomial(5차 다항식)']",국문 초록 정보 없음,"In this study, the multi-lane detection problem is expressed as a CNN-based regression problem, and the lane boundary coordinates are selected as outputs. In addition, we described lanes as fifth-order polynomials and distinguished the ego lane and the side lanes so that we could make the prediction lanes accurately.By eliminating the network branch arrangement and the lane boundary coordinate vector outside the image proposed by Chougule’s method, it was possible to eradicate meaningless data learning in CNN and increase the fast training and performance speed. And we confirmed that the average prediction error was small in the performance evaluation even though the proposed method compared with Chougule’s method under harsher conditions. In addition, even in a specific image with many errors, the predicted lanes did not deviate significantly, meaningful results were derived, and we confirmed robust performance."
A Systems Engineering Approach for Predicting NPP Response under Steam Generator Tube Rupture Conditions using Machine Learning,2022,"['Recurrent Neural Network (RNN)', 'Long Short Term Memory (LSTM)', 'Gated Recurrent Unit (GRU)', 'Convolutional Neural Network (CNN)', 'Machine Learning (ML)', 'Best Estimate Plus Uncertainty (BEPU)']",국문 초록 정보 없음,"Accidents prevention and mitigation is the highest priority of nuclear power plant (NPP) operation, particularly in the aftermath of the Fukushima Daiichi accident, which has reignited public anxieties and skepticism regarding nuclear energy usage. To deal with accident scenarios more effectively, operators must have ample and precise information about key safety parameters as well as their future trajectories. This work investigates the potential of machine learning in forecasting NPP response in real-time to provide an additional validation method and help reduce human error, especially in accident situations where operators are under a lot of stress. First, a base-case SGTR simulation is carried out by the best-estimate code RELAP5/MOD3.4 to confirm the validity of the model against results reported in the APR1400 Design Control Document (DCD). Then, uncertainty quantification is performed by coupling RELAP5/MOD3.4 and the statistical tool DAKOTA to generate a large enough dataset for the construction and training of neural-based machine learning (ML) models, namely LSTM, GRU, and hybrid CNN-LSTM. Finally, the accuracy and reliability of these models in forecasting system response are tested by their performance on fresh data. To facilitate and oversee the process of developing the ML models, a Systems Engineering (SE) methodology is used to ensure that the work is consistently in line with the originating mission statement and that the findings obtained at each subsequent phase are valid."
Scene Text Recognition with Multi-Encoders,2022,"['Scene text recognition', 'Transformer', 'Deep learning', 'Convolutional neural network']",국문 초록 정보 없음,"Although text recognition has significantly evolved over the years, the current models still have huge challenges, especially for irregular text images, such as complex backgrounds, curved text, diverse fonts, distortions, etc. Currently, CNN-based text recognition networks have shown good performance but still face the above challenges. Recently, feature extractor based on transformer has shown excellent advantages for global feature extraction on images. Especially in irregular text images, which can use self-attention to establish the information connection of each part of the image, which can also reduce the influence of the irregular distribution of characters. Therefore, this paper proposes MESTR(Multi-Encoders Scene Text Recognition) that combines a CNN-based[1][2][6] feature extractor and a transformer-based feature extractor. MESTR can extract local and global features of text images at the same time and then integrate global features into local features. During training, we used CTC[6] as guide training in the decoder part, as the compensation training strategy for attentional decoder. Experimental results demonstrate that the proposed MESTR shows competitive results on all seven benchmarks. At the same time, we provide ablation experiments to show the effectiveness of the improved part on the text recognition model."
스마트 디바이스를 활용한 노약자 근감소증 진단과 딥러닝 알고리즘,2022,"['근감소증', '딥러닝', '스마트디바이스', 'IoT', '예측', '보행패턴', 'IMU', '데이터 분석', 'sarcopenia', 'deep-learning', 'smart-device', 'IoT', 'walking-pattern', 'IMU', 'Data-analysis']","연구목적: 본 논문에서는 스마트 디바이스의 높은 보급률을 활용하여 근감소증을 추정 및 예측하는 딥러닝 알고리즘을 제안과 연구를 수행한다. 연구방법: 딥러닝 학습을 위해 스마트 디바이스에 내장된 관성센서를 활용하여 실험을 데이터를 수집하였다. 데이터를 수집하는 테스트용 어플리케이션 구현하여 ‘정상’과 ‘비정상’걸음과 ‘달리기’, ‘낙상’, ‘스쿼트’ 자세의 5 가지 상태를 구분하여 데이터를 수집하였다.  연구결과: LSTM, CNN, RNN model 사용 시 예측 정확도를 분석했고 CNN-LSTM 융합형 모델을 활용하여 이진분류 정확도 99.87%, 다중 분류 92.30%의 정확도를 보였다.  결론: 근감소증이 있는 사람의 경우 걸음걸이의 이상이 생긴다는 점에 착안하여 스마트 디바이스를 활용한 연구를 진행하였다. 본 연구를 활용하여 근감소증으로 인해 생기는 재난안전을 강화 할 수 있을 것이다.",다국어 초록 정보 없음
SLAM을 이용한 카메라 기반의 실내 배송용 자율주행 차량 구현,2022,"['자율주행', '합성곱 신경망', '딥러닝', '실내 위치 측위', '동시적 위치추정 및 지도작성', 'Autonomous Driving', 'Convolutional Neural Network', 'Deep Learning', 'Indoor Localization', 'SLAM']","본 논문에서는 Visual 동시적 위치추정 및 지도작성(SLAM : Simultaneous Localization and Mapping)기술을 응용하여 실내에서 생성된 SLAM 맵을 기반으로 지정된 목적지에 물건을 배달하는 자율주행 차량 플랫폼을 제안하였다. 실내에서 SLAM 맵을 생성하기 위해 소형 자율주행 차량 플랫폼의 상단에 SLAM 맵 생성을 위한 심도 카메라를 설치하고 SLAM 맵 속에서의 정확한 위치 추정을 하기 위해 추적 카메라를 장착하여 구현하였다. 또한, 목적지의 표찰을 인식하기 위해 합성곱 신경망(CNN : Convolutional neural network)을 사용하여 목적지에 정확하게 도착할 수 있도록 주행 알고리즘을 적용하여 설계하였다. 실내 배송 자율주행 차량을 실제로 제작하였고 SLAM 맵의 정확도 확인과 CNN을 통한 목적지 표찰 인식 실험을 수행하였다. 결과적으로 표찰 인식의 성공률을 향상시켜 구현한 실내 배송용 자율주행 차량의 활용 적합성 여부를 확인하였다.",다국어 초록 정보 없음
Study on Microscopic Fracture Surface Analysis based on Deep Learning (1) : Fracture Surface Classification by Convolutional Neural Network,2022,"['Deep Learning(딥러닝)', 'Convolutional Neural Network(합성곱 신경망)', 'Fractography(파면분석학)', 'Microscopic Fracture Surface(미소 파면)', 'Fracture Surface Classification(파면 분류)']",국문 초록 정보 없음,"Fracture surface contains many important information of machine fracture such as crack origin, direction, number of cycle, types and defects. By observing microscopic fracture surface, cause of fracture can be figured out. However it is difficult to pass on expertise and the number of those engineers is lately dicreased.  Recently, deep learning is popular because of 4th industrial revolution. Deep learning is widely used in the vision recognition. Moreover, Convolutional Neural Network(CNN) is a kind of deep learning and optimized to analyze visual imagery and it used to convergence with vision recognition and classification.  In this research, three kind of fracture surfaces are classified by using CNN. In order to improve classification accuracy, different number of filters are set and tested. And several times of image augmentation method is applied. Finally, 95% of classification accuracy is printed. Developed program can classify random microscopic fracture surface images."
Fast neutron-gamma discrimination in organic scintillators via convolution neural network,2022,"['Fast-neutron detection', 'Pulse-shape discrimination', 'Deep-learning', 'Convolution neural network', 'Organic scintillator']",국문 초록 정보 없음,"Due to the high gamma sensitivity of organic scintillators, it is essential to discriminate signals induced by neutron from gamma-ray in fast-neutron detection. With the improvement of digital signal processing techniques, diverse discrimination methods based on pulse-shape variation by radiation type have been developed. The main purpose of this study was to verify the applicability of a deep-learning model, especially convolution neural network (CNN), to pulse-shape discrimination (PSD) in organic scintillation detectors, such as BC-501A (liquid) and EJ-276 (plastic). To that end, waveforms of neutron and gamma-ray were experimentally collected using point sources of 137Cs (gamma-ray) and 252Cf (neutron/gamma-ray) and pre-processed for being compatible with deep-learning. The PSD performance was evaluated for both detectors using the charge comparison method (CCM) which is one of the representative conventional PSD techniques of time-domain. In addition, the CNN-based discriminating algorithms were tested, and its preliminary results were confirmed with confusion matrices which indicate the discrimination accuracy of a deep-learning model."
액티브 러닝을 활용한 반도체 웨이퍼 신규 불량 패턴 검출,2022,"['Semiconductor Manufacturing', 'Defect Identification', 'Wafer Bin Map', 'Active Learning', 'Sampling Strategy', 'Convolutional Neural Network.']",국문 초록 정보 없음,"In the semiconductor manufacturing industry, a wafer bin map (WBM) contains defect patterns that provides important clues to identify the root causes of the defect. Traditionally, field engineers classify the pattern types by manually checking WBM. Recently, many studies have been conducted for automatic classification by using deep learning models. To accurately classify defect patterns with convolutional neural network (CNN)-based deep learning models, every WBM must have accurate pattern labels. However, in reality, it takes a lot of time and efforts for engineers to label all the data. In addition, existing CNN-based studies show limitations that cannot detect new defect patterns, frequently occurred in real situations. In this study, we devise a new pattern detection framework based on active learning. Through this, new patterns can be selectively detected even with existing active learning methodologies, and classification performance can be secured by effectively sampling unlabeled data. And we compared the performance and characteristics of each sampling strategy for new pattern detection. The usefulness and applicability of this study was demonstrated by WM-811K, publicly available WBM data."
토픽모델링을 활용한 한국과 미국의 산업수학 이슈 비교,2022,"['미국', '산업수학', '온라인 뉴스', '온라인 포럼', '토픽모델링', '한국', 'US', 'Industrial Mathematics', 'Online News', 'Online Forum', 'Topic Modeling', 'Korea']","본 연구에서는 텍스트마이닝을 활용해 한국과 미국의 온라인 뉴스와 포럼에서 산업수학과 관련한 이슈를 파악하고, 그 결과를 비교 분석하였다. 이를 위해 한국의 주요 포털 사이트인 네이버의 뉴스 기사, 클리앙의 게시글과 댓글, 그리고 미국의 New York Times와 CNN의 뉴스 기사, Reddit의 게시글과 댓글에서 산업수학과 관련한 텍스트 데이터를 수집하여 구조적 토픽모델링 분석을 수행하였다. 주요 분석결과는 다음과 같다. 첫째, 한국의 뉴스는 산업수학의 필요성과 정부의 지원 측면에 대해, 미국에서는 산업수학이 활용되는 다양한 분야에 대해 다루는 것으로 나타났다. 둘째, 한국에서는 온라인 뉴스와 포럼에서 각기 다른 주제로 동일한 개수의 이슈가 나타났지만, 미국에서는 온라인 포럼보다 뉴스 기사에서 더 많은 이슈를 다루고 있는 것으로 나타났다. 이를 토대로 한국에서 산업수학이 정착하는 데 있어 연구자들에게는 학술적, 그리고 정부에는 실무적 시사점을 제시하였다.","This study explored the issues of industrial mathematics in online news articles and online forums in Korea and the US by using text mining and compared the results. Text data about industrial mathematics were collected from news articles of Naver, a major portal site, and postings and replies on Clien as resources of Korea, and from news articles by the New York Times and CNN as well as postings and replies on Reddit as resources of the US. Structural topic modeling analyses were performed, the major results of which were as follows. First, news articles in Korea mainly dealt with the necessity of industrial mathematics and government support. On the contrary, the news articles in the US focused more on various fields where industrial mathematics fields were utilized. Second, in Korea, the same number of issues with different topics were discussed in news articles and online forums, whereas in the US more issues were covered in news articles than in online forums. It was suggested academic implications for researchers and practical implications for the government for settling industrial mathematics in Korea."
근전도 신호와 딥러닝을 이용한 Finger Motion Tracking,2022,"['근전도(Electromyographic)', '딥러닝(Deep learning)', '가상현실(Virtual Reality)', '손가락 동작 추정(Finger motion tracking)', '회귀(Regression)']",국문 초록 정보 없음,"VR controllers are generally used by hand. But they are not suitable for Handicapped with amputated arm joint. Controllors for them are needed because virtual reality technology can become close to our real life. This study aims to implement it through electromyography signal and Deep learning. Data sets are created through digital filtering and time series feature extraction. Using 1d CNN-LSTM, CNN is used to create a feature map of electromyogram signal and LSTM is used to analyze time series associations. This model takes about 370ms to calculate the predicted data. Loss of prediction through train data is 0.00164, and 0.008458 for test data and 0.008688 for validation data."
Crack segmentation in high-resolution images using cascaded deep convolutional neural networks and Bayesian data fusion,2022,"['Bayesian data fusion', 'crack detection', 'deep learning', 'semantic segmentation', 'structural health monitoring']",국문 초록 정보 없음,"Manual inspection of steel box girders on long span bridges is time-consuming and labor-intensive. The quality of inspection relies on the subjective judgements of the inspectors. This study proposes an automated approach to detect and segment cracks in high-resolution images. An end-to-end cascaded framework is proposed to first detect the existence of cracks using a deep convolutional neural network (CNN) and then segment the crack using a modified U-Net encoder-decoder architecture. A Naive Bayes data fusion scheme is proposed to reduce the false positives and false negatives effectively. To generate the binary crack mask, first, the original images are divided into 448 × 448 overlapping image patches where these image patches are classified as cracks versus non-cracks using a deep CNN. Next, a modified U-Net is trained from scratch using only the crack patches for segmentation. A customized loss function that consists of binary cross entropy loss and the Dice loss is introduced to enhance the segmentation performance. Additionally, a Naive Bayes fusion strategy is employed to integrate the crack score maps from different overlapping crack patches and to decide whether a pixel is crack or not. Comprehensive experiments have demonstrated that the proposed approach achieves an 81.71% mean intersection over union (mIoU) score across 5 different training/test splits, which is 7.29% higher than the baseline reference implemented with the original U-Net."
딥러닝 모델과 비침습적 데이터를 활용한 수술 중 저혈압 예측에 관한 연구,2022,[],"수술 중 저혈압 예측은 환자의 안전과 직결되는 중요한 과제이다. 그러나 인간이 저혈압을 예측하는 것은 많은 경험과 노하우를 필요로 하며, 현재 연구되고 있는 예측 기술은 단일 정보를 활용하여 복합적인 원인을 반영하지 못하거나, 침습적으로 데이터를 획득하여 환자에게 불편함을 준다. 비침습적으로 수집한 데이터를 통한 저혈압 발생 예측에 대한 연구는 꾸준히 진행되어 왔으나, 기존 딥러닝을 이용한 접근방법으로는 정확도가 낮다. 본 논문에서는 그 원인을 1)데이터 전처리 2)데이터 불균형 3)기존 모델의 한계로 구분하고, 이를 해결 가능한 방안을 제시한다. 실험 결과 CNN*CNN에서 Focal Loss를 사용할 때, 가장 높은 성능을 내는 것을 확인했다.",다국어 초록 정보 없음
SwinE-Net: hybrid deep learning approach to novel polyp segmentation using convolutional neural network and Swin Transformer,2022,"['polyp segmentation', 'convolutional neural networks', 'multidilation convolutional block', 'multifeature aggregation block', 'Swin Transformer', 'Vision Transformer']",국문 초록 정보 없음,"Prevention of colorectal cancer (CRC) by inspecting and removing colorectal polyps has become a global health priority because CRC is one of the most frequent cancers in the world. Although recent U-Net-based convolutional neural networks (CNNs) with deep feature representation and skip connections have shown to segment polyps effectively, U-Net-based approaches still have limitations in modeling explicit global contexts, due to the intrinsic nature locality of convolutional operations. To overcome these problems, this study proposes a novel deep learning model, SwinE-Net, for polyp segmentation that effectively combines a CNN-based EfficientNet and Vision Transformer (ViT)-based Swin Ttransformer. The main challenge is to conduct accurate and robust medical segmentation in maintaining global semantics without sacrificing low-level features of CNNs through Swin Transformer. First, the multidilation convolutional block generates refined feature maps to enhance feature discriminability for multilevel feature maps extracted from CNN and ViT. Then, the multifeature aggregation block creates intermediate side outputs from the refined polyp features for efficient training. Finally, the attentive deconvolutional network-based decoder upsamples the refined and combined feature maps to accurately segment colorectal polyps. We compared the proposed approach with previous state-of-the-art methods by evaluating various metrics using five public datasets (Kvasir, ClinicDB, ColonDB, ETIS, and EndoScene). The comparative evaluation, in particular, proved that the proposed approach showed much better performance in the unseen dataset, which shows the generalization and scalability in conducting polyp segmentation. Furthermore, an ablation study was performed to prove the novelty and advantage of the proposed network. The proposed approach outperformed previous studies."
딥러닝 기반 반려동물 모니터링 시스템 및 활동 인식 장치,2022,"['Monitoring system', 'Activity recognition device', 'Deep learning', 'Activity recognition', 'Activity analysis', '모니터링 시스템', '활동 인식 장치', '딥러닝', '활동 인식', '활동 분석']","본 논문에서는 활동 인식장치를 이용한 딥러닝 기반의 반려동물 모니터링 시스템을 제안한다.이 시스템은 반려동물의 활동 인식장치와 반려인의 스마트 기기, 서버로 구성된다. 아두이노 기반활동 인식 장치로부터 가속도와 자이로 데이터를 수집하고, 이로부터 반려동물의 걸음 수를 연산하였다. 수집된 데이터는 전처리 과정을 거쳐 CNN과 LSTM을 하이브리드한 딥러닝 모델을 통해5가지 형태(앉기, 서기, 눕기, 걷기, 뛰기)로 활동을 인식함으로써 활동량을 측정한다. 마지막으로, 반려인의 스마트 기기에 일일 및 주간 브리핑 차트 등 활동 변화에 대한 모니터링을 제공한다.성능 평가 결과, 반려동물의 구체화된 활동 인식 및 활동량 측정이 가능함을 확인하였다. 향후 데이터 축적을 통해 반려동물의 이상행동 탐지 및 헬스 케어 서비스의 확장을 기대할 수 있다.","In this paper, we propose a pet monitoring system based on deep learning using an activity recognition device. The system consists of a pet's activity recognition device, a pet owner's smart device, and a server. Accelerometer and gyroscope data were collected from an Arduino-based activity recognition device, and the number of steps was calculated. The collected data is pre-processed and the amount of activity is measured by recognizing the activity in five types (sitting, standing, lying, walking, running) through a deep learning model that hybridizes CNN and LSTM. Finally, monitoring of changes in the activity, such as daily and weekly briefing charts, is provided on the pet owner's smart device. As a result of the performance evaluation, it was confirmed that specific activity recognition and activity measurement of pets were possible. Abnormal behavior detection of pets and expansion of health care services can be expected through data accumulation in the future."
딥러닝기반 토마토 병해 진단 서비스 연구,2022,"['딥러닝', '토마토병해충', '모바일넷', '레스넷', 'deep learning', 'tomato disease', 'MobileNet', 'ResNet']","토마토 작물은 병해에 노출이 쉽고 단시간에 퍼지므로 병해에 대한 늦은 조치로 인한 피해는 생산량과 매출에 직접적인 영향을 끼친다.  따라서, 토마토의 병해에 대해 누구나 현장에서 간편하고 정확하게 진단하여 조기 예방을 가능하게 하는 서비스가 요구된다. 본 논문에서는 사전에 ImageNet 전이 학습된 딥러닝 기반 모델을 적용하여 토마토의 9가지 병해 및 정상인 경우의 클래스를 분류하고 서비스를 제공하는 시스템을 구성한다. Plant Village 데이터 셋으로부터 토마토 병해 및 정상을 분류한 잎의 이미지 셋을 합성곱을 사용하여 조금 더 가벼운 신경망을 구축한 딥러닝 기반 CNN구조를 갖는 MobileNet, ResNet의 입력을 사용한다. 2가지 제안 모델의 학습을 통해 정확도와 학습속도가 빠른 MobileNet를 사용하여 빠르고 편리한 서비스를 제공할 수 있다.","Tomato crops are easy to expose to disease and spread in a short period of time, so late measures against disease are directly related to production and sales, which can cause damage. Therefore, there is a need for a service that enables early prevention by simply and accurately diagnosing tomato diseases in the field. In this paper, we construct a system that applies a deep learning-based model in which ImageNet transition is learned in advance to classify and serve nine classes of tomatoes for disease and normal cases. We use the input of MobileNet, ResNet, with a deep learning-based CNN structure that builds a lighter neural network using a composite product for the image set of leaves classifying tomato disease and normal from the Plant Village dataset. Through the learning of two proposed models, it is possible to provide fast and convenient services using MobileNet with high accuracy and learning speed."
Development of a Spine X-Ray-Based Fracture Prediction Model Using a Deep Learning Algorithm,2022,"['Osteoporotic fractures', 'Deep learning', 'X-rays', 'Risk assessment']",국문 초록 정보 없음,"Background: Since image-based fracture prediction models using deep learning are lacking, we aimed to develop an X-ray-basedfracture prediction model using deep learning with longitudinal data.Methods: This study included 1,595 participants aged 50 to 75 years with at least two lumbosacral radiographs without baselinefractures from 2010 to 2015 at Seoul National University Hospital. Positive and negative cases were defined according to whethervertebral fractures developed during follow-up. The cases were divided into training (n=1,416) and test (n=179) sets. A convolutional neural network (CNN)-based prediction algorithm, DeepSurv, was trained with images and baseline clinical information (age,sex, body mass index, glucocorticoid use, and secondary osteoporosis). The concordance index (C-index) was used to compare performance between DeepSurv and the Fracture Risk Assessment Tool (FRAX) and Cox proportional hazard (CoxPH) models.Results: Of the total participants, 1,188 (74.4%) were women, and the mean age was 60.5 years. During a mean follow-up period of40.7 months, vertebral fractures occurred in 7.5% (120/1,595) of participants. In the test set, when DeepSurv learned with imagesand clinical features, it showed higher performance than FRAX and CoxPH in terms of C-index values (DeepSurv, 0.612; 95% confidence interval [CI], 0.571 to 0.653; FRAX, 0.547; CoxPH, 0.594; 95% CI, 0.552 to 0.555). Notably, the DeepSurv method withoutclinical features had a higher C-index (0.614; 95% CI, 0.572 to 0.656) than that of FRAX in women.Conclusion: DeepSurv, a CNN-based prediction algorithm using baseline image and clinical information, outperformed the FRAXand CoxPH models in predicting osteoporotic fracture from spine radiographs in a longitudinal cohort."
기울기 보정 알고리즘을 이용한 측면에서의 차량 번호 인식 기술 연구,2022,"['Vehicle number recognition', 'Slope correction', 'YOLO', 'Deep Learning']","교통사고 발생률은 매년 증가하고 있으며 대한민국은 OECD 국가 중에서 상위권에 속한다. 이를 개선하기 위해 다양한 도로교통법이 시행되고 있으며 무인 속도 카메라, 교통단속 카메라 등의 장비를 사용한 다양한 교통단속 방법이 적용되고 있다. 그러나 운전자는 네비게이션을 통해 교통단속 카메라의 위치를 사전 감지하여 단속을 회피함에 따라 불시 단속이 가능한 이동식 단속시스템이 필요하며, 정확한 단속을 위해 도로 측면에서 차량 번호판 인식률을 높일 수 있는 연구가 필요하다. 본 논문에서는 영상처리를 이용한 기울기 보정 알고리즘를 적용하여 도로 측면에서의 차량 번호 인식률을 향상을 위한 방법을 제안한다. 또한 문자 이식 정확도 향상을 위해 CNN 기반의 YOLO 알고리즘을 이용하여 커스텀 데이터 학습을 진행하였다. 해당 알고리즘을 설치 장소에 대한 제약이 없는 이동식 교통단속 카메라 등 에 활용 가능할 것으로 기대된다.","The incidence of traffic accidents is increasing every year, and Korea is among the top OECD countries. In order to improve this, various road traffic laws are being implemented, and various traffic control methods using equipment such as unmanned speed cameras and traffic control cameras are being applied. However, as drivers avoid crackdowns by detecting the location of traffic control cameras in advance through navigation, a mobile crackdown system that can be cracked down is needed, and research is needed to increase the recognition rate of vehicle license plates on the side of the road for accurate crackdown. This paper proposes a method to improve the vehicle number recognition rate on the road side by applying a gradient correction algorithm using image processing. In addition, custom data learning was conducted using a CNN-based YOLO algorithm to improve character recognition accuracy. It is expected that the algorithm can be used for mobile traffic control cameras without restrictions on the installation location."
인공지능을 활용한 도주경로 예측 및 추적 시스템,2022,"['영상분석', '인공지능', '도주경로예측', '자동상황전파', '스마트시티 통합플랫폼', 'Intelligent image analysis', 'Escape route prediction', 'Automatic situation propagation', 'Smart city Integrate platform']","서울특별시는 25개 구청에 7만5천여대의 CCTV가 설치되어 있다. 각 구청은 CCTV관제를 위한 관제센터를 구축하고 시민의 안전을 위해 24시간 CCTV영상관제를 수행하고 있다. 서울특별시는 유관기관과 MOU를 체결하여 긴급/응급 상황에 신속한 대응이 가능하도록 구청의 CCTV영상을 제공하여 시민이 안전한 스마트시티통합플랫폼을 구축하고 있다. 본 논문에서는, 서울특별시 관할구청에서 사건 발생 시, CCTV영상에 대해 인공지능 DNN 기반의 Template Matching 기술, MLP 알고리즘과 CNN 기반으로 YOLO SPP DNN모델을 사용하여 사람과 차량을 판별하여 도주경로를 예측한다. 또한, 관할구청을 이탈하여, 차량 및 사람이 도주 시, 인접 구청에 영상정보와 상황정보를 자동전파 하도록 설계한다. 인공지능을 활용한 도주경로 예측 및 추적 시스템은 스마트시티 통합플랫폼을 전국으로 확장시킬 수 있다.","In Seoul, about 75,000 CCTVs are installed in 25 district offices. Each ward office has built a control center for CCTV control and is performing 24-hour CCTV video control for the safety of citizens. Seoul Metropolitan Government is building a smart city integrated platform that is safe for citizens by providing CCTV images of the ward office to enable rapid response to emergency/emergency situations by signing an MOU with related organizations. In this paper, when an incident occurs at the Seoul Metropolitan Government Office, the escape route is predicted by discriminating people and vehicles using the AI ​​DNN-based Template Matching technology, MLP algorithm and CNN-based YOLO SPP DNN model for CCTV images. . In addition, it is designed to automatically disseminate image information and situation information to adjacent ward offices when vehicles and people escape from the competent ward office. The escape route prediction and tracking system using artificial intelligence can expand the smart city integrated platform nationwide."
Multi-Functional Brain Computer Interface Using Convolutional Neural Networks,2022,"['Brain-Computer Interface', 'Multi-intention recognition', 'Neural Network', 'Convolutional Neural Network', 'Feature extraction']",국문 초록 정보 없음,"Brain-computer interface (BCI) is a promising technology that controls computers or machines using brain signals. With this technology, people with various disabilities, such as neural paralysis, and spinal cord injury can control electric devices or express their intention by thinking. However, previous BCI studies have a limitation that they can predict only one type of intention. To use the BCI system in daily life, the BCI user should be able to achieve various tasks such as moving, text typing, and arm movements. In this paper, we propose a multi-functional BCI method that can predict various intentions simultaneously. To classify multiple intentions, we proposed two prediction models using Neural Networks (NN) and Convolutional Neural Networks (CNN) models. To evaluate the proposed BCI system, the classification accuracy of the model was measured and compared using steady state visually evoked potential (SSVEP), sensory motor rhythm (SMR), and both of them (Multiple Intention). The average prediction accuracies were 22.46% in NN, 55.86% in CNN. These results indicate that the proposed multi-functional BCI can predict multiple intentions. It also means that users of the proposed BCI system can control various electric devices simultaneously."
Electroencephalography-based imagined speech recognition using deep long short-term memory network,2022,"['brain–computer interface', 'deep learning', 'EEG', 'imagined speech recognition', 'long short term memory']",국문 초록 정보 없음,"This article proposes a subject-independent application of brain–computer interfacing (BCI). A 32-channel Electroencephalography (EEG) device is used to measure imagined speech (SI) of four words (sos, stop, medicine, washroom) and one phrase (come-here) across 13 subjects. A deep long short-term memory (LSTM) network has been adopted to recognize the above signals in seven EEG frequency bands individually in nine major regions of the brain. The results show a maximum accuracy of 73.56% and a network prediction time (NPT) of 0.14 s which are superior to other state-of-the-art techniques in the literature. Our analysis reveals that the alpha band can recognize SI better than other EEG frequencies. To reinforce our findings, the above work has been compared by models based on the gated recurrent unit (GRU), convolutional neural network (CNN), and six conventional classifiers. The results show that the LSTM model has 46.86% more average accuracy in the alpha band and 74.54% less average NPT than CNN. The maximum accuracy of GRU was 8.34% less than the LSTM network. Deep networks performed better than traditional classifiers."
Development of a Bayesian-based Uncertainty-aware Tool Wear Prediction Model in the End Milling Process,2022,[],국문 초록 정보 없음,"Titanium alloy is one of the most widely used materials in various industries, such as aerospace, medical, and automotive industry because of its desirable mechanical properties. However, titanium alloy is also a difficult-to-cut material due to the low thermal conductivity and low specific heat. In particular, in an end milling process using titanium alloy, tool wear influences not only the cutting force but also material removal volume per a single tool as well as the quality of the material surface. Therefore, accurate tool wear prediction is necessary during an end milling process to improve product quality and replace the tool at an appropriate time. Furthermore, because the effects of tool wear prediction on the overall process are significant both in terms of cost and time, uncertainty-aware tool wear prediction should be performed. In this work, a deep learning-based tool wear prediction model, which uses a Bayesian approach, is proposed. First, a CNN-based architecture that integrates multi-scale information extracted from raw sensor measurement data, named deep multi-scale CNN (DMSCNN) is proposed. Second, using a Bayesian approach, DMSCNN is transformed into a probabilistic model that outputs a predictive distribution with uncertainty awareness. Experiments with data collected from the real-world end milling process with three distinct setups have proven the effectiveness of the proposed DMSCNN in tool wear prediction. In addition, Bayesian DMSCNN has shown promising results, outperforming existing comparative deterministic methods, as well as probabilistic methods for tool wear prediction."
순차적인 데이터 처리를 통한 딥 러닝 기반 트래픽 분류속도 개선,2022,"['Traffic Classification', 'Application Traffic', 'Machine Learning', 'Deep Learning', 'Processing Speed', '트래픽 분류', '응용 트래픽', '머신 러닝', '딥 러닝', '처리 속도']","네트워크의 발전과 변화된 환경으로 인하여 다양한 응용 프로그램들이 개발되고 사용되고 있다. 이에 따라 네트워크 트래픽의 발생량도 증가하고 있으며 효율적인 네트워크의 관리를 위한 응용 트래픽 분류가 필요하다. 응용트래픽 분류는 대부분 분류 정확도에 중점을 두고 있고, 실제 대용량 트래픽이 발생하는 네트워크 환경에서 트래픽 분류를 빠르게 처리하기 위한 연구가 필요하다. 본 논문에서는 순차적으로 데이터를 처리하여 딥 러닝 기반의트래픽 분류속도를 개선하는 방법에 대하여 제안하고, 제안하는 방법에서 사용하는 임계값 및 신뢰도를 정의한다.앙상블 모델에서의 적절한 임계값은 0.7로 99.78%의 신뢰도를 달성하고 전체 데이터의 58.99%의 데이터를 정확하게 분류하였다. 앙상블 모델에서 분류되고 남은 데이터들을 딥 러닝 모델에 적용하여 실험한 결과 제안한 방법의 전체 처리 속도는 1D CNN만을 사용한 결과보다 0.88초 빠른 처리 속도를 보여주었다.","Due to the development of networks and the changed environment, various application programs are being developed and used. Accordingly, the amount of network traffic is also increasing, and application traffic classification is required for efficient network management. Application traffic classification focus on classification accuracy, and is needed to quickly process traffic classification in a network environment where large-capacity traffic. In this paper, we propose a method to improve the traffic classification speed based on deep learning by sequentially processing data, and define the threshold and reliability used in the proposed method. The appropriate threshold in the ensemble model was 0.7, which achieved a reliability of 99.78% and correctly classified 58.99% of the data. As a result of testing by applying the remaining data classified from the ensemble model to the deep learning model, the overall processing speed of the proposed method was 0.88 seconds faster than the result using only 1D CNN."
Infrared Pedestrian Dataset Training using Swin Transformer model,2022,"['Swin Transformer', 'Infrared Image', 'Object Detection', 'Transformer', 'Ir image', 'Backbone training']",국문 초록 정보 없음,"Recently, studies to replace CNN-based models with Transformer models are being actively conducted. In this paper, the Swin Transformer model, which has recently been attracting attention for its excellent performance, was trained using infrared images and its performance was examined. A Swin Transformer designed for RGB images was tuned for infrared image training to train a separate infrared pedestrian dataset and a simple experiment was performed to further improve the infrared image training performance. In addition, in order to properly tune the Swin Transformer Backbone model to the infrared image data and to improve the training performance, we trained separately configured RGB and infrared datasets and analyzed the results. As a result, it was concluded that the Swin Transformer would be suitable for infrared data training if it was slightly tuned for infrared data and lightweight to avoid overfitting. Based on this experiment, the author plans to create a model suitable for infrared datasets in the future and apply it to various practical applications."
YOLO 기반 금속 외관 결함영역 검출,2022,"['금속 외관', '결함 검출', '객체 검출', '합성곱신경망', '딥러닝', 'Metal Surface', 'Detection of Defects', 'Object Detection', 'Convolution Neural Network', 'Deep Learning']","최근 다양한 분야에 딥러닝 기술이 도입되었고, 특히 영상 처리에 특화된 합성곱신경망(CNN: Convolutional Neural Network)이 많이 활용되고 있다. 금속 외관의 결함영역을 검출하는 많은 응용 분야(예를 들어, 스마트 제조 및 스마트팩토리 분야)에서도 합성곱신경망을 활용한 연구가 활발하게 이루어지고 있다. 본 논문에서는 합성곱신경망 기반 객체 검출(Object Detection) 알고리즘 중 하나인 YOLOv4(YOLO 알고리즘의 4번째 버전)를 활용하여 금속 외관의 결함영역을 검출하는 연구를 수행하고자 한다. 특히, 본 논문에서는YOLOv4 네트워크 구조에 여러 후처리 기법들과 전이 학습을 적용하여 향상된 검출 성능을달성하는 방안을 제안한다. 두 가지 종류의 학습데이터셋((i)공용 데이터셋과 (ii)실측 데이터셋)에 대한 실험을 통해 제안한 방법의 성능을 검증하고 분석한다. 또한 성능 검증을 통해공용 데이터셋과 실측 데이터셋에서의 후처리 기법 및 전이학습에 대한 최적의 조합을 도출하였다.",다국어 초록 정보 없음
강인한 머신 러닝 음향 인식을 위한 잔향 영향 분석,2022,"['Sound classification', 'Reverberation', 'VGG16', 'EfficientNet', 'UrbanSound8K', 'Transfer learning']","머신 러닝을 이용한 소리 분류는 먼저 대량의 소리 데이터를 이용하여 CNN과 같은 심층 신경망을 학습시킨 다음, 판별할 소리를 신경망에 입력하여 결과를 얻는 과정을 거친다. 이때 판별할 소리가 존재하는 음향 환경이 소음이나 잔향이 심한 공간이라면 이로 인한 성능 저하가 일어난다. 본 논문에서는 공간의 잔향의 정도와 머신 러닝 분류기의 인식 성능과의 관계를 분석하였다. 이를 위해 UrbanSound8K 데이터 세트와 VGG16 및 EfficientNet 기반의 전이 학습 시스템을 구성하였으며, 3개의 잔향 파라미터 변화에 따라 총 27종의 잔향 패턴을 생성하고 각각에 대해 인식률 변화를 모의 실험하였다. 실험 결과 잔향으로 인해 머신 러닝의 인식 성능이 저하되었으며, 파라미터 별로는 Wet dry mix의 영향이 가장 크고 다음으로 Diffusion, Decay factor의 순이었다.",다국어 초록 정보 없음
EpiLoc: Deep Camera Localization Under Epipolar Constraint,2022,"['Camera localization', 'End-to-end', 'Epipolar geometry', 'Pixel-level constraint.']",국문 초록 정보 없음,"Recent works have shown that the geometric constraint can be harnessed to boost the performance of CNN-based camera localization. However, the existing strategies are limited to imposing image-level constraint between pose pairs, which is weak and coarse-gained. In this paper, we introduce a pixel-level epipolar geometry constraint to vanilla localization framework without the ground-truth 3D information. Dubbed EpiLoc, our method establishes the geometric relationship between pixels in different images by utilizing the epipolar geometry thus forcing the network to regress more accurate poses. We also propose a variant called EpiSingle to cope with non-sequential training images, which can construct the epipolar geometry constraint based on a single image in a self-supervised manner. Extensive experiments on the public indoor 7Scenes and outdoor RobotCar datasets show that the proposed pixel-level constraint is valuable, and helps our EpiLoc achieve state-of-the-art results in the end-to-end camera localization task."
Sparse estimation residual attention network을 이용한 이미지 denoising network,2022,[],"본 논문은 기존의 SOTA image denoising model보다 우수한 성능을 나타내는 SERANet모델을 제안한다. 해당 모델은 deep CNN에서 발생할 수 있는 문제점을 보완하기 위해 residual encoder decoder (REDNet)를 기반으로 sparse estimation과 residual attention을 수행한다. sparse estimation은 dilated convolution과 일반적인 convolution layer로 구성되어 있어 computation cost에 대한 부담을 적게 하되 이미지 내의 다양한 정보를 습득할 수 있도록 해 준다. residual attention은 REDNet의 encoder 입력단과 decoder의 출력단의 중간 layer에 위치하며, 채널 내 feature의 값을 추출하여 REDNet이 이미지 디노이즈를 효과적으로 수행할 수 있게 한다. 마지막으로 skip connection으로 연결되어 있는 REDNet을 통해 이미지의 디노이즈를 본격적으로 수행할 수 있다. 결과적으로, 제안하는 모델은 다양한 노이즈 레벨의 AWGN에 대해 SOTA 모델보다 우수한 PSNR 성능을 보인다.",다국어 초록 정보 없음
Attention Module이 적용된 Convolution Neural Network와 Multi-feature fusion을 이용한 얼굴표정 인식,2022,[],본 논문은 Attention Module이 적용된 Convolution Neural Network와 Multi-feature fusion을 이용한 얼굴표정 인식에 관한 것이다. 제안된 방법은 이미지 전체의 특징을 다루는 CNN과 얼굴의 주요 특징인 landmarks와 image path를 fusion 하여 얼굴표정 인식을 위한 새로운 융합전략을 제시한다. 제안된 방법에 따라 FER+ 데이터에의 정확도가 기존의 방법보다 1.3 % 증가하였다.,다국어 초록 정보 없음
딥러닝 기반 영상 속 유해언어 차단 시스템 개발,2022,"['필터링', '딥러닝', '디지털 네이티브', '유해 언어', '영상 처리']","본 연구에서는 영유아 및 청소년들을 보호하기 위한 목적으로, 딥러닝 기술을 활용하여 유해 언어를 필터링해 더 안전한 동영상으로 가공하는 시스템을 개발하였다. 이 시스템을 사용하면 음성을 텍스트로 변환하여 화자에 따라 모델의 유해언어 인식 정확도가 달라지는 문제를 해결할 수 있다. 필터링 범위는 문장 전체로, 문장의 공격도를 판단하였다. CNN모델로 욕설, 성적 불쾌감을 조성하는 문장을 필터링하고 해당 부분을 효과음 처리해 영상을 가공한다. 사용자는 웹페이지에 원하는 영상을 업로드하여 시스템을 통해 필터링 된 영상을 제공받을 수 있다. 이로써 영유아 및 청소년이 안전한 영상을 시청함으로써 정서적으로 올바른 성장에 기여할 것으로 기대한다. 또한 자극적인 언어 표현에 피로한 사람, 특정 표현에 대한 트라우마가 있는 사람 등 대상에 국한되지 않고 다양한 목적으로 사용될 수 있을 것이다.",다국어 초록 정보 없음
텍스트-비디오 검색 모델에서의 캡션을 활용한 비디오 특성 대체 방안 연구,2022,"['Multimodal Deep Learning', 'Video-Captioning', 'Text-Video Retrieval']",국문 초록 정보 없음,"In this paper, we propose a method that performs a text-video retrieval model by replacing video properties using captions. In general, the exisiting embedding-based models consist of both joint embedding space construction and the CNN-based video encoding process, which requires a lot of computation in the training as well as the inference process. To overcome this problem, we introduce a video-captioning module to replace the visual property of video with captions generated by the video-captioning module. To be specific, we adopt the caption generator that converts candidate videos into captions in the inference process, thereby enabling direct comparison between the text given as a query and candidate videos without joint embedding space. Through the experiment, the proposed model successfully reduces the amount of computation and inference time by skipping the visual processing process and joint embedding space construction on two benchmark dataset, MSR-VTT and VATEX."
딥러닝 기반 걸음걸이 인증 시스템,2022,[],"개인 정보 보호가 중요시되는 초연결사회에서는 정보와 사용자를 연결하는 매개체는 적법하지 않은 사용자를 판별할 수 있어야 한다. 본 연구는 그 매개체를 스마트폰으로 삼고 인간의 걸음걸이에 기반한 스마트폰 인증 시스템을 제안한다. 인간의 걸음걸이를 딥러닝 모델 중 하나인 CNN으로 학습시킨 후, 스마트폰에 탑재하여 사용자가 스마트폰을 휴대한 상태로 7초간 걸음으로써 적법한 사용자인지 아닌지의 여부를 판별한다. 본 연구에서 제안한 모델의 평가 지표로는 정확도, 정밀도, 재현율, F1-score를 사용했으며, 그 결과, 위 4개의 평가지표 모두 평균 95% 이상의 결과를 얻었다.",다국어 초록 정보 없음
CutPaste-Based Anomaly Detection Model using Multi Scale Feature Extraction in Time Series Streaming Data,2022,"['Anomaly Detection', 'Multi Scale Feature Extraction', 'Self-Supervised Learn']",국문 초록 정보 없음,"The aging society increases emergency situations of the elderly living alone and a variety of social crimes. In order to prevent them, techniques to detect emergency situations through voice are actively researched. This study proposes CutPaste-based anomaly detection model using multi-scale feature extraction in time series streaming data. In the proposed method, an audio file is converted into a spectrogram. In this way, it is possible to use an algorithm for image data, such as CNN. After that, mutli-scale feature extraction is applied. Three images drawn from Adaptive Pooling layer that has different-sized kernels are merged. In consideration of various types of anomaly, including point anomaly, contextual anomaly, and collective anomaly, the limitations of a conventional anomaly model are improved. Finally, CutPaste-based anomaly detection is conducted. Since the model is trained through self-supervised learning, it is possible to detect a diversity of emergency situations as anomaly without labeling. Therefore, the proposed model overcomes the limitations of a conventional model that classifies only labelled emergency situations. Also, the proposed model is evaluated to have better performance than a conventional anomaly detection model."
간선화물의 상자 하차를 위한 외팔 로봇 시스템 개발,2022,"['Object Recognition', 'Robotic Arm', 'Kinematics', 'Task And Motion Planning', 'Image Processing']",국문 초록 정보 없음,"In this paper, the developed trunk cargo unloading automation system is introduced, and the RGB-D sensor-based box loading situation recognition method and unloading plan applied to this system are suggested. First of all, it is necessary to recognize the position of the box in a truck. To do this, we first apply CNN-based YOLO, which can recognize objects in RGB images in real-time. Then, the normal vector of the center of the box is obtained using the depth image to reduce misrecognition in parts other than the box, and the inner wall of the truck in an image is removed. And a method of classifying the layers of the boxes according to the distance using the recognized depth information of the boxes is suggested. Given the coordinates of the boxes on the nearest layer, a method of generating the optimal path to take out the boxes the fastest using this information is introduced. In addition, kinematic analysis is performed to move the conveyor to the position of the box to be taken out of the truck, and kinematic analysis is also performed to control the robot arm that takes out the boxes. Finally, the effectiveness of the developed system and algorithm through a test bed is proved."
2-input 딥러닝 기반 Multi-task 전동 킥보드 안전 주행 시스템,2022,[],국문 초록 정보 없음,"The electric scooter-sharing service has experienced rapid growth with the limelight of personal mobility devices. However, there is a growing concern in society about increasing cases of e-scooter accidents. To address this problem, we propose a deep learning-based electric scooter safe driving system that considers both user images and road images. In our framework, we use CNN-based models to detect whether the user is using a helmet or keeping eyes forward using a user image. At the same time, we check whether the driver is riding on the road and then estimate the distance between the user and the closest pedestrian within a road image. Finally, we determine the final velocity of the e-scooter using the result value of each model. Through a fast and accurate deep learning model, we improve efficiency for real-time inference and achieve high confidence in the system by considering multiple dangers simultaneously."
딥러닝 기술을 적용한 난수 생성기 연구 동향,2022,[],"암호화 프로그램에서 난수생성기는 널리 사용되며 중요한 역할을 하므로 공격의 대상이 되기 쉽고, 따라서 높은 난수성을 확보해야 한다. 최근에는 인공 신경망 기술이 발달함에 따라 난수생성기에 딥러닝 기술을 적용하는 연구들이 다수 진행되었으며, 본 논문에서는 이러한 연구 동향에 대해 알아본다. 크게 난수를 생성하는 연구와 다음에 올 수를 예측하는 예측 공격으로 나뉜다. 공통적으로는 학습해야 할 대상인 난수가 시계열 데이터이므로 대부분의 연구들이 RNN, CNN-1D 신경망을 사용한다. 난수 생성을 위해서는 분류형 신경망이 아닌, 생성형 신경망과 강화학습을 주로 사용하였다. 대부분의 연구들이 NIST SP-800 테스트를 시행하였을 때 높은 난수성을 확보할 수 있었다. 이외에도 최근 양자 컴퓨터가 개발됨에 따라 양자 하드웨어로부터의 양자 난수 생성기에 대한 예측 공격에 관한 연구도 있다. 딥러닝 기반의 난수 생성기에 대해서, 향후에는 기존의 난수생성기보다 빠른 생성 속도를 달성할 수 있는 경량 구현에 대한 연구와 그에 대한 비교 및 평가가 있어야 할 것으로 생각된다.",다국어 초록 정보 없음
딥러닝 기반의 반도체 패키지 다이면 스크래치 검출 방법,2022,"['Scratch Detection', 'Deep Learning', 'Image Processing', 'Semiconductor Package', '.']",국문 초록 정보 없음,.
Recurrence Plot을 이용한 드론 비행음 감지 및 분류,2022,[],본 논문은 시계열 신호인 드론 비행음을 분류하기 위해서 Recurrence Plot을 이용하는 방법을 제안한다. 일반적으로 사람의 신체구조를 반영한 MFCC(Mel Frequency Cepstral Coefficients)의 경우 voice recognition에 더 유리하고 RP(Recurrence Plots)는 대부분의 time-series 데이터에 적용할 수 있어 UAV 등의 동작음을 감지하는데 더욱 적합하다. MFCC와 RP에 대하여 설명한 후에 직접 RP를 그려봄으로써 분류 가능성을 확인하였다. 향후에 CNN을 통해 각 드론의 비행음을 분류가능하도록 연구할 예정이다.,다국어 초록 정보 없음
Diamond ArUco 마커를 이용한 드론 착륙 지점 3차원 좌표 추정 방법 연구,2022,"['drone', 'autonomous landing', 'image recognition', 'fiducial marker', 'object detection']",국문 초록 정보 없음,"As interest in autonomous landing of drones and unmanned systems is rising, research for accurate landing of drones remains a challenge. In general, there is a landing method through GNSS, but the position error of the landing site is not detailed, so landing methods using vision through a camera and additional sensors are suggested. In the previous study of our research team, CNN-based station recognition research was performed, but the recognition error was limited due to external environment(wind pressure, vortex, etc.) during the landing mission. was presented. The existing identifier is a single identifier, and only one fiducial marker recognized by the drone was relied on. Diamond ArUco, the marker presented in this study, has four identifiers in the form of a cross, so a method to minimize the error of 3D coordinate estimation is presented in this paper. evaluation was discussed."
Exploiting Neural Network for Temporal Multi-variate  Air Quality and Pollutant Prediction,2022,"['Air Quality Index (AQI)', 'Air Pollutant', 'Temporal clustering', 'Forecasting']",국문 초록 정보 없음,"In recent years, the air pollution and Air Quality Index (AQI) has been a pivotal point for researchers due to its effect on human health. Various research has been done in predicting the AQI but most of these studies, either lack dense temporal data or cover one or two air pollutant elements. In this paper, a hybrid Convolutional Neural approach integrated with recurrent neural network architecture (CNN- LSTM), is presented to find air pollution inference using a multivariate air pollutant elements dataset. The aim of this research is to design a robust and real-time air pollutant forecasting system by exploiting a neural network. The proposed approach is implemented on a 24-month dataset from Seoul, Republic of Korea. The predicted results are cross-validated with the real dataset and compared with the state-of-the-art techniques to evaluate its robustness and performance. The proposed model outperforms SVM, SVM-Polynomial, ANN, and RF models with 60.17%, 68.99%, 14.6%, and 6.29%, respectively. The model performs SVM and SVM-Polynomial in predicting O3 by 78.04% and 83.79%, respectively. Overall performance of the model is measured in terms of Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE) and the Root Mean Square Error (RMSE)."
A Lightweight Deep Learning-based Anomaly Detection and Classification in Software-Defined Industrial Network,2022,"['SDN', 'IIoT', 'DDoS Detection and Classification', 'Deep Learning']",국문 초록 정보 없음,"Software-Defined Networking (SDN) is a promising platform for Industrial Internet of Things (IIoT) networks that provide flexibility, reliability, and efficiency. SDN-based IIoT networks have a centralized controller that is a single vulnerable target to attack. In this paper, a lightweight Distributed Denial-of-Service (DDoS) detection and classification based on network features is proposed using an improved CNN-LSTM and tested with the latest CICDDoS2019 dataset. The proposed model achieves a low computation time which enables the delay constraint industrial network with a DDoS detection rate above 99.02% and a computation time of 0.14 ms."
딥러닝 표정 인식을 통한 운동 영상 유튜브 하이라이트 업로드 자동화(RPA) 설계,2022,[],"본 논문은 유튜브에 업로드 된 운동 영상을 시청하는 사람의 얼굴 영역을 YoloV3을 이용하여 얼굴 영상에서 눈 및 입술영역을 검출하는 방법을 연구하여, YoloV3은 딥 러닝을 이용한 물체 검출 방법으로 기존의 특징 기반 방법에 비해 성능이 우수한 것으로 알려져 있다. 본 논문에서는 영상을 다차원적으로 분리하고 클래스 확률(Class Probability)을 적용하여 하나의 회귀 문제로 접근한다. 영상의 1 frame을 입력 이미지로 CNN을 통해 텐서(Tensor)의 그리드로 나누고, 각 구간에 따라 객체인 경계박스와 클래스 확률을 생성해 해당 구역의 눈과 입을 검출한다. 검출된 이미지 감성 분석을 통해, 운동 영상 중 하이라이트 부분을 자동으로 선별하는 시스템을 설계하였다.",다국어 초록 정보 없음
머신러닝 기반 금속외관 결함 검출 비교 분석,2022,"['금속 외관', '결함 검출', '머신러닝', '합성곱신경망', 'Metal Surface', 'Defect Detection', 'Machine Learning', 'Convolutional Neural Network']","최근 스마트팩토리와 인공지능 기술의 수요 증가로 인해 다양한 분야에서 인공지능 기술을 적용하는 연구가 진행되고 있다. 결함 검사 분야에서도 인공지능 알고리즘을 도입하기 위한 노력을 기울이고 있다. 특히, 금속 외관의 결함을 검출하는 연구는 다른 소재(목재, 플라스틱, 섬유 등)의 결함을 검출하는 연구에 비해 많은 연구가 이루어지고 있다. 본 논문에서는 머신러닝 기법(서포터 벡터 머신(SVM: Support Vector Machine), 소프트맥스 회귀(Softmax Regression), 결정 트리(Decesion Tree))과 차원 축소 알고리즘(주성분 분석(PCA: Principal Component Analysis), 오토인코더(AutoEncoder))의 9가지 조합과 2가지 합성곱신경망(CNN: Convolution Neural Network) 기법(자체 알고리즘, ResNet)의 금속 외관의 결함 분류 성능 및 속도를 비교하고 분석하는 연구를 수행하고자 한다. 두 종류의 학습 데이터셋((i) 공용 데이터셋, (ii) 실측 데이터셋)에 대한 실험을 통해 각 데이터셋에 대한 성능 및 속도를 비교 분석하고, 가장 효율적인 알고리즘을 찾아낸다.",다국어 초록 정보 없음
센서 퓨전을 통한 자율주행 트랙터의 장애물 인식 시스템 개발,2022,"['자율주행 농기계', '인식 시스템', '딥러닝']","자율주행 농기계는 농업의 노동력 문제에 대한 해결책으로 개발되어 최근 GPS 기반 자율주행 시스템이 적용된 제품들이 상용화되었다. 장애물 인식 및 충돌 예방 기술 개발은 자율주행 농기계가 무인화되기 위한 필수적인 기술이다. 하지만 GPS 센서는 동적 환경에 대한 인식이 어려워 충돌 사고를 예방할 수 없기 때문에, 농업 환경에 적합한 환경 인식 시스템의 구성이 필요하다. 본 연구는 자율주행 경운 트랙터의 충돌 사고 예방을 위해, 센서 퓨전에 기반한 인식 알고리즘을 개발하여 실제 자율주행 상황에서의 충돌 예방 성능을 평가하고자 한다. 객체 분류에 강점을 가지는 RGB 카메라와, 거리 측정에 강인한 라이다 센서를 융합한 센서 시스템으로, RGB 카메라는 Intel社의 D435i를 사용하였으며, 라이다는 Velodyne社의 VLP16을 사용하였다. 인식 알고리즘은 RGB 영상에서 CNN에 기반하여 객체를 인식하고, 영상에 투영된 라이다 데이터를 이용해 상대 거리를 측정한다. 개발된 알고리즘은 실제 농업 환경에서 자율주행 트랙터를 활용하여 유효성을 검증하였으며, 충돌 위험 구간에서의 인식률은 99% 이상, 거리 측정 오차는 50cm 이내, 충돌 예방 성공률은 97% 이상의 성능을 보였다.",다국어 초록 정보 없음
VVC 화면 내 예측에서의 딥러닝 기반 예측 블록 개선을 통한 부호화 효율 향상 기법,2022,"['Intra Prediction', 'Convolutional Neural Network', 'Versatile Video Coding.']","본 논문에서는 컨볼루션 신경망 네트워크를 이용하여 VVC 화면 내 예측으로 얻은 예측 블록을 개선하여 잔차 신호를 보다 줄이는 화면 내 예측 방법을 제안한다. 기존의 화면 내 예측 방법은 일부 고정 규칙을 기반으로 주변의 재구성된 참조 샘플로부터 예측 블록을 생성하므로 복잡한 콘텐츠의 예측 블록을 생성하기 어렵다는 한계가 있다. 또한, 참조 샘플로 이용할 수 있는 정보의 양이 시간적 주변 정보에 비해 적기 때문에 화면 간 예측보다 낮은 부호화 성능을 가진다. 본 연구에서는 앞서 언급한 문제를 해결하기 위해 기존의 비디오 부호화 과정의 화면 내 예측을 통해 생성되는 예측 블록에 CNN을 적용하여 원본 블록과 예측 블록의 차분 신호를 줄이는 화면 내 예측 방법을 제안한다. 부호기에서는 제안 알고리즘의 활성 여부를 나타내는 플래그가 함께 부호화된다. 제안하는 화면 내 예측 방법은 최신 비디오 압축 표준인 Versatile Video Coding의 참조 모델인 VTM version 10.0[1] 대비 휘도 성분에 대하여 향상된 압축 성능을 제공한다.",다국어 초록 정보 없음
연합학습 기반 전력 중개용 태양광 발전 예측,2022,[],"최근 대두된 환경문제로 인해 다양한 재생 에너지의 실리적인 활용 방법에 귀추가 주목되고 있다. 특히 ‘그린뉴딜’, ‘K-RE100’ 등 정부 주도의 정책으로 태양광 발전 시장 규모가 확대되면서, 소규모 발전 사업자의 태양광 발전 참여율도 매년 증가 추세를 보이고 있다. 이로 인해 소규모 발전사업자의 수익을 산정하는 전력 중개 시스템의 태양광 발전 예측은 에너지 시장의 핵심요소로 부각되었다. 하지만 전력 중개용 태양광 발전 예측에는 기후의 간헐성으로 인한 예측 정확도 감소, 소규모 발전 사업자의 개인정보 보호 등 제약이 존재한다. 이 논문에서는 전력 중개용 태양광 발전 예측의 제약을 해소하고, 전력 중개 활성화를 지원키 위한 CNN-LSTM 기반 연합학습 기법을 제안한다.",다국어 초록 정보 없음
Classification of CTC on Fluorescence Image Based on Improved AlexNet,2022,"['Circulating Tumor Cells', 'Computer Aided Diagnosis', 'Cell nucleus']",국문 초록 정보 없음,"These days, cancer has been the most primary cause of death in Japan. Cancer often progresses by repeating metastasis, so early detection and early treatment are important. Analysis of Circulating Tumor Cells (CTCs) has come to gather attention as a new biomarker that CTCs can detect primary cancer in human body. However, the number of CTCs in a billion blood cells is only a few, and detecting CTCs is very hard. Accordingly, we propose an automatic detection method of CTCs from fluorescence microscopy images to enable quantitative analysis by computer. This method consists of two parts. The first part, we use some series of filtering to the images and, new dividing method some overlapping nucleus then, from the images cut out the region of interest (ROI). The second part is distinguishing images by using CNN. We applied the proposed method to 5040 images of 6 samples. As a result, we obtained TPR:94.59%, FPR:6.544% by using AlexNet based model."
Period Independent Transportation Mode Detection for People with Mobility Disabilities: A Pilot Study with DenseNet,2022,"['Transportation mode detection', 'mobility disability', 'wheelchair', 'performance evaluation method']",국문 초록 정보 없음,"Transportation mode detection (TMD) can help improving our daily life by understanding the mobility patterns of people. Such enhanced understanding of mobility can also be beneficial to people with mobility disabilities including wheelchair users. Moreover, as it is hard to collect large dataset from wheelchair users, it is important for TMD for wheelchair users (wTMD) to maintain similar performance on data from different period which might have dissimilar environmental or behavioral characteristics. However, we could not find studies evaluating such period independency of the wTMD model. Thus, we investigated wTMD performance on data from different period, and improved such performance by suggesting a new wTMD model. Our results showed that both our proposed model (DenseNet-based-model) and the baseline model (CNN-based-model) had period dependency, but our proposed model outperformed the baseline model when evaluated with data from different period. Our findings indicate the importance of the evaluation method and show that deep convolutional network with high information interchange can help improving wTMD performance on data from different period."
BCG 신호 최적화를 통한 주행중 운전자 수면 상태 분류에 관한 연구,2022,[],국문 초록 정보 없음,"Drowsy driving requires a lot of social attention because it increases the incidence of traffic accidents and leads to fatal accidents. The number of accidents caused by drowsy driving is increasing every year. Therefore, in order to solve this problem all over the world, research for measuring various biosignals is being conducted. Among them, this paper focuses on non-contact biosignal analysis. Various noises such as engine, tire, and body vibrations are generated in a running vehicle. To measure the driver's heart rate and respiration rate in a driving vehicle with a piezoelectric sensor, a sensor plate that can cushion vehicle vibrations was designed and noise generated from the vehicle was reduced. In addition, we developed a system for classifying whether the driver is sleeping or not by extracting the model using the CNN-LSTM ensemble learning technique based on the signal of the piezoelectric sensor. In order to learn the sleep state, the subject's biosignals were acquired every 30 seconds, and 797 pieces of data were comparatively analyzed."
실시간 객체추적 알고리즘을 적용한 화재감시 시스템 개발에 관한 연구,2022,"['Realtime', 'Fire recognition', 'Fire detector', 'CCTV', 'YOLO']","화재 발생시 화재를 알리는 화재감지기는 급격한 온도변화를 감지하여 경보가 울리는 시스템으로 일정 온도 이상이 되면 화재경보가 발생하게 된다. 화재는 초기 진압이 중요하며, 화재 골든 타임인 화재 발생 10분 이내 화재진압에 실패하면 화재가 급격히 확산되어 피해 면적이 급증하게 된다. 최근 건축 구조물 내에서 사용되는 스마트 화재 감지 CCTV는 화재와 연기를 인식하여 화재를 탐지하는 방식이 아닌 CCTV에 설치된 온도 감지 센서를 이용하여 주위 온도가 센서의 설정 온도보다 높은 경우에 화재로 판단하여 화재 신호를 알리는 방식이다. 이러한 방식은 CCTV의 실시간 동영상 촬영의 장점을 활용하여 화재를 감지하는 것이 아니고, 단순하게 온도 센서에 의해 화재를 감지하고 화재 현장에 대해서만 동영상을 송출한다. 본 연구에서는 실내용 스마트 화재감지 CCTV의 문제점을 개선하고자 불꽃, 연기, 사람 등의 객체들을 추적하고 인식할 수 있는 YOLO 기반의 알고리즘을 CCTV 등의 실시간 감시장비에 적용하였다. 딥러닝 알고리즘 중 하나인 CNN의 경우 Fast-RCNN이 0.5fps, Faster-RCNN이 7fps 수준인 것에 반해 일반적으로 YOLO 알고리즘은 다른 딥러닝 알고리즘들에 비해 FPS(Frame Per Second)가 높다고 알려져 있다. YOLO의 FPS는 45~155fps 수준이며, 높은 FPS는 초당 얼마나 많은 이미지를 인식하는지를 의미한다. 화재는 초기 발견이 중요한 만큼 FPS 역시 매우 중요한 요소이다. 본 연구에서는 높은 수준의 FPS 객체추적 알고리즘인 YOLO 모델을 적용하여 CCTV등 영상을 이용한 실시간 화재감시 시스템에 관한 연구이다.",다국어 초록 정보 없음
Machine Learning Algorithm Accuracy for Code-Switching Analytics in Detecting Mood,2022,"['machine learning', 'mental health prediction', 'code switching analytics', 'systematic review', 'accuracy measurement']",국문 초록 정보 없음,"Nowadays, as we can notice on social media, most users choose to use more than one language in their online postings. Thus, social media analytics needs reviewing as code-switching analytics instead of traditional analytics. This paper aims to present evidence comparable to the accuracy of code-switching analytics techniques in analysing the mood state of social media users. We conducted a systematic literature review (SLR) to study the social media analytics that examined the effectiveness of code-switching analytics techniques. One primary question and three sub-questions have been raised for this purpose. The study investigates the computational models used to detect and measures emotional well-being. The study primarily focuses on online postings text, including the extended text analysis, analysing and predicting using past experiences, and classifying the mood upon analysis. We used thirty-two (32) papers for our evidence synthesis and identified four main task classifications that can be used potentially in code-switching analytics. The tasks include determining analytics algorithms, classification techniques, mood classes, and analytics flow. Results showed that CNN-BiLSTM was the machine learning algorithm that affected code-switching analytics accuracy the most with 83.21%. In addition, the analytics accuracy when using the code-mixing emotion corpus could enhance by about 20% compared to when performing with one language. Our meta-analyses showed that code-mixing emotion corpus was effective in improving the mood analytics accuracy level. This SLR result has pointed to two apparent gaps in the research field: i) lack of studies that focus on Malay-English code-mixing analytics and ii) lack of studies investigating various mood classes via the code-mixing approach."
다중 공간정보 데이터의 점진적 조합에 의한 의미적 분류 딥러닝 모델 학습 성능 분석,2022,"['Multi-modal Data', 'Intrinsic Information', 'Deep Learning', 'Building Extraction', '다중 데이터', '고유정보', '딥러닝', '건물추출']","대부분의 경우 광학 RGB 영상을 딥러닝(DL: Deep learning)의 학습 데이터로 사용하여 객체탐지, 인식, 식별, 분류, 의미적 분할 및 객체 분할 등을 수행하지만, 실세계의 3차원 객체들을 2차원 영상으로 완전하게 파악하는 것 은 한계가 있다. 그러므로 대표적인 3차원 지형 공간정보인 수치표면모델(DSM: Digital Surface Model)과 더불어 DSM에 내재된 특성정보를 이용하여 3차원 지형지물을 분석하는 것이 효과적이다. 건물과 같이 기하학적으로 정 형화된 형태의 인공구조물은 3차원 공간데이터로부터 얻을 수 있는 기하학적 요소와 특성을 이용하여 객체의 분 류와 형상 묘사가 가능하다. 이 연구는 고차원 시각정보(high-level visual information) 시스템에서 중요한 역할을 하는 내재된 고유의 특성정보(intrinsic information)를 기반으로 하며, 이를 위하여 객체의 기하학적 요소인 경사 와 주향을 DSM으로부터 도출하고, 다방향에서 생성한 음영기복영상(SRI: Shaded Relief Image)과 함께 DL 모델 의 학습 수행에 사용하였다. 실험은 ISPRS (International Society for Photogrammetry and Remote Sensing)에서 제공하는 데이터 셋 중에서 DSM과 레이블 데이터를 객체의 의미적 분류를 위해 개발된 합성곱 기반의 SegNet 학 습에 사용하였다. 지형지물을 분류하고 분류 결과를 이용하여 건물을 추출하였다. 특히 DL 모델의 학습 성능 향상 을 위해 학습 데이터의 여러 조합에 따른 시너지 효과를 분석하는 것에 핵심이다. 제안한 방법은 건물 분류와 추출 에 효과적임을 보여주고 있다.","In most cases, optical images have been used as training data of DL (Deep Learning) models for object detection, recognition, identification, classification, semantic segmentation, and instance segmentation. However, properties of 3D objects in the real-world could not be fully explored with 2D images. One of the major sources of the 3D geospatial information is DSM (Digital Surface Model). In this matter, characteristic information derived from DSM would be effective to analyze 3D terrain features. Especially, man-made objects such as buildings having geometrically unique shape could be described by geometric elements that are obtained from 3D geospatial data. The background and motivation of this paper were drawn from concept of the intrinsic image that is involved in high-level visual information processing. This paper aims to extract buildings after classifying terrain features by training DL model with DSM-derived information including slope, aspect, and SRI (Shaded Relief Image). The experiments were carried out using DSM and label dataset provided by ISPRS (International Society for Photogrammetry and Remote Sensing) for CNN-based SegNet model. In particular, experiments focus on combining multi-source information to improve training performance and synergistic effect of the DL model. The results demonstrate that buildings were effectively classified and extracted by the proposed approach."
Multiple damage detection of maglev rail joints using time-frequency spectrogram and convolutional neural network,2022,"['bibliometric analysis', 'centrality index', 'network analysis', 'research trend', 'structural health monitoring', '3D convolutional neural network', 'damage detection', 'maglev rail joints', 'time-frequency spectrogram']",국문 초록 정보 없음,"Maglev rail joints are vital components serving as connections between the adjacent F-type rail sections in maglev guideway. Damage to maglev rail joints such as bolt looseness may result in rough suspension gap fluctuation, failure of suspension control, and even sudden clash between the electromagnets and F-type rail. The condition monitoring of maglev rail joints is therefore highly desirable to maintain safe operation of maglev. In this connection, an online damage detection approach based on three-dimensional (3D) convolutional neural network (CNN) and time-frequency characterization is developed for simultaneous detection of multiple damage of maglev rail joints in this paper. The training and testing data used for condition evaluation of maglev rail joints consist of two months of acceleration recordings, which were acquired in-situ from different rail joints by an integrated online monitoring system during a maglev train running on a test line. Short-time Fourier transform (STFT) method is applied to transform the raw monitoring data into time-frequency spectrograms (TFS). Three CNN architectures, i.e., small-sized CNN (S-CNN), middle-sized CNN (M-CNN), and large-sized CNN (L-CNN), are configured for trial calculation and the M-CNN model with excellent prediction accuracy and high computational efficiency is finally optioned for multiple damage detection of maglev rail joints. Results show that the rail joints in three different conditions (bolt-loosenesscaused rail step, misalignment-caused lateral dislocation, and normal condition) are successfully identified by the proposed approach, even when using data collected from rail joints from which no data were used in the CNN training. The capability of the proposed method is further examined by using the data collected after the loosed bolts have been replaced. In addition, by comparison with the results of CNN using frequency spectrum and traditional neural network using TFS, the proposed TFSCNN framework is proven more accurate and robust for multiple damage detection of maglev rail joints."
딥러닝과 테라헤르츠 기술을 이용한 폴리머 배관 결함 검출에 관한 연구,2022,"['테라헤르츠', '폴리머', '비파괴검사', '딥러닝', '컨볼루션 신경망', 'Terahertz', 'Polymer', 'Non-destructive Testing', 'Deep Learning', 'Convolutional Neural Network']","본 연구에서는 폴리머 배관의 결함을 검출하기 위해 Terahertz time-domain-spectroscopy (THz-TDS) 시스템과 convolutional neural network (CNN) 알고리즘을 사용하였다. THz-TDS 시스템의 투과 모드를 사용하여 정상 폴리머 배관과 결함이 있는 폴리머 배관에 대한 THz scanning data를 확보하였다. 폴리머 배관의 결함부위를 투과한 THz wave는 산란이 발생하여 진폭이 감소하는 것을 확인하였다. THz scanning 이미지 속 폴리머 배관의 결함 부위는 THz 신호의 진폭 감소로 발생한 픽셀의 음영차이로 구분할 수 있는 것을 확인하였다. THz 이미지 데이터는 CNN 학습을 위해 데이터 증대(data augmentation) 기법을 사용하여 증폭시켰으며, 증폭된 THz 이미지 데이터는 정상과 결함으로 종류(class)를 나누어 CNN 딥러닝 알고리즘에 학습시켰다. 딥러닝 학습결과 CNN 모델은 95% 이상의 정확도로 폴리머 배관의 결함을 검출할 수 있음을 확인하였다. 이를 통해, 테라헤르츠 파를 이용하여 폴리머 배관을 비접촉, 비파괴 검사할 수 있으며, CNN 딥러닝 알고리즘을 사용하여 자동화된 결함 검출을 할 수 있음을 확인하였다.","The terahertz time-domain spectroscopy (THz-TDS) system and convolutional neural network (CNN) algorithm were used to detect a defect in a polymer tube. The THz scanning data of the normal and defective polymer tubes were obtained from the THz-TDS transmission mode. The amplitude of the THz wave transmitted by the crack of the polymer tube was decreased by scattering. It was confirmed that the crack in the polymer tube in the THz scanning image can be classified by the shading difference of the pixel. The THz image data were amplified for CNN deep learning using an augmentation technique, and the amplified THz image data were learned by the CNN deep learning algorithm by dividing classes into normal and defect datasets. As a result of deep learning, the CNN model can detect a crack in a polymer tube with an accuracy of 95% or more. Finally, it was confirmed that a defect in a polymer tube can be inspected using a noncontact and nondestructive terahertz inspection method with the CNN deep-learning algorithm."
딥러닝 적용 선별 모델 비교 및 프로토타입 개발: 파프리카 중심으로,2022,"['선별기', '딥러닝', 'Faster R-CNN', 'YOLO', '파프리카']","소비자의 생활 수준이 향상됨에 따라 고품질 농산물에 대한 수요가 증가하고 있다. 과실의 선별은 상품성과 직결되기 때문에 현 소비 트렌드를 따라가기 위해 고려해야 할 주요한 요인 중 하나이다. 중량 선별기의 경우 과실의 중량만을 이용하여 선별하기 때문에 과실의 완숙도 및 장해 여부 선별에 한계가 있고, 광학 선별기의 경우 NIR 카메라 및 다수의 고가 장비를 통해 중량 선별기의 한계를 극복하였으나, 비용적 측면에서 농가에 부담이 따른다. 본 연구에서는 넓은 선별 스펙트럼을 유지하는 동시에 투입되는 장비의 비용을 줄일 수 있는 선별기 제작을 위해 딥러닝 알고리즘인 Faster R-CNN과 YOLO v5를 비교하고, 선별기 프로토타입을 개발하였다. CNN(Convolutional Neural Network)은 이미지 분류에 특화된 딥러닝 알고리즘으로 다중 클래스 분류가 가능하다. Faster R-CNN은 기존 CNN 알고리즘에 별도의 영역 제안 네트워크(RPN, Region Proposal Network)를 적용하여 학습 및 수행 속도가 개선되었다. YOLO(You Only Look Once)는 실시간 객체 인식에 특화된 딥러닝 알고리즘으로 Faster R-CNN과 달리 영역 제안을 위한 별도의 네트워크를 사용하지 않아 처리속도가 빠르다. 코코넛 성숙 단계 분류 연구(Kim et al.등, 2020)에서 Faster R-CNN 모델인 ResNet-50으로 코코넛 이미지 2,000장을 학습한 결과 mAP(평균 정밀도, mean Average Precision)이 89.4% 정확도로 분류하였다. YOLO v3를 이용한 사과 장해 여부 검출 연구(Valdez et al.등, 2020)는 웹으로부터 모은 사과 이미지 452장을 학습한 결과 mAP 74.3%의 정확도를 보고하였다. 본 연구에서 선별 모델로 적합하다고 판단되는 Faster R-CNN의 ResNet-50과 YOLO 모델 중 경량화 특징이 있는 YOLO v5를 이용한 선별 알고리즘을 개발하여 라즈베리파이4 (Raspberry Pi 4, 8GB RAM) 에 구현하여 성능을 비교하였다. 전라북도 부안군 계화면 소재의 ‘파프리카’ 온실에서 파프리카(machay)를 수확하였다. 수확한 파프리카를 촬영하여 학습에 사용할 이미지 데이터를 확보하였고, 웹크롤링을 통해 부족한 이미지 데이터를 추가로 확보하였다. 구득한 이미지 데이터는 ‘성숙과’, ‘미성숙과’, ‘판정보류’, 그리고 ‘비정상과’로 분류하였고, 바운딩 박스를 추가한 라벨데이터를 구축하였다. 전체 이미지 및 라벨 데이터의 80%와, 20%를 각각 학습, 검증에 사용하였다. 카메라 모듈을 통해 실시간으로 촬영하는 영상에 학습한 모델을 적용하여 객체의 클래스를 판별하고, 서보모터가 판별 결과에 따라 레버를 지정한 각도로 움직이도록 설계하였다. 모델의 성능은 mAP, 판별 소요 시간을 평가하였다. 본 연구는 딥러닝을 이용하여 과실의 완숙도 및 장해 여부를 선별하는 데에 그쳤지만, 향후 연구에서 다양한 종류의 이미지 데이터를 확보한다면 병해, 충해, 냉해, 한해 등의 다양한 작물피해 또한 선별하여 범용적으로 적용 가능할 것으로 기대한다.",다국어 초록 정보 없음
배터리 리드탭 압흔 오류 검출의 딥러닝 기법 적용,2022,"['배터리 리드탭', '압흔 오류 검출', '인공지능', '딥러닝', 'Faster R-CNN', '객체 탐지', 'Battery lead tab', 'Welding error detection', 'Artificial intelligence', 'Deep learning', 'Faster R-CNN', 'Object detection']","자동차용 배터리 제조공정 가운데 하나인 Tab Welding 공정에서 생산된 제품의 샘플링 인장검사를 대체하기 위해 현재 비전검사기를 개발하여 사용하고 있다. 그러나, 비전검사는 검사 위치 오차 문제와 이를 개선하기 위해 발생하는 비용 문제를 가지고 있다. 이러한 문제점들을 해결하기 위해 최근 딥러닝 기술을 적용하는 사례들이 발생하고 있다. 본 논문도 그런 사례 중 하나로 기존 제품 검사에 딥러닝 기술 중 하나인 Faster R-CNN을 적용하여 그 유용성을 파악하고자 하였다. 기존 비전검사기를 통해 획득한 이미지들을 학습 데이터로 사용하여 Faster R-CNN ResNet101 V1 1024x1024 모델을 사용하여 학습하였다. 검사 기준인 미검률 0%, 과검률 10%의 기준으로 기존 비전검사와 Faster R-CNN 검사결과를 비교 분석하였다. 미검출률은 기존 비전검사에서 34.5%, Faster R-CNN 검사에서 0%였다. 과검출률은 기존 비전검사에서 100%, Faster R-CNN에서 6.9%였다. 결론적으로 자동차용 배터리 리드탭 암흔 오류 검출에 딥러닝 기술이 매우 유용함을 확인할 수 있었다.",다국어 초록 정보 없음
Frequency response similarity-based bolt clamping force prediction method using convolutional neural networks,2022,"['Bolt clamping force', 'Frequency response function', 'Krylov subspace-based model order reduction', 'MS similarity function', 'MS similarity map', 'Deep learning', 'CNN']",국문 초록 정보 없음,"This paper proposes a convolutional neural network (CNN)-based method with which to predict bolt clamping force using the frequency response of bolted structures. The dynamic characteristics of the bolted structure change with the bolt clamping force, which is predicted using a CNN trained with massive frequency response data. Big data required for training the CNN is constructed using prestressed frequency response analysis according to the clamping force of individual bolts. The numerical efficiency is increased using the Krylov subspace-based model order reduction (MOR) method. The frequency response for each set of bolt clamping forces calculated from the MOR method is converted into form of the magnitude and shape (MS) similarity spectrum by using the MS similarity function. Finally, an MS similarity map is generated by stacking the MS similarity spectrum at several output points. A CNN that is trained using massive MS similarity maps as training data, is used to predict the clamping force of bolted structures. To validate the efficiency and accuracy of a trained CNN in practical applications, the prediction results of the trained network in terms of computation time and accuracy were compared according to the size of the training input data."
Bearing Fault Diagnosis Using One-Dimensional Convolutional Neural Network,2022,"['big data', 'deep learning', 'convolutional neural network', 'rolling bearing fault diagnosis']",국문 초록 정보 없음,"In this paper, a fault diagnosis strategy using one-dimensional convolutional neural network (CNN) is developed for rolling bearing. Firstly, each basic unit in the CNN model to be proposed is introduced in detail, and the optimization algorithm required for the CNN is described to show the working principle, which provides a theoretical basis for the onedimensional CNN model. Next, a series of preprocessing such as overlap sampling and unique thermal coding are performed on the rolling bearing dataset from Case Western Reserve University, and a batch normalization algorithm is proposed to improve the training efficiency and performance of the CNN model. Finally, the designed one-dimensional CNN model is trained, the adaptive ability of the model with variable load is tested, and good results are obtained."
Shrinkage Crack Detection in Expansive Soil using Deep Convolutional Neural Network and Transfer Learning,2022,"['Shrinkage crack', 'Crack detection', 'Expansive soil', 'Deep learning', 'Deep convolutional neural network']",국문 초록 정보 없음,"The formation of shrinkage cracks is a natural phenomenon in expansive soils. The development of these cracks affects both the physical and mechanical properties of the soil. This paper proposes new procedures for predicting and detecting the formation of crack patterns in expansive soils, based on customized Convolution Neural Network (CNN) and transfer learning. A total of four different deep learning models are developed to detect the soil crack pattern by changing the convolution layers and hyper-parameters in the analysis. The novelty of the proposed detection methods lies in the use of customized CNN models in shrinkage crack detection for expansive soils. The customized CNN models are constructed by varying the number of convolution layers and the hyperparameters. The results show that the proposed CNN models provide very accurate results and are capable of detecting the presence of cracks in the soil with great accuracy. The best results are from one of the customized CNN models namely the Customized CNN Model 2 which consists of five convolution layers, three activation layers, one pooling layer, two fully connected layers, and a softmax layer. The results from this model are compared with other well-known approaches from the literature and are shown to provide improved results. Overall, the proposed deep learning methods developed in this paper produce excellent results in terms of the accurate detection of shrinkage soil cracks and can also be applied to other types of soil cracks."
기계학습을 통한 주간 반투명 구름탐지 연구: GK-2A/AMI를 이용하여,2022,"['GK-2A/AMI', 'Transparent cloud', 'Cloud detection', 'Machine learning']",국문 초록 정보 없음,"Clouds are composed of tiny water droplets, ice crystals, or mixtures suspended in the atmosphere and cover about two-thirds of the Earth's surface. Cloud detection in satellite images is a very difficult task to separate clouds and non-cloud areas because of similar reflectance characteristics to some other ground objects or the ground surface. In contrast to thick clouds, which have distinct characteristics, thin transparent clouds have weak contrast between clouds and background in satellite images and appear mixed with the ground surface. In order to overcome the limitations of transparent clouds in cloud detection, this study conducted cloud detection focusing on transparent clouds using machine learning techniques (Random Forest [RF], Convolutional Neural Networks [CNN]). As reference data, Cloud Mask and Cirrus Mask were used in MOD35 data provided by MOderate Resolution Imaging Spectroradiometer (MODIS), and the pixel ratio of training data was configured to be about 1:1:1 for clouds, transparent clouds, and clear sky for model training considering transparent cloud pixels. As a result of the qualitative comparison of the study, bothRF and CNN successfully detected various types of clouds, including transparent clouds, and in the case of RF+CNN, which mixed the results of the RF model and the CNN model, the cloud detection was well performed, and was confirmed that the limitations of the model were improved. As a quantitative result of the study, the overall accuracy (OA) value of RF was 92%, CNN showed 94.11%, and RF+CNN showed 94.29% accuracy."
지능형 OCR 시스템을 위한 한글 필기체 생성 및 분류 모델에 관한 연구,2022,"['OCR', 'CNN', 'GAN', 'Handwriting generation', 'Handwriting recognition', 'OCR', 'CNN', 'GAN', '필체 생성', '필체 인식']","본 논문에서는 다양한 산업분야에 적용 가능한 딥러닝 알고리즘 기반의 한글 필기체 생성 및 분류 모델을 구현하였다. 구현된 GAN 기반의 한글 필기체 생성 모델과 CNN 기반의 한글 필기체 분류 모델 2가지로 구성되어 있다. GAN 모델은 가짜 한글 필기체 데이터를 생성하기 위한 생성자 모델과 가짜 필기체 데이터를 판별하기 위한 판별자 모델로 구성된다. CNN 모델의 경우 'PHD08' 데이터세트를 활용하여 모델의 학습을 수행하였으며, 학습 결과 92.45% 정확도로 한글 필기체를 분류하는 것을 확인하였다. 구현된 GAN 모델을 통해 생성된 한글 필기체 데이터를 기존 CNN 모델의 학습 데이터세트와 통합하여 분류 모델의 성능평가를 진행한 결과 96.86%로 기존 분류 성능보다 우수하게 나타남을 확인하였다.",다국어 초록 정보 없음
OFDM 레이다를 위한 딥러닝 기반 표적의 거리 및 속도 추정 기법,2022,"['OFDM 레이다', '다중 출력 CNN', '거리 및 속도 추정', '딥러닝', 'OFDM radar', 'Multiple output CNN', 'Distance and velocity estimation', 'Deep learning']",본 논문에서는 OFDM 레이다를 위한 딥러닝 기반 표적의 거리 및 속도 추정 기법을 제안한다. 제안하는 기법은 표적으로부터 반사된 수신 신호를 받아 변조신호 제거 후 2차원 FFT를 통해 2차원 주기도를 얻는다. 주기도는 기존 및 제안 방법에서 표적의 거리 및 속도를 추정하는 입력신호이다. 주기도에서 정점은 표적의 위치를 나타내는데 표적의 거리 및 속도 추정을 위해 널리 사용되는 기존 기법은 CFAR (Constant False Alarm Rate) 알고리즘이다. 반면 제안하는 기법은 다중 출력 CNN (Convolutional Neural Network)을 이용하여 거리 및 속도를 추정한다. 기존 기법과 달리 제안 기법은 주기도 이외에 잡음 전력과 같이 추가적인 정보가 필요하지 않아 사용하기 편리하다. 컴퓨터 시뮬레이션 결과에 따르면 제안 추정 기법은 기존 기법보다 거리 및 속도 추정 MSE (Mean Square Error)오차 성능을 5배 이상 개선하며 송신 OFDM 심볼 개수가 증가할수록 정확도가 향상되는 특성을 보인다.,"In this paper, we propose deep learning-based target distance and velocity estimation technique for OFDM radar systems. In the proposed technique, the 2D periodogram is obtained via 2D fast Fourier transform (FFT) from the reflected signal after removing the modulation effect. The periodogram is the input to the conventional and proposed estimators. The peak of the 2D periodogram represents the target, and the constant false alarm rate (CFAR) algorithm is the most popular conventional technique for the target’s distance and speed estimation. In contrast, the proposed method is designed using the multiple output convolutional neural network (CNN). Unlike the conventional CFAR, the proposed estimator is easier to use because it does not require any additional information such as noise power. According to the simulation results, the proposed CNN improves the mean square error (MSE) by more than 5 times compared with the conventional CFAR, and the proposed estimator becomes more accurate as the number of transmitted OFDM symbols increases."
합성곱 신경망을 이용한 풍력 블레이드 상태 구분,2022,"['wind turbine blade', 'CNN', 'state classification', 'spectrogram', 'classification accuracy', '.']","본 논문에서는 풍력 블레이드의 상태를 구분하기 위한 CNN 구분기 설계 및 구분 실험 결과를 제시한다. 상태별로 서로 다른 CNN 구분기를 설계하였으며 구분기 1에는 외관 상태, 구분기 2에는 동작 상태를 구분하였다. 구분하려고 하는 풍력 블레이드의 상태로는 외형적으로는 정상 상태와 파손 상태를 가정하였으며, 동작적으로는 정상 회전과 불균형 회전을 가정하였다. 훈련 데이터는 상태별 잡음이 없는 스펙트로그램을 사용하였고 테스트 데이터는 가우시안 잡음을 추가하여 구분기의 성능을 검증하였다. 실험 결과 SNR이 좋아짐에 따라 구분 결과도 향상되었으며, 5dB 상태일 때 구분기 1의 구분 정확도는 99.83%, 구분기 2의 구분 정확도는 98.68%를 가짐을 확인하였다. 본 연구를 통하여 딥러닝 구분기가 가중합 그래프와 플래시 간격 그래프를 이용하는 선행 연구에 비해 더 좋은 구분 성능을 나타냄을 확인하였다.","This paper shows the CNN(Convolutional neural network) classifier design and simulation results for classifying the state of the wind turbine blade. The separate CNN classifiers are designed to classify by a state, and the appearance states were classified in the classifier 1 and the operation states in the classifier 2. The states of the wind turbine blade to be classified are assumed to be a normal state and a damaged state by an appearance, and a balanced rotation and unbalanced rotation by an operation. As the training data, spectrograms without noise for each state are used, and as the test data, spectrograms with noise are used to verify the performance of the classifier. As a result, the classification performance is improved as the SNR is increased, and the classification accuracy of classifier 1 is 99.83% and the classification accuracy of classifier 2 was 98.68% at the SNR of 5 dB. This research shows that the deep learning classifier has the better performance than the previous research which use the weighted sum graph and the flash interval graph."
Regularized Convolutional Neural Network for Highly Effective Parallel Processing,2022,"['Heterogenous system', 'GPGPU', 'Parallel processing', 'OCR', 'Diverse branch']",국문 초록 정보 없음,"Convolutional neural network (CNN) has been adopted in various areas. Using graphics processing unit (GPU), speed improvement can be achieved on CNN, and many studies have proposed such acceleration methods. However, parallelizing the CNN on GPU is not straightforward because there are irregular characteristics in generating output feature maps in typical CNN models. In this paper, we propose a method that maximizes the utilization of GPU by modifying convolution combinations of a well-known CNN network, LeNet-5. Our regularized implementation on a heterogeneous system has achieved an improvement of up to 37.26 times in convolution and sub-sampling layers. Further, an energy consumption reduction of up to 26.40 times is achieved."
MOX 가스센서의 시료 주입 전후패턴들을 이용한 신경회로망 기반의 적포도주 분류,2022,"['MOX gas sensor', 'electronic nose', 'SVM', 'CNN', 'red wine classification', '.']","MOX(Metal OXide) 가스센서는 고감도, 저가, 긴수명 등 여러 장점에도 불구하고 반응 값의 드리프트로 인해 여전히 안전 방재 영역에서 산업화에 어려움을 가지고 있다. 본 논문에서는 4 종류의 적포도주들의 시료에 대해서 MOX 가스센서의 시료 측정 전의 센서의 상태를 측정하고 그 결과를 시료 측정 후의 데이터에 통합하여  SVM(Support Vector Machine)과 CNN(Convolution Neural Network) 분류 모델의 입력으로 사용하였다. MOX 가스센서의 시료 측정 전의 센서의 상태를 측정하여 분류 모델의 입력 데이터에 포함한 SVM 모델의 경우는 4 종류의 포도주를 100% 정확하게 분류 하였으나 그 데이터를 배제한 경우는 4 종류의 포도주를 2 종류로만 분류 하였다. CNN 모델의 경우는 그 데이터를 포함한 경우에는 4 종류의 포도주를 100% 정확하게 분류하였으나 그 데이터를 배제한 경우에는 1 종류로만 분류하였다.","In spite of a lot of merits of MOX (metal oxide) gas sensor such as high sensitivity, low cost, and long lifetime, it is not popular for MOX gas sensor to be used in fields of safty and security areas due to a lack of stability such as drift. This paper dramatically improves the classification ability for the four kinds of red wines which are prepared here using SVM and CNN classification models based on data before and after sample measurements. In the case of the SVM model, which the data of the state of the sensor before measuring the sample is included in,, 4 kinds of red wine are classified with 100% accuracy, but In the case of the exclusion of the data, the tested wines are classified only with 2 kinds. In the case of the CNN model, which the data of the state of the sensor before measuring the sample is included in,, 4 kinds of red wine are classified with 100% accuracy, but In the case of the exclusion of the data, the wines are classified only one kind."
"Open Arms: Open-Source Arms, Hands & Control",2022,"['Low-cost robotic arms', 'deep learning grasping', 'intelligent control', 'humanoid']",국문 초록 정보 없음,"Open Arms is a novel open-source platform of realistic human-like robotic hands and arms hardware with 28 Degree-of-Freedom (DoF), designed to extend the capabilities and accessibility of humanoid robotic grasping and manipulation. The Open Arms framework includes an open SDK and development environment, simulation tools, and application development tools to build and operate Open Arms. This paper describes these hands’ controls, sensing, mechanisms, aesthetic design, and manufacturing and their real-world applications with a teleoperated nursing robot. From 2015 to 2022, the authors have designed and established the manufacturing of Open Arms as a low-cost, high functionality robotic arms hardware and software framework to serve both humanoid robot applications and the urgent demand for low-cost prosthetics, as part of the Hanson Robotics Sophia Robot platform. Using the techniques of consumer product manufacturing, we set out to define modular, low-cost techniques for approximating the dexterity and sensitivity of human hands. To demonstrate the dexterity and control of our hands, we present a Generative Grasping Residual CNN (GGR-CNN) model that can generate robust antipodal grasps from input images of various objects in real-time speeds (∼22ms). We achieved state-of-the-art accuracy of 92.4% using our model architecture on a standard Cornell Grasping Dataset, which contains a diverse set of household objects."
Hybrid quantum-classical convolutional neural network model for COVID-19 prediction using chest X-ray images,2022,"['COVID-19', 'medical image classification', 'deep neural networks', 'quanvolutional neural networks', 'quantum computing', 'image processing']",국문 초록 정보 없음,"Despite the great efforts to find an effective way for coronavirus disease 2019 (COVID-19) prediction, the virus nature and mutation represent a critical challenge to diagnose the covered cases. However, developing a model to predict COVID-19 via chest X-ray images with accurate performance is necessary to help in early diagnosis. In this paper, a hybrid quantum-classical convolutional neural network (HQ-CNN) model using random quantum circuits as a base to detect COVID-19 patients with chest X-ray images is presented. A collection of 5445 chest X-ray images, including 1350 COVID-19, 1350 normal, 1345 viral pneumonia, and 1400 bacterial pneumonia images, were used to evaluate the HQ-CNN. The proposed HQ-CNN model has achieved higher performance with an accuracy of 98.6% and a recall of 99% on the first experiment (COVID-19 and normal cases). Besides, it obtained an accuracy of 98.2% and a recall of 99.5% on the second experiment (COVID-19 and viral pneumonia cases). Also, it obtained 98% and 98.8% for accuracy and recall, respectively, on the third dataset (COVID-19 and bacterial pneumonia cases). Lastly, it achieved accuracy and recall of 88.2% and 88.6%, respectively, on the multiclass dataset cases. Moreover, the HQ-CNN model is assessed with the statistical analysis (i.e. Cohen’s Kappa and Matthew correlation coefficients). The experimental results revealed that the proposed HQ-CNN model is able to predict the positive COVID-19 cases."
Classification of Midinfrared Spectra of Colon Cancer Tissue Using a Convolutional Neural Network,2022,"['Convolution neural network', 'Hyperspectral imaging', 'Mid-infrared']",국문 초록 정보 없음,"The development of midinfrared (mid-IR) quantum cascade lasers (QCLs) has enabled rapid highcontrast measurement of the mid-IR spectra of biological tissues. Several studies have compared the differences between the mid-IR spectra of colon cancer and noncancerous colon tissues. Most midIR spectrum classification studies have been proposed as machine-learning-based algorithms, but this results in deviations depending on the initial data and threshold values. We aim to develop a process for classifying colon cancer and noncancerous colon tissues through a deep-learning-based convolutionalneural-network (CNN) model. First, we image the midinfrared spectrum for the CNN model, an imagebased deep-learning (DL) algorithm. Then, it is trained with the CNN algorithm and the classification ratio is evaluated using the test data. When the tissue microarray (TMA) and routine pathological slide are tested, the ML-based support-vector-machine (SVM) model produces biased results, whereas we confirm that the CNN model classifies colon cancer and noncancerous colon tissues. These results demonstrate that the CNN model using midinfrared-spectrum images is effective at classifying colon cancer tissue and noncancerous colon tissue, and not only submillimeter-sized TMA but also routine colon cancer tissue samples a few tens of millimeters in size."
딥러닝 기반 운동 자세 교정 시스템의 성능,2022,"['CNN', 'Deep learning', 'Human activity recognition', 'LSTM', 'RNN', 'Time series classification']",국문 초록 정보 없음,"Recently, interesting of home training is getting bigger due to COVID-19. Accordingly, research on applying HAR(human activity recognition) technology to home training has been conducted. However, existing paper of HAR proposed static activity instead of dynamic activity. In this paper, the deep learning model where dynamic exercise posture can be analyzed and the accuracy of the user's exercise posture can be shown is proposed. Fitness images of AI-hub are analyzed by blaze pose. The experiment is compared with three types of deep learning model: RNN(recurrent neural network), LSTM(long short-term memory), CNN(convolution neural network). In simulation results, it was shown that the f1-score of RNN, LSTM and CNN is 0.49, 0.87 and 0.98, respectively. It was confirmed that CNN is more suitable for human activity recognition than other models from simulation results. More exercise postures can be analyzed using a variety learning data."
Study of Convolution Neural Network Based Deep Learning to Classify the Quality  of Self-Piercing Riveting Joint,2022,"['Convolution  Neural  Network(CNN)', 'Classification', 'Self-Piercing  Rivet(SPR)', 'Deep  learning', 'Abnormal process  conditions']",국문 초록 정보 없음,"The SPR(Self-Piercing Riveting) process is a mechanical joining process that is mainly applied to assembling multi- material parts to reduce the weight of the car body. Because the quality of SPR joints is mainly evaluated through cross sectional inspection, which is a type of destructive inspection, it is expensive and time-consuming. Machine learning technology is being proposed as a non-destructive testing because it can predict the quality based on the signals generated during the process. However, research result on the quality prediction modeling of SPR joints have not yet been reported. In this study, the prediction accuracy according to the signal combination was compared and evaluated by applying the CNN algorithm using the displacement and load signals generated during the SPR process and the acoustic signal obtained from the acoustic sensor. The materials used in the experiment were SGAFC 1180Y, CFRP, and SPFC 590 and the thickness were 1.4 mm, 1.8 mm, and 1.0 m respectively and a three-layer SPR process was performed. After evaluating joining was performed by selecting the abnormal process conditions, with 12 con- ditions that may occur during the process. Consequently, in the case of the first model in which the CNN algorithm was based on displacement and load signals, the quality prediction accuracy was estimated to be 90.0%. In the case of the second model in which the CNN algorithm added acoustic signals to the displacement and load signals, the quality prediction accuracy was estimated to be 77.5%."
Evaluation of maxillary sinusitis from panoramic radiographs and cone-beam computed tomographic images using a convolutional neural network,2022,"['Artificial Intelligence', 'Maxillary Sinusitis', 'Panoramic Radiography', 'Cone-Beam Computed Tomography']",국문 초록 정보 없음,"Purpose: This study developed a convolutional neural network (CNN) model to diagnose maxillary sinusitis on panoramic radiographs (PRs) and cone-beam computed tomographic (CBCT) images and evaluated its performance. Materials and Methods: A CNN model, which is an artificial intelligence method, was utilized. The model was trained and tested by applying 5-fold cross-validation to a dataset of 148 healthy and 148 inflamed sinus images. The CNN model was implemented using the PyTorch library of the Python programming language. A receiver operating characteristic curve was plotted, and the area under the curve, accuracy, sensitivity, specificity, positive predictive value, and negative predictive values for both imaging techniques were calculated to evaluate the model. Results: The average accuracy, sensitivity, and specificity of the model in diagnosing sinusitis from PRs were 75.7%, 75.7%, and 75.7%, respectively. The accuracy, sensitivity, and specificity of the deep-learning system in diagnosing sinusitis from CBCT images were 99.7%, 100%, and 99.3%, respectively.Conclusion: The diagnostic performance of the CNN for maxillary sinusitis from PRs was moderately high, whereas it was clearly higher with CBCT images. Three-dimensional images are accepted as the “gold standard” for diagnosis; therefore, this was not an unexpected result. Based on these results, deep-learning systems could be used as an effective guide in assisting with diagnoses, especially for less experienced practitioners."
FEC 환경에서 다중 분기구조의 부분 오프로딩 시스템,2022,"['Fog/Edge Computing', 'Partial Offloading', 'Multi-branch Structure', '2-Tier Cooperative Computing', 'CNN Layer Scheduling', '포그/에지 컴퓨팅', '부분 오프로딩', '다중 분기구조', '2계층 협력 컴퓨팅', 'CNN 계층 스케줄링']","본 논문에서는 FEC (Fog/Edge Computing) 환경에서 다중 분기구조의 부분 오프로딩을 위해 모바일 장치와 에지 서버로 구성된 2계층 협력 컴퓨팅 시스템을 제안한다. 제안 시스템은 다중 분기구조에 대한 재구성 선형화 기법을 적용하여 응용 서비스 처리를 분할하는 알고리즘과 모바일 장치와 에지 서버 간의 부분 오프로딩을 통한 최적의 협업 알고리즘을 포함한다. 또한 계산 오프로딩 및 CNN 계층 스케줄링을 지연시간 최소화 문제로 공식화하고 시뮬레이션을 통해 제안 시스템의 효과를 분석한다. 실험 결과 제안 알고리즘은 DAG 및 체인 토폴로지 모두에 적합하고 다양한 네트워크 조건에 잘 적응할 수 있으며, 로컬이나 에지 전용 실행과 비교하여 효율적인 작업 처리 전략 및 처리시간을 제공한다. 또한 제안 시스템은 모바일 장치에서의 응용 서비스 최적 실행을 위한 모델의 경량화 및 에지 리소스 워크로드의 효율적 분배 관련 연구에 적용 가능하다.","We propose a two-tier cooperative computing system comprised of a mobile device and an edge server for partial offloading of multi-branch structures in Fog/Edge Computing environments in this paper. The proposed system includes an algorithm for splitting up application service processing by using reconstructive linearization techniques for multi-branch structures, as well as an optimal collaboration algorithm based on partial offloading between mobile device and edge server. Furthermore, we formulate computation offloading and CNN layer scheduling as latency minimization problems and simulate the effectiveness of the proposed system. As a result of the experiment, the proposed algorithm is suitable for both DAG and chain topology, adapts well to different network conditions, and provides efficient task processing strategies and processing time when compared to local or edge-only executions. Furthermore, the proposed system can be used to conduct research on the optimization of the model for the optimal execution of application services on mobile devices and the efficient distribution of edge resource workloads."
Evaluation of maxillary sinusitis from panoramic radiographs and cone-beam computed tomographic images using a convolutional neural network,2022,"['Artificial Intelligence', 'Maxillary Sinusitis', 'Panoramic Radiography', 'Cone-Beam Computed Tomography']",국문 초록 정보 없음,"Purpose: This study developed a convolutional neural network (CNN) model to diagnose maxillary sinusitis on panoramic radiographs(PRs) and cone-beam computed tomographic (CBCT) images and evaluated its performance. Materials and Methods: A CNN model, which is an artificial intelligence method, was utilized. The model was trained and tested by applying 5-fold cross-validation to a dataset of 148 healthy and 148 inflamed sinus images. The CNN model was implemented using the PyTorch library of the Python programming language. A receiver operating characteristic curve was plotted, and the area under the curve, accuracy, sensitivity, specificity, positive predictive value, and negative predictive values for both imaging techniques were calculated to evaluate the model. Results: The average accuracy, sensitivity, and specificity of the model in diagnosing sinusitis from PRs were 75.7%, 75.7%, and 75.7%, respectively. The accuracy, sensitivity, and specificity of the deep-learning system in diagnosing sinusitis from CBCT images were 99.7%, 100%, and 99.3%, respectively. Conclusion: The diagnostic performance of the CNN for maxillary sinusitis from PRs was moderately high, whereas it was clearly higher with CBCT images. Three-dimensional images are accepted as the ""gold standard"" for diagnosis; therefore, this was not an unexpected result. Based on these results, deep-learning systems could be used as an effective guide in assisting with diagnoses, especially for less experienced practitioners."
Review of Optimal Convolutional Neural Network Accelerator Platforms for Mobile Devices,2022,"['Convolutional neural networks', 'Mobile device', 'Network compression', 'Hardware accelerator', 'Low-power memory']",국문 초록 정보 없음,"In recent years, convolutional neural networks (CNNs) have achieved remarkable performance enhancement, and researchers have endeavored to use CNN applications on power-constrained mobile devices. Accordingly, low-power and high-performance CNN accelerators for mobile devices are receiving significant attention. This paper presents the overall process of designing optimal CNN accelerator platforms for mobile devices based on algorithm, architecture, and memory system co-design while introducing various existing studies related to specific research fields."
Two-phase flow pattern online monitoring system based on convolutional neural network and transfer learning,2022,"['Flow pattern', 'Online monitoring system', 'Artificial neural network (ANN)', 'Convolutional neural network (CNN)', 'Transfer learning', 'ResNet50']",국문 초록 정보 없음,"Two-phase flow may almost exist in every branch of the energy industry. For the corresponding engineering design, it is very essential and crucial to monitor flow patterns and their transitions accurately.With the high-speed development and success of deep learning based on convolutional neural network (CNN), the study of flow pattern identification recently almost focused on this methodology. Additionally, the photographing technique has attractive implementation features as well, since it is normally considerably less expensive than other techniques. The development of such a two-phase flow pattern online monitoring system is the objective of this work, which seldom studied before. The ongoing preliminary engineering design (including hardware and software) of the system are introduced. The flow pattern identification method based on CNNs and transfer learning was discussed in detail. Several potential CNN candidates such as ALexNet, VggNet16 and ResNets were introduced and compared with each other based on a flow pattern dataset. According to the results, ResNet50 is the most promising CNN network for the system owing to its high precision, fast classification and strong robustness. This work can be a reference for the online monitoring system design in the energy system."
컨볼루션 신경망의 End-to-End 앙상블 방법을 활용한 흉부 X-ray 영상 기반 COVID-19 진단 모델 연구,2022,"['딥러닝', 'COVID-19', '흉부 X선 영상', '컨볼루션 신경망', 'End-to-End 앙상블 학습', 'Deep learning', 'Covid-19', 'Chest X-ray image', 'CNN', 'End-to-End Ensemble Learning']",국문 초록 정보 없음,다국어 초록 정보 없음
실내 바닥면 포인트 클라우드를 이용한 AI 기반 3D 공간구조 추정 기술,2022,"['3D reconstruction', 'Spatial Structure Estimation', 'Digital Twin', 'Coner Detection', 'Metaverse', '3D 재구성', '공간구조 추정', '디지털 트윈', '코너 탐지', '메타버스']","본 논문에서는 RGB-D 카메라를 이용해 실세계 실내 공간을 스캔하여 포인트 클라우드로 구성된 가상공간을 구축한다. 포인트 클라우드는 분산되고 노이즈가 많은 특성이 있어 (포인트 클라우드를 이용하여) 실세계와 유사한 가상공간을 재구성하는 것은 어려운 일이며 매우 도전적인 과제이다. 우리는 CNN 모델을 기반으로 3차원 공간의 구조를 추정하여 모델링 하는 효율적인 방법을 제안한다. 3차원 재구성 알고리즘을 기반으로 RGB-D 이미지 통해 실내 포인트 클라우드를 생성하고, 바닥면 데이터를 추출한다. 바닥면 포인트 클라우드 데이터는 2차원 바이너리 영상으로 투영 변환되고, CNN 모델을 이용해 바닥면의 코너를 탐지한다. 이를 기반으로 실내 공간의 3차원 공간구조를 추정하고 모델링 한다. 향후 본 연구는 효율적으로 실세계와 유사한 메타버스 공간을 구축하는 데에 기여할 것이다.","In this paper, we construct a virtual space composed of point clouds by scanning real-world indoor spaces using RGB-D cameras. Point clouds have distributed and noisy properties, making it difficult and a very challenging task to reconstruct a virtual space similar to the real world (using point clouds). We propose an efficient method for estimating and modeling the structure of 3D space based on CNN model. Based on the 3D reconstruction algorithm, an indoor point cloud is created through RGB-D images and floor data is extracted. Floor point cloud data is projected and converted into 2D binary images, and corners of floor is detected using CNN model. Based on this, the 3D spatial structure of the indoor space is estimated and modeled. In the future, this study will contribute to efficiently establishing a metaverse space similar to the real world."
FMCW 레이다 센서 기반 사람과사물 분류 시스템 설계 및 구현,2022,"['BNN accelerator', 'embedded system', 'FMCW radar', 'FPGA', 'multi-target tracking']","본 논문에서는 FMCW(frequency modulated continuous wave) 레이다 센서를 활용한 사람과 사물을 분류하는 시스템 설계및 구현 결과를 제시한다. 해당 시스템은 다중 객체 탐지를 위한 레이다 센서 신호처리 과정과 객체를 사람 및 사물로 분류하는 딥러닝 과정을 수행한다. 딥러닝의 경우 높은 연산량과 많은 양의 메모리를 요구하기 때문에 경량화가 필수적이다. 따라서 CNN(convolution neural network) 연산을 이진화하여 동작하는 BNN (binary neural network) 구조를 적용하였으며, 실시간 동작을위해 하드웨어 가속기를 설계하고 FPGA 보드 상에서 구현 및 검증하였다. 성능 평가 및 검증 결과 90.5%의 다중 객체 구분 정확도,CNN 대비 96.87% 감소된 메모리 구현이 가능하며, 총 수행 시간은 5ms로 실시간 동작이 가능함을 확인하였다.","This paper proposes the design and implementation results for human and object classification systems utilizingfrequency modulated continuous wave (FMCW) radar sensor. Such a system requires the process of radar sensorsignal processing for multi-target detection and the process of deep learning for the classification of human andobject. Since deep learning requires such a great amount of computation and data processing, the lightweightprocess is utmost essential. Therefore, binary neural network (BNN) structure was adopted, operating convolutionneural network (CNN) computation in a binary condition. In addition, for the real-time operation, a hardwareaccelerator was implemented and verified via FPGA platform. Based on performance evaluation and verifiedresults, it is confirmed that the accuracy for multi-target classification of 90.5%, reduced memory usage by 96.87%compared to CNN and the run time of 5ms are achieved."
오렌지 파이 하드웨어와 AI를 활용한 RGB 색상분류 모델 개발 및 성능분석,2022,"['오렌지파이', 'AI', '머신러닝', '딥러닝', '자율주행', '사회문제해결', '색상 분류', 'RGB', 'Orange Pi', 'AI', 'machine learning', 'deep learning', 'self-driving car', 'solving social problems', 'color classification', 'RGB']","본 연구에서는 주변 조명에 따라 카메라에 다르게 포착되는 R, G, B 색상을 머신러닝 및 딥러닝 라이브러리를 활용하여 분류하는 모델을 개발하고, 이를 이용해서 오렌지 파이를 통해 수집한 데이터를 분류해보는 실험을 진행하였다. 결정 트리, 랜덤 포레스트를 이용하여 분류 모델을 구현하였고, CNN 알고리즘을 활용하여 모델을 개발하여 총 3개의 모델을 완성했다. 성능 테스트 결과 각각 ROC_AUC score 99.6%, 98.6%, 99.9%의 결과를 얻었다. 이외 Accuracy, Precision, Recall, F1 score도 종합적으로 고려하였을 때, CNN algorithm, 결정 트리, 랜덤 포레스트 순으로 좋은 성능을 나타냄을 확인하였다. 추가로 가성비가 좋은 오렌지 파이를 통해 수집한 사진으로 만든 모델을 사용하여 분류하는 실험을 성공적으로 수행함으로써 적은 비용의 기기로도 충분히 AI 관련 프로젝트를 진행할 수 있음을 보였다.","In this study, we developed three models to classify R, G, B colors that are captured differently by the camera depending on the surrounding lighting using machine learning and deep learning libraries, and conducted an experiment to classify data collected by Orange Pi. Three Classification models were implemented using a decision tree, random forest, and CNN algorithm. As a result of performance evaluation using ROC_AUC score, values of 99.6%, 98.6%, 99.9% were derived respectively. Also, when considering Accuracy, Precision, Recall, and F1 score comprehensively, it was confirmed that they showed better performance in the order of CNN algorithm, Decision Tree, and Random Forest. In addition, by successfully conducting experiments on classification using photo data collected through cost-effective Orange Pi, we have shown that AI-related projects can be carried out sufficiently with low-cost devices."
A Hybrid Learning Model to Detect Morphed Images,2022,"['Deep learning', 'Hybrid learning', 'Neural network', 'Morphing', 'Simulation']",국문 초록 정보 없음,"Image morphing methods make seamless transition changes in the image and mask the meaningful information attached to it. This can be detected by traditional machine learning algorithms and new emerging deep learning algorithms. In this research work, scope of different Hybrid learning approaches having combination of Deep learning and Machine learning are being analyzed with the public dataset CASIA V1.0, CASIA V2.0 and DVMM to find the most efficient algorithm. The simulated results with CNN (Convolution Neural Network), Hybrid approach of CNN along with SVM (Support Vector Machine) and Hybrid approach of CNN along with Random Forest algorithm produced 96.92 %, 95.98 and 99.18 % accuracy respectively with the CASIA V2.0 dataset having 9555 images. The accuracy pattern of applied algorithms changes with CASIA V1.0 data and DVMM data having 1721 and 1845 set of images presenting minimal accuracy with Hybrid approach of CNN and Random Forest algorithm. It is confirmed that the choice of best algorithm to find image forgery depends on input data type. This paper presents the combination of best suited algorithm to detect image morphing with different input datasets."
Impacts of label quality on performance of steel fatigue crack recognition using deep learning-based image segmentation,2022,"['crack recognition', 'deep learning', 'image segmentation', 'label quality']",국문 초록 정보 없음,"Structural health monitoring (SHM) plays a vital role in the maintenance and operation of constructions. In recent years, autonomous inspection has received considerable attention because conventional monitoring methods are inefficient and expensive to some extent. To develop autonomous inspection, a potential approach of crack identification is needed to locate defects. Therefore, this study exploits two deep learning-based segmentation models, DeepLabv3+ and Mask R-CNN, for crack segmentation because these two segmentation models can outperform other similar models on public datasets. Additionally, impacts of label quality on model performance are explored to obtain an empirical guideline on the preparation of image datasets. The influence of image cropping and label refining are also investigated, and different strategies are applied to the dataset, resulting in six alternated datasets. By conducting experiments with these datasets, the highest mean Intersection-over-Union (mIoU), 75%, is achieved by Mask R-CNN. The rise in the percentage of annotations by image cropping improves model performance while the label refining has opposite effects on the two models. As the label refining results in fewer error annotations of cracks, this modification enhances the performance of DeepLabv3+. Instead, the performance of Mask R-CNN decreases because fragmented annotations may mistake an instance as multiple instances. To sum up, both DeepLabv3+ and Mask R-CNN are capable of crack identification, and an empirical guideline on the data preparation is presented to strengthen identification successfulness via image cropping and label refining."
볼 베어링 고장진단 기법 비교 및 XAI Grad-CAM을 이용한 분류결과 해석 연구,2022,"['Convolutional Neural Network', 'Bearing Fault', 'Fault Classification', 'XAI', 'Grad-CAM']",국문 초록 정보 없음,"Various machine learning and deep learning methods were proposed to monitor and classify the bearing's health state using vibration signals since bearing faults are one of the most causes of failure of rotationary machine. The process of diagnosing bearing faults using machine learning is as follows. First, the features, including the fault characteristic of the vibration signals, are extracted, and these features are selected to reduce the dimension of the features. These features are input into the machine learning classifier to diagnose the system's health. In addition to machine learning methods, CNN, one of the deep learning methods, is widely used.Since the deep learning model extracts features by itself, only the preprocessing process of converting the bearing signals into 2D is needed. The fault classification accuracy of two vibration signal transformation methods as preprocessing methods for the CNN model was compared. This paper compares the bearing fault classification performance of several machine learning commonly used and the CNN model for the lab-made wind turbine machinery testbed. By comparing different feature extraction, feature selection, and classification methods, the most appropriate pipeline is selected for the testbed. Also, grad-cam, an explainable AI(XAI) technique, is applied to interpret the CNN based classification in terms of interested frequency bandwidth. The XAI analysis was verified by designing preprocessing filters based on the grad-cam outputs for enhancing classification performance."
Convolutional LSTM 모델 기반의 짧은 지연 시간을 갖는 베어링 결함 진단,2022,"['Fault diagnosis', 'Neural networks', 'Embedded systems', 'Low-latency monitoring systems']",국문 초록 정보 없음,다국어 초록 정보 없음
InfoGAN을 이용한 부분 방전 데이터 생성을 통한 패턴 분류기 개선,2022,"['partial discharge', 'convolutional neural networks', 'generative adversarial networks', 'pattern classifier', '부분방전', '합성곱 신경회로망', '생성적 적대 신경회로망', '패턴 분류기']","부분방전의 인식과 분류 개선을 위한 연구는 많은 양질의 데이터를 요구한다. 그러나 부분방전의 발생이 극히 드물고, 취득이 어려운 문제로 인해 부분적으로 얻어진 실제 데이터를포함한 실험 데이터에 의해 연구가 수행되고 있다. 본 논문에서는 데이터 취득이 제한적인부분방전의 분류 개선을 위해 정보 최대화 생성적 적대 신경회로망(InfoGAN)을 적용한다.InfoGAN은 PRPS 전처리를 통해 이미지 데이터로 변환된 실제 데이터를 입력으로 데이터를생성한다. 생성된 데이터는 설계된 합성곱 신경회로망(CNN) 패턴분류기의 학습 데이터로사용된다. 실 학습데이터와 생성된 데이터를 포함한 학습데이터 양쪽을 통해 구축된 두CNN분류기가 부분방전분류의 비교해석을 위해 고려된다. InfoGAN에 의해 생성된 데이터를 통해 구축된 제안된 분류기가 부분적으로 분류기를 개선할 수 있음을 입증한다","A study to improve the recognition and classification of partial discharge requires lots of quality data. However, lots of studies are carried out by experimental data comprising partially obtained actual data due to the extremely rare occurrence of partial discharge and the problem of difficult acquisition. In this study, information maximizing generative adversarial network(InfoGAN) is applied to improve the classification of partial discharge with limited data acquisition. InfoGAN is exploited to generate fake data by using actual inputs transformed to image data through PRPS preprocessing. The generated data (fake data) is used as training data for constucting the convolutional neural network(CNN) pattern classifier. The two CNN classifiers constrcuted with the help of both actual training(existing) data and actual training data including fake data(generated data) are considered for the comparison analysis of partial discharge classification. The experimental results demonstrate that the proposed calssifier constructed through data generated by InfoGAN could partially improve the exising classifier"
One-step deep learning-based method for pixel-level detection of fine cracks in steel girder images,2022,"['CNN', 'crack detection', 'data imbalance', 'feature extraction', 'loss function']",국문 초록 정보 없음,"Identifying fine cracks in steel bridge facilities is a challenging task of structural health monitoring (SHM). This study proposed an end-to-end crack image segmentation framework based on a one-step Convolutional Neural Network (CNN) for pixel-level object recognition with high accuracy. To particularly address the challenges arising from small object detection in complex background, efforts were made in loss function selection aiming at sample imbalance and module modification in order to improve the generalization ability on complicated images. Specifically, loss functions were compared among alternatives including the Binary Cross Entropy (BCE), Focal, Tversky and Dice loss, with the last three specialized for biased sample distribution. Structural modifications with dilated convolution, Spatial Pyramid Pooling (SPP) and Feature Pyramid Network (FPN) were also performed to form a new backbone termed CrackDet. Models of various loss functions and feature extraction modules were trained on crack images and tested on full-scale images collected on steel box girders. The CNN model incorporated the classic U-Net as its backbone, and Dice loss as its loss function achieved the highest mean Intersection-over-Union (mIoU) of 0.7571 on full-scale pictures. In contrast, the best performance on cropped crack images was achieved by integrating CrackDet with Dice loss at a mIoU of 0.7670."
TsCNNs-Based Inappropriate Image and Video Detection System for a Social Network,2022,"['CNN', 'Intelligent Image and Video Detection System', 'Tree-Structured Convolutional Neural Networks (TsCNNs)']",국문 초록 정보 없음,"We propose a detection algorithm based on tree-structured convolutional neural networks (TsCNNs) that findspornography, propaganda, or other inappropriate content on a social media network. The algorithm sequentiallyapplies the typical convolutional neural network (CNN) algorithm in a tree-like structure to minimizeclassification errors in similar classes, and thus improves accuracy. We implemented the detection system andconducted experiments on a data set comprised of 6 ordinary classes and 11 inappropriate classes collected fromthe Korean military social network. Each model of the proposed algorithm was trained, and the performancewas then evaluated according to the images and videos identified. Experimental results with 20,005 new imagesshowed that the overall accuracy in image identification achieved a high-performance level of 99.51%, and theeffectiveness of the algorithm reduced identification errors by the typical CNN algorithm by 64.87 %. Byreducing false alarms in video identification from the domain, the TsCNNs achieved optimal performance of98.11% when using 10 minutes frame-sampling intervals. This indicates that classification through propersampling contributes to the reduction of computational burden and false alarms."
Segmentation 기반 샤인머스캣의 포도알 검출 및 충실도 예측 알고리즘 개발,2022,"['Mask R-CNN', 'Object detection', 'Shine Muscat', 'Density of Grape Clusters', 'DGC']","포도는 인체의 탄수화물 대사를 촉진시키며 피로를 풀어주는 등 인체에 유익한 알칼리성 식품으로 알려지며 재배와 소비량이 꾸준히 증가하고 있다. 이 중 샤인머스캣은 포도의 다양한 종류 중 하나로, 일반 포도의 쓴 맛이 덜하고 산도가 낮으며 아삭아삭한 식감을 가지고 있어 특히 관심이 높아지고 있다. 이러한 샤인머스캣 품종의 소비가 급격하게 증가함에 따라 노동력과 시간을 절약하기 위한 자동화 공정 시스템을 구축하는 것이 필수인데, 특히 전문가의 육안으로만 포도의 등급을 판단하는 것은 아직도 해결해야 하는 과제 중 하나이다.본 연구에서는 포도의 종류 중 하나인 샤인머스캣을 대상 과실로 지정하였으며, RGB 영상장치를 이용하여 수확 후의 샤인머스캣을 다양한 조도 조건하에 촬영하여 영상을 획득하였다. 단일 포도송이에서 포도 열매를 검출하는 알고리즘을 채택하였으며 합성곱 신경망 네트워크 기반의 영상 분할 기법인 Mask R-CNN을 다양한 backbone과 함께 적용하여 각 모델의 성능을 비교 평가하였다. 그 결과, Mask R-CNN ResNet 101이 모든 모델 중 검출 정확도 AP(Average Precison)값이 가장 높은 것으로 분석되었으며, 해당 네트워크로 샤인머스캣의 포도알 직경, 면적, 빈 공간의 면적 등을 구하여 포도알이 얼마나 밀집되어 있는지를 나타내는 지표인 Density of Grape Clusters (DGC)를 구하였다. 본 연구에서 정의한 이러한 지표들을 통해 샤인머스캣의 수확 후 품질 판단을 보다 정확하고, 신속하게 체계화할 수 있다.",다국어 초록 정보 없음
Segmentation 기반 샤인머스캣의 포도알 검출 및 충실도 예측 알고리즘 개발,2022,"['Mask R-CNN', 'Object detection', 'Shine Muscat', 'Density of Grape Clusters', 'DGC']","포도는 인체의 탄수화물 대사를 촉진시키며 피로를 풀어주는 등 인체에 유익한 알칼리성 식품으로 알려지며 재배와 소비량이 꾸준히 증가하고 있다. 이 중 샤인머스캣은 포도의 다양한 종류 중 하나로, 일반 포도의 쓴 맛이 덜하고 산도가 낮으며 아삭아삭한 식감을 가지고 있어 특히 관심이 높아지고 있다. 이러한 샤인머스캣 품종의 소비가 급격하게 증가함에 따라 노동력과 시간을 절약하기 위한 자동화 공정 시스템을 구축하는 것이 필수인데, 특히 전문가의 육안으로만 포도의 등급을 판단하는 것은 아직도 해결해야 하는 과제 중 하나이다.본 연구에서는 포도의 종류 중 하나인 샤인머스캣을 대상 과실로 지정하였으며, RGB 영상장치를 이용하여 수확 후의 샤인머스캣을 다양한 조도 조건하에 촬영하여 영상을 획득하였다. 단일 포도송이에서 포도 열매를 검출하는 알고리즘을 채택하였으며 합성곱 신경망 네트워크 기반의 영상 분할 기법인 Mask R-CNN을 다양한 backbone과 함께 적용하여 각 모델의 성능을 비교 평가하였다. 그 결과, Mask R-CNN ResNet 101이 모든 모델 중 검출 정확도 AP(Average Precison)값이 가장 높은 것으로 분석되었으며, 해당 네트워크로 샤인머스캣의 포도알 직경, 면적, 빈 공간의 면적 등을 구하여 포도알이 얼마나 밀집되어 있는지를 나타내는 지표인 Density of Grape Clusters (DGC)를 구하였다. 본 연구에서 정의한 이러한 지표들을 통해 샤인머스캣의 수확 후 품질 판단을 보다 정확하고, 신속하게 체계화할 수 있다.",다국어 초록 정보 없음
Capacity estimation of lithium‑ion batteries using convolutional neural network and impedance spectra,2022,"['Convolutional neural network (CNN)', 'Electrochemical impedance spectroscopy (EIS)', 'State of health (SoH)', 'Capacity']",국문 초록 정보 없음,"Battery capacity is a parameter that has a very close association with the state of health (SoH) of a Li-ion battery. Due to the complex electrochemical mechanisms behind the degradation of battery life, the estimation of SoH encounters many difficulties. To date, experiment-based methods, model-based methods, and data-driven models have been developed to estimate capacity using data from charging curves. In the case of EVs and HEVs, due to the unpredictable charge patterns employed by users, it is not known how much charging data will be available to predict the capacity at a given point in time. This paper presents a method to accurately estimate capacity using impedance curves obtained from an electrochemical impedance spectroscopy (EIS) test and a convolutional neural network (CNN). The CNN model was trained using the impedance data of a single cell collected at different SoH values, and the trained model was verified using the impedance data of eight other cells. The maximum error in the prediction was found to be 0.57 (% capacity) and the RMS error was found to be 0.233 (% capacity). These results illustrate the accuracy and robustness of the proposed model."
인체 치수 데이터와 K-means 군집 알고리즘을 활용한 체지방 분류 모델,2022,"['Classification', 'Human body size', 'CNN(Convolutional Neural Network)', 'Fat rate percentage', 'K-means clustering']","최근 헬스케어(healthcare) 분야에서 기계학습을 적용한 다양한 연구가 증가하고 있다. 스마트 워치와 같은 웨어러블(wearable) 장치를 통해 심전도 검사, 체성분 분석 등의 기능을 제공하고 있으며 이러한 기능에 딥러닝 기술이 적용되고 있다. 이를 통해 합리적인 의사 결정과 표준화된 프로세스를 도출하여 개인에 맞는 헬스케어 서비스 구축과 연구에 활용되고 있다. 기존에 있는 진료 기록이나 의료보험 정보뿐만 아니라 정부에서 공개하고 있는 공공데이터, 소셜 미디어 데이터, 유전자 데이터 등 다양한 경로로 수집된 데이터를 활용하고 있다. 이 데이터를 모델에 적용하기 위해서는 데이터를 분류하는 작업 등 사람의 개입이 필요하다. 본 논문에서는 가슴둘레나 허리둘레 등 인체 치수를 입력으로 받아 성별과 나이에 따른 군집 별로 평균 체지방률을 분류하는 모델을 제안한다. 데이터는 국가기술표준원에서 제공하고 있는 인체치수데이터를 활용하였고 이 데이터는 분류 모델에 적용하기 어려운 데이터이므로 군집 알고리즘을 적용한 데이터로 변환하였다. 군집화가 완료된 데이터를 이용하여 CNN(Convolutional Neural Network) 모델에 적용하여 분류를 진행한다. 이를 통해 개인 맞춤형 체형관리 서비스나 비만 분석 등 다양한 응용 사례에 활용될 수 있을 것으로 사료된다.","Recently, various cases of applying machine learning in the healthcare field are increasing. Functions such as electrocardiogram and body composition analysis are provided through wearable devices such as smart watches, and deep learning technology is applied to these functions. Through this, rational decision-making and standardized processes are derived, which is being used in research and construction of healthcare services tailored to individuals. In addition to existing medical records and medical insurance information, data collected through various channels such as public data, social media data, and genetic data disclosed by the government are being utilized. In order to apply this data to the model, human intervention is required, such as classifying to data. In this paper, we propose a model that classifying the average body fat percentage by group according to gender and age by receiving human body size data such as chest circumference and waist circumference as input. For the data, the human body size data provided by National Institute of Technology and Standards was used, and since this data is difficult to apply to the classification model, it was converted into data to which a clustering algorithm was applied. Classification is performed by applying to a CNN(Convolutional Neural Network) model. Through this, it is thought that it can be utilized in various application cases such as personalized body shape management service and obesity analysis."
Fourier Ptychographic Microscopy 영상에서의 딥러닝 기반 디지털 염색 방법 연구,2022,"['딥러닝', 'GAN', 'MASK R-CNN', 'H&E 염색', 'FPM', 'Deep learning', 'GAN', 'MASK R-CNN', 'H&E stain', 'FPM']","본 연구에서 세포를 분별하기 위해 H&E 염색이 필요하다. 직접 염색하는 많은 비용과 시간이 필요하다. H&E 염색되지 않은 세포의 Phase image에서 H&E 염색이 된 세포의 Amplitude image로 변환하는 것이 목적이다. FPM으로 촬영한 Image data를 가지고 Matlab을 이용해 매개변수를 변경해 Phase image와 Amplitude image를 만들었다. 정규화를 통해 육안으로 식별이 가능한 이미지를 얻었다. GAN 알고리즘을 이용해 Phase image를 기반으로 Real Amplitude image와 비슷한 Fake Amplitude image를 만들고 Fake Amplitude image를 가지고 MASK R-CNN을 이용하여 세포를 분별하여 객체화를 통해 구분했다. 연구 결과 D loss의 max는 3.3e-1, min은 6.8e-2, G loss max는 6.9e-2, min은 2.9e-2, A loss는 max 5.8e-1, min는 1.2e-1, mask rcnn max는 1.9e0, min은 3.2e-1이다.",다국어 초록 정보 없음
Emotion Recognition using Short-Term Multi-Physiological Signals,2022,"['Convolutional Neural Network (CNN)', 'Emotion Recognition', 'Physiological Signal']",국문 초록 정보 없음,"Technology for emotion recognition is an essential part of human personality analysis. To define human personality characteristics, the existing method used the survey method. However, there are many cases where communication cannot make without considering emotions. Hence, emotional recognition technology is an essential element for communication but has also been adopted in many other fields.A person's emotions are revealed in various ways, typically including facial, speech, and biometric responses. Therefore, various methods can recognize emotions, e.g., images, voice signals, and physiological signals. Physiological signals are measured with biological sensors and analyzed to identify emotions. This study employed two sensor types. First, the existing method, the binary arousal-valence method, was subdivided into four levels to classify emotions in more detail. Then, based on the current techniques classified as High/Low, the model was further subdivided into multi-levels. Finally, signal characteristics were extracted using a 1-D Convolution Neural Network (CNN) and classified sixteen feelings. Although CNN was used to learn images in 2D, sensor data in 1D was used as the input in this paper. Finally, the proposed emotional recognition system was evaluated by measuring actual sensors."
가상 데이터 증식을 이용한 Pix2pix 기반의 물방울 제거 학습,2022,"['deep learning', 'GAN', 'CNN', 'Pix2pix', 'augmentation learning', 'rainwater removal', '.']","본 논문은 딥러닝 기법을 활용하여 영상에서 카메라 렌즈 상에 물방울이 맺힌 부분을 효율적으로 제거하는 영상 변환 방법을 제안한다. 제안 방법에서 다른 도메인의 영상을 새롭게 형성한다는 점에 있어 두 영상의 특징을 잘 파악할 수 있는 GAN(Pix2pix Generative Adversarial Network) 모델을 통해 효과적으로 물방울이 제거된 영상을 얻는 방법을 제안한다. 또한, 촬영 영상을 기반으로 하는 학습 방법에 있어 많은 학습용 데이터가 필요하다는 점과 모델 학습 특성상 불필요한 노이즈가 발생하거나 물방울 사진을 정확하게 얻지 못하는 경우가 발생될 수 있는데, 가상의 물방울 영상 데이터를 생성하고 CNN(Convolution Neural Network)을 이용하여 효과적으로 식별함으로써 학습 데이터를 효율적으로 확보하는 방법을 제안한다.","In this paper, we propose a system that efficiently removes pictures with water droplets on the camera lens using deep learning techniques. We propose a method to effectively obtain a water droplet removal image through the Pix2pix Generative Adversarial Networks(GAN) model, which can understand the characteristics of the two images in terms of newly forming images of different domains. In addition, by applying the fake water droplet data formed by applying the fake water droplet data to the Convolution Neural Network(CNN), paying attention to the fact that a lot of training data is required for image learning, as well as unnecessary noise or water droplet pictures cannot be obtained accurately due to the nature of model learning. We propose a method to efficiently secure data by effectively classifying the formed photos."
Identification of Defects in Casting Products by using a Convolutional Neural Network,2022,"['Casting quality inspection', 'CNN', 'Industry 4.0', 'Machine learning']",국문 초록 정보 없음,"The main perspective when ensuring dependability in speculations over accuracy in casting parts is a project quality confirmation process that is both careful and meticulous under Industry 4.0. When thorough and extensive casting project examination strategies merge with expanded metal project quality standards, casting production, augmented visual inspections, ensemble process modification and execution are improved. In this paper, we use publicly available casting image datasets for visual inspection, which classify defective and non-defective casting. Inspired by the convolutional neural network (CNN), we propose two-stage convolution for modeling, with DenseNet for classifying casting products. Through experimentation, we achieved an F1-score of 99.54% with a processing time of 454ms using a CPU for classification of casting product inspections. The modified modeling of the CNN in this work helps to improve optimization, compared to other basic machine learning mechanisms that measure quality."
Comparison of Deep Learning-Based Object Classification Methods for Detecting Tomato Ripeness,2022,"['SSD', 'Faster R-CNN', 'YOLO', 'Object detection']",국문 초록 정보 없음,"Examination of the technological development in agriculture reveals that not many applicationsuse cameras to detect tomato ripeness; therefore, tomato maturity is still determined manually.Currently, technological advances and developments are occurring rapidly, and are, therefore,also inseparable from the agricultural sector. Object detection can help determining tomatoripeness. In this research, faster region-based convolutional neural network (Faster R-CNN),single shot multibox detector (SSD), and you only look once (YOLO) models were tested torecognize or detect tomato ripeness using input images. The model training process required 5hours and produced a total loss value <0.5, and as the total loss became smaller, the predictedresults improved. Tests were conducted on a training dataset, and average accuracy values of99.55%, 89.3%, and 94.6% were achieved using the Faster R-CNN, SSD, and YOLO models,respectively"
합성곱 신경망을 이용한 정사사진 기반 균열 탐지 기법,2022,"['Ortho-image', 'UAV', 'Machine learning', 'Crack detection', 'CNN']",국문 초록 정보 없음,"Visual inspection methods have limitations, such as reflecting the subjective opinions of workers. Moreover, additional equipment is required when inspecting the high-rise buildings because the height is limited during the inspection. Various methods have been studied to detect concrete cracks due to the disadvantage of existing visual inspection. In this study, a crack detection technology was proposed, and the technology was objectively and accurately through AI. In this study, an efficient method was proposed that automatically detects concrete cracks by using a Convolutional Neural Network(CNN) with the Orthomosaic image, modeled with the help of UAV. The concrete cracks were predicted by three different CNN models: AlexNet, ResNet50, and ResNeXt. The models were verified by accuracy, recall, and F1 Score. The ResNeXt model had the high performance among the three models. Also, this study confirmed the reliability of the model designed by applying it to the experiment."
딥러닝 기반 토마토 잎 병충해 분류 및 시각화를 위한 연구,2022,"['Tomato Pest', 'Deep Learning', 'EfficientNet', 'Grad-CAM', 'CNN', '토마토 병충해', '딥러닝', 'EfficientNet', 'Grad-CAM', 'CNN']","농작물에 피해를 주는 요인은 크게 자연재해와 병충해가 존재하며 병충해는 자연재해보다발생 빈도가 높고 전염이 쉽다. 따라서 병충해가 발생하지 않도록 방제해야 하고, 발생 초기에 바로 진압하는 것이 필요하다. 본 연구에서는 딥러닝 모델을 이용하여 토마토잎의 대표적인 병충해를 분류하고, Grad-CAM 기술을 이용하여 딥러닝 모델이 이미지의 어느 부분을보고 판단하였는지 시각화하여 사용자에게 분류에 대한 근거를 제시하도록 하였다. 또한, 이를 통해 토마토 잎 사진을 이용한 병충해 유무 및 종류를 알려주고 판단의 근거를 시각화해주는 기술을 적용한 웹 애플리케이션을 개발하였다. 본 연구에서는 적은 수의 학습데이터를이용한 효율적인 분류를 위해 다양한 딥러닝 분류 모델 및 학습 방법에 대한 비교 및 분석을 수행하였다. 실험 결과 최신 CNN 모델인 EfficientNetB0 모델로 테스트 분류 정확도99.16%와 0.032초의 추론속도 성능을 보였다","Factors that damage crops are largely natural disasters and pests, and pests occur more frequently than natural disasters and are easily contagious. Therefore, it is necessary to control the disease so that it does not occur, and it is necessary to suppress it immediately at the beginning of the outbreak. In this study, a representative pest of tomato leaf is classified using a deep learning model, and the basis for classification is presented to the user by visualizing which part of the image the deep learning model focuses on and judging using Grad-CAM. In addition, a web application applied with a technology that informs the presence and type of pests using a photo of tomato leaves and visualizes the basis for judgment is developed. In this study, comparison and analysis are performed on various deep learning classification models and training methods for efficient classification using a small number of training data. As a results, the EfficientNetB0 model shows a 99.16% test classification accuracy with 0.032sec inference speed."
Learning-based Framework for Color Conversion between Digital Cinema Package and Streaming Movie,2022,"['Digital cinema', 'DCP', 'DCI-P3', 'Color gamut', 'CNN']",국문 초록 정보 없음,"Humans feel different experiences when viewing a cinema at the theater and home. This paper presents methods to reduce the difference in the viewing experience. Based on the workflow of digital cinema distribution, the proposed method attempts to minimize the color difference between digital cinema packages (DCP) for the theater and streaming movies. For end-to-end mapping between the DCP and streaming movie, this paper proposes a convolutional neural network (CNN)-based color conversion algorithm based on the SMPTE standard. The proposed method consists of three steps: i) color conversion using standard matrices, ii) color conversion using the CNN, and iii) color saturation error removal by fusing the results in steps i) and ii). The proposed method enhances the color of TV streaming images because it minimizes the color difference from the DCP and appropriately extends the color gamut. As a result, the proposed method can provide consumers with indistinguishable quality from a DCP movie at the theater."
혼재된 환경에서의 효율적 로봇 파지를 위한 3차원 물체 인식 알고리즘 개발,2022,"['3D Object Recognition', 'Cluttered Environment', 'YOLO', 'Mask R-CNN']",국문 초록 정보 없음,"3D object detection pipelines often incorporate RGB-based object detection methods such as YOLO, which detects the object classes and bounding boxes from the RGB image. However, in complex environments where objects are heavily cluttered, bounding box approaches may show degraded performance due to the overlapping bounding boxes. Mask based methods such as Mask R-CNN can handle such situation better thanks to their detailed object masks, but they require much longer time for data preparation compared to bounding box-based approaches. In this paper, we present a 3D object recognition pipeline which uses either the YOLO or Mask R-CNN real-time object detection algorithm, K-nearest clustering algorithm, mask reduction algorithm and finally Principal Component Analysis (PCA) alg orithm to efficiently detect 3D poses of objects in a complex environment. Furthermore, we also present an improved YOLO based 3D object detection algorithm that uses a prioritized heightmap clustering algorithm to handle overlapping bounding boxes. The suggested algorithms have successfully been used at the Artificial-Intelligence Robot Challenge (ARC) 2021 competition with excellent results."
ResNet 기반 작물 생육단계 추정 모델 개발,2022,"['딥러닝', '컴퓨터 비전', 'Convolution Neural Network', '작물 생육단계', 'Deep Learing', 'Computer Vision', 'CNN', 'Crop Growth Stage']","산업화 이후 가속화된 지구 온난화 현상으로 인해 기존환경 변화 및 이상기후 발생 빈도가 증가하고 있다. 농업은 기후변화에 매우 민감한 분야의 산업으로 지구 온난화는 작물의 생산량을 감소시키고 재배 지역이 변하는 등의 문제를 발생시킨다. 또한, 환경 변화는 작물의 생육 시기를 불규칙하게 만들어 숙련된 농사꾼들도 작물의 생육단계를 쉽게 추정할 수 없도록 만들어 여러 문제를 발생시킨다. 이에 본 논문에서는 작물의 생육단계를 추정하기 위한 CNN(Convolution Neural Network) 모델을 제안한다. 제안한 모델은 ResNet의 Pooling Layer를 수정한 모델로 ResNet, DenseNet 모델의 생육단계 추정보다 높은 성능 결과를 확인하였다.","Due to the accelerated global warming phenomenon after industrialization, the frequency of changes in the existing environment and abnormal climate is increasing. Agriculture is an industry that is very sensitive to climate change, and global warming causes problems such as reducing crop yields and changing growing regions. In addition, environmental changes make the growth period of crops irregular, making it difficult for even experienced farmers to easily estimate the growth stage of crops, thereby causing various problems. Therefore, in this paper, we propose a CNN model for estimating the growth stage of crops. The proposed model was a model that modified the pooling layer of ResNet, and confirmed the accuracy of higher performance than the growth stage estimation of the ResNet and DenseNet models."
딥러닝 基盤의 諺簡 資料 文字 判讀機 具現에 對한 硏究 –<秋史 諺簡>을 對象으로–,2022,"['Korean letters', 'Chusa’s Korean letters', 'Deep-learning', 'CNN', 'GAN', 'Data augmentation', 'Character decipherer', 'Computer vision', '諺簡', '秋史 諺簡', '딥러닝', 'CNN', 'GAN', '데이터 증강', '문자 판독', '문자 판독기']","본 연구의 목적은 딥러닝(Deep-learning) 기술을 이용해 諺簡 資料에 대한 문자 判讀機를 구현해 보는 것에 있다. 구체적으로는 컴퓨터에게 ‘字體’의 특징을 학습시키는 방식을 이용하였다. 다만, 모든 자료에 대해 적용하기에는 시간과 인력의 제약이 있으므로, <秋史 諺簡> 일부만을 데이터베이스화하여 실현 가능성과 효용을 입증해 보았다.判讀機 구현을 위해 딥러닝에서 이미지 인식에 주로 사용되는 Convolutional Neural Network(CNN) 기술을 이용하였으며, 부족한 데이터를 충당하기 위해 몇 가지 데이터 생성과 증강 기법을 이용하였다. 만들어진 모델은 test 데이터에 대해 top1-88.72%, top5-97.63%의 인식률을 보였다. 이를 토대로 개별 문자 이미지를 입력하면 가장 높은 확률을 보이는 값을 출력해 주는 判讀機를 구현하였다.이렇게 만들어진 判讀機의 활용 방법을 예시하고 효용을 검증하기 위해 <秋史 諺簡> 11에 적용해 보았다. 이 과정에서 해당 문자가 무엇인지 적절하게 맞추는 모습을 볼 수 있었으며, 이외에 가능한 판독안의 목록도 제시해 주는 모습을 볼 수 있었다. 본 判讀機는 字體를 고려해 명시적인 확률값을 계산해 줄 수 있기 때문에 판독에 있어 객관적인 증거로 활용될 수 있을 것으로 보인다.",다국어 초록 정보 없음
Estimation of Automatic Video Captioning in Real Applications using Machine Learning Techniques and Convolutional Neural Network,2022,"['Online videos', 'hearing impaired', 'machine learning', 'feature extraction', 'GLCM', 'Hu moments', 'CNN architecture']",국문 초록 정보 없음,"The prompt development in the field of video is the outbreak of online services which replaces the television media within a shorter period in gaining popularity. The online videos are encouraged more in use due to the captions displayed along with the scenes for better understandability. Not only entertainment media but other marketing companies and organizations are utilizing videos along with captions for their product promotions. The need for captions is enabled for its usage in many ways for hearing impaired and non-native people. Research is continued in an automatic display of the appropriate messages for the videos uploaded in shows, movies, educational videos, online classes, websites, etc. This paper focuses on two concerns namely the first part dealing with the machine learning method for preprocessing the videos into frames and resizing, the resized frames are classified into multiple actions after feature extraction. For the feature extraction statistical method, GLCM and Hu moments are used. The second part deals with the deep learning method where the CNN architecture is used to acquire the results. Finally both the results are compared to find the best accuracy where CNN proves to give top accuracy of 96.10% in classification."
표정 분류에 기반한 감정 인식을 위한 열화상 데이터베이스의 유용성 평가,2022,"['thermal face image', 'facial expression classification', 'emotion recognition', 'CNN architecture', 'database performance']",국문 초록 정보 없음,"Facial expression is an important part of human communication and is an element that helps to understand other people’s intentions. Recently, as a complementary solution in the field of emotion recognition, interest in thermal imaging is increasing as an alternative means to compensate for the shortcomings of visible light imaging. In this paper, thermal image data was acquired by itself and a database was established in which only facial areas necessary for emotional recognition were extracted separately. Verification accuracy and learning time were analyzed using the existing CNN architecture to confirm whether the built database can be used to classify facial expressions for emotion recognition. As a result of analysis through CNN network, ResNet-18 showed a verification accuracy of up to 81.28%, and on average, it showed a verification accuracy of 68.13%. Through this, it was confirmed that the self-built thermal imaging database is useful for emotional recognition research."
자유 앵커 방식과 합성곱 신경망을 이용한 강인한 실시간 번호판 인식 시스템,2022,"['License Plate Recognition', 'Real-Time', 'Anchor-Free Method', 'CNN', 'Deep Learning', '번호판 인식', '실시간', '자유 앵커 방식', '딥러닝']","최근 지능형 교통 체계의 발전에 따라 자동차 번호판 인식 시스템이 다양한 분야에서 활용되고 있다. 주행 중인 자동차의 번호판을 인식하기 위해서는 실시간성이 보장되어야 하며, 영상이 왜곡되어 뚜렷하지 않거나 번호판의 크기가 작은 저해상도 영상에서도 높은 인식률이 유지되어야 한다. 본 논문에서는 자유 앵커 방식 기반의 객체 탐지 알고리즘과 합성곱 신경망(CNN) 기반의 문자 인식 알고리즘을 이용하여 처리 속도를 향상한 실시간 자동차 번호판 인식 시스템을 제안한다. 더불어 공간 변형 네트워크를 이용하여 저해상도 및 왜곡된 영상에서의 인식률을 높였다. 제안하는 시스템의 인식률은 93.769%, 이미지 당 처리 속도는 약 0.006초로 기존 자동차 번호판 인식 시스템보다 빠른 속도로 자동차 번호판을 인식하며, 다양한 환경 및 품질의 영상에 대해 높은 인식률을 유지하는 것을 확인할 수 있다.","With the recent development of intelligent transportation systems, car license plate recognition systems are being used in various fields. Such systems need to guarantee real-time performance to recognize the license plate of a driving car. Also, they should keep a high recognition rate even in problematic situations such as small license plates in low-resolution and unclear image due to distortion. In this paper, we propose a real-time car license plate recognition system that improved processing speed using object detection algorithm based on anchor-free method and text recognition algorithm based on Convolutional Neural Network(CNN). In addition, we used Spatial Transformer Network to increase the recognition rate on the low resolution or distorted images. We confirm that the proposed system is faster than previously existing car license plate recognition systems and maintains a high recognition rate in a variety of environment and quality images because the proposed system’s recognition rate is 93.769% and the processing speed per image is about 0.006 seconds."
"인공지능 딥러닝의 역사와 현황, 그리고 미래 방향",2022,"['Artificial Intelligence (AI)', 'Deep learning', 'Artificial Neural Networks (ANN)', 'Convolutional Neural Network (CNN)', 'Explainable AI (XAI)']",국문 초록 정보 없음,"Deep learning is a subset of machine learning, and machine learning is also a subset of artificial intelligence (AI). The biggest difference between machine learning and deep learning is that in the learning of artificial intelligence models, machine learning basically requires a human feature extraction process before learning, but deep learning does not require this process and the original data is directly used as input. The development of deep learning coincides with the development of artificial neural networks (ANNs), and many people have contributed to the development of artificial neural networks for decades. The following five models are the representative architectures most widely used in deep learning. That is, Deep Feedforward Neural Network (DFFNN), Convolutional Neural Network (CNN), Deep Belief Network (DBN), Autoencoders (AE), and Long Short-Term Memory (LSTM) Network. A convolutional neural network (CNN) is a feedforward NN composed of a convolutional layer, a ReLU activation function, and a pooling layer. CNNs provide properties of weight sharing and local connectivity to process high-dimensional data. In dental and medical fields, an AI model that can be interpretable or explainable (XAI) is needed to increase patient persuasiveness. In the future, explainable AI (XAI) will become an indispensable and practical component in order to obtain an improved, transparent, secure, fair and unbiased AI learning model."
Classification of Harmful content on YouTube based on Deep Learning,2022,"['Content classification', 'convolutional neural network', 'long short-term memory']",국문 초록 정보 없음,다국어 초록 정보 없음
통계 및 이미지 데이터를 활용한 가짜 SNS 계정 식별 기술,2022,"['기계 학습', '딥러닝', '합성곱 신경망', '소셜 네트워크 서비스', '가짜 계정', 'machine learning', 'deep learning', 'convolutional neural network(CNN)', 'social network service', 'fake accounts']","인터넷 기술이 발전함에 따라 SNS 사용자가 늘어나고 있다. SNS의 대중화가 진행되면서 소셜 네트워크의 영향력과 익명성을 활용한 SNS형 범죄가 나날이 증가하고 있는 추세이다. 본 논문에서는 인스타그램에서 SNS형 범죄에 주로 이용되는 가짜 계정 분류를 위해 통계 데이터와 이미지 데이터를 이용하여 각각 기계학습 및 딥러닝(deep learning) 기법을 활용한 가짜 계정 분류 방법을 제안한다. 모델 학습에 사용된 SNS 계정 데이터는 자체적으로 수집하였으며, 수집된 데이터는 통계 데이터 및 이미지 데이터에 기반한다. 통계 데이터의 경우에는 기계학습 및 다층 퍼셉트론 기반으로 학습을 진행하였고, 이미지 데이터의 경우에는 합성곱 신경망(Convolutional Neural Network, CNN) 기반으로 학습을 진행하였다. 학습을 진행한 결과 계정 분류에 대하여 정확도가 전반적으로 높게 나온 것을 확인하였다.","As Internet technology develops, SNS users are increasing. As SNS becomes popular, SNS-type crimes using the influence and anonymity of social networks are increasing day by day. In this paper, we propose a fake account classification method that applies machine learning and deep learning to statistical and image data for fake accounts classification. SNS account data used for training was collected by itself, and the collected data is based on statistical data and image data. In the case of statistical data, machine learning and multi-layer perceptron were employed to train. Furthermore in the case of image data, a convolutional neural network (CNN) was utilized. Accordingly, it was confirmed that the overall performance of account classification was significantly meaningful."
Accuracy of artificial intelligence-assisted landmark identification in serial lateral cephalograms of Class III patients who underwent orthodontic treatment and two-jaw orthognathic surgery,2022,"['Convolutional neural network', 'Landmark identification', 'Two-jaw orthognathic surgery', 'Serial lateral encephalogram']",국문 초록 정보 없음,"Objective: To investigate the pattern of accuracy change in artificial intelligence-assisted landmark identification (LI) using a convolutional neural network (CNN) algorithm in serial lateral cephalograms (Lat-cephs) of Class III (C-III) patients who underwent twojaw orthognathic surgery. Methods: A total of 3,188 Lat-cephs of C-III patients were allocated into the training and validation sets (3,004 Lat-cephs of 751 patients) and test set (184 Lat-cephs of 46 patients; subdivided into the genioplasty and non-genioplasty groups, n = 23 per group) for LI. Each C-III patient in the test set had four Lat-cephs: initial (T0), pre-surgery (T1, presence of orthodontic brackets [OBs]), post-surgery (T2, presence of OBs and surgical plates and screws [S-PS]), and debonding (T3, presence of S-PS and fixed retainers [FR]). After mean errors of 20 landmarks between human gold standard and the CNN model were calculated, statistical analysis was performed. Results: The total mean error was 1.17 mm without significant difference among the four timepoints (T0, 1.20 mm; T1, 1.14 mm; T2, 1.18 mm; T3, 1.15 mm). In comparison of two time-points ([T0, T1] vs. [T2, T3]), ANS, A point, and B point showed an increase in error (p < 0.01, 0.05, 0.01, respectively), while Mx6D and Md6D showeda decrease in error (all p < 0.01). No difference in errors existed at B point, Pogonion, Menton, Md1C, and Md1R between the genioplasty and non-genioplasty groups. Conclusions: The CNN model can be used for LI in serial Lat-cephs despite the presence of OB, S-PS, FR, genioplasty, and bone remodeling."
객체 탐지를 위한 객체 복사 기반의 적대적 생성 신경망 활용 이미지 데이터 증강 기법,2022,"['합성곱 신경망', '적대적 생성 신경망', '이미지 데이터 증강', '객체 탐지', 'convolution neural network (CNN)', 'generative adversarial network (GAN)', 'image data augmentation', 'object detection']","컴퓨터 비전 분야에서는 양질의 이미지 데이터가 합성곱 신경망(CNN) 모델의 성능에 중요한 영향을 미친다. 하지만 실제 도메인에서는 충분한 양질의 데이터를 구하는 것이 어렵기 때문에 이미지 데이터의 증강 기법에 대한 연구가 계속해서 이루어지고 있다. 본 논문에서는 기존에 연구되던 적대적 생성 신경망(GAN)과 객체 복사(Copy-Paste) 기반의 증강 기법을 결합하여 더 다양한 이미지 데이터를 생성할 수 있는 이미지 데이터 증강 기법을 제안한다. 경계 상자(bounding box)가 아닌 객체 경계를 잘라내고, 적대적 생성 신경망을 사용하여 객체를 변형함으로써 기존의 픽셀 단위, 이미지 단위에서 벗어난 객체 단위의 이미지 데이터 증강을 보인다.","In the field of computer vision, massive well-annotated image data are essential to achieve good performance of a convolutional neural network (CNN) model. However, in real world applications, gathering massive well-annotated data is a difficult and time-consuming job. Thus, image data augmentation has been continually studied. In this paper, we proposed an image data augmentation method that could generate more diverse image data by combining generative adversarial network (GAN) and copy-paste based augmentation. The proposed method generated not pixel-level or image-level augmentation, but object-level augmentation by cutting off segmentation boundaries(mask) instead of bounding boxes. It then applyied GAN to transform objects."
Accuracy of one-step automated orthodontic diagnosis model using a convolutional neural network and lateral cephalogram images with different qualities obtained from nationwide multi-hospitals,2022,"['One-step automated orthodontic diagnosis', 'Convolutional neural networks', 'Lateral cephalogram', 'Multi-center study']",국문 초록 정보 없음,"Objective: The purpose of this study was to investigate the accuracy of one-step automated orthodontic diagnosis of skeletodental discrepancies using a convolutional neural network (CNN) and lateral cephalogram images with different qualities from nationwide multi-hospitals. Methods: Among 2,174 lateral cephalograms, 1,993 cephalograms from two hospitals were used for training and internal test sets and 181 cephalograms from eight other hospitals were used for an external test set. They were divided into three classification groups according to anteroposterior skeletal discrepancies (Class I, II, and III), vertical skeletal discrepancies (normodivergent, hypodivergent, and hyperdivergent patterns), and vertical dental discrepancies (normal overbite, deep bite, and open bite) as a gold standard. Pre-trained DenseNet-169 was used as a CNN classifier model. Diagnostic performance was evaluated by receiver operating characteristic (ROC) analysis, t-stochastic neighbor embedding (t-SNE), and gradientweighted class activation mapping (Grad-CAM). Results: In the ROC analysis, the mean area under the curve and the mean accuracy of all classifications were high with both internal and external test sets (all, > 0.89 and > 0.80). In the t-SNE analysis, our model succeeded in creating good separation between three classification groups. Grad-CAM figures showed differences in the location and size of the focus areas between three classification groups in each diagnosis. Conclusions: Since the accuracy of our model was validated with both internal and external test sets, it shows the possible usefulness of a one-step automated orthodontic diagnosis tool using a CNN model. However, it still needs technical improvement in terms of classifying vertical dental discrepancies."
Research on aquatic target image recognition based on convolutional neural networks,2022,"['Aquatic target detection', 'Convolutional Neural Networks', 'Artificial Intelligence']",국문 초록 정보 없음,"Image recognition is not very effective in the water environment due to multiple factors, such as high scattering and high scattering in the water column. This is why the relevant parameters in the Faster R-CNN network model need to adjust continuously to improve the effectiveness of water detection. The control variable method adjusts the program's learning rate by tuning the network model's parameters. Then, the number of training rounds is adjusted according to the loss function of each round, and finally, we can get the number of matches with the minimum loss function. Based on the experimental results on the dataset, it is shown that the proposed method not only selects the learning rate with the best detection results but also has the strongest robustness and achieves a 96%-99% recognition rate for passenger ships, cargo ships, warships, and bridges compared with other learning rates. Experiments show that the Faster R-CNN network model detects water targets with significant results, and the best network model learning rate parameter is 6×10-3."
Softwood Species identification using Convolutional Neural Network,2022,"['Species identification', 'Species classification', 'Convolutional Neural Network', 'Deep learning']",국문 초록 정보 없음,"In order to improve the accessibility of wood species identification, the four domestic and six imported softwood species were classified using deep learning method. The cross-section micrographs were used as a dataset; which 1,535 images of 40x micrographs with earlywood and latewood, and 2,000 images of 200x micrographs for earlywood and latewood each. The classification accuracy and loss rate of 10 species were compared using the four convolutional neural network models such as modified CNN, GoogLeNet, VGG16, and ResNet. In verifying the classification accuracy and loss rate by model, the influencing factors, such as epochs, collected part of the dataset, and dataset augmentation, were analyzed. The modified CNN and GoogLeNet models increased classification accuracy in proportion to the number of epochs, achieving more than 95% classification accuracy in the final stage. At the same time, the loss rate decreased with decreasing the number of epochs. VGG16 model showed a low classification accuracy of 20~30% and a high loss rate regardless of the number of epochs during learning under the same conditions as the other models. The ResNet model showed a high classification accuracy of over 90%, with a low loss rate during the training process. However, classification accuracy decreased to 20~30%, with a high loss rate when the test process. As a result of analyzing the general trends in the four models, the classification accuracy increased with increasing the number of epochs in the latewood and total dataset. In contrast, the earlywood dataset didn't show any tendency. The dataset augmentation was not significantly correlated with the classification accuracy and loss rate. Based on these results, modified CNN and GoogLeNet models among the four deep learning models showed excellent wood species classification performance. Further, it is expected that the two models can be applied to identify unknown ten softwood species."
A Facial Gender Detector on CPU using Multi-dilated Convolution with Attention Modules,2022,"['facial gender detector', 'smart digital advertising', 'convolutional neural network', 'dilated convolution', 'attention module']",국문 초록 정보 없음,"Facial gender detectors have evolved into a vital component of an intelligent advertisement display platform. It is helpful to assist a decision of delivering appropriate advertisements to each audience. To reduce system costs, applications deployed in this platform must be able to run on a CPU. This work proposes a facial gender detector (FGCPU) that can be implemented on a CPU device to support an advertising display platform. The proposed CNN model consists of a multi-dilated convolution with attention modules (MudaNet). The multi-dilated convolution is applied to capture multi-scale features in an efficient manner. The attention module is used to rectify the quality of the feature map. This work’s training and validation process is conducted on the UTKFace, the Labeled Faces in the Wild (LFW), and the Adience Benchmark datasets. As a result, the proposed CNN model is proven to compete with other common and lightweight competitors’ CNN models on these three datasets. Regarding speed, the detector can operate 49.19 frames per second in real-time on a CPU device."
전동기 기계시설물 고장 분류를 위한이미지 인코딩 기반 경량화된 딥러닝 모델,2022,"['Timeseries classification', 'Image encoding', 'Deep learning', 'Lightweight model']","산업 현장에서 사용되는 전동기 기계 설비들의 고장은 베어링, 회전체, 벨트, 축이 상당 부분을 차지한다. 설비들이 기계적 또는 전기적 원인에 의해 고장이 발생하거나 성능이 저하되면 공통 적으로 진동이 발생하고 전류 등이 이상 움직임을 보인다. 이러한 상황에서 불특정하게 발생하는 고장을 쉽게 감지하고 예측하는 것은 필수적이다. 따라서 본 논문에서는 전동기 기계 설비에 부착된 센서에서 생성되는 시계열 데이터를 이미지로 인코딩하는 방법을 사용하여 경량화된 딥러닝 모델을 제안하였다. 이미지 인코딩에는 세 개의 방식을 사용하였고, 각각의 방식에 대한 CNN 기반 딥러닝 분류모델을 생성하였다. CNN 모델은 작은 파라미터를 가지면서도 제일 정확도가 높은 모델을 실험을 통해 만들었다. CNN 모델의 정확도를 분석하고 어떠한 인코딩 방식이 학습에 효율적이고 더 적합한지 실험해보았더니 세 개의 이미지 인코딩 방식 중에서도 GASF 방식이 대체로 정확도가 높게 나온 것을 확인하였다. 본 논문에서 제안한 이미지 인코딩 기반의 경량화된 딥러닝 모델을 이용해 산업에서 활용되는 여러 센서 데이터에 대해 다양한 응용에 활용할 수 있을 것이라 예상된다.",다국어 초록 정보 없음
Convolutional Neural Network based Partial Discharge Detection for Power Transformer using HFCT sensor,2022,"['Fault detection', 'phase-resolved partial discharge', 'power transformer', 'convolutional neural network']",국문 초록 정보 없음,"Fault detection in power equipment is an essential part for the stability of the power grids. Partial discharge inpower equipment is used to classify the insulation status of the power equipments. In this paper, a deep neural network based fault classification algorithm is proposed using phase resolved partial discharges (PRPDs) in power transformer. Convolutional neural network (CNN) is used as a classification algorithm for PRPDs from high frequency current transformer (HFCT). In addition, we apply our CNN model to edge devices. Experimental results showed that the proposed CNN method outperforms other machine learning (ML) based classification algorithms."
Assessment of Drug-Induced Cardiac Arrhythmicity using Deep Learning Approach,2022,"['Arrhythmic Risk Level of Drugs', 'Deep Convolutional Neural Network', 'net charges', 'calcium transient']",국문 초록 정보 없음,"One of the considering things about drug development is some drugs can cause Torsade de Pointes (TdP) which is harmful to society. Thus, the Comprehensive in vitro proarrhythmia assay (CiPA) project was successful in classifying to assess drug-induced arrhythmias through a logistic regression model using qNet as a TdP risk assessment biomarker. However, obtaining that result through in silico simulation is inefficient. We propose using the CNN model to classify three levels of proarrhythmic risk: high, intermediate, and low. To obtain net charges and calcium transients, we use the ToRd myocyte cell model. Drug effects were implemented using IC50 and Hill coefficient. There are 12 drugs as CNN model training data and 16 drugs as test data. qNet variability, qInward variability, CaD90 variability, CaD50 variability, and Ca resting variability are used as input in the CNN model independently. As the result, qInward variability showed better performance for the three classifications, 83% high-risk drug, 80% intermediate, and 80% low-risk drug."
딥러닝 기반 장면인식 기법을 이용한 제조 작업공간 분류모델,2022,"['Scene Recognition', 'Deep Learning', 'Convolutional Neural Network', 'Places365', 'Manufacturing Workspace']","최근 머신러닝 기술의 발달로 산업현장에서 딥러닝(Deep Learning)을 통한 장면인식(Scene Recognition) 방법이다양하게 연구되고 있다. 딥러닝을 이용한 장면인식의 성능은 알고리즘 구조와 학습방법에 따라 크게 영향을 받는다. 본 연구를 위한 사전 연구 결과, Places365 데이터셋으로 학습된 데이터 모델에 의한 제조 작업공간 분류 정확도는 54%로, 이 성능으로는 실제 환경에서 사용하기는 어렵다. 따라서 본 논문에서는 이러한 문제점을 해결하고자CNN(Convolutional Neural Network) 기반에서 3가지의 전략으로 학습 데이터셋을 재구성하여 학습을 실시한 후장면인식 기법을 이용하여 제조 작업공간 분류모델을 제시하였다. 제안한 알고리즘과 데이터셋 구성방법을 통해 학습할 경우, 제조 작업공간에 대한 장면인식 성능은 기존 방법에 비해 28%p 향상됨을 확인하였다.","With the recent development of machine learning technology, various methods of scene recognition through deep learning are being studied in industrial fields. The performance of scene recognition using deep learning is greatly affected by the algorithm structure and learning method. As a result of the preliminary study for this study, it was confirmed that the manufacturing workspace classification accuracy by the data model trained with the Places365 dataset was 54%, which was difficult to use in the real environment. Therefore, in this paper, in order to solve this problem, a classification model of the manufacturing workspace is presented using a scene recognition technique after learning by reconstructing a learning dataset with three strategies based on CNN (Convolutional Neural Network). When learning through the proposed algorithm and data set configuration method, it was confirmed that the scene recognition performance for the manufacturing workspace was improved by 28%p compared to the existing method."
Deep Neural Network와 Convolutional Neural Network 모델을 이용한 산사태 취약성 매핑,2022,"['Landslides', 'Susceptibility map', 'Deep learning', 'Deep neural network', 'Convolutional neural network']",국문 초록 정보 없음,"Landslides are one of the most prevalent natural disasters, threating both humans and property. Also landslides can cause damage at the national level, so effective prediction and prevention are essential. Research to produce a landslide susceptibility map with high accuracy is steadily being conducted, and various models have been applied to landslide susceptibility analysis. Pixel-based machine learning models such as frequency ratio models, logistic regression models, ensembles models, and Artificial Neural Networks have been mainly applied. Recent studies have shown that the kernel-based convolutional neural network (CNN) technique is effective and that the spatial characteristics of input data have a significant effect on the accuracy of landslide susceptibility mapping. For this reason, the purpose of this study is to analyze landslide vulnerability using a pixel-based deep neural network model and a patch-based convolutional neural network model. The research area was set up in Gangwon-do, including Inje, Gangneung, and Pyeongchang, where landslides occurred frequently and damaged. Landslide-related factors include slope, curvature, stream power index (SPI), topographic wetness index (TWI), topographic position index (TPI), timber diameter, timber age, lithology, land use, soil depth, soil parent material, lineament density, fault density, normalized difference vegetation index (NDVI) and normalized difference water index (NDWI) were used. Landslide-related factors were built into a spatial database through data preprocessing, and landslide susceptibility map was predicted using deep neural network (DNN) and CNN models. The model and landslide susceptibility map were verified through average precision (AP) and root mean square errors (RMSE), and as a result of the verification, the patch-based CNN model showed 3.4% improved performance compared to the pixel-based DNN model. The results of this study can be used to predict landslides and are expected to serve as a scientific basis for establishing land use policies and landslide management policies."
기계학습을 이용한 3D CAD 모델 형상과 경계조건의 유형 식별,2022,"['3D CAD Model', 'Boundary Condition', 'Data Classification', 'Extended Voxel Model', 'Machine Learning', 'Multi-Layer Perceptron', 'Convolutional Neural Network']",국문 초록 정보 없음,"In this paper, we propose a machine learning approach for classifying 3D CAD models with boundary conditions. We adopted an extended voxel model to represent a CAD model with its boundary conditions, and to construct the training data. By considering 7 types of part families and 3 types of boundary conditions, we generated 320 similar CAD models for each part family and assigned 3 different boundary conditions to each CAD model, which produces 960 datasets for the part family. We used multi-layer perceptron (MLP) and convolutional neural network (CNN) as machine learning models, which classify the combination type of a given CAD model with its boundary conditions. Using TensorFlow, we trained and tested the models, and compared their performance. We considered the MLP models made of three hidden layers and the CNN models made of two convolutional, two pooling, and three hidden layers. We also conducted a grid search to find the proper number of nodes in hidden layers. From experimental results, we found that the CNN models are better in accuracy than the MLP models. If further enhanced, the proposed approach is expected to become a useful tool for similar case search from archive CAE models."
Deep Learning Analysis to Automatically Detect the Presence of Penetration or Aspiration in Videofluoroscopic Swallowing Study,2022,"['Deep Learning', 'VFSS', 'Deglutition', 'Swallowing Reflex']",국문 초록 정보 없음,"Background: Videofluoroscopic swallowing study (VFSS) is currently considered the gold standard to precisely diagnose and quantitatively investigate dysphagia. However, VFSS interpretation is complex and requires consideration of several factors. Therefore, considering the expected impact on dysphagia management, this study aimed to apply deep learning to detect the presence of penetration or aspiration in VFSS of patients with dysphagia automatically.Methods: The VFSS data of 190 participants with dysphagia were collected. A total of 10 frame images from one swallowing process were selected (five high-peak images and five low-peak images) for the application of deep learning in a VFSS video of a patient with dysphagia. We applied a convolutional neural network (CNN) for deep learning using the Python programming language. For the classification of VFSS findings (normal swallowing, penetration, and aspiration), the classification was determined in both high-peak and lowpeak images. Thereafter, the two classifications determined through high-peak and low-peak images were integrated into a final classification.Results: The area under the curve (AUC) for the validation dataset of the VFSS image for the CNN model was 0.942 for normal findings, 0.878 for penetration, and 1.000 for aspiration.The macro average AUC was 0.940 and micro average AUC was 0.961.Conclusion: This study demonstrated that deep learning algorithms, particularly the CNN, could be applied for detecting the presence of penetration and aspiration in VFSS of patients with dysphagia."
A video-based SlowFastMTB model for detection of small amounts of smoke from incipient forest fires,2022,"['forest fire', 'smoke detection', 'deep learning', 'early detection', 'annotation']",국문 초록 정보 없음,"This paper proposes a video-based SlowFast model that combines the SlowFast deep learning model with a new boundary box annotation algorithm. The new algorithm, namely the MTB (i.e., the ratio of the number of Moving object pixels To the number of Bounding box pixels) algorithm, is devised to automatically annotate the bounding box that includes the smoke with fuzzy boundaries. The model parameters of the MTB algorithm are examined by multifactor analysis of variance. To demonstrate the validity of the proposed approach, a case study is provided that examines real video clips of incipient forest fires with small amounts of smoke. The performance of the proposed approach is compared with those of existing deep learning models, including convolutional neural network (CNN), faster region-based CNN (faster R-CNN), and SlowFast. It is demonstrated that the proposed approach achieves enhanced detection accuracy, while reducing false negative rates."
증강현실  모델  위치  정합  활용을  위한  기계학습  기반의  선박  블록 윤곽선  검출  연구,2022,"['CNN', 'GAN', 'Outline Detection', 'Segmentation']",국문 초록 정보 없음,"As interest in autonomous ships is growing, research on augmented reality-based remote sup- port systems that can be used onboard ships is being conducted. The markerless method is more suitable than the marker method because corrosion and damage can easily occur in the ship. However, in the case of the markerless method, a process of selecting a desired feature point is required, but it is not easy in a complicated ship. Therefore, in this study, the outline detection system was studied to utilize the outline as a feature point for augmenting the augmented real- ity model. Although many existing studies have preceded it, it is not suitable for detecting the contour  of  a  ship  block  with  many  internal  and  external  components.  Therefore,  in  order  to overcome the limitations of the previous method, in this study, to detect only the outline of a ship  block,  a  model  was  built  through  CNN,  GAN,  and  Segmentation  algorithm,  which  are deep learning techniques widely used in image processing, and block outline detection was per- formed.  It  is  also  expected  that  these  results  will  help  automate  and  optimize  the  stockyard management system."
Real-time Deep Learning-based Scene Recognition Model For Metaverse Applications,2022,"['CNN', 'deep learning', 'metaverse', 'scene recognition', 'virtual reality']",국문 초록 정보 없음,"Scene recognition is a type of image recognition task essential to the success of Metaverse applications. Previous works have focused on Scene recognition tasks for real-world environments. However, it is crucial to establish scene recognition models that can be applied in Metaverse applications. This paper applied two Convolutional Neural Networks (CNN) models: SimpleNet and AlexNet, to automatically recognize Virtual scenes. The models are trained on the Scene15 dataset of real-world scenes and tested on virtual-world scenes. The models achieved a test recognition accuracy of 50.96% and 78.08%, and a test time of 50.00ms and 10.00ms respectively on 7 different categories of virtual scenes."
Fundus Photograph Discrimination Using Transfer Learning over Limited Computing Power Environment,2022,"['AI', 'CNN', 'Fundus photograph', 'ImageNet', 'OPhthalmoloscopy', 'Transfer learning']",국문 초록 정보 없음,"In this paper, we demonstrates a reliable and efficient approach to detect eye-related disease with automated fundus screening using convolutional neural network (CNN) and transfer learning that counteracts to insufficient annotated data set and image domain shifts. The weight values learned from the data sets can be used as initial parameters for the other desired neural networks, and additional learning can be conducted on top of the pre-learned model, called transfer learning. It is a particularly useful method when the number of data sets is and small over limited computing power environment. Four different fundus image data sets, image domains such as ethnicity of the target and equipment which the fundus photograph was captured with, were used for the validation. The data sets were annotated by ophthalmologists as healthy, abnormal, or diabetic retinopathy. The ResNet-18 model, pre-trained with ImageNet data set of 1.2 million images of 1000 daily routine objects, were used for transfer learning. The pre-trained model were modified and additionally trained to learn features from the fundus images, and were validated with separate test sets. Given limited quantity of fundus photograph data set and various image domains, the deep learning models can yield robust ophthalmological performance in discriminating pathologies in the eyes. In spite of the simplicity, this study illustrates the capability of transfer learning and suggests pragmatic and practical approach to varied medical settings with fluctuating status of data maintenance and different image domains."
다중 신경망을 이용한 객체 탐지 효율성 개선방안,2022,"['Tensorflow', 'Darknet', 'YOLO']","기존의 Tensorflow CNN 환경에서 Object 탐지 방식은 Tensorflow 자체적으로 Object 라벨링 작업과 탐지를 하는 방식이다. 그러나 현재 YOLO의 등장으로 이미지 객체 탐지의 효율성이 높아졌다. 그로 인하여 기존 신경망보다 더 많은 심층 레이어를 구축할 수 있으며 또한 이미지 객체 인식률을 높일 수 있다.  따라서 본 논문에서는 Darknet, YOLO를 기반으로 한 Object 탐지 시스템을 설계하고 기존에 사용하던 합성곱 신경망에 기반한 다중 레이어 구축과 학습을 수행함으로써 탐지능력과 속도를 비교, 분석하였다. 이로 인하여 본 논문에서는 Darknet의 학습을 효율적으로 이용하는 신경망 방법론을 제시하였다.","In the existing Tensorflow CNN environment, the object detection method is a method of performing object labeling and detection by Tensorflow itself. However, with the advent of YOLO, the efficiency of image object detection has increased. As a result, more deep layers can be built than existing neural networks, and the image object recognition rate can be increased.  Therefore, in this paper, the detection ability and speed were compared and analyzed by designing an object detection system based on Darknet and YOLO and performing multi-layer construction and learning based on the existing convolutional neural network. For this reason, in this paper, a neural network methodology that efficiently uses Darknet’s learning presented."
필터 다양화를 통한 합성곱 신경망의 표현력 향상,2022,"['Deep learning', 'CNN', 'Feature Representation', 'Filter Diversity', 'Singular Value Decomposition (SVD) Entropy', 'Filter Spreading']",국문 초록 정보 없음,"This paper aims to improve the feature representation by diversifying CNN filters inspired by niche concept in evolution. The singular value decomposition (SVD) entropy based efficient metric for diversity is proposed In the proposed approach, filters are clustered by groups and they are calculated as differences from the center values within the groups, rather than by entire rank based comparison. This provides an effective method for increasing the substantial diversity of filters. Furthermore, the filters with low diversity are adjusted by the diversity spreading framework for better diversity in the reconstruction process. The improvement of the filter representation by performing experiments on CIFAR 10/100 data for VGG16, and ImageNet for ResNet34 is provided. Because there are no similar studies, we compare our results with respect to those of relatively relevant pruning methods in terms of classification performance accuracy as well as the pruned rates and flops."
딥러닝 기반 활주로 균열 식별,2022,"['deep learning', 'CNN', 'Mask R-CNN', 'runway', 'crack', 'drone']",국문 초록 정보 없음,"The purpose of this study is to provide a method for identifying runway cracks using deep learning for the efficient operation of air power in wartime and peacetime. The current identification method, which mainly depends on human eyes, requires a lot of time, money and manpower. In order to prevent the consumption of such resources, a drone was utilized to take runway images and cracks were identified from the images via deep learning. Data sets were generated through labeling of the images, and the deep learning model was applied to them to evaluate the learning accuracy. As a result of the verification of the trained model, runway cracks were identified, and also the location and size of the cracks were predicted and compared with the actual cracks. Through this research, it is expected to reduce the consumption of resources and increase the efficiency of air power operation by improving the accuracy and reliability of the identification of runway cracks in wartime and peacetime."
User-to-User Matching Services through Prediction of Mutual Satisfaction Based on Deep Neural Network,2022,"['Convolutional Neural Network (CNN)', 'Deep Learning', 'Deep Neural Network (DNN)', 'Matching Service', 'Recommender Service']",국문 초록 정보 없음,"With the development of the sharing economy, existing recommender services are changing from user–itemrecommendations to user–user recommendations. The most important consideration is that all users shouldhave the best possible satisfaction. To achieve this outcome, the matching service adds information betweenusers and items necessary for the existing recommender service and information between users, so higher-leveldata mining is required. To this end, this paper proposes a user-to-user matching service (UTU-MS) employingthe prediction of mutual satisfaction based on learning. Users were divided into consumers and suppliers, andthe properties considered for recommendations were set by filtering and weighting. Based on this process, weimplemented a convolutional neural network (CNN)–deep neural network (DNN)-based model that can predicteach supplier’s satisfaction from the consumer perspective and each consumer’s satisfaction from the supplierperspective. After deriving the final mutual satisfaction using the predicted satisfaction, a top recommendationlist is recommended to all users. The proposed model was applied to match guests with hosts using Airbnb data,which is a representative sharing economy platform. The proposed model is meaningful in that it has beenoptimized for the sharing economy and recommendations that reflect user-specific priorities."
Handcrafted Cost 기반의 다중뷰 스테레오 정합 네트워크,2022,"['Multi-view stereo', 'CNN', 'Encoder-decoder network', 'Parallel processing', 'OpenCL']","다중 뷰 스테레오 정합 기법은 임의의 화각에서 취득한 여러 장의 입력 영상으로부터 카메라 위치 정보를 활용하여 정교한 깊이 정보를 얻는 방법을 뜻한다. 기존 다중 뷰 스테레오 정합 기법은 인접 영상 간 가려진영역이 적을 때만 잘 작동하며 영상 내 잡음에 취약한 모습을 보였다. 본 논문에서는 소수의 입력 영상으로부터 CNN 기반의 encoder-decoder 구조의 네트워크로 정교한 깊이 영상을 복원하는 기법을 제안한다. 제안하는 기법은 비용 볼륨 구축 알고리즘과 대상 영상에 대한 올바른 참조 영상 선정 기법 그리고 비용 볼륨 regression 네트워크를 통한 변이도 추정 기법으로 구성되어있다. 본 논문에서는 제안하는 기법들을 통해 저 사양 임베디드 보드에서 OpenCL 기반의 병렬 알고리즘으로 다중 뷰 스테레오 정합의 구현 가능성을 보이고, 다중 영상 데이터 셋으로 학습한 네트워크를 통해 소수의 영상으로부터 정교한 깊이 정보를 복원한다.",다국어 초록 정보 없음
다채널 근전도 기반 딥러닝 동작 인식을 활용한 손 재활 훈련시스템 개발 및 사용성 평가,2022,"['Convolutional Neural Network (CNN)', 'EMG', 'Hand rehabilitation', 'Hand posture recognition', 'Usability evaluation']",국문 초록 정보 없음,"The purpose of this study was to develop a hand rehabilitation training system for hemiplegic patients. We also tried to find out five hand postures (WF: Wrist Flexion, WE: Wrist Extension, BG: Ball Grip, HG: Hook Grip, RE: Rest) in real-time using multi-channel EMG-based deep learning. We performed a pre-processing method that converts to Spider Chart image data for the classification of hand movement from five test subjects (total 1,500 data sets) using Convolution Neural Networks (CNN) deep learning with an 8-channel armband. As a result of this study, the recognition accuracy was 92% for WF, 94% for WE, 76% for BG, 82% for HG, and 88% for RE. Also, ten physical therapists participated for the usability evaluation. The questionnaire consisted of 7 items of acceptance, interest, and satisfaction, and the mean and standard deviation were calculated by dividing each into a 5-point scale. As a result, high scores were obtained in immersion and interest in game (4.6±0.43), convenience of the device (4.9±0.30), and satisfaction after treatment (4.1±0.48). On the other hand, Conformity of intention for treatment (3.90±0.49) was relatively low. This is thought to be because the game play may be difficult depending on the degree of spasticity of the hemiplegic patient, and compensation may occur in patient with weakened target muscles. Therefore, it is necessary to develop a rehabilitation program suitable for the degree of disability of the patient."
합성곱신경망을 활용한 과구동기 시스템을 가지는 소형 무인선의 추진기 고장 감지,2022,"['Unmanned surface vehicle(무인 수상 선박)', 'Fault detection(고장 감지)', 'Convolutional neural network(합성곱신경망)', 'ROS', 'Overacturated(과구동기)', 'Wavelet transform(웨이블렛 변환)']",국문 초록 정보 없음,"This paper proposes a fault detection method for a Unmanned Surface Vehicle (USV) with overactuated system. Current status information for fault detection is expressed as a scalogram image. The scalogram image is obtained by wavelet-transforming the USV""s control input and sensor information. The fault detection scheme is based on Convolutional Neural Network (CNN) algorithm. The previously generated scalogram data was transferred learning to GoogLeNet algorithm. The data are generated as scalogram images in real time, and fault is detected through a learning model. The result of fault detection is very robust and highly accurate."
Towards On-device Deep Neural Network Inference and Model Update for Real-time Gesture Classification,2022,"['Convolution neural network (CNN)', 'human-machine Interface', 'rehabilitation', 'surface electromyography (sEMG)', 'tinyML']",국문 초록 정보 없음,"Deep learning resurgence ushered in the application of pattern recognition algorithms in high-impact research fields with impressive accuracy. In addition, deep neural networks (DNN) have recently been used to classify gestures for rehabilitation device control utilizing raw electromyography data. However, the computational resources required by a convolution neural network (CNN) are a constraint that often limits deployment to embedded devices for real-time inference. An optimized edge adaptive convolutional neural network using a short-time Fourier transform (STFT) spectrogram input was proposed in this study. The models classification accuracy was evaluated offline and on-device for inter-subject accuracy. Furthermore, an adaptive weight update approach was implemented to improve inference model accuracy due to degradation. The proposed model and optimization technique achieved offline accuracy of 92.19 % and 94.29 % for the raw and STFT input, respectively. However, the on-device accuracy for raw and STFT input to the model was 82.26 % and 85.19 %, respectively. On the other hand, the adaptive model update increased the respective accuracy by an average of 7% on-device. Finally, our study demonstrates the deployment of DNN on-device for real-time gesture classification inference."
비정상 신호를 가진 연료 펌프의 상태 진단에서 Conv1D 모델의 시간 간격 별 예측 정확성 비교,2022,"['Anomaly detection', 'Centrifugal pump', 'CNN (Convolution Neural Network)', 'Conv1D', 'MLP(Multi-layer Perceptron)', 'Non-stationary signal', 'PCA (Principal component analysis)', 'Time Series', 'Variable speed']",국문 초록 정보 없음,"This study deals with the condition detection of centrifugal pump supplying liquid to marine engines. The purpose is to detect the anomaly and the failure modes of the pump by applying the vibration signals from the simulated failures on the experimental bed. Since the pump rarely experiences faults as well as used to degradation experiments, the vibration signal was gathered from an experimental bed simulating the bearings and lubricant failures. Considering the non-stationarity of variable speed, the convolution is applied to extract the feature of time series rather than the frequency feature. The advantage of CNN implicitly extracting features from a non-stationary signal is used to extract the features applied to Conv1D. After learning the features, a multi-layer perceptron (MLP) was connected to failure classification to identify the operation state. Finally, it is suggested that the time series-based feature extraction can be applied to the condition monitoring of a centrifugal pump with variable speed and non-stationarity."
감귤 착과량 추정을 위한 초분광 데이터 분류 정확도 평가,2022,"['드론', '초분광 센서', '감귤', 'CNN', 'ANN', 'SVM']","감귤 노지 재배의 과학적 근거를 기반으로 한 농작체계의 지능화 및 효율화가 절실히 요구되고 있다. 감귤의 생산량 추정을 위한 기초자료 수집은 한정된 조사인력이 약 22,000ha에 이르는 방대한 면적을 조사하기에 시간이 오래 걸릴 뿐만 아니라 담당직원은 조사인력의 부족으로 격무에 시달리고 있는 실정이다. 또한 조사인력은 관행적으로 직접 관측조사에 의존하며, 일관되지 않은 데이터수집이 이뤄지고 있다. 과수 수확량의 정확한 예측은 수확 후 관리와 마케팅 계획 등에 있어서 필수 요소 중 하나인데, 과수 재배자는 노동력 산출 및 저장 계획의 근거로 중간도매인들은 포장재와 운반비용 산출 등에 활용됨으로 무엇보다 높은 신뢰성이 요구된다 (Wulfsohn et al. 2012). 농업 엔지니어링 기술 최적화와 농업 관리 관행의 표준화의 결합이 절실히 요구되는 가운데 (Leilei et al. 2022), 본 연구는 드론에서 얻은 초분광 영상 데이터를 이용하여 감귤의 열매 수확량을 빠르고 정확하게 예측하는 기초연구로서, 감귤 과실의 분류를 대표적인 감독자분류인 머신러닝 기반의 SVM(Support Vector Machine) 방식, 딥러닝 기반의 ANN(Artificial Neural Network) 방식, CNN(Convolution Neural Network) 방식의 이미지 분석 알고리즘의 분류 정확도를 평가하였다.",다국어 초록 정보 없음
Tutorial and applications of convolutional neural network models in image classification,2022,"['AdamW', 'convolution neural network', 'deep learning', 'ILSVRC']",국문 초록 정보 없음,"Image classification is a supervised learning problem in the machine learning area. We apply deep learning models to classify image data. In particular, we discuss the advantages of the various types of convolutional neural networks competed in the ImageNet large-scale visual recognition challenge (ILSVRC). First, we provide a review of the CNN models to be applied and explain the details of models to be employed. In general, we keep the core structure of the models in the same form proposed in ILSVRC. We investigate the models via four popular image data sets of various sizes. To compare the performance of the models, we adopt top-1 accuracy, top-5 accuracy, and f1-score as the measures of accuracy. We employ AdamW for an optimizer that is a fast algorithm and often yields precise learning. As a result, we show that the Inception-ResNet-v2 model has excellent performance, and the ResNet is robust to imbalanced data."
클라우드 플랫폼을 이용한 원격 육계 검출 모델 개발,2022,"['Cloud platform', 'Faster R-CNN', 'SSD MobileNetv2', 'YOLOv5']","기존 농축산업에 ICT를 접목한 스마트팜은 원격으로 작물이나 가축에 생육, 생장 환경을 관리하고 유지하는 농장을 의미한다. CPU 기반의 클라우드 플랫폼은 작업자 대신 업체에서 관리하여 접근성, 보안 기능이 좋고 필요시에만 사용할 수 있기 때문에 비용이 저렴하다는 장점이 있지만 GPU를 사용하는 플랫폼의 경우에는 가격이 매우 높다는 단점이 있다. 따라서, 원격 객체 인식을 위해서는 GPU를 통해 학습한 모델을 CPU 클라우드 플랫폼으로의 마이그레이션이 필요하다. 본 연구에서는 Naver Cloud Platform을 이용하여 육계를 원격으로 검출하는 딥러닝 모델을 개발하고자 한다. RGB 카메라로 탑뷰에서 촬영된 육계 이미지 1,390장을 Train 60%, Test 20%, Validation 20%으로 나누었고 객체 인식을 위한 딥러닝 모델로는 Faster R-CNN, SSD MobileNetv2, YOLOv5을 사용하였다. 또한, 학습 중 과적합 방지를 위해 Early Stopping 함수를 사용하였다. 딥러닝은 GPU가 설치되어 있는 로컬 컴퓨터에서 학습한 뒤, 학습된 모델을 클라우드 플랫폼으로 마이그레이션하여 객체 인식 결과를 확인하였다. 실험 결과 YOLOv5가 mAP@50IOU=0.906, Recall=0.920으로 가장 좋은 성능을 보여주었으며 학습 시간 또한 다른 모델에 비해 빠른 것으로 나타났다. 육계의 전염병이나 사체는 조기에 발견하는 것이 중요하다. 향후, 병에 걸린 육계의 외관이나 사체의 이미지를 학습하여 원격으로 검출하는 연구가 진행된다면 작업자에게 비용 뿐만 아니라 노동력도 줄일 수 있어 ICT 융복합 육계 스마트팜 보급에 기여할 것으로 예상된다.",다국어 초록 정보 없음
딥러닝 기반 이미지 필터 간 한국인 표정 분류 성능 비교,2022,"['얼굴 표정 분류', 'CNN', 'VGG', 'ResNet', '가장자리 검출 필터', 'Facial Expression Classification', 'CNN', 'VGG', 'ResNet', 'Edge Detection Filter']",국문 초록 정보 없음,다국어 초록 정보 없음
MKL-SVM 기반의 건전성 예측 및 관리기술(PHM)에 관한 연구,2022,"['MKL-SVM', 'Machine Learning', 'CNN', 'PHM']","최근 폴랜트 산업에서는 IIoT(Industrial internet of things), AI(Artificial intelligence), 빅데이터 PHM(Prognostics and Health Management) 그리고 Digital Twin 등의 기술을 기반으로, 폴랜트 설비의 건전성상태를 실시간으로 모니터링하고 이로부터 고장여부 진단은 물론 고장까지 시간을 미리 예측하는 관리기술의 중요성이 강조되고 있다.본 논문에서는 플랜트 설비(펌프, 압축공기, 보일러, 모터, 변압기)의 고장예지 및 사전 결함을 예측하는 건전성 예측 및 관리기술(Prognostics and health management, PHM) 의 고도화를 위해 기계학습 기반의 MKL-SVM 알고리즘을 제안한다.제안된 MKL-SVM 알고리 즘과 CNN(Convolutional Neural Network)모델을 비교하여 성능평가를 하였으며, 제안된 방법으로 검증한 실험에서 사전 결함 예측 가능성이 지속적으로 개선되었음을 검증하였다. 또한, DeepLearning과 효용성 검증실험을 통해 제안하는 방법이 효율적임을 확인하였다.",다국어 초록 정보 없음
계층적 보조 경계 추출을 이용한 단일 영상의 초해상도 기법,2022,"['초해상도', '계층 구조', 'CNN', '딥러닝', '에지', 'Super resolution', 'Hierarchical Structure', 'CNN', 'Deep Learning', 'Edge']",국문 초록 정보 없음,다국어 초록 정보 없음
A review and comparison of convolution neural network models under a unified framework,2022,"['classification', 'convolutional neural network (CNN)', 'ImageNet large-scale visual recognition challenge (ILSVRC)', 'image data']",국문 초록 정보 없음,"There has been active research in image classification using deep learning convolutional neural network (CNN) models. ImageNet large-scale visual recognition challenge (ILSVRC) (2010-2017) was one of the most important competitions that boosted the development of efficient deep learning algorithms. This paper introduces and compares six monumental models that achieved high prediction accuracy in ILSVRC. First, we provide a review of the models to illustrate their unique structure and characteristics of the models. We then compare those models under a unified framework. For this reason, additional devices that are not crucial to the structure are excluded. Four popular data sets with different characteristics are then considered to measure the prediction accuracy. By investigating the characteristics of the data sets and the models being compared, we provide some insight into the architectural features of the models."
이미지 내 객체 분류를 위한 노드 가지치기 기반 압축된 심층 합성곱 신경망 모델,2022,"['딥러닝', '이미지 전처리', '객체 분류', '노드 가지치기', 'CNN', 'Deep learning', 'Convolutional Neural Network', 'Image Preprocessing', 'Object Classification', 'Node Pruning']",국문 초록 정보 없음,"Modern DCNN(Deep Convolutional Neural Network)-based image classification system can train huge amounts of data with high accuracy. However, to use a DCNN, we need a long time and enormous compute capacity to train huge amounts of data for using DCNN. Therefore, this paper proposed a compact DCNN model that can be used in various environments. To classify objects within an image, a dataset was collected by photographing hand gesture images through a webcam. Then new deep learning model based on CNN was designed and trained hand gesture image data and classified with 98% accuracy. We then used node pruning to lighten DCNN models, showing training times that were reduced by about three times compared to original model and hyper-parameter number that was reduced by 63% of the pre-pruned model."
Convolutional neural network 기법을 이용한 턱수염물범 신호 판별,2022,[],국문 초록 정보 없음,"Several studies using Convolutional Neural Network (CNN) have been conducted to detect and classify the sounds of marine mammals in underwater acoustic data collected through passive acoustic monitoring. In this study, the possibility of automatic classification of bearded seal sounds was confirmed using a CNN model based on the underwater acoustic spectrogram images collected from August 2017 to August 2018 in East Siberian Sea. When only the clear seal sound was used as training dataset, overfitting due to memorization was occurred. By evaluating the entire training data by replacing some training data with data containing noise, it was confirmed that overfitting was prevented as the model was generalized more than before with accuracy (0.9743), precision (0.9783), recall (0.9520). As a result, the performance of the classification model for bearded seals signal has improved when the noise was included in the training data."
YOLOv4 알고리즘을 이용한 저품질 자동차 번호판 영상의 숫자 및 문자영역 검출,2022,"['Deep Learning', 'YOLOv4', 'Convolution Neural Network(CNN)', 'Vehicle License Plate', 'Image Recognition']",국문 초록 정보 없음,"Recently, research on license plate recognition, which is a core technology of an intelligent transportation system(ITS), is being actively conducted. In this paper, we propose a method to extract numbers and characters from low-quality license plate images by applying the YOLOv4 algorithm. YOLOv4 is a one-stage object detection method using convolution neural network including BACKBONE, NECK, and HEAD parts. It is a method of detecting objects in real time rather than the previous two-stage object detection method such as the faster R-CNN. In this paper, we studied a method to directly extract number and character regions from low-quality license plate images  without additional edge detection and image segmentation processes. In order to evaluate the performance of the proposed method we experimented with 500 license plate images. In this experiment, 350 images were used for training and the remaining 150 images were used for the testing process. Computer simulations show that the mean average precision of detecting number and character regions on vehicle license plates was about 93.8%."
A New Bank-card Number Identification Algorithm Based on Convolutional Deep Learning Neural Network,2022,"['Bank-card number', 'Identification Algorithm', 'CNN', 'Edge detection', 'Candidate region generation', 'Recognition']",국문 초록 정보 없음,"Recently bank card number recognition plays an important role in improving payment efficiency. In this paper we propose a new bank-card number identification algorithm. The proposed algorithm consists of three modules which include edge detection, candidate region generation, and recognition. The module of ‘edge detection’ is used to obtain the possible digital region. The module of ‘candidate region generation’ has the role to expand the length of the digital region to obtain the candidate card number regions, i.e. to obtain the final bank card number location. And the module of ‘recognition’ has Convolutional deep learning Neural Network (CNN) to identify the final bank card numbers. Experimental results show that the identification rate of the proposed algorithm is 95% for the card numbers, which shows 20% better than that of conventional algorithm or method."
시각적 특징과 물리적 특징에 기반한 스태킹 앙상블 모델을 이용한 과일의 자동 선별,2022,"['Fruit Grading', 'Stacking Ensemble Model', 'CNN', 'Perceptron']",국문 초록 정보 없음,"As consumption of high-quality fruits increases and sales and packaging units become smaller, the demand for automatic fruit grading systems is increasing. Compared to other crops, the quality of fruit is determined by visual characteristics such as shape, color, and scratches, rather than just physical size and weight. Accordingly, this study presents a CNN model that can effectively extract and classify the visual features of fruits and a perceptron that classifies fruits using physical features, and proposes a stacking ensemble model that can effectively combine the classification results of these two neural networks. The experiments with AI Hub public data show that the stacking ensemble model is effective for grading fruits. However, the ensemble model does not always improve the performance of classifying all the fruit grading. So, it is necessary to adapt the model according to the kind of fruit."
Triplet Loss 기반 딥러닝 모델을 통한 유사 아동 그림 선별 알고리즘,2022,"['이미지 유사성', 'Triplet Loss', '인공지능', '딥러닝', 'CNN', '아동 그림분석', 'Image Similarity', 'Triplet Loss', 'Artificial Intelligence', 'Deep Learning', 'CNN', 'Child drawing analysis']","본 논문은 유사 아동 그림 선별 알고리즘 생성을 위한 Triplet Loss 기반 딥러닝 모델 설계를 목적으로 한다. 아동 그림들 사이 유사성 측정을 위해서는 동일 클래스에 속하는 그림 간 특징 벡터의 거리는 가까워야 하고 다른 클래스 간 특징 벡터의 거리는 멀어져야 한다. 따라서, 본 연구에서는 클래스 수가 많아지는 경우에 이미지 유사성 측정에 이점을 지닌 Triplet Loss와 잔여 네트워크(ResNet)를 결합한 딥러닝 모델을 구축하여 유사 아동 그림 선별 알고리즘을 생성하였다. 결론적으로 본 모델을 활용한 유사 아동 그림 선별 알고리즘을 통해 대상 아동 그림과 다른 그림 간의 유사성을 측정하고 유사성이 높은 그림을 선별할 수 있다.",다국어 초록 정보 없음
딥 러닝 기반의 이기종 무선 신호 구분을 위한 데이터 수집 효율화 기법,2022,"['Wireless identification', 'RSSI sampling', 'Unlicensed spectrum', 'CNN', 'Feature selection']","최근 데이터 기반의 딥러닝 기술을 적용하여 비면허 대역의 다양한 통신 신호를 분류하는 연구가 활발히 수행되고 있다. 하지만,복잡한 신경망 모델 사용을 기반으로 이뤄진 이러한 접근법은 높은 연산 능력을 필요로 하게 되어, 자원 제약적인 무선 인터페이스및 사물인터넷(Internet of Things) 장비에서는 사용이 제약된다. 본 연구에서는 비면허 대역의 무선 이기종 기술을 인지하기 위한데이터 기반의 접근 방법을 살펴보고, 신호의 특징 추출 및 데이터화의 효율화 문제를 다룬다. 구체적으로, 비면허 대역의 다른 종류의 무선 통신 기술을 구분하기 위해 수신 신호 강도 측정을 기반으로 한 시계열 데이터를 이용해 합성곱 신경망(ConvolutionalNeural Network, CNN) 모델을 학습시켜 신호를 분류하는 방법을 살펴본다. 이 과정에서 동일한 구조의 신경망 모델의 경량화를위한 효율적 신호의 시계열 데이터 정보 수집시 주파수 대역의 특징을 함께 특징화하는 방법을 제안하고, 그 효과를 평가한다.Bluetooth 호환의 Ubertooth 장비를 이용한 실측 기반의 실험 결과는 제안된 샘플링 기법이 동일한 신경망에 대해서 10% 수준의샘플링 데이터 이용만으로도 동일한 정확도를 유지함을 보여준다.","Recently, there have been many research efforts based on data-based deep learning technologies to deal withthe interference problem between heterogeneous wireless communication devices in unlicensed frequency bands.However, existing approaches are commonly based on the use of complex neural network models, which requirehigh computational power, limiting their efficiency in resource-constrained network interfaces and Internet ofThings (IoT) devices. In this study, we address the problem of classifying heterogeneous wireless technologiesincluding Wi-Fi and ZigBee in unlicensed spectrum bands. We focus on a data-driven approach that employs asupervised-learning method that uses received signal strength indicator (RSSI) data to train Deep ConvolutionalNeural Networks (CNNs). We propose a simple measurement methodology for collecting RSSI training data whichpreserves temporal and spectral properties of the target signal. Real experimental results using an open-source 2.4GHz wireless development platform Ubertooth show that the proposed sampling method maintains the sameaccuracy with only a 10% level of sampling data for the same neural network architecture."
임베디드 시스템에서의 객체 탐지 네트워크추론 가속을 위한 필터 가지치기 기법 연구,2022,"['Deep learning', 'Embedded system', 'Object detection', 'Filter pruning', 'FLOPs']","최근에 컴퓨터 비전 분야에서 우수한 성능을 나타내는 CNN(Convolution neural network)이 각광을 받고 있다. 이는 데이터의 증가와 GPU와 같은 하드웨어 성능의 향상으로 가능하게 되었지만 높은 성능을 위해 네트워크가 깊고 넓어지면서 파라미터와 연산량이 기하급수적으로 증가하였다. 따라서 메모리, 연산 성능, 전력 사용이 제한적인 임베디드 환경에서 큰 네트워크의 활용은 더욱 어려워졌다. 이러한 문제를 해결하기 위해 CNN 모델의 정확도는 유지한 채 중요하지 않은 파라미터들을 제거하는 가지치기 기법이 활발히 연구되고 있다. 하지만 대부분의 가지치기 기법을 다룬 기존 연구는 파라미터 제거와 줄어든 파라미터에 의해 감소된 플롭스(FLOPs)에 대한 결과를 보여주였다. 본 논문에서는 파라미터 수와 함께 플롭스까지 원하는 비율만큼 줄임으로써 가속화된 추론 속도를 갖는 네트워크를 생성할 수 있는 필터 가지치기 기법을 제안한다. 제안하는 필터 가지치기 기법에 대한 성능을 평가하기 위해 VisDrone 데이터 세트와 YOLOv5를 이용하였으며, 가지치기 후 경량화된 네트워크의 추론 속도를 NVIDIA Jetson Xavier NX 플랫폼을 이용하여 측정하였다. 파라미터와 플롭스를 각각 30%, 40%, 50%씩 가지치기한 결과 mAP(0.5:0.95)는 기준 객체 탐지 네트워크 대비 0.6%, 0.9%, 1.2% 감소하는 반면에, 추론 시간은 각각 16.60%, 25.79%, 30.72%가 향상된 결과를 확인하였다.",다국어 초록 정보 없음
인공지능 모델로 식별 가능한 비식별 이미지 생성 방법,2022,"['비식별', '얼굴식별', '적대적공격', 'CCTV', 'DNN', 'CNN', 'De-identification', 'face identification', 'Adversary attack', 'CCTV', 'DNN', 'CNN']","최근 어디에서나 흔하게 볼 수 있는 CCTV는 사생활 침해의 논란이 있다. 심층신경망은 기반 이미지 인식, 패턴 분석과 같은 여러 유용한 서비스에 적용되었다. 한편, 적대적 예제는 심층신경망 보안에 큰 위협이 된다. 예로, 이미지에 약간의 노이즈를 추가하여 만들어진 얼굴 적대적 예제는 얼굴 인식 시스템에서 오인식이 발생 할 수 있다. 하지만 비식별화한 이미지를 재식별이 필요한 일부 상황에서는 적대적 예제가 유용할 수 있다. 이 논문에서는 우리는 재식별 가능한 얼굴 비식별화 방법을 제안한다. 제안하는 기법은 사람의 시각으로 식별할 수 없는 얼굴 식별 모델은 식별을 가능하게 한다. 비식별화 방법은 가우시안 블러와 적대적공격 기법인 C.W 공격을 사용하였다. 그리고 동영상을 이용한 실험으로 이 기법이 작동한다는 것을 보여주었다.",다국어 초록 정보 없음
미디어 인공지능  : 컴퓨터 비전 관련 딥러닝 모델의 미디어 동영상 분야 적용 가능성에 관한 연구,2022,"['deep learning', 'computer vision', 'convolutional neural networks(CNN)', 'recurrent neural networks (RNNs)', 'generative adversarial network (GANs)', 'media AI(media artificial intelligence)', 'video analytics', '딥러닝', '컴퓨터 비전', '합성곱 신경망', '순환 신경망', '적대적 신경망', '미디어 인공지능', '동영상 내용분석']","미디어 동영상 분야는 컴퓨터 비전 관련 딥러닝 모델을 활용해 연구 차원에서는 동영상의 자동화된 내용분석을 수행하고 실무 차원에서는 미디어 분야의 디지털 전환을 통해 서비스를 개선할 여지가 큰 영역이다. 이 논문에서는 미디어 동영상의 분석과 생성에 활용도가 높은 비전 관련 딥러닝 기반 모델을 검토했다. 우선 다양한 모델의 기축이 되는 알고리즘으로서 분류 모델로 널리 사용되는 합성곱 신경망(CNN)과 순환 신경망(RNN), 생성 모델로 사용되는 적대적 생성 신경망(GAN)과 오토인코더(AE), 사전 훈련 모델을 활용하는 전이학습을 살펴보았다. 다음으로 미디어 동영상 영역에서 활용도가 높은 과업을 객체탐지, 행동인식, 사건탐지, 동영상 요약, 동영상 분류 등 5개 대분류와 객체탐지, 안면인식, 표정인식, 랜드마크 인식, 상품인식, 행동인식, 자세추정, 이상탐지, 상황인식, 동영상 요약, 동영상 분류 등 11개 소분류로 제시했다. 이어 각 과업별 SOTA(state-of-the-art)와 벤치마크 데이터셋을 소개했다. 끝으로 이러한 모델의 학문적, 실무적 활용 가능성을 제시해보았다. 본 논문은 수식이나 프로그래밍에 대한 지식이 없이 미디어 연구자나 미디어 서비스 기획자가 비전 분야 딥러닝의 큰 흐름을 파악하고 관련 모델을 직접 활용하거나 컴퓨터공학 분야의 연구자 또는 개발자와 협업할 때 배경지식을 제공할 것으로 기대한다. 또한 비전 관련 딥러닝이 발전함에 따라 미디어 인공지능 기반 동영상 빅데이터 분석 시스템의 개발 가능성도 높아질 것이다.","Recently, media researchers employ deep learning models related to computer vision to perform automated content analysis of videos. Understanding deep learning models is also essential to AI(artificial intelligence) driven digital transformation in the media industry. In this paper, we reviewed computer vision-related deep learning models that are widely used for video analytics and generation. First, we looked at convolutional neural networks (CNNs) and recurrent neural networks (RNNs), which are widely used for classification, as well as generative adversarial network (GANs) and autoencoders (AEs) as generation models, and transfer learning using pre-training models. Following that, we proposed tasks in five major categories for which AI could be highly useful: object detection, action recognition, event detection, video summarization, and video classification. Then, for subtasks such as object detection, face recognition, facial expression recognition, landmark recognition, product recognition, pose estimation, anomaly detection, context recognition, video summarization, and video classification, we introduced state-of-the-arts (SOTAs) and benchmark datasets. Finally, the potential academic and practical applications of these models were discussed. We anticipate that media researchers or media service providers will understand the major trend of deep learning in computer vision and will be able to get knowledge when using deep learning models independently or collaborating with programmers."
GPR Image Recovery Effect on Faster R-CNNBased Buried Target Detection,2022,"['Buried Target Detection', 'Deep Learning', 'Faster R-CNN', 'Low Rank Data Recovery', 'Matrix Completion.']",국문 초록 정보 없음,"Measurements acquired through ground-penetrating radar (GPR) may contain missing information that needs to be recovered before the implementation of any post-processing method, such as target detection, since buried target detection methods fail and cannot produce desired results if the input GPR image contains missing information. This study proves that the recovery of missing information in a GPR image has a direct influence on the performance of subsequent target detection methods. Thus, state-of-the-art matrix completion methods are applied to the GPR image with missing information in both pixel- and column-wise cases with different missing rates, such as 30% and 50%. After the GPR image is successfully recovered, the faster region-based convolutional neural network (Faster R-CNN) target detection method is applied. The performance correlation between matrix completion accuracy and the target detection method’s confidence score is analyzed using both quantitative and visual results. The obtained results demonstrate the importance of GPR image recovery prior to any post-processing implementation, such as target detection."
장애인을 위한 영아 보육 도움 시스템 설계,2022,"['IoT', '인공지능', '영아 보육 시스템', 'YOLO', 'CNN']","본 논문은 4차 산업혁명의 핵심기술인 인공지능과 IoT를 이용해 장애인과 비장애인이 영아를 보육하는 데 있어서 도움을 줄 수 있는 시스템을 설계하였다. 본 시스템은 Raspberry pi를 기반으로 Raspberry pi의 여러 센서를 통해 실시간 영상, 음성, 온도 등 여러 가지 데이터를 수집한 뒤 음성데이터를 벡터화 시켜 CNN 분류 모델을 통해 울음소리를 감지하고 배고픔, 트림, 복통, 피곤, 불편 의 5가지 상태로 분류한다. 또한, YOLO 모델을 이용해 아기 얼굴 상태를 감지하여 질식사를 방지한다. 장애인을 위한 영아 보육 도움 시스템은 시각 장애인이나 청각 장애인 부모가 아이의 돌연사를 방지할 수 있게 도움을 준다.",다국어 초록 정보 없음
Paper Defects Recognition Based on Deformable Convolution,2022,"['Paper defects recognition', 'Faster R-CNN', 'deformable convolution']",국문 초록 정보 없음,다국어 초록 정보 없음
스펙트로그램을 이용한 기계의 이상상태 탐지 모델,2022,"['Spectrogram', 'Machines', 'Abnormal', 'LSTM', 'Predictive Maintenance', 'CNN']",국문 초록 정보 없음,"There are many methods for diagnosing abnormal conditions of machines. Among them we use a method using sound for detecting abnormalities of machines. Experimental data sets were collected at approximately 30 minutes intervals for 2 weeks. The collected data sets are converted into spectrogram images expressed by time, frequency and amplitude with a 5 second time step. In this paper, we propose a learning model created by combining Conv1D for image processing and LSTM for time series data processing to detect abnormal conditions of machines. The comparison test with the existing model combining CNN, Conv1D and GRU shows our method has a promising result."
주행성능 개인화를 위한 딥러닝 기반 운전자 상태 연구,2022,"['Facial Expression Recognition(FER', '얼굴표정인식)', 'Hidden Emotion Recognition(HER', '숨겨진 감정판단)', 'CNN(Convolutional Neural Networks)', 'DNN (Deep Neural Networks)', 'EDA(Electro Dermal Activity)']",국문 초록 정보 없음,"A Monitoring the driver’s condition is essential for intelligent vehicles, and recognizing the emotional state among them is one of most challenging and important task. To monitor the emotional state of driver, most works focus on the Facial Expression Recognition. However, there are many factors that prevent the driver from revealing emotions on his/her face while driving. To address this, we proposed a deep learning-based algorithm to recognize the real emotion hidden behind the expression. Proposed algorithm is consisted by FER and HER. The FER model refers to the state-of-the-art CNN structures to recognize the state of facial expression. The HER model fuses the recognized state of facial expression with bio-physiology signal, EDA, to recognize even the hidden emotional state of driver. For reliable results, we define the driver’s emotion categories and conduct human-in-the-loop experiments to acquire the data. From the experimental results, our fusing approach achieves 114% increase in accuracy compared to using only the facial expressions and achieves 86.8% recognition accuracy in recognizing the induced emotions to the driver in a driving situation."
거푸집 부재 인식을 위한 인공지능 이미지 분할,2022,"['Construction Formwork', 'Safety Management', 'Artificial Intelligence Model', 'Mask R-CNN', 'Image Segmentation', '거푸집', '안전관리', '인공지능모델', '마스크 R-CNN', '이미지 분할']",국문 초록 정보 없음,"Concrete formwork is a crucial component for any construction project. Artificial intelligence offers great potential to automate formwork design by offering various design options and under different criteria depending on the requirements. This study applied image segmentation in 2D formwork drawings to extract sheathing, strut and pipe support formwork elements. The proposed artificial intelligence model can recognize, classify, and extract formwork elements from 2D CAD drawing image and training and test results confirmed the model performed very well at formwork element recognition with average precision and recall better than 80%. Recognition systems for each formwork element can be implemented later to generate 3D BIM models."
Towards Low Complexity Model for Audio Event Detection,2022,"['Audio Event Detection', 'Spatial Drop', 'Separable 2D', 'Batch Normalization', 'VGG', 'CNN', 'Quantization', 'and Mel_Spectrogram']",국문 초록 정보 없음,"In our daily life, we come across different types of information, for example in the format of multimedia and text. We all need different types of information for our common routines as watching/reading the news, listening to the radio, and watching different types of videos. However, sometimes we could run into problems when a certain type of information is required. For example, someone is listening to the radio and wants to listen to jazz, and unfortunately, all the radio channels play pop music mixed with advertisements. The listener gets stuck with pop music and gives up searching for jazz. So, the above example can be solved with an automatic audio classification system. Deep Learning (DL) models could make human life easy by using audio classifications, but it is expensive and difficult to deploy such models at edge devices like nano BLE sense raspberry pi, because these models require huge computational power like graphics processing unit (G.P.U), to solve the problem, we proposed DL model. In our proposed work, we had gone for a low complexity model for Audio Event Detection (AED), we extracted Mel-spectrograms of dimension 128×431×1 from audio signals and applied normalization. A total of 3 data augmentation methods were applied as follows: frequency masking, time masking, and mixup. In addition, we designed Convolutional Neural Network (CNN) with spatial dropout, batch normalization, and separable 2D inspired by VGGnet [1]. In addition, we reduced the model size by using model quantization of float16 to the trained model. Experiments were conducted on the updated dataset provided by the Detection and Classification of Acoustic Events and Scenes (DCASE) 2020 challenge. We confirm that our model achieved a val_loss of 0.33 and an accuracy of 90.34% within the 132.50KB model size."
ArchShapesNet: a novel dataset for benchmarking architectural building information modeling element classification algorithms,2022,"['BIM (Building Information Modeling)', 'semantic enrichment', 'parametric augmentation', 'multi-view CNN']",국문 초록 정보 없음,"Recent studies in the domain of semantic enrichment have employed artificial intelligence (AI) approaches to distinguish and classify building information modeling (BIM) elements to check their conformance with open standard data formats. Training AI algorithms requires the development of well-balanced and robust datasets of BIM elements. However, collection is difficult as sources are limited to existing models and sample libraries. This study developed a parametric augmentation approach to create synthetic copies of BIM elements, and thus rapidly supplement manually collected samples. The approach was used to create ArchShapesNet, a dataset consisting of 11 common architectural elements with an equal size of 4,000 samples per class. Two multi-view convolutional neural networks (CNN), a geometric deep learning algorithm, were trained and tested separately on ArchShapesNet and an initial dataset with sample imbalances. Results showed significant improvement in the accuracy and F1 scores, providing evidence of the utility of ArchShapesNet. The size and scope of the dataset are considered to be the first of their kind and provide a benchmark for testing the semantic integrity of BIM models. The augmentation approach also provides a general framework to create custom datasets for different specialties in the Architectural Engineering and Construction industry."
균형적인 신체활동을 위한 맞춤형 AI 운동 추천 서비스,2022,"['1차원 컨볼루션', '합성곱 신경망', 'WISDM 데이터셋', '신체활동', 'AI 운동 추천 서비스', '1D Convolution', 'CNN', 'Physical Activity', 'WISDM dataset', 'AI Exercise Recommendation Service']","본 논문은 직종별 근무 환경에 따른 상대적 운동량을 고려한 맞춤형 AI 운동 추천 서비스 방법을 제안한다. 가속도 및 자이로 센서를 활용하여 수집된 데이터를 18가지 일상생활의 신체활동으로 분류한 WISDM 데이터베이스를 기반으로 전신, 하체, 상체의 3가지 활동으로 분류한 후 인식된 활동 지표를 통해 적절한 운동을 추천한다. 본 논문에서 신체활동 분류를 위해서 사용하는 1차원 합성곱 신경망(1D CNN; 1 Dimensional Convolutional Neural Network) 모델은 커널 크기가 다른 다수의 1D 컨볼루션(Convolution) 계층을 병렬적으로 연결한 컨볼루션 블록을 사용한다. 컨볼루션 블록은 하나의 입력 데이터에 다층 1D 컨볼루션을 적용함으로써 심층 신경망 모델로 추출할 수 있는 입력 패턴의 세부 지역 특징을 보다 얇은 계층으로도 효과적으로 추출할 수 있다. 제안한 신경망 모델의 성능 평가를 위해서 기존 순환 신경망(RNN; Recurrent Neural Network) 모델과 비교 실험한 결과 98.4%의 현저한 정확도를 보였다.",다국어 초록 정보 없음
Fire Image Classification Based on Convolutional Neural Network for Smart Fire Detection,2022,"['Fire image classification', 'Convolutional neural network', 'Fire detection', 'VGG 19', 'Accuracy']",국문 초록 정보 없음,"This study investigated the effect of the class number on the prediction performance of the convolutional neural network (CNN) classification model that is applied in fire detectors to reduce nuisance fire alarms by appropriately recognizing fire images including those of flames and smoke. A CNN model trained by transfer learning using five image datasets of flame, smoke, normal, haze, and light was realized and trained by altering the class number to generate the classification model. A total of three classification models were generated as follows: classification model 1 was trained using normal and fire images including flames and smoke; classification model 2 was trained using flame, smoke, and normal images; and classification model 3 was trained using flames, smoke, normal, and haze, and light images. A test image dataset independent of training was used to assess the prediction performance of the three classification models. The results indicate that the prediction accuracy for classification models 1, 2, and 3 were approximately 93.0%, 94.2%, and 97.3%, respectively. The performance of the predicted classification improved as the class number increased, because the model could learn with greater precision the features of the normal images that are similar to those of the fire images."
Extracting spatial features of fNIRS signal using a graph representation,2022,"['fNIRS', 'functional connectivity', 'graph convolution network (GCN)']",국문 초록 정보 없음,"Due to its solid ability to extract local spatial features from image, convolutional neural network (CNN) has been used frequently to extract spatial features from functional near infra-red spectroscopy (fNIRS) signal. To apply CNN to multi-channel fNIRS signal, the signal has to be converted to an image. However, 2-dimensional convolution is effective only when adjacent pixels share connectivity. In order to reduce the convolution of features from unrelated channels and leave correlated channels together, graph convolution network based on functional connectivity (FC) is proposed. Spatial features extracted from different types of graphs were compared using support vector machine (SVM). Feature extracted from functional connectivity-based graph showed better performance in classifying unseen data, while 2-D convolution like methods showed sign of overfitting."
기계학습에 의한 후두 장애음성 식별기의 성능 비교,2022,"['diagnosis', 'glottic cancer', 'vocal cords disorder', 'machine learning', 'convolutional neural network']",국문 초록 정보 없음,"This paper studies how to improve the identification rate of laryngeal disability speech data by convolutional neural network (CNN) and machine learning ensemble learning methods. In general, the number of laryngeal dysfunction speech data is small, so even if identifiers are constructed by statistical methods, the phenomenon caused by overfitting depending on the training method can lead to a decrease the identification rate when exposed to external data. In this work, we try to combine results derived from CNN models and machine learning models with various accuracy in a multi-voting manner to ensure improved classification efficiency compared to the original trained models. The Pusan National University Hospital (PNUH) dataset was used to train and validate algorithms. The dataset contains normal voice and voice data of benign and malignant tumors. In the experiment, an attempt was made to distinguish between normal and benign tumors and malignant tumors. As a result of the experiment, the random forest method was found to be the best ensemble method and showed an identification rate of 85%."
A SE Approach for Real-Time NPP Response Prediction under CEA Withdrawal Accident Conditions,2022,"['Recurrent Neural Network (RNN)', 'Long Short Term Memory (LSTM)', 'Gated Recurrent Unit (GRU)', 'Convolutional Neural Network (CNN)', 'Machine Learning (ML)', 'Best Estimate Plus Uncertainty (BEPU)']",국문 초록 정보 없음,"Machine learning (ML) data-driven meta-model is proposed as a surrogate model to reduce the excessive computational cost of the physics-based model and facilitate the real-time prediction of a nuclear power plant's transient response. To forecast the transient response three machine learning (ML) meta-models based on recurrent neural networks (RNNs); specifically, Long Short Term Memory (LSTM), Gated Recurrent Unit (GRU), and a sequence combination of Convolutional Neural Network (CNN) and LSTM are developed. The chosen accident scenario is a control element assembly withdrawal at power concurrent with the Loss Of Offsite Power (LOOP). The transient response was obtained using the best estimate thermal hydraulics code, MARS-KS, and cross-validated against the Design and control document (DCD). DAKOTA software is loosely coupled with MARS-KS code via a python interface to perform the Best Estimate Plus Uncertainty Quantification (BEPU) analysis and generate a time series database of the system response to train, test and validate the ML meta-models. Key uncertain parameters identified as required by the CASU methodology were propagated using the non-parametric Monte-Carlo (MC) random propagation and Latin Hypercube Sampling technique until a statistically significant database (181 samples) as required by Wilk's fifth order is achieved with 95% probability and 95% confidence level. The three ML RNN models were built and optimized with the help of the Talos tool and demonstrated excellent performance in forecasting the most probable NPP transient response. This research was guided by the Systems Engineering (SE) approach for the systematic and efficient planning and execution of the research."
안구 건조증 예방을 위한 AI 기반 생활습관 개선 시스템 연구,2022,"['dry eye syndrome', 'eye health lifestyle', 'eye blinking', 'artificial intelligence', 'convolutional neural network', 'deep learning 10 seconds', 'tear break-up time']","현대인들의 전자기기 사용량이 많아짐에 따라 잘못된 눈 건강 생활습관으로 인해 안구 건조증을 호소하는 사람들이 증가하는데, 안구 건조증은 눈 깜빡임의 적은 빈도수로 인한 눈물막 파괴가 주요 원인이다. 본 논문은 이미지 분석에 특화된 CNN(Convolutional) 딥러닝 모델을 활용하여 사용자의 눈 깜빡임을 인지하여 기록하고 생활습관 개선에 도움을 주는 시스템을 설계 구현한 내용을 기술한다. 본 시스템은 실시간으로 눈 깜빡임을 인지하고 10초 이내에 눈 깜빡임이 없을 시 알람을 주어 잘못된 생활습관을 확인하고 바른 생활습관을 유도하도록 하는 것이 목적이며 실시간으로 눈 깜빡이는 생활습관을 데이터 표와 그래프를 통해 확인하여 안구 건조증 예방에 도움을 준다.","As modern people use electronic devices, more and more people complain of dry eyes due to poor eye health lifestyle, which is mainly due to the small frequency of blinking. This paper describes the design and implementation of a system that recognizes, records, and helps improve lifestyle by using CNN (Convolutional) deep learning models specialized in image analysis. The purpose of this system is to recognize blinking in real time and to give an alarm if there is no blinking within 10 seconds to check the wrong lifestyle and induce the right lifestyle. In addition, it helps prevent dry eye syndrome by checking the blinking lifestyle in real time through data tables and graphs."
영유아와 청소년의 얼굴표정기반 감정인식 성능분석,2022,[],"코로나 바이러스-19 감염증 상황이 지속됨에 따라 영유아 비대면 상담이 증가하였다. 비대면이라는 제한된 환경에서, 보다 정확한 상담을 위해 영유아의 감정을 예측하는 보조도구로써 CNN 학습모델을 이용한 감정분석 결과를 활용할 수 있다. 하지만, 대부분의 감정분석 CNN 모델은 성인 데이터를 위주로 학습이 진행되므로 영유아의 감정인식률은 상대적으로 낮다. 본 논문에서는 영유아와 청소년 데이터의 감정분석 정확도 차이의 원인을 XAI 기법 중 하나인 LIME을 사용해 시각화하여 분석하고, 분석 결과를 근거로 영유아 데이터에 대한 감정인식 성능을 향상시킬 수 있는 방법을 제안한다.",다국어 초록 정보 없음
Conformer-CTC 기반 한국어 음성인식,2022,[],"본 논문은 Conformer 와 CTC 를 결합한 모델을 기반으로 한국어 음성인식을 제안한다. Conformer 는 광역 정보를 잘 표현하는 Transformer 와 지역정보를 잘 표현하는 CNN 을 결합한 모델이며, CTC 는 사전 정렬되지 않은 음성과 문자열의 대응관계를 정렬하며 학습하는 loss 함수이다. Conformer 와 CTC 를 결합하면 음성과 문자열의 사전 정렬없이 음성의 광역정보와 지역정보를 활용하여 음성인식을 할 수 있는 장점이 있다. 제안한 모델은 로그 스펙트로그램을 입력 받으며 CNN 을 통해 로그 스펙트로그램의 주파수와 시간 해상도를 줄인다. 그 후 Conformer 를 통해 음향 특징을 추출하며 CTC 를 이용하여 학습된다. 제안한 모델의 성능 평가를 위해 한국어 통화 기반 음성 말뭉치 데이터 셋인 ClovaCall-Base를 사용하여 학습과 테스트를 하였으며 테스트 결과 13.1%의 음절 오류율로 기존의 연구보다 우수한 성능을 보였다.",다국어 초록 정보 없음
위성 SAR 영상의 지상차량 표적 데이터 셋 및 탐지와 객체분할로의 적용,2022,"['합성 개구면 레이더', '표적 탐지', '객체분할', '영역 및 객체분할용 합성곱 신경망', '딥러닝', 'Synthetic Aperture Radar', 'Target Detection', 'Instance Segmentation', 'Mask R-CNN', 'Deep Learning']",국문 초록 정보 없음,"The advent of deep learning-based algorithms has facilitated researches on target detection from synthetic aperture radar(SAR) imagery. While most of them concentrate on detection tasks for ships with open SAR ship datasets and for aircraft from SAR scenes of airports, there is relatively scarce researches on the detection of SAR ground vehicle targets where several adverse factors such as high false alarm rates, low signal-to-clutter ratios, and multiple targets in close proximity are predicted to degrade the performances. In this paper, a dataset of ground vehicle targets acquired from TerraSAR-X(TSX) satellite SAR images is presented. Then, both detection and instance segmentation are simultaneously carried out on this dataset based on the deep learning-based Mask R-CNN. Finally, this paper shows the future research directions to further improve the performances of detecting the SAR ground vehicle targets."
비지역 희소 어텐션 메커니즘을 활용한 초해상화,2022,"['Super-resolution', 'Deep learning', 'Attention mechanism', 'NLSA', 'IMDN', 'CARN', 'OISR-LF-s', '초해상화', '딥러닝', '어텐션 메커니즘', 'NLSA', 'IMDN', 'CARN', 'OISR-LF-s']","딥러닝이 발전하면서 초해상화 기술은 단순 보간법(Interpolation)에서 벗어나 딥러닝을 활용해 발전하고 있다. 딥러닝을 사용한 초해상화 기술은 합성곱 신경망(Convolutional Neural Network, CNN) 기반의 연구가 일반적이지만, 최근에는 어텐션(Attention) 메커니즘을 활용한 초해상화 연구가 활발히 진행되고 있다. 본 논문에서는 어텐션 메커니즘 중 하나인 비지역 희소 어텐션(Non-Local Sparse Attention, NLSA)을 활용한 초해상화 성능 향상 방법을 제안한다. 실험을 통해 NLSA를 함께 활용하면 기존 초해상화 신경망 모델인 IMDN, CARN, OISR-LF-s의 성능이 향상되는 것을 확인할 수 있었다.","With the development of deep learning, super-resolution (SR) methods have tried to use deep learning mechanism, instead of using simple interpolation. SR methods using deep learning is generally based on convolutional neural networks (CNN), but recently, SR researches using attention mechanism have been actively conducted. In this paper, we propose an approach of improving SR performance using one of the attention mechanisms, non-local sparse attention (NLSA). Through experiments, we confirmed that the performance of the existing SR models, IMDN, CARN, and OISR-LF-s can be improved by using NLSA."
Comparative analysis of imaging diagnostic models for tubular basophilia and mineralization of kidney,2022,"['Artificial intelligence', 'Diagnosis', 'Classification modelsm', 'YOLOv4', 'Tubular basophilia', 'Mineralization']",국문 초록 정보 없음,"Background: Now that it is possible to efficiently classify and save tissue images of laboratory animals using wholeslide imaging, many diagnostic models are being developed through transfer learning with Convolutional Neural Network (CNN). In this study, transfer learning was performed to gain toxicopathological knowledge using CNN models such as InceptionV3 and Xception. For the classification of tubular basophilia and mineralization, two representative background lesions that commonly occur in toxicological studies, accuracies of diagnosis were compared using MobileNetV2, Xception and InceptionV3. For the simultaneous detection of the two lesions, the accuracy was analysed using You Only Look Once version 4 (YOLOv4).Results: The accuracy of the classification models was as follows: MobileNetV2 (epoch 50, accuracy: 98.57%) > Xception (epoch 70, accuracy: 97.47%) > InceptionV3 (epoch 70, accuracy: 89.62%). In the case of object detection, the accuracy of YOLOv4 was 98.62% at epoch 3000.Conclusions: Among the classification models, MobileNetV2 had the best accuracy despite applying a lower epoch than InceptionV3 and Xception. The object detection model, YOLOv4, accurately and simultaneously diagnosed tubular basophilia and mineralization, with an accuracy of 98.62% at epoch 3000."
스마트폰 녹음 여부 검출을 위한 딥러닝 기반 오디오 포렌식,2022,"['audio recording device forensics', 'mel-spectrogram', 'convolutional neural network', 'smartphone']",국문 초록 정보 없음,"Most of audio data used in recent crimes is mostly recorded through portable smartphones. Therefore, it is meaningful for forensic analysis to detect only audio data recorded using the smartphone among vast amounts of audio data. In this paper, based on a CNN model, we propose a forensic algorithm to detect whether or not audio data is recorded by a smartphone. Mel-spectrogram features were extracted by dividing the input audio into 10-second segments and applied to a CNN model that detects smartphone recording through training and testing. Experiments were conducted using the audio data collected by ourselves, and as a result, we achieved 94.98% detection accuracy for each segment and 95.40% detection accuracy for the entire audio."
차량 안전 제어를 위한 파티클 필터 기반의 강건한 다중 인체 3차원 자세 추정,2022,"['Human Pose Estimation(인체 자세 추정)', 'Sensor Fusion(센서 융합)', 'Convolutional Neural Network(합성곱 신경망)', 'Driver Monitoring System(운전자 모니터링 시스템)']",국문 초록 정보 없음,"In autonomous driving cars, 3D pose estimation can be one of the effective methods to enhance safety control for OOP (Out of Position) passengers. There have been many studies on human pose estimation using a camera. Previous methods, however, have limitations in automotive applications. Due to unexplainable failures, CNN methods are unreliable, and other methods perform poorly. This paper proposes robust real-time multi-human 3D pose estimation architecture in vehicle using monocular RGB camera. Using particle filter, our approach integrates CNN 2D/3D pose measurements with available information in vehicle. Computer simulations were performed to confirm the accuracy and robustness of the proposed algorithm."
Bioimage Analyses Using Artificial Intelligence and Future Ecological Research and Education Prospects: A Case Study of the Cichlid Fishes from Lake Malawi Using Deep Learning,2022,"['Animal detection', 'Artificial intelligence', 'Citizenscience', 'Deep learning', 'Education', 'Machine learning']",국문 초록 정보 없음,"Ecological research relies on the interpretation of large amounts of visual data obtained from extensive wildlife surveys, but such large-scale image interpretation is costly and time-consuming. Using an artificial intelligence (AI) machine learning model, especially convolution neural networks (CNN), it is possible to streamline these manual tasks on image information and to protect wildlife and record and predict behavior. Ecological research using deep-learning-based object recognition technology includes various research purposes such as identifying, detecting, and identifying species of wild animals, and identification of the location of poachers in real-time. These advances in the application of AI technology can enable efficient management of endangered wildlife, animal detection in various environments, and real-time analysis of image information collected by unmanned aerial vehicles. Furthermore, the need for school education and social use on biodiversity and environmental issues using AI is raised. School education and citizen science related to ecological activities using AI technology can enhance environmental awareness, and strengthen more knowledge and problem-solving skills in science and research processes. Under these prospects, in this paper, we compare the results of our early 2013 study, which automatically identified African cichlid fish species using photographic data of them, with the results of reanalysis by CNN deep learning method. By using PyTorch and PyTorch Lightning frameworks, we achieve an accuracy of 82.54% and an F1-score of 0.77 with minimal programming and data preprocessing effort. This is a significant improvement over the previous our machine learning methods, which required heavy feature engineering costs and had 78% accuracy."
U-Net과 cWGAN을 이용한 탄성파 탐사 자료 보간 성능 평가,2022,"['seismic data interpolation', 'machine learning', 'U-Net', 'cWGAN', 'ensemble', '탄성파 탐사 보간법', '기계학습', 'U-Net', 'cWGAN', '앙상블']","탄성파 탐사 자료 획득 시 자료의 일부가 손실되는 문제가 발생할 수 있으며 이를 위해 자료 보간이 필수적으로 수행된다. 최근 기계학습 기반 탄성파 자료 보간법 연구가 활발히 진행되고 있으며, 특히 영상처리 분야에서 이미지 초해상화에 활용되고 있는 CNN (Convolutional Neural Network) 기반 알고리즘과 GAN (Generative Adversarial Network) 기반 알고리즘이 탄성파 탐사 자료 보간법으로도 활용되고 있다. 본 연구에서는 손실된 탄성파 탐사 자료를 높은 정확도로 복구하는 보간법을 찾기 위해 CNN 기반 알고리즘인 U-Net과 GAN 기반 알고 리즘인 cWGAN (conditional Wasserstein Generative Adversarial Network)을 탄성파 탐사 자료 보간 모델로 사용하여 성능 평가 및 결과 비 교를 진행하였다. 이때 예측 과정을 Case I과 Case II로 나누어 모델 학습 및 성능 평가를 진행하였다. Case I에서는 규칙적으로 50% 트레 이스가 손실된 자료만을 사용하여 모델을 학습하였고, 생성된 모델을 규칙/불규칙 및 샘플링 비율의 조합으로 구성된 총 6가지 테스트 자 료 세트에 적용하여 모델 성능을 평가하였다. Case II에서는 6가지 테스트 자료와 동일한 형식으로 샘플링된 자료를 이용하여 해당 자료 별 모델을 생성하였고, 이를 Case I과 동일한 테스트 자료 세트에 적용하여 결과를 비교하였다. 결과적으로 cWGAN이 U-Net에 비해 높 은 정확도의 예측 성능을 보였으며, 정량적 평가지수인 PSNR과 SSIM에서도 cWGAN이 높은 값이 나타나는 것을 확인하였다. 하지만 cWGAN의 경우 예측 결과에서 추가적인 잡음이 생성되었으며, 잡음을 제거하고 정확도를 개선하기 위해 앙상블 작업을 수행하였다. Case II에서 생성된 cWGAN 모델들을 이용하여 앙상블을 수행한 결과, 성공적으로 잡음이 제거되었으며 PSNR과 SSIM 또한 기존의 개별 모델 보다 향상된 결과를 나타내었다.",다국어 초록 정보 없음
사전훈련된 딥러닝 네트워크를 활용한 이미지 기반 딥러닝 모델 설계,2022,"['Automatic Modulation Classification', 'Convolutional Neural Network', 'Cognitive Radio Networks', 'Predicted Accuracy', 'Computational Complexity']","본 논문에서는 인지 통신에 사용되는 자동 변조 분류를 위해 이미지 기반 딥러닝 모델을 설계하였다. 제안된설계 방식은 초기 신호 기반 딥러닝 모델과 이미지 기반 딥러닝 모델 2가지로 구분되며 딥러닝 네트워크 유형은Convolutional Neural Network (CNN)을 사용하였다. 신호 기반 딥러닝 모델 프레임 단위로 학습되도록 하였고각 프레임은 1024 신호 샘플로 구성하였다. 학습전 Root Mean Square (RMS) 방식을 통해 프레임을 정규화하였고 실수부와 허수부로 구분하여  × 크기로 입력하였다. 제안된 신호 기반 딥러닝 모델은 컨볼루션 레이어의필터 크기에 따른 정확도 성능에 대하여 분석한 다음  × 필터 크기 지정을 통해 예측성능을 최적화하였다. 이미지 기반 딥러닝 모델은 사전훈련된 신호 기반 딥러닝 네트워크를 사용하여 추출된 특징 데이터를 이미지로 변환하여 학습된 다음 각각의 변조 유형을 예측하도록 하였다. 추출된 특징은 신호 기반 딥러닝 네트워크의Fully-Connected layer를 통해  × 특징 크기로 추출하였으며 각 특징이 가지는 특징값은 –30 - +30 스케일범위에 따라 Red, Green, Blue (RGB) 이미지로 변환하였다. 제안된 모델의 예측 정확도 성능은 Signal-to-Noise Ratio (SNR) 10 dB에서 기존 ECNN, SCGNet 그리고 LCNN 보다 1.38%, 7.41% 그리고 4.05% 높은 예측 정확도를 보였으며 SNR 0 dB에서는 0.26%, 3.4% 그리고 1.13% 각각 높은 성능을 보였다.","In this paper, an image-based deep learning model is designed for Automatic Modulation Classification (AMC) in cognitive radio. The proposed design method consists of a signal-based deep learning model and an image-based deep learning model, and a Convolutional Neural Network (CNN) is used for the deep learning network type. The signal-based deep learning model is trained in units of a frame which is composed of 1024 signal samples. Before being used for training, the frame is normalized through the Root Mean Square (RMS) method, and the frame is dividied into the real part and the imaginary part. The proposed signal-based deep learning model is analyzed according to the filter size of the convolution layer and optimized by specifying  × filter size. The image-based deep learning model is trained through images that is from the extracted feature data using the pretrained signal-based deep learning network, and predicted each modulation type. The feature size is  ×, which is extracted through the Fully-Connected layer of the signal-based deep learning network, and the features are converted into Red, Green, and Blue (RGB) images according to the -30 - +30 scale range. The prediction performance of the proposed model shows 2.13%, 4.05% and 9.47% higher accuracy at Signal-to-Noise Ratio (SNR) 10 dB, and 2.12%, 3.4% and 4.26% higher accuracy at SNR 0 dB than the conventional models ECNN, SCGNet and MCNet, respectively."
A Deep Learning Architecture for Meningioma Brain Tumor Detection and Segmentation,2022,"['Meningioma', 'Tumor', 'Brain image', 'Sub bands']",국문 초록 정보 없음,"The meningioma brain tumor detection and segmentation method is a complex process due to its low intensity pixel profile. In this article, the meningioma brain tumor images were detected and tumor regions were segmented using a convolutional neural network (CNN) classification approach. The source brain MRI images were decomposed using the discrete wavelet transform and these decomposed sub bands were fused using an arithmetic fusion technique. The fused image was data augmented in order to increase the sample size. The data augmented images were classified into either healthy or malignant using a CNN classifier.Then, the tumor region in the classified meningioma brain image was segmented using an connection component analysis algorithm. The tumor region segmented meningioma brain image was compressed using a lossless compression technique. The proposed method stated in this article was experimentally tested with the sets of meningioma brain images from an open access dataset. The experimental results were compared with existing methods in terms of sensitivity, specificity and tumor segmentation accuracy."
딥러닝 기반 폴리에스터 섬유의 염색색상 결과예측 모형 개발,2022,"['폴리에스터 섬유', '딥러닝', '염색색상 예측', 'Polyester Fiber', 'Deep Learning', 'Dyeing Color Prediction']","섬유 소재의 염색은 기업별로 고유의 레시피와 공정으로 인하여 결과물 간의 차이가 존재할 뿐만 아니라 예측하기도 어려운 실정이다. 본 연구는 염색 공정에서의 색상구현 최적화를 위해 딥러닝 기반의 예측 모형을 개발하고자 시도되었다. 이를 위하여 딥러닝 기반 모형인 다층퍼셉트론, CNN 그리고 LSTM 모형을 선정하였다. 총 376건의 데이터 세트를 수집하여 3개의 예측 모형을 학습시켰다. 교차검증 방법을 이용하여 3개의 예측 모형에 대해 비교 및 분석하였다. LSTM 모형의 예측 결과에 대한 CMC(2:1) 색차의 평균이 가장 우수한 것으로 나타났다.","Due to the unique recipes and processes of each company, not only differences among the results of dyeing textile materials exist but they are also difficult to predict. This study attempted to develop a color prediction model based on deep learning to optimize color realization in the dyeing process. For this purpose, deep learning-based models such as multilayer perceptron, CNN and LSTM models were selected. Three forecasting models were trained by collecting a total of 376 data sets. The three predictive models were compared and analyzed using the cross-validation method. The mean of the CMC (2:1) color difference for the prediction results of the LSTM model was found to be the best."
객체 인식을 이용한 차량 모니터링 시스템,2022,"['실시간 객체 인식', '교통 정보 수집', 'YOLOv5', 'DeepSort', 'Ai 보드', 'real-time object detection', 'traffic data-collection', 'YOLOv5', 'AI board']","본 논문은 YOLOv5의 실시간 객체 인식을 이용하여 교통 상황을 모니터링하고, 신뢰성 있는 교통 정보를 수집하는 시스템을 설계한다. 설계된 시스템은 카메라 한 대와 AI 보드 한 대만을 사용하므로 이동 설치에 용이하고, 측정 장비 설치 시 전문인력을 필요로 하지 않으므로 기존 교통 정보 수집 시스템의 경제적 단점을 해결한다. 객체 인식 시에 YOLOv5를 사용하므로 순차적으로 필터를 움직이면서 영상을 처리하는 CNN 기법보다 속도와 정확도에서 높은 성능을 발휘한다. 따라서 신뢰도 높은 정보 수집이 가능할 것이며 수집된 정보를 자동으로 서버에저장한다. 이 시스템을 구현함으로써 장래 교통량 추정, 도로 계획 및 관리에 필요한 자료 수집에 유용하게 활용할 뿐만 아니라 효율적인 실시간 교통량 파악 및 시스템 비용 절감을 기대할 수 있다.","This paper designs a system that monitors traffic conditions and collects reliable traffic information using real-time object recognition of YOLOv5. The designed system uses only one camera and one AI board, making it easy to install on the move, and does not require professionals to install measuring equipment, solving the economic drawbacks of the existing traffic information collection system. Since YOLov5 is used for object recognition, it exhibits higher performance in speed and accuracy than CNN techniques that process images while moving filters sequentially. Therefore, reliable information collection will be possible, and the collected information is automatically stored in the server. By implementing this system, it is not only useful for estimating future traffic volume, collecting data necessary for road planning and management, but also expected to efficiently identify real-time traffic volume and reduce system costs."
SDR 플랫폼을 위한 딥러닝 기반의 무선 자동 변조 분류기술 연구,2022,"['Automatic modulation classification', 'deep learning', 'Software-defined radio', 'SCA', 'convolution neural network', 'input size scalable', 'self-replication padding']","무선 신호 인식 및 자동 변조 분류(Automatic Modulation Classification) 기술은 넓은 주파수 대역에서 다양한 무선 통신 서비스를 단일 단말에서 유연하게 이용 가능한 SDR(Software Defined Radio) 플랫폼의 핵심 요소 기술로 필요성이 높아지고 있다.최근에는 데이터 학습 기반의 딥러닝 기술을 기반으로 정확도가 향상된 여러 가지 자동 변조 분류 모델들이 제안되고 있다. 하지만,대부분의 연구는 모델에 입력되는 무선 신호의 길이가 고정된 경우에 초점을 맞추고 길이가 가변적인 시나리오를 고려하지 않고 있다. 본 연구에서는 SDR의 개방형 플랫폼의 요소 기술로써 임의의 무선 신호의 길이에 대해 변조 분류가 가능한 방법을 제안한다.이를 위해, 두 가지 입력 크기에 대해 학습된 Convolutional Neural Network(CNN) 기반의 주 모델(main model)과 하위 모델(small model)로 분류 시스템을 설계하고, 나머지 구간의 길이로 수신된 신호에 대해서는 자기 복제 패딩 기법으로 입력 샘플을증강시켜 변조 분류를 수행한다. 분류 성능 정확도 및 계산 복잡도의 비교분석을 위한 RadioML 2018.01A 데이터셋을 사용한 실험을 통해 제안하는 기법이 모든 신호 대 잡음비(Signal-to-Noise Ratio, SNR) 영역에서 기존 방식보다 높은 정확도를 제공하면서도 낮은 연산량을 필요함을 보였다.","Automatic modulation classification(AMC) is a core technique in Software Defined Radio(SDR) platform thatenables smart and flexible spectrum sensing and access in a wide frequency band. In this study, we propose asimple yet accurate deep learning-based method that allows AMC for variable-size radio signals. To this end, wedesign a classification architecture consisting of two Convolutional Neural Network(CNN)-based models, namelymain and small models, which were trained on radio signal datasets with two different signal sizes, respectively.Then, for a received signal input with an arbitrary length, modulation classification is performed by augmentingthe input samples using a self-replicating padding technique to fit the input layer size of our model. Experimentsusing the RadioML 2018.01A dataset demonstrated that the proposed method provides higher accuracy than theexisting methods in all signal-to-noise ratio(SNR) domains with less computation overhead."
Yolo-v4 기반 초저지연 차량 식별과 통행량 추적 정밀도 개선,2022,"['cooperative driving infra sensor', 'deep learning', 'object detection', 'object tracking', 'self driving', '협력주행 인프라 센서', '딥러닝', '객체 검출', '객체 추적', '자율주행']","자율주행 기술의 고도화 및 상용화에 따라 차량 자체 센서의 인지 범위의 확장을 위한 인프라 기반 협력주행기술에 대한 수요가 증가하고 있다. 특히 노변에 설치되어 교통 상황을 실시간으로 파악하고 기록하여 차량에 제공할 수 있는 엣지 인프라 기술 연구가 활발하게 진행되고 있으며, 정보 수집을 위한 센서에 대한 연구가 활발한 상황이다. 이러한 흐름에 따라, 최근 CNN 기반의 영상분석을 통한 교통정보 수집 기술에 대한 연구도 활발히 진행되고 있는데, 이러한 CNN 기반의 알고리즘은 영상 내의 외양 특징을 기반으로 개별 객체를 식별할 수 있어 자율주행 자동차에서 인식하지 못하는 도로상의 객체 정보를 제공할 수 있어 인프라 구축에 활용이 가능할 것으로 주목받고 있다. 하지만 기존 C-ITS 사업 대부분은 딥러닝 알고리즘의 높은 요구 연산량으로 인하여 영상분석을 현장이 아닌 센터의 높은 사양 서버에서 처리하고 있는데, 이는 인프라 시스템에서의 정보 제공 지연에 따른 사고의 발생 위험을 증대시킬 위험이 있다. 따라서 이러한 위험을 최소화하기 위해서는 센터가 아닌 노변에서의 실시간 영상분석을 통해 통신 지연을 최소화할 필요가 있다. 본 연구에서는 노변에 위치하여 실시간으로 영상을 분석하여 도로에 위치한 객체 정보를 산출할 수 있는 차량검지 시스템을 설계하였으며, 알고리즘의 노변 환경 적용을 위해 신경망의 구성을 간소화하여 딥러닝 연산량을 줄일 수 있는 방법을 제시한다.",다국어 초록 정보 없음
A novel 3D-Convolution Neural Network for Human Interaction Recognition in videos,2022,"['3D Convolution Neural Network', 'Deep Neural Network', 'Human Action Recognition', 'Human Interaction Recognition', '3D 컨볼루션 신경망', '심층 신경망', '인간 행동 인식', '인간 상호 작용 인식']",국문 초록 정보 없음,"Human Interaction Recognition (HIR) has already been perceived rapid progress same as human action and activity recognition. In HIR, we intend to highlight the problem of human-to-human interaction recognition in videos by exploring the long term inter-related dynamics between multiple humans. In order to understand the human-to-human interaction precisely, HIR system requires a robust feature extraction and selection method based on videos. In this paper, we propose a novel 3D convolutional neural network (3D CNN) followed by a fully connected block, to wisely trace human to human interactions in videos. We feed our proposed model with 15 sequence of video frames to our novel 3D CNN architecture which extracts deep features from all the sequences and then pass those sequences to the fully connected block to boost our efficiency. Our proposed network outperformed the existing state-of-the-art methods by accomplishing extraordinary recognition accuracy on two benchmark datasets, UT-I and TV Human Interaction dataset i.e., 84% and 74% overall and improved from the state-of-the-art techniques. Our proposed network can also be applicable to other numerous multimedia contents and security applications such as video-based learning, service combats, medical futurists, interactive gaming, and surveillance systems."
청각장애인을 위한 인공지능 헤드폰 설계,2022,"['인공지능 헤드폰', '소리 분류', '인공지능', '키워드 인식', '진동 코드', '합성곱 신경망', 'AI headphone', 'Sound Source Classification', 'Artificial Intelligence', 'Keyword Recognition', 'Vibration Code', 'Convolution Neural Network']","이 논문에서는 청각장애인을 위하여 시야 밖에서 발생하는 위험 환경 소리(사이렌, 자동차경적, 비명, 총소리, 공사장 소음 등) 및 특정 음성 키워드(본인 이름, 조심하세요! 등)가 인식이 되면 진동 코드로 알려주어 사고 노출 위험성감소와 편의성을 높여주는 인공지능 헤드폰을 제안하였다. 웨어러블 기기에 걸맞게 저전력 및 휴대가 가능하도록 임베디드PC(Raspberry Pi 4B)에서 동작이 가능한 20종류의 소리를 분류할 수 있는 합성곱 신경망(CNN)기반 네트워크를 제안하였다. 제안한 소리 인식기는 평균 약 95.14% 인식률을 보였으며, 5.12초 길이의 음성 데이터가 라즈베리파이4B 상에서 평균 약 0.139초에 실행되어 실시간 처리가 가능함을 확인하였다.","We designed an artificial intelligence (AI) headphone for hearing impaired people and proposed a convolution neural network (CNN)-based sound classifier with a low computational network that can run on an embedded PC (Raspberry Pi 4B) in real-time. Because our AI headphone can classify 20 types of dangerous or environmental sounds (e.g., siren, car horn, scream, gunshot, etc.) and recognize specific voice keywords (e.g., person name, be careful!, stop!, etc.), it can assist hearing impaired people in reducing the risk of accident exposure and improving convenience. In addition, we use vibration codes to notify the hearing impaired person of detected information to the vibration motors attached to both sides of the headphone. We confirm that our proposed sound classifier achieves an average accuracy rate of approximately 95.14%, and enables real-time processing on the Raspberry Pi 4B because it requires an average computation time of approximately 0.139s with audio recording data for 5.12s."
MBConv 블록 기반 Ni-Ti 합금의 표면연마 이미지 분류모델,2022,"['Mobile Inverted Bottlenet Convolution(모바일 반전 합성곱 신경망)', 'TransientStructural Analysis(과도 구조 해석)', 'Surface Finishing Characteristic(표면가공성)']",국문 초록 정보 없음,"This study suggested a magnetic transporter rotational finishing process to improve the surface integrity of Ni-Ti alloy. In order to predict the effect of surface finishing characteristics, contact time distribution on the workpiece surface under the different process parameters was examined by a simulation. Based on the simulated data, the surface finishing characteristic was scored based on contact time, contact distribution, and impulse. Also, image classification was carried out by using a convolutional neural network(CNN) based on the MBConv block. As a result, the CNN model based on the MBConv block achieved excellent performance for classification accuracy with 98% and 94% of train datasets and validation datasets, respectively."
그룹 집중 기술로 개선된 Trans-Unet기반 단일 영상 연무제거 신경망,2022,"['Computer vision', 'Image dehazing', 'Vision transformer', 'Unet', 'Group attention block']",국문 초록 정보 없음,다국어 초록 정보 없음
MobileNet을 이용한 사람 음성 구간의 오디오 축약 방법,2022,"['audio deduction', 'voice activity detection', 'classification', 'MFCC', 'mobileNet', 'deep learning']","다양한 스마트 기기에서 오디오 정보들을 수집하고 활용하는 응용들이 개발되고 있다. 방대한 오디오 중에서 사람 음성은 중요한 정보로 오디오에서 음성 구간만 축약하는 것은 유용하다. 본 논문에서는 MobileNet을 사용하여 오디오에서 비음성 구간들을 제외한 음성 구간만을 축약시키는 방법을 제안한다. 입력 오디오를 3초 단위 세그먼트로 구분하고, MFCC 특징을 추출하여 사람 음성 판별에 활용하였다. 특히, 기존에 많이 사용되는 CNN 모델은 구조가 깊어져서 연산량이 증가하는 문제가 있어서, 연산량 최적화에 중점을 둔 MobileNet을 활용하였다. 국내외 여러 데이터셋과 자체적으로 수집한 오디오를 사용하여 실험을 수행하였고, 그 결과 세그먼트 단위로 93.92% 음성 검출 정확도와 전체 오디오에 대해 88.05%의 축약 정확도를 달성하였다.","Applications for collecting and utilizing audio information from various smart devices are being developed. Human voice is important data among vast amounts of audio, and it is useful to deduct only voice activity segments from audio. This paper proposes a method to contract only voice activity segments excluding non-speech segments using MobileNet. Input audio is divided into 3 second segments and MFCC features are extracted and used for voice detection. A CNN model widely used in the past has a problem of increasing the amount of computation due to its deep structure. Therefore, MobileNet focused on optimizing the amount of computation is used. Experiments were performed using domestic and foreign datasets and audio collected by ourselves. As a result, we achieved the voice detection accuracy of 93.92% for each segment and the reduction accuracy of 88.05% for the entire audio."
3D Convolutional with Attention for Action Recognition,2022,"['Action Recognition', 'Attention Model', 'Gating', 'Deep Neural Network']",국문 초록 정보 없음,"Human action recognition is one of the challenging tasks in computer vision. The current action recognition methods use computationally expensive models for learning spatio-temporal dependencies of the action. Models utilizing RGB channels and optical flow separately, models using a two-stream fusion technique, and models consisting of both convolutional neural network (CNN) and long-short term memory (LSTM) network are few examples of such complex models. Moreover, fine-tuning such complex models is computationally expensive as well. This paper proposes a deep neural network architecture for learning such dependencies consisting of a 3D convolutional layer, fully connected (FC) layers, and attention layer, which is simpler to implement and gives a competitive performance on the UCF-101 dataset. The proposed method first learns spatial and temporal features of actions through 3D-CNN, and then the attention mechanism helps the model to locate attention to essential features for recognition."
Deep learning-based apical lesion segmentation from panoramic radiographs,2022,"['Artificial Intelligence', 'Deep Learning', 'Periapical Periodontitis', 'Radiography', 'Panoramic']",국문 초록 정보 없음,"Purpose: Convolutional neural networks (CNNs) have rapidly emerged as one of the most promising artificial intelligence methods in the field of medical and dental research. CNNs can provide an effective diagnostic methodology allowing for the detection of early-staged diseases. Therefore, this study aimed to evaluate the performance of a deep CNN algorithm for apical lesion segmentation from panoramic radiographs.Materials and Methods: A total of 1000 panoramic images showing apical lesions were separated into training (n = 800, 80%), validation (n = 100, 10%), and test (n = 100, 10%) datasets. The performance of identifying apical lesions was evaluated by calculating the precision, recall, and F1-score.Results: In the test group of 180 apical lesions, 147 lesions were segmented from panoramic radiographs with an intersection over union (IoU) threshold of 0.3. The F1-score values, as a measure of performance, were 0.828, 0.815, and 0.742, respectively, with IoU thresholds of 0.3, 0.4, and 0.5.Conclusion: This study showed the potential utility of a deep learning-guided approach for the segmentation of apical lesions. The deep CNN algorithm using U-Net demonstrated considerably high performance in detecting apical lesions."
딥러닝을 활용한 반도체 웨이퍼 불량 유형 구분 모델에 관한 연구,2022,[],"기존 산업현장에서는 반도체 웨이퍼 맵을 직접 확인하여 불량을 선별하였다. 육안을 통한 웨이퍼 선별과정은 폭증하는 시장의 수요를 충족시킬 수 없다. 따라서 인간보다 신속‧ 정확한 반도체 웨이퍼 불량을 검출하여, 자동화에 기여할 수 있는 AI 기술을 제시한다. 인공지능 모델의 입력 데이터로는 생성적 대립신경망(GAN)을 통해 다양한 유형의 균형 있는 실제로 수집된 웨이퍼 맵을 사용하였다. 반도체 웨이퍼 불량 유형 구분을 위해 다층퍼셉트론(MLP)과 합성곱 신경망(CNN)을 기반으로 한, 2가지 인공지능 모델을 고안하였고, 실험 결과 CNN 모델이 정확도가 평균 6.4% 더 높았음을 확인했다.",다국어 초록 정보 없음
Deep learning-based apical lesion segmentation from panoramic radiographs,2022,"['Artificial Intelligence', 'Deep Learning', 'Periapical Periodontitis', 'Radiography', 'Panoramic']",국문 초록 정보 없음,"Purpose: Convolutional neural networks (CNNs) have rapidly emerged as one of the most promising artificial intelligence methods in the field of medical and dental research. CNNs can provide an effective diagnostic methodology allowing for the detection of early-staged diseases. Therefore, this study aimed to evaluate the performance of a deep CNN algorithm for apical lesion segmentation from panoramic radiographs. Materials and Methods: A total of 1000 panoramic images showing apical lesions were separated into training (n=800, 80%), validation (n=100, 10%), and test (n=100, 10%) datasets. The performance of identifying apical lesions was evaluated by calculating the precision, recall, and F1-score. Results: In the test group of 180 apical lesions, 147 lesions were segmented from panoramic radiographs with an intersection over union (IoU) threshold of 0.3. The F1-score values, as a measure of performance, were 0.828, 0.815, and 0.742, respectively, with IoU thresholds of 0.3, 0.4, and 0.5. Conclusion: This study showed the potential utility of a deep learning-guided approach for the segmentation of apical lesions. The deep CNN algorithm using U-Net demonstrated considerably high performance in detecting apical lesions."
RGB영상을 이용한 딥러닝 기반 성숙기 잡초 초종 분류모델 개발,2022,"['딥러닝', '분류 모델', '잡초', '영상처리']","작물 재배 시 잡초의 발생은 작물의 생장을 방해하는 주요 요인 중 하나이다. 잡초의 정확한 진단은 적절한 방제 조치를 결정하여 농업 생산량 향상에 직접적인 영향을 끼칠 수 있다. 그러나 잡초를 진단하는 작업은 많은 지식을 요구하여 일반 농업인이 적절한 방제 조치를 취하는데 많은 금전적 시간적 자원을 소모할 것으로 판단된다.합성곱신경망(Convolutional Neural Network, CNN)은 영상 처리 기술 분야에서 이러한 분류 문제에 대해 해결책을 제공할 수 있는 딥러닝 기술이다. 본 연구에서는 RGB 센서를 이용해 잡초 이미지 데이터를 취득한 뒤 이를 토대로 CNN 분류기 모델을 학습시켜 잡초의 진단을 수행하였다. 모델의 성능 평가 지표로는 정확도를 이용하였으며 6 종류의 분류 모델을 학습시켜 각 모델의 최대 분류 정확도를 비교하였다. 이를 위해 정확도에 직접적으로 영향을 미치는 하이퍼파라미터인 학습률에 대해 최적값을 선정하여 학습을 진행하였다.",다국어 초록 정보 없음
Pneumonia Detection from Chest X-ray Images Based on Sequential Model,2022,"['X-ray images', 'pneumonia detection', 'image enhance']",국문 초록 정보 없음,"Pneumonia is a form of acute respiratory infection that affects the lungs. According to the World Health Organization, pneumonia is the leading cause of death for children worldwide. As a result, pneumonia was the top killer of children under the age of five years old in 2015, which is 15% of all deaths worldwide. In this paper, we used CNN model architectures to compare between the result of proposed a CNN method with VGG based model architecture. The model's performance in detecting pneumonia shows that the proposed model based on VGG can classify normal and abnormal X-rays effectively and more accurately than the proposed model used in this paper."
딥러닝 기반의 핵의학 폐검사 분류 모델 적용,2022,"['컨볼루션 신경망', '딥러닝', '폐 신티그라피', '분류-활성화 맵', '핵의학', 'Convolutional neural network', 'Deep learning', 'Lung scintigraphy', 'Class activation map', 'Nuclear medicine']",국문 초록 정보 없음,"The purpose of this study is to apply a deep learning model that can distinguish lung perfusion and lung ventilation images in nuclear medicine, and to evaluate the image classification ability. Image data pre-processing was performed in the following order: image matrix size adjustment, min-max normalization, image center position adjustment, train/validation/test data set classification, and data augmentation. The convolutional neural network(CNN) structures of VGG-16, ResNet-18, Inception-ResNet-v2, and SE-ResNeXt-101 were used. For classification model evaluation, performance evaluation index of classification model, class activation map(CAM), and statistical image evaluation method were applied. As for the performance evaluation index of the classification model, SE-ResNeXt-101 and Inception-ResNet-v2 showed the highest performance with the same results. As a result of CAM, cardiac and right lung regions were highly activated in lung perfusion, and upper lung and neck regions were highly activated in lung ventilation. Statistical image evaluation showed a meaningful difference between SE-ResNeXt-101 and Inception-ResNet-v2. As a result of the study, the applicability of the CNN model for lung scintigraphy classification was confirmed. In the future, it is expected that it will be used as basic data for research on new artificial intelligence models and will help stable image management in clinical practice."
피로도 측정을 위한 정면 얼굴 영상 분석,2022,"['Fatigue measurement', 'Video analysis', 'Migration', 'Video classification', 'Deep learning', 'Machine learning', '피로도 측정', '영상 분석', '영상 분류', '딥러닝', '머신러닝']","사람이 느끼는 피로는 다양한 생체신호로부터 측정이 가능한 것으로 알려져 있으며, 기존 연구는 질병과 관련된 심각한 피로수준을 산정하는데 주된 목적을 두고 있다. 본 연구에서는 피실험자의 영상을 이용하여 딥러닝 기반의 영상 분석 기술을 적용, 피로 여부를 판단하기 위한 모델을 제안한다. 특히 화상 분석에서 통상적으로 사용되는 객체 인식, 요소 추출과 함께 영상 데이터의 시계열적 특성을 고려하여 방법론을 교차한 3개 분석모델을 제시했다. 다양한 피로상황에서 수집된 정면 얼굴 영상 데이터를 이용하여 제시된 모델을 실험하였으며, CNN 모델의 경우 0.67의 정확도로 피로 상태를 분류할 수 있어 영상 분석 기반의 피로 상태 분류가 유의미하다고 판단된다. 또한 모델별 학습 및 검증 절차 분석을 통해 영상 데이터 특성에 따른 모델 적용방안을 제시했다.","We can sense somebody’s feeling fatigue, which means that fatigue can be detected through sensing human biometric signals. Numerous researches for assessing fatigue are mostly focused on diagnosing the edge of disease-level fatigue. In this study, we adapt quantitative analysis approaches for estimating qualitative data, and propose video analysis models for measuring fatigue state. Proposed three deep-learning based classification models selectively include stages of video analysis: object detection, feature extraction and time-series frame analysis algorithms to evaluate each stage’s effect toward dividing the state of fatigue. Using frontal face videos collected from various fatigue situations, our CNN model shows 0.67 accuracy, which means that we empirically show the video analysis models can meaningfully detect fatigue state. Also we suggest the way of model adaptation when training and validating video data for classifying fatigue."
딥러닝 기반 지하 공동구 내 소화기 객체 탐지 모델 개발,2022,"['지하공동구', '딥러닝', '객체검출', '소화기', '디지털트윈', 'Underground Utility Tunnel', 'Deep Learning', 'Object Detection', 'Fire Extinguisher', 'Digital Twin']","연구목적: 본 논문은 지하공동구 내 CCTV에서 촬영된 영상에서 소화기를 탐지하기 위해 딥러닝 모델을 개발하는데 목적이 있다. 연구방법:  딥러닝 기반 지하공동구 내 소화기 탐지를 위해 다양한 소화기 이미지를 수집하였으며  CNN 알고리즘을 기반으로 하여 One-stage Detector 방식을 적용한 모델을 개발하였다.   연구결과:  지하공동구 내 CCTV 영상을 통해 10m 이내의 거리에서 촬영되는 소화기의 검출율은 96%이상으로 우수한 검출율을 보여준다.  다만 10m 이상의 거리에서는 육안으로도 확인하기 힘든 상태로, 소화기 객체 검출율이 급격하게 낮아지는 것을 확인하였다. 결론: 본 논문은 지하공동구 내 소화기 객체를 검출하는 모델을 개발하였으며, 해당 모델이 높은 성능을 보여 지하공동구 디지털트윈 모델 연동에 활용할 수 있을 것으로 판단된다.","Purpose: The purpose of this paper is to develop a deep learning model to detect fire extinguishers in images taken from CCTVs in underground utility tunnels. Method: Various fire extinguisher images were collected for detection of fire extinguishers in the running-based underground utility tunnel, and a model applying the One-stage Detector method was developed based on the CNN algorithm. Result: The detection rate of fire extinguishers photographed within 10m through CCTV video in the underground common area is over 96%, showing excellent detection rate. However, it was confirmed that the fire extinguisher object detection rate drops sharply at a distance of 10 m or more, in a state where it is difficult to see with the naked eye. Conclusion: This paper develops a model for detecting fire extinguisher objects in underground common areas, and the model shows high performance, and it is judged that it can be used for underground common area digital twin model synchronizing."
Feasibility of a deep learning-based diagnostic platform to evaluate lower urinary tract disorders in men using simple uroflowmetry,2022,"['Artificial intelligence', 'Bladder outlet obstruction', 'Detrusor underactivity', 'Lower urinary tract symptoms']",국문 초록 정보 없음,"Purpose: To diagnose lower urinary tract symptoms (LUTS) in a noninvasive manner, we created a prediction model for bladder outlet obstruction (BOO) and detrusor underactivity (DUA) using simple uroflowmetry. In this study, we used deep learning to analyze simple uroflowmetry.Materials and Methods: We performed a retrospective review of 4,835 male patients aged ≥40 years who underwent a urodynamic study at a single center. We excluded patients with a disease or a history of surgery that could affect LUTS. A total of 1,792 patients were included in the study. We extracted a simple uroflowmetry graph automatically using the ABBYY Flexicapture® image capture program (ABBYY, Moscow, Russia). We applied a convolutional neural network (CNN), a deep learning method to predict DUA and BOO. A 5-fold cross-validation average value of the area under the receiver operating characteristic (AUROC) curve was chosen as an evaluation metric. When it comes to binary classification, this metric provides a richer measure of classification performance. Additionally, we provided the corresponding average precision-recall (PR) curves.Results: Among the 1,792 patients, 482 (26.90%) had BOO, and 893 (49.83%) had DUA. The average AUROC scores of DUA and BOO, which were measured using 5-fold cross-validation, were 73.30% (mean average precision [mAP]=0.70) and 72.23% (mAP=0.45), respectively.Conclusions: Our study suggests that it is possible to differentiate DUA from non-DUA and BOO from non-BOO using a simple uroflowmetry graph with a fine-tuned VGG16, which is a well-known CNN model."
전력 사용량 데이터 패턴 분석을 위한 시계열 이미지 생성 방안 연구,2022,"['시계열 데이터', '시계열 이미지', '패턴 분석', '데이터 분류', '콘볼루션 신경망', 'Time Series Data', 'Time Series Image', 'Analyzing Patterns', 'Classification', 'Convolutional Neural Networks']",국문 초록 정보 없음,"To analyze the pattern of time series data, statistical techniques such as Principal Component Analysis (PCA) or autoencoder are used, or features of time series data are utilized based on deep learning models such as Recurrent Neural Network (RNN). However, it is difficult to expect good performance only with simple statistical techniques or RNN-based deep learning models because the environment and causes in which the data is recorded are not simple and various variables affect it. In this paper, we propose a method to image time series data to classify power data using Convolutional Neural Network (CNN)-based deep learning models, which are binary classification models of representative images. To train the model of proposed method, a total 85 images were used by generating images of power usage data for each building every day, and they were binary classified as weekday or weekend data. Recurrence Plot (RP), Gramian Angular Field (GAF), and Markov Transition Field (MTF) algorithms were used as methods for imaging. All time series image-based models showed equal or higher accuracy than conventional LSTM-based models, and among imaging-based CNN models, imaging methods with MTF algorithms derived the highest F1-Score (0.96)."
딥러닝 기반의 가금류 객체 탐지 알고리즘,2022,"['스마트팜', '딥러닝', '객체 검출', '영상 분석', '욜로', 'Smart Farm', 'Deep Learning', 'Object Detection', 'Image Analysis', 'YOLO']","가금의 평균 체중을 구하기 위해서는 닭이 저울 위로 올라가면 측정된 무게 값 데이터를 쌓아 원시 데이터로 닭의 성장 그래프를 그려 이를 예측한다. 하지만 저울에 닭이 여러 마리가 올라가 무게에 편차가 발생하여 평균 체중 예측에 혼란을 준다. 저울의 고도화와 성능검증, 가금의 평균 체중 예측값을 더 정확하게 교정하기 위해 가금의 개체 수 측정하는 것을 목적으로 객체 인식 모델을 비교하는 실험을 진행한다. 연구 결과 Modified YOLOv5가 98.8%, YOLOv5가 98.5%, YOLOv4가 96%, Mask R-CNN가 90%의 정확도를 보였다. 속도는 Modified YOLOv5가 33분 32초, YOLOv5가 25분 40초, YOLOv4가 66분 67초, Mask-RCNN가 172분 8초가 걸렸다. YOLOv5가 가장 빠른 검출 속력을 보였지만 Modified YOLOv5가 가장 높은 정확도를 보여 닭 개체에 가장 정확한 객체 검출 모델임을 알 수 있었다. 향후 객체 인식 모델을 보완하여 좀 더 정밀한 가금의 개체 수를 측정하고 결과 오차에 대해서 개선할 계획이다.","In order to obtain the average weight of a poultry, when the chicken goes up on the scale, it accumulates the measured weight value data and draws a growth graph of the chicken with raw data to predict it. However, several chickens rise on the scale, causing variations in weight, which confuses average weight prediction. Experiments are conducted to compare object recognition models with the aim of measuring the number of individuals to accurately correct the scale's advancement and performance verification, and the average weight prediction. As a result of the study, Modified YOLOv5 98.8%, YOLOv5 98.5%, YOLOv4 96%, and Mask R-CNN showed 90%. The speed took 33m 32s Modified YOLOv5, 25m 40s YOLOv5, 66m 67s YOLOv4, and 172m 8s for Mask-RCNN. Although YOLOv5 showed the fastest detection speed, Modified YOLOv5 showed the highest accuracy, indicating that it was the most accurate object detection model for chicken objects. In the future, we plan to supplement the object recognition model to measure the population of more precise poultry and improve it against the result error."
Prediction of the composition of urinary stones using deep learning,2022,"['Artificial intelligence', 'Deep learning', 'Endoscopy', 'Machine learning', 'Urolithiasis']",국문 초록 정보 없음,"Purpose: This study aimed to predict the composition of urolithiasis using deep learning from urinary stone images.Materials and Methods: We classified 1,332 stones into 31 classes according to the stone composition. The top 4 classes with a frequency of 110 or more (class 1: calcium oxalate monohydrate [COM] 100%, class 2: COM 80%+struvite 20%, class 3: COM 60%+calcium oxalate dihydrate [COD] 40%, class 4: uric acid 100%) were selected. With the 965 stone images of the top 4 classes, we used the seven convolutional neural networks (CNN) to classify urinary stones and compared their classification performances.Results: Among the seven models, Xception_Ir0.001 showed the highest accuracy, precision, and recall and was selected as the CNN model to predict the stone composition. The sensitivity and specificity for the 4 classes by Xception_Ir0.001 were as follows: class 1 (94.24%, 91.73%), class 2 (85.42%, 96.14%), class 3 (86.86%, 99.59%), and class 4 (94.96%, 98.82%). The sensitivity and specificity of the individual components of the stones were as follows. COM (98.82%, 94.96%), COD (86.86%, 99.64%), struvite (85.42%, 95.59%), and uric acid (94.96%, 98.82%). The area under the curves for class 1, 2, 3, and 4 were 0.98, 0.97, 1.00, and 1.00, respectively.Conclusions: This study showed the feasibility of deep learning for the diagnostic ability to assess urinary stone composition from images. It can be an alternative tool for conventional stone analysis and provide decision support to urologists, improving the effectiveness of diagnosis and treatment."
AIoT 기반 고위험 산업안전관리시스템 인공지능 연구,2022,"['인공지능 사물인터넷', '복합 센서 디바이스', '블루투스 메쉬 네트워크', '경량 딥러닝', 'AIoT', 'Complex sensor device', 'BLE Mesh Network', 'Lightweight Deep Learning']","정부는 2021년 1월에 '중대재해처벌법'을 제정 공포하여, 이 법을 시행하고 있다. 하지만, 2021년 산업재해 사고자수가 전년 동기 대비 10.7% 증가하였다. 따라서, 산업 현장에서는 안전대책이 시급한 현실이다. 본 연구에서는 통신 환경이 열악한 고위험 산업현장의 안전관리를 위하여 BLE Mesh 네트워킹 기술을 적용한다. 복합 센서 AIoT 디바이스로 가스 센싱값, 음성, 모션값을 실시간으로 수집하여, 인공지능 LSTM 알고리즘과 CNN 알고리즘을 통해 정보값을 분석하여 위험 상황을 인식하고, 서버에 전송한다. 서버에서는 전송 받은 위험정보를 실시간으로 모니터링 하여 즉각적인 구호조치가 수행되도록 한다. 본 연구에서 제안하는 AIoT 디바이스와 안전관리 시스템을 고위험군 산업현장에 적용하므로써, 산업재해를 최소화하고 사회안전망 확대에도 기여할 것이다.","The government enacted and promulgated the 'Severe Accident Punishment Act' in January 2021 and is implementing this law. However, the number of occupational accidents in 2021 increased by 10.7% compared to the same period of the previous year. Therefore, safety measures are urgently needed in the industrial field. In this study, BLE Mesh networking technology is applied for safety management of high-risk industrial sites with poor communication environment. The complex sensor AIoT device collects gas sensing values, voice and motion values ​​in real time, analyzes the information values ​​through artificial intelligence LSTM algorithm and CNN algorithm, and recognizes dangerous situations and transmits them to the server. The server monitors the transmitted risk information in real time so that immediate relief measures are taken. By applying the AIoT device and safety management system proposed in this study to high-risk industrial sites, it will minimize industrial accidents and contribute to the expansion of the social safety net."
훈련 및 검증 성능 개선을 위한 텐서플로우 병렬 처리 기법,2022,"['멀티 쓰레드', '딥 러닝', '텐서플로우', 'GPU 및 CPU 사용률', 'Multi-threads', 'deep learning', 'TensorFlow', 'GPU and CPU utilization']","대부분의 딥 러닝(Deep Learning) 시스템은 모델의 훈련 및 검증을 위해 많은 시간을 소모한다. 그러나, 단일 쓰레드(Single Thread) 기반의 데이터 전처리 및 배치 과정으로 인해 대기 시간(Wait Time)이 발생하고 그 결과GPU 및 CPU의 사용률을 낭비하는 경향이 있다. 본 논문에서는 멀티 쓰레드(Multi Thread) 기반으로 모델의 훈련 및 검증 과정을 효율적으로 수행하기 위한 새로운 기법을 제안한다. 제안 기법은 모델 복사 과정을 사용함으로써 훈련과 검증 과정을 최대한 중첩(Overlapping)시키며, 그 결과 전반적인 CPU와 GPU의 사용률을 향상시킨다. 제안 기법을 평가하기 위해 우리는 텐서플로우(TensorFlow)을 이용하여 합성곱 신경망(CNN)을 구현하였다. 실험 결과, 제안 기법이 기존 기법 대비 전체 훈련 및 검증 시간을 22.4% 단축시키는 것을 확인할 수 있었다.","Most deep learning systems spend a lot of time on model training and validation.However, they sometimes tend to waste GPU and CPU resources because the pre-processing and batch processes based on a single thread result in a wait time. In this paper, we propose a new scheme that efficiently handles training and validation processes based on multi-threads. The proposed scheme can overlap the training and validation processes as much as possible by using a model copy operation that extends the processes with multi-threads. As a result, it improves the overall utilization of CPU and GPU. For evaluation, we implemented a convolutional neural network (CNN) using the TensorFlow framework. As a result, we clearly confirm that the proposed scheme saves the total training and validation time by up to 22.4% compared with the traditional schemes."
환경 소음 제거를 통한 범용적인 드론 음향 탐지 구현,2022,"['Acoustic Drone Detection', 'Noise Cancellation', 'Noise Reduction', 'Mel Spectrogram', 'Convolutional Neural Network']","다양한 장소에서 드론이 활발하게 이용되면서 비행금지구역 내 불법 침입, 정보 유출, 항공기 충돌 등의 위험이 증가하고 있다. 이러한 위험을 줄이기 위해 비행금지구역으로 침입하는 드론을 탐지할 수 있는 시스템 구축이 필요하다. 기존의 드론 음향 탐지 연구는 탐지 모델에 환경 소음에 노출된 드론 음향을 그대로 학습시켰기 때문에 환경 소음에 독립적인 성능을 얻지 못했다. 이에 본 논문에서는 다양한 공간에서 환경 소음에 노출된 드론 음향을 명확하게 탐지하기 위해 주변 환경 소음을 별도로 수집하고, 드론 음향 신호에서 환경 소음을 제거하여 시끄러운 환경 속에서도 견고한 성능을 나타내는 범용적인 드론 탐지 시스템을 제안한다. 제안하는 시스템은 수집한 드론 음향 신호에서 환경 소음을 제거한 후 Mel Spectrogram 특성추출과 CNN 딥러닝을 이용하여 드론 존재 여부를 예측하였다. 실험 결과, 환경 소음으로 인해 감소했던 드론 탐지 성능을 7% 이상 향상시킴을 확인하였다.","As individual and group users actively use drones, the risks (Intrusion, Information leakage, and Sircraft crashes and so on) in no-fly zones are also increasing. Therefore, it is necessary to build a system that can detect drones intruding into the no-fly zone. General acoustic drone detection researches do not derive location-independent performance by directly learning drone sound including environmental noise in a deep learning model to overcome environmental noise. In this paper, we propose a drone detection system that collects sounds including environmental noise, and detects drones by removing noise from target sound. After removing environmental noise from the collected sound, the proposed system predicts the drone sound using Mel spectrogram and CNN deep learning. As a result, It is confirmed that the drone detection performance, which was weak due to unstudied environmental noises, can be improved by more than 7%."
MBConv 블록 기반 Ni-Ti 합금의 표면연마 이미지 분류모델,2022,"['모바일 반전 합성곱 신경망', '과도 구조 해석', '표면가공성', 'Mobile Inverted Bottelnet Convolution', 'Transient Structural Analysis', 'Surface Finishing Characteristic']","본 연구에서는 Ni-Ti 합금 표면 품질 향상을 위하여 자기장을 이용한 자기 수송체 회전연마 공정을 제시하고자 한다. 연마공정에 영향을 미치는 회전속도와 연마입자 직경에 따른 Ni-Ti 합금의 표면가공성을 평가하기 위하여 과도구조해석 시뮬레이션을 통해 각 조건별 연마입자의 표면 접촉시간 분포도를 이미지화하였다. 이미지 결과를 바탕으로 표면가공 성능을 예측하기 위하여 compound scaling method가 적용된 MBConv 블록 기반 합성곱 신경망 알고리즘을 적용하였다. 제안된 예측모델을 바탕으로 성능을 평가한 결과, 사전에 학습되지 않은 공정조건에 대한 test 데이터에서도 94%의 높은 정확도를 나타냄으로써 본 연구에서 제안한 MBConv 블록을 활용한 예측모델이 효과적임을 확인할 수 있었다.","This study suggested a magnetic transporter rotational finishing process to improve the surface integrity of Ni-Ti alloys. To predict the effect of surface finishing characteristics, contact time distribution of abrasives on the workpiece surface under the different process parameters, which included abrasive diameter and rotational speed, was examined by a simulation. Based on the simulated images, the surface finishing characteristics were scored based on contact time, contact distribution, and impulse. In addition, image classification was performed using a convolutional neural network (CNN) based on the MBConv block. Consequently, the CNN model with the MBConv block achieved excellent performance for classification accuracy with 98%, 94%, and 94% of train, validation, and test datasets, respectively."
Sex determination from lateral cephalometric radiographs using an automated deep learning convolutional neural network,2022,"['Sex Determination Analysis', 'Deep Learning', 'Radiography', 'Cephalometry', 'Cervical Vertebrae']",국문 초록 정보 없음,"Purpose: Despite the proliferation of numerous morphometric and anthropometric methods for sex identification based on linear, angular, and regional measurements of various parts of the body, these methods are subject to error due to the observer's knowledge and expertise. This study aimed to explore the possibility of automated sex determination using convolutional neural networks(CNNs) based on lateral cephalometric radiographs. Materials and Methods: Lateral cephalometric radiographs of 1,476 Iranian subjects (794 women and 682 men) from 18 to 49 years of age were included. Lateral cephalometric radiographs were considered as a network input and output layer including 2 classes(male and female). Eighty percent of the data was used as a training set and the rest as a test set. Hyperparameter tuning of each network was done after preprocessing and data augmentation steps. The predictive performance of different architectures (DenseNet, ResNet, and VGG) was evaluated based on their accuracy in test sets. Results: The CNN based on the DenseNet121 architecture, with an overall accuracy of 90%, had the best predictive power in sex determination. The prediction accuracy of this model was almost equal for men and women. Furthermore, with all architectures, the use of transfer learning improved predictive performance. Conclusion: The results confirmed that a CNN could predict a person's sex with high accuracy. This prediction was independent of human bias because feature extraction was done automatically. However, for more accurate sex determination on a wider scale, further studies with larger sample sizes are desirable."
항공초분광영상을 이용 배추 노균병 조기진단을 위한 딥러닝 모델 개발,2022,"['Early detection', 'airborne hyperspectral', 'UAV', 'downy mildew', 'deep learning']",국문 초록 정보 없음,"As one of the primary agricultural commodities in Korea, Chinese cabbage is vulnerable to disease infections, particularly downy mildew. Downy mildew infections are identified by irregular yellow to pale brown spots on the upper leaf surface, which damage the leaf cells and thus lead to leaf death. An early diagnosis system to detect the disease would be an essential asset to prevent its occurrence and improve plant protection. As one of the non-destructive evaluation methods, hyperspectral imaging is capable of capturing a wide range of spectral wavelengths and sensitive enough to detect disease presence in a plant. A UAV and hyperspectral imaging system offer accurate field-scale downy mildew detection. The preliminary experiment has shown spectral differences between diseased and healthy cabbage plants. Based on hyperspectral image data, the detection system employs a convolutional neural network (CNN) that extracts spectral and spatial features to detect the disease and its location. A 3D CNN architecture will be used in this study to exploit spectral variance further and accurately detect the disease."
A Hybrid Optimized Deep Learning Techniques for Analyzing Mammograms,2022,"['Deep Learning', 'Convolutional Neural Networks (CNNs)', 'Residual Network (ResNet)', 'Teaching Learning Based Optimization Algorithm (TLBO)']",국문 초록 정보 없음,"Early detection continues to be the mainstay of breast cancer control as well as the improvement of its treatment. Even so, the absence of cancer symptoms at the onset has early detection quite challenging. Therefore, various researchers continue to focus on cancer as a topic of health to try and make improvements from the perspectives of diagnosis, prevention, and treatment. This research's chief goal is development of a system with deep learning for classification of the breast cancer as non-malignant and malignant using mammogram images. The following two distinct approaches: the first one with the utilization of patches of the Region of Interest (ROI), and the second one with the utilization of the overall images is used. The proposed system is composed of the following two distinct stages: the pre-processing stage and the Convolution Neural Network (CNN) building stage. Of late, the use of meta-heuristic optimization algorithms has accomplished a lot of progress in resolving these problems. Teaching-Learning Based Optimization algorithm (TIBO) meta-heuristic was originally employed for resolving problems of continuous optimization. This work has offered the proposals of novel methods for training the Residual Network (ResNet) as well as the CNN based on the TLBO and the Genetic Algorithm (GA). The classification of breast cancer can be enhanced with direct application of the hybrid TLBO- GA. For this hybrid algorithm, the TLBO, i.e., a core component, will combine the following three distinct operators of the GA: coding, crossover, and mutation. In the TLBO, there is a representation of the optimization solutions as students. On the other hand, the hybrid TLBO-GA will have further division of the students as follows: the top students, the ordinary students, and the poor students. The experiments demonstrated that the proposed hybrid TLBO-GA is more effective than TLBO and GA."
딥러닝 기법을 사용하는 소프트웨어 결함 예측 모델,2022,"['Fault prediction', 'Deep learning', 'Machine learning']","수십년간 매우 많은 소프트웨어 결함 예측 모델에 관한 연구들이 수행되었으며, 그들 중 기계학습 기법을 사용한모델들이 가장 좋은 성능을 보였다. 딥러닝 기법은 기계학습 분야에서 가장 각광받는 기술이 되었지만 결함 예측 모델의분류기로 사용된 연구는 거의 없었다. 몇몇 연구들은 모델의 입력 소스나 구문 데이터로부터 시맨틱 정보를 얻어내는데딥러닝을 사용하였다. 본 논문은 3개 이상의 은닉층을 갖는 MLP를 이용하여 모델 구조와 하이퍼 파라미터를 변경하여여러 모델들을 제작하였다. 모델 평가 실험 결과 MLP 기반 딥러닝 모델들은 기존 결함 예측 모델들과 Accuracy는 비슷한 성능을 보였으나 AUC는 유의미하게 더 우수한 성능을 보였다. 또한 또다른 딥러닝 모델인 CNN 모델보다도 더 나은성능을 보였다.","Many studies have been conducted on software fault prediction models for decades, and the models using machine learning techniques showed the best performance. Deep learning techniques have become the most popular in the field of machine learning, but few studies have used them as classifiers for fault prediction models. Some studies have used deep learning to obtain semantic information from the model input source code or syntactic data. In this paper, we produced several models by changing the model structure and hyperparameters using MLP with three or more hidden layers. As a result of the model evaluation experiment, the MLP-based deep learning models showed similar performance to the existing models in terms of Accuracy, but significantly better in AUC. It also outperformed another deep learning model, the CNN model."
인공신경망을 활용한 다회용기 보증금 반환 시스템,2022,"['Reusable Container Return System', 'Artificial Neural Network', 'Amazon Web Server', 'HOG Features', 'Multi Layer Perceptron', 'Fusion Network', 'Convolution Neural Network']","다회용기 보증금 반환 시스템은 소비자가 RVM(Reverse Vending Machine)에 다회용기의 QR코드를 스캔하고, 다회용기를 반납하면 보증금을 지급하는 절차로 동작한다. 이 시스템이 올바르게 동작하기 위해서는 반납된 용기에맞는 보증금을 지급하고, 소비자가 등록되지 않은 용기 또는 이물질 등을 넣어 비정상적인 보증금을 받는 사례를 방지해야 한다. 이를 위해 반납된 용기를 정확하게 인식하고, QR코드 정보와 일치하는지 판단하는 검증 과정이 필요하다. 본논문에서는 용기 인식 및 검증을 포함한 다회용기 보증금 반환 시스템의 동작을 자동화하는 방법을 제안한다. 제안하는방법은 비디오 모니터링 환경에서 이진 분류 모델을 사용하여 RVM 내 물체 유무를 판별한다. 이 과정을 실시간으로동작시키기 위해 가벼운 MLP 모델을 활용한다. “물체 있음”으로 판별된 프레임 중 용기 분류에 적합한 이미지를 선정하고, AWS(Amazon Web Server)로 전송한다. AWS로 전송된 이미지는 CNN(Convolution Neural Network) 모델을활용하여 사전에 정의한 클래스 중에서 하나로 분류한다. 목업 장치를 활용한 실험 결과를 통해 제안하는 전체 시스템이98% 이상의 정확도를 보이고, 다회용기 보증금 반환 시스템이 자동화될 수 있음을 보였다.","A Reusable Container Return System (RCRS) operates by refunding deposits when customers scan the QR code and return their used containers to a Reverse Vending Machine (RVM). In these systems, accurate recognition of the returned containers and the verification as to whether it matches the QR code information are essential to refund the deposits according to the container types and prevent the abuse of systems (e.g., putting damaged or non-register items). This paper proposes a new method that fully automates this returning process, including recognition and verification of the containers. First, the proposed method classifies empty/non-empty in the RVM from the input video streams using a binary classification model. This classification is based on a lightweight MLP model and works in real time. Among the ""non-empty""-classified frames, a frame suitable for classification (e.g., frames without motions) is selected. The selected image is sent to Amazon Web Service (AWS) and classified as one of the predefined classes using the CNN model. The experimental results using mock-up platforms showed that the proposed system works at 98% accuracy and demonstrates the possibility of a fully-automated RCRS."
진동 분석 및 합성곱 신경망 기반 기계 고장 진단,2022,"['고장진단', '음질인자', '진동신호', '합성곱 신경망', 'Fault Diagnosis', 'Sound Quality Parameter', 'Vibration Signal', 'Convolutional Neural Network']","진동신호에 음질인자를 적용하여 사람의 청감 특성과 연관된 직관적인 고장 진단 방법론을 제안한다. 기계의 고장으로부터 비정상적인 소음이 발생하며, 이러한 소음을 이용하여 작업자들은 기계의 이상 상태를 탐지한다. 음향 특성은 기계의 다양한 고장 상태에 따라 상이하지만, 작업자의 청감 특성에만 의존하여 여러 고장 상태의 진단에는 한계가 있다. 음질인자는 사람의 청감 특성을 물리량으로 나타낸 지표이다. 하지만, 음향신호는 외부에서 발생하는 다양한 외부 소음에 취약하다. 진동신호는 외부 소음에 매우 강건한 특성을 지니고 있으며 음향신호와 진동신호는 매우 큰 상관성을 가진다. 따라서 전자레인지의 정상 상태 및 여러 고장 상태들에 대한 진동신호를 laser Doppler vibrometer (LDV)로 측정하였다. 진동신호에 음질인자가 적용되었으며, 각 기계의 상태에 대한 음질인자의 특성들이 분석되었다. 합성곱 신경망(convolutional neural network, CNN)은 패턴 인식을 위해 음질인자에서 중요한 특징을 추출하였다. 분류된 특징들은 각 기계의 상태들 간에 경계를 뚜렷하게 하였다. 제안한 방법의 분류 성능은 다른 분류 모델들과의 비교를 통해 검증되었다.","We developed an intuitive fault diagnosis method related to human auditory characteristics by applying sound quality parameters to the vibration signal. Abnormal noise was generated from a fault in a machine, and the operator used this noise to detect the abnormal condition. Although these acoustic characteristics differ with the fault conditions, diagnosing various fault conditions is limited by the auditory characteristics of the operator. The sound quality parameters represent the human auditory characteristics as physical quantities. However, the sound signal is vulnerable to various external noises generated in the environment. The vibration signal is robust to various external noises generated in the process, and the sound signal and vibration signal have a high correlation. Therefore, the vibration signals of the normal condition and various fault conditions were measured using a laser Doppler vibrometer (LDV). The sound quality parameters were applied to the vibration signal, and the characteristics of the sound quality parameters for each machine condition were analyzed. A convolutional neural network (CNN) was used to extract important features from the sound quality parameters for pattern recognition. The classified features facilitated a clear demarcation between the conditions of the machine. The classification performance of the proposed method was verified through comparison with other classification models."
Sex determination from lateral cephalometric radiographs using an automated deep learning convolutional neural network,2022,"['Sex Determination Analysis', 'Deep Learning', 'Radiography', 'Cephalometry', 'Cervical Vertebrae']",국문 초록 정보 없음,"Purpose: Despite the proliferation of numerous morphometric and anthropometric methods for sex identification based on linear, angular, and regional measurements of various parts of the body, these methods are subject to error due to the observer’s knowledge and expertise. This study aimed to explore the possibility of automated sex determination using convolutional neural networks(CNNs) based on lateral cephalometric radiographs.Materials and Methods: Lateral cephalometric radiographs of 1,476 Iranian subjects (794 women and 682 men) from 18 to 49 years of age were included. Lateral cephalometric radiographs were considered as a network input and output layer including 2 classes(male and female). Eighty percent of the data was used as a training set and the rest as a test set. Hyperparameter tuning of each network was done after preprocessing and data augmentation steps.The predictive performance of different architectures (DenseNet, ResNet, and VGG) was evaluated based on their accuracy in test sets.Results: The CNN based on the DenseNet121 architecture, with an overall accuracy of 90%, had the best predictive power in sex determination. The prediction accuracy of this model was almost equal for men and women.Furthermore, with all architectures, the use of transfer learning improved predictive performance.Conclusion: The results confirmed that a CNN could predict a person’s sex with high accuracy. This prediction was independent of human bias because feature extraction was done automatically. However, for more accurate sex determination on a wider scale, further studies with larger sample sizes are desirable."
Machine Learning-based Classification of Hyperspectral Imagery,2022,"['Hyperspectral', 'Classification', 'ANN', 'Dimensionality']",국문 초록 정보 없음,"The classification of hyperspectral imagery (HSI) is essential in the surface of earth observation. Due to the continuous large number of bands, HSI data provide rich information about the object of study; however, it suffers from the curse of dimensionality. Dimensionality reduction is an essential aspect of Machine learning classification. The algorithms based on feature extraction can overcome the data dimensionality issue, thereby allowing the classifiers to utilize comprehensive models to reduce computational costs. This paper assesses and compares two HSI classification techniques. The first is based on the Joint Spatial-Spectral Stacked Autoencoder (JSSSA) method, the second is based on a shallow Artificial Neural Network (SNN), and the third is used the SVM model. The performance of the JSSSA technique is better than the SNN classification technique based on the overall accuracy and Kappa coefficient values. We observed that the JSSSA based method surpasses the SNN technique with an overall accuracy of 96.13% and Kappa coefficient value of 0.95. SNN also achieved a good accuracy of 92.40% and a Kappa coefficient value of 0.90, and SVM achieved an accuracy of 82.87%. The current study suggests that both JSSSA and SNN based techniques prove to be efficient methods for hyperspectral classification of snow features. This work classified the labeled/ground-truth datasets of snow in multiple classes. The labeled/ground-truth data can be valuable for applying deep neural networks such as CNN, hybrid CNN, RNN for glaciology, and snow-related hazard applications."
A Comparison of Meta-learning and Transfer-learning for Few-shot Jamming Signal Classification,2022,"['jamming', 'meta-learning', 'transfer learning', 'classification']",국문 초록 정보 없음,"Typical anti-jamming technologies based on array antennas, Space Time Adaptive Process (STAP) & Space Frequency Adaptive Process (SFAP), are very effective algorithms to perform nulling and beamforming. However, it does not perform equally well for all types of jamming signals. If the anti-jamming algorithm is not optimized for each signal type, antijamming performance deteriorates and the operation stability of the system become worse by unnecessary computation. Therefore, jamming classification technique is required to obtain optimal anti-jamming performance. Machine learning, which has recently been in the spotlight, can be considered to classify jamming signal. In general, performing supervised learning for classification requires a huge amount of data and new learning for unfamiliar signal. In the case of jamming signal classification, it is difficult to obtain large amount of data because outdoor jamming signal reception environment is difficult to configure and the signal type of attacker is unknown. Therefore, this paper proposes few-shot jamming signal classification technique using meta-learning and transfer-learning to train the model using a small amount of data. A training dataset is constructed by anti-jamming algorithm input data within the GNSS receiver when jamming signals are applied. For metalearning, Model-Agnostic Meta-Learning (MAML) algorithm with a general Convolution Neural Networks (CNN) model is used, and the same CNN model is used for transfer-learning. They are trained through episodic training using training datasets on developed our Python-based simulator. The results show both algorithms can be trained with less data and immediately respond to new signal types. Also, the performances of two algorithms are compared to determine which algorithm is more suitable for classifying jamming signals."
태양객체 정보 및 태양광 특성을 이용하여 사용자 위치의 자외선 지수를 산출하는 DNN 모델,2022,"['UVI', 'Image', 'Solar object characteristics', 'User location', 'Sunlight characteristics', 'DNN', '자외선 지수', '이미지', '태양 객체특성', '사용자 위치', '태양광 특성', '딥러닝']","자외선은 노출 정도에 따라 인체에 유익 또는 유해한 영향을 미치므로 개인별 적정 노출을 위해서는 정확한 자외선(UV) 정보가필요하다. 국내의 경우 기상청에서 생활기상정보의 한 요소로 자외선 정보를 제공하고 있으나 지역별 자외선 지수(UVI, Ultraviolet Index)로 사용자 위치의 정확한 UVI를 제공하지는 못하고 있다. 일부에서는 정확한 UVI의 취득을 위해 직접 계측기를 운용하지만 비용이나 편의성에 문제가 있고, 태양의 복사량과 운량 등 주변 환경요소를 통해 자외선 양을 추정하는 연구도 소개되었으나 개인별서비스 방법을 제시하지는 못하였다. 이에 본 논문에서는 각 개인별 위치에서의 정확한 UVI 제공을 위한 태양객체 정보와 태양광특성을 이용한 UVI 산출 딥러닝 모델을 제안한다. 기 수집한 하늘이미지 및 태양광 특성을 분석하여 태양의 위치 및 크기, 조도 등UVI와 상관도가 높은 요소들을 선정한 후 DNN 모델을 위한 데이터 셋을 구성한다. 이후 하늘이미지로부터 Mask R-CNN을 통해 추출한 태양객체 정보와 태양광 특성을 입력하여 UVI를 산출하는 DNN 모델을 구현한다. 국내 UVI 권고기준을 고려, UVI 8이상과 미만인날에 대한 성능평가에서는 기준장비 대비 MAE 0.26의 범위 내 정확한 UVI의 산출이 가능하였다.","UV rays have beneficial or harmful effects on the human body depending on the degree of exposure. An accurate UV information is required for proper exposure to UV rays per individual. The UV rays’ information is provided by the Korea Meteorological Administration as one component of daily weather information in Korea. However, it does not provide an accurate UVI at the user’s location based on the region’s Ultraviolet index. Some operate measuring instrument to obtain an accurate UVI, but it would be costly and inconvenient. Studies which assumed the UVI through environmental factors such as solar radiation and amount of cloud have been introduced, but those studies also could not provide service to individual. Therefore, this paper proposes a deep learning model to calculate UVI using solar object information and sunlight characteristics to provide an accurate UVI at individual location. After selecting the factors, which were considered as highly correlated with UVI such as location and size and illuminance of sun and which were obtained through the analysis of sky images and solar characteristics data, a data set for DNN model was constructed. A DNN model that calculates the UVI was finally realized by entering the solar object information and sunlight characteristics extracted through Mask R-CNN. In consideration of the domestic UVI recommendation standards, it was possible to accurately calculate UVI within the range of MAE 0.26 compared to the standard equipment in the performance evaluation for days with UVI above and below 8."
A Review on Advanced Methodologies to Identify the Breast Cancer Classification using the Deep Learning Techniques,2022,"['Convolutional Neural Network', 'Deep Learning', 'Mammogram', 'Prediction', 'Automatic Analysis of Diagnostic Tests']",국문 초록 정보 없음,"Breast cancer is among the cancers that may be healed as the disease diagnosed at early times before it is distributed through all the areas of the body. The Automatic Analysis of Diagnostic Tests (AAT) is an automated assistance for physicians that can deliver reliable findings to analyze the critically endangered diseases. Deep learning, a family of machine learning methods, has grown at an astonishing pace in recent years. It is used to search and render diagnoses in fields from banking to medicine to machine learning. We attempt to create a deep learning algorithm that can reliably diagnose the breast cancer in the mammogram. We want the algorithm to identify it as cancer, or this image is not cancer, allowing use of a full testing dataset of either strong clinical annotations in training data or the cancer status only, in which a few images of either cancers or noncancer were annotated. Even with this technique, the photographs would be annotated with the condition; an optional portion of the annotated image will then act as the mark. The final stage of the suggested system doesn't need any based labels to be accessible during model training. Furthermore, the results of the review process suggest that deep learning approaches have surpassed the extent of the level of state-of-of-the-the-the-art in tumor identification, feature extraction, and classification. in these three ways, the paper explains why learning algorithms were applied: train the network from scratch, transplanting certain deep learning concepts and constraints into a network, and (another way) reducing the amount of parameters in the trained nets, are two functions that help expand the scope of the networks. Researchers in economically developing countries have applied deep learning imaging devices to cancer detection; on the other hand, cancer chances have gone through the roof in Africa. Convolutional Neural Network (CNN) is a sort of deep learning that can aid you with a variety of other activities, such as speech recognition, image recognition, and classification. To accomplish this goal in this article, we will use CNN to categorize and identify breast cancer photographs from the available databases from the US Centers for Disease Control and Prevention."
A Neural Network-Based Approach to Multiple Wheat Disease Recognition,2022,"['CNN', 'Multilabel classification', 'Wheat diseases', 'Computer vision']",국문 초록 정보 없음,"In this paper, modern computer vision methods are proposed for detecting multiple diseases in wheat leaves. The authors demonstrate that modern neural network architectures are capable of qualitatively detecting and classifying diseases, such as yellow spots, yellow rust, and brown rust, even in cases in which multiple diseases are simultaneously present on the plant. For certain classes of diseases, the main multilabel metrics (accuracy, micro-/macro-precision, recall, and F1-score) range from 0.95 to 0.99. This indicates the possibility of recognizing several diseases on a leaf with an accuracy equal to that of an expert phytopathologist. The architecture of the neural network used in this case is lightweight, which makes it possible to use offline on mobile devices."
합성곱 신경망 네트워크 구조 변화에 따른 숫자 인식률 비교,2022,"['CNN', 'Machine learning', 'MNIST']",국문 초록 정보 없음,다국어 초록 정보 없음
변형 Pseudo labeling 방식을 활용한 준지도 학습 개선 연구,2022,"['cnn', 'deep learning', 'fine-tuning', 'pseudo labeling']","본 논문에서는 준지도 학습방식 중 하나인 Pseudo labeling 방식을 활용하여, 학습 정확도를 개선하기 위하여 사람이 손으로 라벨링 한 것과 유사한 성능을 발휘하기 위해 변형 Pseudo labeling 데이터 생성 방식을 제안한다. 기존에 Pseudo labeling 방식은 단순히 정답라벨(Labeled)을 학습하여 라벨이 없는 데이터(Unlabeled data)를 예측한 값을 도출하였다면, 변형 Pseudo labeling 방식은 정답라벨과 라벨이 없는 데이터를 동시에 F-guess를 수행하고, 재 예측한 결과를 활용하여 중복적 라벨링 방식으로 손실을 줄이는 방법을 제안한다. 그 결과 사람이 손으로 라벨링한 정답라벨과 비교하여 mAP@0.5에서 4.26%, mIOU는 8.9% 정도의 개선된 결과를 얻었다.","In this paper, we propose a modified pseudo-labeling data generation method to improve the learning accuracy by using the pseudo-labeling method, which is one of the semi-supervised learning methods, to achieve similar performance to that of human labeling. In the past, the pseudo labeling method simply learned the correct answer label to derive the predicted value of the unlabeled data, whereas the modified pseudo labeling method uses the result of re-predicting the correct label and the unlabeled data through F-guess at the same time to reduce repetitive labeling loss. A reduction method was proposed. As a result, compared with the human-labeled correct answer label, mAP@0.5 improved by 4.26% and mIOU by 8.9%."
온라인 한글 필기 인식 앱 개발,2022,"['CNN', 'recognition', 'Korean-handwritten character', 'preprocessing', 'spilled text']",국문 초록 정보 없음,다국어 초록 정보 없음
사용자 리뷰에서 표정 인식을 이용한 감정 표현 기법,2022,"['CNN(Convolutional Neural Network)', 'Facial Recognition', 'User Review']",국문 초록 정보 없음,"Today, the online market has grown rapidly due to the development of digital platforms and the pandemic situation. Therefore, unlike the existing offline market, the distinctiveness of the online market has prompted users to check online reviews. It has been established that reviews play a significant part in influencing the user's purchase intention through precedents of several studies. However, the current review writing method makes it difficult for other users to understand the writer's emotions by expressing them through elements like tone and words. If the writer also wanted to emphasize something, it was very cumbersome to thicken the parts or change the colors to reflect their emotions. Therefore, in this paper, we propose a technique to check the user's emotions through facial expression recognition using a camera, to automatically set colors for each emotion using research on existing emotions and colors, and give colors based on the user's intention."
코스트 맵을 이용한 딥러닝 기반 자율주행 차량의 충돌 회피 경로 계획,2022,"['CNN(합성곱 신경망)', 'Cost map(코스트 맵)', 'Local Path Planning(로컬 경로 계획)', 'nuScenes DB(누씬 데이터베이스)', 'Deep Learning(딥러닝)']",국문 초록 정보 없음,다국어 초록 정보 없음
모바일용 온라인 한글 필기 인식 시스템 개발,2022,"['CNN', 'recognition', 'Korean-handwritten character', 'preprocessing', 'spilled text']",국문 초록 정보 없음,다국어 초록 정보 없음
데이터 자동 생성 방식을 활용한 객체 인식률 개선 방안 연구,2022,"['CNN', 'Deep learning', 'DeepStream', 'Darknet']","본 논문에서는 실시간 객체 인식 모델 경량화 및 추론을 위해 주로 사용하는 DeepStream의 초기 객체 오인식을 개선하기 위하여 Darknet을 활용한 데이터 자동 생성 방식을 제안한다. 기존에는 객체 오인식을 개선하기 위하여 새로운 데이터 수집 또는 증강 방식을 활용하여 많은 데이터를 추가 확보하여 인식률 개선에 목적이 있다면, 제안하는 방식은 경량화 추론에 사용되는 DeepStream에서의 객체 인식 정확성을 Darknet을 활용하여 재인식 후 차이가 있는 경우에만 데이터를 자동 생성하고 재학습을 진행하는 방식으로 변경하였다. 그 결과 초기 대비 mAP@0.5에서 11.7% 정도의 개선된 결과를 얻었으며, 데이터 증가 수량은 기존 5,565개에서 11,000개로 약 50% 정도 증가한 결과를 얻었다.","In this paper, we propose an automatic data generation method using Darknet to improve the initial object misrecognition of DeepStream, which is mainly used for weight reduction and inference of real-time object recognition models. In the past, if the purpose is to improve recognition rate by securing a lot of data using a new data collection or augmentation method to improve object recognition, the proposed method is to automatically generate data and conduct learning only when there is a difference after re-recognition using Darknet. As a result, an improvement result of 11.7% from mAP@0.5 compared to the initial stage was obtained, and the data growth quantity was increased by about 50% from 5,565 to 11,000."
과적합을 감소시킨 MobileNet을 이용한 드론 촬영 이미지 분류,2022,"['CNN', 'Overfitting', 'Gradient Vanishing', 'PReLU', 'Dropout']",국문 초록 정보 없음,다국어 초록 정보 없음
이종 객체 검출과 중복 라벨링 방식을 활용한 데이터 자동생성 및 객체 인식률 개선 연구,2022,"['CNN', 'deep learning', 'darknet', 'deepStream']",국문 초록 정보 없음,"Currently, in special cases where data collection is limited, such as fire, fire data is collected directly or data is collected using a data augmentation method. And the collected data is being manually labeled. In order to improve this, this paper automatically labels fire data recognized through CCTV or video using heterogeneous object detection and fine-tuning methods, and then automatically proceeds to training. In addition, in order to improve the recognition rate, an integrated learning method with overlapping labeling and a selective application method of image data using the difference in object detection IOU were applied. As a result, automatic data generation increased by about 95% from 5,565 to 10,885, and the recognition rate was improved by about 12.4% from 64.9% to 77.3% based on mAP@0.5."
딥러닝을 활용한 적조 판별,2022,"['적조', 'CNN', '딥러닝']",국문 초록 정보 없음,다국어 초록 정보 없음
상관계수 분석 및 합성곱 신경망기법 기반 시간이력 변형율 예측을 통한 구조물 부재 안전성 평가 기법,2022,"['상관계수', 'CNN', 'SHM', 'Correlation coefficient']",국문 초록 정보 없음,다국어 초록 정보 없음
알츠하이머 치매환자 분류 방법 비교 분석,2022,"['알츠하이머', 'CNN', '다중 커널 학습 분류기', '기계학습']",국문 초록 정보 없음,다국어 초록 정보 없음
VEHICLE NUMBER DETECTION AI SYSTEM FOR PEDESTRIAN SAFETY,2022,"['YOLO', 'CNN', 'OCR', 'Deep Learning', 'Accuracy']",국문 초록 정보 없음,다국어 초록 정보 없음
비정상심박 검출을 위해 영상화된 심전도 신호를 이용한 비교학습 기반 딥러닝 알고리즘,2022,"['심전도', '딥러닝', 'CNN', '템플릿 군', '비정상심박 검출', 'Electrocardiogram', 'Deep learning', 'Convolutional neural network', 'Template cluster', 'Abnormal beat detection']","심전도 신호는 개인에 따라 형태와 특징이 다양하므로, 하나의 신경망으로는 분류하기가 어렵다. 주어진 데이터를 직접적으로 분류하는 것은 어려우나, 대응되는 정상 데이터가 있을 경우, 이를 비교하여 정상 및 비정상을 분류하는 것은 상대적으로 쉽고 정확하다. 본 논문에서는 템플릿 군을 이용하여 대표정상심박 정보를 획득하고, 이를 입력심박에 결합함으로써 심박을 분류한다. 결합된 심박을 영상화한 후, 학습 및 분류를 진행하여, 하나의 신경망으로도 다양한 레코드의 비정상심박을 검출이 가능하였다. 특히, GoogLeNet, ResNet, DarkNet 등 다양한 신경망에 대해서도 비교학습 기법을 적용한 결과, 모두 우수한 검출성능을 가졌으며, GoogLeNet의 경우 99.72%의 민감도로, 실험에 사용된 신경망 중 가장 우수한 성능을 가졌음을 확인하였다.","Electrocardiogram (ECG) signal's shape and characteristic varies through each individual, so it is difficult to classify with one neural network. It is difficult to classify the given data directly, but if corresponding normal beat is given, it is relatively easy and accurate to classify the beat by comparing two beats. In this study, we classify the ECG signal by generating the reference normal beat through the template cluster, and combining with the input ECG signal. It is possible to detect abnormal beats of various individual’s records with one neural network by learning and classifying with the imaged ECG beats which are combined with corresponding reference normal beat. Especially, various neural networks, such as GoogLeNet, ResNet, and DarkNet, showed excellent performance when using the comparative learning. Also, we can confirmed that GoogLeNet has 99.72% sensitivity, which is the highest performance of the three neural networks."
"Deep learning-based prediction of the state and performance of an anaerobic digester using electrochemical sensors available (pH, EC, ORP)",2022,"['Deep learning', 'CNN', 'LSTM', 'Sensor', 'Anaerobic digestion']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝 모델을 이용한 CT 데이터 위조 및 탐지에 관한 연구,2022,"['Cycle-GAN', 'CNN', 'CT data', 'forgery', 'Detection', 'Artificial intelligence', 'Medical data']",국문 초록 정보 없음,"Currently, research on deep learning models is being actively conducted, and many studies are being conducted in various fields. In the medical field, research is also being conducted using various medical data such as medical images and electronic medical records. In particular, research is underway to solve research problems in the medical field due to lack of data by using image conversion technology. However, through highly developed AI models, forged images can cause many problems. If forged images are abused in the medical field, it is a big problem that can endanger patients' lives. In this paper, the Cycle-GAN forgery model is constructed using CT images to solve and prevent problems that may arise through forgery images generated through artificial intelligence models. After that, the quality evaluation of the forged image was conducted. In addition, forgery image detection was performed through a forgery detection model composed of a Concat block, and detection performance was quantified with a classification performance evaluation index. As a result of classification performance indicators, each indicator showed a high value of more than 99%. Through this, it can be seen that the CT image forgery detection model of this paper has excellent performance. In the future, research will be conducted using various medical data as well as CT images, and the detection of forged data will be conducted in various ways."
A Manually Captured and Modified Phone Screen Image Dataset for Widget Classification on CNNs,2022,"['Captured Image', 'CNN', 'Deep Learning Dataset', 'Image Classification', 'Object Detection', 'Widget']",국문 초록 정보 없음,"The applications and user interfaces (UIs) of smart mobile devices are constantly diversifying. For example,deep learning can be an innovative solution to classify widgets in screen images for increasing convenience.To this end, the present research leverages captured images and the ReDraw dataset to write deep learningdatasets for image classification purposes. First, as the validation for datasets using ResNet50 and EfficientNet,the experiments show that the dataset composed in this study is helpful for classification according to a widget'sfunctionality. An implementation for widget detection and classification on RetinaNet and EfficientNet is thenexecuted. Finally, the research suggests the Widg-C and Widg-D datasets—a deep learning dataset for identifyingthe widgets of smart devices—and implementing them for use with representative convolutional neuralnetwork models."
데이터 시각화를 활용한 공정 데이터의 불량예측 기법,2022,"['Defect detection', 'CNN', 'LIME', 'Explainable artificial intelligence', 'Data augmentation']",국문 초록 정보 없음,다국어 초록 정보 없음
"Deep learning-based prediction of the state and performance of an anaerobic digester using electrochemical sensors available (pH, EC, ORP)",2022,"['Deep learning', 'CNN', 'LSTM', 'Sensor', 'Anaerobic digestion']",국문 초록 정보 없음,다국어 초록 정보 없음
Efficient 3D Printer Fault Classification Using a Multi-Block 2D-Convolutional Neural Network,2022,"['3D Printing', 'CNN(convolutional neural network)', 'Efficient model', 'Fault detection', 'Manufacturing']",국문 초록 정보 없음,다국어 초록 정보 없음
Deep Learning-based Driver Fatigue Detection System,2022,"['Multi-stream CNN', 'Fatigue Detection', 'Deep Learning']",국문 초록 정보 없음,다국어 초록 정보 없음
실시간 말벌 탐지를 위한 향상된 타일링 기법,2022,"['Object detection', 'CNN', 'Vespa monitoring system', 'YOLOX', 'Tiling']",국문 초록 정보 없음,"In order to effectively control wasps, which are the main cause of damage in beekeeping, a monitoring system that can check the appearance of wasps in real time is necessary.Convolutional Neural Networks (CNNs), currently widely used in the field of object recognition, cannot successfully detect and classify small objects such as wasps. When a wasp is photographed at a distance of 40 cm with a 4K-camera, the size of the wasp is only 2~3% of the total image. Therefore, in order to increase the recognition accuracy of small objects, we use a tiling method to detect wasps by dividing the image into 3×3. In the traditional tiling methods do not recognize objects located on the divided boundary well. In order to improve the object recognition performance of the tiling method, we propose an improved tiling method that additionally detect a partial area centered on the boundary line in the original image when there are some objects on the tile boundary line. We evaluated the performance of the proposed tiling method using the YOLOX model after producing 7,505 4K resolution images in which 5 species of wasps and 1 type of bee were randomly placed on a 3×3 tile boundary. In experiments on image data created for wasp object recognition training, the PASCAL VOC mAP of traditional tiling methods was 3.28%. However, the mAP of the proposed tiling method was 14.14%, which showed better performance of the proposed tiling technique in terms of accuracy."
데이터 시각화를 통한 자동차 내장 부품 제조 공정의 불량 예측 기법,2022,"['불량 예측', 'CNN', 'LIME', 'XAI(설명가능한 인공지능)', 'Data Augmentation(데이터 증강)']",국문 초록 정보 없음,다국어 초록 정보 없음
FSR 선세와 영상분석을 이용한 족부 기립 상태별 움직임 측정 방법,2022,"['FSR sensor', 'CNN', 'Camera Vision']",국문 초록 정보 없음,다국어 초록 정보 없음
Feature Extraction and Recognition of Myanmar Characters Based on Deep Learning,2022,"['Deep learning CNN', 'Feature Extraction and Recognition', 'Myanmar Characters', 'Orientation', 'Texture', 'Skeleton']",국문 초록 정보 없음,"Recently, with the economic development of Southeast Asia, the use of information devices is widely spreading, and the demand for application services using intelligent character recognition is increasing. This paper discusses deep learning-based feature extraction and recognition of Myanmar, one of the Southeast Asian countries. Myanmar alphabet (33 letters) and Myanmar numerals (10 numbers) are used for feature extraction. In this paper, the number of nine features are extracted and more than three new features are proposed. Extracted features of each characters and numbers are expressed with successful results. In the recognition part, convolutional neural networks are used to assess its execution on character distinction. Its algorithm is implemented on captured image data-sets and its implementation is evaluated. The precision of models on the input data set is 96 % and uses a real-time input image."
ResNet50 전이학습을 활용한 손동작 인식 기반 가위바위보 게임 구현,2022,"['합성곱 신경망(CNN)', '전이학습', '손동작 인식', '가위바위보 게임', 'ResNet50']",국문 초록 정보 없음,다국어 초록 정보 없음
적대적 생성 신경망을 이용한 조직병리학 영상 초해상화,2022,"['Deep learning', 'CNN', 'Super-resolution', 'Histopathology', 'Medical image']","이미지 디지털화 기술이 발전을 이루면서 기존 현미경으로 진행하던 조직 검사는 슬라이드 스캐너를 통해 디지털 이미지로 촬영 및 저장된다. 슬라이드 스캐너는 수 기가 바이트의 고해상도 이미지로 촬영하기 때문에 조직병리학 영상 촬영에 긴 시간이 소요되며 또한 이를 저장하기 위한 많은 메모리 공간이 필요하다. 이를 해결하기 위해 낮은 해상도로 저장하고, 후에 복원하는 초해상화 기법을 조직병리학 영상에 적용한 연구들이 등장하였다. 본 논문에서는 Bicubic Interpolation으로 된 이미지 위에 적대적 생성 신경망을 이용해 만든 잔차 이미지를 더하는 방법으로 원본에 가까우면서도 시각적으로 자연스러운 초해상화 된 조직병리학 영상을 생성하였다. 실험 결과 4x 확대하였을 때, PSNR 29.24dB을 달성하였으며, 정성적으로도 원본에 가까운 이미지를 생성할 수 있음을 보여주었다.",다국어 초록 정보 없음
ArcFace를 사용한 경량 신원인식 네트워크,2022,"['ArcFace', 'lightweight CNN', 'identity recognition', 'edge AI']",국문 초록 정보 없음,"In this paper, we propose a lightweight identity recognition network combining ArcFace, a loss function with robust characteristics in the field of face recognition, and ResNet-18. In this paper, ResNet-18 is modified to a single-channel-based network to reduce the computational amount of the ResNet-18 network. And to compensate for the network performance degradation due to the decrease in the number of channels, ArcFace, which uses an angle margin-based loss function, was combined with a single-channel-based ResNet-18 network to compensate for the network performance degradation. The proposed network performed training and inference with 10,056 experimental data sets consisting of face photos of 33 people. As a result of the experiment, it was confirmed that the proposed ArcFace-based lightweight ResNet-18 improved processing speed by about 1.3 times compared to the existing ResNet-18. In addition, an inference accuracy of 96.9%, similar to that of the existing network ResNet-18, which is 97.6%, was derived."
딥러닝 기반 실종자 식별 지능형 CCTV,2022,"['Deep Learning', 'CNN', 'Missing Person', 'Pan-Tilt camera control', 'OpenCV']",국문 초록 정보 없음,다국어 초록 정보 없음
Unsteady Flow Analysis of Pitching Airfoil Using Conditional U-Net,2022,"['Surrogate Model', 'CNN', 'Transposed Convolutional Layer', 'Conditional U-Net']",국문 초록 정보 없음,다국어 초록 정보 없음
내재 요소 및 재조명을 이용한 얼굴 그림자 제거,2022,"['Deep learning', 'CNN', 'Encoder-deocoder network', 'Shadow removal', 'Relighting']","인물 사진에서 발생한 그림자는 사진의 품질에 영향을 미친다. 그림자로 인해 얼굴의 구조나 색상에 왜곡이 발생하며 이는 얼굴 인식 및 탐지와 작업에서 성능 저하가 발생한다. 이를 해결하기 위해 그림자가 있는 단일 얼굴 영상에서 그림자를 제거하는 방법을 제안한다. 본 논문에서는 임의의 방향에서 조명을 비추는 상황에서 발생한 그림자를 제거하는 것을 목표로 한다. 이를 위해 원래의 조명 방향에서 다른 원하는 조명 방향으로 비추는 새로운 영상을 생성하는 재조명 방법에서 영감을 받아 정면에서 조명을 비추는 영상을 생성하여 그림자를 제거하고자 한다. 인코더-디코더 구조를 통해 비율 영상을 생성하여 그림자가 있는 입력 영상에 곱해주어 그림자 제거 영상을 생성한다. 얼굴의 기하학적 구조를 반영하기 위해 얼굴의 노말 맵을 추정하는 디코더를 추가했으며 노말 맵과 조명 방향으로 그림자 마스크를 추정하여 그림자 제거 영상을 생성하는 데 도움을 준다. 그림자가 제거된 영상은 조명으로 인해 밝았던 영역의 부자연스러움이 존재하기 때문에 이를 제거하기 위해 보정 네트워크의 특징 마스킹 메커니즘을 사용하여 보완하고자 한다. YaleB 데이터셋에서 기존 그림자 제거 연구에 비해 RMSE, PSNR, SSIM의 지표에서 각각 0.04, 2.88, 0.06의 성능 향상을 얻었다.",다국어 초록 정보 없음
Brain Tumor Prediction through Behavior Analysis of Cells Growth Using Machine Learning Techniques,2022,"['Index Terms', 'MRI', 'CNN', 'SVM', 'Detection', 'Cancer.']",국문 초록 정보 없음,"Brain tumor is a very terrible disease. Brain tumor is caused by an increased number of cells. The presence of the skull layer around the brain makes it tough in studying the behavior of growth cells. It also raises the complication for the identification of disease. The initial discovery of a brain tumor is necessary to defend the survival of patients. Frequently, the brain cancer segmentation, and classification through the MRI images technique. Though, the radiologists are not providing actual visualization of brain cells in MRI images due to the irregular growth of cells, which forms of cells are growing rapidly and slow at some stage in brain tumors in the brain. So, automatic strategies are required to evaluate thoughts tumors exactly from MRI images in this research automatic, MRI brain tumors are used for classification, segmentation, and Behavior analysis of cell growth. The problem of visualization of cell growth and behavior analysis of brain cells is solved through MRI images which enhance the detection of cancer. To analyze the behavior of cell growth, which forms of cells are growing rapidly and slow at some stage in brain tumors, and analyze the area of images in which type of cells is affected. Single models are less efficient. We will use ensemble models which would also be helpful for better performance and accuracy."
웹 크롤링과 전이학습을 활용한 이미지 분류 모델,2022,"['Data preprocessing', 'web crawling', 'CNN', 'transfer learning', 'image classification']","딥러닝의 발전으로 딥러닝 모델들이 이미지 인식, 음성 인식 등 여러 분야에서 활발하게 사용 중이다. 하지만 이 딥러닝을 효과적으로 사용하기 위해서는 대형 데이터 세트가 필요하지만 이를 구축하기에는 많은 시간과 노력 그리고 비용이 필요하다. 본 논문에서는 웹 크롤링이라는 이미지 수집 방법을 통해서 이미지를 수집하고 데이터 전처리 과정을 거쳐 이미지 분류 모델에 사용할 수 있게데이터 세트를 구축한다. 더 나아가 전이학습을 이미지 분류 모델에 접목해 카테고리값을 넣어 자동으로 이미지를 분류할 수 있는경량화된 모델과 적은 훈련 시간 및 높은 정확도를 얻을 수 있는 이미지 분류 모델을 제안한다.","In this paper, to solve the large dataset problem, we collect images through an image collection method calledweb crawling and build datasets for use in image classification models through a data preprocessing process. Wealso propose a lightweight model that can automatically classify images by adding category values by incorporatingtransfer learning into the image classification model and an image classification model that reduces training timeand achieves high accuracy."
양식장 이미지를 활용한 딥러닝 기반 저어류 객체 및 특징점 탐지에 관한 연구,2022,"['Olive Flounder image', 'CNN', 'Deep learning', 'Object detection', 'Keypoint detection']",국문 초록 정보 없음,다국어 초록 정보 없음
뇌-컴퓨터 인터페이스 데이터 간 전이 학습을 위한 신호 정렬 기법,2022,"['전이 학습', '제로 트레이닝', 'CNN(Convolution Neural Network)', '가상현실', '증강현실']",뇌파를 이용하여 의도를 인식하는 기술인 뇌-컴퓨터 인터페이스는 사람마다 다른 뇌파 특성으로 인하여 사용 시 매번 새롭게 뇌파를 측정하고 분류기 모델을 구현해야 한다. 하지만 뇌파를 매번 측정하는 것은 상당한 시간을 필요로 하기에 불필요한 뇌파 측정 및 모델 생성 시간을 줄이기 위한 방법이 필요한 상황이다. 본 연구에서는 기존에 측정된 데이터를 재사용할 시에 신호의 특성이 다른 점을 교정하여 분류기 모델을 효과적으로 구성할 수 있는 상관계수기반 신호 정렬 방법을 제안한다. 분석 결과 데이터를 사용하여 분류기 모델을 구성하는 일반적인 방식은 20.8%의 정확도를 보인 반면 제안한 방법은 58.7% 의 비교적 높은 정확도를 보였다.,다국어 초록 정보 없음
헬멧 착용 여부 및 쓰러짐 사고 감지를 위한 AI 영상처리와 알람 시스템의 구현,2022,"['Convolutional Neural Network (CNN)', 'YOLO', 'Object detection', 'Deep learning', 'Industrial site', '합성곱 신경망', 'YOLO', '객체 검출', '딥러닝', '산업현장']","본 논문은 실시간 영상 분석을 통해서 산업현장에서 활동하는 여러 근로자의 영상 객체를 추출해 내고, 추출된 이미지로 부터 개별 영상 분석을 통해 헬멧의 착용 여부와 낙상 사고 여부를 확인하는 방법을 구현한다. 근로자의 영상 객체를 탐지하기 위해서 딥러닝 기반 컴퓨터 비전 모델인 YOLO를 사용하였으며, 추출된 이미지를 이용하여 헬멧의 착용여부를 판단하기 위해 따로 5,000장의 다양한 헬멧 학습 데이터 이미지를 만들어서 사용하였다. 또한, 낙상사고 여부를 판단하기 위해서 Mediapipe의 Pose 실시간 신체추적 알고리즘을 사용하여 머리의 위치를 확인하고 움직이는 속도를 계산하여 쓰러짐 여부를 판단하였다. 결과에 신뢰성을 주기위한 방법으로 YOLO의 바운딩 박스의 크기를 구하여 객체의 자세를 유추하는 방법을 추가하고 구현하였다. 최종적으로 관리자에게 알림 서비스를 위하여 텔레그램 API Bot과 Firebase DB 서버를 구현하였다.","This paper presents an implementation of detecting whether a helmet is worn and there is a fall accident through individual image analysis in real-time from extracting the image objects of several workers active in the industrial field. In order to detect image objects of workers, YOLO, a deep learning-based computer vision model, was used, and for whether a helmet is worn or not, the extracted images with 5,000 different helmet learning data images were applied. For whether a fall accident occurred, the position of the head was checked using the Pose real-time body tracking algorithm of Mediapipe, and the movement speed was calculated to determine whether the person fell. In addition, to give reliability to the result of a falling accident, a method to infer the posture of an object by obtaining the size of YOLO's bounding box was proposed and implemented. Finally, Telegram API Bot and Firebase DB server were implemented for notification service to administrators."
디지털 병리 이미지를 활용한 딥러닝 기반 생존 예측 모형 개발,2022,"['digital pathology', 'survival analysis', 'CNN', 'deep learning', 'whole slide image']",국문 초록 정보 없음,다국어 초록 정보 없음
Text Classification Method Using Deep Learning Model Fusion and Its Application,2022,"['cLong-Short Term Memory', 'CNN deep learning methods', 'multi-category news datasets']",국문 초록 정보 없음,다국어 초록 정보 없음
GeoAI 기반 도시 변화탐지 서비스 도입과 활용방안,2022,"['GeoAI', '항공영상', '객체탐지', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
"AI기반 음식 분석 애플리케이션, 플랜밀",2022,"['Machine Learning', 'AI', 'CNN', 'Image classification', 'Food recognization', 'Food analysis', 'Food recommedation', 'Nutrion info']","현대인의 생활이 날로 바쁘고 복잡해짐과 동시에 팬데믹 현상까지 겹쳐 배달 음식 주문율이 높아지고 있다. 이는 영양분의 불균형을 초래하기 쉽고 이로 인한 만성질환 등 건강상의 이슈로 이어져 필요한 영양소 등을 분석하고 파악하여 식단을 조절하려는 요구가 점점 더 증가하고 있다.  본 논문은 사용자의 체형, 활동 지수, 기초대사량 및 목표 칼로리 기반으로 3대 영양소 비율과 칼로리 정보를 제시하고 AI 기반 이미지 분석 기술로 사용자가 섭취하는 영양과 칼로리를 분석해 사용자에게 적합한 식단을 제시하는 애플리케이션 구현 방안을 제시한다.","Modern people’s lives are getting busier and more complicated, and at the same time, the pandemic phenomenon overlaps, so they order delivery food more and more frequently. It is easy to cause an imbalance of nutrients, and this leads to health issues such as chronic diseases, and there is an increasing demand for analyzing and identifying necessary nutrients to adjust the diet.  This paper presents the ratio of three nutrients and calorie information based on the user’s body type, activity index, basal metabolic rate, and target calorie, and is an application that presents a diet suitable for the user by analyzing the nutrition and calories consumed by the user with AI-based image analysis technology. Suggest implementation plan."
3차원 합성곱 신경망을 이용한 시공간정보 통합 기반 단안카메라 3차원 객체검출,2022,"['Autonomous Driving(자율주행)', '3D CNN(3차원 컨볼루션 네트워크)', '3D Object Detection(3D 객체검출)', 'Monocular Camera Sensor(단안카메라센서)', 'Spatio-Temporality(시공간성)', 'Depth Estimation(깊이추정)']","자율주행과 연관된 객체 검출은 사고예방, 정확한 주행의 측면에서 아주 중요한 선결조건이다. 이때, 다양한 센서정보를 사용하여 동적, 정적 객체 검출을 시행한다. 객체 검출 자체도 중요하지만 자율주행에이전트와 주변의 사물간의 거리정보를 최대한 오류없이 탐지해내는 것 또한 아주 중요한 해결 과제이다.  기존의 3차원 물체 검출 방법에서 사용되었던 2차원 컨볼루션 네트워크는 카메라 영상으로부터 오직 공간적인 정보만을 추출하여 물체검출을 수행하였다. 본 논문에서는 각 이미지에서의 공간정보를 뽑아내어 객체검출을 하는 기존의 2차원 컨볼루션 네트워크 구조 대신 여러 장의 연속된 영상 프레임으로부터 시간적인 정보를 사용하는 3차원 컨볼루션 네트워크에 기반한 3차원 객체 검출기를 제안한다. 시간과 연관된 정보를 사용함으로써, 기존의 공간 정보 단독 입력을 시공간적인 입력으로 개선시키는 효과를 얻을 수 있다. 실험 결과 시계열 데이터의 사용은 기존의 단일 이미지 기반의 객체검출기에 비하여 성능의 향상을 이끌어내었다.",다국어 초록 정보 없음
StarGAN v2 기반 패션 아이템 다중 도메인 변환을 통한 이미지 생성 모델 구현,2022,"['Object Detection', 'Mask R-CNN', 'Fashion Design Technique', 'GAN', 'StarGAN v2']","최근 다양한 GAN 모델이 개발되어 여러 분야에서 활용되고 있다. 본 논문에서는 패션 아이템에 대한 다중 세부 아이템 도메인 변환 시스템 구현을 위해 GAN 모델을 활용하고자 한다. 이를 위해 조건을 지정하여 원하는 도메인 스타일로 변환된 이미지를 생성할 수 있으며 객관적으로 검증된 StarGAN v2를 채택하여 실험 및 구현을 진행하였다. 데이터셋의 레이블링을 최소화하며 도메인에 따른 변환 결과를 정확히 도출할 수 있도록 세부 아이템별로 모델을 각각 생성하였다. 학습된 이미지 생성 모델을 활용하여 하나의 이미지에서 추출한 스타일을 다른 이미지에 합성하는 결과를 도출하였고, 모델들을 모두 활용하여 하나의 이미지에 대해 여러 도메인을 변환할 수 있도록 방안을 제시하였다. 각각의 도메인 변환 이미지 생성 모델에 대한 성능 평가를 위해 실제 이미지와 생성 이미지 사이의 유사도를 측정하고 평가 분석하였다.","Various GANs have been recently developed and are being used in wide application areas. In this paper, we intend to utilize the GAN model to implement a domain transformation system for multi-detailed item on fashion items. For the purpose, we experimented and implemented StarGAN v2, which is objectively verified model that can generate images converted to the desired domain style by specifying conditions. Models were created for each detailed item to minimize labeling of datasets and accurately derive transformation results according to domains. Using the pretrained image generation model, we derive a result of synthesizing styles extracted from one image into another image, and we present a plan to allow multiple domains to be transformed for one image by utilizing all of the models. Similarity between real and generated images is measured for performance evaluation of each domain transformed by image generation model."
Generative Adversarial Network를 이용한 PCB 부품 결함탐지,2022,"['PCB parts', 'Deep learning', 'CNN', 'GAN', 'DCGAN']",국문 초록 정보 없음,다국어 초록 정보 없음
Categorization of actions in soccer videos using a combination of transfer learning and Gated Recurrent Unit,2022,"['Convolutional Neural Network (CNN)', 'Gated Recurrent Unit (GRU)', 'RecurrenT Neural Network (RNN)', 'Transfer learning']",국문 초록 정보 없음,"Extraction of knowledge from soccer videos has enormous applications like context-based advertisement, content-based video retrieval, match summarization, and highlight extraction. Overlapping soccer actions and uncontrolled video capturing conditions make it challenging to detect action accurately. For overcoming these problems, Convolutional Neural Network and Recurrent Neural Network are used jointly to classify different lengths of soccer actions. Initially, transfer learning from pre-trained VGG network extracts characteristic spatial features. Afterwards, Gated Recurrent Unit deals with temporal dependency and solves the vanishing gradient problem. Finally, softmax layer assigns decimal probabilities to each class. Experimental results demystify the significance of the proposed architecture."
나노 세라믹 3D 프린팅의 인공지능 모니터링,2022,"['Ceramic', '3D printing', 'CNN', 'AI']",국문 초록 정보 없음,다국어 초록 정보 없음
A Deep Learning Approach for Identifying User Interest from Targeted Advertising,2022,"['Convolutional Neural Network (CNN)', 'Deep Learning', 'Digital Forensics', 'User Interest', 'User Profiling']",국문 초록 정보 없음,"In the Internet of Things (IoT) era, the types of devices used by one user are becoming more diverse and thenumber of devices is also increasing. However, a forensic investigator is restricted to exploit or collect all theuser’s devices; there are legal issues (e.g., privacy, jurisdiction) and technical issues (e.g., computing resources,the increase in storage capacity). Therefore, in the digital forensics field, it has been a challenge to acquireinformation that remains on the devices that could not be collected, by analyzing the seized devices. In thisstudy, we focus on the fact that multiple devices share data through account synchronization of the onlineplatform. We propose a novel way of identifying the user's interest through analyzing the remnants of targetedadvertising which is provided based on the visited websites or search terms of logged-in users. We introduce adetailed methodology to pick out the targeted advertising from cache data and infer the user’s interest usingdeep learning. In this process, an improved learning model considering the unique characteristics ofadvertisement is implemented. The experimental result demonstrates that the proposed method can effectivelyidentify the user interest even though only one device is examined."
Cu-Al 레이저 용접 특성 분석 및 DNN 알고리즘을 이용한 용접 특성 예측모델 개발,2022,"['Deep Learning', 'Tip-rotating', 'CNN', 'Image Classification', 'Arc Image', 'AI Algorithm', 'Monitoring System']",국문 초록 정보 없음,다국어 초록 정보 없음
Neural Style Transfer,2022,"['Convolutional Neural Network (CNN)', 'Neural Style Transfer (NST)', 'Variation Loss']",국문 초록 정보 없음,"It is a very challenging task for image processing techniques to render the semantic contents of one image in different styles. For this, Neural Style Transfer (NST) is being used. NST is an application of Deep Neural Networks. The basic purpose of this paper is to help Textile industry and fashion industry using NST. The global apparel manufacturing market is a trillion $ market. Designing apparel is a major task and post COVID era all industry is struggling to minimize operational cost. We propose a neural network for style transfer, which can generate millions of stylized images using content and style images pair."
Quality Classification of Injection-Molded Microfluidic Chip using Convolutional Neural Network,2022,"['Convolutional neural network (CNN)', 'Microfluidic chip', 'Quality', 'Injection molding']",국문 초록 정보 없음,다국어 초록 정보 없음
설명가능한 AI를 통한 디노이징된 Wafer Bin Map 이미지 데이터 패턴 분류 및 원인 추론,2022,"['Wafer Bin Map', 'CNN(합성공 신경망 네트워크)', 'eXplainable AI(설명가능한 인공지능)', 'Denoising(노이즈 제거)', 'Causal Inference (원인추론)']",국문 초록 정보 없음,다국어 초록 정보 없음
항공기상지원을 위한 GK-2A/AMI 위성 이미지 딥러닝을 이용한 안개 탐지 모델 개발,2022,"['GK-2A/AMI', 'CNN', '안개 탐지', '시정']",국문 초록 정보 없음,다국어 초록 정보 없음
Two-stream Convolutional Long- and Short-term Memory 모델의 2001-2021년 9월 북극 해빙 예측 성능 평가,2022,"['Arctic', 'Artificial intelligence', 'CNN', 'ConvLSTM', 'LSTM', 'Prediction', 'Sea ice']",국문 초록 정보 없음,"Sea ice, frozen sea water, in the Artic is a primary indicator of global warming. Due to its importance to the climate system, shipping-route navigation, and fisheries, Arctic sea ice prediction has gained increased attention in various disciplines. Recent advances in artificial intelligence (AI), motivated by a desire to develop more autonomous and efficient future predictions, have led to the development of new sea ice prediction models as alternatives to conventional numerical and statistical prediction models. This study aims to evaluate the performance of the two-stream convolutional long-and short-term memory (TS-ConvLSTM) AI model, which is designed for learning both global and local characteristics of the Arctic sea ice changes, for the minimum September Arctic sea ice from 2001 to 2021, and to show the possibility for an operational prediction system. Although the TS-ConvLSTM model generally increased the prediction performance as training data increased, predictability for the marginal ice zone, 5-50% concentration, showed a negative trend due to increasing first-year sea ice and warming. Additionally, a comparison of sea ice extent predicted by the TS-ConvLSTM with the median Sea Ice Outlooks (SIOs) submitted to the Sea Ice Prediction Network has been carried out. Unlike the TS-ConvLSTM, the median SIOs did not show notable improvements as time passed (i.e., the amount of training data increased). Although the TS-ConvLSTM model has shown the potential for the operational sea ice prediction system, learning more spatio-temporal patterns in the difficult-to-predict natural environment for the robust prediction system should be considered in future work."
Damage localization and quantification of a truss bridge using PCA and convolutional neural network,2022,"['convolutional neural network (CNN)', 'damage detection', 'normalized modal strain energy change', 'principal component analysis (PCA)']",국문 초록 정보 없음,"Deep learning algorithms for Structural Health Monitoring (SHM) have been extracting the interest of researchers and engineers. These algorithms commonly used loss functions and evaluation indices like the mean square error (MSE) which were not originally designed for SHM problems. An updated loss function which was specifically constructed for deep-learningbased structural damage detection problems has been proposed in this study. By tuning the coefficients of the loss function, the weights for damage localization and quantification can be adapted to the real situation and the deep learning network can avoid unnecessary iterations on damage localization and focus on the damage severity identification. To prove efficiency of the proposed method, structural damage detection using convolutional neural networks (CNNs) was conducted on a truss bridge model. Results showed that the validation curve with the updated loss function converged faster than the traditional MSE. Data augmentation was conducted to improve the anti-noise ability of the proposed method. For reducing the training time, the normalized modal strain energy change (NMSEC) was extracted, and the principal component analysis (PCA) was adopted for dimension reduction. The results showed that the training time was reduced by 90% and the damage identification accuracy could also have a slight increase. Furthermore, the effect of different modes and elements on the training dataset was also analyzed. The proposed method could greatly improve the performance for structural damage detection on both the training time and detection accuracy."
Hellinger 거리 IoU와 Objectron 적용을 기반으로 하는 객체 감지,2022,"['3D Object Recognition', 'CNN', 'Gaussian', 'Hellinger Distance', 'IoU', 'Objectron']","2D 객체 감지 시스템은 최근 몇 년 동안 심층 신경망과 대규모 이미지 데이터세트의 사용으로 크게 개선되었지만, 아직도 범주 내에서 데이터 부족, 다양한 외관 및 객체 형상 때문에 자율 탐색 등과 같은 로봇 공학과 관련된 응용에서 2D 물체 감지 시스템은 적절하지 않다. 최근에 소개되고 있는 구글 Objectron 또한 증강 현실 세션 데이터를 사용하는 새로운 데이터 파이프라인이라는 점에서 도약이라 할 수 있지만, 3D 공간에서 2D 객체 이해라는 측면에서 마찬가지로 한계가 있다. 이에 본 연구에서는 더 성숙한 2D 물체 감지 방법을 Objectron에 도입하는 3D 물체 감지 시스템을나타낸다. 대부분의 객체 감지 방법은 경계 상자를 사용하여 객체 모양과 위치를 인코딩한다. 본 작업에서는 가우스 분포를 사용하여 객체 영역의 확률적 표현을 탐색하는데, 일종의 확률적 IoU라 할 수 있는 Hellinger 거리를 기반으로 하는가우스 분포에 대한 유사성 측도를 제시한다. 이러한 2D 표현은 모든 객체 감지기에 원활하게 통합할 수 있으며, 실험결과 데이터 집합에서 주석이 달린 분할 영역에 더 가까워서 Objectron의 단점이라 할 수 있는 3D 감지 정확도를 높일수 있다.","Although 2D Object detection has been largely improved in the past years with the advance of deep learning methods and the use of large labeled image datasets, 3D object detection from 2D imagery is a challenging problem in a variety of applications such as robotics, due to the lack of data and diversity of appearances and shapes of objects within a category. Google has just announced the launch of Objectron that has a novel data pipeline using mobile augmented reality session data.However, it also is corresponding to 2D-driven 3D object detection technique. This study explores more mature 2D object detection method, and applies its 2D projection to Objectron 3D lifting system. Most object detection methods use bounding boxes to encode and represent the object shape and location.In this work, we explore a stochastic representation of object regions using Gaussian distributions. We also present a similarity measure for the Gaussian distributions based on the Hellinger Distance, which can be viewed as a stochastic Intersection-over-Union. Our experimental results show that the proposed Gaussian representations are closer to annotated segmentation masks in available datasets. Thus, less accuracy problem that is one of several limitations of Objectron can be relaxed."
인공지능 AutoEncoder를 활용한 항공기 파손 탐지 및 분류,2022,"['Anomaly detection(이상 탐지)', 'CNN(합성곱 신경망)', 'Bi-LSTM(양방향 장단기 메모리)', 'Artificial Intelligence(인공지능)', 'Deep-learning(딥러닝)']",국문 초록 정보 없음,다국어 초록 정보 없음
용접부 아크 이미지 기반의 딥러닝 모델을 활용한 팁회전 아크 용접에서의 품질 판단 알고리즘 연구,2022,"['Deep Learning', 'Tip-rotating', 'CNN', 'Image Classification', 'Arc Image', 'AI Algorithm', 'Monitoring System']",국문 초록 정보 없음,다국어 초록 정보 없음
Automatic Bleeding Recognition for Assisting Laparoscopic Surgery,2022,"['Bleeding Detection', 'Minimally Invasive Surgery', 'Laparoscopic Surgery', 'CNN', 'Monitoring System']",국문 초록 정보 없음,다국어 초록 정보 없음
Bounding Box CutMix와 표준화 거리 기반의 IoU를 통한 재활용품 탐지,2022,"['Deep learning', 'Convolutional neural network (CNN)', 'Object detection', 'Recyclable object', 'Data augmentation', 'IoU']",국문 초록 정보 없음,"In this paper, we developed a deep learning-based recyclable object detection model. The model is developed based on YOLOv5 that is a one-stage detector. The deep learning model detects and classifies the recyclable object into 7 categories: paper, carton, can, glass, pet, plastic, and vinyl. We propose two methods for recyclable object detection models to solve problems during training. Bounding Box CutMix solved the no-objects training images problem of Mosaic, a data augmentation used in YOLOv5. Standardized Distance-based IoU replaced DIoU using a normalization factor that is not affected by the center point distance of the bounding boxes. The recyclable object detection model showed a final mAP performance of 0.91978 with Bounding Box CutMix and 0.91149 with Standardized Distance-based IoU."
Verification of a Machine Learning-Based Prediction System considering the Wake Effect of Dongbok Wind Farm Using RTDS,2022,"['Wake effect', 'Machine learning', 'RTDS', 'CNN-LSTM']",국문 초록 정보 없음,다국어 초록 정보 없음
Related Video 정보를 활용한 YouTube 가짜뉴스 탐지 기법,2022,"['YouTube', 'Fake News', 'Related Videos', 'CNN', 'BERT']",국문 초록 정보 없음,다국어 초록 정보 없음
용접 공정 간 자동 결함 검출을 위한 연구,2022,"['Deep learning', 'Object detection', 'Welding', 'YOLOv5', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
인공지능 기반 객체인식 기법에 관한 연구,2022,"['Artificial Intelligence', 'Object Recognition', 'YOLO', 'R-CNN']",최근 들어 차산업 4 연관기술인 사이버물리시스템(CPS) 구축을 위해 물리 모델과 제어회로 시뮬레이션을 위한 가상제어시스템 구축 작업이 다양한 산업 분야에서 요구가 점점 증가하고 있다. 전자 문서화 되지 않은 문서들에 대한 직접입력을 통한 변환은 시간과 비용이 많이 소모된다. 이를 위해 이미 출력된 대량의 도면을 인공지능을 이용한 객체 인식을 통해 디지털화 작업은 매우 중요하다고 할 수 있다. 본 논문에서는 도면내 객체를 정확하게 인식하고 이를 다양한응용에 활용할 수 있도록 하기 위하여 도면내 객체의 특징을 분석하여 인공지능을 활용한 인식 기법을 제안하였다. 객체 인식의 성능을 높이기 위하여 객체별 인식 후 그 정보를 저장하는 중간 파일을 생성하게 하였다. 그리고 인식 결과를 도면에서 삭제하여 다음 인식 대상의 인식률을 향상시켰다. 그리고 그 인식 결과를 표준화 포맷 문서로 저장하여 이를 제어시스템의 다양한 분야에 활용할 수 있도록 하였다. 본 논문에서 제안한 기법의 우수한 성능은 위해 실험을 통해확인할 수 있었다.,"Recently, in order to build a cyber physical system(CPS) that is a technology related to the 4th industry, the construction of the virtual control system for physical model and control circuit simulation is increasingly required in various industries. It takes a lot of time and money to convert documents that are not electronically documented through direct input. For this, it is very important to digitize a large number of drawings that have already been printed through object recognition using artificial intelligence. In this paper, in order to accurately recognize objects in drawings and to utilize them in various applications, a recognition technique using artificial intelligence by analyzing the characteristics of objects in drawing was proposed. In order to improve the performance of object recognition, each object was recognized and then an intermediate file storing the information was created. And the recognition rate of the next recognition target was improved by deleting the recognition result from the drawing. In addition, the recognition result was stored as a standardized format document so that it could be utilized in various fields of the control system. The excellent performance of the technique proposed in this paper was confirmed through the experiments."
Analysis of YOLOv5 results based on detection speed and precision,2022,"['Object detection', 'Computer vision', 'YOLOv5', 'Deep learning', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
시계열 토지피복도 제작을 위한 준감독학습 기반의 훈련자료 자동 추출,2022,"['Land-cover classification', 'Convolutional neural network (CNN)', 'Semi-supervised learning', 'Training data']",국문 초록 정보 없음,"This paper presents a novel training data extraction approach using semi-supervised learning (SSL)-based classification without the analyst intervention for time-series land-cover mapping. The SSL-based approach first performs initial classification using initial training data obtained from past images including land-cover characteristics similar to the image to be classified. Reliable training data from the initial classification result are then extracted from SSL-based iterative classification using classification uncertainty information and class labels of neighboring pixels as constraints. The potential of the SSL-based training data extraction approach was evaluated from a classification experiment using unmanned aerial vehicle images in croplands. The use of new training data automatically extracted by the proposed SSL approach could significantly alleviate the misclassification in the initial classification result. In particular, isolated pixels were substantially reduced by considering spatial contextual information from adjacent pixels. Consequently, the classification accuracy of the proposed approach was similar to that of classification using manually extracted training data. These results indicate that the SSL-based iterative classification presented in this study could be effectively applied to automatically extract reliable training data for time-series land-cover mapping."
Incremental Strategy-based Residual Regression Networks for Node Localization in Wireless Sensor Networks,2022,"['Wireless Sensor Networks (WSNs)', 'Convolutional Neural Networks (CNN)', 'Data Augmentation', 'Node Localization', 'Degree of intersection']",국문 초록 정보 없음,"The easy scalability and low cost of range-free localization algorithms have led to their wide attention and application in node localization of wireless sensor networks. However, the existing range-free localization algorithms still have problems, such as large cumulative errors and poor localization performance. To solve these problems, an incremental strategy-based residual regression network is proposed for node localization in wireless sensor networks. The algorithm predicts the coordinates of the nodes to be solved by building a deep learning model and fine-tunes the prediction results by regression based on the intersection of the communication range between the predicted and real coordinates and the loss function, which improves the localization performance of the algorithm. Moreover, a correction scheme is proposed to correct the augmented data in the incremental strategy, which reduces the cumulative error generated during the algorithm localization. The analysis through simulation experiments demonstrates that our proposed algorithm has strong robustness and has obvious advantages in localization performance compared with other algorithms."
다중센서 기반의 서리관측 시스템(MFOS)의 최근 개선과 적용,2022,"['MFOS', 'Frost Observation', 'mask R-CNN', 'Leaf wetness sensor', 'RGB']",국문 초록 정보 없음,다국어 초록 정보 없음
Practical Analysis for Improving Performance from One-stage Object Detectors,2022,"['Object detection', 'Deep learning']",국문 초록 정보 없음,"Since the advent of the CNN, the performance of object detectors has been greatly improved. In addition, with the one-stage object detector, the detection algorithm has been lightened and improved to a level that can be applied to real-time applications. However, the research directions for one-stage object detectors focus on obtaining high performance on a benchmark dataset, and there is less consideration of how to improve performance with real-world data. In this paper, we check how methods popularly used to enhance performance from neural networks respond to datasets similar to real-world data. Also, we experimentally confirm that a training configuration setup that considers the target dataset can be more effective than complex training strategies like knowledge distillation. Although this analysis is somewhat heuristic, we expect it will provide meaningful insights for researchers and developers who want to apply an object detector to actual applications."
말벌 모니터링을 위한 타일링 기반 객체 검출,2022,"['Vespa monitoring system(말벌모니터링시스템)', 'YOLOX', 'tiling(타일링)', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
공개 데이터셋을 활용한 항공기 EO/IR 카메라 이미지의 객체 검출 성능 향상 방안 연구,2022,"['Object Detection(객체 검출)', 'Deep Learning(딥러닝)', 'CNN(합성곱신경망)', 'Open Dataset(공개 데이터셋)', 'Image Processing(영상 처리)']",국문 초록 정보 없음,다국어 초록 정보 없음
Smart Image Analysis and Recognition Methodology for Earthwork Operation Based on the Convolutional Neural Network Model,2022,"['Earthwork', 'Management system', 'LOT', 'Convolutional Neural Network(CNN)']",국문 초록 정보 없음,다국어 초록 정보 없음
전자전 환경에서 전이학습 기반 저피탐 레이더 변조 신호 분류 성능 분석,2022,"['LPI Radar', 'Intra-pulse Modulation', 'CNN', 'Transfer Learning', 'Deep learning']","최근 저피탐 레이더 기술의 발전에 따라 LPI 레이더 위협 신호의 정확한 탐지 및 변조 방식 분류 기술이 중요한 기술로 대두되고 있다. 특히 레이더 변조방식 분류에 관한 연구는 딥러닝 기반의 이미지 처리분야에서도 연구가 활발히 진행되고 있다. 하지만 이러한 딥러닝 기반 기술은 실제 무기체계에 적용하는데 있어 양질의 학습 데이터 확보에 어려움이 존재한다. 본 논문에서는 전자전의 신호 수집환경을 고려하여, 전이 학습을 이용하여 낮은 SNR 환경에서도 레이더 신호 분류 성능을 향상시키는 방법을 제안한다.제안한 전이 학습 기반의 분류 방법은 –12 dB 환경에서 90% 이상의 분류 성공률을 보임을 확인하였다.","As the development of low detection radar technology, accurate detection and modulation classification technology for LPI threat signals is emerging as an important technology. In particular, research on the classification of radar modulation methods has been actively conducted recently by applying deep learning-based image processing technology. However, these deep learning-based approaches have difficulties in securing high-quality learning data when applied to weapon systems. In this paper, we propose a method to improve radar signal classification performance even in a low SNR environment using transfer learning considering the signal reception environment of electronic warfare. It was confirmed that the proposed transfer learning-based classification method showed a classification success rate of over 90% at -12 dB."
Deep learning recommendation methodology for the restaurant industry : learning the interaction between consumer preferences and restaurant attributions,2022,"['레스토랑 추천 시스템', '합성곱 신경망(CNN)', '임베딩 기법', '레스토랑 속성']","최근에는 외식 산업의 발달과 레스토랑의 수요 증가로 인해 레스토랑 추천 시스템 연구가 활발하게 제안되고 있다. 기존 레스토랑 추천 시스템 연구는 정량적인 평점 정보 또는 온라인 리뷰의 감성분석을 통해 사용자의 선호도를 추출하였는데 이는 사용자의 선호도를 의미론적으로 추출하지 못한다는 한계가 존재한다. 또한, 레스 토랑의 세부적인 속성과 사용자의 선호도를 효과적으로 반영한 연구는 부족한 실정이다. 이를 해결하기 위해 본 연구에서는 딥러닝 기법을 적용하여 소비자의 선호도와 레스토랑 속성의 상호작용을 효과적으로 학습할 수 있는 모델을 제안하였다. 먼저, 소비자의 선호도를 추출하기 위해 합성곱 신경망을 온라인 리뷰에 적용하고, 레스토랑의 세부적인 속성을 추출하기 위해 레스토랑 카테고리 정보에 임베딩 기법을 적용했다. 최종적으로 요소별 연산을 통해 소비자 선호도와 레스토랑 속성 간의 상호작용을 학습했다. 본 연구에서 제안한 모델의 추천 성능을 평가하기 위해 Yelp.com에서 제공하는 온라인 리뷰를 사용하였다. 실험 결과, 기존 연구의 다양한 모델과 비교했을 때 본 연구에서 제안한 모델이 우수한 추천 성능을 보이는 것을 확인하였다. 본 연구에서 제 안하는 방법론은 기존 연구에서 세부적인 속성을 정교하게 추출하는데 어려움이 존재하는 문제점을 개선할 수 있을 것으로 기대한다.",다국어 초록 정보 없음
무장 선택을 위한 딥러닝 기반의 비행체 식별 기법 연구,2022,"['Aerial vehicle', 'Air defense', 'Armament selection', 'CNN', 'Deep learning']",국문 초록 정보 없음,"As air combat system technologies developed in recent years, the development of air defense systems is required. In the operating concept of the anti-aircraft defense system, selecting an appropriate armament for the target is one of the systems capabilities in efficiently responding to threats using limited anti-aircraft power. Much of the flying threat identification relies on the operators visual identification. However, there are many limitations in visually discriminating a flying object maneuvering high speed from a distance. In addition, as the demand for unmanned and intelligent weapon systems on the modern battlefield increases, it is essential to develop a technology that automatically identifies and classifies the aircraft instead of the operators visual identification. Although some examples of weapon system identification with deep learning-based models by collecting video data for tanks and warships have been presented, aerial vehicle identification is still lacking. Therefore, in this paper, we present a model for classifying fighters, helicopters, and drones using a convolutional neural network model and analyze the performance of the presented model."
A Study on the Optimal Artificial Intelligence Model for  Determination of Urolithiasis,2022,"['Urolithiasis', 'Ureter stones', 'ResNet-50', 'Fast R-CNN', 'Surgical support technology']",국문 초록 정보 없음,"Purpose: This paper aims to develop a clinical decision support system (CDSS) that can help detect the stone that is most important to the diagnosis of urolithiasis. Among them, especially for the development of artificial intelligence (AI) models that support a final judgment in CDSS, we would like to study the optimal AI model by comparing and evaluating them.Methods: This paper proposes the optimal ureter stone detection model using various AI technologies. The use of AI technology compares and evaluates methods such as machine learning (support vector machine), deep learning (ResNet-50, Fast RCNN), and image processing (watershed) to find a more effective method for detecting ureter stones.Results: The final value of sensitivity, which is calculated using true positive (TP) and false negative and is a measure of the probability of TP results, showed high recognition accuracy, with an average value of 0.93 for ResNet-50. This finding confirmed that accurate guidance to the stones area was possible when the developed platform was used to support actual surgery.Conclusions: The general situation in the most effective way to the detection stone can be found. But a variety of variables may be slightly different the difference through the term could tell. Future works, on urological diseases, are diverse and the research will be expanded by customizing AI models specialized for those diseases."
딥러닝 기반의 산업 현장 위험도 예측,2022,"['Risk prediction', 'IMU', 'Deep learning', 'CNN', 'LSTM']",국문 초록 정보 없음,다국어 초록 정보 없음
Diagnosing a Child with Autism using Artificial Intelligence,2022,"['Autism""ASD""', 'Children', 'Machine learning', 'CNN', 'RNN']",국문 초록 정보 없음,"Children are the foundation and future of this society and understanding their impressions and behaviors is very important and the child's behavioral problems are a burden on the family and society as well as have a bad impact on the development of the child, and the early diagnosis of these problems helps to solve or mitigate them, and in this research project we aim to understand and know the behaviors of children, through artificial intelligence algorithms that helped solve many complex problems in an automated system, By using this technique to read and analyze the behaviors and feelings of the child by reading the features of the child's face, the movement of the child's body, the method of the child's session and nervous emotions, and by analyzing these factors we can predict the feelings and behaviors of children from grief, tension, happiness and anger as well as determine whether this child has the autism spectrum or not. The scarcity of studies and the privacy of data and its scarcity on these behaviors and feelings limited researchers in the process of analysis and training to the model presented in a set of images, videos and audio recordings that can be connected, this model results in understanding the feelings of children and their behaviors and helps doctors and specialists to understand and know these behaviors and feelings."
Swin Transformer-based multi-scale crowd localization method,2022,"['Crowd Counting', 'Head Detection', 'Convolutional neural network (CNN)']",국문 초록 정보 없음,"In this paper, we propose a new framework that enables an object detector trained with only point-level annotations to estimate the centroids and sizes of objects in dense scenes. Specifically, the framework is based on the Swin Transformer structure and introduces a self-designed resolution feature fusion module in the hierarchical structure, where the estimation of object centroids is done directly by point supervision, and the object pseudo-size is initialized based on the assumption of local uniform distribution, and the regression of object size is guided by an improved congestion-aware loss function. In the NWPU-Crowd dataset, our method outperformed the existing state-of-the-art detection counting methods in F1-measure, precision, MSE evaluation criteria."
깊이 정보를 이용한 딥러닝 기반 신호등 검출,2022,"['Traffic Light Detection', 'Faster R-CNN', 'Depth Estimation']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝을 이용한 조류 경보제의 유해 남조 예측 모델 개발 및 성능 평가,2022,"['유해 남조', 'DeepLearning', '조류 경보제', '1D-CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
A comparative study of artificial intelligence analysis for diagnosis of liver fibrosis in rats,2022,"['AI model', 'DeepLab', 'Mask R-CNN', 'SSD', 'Hepatic fibrosis']",국문 초록 정보 없음,다국어 초록 정보 없음
Hepatic steatosis screening analysis study applying artificial intelligence to rats,2022,"['AI model', 'DeepLab', 'Mask R-CNN', 'YOLO', 'Hepatic steatosis']",국문 초록 정보 없음,다국어 초록 정보 없음
레이블 매핑을 이용한 다중 이미지 분류,2022,"['multi-image classification', 'image datasets', 'CNN', 'learning rate']",국문 초록 정보 없음,다국어 초록 정보 없음
Recent Review of Style Transfer,2022,"['artistic neural style transfer', 'neural network', 'CNN', 'deep  learning']",국문 초록 정보 없음,"A lot of progress has happened since the seminal work of Gatys' neural style transfer. This survey aims to explain concepts of style transfer, and briefly look at various improvements after the IEEE survey published in 2020."
Skeleton 정보와 LSTM을 이용한 작업자 동작인식,2022,"['Pose Estimation', 'Pose Classification', 'Hourglass', 'LSTM', 'CNN', 'Group Normalization']",국문 초록 정보 없음,다국어 초록 정보 없음
FPGA를 활용한 합성곱 신경망 모델의 실시간 추론을 위한 Edge AI 하드웨어 연구,2022,"['합성곱 신경망', 'FPGA', 'AI 가속기', 'Edge AI']","최근 합성곱 신경망(Convolutional Neural Network, CNN)을 활용한 이미지 분석에 관한 연구가 활발하게 진행되고 있다. 합성곱 신경망은 인공신경망의 한 종류로, 기존 handwritten 방식의 이미지 분석보다 정확도가 높아 널리 사용되고 있다. 하지만 합성곱 신경망 모델의 추론 과정에는 다수의 MAC(Multiply-Accumulate) 연산이 필요하며, 이를 edge device에서 실시간으로 모두 처리하기는 어렵다. 이 때문에, 현재 상용화된 대부분의 합성곱 신경망 모델 기반의 IoT 서비스는 edge device에서 중앙 서버로 데이터를 전송한 후, 중앙 장치가 합성곱 신경망 모델의 추론을 처리하는 방식을 사용하고 있다. 하지만 이 방식은 네트워크에 부담을 주고, 네트워크 상태에 따라 실시간 처리가 지연될 수 있다는 단점이 있다. 이에 본 연구에서는 Xilinx Vivado Design Suite을 사용하여 edge device에서 LeNet-5 합성곱 신경망 추론이 가능한 edge AI 하드웨어를 설계하고, Xilinx Zedboard FPGA에 포팅하여 실시간 동작이 가능함을 증명하였다.",다국어 초록 정보 없음
Local Non-linear Quantization for Neural Network Compression in MPEG-NNR,2022,"['Neural network compression', 'NNR', 'NCTM', 'CNN', 'Non-linear quantization']",국문 초록 정보 없음,"Deep Convolutional Neural Networks (CNNs) have demonstrated excellent performance in various visual applications, but their deployment, especially in resource-constrained environments, is limited due to their enormous computational complexity and memory requirements. Therefore, compression of network models while still maintaining the task performance of the trained model is being studied. Recently, the Moving Picture Experts Group (MPEG) developed a standard called Neural Network compression and Representation (NNR) that provides a compressed representation of trained neural networks in an interoperable form. In this paper, we propose a local non-linear quantization (LNQ) method for compressing weight parameters of neural network models. The experimental results show that the proposed LNQ achieves about a 29% gain in compression efficiency with virtually no loss of performance in the tasks, compared to the NNR test model, called the Neural network Compression Test Model (NCTM) version 3.0."
Bi-directional evolutionary 3D topology optimization with a deep neural network,2022,"['Topology optimization', 'Deep learning', 'BESO', 'CNN', 'Python']",국문 초록 정보 없음,"The FEM-based topology optimization repeats usually finite element analyses many times to converge to the stopping criteria. If the near-optimal topology data are available in advance at the beginning of an optimization process, the iterative computation could be greatly reduced. In an effort to obtain swiftly optimum topology solutions, the deep learning and neural networks with a special segmentation scheme of digital images are combined with the BESO (bi-directional evolutionary structural optimization) topology method in this study. The pre-trained digital images of 3200 optimum topologies construct the design domain for the main topology optimization. Additionally, a new post-processor is developed in order to reconstruct the relative locations among finite elements in the raw outputs generated by the neural network.The proposed method has been demonstrated to be efficient in lowering the iterations with several 2D and 3D optimization examples. The iteration counts can be reduced 63 % for a 2D example and by 72.5 % for a 3D one, compared to BESO results alone."
천장 환경 내 위험물 탐색을 위한 소형 궤도 로봇의 영상 기반 위험물 탐지 알고리즘에 관한 연구,2022,"['Object detection', 'Narrow space', 'Abandoned object', 'CNN', 'Transfer learning']",국문 초록 정보 없음,다국어 초록 정보 없음
합성곱신경망을 활용한 천리안위성 2A호 영상 기반의 동해안 냉수대 감지 연구,2022,"['Geo-Kompsat 2A', 'Cold water', 'Upwelling', 'Korean peninsula', 'Deep learning', 'Convolution neural network']","본 연구에서는 천리안위성 2A호 1일 평균 표층수온영상을 대상으로 합성곱신경망(convolution neural network, CNN) 딥러닝 기법을 적용하여 냉수대 발생 여부를 분류하는 연구를 수행하였다. 이를 위하여, 2019년부터 2022년까지 1,155장의 영상을 사용하였으며, 국립수산과학원 제공 냉수대 발생 주의보 및 경보자료로부터 냉수대 발생 영상과 그 외 영상으로 분류하여 학습을 수행하였다. 학습 결과로 82.5%의 probability of detection (POD)와 54.4%의 false alarm ratio (FAR) 지수를 획득하였다. 오분류 분석을 통해 냉수대 분류에 실패한 경우의 대부분은 구름의 영향 때문이며, 비냉수대를 오분류한 경우의 대부분은 실제 영상에 냉수대가 존재함을 확인하였다.",다국어 초록 정보 없음
패션 의류 영상 분류 딥러닝,2022,"['deep learning', 'fashion clothing image', 'Fashion-MNIST dataset', 'CNN', 'LeNet', 'LSTM', 'BiLSTM']",국문 초록 정보 없음,다국어 초록 정보 없음
블라인드 영상 화질 평가 기술의 최신 연구 동향,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
시계열 데이터의 영상 변환을 이용한 유연인쇄압력 센서 데이터 분석,2022,"['Time Series Data', 'Data Analysis', 'Pressure Sensor', 'Classification', 'CNN', 'Deep Learning']",국문 초록 정보 없음,다국어 초록 정보 없음
Skin Lesion Segmentation with Codec Structure Based Upper and Lower Layer Feature Fusion Mechanism,2022,"['semantic segmentation', 'skin lesion segmentation', 'deep learning', 'convolutional neural network (CNN)', 'atrous spatial pyramid pooling']",국문 초록 정보 없음,"The U-Net architecture-based segmentation models attained remarkable performance in numerous medical image segmentation missions like skin lesion segmentation. Nevertheless, the resolution gradually decreases and the loss of spatial information increases with deeper network. The fusion of adjacent layers is not enough to make up for the lost spatial information, thus resulting in errors of segmentation boundary so as to decline the accuracy of segmentation. To tackle the issue, we propose a new deep learning-based segmentation model. In the decoding stage, the feature channels of each decoding unit are concatenated with all the feature channels of the upper coding unit. Which is done in order to ensure the segmentation effect by integrating spatial and semantic information, and promotes the robustness and generalization of our model by combining the atrous spatial pyramid pooling (ASPP) module and channel attention module (CAM). Extensive experiments on ISIC2016 and ISIC2017 common datasets proved that our model implements well and outperforms compared segmentation models for skin lesion segmentation."
Semantic Segmentation with Perceiver IO,2022,"['Semantic segmentation', 'Perceiver IO', 'Deep learning']",국문 초록 정보 없음,"Recently, in deep learning, the transformer is replacing the convolutional neural network (CNN) due to its performance and simple design. In particular, in recent studies, constructing an encoder of the transformer that effectively extracts features on an image has been widely used. However, even in these cases, models utilizing existing deep neural network structures needed to use a form suitable for each data format according to input modality. Recently, the Perceiver IO [6] has been proposed to overcome this limitation. It can process various data formats through one structure to extract a characteristic value. Also, it uses an output query to output data as we want. In this paper, a semantic segmentation model using the characteristics of the Perceiver IO is presented. Two types of input configuration are suggested, and experimental results show the feasibility of the proposed method."
Development of fault detection and diagnosis system for rotating machine using deep learning,2022,"['Machine learning', 'Rotating machine', 'Fault detection and diagnosis', 'Monitoring system', 'CNN', 'SVR']",국문 초록 정보 없음,다국어 초록 정보 없음
다해상도 이미지를 위한 스테그어날리시스 학습 기법,2022,"['스테그어날리시스', '딥러닝', '합성곱신경망', '디지털포렌식', '컴퓨터비전', 'Steganalysis', 'Deep Learning', 'CNN', 'Digital Forensics', 'Computer Vision']",국문 초록 정보 없음,다국어 초록 정보 없음
학습 기반 리튬 이온 배터리 수명 예측 시스템,2022,"['LIB(Lithium Ion Battery)', 'Fault diagnosis', 'State estimation', 'CNN(Convolutional neural network)']",국문 초록 정보 없음,다국어 초록 정보 없음
Prediction of the superiority of the hydrodynamic performance of hull forms using deep learning,2022,"['Hull form design Hydrodynamic performance', 'Superiority prediction', 'Deep learning', 'Convolutional Neural Network (CNN)', 'Computational Fluid Dynamics (CFD)']",국문 초록 정보 없음,"When designing a ship's hull form, a designer creates various candidate hull forms and performs a Computational Fluid Dynamics (CFD) analysis to evaluate the performance of each candidate. Designers consider quantitative indicators, such as the total resistance and wake coefficient, and qualitative indicators, such as the wave height and pressure distributions, when evaluating the performance of a hull form. During the design process, quantitative and qualitative indicators are often used to determine the superiority of two hull forms. However, in the case of quantitative indicators, the difference between the two hull forms is often minimal; thus, superiority cannot be readily determined. Furthermore, because qualitative indicators are in the form of images, it is challenging to determine the superiority in many cases, even for experienced designers. To solve this problem, we propose a convolutional neural networkbased model for predicting the superiority of hull form performance from a qualitative indicator of the image form derived from CFD analysis. The proposed prediction model received various types of hull form performance images. From these results, the hull form performance characteristics were well fused for prediction with high accuracy. CFD analysis images and quantitative indicators for 1600 hull forms were used to determine the superiority of the prediction model. The learned model was verified using 240 hulls. The result confirmed that the proposed model accurately predicted superiority with an accuracy of approximately 94%."
Retinal Disease Identification using Upgraded CLAHE filter and Transfer Convolution Neural Network,2022,"['Retinal disease', 'Retinal fundus images', 'Convolution neural network (CNN)', '(CLAHE) filter']",국문 초록 정보 없음,"Retinal tissue plays a crucial part in human vision. Infections of retinal tissue and delayed treatment or untreated infection could lead to loss of vision. Additionally, the diagnosis is prone to errors when huge dataset is involved. Therefore, a fully automated model of identification of retinal disease is proposed to reduce human interaction while retaining its high accuracy classification results. This paper introduces an enhanced design of a fully automatic multi-class retina diseases prediction system to assist ophthalmologists in making speedy and accurate investigation. Retinal fundus images, which have been used in this study, were downloaded from the stare website (157 images from five classes: BDR, CRVO, CNV, PDR, and Normal). The five files were categorized according to their annotations conducted by the experienced specialists. The categorized images were first processed with the proposed upgraded contrast-limited adaptive histogram filter for image brightness enhancement, noise reduction, and intensity spectrum normalization. The proposed model was designed with transfer learning method and the fine-tuned pre-trained RESNET50. Eventually, the proposed framework was examined with performance evaluation parameters, recorded a classification rate with 100% sensitivity, 100% specificity, and 100% accuracy. The performance of the proposed model showed a magnificent superiority as compared to the state-of-the-art studies."
Species Prediction of Marine Ragworms Based on Web-based Deep Learning Tool,2022,"['Convolutional neural network', 'K-fold cross validation', 'Marine ragworms', 'Species prediction', 'Teachable machine']",국문 초록 정보 없음,다국어 초록 정보 없음
리튬-이온 배터리 이종 신호의 컨볼루션 신경망 기반 이상 현상 검출,2022,[],"본 논문은 Li-Ion Battery 의 이종 신호들에서 스펙트로그램(spectrogram)기반 CNN(Convolution Neural Network)) 기반 이상 현상 검출(anomaly detection) 방법을 제안하였다. 이종 신호들로부터 스펙트로그램을 생성하고, 생성된 일부를 학습데이터로, 나머지는 test 데이터로 사용하였다. 추론을 통해 정상신호, AC 노이즈를 포함한 신호, Impulse 노이즈를 포함한 신호 등 3 가지의 클래스로 배터리 데이터 신호를 분류하였다. 본 논문에서 제안한 방법의 성능은 높은 정확도를 나타냄으로써 검증되었다.",다국어 초록 정보 없음
Development of a Deep Learning Based 4D-Radar and Low-Cost Vision Sensor Fusion Algorithm for Vehicle Detection,2022,"['Deep Learning Sensor Fusion', 'Vehicle Detection', 'Annotation', 'Convolutional Neural Network (CNN)']",국문 초록 정보 없음,다국어 초록 정보 없음
Deep Learning Approach for Essential Gene Prediction with DNA Sequence,2022,"['synthetic biology', 'artificial intelligence', 'essential genes', 'deep learning', 'CNN', 'LSTM', 'microbiome']",국문 초록 정보 없음,다국어 초록 정보 없음
Design of Intelligent Monitoring System for Smart Farm Applying Machine Learning,2022,"['IoT', 'deep learning', 'intelligent smart farm monitoring', 'context awareness', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
Enhanced 3D Residual Network for Human Fall Detection in Video Surveillance,2022,"['Video surveillance', 'fall detection', 'deep learning', 'residual network', '3D CNN']",국문 초록 정보 없음,"In the public healthcare, a computational system that can automatically and efficiently detect and classify falls from a video sequence has significant potential. With the advancement of deep learning, which can extract temporal and spatial information, has become more widespread. However, traditional 3D CNNs that usually adopt shallow networks cannot obtain higher recognition accuracy than deeper networks. Additionally, some experiences of neural network show that the problem of gradient explosions occurs with increasing the network layers. As a result, an enhanced three-dimensional ResNet-based method for fall detection (3D-ERes-FD) is proposed to directly extract spatio-temporal features to address these issues. In our method, a 50-layer 3D residual network is used to deepen the network for improving fall recognition accuracy. Furthermore, enhanced residual units with four convolutional layers are developed to efficiently reduce the number of parameters and increase the depth of the network. According to the experimental results, the proposed method outperformed several state-of-the-art methods."
Methods in the spatial deep learning: current status and future direction,2022,"['Deep learning', 'Machine learning', 'Remote sensing', 'Classification', 'Convolution neural network (CNN)', 'Long short-term memory (LSTM)', 'Autoencoder']",국문 초록 정보 없음,"A deep neural network (DNN), evolved from a traditional artificial neural network, has been seamlessly adapted for the spatial data domain over the years. Deep learning (DL) has been widely applied for a number of applications and a variety of thematic domains. This article reports on a systematic review of methods adapted in major DNN applications with remote sensing data published between 2010 and 2020 aiming to understand the major application area, a framework for model development and the prospect of DL application in spatial data analysis. It has been found that image fusion, change detection, scene classification, image segmentation, and feature detection are the most commonly used application areas. Based on the publication in these thematic areas, a generic framework has been devised to guide a model development using DL based on the methods followed in the past. Finally, recent trends and prospects in terms of data, method, and application of deep learning with remote sensing data are discussed. The review finds that while DL-based approaches have the potential to unfold hidden information, they face challenges in selecting the most appropriate data, methods, and model parameterizations which may hinder the performance. The increasing trend of application of DL in the spatial domain is expected to leverage its strength at its optimum to the research frontiers."
Linkage-based Parking Slot Detection in AVM Images,2022,"['Parking slot detection', 'deep learning', 'convolutional neural network (CNN)', 'one-stage detector', 'around view monitor (AVM) image']",국문 초록 정보 없음,다국어 초록 정보 없음
형태학적 연산과 경계추출 학습이 강화된 U-Net을 활용한 Sentinel-1 영상 기반 수체탐지,2022,"['Synthetic aperture radar (SAR)', 'Deep learning', 'Convolutional neural network (CNN)', 'Water detection', 'Morphology transformation', 'Edge detection']",국문 초록 정보 없음,"Synthetic Aperture Radar (SAR) is considered to be suitable for near real-time inundation monitoring. The distinctly different intensity between water and land makes it adequate for waterbody detection, but the intrinsic speckle noise and variable intensity of SAR images decrease the accuracy of waterbody detection. In this study, we suggest two modules, named ‘morphology module’ and ‘edge-enhanced module’, which are the combinations of pooling layers and convolutional layers, improving the accuracy of waterbody detection. The morphology module is composed of min-pooling layers and max-pooling layers, which shows the effect of morphological transformation. The edge-enhanced module is composed of convolution layers, which has the fixed weights of the traditional edge detection algorithm. After comparing the accuracy of various versions of each module for U-Net, we found that the optimal combination is the case that the morphology module of min-pooling and successive layers of min-pooling and max-pooling, and the edge-enhanced module of Scharr filter were the inputs of conv9. This morphologic and edge-enhanced U-Net improved the F1-score by 9.81% than the original U-Net. Qualitative inspection showed that our model has capability of detecting small-sized waterbody and detailed edge of water, which are the distinct advancement of the model presented in this research, compared to the original U-Net."
딥러닝을 이용한 심전도 분류 알고리즘에 관한 연구,2022,"['ECG', 'Arrhythmia', 'Deep learning', 'MIT-BIH', 'Convolution neural network(CNN)']",국문 초록 정보 없음,"The electrocardiogram(ECG) is a algorithm of recording the change in potential value for the activity of the heart by time and has been used as a testbed algorithm to analyze the normal/abnormal state of the heart. The ECG analysis algorithm uses a frequency band filter but recently deep learning and machine learning using artificial intelligence technology. In this paper, we used of ECG data, a band filter between 0.67Hz and 50Hz was used by fast Fourier Transform and the ECG data for four seconds were reconstructed into data for three seconds before and one second after the beat to be classified as one. As the learning algorithm of artificial intelligence, deep learning, convolution neural network operation was used. To prevent overfitting of the learning model, we developed a model that classifies ECG by repeating dropout. for training data, 70% were trained using 44 data set excluding pacemaker among 48 record set of MIT-BIH arrhythmia data set. As a result of the testbed, the average accuracy of the convolution neural network model was 99.8%, whereas the average accuracy of all classification was 99.6% as a result of the evaluation data, indication the it showed similar compared to the performance of the conventional ECG classification. In this paper, it is a classification for heart beat. but it is possible to contribute to the study on classification of atrial fibrillation as classification of ECG rhythms by learning models."
Artificial neural network reconstructs core power distribution,2022,"['Artificial neural network', 'In-core power', 'distribution', 'RBF', 'CNN']",국문 초록 정보 없음,"To effectively monitor the variety of distributions of neutron flux, fuel power or temperatures in thereactor core, usually the ex-core and in-core neutron detectors are employed. The thermocouples fortemperature measurement are installed in the coolant inlet or outlet of the respective fuel assemblies. Itis necessary to reconstruct the measurement information of the whole reactor position. However, thereading of different types of detector in the core reflects different aspects of the 3D power distribution.The feasibility of reconstruction the core three-dimension power distribution by using different combinations of in-core, ex-core and thermocouples detectors is analyzed in this paper to synthesize theuseful information of various detectors. A comparison of multilayer perceptron (MLP) network and radialbasis function (RBF) network is performed. RBF results are more extreme precision but also moresensitivity to detector failure and uncertainty, compare to MLP networks. This is because that localizedneural network could offer conservative regression in RBF. Adding random disturbance in trainingdataset is helpful to reduce the influence of detector failure and uncertainty. Some convolution neuralnetworks seem to be helpful to get more accurate results by use more spatial layout information, thoughrelative researches are still under way"
Particulate Matter Estimation from Public Weather Data and Closed-Circuit Television Images,2022,"['Deep learning', 'PM concentration', 'VGG-16', 'LSTM', 'Public CCTV', 'CNN']",국문 초록 정보 없음,"This article proposes a method of estimating the concentrations of particulate matter (PM2.5 and PM10) using public data, including road-traffic closed-circuit television (CCTV) images, Smart Seoul City data sensor environment information, and Korea Meteorological Administrationdata. The region-of-interest images and full scenes derived from CCTV footage were used as the basis for the deep learning model, which combines a convolutional neural network and long short-term memory, to establish the particulate matter (PM) concentration prediction methodology. In the experiment, the prediction accuracies corresponding to various types of mean values were calculated by training the model with various mean measurement values for the surface PM2.5 and PM10 concentrations, as well as the corresponding CCTV images and weather data at different time points. In the experiments performed under relatively stable PM concentrations, R2 generally exceeded 0.9 and tended to increase with an increasing range of mean concentration values. In particular, in sections with rapid changes in the PM concentration within an hourly interval, higher R2 values were obtained by the model trained with the average PM concentrations of the time series before and after image capture, outperforming the method that used prior mean observation values and better reflecting the current PM concentration."
RDNN: Rumor Detection Neural Network for Veracity Analysis in Social Media Text,2022,"['Attention mechanism', 'Bidirectional Long Short Term Memory (Bi-LSTM)', 'Convolution Neural Network (CNN)', 'Deep Learning', 'Natural Language Processing']",국문 초록 정보 없음,"A widely used social networking service like Twitter has the ability to disseminate information to large groups of people even during a pandemic. At the same time, it is a convenient medium to share irrelevant and unverified information online and poses a potential threat to society. In this research, conventional machine learning algorithms are analyzed to classify the data as either non-rumor data or rumor data. Machine learning techniques have limited tuning capability and make decisions based on their learning. To tackle this problem the authors propose a deep learning-based Rumor Detection Neural Network model to predict the rumor tweet in real-world events. This model comprises three layers, AttCNN layer is used to extract local and position invariant features from the data, AttBi-LSTM layer to extract important semantic or contextual information and HPOOL to combine the down sampling patches of the input feature maps from the average and maximum pooling layers. A dataset from Kaggle and ground dataset #gaja are used to train the proposed Rumor Detection Neural Network to determine the veracity of the rumor. The experimental results of the RDNN Classifier demonstrate an accuracy of 93.24% and 95.41% in identifying rumor tweets in real-time events."
A Study on the Dynamic Image-Based Dark Channel Prior and Smoke Detection Using Deep Learning,2022,"['Deep learning', 'Dark channel prior', 'Optical flow technique', 'Image pre-processing', 'CNN']",국문 초록 정보 없음,"The detection of smoke in a fi re is a very important research topic because a large amount of carbon monoxide, which is potentially lethal, can be generated and released in the early stages of a fi re. In particular, if a fi re occurs in the form of smoldering combustion, it produces a glowing combustion without fl ames on the surface of the heat source, and the temperature is over 1000 °C. In this study, the dark channel prior, an algorithm previously used for haze removal, is used to detect areas where smoke may exist. The dark channel characteristic makes it possible to eff ectively detect the smoke area included background interference or noise. Additionally, in order to detect the characteristic that the smoke generated from the fi re rises due to the density diff erence at high temperatures, the area of the smoke was detected using the optical fl ow technique based on the Lucas–Kanade method. Image pre-processing using the dark channel prior and the optical fl ow technique can eff ectively detect the smoke areas and signifi cantly reduce false positive rate. Through this, in order to accurately determine the fi ltered region as smoke or non-smoke, a Convolutional Neural Network was employed. As a result, it was confi rmed that accuracy and precision were improved by 4% and 7%, respectively, compared to object detection models that performed detection without image pre-processing."
데이터 스트리밍 플랫폼과 딥러닝을 활용한 예지정비 시스템 설게,2022,"['Kafka', 'Prognostics and Health Management', 'PHM', 'Convolutional Neural Network', 'CNN', 'Long Short Term Memory', 'LSTM', 'Artificial Neural Network', 'ANN']",국문 초록 정보 없음,다국어 초록 정보 없음
왜곡 정보 모듈을 이용한 이미지 디블러 방법,2022,"['Image Deblurring', 'Distortion-guided Module', 'Transformer', 'Convolution Neural Network']","영상 흐려짐은 피사체의 움직임, 카메라의 흔들림 등의 요인으로 발생하는 현상이다. 최근 합성곱 심층신경망(Convolution Neural Network, CNN)을 활용하여 흐려짐 현상을 복원하는 연구가 활발하게 진행되었으며, 원본과 정답 영상의 차이를 이용하여 복원 과정을 가이드하는 방법이 뛰어난 성능을 보였다. 본 논문에서는 왜곡 정보를 기반으로 흐려진 영상 복원 성능을 개선하는 방법을 제안한다. 이를 위해 학습 시, 원본과 정답 영상 차이에 대한 이진화를 수행하여 복원 과정을 가이드 할 수 있도록 하는 트랜스포머(Transformer) 기반 신경망 모듈을 설계하였다. 제안하는 방법은 학습 과정에서 잠재 특징을 기반으로 전역적 추론을 통해 예측한 왜곡 위치 정보 분포를 흐려짐 복원 과정에 반영한다. 다양한 영상 흐려짐 복원 신경망에 제안하는 모듈을 적용하여 복원 성능을 효과적으로 향상시킬 수 있음을 확인하였다.",다국어 초록 정보 없음
깊이 이미지를 이용한 딥러닝 기반 충돌 확률 예측 및 장애물 회피 알고리즘,2022,"['Deep-learning', 'Depth image', 'Obstacle avoidance', 'collision probability', '.']",국문 초록 정보 없음,.
"러시아-우크라, ‘그들만의 전쟁’이 아니었다",2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝 기반 알약 인식 및 분류 모델 구현,2022,"['알약 분류 모델', '알약 인식', '딥러닝', '합성곱 신경망', 'Pill Classification Model', 'Pill Recognition', 'Deep Learning', 'CNN']",국문 초록 정보 없음,"Recently, as interest in health promotion increases and drug crimes increase, the demand for searching for the efficacy and dosage of pills is increasing. Therefore, in this paper, we proposed a deep learning-based model for recognizing and classifying pills from pill images. We first collected pill image data and recognized the pill in the image. Next, we proposed and implemented a model that classifies the color and shape of the recognized pill and recognizes the string written on the pill."
산업단지 단위공장의 에너지 최적화를 위한 AI기반 용수 예측모델에 관한 연구,2022,"['Optimization', 'Artificial Neural Network', 'ANN', 'Water Quality Prediction', 'Predictive Analytics', 'Industrial Complex', 'Convolutional Neural Network', 'CNN', 'QGIS', 'Quantum GIS']",국문 초록 정보 없음,다국어 초록 정보 없음
임베디드 보드에서 차량 감지 및 추적을 위한 딥러닝 모델 최적화,2022,"['Vehicle detection', 'Vehicle tracking', 'embedded board', 'SSD', 'MobileNet', 'convolutional neural network', '차량 감지', '차량 추적', '임베디드 보드', 'SSD', 'MobileNet', 'CNN']","본 논문은 임베디드 보드에서 차량을 감지하고 추적하기 위한 딥러닝 모델을 제안한다. 딥러닝이 기존 이미지 처리 방법에서 높은 정확도를 보여주고 있기 때문에 기존 객체 검출기로 거리나 교량에서 차량을 감지할 수 있다. 그러나, 범용 PC를 사용하는 경우 GPU를 사용하여 프로그램을 실시간으로 동작하는 것이 가능하지만, 임베디드 보드에서는 GPU를 사용하기 어렵고 낮은 성능의 CPU를 사용하므로 프로그램의 실시간 처리가 불가능하다. 본 논문에서는 양자화, edge TPU와 같은 방법을 이용해서 에지 컴퓨팅 기반 딥러닝을 이용한 객체 감지의 정확도와 성능 향상을 시도하였다. Yolo와 같은 다른 네트워크보다 MobileNet을기반한 SSDLite가 빠른 추론시간과 높은 정확도를 보여줘 선정했다. SSDMobileNetV2를 객체 감지기로 사용한 DeepSORT로 모델을 학습하여 차량을 추적할 수 있도록 하였다. 본 논문에서는 H6 CPU를 이용하여 자체 제작한 보드를 통해 차량 감지 및 추적을 위한 딥러닝모델의 성능을 확인하였다","This paper proposes a deep learning model to detect and track the vehicle on an embedded device. Since deep learning has achieved high accuracy over the classical image processing method, object detectors can detect vehicles in the street and highway. It can be normal to run the computer detection program with graphic processor unit (GPU) support, but it is challenging to run it on the embedded board with no GPU support and low central processing unit (CPU) performance. This paper focuses on balancing edge-computing-based deep learning object detection's accuracy and performance using additional techniques such as quantization, edge TPU. SSDLite with MobileNet backbone is chosen due to its lighter than other networks but still obtain good performance compare with Yolo. The model was learned with DeepSORT using SSDMobileNetV2 as an object detector so that the vehicle could be tracked. This paper evaluates the performance of deep learning model to detect and track the vehicle through the developed board using H6 CPU."
ARM 기반 임베디드 시스템에서 mixed precision 을 위한 c/tensorflow 프레임워크 구성,2022,[],"ARM 아키텍처를 사용하는 임베디드 시스템에서 int8, fp16, fp32 데이터를 조합하여 c/c++로 작성된 mixed precision CNN 을 실행시키기 위한 프레임워크 구성으로, 네트워크의 레이어마다 다른 정밀도를 사용하여 네트워크 경량화 및 추론 정확도 향상을 위한 최적의 설정을 탐색하는 실험 및 분석이 가능토록 하는 것을 목적으로 한다. 주요 구성은 network forwarding 중 레이어의 입력이 레이어에 설정된 정밀도와 다를 경우 실행되는 양자화/반양자화를 c/c++로 바인딩된 tensorflow 의 quantization 모듈을 사용하여 진행하고 ARM 시스템에서 c/c++의 fp16 을 사용하기 위해 fp16 를 컴파일이 가능한 ARM compiler 를 사용하는 프레임워크를 제안한다.",다국어 초록 정보 없음
Convolutional Neural Network 기반의 노면 분류 알고리즘 개발,2022,"['Road Surface(노면)', 'Deep Learning(심층 학습)', 'Classification(분류)', 'Terrain mode(터레인 모드)', 'CNN(합성곱 신경망)']",국문 초록 정보 없음,다국어 초록 정보 없음
무선통신시스템에서 딥러닝에 기반한 미래 신호대잡음비 예측,2022,"['SNR   pre d i c t i o n', 'Deep   learning', 'TDD', 'Multi   output', 'CNN', '신 호대잡음비   예측', '딥러 닝', '시분 할    전이중', '다중출력', '합성곱   신경망']","무선 통신 환경에서 딥러 닝을 기반으로 미래 신 호대잡음비( S N R ) 를 예측하 는 기술을 제안한다. 본 논문에서 고려하는 통 신 시스템은 시분 할 전이중 방식을 사용하며, 여러 개의 안테나로 수신하며 동일한 안테나를 이용하여 미래에 송신한다. 여러 수신 안테나에서 과거에 수신된 SNR을 기반으로, 미래 송신 안테나 별로 SNR을 예측하는 합성곱 신경망 모델을 제안한다. 수신하는 비율 또는 수신 SNR을 기록하는 비율 은 10%에서 100%로 설정한다. 만약 수신 기록이 없어 SNR 기록이 존재하지 않는다면 이전에 수신된 SNR과 이후 수신된 SNR의 선형 보간(Linear interpolation)을 통해 수신 SNR을 설정한다. 모의실험 결과에 따르면 광대역 신호일 때 협대역 신호보다우수한 성능을 보인다. 광대역인 경우 20km/h의 속도를 기준으로 제안방법이 기존방법에 비해 약 0.37dB에서 약0.98dB 우수하고, 협대역인 경우 20km/h의 속도를 기준으로 제안방법이 약 0.29dB에서 약 0.88dB 우수하다.","This pa pe r proposes a deep-learning based signal to noise ra t i o (SNR) pre d i c t i o n technique fo r wireless communication environments. The communication system considered in this pa pe r uses time division duplex ( T DD) , and re c e i v e s signal using multiple antennas while transmits with only one antenna.Ba s e d on the SNR measurements when receiving in the pa s t , we proposed a convolutional neural network ( C NN) model to pre d i c t the SNRs fo r all antennas at the time of fu t u re transmission. If there is no re c e i v e d signal nor SNR measurement, the SNR measurements are filled by linear interpolation of neighboring two re c e i v e d SNRs. According to the simulation results, the wideband signals show better pre d i c t i o n pe rfo rm a n c e than the n a rro w b a n d signals. In the case of wideband, the proposed technique is about 0.37～0.98 dB superior to the conventional method fo r 20 km/h. Fo r n a rro w b a n d , the proposed one is better by 0.29～0.88 dB."
A Comparative Study on Reduced Order Models Using a Linear or Nonlinear Learning Process,2022,"['Reduced order model(ROM)', 'Proper orthogonal decomposition(POD)', 'Gaussian process regression (GPR)', 'Convolutional neural network(CNN)']",국문 초록 정보 없음,다국어 초록 정보 없음
호가창과 뉴스 헤드라인을 이용한 딥러닝 기반 주가 변동 예측 기법,2022,"['주가예측', '호가창', '뉴스', '합성곱 신경망', 'Word2vec', 'Stock Price Prediction', 'Limit Order Book', 'News', 'CNN', 'Word2vec']","최근 머신러닝 및 딥러닝 기법을 활용한 주식 가격 예측 연구가 다양하게 이루어지고 있다. 그 중에서도 최근에는 주식 매수 및 매도 주문 정보를 담고 있는 호가창을 이용하여 주가를 예측하려는 연구가 시도되고 있다. 하지만 호가창을 활용한 연구는 대부분 가장 최근 일정 기간 동안의 호가창 추이만을 고려하며, 호가창의 중기 추이와 단기 추이를 같이 고려하는 연구는 거의 진행되지 않았다. 이에 본 논문에서는 호가창의 중기와 단기 추이를 모두 고려하여 주가 등락을 보다 정확히 예측하는 딥러닝 기반 예측 모델을 제안한다. 더욱이 본 논문에서 제안하는 모델은 중단기 호가창 정보 외에도 해당 종목에 대한 동기간 뉴스 헤드라인까지 고려하여 기업의 정성적 상황까지 주가 예측에 반영한다. 본 논문에서 제안하는 딥러닝 기반 예측 모델은 호가창 변화의 특징을 합성곱 신경망으로 추출하고 뉴스 헤드라인의 특징을 Word2vec을 이용하여 추출한 뒤, 이들 정보를 결합하여 특정 기업 주식의 다음 날 등락 여부를 예측한다. 실제 NASDAQ 호가창 데이터와 뉴스 헤드라인 데이터를 사용하여 제안 모델로 5개 종목(Amazon, Apple, Facebook, Google, Tesla)의 일일 주가 등락을 예측한 결과, 제안 모델은 기존 모델에 비해 정확도를 최대 17.66%p, 평균 14.47%p 향상시켰다. 또한 해당 모델로 모의 투자를 수행한 결과, 21 영업일 동안 종목에 따라 최소 $492.46, 최대 $2,840.83의 수익을 얻었다.","Recently, various studies have been conducted on stock price prediction using machine learning and deep learning techniques. Among these studies, the latest studies have attempted to predict stock prices using limit order books, which contain buy and sell order information of stocks. However, most of the studies using limit order books consider only the trend of limit order books over the most recent period of a specified length, and few studies consider both the medium and short term trends of limit order books. Therefore, in this paper, we propose a deep learning-based prediction model that predicts stock price more accurately by considering both the medium and short term trends of limit order books. Moreover, the proposed model considers news headlines during the same period to reflect the qualitative status of the company in the stock price prediction. The proposed model extracts the features of changes in limit order books with CNNs and the features of news headlines using Word2vec, and combines these information to predict whether a particular company’s stock will rise or fall the next day. We conducted experiments to predict the daily stock price fluctuations of five stocks (Amazon, Apple, Facebook, Google, Tesla) with the proposed model using the real NASDAQ limit order book data and news headline data, and the proposed model improved the accuracy by up to 17.66%p and the average by 14.47%p on average. In addition, we conducted a simulated investment with the proposed model and earned a minimum of $492.46 and a maximum of $2,840.93 depending on the stock for 21 business days."
액체섬광검출용액의 구성 요소 판별 및 핵 입자 실험 데이터 획득 관련 저속 제어 시스템에서 합성 곱 신경망 적용 가능성 연구,2022,"['Slow control', 'Liquid scintillator', 'Deep convolutional neural network', 'Pixel image analysis', 'High energy experiment', 'Neutrino', 'IoT', 'Embedded systems', '저속 제어', '액체섬광검출 용액', '심층 합성 곱 신경망', '픽셀 이미지 분석', '핵 입자 실험', '중성미자', '사물 인터넷', '내장형 시스템']","본 논문은 사물 인터넷 기술과 기계 학습을 핵, 입자 실험의 데이터 획득 관련 저속 제어 시스템에 적용하였다. 합성곱 신경망을 이용하여 액체섬광검출 용액의 형광체 판별을 구축 응용의 한 예로 시도하였다. 실험실 수준에서, 액체섬광검출 용액의 형광 방출 성능에 큰 영향을 끼치는 인자들은 보고 되었지만 대형 실험의 극한 상황에서 장기간 성능 연구는 진행 중에 있다. 그 이유는 핵, 입자 실험 특성상 액체섬광검출 용액은 검출기 안에 밀봉되기 때문에 비침습적인 샘플 검사가 어렵기 때문이다. 특히 원자력 발전소 같은 방사선량이 아주 높은 극한 환경에서 액체섬광검출 용액의 장기적인 물리 화학적 안정성은 아직 보고되지 않았다. 방사능 위험 지역에 대한 접근은 많은 시간과 노력이 필요하다. 한편, 핵과 중성미자 간의 산란 단면적 추정 시, 계통 오차의 주된 요인은 중성미자 선속 정확도이다. 입자 붕괴를 통해 중성미자 발생과 측정이 간접적으로 이루어지기 때문에, 검출기 반응에 대한 감시 및 보정 목적의 저속 제어 시스템의 성능 향상이 요구된다. 현재까지 마이크로 컨트롤러의 경량화, 집적화, 그리고 사물 인터넷 기술이 발전하여 내장형 시스템의 경제성과 신뢰성이 크게 향상되었다. 그 결과로 연구자의 안전, 오랜 시간 극한 상황에서 액체섬광검출 용액의 환경 데이터 획득 및 향후 낮은 획득률을 가진 반도체 이미지 센서를 이용한 실험 비결 (know-how) 확보를 할 수 있을 것으로 기대한다.","In this paper, we tried to estimate the fluor components of a liquid scintillator using a convolutional neural network (CNN) while applying and building the internet of things (IoT) and machine learning in a slow control system. Various factors affecting the fluorescent emission of liquid scintillators have been reported at the laboratory level. However, long-term performance studies are still ongoing under extreme environmental conditions in large-scale experiments beyond the laboratory level. Given the characteristics of neutrino experiments, the liquid scintillator is sealed inside the detector, making it difficult to observe non-invasive samples. In particular, the long-term physical and chemical stability of liquid scintillators in extreme environments with high radiation bombardment doses, such as nuclear power plants, has not been reported. Accessing a highly radioactive area requires considerable time and effort. In addition, the cost efficiency and reliability of embedded systems have improved with the development of microcontroller weight reduction, integration, and IoT technology. Therefore, researchers hypothesized that long-term liquid scintillators could ensure the operator’s safety and acquire environmental data under extreme conditions. Moreover, experimental know-how can be obtained by using low-gain semiconductor image sensors."
가닥 지오메트리 이미지를 이용한 ConvNet 기반의 헤어 및 털 합성기,2022,"['Hair simulation', 'Fur simulation', 'Convolutional neural network', 'Physically based simulation', 'Strand geometry image', '헤어 시뮬레이션', '털 시뮬레이션', '합성곱 신경망', '물리 기반 시뮬레이션', '가닥 지오메트리 이미지']","본 논문에서는 라인 형태인 가닥(Strand) 지오메트리 이미지와 합성곱 신경망(Convolutional Neural Network, ConvNet 혹은 CNN)을 이용하여 저해상도 헤어 및 털 시뮬레이션을 고해상도로 노이즈 없이 표현할 수 있는 기법을 제안한다. 저해상도와 고해상도 데이터 간의 쌍은 물리 기반 시뮬레이션을 통해 얻을 수 있으며, 이렇게 얻어진 데이터를 이용하여 저해상도-고해상도 데이터쌍을 설정한다. 학습할 때 사용되는 데이터는 헤어 가닥 형태의 위치를 지오메트리 이미지로 변환하여 사용한다. 본 논문에서 제안하는 헤어 및 털 네트워크는 저해상도 이미지를 고해상도 이미지로 업스케일링(Upscaling)시키는 이미지 합성기를 위해 사용된다. 테스트 결과로 얻어진 고해상도 지오메트리 이미지가 고해상도 헤어로 다시 변환되면, 하나의 매핑 함수로 표현하기 어려운 헤어의 찰랑거리는(Elastic) 움직임을 잘 표현할 수 있다. 합성 결과에 대한 성능으로 이전 물리 기반 시뮬레이션보다 빠른 성능을 보였으며, 복잡한 수치해석을 몰라도 쉽게 실행이 가능하다.","In this paper, we propose a technique that can express low-resolution hair and fur simulations in high-resolution without noise using ConvNet and geometric images of strands in the form of lines. Pairs between low-resolution and high-resolution data can be obtained through physics-based simulation, and a low-resolution-high-resolution data pair is established using the obtained data. The data used for training is used by converting the position of the hair strands into a geometric image. The hair and fur network proposed in this paper is used for an image synthesizer that upscales a low-resolution image to a high-resolution image. If the high-resolution geometry image obtained as a result of the test is converted back to high-resolution hair, it is possible to express the elastic movement of hair, which is difficult to express with a single mapping function. As for the performance of the synthesis result, it showed faster performance than the traditional physics-based simulation, and it can be easily executed without knowing complex numerical analysis."
심전도의 다양한 2차원 변환에 의한 합성곱 신경망기반 개인식별,2022,"['person identification', 'electrocardiogram', 'convolutional neural networks', 'time-frequency transform', 'Short-Time Fourier Transform', 'Fourier Synchrosqueezed Transform']",국문 초록 정보 없음,"In this paper, we propose personal identification method based on Convolutional Neural Networks (CNN) by various two-dimensional (2D) transform of Electrocardiogram (ECG) signals. For this purpose, various 2D time-frequency representation are peformed by Short-Time Fourier Transform (STFT), Fourier Synchrosqueezed Transform (FSST), and Wavelet Synchrosqueezed Transform (WSST) from one-dimensional ECG signals. The individual identification performance is achieved by transfer learning based on the pretrained GoogleNet and ResNet-101. The performance of experimental results are compared by the well-known PTB-ECG database."
합성곱신경망 기반 목재 수종분류의 영향인자 분석,2022,[],"본 연구에서는 인공신경망을 활용하여 수종간 분류 가능성을 검증하고, 수종의 분류 과정에서 작용하는 영향 인자를 분석하기 위해 기존 합성곱신경망(CNN) 모델을 개선한 모델을 이용, 수종분류 정확도에 영향을 미치는 인자를 분석하였다.본 연구에서 검증한 인공신경망 모델은 최종적으로 95% 이상의 높은 분류정확도를 나타내어 인공신경망을 활용하는 딥러닝 기술을 통해 목재의 수종 분류, 나아가 수종 식별을 매우 높은 정확도로 수행 가능한 것으로 검증되었다.학습횟수의 증가에 따라 데이터의 손실률은 감소하고 분류 정확도는 증가하는 경향이 나타났으며, 전체부위 및 만재부에서 확보한 데이터셋을 활용할 경우 손실률과 분류 정확도에 영향이 있었으나, 전체부위 데이터셋은 성능 하락이, 만재부 데이터셋은 성능이 향상되는 경향이 나타났으며, 데이터셋의 증폭여부는 손실률 및 분류 정확도에 영향은 있었으나 그 영향의 정도가 크지 않았다.",다국어 초록 정보 없음
Development of AI distinction service system using data dimension transformation method,2022,"['electrocardiography (ECG)', '3-dimensional method', 'K-nearest neighbor (KNN)', 'support vector machine (SVM)', 'convolution neural network (CNN)']",국문 초록 정보 없음,다국어 초록 정보 없음
심층 신경회로망을 이용한 운전자 조향특성 분류에 대한 연구,2022,[],국문 초록 정보 없음,"In this paper, a classification algorithm for the drivers steering characteristics is presented using a deep neural network(DNN). DNN is composed of convolution neural network(CNN) for feature extraction and fully connected neural network for classification. Actual drivers steering data were collected from a real car and those data were trained by DNN into three classes: ‘strong’, ‘medium’, and ‘weak’ depending upon their forces. The classification accuracy of the algorithm was about 81.2%."
시계열 학습 기반 리튬 이온 배터리 상태 진단 시스템,2022,"['Lithium Ion Battery(LIB', '리튬 이온 배터리)', 'Fault diagnosis(고장 진단)', 'State estimation(상태 예측)', 'Time-series data(시계열 데이터)', 'Convolutional Neural Network(CNN', '합성곱 신경망)']",국문 초록 정보 없음,다국어 초록 정보 없음
얼굴 감정 분류 기술을 적용한 학습자의 수업 집중도 고찰 : 해외문헌을 중심으로,2022,"['ITS', '얼굴 인식', '학습자 집중도', 'AI', '인공지능', 'ITS', 'Face classification', 'Leaner’s focus', 'AI', 'Artificial Intelligence']",국문 초록 정보 없음,다국어 초록 정보 없음
DenseFuse 기반의 광대역 영상 합성 학습을 위한 효과적인 데이터 분류 및 가중치 학습 모델,2022,"['image fusion', 'deep learning', 'supervised learning', 'infrared image', 'visible image']",국문 초록 정보 없음,"In this paper, to improve the slow processing speed of the multi-resolution based visible and NIR(Near-infrared) image synthesis method, we present a fast synthesis method using DenseFuse, one of the CNN(Convolutional Neural Network)-based image synthesis methods. The proposed method applies a raster scan algorithm to secure visible and NIR datasets for effective learning, and presents a dataset classification method using luminance and variance. Also, in this paper, a method for synthesizing a feature map in a fusion layer is presented and compared with the method for synthesizing a feature map in other fusion layers. The proposed method learns the superior image quality of the multi-resolution based image synthesis method, and shows a clear synthesized image with better visibility than other existing learning-based image synthesis methods. Compared with the multi-resolution based image synthesis method used as the target image, the proposed method has the advantage in processing speed by reducing the processing time to 3 times or more."
합성곱 신경망과 장단기 메모리를 이용한 사격음 분석 기법,2022,[],국문 초록 정보 없음,"This paper proposes a model which classifies the type of guns and information about sound source location using deep neural network. The proposed classification model is composed of convolutional neural networks (CNN) and long short-term memory (LSTM). For training and test the model, we use the Gunshot Audio Forensic Dataset generated by the project supported by the National Institute of Justice (NIJ). The acoustic signals are transformed to Mel-Spectrogram and they are provided as learning and test data for the proposed model. The model is compared with the control model consisting of convolutional neural networks only. The proposed model shows high accuracy more than 90 %."
근전도 기반의 Spider Chart와 딥러닝을 활용한 일상생활 잡기 손동작 분류,2022,"['Convolution neural network', 'Electromyography', 'Pre-processing', 'Hand motion', 'Spider chart']",국문 초록 정보 없음,"In this paper, we propose a pre-processing method that converts to Spider Chart image data for classification of gripping movement using EMG (electromyography) sensors and Convolution Neural Networks (CNN) deep learning. First, raw data for six hand gestures are extracted from five test subjects using an 8-channel armband and converted into Spider Chart data of octagonal shapes, which are divided into several sliding windows and are learned. In classifying six hand gestures, the classification performance is compared with the proposed pre-processing method and the existing methods. Deep learning was performed on the dataset by dividing 70% of the total into training, 15% as testing, and 15% as validation. For system performance evaluation, five cross-validations were applied by dividing 80% of the entire dataset by training and 20% by testing. The proposed method generates 97% and 94.54% in cross-validation and general tests, respectively, using the Spider Chart preprocessing, which was better results than the conventional methods."
Convolution Block Attention Module 을 적용한 단일 이미지 생성 모델의 성능 비교 실험,2022,[],본 논문은 단일 이미지만으로 학습하여 이미지를 생성하여 주목받은 딥러닝 기반 생성모델 SinGAN 의 훈련시간과 파라미터 수가 매우 크다는 한계를 개선시킨 ConSinGAN 모델의 생성기와 판별기의 CNN 구조에 각각 또는 동시에 Convolutional Block Attention Module (CBAM)을 추가하여 학습한 뒤 생성된 이미지를 바탕으로 모델의 성능을 비교하였다. 본 실험은 기존 ConSinGAN 에 CBAM 을 적용하여 생성한 이미지에 대한 정량적 평가를 통해 모델 성능의 개선 여부와 한계를 확인한다.,다국어 초록 정보 없음
라즈베리파이를 이용한 객체검출방안에 관한 연구,2022,"['라즈베리파이', '비정형 데이터', '카메라 센서', '인체감지 센서', '컨볼루션 신경망 네트워크', 'YOLO 알고리즘', 'Raspberry Pi', 'Unstructured data', 'Camera sensor', 'Passive infrared sensor', 'CNN', 'YOLO algorithm']",국문 초록 정보 없음,다국어 초록 정보 없음
데이터 증강을 이용한 커뮤니티 질의응답 모델 학습,2022,"['커뮤니티 질의응답', '데이터 증강', '언어모델', '문장생성', 'BERT']","커뮤니티 질의응답(cQA) 시스템은 사용자가 요구하는 정보를 담은 질문을 이용해 그 목적에 맞는 답변을 찾아내는 것으로, 자주 찾는 질문(FAQ)와 같은 소규모 시스템에도 사용할 수 있다. 기존 cQA 시스템으로는 tf-idf 기반 방법, 워드벡터와 CNN 을 이용한 방법 등이 개발되었다. 본 논문에서는 BERT 기반 딥러닝 모델을 cQA 시스템으로 개발하였다. 그러나, 소규모의 FAQ 용 cQA 시스템의 초기에는 사용자와 컴퓨터의 상호작용이 거의 없기 때문에 다양한 사용 예를 이용한 학습 효과를 충분히 내기 어렵다. 따라서, 이 문제를 해결하기 위해 GPT2 기반의 문장생성 모델인 DINO 를 한국어에 맞게 학습한 KoGPT2-DINO 를 이용하여 학습데이터를 증강하고, 증강된 데이터를 BERT 기반의 단일 문장 레이블링 모델로 학습하였다. 그 결과, 원본데이터 만으로 학습한 모델의 성능보다 증강한 데이터로 학습한 모델의 성능이 최대 6.57% 포인트 증가하였다.",다국어 초록 정보 없음
MediaPipe를 활용한 수어 번역 시스템 개발,2022,[],"다양한 언어로 소통하고 있는 우리는 다른 언어와 교류하기 위해 번역, 통역의 존재가 필수가 되기도 한다. 하지만 음성언어를 사용하지 않는 즉, 손으로 언어를 표현하는 수어를 번역하는 통역의 존재는 아직 실현되지 않았다. 이에 본 논문에서는 MediaPipe와 OpenCV 라이브러리를 이용하여 손의 형태를 인식하고 CNN 알고리즘을 통한 텍스트 데이터화 하여 수어 동작을 학습시켜 이를 번역시켜주는 시스템을 연구한다. 이를 통해 공공기관을 이용함에 불편함을 줄이고, 농인의 의사를 보다 빠르게 파악할 수 있도록 도와주는 번역 시스템 제작하는 것에 목적이 있다.",다국어 초록 정보 없음
영상 화소 밝기 특징강화를 통한 딥러닝 기반 의료영상 분할성능 개선,2022,"['Clinical decision support system', 'Medical image segmentation', 'Intensity enhancement', 'Gaussian mixture model', 'U-net']","영상판독을 통한 임상 의사결정 지원시스템 개발에 있어서, 분석하고자 하는 병변 또는 장기만을 효과적으로 추출할 수 있는 영상 분할 기술은 활발한 연구가 진행되어 왔다. 특히, 영상내의 형태특징정보를 효과적으로 추출할 수 있는 딥러닝 계열의 Convolutional Neural Network (CNN) 모델을 기반으로 한 U-net 모델은 의료 영상 분할 연구에서 가장 중요한 모델중 하나로 사용되어지고 있다. 하지만, 특정 병변 및 장기의 경우 형태특징정보뿐만 아니라 병변 및 장기의 물리적 특성에 따른 영상에서의 화소 밝기 특징정보 또한 중요한 역할을 하지만 형태특징정보에 더욱 의존적인 U-net 모델의 경우에는 모델 학습과정에서 밝기 특징 정보가 누락될 수 있는 단점이 있다. 이에 본 논문에서는, 세밀한 영상 분할을 위해 특정 병변 및 장기가 가지고 있는 밝기 특징 정보를 가우시안 혼합모델(Gaussian Mixture Model: GMM)을 통해 모델링 및 강화하여 영상분할에 필요한 사전지식으로 사용할 수 있도록 기존 U-net 모델을 개선하였다. 제안한 알고리즘의 성능 검증을 위해 구강X-ray 영상에서의 치아 분할, 뇌 CT영상에서의 뇌출혈 분할 및 뇌MR 영상에서의 뇌종양 분할 실험을 진행하였으며, 영상의 밝기정보를 강화한 제안 모델이 기존의 U-net에 비해 더욱 세밀한 영상분할이 가능한 것을 확인하였다. 제안한 영상 화소 밝기 특징강화 접근방법은 영상분할외에도 영상분류, 예측 등 다양한 영상분석 방법에 적용되어 영상전처리로써 중요한 역할을 할 수 있을 것이다.",다국어 초록 정보 없음
AI 가속기 설계 영역 탐색에 대한 연구,2022,[],AI 가속기는 머신 러닝 및 딥 러닝을 포함한 인공 지능 및 기계 학습 응용 프로그램의 연산을 더 빠르게 수행하도록 설계된 일종의 하드웨어 가속기 또는 컴퓨터 시스템이다. 가속기를 설계하기 위해선 설계 영역 탐색(Design Space Exploration)을 하여야 하고 여러 인공지능 중에서도 합성 곱 신경망(CNN)에 대한 설계 영역 탐색을 소개한다.,다국어 초록 정보 없음
Siame-FPN기반 객체 특징 추적 알고리즘,2022,"['Computer Vision', 'Convolutional Neural Networks', 'Deep Learning', 'Object Tracking', 'Siamese Network']",국문 초록 정보 없음,"Visual tracking of selected target objects is fundamental challenging problems in computer vision. Object tracking localize the region of target object with bounding box in the video. We propose a Siam-FPN based custom fully CNN to solve visual tracking problems by regressing the target area in an end-to-end manner. A method of preserving the feature information flow using a feature map connection structure was applied. In this way, information is preserved and emphasized across the network. To regress object region and to classify object, the region proposal network was connected with the Siamese network. The performance of the tracking algorithm was evaluated using the OTB-100 dataset. Success Plot and Precision Plot were used as evaluation matrix. As a result of the experiment, 0.621 in Success Plot and 0.838 in Precision Plot were achieved."
오토인코더를 이용한 차량용 레이더 시스템에서 타깃 분류,2022,[],"안정적인 자율 주행을 위해서는 차량 주변 환경을 빠르고 정확하게 인지하는 것이 중요하다. 또한 차량용 레이더 시스템의 특성상 크기가 큰 저장소나 고속의 데이터 처리가 가능한 하드웨어의 장착이 어렵다. 따라서 본 연구에서는 차량용 레이더 시스템에서 타깃 분류를 수행함에 있어 타깃의 특성을 잘 추출할 수 있는 오토인코더 모델을 사용하여 분류를 진행하였고, 기존 CNN 모델 대비 더 적은 파라미터로 구성된 모델을 제안하였다. 보행자, 자전거, 자동차, 세그웨이를 분류하였고, 인코더의 출력 벡터를 사용하여 분류를 진행한 결과 86.7% 이상의 분류 정확도를 확인하였다.",다국어 초록 정보 없음
기계학습 기반 악성코드 검출을 위한 이미지 생성 방법,2022,"['malware detection', 'static analysis', 'machine learning', 'image recognition']",국문 초록 정보 없음,"Many attempts have been made to apply image recognition based on machine learning which has recently advanced dramatically to malware detection. They convert executable files to images and train deep learning networks like CNN to recognize or categorize dangerous executable files, which shows promising results. In this study, we are looking for an effective image generation method that may be used to identify malware using machine learning. To that end, we experiment and assess the effectiveness of various image generation methods in relation to malware detection. Then, we suggest a linear image creation method which represents control flow more clearly and our experiment shows our method can result in better precision in malware detection."
Enhancement of Anomaly Detection Using Two-Stage Anomlay Segmentation Model,2022,"['Anomaly detection', 'Segmentation model', 'Convolutional Neural Network']",국문 초록 정보 없음,"For the anomaly detection task, previously presented deep learning approaches suffer from one potential issue in the testing stage, the resultant output image has noise and missing anomaly area. To deal with this issue, we present a novel two-stage convolutional neural network (CNN) for anomaly detection. In the training stage, the first model is trained by inserting pseudo-anomalies, while the second model is trained by a superpixel technique which segments the image refined by the first model. The superpixel technique can recover partially visible anomaly patterns and suppress noise outside the recovered anomaly patches. We trained the proposed model using an industrial dataset MVTec and compared its performance with state-of-the-art pseudo-anomalous method [11]. Our method shows comparable pixel based percentage area under the receiver operating characteristic (%AUROC) of 96.0% which is only 1.3% less than the performance of DRAEM. However, our model uses four times less number of parameters."
딥러닝 알고리즘을 적용한 컬처마이닝,2022,"['ディ─プラ─ニング、文化要素抽出システム（CEMS）、文化イメージフレームネットワーク (CIFN)、文化要素(CE)、文化イメージフレーム', 'Deep Learning', 'CEMS (Cultural Element Mining System)', 'CIFN (Cultural Image Frame Network)', 'Cultural Element', 'Cultural Image Frame(CIF)']",국문 초록 정보 없음,"This paper is a paper conceived to improve the Cultural Image Frame Network (CIFN) by utilizing deep learning-based image learning datasets that have recently received much attention in major research fields such  as  computer  vision  and  Natural  Language  Processing  (NLP).  In  particular,  CNN,  which  uses convolutional filters for images to calculate quickly and considers the entire image, including specific objects as well as backgrounds, is a very suitable algorithm for extracting cultural elements that constitute the cultural image frame of this culture mining study. In addition, by utilizing images in the form of refined images verified with deep learning experimental and test datasets, the limitations of existing research, such as (1) reliability of tagging information, (2) inaccuracy of the segmentation method, and (3) redundancy of images, can contribute to more sophisticated research."
합성곱 신경망을 이용한 RSSI 기반 송신기의 실내 위치 예측,2022,[],"본 논문에서는 긴급구조 상황에서 요구조자 휴대전화 송신 신호의 RSSI(Received Signal Strength Indicator) 측정값을 바탕으로 휴대전화의 실내 위치를 정밀하게 탐색하기 위해, 송신기가 위치한 방, RSSI map 및 벽의 영향을 포함한 실내지도를 Convolutional Neural Network(CNN)을 이용해 동시에 학습하였다. 이렇게 개발된 학습 모델은 송신기가 존재하는 방의 위치를 높은 정확도로 예측함을 확인하였다.",다국어 초록 정보 없음
편광현미경 이미지 기반 염기성 화산암 분류를 위한 인공지능 모델의 효용성 평가,2022,[],국문 초록 정보 없음,"In order to minimize the human and time consumption required for rock classification, research on rock classification using artificial intelligence (AI) has recently developed. In this study, basic volcanic rocks were subdivided by using polarizing microscope thin section images. A convolutional neural network (CNN) model based on Tensorflow and Keras libraries was self-producted for rock classification. A total of 720 images of olivine basalt, basaltic andesite, olivine tholeiite, trachytic olivine basalt reference specimens were mounted with open nicol, cross nicol, and adding gypsum plates, and trained at the training : test = 7 : 3 ratio. As a result of machine learning, the classification accuracy was over 80-90%. When we confirmed the classification accuracy of each AI model, it is expected that the rock classification method of this model will not be much different from the rock classification process of a geologist. Furthermore, if not only this model but also models that subdivide more diverse rock types are produced and integrated, the AI model that satisfies both the speed of data classification and the accessibility of non-experts can be developed, thereby providing a new framework for basic petrology research."
합성곱 신경망 기반 회귀 문제에 대한 클래스 활성화 맵 활용에 관한 연구,2022,[],"최근 딥러닝은 다양한 어플리케이션에서 기존 결과를 뛰어넘는 높은 성능을 보이고 있으나, 모델의 복잡성에 따른 블랙박스적 특징으로 인해 추론 과정과 결과에 대한 해석에 어려움이 있다. 이를 극복하기 위하여 최근 설명가능한 인공지능 (XAI) 기술들이 활발하게 연구되고 있다. 클래스 활성화 맵(CAM)은 CNN 기반 분류 모델에서 활용되는 대표적인 XAI 기술로서, 본 연구에서는 회귀 문제에 대한 클래스 활성화 맵 기법의 적용가능성을 탐색하기 위하여 동일 데이터셋에 대한 분류 및 회귀 모델의 GradCAM 및 GradCAM ++알고리즘의 결과를 비교하였다.",다국어 초록 정보 없음
A deep learning approach to permanent tooth germ detection on pediatric panoramic radiographs,2022,"['Tooth Germ', 'Radiograph', 'Panoramic', 'Pediatric Dentistry']",국문 초록 정보 없음,"Purpose: The aim of this study was to assess the performance of a deep learning system for permanent tooth germ detection on pediatric panoramic radiographs.Materials and Methods: In total, 4518 anonymized panoramic radiographs of children between 5 and 13 years of age were collected. YOLOv4, a convolutional neural network (CNN)-based object detection model, was used to automatically detect permanent tooth germs. Panoramic images of children processed in LabelImg were trained and tested in the YOLOv4 algorithm. True-positive, false-positive, and false-negative rates were calculated. A confusion matrix was used to evaluate the performance of the model.Results: The YOLOv4 model, which detected permanent tooth germs on pediatric panoramic radiographs, provided an average precision value of 94.16% and an F1 value of 0.90, indicating a high level of significance. The average YOLOv4 inference time was 90 ms.Conclusion: The detection of permanent tooth germs on pediatric panoramic X-rays using a deep learning-based approach may facilitate the early diagnosis of tooth deficiency or supernumerary teeth and help dental practitioners find more accurate treatment options while saving time and effort."
구강암 조기발견을 위한 영상인식 시스템,2022,[],국문 초록 정보 없음,"Oral cancer is a type of cancer that has a high possibility to be cured if it is threatened earlier. The convolutional neural network is very popular for being a good algorithm for image recognition. In this research, we try to compare 4 different architectures of the CNN algorithm: Convnet, VGG16, Inception V3, and Resnet. As we compared those 4 architectures we found that VGG16 and Resnet model has better performance with an 85.35% accuracy rate compared to the other 3 architectures. In the future, we are sure that image recognition can be more developed to identify oral cancer earlier."
Performance Analysis of Cloud-Net with Cross-sensor Training Dataset for Satellite Image-based Cloud Detection,2022,"['Cloud Detection', 'KOMPSAT-3']",국문 초록 정보 없음,"Since satellite images generally include clouds in the atmosphere, it is essential to detect or mask clouds before satellite image processing. Clouds were detected using physical characteristics of clouds in previous research. Cloud detection methods using deep learning techniques such as CNN or the modified U-Net in image segmentation field have been studied recently. Since image segmentation is the process of assigning a label to every pixel in an image, precise pixel-based dataset is required for cloud detection. Obtaining accurate training datasets is more important than a network configuration in image segmentation for cloud detection. Existing deep learning techniques used different training datasets. And test datasets were extracted from intra-dataset which were acquired by same sensor and procedure as training dataset. Different datasets make it difficult to determine which network shows a better overall performance.To verify the effectiveness of the cloud detection network such as Cloud-Net, two types of networks were trained using the cloud dataset from KOMPSAT-3 images provided by the AIHUB site and the L8-Cloud dataset from Landsat8 images which was publicly opened by a Cloud-Net author. Test data from intra-dataset of KOMPSAT-3 cloud dataset were used for validating the network. The simulation results show that the network trained with KOMPSAT-3 cloud dataset shows good performance on the network trained with L8-Cloud dataset. Because Landsat8 and KOMPSAT-3 satellite images have different GSDs, making it difficult to achieve good results from cross-sensor validation. The network could be superior for intra-dataset, but it could be inferior for cross-sensor data. It is necessary to study techniques that show good results in cross-senor validation dataset in the future."
Autoencoder 및 Variational Autoencoder 기반 위조지문 판별 모델 비교,2022,[],국문 초록 정보 없음,"In this study, to distinguish between actual and artificial fingerprint data, an experiment was conducted to compare the performance of six discriminant models, three per technique, based on two unsupervised learning methods, Autoencoder and Variable Autoencoder. Accuracy (ACC), precision (PRC), reproduction rate (REC), specificity (SPC), and F1 Score were measured and compared for each model. 5 performance indicators showed that the LSTM model has the best performance among AE models, and the 1D CNN, and DNN models have also the best performance among VAE models."
발달 장애 아동의 행동 및 생리적 정보를 통한 딥러닝 기반 참여도 분류,2022,"['발달장애 아동', '참여도', '딥러닝']","본 연구에서는 발달 장애 아동의 행동적, 생리적 정보를 통해 참여도를 분류할 수 있는 딥러닝 모델을 제시하였다. 발달 장애 아동 21 명을 대상으로 아동이 체육 기반 인터렉티브 콘텐츠를 수행할 때 아동의 생체 및 행동 데이터를 웨어러블 디바이스를 사용하여 수집하였다. 데이터는 가속도, 피부 전도도, 체온, 스켈레톤 데이터, 콘텐츠 수행의 성공/실패 여부, 그리고 참여도 총 6 종류의 데이터를 수집하였다. 본 연구에서 제시한 모델은 Convolution 1D 레이어 4 개와 FC 레이어 1 개로 이루어진 CNN 기반의 모델로, 모델 최적화를 위해 매개변수, 데이터 종류, 모델 구조 변화에 따른 정확도 비교를 진행, 최적의 모델을 도출하였다. 본 연구에서 제안한 모델이 기존 연구에 사용된 SVM, RF 등과 같은 모델과 비교하였을 때 뛰어난 성능을 보임을 확인하였으며 이후 실시간으로 아동의 참여도를 측정할 수 있는 도구를 개발할 수 있을 것으로 기대된다.",다국어 초록 정보 없음
딥러닝 기반의 2차원 이미지 왜곡 분류 및 이미지 각도 보정 시스템 개발,2022,"['Neural Network', 'Image Processing', 'Image Distortion', 'Camera Calibration']",국문 초록 정보 없음,"When taking a picture with a camera, the distortion that is different from reality occurs due to wide-angle lenses and camera angles.In this paper, we propose an image distortion classification and calibration program that provides users with standard images before distortion by classification and calibrating distortion. The program automatically predicts camera parameters from a single input image and proceeds with calibration. Inputting the image, distortion image classification using deep learning (CNN) determines whether Wide-angle lens distortion and Camera-angle distortion exist. When it is determined that distortion exists, deep learning and OpenCV are used to calibrate the distortion state according to each image characteristic. As a result of the program operation, it was confirmed that the output image was calibrated similarly to the actual one, and more fine distortion calibration can be expected by finding distortions that were difficult to judge only with human eyes."
DeepLabV3+와 Swin Transformer 모델을 이용한 Sentinel-2 영상의 구름탐지,2022,"['Cloud detection', 'Deep learning', 'Sentinel-2']",국문 초록 정보 없음,"Sentinel-2 can be used as proxy data for the Korean Compact Advanced Satellite 500-4 (CAS500-4), also known as Agriculture and Forestry Satellite, in terms of spectral wavelengths and spatial resolution. This letter examined cloud detection for later use in the CAS500-4 based on deep learning technologies. DeepLabV3+, a traditional Convolutional Neural Network (CNN) model, and Shifted Windows (Swin) Transformer, a state-of-the-art (SOTA) Transformer model, were compared using 22,728 images provided by Radiant Earth Foundation (REF). Swin Transformer showed a better performance with a precision of 0.886 and a recall of 0.875, which is a balanced result, unbiased between over- and under-estimation. Deep learning-based cloud detection is expected to be a future operational module for CAS500-4 through optimization for the Korean Peninsula."
연구개발정보 문헌 자동분류를 위한 자연어 처리 딥러닝 모델 개발: 기후기술 분류체계를 중심으로,2022,"['Multi-class classification', 'Natural language', 'Deep learning', 'Climate technology']","신기후체제에 들어서며 전세계적으로 탄소중립을 선언하고 있으며 이를 위해 국가연구개발사업이 어떤 기후기술에 투자되고 있는지 관심이 고조되고 있다. 본 연구에서는 국가연구개발사업들의 문헌정보를 활용하여 45개의 기후기술 분류체계로 자동분류하는 딥러닝 모델을 개발하였다. NTIS에 등록되어 있는 2016∼2020년에 수행된 291,381건의 연구개발과제 중 2016∼2019년의 217,880건은 훈련 데이터셋으로, 2020년의 73,501건은 테스트 데이터셋으로 구분하여 실험하였다. 형태소 분석을 위해 kiwi와 Mecab을 사용하였으며 딥러닝 모델의 구조는 1D-CNN을 활용한 FC, EC 모델과 ELECTRA 사전학습 모델을 활용한 KoE 모델을 개발하였다. 각 클래스별 빈도의 편차가 큰 불균형데이터임을 고려하여 성능지표로 F1 스코어를 활용하였으며 각 개별모델과 앙상블 모델의 성능을 확인하였다. 개별모델에서는 키워드 빈도를 중심으로 학습하는 FC 모델이 0.824의 F1 스코어로 가장 우수했으며, 앙상블 모델에서는 개별모델 모두를 소프트 보팅(soft voting)한 Ens4 모델이 0.833의 F1 스코어로 가장 높은 성능을 나타냈다. 일반적인 말뭉치보다 전문적인 용어를 다수 포함하고 있는 대량의 기술문서 자동분류에서 본 모델을 사용한다면 기술전문가가 직접 라벨링하는 방법보다 보다 효율적인 프로세스를 갖출 수 있을 것이다.",다국어 초록 정보 없음
CCTV 이미지 분리를 이용한 농업용수로의 공급량 계측,2022,"['U-Net 모델', 'CCTV 이미지', '농업용수로']","농업용수를 효율적으로 사용하기 위해서는 이용량에 대한 정확한 정보가 필요하다. 현재는 초음파 수위계를 이용하여 농업용 저수지와 수로의 수위 데이터를 측정하고 있으며, 수위계 자체의 오류나 주변 환경으로 인해 오류값이나 결측값이 일부 발생하고 있다. 한편, CCTV(Closed Circuit Television) 영상을 이용한 CV(Computer Vision)는 컴퓨터 기술의 발전과 함께 여러 연구 분야에서 활용되고 있다. 본 연구는 CNN(Convolutional Neural Network) 기반 이미지 분리 모델인 U-Net과 CCTV 영상을 이용하여 농업용 수로의 수위를 추정하는 것을 목적으로 한다. U-Net은 대표적인 이미지 분리 모델 중 하나로 의공학, 원격탐사 등 여러 분야에서 가장 많이 활용되고 있으며 이미지에서 원하는 부분을 분리해내는 데에 기존 머신러닝 기술에 비해 좋은 성능을 보이는 것으로 알려져 있다. 본 연구는 국내 농업용 저수지의 관개수로 8개 지구에서 이미지를 획득하여 각각의 모델을 구성하였으며, 총 6,950개의 이미지를 모델에 적용하였다. 전체 이미지의 70%는 훈련에, 10%는 검증에, 20%는 테스트에 사용하였으며, 모델의 성능을 높이기 위해 데이터 증강 기법을 적용하였다. 모델의 성능은 F1 점수와 IoU 점수를 사용하여 평가하였다. 모델을 통해 분리된 수면 면적으로부터 농업용수로의 수위를 계측하고, 최종적으로는 수로의 rating curve 식을 이용하여 공급량을 산정한 후 초음파 수위계를 통해 산정된 공급량 값과 비교하였다. 본 연구는 초음파 수위계의 보조적인 방법으로 농업용 수로의 수위와 공급량을 추정하는 데 활용이 될 수 있을 것이다.",다국어 초록 정보 없음
다중 융합 네트워크 기반 이동 객체 행동 인식,2022,[],"단일 데이터로부터의 이동 객체에 대한 행동 인식 연구는 데이터 수집 과정에서 발생하는 노이즈의 영향을 크게 받는다. 본 논문은 영상 데이터와 센서 데이터를 이용하여 다중 융합 네트워크 기반이동 객체 행동 인식 방법을 제안한다. 영상으로부터 객체가 감지된 영역의 추출과 센서 데이터의 이상치 제거 및 결측치 보간을 통해 전처리된 데이터들을 융합하여 시퀀스를 생성한다. 생성된 시퀀스는 CNN(Convolutional Neural Networks)과 LSTM(Long Short Term Memory)기반 다중 융합 네트워크 모델을 통해 시계열에 따른 행동 특징들을 추출하고, 깊은 FC(Fully Connected) 계층을 통해 특징들을 융합하여 행동을 예측한다. 본 연구에서 제시된 방법은 사람을 포함한 동물, 로봇 등의 다양한 객체에 적용될 수 있다.",다국어 초록 정보 없음
딥러닝을 이용한 원격탐사 영상분석 연구동향,2022,"['Deep learning', 'Remote sensing', 'Image analysis']",국문 초록 정보 없음,"Artificial Intelligence (AI) techniques have been effectively used for image classification, object detection, and image segmentation. Along with the recent advancement of computing power, deep learning models can build deeper and thicker networks and achieve better performance by creating more appropriate feature maps based on effective activation functions and optimizer algorithms. This review paper examined technical and academic trends of Convolutional Neural Network (CNN) and Transformer models that are emerging techniques in remote sensing and suggested their utilization strategies and development directions. A timely supply of satellite images and real-time processing for deep learning to cope with disaster monitoring will be required for future work. In addition, a big data platform dedicated to satellite images should be developed and integrated with drone and Closed-circuit Television (CCTV) images."
BCI 를 위한 동작 상상 뇌파 분류에 관한 연구,2022,[],"뇌신호로부터 사람의 의도를 파악하여 디바이스를 제어하기 위한 뇌-컴퓨터 인터페이스 (brain-computer interface, BCI) 기술이 최근 급격히 발전하고 있다. 본 논문에서는 오른손과 왼손의 움직임을 상상할 때 발생하는 동작 상상 (motor imagery) 뇌파(electroencephalogram, EEG)를 이용해 오른손과 왼손의 움직임을 예측하는 BCI 시스템을 개발하였다. Emotiv 사의 14 채널 무선 뇌파 측정 기기를 사용하여 동장 상상 뇌파를 측정하였고, 합성곱 신경망(convolutional neural networks, CNN) 기반의 분류 모델을 사용하여 오른손과 왼손의 움직임을 예측하였다. 한 사람의 뇌파 데이터를 사용하여 분류정확도 83%를 달성하였다. 향후 분류 모델을 응용하면 간단한 게임 제어에 사용될 수 있을 것으로 기대한다.",다국어 초록 정보 없음
메타버스를 위한 가상 휴먼의 3차원 의상 모델링,2022,"['Metaverse', 'virtual human', '3D cloth modeling']",국문 초록 정보 없음,"In this paper, we propose the new method of creating 3D virtual-human reflecting the pattern of clothes worn by the person in thehigh-resolution whole body front image and the body shape data about the person. To get the pattern of clothes, we proceed InstanceSegmentation and clothes parsing using Cascade Mask R-CNN. After, we use Pix2Pix to blur the boundaries and estimate the backgroundcolor and can get UV-Map of 3D clothes mesh proceeding UV-Map base warping. Also, we get the body shape data using SMPL-X anddeform the original clothes and body mesh. With UV-Map of clothes and deformed clothes and body mesh, user finally can see theanimation of 3D virtual-human reflecting user’s appearance by rendering with the state-of-the game engine, i.e. Unreal Engine."
XAI 기반 반려견 품종 분류,2022,"['Explainable Artificial intelligence', 'Xception', 'Convolutional neural network', 'Dog breed', 'Local interpretable model-agnostic explanation']","최근 반려견에 대한 관심이 날이 갈수록 뜨거워지고 있다. 우리나라는 반려견을 기르는 인구가 급증하면서 '펫코노미’ 시대가 도래했다. 2020년 현재 반려견은 약 512만 가구에서 기르는 것으로 나타났다. 사람들은 반려견을 입양할 때 외모와 성격에 따라 견종을 선택한다. 하지만 펫샾에서 더 비싼 품종으로 속이는 문제가 발생해오고 있다. 이에 딥러닝을 이용한 품종 구별에 관한 연구가 활발히 진행되어왔다. 하지만 딥러닝을 이용한 품종 구별 방법을 구매자가 이해하는 것은 어렵다. 이러한 문제를 해결하기 위해 본 논문에서 우리는 반려견의 품종을 구별하는 CNN 기반의 딥러닝 모델을 구축한 후 이를 XAI 기법 중 하나인 LIME을 이용하여 분류 근거를 이미지로 보여준다. 데이터 셋을 위해 우리나라에서 가장 많이 키우는 견종을 선정한 후, 서로 구분이 어려운 품종들을 추가하였다. 그런 다음 실험들을 통해 최적의 하이퍼파라미터들을 찾아 분류의 근거를 가장 잘 보여주는 이미지를 추출했다. 이를 근거로 펫을 입양하는 사람은 자신이 입양하려는 펫의 품종을 믿을 수 있고, 펫샵 역시 품종의 근거를 제시함으로써 신뢰를 구축할 수 있다.",다국어 초록 정보 없음
딥러닝 기술에 기반한 사용자 이동 경로의 이상치 탐지 기법,2022,"['anomaly detection', 'outlier detection', 'trajectory', 'deep learning', 'data quality']",국문 초록 정보 없음,"Trajectory data refers to data having a continuous GPS location using various mobile devices, and data inspection and refinement are important in order for such trajectory data to be utilized for machine learning. The Anomaly detection technology improves the performance of machine learning by finding outliers in the dataset and improving the quality of the data. This paper describes outlier types from user trajectories and proposes a model for detecting outliers using 5 deep learning models(CNN, DNN, LSTM, Bi-LSTM, LSTM-autoencoder). In addition, in order to select the most suitable model among the 5 deep learning models, the actual trajectory dataset is trained on each model, and its performance is measured by detecting outliers. As a result of the comparative evaluation, the LSTM-autoencoder model had the highest F1-score for anomaly detection compared to other models and showed stable performance."
멀티채널 충전/방전 프로파일을 활용한 딥러닝 기반 리튬이온 배터리 용량 추정,2022,[],"리튬 이온 배터리 팩을 안전하고 효율적으로 사용하려면 배터리 상태를 모니터링하는 것이 매우 중요하다. 따라서 다양한 배터리 상태 중에서 배터리의 성능과 수명을 나타내는 SOH(State-of-Health)를 추정해야 하는 것이 주요 쟁점이다. 본 논문에서는 인공신경망(ANN)의 다양한 구조를 이용하여 SOH를 추정하고 충전 과정에서 측정된 배터리 셀의 전압, 전류, 온도를 SOH를 추정하는 특성으로 사용한다. 또한 쿨롱 계수 방식으로 측정한 배터리 셀의 방전 용량을 특징으로 추가로 사용하여 충전과 방전시의 프로파일을 동시에 고려하는 딥러닝 방식을 제안한다. FNN(Feedforward Neural Network), CNN(Convolutional Neural Network), LSTM(Long Short-Term Memory) 등 다양한 ANN 구조의 성능을 평가하고, 방전 용량을 사용하면 SOH 추정 성능이 크게 향상됨을 확인하였다.",다국어 초록 정보 없음
온실 참외 과실 인식을 위한 개체분할 모델의 적용,2022,"['참외', '스마트팜', '수확로봇', '개체분할', '딥러닝']","인공지능과 센싱 등의 기술이 고도화되면서 지능형 농업이 발전함에 따라 온실에서 로봇 기반 수확 및 모니터링을 위한 작물 영상 기반 인식 기술의 필요성이 증대되고 있다. 또한 최근 참외의 시설 및 수경재배 증가에 따른 생력화 가능성이 대두되었으나, 참외는 덩굴성 줄기로 인해 토마토, 파프리카와 같은 수직형 수형이 아닌 수평형 수형을 지니고 있고 잎이 상대적으로 크기 때문에 과실 인식이 어렵다. 본 연구는 CNN(Convolutional Neural Networks) 알고리즘 중 real-time 개체분할(instance segmentation) 방식인 YOLACT를 이용해 RGB 영상 기반 온실 참외 과실에 대한 인식 기술 개발을 목적으로 수행되었다. 또한 검출된 참외 과실의 수확 여부를 결정하기 위해 숙성 완료한 과실과 그렇지 않은 과실을 두 클래스로 나누어 학습하여 과실의 숙도 선별도 동시에 이루어졌다. 카메라를 통해 획득한 참외 영상에서 참외 영역을 구분하기 위해 Labelme 프로그램을 이용해 참외 과실을 Polygon 방식으로 labeling 하여 개체분할을 위한 데이터 전처리를 수행했다. 수확 과실 인식을 위해 YOLACT 알고리즘을 사용하여 데이터를 학습시켰고, 학습된 모델을 실제 촬영한 동영상을 이용하여 검증했다. 학습을 위해 사용된 이미지 수는 총 493장이며 해당 이미지에서 labeling 된 총 과실수는 2,450개였고, 에포크와 배치 사이즈, 학습률은 각각 1000, 16, 0.001으로 설정하였다. 학습 모델의 total loss 값은 0.3039에서 수렴하였으며 검증 결과 참외 과실이 명확히 구분되어 숙도 여부를 정확히 인지하였다. 본 연구 결과를 토대로 과실의 숙도에 따른 수확 로봇을 개발하는 경우 픽셀 기반으로 작물의 구체적인 형태를 인식하는 개체분할 모델을 적용하는 것이 로봇의 수확 성능을 높이고 수확량을 예측하는 데 유용할 수 있을 것으로 기대된다.",다국어 초록 정보 없음
온실 참외 과실 인식을 위한 개체분할 모델의 적용,2022,"['참외', '스마트팜', '수확로봇', '개체분할', '딥러닝']","인공지능과 센싱 등의 기술이 고도화되면서 지능형 농업이 발전함에 따라 온실에서 로봇 기반 수확 및 모니터링을 위한 작물 영상 기반 인식 기술의 필요성이 증대되고 있다. 또한 최근 참외의 시설 및 수경재배 증가에 따른 생력화 가능성이 대두되었으나, 참외는 덩굴성 줄기로 인해 토마토, 파프리카와 같은 수직형 수형이 아닌 수평형 수형을 지니고 있고 잎이 상대적으로 크기 때문에 과실 인식이 어렵다. 본 연구는 CNN(Convolutional Neural Networks) 알고리즘 중 real-time 개체분할(instance segmentation) 방식인 YOLACT를 이용해 RGB 영상 기반 온실 참외 과실에 대한 인식 기술 개발을 목적으로 수행되었다. 또한 검출된 참외 과실의 수확 여부를 결정하기 위해 숙성 완료한 과실과 그렇지 않은 과실을 두 클래스로 나누어 학습하여 과실의 숙도 선별도 동시에 이루어졌다. 카메라를 통해 획득한 참외 영상에서 참외 영역을 구분하기 위해 Labelme 프로그램을 이용해 참외 과실을 Polygon 방식으로 labeling 하여 개체분할을 위한 데이터 전처리를 수행했다. 수확 과실 인식을 위해 YOLACT 알고리즘을 사용하여 데이터를 학습시켰고, 학습된 모델을 실제 촬영한 동영상을 이용하여 검증했다. 학습을 위해 사용된 이미지 수는 총 493장이며 해당 이미지에서 labeling 된 총 과실수는 2,450개였고, 에포크와 배치 사이즈, 학습률은 각각 1000, 16, 0.001으로 설정하였다. 학습 모델의 total loss 값은 0.3039에서 수렴하였으며 검증 결과 참외 과실이 명확히 구분되어 숙도 여부를 정확히 인지하였다. 본 연구 결과를 토대로 과실의 숙도에 따른 수확 로봇을 개발하는 경우 픽셀 기반으로 작물의 구체적인 형태를 인식하는 개체분할 모델을 적용하는 것이 로봇의 수확 성능을 높이고 수확량을 예측하는 데 유용할 수 있을 것으로 기대된다.",다국어 초록 정보 없음
Continuous Blood Pressure Estimation using 1D Convolutional Neural Network and Attention Mechanism,2022,"['Luong attention', 'Blood pressure', '1D convolutional neural network', 'Attention mechanism']",국문 초록 정보 없음,"Patients with hypertensive blood pressure (BP) needs a round-the-clock BP monitoring and must take precautions to prevent emergencies such as stroke or heart failure. This paper suggests a deep neural network (DNNs–based BP estimation approach using electrocardiogram (ECG), photoplethysmogram (PPG), and ballistocardiogram (BCG) signals. The proposed approach consists of a one-dimensional convolutional neural network (1D CNN) followed by the attention mechanism known as Luong attention. Estimations under the proposed model yield mean absolute error (MAE) of 3.299±2.419 for systolic and 2.69±1.821 for diastolic BP. The algorithm can effectively predict BP without a recurrent neural network (RNNs), which is a typical DNNs model for processing sequential data. Additionally, the proposed approach is preferable owing to its ability to explain the model."
계층적 분류 및 회귀 그래프 신경망을 이용한 최적의 트러스 구조 예측 방법,2022,"['위상최적화(Topology optimization)', '그래프신경망(Graph neural network)', '딥러닝(Deep learning)', '트러스구조(Truss structure)', '최적설계(Optimal design)', 'Ground structure method']",국문 초록 정보 없음,"This paper proposes a graph neural network-based hierarchical classification and regression model to predict the optimal ground structure layout. A ground structure consists of a set of interconnected bars similar to a graph structure. The number of bars and joints depends on the size and configuration of the target design domains. Conventional neural networks, such as MLP and CNN, cannot handle such variable-dimensional data. Therefore, we adopted a graph neural network using the similarity between ground structure and graph. Only a few of the potential bar candidates remained after ground structure optimization converged. It causes the highly imbalanced distribution of bar areas, which is difficult to predict. Therefore, we construct the model to process a binary classification task to classify the presence or absence of remaining bars among potential bar candidates, and then sequentially process a regression task to predict the detailed value of the cross-sectional areas. To validate the proposed model, three types of ground structure optimization problems were defined: cantilever, simply supported, and L-shape beams. The model was evaluated with three evaluation metrics: classification, regression, and optimality. As a result, it predicts the presence or absence of the optimal ground structure with more than 95% accuracy and predicts the cross-sectional areas of the remaining bars with greater than 95% accuracy."
시계열 데이터의 이상 탐지를 위한 Recurrence Plot 알고리즘 기반 시계열 이미지 생성 방안,2022,[],시계열 데이터에서 이상치를 탐지하기 위해서는 PCA나 오토인코더와 같은 통계적 기법을 사용하거나 RNN 같은 딥러닝 모델을 기반으로 이상치를 탐지한다. 그러나 이상치가 기록되는 환경 및 원인이 단순하지 않고 다양한 변인이 영향을 미치기 때문에 간단한 통계적 기법 또는 RNN 기반 딥러닝 모델만으로 좋은 성능을 기대하기 어렵다. 본 논문에서는 시계열 데이터를 이미지화시켜서 대표적인 이미지의 이진(Binary) 분류 모델인 CNN 기반의 딥러닝 모델을 사용하여 이상치를 탐지하는 방법을 제안하였고 기존 LSTM 기반 모델보다 0.01 높은 F1-Score를 보여줌으로써 동등하거나 더 높은 성능을 도출하였다.,다국어 초록 정보 없음
A deep learning approach to permanent tooth germ detection on pediatric panoramic radiographs,2022,"['Tooth Germ', 'Radiograph', 'Panoramic', 'Pediatric Dentistry']",국문 초록 정보 없음,"Purpose: The aim of this study was to assess the performance of a deep learning system for permanent tooth germ detection on pediatric panoramic radiographs. Materials and Methods: In total, 4518 anonymized panoramic radiographs of children between 5 and 13 years of age were collected. YOLOv4, a convolutional neural network (CNN)-based object detection model, was used to automatically detect permanent tooth germs. Panoramic images of children processed in LabelImg were trained and tested in the YOLOv4 algorithm. True-positive, false-positive, and false-negative rates were calculated. A confusion matrix was used to evaluate the performance of the model. Results: The YOLOv4 model, which detected permanent tooth germs on pediatric panoramic radiographs, provided an average precision value of 94.16% and an F1 value of 0.90, indicating a high level of significance. The average YOLOv4 inference time was 90 ms. Conclusion: The detection of permanent tooth germs on pediatric panoramic X-rays using a deep learning-based approach may facilitate the early diagnosis of tooth deficiency or supernumerary teeth and help dental practitioners find more accurate treatment options while saving time and effort"
OC-SVM기반 탑승자 칵핏모듈 충돌 상해위험도 예측알고리즘 연구,2022,"['Passenger criterion(탑승자 상해도)', 'Passenger safety(탑승자 안전)', 'Passive safety(수동 안전)', 'Anomaly Detection(이상 감지)', 'Machine Learning(머신 러닝)']","본 논문에서는 칵핏모듈과 탑승자 충돌에 따른 상해위험도 예측알고리즘을 제안한다. 상해위험도는 충돌 충격 값 ‘64G’를 기준 값으로 정하고, 64G미만은 상해위험도 ‘보통’, 64G 이상은 ‘위험’으로 구분한다. 상해위험도 예측을 위한 알고리즘은 OC-SVM을 선정하였으며, 영상데이터 3종류(A/L/T Section)와 수치 데이터 2종류(충격 속도, 충격 각도)를 Concatenation연산 후 OC-SVM 알고리즘의 입력으로 활용된다. 영상데이터의 경우 InceptionResNetV2[2]의 CNN(Convolution Neural Network)부분만 추출한 네트워크를 기반으로 Concatenation연산 전에 영상데이터 내부 특징 추출 과정을 진행한다. 제안한 예측 알고리즘은 테스트 데이터 선정 방법에 따라 (1) 40차종 중 19차종 선정, (2) K개의 데이터 선정, 총 2가지 경우를 기반으로 성능을 검증한다.",다국어 초록 정보 없음
파워쉘 기반 악성코드에 대한 역난독화 처리와 딥러닝 기반 탐지 방법,2022,"['Powershell', 'deobfuscation', 'deep learning']","2021년에는 코로나의 여파로 랜섬웨어를 활용한 공격이 유행했으며 그 수는 매년 급증하고 있다. 그 중 파워쉘은 랜섬웨어에 주요 기술로 사용되고 있어 파워쉘 기반 악성코드 탐지 기법의 필요성은 증가하고 있으나 기존의 탐지 기법은 난독화가 적용된 스크립트를 탐지하지 못하거나 역난독화에 시간이 오래 소요되는 한계가 존재한다. 이에 본 논문에서는 간단하고 빠른 역난독화 처리과정, Word2Vec과 CNN(Convolutional Neural Network)으로 구성되어 스크립트의 의미를 학습하고 특징을 추출해 악성 여부를 판단할 수 있는 딥러닝 기반의 분류 모델을 제안한다. 2021 사이버보안 AI/빅데이터 활용 경진대회의 AI 기반 파워쉘 악성 스크립트 탐지 트랙에서 제공된 1400개의 악성코드와 8600개의 정상 스크립트를 이용하여 제안한 모델을 테스트한 결과 기존보다 5.04배 빠른 역난독화 실행 시간, 100%의 역난독화 성공률, 0.01의 FPR(False Positve Rate), 0.965의 TPR(True Positive Rate)로 악성코드를 빠르고 효과적으로 탐지함을 보인다.",다국어 초록 정보 없음
딥러닝 기반의 IMU 센서 데이터를 활용한 운동 분류 및 횟수 예측 연구,2022,[],웨이트 트레이닝을 통해 운동 수행능력을 성장시키기 위해서는 운동 별로 세트 수와 반복 횟수를 기록해두는 것이 중요하다. 이를 자동화하기 위해 귀에 착용하는 히어러블(hearable) 장치 내에 내장된 IMU 센서를 통해 사용자의 운동 데이터를 수집하고 이를 활용하여 운동 종목과 반복횟수를 예측하는 딥러닝 기반의 알고리즘을 제안한다. 본 논문에서 제안하는 인공 신경망 모델은 2D 합성곱 신경망(CNN)을 활용하며 학습 성능을 극대화하기 위하여 취득된 센서 데이터의 주파수 및 내재적 특징을 고려하여 여러 시계열 데이터 증강 기법을 적용하여 학습 데이터를 증강한다. 실험을 통해 각 데이터 증강 기법이 운동 분류 예측 및 횟수 예측에 미치는 영향을 알아보고 최종적으로 모든 데이터 증강 기법이 활용되었을 때의 성능을 소개한다.,다국어 초록 정보 없음
이동통신 시스템에서 인공지능을 이용한 경로 손실 예측 및 기지국 지형 구분 방법,2022,[],"이동통신 시스템에서 정확하고 신속한 통신망 구축은 중요하다. 현재 무선통신 시스템을 구성하기 위해서는 셀 플래닝 장비를 통해 기지국의 파라미터를 설정한다. 하지만 기지국의 신규 설치마다 셀 플래닝을 새로 수행해야 하며, 셀 플래닝에 반영되지 않은 장애물 정보 등 실제 환경과 맞지 않는 파라미터가 설정되는 문제가 발생할 수 있다. 이 논문에서는 SON 서버에서 기지국의 위치와 단말의 측정 정보를 이용한 DNN 모델을 통해 경로 손실 예측을 수행하고, 지형을 구분하는 CNN 모델을 통해 예측된 경로 손실의 지형을 구분한다. 구분된 지형을 바탕으로 SON 서버에서 해당 지형에 맞는 지형별 기지국 파라미터를 자동으로 설정하고 지속해서 지형별 파라미터를 업데이트하여, 지형과 주변 환경 변화를 고려한 기지국 파라미터를 자동으로 설정할 수 있다.",다국어 초록 정보 없음
A Study on Finding Emergency Conditions for Automatic Authentication Applying Big Data Processing and AI Mechanism on Medical Information Platform,2022,"['AI Mechanism & Big Data Processing', 'Automatic Authentication', 'Edge Computing', 'Emergency Conditions', 'Medical Information Platform']",국문 초록 정보 없음,"We had researched an automatic authentication-supported medical information platform[6]. The proposed automatic authentication consists of user authentication and mobile terminal authentication, and the authentications are performed simultaneously in patients’ emergency conditions. In this paper, we studied on finding emergency conditions for the automatic authentication by applying big data processing and AI mechanism on the extended medical information platform with an added edge computing system. We used big data processing, SVM, and 1-Dimension CNN of AImechanism to find emergency conditions as authentication means considering patients’ underlying diseases such as hypertension, diabetes mellitus, and arrhythmia. To quickly determine a patient’s emergency conditions, we placed edge computing at the end of the platform. The medical information server derives patients’ emergency conditions decision values using big data processing and AI mechanism and transmits the values to an edge node. If the edge node determines the patient emergency conditions, the edge node notifies the emergency conditions to the medical information server. The medical server transmits an emergency message to the patient’s charge medical staff. The medical staff performs the automatic authentication using a mobile terminal. After the automatic authentication is completed, the medical staff can access the patient’s upper medical information that was not seen in the normal condition."
음압자료를 이용한 해저면 분류 기술 현황,2022,"['해저면 원격 분류', '멀티빔 음향시스템', '후방산란', '해저 서식지', 'Remote Seabed Classification', 'Multibeam Echosounder', 'Backscatter', 'Benthic Habitat Map']",국문 초록 정보 없음,"This paper is intended to share basic information to advance the acoustic seabed classification technology. Chapter 1 describes the necessity and basic concept of the corresponding technology, and Chapter 2 summarizes the current trends of acoustic seabed classification technology, which is based on international case studies such as QTC-Multiview, Self-Organizing Map, APL model, Angular Response Analysis, Improved SOM, CNN, etc. Chapter 3 discusses the research topics to enhance detectability and recognizability for the sediment type and to improve the accuracy of the classification. The research topics include methodologies to obtain the ground-truth suitable to the penetration depth of acoustic waves and the consistency of backscatter data."
합성곱신경망을 활용한 과구동기 시스템을 가지는 소형 무인선의 추진기 고장 감지,2022,"['Unmanned surface vehicle(무인 수상 선박)', 'Fault detection(고장 감지)', 'Convolutional neural network(합성곱신경망)', 'ROS', 'Overacturated(과구동기)', 'Wavelet transform(웨이블렛 변환)']",국문 초록 정보 없음,"This paper proposes a fault detection method for a Unmanned Surface Vehicle (USV) with overactuated system. Current status information for fault detection is expressed as a scalogram image. The scalogram image is obtained by wavelet-transforming the USVs control input and sensor information. The fault detection scheme is based on Convolutional Neural Network (CNN) algorithm. The previously generated scalogram data was transferred learning to GoogLeNet algorithm. The data are generated as scalogram images in real time, and fault is detected through a learning model. The result of fault detection is very robust and highly accurate."
4mCPred-Caps: Identification of DNA N4-methylcytosine sites using CapsuleNet,2022,"['N4-methylcytosine', 'Epigenetics', 'CapsuleNet', 'Neural networks']",국문 초록 정보 없음,"N4-methylcytosine (4mC) is amongst the most significant DNA modifications and is associated with the progression of gene expression, gene differentiation, and cell proliferation. It is essential to locate their alteration sites in the genome sequences in order to understand the biological roles of 4mC. Deep learning has recently gained popularity and is widely used for the identification of 4mC sites. In this study, a convolutional neural network (CNN) based model using CapsuleNet, 4mCPred-Caps, was created to categorize 4mC sites in three different species, Arabidopsis thaliana, Caenorhabditis elegans, and Drosophila melanogaster. Using the benchmark datasets of these species, we assessed the model performance and equate it with the previously available methodologies. We built our model using a single encoding technique called one-hot-encoding along with a special architecture called CapsuleNet. The proposed model acquired an accuracy of 84.8%, 90%, and 88.2% respectively on Arabidopsis thaliana, Caenorhabditis elegans, and Drosophila melanogaster respectively. The outcomes demonstrate that the proposed model surpassed the currently available tools in terms of all assessment parameters. The results collected indicate that the suggested approach can be very beneficial in the area of bioinformatics."
합성곱 신경망 기반 분류 모델의 화재 예측 성능 분석,2022,"['Fire detection', 'Fire image classification', 'Convolutional neural network', 'Fire prediction performance']","본 연구에서는 화재 안전 향상을 위한 엣지 컴퓨팅(edge computing) 기반 화재감지시스템에 적용 가능한 합성곱 신경망 기반 이미지 분류 모델들인 MobileNetV2, ResNet101, EfficientNetB0를 이용하여 화재 예측 성능 해석을 수행하였다. 성능평가지표인 정확도, 재현율, 정밀도, F1-score와 혼동 행렬을 이용하여 화재 예측 성능을 비교 분석하였다. 또한 분류 모델의 경량화와 관련한 모델 용량 및 추론시간에 대한 비교 분석을 수행하였다. 비교 분석 결과로서 화재 예측 정확도는 EfficientNetB0 모델이 가장 높았으며 경량성 측면에서는 MobileNetV2가 가장 우수한 것으로 확인하였다. 더하여 화재와 유사한 특징을 갖는 비 화재 이미지인 빛과 연무에 대한 이미지 특성을 추가 학습한 결과, 경량성은 우수하나 예측 성능이 낮은 MobileNetV2의 화재 예측 정확도가 개선되는 것을 확인하였다.","In this study, fire prediction performance was analyzed using convolutional neural network (CNN)-based classification models such as MobileNetV2, ResNet101, and EfficientNetB0 applicable to an edge computing-based fire detection system for improving fire safety. The fire prediction performance was evaluated using the performance evaluation measures including accuracy, recall, precision, F1-score, and the confusion matrix. The model size and inference time were assessed in terms of the light-weight classification model for the practical deployment and use. The analysis results confirmed that the EfficientNetB0 model had the highest fire prediction accuracy, and the MobileNetV2 was the best light-weight classification model. Notably, additionally learning the image features about light and haze images having similar features with those of the fire images improved the fire prediction accuracy of the light-weight MobileNetV2 model."
An Improved Attention-based Bidirectional LSTM Model for Cyanobacterial Bloom Prediction,2022,"['Attention mechanism', 'bidirectional LSTM model', 'convolutional neural network', 'cyanobacterial bloom prediction.']",국문 초록 정보 없음,"Cyanobacterial blooms are one of the most serious water pollution problems for freshwater lakes. The treatment of blooms requires a lot of material and financial resources, so an early accurate prediction of cyanobacterial blooms is a very important way to deal with the outbreak of them. But it is challenging to predict the cyanobacterial blooms due to the uncertainty and complexity of their growth process. To deal with this problem, an improved attention-based bidirectional long short-term memory (LSTM) model is proposed in this paper, to make multistep predictions of chlorophyll-a concentration, which is a recognized characterization of algae activity. Firstly, the convolutional neural network (CNN) is used to extract data features and spatiotemporal correlation. Secondly, the bidirectional LSTM network (BiLSTM) is used to predict the concentration of chlorophyll-a based on the extracted features. Finally, the attention mechanism is used to calculate the weights for the characteristic factors that affect the chlorophyll-a concentration. At last, some experiments are carried out based on the real monitoring data of a platform in the Taihu Lake area. Compared with the prediction results of the other four state-of-the-art deep learning methods, the results show that the proposed method in this paper has the highest prediction accuracy."
딥러닝을 이용한 돼지 얼굴 인식,2022,[],국문 초록 정보 없음,"The development of livestock faces intensive farming results in a rising need for recognition of individual animals such as cows and pigs is related to high traceability. In this paper, we present a non-invasive biometrics systematic approach based on the deep-learning classification model to pig face identification. Firstly, in our systematic method, we build a ROS data collection system block to collect 10 pig face data images. Secondly, we proposed a preprocessing block in that we utilize the SSIM method to filter some images of collected images that have high similarity. Thirdly, we employ the improved image classification model of CNN (ViT), which uses the finetuning and pretraining technique to recognize the individual pig face. Finally, our proposed method achieves the accuracy about 98.66%."
Generation of Super-Resolution Images from Satellite Images Based on Improved RCAN,2022,"['Satellite Images', 'Super-Resolution', 'Convolutional Neural Network', 'Residual Channel Attention Network', 'Style-based Recalibration Module']",국문 초록 정보 없음,"Satellite images can be analyzed and used for a variety of purposes. In the future, satellite image analysis will become more important since the number of satellites launches, and the amount of satellite data increase every year. Under these circumstances, there are some problems to be solved. One is the existence of low-resolution satellite images. To analyze the lower resolution of satellite images there are some technical issues such as reduction of noise, misclassification of object recognition. Therefore, high-resolution images are necessary. However, high-resolution satellite images are expensive, and its images may not be available in the past satellite images. Super-resolution which is introduced in image processing is a method to solve these problems. Convolutional neural network (CNN)-based methods are effective, and there is a need for models that can perform super-resolution with higher accuracy. In this paper, we propose a method for super-resolving satellite images, based on the improved the RCAN (residual channel attention network) model with SRM (style-based recalibration module). The proposed method improves the PSNR (peak signal to noise ratio) by 0.0181 dB compared to the conventional RCAN model."
레이저 변위 센서를 활용한 배관 표면 상태분류,2022,"['Pipe(배관)', 'Laser Displacement Sensor(레이저 변위 센서)', 'Convolution Neural Network(합성곱신경망)', 'VGGNet(VGGNet)', 'State Classification(상태분류)']",국문 초록 정보 없음,"Although pipe performs various functions in industrial sites and residential spaces, if it is damaged due to corrosion caused by the external environment, it may cause equipment failure or a major accident. For this reason, various studies for safety management are being conducted, but studies on detecting corrosion or cracks on the pipe surface using a laser displacement sensor have hardly been conducted. Therefore, in this study, the corrosion degree of the pipe surface was compared and classified into 4 corrosion conditions, and inspection equipment using a laser scanner was manufactured. The corrosion height was calculated from the four surface data obtained from the measuring equipment and applied to various CNN algorithms, and 91% accuracy was obtained during training using the Modified VGGNet16 code with reduced number of parameters."
Remote Sensing Image Classification for Land Cover Mapping in Developing Countries: A Novel Deep Learning Approach,2022,"['Convolutional neural network', 'remote sensing image classification', 'Land cover mapping', 'medium-resolution']",국문 초록 정보 없음,"Convolutional Neural networks (CNNs) are a category of deep learning networks that have proven very effective in computer vision tasks such as image classification. Notwithstanding, not much has been seen in its use for remote sensing image classification in developing countries. This is majorly due to the scarcity of training data. Recently, transfer learning technique has successfully been used to develop state-of-the art models for remote sensing (RS) image classification tasks using training and testing data from well-known RS data repositories. However, the ability of such model to classify RS test data from a different dataset has not been sufficiently investigated. In this paper, we propose a deep CNN model that can classify RS test data from a dataset different from the training dataset. To achieve our objective, we first, re-trained a ResNet-50 model using EuroSAT, a large-scale RS dataset to develop a base model then we integrated Augmentation and Ensemble learning to improve its generalization ability. We further experimented on the ability of this model to classify a novel dataset (Nig_Images). The final classification results shows that our model achieves a 96% and 80% accuracy on EuroSAT and Nig_Images test data respectively. Adequate knowledge and usage of this framework is expected to encourage research and the usage of deep CNNs for land cover mapping in cases of lack of training data as obtainable in developing countries."
한국 남부 해역 SST의 계절 및 경년 변동이 단기 딥러닝 모델의 SST 예측에 미치는 영향,2022,"['Short-term U-Net based SST prediction', 'PDO and Seasonal Variabilities']",국문 초록 정보 없음,"Sea Surface Temperature (SST), one of the ocean features, has a significant impact on climate, marine ecosystem and human activities. Therefore, SST prediction has been always an important issue. Recently, deep learning has drawn much attentions, since it can predict SST by training past SST patterns. Compared to the numerical simulations, deep learning model is highly efficient, since it can estimate nonlinear relationships between input data. With the recent development of Graphics Processing Unit (GPU) in computer, large amounts of data can be calculated repeatedly and rapidly. In this study, Short-term SST will be predicted through Convolutional Neural Network (CNN)-based U-Net that can handle spatiotemporal data concurrently and overcome the drawbacks of previously existing deep learning-based models. The SST prediction performance depends on the seasonal and interannual SST variabilities around the southern coast of Korea. The predicted SST has a wide range of variance during spring and summer, while it has small range of variance during fall and winter. A wide range of variance also has a significant correlation with the change of the Pacific Decadal Oscillation (PDO) index. These results are found to be affected by the intensity of the seasonal and PDO-related interannual SST fronts and their intensity variations along the southern Korean seas. This study implies that the SST prediction performance using the developed deep learning model can be significantly varied by seasonal and interannual variabilities in SST."
정적 영상 기반 행동 인식을 활용한 낙상 감지 기술 및 운전자 부주의 감지 기술 개발,2022,"['Still Image-based Action Recognition', 'Fall Detection', 'Driver Drowsiness Detection', 'Hazardous Event Detection', '.']",국문 초록 정보 없음,.
사물인터넷 기기 고장 진단을 위한 그래프 신경망 모델 기반 분류 방법,2022,"['Graph convolutional networks', 'Convolutional neural networks', 'Fault diagnosis', 'Internet of things']","각종 기기들이 연결되는 사물인터넷(internet of things) 시스템에서 중요한 부품의 고장은 경제적, 인명의 손실을 야기할 수 있다. 시스템 내에서 발생하는 고장으로 인한 손실을 줄이기 위해 고장 검진 기술이 IoT에서 중요한 기술로써 여겨지고 있다. 본 논문에서는 그래프 신경망 기반 방법을 사용하여 시스템 내의 설비에서 취득된 진동 데이터의특징을 추출하여 고장 여부를 판단하고 유형을 분류하는 방법을 제안한다. 딥러닝 모델의 학습을 위해, CWRU(case western reserve university)에서 취득된 고장 데이터 셋을 입력 데이터로 사용한다. 제안하는 모델의 분류 정확도 성능을 확인하기 위해 기존 제안된 합성곱 신경망(convolutional neural networks) 기반 분류 모델과 제안된 모델을비교한다. 시뮬레이션 결과, 제안된 모델은 불균등하게 나누어진 데이터에서 기존 모델보다 분류 정확도를 약 5% 향상시킬 수 있는 것을 확인하였다. 이후 연구로, 제안하는 모델을 경량화해서 분류 속도를 개선할 예정이다.","In the IoT(internet of things) where various devices can be connected, failure of essential devices may lead to a lot of economic and life losses. For reducing the losses, fault diagnosis techniques have been considered an essential part of IoT. In this paper, the method based on a graph neural network is proposed for determining fault and classifying types by extracting features from vibration data of systems. For training of the deep learning model, fault dataset are used as input data obtained from the CWRU(case western reserve university). To validate the classification performance of the proposed model, a conventional CNN(convolutional neural networks)―based fault classification model is compared with the proposed model. From the simulation results, it was confirmed that the classification performance of the proposed model outweighed the conventional model by up to 5% in the unevenly distributed data. The classification runtime can be improved by lightweight the proposed model in future works."
A Computerized Doughty Predictor Framework for Corona Virus Disease: Combined Deep Learning based Approach,2022,"['Adaptive Dragonfly Algorithm', 'Auto Augmentation', 'COVID-19 Predictor', 'Deep Learning', 'Ensemble Learning', 'Image Processing', 'UNet Segmentation']",국문 초록 정보 없음,"Nowadays, COVID-19 infections are influencing our daily lives which have spread globally. The major symptoms’ of COVID-19 are dry cough, sore throat, and fever which in turn to critical complications like multi organs failure, acute respiratory distress syndrome, etc. Therefore, to hinder the spread of COVID-19, a Computerized Doughty Predictor Framework (CDPF) is developed to yield benefits in monitoring the progression of disease from Chest CT images which will reduce the mortality rates significantly. The proposed framework CDPF employs Convolutional Neural Network (CNN) as a feature extractor to extract the features from CT images. Subsequently, the extracted features are fed into the Adaptive Dragonfly Algorithm (ADA) to extract the most significant features which will smoothly drive the diagnosing of the COVID and Non-COVID cases with the support of Doughty Learners (DL). This paper uses the publicly available SARS-CoV-2 and Github COVID CT dataset which contains 2482 and 812 CT images with two class labels COVID+ and COVID-. The performance of CDPF is evaluated against existing state of art approaches, which shows the superiority of CDPF with the diagnosis accuracy of about 99.76%."
앙상블 학습 알고리즘과 인공지능 표정 인식 기술을 활용한 사용자 감정 맞춤 힐링 서비스,2022,[],국문 초록 정보 없음,"The keyword ‘healing’ is essential to the competitive society and culture of Koreans. In addition, as the time at home increases due to COVID-19, the demand for indoor healing services has increased.Therefore, this thesis analyzes the user's facial expression so that people can receive various 'customized' healing services indoors, and based on this, provides lighting, ASMR, video recommendation service, and facial expression recording service.The user's expression was analyzed by applying the ensemble algorithm to the expression prediction results of various CNN models after extracting only the face through object detection from the image taken by the user."
객체 검출과 객체 분할 방법의 무인 감시 데이터셋 적용 결과 비교,2022,"['Visual surveillance', 'Deep learning', 'Transformer', 'Semantic segmentation', 'Object detection', '.']",국문 초록 정보 없음,.
Autonomous Underwater Vehicle Control for Fishnet Inspection in Turbid Water Environments,2022,"['Autonomous underwater vehicle', 'convolutional neural network', 'underwater inspection', 'vision-based control.']",국문 초록 정보 없음,"Fisheries are essential for the economic supply of proteins. Detecting damaged fishnets using autonomous underwater vehicles (AUVs) may be an efficient and safe solution for avoiding dangers to human divers. However, in turbid underwater environments, visibility is significantly degraded by floating particles that cause light attenuation, which is one of the main problems for accurate underwater inspection by optical cameras. To obtain clear images for net inspection, we propose an AUV pose control strategy for fish farming net inspection in turbid water, based on the mean gradient feature over the partial or entire image. To alleviate the laborious human process of setting the desired set-point for distance control, a convolutional neural network (CNN) is trained offline using a supervised learning method and combined with a controller. The proposed method can maintain a relatively constant relative pose with respect to a fishnet, which is sufficient to acquire clear net images in turbid water and check whether a part of the net is damaged or not. Experimental results in both swimming pools and real fish farm environments demonstrated the effectiveness of the proposed methods."
딥러닝 기반 고인쇄물 내 글자 추출 및 인식을 통한 3차원 활자 복원,2022,"['Type reconstruction', 'Image segmentation', 'Character segmentation', 'Character classification', 'Historical printed documents']","한글 활자 및 활자본은 역사적 가치뿐만 아니라 인쇄사, 국어사, 한글 글꼴 등 여러 측면에서 중요한 가치를 지닌다. 하지만 오랜 세월이 지나면서 그 당시의 활자들이 온전히 보존되어 전해지지 않은 경우가 대부분이다. 본 논문에서는 딥러닝을 기반으로 활자로 인쇄된 고문서의 글씨로부터 활자 구조 정보를 추출하여 활자본 인쇄에 사용된 3차원 활자의 정보들을 추정하는 방법을 제안한다. 먼저, 고인쇄 활자본의 고해상도 스캔 영상 데이터에 대해 딥러닝(U-Net)을 적용하여 글자 획 영역만을 추출하고 음소 단위 영역으로 나누어 모든 글자에 대해 글자 인식과 위치를 파악한다. 추출된 글자 분할 데이터는 음소별로 구분하여 인식하는 Convolutional neural network (CNN) 모델을 통해 같은 글자끼리 분류한다. 같은 글자 영상 간 정합을 위해 이동과 회전 변환을 얻도록 간소화된 Homography network을 사용하여 정합 후, 유사도를 기반으로 동일 활자로 인쇄한 글자들로 세분화한다. 마지막으로 동일 활자 영상을 통합하여 3차원 활자 모형을 복원한다. 실험을 통해 제안하는 각 과정이 성공적으로 수행되는 것을 확인했다.",다국어 초록 정보 없음
딥러닝 기반 수어 교육 온라인 플랫폼 구현,2022,"['딥러닝', '동작 인식', '교육', '수어', '청각 장애인', 'Deep Learning', 'Motion Recognition', 'Education', 'Sign Language', 'People with hearing impairment']",국문 초록 정보 없음,"Sign language is the main communication method for people with hearing impairments. However, the educational system and learning content for sign language acquisition have been characterized by a lack of accessibility and low quality in Korea. In 2022, 15 educational platforms regarding sign language acquisition exist. The formats mainly consist of watching videos and following pre-recorded hand movements, but real-time feedback is not provided about learned content. Thus, this study proposes a platform to teach sign language that provides real-time feedback on the proper hand movements of sign language. Based on CNN and LSTM, this model of distinguishing sign language movements uses a data-tracking system that tracks learners arms, hands, and fingers using OpenPose and MediaPipe. Through deep learning, the platform can help learners identify accurate hand movements and learn sign language interactively."
Towards Delay Aware Data Recovery using Deep Learning in Embedded IoT Application,2022,"['Data recovery', 'embedded devices', 'latency aware', 'LSTM']",국문 초록 정보 없음,"Data recovery technique in internet of things (IoT) network able to improve the devices longevity by reducing data retransmission. Most of existing research mainly focused on improving the prediction accuracy based on simulation work. Therefore, this study evaluate the data recovery in real world environment using deep learning (DL) and embedded devices by considering the processing time delay. The main goals is to ensure the low latency by applying data recovery in IoT network with low computational resource. A low complexity of deep neural network (DNN), convolutional neural network (CNN), and long short-term memory (LSTM) network were compared. Based on experimental results, the DNN network model is able to maintain low processing delay with average of 5.18 ms and 98.85% accuracy to recover single missing data."
Crack Detection Based on Generative Adversarial Networks and Deep Learning,2022,"['Structural health monitoring', 'Generative adversarial network', 'Generated images', 'Crack classification', 'Crack segmentation']",국문 초록 정보 없음,"This paper proposes a novel crack detection method using the three-stages detection model. Deep learning technology has been a focus of attention in the field of crack detection; however, it needs big data to train the corresponding network model. More training samples and the combination of multiple deep learning algorithms help to improve the detection performance. Therefore, this paper employed a generative adversarial network (GAN) model to generate abundant virtual crack images with similar features to real images, these virtual images are used to train the CNN classifier and DeepLab_v3+ respectively, and then the real images are used to evaluate the performance of the three-stages detection method. The results show that the proposed three-stages detection method has excellent detection effect on the crack detection is better than that of the control experiment (the NI_MIoU, NI_Accuracy, NI_F-score and NI_MCC are increased by 22.1% − 55.6%, 5.2% − 9.8%, 37.4% − 40.0% and 6.2% − 11.1%, respectively)). These results demonstrate that the three-stages detection model has made a beneficial contribution to the crack detection."
딥러닝을 이용한 안과 질환 자동화 진단시스템,2022,"['Automated Diagnostics', 'Convolution neural network', 'Deep learning', 'Eye disease', 'Image classification']",국문 초록 정보 없음,"Because the face of population ageing is much faster, early diagnosis of the eye diseases is important. As for the diagnosis, a fundus photography is popular. However, it is very difficult to make exact diagnosis due to blurred images, diagnosis time and human errors, which results in misdiagnosis and blindness in worst case scenario. To solve the problems, machine learning based diagnosis systems were suggested. However, the machine learning based systems inevitably contained expert parameters, like C for margins and gamma for boundary conditions as in support vector machines. Recently, as deep learning methods have been popular, the convolutional neural network (CNN) based image classifications are being used for eye disease diagnosis. However, the previous researches did not use balanced datasets and showed only accuracies for performance verifications. This paper proposes deep learning based eye disease diagnosis systems and balanced datasets are used for better performance. In addition, F1 score and receiver operation characteristic (ROC) curve with area under ROC curve (AUC) including accuracies are measured for exact performance verification. As for classes, normal, diabetic retinopathy, macular degeneration, cataracts, glaucoma, and pathological myopia, i.e., six classes are defined. Moreover, as a dataset, total 4965 data images are used. From the experimental result, we achieved 0.901 as an average F1 score."
랜드마크 기반 앙상블 네트워크를 이용한 얼굴 표정 분류,2022,"['얼굴 표정 분류', '앙상블 네트워크', '랜드마크', '얼굴 부분 특징', '딥러닝', 'Classification of facial expressions', 'Ensemble network', 'Landmark', 'Face feature', 'Deep learning']",국문 초록 정보 없음,"Research on facial expression classification has been steadily studied in relation to facial components and characteristics extraction. In this study, an algorithm for classifying facial expressions using a landmark-based ensemble network is also proposed to effectively classify facial expressions using these changes. First, only the face part is extracted from the entire face image through the preprocessing process, and then feature information is constructed using only the face image. And new landmark-based feature information is extracted using landmark information from the face image. After learning face-wide image feature information and landmark-based feature information on each CNN network, facial expressions are classified through ensemble learning. As a result of the experiment, it can be seen that the proposed algorithm shows 1.14% better classification performance than the technology that classified facial expressions using only existing facial images and 0.57% better classification performance than the technology that classified facial expressions using only landmark feature information."
멀티 채널 충전 프로파일과 방전 용량을 사용한 딥러닝 기반 리튬 이온 배터리 건강 상태 추정,2022,"['Artificial Neural Network', 'BMS(Battery Management System)', 'Deep Learning', 'Lithium-ion Battery', 'SOH(State-of-Health)']","리튬 이온 배터리팩의 안전하고 효율적인 사용을 위해서는 배터리의 상태를 모니터링하는 것이 중요하다. 다양한 배터리의 상태지표 중에서도 배터리의 성능과 수명을 대표하는 SOH(State-of-Health)를 추정할 필요가 있다.본 논문에서는 다양한 구조의 인공신경망을 사용하여 SOH를 추정하였다. SOH 추정을 위한 입력으로 배터리의충전중 전압, 전류, 온도의 측정치를 사용하였다. 또한 방전 중에 전류적산법을 통해 추정된 배터리의 용량을 충전중에 기록된 측정치와 함께 입력으로 사용하여 성능을 개선한 모델을 제안한다. 순방향 신경망, 합성곱 신경망, 장단기 메모리 모델의 SOH 추정 성능을 평가하였고, 방전 용량을 모델의 입력으로 사용하면 모델의 성능이 크게향상됨을 확인하였다.","For safe and efficient use of lithium ion battery pack, it is important to monitor the states of battery.Among various states of battery, it is required to estimate SOH (State-of-Health), which represents the performance and life of battery. In this paper, we estimate SOH using various structures of artificial neural network (ANN). We use the measured voltage, current, and temperature of battery cell during charging process as a feature to estimate SOH. We also use the discharged capacity, measured by the coulomb counting method, of battery cell as the feature. We evaluate the performance of various structures of ANN such as feedforward neural network (FNN), convolutional neural network (CNN) and long short-term memory (LSTM) and confirm that the use of discharged capacity significantly improves the SOH estimation performance."
인공지능과 자율운용 기술을 이용한 긴급형 이동통신 기지국 자율설정 및 최적화,2022,"['Mobile Communication Network', 'SON(Self-Organization Network)', 'AI(Artificial Intelligence)', 'Tactical Network', 'Public Safety Network', '이동통신 네트워크', '자율운용', '인공지능', '전술 네트워크', '재난망']","긴급 상황에 대비하는 재난망이나 전술 이동통신 네트워크는 현장에 적응하여 신속하고 정확하게 구축하는 것이 중요하다. 전통적인 무선통신 시스템을 구성하기 위해서는 셀 플래닝 장비를 통해 기지국의 파라미터를 설정한다. 하지만 셀 플래닝을 위해서는 환경에 대한 정보나 데이터가 사전에 구축되어 있어야 하며, 셀 플래닝에 반영되지 않아 현장에 맞지 않는 파라미터가 사용되면 네트워크 구축 후 문제의 해결 및 성능 향상을 위해서 별도의 최적화가 진행되어야 한다. 이 논문에서는 이동통신 기지국에서의 인공지능(AI)과 자율운용(SON) 기술을 사용한 신속한 이동통신망 구축 및 최적화 방법을 제시한다. 기지국의 위치와 단말의 측정 정보를 이용한 DNN 모델을 통해 경로 손실 예측을 수행하여 지형을 구분하는 CNN 모델을 기지국 파라미터를 자동으로 설정한 후, 운용 중에 수집되는 데이터로 경로 손실 모델을 학습시키며 이를 이용해 Coverage/Capacity 최적화를 지속적으로 수행할 수 있도록 한다.",다국어 초록 정보 없음
A Model for Machine Fault Diagnosis based on Mutual Exclusion Theory and Out-of-Distribution Detection,2022,"['out-of-distribution', 'convolutional neural network', 'mutually exclusive events', 'fusion networks', 'autoencoder']",국문 초록 정보 없음,"The primary task of machine fault diagnosis is to judge whether the current state is normal or damaged, so it is a typical binary classification problem with mutual exclusion. Mutually exclusive events and out-of-domain detection have one thing in common: there are two types of data and no intersection. We proposed a fusion model method to improve the accuracy of machine fault diagnosis, which is based on the mutual exclusivity of events and the commonality of out-of-distribution detection, and finally generalized to all binary classification problems. It is reported that the performance of a convolutional neural network (CNN) will decrease as the recognition type increases, so the variational auto-encoder (VAE) is used as the primary model. Two VAE models are used to train the machine's normal and fault sound data. Two reconstruction probabilities will be obtained during the test. The smaller value is transformed into a correction value of another value according to the mutually exclusive characteristics. Finally, the classification result is obtained according to the fusion algorithm. Filtering normal data features from fault data features is proposed, which shields the interference and makes the fault features more prominent. We confirm that good performance improvements have been achieved in the machine fault detection data set, and the results are better than most mainstream models."
Application of the machine learning technique for the development of a condensation heat transfer model for a passive containment cooling system,2022,"['PCCS', 'Condensation heat transfer', 'Non-condensable gas', 'Machine learning']",국문 초록 정보 없음,"A condensation heat transfer model is essential to accurately predict the performance of the passivecontainment cooling system (PCCS) during an accident in an advanced light water reactor. However,most of existing models tend to predict condensation heat transfer very well for a specific range ofthermal-hydraulic conditions. In this study, a new correlation for condensation heat transfer coefficient(HTC) is presented using machine learning technique. To secure sufficient training data, a large numberof pseudo data were produced by using ten existing condensation models. Then, a neural network modelwas developed, consisting of a fully connected layer and a convolutional neural network (CNN) algorithm, DenseNet. Based on the hold-out cross-validation, the neural network was trained and validatedagainst the pseudo data. Thereafter, it was evaluated using the experimental data, which were not usedfor training. The machine learning model predicted better results than the existing models. It was alsoconfirmed through a parametric study that the machine learning model presents continuous andphysical HTCs for various thermal-hydraulic conditions. By reflecting the effects of individual variablesobtained from the parametric analysis, a new correlation was proposed. It yielded better results foralmost all experimental conditions than the ten existing models."
EEG기반의 AI채용시스템을 활용한 면접자들의 진실성 탐구,2022,"['AI채용시스템', '인공지능', 'EEG', '채용', '딥러닝', 'AI Recruitment System', 'Artificial Intelligence', 'EEG', 'Recruitment', 'Deep Learning']",국문 초록 정보 없음,"An increasing number of companies are using AI recruitment system for the purpose of improved work efficiency. This study was designed to conduct an EEG-based biological experiment to explore the sincerity of applicants who were interviewed using an AI recruitment system. By asking interviewees with 10 questions of situation-solving ability assuming a random trouble-solving situation, EEG signals were collected from the interviewees during the interview and their sincerity was explored. As a result of the experiment, the accuracy of the CNN model showed slightly better results for truthfulnrss assessment"
Application of a deep learning algorithm to Compton imaging of radioactive point sources with a single planar CdTe pixelated detector,2022,"['CdTe', 'Compton imaging', 'Deep learning', 'Machine learning', 'Convolutional neural networks']",국문 초록 정보 없음,"Compton imaging is the main method for locating radioactive hot spots emitting high-energy gammaray photons. In particular, this imaging method is crucial when the photon energy is too high for codedmask aperture imaging methods to be effective or when a large field of view is required. Reconstructionof the photon source requires advanced Compton event processing algorithms to determine the exactposition of the source. In this study, we introduce a novel method based on a Deep Learning algorithmwith a Convolutional Neural Network (CNN) to perform Compton imaging. This algorithm is trained onsimulated data and tested on real data acquired with Caliste, a single planar CdTe pixelated detector. Weshow that performance in terms of source location accuracy is equivalent to state-of-the-art algorithms,while computa"
Scaling Up Face Masks Classification Using a Deep Neural Network and Classical Method Inspired Hybrid Technique,2022,"['CNNs', 'Face masks', 'Machine learning', 'Multi-layer perceptron', 'ResNet-101']",국문 초록 정보 없음,"Classification of persons wearing and not wearing face masks in images has emerged as a new computer vision problem during the COVID-19 pandemic. In order to address this problem and scale up the research in this domain, in this paper a hybrid technique by employing ResNet-101 and multi-layer perceptron (MLP) classifier has been proposed. The proposed technique is tested and validated on a self-created face masks classification dataset and a standard dataset. On self-created dataset, the proposed technique achieved a classification accuracy of 97.3%. To embrace the proposed technique, six other state-of-the-art CNN feature extractors with six other classical machine learning classifiers have been tested and compared with the proposed technique. The proposed technique achieved better classification accuracy and 1-6% higher precision, recall, and F1 score as compared to other tested deep feature extractors and machine learning classifiers."
AI기반 영상 분할 알고리즘을 이용한 오리축사 바닥 깔짚 분할에 관한 연구,2022,"['Artificial intelligence', 'Deep learning', 'Object detection', 'Duck detection', 'UNet']","오리 사육 시 바닥 깔짚의 적정 수분함량을 유지하는 것은 오리 사육 환경조성에 중요한 요소 중 하나이다. 오리를 사육하기 위해 오리 축사의 환경을 청결하게 유지할 필요가 있고 이를 위해 깔짚의 수분함량을 실시간으로 파악하여 수분이 부족할 경우 수분을 보충해 주어야 한다. 현재 사용되는 휴대용 수분계는 오차가 발생하기 쉽고 사람이 직접 사용해야 하기 때문에 실시간 관리가 어렵다. 본 연구는 깔짚 수분 량의 실시간 관리와 정확한 측정을 위해, 입력 영상에서 깔짚 영역을 자동으로 분할하는 방법을 제안한다. 깔짚 영역 자동 분할을 위해 딥러닝 기반 영상 분할네트워크를 사용하였고 합성곱 신경망(CNN, Convolutional Neural Network)기반의 UNet을 적용하였다. UNet을 이용하여 오리 축사 영상으로부터 바닥 깔짚 영역을 자동으로 찾고 영상의 화소 단위로 영역을 추출하여 깔짚 영역을 분할한다. 본 연구를 통하여 오리 축사 바닥 깔짚 영역을 자동으로 찾고 깔짚 영역의 수분함량을 예측하는데 적용할 수 있을 것으로 기대된다.",다국어 초록 정보 없음
출석시스템 자동화를 위한 얼굴인식,2022,"['face recognition', 'attendance system automation', 'machine learning']",국문 초록 정보 없음,"The current attendance system is time-consuming and has the possibility of proxy attendance and illegal listening. This study was conducted to increase the convenience and fairness of attendance confirmation by learning students' faces using deep learning technology. Twenty photos of seven students were collected, and about 4,000 photos were made through image improvement and used as learning materials and test materials. The collected image data was preprocessed using Open CV and then repeated 25 times (epoch) consisting of a total of 8 layers, including 3 convolution layers, 3 max pooling layers, and 2 fully connected layers in the CNN structure. By learning the data of 7 people, it was confirmed whether it was possible to automate the attendance system using deep learning. By expanding this study, it is expected that a new attendance system will be established and convenience and fairness will be improved."
Markov Transition Field를 적용한 RSSI 신호 기반 실내 위치 인식 연구,2022,[],"Wi-Fi 및 BLE 기반 핑거프린트 방식의 경우, 모바일 기기에서도 별도의 센서 없이 측위가 가능하다는 장점으로 인해 실내 측위 기술로 활용되고 있다. 그러나 실내 환경에서의 RSSI는 주변 장애물과 다중 경로 효과에 의해 신호가 왜곡되고 세기가 약해지는 단점이 존재한다. 본 논문은 불안정한 RSSI 기반 실내 위치 인식 정확도 향상을 위해 non-GPS 실내 환경에서 BLE RSSI 기반 핑거 프린트 방식 실내 측위 모델을 제안한다. 또한 검증 방안으로써 2m×3m 실내 공간의 8개의 AP에서 얻은 RSSI 신호를 시계열 데이터 이미지화 알고리즘인 Markov Transition Field로 변환하여 데이터셋을 구축했다. 제안된 모델은 변환된 데이터를 통해 범위 내의 위치를 분류하도록 학습된다. 실험 결과를 토대로, 테스트 정확도 97.6%, 98.2%를 나타냈으며 이는 이미지화 알고리즘의 CNN 적용이 우수한 성능을 낼 수 있음을 보여준다.",다국어 초록 정보 없음
Use of Machine Learning in Stroke Rehabilitation: A Narrative Review,2022,"['Machine Learning', 'Artificial Intelligence', 'Stroke', 'Rehabilitation', 'Deep Learning']",국문 초록 정보 없음,"A narrative review was conducted of machine learning applications and research in the field of stroke rehabilitation. The machine learning models commonly used in medical research include random forest, logistic regression, and deep neural networks. Convolutional neural networks (CNNs), a type of deep neural network, are typically used for image analysis.Machine learning has been used in stroke rehabilitation to predict recover y of motor function using a large amount of clinical data as input. Recent studies on predicting motor function have trained CNN models using magnetic resonance images as input data together with clinical data to increase the accuracy of motor function prediction models. Additionally, a model interpreting videofluoroscopic swallowing studies was developed and investigated. In the future, we anticipate that machine learning will be actively used to treat stroke patients, such as predicting the occurrence of depression and the recover y of language, cognitive, and sensor y function, as well as prescribing appropriate rehabilitation treatments"
머신러닝 분류기를 사용한 만성콩팥병 자동 진단 및 중증도 예측 연구,2022,"['chronic kidney disease', 'machine learning', 'automatic classification']",국문 초록 정보 없음,"This paper proposes an optimal methodology for automatically diagnosing and predicting the severity of the chronic kidney disease (CKD) using patients’ utterances. In patients with CKD, the voice changes due to the weakening of respiratory and laryngeal muscles and vocal fold edema. Previous studies have phonetically analyzed the voices of patients with CKD, but no studies have been conducted to classify the voices of patients. In this paper, the utterances of patients with CKD were classified using the variety of utterance types (sustained vowel, sentence, general sentence), the feature sets [handcrafted features, extended Geneva Minimalistic Acoustic Parameter Set (eGeMAPS), CNN extracted features], and the classifiers (SVM, XGBoost). Total of 1,523 utterances which are 3 hours, 26 minutes, and 25 seconds long, are used. F1-score of 0.93 for automatically diagnosing a disease, 0.89 for a 3-classes problem, and 0.84 for a 5-classes problem were achieved. The highest performance was obtained when the combination of general sentence utterances, handcrafted feature set, and XGBoost was used. The result suggests that a general sentence utterance that can reflect all speakers’ speech characteristics and an appropriate feature set extracted from there are adequate for the automatic classification of CKD patients’ utterances."
디지털 농업을 위한 피드백 기반 스마트 관개 시스템,2022,"['Digital Argriculture', 'Irrigation System', 'Machine Learning', 'Soil Texture Classification', 'Smart Farm', '수확로봇', '이송로봇', '수확속도', '다수로봇운용', '그린하우스 로봇']","디지털 농업은 농업 현장에서 발생하는 현상을 디지털화하여 농업 활동의 편의성과 생산성을 향상시킬 수 있는기술이다. 관개 시스템은 농업에서 가장 중요한 요소이다. 관개 시스템에 대한 자동화는 다양하게 진행되고 있다.하지만, 대부분의 연구에서 초기 설정에 따라 획일적인 주기로 관개를 실행하기 때문에 관리자의 개입이 필요한단점을 가진다. 본 연구는 기존 연구에서 발생했던 단점을 보완하기 위하여 실시간 토양 변화를 감지하여 머신러닝을 기반으로 토성을 분류할 수 있는 능동적인 스마트 관개 시스템을 제안한다. 능동적인 스마트 관개 시스템을구축하기 위해서 토성 분석 기술과 소프트웨어 업데이트 기술이 필요하다. 토성 분류를 위해서 토양 변화에 대한시계열 데이터를 기반으로 합성곱신경망, 순환신경망, 장단기 메모리와 같은 머신러닝 모델을 설계하였다. 또한, 토성 분류 결과를 원격지에 설치된 관개 제어기로 전송 및 수정할 수 있는 아키텍처를 제안한다. 머신러닝 모델을평가하기 위해서 100회 반복하여 수행된 결과를 혼동행렬을 적용하여 신뢰성을 평가하였으며, 약 90%의 모델 신뢰성을 가지는 것을 확인하였다. 변경된 토성 분류 결과를 데이터베이스에서 관개 제어기로 전송하는 원격 시스템의 안정성을 검증하였다.","Digital agriculture is able to improve the convenience and productivity by digitalizing occurred event in agricultural process. The irrigation system is the most important element in agricultural process. There are various research on automation of irrigation system. Most of research have the disadvantage that administrator need to intervene to irrigate. In this work, we propose a smart irrigation system that can monitor agricultural environment and can decide irrigation period and irrigation time. Also, we design machine learning models base on time series data such as CNN, Simple RNN, LSTM to classified soil texture. Performance of the classification algorithm was evaluated using the confusion matrix, the classification performance was evaluated about 90%. In order to implement tiny machine learning on an embedded system in future work., we will consider Simple RNN that has the fewest parameters of them."
회전기계를 위한 건전성 예측 및 관리 시스템 개발과 로터리 테이블에 적용,2022,"['스마트팩토리', '건전성 예측 및 관리', '딥러닝', '합성곱 신경망', 'Smart factory', 'Prognostics and health management', 'Deep learning', 'Convolutional neural network']",국문 초록 정보 없음,"Recently, interest in Prognostics and Health management (PHM) has been increasing as an advanced technology of maintenance. PHM technology is a technology that allows equipment to check its condition and predict failures in advance. To realize PHM technology, it is important to implement artificial intelligence technology that diagnoses failures based on data. Vibration data is often used to diagnose the state of the rotating machine. Additionally, there have been many efforts to convert vibration data into 2D images to apply a convolutional neural network (CNN), which is emerging as a powerful algorithm in the image processing field, to vibration data. In this study, a series of PHM processes for acquiring data from a rotary machine and using it to check the condition of the machine were applied to the rotary table. Additionally, a study was conducted to introduce and compare two methodologies for converting vibration data into 2D images. Finally, a GUI program to implement the PHM process was developed."
합성곱 신경망을 이용한 선박의 잉여저항계수 추정,2022,[],국문 초록 정보 없음,"In the design stage of hull forms, a fast prediction method of resistance performance is needed. In these days, large test matrix of candidate hull forms is tested using Computational Fluid Dynamics (CFD) in order to choose the best hull form before the model test. This process requires large computing times and resources. If there is a fast and reliable prediction method for hull form performance, it can be used as the first filter before applying CFD. In this paper, we suggest the offset-based performance prediction method. The hull form geometry information is applied in the form of 2D offset (non-dimensionalized by breadth and draft), and it is studied using Convolutional Neural Network (CNN) and adapted to the model test results (Residual Resistance Coefficient; C<sub>R</sub>). Some additional variables which are not included in the offset data such as main dimensions are merged with the offset data in the process. The present model shows better performance comparing with the simple regression models."
방사선 투과 이미지에서의 용접 결함 검출을 위한 딥러닝 알고리즘 비교 연구,2022,"['Radiographic Testing', 'Welding Defect', 'Deep Learning']",국문 초록 정보 없음,"An automated system is needed for the effectiveness of non-destructive testing. In order to utilize the radiographic testing data accumulated in the film, the types of welding defects were classified into 9 and the shape of defects were analyzed. Data was preprocessed to use deep learning with high performance in image classification, and a combination of one-stage/two-stage method and convolutional neural networks/Transformer backbone was compared to confirm a model suitable for welding defect detection. The combination of two-stage, which can learn step-by-step, and deep-layered CNN backbone, showed the best performance with mean average precision 0.868."
Study on the University Students’ Behaviors of Linguistic Information Process and Learning Strategies through Note-taking Task,2022,"['note taking activity', 'information process', 'listening skills', 'scaffolding support', 'teacher’s guidance']",국문 초록 정보 없음,"Note-taking tasks can be considered a process to achieve communication by helping learners organize linguistic information they strive to convey through cognitive activities. To successfully communicate, learners must develop various linguistic and cognitive skills, such as advanced listening proficiency and the reconstruction of intended stories. This study aims to discover the major types of errors affecting university-level learners’ note-taking activities and a teacher’s scaffolding guidance in order to foster note-taking skills and learning strategies. Seventy-nine university students enrolled in an audio visual English class took part in this study. They were required to routinely carry out note-taking activities by watching both CNN news reports and academic lectures dealing with social issues. This study found that the learners routinely missed a substantial number of content words despite repetitive note-taking tasks. In addition, important phrases were omitted due to variations in pronunciation, unfamiliar proper nouns, and complex numbers. It was also revealed that students appeared to struggle with several abbreviations and symbols when reconstructing the meaning of the information. In order to tackle these problems, various teaching strategies were introduced and implemented to increase note-taking effectiveness as well as maximize learners’ confidence and help them more accurately grasp the content. Based on these results, this study recommends providing structured scaffolding for learners to perform effective and efficient note-taking tasks. This will have a positive influence on learning strategies. It will also encourage students to actively participate in tasks and produce well-organized information on given subjects, which require linguistic information processing."
Classification of dog skin diseases using deep learning with images captured from multispectral imaging device,2022,"['Deep learning', 'Dog skin disease', 'Multispectral image', 'Dermatosis']",국문 초록 정보 없음,"Background Dog-associated infections are related to more than 70 human diseases. Given that the health diagnosis of a dog requires expertise of the veterinarian, an artificial intelligence model for detecting dog diseases could significantly reduce time and cost required for a diagnosis and efficiently maintain animal health.Objective We collected normal and multispectral images to develop classification model of each three dog skin diseases (bacterial dermatosis, fungal infection, and hypersensitivity allergic dermatosis). The single models (normal image- and multispectral image-based) and consensus models were developed used to four CNN model architecture (InceptionNet, ResNet, DenseNet, MobileNet) and select well-performed model.Results For single models, such as normal image- or multispectral image-based model, the best accuracies and Matthew’s correlation coefficients (MCCs) for validation data set were 0.80 and 0.64 for bacterial dermatosis, 0.70 and 0.36 for fungal infection, and 0.82 and 0.47 for hypersensitivity allergic dermatosis. For the consensus models, the best accuracies and MCCs for the validation set were 0.89 and 0.76 for the bacterial dermatosis data set, 0.87 and 0.63 for the fungal infection data set, and 0.87 and 0.63 for the hypersensitivity allergic dermatosis data set, respectively, which supported that the consensus models of each disease were more balanced and well-performed.Conclusions We developed consensus models for each skin disease for dogs by combining each best model developed with the normal and multispectral images, respectively. Since the normal images could be used to determine areas suspected of lesion of skin disease and additionally the multispectral images could help confirming skin redness of the area, the models achieved higher prediction accuracy with balanced performance between sensitivity and specificity."
자율주행 트랙터의 안전 농작업을 위한 인식 시스템 개발 기초연구,2022,"['자율주행 농기계', '인식 시스템', '딥러닝']","GPS 센서에 기반한 자율주행 농업용 트랙터는 동적인 환경에 대한 인식이 어렵기 때문에 작업 환경 주시를 위하여 작업자가 탑승하여야 한다. 트랙터의 인식 시스템 개발은 농업기계 자율주행 기술 단계의 발전과 농업기계 무인화를 위한 필수적인 단계이며, 자율작업 시 사람 인식 및 충돌 방지 기술 개발을 통한 인명 보호 기술이 필요하다. 본 연구는 목적은 자율주행 트랙터의 안전한 농작업을 위한 인식 시스템을 개발하여 적용하고, 이를 현장에서 평가하기 위함이다. 인식 시스템은 4개의 스테레오 카메라 Stereolabs ZED2i와 8개의 초음파 센서 DFRobot URM08, 임베디드 PC Nvidia Jetson Xavier NX로 구성되었으며, 트랙터의 360도 전방향으로 15m의 인식 범위를 가진다. 인식 알고리즘에는 CNN 기반 딥러닝 기법을 적용하였으며, 스테레오 카메라를 통한 거리측정 및 센서 좌표계 변환을 통해 트랙터와 장애물의 상대거리를 측정하였다. 현장 실험은 실제 농지 내부에서 주광 하에서 진행하였고, 동적인 상황에서의 인식 성능을 평가하기 위해 빠르게 움직이는 장애물, 가려진 장애물 등의 시나리오를 설정하여 인식 성능을 평가하였다. 스테레오 카메라는 트랙터의 감지 영역 내에서 99% 이상의 사람 검출 성능을 보였으며 초음파센서는 저조도 환경에서 99% 이상의 장애물 인식 성능을 보였다.",다국어 초록 정보 없음
A Deep Learning Method for Brain Tumor Classification Based on Image Gradient,2022,"['Brain Tumor Classification', 'Image Gradient', 'Deep Learning', 'Convolutional Neural Network']",국문 초록 정보 없음,"Tumors of the brain are the deadliest, with a life expectancy of only a few years for those with the most advanced forms. Diagnosing a brain tumor is critical to developing a treatment plan to help patients with the disease live longer. A misdiagnosis of brain tumors will lead to incorrect medical treatment, decreasing a patient's chance of survival. Radiologists classify brain tumors via biopsy, which takes a long time. As a result, the doctor will need an automatic classification system to identify brain tumors. Image classification is one application of the deep learning method in computer vision. One of the deep learning's most powerful algorithms is the convolutional neural network (CNN). This paper will introduce a novel deep learning structure and image gradient to classify brain tumors. Meningioma, glioma, and pituitary tumors are the three most popular forms of brain cancer represented in the Figshare dataset, which contains 3,064 T1-weighted brain images from 233 patients. According to the numerical results, our method is more accurate than other approaches."
Automatic Classification of Respiratory Sound Considering Hierarchical Structure,2022,"['Respiratory Sounds', 'Branch Convolutional Neural Network', 'Computer Aided Diagnosis', 'Linear Predictive Coefficient', 'Harmonious / Percussive Sound Separation']",국문 초록 정보 없음,"Respiratory diseases are one of the leading causes of death worldwide. Approximately 8 million people die annually from respiratory diseases. Diagnosis is made primarily by auscultation using a stethoscope. The lack of quantitative criteria makes diagnosis difficult in the field where physicians are in short supply. To solve this problem, a computer aided diagnosis (CAD) system that quantitatively analyzes and classifies respiratory sounds and outputs them as a second opinion is needed. In this paper, HPSS (Harmonious / Percussive Sound Separation) is used to separate abnormal respiratory sound features. Images are generated from the spectral envelopes obtained by linear prediction coefficients (LPC) for each of the three types of respiratory sound data before separation. The CNN (convolutional neural networks) framework based on hierarchical structure of the correct labels is introduced. The proposed method was applied to the dataset used in the International Conference on Biomedical and Health Informatics (ICBHI) 2017 Challenge. As a result, we obtained a sensitivity of 63.5%, specificity of 85.1%, average score of 74.3%, harmonic score of 72.7%, area under the curve of 87.8%, and false negative rate of 24.5%, respectively."
컴퓨터 비전과 딥러닝을 이용한 목재 결함의 검출 및 정량화,2022,[],"목재 표면 검사를 위해 컴퓨터 비전과 딥러닝을 이용한 자동화 결함 검출 모델을 수립하였다. 컨베이어, 라인 스캔 카메라, 적외선 센서 트리거로 구성된 연속 이미지 획득 시스템을 우선 구축하여 목재 이미지 데이터를 획득하였다. 이미지 획득 시스템은 크기에 상관없이 연속 투입되는 모든 판재의 표면을 스캔할 수 있다. 총 304장의 잣나무 표면 이미지로 데이터베이스가 구축되었다. 『KS F 2151 침엽수 구조 용재의 육안 등급 구분 방법』에 따라 목재 결함을 옹이, 갈라짐, 수피로 구분하였으며, 옹이는 산옹이, 죽은 옹이, 썩은 옹이, 긴 옹이 등 4종류로 세분화하였다. VGG annotator를 이용하여 모든 이미지 데이터에 결함의 위치, 형상, 종류에 관한 정보를 목록화하였다. 검출 모델은 ResNet-101을 backbone 네트워크로 하는 Mask R-CNN을 기반으로 설계되었으며, 모델은 IOU(intersection over union) 50% 이상에 대한 mAP(mean average precision)로 평가되었다. 또한 KS F 2151에서 규정한 방식으로 각 결함의 기준 치수가 산출되도록 모델을 설계하였다. 테스트 세트에 대한 모델의 mAP는 57.0%로 산출되었는데, 이는 4종의 옹이만 학습한 모델의 mAP 80.4%보다 낮다. 성능 감소의 원인은 갈라짐에 대한 모델의 검출 성능이 낮았던 것에 기인한다. 갈라짐에 대한 검출 오류는 주석을 달지 않은 미세한 갈라짐을 모델이 검출한 경우, 그리고 길게 분포된 하나의 갈라짐을 모델이 다중의 갈라짐으로 검출한 경우의 두 가지 유형으로 분석되었다. 이러한 오류는 주석 수정 및 데이터 세트 증량을 통해 개선할 수 있을 것으로 판단된다. 개발된 모델은 옹이만을 다루던 기존 자동화 탐지 기법과는 달리 다양한 결함들을 검출할 뿐만 아니라 결함의 정량화 기능을 갖추어 목재 표면 검사에 실질적 도움이 될 것으로 기대된다.",다국어 초록 정보 없음
심층신경망을 이용한 딸기 생육상태 추정,2022,"['deep neural network', 'protected horticulture', 'strawberry', 'growth status']",국문 초록 정보 없음,"For high-quality, high-yield cultivation, especially work in protected horticulture such as the control of an appropriate environment and physical actions are essential. Recently, automating cultivation technique for agricultural work using long cultivation experience and artificial intelligence has been proposed. And automating work should be based on crop statuses such as age and condition. In particular, since fruits and vegetables have both vegetative and reproductive growth stages, it is important to understand more precisely the status of crops. The purpose of this study is to estimate the growth status of strawberry plant after transplanting from RGB images using a deep neural network. The images were acquired using a GoPro camera (GoPro HERO 10, GoPro Inc., USA) of the strawberry plant ‘Seolhyang’, which was transplanted in a venro-type glass greenhouse. Videos were filmed for 8 weeks at the interval of 1 week from July 6th. The images were augmented using ImageDataGenerator in keras module and inputted to a deep neural network model of various structures. The models used for training are MLP, CNN, and vision transformer. The model showed a performance of more than 95% accuracy. In the future, for the deep neural network structure that showed the highest performance, We are going to proceed ablation test for each RGB channel and compare performance for the different numbers of layers. The application of the deep neural network in this study shows that it could be the basis for the design of work for each growth status in the construction of an automated system for high quality and high yield in strawberry cultivation."
Environment Recognition from Spherical Camera Images Based on Multi-Attention DeepLab,2022,"['Autonomous Wheelchair', 'Semantic Segmentation', 'Spherical Camera', 'Panoramic Image', 'DeepLab v3+', 'Convolutional Neural Network', 'MobileNet v2', 'scSE Block', 'Pairwise Self-Attention', 'Joint Pyramid Upsampling']",국문 초록 정보 없음,"Electric wheelchair is an easy-to-operate means of transportation that does not require physical strength. With the number of electric wheelchair users increasing in recent years, the increase in traffic accidents becomes a problem. Therefore, by developing an autonomous electric wheelchair, it is expected that the risk of accidents will be reduced and the convenience of the electric wheelchair will be improved. Environment recognition is indispensable for the development of autonomous electric wheelchairs. We propose a semantic segmentation method for recognizing 16 objects in traffic environment. This paper examines the improvement of problems such as the high price of autonomous electric wheelchairs due to the increase in the number of sensors used, which has been a concern in related research. Therefore, we use panoramic images acquired by a spherical camera as input data, and extern the Multi-Attention Deep Lab algorithms fitting for the recognition of distorted images. A new CNN model is constructed sing Deep Lab v3+, scSE Block, Pairwise Self-Attention, and Joint Pyramid Up-sampling. We conducted a recognition experiment using images taken on campus and verified its effectiveness. (Comparing to DeepLab v3+, IoU and Dice showed a 3.5% and 3.6% improvement in accuracy, respectively.)"
A Deep Learning Model for Predicting User Personality Using Social Media Profile Images,2022,"['Personality Traits', 'Classification', 'Deep Learning', 'Convolution Neural Networks', 'Five Factor Model']",국문 초록 정보 없음,"Social media is a form of communication based on the internet to share information through content and images. Their choice of profile images and type of image they post can be closely connected to their personality. The user posted images are designated as personality traits. The objective of this study is to predict five factor model personality dimensions from profile images by using deep learning and neural networks. Developed a deep learning framework-based neural network for personality prediction. The personality types of the Big Five Factor model can be quantified from user profile images. To measure the effectiveness, proposed two models using convolution Neural Networks to classify each personality of the user. Done performance analysis among two different models for efficiently predict personality traits from profile image. It was found that VGG-69 CNN models are best performing models for producing the classification accuracy of 91% to predict user personality traits."
STFT를 통한 합성곱 신경망 기반의 포터블 에어컨 고장 진단,2022,"['소음(Noise)', '진동(Vibration)', '고장 진단(Fault Diagnosis)', '합성곱 신경망(Convolution Neural Network)', '단시간 푸리에 변환(Short-Time Fourier Transform)']",국문 초록 정보 없음,"Various machines and home appliances experience aging and failure due to their continued use. Electronic problems such as circuit failures are easy to diagnose on the product itself, but mechanical defects and faults are difficult to diagnose. Since acoustic signals generated from a machine include inherent operating characteristics, the unwanted mechanical faults can be diagnosed by analyzing different patterns between normal and fault signals. In this study, the mechanical failure diagnosis of a commercial portable air conditioner has been implemented based on a deep learning-based image classification technique. Short-time Fourier transform (STFT) is used to effectively analyze the frequency characteristics that occur in the event of machine failures, and then the fault status of the air conditioner is examined by classifying the extracted spectrogram images through convolution neural network (CNN). The proposed method shows a precise fault diagnosis without additional devices and can be effectively applied for fault diagnostic algorithms of various home appliances."
작물 분류를 위한 딥러닝 기반 비지도 도메인 적응 모델 비교,2022,"['Crop classification', 'Deep learning', 'Unmanned aerial vehicle (UAV)', 'Unsupervised domain adaptation']",국문 초록 정보 없음,"The unsupervised domain adaptation can solve the impractical issue of repeatedly collecting high-quality training data every year for annual crop classification. This study evaluates the applicability of deep learning-based unsupervised domain adaptation models for crop classification. Three unsupervised domain adaptation models including a deep adaptation network (DAN), a deep reconstructionclassification network, and a domain adversarial neural network (DANN) are quantitatively compared via a crop classification experiment using unmanned aerial vehicle images in Hapcheon-gun and Changnyeong-gun, the major garlic and onion cultivation areas in Korea. As source baseline and target baseline models, convolutional neural networks (CNNs) are additionally applied to evaluate the classification performance of the unsupervised domain adaptation models. The three unsupervised domain adaptation models outperformed the source baseline CNN, but the different classification performances were observed depending on the degree of inconsistency between data distributions in source and target images. The classification accuracy of DAN was higher than that of the other two models when the inconsistency between source and target images was low, whereas DANN has the best classification performance when the inconsistency between source and target images was high. Therefore, the extent to which data distributions of the source and target images match should be considered to select the best unsupervised domain adaptation model to generate reliable classification results."
Meta-Learning Approaches for mmWave Path Loss Modeling in Smart Factories,2022,['Millimeter waveSmart factoryPath loss modelingMeta-learningDeep learning'],국문 초록 정보 없음,"With the growing interest in both public and private 5G services based on millimeter wave (mmWave) communication for indoor usage scenarios such as smart factories, site design specialists are seeking sophisticated methods and tools for simulating indoor radio coverage based on highly accurate path loss prediction models. Although machine learning approaches can be used in path loss modeling thanks to the highly accurate prediction capability, their performance can be limited by the size of available measurement data set used for training. In this paper, we propose new approaches to train path loss models in the few-shot learning scenarios of smart factories. The proposed approaches are based on meta-learning with slight modifications to perform fine-tuning over an entire train data set rather than a meta-test data set. It is shown that the indoor path loss models based on convolutional neural networks (CNNs) trained by meta-learning based on three different meta-train task assignment schemes outperform both a conventional CNN model and an empirical model."
합성곱 신경망 기반 화재 분류 모델의 예측성능에 관한 기초 연구,2022,"['Fire image classification', 'Computer vision', 'Convolutional Neural Network', 'Prediction accuracy']","최근 사회의 밀집화, 심층화, 고층화 등의 현상은 복합적이고 대규모적인 화재안전사고를 유발하고 있다. 이러한 화재안전사고의 피해를 최소화하기 위해서 조기 발견 및 진압을 위한 화재감지 기술에 관한 다양한 연구들이 수행되고 있다. 일반적으로 화재 시 발생하는 화염, 연기 및 열 등을 감지하는 기술을 활용한 단일 혹은 복합 감지 센서에 관한 연구가 많이 이루어지고 있으며 기술적 비용적 한계를 해결하기 위해 최근 컴퓨터 비전 기술을 활용한 화재감지 연구가 활발하게 진행되고 있다. 화재 이미지의 공간정보를 반영한 이미지 특징 추출을 통해 우수한 화재 예측성능을 갖는 합성곱 신경망 기반의 화재감지기술은 신뢰성을 확보하고 실 예측성능을 향상이 요구되고 있다. 본 연구에서는 합성곱 신경망 기반의 화재 이미지 분류 모델의 신뢰성 확보 및 성능향상을 목적으로 화재와 유사한 이미지 특성을 갖는 이미지 군들에 대한 추가적 학습이 분류 모델의 예측성능에 미치는 영향을 분석하였다. 이를 위해 화재를 나타내는 화염 및 연기 이미지뿐만 아니라 연무 및 빛 이미지 군을 추가하여 클래스 수 변경에 따른 분류 모델의 성능 비교를 수행하였으며 CNN 모델, 손실함수, 최적화법 등 분류 모델 알고리즘은 동일하게 적용하였다. 정밀도, 재현율, 정확도 등의 지표들을 이용하여 정량적으로 예측성능을 비교하였으며 혼동행렬을 이용하여 분류 모델의 예측 경향 및 상세 특징을 분석하였다. 이를 통해서 학습 클래스의 증가에 따라서 화재와 유사한 이미지에 대한 분류 예측성능이 향상됨을 확인하였다. 본 기초 연구결과를 기반으로 다른 신뢰성 및 성능향상 기술과의 연계를 통해 실 화재감지 적용 가능 분류 모델 개발을 위한 성능검증 및 개선을 진행할 계획이다.",다국어 초록 정보 없음
심층신경망을 이용한 딸기 생육상태 추정,2022,"['deep neural network', 'protected horticulture', 'strawberry', 'growth status']",국문 초록 정보 없음,"For high-quality, high-yield cultivation, especially work in protected horticulture such as the control of an appropriate environment and physical actions are essential. Recently, automating cultivation technique for agricultural work using long cultivation experience and artificial intelligence has been proposed. And automating work should be based on crop statuses such as age and condition. In particular, since fruits and vegetables have both vegetative and reproductive growth stages, it is important to understand more precisely the status of crops. The purpose of this study is to estimate the growth status of strawberry plant after transplanting from RGB images using a deep neural network. The images were acquired using a GoPro camera (GoPro HERO 10, GoPro Inc., USA) of the strawberry plant ‘Seolhyang’, which was transplanted in a venro-type glass greenhouse. Videos were filmed for 8 weeks at the interval of 1 week from July 6th. The images were augmented using ImageDataGenerator in keras module and inputted to a deep neural network model of various structures. The models used for training are MLP, CNN, and vision transformer. The model showed a performance of more than 95% accuracy. In the future, for the deep neural network structure that showed the highest performance, We are going to proceed ablation test for each RGB channel and compare performance for the different numbers of layers. The application of the deep neural network in this study shows that it could be the basis for the design of work for each growth status in the construction of an automated system for high quality and high yield in strawberry cultivation."
다중 패치를 이용한 트랜스포머 기반 장면 텍스트 인식,2022,"['Deep learning', 'Scene text recognition', 'Transformer', '.']",국문 초록 정보 없음,.
Classification of Covid-19 Infection Based on Chest X-ray Pictures Using OpenCv and Convolution Neural Networks,2022,"['Imbalance classification', 'image generation', 'convolution neural networks', 'ensemble learning', 'multi-class classification']",국문 초록 정보 없음,"COVID-19 is a pathogen called SARS-CoV-2, an RNA virus that can infect various animals, including humans. As COVID-19 spread globally, the World Health Organization upgraded it to a pandemic in March 2020. In addition to solving the problem of shortage of medical personnel, rapid and accurate classification of infected patients emerged as an important issue. Therefore, we propose a deep learning-based chest X-ray image reading model that can notify the doctor whether the patient is infected. The goal is to achieve multiclass classification, which not only classifies COVID-19 infections, but also other lung diseases to help the medical community. The proposed method is a combination model. It involves pre-processing the chest X-ray image using the image augmentation method and various convolutional neural network (CNN) models. The purpose of the proposed method is to classify COVID-19, normal people, and viral pneumonia appropriately. Overall, 15,153 X-ray images were used in the study. By using the proposed method, we obtained a model with high accuracy through improved image data. Characteristically, some models tend to detect COVID-19 and pneumonia properly. Finally, an ensemble model was created using models made by the proposed method. Eventually, we obtained a high accuracy (0.981) model for detecting infections appropriately."
자율운항선박 보조기기 내 고무 씰의 상태기반정비를 위한  고장진단용 데이터베이스 및 알고리즘 개발에 관한 연구,2022,"['Rubber Seal', 'Condition Based Maintenance', 'Fault Diagnosis', 'Accelerated Test', 'Data-driven Approach']",국문 초록 정보 없음,"Purpose: The marine oil purifier is a critical piece of auxiliary equipment on autonomous ships that can cause major engine failures if not maintained properly. Diagnosis of auxiliary equipment failures, especially those caused by degradation of seals, is difficult using current diagnostic techniques. The aim of this study is to develop a database and algorithm that will identify areas where condition-based maintenance is necessary for rubber seals.Methods: A multistep accelerated thermal aging test was performed on the marine oil purifier’s rubber seal. Using the purifier’s failure-simulation testbed, diagnostic data indicating the vibration-based condition due to the level of seal degradation was collected. Time and frequency domain analysis was performed using the established database, and a failure classification method using STFT and CNN was proposed.Results: Tensile and hardness test results indicated that rubber seals experienced decreasing tensile properties when undergoing the accelerated thermal aging process. A valid difference in the frequency domain was observed in the equipment condition monitoring data. Failure classification methods indicated an accuracy of 99%.Conclusion: In this study, a database and algorithm were developed for diagnosing the condition of rubber seals in marine oil purifiers. Their effectiveness was verified using time and frequency domain analysis and failure classification methods. The validity of the developed data-driven failure diagnosis method was successfully confirmed."
Profane or Not: Improving Korean Profane Detection using Deep Learning,2022,"['Profanity', 'deep learning', 'convolutional neural network', 'text mining', 'natural language processing']",국문 초록 정보 없음,"Abusive behaviors have become a common issue in many online social media platforms. Profanity is common form of abusive behavior in online. Social media platforms operate the filtering system using popular profanity words lists, but this method has drawbacks that it can be bypassed using an altered form and it can detect normal sentences as profanity. Especially in Korean language, the syllable is composed of graphemes and words are composed of multiple syllables, it can be decomposed into graphemes without impairing the transmission of meaning, and the form of a profane word can be seen as a different meaning in a sentence. This work focuses on the problem of filtering system mis-detecting normal phrases with profane phrases. For that, we proposed the deep learning-based framework including grapheme and syllable separation-based word embedding and appropriate CNN structure. The proposed model was evaluated on the chatting contents from the one of the famous online games in South Korea and generated 90.4% accuracy."
지상 초분광영상을 이용한 배추의 노균병 조기검출을 위한 딥러닝 모델 개발,2022,"['early detection', 'spectral features', 'deep learning', 'downy mildew', 'hyperspectral images']",국문 초록 정보 없음,"The main economic threat to Chinese cabbage producers in Korea is downy mildew on Brassica rapa. Affected leaves have become less valuable, and the Chinese cabbage which invaded are troublesome because symptom can occur and spreads rapidly wherever brassica crops are grown. Early identification with hyperspectral imaging approaches for downy mildew may potentially assist producers in identifying infection before apparent symptoms arise that are marked with unusual yellow to light brown patches on the top leaf area. Hyperspectral imaging (HSI) detects leaf disease in a sensitive and wide range of spectral wavelengths, and it is a broad field applicable. This study employed hyperspectral imagery focused on crops in the pots to gather high-resolution hyperspectral data and identify downy mildew at the early asymptomatic phases. Downy mildew spectral profiles are obtained from calibrated and preprocessed hyperspectral images. A deep learning Convolutional Neural Network (CNN) model is established to distinguish spatial and spectra patterns between healthy and diseased plants from hyperspectral image data series. The developed model is expected to achieve 90% accuracy and can be used to support the development of aerial hyperspectral imagery."
대조 학습에 기반한 기침 소리 분류 모델 분석,2022,"['자기지도학습', '대조 학습', 'mel-spectrogram', '증강기법', 'self-supervised learning', 'contrastive learning', 'mel-spectrogram', 'augmentation']","최근 COVID-19 확산으로, 기침 소리를 활용한 호흡기 질환 예측 연구가 다양하게 이루어지고 있으나 labeling된 기침 데이터는 임상 전문의들의 소견이 필요하기 때문에 구하기 어렵다. 반면 unlabeled data는 풍부하다는 점에서 self-supervised Learning (SSL)을 적용한다면 좋은 효과를 기대할 수 있다. SSL 방법 중, positive, negative pair의 유사성을 학습하는 대조 학습 방법이 소리 분야에서 많이 연구가 되고 있지만, 적합한 데이터 형태 및 학습 방법 등에 대한 심층적인 연구가 적고, 기침 소리의 대조 학습에 대한 연구는 부족한 상황이다. 본 연구에서는 기침 소리를 활용한 대조 학습 연구의 방향성을 제시하기 위해, 기침 소리 분류 모델을 구축하고 다양한 실험을 진행하였다. 실험 결과, 소리의 feature 중 mel-spectrogram이 기침 소리의 표현으로 적합하였고, 대조학습이 학습 데이터 크기에 대한 의존성을 감소시키는 것으로 나타났다. 또한 모델 성능 고도화를 위해 channel 수와 filter의 종류, augmentation 기법들을 비교 분석한 결과 single-channel, 2D-CNN이 적합하였고, time shift와 block masking을 조합했을 때 가장 뛰어난 성능을 보였다. 마지막으로 기침 소리 분류 이외에 covid-19 분류에도 성능 향상을 보이는 것을 확인하였다.",다국어 초록 정보 없음
STFT를 통한 합성곱 신경망 기반의 포터블 에어컨 고장 진단,2022,"['소음(Noise)', '진동(Vibration)', '고장 진단(Fault Diagnosis)', '합성곱 신경망(Convolution Neural Network)', '단시간 푸리에 변환(Short-Time Fourier Transform)']",국문 초록 정보 없음,"Various machines and home appliances experience aging and failure due to their continued use. Electronic problems such as circuit failures are easy to diagnose on the product itself, but mechanical defects and faults are difficult to diagnose. Since acoustic signals generated from a machine include inherent operating characteristics, the unwanted mechanical faults can be diagnosed by analyzing different patterns between normal and fault signals. In this study, the mechanical failure diagnosis of a commercial portable air conditioner has been implemented based on a deep learning-based image classification technique. Short-time Fourier transform (STFT) is used to effectively analyze the frequency characteristics that occur in the event of machine failures, and then the fault status of the air conditioner is examined by classifying the extracted spectrogram images through convolution neural network (CNN). The proposed method shows a precise fault diagnosis without additional devices and can be effectively applied for fault diagnostic algorithms of various home appliances."
Extraction of Cervical Lymph Nodes using Improved U-Net++,2022,"['Computer Aided Diagnosis', 'Cervical Lymph Node', 'Segmentation', 'Convolutional Neural Network', 'U-Net++']",국문 초록 정보 없음,"Early detection and treatment of the lymph node are important since swelling of the neck is a likely factor in systemic metastasis of cancer. One of the diagnoses of cervical swelling is a CT scan, which has a beneficial influence on the diagnosis of the disease. However, the reading of CT images is burdened by the large number of images, which increases the physicians workload. In addition, since it is based on the subjective judgment of the physician, there may be discrepancies in diagnostic results and undetected cases due to differences in experience. A means of solving these problems requires a CAD system that provides a second opinion to the physician. Therefore, this paper proposes a segmentation method of cervical lymph node region for the purpose of developing a CAD system for the diagnosis of cervical lymphadenopathy from CT images. The proposal method is a CNN model with U-Net++ as the backbone, introducing CBAM (convolution block attention module) and dual-branch multi-scale attention module. The proposed method was applied to CT images of 11 cases, yielding IoU of 62.29, confirming its validity."
Fingertip Force and Muscle Activation Patterns at Varying grasp Objects,2022,"['Hand grasp', 'Fingertip force', 'Electromyography', 'Force sensistive resistor']",국문 초록 정보 없음,"In this study, we tried to collect and analyze the kinetic and neurological information such as finger-tip forces and EMG for several representative (the most commonly used) grasp movements to explore their force and muscle activation patterns based on the newly defined grasp taxonomy. Ten able-bodied (five males, five females) volunteered to participate and they performed five different grasp tasks: holding a bottle (Bottle), turning a doorknob (Knob), cutting with a knife (Knife), brushing with a toothbrush (Toothbrush), holding a thick book (Book) after we attached five force sensitive resistor (FSR) sensors on the tip of fingers and four surface electromyogram (sEMG) electrodes on the lower arm of the subject’s dominant hand. Root Mean Square (RMS) and Mean Absolute Value (MAV) from the mean maximum values of sEMG(%) and fingertip force(kgf) of all ten subjects were extracted as features. The classification from the feature dataset using convolutional neural network (CNN) was applied and analyzed the results of accuracy and repeatability. The mean maximum values of EMG and fingertip forces during five different grasp tasks, and the MAV and RMS which were extracted features from the above were compared with task pairs. They showed significant differences in comparison of four pairs of tasks which were Bottle and Knife (p = 0.005 in both MAV and RMS), Bottle and Toothbrush (p = 0.005in both MAV and RMS), Bottle and Book (p = 0.013 in both MAV and RMS), Knob and Toothbrush (p = 0.047 in MAV and p = 0.028 in RMS). The classification accuracy of the Bottle grasp task was the largest at 60% (true positive predictive rate is 60% and false postive rate is 40%), while the other tasks showed an 30-40% of accuracy. Repeatability was 60% in the Bottle task and 50% in the Knob task, and those of the other tasks were ranged 30-40%. Overall, it is believed that the small number of samples in the study is the main reason of the low accuracy and repeatability of the classification. A total of nine variables (four sEMG and five forces) showed different significances in paired mean comparisons for five grasp tasks (graspping a bottle, turning a doorknob, cutting with a knife, brushing teeth with a toothbrush, holding a thick book). A comparison of the reduced variable from feature extraction also showed different classification accuracy for five grasp tasks."
Resolution-Aware Deep Learning Model for Emergency Communication in Smart Homes using Thermal Sensor,2022,"['Emergency and Activity Recognition', 'Deep Learning', 'Thermal Sensor', 'Sensor Resolution']",국문 초록 정보 없음,"Due to the development in sensor technologies and smart homes, Emergency and Activity Detection (EAD) has become a growing research issue as there is a need to support safety and security in homes. In this work, the impact of three different thermal sensor resolutions was investigated for EAD. The design of the system includes three parts: data acquisition, EAD and the emergency alert system. An alert system is considered reliable if the sensing model can mitigate the introduction of noise by the sensors or noisy environments. Research in this domain has seen the adoption of sensors with different resolutions. However, not much work has been done in developing resolution-aware models considering the impact of sensor resolutions on both the quality of data and the performance of the classification models. In this work, a CNN model was developed for EAD from datasets of various sensors with diverse resolutions. The results showed that the proposed model exhibited resilience in handling the error that may occur from the impact of sensor resolution for classification of normal daily living activity and emergency in a smart home."
합성곱 신경망 기반 의미론적 분할 기술을 이용한 국내 밭작물의 분리 기법 연구,2022,"['UAV', '작물 분리', '딥러닝', '합성곱신경망', '의미론적 분할']","작물 배경 분리 알고리즘은 농작물 원격탐사에서 기본적이고 중요한 기술이다. 작물 성장 단계 예측, 작물 열 감지, 작물 밀도 추정, 잎 질병 감지 및 작물 바이오매스 모니터링과 같은 많은 연구는 작물 분리 알고리즘의 성능에 크게 의존한다. 현장 조건에서 무인항공기(UAV) 영상의 작물 배경 분리은 바람과 빛 조건 변화에 의한 영상의 기하학적 왜곡을 고려하여 더욱 정교해야 한다. 특히, 한국의 밭작물 재배 조건에서는 잡초 억제 및 한파 피해 방지를 위해 멀칭 비닐을 사용하기 때문에 영상 내 배경이 더욱 복잡하다. 우리의 선행 연구에서는 RGB 영상 기반의 식생지수와 CIE LAB 색공간을 사용하여 배추, 무, 양파, 그리고 마늘 등 한국의 주요 밭작물에 대한 작물 분리 알고리즘을 개발하였다. 그러나 양파, 마늘과 같이 잎이 길고 좁으며 생김새가 불규칙한 작물은 작물과 배경의 경계가 불명확하고 그림자에 의한 영향이 커서 작물 배경 분리 성능이 크게 제한되는 것으로 보고되었다. 본 연구에서는 UAV 영상에서 토양 및 배경으로부터 작물을 효과적으로 분리하기 위해 CNN 기반 의미론적 분할(Semantic segmentation) 알고리즘을 개발하였다. 먼저, 다중 분광 영상을 사용하여 작물 식별에 특화된 NDVI 영상을 생성하였다. NDVI 영상은 수동 임계값을 사용하여 작물과 배경으로 정교하게 이진화되었다. 이진 이미지(Binary image)는 의미론적 분할을 위한 학습 데이터를 구성하기 위해 작물과 배경의 위치를 결정하는 주석 파일(Label)로 사용되었다. 데이터 학습을 위해 생장 초기부터 후기 단계의 UAV RGB 및 NDVI 영상을 256 x 256 픽셀 크기로 잘라내어 총 5,189개의 크롭 영상을 얻었다. 의미론적 분할을 위한 학습 모델은 U-Net을 사용하였으며, 데이터의 70%는 training, 15%는 validation, 15%는 test에 사용되었다. 학습 진행시 모든 데이터는 0에서 1 사이의 값으로 정규화되었다. 데이터 학습에는 U-Net 구조가 적용되었고, Adam optimizer와 ReLU 활성화 함수를 사용하였으며, Softmax 함수를 사용해 픽셀별 분류를 수행하였다. 본 연구에서 개발한 U-Net 모델을 적용하였을 때 모든 테스트 데이터에 대하여 75%이상의 작물 분리 결과를 얻을 수 있었다. NDVI 기반 주석 파일의 정확도를 높인다면, 작물 분리 성능을 향상시킬 수 있을 것으로 기대된다.",다국어 초록 정보 없음
K-Means 클러스터링 기반 패션 이미지 색상 분류 구현,2022,[],"이미지 색상 분류 방식을 위한 연구는 오랫동안 계속되고 있으며 이는 패션 이미지의 색상 추출에도 적용되고 있다. 본 논문에서는 패션 이미지 색상 분류를 직접 구현하여 분석한다. 간단하고 빠르게 클러스터링 할 수 있는 K-means 알고리즘을 기반으로 기존의 패션 이미지 색상 분류 방식보다 최적의 결과를 낼 수 있는 방안을 연구하였다. 한 가지 이상의 주요 색상에 대한 명확한 결과를 얻기 위해 이미지 내 배경을 제외한 패션 아이템 부분 픽셀값만 K-means 모델에 입력되도록 하였다. 이미지 내의 객체와 배경 영역을 구분하기 위해 상의를 인식하는 MaskRCNN 학습 모델을 이용하였고, 결과 이미지에 α 채널을 추가하여 인식된 객체 외 영역에는 0을 값으로 주었다. 이러한 방식으로 전처리된 이미지 내 α 채널 값이 0인 영역을 제외한 RGB채널의 데이터만을 모델에 입력하였다. 즉, 이미지 내 아이템의 색상 값만으로 클러스터링하여 기존의 방식보다 명확한 아이템의 색상 분류 결과를 도출했다. 추가로 K-means 모델의 적절한 K값 지정을 위해 CNN 분류 모델을 이용한 선처리 방식을 제안한다.",다국어 초록 정보 없음
Martial Arts Moves Recognition Method Based on Visual Image,2022,"['Action Recognition', 'Hidden Markov Model', 'Martial Art', 'Visual Image', 'Wushu']",국문 초록 정보 없음,"Intelligent monitoring, life entertainment, medical rehabilitation, and other fields are only a few exampleswhere visual image technology is becoming increasingly sophisticated and playing a significant role.Recognizing Wushu, or martial arts, movements through the use of visual image technology helps promote anddevelop Wushu. In order to segment and extract the signals of Wushu movements, this study analyzes thedenoising of the original data using the wavelet transform and provides a sliding window data segmentationtechnique. Wushu movement The Wushu movement recognition model is built based on the hidden Markovmodel (HMM). The HMM model is trained and taught with the help of the Baum-Welch algorithm, which isthen enhanced using the frequency weighted training approach and the mean training method. To identify thedynamic Wushu movement, the Viterbi algorithm is used to determine the probability of the optimal statesequence for each Wushu movement model. In light of the foregoing, an HMM-based martial arts movementsrecognition model is developed. The recognition accuracy of the HMM model increases to 99.60% when thenumber of samples is 4,000, which is greater than the accuracy of the SVM (by 0.94%), the CNN (by 1.12%),and the BP (by 1.14%). From what has been discussed, it appears that the suggested system for detecting martialarts acts is trustworthy and effective, and that it may contribute to the growth of martial arts."
Embedded High Accuracy Compact Transformer Vision System for Real-Time Health Detection During Seedling Transplanting,2022,"['Computer vision', 'Seedling transplanting', 'Transformers']",국문 초록 정보 없음,"Seedling transplanting is an important step in plant production to transplant seedlings into low-density trays at specific growth stages while discarding unhealthy seedlings. Several health detection methods based on machine learning or deep learning have been proposed. However there are still gaps in accuracy and efficiency compared to manual work. In this study, we proposed an embedded compact transformer vision system for real-time health detection during seedling transplanting. The vision system consisted of a camera (Kinect Azure) capturing RGB images in real time and a detection algorithm in an embedded PC (Jetson AGX Xavier). We introduced compact Transformers in the detection algorithm by designing the appropriate size and convolutional tokeniztion, so that the model had fewer parameters (22.58M) while outperforming the current state-of-the-art CNN models. In the validation experiment, two groups of paprika seedlings were cultivated to distinguish healthy and unhealthy by treating water stress. The algorithm showed 94.4% accuracy in the random tests. The experimental results quantitatively demonstrate that the accuracy of our method is competitive for manual. The proposed simple and compact transformers algorithm performs well in embedded devices with limited computational resources. High accuracy detection of seedling health is achieved, which promotes the practical development of future automatic transplanting robots."
Interference intention classification of moving obstacles used for USV collision avoidance,2022,"['Unmanned Surface Vessels (USV)', 'Interference intention classification', 'Machine vision', 'Collision avoidance', 'Machine learning']",국문 초록 정보 없음,"Unmanned Surface Vessels (USV) may interfere with ships in the same lane during navigation and may be affected by ships that actively collide or intercept the USV. Evidently, the latter poses a greater threat than the former. This paper proposes the concept of active and inactive interference. It is necessary for the USV to accurately classify the vessels’ intentions to conduct a suitable collision avoidance strategy.However, the existing research on collision avoidance of USV focuses on avoiding moving obstacles and rarely considers the interference intention of dynamic obstacles for USV when choosing collision avoidance strategies. This paper proposes an algorithm to recognize the interference intention of ships by combining visual classification with a Support Vector Machine (SVM). First, a Convolutional Neural Network (CNN) is proposed to distinguish the merchant ship from a high-performance ship that actively interferes with the USV with high probability. A high-dimensional feature dataset was designed to illustrate the navigation characteristics of an obstacle, and Principal Component Analysis (PCA) was then employed to reduce the dimensionality of the dataset for obstacle classification. A modified SVM is presented to classify obstacles into active and inactive interference intention categories. Moreover, an escape algorithm based on an improved artificial potential field method is proposed for vessels with active interference. The simulation and experimental results clearly show that the USV can successfully identify the interference intention of obstacles and adopt a specific collision avoidance strategy for obstacles with active interference intentions. Using this algorithm, the USV can safely avoid obstacles with different interference intentions."
Enhanced Pseudo Labeling Based on Bidirectional Object Tracker for Training Object Detection CNNs,2022,"['Object detector', 'pseudo labels', 'bounding box', 'confidence.']",국문 초록 정보 없음,"This paper presents an improved approach to generate pseudo labels for unlabeled dataset. To properly train a network, large amount of dataset is required. The publicly available datasets are often not large enough or versatile. Although we can acquire a great deal of images from the internet, those images are not labeled. Conventionally, the generation of ground truth labels requires human effort which is very expensive and time-consuming. Recently, existing object detectors are being employed to automate the generation of labels, called pseudo labels. Such pseudo labels have poor accuracy, since most of the object detectors employ simplistic confidence thresholding, which tends to discard even good labels. This paper proposes an enhanced pseudo labeling technique that selects the predicted labels using a bi-directional tracking method instead of simplistic confidence thresholding. The proposed technique can recover many predicted labels that are actual good labels but would have been discarded due to their poor confidence. Our method can produce pseudo labels for new training dataset with higher accuracy than conventional pseudo labeling techniques, thus offering better training accuracy for object detector CNN models."
A Remote Sensing Scene Classification Model Based on EfficientNetV2L Deep Neural Networks,2022,"['VHR', 'Remote sensing', 'scene classification', 'Deep learning', 'EfficientNet']",국문 초록 정보 없음,"Scene classification of very high-resolution (VHR) imagery can attribute semantics to land cover in a variety of domains. Real-world application requirements have not been addressed by conventional techniques for remote sensing image classification. Recent research has demonstrated that deep convolutional neural networks (CNNs) are effective at extracting features due to their strong feature extraction capabilities. In order to improve classification performance, these approaches rely primarily on semantic information. Since the abstract and global semantic information makes it difficult for the network to correctly classify scene images with similar structures and high interclass similarity, it achieves a low classification accuracy. We propose a VHR remote sensing image classification model that uses extracts the global feature from the original VHR image using an EfficientNet-V2L CNN pre-trained to detect similar classes. The image is then classified using a multilayer perceptron (MLP). This method was evaluated using two benchmark remote sensing datasets: the 21-class UC Merced, and the 38-class PatternNet. As compared to other state-of-the-art models, the proposed model significantly improves performance."
A cable tension identification technology using percussion sound,2022,"['Artificial Neural Network', 'carbon nanotubes', 'cementitious composites', 'fire', 'mechanical', 'polypropylene fibers', 'cable tension identification', 'deep learning', 'percussion sound', 'structural health monitoring']",국문 초록 정보 없음,"The loss of cable tension for civil infrastructure reduces structural bearing capacity and causes harmful deformation of structures. Currently, most of the structural health monitoring (SHM) approaches for cables rely on contact transducers. This paper proposes a cable tension identification technology using percussion sound, which provides a fast determination of steel cable tension without physical contact between cables and sensors. Notably, inspired by the concept of tensioning strings for piano tuning, this proposed technology predicts cable tension value by deep learning assisted classification of ""percussion"" sound from tapping a steel cable. To simulate the non-linear mapping of human ears to sound and to better quantify the minor changes in the high-frequency bands of the sound spectrum generated by percussions, Mel-frequency cepstral coefficients (MFCCs) were extracted as acoustic features to train the deep learning network. A convolutional neural network (CNN) with four convolutional layers and two global pooling layers was employed to identify the cable tension in a certain designed range. Moreover, theoretical and finite element methods (FEM) were conducted to prove the feasibility of the proposed technology. Finally, the identification performance of the proposed technology was experimentally investigated. Overall, results show that the proposed percussion-based technology has great potentials for estimating cable tension for <i>in-situ</i> structural safety assessment."
데이터 증강 기반 효율적인 무선 신호 분류 연구,2022,"['Wireless Signal', 'Signal Classification', 'Deep learning', 'GAN', 'IoT']","사물인터넷 환경에서는 다양한 무선 통신 기술을 사용하는 기기들이 점점 증가하고 있다. 특히, 다양한 무선 신호 변조 유형을 정확하게 식별하기 위해 효율적인 특성 추출 기법을 설계하고 무선 신호의 종류를 분류하는 것이 필수적이다. 하지만, 실제 환경에서 레이블이 지정된 무선 신호 데이터를 수집하는 것은 쉬운 문제가 아니다. 최근 무선 신호 분류를 위해 딥러닝 기반의 다양한 학습 기법들이 제안되어졌다. 딥러닝의 경우 훈련 데이터셋이 적을 경우 과대적합에 빠질 가능성이 높으며, 이는 딥러닝 모델을 활용한 무선 신호 분류 기법의 성능 저하를 유발한다. 본 연구에서는 다양한 무선 신호들이 존재할 때 분류 성능을 높이기 위해 생성적 적대 신경망 기반 데이터 증대 기법을 제안한다. 분류해야 하는 무선 신호의 종류가 다양할 때 특정 무선 신호를 나타내는 데이터의 양이 적거나 균형이 맞지 않는 경우 제안한 기법을 활용하여 필요한 무선 신호와 관련된 데이터의 양을 증가시킨다. 제안한 데이터 증강 알고리즘의 유효성을 검증하기 위해 무선 신호의 데이터양을 증가시키고 균형을 맞춘 결과를 바탕으로 CNN 및 LSTM 기반 무선 신호 분류기를 구현하여 실험해본 결과 데이터 균형을 맞추지 않았을 때보다 분류 정확도가 높아지는 것을 확인하였다.",다국어 초록 정보 없음
머신러닝기반 색채조화 배색 모델 구현,2022,"['배색 모델', '색채조화', '머신러닝', '모던', '내추럴', '거실', 'Color Scheme Model', 'Color Harmony', 'Machine Learning', 'Modern', 'Natural', 'Living Room']",국문 초록 정보 없음,"To satisfy the diverse needs of consumers, emotional designs that focus on consumers have emerged. Consumers who consume emotionally have a high score on the happiness index and satisfaction. Among them, consumers pursue a style that suits their lifestyle in the residential space where they live. And in detail, consumers are highly satisfied by changing the color and material of objects placed in the space. Consumers prefer the natural and the modern styles from among the styles of interior design. Furthermore, when consumers plan the color scheme of residential spaces, living rooms are the top priority among residential spaces. Therefore, the purpose of this paper is to develop a model based on machine learning that recommends colors of furniture or objects to be placed in the living room of consumers. The data learned in the developed model is RGB of three colors extracted from natural and modern living room images. The living room space images are collected based on keywords on the I.R.I image scale, which visually measures Koreans' color sensitivity, and in addition, the living room space images are collected through a sharing platform. The collected images are cleaned and integrated using the I.R.I color image scale and CNN model. The color data (RGB) of the cleaned images are learned in XGBoost and LightGBM, which perform machine learning tasks. The color recommendation models in this paper are evaluated using r² and MSE, which are evaluation methods for regression models supported by Scikit-Learn. And the model with the highest evaluation score is selected. Therefore, in this paper, a color scheme model for color harmony in the living room was selected as XGBoost No. 2 “train : value = 8 : 2”. This is effective as a color scheme model, and it will be a model that can satisfy consumers with individuality in the era of emotional design."
Application of Deep Learning: A Review for Firefighting,2022,"['Deep Learning', 'Firefighting', 'Literature Review', 'Structural Fires']",국문 초록 정보 없음,"The aim of this paper is to investigate the prevalence of Deep Learning in the literature on Fire & Rescue Service. It is found that deep learning techniques are only beginning to benefit the firefighters. The popular areas where deep learning techniques are making an impact are situational awareness, decision making, mental stress, injuries, well-being of the firefighter such as his sudden fall, inability to move and breathlessness, path planning by the firefighters while getting to an fire scene, wayfinding, tracking firefighters, firefighter physical fitness, employment, prediction of firefighter intervention, firefighter operations such as object recognition in smoky areas, firefighter efficacy, smart firefighting using edge computing, firefighting in teams, and firefighter clothing and safety. The techniques that were found applied in firefighting were Deep learning, Traditional K-Means clustering with engineered time and frequency domain features, Convolutional autoencoders, Long Short-Term Memory (LSTM), Deep Neural Networks, Simulation, VR, ANN, Deep Q Learning, Deep learning based on conditional generative adversarial networks, Decision Trees, Kalman Filters, Computational models, Partial Least Squares, Logistic Regression, Random Forest, Edge computing, C5 Decision Tree, Restricted Boltzmann Machine, Reinforcement Learning, and Recurrent LSTM. The literature review is centered on Firefighters/firemen not involved in wildland fires. The focus was also not on the fire itself. It must also be noted that several deep learning techniques such as CNN were mostly used in fire behavior, fire imaging and identification as well. Those papers that deal with fire behavior were also not part of this literature review."
도커 기반의 빅데이터 분석 환경을 고려한 딥러닝 플랫폼 설계,2022,"['컨테이너', '데이터 유형', '텍스트 분류', '이미지 분류', '모델 배포', 'Container', 'Data Type', 'Text Classification', 'Image Classification', 'Model Serving']","딥러닝 모델을 학습하고 학습된 모델에서 새로운 데이터에 대한 예측을 수행하기 위해서는 모델 생성부터 예측까지 전체 과정을 간편하게 사용할 수 있는 환경이 필요하다. 그러나 대부분의 인공지능 서비스들은 모델 성능을 높이기 위한 파라미터를 결정하는데 많은 시간과 노력을 기울이고 있다. 따라서 본 연구에서는 공개 소스를 활용하여 컨테이너 기반으로 딥러닝 분류 모델의 배포 및 관리가 쉬운 아키텍처를 설계하고자 한다. 분류 모델은 시계열, 비시계열, 이미지 데이터에 대한 3가지 방법론을 제안한다. 실험 결과 데이터 유형별로 장단기 메모리 구조, 컨볼루션 신경망 구조, 순환 신경망 구조, 사전 훈련 모델을 사용할 수 있는 컨테이너를 제공함으로써 모든 데이터를 적절하게 분류할 수 있었다.","In order to learned a deep learning models and performed predictions on new data in the learned models, an environment that could simple used to the all processed from models generated to prediction is needed. However, most artificial intelligence services a lot of time and effort to determine parameters decide to increased the models performance. Therefore, in this study, architectures are designed for the distribution, management of container based deep learning classification models of the using open source. Propose were made for a total of three: time-series, non time-series, and image data, which are classification models. As a result of the experiment, all data could be proper classified by provided container for LSTM(Long Short-Term Memory), CNN(Convolutional Neural Network), RNN(Recurrent Neural Network) and pre-training models by data typed."
360 파노라마 실내공간 사진 기반 지능형 레퍼런스 데이터베이스 구축,2022,"['360 파노라마 이미지', '데이터아카이빙', '실내 디자인 레퍼런스 이미지', '자동 분류', '딥러닝', '360-degree panorama picture', 'Data Archiving', 'Interior Design Reference Image', 'Auto-classification', 'Deep Learning']","(연구배경 및 목적) 공간을 디자인하는 과정은 여러 사람이나 그룹간의 협업이 수반되기 때문에 디자인 의사소통은 디자이너가 디자인 정보를 공유하고 결정을 내리는 데 중요한 역할을 한다. 최근 가상현실의 도래로 많은 관찰자들이 수동적인 공간 경험을 넘어 원하는 공간을 어디에서나 경험할 수 있게 되었다. 본 연구의 목적은 지금까지 사용되어 온 실내공간 디자인 의사소통 도구를 분석하고, 360 파노라마 이미지를 기반으로 지능형 인테리어 디자인 레퍼런스 데이터베이스 프로토타입을 구축하는 것이다. (연구방법) 본 논문에서는 고화질 파노라마 사진에서 추출한 인테리어 디자인 이미지를 자동으로 분류하는 딥러닝 기술을 이용하여 문제를 해결하였다. 본 논문에서는 레퍼런스 이미지 아카이브 구축 프로세스를 단순화하는 접근 방식을 제시한다. 연구 방법 및 절차는 1) 360 파노라마 이미지 준비, 2) 실내공간 디자인을 위한 레퍼런스 이미지 자동 추출, 3) 이미지 데이터셋을 다양화하기 위해 각 이미지에 나타나는 특징을 자동 분류 및 인식, 4) 인식 정보 및 이미지의 저장. (결과) 앞서 언급한 방법을 기반으로 본 연구에서는 실행가능한 프로토타입을 제작하여 그 활용성을 검증하고자 하였다. 360도 파노라마 이미지의 소스는 360도 카메라를 이용하여 촬영한 고화질 사진뿐만 아니라 CAD나 BIM으로 생성된 사실적인 렌더링 가상 이미지를 동시에 활용한다. 주어진 실내 360도 파노라마 영상을 분할하는 방법에는 파라메트릭 방식과 미리 설정된 큐브 맵 방식이 있다. 첫 번째 방법을 통해 주어진 이미지를 특정 시야각과 이미지 크기를 가진 격자로 분할한다. 반면 큐브 맵 방식은 시야가 다르고 이미지 크기가 정해진 6개의 이미지만 생성한다. 학습된 딥러닝 기반 CNN 모델은 분할된 각 이미지에 공간 사용량, 디자인 스타일 등의 디자인 관련 정보를 인식하고 라벨링한다. 분할된 이미지는 레이블이 지정된 데이터와 함께 데이터베이스에 자동으로 보관된다. (결론) 본 논문은 건축 설계 분야에서 방대한 양의 질적 360도 파노라마 이미지 데이터를 아카이브하고 활용하는 데 기여할 것으로 기대된다. 특히, 사람들이 임의적으로 취급하는 인테리어 디자인 레퍼런스를 보관하는 방식을 표준화할 것이다. 추후 연구를 통해 주어진 인테리어 디자인 이미지로부터 인식 정보(예: 디자인 관련 객체 및 디자인 스타일 등)의 범위를 확장하고, 저장된 데이터를 디자인 프로세스에 활용하는 방법을 개발하고자 한다.",다국어 초록 정보 없음
Developing the Hoax: A Discord Chatbot That Classify Fake News Using Recurrent Neural Network,2022,"['Fake News Classification', 'RNN', 'LSTM', 'Discord API', 'Chatbot', 'Deep learning']",국문 초록 정보 없음,"Internet has replaced traditional media and become one of the major news media platforms. News from internet sources tend, since they are accessible and convenient, to travel quicker and simpler than conventional news sources. However, not all of the media reports obtained from unverified sources are authentic as fake news arises in large numbers and is prevalent in online communities for both political and commercial reasons.Fake news can deceive or misinform readers theoretically or intentionally because people will easily get tangled by any of this information which may impact on the offline community. Although some manual websites are designed to check if the piece of information is true, the volume of quick-spread information online, notably on the web, does not scale. In order to solve this issue automatic fact-checking applications were designed to tackle the requirement of scalability and automation. However, current application methods lack an inclusive multi-dimensional data set to identify fake news features to improve machine learning classification model performance. To overcome this problem, this research paper proposed the Hoax chatbot which classifies the data when user enters an article headline into it. In this research work, the classification of dataset has been done using recurrent neural network (RNN) and long short-term memory (LSTM) model. The fake and true news dataset are preprocessed and used to train the model. Saved model is deployed on the discord server in order to check the credibility of the given input text. Discord API gives an access to run python files into their chatbot. In terms of analysis, the proposed model outperforms already existed neural network model such as convolutional neural network (CNN) with an accuracy of 96.77%."
EDNN based prediction of strength and durability properties of HPC using fibres & copper slag,2022,"['copper slag', 'Enhanced Deep Neural Network (EDNN)', 'fibre synergy', 'High-Performance Concrete (HPC)', 'Switched Multi-Objective Jellyfish Optimization (SMOJO)']",국문 초록 정보 없음,"For producing cement and concrete, the construction field has been encouraged by the usage of industrial soil waste (or) secondary materials since it decreases the utilization of natural resources. Simultaneously, for ensuring the quality, the analyses of the strength along with durability properties of that sort of cement and concrete are required. The prediction of strength along with other properties of High-Performance Concrete (HPC) by optimization and machine learning algorithms are focused by already available research methods. However, an error and accuracy issue are possessed. Therefore, the Enhanced Deep Neural Network (EDNN) based strength along with durability prediction of HPC was utilized by this research method. Initially, the data is gathered in the proposed work. Then, the data's pre-processing is done by the elimination of missing data along with normalization. Next, from the pre-processed data, the features are extracted. Hence, the data input to the EDNN algorithm which predicts the strength along with durability properties of the specific mixing input designs. Using the Switched Multi-Objective Jellyfish Optimization (SMOJO) algorithm, the weight value is initialized in the EDNN. The Gaussian radial function is utilized as the activation function. The proposed EDNN's performance is examined with the already available algorithms in the experimental analysis. Based on the RMSE, MAE, MAPE, and R<sup>2</sup> metrics, the performance of the proposed EDNN is compared to the existing DNN, CNN, ANN, and SVM methods. Further, according to the metrices, the proposed EDNN performs better. Moreover, the effectiveness of proposed EDNN is examined based on the accuracy, precision, recall, and F-Measure metrics. With the already-existing algorithms i.e., JO, GWO, PSO, and GA, the fitness for the proposed SMOJO algorithm is also examined. The proposed SMOJO algorithm achieves a higher fitness value than the already available algorithm."
무인기로 취득한 RGB 영상과 YOLOv5를 이용한 수수 이삭 탐지,2022,"['Sorghum', 'UAV', 'RGB', 'YOLO', 'Detection']","본 연구는 수수의 수확량 추정을 위해 무인기로 취득한 RGB 영상과 YOLOv5를 이용하여 수수 이삭 탐지 모델을 개발하였다. 이삭이 가장 잘 식별되는 9월 2일의 영상 중 512×512로 분할된 2000장을 이용하여 모델의 학습, 검증 및 테스트하였다. YOLOv5의 모델 중 가장 파라미터가 적은 YOLOv5s에서 mAP@50=0.845로 수수 이삭을 탐지할 수 있었다. 파라미터가 증가한 YOLOv5m에서는 mAP@50=0.844로 수수 이삭을 탐지할 수 있었다. 두 모델의 성능이 유사하나 YOLOv5s (4시간 35분)가 YOLOv5m (5시간 15분)보다 훈련시간이 더 빨라 YOLOv5s가 수수 이삭 탐지에 효율적이라고 판단된다. 개발된 모델을 이용하여 수수의 수확량 예측을 위한 단위면적당 이삭 수를 추정하는 알고리즘의 기초자료로 유용하게 활용될 것으로 판단된다. 추가적으로 아직 개발의 초기 단계를 감안하면 확보된 데이터를 이용하여 성능 개선 및 다른 CNN 모델과 비교 검토할 필요가 있다고 사료된다.","The purpose of this study is to detect the sorghum panicle using YOLOv5 based on RGB images acquired by a unmanned aerial vehicle (UAV) system. The high-resolution images acquired using the RGB camera mounted in the UAV on September 2, 2022 were split into 512×512 size for YOLOv5 analysis. Sorghum panicles were labeled as bounding boxes in the split image. 2,000images of 512×512 size were divided at a ratio of 6:2:2 and used to train, validate, and test the YOLOv5 model, respectively. When learning with YOLOv5s, which has the fewest parameters among YOLOv5 models, sorghum panicles were detected with mAP@50=0.845. In YOLOv5m with more parameters, sorghum panicles could be detected with mAP@50=0.844. Although the performance of the two models is similar, YOLOv5s (4 hours 35 minutes) has a faster training time than YOLOv5m (5 hours 15 minutes). Therefore, in terms of time cost, developing the YOLOv5s model was considered more efficient for detecting sorghum panicles. As an important step in predicting sorghum yield, a technique for detecting sorghum panicles using high-resolution RGB images and the YOLOv5 model was presented."
수기 운송장 인식용 한글 OCR 학습 데이터세트 구축에 관한 연구,2022,[],"최근 인공지능을 이용한 이미지 혹은 영상 분석을 위해 컴퓨터 비전 분야에 관한 연구가 폭발적인 관심을 받고 있 다. 컴퓨터의 사용이 많아지면서 이미지 파일로 존재하는 문자를 수정 가능한 텍스트 형태로 바꾸기 위한 인공지능 기 반 시스템의 개발 필요성이 대두되었는데, 특히 종이 문서를 디지털 문서로 변환하는 작업을 무인화할 수 있는 시스템 의 핵심적인 기술인 광학 문자 인식 기술(Optical Character Recognition, OCR)은 높은 인식률과 성능으로 차량 번호 판 인식, 신분증 인식, 신용카드 인식 등 다양한 플랫폼에서 활용되고 있다. 인쇄체에 대한 OCR 기술은 많은 연구가 이루어지고 있으나 최근 코로나로 인해 시장 규모가 폭발적으로 성장한 물류 운송 플랫폼에서 주로 사용되는 필기체 의 문자 인식 기술은 그렇지 못하다. 영문 필기체 인식률이 높은 정확도를 보인다는 것에 비해 한글 필기체 인식률은 더 낮은 정확도를 보였는데, 한글 데이터의 가짓수가 적고, 한글 구조의 복잡성으로 인해 한글 필기체의 학습이 더욱 어렵기 때문이다. 영문은 대, 소문자를 합쳐 총 52개의 문자를 분류하면 되지만, 한글의 경우 자음과 모음으로 음절이 구성되어 총 분류가 필요한 문자의 수가 11,172개로 분류 난이도가 매우 높다는 단점이 있고 이 때문에 학습이 어렵 다. 이러한 단점을 해결하기 위해 분류할 문자의 수를 줄여 학습의 난이도를 낮추는 것이 필수적이다. 따라서 한글의 구조적 특성을 이용하여 인식 단위를 자음, 모음 단위로 한정하여 분류하는 모델을 구성한다면 분류해야 할 문자의 수 가 초성 19개, 중성 21개, 종성 20개로 총 60개로 줄일 수 있어 학습의 난이도를 낮추고 정확도를 높일 수 있을 것이 다. 그러나 자음, 모음 인식 모델에 적용할 오픈된 한글의 자음, 모음 데이터세트는 없었으며, 비슷한 문제를 해결하기 위한 데이터세트도 존재하지 않았다. 또한, 오픈된 많은 한글 음절 단위의 데이터세트조차 본 연구에서 해결하려 하는 수기 운송장 인식 문제와 관련성이 없는 특징들이 내재 되어있는 경우들이 빈번했다. 따라서 현재 해결하려고 하는 문 제에 맞춰 직접 원하는 방법으로 데이터세트를 구축하여 수기 운송장 인식 문제를 해결하고자 한다. 본 연구에서는 수기 운송장 내 문자들을 인식하기 위한 학습용 데이터세트 구축 방법을 제안한다. 제안하는 데이터 세트의 구성은 기존의 한글 OCR 데이터세트처럼 음절 단위로만 구성된 것이 아닌, 자음, 모음 단위의 데이터로 이루 어진다. 이는 분류하여야 할 문자의 수를 60개까지 획기적으로 줄임으로써 학습모델의 정확도를 높일 수 있을 것이다. 또한, 딥러닝 기반 CNN(Convolutional Neural Networks)로 구성된 기존 OCR 모델에 제안하는 샘플 데이터세트를 적 용하여 적절성 여부를 판단하였다. 추후 연구인 한글의 자음, 모음 단위 인식 모델과 기존 한글 OCR 모델을 결합하여 한글 필기체 인식률을 향상시키는 알고리즘에 관한 연구에 기반이 되는 데이터세트로 활용할 가능성을 확인하였다.",다국어 초록 정보 없음
기계장비 진동 데이터를 이용한 딥러닝 기반의 고장 분류 모델,2022,"['Time Series', 'Deep Learning', 'Machine learning', 'Classification', 'Predictive Maintenance', '시계열 데이터', '딥러닝', '기계학습', '분류', '예지 보전']","최근 4차 산업 혁명으로 인해 공장에서는 기계 시설물의 고장으로 인한 제조 및 생산 시간 증가와 수리비용 증가를 최신 기술을 통해 예방하고자 한다. 그리하여 연구자들은 안전사고 및 고장을 예지(豫知)하고, 제품 불량 등으로 인한 시민 불편, 사회적 혼란 등의 문제를 방지하기 위해 노력하고 있다. 이런 문제 해결을 위해 장비에 부착된 센서로부터 받은 데이터를 통해 기계 상황을 모니터링 및 예측 가능한 시스템이 요구된다. 본 논문에서는 기계설비에서 생성되는 시계열 데이터를 다양한 딥러닝 기반의 시계열 분류 모델에서 비교분석을 수행하였다. 총 13개의 모델을 사용하여 어떤 딥러닝 모델이 학습에 효율적이고 성능이 좋은지 실험을 수행하였고, 시계열의 복잡한 패턴과 시간 및 공간 패턴을 효과적으로 학습하는 CNN 계열 모델이 정확도, 정밀도, 재현율, F1 성능지표에서 100% 성능을 달성하여 우수한 것을 확인할 수 있었다. 기존까지 진동 시계열 데이터에 대해 다양한 딥러닝 모델의 비교분석이 연구는 없었기에 본 논문의 결과를 통해 다른 기계 시설물의 고장 분류에 있어서 도움이 될 것이라 예상된다.","Due to the recent Fourth Industrial Revolution, factories want to prevent the increase in manufacturing and production time and repair costs due to the failure of mechanical facilities through the latest technology. Therefore, researchers are trying to predict safety accidents and failures, and to prevent problems such as civil inconvenience and social confusion caused by product defects. To solve this problem, a system that can monitor and predict the machine situation through data received from sensors attached to the equipment is required. In this paper, comparative analysis was performed on time series data generated in machine facilities in various deep learning-based time series classification models. A total of 13 models were used to experiment with which deep learning models were efficient and performing well, and the models that effectively learned time and space patterns of time series recorded 100% performance in accuracy, precision, reproducibility, and F1 performance indicators. Since there have been no studies on the comparative analysis of various deep learning models for vibration time series data until now, the results of this paper are expected to help in classifying failures in other mechanical facilities."
병렬 병합 구조를 이용한 기상 데이터의 예측률 향상을 위한 딥러닝 모델,2022,"['deep neural network', 'long short term memory', 'convolution neural network', 'ResNet', 'Inception', '.']","본 연구는 딥러닝 기본모델인 DNN, LSTM, BiLSTM, 1D-CNN 등으로, 예측의 성능을 향상하기 위해, 중간층을 병렬로 병합하는 구조를 제안하였다. 제안모델 1은 동일한 기본모델을 병렬 병합한 구조이고, 제안모델 2는 서로 다른 모델의 병렬 병합한 구조이다. 각 모델의 평가는 RMSE와 MAE로 10회 실험에 대한 평균값이다. 제안모델 1에서 가장 좋은 예측률을 보인 BiLSTM2의 RMSE는 0.064이다. 제안모델 2의 RMSE는 DC(DNN-CNN), LC(BiLSTM-CNN), DLC(DNN-BiLSTM-CNN) 등 모든 모델이 0.054였다. 이처럼 제안모델 2가 12.8%의 성능 향상을 보였다. 제안모델 2가 서로 다른 모델의 장점을 유지하면서 많은 파라메터로, 예측률을 향상할 수 있게 하는 모델임을 확인할 수 있었다.","In this study, using deep learning basic models DNN, LSTM, BiLSTM, and 1D-CNN, to improve prediction performance, we proposed a structure in which hidden layers are merged in parallel. Proposed model 1 is a parallel merging structure of the same basic model, and Proposed model 2 is a parallel merging structure of different models. The evaluation of each model is the average value for 10 experiments with RMSE and MAE. The RMSE of BiLSTM2, which showed the best prediction rate in Proposed Model 1, is 0.064. The RMSE of Proposed Model 2 was 0.054 for all models including DC (DNN-CNN), LC (BiLSTM-CNN), and DLC (DNN-BiLSTM-CNN). As such, Proposed Model 2 showed a performance improvement of 12.8%. It was confirmed that Proposed Model 2 is a model that can improve the prediction rate by using many parameters while maintaining the advantages of different models."
전동 이동 보조기기 주행 안전성 향상을 위한 AI기반 객체 인식 모델의 구현,2022,"['전동 이동보조 기기', '교통약자', '객체 인식', '딥러닝', '디텍트론2', 'Electric Mobility Aids', 'Transportation handicapped', 'Object Recognition', 'Deep learning', 'Detectron2']","본 연구에서는 전동 이동 보조기기를 이용하는 교통약자의 이동을 저해하거나 불편을 초래하는 횡단 보도, 측구, 맨홀, 점자블록, 부분 경사로, 임시안전 방호벽, 계단, 경사형 연석과 같은 주행 장애물 객체를 촬영한 뒤 객체를 분류하고 이를 자동 인식하는 최적의 AI 모델을 개발하여 주행 중인 전동 이동 보조기기의 전방에 나타난 장애물을 효율적으로 판단할 수 있는 알고리즘을 구현하고자 한다. 객체 검출을 높은 확률로 AI 학습이 될 수 있도록 데이터 셋 구축 시 라벨링 형태를 폴리곤 형태로 라벨링 하며, 폴리곤 형태로 라벨링 된 객체를 탐지할 수 있는 Detectron2 프레임워크를 활용하여 Mask R-CNN 모델을 활용하여 개발을 진행하였다. 영상 획득은 일반인과 교통약자의 두 개 그룹으로 구분하여 진행하였고 테스트베드 2개 지역에서 얻어진 영상정보를 확보하였다. Mask R-CNN 학습 결과 파라미터 설정은 IMAGES_PER _BATCH : 2, BASE_LEARNING_RATE 0.001, MAX_ITERATION : 10,000으로 학습한 모델이 68.532로 가장 높은 성능을 보인 것이 확인되어 주행 위험, 장애 요소를 빠르고 정확하게 사용자가 인지할 수 있도록 하는 딥러닝 모델을 구축이 가능한 것을 확인할 수 있었다.","In this study, we photograph driving obstacle objects such as crosswalks, side spheres, manholes, braille blocks, partial ramps, temporary safety barriers, stairs, and inclined curb that hinder or cause inconvenience to the movement of the vulnerable using electric mobility aids. We develop an optimal AI model that classifies photographed objects and automatically recognizes them, and implement an algorithm that can efficiently determine obstacles in front of electric mobility aids. In order to enable object detection to be AI learning with high probability, the labeling form is labeled as a polygon form when building a dataset. It was developed using a Mask R-CNN model in Detectron2 framework that can detect objects labeled in the form of polygons. Image acquisition was conducted by dividing it into two groups: the general public and the transportation weak, and image information obtained in two areas of the test bed was secured. As for the parameter setting of the Mask R-CNN learning result, it was confirmed that the model learned with IMAGES_PER_BATCH: 2, BASE_LEARNING_RATE 0.001, MAX_ITERATION: 10,000 showed the highest performance at 68.532, so that the user can quickly and accurately recognize driving risks and obstacles."
A YOLOv4 Model with FPN for Service Plates Detection,2022,"['Service plates detection', 'YOLOv4', 'FPN', 'Transfer learning']",국문 초록 정보 없음,"Intelligent service plates detection plays an important role in smart city. For example, intelligent service plates detection can realize more effi cient and accurate self-service charges for restaurants, and saves labor costs, additionally. This paper constructs a service plates detection dataset. On this basis, Faster R-CNN and MobilenetV3 are fi rstly leveraged to conduct service plates detection. In addition, authors propose an intelligent service plate detection method based on FPN (Feature Pyramid Network) + YOLOv4 network. Specifi cally, YOLOv4 is utilized to extract initial image features, and a variant of FPN network for YOLOv4 backbone is designed to aggregate multi-granularity image features. To boost the training effi ciency, transfer learning algorithm is also introduced into our approach. Through the corporation of FPN + YOLOv4 framework and transfer learning algorithm, they realize the accurate and fast intelligent service plate detection. The experimental results show that: compared with MobilenetV3 model and faster R-CNN, our method achieves great improvement. In the future, authors will improve the network to achieve higher accuracy and faster calculation speed, and expand our data set to more realistic scene images"
Dysarthric-Speech Detection Using Transfer Learning With Convolutional Neural Networks,2022,"['Dysarthria', 'Deep learning', 'Medical technology', 'Transfer learning', 'Machine learning']",국문 초록 정보 없음,"Speech Dysarthria is a disorder in which speech muscles become weak, and it becomes difficult to articulate otherwise linguistically normal speech. This work is based on detection of speech dysarthria and how it can assist physicians, specialists, and doctors in its detection. The proposed work achieves higher accuracies on the TORGO dataset by using a transfer learning based convolutional neural network model (TL-CNN) and by converting the audio samples to Mel-spectrograms. The proposed work TL-CNN achieved better accuracy when compared with other machine learning models."
딥러닝과 그래프 모델을 활용한 고해상도 영상의 건물 변화탐지,2022,"['Change Detection', 'High Spatial Resolution Images', 'Graph Model', 'Deep Learning', 'Instance Segmentation', '변화탐지', '고해상도 영상', '그래프 모델', '딥러닝', '인스턴스 분할227']","다시기 고해상도 영상에 존재하는 건물의 위치 및 형태학적 왜곡은 건물의 변화탐지를 어렵게 만드는 요인 중 하나이다. 이를 해결하기 위하여 부가적인 3차원 지형정보 및 딥러닝을 활용한 연구가 수행되고 있지만, 실제 사례에 적용되기 어려운 한계가 있다. 본 연구에서는 건물의 효율적인 변화탐지를 수행하기 위하여, 건물의 위치 정보뿐만 아니라 건물 간 위상정보를 활용하는 방안을 제시한다. 다양한 비연직 영상에서의 건물을 학습하기 위하여 SpaceNet v2 데이터셋을 사용하여 Mask R-CNN (Region-based Convolutional Neural Network)을 학습하였으며, 건물 객체를 탐지하여 중심점을 노드로 추출하였다. 추출한 건물 노드를 중심으로 서로 다른 두 시기에 대해 각각 TIN (Triangulated Irregular Network) 그래프들을 형성하고, 두 그래프 간 구조적 차이가 발생한 영역에 기반하여 변화 건물을 추출하기 위해 그래프 유사도와 노드의 위치 차이를 반영한 변화 지수를 제안하였다. 최종적으로 변화 지숫값을 기반으로 두 그래프 간 비교를 통해 새롭게 생성되거나 삭제된 건물을 탐지하였다. 총 3쌍의 테스트 영역에 대해 제안한 기법을 적용한 결과, 건물들 간 연결성의 변화를 고려함으로써 기복 변위에 의해 서로 다른 시기 간 동일 건물 쌍을 판단하기 어려운 경우에도 변화가 발생한 건물을 적절하게 탐지하는 것을 확인할 수 있었다.","The most critical factors for detecting changes in very high-resolution satellite images are building positional inconsistencies and relief displacements caused by satellite side-view. To resolve the above problems, additional processing using a digital elevation model and deep learning approach have been proposed. Unfortunately, these approaches are not sufficiently effective in solving these problems. This study proposed a change detection method that considers both positional and topology information of buildings. Mask R-CNN (Region-based Convolutional Neural Network) was trained on a SpaceNet building detection v2 dataset, and the central points of each building were extracted as building nodes. Then, triangulated irregular network graphs were created on building nodes from temporal images. To extract the area, where there is a structural difference between two graphs, a change index reflecting the similarity of the graphs and differences in the location of building nodes was proposed. Finally, newly changed or deleted buildings were detected by comparing the two graphs. Three pairs of test sites were selected to evaluate the proposed method’s effectiveness, and the results showed that changed buildings were detected in the case of side-view satellite images with building positional inconsistencies."
딥러닝 기반 알고리즘을 활용한 산불 객체 탐지,2022,"['딥러닝', '객체 검출', '분류', '욜로', '산림', '화재', 'Deep Learning', 'Object Detection', 'Classification', 'YOLO', 'Forest', 'Fire']","우리는 산불로 인한 피해로 직, 간접적인 피해를 받고 있는데 피해를 줄이기 위해서는 초기에 산불을 검출하는 것이 중요하다. 기존 산불 검출 방법으로는 촬영 이미지를 영상처리 기술을 통해 감지하거나 센서를 일정 구간별로 설치하여 모니터링하는 방법을 사용했다. 본 논문은 유지비용이 많이 들어가는 기존 방법을 개선하기 위해 객체 탐지 인공지능 기술, YOLO를 사용하여 객체 검출을 하고 인공지능 모델을 통해 나온 검출 결과를 제공하는 시스템 구현을 진행한다. 연구 결과 주요 성능지표인 mAP가 Proposed LFire 0.959, YOLOv5 0.931, YOLOv4 0.943, R-CNN 0.879가 나왔다. 본 논문에서 제안하는 모델인 Proposed LFire가 가장 높은 것을 통해 산불 검출 데이터에 적합한 객체 검출모델로 볼 수 있다. 향후 보편적으로 사용할 수 있는 RGB 채널 산림 이미지 특징에 맞는 이미지 전처리 및 모델 학습을 통해 검출 성능을 높이는 방향으로 연구할 계획이다.","We are suffering direct and indirect damage from forest fires, and it is essential to detect them early to reduce the damage. Existing forest fire detection methods used a method of detecting photographed images through image processing technology or installing sensors at certain intervals to monitor them. To improve the existing process that is expensive to maintain, this paper conducts object detection using object detection artificial intelligence technology, YOLO. It implements a system that provides detection results from artificial intelligence models. As a result of the study, the main performance indicators, mAP, were Proposed LFire 0.959, YOLOv5 0.931, YOLOv4 0.943, and R-CNN 0.879. The proposed model in this paper, Proposed LFire, is the highest, which can be seen as an object detection model suitable for forest fire detection data. In the future, we plan to study in the direction of increasing detection performance through image preprocessing and model learning suitable for RGB channel forest image features that can be used universally."
무인항공기 초분광 이미지 기반 배추 노균병 조기진단을 위한 딥러닝 모델 개발,2022,"['Downy midlew', 'Diagnosis', 'UAV', 'Hyperspectral', 'Deep learning']",국문 초록 정보 없음,"Downy mildew is one of the most common plant diseases in Korea that could easily infect plants such as cabbage, cucumber, and garlic. Particularly on Chinese cabbage, the disease is identified by yellow-tan spots on the upper leaf surface, causing infected leaves to drop off and eventually plant death. An early diagnosis of the disease with minimum physical damage to the plant could highly reduce crop losses. Hyperspectral imaging as one of the non-destructive evaluation methods has recently become more popular due to its capability to capture a wide spectral range. The combination of a UAV and hyperspectral imaging system offers abundant data resources that could provide adequate information for early diagnosis of downy mildew infection on the Chinese cabbage farm fields. Based on hyperspectral image data, the diagnosis system employs a deep learning algorithm that computes complex relations and finds a pattern in the data to detect the disease and its location. Similar algorithms such as R-CNN, Faster R-CNN, and YOLO have been implemented in many fields of study and are able to deliver results with good accuracy and robustness."
봇 프레임워크를 활용한 챗봇 구현 방안,2022,"['Chatbot', 'NLP', 'BotFrame', 'RNN', 'Cloud']","본 논문에서 챗봇에서 사용하는 AI알고리즘과 자연어처리 방법을 분류하고 제시하고 챗봇 구현에 사용할 수 있는 프레임워크에 대해서도 기술한다. 챗봇은 사용자 인터페이스를 대화방식으로 구성하여 입력된 문자열을 해석하고 입력된 문자열에 적절한 답을 학습된 데이터에서 선택하여 출력하는 구조의 시스템이다. 최근 콜센터와 주문 업무에 적용하여 인건비를 감소하고 정확한 업무를 할 수 있는 장점이 있다. 하지만 질문에 대한 적정한 답변 집합을 생성하기 위해 학습이 필요하며 이를 위해 상당한 계산 기능을 갖는 하드웨어가 필요하다. 개발을 하는 업체는 물론 AI분야 개발을 학습하는 학생들의 실습은 한계가 있다. 현재 챗봇은 기존의 전통적인 업무를 대체하고 있으며 시스템을 이해하고 구현하는 실습과정이 필요한 실정이다. 정형화되어 있는 데이터에 대해서만 응답을 하는 수준을 넘어 딥러닝 등의 기술을 적용하여 비정형 데이터를 학습시켜 질문에 대한 응답의 정확성을 높이기 위해 RNN과 Char-CNN 등을 사용해야한다. 챗봇을 구현하기 위해서는 이와 같은 이론을 이해하고 있어야한다. 본 논문에서는 단기간에 챗봇 코딩교육에 활용할 수 있는 방안과 기존 개발자, 학생들이 챗봇 구현을 할 수 있는 플랫폼을 활용하여 학생들이 전체시스템을 구현 예를 제시하였다.","In this paper, we classify and present AI algorithms and natural language processing methods used in chatbots. A framework that can be used to implement a chatbot is also described. A chatbot is a system with a structure that interprets the input string by constructing the user interface in a conversational manner and selects an appropriate answer to the input string from the learned data and outputs it. However, training is required to generate an appropriate set of answers to a question and hardware with considerable computational power is required. Therefore, there is a limit to the practice of not only developing companies but also students learning AI development. Currently, chatbots are replacing the existing traditional tasks, and a practice course to understand and implement the system is required. RNN and Char-CNN are used to increase the accuracy of answering questions by learning unstructured data by applying technologies such as deep learning beyond the level of responding only to standardized data. In order to implement a chatbot, it is necessary to understand such a theory. In addition, the students presented examples of implementation of the entire system by utilizing the methods that can be used for coding education and the platform where existing developers and students can implement chatbots."
다중 특징 융합 기반 3차원 객체 검출 알고리즘,2022,"['F-포인트넷', '포인트CNN', '포인트 클라우드', '객체 검출', '특징 용합', 'F-PointNets', 'PointCNN', 'Point cloud', 'Object detection', 'Feature fusion']",국문 초록 정보 없음,"3D shape feature learning plays an important role in both industry and academia. Recently, feature understanding tasks such as object detection and object segmentation have been greatly developed. PointCNN is one of the excellent neural networks used for 3D object database classification. We designed a point cloud target detection algorithm based on the hybrid architecture of F-PointNet and PointCNN. First, the two-dimensional target detection model of the image is used to extract the two-dimensional area of the target and map it to the point cloud data to obtain the candidate area of the target. Then the 3D target mask of the candidate area is predicted by the PointCNN algorithm. Finally, the mask is used to detect the 3D target. We conducted experiments to prove that the mask extracted by PointCNN is easier to recognize 3D objects than the original F-PointNet."
스마트 패션산업 발전을 위한 딥러닝 기반의 의류 이미지 분류 연구,2022,[],프로젝트 테마는 ‘CNN 딥러닝 모델을 기반으로 한 AI 가상 옷장’이다. 딥러닝 기술을 웹페이지에 적용시켜 사용자의 옷장 속에 있는 옷들을 자동으로 저장해서 관리해준다. 의류 이미지를 수집하고 딥러닝 모델을 통해 이미지를 학습시키고 분류하여 저장함으로써 사람들이 옷을 쉽게 찾을 수 있는 방법을 고안한다.,다국어 초록 정보 없음
각도 마진 손실 함수를 적용한 객체 분류,2022,[],"객체 분류는 입력으로 주어진 이미지에 포함된 객체의 종류를 판단하는 기술이다. 대표적인 딥러닝 기반의 객체 분류 방법으로서 Faster R-CNN[2], YOLO[3] 등의 모델이 개발되었으나, 여전히 성능 향상의 여지가 있다. 본 연구에서는 각도 마진 손실 함수를 기존의 몇 가지 객채 분류 모델에 적용하여 성능 향상을 유도한다. 각도 마진 손실 함수는 얼굴 인식 모델인 SphereFace[4]에서 제안한 방법으로, 얼굴 인식과 같이 단일 도메인의 데이터셋을 분류하는 문제를 풀기 위해 제안되었다. 이는 기존 소프트맥스 함수에서 클래스 결정 경계선에 마진을 주는 방식으로 클래스 간의 구분 능력을 향상시킨다. 본 논문은 각도 마진 손실함수를 CIFAR10, CIFAR100 데이터셋의 분류 문제에 적용하였으며 ResNet, EfficientNet, MobileNet 등의 백본 네트워크로 실험하여 평균적으로 mAP 성능이 향상되는 것을 확인하였다.",다국어 초록 정보 없음
Hybrid FRP 앵커의 초기 균열 탐색평가,2022,"['crack', 'FRP', 'anchor', 'hybrid', 'deep learning', '균열', 'FRP', '앵커', 'Hybrid', '딥러닝']",본 연구는 기계식 앵커와 FRP를 새로운 시스템으로 복합하여 새로운 메커니즘의 Hybrid 앵커모델의 파괴형태중 균열을 영상기반으로 프로세싱하여 균열탐지하는 메카니즘을 제시하였다. 기존의 cascade mask R-CNN 방식보다 탐지율과 효율성이 우수한 Dense-UNet 기법을 활용하여 균열탐사기법에 활용하였다. 기존의 균열 뿐 아니라 앵커주위의 Round crack도 함께 탐사되어 앵커 설치후 초기 균열 탐사에 효율성을 크게 가질 수 있다고 판단된다. 따라서 향후연구에서는 이미지 프로세싱 타임을 줄이면서 정확도를 높일수 있는 Post-Processing이 보완된다면 균열탐사 및 오탐을 줄이는데 크게 효과적일 것으로 사료된다.또한 피사체와 카메라와의 거리를 계산하여 알고리즘에 고려한다면 구조적 균열기준인 0.3 mm의 균열 탐사에도 활용할 수 있는 효과적인 기법이라 판단된다.,다국어 초록 정보 없음
딥 러닝 시각 지능과 경로 탐색을 통한 사람형 로봇손의 목표 물체 파지 시스템,2022,[],"다중 물체 환경에서 사람형 로봇손이 목표 물체를 파지하기 위해서는 목표 물체 인식, 충돌 없는 경로 설정, 사람형 로봇손의 물체 파지 지능이 필요하다. 본 논문에서는 딥 러닝 Mask R-CNN 을 통해 물체를 검출하고 3D 정보를 인식한 후, RRT-Connect 경로 탐색 알고리즘으로 충돌 회피 경로를 파악하고, 최종적으로 사람형 로봇손이 다중 물체 속에서 목표 물체를 파지하고 이동하는 하드웨어 시스템을 구현한다.",다국어 초록 정보 없음
선분 분할 탐지를 활용한 마스크 된 이미지 내의 물체 6자유도 자세 추정,2022,"['3-D object pose estimation', 'Line segment detection', 'Object contour detection', 'Bin picking', 'Robot vision', '.']",국문 초록 정보 없음,.
분할된 휴대 수하물 데이터셋에 대한 다중 Pipeline과 결합한 다중 Student-Teacher 프레임워크의 효과에 관한 연구,2022,[],국문 초록 정보 없음,"In this paper, we investigate the student-teacher framework involving multiple mean teachers coupled with the multiple pipelines on the partitioned SIXRay-10 dataset. Firstly, SIXRay-10 dataset is partitioned and the multiple pipelines are applied with ResNet-50 backbone and Faster R-CNN detector to get the enhanced detection accuracy of 80.6 mAP0.5. Secondly, for each pipeline, a mean teacher model is defined as an exponential moving average of the student model parameters and the pipelines are dynamically aligned according to its bounding box regression loss to get 82.1 mAP0.5."
Fundamental Function Design of Real-Time Unmanned Monitoring System Applying YOLOv5s on NVIDIA TX2<sup>TM</sup> AI Edge Computing Platform,2022,"['AI', 'Object Detection', 'NMS', 'YOLOv5s']",국문 초록 정보 없음,"In this paper, for the purpose of designing an real-time unmanned monitoring system, the YOLOv5s (small) object detection model was applied on the NVIDIA TX2<sup>TM</sup> AI (Artificial Intelligence) edge computing platform in order to design the fundamental function of an unmanned monitoring system that can detect objects in real time. YOLOv5s was applied to the our real-time unmanned monitoring system based on the performance evaluation of object detection algorithms (for example, R-CNN, SSD, RetinaNet, and YOLOv5). In addition, the performance of the four YOLOv5 models (small, medium, large, and xlarge) was compared and evaluated. Furthermore, based on these results, the YOLOv5s model suitable for the design purpose of this paper was ported to the NVIDIA TX2<sup>TM</sup> AI edge computing system and it was confirmed that it operates normally. The real-time unmanned monitoring system designed as a result of the research can be applied to various application fields such as an security or monitoring system. Future research is to apply NMS (Non-Maximum Suppression) modification, model reconstruction, and parallel processing programming techniques using CUDA (Compute Unified Device Architecture) for the improvement of object detection speed and performance."
스마트 자율배송을 위한 클래스 분류와 객체별 학습데이터 유형,2022,"['딥러닝', '주행 환경 인식', 'AI 학습용 데이터', '객체인식', '자율주행', 'Deep Learning', 'Perception', 'AI training data', 'Object Detection', 'Autonomous Driving']","자율배송 운행 데이터는 코로나 시대의 라스트마일 배송에 대한 패러다임 변화를 주도하는 핵심이다. 국내자율배송로봇과 해외 기술선도국가 간의 기술격차 해소를 위해서는 인공지능 학습에 사용 가능한 대규모 데이터 수집과 검증이 최우선으로 요구된다. 따라서 해외 기술선도국가에서는 인공지능 학습데이터를 누구든사용가능한 공공데이터 형태로 오픈하여 검증과 기술발전에 기여하고 있다. 본 논문은 자율배송로봇 학습을 목적으로 326개의 객체를 수집하고 Mask r-cnn, Yolo v3 등의 인공지능 모델을 학습하고 검증하였다.추가적으로 두 모델을 기반으로 비교하고 향후 자율배송로봇 연구에 요구되는 요소를 고찰하였다.",다국어 초록 정보 없음
Fundamental Function Design of Real-Time Unmanned Monitoring System Applying YOLOv5s on NVIDIA TX2TM AI Edge Computing Platform,2022,"['AI', 'Object Detection', 'NMS', 'YOLOv5s']",국문 초록 정보 없음,"In this paper, for the purpose of designing an real-time unmanned monitoring system, the YOLOv5s (small) object detection model was applied on the NVIDIA TX2TM AI (Artificial Intelligence) edge computing platform in order to design the fundamental function of an unmanned monitoring system that can detect objects in real time. YOLOv5s was applied to the our real-time unmanned monitoring system based on the performance evaluation of object detection algorithms (for example, R-CNN, SSD, RetinaNet, and YOLOv5). In addition, the performance of the four YOLOv5 models (small, medium, large, and xlarge) was compared and evaluated.Furthermore, based on these results, the YOLOv5s model suitable for the design purpose of this paper was ported to the NVIDIA TX2TM AI edge computing system and it was confirmed that it operates normally. The real-time unmanned monitoring system designed as a result of the research can be applied to various application fields such as an security or monitoring system. Future research is to apply NMS (Non-Maximum Suppression) modification, model reconstruction, and parallel processing programming techniques using CUDA (Compute Unified Device Architecture) for the improvement of object detection speed and performance."
객체 검출을 활용한 교육적 목적의 웹 기반 브레드보드 전기회로 분석,2022,"['전기전자 실험', '서비스', '브레드보드', '위치 검출', '위치 예측', 'Electrical and electronic testing', 'Service', 'Breadboard', 'Position detection', 'Position prediction']",국문 초록 정보 없음,"In an experiment where students learn electrical and electronic theory and apply it, students have difficulty in connecting circuits. To alleviate the above difficulties, we first propose a circuit analysis service. The proposed method detects an electric device using an object detection model in which electric devices connected to a breadboard are labeled with data. To verify this, we connect to the breadboard circuit and create a custom dataset through photographs. The proposed method is divided into two processes: electric device prediction and electric device position detection. The electric device prediction model was compared using five object detection models, and the Faster R-CNN model had the best prediction performance. The electrical device position detector extracts features from the object detection model through transition learning to predict two coordinates (x1, y1), (x2, y2). A comparison of each model confirmed that the ResNet model has good location detection performance. Through this, it was confirmed that the proposed method alleviates the difficulty of first-time students learning electric and electronic experiments."
Development of FPGA-based deep learning orthosis actuating system using bio signal data,2022,"['EEG', 'EMG', 'Rehabilitation Device', 'HCI', '3D-printing']",국문 초록 정보 없음,"Recently, many health care applications for rehabilitation are used to developed with various technologies for treatment and assistance. And these technologies are mainly applied to purpose with improve the essential activities for human life. In this study, we develop the 3D-printed hand orthosis for patients who has low motor function from the spinal cord injury (SCI) or stroke, and build the hand motion actuating system with Field-Programmable Gate Array (FPGA) using Electroencephalogram (EEG) and Electromyogram (EMG). Our system applied the custom 2D-CNN deep learning algorithm for the higher motion accuracy, real-time motion actuating. And we conducted experiment to investigate the characteristics of each seven gesture in EEG and EMG with seven healthy subjects. In experiment, subject do the gesture as same as showing in screen, then the system acquired the bio signals and analysis in same time. In further, to evaluate the system, we’ll verifying the motor function improvement through experiment to actual patients with orthosis. And also compare the performance with other on-chip programmable device."
RoI 추출 방법에 따른 기계를 위한 영상 압축 성능 비교,2022,[],"기존 RDO(Rate Distortion Optimization) 기반 압축 방식은 압축 성능에 초점을 두기 때문에 영상 내 인지 특성이 무시될 수 있다. 따라서 RoI(Region of Interest)을 기반으로 압축률을 조절하는 연구가 고안[1, 2, 3, 4] 되었으며, HVS(Human Visual System) 관점에서 영상 내 중요한 부분에 대해 더 높은 품질로 영상을 압축하는 연구가 대부분이다. 최근 인공지능 기술이 발전함에 따라 지능형 영상 분석에 대한 수요가 증가하고 있으며, 이에 따라 머신 비전을 위한 영상 부호화 및 효율적인 전송에 대한 필요성이 대두되고 있다. 본 논문에서는 VVC(Versatile Video Coding)의 dQP(delta Quantization Parameter)를 활용하여 RoI(Region of Interest) 기반 압축 방법을 제안하고, 두가지의 RoI 추출 방식을 소개한다. Detectron2 Faster R-CNN X101-FPN [5]의 첫번째 탐지기를 통해 후보 영역 기반 RoI 을 추출하고, 두번째 탐지기를 통해 객체 기반 RoI 을 추출하여, 영상 내 객체 부분과 비객체 부분으로 나누어 서로 다른 압축률로 압축을 수행하였으며, 이에 따른 성능을 비교하고자 한다.",다국어 초록 정보 없음
초분광 영상과 머신러닝을 이용한 소고기 미생물 오염도 판정기술 개발,2022,"['초분광', '근적외선', '기계학습', '소고기', '미생물']","근적외선 초분광 데이터 획득 장치를 이용하여 비파괴 방식으로 소고기의 미생물 오염도를 예측하는 모델을 개발하였다. 실험 대상인 국내산 육우 시료를 15일에 걸쳐 다양한 온도 조건에 놓이게 하여 신선도 변화 및 미생물 생장을 유도하였다. 암실 환경의 데이터 획득 장치에서 초분광 데이터 큐브를 획득하였고 전통적 방법으로 total aerobic bacteria(TAB) 실험을 수행하여 소고기의 미생물 오염도에 대한 기준값을 확보하였다. 데이터 정제를 통해 스펙트럼을 추출하였고 80%의 training set와 20%의 test set로 분리하였다. 입력 변수를 선택 사용하여 차원을 축소하는 기준으로 VIP(variable importance in projection) score 개념을 도입하여 상대적으로 중요성이 낮은 데이터를 제거하고 예측 성능 변화를 확인하였다. 모델 개발에는 PLSR, SVR, ANN, 1D-CNN 기법을 적용하였다. 예측 모델 개발 결과 스펙트럼 데이터에 의한 미생물 오염도 데이터 학습이 잘 이루어지는 것을 확인할 수 있었다. 차원 축소 데이터를 사용하면 약간의 성능 하락이 발생하였으나 모델 개발의 연산량 감소 등의 이득을 감안하면 충분히 고려할 수 있는 차이이다. 개발한 모델에 대해 화학지도를 작성하여 모델의 성능을 다시 검증하고 각 실험군별 시료의 성질 차이를 파악하였다. 마지막으로 이러한 실험 과정을 재차 반복하여, 검증에 필요한 verification set 데이터를 만들고 개발된 모든 모델에 적용하여 해당 모델의 범용성을 평가하였다.",다국어 초록 정보 없음
Location Recognition of Indoor Firefighting Facilities based on RGB -D C amera and 3D L iDAR,2022,"['Spatial data', 'Object recognition', '3D LiDAR SLAM']",국문 초록 정보 없음,"Recently, as fires frequently occur in large buildings, digital twin (DT) technology that enables remote and real-time monitoring and control similar to the real world environment is being studied as a disaster response technology in buildings. In order to use DT technology, it is essential to collect the spatial data of actual building indoor environments and firefighting facilities. This study proposes an indoor spatial data collecting system that can generate the modeling data inside the building and location data of firefighting facilities using laser imaging detection and ranging (LiDAR) and RGB-D cameras. First, point clouds from three-dimensional (3D) LiDAR and the FAST-LIO2 (Fast LiDAR-Inertial Odometry) algorithm are used to obtain odometry information in an indoor environment. The firefighting facilities located inside the building are detected using RGB images and the deep learning model Faster region-based convolutional neural network (R-CNN) with Inception V2 architecture trained using RGB images of four types of firefighting facilities: fire extinguishers, fire hydrants, exit signs, and fire detectors. When a firefighting facility is detected, the relative distance between the RGB-D camera and the firefighting facility is calculated through the depth image and intrinsic parameters of the RGB-D camera. Afterwards, odometry information obtained from FAST-LIO2 and the relative distance are combined to obtain the 3D location of the firefighting facility. Point clouds of the FAST-LIO2 algorithm are then converted into models of the building indoor environment. Through this method, spatial data of an actual building can be constructed and used with DT technology."
A Lightweight Pedestrian Intrusion Detection and Warning Method for Intelligent Traffic Security,2022,"['Traffic safety', 'pedestrian detection', 'computer vision', 'YOLOv5', 'lightweight']",국문 초록 정보 없음,"As a research hotspot, pedestrian detection has a wide range of applications in the field of computer vision in recent years. However, current pedestrian detection methods have problems such as insufficient detection accuracy and large models that are not suitable for large-scale deployment. In view of these problems mentioned above, a lightweight pedestrian detection and early warning method using a new model called you only look once (Yolov5) is proposed in this paper, which utilizing advantages of Yolov5s model to achieve accurate and fast pedestrian recognition. In addition, this paper also optimizes the loss function of the batch normalization (BN) layer. After sparsification, pruning and fine-tuning, got a lot of optimization, the size of the model on the edge of the computing power is lower equipment can be deployed. Finally, from the experimental data presented in this paper, under the training of the road pedestrian dataset that we collected and processed independently, the Yolov5s model has certain advantages in terms of precision and other indicators compared with traditional single shot multiBox detector (SSD) model and fast region-convolutional neural network (Fast R-CNN) model.After pruning and lightweight, the size of training model is greatly reduced without a significant reduction in accuracy, and the final precision reaches 87%, while the model size is reduced to 7,723 KB."
Classification of Livestock Diseases Using GLCM and Artificial Neural Networks,2022,"['Machine Learning', 'Convolutional Neural Network', 'Gray Level Co- occurrence Matrix', 'Classification', 'Calf Health']",국문 초록 정보 없음,"In the naked eye observation, the health of livestock can be controlled by the range of activity, temperature, pulse, cough, snot, eye excrement, ears and feces. In order to confirm the health of livestock, this paper uses calf face image data to classify the health status by image shape, color and texture. A series of images that have been processed in advance and can judge the health status of calves were used in the study, including 177 images of normal calves and 130 images of abnormal calves. We used GLCM calculation and Convolutional Neural Networks to extract 6 texture attributes of GLCM from the dataset containing the health status of calves by detecting the image of calves and learning the composite image of Convolutional Neural Networks. In the research, the classification ability of GLCM-CNN shows a classification rate of 91.3%, and the subsequent research will be further applied to the texture attributes of GLCM. It is hoped that this study can help us master the health status of livestock that cannot be observed by the naked eye."
다차원 영상을 활용한 매개모기 자동탐지 장치 개발,2022,"['매개모기', '인공지능', '딥러닝', '다차원 이미지 영상분석', '합성곱 알고리즘']","세계보건기구(WHO)에 의하면 말라리아, 일본 뇌염 그리고 뎅기 바이러스 등 모기 매개 감염병으로 인해 매년 70만명 이상이 사망한다. 최근 이상기온 및 기상이변으로 모기 개체수가 증가하여 감염병에 대한 노출이 심화되는 추세이다. 그러나 말라리아 이외의 모기 매개 감염병은 치료제가 개발되어 있지 않으므로 사전 방역 및 방제를 통한 매개모기 감염병에 대한 노출을 최소화하는 것이 중요하다. 효과적인 매개모기 감염병 확대 방지를 위해서는 감염병을 매개하는 모기 종류에 대한 개체수 모니터링이 필수적이다. 하지만 현재 모기 포집 장치는 종이 아닌 개체수만 측정이 가능하여 종별 감염병에 대해 효과적인 방제 체계에 기여를 하지 못하고 있다. 따라서, 본 연구에서는 딥러닝 영상분석기술을 활용하여 국내 주요 매개 모기 5종에 대해 종 동정 및 개체수 파악이 가능한 매개 모기 자동 탐지 장치를 개발하였다. 모기 자동 탐지 장치는 전기 충격 방식과 배경판 슬라이딩 방식으로 포집된 모기의 컬러 및 형광 영상을 선명하게 촬영할 수 있도록 개발되었다. 실제 모기 포집 현장에서의 조건과 동일한 영상 데이터를 확보하기 위해 살아있는 1３종의 야생 모기로 컬러 및 형광 이미지 데이터 셋을 구축하여 모기의 색, 형태 및 형광 특징을 분석에 활용할 수 있도록 하였다. 딥러닝 영상분석 알고리즘으로는 최신 BackBone인 Swin transformer와 딥러닝 객체 탐지 모델의 detector인 Faster R-CNN(Region-Convolutional Neural Network)을 결합하여 최종 탐지 모델을 구축하였다. 모델 성능 향상을 위해 컬러 및 형광 이미지의 예측 결과를 통합 후, NMS(Non-maximum suppression) 기법을 적용하였다. 외부 환경에 설치된 장치에 야생 모기를 투입하여 Blind test를 실시한 결과, 평균 91.7%의 분류 정확도를 확인할 수 있었다. 본 연구에서 개발된 딥러닝 객체 탐지 기술을 활용한 모기 포집 장치는 실외 현장에서 모기 종류 및 개체수 모니터링에 활용될 수 있을 것으로 사료된다.",다국어 초록 정보 없음
Real-time Fruit Cluster Spatial Coordinates Extraction and Instance Segmentation using a RGB depth camera,2022,"['Depth camera', 'Instance segmentation', 'Fruit cluster', 'Fruit thinning', 'Spatial coordinates extraction']",국문 초록 정보 없음,"Preserving a phenotypic optimal fruit and thining other fruits are the key process of fruit production. The real-time detection of phenotypic optimal fruit can provide a new management strategy and technical support for orchard managers. Since manual screening is very inconvenient, effective screening is a key link to reduce costs and increase production efficiency. Therefore, the goal of this study was to develop a new fruit cluster detection technology to support robot fruit thinning. This research work brought several contributions. The ground truth data was converted into the Creating Common Object in Context (COCO) annotation format. The model using the backbone structure ReSNet-101-FPN was trained. The spatial location of fruit clusters was extracted using a depth camera. The results showed that Detectron2's Mask R-CNN with a ReSNet-101-FPN backbone was determined to be the optimal model. A method combining instance segmentation with distance calculation of a target objects was proposed. It could accurately screen out single optimal fruit from fruit clusters and could also be used for segmentation and analysis of other types of fruit clusters．"
Recognition and detection of pig posture based on instance segmentation and computer vision in pig farm,2022,"['Computer vision', 'smart farming', 'pig posture', 'instance segmentation', 'pig identification']",국문 초록 정보 없음,"Pig posture changes throughout the growing period are most often indicators to illness. Monitoring pigs postural movements enables us to identify morphological changes in pigs early and to detect potential risk factors for pig health. Large-scale pig farming requires extensive manual monitoring by pig farmers, which is time-consuming and laborious. Computer vision-based monitoring of posture activities over time may help to limit the spread of disease infections. The objective of this study was to recognize and detect pig posture using an masked based instance segmentation in the pig farm. Two automatic video acquisition systems were installed from top and side view, respectively. RGB images were extracted from the RGB video files and used for annotation work. Manual annotation of 200 images were prepared as training dataset, including the three postures: standing, lying, and eating from bin. An instance segmentation framework was employed to recognize and detect pig posture. A region proposal network is used in the first stage of the masked R-CNN based instance segmentation procedure. It obtains features from candidate boxes using RoIPool and conducts classification and bounding-box regression in the second step. Proposed method was evaluated using test image dataset and the experimental results showed the proposed framework obtained a F1 score of 0.911. Our work investigated a new way for recognizing and detecting pig posture in pig farm, which enables useful research into vision-based, real-time automated pig monitoring and diseases assessment."
다차원 영상을 활용한 매개모기 자동탐지 장치 개발,2022,"['매개모기', '인공지능', '딥러닝', '다차원 이미지 영상분석', '합성곱 알고리즘']","세계보건기구(WHO)에 의하면 말라리아, 일본 뇌염 그리고 뎅기 바이러스 등 모기 매개 감염병으로 인해 매년 70만명 이상이 사망한다. 최근 이상기온 및 기상이변으로 모기 개체수가 증가하여 감염병에 대한 노출이 심화되는 추세이다. 그러나 말라리아 이외의 모기 매개 감염병은 치료제가 개발되어 있지 않으므로 사전 방역 및 방제를 통한 매개모기 감염병에 대한 노출을 최소화하는 것이 중요하다. 효과적인 매개모기 감염병 확대 방지를 위해서는 감염병을 매개하는 모기 종류에 대한 개체수 모니터링이 필수적이다. 하지만 현재 모기 포집 장치는 종이 아닌 개체수만 측정이 가능하여 종별 감염병에 대해 효과적인 방제 체계에 기여를 하지 못하고 있다. 따라서, 본 연구에서는 딥러닝 영상분석기술을 활용하여 국내 주요 매개 모기 5종에 대해 종 동정 및 개체수 파악이 가능한 매개 모기 자동 탐지 장치를 개발하였다. 모기 자동 탐지 장치는 전기 충격 방식과 배경판 슬라이딩 방식으로 포집된 모기의 컬러 및 형광 영상을 선명하게 촬영할 수 있도록 개발되었다. 실제 모기 포집 현장에서의 조건과 동일한 영상 데이터를 확보하기 위해 살아있는 1３종의 야생 모기로 컬러 및 형광 이미지 데이터 셋을 구축하여 모기의 색, 형태 및 형광 특징을 분석에 활용할 수 있도록 하였다. 딥러닝 영상분석 알고리즘으로는 최신 BackBone인 Swin transformer와 딥러닝 객체 탐지 모델의 detector인 Faster R-CNN(Region-Convolutional Neural Network)을 결합하여 최종 탐지 모델을 구축하였다. 모델 성능 향상을 위해 컬러 및 형광 이미지의 예측 결과를 통합 후, NMS(Non-maximum suppression) 기법을 적용하였다. 외부 환경에 설치된 장치에 야생 모기를 투입하여 Blind test를 실시한 결과, 평균 91.7%의 분류 정확도를 확인할 수 있었다. 본 연구에서 개발된 딥러닝 객체 탐지 기술을 활용한 모기 포집 장치는 실외 현장에서 모기 종류 및 개체수 모니터링에 활용될 수 있을 것으로 사료된다.",다국어 초록 정보 없음
설명 가능한 합성곱 신경망을 활용한 센서 기반의 시계열 데이터 분류 모델 제안,2022,"['Sensor Data', 'Time Series Classification', 'Pattern Recognition', 'Deep Learning', 'eXplainable Artificial Intelligence(XAI)', '센서 데이터', '시계열 데이터 분류', '패턴 인식', '딥러닝', '설명가능한 인공지능']","센서 데이터를 활용하여 설비의 이상 진단이 가능해졌다. 하지만 설비 이상에 대한 원인 분석은 미비한 실정이다. 본 연구에서는 센서 기반 시계열 데이터 분류 모델을 위한 해석가능한 합성곱 신경망 프레임워크를 제안한다. 연구에서 사용된 센서 기반 시계열 데이터는 실제 차량에 부착된 센서를 통해 수집되었고, 반도체의 웨이퍼 데이터는 공정 과정에서 수집되었다. 추가로 실제 기계 설비에서 수집된 주기 신호 데이터를 이용 하였으며, 충분한 학습을 위해 Data augmentation 방법론인 Scaling과 Jittering을 적용하였다. 또한, 본 연구에서는 3가지 합성곱 신경망 기반 모델들을 제안하고 각각의 성능을 비교하였다. 본 연구에서는 ResNet에 Jittering을 적용한 결과 정확도 95%, F1 점수 95%로 가장 뛰어난 성능을 보였으며, 기존 연구 대비 3%의 성능 향상을 보였다. 더 나아가 결과의 해석을 위한 XAI 방법론으로 Class Activation Map과 Layer Visualization을 제안하였으며, 센서 데이터 분류에 중요 영향을 끼치는 시계열 구간을 시각적으로 확인하였다.","Sensor data can provide fault diagnosis for equipment. However, the cause analysis for fault results of equipment is not often provided. In this study, we propose an explainable convolutional neural network framework for the sensor-based time series classification model. We used sensor-based time series dataset, acquired from vehicles equipped with sensors, and the Wafer dataset, acquired from manufacturing process. Moreover, we used Cycle Signal dataset, acquired from real world mechanical equipment, and for Data augmentation methods, scaling and jittering were used to train our deep learning models. In addition, our proposed classification models are convolutional neural network based models, FCN, 1D-CNN, and ResNet, to compare evaluations for each model. Our experimental results show that the ResNet provides promising results in the context of time series classification with accuracy and F1 Score reaching 95%, improved by 3% compared to the previous study. Furthermore, we propose XAI methods, Class Activation Map and Layer Visualization, to interpret the experiment result. XAI methods can visualize the time series interval that shows important factors for sensor data classification."
