title,date,keywords,abstract,multilingual_abstract
재구성 가능한 모듈 기반 CNN 가속기 구현,2022,"['CNN accelerator', 'module-based architecture', 'FPGA', 'Verilog-HDL', '.']","본 논문에서는 CNN(Convolutional Neural Network)을 구성하는 주요 연산 모듈을 모듈 제어 명령어를 통해 구동함으로써 네트워크를 구현할 수 있는 CNN 가속기를 제안한다. 모듈 기반 CNN 가속기는 합성곱(Convolution), 풀링(Pooling) 등 CNN의 주요 연산 모듈로 구성되어 있으며, 프로세서에서 모듈 제어 명령어를 통해 네트워크 구성에 필요한 연산 모듈을 선택 및 내부 파라미터를 설정 할 수 있다. 본 논문에서 제안하는 모듈 기반 CNN 가속기를 사용하여 Xilinx SoC형 FPGA에 ResNet-18을 구현하였으며 CNN 프레임워크 모델인 PyTorch와 C 기반 검증 모델을 사용하여 출력 결과를 비교 검증하였다. 실험결과, CNN 가속기의 추론 결과는 92.87%의 정확도를 보였다.","In this paper, we propose a CNN(convolution neural network) accelerator that can implement a network by driving main computation modules constituting the CNN through module control commands. The module-based CNN accelerator consists of CNN's main computation modules such as convolution and pooling, and the processor can select the computation module required for network configuration and set internal parameters through module control commands. In this paper, ResNet-18 was implemented on a Xilinx SoC-type FPGA using the proposed module-based CNN accelerator, and the output results were compared and verified using PyTorch, a CNN framework model, and a C-based verification model. As a result of the experiment, the inference result of the CNN accelerator showed an accuracy of 92.87%."
CNN 기반 딥러닝을 이용한 베어링 고장 진단의 정확도 및 계산 복잡도 분석,2022,"['Fault Diagnosis', 'Fault Detection', 'Bearing', 'Deep Learning', 'Complexity', '고장 진단', '고장 검출', '베어링', '딥러닝', '복잡도']","산업 현장에서 사용되는 기계 설비 고장의 상당 부분을 베어링의 고장이 차지하고 있는 상황에서, 베어링 고장으로 인해 발생하는 경제적/시간적 손실을 최소화하기 위해서는 빠르고 정확한 베어링 고장 진단 시스템 구축이 요구된다. 본 논문에서는 베어링의 상태 정보를 담고 있는 음향 방출 신호를 시간-주파수 영역의 스펙트로그램 이미지로 변환한 후에, CNN 기반 딥러닝을 적용하여 베어링의 상태를 정확하게 판단할 수 있는 베어링 고장 진단 기법을 제안한다. 제안된 고장 진단 기법을 다양한 CNN 모델을 활용하여 구현함으로써 CNN 모델에 따른 딥러닝 기반 베어링 고장 진단의 정확성을 평가하고자 한다. 또한, 실제 산업 현장에서의 실시간 고장 진단 가능성을 판단하기 위해 CNN 모델에 따른 고장 진단 계산 복잡도를 분석한다. 이를 위해, 적용되는 CNN 모델에 따른 고장 진단 연산의 Multiply-Accumulate 복잡도를 구하고 실제 현장 적용에 적합할 것으로 판단되는 CNN 모델을 선택한 후, 해당 CNN 모델이 적용된 고장 진단을 라즈베리파이보드에서 동작시켜 봄으로써 산업 현장에 적용 가능한 임베디드시스템에서의 실시간 진단 가능성을 확인하고자 한다. 실험 결과, 기존의 신호 처리를 기반으로 하는 베어링 고장 진단 기법들이 약 80%의 정확도를 보여주는 반면 제안하는 딥러닝을 적용한 베어링 고장 진단 기법은 100%에 가까운 높은 진단 정확도를 제공한다. 하지만, 가장 낮은 계산 복잡도를 요구하는 ShuffleNet을 적용하는 제안 기법의 경우에도 라즈베리파이보드에서 진단을 수행하는데 24,270ms를 소요하여, 산업 현장에서 사용되기 위해서는 계산 복잡도를 더욱 낮출 수 있는 방안이 개발되어야 함을 알 수 있다.","Bearing faults account for a large portion of machine faults in real industrial sites. To minimize the damages caused by bearing faults, it is necessary to provide an accurate real-time bearing faults diagnosis system. In this work, we propose a new bearing fault diagnosis method using deep learning with various CNN models, where acoustic emission signals from working bearings are used to analyze the status of bearings. In the proposed method, the acoustic emission signals acquired from the bearings are converted into spectrogram images in the time-frequency domain, and then the status of bearings can be diagnosed through deep learning with various CNN models. Traditional signal processing based bearing fault diagnosis methods show the accuracy of about 80%, while our proposed deep learning based method provides very high fault diagnosis accuracy of about 100%. We also apply the proposed deep learning based fault diagnosis method to Raspberry Pi to test the availability for the working conditions in real industrial sites. We measured the multiply-accumulate complexity of the fault diagnosis process with various CNN models to find the CNN model suitable for real working conditions, and then the selected ShuffleNet CNN model was implanted and operated in Raspberry Pi to check the possibility of real-time bearing fault diagnosis."
CNN을 이용한 건축적 형상에 대한 선호 추정,2022,"['형태', 'CNN', 'ANN', '선호', '딥러닝', 'Form', 'CNN', 'ANN', 'Preference', 'Deep Learning']","본 연구의 목적은 인공신경망을 이용한 형태에 대한 선호도 파악의 가능성을 탐구하는 것이다. 이를 위해서 본 연구에서는 첫 번째 단계에서 사람들에게 형태에 대한 일관성있는 선호도가 존재하는지를 검토하였다. 첫 번째 단계의 연구 결과, 개인들에게는 형태에 대한 일관성있는 선호가 존재함을 확인하였다. 두 번째 단계에서는 인공신경망을 이용한 형태에 대한 선호도 파악의 가능성을 검토하였다. 첫 번째 단계에서 사용한 동일한 데이터를 이용하여 인공신경망을 학습시켜 분류 모델을 도출하였다. 이 분류 모델을 이용하여 분류 정확도를 평가하는 테스트를 실시하였다. 테스트 결과 75.7% 라는 높은 분류 정확도를 나타내었다. 이러한 높은 분류 정확도를 통해 인공신경망을 이용한 형태에 대한 선호도 파악의 가능성이 확인되었다고 주장할 수 있을 것이다.","This study aims to explore the possibility that artificial intelligence can identify human preferences through images using the convolutional neural network (CNN). To determine if people had a consistent preference for form, experiment participants were asked to select the preferred images among 200 images twice, which were automatically generated in dynamo. In the two consecutive image selection processes, ten participants repeatedly selected the same images at a rate of 79 percent. These results confirmed that there is a consistent preference for form. Next, the possibility of identifying the preference for form using CNN was investigated. Data for each experiment participant was divided into two sets. The preferred and non-preferred images were included in each set at a certain percentage. A classification model was produced by conducting supervised learning using CNN with one of the two sets. The classification accuracy was measured by applying this classification model to the other set. As a result of these tests, the classification model created by CNN could classify the preferred and non-preferred images with 82.7 percent accuracy. In random selection, the probability of correctly classifying the preferred and non-preferred images with more than 82.7 percent accuracy was 6.5 x 10-12 percent. Therefore, 82.7 percent reflects a fairly high classification accuracy. Based on this high accuracy, it was possible to identify human preferences for form using CNN"
Multi-channel CNN 기반 온라인 리뷰 유용성 예측 모델 개발에 관한 연구,2022,"['Online Reviews', 'Review Helpfulness', 'Review Text', 'Multi-channel CNN', '라인 리뷰', '리뷰 유용성', '리뷰 텍스트', 'multi-channel CNN']","온라인 리뷰는 소비자의 구매 의사결정 과정에서 중요한 역할을 담당하고 있으므로 소비자에게 유용하고 신뢰성이 있 는리뷰를제공하는것이중요하다. 기존의온라인리뷰유용성예측관련연구는주로온라인리뷰의텍스트와평점정 보 간의 일관성을 바탕으로 리뷰 유용성을 예측하였다. 그러나 기존 연구는 평점 정보를 스칼라로 표현했기 때문에 표현 수용력이 제한적이거나 평점 정보와 리뷰 텍스트 정보와의 상호작용을 제한적으로 학습하는 한계가 존재한다. 본 연구에 서는 기존 연구의 한계점을 보완하기 위해 리뷰 텍스트와 평점 정보 간의 상호작용을 효과적으로 학습할 수 있는 CNN-RHP(CNN based Review Helpfulness Prediction) 모델을 제안하였다. 먼저, 리뷰 텍스트의 의미론적 특성을 추출하 기 위해 multi-channel CNN을 적용하였다. 다음으로, 평점 정보는 텍스트 특성과 동일한 차원을 나타내는 독립된 고차원 임베딩 특성 벡터로 변환하였다. 최종적으로 요소별(Element-wise) 연산을 통해 리뷰 텍스트와 평점 정보 간의 일관성을 학습하였다. 본 연구에서는 제안된 CNN-RHP 모델의 성능을 평가하기 위해 Amazom.com에서 수집된 온라인 소비자 리 뷰를 사용하였다. 실험 결과, 본 연구에서 제안한 CNN-RHP 모델이 기존 연구에서 제안된 여러 모델과 비교했을 때 우수 한 예측 성능을 나타내는 것을 확인하였다. 본 연구의 결과는 온라인 전자상거래 플랫폼에서 소비자들에게 리뷰 유용성 예측 서비스를 제공할 때 유의미한 시사점을 제공할 수 있다.",
금속탐지를 위한 CNN 및 RNN 네트워크 개발에 관한 연구,2022,"['컨벌류션', '딥러닝', '전자파유도', '전자기유도 센서', '순환신경 망네트워크', 'CNN', 'Deep Learning', 'Electromagnetic Induction', 'MI Sensor', 'RNN']","본 논문은 다중 MI 센서에서 얻은 데이터에 대한 딥 러닝을 이용한 신호 처리 필터링 방법과 금속 탐지 방법의효율성에 관한 연구이다. MI 센서는 자기장의 변화를 감지하는 원리로 금속 물체를 감지하는 수동형 센서입니다.다만, 금속 물체를 검출할 경우, 금속에 의한 자기장의 변화량이 적기 때문에 검출 가능한 거리에 한계가 있다. 이를효과적으로 감지하고 분석하기 위해 딥러닝을 활용한 방법이 적용됐다. 또한 신호처리 필터링 방법을 이용하여 딥러닝 모델의 성능을 비교 분석하였다. 본 논문에서는 자기 임피던스 센서에서 추출한 데이터에서 CNN과 RNN 네트워크의 탐지 성능을 비교 분석하였다. RNN 모델은 CNN 모델보다 더 높은 성능을 보였다. 그러나 얕은 단계에서는CNN 모델이 RNN 모델보다 더 높은 성능을 보였다.","This paper is a study on the efficiency of the filtering method of signal processing and the metal detection method using deep learning for data obtained from multiple MI sensors. The MI sensor is a principle that detects changes in magnetic field and is a passive sensor that detects metal objects. However, when detecting a metal object, the amount of change in the magnetic field caused by the metal is small, so there is a limit to the detectable distance. In order to effectively detect and analyze this, a method using deep learning was applied. In addition, the performance of the deep learning model was compared and analyzed using the filtering method of signal processing. In this paper, the detection performance of CNN and RNN networks was compared and analyzed from the data extracted from the self-impedance sensor. The RNN model showed higher performance than the CNN model. However, in the shallow stage, the CNN model showed higher performance than the RNN model."
비정형 패션 이미지 검색을 위한 MASK R-CNN 선형처리 기반 CNN 분류 학습모델 구현,2022,"['비정형 데이터', '이미지 분류', '신경망', 'Mask R-CNN', 'Unstructured Data', 'Image Classification', 'Neural Network', 'Mask R-CNN']","본 논문에서는 패션 분야의 비정형 데이터 검색을 위한 패션 아이템별 세부 컨포넌트 이미지 분류 알고리즘을 제안한다. 코로나-19 환경으로 인하여 최근 AI 기반 쇼핑몰이 증가하는 추세이다. 하지만 기존의 키워드 검색과 사용자 서핑 행위 기반 개인 맞춤형 스타일 추천으로는 정확한 비정형 데이터 검색에는 한계가 있다. 본 연구는 다양한 온라인 쇼핑 사이트에서 크롤링한 이미지를 사용하여 Mask R-CNN을 활용한 전처리를 진행한 후, CNN을 통해 패션 아이템별 컴포넌트에 대한 분류를 진행하였다. 셔츠의 카라 및 패턴과 청바지의 핏, 워싱 및 컬러에 대한 분류를 진행하였으며, 다양한 전이학습 모델을 비교 분석한 후 가장 높은 정확도가 나온 Densenet121모델을 사용하여 셔츠의 카라는 93.28%, 셔츠의 패턴은 98.10%의 정확도를 도달하였으며, 청바지의 핏은 Notched, Spread, Straight 3가지의 클래스의 경우 91.73%, Regular 핏을 추가한 4가지의 클래스의 경우 81.59%, 청바지의 색상은 93.91%, 청바지의 Washing은 91.20%, 청바지의 Demgae는 92.96%의 정확도를 도출하였다.",
소나무 재선충 탐지를 위한 U-NET모델과 Mask R-CNN모델의 정사영상 비교분석,2022,"['Pine Wilt', 'U-NET Model', 'Mask R-CNN Model', 'Orthophoto Imagery', 'Training Data', '소나무재선충', 'U-NET모델', 'Mask R-CNN모델', '정사영상', '학습데이터']","본 연구는 소나무재선충 탐지를 위해 딥러닝 모델인 U-NET 모델과 Mask R-CNN 모델을 이용하여 소나무 재선충 피해지역을 분석한 후 탐지능력을 비교해 보았다. 이를 위해 먼저 소나무재선충 피해대상지를 선정하고 드론 촬영 후 정사영상을 획득하였다. 딥러닝을 위한 학습데이터로는 시계열별 2,123개의 소나무재선충 정사영상 자료를 사용하였다. 검증을 위한 참값자료는 연구대상지의 고사목 제거 위치데이터를 사용하였다. 분석 결과 U-NET 모델은 재현율 96.6% 정밀도 80.2%를 얻었으며, Mask R-CNN 모델은 재현율 86.4% 정밀도 75.0%를 얻었다. 이것은 영상의 해상도 차이, 블러닝과 비네팅 현상, 수목 종류, 계절에 따른 단풍과 잎사귀의 갈변 등으로 인한 것이며, 각 지역별 수목의 특징과 산림환경에 적합한 다양한 학습데이터를 학습시킨다면 딥러닝의 탐지능력은 향상될 것이라 판단된다.","This study compared the detection capabilities of the two deep learning models (U-NET model and the Mask R-CNN model) in Pine wilt disease damaged area through image analysis on the basis of orthophoto imagery. To this end, we obtained the 2,123 time-series imageries of damaged pine trees by Pine wilt disease for training data. The location data of cleared pine trees in the study site was used as the reference data to verify models. As a result of the analysis, the U-NET model obtained a recall rate of 96.6% and an accuracy of 80.2%, and the Mask R-CNN model obtained a recall rate of 86.4% and an accuracy of 75.0%. This is due to differences in image resolution, browning and vignette phenomena, tree types, seasonal autumn leaves and browning of leaves, etc., and learning various learning data suitable for the characteristics of trees and forest environment in each region. Then, it is judged that the detection ability of deep learning is improved."
CNN을 이용한 Al 6061 압출재의 표면 결함 분류 연구,2022,"['Convolution Neural Network', 'Surface Defect', 'Aluminum alloy', 'Extrusion', 'Deep Learning', 'Data Augmentation']",,"Convolution Neural Network(CNN) is a class of deep learning algorithms and can be used for image analysis. In particular, it has excellent performance in finding the pattern of images. Therefore, CNN is commonly applied for recognizing, learning and classifying images. In this study, the surface defect classification performance of Al 6061 extruded material using CNN-based algorithms were compared and evaluated. First, the data collection criteria were suggested and a total of 2,024 datasets were prepared. And they were randomly classified into 1,417 learning data and 607 evaluation data. After that, the size and quality of the training data set were improved using data augmentation techniques to increase the performance of deep learning. The CNN-based algorithms used in this study were VGGNet-16, VGGNet-19, ResNet-50 and DenseNet-121. The evaluation of the defect classification performance was made by comparing the accuracy, loss, and learning speed using verification data. The DenseNet-121 algorithm showed better performance than other algorithms with an accuracy of 99.13% and a loss value of 0.037. This was due to the structural characteristics of the DenseNet model, and the information loss was reduced by acquiring information from all previous layers for image identification in this algorithm. Based on the above results, the possibility of machine vision application of CNN-based model for the surface defect classification of Al extruded materials was also discussed."
CNN 은닉층 증가에 따른 인공지능 정확도 평가: 뇌출혈 CT 데이터,2022,"['인공지능', '컨볼루션 신경망', '은닉층', '전산화단층촬영', '뇌출혈', 'AI', 'CNN', 'hidden layer', 'Computed Tomography', 'Cerebral Hemorrhage']",딥러닝은 다량의 데이터 속에서 핵심적인 내용을 요약해 학습하는 알고리즘의 집합으로 의료영상 분야에서 병변을 진단하는 목적으로 사용되기 위해 발전하고 있다. 본 논문에서는 뇌출혈 진단 정확성을 평가하기 위해 CNN을 이용해 뇌실질 CT 영상과 뇌출혈이 의심되는 뇌실질 CT의 진단 정확도를 도출하였다. 은닉층 수에 따른 정확도를 비교한 결과 은닉층이 증가할수록 정확도가 높아졌다. 본 연구에서 도출된 CT 뇌출혈 유무 분석 결과는 앞으로 의료영상 분야와 인공지능 접목에 관한 연구에서 기초 자료로 사용될 것으로 사료된다.,"Deep learning is a collection of algorithms that enable learning by summarizing the key contents of large amounts of data; it is being developed to diagnose lesions in the medical imaging field. To evaluate the accuracy of the cerebral hemorrhage diagnosis, we used a convolutional neural network (CNN) to derive the diagnostic accuracy of cerebral parenchyma computed tomography (CT) images and the cerebral parenchyma CT images of areas where cerebral hemorrhages are suspected of having occurred. We compared the accuracy of CNN with different numbers of hidden layers and discovered that CNN with more hidden layers resulted in higher accuracy. The analysis results of the derived CT images used in this study to determine the presence of cerebral hemorrhages are expected to be used as foundation data in studies related to the application of artificial intelligence in the medical imaging industry."
CNN 아키텍쳐 기반 인공 고관절 판독 모델 성능 비교 연구,2022,"['THRA', 'Medical image processing field', 'Patient information', 'Anonymization', 'Binarization work', 'CNN-based architecture']","최근, 고관절 전치환술의 진행에 있어, 제조사마다 규격이 다른 인공관절의 특성으로 인해 과거에 삽입했던 제품과 호환되는 제품을 반드시 사용해야 하는 고질적인 문제점이 있다. 이런 문제를 해결하기 위해 집도의는 수술에 들어가기 전에 X-Ray이미지를 보고 경험치료를 바탕으로 가장 비슷한 인공 보철물을 준비한다. 이러한 준비 과정은 의사의 경험에 따라 오차가 발생할 위험이 있다. 이에 따라 전 세계의 많은 고관절 인공 보철물 제조사는 자사의 데이터를 활용하여 인공 보철물 제품군의 이미지 판독 시스템의 개발이 활발히 이루어지고 있는 추세이다. 따라서 본 연구는 의료영상처리분야에서 시각 정보에 기반한 고차원적 추상화를 통한 병변 진단 및 예후 예측에 뛰어나 성능을 보이는 CNN(Convolutional Neural Network)기반의 다양한 아키텍처 모델들의 성능을 비교한다. 연구방법은 다음과 같다. 국내 유일의 인공고관절 제조업체인 ㈜코렌텍에서 제공한 자사 제품이 사용된 X-Ray 이미지와 Kaggle 데이터셋 ‘Aseptic Loose Hip Implant X-Ray Database’을 활용한다. 이때 사용되는 X-Ray 이미지는 환자 정보에 대한 비식별화가 된 상태이다. 습득한 X-Ray 이미지는 인공 보철물이 나타난 부분을 뜯어내 배경을 제거한 후 이진화 작업, 특정 영역 외 객체 제거, 이미지 반전 등 데이터 전처리 작업을 거치고, 전처리된 데이터셋을 이진 분류모델에 맞게 변환한다. 이후 CNN기반의 다양한 아키텍처 모델에 적용하여 각 모델에 대한 성능을 비교한다. 성능비교에 사용한 CNN기반 모델은 CNN, VGG16, GoogLe Net/Inception Net, Xception Net, Mobile Net, ResNet 총 6개이며, 각 모델에 대한 특징과 연결점에 대해 설명한다.",
CNN을 활용한 OLED 디스플레이 결함 검출 시스템 구현,2022,"['machine learning', 'mura', 'AOI', 'CNN', '.']",최근에는 머신러닝 기술이 발전함에 따라 다양한 산업에서 이를 적용한 기술들이 개발되고 있다. 하지만 패널을 생산하는 공정에서는 아직 머신러닝을 결합하여 Mura를 검출하는 방법이 보편화되어 있지 않다. 현재 생산 공정에서 주로 사용되고 있는 AOI(Automated Optical Inspection) 기법은 사전에 입력된 Mura를 검출하는데 효과적이지만 새로운 Mura가 입력되면 검출하지 못하는 문제가 발생한다. 본 논문에서는 이러한  문제를 해결하기 위해 CNN(Convolutional Neural Networks)을 이용한 Mura 검출 시스템을 구현하였다. 패널의 이미지 데이터들은 29M 카메라와 Frame Grabber를 이용하여 수집하고 총 5단계로 구성된 데이터 가공 기법을 적용하여 정형화된 데이터를 생성하였다. 이후 생성된 데이터들을 CNN 모델의 입력으로 사용하여 Mura 검출을 수행하였다. 실험 결과 50개의 테스트 데이터에서 100%의 정확도를 얻을 수 있었다.,"Recently, as machine learning technology develops, technologies applying it are being developed in various industries. However, in the process of producing panels, Mura detecting method using machine learning is not yet common. The AOI(Automated Optical Inspection) technique, which is mainly used in the current production process, is effective in detecting typical mura pattern, but has a problem not detecting when a new mura pattern. In this paper, we implemented a mura detection system using CNN(Convolutional Neural Networks) to solve this problem. The image data of the panel was collected using a 29M camera and a frame grabber, and standardized data was generated by applying a data processing technique consisting of a total of 5 steps. Then, This generated data is used for CNN model for Mura detection. As a result, we confirmed the 100% accuacy Mura detection for 50 test data."
CNN 기반 지문분류 연구 동향,2022,"['Fingerprint Classification', 'Pattern Recognition', 'Feature Extraction', 'CNN', 'Deep Learning', '지문분류', '패턴 인식', '특징추출', '합성곱 신경망', '딥러닝']",,"Recently, various researches have been made on a fingerprint classification method using Convolutional Neural Networks (CNN), which is widely used for multidimensional and complex pattern recognition such as images. The CNN-based fingerprint classification method can be executed by integrating the two-step process, which is generally divided into feature extraction and classification steps. Therefore, since the CNN-based methods can automatically extract features of fingerprint images, they have an advantage of shortening the process. In addition, since they can learn various features of incomplete or low-quality fingerprints, they have flexibility for feature extraction in exceptional situations. In this paper, we intend to identify the research trends of CNN-based fingerprint classification and discuss future direction of research through the analysis of experimental methods and results."
CNN-LSTM 합성모델에 의한 하수관거 균열 예측모델,2022,"['CNN', 'LSTM', 'Hybrid model', 'Sewer pipe']",,"In this paper, we propose a GoogleNet transfer learning and CNN-LSTM combination method to improve the time-series prediction performance for crack detection using crack data captured inside the sewer pipes. LSTM can solve the long-term dependency problem of CNN, so spatial and temporal characteristics can be considered at the same time. The predictive performance of the proposed method is excellent in all test variables as a result of comparing the RMSE(Root Mean Square Error) for time series sections using the crack data inside the sewer pipe. In addition, as a result of examining the prediction performance at the time of data generation, the proposed method was verified that it is effective in predicting crack detection by comparing with the existing CNN-only model. If the proposed method and experimental results obtained through this study are utilized, it can be applied in various fields such as the environment and humanities where time series data occurs frequently as well as crack data of concrete structures."
단백질 기능 예측 문제에서 시퀀스 패턴 추출을 위한 작은 CNN-RNN 접목 모델 연구,2022,"['PSSM', 'Deep learning', 'Protein Function Prediction', 'Feature Engraft Model', 'Overlapped R', 'PSSM', '딥러닝', '단백질 기능 예측', '특징 접목 모델', '중첩 RNN']","본 논문에서는 2020년 기준 단백질 서열을 이용한 기능과 구조 예측 분야에서 가장 많이 사용되고있는 딥러닝 모델인 CNN과 LSTM/GRU 모델을 동일한 조건 하에 비교 평가한 연구를 토대로 새로운효소 기능 예측 모델인 PSCREM을 설계하였다. CNN 합성곱 시 누락되는 세부 패턴을 보존하기 위하여서열 진화정보를 이용하였으며 중첩 RNN을 통해 기능적으로 중요한 의미를 가지는 아미노산 간의관계 정보를 추출하고 특징 맵 제작에 참조하였다. 사용된 RNN 계열의 알고리즘은 LSTM과 GRU로보통 stacked RNN 기법으로 100 units 이상 2~3회 쌓는 것이 일반적이나 본 논문에서는 10, 20 unit으로구성한 뒤 중첩시켜서 특징 맵 제작에 사용하였다. 모델에 들어가는 데이터는 단백질 서열 데이터로PSSM profile로 가공한 뒤 사용되었다. 실험 결과 효소 번호 첫 번째 자리를 예측하는 문제에 대해86.4%의 정확도를 나타냄을 입증하였고, 효소 번호 3번째 자리까지 예측 정확도 84.4%의 성능을 내는것을 확인하였다. PSCREM은 Overlapped RNN을 통해 단백질 기능에 관련된 고유 패턴을 더 잘 파악하며Overlapped RNN은 단백질 기능 및 구조 예측 추출 분야에 새로운 방법론으로서 제안된다.","In this paper, we designed a new enzyme function prediction model PSCREM based on a study that compared and evaluated CNN and LSTM/GRU models, which are the most widely used deep learning models in the field of predicting functions and structures using protein sequences in 2020, under the same conditions. Sequence evolution information was used to preserve detailed patterns which would miss in CNN convolution, and the relationship information between amino acids with functional significance was extracted through overlapping RNNs. It was referenced to feature map production. The RNN family of algorithms used in small CNN-RNN models are LSTM algorithms and GRU algorithms, which are usually stacked two to three times over 100 units, but in this paper, small RNNs consisting of 10 and 20 units are overlapped. The model used the PSSM profile, which is transformed from protein sequence data. The experiment proved 86.4% the performance for the problem of predicting the main classes of enzyme number, and it was confirmed that the performance was 84.4% accurate up to the sub-sub classes of enzyme number. Thus, PSCREM better identifies unique patterns related to protein function through overlapped RNN, and Overlapped RNN is proposed as a novel methodology for protein function and structure prediction extraction."
GAN 오버샘플링 기법과 CNN-BLSTM 결합 모델을 이용한 부정맥 분류,2022,"['Arrhythmia', 'CNN', 'GAN', 'BLSTM', 'MIT-BIH', '부정맥', '합성곱 신경망', '적대적 생성 신경망', '양방향 장단기 기억 신경망', 'MIT-BIH']","부정맥이란 심장이 불규칙한 리듬이나 비정상적인 심박동수를 갖는 것을 말하며, 뇌졸중, 심정지 등을 유발하거나 사망에도 이를 수 있는 만큼, 조기 진단과 관리가 무엇보다 중요하다.본 연구에서는 심전도 신호의 QRS 특징 추출에 적합한 CNN과 기존 LSTM의 직전 패턴의 수렴 한계를 해결할 수 있는 BLSTM을 연결한 CNN-BLSTM 결합 모델을 이용한 부정맥 분류 방법을 제안한다. 이를 위해 먼저 전처리 과정을 통해 잡음을 제거한 심전도 신호에서 QRS 특징점을 검출하고 단일 비트 세그먼트를 추출하였다. 이때 데이터의 불균형 문제를 해결하기 위해 GAN 오버샘플링 기법을 적용하였다. 이 후 합성곱 계층을 통해 부정맥 신호의 패턴을 정밀하게 추출하도록 구성하고 이를 BLSTM의 입력으로 사용한 후 매개변수를 학습시키고 검증 데이터로 학습 모델을 평가한 후 부정맥 분류의 정확도를 확인하였다. 제안한 방법의 우수성을 입증하기 위해 MIT-BIH 부정맥 데이터베이스를 이용하여 분류의 정확도, 정밀도, 재현율, F1-score를 비교하였다. 성능평가 결과 각각 99.30%, 98.70%, 97.50%, 98.06%로 우수한 분류율을 나타내는 것을 확인할 수 있었다.","Arrhythmia is a condition in which the heart has an irregular rhythm or abnormal heart rate, early diagnosis and management is very important because it can cause stroke, cardiac arrest, or even death.In this paper, we propose arrhythmia classification using hybrid combination model of CNN-BLSTM. For this purpose, the QRS features are detected from noise removed signal through pre-processing and a single bit segment was extracted. In this case, the GAN oversampling technique is applied to solve the data imbalance problem. It consisted of CNN layers to extract the patterns of the arrhythmia precisely, used them as the input of the BLSTM. The weights were learned through deep learning and the learning model was evaluated by the validation data. To evaluate the performance of the proposed method, classification accuracy, precision, recall, and F1-score were compared by using the MIT-BIH arrhythmia database. The achieved scores indicate 99.30%, 98.70%, 97.50%, 98.06% in terms of the accuracy, precision, recall, F1 score, respectively."
생산 공정에서 CNN을 이용한 음향 PSD 영상 기반 공구 상태 진단 기법,2022,"['공구 상태 진단', '전력스펙트럼밀도', '합성곱신경망', '가공 공정', '음향 신호', 'Tool Condition Monitoring', 'PSD(Power Spectral Density)', 'CNN(Convolution Neural Network)', 'Machining Process', 'Sound Signal']","정보통신기술(ICT)를 적용한 스마트팩토리로 불리는 지능형 생산 공장은 각종 센서를 통해 공정 데이터를 실시간으로 수집하고 있다. 이렇게 수집된 데이터를 효과적으로 활용하는 연구가 많이 진행되고 있는데, 본 논문에서는 생산 공정에서 발생되는 음향 신호를 기반으로 공구 상태를 진단하는 기법을 제안한다. 첫 번째로 결함이 있는 공구를 감지할 뿐만 아니라 공회전 및 공정 운용에 따른 다양한 공구 상태를 제시한다. 두 번째로 푸리에 분석을 이용하여 사운드의 전력스펙트럼을 영상으로 표현하고, 데이터에 숨겨진 건강한 패턴을 드러내고, 강조하기 위해 일부 변형을 적용한다. 마지막으로 이렇게 획득한 대비 강화된 PSD 영상은 CNN을 이용해 상태별로 진단한다. 그 결과 제안한 음향 PSD 영상 + CNN 방법은 데이터의 차별화된 특징이 잘 반영되어 공구 상태에 따른 높은 진단 결과를 보여준다.","The intelligent production plant called smart factories that apply information and communication technology (ICT) are collecting data in real time through various sensors. Recently, researches that effectively applying to these collected data have gained a lot of attention. This paper proposes a method for the tool condition monitoring based on the sound signal generated in machining process. First, it not only detects a fault tool, but also presents various tool states according to idle and active operation. The second, it's to represent the power spectrum of the sounds as images and apply some transformations on them in order to reveal, expose, and emphasize the health patterns that are hidden inside them. Finally, the contrast-enhanced PSD image obtained is diagnosed by using CNN. The results of the experiments demonstrate the high discrimination potential afforded by the proposed sound PSD image + CNN and show high diagnostic results according to the tool status."
EMD-CNN-LSTM을 이용한 하이브리드 방식의 리튬 이온 배터리 잔여 수명 예측,2022,"['Remaining useful life', 'Deep learning', 'Convolution neural network', 'Long short term memory', 'Empirical mode decomposition']",,"This paper proposes a battery remaining useful life (RUL) prediction method using a deep learning-based EMD–CNN–LSTM hybrid method. The proposed method pre-processes capacity data by applying empirical mode decomposition (EMD) and predicts the remaining useful life using CNN-LSTM. CNN–LSTM is a hybrid method that combines convolution neural network (CNN), which analyzes spatial features, and long short term memory (LSTM), which is a deep learning technique that processes time series data analysis. The performance of the proposed remaining useful life prediction method is verified using the battery aging experiment data provided by the NASA Ames Prognostics Center of Excellence and shows higher accuracy than does the conventional method."
CNN을 이용한 실내가구 인테리어배치 AR알고리즘 모델링에 대한 연구,2022,"['3D Scanning', 'AR Labeling', 'Interior', 'Furniture', 'CNN', '3D 스캐닝(Scanning)', 'AR 레이블링(Labeling)', '인테리어(Interior)', '가구(Furniture)', 'CNN']","본 논문에서는 증강현실 기술을 적용하여 실내 가구 인테리어를 배치하는데 작업의 효율성을 높일수 있는 모델을 연구하였다. 현재 증강현실을 적용한 기존 시스템에서는 가구의 이미지를 출력할 때기업 제품의 규모와 성격 등에 따라 정보가 제한적으로 제공되는 문제가 있다. 이러한 문제점을 해결하기위해 본 논문에서는 AR 레이블링 알고리즘을 제시하였다. AR 레이블링 알고리즘은 촬영된 이미지에서특징점을 추출하고 실내 위치 정보를 포함한 데이터베이스를 구축하였다. CNN 기법을 활용하여 실내공간에서 가구의 위치 데이터를 검출해 학습시키는 방법을 채택하였다. 학습한 결과를 통해 실내 위치와학습시켜 나타낸 위치와의 오차를 현저히 낮출 수 있다는 것을 확인한다. 또한 가구의 정확한 이미지추출과 함께 가구에 대한 상세한 정보를 받아 사용자가 원하는 가구들을 증강현실을 통해 쉽게 배치할수 있도록 하는 연구를 진행하였다. 연구 결과 모델의 정확도와 손실률이 99%, 0.026으로 나타나 신뢰성을확보하여 본 연구가 유의미함을 알 수 있었다. 본 연구 결과는 AR 레이블의 설계, 구현을 통해 원하는가구들을 실내에 정확히 배치하여 소비자의 만족도와 구매 욕구를 충족시킬 수 있을 것으로 기대된다.","In this paper, a model that can increase the efficiency of work in arranging interior furniture by applying augmented reality technology was studied. In the existing system to which augmented reality is currently applied, there is a problem in that information is limitedly provided depending on the size and nature of the company's product when outputting the image of furniture. To solve this problem, this paper presents an AR labeling algorithm. The AR labeling algorithm extracts feature points from the captured images and builds a database including indoor location information. A method of detecting and learning the location data of furniture in an indoor space was adopted using the CNN technique. Through the learned result, it is confirmed that the error between the indoor location and the location shown by learning can be significantly reduced. In addition, a study was conducted to allow users to easily place desired furniture through augmented reality by receiving detailed information about furniture along with accurate image extraction of furniture. As a result of the study, the accuracy and loss rate of the model were found to be 99% and 0.026, indicating the significance of this study by securing reliability. The results of this study are expected to satisfy consumers' satisfaction and purchase desires by accurately arranging desired furniture indoors through the design and implementation of AR labels."
홍수 위험도 판별을 위한 CNN 기반의 분류 모델 구현,2022,"['DNN', 'K-Means Clustering', '시계열 데이터', '위험도 판별', '홍수', 'DNN', 'K-Means Clustering', 'Time series data', 'Flood Risk Determination', 'Flood']","지구온난화 및 이상 기후로 인해 홍수의 빈도 및 피해 규모가 늘어나고 있으며,  홍수 취약 지역에 노출된 사람이 2000년도에 비하여 25% 증가하였다. 홍수는 막대한 금전적, 인명적 손실을 유발하며, 홍수로 인한 손실을 줄이기 위해 홍수를 미리 예측하고 빠른 대피를 결정해야 한다. 본 논문은 홍수 예측을 위한 핵심 데이터인 강우량과 수위 데이터를 활용하여 시기적절한 대피 결정이 이루어질 수 있도록 CNN기반 분류 모델을 활용하여 홍수 위험도 판별 모델을 제안한다. 본 논문에서 제안한 CNN 기반 분류 모델과 DNN 기반의 분류 모델의 결과를 비교하여 더 좋은 성능을 보이는 것을 확인하였다. 이를 통해 홍수의 위험도를 판별하여, 대피 여부 판단하며 최적의 시기에 대피 결정을 내릴 수 있도록 하는 초기 연구로서 활용할 수 있을 것으로 사료된다.","Due to global warming and abnormal climate, the frequency and damage of floods are increasing, and the number of people exposed to flood-prone areas has increased by 25% compared to 2000. Floods cause huge financial and human losses, and in order to reduce the losses caused by floods, it is necessary to predict the flood in advance and decide to evacuate quickly. This paper proposes a flood risk determination model using a CNN-based classification model so that timely evacuation decisions can be made using rainfall and water level data, which are key data for flood prediction. By comparing the results of the CNN-based classification model proposed in this paper and the DNN-based classification model, it was confirmed that it showed better performance. Through this, it is considered that it can be used as an initial study to determine the risk of flooding, determine whether to evacuate, and make an evacuation decision at the optimal time."
UAV 영상 기반의 Faster R-CNN 기법을 활용한 샌드위치패널 지붕탐색,2022,"['무인항공기', 'Faster R-CNN', '샌드위치패널', '객체 탐지 알고리즘', 'UAV Image', 'Faster R-CNN', 'Sandwich Panel', 'Object Detection Algorithms']","우리나라 건축물 중 샌드위치패널(조립식판넬) 건축물은 건축시장에서 선호되지만 화재에 취약한 건축자재로 분류된다. 샌드위치패널(조립식판넬) 건물의 화재는 화재의 빠른 확산으로 인해 짧은 시간에 대형 화재로 이어질 가능성이 높으며, 다른 건물에 비해 인명 및 재산 피해의 주요 원인이 되는 건물 붕괴 위험이 높다. 화재로 인한 인명 및 재산 피해를 방지하기 위해서는 화재에 취약한 건축물에 대한 관리가 절실히 필요한 실정이다. 따라서 본 연구에서는 항공사진보다 영상 획득이 용이한 무인항공기(UAV)와 최근 활발히 활용되고 있는 CNN의 객체 탐지 알고리즘을 결합하여 화재에 취약 건물의 지붕을 탐색하고 분류하는 방법을 제안하였다. 구체적으로, UAV로 촬영한 영상에서 화재가 발생하기 쉬운 지붕을 탐색 및 분류할 때 다양한 촬영 고도에서 촬영한  UAV 영상을 제작하여 학습 데이터로 활용하고, 또 다른 학습 데이터와 비교하여 화재 취약 건물 지붕을 감지하기 위한 최적의 조건을 찾는 것이다.","Among the buildings in Korea, sandwich panel buildings are classified as building materials that are preferred in the building market but vulnerable to fire. The fire in the sandwich panel building is likely to lead to large fires in a short time due to the fast spread of fire and the risk of building collapse is considerable compared to other buildings, which is the main cause of human and property damage. In order to prevent human and property damage from fire, management of buildings vulnerable to fire is desperately needed. Therefore, in this work, we proposed a method to explore and classify the roofs of vulnerable buildings in fire by combining unmanned aerial vehicles (UAV) that are easier to obtain images than aerial photographs and CNN's recently actively utilized object detection algorithms. Specifically, when exploring and classifying fire-prone roofs from images taken with UAV, the objective is to build and use images taken at various shoot elevations as learning data, and to find optimal conditions for detecting roofs of buildings by comparing results when another learning data is added to learning data."
웨이블릿 변환 기반 CNN을 활용한 무선 신호 분류,2022,"['Convolutional neural network', 'Signal classification', 'F1-score', 'Transfer learning', 'Wavelet transform', '합성곱 신경망', '신호 분류', 'F1-스코어', '전이 학습', '웨이블릿 변환']","다양한 변조 기법을 사용하여 저피탐 능력을 갖춘 신호원들이 증가하면서, 신호의 변조 방식을 분류하는 연구가 꾸준히 진행되고 있다. 최근 신호 간섭이나 잡음 환경에서 수신 신호 분류의 성능 개선을 위하여 전처리 과정으로 FFT를 이용하는 CNN(Convolutional Neural Network) 딥러닝 기법이 제안되었다. 하지만 윈도우가 고정되는 FFT의 특성상 탐지 신호의 시간에 따른 변화를 정확히 분류해내지 못한다. 따라서 본 논문에서는 시간 영역과 주파수 영역에서 높은 해상도를 가지고 또한 다양한 유형의 신호를 시간 및 주파수 영역에서 동시에 표현할 수 있는 웨이블릿 변환(wavelet transform)을 전처리 과정으로 사용하는 CNN 모델을 제안한다. 시뮬레이션을 통해 제안하는 웨이블릿 변환 방식이 FFT 변환 방식에 비해 정확도와 학습 속도 측면에서 SNR 변화에 무관하게 우수한 성능을 보이고, 특히 낮은 SNR일 때 더욱 큰 차이를 보임을 입증하였다.","As the number of signal sources with low detectability by using various modulation techniques increases, research to classify signal modulation methods is steadily progressing. Recently, a Convolutional Neural Network (CNN) deep learning technique using FFT as a preprocessing process has been proposed to improve the performance of received signal classification in signal interference or noise environments. However, due to the characteristics of the FFT in which the window is fixed, it is not possible to accurately classify the change over time of the detection signal. Therefore, in this paper, we propose a CNN model that has high resolution in the time domain and frequency domain and uses wavelet transform as a preprocessing process that can express various types of signals simultaneously in time and frequency domains. It has been demonstrated that the proposed wavelet transform method through simulation shows superior performance regardless of the SNR change in terms of accuracy and learning speed compared to the FFT transform method, and shows a greater difference, especially when the SNR is low."
CNN-LSTM 혼합모델을 이용한 비행상태 예측 기법,2022,"['UAV(무인항공기)', 'UAM(도심형 항공 이동 수단)', 'CNN(합성곱 신경망)', 'LSTM(장단기 메모리)']","최근 차세대 운송시스템으로 주목받고 있는 UAM 분야에서 무인항공기 활용을 위한 기술 개발이 활발히 진행되고 있다. 이러한 기술이 적용된 무인항공기는 주로 도심에서 운용되기 때문에 추락사고를 예방하는 것이 중요하다. 그러나 충돌이 발생되는 무인항공기는 비선형성이 강하기 때문에 비정상 비행 상태를 예측하는 것은 쉽지 않은 일이다. 본 논문에서는 CNN-LSTM 혼합모델을 이용하여 무인항공기의 비행상태를 예측하는 방법을 제안한다. 제안 모델은 비행 데이터간의 시간적, 공간적 특징을 추출하는 CNN 모델과 추출된 특징의 장단기 시간 의존성을 추출하는 LSTM 모델을 결합하여 미래의 특정 시점에서 비행 상태변수를 예측한다. 모의 실험은 제안하는 방법이 기존 인공신경망 모델에 기반한 예측 방법보다 우수한 성능을 보인다.",
CNN에서 입력 최댓값을 이용한 SoftMax 연산 기법,2022,"['CNN', 'SoftMax', 'Accelerator', 'Exponential function']",,"A convolutional neural network(CNN) is widely used in the computer vision tasks, but its computing power requirement needs a design of a special circuit. Most of the computations in a CNN can be implemented efficiently in a digital circuit, but the SoftMax layer has operations unsuitable for circuit implementation, which are exponential and logarithmic functions. This paper proposes a new method to integrate the exponential and logarithmic tables of the conventional circuits into a single table. The proposed structure accesses a look-up table (LUT) only with a few maximum values, and the LUT has the result value directly. Our proposed method significantly reduces the space complexity of the SoftMax layer circuit implementation. But our resulting circuit is comparable to the original baseline with small degradation in precision."
CNN을 활용한 웨이퍼 불량 원인 인자 파악에 관한 연구 : 반도체 전공정 중심으로,2022,"['인공지능', 'CNN머신러닝', '불량 웨이퍼', 'AI', 'CNN', 'Machine learning', 'Defected Wafer']","본 연구는 반도체 제조공정에서의 웨이퍼 불량 원인을 조기 감지하고, 예측하는 시스템 구축을 통한 생산성 향상을 목적으로 한다. 연구 방법으로서 파라미터 탐색을 위해 랜덤 포레스트와 라쏘 알고리즘을 사용하였고, 불량 웨이퍼의 원인 공정 학습에는 CNN 알고리즘을 사용했다. 이번 연구에 적용된 신경망 구조는 de-sampling layer 1개, convolution layer 5개, full connected layer 3개, 8개 layer로 최적화하여 적용하였다. 랜덤 포래스트와 라쏘 알고리즘을 통해 Average와 Standard Deviation 차이가 불량 웨이퍼 원인이 되는 파라미터 후보군을 랭킹에 따라 추출하여 중첩되는 파라미터를 주요 원인으로 도출하였다.본 연구의 실증적 성과로는 첫째. 기존의 연구가 단순히 웨이퍼의 불량 패턴에 대한 분류가 대부분이었다면 이번 연구는 반도체 제조공정의 데이터를 사용하여, 적합한 모델 알고리즘 연구를 통하여 전공정에서의 실제 불량의 근본적인 원인이 되는 파라미터를 식별할 수 있었다. 둘째, 원인 공정 및 파라미터를 확보하여 불량 유형의 대상 공정 및 파라미터 축소를 통하여 모델의 학습지능의 정확도가 향상되고, 불량 유형에 대한 추가로 확보한 학습데이터를 가지고 재학습한 결과 학습지능이 향상되는 것을 확인하였다.",
Opcode 빈도수 기반 악성코드 이미지를 활용한 CNN 기반 악성코드 탐지 기법,2022,"['Machine Learning', 'Convolution Neural Network', 'Clustering', 'Malware Detection']","인터넷이 발달하고 컴퓨터 이용률이 높아짐에 따라 악성코드로 인한 위협 또한 함께 증가하고 있다. 매년 발견되는 악성코드의 수는 급격히 증가하여 자동으로 대량의 악성코드를 분석하기 위한 시스템이 필요한 상황이다. 본 논문에서는 딥러닝 알고리즘을 활용한 악성코드 자동 분석 기법을 소개한다. CNN(Convolutional Neural Network)라는 이미지 분류에 활용도가 높은 알고리즘을 이용하여 악성코드의 특징을 이미지화한 데이터를 분석한다. 제안하는 방법은 악성코드의 Semantic한 정보를 탐지에 활용하기 위하여 단순 바이너리 바이트를 기반으로 생성한 이미지가 아닌, 바이너리의 명령어 빈도수를 기반으로 생성한 이미지를 CNN으로 분석한다. 악성코드 10,000개 정상코드 10,000개로 구성된 대량의 데이터 셋을 활용하여 탐지 성능을 확인한 결과, 제안하는 방법은 91%의 정확도로 악성코드를 탐지할 수 있음이 확인되었다.","As the Internet develops and the utilization rate of computers increases, the threats posed by malware keep increasing. This leads to the demand for a system to automatically analyzes a large amount of malware. In this paper, an automatic malware analysis technique using a deep learning algorithm is introduced. Our proposed method uses CNN (Convolutional Neural Network) to analyze the malicious features represented as images. To reflect semantic information of malware for detection, our method uses the opcode frequency data of binary for image generation, rather than using bytes of binary. As a result of the experiments using the datasets consisting of 20,000 samples, it was found that the proposed method can detect malicious codes with 91% accuracy."
CNN을 사용한 공간 데이터 분류 방법,2022,"['CNN', 'spatial data', 'shapefile', 'VGG16', 'transfer learning', '.']","본 논문에서는 모바일 환경, 디지털 트윈 등의 기반 기술로서 중요성이 증대되고 있는 공간 데이터를 딥러닝 기술을 사용하여 분류하기 위한 방법을 제안한다. 공간 데이터 분류를 위한 딥러닝 기술로는 CNN을 사용한다. 학습을 위한 데이터셋은 공간 데이터를 전처리하여 구축한다. 데이터셋을 훈련 및 검증하기 위한 학습 모델은 컨볼루션 레이어와 완전 연결 레이어로 구성한다. 컨볼루션 레이어는 VGG16의 컨볼루션 레이어를 채택하고 전이 학습을 사용한다. 완전 연결 레이어는 Flatten 레이어, ReLU 함수, Dropout 레이어, Softmax 함수로 구성한다. 본 논문에서 제안한 공간 데이터 분류 방법을 연속수치지형도에 대해 적용한 실험을 수행하여 99.1%의 검증 정확도를 확인할 수 있었다.","This paper proposes a method for classifying spatial data, which is increasingly important as a base technology for mobile environments and digital twins, using deep learning technology. CNN is used as a deep learning technology for spatial data classification. A dataset for learning is constructed by preprocessing spatial data. The learning model for training and validating the dataset consists of a convolution layer and a fully connected layer. The convolution layer adopts the convolution layer of VGG16 and uses transfer learning. The fully connected layer consists of a Flatten layer, a ReLU function, a Dropout layer, and a Softmax function. An experiment in which the spatial data classification method proposed in this paper was applied to Korea national map was performed, and verification accuracy of 99.1% was obtained."
1D CNN을 이용한 이미지 기반의 진동 신호 측정 및 보정,2022,"['Image Processing', 'Camera', 'Quadcopter', 'Vibration Signal', 'Convolution Neural Networks', '영상 처리', '카메라', '쿼드콥터', '진동 신호', '합성곱 신경망']","가속도 센서 기반의 진동 모니터링은 과거부터 구조물의 안전 측정 용도로 널리 사용되어 왔다. 최근 비접촉 촬영 카메라 기반의 진동 모니터링 기술이 연구되고 있지만 센서의 추가 설치 비용 문제와 외란이 가해지지 않는 위치의 필요성이 존재한다. 본 연구에서는 앞선 문제들을 해결하기 위해 접촉 촬영 카메라 기반의 진동 신호 추출과 오차 보정을 위한 합성곱 신경망(CNN: convoliution neural network)을 결합한 방법을 제시한다. 접촉 촬영 방식의 카메라를 통해 새로운 카메라의 추가 없이 기존의 카메라를 활용할 수 있도록 한다. 또한, 접촉 촬영 방식의 카메라가 가지고 있는 정확도에 대한 한계점을 오차 보정을 위한 CNN을 통해 해결한다. 제안된 방법론은 쿼드콥터(quadcopter)를 이용한 실험 데이터를 통해 실제 센서에 대해 비교하여 정확도와 성능을 검증하였다.","Vibration monitoring based on an accelerometer has been used in the past to monitor structural health. Recently, vibration monitoring technology based on non-contact shooting cameras have been studied. However, there are certain issues, such as the additional cost for more sensor attachment and the need for a location without disturbance. This study presents a method for solving such problems by combining signal extraction based on a contact shooting camera with a convolution neural network (CNN) for error calibration. Using the contact shooting method, the existing camera can be reused without adding new ones. Additionally, this also makes it possible to overcome the accuracy limits of the contact shooting camera. The suggested methodology was verified by determining the accuracy and performance of a real sensor using the data from the quadcopter experiment."
다양한 CNN모델을 사용한 컬러 콘택트렌즈 불량 검출,2022,"['컬러 콘택트렌즈', '딥러닝', 'ResNet', 'GoogLeNet', 'DenseNet', 'MobileNet', 'Contact Lens', 'Deep Learning', 'ResNet', 'GoogLeNet', 'DenseNet', 'MobileNet']","4차 산업혁명과 함께 디지털 전환(Digital Transformation, DX) 기술이 중요해지고 있다. 이와 함께 인공지능을 통한 생산공정에서의 불량 검출 및 분류에 대한 연구가 활발히 이루어지고 있다. 본 논문에서는 다양한 CNN 모델을 사용하여 컬러 콘택트렌즈 생산공정에서 발생하는 불량 검출을 효과적으로 수행하는 모델을 선정하고자 하며, 이를 통해 생산 및 품질의 향상을 이루어, 자원의 낭비와 소비자의 안전을 확보하고자 한다. 이를 위해 컬러 콘택트렌즈 영상에 대한 전처리와 증강을 통해 학습 및 검증  데이터를 생성하였으며, RGB 및 HSV 채널 영상에 대해 ResNet101, GoogLeNet V2, GoogLeNet V4, DenseNet121, MobileNet의 CNN 기법을 활용하여 RGB와 HSV 채널별로 불량 탐지율 비교 분석하였다. 위 모델의 정확도는 순서대로 각각 89.74%, 84.46%, 95.43%, 82.80%, 89.74%로, RGB 채널의 GoogLeNet V4가 가장 높은 불량 검출 정확도를 얻었으며, 대부분의 모델에서 RGB 채널이 HSV 채널보다 더 좋은 결과를 얻어냄을 알 수 있었다.","The importance of Digital Transformation (DX) technology has increased with the Fourth Industrial Revolution. At the same time, research on defect detection and classification in the production process through artificial intelligence has been actively applied. In this paper, we select a model that effectively detects defects that occur in the production process of color contact lenses using various models, secure reducing resource waste and consumer safety by improving production and quality. For this purpose, data for training and validation were generated through preprocessing and augmentation of color contact lens images, using CNN technologies such as ResNet101, GoogLeNet V2, GoogLeNet V4, DenseNet121, MobileNet compared and analyzed the defect detection rate for each RGB channel and HSV channel. The accuracies of the above models are 89.74%, 84.46%, 95.43%, 82.80%, and 89.74% respectively, with GoogLeNet V4 on the RGB channel having the highest defect detection accuracy, and in most models, the RGB channel is higher than the HSV channel."
Skeleton Keypoints를 활용한 CNN3D 기반의  버스 승객 승하차 예측모델,2022,"['Pose estimation', 'Action recognition', '자세 추정', '행동 인식']","버스는 대중적으로 많이 이용되는 교통수단이다. 그만큼 승객의 안전관리를 위해 철저한 대비가 필요하다. 하지만 2018년 승차하기 위해 접근하는 노인을 인지하지 못하고 버스가 출발하면서 사망사고가 발생하는 등 안전 시스템이 미흡한 상황이다. 기존에 뒷문 계단 쪽 센서를 통해 끼임 사고를 방지하는 안전 시스템은 있지만, 이러한 시스템은 위 사고처럼 승하차하려는 과정에서 발생하는 사고를 예방하진 못한다. 버스 승객의 승하차 의도를 예측할 수 있다면, 위와 같은 사고를 예방하는 안전 시스템 개발에 도움이 될 것이다. 그러나 승객의 승하차 의도를 예측하는 연구는 부족한 상태이다. 따라서 본 논문에서는 버스에 부착된 카메라 영상에서 UDP-Pose를 통해 승객의 skeleton keypoints를 추출하고, 이를 활용한 1x1 CNN3D 기반의 버스 승객 승하차 의도를 예측하는 모델을 제안한다. 제안한 모델은 승객의 승하차 의도를 예측하는 부분에서 RNN, LSTM 모델보다 약 1~2% 높은 정확도를 보여준다.","Buses are a popular means of transportation. As such, thorough preparation is needed for passenger safety management. However, the safety system is insufficient because there are accidents such as a death accident occurred when the bus departed without recognizing the elderly approaching to get on in 2018. There is a safety system that prevents pinching accidents through sensors on the back door stairs, but such a system does not prevent accidents that occur in the process of getting on and off like the above accident. If it is possible to predict the intention of bus passengers to get on and off, it will help to develop a safety system to prevent such accidents. However, studies predicting the intention of passengers to get on and off are insufficient. Therefore, in this paper, we propose a 1x1 CNN3D-based getting on and off intention prediction model using skeleton keypoints of passengers extracted from the camera image attached to the bus through UDP-Pose. The proposed model shows approximately 1~2% higher accuracy than the RNN and LSTM models in predicting passenger’s getting on and off intentions."
CNN을 이용한 차량용 카메라 이미지센서의 고장진단,2022,"['Machine Learning', 'Image Sensor', 'Failure Diagnostics', 'Failure Mode and Effect Analysis', 'Prognostics and Health Management']","최근 자율주행 기술 개발과 함께 차량 내 카메라 모듈 수가 확대되며 활용 기술이 다양해지고 있다. 차량용 카메라는 여러 가지 노출 환경으로 인해 다양한 종류의 고장이 발생하여 높은 신뢰성이 요구되며, 그중 주변 환경을 영상으로 출력하는 이미지센서의 역할이 중요하다. 전자장비에 PHM을 적용하는 경우 상태를 관찰할 수 있는 센서를 부착하는 과정이 어려워 전기적인 신호 출력 값들을 추출하기가 쉽지 않다. 따라서, 본 연구에서는 차량용 카메라에 대해 FMEA를 적용하여 기능별 잠재적 결함을 분석하고, 센서 부착으로 인해 회로기판에 영향을 주지 않기 위해 이미지를 통해 이미지센서의 상태를 진단하는 딥러닝 모델을 제작하였다. 동영상을 프레임마다 분류해야 하므로 단위 시간당 많은 연산을 처리할 수 있는 CNN의 주요 모델 중 VGGNet을 기반으로 학습을 진행하였고, 전체 데이터를 50%, 25%, 25%로 나누어 각각 Training, Validating, Testing데이터로 사용하였다. 이미지 손상 정도에 따라 고장진단분류 학습결과 Precision, Recall, F1-Score 및 Accuracy는 평균 92.6%의 성능을 확인하였으며, Grad-CAM을 사용하여 모델이 정확하게 학습되었는지 검증하였다. 본 실험에서 사용된 시편의 수가 적어 가속수명시험 적용이 제한되었으며, 충분한 시편의 수와 가속성 검증을 고려한 가속수명시험을 통해 데이터를 수집하면 정확한 수명예측도 가능할 것으로 기대된다.","With the recent development of autonomous driving technology, the number of camera modules in the vehicle is expanding, and the technology to utilize is diversifying. Vehicle cameras require high reliability because of various failures caused by various exposure environments. Among them, the role of an image sensor that outputs the surrounding environment as an image is important. When PHM is applied to electronic devices, extracting the electrical signal output value is problematic because it is difficult to attach a sensor that can observe the state. Therefore, this study applied FMEA to a vehicle camera to analyze potential defects by function. A deep learning model was developed to diagnose the state of the image sensor through images so that the sensor attachment does not affect the circuit board. Because videos have to be classified for each frame, training was conducted based on VGGNet among the main models of CNN that can process many operations per unit of time. The total data was divided into 50%, 25%, and 25% and used as training, validating, and testing data, respectively. As a result of learning the fault diagnosis classification according to the degree of image damage, the performance of precision, recall, F1-Score, and accuracy was 92.6% on average, and the model was verified using Grad-CAM. As the number of samples used in this experiment was small, there was a limit to the application of the accelerated life test. Accurate life prediction may be possible if data are collected through the accelerated life test considering the sufficient number of samples and acceleration verification."
다수 조명의 채널별 융합을 이용한 CNN 기반 머신 비전 분류기,2022,"['Semiconductor', 'Auto Visual Inspection', 'Deep Learning', 'CNN', '.']",,.
정확도 향상을 위한 CNN-LSTM 기반 풍력발전 예측 시스템,2022,"['CNN', 'LSTM', 'Wind power prediction', '풍력발전예측', 'Machine learning', '기계학습']",,"In this study, we propose a wind power generation prediction system that applies machine learning and data mining to predict wind power generation. This system increases the utilization rate of new and renewable energy sources. For time-series data, the data set was established by measuring wind speed, wind generation, and environmental factors influencing the wind speed. The data set was pre-processed so that it could be applied appropriately to the model. The prediction system applied the CNN (Convolutional Neural Network) to the data mining process and then used the LSTM (Long Short-Term Memory) to learn and make predictions. The preciseness of the proposed system is verified by comparing the prediction data with the actual data, according to the presence or absence of data mining in the model of the prediction system."
GPR 영상에서 CNN을 이용한 지뢰 식별 연구,2022,"['Mine Detection', 'Gound Penetrating Radar', 'Deep Learning', 'Convolutional Neural Network', 'Accuracy']","우리나라의 지뢰지대는 여의도 면적의 44배인 128㎢이며, 매설량은 최소 82만 8천개에 달한다. 지표투과레이다는 기존 지뢰탐지기로 찾아내지 못했던 목함과 발목 지뢰 등 비금속 지뢰까지 탐지가 가능하고, 탐지된 지뢰를 영상으로 확인할 수 있다는 점에서 탐지율은 월등히 높아지고 오경보율은 저하되는 등 지뢰 탐지 성능이 기존 금속탐지기보다 매우 향상되었다. 최근에는 영상 식별 성능을 강화하기 위하여 레이다 신호에 인공지능을 접목한 연구가 증가하고 있으나, 군사보안 상의 이유로 실제 지뢰의 GPR 데이터는 민간에서 연구가 진행되기가 어려웠다. 본 논문에서는 실제 군에서 사용 예정인 지뢰탐지기-II의 GPR 영상 데이터를 기반으로 CNN(Convolutional Neural Network) 모델에 적용하여 99.5%의 정확도를 확인하였으며, 시뮬레이션을 통한 연구와 비교하여 실제 데이터를 학습한 모델의 성능이 우수함을 확인하였다. 또한 토양별로 실험을 진행하여 사양토, 부엽토, 수풀에서 각각 100%, 99%, 98.9%의 정확도를 보임을 확인하였다. 앞으로 실제 야전에서 지뢰탐지기-II를 운용하며 지속적으로 데이터를 구축해 나간다면 정확도는 더욱 높아질 것으로 기대된다. 향후 지뢰 유사물질의 파형에 대한 개별 학습을 통해 오경보율을 줄여 나가는 연구를 수행할 예정이다.","The landmine zone in the Republic of Korea is 128㎢ and the landmines buried total at least 828,000 units. Ground penetrating radar (GPR) has improved mine detection performance, compared to metal detection, in that it can detect non-metallic landmines not found by conventional detectors. Also, GPR can check the detected landmines via video, increasing the detection rate and lowering the false alarm rate. Even though many studies on artificial intelligence with radar signals have been discussed to enhance the performance of image identification, private-level research based on actual GPR data has been difficult to conduct owing to military security. This paper confirmed 99.5% accuracy by applying a Convolutional Neural Network (CNN) model based on GPR data from Mine Detector II, scheduled for use by the army, which is more accurate than in previous studies. In addition, we conducted experiments based on three soil types and confirmed accuracies of 100%, 99%, and 98.9%. We expect accuracy will increase further with the accumulation of data from field operations. In the future, research will be conducted to reduce the false alarm rate by learning the waveforms of mine-like substances."
어텐션임베딩과 다채널 CNN 기반 반시민성 검출 알고리즘,2022,,"온라인 포털 플랫폼은 뉴스 기사와 온라인 댓글을 제공하고 있으나, 온라인 댓글의 익명성은 반시민적 표현을 증가시켜 사회적 문제점으로 간주되고 있다. 댓글의 반시민성 검출 연구가 많이 이루어진 국외와 달리, 국내에서는 비시민성을 세분화한 한국어 데이터셋이 구현되지 않아 심도있는 연구가 이루어지지 못하였다. 본 연구에서는 댓글의 반시민성에 대한 라벨링을 총 13가지 항목으로 시행하였으며 반시민적 표현으로 요약하였다. 또한 어텐션 알고리즘을 이중으로 적용하여 임베딩 벡터를 추출하였고 이후 2-d CNN으로 반시민성 항목을 분류하였다. 그 결과, 제안한 알고리즘이 무례한 호칭 및 공격적 어조 등의 반시민성 검출에 유용하다는 것을 보여주었다. 본 연구는 민주적 담론을 저해하는 반시민적 댓글들을 탐지함으로써 건전한 온라인 댓글 문화 형성에 기여할 것으로 기대된다.",
가야 토기의 편년 추정을 위한 딥러닝 CNN-DBSCAN 기반 굽다리 접시 유형 예측 모형 개발,2022,"['Gaya artifacts', 'Typology', 'Image Classification', 'Artificial Intelligence', 'Prediction of chronological age', '가야유물', '형식학', '이미지 분류', '인공지능', '편년추정']",,"The aims of this study is to propose a new typology classification methodology for estimating the chronological age of Gaya pottery (excavated from Changnyeong area) using artificial intelligence image classification technology based on archaeological formalism. In order to achieve the purpose, 1) image data collection, processing and DB establishment of Gobae (grilled plate), which has a large number of excavations and sensitive changes in properties over time, 2) deep learning CNN image feature extraction and DBSCAN Class classification model development and estimation, 3) The differences and similarities between the existing classification and AI classification are considered. As a result, in the classification of people, the width of the plate and the height of the leg was recognized as the main characteristic, but in the classification of CNN-DBSCAN, the machine had differences by type in the open shape of the lid, the depth of the plate, and the open shape of the legs. The results of this study are expected to provide new insights into the classification system of artifacts with complex properties."
CNN 기반 전이학습을 이용한 뼈 전이가 존재하는 뼈 스캔 영상 분류,2022,"['Deep Learning', 'Computer Vision', 'CNN', 'Transfer Learning', 'Medical Image', 'Bone Scan']",,"Whole body bone scan is the most frequently performed nuclear medicine imaging to evaluate bone metastasis in cancer patients. We evaluated the performance of a VGG16-based transfer learning classifier for bone scan images in which metastatic bone lesion was present. A total of 1,000 bone scans in 1,000 cancer patients (500 patients with bone metastasis, 500 patients without bone metastasis) were evaluated. Bone scans were labeled with abnormal/normal for bone metastasis using medical reports and image review. Subsequently, gradient-weighted class activation maps (Grad-CAMs) were generated for explainable AI. The proposed model showed AUROC 0.96 and F1-Score 0.90, indicating that it outperforms to VGG16, ResNet50, Xception, DenseNet121 and InceptionV3. Grad-CAM visualized that the proposed model focuses on hot uptakes, which are indicating active bone lesions, for classification of whole body bone scan images with bone metastases."
멀티 테스크 CNN의 경량화 모델을 이용한 차량 및 차선의 동시 검출,2022,"['Shared backbone', 'Multi-Task CNN', 'Object detection', 'Lane detection', '자율주행', '백본 공유 모델', '차량 검출', '차선 검출']",,"As deep learning-based autonomous driving technology develops, artificial intelligence models for various purposes have been studied. Based on these studies, several models were used simultaneously to develop autonomous driving systems. It can occur by increasing hardware resource consumption. We propose a multi-tasks model using a shared backbone to solve this problem. This can solve the increase in the number of backbones for using AI models. As a result, in the proposed lightweight model, the model parameters could be reduced by more than 50% compared to the existing model, and the speed could be improved. In addition, each lane can be classified through lane detection using the instance segmentation method. However, further research is needed on the decrease in accuracy compared to the existing model."
위성 영상을 위한 경량화된 CNN 기반의 보간 기술 연구,2022,"['Interpolation', 'Super-resolution', 'Remote sensing', 'Satellite images']",,"In order to obtain satellite image products using the image transmitted to the ground station after capturing the satellite images, many image pre/post-processing steps are involved. During the pre/post-processing, when converting from level 1R images to level 1G images, geometric correction is essential. An interpolation method necessary for geometric correction is inevitably used, and the quality of the level 1G images is determined according to the accuracy of the interpolation method. Also, it is crucial to speed up the interpolation algorithm by the level processor. In this paper, we proposed a lightweight CNN-based interpolation method required for geometric correction when converting from level 1R to level 1G. The proposed method doubles the resolution of satellite images and constructs a deep learning network with a lightweight deep convolutional neural network for fast processing speed. In addition, a feature map fusion method capable of improving the image quality of multispectral (MS) bands using panchromatic (PAN) band information was proposed. The images obtained through the proposed interpolation method improved by about 0.4 dB for the PAN image and about 4.9 dB for the MS image in the quantitative peak signal-to-noise ratio (PSNR) index compared to the existing deep learning-based interpolation methods. In addition, it was confirmed that the time required to acquire an image that is twice the resolution of the 36,500×36,500 input image based on the PAN image size is improved by about 1.6 times compared to the existing deep learning-based interpolation method."
마스크 R-CNN과 랜덤 포레스트 방법을 이용한 당뇨병성 망막병증 분류,2022,"['Diabetic Retinopathy', 'Random Forest Classifier', 'Mask R-CNN', 'Data Augmentation', '당뇨병성 망막병증', '랜덤포레스트 분류기', 'Mask R-CNN', 'Data Augmentation', 'Image Processing']","본 논문에서는 딥러닝 기법의 하나인 Mask R-CNN과 랜덤포레스트 분류기를 이용해 당뇨병성 망막병증의 병리학적인 특징을 검출하고 분석하여 자동 진단하는 시스템을 연구하였다. 당뇨병성 망막병증은 특수장비로 촬영한 안저영상을 통해 진단할 수 있는데 밝기, 색조 및 명암은 장치에 따라다를 수 있으며 안과 전문의의 의료적 판단을 도울 인공지능을 이용한 자동진단 시스템 연구와 개발이 가능하다. 이 시스템은 미세혈관류와 망막출혈을 Mask R-CNN 기법으로 검출하고, 후처리 과정을거쳐 랜덤포레스트 분류기를 이용하여 안구의 정상과 비정상 상태를 진단한다. Mask R-CNN 알고리즘의 검출 성능 향상을 위해 이미지 증강 작업을 실시하여 학습을 진행하였으며 검출 정확도 측정을위한 평가지표로는 다이스 유사계수와 Mean Accuracy를 사용하였다. 비교군으로는 Faster R-CNN 기법을 사용하였고 본 연구를 통한 검출 성능은 평균 90%의 다이스 계수를 통한 정확도를 나타내었으며 Mean Accuracy의 경우 91% 정확도의 검출 성능을 보였다. 검출된 병리증상을 토대로 랜덤포레스트 분류기를 학습하여 당뇨병성 망막 병증을 진단한 경우 99%의 정확도를 보였다.","In this paper, we studied a system that detects and analyzes the pathological features of diabetic retinopathy using Mask R-CNN and a Random Forest classifier. Those are one of the deep learning techniques and automatically diagnoses diabetic retinopathy. Diabetic retinopathy can be diagnosed through fundus images taken with special equipment. Brightness, color tone, and contrast may vary depending on the device. Research and development of an automatic diagnosis system using artificial intelligence to help ophthalmologists make medical judgments possible. This system detects pathological features such as microvascular perfusion and retinal hemorrhage using the Mask R-CNN technique. It also diagnoses normal and abnormal conditions of the eye by using a Random Forest classifier after pre-processing. In order to improve the detection performance of the Mask R-CNN algorithm, image augmentation was performed and learning procedure was conducted.Dice similarity coefficients and mean accuracy were used as evaluation indicators to measure detection accuracy.The Faster R-CNN method was used as a control group, and the detection performance of the Mask R-CNN method through this study showed an average of 90% accuracy through Dice coefficients. In the case of mean accuracy it showed 91% accuracy. When diabetic retinopathy was diagnosed by learning a Random Forest classifier based on the detected pathological symptoms, the accuracy was 99%."
초등학생을 위한 모듈형 CNN 핵심 원리 교육 프로그램 개발,2022,"['인공지능교육', 'CNN', '합성곱', '스트라이드', '패딩', '풀링', 'Artificial   intelligence   education', 'CNN', 'Convolution', 'Stride', 'Padding', 'Pooling']","인공지능 교육의 방향과 깊이에 대한 논의가 계속되고 있는 오늘날, 본 논문에서는 ｢초· 중 등 인공지능 교육 내용기준｣의 고등학교 과정에서 도입되는 CNN( 합성곱 신경망) 에 대하여 초등학생을 대상으로 교육하는 프로그램을 제안한다. CNN 알고리즘의 핵심인 합성곱 연산은 곱셈과 덧셈의 연속적인 혼합계산이라는 점에서 수학과교육과정과의 융합을 모색 할 수 있다. 제안된 CNN 교육 프로그램에 서 교수자는 합성곱, 스트라이드, 패딩, 풀링이라는 4개 모듈을 합리적으로 조합하고 학습자의 학년 수준에서 다룰 수 있는 수 체계와 연산을 접목할 수 있다.권장되는 모듈의 조합은 6 가지이며, 초등학 교 2 학년부터 6학년 학습자까지 학습의 범위와 깊이에 차이를 둔다. 향후 현장 수업을 통해 교육 프로그램의 효과성을 검증할 필요가 있다.","This paper proposes a program to educate elementary school students ab out Convolutional Neural Netw ork ( CNN) . This algorithm introduced in the high school course of the “Elementary and Secondary AI Education Content Standards” . Convolutions, the core of CNN algorithms, are continuous mix ed computations of multiplication and addition, so convergence with elementary mathematics curriculum can be sought. In the proposed CNN education program, instructors can comb ine 4 modules: convolution, stride, padding, and pooling, and incorporate mathematical systems and operations related with the learners' grades. There are 6 recommended comb inations of modules, and there are differences in the scope and depth of learning from 2nd to 6th graders. It is necessary to verify the effectiveness of the program through field classes in the future."
1-D CNN 기반 자동차 휠 너트 풀림 상태 예측 기법 개발,2022,"['1-D 합성곱 신경망', '휠 너트 풀림', '가속도계', '실시간 예측', '데이터기반 고장진단', '1-D Convolutional Neural Network', 'Wheel Nut Loosening', 'Accelerometer', 'Real-time Prediction', 'Data-based Fault Diagnosis']",,"To predict the loosening state of a ehicle wheel nuts, a prediction algorithm featuring a 1-D convolutional neural network (CNN) has been proposed. After the acceleration of unsprung mass is measured, a feature matrix is obtained. Based on the feature matrix, the training stage of the 1-D CNN is conducted. Then, it is implemented using MATLAB/Simulink post data preprocessing, learning, and verification. To evaluate the prediction performance of the proposed model, we compared it with a 2-D CNN model. In addition, the robustness of the 1-D CNN model under various types of sensor noise has been analyzed."
2차원 변환과 CNN 딥러닝 기반 음향 인식 시스템에 관한 연구,2022,"['음향 데이터', 'CNN', '2차원 이미지', '증강', '앙상블 학습', 'Sound Data Set', 'CNN', '2-D data', 'Augmentation', 'Ensemble Learning']","본 논문은 일상생활에서 흔히 들을 수 있는 소리(비명소리, 박수 소리, 여러 명의 박수 소리, 자동차 지나가는 소리, 배경음 등)를 감지하는 음향 인식을 위하여, 신호처리 및 딥러닝을 적용하는 연구에 관한 것이다. 제안된 음향 인식에서는, 인식 정확도의 향상을 위해서 음향 파형의 스펙트럼, 음향 데이터의 증강, 2차원(2-D) 이미지 변환에 관한 기술들이 사용되었고, 예측의 정확도를 향상을 위한 앙상블 학습, Convolution Neural Network(CNN) 딥러닝 기술들이 적용된다. 제안된 음향 인식 기술은 실험을 통해 다양한 음향을 정확하게 인식할 수 있음을 보여준다.","This paper proposes a study on applying signal processing and deep learning for sound recognition that detects sounds commonly heard in daily life (Screaming, Clapping, Crowd_clapping, Car_passing_by and Back_ground, etc.). In the proposed sound recognition, several techniques related to the spectrum of sound waves, augmentation of sound data, ensemble learning for various predictions, convolutional neural networks (CNN) deep learning, and two-dimensional (2-D) data are used for improving the recognition accuracy. The proposed sound recognition technology shows that it can accurately recognize various sounds through experiments."
지적재조사사업에서의 무인비행장치와 Mask R-CNN을 이용한 건축물 현황 취득 방안 연구,2022,"['Cadastral Resurvey Project', 'Unmanned Aerial Vehicle', 'Deep Learning', 'Mask R-CNN', 'Building Boundary', '지적재조사사업', '무인비행장치', '딥러닝', 'Mask R-CNN', '건축물 현황']","지적재조사사업에서 건축물의 현황 파악은 지적재조사지역 측량조사 시에 수행한다. 이는 지적재조사 측량 시에 건축물 현황 조사를 추가적으로 수행해야 되므로 시간, 비용 손실이 발생하게 된다. 이를 감소하기 위해 무인비행장치 영상과 딥러닝의 Mask R-CNN 알고리즘을 적용하여 건축물에 대한 현황 추출을 진행하였다. 추출된 객체와 지상측량의 경계점 성과를 비교하였다. 비교 결과 RMSE X=0.072m, Y=0.062m로 지적재조사사업에 적용 가능한 값을 도출하였다. 하지만 건축물 현황 추출률이 약 50%이며 추출된 객체의 정확도가 낮은 건축물도 발생하였다. 이는 훈련데이터의 부족 등으로 건축물 명확하게 인식하지 못한 것으로 판단된다. 향후 데이터의 축적과 딥러닝 알고리즘의 발전으로 추출률이 더욱 높아진다면 향후 지적재조사사업 등 지적 분야에 적용이 가능할 것으로 판단된다.","In the cadastral re survey project, the current status of buildings is assessed during the survey of the cadastral re survey area. This results in loss of time and cost because it is necessary to additionally conduct a building status survey during the cadastral re survey. To reduce this, we applied the unmanned aerial vehicle image and the Mask R-CNN algorithm of deep learning to extract the current status of the building. The performance of the extracted object and the boundary point of the ground survey was compared. As a result of comparison, RMSE X = 0.072m, Y = 0.062m, a value applicable to the cadastral resurvey project was derived. However, the extraction rate of the building status was about 50%, and there were also buildings with low accuracy of the extracted objects. It is judged that the building was not clearly recognized due to the lack of training data. If the extraction rate is further increased due to the accumulation of data and the development of deep learning algorithms in the future, it is judged that it can be applied to cadastral fields such as cadastral resurvey project in the future."
현장 안전사고 예방을 위한 패스터 R-CNN 기반 작업자와 기계 상호간섭 범위탐지 모델 제안 및 검증,2022,"['머신러닝', '건설 안전 관리', '딥 러닝', '패스터 R-CNN', '시각 검사 모델', '이미지 분석', 'Machine Learning', 'Construction Safety Management', 'Deep Learning', 'Faster R-CNN', 'Visual Inspection Model', 'Image Analysis']","건설공사의 안전관리는 공사 일정 및 현장 실시에 큰 영향을 미친다. 그러나 현재 현장 안전감시 방법은 육체노동 의존도가 높다. 따라서 내용 누락과 같은 인적 오류가 발생할 수 있다. 이러한 문제를 해결하기 위해 본 연구는 기계학습 시각 감지 알고리즘을 적용하여 건설 현장 작업자의 위험 행동을 식별함으로써 근로자의 외부 모니터링을 강화하고 안전사고 발생을 어느 정도 줄일 수 있다. 본 논문은 객체 감지 알고리즘과 공간 위치 파악 관계 정의를 결합한 방법을 제안한다. 건설 현장의 기계와 작업자만 정확하게 감지하면 되고, 공간 위치 관계의 정의를 활용해 위험한 행동을 파악할 수 있다. 첫째, 본 연구에 적합한 모니터링 네트워크 프레임워크는 건설 현장의 환경 특성 및 이미지 특성에 맞게 구축되었다. 그런 다음 건설 현장의 시각 탐지 데이터를 얻기 위해 컴퓨터가 Faster R-CNN 알고리즘을 기반으로 한 건설 이미지에서 기계와 작업자를 탐지한다. 마지막으로 이미지에서 기계와 작업자의 위치 관계를 결정하기 위해 세 가지 공간 개념이 정의된다. 그리고 건설 현장에서 감지된 기계 및 작업자의 위치정보와 결합하여 시각화된 형태로 제시한다. 연구의 결과를 바탕으로 건설 안전관리 사업의 정보화, 지능화에 새로운 기술 지원되기를 바란다.","Safety management of construction projects have a significant impact on the construction project’s schedule and the control carried out on site. Current site safety monitoring methods are highly dependent on manual labor; human errors can occur through missing content. This study aims to resolve these issues by applying machine learning visual detection algorithms to identify unsafe behaviors of workers at construction sites, to enhance external monitoring of workers and to relatively reduce the occurrence of safety accidents. A proposed method combines an object detection algorithm and spatial localization relationship definition. Only the machinery and workers at the construction site need to be accurately detected and the definition of spatial location relationship can be used to identify dangerous behaviors. A monitoring network framework suitable for this study was constructed with the environmental characteristics and image features of a construction site. The machines and workers were detected from construction images based on the Faster R-CNN algorithm for a computer to obtain the visual detection data from the construction site. Three spatial concepts were defined to determine the position relationships of machines and workers in these images. The detected location information of machines and workers at the construction site were combined and presented in a visualized form. Based on the results of this research, it confirmed that the method and performance were suitable for construction site safety management, which is expected to contribute to the speed, level of accuracy and risk warning with the application of automated progress monitoring methods."
CNN 기반 MS Office 악성 문서 탐지,2022,"['MS Office', 'malicious', 'detection', 'CNN', 'deep learning']",,"Document-type malicious codes are being actively distributed using attachments on websites or e-mails. Document-type malicious code is relatively easy to bypass security programs because the executable file is not executed directly. Therefore, document-type malicious code should be detected and prevented in advance. To detect document-type malicious code, we identified the document structure and selected keywords suspected of being malicious. We then created a dataset by converting the stream data in the document to ASCII code values. We specified the location of malicious keywords in the document stream data, and classified the stream as malicious by recognizing the adjacent information of the malicious keywords. As a result of detecting malicious codes by applying the CNN model, we derived accuracies of 0.97 and 0.92 in stream units and file units, respectively."
CNN 알고리즘을 이용한 의료 영상 데이터 크기에 따른 정확성 분석,2022,"['인공지능', 'CNN', '영상', '정확성분석', 'AI', 'CNN', 'Image', 'Accuracy analysis']",최근 인공지능에 대한 관심과 활용이 증가하면서 의료 산업의 패러다임도 치료나 병원중심의 이용에서 예방과 이용자 중심으로 변화되고 있다. 이와 관련된 기술발전은 의료 빅데이터 구축과 활용을 통한 서비스 향상 및 발전으로 이어지는 사례들로 많이 구축 활용되고 있다. 이에 본 연구에서는9천여 장의 의료 영상 데이터를 기반으로 입력 영상 크기 및 훈련 회수에 따라 정확성 값을 비교하여높은 결과 값을 갖는 입력 영상 데이터 조건을 찾는다. 이렇게 함으로써 소규모 의료 영상 데이터를이용하여 높은 정확성을 확보함으로써 적은 비용으로도 질병 유무 판단에 활용할 수 있을 것이다. 이를 위해 2차원 영상 데이터 학습과 정확성 분석에 효과적인 CNN 알고리즘을 사용하여 진행한다.,
비소세포폐암 환자의 재발 예측을 위한 흉부 CT 영상 패치 기반 CNN 분류 및 시각화,2022,"['Non-Small Cell Lung Cancer(NSCLC)', 'Recurrence Prediction', 'Deep Learning', 'Classification', 'Ensemble Learning', 'Convolutional Neural Network(CNN)1', '비소세포폐암', '재발 예측', '딥러닝', '분류', '앙상블 학습', '합성곱 신경망']","비소세포폐암(NSCLC)은 전체 폐암 중 85%의 높은 비중을 차지하며 사망률(22.7%)이 다른 암에 비해 현저히 높은 암으로비소세포폐암 환자의 수술 후 예후에 대한 예측은 매우 중요하다. 본 연구에서는 종양을 관심영역으로 갖는 비소세포폐암환자의 수술 전 흉부 CT 영상 패치의 종류를 종양 관련 정보에 따라 총 다섯 가지로 다양화하고, 이를 입력데이터로 갖는사전 학습 된 ResNet 과 EfficientNet CNN 네트워크를 사용하여 단일 모델과 간접 투표 방식을 이용한 앙상블 모델, 그리고3 개의 입력 채널을 활용한 앙상블 모델에서의 실험 결과 및 성능을 오분류의 사례와 Grad-CAM 시각화를 통해 비교분석한다. 실험 결과, 종양 주변부 패치를 학습한 ResNet152 단일 모델과 EfficientNet-b7 단일 모델은 각각 87.93%와81.03%의 정확도를 보였다. 또한 ResNet152 에서 총 3 개의 입력 채널에 각각 영상 패치, 종양 주변부 패치, 형상 집중 종양내부 패치를 넣어 앙상블 모델을 구성한 경우에는 정확도 87.93%를, EfficientNet-b7 에서 간접 투표 방식으로 영상 패치와종양 주변부 패치 학습 모델을 앙상블 한 경우에는 정확도 84.48%를 도출하며 안정적인 성능을 보였다.","Non-small cell lung cancer (NSCLC) accounts for a high proportion of 85% among all lung cancer and has a significantly higher mortality rate (22.7%) compared to other cancers. Therefore, it is very important to predict the prognosis after surgery in patients with non-small cell lung cancer. In this study, the types of preoperative chest CT image patches for non-small cell lung cancer patients with tumor as a region of interest are diversified into five types according to tumor-related information, and performance of single classifier model, ensemble classifier model with soft-voting method, and ensemble classifier model using 3 input channels for combination of three different patches using pre-trained ResNet and EfficientNet CNN networks are analyzed through misclassification cases and Grad-CAM visualization. As a result of the experiment, the ResNet152 single model and the EfficientNet-b7 single model trained on the peritumoral patch showed accuracy of 87.93% and 81.03%, respectively. In addition, ResNet152 ensemble model using the image, peritumoral, and shape-focused intratumoral patches which were placed in each input channels showed stable performance with an accuracy of 87.93%. Also, EfficientNet-b7 ensemble classifier model with soft-voting method using the image and peritumoral patches showed accuracy of 84.48%."
MFCCs를 이용한 입력 변환과 CNN 학습에 기반한운영 환경 변화에 강건한 베어링 결함 진단 방법,2022,"['Bearing Fault Diagnosis', 'Deep Learning', 'Distribution Difference', 'MFCCs', 'CNN', '베어링 결함 진단', '딥러닝', '분포 차이', 'MFCCs', 'CNN']",,"There have been many successful researches on a bearing fault diagnosis based on Deep Learning, but there is still a critical issueof the data distribution difference between training data and test data from their different working conditions causing performancedegradation in applying those methods to the machines in the field. As a solution, a data adaptation method has been proposed andshowed a good result, but each and every approach is strictly limited to a specific applying scenario or presupposition, which makesit still difficult to be used as a real-world application. Therefore, in this study, we have proposed a method that, using a data transformationwith MFCCs and a simple CNN architecture, can perform a robust diagnosis on a target domain data without an additional learningor tuning on the model generated from a source domain data and conducted an experiment and analysis on the proposed method withthe CWRU bearing dataset, which is one of the representative datasests for bearing fault diagnosis. The experimental results showedthat our method achieved an equal performance to those of transfer learning based methods and a better performance by at least 15%compared to that of an input transformation based baseline method."
모바일 디바이스를 위한 소형 CNN 가속기의 마이크로코드 기반 컨트롤러,2022,"['Microcode', 'Convolution Neural Network Accelerator', 'SoC', 'FPGA', '마이크로코드', '컨볼루션 뉴럴 네트워크 가속기', 'SoC', 'FPGA']","본 논문은 프로그램 가능한 구조를 사용하여 재구성이 가능하고 저 전력 초소형의 장점을 모두 제공하는 인공지능 가속기를 위한 마이크로코드 기반 뉴럴 네트워크 가속기 컨트롤러를 제안한다. 대상 가속기가 다양한 뉴럴 네트워크 모델을 지원하도록 마이크로코드 컴파일러를 통해 뉴럴 네트워크 모델을 마이크로코드로 변환하여 가속기의 메모리 접근과 모든 연산기를 제어할 수 있다. 200MHz의 System Clock을 기준으로 설계하였으며, YOLOv2-Tiny CNN model을 구동하도록 컨트롤러를 구현하였다. 객체 감지를 위한 VOC 2012 dataset 추론용 컨트롤러를 구현할 경우 137.9ms/image, mask 착용 여부 감지를 위한 mask detection dataset 추론용으로 구현할 경우 99.5ms/image의 detection speed를 달성하였다. 제안된 컨트롤러를 탑재한 가속기를 실리콘칩으로 구현할 때 게이트 카운트는 618,388이며, 이는 CPU core로서 RISC-V (U5-MC2)를 탑재할 경우 대비 약 65.5% 감소한 칩 면적을 제공한다.","This paper proposes a microcode-based neural network accelerator controller for artificial intelligence accelerators that can be reconstructed using a programmable architecture and provide the advantages of low-power and ultra-small chip size. In order for the target accelerator to support various neural network models, the neural network model can be converted into microcode through microcode compiler and mounted on accelerator to control the operators of the accelerator such as datapath and memory access. While the proposed controller and accelerator can run various CNN models, in this paper, we tested them using the YOLOv2-Tiny CNN model. Using a system clock of 200 MHz, the Controller and accelerator achieved an inference time of 137.9 ms/image for VOC 2012 dataset to detect object, 99.5ms/image for mask detection dataset to detect wearing mask. When implementing an accelerator equipped with the proposed controller as a silicon chip, the gate count is 618,388, which corresponds to 65.5% reduction in chip area compared with an accelerator employing a CPU-based controller (RISC-V)."
XAI Grad-CAM 기반 궤양병 감귤 이미지 분류 CNN 모델의 점검,2022,"['딥러닝', '비정형 데이터', '설명 가능한 인공지능', 'CNN', 'Grad-CAM', 'deep learning', 'unstructured data', 'XAI']","하드웨어의 성능 및 정보처리 기술이 급격히 발전하면서 비정형 데이터의 처리 및 가치 창출에 관한 관심이 증가하고 있다. 이를 위한 다양한 인공지능 아키텍처들이 개발되고 있으며, 모델의 의사결정 분기점이 기하급수적으로 늘어나면서 큰 성능의 개선이 이루어지고 있다. 그러나복잡한 모델 구조는 연구자의 결과 해석 용이성을 저해하는 주요한 원인이 되며, 모델 성능의발전 속도와는 달리 설명 능력에 대해서는 진척이 더딘 실정이다. 설명 가능한 인공지능, 이하XAI(eXplainable Artificial Intelligence)는 위와 같은 문제를 해결하기 위해 등장하였으며, 모델의블랙박스를 이해 가능한 수준으로 분해하여 해석 가능성 및 신뢰도 제고에 도움을 준다. 본 연구에서는 CNN(Convolutional Neural Network) 모델을 사용하여 궤양병 감귤 이미지 분류 문제에접근하였으며, 최종적으로 설계한 모델은 약 97% 수준의 정확도를 보였다. 이후 모델의 신뢰성제고 및 개선 방향 판단을 위해 XAI 기법 중 하나인 Grad-CAM(Gradient-weighted Class Activation Mapping)을 적용하였으며, 이를 통해 구축한 모델이 최종적인 판단을 내리는데 중요한 역할을한 이미지의 특정 영역을 파악하는 과정을 진행하였다. 점검 결과 이미지 외곽의 형태가 객체와구분이 되지 않아 영향을 크게 받는 경우 및 특정 객체의 고유한 형태가 오분류 원인으로 감지되었다.","By the rapid development of hardware performance and information processing technology, interest in processing unstructured data and creating value is increasing. Various types of AI architectures are being developed and as the decision-making junction of the model increased exponentially, the performance is being improved. However, complex model structure is a major cause of hindering researchers' ease of interpret results and unlike the speed of development of model performance, the progress is slow on explanatory ability.Explainable artificial intelligence (XAI) has emerged to solve this problem and decomposes the model's black box to an understandable level to help improve interpretability and reliability. In this research, we approach the ucler disease citrus image classification problem by using CNN model, and the final model showed approximately 97% accuracy. After that, to improve the reliability of the model and to determine the specific area of the image that played a major role in making the final judgment, Gradient-weighted Class Activation Mapping (Grad-CAM), one of the XAI techniques was applied. As a result of the inspection, it was detected that the shape outside the image wasn't distinguished from the object which was greatly affected. So, the unique shape of a specific object was the main cause of misclassification."
동작 인식을 위한 교사-학생 구조 기반 CNN,2022,"['양 스트림', '교사-학생 아키텍처', 'CNN', '광학 흐름', '동작 인식', 'Two-Stream Network', 'Teacher-Student Architecture', 'CNN', 'Optical Flow', 'Action Recognition']","대부분 첨단 동작 인식 컨볼루션 네트워크는 RGB 스트림과 광학 흐름 스트림, 양 스트림 아키텍처를 기반으로 하고 있다. RGB 프레임 스트림은모양 특성을 나타내고 광학 흐름 스트림은 동작 특성을 해석한다. 그러나 광학 흐름은 계산 비용이 매우 높기 때문에 동작 인식 시간에 지연을초래한다. 이에 양 스트림 네트워크와 교사-학생 아키텍처에서 영감을 받아 행동 인식을 위한 새로운 네트워크 디자인을 개발하였다. 제안 신경망은두 개의 하위 네트워크로 구성되어있다. 즉, 교사 역할을 하는 광학 흐름 하위 네트워크와 학생 역할을 하는 RGB 프레임 하위 네트워크를 연결하였다.훈련 단계에서 광학 흐름의 특징을 추출하고 교사 서브 네트워크를 훈련시킨 다음 그 특징을 학생 서브 네트워크를 훈련시키기 위한 기준선으로지정하여 학생 서브 네트워크에 전송한다. 테스트 단계에서는 광학 흐름을 계산하지 않고 대기 시간이 줄어들도록 학생 네트워크만 사용한다.제안 네트워크는 실험을 통하여 정확도 면에서 일반 이중 스트림 아키텍처에 비해 높은 정확도를 보여주는 것을 확인하였다.","Convolutional neural network (CNN) generally uses two-stream architecture RGB and optical flow stream for its action recognitionfunction. RGB frames stream display appearance and optical flow stream interprets its action. However, the standard method of usingoptical flow is costly in its computational time and latency associated with increased action recognition. The purpose of the study wasto evaluate a novel way to create a two sub-networks in neural networks. The optical flow sub-network was assigned as a teacher andthe RGB frames as a student. In the training stage, the optical flow sub-network extracts features through the teacher sub-network andtransmits the information to student sub-network for baseline training. In the test stage, only student sub-network was operational withdecreased in latency without computing optical flow. Experimental results shows that our network fed only by RGB stream gets a competitiveaccuracy of 54.5% on HMDB51, which is 1.5 times better than that on R3D-18."
"fNIRS 실험자료 기반 비즈니스 문제해결창의성 (BPSC)를 예측하기 위한 뉴로사이언스 마이닝 적용에 관한 연구: CNN, BiLSTM, 어텐션네트워크 결합을 중심으로",2022,"['Neuroscience mining (NSM)', 'Business problem-solving creativity (BPSC)', 'fNIRS', 'CNN', 'BiLSTM', 'Attention mechanism', '뉴로사이언스 마이닝', '비즈니스 문제 해결 창의성', '기능성 근적외선 분광법', '합성곱 신경망', '양방향 장단기기억 신경망', '어텐션 메커니즘']","인공지능 기술이 발달하면서 뉴로사이언스 마이닝(NSM: NeuroScience Mining)과 AI를 접목하려는 시도가 증가하고 있다. 나아가 NSM은 뉴로사이언스와 비즈니스 애널리틱스의 결합으로 인해 연구범위가 확장되고 있다. 본 연구에서는 fNIRS 실험을 통해 확보한 뉴로 데이터를 분석하여 비즈니스 문제 해결 창의성(BPSC: business problem-solving creativity)을 예측하고 이를 통해 NSM의 잠재력을 조사한다. BPSC는 비즈니스에서 차별성을 가지게 하는 중요한 요소이지만, 인지적 자원의 하나인 BPSC의 측정 및 예측에는한계가 존재한다. 본 논문에서는 BPSC 예측 성능을 높이는 방안으로 CNN, BiLSTM 그리고 어텐션 네트워크를 결합한 새로운 NSM 기법을 제안한다. 제안된 NSM 기법을 15만 개 이상의 fNIRS 데이터를 활용하여 유효성을 입증하였다. 연구 결과, 본 논문에서 제안하는 NSM 방법이 벤치마킹한 알고리즘(CNN, BiLSTM)에 비하여 우수한 성능을 가지는 것으로 나타났다.",
CNN 모델 기반의 소아 ADHD 분류 기법,2022,,,"ADHD is a disorder showing inattentiveness and hyperactivity. Since symptoms diagnosed in childhood continue to the adulthood, it is important to diagnose ADHD and start treatments in early stages. However, it has the problems to acquire enough and accurate data for the diagnosis because the mental state of children is immature using the self-diagnosis method or the computerized test. In this paper, we present the classification method based on the CNN model and execute experiment using the EEG data to improve the objectiveness and the accuracy of ADHD diagnosis. For the experiment, we build the 3D convolutional networks model and exploit the 5-folds cross validation method. The result shows the 97% accuracy on average."
합성곱신경망(CNN)을 활용하여 국내 해양레저관광지 사진 분류 및 해양레저관광 행태를 분석할 수 있는가?,2022,"['해양레저관광지', '해수욕장', '이미지 분류', '딥러닝', 'CNN', 'Marine Tourism', 'Beach', 'Image Classification', 'Deep-learning', 'Convolutional Neural Network']",,"In order to quickly respond to changes in marine tourism trends and to establish effective policies, it is necessary to prepare a reliable method for collecting data on visits. The purpose of this study is to conduct an exploratory study on the behavior of marine leisure tourism users by using images, which are unstructured data of public data and social media data, in order to analyze the characteristics of domestic marine tourism. As a research method, the possibility was proposed as a new research method by using the convolutional neural network(CNN) algorithm used for image classification based on deep learning. Supervised learning was performed by classifying behaviors based on theories based on public data and images collected through SNS. As a result of the study, the behaviors of beach users were largely classified into landscape-based and activity-based. As the supervised learning of this study did not show satisfactory results, it is necessary to classify marine leisure tourism behavior by applying the photo classification algorithm for future research. In addition, a management plan for public data was proposed for continuous research use."
"순차적 추천에서의 RNN, CNN 및 GAN 모델 비교 연구",2022,"['recommender system', 'rnn', 'cnn', 'gan', 'deep learning', 'sequence modeling', '추천 시스템', '순환 신경망', '합성곱 신경망', '생성적 적대 신경망', '순차적 모델링']","최근 추천 시스템은 영화, 음악, 온라인 쇼핑 및 SNS 등 다양한 분야들에서 광범위하게 활용되고 있으며, 추천 시스템 분야에서 1세대 모델이라고 할수 있는 Apriori 모델을 통한 연관분석부터 최근 많은 주목을 받는 딥러닝 기반 모델들까지 많은 모델들이 제안되어왔다. 추천 시스템에서 기본 모델들은 협업 필터링(Collaborative filtering) 방법, 콘텐츠 기반 필터링(Content-based filtering) 방법, 그리고 이 두 방법을 통합적으로 사용하는 하이브리드 필터링(Hybrid filtering) 방법으로 분류될 수 있다. 하지만 이러한 모델들은 최근 점점 빠르게 변화하는 사용자-아이템 간의 상호관계와 빅데이터의 발전과 같은 내외 변화 요인들에 적응하지 못하면서 점점 분야 내 방법론으로써의 지위를 잃어가고 있다. 반면, 추천 시스템 내에서 딥러닝 기반 모델들은 비선형 변환, 표현학습, 순차적 모델링, 그리고 유연성과 같은 장점들 때문에 그 비중이 높아지고 있는 추세이다. 본 논문에서는 딥러닝 기반 추천 모델들 중에서도 사용자-아이템 간의 상호작용에 대해 보다 정확하고, 유연성 있게 분석이 가능한 순차적 모델링에 적합한 순환 신경망, 합성곱 신경망, 그리고 생성적 적대 신경망 중심 기반 모델로 분류하여 비교 및 분석한다.","Recently, the recommender system has been widely used in various fields such as movies, music, online shopping, and social media, and in the meantime, the recommender model has been developed from correlation analysis through the Apriori model, which can be said to be the first-generation model in the recommender system field. In 2005, many models have been proposed, including deep learning-based models, which are receiving a lot of attention within the recommender model. The recommender model can be classified into a collaborative filtering method, a content-based method, and a hybrid method that uses these two methods integrally. However, these basic methods are gradually losing their status as methodologies in the field as they fail to adapt to internal and external changing factors such as the rapidly changing user-item interaction and the development of big data. On the other hand, the importance of deep learning methodologies in recommender systems is increasing because of its advantages such as nonlinear transformation, representation learning, sequence modeling, and flexibility. In this paper, among deep learning methodologies, RNN, CNN, and GAN-based models suitable for sequential modeling that can accurately and flexibly analyze user-item interactions are classified, compared, and analyzed."
한국과 미국 방송사의 코로나19 뉴스에 대해 CNN 기반 정량적 음성 감정 양상 비교 분석,2022,"['코로나19', '뉴스 영상', '음성 감정 분석', 'CNN', 'Covid-19', 'News videos', 'Vocal emotion detection', 'CNN']","전례 없는 코로나19 팬데믹 상황에서 대중의 정보에의 요구는 과도한 코로나19 뉴스 소비를 조장하였다. 뉴스는 대중의 심리적 안녕에도 영향을 미치기에 뉴스 보도 양태에 대한 각별한 주의가 요구된다. 이에 본 연구는 한국과 미국의 주요 뉴스 미디어의 코로나19 관련 뉴스의 음성 감정 양상을 합성곱 신경망에 기반하여 분석하였다. 분석 결과, 대부분의 뉴스 미디어에서 중립이 탐지되었으나 슬픔과 분노도 탐지되었다. 이러한 양상은한국의 뉴스 미디어에서 두드러진 반면 미국 뉴스 미디어에서는 나타나지 않았다. 본 연구는 코로나19 뉴스의 첫 음성 감정 분석 연구로, 뉴스의 감정 분석에 있어 새로운 방향을 제시할 뿐 아니라 팬데믹에 대한 이해 증진에 있어 광범위한 함의를 지닌다.","During the unprecedented COVID-19 outbreak, the public’s information needs created an environment where they overwhelmingly consume information on the chronic disease. Given that news media affect the public’s emotional well-being, the pandemic situation highlights the importance of paying particular attention to how news stories frame their coverage. In this study, COVID-19 news speech emotion from mainstream broadcasters in South Korea and the United States (US) were analyzed using convolutional neural networks. Results showed that neutrality was detected across broadcasters. However, emotions such as sadness and anger were also detected. This was evident in Korean broadcasters, whereas those emotions were not detected in the US broadcasters. This is the first quantitative vocal emotion analysis of COVID-19 news speech. Overall, our findings provide new insight into news emotion analysis and have broad implications for better understanding of the COVID-19 pandemic."
야구 경기 승패 예측을 위한 합성곱 신경망(CNN) 최적화 연구,2022,"['인공지능', '딥러닝', '빅데이터', '인공신경망', '경기분석', 'Artificial Intelligence(AI)', 'Deep Learning(DL)', 'bigdata', 'artificial neural network', 'performance analysis']","최근 야구 종목의 인공지능 기반의 승패 예측 연구는 점진적인 발전을 보이며, 머신러닝에서 딥러닝까지 다각도의 연구가 진행되고 있다. 인공지능의 학습 성능은 설계된 모델의 하이퍼 파라미터에 값에 영향을 받으며, 최적의 하이퍼 파라미터 값을 찾는 것은 인공지능 모델 설계에서 필수적인 과정이다. 이 연구는 야구 경기의 승패 예측을 위한 합성곱 신경망(CNN)의 최적화 모델을 개발하는 연구로, 성능 최적화를 위해 하이퍼 파라미터 튜닝 방법을 적용하였다. 연구의 목적 달성을 위해 이 연구는 크게 세 단계로 구분된다. 첫 번째 단계는, Sequential 기반의 합성곱 신경망 모델을 1차 개발하는 단계이다. 두 번째 단계는 첫 번째 단계에서 개발한 모델의 하이퍼 파라미터 항목을 조절하여 성능을 비교하는 실험을 10회 진행하여, 최적의 하이퍼 파라미터 값을 찾는 단계이다. 실험결과 최적 성능의 하이퍼 파라미터는 필터(커널) 크기 ‘3*3’, 학습비 ‘8:2’, 배치 사이즈 ‘32’, 에포크 ‘10’으로 결정하였다. 마지막 단계는, 결정한 하이퍼 파라미터를 적용하여 최적의 야구 승패 예측을 위한 합성곱 신경망 모델을 개발하는 단계로, 최종 모델의 성능은 정확도 '84.79', 정밀도 ‘84.84’, 재현율 ‘84.58’, F1 score ‘84.78’로 확인되었다.","Recently, artificial intelligence-based win-loss prediction study in baseball is gradual development from machine learning to deep learning. The training performance of artificial intelligence is affected by the values of the hyper parameter of the designed model. Therefore, finding optimal hyper parameter values is essential in artificial intelligence model design. This study is to develop an optimization model of a Convolutional Neural Network(CNN) for predicting the win/loss of a baseball game, and the hyper parameter tuning method was applied for performance optimization. This study consists of three steps. The first step is to develop the Sequential-based Convolutional Neural Network model. The second step is to find the optimal hyper parameter value by conducting 10 experiments to compare the performance by adjusting the hyper parameter values of the model developed in the first step. As a result of the experiments to compare, the optimal performance hyper parameter values were determined as filter (kernel) size ‘3*3’, learning ratio ‘8:2’, batch size ‘32’, and epoch ‘10’. The last step is to develop a Convolutional Neural Network model for optimal win/loss prediction by applying the determined hyper parameter values. The performance of the final model was confirmed with accuracy ‘84.79’, precision ‘84.84’, recall ‘84.58', and F1 score ‘84.78’."
컨볼루션 신경망(CNN)을 이용한 폭발물 성분 용량별 분류 성능 평가에 관한 연구,2022,,,"This paper is a study to evaluate the performance when classifying explosive components by capacity using a convolutional neural network (CNN). Among the existing explosive classification methods, the IMS steam detector method determines the presence or absence of an explosive only when the explosive concentration exceeds the threshold set by the user. The IMS steam detector has a problem of determining that even if an explosive exists, the explosive does not exist in an amount that does not exceed the threshold. Therefore, it is necessary to detect the explosive component even when the concentration of the explosive component does not exceed the threshold. Accordingly, in this paper, after imaging explosive time series data with the Gramian Angular Field (GAF) algorithm, it is possible to determine whether there are explosive components and the amount of explosive components even when the concentration of explosive components does not exceed a threshold."
Attention-CNN을 이용한 유도탄 비행데이터의 이상성 검출 기법 연구,2022,"['Monte-Carlo simulation', 'anomaly detection', 'transformer', 'attention score', 'convolutional neural networks', 'data analytics', '.']",,.
압축 왜곡 감소를 위한 CNN 기반 이미지 화질개선 알고리즘,2022,"['Computer Vision', 'Deep Learning', 'Convolutional Neural Network', 'Image Processing', 'Image Restoration', 'Image Artifacts Reduction']",,"As realistic media are widespread in various image processing areas, image or video compression is one of the key technologies to enable real-time applications with limited network bandwidth. Generally, image or video compression cause the unnecessary compression artifacts, such as blocking artifacts and ringing effects. In this study, we propose a Deep Residual Channel-attention Network, so called DRCAN, which consists of an input layer, a feature extractor and an output layer. Experimental results showed that the proposed DRCAN can reduced the total memory size and the inference time by as low as 47% and 59%, respectively. In addition, DRCAN can achieve a better peak signal-to-noise ratio and structural similarity index measure for compressed images compared to the previous methods."
합성곱 신경망(CNN) 기반 실시간 월파 감지 및 처오름 높이 산정,2022,"['artificial intelligence', 'wave-overtopping detection', 'convolutional neural networks', 'filtering algorithm', '인공지능', '월파 감지', '영상분석', '합성곱 신경망', '여과 알고리즘']","본 연구에서는 인공지능을 활용한 영상분석 기술을 통해 영상 내의 월파를 실시간으로 감지하고 처오름 높이를 산정하는 기술을 제안하였다. 본 연구에서 제안한 월파 감지 시스템은 실시간으로 악기상 및 야간에도 월파를 감지할 수 있음을 확인하였다. 특히, 합성곱 신경망을 적용하여 실시간으로 CCTV 영상에서 파랑의 처오름을 감지하고 월파 여부를 판단하는 여과 알고리즘을 적용하여 월파의 발생 감지에 대한 정확성을 향상시켰다. AP50을 통해 월파 감지 결과의 정확도는 59.6%로 산정되었으며, 월파 감지 모델의 속도는 GPU 기준 70fps로 실시간 감지에 적합한 정확도와 속도를 보임을 확인하였다.","The purpose of this study was to propose technology to detect the wave in the image in real-time, and calculate the height of the wave-overtopping through image analysis using artificial intelligence. It was confirmed that the proposed wave overtopping detection system proposed in this study could detect the occurring of wave overtopping, even in severe weather and at night in real-time. In particular, a filtering algorithm for determining if the wave overtopping event was used, to improve the accuracy of detecting the occurrence of wave overtopping, based on a convolutional neural networks to catch the wave overtopping in CCTV images in real-time. As a result, the accuracy of the wave overtopping detection through AP50 was reviewed as 59.6%, and the speed of the overtaking detection model was 70fps based on GPU, confirming that accuracy and speed are suitable for real-time wave overtopping detection."
모노 카메라를 사용하는 머신 비전 시스템에서 비정형 결함을 검사하는 CNN을 훈련하기 위한 데이터 증식 방법,2022,"['Machine Vision(머신 비전)', 'Convolutional Neural Networks(합성곱 신경망)', 'Data Augmentation (데이터 증식)', 'Image Segmentation(이미지 영역 분할)']",최근 합성곱 신경망(CNN)을 머신 비전에 적용함으로써 비정형 결함의 검사에서 우수한 검사 성능을 보이고 있다. 그러나 머신 비전 시스템에서 CNN을 훈련하기 위해 충분한 양의 데이터를 모으고 정리하는 것은 상당한 시간이 필요하다. 이 문제를 해결하기 위해 본 연구는 모노 카메라를 사용하는 머신 비전 시스템에서 CNN을 사용하여 비정형 결함을 검사할 때 사용할 수 있는 데이터 증식 방법을 제안한다. 임의의 패턴에서 비정형의 결함을 검출하기 위해 제작된 DAGM 2007 데이터 중 1번 하위 클래스 데이터를 실험 데이터로 사용하였다. 결함 검출을 위한 CNN은 Mask R-CNN ResNet 50을 사용하였다. 제안하는 방법을 통해 증식한 데이터로 훈련한 CNN이 원본 회색조 이미지로 검증을 수행했을 때 원본 데이터로 훈련한 CNN에 비해 Mask mAP@0.5:0.95 기준 평균 16.73%p 높은 61.38%의 정확도를 보이는 것을 확인했다. 본 연구에서 적용한 데이터 증식 방법을 통해 모노 카메라를 활용하는 머신 비전시스템에서 우수한 성능을 가진 CNN을 훈련할 수 있다.,"Applying convolutional neural networks (CNN) to machine vision has recently exhibited excellent performance in amorphous defect inspection. However, collecting and annotating sufficient amounts of data to train CNNs in machine vision systems take considerable time. In this study, a data augmentation method is proposed that can be used to inspect amorphous defects using CNNs in machine vision systems using mono cameras. Class 1 subdata of the DAGM 2007 dataset produced to detect defects in arbitrary patterns were used as experimental data. We trained Mask R-CNN ResNet 50 for defect inspection. Through the proposed method, we found that the CNN trained with the augmented data exhibited an average accuracy of 61.38%, which is 16.73%p higher based on Mask mAP@0.5:0.95 compared to the CNN trained with the original data when validation was performed with original grayscale images. By using the data augmentation method applied in this study, CNNs in the machine vision systems using mono cameras can achieve higher inspection performance."
A Novel Framework Based on CNN-LSTM Neural Network for Prediction of Missing Values in Electricity Consumption Time-Series Datasets,2022,"['CNN-LSTM Neural Network', 'Electricity Consumption Prediction', 'Large Gaps of Missing Values', 'Prediction of Missing Values in Time-Series Data', 'Smart Home System']",,"Adopting Internet of Things (IoT)-based technologies in smart homes helps users analyze home applianceselectricity consumption for better overall cost monitoring. The IoT application like smart home system (SHS)could suffer from large missing values gaps due to several factors such as security attacks, sensor faults, orconnection errors. In this paper, a novel framework has been proposed to predict large gaps of missing valuesfrom the SHS home appliances electricity consumption time-series datasets. The framework follows a series ofsteps to detect, predict and reconstruct the input time-series datasets of missing values. A hybrid convolutionalneural network-long short term memory (CNN-LSTM) neural network used to forecast large missing valuesgaps. A comparative experiment has been conducted to evaluate the performance of hybrid CNN-LSTM withits single variant CNN and LSTM in forecasting missing values. The experimental results indicate a performancesuperiority of the CNN-LSTM model over the single CNN and LSTM neural networks."
LIF/IF Model을 활용한 SNN/CNN Accumulator의 H/W 구현,2022,"['SNN', 'IF', 'LIF', 'FPGA']",,
CNN을 이용한 영상기반 토지이용현황조사에 관한 연구,2022,"['CNN(Convlutional Neural Network)', '토지이용현황', '영상기반 토지이용현황조사', '조사의 자동화', '조사항목 체계 재분류', 'CNN(Convolutional Neural Network)', 'Land Use Status', 'Image-based Land Use Status Survey', 'Automation of survey', 'Reclassification of survey items system']","본 연구의 목적은 효율적인 토지이용현황조사를 위해 현재 수행 중인 토지이용현황과 관련된 조사들을 분석하여 조사항목의 중복성을 검토하고 실증분석을 통해 조사항목의 자동화 방안을 제시하는 것이다. 이러한 연구의 목적을 달성하기 위하여 조사항목의 중복성과 조사의 자동화 측면으로 한정하여 수행하였다. 현행 토지이용현황과 관련된 조사들은 서로 중복된 조사항목을 개별적으로 수행하고 있어 행정력이 낭비되는 비효율적인 형태를 보이고 있다. 또한, 조사하는 방법도 직접 현장에 방문하는 방식과 위성이나 항공, 드론으로 얻어진 영상을 기반으로 하는 방식 등 각기 다른 방식으로 수행되고 있어 조사유형에 따라 상이한 결과가 나타날 수 있는 불안요소를 지니고 있으며, 특히 현장조사 방식의 경우 접근이 어려운 지역에 대한 정확한 조사가 진행되기 어렵다. 따라서 본 연구의 실험결과와 마찬가지로 중복조사 항목을 재분류하여, 하나의 조사항목 체계로 통합하고 연계 및 공유할 수 있는 환경을 구축해야 한다. 또한, 효율적인 조사 수행을 위해 영상기반의 조사가 활성화되어야 한다. 영상기반 토지이용현황조사가 이루어진다면 유사한 패턴을 보이는 조사항목에 대해 CNN(Convolutional Neural Network) 기법을 활용하여 자동으로 조사할 수 있는 방안도 함께 고려할 수 있을 것이다.","This study aims to analyze the surveys related to the current land use status for an efficient land use status survey, review the redundancy of survey items, and suggest a method for automating survey items through empirical analysis. In order to achieve the purpose of this study, it was carried out by limiting the redundancy of the survey items and the aspect of automation of the survey. Surveys related to the current state of land use show an inefficient form of wasting administrative power as they individually perform overlapping survey items. In addition, since the method of survey is carried out in different ways, such as a method of visiting the site directly and a method based on images obtained by satellite, air, or drone, there is an anxiety factor that may result in different results depending on the type of survey, In particular, in the case of an on-site survey method, it is challenging to conduct an accurate survey in an area where access is difficult. Therefore, as with the experimental results, it is necessary to reclassify the duplicated survey items to establish an environment that can be integrated, linked, and shared into a single survey item system. In addition, the image-based survey should be activated for an efficient survey. For example, suppose an image-based land use status survey is conducted, Then, a method for automatically surveying items showing a similar pattern using CNN(convolutional neural network) method may be considered."
초해상화 기반 CNN을 이용한 군사용 SAR 자동표적인식 모델 연구,2022,"['Convolutional Neural Network', 'Automatic Target Recognition', 'Synthetic Aperture Radar', 'Super-Resolution']",,"Herein, we propose employing the super-resolution-based convolutional neural network (CNN) to design the automatic target recognition (ATR) of military synthetic aperture radar (SAR) images. Previous SAR ATR methods showed a good recognition performance with a low depression angle, but poor performance with a high depression angle. In a warfighting environment, good recognition performance is required even with a high depression angle. To address this issue, we combine the super-resolution method and the CNN. In comparison with the conventional VGGnet with a high depression angle, the proposed super-resolution-based CNN showed a 3%-4% improvement in accuracy. The MSTAR SAR dataset was utilized for validation."
근전도 신호 기반 Multi-Stream CNN 및 경험적 모드 분해를 이용한 사용자 인식,2022,"['electromyogram signal', 'personal recognition', 'empirical mode decomposition', 'multi-stream convolutional neural network']",,"The Electromyogram(EMG) signal is a biosignal generated during contraction of the skeletal muscle, and different signal waveforms are generated according to the performed motion. Accordingly, it is possible to solve the problem that the registration information of the existing personal recognition method cannot be changed. In this paper, we propose a personal recognition method using EMG signal-based Empirical Mode Decomposition(EMD) and multi-stream CNN. The proposed method decomposes the EMG signal into an Intrinsic Mode Function(IMF) using EMD for increase feature data. The decomposed IMF 1-4 is used as input data to the designed multi-stream CNN to perform personal recognition. As a result of the experiment using Ninapro DB2, which is benchmarking EMG data, the method using the multi-stream CNN and the IMF showed an accuracy of 98.3%, which was 1% higher than the existing study using CNN."
MFCC 기반 환경음 분류 CNN에서 커널 사이즈와 풀링 레이어에 의한 성능분석,2022,"['인공지능', '딥러닝', '합성곱 신경망', '파이썬', '소리 분류', 'Artificial Intelligence', 'Deep Learning', 'Convolution Neural Network', 'Python', 'Sound classification']",,"Research on audio classification is being actively conducted for the improved life of the deaf and elderly, and for the development of audio-related industries. CNN(Convolutional Neural Network) is one of the neural networks used for audio classification, and is mainly used to classify images by learning the characteristics of input data on its own. Kernel size and pooling are important variables that affect the setting of the number of parameters in the CNN. This paper extracts MFCC from UrbanSound8K which is an audio dataset widely used in environmental sound classification studies and makes it learn on CNN. Under three CNN scenarios, we changed the kernel size and the number of pooling layers in each scenario, and tried to find out the relationship between the accuracy and parameter number. Through experiments, it was confirmed that both accuracy and parameters improved as the kernel size and the number of pooling layers increased."
CNN-based Adaptive K for Improving Positioning Accuracy in W-kNN-based LTE Fingerprint Positioning,2022,"['LTE fingerprint positioning', 'RSRP measurement', 'W-kNN', 'CNN', 'adaptive K']",,"In order to provide a location-based services regardless of indoor or outdoor space, it is important to provide position information of the terminal regardless of location. Among the wireless/mobile communication resources used for this purpose, Long Term Evolution (LTE) signal is a representative infrastructure that can overcome spatial limitations, but the positioning method based on the location of the base station has a disadvantage in that the accuracy is low. Therefore, a fingerprinting technique, which is a pattern recognition technology, has been widely used. The simplest yet widely applied algorithm among Fingerprint positioning technologies is k-Nearest Neighbors (kNN). However, in the kNN algorithm, it is difficult to find the optimal K value with the lowest positioning error for each location to be estimated, so it is generally fixed to an appropriate K value and used. Since the optimal K value cannot be applied to each estimated location, therefore, there is a problem in that the accuracy of the overall estimated location information is lowered. Considering this problem, this paper proposes a technique for adaptively varying the K value by using a Convolutional Neural Network (CNN) model among Artificial Neural Network (ANN) techniques. First, by using the signal information of the measured values obtained in the service area, an image is created according to the Physical Cell Identity (PCI) and Band combination, and an answer label for supervised learning is created. Then, the structure of the CNN is modeled to classify K values through the image information of the measurements. The performance of the proposed technique is verified based on actual data measured in the testbed. As a result, it can be seen that the proposed technique improves the positioning performance compared to using a fixed K value."
Snoring Sound Classification Using 1D-CNN Model Based on Multi-Feature Extraction,2022,"['Sound recognition', 'Snoring sound', 'CNN', 'Multi-feature extraction']",,"Sound is an essential element of human relationships and communication. The sound recognition process involves three phases: signal preprocessing, feature extraction, and classification. This paper describes research on the classification of snoring data used to determine the importance of sleep health in humans. However, current sound classification methods using deep learning approaches do not yield desirable results for building good models. This is because some of the salient features required to sufficiently discriminate sounds and improve the accuracy of the classification are poorly captured during training. In this study, we propose a new convolutional neural network (CNN) model for sound classification using multi-feature extraction. The extracted features were used to form a new dataset that was used as the input to the CNN. Experiments were conducted on snoring and non-snoring datasets. The accuracy of the proposed model was 99.7% for snoring sounds, demonstrating an almost perfect classification and superior results compared to existing methods."
Detection of fake news using deep learning CNN–RNN based methods,2022,"['Fake news detection', 'Deep learning', 'CNN', 'Bidirectional LSTM', 'ResNet']",,"Fake news is inaccurate information that is intentionally disseminated for a specific purpose. If allowed to spread, fake news can harm the political and social spheres, so several studies are conducted to detect fake news. This study uses a deep learning method with several architectures such as CNN, Bidirectional LSTM, and ResNet, combined with pre-trained word embedding, trained using four different datasets. Each data goes through a data augmentation process using the back-translation method to reduce data imbalances between classes. The results showed that the Bidirectional LSTM architecture outperformed CNN and ResNet on all tested datasets."
Intelligent identification of mortar void in ballastless slab track using the wheelset acceleration combined with CNN-SVM,2022,"['Ballastless slab track', 'Mortar void identification', 'Local mean decomposition', 'Hybrid CNN-SVM classifier']",,"Mortar void is a hidden defect in ballastless slab track difficult to be efficiently identified by traditional detection methods. This paper is dedicated to proposing a new detection method to identify the mortar void position and length using the vehicle response combined with the hybrid convolutional neural network-support vector machine (CNN-SVM) classifier. The vertical wheelset accelerations with different mortar void conditions are collected from a vehicle-track coupled dynamics simulation model. The first components decomposed from wheelset accelerations by local mean decomposition and their envelopes are utilized as the training data due to their sensitivity to mortar void. To improve the identification precision, the scope descent method is proposed to determine the range influenced by mortar void (IMVR) and samples are labeled according to IMVR. Meanwhile, identification results are post processed based on the mortar void characteristics. The results show that over 90 % mortar void conditions with the length of 0.65 m are detected correctly and the identification has a higher precision with the mortar void length greater than 0.95 m. The proposed technology of mortar void detection using the wheelset accelerations with the hybrid CNN-SVM classifier provides reference for engineering application, which is of great significance to relieve the pressure of health monitoring of railway track."
CNN-based fire detection method on autonomous ships using composite channels composed of RGB and IR data,2022,"['Autonomous ship Fire safety', 'Fire detection', 'RGB-IR', 'CNN', 'Composite channel data']",,"Since fires grow exponentially after an outbreak, it is crucial to extinguish them quickly. In the case of fires occurring on commercial ships and naval vessels, smoke and heat in the narrow enclosed compartments of the ships make it difficult to extinguish fires, threatening human safety, and causing massive property damage. So-called autonomous ships are operated without crew members in charge of fire suppression. Therefore, it is crucial to improve the performance and reliability of the automatic fire detection and suppression system. However, the standard fire detection system installed on ships is not adequate for the level of fire risk. Existing fire detection methods still have false alarm problems, and it takes a long time for heat and smoke from the fire to reach the detector. In this study, the use of combined channel data (RGB-IR) is proposed as an image-based fire detection method applicable to ships. In nature, many animals obtain multiple wavelength information, which is advantageous for hunting or risk preparedness in a wild environment. In this way, it is assumed that both the characteristics of RGB data in the visible area and IR data in the infrared area may be utilized through the combined channel data. A fire detection model with composite channel data input was built using deep learning with a Convolution Neural Network (CNN), a fire detection model using composite channel data input was constructed, and hyper-parameters were tuned during the training process to determine the optimal model and compare it with the existing RGB and IR models, respectively. Compared with the model using only conventional RGB or IR data, the fire detection accuracy of the model using RGB-IR combined channel data increased and the false detection rate decreased."
CNN-32DC: An improved radar-based drone recognition system based on Convolutional Neural Network,2022,"['Constant false alarm rate', 'Doppler effect', 'Drone detection', 'Micro-doppler signal processing', 'Radar']",,"This paper proposed a system that will guard infrastructures against incoming threats from drones by detecting it with the use of a radar device-based detection scheme. The database acquired, named Real Doppler RAD-DAR (Radar with Digital Array Receiver) is constructed by a Microwave and Radar Group. The radar used uses a Frequency Modulated Continuous Wave (FMCW) on an 8.75 GHz based frequency band with a BW of 500 MHz. The proposed Convolutional Neural Network (CNN), CNN-32DC is varied with different number of filters, combination layers, and number of feature extraction blocks, the preference that will give the most accurate result was selected and compared with different machine learning and classification learning algorithms gained an accuracy that exceeds other networks with less processing time."
CNN 기반 사과의 품질 등급 분류를 위한 영향력 있는 색상 채널 탐색,2022,"['딥러닝', '사과', '품질 등급', '분류', 'Deep Learning', 'Convolution Neural Network', 'Apple', 'Quality Grade', 'Classification', 'CNN']",,"During the distribution process until the sale of agricultural products, the process of determining the appearance quality of agricultural products is mainly conducted with the naked eye, resulting in uneven quality problems. In order to reduce the decline in merchantability and economic loss due to quality problems, it was intended to reduce errors in the classification process among the quality discrimination processes. To this end, a CNN-based quality grade classification study was conducted on Fuji apples, and a single color that determines the classification of quality grades among color images consisting of three channels (Red, Green, and Blue) was sought. In order to check the influence of each color, eight model structures with different numbers of layers and convolution filters were set, and experiments were conducted on five channels (RGB, Red, Green, Blue and Gray). Through this study, it was confirmed that the Blue channel is the most stable color and influential color channel in the classification of apple quality grades."
CNN-based Human Recognition and Extended Kalman Filter-based Position Tracking Using 360° LiDAR,2022,"['LiDAR (라이다)', 'CNN machine learning (CNN 머신러닝)', 'Extended kalman filter (확장 칼만 필터)', 'Occupied grid map (점유 격자 지도)']",,
SpeedyCNet : 계층적 학습기의 통과 및 단계적 분류를 통한 CNN 모델의 훈련속도 향상,2022,"['딥러닝', 'CNN모델', '훈련속도 향상', '이미지 분류', '모델 아키텍처', 'Deep learning', 'CNN Model', 'Acceleration of training time', 'Classification', 'Architecture']",,
CNN-LSTM 기반 낙상 감지 시스템 구현,2022,"['Deep learning', 'CNN', 'RNN', 'LSTM', 'Fall Detection']",,
CNN-LSTM을 사용한 긴 주기 펄스 레이다 신호 속성 분류,2022,"['Radar Signal Classification', 'CNN', 'LSTM', 'Pulsed Radar Signal Attributes']",,
걸음걸이와 CNN을 활용한 스마트폰 인증 시스템,2022,"['human gait', 'convolutional neural network', 'authentication']",,"In a society centered on hyper-connectivity, as important as information sharing is that each piece of information must be viewed only by legitimate users. In this study, we propose a smartphone authentication system based on human gait, breaking away from the traditional authentication method. After learning human gait with CNN, it is mounted on a smartphone to determine whether the user is a legitimate user by walking for 7 seconds while carrying the smartphone. Accuracy, precision, recall, F1-score, and EER were applied as evaluation indicators of the model proposed in this study. As a result, accuracy, precision, recall, and F1-score all achieved an average of 95% or more, and the average EER was 0.048. What the system analysis results show is that the system proposed in this study has high reliability and low error rate. As a result, this study showed the possibility that human gait could be used as a new user authentication method."
시분할 CNN-LSTM 기반의 시계열 진동 데이터를 이용한 회전체 기계 설비의 이상 진단,2022,"['Anomaly Detection', 'Fault Diagnosis', 'CNN-LSTM']",,
A 1D CNN-LSTM using Wav2vec 2.0 for Violent Scene Discrimination,2022,"['Violent scene discrimination', 'Wav2vec 2.0', 'Audio signal processing']",,"In this paper, an effective system for discriminating violent scenes in movies from audio signals alone is proposed. The technology for automatic discrimination of violent scenes is one of the most crucial aspects of media filtering, protecting users from undesired media. Previous studies have conducted violent scene discrimination using a mel spectrogram and 2D convolutional neural networks (CNNs); however, the mel spectrogram cannot extract mutual information from audio, and 2D CNNs are unsuitable for audio. Therefore, these models do not yield good performance. The system proposed in this paper extracts audio features by using Wav2vec 2.0, which can extract mutual information from audio. The features of the extracted audio are inputted to a 1D CNN and long short-term memory (LSTM), which are algorithms suitable for audio, and violent scenes are discriminated through fully connected and softmax layers. To evaluate the proposed system, violent scenes are discriminated using the Violent Movie Scenes Dataset (VMD). As a result, the accuracy of the proposed system when discriminating violent scenes is 96.25%, providing better performance than in previous studies."
[응용논문] 음향신호를 이용한 모터 기어 박스 모듈의 CNN기반 2단계 불량 검출 기법,2022,"['Fault detection(불량진단)', 'CNN(합성곱 신경망)', 'Audio classification(오디오 분류)', 'Mel-spectrogram(멜 스펙트로그램)', 'Motor gear box(모터 기어 박스)']",,
손사보 악보의 광학음악인식을 위한 CNN기반의 보표 및 마디 인식,2022,"['Convolutional Neural Network', 'Handwritten music sheet', 'Measure detection', 'Staff-line detection']",,"With the development of computer music notation programs, when drawing sheet music, it is often drawn using a computer. However, there are still many use of hand-written notations for educational purposes or to quickly draw sheet music such as listening and dictating. In previous studies, OMR focused on recognizing the printed music sheet made by music notation program. the result of handwritten OMR with camera is poor because different people have different writing methods, and lens distortion. In this study, as a pre-processing process for recognizing handwritten music sheet, we propose a method for recognizing a staff using linear regression and a method for recognizing a bar using CNN. F1 scores of staff recognition and barline detection are 99.09% and 95.48%, respectively. This methodologies are expected to contribute to improving the accuracy of handwriting."
DFU_SPNet: A stacked parallel convolution layers based CNN to improve Diabetic Foot Ulcer classification,2022,"['Diabetic Foot Ulcer', 'Parallel convolution', 'Convolutional neural network', 'Classification']",,"Diabetic Foot Ulcer (DFU) is a complication of diabetes that causes lower limb amputation. In this work, a unique stacked parallel convolution layers-based network (DFU_SPNet) is proposed to perform DFU vs. normal skin classification. The main objective of this work is to design an effective CNN-based classification model, along with proper fine-tuning of optimizer settings. DFU_SPNet consists of 3 blocks of parallel convolution layers with multiple kernel sizes, for local and global feature abstractions. The proposed DFU_SPNet, trained using SGD (with momentum) optimizer with learning rate on the DFUNet dataset, outperformed the current state-of-the-art results with an AUC of 0.974."
CNN을 이용한 불가사리 인식,2022,"['North-pacific sea star', 'Bat sea star', 'Detection', 'Unmanned underwater vehicle', 'Deep neural network', '아무르 불가사리', '별 불가사리', '검출', '수중드론', '심층신경망']","불가사리는 우리나라의 패류 양식업에 많은 피해를 주고 있다. 불가사리는 놀라운 재생력과생존력이 있어서 퇴치를 하기 위해서는 포획을 하는 것이 가장 좋은 방법이다. 본 연구는 수중드론을 이용하여 포획한다는 것을 가정하였다. 수중드론이 유영하면서 촬영한 해저의 바닥의 영상에서 비스듬하게 보이는 불가사리를 전이학습된 YOLOv5를 이용하여 검출한 후, 접근하여 위에서 불가사리를 내려다 보면서 포획한다. 거제, 통영 앞바다에서 촬영된 영상을전처리 없이 학습시켰음에도 아무르 불가사리를 91.5%, 별불가사리는 81.0%의 비교적 높은검출 정밀도를 보였다.","Sea stars give a lot of damage to the shellfish aquaculture industry in Korea. Sea stars have amazing regenerative and survivability, so catching them is the best way to get rid of them. In this study, it was assumed that capture using an underwater drone. In the images of the bottom of the sea floor taken by an underwater drone swimming, oblique sea stars are detected using the transfer-learned YOLOv5, then approaches and captures the sea stars while looking down at them from above.Even though the images taken off the coast of Geoje and Tongyeong were trained without pre-processing, 91.5% for North-pacific sea stars and 81.0% for bat sea stars showed relatively high detection accuracy."
"전처리 되지 않은 진동 신호로 플랭크 웨어 예측하는 1D-CNN, 2D-CNN과 LSTM로 구성된 인공지능 네트워크",2022,"['툴 상태 감시', '합성곱 신경망', '장단기 메모리', '플랭크웨어', '1차원 CNN', '2차원 CNN', 'Tool Condition Monitoring', 'Convolutional Neural Network', 'Long Short Term Memories', 'Frack wear', '1D-CNN', '2D-CNN']",,"Turning processing machines have been widely employed due to their precision and versatility. As the number of cycles increases, the performance of these devices generally degrades owing to tool wear. Therefore, real-time tool condition monitoring (TCM) that utilizes statistical or machine learning methods has gained significant attention in both academia and industry. However, these methods necessitate sufficient data pre-processing, requiring a high degree of academic understanding as well as significant amount of time. Therefore, this research proposes an advanced artificial intelligence network to monitor a wide range of tools by utilizing raw signals without pre-processing. This study first developed a method consisting of 1D and 2D multi filters convolution neural networks (CNNs) and stacked long short term memories (LSTM). To activate the LSTM in a stable manner, the CNN plays a crucial role in dimensionality reduction. Accordingly, two dimensionality reduction approaches were proposed. These were layer normalized 1D&2D-CNN Multi filters. Then, following multi filters, the stacked LSTM was used to extract the sequential features. Next, the performance of the proposed network using the NASA milling dataset was observed and compared between the 1D/2D-CNN without Flank wear information, pre-processing, and previous research network inclusion. Consequently, although the 1D-CNN method did not have them, it achieved a similar level of accuracy as the present method using past Flank wear input."
Mask R-CNN-based Occlusion Anomaly Detection Considering Orientation in Manufacturing Process Data,2022,"['Manufacturing process', 'Orientation', 'Object detection', 'Mask R-CNN', 'Anomaly detection']",,"In a manufacturing process, data analysis is conducted to identify defective products in real time to lower their massive production and improve the rate of efficient production. In the production process, it is difficult to find defective products mixed with normal products. Therefore, it is necessary to detect defective products generated in the production process and reduce the risk of their production. Consequently, this study proposes the Mask R-CNN-based occlusion anomaly detection method in consideration of the orientation of manufacturing process data. The proposed method uses Mask R-CNN to find abnormal objects, such as occluded objects, in a manufacturing process line. In the manufacturing process, some products are hidden. Accordingly, preprocessing in consideration of multiple orientations is applied to generate data. The generated data is performed to detect occlusions and anomalies using Mask R-CNN. The mean of IoU was compared to evaluate the detection accuracy of YOLO and Mask R-CNN. YOLO showed excellent performance when there was a constant distance and orientation and no occluded object. However, Mask R-CNN performed excellently when there was any occluded object and the orientation was considered. Therefore, for occlusion anomaly detection in a manufacturing process, Mask R-CNN can reduce the production rate of defective products."
CNN 기반의 이미지 특징과 객체 정보를 결합한 내용 기반 이미지 검색 기법,2022,"['image retrieval', 'CNN', 'object recognition', 'image feature']",,"Contents-based image retrieval (CBIR) method is to find an similar image to the query image among the image database. Recently, the methods extracting the image features using a deep neural network such as the Convolution Neural Network (CNN) have been proposed. These methods can retrieve similar images by comparing the global deep features of images, but it is difficult to retrieval images using specific object information in the image. In this paper, we proposes a new image feature extraction method that combines the CNN based image features and recognized objects’ information. In addition, a new similarity metric combining RBF(Radial Basis Function) and Jaccard Distance for the proposed image feature extraction method. In order to show the superiority of the proposed method, we perform experiments comparing the proposed method and the CNN based CBIR method. Through the experiments, it is shown that the accuracy of the proposed method is more than twice as much as CNN based CBIR method."
A Read Disturbance Tolerant Phase Change Memory System for CNN Inference Workloads,2022,"['Phase-change memory', 'read disturbance error', 'CNN inference', 'non-volatile memory', 'reliability']",,"Phase-change memory (PCM) garners attention as the most promising nonvolatile memory (NVM). In particular, PCM is suitable for applications that are not memory intensive, and the convolutional neural network (CNN) inference is widely known as a representative computation- intensive model. Therefore, CNN inference seems to be very suitable for a PCM-based system. However, the PCM suffers from the characteristic of being vulnerable to disturbance errors. In particular, read disturbance error (RDE) becomes a serious problem for workloads involving a large number of zeros, and unfortunately, matrices in CNN are sparse, which inevitably incurs a significant amount of RDEs. In this paper, we present an RDE-tolerant PCM-based system for CNN inference workloads. The proposed method restores vulnerable data words by leveraging a dedicated SRAM-based table. Furthermore, we also propose a replacement policy, which detects non-urgent entries, by utilizing the contents (i.e., counters) in the table. As a result, the proposed method significantly reduces RDEs with minor speed degradation."
Contactless User Identification System using Multi-channel Palm Images Facilitated by Triple Attention U-Net and CNN Classifier Ensemble Models,2022,"['Palm-based Identification', 'Contactless Identification System', 'Multi-channel image', 'Attention U-Net', 'Ensemble of Pre-trained CNN Models', '손바닥 기반 신원 인식', '비접촉식 신원 인식 시스템', '멀티채널 영상', '어텐션 유넷', 'CNN 모델 앙상블']","본 논문에서는 기존의 스마트폰 카메라 센서를 사용하여 비접촉식 손바닥 기반 사용자 식별 시스템을 구축하기 위해 Attention U-Net 모델과 사전 훈련된 컨볼루션 신경망(CNN)이 있는 다채널 손바닥 이미지를 이용한 앙상블 모델을 제안한다. Attention U-Net 모델은 손바닥(손가락 포함), 손바닥(손바닥 미포함) 및 손금을 포함한 관심 영역을 추출하는 데 사용되며, 이는 앙상블 분류기로 입력되는 멀티채널 이미지를 생성하기 위해 결합 된다. 생성된 데이터는 제안된 손바닥 정보 기반 사용자 식별 시스템에 입력되며 사전 훈련된 CNN 모델 3개를 앙상블 한 분류기를 사용하여 클래스를 예측한다. 제안된 모델은 각각 98.60%, 98.61%, 98.61%, 98.61%의 분류 정확도, 정밀도, 재현율, F1-Score를 달성할 수 있음을 입증하며, 이는 저렴한 이미지 센서를 사용하고 있음에도 불구하고 제안된 모델이 효과적이라는 것을 나타낸다. 본 논문에서 제안하는 모델은 COVID-19 펜데믹 상황에서 기존 시스템에 비하여 높은 안전성과 신뢰성으로 대안이 될 수 있다.","In this paper, we propose an ensemble model facilitated by multi-channel palm images with attention U-Net models and pretrained convolutional neural networks (CNNs) for establishing a contactless palm-based user identification system using conventional inexpensive camera sensors. Attention U-Net models are used to extract the areas of interest including hands (i.e., with fingers), palms (i.e., without fingers) and palm lines, which are combined to generate three channels being ped into the ensemble classifier. Then, the proposed palm information-based user identification system predicts the class using the classifier ensemble with three outperforming pre-trained CNN models. The proposed model demonstrates that the proposed model could achieve the classification accuracy, precision, recall, F1-score of 98.60%, 98.61%, 98.61%, 98.61% respectively, which indicate that the proposed model is effective even though we are using very cheap and inexpensive image sensors. We believe that in this COVID-19 pandemic circumstances, the proposed palm-based contactless user identification system can be an alternative, with high safety and reliability, compared with currently overwhelming contact-based systems."
Mask R-CNN에 의한 자동차 탐지에서 학습 영상 화면 축척과 촬영계절이 정확도에 미치는 영향 분석,2022,"['딥러닝', 'Mask R-CNN', '원격탐사', '객체탐지', 'Deep Learning', 'Mask R-CNN', 'Remote Sensing', 'Object Detection']","본 연구에서는 딥러닝 객체탐지 기법의 정확도 향상을 위해 항공사진과 드론 영상을 대상으로 확대율 조건과 계 절요인이 탐지정확도에 미치는 영향을 실험을 통해 분석하였다. 딥러닝 객체탐지기법 중 빠른 학습 속도와 높은 정 확도를 나타내는 Mask R-CNN을 사용하여 탐지대상인 자동차를 픽셀 단위로 탐지하고자 하였다. ‘서울시 항공사 진서비스’를 통해 화면 확대 레벨을 달리하며 학습 영상을 캡처하고 각각을 학습하여 정확도를 분석하였다. 실험결 과에 따르면 확대 레벨이 높아질수록 mAP 평균이 60%, 67%, 75%로 높아졌다. 데이터 세트의 train, test 데이터의 확대율을 엇갈려서 배치한 경우에는 확대율이 매우 낮은 경우를 제외하고 저배율의 데이터를 train 데이터로, 고배 율의 데이터를 test 데이터로 배치하였을 때 높은 mAP로 반대의 경우보다 20% 이상 차이를 보였다. 그리고 4개월 의 시차로 계절적 차이를 두고 촬영한 드론 영상의 경우, 같은 시기 영상자료 학습결과가 평균 93%로 높은 정확도 를 나타내어 계절적 차이도 학습에 영향을 주는 것을 확인되었다.","In order to improve the accuracy of the deep learning object detection technique, the effect of magnification rate conditions and seasonal factors on detection accuracy in aerial photographs and drone images was analyzed through experiments. Among the deep learning object detection techniques, Mask R-CNN, which shows fast learning speed and high accuracy, was used to detect the vehicle to be detected in pixel units. Through Seoul's aerial photo service, learning images were captured at different screen magnifications, and the accuracy was analyzed by learning each. According to the experimental results, the higher the magnification level, the higher the mAP average to 60%, 67%, and 75%. When the magnification rates of train and test data of the data set were alternately arranged, low magnification data was arranged as train data, and high magnification data was arranged as test data, showing a difference of more than 20% compared to the opposite case. And in the case of drone images with a seasonal difference with a time difference of 4 months, the results of learning the image data at the same period showed high accuracy with an average of 93%, confirming that seasonal differences also affect learning."
Performance evaluation of mask R-CNN for lung segmentation using computed tomographic images,2022,"['Mask R-CNN', 'Segmentation', 'Network architecture', 'Optimizer', 'Computed tomography']",,"Image segmentation techniques based on machine learning are able to improve diagnostic and therapeutic accuracy by localizing target areas. The accuracy and efciency of these techniques are dependent on network architecture and loss minimization method because the performance of a machine learning model is determined by training strategies. In this study, the lung segmentation based on computed tomographic images was performed by using mask regional convolutional neural networks (R-CNNs) with various feature extraction networks and optimizers. The efects of the feature extraction networks and optimizers on the trained mask R-CNNs were evaluated in terms of total training loss, segmentation accuracy and training time. The results showed that the convergence of total loss values during network training was afected by the architectures of the feature extraction networks as well as the optimizers. The lung segmentation accuracy and training time of the mask R-CNN were mainly dependent on the optimizer and network architecture, respectively. Among the various optimizers, the ASGD optimizer maximized lung segmentation accuracy, and the training time was reduced by the feature extraction network including general convolution layers and feature pyramid network (FPN). In conclusion, it is important to apply the optimal network architecture and optimizer to the mask R-CNN for maximizing its performance, and the optimized mask R-CNN can be potentially used for improving diagnostic and therapeutic accuracy."
Comparison of Multi-Label U-Net and Mask R-CNN for panoramic radiograph segmentation to detect periodontitis,2022,"['Radiography', 'Panoramic', 'Deep Learning', 'Periodontitis', 'Tooth']",,"Purpose: Periodontitis, the most prevalent chronic inflammatory condition affecting teeth-supporting tissues, is diagnosed and classified through clinical and radiographic examinations. The staging of periodontitis using panoramic radiographs provides information for designing computer-assisted diagnostic systems. Performing image segmentation in periodontitis is required for image processing in diagnostic applications. This study evaluated image segmentation for periodontitis staging based on deep learning approaches. Materials and Methods: Multi-Label U-Net and Mask R-CNN models were compared for image segmentation to detect periodontitis using 100 digital panoramic radiographs. Normal conditions and 4 stages of periodontitis were annotated on these panoramic radiographs. A total of 1100 original and augmented images were then randomly divided into a training (75%) dataset to produce segmentation models and a testing (25%) dataset to determine the evaluation metrics of the segmentation models. Results: The performance of the segmentation models against the radiographic diagnosis of periodontitis conducted by a dentist was described by evaluation metrics(i.e., dice coefficient and intersection-over-union [IoU] score). MultiLabel U-Net achieved a dice coefficient of 0.96 and an IoU score of 0.97. Meanwhile, Mask R-CNN attained a dice coefficient of 0.87 and an IoU score of 0.74. U-Net showed the characteristic of semantic segmentation, and Mask R-CNN performed instance segmentation with accuracy, precision, recall, and F1-score values of 95%, 85.6%, 88.2%, and 86.6%, respectively. Conclusion: Multi-Label U-Net produced superior image segmentation to that of Mask R-CNN. The authors recommend integrating it with other techniques to develop hybrid models for automatic periodontitis detection."
Comparison of Multi-Label U-Net and Mask R-CNN for panoramic radiograph segmentation to detect periodontitis,2022,"['Radiography', 'Panoramic', 'Deep Learning', 'Periodontitis', 'Tooth']",,"Purpose: Periodontitis, the most prevalent chronic inflammatory condition affecting teeth-supporting tissues, is diagnosed and classified through clinical and radiographic examinations. The staging of periodontitis using panoramic radiographs provides information for designing computer-assisted diagnostic systems. Performing image segmentation in periodontitis is required for image processing in diagnostic applications. This study evaluated image segmentation for periodontitis staging based on deep learning approaches.Materials and Methods: Multi-Label U-Net and Mask R-CNN models were compared for image segmentation to detect periodontitis using 100 digital panoramic radiographs. Normal conditions and 4 stages of periodontitis were annotated on these panoramic radiographs. A total of 1100 original and augmented images were then randomly divided into a training (75%) dataset to produce segmentation models and a testing (25%) dataset to determine the evaluation metrics of the segmentation models.Results: The performance of the segmentation models against the radiographic diagnosis of periodontitis conducted by a dentist was described by evaluation metrics (i.e., dice coefficient and intersection-over-union [IoU] score). Multi- Label U-Net achieved a dice coefficient of 0.96 and an IoU score of 0.97. Meanwhile, Mask R-CNN attained a dice coefficient of 0.87 and an IoU score of 0.74. U-Net showed the characteristic of semantic segmentation, and Mask R-CNN performed instance segmentation with accuracy, precision, recall, and F1-score values of 95%, 85.6%, 88.2%, and 86.6%, respectively.Conclusion: Multi-Label U-Net produced superior image segmentation to that of Mask R-CNN. The authors recommend integrating it with other techniques to develop hybrid models for automatic periodontitis detection."
CNN 기반 CCTV 동영상 내 보행자 응급 상황 자동 감지 기술 연구,2022,"['응급상황', '영상인식', 'Deep Learning', 'YOLO', 'Emergency', 'Image Recognition', 'CCTV', '딥러닝']",,"Since most medical emergencies including cardiac arrest and stroke happen unexpectedly, it is critical to recognize and respond to the situations immediately. In this paper, we propose an AI-based system which recognizes automatically medical emergencies where pedestrians fall unexpectedly due to their health problems captured in real-time video clips from CCTVs and locates the geometric position on a map on a web page to provide with prompt first aids. To this end, we extend the YOLO (You Only Look Once) network, a variant of the Convolutional Neural Network (CNN) which is suitable for 2D still images, not video. Though many researchers have studied on the methods dedicated to recognize objects in video, with a belief that CNN is not enough to recognize motions, we show that it is possible to build a robust but simple medical emergency detection system by extending the YOLO network - a variant of CNN - that only handles 2D images. Also, we report the performance of the proposed system in four performance measures in this paper."
심혈관 상태 식별을 위한 CNN Block 구조를 적용한 고성능 ECG 데이터 분석시스템,2022,"['CNN block structure', 'ECG data analysis scheme', 'ResNeXt', 'MIT-BIH database', 'F1-score']",,
A Painting Style System using an Improved CNN Algorithm,2022,"['CNN', 'Style rendering', 'Artificial neural network', 'Artistic style']",,"The rapid development of deep learning technology allows ordinary people to create artwork that imitates the style of paintings by famous masters through an algorithm. To create such works with artistic style, this research proposes an artificial neural network algorithm based on an improved convolutional neural network (CNN). First, a fast style-rendering model based on the improved CNN is constructed, and then, a server front end is built with the Bootstrap framework. The server-side back end of the system is built by combining a Python algorithm and a web framework, and finally, a complete model of the front-end and back-end network of the style rendering system is constructed. The model proposed in this paper is compared with two other models to verify its performance. The results show that information entropy of the model constructed is the highest at 5.58, which is higher than information entropy of the other two models. The average gradient value and the peak signal-to-noise ratio under the constructed model are 22.54 and 27.81, respectively, which are also higher than the other two models. Mutual information and the structural similarity index between rendered images and sample images under all three models were compared. Mutual information and structural similarity index of the model constructed by this research are 1.19 and 0.56, respectively, with much larger data sizes than the two comparison models."
Mask R-CNN 기반 심층학습을 이용한 개체영상의 인공지능 학습데이터 구축,2022,"['어노테이션', '학습데이터', '인스턴스 분할', '개체영상', 'Mask R-CNN', 'Annotation', 'Learning Data', 'Instance Segmentation', 'Object Image']","본 논문에서는 심층학습을 이용한 개체영상의 인공지능 학습데이터 구축을 제안한다. 이를 위해 전이학습의 Mask R-CNN 모델을 이용하여 영상의 개체들을 각각 인스턴스 분할하고, 분할된 개체를 대상으로 경계상자 좌표와 인스턴스를 이용하여 배경을 제거한 개체영역만을 추출한 후 데이터베이스를 구축한다. 여기서 인스턴스 분할은 동일한 클래스 내의 개체들을 분할하기 위함이고, 배경의 제거는 순수 개체영역만으로 구성된 학습데이터를 얻기 위함이다. 제안된 방법을 임의의 크기를 가진 시설작물 RGB 딸기영상 40장과 DermQuest 피부병변 영상 82장을 대상으로 잎과 병변의 개체로 구성된 학습데이터 구축에 적용하여 실험한다. 실험의 결과, 평균 정확도와 평균 재현율에서 우수한 성능을 가진 학습데이터의 구축이 가능함을 알 수 있다. 또한 각 개체의 추출을 자동화함으로써 어노테이션에 소요되는 시간을 크게 줄일 수 있다. 특히 딸기영상의 경우 여러 개의 잎들이 중첩된 경우에도 개체의 분할성능이 우수하여 데이터의 추출이 잘 이루어짐을 확인하였다.","In this paper, we propose the construction of artificial intelligence learning data of object images using deep learning. To this end, each instance of the image objects is segmented using the Mask R-CNN model of transfer learning, and only the object area from which the background has been removed using the bounding box coordinates and instances of the segmented object is constructed, and then the database is built. Here, the instance segmentation is to divide objects within the same class, and the background removal is to obtain learning data composed only of the pure object area. The proposed method is applied to construct learning data composed of leaves and lesions for 40 RGB strawberry images of facility crops and 82 DermQuest skin lesion images with the arbitrary size, respectively. The experiment results show that it is possible to construct training data with excellent performance in average accuracy and average recall. By automating the extraction of each object, the time spent on annotations can be significantly reduced. Especially, in the case of strawberry image, it was confirmed that data extraction was performed well because the segmentation performance of the individual was excellent even when several leaves were overlapped."
A study on road damage detection for safe driving of autonomous vehicles based on OpenCV and CNN,2022,"['OpenCV', 'CNN', 'Data augmentation', 'Histogram Equalization', 'Object accuracy.']",,"For safe driving of autonomous vehicles, road damage detection is very important to lower the potential risk. In order to ensure safety while an autonomous vehicle is driving on the road, technology that can cope with various obstacles is required. Among them, technology that recognizes static obstacles such as poor road conditions as well as dynamic obstacles that may be encountered while driving, such as crosswalks, manholes, hollows, and speed bumps, is a priority. In this paper, we propose a method to extract similarity of images and find damaged road images using OpenCV image processing and CNN algorithm. To implement this, we trained a CNN model using 280 training datasheets and 70 test datasheets out of 350 image data. As a result of training, the object recognition processing speed and recognition speed of 100 images were tested, and the average processing speed was 45.9 ms, the average recognition speed was 66.78 ms, and the average object accuracy was 92%. In the future, it is expected that the driving safety of autonomous vehicles will be improved by using technology that detects road obstacles encountered while driving."
Comparison of Performance According to Preprocessing Methods in Estimating %IMF of Hanwoo Using CNN in Ultrasound Images,2022,"['Preprocessing', 'Hanwoo', 'Ultrasound Images', 'CNN', '%IMF(Intramuscular Fat Percentage)']",,"There have been various studies in Korea to develop a %IMF(Intramuscular Fat Percentage) estimation method suitable for Hanwoo. Recently, a %IMF estimation method using a convolutional neural network (CNN), a kind of deep learning method among artificial intelligence methods, has been studied. In this study, we performed a performance comparison when various preprocessing methods were applied to the %IMF estimation of ultrasound images using CNN as mentioned above. The preprocessing methods used in this study are normalization, histogram equalization, edge enhancement, and a method combining normalization and edge enhancement. When estimating the %IMF of Hanwoo by the conventional method that did not apply preprocessing in the experiment, the accuracy was 98.2%. The other hand, we found that the accuracy improved to 99.5% when using preprocessing with histogram equalization alone or combined regularization and edge enhancement."
Comparison of Performance According to Preprocessing Methods in Estimating %IMF of Hanwoo Using CNN in Ultrasound Images,2022,"['Preprocessing', 'Hanwoo', 'Ultrasound Images', 'CNN', '%IMF(Intramuscular Fat Percentage)']",,"There have been various studies in Korea to develop a %IMF(Intramuscular Fat Percentage) estimation method suitable for Hanwoo. Recently, a %IMF estimation method using a convolutional neural network (CNN), a kind of deep learning method among artificial intelligence methods, has been studied. In this study, we performed a performance comparison when various preprocessing methods were applied to the %IMF estimation of ultrasound images using CNN as mentioned above. The preprocessing methods used in this study are normalization, histogram equalization, edge enhancement, and a method combining normalization and edge enhancement. When estimating the %IMF of Hanwoo by the conventional method that did not apply preprocessing in the experiment, the accuracy was 98.2%. The other hand, we found that the accuracy improved to 99.5% when using preprocessing with histogram equalization alone or combined regularization and edge enhancement."
Mask Region-Based Convolutional Neural Network (R-CNN) Based Image Segmentation of Rays in Softwoods,2022,"['instance segmentation', 'Mask region-based convolutional neural network (R-CNN)', 'rays', 'quantitative wood anatomy']",,"The current study aimed to verify the image segmentation ability of rays in tangential thin sections of conifers using artificial intelligence technology. The applied model was Mask region-based convolutional neural network (Mask R-CNN) and softwoods (viz. Picea jezoensis, Larix gmelinii, Abies nephrolepis, Abies koreana, Ginkgo biloba, Taxus cuspidata, Cryptomeria japonica, Cedrus deodara, Pinus koraiensis) were selected for the study. To take digital pictures, thin sections of thickness 10–15 μm were cut using a microtome, and then stained using a 1:1 mixture of 0.5% astra blue and 1% safranin. In the digital images, rays were selected as detection objects, and Computer Vision Annotation Tool was used to annotate the rays in the training images taken from the tangential sections of the woods. The performance of the Mask R-CNN applied to select rays was as high as 0.837 mean average precision and saving the time more than half of that required for Ground Truth. During the image analysis process, however, division of the rays into two or more rays occurred. This caused some errors in the measurement of the ray height. To improve the image processing algorithms, further work on combining the fragments of a ray into one ray segment, and increasing the precision of the boundary between rays and the neighboring tissues is required."
CNN 기반 선박 형광 도막 두께 측정,2022,"['Painting thickness measurement', 'Deep learning', 'Smart shipyard']",,"To reduce the number of ship painting inspections in shipyards, there are trials to use visible fluorescent paint with a thickness of paint that can be visually inspected. However, due to the problem that the paint color varies depending on the illuminance and the type of light source, the reliability of the visual inspection is not consistent depending on the inspectors. Therefore, this study proposes a painting inspection method using machine learning technique instead of visual inspection. We propose automation of paint measurements using CNN model to find color variations in captured images according to the illuminance of paint. The actual thickness value of the paint was obtained from the specimen using a contact thickness measuring device. The color model was used to create a deep learning model suitable for the thickness characteristics of the image data. As a result, the proposed CNN model can measure the thickness of the paint within ±20 μm."
ShortcutFusion++: Optimizing an End-to-End CNN Accelerator for High PE Utilization,2022,"['CNN accelerator', 'Processing element', 'Hardware utilization', 'FPGA', 'YOLO-v3']",,"ShorcutFusion [1] is an end-to-end framework that effectively maps many well-known deep neural networks (DNNs), such as MobileNet-v2, EfficientNet-B0, ResNet-50, and YOLO-v3, to a generic CNN accelerator on FPGA. Nevertheless, its processing elements are not fully utilized when supporting various networks, leading to relatively low hardware utilization (e.g., 68.42% for YOLO-v3). This study aimed to enhance the performance of ShortcutFusion and introduce ShortcutFusion++ by proposing two simple but effective techniques for eliminating unnecessary stalls in conventional design. First, the prefetching scheme was re-designed to avoid bubble cycles when feeding data to the PE array. Second, the output buffer was reconstructed to pipeline the operations of PEs and the process of writing output feature maps to off-chip memory. The experimental results show that ShortcutFusion++ achieves a PE utilization of 80.95% for the wellknown object detection network YOLO-v3, outperforming its baseline by 12.53%."
Faster R-CNN을 이용한 갓길 차로 위반 차량 검출,2022,"['위반 차량 검지', '객체분류', '딥러닝', '기계 학습', 'Traffic violoation detection', 'Object classification', 'Deep learning', 'Machine learning']",,
An   Improved   CNN   VGG19   Architecture   for   Detection   and Classification   of   Electric   Fire   Short-Circuit   Marks,2022,"['VGG19', 'CNN', 'Electric   Fire', 'Arc-beads    data', 'VGG19', '합성곱신경망', '전기화재', '용융흔']",,"In this paper, the VGG19 algorithm was used by applying the transfer learning for the classification of molten traces of electric fire arc-beads data which is one of the most used models in convolutional neural network(CNN) computer vision tasks. The most essential basis for detecting direct indications of electric fires is the melting traces of wires that occur at the site of an electric fire, depending on the severity and shape of the melting. The proposed VGG19 method was altered and used such that it could detect molten traces, and the molten trace data of the wires required for learning were created in the lab. The final validation accuracy result was 96.31% with validation loss of 0.1169. Through the result of securing such high accuracy, the possibility of using the melting trace detection algorithm to verify the presence or absence of an electric fire was shown."
Feature Extraction of Non-proliferative Diabetic Retinopathy Using Faster R-CNN and Automatic Severity Classification System Using Random Forest Method,2022,"['Faster R-CNN', 'Classification', 'Machine Learning', 'Non-proliferative Diabetic Retinopathy', 'Random Forest']",,"Non-proliferative diabetic retinopathy is a representative complication of diabetic patients and is known to bea major cause of impaired vision and blindness. There has been ongoing research on automatic detection ofdiabetic retinopathy, however, there is also a growing need for research on an automatic severity classificationsystem. This study proposes an automatic detection system for pathological symptoms of diabetic retinopathysuch as microaneurysms, retinal hemorrhage, and hard exudate by applying the Faster R-CNN technique. Anautomatic severity classification system was devised by training and testing a Random Forest classifier basedon the data obtained through preprocessing of detected features. An experiment of classifying 228 test fundusimages with the proposed classification system showed 97.8% accuracy."
Comparison of vibration visualization methods for classification of chaos based on CNN,2022,"['Vibration', 'Chaos', 'Classification', 'CNN', 'Visualization method']",,"This study assessed methods for visualizing the vibrations for chaotic systems using a time series, fast Fourier transform (FFT), threshold recurrence plot, and unthresholded recurrence plot. The image classification was then performed using CNN, and the accuracy of each visualization method was compared and analyzed. The nonlinear behavior of chaotic systems was examined using the commonly known Van der pol, Rossler, and Duffing equations. The Lyapunov exponent was calculated for each model parameter change to determine the chaos. The classification accuracy was examined for the chaotic signal in each visualization method of the proposed architecture based on VGG 16 using the determined label and image.The classification accuracy for the chaos of each visualization method is the result of signals mixed randomly five times. FFT analysis showed the highest evaluation result."
보행주기를 이용한 개인식별 CNN 모델,2022,"['gait cycle', 'convolutional neural network', 'personal identification']",,"Various studies exist to identify individuals. Personal identification research based on inertial data, that is, acceleration and angular velocity acquired with an inertial sensor, is also one of these efforts. In fact, when learning inertial data with CNN, individuals can be identified with high accuracy. However, the individual identification model using inertial data significantly lowers the identification performance when the shoes worn by the individual change. This paper deals with improving this problem by using gait cycle data extracted from inertia data. First, the CNN model using the gait cycle was implemented, and then the model was evaluated using the representative performance evaluation indicators, such as accuracy, precision, recall, and F1-score. As a result, it was confirmed that the proposed model can identify individuals with more than 90% accuracy even when the shoes worn are different."
개인 인증을 위한 CNN 기반 보행 패턴 식별,2022,"['gait analysis', 'convolutional neural network', 'personal authentication', '.']","최신의 보행 분석 연구에서 사람의 걸음걸이가 지닌 고유한 특징을 사용자 인증 수단으로 활용하려는 노력이 진행 중이다. 본 논문에서는 관성 센서로 획득한 인간의 걸음걸이 데이터를 CNN 모델로 학습하여 보행자가 누구인지 식별하는 것을 연구한다. 학습 모델의 평가지표로 흔히 사용하는 정확도, 정밀도, 재현율, F1-score, ROC Curve, AUC와 생체인증 평가지표인 FAR, FRR, EER을 활용하여 본 논문에서 제안한 모델을 평가하였다. 그 결과, 정확도, 정밀도, 재현율, F1-score 모두 99% 이상의 결과를 얻었다. 또한, 평균 AUC는 0.99, 평균 EER은 0.0009로 연구에서 제안된 모델이 높은 신뢰성을 가지고 사람의 걸음걸이를 식별할 수 있으며 사용자 인증을 위한 수단으로 사용 가능하다는 결론에 도달했다.","Efforts are underway to utilize the unique characteristics of human gait as a tool for user authentication in the latest gait analysis study. In this paper, we study the identification of pedestrians by learning human gait data acquired by an inertial sensor with a CNN model. The model proposed in this paper is evaluated using accuracy, precision, recall, F1-score, ROC Curve, AUC, which are used as general evaluation indicators, and FAR, FRR, and EER, which are biometric evaluation matrices. As a result, the accuracy, precision, recall, and F1-score are all over 99%. In addition, the average AUC is 0.99, and the average EER is 0.0009, which leads to the conclusion that the model proposed in the study can identify human gait with high reliability and can be used as a method for user authentication."
The Evaluation of Deep Learning Using Convolutional Neural Network (CNN) Approach for Identifying Arabica and Robusta Coffee Plants,2022,"['Leaf classification', 'Robusta coffee', 'Arabica coffee', 'Convolutional neural network', 'Coffee species', 'Precision agriculture']",,"Purpose Arabica and Robusta coffee plants are physically distinctive as manifested in their leaves, leaf shape, color, and size.However, for ordinary people or those who have just begun their business in coffee cultivation, identifying the type of coffee plant can be challenging. In this study, we incorporated and evaluated deep learning technology to identify the types of coffee based on leaf image identification.Methods In this study, we designed a deep learning architecture and compared it with the well-known approaches, including LeNet, AlexNet, ResNet-50, and GoogleNet. A total of 19,980 image datasets were split into training and testing data, consisting of 15,984 images and 3,996 images, respectively.Results The hyperparameters were taken into account where the use of 100 epoch and 0.0001 learning rate provided the highest accuracy. In addition, 10-fold cross-validation and ROC were used for evaluating the proposed architectures. The results show that the developed convolutional neural network (CNN) generated the highest accuracy of 97.67% compared to LeNet, AlexNet, ResNet-50, and GoogleNet with an accuracy rate of 97.20%, 95.10%, 72.35%, and 82,16%, respectively.Conclusions The modified-CNN algorithm had satisfactory accuracy in identifying different types of coffee. The underlying principles of such classification draw specific attention to the leaf shape, size, and color of Arabica and Robusta coffee. For future works, it is a potential method that can be used to rapidly identify diverse varieties of Robusta and Arabica coffee plants based on leaf tissue and above canopy characteristics."
CNN 모델을 이용한 위해 식품 알림 애플리케이션의 개발,2022,"['Hazard Food', 'CNN', 'Crawling', 'Real-time Reasoning', 'Model Quantization']",,
CNN 이미지 분류 모델을 위한 메타모픽 테스트 케이스 생성 기법,2022,"['CNN', '메타모픽 테스팅', '테스트 케이스 생성', '머신러닝 테스팅', 'metamorphic testing', 'test case generation', 'machine learning testing']",,
합성곱신경망(CNN)을 활용하여 국내 해양레저관광지 사진 분류 및 해양레저관광 행태를 분석할 수 있는가?,2022,"['해양레저관광지(Marine Tourism)', '해수욕장(Beach)', '이미지 분류(Image Classification)', '딥러닝(Deep-learning)', 'CNN(Convolutional Neural Network)']",,
Face Recognition Resear ch Based on Multi-Layer s Residual Unit CNN Model,2022,"['Face Recognition', 'CNN Model', 'Deep Learning', 'Generative Adversarial Network']",,
방향 정규화 및 CNN 딥러닝 기반 차량 번호판 인식에 관한 연구,2022,"['Licence plate recognition', 'Character segmentation', 'Character recognition', 'Direction normalization', 'Mask R-CNN']",,
관개용수로 CCTV 이미지를 이용한 CNN 딥러닝 이미지 모델 적용,2022,"['Image classification', 'image segmentation', 'CCTV images', 'irrigation canal']",,"A more accurate understanding of the irrigation water supply is necessary for efficient agricultural water management. Although we measure water levelsin an irrigation canal using ultrasonic water level gauges, some errors occur due to malfunctions or the surrounding environment. This study aims toapply CNN (Convolutional Neural Network) Deep-learning-based image classification and segmentation models to the irrigation canal’s CCTV(Closed-Circuit Television) images. The CCTV images were acquired from the irrigation canal of the agricultural reservoir in Cheorwon-gun,Gangwon-do. We used the ResNet-50 model for the image classification model and the U-Net model for the image segmentation model. Using theNatural Breaks algorithm, we divided water level data into 2, 4, and 8 groups for image classification models. The classification models of 2, 4, and8 groups showed the accuracy of 1.000, 0.987, and 0.634, respectively. The image segmentation model showed a Dice score of 0.998 and predictedwater levels showed R2of 0.97 and MAE (Mean Absolute Error) of 0.02 m. The image classification models can be applied to the automaticgate-controller at four divisions of water levels. Also, the image segmentation model results can be applied to the alternative measurement for ultrasonicwater gauges. We expect that the results of this study can provide a more scientific and efficient approach for agricultural water management."
Integrated YOLO and CNN algorithms for Evaluating Degree of Walkway Breakage,2022,"['Walkway', 'YOLO algorithm', 'Image deep learning', 'Breakage detection', 'Walking environment assessment', 'Pedestrian safety', 'Evaluation indicators']",,"The focus of policymaking in Korea has changed from vehicle-centric road environments to people-centric environments. As the importance of walking has increased, the construction of pedestrian paths and interest in pedestrian environments have also increased. However, problem recognition and resolution require considerable time in the event of a problem in a pedestrian path. People with reduced mobility tend to resist changes in roads that they use. Thus, damaged pedestrian paths and obstacles pose a considerable risk and economic loss to transportation. In this study, we aimed to minimize the time and cost required for the evaluation of pedestrian paths by developing an automatic system for determining damage using integrated You Only Look Once (YOLO) and convolutional neural network (CNN) image deep learning algorithms. We constructed a model using image deep learning by dividing the steps into walkway breakage detection and score evaluation according to the degree of breakage. The accuracy of the model was determined to be 92%. In the future, the evaluation of pedestrian path damage is expected to be automated using images and videos, thereby reducing the time required for the detection and restoration of damage."
Improved real-time power analysis attack using CPA and CNN,2022,"['Side Channel Attack', 'AES', 'CPA', 'CNN', 'ATmega328', 'Oscilloscope', '부채널 공격', '고급 암호화 표준', '차분 전력 공격', '합성곱 신경망', '오실로스코프']",,
CNN 기반 차량 밑면 중심점 검출을 통한 차량 위치 추정 정확도 개선,2022,"['Vehicle position estimation(차량 위치 추정)', 'Bottom face center(밑면 중심점)', 'Deep neural network(딥뉴럴네트워크)', 'Vehicle-to-infrastructure communication(V2I 통신)', 'Surveillance camera(감시 카메라)']",,
Image Retrieval Based on the Weighted and Regional Integration of CNN Features,2022,"['Image retrieval', 'Weighting feature', 'Global feature', 'Convolutional neural network', 'Regional integration']",,"The features extracted by convolutional neural networks are more descriptive of images than traditional features, and their convolutional layers are more suitable for retrieving images than are fully connected layers. The convolutional layer features will consume considerable time and memory if used directly to match an image. Therefore, this paper proposes a feature weighting and region integration method for convolutional layer features to form global feature vectors and subsequently use them for image matching. First, the 3D feature of the last convolutional layer is extracted, and the convolutional feature is subsequently weighted again to highlight the edge information and position information of the image. Next, we integrate several regional eigenvectors that are processed by sliding windows into a global eigenvector. Finally, the initial ranking of the retrieval is obtained by measuring the similarity of the query image and the test image using the cosine distance, and the final mean Average Precision (mAP) is obtained by using the extended query method for rearrangement. We conduct experiments using the Oxford5k and Paris6k datasets and their extended datasets, Paris106k and Oxford105k. These experimental results indicate that the global feature extracted by the new method can better describe an image."
3D-CNN Method over Shifted Patch Tokenization for MRI-Based Diagnosis of Alzheimer’s Disease Using Segmented Hippocampus,2022,"['Alzheimer’s Disease', 'Shifted Patch Tokenization', 'Convolutional Neural Network', 'Hippocampus Image Classification.']",,"The application of a potential deep learning algorithm to the diagnosis of various neuropathic diseases such as AD (Alzheimer's disease) is attracting attention. This paper describes the implementation of a potential 3D-CNN (3D-convolutional neural network) network-based method for predicting hippocampal atrophy by applying deep learning technology to magnetic resonance imaging of Alzheimer's diseaserelated patients. The proposed method is implemented by applying the HippMapp3r algorithm for hippocampal MRI (magnetic resonance image) segmentation from the original image and applying the EfficientNet tool to help determine AD. To increase the accuracy of judgment in this process, the shifted patch tokenization (SPT) method was proposed and also implemented. The proposed framework can be very helpful in diagnosing AD by showing 94% and 96% accuracy in training and test sets, respectively."
A Tuberculosis Detection Method Using Attention and Sparse R-CNN,2022,"['Tuberculosis', 'Chest X-ray', 'Computer-aided diagnosis', 'Object detection', 'Attention']",,"To achieve accurate detection of tuberculosis (TB) areas in chest radiographs, we design a chest X-ray TB area detection algorithm. The algorithm consists of two stages: the chest X-ray TB classification network (CXTCNet) and the chest X-ray TB area detection network (CXTDNet). CXTCNet is used to judge the presence or absence of TB areas in chest X-ray images, thereby excluding the influence of other lung diseases on the detection of TB areas. It can reduce false positives in the detection network and improve the accuracy of detection results. In CXTCNet, we propose a channel attention mechanism (CAM) module and combine it with DenseNet. This module enables the network to learn more spatial and channel features information about chest X-ray images, thereby improving network performance. CXTDNet is a design based on a sparse object detection algorithm (Sparse R-CNN). A group of fixed learnable proposal boxes and learnable proposal features are using for classification and location. The predictions of the algorithm are output directly without non-maximal suppression post-processing. Furthermore, we use CLAHE to reduce image noise and improve image quality for data preprocessing. Experiments on dataset TBX11K show that the accuracy of the proposed CXTCNet is up to 99.10%, which is better than most current TB classification algorithms. Finally, our proposed chest X-ray TB detection algorithm could achieve AP of 45.35% and AP50 of 74.20%. We also establish a chest X-ray TB dataset with 304 sheets. And experiments on this dataset showed that the accuracy of the diagnosis was comparable to that of radiologists. We hope that our proposed algorithm and established dataset will advance the field of TB detection."
객체 추적을 위한 보틀넥 기반 Siam-CNN 알고리즘,2022,"['Deep Learning', 'Computer Vision', 'Object Tracking', 'Convolutional Neural Networks', 'Siamese Network']",,
데이터별 딥러닝 학습 모델의 정확도 향상을 위한 외곽선 특징 적용방안 연구,2022,"['CNN', 'Contour detection', 'Data augmentation']","CNN은 딥러닝의 한 종류로 이미지나 영상 데이터를 처리할 때 사용하는 신경망이다. 필터가 이미지를 순회하며이미지의 특징을 추출하여 이미지를 구분한다. 딥러닝은 데이터가 많을수록 좋은 모델을 만들 수 있는 특징이 있고, CNN에서는 적은 데이터의 약점을 보완하기 위해 회전, 확대, 이동, 뒤집기 같은 방법의 데이터 증강이라는 기법으로데이터의 양을 인위적으로 늘리는 방법을 사용한다. 외곽선 이미지 학습은 이미지 데이터에서 외곽선에 해당하는 영역을추출하는 것이다. CNN 학습 시, 외곽선 이미지 학습이 기존의 데이터 증강기법과 비교하여 성능 향상의 도움이 되는지확인하고자 한다.","CNN is a type of deep learning and is a neural network used to process images or image data.The filter traverses the image and extracts features of the image to distinguish the image. Deep learning has the characteristic that the more data, the better models can be made, and CNN uses a method of artificially increasing the amount of data by means of data augmentation such as rotation, zoom, shift, and flip to compensate for the weakness of less data. When learning CNN, we would like to check whether outline image learning is helpful in improving performance compared to conventional data augmentation techniques."
합성곱-장단기 기억 신경망의 하이브리드 결합 모델을 이용한 부정맥 분류,2022,"['Arrhythmia', 'CNN', 'LSTM', 'Deep learning', 'MIT-BIH', '부정맥', '합성곱 신경망', '장단기 기억 신경망', '심층 신경망', 'MIT-BIH']","부정맥은 심장 박동이 비정상 혹은 불규칙하게 뛰고 있는 상태를 말하며, 실신이나 심장돌연사 등과 같은 위험한 상황을 유발할 수 있기 때문에 이의 조기 검출은 매우 중요하다.하지만 심전도 신호의 개인차로 인해 분류 시 성능하락이 나타날 수밖에 없다. 본 연구에서는 CNN-LSTM 하이브리드 결합 모델을 이용한 부정맥 분류 방법을 제안한다. 이를 위해 먼저 잡음을 제거한 ECG 신호에서 R파를 검출하고 단일 비트 세그먼트를 추출하였다. 이후 부정맥 신호의 특징을 세밀하게 추출하도록 8개의 합성곱 계층으로 구성하고 이를 LSTM의 입력으로 사용한 후 가중치를 학습시키고 검증 데이터로 모델을 평가한 후 정상 및 부정맥 분류의 변화를 확인하였다. 제안한 방법의 타당성 검증을 위해 MIT-BIH 부정맥 데이터베이스를 사용하여 정확도(accuracy), 정밀도(precision), 재현율(recall), F1 스코어가 사용되었다. 성능평가 결과, 정확도, 정밀도, 재현율, F1 스코어는 각각 92.3%, 90.98%, 92.20%, 90.72%의 우수한 분류율을 나타내었다.","Arrhythmia is a condition in which the heart beats abnormally or irregularly, early detection is very important because it can cause dangerous situations such as fainting or sudden cardiac death. However, performance degradation occurs due to personalized differences in ECG signals.In this paper, we propose arrhythmia classification using hybrid combination model of CNN-LSTM. For this purpose, the R wave is detected from noise removed signal and a single bit segment was extracted. It consisted of eight convolutional layers to extract the features of the arrhythmia in detail, used them as the input of the LSTM. The weights were learned through deep learning and the model was evaluated by the verification data.The performance was compared in terms of the accuracy, precision, recall, F1 score through MIT-BIH arrhythmia database. The achieved scores indicate 92.3%, 90.98%, 92.20%, 90.72% in terms of the accuracy, precision, recall, F1 score, respectively."
소규모 합성곱 신경망을 사용한 연령 및 성별 분류,2022,"['Age Classification', 'Gender classification', 'Unfiltered Image Recognition', 'Imbalanced Classification Problems', '나이 분류', '성별 분류', '필터링되지 않은 영상 인식', '불균형 분류 문제']","인공지능은 놀라운 이점으로 우리 삶의 중요한 부분을 차지하고 있다. 기계는 이미지에서 물체를 인식하는 것, 특히 사람들을 정확한 나이와 성별 그룹으로 분류하는 것에 있어서 인간을 능가하고 있다. 이러한 측면에서 나이와 성별 분류는 최근 수십 년 동안 컴퓨터 비전 연구자들 사이에서 뜨거운 주제 중 하나였다. 심층 합성곱 신경망(CNN) 모델의 배포는 최첨단 성능을 달성했다. 그러나 대부분의 CNN 기반 아키텍처는 수십 개의 훈련 매개 변수로 매우 복잡하기 때문에 많은 계산 시간과 자원이 필요하다. 이러한 이유로 기존 방법에 비해 훈련 매개 변수와 훈련 시간이 현저히 적은 새로운 CNN기반 분류 알고리즘을 제안한다. 덜 복잡함에도 불구하고 우리 모델은 UTKFace 데이터 세트에서 연령 및 성별 분류의 더 나은 정확도를 보여준다.",
합성곱 신경망 및 영상처리 기법을 활용한피부 모공 등급 예측 시스템,2022,"['Skin', 'Pore', 'Image processing', 'CNN', 'Prediction']","본 논문은 사용자들에 의해 촬영된 피부이미지를 가공하여 데이터 세트를 구축하고, 제안한 영상처리 기법에 의해 모공 특징이미지를 생성하여, CNN(Convolution Neural Network) 모델 기반의 모공 상태 등급 예측 시스템을 구현한다. 본 논문에서 활용하는피부이미지 데이터 세트는, 피부미용 전문가의 육안 분류 기준에 근거하여, 모공 특징에 대한 등급을 라벨링 하였다. 제안한 영상처리 기법을 적용하여 피부이미지로 부터 모공 특징 이미지를 생성하고, 모공 특징 등급을 예측하는 CNN 모델의 학습을 진행하였다.제안한 CNN 모델에 의한 모공 특징은 전문가의 육안 분류 결과와 유사한 예측 결과를 얻었으며, 비교 모델(Resnet-50)에 의한 결과보다 적은 학습시간과 높은 예측결과를 얻었다. 본 논문의 본론에서는 제안한 영상처리 기법과 CNN 적용의 결과에 대해 서술하며, 결론에서는 제안한 방법에 대한 결과와 향후 연구방안에 대해 서술한다.","In this paper, we propose a prediction system for skin pore labeling based on a CNN(Convolution NeuralNetwork) model, where a data set is constructed by processing skin images taken by users, and a pore featureimage is generated by the proposed image processing algorithm. The skin image data set was labeled for porecharacteristics based on the visual classification criteria of skin beauty experts. The proposed image processingalgorithm was applied to generate pore feature images from skin images and to train a CNN model that predictspore feature ratings. The prediction results with pore features by the proposed CNN model is similar to expertsvisual classification results, where less learning time and higher prediction results were obtained than the resultsby the comparison model (Resnet-50). In this paper, we describe the proposed image processing algorithm andCNN model, the results of the prediction system and future research plans."
합성곱 신경망과 인코더-디코더 모델들을 이용한 익형의 유체력 계수와 유동장 예측,2022,"['합성곱 신경망', '인코더-디코더', '심층학습', '익형', '전산유체역학', 'Convolutional Neural Network', 'Encoder-Decoder', 'Deep Learning', 'Airfoil', 'Computational Fluid Dynamic']",,"The evaluation of the drag and lift as the aerodynamic performance of airfoils is essential.In addition, the analysis of the velocity and pressure fields is needed to support the physical mechanism of the force coefficients of the airfoil. Thus, the present study aims at establishing two different deep learning models to predict force coefficients and flow fields of the airfoil. One is the convolutional neural network (CNN) model to predict drag and lift coefficients of airfoil. Another is the Encoder-Decoder (ED) model to predict pressure distribution and velocity vector field. The images of airfoil section are applied as the input data of both models. Thus, the computational fluid dynamics (CFD) is adopted to form the dataset to training and test of both CNN models. The models are established by the convergence performance for the various hyperparameters. The prediction capability of the established CNN model and ED model is evaluated for the various NACA sections by comparing the true results obtained by the CFD, resulting in the high accurate prediction. It is noted that the predicted results near the leading edge, where the velocity has sharp gradient, reveal relatively lower accuracies. Therefore, the more and high resolved dataset are required to improve the highly nonlinear flow fields."
Scalogram과 Switchable 정규화 기반 합성곱 신경망을활용한베이링 결함탐지,2022,"['Bearjng fault detecaon', 'deep learnjng', 'C鬪U dataset', 'swjtchable normaJjzatjon', 'scalogram', 'convoluaonaJ neural network']","베어링은 기계가 작동할때 중요한 역할을 한댜 때문에, 베어링에 결함이 발생하면 기계전체의 치명적인 결함을 발생시킨다. 그러 므로 베어링 결함은 조기에 발견되어야한댜 본 논문에서는 연속 웨이불릿 변환과 Switchable 정규회를 기반으로 한 합성곱 신경망 (SN-CNN)을 이용한 방법을 베어링 결함 감지 모델에 대해 설명한다. 모델의 정확도는 Case Western Reserve University (CWRU) 베어링 데이터 집합을 사용히여 측정되었다. 또한 배치 정규희{BN, Batch Normalization)[l] 방법과 스펙트로그램 이미 지가 모델 성능의 비교를 위해 시용되었댜","Bearing plays an important role in the operation of most machinery, Therefore, when a defect occurs in the bearing, a fatal defect throughout the machine is generated. In this reason, bearing defects should be detected early. In this paper, we describe a method using Convolutional Neural Networks (SN-CNNs) based on continuous wavelet transformations and Switchable normalization for bearing defect detection models. The accuracy of the model was measured using the Case Western Reserve University (CWRU) bearing dataset. In addition, batch normalization methods and spectrogram images are used to compare model performance. The proposed model achieved over 99% testing accuracy in CWRU dataset."
변전소 불량애자 검출을 위한 드론 EO/IR 영상 기반의 경량화 객체탐지 모델 응용 연구,2022,"['Defect Insulator', 'Light-weight deep learning', 'Real-Time Object Detection', 'Drone Surveillance', 'EO/IR Image', 'Embedded GPU']",,"This paper proposes a monitoring system of defected substation insulators based on drone EO/IR images and a light-weight deep learning model. The defected substation insulators generate corona discharge and excessive heating. Thus, this study used RGB-thermal blended images from drone EO/IR cameras to monitor insulator failures, which is not visible to naked eyes. Also, this paper compared several light-weighted object detection models to select the most suitable model to deploy on the embedded processor of drones. The applied compressed CNN model, YOLOv4 backbone with group convolution and channel shuffle operations, is sufficiently fast and light-weighted for an embedded GPU processor. Experiments with mockup insulators with corona discharge showed that the proposed system resulted 99.50% mAP, 5.9fps on embedded GPU(Jetson Nano), and has 3.9MB memory that is 37.99 times lighter than YOLOv4."
시공간 특성을 고려한 딥러닝 기반 교통 속도 예측 모델,2022,"['traffic predidction', 'deep learning', 'CNN', 'RNN', 'Attention', '.']","교통량과 속도는 지능형 교통 시스템을 구축하기 위해 필요한 가장 중요한 교통 정보이다. 최근 사물인터넷, 빅데이터, 인공지능 등의 기술 발전에 따라 다양한 딥러닝 기술들이 교통 정보 예측에 많이 활용되고 있다. 본 논문에서는 도로의 공간적 특징과 시간에 따른 속도 변화 특징을 반영하기 위하여 3개의 모델을 결합한 CNN-RNN-Attention 속도 예측 모델을 제안한다. 컨볼루션 신경망(CNN)과 순환신경망(RNN)을 활용하여 도로의 공간적 특성과 시계열 특성을 각각 학습하고, 학습된 결과에 어텐션(Attention) 기법을 적용하여 가중치를 부여함으로써 성능을 향상시켰다. 제안된 모델은 한국도로공사 링크 통행속도 데이터를 활용하여 실험을 진행하였으며, CNN 단일 모델, GRU 단일 모델 그리고 CNN과 GRU을 결합한 모델 대비 성능이 우수함을 증명하였다.","The volume and the speed of traffic are the key factors for establishing an intelligent traffic system. The latest technical accomplishments such as Internet on Things, big data and artificial intelligence made various deep learning technologies possible to be used for predicting traffic conditions. In this Paper, we propose a CNN-RNN-Attention prediction model combines three models to reflect the spatial-temporal characteristics. Convolutional Neural Network(CNN) and Recurrent Neural Network(RNN) are used to learn spatial and temporal characteristics of roads, respectively. Then we go through the attention model which improves the performance of our model by calculating the weights of CNN-RNN results. The proposed model was tested using the link speed data of Korea Expressway Corporation, and it was proved that the performance result was superior to that of the CNN single model, the RNN single model and the model which are combines CNN with RNN."
송아지 질병 결정 지원 모델,2022,,"송아지 질병 진단을 위해 사용되는 여러 데이터 중에서 분변은 질병 진단의 중요한 역할을 한다. 송아지 분변 이미지에서 형태, 색상, 질감으로 건강 상태를 알 수 있다. 건강 상태를 파악할 수 있는 분변 이미지는 분변 상태에 따라 정상 송아지 207개와 설사증 송아지 158개의 데이터를 전처리하여 사용하였다. 본 논문에서는 수집된 송아지 데이터 중에서 분변 변수의 이미지를 탐지하고 합성곱 네트워크 기술을 활용하여 질병 증상을 포함하고 있는 데이터 세트에 대해 CNN과 GLCM의 속성을 결합한 GLCM-CNN을 적용하여 이미지를 학습시켰다. CNN의 89.9% 정확도와 GLCM-CNN는 91.7%의 정확도를 보이는 GLCM-CNN는 1.8%의 높은 정확도를 나타내는 유의미한 차이가 있었다.","Among the data used for the diagnosis of calf disease, feces play an important role in disease diagnosis. In the image of calf feces, the health status can be known by the shape, color, and texture. For the fecal image that can identify the health status, data of 207 normal calves and 158 calves with diarrhea were pre-processed according to fecal status and used. In this paper, images of fecal variables are detected among the collected calf data and images are trained by applying GLCM-CNN, which combines the properties of CNN and GLCM, on a dataset containing disease symptoms using convolutional network technology. There was a significant difference between CNN's 89.9% accuracy and GLCM-CNN, which showed 91.7% accuracy, and GLCM-CNN showed a high accuracy of 1.8%."
선박용 밸브의 내부 누설 진단을 위한 음향방출신호의 머신러닝 기법 적용 연구,2022,"['밸브', '분류', '서포트 벡터 머신', '합성곱 신경망', '머신러닝', '딥러닝', 'Valve', 'Classification', 'Support Vector Machine (SVM)', 'Convolutional neural network (CNN)', 'Machine learning', 'Deep learning']","밸브의 내부 누설 현상은 밸브의 내부 부품의 손상에 의해 발생하며 배관 시스템의 사고와 운전정지를 일으키는 주요 요인이다. 본 연구는 버터플라이형 밸브의 내부 누설에 따라 배관계에서 발생하는 음향방출 신호를 이용하여 배관 가동 중 실시간 누설 진단의 가능성을 검토하였다. 이를 위해 밸브의 작동 모드별로 측정한 시간영역의 AE 원시신호를 취득하였으며 이로부터 구축한 데이터셋은 데이터 기반의 인공지능 알고리즘에 적용하여 밸브의 내부 누설 유무를 진단하는 모델을 생성하였다. 누설 유무진단을 분류의 문제로 정의하여 SVM 기반의 머신러닝과 CNN 기반의 딥러닝 분류 알고리즘을 적용하였다. 데이터의 특징 추출에 기반한 SVM 분류 모델의 경우, 이진분류 모델에서 구축된 모델에 따라 83~90%의 정확도를 나타냈으며, 다중 클래스인 경우 분류 정확도가 66%로 감소하였다. 반면, CNN 기반의 다중 클래스 분류 모델의 경우 99.85%의 분류 정확도를 얻을 수 있었다. 결론적으로 밸브 내부 누설 진단을 위한 SVM 분류모델은 다중 클래스의 정확도 향상을 위해 적절한 특징 추출이 필요하며, CNN 기반의 분류모델은 프로세서의 성능 저하만 없다면 누설진단과 밸브 개도 분류에 효율적인 접근방법임을 확인하였다.","Valve internal leakage is caused by damage to the internal parts of the valve, resulting in accidents and shutdowns of the piping system. This study investigated the possibility of a real-time leak detection method using the acoustic emission (AE) signal generated from the piping system during the internal leakage of a butterfly valve. Datasets of raw time-domain AE signals were collected and postprocessed for each operation mode of the valve in a systematic manner to develop a data-driven model for the detection and classification of internal leakage, by applying machine learning algorithms. The aim of this study was to determine whether it is possible to treat leak detection as a classification problem by applying two classification algorithms: support vector machine (SVM) and convolutional neural network (CNN). The results showed different performances for the algorithms and datasets used. The SVM-based binary classification models, based on feature extraction of data, achieved an overall accuracy of 83% to 90%, while in the case of a multiple classification model, the accuracy was reduced to 66%. By contrast, the CNN-based classification model achieved an accuracy of 99.85%, which is superior to those of any other models based on the SVM algorithm. The results revealed that the SVM classification model requires effective feature extraction of the AE signals to improve the accuracy of multi-class classification. Moreover, the CNN-based classification can be a promising approach to detect both leakage and valve opening as long as the performance of the processor does not degrade."
합성곱 신경망을 적용한 볼 베어링의 결함 분류,2022,"['Ball Bearing(볼 베어링)', 'Convolutional Neural Network(합성곱 신경망)', 'Fault Classification(결함 분류)', 'Machine Learning(기계학습)', 'Multi-Layer Perceptron(다층 지각)']","볼 베어링은 회전 기계의 성능을 결정하는 주요 구성 요소 중 하나로 볼과 내·외륜 사이의 구름접촉으로 다양한 결함이 발생하며, 이는 회전 기계에서 발생하는 고장의 주요 원인이다. 이를 사전에 방지하기 위하여 다양한 기계학습 알고리즘을 적용한 볼 베어링의 결함 분류 모델에 대한 연구가 이루어지고 있다. 하지만 정확도가 높은 결함 분류 모델을 구축하기 위하여 충분한 데이터를 수집하는 데에는 어려움이 따른다. 본 연구에서는 데이터가 충분하지 않은 환경에서 결함 분류를 위해 합성곱 신경망(CNN: convolution neural network)이 적용된 결함 분류 모델을 제안하였으며, 정상상태 및 5가지 결함 데이터를 대상으로 분류 모델의 학습을 수행하고 결함 분류의 정확도를 평가하였다. 또한, 다층 지각(multi-layer perceptron)과 장단기 메모리(long short-term memory) 알고리즘이 적용된 기존의 결함 분류 모델과 CNN 모델의 결함 분류 정확도를 비교하였다. 이를 통해 데이터가 충분하지 않은 환경에서 볼 베어링 결함 상태를 분류하는 데 있어 CNN 모델의 적용이 적합함을 확인하였다.","A ball bearing is one of the main components that play an important role in the performance of rotating machinery. Faults occur frequently owing to concentrated loads on the contact areas between balls and race tracks, which directly affect operation of the rotating machinery. To prevent such issues in advance, studies on the fault classification models have been carried out, for which various machine learning algorithms were considered. To attain a high accuracy fault classification model, even though sufficient collected fault data are needed, there are still limit and restriction on this purpose. In the present study, a fault classification model for a ball bearing was proposed, in which CNN (convolution neural network) algorithm was applied to classify faults with a high accuracy even for insufficient collected fault data. The CNN model was constructed after training with the vibration signals acquired from operating ball bearing including normal condition and five fault types. In addition, other fault classification models were prepared using conventional machine learning algorithms, such as MLP (multi-layer perceptron) and LSTM (long short-term memory). The obtained results were compared with those of the CNN algorithm. Subsequently, the availability of the CNN model was verified with insufficient collected fault data."
단백질 기능 예측 모델의 주요 딥러닝 모델 비교 실험,2022,"['CNN', 'LSTM', 'GRU', '결합 모델', '단백질 서열', 'CNN', 'LSTM', 'GRU', 'Combined Model', 'Protein Sequence']",,"Proteins are the basic unit of all life activities, and understanding them is essential for studying life phenomena. Since the emergenceof the machine learning methodology using artificial neural networks, many researchers have tried to predict the function of proteinsusing only protein sequences. Many combinations of deep learning models have been reported to academia, but the methods are differentand there is no formal methodology, and they are tailored to different data, so there has never been a direct comparative analysis ofwhich algorithms are more suitable for handling protein data. In this paper, the single model performance of each algorithm was comparedand evaluated based on accuracy and speed by applying the same data to CNN, LSTM, and GRU models, which are the most frequentlyused representative algorithms in the convergence research field of predicting protein functions, and the final evaluation scale is presentedas Micro Precision, Recall, and F1-score. The combined models CNN-LSTM and CNN-GRU models also were evaluated in the same way.Through this study, it was confirmed that the performance of LSTM as a single model is good in simple classification problems, overlappingCNN was suitable as a single model in complex classification problems, and the CNN-LSTM was relatively better as a combination model."
소셜미디어 사진 게시물의 딥러닝을 활용한 도시공원 이용자 활동 이미지 분류모델 개발,2022,"['Convolutional Neural Network (CNN)', 'Computer Vision', 'Urban Park Evaluation', 'Patterns of Urban Park Use', '합성곱신경망(CNN)', '컴퓨터 비전', '도시공원 평가', '도시공원 이용패턴']","본 연구의 목적은 인공지능의 딥러닝을 활용하여 소셜미디어에서 공유되는 도시공원 이용자 활동사진을 분류하는 기초 모델을 만드는 것이다. 소셜미디어 데이터는 네이버 검색을 통해 수집된 도시공원 관련 사진들을 수집하여 분류모델에 활용하였다. 도시공원 특성 평가에 활용할 수 있는 지표인 자연성(naturalness), 잠재적 매력성(potential attraction), 활동(activity)을 기반으로 최종 21개의 분류 항목체계를 만들고, 항목별로 네이버에서 공유되는 실제 도시공원 사진을 수집하여 주석이 달린 데이터 세트를 구축했다. 수집한 사진 데이터 세트에 대해 커스텀(cuntom) CNN 모델과 사전 훈련된 CNN의 전이학습 모델을 설계하고 분석하였다. 연구결과, 가장 우수한 성능을 보였던 Xception 전이학습 모델이 최종적으로 도시공원 이용자 활동 이미지 분류모델로 선정되었으며, 그 외 다양한 평가 지표를 통해 모델을 평가했다. 본 연구는 소셜미디어에 공유되는 이용자 사진을 활용하여 도시공원 특성을 평가할 수 있는 지표로서 AI를 구축한 것에 의의가 있다. 딥러닝을 활용한 분류모델은 수동분류에 대한 한계를 보완하고, 대량의 도시공원 사진을 효율적으로 분류할 수 있어서 향후 도시공원의 모니터링 및 관리에 활용할 수 있는 유용한 방법이라고 할 수 있다.","This study aims to create a basic model for classifying the activity photos that urban park users shared on social media using Deep Learning through Artificial Intelligence. Regarding the social media data, photos related to urban parks were collected through a Naver search, were collected, and used for the classification model. Based on the indicators of Naturalness, Potential Attraction, and Activity, which can be used to evaluate the characteristics of urban parks, 21 classification categories were created.  Urban park photos shared on Naver were collected by category, and annotated datasets were created. A custom CNN model and a transfer learning model utilizing a CNN pre-trained on the collected photo datasets were designed and subsequently analyzed. As a result of the study, the Xception transfer learning model, which demonstrated the best performance, was selected as the urban park user activity image classification model and evaluated through several evaluation indicators. This study is meaningful in that it has built AI as an index that can evaluate the characteristics of urban parks by using user-shared photos on social media. The classification model using Deep Learning mitigates the limitations of manual classification, and it can efficiently classify large amounts of urban park photos. So, it can be said to be a useful method that can be used for the monitoring and management of city parks in the future."
딥러닝을 이용한 병징에 최적화된 딸기 병충해 검출 기법,2022,"['데이터 증강', '빅데이터', '스마트팜', 'CNN', 'YOLO', 'big data', 'CNN', 'data augmentation', 'smart farm', 'YOLO']",본 논문은 딥러닝 알고리즘을 이용하여 딸기 영상 데이터의 병충해 존재 여부를 자동으로 검출할 수 있는 서비스 모델을 제안한다. 또한 병징에 특화된 분할 이미지 데이터 세트를 제안하여 딥러닝 모델의 병충해 검출 성능을 향상한다. 딥러닝모델은 CNN 기반 YOLO를 선정하여 기존의 R-CNN 기반 모델의 느린 학습속도와 추론속도를 개선하였다. 병충해 검출 모델을 학습하기 위해 일반적인 데이터 세트와 제안하는 분할 이미지 데이터 세트를 구축하였다. 딥러닝 모델이 일반적인 학습 데이터 세트를 학습했을 때 병충해 검출률은 81.35%이며 병충해 검출 신뢰도는 73.35%이다. 반면 딥러닝 모델이 분할 이미지 학습 데이터 세트를 학습했을 때 병충해 검출률은 91.93%이며 병충해 검출 신뢰도는 83.41%이다. 따라서 분할 이미지 데이터를 학습한 딥러닝 모델의 성능이 우수하다는 것을 증명할 수 있었다.,"This study aimed to develop a service model that uses a deep learning algorithm for detecting diseases and pests in strawberries through image data. In addition, the pest detection performance of deep learning models was further improved by proposing segmented image data sets specialized in disease and pest symptoms. The CNN-based YOLO deep learning model was selected to enhance the existing R-CNN-based model's slow learning speed and inference speed. A general image data set and a proposed segmented image dataset was prepared to train the pest and disease detection model. When the deep learning model was trained with the general training data set, the pest detection rate was 81.35%, and the pest detection reliability was 73.35%. On the other hand, when the deep learning model was trained with the segmented image dataset, the pest detection rate increased to 91.93%, and detection reliability was increased to 83.41%. This study concludes with the possibility of improving the performance of the deep learning model by using a segmented image dataset instead of a general image dataset."
GIS를 이용한 토양정보 기반의 배추 생산량 예측 수정모델 개발,2022,"['딥러닝', '농산물 생산량 예측', 'CNN', 'RNN', 'LSTM', '하이퍼파라미터 최적화', 'Deep Learning', 'Crop Yield Prediction', 'CNN', 'RNN', 'LSTM', 'Hyperparameter Optimization']","본 연구는 GIS를 통해 토양정보를 수집하고 가공하여 농산물 생산량을 예측하는 모델을 제안한다. 농산물 생산 량 예측 딥러닝 알고리즘은 공개된 CNN-RNN 농산물 생산량 예측 모델 구조를 변경하여 국내 농산물 자료 환경에 적합하도록 새롭게 구축하다. 기존모델은 두 가지 특징을 가지고 있는데 첫 번째는 농산물의 생산량을 해당 필지 값이 아닌 당해 평균값으로 대체한다는 것이고 두 번째는 예측하는 연도의 데이터까지 학습한다는 것이다. 새로운 모델은 해당 필지의 값을 그대로 사용하여 데이터의 정확성을 확보하고 예측하고자 하는 연도 이전의 데이터만 가지 고 학습할 수 있도록 네트워크 구조를 개선하다. 제안한 CNN-RNN 모델은 1980년부터 2020년까지의 기상정보, 토양정보, 토양적성도, 생산량 데이터를 학습하여 김장용 가을배추의 지역별 단위면적당 생산량을 예측한다. 2018 년부터 2021년까지 4개 연도별 자료에 대하여 계산하고 생산량을 예측한 결과, 테스트 데이터셋에 대한 오차백분율 이 약 10% 내외로 실제값과 비교하여 정확도 높은 생산량 예측이 가능했고, 특히 전체 생산량 비중이 큰 지역에서의 생산량은 비교적 근접하게 예측하는 것으로 분석되었다. 또한 제안모델과 기존모델은 모두 학습자료 연도 수가 증가 할수록 점점 오차가 작아지므로 학습데이터가 많아질수록 범용 성능은 향상되는 결과를 나타낸다.","This study proposes a deep learning algorithm to predict crop yield using GIS (Geographic Information System) to extract soil properties from Soilgrids and soil suitability class maps. The proposed model modified the structure of a published CNN-RNN (Convolutional Neural Network-Recurrent Neural Network) based crop yield prediction model suitable for the domestic crop environment. The existing model has two characteristics. The first is that it replaces the original yield with the average yield of the year, and the second is that it trains the data of the predicted year. The new model uses the original field value to ensure accuracy, and the network structure has been improved so that it can train only with data prior to the year to be predicted. The proposed model predicted the yield per unit area of autumn cabbage for kimchi by region based on weather, soil, soil suitability classes, and yield data from 1980 to 2020. As a result of computing and predicting data for each of the four years from 2018 to 2021, the error amount for the test data set was about 10%, enabling accurate yield prediction, especially in regions with a large proportion of total yield. In addition, both the proposed model and the existing model show that the error gradually decreases as the number of years of training data increases, resulting in improved general-purpose performance as the number of training data increases."
인공지능 기반 IBD Scoring System,2022,"['Inflammatory bowel disease', 'ulcerative colitis', 'endoscopic score', 'scoring system', 'R-CNN', '염증성 장질환', '궤양성 대장염', '내시경 점수', '점수 시스템', '영역 기반 합성곱 신경망']","염증성 장질환은 크론병과 궤양성 대장염으로 구성되어 있다. 최근 궤양성 대장염 환자의 내시경 수요가 급격하게 증가하고 있으며, 궤양성 대장염은 일생동안 호전과 악화를 반복하는 염증성 장질환 이기 때문에 꾸준한 관리가 필요하다. 궤양성 대장염의 내시경적 질병 활성도를 평가하는 지표로 MES를 주로 사용한다. 본 논문에서는 정확도가 우수한 MES 평가 지표를 인공지능 기술을 통해 자동 분석하여 스코어링 해 주는 시스템을 제안한다. 스코어링 자동 분석을 위해 Faster R-CNN 알고리즘을 개선하여 적용하였다. 인공지능 알고리즘의 정확도를 평가하기 위해 MLP, SVM, CNN모델과 본 논문에서 제안하는 방법에 대한 정확도를 비교 평가 하였다. 비교 평가 결과 평균 88%의 정확도를 도출하여 성능을 증명하였다. 이러한 시스템은 임상 현장에서 내시경 시술에 보조적인 수단으로 활용될 수 있다. 내시경 영상을 활용한 본 연구의 성과물은 염증성 장질환 중 하나인 궤양성 대장염의 진료에서 인공지능을 활용하여 진료의 질 향상을 높이는 계기가 될 수 있다. 향후 연구로 다기관 데이터 수집을 통한 데이터의 확장을 통해 정확도를 개선하고자 한다.","Inflammatory bowel disease consists of Crohn's disease and ulcerative colitis. Recently, the demand for endoscopy from ulcerative colitis patients is rapidly increasing, and since ulcerative colitis is an inflammatory bowel disease that repeats improvement and worsening throughout life, continuous management is required. MES is mainly used as an index to evaluate the endoscopic disease activity of ulcerative colitis. In this paper, we propose a system that automatically analyzes and scores MES evaluation indicators with excellent accuracy through artificial intelligence technology. Faster R-CNN algorithm was improved and applied for automatic scoring analysis. In order to evaluate the accuracy of the artificial intelligence algorithm, the accuracy of the MLP, SVM, and CNN models and the method proposed in this paper were compared and evaluated. As a result of comparative evaluation, an average accuracy of 88% was derived to prove the performance. Such a system can be used as an auxiliary means for endoscopic procedures in the clinical field. The results of this study using endoscopic imaging can serve as an opportunity to improve the quality of care by using artificial intelligence in the treatment of ulcerative colitis, one of the inflammatory bowel diseases. Future research aims to improve accuracy through data expansion through multi-institutional data collection."
플라스틱 덕트 내부의 공동 조사를 위한 Impact-Echo 실험과 딥러닝 모델 적용 연구,2022,"['충격공진법', '딥러닝', '합성곱 신경망', '장단기 기억 신경망', '플라스틱 덕트', 'Impact-Echo', 'deep learning', 'CNN', 'LSTM', 'plastic duct']","PSC 교량은 미리 콘크리트에 프리스트레스트를 도입시킨 교량구조이다. PSC 교량에서 덕트 내 공극은 강연선 부식을 발생시키기 때문에 PSC 교량 덕트 내 공극을 조사하는 것이 중요하다. 최근 연구들에서는 PSC 교량 덕트 내 공극을 조사하기 위해 비파괴검사 방법인 Impact-Echo(IE)에 딥러닝 모델을 적용하여 평가한 연구가 진행되었다. 하지만 원형 플라스틱 덕트 내부에 위치한 공극을 찾기 위해 LSTM 모델과 일차원 CNN 모델을 적용한 연구는 많이 수행되지 않았다. 따라서 이 연구는 IE 실험을 하여 수집된 데이터를 LSTM 모델과 CNN 모델 그리고 CNN 모델과 LSTM 모델을 조합한 모델에 적용하였고 모델들의 공극 여부의 정확도를 평가하였다. 실험 결과, CNN-LSTM 모델이 3개의 딥러닝 모델 중에서 93 %의 정확도로 가장 정확도가 높은 딥러닝 모델로 평가되었다.",
Wavelet 변환과 결합한 잔차 학습을 이용한 희박뷰 전산화단층영상의 인공물 감소,2022,"['Wavelet transformation', 'Residual learning', 'Sparse-view', 'Artifact reduction', 'Wavelet 변환', '잔차 학습', '희박뷰', '인공물 제거']","희박뷰 전산화단층촬영(computed tomography; CT) 영상화 기술은 피폭 방사선량을 감소시킬 수 있을 뿐만 아니라 획득한 투영상의 균일성을 유지하고 잡음을 감소시킬 수 있는 장점이 있다. 하지만 재구성 영상 내 인공물 발생으로 인하여 화질 및 피사체 구조가 왜곡되는 단점이 있다. 본 연구에서는 희박뷰 CT 영상의 인공물 감소를 위해 wavelet 변환과 잔차 학습(residual learning)을 적용한 콘볼루션 신경망(convolutional neural network; CNN) 기반 영상화 모델을 개발하고, 개발한 모델을 통한 희박뷰 CT 영상의 인공물 감소 정도를 정량적으로 분석하였다. CNN은 wavelet 변환 층, 콘볼루션 층 및 역 wavelet 변환 층으로 구성하였으며, 희박뷰 CT 영상과 잔차 영상을 각각 입출력 영상으로 설정하여 영상화 모델 학습을 진행하였다. 영상화 모델 학습을 위해 평균제곱오차(mean squared error; MSE)를 손실함수로, Adam 함수를 최적화 함수로 사용하였다. 학습된 모델을 통해 입력 희박뷰 CT 영상에 대한 예측 잔차 영상을 획득하고, 두 영상간의 감산을 통해 최종 결과 영상을 획득하였다. 또한 최종 결과 영상에 대한 시각적 특성, 최대신호대잡음비(peak signal-to- noise ratio; PSNR) 및 구조적유사성지수(structural similarity; SSIM)를 측정하였다. 연구결과 본 연구에서 개발한 영상화 모델을 통해 희박뷰 CT 영상의 인공물이 효과적으로 제거되며, 공간분해능이 향상되는 결과를 확인하였다. 또한 wavelet 변환과 잔차 학습을 미적용한 영상화 모델에 비해 본 연구에서 개발한 영상화 모델은 결과 영상의 PSNR 및 SSIM을 각각 8.18% 및 19.71% 향상시킬 수 있음을 확인하였다. 따라서 본 연구에서 개발한 영상화 모델을 이용하여 희박뷰 CT 영상의 인공물 제거는 물론 공간분해능 향상 및 정량적 정확도 향상 효과를 획득할 수 있다.","Sparse-view computed tomography (CT) imaging technique is able to reduce radiation dose, ensure the uniformity of image characteristics among projections and suppress noise. However, the reconstructed images obtained by the sparse-view CT imaging technique suffer from severe artifacts, resulting in the distortion of image quality and internal structures. In this study, we proposed a convolutional neural network (CNN) with wavelet transformation and residual learning for reducing artifacts in sparse-view CT image, and the performance of the trained model was quantitatively analyzed. The CNN consisted of wavelet transformation, convolutional and inverse wavelet transformation layers, and input and output images were configured as sparse-view CT images and residual images, respectively. For training the CNN, the loss function was calculated by using mean squared error (MSE), and the Adam function was used as an optimizer. Result images were obtained by subtracting the residual images, which were predicted by the trained model, from sparse-view CT images. The quantitative accuracy of the result images were measured in terms of peak signal-to-noise ratio (PSNR) and structural similarity (SSIM). The results showed that the trained model is able to improve the spatial resolution of the result images as well as reduce artifacts in sparse-view CT images effectively. Also, the trained model increased the PSNR and SSIM by 8.18% and 19.71% in comparison to the imaging model trained without wavelet transformation and residual learning, respectively. Therefore, the imaging model proposed in this study can restore the image quality of sparse-view CT image by reducing artifacts, improving spatial resolution and quantitative accuracy."
이물질 구별을 통한 음식물쓰레기 배출시스템 개선에 관한 연구,2022,"['AI', 'CNN', 'food waste', 'Machine learning', 'RFID']","산업화의 발전으로 음식물 및 쓰레기 배출량이 급격히 증가하고 있다. 이에 정부도 심각성을 인지하고 이를 줄이고자 다방면으로 노력을 하고 있다. 그 일환으로 음식물 종량제을 도입을 하였고 도입 초기 여러 시행착오가 있었지만20 ~ 30%의 감량 효과를 보여주고 있다. 이러한 실적은 음식물 종량제가 정착이 되고 있음을 암시하고 있다.하지만1차 수거에서 2차 수거과정을 통해 집하장으로 모여서 자원 순환을 과정에서 이물질로 인한 폐해가 발생하고 있다. 이에본 연구에서는 이러한 문제점을 근본적으로 해결하고자 인공지능을 적용하여 개선하고자 한다. 음식물쓰레기 특성상 많은 이미지를 구하는데는 한계가 있어 CNN을 기반으로 한 여러 모델을 비교하여 이를 이상 데이터 분류 즉, CNN 기반모델들에 여러 유형의 이물질에 대한 학습을 시킨 후 그 중 정확도가 놓은 모델을 적용하여 설비 보호와 이물질 구분을위해 투입되는 인력 등 유지보수에 대한 개선책을 마련하고자 한다.","With the development of industrialization, the amount of food and waste is rapidly increasing.Accordingly, the government is aware of the seriousness and is making efforts in various ways to reduce it. As a part of that, the volume-based food system was introduced, and although there were several trials and errors at the beginning of the introduction, it shows a reduction effect of 20 to 30%. These results suggest that the volume-based food system is being established. However, the waste is caused by foreign substances in the process of recycling resources by collecting them from the 1st collection to the 2nd collection process. Therefore, in this study, to solve these problems fundamentally, artificial intelligence is applied to classify foreign substances and improve them. Due to the nature of food waste, there is a limit to obtaining many images, so we compare several models based on CNNs and classify them as abnormal data, that is, CNN-based models are trained on various types of foreign substances, and then models with high accuracy are selected. We intend to prepare improvement measures for maintenance, such as manpower input to protect equipment and classify foreign substances by applying it."
Jetson Nano와 3D프린터를 이용한 인공지능 교육용 키트 제작,2022,"['인공지능', '딥러닝', 'CNN', 'OpenCV', 'IoT', 'AI', 'Deep learning', 'CNN', 'OpenCV', 'IoT']","본 논문에서는 인공지능교육의 어려움을 해결하기 위하여 인공지능 교육에 활용이 가능한 교육용 키트를 개발하였다. 이를 통하여 이론 중심에서 실무 위주의 경험을 학습하기 위한 CNN과 OpenCV를 이용하여 컴퓨터 비전 기술을 이용한 사람 인식(Object Detection and Person Detection in Computer Vision)과 특정 오브젝트를 학습시키고 인식시키는 사용자 이미지인식(Your Own Image Recognition), 사용자 객체 분류(Segmentation) 및 세분화(Classification Datasets), 학습된 타켓을 공격하는 IoT하드웨어 제어와 인공지능 보드인 Jetson Nano GPIO를 제어함으로써 효과적인 인공지능 학습에 도움이 되는 교재를 개발하여 활용할 수 있도록 하였다.","In this paper, an educational kit that can be used in AI education was developed to solve the difficulties of AI education. Through this, object detection and person detection in computer vision using CNN and OpenCV to learn practical-oriented experiences from theory-centered and user image recognition (Your Own) that learns and recognizes specific objects Image Recognition), user object classification (Segmentation) and segmentation (Classification Datasets), IoT hardware control that attacks the learned target, and Jetson Nano GPIO, an AI board, are developed and utilized to develop and utilize textbooks that help effective AI learning made it possible."
부분 지문 이미지를 이용한 개인 식별 방법,2022,"['부분 지문', '딥러닝', '개인 식별', 'CNN', '데이터 증식', 'Partial Fingerprint', 'Deep Learning', 'Identification', 'CNN', 'Data Augmentation']",,
지리적 인접성을 이용한 아파트 가격변화율 예측 모델 개발,2022,"['서울시 아파트 가격변화율', '지리적 인접성', '예측 모델', 'CNN', 'rate of change in apartment prices in Seoul', 'geographical adjacency', 'predictive model', 'CNN']","최근 들어 금관구, 노도강, 마용성 등 주택가격이 권역별로 변동하는 탈동조화 현상이 심화하고 있다. 해당 현상의 특징은 각 권역이 지리적으로 가까운 구들로 구성되어 있다는 것이다. 본 논문은 서울시의 인접한 자치구들 사이에는 가격이 상호 동조한다고 보고 가격 변동이 인접 지역에 의한 것임을 확인하고자 한다. 가설 검증에는 아파트 가격변화율, 거시경제지표 및 사교육 지표가 사용되며 이는 3차원(시간, 거리, 속성)의 데이터로 조립되고 CNN으로 학습된다. 조립 방식에 따라 모델은 3가지 하위 모델(타깃 지역만 고려(I), 원거리 지역 고려(II), 이웃 수 변경(III))로 세분되며 성능은 MAE와 MDA로 측정된다. 실험 결과, 이웃을 사용한 모델은 영속성 모델과 XGBoost 보다 좋은 성능을 보였고 하위 모델은 모델 III(이웃 수 3인 경우), II, I 순으로 좋은 성능을 보였다. 이를 통해 ‘이웃’이 타깃 지역의 아파트 가격변화율에 영향을 미친다는 것을 알 수 있었다.","Recently, in the real estate market, decoupling in which housing prices fluctuate by the region has been escalating. This phenomenon implies that each region is composed of districts that are adjacent to one another. This thesis confirms that the prices of a district change in synchronization with that of the adjacent districts and proves that the fluctuations in apartment prices in the districts within Seoul are due to the neighbors. The rate of change in apartment prices, macroeconomic indicators, and private education indicators are used to test the hypothesis with a 3D (time, distance, and attribute) model, which is further deciphered using CNN. The model considers the situation of neighbors and is subdivided into the following three sub-models: consideration only for the target area (I), consideration for long-distance areas (II), and change in the number of neighbors (III). The metrics used are mean absolute error and mean directional accuracy. It was observed that the model with neighbors performed better than the persistence model and XGBoost. Furthermore, its sub-models showed good performance in the order of model III (with 3 neighbors), II, and I. This study clearly exhibits that the factor “neighbor” affects the rate of change in apartment prices."
INTERIOR WIND NOISE PREDICTION AND VISUAL EXPLANATION SYSTEM FOR EXTERIOR VEHICLE DESIGN USING COMBINED CONVOLUTION NEURAL NETWORKS,2022,"['Wind noise prediction', 'Image regression', 'Convolutional neural networks (CNN)', 'Gradient-weighted class activation map (Grad-CAM)']",,"An analytical model configuration, in addition to air pressure analysis and post-processing, was conducted to measure the interior wind noise by changing the exterior vehicular design. Although wind noise can be calculated accurately through the current process, it requires three to five days for each design. In this study, a convolutional neural network (CNN), which is a class of deep neural networks designed for processing image data, was applied to predict the wind noise with vehicle design images from four different views. Feature maps were extracted from the CNN models trained with images of each view and concatenated to flow through a sequence of fully connected (FC) layers to predict the wind noise. Moreover, visualization of the significant vehicle parts for wind noise prediction was provided using a gradient-weighted class activation map (Grad- CAM). Finally, we compared the performance of various CNN-based models, such as ResNet, DenseNet, and EfficientNet, in addition to the architecture of the FC layers. The proposed method can predict the wind noise using vehicle images from different views with a root-mean-square error (RMSE) value of 0.206, substantially reducing the time and cost required for interior wind noise estimation."
Prediction of Solar Photovoltaic Power Generation by Weather Using LSTM,2022,"['딥러닝', '예측', '기상', '태양광 발전', 'LSTM', 'deep learning', 'prediction', 'weather', 'solar photovoltaic power generation', 'LSTM']","딥러닝은 주가 및 농산물 가격 예측과 같이 데이터를 분석해 일련의 규칙을 발견하고 미래를예상해 우리의 삶에서 다양한 도움을 주고 있다. 본 연구는 태양광 에너지 사용의 중요성이 늘어나는 상황에서 기상에 따른 태양광 발전 실적을 딥러닝을 통해 분석하고 발전량을 예측한다. 본연구에서는 시계열 데이터 예측에서 두각을 나타내고 있는 LSTM(Long Short Term Memory network)을 사용한 모델을 제안하며 이미지를 비롯한 다양한 차원의 데이터를 분석할 때 사용되는CNN(Convolutional Neural Network)과 두 모델을 결합한 CNN-LSTM과의 성능을 비교한다. 세 가지모델의 성능은 태양광 발전 실적의 실제값과 딥러닝을 통해 예측한 값으로 MSE, RMSE, 결정계수를 계산하여 비교하였고 그 결과 LSTM 모델의 성능이 가장 우수한 것으로 나타났다. 따라서본 연구는 LSTM을 사용한 태양광 발전량 예측을 제안한다.","Deep learning analyzes data to discover a series of rules and anticipates the future, helping us in various ways in our lives. For example, prediction of stock prices and agricultural prices. In this research, the results of solar photovoltaic power generation accompanied by weather are analyzed through deep learning in situations where the importance of solar energy use increases, and the amount of power generation is predicted. In this research, we propose a model using LSTM(Long Short Term Memory network) that stand out in time series data prediction. And we compare LSTM’s performance with CNN(Convolutional Neural Network), which is used to analyze various dimensions of data, including images, and CNN-LSTM, which combines the two models. The performance of the three models was compared by calculating the MSE, RMSE, R-Squared with the actual value of the solar photovoltaic power generation performance and the predicted value. As a result, it was found that the performance of the LSTM model was the best. Therefor, this research proposes predicting solar photovoltaic power generation using LSTM."
딥러닝 유사도 기반 현품 영상과 도면 영상의 1:1 매칭 방법,2022,"['Deep Learning', 'CNN(Convolutional Neural Network)', 'Drawing Image', 'Real Product Image', 'Siamese Network', '1:1 Verification', '심층학습', '합성인공신경망', '도면 영상', '현품 영상', '샴신경망', '1:1 검증']","본 논문은 주어진 현품 영상과 도면 영상의 유사도를 비교하여 1:1 검증을 위한 방법을 제시한 것으로, CNN(Convolutional Neural Network) 기반의 딥러닝 모델을 두 개로 결합하여 Siamese Net을 구성하고현품 영상과 도면 영상(정면도, 좌우 측면도, 평면도 등)을 같은 제품이면 1로 다른 제품이면 0으로학습하며, 추론은 현품 영상과 도면 영상을 쌍으로 질의하여 해당 쌍이 같은 제품인지 아닌지를 판별하는 딥러닝 모델을 제안한다. 현품 영상과 도면 영상과의 유사도가 문턱 값(Threshold: 0.5) 이상이면동일한 제품이고, 문턱 값 미만이면 다른 제품이라고 판별한다. 본 연구에서는 질의 쌍으로 동일제품의현품 영상과 도면 영상이 주어졌을 때(긍정 : 긍정) “동일제품”으로 판별할 정확도는 약 71.8%로 나타났고, 질의 쌍으로 다른 현품 영상과 도면 영상이 주어졌을 때(긍정: 부정) “다른제품”으로 판별할 정확도는 약 83..1%를 나타내었다. 향후 제안한 모델에 파라미터 최적화 연구를 접목하고 데이터 정제 등의과정을 추가하여 현품 영상과 도면 영상의 매칭 정확도를 높이는 연구를 진행할 예정이다.","This paper presents a method for 1:1 verification by comparing the similarity between the given real product image and the drawing image. The proposed method combines two existing CNN-based deep learning models to construct a Siamese Network. After extracting the feature vector of the image through the FC (Fully Connected) Layer of each network and comparing the similarity, if the real product image and the drawing image (front view, left and right side view, top view, etc) are the same product, the similarity is set to 1 for learning and, if it is a different product, the similarity is set to 0. The test (inference) model is a deep learning model that queries the real product image and the drawing image in pairs to determine whether the pair is the same product or not. In the proposed model, through a comparison of the similarity between the real product image and the drawing image, if the similarity is greater than or equal to a threshold value (Threshold: 0.5), it is determined that the product is the same, and if it is less than or equal to, it is determined that the product is a different product. The proposed model showed an accuracy of about 71.8% for a query to a product (positive: positive) with the same drawing as the real product, and an accuracy of about 83.1% for a query to a different product (positive: negative). In the future, we plan to conduct a study to improve the matching accuracy between the real product image and the drawing image by combining the parameter optimization study with the proposed model and adding processes such as data purification."
음각 정보를 이용한 딥러닝 기반의 알약 식별 알고리즘 연구,2022,"['Pill identification', 'Deep learning', 'Imprinted text', 'Keras OCR', 'CNN']",,"In this paper, we propose a pill identification model using engraved text feature and image feature such as shape and color, and compare it with an identification model that does not use engraved text feature to verify the possibility of improving identification performance by improving recognition rate of the engraved text. The data con- sisted of 100 classes and used 10 images per class. The engraved text feature was acquired through Keras OCR based on deep learning and 1D CNN, and the image feature was acquired through 2D CNN. According to the identification results, the accuracy of the text recognition model was 90%. The accuracy of the comparative model and the proposed model was 91.9% and 97.6%. The accuracy, precision, recall, and F1-score of the proposed model were better than those of the comparative model in terms of statistical significance. As a result, we confirmed that the expansion of the range of feature improved the performance of the identification model."
Detection and Weak Segmentation of Masses in Gray-Scale Breast Mammogram Images Using Deep Learning,2022,"['Breast mammogram', 'detection lesion of mass', 'deep learning', 'convolutional neural network', 'data normalization']",,"Purpose: In this paper, we propose deep-learning methodology with which to enhance the mass differentiation performance of convolutional neural network (CNN)-based architecture.Materials and Methods: We differentiated breast mass lesions from gray-scale X-ray mammography images based on regions of interest (ROIs). Our dataset comprised breast mammogram images for 150 cases of malignant masses from which we extracted the mass ROI, and we composed a CNN-based deep learning model trained on this dataset to identify ROI mass lesions. The test dataset was created by shifting some of the training data images. Thus, although both datasets were different, they retained a deep structural similarity. We then applied our trained deep-learning model to detect masses on 8-bit mammogram images containing malignant masses. The input images were preprocessed by applying a scaling parameter of intensity before being used to train the CNN model for mass differentiation.Results: The highest area under the receiver operating characteristic curve was 0.897 (Î 20).Conclusion: Our results indicated that the proposed patch-wise detection method can be utilized as a mass detection and segmentation tool."
실도로 주행 데이터를 이용한 도로 인프라 센서 기반 차선 변경 거동 검출 네트워크 연구,2022,"['차선 변경', '거동 검출', '인프라 센서', '데이터 증강', '확장성', 'Lane change', 'Maneuver classification', 'Roadside sensor', 'Data augmentation', 'Scalability']",,"In this paper, a classification algorithm of lane change maneuver based on roadside sensors on highway is proposed. Data augmentation using field operational test data is also considered for scalability. The maneuver classification is composed of semantic maps and convolution neural network(CNN). The semantic map aims to represent a bird’s eye view of both vehicle and road geometry, and the corresponding trajectory of the vehicle. The CNN is used to classify a lane change maneuver of multiple vehicles. While good performance of maneuver classification is shown with respect to a well-known dataset called highD, it is still necessary to consider scalability. Thus, the data augmentation is suggested to build a semantic map based on field operational test data. Despite different sensor characteristics of two datasets, it is demonstrated how the performance of CNN-based maneuver classification is improved in terms of scalability is demonstrated."
Convolutional Neural Network-Based Target Detector Using Maxpooling and Hadamard Division Layers in FM-Band Passive Coherent Location,2022,"['Constant False Alarm Rate', 'Convolutional Neural Network', 'Passive Coherent Location', 'Target Detection']",,"The constant false alarm rate (CFAR) has been widely used in radar systems to detect target echo signals because of its simplicity. With the recent development of different types of neural networks (NNs), NN architecture-based target detection methods are also being considered. Several studies related to NN-based target detectors have introduced multi-layer perceptron-based and convolutional neural network (CNN)-based structures. In this paper, we propose a CNN-based target detection method in frequency modulation (FM)-band passive coherent location (PCL). We improved the detection performance using a maxpooling layer and a Hadamard division layer, which are parallelly placed with a CNN layer. Moreover, in our method there is no need to determine the specific cell configuration (e.g., cell under test, reference cells, and guard cells) because the proposed method obtains the trained kernels by end-to-end learning. We show that the trained kernels help in the extraction of either signal or noise components. Through the simulations, we also prove that the proposed method can yield an improved receiver operating characteristic compared to that of a cell-averaging CFAR detector for FM-band PCL in a homogeneous environment."
산림복원 대상 후보지 추출을 위한 딥러닝 접근법,2022,"['딥러닝', '분할', '산림복원', '항공사진', 'Aerial photo', 'Deep learning', 'Forest restoration', 'Segmentation']","이미지 인식에 특화된 CNN (Convolutional Neural Network) 기반의 딥러닝 기법은 영상의 항목별 분류가 필요한 다양한 연구에 적용되고있다. 본 연구는 건물, 도로, 논, 밭, 산림, 나지의 6가지 항목을 산림복원 대상 후보지로 정의하고 CNN 기반의 산림복원 대상 후보지 추출 및분류의 최적 방법론을 탐색하였다. 6,640개의 데이터셋을 75:25의 비율로 훈련(4,980개) 및 검증(1,660개)로 구분하여 구축하고 학습에 활용하였다.모델별 정확도는 픽셀정확도(PA), 평균 교차 겹침 결합(Mean IoU)을 이용하여 평가하였다. 픽셀정확도는 90.6%, 평균 교차 겹침 결합은 80.8%로산정되어 Inception-Resnet-v2 모델이 세 모델 중 가장 산림복원 대상 후보지 추출에 뛰어난 정확도를 보였다. 이 결과는 기존의 산림복원 대상후보지 현장조사 혹은 항공사진을 활용한 조사에 비해 시공간적 이점을 가지며, 향후 산림복원 대상지 선정 자료로 적용 가능성이 있다고 판단된다.","Many studies using aerial photography and deep learning are increasing for efficient monitoring of the forest resources. We defined six semantic classes of buildings, roads, paddy fields, fields, forests, and barren as forest restoration target sites and explored the optimal methodology for extracting and classifying target sites for forest restoration based on CNN. The datasets (6,640) were divided at a ratio of 75:25 into training (4,980) and validation datasets (1,660). The accuracy of each model was evaluated using pixel accuracy (PA) and Mean Intersection over union (Mean IoU). PA was calculated as 90.6% and Mean IoU was 80.8%, and the Inception-Resnet-v2 model showed excellent accuracy in extracting target sites for forest restoration among the three models. This result has a Spatio-temporal advantage over the existing field survey for forest restoration sites or surveys using aerial photographs by manually. This study will be able to contribute to the classification of forest restoration sites efficiently and support forest restoration."
Comparison and optimization of deep learning-based radiosensitivity prediction models using gene expression profiling in National Cancer Institute-60 cancer cell line,2022,"['Radiosensitivity', 'Prediction', 'Deep learning', 'Model comparison', 'Gene expression', 'Survival fraction at 2Gy']",,"Background: In this study, various types of deep-learning models for predicting in vitro radiosensitivity from gene-expression profiling were compared.Methods: The clonogenic surviving fractions at 2 Gy from previous publications and microarray geneexpression data from the National Cancer Institute-60 cell lines were used to measure the radiosensitivity. Seven different prediction models including three distinct multi-layered perceptrons (MLP), four different convolutional neural networks (CNN) were compared. Folded cross-validation was applied to train and evaluate model performance. The criteria for correct prediction were absolute error < 0.02 or relative error < 10%. The models were compared in terms of prediction accuracy, training time per epoch, training fluctuations, and required calculation resources.Results: The strength of MLP-based models was their fast initial convergence and short training time per epoch. They represented significantly different prediction accuracy depending on the model configuration. The CNN-based models showed relatively high prediction accuracy, low training fluctuations, and a relatively small increase in the memory requirement as the model deepens.Conclusion: Our findings suggest that a CNN-based model with moderate depth would be appropriate when the prediction accuracy is important, and a shallow MLP-based model can be recommended when either the training resources or time are limited"
고속 푸리에 합성곱을 이용한 파지 조건에 강인한 촉각센서 기반 물체 인식 방법,2022,"['Tactile Sensor', 'Gripper', 'Object Recognition', 'Fast Fourier Convolution (FFC)']",,"The accurate object recognition is important for the precise and accurate manipulation. To enhance the recognition performance, we can use various types of sensors. In general, acquired data from sensors have a high sampling rate. So, in the past, the RNN-based model is commonly used to handle and analyze the time-series sensor data. However, the RNN-based model has limitations of excessive parameters. CNN-based model also can be used to analyze time-series input data. However, CNN-based model also has limitations of the small receptive field in early layers. For this reason, when we use a CNN-based model, model architecture should be deeper and heavier to extract useful global features.Thus, traditional methods like RN N -based and CN N -based model needs huge amount of learning parameters. Recently studied result shows that Fast Fourier Convolution (FFC) can overcome the limitations of traditional methods. This operator can extract global features from the first hidden layer, so it can be effectively used for feature extracting of sensor data that have a high sampling rate. In this paper, we propose the algorithm to recognize objects using tactile sensor data and the FFC model. The data was acquired from 11 types of objects to verify our posed model. We collected pressure, current, position data when the gripper grasps the objects by random force. As a result, the accuracy is enhanced from 84.66% to 91.43% when we use the proposed FFC-based model instead of the traditional model."
Methodology to classify hazardous compounds via deep learning based on convolutional neural networks,2022,"['Hazardous compounds', 'Classification', 'Deep learning', 'Artificial intelligence', 'MSDS', 'GHS']",,"Compounds information such as Chemical Abstracts Service (CAS) registry number, hazards, and properties have been provided through Globally Harmonized System (GHS) based Material Safety Data Sheet (MSDS). This information can help users avoid hazardous compounds and handle chemicals in proper way. GHS specifies that hazards of compounds are categorized through animal testing (or in vivo testing) , in vitro testing, epidemiological surveillance, and clinical trials. In this study, artificial intelligence (AI) is used to replace traditional approaches in predicting the toxicity of chemicals. A database of hazardous compounds is generated by data provided by the Ministry of Environment (ME), training and learning based on convolutional neural network (CNN) are carried out following data featurization. As a result, 90% of accuracy for CNN-based model is obtained using the image dataset. In contrast to the previous methods, the classification method based on CNN-based model in this study allows for the efficient discrimination of hazard chemicals without any additional tests."
Graph neural network based multiple accident diagnosis in nuclear power plants: Data optimization to represent the system configuration,2022,"['Multiple accident', 'Nuclear power plant', 'Graph', 'Graph neural network']",,"Because nuclear power plants (NPPs) are safety-critical infrastructure, it is essential to increase their safety and minimize risk. To reduce human error and support decision-making by operators, several artificial-intelligence-based diagnosis methods have been proposed. However, because of the nature of data-driven methods, conventional artificial intelligence requires large amount of measurement values to train and achieve enough diagnosis resolution.We propose a graph neural network (GNN) based accident diagnosis algorithm to achieve high diagnosis resolution with limited measurements. The proposed algorithm is trained with both the knowledge about physical correlation between components and measurement values. To validate the proposed methodology has a sufficiently high diagnostic resolution with limited measurement values, the diagnosis of multiple accidents was performed with limited measurement values and also, the performance was compared with convolution neural network (CNN). In case of the experiment that requires low diagnostic resolution, both CNN and GNN showed good results. However, for the tests that requires high diagnostic resolution, GNN greatly outperformed the CNN."
A Study on Image Labeling Technique for Deep-Learning-Based Multinational Tanks Detection Model,2022,"['Convolutional Neural Network (CNN)', 'Computer Vision', 'Deep Learning', 'YOLO Network']",,"Recently, the improvement of computational processing ability due to the rapid development of computing technology has greatly advanced the field of artificial intelligence, and research to apply it in various domains is active. In particular, in the national defense field, attention is paid to intelligent recognition among machine learning techniques, and efforts are being made to develop object identification and monitoring systems using artificial intelligence. To this end, various image processing technologies and object identification algorithms are applied to create a model that can identify friendly and enemy weapon systems and personnel in real-time. In this paper, we conducted image processing and object identification focused on tanks among various weapon systems. We initially conducted processing the tanks' image using a convolutional neural network, a deep learning technique. The feature map was examined and the important characteristics of the tanks crucial for learning were derived. Then, using YOLOv5 Network, a CNN-based object detection network, a model trained by labeling the entire tank and a model trained by labeling only the turret of the tank were created and the results were compared. The model and labeling technique we proposed in this paper can more accurately identify the type of tank and contribute to the intelligent recognition system to be developed in the future."
Real-time work intensity estimation algorithm based on deep learning using heart rate and skin temperature,2022,"['Work intensity estimation', '1D CNN', 'LSTM', 'Deep learning']",,"In harsh environments where high-intensity work is performed, predicting the work intensity based on the vital signs of a worker can be useful in preventing accidents. Considering existing worker management systems are analyzed using set thresholds, they cannot resolve variables caused by individual differences. Therefore, we propose an algorithm to estimate the work intensity of workers based on their heart rate and body temperature using a deep learning-based 1D CNN-LSTM model. The proposed algorithm uses time-series signals of 60 s to accurately estimate the work intensity by considering the time-series characteristics. In addition, the proposed algorithm considers the individual differences in bio-signals by extracting and using data from the exercise and rest states of workers. To verify the performance of the proposed algorithm, we compared estimation performance factors such as model accuracy, precision, recall, and F1 score with those of various models; the results showed a high estimation accuracy of 99.96%. We believe the proposed algorithm can help minimize damage by preemptively responding to unexpected accidents that may occur at work sites by accurately estimating the work intensity based on the individual differences among workers."
컨벌루션 신경망을 사용한 다중 차선 인식,2022,"['Multi-lanes detection(다중 차선 인식)', 'Convolutional neural network(컨벌루션 신경망)', 'fifth-order polynomial(5차 다항식)']",,"In this study, the multi-lane detection problem is expressed as a CNN-based regression problem, and the lane boundary coordinates are selected as outputs. In addition, we described lanes as fifth-order polynomials and distinguished the ego lane and the side lanes so that we could make the prediction lanes accurately.By eliminating the network branch arrangement and the lane boundary coordinate vector outside the image proposed by Chougule’s method, it was possible to eradicate meaningless data learning in CNN and increase the fast training and performance speed. And we confirmed that the average prediction error was small in the performance evaluation even though the proposed method compared with Chougule’s method under harsher conditions. In addition, even in a specific image with many errors, the predicted lanes did not deviate significantly, meaningful results were derived, and we confirmed robust performance."
A Systems Engineering Approach for Predicting NPP Response under Steam Generator Tube Rupture Conditions using Machine Learning,2022,"['Recurrent Neural Network (RNN)', 'Long Short Term Memory (LSTM)', 'Gated Recurrent Unit (GRU)', 'Convolutional Neural Network (CNN)', 'Machine Learning (ML)', 'Best Estimate Plus Uncertainty (BEPU)']",,"Accidents prevention and mitigation is the highest priority of nuclear power plant (NPP) operation, particularly in the aftermath of the Fukushima Daiichi accident, which has reignited public anxieties and skepticism regarding nuclear energy usage. To deal with accident scenarios more effectively, operators must have ample and precise information about key safety parameters as well as their future trajectories. This work investigates the potential of machine learning in forecasting NPP response in real-time to provide an additional validation method and help reduce human error, especially in accident situations where operators are under a lot of stress. First, a base-case SGTR simulation is carried out by the best-estimate code RELAP5/MOD3.4 to confirm the validity of the model against results reported in the APR1400 Design Control Document (DCD). Then, uncertainty quantification is performed by coupling RELAP5/MOD3.4 and the statistical tool DAKOTA to generate a large enough dataset for the construction and training of neural-based machine learning (ML) models, namely LSTM, GRU, and hybrid CNN-LSTM. Finally, the accuracy and reliability of these models in forecasting system response are tested by their performance on fresh data. To facilitate and oversee the process of developing the ML models, a Systems Engineering (SE) methodology is used to ensure that the work is consistently in line with the originating mission statement and that the findings obtained at each subsequent phase are valid."
스마트 디바이스를 활용한 노약자 근감소증 진단과 딥러닝 알고리즘,2022,"['근감소증', '딥러닝', '스마트디바이스', 'IoT', '예측', '보행패턴', 'IMU', '데이터 분석', 'sarcopenia', 'deep-learning', 'smart-device', 'IoT', 'walking-pattern', 'IMU', 'Data-analysis']","연구목적: 본 논문에서는 스마트 디바이스의 높은 보급률을 활용하여 근감소증을 추정 및 예측하는 딥러닝 알고리즘을 제안과 연구를 수행한다. 연구방법: 딥러닝 학습을 위해 스마트 디바이스에 내장된 관성센서를 활용하여 실험을 데이터를 수집하였다. 데이터를 수집하는 테스트용 어플리케이션 구현하여 ‘정상’과 ‘비정상’걸음과 ‘달리기’, ‘낙상’, ‘스쿼트’ 자세의 5 가지 상태를 구분하여 데이터를 수집하였다.  연구결과: LSTM, CNN, RNN model 사용 시 예측 정확도를 분석했고 CNN-LSTM 융합형 모델을 활용하여 이진분류 정확도 99.87%, 다중 분류 92.30%의 정확도를 보였다.  결론: 근감소증이 있는 사람의 경우 걸음걸이의 이상이 생긴다는 점에 착안하여 스마트 디바이스를 활용한 연구를 진행하였다. 본 연구를 활용하여 근감소증으로 인해 생기는 재난안전을 강화 할 수 있을 것이다.",
Fast neutron-gamma discrimination in organic scintillators via convolution neural network,2022,"['Fast-neutron detection', 'Pulse-shape discrimination', 'Deep-learning', 'Convolution neural network', 'Organic scintillator']",,"Due to the high gamma sensitivity of organic scintillators, it is essential to discriminate signals induced by neutron from gamma-ray in fast-neutron detection. With the improvement of digital signal processing techniques, diverse discrimination methods based on pulse-shape variation by radiation type have been developed. The main purpose of this study was to verify the applicability of a deep-learning model, especially convolution neural network (CNN), to pulse-shape discrimination (PSD) in organic scintillation detectors, such as BC-501A (liquid) and EJ-276 (plastic). To that end, waveforms of neutron and gamma-ray were experimentally collected using point sources of 137Cs (gamma-ray) and 252Cf (neutron/gamma-ray) and pre-processed for being compatible with deep-learning. The PSD performance was evaluated for both detectors using the charge comparison method (CCM) which is one of the representative conventional PSD techniques of time-domain. In addition, the CNN-based discriminating algorithms were tested, and its preliminary results were confirmed with confusion matrices which indicate the discrimination accuracy of a deep-learning model."
SLAM을 이용한 카메라 기반의 실내 배송용 자율주행 차량 구현,2022,"['자율주행', '합성곱 신경망', '딥러닝', '실내 위치 측위', '동시적 위치추정 및 지도작성', 'Autonomous Driving', 'Convolutional Neural Network', 'Deep Learning', 'Indoor Localization', 'SLAM']","본 논문에서는 Visual 동시적 위치추정 및 지도작성(SLAM : Simultaneous Localization and Mapping)기술을 응용하여 실내에서 생성된 SLAM 맵을 기반으로 지정된 목적지에 물건을 배달하는 자율주행 차량 플랫폼을 제안하였다. 실내에서 SLAM 맵을 생성하기 위해 소형 자율주행 차량 플랫폼의 상단에 SLAM 맵 생성을 위한 심도 카메라를 설치하고 SLAM 맵 속에서의 정확한 위치 추정을 하기 위해 추적 카메라를 장착하여 구현하였다. 또한, 목적지의 표찰을 인식하기 위해 합성곱 신경망(CNN : Convolutional neural network)을 사용하여 목적지에 정확하게 도착할 수 있도록 주행 알고리즘을 적용하여 설계하였다. 실내 배송 자율주행 차량을 실제로 제작하였고 SLAM 맵의 정확도 확인과 CNN을 통한 목적지 표찰 인식 실험을 수행하였다. 결과적으로 표찰 인식의 성공률을 향상시켜 구현한 실내 배송용 자율주행 차량의 활용 적합성 여부를 확인하였다.",
Study on Microscopic Fracture Surface Analysis based on Deep Learning (1) : Fracture Surface Classification by Convolutional Neural Network,2022,"['Deep Learning(딥러닝)', 'Convolutional Neural Network(합성곱 신경망)', 'Fractography(파면분석학)', 'Microscopic Fracture Surface(미소 파면)', 'Fracture Surface Classification(파면 분류)']",,"Fracture surface contains many important information of machine fracture such as crack origin, direction, number of cycle, types and defects. By observing microscopic fracture surface, cause of fracture can be figured out. However it is difficult to pass on expertise and the number of those engineers is lately dicreased.  Recently, deep learning is popular because of 4th industrial revolution. Deep learning is widely used in the vision recognition. Moreover, Convolutional Neural Network(CNN) is a kind of deep learning and optimized to analyze visual imagery and it used to convergence with vision recognition and classification.  In this research, three kind of fracture surfaces are classified by using CNN. In order to improve classification accuracy, different number of filters are set and tested. And several times of image augmentation method is applied. Finally, 95% of classification accuracy is printed. Developed program can classify random microscopic fracture surface images."
액티브 러닝을 활용한 반도체 웨이퍼 신규 불량 패턴 검출,2022,"['Semiconductor Manufacturing', 'Defect Identification', 'Wafer Bin Map', 'Active Learning', 'Sampling Strategy', 'Convolutional Neural Network.']",,"In the semiconductor manufacturing industry, a wafer bin map (WBM) contains defect patterns that provides important clues to identify the root causes of the defect. Traditionally, field engineers classify the pattern types by manually checking WBM. Recently, many studies have been conducted for automatic classification by using deep learning models. To accurately classify defect patterns with convolutional neural network (CNN)-based deep learning models, every WBM must have accurate pattern labels. However, in reality, it takes a lot of time and efforts for engineers to label all the data. In addition, existing CNN-based studies show limitations that cannot detect new defect patterns, frequently occurred in real situations. In this study, we devise a new pattern detection framework based on active learning. Through this, new patterns can be selectively detected even with existing active learning methodologies, and classification performance can be secured by effectively sampling unlabeled data. And we compared the performance and characteristics of each sampling strategy for new pattern detection. The usefulness and applicability of this study was demonstrated by WM-811K, publicly available WBM data."
토픽모델링을 활용한 한국과 미국의 산업수학 이슈 비교,2022,"['미국', '산업수학', '온라인 뉴스', '온라인 포럼', '토픽모델링', '한국', 'US', 'Industrial Mathematics', 'Online News', 'Online Forum', 'Topic Modeling', 'Korea']","본 연구에서는 텍스트마이닝을 활용해 한국과 미국의 온라인 뉴스와 포럼에서 산업수학과 관련한 이슈를 파악하고, 그 결과를 비교 분석하였다. 이를 위해 한국의 주요 포털 사이트인 네이버의 뉴스 기사, 클리앙의 게시글과 댓글, 그리고 미국의 New York Times와 CNN의 뉴스 기사, Reddit의 게시글과 댓글에서 산업수학과 관련한 텍스트 데이터를 수집하여 구조적 토픽모델링 분석을 수행하였다. 주요 분석결과는 다음과 같다. 첫째, 한국의 뉴스는 산업수학의 필요성과 정부의 지원 측면에 대해, 미국에서는 산업수학이 활용되는 다양한 분야에 대해 다루는 것으로 나타났다. 둘째, 한국에서는 온라인 뉴스와 포럼에서 각기 다른 주제로 동일한 개수의 이슈가 나타났지만, 미국에서는 온라인 포럼보다 뉴스 기사에서 더 많은 이슈를 다루고 있는 것으로 나타났다. 이를 토대로 한국에서 산업수학이 정착하는 데 있어 연구자들에게는 학술적, 그리고 정부에는 실무적 시사점을 제시하였다.","This study explored the issues of industrial mathematics in online news articles and online forums in Korea and the US by using text mining and compared the results. Text data about industrial mathematics were collected from news articles of Naver, a major portal site, and postings and replies on Clien as resources of Korea, and from news articles by the New York Times and CNN as well as postings and replies on Reddit as resources of the US. Structural topic modeling analyses were performed, the major results of which were as follows. First, news articles in Korea mainly dealt with the necessity of industrial mathematics and government support. On the contrary, the news articles in the US focused more on various fields where industrial mathematics fields were utilized. Second, in Korea, the same number of issues with different topics were discussed in news articles and online forums, whereas in the US more issues were covered in news articles than in online forums. It was suggested academic implications for researchers and practical implications for the government for settling industrial mathematics in Korea."
Development of a Spine X-Ray-Based Fracture Prediction Model Using a Deep Learning Algorithm,2022,"['Osteoporotic fractures', 'Deep learning', 'X-rays', 'Risk assessment']",,"Background: Since image-based fracture prediction models using deep learning are lacking, we aimed to develop an X-ray-basedfracture prediction model using deep learning with longitudinal data.Methods: This study included 1,595 participants aged 50 to 75 years with at least two lumbosacral radiographs without baselinefractures from 2010 to 2015 at Seoul National University Hospital. Positive and negative cases were defined according to whethervertebral fractures developed during follow-up. The cases were divided into training (n=1,416) and test (n=179) sets. A convolutional neural network (CNN)-based prediction algorithm, DeepSurv, was trained with images and baseline clinical information (age,sex, body mass index, glucocorticoid use, and secondary osteoporosis). The concordance index (C-index) was used to compare performance between DeepSurv and the Fracture Risk Assessment Tool (FRAX) and Cox proportional hazard (CoxPH) models.Results: Of the total participants, 1,188 (74.4%) were women, and the mean age was 60.5 years. During a mean follow-up period of40.7 months, vertebral fractures occurred in 7.5% (120/1,595) of participants. In the test set, when DeepSurv learned with imagesand clinical features, it showed higher performance than FRAX and CoxPH in terms of C-index values (DeepSurv, 0.612; 95% confidence interval [CI], 0.571 to 0.653; FRAX, 0.547; CoxPH, 0.594; 95% CI, 0.552 to 0.555). Notably, the DeepSurv method withoutclinical features had a higher C-index (0.614; 95% CI, 0.572 to 0.656) than that of FRAX in women.Conclusion: DeepSurv, a CNN-based prediction algorithm using baseline image and clinical information, outperformed the FRAXand CoxPH models in predicting osteoporotic fracture from spine radiographs in a longitudinal cohort."
딥러닝 기반 반려동물 모니터링 시스템 및 활동 인식 장치,2022,"['Monitoring system', 'Activity recognition device', 'Deep learning', 'Activity recognition', 'Activity analysis', '모니터링 시스템', '활동 인식 장치', '딥러닝', '활동 인식', '활동 분석']","본 논문에서는 활동 인식장치를 이용한 딥러닝 기반의 반려동물 모니터링 시스템을 제안한다.이 시스템은 반려동물의 활동 인식장치와 반려인의 스마트 기기, 서버로 구성된다. 아두이노 기반활동 인식 장치로부터 가속도와 자이로 데이터를 수집하고, 이로부터 반려동물의 걸음 수를 연산하였다. 수집된 데이터는 전처리 과정을 거쳐 CNN과 LSTM을 하이브리드한 딥러닝 모델을 통해5가지 형태(앉기, 서기, 눕기, 걷기, 뛰기)로 활동을 인식함으로써 활동량을 측정한다. 마지막으로, 반려인의 스마트 기기에 일일 및 주간 브리핑 차트 등 활동 변화에 대한 모니터링을 제공한다.성능 평가 결과, 반려동물의 구체화된 활동 인식 및 활동량 측정이 가능함을 확인하였다. 향후 데이터 축적을 통해 반려동물의 이상행동 탐지 및 헬스 케어 서비스의 확장을 기대할 수 있다.","In this paper, we propose a pet monitoring system based on deep learning using an activity recognition device. The system consists of a pet's activity recognition device, a pet owner's smart device, and a server. Accelerometer and gyroscope data were collected from an Arduino-based activity recognition device, and the number of steps was calculated. The collected data is pre-processed and the amount of activity is measured by recognizing the activity in five types (sitting, standing, lying, walking, running) through a deep learning model that hybridizes CNN and LSTM. Finally, monitoring of changes in the activity, such as daily and weekly briefing charts, is provided on the pet owner's smart device. As a result of the performance evaluation, it was confirmed that specific activity recognition and activity measurement of pets were possible. Abnormal behavior detection of pets and expansion of health care services can be expected through data accumulation in the future."
인공지능을 활용한 도주경로 예측 및 추적 시스템,2022,"['영상분석', '인공지능', '도주경로예측', '자동상황전파', '스마트시티 통합플랫폼', 'Intelligent image analysis', 'Escape route prediction', 'Automatic situation propagation', 'Smart city Integrate platform']","서울특별시는 25개 구청에 7만5천여대의 CCTV가 설치되어 있다. 각 구청은 CCTV관제를 위한 관제센터를 구축하고 시민의 안전을 위해 24시간 CCTV영상관제를 수행하고 있다. 서울특별시는 유관기관과 MOU를 체결하여 긴급/응급 상황에 신속한 대응이 가능하도록 구청의 CCTV영상을 제공하여 시민이 안전한 스마트시티통합플랫폼을 구축하고 있다. 본 논문에서는, 서울특별시 관할구청에서 사건 발생 시, CCTV영상에 대해 인공지능 DNN 기반의 Template Matching 기술, MLP 알고리즘과 CNN 기반으로 YOLO SPP DNN모델을 사용하여 사람과 차량을 판별하여 도주경로를 예측한다. 또한, 관할구청을 이탈하여, 차량 및 사람이 도주 시, 인접 구청에 영상정보와 상황정보를 자동전파 하도록 설계한다. 인공지능을 활용한 도주경로 예측 및 추적 시스템은 스마트시티 통합플랫폼을 전국으로 확장시킬 수 있다.","In Seoul, about 75,000 CCTVs are installed in 25 district offices. Each ward office has built a control center for CCTV control and is performing 24-hour CCTV video control for the safety of citizens. Seoul Metropolitan Government is building a smart city integrated platform that is safe for citizens by providing CCTV images of the ward office to enable rapid response to emergency/emergency situations by signing an MOU with related organizations. In this paper, when an incident occurs at the Seoul Metropolitan Government Office, the escape route is predicted by discriminating people and vehicles using the AI ​​DNN-based Template Matching technology, MLP algorithm and CNN-based YOLO SPP DNN model for CCTV images. . In addition, it is designed to automatically disseminate image information and situation information to adjacent ward offices when vehicles and people escape from the competent ward office. The escape route prediction and tracking system using artificial intelligence can expand the smart city integrated platform nationwide."
딥러닝기반 토마토 병해 진단 서비스 연구,2022,"['딥러닝', '토마토병해충', '모바일넷', '레스넷', 'deep learning', 'tomato disease', 'MobileNet', 'ResNet']","토마토 작물은 병해에 노출이 쉽고 단시간에 퍼지므로 병해에 대한 늦은 조치로 인한 피해는 생산량과 매출에 직접적인 영향을 끼친다.  따라서, 토마토의 병해에 대해 누구나 현장에서 간편하고 정확하게 진단하여 조기 예방을 가능하게 하는 서비스가 요구된다. 본 논문에서는 사전에 ImageNet 전이 학습된 딥러닝 기반 모델을 적용하여 토마토의 9가지 병해 및 정상인 경우의 클래스를 분류하고 서비스를 제공하는 시스템을 구성한다. Plant Village 데이터 셋으로부터 토마토 병해 및 정상을 분류한 잎의 이미지 셋을 합성곱을 사용하여 조금 더 가벼운 신경망을 구축한 딥러닝 기반 CNN구조를 갖는 MobileNet, ResNet의 입력을 사용한다. 2가지 제안 모델의 학습을 통해 정확도와 학습속도가 빠른 MobileNet를 사용하여 빠르고 편리한 서비스를 제공할 수 있다.","Tomato crops are easy to expose to disease and spread in a short period of time, so late measures against disease are directly related to production and sales, which can cause damage. Therefore, there is a need for a service that enables early prevention by simply and accurately diagnosing tomato diseases in the field. In this paper, we construct a system that applies a deep learning-based model in which ImageNet transition is learned in advance to classify and serve nine classes of tomatoes for disease and normal cases. We use the input of MobileNet, ResNet, with a deep learning-based CNN structure that builds a lighter neural network using a composite product for the image set of leaves classifying tomato disease and normal from the Plant Village dataset. Through the learning of two proposed models, it is possible to provide fast and convenient services using MobileNet with high accuracy and learning speed."
SwinE-Net: hybrid deep learning approach to novel polyp segmentation using convolutional neural network and Swin Transformer,2022,"['polyp segmentation', 'convolutional neural networks', 'multidilation convolutional block', 'multifeature aggregation block', 'Swin Transformer', 'Vision Transformer']",,"Prevention of colorectal cancer (CRC) by inspecting and removing colorectal polyps has become a global health priority because CRC is one of the most frequent cancers in the world. Although recent U-Net-based convolutional neural networks (CNNs) with deep feature representation and skip connections have shown to segment polyps effectively, U-Net-based approaches still have limitations in modeling explicit global contexts, due to the intrinsic nature locality of convolutional operations. To overcome these problems, this study proposes a novel deep learning model, SwinE-Net, for polyp segmentation that effectively combines a CNN-based EfficientNet and Vision Transformer (ViT)-based Swin Ttransformer. The main challenge is to conduct accurate and robust medical segmentation in maintaining global semantics without sacrificing low-level features of CNNs through Swin Transformer. First, the multidilation convolutional block generates refined feature maps to enhance feature discriminability for multilevel feature maps extracted from CNN and ViT. Then, the multifeature aggregation block creates intermediate side outputs from the refined polyp features for efficient training. Finally, the attentive deconvolutional network-based decoder upsamples the refined and combined feature maps to accurately segment colorectal polyps. We compared the proposed approach with previous state-of-the-art methods by evaluating various metrics using five public datasets (Kvasir, ClinicDB, ColonDB, ETIS, and EndoScene). The comparative evaluation, in particular, proved that the proposed approach showed much better performance in the unseen dataset, which shows the generalization and scalability in conducting polyp segmentation. Furthermore, an ablation study was performed to prove the novelty and advantage of the proposed network. The proposed approach outperformed previous studies."
Electroencephalography-based imagined speech recognition using deep long short-term memory network,2022,"['brain–computer interface', 'deep learning', 'EEG', 'imagined speech recognition', 'long short term memory']",,"This article proposes a subject-independent application of brain–computer interfacing (BCI). A 32-channel Electroencephalography (EEG) device is used to measure imagined speech (SI) of four words (sos, stop, medicine, washroom) and one phrase (come-here) across 13 subjects. A deep long short-term memory (LSTM) network has been adopted to recognize the above signals in seven EEG frequency bands individually in nine major regions of the brain. The results show a maximum accuracy of 73.56% and a network prediction time (NPT) of 0.14 s which are superior to other state-of-the-art techniques in the literature. Our analysis reveals that the alpha band can recognize SI better than other EEG frequencies. To reinforce our findings, the above work has been compared by models based on the gated recurrent unit (GRU), convolutional neural network (CNN), and six conventional classifiers. The results show that the LSTM model has 46.86% more average accuracy in the alpha band and 74.54% less average NPT than CNN. The maximum accuracy of GRU was 8.34% less than the LSTM network. Deep networks performed better than traditional classifiers."
순차적인 데이터 처리를 통한 딥 러닝 기반 트래픽 분류속도 개선,2022,"['Traffic Classification', 'Application Traffic', 'Machine Learning', 'Deep Learning', 'Processing Speed', '트래픽 분류', '응용 트래픽', '머신 러닝', '딥 러닝', '처리 속도']","네트워크의 발전과 변화된 환경으로 인하여 다양한 응용 프로그램들이 개발되고 사용되고 있다. 이에 따라 네트워크 트래픽의 발생량도 증가하고 있으며 효율적인 네트워크의 관리를 위한 응용 트래픽 분류가 필요하다. 응용트래픽 분류는 대부분 분류 정확도에 중점을 두고 있고, 실제 대용량 트래픽이 발생하는 네트워크 환경에서 트래픽 분류를 빠르게 처리하기 위한 연구가 필요하다. 본 논문에서는 순차적으로 데이터를 처리하여 딥 러닝 기반의트래픽 분류속도를 개선하는 방법에 대하여 제안하고, 제안하는 방법에서 사용하는 임계값 및 신뢰도를 정의한다.앙상블 모델에서의 적절한 임계값은 0.7로 99.78%의 신뢰도를 달성하고 전체 데이터의 58.99%의 데이터를 정확하게 분류하였다. 앙상블 모델에서 분류되고 남은 데이터들을 딥 러닝 모델에 적용하여 실험한 결과 제안한 방법의 전체 처리 속도는 1D CNN만을 사용한 결과보다 0.88초 빠른 처리 속도를 보여주었다.","Due to the development of networks and the changed environment, various application programs are being developed and used. Accordingly, the amount of network traffic is also increasing, and application traffic classification is required for efficient network management. Application traffic classification focus on classification accuracy, and is needed to quickly process traffic classification in a network environment where large-capacity traffic. In this paper, we propose a method to improve the traffic classification speed based on deep learning by sequentially processing data, and define the threshold and reliability used in the proposed method. The appropriate threshold in the ensemble model was 0.7, which achieved a reliability of 99.78% and correctly classified 58.99% of the data. As a result of testing by applying the remaining data classified from the ensemble model to the deep learning model, the overall processing speed of the proposed method was 0.88 seconds faster than the result using only 1D CNN."
YOLO 기반 금속 외관 결함영역 검출,2022,"['금속 외관', '결함 검출', '객체 검출', '합성곱신경망', '딥러닝', 'Metal Surface', 'Detection of Defects', 'Object Detection', 'Convolution Neural Network', 'Deep Learning']","최근 다양한 분야에 딥러닝 기술이 도입되었고, 특히 영상 처리에 특화된 합성곱신경망(CNN: Convolutional Neural Network)이 많이 활용되고 있다. 금속 외관의 결함영역을 검출하는 많은 응용 분야(예를 들어, 스마트 제조 및 스마트팩토리 분야)에서도 합성곱신경망을 활용한 연구가 활발하게 이루어지고 있다. 본 논문에서는 합성곱신경망 기반 객체 검출(Object Detection) 알고리즘 중 하나인 YOLOv4(YOLO 알고리즘의 4번째 버전)를 활용하여 금속 외관의 결함영역을 검출하는 연구를 수행하고자 한다. 특히, 본 논문에서는YOLOv4 네트워크 구조에 여러 후처리 기법들과 전이 학습을 적용하여 향상된 검출 성능을달성하는 방안을 제안한다. 두 가지 종류의 학습데이터셋((i)공용 데이터셋과 (ii)실측 데이터셋)에 대한 실험을 통해 제안한 방법의 성능을 검증하고 분석한다. 또한 성능 검증을 통해공용 데이터셋과 실측 데이터셋에서의 후처리 기법 및 전이학습에 대한 최적의 조합을 도출하였다.",
강인한 머신 러닝 음향 인식을 위한 잔향 영향 분석,2022,"['Sound classification', 'Reverberation', 'VGG16', 'EfficientNet', 'UrbanSound8K', 'Transfer learning']","머신 러닝을 이용한 소리 분류는 먼저 대량의 소리 데이터를 이용하여 CNN과 같은 심층 신경망을 학습시킨 다음, 판별할 소리를 신경망에 입력하여 결과를 얻는 과정을 거친다. 이때 판별할 소리가 존재하는 음향 환경이 소음이나 잔향이 심한 공간이라면 이로 인한 성능 저하가 일어난다. 본 논문에서는 공간의 잔향의 정도와 머신 러닝 분류기의 인식 성능과의 관계를 분석하였다. 이를 위해 UrbanSound8K 데이터 세트와 VGG16 및 EfficientNet 기반의 전이 학습 시스템을 구성하였으며, 3개의 잔향 파라미터 변화에 따라 총 27종의 잔향 패턴을 생성하고 각각에 대해 인식률 변화를 모의 실험하였다. 실험 결과 잔향으로 인해 머신 러닝의 인식 성능이 저하되었으며, 파라미터 별로는 Wet dry mix의 영향이 가장 크고 다음으로 Diffusion, Decay factor의 순이었다.",
EpiLoc: Deep Camera Localization Under Epipolar Constraint,2022,"['Camera localization', 'End-to-end', 'Epipolar geometry', 'Pixel-level constraint.']",,"Recent works have shown that the geometric constraint can be harnessed to boost the performance of CNN-based camera localization. However, the existing strategies are limited to imposing image-level constraint between pose pairs, which is weak and coarse-gained. In this paper, we introduce a pixel-level epipolar geometry constraint to vanilla localization framework without the ground-truth 3D information. Dubbed EpiLoc, our method establishes the geometric relationship between pixels in different images by utilizing the epipolar geometry thus forcing the network to regress more accurate poses. We also propose a variant called EpiSingle to cope with non-sequential training images, which can construct the epipolar geometry constraint based on a single image in a self-supervised manner. Extensive experiments on the public indoor 7Scenes and outdoor RobotCar datasets show that the proposed pixel-level constraint is valuable, and helps our EpiLoc achieve state-of-the-art results in the end-to-end camera localization task."
텍스트-비디오 검색 모델에서의 캡션을 활용한 비디오 특성 대체 방안 연구,2022,"['Multimodal Deep Learning', 'Video-Captioning', 'Text-Video Retrieval']",,"In this paper, we propose a method that performs a text-video retrieval model by replacing video properties using captions. In general, the exisiting embedding-based models consist of both joint embedding space construction and the CNN-based video encoding process, which requires a lot of computation in the training as well as the inference process. To overcome this problem, we introduce a video-captioning module to replace the visual property of video with captions generated by the video-captioning module. To be specific, we adopt the caption generator that converts candidate videos into captions in the inference process, thereby enabling direct comparison between the text given as a query and candidate videos without joint embedding space. Through the experiment, the proposed model successfully reduces the amount of computation and inference time by skipping the visual processing process and joint embedding space construction on two benchmark dataset, MSR-VTT and VATEX."
Exploiting Neural Network for Temporal Multi-variate  Air Quality and Pollutant Prediction,2022,"['Air Quality Index (AQI)', 'Air Pollutant', 'Temporal clustering', 'Forecasting']",,"In recent years, the air pollution and Air Quality Index (AQI) has been a pivotal point for researchers due to its effect on human health. Various research has been done in predicting the AQI but most of these studies, either lack dense temporal data or cover one or two air pollutant elements. In this paper, a hybrid Convolutional Neural approach integrated with recurrent neural network architecture (CNN- LSTM), is presented to find air pollution inference using a multivariate air pollutant elements dataset. The aim of this research is to design a robust and real-time air pollutant forecasting system by exploiting a neural network. The proposed approach is implemented on a 24-month dataset from Seoul, Republic of Korea. The predicted results are cross-validated with the real dataset and compared with the state-of-the-art techniques to evaluate its robustness and performance. The proposed model outperforms SVM, SVM-Polynomial, ANN, and RF models with 60.17%, 68.99%, 14.6%, and 6.29%, respectively. The model performs SVM and SVM-Polynomial in predicting O3 by 78.04% and 83.79%, respectively. Overall performance of the model is measured in terms of Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE) and the Root Mean Square Error (RMSE)."
딥러닝 기반의 반도체 패키지 다이면 스크래치 검출 방법,2022,"['Scratch Detection', 'Deep Learning', 'Image Processing', 'Semiconductor Package', '.']",,.
간선화물의 상자 하차를 위한 외팔 로봇 시스템 개발,2022,"['Object Recognition', 'Robotic Arm', 'Kinematics', 'Task And Motion Planning', 'Image Processing']",,"In this paper, the developed trunk cargo unloading automation system is introduced, and the RGB-D sensor-based box loading situation recognition method and unloading plan applied to this system are suggested. First of all, it is necessary to recognize the position of the box in a truck. To do this, we first apply CNN-based YOLO, which can recognize objects in RGB images in real-time. Then, the normal vector of the center of the box is obtained using the depth image to reduce misrecognition in parts other than the box, and the inner wall of the truck in an image is removed. And a method of classifying the layers of the boxes according to the distance using the recognized depth information of the boxes is suggested. Given the coordinates of the boxes on the nearest layer, a method of generating the optimal path to take out the boxes the fastest using this information is introduced. In addition, kinematic analysis is performed to move the conveyor to the position of the box to be taken out of the truck, and kinematic analysis is also performed to control the robot arm that takes out the boxes. Finally, the effectiveness of the developed system and algorithm through a test bed is proved."
CutPaste-Based Anomaly Detection Model using Multi Scale Feature Extraction in Time Series Streaming Data,2022,"['Anomaly Detection', 'Multi Scale Feature Extraction', 'Self-Supervised Learn']",,"The aging society increases emergency situations of the elderly living alone and a variety of social crimes. In order to prevent them, techniques to detect emergency situations through voice are actively researched. This study proposes CutPaste-based anomaly detection model using multi-scale feature extraction in time series streaming data. In the proposed method, an audio file is converted into a spectrogram. In this way, it is possible to use an algorithm for image data, such as CNN. After that, mutli-scale feature extraction is applied. Three images drawn from Adaptive Pooling layer that has different-sized kernels are merged. In consideration of various types of anomaly, including point anomaly, contextual anomaly, and collective anomaly, the limitations of a conventional anomaly model are improved. Finally, CutPaste-based anomaly detection is conducted. Since the model is trained through self-supervised learning, it is possible to detect a diversity of emergency situations as anomaly without labeling. Therefore, the proposed model overcomes the limitations of a conventional model that classifies only labelled emergency situations. Also, the proposed model is evaluated to have better performance than a conventional anomaly detection model."
Diamond ArUco 마커를 이용한 드론 착륙 지점 3차원 좌표 추정 방법 연구,2022,"['drone', 'autonomous landing', 'image recognition', 'fiducial marker', 'object detection']",,"As interest in autonomous landing of drones and unmanned systems is rising, research for accurate landing of drones remains a challenge. In general, there is a landing method through GNSS, but the position error of the landing site is not detailed, so landing methods using vision through a camera and additional sensors are suggested. In the previous study of our research team, CNN-based station recognition research was performed, but the recognition error was limited due to external environment(wind pressure, vortex, etc.) during the landing mission. was presented. The existing identifier is a single identifier, and only one fiducial marker recognized by the drone was relied on. Diamond ArUco, the marker presented in this study, has four identifiers in the form of a cross, so a method to minimize the error of 3D coordinate estimation is presented in this paper. evaluation was discussed."
머신러닝 기반 금속외관 결함 검출 비교 분석,2022,"['금속 외관', '결함 검출', '머신러닝', '합성곱신경망', 'Metal Surface', 'Defect Detection', 'Machine Learning', 'Convolutional Neural Network']","최근 스마트팩토리와 인공지능 기술의 수요 증가로 인해 다양한 분야에서 인공지능 기술을 적용하는 연구가 진행되고 있다. 결함 검사 분야에서도 인공지능 알고리즘을 도입하기 위한 노력을 기울이고 있다. 특히, 금속 외관의 결함을 검출하는 연구는 다른 소재(목재, 플라스틱, 섬유 등)의 결함을 검출하는 연구에 비해 많은 연구가 이루어지고 있다. 본 논문에서는 머신러닝 기법(서포터 벡터 머신(SVM: Support Vector Machine), 소프트맥스 회귀(Softmax Regression), 결정 트리(Decesion Tree))과 차원 축소 알고리즘(주성분 분석(PCA: Principal Component Analysis), 오토인코더(AutoEncoder))의 9가지 조합과 2가지 합성곱신경망(CNN: Convolution Neural Network) 기법(자체 알고리즘, ResNet)의 금속 외관의 결함 분류 성능 및 속도를 비교하고 분석하는 연구를 수행하고자 한다. 두 종류의 학습 데이터셋((i) 공용 데이터셋, (ii) 실측 데이터셋)에 대한 실험을 통해 각 데이터셋에 대한 성능 및 속도를 비교 분석하고, 가장 효율적인 알고리즘을 찾아낸다.",
VVC 화면 내 예측에서의 딥러닝 기반 예측 블록 개선을 통한 부호화 효율 향상 기법,2022,"['Intra Prediction', 'Convolutional Neural Network', 'Versatile Video Coding.']","본 논문에서는 컨볼루션 신경망 네트워크를 이용하여 VVC 화면 내 예측으로 얻은 예측 블록을 개선하여 잔차 신호를 보다 줄이는 화면 내 예측 방법을 제안한다. 기존의 화면 내 예측 방법은 일부 고정 규칙을 기반으로 주변의 재구성된 참조 샘플로부터 예측 블록을 생성하므로 복잡한 콘텐츠의 예측 블록을 생성하기 어렵다는 한계가 있다. 또한, 참조 샘플로 이용할 수 있는 정보의 양이 시간적 주변 정보에 비해 적기 때문에 화면 간 예측보다 낮은 부호화 성능을 가진다. 본 연구에서는 앞서 언급한 문제를 해결하기 위해 기존의 비디오 부호화 과정의 화면 내 예측을 통해 생성되는 예측 블록에 CNN을 적용하여 원본 블록과 예측 블록의 차분 신호를 줄이는 화면 내 예측 방법을 제안한다. 부호기에서는 제안 알고리즘의 활성 여부를 나타내는 플래그가 함께 부호화된다. 제안하는 화면 내 예측 방법은 최신 비디오 압축 표준인 Versatile Video Coding의 참조 모델인 VTM version 10.0[1] 대비 휘도 성분에 대하여 향상된 압축 성능을 제공한다.",
BCG 신호 최적화를 통한 주행중 운전자 수면 상태 분류에 관한 연구,2022,,,"Drowsy driving requires a lot of social attention because it increases the incidence of traffic accidents and leads to fatal accidents. The number of accidents caused by drowsy driving is increasing every year. Therefore, in order to solve this problem all over the world, research for measuring various biosignals is being conducted. Among them, this paper focuses on non-contact biosignal analysis. Various noises such as engine, tire, and body vibrations are generated in a running vehicle. To measure the driver's heart rate and respiration rate in a driving vehicle with a piezoelectric sensor, a sensor plate that can cushion vehicle vibrations was designed and noise generated from the vehicle was reduced. In addition, we developed a system for classifying whether the driver is sleeping or not by extracting the model using the CNN-LSTM ensemble learning technique based on the signal of the piezoelectric sensor. In order to learn the sleep state, the subject's biosignals were acquired every 30 seconds, and 797 pieces of data were comparatively analyzed."
다중 공간정보 데이터의 점진적 조합에 의한 의미적 분류 딥러닝 모델 학습 성능 분석,2022,"['Multi-modal Data', 'Intrinsic Information', 'Deep Learning', 'Building Extraction', '다중 데이터', '고유정보', '딥러닝', '건물추출']","대부분의 경우 광학 RGB 영상을 딥러닝(DL: Deep learning)의 학습 데이터로 사용하여 객체탐지, 인식, 식별, 분류, 의미적 분할 및 객체 분할 등을 수행하지만, 실세계의 3차원 객체들을 2차원 영상으로 완전하게 파악하는 것 은 한계가 있다. 그러므로 대표적인 3차원 지형 공간정보인 수치표면모델(DSM: Digital Surface Model)과 더불어 DSM에 내재된 특성정보를 이용하여 3차원 지형지물을 분석하는 것이 효과적이다. 건물과 같이 기하학적으로 정 형화된 형태의 인공구조물은 3차원 공간데이터로부터 얻을 수 있는 기하학적 요소와 특성을 이용하여 객체의 분 류와 형상 묘사가 가능하다. 이 연구는 고차원 시각정보(high-level visual information) 시스템에서 중요한 역할을 하는 내재된 고유의 특성정보(intrinsic information)를 기반으로 하며, 이를 위하여 객체의 기하학적 요소인 경사 와 주향을 DSM으로부터 도출하고, 다방향에서 생성한 음영기복영상(SRI: Shaded Relief Image)과 함께 DL 모델 의 학습 수행에 사용하였다. 실험은 ISPRS (International Society for Photogrammetry and Remote Sensing)에서 제공하는 데이터 셋 중에서 DSM과 레이블 데이터를 객체의 의미적 분류를 위해 개발된 합성곱 기반의 SegNet 학 습에 사용하였다. 지형지물을 분류하고 분류 결과를 이용하여 건물을 추출하였다. 특히 DL 모델의 학습 성능 향상 을 위해 학습 데이터의 여러 조합에 따른 시너지 효과를 분석하는 것에 핵심이다. 제안한 방법은 건물 분류와 추출 에 효과적임을 보여주고 있다.","In most cases, optical images have been used as training data of DL (Deep Learning) models for object detection, recognition, identification, classification, semantic segmentation, and instance segmentation. However, properties of 3D objects in the real-world could not be fully explored with 2D images. One of the major sources of the 3D geospatial information is DSM (Digital Surface Model). In this matter, characteristic information derived from DSM would be effective to analyze 3D terrain features. Especially, man-made objects such as buildings having geometrically unique shape could be described by geometric elements that are obtained from 3D geospatial data. The background and motivation of this paper were drawn from concept of the intrinsic image that is involved in high-level visual information processing. This paper aims to extract buildings after classifying terrain features by training DL model with DSM-derived information including slope, aspect, and SRI (Shaded Relief Image). The experiments were carried out using DSM and label dataset provided by ISPRS (International Society for Photogrammetry and Remote Sensing) for CNN-based SegNet model. In particular, experiments focus on combining multi-source information to improve training performance and synergistic effect of the DL model. The results demonstrate that buildings were effectively classified and extracted by the proposed approach."
딥러닝과 테라헤르츠 기술을 이용한 폴리머 배관 결함 검출에 관한 연구,2022,"['테라헤르츠', '폴리머', '비파괴검사', '딥러닝', '컨볼루션 신경망', 'Terahertz', 'Polymer', 'Non-destructive Testing', 'Deep Learning', 'Convolutional Neural Network']","본 연구에서는 폴리머 배관의 결함을 검출하기 위해 Terahertz time-domain-spectroscopy (THz-TDS) 시스템과 convolutional neural network (CNN) 알고리즘을 사용하였다. THz-TDS 시스템의 투과 모드를 사용하여 정상 폴리머 배관과 결함이 있는 폴리머 배관에 대한 THz scanning data를 확보하였다. 폴리머 배관의 결함부위를 투과한 THz wave는 산란이 발생하여 진폭이 감소하는 것을 확인하였다. THz scanning 이미지 속 폴리머 배관의 결함 부위는 THz 신호의 진폭 감소로 발생한 픽셀의 음영차이로 구분할 수 있는 것을 확인하였다. THz 이미지 데이터는 CNN 학습을 위해 데이터 증대(data augmentation) 기법을 사용하여 증폭시켰으며, 증폭된 THz 이미지 데이터는 정상과 결함으로 종류(class)를 나누어 CNN 딥러닝 알고리즘에 학습시켰다. 딥러닝 학습결과 CNN 모델은 95% 이상의 정확도로 폴리머 배관의 결함을 검출할 수 있음을 확인하였다. 이를 통해, 테라헤르츠 파를 이용하여 폴리머 배관을 비접촉, 비파괴 검사할 수 있으며, CNN 딥러닝 알고리즘을 사용하여 자동화된 결함 검출을 할 수 있음을 확인하였다.","The terahertz time-domain spectroscopy (THz-TDS) system and convolutional neural network (CNN) algorithm were used to detect a defect in a polymer tube. The THz scanning data of the normal and defective polymer tubes were obtained from the THz-TDS transmission mode. The amplitude of the THz wave transmitted by the crack of the polymer tube was decreased by scattering. It was confirmed that the crack in the polymer tube in the THz scanning image can be classified by the shading difference of the pixel. The THz image data were amplified for CNN deep learning using an augmentation technique, and the amplified THz image data were learned by the CNN deep learning algorithm by dividing classes into normal and defect datasets. As a result of deep learning, the CNN model can detect a crack in a polymer tube with an accuracy of 95% or more. Finally, it was confirmed that a defect in a polymer tube can be inspected using a noncontact and nondestructive terahertz inspection method with the CNN deep-learning algorithm."
배터리 리드탭 압흔 오류 검출의 딥러닝 기법 적용,2022,"['배터리 리드탭', '압흔 오류 검출', '인공지능', '딥러닝', 'Faster R-CNN', '객체 탐지', 'Battery lead tab', 'Welding error detection', 'Artificial intelligence', 'Deep learning', 'Faster R-CNN', 'Object detection']","자동차용 배터리 제조공정 가운데 하나인 Tab Welding 공정에서 생산된 제품의 샘플링 인장검사를 대체하기 위해 현재 비전검사기를 개발하여 사용하고 있다. 그러나, 비전검사는 검사 위치 오차 문제와 이를 개선하기 위해 발생하는 비용 문제를 가지고 있다. 이러한 문제점들을 해결하기 위해 최근 딥러닝 기술을 적용하는 사례들이 발생하고 있다. 본 논문도 그런 사례 중 하나로 기존 제품 검사에 딥러닝 기술 중 하나인 Faster R-CNN을 적용하여 그 유용성을 파악하고자 하였다. 기존 비전검사기를 통해 획득한 이미지들을 학습 데이터로 사용하여 Faster R-CNN ResNet101 V1 1024x1024 모델을 사용하여 학습하였다. 검사 기준인 미검률 0%, 과검률 10%의 기준으로 기존 비전검사와 Faster R-CNN 검사결과를 비교 분석하였다. 미검출률은 기존 비전검사에서 34.5%, Faster R-CNN 검사에서 0%였다. 과검출률은 기존 비전검사에서 100%, Faster R-CNN에서 6.9%였다. 결론적으로 자동차용 배터리 리드탭 암흔 오류 검출에 딥러닝 기술이 매우 유용함을 확인할 수 있었다.",
Frequency response similarity-based bolt clamping force prediction method using convolutional neural networks,2022,"['Bolt clamping force', 'Frequency response function', 'Krylov subspace-based model order reduction', 'MS similarity function', 'MS similarity map', 'Deep learning', 'CNN']",,"This paper proposes a convolutional neural network (CNN)-based method with which to predict bolt clamping force using the frequency response of bolted structures. The dynamic characteristics of the bolted structure change with the bolt clamping force, which is predicted using a CNN trained with massive frequency response data. Big data required for training the CNN is constructed using prestressed frequency response analysis according to the clamping force of individual bolts. The numerical efficiency is increased using the Krylov subspace-based model order reduction (MOR) method. The frequency response for each set of bolt clamping forces calculated from the MOR method is converted into form of the magnitude and shape (MS) similarity spectrum by using the MS similarity function. Finally, an MS similarity map is generated by stacking the MS similarity spectrum at several output points. A CNN that is trained using massive MS similarity maps as training data, is used to predict the clamping force of bolted structures. To validate the efficiency and accuracy of a trained CNN in practical applications, the prediction results of the trained network in terms of computation time and accuracy were compared according to the size of the training input data."
Shrinkage Crack Detection in Expansive Soil using Deep Convolutional Neural Network and Transfer Learning,2022,"['Shrinkage crack', 'Crack detection', 'Expansive soil', 'Deep learning', 'Deep convolutional neural network']",,"The formation of shrinkage cracks is a natural phenomenon in expansive soils. The development of these cracks affects both the physical and mechanical properties of the soil. This paper proposes new procedures for predicting and detecting the formation of crack patterns in expansive soils, based on customized Convolution Neural Network (CNN) and transfer learning. A total of four different deep learning models are developed to detect the soil crack pattern by changing the convolution layers and hyper-parameters in the analysis. The novelty of the proposed detection methods lies in the use of customized CNN models in shrinkage crack detection for expansive soils. The customized CNN models are constructed by varying the number of convolution layers and the hyperparameters. The results show that the proposed CNN models provide very accurate results and are capable of detecting the presence of cracks in the soil with great accuracy. The best results are from one of the customized CNN models namely the Customized CNN Model 2 which consists of five convolution layers, three activation layers, one pooling layer, two fully connected layers, and a softmax layer. The results from this model are compared with other well-known approaches from the literature and are shown to provide improved results. Overall, the proposed deep learning methods developed in this paper produce excellent results in terms of the accurate detection of shrinkage soil cracks and can also be applied to other types of soil cracks."
기계학습을 통한 주간 반투명 구름탐지 연구: GK-2A/AMI를 이용하여,2022,"['GK-2A/AMI', 'Transparent cloud', 'Cloud detection', 'Machine learning']",,"Clouds are composed of tiny water droplets, ice crystals, or mixtures suspended in the atmosphere and cover about two-thirds of the Earth's surface. Cloud detection in satellite images is a very difficult task to separate clouds and non-cloud areas because of similar reflectance characteristics to some other ground objects or the ground surface. In contrast to thick clouds, which have distinct characteristics, thin transparent clouds have weak contrast between clouds and background in satellite images and appear mixed with the ground surface. In order to overcome the limitations of transparent clouds in cloud detection, this study conducted cloud detection focusing on transparent clouds using machine learning techniques (Random Forest [RF], Convolutional Neural Networks [CNN]). As reference data, Cloud Mask and Cirrus Mask were used in MOD35 data provided by MOderate Resolution Imaging Spectroradiometer (MODIS), and the pixel ratio of training data was configured to be about 1:1:1 for clouds, transparent clouds, and clear sky for model training considering transparent cloud pixels. As a result of the qualitative comparison of the study, bothRF and CNN successfully detected various types of clouds, including transparent clouds, and in the case of RF+CNN, which mixed the results of the RF model and the CNN model, the cloud detection was well performed, and was confirmed that the limitations of the model were improved. As a quantitative result of the study, the overall accuracy (OA) value of RF was 92%, CNN showed 94.11%, and RF+CNN showed 94.29% accuracy."
지능형 OCR 시스템을 위한 한글 필기체 생성 및 분류 모델에 관한 연구,2022,"['OCR', 'CNN', 'GAN', 'Handwriting generation', 'Handwriting recognition', 'OCR', 'CNN', 'GAN', '필체 생성', '필체 인식']","본 논문에서는 다양한 산업분야에 적용 가능한 딥러닝 알고리즘 기반의 한글 필기체 생성 및 분류 모델을 구현하였다. 구현된 GAN 기반의 한글 필기체 생성 모델과 CNN 기반의 한글 필기체 분류 모델 2가지로 구성되어 있다. GAN 모델은 가짜 한글 필기체 데이터를 생성하기 위한 생성자 모델과 가짜 필기체 데이터를 판별하기 위한 판별자 모델로 구성된다. CNN 모델의 경우 'PHD08' 데이터세트를 활용하여 모델의 학습을 수행하였으며, 학습 결과 92.45% 정확도로 한글 필기체를 분류하는 것을 확인하였다. 구현된 GAN 모델을 통해 생성된 한글 필기체 데이터를 기존 CNN 모델의 학습 데이터세트와 통합하여 분류 모델의 성능평가를 진행한 결과 96.86%로 기존 분류 성능보다 우수하게 나타남을 확인하였다.",
OFDM 레이다를 위한 딥러닝 기반 표적의 거리 및 속도 추정 기법,2022,"['OFDM 레이다', '다중 출력 CNN', '거리 및 속도 추정', '딥러닝', 'OFDM radar', 'Multiple output CNN', 'Distance and velocity estimation', 'Deep learning']",본 논문에서는 OFDM 레이다를 위한 딥러닝 기반 표적의 거리 및 속도 추정 기법을 제안한다. 제안하는 기법은 표적으로부터 반사된 수신 신호를 받아 변조신호 제거 후 2차원 FFT를 통해 2차원 주기도를 얻는다. 주기도는 기존 및 제안 방법에서 표적의 거리 및 속도를 추정하는 입력신호이다. 주기도에서 정점은 표적의 위치를 나타내는데 표적의 거리 및 속도 추정을 위해 널리 사용되는 기존 기법은 CFAR (Constant False Alarm Rate) 알고리즘이다. 반면 제안하는 기법은 다중 출력 CNN (Convolutional Neural Network)을 이용하여 거리 및 속도를 추정한다. 기존 기법과 달리 제안 기법은 주기도 이외에 잡음 전력과 같이 추가적인 정보가 필요하지 않아 사용하기 편리하다. 컴퓨터 시뮬레이션 결과에 따르면 제안 추정 기법은 기존 기법보다 거리 및 속도 추정 MSE (Mean Square Error)오차 성능을 5배 이상 개선하며 송신 OFDM 심볼 개수가 증가할수록 정확도가 향상되는 특성을 보인다.,"In this paper, we propose deep learning-based target distance and velocity estimation technique for OFDM radar systems. In the proposed technique, the 2D periodogram is obtained via 2D fast Fourier transform (FFT) from the reflected signal after removing the modulation effect. The periodogram is the input to the conventional and proposed estimators. The peak of the 2D periodogram represents the target, and the constant false alarm rate (CFAR) algorithm is the most popular conventional technique for the target’s distance and speed estimation. In contrast, the proposed method is designed using the multiple output convolutional neural network (CNN). Unlike the conventional CFAR, the proposed estimator is easier to use because it does not require any additional information such as noise power. According to the simulation results, the proposed CNN improves the mean square error (MSE) by more than 5 times compared with the conventional CFAR, and the proposed estimator becomes more accurate as the number of transmitted OFDM symbols increases."
합성곱 신경망을 이용한 풍력 블레이드 상태 구분,2022,"['wind turbine blade', 'CNN', 'state classification', 'spectrogram', 'classification accuracy', '.']","본 논문에서는 풍력 블레이드의 상태를 구분하기 위한 CNN 구분기 설계 및 구분 실험 결과를 제시한다. 상태별로 서로 다른 CNN 구분기를 설계하였으며 구분기 1에는 외관 상태, 구분기 2에는 동작 상태를 구분하였다. 구분하려고 하는 풍력 블레이드의 상태로는 외형적으로는 정상 상태와 파손 상태를 가정하였으며, 동작적으로는 정상 회전과 불균형 회전을 가정하였다. 훈련 데이터는 상태별 잡음이 없는 스펙트로그램을 사용하였고 테스트 데이터는 가우시안 잡음을 추가하여 구분기의 성능을 검증하였다. 실험 결과 SNR이 좋아짐에 따라 구분 결과도 향상되었으며, 5dB 상태일 때 구분기 1의 구분 정확도는 99.83%, 구분기 2의 구분 정확도는 98.68%를 가짐을 확인하였다. 본 연구를 통하여 딥러닝 구분기가 가중합 그래프와 플래시 간격 그래프를 이용하는 선행 연구에 비해 더 좋은 구분 성능을 나타냄을 확인하였다.","This paper shows the CNN(Convolutional neural network) classifier design and simulation results for classifying the state of the wind turbine blade. The separate CNN classifiers are designed to classify by a state, and the appearance states were classified in the classifier 1 and the operation states in the classifier 2. The states of the wind turbine blade to be classified are assumed to be a normal state and a damaged state by an appearance, and a balanced rotation and unbalanced rotation by an operation. As the training data, spectrograms without noise for each state are used, and as the test data, spectrograms with noise are used to verify the performance of the classifier. As a result, the classification performance is improved as the SNR is increased, and the classification accuracy of classifier 1 is 99.83% and the classification accuracy of classifier 2 was 98.68% at the SNR of 5 dB. This research shows that the deep learning classifier has the better performance than the previous research which use the weighted sum graph and the flash interval graph."
MOX 가스센서의 시료 주입 전후패턴들을 이용한 신경회로망 기반의 적포도주 분류,2022,"['MOX gas sensor', 'electronic nose', 'SVM', 'CNN', 'red wine classification', '.']","MOX(Metal OXide) 가스센서는 고감도, 저가, 긴수명 등 여러 장점에도 불구하고 반응 값의 드리프트로 인해 여전히 안전 방재 영역에서 산업화에 어려움을 가지고 있다. 본 논문에서는 4 종류의 적포도주들의 시료에 대해서 MOX 가스센서의 시료 측정 전의 센서의 상태를 측정하고 그 결과를 시료 측정 후의 데이터에 통합하여  SVM(Support Vector Machine)과 CNN(Convolution Neural Network) 분류 모델의 입력으로 사용하였다. MOX 가스센서의 시료 측정 전의 센서의 상태를 측정하여 분류 모델의 입력 데이터에 포함한 SVM 모델의 경우는 4 종류의 포도주를 100% 정확하게 분류 하였으나 그 데이터를 배제한 경우는 4 종류의 포도주를 2 종류로만 분류 하였다. CNN 모델의 경우는 그 데이터를 포함한 경우에는 4 종류의 포도주를 100% 정확하게 분류하였으나 그 데이터를 배제한 경우에는 1 종류로만 분류하였다.","In spite of a lot of merits of MOX (metal oxide) gas sensor such as high sensitivity, low cost, and long lifetime, it is not popular for MOX gas sensor to be used in fields of safty and security areas due to a lack of stability such as drift. This paper dramatically improves the classification ability for the four kinds of red wines which are prepared here using SVM and CNN classification models based on data before and after sample measurements. In the case of the SVM model, which the data of the state of the sensor before measuring the sample is included in,, 4 kinds of red wine are classified with 100% accuracy, but In the case of the exclusion of the data, the tested wines are classified only with 2 kinds. In the case of the CNN model, which the data of the state of the sensor before measuring the sample is included in,, 4 kinds of red wine are classified with 100% accuracy, but In the case of the exclusion of the data, the wines are classified only one kind."
Hybrid quantum-classical convolutional neural network model for COVID-19 prediction using chest X-ray images,2022,"['COVID-19', 'medical image classification', 'deep neural networks', 'quanvolutional neural networks', 'quantum computing', 'image processing']",,"Despite the great efforts to find an effective way for coronavirus disease 2019 (COVID-19) prediction, the virus nature and mutation represent a critical challenge to diagnose the covered cases. However, developing a model to predict COVID-19 via chest X-ray images with accurate performance is necessary to help in early diagnosis. In this paper, a hybrid quantum-classical convolutional neural network (HQ-CNN) model using random quantum circuits as a base to detect COVID-19 patients with chest X-ray images is presented. A collection of 5445 chest X-ray images, including 1350 COVID-19, 1350 normal, 1345 viral pneumonia, and 1400 bacterial pneumonia images, were used to evaluate the HQ-CNN. The proposed HQ-CNN model has achieved higher performance with an accuracy of 98.6% and a recall of 99% on the first experiment (COVID-19 and normal cases). Besides, it obtained an accuracy of 98.2% and a recall of 99.5% on the second experiment (COVID-19 and viral pneumonia cases). Also, it obtained 98% and 98.8% for accuracy and recall, respectively, on the third dataset (COVID-19 and bacterial pneumonia cases). Lastly, it achieved accuracy and recall of 88.2% and 88.6%, respectively, on the multiclass dataset cases. Moreover, the HQ-CNN model is assessed with the statistical analysis (i.e. Cohen’s Kappa and Matthew correlation coefficients). The experimental results revealed that the proposed HQ-CNN model is able to predict the positive COVID-19 cases."
Classification of Midinfrared Spectra of Colon Cancer Tissue Using a Convolutional Neural Network,2022,"['Convolution neural network', 'Hyperspectral imaging', 'Mid-infrared']",,"The development of midinfrared (mid-IR) quantum cascade lasers (QCLs) has enabled rapid highcontrast measurement of the mid-IR spectra of biological tissues. Several studies have compared the differences between the mid-IR spectra of colon cancer and noncancerous colon tissues. Most midIR spectrum classification studies have been proposed as machine-learning-based algorithms, but this results in deviations depending on the initial data and threshold values. We aim to develop a process for classifying colon cancer and noncancerous colon tissues through a deep-learning-based convolutionalneural-network (CNN) model. First, we image the midinfrared spectrum for the CNN model, an imagebased deep-learning (DL) algorithm. Then, it is trained with the CNN algorithm and the classification ratio is evaluated using the test data. When the tissue microarray (TMA) and routine pathological slide are tested, the ML-based support-vector-machine (SVM) model produces biased results, whereas we confirm that the CNN model classifies colon cancer and noncancerous colon tissues. These results demonstrate that the CNN model using midinfrared-spectrum images is effective at classifying colon cancer tissue and noncancerous colon tissue, and not only submillimeter-sized TMA but also routine colon cancer tissue samples a few tens of millimeters in size."
딥러닝 기반 운동 자세 교정 시스템의 성능,2022,"['CNN', 'Deep learning', 'Human activity recognition', 'LSTM', 'RNN', 'Time series classification']",,"Recently, interesting of home training is getting bigger due to COVID-19. Accordingly, research on applying HAR(human activity recognition) technology to home training has been conducted. However, existing paper of HAR proposed static activity instead of dynamic activity. In this paper, the deep learning model where dynamic exercise posture can be analyzed and the accuracy of the user's exercise posture can be shown is proposed. Fitness images of AI-hub are analyzed by blaze pose. The experiment is compared with three types of deep learning model: RNN(recurrent neural network), LSTM(long short-term memory), CNN(convolution neural network). In simulation results, it was shown that the f1-score of RNN, LSTM and CNN is 0.49, 0.87 and 0.98, respectively. It was confirmed that CNN is more suitable for human activity recognition than other models from simulation results. More exercise postures can be analyzed using a variety learning data."
Study of Convolution Neural Network Based Deep Learning to Classify the Quality  of Self-Piercing Riveting Joint,2022,"['Convolution  Neural  Network(CNN)', 'Classification', 'Self-Piercing  Rivet(SPR)', 'Deep  learning', 'Abnormal process  conditions']",,"The SPR(Self-Piercing Riveting) process is a mechanical joining process that is mainly applied to assembling multi- material parts to reduce the weight of the car body. Because the quality of SPR joints is mainly evaluated through cross sectional inspection, which is a type of destructive inspection, it is expensive and time-consuming. Machine learning technology is being proposed as a non-destructive testing because it can predict the quality based on the signals generated during the process. However, research result on the quality prediction modeling of SPR joints have not yet been reported. In this study, the prediction accuracy according to the signal combination was compared and evaluated by applying the CNN algorithm using the displacement and load signals generated during the SPR process and the acoustic signal obtained from the acoustic sensor. The materials used in the experiment were SGAFC 1180Y, CFRP, and SPFC 590 and the thickness were 1.4 mm, 1.8 mm, and 1.0 m respectively and a three-layer SPR process was performed. After evaluating joining was performed by selecting the abnormal process conditions, with 12 con- ditions that may occur during the process. Consequently, in the case of the first model in which the CNN algorithm was based on displacement and load signals, the quality prediction accuracy was estimated to be 90.0%. In the case of the second model in which the CNN algorithm added acoustic signals to the displacement and load signals, the quality prediction accuracy was estimated to be 77.5%."
Evaluation of maxillary sinusitis from panoramic radiographs and cone-beam computed tomographic images using a convolutional neural network,2022,"['Artificial Intelligence', 'Maxillary Sinusitis', 'Panoramic Radiography', 'Cone-Beam Computed Tomography']",,"Purpose: This study developed a convolutional neural network (CNN) model to diagnose maxillary sinusitis on panoramic radiographs(PRs) and cone-beam computed tomographic (CBCT) images and evaluated its performance. Materials and Methods: A CNN model, which is an artificial intelligence method, was utilized. The model was trained and tested by applying 5-fold cross-validation to a dataset of 148 healthy and 148 inflamed sinus images. The CNN model was implemented using the PyTorch library of the Python programming language. A receiver operating characteristic curve was plotted, and the area under the curve, accuracy, sensitivity, specificity, positive predictive value, and negative predictive values for both imaging techniques were calculated to evaluate the model. Results: The average accuracy, sensitivity, and specificity of the model in diagnosing sinusitis from PRs were 75.7%, 75.7%, and 75.7%, respectively. The accuracy, sensitivity, and specificity of the deep-learning system in diagnosing sinusitis from CBCT images were 99.7%, 100%, and 99.3%, respectively. Conclusion: The diagnostic performance of the CNN for maxillary sinusitis from PRs was moderately high, whereas it was clearly higher with CBCT images. Three-dimensional images are accepted as the ""gold standard"" for diagnosis; therefore, this was not an unexpected result. Based on these results, deep-learning systems could be used as an effective guide in assisting with diagnoses, especially for less experienced practitioners."
FEC 환경에서 다중 분기구조의 부분 오프로딩 시스템,2022,"['Fog/Edge Computing', 'Partial Offloading', 'Multi-branch Structure', '2-Tier Cooperative Computing', 'CNN Layer Scheduling', '포그/에지 컴퓨팅', '부분 오프로딩', '다중 분기구조', '2계층 협력 컴퓨팅', 'CNN 계층 스케줄링']","본 논문에서는 FEC (Fog/Edge Computing) 환경에서 다중 분기구조의 부분 오프로딩을 위해 모바일 장치와 에지 서버로 구성된 2계층 협력 컴퓨팅 시스템을 제안한다. 제안 시스템은 다중 분기구조에 대한 재구성 선형화 기법을 적용하여 응용 서비스 처리를 분할하는 알고리즘과 모바일 장치와 에지 서버 간의 부분 오프로딩을 통한 최적의 협업 알고리즘을 포함한다. 또한 계산 오프로딩 및 CNN 계층 스케줄링을 지연시간 최소화 문제로 공식화하고 시뮬레이션을 통해 제안 시스템의 효과를 분석한다. 실험 결과 제안 알고리즘은 DAG 및 체인 토폴로지 모두에 적합하고 다양한 네트워크 조건에 잘 적응할 수 있으며, 로컬이나 에지 전용 실행과 비교하여 효율적인 작업 처리 전략 및 처리시간을 제공한다. 또한 제안 시스템은 모바일 장치에서의 응용 서비스 최적 실행을 위한 모델의 경량화 및 에지 리소스 워크로드의 효율적 분배 관련 연구에 적용 가능하다.","We propose a two-tier cooperative computing system comprised of a mobile device and an edge server for partial offloading of multi-branch structures in Fog/Edge Computing environments in this paper. The proposed system includes an algorithm for splitting up application service processing by using reconstructive linearization techniques for multi-branch structures, as well as an optimal collaboration algorithm based on partial offloading between mobile device and edge server. Furthermore, we formulate computation offloading and CNN layer scheduling as latency minimization problems and simulate the effectiveness of the proposed system. As a result of the experiment, the proposed algorithm is suitable for both DAG and chain topology, adapts well to different network conditions, and provides efficient task processing strategies and processing time when compared to local or edge-only executions. Furthermore, the proposed system can be used to conduct research on the optimization of the model for the optimal execution of application services on mobile devices and the efficient distribution of edge resource workloads."
Evaluation of maxillary sinusitis from panoramic radiographs and cone-beam computed tomographic images using a convolutional neural network,2022,"['Artificial Intelligence', 'Maxillary Sinusitis', 'Panoramic Radiography', 'Cone-Beam Computed Tomography']",,"Purpose: This study developed a convolutional neural network (CNN) model to diagnose maxillary sinusitis on panoramic radiographs (PRs) and cone-beam computed tomographic (CBCT) images and evaluated its performance. Materials and Methods: A CNN model, which is an artificial intelligence method, was utilized. The model was trained and tested by applying 5-fold cross-validation to a dataset of 148 healthy and 148 inflamed sinus images. The CNN model was implemented using the PyTorch library of the Python programming language. A receiver operating characteristic curve was plotted, and the area under the curve, accuracy, sensitivity, specificity, positive predictive value, and negative predictive values for both imaging techniques were calculated to evaluate the model. Results: The average accuracy, sensitivity, and specificity of the model in diagnosing sinusitis from PRs were 75.7%, 75.7%, and 75.7%, respectively. The accuracy, sensitivity, and specificity of the deep-learning system in diagnosing sinusitis from CBCT images were 99.7%, 100%, and 99.3%, respectively.Conclusion: The diagnostic performance of the CNN for maxillary sinusitis from PRs was moderately high, whereas it was clearly higher with CBCT images. Three-dimensional images are accepted as the “gold standard” for diagnosis; therefore, this was not an unexpected result. Based on these results, deep-learning systems could be used as an effective guide in assisting with diagnoses, especially for less experienced practitioners."
Two-phase flow pattern online monitoring system based on convolutional neural network and transfer learning,2022,"['Flow pattern', 'Online monitoring system', 'Artificial neural network (ANN)', 'Convolutional neural network (CNN)', 'Transfer learning', 'ResNet50']",,"Two-phase flow may almost exist in every branch of the energy industry. For the corresponding engineering design, it is very essential and crucial to monitor flow patterns and their transitions accurately.With the high-speed development and success of deep learning based on convolutional neural network (CNN), the study of flow pattern identification recently almost focused on this methodology. Additionally, the photographing technique has attractive implementation features as well, since it is normally considerably less expensive than other techniques. The development of such a two-phase flow pattern online monitoring system is the objective of this work, which seldom studied before. The ongoing preliminary engineering design (including hardware and software) of the system are introduced. The flow pattern identification method based on CNNs and transfer learning was discussed in detail. Several potential CNN candidates such as ALexNet, VggNet16 and ResNets were introduced and compared with each other based on a flow pattern dataset. According to the results, ResNet50 is the most promising CNN network for the system owing to its high precision, fast classification and strong robustness. This work can be a reference for the online monitoring system design in the energy system."
실내 바닥면 포인트 클라우드를 이용한 AI 기반 3D 공간구조 추정 기술,2022,"['3D reconstruction', 'Spatial Structure Estimation', 'Digital Twin', 'Coner Detection', 'Metaverse', '3D 재구성', '공간구조 추정', '디지털 트윈', '코너 탐지', '메타버스']","본 논문에서는 RGB-D 카메라를 이용해 실세계 실내 공간을 스캔하여 포인트 클라우드로 구성된 가상공간을 구축한다. 포인트 클라우드는 분산되고 노이즈가 많은 특성이 있어 (포인트 클라우드를 이용하여) 실세계와 유사한 가상공간을 재구성하는 것은 어려운 일이며 매우 도전적인 과제이다. 우리는 CNN 모델을 기반으로 3차원 공간의 구조를 추정하여 모델링 하는 효율적인 방법을 제안한다. 3차원 재구성 알고리즘을 기반으로 RGB-D 이미지 통해 실내 포인트 클라우드를 생성하고, 바닥면 데이터를 추출한다. 바닥면 포인트 클라우드 데이터는 2차원 바이너리 영상으로 투영 변환되고, CNN 모델을 이용해 바닥면의 코너를 탐지한다. 이를 기반으로 실내 공간의 3차원 공간구조를 추정하고 모델링 한다. 향후 본 연구는 효율적으로 실세계와 유사한 메타버스 공간을 구축하는 데에 기여할 것이다.","In this paper, we construct a virtual space composed of point clouds by scanning real-world indoor spaces using RGB-D cameras. Point clouds have distributed and noisy properties, making it difficult and a very challenging task to reconstruct a virtual space similar to the real world (using point clouds). We propose an efficient method for estimating and modeling the structure of 3D space based on CNN model. Based on the 3D reconstruction algorithm, an indoor point cloud is created through RGB-D images and floor data is extracted. Floor point cloud data is projected and converted into 2D binary images, and corners of floor is detected using CNN model. Based on this, the 3D spatial structure of the indoor space is estimated and modeled. In the future, this study will contribute to efficiently establishing a metaverse space similar to the real world."
FMCW 레이다 센서 기반 사람과사물 분류 시스템 설계 및 구현,2022,"['BNN accelerator', 'embedded system', 'FMCW radar', 'FPGA', 'multi-target tracking']","본 논문에서는 FMCW(frequency modulated continuous wave) 레이다 센서를 활용한 사람과 사물을 분류하는 시스템 설계및 구현 결과를 제시한다. 해당 시스템은 다중 객체 탐지를 위한 레이다 센서 신호처리 과정과 객체를 사람 및 사물로 분류하는 딥러닝 과정을 수행한다. 딥러닝의 경우 높은 연산량과 많은 양의 메모리를 요구하기 때문에 경량화가 필수적이다. 따라서 CNN(convolution neural network) 연산을 이진화하여 동작하는 BNN (binary neural network) 구조를 적용하였으며, 실시간 동작을위해 하드웨어 가속기를 설계하고 FPGA 보드 상에서 구현 및 검증하였다. 성능 평가 및 검증 결과 90.5%의 다중 객체 구분 정확도,CNN 대비 96.87% 감소된 메모리 구현이 가능하며, 총 수행 시간은 5ms로 실시간 동작이 가능함을 확인하였다.","This paper proposes the design and implementation results for human and object classification systems utilizingfrequency modulated continuous wave (FMCW) radar sensor. Such a system requires the process of radar sensorsignal processing for multi-target detection and the process of deep learning for the classification of human andobject. Since deep learning requires such a great amount of computation and data processing, the lightweightprocess is utmost essential. Therefore, binary neural network (BNN) structure was adopted, operating convolutionneural network (CNN) computation in a binary condition. In addition, for the real-time operation, a hardwareaccelerator was implemented and verified via FPGA platform. Based on performance evaluation and verifiedresults, it is confirmed that the accuracy for multi-target classification of 90.5%, reduced memory usage by 96.87%compared to CNN and the run time of 5ms are achieved."
InfoGAN을 이용한 부분 방전 데이터 생성을 통한 패턴 분류기 개선,2022,"['partial discharge', 'convolutional neural networks', 'generative adversarial networks', 'pattern classifier', '부분방전', '합성곱 신경회로망', '생성적 적대 신경회로망', '패턴 분류기']","부분방전의 인식과 분류 개선을 위한 연구는 많은 양질의 데이터를 요구한다. 그러나 부분방전의 발생이 극히 드물고, 취득이 어려운 문제로 인해 부분적으로 얻어진 실제 데이터를포함한 실험 데이터에 의해 연구가 수행되고 있다. 본 논문에서는 데이터 취득이 제한적인부분방전의 분류 개선을 위해 정보 최대화 생성적 적대 신경회로망(InfoGAN)을 적용한다.InfoGAN은 PRPS 전처리를 통해 이미지 데이터로 변환된 실제 데이터를 입력으로 데이터를생성한다. 생성된 데이터는 설계된 합성곱 신경회로망(CNN) 패턴분류기의 학습 데이터로사용된다. 실 학습데이터와 생성된 데이터를 포함한 학습데이터 양쪽을 통해 구축된 두CNN분류기가 부분방전분류의 비교해석을 위해 고려된다. InfoGAN에 의해 생성된 데이터를 통해 구축된 제안된 분류기가 부분적으로 분류기를 개선할 수 있음을 입증한다","A study to improve the recognition and classification of partial discharge requires lots of quality data. However, lots of studies are carried out by experimental data comprising partially obtained actual data due to the extremely rare occurrence of partial discharge and the problem of difficult acquisition. In this study, information maximizing generative adversarial network(InfoGAN) is applied to improve the classification of partial discharge with limited data acquisition. InfoGAN is exploited to generate fake data by using actual inputs transformed to image data through PRPS preprocessing. The generated data (fake data) is used as training data for constucting the convolutional neural network(CNN) pattern classifier. The two CNN classifiers constrcuted with the help of both actual training(existing) data and actual training data including fake data(generated data) are considered for the comparison analysis of partial discharge classification. The experimental results demonstrate that the proposed calssifier constructed through data generated by InfoGAN could partially improve the exising classifier"
볼 베어링 고장진단 기법 비교 및 XAI Grad-CAM을 이용한 분류결과 해석 연구,2022,"['Convolutional Neural Network', 'Bearing Fault', 'Fault Classification', 'XAI', 'Grad-CAM']",,"Various machine learning and deep learning methods were proposed to monitor and classify the bearing's health state using vibration signals since bearing faults are one of the most causes of failure of rotationary machine. The process of diagnosing bearing faults using machine learning is as follows. First, the features, including the fault characteristic of the vibration signals, are extracted, and these features are selected to reduce the dimension of the features. These features are input into the machine learning classifier to diagnose the system's health. In addition to machine learning methods, CNN, one of the deep learning methods, is widely used.Since the deep learning model extracts features by itself, only the preprocessing process of converting the bearing signals into 2D is needed. The fault classification accuracy of two vibration signal transformation methods as preprocessing methods for the CNN model was compared. This paper compares the bearing fault classification performance of several machine learning commonly used and the CNN model for the lab-made wind turbine machinery testbed. By comparing different feature extraction, feature selection, and classification methods, the most appropriate pipeline is selected for the testbed. Also, grad-cam, an explainable AI(XAI) technique, is applied to interpret the CNN based classification in terms of interested frequency bandwidth. The XAI analysis was verified by designing preprocessing filters based on the grad-cam outputs for enhancing classification performance."
Convolutional LSTM 모델 기반의 짧은 지연 시간을 갖는 베어링 결함 진단,2022,"['Fault diagnosis', 'Neural networks', 'Embedded systems', 'Low-latency monitoring systems']",,
TsCNNs-Based Inappropriate Image and Video Detection System for a Social Network,2022,"['CNN', 'Intelligent Image and Video Detection System', 'Tree-Structured Convolutional Neural Networks (TsCNNs)']",,"We propose a detection algorithm based on tree-structured convolutional neural networks (TsCNNs) that findspornography, propaganda, or other inappropriate content on a social media network. The algorithm sequentiallyapplies the typical convolutional neural network (CNN) algorithm in a tree-like structure to minimizeclassification errors in similar classes, and thus improves accuracy. We implemented the detection system andconducted experiments on a data set comprised of 6 ordinary classes and 11 inappropriate classes collected fromthe Korean military social network. Each model of the proposed algorithm was trained, and the performancewas then evaluated according to the images and videos identified. Experimental results with 20,005 new imagesshowed that the overall accuracy in image identification achieved a high-performance level of 99.51%, and theeffectiveness of the algorithm reduced identification errors by the typical CNN algorithm by 64.87 %. Byreducing false alarms in video identification from the domain, the TsCNNs achieved optimal performance of98.11% when using 10 minutes frame-sampling intervals. This indicates that classification through propersampling contributes to the reduction of computational burden and false alarms."
Emotion Recognition using Short-Term Multi-Physiological Signals,2022,"['Convolutional Neural Network (CNN)', 'Emotion Recognition', 'Physiological Signal']",,"Technology for emotion recognition is an essential part of human personality analysis. To define human personality characteristics, the existing method used the survey method. However, there are many cases where communication cannot make without considering emotions. Hence, emotional recognition technology is an essential element for communication but has also been adopted in many other fields.A person's emotions are revealed in various ways, typically including facial, speech, and biometric responses. Therefore, various methods can recognize emotions, e.g., images, voice signals, and physiological signals. Physiological signals are measured with biological sensors and analyzed to identify emotions. This study employed two sensor types. First, the existing method, the binary arousal-valence method, was subdivided into four levels to classify emotions in more detail. Then, based on the current techniques classified as High/Low, the model was further subdivided into multi-levels. Finally, signal characteristics were extracted using a 1-D Convolution Neural Network (CNN) and classified sixteen feelings. Although CNN was used to learn images in 2D, sensor data in 1D was used as the input in this paper. Finally, the proposed emotional recognition system was evaluated by measuring actual sensors."
Fourier Ptychographic Microscopy 영상에서의 딥러닝 기반 디지털 염색 방법 연구,2022,"['딥러닝', 'GAN', 'MASK R-CNN', 'H&E 염색', 'FPM', 'Deep learning', 'GAN', 'MASK R-CNN', 'H&E stain', 'FPM']","본 연구에서 세포를 분별하기 위해 H&E 염색이 필요하다. 직접 염색하는 많은 비용과 시간이 필요하다. H&E 염색되지 않은 세포의 Phase image에서 H&E 염색이 된 세포의 Amplitude image로 변환하는 것이 목적이다. FPM으로 촬영한 Image data를 가지고 Matlab을 이용해 매개변수를 변경해 Phase image와 Amplitude image를 만들었다. 정규화를 통해 육안으로 식별이 가능한 이미지를 얻었다. GAN 알고리즘을 이용해 Phase image를 기반으로 Real Amplitude image와 비슷한 Fake Amplitude image를 만들고 Fake Amplitude image를 가지고 MASK R-CNN을 이용하여 세포를 분별하여 객체화를 통해 구분했다. 연구 결과 D loss의 max는 3.3e-1, min은 6.8e-2, G loss max는 6.9e-2, min은 2.9e-2, A loss는 max 5.8e-1, min는 1.2e-1, mask rcnn max는 1.9e0, min은 3.2e-1이다.",
Identification of Defects in Casting Products by using a Convolutional Neural Network,2022,"['Casting quality inspection', 'CNN', 'Industry 4.0', 'Machine learning']",,"The main perspective when ensuring dependability in speculations over accuracy in casting parts is a project quality confirmation process that is both careful and meticulous under Industry 4.0. When thorough and extensive casting project examination strategies merge with expanded metal project quality standards, casting production, augmented visual inspections, ensemble process modification and execution are improved. In this paper, we use publicly available casting image datasets for visual inspection, which classify defective and non-defective casting. Inspired by the convolutional neural network (CNN), we propose two-stage convolution for modeling, with DenseNet for classifying casting products. Through experimentation, we achieved an F1-score of 99.54% with a processing time of 454ms using a CPU for classification of casting product inspections. The modified modeling of the CNN in this work helps to improve optimization, compared to other basic machine learning mechanisms that measure quality."
Comparison of Deep Learning-Based Object Classification Methods for Detecting Tomato Ripeness,2022,"['SSD', 'Faster R-CNN', 'YOLO', 'Object detection']",,"Examination of the technological development in agriculture reveals that not many applicationsuse cameras to detect tomato ripeness; therefore, tomato maturity is still determined manually.Currently, technological advances and developments are occurring rapidly, and are, therefore,also inseparable from the agricultural sector. Object detection can help determining tomatoripeness. In this research, faster region-based convolutional neural network (Faster R-CNN),single shot multibox detector (SSD), and you only look once (YOLO) models were tested torecognize or detect tomato ripeness using input images. The model training process required 5hours and produced a total loss value <0.5, and as the total loss became smaller, the predictedresults improved. Tests were conducted on a training dataset, and average accuracy values of99.55%, 89.3%, and 94.6% were achieved using the Faster R-CNN, SSD, and YOLO models,respectively"
Capacity estimation of lithium‑ion batteries using convolutional neural network and impedance spectra,2022,"['Convolutional neural network (CNN)', 'Electrochemical impedance spectroscopy (EIS)', 'State of health (SoH)', 'Capacity']",,"Battery capacity is a parameter that has a very close association with the state of health (SoH) of a Li-ion battery. Due to the complex electrochemical mechanisms behind the degradation of battery life, the estimation of SoH encounters many difficulties. To date, experiment-based methods, model-based methods, and data-driven models have been developed to estimate capacity using data from charging curves. In the case of EVs and HEVs, due to the unpredictable charge patterns employed by users, it is not known how much charging data will be available to predict the capacity at a given point in time. This paper presents a method to accurately estimate capacity using impedance curves obtained from an electrochemical impedance spectroscopy (EIS) test and a convolutional neural network (CNN). The CNN model was trained using the impedance data of a single cell collected at different SoH values, and the trained model was verified using the impedance data of eight other cells. The maximum error in the prediction was found to be 0.57 (% capacity) and the RMS error was found to be 0.233 (% capacity). These results illustrate the accuracy and robustness of the proposed model."
가상 데이터 증식을 이용한 Pix2pix 기반의 물방울 제거 학습,2022,"['deep learning', 'GAN', 'CNN', 'Pix2pix', 'augmentation learning', 'rainwater removal', '.']","본 논문은 딥러닝 기법을 활용하여 영상에서 카메라 렌즈 상에 물방울이 맺힌 부분을 효율적으로 제거하는 영상 변환 방법을 제안한다. 제안 방법에서 다른 도메인의 영상을 새롭게 형성한다는 점에 있어 두 영상의 특징을 잘 파악할 수 있는 GAN(Pix2pix Generative Adversarial Network) 모델을 통해 효과적으로 물방울이 제거된 영상을 얻는 방법을 제안한다. 또한, 촬영 영상을 기반으로 하는 학습 방법에 있어 많은 학습용 데이터가 필요하다는 점과 모델 학습 특성상 불필요한 노이즈가 발생하거나 물방울 사진을 정확하게 얻지 못하는 경우가 발생될 수 있는데, 가상의 물방울 영상 데이터를 생성하고 CNN(Convolution Neural Network)을 이용하여 효과적으로 식별함으로써 학습 데이터를 효율적으로 확보하는 방법을 제안한다.","In this paper, we propose a system that efficiently removes pictures with water droplets on the camera lens using deep learning techniques. We propose a method to effectively obtain a water droplet removal image through the Pix2pix Generative Adversarial Networks(GAN) model, which can understand the characteristics of the two images in terms of newly forming images of different domains. In addition, by applying the fake water droplet data formed by applying the fake water droplet data to the Convolution Neural Network(CNN), paying attention to the fact that a lot of training data is required for image learning, as well as unnecessary noise or water droplet pictures cannot be obtained accurately due to the nature of model learning. We propose a method to efficiently secure data by effectively classifying the formed photos."
인체 치수 데이터와 K-means 군집 알고리즘을 활용한 체지방 분류 모델,2022,"['Classification', 'Human body size', 'CNN(Convolutional Neural Network)', 'Fat rate percentage', 'K-means clustering']","최근 헬스케어(healthcare) 분야에서 기계학습을 적용한 다양한 연구가 증가하고 있다. 스마트 워치와 같은 웨어러블(wearable) 장치를 통해 심전도 검사, 체성분 분석 등의 기능을 제공하고 있으며 이러한 기능에 딥러닝 기술이 적용되고 있다. 이를 통해 합리적인 의사 결정과 표준화된 프로세스를 도출하여 개인에 맞는 헬스케어 서비스 구축과 연구에 활용되고 있다. 기존에 있는 진료 기록이나 의료보험 정보뿐만 아니라 정부에서 공개하고 있는 공공데이터, 소셜 미디어 데이터, 유전자 데이터 등 다양한 경로로 수집된 데이터를 활용하고 있다. 이 데이터를 모델에 적용하기 위해서는 데이터를 분류하는 작업 등 사람의 개입이 필요하다. 본 논문에서는 가슴둘레나 허리둘레 등 인체 치수를 입력으로 받아 성별과 나이에 따른 군집 별로 평균 체지방률을 분류하는 모델을 제안한다. 데이터는 국가기술표준원에서 제공하고 있는 인체치수데이터를 활용하였고 이 데이터는 분류 모델에 적용하기 어려운 데이터이므로 군집 알고리즘을 적용한 데이터로 변환하였다. 군집화가 완료된 데이터를 이용하여 CNN(Convolutional Neural Network) 모델에 적용하여 분류를 진행한다. 이를 통해 개인 맞춤형 체형관리 서비스나 비만 분석 등 다양한 응용 사례에 활용될 수 있을 것으로 사료된다.","Recently, various cases of applying machine learning in the healthcare field are increasing. Functions such as electrocardiogram and body composition analysis are provided through wearable devices such as smart watches, and deep learning technology is applied to these functions. Through this, rational decision-making and standardized processes are derived, which is being used in research and construction of healthcare services tailored to individuals. In addition to existing medical records and medical insurance information, data collected through various channels such as public data, social media data, and genetic data disclosed by the government are being utilized. In order to apply this data to the model, human intervention is required, such as classifying to data. In this paper, we propose a model that classifying the average body fat percentage by group according to gender and age by receiving human body size data such as chest circumference and waist circumference as input. For the data, the human body size data provided by National Institute of Technology and Standards was used, and since this data is difficult to apply to the classification model, it was converted into data to which a clustering algorithm was applied. Classification is performed by applying to a CNN(Convolutional Neural Network) model. Through this, it is thought that it can be utilized in various application cases such as personalized body shape management service and obesity analysis."
합성곱 신경망을 이용한 정사사진 기반 균열 탐지 기법,2022,"['Ortho-image', 'UAV', 'Machine learning', 'Crack detection', 'CNN']",,"Visual inspection methods have limitations, such as reflecting the subjective opinions of workers. Moreover, additional equipment is required when inspecting the high-rise buildings because the height is limited during the inspection. Various methods have been studied to detect concrete cracks due to the disadvantage of existing visual inspection. In this study, a crack detection technology was proposed, and the technology was objectively and accurately through AI. In this study, an efficient method was proposed that automatically detects concrete cracks by using a Convolutional Neural Network(CNN) with the Orthomosaic image, modeled with the help of UAV. The concrete cracks were predicted by three different CNN models: AlexNet, ResNet50, and ResNeXt. The models were verified by accuracy, recall, and F1 Score. The ResNeXt model had the high performance among the three models. Also, this study confirmed the reliability of the model designed by applying it to the experiment."
Learning-based Framework for Color Conversion between Digital Cinema Package and Streaming Movie,2022,"['Digital cinema', 'DCP', 'DCI-P3', 'Color gamut', 'CNN']",,"Humans feel different experiences when viewing a cinema at the theater and home. This paper presents methods to reduce the difference in the viewing experience. Based on the workflow of digital cinema distribution, the proposed method attempts to minimize the color difference between digital cinema packages (DCP) for the theater and streaming movies. For end-to-end mapping between the DCP and streaming movie, this paper proposes a convolutional neural network (CNN)-based color conversion algorithm based on the SMPTE standard. The proposed method consists of three steps: i) color conversion using standard matrices, ii) color conversion using the CNN, and iii) color saturation error removal by fusing the results in steps i) and ii). The proposed method enhances the color of TV streaming images because it minimizes the color difference from the DCP and appropriately extends the color gamut. As a result, the proposed method can provide consumers with indistinguishable quality from a DCP movie at the theater."
딥러닝 기반 토마토 잎 병충해 분류 및 시각화를 위한 연구,2022,"['Tomato Pest', 'Deep Learning', 'EfficientNet', 'Grad-CAM', 'CNN', '토마토 병충해', '딥러닝', 'EfficientNet', 'Grad-CAM', 'CNN']","농작물에 피해를 주는 요인은 크게 자연재해와 병충해가 존재하며 병충해는 자연재해보다발생 빈도가 높고 전염이 쉽다. 따라서 병충해가 발생하지 않도록 방제해야 하고, 발생 초기에 바로 진압하는 것이 필요하다. 본 연구에서는 딥러닝 모델을 이용하여 토마토잎의 대표적인 병충해를 분류하고, Grad-CAM 기술을 이용하여 딥러닝 모델이 이미지의 어느 부분을보고 판단하였는지 시각화하여 사용자에게 분류에 대한 근거를 제시하도록 하였다. 또한, 이를 통해 토마토 잎 사진을 이용한 병충해 유무 및 종류를 알려주고 판단의 근거를 시각화해주는 기술을 적용한 웹 애플리케이션을 개발하였다. 본 연구에서는 적은 수의 학습데이터를이용한 효율적인 분류를 위해 다양한 딥러닝 분류 모델 및 학습 방법에 대한 비교 및 분석을 수행하였다. 실험 결과 최신 CNN 모델인 EfficientNetB0 모델로 테스트 분류 정확도99.16%와 0.032초의 추론속도 성능을 보였다","Factors that damage crops are largely natural disasters and pests, and pests occur more frequently than natural disasters and are easily contagious. Therefore, it is necessary to control the disease so that it does not occur, and it is necessary to suppress it immediately at the beginning of the outbreak. In this study, a representative pest of tomato leaf is classified using a deep learning model, and the basis for classification is presented to the user by visualizing which part of the image the deep learning model focuses on and judging using Grad-CAM. In addition, a web application applied with a technology that informs the presence and type of pests using a photo of tomato leaves and visualizes the basis for judgment is developed. In this study, comparison and analysis are performed on various deep learning classification models and training methods for efficient classification using a small number of training data. As a results, the EfficientNetB0 model shows a 99.16% test classification accuracy with 0.032sec inference speed."
"인공지능 딥러닝의 역사와 현황, 그리고 미래 방향",2022,"['Artificial Intelligence (AI)', 'Deep learning', 'Artificial Neural Networks (ANN)', 'Convolutional Neural Network (CNN)', 'Explainable AI (XAI)']",,"Deep learning is a subset of machine learning, and machine learning is also a subset of artificial intelligence (AI). The biggest difference between machine learning and deep learning is that in the learning of artificial intelligence models, machine learning basically requires a human feature extraction process before learning, but deep learning does not require this process and the original data is directly used as input. The development of deep learning coincides with the development of artificial neural networks (ANNs), and many people have contributed to the development of artificial neural networks for decades. The following five models are the representative architectures most widely used in deep learning. That is, Deep Feedforward Neural Network (DFFNN), Convolutional Neural Network (CNN), Deep Belief Network (DBN), Autoencoders (AE), and Long Short-Term Memory (LSTM) Network. A convolutional neural network (CNN) is a feedforward NN composed of a convolutional layer, a ReLU activation function, and a pooling layer. CNNs provide properties of weight sharing and local connectivity to process high-dimensional data. In dental and medical fields, an AI model that can be interpretable or explainable (XAI) is needed to increase patient persuasiveness. In the future, explainable AI (XAI) will become an indispensable and practical component in order to obtain an improved, transparent, secure, fair and unbiased AI learning model."
ResNet 기반 작물 생육단계 추정 모델 개발,2022,"['딥러닝', '컴퓨터 비전', 'Convolution Neural Network', '작물 생육단계', 'Deep Learing', 'Computer Vision', 'CNN', 'Crop Growth Stage']","산업화 이후 가속화된 지구 온난화 현상으로 인해 기존환경 변화 및 이상기후 발생 빈도가 증가하고 있다. 농업은 기후변화에 매우 민감한 분야의 산업으로 지구 온난화는 작물의 생산량을 감소시키고 재배 지역이 변하는 등의 문제를 발생시킨다. 또한, 환경 변화는 작물의 생육 시기를 불규칙하게 만들어 숙련된 농사꾼들도 작물의 생육단계를 쉽게 추정할 수 없도록 만들어 여러 문제를 발생시킨다. 이에 본 논문에서는 작물의 생육단계를 추정하기 위한 CNN(Convolution Neural Network) 모델을 제안한다. 제안한 모델은 ResNet의 Pooling Layer를 수정한 모델로 ResNet, DenseNet 모델의 생육단계 추정보다 높은 성능 결과를 확인하였다.","Due to the accelerated global warming phenomenon after industrialization, the frequency of changes in the existing environment and abnormal climate is increasing. Agriculture is an industry that is very sensitive to climate change, and global warming causes problems such as reducing crop yields and changing growing regions. In addition, environmental changes make the growth period of crops irregular, making it difficult for even experienced farmers to easily estimate the growth stage of crops, thereby causing various problems. Therefore, in this paper, we propose a CNN model for estimating the growth stage of crops. The proposed model was a model that modified the pooling layer of ResNet, and confirmed the accuracy of higher performance than the growth stage estimation of the ResNet and DenseNet models."
딥러닝 基盤의 諺簡 資料 文字 判讀機 具現에 對한 硏究 –<秋史 諺簡>을 對象으로–,2022,"['Korean letters', 'Chusa’s Korean letters', 'Deep-learning', 'CNN', 'GAN', 'Data augmentation', 'Character decipherer', 'Computer vision', '諺簡', '秋史 諺簡', '딥러닝', 'CNN', 'GAN', '데이터 증강', '문자 판독', '문자 판독기']","본 연구의 목적은 딥러닝(Deep-learning) 기술을 이용해 諺簡 資料에 대한 문자 判讀機를 구현해 보는 것에 있다. 구체적으로는 컴퓨터에게 ‘字體’의 특징을 학습시키는 방식을 이용하였다. 다만, 모든 자료에 대해 적용하기에는 시간과 인력의 제약이 있으므로, <秋史 諺簡> 일부만을 데이터베이스화하여 실현 가능성과 효용을 입증해 보았다.判讀機 구현을 위해 딥러닝에서 이미지 인식에 주로 사용되는 Convolutional Neural Network(CNN) 기술을 이용하였으며, 부족한 데이터를 충당하기 위해 몇 가지 데이터 생성과 증강 기법을 이용하였다. 만들어진 모델은 test 데이터에 대해 top1-88.72%, top5-97.63%의 인식률을 보였다. 이를 토대로 개별 문자 이미지를 입력하면 가장 높은 확률을 보이는 값을 출력해 주는 判讀機를 구현하였다.이렇게 만들어진 判讀機의 활용 방법을 예시하고 효용을 검증하기 위해 <秋史 諺簡> 11에 적용해 보았다. 이 과정에서 해당 문자가 무엇인지 적절하게 맞추는 모습을 볼 수 있었으며, 이외에 가능한 판독안의 목록도 제시해 주는 모습을 볼 수 있었다. 본 判讀機는 字體를 고려해 명시적인 확률값을 계산해 줄 수 있기 때문에 판독에 있어 객관적인 증거로 활용될 수 있을 것으로 보인다.",
자유 앵커 방식과 합성곱 신경망을 이용한 강인한 실시간 번호판 인식 시스템,2022,"['License Plate Recognition', 'Real-Time', 'Anchor-Free Method', 'CNN', 'Deep Learning', '번호판 인식', '실시간', '자유 앵커 방식', '딥러닝']","최근 지능형 교통 체계의 발전에 따라 자동차 번호판 인식 시스템이 다양한 분야에서 활용되고 있다. 주행 중인 자동차의 번호판을 인식하기 위해서는 실시간성이 보장되어야 하며, 영상이 왜곡되어 뚜렷하지 않거나 번호판의 크기가 작은 저해상도 영상에서도 높은 인식률이 유지되어야 한다. 본 논문에서는 자유 앵커 방식 기반의 객체 탐지 알고리즘과 합성곱 신경망(CNN) 기반의 문자 인식 알고리즘을 이용하여 처리 속도를 향상한 실시간 자동차 번호판 인식 시스템을 제안한다. 더불어 공간 변형 네트워크를 이용하여 저해상도 및 왜곡된 영상에서의 인식률을 높였다. 제안하는 시스템의 인식률은 93.769%, 이미지 당 처리 속도는 약 0.006초로 기존 자동차 번호판 인식 시스템보다 빠른 속도로 자동차 번호판을 인식하며, 다양한 환경 및 품질의 영상에 대해 높은 인식률을 유지하는 것을 확인할 수 있다.","With the recent development of intelligent transportation systems, car license plate recognition systems are being used in various fields. Such systems need to guarantee real-time performance to recognize the license plate of a driving car. Also, they should keep a high recognition rate even in problematic situations such as small license plates in low-resolution and unclear image due to distortion. In this paper, we propose a real-time car license plate recognition system that improved processing speed using object detection algorithm based on anchor-free method and text recognition algorithm based on Convolutional Neural Network(CNN). In addition, we used Spatial Transformer Network to increase the recognition rate on the low resolution or distorted images. We confirm that the proposed system is faster than previously existing car license plate recognition systems and maintains a high recognition rate in a variety of environment and quality images because the proposed system’s recognition rate is 93.769% and the processing speed per image is about 0.006 seconds."
혼재된 환경에서의 효율적 로봇 파지를 위한 3차원 물체 인식 알고리즘 개발,2022,"['3D Object Recognition', 'Cluttered Environment', 'YOLO', 'Mask R-CNN']",,"3D object detection pipelines often incorporate RGB-based object detection methods such as YOLO, which detects the object classes and bounding boxes from the RGB image. However, in complex environments where objects are heavily cluttered, bounding box approaches may show degraded performance due to the overlapping bounding boxes. Mask based methods such as Mask R-CNN can handle such situation better thanks to their detailed object masks, but they require much longer time for data preparation compared to bounding box-based approaches. In this paper, we present a 3D object recognition pipeline which uses either the YOLO or Mask R-CNN real-time object detection algorithm, K-nearest clustering algorithm, mask reduction algorithm and finally Principal Component Analysis (PCA) alg orithm to efficiently detect 3D poses of objects in a complex environment. Furthermore, we also present an improved YOLO based 3D object detection algorithm that uses a prioritized heightmap clustering algorithm to handle overlapping bounding boxes. The suggested algorithms have successfully been used at the Artificial-Intelligence Robot Challenge (ARC) 2021 competition with excellent results."
표정 분류에 기반한 감정 인식을 위한 열화상 데이터베이스의 유용성 평가,2022,"['thermal face image', 'facial expression classification', 'emotion recognition', 'CNN architecture', 'database performance']",,"Facial expression is an important part of human communication and is an element that helps to understand other people’s intentions. Recently, as a complementary solution in the field of emotion recognition, interest in thermal imaging is increasing as an alternative means to compensate for the shortcomings of visible light imaging. In this paper, thermal image data was acquired by itself and a database was established in which only facial areas necessary for emotional recognition were extracted separately. Verification accuracy and learning time were analyzed using the existing CNN architecture to confirm whether the built database can be used to classify facial expressions for emotion recognition. As a result of analysis through CNN network, ResNet-18 showed a verification accuracy of up to 81.28%, and on average, it showed a verification accuracy of 68.13%. Through this, it was confirmed that the self-built thermal imaging database is useful for emotional recognition research."
Accuracy of artificial intelligence-assisted landmark identification in serial lateral cephalograms of Class III patients who underwent orthodontic treatment and two-jaw orthognathic surgery,2022,"['Convolutional neural network', 'Landmark identification', 'Two-jaw orthognathic surgery', 'Serial lateral encephalogram']",,"Objective: To investigate the pattern of accuracy change in artificial intelligence-assisted landmark identification (LI) using a convolutional neural network (CNN) algorithm in serial lateral cephalograms (Lat-cephs) of Class III (C-III) patients who underwent twojaw orthognathic surgery. Methods: A total of 3,188 Lat-cephs of C-III patients were allocated into the training and validation sets (3,004 Lat-cephs of 751 patients) and test set (184 Lat-cephs of 46 patients; subdivided into the genioplasty and non-genioplasty groups, n = 23 per group) for LI. Each C-III patient in the test set had four Lat-cephs: initial (T0), pre-surgery (T1, presence of orthodontic brackets [OBs]), post-surgery (T2, presence of OBs and surgical plates and screws [S-PS]), and debonding (T3, presence of S-PS and fixed retainers [FR]). After mean errors of 20 landmarks between human gold standard and the CNN model were calculated, statistical analysis was performed. Results: The total mean error was 1.17 mm without significant difference among the four timepoints (T0, 1.20 mm; T1, 1.14 mm; T2, 1.18 mm; T3, 1.15 mm). In comparison of two time-points ([T0, T1] vs. [T2, T3]), ANS, A point, and B point showed an increase in error (p < 0.01, 0.05, 0.01, respectively), while Mx6D and Md6D showeda decrease in error (all p < 0.01). No difference in errors existed at B point, Pogonion, Menton, Md1C, and Md1R between the genioplasty and non-genioplasty groups. Conclusions: The CNN model can be used for LI in serial Lat-cephs despite the presence of OB, S-PS, FR, genioplasty, and bone remodeling."
통계 및 이미지 데이터를 활용한 가짜 SNS 계정 식별 기술,2022,"['기계 학습', '딥러닝', '합성곱 신경망', '소셜 네트워크 서비스', '가짜 계정', 'machine learning', 'deep learning', 'convolutional neural network(CNN)', 'social network service', 'fake accounts']","인터넷 기술이 발전함에 따라 SNS 사용자가 늘어나고 있다. SNS의 대중화가 진행되면서 소셜 네트워크의 영향력과 익명성을 활용한 SNS형 범죄가 나날이 증가하고 있는 추세이다. 본 논문에서는 인스타그램에서 SNS형 범죄에 주로 이용되는 가짜 계정 분류를 위해 통계 데이터와 이미지 데이터를 이용하여 각각 기계학습 및 딥러닝(deep learning) 기법을 활용한 가짜 계정 분류 방법을 제안한다. 모델 학습에 사용된 SNS 계정 데이터는 자체적으로 수집하였으며, 수집된 데이터는 통계 데이터 및 이미지 데이터에 기반한다. 통계 데이터의 경우에는 기계학습 및 다층 퍼셉트론 기반으로 학습을 진행하였고, 이미지 데이터의 경우에는 합성곱 신경망(Convolutional Neural Network, CNN) 기반으로 학습을 진행하였다. 학습을 진행한 결과 계정 분류에 대하여 정확도가 전반적으로 높게 나온 것을 확인하였다.","As Internet technology develops, SNS users are increasing. As SNS becomes popular, SNS-type crimes using the influence and anonymity of social networks are increasing day by day. In this paper, we propose a fake account classification method that applies machine learning and deep learning to statistical and image data for fake accounts classification. SNS account data used for training was collected by itself, and the collected data is based on statistical data and image data. In the case of statistical data, machine learning and multi-layer perceptron were employed to train. Furthermore in the case of image data, a convolutional neural network (CNN) was utilized. Accordingly, it was confirmed that the overall performance of account classification was significantly meaningful."
객체 탐지를 위한 객체 복사 기반의 적대적 생성 신경망 활용 이미지 데이터 증강 기법,2022,"['합성곱 신경망', '적대적 생성 신경망', '이미지 데이터 증강', '객체 탐지', 'convolution neural network (CNN)', 'generative adversarial network (GAN)', 'image data augmentation', 'object detection']","컴퓨터 비전 분야에서는 양질의 이미지 데이터가 합성곱 신경망(CNN) 모델의 성능에 중요한 영향을 미친다. 하지만 실제 도메인에서는 충분한 양질의 데이터를 구하는 것이 어렵기 때문에 이미지 데이터의 증강 기법에 대한 연구가 계속해서 이루어지고 있다. 본 논문에서는 기존에 연구되던 적대적 생성 신경망(GAN)과 객체 복사(Copy-Paste) 기반의 증강 기법을 결합하여 더 다양한 이미지 데이터를 생성할 수 있는 이미지 데이터 증강 기법을 제안한다. 경계 상자(bounding box)가 아닌 객체 경계를 잘라내고, 적대적 생성 신경망을 사용하여 객체를 변형함으로써 기존의 픽셀 단위, 이미지 단위에서 벗어난 객체 단위의 이미지 데이터 증강을 보인다.","In the field of computer vision, massive well-annotated image data are essential to achieve good performance of a convolutional neural network (CNN) model. However, in real world applications, gathering massive well-annotated data is a difficult and time-consuming job. Thus, image data augmentation has been continually studied. In this paper, we proposed an image data augmentation method that could generate more diverse image data by combining generative adversarial network (GAN) and copy-paste based augmentation. The proposed method generated not pixel-level or image-level augmentation, but object-level augmentation by cutting off segmentation boundaries(mask) instead of bounding boxes. It then applyied GAN to transform objects."
Accuracy of one-step automated orthodontic diagnosis model using a convolutional neural network and lateral cephalogram images with different qualities obtained from nationwide multi-hospitals,2022,"['One-step automated orthodontic diagnosis', 'Convolutional neural networks', 'Lateral cephalogram', 'Multi-center study']",,"Objective: The purpose of this study was to investigate the accuracy of one-step automated orthodontic diagnosis of skeletodental discrepancies using a convolutional neural network (CNN) and lateral cephalogram images with different qualities from nationwide multi-hospitals. Methods: Among 2,174 lateral cephalograms, 1,993 cephalograms from two hospitals were used for training and internal test sets and 181 cephalograms from eight other hospitals were used for an external test set. They were divided into three classification groups according to anteroposterior skeletal discrepancies (Class I, II, and III), vertical skeletal discrepancies (normodivergent, hypodivergent, and hyperdivergent patterns), and vertical dental discrepancies (normal overbite, deep bite, and open bite) as a gold standard. Pre-trained DenseNet-169 was used as a CNN classifier model. Diagnostic performance was evaluated by receiver operating characteristic (ROC) analysis, t-stochastic neighbor embedding (t-SNE), and gradientweighted class activation mapping (Grad-CAM). Results: In the ROC analysis, the mean area under the curve and the mean accuracy of all classifications were high with both internal and external test sets (all, > 0.89 and > 0.80). In the t-SNE analysis, our model succeeded in creating good separation between three classification groups. Grad-CAM figures showed differences in the location and size of the focus areas between three classification groups in each diagnosis. Conclusions: Since the accuracy of our model was validated with both internal and external test sets, it shows the possible usefulness of a one-step automated orthodontic diagnosis tool using a CNN model. However, it still needs technical improvement in terms of classifying vertical dental discrepancies."
전동기 기계시설물 고장 분류를 위한이미지 인코딩 기반 경량화된 딥러닝 모델,2022,"['Timeseries classification', 'Image encoding', 'Deep learning', 'Lightweight model']","산업 현장에서 사용되는 전동기 기계 설비들의 고장은 베어링, 회전체, 벨트, 축이 상당 부분을 차지한다. 설비들이 기계적 또는 전기적 원인에 의해 고장이 발생하거나 성능이 저하되면 공통 적으로 진동이 발생하고 전류 등이 이상 움직임을 보인다. 이러한 상황에서 불특정하게 발생하는 고장을 쉽게 감지하고 예측하는 것은 필수적이다. 따라서 본 논문에서는 전동기 기계 설비에 부착된 센서에서 생성되는 시계열 데이터를 이미지로 인코딩하는 방법을 사용하여 경량화된 딥러닝 모델을 제안하였다. 이미지 인코딩에는 세 개의 방식을 사용하였고, 각각의 방식에 대한 CNN 기반 딥러닝 분류모델을 생성하였다. CNN 모델은 작은 파라미터를 가지면서도 제일 정확도가 높은 모델을 실험을 통해 만들었다. CNN 모델의 정확도를 분석하고 어떠한 인코딩 방식이 학습에 효율적이고 더 적합한지 실험해보았더니 세 개의 이미지 인코딩 방식 중에서도 GASF 방식이 대체로 정확도가 높게 나온 것을 확인하였다. 본 논문에서 제안한 이미지 인코딩 기반의 경량화된 딥러닝 모델을 이용해 산업에서 활용되는 여러 센서 데이터에 대해 다양한 응용에 활용할 수 있을 것이라 예상된다.",
기계학습을 이용한 3D CAD 모델 형상과 경계조건의 유형 식별,2022,"['3D CAD Model', 'Boundary Condition', 'Data Classification', 'Extended Voxel Model', 'Machine Learning', 'Multi-Layer Perceptron', 'Convolutional Neural Network']",,"In this paper, we propose a machine learning approach for classifying 3D CAD models with boundary conditions. We adopted an extended voxel model to represent a CAD model with its boundary conditions, and to construct the training data. By considering 7 types of part families and 3 types of boundary conditions, we generated 320 similar CAD models for each part family and assigned 3 different boundary conditions to each CAD model, which produces 960 datasets for the part family. We used multi-layer perceptron (MLP) and convolutional neural network (CNN) as machine learning models, which classify the combination type of a given CAD model with its boundary conditions. Using TensorFlow, we trained and tested the models, and compared their performance. We considered the MLP models made of three hidden layers and the CNN models made of two convolutional, two pooling, and three hidden layers. We also conducted a grid search to find the proper number of nodes in hidden layers. From experimental results, we found that the CNN models are better in accuracy than the MLP models. If further enhanced, the proposed approach is expected to become a useful tool for similar case search from archive CAE models."
딥러닝 기반 장면인식 기법을 이용한 제조 작업공간 분류모델,2022,"['Scene Recognition', 'Deep Learning', 'Convolutional Neural Network', 'Places365', 'Manufacturing Workspace']","최근 머신러닝 기술의 발달로 산업현장에서 딥러닝(Deep Learning)을 통한 장면인식(Scene Recognition) 방법이다양하게 연구되고 있다. 딥러닝을 이용한 장면인식의 성능은 알고리즘 구조와 학습방법에 따라 크게 영향을 받는다. 본 연구를 위한 사전 연구 결과, Places365 데이터셋으로 학습된 데이터 모델에 의한 제조 작업공간 분류 정확도는 54%로, 이 성능으로는 실제 환경에서 사용하기는 어렵다. 따라서 본 논문에서는 이러한 문제점을 해결하고자CNN(Convolutional Neural Network) 기반에서 3가지의 전략으로 학습 데이터셋을 재구성하여 학습을 실시한 후장면인식 기법을 이용하여 제조 작업공간 분류모델을 제시하였다. 제안한 알고리즘과 데이터셋 구성방법을 통해 학습할 경우, 제조 작업공간에 대한 장면인식 성능은 기존 방법에 비해 28%p 향상됨을 확인하였다.","With the recent development of machine learning technology, various methods of scene recognition through deep learning are being studied in industrial fields. The performance of scene recognition using deep learning is greatly affected by the algorithm structure and learning method. As a result of the preliminary study for this study, it was confirmed that the manufacturing workspace classification accuracy by the data model trained with the Places365 dataset was 54%, which was difficult to use in the real environment. Therefore, in this paper, in order to solve this problem, a classification model of the manufacturing workspace is presented using a scene recognition technique after learning by reconstructing a learning dataset with three strategies based on CNN (Convolutional Neural Network). When learning through the proposed algorithm and data set configuration method, it was confirmed that the scene recognition performance for the manufacturing workspace was improved by 28%p compared to the existing method."
Deep Neural Network와 Convolutional Neural Network 모델을 이용한 산사태 취약성 매핑,2022,"['Landslides', 'Susceptibility map', 'Deep learning', 'Deep neural network', 'Convolutional neural network']",,"Landslides are one of the most prevalent natural disasters, threating both humans and property. Also landslides can cause damage at the national level, so effective prediction and prevention are essential. Research to produce a landslide susceptibility map with high accuracy is steadily being conducted, and various models have been applied to landslide susceptibility analysis. Pixel-based machine learning models such as frequency ratio models, logistic regression models, ensembles models, and Artificial Neural Networks have been mainly applied. Recent studies have shown that the kernel-based convolutional neural network (CNN) technique is effective and that the spatial characteristics of input data have a significant effect on the accuracy of landslide susceptibility mapping. For this reason, the purpose of this study is to analyze landslide vulnerability using a pixel-based deep neural network model and a patch-based convolutional neural network model. The research area was set up in Gangwon-do, including Inje, Gangneung, and Pyeongchang, where landslides occurred frequently and damaged. Landslide-related factors include slope, curvature, stream power index (SPI), topographic wetness index (TWI), topographic position index (TPI), timber diameter, timber age, lithology, land use, soil depth, soil parent material, lineament density, fault density, normalized difference vegetation index (NDVI) and normalized difference water index (NDWI) were used. Landslide-related factors were built into a spatial database through data preprocessing, and landslide susceptibility map was predicted using deep neural network (DNN) and CNN models. The model and landslide susceptibility map were verified through average precision (AP) and root mean square errors (RMSE), and as a result of the verification, the patch-based CNN model showed 3.4% improved performance compared to the pixel-based DNN model. The results of this study can be used to predict landslides and are expected to serve as a scientific basis for establishing land use policies and landslide management policies."
Deep Learning Analysis to Automatically Detect the Presence of Penetration or Aspiration in Videofluoroscopic Swallowing Study,2022,"['Deep Learning', 'VFSS', 'Deglutition', 'Swallowing Reflex']",,"Background: Videofluoroscopic swallowing study (VFSS) is currently considered the gold standard to precisely diagnose and quantitatively investigate dysphagia. However, VFSS interpretation is complex and requires consideration of several factors. Therefore, considering the expected impact on dysphagia management, this study aimed to apply deep learning to detect the presence of penetration or aspiration in VFSS of patients with dysphagia automatically.Methods: The VFSS data of 190 participants with dysphagia were collected. A total of 10 frame images from one swallowing process were selected (five high-peak images and five low-peak images) for the application of deep learning in a VFSS video of a patient with dysphagia. We applied a convolutional neural network (CNN) for deep learning using the Python programming language. For the classification of VFSS findings (normal swallowing, penetration, and aspiration), the classification was determined in both high-peak and lowpeak images. Thereafter, the two classifications determined through high-peak and low-peak images were integrated into a final classification.Results: The area under the curve (AUC) for the validation dataset of the VFSS image for the CNN model was 0.942 for normal findings, 0.878 for penetration, and 1.000 for aspiration.The macro average AUC was 0.940 and micro average AUC was 0.961.Conclusion: This study demonstrated that deep learning algorithms, particularly the CNN, could be applied for detecting the presence of penetration and aspiration in VFSS of patients with dysphagia."
A video-based SlowFastMTB model for detection of small amounts of smoke from incipient forest fires,2022,"['forest fire', 'smoke detection', 'deep learning', 'early detection', 'annotation']",,"This paper proposes a video-based SlowFast model that combines the SlowFast deep learning model with a new boundary box annotation algorithm. The new algorithm, namely the MTB (i.e., the ratio of the number of Moving object pixels To the number of Bounding box pixels) algorithm, is devised to automatically annotate the bounding box that includes the smoke with fuzzy boundaries. The model parameters of the MTB algorithm are examined by multifactor analysis of variance. To demonstrate the validity of the proposed approach, a case study is provided that examines real video clips of incipient forest fires with small amounts of smoke. The performance of the proposed approach is compared with those of existing deep learning models, including convolutional neural network (CNN), faster region-based CNN (faster R-CNN), and SlowFast. It is demonstrated that the proposed approach achieves enhanced detection accuracy, while reducing false negative rates."
증강현실  모델  위치  정합  활용을  위한  기계학습  기반의  선박  블록 윤곽선  검출  연구,2022,"['CNN', 'GAN', 'Outline Detection', 'Segmentation']",,"As interest in autonomous ships is growing, research on augmented reality-based remote sup- port systems that can be used onboard ships is being conducted. The markerless method is more suitable than the marker method because corrosion and damage can easily occur in the ship. However, in the case of the markerless method, a process of selecting a desired feature point is required, but it is not easy in a complicated ship. Therefore, in this study, the outline detection system was studied to utilize the outline as a feature point for augmenting the augmented real- ity model. Although many existing studies have preceded it, it is not suitable for detecting the contour  of  a  ship  block  with  many  internal  and  external  components.  Therefore,  in  order  to overcome the limitations of the previous method, in this study, to detect only the outline of a ship  block,  a  model  was  built  through  CNN,  GAN,  and  Segmentation  algorithm,  which  are deep learning techniques widely used in image processing, and block outline detection was per- formed.  It  is  also  expected  that  these  results  will  help  automate  and  optimize  the  stockyard management system."
Fundus Photograph Discrimination Using Transfer Learning over Limited Computing Power Environment,2022,"['AI', 'CNN', 'Fundus photograph', 'ImageNet', 'OPhthalmoloscopy', 'Transfer learning']",,"In this paper, we demonstrates a reliable and efficient approach to detect eye-related disease with automated fundus screening using convolutional neural network (CNN) and transfer learning that counteracts to insufficient annotated data set and image domain shifts. The weight values learned from the data sets can be used as initial parameters for the other desired neural networks, and additional learning can be conducted on top of the pre-learned model, called transfer learning. It is a particularly useful method when the number of data sets is and small over limited computing power environment. Four different fundus image data sets, image domains such as ethnicity of the target and equipment which the fundus photograph was captured with, were used for the validation. The data sets were annotated by ophthalmologists as healthy, abnormal, or diabetic retinopathy. The ResNet-18 model, pre-trained with ImageNet data set of 1.2 million images of 1000 daily routine objects, were used for transfer learning. The pre-trained model were modified and additionally trained to learn features from the fundus images, and were validated with separate test sets. Given limited quantity of fundus photograph data set and various image domains, the deep learning models can yield robust ophthalmological performance in discriminating pathologies in the eyes. In spite of the simplicity, this study illustrates the capability of transfer learning and suggests pragmatic and practical approach to varied medical settings with fluctuating status of data maintenance and different image domains."
필터 다양화를 통한 합성곱 신경망의 표현력 향상,2022,"['Deep learning', 'CNN', 'Feature Representation', 'Filter Diversity', 'Singular Value Decomposition (SVD) Entropy', 'Filter Spreading']",,"This paper aims to improve the feature representation by diversifying CNN filters inspired by niche concept in evolution. The singular value decomposition (SVD) entropy based efficient metric for diversity is proposed In the proposed approach, filters are clustered by groups and they are calculated as differences from the center values within the groups, rather than by entire rank based comparison. This provides an effective method for increasing the substantial diversity of filters. Furthermore, the filters with low diversity are adjusted by the diversity spreading framework for better diversity in the reconstruction process. The improvement of the filter representation by performing experiments on CIFAR 10/100 data for VGG16, and ImageNet for ResNet34 is provided. Because there are no similar studies, we compare our results with respect to those of relatively relevant pruning methods in terms of classification performance accuracy as well as the pruned rates and flops."
딥러닝 기반 활주로 균열 식별,2022,"['deep learning', 'CNN', 'Mask R-CNN', 'runway', 'crack', 'drone']",,"The purpose of this study is to provide a method for identifying runway cracks using deep learning for the efficient operation of air power in wartime and peacetime. The current identification method, which mainly depends on human eyes, requires a lot of time, money and manpower. In order to prevent the consumption of such resources, a drone was utilized to take runway images and cracks were identified from the images via deep learning. Data sets were generated through labeling of the images, and the deep learning model was applied to them to evaluate the learning accuracy. As a result of the verification of the trained model, runway cracks were identified, and also the location and size of the cracks were predicted and compared with the actual cracks. Through this research, it is expected to reduce the consumption of resources and increase the efficiency of air power operation by improving the accuracy and reliability of the identification of runway cracks in wartime and peacetime."
다채널 근전도 기반 딥러닝 동작 인식을 활용한 손 재활 훈련시스템 개발 및 사용성 평가,2022,"['Convolutional Neural Network (CNN)', 'EMG', 'Hand rehabilitation', 'Hand posture recognition', 'Usability evaluation']",,"The purpose of this study was to develop a hand rehabilitation training system for hemiplegic patients. We also tried to find out five hand postures (WF: Wrist Flexion, WE: Wrist Extension, BG: Ball Grip, HG: Hook Grip, RE: Rest) in real-time using multi-channel EMG-based deep learning. We performed a pre-processing method that converts to Spider Chart image data for the classification of hand movement from five test subjects (total 1,500 data sets) using Convolution Neural Networks (CNN) deep learning with an 8-channel armband. As a result of this study, the recognition accuracy was 92% for WF, 94% for WE, 76% for BG, 82% for HG, and 88% for RE. Also, ten physical therapists participated for the usability evaluation. The questionnaire consisted of 7 items of acceptance, interest, and satisfaction, and the mean and standard deviation were calculated by dividing each into a 5-point scale. As a result, high scores were obtained in immersion and interest in game (4.6±0.43), convenience of the device (4.9±0.30), and satisfaction after treatment (4.1±0.48). On the other hand, Conformity of intention for treatment (3.90±0.49) was relatively low. This is thought to be because the game play may be difficult depending on the degree of spasticity of the hemiplegic patient, and compensation may occur in patient with weakened target muscles. Therefore, it is necessary to develop a rehabilitation program suitable for the degree of disability of the patient."
Tutorial and applications of convolutional neural network models in image classification,2022,"['AdamW', 'convolution neural network', 'deep learning', 'ILSVRC']",,"Image classification is a supervised learning problem in the machine learning area. We apply deep learning models to classify image data. In particular, we discuss the advantages of the various types of convolutional neural networks competed in the ImageNet large-scale visual recognition challenge (ILSVRC). First, we provide a review of the CNN models to be applied and explain the details of models to be employed. In general, we keep the core structure of the models in the same form proposed in ILSVRC. We investigate the models via four popular image data sets of various sizes. To compare the performance of the models, we adopt top-1 accuracy, top-5 accuracy, and f1-score as the measures of accuracy. We employ AdamW for an optimizer that is a fast algorithm and often yields precise learning. As a result, we show that the Inception-ResNet-v2 model has excellent performance, and the ResNet is robust to imbalanced data."
합성곱신경망을 활용한 과구동기 시스템을 가지는 소형 무인선의 추진기 고장 감지,2022,"['Unmanned surface vehicle(무인 수상 선박)', 'Fault detection(고장 감지)', 'Convolutional neural network(합성곱신경망)', 'ROS', 'Overacturated(과구동기)', 'Wavelet transform(웨이블렛 변환)']",,"This paper proposes a fault detection method for a Unmanned Surface Vehicle (USV) with overactuated system. Current status information for fault detection is expressed as a scalogram image. The scalogram image is obtained by wavelet-transforming the USV""s control input and sensor information. The fault detection scheme is based on Convolutional Neural Network (CNN) algorithm. The previously generated scalogram data was transferred learning to GoogLeNet algorithm. The data are generated as scalogram images in real time, and fault is detected through a learning model. The result of fault detection is very robust and highly accurate."
비정상 신호를 가진 연료 펌프의 상태 진단에서 Conv1D 모델의 시간 간격 별 예측 정확성 비교,2022,"['Anomaly detection', 'Centrifugal pump', 'CNN (Convolution Neural Network)', 'Conv1D', 'MLP(Multi-layer Perceptron)', 'Non-stationary signal', 'PCA (Principal component analysis)', 'Time Series', 'Variable speed']",,"This study deals with the condition detection of centrifugal pump supplying liquid to marine engines. The purpose is to detect the anomaly and the failure modes of the pump by applying the vibration signals from the simulated failures on the experimental bed. Since the pump rarely experiences faults as well as used to degradation experiments, the vibration signal was gathered from an experimental bed simulating the bearings and lubricant failures. Considering the non-stationarity of variable speed, the convolution is applied to extract the feature of time series rather than the frequency feature. The advantage of CNN implicitly extracting features from a non-stationary signal is used to extract the features applied to Conv1D. After learning the features, a multi-layer perceptron (MLP) was connected to failure classification to identify the operation state. Finally, it is suggested that the time series-based feature extraction can be applied to the condition monitoring of a centrifugal pump with variable speed and non-stationarity."
딥러닝 기반 이미지 필터 간 한국인 표정 분류 성능 비교,2022,"['얼굴 표정 분류', 'CNN', 'VGG', 'ResNet', '가장자리 검출 필터', 'Facial Expression Classification', 'CNN', 'VGG', 'ResNet', 'Edge Detection Filter']",,
User-to-User Matching Services through Prediction of Mutual Satisfaction Based on Deep Neural Network,2022,"['Convolutional Neural Network (CNN)', 'Deep Learning', 'Deep Neural Network (DNN)', 'Matching Service', 'Recommender Service']",,"With the development of the sharing economy, existing recommender services are changing from user–itemrecommendations to user–user recommendations. The most important consideration is that all users shouldhave the best possible satisfaction. To achieve this outcome, the matching service adds information betweenusers and items necessary for the existing recommender service and information between users, so higher-leveldata mining is required. To this end, this paper proposes a user-to-user matching service (UTU-MS) employingthe prediction of mutual satisfaction based on learning. Users were divided into consumers and suppliers, andthe properties considered for recommendations were set by filtering and weighting. Based on this process, weimplemented a convolutional neural network (CNN)–deep neural network (DNN)-based model that can predicteach supplier’s satisfaction from the consumer perspective and each consumer’s satisfaction from the supplierperspective. After deriving the final mutual satisfaction using the predicted satisfaction, a top recommendationlist is recommended to all users. The proposed model was applied to match guests with hosts using Airbnb data,which is a representative sharing economy platform. The proposed model is meaningful in that it has beenoptimized for the sharing economy and recommendations that reflect user-specific priorities."
A review and comparison of convolution neural network models under a unified framework,2022,"['classification', 'convolutional neural network (CNN)', 'ImageNet large-scale visual recognition challenge (ILSVRC)', 'image data']",,"There has been active research in image classification using deep learning convolutional neural network (CNN) models. ImageNet large-scale visual recognition challenge (ILSVRC) (2010-2017) was one of the most important competitions that boosted the development of efficient deep learning algorithms. This paper introduces and compares six monumental models that achieved high prediction accuracy in ILSVRC. First, we provide a review of the models to illustrate their unique structure and characteristics of the models. We then compare those models under a unified framework. For this reason, additional devices that are not crucial to the structure are excluded. Four popular data sets with different characteristics are then considered to measure the prediction accuracy. By investigating the characteristics of the data sets and the models being compared, we provide some insight into the architectural features of the models."
Handcrafted Cost 기반의 다중뷰 스테레오 정합 네트워크,2022,"['Multi-view stereo', 'CNN', 'Encoder-decoder network', 'Parallel processing', 'OpenCL']","다중 뷰 스테레오 정합 기법은 임의의 화각에서 취득한 여러 장의 입력 영상으로부터 카메라 위치 정보를 활용하여 정교한 깊이 정보를 얻는 방법을 뜻한다. 기존 다중 뷰 스테레오 정합 기법은 인접 영상 간 가려진영역이 적을 때만 잘 작동하며 영상 내 잡음에 취약한 모습을 보였다. 본 논문에서는 소수의 입력 영상으로부터 CNN 기반의 encoder-decoder 구조의 네트워크로 정교한 깊이 영상을 복원하는 기법을 제안한다. 제안하는 기법은 비용 볼륨 구축 알고리즘과 대상 영상에 대한 올바른 참조 영상 선정 기법 그리고 비용 볼륨 regression 네트워크를 통한 변이도 추정 기법으로 구성되어있다. 본 논문에서는 제안하는 기법들을 통해 저 사양 임베디드 보드에서 OpenCL 기반의 병렬 알고리즘으로 다중 뷰 스테레오 정합의 구현 가능성을 보이고, 다중 영상 데이터 셋으로 학습한 네트워크를 통해 소수의 영상으로부터 정교한 깊이 정보를 복원한다.",
인공지능 모델로 식별 가능한 비식별 이미지 생성 방법,2022,"['비식별', '얼굴식별', '적대적공격', 'CCTV', 'DNN', 'CNN', 'De-identification', 'face identification', 'Adversary attack', 'CCTV', 'DNN', 'CNN']","최근 어디에서나 흔하게 볼 수 있는 CCTV는 사생활 침해의 논란이 있다. 심층신경망은 기반 이미지 인식, 패턴 분석과 같은 여러 유용한 서비스에 적용되었다. 한편, 적대적 예제는 심층신경망 보안에 큰 위협이 된다. 예로, 이미지에 약간의 노이즈를 추가하여 만들어진 얼굴 적대적 예제는 얼굴 인식 시스템에서 오인식이 발생 할 수 있다. 하지만 비식별화한 이미지를 재식별이 필요한 일부 상황에서는 적대적 예제가 유용할 수 있다. 이 논문에서는 우리는 재식별 가능한 얼굴 비식별화 방법을 제안한다. 제안하는 기법은 사람의 시각으로 식별할 수 없는 얼굴 식별 모델은 식별을 가능하게 한다. 비식별화 방법은 가우시안 블러와 적대적공격 기법인 C.W 공격을 사용하였다. 그리고 동영상을 이용한 실험으로 이 기법이 작동한다는 것을 보여주었다.",
A New Bank-card Number Identification Algorithm Based on Convolutional Deep Learning Neural Network,2022,"['Bank-card number', 'Identification Algorithm', 'CNN', 'Edge detection', 'Candidate region generation', 'Recognition']",,"Recently bank card number recognition plays an important role in improving payment efficiency. In this paper we propose a new bank-card number identification algorithm. The proposed algorithm consists of three modules which include edge detection, candidate region generation, and recognition. The module of ‘edge detection’ is used to obtain the possible digital region. The module of ‘candidate region generation’ has the role to expand the length of the digital region to obtain the candidate card number regions, i.e. to obtain the final bank card number location. And the module of ‘recognition’ has Convolutional deep learning Neural Network (CNN) to identify the final bank card numbers. Experimental results show that the identification rate of the proposed algorithm is 95% for the card numbers, which shows 20% better than that of conventional algorithm or method."
스펙트로그램을 이용한 기계의 이상상태 탐지 모델,2022,"['Spectrogram', 'Machines', 'Abnormal', 'LSTM', 'Predictive Maintenance', 'CNN']",,"There are many methods for diagnosing abnormal conditions of machines. Among them we use a method using sound for detecting abnormalities of machines. Experimental data sets were collected at approximately 30 minutes intervals for 2 weeks. The collected data sets are converted into spectrogram images expressed by time, frequency and amplitude with a 5 second time step. In this paper, we propose a learning model created by combining Conv1D for image processing and LSTM for time series data processing to detect abnormal conditions of machines. The comparison test with the existing model combining CNN, Conv1D and GRU shows our method has a promising result."
GPR Image Recovery Effect on Faster R-CNNBased Buried Target Detection,2022,"['Buried Target Detection', 'Deep Learning', 'Faster R-CNN', 'Low Rank Data Recovery', 'Matrix Completion.']",,"Measurements acquired through ground-penetrating radar (GPR) may contain missing information that needs to be recovered before the implementation of any post-processing method, such as target detection, since buried target detection methods fail and cannot produce desired results if the input GPR image contains missing information. This study proves that the recovery of missing information in a GPR image has a direct influence on the performance of subsequent target detection methods. Thus, state-of-the-art matrix completion methods are applied to the GPR image with missing information in both pixel- and column-wise cases with different missing rates, such as 30% and 50%. After the GPR image is successfully recovered, the faster region-based convolutional neural network (Faster R-CNN) target detection method is applied. The performance correlation between matrix completion accuracy and the target detection method’s confidence score is analyzed using both quantitative and visual results. The obtained results demonstrate the importance of GPR image recovery prior to any post-processing implementation, such as target detection."
YOLOv4 알고리즘을 이용한 저품질 자동차 번호판 영상의 숫자 및 문자영역 검출,2022,"['Deep Learning', 'YOLOv4', 'Convolution Neural Network(CNN)', 'Vehicle License Plate', 'Image Recognition']",,"Recently, research on license plate recognition, which is a core technology of an intelligent transportation system(ITS), is being actively conducted. In this paper, we propose a method to extract numbers and characters from low-quality license plate images by applying the YOLOv4 algorithm. YOLOv4 is a one-stage object detection method using convolution neural network including BACKBONE, NECK, and HEAD parts. It is a method of detecting objects in real time rather than the previous two-stage object detection method such as the faster R-CNN. In this paper, we studied a method to directly extract number and character regions from low-quality license plate images  without additional edge detection and image segmentation processes. In order to evaluate the performance of the proposed method we experimented with 500 license plate images. In this experiment, 350 images were used for training and the remaining 150 images were used for the testing process. Computer simulations show that the mean average precision of detecting number and character regions on vehicle license plates was about 93.8%."
임베디드 시스템에서의 객체 탐지 네트워크추론 가속을 위한 필터 가지치기 기법 연구,2022,"['Deep learning', 'Embedded system', 'Object detection', 'Filter pruning', 'FLOPs']","최근에 컴퓨터 비전 분야에서 우수한 성능을 나타내는 CNN(Convolution neural network)이 각광을 받고 있다. 이는 데이터의 증가와 GPU와 같은 하드웨어 성능의 향상으로 가능하게 되었지만 높은 성능을 위해 네트워크가 깊고 넓어지면서 파라미터와 연산량이 기하급수적으로 증가하였다. 따라서 메모리, 연산 성능, 전력 사용이 제한적인 임베디드 환경에서 큰 네트워크의 활용은 더욱 어려워졌다. 이러한 문제를 해결하기 위해 CNN 모델의 정확도는 유지한 채 중요하지 않은 파라미터들을 제거하는 가지치기 기법이 활발히 연구되고 있다. 하지만 대부분의 가지치기 기법을 다룬 기존 연구는 파라미터 제거와 줄어든 파라미터에 의해 감소된 플롭스(FLOPs)에 대한 결과를 보여주였다. 본 논문에서는 파라미터 수와 함께 플롭스까지 원하는 비율만큼 줄임으로써 가속화된 추론 속도를 갖는 네트워크를 생성할 수 있는 필터 가지치기 기법을 제안한다. 제안하는 필터 가지치기 기법에 대한 성능을 평가하기 위해 VisDrone 데이터 세트와 YOLOv5를 이용하였으며, 가지치기 후 경량화된 네트워크의 추론 속도를 NVIDIA Jetson Xavier NX 플랫폼을 이용하여 측정하였다. 파라미터와 플롭스를 각각 30%, 40%, 50%씩 가지치기한 결과 mAP(0.5:0.95)는 기준 객체 탐지 네트워크 대비 0.6%, 0.9%, 1.2% 감소하는 반면에, 추론 시간은 각각 16.60%, 25.79%, 30.72%가 향상된 결과를 확인하였다.",
이미지 내 객체 분류를 위한 노드 가지치기 기반 압축된 심층 합성곱 신경망 모델,2022,"['딥러닝', '이미지 전처리', '객체 분류', '노드 가지치기', 'CNN', 'Deep learning', 'Convolutional Neural Network', 'Image Preprocessing', 'Object Classification', 'Node Pruning']",,"Modern DCNN(Deep Convolutional Neural Network)-based image classification system can train huge amounts of data with high accuracy. However, to use a DCNN, we need a long time and enormous compute capacity to train huge amounts of data for using DCNN. Therefore, this paper proposed a compact DCNN model that can be used in various environments. To classify objects within an image, a dataset was collected by photographing hand gesture images through a webcam. Then new deep learning model based on CNN was designed and trained hand gesture image data and classified with 98% accuracy. We then used node pruning to lighten DCNN models, showing training times that were reduced by about three times compared to original model and hyper-parameter number that was reduced by 63% of the pre-pruned model."
미디어 인공지능  : 컴퓨터 비전 관련 딥러닝 모델의 미디어 동영상 분야 적용 가능성에 관한 연구,2022,"['deep learning', 'computer vision', 'convolutional neural networks(CNN)', 'recurrent neural networks (RNNs)', 'generative adversarial network (GANs)', 'media AI(media artificial intelligence)', 'video analytics', '딥러닝', '컴퓨터 비전', '합성곱 신경망', '순환 신경망', '적대적 신경망', '미디어 인공지능', '동영상 내용분석']","미디어 동영상 분야는 컴퓨터 비전 관련 딥러닝 모델을 활용해 연구 차원에서는 동영상의 자동화된 내용분석을 수행하고 실무 차원에서는 미디어 분야의 디지털 전환을 통해 서비스를 개선할 여지가 큰 영역이다. 이 논문에서는 미디어 동영상의 분석과 생성에 활용도가 높은 비전 관련 딥러닝 기반 모델을 검토했다. 우선 다양한 모델의 기축이 되는 알고리즘으로서 분류 모델로 널리 사용되는 합성곱 신경망(CNN)과 순환 신경망(RNN), 생성 모델로 사용되는 적대적 생성 신경망(GAN)과 오토인코더(AE), 사전 훈련 모델을 활용하는 전이학습을 살펴보았다. 다음으로 미디어 동영상 영역에서 활용도가 높은 과업을 객체탐지, 행동인식, 사건탐지, 동영상 요약, 동영상 분류 등 5개 대분류와 객체탐지, 안면인식, 표정인식, 랜드마크 인식, 상품인식, 행동인식, 자세추정, 이상탐지, 상황인식, 동영상 요약, 동영상 분류 등 11개 소분류로 제시했다. 이어 각 과업별 SOTA(state-of-the-art)와 벤치마크 데이터셋을 소개했다. 끝으로 이러한 모델의 학문적, 실무적 활용 가능성을 제시해보았다. 본 논문은 수식이나 프로그래밍에 대한 지식이 없이 미디어 연구자나 미디어 서비스 기획자가 비전 분야 딥러닝의 큰 흐름을 파악하고 관련 모델을 직접 활용하거나 컴퓨터공학 분야의 연구자 또는 개발자와 협업할 때 배경지식을 제공할 것으로 기대한다. 또한 비전 관련 딥러닝이 발전함에 따라 미디어 인공지능 기반 동영상 빅데이터 분석 시스템의 개발 가능성도 높아질 것이다.","Recently, media researchers employ deep learning models related to computer vision to perform automated content analysis of videos. Understanding deep learning models is also essential to AI(artificial intelligence) driven digital transformation in the media industry. In this paper, we reviewed computer vision-related deep learning models that are widely used for video analytics and generation. First, we looked at convolutional neural networks (CNNs) and recurrent neural networks (RNNs), which are widely used for classification, as well as generative adversarial network (GANs) and autoencoders (AEs) as generation models, and transfer learning using pre-training models. Following that, we proposed tasks in five major categories for which AI could be highly useful: object detection, action recognition, event detection, video summarization, and video classification. Then, for subtasks such as object detection, face recognition, facial expression recognition, landmark recognition, product recognition, pose estimation, anomaly detection, context recognition, video summarization, and video classification, we introduced state-of-the-arts (SOTAs) and benchmark datasets. Finally, the potential academic and practical applications of these models were discussed. We anticipate that media researchers or media service providers will understand the major trend of deep learning in computer vision and will be able to get knowledge when using deep learning models independently or collaborating with programmers."
Convolutional neural network 기법을 이용한 턱수염물범 신호 판별,2022,,,"Several studies using Convolutional Neural Network (CNN) have been conducted to detect and classify the sounds of marine mammals in underwater acoustic data collected through passive acoustic monitoring. In this study, the possibility of automatic classification of bearded seal sounds was confirmed using a CNN model based on the underwater acoustic spectrogram images collected from August 2017 to August 2018 in East Siberian Sea. When only the clear seal sound was used as training dataset, overfitting due to memorization was occurred. By evaluating the entire training data by replacing some training data with data containing noise, it was confirmed that overfitting was prevented as the model was generalized more than before with accuracy (0.9743), precision (0.9783), recall (0.9520). As a result, the performance of the classification model for bearded seals signal has improved when the noise was included in the training data."
딥 러닝 기반의 이기종 무선 신호 구분을 위한 데이터 수집 효율화 기법,2022,"['Wireless identification', 'RSSI sampling', 'Unlicensed spectrum', 'CNN', 'Feature selection']","최근 데이터 기반의 딥러닝 기술을 적용하여 비면허 대역의 다양한 통신 신호를 분류하는 연구가 활발히 수행되고 있다. 하지만,복잡한 신경망 모델 사용을 기반으로 이뤄진 이러한 접근법은 높은 연산 능력을 필요로 하게 되어, 자원 제약적인 무선 인터페이스및 사물인터넷(Internet of Things) 장비에서는 사용이 제약된다. 본 연구에서는 비면허 대역의 무선 이기종 기술을 인지하기 위한데이터 기반의 접근 방법을 살펴보고, 신호의 특징 추출 및 데이터화의 효율화 문제를 다룬다. 구체적으로, 비면허 대역의 다른 종류의 무선 통신 기술을 구분하기 위해 수신 신호 강도 측정을 기반으로 한 시계열 데이터를 이용해 합성곱 신경망(ConvolutionalNeural Network, CNN) 모델을 학습시켜 신호를 분류하는 방법을 살펴본다. 이 과정에서 동일한 구조의 신경망 모델의 경량화를위한 효율적 신호의 시계열 데이터 정보 수집시 주파수 대역의 특징을 함께 특징화하는 방법을 제안하고, 그 효과를 평가한다.Bluetooth 호환의 Ubertooth 장비를 이용한 실측 기반의 실험 결과는 제안된 샘플링 기법이 동일한 신경망에 대해서 10% 수준의샘플링 데이터 이용만으로도 동일한 정확도를 유지함을 보여준다.","Recently, there have been many research efforts based on data-based deep learning technologies to deal withthe interference problem between heterogeneous wireless communication devices in unlicensed frequency bands.However, existing approaches are commonly based on the use of complex neural network models, which requirehigh computational power, limiting their efficiency in resource-constrained network interfaces and Internet ofThings (IoT) devices. In this study, we address the problem of classifying heterogeneous wireless technologiesincluding Wi-Fi and ZigBee in unlicensed spectrum bands. We focus on a data-driven approach that employs asupervised-learning method that uses received signal strength indicator (RSSI) data to train Deep ConvolutionalNeural Networks (CNNs). We propose a simple measurement methodology for collecting RSSI training data whichpreserves temporal and spectral properties of the target signal. Real experimental results using an open-source 2.4GHz wireless development platform Ubertooth show that the proposed sampling method maintains the sameaccuracy with only a 10% level of sampling data for the same neural network architecture."
시각적 특징과 물리적 특징에 기반한 스태킹 앙상블 모델을 이용한 과일의 자동 선별,2022,"['Fruit Grading', 'Stacking Ensemble Model', 'CNN', 'Perceptron']",,"As consumption of high-quality fruits increases and sales and packaging units become smaller, the demand for automatic fruit grading systems is increasing. Compared to other crops, the quality of fruit is determined by visual characteristics such as shape, color, and scratches, rather than just physical size and weight. Accordingly, this study presents a CNN model that can effectively extract and classify the visual features of fruits and a perceptron that classifies fruits using physical features, and proposes a stacking ensemble model that can effectively combine the classification results of these two neural networks. The experiments with AI Hub public data show that the stacking ensemble model is effective for grading fruits. However, the ensemble model does not always improve the performance of classifying all the fruit grading. So, it is necessary to adapt the model according to the kind of fruit."
Triplet Loss 기반 딥러닝 모델을 통한 유사 아동 그림 선별 알고리즘,2022,"['이미지 유사성', 'Triplet Loss', '인공지능', '딥러닝', 'CNN', '아동 그림분석', 'Image Similarity', 'Triplet Loss', 'Artificial Intelligence', 'Deep Learning', 'CNN', 'Child drawing analysis']","본 논문은 유사 아동 그림 선별 알고리즘 생성을 위한 Triplet Loss 기반 딥러닝 모델 설계를 목적으로 한다. 아동 그림들 사이 유사성 측정을 위해서는 동일 클래스에 속하는 그림 간 특징 벡터의 거리는 가까워야 하고 다른 클래스 간 특징 벡터의 거리는 멀어져야 한다. 따라서, 본 연구에서는 클래스 수가 많아지는 경우에 이미지 유사성 측정에 이점을 지닌 Triplet Loss와 잔여 네트워크(ResNet)를 결합한 딥러닝 모델을 구축하여 유사 아동 그림 선별 알고리즘을 생성하였다. 결론적으로 본 모델을 활용한 유사 아동 그림 선별 알고리즘을 통해 대상 아동 그림과 다른 그림 간의 유사성을 측정하고 유사성이 높은 그림을 선별할 수 있다.",
Paper Defects Recognition Based on Deformable Convolution,2022,"['Paper defects recognition', 'Faster R-CNN', 'deformable convolution']",,
거푸집 부재 인식을 위한 인공지능 이미지 분할,2022,"['Construction Formwork', 'Safety Management', 'Artificial Intelligence Model', 'Mask R-CNN', 'Image Segmentation', '거푸집', '안전관리', '인공지능모델', '마스크 R-CNN', '이미지 분할']",,"Concrete formwork is a crucial component for any construction project. Artificial intelligence offers great potential to automate formwork design by offering various design options and under different criteria depending on the requirements. This study applied image segmentation in 2D formwork drawings to extract sheathing, strut and pipe support formwork elements. The proposed artificial intelligence model can recognize, classify, and extract formwork elements from 2D CAD drawing image and training and test results confirmed the model performed very well at formwork element recognition with average precision and recall better than 80%. Recognition systems for each formwork element can be implemented later to generate 3D BIM models."
ArchShapesNet: a novel dataset for benchmarking architectural building information modeling element classification algorithms,2022,"['BIM (Building Information Modeling)', 'semantic enrichment', 'parametric augmentation', 'multi-view CNN']",,"Recent studies in the domain of semantic enrichment have employed artificial intelligence (AI) approaches to distinguish and classify building information modeling (BIM) elements to check their conformance with open standard data formats. Training AI algorithms requires the development of well-balanced and robust datasets of BIM elements. However, collection is difficult as sources are limited to existing models and sample libraries. This study developed a parametric augmentation approach to create synthetic copies of BIM elements, and thus rapidly supplement manually collected samples. The approach was used to create ArchShapesNet, a dataset consisting of 11 common architectural elements with an equal size of 4,000 samples per class. Two multi-view convolutional neural networks (CNN), a geometric deep learning algorithm, were trained and tested separately on ArchShapesNet and an initial dataset with sample imbalances. Results showed significant improvement in the accuracy and F1 scores, providing evidence of the utility of ArchShapesNet. The size and scope of the dataset are considered to be the first of their kind and provide a benchmark for testing the semantic integrity of BIM models. The augmentation approach also provides a general framework to create custom datasets for different specialties in the Architectural Engineering and Construction industry."
A SE Approach for Real-Time NPP Response Prediction under CEA Withdrawal Accident Conditions,2022,"['Recurrent Neural Network (RNN)', 'Long Short Term Memory (LSTM)', 'Gated Recurrent Unit (GRU)', 'Convolutional Neural Network (CNN)', 'Machine Learning (ML)', 'Best Estimate Plus Uncertainty (BEPU)']",,"Machine learning (ML) data-driven meta-model is proposed as a surrogate model to reduce the excessive computational cost of the physics-based model and facilitate the real-time prediction of a nuclear power plant's transient response. To forecast the transient response three machine learning (ML) meta-models based on recurrent neural networks (RNNs); specifically, Long Short Term Memory (LSTM), Gated Recurrent Unit (GRU), and a sequence combination of Convolutional Neural Network (CNN) and LSTM are developed. The chosen accident scenario is a control element assembly withdrawal at power concurrent with the Loss Of Offsite Power (LOOP). The transient response was obtained using the best estimate thermal hydraulics code, MARS-KS, and cross-validated against the Design and control document (DCD). DAKOTA software is loosely coupled with MARS-KS code via a python interface to perform the Best Estimate Plus Uncertainty Quantification (BEPU) analysis and generate a time series database of the system response to train, test and validate the ML meta-models. Key uncertain parameters identified as required by the CASU methodology were propagated using the non-parametric Monte-Carlo (MC) random propagation and Latin Hypercube Sampling technique until a statistically significant database (181 samples) as required by Wilk's fifth order is achieved with 95% probability and 95% confidence level. The three ML RNN models were built and optimized with the help of the Talos tool and demonstrated excellent performance in forecasting the most probable NPP transient response. This research was guided by the Systems Engineering (SE) approach for the systematic and efficient planning and execution of the research."
균형적인 신체활동을 위한 맞춤형 AI 운동 추천 서비스,2022,"['1차원 컨볼루션', '합성곱 신경망', 'WISDM 데이터셋', '신체활동', 'AI 운동 추천 서비스', '1D Convolution', 'CNN', 'Physical Activity', 'WISDM dataset', 'AI Exercise Recommendation Service']","본 논문은 직종별 근무 환경에 따른 상대적 운동량을 고려한 맞춤형 AI 운동 추천 서비스 방법을 제안한다. 가속도 및 자이로 센서를 활용하여 수집된 데이터를 18가지 일상생활의 신체활동으로 분류한 WISDM 데이터베이스를 기반으로 전신, 하체, 상체의 3가지 활동으로 분류한 후 인식된 활동 지표를 통해 적절한 운동을 추천한다. 본 논문에서 신체활동 분류를 위해서 사용하는 1차원 합성곱 신경망(1D CNN; 1 Dimensional Convolutional Neural Network) 모델은 커널 크기가 다른 다수의 1D 컨볼루션(Convolution) 계층을 병렬적으로 연결한 컨볼루션 블록을 사용한다. 컨볼루션 블록은 하나의 입력 데이터에 다층 1D 컨볼루션을 적용함으로써 심층 신경망 모델로 추출할 수 있는 입력 패턴의 세부 지역 특징을 보다 얇은 계층으로도 효과적으로 추출할 수 있다. 제안한 신경망 모델의 성능 평가를 위해서 기존 순환 신경망(RNN; Recurrent Neural Network) 모델과 비교 실험한 결과 98.4%의 현저한 정확도를 보였다.",
기계학습에 의한 후두 장애음성 식별기의 성능 비교,2022,"['diagnosis', 'glottic cancer', 'vocal cords disorder', 'machine learning', 'convolutional neural network']",,"This paper studies how to improve the identification rate of laryngeal disability speech data by convolutional neural network (CNN) and machine learning ensemble learning methods. In general, the number of laryngeal dysfunction speech data is small, so even if identifiers are constructed by statistical methods, the phenomenon caused by overfitting depending on the training method can lead to a decrease the identification rate when exposed to external data. In this work, we try to combine results derived from CNN models and machine learning models with various accuracy in a multi-voting manner to ensure improved classification efficiency compared to the original trained models. The Pusan National University Hospital (PNUH) dataset was used to train and validate algorithms. The dataset contains normal voice and voice data of benign and malignant tumors. In the experiment, an attempt was made to distinguish between normal and benign tumors and malignant tumors. As a result of the experiment, the random forest method was found to be the best ensemble method and showed an identification rate of 85%."
위성 SAR 영상의 지상차량 표적 데이터 셋 및 탐지와 객체분할로의 적용,2022,"['합성 개구면 레이더', '표적 탐지', '객체분할', '영역 및 객체분할용 합성곱 신경망', '딥러닝', 'Synthetic Aperture Radar', 'Target Detection', 'Instance Segmentation', 'Mask R-CNN', 'Deep Learning']",,"The advent of deep learning-based algorithms has facilitated researches on target detection from synthetic aperture radar(SAR) imagery. While most of them concentrate on detection tasks for ships with open SAR ship datasets and for aircraft from SAR scenes of airports, there is relatively scarce researches on the detection of SAR ground vehicle targets where several adverse factors such as high false alarm rates, low signal-to-clutter ratios, and multiple targets in close proximity are predicted to degrade the performances. In this paper, a dataset of ground vehicle targets acquired from TerraSAR-X(TSX) satellite SAR images is presented. Then, both detection and instance segmentation are simultaneously carried out on this dataset based on the deep learning-based Mask R-CNN. Finally, this paper shows the future research directions to further improve the performances of detecting the SAR ground vehicle targets."
Comparative analysis of imaging diagnostic models for tubular basophilia and mineralization of kidney,2022,"['Artificial intelligence', 'Diagnosis', 'Classification modelsm', 'YOLOv4', 'Tubular basophilia', 'Mineralization']",,"Background: Now that it is possible to efficiently classify and save tissue images of laboratory animals using wholeslide imaging, many diagnostic models are being developed through transfer learning with Convolutional Neural Network (CNN). In this study, transfer learning was performed to gain toxicopathological knowledge using CNN models such as InceptionV3 and Xception. For the classification of tubular basophilia and mineralization, two representative background lesions that commonly occur in toxicological studies, accuracies of diagnosis were compared using MobileNetV2, Xception and InceptionV3. For the simultaneous detection of the two lesions, the accuracy was analysed using You Only Look Once version 4 (YOLOv4).Results: The accuracy of the classification models was as follows: MobileNetV2 (epoch 50, accuracy: 98.57%) > Xception (epoch 70, accuracy: 97.47%) > InceptionV3 (epoch 70, accuracy: 89.62%). In the case of object detection, the accuracy of YOLOv4 was 98.62% at epoch 3000.Conclusions: Among the classification models, MobileNetV2 had the best accuracy despite applying a lower epoch than InceptionV3 and Xception. The object detection model, YOLOv4, accurately and simultaneously diagnosed tubular basophilia and mineralization, with an accuracy of 98.62% at epoch 3000."
Bioimage Analyses Using Artificial Intelligence and Future Ecological Research and Education Prospects: A Case Study of the Cichlid Fishes from Lake Malawi Using Deep Learning,2022,"['Animal detection', 'Artificial intelligence', 'Citizenscience', 'Deep learning', 'Education', 'Machine learning']",,"Ecological research relies on the interpretation of large amounts of visual data obtained from extensive wildlife surveys, but such large-scale image interpretation is costly and time-consuming. Using an artificial intelligence (AI) machine learning model, especially convolution neural networks (CNN), it is possible to streamline these manual tasks on image information and to protect wildlife and record and predict behavior. Ecological research using deep-learning-based object recognition technology includes various research purposes such as identifying, detecting, and identifying species of wild animals, and identification of the location of poachers in real-time. These advances in the application of AI technology can enable efficient management of endangered wildlife, animal detection in various environments, and real-time analysis of image information collected by unmanned aerial vehicles. Furthermore, the need for school education and social use on biodiversity and environmental issues using AI is raised. School education and citizen science related to ecological activities using AI technology can enhance environmental awareness, and strengthen more knowledge and problem-solving skills in science and research processes. Under these prospects, in this paper, we compare the results of our early 2013 study, which automatically identified African cichlid fish species using photographic data of them, with the results of reanalysis by CNN deep learning method. By using PyTorch and PyTorch Lightning frameworks, we achieve an accuracy of 82.54% and an F1-score of 0.77 with minimal programming and data preprocessing effort. This is a significant improvement over the previous our machine learning methods, which required heavy feature engineering costs and had 78% accuracy."
차량 안전 제어를 위한 파티클 필터 기반의 강건한 다중 인체 3차원 자세 추정,2022,"['Human Pose Estimation(인체 자세 추정)', 'Sensor Fusion(센서 융합)', 'Convolutional Neural Network(합성곱 신경망)', 'Driver Monitoring System(운전자 모니터링 시스템)']",,"In autonomous driving cars, 3D pose estimation can be one of the effective methods to enhance safety control for OOP (Out of Position) passengers. There have been many studies on human pose estimation using a camera. Previous methods, however, have limitations in automotive applications. Due to unexplainable failures, CNN methods are unreliable, and other methods perform poorly. This paper proposes robust real-time multi-human 3D pose estimation architecture in vehicle using monocular RGB camera. Using particle filter, our approach integrates CNN 2D/3D pose measurements with available information in vehicle. Computer simulations were performed to confirm the accuracy and robustness of the proposed algorithm."
사전훈련된 딥러닝 네트워크를 활용한 이미지 기반 딥러닝 모델 설계,2022,"['Automatic Modulation Classification', 'Convolutional Neural Network', 'Cognitive Radio Networks', 'Predicted Accuracy', 'Computational Complexity']","본 논문에서는 인지 통신에 사용되는 자동 변조 분류를 위해 이미지 기반 딥러닝 모델을 설계하였다. 제안된설계 방식은 초기 신호 기반 딥러닝 모델과 이미지 기반 딥러닝 모델 2가지로 구분되며 딥러닝 네트워크 유형은Convolutional Neural Network (CNN)을 사용하였다. 신호 기반 딥러닝 모델 프레임 단위로 학습되도록 하였고각 프레임은 1024 신호 샘플로 구성하였다. 학습전 Root Mean Square (RMS) 방식을 통해 프레임을 정규화하였고 실수부와 허수부로 구분하여  × 크기로 입력하였다. 제안된 신호 기반 딥러닝 모델은 컨볼루션 레이어의필터 크기에 따른 정확도 성능에 대하여 분석한 다음  × 필터 크기 지정을 통해 예측성능을 최적화하였다. 이미지 기반 딥러닝 모델은 사전훈련된 신호 기반 딥러닝 네트워크를 사용하여 추출된 특징 데이터를 이미지로 변환하여 학습된 다음 각각의 변조 유형을 예측하도록 하였다. 추출된 특징은 신호 기반 딥러닝 네트워크의Fully-Connected layer를 통해  × 특징 크기로 추출하였으며 각 특징이 가지는 특징값은 –30 - +30 스케일범위에 따라 Red, Green, Blue (RGB) 이미지로 변환하였다. 제안된 모델의 예측 정확도 성능은 Signal-to-Noise Ratio (SNR) 10 dB에서 기존 ECNN, SCGNet 그리고 LCNN 보다 1.38%, 7.41% 그리고 4.05% 높은 예측 정확도를 보였으며 SNR 0 dB에서는 0.26%, 3.4% 그리고 1.13% 각각 높은 성능을 보였다.","In this paper, an image-based deep learning model is designed for Automatic Modulation Classification (AMC) in cognitive radio. The proposed design method consists of a signal-based deep learning model and an image-based deep learning model, and a Convolutional Neural Network (CNN) is used for the deep learning network type. The signal-based deep learning model is trained in units of a frame which is composed of 1024 signal samples. Before being used for training, the frame is normalized through the Root Mean Square (RMS) method, and the frame is dividied into the real part and the imaginary part. The proposed signal-based deep learning model is analyzed according to the filter size of the convolution layer and optimized by specifying  × filter size. The image-based deep learning model is trained through images that is from the extracted feature data using the pretrained signal-based deep learning network, and predicted each modulation type. The feature size is  ×, which is extracted through the Fully-Connected layer of the signal-based deep learning network, and the features are converted into Red, Green, and Blue (RGB) images according to the -30 - +30 scale range. The prediction performance of the proposed model shows 2.13%, 4.05% and 9.47% higher accuracy at Signal-to-Noise Ratio (SNR) 10 dB, and 2.12%, 3.4% and 4.26% higher accuracy at SNR 0 dB than the conventional models ECNN, SCGNet and MCNet, respectively."
A Deep Learning Architecture for Meningioma Brain Tumor Detection and Segmentation,2022,"['Meningioma', 'Tumor', 'Brain image', 'Sub bands']",,"The meningioma brain tumor detection and segmentation method is a complex process due to its low intensity pixel profile. In this article, the meningioma brain tumor images were detected and tumor regions were segmented using a convolutional neural network (CNN) classification approach. The source brain MRI images were decomposed using the discrete wavelet transform and these decomposed sub bands were fused using an arithmetic fusion technique. The fused image was data augmented in order to increase the sample size. The data augmented images were classified into either healthy or malignant using a CNN classifier.Then, the tumor region in the classified meningioma brain image was segmented using an connection component analysis algorithm. The tumor region segmented meningioma brain image was compressed using a lossless compression technique. The proposed method stated in this article was experimentally tested with the sets of meningioma brain images from an open access dataset. The experimental results were compared with existing methods in terms of sensitivity, specificity and tumor segmentation accuracy."
U-Net과 cWGAN을 이용한 탄성파 탐사 자료 보간 성능 평가,2022,"['seismic data interpolation', 'machine learning', 'U-Net', 'cWGAN', 'ensemble', '탄성파 탐사 보간법', '기계학습', 'U-Net', 'cWGAN', '앙상블']","탄성파 탐사 자료 획득 시 자료의 일부가 손실되는 문제가 발생할 수 있으며 이를 위해 자료 보간이 필수적으로 수행된다. 최근 기계학습 기반 탄성파 자료 보간법 연구가 활발히 진행되고 있으며, 특히 영상처리 분야에서 이미지 초해상화에 활용되고 있는 CNN (Convolutional Neural Network) 기반 알고리즘과 GAN (Generative Adversarial Network) 기반 알고리즘이 탄성파 탐사 자료 보간법으로도 활용되고 있다. 본 연구에서는 손실된 탄성파 탐사 자료를 높은 정확도로 복구하는 보간법을 찾기 위해 CNN 기반 알고리즘인 U-Net과 GAN 기반 알고 리즘인 cWGAN (conditional Wasserstein Generative Adversarial Network)을 탄성파 탐사 자료 보간 모델로 사용하여 성능 평가 및 결과 비 교를 진행하였다. 이때 예측 과정을 Case I과 Case II로 나누어 모델 학습 및 성능 평가를 진행하였다. Case I에서는 규칙적으로 50% 트레 이스가 손실된 자료만을 사용하여 모델을 학습하였고, 생성된 모델을 규칙/불규칙 및 샘플링 비율의 조합으로 구성된 총 6가지 테스트 자 료 세트에 적용하여 모델 성능을 평가하였다. Case II에서는 6가지 테스트 자료와 동일한 형식으로 샘플링된 자료를 이용하여 해당 자료 별 모델을 생성하였고, 이를 Case I과 동일한 테스트 자료 세트에 적용하여 결과를 비교하였다. 결과적으로 cWGAN이 U-Net에 비해 높 은 정확도의 예측 성능을 보였으며, 정량적 평가지수인 PSNR과 SSIM에서도 cWGAN이 높은 값이 나타나는 것을 확인하였다. 하지만 cWGAN의 경우 예측 결과에서 추가적인 잡음이 생성되었으며, 잡음을 제거하고 정확도를 개선하기 위해 앙상블 작업을 수행하였다. Case II에서 생성된 cWGAN 모델들을 이용하여 앙상블을 수행한 결과, 성공적으로 잡음이 제거되었으며 PSNR과 SSIM 또한 기존의 개별 모델 보다 향상된 결과를 나타내었다.",
스마트폰 녹음 여부 검출을 위한 딥러닝 기반 오디오 포렌식,2022,"['audio recording device forensics', 'mel-spectrogram', 'convolutional neural network', 'smartphone']",,"Most of audio data used in recent crimes is mostly recorded through portable smartphones. Therefore, it is meaningful for forensic analysis to detect only audio data recorded using the smartphone among vast amounts of audio data. In this paper, based on a CNN model, we propose a forensic algorithm to detect whether or not audio data is recorded by a smartphone. Mel-spectrogram features were extracted by dividing the input audio into 10-second segments and applied to a CNN model that detects smartphone recording through training and testing. Experiments were conducted using the audio data collected by ourselves, and as a result, we achieved 94.98% detection accuracy for each segment and 95.40% detection accuracy for the entire audio."
비지역 희소 어텐션 메커니즘을 활용한 초해상화,2022,"['Super-resolution', 'Deep learning', 'Attention mechanism', 'NLSA', 'IMDN', 'CARN', 'OISR-LF-s', '초해상화', '딥러닝', '어텐션 메커니즘', 'NLSA', 'IMDN', 'CARN', 'OISR-LF-s']","딥러닝이 발전하면서 초해상화 기술은 단순 보간법(Interpolation)에서 벗어나 딥러닝을 활용해 발전하고 있다. 딥러닝을 사용한 초해상화 기술은 합성곱 신경망(Convolutional Neural Network, CNN) 기반의 연구가 일반적이지만, 최근에는 어텐션(Attention) 메커니즘을 활용한 초해상화 연구가 활발히 진행되고 있다. 본 논문에서는 어텐션 메커니즘 중 하나인 비지역 희소 어텐션(Non-Local Sparse Attention, NLSA)을 활용한 초해상화 성능 향상 방법을 제안한다. 실험을 통해 NLSA를 함께 활용하면 기존 초해상화 신경망 모델인 IMDN, CARN, OISR-LF-s의 성능이 향상되는 것을 확인할 수 있었다.","With the development of deep learning, super-resolution (SR) methods have tried to use deep learning mechanism, instead of using simple interpolation. SR methods using deep learning is generally based on convolutional neural networks (CNN), but recently, SR researches using attention mechanism have been actively conducted. In this paper, we propose an approach of improving SR performance using one of the attention mechanisms, non-local sparse attention (NLSA). Through experiments, we confirmed that the performance of the existing SR models, IMDN, CARN, and OISR-LF-s can be improved by using NLSA."
SDR 플랫폼을 위한 딥러닝 기반의 무선 자동 변조 분류기술 연구,2022,"['Automatic modulation classification', 'deep learning', 'Software-defined radio', 'SCA', 'convolution neural network', 'input size scalable', 'self-replication padding']","무선 신호 인식 및 자동 변조 분류(Automatic Modulation Classification) 기술은 넓은 주파수 대역에서 다양한 무선 통신 서비스를 단일 단말에서 유연하게 이용 가능한 SDR(Software Defined Radio) 플랫폼의 핵심 요소 기술로 필요성이 높아지고 있다.최근에는 데이터 학습 기반의 딥러닝 기술을 기반으로 정확도가 향상된 여러 가지 자동 변조 분류 모델들이 제안되고 있다. 하지만,대부분의 연구는 모델에 입력되는 무선 신호의 길이가 고정된 경우에 초점을 맞추고 길이가 가변적인 시나리오를 고려하지 않고 있다. 본 연구에서는 SDR의 개방형 플랫폼의 요소 기술로써 임의의 무선 신호의 길이에 대해 변조 분류가 가능한 방법을 제안한다.이를 위해, 두 가지 입력 크기에 대해 학습된 Convolutional Neural Network(CNN) 기반의 주 모델(main model)과 하위 모델(small model)로 분류 시스템을 설계하고, 나머지 구간의 길이로 수신된 신호에 대해서는 자기 복제 패딩 기법으로 입력 샘플을증강시켜 변조 분류를 수행한다. 분류 성능 정확도 및 계산 복잡도의 비교분석을 위한 RadioML 2018.01A 데이터셋을 사용한 실험을 통해 제안하는 기법이 모든 신호 대 잡음비(Signal-to-Noise Ratio, SNR) 영역에서 기존 방식보다 높은 정확도를 제공하면서도 낮은 연산량을 필요함을 보였다.","Automatic modulation classification(AMC) is a core technique in Software Defined Radio(SDR) platform thatenables smart and flexible spectrum sensing and access in a wide frequency band. In this study, we propose asimple yet accurate deep learning-based method that allows AMC for variable-size radio signals. To this end, wedesign a classification architecture consisting of two Convolutional Neural Network(CNN)-based models, namelymain and small models, which were trained on radio signal datasets with two different signal sizes, respectively.Then, for a received signal input with an arbitrary length, modulation classification is performed by augmentingthe input samples using a self-replicating padding technique to fit the input layer size of our model. Experimentsusing the RadioML 2018.01A dataset demonstrated that the proposed method provides higher accuracy than theexisting methods in all signal-to-noise ratio(SNR) domains with less computation overhead."
Yolo-v4 기반 초저지연 차량 식별과 통행량 추적 정밀도 개선,2022,"['cooperative driving infra sensor', 'deep learning', 'object detection', 'object tracking', 'self driving', '협력주행 인프라 센서', '딥러닝', '객체 검출', '객체 추적', '자율주행']","자율주행 기술의 고도화 및 상용화에 따라 차량 자체 센서의 인지 범위의 확장을 위한 인프라 기반 협력주행기술에 대한 수요가 증가하고 있다. 특히 노변에 설치되어 교통 상황을 실시간으로 파악하고 기록하여 차량에 제공할 수 있는 엣지 인프라 기술 연구가 활발하게 진행되고 있으며, 정보 수집을 위한 센서에 대한 연구가 활발한 상황이다. 이러한 흐름에 따라, 최근 CNN 기반의 영상분석을 통한 교통정보 수집 기술에 대한 연구도 활발히 진행되고 있는데, 이러한 CNN 기반의 알고리즘은 영상 내의 외양 특징을 기반으로 개별 객체를 식별할 수 있어 자율주행 자동차에서 인식하지 못하는 도로상의 객체 정보를 제공할 수 있어 인프라 구축에 활용이 가능할 것으로 주목받고 있다. 하지만 기존 C-ITS 사업 대부분은 딥러닝 알고리즘의 높은 요구 연산량으로 인하여 영상분석을 현장이 아닌 센터의 높은 사양 서버에서 처리하고 있는데, 이는 인프라 시스템에서의 정보 제공 지연에 따른 사고의 발생 위험을 증대시킬 위험이 있다. 따라서 이러한 위험을 최소화하기 위해서는 센터가 아닌 노변에서의 실시간 영상분석을 통해 통신 지연을 최소화할 필요가 있다. 본 연구에서는 노변에 위치하여 실시간으로 영상을 분석하여 도로에 위치한 객체 정보를 산출할 수 있는 차량검지 시스템을 설계하였으며, 알고리즘의 노변 환경 적용을 위해 신경망의 구성을 간소화하여 딥러닝 연산량을 줄일 수 있는 방법을 제시한다.",
청각장애인을 위한 인공지능 헤드폰 설계,2022,"['인공지능 헤드폰', '소리 분류', '인공지능', '키워드 인식', '진동 코드', '합성곱 신경망', 'AI headphone', 'Sound Source Classification', 'Artificial Intelligence', 'Keyword Recognition', 'Vibration Code', 'Convolution Neural Network']","이 논문에서는 청각장애인을 위하여 시야 밖에서 발생하는 위험 환경 소리(사이렌, 자동차경적, 비명, 총소리, 공사장 소음 등) 및 특정 음성 키워드(본인 이름, 조심하세요! 등)가 인식이 되면 진동 코드로 알려주어 사고 노출 위험성감소와 편의성을 높여주는 인공지능 헤드폰을 제안하였다. 웨어러블 기기에 걸맞게 저전력 및 휴대가 가능하도록 임베디드PC(Raspberry Pi 4B)에서 동작이 가능한 20종류의 소리를 분류할 수 있는 합성곱 신경망(CNN)기반 네트워크를 제안하였다. 제안한 소리 인식기는 평균 약 95.14% 인식률을 보였으며, 5.12초 길이의 음성 데이터가 라즈베리파이4B 상에서 평균 약 0.139초에 실행되어 실시간 처리가 가능함을 확인하였다.","We designed an artificial intelligence (AI) headphone for hearing impaired people and proposed a convolution neural network (CNN)-based sound classifier with a low computational network that can run on an embedded PC (Raspberry Pi 4B) in real-time. Because our AI headphone can classify 20 types of dangerous or environmental sounds (e.g., siren, car horn, scream, gunshot, etc.) and recognize specific voice keywords (e.g., person name, be careful!, stop!, etc.), it can assist hearing impaired people in reducing the risk of accident exposure and improving convenience. In addition, we use vibration codes to notify the hearing impaired person of detected information to the vibration motors attached to both sides of the headphone. We confirm that our proposed sound classifier achieves an average accuracy rate of approximately 95.14%, and enables real-time processing on the Raspberry Pi 4B because it requires an average computation time of approximately 0.139s with audio recording data for 5.12s."
그룹 집중 기술로 개선된 Trans-Unet기반 단일 영상 연무제거 신경망,2022,"['Computer vision', 'Image dehazing', 'Vision transformer', 'Unet', 'Group attention block']",,
Deep learning-based apical lesion segmentation from panoramic radiographs,2022,"['Artificial Intelligence', 'Deep Learning', 'Periapical Periodontitis', 'Radiography', 'Panoramic']",,"Purpose: Convolutional neural networks (CNNs) have rapidly emerged as one of the most promising artificial intelligence methods in the field of medical and dental research. CNNs can provide an effective diagnostic methodology allowing for the detection of early-staged diseases. Therefore, this study aimed to evaluate the performance of a deep CNN algorithm for apical lesion segmentation from panoramic radiographs. Materials and Methods: A total of 1000 panoramic images showing apical lesions were separated into training (n=800, 80%), validation (n=100, 10%), and test (n=100, 10%) datasets. The performance of identifying apical lesions was evaluated by calculating the precision, recall, and F1-score. Results: In the test group of 180 apical lesions, 147 lesions were segmented from panoramic radiographs with an intersection over union (IoU) threshold of 0.3. The F1-score values, as a measure of performance, were 0.828, 0.815, and 0.742, respectively, with IoU thresholds of 0.3, 0.4, and 0.5. Conclusion: This study showed the potential utility of a deep learning-guided approach for the segmentation of apical lesions. The deep CNN algorithm using U-Net demonstrated considerably high performance in detecting apical lesions."
MobileNet을 이용한 사람 음성 구간의 오디오 축약 방법,2022,"['audio deduction', 'voice activity detection', 'classification', 'MFCC', 'mobileNet', 'deep learning']","다양한 스마트 기기에서 오디오 정보들을 수집하고 활용하는 응용들이 개발되고 있다. 방대한 오디오 중에서 사람 음성은 중요한 정보로 오디오에서 음성 구간만 축약하는 것은 유용하다. 본 논문에서는 MobileNet을 사용하여 오디오에서 비음성 구간들을 제외한 음성 구간만을 축약시키는 방법을 제안한다. 입력 오디오를 3초 단위 세그먼트로 구분하고, MFCC 특징을 추출하여 사람 음성 판별에 활용하였다. 특히, 기존에 많이 사용되는 CNN 모델은 구조가 깊어져서 연산량이 증가하는 문제가 있어서, 연산량 최적화에 중점을 둔 MobileNet을 활용하였다. 국내외 여러 데이터셋과 자체적으로 수집한 오디오를 사용하여 실험을 수행하였고, 그 결과 세그먼트 단위로 93.92% 음성 검출 정확도와 전체 오디오에 대해 88.05%의 축약 정확도를 달성하였다.","Applications for collecting and utilizing audio information from various smart devices are being developed. Human voice is important data among vast amounts of audio, and it is useful to deduct only voice activity segments from audio. This paper proposes a method to contract only voice activity segments excluding non-speech segments using MobileNet. Input audio is divided into 3 second segments and MFCC features are extracted and used for voice detection. A CNN model widely used in the past has a problem of increasing the amount of computation due to its deep structure. Therefore, MobileNet focused on optimizing the amount of computation is used. Experiments were performed using domestic and foreign datasets and audio collected by ourselves. As a result, we achieved the voice detection accuracy of 93.92% for each segment and the reduction accuracy of 88.05% for the entire audio."
딥러닝 기반 지하 공동구 내 소화기 객체 탐지 모델 개발,2022,"['지하공동구', '딥러닝', '객체검출', '소화기', '디지털트윈', 'Underground Utility Tunnel', 'Deep Learning', 'Object Detection', 'Fire Extinguisher', 'Digital Twin']","연구목적: 본 논문은 지하공동구 내 CCTV에서 촬영된 영상에서 소화기를 탐지하기 위해 딥러닝 모델을 개발하는데 목적이 있다. 연구방법:  딥러닝 기반 지하공동구 내 소화기 탐지를 위해 다양한 소화기 이미지를 수집하였으며  CNN 알고리즘을 기반으로 하여 One-stage Detector 방식을 적용한 모델을 개발하였다.   연구결과:  지하공동구 내 CCTV 영상을 통해 10m 이내의 거리에서 촬영되는 소화기의 검출율은 96%이상으로 우수한 검출율을 보여준다.  다만 10m 이상의 거리에서는 육안으로도 확인하기 힘든 상태로, 소화기 객체 검출율이 급격하게 낮아지는 것을 확인하였다. 결론: 본 논문은 지하공동구 내 소화기 객체를 검출하는 모델을 개발하였으며, 해당 모델이 높은 성능을 보여 지하공동구 디지털트윈 모델 연동에 활용할 수 있을 것으로 판단된다.","Purpose: The purpose of this paper is to develop a deep learning model to detect fire extinguishers in images taken from CCTVs in underground utility tunnels. Method: Various fire extinguisher images were collected for detection of fire extinguishers in the running-based underground utility tunnel, and a model applying the One-stage Detector method was developed based on the CNN algorithm. Result: The detection rate of fire extinguishers photographed within 10m through CCTV video in the underground common area is over 96%, showing excellent detection rate. However, it was confirmed that the fire extinguisher object detection rate drops sharply at a distance of 10 m or more, in a state where it is difficult to see with the naked eye. Conclusion: This paper develops a model for detecting fire extinguisher objects in underground common areas, and the model shows high performance, and it is judged that it can be used for underground common area digital twin model synchronizing."
딥러닝 기반의 핵의학 폐검사 분류 모델 적용,2022,"['컨볼루션 신경망', '딥러닝', '폐 신티그라피', '분류-활성화 맵', '핵의학', 'Convolutional neural network', 'Deep learning', 'Lung scintigraphy', 'Class activation map', 'Nuclear medicine']",,"The purpose of this study is to apply a deep learning model that can distinguish lung perfusion and lung ventilation images in nuclear medicine, and to evaluate the image classification ability. Image data pre-processing was performed in the following order: image matrix size adjustment, min-max normalization, image center position adjustment, train/validation/test data set classification, and data augmentation. The convolutional neural network(CNN) structures of VGG-16, ResNet-18, Inception-ResNet-v2, and SE-ResNeXt-101 were used. For classification model evaluation, performance evaluation index of classification model, class activation map(CAM), and statistical image evaluation method were applied. As for the performance evaluation index of the classification model, SE-ResNeXt-101 and Inception-ResNet-v2 showed the highest performance with the same results. As a result of CAM, cardiac and right lung regions were highly activated in lung perfusion, and upper lung and neck regions were highly activated in lung ventilation. Statistical image evaluation showed a meaningful difference between SE-ResNeXt-101 and Inception-ResNet-v2. As a result of the study, the applicability of the CNN model for lung scintigraphy classification was confirmed. In the future, it is expected that it will be used as basic data for research on new artificial intelligence models and will help stable image management in clinical practice."
피로도 측정을 위한 정면 얼굴 영상 분석,2022,"['Fatigue measurement', 'Video analysis', 'Migration', 'Video classification', 'Deep learning', 'Machine learning', '피로도 측정', '영상 분석', '영상 분류', '딥러닝', '머신러닝']","사람이 느끼는 피로는 다양한 생체신호로부터 측정이 가능한 것으로 알려져 있으며, 기존 연구는 질병과 관련된 심각한 피로수준을 산정하는데 주된 목적을 두고 있다. 본 연구에서는 피실험자의 영상을 이용하여 딥러닝 기반의 영상 분석 기술을 적용, 피로 여부를 판단하기 위한 모델을 제안한다. 특히 화상 분석에서 통상적으로 사용되는 객체 인식, 요소 추출과 함께 영상 데이터의 시계열적 특성을 고려하여 방법론을 교차한 3개 분석모델을 제시했다. 다양한 피로상황에서 수집된 정면 얼굴 영상 데이터를 이용하여 제시된 모델을 실험하였으며, CNN 모델의 경우 0.67의 정확도로 피로 상태를 분류할 수 있어 영상 분석 기반의 피로 상태 분류가 유의미하다고 판단된다. 또한 모델별 학습 및 검증 절차 분석을 통해 영상 데이터 특성에 따른 모델 적용방안을 제시했다.","We can sense somebody’s feeling fatigue, which means that fatigue can be detected through sensing human biometric signals. Numerous researches for assessing fatigue are mostly focused on diagnosing the edge of disease-level fatigue. In this study, we adapt quantitative analysis approaches for estimating qualitative data, and propose video analysis models for measuring fatigue state. Proposed three deep-learning based classification models selectively include stages of video analysis: object detection, feature extraction and time-series frame analysis algorithms to evaluate each stage’s effect toward dividing the state of fatigue. Using frontal face videos collected from various fatigue situations, our CNN model shows 0.67 accuracy, which means that we empirically show the video analysis models can meaningfully detect fatigue state. Also we suggest the way of model adaptation when training and validating video data for classifying fatigue."
Deep learning-based apical lesion segmentation from panoramic radiographs,2022,"['Artificial Intelligence', 'Deep Learning', 'Periapical Periodontitis', 'Radiography', 'Panoramic']",,"Purpose: Convolutional neural networks (CNNs) have rapidly emerged as one of the most promising artificial intelligence methods in the field of medical and dental research. CNNs can provide an effective diagnostic methodology allowing for the detection of early-staged diseases. Therefore, this study aimed to evaluate the performance of a deep CNN algorithm for apical lesion segmentation from panoramic radiographs.Materials and Methods: A total of 1000 panoramic images showing apical lesions were separated into training (n = 800, 80%), validation (n = 100, 10%), and test (n = 100, 10%) datasets. The performance of identifying apical lesions was evaluated by calculating the precision, recall, and F1-score.Results: In the test group of 180 apical lesions, 147 lesions were segmented from panoramic radiographs with an intersection over union (IoU) threshold of 0.3. The F1-score values, as a measure of performance, were 0.828, 0.815, and 0.742, respectively, with IoU thresholds of 0.3, 0.4, and 0.5.Conclusion: This study showed the potential utility of a deep learning-guided approach for the segmentation of apical lesions. The deep CNN algorithm using U-Net demonstrated considerably high performance in detecting apical lesions."
A novel 3D-Convolution Neural Network for Human Interaction Recognition in videos,2022,"['3D Convolution Neural Network', 'Deep Neural Network', 'Human Action Recognition', 'Human Interaction Recognition', '3D 컨볼루션 신경망', '심층 신경망', '인간 행동 인식', '인간 상호 작용 인식']",,"Human Interaction Recognition (HIR) has already been perceived rapid progress same as human action and activity recognition. In HIR, we intend to highlight the problem of human-to-human interaction recognition in videos by exploring the long term inter-related dynamics between multiple humans. In order to understand the human-to-human interaction precisely, HIR system requires a robust feature extraction and selection method based on videos. In this paper, we propose a novel 3D convolutional neural network (3D CNN) followed by a fully connected block, to wisely trace human to human interactions in videos. We feed our proposed model with 15 sequence of video frames to our novel 3D CNN architecture which extracts deep features from all the sequences and then pass those sequences to the fully connected block to boost our efficiency. Our proposed network outperformed the existing state-of-the-art methods by accomplishing extraordinary recognition accuracy on two benchmark datasets, UT-I and TV Human Interaction dataset i.e., 84% and 74% overall and improved from the state-of-the-art techniques. Our proposed network can also be applicable to other numerous multimedia contents and security applications such as video-based learning, service combats, medical futurists, interactive gaming, and surveillance systems."
딥러닝 기반 폴리에스터 섬유의 염색색상 결과예측 모형 개발,2022,"['폴리에스터 섬유', '딥러닝', '염색색상 예측', 'Polyester Fiber', 'Deep Learning', 'Dyeing Color Prediction']","섬유 소재의 염색은 기업별로 고유의 레시피와 공정으로 인하여 결과물 간의 차이가 존재할 뿐만 아니라 예측하기도 어려운 실정이다. 본 연구는 염색 공정에서의 색상구현 최적화를 위해 딥러닝 기반의 예측 모형을 개발하고자 시도되었다. 이를 위하여 딥러닝 기반 모형인 다층퍼셉트론, CNN 그리고 LSTM 모형을 선정하였다. 총 376건의 데이터 세트를 수집하여 3개의 예측 모형을 학습시켰다. 교차검증 방법을 이용하여 3개의 예측 모형에 대해 비교 및 분석하였다. LSTM 모형의 예측 결과에 대한 CMC(2:1) 색차의 평균이 가장 우수한 것으로 나타났다.","Due to the unique recipes and processes of each company, not only differences among the results of dyeing textile materials exist but they are also difficult to predict. This study attempted to develop a color prediction model based on deep learning to optimize color realization in the dyeing process. For this purpose, deep learning-based models such as multilayer perceptron, CNN and LSTM models were selected. Three forecasting models were trained by collecting a total of 376 data sets. The three predictive models were compared and analyzed using the cross-validation method. The mean of the CMC (2:1) color difference for the prediction results of the LSTM model was found to be the best."
객체 인식을 이용한 차량 모니터링 시스템,2022,"['실시간 객체 인식', '교통 정보 수집', 'YOLOv5', 'DeepSort', 'Ai 보드', 'real-time object detection', 'traffic data-collection', 'YOLOv5', 'AI board']","본 논문은 YOLOv5의 실시간 객체 인식을 이용하여 교통 상황을 모니터링하고, 신뢰성 있는 교통 정보를 수집하는 시스템을 설계한다. 설계된 시스템은 카메라 한 대와 AI 보드 한 대만을 사용하므로 이동 설치에 용이하고, 측정 장비 설치 시 전문인력을 필요로 하지 않으므로 기존 교통 정보 수집 시스템의 경제적 단점을 해결한다. 객체 인식 시에 YOLOv5를 사용하므로 순차적으로 필터를 움직이면서 영상을 처리하는 CNN 기법보다 속도와 정확도에서 높은 성능을 발휘한다. 따라서 신뢰도 높은 정보 수집이 가능할 것이며 수집된 정보를 자동으로 서버에저장한다. 이 시스템을 구현함으로써 장래 교통량 추정, 도로 계획 및 관리에 필요한 자료 수집에 유용하게 활용할 뿐만 아니라 효율적인 실시간 교통량 파악 및 시스템 비용 절감을 기대할 수 있다.","This paper designs a system that monitors traffic conditions and collects reliable traffic information using real-time object recognition of YOLOv5. The designed system uses only one camera and one AI board, making it easy to install on the move, and does not require professionals to install measuring equipment, solving the economic drawbacks of the existing traffic information collection system. Since YOLov5 is used for object recognition, it exhibits higher performance in speed and accuracy than CNN techniques that process images while moving filters sequentially. Therefore, reliable information collection will be possible, and the collected information is automatically stored in the server. By implementing this system, it is not only useful for estimating future traffic volume, collecting data necessary for road planning and management, but also expected to efficiently identify real-time traffic volume and reduce system costs."
Feasibility of a deep learning-based diagnostic platform to evaluate lower urinary tract disorders in men using simple uroflowmetry,2022,"['Artificial intelligence', 'Bladder outlet obstruction', 'Detrusor underactivity', 'Lower urinary tract symptoms']",,"Purpose: To diagnose lower urinary tract symptoms (LUTS) in a noninvasive manner, we created a prediction model for bladder outlet obstruction (BOO) and detrusor underactivity (DUA) using simple uroflowmetry. In this study, we used deep learning to analyze simple uroflowmetry.Materials and Methods: We performed a retrospective review of 4,835 male patients aged ≥40 years who underwent a urodynamic study at a single center. We excluded patients with a disease or a history of surgery that could affect LUTS. A total of 1,792 patients were included in the study. We extracted a simple uroflowmetry graph automatically using the ABBYY Flexicapture® image capture program (ABBYY, Moscow, Russia). We applied a convolutional neural network (CNN), a deep learning method to predict DUA and BOO. A 5-fold cross-validation average value of the area under the receiver operating characteristic (AUROC) curve was chosen as an evaluation metric. When it comes to binary classification, this metric provides a richer measure of classification performance. Additionally, we provided the corresponding average precision-recall (PR) curves.Results: Among the 1,792 patients, 482 (26.90%) had BOO, and 893 (49.83%) had DUA. The average AUROC scores of DUA and BOO, which were measured using 5-fold cross-validation, were 73.30% (mean average precision [mAP]=0.70) and 72.23% (mAP=0.45), respectively.Conclusions: Our study suggests that it is possible to differentiate DUA from non-DUA and BOO from non-BOO using a simple uroflowmetry graph with a fine-tuned VGG16, which is a well-known CNN model."
MBConv 블록 기반 Ni-Ti 합금의 표면연마 이미지 분류모델,2022,"['모바일 반전 합성곱 신경망', '과도 구조 해석', '표면가공성', 'Mobile Inverted Bottelnet Convolution', 'Transient Structural Analysis', 'Surface Finishing Characteristic']","본 연구에서는 Ni-Ti 합금 표면 품질 향상을 위하여 자기장을 이용한 자기 수송체 회전연마 공정을 제시하고자 한다. 연마공정에 영향을 미치는 회전속도와 연마입자 직경에 따른 Ni-Ti 합금의 표면가공성을 평가하기 위하여 과도구조해석 시뮬레이션을 통해 각 조건별 연마입자의 표면 접촉시간 분포도를 이미지화하였다. 이미지 결과를 바탕으로 표면가공 성능을 예측하기 위하여 compound scaling method가 적용된 MBConv 블록 기반 합성곱 신경망 알고리즘을 적용하였다. 제안된 예측모델을 바탕으로 성능을 평가한 결과, 사전에 학습되지 않은 공정조건에 대한 test 데이터에서도 94%의 높은 정확도를 나타냄으로써 본 연구에서 제안한 MBConv 블록을 활용한 예측모델이 효과적임을 확인할 수 있었다.","This study suggested a magnetic transporter rotational finishing process to improve the surface integrity of Ni-Ti alloys. To predict the effect of surface finishing characteristics, contact time distribution of abrasives on the workpiece surface under the different process parameters, which included abrasive diameter and rotational speed, was examined by a simulation. Based on the simulated images, the surface finishing characteristics were scored based on contact time, contact distribution, and impulse. In addition, image classification was performed using a convolutional neural network (CNN) based on the MBConv block. Consequently, the CNN model with the MBConv block achieved excellent performance for classification accuracy with 98%, 94%, and 94% of train, validation, and test datasets, respectively."
Prediction of the composition of urinary stones using deep learning,2022,"['Artificial intelligence', 'Deep learning', 'Endoscopy', 'Machine learning', 'Urolithiasis']",,"Purpose: This study aimed to predict the composition of urolithiasis using deep learning from urinary stone images.Materials and Methods: We classified 1,332 stones into 31 classes according to the stone composition. The top 4 classes with a frequency of 110 or more (class 1: calcium oxalate monohydrate [COM] 100%, class 2: COM 80%+struvite 20%, class 3: COM 60%+calcium oxalate dihydrate [COD] 40%, class 4: uric acid 100%) were selected. With the 965 stone images of the top 4 classes, we used the seven convolutional neural networks (CNN) to classify urinary stones and compared their classification performances.Results: Among the seven models, Xception_Ir0.001 showed the highest accuracy, precision, and recall and was selected as the CNN model to predict the stone composition. The sensitivity and specificity for the 4 classes by Xception_Ir0.001 were as follows: class 1 (94.24%, 91.73%), class 2 (85.42%, 96.14%), class 3 (86.86%, 99.59%), and class 4 (94.96%, 98.82%). The sensitivity and specificity of the individual components of the stones were as follows. COM (98.82%, 94.96%), COD (86.86%, 99.64%), struvite (85.42%, 95.59%), and uric acid (94.96%, 98.82%). The area under the curves for class 1, 2, 3, and 4 were 0.98, 0.97, 1.00, and 1.00, respectively.Conclusions: This study showed the feasibility of deep learning for the diagnostic ability to assess urinary stone composition from images. It can be an alternative tool for conventional stone analysis and provide decision support to urologists, improving the effectiveness of diagnosis and treatment."
전력 사용량 데이터 패턴 분석을 위한 시계열 이미지 생성 방안 연구,2022,"['시계열 데이터', '시계열 이미지', '패턴 분석', '데이터 분류', '콘볼루션 신경망', 'Time Series Data', 'Time Series Image', 'Analyzing Patterns', 'Classification', 'Convolutional Neural Networks']",,"To analyze the pattern of time series data, statistical techniques such as Principal Component Analysis (PCA) or autoencoder are used, or features of time series data are utilized based on deep learning models such as Recurrent Neural Network (RNN). However, it is difficult to expect good performance only with simple statistical techniques or RNN-based deep learning models because the environment and causes in which the data is recorded are not simple and various variables affect it. In this paper, we propose a method to image time series data to classify power data using Convolutional Neural Network (CNN)-based deep learning models, which are binary classification models of representative images. To train the model of proposed method, a total 85 images were used by generating images of power usage data for each building every day, and they were binary classified as weekday or weekend data. Recurrence Plot (RP), Gramian Angular Field (GAF), and Markov Transition Field (MTF) algorithms were used as methods for imaging. All time series image-based models showed equal or higher accuracy than conventional LSTM-based models, and among imaging-based CNN models, imaging methods with MTF algorithms derived the highest F1-Score (0.96)."
딥러닝 기반의 가금류 객체 탐지 알고리즘,2022,"['스마트팜', '딥러닝', '객체 검출', '영상 분석', '욜로', 'Smart Farm', 'Deep Learning', 'Object Detection', 'Image Analysis', 'YOLO']","가금의 평균 체중을 구하기 위해서는 닭이 저울 위로 올라가면 측정된 무게 값 데이터를 쌓아 원시 데이터로 닭의 성장 그래프를 그려 이를 예측한다. 하지만 저울에 닭이 여러 마리가 올라가 무게에 편차가 발생하여 평균 체중 예측에 혼란을 준다. 저울의 고도화와 성능검증, 가금의 평균 체중 예측값을 더 정확하게 교정하기 위해 가금의 개체 수 측정하는 것을 목적으로 객체 인식 모델을 비교하는 실험을 진행한다. 연구 결과 Modified YOLOv5가 98.8%, YOLOv5가 98.5%, YOLOv4가 96%, Mask R-CNN가 90%의 정확도를 보였다. 속도는 Modified YOLOv5가 33분 32초, YOLOv5가 25분 40초, YOLOv4가 66분 67초, Mask-RCNN가 172분 8초가 걸렸다. YOLOv5가 가장 빠른 검출 속력을 보였지만 Modified YOLOv5가 가장 높은 정확도를 보여 닭 개체에 가장 정확한 객체 검출 모델임을 알 수 있었다. 향후 객체 인식 모델을 보완하여 좀 더 정밀한 가금의 개체 수를 측정하고 결과 오차에 대해서 개선할 계획이다.","In order to obtain the average weight of a poultry, when the chicken goes up on the scale, it accumulates the measured weight value data and draws a growth graph of the chicken with raw data to predict it. However, several chickens rise on the scale, causing variations in weight, which confuses average weight prediction. Experiments are conducted to compare object recognition models with the aim of measuring the number of individuals to accurately correct the scale's advancement and performance verification, and the average weight prediction. As a result of the study, Modified YOLOv5 98.8%, YOLOv5 98.5%, YOLOv4 96%, and Mask R-CNN showed 90%. The speed took 33m 32s Modified YOLOv5, 25m 40s YOLOv5, 66m 67s YOLOv4, and 172m 8s for Mask-RCNN. Although YOLOv5 showed the fastest detection speed, Modified YOLOv5 showed the highest accuracy, indicating that it was the most accurate object detection model for chicken objects. In the future, we plan to supplement the object recognition model to measure the population of more precise poultry and improve it against the result error."
훈련 및 검증 성능 개선을 위한 텐서플로우 병렬 처리 기법,2022,"['멀티 쓰레드', '딥 러닝', '텐서플로우', 'GPU 및 CPU 사용률', 'Multi-threads', 'deep learning', 'TensorFlow', 'GPU and CPU utilization']","대부분의 딥 러닝(Deep Learning) 시스템은 모델의 훈련 및 검증을 위해 많은 시간을 소모한다. 그러나, 단일 쓰레드(Single Thread) 기반의 데이터 전처리 및 배치 과정으로 인해 대기 시간(Wait Time)이 발생하고 그 결과GPU 및 CPU의 사용률을 낭비하는 경향이 있다. 본 논문에서는 멀티 쓰레드(Multi Thread) 기반으로 모델의 훈련 및 검증 과정을 효율적으로 수행하기 위한 새로운 기법을 제안한다. 제안 기법은 모델 복사 과정을 사용함으로써 훈련과 검증 과정을 최대한 중첩(Overlapping)시키며, 그 결과 전반적인 CPU와 GPU의 사용률을 향상시킨다. 제안 기법을 평가하기 위해 우리는 텐서플로우(TensorFlow)을 이용하여 합성곱 신경망(CNN)을 구현하였다. 실험 결과, 제안 기법이 기존 기법 대비 전체 훈련 및 검증 시간을 22.4% 단축시키는 것을 확인할 수 있었다.","Most deep learning systems spend a lot of time on model training and validation.However, they sometimes tend to waste GPU and CPU resources because the pre-processing and batch processes based on a single thread result in a wait time. In this paper, we propose a new scheme that efficiently handles training and validation processes based on multi-threads. The proposed scheme can overlap the training and validation processes as much as possible by using a model copy operation that extends the processes with multi-threads. As a result, it improves the overall utilization of CPU and GPU. For evaluation, we implemented a convolutional neural network (CNN) using the TensorFlow framework. As a result, we clearly confirm that the proposed scheme saves the total training and validation time by up to 22.4% compared with the traditional schemes."
AIoT 기반 고위험 산업안전관리시스템 인공지능 연구,2022,"['인공지능 사물인터넷', '복합 센서 디바이스', '블루투스 메쉬 네트워크', '경량 딥러닝', 'AIoT', 'Complex sensor device', 'BLE Mesh Network', 'Lightweight Deep Learning']","정부는 2021년 1월에 '중대재해처벌법'을 제정 공포하여, 이 법을 시행하고 있다. 하지만, 2021년 산업재해 사고자수가 전년 동기 대비 10.7% 증가하였다. 따라서, 산업 현장에서는 안전대책이 시급한 현실이다. 본 연구에서는 통신 환경이 열악한 고위험 산업현장의 안전관리를 위하여 BLE Mesh 네트워킹 기술을 적용한다. 복합 센서 AIoT 디바이스로 가스 센싱값, 음성, 모션값을 실시간으로 수집하여, 인공지능 LSTM 알고리즘과 CNN 알고리즘을 통해 정보값을 분석하여 위험 상황을 인식하고, 서버에 전송한다. 서버에서는 전송 받은 위험정보를 실시간으로 모니터링 하여 즉각적인 구호조치가 수행되도록 한다. 본 연구에서 제안하는 AIoT 디바이스와 안전관리 시스템을 고위험군 산업현장에 적용하므로써, 산업재해를 최소화하고 사회안전망 확대에도 기여할 것이다.","The government enacted and promulgated the 'Severe Accident Punishment Act' in January 2021 and is implementing this law. However, the number of occupational accidents in 2021 increased by 10.7% compared to the same period of the previous year. Therefore, safety measures are urgently needed in the industrial field. In this study, BLE Mesh networking technology is applied for safety management of high-risk industrial sites with poor communication environment. The complex sensor AIoT device collects gas sensing values, voice and motion values ​​in real time, analyzes the information values ​​through artificial intelligence LSTM algorithm and CNN algorithm, and recognizes dangerous situations and transmits them to the server. The server monitors the transmitted risk information in real time so that immediate relief measures are taken. By applying the AIoT device and safety management system proposed in this study to high-risk industrial sites, it will minimize industrial accidents and contribute to the expansion of the social safety net."
환경 소음 제거를 통한 범용적인 드론 음향 탐지 구현,2022,"['Acoustic Drone Detection', 'Noise Cancellation', 'Noise Reduction', 'Mel Spectrogram', 'Convolutional Neural Network']","다양한 장소에서 드론이 활발하게 이용되면서 비행금지구역 내 불법 침입, 정보 유출, 항공기 충돌 등의 위험이 증가하고 있다. 이러한 위험을 줄이기 위해 비행금지구역으로 침입하는 드론을 탐지할 수 있는 시스템 구축이 필요하다. 기존의 드론 음향 탐지 연구는 탐지 모델에 환경 소음에 노출된 드론 음향을 그대로 학습시켰기 때문에 환경 소음에 독립적인 성능을 얻지 못했다. 이에 본 논문에서는 다양한 공간에서 환경 소음에 노출된 드론 음향을 명확하게 탐지하기 위해 주변 환경 소음을 별도로 수집하고, 드론 음향 신호에서 환경 소음을 제거하여 시끄러운 환경 속에서도 견고한 성능을 나타내는 범용적인 드론 탐지 시스템을 제안한다. 제안하는 시스템은 수집한 드론 음향 신호에서 환경 소음을 제거한 후 Mel Spectrogram 특성추출과 CNN 딥러닝을 이용하여 드론 존재 여부를 예측하였다. 실험 결과, 환경 소음으로 인해 감소했던 드론 탐지 성능을 7% 이상 향상시킴을 확인하였다.","As individual and group users actively use drones, the risks (Intrusion, Information leakage, and Sircraft crashes and so on) in no-fly zones are also increasing. Therefore, it is necessary to build a system that can detect drones intruding into the no-fly zone. General acoustic drone detection researches do not derive location-independent performance by directly learning drone sound including environmental noise in a deep learning model to overcome environmental noise. In this paper, we propose a drone detection system that collects sounds including environmental noise, and detects drones by removing noise from target sound. After removing environmental noise from the collected sound, the proposed system predicts the drone sound using Mel spectrogram and CNN deep learning. As a result, It is confirmed that the drone detection performance, which was weak due to unstudied environmental noises, can be improved by more than 7%."
Sex determination from lateral cephalometric radiographs using an automated deep learning convolutional neural network,2022,"['Sex Determination Analysis', 'Deep Learning', 'Radiography', 'Cephalometry', 'Cervical Vertebrae']",,"Purpose: Despite the proliferation of numerous morphometric and anthropometric methods for sex identification based on linear, angular, and regional measurements of various parts of the body, these methods are subject to error due to the observer’s knowledge and expertise. This study aimed to explore the possibility of automated sex determination using convolutional neural networks(CNNs) based on lateral cephalometric radiographs.Materials and Methods: Lateral cephalometric radiographs of 1,476 Iranian subjects (794 women and 682 men) from 18 to 49 years of age were included. Lateral cephalometric radiographs were considered as a network input and output layer including 2 classes(male and female). Eighty percent of the data was used as a training set and the rest as a test set. Hyperparameter tuning of each network was done after preprocessing and data augmentation steps.The predictive performance of different architectures (DenseNet, ResNet, and VGG) was evaluated based on their accuracy in test sets.Results: The CNN based on the DenseNet121 architecture, with an overall accuracy of 90%, had the best predictive power in sex determination. The prediction accuracy of this model was almost equal for men and women.Furthermore, with all architectures, the use of transfer learning improved predictive performance.Conclusion: The results confirmed that a CNN could predict a person’s sex with high accuracy. This prediction was independent of human bias because feature extraction was done automatically. However, for more accurate sex determination on a wider scale, further studies with larger sample sizes are desirable."
진동 분석 및 합성곱 신경망 기반 기계 고장 진단,2022,"['고장진단', '음질인자', '진동신호', '합성곱 신경망', 'Fault Diagnosis', 'Sound Quality Parameter', 'Vibration Signal', 'Convolutional Neural Network']","진동신호에 음질인자를 적용하여 사람의 청감 특성과 연관된 직관적인 고장 진단 방법론을 제안한다. 기계의 고장으로부터 비정상적인 소음이 발생하며, 이러한 소음을 이용하여 작업자들은 기계의 이상 상태를 탐지한다. 음향 특성은 기계의 다양한 고장 상태에 따라 상이하지만, 작업자의 청감 특성에만 의존하여 여러 고장 상태의 진단에는 한계가 있다. 음질인자는 사람의 청감 특성을 물리량으로 나타낸 지표이다. 하지만, 음향신호는 외부에서 발생하는 다양한 외부 소음에 취약하다. 진동신호는 외부 소음에 매우 강건한 특성을 지니고 있으며 음향신호와 진동신호는 매우 큰 상관성을 가진다. 따라서 전자레인지의 정상 상태 및 여러 고장 상태들에 대한 진동신호를 laser Doppler vibrometer (LDV)로 측정하였다. 진동신호에 음질인자가 적용되었으며, 각 기계의 상태에 대한 음질인자의 특성들이 분석되었다. 합성곱 신경망(convolutional neural network, CNN)은 패턴 인식을 위해 음질인자에서 중요한 특징을 추출하였다. 분류된 특징들은 각 기계의 상태들 간에 경계를 뚜렷하게 하였다. 제안한 방법의 분류 성능은 다른 분류 모델들과의 비교를 통해 검증되었다.","We developed an intuitive fault diagnosis method related to human auditory characteristics by applying sound quality parameters to the vibration signal. Abnormal noise was generated from a fault in a machine, and the operator used this noise to detect the abnormal condition. Although these acoustic characteristics differ with the fault conditions, diagnosing various fault conditions is limited by the auditory characteristics of the operator. The sound quality parameters represent the human auditory characteristics as physical quantities. However, the sound signal is vulnerable to various external noises generated in the environment. The vibration signal is robust to various external noises generated in the process, and the sound signal and vibration signal have a high correlation. Therefore, the vibration signals of the normal condition and various fault conditions were measured using a laser Doppler vibrometer (LDV). The sound quality parameters were applied to the vibration signal, and the characteristics of the sound quality parameters for each machine condition were analyzed. A convolutional neural network (CNN) was used to extract important features from the sound quality parameters for pattern recognition. The classified features facilitated a clear demarcation between the conditions of the machine. The classification performance of the proposed method was verified through comparison with other classification models."
딥러닝 기법을 사용하는 소프트웨어 결함 예측 모델,2022,"['Fault prediction', 'Deep learning', 'Machine learning']","수십년간 매우 많은 소프트웨어 결함 예측 모델에 관한 연구들이 수행되었으며, 그들 중 기계학습 기법을 사용한모델들이 가장 좋은 성능을 보였다. 딥러닝 기법은 기계학습 분야에서 가장 각광받는 기술이 되었지만 결함 예측 모델의분류기로 사용된 연구는 거의 없었다. 몇몇 연구들은 모델의 입력 소스나 구문 데이터로부터 시맨틱 정보를 얻어내는데딥러닝을 사용하였다. 본 논문은 3개 이상의 은닉층을 갖는 MLP를 이용하여 모델 구조와 하이퍼 파라미터를 변경하여여러 모델들을 제작하였다. 모델 평가 실험 결과 MLP 기반 딥러닝 모델들은 기존 결함 예측 모델들과 Accuracy는 비슷한 성능을 보였으나 AUC는 유의미하게 더 우수한 성능을 보였다. 또한 또다른 딥러닝 모델인 CNN 모델보다도 더 나은성능을 보였다.","Many studies have been conducted on software fault prediction models for decades, and the models using machine learning techniques showed the best performance. Deep learning techniques have become the most popular in the field of machine learning, but few studies have used them as classifiers for fault prediction models. Some studies have used deep learning to obtain semantic information from the model input source code or syntactic data. In this paper, we produced several models by changing the model structure and hyperparameters using MLP with three or more hidden layers. As a result of the model evaluation experiment, the MLP-based deep learning models showed similar performance to the existing models in terms of Accuracy, but significantly better in AUC. It also outperformed another deep learning model, the CNN model."
Sex determination from lateral cephalometric radiographs using an automated deep learning convolutional neural network,2022,"['Sex Determination Analysis', 'Deep Learning', 'Radiography', 'Cephalometry', 'Cervical Vertebrae']",,"Purpose: Despite the proliferation of numerous morphometric and anthropometric methods for sex identification based on linear, angular, and regional measurements of various parts of the body, these methods are subject to error due to the observer's knowledge and expertise. This study aimed to explore the possibility of automated sex determination using convolutional neural networks(CNNs) based on lateral cephalometric radiographs. Materials and Methods: Lateral cephalometric radiographs of 1,476 Iranian subjects (794 women and 682 men) from 18 to 49 years of age were included. Lateral cephalometric radiographs were considered as a network input and output layer including 2 classes(male and female). Eighty percent of the data was used as a training set and the rest as a test set. Hyperparameter tuning of each network was done after preprocessing and data augmentation steps. The predictive performance of different architectures (DenseNet, ResNet, and VGG) was evaluated based on their accuracy in test sets. Results: The CNN based on the DenseNet121 architecture, with an overall accuracy of 90%, had the best predictive power in sex determination. The prediction accuracy of this model was almost equal for men and women. Furthermore, with all architectures, the use of transfer learning improved predictive performance. Conclusion: The results confirmed that a CNN could predict a person's sex with high accuracy. This prediction was independent of human bias because feature extraction was done automatically. However, for more accurate sex determination on a wider scale, further studies with larger sample sizes are desirable."
인공신경망을 활용한 다회용기 보증금 반환 시스템,2022,"['Reusable Container Return System', 'Artificial Neural Network', 'Amazon Web Server', 'HOG Features', 'Multi Layer Perceptron', 'Fusion Network', 'Convolution Neural Network']","다회용기 보증금 반환 시스템은 소비자가 RVM(Reverse Vending Machine)에 다회용기의 QR코드를 스캔하고, 다회용기를 반납하면 보증금을 지급하는 절차로 동작한다. 이 시스템이 올바르게 동작하기 위해서는 반납된 용기에맞는 보증금을 지급하고, 소비자가 등록되지 않은 용기 또는 이물질 등을 넣어 비정상적인 보증금을 받는 사례를 방지해야 한다. 이를 위해 반납된 용기를 정확하게 인식하고, QR코드 정보와 일치하는지 판단하는 검증 과정이 필요하다. 본논문에서는 용기 인식 및 검증을 포함한 다회용기 보증금 반환 시스템의 동작을 자동화하는 방법을 제안한다. 제안하는방법은 비디오 모니터링 환경에서 이진 분류 모델을 사용하여 RVM 내 물체 유무를 판별한다. 이 과정을 실시간으로동작시키기 위해 가벼운 MLP 모델을 활용한다. “물체 있음”으로 판별된 프레임 중 용기 분류에 적합한 이미지를 선정하고, AWS(Amazon Web Server)로 전송한다. AWS로 전송된 이미지는 CNN(Convolution Neural Network) 모델을활용하여 사전에 정의한 클래스 중에서 하나로 분류한다. 목업 장치를 활용한 실험 결과를 통해 제안하는 전체 시스템이98% 이상의 정확도를 보이고, 다회용기 보증금 반환 시스템이 자동화될 수 있음을 보였다.","A Reusable Container Return System (RCRS) operates by refunding deposits when customers scan the QR code and return their used containers to a Reverse Vending Machine (RVM). In these systems, accurate recognition of the returned containers and the verification as to whether it matches the QR code information are essential to refund the deposits according to the container types and prevent the abuse of systems (e.g., putting damaged or non-register items). This paper proposes a new method that fully automates this returning process, including recognition and verification of the containers. First, the proposed method classifies empty/non-empty in the RVM from the input video streams using a binary classification model. This classification is based on a lightweight MLP model and works in real time. Among the ""non-empty""-classified frames, a frame suitable for classification (e.g., frames without motions) is selected. The selected image is sent to Amazon Web Service (AWS) and classified as one of the predefined classes using the CNN model. The experimental results using mock-up platforms showed that the proposed system works at 98% accuracy and demonstrates the possibility of a fully-automated RCRS."
A Comparison of Meta-learning and Transfer-learning for Few-shot Jamming Signal Classification,2022,"['jamming', 'meta-learning', 'transfer learning', 'classification']",,"Typical anti-jamming technologies based on array antennas, Space Time Adaptive Process (STAP) & Space Frequency Adaptive Process (SFAP), are very effective algorithms to perform nulling and beamforming. However, it does not perform equally well for all types of jamming signals. If the anti-jamming algorithm is not optimized for each signal type, antijamming performance deteriorates and the operation stability of the system become worse by unnecessary computation. Therefore, jamming classification technique is required to obtain optimal anti-jamming performance. Machine learning, which has recently been in the spotlight, can be considered to classify jamming signal. In general, performing supervised learning for classification requires a huge amount of data and new learning for unfamiliar signal. In the case of jamming signal classification, it is difficult to obtain large amount of data because outdoor jamming signal reception environment is difficult to configure and the signal type of attacker is unknown. Therefore, this paper proposes few-shot jamming signal classification technique using meta-learning and transfer-learning to train the model using a small amount of data. A training dataset is constructed by anti-jamming algorithm input data within the GNSS receiver when jamming signals are applied. For metalearning, Model-Agnostic Meta-Learning (MAML) algorithm with a general Convolution Neural Networks (CNN) model is used, and the same CNN model is used for transfer-learning. They are trained through episodic training using training datasets on developed our Python-based simulator. The results show both algorithms can be trained with less data and immediately respond to new signal types. Also, the performances of two algorithms are compared to determine which algorithm is more suitable for classifying jamming signals."
태양객체 정보 및 태양광 특성을 이용하여 사용자 위치의 자외선 지수를 산출하는 DNN 모델,2022,"['UVI', 'Image', 'Solar object characteristics', 'User location', 'Sunlight characteristics', 'DNN', '자외선 지수', '이미지', '태양 객체특성', '사용자 위치', '태양광 특성', '딥러닝']","자외선은 노출 정도에 따라 인체에 유익 또는 유해한 영향을 미치므로 개인별 적정 노출을 위해서는 정확한 자외선(UV) 정보가필요하다. 국내의 경우 기상청에서 생활기상정보의 한 요소로 자외선 정보를 제공하고 있으나 지역별 자외선 지수(UVI, Ultraviolet Index)로 사용자 위치의 정확한 UVI를 제공하지는 못하고 있다. 일부에서는 정확한 UVI의 취득을 위해 직접 계측기를 운용하지만 비용이나 편의성에 문제가 있고, 태양의 복사량과 운량 등 주변 환경요소를 통해 자외선 양을 추정하는 연구도 소개되었으나 개인별서비스 방법을 제시하지는 못하였다. 이에 본 논문에서는 각 개인별 위치에서의 정확한 UVI 제공을 위한 태양객체 정보와 태양광특성을 이용한 UVI 산출 딥러닝 모델을 제안한다. 기 수집한 하늘이미지 및 태양광 특성을 분석하여 태양의 위치 및 크기, 조도 등UVI와 상관도가 높은 요소들을 선정한 후 DNN 모델을 위한 데이터 셋을 구성한다. 이후 하늘이미지로부터 Mask R-CNN을 통해 추출한 태양객체 정보와 태양광 특성을 입력하여 UVI를 산출하는 DNN 모델을 구현한다. 국내 UVI 권고기준을 고려, UVI 8이상과 미만인날에 대한 성능평가에서는 기준장비 대비 MAE 0.26의 범위 내 정확한 UVI의 산출이 가능하였다.","UV rays have beneficial or harmful effects on the human body depending on the degree of exposure. An accurate UV information is required for proper exposure to UV rays per individual. The UV rays’ information is provided by the Korea Meteorological Administration as one component of daily weather information in Korea. However, it does not provide an accurate UVI at the user’s location based on the region’s Ultraviolet index. Some operate measuring instrument to obtain an accurate UVI, but it would be costly and inconvenient. Studies which assumed the UVI through environmental factors such as solar radiation and amount of cloud have been introduced, but those studies also could not provide service to individual. Therefore, this paper proposes a deep learning model to calculate UVI using solar object information and sunlight characteristics to provide an accurate UVI at individual location. After selecting the factors, which were considered as highly correlated with UVI such as location and size and illuminance of sun and which were obtained through the analysis of sky images and solar characteristics data, a data set for DNN model was constructed. A DNN model that calculates the UVI was finally realized by entering the solar object information and sunlight characteristics extracted through Mask R-CNN. In consideration of the domestic UVI recommendation standards, it was possible to accurately calculate UVI within the range of MAE 0.26 compared to the standard equipment in the performance evaluation for days with UVI above and below 8."
A Neural Network-Based Approach to Multiple Wheat Disease Recognition,2022,"['CNN', 'Multilabel classification', 'Wheat diseases', 'Computer vision']",,"In this paper, modern computer vision methods are proposed for detecting multiple diseases in wheat leaves. The authors demonstrate that modern neural network architectures are capable of qualitatively detecting and classifying diseases, such as yellow spots, yellow rust, and brown rust, even in cases in which multiple diseases are simultaneously present on the plant. For certain classes of diseases, the main multilabel metrics (accuracy, micro-/macro-precision, recall, and F1-score) range from 0.95 to 0.99. This indicates the possibility of recognizing several diseases on a leaf with an accuracy equal to that of an expert phytopathologist. The architecture of the neural network used in this case is lightweight, which makes it possible to use offline on mobile devices."
사용자 리뷰에서 표정 인식을 이용한 감정 표현 기법,2022,"['CNN(Convolutional Neural Network)', 'Facial Recognition', 'User Review']",,"Today, the online market has grown rapidly due to the development of digital platforms and the pandemic situation. Therefore, unlike the existing offline market, the distinctiveness of the online market has prompted users to check online reviews. It has been established that reviews play a significant part in influencing the user's purchase intention through precedents of several studies. However, the current review writing method makes it difficult for other users to understand the writer's emotions by expressing them through elements like tone and words. If the writer also wanted to emphasize something, it was very cumbersome to thicken the parts or change the colors to reflect their emotions. Therefore, in this paper, we propose a technique to check the user's emotions through facial expression recognition using a camera, to automatically set colors for each emotion using research on existing emotions and colors, and give colors based on the user's intention."
이종 객체 검출과 중복 라벨링 방식을 활용한 데이터 자동생성 및 객체 인식률 개선 연구,2022,"['CNN', 'deep learning', 'darknet', 'deepStream']",,"Currently, in special cases where data collection is limited, such as fire, fire data is collected directly or data is collected using a data augmentation method. And the collected data is being manually labeled. In order to improve this, this paper automatically labels fire data recognized through CCTV or video using heterogeneous object detection and fine-tuning methods, and then automatically proceeds to training. In addition, in order to improve the recognition rate, an integrated learning method with overlapping labeling and a selective application method of image data using the difference in object detection IOU were applied. As a result, automatic data generation increased by about 95% from 5,565 to 10,885, and the recognition rate was improved by about 12.4% from 64.9% to 77.3% based on mAP@0.5."
A Manually Captured and Modified Phone Screen Image Dataset for Widget Classification on CNNs,2022,"['Captured Image', 'CNN', 'Deep Learning Dataset', 'Image Classification', 'Object Detection', 'Widget']",,"The applications and user interfaces (UIs) of smart mobile devices are constantly diversifying. For example,deep learning can be an innovative solution to classify widgets in screen images for increasing convenience.To this end, the present research leverages captured images and the ReDraw dataset to write deep learningdatasets for image classification purposes. First, as the validation for datasets using ResNet50 and EfficientNet,the experiments show that the dataset composed in this study is helpful for classification according to a widget'sfunctionality. An implementation for widget detection and classification on RetinaNet and EfficientNet is thenexecuted. Finally, the research suggests the Widg-C and Widg-D datasets—a deep learning dataset for identifyingthe widgets of smart devices—and implementing them for use with representative convolutional neuralnetwork models."
ArcFace를 사용한 경량 신원인식 네트워크,2022,"['ArcFace', 'lightweight CNN', 'identity recognition', 'edge AI']",,"In this paper, we propose a lightweight identity recognition network combining ArcFace, a loss function with robust characteristics in the field of face recognition, and ResNet-18. In this paper, ResNet-18 is modified to a single-channel-based network to reduce the computational amount of the ResNet-18 network. And to compensate for the network performance degradation due to the decrease in the number of channels, ArcFace, which uses an angle margin-based loss function, was combined with a single-channel-based ResNet-18 network to compensate for the network performance degradation. The proposed network performed training and inference with 10,056 experimental data sets consisting of face photos of 33 people. As a result of the experiment, it was confirmed that the proposed ArcFace-based lightweight ResNet-18 improved processing speed by about 1.3 times compared to the existing ResNet-18. In addition, an inference accuracy of 96.9%, similar to that of the existing network ResNet-18, which is 97.6%, was derived."
실시간 말벌 탐지를 위한 향상된 타일링 기법,2022,"['Object detection', 'CNN', 'Vespa monitoring system', 'YOLOX', 'Tiling']",,"In order to effectively control wasps, which are the main cause of damage in beekeeping, a monitoring system that can check the appearance of wasps in real time is necessary.Convolutional Neural Networks (CNNs), currently widely used in the field of object recognition, cannot successfully detect and classify small objects such as wasps. When a wasp is photographed at a distance of 40 cm with a 4K-camera, the size of the wasp is only 2~3% of the total image. Therefore, in order to increase the recognition accuracy of small objects, we use a tiling method to detect wasps by dividing the image into 3×3. In the traditional tiling methods do not recognize objects located on the divided boundary well. In order to improve the object recognition performance of the tiling method, we propose an improved tiling method that additionally detect a partial area centered on the boundary line in the original image when there are some objects on the tile boundary line. We evaluated the performance of the proposed tiling method using the YOLOX model after producing 7,505 4K resolution images in which 5 species of wasps and 1 type of bee were randomly placed on a 3×3 tile boundary. In experiments on image data created for wasp object recognition training, the PASCAL VOC mAP of traditional tiling methods was 3.28%. However, the mAP of the proposed tiling method was 14.14%, which showed better performance of the proposed tiling technique in terms of accuracy."
Efficient 3D Printer Fault Classification Using a Multi-Block 2D-Convolutional Neural Network,2022,"['3D Printing', 'CNN(convolutional neural network)', 'Efficient model', 'Fault detection', 'Manufacturing']",,
Feature Extraction and Recognition of Myanmar Characters Based on Deep Learning,2022,"['Deep learning CNN', 'Feature Extraction and Recognition', 'Myanmar Characters', 'Orientation', 'Texture', 'Skeleton']",,"Recently, with the economic development of Southeast Asia, the use of information devices is widely spreading, and the demand for application services using intelligent character recognition is increasing. This paper discusses deep learning-based feature extraction and recognition of Myanmar, one of the Southeast Asian countries. Myanmar alphabet (33 letters) and Myanmar numerals (10 numbers) are used for feature extraction. In this paper, the number of nine features are extracted and more than three new features are proposed. Extracted features of each characters and numbers are expressed with successful results. In the recognition part, convolutional neural networks are used to assess its execution on character distinction. Its algorithm is implemented on captured image data-sets and its implementation is evaluated. The precision of models on the input data set is 96 % and uses a real-time input image."
내재 요소 및 재조명을 이용한 얼굴 그림자 제거,2022,"['Deep learning', 'CNN', 'Encoder-deocoder network', 'Shadow removal', 'Relighting']","인물 사진에서 발생한 그림자는 사진의 품질에 영향을 미친다. 그림자로 인해 얼굴의 구조나 색상에 왜곡이 발생하며 이는 얼굴 인식 및 탐지와 작업에서 성능 저하가 발생한다. 이를 해결하기 위해 그림자가 있는 단일 얼굴 영상에서 그림자를 제거하는 방법을 제안한다. 본 논문에서는 임의의 방향에서 조명을 비추는 상황에서 발생한 그림자를 제거하는 것을 목표로 한다. 이를 위해 원래의 조명 방향에서 다른 원하는 조명 방향으로 비추는 새로운 영상을 생성하는 재조명 방법에서 영감을 받아 정면에서 조명을 비추는 영상을 생성하여 그림자를 제거하고자 한다. 인코더-디코더 구조를 통해 비율 영상을 생성하여 그림자가 있는 입력 영상에 곱해주어 그림자 제거 영상을 생성한다. 얼굴의 기하학적 구조를 반영하기 위해 얼굴의 노말 맵을 추정하는 디코더를 추가했으며 노말 맵과 조명 방향으로 그림자 마스크를 추정하여 그림자 제거 영상을 생성하는 데 도움을 준다. 그림자가 제거된 영상은 조명으로 인해 밝았던 영역의 부자연스러움이 존재하기 때문에 이를 제거하기 위해 보정 네트워크의 특징 마스킹 메커니즘을 사용하여 보완하고자 한다. YaleB 데이터셋에서 기존 그림자 제거 연구에 비해 RMSE, PSNR, SSIM의 지표에서 각각 0.04, 2.88, 0.06의 성능 향상을 얻었다.",
비정상심박 검출을 위해 영상화된 심전도 신호를 이용한 비교학습 기반 딥러닝 알고리즘,2022,"['심전도', '딥러닝', 'CNN', '템플릿 군', '비정상심박 검출', 'Electrocardiogram', 'Deep learning', 'Convolutional neural network', 'Template cluster', 'Abnormal beat detection']","심전도 신호는 개인에 따라 형태와 특징이 다양하므로, 하나의 신경망으로는 분류하기가 어렵다. 주어진 데이터를 직접적으로 분류하는 것은 어려우나, 대응되는 정상 데이터가 있을 경우, 이를 비교하여 정상 및 비정상을 분류하는 것은 상대적으로 쉽고 정확하다. 본 논문에서는 템플릿 군을 이용하여 대표정상심박 정보를 획득하고, 이를 입력심박에 결합함으로써 심박을 분류한다. 결합된 심박을 영상화한 후, 학습 및 분류를 진행하여, 하나의 신경망으로도 다양한 레코드의 비정상심박을 검출이 가능하였다. 특히, GoogLeNet, ResNet, DarkNet 등 다양한 신경망에 대해서도 비교학습 기법을 적용한 결과, 모두 우수한 검출성능을 가졌으며, GoogLeNet의 경우 99.72%의 민감도로, 실험에 사용된 신경망 중 가장 우수한 성능을 가졌음을 확인하였다.","Electrocardiogram (ECG) signal's shape and characteristic varies through each individual, so it is difficult to classify with one neural network. It is difficult to classify the given data directly, but if corresponding normal beat is given, it is relatively easy and accurate to classify the beat by comparing two beats. In this study, we classify the ECG signal by generating the reference normal beat through the template cluster, and combining with the input ECG signal. It is possible to detect abnormal beats of various individual’s records with one neural network by learning and classifying with the imaged ECG beats which are combined with corresponding reference normal beat. Especially, various neural networks, such as GoogLeNet, ResNet, and DarkNet, showed excellent performance when using the comparative learning. Also, we can confirmed that GoogLeNet has 99.72% sensitivity, which is the highest performance of the three neural networks."
딥러닝 모델을 이용한 CT 데이터 위조 및 탐지에 관한 연구,2022,"['Cycle-GAN', 'CNN', 'CT data', 'forgery', 'Detection', 'Artificial intelligence', 'Medical data']",,"Currently, research on deep learning models is being actively conducted, and many studies are being conducted in various fields. In the medical field, research is also being conducted using various medical data such as medical images and electronic medical records. In particular, research is underway to solve research problems in the medical field due to lack of data by using image conversion technology. However, through highly developed AI models, forged images can cause many problems. If forged images are abused in the medical field, it is a big problem that can endanger patients' lives. In this paper, the Cycle-GAN forgery model is constructed using CT images to solve and prevent problems that may arise through forgery images generated through artificial intelligence models. After that, the quality evaluation of the forged image was conducted. In addition, forgery image detection was performed through a forgery detection model composed of a Concat block, and detection performance was quantified with a classification performance evaluation index. As a result of classification performance indicators, each indicator showed a high value of more than 99%. Through this, it can be seen that the CT image forgery detection model of this paper has excellent performance. In the future, research will be conducted using various medical data as well as CT images, and the detection of forged data will be conducted in various ways."
적대적 생성 신경망을 이용한 조직병리학 영상 초해상화,2022,"['Deep learning', 'CNN', 'Super-resolution', 'Histopathology', 'Medical image']","이미지 디지털화 기술이 발전을 이루면서 기존 현미경으로 진행하던 조직 검사는 슬라이드 스캐너를 통해 디지털 이미지로 촬영 및 저장된다. 슬라이드 스캐너는 수 기가 바이트의 고해상도 이미지로 촬영하기 때문에 조직병리학 영상 촬영에 긴 시간이 소요되며 또한 이를 저장하기 위한 많은 메모리 공간이 필요하다. 이를 해결하기 위해 낮은 해상도로 저장하고, 후에 복원하는 초해상화 기법을 조직병리학 영상에 적용한 연구들이 등장하였다. 본 논문에서는 Bicubic Interpolation으로 된 이미지 위에 적대적 생성 신경망을 이용해 만든 잔차 이미지를 더하는 방법으로 원본에 가까우면서도 시각적으로 자연스러운 초해상화 된 조직병리학 영상을 생성하였다. 실험 결과 4x 확대하였을 때, PSNR 29.24dB을 달성하였으며, 정성적으로도 원본에 가까운 이미지를 생성할 수 있음을 보여주었다.",
A Deep Learning Approach for Identifying User Interest from Targeted Advertising,2022,"['Convolutional Neural Network (CNN)', 'Deep Learning', 'Digital Forensics', 'User Interest', 'User Profiling']",,"In the Internet of Things (IoT) era, the types of devices used by one user are becoming more diverse and thenumber of devices is also increasing. However, a forensic investigator is restricted to exploit or collect all theuser’s devices; there are legal issues (e.g., privacy, jurisdiction) and technical issues (e.g., computing resources,the increase in storage capacity). Therefore, in the digital forensics field, it has been a challenge to acquireinformation that remains on the devices that could not be collected, by analyzing the seized devices. In thisstudy, we focus on the fact that multiple devices share data through account synchronization of the onlineplatform. We propose a novel way of identifying the user's interest through analyzing the remnants of targetedadvertising which is provided based on the visited websites or search terms of logged-in users. We introduce adetailed methodology to pick out the targeted advertising from cache data and infer the user’s interest usingdeep learning. In this process, an improved learning model considering the unique characteristics ofadvertisement is implemented. The experimental result demonstrates that the proposed method can effectivelyidentify the user interest even though only one device is examined."
헬멧 착용 여부 및 쓰러짐 사고 감지를 위한 AI 영상처리와 알람 시스템의 구현,2022,"['Convolutional Neural Network (CNN)', 'YOLO', 'Object detection', 'Deep learning', 'Industrial site', '합성곱 신경망', 'YOLO', '객체 검출', '딥러닝', '산업현장']","본 논문은 실시간 영상 분석을 통해서 산업현장에서 활동하는 여러 근로자의 영상 객체를 추출해 내고, 추출된 이미지로 부터 개별 영상 분석을 통해 헬멧의 착용 여부와 낙상 사고 여부를 확인하는 방법을 구현한다. 근로자의 영상 객체를 탐지하기 위해서 딥러닝 기반 컴퓨터 비전 모델인 YOLO를 사용하였으며, 추출된 이미지를 이용하여 헬멧의 착용여부를 판단하기 위해 따로 5,000장의 다양한 헬멧 학습 데이터 이미지를 만들어서 사용하였다. 또한, 낙상사고 여부를 판단하기 위해서 Mediapipe의 Pose 실시간 신체추적 알고리즘을 사용하여 머리의 위치를 확인하고 움직이는 속도를 계산하여 쓰러짐 여부를 판단하였다. 결과에 신뢰성을 주기위한 방법으로 YOLO의 바운딩 박스의 크기를 구하여 객체의 자세를 유추하는 방법을 추가하고 구현하였다. 최종적으로 관리자에게 알림 서비스를 위하여 텔레그램 API Bot과 Firebase DB 서버를 구현하였다.","This paper presents an implementation of detecting whether a helmet is worn and there is a fall accident through individual image analysis in real-time from extracting the image objects of several workers active in the industrial field. In order to detect image objects of workers, YOLO, a deep learning-based computer vision model, was used, and for whether a helmet is worn or not, the extracted images with 5,000 different helmet learning data images were applied. For whether a fall accident occurred, the position of the head was checked using the Pose real-time body tracking algorithm of Mediapipe, and the movement speed was calculated to determine whether the person fell. In addition, to give reliability to the result of a falling accident, a method to infer the posture of an object by obtaining the size of YOLO's bounding box was proposed and implemented. Finally, Telegram API Bot and Firebase DB server were implemented for notification service to administrators."
StarGAN v2 기반 패션 아이템 다중 도메인 변환을 통한 이미지 생성 모델 구현,2022,"['Object Detection', 'Mask R-CNN', 'Fashion Design Technique', 'GAN', 'StarGAN v2']","최근 다양한 GAN 모델이 개발되어 여러 분야에서 활용되고 있다. 본 논문에서는 패션 아이템에 대한 다중 세부 아이템 도메인 변환 시스템 구현을 위해 GAN 모델을 활용하고자 한다. 이를 위해 조건을 지정하여 원하는 도메인 스타일로 변환된 이미지를 생성할 수 있으며 객관적으로 검증된 StarGAN v2를 채택하여 실험 및 구현을 진행하였다. 데이터셋의 레이블링을 최소화하며 도메인에 따른 변환 결과를 정확히 도출할 수 있도록 세부 아이템별로 모델을 각각 생성하였다. 학습된 이미지 생성 모델을 활용하여 하나의 이미지에서 추출한 스타일을 다른 이미지에 합성하는 결과를 도출하였고, 모델들을 모두 활용하여 하나의 이미지에 대해 여러 도메인을 변환할 수 있도록 방안을 제시하였다. 각각의 도메인 변환 이미지 생성 모델에 대한 성능 평가를 위해 실제 이미지와 생성 이미지 사이의 유사도를 측정하고 평가 분석하였다.","Various GANs have been recently developed and are being used in wide application areas. In this paper, we intend to utilize the GAN model to implement a domain transformation system for multi-detailed item on fashion items. For the purpose, we experimented and implemented StarGAN v2, which is objectively verified model that can generate images converted to the desired domain style by specifying conditions. Models were created for each detailed item to minimize labeling of datasets and accurately derive transformation results according to domains. Using the pretrained image generation model, we derive a result of synthesizing styles extracted from one image into another image, and we present a plan to allow multiple domains to be transformed for one image by utilizing all of the models. Similarity between real and generated images is measured for performance evaluation of each domain transformed by image generation model."
Two-stream Convolutional Long- and Short-term Memory 모델의 2001-2021년 9월 북극 해빙 예측 성능 평가,2022,"['Arctic', 'Artificial intelligence', 'CNN', 'ConvLSTM', 'LSTM', 'Prediction', 'Sea ice']",,"Sea ice, frozen sea water, in the Artic is a primary indicator of global warming. Due to its importance to the climate system, shipping-route navigation, and fisheries, Arctic sea ice prediction has gained increased attention in various disciplines. Recent advances in artificial intelligence (AI), motivated by a desire to develop more autonomous and efficient future predictions, have led to the development of new sea ice prediction models as alternatives to conventional numerical and statistical prediction models. This study aims to evaluate the performance of the two-stream convolutional long-and short-term memory (TS-ConvLSTM) AI model, which is designed for learning both global and local characteristics of the Arctic sea ice changes, for the minimum September Arctic sea ice from 2001 to 2021, and to show the possibility for an operational prediction system. Although the TS-ConvLSTM model generally increased the prediction performance as training data increased, predictability for the marginal ice zone, 5-50% concentration, showed a negative trend due to increasing first-year sea ice and warming. Additionally, a comparison of sea ice extent predicted by the TS-ConvLSTM with the median Sea Ice Outlooks (SIOs) submitted to the Sea Ice Prediction Network has been carried out. Unlike the TS-ConvLSTM, the median SIOs did not show notable improvements as time passed (i.e., the amount of training data increased). Although the TS-ConvLSTM model has shown the potential for the operational sea ice prediction system, learning more spatio-temporal patterns in the difficult-to-predict natural environment for the robust prediction system should be considered in future work."
Categorization of actions in soccer videos using a combination of transfer learning and Gated Recurrent Unit,2022,"['Convolutional Neural Network (CNN)', 'Gated Recurrent Unit (GRU)', 'RecurrenT Neural Network (RNN)', 'Transfer learning']",,"Extraction of knowledge from soccer videos has enormous applications like context-based advertisement, content-based video retrieval, match summarization, and highlight extraction. Overlapping soccer actions and uncontrolled video capturing conditions make it challenging to detect action accurately. For overcoming these problems, Convolutional Neural Network and Recurrent Neural Network are used jointly to classify different lengths of soccer actions. Initially, transfer learning from pre-trained VGG network extracts characteristic spatial features. Afterwards, Gated Recurrent Unit deals with temporal dependency and solves the vanishing gradient problem. Finally, softmax layer assigns decimal probabilities to each class. Experimental results demystify the significance of the proposed architecture."
Hellinger 거리 IoU와 Objectron 적용을 기반으로 하는 객체 감지,2022,"['3D Object Recognition', 'CNN', 'Gaussian', 'Hellinger Distance', 'IoU', 'Objectron']","2D 객체 감지 시스템은 최근 몇 년 동안 심층 신경망과 대규모 이미지 데이터세트의 사용으로 크게 개선되었지만, 아직도 범주 내에서 데이터 부족, 다양한 외관 및 객체 형상 때문에 자율 탐색 등과 같은 로봇 공학과 관련된 응용에서 2D 물체 감지 시스템은 적절하지 않다. 최근에 소개되고 있는 구글 Objectron 또한 증강 현실 세션 데이터를 사용하는 새로운 데이터 파이프라인이라는 점에서 도약이라 할 수 있지만, 3D 공간에서 2D 객체 이해라는 측면에서 마찬가지로 한계가 있다. 이에 본 연구에서는 더 성숙한 2D 물체 감지 방법을 Objectron에 도입하는 3D 물체 감지 시스템을나타낸다. 대부분의 객체 감지 방법은 경계 상자를 사용하여 객체 모양과 위치를 인코딩한다. 본 작업에서는 가우스 분포를 사용하여 객체 영역의 확률적 표현을 탐색하는데, 일종의 확률적 IoU라 할 수 있는 Hellinger 거리를 기반으로 하는가우스 분포에 대한 유사성 측도를 제시한다. 이러한 2D 표현은 모든 객체 감지기에 원활하게 통합할 수 있으며, 실험결과 데이터 집합에서 주석이 달린 분할 영역에 더 가까워서 Objectron의 단점이라 할 수 있는 3D 감지 정확도를 높일수 있다.","Although 2D Object detection has been largely improved in the past years with the advance of deep learning methods and the use of large labeled image datasets, 3D object detection from 2D imagery is a challenging problem in a variety of applications such as robotics, due to the lack of data and diversity of appearances and shapes of objects within a category. Google has just announced the launch of Objectron that has a novel data pipeline using mobile augmented reality session data.However, it also is corresponding to 2D-driven 3D object detection technique. This study explores more mature 2D object detection method, and applies its 2D projection to Objectron 3D lifting system. Most object detection methods use bounding boxes to encode and represent the object shape and location.In this work, we explore a stochastic representation of object regions using Gaussian distributions. We also present a similarity measure for the Gaussian distributions based on the Hellinger Distance, which can be viewed as a stochastic Intersection-over-Union. Our experimental results show that the proposed Gaussian representations are closer to annotated segmentation masks in available datasets. Thus, less accuracy problem that is one of several limitations of Objectron can be relaxed."
웹 크롤링과 전이학습을 활용한 이미지 분류 모델,2022,"['Data preprocessing', 'web crawling', 'CNN', 'transfer learning', 'image classification']","딥러닝의 발전으로 딥러닝 모델들이 이미지 인식, 음성 인식 등 여러 분야에서 활발하게 사용 중이다. 하지만 이 딥러닝을 효과적으로 사용하기 위해서는 대형 데이터 세트가 필요하지만 이를 구축하기에는 많은 시간과 노력 그리고 비용이 필요하다. 본 논문에서는 웹 크롤링이라는 이미지 수집 방법을 통해서 이미지를 수집하고 데이터 전처리 과정을 거쳐 이미지 분류 모델에 사용할 수 있게데이터 세트를 구축한다. 더 나아가 전이학습을 이미지 분류 모델에 접목해 카테고리값을 넣어 자동으로 이미지를 분류할 수 있는경량화된 모델과 적은 훈련 시간 및 높은 정확도를 얻을 수 있는 이미지 분류 모델을 제안한다.","In this paper, to solve the large dataset problem, we collect images through an image collection method calledweb crawling and build datasets for use in image classification models through a data preprocessing process. Wealso propose a lightweight model that can automatically classify images by adding category values by incorporatingtransfer learning into the image classification model and an image classification model that reduces training timeand achieves high accuracy."
Skeleton 정보와 LSTM을 이용한 작업자 동작인식,2022,"['Pose Estimation', 'Pose Classification', 'Hourglass', 'LSTM', 'CNN', 'Group Normalization']",,
Bounding Box CutMix와 표준화 거리 기반의 IoU를 통한 재활용품 탐지,2022,"['Deep learning', 'Convolutional neural network (CNN)', 'Object detection', 'Recyclable object', 'Data augmentation', 'IoU']",,"In this paper, we developed a deep learning-based recyclable object detection model. The model is developed based on YOLOv5 that is a one-stage detector. The deep learning model detects and classifies the recyclable object into 7 categories: paper, carton, can, glass, pet, plastic, and vinyl. We propose two methods for recyclable object detection models to solve problems during training. Bounding Box CutMix solved the no-objects training images problem of Mosaic, a data augmentation used in YOLOv5. Standardized Distance-based IoU replaced DIoU using a normalization factor that is not affected by the center point distance of the bounding boxes. The recyclable object detection model showed a final mAP performance of 0.91978 with Bounding Box CutMix and 0.91149 with Standardized Distance-based IoU."
인공지능 기반 객체인식 기법에 관한 연구,2022,"['Artificial Intelligence', 'Object Recognition', 'YOLO', 'R-CNN']",최근 들어 차산업 4 연관기술인 사이버물리시스템(CPS) 구축을 위해 물리 모델과 제어회로 시뮬레이션을 위한 가상제어시스템 구축 작업이 다양한 산업 분야에서 요구가 점점 증가하고 있다. 전자 문서화 되지 않은 문서들에 대한 직접입력을 통한 변환은 시간과 비용이 많이 소모된다. 이를 위해 이미 출력된 대량의 도면을 인공지능을 이용한 객체 인식을 통해 디지털화 작업은 매우 중요하다고 할 수 있다. 본 논문에서는 도면내 객체를 정확하게 인식하고 이를 다양한응용에 활용할 수 있도록 하기 위하여 도면내 객체의 특징을 분석하여 인공지능을 활용한 인식 기법을 제안하였다. 객체 인식의 성능을 높이기 위하여 객체별 인식 후 그 정보를 저장하는 중간 파일을 생성하게 하였다. 그리고 인식 결과를 도면에서 삭제하여 다음 인식 대상의 인식률을 향상시켰다. 그리고 그 인식 결과를 표준화 포맷 문서로 저장하여 이를 제어시스템의 다양한 분야에 활용할 수 있도록 하였다. 본 논문에서 제안한 기법의 우수한 성능은 위해 실험을 통해확인할 수 있었다.,"Recently, in order to build a cyber physical system(CPS) that is a technology related to the 4th industry, the construction of the virtual control system for physical model and control circuit simulation is increasingly required in various industries. It takes a lot of time and money to convert documents that are not electronically documented through direct input. For this, it is very important to digitize a large number of drawings that have already been printed through object recognition using artificial intelligence. In this paper, in order to accurately recognize objects in drawings and to utilize them in various applications, a recognition technique using artificial intelligence by analyzing the characteristics of objects in drawing was proposed. In order to improve the performance of object recognition, each object was recognized and then an intermediate file storing the information was created. And the recognition rate of the next recognition target was improved by deleting the recognition result from the drawing. In addition, the recognition result was stored as a standardized format document so that it could be utilized in various fields of the control system. The excellent performance of the technique proposed in this paper was confirmed through the experiments."
A Study on the Optimal Artificial Intelligence Model for  Determination of Urolithiasis,2022,"['Urolithiasis', 'Ureter stones', 'ResNet-50', 'Fast R-CNN', 'Surgical support technology']",,"Purpose: This paper aims to develop a clinical decision support system (CDSS) that can help detect the stone that is most important to the diagnosis of urolithiasis. Among them, especially for the development of artificial intelligence (AI) models that support a final judgment in CDSS, we would like to study the optimal AI model by comparing and evaluating them.Methods: This paper proposes the optimal ureter stone detection model using various AI technologies. The use of AI technology compares and evaluates methods such as machine learning (support vector machine), deep learning (ResNet-50, Fast RCNN), and image processing (watershed) to find a more effective method for detecting ureter stones.Results: The final value of sensitivity, which is calculated using true positive (TP) and false negative and is a measure of the probability of TP results, showed high recognition accuracy, with an average value of 0.93 for ResNet-50. This finding confirmed that accurate guidance to the stones area was possible when the developed platform was used to support actual surgery.Conclusions: The general situation in the most effective way to the detection stone can be found. But a variety of variables may be slightly different the difference through the term could tell. Future works, on urological diseases, are diverse and the research will be expanded by customizing AI models specialized for those diseases."
무장 선택을 위한 딥러닝 기반의 비행체 식별 기법 연구,2022,"['Aerial vehicle', 'Air defense', 'Armament selection', 'CNN', 'Deep learning']",,"As air combat system technologies developed in recent years, the development of air defense systems is required. In the operating concept of the anti-aircraft defense system, selecting an appropriate armament for the target is one of the systems capabilities in efficiently responding to threats using limited anti-aircraft power. Much of the flying threat identification relies on the operators visual identification. However, there are many limitations in visually discriminating a flying object maneuvering high speed from a distance. In addition, as the demand for unmanned and intelligent weapon systems on the modern battlefield increases, it is essential to develop a technology that automatically identifies and classifies the aircraft instead of the operators visual identification. Although some examples of weapon system identification with deep learning-based models by collecting video data for tanks and warships have been presented, aerial vehicle identification is still lacking. Therefore, in this paper, we present a model for classifying fighters, helicopters, and drones using a convolutional neural network model and analyze the performance of the presented model."
전자전 환경에서 전이학습 기반 저피탐 레이더 변조 신호 분류 성능 분석,2022,"['LPI Radar', 'Intra-pulse Modulation', 'CNN', 'Transfer Learning', 'Deep learning']","최근 저피탐 레이더 기술의 발전에 따라 LPI 레이더 위협 신호의 정확한 탐지 및 변조 방식 분류 기술이 중요한 기술로 대두되고 있다. 특히 레이더 변조방식 분류에 관한 연구는 딥러닝 기반의 이미지 처리분야에서도 연구가 활발히 진행되고 있다. 하지만 이러한 딥러닝 기반 기술은 실제 무기체계에 적용하는데 있어 양질의 학습 데이터 확보에 어려움이 존재한다. 본 논문에서는 전자전의 신호 수집환경을 고려하여, 전이 학습을 이용하여 낮은 SNR 환경에서도 레이더 신호 분류 성능을 향상시키는 방법을 제안한다.제안한 전이 학습 기반의 분류 방법은 –12 dB 환경에서 90% 이상의 분류 성공률을 보임을 확인하였다.","As the development of low detection radar technology, accurate detection and modulation classification technology for LPI threat signals is emerging as an important technology. In particular, research on the classification of radar modulation methods has been actively conducted recently by applying deep learning-based image processing technology. However, these deep learning-based approaches have difficulties in securing high-quality learning data when applied to weapon systems. In this paper, we propose a method to improve radar signal classification performance even in a low SNR environment using transfer learning considering the signal reception environment of electronic warfare. It was confirmed that the proposed transfer learning-based classification method showed a classification success rate of over 90% at -12 dB."
Local Non-linear Quantization for Neural Network Compression in MPEG-NNR,2022,"['Neural network compression', 'NNR', 'NCTM', 'CNN', 'Non-linear quantization']",,"Deep Convolutional Neural Networks (CNNs) have demonstrated excellent performance in various visual applications, but their deployment, especially in resource-constrained environments, is limited due to their enormous computational complexity and memory requirements. Therefore, compression of network models while still maintaining the task performance of the trained model is being studied. Recently, the Moving Picture Experts Group (MPEG) developed a standard called Neural Network compression and Representation (NNR) that provides a compressed representation of trained neural networks in an interoperable form. In this paper, we propose a local non-linear quantization (LNQ) method for compressing weight parameters of neural network models. The experimental results show that the proposed LNQ achieves about a 29% gain in compression efficiency with virtually no loss of performance in the tasks, compared to the NNR test model, called the Neural network Compression Test Model (NCTM) version 3.0."
Practical Analysis for Improving Performance from One-stage Object Detectors,2022,"['Object detection', 'Deep learning']",,"Since the advent of the CNN, the performance of object detectors has been greatly improved. In addition, with the one-stage object detector, the detection algorithm has been lightened and improved to a level that can be applied to real-time applications. However, the research directions for one-stage object detectors focus on obtaining high performance on a benchmark dataset, and there is less consideration of how to improve performance with real-world data. In this paper, we check how methods popularly used to enhance performance from neural networks respond to datasets similar to real-world data. Also, we experimentally confirm that a training configuration setup that considers the target dataset can be more effective than complex training strategies like knowledge distillation. Although this analysis is somewhat heuristic, we expect it will provide meaningful insights for researchers and developers who want to apply an object detector to actual applications."
시계열 토지피복도 제작을 위한 준감독학습 기반의 훈련자료 자동 추출,2022,"['Land-cover classification', 'Convolutional neural network (CNN)', 'Semi-supervised learning', 'Training data']",,"This paper presents a novel training data extraction approach using semi-supervised learning (SSL)-based classification without the analyst intervention for time-series land-cover mapping. The SSL-based approach first performs initial classification using initial training data obtained from past images including land-cover characteristics similar to the image to be classified. Reliable training data from the initial classification result are then extracted from SSL-based iterative classification using classification uncertainty information and class labels of neighboring pixels as constraints. The potential of the SSL-based training data extraction approach was evaluated from a classification experiment using unmanned aerial vehicle images in croplands. The use of new training data automatically extracted by the proposed SSL approach could significantly alleviate the misclassification in the initial classification result. In particular, isolated pixels were substantially reduced by considering spatial contextual information from adjacent pixels. Consequently, the classification accuracy of the proposed approach was similar to that of classification using manually extracted training data. These results indicate that the SSL-based iterative classification presented in this study could be effectively applied to automatically extract reliable training data for time-series land-cover mapping."
Incremental Strategy-based Residual Regression Networks for Node Localization in Wireless Sensor Networks,2022,"['Wireless Sensor Networks (WSNs)', 'Convolutional Neural Networks (CNN)', 'Data Augmentation', 'Node Localization', 'Degree of intersection']",,"The easy scalability and low cost of range-free localization algorithms have led to their wide attention and application in node localization of wireless sensor networks. However, the existing range-free localization algorithms still have problems, such as large cumulative errors and poor localization performance. To solve these problems, an incremental strategy-based residual regression network is proposed for node localization in wireless sensor networks. The algorithm predicts the coordinates of the nodes to be solved by building a deep learning model and fine-tunes the prediction results by regression based on the intersection of the communication range between the predicted and real coordinates and the loss function, which improves the localization performance of the algorithm. Moreover, a correction scheme is proposed to correct the augmented data in the incremental strategy, which reduces the cumulative error generated during the algorithm localization. The analysis through simulation experiments demonstrates that our proposed algorithm has strong robustness and has obvious advantages in localization performance compared with other algorithms."
Bi-directional evolutionary 3D topology optimization with a deep neural network,2022,"['Topology optimization', 'Deep learning', 'BESO', 'CNN', 'Python']",,"The FEM-based topology optimization repeats usually finite element analyses many times to converge to the stopping criteria. If the near-optimal topology data are available in advance at the beginning of an optimization process, the iterative computation could be greatly reduced. In an effort to obtain swiftly optimum topology solutions, the deep learning and neural networks with a special segmentation scheme of digital images are combined with the BESO (bi-directional evolutionary structural optimization) topology method in this study. The pre-trained digital images of 3200 optimum topologies construct the design domain for the main topology optimization. Additionally, a new post-processor is developed in order to reconstruct the relative locations among finite elements in the raw outputs generated by the neural network.The proposed method has been demonstrated to be efficient in lowering the iterations with several 2D and 3D optimization examples. The iteration counts can be reduced 63 % for a 2D example and by 72.5 % for a 3D one, compared to BESO results alone."
Methods in the spatial deep learning: current status and future direction,2022,"['Deep learning', 'Machine learning', 'Remote sensing', 'Classification', 'Convolution neural network (CNN)', 'Long short-term memory (LSTM)', 'Autoencoder']",,"A deep neural network (DNN), evolved from a traditional artificial neural network, has been seamlessly adapted for the spatial data domain over the years. Deep learning (DL) has been widely applied for a number of applications and a variety of thematic domains. This article reports on a systematic review of methods adapted in major DNN applications with remote sensing data published between 2010 and 2020 aiming to understand the major application area, a framework for model development and the prospect of DL application in spatial data analysis. It has been found that image fusion, change detection, scene classification, image segmentation, and feature detection are the most commonly used application areas. Based on the publication in these thematic areas, a generic framework has been devised to guide a model development using DL based on the methods followed in the past. Finally, recent trends and prospects in terms of data, method, and application of deep learning with remote sensing data are discussed. The review finds that while DL-based approaches have the potential to unfold hidden information, they face challenges in selecting the most appropriate data, methods, and model parameterizations which may hinder the performance. The increasing trend of application of DL in the spatial domain is expected to leverage its strength at its optimum to the research frontiers."
Skin Lesion Segmentation with Codec Structure Based Upper and Lower Layer Feature Fusion Mechanism,2022,"['semantic segmentation', 'skin lesion segmentation', 'deep learning', 'convolutional neural network (CNN)', 'atrous spatial pyramid pooling']",,"The U-Net architecture-based segmentation models attained remarkable performance in numerous medical image segmentation missions like skin lesion segmentation. Nevertheless, the resolution gradually decreases and the loss of spatial information increases with deeper network. The fusion of adjacent layers is not enough to make up for the lost spatial information, thus resulting in errors of segmentation boundary so as to decline the accuracy of segmentation. To tackle the issue, we propose a new deep learning-based segmentation model. In the decoding stage, the feature channels of each decoding unit are concatenated with all the feature channels of the upper coding unit. Which is done in order to ensure the segmentation effect by integrating spatial and semantic information, and promotes the robustness and generalization of our model by combining the atrous spatial pyramid pooling (ASPP) module and channel attention module (CAM). Extensive experiments on ISIC2016 and ISIC2017 common datasets proved that our model implements well and outperforms compared segmentation models for skin lesion segmentation."
다해상도 이미지를 위한 스테그어날리시스 학습 기법,2022,"['스테그어날리시스', '딥러닝', '합성곱신경망', '디지털포렌식', '컴퓨터비전', 'Steganalysis', 'Deep Learning', 'CNN', 'Digital Forensics', 'Computer Vision']",,
Particulate Matter Estimation from Public Weather Data and Closed-Circuit Television Images,2022,"['Deep learning', 'PM concentration', 'VGG-16', 'LSTM', 'Public CCTV', 'CNN']",,"This article proposes a method of estimating the concentrations of particulate matter (PM2.5 and PM10) using public data, including road-traffic closed-circuit television (CCTV) images, Smart Seoul City data sensor environment information, and Korea Meteorological Administrationdata. The region-of-interest images and full scenes derived from CCTV footage were used as the basis for the deep learning model, which combines a convolutional neural network and long short-term memory, to establish the particulate matter (PM) concentration prediction methodology. In the experiment, the prediction accuracies corresponding to various types of mean values were calculated by training the model with various mean measurement values for the surface PM2.5 and PM10 concentrations, as well as the corresponding CCTV images and weather data at different time points. In the experiments performed under relatively stable PM concentrations, R2 generally exceeded 0.9 and tended to increase with an increasing range of mean concentration values. In particular, in sections with rapid changes in the PM concentration within an hourly interval, higher R2 values were obtained by the model trained with the average PM concentrations of the time series before and after image capture, outperforming the method that used prior mean observation values and better reflecting the current PM concentration."
A Study on the Dynamic Image-Based Dark Channel Prior and Smoke Detection Using Deep Learning,2022,"['Deep learning', 'Dark channel prior', 'Optical flow technique', 'Image pre-processing', 'CNN']",,"The detection of smoke in a fi re is a very important research topic because a large amount of carbon monoxide, which is potentially lethal, can be generated and released in the early stages of a fi re. In particular, if a fi re occurs in the form of smoldering combustion, it produces a glowing combustion without fl ames on the surface of the heat source, and the temperature is over 1000 °C. In this study, the dark channel prior, an algorithm previously used for haze removal, is used to detect areas where smoke may exist. The dark channel characteristic makes it possible to eff ectively detect the smoke area included background interference or noise. Additionally, in order to detect the characteristic that the smoke generated from the fi re rises due to the density diff erence at high temperatures, the area of the smoke was detected using the optical fl ow technique based on the Lucas–Kanade method. Image pre-processing using the dark channel prior and the optical fl ow technique can eff ectively detect the smoke areas and signifi cantly reduce false positive rate. Through this, in order to accurately determine the fi ltered region as smoke or non-smoke, a Convolutional Neural Network was employed. As a result, it was confi rmed that accuracy and precision were improved by 4% and 7%, respectively, compared to object detection models that performed detection without image pre-processing."
Enhanced 3D Residual Network for Human Fall Detection in Video Surveillance,2022,"['Video surveillance', 'fall detection', 'deep learning', 'residual network', '3D CNN']",,"In the public healthcare, a computational system that can automatically and efficiently detect and classify falls from a video sequence has significant potential. With the advancement of deep learning, which can extract temporal and spatial information, has become more widespread. However, traditional 3D CNNs that usually adopt shallow networks cannot obtain higher recognition accuracy than deeper networks. Additionally, some experiences of neural network show that the problem of gradient explosions occurs with increasing the network layers. As a result, an enhanced three-dimensional ResNet-based method for fall detection (3D-ERes-FD) is proposed to directly extract spatio-temporal features to address these issues. In our method, a 50-layer 3D residual network is used to deepen the network for improving fall recognition accuracy. Furthermore, enhanced residual units with four convolutional layers are developed to efficiently reduce the number of parameters and increase the depth of the network. According to the experimental results, the proposed method outperformed several state-of-the-art methods."
RDNN: Rumor Detection Neural Network for Veracity Analysis in Social Media Text,2022,"['Attention mechanism', 'Bidirectional Long Short Term Memory (Bi-LSTM)', 'Convolution Neural Network (CNN)', 'Deep Learning', 'Natural Language Processing']",,"A widely used social networking service like Twitter has the ability to disseminate information to large groups of people even during a pandemic. At the same time, it is a convenient medium to share irrelevant and unverified information online and poses a potential threat to society. In this research, conventional machine learning algorithms are analyzed to classify the data as either non-rumor data or rumor data. Machine learning techniques have limited tuning capability and make decisions based on their learning. To tackle this problem the authors propose a deep learning-based Rumor Detection Neural Network model to predict the rumor tweet in real-world events. This model comprises three layers, AttCNN layer is used to extract local and position invariant features from the data, AttBi-LSTM layer to extract important semantic or contextual information and HPOOL to combine the down sampling patches of the input feature maps from the average and maximum pooling layers. A dataset from Kaggle and ground dataset #gaja are used to train the proposed Rumor Detection Neural Network to determine the veracity of the rumor. The experimental results of the RDNN Classifier demonstrate an accuracy of 93.24% and 95.41% in identifying rumor tweets in real-time events."
딥러닝을 이용한 심전도 분류 알고리즘에 관한 연구,2022,"['ECG', 'Arrhythmia', 'Deep learning', 'MIT-BIH', 'Convolution neural network(CNN)']",,"The electrocardiogram(ECG) is a algorithm of recording the change in potential value for the activity of the heart by time and has been used as a testbed algorithm to analyze the normal/abnormal state of the heart. The ECG analysis algorithm uses a frequency band filter but recently deep learning and machine learning using artificial intelligence technology. In this paper, we used of ECG data, a band filter between 0.67Hz and 50Hz was used by fast Fourier Transform and the ECG data for four seconds were reconstructed into data for three seconds before and one second after the beat to be classified as one. As the learning algorithm of artificial intelligence, deep learning, convolution neural network operation was used. To prevent overfitting of the learning model, we developed a model that classifies ECG by repeating dropout. for training data, 70% were trained using 44 data set excluding pacemaker among 48 record set of MIT-BIH arrhythmia data set. As a result of the testbed, the average accuracy of the convolution neural network model was 99.8%, whereas the average accuracy of all classification was 99.6% as a result of the evaluation data, indication the it showed similar compared to the performance of the conventional ECG classification. In this paper, it is a classification for heart beat. but it is possible to contribute to the study on classification of atrial fibrillation as classification of ECG rhythms by learning models."
합성곱신경망을 활용한 천리안위성 2A호 영상 기반의 동해안 냉수대 감지 연구,2022,"['Geo-Kompsat 2A', 'Cold water', 'Upwelling', 'Korean peninsula', 'Deep learning', 'Convolution neural network']","본 연구에서는 천리안위성 2A호 1일 평균 표층수온영상을 대상으로 합성곱신경망(convolution neural network, CNN) 딥러닝 기법을 적용하여 냉수대 발생 여부를 분류하는 연구를 수행하였다. 이를 위하여, 2019년부터 2022년까지 1,155장의 영상을 사용하였으며, 국립수산과학원 제공 냉수대 발생 주의보 및 경보자료로부터 냉수대 발생 영상과 그 외 영상으로 분류하여 학습을 수행하였다. 학습 결과로 82.5%의 probability of detection (POD)와 54.4%의 false alarm ratio (FAR) 지수를 획득하였다. 오분류 분석을 통해 냉수대 분류에 실패한 경우의 대부분은 구름의 영향 때문이며, 비냉수대를 오분류한 경우의 대부분은 실제 영상에 냉수대가 존재함을 확인하였다.",
형태학적 연산과 경계추출 학습이 강화된 U-Net을 활용한 Sentinel-1 영상 기반 수체탐지,2022,"['Synthetic aperture radar (SAR)', 'Deep learning', 'Convolutional neural network (CNN)', 'Water detection', 'Morphology transformation', 'Edge detection']",,"Synthetic Aperture Radar (SAR) is considered to be suitable for near real-time inundation monitoring. The distinctly different intensity between water and land makes it adequate for waterbody detection, but the intrinsic speckle noise and variable intensity of SAR images decrease the accuracy of waterbody detection. In this study, we suggest two modules, named ‘morphology module’ and ‘edge-enhanced module’, which are the combinations of pooling layers and convolutional layers, improving the accuracy of waterbody detection. The morphology module is composed of min-pooling layers and max-pooling layers, which shows the effect of morphological transformation. The edge-enhanced module is composed of convolution layers, which has the fixed weights of the traditional edge detection algorithm. After comparing the accuracy of various versions of each module for U-Net, we found that the optimal combination is the case that the morphology module of min-pooling and successive layers of min-pooling and max-pooling, and the edge-enhanced module of Scharr filter were the inputs of conv9. This morphologic and edge-enhanced U-Net improved the F1-score by 9.81% than the original U-Net. Qualitative inspection showed that our model has capability of detecting small-sized waterbody and detailed edge of water, which are the distinct advancement of the model presented in this research, compared to the original U-Net."
Artificial neural network reconstructs core power distribution,2022,"['Artificial neural network', 'In-core power', 'distribution', 'RBF', 'CNN']",,"To effectively monitor the variety of distributions of neutron flux, fuel power or temperatures in thereactor core, usually the ex-core and in-core neutron detectors are employed. The thermocouples fortemperature measurement are installed in the coolant inlet or outlet of the respective fuel assemblies. Itis necessary to reconstruct the measurement information of the whole reactor position. However, thereading of different types of detector in the core reflects different aspects of the 3D power distribution.The feasibility of reconstruction the core three-dimension power distribution by using different combinations of in-core, ex-core and thermocouples detectors is analyzed in this paper to synthesize theuseful information of various detectors. A comparison of multilayer perceptron (MLP) network and radialbasis function (RBF) network is performed. RBF results are more extreme precision but also moresensitivity to detector failure and uncertainty, compare to MLP networks. This is because that localizedneural network could offer conservative regression in RBF. Adding random disturbance in trainingdataset is helpful to reduce the influence of detector failure and uncertainty. Some convolution neuralnetworks seem to be helpful to get more accurate results by use more spatial layout information, thoughrelative researches are still under way"
Retinal Disease Identification using Upgraded CLAHE filter and Transfer Convolution Neural Network,2022,"['Retinal disease', 'Retinal fundus images', 'Convolution neural network (CNN)', '(CLAHE) filter']",,"Retinal tissue plays a crucial part in human vision. Infections of retinal tissue and delayed treatment or untreated infection could lead to loss of vision. Additionally, the diagnosis is prone to errors when huge dataset is involved. Therefore, a fully automated model of identification of retinal disease is proposed to reduce human interaction while retaining its high accuracy classification results. This paper introduces an enhanced design of a fully automatic multi-class retina diseases prediction system to assist ophthalmologists in making speedy and accurate investigation. Retinal fundus images, which have been used in this study, were downloaded from the stare website (157 images from five classes: BDR, CRVO, CNV, PDR, and Normal). The five files were categorized according to their annotations conducted by the experienced specialists. The categorized images were first processed with the proposed upgraded contrast-limited adaptive histogram filter for image brightness enhancement, noise reduction, and intensity spectrum normalization. The proposed model was designed with transfer learning method and the fine-tuned pre-trained RESNET50. Eventually, the proposed framework was examined with performance evaluation parameters, recorded a classification rate with 100% sensitivity, 100% specificity, and 100% accuracy. The performance of the proposed model showed a magnificent superiority as compared to the state-of-the-art studies."
Prediction of the superiority of the hydrodynamic performance of hull forms using deep learning,2022,"['Hull form design Hydrodynamic performance', 'Superiority prediction', 'Deep learning', 'Convolutional Neural Network (CNN)', 'Computational Fluid Dynamics (CFD)']",,"When designing a ship's hull form, a designer creates various candidate hull forms and performs a Computational Fluid Dynamics (CFD) analysis to evaluate the performance of each candidate. Designers consider quantitative indicators, such as the total resistance and wake coefficient, and qualitative indicators, such as the wave height and pressure distributions, when evaluating the performance of a hull form. During the design process, quantitative and qualitative indicators are often used to determine the superiority of two hull forms. However, in the case of quantitative indicators, the difference between the two hull forms is often minimal; thus, superiority cannot be readily determined. Furthermore, because qualitative indicators are in the form of images, it is challenging to determine the superiority in many cases, even for experienced designers. To solve this problem, we propose a convolutional neural networkbased model for predicting the superiority of hull form performance from a qualitative indicator of the image form derived from CFD analysis. The proposed prediction model received various types of hull form performance images. From these results, the hull form performance characteristics were well fused for prediction with high accuracy. CFD analysis images and quantitative indicators for 1600 hull forms were used to determine the superiority of the prediction model. The learned model was verified using 240 hulls. The result confirmed that the proposed model accurately predicted superiority with an accuracy of approximately 94%."
딥러닝 기반 알약 인식 및 분류 모델 구현,2022,"['알약 분류 모델', '알약 인식', '딥러닝', '합성곱 신경망', 'Pill Classification Model', 'Pill Recognition', 'Deep Learning', 'CNN']",,"Recently, as interest in health promotion increases and drug crimes increase, the demand for searching for the efficacy and dosage of pills is increasing. Therefore, in this paper, we proposed a deep learning-based model for recognizing and classifying pills from pill images. We first collected pill image data and recognized the pill in the image. Next, we proposed and implemented a model that classifies the color and shape of the recognized pill and recognizes the string written on the pill."
호가창과 뉴스 헤드라인을 이용한 딥러닝 기반 주가 변동 예측 기법,2022,"['주가예측', '호가창', '뉴스', '합성곱 신경망', 'Word2vec', 'Stock Price Prediction', 'Limit Order Book', 'News', 'CNN', 'Word2vec']","최근 머신러닝 및 딥러닝 기법을 활용한 주식 가격 예측 연구가 다양하게 이루어지고 있다. 그 중에서도 최근에는 주식 매수 및 매도 주문 정보를 담고 있는 호가창을 이용하여 주가를 예측하려는 연구가 시도되고 있다. 하지만 호가창을 활용한 연구는 대부분 가장 최근 일정 기간 동안의 호가창 추이만을 고려하며, 호가창의 중기 추이와 단기 추이를 같이 고려하는 연구는 거의 진행되지 않았다. 이에 본 논문에서는 호가창의 중기와 단기 추이를 모두 고려하여 주가 등락을 보다 정확히 예측하는 딥러닝 기반 예측 모델을 제안한다. 더욱이 본 논문에서 제안하는 모델은 중단기 호가창 정보 외에도 해당 종목에 대한 동기간 뉴스 헤드라인까지 고려하여 기업의 정성적 상황까지 주가 예측에 반영한다. 본 논문에서 제안하는 딥러닝 기반 예측 모델은 호가창 변화의 특징을 합성곱 신경망으로 추출하고 뉴스 헤드라인의 특징을 Word2vec을 이용하여 추출한 뒤, 이들 정보를 결합하여 특정 기업 주식의 다음 날 등락 여부를 예측한다. 실제 NASDAQ 호가창 데이터와 뉴스 헤드라인 데이터를 사용하여 제안 모델로 5개 종목(Amazon, Apple, Facebook, Google, Tesla)의 일일 주가 등락을 예측한 결과, 제안 모델은 기존 모델에 비해 정확도를 최대 17.66%p, 평균 14.47%p 향상시켰다. 또한 해당 모델로 모의 투자를 수행한 결과, 21 영업일 동안 종목에 따라 최소 $492.46, 최대 $2,840.83의 수익을 얻었다.","Recently, various studies have been conducted on stock price prediction using machine learning and deep learning techniques. Among these studies, the latest studies have attempted to predict stock prices using limit order books, which contain buy and sell order information of stocks. However, most of the studies using limit order books consider only the trend of limit order books over the most recent period of a specified length, and few studies consider both the medium and short term trends of limit order books. Therefore, in this paper, we propose a deep learning-based prediction model that predicts stock price more accurately by considering both the medium and short term trends of limit order books. Moreover, the proposed model considers news headlines during the same period to reflect the qualitative status of the company in the stock price prediction. The proposed model extracts the features of changes in limit order books with CNNs and the features of news headlines using Word2vec, and combines these information to predict whether a particular company’s stock will rise or fall the next day. We conducted experiments to predict the daily stock price fluctuations of five stocks (Amazon, Apple, Facebook, Google, Tesla) with the proposed model using the real NASDAQ limit order book data and news headline data, and the proposed model improved the accuracy by up to 17.66%p and the average by 14.47%p on average. In addition, we conducted a simulated investment with the proposed model and earned a minimum of $492.46 and a maximum of $2,840.93 depending on the stock for 21 business days."
액체섬광검출용액의 구성 요소 판별 및 핵 입자 실험 데이터 획득 관련 저속 제어 시스템에서 합성 곱 신경망 적용 가능성 연구,2022,"['Slow control', 'Liquid scintillator', 'Deep convolutional neural network', 'Pixel image analysis', 'High energy experiment', 'Neutrino', 'IoT', 'Embedded systems', '저속 제어', '액체섬광검출 용액', '심층 합성 곱 신경망', '픽셀 이미지 분석', '핵 입자 실험', '중성미자', '사물 인터넷', '내장형 시스템']","본 논문은 사물 인터넷 기술과 기계 학습을 핵, 입자 실험의 데이터 획득 관련 저속 제어 시스템에 적용하였다. 합성곱 신경망을 이용하여 액체섬광검출 용액의 형광체 판별을 구축 응용의 한 예로 시도하였다. 실험실 수준에서, 액체섬광검출 용액의 형광 방출 성능에 큰 영향을 끼치는 인자들은 보고 되었지만 대형 실험의 극한 상황에서 장기간 성능 연구는 진행 중에 있다. 그 이유는 핵, 입자 실험 특성상 액체섬광검출 용액은 검출기 안에 밀봉되기 때문에 비침습적인 샘플 검사가 어렵기 때문이다. 특히 원자력 발전소 같은 방사선량이 아주 높은 극한 환경에서 액체섬광검출 용액의 장기적인 물리 화학적 안정성은 아직 보고되지 않았다. 방사능 위험 지역에 대한 접근은 많은 시간과 노력이 필요하다. 한편, 핵과 중성미자 간의 산란 단면적 추정 시, 계통 오차의 주된 요인은 중성미자 선속 정확도이다. 입자 붕괴를 통해 중성미자 발생과 측정이 간접적으로 이루어지기 때문에, 검출기 반응에 대한 감시 및 보정 목적의 저속 제어 시스템의 성능 향상이 요구된다. 현재까지 마이크로 컨트롤러의 경량화, 집적화, 그리고 사물 인터넷 기술이 발전하여 내장형 시스템의 경제성과 신뢰성이 크게 향상되었다. 그 결과로 연구자의 안전, 오랜 시간 극한 상황에서 액체섬광검출 용액의 환경 데이터 획득 및 향후 낮은 획득률을 가진 반도체 이미지 센서를 이용한 실험 비결 (know-how) 확보를 할 수 있을 것으로 기대한다.","In this paper, we tried to estimate the fluor components of a liquid scintillator using a convolutional neural network (CNN) while applying and building the internet of things (IoT) and machine learning in a slow control system. Various factors affecting the fluorescent emission of liquid scintillators have been reported at the laboratory level. However, long-term performance studies are still ongoing under extreme environmental conditions in large-scale experiments beyond the laboratory level. Given the characteristics of neutrino experiments, the liquid scintillator is sealed inside the detector, making it difficult to observe non-invasive samples. In particular, the long-term physical and chemical stability of liquid scintillators in extreme environments with high radiation bombardment doses, such as nuclear power plants, has not been reported. Accessing a highly radioactive area requires considerable time and effort. In addition, the cost efficiency and reliability of embedded systems have improved with the development of microcontroller weight reduction, integration, and IoT technology. Therefore, researchers hypothesized that long-term liquid scintillators could ensure the operator’s safety and acquire environmental data under extreme conditions. Moreover, experimental know-how can be obtained by using low-gain semiconductor image sensors."
심전도의 다양한 2차원 변환에 의한 합성곱 신경망기반 개인식별,2022,"['person identification', 'electrocardiogram', 'convolutional neural networks', 'time-frequency transform', 'Short-Time Fourier Transform', 'Fourier Synchrosqueezed Transform']",,"In this paper, we propose personal identification method based on Convolutional Neural Networks (CNN) by various two-dimensional (2D) transform of Electrocardiogram (ECG) signals. For this purpose, various 2D time-frequency representation are peformed by Short-Time Fourier Transform (STFT), Fourier Synchrosqueezed Transform (FSST), and Wavelet Synchrosqueezed Transform (WSST) from one-dimensional ECG signals. The individual identification performance is achieved by transfer learning based on the pretrained GoogleNet and ResNet-101. The performance of experimental results are compared by the well-known PTB-ECG database."
깊이 이미지를 이용한 딥러닝 기반 충돌 확률 예측 및 장애물 회피 알고리즘,2022,"['Deep-learning', 'Depth image', 'Obstacle avoidance', 'collision probability', '.']",,.
왜곡 정보 모듈을 이용한 이미지 디블러 방법,2022,"['Image Deblurring', 'Distortion-guided Module', 'Transformer', 'Convolution Neural Network']","영상 흐려짐은 피사체의 움직임, 카메라의 흔들림 등의 요인으로 발생하는 현상이다. 최근 합성곱 심층신경망(Convolution Neural Network, CNN)을 활용하여 흐려짐 현상을 복원하는 연구가 활발하게 진행되었으며, 원본과 정답 영상의 차이를 이용하여 복원 과정을 가이드하는 방법이 뛰어난 성능을 보였다. 본 논문에서는 왜곡 정보를 기반으로 흐려진 영상 복원 성능을 개선하는 방법을 제안한다. 이를 위해 학습 시, 원본과 정답 영상 차이에 대한 이진화를 수행하여 복원 과정을 가이드 할 수 있도록 하는 트랜스포머(Transformer) 기반 신경망 모듈을 설계하였다. 제안하는 방법은 학습 과정에서 잠재 특징을 기반으로 전역적 추론을 통해 예측한 왜곡 위치 정보 분포를 흐려짐 복원 과정에 반영한다. 다양한 영상 흐려짐 복원 신경망에 제안하는 모듈을 적용하여 복원 성능을 효과적으로 향상시킬 수 있음을 확인하였다.",
가닥 지오메트리 이미지를 이용한 ConvNet 기반의 헤어 및 털 합성기,2022,"['Hair simulation', 'Fur simulation', 'Convolutional neural network', 'Physically based simulation', 'Strand geometry image', '헤어 시뮬레이션', '털 시뮬레이션', '합성곱 신경망', '물리 기반 시뮬레이션', '가닥 지오메트리 이미지']","본 논문에서는 라인 형태인 가닥(Strand) 지오메트리 이미지와 합성곱 신경망(Convolutional Neural Network, ConvNet 혹은 CNN)을 이용하여 저해상도 헤어 및 털 시뮬레이션을 고해상도로 노이즈 없이 표현할 수 있는 기법을 제안한다. 저해상도와 고해상도 데이터 간의 쌍은 물리 기반 시뮬레이션을 통해 얻을 수 있으며, 이렇게 얻어진 데이터를 이용하여 저해상도-고해상도 데이터쌍을 설정한다. 학습할 때 사용되는 데이터는 헤어 가닥 형태의 위치를 지오메트리 이미지로 변환하여 사용한다. 본 논문에서 제안하는 헤어 및 털 네트워크는 저해상도 이미지를 고해상도 이미지로 업스케일링(Upscaling)시키는 이미지 합성기를 위해 사용된다. 테스트 결과로 얻어진 고해상도 지오메트리 이미지가 고해상도 헤어로 다시 변환되면, 하나의 매핑 함수로 표현하기 어려운 헤어의 찰랑거리는(Elastic) 움직임을 잘 표현할 수 있다. 합성 결과에 대한 성능으로 이전 물리 기반 시뮬레이션보다 빠른 성능을 보였으며, 복잡한 수치해석을 몰라도 쉽게 실행이 가능하다.","In this paper, we propose a technique that can express low-resolution hair and fur simulations in high-resolution without noise using ConvNet and geometric images of strands in the form of lines. Pairs between low-resolution and high-resolution data can be obtained through physics-based simulation, and a low-resolution-high-resolution data pair is established using the obtained data. The data used for training is used by converting the position of the hair strands into a geometric image. The hair and fur network proposed in this paper is used for an image synthesizer that upscales a low-resolution image to a high-resolution image. If the high-resolution geometry image obtained as a result of the test is converted back to high-resolution hair, it is possible to express the elastic movement of hair, which is difficult to express with a single mapping function. As for the performance of the synthesis result, it showed faster performance than the traditional physics-based simulation, and it can be easily executed without knowing complex numerical analysis."
무선통신시스템에서 딥러닝에 기반한 미래 신호대잡음비 예측,2022,"['SNR   pre d i c t i o n', 'Deep   learning', 'TDD', 'Multi   output', 'CNN', '신 호대잡음비   예측', '딥러 닝', '시분 할    전이중', '다중출력', '합성곱   신경망']","무선 통신 환경에서 딥러 닝을 기반으로 미래 신 호대잡음비( S N R ) 를 예측하 는 기술을 제안한다. 본 논문에서 고려하는 통 신 시스템은 시분 할 전이중 방식을 사용하며, 여러 개의 안테나로 수신하며 동일한 안테나를 이용하여 미래에 송신한다. 여러 수신 안테나에서 과거에 수신된 SNR을 기반으로, 미래 송신 안테나 별로 SNR을 예측하는 합성곱 신경망 모델을 제안한다. 수신하는 비율 또는 수신 SNR을 기록하는 비율 은 10%에서 100%로 설정한다. 만약 수신 기록이 없어 SNR 기록이 존재하지 않는다면 이전에 수신된 SNR과 이후 수신된 SNR의 선형 보간(Linear interpolation)을 통해 수신 SNR을 설정한다. 모의실험 결과에 따르면 광대역 신호일 때 협대역 신호보다우수한 성능을 보인다. 광대역인 경우 20km/h의 속도를 기준으로 제안방법이 기존방법에 비해 약 0.37dB에서 약0.98dB 우수하고, 협대역인 경우 20km/h의 속도를 기준으로 제안방법이 약 0.29dB에서 약 0.88dB 우수하다.","This pa pe r proposes a deep-learning based signal to noise ra t i o (SNR) pre d i c t i o n technique fo r wireless communication environments. The communication system considered in this pa pe r uses time division duplex ( T DD) , and re c e i v e s signal using multiple antennas while transmits with only one antenna.Ba s e d on the SNR measurements when receiving in the pa s t , we proposed a convolutional neural network ( C NN) model to pre d i c t the SNRs fo r all antennas at the time of fu t u re transmission. If there is no re c e i v e d signal nor SNR measurement, the SNR measurements are filled by linear interpolation of neighboring two re c e i v e d SNRs. According to the simulation results, the wideband signals show better pre d i c t i o n pe rfo rm a n c e than the n a rro w b a n d signals. In the case of wideband, the proposed technique is about 0.37～0.98 dB superior to the conventional method fo r 20 km/h. Fo r n a rro w b a n d , the proposed one is better by 0.29～0.88 dB."
임베디드 보드에서 차량 감지 및 추적을 위한 딥러닝 모델 최적화,2022,"['Vehicle detection', 'Vehicle tracking', 'embedded board', 'SSD', 'MobileNet', 'convolutional neural network', '차량 감지', '차량 추적', '임베디드 보드', 'SSD', 'MobileNet', 'CNN']","본 논문은 임베디드 보드에서 차량을 감지하고 추적하기 위한 딥러닝 모델을 제안한다. 딥러닝이 기존 이미지 처리 방법에서 높은 정확도를 보여주고 있기 때문에 기존 객체 검출기로 거리나 교량에서 차량을 감지할 수 있다. 그러나, 범용 PC를 사용하는 경우 GPU를 사용하여 프로그램을 실시간으로 동작하는 것이 가능하지만, 임베디드 보드에서는 GPU를 사용하기 어렵고 낮은 성능의 CPU를 사용하므로 프로그램의 실시간 처리가 불가능하다. 본 논문에서는 양자화, edge TPU와 같은 방법을 이용해서 에지 컴퓨팅 기반 딥러닝을 이용한 객체 감지의 정확도와 성능 향상을 시도하였다. Yolo와 같은 다른 네트워크보다 MobileNet을기반한 SSDLite가 빠른 추론시간과 높은 정확도를 보여줘 선정했다. SSDMobileNetV2를 객체 감지기로 사용한 DeepSORT로 모델을 학습하여 차량을 추적할 수 있도록 하였다. 본 논문에서는 H6 CPU를 이용하여 자체 제작한 보드를 통해 차량 감지 및 추적을 위한 딥러닝모델의 성능을 확인하였다","This paper proposes a deep learning model to detect and track the vehicle on an embedded device. Since deep learning has achieved high accuracy over the classical image processing method, object detectors can detect vehicles in the street and highway. It can be normal to run the computer detection program with graphic processor unit (GPU) support, but it is challenging to run it on the embedded board with no GPU support and low central processing unit (CPU) performance. This paper focuses on balancing edge-computing-based deep learning object detection's accuracy and performance using additional techniques such as quantization, edge TPU. SSDLite with MobileNet backbone is chosen due to its lighter than other networks but still obtain good performance compare with Yolo. The model was learned with DeepSORT using SSDMobileNetV2 as an object detector so that the vehicle could be tracked. This paper evaluates the performance of deep learning model to detect and track the vehicle through the developed board using H6 CPU."
얼굴 감정 분류 기술을 적용한 학습자의 수업 집중도 고찰 : 해외문헌을 중심으로,2022,"['ITS', '얼굴 인식', '학습자 집중도', 'AI', '인공지능', 'ITS', 'Face classification', 'Leaner’s focus', 'AI', 'Artificial Intelligence']",,
합성곱 신경망과 장단기 메모리를 이용한 사격음 분석 기법,2022,,,"This paper proposes a model which classifies the type of guns and information about sound source location using deep neural network. The proposed classification model is composed of convolutional neural networks (CNN) and long short-term memory (LSTM). For training and test the model, we use the Gunshot Audio Forensic Dataset generated by the project supported by the National Institute of Justice (NIJ). The acoustic signals are transformed to Mel-Spectrogram and they are provided as learning and test data for the proposed model. The model is compared with the control model consisting of convolutional neural networks only. The proposed model shows high accuracy more than 90 %."
근전도 기반의 Spider Chart와 딥러닝을 활용한 일상생활 잡기 손동작 분류,2022,"['Convolution neural network', 'Electromyography', 'Pre-processing', 'Hand motion', 'Spider chart']",,"In this paper, we propose a pre-processing method that converts to Spider Chart image data for classification of gripping movement using EMG (electromyography) sensors and Convolution Neural Networks (CNN) deep learning. First, raw data for six hand gestures are extracted from five test subjects using an 8-channel armband and converted into Spider Chart data of octagonal shapes, which are divided into several sliding windows and are learned. In classifying six hand gestures, the classification performance is compared with the proposed pre-processing method and the existing methods. Deep learning was performed on the dataset by dividing 70% of the total into training, 15% as testing, and 15% as validation. For system performance evaluation, five cross-validations were applied by dividing 80% of the entire dataset by training and 20% by testing. The proposed method generates 97% and 94.54% in cross-validation and general tests, respectively, using the Spider Chart preprocessing, which was better results than the conventional methods."
DenseFuse 기반의 광대역 영상 합성 학습을 위한 효과적인 데이터 분류 및 가중치 학습 모델,2022,"['image fusion', 'deep learning', 'supervised learning', 'infrared image', 'visible image']",,"In this paper, to improve the slow processing speed of the multi-resolution based visible and NIR(Near-infrared) image synthesis method, we present a fast synthesis method using DenseFuse, one of the CNN(Convolutional Neural Network)-based image synthesis methods. The proposed method applies a raster scan algorithm to secure visible and NIR datasets for effective learning, and presents a dataset classification method using luminance and variance. Also, in this paper, a method for synthesizing a feature map in a fusion layer is presented and compared with the method for synthesizing a feature map in other fusion layers. The proposed method learns the superior image quality of the multi-resolution based image synthesis method, and shows a clear synthesized image with better visibility than other existing learning-based image synthesis methods. Compared with the multi-resolution based image synthesis method used as the target image, the proposed method has the advantage in processing speed by reducing the processing time to 3 times or more."
Performance Analysis of Cloud-Net with Cross-sensor Training Dataset for Satellite Image-based Cloud Detection,2022,"['Cloud Detection', 'KOMPSAT-3']",,"Since satellite images generally include clouds in the atmosphere, it is essential to detect or mask clouds before satellite image processing. Clouds were detected using physical characteristics of clouds in previous research. Cloud detection methods using deep learning techniques such as CNN or the modified U-Net in image segmentation field have been studied recently. Since image segmentation is the process of assigning a label to every pixel in an image, precise pixel-based dataset is required for cloud detection. Obtaining accurate training datasets is more important than a network configuration in image segmentation for cloud detection. Existing deep learning techniques used different training datasets. And test datasets were extracted from intra-dataset which were acquired by same sensor and procedure as training dataset. Different datasets make it difficult to determine which network shows a better overall performance.To verify the effectiveness of the cloud detection network such as Cloud-Net, two types of networks were trained using the cloud dataset from KOMPSAT-3 images provided by the AIHUB site and the L8-Cloud dataset from Landsat8 images which was publicly opened by a Cloud-Net author. Test data from intra-dataset of KOMPSAT-3 cloud dataset were used for validating the network. The simulation results show that the network trained with KOMPSAT-3 cloud dataset shows good performance on the network trained with L8-Cloud dataset. Because Landsat8 and KOMPSAT-3 satellite images have different GSDs, making it difficult to achieve good results from cross-sensor validation. The network could be superior for intra-dataset, but it could be inferior for cross-sensor data. It is necessary to study techniques that show good results in cross-senor validation dataset in the future."
편광현미경 이미지 기반 염기성 화산암 분류를 위한 인공지능 모델의 효용성 평가,2022,,,"In order to minimize the human and time consumption required for rock classification, research on rock classification using artificial intelligence (AI) has recently developed. In this study, basic volcanic rocks were subdivided by using polarizing microscope thin section images. A convolutional neural network (CNN) model based on Tensorflow and Keras libraries was self-producted for rock classification. A total of 720 images of olivine basalt, basaltic andesite, olivine tholeiite, trachytic olivine basalt reference specimens were mounted with open nicol, cross nicol, and adding gypsum plates, and trained at the training : test = 7 : 3 ratio. As a result of machine learning, the classification accuracy was over 80-90%. When we confirmed the classification accuracy of each AI model, it is expected that the rock classification method of this model will not be much different from the rock classification process of a geologist. Furthermore, if not only this model but also models that subdivide more diverse rock types are produced and integrated, the AI model that satisfies both the speed of data classification and the accessibility of non-experts can be developed, thereby providing a new framework for basic petrology research."
A deep learning approach to permanent tooth germ detection on pediatric panoramic radiographs,2022,"['Tooth Germ', 'Radiograph', 'Panoramic', 'Pediatric Dentistry']",,"Purpose: The aim of this study was to assess the performance of a deep learning system for permanent tooth germ detection on pediatric panoramic radiographs.Materials and Methods: In total, 4518 anonymized panoramic radiographs of children between 5 and 13 years of age were collected. YOLOv4, a convolutional neural network (CNN)-based object detection model, was used to automatically detect permanent tooth germs. Panoramic images of children processed in LabelImg were trained and tested in the YOLOv4 algorithm. True-positive, false-positive, and false-negative rates were calculated. A confusion matrix was used to evaluate the performance of the model.Results: The YOLOv4 model, which detected permanent tooth germs on pediatric panoramic radiographs, provided an average precision value of 94.16% and an F1 value of 0.90, indicating a high level of significance. The average YOLOv4 inference time was 90 ms.Conclusion: The detection of permanent tooth germs on pediatric panoramic X-rays using a deep learning-based approach may facilitate the early diagnosis of tooth deficiency or supernumerary teeth and help dental practitioners find more accurate treatment options while saving time and effort."
딥러닝 알고리즘을 적용한 컬처마이닝,2022,"['ディ─プラ─ニング、文化要素抽出システム（CEMS）、文化イメージフレームネットワーク (CIFN)、文化要素(CE)、文化イメージフレーム', 'Deep Learning', 'CEMS (Cultural Element Mining System)', 'CIFN (Cultural Image Frame Network)', 'Cultural Element', 'Cultural Image Frame(CIF)']",,"This paper is a paper conceived to improve the Cultural Image Frame Network (CIFN) by utilizing deep learning-based image learning datasets that have recently received much attention in major research fields such  as  computer  vision  and  Natural  Language  Processing  (NLP).  In  particular,  CNN,  which  uses convolutional filters for images to calculate quickly and considers the entire image, including specific objects as well as backgrounds, is a very suitable algorithm for extracting cultural elements that constitute the cultural image frame of this culture mining study. In addition, by utilizing images in the form of refined images verified with deep learning experimental and test datasets, the limitations of existing research, such as (1) reliability of tagging information, (2) inaccuracy of the segmentation method, and (3) redundancy of images, can contribute to more sophisticated research."
기계학습 기반 악성코드 검출을 위한 이미지 생성 방법,2022,"['malware detection', 'static analysis', 'machine learning', 'image recognition']",,"Many attempts have been made to apply image recognition based on machine learning which has recently advanced dramatically to malware detection. They convert executable files to images and train deep learning networks like CNN to recognize or categorize dangerous executable files, which shows promising results. In this study, we are looking for an effective image generation method that may be used to identify malware using machine learning. To that end, we experiment and assess the effectiveness of various image generation methods in relation to malware detection. Then, we suggest a linear image creation method which represents control flow more clearly and our experiment shows our method can result in better precision in malware detection."
Siame-FPN기반 객체 특징 추적 알고리즘,2022,"['Computer Vision', 'Convolutional Neural Networks', 'Deep Learning', 'Object Tracking', 'Siamese Network']",,"Visual tracking of selected target objects is fundamental challenging problems in computer vision. Object tracking localize the region of target object with bounding box in the video. We propose a Siam-FPN based custom fully CNN to solve visual tracking problems by regressing the target area in an end-to-end manner. A method of preserving the feature information flow using a feature map connection structure was applied. In this way, information is preserved and emphasized across the network. To regress object region and to classify object, the region proposal network was connected with the Siamese network. The performance of the tracking algorithm was evaluated using the OTB-100 dataset. Success Plot and Precision Plot were used as evaluation matrix. As a result of the experiment, 0.621 in Success Plot and 0.838 in Precision Plot were achieved."
영상 화소 밝기 특징강화를 통한 딥러닝 기반 의료영상 분할성능 개선,2022,"['Clinical decision support system', 'Medical image segmentation', 'Intensity enhancement', 'Gaussian mixture model', 'U-net']","영상판독을 통한 임상 의사결정 지원시스템 개발에 있어서, 분석하고자 하는 병변 또는 장기만을 효과적으로 추출할 수 있는 영상 분할 기술은 활발한 연구가 진행되어 왔다. 특히, 영상내의 형태특징정보를 효과적으로 추출할 수 있는 딥러닝 계열의 Convolutional Neural Network (CNN) 모델을 기반으로 한 U-net 모델은 의료 영상 분할 연구에서 가장 중요한 모델중 하나로 사용되어지고 있다. 하지만, 특정 병변 및 장기의 경우 형태특징정보뿐만 아니라 병변 및 장기의 물리적 특성에 따른 영상에서의 화소 밝기 특징정보 또한 중요한 역할을 하지만 형태특징정보에 더욱 의존적인 U-net 모델의 경우에는 모델 학습과정에서 밝기 특징 정보가 누락될 수 있는 단점이 있다. 이에 본 논문에서는, 세밀한 영상 분할을 위해 특정 병변 및 장기가 가지고 있는 밝기 특징 정보를 가우시안 혼합모델(Gaussian Mixture Model: GMM)을 통해 모델링 및 강화하여 영상분할에 필요한 사전지식으로 사용할 수 있도록 기존 U-net 모델을 개선하였다. 제안한 알고리즘의 성능 검증을 위해 구강X-ray 영상에서의 치아 분할, 뇌 CT영상에서의 뇌출혈 분할 및 뇌MR 영상에서의 뇌종양 분할 실험을 진행하였으며, 영상의 밝기정보를 강화한 제안 모델이 기존의 U-net에 비해 더욱 세밀한 영상분할이 가능한 것을 확인하였다. 제안한 영상 화소 밝기 특징강화 접근방법은 영상분할외에도 영상분류, 예측 등 다양한 영상분석 방법에 적용되어 영상전처리로써 중요한 역할을 할 수 있을 것이다.",
딥러닝 기술에 기반한 사용자 이동 경로의 이상치 탐지 기법,2022,"['anomaly detection', 'outlier detection', 'trajectory', 'deep learning', 'data quality']",,"Trajectory data refers to data having a continuous GPS location using various mobile devices, and data inspection and refinement are important in order for such trajectory data to be utilized for machine learning. The Anomaly detection technology improves the performance of machine learning by finding outliers in the dataset and improving the quality of the data. This paper describes outlier types from user trajectories and proposes a model for detecting outliers using 5 deep learning models(CNN, DNN, LSTM, Bi-LSTM, LSTM-autoencoder). In addition, in order to select the most suitable model among the 5 deep learning models, the actual trajectory dataset is trained on each model, and its performance is measured by detecting outliers. As a result of the comparative evaluation, the LSTM-autoencoder model had the highest F1-score for anomaly detection compared to other models and showed stable performance."
딥러닝을 이용한 원격탐사 영상분석 연구동향,2022,"['Deep learning', 'Remote sensing', 'Image analysis']",,"Artificial Intelligence (AI) techniques have been effectively used for image classification, object detection, and image segmentation. Along with the recent advancement of computing power, deep learning models can build deeper and thicker networks and achieve better performance by creating more appropriate feature maps based on effective activation functions and optimizer algorithms. This review paper examined technical and academic trends of Convolutional Neural Network (CNN) and Transformer models that are emerging techniques in remote sensing and suggested their utilization strategies and development directions. A timely supply of satellite images and real-time processing for deep learning to cope with disaster monitoring will be required for future work. In addition, a big data platform dedicated to satellite images should be developed and integrated with drone and Closed-circuit Television (CCTV) images."
Continuous Blood Pressure Estimation using 1D Convolutional Neural Network and Attention Mechanism,2022,"['Luong attention', 'Blood pressure', '1D convolutional neural network', 'Attention mechanism']",,"Patients with hypertensive blood pressure (BP) needs a round-the-clock BP monitoring and must take precautions to prevent emergencies such as stroke or heart failure. This paper suggests a deep neural network (DNNs–based BP estimation approach using electrocardiogram (ECG), photoplethysmogram (PPG), and ballistocardiogram (BCG) signals. The proposed approach consists of a one-dimensional convolutional neural network (1D CNN) followed by the attention mechanism known as Luong attention. Estimations under the proposed model yield mean absolute error (MAE) of 3.299±2.419 for systolic and 2.69±1.821 for diastolic BP. The algorithm can effectively predict BP without a recurrent neural network (RNNs), which is a typical DNNs model for processing sequential data. Additionally, the proposed approach is preferable owing to its ability to explain the model."
딥러닝 기반의 2차원 이미지 왜곡 분류 및 이미지 각도 보정 시스템 개발,2022,"['Neural Network', 'Image Processing', 'Image Distortion', 'Camera Calibration']",,"When taking a picture with a camera, the distortion that is different from reality occurs due to wide-angle lenses and camera angles.In this paper, we propose an image distortion classification and calibration program that provides users with standard images before distortion by classification and calibrating distortion. The program automatically predicts camera parameters from a single input image and proceeds with calibration. Inputting the image, distortion image classification using deep learning (CNN) determines whether Wide-angle lens distortion and Camera-angle distortion exist. When it is determined that distortion exists, deep learning and OpenCV are used to calibrate the distortion state according to each image characteristic. As a result of the program operation, it was confirmed that the output image was calibrated similarly to the actual one, and more fine distortion calibration can be expected by finding distortions that were difficult to judge only with human eyes."
메타버스를 위한 가상 휴먼의 3차원 의상 모델링,2022,"['Metaverse', 'virtual human', '3D cloth modeling']",,"In this paper, we propose the new method of creating 3D virtual-human reflecting the pattern of clothes worn by the person in thehigh-resolution whole body front image and the body shape data about the person. To get the pattern of clothes, we proceed InstanceSegmentation and clothes parsing using Cascade Mask R-CNN. After, we use Pix2Pix to blur the boundaries and estimate the backgroundcolor and can get UV-Map of 3D clothes mesh proceeding UV-Map base warping. Also, we get the body shape data using SMPL-X anddeform the original clothes and body mesh. With UV-Map of clothes and deformed clothes and body mesh, user finally can see theanimation of 3D virtual-human reflecting user’s appearance by rendering with the state-of-the game engine, i.e. Unreal Engine."
DeepLabV3+와 Swin Transformer 모델을 이용한 Sentinel-2 영상의 구름탐지,2022,"['Cloud detection', 'Deep learning', 'Sentinel-2']",,"Sentinel-2 can be used as proxy data for the Korean Compact Advanced Satellite 500-4 (CAS500-4), also known as Agriculture and Forestry Satellite, in terms of spectral wavelengths and spatial resolution. This letter examined cloud detection for later use in the CAS500-4 based on deep learning technologies. DeepLabV3+, a traditional Convolutional Neural Network (CNN) model, and Shifted Windows (Swin) Transformer, a state-of-the-art (SOTA) Transformer model, were compared using 22,728 images provided by Radiant Earth Foundation (REF). Swin Transformer showed a better performance with a precision of 0.886 and a recall of 0.875, which is a balanced result, unbiased between over- and under-estimation. Deep learning-based cloud detection is expected to be a future operational module for CAS500-4 through optimization for the Korean Peninsula."
음압자료를 이용한 해저면 분류 기술 현황,2022,"['해저면 원격 분류', '멀티빔 음향시스템', '후방산란', '해저 서식지', 'Remote Seabed Classification', 'Multibeam Echosounder', 'Backscatter', 'Benthic Habitat Map']",,"This paper is intended to share basic information to advance the acoustic seabed classification technology. Chapter 1 describes the necessity and basic concept of the corresponding technology, and Chapter 2 summarizes the current trends of acoustic seabed classification technology, which is based on international case studies such as QTC-Multiview, Self-Organizing Map, APL model, Angular Response Analysis, Improved SOM, CNN, etc. Chapter 3 discusses the research topics to enhance detectability and recognizability for the sediment type and to improve the accuracy of the classification. The research topics include methodologies to obtain the ground-truth suitable to the penetration depth of acoustic waves and the consistency of backscatter data."
파워쉘 기반 악성코드에 대한 역난독화 처리와 딥러닝 기반 탐지 방법,2022,"['Powershell', 'deobfuscation', 'deep learning']","2021년에는 코로나의 여파로 랜섬웨어를 활용한 공격이 유행했으며 그 수는 매년 급증하고 있다. 그 중 파워쉘은 랜섬웨어에 주요 기술로 사용되고 있어 파워쉘 기반 악성코드 탐지 기법의 필요성은 증가하고 있으나 기존의 탐지 기법은 난독화가 적용된 스크립트를 탐지하지 못하거나 역난독화에 시간이 오래 소요되는 한계가 존재한다. 이에 본 논문에서는 간단하고 빠른 역난독화 처리과정, Word2Vec과 CNN(Convolutional Neural Network)으로 구성되어 스크립트의 의미를 학습하고 특징을 추출해 악성 여부를 판단할 수 있는 딥러닝 기반의 분류 모델을 제안한다. 2021 사이버보안 AI/빅데이터 활용 경진대회의 AI 기반 파워쉘 악성 스크립트 탐지 트랙에서 제공된 1400개의 악성코드와 8600개의 정상 스크립트를 이용하여 제안한 모델을 테스트한 결과 기존보다 5.04배 빠른 역난독화 실행 시간, 100%의 역난독화 성공률, 0.01의 FPR(False Positve Rate), 0.965의 TPR(True Positive Rate)로 악성코드를 빠르고 효과적으로 탐지함을 보인다.",
이동통신 시스템에서 인공지능을 이용한 경로 손실 예측 및 기지국 지형 구분 방법,2022,,"이동통신 시스템에서 정확하고 신속한 통신망 구축은 중요하다. 현재 무선통신 시스템을 구성하기 위해서는 셀 플래닝 장비를 통해 기지국의 파라미터를 설정한다. 하지만 기지국의 신규 설치마다 셀 플래닝을 새로 수행해야 하며, 셀 플래닝에 반영되지 않은 장애물 정보 등 실제 환경과 맞지 않는 파라미터가 설정되는 문제가 발생할 수 있다. 이 논문에서는 SON 서버에서 기지국의 위치와 단말의 측정 정보를 이용한 DNN 모델을 통해 경로 손실 예측을 수행하고, 지형을 구분하는 CNN 모델을 통해 예측된 경로 손실의 지형을 구분한다. 구분된 지형을 바탕으로 SON 서버에서 해당 지형에 맞는 지형별 기지국 파라미터를 자동으로 설정하고 지속해서 지형별 파라미터를 업데이트하여, 지형과 주변 환경 변화를 고려한 기지국 파라미터를 자동으로 설정할 수 있다.",
A Study on Finding Emergency Conditions for Automatic Authentication Applying Big Data Processing and AI Mechanism on Medical Information Platform,2022,"['AI Mechanism & Big Data Processing', 'Automatic Authentication', 'Edge Computing', 'Emergency Conditions', 'Medical Information Platform']",,"We had researched an automatic authentication-supported medical information platform[6]. The proposed automatic authentication consists of user authentication and mobile terminal authentication, and the authentications are performed simultaneously in patients’ emergency conditions. In this paper, we studied on finding emergency conditions for the automatic authentication by applying big data processing and AI mechanism on the extended medical information platform with an added edge computing system. We used big data processing, SVM, and 1-Dimension CNN of AImechanism to find emergency conditions as authentication means considering patients’ underlying diseases such as hypertension, diabetes mellitus, and arrhythmia. To quickly determine a patient’s emergency conditions, we placed edge computing at the end of the platform. The medical information server derives patients’ emergency conditions decision values using big data processing and AI mechanism and transmits the values to an edge node. If the edge node determines the patient emergency conditions, the edge node notifies the emergency conditions to the medical information server. The medical server transmits an emergency message to the patient’s charge medical staff. The medical staff performs the automatic authentication using a mobile terminal. After the automatic authentication is completed, the medical staff can access the patient’s upper medical information that was not seen in the normal condition."
연구개발정보 문헌 자동분류를 위한 자연어 처리 딥러닝 모델 개발: 기후기술 분류체계를 중심으로,2022,"['Multi-class classification', 'Natural language', 'Deep learning', 'Climate technology']","신기후체제에 들어서며 전세계적으로 탄소중립을 선언하고 있으며 이를 위해 국가연구개발사업이 어떤 기후기술에 투자되고 있는지 관심이 고조되고 있다. 본 연구에서는 국가연구개발사업들의 문헌정보를 활용하여 45개의 기후기술 분류체계로 자동분류하는 딥러닝 모델을 개발하였다. NTIS에 등록되어 있는 2016∼2020년에 수행된 291,381건의 연구개발과제 중 2016∼2019년의 217,880건은 훈련 데이터셋으로, 2020년의 73,501건은 테스트 데이터셋으로 구분하여 실험하였다. 형태소 분석을 위해 kiwi와 Mecab을 사용하였으며 딥러닝 모델의 구조는 1D-CNN을 활용한 FC, EC 모델과 ELECTRA 사전학습 모델을 활용한 KoE 모델을 개발하였다. 각 클래스별 빈도의 편차가 큰 불균형데이터임을 고려하여 성능지표로 F1 스코어를 활용하였으며 각 개별모델과 앙상블 모델의 성능을 확인하였다. 개별모델에서는 키워드 빈도를 중심으로 학습하는 FC 모델이 0.824의 F1 스코어로 가장 우수했으며, 앙상블 모델에서는 개별모델 모두를 소프트 보팅(soft voting)한 Ens4 모델이 0.833의 F1 스코어로 가장 높은 성능을 나타냈다. 일반적인 말뭉치보다 전문적인 용어를 다수 포함하고 있는 대량의 기술문서 자동분류에서 본 모델을 사용한다면 기술전문가가 직접 라벨링하는 방법보다 보다 효율적인 프로세스를 갖출 수 있을 것이다.",
XAI 기반 반려견 품종 분류,2022,"['Explainable Artificial intelligence', 'Xception', 'Convolutional neural network', 'Dog breed', 'Local interpretable model-agnostic explanation']","최근 반려견에 대한 관심이 날이 갈수록 뜨거워지고 있다. 우리나라는 반려견을 기르는 인구가 급증하면서 '펫코노미’ 시대가 도래했다. 2020년 현재 반려견은 약 512만 가구에서 기르는 것으로 나타났다. 사람들은 반려견을 입양할 때 외모와 성격에 따라 견종을 선택한다. 하지만 펫샾에서 더 비싼 품종으로 속이는 문제가 발생해오고 있다. 이에 딥러닝을 이용한 품종 구별에 관한 연구가 활발히 진행되어왔다. 하지만 딥러닝을 이용한 품종 구별 방법을 구매자가 이해하는 것은 어렵다. 이러한 문제를 해결하기 위해 본 논문에서 우리는 반려견의 품종을 구별하는 CNN 기반의 딥러닝 모델을 구축한 후 이를 XAI 기법 중 하나인 LIME을 이용하여 분류 근거를 이미지로 보여준다. 데이터 셋을 위해 우리나라에서 가장 많이 키우는 견종을 선정한 후, 서로 구분이 어려운 품종들을 추가하였다. 그런 다음 실험들을 통해 최적의 하이퍼파라미터들을 찾아 분류의 근거를 가장 잘 보여주는 이미지를 추출했다. 이를 근거로 펫을 입양하는 사람은 자신이 입양하려는 펫의 품종을 믿을 수 있고, 펫샵 역시 품종의 근거를 제시함으로써 신뢰를 구축할 수 있다.",
합성곱신경망을 활용한 과구동기 시스템을 가지는 소형 무인선의 추진기 고장 감지,2022,"['Unmanned surface vehicle(무인 수상 선박)', 'Fault detection(고장 감지)', 'Convolutional neural network(합성곱신경망)', 'ROS', 'Overacturated(과구동기)', 'Wavelet transform(웨이블렛 변환)']",,"This paper proposes a fault detection method for a Unmanned Surface Vehicle (USV) with overactuated system. Current status information for fault detection is expressed as a scalogram image. The scalogram image is obtained by wavelet-transforming the USVs control input and sensor information. The fault detection scheme is based on Convolutional Neural Network (CNN) algorithm. The previously generated scalogram data was transferred learning to GoogLeNet algorithm. The data are generated as scalogram images in real time, and fault is detected through a learning model. The result of fault detection is very robust and highly accurate."
A deep learning approach to permanent tooth germ detection on pediatric panoramic radiographs,2022,"['Tooth Germ', 'Radiograph', 'Panoramic', 'Pediatric Dentistry']",,"Purpose: The aim of this study was to assess the performance of a deep learning system for permanent tooth germ detection on pediatric panoramic radiographs. Materials and Methods: In total, 4518 anonymized panoramic radiographs of children between 5 and 13 years of age were collected. YOLOv4, a convolutional neural network (CNN)-based object detection model, was used to automatically detect permanent tooth germs. Panoramic images of children processed in LabelImg were trained and tested in the YOLOv4 algorithm. True-positive, false-positive, and false-negative rates were calculated. A confusion matrix was used to evaluate the performance of the model. Results: The YOLOv4 model, which detected permanent tooth germs on pediatric panoramic radiographs, provided an average precision value of 94.16% and an F1 value of 0.90, indicating a high level of significance. The average YOLOv4 inference time was 90 ms. Conclusion: The detection of permanent tooth germs on pediatric panoramic X-rays using a deep learning-based approach may facilitate the early diagnosis of tooth deficiency or supernumerary teeth and help dental practitioners find more accurate treatment options while saving time and effort"
사물인터넷 기기 고장 진단을 위한 그래프 신경망 모델 기반 분류 방법,2022,"['Graph convolutional networks', 'Convolutional neural networks', 'Fault diagnosis', 'Internet of things']","각종 기기들이 연결되는 사물인터넷(internet of things) 시스템에서 중요한 부품의 고장은 경제적, 인명의 손실을 야기할 수 있다. 시스템 내에서 발생하는 고장으로 인한 손실을 줄이기 위해 고장 검진 기술이 IoT에서 중요한 기술로써 여겨지고 있다. 본 논문에서는 그래프 신경망 기반 방법을 사용하여 시스템 내의 설비에서 취득된 진동 데이터의특징을 추출하여 고장 여부를 판단하고 유형을 분류하는 방법을 제안한다. 딥러닝 모델의 학습을 위해, CWRU(case western reserve university)에서 취득된 고장 데이터 셋을 입력 데이터로 사용한다. 제안하는 모델의 분류 정확도 성능을 확인하기 위해 기존 제안된 합성곱 신경망(convolutional neural networks) 기반 분류 모델과 제안된 모델을비교한다. 시뮬레이션 결과, 제안된 모델은 불균등하게 나누어진 데이터에서 기존 모델보다 분류 정확도를 약 5% 향상시킬 수 있는 것을 확인하였다. 이후 연구로, 제안하는 모델을 경량화해서 분류 속도를 개선할 예정이다.","In the IoT(internet of things) where various devices can be connected, failure of essential devices may lead to a lot of economic and life losses. For reducing the losses, fault diagnosis techniques have been considered an essential part of IoT. In this paper, the method based on a graph neural network is proposed for determining fault and classifying types by extracting features from vibration data of systems. For training of the deep learning model, fault dataset are used as input data obtained from the CWRU(case western reserve university). To validate the classification performance of the proposed model, a conventional CNN(convolutional neural networks)―based fault classification model is compared with the proposed model. From the simulation results, it was confirmed that the classification performance of the proposed model outweighed the conventional model by up to 5% in the unevenly distributed data. The classification runtime can be improved by lightweight the proposed model in future works."
한국 남부 해역 SST의 계절 및 경년 변동이 단기 딥러닝 모델의 SST 예측에 미치는 영향,2022,"['Short-term U-Net based SST prediction', 'PDO and Seasonal Variabilities']",,"Sea Surface Temperature (SST), one of the ocean features, has a significant impact on climate, marine ecosystem and human activities. Therefore, SST prediction has been always an important issue. Recently, deep learning has drawn much attentions, since it can predict SST by training past SST patterns. Compared to the numerical simulations, deep learning model is highly efficient, since it can estimate nonlinear relationships between input data. With the recent development of Graphics Processing Unit (GPU) in computer, large amounts of data can be calculated repeatedly and rapidly. In this study, Short-term SST will be predicted through Convolutional Neural Network (CNN)-based U-Net that can handle spatiotemporal data concurrently and overcome the drawbacks of previously existing deep learning-based models. The SST prediction performance depends on the seasonal and interannual SST variabilities around the southern coast of Korea. The predicted SST has a wide range of variance during spring and summer, while it has small range of variance during fall and winter. A wide range of variance also has a significant correlation with the change of the Pacific Decadal Oscillation (PDO) index. These results are found to be affected by the intensity of the seasonal and PDO-related interannual SST fronts and their intensity variations along the southern Korean seas. This study implies that the SST prediction performance using the developed deep learning model can be significantly varied by seasonal and interannual variabilities in SST."
레이저 변위 센서를 활용한 배관 표면 상태분류,2022,"['Pipe(배관)', 'Laser Displacement Sensor(레이저 변위 센서)', 'Convolution Neural Network(합성곱신경망)', 'VGGNet(VGGNet)', 'State Classification(상태분류)']",,"Although pipe performs various functions in industrial sites and residential spaces, if it is damaged due to corrosion caused by the external environment, it may cause equipment failure or a major accident. For this reason, various studies for safety management are being conducted, but studies on detecting corrosion or cracks on the pipe surface using a laser displacement sensor have hardly been conducted. Therefore, in this study, the corrosion degree of the pipe surface was compared and classified into 4 corrosion conditions, and inspection equipment using a laser scanner was manufactured. The corrosion height was calculated from the four surface data obtained from the measuring equipment and applied to various CNN algorithms, and 91% accuracy was obtained during training using the Modified VGGNet16 code with reduced number of parameters."
멀티 채널 충전 프로파일과 방전 용량을 사용한 딥러닝 기반 리튬 이온 배터리 건강 상태 추정,2022,"['Artificial Neural Network', 'BMS(Battery Management System)', 'Deep Learning', 'Lithium-ion Battery', 'SOH(State-of-Health)']","리튬 이온 배터리팩의 안전하고 효율적인 사용을 위해서는 배터리의 상태를 모니터링하는 것이 중요하다. 다양한 배터리의 상태지표 중에서도 배터리의 성능과 수명을 대표하는 SOH(State-of-Health)를 추정할 필요가 있다.본 논문에서는 다양한 구조의 인공신경망을 사용하여 SOH를 추정하였다. SOH 추정을 위한 입력으로 배터리의충전중 전압, 전류, 온도의 측정치를 사용하였다. 또한 방전 중에 전류적산법을 통해 추정된 배터리의 용량을 충전중에 기록된 측정치와 함께 입력으로 사용하여 성능을 개선한 모델을 제안한다. 순방향 신경망, 합성곱 신경망, 장단기 메모리 모델의 SOH 추정 성능을 평가하였고, 방전 용량을 모델의 입력으로 사용하면 모델의 성능이 크게향상됨을 확인하였다.","For safe and efficient use of lithium ion battery pack, it is important to monitor the states of battery.Among various states of battery, it is required to estimate SOH (State-of-Health), which represents the performance and life of battery. In this paper, we estimate SOH using various structures of artificial neural network (ANN). We use the measured voltage, current, and temperature of battery cell during charging process as a feature to estimate SOH. We also use the discharged capacity, measured by the coulomb counting method, of battery cell as the feature. We evaluate the performance of various structures of ANN such as feedforward neural network (FNN), convolutional neural network (CNN) and long short-term memory (LSTM) and confirm that the use of discharged capacity significantly improves the SOH estimation performance."
Application of the machine learning technique for the development of a condensation heat transfer model for a passive containment cooling system,2022,"['PCCS', 'Condensation heat transfer', 'Non-condensable gas', 'Machine learning']",,"A condensation heat transfer model is essential to accurately predict the performance of the passivecontainment cooling system (PCCS) during an accident in an advanced light water reactor. However,most of existing models tend to predict condensation heat transfer very well for a specific range ofthermal-hydraulic conditions. In this study, a new correlation for condensation heat transfer coefficient(HTC) is presented using machine learning technique. To secure sufficient training data, a large numberof pseudo data were produced by using ten existing condensation models. Then, a neural network modelwas developed, consisting of a fully connected layer and a convolutional neural network (CNN) algorithm, DenseNet. Based on the hold-out cross-validation, the neural network was trained and validatedagainst the pseudo data. Thereafter, it was evaluated using the experimental data, which were not usedfor training. The machine learning model predicted better results than the existing models. It was alsoconfirmed through a parametric study that the machine learning model presents continuous andphysical HTCs for various thermal-hydraulic conditions. By reflecting the effects of individual variablesobtained from the parametric analysis, a new correlation was proposed. It yielded better results foralmost all experimental conditions than the ten existing models."
회전기계를 위한 건전성 예측 및 관리 시스템 개발과 로터리 테이블에 적용,2022,"['스마트팩토리', '건전성 예측 및 관리', '딥러닝', '합성곱 신경망', 'Smart factory', 'Prognostics and health management', 'Deep learning', 'Convolutional neural network']",,"Recently, interest in Prognostics and Health management (PHM) has been increasing as an advanced technology of maintenance. PHM technology is a technology that allows equipment to check its condition and predict failures in advance. To realize PHM technology, it is important to implement artificial intelligence technology that diagnoses failures based on data. Vibration data is often used to diagnose the state of the rotating machine. Additionally, there have been many efforts to convert vibration data into 2D images to apply a convolutional neural network (CNN), which is emerging as a powerful algorithm in the image processing field, to vibration data. In this study, a series of PHM processes for acquiring data from a rotary machine and using it to check the condition of the machine were applied to the rotary table. Additionally, a study was conducted to introduce and compare two methodologies for converting vibration data into 2D images. Finally, a GUI program to implement the PHM process was developed."
머신러닝 분류기를 사용한 만성콩팥병 자동 진단 및 중증도 예측 연구,2022,"['chronic kidney disease', 'machine learning', 'automatic classification']",,"This paper proposes an optimal methodology for automatically diagnosing and predicting the severity of the chronic kidney disease (CKD) using patients’ utterances. In patients with CKD, the voice changes due to the weakening of respiratory and laryngeal muscles and vocal fold edema. Previous studies have phonetically analyzed the voices of patients with CKD, but no studies have been conducted to classify the voices of patients. In this paper, the utterances of patients with CKD were classified using the variety of utterance types (sustained vowel, sentence, general sentence), the feature sets [handcrafted features, extended Geneva Minimalistic Acoustic Parameter Set (eGeMAPS), CNN extracted features], and the classifiers (SVM, XGBoost). Total of 1,523 utterances which are 3 hours, 26 minutes, and 25 seconds long, are used. F1-score of 0.93 for automatically diagnosing a disease, 0.89 for a 3-classes problem, and 0.84 for a 5-classes problem were achieved. The highest performance was obtained when the combination of general sentence utterances, handcrafted feature set, and XGBoost was used. The result suggests that a general sentence utterance that can reflect all speakers’ speech characteristics and an appropriate feature set extracted from there are adequate for the automatic classification of CKD patients’ utterances."
디지털 농업을 위한 피드백 기반 스마트 관개 시스템,2022,"['Digital Argriculture', 'Irrigation System', 'Machine Learning', 'Soil Texture Classification', 'Smart Farm', '수확로봇', '이송로봇', '수확속도', '다수로봇운용', '그린하우스 로봇']","디지털 농업은 농업 현장에서 발생하는 현상을 디지털화하여 농업 활동의 편의성과 생산성을 향상시킬 수 있는기술이다. 관개 시스템은 농업에서 가장 중요한 요소이다. 관개 시스템에 대한 자동화는 다양하게 진행되고 있다.하지만, 대부분의 연구에서 초기 설정에 따라 획일적인 주기로 관개를 실행하기 때문에 관리자의 개입이 필요한단점을 가진다. 본 연구는 기존 연구에서 발생했던 단점을 보완하기 위하여 실시간 토양 변화를 감지하여 머신러닝을 기반으로 토성을 분류할 수 있는 능동적인 스마트 관개 시스템을 제안한다. 능동적인 스마트 관개 시스템을구축하기 위해서 토성 분석 기술과 소프트웨어 업데이트 기술이 필요하다. 토성 분류를 위해서 토양 변화에 대한시계열 데이터를 기반으로 합성곱신경망, 순환신경망, 장단기 메모리와 같은 머신러닝 모델을 설계하였다. 또한, 토성 분류 결과를 원격지에 설치된 관개 제어기로 전송 및 수정할 수 있는 아키텍처를 제안한다. 머신러닝 모델을평가하기 위해서 100회 반복하여 수행된 결과를 혼동행렬을 적용하여 신뢰성을 평가하였으며, 약 90%의 모델 신뢰성을 가지는 것을 확인하였다. 변경된 토성 분류 결과를 데이터베이스에서 관개 제어기로 전송하는 원격 시스템의 안정성을 검증하였다.","Digital agriculture is able to improve the convenience and productivity by digitalizing occurred event in agricultural process. The irrigation system is the most important element in agricultural process. There are various research on automation of irrigation system. Most of research have the disadvantage that administrator need to intervene to irrigate. In this work, we propose a smart irrigation system that can monitor agricultural environment and can decide irrigation period and irrigation time. Also, we design machine learning models base on time series data such as CNN, Simple RNN, LSTM to classified soil texture. Performance of the classification algorithm was evaluated using the confusion matrix, the classification performance was evaluated about 90%. In order to implement tiny machine learning on an embedded system in future work., we will consider Simple RNN that has the fewest parameters of them."
Application of a deep learning algorithm to Compton imaging of radioactive point sources with a single planar CdTe pixelated detector,2022,"['CdTe', 'Compton imaging', 'Deep learning', 'Machine learning', 'Convolutional neural networks']",,"Compton imaging is the main method for locating radioactive hot spots emitting high-energy gammaray photons. In particular, this imaging method is crucial when the photon energy is too high for codedmask aperture imaging methods to be effective or when a large field of view is required. Reconstructionof the photon source requires advanced Compton event processing algorithms to determine the exactposition of the source. In this study, we introduce a novel method based on a Deep Learning algorithmwith a Convolutional Neural Network (CNN) to perform Compton imaging. This algorithm is trained onsimulated data and tested on real data acquired with Caliste, a single planar CdTe pixelated detector. Weshow that performance in terms of source location accuracy is equivalent to state-of-the-art algorithms,while computa"
Study on the University Students’ Behaviors of Linguistic Information Process and Learning Strategies through Note-taking Task,2022,"['note taking activity', 'information process', 'listening skills', 'scaffolding support', 'teacher’s guidance']",,"Note-taking tasks can be considered a process to achieve communication by helping learners organize linguistic information they strive to convey through cognitive activities. To successfully communicate, learners must develop various linguistic and cognitive skills, such as advanced listening proficiency and the reconstruction of intended stories. This study aims to discover the major types of errors affecting university-level learners’ note-taking activities and a teacher’s scaffolding guidance in order to foster note-taking skills and learning strategies. Seventy-nine university students enrolled in an audio visual English class took part in this study. They were required to routinely carry out note-taking activities by watching both CNN news reports and academic lectures dealing with social issues. This study found that the learners routinely missed a substantial number of content words despite repetitive note-taking tasks. In addition, important phrases were omitted due to variations in pronunciation, unfamiliar proper nouns, and complex numbers. It was also revealed that students appeared to struggle with several abbreviations and symbols when reconstructing the meaning of the information. In order to tackle these problems, various teaching strategies were introduced and implemented to increase note-taking effectiveness as well as maximize learners’ confidence and help them more accurately grasp the content. Based on these results, this study recommends providing structured scaffolding for learners to perform effective and efficient note-taking tasks. This will have a positive influence on learning strategies. It will also encourage students to actively participate in tasks and produce well-organized information on given subjects, which require linguistic information processing."
객체 검출과 객체 분할 방법의 무인 감시 데이터셋 적용 결과 비교,2022,"['Visual surveillance', 'Deep learning', 'Transformer', 'Semantic segmentation', 'Object detection', '.']",,.
Scaling Up Face Masks Classification Using a Deep Neural Network and Classical Method Inspired Hybrid Technique,2022,"['CNNs', 'Face masks', 'Machine learning', 'Multi-layer perceptron', 'ResNet-101']",,"Classification of persons wearing and not wearing face masks in images has emerged as a new computer vision problem during the COVID-19 pandemic. In order to address this problem and scale up the research in this domain, in this paper a hybrid technique by employing ResNet-101 and multi-layer perceptron (MLP) classifier has been proposed. The proposed technique is tested and validated on a self-created face masks classification dataset and a standard dataset. On self-created dataset, the proposed technique achieved a classification accuracy of 97.3%. To embrace the proposed technique, six other state-of-the-art CNN feature extractors with six other classical machine learning classifiers have been tested and compared with the proposed technique. The proposed technique achieved better classification accuracy and 1-6% higher precision, recall, and F1 score as compared to other tested deep feature extractors and machine learning classifiers."
A Computerized Doughty Predictor Framework for Corona Virus Disease: Combined Deep Learning based Approach,2022,"['Adaptive Dragonfly Algorithm', 'Auto Augmentation', 'COVID-19 Predictor', 'Deep Learning', 'Ensemble Learning', 'Image Processing', 'UNet Segmentation']",,"Nowadays, COVID-19 infections are influencing our daily lives which have spread globally. The major symptoms’ of COVID-19 are dry cough, sore throat, and fever which in turn to critical complications like multi organs failure, acute respiratory distress syndrome, etc. Therefore, to hinder the spread of COVID-19, a Computerized Doughty Predictor Framework (CDPF) is developed to yield benefits in monitoring the progression of disease from Chest CT images which will reduce the mortality rates significantly. The proposed framework CDPF employs Convolutional Neural Network (CNN) as a feature extractor to extract the features from CT images. Subsequently, the extracted features are fed into the Adaptive Dragonfly Algorithm (ADA) to extract the most significant features which will smoothly drive the diagnosing of the COVID and Non-COVID cases with the support of Doughty Learners (DL). This paper uses the publicly available SARS-CoV-2 and Github COVID CT dataset which contains 2482 and 812 CT images with two class labels COVID+ and COVID-. The performance of CDPF is evaluated against existing state of art approaches, which shows the superiority of CDPF with the diagnosis accuracy of about 99.76%."
A Model for Machine Fault Diagnosis based on Mutual Exclusion Theory and Out-of-Distribution Detection,2022,"['out-of-distribution', 'convolutional neural network', 'mutually exclusive events', 'fusion networks', 'autoencoder']",,"The primary task of machine fault diagnosis is to judge whether the current state is normal or damaged, so it is a typical binary classification problem with mutual exclusion. Mutually exclusive events and out-of-domain detection have one thing in common: there are two types of data and no intersection. We proposed a fusion model method to improve the accuracy of machine fault diagnosis, which is based on the mutual exclusivity of events and the commonality of out-of-distribution detection, and finally generalized to all binary classification problems. It is reported that the performance of a convolutional neural network (CNN) will decrease as the recognition type increases, so the variational auto-encoder (VAE) is used as the primary model. Two VAE models are used to train the machine's normal and fault sound data. Two reconstruction probabilities will be obtained during the test. The smaller value is transformed into a correction value of another value according to the mutually exclusive characteristics. Finally, the classification result is obtained according to the fusion algorithm. Filtering normal data features from fault data features is proposed, which shields the interference and makes the fault features more prominent. We confirm that good performance improvements have been achieved in the machine fault detection data set, and the results are better than most mainstream models."
정적 영상 기반 행동 인식을 활용한 낙상 감지 기술 및 운전자 부주의 감지 기술 개발,2022,"['Still Image-based Action Recognition', 'Fall Detection', 'Driver Drowsiness Detection', 'Hazardous Event Detection', '.']",,.
A Deep Learning Method for Brain Tumor Classification Based on Image Gradient,2022,"['Brain Tumor Classification', 'Image Gradient', 'Deep Learning', 'Convolutional Neural Network']",,"Tumors of the brain are the deadliest, with a life expectancy of only a few years for those with the most advanced forms. Diagnosing a brain tumor is critical to developing a treatment plan to help patients with the disease live longer. A misdiagnosis of brain tumors will lead to incorrect medical treatment, decreasing a patient's chance of survival. Radiologists classify brain tumors via biopsy, which takes a long time. As a result, the doctor will need an automatic classification system to identify brain tumors. Image classification is one application of the deep learning method in computer vision. One of the deep learning's most powerful algorithms is the convolutional neural network (CNN). This paper will introduce a novel deep learning structure and image gradient to classify brain tumors. Meningioma, glioma, and pituitary tumors are the three most popular forms of brain cancer represented in the Figshare dataset, which contains 3,064 T1-weighted brain images from 233 patients. According to the numerical results, our method is more accurate than other approaches."
방사선 투과 이미지에서의 용접 결함 검출을 위한 딥러닝 알고리즘 비교 연구,2022,"['Radiographic Testing', 'Welding Defect', 'Deep Learning']",,"An automated system is needed for the effectiveness of non-destructive testing. In order to utilize the radiographic testing data accumulated in the film, the types of welding defects were classified into 9 and the shape of defects were analyzed. Data was preprocessed to use deep learning with high performance in image classification, and a combination of one-stage/two-stage method and convolutional neural networks/Transformer backbone was compared to confirm a model suitable for welding defect detection. The combination of two-stage, which can learn step-by-step, and deep-layered CNN backbone, showed the best performance with mean average precision 0.868."
인공지능과 자율운용 기술을 이용한 긴급형 이동통신 기지국 자율설정 및 최적화,2022,"['Mobile Communication Network', 'SON(Self-Organization Network)', 'AI(Artificial Intelligence)', 'Tactical Network', 'Public Safety Network', '이동통신 네트워크', '자율운용', '인공지능', '전술 네트워크', '재난망']","긴급 상황에 대비하는 재난망이나 전술 이동통신 네트워크는 현장에 적응하여 신속하고 정확하게 구축하는 것이 중요하다. 전통적인 무선통신 시스템을 구성하기 위해서는 셀 플래닝 장비를 통해 기지국의 파라미터를 설정한다. 하지만 셀 플래닝을 위해서는 환경에 대한 정보나 데이터가 사전에 구축되어 있어야 하며, 셀 플래닝에 반영되지 않아 현장에 맞지 않는 파라미터가 사용되면 네트워크 구축 후 문제의 해결 및 성능 향상을 위해서 별도의 최적화가 진행되어야 한다. 이 논문에서는 이동통신 기지국에서의 인공지능(AI)과 자율운용(SON) 기술을 사용한 신속한 이동통신망 구축 및 최적화 방법을 제시한다. 기지국의 위치와 단말의 측정 정보를 이용한 DNN 모델을 통해 경로 손실 예측을 수행하여 지형을 구분하는 CNN 모델을 기지국 파라미터를 자동으로 설정한 후, 운용 중에 수집되는 데이터로 경로 손실 모델을 학습시키며 이를 이용해 Coverage/Capacity 최적화를 지속적으로 수행할 수 있도록 한다.",
Use of Machine Learning in Stroke Rehabilitation: A Narrative Review,2022,"['Machine Learning', 'Artificial Intelligence', 'Stroke', 'Rehabilitation', 'Deep Learning']",,"A narrative review was conducted of machine learning applications and research in the field of stroke rehabilitation. The machine learning models commonly used in medical research include random forest, logistic regression, and deep neural networks. Convolutional neural networks (CNNs), a type of deep neural network, are typically used for image analysis.Machine learning has been used in stroke rehabilitation to predict recover y of motor function using a large amount of clinical data as input. Recent studies on predicting motor function have trained CNN models using magnetic resonance images as input data together with clinical data to increase the accuracy of motor function prediction models. Additionally, a model interpreting videofluoroscopic swallowing studies was developed and investigated. In the future, we anticipate that machine learning will be actively used to treat stroke patients, such as predicting the occurrence of depression and the recover y of language, cognitive, and sensor y function, as well as prescribing appropriate rehabilitation treatments"
Crack Detection Based on Generative Adversarial Networks and Deep Learning,2022,"['Structural health monitoring', 'Generative adversarial network', 'Generated images', 'Crack classification', 'Crack segmentation']",,"This paper proposes a novel crack detection method using the three-stages detection model. Deep learning technology has been a focus of attention in the field of crack detection; however, it needs big data to train the corresponding network model. More training samples and the combination of multiple deep learning algorithms help to improve the detection performance. Therefore, this paper employed a generative adversarial network (GAN) model to generate abundant virtual crack images with similar features to real images, these virtual images are used to train the CNN classifier and DeepLab_v3+ respectively, and then the real images are used to evaluate the performance of the three-stages detection method. The results show that the proposed three-stages detection method has excellent detection effect on the crack detection is better than that of the control experiment (the NI_MIoU, NI_Accuracy, NI_F-score and NI_MCC are increased by 22.1% − 55.6%, 5.2% − 9.8%, 37.4% − 40.0% and 6.2% − 11.1%, respectively)). These results demonstrate that the three-stages detection model has made a beneficial contribution to the crack detection."
합성곱 신경망을 이용한 선박의 잉여저항계수 추정,2022,,,"In the design stage of hull forms, a fast prediction method of resistance performance is needed. In these days, large test matrix of candidate hull forms is tested using Computational Fluid Dynamics (CFD) in order to choose the best hull form before the model test. This process requires large computing times and resources. If there is a fast and reliable prediction method for hull form performance, it can be used as the first filter before applying CFD. In this paper, we suggest the offset-based performance prediction method. The hull form geometry information is applied in the form of 2D offset (non-dimensionalized by breadth and draft), and it is studied using Convolutional Neural Network (CNN) and adapted to the model test results (Residual Resistance Coefficient; C<sub>R</sub>). Some additional variables which are not included in the offset data such as main dimensions are merged with the offset data in the process. The present model shows better performance comparing with the simple regression models."
Classification of dog skin diseases using deep learning with images captured from multispectral imaging device,2022,"['Deep learning', 'Dog skin disease', 'Multispectral image', 'Dermatosis']",,"Background Dog-associated infections are related to more than 70 human diseases. Given that the health diagnosis of a dog requires expertise of the veterinarian, an artificial intelligence model for detecting dog diseases could significantly reduce time and cost required for a diagnosis and efficiently maintain animal health.Objective We collected normal and multispectral images to develop classification model of each three dog skin diseases (bacterial dermatosis, fungal infection, and hypersensitivity allergic dermatosis). The single models (normal image- and multispectral image-based) and consensus models were developed used to four CNN model architecture (InceptionNet, ResNet, DenseNet, MobileNet) and select well-performed model.Results For single models, such as normal image- or multispectral image-based model, the best accuracies and Matthew’s correlation coefficients (MCCs) for validation data set were 0.80 and 0.64 for bacterial dermatosis, 0.70 and 0.36 for fungal infection, and 0.82 and 0.47 for hypersensitivity allergic dermatosis. For the consensus models, the best accuracies and MCCs for the validation set were 0.89 and 0.76 for the bacterial dermatosis data set, 0.87 and 0.63 for the fungal infection data set, and 0.87 and 0.63 for the hypersensitivity allergic dermatosis data set, respectively, which supported that the consensus models of each disease were more balanced and well-performed.Conclusions We developed consensus models for each skin disease for dogs by combining each best model developed with the normal and multispectral images, respectively. Since the normal images could be used to determine areas suspected of lesion of skin disease and additionally the multispectral images could help confirming skin redness of the area, the models achieved higher prediction accuracy with balanced performance between sensitivity and specificity."
딥러닝을 이용한 안과 질환 자동화 진단시스템,2022,"['Automated Diagnostics', 'Convolution neural network', 'Deep learning', 'Eye disease', 'Image classification']",,"Because the face of population ageing is much faster, early diagnosis of the eye diseases is important. As for the diagnosis, a fundus photography is popular. However, it is very difficult to make exact diagnosis due to blurred images, diagnosis time and human errors, which results in misdiagnosis and blindness in worst case scenario. To solve the problems, machine learning based diagnosis systems were suggested. However, the machine learning based systems inevitably contained expert parameters, like C for margins and gamma for boundary conditions as in support vector machines. Recently, as deep learning methods have been popular, the convolutional neural network (CNN) based image classifications are being used for eye disease diagnosis. However, the previous researches did not use balanced datasets and showed only accuracies for performance verifications. This paper proposes deep learning based eye disease diagnosis systems and balanced datasets are used for better performance. In addition, F1 score and receiver operation characteristic (ROC) curve with area under ROC curve (AUC) including accuracies are measured for exact performance verification. As for classes, normal, diabetic retinopathy, macular degeneration, cataracts, glaucoma, and pathological myopia, i.e., six classes are defined. Moreover, as a dataset, total 4965 data images are used. From the experimental result, we achieved 0.901 as an average F1 score."
랜드마크 기반 앙상블 네트워크를 이용한 얼굴 표정 분류,2022,"['얼굴 표정 분류', '앙상블 네트워크', '랜드마크', '얼굴 부분 특징', '딥러닝', 'Classification of facial expressions', 'Ensemble network', 'Landmark', 'Face feature', 'Deep learning']",,"Research on facial expression classification has been steadily studied in relation to facial components and characteristics extraction. In this study, an algorithm for classifying facial expressions using a landmark-based ensemble network is also proposed to effectively classify facial expressions using these changes. First, only the face part is extracted from the entire face image through the preprocessing process, and then feature information is constructed using only the face image. And new landmark-based feature information is extracted using landmark information from the face image. After learning face-wide image feature information and landmark-based feature information on each CNN network, facial expressions are classified through ensemble learning. As a result of the experiment, it can be seen that the proposed algorithm shows 1.14% better classification performance than the technology that classified facial expressions using only existing facial images and 0.57% better classification performance than the technology that classified facial expressions using only landmark feature information."
합성곱 신경망 기반 분류 모델의 화재 예측 성능 분석,2022,"['Fire detection', 'Fire image classification', 'Convolutional neural network', 'Fire prediction performance']","본 연구에서는 화재 안전 향상을 위한 엣지 컴퓨팅(edge computing) 기반 화재감지시스템에 적용 가능한 합성곱 신경망 기반 이미지 분류 모델들인 MobileNetV2, ResNet101, EfficientNetB0를 이용하여 화재 예측 성능 해석을 수행하였다. 성능평가지표인 정확도, 재현율, 정밀도, F1-score와 혼동 행렬을 이용하여 화재 예측 성능을 비교 분석하였다. 또한 분류 모델의 경량화와 관련한 모델 용량 및 추론시간에 대한 비교 분석을 수행하였다. 비교 분석 결과로서 화재 예측 정확도는 EfficientNetB0 모델이 가장 높았으며 경량성 측면에서는 MobileNetV2가 가장 우수한 것으로 확인하였다. 더하여 화재와 유사한 특징을 갖는 비 화재 이미지인 빛과 연무에 대한 이미지 특성을 추가 학습한 결과, 경량성은 우수하나 예측 성능이 낮은 MobileNetV2의 화재 예측 정확도가 개선되는 것을 확인하였다.","In this study, fire prediction performance was analyzed using convolutional neural network (CNN)-based classification models such as MobileNetV2, ResNet101, and EfficientNetB0 applicable to an edge computing-based fire detection system for improving fire safety. The fire prediction performance was evaluated using the performance evaluation measures including accuracy, recall, precision, F1-score, and the confusion matrix. The model size and inference time were assessed in terms of the light-weight classification model for the practical deployment and use. The analysis results confirmed that the EfficientNetB0 model had the highest fire prediction accuracy, and the MobileNetV2 was the best light-weight classification model. Notably, additionally learning the image features about light and haze images having similar features with those of the fire images improved the fire prediction accuracy of the light-weight MobileNetV2 model."
딥러닝 기반 고인쇄물 내 글자 추출 및 인식을 통한 3차원 활자 복원,2022,"['Type reconstruction', 'Image segmentation', 'Character segmentation', 'Character classification', 'Historical printed documents']","한글 활자 및 활자본은 역사적 가치뿐만 아니라 인쇄사, 국어사, 한글 글꼴 등 여러 측면에서 중요한 가치를 지닌다. 하지만 오랜 세월이 지나면서 그 당시의 활자들이 온전히 보존되어 전해지지 않은 경우가 대부분이다. 본 논문에서는 딥러닝을 기반으로 활자로 인쇄된 고문서의 글씨로부터 활자 구조 정보를 추출하여 활자본 인쇄에 사용된 3차원 활자의 정보들을 추정하는 방법을 제안한다. 먼저, 고인쇄 활자본의 고해상도 스캔 영상 데이터에 대해 딥러닝(U-Net)을 적용하여 글자 획 영역만을 추출하고 음소 단위 영역으로 나누어 모든 글자에 대해 글자 인식과 위치를 파악한다. 추출된 글자 분할 데이터는 음소별로 구분하여 인식하는 Convolutional neural network (CNN) 모델을 통해 같은 글자끼리 분류한다. 같은 글자 영상 간 정합을 위해 이동과 회전 변환을 얻도록 간소화된 Homography network을 사용하여 정합 후, 유사도를 기반으로 동일 활자로 인쇄한 글자들로 세분화한다. 마지막으로 동일 활자 영상을 통합하여 3차원 활자 모형을 복원한다. 실험을 통해 제안하는 각 과정이 성공적으로 수행되는 것을 확인했다.",
An Improved Attention-based Bidirectional LSTM Model for Cyanobacterial Bloom Prediction,2022,"['Attention mechanism', 'bidirectional LSTM model', 'convolutional neural network', 'cyanobacterial bloom prediction.']",,"Cyanobacterial blooms are one of the most serious water pollution problems for freshwater lakes. The treatment of blooms requires a lot of material and financial resources, so an early accurate prediction of cyanobacterial blooms is a very important way to deal with the outbreak of them. But it is challenging to predict the cyanobacterial blooms due to the uncertainty and complexity of their growth process. To deal with this problem, an improved attention-based bidirectional long short-term memory (LSTM) model is proposed in this paper, to make multistep predictions of chlorophyll-a concentration, which is a recognized characterization of algae activity. Firstly, the convolutional neural network (CNN) is used to extract data features and spatiotemporal correlation. Secondly, the bidirectional LSTM network (BiLSTM) is used to predict the concentration of chlorophyll-a based on the extracted features. Finally, the attention mechanism is used to calculate the weights for the characteristic factors that affect the chlorophyll-a concentration. At last, some experiments are carried out based on the real monitoring data of a platform in the Taihu Lake area. Compared with the prediction results of the other four state-of-the-art deep learning methods, the results show that the proposed method in this paper has the highest prediction accuracy."
딥러닝 기반 수어 교육 온라인 플랫폼 구현,2022,"['딥러닝', '동작 인식', '교육', '수어', '청각 장애인', 'Deep Learning', 'Motion Recognition', 'Education', 'Sign Language', 'People with hearing impairment']",,"Sign language is the main communication method for people with hearing impairments. However, the educational system and learning content for sign language acquisition have been characterized by a lack of accessibility and low quality in Korea. In 2022, 15 educational platforms regarding sign language acquisition exist. The formats mainly consist of watching videos and following pre-recorded hand movements, but real-time feedback is not provided about learned content. Thus, this study proposes a platform to teach sign language that provides real-time feedback on the proper hand movements of sign language. Based on CNN and LSTM, this model of distinguishing sign language movements uses a data-tracking system that tracks learners arms, hands, and fingers using OpenPose and MediaPipe. Through deep learning, the platform can help learners identify accurate hand movements and learn sign language interactively."
EEG기반의 AI채용시스템을 활용한 면접자들의 진실성 탐구,2022,"['AI채용시스템', '인공지능', 'EEG', '채용', '딥러닝', 'AI Recruitment System', 'Artificial Intelligence', 'EEG', 'Recruitment', 'Deep Learning']",,"An increasing number of companies are using AI recruitment system for the purpose of improved work efficiency. This study was designed to conduct an EEG-based biological experiment to explore the sincerity of applicants who were interviewed using an AI recruitment system. By asking interviewees with 10 questions of situation-solving ability assuming a random trouble-solving situation, EEG signals were collected from the interviewees during the interview and their sincerity was explored. As a result of the experiment, the accuracy of the CNN model showed slightly better results for truthfulnrss assessment"
Autonomous Underwater Vehicle Control for Fishnet Inspection in Turbid Water Environments,2022,"['Autonomous underwater vehicle', 'convolutional neural network', 'underwater inspection', 'vision-based control.']",,"Fisheries are essential for the economic supply of proteins. Detecting damaged fishnets using autonomous underwater vehicles (AUVs) may be an efficient and safe solution for avoiding dangers to human divers. However, in turbid underwater environments, visibility is significantly degraded by floating particles that cause light attenuation, which is one of the main problems for accurate underwater inspection by optical cameras. To obtain clear images for net inspection, we propose an AUV pose control strategy for fish farming net inspection in turbid water, based on the mean gradient feature over the partial or entire image. To alleviate the laborious human process of setting the desired set-point for distance control, a convolutional neural network (CNN) is trained offline using a supervised learning method and combined with a controller. The proposed method can maintain a relatively constant relative pose with respect to a fishnet, which is sufficient to acquire clear net images in turbid water and check whether a part of the net is damaged or not. Experimental results in both swimming pools and real fish farm environments demonstrated the effectiveness of the proposed methods."
Martial Arts Moves Recognition Method Based on Visual Image,2022,"['Action Recognition', 'Hidden Markov Model', 'Martial Art', 'Visual Image', 'Wushu']",,"Intelligent monitoring, life entertainment, medical rehabilitation, and other fields are only a few exampleswhere visual image technology is becoming increasingly sophisticated and playing a significant role.Recognizing Wushu, or martial arts, movements through the use of visual image technology helps promote anddevelop Wushu. In order to segment and extract the signals of Wushu movements, this study analyzes thedenoising of the original data using the wavelet transform and provides a sliding window data segmentationtechnique. Wushu movement The Wushu movement recognition model is built based on the hidden Markovmodel (HMM). The HMM model is trained and taught with the help of the Baum-Welch algorithm, which isthen enhanced using the frequency weighted training approach and the mean training method. To identify thedynamic Wushu movement, the Viterbi algorithm is used to determine the probability of the optimal statesequence for each Wushu movement model. In light of the foregoing, an HMM-based martial arts movementsrecognition model is developed. The recognition accuracy of the HMM model increases to 99.60% when thenumber of samples is 4,000, which is greater than the accuracy of the SVM (by 0.94%), the CNN (by 1.12%),and the BP (by 1.14%). From what has been discussed, it appears that the suggested system for detecting martialarts acts is trustworthy and effective, and that it may contribute to the growth of martial arts."
Profane or Not: Improving Korean Profane Detection using Deep Learning,2022,"['Profanity', 'deep learning', 'convolutional neural network', 'text mining', 'natural language processing']",,"Abusive behaviors have become a common issue in many online social media platforms. Profanity is common form of abusive behavior in online. Social media platforms operate the filtering system using popular profanity words lists, but this method has drawbacks that it can be bypassed using an altered form and it can detect normal sentences as profanity. Especially in Korean language, the syllable is composed of graphemes and words are composed of multiple syllables, it can be decomposed into graphemes without impairing the transmission of meaning, and the form of a profane word can be seen as a different meaning in a sentence. This work focuses on the problem of filtering system mis-detecting normal phrases with profane phrases. For that, we proposed the deep learning-based framework including grapheme and syllable separation-based word embedding and appropriate CNN structure. The proposed model was evaluated on the chatting contents from the one of the famous online games in South Korea and generated 90.4% accuracy."
Classification of Covid-19 Infection Based on Chest X-ray Pictures Using OpenCv and Convolution Neural Networks,2022,"['Imbalance classification', 'image generation', 'convolution neural networks', 'ensemble learning', 'multi-class classification']",,"COVID-19 is a pathogen called SARS-CoV-2, an RNA virus that can infect various animals, including humans. As COVID-19 spread globally, the World Health Organization upgraded it to a pandemic in March 2020. In addition to solving the problem of shortage of medical personnel, rapid and accurate classification of infected patients emerged as an important issue. Therefore, we propose a deep learning-based chest X-ray image reading model that can notify the doctor whether the patient is infected. The goal is to achieve multiclass classification, which not only classifies COVID-19 infections, but also other lung diseases to help the medical community. The proposed method is a combination model. It involves pre-processing the chest X-ray image using the image augmentation method and various convolutional neural network (CNN) models. The purpose of the proposed method is to classify COVID-19, normal people, and viral pneumonia appropriately. Overall, 15,153 X-ray images were used in the study. By using the proposed method, we obtained a model with high accuracy through improved image data. Characteristically, some models tend to detect COVID-19 and pneumonia properly. Finally, an ensemble model was created using models made by the proposed method. Eventually, we obtained a high accuracy (0.981) model for detecting infections appropriately."
작물 분류를 위한 딥러닝 기반 비지도 도메인 적응 모델 비교,2022,"['Crop classification', 'Deep learning', 'Unmanned aerial vehicle (UAV)', 'Unsupervised domain adaptation']",,"The unsupervised domain adaptation can solve the impractical issue of repeatedly collecting high-quality training data every year for annual crop classification. This study evaluates the applicability of deep learning-based unsupervised domain adaptation models for crop classification. Three unsupervised domain adaptation models including a deep adaptation network (DAN), a deep reconstructionclassification network, and a domain adversarial neural network (DANN) are quantitatively compared via a crop classification experiment using unmanned aerial vehicle images in Hapcheon-gun and Changnyeong-gun, the major garlic and onion cultivation areas in Korea. As source baseline and target baseline models, convolutional neural networks (CNNs) are additionally applied to evaluate the classification performance of the unsupervised domain adaptation models. The three unsupervised domain adaptation models outperformed the source baseline CNN, but the different classification performances were observed depending on the degree of inconsistency between data distributions in source and target images. The classification accuracy of DAN was higher than that of the other two models when the inconsistency between source and target images was low, whereas DANN has the best classification performance when the inconsistency between source and target images was high. Therefore, the extent to which data distributions of the source and target images match should be considered to select the best unsupervised domain adaptation model to generate reliable classification results."
다중 패치를 이용한 트랜스포머 기반 장면 텍스트 인식,2022,"['Deep learning', 'Scene text recognition', 'Transformer', '.']",,.
Meta-Learning Approaches for mmWave Path Loss Modeling in Smart Factories,2022,['Millimeter waveSmart factoryPath loss modelingMeta-learningDeep learning'],,"With the growing interest in both public and private 5G services based on millimeter wave (mmWave) communication for indoor usage scenarios such as smart factories, site design specialists are seeking sophisticated methods and tools for simulating indoor radio coverage based on highly accurate path loss prediction models. Although machine learning approaches can be used in path loss modeling thanks to the highly accurate prediction capability, their performance can be limited by the size of available measurement data set used for training. In this paper, we propose new approaches to train path loss models in the few-shot learning scenarios of smart factories. The proposed approaches are based on meta-learning with slight modifications to perform fine-tuning over an entire train data set rather than a meta-test data set. It is shown that the indoor path loss models based on convolutional neural networks (CNNs) trained by meta-learning based on three different meta-train task assignment schemes outperform both a conventional CNN model and an empirical model."
데이터 증강 기반 효율적인 무선 신호 분류 연구,2022,"['Wireless Signal', 'Signal Classification', 'Deep learning', 'GAN', 'IoT']","사물인터넷 환경에서는 다양한 무선 통신 기술을 사용하는 기기들이 점점 증가하고 있다. 특히, 다양한 무선 신호 변조 유형을 정확하게 식별하기 위해 효율적인 특성 추출 기법을 설계하고 무선 신호의 종류를 분류하는 것이 필수적이다. 하지만, 실제 환경에서 레이블이 지정된 무선 신호 데이터를 수집하는 것은 쉬운 문제가 아니다. 최근 무선 신호 분류를 위해 딥러닝 기반의 다양한 학습 기법들이 제안되어졌다. 딥러닝의 경우 훈련 데이터셋이 적을 경우 과대적합에 빠질 가능성이 높으며, 이는 딥러닝 모델을 활용한 무선 신호 분류 기법의 성능 저하를 유발한다. 본 연구에서는 다양한 무선 신호들이 존재할 때 분류 성능을 높이기 위해 생성적 적대 신경망 기반 데이터 증대 기법을 제안한다. 분류해야 하는 무선 신호의 종류가 다양할 때 특정 무선 신호를 나타내는 데이터의 양이 적거나 균형이 맞지 않는 경우 제안한 기법을 활용하여 필요한 무선 신호와 관련된 데이터의 양을 증가시킨다. 제안한 데이터 증강 알고리즘의 유효성을 검증하기 위해 무선 신호의 데이터양을 증가시키고 균형을 맞춘 결과를 바탕으로 CNN 및 LSTM 기반 무선 신호 분류기를 구현하여 실험해본 결과 데이터 균형을 맞추지 않았을 때보다 분류 정확도가 높아지는 것을 확인하였다.",
대조 학습에 기반한 기침 소리 분류 모델 분석,2022,"['자기지도학습', '대조 학습', 'mel-spectrogram', '증강기법', 'self-supervised learning', 'contrastive learning', 'mel-spectrogram', 'augmentation']","최근 COVID-19 확산으로, 기침 소리를 활용한 호흡기 질환 예측 연구가 다양하게 이루어지고 있으나 labeling된 기침 데이터는 임상 전문의들의 소견이 필요하기 때문에 구하기 어렵다. 반면 unlabeled data는 풍부하다는 점에서 self-supervised Learning (SSL)을 적용한다면 좋은 효과를 기대할 수 있다. SSL 방법 중, positive, negative pair의 유사성을 학습하는 대조 학습 방법이 소리 분야에서 많이 연구가 되고 있지만, 적합한 데이터 형태 및 학습 방법 등에 대한 심층적인 연구가 적고, 기침 소리의 대조 학습에 대한 연구는 부족한 상황이다. 본 연구에서는 기침 소리를 활용한 대조 학습 연구의 방향성을 제시하기 위해, 기침 소리 분류 모델을 구축하고 다양한 실험을 진행하였다. 실험 결과, 소리의 feature 중 mel-spectrogram이 기침 소리의 표현으로 적합하였고, 대조학습이 학습 데이터 크기에 대한 의존성을 감소시키는 것으로 나타났다. 또한 모델 성능 고도화를 위해 channel 수와 filter의 종류, augmentation 기법들을 비교 분석한 결과 single-channel, 2D-CNN이 적합하였고, time shift와 block masking을 조합했을 때 가장 뛰어난 성능을 보였다. 마지막으로 기침 소리 분류 이외에 covid-19 분류에도 성능 향상을 보이는 것을 확인하였다.",
Interference intention classification of moving obstacles used for USV collision avoidance,2022,"['Unmanned Surface Vessels (USV)', 'Interference intention classification', 'Machine vision', 'Collision avoidance', 'Machine learning']",,"Unmanned Surface Vessels (USV) may interfere with ships in the same lane during navigation and may be affected by ships that actively collide or intercept the USV. Evidently, the latter poses a greater threat than the former. This paper proposes the concept of active and inactive interference. It is necessary for the USV to accurately classify the vessels’ intentions to conduct a suitable collision avoidance strategy.However, the existing research on collision avoidance of USV focuses on avoiding moving obstacles and rarely considers the interference intention of dynamic obstacles for USV when choosing collision avoidance strategies. This paper proposes an algorithm to recognize the interference intention of ships by combining visual classification with a Support Vector Machine (SVM). First, a Convolutional Neural Network (CNN) is proposed to distinguish the merchant ship from a high-performance ship that actively interferes with the USV with high probability. A high-dimensional feature dataset was designed to illustrate the navigation characteristics of an obstacle, and Principal Component Analysis (PCA) was then employed to reduce the dimensionality of the dataset for obstacle classification. A modified SVM is presented to classify obstacles into active and inactive interference intention categories. Moreover, an escape algorithm based on an improved artificial potential field method is proposed for vessels with active interference. The simulation and experimental results clearly show that the USV can successfully identify the interference intention of obstacles and adopt a specific collision avoidance strategy for obstacles with active interference intentions. Using this algorithm, the USV can safely avoid obstacles with different interference intentions."
자율운항선박 보조기기 내 고무 씰의 상태기반정비를 위한  고장진단용 데이터베이스 및 알고리즘 개발에 관한 연구,2022,"['Rubber Seal', 'Condition Based Maintenance', 'Fault Diagnosis', 'Accelerated Test', 'Data-driven Approach']",,"Purpose: The marine oil purifier is a critical piece of auxiliary equipment on autonomous ships that can cause major engine failures if not maintained properly. Diagnosis of auxiliary equipment failures, especially those caused by degradation of seals, is difficult using current diagnostic techniques. The aim of this study is to develop a database and algorithm that will identify areas where condition-based maintenance is necessary for rubber seals.Methods: A multistep accelerated thermal aging test was performed on the marine oil purifier’s rubber seal. Using the purifier’s failure-simulation testbed, diagnostic data indicating the vibration-based condition due to the level of seal degradation was collected. Time and frequency domain analysis was performed using the established database, and a failure classification method using STFT and CNN was proposed.Results: Tensile and hardness test results indicated that rubber seals experienced decreasing tensile properties when undergoing the accelerated thermal aging process. A valid difference in the frequency domain was observed in the equipment condition monitoring data. Failure classification methods indicated an accuracy of 99%.Conclusion: In this study, a database and algorithm were developed for diagnosing the condition of rubber seals in marine oil purifiers. Their effectiveness was verified using time and frequency domain analysis and failure classification methods. The validity of the developed data-driven failure diagnosis method was successfully confirmed."
Developing the Hoax: A Discord Chatbot That Classify Fake News Using Recurrent Neural Network,2022,"['Fake News Classification', 'RNN', 'LSTM', 'Discord API', 'Chatbot', 'Deep learning']",,"Internet has replaced traditional media and become one of the major news media platforms. News from internet sources tend, since they are accessible and convenient, to travel quicker and simpler than conventional news sources. However, not all of the media reports obtained from unverified sources are authentic as fake news arises in large numbers and is prevalent in online communities for both political and commercial reasons.Fake news can deceive or misinform readers theoretically or intentionally because people will easily get tangled by any of this information which may impact on the offline community. Although some manual websites are designed to check if the piece of information is true, the volume of quick-spread information online, notably on the web, does not scale. In order to solve this issue automatic fact-checking applications were designed to tackle the requirement of scalability and automation. However, current application methods lack an inclusive multi-dimensional data set to identify fake news features to improve machine learning classification model performance. To overcome this problem, this research paper proposed the Hoax chatbot which classifies the data when user enters an article headline into it. In this research work, the classification of dataset has been done using recurrent neural network (RNN) and long short-term memory (LSTM) model. The fake and true news dataset are preprocessed and used to train the model. Saved model is deployed on the discord server in order to check the credibility of the given input text. Discord API gives an access to run python files into their chatbot. In terms of analysis, the proposed model outperforms already existed neural network model such as convolutional neural network (CNN) with an accuracy of 96.77%."
머신러닝기반 색채조화 배색 모델 구현,2022,"['배색 모델', '색채조화', '머신러닝', '모던', '내추럴', '거실', 'Color Scheme Model', 'Color Harmony', 'Machine Learning', 'Modern', 'Natural', 'Living Room']",,"To satisfy the diverse needs of consumers, emotional designs that focus on consumers have emerged. Consumers who consume emotionally have a high score on the happiness index and satisfaction. Among them, consumers pursue a style that suits their lifestyle in the residential space where they live. And in detail, consumers are highly satisfied by changing the color and material of objects placed in the space. Consumers prefer the natural and the modern styles from among the styles of interior design. Furthermore, when consumers plan the color scheme of residential spaces, living rooms are the top priority among residential spaces. Therefore, the purpose of this paper is to develop a model based on machine learning that recommends colors of furniture or objects to be placed in the living room of consumers. The data learned in the developed model is RGB of three colors extracted from natural and modern living room images. The living room space images are collected based on keywords on the I.R.I image scale, which visually measures Koreans' color sensitivity, and in addition, the living room space images are collected through a sharing platform. The collected images are cleaned and integrated using the I.R.I color image scale and CNN model. The color data (RGB) of the cleaned images are learned in XGBoost and LightGBM, which perform machine learning tasks. The color recommendation models in this paper are evaluated using r² and MSE, which are evaluation methods for regression models supported by Scikit-Learn. And the model with the highest evaluation score is selected. Therefore, in this paper, a color scheme model for color harmony in the living room was selected as XGBoost No. 2 “train : value = 8 : 2”. This is effective as a color scheme model, and it will be a model that can satisfy consumers with individuality in the era of emotional design."
360 파노라마 실내공간 사진 기반 지능형 레퍼런스 데이터베이스 구축,2022,"['360 파노라마 이미지', '데이터아카이빙', '실내 디자인 레퍼런스 이미지', '자동 분류', '딥러닝', '360-degree panorama picture', 'Data Archiving', 'Interior Design Reference Image', 'Auto-classification', 'Deep Learning']","(연구배경 및 목적) 공간을 디자인하는 과정은 여러 사람이나 그룹간의 협업이 수반되기 때문에 디자인 의사소통은 디자이너가 디자인 정보를 공유하고 결정을 내리는 데 중요한 역할을 한다. 최근 가상현실의 도래로 많은 관찰자들이 수동적인 공간 경험을 넘어 원하는 공간을 어디에서나 경험할 수 있게 되었다. 본 연구의 목적은 지금까지 사용되어 온 실내공간 디자인 의사소통 도구를 분석하고, 360 파노라마 이미지를 기반으로 지능형 인테리어 디자인 레퍼런스 데이터베이스 프로토타입을 구축하는 것이다. (연구방법) 본 논문에서는 고화질 파노라마 사진에서 추출한 인테리어 디자인 이미지를 자동으로 분류하는 딥러닝 기술을 이용하여 문제를 해결하였다. 본 논문에서는 레퍼런스 이미지 아카이브 구축 프로세스를 단순화하는 접근 방식을 제시한다. 연구 방법 및 절차는 1) 360 파노라마 이미지 준비, 2) 실내공간 디자인을 위한 레퍼런스 이미지 자동 추출, 3) 이미지 데이터셋을 다양화하기 위해 각 이미지에 나타나는 특징을 자동 분류 및 인식, 4) 인식 정보 및 이미지의 저장. (결과) 앞서 언급한 방법을 기반으로 본 연구에서는 실행가능한 프로토타입을 제작하여 그 활용성을 검증하고자 하였다. 360도 파노라마 이미지의 소스는 360도 카메라를 이용하여 촬영한 고화질 사진뿐만 아니라 CAD나 BIM으로 생성된 사실적인 렌더링 가상 이미지를 동시에 활용한다. 주어진 실내 360도 파노라마 영상을 분할하는 방법에는 파라메트릭 방식과 미리 설정된 큐브 맵 방식이 있다. 첫 번째 방법을 통해 주어진 이미지를 특정 시야각과 이미지 크기를 가진 격자로 분할한다. 반면 큐브 맵 방식은 시야가 다르고 이미지 크기가 정해진 6개의 이미지만 생성한다. 학습된 딥러닝 기반 CNN 모델은 분할된 각 이미지에 공간 사용량, 디자인 스타일 등의 디자인 관련 정보를 인식하고 라벨링한다. 분할된 이미지는 레이블이 지정된 데이터와 함께 데이터베이스에 자동으로 보관된다. (결론) 본 논문은 건축 설계 분야에서 방대한 양의 질적 360도 파노라마 이미지 데이터를 아카이브하고 활용하는 데 기여할 것으로 기대된다. 특히, 사람들이 임의적으로 취급하는 인테리어 디자인 레퍼런스를 보관하는 방식을 표준화할 것이다. 추후 연구를 통해 주어진 인테리어 디자인 이미지로부터 인식 정보(예: 디자인 관련 객체 및 디자인 스타일 등)의 범위를 확장하고, 저장된 데이터를 디자인 프로세스에 활용하는 방법을 개발하고자 한다.",
도커 기반의 빅데이터 분석 환경을 고려한 딥러닝 플랫폼 설계,2022,"['컨테이너', '데이터 유형', '텍스트 분류', '이미지 분류', '모델 배포', 'Container', 'Data Type', 'Text Classification', 'Image Classification', 'Model Serving']","딥러닝 모델을 학습하고 학습된 모델에서 새로운 데이터에 대한 예측을 수행하기 위해서는 모델 생성부터 예측까지 전체 과정을 간편하게 사용할 수 있는 환경이 필요하다. 그러나 대부분의 인공지능 서비스들은 모델 성능을 높이기 위한 파라미터를 결정하는데 많은 시간과 노력을 기울이고 있다. 따라서 본 연구에서는 공개 소스를 활용하여 컨테이너 기반으로 딥러닝 분류 모델의 배포 및 관리가 쉬운 아키텍처를 설계하고자 한다. 분류 모델은 시계열, 비시계열, 이미지 데이터에 대한 3가지 방법론을 제안한다. 실험 결과 데이터 유형별로 장단기 메모리 구조, 컨볼루션 신경망 구조, 순환 신경망 구조, 사전 훈련 모델을 사용할 수 있는 컨테이너를 제공함으로써 모든 데이터를 적절하게 분류할 수 있었다.","In order to learned a deep learning models and performed predictions on new data in the learned models, an environment that could simple used to the all processed from models generated to prediction is needed. However, most artificial intelligence services a lot of time and effort to determine parameters decide to increased the models performance. Therefore, in this study, architectures are designed for the distribution, management of container based deep learning classification models of the using open source. Propose were made for a total of three: time-series, non time-series, and image data, which are classification models. As a result of the experiment, all data could be proper classified by provided container for LSTM(Long Short-Term Memory), CNN(Convolutional Neural Network), RNN(Recurrent Neural Network) and pre-training models by data typed."
기계장비 진동 데이터를 이용한 딥러닝 기반의 고장 분류 모델,2022,"['Time Series', 'Deep Learning', 'Machine learning', 'Classification', 'Predictive Maintenance', '시계열 데이터', '딥러닝', '기계학습', '분류', '예지 보전']","최근 4차 산업 혁명으로 인해 공장에서는 기계 시설물의 고장으로 인한 제조 및 생산 시간 증가와 수리비용 증가를 최신 기술을 통해 예방하고자 한다. 그리하여 연구자들은 안전사고 및 고장을 예지(豫知)하고, 제품 불량 등으로 인한 시민 불편, 사회적 혼란 등의 문제를 방지하기 위해 노력하고 있다. 이런 문제 해결을 위해 장비에 부착된 센서로부터 받은 데이터를 통해 기계 상황을 모니터링 및 예측 가능한 시스템이 요구된다. 본 논문에서는 기계설비에서 생성되는 시계열 데이터를 다양한 딥러닝 기반의 시계열 분류 모델에서 비교분석을 수행하였다. 총 13개의 모델을 사용하여 어떤 딥러닝 모델이 학습에 효율적이고 성능이 좋은지 실험을 수행하였고, 시계열의 복잡한 패턴과 시간 및 공간 패턴을 효과적으로 학습하는 CNN 계열 모델이 정확도, 정밀도, 재현율, F1 성능지표에서 100% 성능을 달성하여 우수한 것을 확인할 수 있었다. 기존까지 진동 시계열 데이터에 대해 다양한 딥러닝 모델의 비교분석이 연구는 없었기에 본 논문의 결과를 통해 다른 기계 시설물의 고장 분류에 있어서 도움이 될 것이라 예상된다.","Due to the recent Fourth Industrial Revolution, factories want to prevent the increase in manufacturing and production time and repair costs due to the failure of mechanical facilities through the latest technology. Therefore, researchers are trying to predict safety accidents and failures, and to prevent problems such as civil inconvenience and social confusion caused by product defects. To solve this problem, a system that can monitor and predict the machine situation through data received from sensors attached to the equipment is required. In this paper, comparative analysis was performed on time series data generated in machine facilities in various deep learning-based time series classification models. A total of 13 models were used to experiment with which deep learning models were efficient and performing well, and the models that effectively learned time and space patterns of time series recorded 100% performance in accuracy, precision, reproducibility, and F1 performance indicators. Since there have been no studies on the comparative analysis of various deep learning models for vibration time series data until now, the results of this paper are expected to help in classifying failures in other mechanical facilities."
무인기로 취득한 RGB 영상과 YOLOv5를 이용한 수수 이삭 탐지,2022,"['Sorghum', 'UAV', 'RGB', 'YOLO', 'Detection']","본 연구는 수수의 수확량 추정을 위해 무인기로 취득한 RGB 영상과 YOLOv5를 이용하여 수수 이삭 탐지 모델을 개발하였다. 이삭이 가장 잘 식별되는 9월 2일의 영상 중 512×512로 분할된 2000장을 이용하여 모델의 학습, 검증 및 테스트하였다. YOLOv5의 모델 중 가장 파라미터가 적은 YOLOv5s에서 mAP@50=0.845로 수수 이삭을 탐지할 수 있었다. 파라미터가 증가한 YOLOv5m에서는 mAP@50=0.844로 수수 이삭을 탐지할 수 있었다. 두 모델의 성능이 유사하나 YOLOv5s (4시간 35분)가 YOLOv5m (5시간 15분)보다 훈련시간이 더 빨라 YOLOv5s가 수수 이삭 탐지에 효율적이라고 판단된다. 개발된 모델을 이용하여 수수의 수확량 예측을 위한 단위면적당 이삭 수를 추정하는 알고리즘의 기초자료로 유용하게 활용될 것으로 판단된다. 추가적으로 아직 개발의 초기 단계를 감안하면 확보된 데이터를 이용하여 성능 개선 및 다른 CNN 모델과 비교 검토할 필요가 있다고 사료된다.","The purpose of this study is to detect the sorghum panicle using YOLOv5 based on RGB images acquired by a unmanned aerial vehicle (UAV) system. The high-resolution images acquired using the RGB camera mounted in the UAV on September 2, 2022 were split into 512×512 size for YOLOv5 analysis. Sorghum panicles were labeled as bounding boxes in the split image. 2,000images of 512×512 size were divided at a ratio of 6:2:2 and used to train, validate, and test the YOLOv5 model, respectively. When learning with YOLOv5s, which has the fewest parameters among YOLOv5 models, sorghum panicles were detected with mAP@50=0.845. In YOLOv5m with more parameters, sorghum panicles could be detected with mAP@50=0.844. Although the performance of the two models is similar, YOLOv5s (4 hours 35 minutes) has a faster training time than YOLOv5m (5 hours 15 minutes). Therefore, in terms of time cost, developing the YOLOv5s model was considered more efficient for detecting sorghum panicles. As an important step in predicting sorghum yield, a technique for detecting sorghum panicles using high-resolution RGB images and the YOLOv5 model was presented."
병렬 병합 구조를 이용한 기상 데이터의 예측률 향상을 위한 딥러닝 모델,2022,"['deep neural network', 'long short term memory', 'convolution neural network', 'ResNet', 'Inception', '.']","본 연구는 딥러닝 기본모델인 DNN, LSTM, BiLSTM, 1D-CNN 등으로, 예측의 성능을 향상하기 위해, 중간층을 병렬로 병합하는 구조를 제안하였다. 제안모델 1은 동일한 기본모델을 병렬 병합한 구조이고, 제안모델 2는 서로 다른 모델의 병렬 병합한 구조이다. 각 모델의 평가는 RMSE와 MAE로 10회 실험에 대한 평균값이다. 제안모델 1에서 가장 좋은 예측률을 보인 BiLSTM2의 RMSE는 0.064이다. 제안모델 2의 RMSE는 DC(DNN-CNN), LC(BiLSTM-CNN), DLC(DNN-BiLSTM-CNN) 등 모든 모델이 0.054였다. 이처럼 제안모델 2가 12.8%의 성능 향상을 보였다. 제안모델 2가 서로 다른 모델의 장점을 유지하면서 많은 파라메터로, 예측률을 향상할 수 있게 하는 모델임을 확인할 수 있었다.","In this study, using deep learning basic models DNN, LSTM, BiLSTM, and 1D-CNN, to improve prediction performance, we proposed a structure in which hidden layers are merged in parallel. Proposed model 1 is a parallel merging structure of the same basic model, and Proposed model 2 is a parallel merging structure of different models. The evaluation of each model is the average value for 10 experiments with RMSE and MAE. The RMSE of BiLSTM2, which showed the best prediction rate in Proposed Model 1, is 0.064. The RMSE of Proposed Model 2 was 0.054 for all models including DC (DNN-CNN), LC (BiLSTM-CNN), and DLC (DNN-BiLSTM-CNN). As such, Proposed Model 2 showed a performance improvement of 12.8%. It was confirmed that Proposed Model 2 is a model that can improve the prediction rate by using many parameters while maintaining the advantages of different models."
전동 이동 보조기기 주행 안전성 향상을 위한 AI기반 객체 인식 모델의 구현,2022,"['전동 이동보조 기기', '교통약자', '객체 인식', '딥러닝', '디텍트론2', 'Electric Mobility Aids', 'Transportation handicapped', 'Object Recognition', 'Deep learning', 'Detectron2']","본 연구에서는 전동 이동 보조기기를 이용하는 교통약자의 이동을 저해하거나 불편을 초래하는 횡단 보도, 측구, 맨홀, 점자블록, 부분 경사로, 임시안전 방호벽, 계단, 경사형 연석과 같은 주행 장애물 객체를 촬영한 뒤 객체를 분류하고 이를 자동 인식하는 최적의 AI 모델을 개발하여 주행 중인 전동 이동 보조기기의 전방에 나타난 장애물을 효율적으로 판단할 수 있는 알고리즘을 구현하고자 한다. 객체 검출을 높은 확률로 AI 학습이 될 수 있도록 데이터 셋 구축 시 라벨링 형태를 폴리곤 형태로 라벨링 하며, 폴리곤 형태로 라벨링 된 객체를 탐지할 수 있는 Detectron2 프레임워크를 활용하여 Mask R-CNN 모델을 활용하여 개발을 진행하였다. 영상 획득은 일반인과 교통약자의 두 개 그룹으로 구분하여 진행하였고 테스트베드 2개 지역에서 얻어진 영상정보를 확보하였다. Mask R-CNN 학습 결과 파라미터 설정은 IMAGES_PER _BATCH : 2, BASE_LEARNING_RATE 0.001, MAX_ITERATION : 10,000으로 학습한 모델이 68.532로 가장 높은 성능을 보인 것이 확인되어 주행 위험, 장애 요소를 빠르고 정확하게 사용자가 인지할 수 있도록 하는 딥러닝 모델을 구축이 가능한 것을 확인할 수 있었다.","In this study, we photograph driving obstacle objects such as crosswalks, side spheres, manholes, braille blocks, partial ramps, temporary safety barriers, stairs, and inclined curb that hinder or cause inconvenience to the movement of the vulnerable using electric mobility aids. We develop an optimal AI model that classifies photographed objects and automatically recognizes them, and implement an algorithm that can efficiently determine obstacles in front of electric mobility aids. In order to enable object detection to be AI learning with high probability, the labeling form is labeled as a polygon form when building a dataset. It was developed using a Mask R-CNN model in Detectron2 framework that can detect objects labeled in the form of polygons. Image acquisition was conducted by dividing it into two groups: the general public and the transportation weak, and image information obtained in two areas of the test bed was secured. As for the parameter setting of the Mask R-CNN learning result, it was confirmed that the model learned with IMAGES_PER_BATCH: 2, BASE_LEARNING_RATE 0.001, MAX_ITERATION: 10,000 showed the highest performance at 68.532, so that the user can quickly and accurately recognize driving risks and obstacles."
A YOLOv4 Model with FPN for Service Plates Detection,2022,"['Service plates detection', 'YOLOv4', 'FPN', 'Transfer learning']",,"Intelligent service plates detection plays an important role in smart city. For example, intelligent service plates detection can realize more effi cient and accurate self-service charges for restaurants, and saves labor costs, additionally. This paper constructs a service plates detection dataset. On this basis, Faster R-CNN and MobilenetV3 are fi rstly leveraged to conduct service plates detection. In addition, authors propose an intelligent service plate detection method based on FPN (Feature Pyramid Network) + YOLOv4 network. Specifi cally, YOLOv4 is utilized to extract initial image features, and a variant of FPN network for YOLOv4 backbone is designed to aggregate multi-granularity image features. To boost the training effi ciency, transfer learning algorithm is also introduced into our approach. Through the corporation of FPN + YOLOv4 framework and transfer learning algorithm, they realize the accurate and fast intelligent service plate detection. The experimental results show that: compared with MobilenetV3 model and faster R-CNN, our method achieves great improvement. In the future, authors will improve the network to achieve higher accuracy and faster calculation speed, and expand our data set to more realistic scene images"
딥러닝과 그래프 모델을 활용한 고해상도 영상의 건물 변화탐지,2022,"['Change Detection', 'High Spatial Resolution Images', 'Graph Model', 'Deep Learning', 'Instance Segmentation', '변화탐지', '고해상도 영상', '그래프 모델', '딥러닝', '인스턴스 분할227']","다시기 고해상도 영상에 존재하는 건물의 위치 및 형태학적 왜곡은 건물의 변화탐지를 어렵게 만드는 요인 중 하나이다. 이를 해결하기 위하여 부가적인 3차원 지형정보 및 딥러닝을 활용한 연구가 수행되고 있지만, 실제 사례에 적용되기 어려운 한계가 있다. 본 연구에서는 건물의 효율적인 변화탐지를 수행하기 위하여, 건물의 위치 정보뿐만 아니라 건물 간 위상정보를 활용하는 방안을 제시한다. 다양한 비연직 영상에서의 건물을 학습하기 위하여 SpaceNet v2 데이터셋을 사용하여 Mask R-CNN (Region-based Convolutional Neural Network)을 학습하였으며, 건물 객체를 탐지하여 중심점을 노드로 추출하였다. 추출한 건물 노드를 중심으로 서로 다른 두 시기에 대해 각각 TIN (Triangulated Irregular Network) 그래프들을 형성하고, 두 그래프 간 구조적 차이가 발생한 영역에 기반하여 변화 건물을 추출하기 위해 그래프 유사도와 노드의 위치 차이를 반영한 변화 지수를 제안하였다. 최종적으로 변화 지숫값을 기반으로 두 그래프 간 비교를 통해 새롭게 생성되거나 삭제된 건물을 탐지하였다. 총 3쌍의 테스트 영역에 대해 제안한 기법을 적용한 결과, 건물들 간 연결성의 변화를 고려함으로써 기복 변위에 의해 서로 다른 시기 간 동일 건물 쌍을 판단하기 어려운 경우에도 변화가 발생한 건물을 적절하게 탐지하는 것을 확인할 수 있었다.","The most critical factors for detecting changes in very high-resolution satellite images are building positional inconsistencies and relief displacements caused by satellite side-view. To resolve the above problems, additional processing using a digital elevation model and deep learning approach have been proposed. Unfortunately, these approaches are not sufficiently effective in solving these problems. This study proposed a change detection method that considers both positional and topology information of buildings. Mask R-CNN (Region-based Convolutional Neural Network) was trained on a SpaceNet building detection v2 dataset, and the central points of each building were extracted as building nodes. Then, triangulated irregular network graphs were created on building nodes from temporal images. To extract the area, where there is a structural difference between two graphs, a change index reflecting the similarity of the graphs and differences in the location of building nodes was proposed. Finally, newly changed or deleted buildings were detected by comparing the two graphs. Three pairs of test sites were selected to evaluate the proposed method’s effectiveness, and the results showed that changed buildings were detected in the case of side-view satellite images with building positional inconsistencies."
Dysarthric-Speech Detection Using Transfer Learning With Convolutional Neural Networks,2022,"['Dysarthria', 'Deep learning', 'Medical technology', 'Transfer learning', 'Machine learning']",,"Speech Dysarthria is a disorder in which speech muscles become weak, and it becomes difficult to articulate otherwise linguistically normal speech. This work is based on detection of speech dysarthria and how it can assist physicians, specialists, and doctors in its detection. The proposed work achieves higher accuracies on the TORGO dataset by using a transfer learning based convolutional neural network model (TL-CNN) and by converting the audio samples to Mel-spectrograms. The proposed work TL-CNN achieved better accuracy when compared with other machine learning models."
딥러닝 기반 알고리즘을 활용한 산불 객체 탐지,2022,"['딥러닝', '객체 검출', '분류', '욜로', '산림', '화재', 'Deep Learning', 'Object Detection', 'Classification', 'YOLO', 'Forest', 'Fire']","우리는 산불로 인한 피해로 직, 간접적인 피해를 받고 있는데 피해를 줄이기 위해서는 초기에 산불을 검출하는 것이 중요하다. 기존 산불 검출 방법으로는 촬영 이미지를 영상처리 기술을 통해 감지하거나 센서를 일정 구간별로 설치하여 모니터링하는 방법을 사용했다. 본 논문은 유지비용이 많이 들어가는 기존 방법을 개선하기 위해 객체 탐지 인공지능 기술, YOLO를 사용하여 객체 검출을 하고 인공지능 모델을 통해 나온 검출 결과를 제공하는 시스템 구현을 진행한다. 연구 결과 주요 성능지표인 mAP가 Proposed LFire 0.959, YOLOv5 0.931, YOLOv4 0.943, R-CNN 0.879가 나왔다. 본 논문에서 제안하는 모델인 Proposed LFire가 가장 높은 것을 통해 산불 검출 데이터에 적합한 객체 검출모델로 볼 수 있다. 향후 보편적으로 사용할 수 있는 RGB 채널 산림 이미지 특징에 맞는 이미지 전처리 및 모델 학습을 통해 검출 성능을 높이는 방향으로 연구할 계획이다.","We are suffering direct and indirect damage from forest fires, and it is essential to detect them early to reduce the damage. Existing forest fire detection methods used a method of detecting photographed images through image processing technology or installing sensors at certain intervals to monitor them. To improve the existing process that is expensive to maintain, this paper conducts object detection using object detection artificial intelligence technology, YOLO. It implements a system that provides detection results from artificial intelligence models. As a result of the study, the main performance indicators, mAP, were Proposed LFire 0.959, YOLOv5 0.931, YOLOv4 0.943, and R-CNN 0.879. The proposed model in this paper, Proposed LFire, is the highest, which can be seen as an object detection model suitable for forest fire detection data. In the future, we plan to study in the direction of increasing detection performance through image preprocessing and model learning suitable for RGB channel forest image features that can be used universally."
봇 프레임워크를 활용한 챗봇 구현 방안,2022,"['Chatbot', 'NLP', 'BotFrame', 'RNN', 'Cloud']","본 논문에서 챗봇에서 사용하는 AI알고리즘과 자연어처리 방법을 분류하고 제시하고 챗봇 구현에 사용할 수 있는 프레임워크에 대해서도 기술한다. 챗봇은 사용자 인터페이스를 대화방식으로 구성하여 입력된 문자열을 해석하고 입력된 문자열에 적절한 답을 학습된 데이터에서 선택하여 출력하는 구조의 시스템이다. 최근 콜센터와 주문 업무에 적용하여 인건비를 감소하고 정확한 업무를 할 수 있는 장점이 있다. 하지만 질문에 대한 적정한 답변 집합을 생성하기 위해 학습이 필요하며 이를 위해 상당한 계산 기능을 갖는 하드웨어가 필요하다. 개발을 하는 업체는 물론 AI분야 개발을 학습하는 학생들의 실습은 한계가 있다. 현재 챗봇은 기존의 전통적인 업무를 대체하고 있으며 시스템을 이해하고 구현하는 실습과정이 필요한 실정이다. 정형화되어 있는 데이터에 대해서만 응답을 하는 수준을 넘어 딥러닝 등의 기술을 적용하여 비정형 데이터를 학습시켜 질문에 대한 응답의 정확성을 높이기 위해 RNN과 Char-CNN 등을 사용해야한다. 챗봇을 구현하기 위해서는 이와 같은 이론을 이해하고 있어야한다. 본 논문에서는 단기간에 챗봇 코딩교육에 활용할 수 있는 방안과 기존 개발자, 학생들이 챗봇 구현을 할 수 있는 플랫폼을 활용하여 학생들이 전체시스템을 구현 예를 제시하였다.","In this paper, we classify and present AI algorithms and natural language processing methods used in chatbots. A framework that can be used to implement a chatbot is also described. A chatbot is a system with a structure that interprets the input string by constructing the user interface in a conversational manner and selects an appropriate answer to the input string from the learned data and outputs it. However, training is required to generate an appropriate set of answers to a question and hardware with considerable computational power is required. Therefore, there is a limit to the practice of not only developing companies but also students learning AI development. Currently, chatbots are replacing the existing traditional tasks, and a practice course to understand and implement the system is required. RNN and Char-CNN are used to increase the accuracy of answering questions by learning unstructured data by applying technologies such as deep learning beyond the level of responding only to standardized data. In order to implement a chatbot, it is necessary to understand such a theory. In addition, the students presented examples of implementation of the entire system by utilizing the methods that can be used for coding education and the platform where existing developers and students can implement chatbots."
다중 특징 융합 기반 3차원 객체 검출 알고리즘,2022,"['F-포인트넷', '포인트CNN', '포인트 클라우드', '객체 검출', '특징 용합', 'F-PointNets', 'PointCNN', 'Point cloud', 'Object detection', 'Feature fusion']",,"3D shape feature learning plays an important role in both industry and academia. Recently, feature understanding tasks such as object detection and object segmentation have been greatly developed. PointCNN is one of the excellent neural networks used for 3D object database classification. We designed a point cloud target detection algorithm based on the hybrid architecture of F-PointNet and PointCNN. First, the two-dimensional target detection model of the image is used to extract the two-dimensional area of the target and map it to the point cloud data to obtain the candidate area of the target. Then the 3D target mask of the candidate area is predicted by the PointCNN algorithm. Finally, the mask is used to detect the 3D target. We conducted experiments to prove that the mask extracted by PointCNN is easier to recognize 3D objects than the original F-PointNet."
Hybrid FRP 앵커의 초기 균열 탐색평가,2022,"['crack', 'FRP', 'anchor', 'hybrid', 'deep learning', '균열', 'FRP', '앵커', 'Hybrid', '딥러닝']",본 연구는 기계식 앵커와 FRP를 새로운 시스템으로 복합하여 새로운 메커니즘의 Hybrid 앵커모델의 파괴형태중 균열을 영상기반으로 프로세싱하여 균열탐지하는 메카니즘을 제시하였다. 기존의 cascade mask R-CNN 방식보다 탐지율과 효율성이 우수한 Dense-UNet 기법을 활용하여 균열탐사기법에 활용하였다. 기존의 균열 뿐 아니라 앵커주위의 Round crack도 함께 탐사되어 앵커 설치후 초기 균열 탐사에 효율성을 크게 가질 수 있다고 판단된다. 따라서 향후연구에서는 이미지 프로세싱 타임을 줄이면서 정확도를 높일수 있는 Post-Processing이 보완된다면 균열탐사 및 오탐을 줄이는데 크게 효과적일 것으로 사료된다.또한 피사체와 카메라와의 거리를 계산하여 알고리즘에 고려한다면 구조적 균열기준인 0.3 mm의 균열 탐사에도 활용할 수 있는 효과적인 기법이라 판단된다.,
선분 분할 탐지를 활용한 마스크 된 이미지 내의 물체 6자유도 자세 추정,2022,"['3-D object pose estimation', 'Line segment detection', 'Object contour detection', 'Bin picking', 'Robot vision', '.']",,.
스마트 자율배송을 위한 클래스 분류와 객체별 학습데이터 유형,2022,"['딥러닝', '주행 환경 인식', 'AI 학습용 데이터', '객체인식', '자율주행', 'Deep Learning', 'Perception', 'AI training data', 'Object Detection', 'Autonomous Driving']","자율배송 운행 데이터는 코로나 시대의 라스트마일 배송에 대한 패러다임 변화를 주도하는 핵심이다. 국내자율배송로봇과 해외 기술선도국가 간의 기술격차 해소를 위해서는 인공지능 학습에 사용 가능한 대규모 데이터 수집과 검증이 최우선으로 요구된다. 따라서 해외 기술선도국가에서는 인공지능 학습데이터를 누구든사용가능한 공공데이터 형태로 오픈하여 검증과 기술발전에 기여하고 있다. 본 논문은 자율배송로봇 학습을 목적으로 326개의 객체를 수집하고 Mask r-cnn, Yolo v3 등의 인공지능 모델을 학습하고 검증하였다.추가적으로 두 모델을 기반으로 비교하고 향후 자율배송로봇 연구에 요구되는 요소를 고찰하였다.",
Fundamental Function Design of Real-Time Unmanned Monitoring System Applying YOLOv5s on NVIDIA TX2<sup>TM</sup> AI Edge Computing Platform,2022,"['AI', 'Object Detection', 'NMS', 'YOLOv5s']",,"In this paper, for the purpose of designing an real-time unmanned monitoring system, the YOLOv5s (small) object detection model was applied on the NVIDIA TX2<sup>TM</sup> AI (Artificial Intelligence) edge computing platform in order to design the fundamental function of an unmanned monitoring system that can detect objects in real time. YOLOv5s was applied to the our real-time unmanned monitoring system based on the performance evaluation of object detection algorithms (for example, R-CNN, SSD, RetinaNet, and YOLOv5). In addition, the performance of the four YOLOv5 models (small, medium, large, and xlarge) was compared and evaluated. Furthermore, based on these results, the YOLOv5s model suitable for the design purpose of this paper was ported to the NVIDIA TX2<sup>TM</sup> AI edge computing system and it was confirmed that it operates normally. The real-time unmanned monitoring system designed as a result of the research can be applied to various application fields such as an security or monitoring system. Future research is to apply NMS (Non-Maximum Suppression) modification, model reconstruction, and parallel processing programming techniques using CUDA (Compute Unified Device Architecture) for the improvement of object detection speed and performance."
Fundamental Function Design of Real-Time Unmanned Monitoring System Applying YOLOv5s on NVIDIA TX2TM AI Edge Computing Platform,2022,"['AI', 'Object Detection', 'NMS', 'YOLOv5s']",,"In this paper, for the purpose of designing an real-time unmanned monitoring system, the YOLOv5s (small) object detection model was applied on the NVIDIA TX2TM AI (Artificial Intelligence) edge computing platform in order to design the fundamental function of an unmanned monitoring system that can detect objects in real time. YOLOv5s was applied to the our real-time unmanned monitoring system based on the performance evaluation of object detection algorithms (for example, R-CNN, SSD, RetinaNet, and YOLOv5). In addition, the performance of the four YOLOv5 models (small, medium, large, and xlarge) was compared and evaluated.Furthermore, based on these results, the YOLOv5s model suitable for the design purpose of this paper was ported to the NVIDIA TX2TM AI edge computing system and it was confirmed that it operates normally. The real-time unmanned monitoring system designed as a result of the research can be applied to various application fields such as an security or monitoring system. Future research is to apply NMS (Non-Maximum Suppression) modification, model reconstruction, and parallel processing programming techniques using CUDA (Compute Unified Device Architecture) for the improvement of object detection speed and performance."
객체 검출을 활용한 교육적 목적의 웹 기반 브레드보드 전기회로 분석,2022,"['전기전자 실험', '서비스', '브레드보드', '위치 검출', '위치 예측', 'Electrical and electronic testing', 'Service', 'Breadboard', 'Position detection', 'Position prediction']",,"In an experiment where students learn electrical and electronic theory and apply it, students have difficulty in connecting circuits. To alleviate the above difficulties, we first propose a circuit analysis service. The proposed method detects an electric device using an object detection model in which electric devices connected to a breadboard are labeled with data. To verify this, we connect to the breadboard circuit and create a custom dataset through photographs. The proposed method is divided into two processes: electric device prediction and electric device position detection. The electric device prediction model was compared using five object detection models, and the Faster R-CNN model had the best prediction performance. The electrical device position detector extracts features from the object detection model through transition learning to predict two coordinates (x1, y1), (x2, y2). A comparison of each model confirmed that the ResNet model has good location detection performance. Through this, it was confirmed that the proposed method alleviates the difficulty of first-time students learning electric and electronic experiments."
A Lightweight Pedestrian Intrusion Detection and Warning Method for Intelligent Traffic Security,2022,"['Traffic safety', 'pedestrian detection', 'computer vision', 'YOLOv5', 'lightweight']",,"As a research hotspot, pedestrian detection has a wide range of applications in the field of computer vision in recent years. However, current pedestrian detection methods have problems such as insufficient detection accuracy and large models that are not suitable for large-scale deployment. In view of these problems mentioned above, a lightweight pedestrian detection and early warning method using a new model called you only look once (Yolov5) is proposed in this paper, which utilizing advantages of Yolov5s model to achieve accurate and fast pedestrian recognition. In addition, this paper also optimizes the loss function of the batch normalization (BN) layer. After sparsification, pruning and fine-tuning, got a lot of optimization, the size of the model on the edge of the computing power is lower equipment can be deployed. Finally, from the experimental data presented in this paper, under the training of the road pedestrian dataset that we collected and processed independently, the Yolov5s model has certain advantages in terms of precision and other indicators compared with traditional single shot multiBox detector (SSD) model and fast region-convolutional neural network (Fast R-CNN) model.After pruning and lightweight, the size of training model is greatly reduced without a significant reduction in accuracy, and the final precision reaches 87%, while the model size is reduced to 7,723 KB."
Classification of Livestock Diseases Using GLCM and Artificial Neural Networks,2022,"['Machine Learning', 'Convolutional Neural Network', 'Gray Level Co- occurrence Matrix', 'Classification', 'Calf Health']",,"In the naked eye observation, the health of livestock can be controlled by the range of activity, temperature, pulse, cough, snot, eye excrement, ears and feces. In order to confirm the health of livestock, this paper uses calf face image data to classify the health status by image shape, color and texture. A series of images that have been processed in advance and can judge the health status of calves were used in the study, including 177 images of normal calves and 130 images of abnormal calves. We used GLCM calculation and Convolutional Neural Networks to extract 6 texture attributes of GLCM from the dataset containing the health status of calves by detecting the image of calves and learning the composite image of Convolutional Neural Networks. In the research, the classification ability of GLCM-CNN shows a classification rate of 91.3%, and the subsequent research will be further applied to the texture attributes of GLCM. It is hoped that this study can help us master the health status of livestock that cannot be observed by the naked eye."
설명 가능한 합성곱 신경망을 활용한 센서 기반의 시계열 데이터 분류 모델 제안,2022,"['Sensor Data', 'Time Series Classification', 'Pattern Recognition', 'Deep Learning', 'eXplainable Artificial Intelligence(XAI)', '센서 데이터', '시계열 데이터 분류', '패턴 인식', '딥러닝', '설명가능한 인공지능']","센서 데이터를 활용하여 설비의 이상 진단이 가능해졌다. 하지만 설비 이상에 대한 원인 분석은 미비한 실정이다. 본 연구에서는 센서 기반 시계열 데이터 분류 모델을 위한 해석가능한 합성곱 신경망 프레임워크를 제안한다. 연구에서 사용된 센서 기반 시계열 데이터는 실제 차량에 부착된 센서를 통해 수집되었고, 반도체의 웨이퍼 데이터는 공정 과정에서 수집되었다. 추가로 실제 기계 설비에서 수집된 주기 신호 데이터를 이용 하였으며, 충분한 학습을 위해 Data augmentation 방법론인 Scaling과 Jittering을 적용하였다. 또한, 본 연구에서는 3가지 합성곱 신경망 기반 모델들을 제안하고 각각의 성능을 비교하였다. 본 연구에서는 ResNet에 Jittering을 적용한 결과 정확도 95%, F1 점수 95%로 가장 뛰어난 성능을 보였으며, 기존 연구 대비 3%의 성능 향상을 보였다. 더 나아가 결과의 해석을 위한 XAI 방법론으로 Class Activation Map과 Layer Visualization을 제안하였으며, 센서 데이터 분류에 중요 영향을 끼치는 시계열 구간을 시각적으로 확인하였다.","Sensor data can provide fault diagnosis for equipment. However, the cause analysis for fault results of equipment is not often provided. In this study, we propose an explainable convolutional neural network framework for the sensor-based time series classification model. We used sensor-based time series dataset, acquired from vehicles equipped with sensors, and the Wafer dataset, acquired from manufacturing process. Moreover, we used Cycle Signal dataset, acquired from real world mechanical equipment, and for Data augmentation methods, scaling and jittering were used to train our deep learning models. In addition, our proposed classification models are convolutional neural network based models, FCN, 1D-CNN, and ResNet, to compare evaluations for each model. Our experimental results show that the ResNet provides promising results in the context of time series classification with accuracy and F1 Score reaching 95%, improved by 3% compared to the previous study. Furthermore, we propose XAI methods, Class Activation Map and Layer Visualization, to interpret the experiment result. XAI methods can visualize the time series interval that shows important factors for sensor data classification."
