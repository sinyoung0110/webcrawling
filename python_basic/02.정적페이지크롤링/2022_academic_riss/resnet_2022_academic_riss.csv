title,date,keywords,abstract,multilingual_abstract
ResNet 기반 작물 생육단계 추정 모델 개발,2022,"['딥러닝', '컴퓨터 비전', 'Convolution Neural Network', '작물 생육단계', 'Deep Learing', 'Computer Vision', 'CNN', 'Crop Growth Stage']","산업화 이후 가속화된 지구 온난화 현상으로 인해 기존환경 변화 및 이상기후 발생 빈도가 증가하고 있다. 농업은 기후변화에 매우 민감한 분야의 산업으로 지구 온난화는 작물의 생산량을 감소시키고 재배 지역이 변하는 등의 문제를 발생시킨다. 또한, 환경 변화는 작물의 생육 시기를 불규칙하게 만들어 숙련된 농사꾼들도 작물의 생육단계를 쉽게 추정할 수 없도록 만들어 여러 문제를 발생시킨다. 이에 본 논문에서는 작물의 생육단계를 추정하기 위한 CNN(Convolution Neural Network) 모델을 제안한다. 제안한 모델은 ResNet의 Pooling Layer를 수정한 모델로 ResNet, DenseNet 모델의 생육단계 추정보다 높은 성능 결과를 확인하였다.","Due to the accelerated global warming phenomenon after industrialization, the frequency of changes in the existing environment and abnormal climate is increasing. Agriculture is an industry that is very sensitive to climate change, and global warming causes problems such as reducing crop yields and changing growing regions. In addition, environmental changes make the growth period of crops irregular, making it difficult for even experienced farmers to easily estimate the growth stage of crops, thereby causing various problems. Therefore, in this paper, we propose a CNN model for estimating the growth stage of crops. The proposed model was a model that modified the pooling layer of ResNet, and confirmed the accuracy of higher performance than the growth stage estimation of the ResNet and DenseNet models."
Identity-CBAM ResNet 기반 얼굴 감정 식별 모듈,2022,[],"인공지능 시대에 들어서면서 개인 맞춤형 환경을 제공하기 위하여 사람의 감정을 인식하고 교감하는 기술이 많이 발전되고 있다. 사람의 감정을 인식하는 방법으로는 얼굴, 음성, 신체 동작, 생체 신호 등이 있지만 이 중 가장 직관적이면서도 쉽게 접할 수 있는 것은 표정이다. 따라서, 본 논문에서는 정확도 높은 얼굴 감정 식별을 위해서 Convolution Block Attention Module(CBAM)의 각 Gate와 Residual Block, Skip Connection을 이용한 Identity- CBAM Module을 제안한다. CBAM의 각 Gate와 Residual Block을 이용하여 각각의 표정에 대한 핵심 특징 정보들을 강조하여 Context 한 모델로 변화시켜주는 효과를 가지게 하였으며 Skip-Connection을 이용하여 기울기 소실 및 폭발에 강인하게 해주는 모듈을 제안한다. AI-HUB의 한국인 감정 인식을 위한 복합 영상 데이터 세트를 이용하여 총 6개의 클래스로 구분하였으며, F1-Score, Accuracy 기준으로 Identity-CBAM 모듈을 적용하였을 때 Vanilla ResNet50, ResNet101 대비 F1-Score 0.4∼2.7%, Accuracy 0.18∼2.03%의 성능 향상을 달성하였다. 또한, Guided Backpropagation과 Guided GradCam을 통해 시각화하였을 때 중요 특징점들을 더 세밀하게 표현하는 것을 확인하였다. 결과적으로 이미지 내 표정 분류 Task 에서 Vanilla ResNet50, ResNet101을 사용하는 것보다 Identity-CBAM Module을 함께 사용하는 것이 더 적합함을 입증하였다.",다국어 초록 정보 없음
스펙트럼 첨도를 이용한 ResNet 기반의 표적 분류 성능 분석,2022,"['Micro-Doppler', 'Characteristic vector', 'Spectral kurtosis', 'Target classification', 'ResNet34']","미세 도플러 (micro-Doppler) 변조는 각 개체의 구분 및 각각의 움직임에 대한 미세한 운동 상태를 나타내는 표적 특징으로서, 표적을 인식하고 분류하는 기술에 활용되고 있다. 미세 도플러 주파수는 물체의 회전과 진동 등의 기본적인 운동 특징에 의한 도플러 주파수의 변조 형태로 나타나며, 이를 이용하면 높은 표적 인식 정확도로 표적을 추적하고 분류할 수 있다. 본 논문에서는 드론, 조류, 사람 표적에 따른 미세 운동 신호를 모델링하고, 미세 도플러 영상의 스펙트럼 첨도를 계산하여 표적의 미세 도플러 특징 벡터를 추출한다. 그리고 서로 다른 미세 운동을 하는 표적을 분류하기 위해 스펙트럼 첨도를 입력으로 하는 ResNet34 심층 신경망 네트워크를 적용한다. 모의실험을 통해 각 표적의 레이더 실측 데이터 입력 세트에 따른 ResNet34 알고리즘의 분류 성능을 분석한다. 모의실험 결과를 통해 제안하는 기법이 정확도, 정밀도, 재현도 측면에서 평균 95% 이상의 성능을 제시함으로써, 미세 도플러 영상을 이용하는 기존 기법보다 우수함을 보인다.",다국어 초록 정보 없음
A Robust Energy Consumption Forecasting Model using ResNet-LSTM with Huber Loss,2022,"['Energy consumption predication', 'ResNet-LSTM', 'ResNet', 'LSTM', 'Huber loss', 'deep learning']",국문 초록 정보 없음,"Energy consumption has grown alongside dramatic population increases. Statistics show that buildings in particular utilize a significant amount of energy, worldwide. Because of this, building energy prediction is crucial to best optimize utilities' energy plans and also create a predictive model for consumers. To improve energy prediction performance, this paper proposes a ResNet-LSTM model that combines residual networks (ResNets) and long short-term memory (LSTM) for energy consumption prediction. ResNets are utilized to extract complex and rich features, while LSTM has the ability to learn temporal correlation; the dense layer is used as a regression to forecast energy consumption. To make our model more robust, we employed Huber loss during the optimization process. Huber loss obtains high efficiency by handling minor errors quadratically. It also takes the absolute error for large errors to increase robustness. This makes our model less sensitive to outlier data. Our proposed system was trained on historical data to forecast energy consumption for different time series. To evaluate our proposed model, we compared our model's performance with several popular machine learning and deep learning methods such as linear regression, neural networks, decision tree, and convolutional neural networks, etc. The results show that our proposed model predicted energy consumption most accurately."
A ResNet based multiscale feature extraction for classifying multi-variate medical time series,2022,"['Multi-scale convolutional feature extraction methods', 'ResNet50 structure', 'Squeeze-and-Excitation Modules']",국문 초록 정보 없음,"We construct a deep neural network model named ECGResNet. This model can diagnosis diseases based on 12-lead ECG data of eight common cardiovascular diseases with a high accuracy. We chose the 16 Blocks of ResNet50 as the main body of the model and added the Squeeze-and-Excitation module to learn the data information between channels adaptively. We modified the first convolutional layer of ResNet50 which has a convolutional kernel of 7 to a superposition of convolutional kernels of 8 and 16 as our feature extraction method. This way allows the model to focus on the overall trend of the ECG signal while also noticing subtle changes. The model further improves the accuracy of cardiovascular and cerebrovascular disease classification by using a fully connected layer that integrates factors such as gender and age. The ECGResNet model adds Dropout layers to both the residual block and SE module of ResNet50, further avoiding the phenomenon of model overfitting. The model was eventually trained using a five-fold cross-validation and Flooding training method, with an accuracy of 95% on the test set and an F1-score of 0.841.We design a new deep neural network, innovate a multi-scale feature extraction method, and apply the SE module to extract features of ECG data."
ResNet-Based Simulations for a Heat-Transfer Model Involving an Imperfect Contact,2022,"['Composite material', 'deep learning', 'heat transfer', 'Kapitza thermal resistance', 'ResNet']",국문 초록 정보 없음,"Simulating the heat transfer in a composite material is an important topic in material science. Difficulties arise from the fact that adjacent materials cannot match perfectly, resulting in discontinuity in the temperature variables. Although there have been several numerical methods for solving the heat-transfer problem in imperfect contact conditions, the methods known so far are complicated to implement, and the computational times are non-negligible. In this study, we developed a ResNet-type deep neural network for simulating a heat transfer model in a composite material. To train the neural network, we generated datasets by numerically solving the heat-transfer equations with Kapitza thermal resistance conditions. Because datasets involve various configurations of composite materials, our neural networks are robust to the shapes of material-material interfaces. Our algorithm can predict the thermal behavior in real time once the networks are trained. The performance of the proposed neural networks is documented, where the root mean square error (RMSE) and mean absolute error (MAE) are below 2.47E-6, and 7.00E-4, respectively."
Rotate vector reducer design using resnet-based model and integration of discretized optimization,2022,"['Sequential engineering', 'RV reducer', 'Design automation', 'Multidisciplinary optimization', 'Secondary development']",국문 초록 정보 없음,"The author present an artificial intelligent (AI)-based deep generative model that demonstrate how to generate design options of mechanical systems, which are not only suitable for specific working conditions but also optimized for engineering performance. In current study, (1) a structural generative residual netowork (SG-Resnet) model is developed to establish the non-linear mapping between the working conditions and the external dimensions of the reducer, the main hyperparameters influencing the prediction ability and learning rate of the SG-Resnet are analyzed. (2) The mixed population non dominated sorting genetic algorithm-II (MP-NSGA-II) is proposed, and used to obtain pareto optimal solutions of the internal dimensions of the reducer. Experiments are performed to validate the positive effect of the structural generative model on the stiffness of the reducer. This research provides a novel method for reducer design and lays a solid foundation for the development of sequential engineering software for integrated rotate vector (RV) reducer."
ResNet을 기반으로 한 Poisson-Boltmann 방정식의 풀이법,2022,"['Poisson Boltmann equation', 'ResNet', 'Deep Learning', 'Finite Element Method', 'Electronic Potential']",국문 초록 정보 없음,다국어 초록 정보 없음
ResNet50 전이학습을 활용한 손동작 인식 기반 가위바위보 게임 구현,2022,"['합성곱 신경망(CNN)', '전이학습', '손동작 인식', '가위바위보 게임', 'ResNet50']",국문 초록 정보 없음,다국어 초록 정보 없음
ResNet-18과 SVM을 사용한 학습 기반 GNSS 재밍 식별 기법,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
Image Recognition using Improved ResNet50 Model with Novel Attention Mechanism,2022,"['Image Recognition', 'Convolutional Block Attention Module', 'Res-Net50', 'Attention Mechanism']",국문 초록 정보 없음,다국어 초록 정보 없음
Cardiac Anomaly Classification in Multi-lead ECG Using Resnet-adapted to Cyclical Learning Rate,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
Identification of abnormal tissue from CT images using improved ResNet34,2022,"['CT', 'computer-aided diagnosis', 'clinical information', 'multimodal', 'deep learning']",국문 초록 정보 없음,"In recent years, CT examinations have been widely used as a screening method to detect lung cancer. However, reading enormous CT images become a heavy burden to the physician. To avoid this problem, computer-aided diagnosis systems have been introduced on CT screening. In general, physicians consider patient information in addition to image information when they make a diagnosis, new efforts are being made to improve the accuracy of diagnosis by mimicking this information with a machine. In this paper, we propose a method for identifying pulmonary nodules by adding medical record information to images to improve the accuracy of diagnosis. We classify nodules from unknown data by assigning branching information of vascular opacities, straight vascular shadows, and nodular shadows as labeled image, which are a cause of misrecognition based on image features in machine learning. In the experiment, the classification accuracy of the nodule class was improved by adding clinical information to 644 images including 161 nodal images."
충격 전 낙상 검출: ResNet 1D vs. ResNet 2D,2022,"['Fall', 'Pre-impact fall detection', 'Deep learning', 'Convolutional neural network', 'ResNet']",국문 초록 정보 없음,다국어 초록 정보 없음
Transfer Learning-Based Face Mask Detection using ResNet,2022,"['Transfer Learning', 'Face Mask Detection', 'Deep Learning', 'COVID-19', 'ResNet']",국문 초록 정보 없음,다국어 초록 정보 없음
충격 전 낙상 검출: VGGNet V.S. ResNet,2022,"['Pre-impact Fall Detection', 'Deep Learning', 'VGGNet', 'ResNet']",국문 초록 정보 없음,다국어 초록 정보 없음
이진화된 ResNet 모델의 효율적인 Residual Learning을 위한 네트워크 설계 방법,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝을 이용한 직물의 결함 검출에 관한 연구,2022,"['fabric defects', 'VGGNet', 'ResNet', 'Grad-CAM', '직물결함', 'VGGNet', 'ResNet', 'Grad-CAM']","섬유산업에서 생산된 직물의 결함을 식별하는 것은 품질관리를 위한 핵심적인 절차이다. 본 연구는 직물의 이미지를 분석하여 결함을 검출하는 모델을 만들고자 하였다. 연구에 사용된 모델은 딥러닝 기반의 VGGNet과 ResNet이었고, 두 모델의 결함 검출 성능을 비교하여 평가하였다. 정확도는 VGGNet 모델이 0.859, ResNet 모델이 0.893으로 ResNet 모델의 정확도가 더 높은 결과를 보여주었다. 추가적으로 딥러닝 모델이 직물의 이미지 내에서 결함으로 인식한 부분의 위치를 알아보기 위하여 XAI(eXplainable Artificial Intelligence)기법인 Grad-CAM 알고리즘을 사용하여 모델의 관심영역을 도출하였다. 그 결과 딥러닝 모델이 직물의 결함으로 인식한 부분이 육안으로도 실제 결함이 있는 것으로 확인되었다. 본 연구의 결과는 직물의 결함 검출에 있어서 딥러닝 기반의 인공지능을 활용함으로써 섬유의 생산과정에서 발생하는 시간과 비용을 줄일 수 있을 것으로 기대된다.","Identifying defects in textiles is a key procedure for quality control. This study attempted to create a model that detects defects by analyzing the images of the fabrics. The models used in the study were deep learning-based VGGNet and ResNet, and the defect detection performance of the two models was compared and evaluated. The accuracy of the VGGNet and the ResNet model was 0.859 and 0.893, respectively, which showed the higher accuracy of the ResNet. In addition, the region of attention of the model was derived by using the Grad-CAM algorithm, an eXplainable Artificial Intelligence (XAI) technique, to find out the location of the region that the deep learning model recognized as a defect in the fabric image. As a result, it was confirmed that the region recognized by the deep learning model as a defect in the fabric was actually defective even with the naked eyes. The results of this study are expected to reduce the time and cost incurred in the fabric production process by utilizing deep learning-based artificial intelligence in the defect detection of the textile industry."
ArcFace를 사용한 경량 신원인식 네트워크,2022,"['ArcFace', 'lightweight CNN', 'identity recognition', 'edge AI']",국문 초록 정보 없음,"In this paper, we propose a lightweight identity recognition network combining ArcFace, a loss function with robust characteristics in the field of face recognition, and ResNet-18. In this paper, ResNet-18 is modified to a single-channel-based network to reduce the computational amount of the ResNet-18 network. And to compensate for the network performance degradation due to the decrease in the number of channels, ArcFace, which uses an angle margin-based loss function, was combined with a single-channel-based ResNet-18 network to compensate for the network performance degradation. The proposed network performed training and inference with 10,056 experimental data sets consisting of face photos of 33 people. As a result of the experiment, it was confirmed that the proposed ArcFace-based lightweight ResNet-18 improved processing speed by about 1.3 times compared to the existing ResNet-18. In addition, an inference accuracy of 96.9%, similar to that of the existing network ResNet-18, which is 97.6%, was derived."
비소세포폐암 환자의 재발 예측을 위한 흉부 CT 영상 패치 기반 CNN 분류 및 시각화,2022,"['Non-Small Cell Lung Cancer(NSCLC)', 'Recurrence Prediction', 'Deep Learning', 'Classification', 'Ensemble Learning', 'Convolutional Neural Network(CNN)1', '비소세포폐암', '재발 예측', '딥러닝', '분류', '앙상블 학습', '합성곱 신경망']","비소세포폐암(NSCLC)은 전체 폐암 중 85%의 높은 비중을 차지하며 사망률(22.7%)이 다른 암에 비해 현저히 높은 암으로비소세포폐암 환자의 수술 후 예후에 대한 예측은 매우 중요하다. 본 연구에서는 종양을 관심영역으로 갖는 비소세포폐암환자의 수술 전 흉부 CT 영상 패치의 종류를 종양 관련 정보에 따라 총 다섯 가지로 다양화하고, 이를 입력데이터로 갖는사전 학습 된 ResNet 과 EfficientNet CNN 네트워크를 사용하여 단일 모델과 간접 투표 방식을 이용한 앙상블 모델, 그리고3 개의 입력 채널을 활용한 앙상블 모델에서의 실험 결과 및 성능을 오분류의 사례와 Grad-CAM 시각화를 통해 비교분석한다. 실험 결과, 종양 주변부 패치를 학습한 ResNet152 단일 모델과 EfficientNet-b7 단일 모델은 각각 87.93%와81.03%의 정확도를 보였다. 또한 ResNet152 에서 총 3 개의 입력 채널에 각각 영상 패치, 종양 주변부 패치, 형상 집중 종양내부 패치를 넣어 앙상블 모델을 구성한 경우에는 정확도 87.93%를, EfficientNet-b7 에서 간접 투표 방식으로 영상 패치와종양 주변부 패치 학습 모델을 앙상블 한 경우에는 정확도 84.48%를 도출하며 안정적인 성능을 보였다.","Non-small cell lung cancer (NSCLC) accounts for a high proportion of 85% among all lung cancer and has a significantly higher mortality rate (22.7%) compared to other cancers. Therefore, it is very important to predict the prognosis after surgery in patients with non-small cell lung cancer. In this study, the types of preoperative chest CT image patches for non-small cell lung cancer patients with tumor as a region of interest are diversified into five types according to tumor-related information, and performance of single classifier model, ensemble classifier model with soft-voting method, and ensemble classifier model using 3 input channels for combination of three different patches using pre-trained ResNet and EfficientNet CNN networks are analyzed through misclassification cases and Grad-CAM visualization. As a result of the experiment, the ResNet152 single model and the EfficientNet-b7 single model trained on the peritumoral patch showed accuracy of 87.93% and 81.03%, respectively. In addition, ResNet152 ensemble model using the image, peritumoral, and shape-focused intratumoral patches which were placed in each input channels showed stable performance with an accuracy of 87.93%. Also, EfficientNet-b7 ensemble classifier model with soft-voting method using the image and peritumoral patches showed accuracy of 84.48%."
무선 단말기 Fingerprint 식별을 위한 딥러닝 구조 개발,2022,"['DMR Fingerprint', 'ResNet-1D', 'fingerprinting feature', 'polar coordinate']","RF-Fingerprint 기술은 전송된 파형에서 송신기의 하드웨어 고유 특성을 추출하는 기술로써, 디바이스 보안분야에 매우 유용한 기술 중의 하나이다. 본 논문은 무선 단말기의 In-phase(I)와 Quadrature(Q) 값을 입력으로 동종무선 단말기 및 이기종 무선 단말기를 식별할 수 있는 fingerprint 특징을 추출하고 이를 식별할 수 있는 딥러닝 구조를제안한다. 동종/이기종 무선 단말기를 식별하기 위한 특징으로 I/Q를 극좌표로 변환한 후 크기 값을 시간축으로 배열한데이터를 무선 단말기의 fingerprinting 특징으로 제안하고 이를 식별하기 위해서 수정된 1차원 ResNet 모델을 제안한다. 실험을 위해서 동일 모델 10대의 두 종류 무선 단말기를 대상으로 제안한 딥러닝 구조의 성능을 분석한다. 제안한딥러닝 구조 및 fingerprint 특징의 성능 검증을 위해서 4000개의 데이터셋 중에서 20%인 800개 데이터셋을 이용하여성능 분석한 결과 약 99.5%의 식별 성능을 보였다.","Radio frequency fingerprinting refers to a methodology that extracts hardware-specific characteristics of a transmitter that are unintentionally embedded in a transmitted waveform. In this paper, we put forward a fingerprinting feature and deep learning structure that can identify the same type of Digital Mobile Radio(DMR) by inputting the in-phase(I) and quadrature(Q). We proposes using the magnitude in polar coordinates of I/Q as RF fingerprinting feature and a modified ResNet-1D structure that can identify them. Experimental results show that our proposed modified ResNet-1D structure can achieve recognition accuracy of 99.5% on 20 DMR."
Development of an Artificial Intelligence-Based Support  Technology for Urethral and Ureteral Stricture Surgery,2022,"['Urethral stricture', 'Ureteral stricture', 'ResNet-50', 'Surgical support technology', 'Endoscope', 'Artificial intelligence']",국문 초록 정보 없음,"Purpose: This paper proposes a technological system that uses artificial intelligence to recognize and guide the operator to the exact stenosis area during endoscopic surgery in patients with urethral or ureteral strictures. The aim of this technological solution was to increase surgical efficiency.Methods: The proposed system utilizes the ResNet-50 algorithm, an artificial intelligence technology, and analyzes images entering the endoscope during surgery to detect the stenosis location accurately and provide intraoperative clinical assistance.The ResNet-50 algorithm was chosen to facilitate accurate detection of the stenosis site.Results: The high recognition accuracy of the system was confirmed by an average final sensitivity value of 0.96. Since sensitivity is a measure of the probability of a true-positive test, this finding confirms that the system provided accurate guidance to the stenosis area when used for support in actual surgery.Conclusions: The proposed method supports surgery for patients with urethral or ureteral strictures by applying the ResNet-50 algorithm. The system analyzes images entering the endoscope during surgery and accurately detects stenosis, thereby assisting in surgery. In future research, we intend to provide both conservative and flexible boundaries of the strictures."
다양한 CNN모델을 사용한 컬러 콘택트렌즈 불량 검출,2022,"['컬러 콘택트렌즈', '딥러닝', 'ResNet', 'GoogLeNet', 'DenseNet', 'MobileNet', 'Contact Lens', 'Deep Learning', 'ResNet', 'GoogLeNet', 'DenseNet', 'MobileNet']","4차 산업혁명과 함께 디지털 전환(Digital Transformation, DX) 기술이 중요해지고 있다. 이와 함께 인공지능을 통한 생산공정에서의 불량 검출 및 분류에 대한 연구가 활발히 이루어지고 있다. 본 논문에서는 다양한 CNN 모델을 사용하여 컬러 콘택트렌즈 생산공정에서 발생하는 불량 검출을 효과적으로 수행하는 모델을 선정하고자 하며, 이를 통해 생산 및 품질의 향상을 이루어, 자원의 낭비와 소비자의 안전을 확보하고자 한다. 이를 위해 컬러 콘택트렌즈 영상에 대한 전처리와 증강을 통해 학습 및 검증  데이터를 생성하였으며, RGB 및 HSV 채널 영상에 대해 ResNet101, GoogLeNet V2, GoogLeNet V4, DenseNet121, MobileNet의 CNN 기법을 활용하여 RGB와 HSV 채널별로 불량 탐지율 비교 분석하였다. 위 모델의 정확도는 순서대로 각각 89.74%, 84.46%, 95.43%, 82.80%, 89.74%로, RGB 채널의 GoogLeNet V4가 가장 높은 불량 검출 정확도를 얻었으며, 대부분의 모델에서 RGB 채널이 HSV 채널보다 더 좋은 결과를 얻어냄을 알 수 있었다.","The importance of Digital Transformation (DX) technology has increased with the Fourth Industrial Revolution. At the same time, research on defect detection and classification in the production process through artificial intelligence has been actively applied. In this paper, we select a model that effectively detects defects that occur in the production process of color contact lenses using various models, secure reducing resource waste and consumer safety by improving production and quality. For this purpose, data for training and validation were generated through preprocessing and augmentation of color contact lens images, using CNN technologies such as ResNet101, GoogLeNet V2, GoogLeNet V4, DenseNet121, MobileNet compared and analyzed the defect detection rate for each RGB channel and HSV channel. The accuracies of the above models are 89.74%, 84.46%, 95.43%, 82.80%, and 89.74% respectively, with GoogLeNet V4 on the RGB channel having the highest defect detection accuracy, and in most models, the RGB channel is higher than the HSV channel."
심혈관 상태 식별을 위한 CNN Block 구조를 적용한 고성능 ECG 데이터 분석시스템,2022,"['CNN block structure', 'ECG data analysis scheme', 'ResNeXt', 'MIT-BIH database', 'F1-score']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝 기반의 핵의학 폐검사 분류 모델 적용,2022,"['컨볼루션 신경망', '딥러닝', '폐 신티그라피', '분류-활성화 맵', '핵의학', 'Convolutional neural network', 'Deep learning', 'Lung scintigraphy', 'Class activation map', 'Nuclear medicine']",국문 초록 정보 없음,"The purpose of this study is to apply a deep learning model that can distinguish lung perfusion and lung ventilation images in nuclear medicine, and to evaluate the image classification ability. Image data pre-processing was performed in the following order: image matrix size adjustment, min-max normalization, image center position adjustment, train/validation/test data set classification, and data augmentation. The convolutional neural network(CNN) structures of VGG-16, ResNet-18, Inception-ResNet-v2, and SE-ResNeXt-101 were used. For classification model evaluation, performance evaluation index of classification model, class activation map(CAM), and statistical image evaluation method were applied. As for the performance evaluation index of the classification model, SE-ResNeXt-101 and Inception-ResNet-v2 showed the highest performance with the same results. As a result of CAM, cardiac and right lung regions were highly activated in lung perfusion, and upper lung and neck regions were highly activated in lung ventilation. Statistical image evaluation showed a meaningful difference between SE-ResNeXt-101 and Inception-ResNet-v2. As a result of the study, the applicability of the CNN model for lung scintigraphy classification was confirmed. In the future, it is expected that it will be used as basic data for research on new artificial intelligence models and will help stable image management in clinical practice."
Feasibility of Deep Learning-Based Analysis of Auscultation for Screening Significant Stenosis of Native Arteriovenous Fistula for Hemodialysis Requiring Angioplasty,2022,"['Angioplasty', 'Deep learning', 'Arteriovenous fistula', 'Auscultation', 'Renal dialysis']",국문 초록 정보 없음,"Objective: To investigate the feasibility of using a deep learning-based analysis of auscultation data to predict significant stenosis of arteriovenous fistulas (AVF) in patients undergoing hemodialysis requiring percutaneous transluminal angioplasty (PTA).Materials and Methods: Forty patients (24 male and 16 female; median age, 62.5 years) with dysfunctional native AVF were prospectively recruited. Digital sounds from the AVF shunt were recorded using a wireless electronic stethoscope before (pre-PTA) and after PTA (post-PTA), and the audio files were subsequently converted to mel spectrograms, which were used to construct various deep convolutional neural network (DCNN) models (DenseNet201, EfficientNetB5, and ResNet50). The performance of these models for diagnosing ≥ 50% AVF stenosis was assessed and compared. The ground truth for the presence of ≥ 50% AVF stenosis was obtained using digital subtraction angiography. Gradient-weighted class activation mapping (Grad-CAM) was used to produce visual explanations for DCNN model decisions.Results: Eighty audio files were obtained from the 40 recruited patients and pooled for the study. Mel spectrograms of “pre-PTA” shunt sounds showed patterns corresponding to abnormal high-pitched bruits with systolic accentuation observed in patients with stenotic AVF. The ResNet50 and EfficientNetB5 models yielded an area under the receiver operating characteristic curve of 0.99 and 0.98, respectively, at optimized epochs for predicting ≥ 50% AVF stenosis. However, Grad- CAM heatmaps revealed that only ResNet50 highlighted areas relevant to AVF stenosis in the mel spectrogram.Conclusion: Mel spectrogram-based DCNN models, particularly ResNet50, successfully predicted the presence of significant AVF stenosis requiring PTA in this feasibility study and may potentially be used in AVF surveillance."
A Study on the Optimal Artificial Intelligence Model for  Determination of Urolithiasis,2022,"['Urolithiasis', 'Ureter stones', 'ResNet-50', 'Fast R-CNN', 'Surgical support technology']",국문 초록 정보 없음,"Purpose: This paper aims to develop a clinical decision support system (CDSS) that can help detect the stone that is most important to the diagnosis of urolithiasis. Among them, especially for the development of artificial intelligence (AI) models that support a final judgment in CDSS, we would like to study the optimal AI model by comparing and evaluating them.Methods: This paper proposes the optimal ureter stone detection model using various AI technologies. The use of AI technology compares and evaluates methods such as machine learning (support vector machine), deep learning (ResNet-50, Fast RCNN), and image processing (watershed) to find a more effective method for detecting ureter stones.Results: The final value of sensitivity, which is calculated using true positive (TP) and false negative and is a measure of the probability of TP results, showed high recognition accuracy, with an average value of 0.93 for ResNet-50. This finding confirmed that accurate guidance to the stones area was possible when the developed platform was used to support actual surgery.Conclusions: The general situation in the most effective way to the detection stone can be found. But a variety of variables may be slightly different the difference through the term could tell. Future works, on urological diseases, are diverse and the research will be expanded by customizing AI models specialized for those diseases."
새로운 반려견 등록방식 도입을 위한 안면 인식 성능 개선 연구,2022,"['Deep Learning', 'Face Recognition', 'Dog Recognition', 'ResNet', 'Triplet Loss']","동물보호법 개정에 따라 반려견 등록이 의무화 되었음에도 불구하고, 현재 등록 방법의 불편함으로 등록율이 저조한 상태이다. 본논문에서는 새로운 등록 방법으로 검토되고 있는 반려견 안면 인식 기술에 대한 성능 개선 연구를 진행하였다. 딥러닝 학습을 통해,반려견의 안면 인식을 위한 임베딩 벡터를 생성하여 반려견 개체별로 식별하기 위한 방법을 실험하였다. 딥러닝 학습을 위한 반려견이미지 데이터셋을 구축하고, InceptionNet과 ResNet-50을 백본 네트워크로 사용하여 실험하였다. 삼중항 손실 방법으로 학습하였으며,안면 검증과 안면 식별로 나뉘어 실험하였다. ResNet-50 기반의 모델에서 최고 93.46%의 안면 검증 성능을 얻을 수 있었으며, 안면식별 시험에서는 rank-5에서 91.44%의 최고 성능을 각각 얻을 수 있었다. 본 논문에서 제시한 실험 방법과 결과는 반려견의 등록 여부 확인, 반려견 출입시설에서의 개체 확인 등 다양한 분야로 활용이 가능하다.",다국어 초록 정보 없음
딥러닝기반 토마토 병해 진단 서비스 연구,2022,"['딥러닝', '토마토병해충', '모바일넷', '레스넷', 'deep learning', 'tomato disease', 'MobileNet', 'ResNet']","토마토 작물은 병해에 노출이 쉽고 단시간에 퍼지므로 병해에 대한 늦은 조치로 인한 피해는 생산량과 매출에 직접적인 영향을 끼친다.  따라서, 토마토의 병해에 대해 누구나 현장에서 간편하고 정확하게 진단하여 조기 예방을 가능하게 하는 서비스가 요구된다. 본 논문에서는 사전에 ImageNet 전이 학습된 딥러닝 기반 모델을 적용하여 토마토의 9가지 병해 및 정상인 경우의 클래스를 분류하고 서비스를 제공하는 시스템을 구성한다. Plant Village 데이터 셋으로부터 토마토 병해 및 정상을 분류한 잎의 이미지 셋을 합성곱을 사용하여 조금 더 가벼운 신경망을 구축한 딥러닝 기반 CNN구조를 갖는 MobileNet, ResNet의 입력을 사용한다. 2가지 제안 모델의 학습을 통해 정확도와 학습속도가 빠른 MobileNet를 사용하여 빠르고 편리한 서비스를 제공할 수 있다.","Tomato crops are easy to expose to disease and spread in a short period of time, so late measures against disease are directly related to production and sales, which can cause damage. Therefore, there is a need for a service that enables early prevention by simply and accurately diagnosing tomato diseases in the field. In this paper, we construct a system that applies a deep learning-based model in which ImageNet transition is learned in advance to classify and serve nine classes of tomatoes for disease and normal cases. We use the input of MobileNet, ResNet, with a deep learning-based CNN structure that builds a lighter neural network using a composite product for the image set of leaves classifying tomato disease and normal from the Plant Village dataset. Through the learning of two proposed models, it is possible to provide fast and convenient services using MobileNet with high accuracy and learning speed."
CNN 기반 모델들을 활용한 버섯 이미지 분류 연구,2022,[],"본 논문에서는 버섯 이미지의 분류를 위하여 CNN 기반 모델(LeNet, ResNet50, ResNet152, MobileNet)을 사용하였다. 본 연구에 사용된 데이터는 Kaggle에 데이터 세트를 이용하였다. 정확도를 높이기 위해 데이터 전처리 작업과 4개 정도의 모델들을 활용해 보았다. 여러 모델들을 이용하여 학습하였을 때, 분류 예측 정확도는 ResNet, MobileNet에서 75% 정도가 나온 것을 확인할 수 있었다. 더 나아가 이렇게 학습된 분류 모델을 활용하여 독버섯으로 인한 사고가 방지되길 기대한다.",다국어 초록 정보 없음
안전벨트에 관성측정장치 장착을 통한 운전자의 호흡 상태 모니터링,2022,"['운전자 모니터링 시스템', '생체신호 분석', '관성측정장치', '운전자 상태 분류', 'Driver Monitoring Systems', 'Bio-Signal Data Measurement', 'Inertial Measurement Unit', 'ResNet', 'Driver States Classification']","사람의 건강 상태를 파악하는 것은 응급상황 예방 및 대처에 있어 매우 중요하다. 호흡 상태와 같은 생활 징후를 파악하는 것은 응급상황 발생 여부를 확인할 수 있는 주요한 요소로 작용한다. 이때, 운전자의 생체신호로부터 운전 중에 발생하는 응급상황을 모니터링할 수 있다면, 운전자의 제어권 상실로 인해 발생하는 교통사고에 대한 대처가 가능하다. 본 논문에서는 운전자의 응급상황을 모니터링하기 위해 운전자의 흉부 움직임을 측정하고, 측정된 데이터를 통해 운전자의 호흡 상태를 분류한다. 운전자의 호흡 상태는 관성측정장치를 사용하여 측정하고, Kalman filter를 통해 가속도와 자이로 센서값에 대한 노이즈를 제거한다. 이후, 운전자의 호흡 상태를 정확히 분류하기 위해 데이터를 이미지로 가시화하며, ResNet을 통한 학습을 진행한다. 각 이미지화된 데이터에 대한 분류 성능을 비교하고, 가장 높은 정확도를 보이는 관성측정장치의 데이터를 확인한다.","Monitoring a person""s health status is a crucial factor to prevent and react to emergencies. Especially, identifying vital signs such as respiratory status is directly related to recognizing urgent situations. Therefore, we can initiatively respond to traffic accidents caused by the loss of control/consciousness if the emergencies can be detected based on a person’s vital reaction while driving a car. To solve this issue, this paper proposes a methodology to monitor the emergencies in driver’s health condition by measuring the dynamic movement of a chest and then classifying the respiratory conditions. First, the driver’s respiratory status is measured by a seat belt equipped with an inertial measurement unit (IMU) and the measured data is denoised by applying the Kalman filter. To classify respiratory status, next, each IMU data is visualized as an image, and then the image is used to train the ResNet. Finally, the classification accuracies under various combinations of visualization approaches and IMU data types are compared to scrutinize the combination yielding the best classification accuracy. The result from this study allows us to design a driver respiratory monitoring system with the IMU installed seat belt."
Two-phase flow pattern online monitoring system based on convolutional neural network and transfer learning,2022,"['Flow pattern', 'Online monitoring system', 'Artificial neural network (ANN)', 'Convolutional neural network (CNN)', 'Transfer learning', 'ResNet50']",국문 초록 정보 없음,"Two-phase flow may almost exist in every branch of the energy industry. For the corresponding engineering design, it is very essential and crucial to monitor flow patterns and their transitions accurately.With the high-speed development and success of deep learning based on convolutional neural network (CNN), the study of flow pattern identification recently almost focused on this methodology. Additionally, the photographing technique has attractive implementation features as well, since it is normally considerably less expensive than other techniques. The development of such a two-phase flow pattern online monitoring system is the objective of this work, which seldom studied before. The ongoing preliminary engineering design (including hardware and software) of the system are introduced. The flow pattern identification method based on CNNs and transfer learning was discussed in detail. Several potential CNN candidates such as ALexNet, VggNet16 and ResNets were introduced and compared with each other based on a flow pattern dataset. According to the results, ResNet50 is the most promising CNN network for the system owing to its high precision, fast classification and strong robustness. This work can be a reference for the online monitoring system design in the energy system."
Automatic detection of icing wind turbine using deep learning method,2022,"['convolutional neural networks', 'deep learning method', 'grad-CAM', 'icing', 'wind turbine', 'inception-V3', 'resnet-50', 'score-CAM', 'VGG-16', 'VGG-19']",국문 초록 정보 없음,"Detecting the icing on wind turbine blades built-in cold regions with conventional methods is always a very laborious, expensive and very difficult task. Regarding this issue, the use of smart systems has recently come to the agenda. It is quite possible to eliminate this issue by using the deep learning method, which is one of these methods. In this study, an application has been implemented that can detect icing on wind turbine blades images with visualization techniques based on deep learning using images. Pre-trained models of Resnet-50, VGG-16, VGG-19 and Inception-V3, which are well-known deep learning approaches, are used to classify objects automatically. Grad-CAM, Grad-CAM++, and Score-CAM visualization techniques were considered depending on the deep learning methods used to predict the location of icing regions on the wind turbine blades accurately. It was clearly shown that the best visualization technique for localization is Score-CAM. Finally, visualization performance analyses in various cases which are close-up and remote photos of a wind turbine, density of icing and light were carried out using Score-CAM for Resnet-50. As a result, it is understood that these methods can detect icing occurring on the wind turbine with acceptable high accuracy"
딥러닝 기반의 반도체 패키지 다이면 스크래치 검출 방법,2022,"['Scratch Detection', 'Deep Learning', 'Image Processing', 'Semiconductor Package', '.']",국문 초록 정보 없음,.
설명 가능한 합성곱 신경망을 활용한 센서 기반의 시계열 데이터 분류 모델 제안,2022,"['Sensor Data', 'Time Series Classification', 'Pattern Recognition', 'Deep Learning', 'eXplainable Artificial Intelligence(XAI)', '센서 데이터', '시계열 데이터 분류', '패턴 인식', '딥러닝', '설명가능한 인공지능']","센서 데이터를 활용하여 설비의 이상 진단이 가능해졌다. 하지만 설비 이상에 대한 원인 분석은 미비한 실정이다. 본 연구에서는 센서 기반 시계열 데이터 분류 모델을 위한 해석가능한 합성곱 신경망 프레임워크를 제안한다. 연구에서 사용된 센서 기반 시계열 데이터는 실제 차량에 부착된 센서를 통해 수집되었고, 반도체의 웨이퍼 데이터는 공정 과정에서 수집되었다. 추가로 실제 기계 설비에서 수집된 주기 신호 데이터를 이용 하였으며, 충분한 학습을 위해 Data augmentation 방법론인 Scaling과 Jittering을 적용하였다. 또한, 본 연구에서는 3가지 합성곱 신경망 기반 모델들을 제안하고 각각의 성능을 비교하였다. 본 연구에서는 ResNet에 Jittering을 적용한 결과 정확도 95%, F1 점수 95%로 가장 뛰어난 성능을 보였으며, 기존 연구 대비 3%의 성능 향상을 보였다. 더 나아가 결과의 해석을 위한 XAI 방법론으로 Class Activation Map과 Layer Visualization을 제안하였으며, 센서 데이터 분류에 중요 영향을 끼치는 시계열 구간을 시각적으로 확인하였다.","Sensor data can provide fault diagnosis for equipment. However, the cause analysis for fault results of equipment is not often provided. In this study, we propose an explainable convolutional neural network framework for the sensor-based time series classification model. We used sensor-based time series dataset, acquired from vehicles equipped with sensors, and the Wafer dataset, acquired from manufacturing process. Moreover, we used Cycle Signal dataset, acquired from real world mechanical equipment, and for Data augmentation methods, scaling and jittering were used to train our deep learning models. In addition, our proposed classification models are convolutional neural network based models, FCN, 1D-CNN, and ResNet, to compare evaluations for each model. Our experimental results show that the ResNet provides promising results in the context of time series classification with accuracy and F1 Score reaching 95%, improved by 3% compared to the previous study. Furthermore, we propose XAI methods, Class Activation Map and Layer Visualization, to interpret the experiment result. XAI methods can visualize the time series interval that shows important factors for sensor data classification."
반려견 자동 품종 분류를 위한 전이학습 효과 분석,2022,"['Deep Learning', 'Transfer Learning', 'Resnet', 'VGGNet', 'Dog Breed']",국문 초록 정보 없음,"Compared to the continuously increasing dog population and industry size in Korea, systematic analysis of related data and research on breed classification methods are very insufficient. In this paper, an automatic breed classification method is proposed using deep learning technology for 14 major dog breeds domestically raised. To do this, dog images are collected for deep learning training and a dataset is built, and a breed classification algorithm is created by performing transfer learning based on VGG-16 and Resnet-34 as backbone networks. In order to check the transfer learning effect of the two models on dog images, we compared the use of pre-trained weights and the experiment of updating the weights. When fine tuning was performed based on VGG-16 backbone network, in the final model, the accuracy of Top 1 was about 89% and that of Top 3 was about 94%, respectively. The domestic dog breed classification method and data construction proposed in this paper have the potential to be used for various application purposes, such as classification of abandoned and lost dog breeds in animal protection centers or utilization in pet-feed industry."
Scaling Up Face Masks Classification Using a Deep Neural Network and Classical Method Inspired Hybrid Technique,2022,"['CNNs', 'Face masks', 'Machine learning', 'Multi-layer perceptron', 'ResNet-101']",국문 초록 정보 없음,"Classification of persons wearing and not wearing face masks in images has emerged as a new computer vision problem during the COVID-19 pandemic. In order to address this problem and scale up the research in this domain, in this paper a hybrid technique by employing ResNet-101 and multi-layer perceptron (MLP) classifier has been proposed. The proposed technique is tested and validated on a self-created face masks classification dataset and a standard dataset. On self-created dataset, the proposed technique achieved a classification accuracy of 97.3%. To embrace the proposed technique, six other state-of-the-art CNN feature extractors with six other classical machine learning classifiers have been tested and compared with the proposed technique. The proposed technique achieved better classification accuracy and 1-6% higher precision, recall, and F1 score as compared to other tested deep feature extractors and machine learning classifiers."
합성곱신경망 모델에 따른 침엽수재 수종식별 성능 비교 및 최적 모델 개발,2022,[],국문 초록 정보 없음,"The four convolutional neural network(CNN) architectures such as GoogLeNet, ResNet50, VGG16, and modified CNN were analyzed for investigating the effect of environmental variables on the accuracy of species identification like focused position, epochs, data augmentation and optimizer. Totally 5,535 cross-section images including 1,535 images of low-magnification(40X), 2,000 images of earlywood focused image(200X), and 2,000 images of latewood focused image(200X) were prepared for the dataset establishment. After the preparation, each dataset was randomly separated into 80% of the training group and 20% of the verification group. Data augmentation was applied only in training group for verifying the effectiveness of the dataset amount. As a result of training and verification process, the GoogLeNet architecture increased classification accuracy in proportion to the number of training epochs, and its classification accuracy achieved 99.0% at training process and 98.1% at verification process when applied non-augmented latewood dataset. In augmented latewood dataset, classification accuracy achieved 91.1% and 91.6% at training and verification process, respectively. In contrast, the best classification accuracy of ResNet50 architecture was 87.7% at training process and 71.3% at verification process. VGG16 architecture showed poor performance with around 10% accuracy at both training and verification processes under all conditions. The modified CNN architecture showed excellent classification accuracy with 95.9~99.8% at training process and 95.1~96.9% at verification process when using the earlywood dataset with 100 epochs condition. Moreover, the latewood dataset with 100 epochs condition also makes remarkable results as 96.2~99.2% at training process and 96.5~96.7% at verification process. Based on the results, data augmentation was not significantly affected to classification accuracy of CNN based softwood identification system in this research. In contrast, classification accuracy showed the increased tendency with an increment of training epochs and adoption of the latewood dataset."
합성곱 신경망 기반 분류 모델의 화재 예측 성능 분석,2022,"['Fire detection', 'Fire image classification', 'Convolutional neural network', 'Fire prediction performance']","본 연구에서는 화재 안전 향상을 위한 엣지 컴퓨팅(edge computing) 기반 화재감지시스템에 적용 가능한 합성곱 신경망 기반 이미지 분류 모델들인 MobileNetV2, ResNet101, EfficientNetB0를 이용하여 화재 예측 성능 해석을 수행하였다. 성능평가지표인 정확도, 재현율, 정밀도, F1-score와 혼동 행렬을 이용하여 화재 예측 성능을 비교 분석하였다. 또한 분류 모델의 경량화와 관련한 모델 용량 및 추론시간에 대한 비교 분석을 수행하였다. 비교 분석 결과로서 화재 예측 정확도는 EfficientNetB0 모델이 가장 높았으며 경량성 측면에서는 MobileNetV2가 가장 우수한 것으로 확인하였다. 더하여 화재와 유사한 특징을 갖는 비 화재 이미지인 빛과 연무에 대한 이미지 특성을 추가 학습한 결과, 경량성은 우수하나 예측 성능이 낮은 MobileNetV2의 화재 예측 정확도가 개선되는 것을 확인하였다.","In this study, fire prediction performance was analyzed using convolutional neural network (CNN)-based classification models such as MobileNetV2, ResNet101, and EfficientNetB0 applicable to an edge computing-based fire detection system for improving fire safety. The fire prediction performance was evaluated using the performance evaluation measures including accuracy, recall, precision, F1-score, and the confusion matrix. The model size and inference time were assessed in terms of the light-weight classification model for the practical deployment and use. The analysis results confirmed that the EfficientNetB0 model had the highest fire prediction accuracy, and the MobileNetV2 was the best light-weight classification model. Notably, additionally learning the image features about light and haze images having similar features with those of the fire images improved the fire prediction accuracy of the light-weight MobileNetV2 model."
감정 분류를 이용한 표정 연습 보조 인공지능,2022,"['감정 분류', '표정 연습', '얼굴 이미지 처리', '자연어 처리', 'Emotion Classification', 'Facial Expression Practice', 'Facial Image Processing', 'Natural Language Processing']",본 연구에서는 감정을 표현하기 위한 표정 연습을 보조하는 인공지능을 개발하였다. 개발한 인공지능은 서술형 문장과 표정 이미지로 구성된 멀티모달 입력을 심층신경망에 사용하고 서술형 문장에서 예측되는 감정과 표정 이미지에서 예측되는 감정 사이의 유사도를 계산하여 출력하였다. 사용자는 서술형 문장으로 주어진 상황에 맞게 표정을 연습하고 인공지능은 서술형 문장과 사용자의 표정 사이의 유사도를 수치로 출력하여 피드백한다. 표정 이미지에서 감정을 예측하기 위해 ResNet34 구조를 사용하였으며 FER2013 공공데이터를 이용해 훈련하였다. 자연어인 서술형 문장에서 감정을 예측하기 위해 KoBERT 모델을 전이학습 하였으며 AIHub의 감정 분류를 위한 대화 음성 데이터 세트를 사용해 훈련하였다. 표정 이미지에서 감정을 예측하는 심층신경망은 65% 정확도를 달성하여 사람 수준의 감정 분류 능력을 보여주었다. 서술형 문장에서 감정을 예측하는 심층신경망은 90% 정확도를 달성하였다. 감정표현에 문제가 없는 일반인이 개발한 인공지능을 이용해 표정 연습 실험을 수행하여 개발한 인공지능의 성능을 검증하였다.,"In this study, an artificial intelligence(AI) was developed to help with facial expression practice in order to express emotions. The developed AI used multimodal inputs consisting of sentences and facial images for deep neural networks (DNNs). The DNNs calculated similarities between the emotions predicted by the sentences and the emotions predicted by facial images. The user practiced facial expressions based on the situation given by sentences, and the AI provided the user with numerical feedback based on the similarity between the emotion predicted by sentence and the emotion predicted by facial expression. ResNet34 structure was trained on FER2013 public data to predict emotions from facial images. To predict emotions in sentences, KoBERT model was trained in transfer learning manner using the conversational speech dataset for emotion classification opened to the public by AIHub. The DNN that predicts emotions from the facial images demonstrated 65% accuracy, which is comparable to human emotional classification ability. The DNN that predicts emotions from the sentences achieved 90% accuracy. The performance of the developed AI was evaluated through experiments with changing facial expressions in which an ordinary person was participated."
포인트 클라우드 및 투영 이미지를 이용한 다중 모달 형상 분류,2022,"['포인트 클라우드', '심층신경망', '딥러닝', '다중 모달', '형상 분류', 'Point Cloud', 'Deep Neural Network', 'Deep Learning', 'Multi-modal', 'Shape Classification']","포인트 클라우드의 형상을 분류하기 위해 심층신경망을 활용할 때, 점들의 좌푯값만을 활용하거나 연산 부담이 큰 3차원 렌더링을 통해 생성한 이미지를 활용하여 형상 분류를 수행한다. 본 연구에서는 좌푯 값과 해당 좌표를 활용해 생성한 투영 이미지를 함께 다중 모달로 심층신경망의 입력으로 활용하는 포인트 클라우드의 형상 분류 기법을 제안한다. 성능 향상 여부를 확인하고자, 좌푯값 기반으로 형상을 분류하는 PointNet과 이미지 기반 분류 모델인 ResNet-18을 조합하여 다중 모달 모델을 구성하고 ModelNet40 데이터셋에 대해서 투영 이미지의 여부 및 방향(등각면, 정면, 측면, 상면)에 따른 성능 평가를 수행하였다. 그 결과 측면 투영 이미지가 함께 고려될 때 가장 성능이 좋았으며, 정면 투영 이미지의 경우가 두 번째로 우수한 성능을 보였다. 이는 포인트 클라우드의 형상 분류에 있어서 좌푯값과 더불어 투영 이미지를 함께 입력으로 활용하는 것이 형상 분류에 효과적임을 뒷받침한다.","A deep neural network is used to classify the shape of the point cloud using only the coordinate values of the points or the rendered image. In this study, we proposed a point cloud shape classification technique using the coordinate values and the projection image generated using the coordinates as an input to a multi-modal deep neural network. To verify the performance improvement, the multi-modal model built using PointNet, which classifies the shapes based on coordinate values, and ResNet-18, an image-based classification model, was evaluated for the shape classification performance on a ModelNet40 dataset. The result showed that the performance was the best when the side projection image was additionally considered and the second best when the front projection image was considered. This supports the idea that the shape classification performance of the point cloud can be improved using the coordinate values and its projection image as the input to the deep neural network in a multi-modal manner."
SVM on Top of Deep Networks for Covid-19 Detection from Chest X-ray Images,2022,"['Covid-19', 'X-ray image', 'Deep learning', 'Support vector machines']",국문 초록 정보 없음,"In this study, we propose training a support vector machine (SVM) model on top of deep networks for detecting Covid-19 from chest X-ray images. We started by gathering a real chest X-ray image dataset, including positive Covid-19, normal cases, and other lung diseases not caused by Covid-19. Instead of training deep networks from scratch, we fine-tuned recent pre-trained deep network models, such as DenseNet121, MobileNet v2, Inception v3, Xception, ResNet50, VGG16, and VGG19, to classify chest X-ray images into one of three classes (Covid-19, normal, and other lung). We propose training an SVM model on top of deep networks to perform a nonlinear combination of deep network outputs, improving classification over any single deep network. The empirical test results on the real chest X-ray image dataset show that deep network models, with an exception of ResNet50 with 82.44%, provide an accuracy of at least 92% on the test set. The proposed SVM on top of the deep network achieved the highest accuracy of 96.16%."
재구성 가능한 모듈 기반 CNN 가속기 구현,2022,"['CNN accelerator', 'module-based architecture', 'FPGA', 'Verilog-HDL', '.']","본 논문에서는 CNN(Convolutional Neural Network)을 구성하는 주요 연산 모듈을 모듈 제어 명령어를 통해 구동함으로써 네트워크를 구현할 수 있는 CNN 가속기를 제안한다. 모듈 기반 CNN 가속기는 합성곱(Convolution), 풀링(Pooling) 등 CNN의 주요 연산 모듈로 구성되어 있으며, 프로세서에서 모듈 제어 명령어를 통해 네트워크 구성에 필요한 연산 모듈을 선택 및 내부 파라미터를 설정 할 수 있다. 본 논문에서 제안하는 모듈 기반 CNN 가속기를 사용하여 Xilinx SoC형 FPGA에 ResNet-18을 구현하였으며 CNN 프레임워크 모델인 PyTorch와 C 기반 검증 모델을 사용하여 출력 결과를 비교 검증하였다. 실험결과, CNN 가속기의 추론 결과는 92.87%의 정확도를 보였다.","In this paper, we propose a CNN(convolution neural network) accelerator that can implement a network by driving main computation modules constituting the CNN through module control commands. The module-based CNN accelerator consists of CNN's main computation modules such as convolution and pooling, and the processor can select the computation module required for network configuration and set internal parameters through module control commands. In this paper, ResNet-18 was implemented on a Xilinx SoC-type FPGA using the proposed module-based CNN accelerator, and the output results were compared and verified using PyTorch, a CNN framework model, and a C-based verification model. As a result of the experiment, the inference result of the CNN accelerator showed an accuracy of 92.87%."
FCPNet : A novel model to predict forward collision based-upon CNN,2022,"['unmanned aerial vehicle', 'convolutional neural network', 'collision prediction', 'Raspberry Pi']",국문 초록 정보 없음,"Predicting real-time collisions in unknown environments is a challenge especially for autonomous vehicles to avoid obstacles during missions. In this paper, we propose a novel approach called FCPNet which is a model based on Convolutional Neural Network (CNN) for a fast collision prediction. FCPNet is designed to run on CPU and embedded in an autonomous Unmanned Aerial Vehicle (UAV). Inspired by DroNet, FCPNet is composed of a ResNet-8 with three residual blocks, a dropout layer, and one output layer. Training and validation data are the Zurich images collected in an unstructured outdoor environment such as a city. This dataset consists of 31, 972 color images in two classes: collision and no collision. FCPNet is compared to VGG-16, ResNet50V2, and MobileNetV2 models on CPU. The proposed model achieves the best F1-score and execution time on Raspberry Pi 4 thanks to the optimized parameters and class weights initialization to deal with an imbalanced dataset. The collision prediction probabilities as an alternative approach to ultrasonic sensors are presented in terms of confusion matrix showing the outstanding performance of FCPNet. We plan to use the proposed model with an obstacle avoidance policy to build robust and fast autonomous aerial vehicles."
발레 자세 교정을 위한 발레 동작 코칭 시스템,2022,"['발레', '심플 포즈', '오픈 포즈', '관절 좌표 추출', '특징 중요도 분석', 'Ballet', 'Simple pose', 'Open pose', 'Keypoints detection', 'Analysis of feature importance']","발레는 몸의 가동 범위가 넓은 운동인 만큼 정확하지 않은 자세로 운동을 하게 되면 부상을 입을 수 있고, 운동 효과를 느끼기 어렵다는 문제점이 있다. 이에 사용자가 올바른 자세로 운동을 할 수 있도록 돕는 발레 코칭 시스템을 제안한다. 제안한 방법은 15개의 관절이 레이블링 된 발레 동작을 기반으로 ResNet 기반의 Simple pose 모델과 Open pose의 BODY-25 모델을 사용하여 관절의 좌표를 검출한다. 검출한 관절 좌표의 분포를 히스토그램의 분위 수 분석을 통해 분석했다. 6가지 분류기를 통해 3가지 발레 동작 분류를 4가지 성능 지표를 통해 분석한다. Gradient Boosting Classifier가 비교한 모델 중 가장 최적의 성능 획득했다. 특징 중요도 분석 결과, 발목 관절이 중요하게 사용됨을 확인했다. 또한 4가지 특징 추출 방법에 따른 모델의 성능을 분석했다. 그리고 Odds ratio를 구하여 동작 별 예측 성공 비율을 비교했다. 제안한 방법이 발레 동작 코칭을 할 수 있음을 확인했다.","Since ballet is an exercise with a wide range of movement, if you exercise with an incorrect posture, you may get injured and it is difficult to feel the effect of the exercise. We propose a ballet coaching system that helps users to exercise with correct posture. The proposed method detects joint coordinates using the ResNet-based Simple pose model and the Open pose BODY-25 model based on ballet motions labeled with 15 joints. Analysis of the quantiles of the histogram was performed on the distribution of the detected joint coordinates. Using 6 classifiers, 3 ballet motion classifications are analyzed through 4 performance indicators. Gradient Boosting Classifier obtained the most optimal performance among the compared models. As a result of the feature importance analysis, it was confirmed that the ankle joint is important. We also analyzed the performance of the model according to four feature extraction method. And the Odds ratio was obtained and the prediction success rates for each motion were compared. The proposed method can coach ballet movements."
구강암 조기발견을 위한 영상인식 시스템,2022,[],국문 초록 정보 없음,"Oral cancer is a type of cancer that has a high possibility to be cured if it is threatened earlier. The convolutional neural network is very popular for being a good algorithm for image recognition. In this research, we try to compare 4 different architectures of the CNN algorithm: Convnet, VGG16, Inception V3, and Resnet. As we compared those 4 architectures we found that VGG16 and Resnet model has better performance with an 85.35% accuracy rate compared to the other 3 architectures. In the future, we are sure that image recognition can be more developed to identify oral cancer earlier."
Softwood Species identification using Convolutional Neural Network,2022,"['Species identification', 'Species classification', 'Convolutional Neural Network', 'Deep learning']",국문 초록 정보 없음,"In order to improve the accessibility of wood species identification, the four domestic and six imported softwood species were classified using deep learning method. The cross-section micrographs were used as a dataset; which 1,535 images of 40x micrographs with earlywood and latewood, and 2,000 images of 200x micrographs for earlywood and latewood each. The classification accuracy and loss rate of 10 species were compared using the four convolutional neural network models such as modified CNN, GoogLeNet, VGG16, and ResNet. In verifying the classification accuracy and loss rate by model, the influencing factors, such as epochs, collected part of the dataset, and dataset augmentation, were analyzed. The modified CNN and GoogLeNet models increased classification accuracy in proportion to the number of epochs, achieving more than 95% classification accuracy in the final stage. At the same time, the loss rate decreased with decreasing the number of epochs. VGG16 model showed a low classification accuracy of 20~30% and a high loss rate regardless of the number of epochs during learning under the same conditions as the other models. The ResNet model showed a high classification accuracy of over 90%, with a low loss rate during the training process. However, classification accuracy decreased to 20~30%, with a high loss rate when the test process. As a result of analyzing the general trends in the four models, the classification accuracy increased with increasing the number of epochs in the latewood and total dataset. In contrast, the earlywood dataset didn't show any tendency. The dataset augmentation was not significantly correlated with the classification accuracy and loss rate. Based on these results, modified CNN and GoogLeNet models among the four deep learning models showed excellent wood species classification performance. Further, it is expected that the two models can be applied to identify unknown ten softwood species."
Performance Comparison of Backbone Networks for Multi-Tasking in Self-Driving Operations,2022,"['Deep learning', 'drivable area segmentation', 'end-to-end', 'lane detection', 'multi-tasking', 'object detection']",국문 초록 정보 없음,"In the era of big data, increased focus has been on improving neural network based Deep Learning models. This led to various classification networks which can be used as a backbone in multi-task learning. However, depending on the selected backbone, multi-tasking performance differs. While given backbone network shows better performance on a detection task, does not mean such performance generalizes in segmentation task as well. Detailed investigations should be conducted to achieve best inference speed-accuracy trade-off prior to implementing a single neural network, which handles multiple tasks. In this research, the performance comparison among EfficientNet, ResNet101, VGG16, ResNet50 and MobilenetV2 on the Berkeley Driving Dataset (BDD100K) for autonomous driving using multi-tasking architecture are provided. Backbones that offer best time-accuracy trade-off for multi-task learning are evaluated. Implemented architecture contains three most crucial tasks in self-driving operations, object detection, drivable area segmentation and lane detection. EfficientNet based model showed the best mAP on the object detection task, as well as on the segmentation tasks, extracting both the long and wide roads with accurate lane lines. The model with MobilenetV2 backbone however, demonstrates the fastest inference speed with relatively lower performance in all tasks."
Real-time Fruit Cluster Spatial Coordinates Extraction and Instance Segmentation using a RGB depth camera,2022,"['Depth camera', 'Instance segmentation', 'Fruit cluster', 'Fruit thinning', 'Spatial coordinates extraction']",국문 초록 정보 없음,"Preserving a phenotypic optimal fruit and thining other fruits are the key process of fruit production. The real-time detection of phenotypic optimal fruit can provide a new management strategy and technical support for orchard managers. Since manual screening is very inconvenient, effective screening is a key link to reduce costs and increase production efficiency. Therefore, the goal of this study was to develop a new fruit cluster detection technology to support robot fruit thinning. This research work brought several contributions. The ground truth data was converted into the Creating Common Object in Context (COCO) annotation format. The model using the backbone structure ReSNet-101-FPN was trained. The spatial location of fruit clusters was extracted using a depth camera. The results showed that Detectron2's Mask R-CNN with a ReSNet-101-FPN backbone was determined to be the optimal model. A method combining instance segmentation with distance calculation of a target objects was proposed. It could accurately screen out single optimal fruit from fruit clusters and could also be used for segmentation and analysis of other types of fruit clusters．"
The Evaluation of Deep Learning Using Convolutional Neural Network (CNN) Approach for Identifying Arabica and Robusta Coffee Plants,2022,"['Leaf classification', 'Robusta coffee', 'Arabica coffee', 'Convolutional neural network', 'Coffee species', 'Precision agriculture']",국문 초록 정보 없음,"Purpose Arabica and Robusta coffee plants are physically distinctive as manifested in their leaves, leaf shape, color, and size.However, for ordinary people or those who have just begun their business in coffee cultivation, identifying the type of coffee plant can be challenging. In this study, we incorporated and evaluated deep learning technology to identify the types of coffee based on leaf image identification.Methods In this study, we designed a deep learning architecture and compared it with the well-known approaches, including LeNet, AlexNet, ResNet-50, and GoogleNet. A total of 19,980 image datasets were split into training and testing data, consisting of 15,984 images and 3,996 images, respectively.Results The hyperparameters were taken into account where the use of 100 epoch and 0.0001 learning rate provided the highest accuracy. In addition, 10-fold cross-validation and ROC were used for evaluating the proposed architectures. The results show that the developed convolutional neural network (CNN) generated the highest accuracy of 97.67% compared to LeNet, AlexNet, ResNet-50, and GoogleNet with an accuracy rate of 97.20%, 95.10%, 72.35%, and 82,16%, respectively.Conclusions The modified-CNN algorithm had satisfactory accuracy in identifying different types of coffee. The underlying principles of such classification draw specific attention to the leaf shape, size, and color of Arabica and Robusta coffee. For future works, it is a potential method that can be used to rapidly identify diverse varieties of Robusta and Arabica coffee plants based on leaf tissue and above canopy characteristics."
Corneal Ulcer Region Detection With Semantic Segmentation Using Deep Learning,2022,[],국문 초록 정보 없음,"Traditional methods of measuring corneal ulcers were difficult to present objective basis for diagnosis because of the subjective judgment of the medical staff through photographs taken with special equipment. In this paper, we propose a method to detect the ulcer area on a pixel basis in corneal ulcer images using a semantic segmentation model. In order to solve this problem, we performed the experiment to detect the ulcer area based on the DeepLab model which has the highest performance in semantic segmentation model. For the experiment, the training and test data were selected and the backbone network of DeepLab model which set as Xception and ResNet, respectively were evaluated and compared the performances. We used Dice similarity coefficient and IoU value as an indicator to evaluate the performances. Experimental results show that when 'crop & resized' images are added to the dataset, it segment the ulcer area with an average accuracy about 93% of Dice similarity coefficient on the DeepLab model with ResNet101 as the backbone network. This study shows that the semantic segmentation model used for object detection also has an ability to make significant results when classifying objects with irregular shapes such as corneal ulcers. Ultimately, we will perform the extension of datasets and experiment with adaptive learning methods through future studies so that they can be implemented in real medical diagnosis environment."
A three-stage deep-learning-based method for crack detection of high-resolution steel box girder image,2022,"['crack detection', 'high-resolution image', 'steel box girder', 'three-stage method']",국문 초록 정보 없음,"Crack detection plays an important role in the maintenance and protection of steel box girder of bridges. However, since the cracks only occupy an extremely small region of the high-resolution images captured from actual conditions, the existing methods cannot deal with this kind of image effectively. To solve this problem, this paper proposed a novel three-stage method based on deep learning technology and morphology operations. The training set and test set used in this paper are composed of 360 images (4928 × 3264 pixels) in steel girder box. The first stage of the proposed model converted highresolution images into sub-images by using patch-based method and located the region of cracks by CBAM ResNet-50 model. The <i>Recall</i> reaches 0.95 on the test set. The second stage of our method uses the Attention U-Net model to get the accurate geometric edges of cracks based on results in the first stage. The <i>IoU</i> of the segmentation model implemented in this stage attains 0.48. In the third stage of the model, we remove the wrong-predicted isolated points in the predicted results through dilate operation and outlier elimination algorithm. The <i>IoU</i> of test set ascends to 0.70 after this stage. Ablation experiments are conducted to optimize the parameters and further promote the accuracy of the proposed method. The result shows that: (1) the best patch size of sub-images is 1024 × 1024. (2) the CBAM ResNet-50 and the Attention U-Net achieved the best results in the first and the second stage, respectively. (3) Pre-training the model of the first two stages can improve the <i>IoU</i> by 2.9%. In general, our method is of great significance for crack detection."
1인 가구 환경에서 프라이버시 보호 영상을 활용한 위험 행동 인식에 관한 연구,2022,"['Deep Learning', 'Privacy', 'Action Recognition', 'YOLOv5', 'Single-person household', '딥러닝', '프라이버시', '행동 인식', '1인 가구']","최근 딥러닝 기술의 발달로 사람의 행동을 인식하는 연구가 진행 중에 있다. 본 논문에서는 딥러닝 기술을 활용하여 1인 가구 환경에서 발생할 수 있는 위험 행동을 인식하는 연구를 진행하였다. 1인 가구의 특성상 개인의 프라이버시 보호가 필요하다. 본 논문에서는 개인의 프라이버시 보호를 위해 가우시안 블러 필터가 적용된 프라이버시 보호 영상에서 사람의 위험 행동을 인식한다. 위험 행동 인식 방법은 객체 검출 모델인 YOLOv5 모델을 활용하여 영상에서 사람 객체 검출 및 전처리 방법을 적용한 후 행동 인식 모델의 입력값으로 활용하여 위험 행동을 인식한다. 실험에는 ResNet3D, I3D, SlowFast 모델을 사용하였고, 실험 결과 SlowFast 모델이 프라이버시 보호 영상에서 95.7%로 가장 높은 정확도를 달성하였다. 이를 통해 개인의 프라이버시를 보호하면서 1인 가구 환경에서 사람의 위험 행동을 인식하는 것이 가능하다.","Recently, with the development of deep learning technology, research on recognizing human behavior is in progress. In this paper, a study was conducted to recognize risky behaviors that may occur in a single-person household environment using deep learning technology. Due to the nature of single-person households, personal privacy protection is necessary. In this paper, we recognize human dangerous behavior in privacy protection video with Gaussian blur filters for privacy protection of individuals. The dangerous behavior recognition method uses the YOLOv5 model to detect and preprocess human object from video, and then uses it as an input value for the behavior recognition model to recognize dangerous behavior. The experiments used ResNet3D, I3D, and SlowFast models, and the experimental results show that the SlowFast model achieved the highest accuracy of 95.7% in privacy-protected video. Through this, it is possible to recognize human dangerous behavior in a single-person household environment while protecting individual privacy."
A new lightweight network based on MobileNetV3,2022,"['MobileNetV3', 'Real-time image classification', 'Lightweight network', 'Deep convolutional neural network', 'residual structure']",국문 초록 정보 없음,"The MobileNetV3 is specially designed for mobile devices with limited memory and computing power. To reduce the network parameters and improve the network inference speed, a new lightweight network is proposed based on MobileNetV3. Firstly, to reduce the computation of residual blocks, a partial residual structure is designed by dividing the input feature maps into two parts. The designed partial residual structure is used to replace the residual block in MobileNetV3. Secondly, a dual-path feature extraction structure is designed to further reduce the computation of MobileNetV3. Different convolution kernel sizes are used in the two paths to extract feature maps with different sizes. Besides, a transition layer is also designed for fusing features to reduce the influence of the new structure on accuracy. The CIFAR-100 dataset and Image Net dataset are used to test the performance of the proposed partial residual structure. The ResNet based on the proposed partial residual structure has smaller parameters and FLOPs than the original ResNet. The performance of improved MobileNetV3 is tested on CIFAR-10, CIFAR-100 and ImageNet image classification task dataset. Comparing MobileNetV3, GhostNet and MobileNetV2, the improved MobileNetV3 has smaller parameters and FLOPs. Besides, the improved MobileNetV3 is also tested on CPU and Raspberry Pi. It is faster than other networks"
합성곱 신경망 및 영상처리 기법을 활용한피부 모공 등급 예측 시스템,2022,"['Skin', 'Pore', 'Image processing', 'CNN', 'Prediction']","본 논문은 사용자들에 의해 촬영된 피부이미지를 가공하여 데이터 세트를 구축하고, 제안한 영상처리 기법에 의해 모공 특징이미지를 생성하여, CNN(Convolution Neural Network) 모델 기반의 모공 상태 등급 예측 시스템을 구현한다. 본 논문에서 활용하는피부이미지 데이터 세트는, 피부미용 전문가의 육안 분류 기준에 근거하여, 모공 특징에 대한 등급을 라벨링 하였다. 제안한 영상처리 기법을 적용하여 피부이미지로 부터 모공 특징 이미지를 생성하고, 모공 특징 등급을 예측하는 CNN 모델의 학습을 진행하였다.제안한 CNN 모델에 의한 모공 특징은 전문가의 육안 분류 결과와 유사한 예측 결과를 얻었으며, 비교 모델(Resnet-50)에 의한 결과보다 적은 학습시간과 높은 예측결과를 얻었다. 본 논문의 본론에서는 제안한 영상처리 기법과 CNN 적용의 결과에 대해 서술하며, 결론에서는 제안한 방법에 대한 결과와 향후 연구방안에 대해 서술한다.","In this paper, we propose a prediction system for skin pore labeling based on a CNN(Convolution NeuralNetwork) model, where a data set is constructed by processing skin images taken by users, and a pore featureimage is generated by the proposed image processing algorithm. The skin image data set was labeled for porecharacteristics based on the visual classification criteria of skin beauty experts. The proposed image processingalgorithm was applied to generate pore feature images from skin images and to train a CNN model that predictspore feature ratings. The prediction results with pore features by the proposed CNN model is similar to expertsvisual classification results, where less learning time and higher prediction results were obtained than the resultsby the comparison model (Resnet-50). In this paper, we describe the proposed image processing algorithm andCNN model, the results of the prediction system and future research plans."
COVID-19 Diagnosis from CXR images through pre-trained Deep Visual Embeddings,2022,"['COVID-19', 'Deep Visual Features', 'Transfer Learning', 'Classification', 'Logistic Regression']",국문 초록 정보 없음,"COVID-19 is an acute respiratory syndrome that affects the host's breathing and respiratory system. The novel disease's first case was reported in 2019 and has created a state of emergency in the whole world and declared a global pandemic within months after the first case. The disease created elements of socioeconomic crisis globally. The emergency has made it imperative for professionals to take the necessary measures to make early diagnoses of the disease. The conventional diagnosis for COVID-19 is through Polymerase Chain Reaction (PCR) testing. However, in a lot of rural societies, these tests are not available or take a lot of time to provide results. Hence, we propose a COVID-19 classification system by means of machine learning and transfer learning models. The proposed approach identifies individuals with COVID-19 and distinguishes them from those who are healthy with the help of Deep Visual Embeddings (DVE). Five state-of-the-art models: VGG-19, ResNet50, Inceptionv3, MobileNetv3, and EfficientNetB7, were used in this study along with five different pooling schemes to perform deep feature extraction. In addition, the features are normalized using standard scaling, and 4-fold cross-validation is used to validate the performance over multiple versions of the validation data. The best results of 88.86% UAR, 88.27% Specificity, 89.44% Sensitivity, 88.62% Accuracy, 89.06% Precision, and 87.52% F1-score were obtained using ResNet-50 with Average Pooling and Logistic regression with class weight as the classifier."
영상 기반 Semantic Segmentation 알고리즘을 이용한 도로 추출,2022,"['Drone Image', 'Semantic Segmentation', 'Remote Sensing', 'Road Extraction', '드론 정사영상', 'Semantic Segmentation', '원격 탐사', '도로 추출']","현대에는 급속한 산업화와 인구 증가로 인해 도시들이 더욱 복잡해지고 있다. 특히 도심은 택지개발, 재건축, 철거 등으로 인해 빠르게 변화하는 지역에 해당한다. 따라서 자율주행에 필요한 정밀도로지도와 같은 다양한 목적을 위해 빠른 정보 갱신이 필요하다. 우리나라의 경우 기존 지도 제작 과정을 통해 지도를 제작하면 정확한 공간정보를 생성할 수 있으나 대상 지역이 넓은 경우 시간과 비용이 많이 든다는 한계가 있다. 지도 요소 중 하나인 도로는 인류 문명을 위한 많은 다양한 자원을 제공하는 중추이자 필수적인 수단에 해당한다. 따라서 도로 정보를 정확하고 신속하게 갱신하는 것이 중요하다. 이 목표를 달성하기 위해 본 연구는 Semantic Segmentation 알고리즘인 LinkNet, D-LinkNet 및 NL-LinkNet을 사용하여 광주광역시 도시철도 2호선 공사 현장을 촬영한 드론 정사영상에서 도로를 추출한 다음 성능이 가장 높은 모델에 하이퍼 파라미터 최적화를 적용하였다. 그 결과, 사전 훈련된 ResNet-34를 Encoder로 사용한 LinkNet 모델이 85.125 mIoU를 달성했다. 향후 연구 방향으로 최신 Semantic Segmentation 알고리즘 또는 준지도 학습 기반 Semantic Segmentation 기법을 사용하는 연구의 결과와의 비교 분석이 수행될 것이다. 본 연구의 결과는 기존 지도 갱신 프로세스의 속도를 개선하는 데 도움을 줄 수 있을 것으로 예상된다.","Cities are becoming more complex due to rapid industrialization and population growth in modern times. In particular, urban areas are rapidly changing due to housing site development, reconstruction, and demolition. Thus accurate road information is necessary for various purposes, such as High Definition Map for autonomous car driving. In the case of the Republic of Korea, accurate spatial information can be generated by making a map through the existing map production process. However, targeting a large area is limited due to time and money. Road, one of the map elements, is a hub and essential means of transportation that provides many different resources for human civilization. Therefore, it is essential to update road information accurately and quickly. This study uses Semantic Segmentation algorithms Such as LinkNet, D-LinkNet, and NL-LinkNet to extract roads from drone images and then apply hyperparameter optimization to models with the highest performance. As a result, the LinkNet model using pre-trained ResNet-34 as the encoder achieved 85.125 mIoU. Subsequent studies should focus on comparing the results of this study with those of studies using state-of-the-art object detection algorithms or semi-supervised learning-based Semantic Segmentation techniques. The results of this study can be applied to improve the speed of the existing map update process."
딥러닝 적용 선별 모델 비교 및 프로토타입 개발: 파프리카 중심으로,2022,"['선별기', '딥러닝', 'Faster R-CNN', 'YOLO', '파프리카']","소비자의 생활 수준이 향상됨에 따라 고품질 농산물에 대한 수요가 증가하고 있다. 과실의 선별은 상품성과 직결되기 때문에 현 소비 트렌드를 따라가기 위해 고려해야 할 주요한 요인 중 하나이다. 중량 선별기의 경우 과실의 중량만을 이용하여 선별하기 때문에 과실의 완숙도 및 장해 여부 선별에 한계가 있고, 광학 선별기의 경우 NIR 카메라 및 다수의 고가 장비를 통해 중량 선별기의 한계를 극복하였으나, 비용적 측면에서 농가에 부담이 따른다. 본 연구에서는 넓은 선별 스펙트럼을 유지하는 동시에 투입되는 장비의 비용을 줄일 수 있는 선별기 제작을 위해 딥러닝 알고리즘인 Faster R-CNN과 YOLO v5를 비교하고, 선별기 프로토타입을 개발하였다. CNN(Convolutional Neural Network)은 이미지 분류에 특화된 딥러닝 알고리즘으로 다중 클래스 분류가 가능하다. Faster R-CNN은 기존 CNN 알고리즘에 별도의 영역 제안 네트워크(RPN, Region Proposal Network)를 적용하여 학습 및 수행 속도가 개선되었다. YOLO(You Only Look Once)는 실시간 객체 인식에 특화된 딥러닝 알고리즘으로 Faster R-CNN과 달리 영역 제안을 위한 별도의 네트워크를 사용하지 않아 처리속도가 빠르다. 코코넛 성숙 단계 분류 연구(Kim et al.등, 2020)에서 Faster R-CNN 모델인 ResNet-50으로 코코넛 이미지 2,000장을 학습한 결과 mAP(평균 정밀도, mean Average Precision)이 89.4% 정확도로 분류하였다. YOLO v3를 이용한 사과 장해 여부 검출 연구(Valdez et al.등, 2020)는 웹으로부터 모은 사과 이미지 452장을 학습한 결과 mAP 74.3%의 정확도를 보고하였다. 본 연구에서 선별 모델로 적합하다고 판단되는 Faster R-CNN의 ResNet-50과 YOLO 모델 중 경량화 특징이 있는 YOLO v5를 이용한 선별 알고리즘을 개발하여 라즈베리파이4 (Raspberry Pi 4, 8GB RAM) 에 구현하여 성능을 비교하였다. 전라북도 부안군 계화면 소재의 ‘파프리카’ 온실에서 파프리카(machay)를 수확하였다. 수확한 파프리카를 촬영하여 학습에 사용할 이미지 데이터를 확보하였고, 웹크롤링을 통해 부족한 이미지 데이터를 추가로 확보하였다. 구득한 이미지 데이터는 ‘성숙과’, ‘미성숙과’, ‘판정보류’, 그리고 ‘비정상과’로 분류하였고, 바운딩 박스를 추가한 라벨데이터를 구축하였다. 전체 이미지 및 라벨 데이터의 80%와, 20%를 각각 학습, 검증에 사용하였다. 카메라 모듈을 통해 실시간으로 촬영하는 영상에 학습한 모델을 적용하여 객체의 클래스를 판별하고, 서보모터가 판별 결과에 따라 레버를 지정한 각도로 움직이도록 설계하였다. 모델의 성능은 mAP, 판별 소요 시간을 평가하였다. 본 연구는 딥러닝을 이용하여 과실의 완숙도 및 장해 여부를 선별하는 데에 그쳤지만, 향후 연구에서 다양한 종류의 이미지 데이터를 확보한다면 병해, 충해, 냉해, 한해 등의 다양한 작물피해 또한 선별하여 범용적으로 적용 가능할 것으로 기대한다.",다국어 초록 정보 없음
언어장애인의 스마트스피커 접근성 향상을 위한 개인화된 음성 분류 기법,2022,"['스마트스피커', '언어장애인', '장애인접근성', '개인화된 음성분류기법', '딥러닝', 'smart speaker', 'speech-impaired people', 'disabled accessibility', 'personalized speech classification scheme', 'deep learning']","음성인식 기술과 인공지능 기술을 기반으로 한 스마트스피커의 보급으로 비장애인뿐만 아니라 시각장애인이나 지체장애인들도 홈 네트워크 서비스를 연동하여 주택의 전등이나 TV와 같은 가전제품을 음성을 통해 쉽게 제어할 수 있게 되어 삶의 질이 대폭 향상되었다. 하지만 언어장애인의 경우 조음장애나 구음장애 등으로 부정확한 발음을 하게 됨으로서 스마트스피커의 유용한 서비스를 사용하는 것이 불가능하다. 본 논문에서는 스마트스피커에서 제공되는 기능 중 일부 서비스를 대상으로 언어장애인이 이용할 수 있도록 개인화된 음성분류 기법을 제안한다. 본 논문에서는 소량의 데이터와 짧은 학습시간으로도 언어장애인이 구사하는 문장의 인식률과 정확도를 높여 스마트스피커가 제공하는 서비스를 실제로 이용할 수 있도록 하는 것이 목표이다. 본 논문에서는 ResNet18 모델을 fine tuning하고 데이터 증강과 one cycle learning rate 최적화 기법을 추가하여 적용하였으며, 실험을 통하여 30개의 스마트스피커 명령어 별로 10회 녹음한 후 3분 이내로 학습할 경우 음성분류 정확도가 95.2% 정도가 됨을 보였다.","With the spread of smart speakers based on voice recognition technology and deep learning technology, not only non-disabled people, but also the blind or physically handicapped can easily control home appliances such as lights and TVs through voice by linking home network services. This has greatly improved the quality of life. However, in the case of speech-impaired people, it is impossible to use the useful services of the smart speaker because they have inaccurate pronunciation due to articulation or speech disorders. In this paper, we propose a personalized voice classification technique for the speech-impaired to use for some of the functions provided by the smart speaker. The goal of this paper is to increase the recognition rate and accuracy of sentences spoken by speech-impaired people even with a small amount of data and a short learning time so that the service provided by the smart speaker can be actually used. In this paper, data augmentation and one cycle learning rate optimization technique were applied while fine-tuning ResNet18 model. Through an experiment, after recording 10 times for each 30 smart speaker commands, and learning within 3 minutes, the speech classification recognition rate was about 95.2%."
딥러닝 기반의 의류 이미지 분석을 통한 텍스타일 재료 분류에 관한 연구,2022,"['분류', '의류', '텍스타일 재료', 'EfficientNet', 'ResNet50']",국문 초록 정보 없음,다국어 초록 정보 없음
ShortcutFusion++: Optimizing an End-to-End CNN Accelerator for High PE Utilization,2022,"['CNN accelerator', 'Processing element', 'Hardware utilization', 'FPGA', 'YOLO-v3']",국문 초록 정보 없음,"ShorcutFusion [1] is an end-to-end framework that effectively maps many well-known deep neural networks (DNNs), such as MobileNet-v2, EfficientNet-B0, ResNet-50, and YOLO-v3, to a generic CNN accelerator on FPGA. Nevertheless, its processing elements are not fully utilized when supporting various networks, leading to relatively low hardware utilization (e.g., 68.42% for YOLO-v3). This study aimed to enhance the performance of ShortcutFusion and introduce ShortcutFusion++ by proposing two simple but effective techniques for eliminating unnecessary stalls in conventional design. First, the prefetching scheme was re-designed to avoid bubble cycles when feeding data to the PE array. Second, the output buffer was reconstructed to pipeline the operations of PEs and the process of writing output feature maps to off-chip memory. The experimental results show that ShortcutFusion++ achieves a PE utilization of 80.95% for the wellknown object detection network YOLO-v3, outperforming its baseline by 12.53%."
전이 학습을 이용한 패션 스타일 검색 서비스,2022,[],우리는 전이 학습을 이용하여 원하는 특정 패션 스타일 분류기를 학습하였다. 패션 스타일 검색 결과물을 온라인 쇼핑몰과 연결하는 웹 서비스를 사용자에게 제공한다. 패션 스타일 분류기는 구글에서 이미지 검색을 통해 수집된 데이터를 이용하여 ResNet34[1]에 전이 학습하였다. 학습된 분류 모델을 이용하여 사용자 이미지로부터 패션 스타일을 17가지 클래스로 분류하였고 F1 스코어는 평균 65.5%를 얻었다. 패션 스타일 분류 결과를 네이버 쇼핑몰과 연결하여 사용자가 원하는 패션 상품을 구매할 수 있는 서비스를 제공한다.,다국어 초록 정보 없음
분할된 휴대 수하물 데이터셋에 대한 다중 Pipeline과 결합한 다중 Student-Teacher 프레임워크의 효과에 관한 연구,2022,[],국문 초록 정보 없음,"In this paper, we investigate the student-teacher framework involving multiple mean teachers coupled with the multiple pipelines on the partitioned SIXRay-10 dataset. Firstly, SIXRay-10 dataset is partitioned and the multiple pipelines are applied with ResNet-50 backbone and Faster R-CNN detector to get the enhanced detection accuracy of 80.6 mAP0.5. Secondly, for each pipeline, a mean teacher model is defined as an exponential moving average of the student model parameters and the pipelines are dynamically aligned according to its bounding box regression loss to get 82.1 mAP0.5."
위성 및 드론 영상을 이용한 해안쓰레기 모니터링 기법 개발,2022,"['Sentinel-2', 'Drone', 'Multispectral image', 'Deep learning', 'Marine debris']",국문 초록 정보 없음,"This study proposes a marine debris monitoring methods using satellite and drone multispectral images. A multi-layer perceptron (MLP) model was applied to detect marine debris using Sentinel-2 satellite image. And for the detection of marine debris using drone multispectral images, performance evaluation and comparison of U-Net, DeepLabv3+ (ResNet50) and DeepLabv3+ (Inceptionv3) among deep learning models were performed (mIoU 0.68). As a result of marine debris detection using satellite image, the F1-Score was 0.97. Marine debris detection using drone multispectral images was performed on vegetative debris and plastics. As a result of detection, when DeepLabv3+ (Inceptionv3) was used, the most model accuracy, mean intersection over union (mIoU), was 0.68. Vegetative debris showed an F1-Score of 0.93 and IoU of 0.86, while plastics showed low performance with an F1-Score of 0.5 and IoU of 0.33. However, the F1-Score of the spectral index applied to generate plastic mask images was 0.81, which was higher than the plastics detection performance of DeepLabv3+ (Inceptionv3), and it was confirmed that plastics monitoring using the spectral index was possible. The marine debris monitoring technique proposed in this study can be used to establish a plan for marine debris collection and treatment as well as to provide quantitative data on marine debris generation."
Steel Surface Defect Detection using the RetinaNet Detection Model,2022,"['Defect Detection', 'Deep Learning', 'Steel Defect Detection', 'RetinaNet model', 'One-Stage Detector']",국문 초록 정보 없음,"Some surface defects make the weak quality of steel materials. To limit these defects, we advocate a onestage detector model RetinaNet among diverse detection algorithms in deep learning. There are several backbones in the RetinaNet model. We acknowledged two backbones, which are ResNet50 and VGG19. To validate our model, we compared and analyzed several traditional models, one-stage models like YOLO and SSD models and two-stage models like Faster-RCNN, EDDN, and Xception models, with simulations based on steel individual classes. We also performed the correlation of the time factor between one-stage and twostage models. Comparative analysis shows that the proposed model achieves excellent results on the dataset of the Northeastern University surface defect detection dataset. We would like to work on different backbones to check the efficiency of the model for real world, increasing the datasets through augmentation and focus on improving our limitation."
기침 파형 패턴을 활용한 COVID-19 확진자 식별 딥러닝 모델,2022,[],"코로나 바이러스(COVID-19)의 확산에 따라 이 질병에 대해 사람들의 관심이 높아졌다. 이러한 사회적 배경 속에서 본 논문은 코로나 증상 중 하나인 기침 소리로 코로나 감염 여부를 예측하는 모델을 만들었다. 기침의 파형을 스펙트로그램 형변환을 거쳐 이미지로 만들었으며, 이를 학습데이터로 사용하였다. ResNet50 모델을 사용하여 학습을 진행하여 예측 결과를 얻었다.",다국어 초록 정보 없음
심층학습 알고리즘을 활용한 인접면 우식 탐지,2022,"['Artificial intelligence', 'Deep learning', 'Proximal caries', 'Primary teeth', 'Intraoral radiography', '.']","이번 연구는 소아의 인접면 우식을 진단하는데 있어 사용하고 있는 구내방사선 사진에서 심층학습(deep learning) 알고리즘을 활용하여 치아우식을 진단하는 모델의 성능을 평가하고자 하였다.제1유구치와 제2유구치 사이의 인접면이 포함된 500개의 구내방사선 사진을 대상으로 연구를 시행하였다. 치아우식을 진단하는 모델의 학습에는 Resnet50 기반의 인공신경망 모델을 사용하였다. 평가자료군에서 진단모델의 정확도, 민감도, 특이도를 구하고, ROC 곡선을 얻어 AUC 값을 바탕으로 분류 모델의 성능을 평가하였다.학습 모델의 정확도는 0.84, 민감도는 0.74, 특이도는 0.94로 나타났으며 AUC는 0.86으로 나타났다.인공신경망을 기반으로 하는 소아의 구내방사선 사진에서의 인접면 우식의 진단 모델은 비교적 높은 정확도를 보여주었다. 심층학습 모델은 구내방사선 사진상에서 인접면 우식을 진단하는데 있어 향후 치과의사를 보조하는 진단 도구로서 활용될 수 있을 것이다.",다국어 초록 정보 없음
기계학습 모델 기반 병해충 진단 연구,2022,[],"최근 이상기온과 기상이변 문제가 대두되는 가운데 병해충으로 인한 작물의 피해사례가 증가하고 있다. 작물의 병해충 진단이 늦어질 경우 농가 전체에 퍼져 큰 피해를 볼 수 있다. 본 논문에서는 병해충 피해를 초기에 진단하기 위해 AlexNet, VGG-16, Inception-v3, ResNet50 모델을 이용하여 작물 이미지의 병해충 진단을 진행하였고, f1-score와 Precision, Recall을 바탕으로 이미지 분류 성능을 검증하였다. 실험 결과 Inception-v3 모델의 f1-score 값이 평균 0.89로 이미지 예측에 가장 적합한 모델임을 확인할 수 있었다.",다국어 초록 정보 없음
스마트팜 이미지 데이터를 이용한 딸기의 생육 단계 분류 모델 개발에 관한 연구,2022,[],본 논문은 이미지 데이터를 이용하여 딸기의 생육 단계를 자동 분류하는 시스템을 개발하고 기존 스마트팜 기술과 연계하여 각 생육 단계 별 적합한 환경 조성과 적절한 수확 시기를 알려주는 시스템을 개발하고자 한다. 딸기의 생육 단계별 이미지 데이터를 제공받고 ResNet50 기반으로 딸기의 생육 단계를 분류하는 모델을 설계하여 딸기의 생육 단계를 분류하는 연구를 진행하였다. 실험 결과 생육 단계 분류 모델의 정확도는 약 98.7%로 나타났고 결과값의 시각화를 통해 분류에 우수한 성능을 나타내는 모델임을 검증하였다.,다국어 초록 정보 없음
미술 심리 치료 분야의 의사결정 지원을 위한 비지도학습 기반의 AI 모델 적용에 관한 연구,2022,"['미술치료', '인간과 컴퓨터 상호작용', '비지도학습', '딥러닝', '이미지 분류', '트랜스포머']","본 논문에서는 미술 심리 치료의 그림검사(Drawing Test) 과정에서 심리 치료사의 의사 결정 도움을 위해 소규모 데이터셋을 활용한 비지도 학습 기반의 모델 개발 가능성에 대해 살펴본다. 비지도학습 기반의 VQViT(Vector Quantized-Vision Transformer)와 BEiT(Bidirectional Encoder representation from Image Transformers) 모델을 지도학습 기반의 ViT(Vision Transformer)와 Resnet-101 모델과 성능 비교 실험을 진행하였다. 그 결과 비지도학습 기반의 BEiT 가 가장 높은 정확도를 보였다. 비지도학습 기반 모델을 활용해 웹 페이지를 제작하였으며, 미술 심리 치료에서의 이미지 분류 모델 활용을 통한 전문가의 의사결정 지원 가능성을 확인하였다. 마지막으로, 본 논문에서는 미술 심리치료 분야에서 딥러닝 기반 이미지 분류 모델 의사결정 지원 방향성을 논의한다.",다국어 초록 정보 없음
Privacy 보호를 위한 인공지능 기반 자율주행 시스템 연구,2022,[],"본 논문에서는 자율주행 중 발생하는 사생활 침해 문제를 해결하기 위한 인공지능 기반 자율 주행 시스템을 제안한다. 영상을 사용하여 실시간으로 교통신호를 판별하여 도로를 성공적으로 주행하도록 한다. 또한, 수집한 영상 데이터 중 개인정보라고 인식되는 얼굴 영역을 스스로 판단하여 모자이크 처리하는 개인정보 보호 기능을 추가로 실현한다. GPU 임베디드보드를 활용하여 자율 주행 차량을 구현한다. 교통신호 판별에는 ResNet18 모델을, 개인정보 보호에는 YOLOv5 기술을 사용하여 각 기능을 병렬적으로 처리한다. 모의실험 결과를 통해 제안하는 시스템의 자율주행 기능 및 실시간 모자이크 처리 성공 여부를 입증한다.",다국어 초록 정보 없음
베어링 진단을 위한 진동 신호 기반의 딥러닝 모델,2022,[],"최근 자동차, 철도차량 등 사용자가 있는 기계 시스템에서의 고장 발생 시 사용자의 안전과 관련된 사고로 이어질 수 있어 부품에 대한 모니터링 및 고장 여부 판단은 매우 중요하다. 이러한 부품 중에서 베어링은 회전체와 회전하지 않는 물체 사이에서 회전이 원활하게 이루어질 수 있도록 하는 부품인데, 베어링에 결함이 발생하게 될 경우, 기계 시스템이 정지하거나, 마찰 열에 의해 화재 등의 치명적인 위험이 발생한다. 본 논문에서는 Resnet과 오토인코더를 활용하여 진동 신호 기반의 베어링의 고장을 감지하고 분류할 수 있는 모델을 제안한다. 제안 방법은 raw data를 이미지로 변환하여 입력으로 사용하는데, 이러한 접근을 통해 수집된 데이터의 손실을 최소화하고 데이터가 가지는 정보를 최대한 분석에 활용할 수 있다. 제안 모델의 검증을 위하여 공개된 데이터셋으로 학습/검증 하였고, 제안 방법이 기존 방법과 비교하여 더 높은 F1 Score와 정확도를 보임을 확인하였다.",다국어 초록 정보 없음
배터리 리드탭 압흔 오류 검출의 딥러닝 기법 적용,2022,"['배터리 리드탭', '압흔 오류 검출', '인공지능', '딥러닝', 'Faster R-CNN', '객체 탐지', 'Battery lead tab', 'Welding error detection', 'Artificial intelligence', 'Deep learning', 'Faster R-CNN', 'Object detection']","자동차용 배터리 제조공정 가운데 하나인 Tab Welding 공정에서 생산된 제품의 샘플링 인장검사를 대체하기 위해 현재 비전검사기를 개발하여 사용하고 있다. 그러나, 비전검사는 검사 위치 오차 문제와 이를 개선하기 위해 발생하는 비용 문제를 가지고 있다. 이러한 문제점들을 해결하기 위해 최근 딥러닝 기술을 적용하는 사례들이 발생하고 있다. 본 논문도 그런 사례 중 하나로 기존 제품 검사에 딥러닝 기술 중 하나인 Faster R-CNN을 적용하여 그 유용성을 파악하고자 하였다. 기존 비전검사기를 통해 획득한 이미지들을 학습 데이터로 사용하여 Faster R-CNN ResNet101 V1 1024x1024 모델을 사용하여 학습하였다. 검사 기준인 미검률 0%, 과검률 10%의 기준으로 기존 비전검사와 Faster R-CNN 검사결과를 비교 분석하였다. 미검출률은 기존 비전검사에서 34.5%, Faster R-CNN 검사에서 0%였다. 과검출률은 기존 비전검사에서 100%, Faster R-CNN에서 6.9%였다. 결론적으로 자동차용 배터리 리드탭 암흔 오류 검출에 딥러닝 기술이 매우 유용함을 확인할 수 있었다.",다국어 초록 정보 없음
자전거 교통사고 다발지역 예측을 위한 딥러닝 모형의 적용,2022,"['자전거 교통사고(Bicycle collision)', '딥러닝(Deep learning)']",국문 초록 정보 없음,"A rising importance of bicycle as the paradigm shift in transportation has led to the need for an action to ensure the bicycle users’ safety by preventing bicycle collisions. This study aims to predict bicycle collision hot spots in Korea using collected Google Street View(GSV) images of bicycle collision hot spots and non-hot spots. We’ve conducted experiments with five deep learning models(VGG16, 19, ResNet50, 101, and Inception), and employed the CAM analysis to visualize the factors contributing to bicycle collisions. The VGG19 model is turned out to be the best model for predicting bicycle collision hot spots, and the CAM analysis shows that roads with larger scale, and with more vehicles and physical facilities(such as crosswalks, traffic lights, pillars) are related to bicycle collision hot spots. This study indicatess the effectiveness of using GSV images and deep learning model, and suggests more concrete and specific political implications for building safer environment for bicycle users."
A Manually Captured and Modified Phone Screen Image Dataset for Widget Classification on CNNs,2022,"['Captured Image', 'CNN', 'Deep Learning Dataset', 'Image Classification', 'Object Detection', 'Widget']",국문 초록 정보 없음,"The applications and user interfaces (UIs) of smart mobile devices are constantly diversifying. For example,deep learning can be an innovative solution to classify widgets in screen images for increasing convenience.To this end, the present research leverages captured images and the ReDraw dataset to write deep learningdatasets for image classification purposes. First, as the validation for datasets using ResNet50 and EfficientNet,the experiments show that the dataset composed in this study is helpful for classification according to a widget'sfunctionality. An implementation for widget detection and classification on RetinaNet and EfficientNet is thenexecuted. Finally, the research suggests the Widg-C and Widg-D datasets—a deep learning dataset for identifyingthe widgets of smart devices—and implementing them for use with representative convolutional neuralnetwork models."
심전도의 다양한 2차원 변환에 의한 합성곱 신경망기반 개인식별,2022,"['person identification', 'electrocardiogram', 'convolutional neural networks', 'time-frequency transform', 'Short-Time Fourier Transform', 'Fourier Synchrosqueezed Transform']",국문 초록 정보 없음,"In this paper, we propose personal identification method based on Convolutional Neural Networks (CNN) by various two-dimensional (2D) transform of Electrocardiogram (ECG) signals. For this purpose, various 2D time-frequency representation are peformed by Short-Time Fourier Transform (STFT), Fourier Synchrosqueezed Transform (FSST), and Wavelet Synchrosqueezed Transform (WSST) from one-dimensional ECG signals. The individual identification performance is achieved by transfer learning based on the pretrained GoogleNet and ResNet-101. The performance of experimental results are compared by the well-known PTB-ECG database."
Breast Masses Evaluation Using Deep Learning for Mammogram Imaging: A Pilot Study,2022,[],국문 초록 정보 없음,"Following the improvements in the field of deep learning, the applications of convolutional neural networks emerge promising to apply in medical image analysis. This study demonstrates the classification of breast masses related to benign or malignant cancers from the mammographic image dataset of the digital database for screening mammography (DDSM). 50-layer residual network (ResNet50) architecture, adaptive gradient algorithm (Adagrad) optimizer, a learning rate scheduler, and a fine-tuning strategy are employed when training the convolutional neural network model. Additionally, to balance the dataset, image augmentations are employed. According to the accuracy and loss of the test dataset, the results indicate that the classifier in this study is reliable to classify breast cancer in the category of benign or malignant from the breast masses. However, more studies are necessary to expand the comprehensive understanding relative to the developed model in this research."
반려동물용 자동 사료급식기의 비용효율적 사료 중량 예측을 위한 딥러닝 방법,2022,"['사료급식기', '컴퓨터 비전', '중량 예측', '딥러닝', '합성곱 신경망', 'pet feeder', 'computer vision', 'weight prediction', 'deep learning', 'convolutional neural network']","최근 IoT 기술의 발달로 외출 중에도 반려동물에 급여하도록 자동 사료급식기가 유통되고 있다. 그러나 자동급식에서 중요한 중량을 측정하는 저울 방식은 쉽게 고장이 나고, 3D카메라 방식은 비용이 든다는 단점이 있으며, 2D카메라 방식 은중량측정의정확도가떨어진다. 특히사료가복합된경우중량측정문제는더욱어려워질수있다. 따라서본연구의 목적은 2D카메라를 사용하면서도 중량을 정확하게 추정할 수 있는 딥러닝 접근법을 제안하는 것이다. 이를 위해 다양한 합성곱 신경망을 이용하였으며, 그중 ResNet101 기반 모델이 3.06 gram의 평균 절대 오차와 3.40%의 평균 절대비 오차를 기록하며 가장 우수한 성능을 보였다. 본 연구의 결과로 사료와 같이 규격화된 물체의 중량을 확보가 용이한 2D 이미지를 통해서만 예측할 필요가 있을 경우 유용한 정보로 활용될 수 있다.",다국어 초록 정보 없음
Human activity recognition based on wrist PPG via the ensemble method,2022,"['HAR', 'Exercise', 'PPG', 'ECG', 'Classification', 'Ensemble', 'Machine learning', 'Transfer learning']",국문 초록 정보 없음,"Human activity recognition via Electrocardiography (ECG) and Photoplethysmography (PPG) is extensively researched. While ECG requires less filtering and is less prone to disturbance and artifacts, nonetheless, PPG is cheaper and widely available in smart devices, making it a desired alternative. In this study, we explore the employment of the ensemble method with several pre-trained machine learning models namely Resnet50V2, MobileNetV2, and Xception for the classification of wrist PPG data of human activity, in comparison to its ECG counterpart. The study produced promising results with a test classification accuracy of 88.91% and 94.28% for PPG and ECG, respectively."
Enhanced 3D Residual Network for Human Fall Detection in Video Surveillance,2022,"['Video surveillance', 'fall detection', 'deep learning', 'residual network', '3D CNN']",국문 초록 정보 없음,"In the public healthcare, a computational system that can automatically and efficiently detect and classify falls from a video sequence has significant potential. With the advancement of deep learning, which can extract temporal and spatial information, has become more widespread. However, traditional 3D CNNs that usually adopt shallow networks cannot obtain higher recognition accuracy than deeper networks. Additionally, some experiences of neural network show that the problem of gradient explosions occurs with increasing the network layers. As a result, an enhanced three-dimensional ResNet-based method for fall detection (3D-ERes-FD) is proposed to directly extract spatio-temporal features to address these issues. In our method, a 50-layer 3D residual network is used to deepen the network for improving fall recognition accuracy. Furthermore, enhanced residual units with four convolutional layers are developed to efficiently reduce the number of parameters and increase the depth of the network. According to the experimental results, the proposed method outperformed several state-of-the-art methods."
표정 분류에 기반한 감정 인식을 위한 열화상 데이터베이스의 유용성 평가,2022,"['thermal face image', 'facial expression classification', 'emotion recognition', 'CNN architecture', 'database performance']",국문 초록 정보 없음,"Facial expression is an important part of human communication and is an element that helps to understand other people’s intentions. Recently, as a complementary solution in the field of emotion recognition, interest in thermal imaging is increasing as an alternative means to compensate for the shortcomings of visible light imaging. In this paper, thermal image data was acquired by itself and a database was established in which only facial areas necessary for emotional recognition were extracted separately. Verification accuracy and learning time were analyzed using the existing CNN architecture to confirm whether the built database can be used to classify facial expressions for emotion recognition. As a result of analysis through CNN network, ResNet-18 showed a verification accuracy of up to 81.28%, and on average, it showed a verification accuracy of 68.13%. Through this, it was confirmed that the self-built thermal imaging database is useful for emotional recognition research."
게이트심장혈액풀검사에서 딥러닝 기반 좌심실 영역 분할방법의 유용성 평가,2022,['대한방사선과학회(구 대한방사선기술학회)'],국문 초록 정보 없음,"The Cardiac Gated Blood Pool (GBP) scintigram, a nuclear medicine imaging, calculates the left ventricular Ejection Fraction (EF) by segmenting the left ventricle from the heart. However, in order to accurately segment the substructure of the heart, specialized knowledge of cardiac anatomy is required, and depending on the expert s processing, there may be a problem in which the left ventricular EF is calculated differently. In this study, using the DeepLabV3 architecture, GBP images were trained on 93 training data with a ResNet-50 backbone. Afterwards, the trained model was applied to 23 separate test sets of GBP to evaluate the reproducibility of the region of interest and left ventricular EF. Pixel accuracy, dice coefficient, and IoU for the region of interest were 99.32±0.20, 94.65±1.45, 89.89±2.62(%) at the diastolic phase, and 99.26±0.34, 90.16±4.19, and 82.33±6.69(%) at the systolic phase, respectively. Left ventricular EF was calculated to be an average of 60.37±7.32% in the ROI set by humans and 58.68±7.22% in the ROI set by the deep learning segmentation model. (p<0.05) The automated segmentation method using deep learning presented in this study similarly predicts the average human-set ROI and left ventricular EF when a random GBP image is an input. If the automatic segmentation method is developed and applied to the functional examination method that needs to set ROI in the field of cardiac scintigram in nuclear medicine in the future, it is expected to greatly contribute to improving the efficiency and accuracy of processing and analysis by nuclear medicine specialists."
관개용수로 CCTV 이미지를 이용한 CNN 딥러닝 이미지 모델 적용,2022,"['Image classification', 'image segmentation', 'CCTV images', 'irrigation canal']",국문 초록 정보 없음,"A more accurate understanding of the irrigation water supply is necessary for efficient agricultural water management. Although we measure water levelsin an irrigation canal using ultrasonic water level gauges, some errors occur due to malfunctions or the surrounding environment. This study aims toapply CNN (Convolutional Neural Network) Deep-learning-based image classification and segmentation models to the irrigation canal’s CCTV(Closed-Circuit Television) images. The CCTV images were acquired from the irrigation canal of the agricultural reservoir in Cheorwon-gun,Gangwon-do. We used the ResNet-50 model for the image classification model and the U-Net model for the image segmentation model. Using theNatural Breaks algorithm, we divided water level data into 2, 4, and 8 groups for image classification models. The classification models of 2, 4, and8 groups showed the accuracy of 1.000, 0.987, and 0.634, respectively. The image segmentation model showed a Dice score of 0.998 and predictedwater levels showed R2of 0.97 and MAE (Mean Absolute Error) of 0.02 m. The image classification models can be applied to the automaticgate-controller at four divisions of water levels. Also, the image segmentation model results can be applied to the alternative measurement for ultrasonicwater gauges. We expect that the results of this study can provide a more scientific and efficient approach for agricultural water management."
악성코드 이미지 분류를 위한 CNN 모델 성능 비교,2022,[],"최근 IT 산업의 지속적인 발전으로 사용자들을 위협하는 악성코드, 피싱, 랜섬웨어와 같은 사이버 공격 또한 계속해서 발전하고 더 지능화되고 있으며 변종 악성코드도 기하급수적으로 늘어나고 있다. 지금까지의 시그니처 패턴 기반의 탐지법으로는 이러한 방대한 양의 알려지지 않은 악성코드를 탐지할 수 없다. 따라서 CNN(Convolutional Neural Network)을 활용하여 악성코드를 탐지하는 기법들이 제안되고 있다. 이에 본 논문에서는 CNN 모델 중 낮은 인식 오류율을 지닌 모델을 선정하여 정확도(Accuracy)와 F1-score 평가 지표를 통해 비교하고자 한다. 두 가지의 악성코드 이미지화 방법을 사용하였으며, 2015 년 이후 ILSVRC 에서 우승을 차지한 모델들과, 추가로 2019 년에 발표된 EfficientNet 을 사용하여 악성코드 이미지를 분류하였다. 그 결과 2 바이트를 한 쌍의 좌표로 변환하여 생성한 256 * 256 크기의 악성코드 이미지를 ResNet-152 모델을 이용해 분류하는 것이 우수한 성능을 보임을 실험적으로 확인하였다.",다국어 초록 정보 없음
No-Reference Image Quality Assessment based on Quality Awareness Feature and Multi-task Training,2022,"['Deep Learning', 'No-Reference Image Quality Assessment', 'Multiple Task Learning', 'Score Prediction']",국문 초록 정보 없음,"The existing image quality assessment (IQA) datasets have a small number of samples. Some methods based on transfer learning or data augmentation cannot make good use of image quality-related features. A No Reference (NR)-IQA method based on multi-task training and quality awareness is proposed. First, single or multiple distortion types and levels are imposed on the original image, and different strategies are used to augment different types of distortion datasets. With the idea of weak supervision, we use the Full Reference (FR)-IQA methods to obtain the pseudo-score label of the generated image. Then, we combine the classification information of the distortion type, level, and the information of the image quality score. The ResNet50 network is trained in the pre-train stage on the augmented dataset to obtain more quality-aware pre-training weights. Finally, the fine-tuning stage training is performed on the target IQA dataset using the quality-aware weights to predicate the final prediction score. Various experiments designed on the synthetic distortions and authentic distortions datasets (LIVE, CSIQ, TID2013, LIVEC, KonIQ-10K) prove that the proposed method can utilize the image quality-related features better than the method using only single-task training. The extracted quality-aware features improve the accuracy of the model."
CNN 기반 전이학습을 이용한 뼈 전이가 존재하는 뼈 스캔 영상 분류,2022,"['Deep Learning', 'Computer Vision', 'CNN', 'Transfer Learning', 'Medical Image', 'Bone Scan']",국문 초록 정보 없음,"Whole body bone scan is the most frequently performed nuclear medicine imaging to evaluate bone metastasis in cancer patients. We evaluated the performance of a VGG16-based transfer learning classifier for bone scan images in which metastatic bone lesion was present. A total of 1,000 bone scans in 1,000 cancer patients (500 patients with bone metastasis, 500 patients without bone metastasis) were evaluated. Bone scans were labeled with abnormal/normal for bone metastasis using medical reports and image review. Subsequently, gradient-weighted class activation maps (Grad-CAMs) were generated for explainable AI. The proposed model showed AUROC 0.96 and F1-Score 0.90, indicating that it outperforms to VGG16, ResNet50, Xception, DenseNet121 and InceptionV3. Grad-CAM visualized that the proposed model focuses on hot uptakes, which are indicating active bone lesions, for classification of whole body bone scan images with bone metastases."
합성곱 신경망을 이용한 정사사진 기반 균열 탐지 기법,2022,"['Ortho-image', 'UAV', 'Machine learning', 'Crack detection', 'CNN']",국문 초록 정보 없음,"Visual inspection methods have limitations, such as reflecting the subjective opinions of workers. Moreover, additional equipment is required when inspecting the high-rise buildings because the height is limited during the inspection. Various methods have been studied to detect concrete cracks due to the disadvantage of existing visual inspection. In this study, a crack detection technology was proposed, and the technology was objectively and accurately through AI. In this study, an efficient method was proposed that automatically detects concrete cracks by using a Convolutional Neural Network(CNN) with the Orthomosaic image, modeled with the help of UAV. The concrete cracks were predicted by three different CNN models: AlexNet, ResNet50, and ResNeXt. The models were verified by accuracy, recall, and F1 Score. The ResNeXt model had the high performance among the three models. Also, this study confirmed the reliability of the model designed by applying it to the experiment."
의류 수요 정보 예측을 위한 멀티모달 기반 딥 뉴럴 네트워크,2022,[],국문 초록 정보 없음,"This paper proposes a deep neural network to estimate the quantitative demand information of clothes displayed in an online shopping mall, using images and other miscellaneous information.  In this paper, we construct a clothing demand evaluation database with clothing images collected from an online shopping mall, along with product names, prices, genders, preferred genders, preferred age groups, product numbers, cumulative sales, and product categories. Various modalities are combined in the proposed deep neural network to predict the demand information. To process the images and the text information (product names), we employ ResNet18 and the Multilingual BERT, respectively, in the proposed network.  The experimental results show that the proposed multi-modal network shows reliable performance in predicting the demand of clothing."
Convolutional neural network-based data anomaly detection considering class imbalance with limited data,2022,"['class imbalance', 'data anomaly detection', 'focal loss', 'limited labelled data', 'transfer learning']",국문 초록 정보 없음,"The raw data collected by structural health monitoring (SHM) systems may suffer multiple patterns of anomalies, which pose a significant barrier for an automatic and accurate structural condition assessment. Therefore, the detection and classification of these anomalies is an essential pre-processing step for SHM systems. However, the heterogeneous data patterns scarce anomalous samples and severe class imbalance make data anomaly detection difficult. In this regard, this study proposes a convolutional neural network-based data anomaly detection method. The time and frequency domains data are transferred as images and used as the input of the neural network for training. ResNet18 is adopted as the feature extractor to avoid training with massive labelled data. In addition, the focal loss function is adopted to soften the class imbalance-induced classification bias. The effectiveness of the proposed method is validated using acceleration data collected in a long-span cable-stayed bridge. The proposed approach detects and classifies data anomalies with high accuracy."
필터 다양화를 통한 합성곱 신경망의 표현력 향상,2022,"['Deep learning', 'CNN', 'Feature Representation', 'Filter Diversity', 'Singular Value Decomposition (SVD) Entropy', 'Filter Spreading']",국문 초록 정보 없음,"This paper aims to improve the feature representation by diversifying CNN filters inspired by niche concept in evolution. The singular value decomposition (SVD) entropy based efficient metric for diversity is proposed In the proposed approach, filters are clustered by groups and they are calculated as differences from the center values within the groups, rather than by entire rank based comparison. This provides an effective method for increasing the substantial diversity of filters. Furthermore, the filters with low diversity are adjusted by the diversity spreading framework for better diversity in the reconstruction process. The improvement of the filter representation by performing experiments on CIFAR 10/100 data for VGG16, and ImageNet for ResNet34 is provided. Because there are no similar studies, we compare our results with respect to those of relatively relevant pruning methods in terms of classification performance accuracy as well as the pruned rates and flops."
금속 음영이 포함된 CBCT 영상에서 딥러닝을 이용한 해부학적 구조물의 다중 클래스 분할 방법,2022,"['Deep learning', 'Anatomical structure segmentation', 'Metal artifacts', 'U-Net', 'Tversky loss']",국문 초록 정보 없음,"In order to perform preoperative surgical planning, accurate segmentation of anatomical structures in cone-beam computed tomography (CBCT) images is required. However, this image segmentation is often impeded by metal artifacts, and it takes a lot of time due to morphological variability in patients. In this paper, we proposed a deep learning based automatic multi-class segmentation method for anatomical structures in CBCT images containing metal artifacts. Four U-Net based deep learning models were used for anatomical structure segmentation. Each deep learning model was constructed by changing the encoder of U-Net architecture to the backbones (DenseNet121, VGGNet16, ResNet101, and EfficienNetB4). For training and testing our method, we used 20744 CBCT images containing metal artifacts from 30 patient datasets. Experimental results show that the segmentation performances of the mandible, midfacial bone, mandibular canal, and maxillary sinus were achieved F1 scores of 0.912±0.070, 0.880±0.080, 0.687±0.265, and 0.954±0.063 using DenseNet121 with Tversky loss, respectively. Furthermore, our method was able to perform robust and accurate segmentation of anatomical structures in CBCT images containing metal artifacts."
다수 조명의 채널별 융합을 이용한 CNN 기반 머신 비전 분류기,2022,"['Semiconductor', 'Auto Visual Inspection', 'Deep Learning', 'CNN', '.']",국문 초록 정보 없음,.
컴퓨터 비전과 딥러닝을 이용한 목재 결함의 검출 및 정량화,2022,[],"목재 표면 검사를 위해 컴퓨터 비전과 딥러닝을 이용한 자동화 결함 검출 모델을 수립하였다. 컨베이어, 라인 스캔 카메라, 적외선 센서 트리거로 구성된 연속 이미지 획득 시스템을 우선 구축하여 목재 이미지 데이터를 획득하였다. 이미지 획득 시스템은 크기에 상관없이 연속 투입되는 모든 판재의 표면을 스캔할 수 있다. 총 304장의 잣나무 표면 이미지로 데이터베이스가 구축되었다. 『KS F 2151 침엽수 구조 용재의 육안 등급 구분 방법』에 따라 목재 결함을 옹이, 갈라짐, 수피로 구분하였으며, 옹이는 산옹이, 죽은 옹이, 썩은 옹이, 긴 옹이 등 4종류로 세분화하였다. VGG annotator를 이용하여 모든 이미지 데이터에 결함의 위치, 형상, 종류에 관한 정보를 목록화하였다. 검출 모델은 ResNet-101을 backbone 네트워크로 하는 Mask R-CNN을 기반으로 설계되었으며, 모델은 IOU(intersection over union) 50% 이상에 대한 mAP(mean average precision)로 평가되었다. 또한 KS F 2151에서 규정한 방식으로 각 결함의 기준 치수가 산출되도록 모델을 설계하였다. 테스트 세트에 대한 모델의 mAP는 57.0%로 산출되었는데, 이는 4종의 옹이만 학습한 모델의 mAP 80.4%보다 낮다. 성능 감소의 원인은 갈라짐에 대한 모델의 검출 성능이 낮았던 것에 기인한다. 갈라짐에 대한 검출 오류는 주석을 달지 않은 미세한 갈라짐을 모델이 검출한 경우, 그리고 길게 분포된 하나의 갈라짐을 모델이 다중의 갈라짐으로 검출한 경우의 두 가지 유형으로 분석되었다. 이러한 오류는 주석 수정 및 데이터 세트 증량을 통해 개선할 수 있을 것으로 판단된다. 개발된 모델은 옹이만을 다루던 기존 자동화 탐지 기법과는 달리 다양한 결함들을 검출할 뿐만 아니라 결함의 정량화 기능을 갖추어 목재 표면 검사에 실질적 도움이 될 것으로 기대된다.",다국어 초록 정보 없음
A Deep Learning-Based Compact Weighted Binary Classification Technique to Discriminate between Targets and Clutter in SAR Images,2022,"['Automatic Target Detection (ATD)', 'Deep Learning (DL)', 'Machine Learning (ML)', 'Synthetic Aperture Radar (SAR).']",국문 초록 정보 없음,"The proposed approach is a deep learning-based compact weighted binary classification (DL-CWBC) method to discriminate between targets and clutter in synthetic aperture radar (SAR) images. A new modified cross-entropy error function is proposed to improve the probability of detection by controlling the rate of false alarms (FAs). The unique feature of a CWBC algorithm is reducing the FA rate and maximizing the probability of target detection without missing any target. For pre-processing, targets and clutter are detected through a constant false alarm rate (CFAR) as a conventional detection algorithm. These are then manually divided into two classes. The classified targets and clutter were trained through a ResNet-101 network. There is a trade-off between the minimization of the FA rate and the maximization of the detection probability for targets of interest (TOIs). The weighted coefficient of the modified cross-entropy error function tries to maximize the performance of this trade-off. In addition, the proposed approach enables us not to miss any targets by an extreme distinction decision. Above all, the DL-CWBC algorithm performs very well despite its simplicity."
1-D PE 어레이로 컨볼루션 연산을 수행하는 저전력 DCNN 가속기,2022,"['FPGA', 'Deep Convolutional Neural Network', 'Accelerator', 'Processing Element', 'Data Reuse']",국문 초록 정보 없음,"In this paper, we propose a novel method of performing convolutional operations on a 2-D Processing Element(PE) array. The conventional method [1] of mapping the convolutional operation using the 2-D PE array lacks flexibility and provides low utilization of PEs. However, by mapping a convolutional operation from a 2-D PE array to a 1-D PE array, the proposed method can increase the number and utilization of active PEs. Consequently, the throughput of the proposed Deep Convolutional Neural Network(DCNN) accelerator can be increased significantly.  Furthermore, the power consumption for the transmission of weights between PEs can be saved. Based on the simulation results, the performance of the proposed method provides approximately 4.55%, 13.7%, and 2.27% throughput gains for each of the convolutional layers of AlexNet, VGG16, and ResNet50 using the DCNN accelerator with a (weights size) x (output data size) 2-D PE array compared to the conventional method. Additionally the proposed method provides approximately 63.21%, 52.46%, and 39.23% power savings."
Representative Batch Normalization for Scene Text Recognition,2022,"['Scene text recognition', 'deep learning', 'Representative Batch Normalization', 'Feature representation', 'Feature enhancement']",국문 초록 정보 없음,"Scene text recognition has important application value and attracted the interest of plenty of researchers. At present, many methods have achieved good results, but most of the existing approaches attempt to improve the performance of scene text recognition from the image level. They have a good effect on reading regular scene texts. However, there are still many obstacles to recognizing text on low-quality images such as curved, occlusion, and blur. This exacerbates the difficulty of feature extraction because the image quality is uneven. In addition, the results of model testing are highly dependent on training data, so there is still room for improvement in scene text recognition methods. In this work, we present a natural scene text recognizer to improve the recognition performance from the feature level, which contains feature representation and feature enhancement. In terms of feature representation, we propose an efficient feature extractor combined with Representative Batch Normalization and ResNet. It reduces the dependence of the model on training data and improves the feature representation ability of different instances. In terms of feature enhancement, we use a feature enhancement network to expand the receptive field of feature maps, so that feature maps contain rich feature information. Enhanced feature representation capability helps to improve the recognition performance of the model. We conducted experiments on 7 benchmarks, which shows that this method is highly competitive in recognizing both regular and irregular texts. The method achieved top1 recognition accuracy on four benchmarks of IC03, IC13, IC15, and SVTP ."
샴 네트워크 기반의 적은 데이터셋을 이용한 유사한 형태의 특정 객체 인식 연구,2022,"['Object Recognition', 'Deep Learning', 'Few-shot Learning', 'Siamese Network', 'Convolutional Neural Network', '.']",국문 초록 정보 없음,.
Cycle-accurate NPU 시뮬레이터 및 데이터 접근 방식에 따른 NPU 성능평가,2022,"['Neural Processing Unit', 'Convolutional Neural Network', 'Data Reuse', 'FIFO', 'Interleaved Memory']",국문 초록 정보 없음,"Currently, there are increasing demands for applying deep neural networks (DNNs) in the embedded domain such as classification and object detection. The DNN processing in embedded domain often requires custom hardware such as NPU for acceleration due to the constraints in power, performance, and area. Processing DNN models requires a large amount of data, and its seamless transfer to NPU is crucial for performance. In this paper, we developed a cycle-accurate NPU simulator to evaluate diverse NPU microarchitectures. In addition, we propose a novel technique for reducing the number of memory accesses when processing convolutional layers in convolutional neural networks (CNNs) on the NPU. The main idea is to reuse data with memory interleaving, which recycles the overlapping data between previous and current input windows. Data memory interleaving makes it possible to quickly read consecutive data in unaligned locations. We implemented the proposed technique to the cycle-accurate NPU simulator and measured the performance with LeNet-5, VGGNet-16, and ResNet-50. The experiment shows up to 2.08x speedup in processing one convolutional layer, compared to the baseline."
Analysis of Weights and Feature Patterns in Popular 2D Deep Neural Networks Models for MRI Image Classification,2022,"['Deep Neural Network', 'Activation Channels', 'MRI', 'Fully Connected Layer', 'Weights Correlation.']",국문 초록 정보 없음,"A deep neural network (DNN) includes variables whose values keep on changing with the training process until it reaches the final point of convergence. These variables are the co-efficient of a polynomial expression to relate to the feature extraction process. In general, DNNs work in multiple ‘dimensions’ depending upon the number of channels and batches accounted for training. However, after the execution of feature extraction and before entering the SoftMax or other classifier, there is a conversion of features from multiple N-dimensions to a single vector form, where ‘N’ represents the number of activation channels. This usually happens in a Fully connected layer (FCL) or a dense layer. This reduced 2D feature is the subject of study for our analysis. For this, we have used the FCL, so the trained weights of this FCL will be used for the weight-class correlation analysis. The popular DNN models selected for our study are ResNet-101, VGG-19, and GoogleNet. These models’ weights are directly used for fine-tuning (with all trained weights initially transferred) and scratch trained (with no weights transferred). Then the comparison is done by plotting the graph of feature distribution and the final FCL weights."
CNN을 이용한 Al 6061 압출재의 표면 결함 분류 연구,2022,"['Convolution Neural Network', 'Surface Defect', 'Aluminum alloy', 'Extrusion', 'Deep Learning', 'Data Augmentation']",국문 초록 정보 없음,"Convolution Neural Network(CNN) is a class of deep learning algorithms and can be used for image analysis. In particular, it has excellent performance in finding the pattern of images. Therefore, CNN is commonly applied for recognizing, learning and classifying images. In this study, the surface defect classification performance of Al 6061 extruded material using CNN-based algorithms were compared and evaluated. First, the data collection criteria were suggested and a total of 2,024 datasets were prepared. And they were randomly classified into 1,417 learning data and 607 evaluation data. After that, the size and quality of the training data set were improved using data augmentation techniques to increase the performance of deep learning. The CNN-based algorithms used in this study were VGGNet-16, VGGNet-19, ResNet-50 and DenseNet-121. The evaluation of the defect classification performance was made by comparing the accuracy, loss, and learning speed using verification data. The DenseNet-121 algorithm showed better performance than other algorithms with an accuracy of 99.13% and a loss value of 0.037. This was due to the structural characteristics of the DenseNet model, and the information loss was reduced by acquiring information from all previous layers for image identification in this algorithm. Based on the above results, the possibility of machine vision application of CNN-based model for the surface defect classification of Al extruded materials was also discussed."
ISAR 영상 기반 해상표적 식별을 위한 인공지능 연구,2022,"['Artificial Intelligence', 'Inverse Synthetic Aperture Radar', 'Radar Image', 'Maritime Target']",국문 초록 정보 없음,"Artificial intelligence is driving the Fourth Industrial Revolution and is in the spotlight as a general-purpose technology. As the data collection from the battlefield increases rapidly, the need to us artificial intelligence is increasing in the military, but it is still in its early stages. In order to identify maritime targets, Republic of Korea navy acquires images by ISAR(Inverse Synthetic Aperture Radar) of maritime patrol aircraft, and humans make out them. The radar image is displayed by synthesizing signals reflected from the target after radiating radar waves. In addition, day/night and all-weather observations are possible. In this study, an artificial intelligence is used to identify maritime targets based on radar images. Data of radar images of 24 maritime targets in Republic of Korea and North Korea acquired by ISAR were pre-processed, and an artificial intelligence algo- rithm(ResNet-50) was applied. The accuracy of maritime targets identification showed about 99%. Out of the 81 warship types, 75 types took less than 5 seconds, and 6 types took 15 to 163 seconds."
Safety monitoring system of personal mobility driving using deep learning,2022,"['deep learning', 'personal mobility', 'short-time Fourier transform', 'wavelet transform', 'convolutional neural networks']",국문 초록 정보 없음,"Although the e-scooter sharing service market is growing as a representative last-mile mobility, the accident rate is increasing proportionally as the number of users increases. This study proposes a deep learning-based personal mobility driver monitoring system that detects inattentive driving by classifying vibration data transmitted to the e-scooter when the driver fails to concentrate on driving. First, the N-back task technique is used. The driver was stimulated by external visual and auditory factors to generate a cognitive load, and vibration data were collected through a six-axis sensor. Second, the generated vibration data were pre-processed using short-time Fourier transform and wavelet transform (WT) and then converted into an image (spectrogram). Third, four multimodal convolutional neural networks such as LeNet-5, VGG16, ResNet50, and DenseNet121 were constructed and their performance was compared to find the best architecture. Experimental results show that multimodal DenseNet121 with WT can accurately classify safe, slightly anxious, and very anxious driving conditions. The proposed model can be applied to real-time monitoring and warning systems for sharing service providers and used as a basis for insurance and legal action in the case of accidents."
환경변화에 강인한 딥러닝 기반의 터널 균열 측정 및 진단,2022,"['Tunnel crack', 'deep learning', 'CCTV', 'crack', 'XAI']",국문 초록 정보 없음,"A tunnel is an essential public facility that enables uninterrupted transportation in crowded cities. Over time, various factors such as ageing and harsh environment could slowly damage the tunnel, leading to cracks and even human loss. There, the tunnel needs to be investigated regularly. Previous maintenance methods have primarily counted on the operators who directly monitor recorded videos to inspect the cracks and determine their seriousness. However, this is a time-consuming and error-prone process. Firstly, this paper introduces a huge tunnel cracks segmentation dataset that contains a total of 170,339 images. Next, a tunnel crack segmentation system that can automatically identify different types of cracks is suggested based on the collected data. The model uses the U-Net structure as the baseline model, with the encoder replaced by a pre-trained Resnet-152 model to improve the effectiveness of the feature extract process. Finally, additional measurements of the detected cracks, such as crack length and crack thickness, are computed."
Fundus Photograph Discrimination Using Transfer Learning over Limited Computing Power Environment,2022,"['AI', 'CNN', 'Fundus photograph', 'ImageNet', 'OPhthalmoloscopy', 'Transfer learning']",국문 초록 정보 없음,"In this paper, we demonstrates a reliable and efficient approach to detect eye-related disease with automated fundus screening using convolutional neural network (CNN) and transfer learning that counteracts to insufficient annotated data set and image domain shifts. The weight values learned from the data sets can be used as initial parameters for the other desired neural networks, and additional learning can be conducted on top of the pre-learned model, called transfer learning. It is a particularly useful method when the number of data sets is and small over limited computing power environment. Four different fundus image data sets, image domains such as ethnicity of the target and equipment which the fundus photograph was captured with, were used for the validation. The data sets were annotated by ophthalmologists as healthy, abnormal, or diabetic retinopathy. The ResNet-18 model, pre-trained with ImageNet data set of 1.2 million images of 1000 daily routine objects, were used for transfer learning. The pre-trained model were modified and additionally trained to learn features from the fundus images, and were validated with separate test sets. Given limited quantity of fundus photograph data set and various image domains, the deep learning models can yield robust ophthalmological performance in discriminating pathologies in the eyes. In spite of the simplicity, this study illustrates the capability of transfer learning and suggests pragmatic and practical approach to varied medical settings with fluctuating status of data maintenance and different image domains."
Retinal Disease Identification using Upgraded CLAHE filter and Transfer Convolution Neural Network,2022,"['Retinal disease', 'Retinal fundus images', 'Convolution neural network (CNN)', '(CLAHE) filter']",국문 초록 정보 없음,"Retinal tissue plays a crucial part in human vision. Infections of retinal tissue and delayed treatment or untreated infection could lead to loss of vision. Additionally, the diagnosis is prone to errors when huge dataset is involved. Therefore, a fully automated model of identification of retinal disease is proposed to reduce human interaction while retaining its high accuracy classification results. This paper introduces an enhanced design of a fully automatic multi-class retina diseases prediction system to assist ophthalmologists in making speedy and accurate investigation. Retinal fundus images, which have been used in this study, were downloaded from the stare website (157 images from five classes: BDR, CRVO, CNV, PDR, and Normal). The five files were categorized according to their annotations conducted by the experienced specialists. The categorized images were first processed with the proposed upgraded contrast-limited adaptive histogram filter for image brightness enhancement, noise reduction, and intensity spectrum normalization. The proposed model was designed with transfer learning method and the fine-tuned pre-trained RESNET50. Eventually, the proposed framework was examined with performance evaluation parameters, recorded a classification rate with 100% sensitivity, 100% specificity, and 100% accuracy. The performance of the proposed model showed a magnificent superiority as compared to the state-of-the-art studies."
Analyzing Angle detection in aerial image,2022,"['Remote sensing image', 'Convolution neural network', 'Angle Detection on aerial image']",국문 초록 정보 없음,"We explore a method to extract the rotated angle of an object from the aerial image extracted from DOTA Dataset. The recently proposed methods of Object Detection are in forms of fine regression after find most appropriate box from set anchor boxes of various angles. These models showed excellent detection performances about rotated object in aerial image. However, Those are a lot of added calculations for rotated anchor boxes. In order to approach this problem in a different way than the rotated anchor box. We analyse a different type of model that directly estimate the angle of an object like Image Tilt correction. Directly applying this method also have a own problem, which occurs in angle detection in aerial image. we modify the method that using logical operation for angle loss to separate Direction from angle and improve the model performance in Angular Error Accuracy by section. All experiment in this paper using resnet50 based model and ablation studies on model depth were conducted."
Remote Sensing Image Classification for Land Cover Mapping in Developing Countries: A Novel Deep Learning Approach,2022,"['Convolutional neural network', 'remote sensing image classification', 'Land cover mapping', 'medium-resolution']",국문 초록 정보 없음,"Convolutional Neural networks (CNNs) are a category of deep learning networks that have proven very effective in computer vision tasks such as image classification. Notwithstanding, not much has been seen in its use for remote sensing image classification in developing countries. This is majorly due to the scarcity of training data. Recently, transfer learning technique has successfully been used to develop state-of-the art models for remote sensing (RS) image classification tasks using training and testing data from well-known RS data repositories. However, the ability of such model to classify RS test data from a different dataset has not been sufficiently investigated. In this paper, we propose a deep CNN model that can classify RS test data from a dataset different from the training dataset. To achieve our objective, we first, re-trained a ResNet-50 model using EuroSAT, a large-scale RS dataset to develop a base model then we integrated Augmentation and Ensemble learning to improve its generalization ability. We further experimented on the ability of this model to classify a novel dataset (Nig_Images). The final classification results shows that our model achieves a 96% and 80% accuracy on EuroSAT and Nig_Images test data respectively. Adequate knowledge and usage of this framework is expected to encourage research and the usage of deep CNNs for land cover mapping in cases of lack of training data as obtainable in developing countries."
Beta and Alpha Regularizers of Mish Activation Functions for Machine Learning Applications in Deep Neural Networks,2022,"['Neural Network', 'Machine Learning Applications', 'α and β Regularizers', 'Activation Function.']",국문 초록 정보 없음,"A very complex task in deep learning such as image classification must be solved with the help of neural networks and activation functions. The backpropagation algorithm advances backward from the output layer towards the input layer, the gradients often get smaller and smaller and approach zero which eventually leaves the weights of the initial or lower layers nearly unchanged, as a result, the gradient descent never converges to the optimum. We propose a two-factor non-saturating activation functions known as Bea-Mish for machine learning applications in deep neural networks. Our method uses two factors, beta (β) and alpha (α), to normalize the area below the boundary in the Mish activation function and we regard these elements as Bea. Bea-Mish provide a clear understanding of the behaviors and conditions governing this regularization term can lead to a more principled approach for constructing better performing activation functions. We evaluate Bea-Mish results against Mish and Swish activation functions in various models and data sets. Empirical results show that our approach (Bea-Mish) outperforms native Mish using SqueezeNet backbone with an average precision (AP50val) of 2.51% in CIFAR-10 and top-1accuracy in ResNet-50 on ImageNet-1k. shows an improvement of 1.20%."
Use of deep learning in nano image processing through the CNN model,2022,"['convolutional neural network', 'CT image', 'deep learning', 'image processing', 'lung cancer']",국문 초록 정보 없음,"Deep learning is another field of artificial intelligence (AI) utilized for computer aided diagnosis (CAD) and image processing in scientific research. Considering numerous mechanical repetitive tasks, reading image slices need time and improper with geographical limits, so the counting of image information is hard due to its strong subjectivity that raise the error ratio in misdiagnosis. Regarding the highest mortality rate of Lung cancer, there is a need for biopsy for determining its class for additional treatment. Deep learning has recently given strong tools in diagnose of lung cancer and making therapeutic regimen. However, identifying the pathological lung cancer's class by CT images in beginning phase because of the absence of powerful AI models and public training data set is difficult. Convolutional Neural Network (CNN) was proposed with its essential function in recognizing the pathological CT images. 472 patients subjected to staging FDG-PET/CT were selected in 2 months prior to surgery or biopsy. CNN was developed and showed the accuracy of 87%, 69%, and 69% in training, validation, and test sets, respectively, for T1-T2 and T3-T4 lung cancer classification. Subsequently, CNN (or deep learning) could improve the CT images' data set, indicating that the application of classifiers is adequate to accomplish better exactness in distinguishing pathological CT images that performs better than few deep learning models, such as ResNet-34, Alex Net, and Dense Net with or without Soft max weights."
Multiple butterfly recognition based on deep residual learning and image analysis,2022,"['butterfly  identification', 'deep  residual  learning', 'image  recognition', 'multiple  species recognition']",국문 초록 정보 없음,"Insect recognition is crucial for taxonomy. It helps researchers to process tremendous and various ecology data. Most studies focus on fine-tuning the deep learning network or altering the algorithm to enhance the identification accuracy, and some useful tools have been generated with these methods. This study focuses on the influence of image data on the recognition model. The single data set source of the existing automated identification tools is relatively simple, and the competition-based data set released only focuses on evaluating the model at present.For the first time, this article integrates butterfly image data sets from multiple sources, covered illustrated books, and popular butterfly science websites. The image types include standard specimen images, illustrated book scan images and camera shots. In addition, these images included not only fixed poses, but also various other images of butterflies in natural poses. The size of these images is also various. The testing data set is new data that does not belong to the training set, which also verifies the generalizability of the model, indicating that in practical applications this model can identify new images. This testing method is a breakthrough compared to the previous work. We designed different data sets using the ResNet18 network to train a classifier, which achieves a validation accuracy of 86% in the end of the analysis.By adjusting the data sets, the accuracy changes as well. This study provides a method to recognize hundreds of butterfly species and analyzes the testing progress from the point of view of data. It is the first to combine butterflies from multiple countries in a single data set, with a recognition accuracy that outperforms previous experiments, to the best of our knowledge. We further analyze the testing results of butterfly recognition at the family and genus level. We perform two more experiments to demonstrate the model in the case of similar species or genus."
디지털트윈 구축을 위한 3차원 공간정보 폐색영역 검출 및 복원 기술개발,2022,"['Digital Twin', '3D Modeling', 'Occlusion Area', 'Detection', 'In-paining']","디지털트윈의 중요한 요소는 실제 객체에 대한 폐색영역이 없는 실감형 공간정보를 구축하고 제공하여야 한다. 하지만 3차원 공간정보 모델링에서는 촬영 각도와 촬영 시기로 인해 필연적으로 폐색영역이 발생한다. 이에 최신 기술인 인공지능 기술을 이용한 특정객체의 검출과 이를 제거하고 복원할 수 있는 기술을 구현하고자 한다. 연구에서는 인공지능 모델 중에서 ResNet 알고리즘을 사용하 폐색 유발 객체를 자동으로 검출하고, 텍스처링 영상에서 검출된 폐색영역을 삭제하여 특정 알고리즘을 적용하여 해당 건물의 텍스처링 영상에서 폐색영역을 복원하는 복원 기술을 개발하였다. 실험데이터는 건물 모델링에서 가장 많은 폐색을 유발하는 가로수를 대상으로 최신모델인 ResNet 학습모델을 사용하여 폐색영역을 유발하는 가로수 객체 데이터셋을 만들고 자동으로 검출하였으며 그 결과를 분석하였다. 연구의 결과로는 ResNet 알고리즘을 이용하여 비정형 데이터인 가로수를 검출할 수 있으며, DeepFillv2 알고리즘을 이용하여 가로수를 제거하고 인접 픽셀을 이용하여 상가와 아파트 텍스처링 영상을 복원하였다.","An important element of a digital twin is to model and provide realistic spatial information without an occluded area for real objects. In 3D spatial information modeling, however, an occluded area inevitably occurs due to the shooting angle and shooting time. In this regard, this study implemented a technology that can detect a specific object using the latest technology, AI, and remove and in-paint it. In this study, the occlusion-causing object was automatically detected using the ResNet algorithm and the occlusion area in-painting in the texturing image. For the experimental data, the ResNet algorithm was applied to street trees that cause the most occlusion in building modeling to produce a street tree dataset and automatically detected and analyzed the results. Street trees, which are unstructured data, can be detected using the ResNet algorithm and removed using the DeepFillv2 algorithm, producing texturing images of shops and apartments that are restored using the adjacent pixels."
개선된 Deep Residual Learning 및 물리 모델 데이터를 이용한 잡음 조건에서의 자동차 샤시 결함 진단,2022,"['Deep Learning(딥러닝)', 'Vehicle Chassis System(차량 샤시 시스템)', 'Physics Model(물리 모델)', 'ResNet(심층 잔차 신경망)', 'DenseNet(밀집 연결 합성곱 네크워크)', 'FFT(빠른 푸리에 변환)', 'Domain Adaption(도메인 적응)', 'SNR(신호 대 잡음비)']",국문 초록 정보 없음,"For autonomous vehicles, technology that monitors the state of the vehicle and detects a failure using sensor data is receiving increasing attention. The purpose of this study is to determine the type and location of faults of a vehicle chassis system under noisy conditions using acceleration data and deep learning. Because there is a limit in the acquisition of specific defect data from a real vehicle, normal and defect data were obtained using a vehicle physics model that considers various vehicle speeds, vehicle-to-vehicle variations and road changes. We proposed DNI-ResNet (DenseNet Inspired ResNet), which applied the advantages of DenseNet to ResNet, and used it to determine the type and location of defects occurring in the rubber of the vehicle chassis system. Additionally, the domain adaptation ability of the proposed method was verified with various vehicle speed and new types of defects."
Deep learning-guided attenuation correction in the image domain for myocardial perfusion SPECT imaging,2022,"['SPECT', 'myocardial perfusion imaging', 'quantification', 'attenuation correction', 'deep learning']",국문 초록 정보 없음,"We investigate the accuracy of direct attenuation correction (AC) in the image domain for myocardial perfusion SPECT (single-photon emission computed tomography) imaging (MPI-SPECT) using residual (ResNet) and UNet deep convolutional neural networks. MPI-SPECT 99mTc-sestamibi images of 99 patients were retrospectively included. UNet and ResNet networks were trained using non-attenuation-corrected SPECT images as input, whereas CT-based attenuation-corrected (CT-AC) SPECT images served as reference. Chang’s calculated AC approach considering a uniform attenuation coefficient within the body contour was also implemented. Clinical and quantitative evaluations of the proposed methods were performed considering SPECT CT-AC images of 19 subjects (external validation set) as reference. Image-derived metrics, including the voxel-wise mean error (ME), mean absolute error, relative error, structural similarity index (SSI), and peak signal-to-noise ratio, as well as clinical relevant indices, such as total perfusion deficit (TPD), were utilized. Overall, AC SPECT images generated using the deep learning networks exhibited good agreement with SPECT CT-AC images, substantially outperforming Chang’s method. The ResNet and UNet models resulted in an ME of −6.99 ± 16.72 and −4.41 ± 11.8 and an SSI of 0.99 ± 0.04 and 0.98 ± 0.05, respectively. Chang’s approach led to ME and SSI of 25.52 ± 33.98 and 0.93 ± 0.09, respectively. Similarly, the clinical evaluation revealed a mean TPD of 12.78 ± 9.22% and 12.57 ± 8.93% for ResNet and UNet models, respectively, compared to 12.84 ± 8.63% obtained from SPECT CT-AC images. Conversely, Chang’s approach led to a mean TPD of 16.68 ± 11.24%. The deep learning AC methods have the potential to achieve reliable AC in MPI-SPECT imaging."
Detection of fake news using deep learning CNN–RNN based methods,2022,"['Fake news detection', 'Deep learning', 'CNN', 'Bidirectional LSTM', 'ResNet']",국문 초록 정보 없음,"Fake news is inaccurate information that is intentionally disseminated for a specific purpose. If allowed to spread, fake news can harm the political and social spheres, so several studies are conducted to detect fake news. This study uses a deep learning method with several architectures such as CNN, Bidirectional LSTM, and ResNet, combined with pre-trained word embedding, trained using four different datasets. Each data goes through a data augmentation process using the back-translation method to reduce data imbalances between classes. The results showed that the Bidirectional LSTM architecture outperformed CNN and ResNet on all tested datasets."
Preliminary study of artificial intelligence-based fuel-rod pattern analysis of low-quality tomographic image of fuel assembly,2022,"['Single-photon emission computed', 'tomography', 'Monte Carlo', 'Nuclear fuel assembly', 'Artificial intelligence', 'VGG', 'GoogLeNet', 'ResNet']",국문 초록 정보 없음,"Single-photon emission computed tomography is one of the reliable pin-by-pin verification techniques for spent-fuel assemblies. One of the challenges with this technique is to increase the total fuel assembly verification speed while maintaining high verification accuracy. The aim of the present study, therefore, was to develop an artificial intelligence (AI) algorithm-based tomographic image analysis technique for partial-defect verification of fuel assemblies. With the Monte Carlo (MC) simulation technique, a tomographic image dataset consisting of 511 fuel-rod patterns of a 3  3 fuel assembly was generated, and with these images, the VGG16, GoogLeNet, and ResNet models were trained. According to an evaluation of these models for different training dataset sizes, the ResNet model showed 100% pattern estimation accuracy. And, based on the different tomographic image qualities, all of the models showed almost 100% pattern estimation accuracy, even for low-quality images with unrecognizable fuel patterns.This study verified that an AI model can be effectively employed for accurate and fast partial-defect verification of fuel assemblies"
영상 인식을 위한 딥러닝 모델의 적대적 공격에 대한 백색 잡음 효과에 관한 연구,2022,"['Deep learning', 'Adversarial attack', 'FGSM attack', 'BIM attack', 'CW attack', 'White noise', 'Perturbation']","본 논문에서는 영상 데이터에 대한 적대적 공격으로부터 생성된 적대적 예제로 인하여 발생할 수 있는 딥러닝 시스템의 오분류를 방어하기 위한 방법으로 분류기의 입력 영상에 백색 잡음을 가산하는 방법을 제안하였다. 제안된 방법은 적대적이든 적대적이지 않던 구분하지 않고 분류기의 입력 영상에 백색 잡음을 더하여 적대적 예제가 분류기에서 올바른 출력을 발생할 수 있도록 유도하는 것이다. 제안한 방법은 FGSM 공격, BIM 공격 및 CW 공격으로 생성된 적대적 예제에 대하여 서로 다른 레이어 수를 갖는 Resnet 모델에 적용하고 결과를 고찰하였다. 백색 잡음의 가산된 데이터의 경우 모든 Resnet 모델에서 인식률이 향상되었음을 관찰할 수 있다. 제안된 방법은 단순히 백색 잡음을 경험적인 방법으로 가산하고 결과를 관찰하였으나 에 대한 엄밀한 분석이 추가되는 경우 기존의 적대적 훈련 방법과 같이 비용과 시간이 많이 소요되는 적대적 공격에 대한 방어 기술을 제공할 수 있을 것으로 사료된다.","In this paper we propose white noise adding method to prevent missclassification of deep learning system by adversarial attacks. The proposed method is that adding white noise to input image that is benign or adversarial example. The experimental results are showing that the proposed method is robustness to 3 adversarial attacks such as FGSM attack, BIN attack and CW attack. The recognition accuracies of Resnet model with 18, 34, 50 and 101 layers are enhanced when white noise is added to test data set while it does not affect to classification of benign test dataset. The proposed model is applicable to defense to adversarial attacks and replace to time- consuming and high expensive defense method against adversarial attacks such as adversarial training method and deep learning replacing method."
뉴스 감성 분석을 이용한 딥러닝 기반 주가 예측에 대한 연구,2022,"['Stock Price Forecasting', 'LSTM', 'ResNet', 'Sentiment Analysis', 'Text Summarization', '주가 예측 모델', '텍스트 요약', 'LSTM', 'ResNet', '감정 분석']","주가는 거래량, 종가 등과 같은 숫자 기반의 내부적인 요인뿐만 아니라 법, 유행 등 여러 외부요인에 의해 영향을 받는다. 수많은 요인이 주가에 영향을 미치기 때문에 단편적인 주식 데이터만을 이용한 정확한 주가 예측은 매우 어려운 일이다. 특히 기업의 가치는 실제 주식을 거래하는사람들의 인식에 영향을 많이 받기 때문에 특정 기업에 대한 감성 정보가 중요한 요인으로 여겨진다. 본 논문에서는 시간적 특성을 고려한 뉴스 데이터의 감성 분석을 이용한 딥러닝 기반 주가예측 모델을 제안하고자 한다. 주식과 뉴스 데이터, 서로 다른 특성을 가진 2개의 이종 데이터를시간 크기에 따라 통합하여 모델의 입력으로 사용하며, 시간 크기와 감성 지표가 주가 예측에 미치는 영향에 대해 최종적으로 비교 및 분석한다. 또한 우리는 기존 모델과의 비교 실험을 통해제안 모델의 정확성이 개선되었음을 검증한다.","Stock prices are influenced by a number of external factors, such as laws and trends, as well as number-based internal factors such as trading volume and closing prices. Since many factors affect stock prices, it is very difficult to accurately predict stock prices using only fragmentary stock data. In particular, since the value of a company is greatly affected by the perception of people who actually trade stocks, emotional information about a specific company is considered an important factor. In this paper, we propose a deep learning-based stock price prediction model using sentiment analysis with news data considering temporal characteristics. Stock and news data, two heterogeneous data with different characteristics, are integrated according to time scale and used as input to the model, and the effect of time scale and sentiment index on stock price prediction is finally compared and analyzed. Also, we verify that the accuracy of the proposed model is improved through comparative experiments with existing models."
딥러닝 기반 이미지 필터 간 한국인 표정 분류 성능 비교,2022,"['얼굴 표정 분류', 'CNN', 'VGG', 'ResNet', '가장자리 검출 필터', 'Facial Expression Classification', 'CNN', 'VGG', 'ResNet', 'Edge Detection Filter']",국문 초록 정보 없음,다국어 초록 정보 없음
A Hybrid Optimized Deep Learning Techniques for Analyzing Mammograms,2022,"['Deep Learning', 'Convolutional Neural Networks (CNNs)', 'Residual Network (ResNet)', 'Teaching Learning Based Optimization Algorithm (TLBO)']",국문 초록 정보 없음,"Early detection continues to be the mainstay of breast cancer control as well as the improvement of its treatment. Even so, the absence of cancer symptoms at the onset has early detection quite challenging. Therefore, various researchers continue to focus on cancer as a topic of health to try and make improvements from the perspectives of diagnosis, prevention, and treatment. This research's chief goal is development of a system with deep learning for classification of the breast cancer as non-malignant and malignant using mammogram images. The following two distinct approaches: the first one with the utilization of patches of the Region of Interest (ROI), and the second one with the utilization of the overall images is used. The proposed system is composed of the following two distinct stages: the pre-processing stage and the Convolution Neural Network (CNN) building stage. Of late, the use of meta-heuristic optimization algorithms has accomplished a lot of progress in resolving these problems. Teaching-Learning Based Optimization algorithm (TIBO) meta-heuristic was originally employed for resolving problems of continuous optimization. This work has offered the proposals of novel methods for training the Residual Network (ResNet) as well as the CNN based on the TLBO and the Genetic Algorithm (GA). The classification of breast cancer can be enhanced with direct application of the hybrid TLBO- GA. For this hybrid algorithm, the TLBO, i.e., a core component, will combine the following three distinct operators of the GA: coding, crossover, and mutation. In the TLBO, there is a representation of the optimization solutions as students. On the other hand, the hybrid TLBO-GA will have further division of the students as follows: the top students, the ordinary students, and the poor students. The experiments demonstrated that the proposed hybrid TLBO-GA is more effective than TLBO and GA."
GAN을 활용한 인테리어 스타일 변환 모델에 관한 연구,2022,"['CycleGAN', '이미지 변환', '인테리어 스타일', '이미지 렌더링', 'CycleGAN', 'Image Translation', 'Interior Style', 'Image Rendering']",국문 초록 정보 없음,"Recently, demand for designing own space is increasing as the rapid growth of home furnishing market. However, there is a limitation that it is not easy to compare the style between before construction view and after view. This study aims to translate real image into another style with GAN model learned with interior images. To implement this, first we established style criteria and collected modern, natural, and classic style images, and experimented with ResNet, UNet, Gradient penalty concept to CycleGAN algorithm. As a result of training, model recognize common indoor image elements, such as floor, wall, and furniture, and suitable color, material was converted according to interior style. On the other hand, the form of furniture, ornaments, and detailed pattern expressions are difficult to be recognized by CycleGAN model, and the accuracy lacked. Although UNet converted images more radically than ResNet, it was more stained. The GAN algorithm allowed us to represent results within 2 seconds. Through this, it is possible to quickly and easily visualize and compare the front and after the interior space style to be constructed. Furthermore, this GAN will be available to use in the design rendering include interior."
비정상심박 검출을 위해 영상화된 심전도 신호를 이용한 비교학습 기반 딥러닝 알고리즘,2022,"['심전도', '딥러닝', 'CNN', '템플릿 군', '비정상심박 검출', 'Electrocardiogram', 'Deep learning', 'Convolutional neural network', 'Template cluster', 'Abnormal beat detection']","심전도 신호는 개인에 따라 형태와 특징이 다양하므로, 하나의 신경망으로는 분류하기가 어렵다. 주어진 데이터를 직접적으로 분류하는 것은 어려우나, 대응되는 정상 데이터가 있을 경우, 이를 비교하여 정상 및 비정상을 분류하는 것은 상대적으로 쉽고 정확하다. 본 논문에서는 템플릿 군을 이용하여 대표정상심박 정보를 획득하고, 이를 입력심박에 결합함으로써 심박을 분류한다. 결합된 심박을 영상화한 후, 학습 및 분류를 진행하여, 하나의 신경망으로도 다양한 레코드의 비정상심박을 검출이 가능하였다. 특히, GoogLeNet, ResNet, DarkNet 등 다양한 신경망에 대해서도 비교학습 기법을 적용한 결과, 모두 우수한 검출성능을 가졌으며, GoogLeNet의 경우 99.72%의 민감도로, 실험에 사용된 신경망 중 가장 우수한 성능을 가졌음을 확인하였다.","Electrocardiogram (ECG) signal's shape and characteristic varies through each individual, so it is difficult to classify with one neural network. It is difficult to classify the given data directly, but if corresponding normal beat is given, it is relatively easy and accurate to classify the beat by comparing two beats. In this study, we classify the ECG signal by generating the reference normal beat through the template cluster, and combining with the input ECG signal. It is possible to detect abnormal beats of various individual’s records with one neural network by learning and classifying with the imaged ECG beats which are combined with corresponding reference normal beat. Especially, various neural networks, such as GoogLeNet, ResNet, and DarkNet, showed excellent performance when using the comparative learning. Also, we can confirmed that GoogLeNet has 99.72% sensitivity, which is the highest performance of the three neural networks."
Detection and Localization of Coordinated State-and-Topology False Data Injection Attack by Multi-modal Learning,2022,"['Power system cyber security', 'False data injection attack', 'Topology attack', 'Multi-modal learning', 'Data-driven methods']",국문 초록 정보 없음,"False data injection attack (FDIA) is a typical cyber-attack targeting on power system state estimation. By inserting bias into the power system meter measurements, FDIA can cause errors in state estimation and consequently mislead power system operation. Recently, the coordinated state-and-topology FDIA was developed to falsify both the meter measurements and the topology information to conceal a cyber or physical attack. Conventional machine-learning-based detection methods against FDIA depend on the complete observability of power system topology, therefore cannot detect the coordinated state-andtopology FDIA. To address this challenge, we propose a multi-modal learning model based on Graph Auto-Encoder (GAE) and Residual Neural Networks (ResNet) to detect this type of FDIA. First, GAE is used to learn the compact representation of power system topologies. Then, the obtained topological representation is fused with the measurement to obtain the multi-modal features. Third, ResNet is trained as a multi-label classifi er to accept the fused features and generate an array, which can detect attack scenarios and identify the falsifi ed measurements/topologies by coordinated attacks. Comprehensive case studies using IEEE 9-bus, IEEE 57-bus, and IEEE 118-bus systems are presented. The simulation results show that, as compared to single feature methods, the proposed method is more eff ective in detecting coordinated state-and-topology attacks, and more robust in case of FDIA under unseen topological changes in power system operation"
산림복원 대상 후보지 추출을 위한 딥러닝 접근법,2022,"['딥러닝', '분할', '산림복원', '항공사진', 'Aerial photo', 'Deep learning', 'Forest restoration', 'Segmentation']","이미지 인식에 특화된 CNN (Convolutional Neural Network) 기반의 딥러닝 기법은 영상의 항목별 분류가 필요한 다양한 연구에 적용되고있다. 본 연구는 건물, 도로, 논, 밭, 산림, 나지의 6가지 항목을 산림복원 대상 후보지로 정의하고 CNN 기반의 산림복원 대상 후보지 추출 및분류의 최적 방법론을 탐색하였다. 6,640개의 데이터셋을 75:25의 비율로 훈련(4,980개) 및 검증(1,660개)로 구분하여 구축하고 학습에 활용하였다.모델별 정확도는 픽셀정확도(PA), 평균 교차 겹침 결합(Mean IoU)을 이용하여 평가하였다. 픽셀정확도는 90.6%, 평균 교차 겹침 결합은 80.8%로산정되어 Inception-Resnet-v2 모델이 세 모델 중 가장 산림복원 대상 후보지 추출에 뛰어난 정확도를 보였다. 이 결과는 기존의 산림복원 대상후보지 현장조사 혹은 항공사진을 활용한 조사에 비해 시공간적 이점을 가지며, 향후 산림복원 대상지 선정 자료로 적용 가능성이 있다고 판단된다.","Many studies using aerial photography and deep learning are increasing for efficient monitoring of the forest resources. We defined six semantic classes of buildings, roads, paddy fields, fields, forests, and barren as forest restoration target sites and explored the optimal methodology for extracting and classifying target sites for forest restoration based on CNN. The datasets (6,640) were divided at a ratio of 75:25 into training (4,980) and validation datasets (1,660). The accuracy of each model was evaluated using pixel accuracy (PA) and Mean Intersection over union (Mean IoU). PA was calculated as 90.6% and Mean IoU was 80.8%, and the Inception-Resnet-v2 model showed excellent accuracy in extracting target sites for forest restoration among the three models. This result has a Spatio-temporal advantage over the existing field survey for forest restoration sites or surveys using aerial photographs by manually. This study will be able to contribute to the classification of forest restoration sites efficiently and support forest restoration."
블랙 박스 모델의 출력값을 이용한 AI 모델 종류 추론 공격,2022,"['AI security', 'Privacy', 'Exploratory Attack', 'Inference Attack']","AI 기술이 여러 분야에 성공적으로 도입되는 추세이며, 서비스로 환경에 배포된 모델들은 지적 재산권과 데이터를 보호하기 위해 모델의 정보를 노출시키지 않는 블랙 박스 상태로 배포된다. 블랙 박스 환경에서 공격자들은 모델 출력을 이용해 학습에 쓰인 데이터나 파라미터를 훔치려고 한다. 본 논문은 딥러닝 모델을 대상으로 모델 종류에 대한 정보를 추론하는 공격이 없다는 점에서 착안하여, 모델의 구성 레이어 정보를 직접 알아내기 위해 모델의 종류를 추론하는 공격 방법을 제안한다. MNIST 데이터셋으로 학습된 ResNet, VGGNet, AlexNet과 간단한 컨볼루션 신경망 모델까지 네 가지 모델의 그레이 박스 및 블랙 박스 환경에서의 출력값을 이용해 모델의 종류가 추론될 수 있다는 것을 보였다. 또한 본 논문이 제안하는 방식인 대소 관계 피쳐를 딥러닝 모델에 함께 학습시킨 경우 블랙 박스 환경에서 약 83%의 정확도로 모델의 종류를 추론했으며, 그 결과를 통해 공격자에게 확률 벡터가 아닌 제한된 정보만 제공되는 상황에서도 모델 종류가 추론될 수 있음을 보였다.","AI technology is being successfully introduced in many fields, and models deployed as a service are deployed with black box environment that does not expose the model's information to protect intellectual property rights and data. In a black box environment, attackers try to steal data or parameters used during training by using model output. This paper proposes a method of inferring the type of model to directly find out the composition of layer of the target model, based on the fact that there is no attack to infer the information about the type of model from the deep learning model. With ResNet, VGGNet, AlexNet, and simple convolutional neural network models trained with MNIST datasets, we show that the types of models can be inferred using the output values in the gray box and black box environments of the each model. In addition, we inferred the type of model with approximately 83% accuracy in the black box environment if we train the big and small relationship feature that proposed in this paper together, the results show that the model type can be infrerred even in situations where only partial information is given to attackers, not raw probability vectors."
모노 카메라를 사용하는 머신 비전 시스템에서 비정형 결함을 검사하는 CNN을 훈련하기 위한 데이터 증식 방법,2022,"['Machine Vision(머신 비전)', 'Convolutional Neural Networks(합성곱 신경망)', 'Data Augmentation (데이터 증식)', 'Image Segmentation(이미지 영역 분할)']",최근 합성곱 신경망(CNN)을 머신 비전에 적용함으로써 비정형 결함의 검사에서 우수한 검사 성능을 보이고 있다. 그러나 머신 비전 시스템에서 CNN을 훈련하기 위해 충분한 양의 데이터를 모으고 정리하는 것은 상당한 시간이 필요하다. 이 문제를 해결하기 위해 본 연구는 모노 카메라를 사용하는 머신 비전 시스템에서 CNN을 사용하여 비정형 결함을 검사할 때 사용할 수 있는 데이터 증식 방법을 제안한다. 임의의 패턴에서 비정형의 결함을 검출하기 위해 제작된 DAGM 2007 데이터 중 1번 하위 클래스 데이터를 실험 데이터로 사용하였다. 결함 검출을 위한 CNN은 Mask R-CNN ResNet 50을 사용하였다. 제안하는 방법을 통해 증식한 데이터로 훈련한 CNN이 원본 회색조 이미지로 검증을 수행했을 때 원본 데이터로 훈련한 CNN에 비해 Mask mAP@0.5:0.95 기준 평균 16.73%p 높은 61.38%의 정확도를 보이는 것을 확인했다. 본 연구에서 적용한 데이터 증식 방법을 통해 모노 카메라를 활용하는 머신 비전시스템에서 우수한 성능을 가진 CNN을 훈련할 수 있다.,"Applying convolutional neural networks (CNN) to machine vision has recently exhibited excellent performance in amorphous defect inspection. However, collecting and annotating sufficient amounts of data to train CNNs in machine vision systems take considerable time. In this study, a data augmentation method is proposed that can be used to inspect amorphous defects using CNNs in machine vision systems using mono cameras. Class 1 subdata of the DAGM 2007 dataset produced to detect defects in arbitrary patterns were used as experimental data. We trained Mask R-CNN ResNet 50 for defect inspection. Through the proposed method, we found that the CNN trained with the augmented data exhibited an average accuracy of 61.38%, which is 16.73%p higher based on Mask mAP@0.5:0.95 compared to the CNN trained with the original data when validation was performed with original grayscale images. By using the data augmentation method applied in this study, CNNs in the machine vision systems using mono cameras can achieve higher inspection performance."
Tutorial and applications of convolutional neural network models in image classification,2022,"['AdamW', 'convolution neural network', 'deep learning', 'ILSVRC']",국문 초록 정보 없음,"Image classification is a supervised learning problem in the machine learning area. We apply deep learning models to classify image data. In particular, we discuss the advantages of the various types of convolutional neural networks competed in the ImageNet large-scale visual recognition challenge (ILSVRC). First, we provide a review of the CNN models to be applied and explain the details of models to be employed. In general, we keep the core structure of the models in the same form proposed in ILSVRC. We investigate the models via four popular image data sets of various sizes. To compare the performance of the models, we adopt top-1 accuracy, top-5 accuracy, and f1-score as the measures of accuracy. We employ AdamW for an optimizer that is a fast algorithm and often yields precise learning. As a result, we show that the Inception-ResNet-v2 model has excellent performance, and the ResNet is robust to imbalanced data."
A study for selecting optimal classification AI model for 1-naphthyl isothiocyanate-induced liver necrosis in the mouse,2022,"['Classification algorithms', 'ResNet-50', 'Xception', 'EfficientNet-B0', 'Liver necrosis']",국문 초록 정보 없음,다국어 초록 정보 없음
레즈넷을 사용한 충격 전 낙상 검출에서의 필터 수에 따른 정확도와 메모리 크기,2022,"['Fall detection', 'Deep learning', 'ResNet', 'Filters', 'Memory']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝과 다양한 데이터 증강 기법을 활용한 주변국 군용기 기종 분류에 관한 연구,2022,"['Deep Learning(딥러닝)', 'ResNet(레스넷)', 'Fine-Grained Visual Classification(세밀한 이미지 분류)', 'Edge Detection(윤곽선 탐지)', 'Image Data Augmentation(이미지 데이터 증강)']",국문 초록 정보 없음,"The analysis of foreign aircraft appearing suddenly in air defense identification zones requires a lot of cost and time. This study aims to develop a pre-trained model that can identify neighboring military aircraft based on aircraft photographs available on the web and present a model that can determine which aircraft corresponds to based on aerial photographs taken by allies. The advantages of this model are to reduce the cost and time required for model classification by proposing a pre-trained model and to improve the performance of the classifier by data augmentation of edge-detected images, cropping, flipping and so on."
음성기반 대화형 서비스 키오스크 설계 및 구현,2022,"['Web', 'Voice recognition', 'Collaborative Filtering', 'Recommendation System', 'Dialogflow', 'REST API', 'ResNet', 'MobileNet']","최근에 늘어가는 키오스크(KIOSK)의 수요에 따라 불편함을 호소하는 이용자가 많아졌다. 이에 음성 기반 대화형 서비스를 구현하여 손쉽게 메뉴 선택 및 주문을 가능하게 해주는 키오스크를 제작해 웹의 형태로 제공한다. Annyang API와SpeechSynthesis API를 바탕으로 음성 기능을 구현하고 Dialogflow를 통해 사용자의 의도를 파악하는 과정을 Rest API를 기반으로 구현하는 방법에 대해 논한다. 또한 협업 필터링을 기반으로 추천 시스템을 적용하여 기존 키오스크의 낮은 소비자 접근성을 개선하였고, 음성인식 서비스 이용 도중 발생하는 비말로 인한 감염을 예방하기 위해 서비스 이용 전 마스크 착용을 확인하는 기능을 제공한다.","As the demand for kiosks increases, more users complain of discomfort. Accordingly, a kiosk that enables easy menu selectionand order by producing a voice-based interactive service is produced and provided in the form of a web. It implements voice functions based on the Annyang API and SpeechSynthesis API, and understands the user’s intention through Dialogflow. And discusshow to implement this process based on Rest API. In addition, the recommendation system is applied based on collaborative filteringto improve the low consumer accessibility of existing kiosks, and to prevent infection caused by droplets during the use of voicerecognition services, it provides the ability to check the wearing of masks before using the service."
CCTV 영상의 이상행동 다중 분류를 위한 결합 인공지능 모델에 관한 연구,2022,"['CCTV', 'Abnormal Event', '3D Convolutional Neural Network', 'Transfer Learning', 'ResNet']",국문 초록 정보 없음,다국어 초록 정보 없음
Healing Game using AI and Art Therapy,2022,"['Healing Game', 'Self-help-therapy', 'Word Cloud', 'Unity ML Agent', 'ResNet']",국문 초록 정보 없음,"Recently, AI technology is developing rapidly every day, and AI technology is being used in various fields. This paper produced a healing game that comforts the mind tired of human relationships and personal reasons in the COVID-19 situation by using AI technology in the art field. In the produced healing game, the effect of self-help-therapy may be obtained, and thus, it is expected that a user may obtain a healing effect in a daily use process through a healing game without the help of a therapist. By statistically analyzing the game review data, a healing game was created by accommodating the public's demands as a healing game, and users were able to obtain a self-help-therapy effect by making a simple storyline and a simple conversation that could interact with AI before the game began."
병렬 병합 구조를 이용한 기상 데이터의 예측률 향상을 위한 딥러닝 모델,2022,"['deep neural network', 'long short term memory', 'convolution neural network', 'ResNet', 'Inception', '.']","본 연구는 딥러닝 기본모델인 DNN, LSTM, BiLSTM, 1D-CNN 등으로, 예측의 성능을 향상하기 위해, 중간층을 병렬로 병합하는 구조를 제안하였다. 제안모델 1은 동일한 기본모델을 병렬 병합한 구조이고, 제안모델 2는 서로 다른 모델의 병렬 병합한 구조이다. 각 모델의 평가는 RMSE와 MAE로 10회 실험에 대한 평균값이다. 제안모델 1에서 가장 좋은 예측률을 보인 BiLSTM2의 RMSE는 0.064이다. 제안모델 2의 RMSE는 DC(DNN-CNN), LC(BiLSTM-CNN), DLC(DNN-BiLSTM-CNN) 등 모든 모델이 0.054였다. 이처럼 제안모델 2가 12.8%의 성능 향상을 보였다. 제안모델 2가 서로 다른 모델의 장점을 유지하면서 많은 파라메터로, 예측률을 향상할 수 있게 하는 모델임을 확인할 수 있었다.","In this study, using deep learning basic models DNN, LSTM, BiLSTM, and 1D-CNN, to improve prediction performance, we proposed a structure in which hidden layers are merged in parallel. Proposed model 1 is a parallel merging structure of the same basic model, and Proposed model 2 is a parallel merging structure of different models. The evaluation of each model is the average value for 10 experiments with RMSE and MAE. The RMSE of BiLSTM2, which showed the best prediction rate in Proposed Model 1, is 0.064. The RMSE of Proposed Model 2 was 0.054 for all models including DC (DNN-CNN), LC (BiLSTM-CNN), and DLC (DNN-BiLSTM-CNN). As such, Proposed Model 2 showed a performance improvement of 12.8%. It was confirmed that Proposed Model 2 is a model that can improve the prediction rate by using many parameters while maintaining the advantages of different models."
확률분포 분리기반 지식증류를 활용한 분류기 개선에 관한 연구,2022,"['지식증류', '모방학습', '분류기']","본 논문에서는 교사-학생 프레임워크에서 학생이 교사의 클래스 확률을 모사하는 새로운 Knowledge Distillation 방법을 제시한다. 전통적인 Knowledge Distillation 기법은 교사와 학생의 logits을 soften시켜 모방을 진행하지만, 제안하는 방법은 기존 방법과 다르게 교사와 학생의 Top-1 확률값을 포함한 확률분포와 Top-1의 확률값과 나머지 logits을 분리하고 soften시켜 dark knowledge를 생성하여 새로운 확률분포를 만든다. 학생은 교사의 분리된 각각의 2가지 형태의 클래스 확률을 모방하여 성능을 높인다. CIFAR 데이터셋에서 resnet, vgg, wrn과 같은 다양한 네트워크로 제안하는 방법론의 우수성을 실험을 통해 입증한다.",다국어 초록 정보 없음
단일 파노라마 입력의 실내 공간 레이아웃 복원 모델 경량화,2022,"['Room Layout Estimation', 'Neural Architecture Search', 'Lightweight Deep Learning', '.']",국문 초록 정보 없음,.
사과 병해충 분류를 위한 CNN 기반 모델 비교,2022,[],"세계에서 가장 중요한 온대 과일 작물 중 하나인 사과의 생산성과 품질은 병해충 여부에 큰 영향을 받는다. 이를 진단하기 위해서는 효율적이고 많은 전문 지식과 상당한 시간이 필요하다. 그러므로 이를 해결하기 위해 효율적이고 정확하게 다양한 병해충을 진단하는 시스템이 필요하다. 본 논문에서는 이미지 분석에 큰 효율을 보인 딥러닝 기반 CNN 들을 비교 분석하여 사과의 병해충 여부를 판별하고 최적의 모델을 제시한다. 딥러닝 기반 CNN 구조를 가진 AlexNet, VGGNet, Inception-ResNet-v2, DenseNet 을 채택해 사과 병해충 분류 성능 평가를 진행했다. 그 결과 DenseNet 이 가장 우수한 성능을 보여주었다.",다국어 초록 정보 없음
Triplet Loss 기반 딥러닝 모델을 통한 유사 아동 그림 선별 알고리즘,2022,"['이미지 유사성', 'Triplet Loss', '인공지능', '딥러닝', 'CNN', '아동 그림분석', 'Image Similarity', 'Triplet Loss', 'Artificial Intelligence', 'Deep Learning', 'CNN', 'Child drawing analysis']","본 논문은 유사 아동 그림 선별 알고리즘 생성을 위한 Triplet Loss 기반 딥러닝 모델 설계를 목적으로 한다. 아동 그림들 사이 유사성 측정을 위해서는 동일 클래스에 속하는 그림 간 특징 벡터의 거리는 가까워야 하고 다른 클래스 간 특징 벡터의 거리는 멀어져야 한다. 따라서, 본 연구에서는 클래스 수가 많아지는 경우에 이미지 유사성 측정에 이점을 지닌 Triplet Loss와 잔여 네트워크(ResNet)를 결합한 딥러닝 모델을 구축하여 유사 아동 그림 선별 알고리즘을 생성하였다. 결론적으로 본 모델을 활용한 유사 아동 그림 선별 알고리즘을 통해 대상 아동 그림과 다른 그림 간의 유사성을 측정하고 유사성이 높은 그림을 선별할 수 있다.",다국어 초록 정보 없음
비가시 공간에서의 MIMO 안테나 기반 벽체 투과 레이더 신호를 이용한 물체 분류에 관한 연구,2022,[],"비가시 공간의 물체를 탐지하는 기술은 일반적인 시야에서 볼 수 없는 영역 내 사물을 인식하는 기술이며, RF 신호는 벽을 투과하여 물체를 측정할 수 있는 특성을 지녀 이를 구현하기에 적합한 센서 형태로 꼽히고 있다. 본 논문에서는 안테나와 탐지하고자 하는 물체 사이에 위치하는 벽의 다양한 소재를 사용하여 비가시 영역을 구성하고, MIMO 레이더 안테나와 UWB 레이더 칩을 통해 RF 데이터를 수집하였다. 이때 MIMO 안테나 구성을 변화하면서 수집한 데이터셋을 입력값으로 받는 ResNet 기반 네트워크를 사용하며 학습을 진행하였다. 이로써 MIMO 안테나 구성의 변화에 따라 비가시 영역의 물체 정보에 대한 해상도 차이를 다른 소재로 구성된 벽체 별로 분석하였다.",다국어 초록 정보 없음
3D 특징 벡터를 이용한 영아 울음소리 분류,2022,[],"영아는 울음이라는 비언어적 의사 소통 방식을 사용하여 모든 욕구를 표현한다. 하지만 영아의 울음소리를 파악하는 것에는 어려움이 따른다. 영아의 울음소리를 해석하기 위해 많은 연구가 진행되었다. 이에 본 논문에서는 3D 특징 벡터를 이용한 영아의 울음소리 분류를 제안한다. Donate-acorpus-cry 데이터 세트는 복통, 트림, 불편, 배고픔, 피곤으로 총 5 개의 클래스로 분류된 데이터를 사용한다. 데이터들은 원래 속도의 90%와 110%로 수정하는 방법인 템포조절을 통해 증강한다. Spectrogram, Mel-Spectrogram, MFCC 로 특징 벡터화를 시켜준 후, 각각의 2 차원 특징벡터를 묶어 3차원 특징벡터로 구성한다. 이후 3 차원 특징 벡터를 ResNet 과 EfficientNet 모델로 학습을 진행한다. 그 결과 2 차원 특징 벡터는 0.89(F1) 3 차원 특징 벡터의 경우 0.98(F1)으로 0.09 의 성능 향상을 보여주었다.",다국어 초록 정보 없음
어텐션 메커니즘을 활용한 딥러닝 기반의 번호판 검출 및 인식,2022,"['Korean license plate recognition', 'Korean license plate detection', 'Deep Learning', 'Attention Mechanism']","최근 차량관련 기술의 발전은 빅데이터와 인공지능 기술을 기반으로 새로운 성능지표를 달성하고 있다. 본 연구는 License Plate Recognition을 스마트시티의 일부로서 효과적으로 구현하는데 필요한 요소기 술을 제안한다. LPR 기술은 새로운 번호판을 도입하거나 서체나 글자수 등의 포맷 변경 등 환경 변화 및 조건에 매우 민감한 문제점을 가지고 있다. 제안된 알고리즘은 언급된 문제들을 효율적으로 해결 가 능한 딥러닝 기반 LPR 기술을 소개한다. 본 연구는 (1) 차량 이미지에서 번호판을 검출하기 위해 Atte ntion Mechanism Module을 사용하여 효과적으로 인식할 수 있는 License Plate Detection 시스템 (2 ) TPS-ResNet-BiLSTM-Attn 모델을 기반으로 한 번호판 인식 기술을 제안한다. 제안된 프레임워크 는 성능평가 결과 검출율 (mAP) 97.6%, 인식률 (Accuracy) 97.3%의 인식률을 달성한다.",다국어 초록 정보 없음
Deep Learning for Weeds’ Growth Point Detection based on U-Net,2022,"['artificial intelligence', 'growth point', 'deep learning', 'semantic graphics', 'U-Net']",국문 초록 정보 없음,"Weeds bring disadvantages to crops since they can damage them, and a clean treatment with less pollution and contamination should be developed. Artificial intelligence gives new hope to agriculture to achieve smart farming. This study delivers an automated weeds growth point detection using deep learning. This study proposes a combination of semantic graphics for generating data annotation and U-Net with pre-trained deep learning as a backbone for locating the growth point of the weeds on the given field scene. The dataset was collected from an actual field. We measured the intersection over union, f1-score, precision, and recall to evaluate our method. Moreover, Mobilenet V2 was chosen as the backbone and compared with Resnet 34. The results showed that the proposed method was accurate enough to detect the growth point and handle the brightness variation. The best performance was achieved by Mobilenet V2 as a backbone with IoU 96.81%, precision 97.77%, recall 98.97%, and f1-score 97.30%."
Classification of dog skin diseases using deep learning with images captured from multispectral imaging device,2022,"['Deep learning', 'Dog skin disease', 'Multispectral image', 'Dermatosis']",국문 초록 정보 없음,"Background Dog-associated infections are related to more than 70 human diseases. Given that the health diagnosis of a dog requires expertise of the veterinarian, an artificial intelligence model for detecting dog diseases could significantly reduce time and cost required for a diagnosis and efficiently maintain animal health.Objective We collected normal and multispectral images to develop classification model of each three dog skin diseases (bacterial dermatosis, fungal infection, and hypersensitivity allergic dermatosis). The single models (normal image- and multispectral image-based) and consensus models were developed used to four CNN model architecture (InceptionNet, ResNet, DenseNet, MobileNet) and select well-performed model.Results For single models, such as normal image- or multispectral image-based model, the best accuracies and Matthew’s correlation coefficients (MCCs) for validation data set were 0.80 and 0.64 for bacterial dermatosis, 0.70 and 0.36 for fungal infection, and 0.82 and 0.47 for hypersensitivity allergic dermatosis. For the consensus models, the best accuracies and MCCs for the validation set were 0.89 and 0.76 for the bacterial dermatosis data set, 0.87 and 0.63 for the fungal infection data set, and 0.87 and 0.63 for the hypersensitivity allergic dermatosis data set, respectively, which supported that the consensus models of each disease were more balanced and well-performed.Conclusions We developed consensus models for each skin disease for dogs by combining each best model developed with the normal and multispectral images, respectively. Since the normal images could be used to determine areas suspected of lesion of skin disease and additionally the multispectral images could help confirming skin redness of the area, the models achieved higher prediction accuracy with balanced performance between sensitivity and specificity."
Genetic Algorithm-Based Structure Reduction for Convolutional Neural Network,2022,"['Structure reduction', 'Convolutional neural network', 'Genetic algorithm', 'Knowledge distillation']",국문 초록 정보 없음,"Due to the heavy computational burden, deep models of embedded and mobile systems inevitably require network reduction with minimum performance degradation. Pruning method is mainly used to reduce the model by removing some fi lters only within the layer without changing the structure. Some methods for structural reduction of models are far from optimization.We propose a structure reduction method using a genetic algorithm to optimize the removal of reducible layers. Knowledge distillation is carried out to recover the resultant network. We evaluate our method for ResNet on two image classifi cation datasets, CIFAR-10 and CIFAR-100. Experiments show that our method performs a signifi cant improvement over other state-of-the-art methods."
A Novel Transfer Learning-Based Algorithm for Detecting Violence Images,2022,"['Deep learning', 'Image classification', 'Pre-training', 'Violence images']",국문 초록 정보 없음,"Violence in the Internet era poses a new challenge to the current counter-riot work, and according to research and analysis, most of the violent incidents occurring are related to the dissemination of violence images. The use of the popular deep learning neural network to automatically analyze the massive amount of images on the Internet has become one of the important tools in the current counter-violence work. This paper focuses on the use of transfer learning techniques and the introduction of an attention mechanism to the residual network (ResNet) model for the classification and identification of violence images. Firstly, the feature elements of the violence images are identified and a targeted dataset is constructed; secondly, due to the small number of positive samples of violence images, pre-training and attention mechanisms are introduced to suggest improvements to the traditional residual network; finally, the improved model is trained and tested on the constructed dedicated dataset. The research results show that the improved network model can quickly and accurately identify violence images with an average accuracy rate of 92.20%, thus effectively reducing the cost of manual identification and providing decision support for combating rebel organization activities."
머신러닝 기반 금속외관 결함 검출 비교 분석,2022,"['금속 외관', '결함 검출', '머신러닝', '합성곱신경망', 'Metal Surface', 'Defect Detection', 'Machine Learning', 'Convolutional Neural Network']","최근 스마트팩토리와 인공지능 기술의 수요 증가로 인해 다양한 분야에서 인공지능 기술을 적용하는 연구가 진행되고 있다. 결함 검사 분야에서도 인공지능 알고리즘을 도입하기 위한 노력을 기울이고 있다. 특히, 금속 외관의 결함을 검출하는 연구는 다른 소재(목재, 플라스틱, 섬유 등)의 결함을 검출하는 연구에 비해 많은 연구가 이루어지고 있다. 본 논문에서는 머신러닝 기법(서포터 벡터 머신(SVM: Support Vector Machine), 소프트맥스 회귀(Softmax Regression), 결정 트리(Decesion Tree))과 차원 축소 알고리즘(주성분 분석(PCA: Principal Component Analysis), 오토인코더(AutoEncoder))의 9가지 조합과 2가지 합성곱신경망(CNN: Convolution Neural Network) 기법(자체 알고리즘, ResNet)의 금속 외관의 결함 분류 성능 및 속도를 비교하고 분석하는 연구를 수행하고자 한다. 두 종류의 학습 데이터셋((i) 공용 데이터셋, (ii) 실측 데이터셋)에 대한 실험을 통해 각 데이터셋에 대한 성능 및 속도를 비교 분석하고, 가장 효율적인 알고리즘을 찾아낸다.",다국어 초록 정보 없음
Hybrid Tensor Flow DNN and Modified Residual Network Approach for Cyber Security Threats Detection in Internet of Things,2022,"['IoT', 'malware detection', 'software piracy', 'cyber security', 'data mining', 'Tensor flow DNN']",국문 초록 정보 없음,"The prominence of IoTs (Internet of Things) and exponential advancement of computer networks has resulted in massive essential applications. Recognizing various cyber-attacks or anomalies in networks and establishing effective intrusion recognition systems are becoming increasingly vital to current security. MLTs (Machine Learning Techniques) can be developed for such data-driven intelligent recognition systems. Researchers have employed a TFDNNs (Tensor Flow Deep Neural Networks) and DCNNs (Deep Convolution Neural Networks) to recognize pirated software and malwares efficiently. However, tuning the amount of neurons in multiple layers with activation functions leads to learning error rates, degrading classifier's reliability. HTFDNNs ( Hybrid tensor flow DNNs) and MRNs (Modified Residual Networks) or Resnet CNNs were presented to recognize software piracy and malwares. This study proposes HTFDNNs to identify stolen software starting with plagiarized source codes. This work uses Tokens and weights for filtering noises while focusing on token's for identifying source code thefts. DLTs (Deep learning techniques) are then used to detect plagiarized sources. Data from Google Code Jam is used for finding software piracy. MRNs visualize colour images for identifying harms in networks using IoTs. Malware samples of Maling dataset is used for tests in this work."
딥러닝 훈련을 위한 GAN 기반 거짓 영상 분석효과에 대한 연구,2022,"['Generative Adversarial Network (GAN)', 'Visual intelligence', 'Fake image', 'Power facility']",국문 초록 정보 없음,"To inspect the power facility faults using artificial intelligence, it need that improve the accuracy of the diagnostic model are required. Data augmentation skill using generative adversarial network (GAN) is one of the best ways to improve deep learning performance. GAN model can create realistic-looking fake images using two competitive learning networks such as discriminator and generator. In this study, we intend to verify the effectiveness of virtual data generation technology by including the fake image of power facility generated through GAN in the deep learning training set. The GAN-based fake image was created for damage of LP insulator, and ResNet based normal and defect classification model was developed to verify the effect. Through this, we analyzed the model accuracy according to the ratio of normal and defective training data."
각도 마진 손실 함수를 적용한 객체 분류,2022,[],"객체 분류는 입력으로 주어진 이미지에 포함된 객체의 종류를 판단하는 기술이다. 대표적인 딥러닝 기반의 객체 분류 방법으로서 Faster R-CNN[2], YOLO[3] 등의 모델이 개발되었으나, 여전히 성능 향상의 여지가 있다. 본 연구에서는 각도 마진 손실 함수를 기존의 몇 가지 객채 분류 모델에 적용하여 성능 향상을 유도한다. 각도 마진 손실 함수는 얼굴 인식 모델인 SphereFace[4]에서 제안한 방법으로, 얼굴 인식과 같이 단일 도메인의 데이터셋을 분류하는 문제를 풀기 위해 제안되었다. 이는 기존 소프트맥스 함수에서 클래스 결정 경계선에 마진을 주는 방식으로 클래스 간의 구분 능력을 향상시킨다. 본 논문은 각도 마진 손실함수를 CIFAR10, CIFAR100 데이터셋의 분류 문제에 적용하였으며 ResNet, EfficientNet, MobileNet 등의 백본 네트워크로 실험하여 평균적으로 mAP 성능이 향상되는 것을 확인하였다.",다국어 초록 정보 없음
객체 검출을 활용한 교육적 목적의 웹 기반 브레드보드 전기회로 분석,2022,"['전기전자 실험', '서비스', '브레드보드', '위치 검출', '위치 예측', 'Electrical and electronic testing', 'Service', 'Breadboard', 'Position detection', 'Position prediction']",국문 초록 정보 없음,"In an experiment where students learn electrical and electronic theory and apply it, students have difficulty in connecting circuits. To alleviate the above difficulties, we first propose a circuit analysis service. The proposed method detects an electric device using an object detection model in which electric devices connected to a breadboard are labeled with data. To verify this, we connect to the breadboard circuit and create a custom dataset through photographs. The proposed method is divided into two processes: electric device prediction and electric device position detection. The electric device prediction model was compared using five object detection models, and the Faster R-CNN model had the best prediction performance. The electrical device position detector extracts features from the object detection model through transition learning to predict two coordinates (x1, y1), (x2, y2). A comparison of each model confirmed that the ResNet model has good location detection performance. Through this, it was confirmed that the proposed method alleviates the difficulty of first-time students learning electric and electronic experiments."
INTERIOR WIND NOISE PREDICTION AND VISUAL EXPLANATION SYSTEM FOR EXTERIOR VEHICLE DESIGN USING COMBINED CONVOLUTION NEURAL NETWORKS,2022,"['Wind noise prediction', 'Image regression', 'Convolutional neural networks (CNN)', 'Gradient-weighted class activation map (Grad-CAM)']",국문 초록 정보 없음,"An analytical model configuration, in addition to air pressure analysis and post-processing, was conducted to measure the interior wind noise by changing the exterior vehicular design. Although wind noise can be calculated accurately through the current process, it requires three to five days for each design. In this study, a convolutional neural network (CNN), which is a class of deep neural networks designed for processing image data, was applied to predict the wind noise with vehicle design images from four different views. Feature maps were extracted from the CNN models trained with images of each view and concatenated to flow through a sequence of fully connected (FC) layers to predict the wind noise. Moreover, visualization of the significant vehicle parts for wind noise prediction was provided using a gradient-weighted class activation map (Grad- CAM). Finally, we compared the performance of various CNN-based models, such as ResNet, DenseNet, and EfficientNet, in addition to the architecture of the FC layers. The proposed method can predict the wind noise using vehicle images from different views with a root-mean-square error (RMSE) value of 0.206, substantially reducing the time and cost required for interior wind noise estimation."
Segmentation 기반 샤인머스캣의 포도알 검출 및 충실도 예측 알고리즘 개발,2022,"['Mask R-CNN', 'Object detection', 'Shine Muscat', 'Density of Grape Clusters', 'DGC']","포도는 인체의 탄수화물 대사를 촉진시키며 피로를 풀어주는 등 인체에 유익한 알칼리성 식품으로 알려지며 재배와 소비량이 꾸준히 증가하고 있다. 이 중 샤인머스캣은 포도의 다양한 종류 중 하나로, 일반 포도의 쓴 맛이 덜하고 산도가 낮으며 아삭아삭한 식감을 가지고 있어 특히 관심이 높아지고 있다. 이러한 샤인머스캣 품종의 소비가 급격하게 증가함에 따라 노동력과 시간을 절약하기 위한 자동화 공정 시스템을 구축하는 것이 필수인데, 특히 전문가의 육안으로만 포도의 등급을 판단하는 것은 아직도 해결해야 하는 과제 중 하나이다.본 연구에서는 포도의 종류 중 하나인 샤인머스캣을 대상 과실로 지정하였으며, RGB 영상장치를 이용하여 수확 후의 샤인머스캣을 다양한 조도 조건하에 촬영하여 영상을 획득하였다. 단일 포도송이에서 포도 열매를 검출하는 알고리즘을 채택하였으며 합성곱 신경망 네트워크 기반의 영상 분할 기법인 Mask R-CNN을 다양한 backbone과 함께 적용하여 각 모델의 성능을 비교 평가하였다. 그 결과, Mask R-CNN ResNet 101이 모든 모델 중 검출 정확도 AP(Average Precison)값이 가장 높은 것으로 분석되었으며, 해당 네트워크로 샤인머스캣의 포도알 직경, 면적, 빈 공간의 면적 등을 구하여 포도알이 얼마나 밀집되어 있는지를 나타내는 지표인 Density of Grape Clusters (DGC)를 구하였다. 본 연구에서 정의한 이러한 지표들을 통해 샤인머스캣의 수확 후 품질 판단을 보다 정확하고, 신속하게 체계화할 수 있다.",다국어 초록 정보 없음
Sex determination from lateral cephalometric radiographs using an automated deep learning convolutional neural network,2022,"['Sex Determination Analysis', 'Deep Learning', 'Radiography', 'Cephalometry', 'Cervical Vertebrae']",국문 초록 정보 없음,"Purpose: Despite the proliferation of numerous morphometric and anthropometric methods for sex identification based on linear, angular, and regional measurements of various parts of the body, these methods are subject to error due to the observer's knowledge and expertise. This study aimed to explore the possibility of automated sex determination using convolutional neural networks(CNNs) based on lateral cephalometric radiographs. Materials and Methods: Lateral cephalometric radiographs of 1,476 Iranian subjects (794 women and 682 men) from 18 to 49 years of age were included. Lateral cephalometric radiographs were considered as a network input and output layer including 2 classes(male and female). Eighty percent of the data was used as a training set and the rest as a test set. Hyperparameter tuning of each network was done after preprocessing and data augmentation steps. The predictive performance of different architectures (DenseNet, ResNet, and VGG) was evaluated based on their accuracy in test sets. Results: The CNN based on the DenseNet121 architecture, with an overall accuracy of 90%, had the best predictive power in sex determination. The prediction accuracy of this model was almost equal for men and women. Furthermore, with all architectures, the use of transfer learning improved predictive performance. Conclusion: The results confirmed that a CNN could predict a person's sex with high accuracy. This prediction was independent of human bias because feature extraction was done automatically. However, for more accurate sex determination on a wider scale, further studies with larger sample sizes are desirable."
Sex determination from lateral cephalometric radiographs using an automated deep learning convolutional neural network,2022,"['Sex Determination Analysis', 'Deep Learning', 'Radiography', 'Cephalometry', 'Cervical Vertebrae']",국문 초록 정보 없음,"Purpose: Despite the proliferation of numerous morphometric and anthropometric methods for sex identification based on linear, angular, and regional measurements of various parts of the body, these methods are subject to error due to the observer’s knowledge and expertise. This study aimed to explore the possibility of automated sex determination using convolutional neural networks(CNNs) based on lateral cephalometric radiographs.Materials and Methods: Lateral cephalometric radiographs of 1,476 Iranian subjects (794 women and 682 men) from 18 to 49 years of age were included. Lateral cephalometric radiographs were considered as a network input and output layer including 2 classes(male and female). Eighty percent of the data was used as a training set and the rest as a test set. Hyperparameter tuning of each network was done after preprocessing and data augmentation steps.The predictive performance of different architectures (DenseNet, ResNet, and VGG) was evaluated based on their accuracy in test sets.Results: The CNN based on the DenseNet121 architecture, with an overall accuracy of 90%, had the best predictive power in sex determination. The prediction accuracy of this model was almost equal for men and women.Furthermore, with all architectures, the use of transfer learning improved predictive performance.Conclusion: The results confirmed that a CNN could predict a person’s sex with high accuracy. This prediction was independent of human bias because feature extraction was done automatically. However, for more accurate sex determination on a wider scale, further studies with larger sample sizes are desirable."
Segmentation 기반 샤인머스캣의 포도알 검출 및 충실도 예측 알고리즘 개발,2022,"['Mask R-CNN', 'Object detection', 'Shine Muscat', 'Density of Grape Clusters', 'DGC']","포도는 인체의 탄수화물 대사를 촉진시키며 피로를 풀어주는 등 인체에 유익한 알칼리성 식품으로 알려지며 재배와 소비량이 꾸준히 증가하고 있다. 이 중 샤인머스캣은 포도의 다양한 종류 중 하나로, 일반 포도의 쓴 맛이 덜하고 산도가 낮으며 아삭아삭한 식감을 가지고 있어 특히 관심이 높아지고 있다. 이러한 샤인머스캣 품종의 소비가 급격하게 증가함에 따라 노동력과 시간을 절약하기 위한 자동화 공정 시스템을 구축하는 것이 필수인데, 특히 전문가의 육안으로만 포도의 등급을 판단하는 것은 아직도 해결해야 하는 과제 중 하나이다.본 연구에서는 포도의 종류 중 하나인 샤인머스캣을 대상 과실로 지정하였으며, RGB 영상장치를 이용하여 수확 후의 샤인머스캣을 다양한 조도 조건하에 촬영하여 영상을 획득하였다. 단일 포도송이에서 포도 열매를 검출하는 알고리즘을 채택하였으며 합성곱 신경망 네트워크 기반의 영상 분할 기법인 Mask R-CNN을 다양한 backbone과 함께 적용하여 각 모델의 성능을 비교 평가하였다. 그 결과, Mask R-CNN ResNet 101이 모든 모델 중 검출 정확도 AP(Average Precison)값이 가장 높은 것으로 분석되었으며, 해당 네트워크로 샤인머스캣의 포도알 직경, 면적, 빈 공간의 면적 등을 구하여 포도알이 얼마나 밀집되어 있는지를 나타내는 지표인 Density of Grape Clusters (DGC)를 구하였다. 본 연구에서 정의한 이러한 지표들을 통해 샤인머스캣의 수확 후 품질 판단을 보다 정확하고, 신속하게 체계화할 수 있다.",다국어 초록 정보 없음
인공지능 학습을 통한 벼 작황정보 예측,2022,"['벼', 'AI', '드론', '작황정보', '딥러닝', '알고리즘']","정밀한 농작물 생육상태 진단 및 수확량 예측 분석 모델을 개발을 위해서는 최적화된 분석 모델개발이 필요하다. 확보한 드론 영상으로 농업 공간정보 구축하고 벼 농작물 생육/작황 상태 모니터링 정보를 가시화 기술이 필요하다. 따라서 본 연구에서는 학습용 데이터 기반하에 AI 플랫폼 구축하는데 있다. AI 학습 데이터 구축을 위해 영상전처리 후의 필지단위 타일링 가공 데이터에 작황정보 현장조사 라벨링 데이터를 업로드하였으며 작물 필지와 그 외 지역 구분을 위한 필지 외곽선 추출작업 진행하였다. 테이블 구성 및 이미지 마스킹에 대한 메타정보를 입력하였다. 작물 및 재배면적 판독을 위한 학습 데이터 구축을 위해 각 재배/수확필지를 구분하여 태깅하였다. 인공지능 데이터 구축에서는 75 : 25 로 비율의 Train set으로 진행하였다. 드론 영상은 일정 크기인 512 x 512픽셀로 그리드 분할하고, 태깅된 데이터는 마스킹 이미지로 변환하여 그리드 분할하였다. 그리드 분할된 이미지와 마스킹 이미지는 학습과 테스트를 위한 데이터로 75 :25 의 비율로 분리하였다.AI 알고리즘을 활용한 농작물 생육상태 진단 및 품질, 수확량 예측 분석 모델 선정하였으며, 최적 분석모델 개발을 위한 Classification & Segmentation + Regression Analysis 모델을 적용하였다. 알고리즘을 바탕으로 선정된 벼 농작물 판독 및 인식 모델인 U-Net 모델 개발을 완료하였다. 딥러닝 기술 기반의 이미지 분할기술 중 Semantic Segmentation 기술을 활용하여 이미지 분할 방법 적용하여 농작물(벼)판독 및 재배면적 산출하였다. 선정된 작물의 품질 및 수확량 예측을 위한 추론 모델인 RESNET 모델을 개발할 예정에 있다.",다국어 초록 정보 없음
CNN 아키텍쳐 기반 인공 고관절 판독 모델 성능 비교 연구,2022,"['THRA', 'Medical image processing field', 'Patient information', 'Anonymization', 'Binarization work', 'CNN-based architecture']","최근, 고관절 전치환술의 진행에 있어, 제조사마다 규격이 다른 인공관절의 특성으로 인해 과거에 삽입했던 제품과 호환되는 제품을 반드시 사용해야 하는 고질적인 문제점이 있다. 이런 문제를 해결하기 위해 집도의는 수술에 들어가기 전에 X-Ray이미지를 보고 경험치료를 바탕으로 가장 비슷한 인공 보철물을 준비한다. 이러한 준비 과정은 의사의 경험에 따라 오차가 발생할 위험이 있다. 이에 따라 전 세계의 많은 고관절 인공 보철물 제조사는 자사의 데이터를 활용하여 인공 보철물 제품군의 이미지 판독 시스템의 개발이 활발히 이루어지고 있는 추세이다. 따라서 본 연구는 의료영상처리분야에서 시각 정보에 기반한 고차원적 추상화를 통한 병변 진단 및 예후 예측에 뛰어나 성능을 보이는 CNN(Convolutional Neural Network)기반의 다양한 아키텍처 모델들의 성능을 비교한다. 연구방법은 다음과 같다. 국내 유일의 인공고관절 제조업체인 ㈜코렌텍에서 제공한 자사 제품이 사용된 X-Ray 이미지와 Kaggle 데이터셋 ‘Aseptic Loose Hip Implant X-Ray Database’을 활용한다. 이때 사용되는 X-Ray 이미지는 환자 정보에 대한 비식별화가 된 상태이다. 습득한 X-Ray 이미지는 인공 보철물이 나타난 부분을 뜯어내 배경을 제거한 후 이진화 작업, 특정 영역 외 객체 제거, 이미지 반전 등 데이터 전처리 작업을 거치고, 전처리된 데이터셋을 이진 분류모델에 맞게 변환한다. 이후 CNN기반의 다양한 아키텍처 모델에 적용하여 각 모델에 대한 성능을 비교한다. 성능비교에 사용한 CNN기반 모델은 CNN, VGG16, GoogLe Net/Inception Net, Xception Net, Mobile Net, ResNet 총 6개이며, 각 모델에 대한 특징과 연결점에 대해 설명한다.",다국어 초록 정보 없음
