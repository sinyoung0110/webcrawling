title,date,keywords,abstract,multilingual_abstract
YOLO-v5를 이용한 등검은말벌집 탐색 기술 연구,2022,"['Artificial intelligence', 'Vespa velutina nest', 'Detection']",,"Vespa velutina, such as ecological disturbance wildlife introduced into Busan through Shanghai, China in 2003, is an ecologicla disturbance wildlife and difficult to find with the naked eye due to the nature of creating wasp nests in high places in the forest. In addition, its population increases every year, causing the economical damage to beekiipers (about 170 billion won).Therefore, the purpose of this study is to acquire images and explore the location of Vespa velutina based on artificial intelligence (AI) to easily remove Vespa velutina using drones.Differently from the ground images, aerial images have the characteristic that the objects become very small as the altitude rises, so it is necessary to study the appropriate image size that can be mounted on drones and can search Vespa velutina with AI. The AI model YOLO-v5 using four image sizes (640×384 px, 1,280×736, 1,920×1,088, 3,840×2,176) was applied in this study and the original size of the image (3,840×2,160) was used for learining and verification.When confidence was higher than 0.7, F1 score of YOLO-v5s-default (640) learned with image size 640×384 was 2.4%, YOLO-v5s-1280 was 36.5%, YOLO-v5s-1920 was 64.2% and YOLOv5s- 3840 obtained the best detection performance at 96.1%. In addition, the performance was confirmed when the verification image size was 3,840×2,176 in four AI learned with different image sizes. In this case, YOLO-v5s-default (640) had F1 score of 4.4%, YOLO-v5s-1280 was 7.1% and YOLO-v5s-1920 was 16.4% with no performance improvement. Therefore, this study found that the networks that are learned and validated using the aerial images larger than 640 showed the better performance. Continuous research on real-time information sharing and estimation of the location of the occurrence of Vespa velutina through data collection using drone systems will be carried out."
실내 방범 로봇에서 YOLO와 VMD를 활용한 실내 침입자 탐지,2022,"['Intruder detection', 'Autonomous robots', 'Motion detection']",,"Today, security has become an important issue in all areas of life. Recently, the intruder response method is changing to using CCTV or thermal imaging equipment to search for intruders with a small number of people and respond to security companies when they are caught. However, the fixed CCTV has the disadvantage that it can respond to intrusions only in a limited area and there may be blind spots.Therefore, in this paper, we propose an indoor intruder detection system through YOLO and VMD based on an indoor crime prevention robot capable of autonomous driving to solve the shortcomings of the existing fixed CCTV. The autonomous driving of the robot proceeds by sequentially moving the coordinates designated by the manager through the multi-point cruise function. Using the YOLO v3 Tiny model that can be used even in low-spec environments among various YOLO models, if an object corresponding to the Person class is detected, it is determined as the first intruder detection. VMD detects the movement of an object by comparing the three frames, and when a movement is detected, it is finally determined as an intruder. An experiment was conducted to compare the mAP and FPS of YOLO v3 and YOLO v3 Tiny, and it was confirmed that the FPS of YOLO v3 Tiny was 223, far superior to YOLO v3."
YOLO에 기반한 유해 야생동물 피해방지 및 퇴치 시스템 구현,2022,"['Wild animals', 'AI-based image analysis', 'YOLO(You Only Look Once', 'High-luminance LEDs', 'Ultrasonic Frequency Speakers', '야생동물', 'AI기반 영상분석', 'YOLO', '고휘도 LED', '초음파 스피커']","해마다 야생동물이 인간의 거주지에 출몰하는 횟수가 증가하여 재산 및 인명 피해가 증가하고 있다. 특히, 고속도로나 농가에 야생동물이 출몰하는 경우에 그 피해가 더 심하다. 이런 문제점을 해결하기 위해 고속도로에는 생태통로와 유도펜스를 설치하였다. 또한, 농가에서도 문제를 해결하기 위해 센서를 이용한 경적 퇴치기, 그물망 설치, 배설물로 퇴치 하는 등방법을 쓰고 있으나 고가의 비용이 들며 그 효과가 높지 않다. 본 논문에서는 AI 기반 영상분석 방법인 YOLO(You Only Live Once)를 이용하여 유해동물을 실시간 분석하여 오작동을 줄였고, 퇴치장치로 고휘도 LED와 초음파 주파수 스피커를 이용였다. 스피커는 동물들만 들을 수 있는 가청주파수를 출력하여 야생동물만 퇴치하도록 효율성을 높였다. 제안하는 시스템은, 경제적으로 설치할 수 있도록 범용 보드를 사용하여 설계되어 있으며 기존의 센서를 이용한 장치들보다 감지 성능이 높다.","Every year, the number of wild animals appearing in human settlements increases, resulting in increased damage to property and human life. In particular, the damage is more severe when wild animals appear on highways or farmhouses. To solve this problem, ecological pathways and guide fences are being installed on highways. In addition, in order to solve the problem in farms, horn repelling using sensors, installing a net, and repelling by smell of excrement are being used. However, these methods are expensive and their effectiveness is not high. In this paper, we used YOLO (You Only Look Once), an AI-based image analysis method, to analyze harmful animals in real time to reduce malfunctions, and high-brightness LEDs and ultrasonic frequency speakers were used as extermination devices. The speaker outputs an audible frequency that only animals can hear, increasing the efficiency to only exterminate wild animals. The proposed system is designed using a general-purpose board so that it can be installed economically, and the detection performance is higher than that of the devices using the existing sensor."
카메라 영상의 기하학적 해석을 통한 YOLO 알고리즘 기반 해상물체탐지시스템 개발에 관한 연구,2022,"['자율운항선박', '물표탐지', 'YOLO', '기하학', '카메라 캘리브레이션', 'Autonomous ship', 'Object detection', 'YOLO', 'Geometry', 'Camera calibration']","자율운항선박이 상용화되어 연안을 항해하기 위해서는 해상의 장애물을 탐지할 수 있어야 한다. 연안에서 가장 많이 볼 수 있는 장애물 중의 하나는 양식장의 부표이다. 이에 본 연구에서는 YOLO 알고리즘을 이용하여 해상의 부표를 탐지하고, 카메라 영상의 기하학적 해석을 통해 선박으로부터 떨어진 부표의 거리와 방위를 계산하여 장애물을 시각화하는 해상물체탐지시스템을 개발하였다. 1,224장의 양식장 부표 사진으로 해양물체탐지모델을 훈련시킨 결과, 모델의 Precision은 89.0%, Recall은 95.0% 그리고 F1-score는 92.0%이었다. 얻어진 영상좌표를 이용하여 카메라로부터 떨어진 물체의 거리와 방위를 계산하기 위해 카메라 캘리브레이션을 실시하고 해상물체탐지시스템의 성능을 검증하기 위해 Experiment A, B를 설계하였다. 해상물체탐지시스템의 성능을 검증한 결과 해상물체탐지시스템이 레이더보다 근거리 탐지 능력이 뛰어나서 레이더와 더불어 항행보조장비로 사용이 가능할 것으로 판단된다.","For autonomous ships to be commercialized and be able to navigate in coastal water, they must be able to detect maritime obstacles. One of the most common obstacles seen in coastal area are the farm buoys. In this study, a maritime object detection system was developed that detects buoys using the YOLO algorithm and visualizes the distance and bearing between buoys and the ship through geometric interpretation of camera images. After training the maritime object detection model with 1,224 pictures of buoys, the precision of the model was 89.0%, the recall was 95.0%, and the F1-score was 92.0%. Camera calibration had been conducted to calculate the distance and bearing of an object away from the camera using the obtained image coordinates and Experiment A and B were designed to verify the performance of the maritime object detection system. As a result of verifying the performance of the maritime object detection system, it can be seen that the maritime object detection system is superior to radar in its short-distance detection capability, so that it can be used as a navigational aid along with the radar."
NRP-Sys: YOLO 기반 동일 물체 분리 검출을 위한 비선형 회귀 예측 시스템,2022,"['deep learning', 'object detection', 'regression', 'prediction', 'YOLO', '.']","최근 4차 산업혁명이 가속됨에 따라 딥러닝은 제조업과의 융합이 두드러지고 있다. 제조업의 공정 과정은 대부분 수동적인 작업으로 이루어지고 있고 숙련된 작업자에 의존도가 매우 높다. 그로 인해 사람에 의한 실수나 오류 때문에 작업의 속도와 생산성이 저하되고 있다. 이러한 실수를 보완하기 위해서 딥러닝의 기술을 접목하여 개선을 할 수 있다. 본 논문에서는 YOLO 기반 철근 끝점 인식 및 추적을 통한 자동 철근 교정 작업을 하는 철근 끝점 예측 검출 모델 NRP-Sys(Nonlinear Regression Prediction System)를 제안한다. 비전 카메라로부터 철근 끝점 검출 및 추적을 수행한다. 이를 통해 수집한 좌표 정보를 회귀 분석 중 급격한 변화에 덜 민감한 2차 회귀 함수로 끝점 위치를 예측한다. 제안하는 방법은 둘 이상의 끝점의 시작점을 설정하여 위치를 분리하고 각각을 예측하는 방법으로 예측값과 실제값을 비교하여 out-cell의 평균 정확도 94.51%, in-cell의 평균 정확도 95.53%를 보인다.","As the 4th Industrial Revolution accelerates recently, convergence with the manufacturing industry is emerging. Most of the manufacturing process processes are passive and highly dependent on skilled workers. As a result, the speed and productivity of work are deteriorating due to human mistakes or errors. In order to compensate for these mistakes, improvement can be made by combining deep learning technology. In this paper, we propose a reinforcement endpoint prediction detection model NRP-Sys(Nonlinear Regression Prediction System) that automatically corrects rebar through YOLO-based reinforcement endpoint recognition and tracking. The reinforcement endpoint is detected and tracked from the vision camera. Through this, the location of the endpoint is predicted with a quadratic regression function that is less sensitive to rapid changes during regression analysis. The proposed method shows 94.51% average accuracy of out-cell and 95.53% average accuracy of In-cell by comparing the predicted and actual values by setting the starting point of two or more endpoints to separate locations and predicting each."
YOLO 기반 금속 외관 결함영역 검출,2022,"['금속 외관', '결함 검출', '객체 검출', '합성곱신경망', '딥러닝', 'Metal Surface', 'Detection of Defects', 'Object Detection', 'Convolution Neural Network', 'Deep Learning']","최근 다양한 분야에 딥러닝 기술이 도입되었고, 특히 영상 처리에 특화된 합성곱신경망(CNN: Convolutional Neural Network)이 많이 활용되고 있다. 금속 외관의 결함영역을 검출하는 많은 응용 분야(예를 들어, 스마트 제조 및 스마트팩토리 분야)에서도 합성곱신경망을 활용한 연구가 활발하게 이루어지고 있다. 본 논문에서는 합성곱신경망 기반 객체 검출(Object Detection) 알고리즘 중 하나인 YOLOv4(YOLO 알고리즘의 4번째 버전)를 활용하여 금속 외관의 결함영역을 검출하는 연구를 수행하고자 한다. 특히, 본 논문에서는YOLOv4 네트워크 구조에 여러 후처리 기법들과 전이 학습을 적용하여 향상된 검출 성능을달성하는 방안을 제안한다. 두 가지 종류의 학습데이터셋((i)공용 데이터셋과 (ii)실측 데이터셋)에 대한 실험을 통해 제안한 방법의 성능을 검증하고 분석한다. 또한 성능 검증을 통해공용 데이터셋과 실측 데이터셋에서의 후처리 기법 및 전이학습에 대한 최적의 조합을 도출하였다.",
Yolo-v4 기반 초저지연 차량 식별과 통행량 추적 정밀도 개선,2022,"['cooperative driving infra sensor', 'deep learning', 'object detection', 'object tracking', 'self driving', '협력주행 인프라 센서', '딥러닝', '객체 검출', '객체 추적', '자율주행']","자율주행 기술의 고도화 및 상용화에 따라 차량 자체 센서의 인지 범위의 확장을 위한 인프라 기반 협력주행기술에 대한 수요가 증가하고 있다. 특히 노변에 설치되어 교통 상황을 실시간으로 파악하고 기록하여 차량에 제공할 수 있는 엣지 인프라 기술 연구가 활발하게 진행되고 있으며, 정보 수집을 위한 센서에 대한 연구가 활발한 상황이다. 이러한 흐름에 따라, 최근 CNN 기반의 영상분석을 통한 교통정보 수집 기술에 대한 연구도 활발히 진행되고 있는데, 이러한 CNN 기반의 알고리즘은 영상 내의 외양 특징을 기반으로 개별 객체를 식별할 수 있어 자율주행 자동차에서 인식하지 못하는 도로상의 객체 정보를 제공할 수 있어 인프라 구축에 활용이 가능할 것으로 주목받고 있다. 하지만 기존 C-ITS 사업 대부분은 딥러닝 알고리즘의 높은 요구 연산량으로 인하여 영상분석을 현장이 아닌 센터의 높은 사양 서버에서 처리하고 있는데, 이는 인프라 시스템에서의 정보 제공 지연에 따른 사고의 발생 위험을 증대시킬 위험이 있다. 따라서 이러한 위험을 최소화하기 위해서는 센터가 아닌 노변에서의 실시간 영상분석을 통해 통신 지연을 최소화할 필요가 있다. 본 연구에서는 노변에 위치하여 실시간으로 영상을 분석하여 도로에 위치한 객체 정보를 산출할 수 있는 차량검지 시스템을 설계하였으며, 알고리즘의 노변 환경 적용을 위해 신경망의 구성을 간소화하여 딥러닝 연산량을 줄일 수 있는 방법을 제시한다.",
유통과정 작물의 질병 분류를 위한 YOLO 기반 객체탐지,2022,"['crop disease detection', 'computer vision', 'object detection']",,"Most agricultural products in South Korea are cultivated in the open field and delivered to customers through the distribution channels. It is important to ensure that crops are not susceptible to pests and diseases during delivery. In this paper, we propose to detect diseases of crops in earlier time by using YOLOv4, which is a real-time object detection algorithm, to ensure the freshness of crops. We compared the proposed detector with the YOLOv3-based detector in terms of the accurate performance. The experimental results addressed that the proposed method clearly detects the types and stages of chili pepper diseases. We expect that the proposed approach can be used for a fast and accurate freshness monitoring system."
Yolo V4 딥러닝 지능기술을 이용한 과일 불량 부위 검출,2022,"['automatic fruit quality screening system', 'fruit’s defective area detection', 'image processing                     technique', 'yolo v4', 'deep learning intelligent technology', '과일 품질 선별시스템', '과일 불량부위 검출', '영상처리 기법', 'Yolo V4', '딥러닝 지능 기술']","과일 품질 자동 선별 시스템에서 흠집이나 부패한 부위가 존재하는 불량 과일을 우선적으로 검출하여 제거하는 작업은 매우 중요하다. 본 연구에서는 기존의 영상처리 기법을 이용하여 불량 부위가 있는 과일 검출하는 방법의 한계점을 극복하기 위하여, 최신 인공지능 기술인 Yolo V4 딥러닝 지능기술을 이용하여 과일 불량 부위를 검출하는 방법을 제안한다. 본 연구에서는 흠집 또는 부패 부위가 존재하는 1,100개의 불량 사과 및 1,300개의 불량 배를 포함한 총 2,400개의 불량 과일에 대하여 Yolo V4 딥러닝 모델을 사용하여 학습하고 불량 부위 검출 실험을 하였다. 성능 실험 결과에 따르면 사과의 정확률은 0.80, 재현율은 0.76,  IoU는 69.92%, mAP는 65.27%이고, 배의 정확률은 0.86, 재현율은 0.81,  IoU는 70.54%, mAP는 68.75%의 성능을 나타내었다. 본 연구에서 제안한 방법은 기존 영상처리 기법을 이용한 방법보다 불량 부위가 있는 과일을 실시간으로 정확하게 선별하여 기존 과일 자동 품질 선별시스템의 성능을 획기적으로 개선할 수 있다.","It is very important to first detect and remove defective fruits with scratches or bruised areas in the automatic fruit quality screening system. This paper proposes a method of detecting defective areas in fruits using the latest artificial intelligence technology, the Yolo V4 deep learning model in order to overcome the limitations of the method of detecting fruit’s defective areas using the existing image processing techniques. In this study, a total of 2,400 defective fruits, including 1,000 defective apples and 1,400 defective fruits with scratch or decayed areas, were learned using the Yolo V4 deep learning model and experiments were conducted to detect defective areas. As a result of the performance test, the precision of apples is 0.80, recall is 0.76, IoU is 69.92% and mAP is 65.27%. The precision of pears is 0.86, recall is 0.81, IoU is 70.54% and mAP is 68.75%. The method proposed in this study can dramatically improve the performance of the existing automatic fruit quality screening system by accurately selecting fruits with defective areas in real time rather than using the existing image processing techniques."
"YOLO, EAST: 신경망 모델을 이용한문자열 위치 검출 성능 비교",2022,"['문자열 탐지', 'YOLO', 'EAST', '신경망', 'Scene Text Detection', 'YOLO', 'EAST', 'Neural Network']",,"In this paper, YOLO and EAST models are tested to analyze their performance in text area detecting for real-world and normal textimages. The earl ier YOLO models which include YOLOv3 have been known to underperform in detecting text areas for given images,but the recently released YOLOv4 and YOLOv5 achieved promising performances to detect text area included in various images.Experimental results show that both of YOLO v4 and v5 models are expected to be widely used for text detection in the filed of scenetext recognition in the future."
YOLO 알고리즘 기반 국토위성영상의 선박 모니터링 가능성 평가 연구: 부산 신항과 캘리포니아 오클랜드항을 대상으로,2022,"['Ship detection', 'Ship classification', 'CAS500-1', 'KOMPSAT-3', 'AIS', 'YOLO']",,"Maritime transport accounts for 99.7% of the exports and imports of the Republic of Korea; therefore, developing a vessel monitoring system for efficient operation is of significant interest. Several studies have focused on tracking and monitoring vessel movements based on automatic identification system (AIS) data; however, ships without AIS have limited monitoring and tracking ability. High-resolution optical satellite images can provide the missing layer of information in AIS-based monitoring systems because they can identify non-AIS vessels and small ships over a wide range. Therefore, it is necessary to investigate vessel monitoring and small vessel classification systems using high-resolution optical satellite images. This study examined the possibility of developing ship monitoring systems using Compact Advanced Satellite 500-1 (CAS500-1) satellite images by first training a deep learning model using satellite image data and then performing detection in other images. To determine the effectiveness of the proposed method, the learning data was acquired from ships in the Yellow Sea and its major ports, and the detection model was established using the You Only Look Once (YOLO) algorithm. The ship detection performance was evaluated for a domestic and an international port. The results obtained using the detection model in ships in the anchorage and berth areas were compared with the ship classification information obtained using AIS, and an accuracy of 85.5% and 70% was achieved using domestic and international classification models, respectively. The results indicate that high-resolution satellite images can be used in mooring ships for vessel monitoring. The developed approach can potentially be used in vessel tracking and monitoring systems at major ports around the world if the accuracy of the detection model is improved through continuous learning data construction."
YOLO v2를 이용한 고해상도 항공영상에서의 태양광발전소 탐지 방법 연구,2022,"['Deep learning', 'Solar power plant', 'Land-use', 'Aerial Image', 'YOLO v2']",,"As part of strengthening energy security and responding to climate change, the government has promoted various renewable energy measures to increase the development of renewable energy facilities. As a result, small-scale solar installations in rural areas have increased rapidly. The number of complaints from local residents is increasing. Therefore, in this study, deep learning technology is applied to high-resolution aerial images on the internet to detect solar power plants installed in rural areas to determine whether or not solar power plants are installed. Specifically, I examined the solar facility detector generated by training the YOLO(You Only Look Once) v2 object detector and looked at its usability. As a result, about 800 pieces of training data showed a high object detection rate of 93%. By constructing such an object detection model, it is expected that it can be utilized for land use monitoring in rural areas, and it can be utilized as a spatial data construction plan for rural areas using technology for detecting small-scale agricultural facilities."
딥러닝 모델에서 포트홀 데이터셋의 성능 향상을 위한 전처리 방법 제안과 YOLO 모델을 통한 검증,2022,"['포트홀 탐지', '전처리', 'YOLO', 'Superpixel', 'Sobel Edge detection', 'Intensity transformation', 'Pothole detection', 'Pre-processing', 'YOLO', 'Superpixel', 'Sobel edge detection', 'Intensity transformation']","포트홀은 아스팔트 포장도로의 구조적 결함을 나타내는 중요한 단서임과 동시에 많은 인명 피해와 재산 피해를 일으킨다. 따라서 정확한 포트홀 탐지는 도로 표면의 유지보수에 있어서 중요한 과제이다. 포트홀 탐지를 위해 많은 머신러닝 기술이 도입되고 있으며 딥러닝 모델의 효율성을 높이기 위해 데이터 전처리가 필요하다. 본 논문에서는 포트홀 데이터셋에서 중요한 질감과 형태를 강조하는 전처리 방법을 제안한다. 제안된 전처리 방법은 Intensity transformation을 사용해 도로의 불필요한 요소를 줄이고 포트홀의 질감과 형태를 부각한다. 또한 Superpixel, Sobel edge detection을 사용해 포트홀의 특징을 검출한다. 제안된 전처리 방법과 기존의 전처리 방법의 성능 비교를 통해 포트홀 검출에서 제안된 전처리 방법이 기존 방법보다 더 효과적인 방법이라는 것을 보여준다.","Potholes are an important clue to the structural defects of asphalt pavement and cause many casualties and property damage. Therefore, accurate pothole detection is an important task in road surface maintenance. Many machine learning technologies are being introduced for pothole detection, and data preprocessing is required to increase the efficiency of deep learning models. In this paper, we propose a preprocessing method that emphasizes important textures and shapes in pothole datasets. The proposed preprocessing method uses intensity transformation to reduce unnecessary elements of the road and emphasize the texture and shape of the pothole. In addition, the feature of the porthole is detected using Superpixel and Sobel edge detection. Through performance comparison between the proposed preprocessing method and the existing preprocessing method, it is shown that the proposed preprocessing method is a more effective method than the existing method in detecting potholes."
Non-Local Means 잡음 제거와 데이터 증강을 이용한 YOLO 기반 객체 특징 탐색,2022,"['Denoising', 'Crawling', 'Augmentation', 'Object Detection', 'YOLOv3', 'Smart Farms', 'Deep Learning', 'Data Analysis']",,"When fruits are harvested in farms, most of them go through a manual sorting process and classify and distribute decomposed fruits.However, there is a limit to manually classifying large amounts in a situation where the number of workers is decreasing in farms.To solve this problem, it is important to divide normal and decomposed fruits in real time to minimize the proportion of manpower used in the screening process. We propose a method of YOLO based Object Features Detection Using Non-Local Means Denoising and Data Augmentation. The proposed method collects desired data through the Crawling method, and the preprocessing minimizes image noise through Non-Local Means Denoising. The built image dataset uses YOLOv3, an object detection algorithm, to distinguish and detect normal and decayed fruits. As a result of performance evaluation, object detection of YOLOv3 objects in a proposed method rather than detection results shows that Recall increases 10% performance and increases 9% in the remaining Recall and IoU. Therefore, the proposed method can increase screening efficiency by detecting decayed fruits well."
욜로(YOLO)족의 체험관광이 관광만족과 행동의도에 미치는 영향: 실존적 진정성 조절효과를 중심으로,2022,"['You Only Live Once', 'Existential authenticity', 'Tourist Satisfaction', 'Behavioral Intention)', '욜로', '실존적 진정성', '관광만족', '행동의도']",,"The purpose of this study is to conduct an empirical analysis regarding the effect of experiential tourism on tourism satisfaction and behavioral intention, and the effect of controlling existential authenticity. In order to collect the data of this study, a survey was conducted on those who have traveled domestically and abroad for the past year, and thought of themselves to be YOLO even amongst COVID-19 social distancing measures. As a result of this study, experiential tourism was found to have a significant effect on tourism satisfaction. However, that deviant factors did not have a significant effect. In addition, as a result of verifying the effect of experiential tourism on behavioral intention and the effect of tourism satisfaction on behavioral intention, significant results were found. Finally, according to the results of the analysis of the authenticity control effect, it was found that all experiential tourism had a statistically significant effect on tourism satisfaction."
YOLO 네트워크를 사용한 다중 차선 인식,2022,"['자율주행 차량', '다중 차선 인식', '욜로', 'Autonomous vehichle', 'Multi-Lanes recognition', 'YOLO']",,"Future autonomous vehicles need to recognize the ego lanes required for lane change and the side left and right lanes differently. Therefore, multi-lane recognition is needed. In this study, using the YOLO network, mainly used for object recognition, the proposed method recognizes the ego, left and right side lanes as different objects and identifies the correct lanes. As a result of the performance evaluation on the TuSimple test data, the proposed method recognized the ego lanes and the left and right side lanes differently. It showed very stable lane recognition results. And by detecting lanes that do not exist in the ground truth of TuSimple data, the proposed method is very robust in lanes detection. Nevertheless, studies related to learning data reinforcement in which lanes are located in the center or at the left and right edges of the image and accurate network learning for lanes are needed."
Dynamic Beehive Detection and Tracking System Based on YOLO V5 and Unmanned Aerial Vehicle,2022,"['Automatic control', 'Beehive', 'Edge computing', 'Object detection', 'YOLO']",,"Purpose With urban development and improvements in human living conditions, wild beehives in densely populated areas present a threat to human safety. The traditional manual method of clear beehives may result in secondary injury to humans.Methods This paper proposes a beehive detection model based on YOLO V5 by introducing the Shufe Block V2 and depthwise separable convolution (DSC) modules to decrease the original model parameters. The model can be deployed on edge computation devices such as Raspberry 4B with good detection accuracy. The PID algorithm and dual servo motors were combined with the object detection model to track the beehive automatically. The results of experiments showed that the inference speed of the improved beehive detection model was 92.5% faster than the original YOLO V5s model, although the detection accuracy and other indicators were not signifcantly diferent.Results The accuracy of the system in this study was as high as 96% in real-time detection, and the maximum recognition distance was 2.5 m. The performance test results of the system deployed on an unmanned aerial vehicle (UAV) showed that 90% of the beehive tracking process could be completed within 2 s, positioning the object in the center of the images collected by the camera. At the same time, when the UAV was moving at random, the detection and tracking system could still follow the beehive quickly and automatically.Conclusion The detection model and tracking system established in this paper provide important support to reduce the secondary damage to the rescue workers that may occur in beehive governance."
Integrated YOLO and CNN algorithms for Evaluating Degree of Walkway Breakage,2022,"['Walkway', 'YOLO algorithm', 'Image deep learning', 'Breakage detection', 'Walking environment assessment', 'Pedestrian safety', 'Evaluation indicators']",,"The focus of policymaking in Korea has changed from vehicle-centric road environments to people-centric environments. As the importance of walking has increased, the construction of pedestrian paths and interest in pedestrian environments have also increased. However, problem recognition and resolution require considerable time in the event of a problem in a pedestrian path. People with reduced mobility tend to resist changes in roads that they use. Thus, damaged pedestrian paths and obstacles pose a considerable risk and economic loss to transportation. In this study, we aimed to minimize the time and cost required for the evaluation of pedestrian paths by developing an automatic system for determining damage using integrated You Only Look Once (YOLO) and convolutional neural network (CNN) image deep learning algorithms. We constructed a model using image deep learning by dividing the steps into walkway breakage detection and score evaluation according to the degree of breakage. The accuracy of the model was determined to be 92%. In the future, the evaluation of pedestrian path damage is expected to be automated using images and videos, thereby reducing the time required for the detection and restoration of damage."
헬멧 착용 여부 및 쓰러짐 사고 감지를 위한 AI 영상처리와 알람 시스템의 구현,2022,"['Convolutional Neural Network (CNN)', 'YOLO', 'Object detection', 'Deep learning', 'Industrial site', '합성곱 신경망', 'YOLO', '객체 검출', '딥러닝', '산업현장']","본 논문은 실시간 영상 분석을 통해서 산업현장에서 활동하는 여러 근로자의 영상 객체를 추출해 내고, 추출된 이미지로 부터 개별 영상 분석을 통해 헬멧의 착용 여부와 낙상 사고 여부를 확인하는 방법을 구현한다. 근로자의 영상 객체를 탐지하기 위해서 딥러닝 기반 컴퓨터 비전 모델인 YOLO를 사용하였으며, 추출된 이미지를 이용하여 헬멧의 착용여부를 판단하기 위해 따로 5,000장의 다양한 헬멧 학습 데이터 이미지를 만들어서 사용하였다. 또한, 낙상사고 여부를 판단하기 위해서 Mediapipe의 Pose 실시간 신체추적 알고리즘을 사용하여 머리의 위치를 확인하고 움직이는 속도를 계산하여 쓰러짐 여부를 판단하였다. 결과에 신뢰성을 주기위한 방법으로 YOLO의 바운딩 박스의 크기를 구하여 객체의 자세를 유추하는 방법을 추가하고 구현하였다. 최종적으로 관리자에게 알림 서비스를 위하여 텔레그램 API Bot과 Firebase DB 서버를 구현하였다.","This paper presents an implementation of detecting whether a helmet is worn and there is a fall accident through individual image analysis in real-time from extracting the image objects of several workers active in the industrial field. In order to detect image objects of workers, YOLO, a deep learning-based computer vision model, was used, and for whether a helmet is worn or not, the extracted images with 5,000 different helmet learning data images were applied. For whether a fall accident occurred, the position of the head was checked using the Pose real-time body tracking algorithm of Mediapipe, and the movement speed was calculated to determine whether the person fell. In addition, to give reliability to the result of a falling accident, a method to infer the posture of an object by obtaining the size of YOLO's bounding box was proposed and implemented. Finally, Telegram API Bot and Firebase DB server were implemented for notification service to administrators."
딥러닝을 이용한 병징에 최적화된 딸기 병충해 검출 기법,2022,"['데이터 증강', '빅데이터', '스마트팜', 'CNN', 'YOLO', 'big data', 'CNN', 'data augmentation', 'smart farm', 'YOLO']",본 논문은 딥러닝 알고리즘을 이용하여 딸기 영상 데이터의 병충해 존재 여부를 자동으로 검출할 수 있는 서비스 모델을 제안한다. 또한 병징에 특화된 분할 이미지 데이터 세트를 제안하여 딥러닝 모델의 병충해 검출 성능을 향상한다. 딥러닝모델은 CNN 기반 YOLO를 선정하여 기존의 R-CNN 기반 모델의 느린 학습속도와 추론속도를 개선하였다. 병충해 검출 모델을 학습하기 위해 일반적인 데이터 세트와 제안하는 분할 이미지 데이터 세트를 구축하였다. 딥러닝 모델이 일반적인 학습 데이터 세트를 학습했을 때 병충해 검출률은 81.35%이며 병충해 검출 신뢰도는 73.35%이다. 반면 딥러닝 모델이 분할 이미지 학습 데이터 세트를 학습했을 때 병충해 검출률은 91.93%이며 병충해 검출 신뢰도는 83.41%이다. 따라서 분할 이미지 데이터를 학습한 딥러닝 모델의 성능이 우수하다는 것을 증명할 수 있었다.,"This study aimed to develop a service model that uses a deep learning algorithm for detecting diseases and pests in strawberries through image data. In addition, the pest detection performance of deep learning models was further improved by proposing segmented image data sets specialized in disease and pest symptoms. The CNN-based YOLO deep learning model was selected to enhance the existing R-CNN-based model's slow learning speed and inference speed. A general image data set and a proposed segmented image dataset was prepared to train the pest and disease detection model. When the deep learning model was trained with the general training data set, the pest detection rate was 81.35%, and the pest detection reliability was 73.35%. On the other hand, when the deep learning model was trained with the segmented image dataset, the pest detection rate increased to 91.93%, and detection reliability was increased to 83.41%. This study concludes with the possibility of improving the performance of the deep learning model by using a segmented image dataset instead of a general image dataset."
ShortcutFusion++: Optimizing an End-to-End CNN Accelerator for High PE Utilization,2022,"['CNN accelerator', 'Processing element', 'Hardware utilization', 'FPGA', 'YOLO-v3']",,"ShorcutFusion [1] is an end-to-end framework that effectively maps many well-known deep neural networks (DNNs), such as MobileNet-v2, EfficientNet-B0, ResNet-50, and YOLO-v3, to a generic CNN accelerator on FPGA. Nevertheless, its processing elements are not fully utilized when supporting various networks, leading to relatively low hardware utilization (e.g., 68.42% for YOLO-v3). This study aimed to enhance the performance of ShortcutFusion and introduce ShortcutFusion++ by proposing two simple but effective techniques for eliminating unnecessary stalls in conventional design. First, the prefetching scheme was re-designed to avoid bubble cycles when feeding data to the PE array. Second, the output buffer was reconstructed to pipeline the operations of PEs and the process of writing output feature maps to off-chip memory. The experimental results show that ShortcutFusion++ achieves a PE utilization of 80.95% for the wellknown object detection network YOLO-v3, outperforming its baseline by 12.53%."
객체 인식 모델 기반 실시간 교통신호 정보 인식,2022,"['차량 신호 인식', '자율주행', '딥러닝', 'YOLO', '객체탐지', 'Traffic Light Recognition', 'Autonomous Driving', 'Deep Learning', 'YOLO', 'Object Detection']","최근 자율주행 기술에서 차량 주변 객체 인식과 교통표지판 및 차량 신호 인식을 위한 연구가 활발히 수행되고 있으며, 특히 차량 신호 인식은 자율주행 기술에 있어서 핵심 요소로 평가되고 있다. 이에 차량 신호 인식을 위한 다양한 연구가 진행되어 왔으며, 최근에는 딥러닝 기반 객체 인식 모델을 활용한 차량 신호 인식 연구가 크게 증가하고 있다. 또한 AIHub에서 음성, 비전, 자율주행 등을 위한 양질의 국내 인공지능 학습데이터 셋이 공개됨에 따라 이들 데이터를 활용한 국내 환경에 적합한 차량 신호 인식 모델의 개발도 가능하게 되었다. 이에 본 연구에서는 AIHub의 학습데이터와 객체 인식모델 YOLO를 적용한 국내 차량 신호 인식 모델을 개발하였다. 특히 차량 신호의 인식 성능을 개선하기 위하여 YOLOv4와 YOLOv5의 다양한 모델을 적용하였으며 학습데이터의 클래스도 다양하게 분류하여 실험을 수행하였다. 결론적으로 YOLOv5가 YOLOv4보다 차량 신호 인식에 조금 더 적합함을 확인할 수 있었으며, 두 모델의 아키텍처 비교를 통하여 YOLOv5 성능이 우수한 이유를 확인할 수 있었다.",
시각 장애인의 보행 보조를 위한 점자블록 인식 정확도 향상 방안: YOLOv5와 꼭짓점 좌표 분석 활용,2022,"['시각 장애인', '보행 보조', '점자블록', 'YOLO', '꼭짓점', 'visually impaired', 'walking assistance', 'braille block', 'YOLO', 'vertices']","본 논문에서는 시각장애인의 보행에 도움을 주기 위하여 점자블록을 하나의 카메라로 정확하게 인식할 수 있는 정확도 향상 방안을 제안한다. 본 논문은 YOLO와 이진화 처리, 꼭짓점 검출 알고리즘을 조합하여 점자블록을 실시간 검출하여 관심 영역을 추출하는 정확도 향상 기법을 제안한다. 추출된 관심 영역을 정확하고 효율적인 이진화 작업을 수행할 수 있도록 프레임마다 유동적인 색상 범위를 설정함으로써 강인한 이진화 처리가 가능하다. 이진화된 영상에서 꼭짓점을 검출한 뒤 꼭짓점의 개수와 매칭되는 테이블 정보에 따라 점자블록 상태를 판단한다. 실험 결과, 이전 기존 연구보다 정확한 점자블록 패턴 정보를 제공하며, 성능이 가장 우수하게 나타났다. 본 논문에서 제안한 점자블록 인식 기술을 활용하면, 시각 장애인의 안정적인 보행에 도움을 줄 수 있는 보조 장치 개발에 기여할 수 있을 것이다.",
딥러닝 기반 알고리즘을 활용한 산불 객체 탐지,2022,"['딥러닝', '객체 검출', '분류', '욜로', '산림', '화재', 'Deep Learning', 'Object Detection', 'Classification', 'YOLO', 'Forest', 'Fire']","우리는 산불로 인한 피해로 직, 간접적인 피해를 받고 있는데 피해를 줄이기 위해서는 초기에 산불을 검출하는 것이 중요하다. 기존 산불 검출 방법으로는 촬영 이미지를 영상처리 기술을 통해 감지하거나 센서를 일정 구간별로 설치하여 모니터링하는 방법을 사용했다. 본 논문은 유지비용이 많이 들어가는 기존 방법을 개선하기 위해 객체 탐지 인공지능 기술, YOLO를 사용하여 객체 검출을 하고 인공지능 모델을 통해 나온 검출 결과를 제공하는 시스템 구현을 진행한다. 연구 결과 주요 성능지표인 mAP가 Proposed LFire 0.959, YOLOv5 0.931, YOLOv4 0.943, R-CNN 0.879가 나왔다. 본 논문에서 제안하는 모델인 Proposed LFire가 가장 높은 것을 통해 산불 검출 데이터에 적합한 객체 검출모델로 볼 수 있다. 향후 보편적으로 사용할 수 있는 RGB 채널 산림 이미지 특징에 맞는 이미지 전처리 및 모델 학습을 통해 검출 성능을 높이는 방향으로 연구할 계획이다.","We are suffering direct and indirect damage from forest fires, and it is essential to detect them early to reduce the damage. Existing forest fire detection methods used a method of detecting photographed images through image processing technology or installing sensors at certain intervals to monitor them. To improve the existing process that is expensive to maintain, this paper conducts object detection using object detection artificial intelligence technology, YOLO. It implements a system that provides detection results from artificial intelligence models. As a result of the study, the main performance indicators, mAP, were Proposed LFire 0.959, YOLOv5 0.931, YOLOv4 0.943, and R-CNN 0.879. The proposed model in this paper, Proposed LFire, is the highest, which can be seen as an object detection model suitable for forest fire detection data. In the future, we plan to study in the direction of increasing detection performance through image preprocessing and model learning suitable for RGB channel forest image features that can be used universally."
엣지 컴퓨팅 환경에서 적용 가능한 딥러닝 기반 라벨 검사 시스템 구현,2022,"['Edge-Computing System', 'Deep Learning', 'Machine Vision', 'Vision Inspection', 'Object Detection']",,"In this paper, the two-stage object detection approach is proposed to implement a deep learning-based label inspection system on edge computing environments. Since the label printed on the products during the production process contains important information related to the product, it is significantly to check the label information is correct. The proposed system uses the lightweight deep learning model that able to employ in the low-performance edge computing devices, and the two-stage object detection approach is applied to compensate for the low accuracy relatively. The proposed Two-Stage object detection approach consists of two object detection networks, Label Area Detection Network and Character Detection Network. Label Area Detection Network finds the label area in the product image, and Character Detection Network detects the words in the label area. Using this approach, we can detect characters precise even with a lightweight deep learning models. The SF-YOLO model applied in the proposed system is the YOLO-based lightweight object detection network designed for edge computing devices. This model showed up to 2 times faster processing time and a considerable improvement in accuracy, compared to other YOLO-based lightweight models such as YOLOv3-tiny and YOLOv4-tiny. Also since the amount of computation is low, it can be easily applied in edge computing environments."
딥러닝 기반 객체 인식을 통한 철계 열처리 부품의 인지에 관한 연구,2022,"['Heat Treatment', 'Object Detection', 'Transfer Learning', 'Real-Time', 'Deep Learning']",,"In this study, a model for automatically recognizing several steel parts through a camera before charging materials was developed under the assumption that the temperature distribution in the pre-air atmosphere was known. For model development, datasets were collected in random environments and factories. In this study, the YOLO-v5 model, which is a YOLO model with strengths in real-time detection in the field of object detection, was used, and the disadvantages of taking a lot of time to collect images and learning models was solved through the transfer learning methods. The performance evaluation results of the derived model showed excellent performance of 0.927 based on mAP 0.5. The derived model will be applied to the model development study, which uses the model to accurately recognize the material and then match it with the temperature distribution in the atmosphere to determine whether the material layout is suitable before charging materials."
공공 다중CCTV 기반에서 재식별 기술을 활용한 특정대상 탐지 및 추적기법 구현,2022,"['AI', 'Deep Learning', 'Re-identification', 'Algorithm', 'CCTV']","정부에서는 전국에 설치된 공공 CCTV를 이용하여 실종아동 등 범죄 예방을 위하여 많은 노력을 하고 있다.하지만, 운용인력의 부족과 장시간 집중에 따른 집중력 약화 그리고 추적의 어려움 등이 나타나고 있다. 또한, 딥러닝알고리즘을 통하여 실시간 객체 탐색 및 재인식 그리고 추적을 적용하는 것은 복잡한 신경망 분석의 사유로 파라미터가증가하고 속도감소 메모리 부족이라는 현상을 나타냈다. 본 논문에서는 실시간 객체 인식이 가능한 Yolo의 적용과Batch 및 TensorRT 기술 적용을 통하여 신경망을 경량화를 통하여 속도 개선 및 메모리 절약이 가능하도록 설계하였다. 이 논문에서는 이러한 발전된 알고리즘의 연구를 바탕으로 K-reciprocal nearest neighbor 알고리즘, Jaccard distance 비유사도 측정 알고리즘, 산출물 알고리즘 등을 개발하여 공공 CCTV 식별추적시스템 구축을 제시하였다. 그결과, 비교분석을 통한 알고리즘 조합을 통해 공공 다중CCTV환경에서 실시간으로 객체를 인식하고 재식별하여 객체를추적할 수 있는 한국형 공공 추적시스템을 제안하였다.","The government is making great efforts to prevent crimes such as missing children by using public CCTVs. However, there is a shortage of operating manpower, weakening of concentration due to long-term concentration, and difficulty in tracking. In addition, applying real-time object search, re-identification, and tracking through a deep learning algorithm showed a phenomenon of increased parameters and insufficient memory for speed reduction due to complex network analysis. In this paper, we designed the network to improve speed and save memory through the application of Yolo v4, which can recognize real-time objects, and the application of Batch and TensorRT technology. In this thesis, based on the research on these advanced algorithms, OSNet re-ranking and K-reciprocal nearest neighbor for re-identification, Jaccard distance dissimilarity measurement algorithm for correlation, etc.are developed and used in the solution of CCTV national safety identification and tracking system. As a result, we propose a solution that can track objects by recognizing and re-identification objects in real-time within situation of a Korean public multi-CCTV environment through a set of algorithm combinations."
임베디드 보드에서 차량 감지 및 추적을 위한 딥러닝 모델 최적화,2022,"['Vehicle detection', 'Vehicle tracking', 'embedded board', 'SSD', 'MobileNet', 'convolutional neural network', '차량 감지', '차량 추적', '임베디드 보드', 'SSD', 'MobileNet', 'CNN']","본 논문은 임베디드 보드에서 차량을 감지하고 추적하기 위한 딥러닝 모델을 제안한다. 딥러닝이 기존 이미지 처리 방법에서 높은 정확도를 보여주고 있기 때문에 기존 객체 검출기로 거리나 교량에서 차량을 감지할 수 있다. 그러나, 범용 PC를 사용하는 경우 GPU를 사용하여 프로그램을 실시간으로 동작하는 것이 가능하지만, 임베디드 보드에서는 GPU를 사용하기 어렵고 낮은 성능의 CPU를 사용하므로 프로그램의 실시간 처리가 불가능하다. 본 논문에서는 양자화, edge TPU와 같은 방법을 이용해서 에지 컴퓨팅 기반 딥러닝을 이용한 객체 감지의 정확도와 성능 향상을 시도하였다. Yolo와 같은 다른 네트워크보다 MobileNet을기반한 SSDLite가 빠른 추론시간과 높은 정확도를 보여줘 선정했다. SSDMobileNetV2를 객체 감지기로 사용한 DeepSORT로 모델을 학습하여 차량을 추적할 수 있도록 하였다. 본 논문에서는 H6 CPU를 이용하여 자체 제작한 보드를 통해 차량 감지 및 추적을 위한 딥러닝모델의 성능을 확인하였다","This paper proposes a deep learning model to detect and track the vehicle on an embedded device. Since deep learning has achieved high accuracy over the classical image processing method, object detectors can detect vehicles in the street and highway. It can be normal to run the computer detection program with graphic processor unit (GPU) support, but it is challenging to run it on the embedded board with no GPU support and low central processing unit (CPU) performance. This paper focuses on balancing edge-computing-based deep learning object detection's accuracy and performance using additional techniques such as quantization, edge TPU. SSDLite with MobileNet backbone is chosen due to its lighter than other networks but still obtain good performance compare with Yolo. The model was learned with DeepSORT using SSDMobileNetV2 as an object detector so that the vehicle could be tracked. This paper evaluates the performance of deep learning model to detect and track the vehicle through the developed board using H6 CPU."
Pessimism Transformed to Hope:  Applying Transformative Learning  to Assist Young People in Korea,2022,"['Transformative learning', 'church education', 'eschatology', 'pessimism', 'Korean Christianity']",,"This study presents the increasing pessimism of young people in South Korea as they are confronted with societal situations that cause them to be disoriented. Young people’s pessimistic perspectives, attitudes, and responses to societal challenges are found when examining the following terms: Chosun Hell, Spoon Class Theory, and YOLO. Moreover, this study presents that pessimism has penetrated into the church through its neglect of eschatology. Transformative learning theory is a useful tool to address young people’s disoriented dilemmas and provide possible ways for Christian educators to foster them to have transformed perspectives rooted in the Bible. Especially, critical thinking and discourse have their value to enable young people in Korea faced with their particular difficulties to find hope and purpose through God’s Word and His kingdom, become more like Christ, and shine in the midst of all that is happening."
오픈소스 하드웨어와 딥러닝 기반 객체 탐지 알고리즘을 활용한 교내 유동인구 분석,2022,"['Floating Population', 'Deep Learning', 'Remote Sensing', 'Object-Detection', 'OSHW', '유동인구', '딥러닝', '원격탐사', '객체 탐지', '오픈소스 하드웨어']",,"In this study, the floating population survey and analysis of Pukyong National University campus were conducted using images through an object detection algorithm based on the open source hardware Raspberry Pi and deep learning technology. For the study, images were collected for a total of 5 days from May 10th to May 14th using Raspberry Pi. After that, people were detected from the collected images using YOLO3's IMAGEAI and YOLOv5 models, and Haar-like features and HOG models were used for accuracy comparison analysis. As a result of comparison, the smallest floating population was observed on the 10th day, the anniversary of the opening of the school, and the largest floating population was observed on the 12th day for the entrance and the 14th for the exit. If the spatial and temporal scope of the study is expanded, it is expected that more accurate floating population analysis will be possible."
국내 도로 환경에 특화된 자율주행을 위한 멀티카메라 데이터 셋 구축 및 유효성 검증,2022,"['2D Dataset', 'Camera', 'Autonomous driving']",,"Along with the advancement of deep learning technology, securing high-quality dataset for verification of developed technology is emerging as an important issue, and developing robust deep learning models to the domestic road environment is focused by many research groups. Especially, unlike expressways and automobile-only roads, in the complex city driving environment, various dynamic objects such as motorbikes, electric kickboards, large buses/truck, freight cars, pedestrians, and traffic lights are mixed in city road. In this paper, we built our dataset through multi camera-based processing (collection, refinement, and annotation) including the various objects in the city road and estimated quality and validity of our dataset by using YOLO-based model in object detection. Then, quantitative evaluation of our dataset is performed by comparing with the public dataset and qualitative evaluation of it is performed by comparing with experiment results using open platform. We generated our 2D dataset based on annotation rules of KITTI/COCO dataset, and compared the performance with the public dataset using the evaluation rules of KITTI/COCO dataset. As a result of comparison with public dataset, our dataset shows about 3 to 53% higher performance and thus the effectiveness of our dataset was validated."
에지 디바이스를 활용한 실시간 말벌 모니터링  시스템의 설계 및 구현,2022,"['Deep Learning', 'Wasp Monitoring System', 'Edge Device', 'Real-Time Processing']",,"In this paper, an edge-enabled wasps monitoring system based on state of the art deep learning model is proposed to classify wasps species and transmit their information to clients for pest control and ecology research. We utilized and evaluated the lightweight models of YOLOv5, YOLOX, and YOLOv7 series to select the optimal object detection model for wasps. In order to improve the recognition performance of small objects such as wasps, a new tiling method is proposed which can reclassify objects located on boundary area between tiles. Our monitoring system is composed by local GPU-based edge computers, Server, and Web-based reporting system. In our experiment, the YOLOX- nano model showed the highest performance among YOLO-based models above in terms of recall, precision, Fi-score, and mAP@IOUs for our custom test data set. However, even the YOLOX-nano model also requires the tiling process for a better bounding box generation for small objects under the real environment. As a result, the proposed wasps monitoring system showed meaningful efficiency for applying in the field of pest control and ecology research."
A Study on Algorithm Selection and Comparison for Improving the Performance of an  Artificial Intelligence Product Recognition Automatic Payment System,2022,"['Self-Service Technology', 'Automatic payment system', 'Artificial Intelligence', 'Object detection', 'YOLO']",,"This study is to select an optimal object detection algorithm for designing a self-checkout counter to improve the inconvenience of payment systems for products without existing barcodes. To this end, a performance comparison analysis of YOLO v2, Tiny YOLO v2, and the latest YOLO v5 among deep learning-based object detection algorithms was performed to derive results. In this paper, performance comparison was conducted by forming learning data as an example of 'donut' in a bakery store, and the performance result of YOLO v5 was the highest at 96.9% of mAP. Therefore, YOLO v5 was selected as the artificial intelligence object detection algorithm to be applied in this paper. As a result of performance analysis, when the optimal threshold was set for each donut, the precision and reproduction rate of all donuts exceeded 0.85, and the majority of donuts showed excellent recognition performance of 0.90 or more. We expect that the results of this paper will be helpful as the fundamental data for the development of an automatic payment system using AI self-service technology that is highly usable in the non-face-to-face era."
A Study on Algorithm Selection and Comparison for Improving the Performance of an Artificial Intelligence Product Recognition Automatic Payment System,2022,"['Self-Service Technology', 'Automatic payment system', 'Artificial Intelligence', 'Object detection', 'YOLO']",,"This study is to select an optimal object detection algorithm for designing a self-checkout counter to improve the inconvenience of payment systems for products without existing barcodes. To this end, a performance comparison analysis of YOLO v2, Tiny YOLO v2, and the latest YOLO v5 among deep learning-based object detection algorithms was performed to derive results. In this paper, performance comparison was conducted by forming learning data as an example of 'donut' in a bakery store, and the performance result of YOLO v5 was the highest at 96.9% of mAP. Therefore, YOLO v5 was selected as the artificial intelligence object detection algorithm to be applied in this paper. As a result of performance analysis, when the optimal threshold was set for each donut, the precision and reproduction rate of all donuts exceeded 0.85, and the majority of donuts showed excellent recognition performance of 0.90 or more. We expect that the results of this paper will be helpful as the fundamental data for the development of an automatic payment system using AI self-service technology that is highly usable in the non-face-to-face era."
경량화된 임베디드 시스템에서 의미론적인 픽셀 분할 마스킹을 이용한 효율적인 영상 객체 인식 기법,2022,"['객체 인식', 'OpenCV', 'ENet', 'YOLO', '딥러닝', 'Object detection', 'OpenCV', 'ENet', 'YOLO', 'Deep learning']","카메라를 이용한 영상 처리와 그에 따른 인공지능 기술의 발달로 다양한 분야의 기술이 발전하기 시작했다. 하지만 보드가 가벼울수록 연산이 많이 필요한 영상 처리 알고리즘을 구현하기 힘들다. 본 논문에서는 경량 임베디드 보드에서 물체 인식 알고리즘을 위한 딥러닝을 사용하는 방법을 제안한다. 비교적 적은 양의 계산으로 segmentation을 처리하는 딥러닝 알고리즘을 사용하여 ROI(Region of Interest)를 결정할 수 있다. 영역을 마스킹한 후, 더 정확한 딥러닝 알고리즘을 사용해 물체 감지를 할 수 있다. Python에서 입력 이미지를 처리하기 위해 OpenCV를 사용했고 ENet과 YOLO(You Only Look Once)를 사용하여 이미지를 처리했다. 이 알고리즘을 실행함으로써 평균 오차가 절반으로 감소해 정확한 객체 검출을 처리할 수 있고 경량 임베디드 보드에서 실시간으로 객체 인식을 실행할 수 있다.이 연구는 자율주행과 IoT에서 저가격 경량화된 응용에 활용될 수 있을 것으로 기대된다.","AI-based image processing technologies in various fields have been widely studied. However, the lighter the board, the more difficult it is to reduce the weight of image processing algorithm due to a lot of computation. In this paper, we propose a method using deep learning for object recognition algorithm in lightweight embedded boards. We can determine the area using a deep neural network architecture algorithm that processes semantic segmentation with a relatively small amount of computation. After masking the area, by using more accurate deep learning algorithm we could operate object detection with improved accuracy for efficient neural network (ENet) and You Only Look Once (YOLO) toward executing object recognition in real time for lightweighted embedded boards. This research is expected to be used for autonomous driving applications, which have to be much lighter and cheaper than the existing approaches used for object recognition."
혼재된 환경에서의 효율적 로봇 파지를 위한 3차원 물체 인식 알고리즘 개발,2022,"['3D Object Recognition', 'Cluttered Environment', 'YOLO', 'Mask R-CNN']",,"3D object detection pipelines often incorporate RGB-based object detection methods such as YOLO, which detects the object classes and bounding boxes from the RGB image. However, in complex environments where objects are heavily cluttered, bounding box approaches may show degraded performance due to the overlapping bounding boxes. Mask based methods such as Mask R-CNN can handle such situation better thanks to their detailed object masks, but they require much longer time for data preparation compared to bounding box-based approaches. In this paper, we present a 3D object recognition pipeline which uses either the YOLO or Mask R-CNN real-time object detection algorithm, K-nearest clustering algorithm, mask reduction algorithm and finally Principal Component Analysis (PCA) alg orithm to efficiently detect 3D poses of objects in a complex environment. Furthermore, we also present an improved YOLO based 3D object detection algorithm that uses a prioritized heightmap clustering algorithm to handle overlapping bounding boxes. The suggested algorithms have successfully been used at the Artificial-Intelligence Robot Challenge (ARC) 2021 competition with excellent results."
저속 특장차의 도심 자율주행을 위한 신호등 인지 알고리즘 적용 및 검증,2022,"['저속 무인 특장차', '딥러닝', '신호등 인지 알고리즘', '실시간 사물 감지', 'Low-speed unmanned special vehicle', 'Deep Learning', 'Traffic light recognition Algorithm', 'Real-Time Object Detection', 'YOLO algorithm']",,"In this study, a traffic light recognition algorithm was implemented and validated for low-speed special purpose vehicles in an urban environment. Real-time image data using a camera and YOLO algorithm were applied. Two methods were presented to increase the accuracy of the traffic light recognition algorithm, and it was confirmed that the second method had the higher accuracy according to the traffic light type. In addition, it was confirmed that the optimal YOLO algorithm was YOLO v5m, which has over 98% mAP values and higher efficiency. In the future, it is thought that the traffic light recognition algorithm can be used as a dual system to secure the platform safety in the traffic information error of C-ITS."
드론과 인공지능을 활용한 실종자 탐색에 관한 연구,2022,"['Drone', 'YOLO algorithm', 'Object detection']","본 연구는 4차산업혁명 시대를 대표하는 인공지능을 드론에 탑재하여 실시간 이미지 정보를 획득하고 건강상, 또는 실신 등 응급을 요 하는 사람을 탐색함으로써 사각지대를 최소화하고 탐색의 효율성을 높이는데 그 목적이 있다. 본 연구는 드론에 영상정보 획득 장치를 탑재하고 미디어 서버에 전송 후 프레임 단위의 인공지능 학습 알고리즘을 적용하여 사람 인식 결과를 분석 후 해당 GPS 정보를 획득하는 절차로 진행된다. 최근 소개된 여러 인공지능 알고리즘 중에서 대표되는 YOLO 알고리즘을 적용하여 마네킹 또는 실제 이미지를 학습함으로써 신뢰도 높은 실험 결과를 보였으며 드론의 활용범위가 확대됨에 따라 인간의 접근 사각지대에서 그 역할이 확대될 것으로 기대된다. 논문의 구성은 임무 수행을 위한 드론의 사양을 소개하고 인공지능의 개념 및 활용 방법, 실제 드론 비행을 통한 이미지 획득 및 결과 분석 그리고 향후 활용범위로 기술하였다.","This study provides several methods to minimize dead zone and to detect missing person using combined DRONE and AI especially called 4th Industrial Revolution. That is composed of image acquisition for a person who is in needed of support. The procedure is DRONE that is made of image acquisition and transfer system. after that can be shown GPS information. Currently representative AI algorithm is YOLO (You Only Look Once) that can be adopted to find manikin or real image by learning with dataset. The output was reached in reliable and efficient results. As the trends of DRONE is expanded widely that will provide various roll. This paper was composed of three parts. the first is DRONE specification, the second is the definition of AI and procedures, the third is the methods of image acquisition using DRONE, the last is the future of DRONE with AI."
CNN 기반 CCTV 동영상 내 보행자 응급 상황 자동 감지 기술 연구,2022,"['응급상황', '영상인식', 'Deep Learning', 'YOLO', 'Emergency', 'Image Recognition', 'CCTV', '딥러닝']",,"Since most medical emergencies including cardiac arrest and stroke happen unexpectedly, it is critical to recognize and respond to the situations immediately. In this paper, we propose an AI-based system which recognizes automatically medical emergencies where pedestrians fall unexpectedly due to their health problems captured in real-time video clips from CCTVs and locates the geometric position on a map on a web page to provide with prompt first aids. To this end, we extend the YOLO (You Only Look Once) network, a variant of the Convolutional Neural Network (CNN) which is suitable for 2D still images, not video. Though many researchers have studied on the methods dedicated to recognize objects in video, with a belief that CNN is not enough to recognize motions, we show that it is possible to build a robust but simple medical emergency detection system by extending the YOLO network - a variant of CNN - that only handles 2D images. Also, we report the performance of the proposed system in four performance measures in this paper."
Comparison of Deep Learning-Based Object Classification Methods for Detecting Tomato Ripeness,2022,"['SSD', 'Faster R-CNN', 'YOLO', 'Object detection']",,"Examination of the technological development in agriculture reveals that not many applicationsuse cameras to detect tomato ripeness; therefore, tomato maturity is still determined manually.Currently, technological advances and developments are occurring rapidly, and are, therefore,also inseparable from the agricultural sector. Object detection can help determining tomatoripeness. In this research, faster region-based convolutional neural network (Faster R-CNN),single shot multibox detector (SSD), and you only look once (YOLO) models were tested torecognize or detect tomato ripeness using input images. The model training process required 5hours and produced a total loss value <0.5, and as the total loss became smaller, the predictedresults improved. Tests were conducted on a training dataset, and average accuracy values of99.55%, 89.3%, and 94.6% were achieved using the Faster R-CNN, SSD, and YOLO models,respectively"
인공지능을 활용한 드론테러 대응방안,2022,"['드론', '테러', '드론탐지', '인공지능', 'YOLO', 'Drones', 'Terrorism', 'Drone Detection', 'Artificial Intelligence', 'YOLO']","드론은 휴대하기 쉽고, 접근성이 좋아 군사적으로 상업적으로 많이 활용되면서 최근 새로운 테러수단으로 등장하고 있다. 실제 드론을 이용한 테러는 증가하고 있으며, 드론의 낮은 가격, 쉬운 개조방법, 크기나 무게의 다운사이징을 통해 테러리스트들에게는 최적의 수단으로 각광받고 있다. 드론이 테러수단으로 사용된 사례를 알아보고, 드론을 탐지하기 위한 방법으로 인공지능기술을 적용한 YOLO 드론탐지 기법을 소개한다.",
YOLOv5 및 OpenPose를 이용한 건설현장 근로자 탐지성능 향상에 대한 연구,2022,"['건설업', '근로자 탐지', '자세 추정', '딥러닝', 'YOLO', 'OpenPose', 'Construction', 'Work Detection', 'Pose Estimation', 'Deep Learning', 'YOLO', 'OpenPose']","건설업은 사망자 수가 가장 많이 발생하는 산업이며, 다양한 제도 개선에도 사망자는 크게 줄어들지 않고 있다. 이에 따라, CCTV 영상에 인공지능(AI)을 적용한 실시간 안전관리가 부각되고 있다. 건설현장의 영상에 대한 AI를 적용한 근로자 탐지연구가 진행되고 있지만, 건설업의 특성상 복잡한 배경 등의 문제로 인해 성능 발현에 제한이 있다. 본 연구에서는 근로자의 탐지 및 자세 추정에 대한 성능 향상을 위해 YOLO 모델과 OpenPose 모델을 융합하여, 복잡 다양한 조건에서의 근로자에 대한 탐지 성능을 향상시켰다. 이는 향후 근로자의 불안전안 행동 및 건강관리 측면에서 활용도가 높을 것으로 예상된다.",
딥러닝 기반의 객체 검출을 이용한 상대적 거리 예측 및 접촉 감지,2022,"['영상분석', '인공신경망', '딥러닝', '접촉 감지', 'YOLO', 'Image Analysis', 'Artificial Neural Network', 'Deep Learning', 'Contact Detection', 'YOLO']",,
산림병해충 피해의심목 자동탐지 알고리즘 개발 연구,2022,"['dep learning', 'drone', 'ortho-image', 'forest disaster', 'automatic detection', 'YOLO', '딥러닝', '드론', '정사영상', '산림재해', '자동탐지', 'YOLO']",,"Recently, the forests in Korea have acumulated damage due to continuous forest disasters, and the ned for technologies to monitor forest managements is being isued.The size of the afected area is large terain, technologies using drones, artificial inteligence, and big data are being studied. In this study, a standard dataset were conducted to develop an algorithm that automaticaly detects suspicious tres damaged by forest pests using dep learning and drones. Experiments using the YOLO model among object detection algorithm models, the YOLOv4-P7 model showed the highest recal rate of 69.69% and precision of 69.15%. It was confirmed that YOLOv4-P7 should be used as an automatic detection algorithm model for tres suspected of being damaged by forest pests, considering the detection target is an ortho-image with a large image size."
객체 탐지를 활용한 근로자 충돌 안전관리 시스템,2022,"['YOLO', '객체 탐지', '데이터 모델링', '산업안전', '충돌위험', 'Data modeling', 'Collision risk', 'Industrial safety', 'Object detection', 'YOLO']",,"Recently, AI, big data, and IoT technologies are being used in various solutions such as fire detection and gas or dangerous substance detection for safety accident prevention. According to the status of occupational accidents published by the Ministry of Employment and Labor in 2021, the accident rate, the number of injured, and the number of deaths have increased compared to 2020. In this paper, referring to the dataset construction guidelines provided by the National Intelligence Service Agency(NIA), the dataset is directly collected from the field and learned with YOLOv4 to propose a collision risk object detection system through object detection. The accuracy of the dangerous situation rule violation was 88% indoors and 92% outdoors. Through this system, it is thought that it will be possible to analyze safety accidents that occur in industrial sites in advance and use them to intelligent platforms research."
실시간 객체 감지 기술로 다중 바코드와 QR코드 인식 시스템 설계,2022,"['barcode', 'QR code', 'YOLO', 'object detection', 'smart factory']",,"In today’s smart factory sites, barcodes and QR codes are used to manage various parts. When many parts are mixed at the production site, it takes a lot of time to individually scan and process barcodes and QR codes for each part. In such a situation, after capturing images of parts in a certain area, barcodes and QR codes are detected using YOLO algorithm, a real-time detection technology, and cut into individual images. In the next step, it is designed to be rotated into an image in a state that the scanner can recognize, and then decoded with the Pyzbar library, a barcode and QR code reader, through the image correction step. According to the degree of damage or contamination of barcodes or QR codes by process, the recognition rate could be improved by applying the deblur library to improve and decode."
딥러닝 기반의 객체 탐지 모델을 활용한 과수 생육 단계 판별 시스템,2022,"['딥러닝', '컴퓨터비전', '객체탐지', 'YOLO', '모바일 시스템', 'Deep learning', 'Computer Vision', 'Object Detection', 'YOLO', 'Mobile system']","인공지능 기술의 발전으로 다양한 분야에서 AI가 접목된 시스템에 대한 관심이 급증하고 있다. 농업에서도 정보통신 기술을 적용한 스마트팜이 활용되고 있으며, 자율주행, 인공위성, 빅데이터 등의 다양한 첨단 기술을 접목하여 데이터 기반의 정밀 농업이 상용화되고 있다. 국내의 경우 시설농업 분야 스마트농업의 상용화 사례가 증가하고 있으나 시설원예 분야에 투자 편증이 심하여, 시설농업과 노지 농업의 투자 격차가 지속해서 벌어지고 있다. 특히, 과수, 식물공장 분야는 투자 규모가 작다. 또한, 빅데이터 수집, 활용 체계가 미흡하다는 문제점이 있다. 이에 본 논문에서는 농업의 빅데이터를 활용하는 방안으로 딥러닝 기반의 객체 탐지 모델을 활용한 과수 생육 단계 판별 시스템을 제안한다. 해당 시스템은 농업 현장에서 사용할 수 있도록 하이브리드 앱을 설계 및 구현하며 과수 생육단계 판별을 위한 객체 탐지 기능을 제공한다.","Recently, research and system using AI is rapidly increasing in various fields. Smart farm using artificial intelligence and information communication technology is also being studied in agriculture. In addition, data-based precision agriculture is being commercialized by convergence various advanced technology such as autonomous driving, satellites, and big data. In Korea, the number of commercialization cases of facility agriculture among smart agriculture is increasing. However, research and investment are being biased in the field of facility agriculture. The gap between research and investment in facility agriculture and open-air agriculture continues to increase. The fields of fruit trees and plant factories have low research and investment. There is a problem that the big data collection and utilization system is insufficient. In this paper, we are proposed the system for determining the fruit tree growth stage using a deep learning-based object detection model. The system was proposed as a hybrid app for use in agricultural sites. In addition, we are implemented an object detection function for the fruit tree growth stage determine."
Identifying threatening drone based on deep learning with SWIR camera,2022,"['Drone', 'Deep Learning', 'Drone Identification', 'YOLO', 'SWIR camera']",,"Small drones of various sizes are used in numerous fields, including commerce, reconnaissance, and offensive attacks. Major facilities such as security areas of port, power, and offshore plants urgently need to develop solutions for detecting drones as an active countermeasure against small drone attacks because small drones used for military and terrorism pose a significant threat. It is not easy to detect various drones such as invasive or threatening ones, though recent developments have made it possible to detect them using three-dimensional radar. Therefore, this paper develops threatening drone identification system, which consists of two components: One is a software component for identifying threatening drones among various ones and the other is a hardware component for the system. The former uses well-known YOLO(You Look Only Once) (v7) model and the latter comprises a PC for running the model and an SWIR (Short-Wave InfraRed) camera for surveillance. Datasets for training and evaluation are constructed by hand from air-borne videos taken drones including threating one and is labelled by two types: normal and threatening. The datasets are comprised of 3,992 color images and 4,410 thermal images, which are trained separately. Through experiments, we have shown that mAP@.5 and mAP@.95 are 0.999 and 0.753 (0.999 and 0.760) for color images (for thermal images), respectively. Consequently the proposed system is helpful in identifying threating drones."
발전설비제조공장의 작업 안전 유스케이스 분석을 통한 영상기반 안전관리기술 개발,2022,"['Heat exchanger rod', 'Work environment safety', 'Vision recognition', 'Yolo', 'Personal protective equipment']",,
영상 처리를 이용한 IoT 기반 웨어러블 스마트 안전장비,2022,"['Kickboard sharing services', 'Single-person transportation', 'Object detection', 'YOLO v5', 'Driving assistance']",,"With the recent expansion of electric kickboards and bicycle sharing services, more and more people use them. In addition, the rapid growth of the delivery business due to the COVID-19 has significantly increased the use of two-wheeled vehicles and personal mobility. As the accident rate increases, the rule related to the two-wheeled vehicles is changed to 'mandatory helmets for kickboards and single-person transportation' and was revised to prevent boarding itself without driver's license. In this paper, we propose a wearable smart safety equipment, called SafetyHelmet, that can keep helmet-wearing duty and lower the accident rate with the communication between helmets and mobile devices. To make this function available, we propose a safe driving assistance function by notifying the driver when an object that interferes with driving such as persons or other vehicles are detected by applying the YOLO v5 object detection algorithm. Therefore it is intended to provide a safer driving assistance by reducing the failure rate to identify dangers while driving single-person transportation."
‘싱글 라이프’ 미디어 콘텐츠의 시청이  비혼 의지와 여가활동 라이프스타일에 미치는 영향,2022,"['싱글 라이프', '비혼', '관찰 리얼리티', '브이로그', '욜로', '라이프스타일', 'Single Household', 'Singlehood Life', 'Reality TV', 'YouTube Vlog', 'YOLO', 'Lifestyle']","본 연구는 1인 가구의 확산과 비혼의 증가라는 사회 트렌드의 요인으로 엔터테인먼트 미디어 콘텐츠의 영향을 살펴보고자 했다. ‘싱글 라이프’를 보여주는 관찰 리얼리티 및 유튜브 브이로그 콘텐츠의 증가는 1인 가구 확산이라는 현상을 반영한 것이기도 하지만, 이미 주류가 된 1인 가구들은 미디어 이용을 통해 이러한 라이프스타일에 대한 의지를 공고히 할 수도 있다. “라이프스타일 변형적 리얼리티 콘텐츠” 관점에 따르면, 근래의 리얼리티 영상 콘텐츠는 단순히 오락과 재미에 그치는 것이 아니라 수용자의 현실 삶의 방식을 변화시킬 의미있는 경험을 제공한다. 최근 ‘욜로(YOLO)’에서 ‘갓생’으로 변화하는 라이프스타일에 대한 논의들은 주로 인구사회학적 변인들을 중심으로 그 원인을 설명해온 가운데, 1인 가구 시청자들에게 ‘싱글 라이프’ 관련 미디어 콘텐츠가 갖는 의미를 분석했다. 미혼 성인남녀를 대상으로 설문조사 실시 결과, ‘싱글 라이프’를 보여주는 관찰 리얼리티 프로그램과 유튜브 브이로그의 이용이 많을수록 수용자의 동일시와 비혼 의지가 높았으며, 현재중심적인 라이프스타일과 미래지향적인 라이프스타일이 모두 유의미하게 높은 것으로 나타났다. 이를 바탕으로, 엔터테인먼트 콘텐츠의 최근 경향이 청년층의 삶의 방식에 미치는 영향의 함의에 대해 논했다.","This study explored the effects of recent ‘single life’ media contents on the spread of singlehood culture for Korean youth. Extant research on the changing trends across present-centered vs. future-oriented lifestyles had focused mainly on demographic or sociological factors. “Lifestyle transforming (entertainment) reality contents” perspective suggests that reality contents revealing one’s personal daily life provides not just entertaining enjoyment but also and more importantly meaningful life-changing experiences for viewers. Given the dependency of single household youth on media use, it is expected that ‘singlehood life’ media contents such as reality television and YouTube Vlog would have greater influence on viewers’ own reality and lifestyles. Survey results indicate that viewership of ‘singlehood life’ contents showed significant impacts on youth viewers’ identification and unmarriedness, as well as present-centered and future-oriented lifestyles. Theoretical and practical implications of these results were discussed."
정밀 밀링가공시 딥러닝 기법을 이용한 절삭공구 적정성 연구,2022,"['Artificial Intelligence(인공지능)', 'Milling Operation(밀링작업)', 'T Groove Dovetail Assembly(T글루브 도브테일 조립체)', 'Cutting Tool(절삭공구)', 'Adequacy(적정성)', 'Deep Learning(딥러닝)', 'You Only Look Once(YOLO)(욜로)']",,"Recently, the applicability of artificial intelligence, one of the core technologies of the 4th Industrial Revolution, has gradually in the manufacturing sector. The cutting tools used in the milling process require careful inspections to prevent unsuspected interruptions in the manufacturing process. In this study, deep learning image processing technology was used to determine the cutting tool adequacy for the T-groove dovetail assembly milling process. Here, adequacy refers to checking for tool breakage and an appropriate set-up length. This approach involves the application of deep learning techniques on tool images acquired during the cutting process. For this purpose, YOLO, a fast image-processing object-detection technique, was used. Through the images acquired during the working process, the type of cutting tool, tool breakage, and appropriateness of the setup length could be determined."
딥러닝 기반 컨테이너 적재 정렬 상태 및 사고 위험도 검출 기법,2022,"['컨테이너', 'YOLOv4', '딥러닝', '객체인식', 'Shipping Container', 'YOLOv4', 'Deep Learning', 'Object Detection']","최근 항만에서는 부정확한 컨테이너 적재로 인해 컨테이너가 강풍에 쉽게 쓰러지는 컨테이너 붕괴 사고가 빈번이 발생하고 있으며 이는 물적피해와 항만 시스템 마비로 이어지고 있다. 본 논문에서는 이런 사고를 미연에 방지하기 위해 딥러닝 기반 컨테이너 적재 상태 및 사고 위험도검출 시스템을 제안한다. 제안된 시스템은 darknet 기반 YOLO 모델을 활용하여 컨테이너 상하의 코너캐스팅을 통해 컨테이너 정렬 상태를 실시간으로 파악하고 관리자에게 사고 위험도를 알리는 시스템이다. 제안된 시스템은 추론 속도, 분류 정확도, 검출 정확도 등을 성능 지표와 실제 구현환경에서 최적의 성능을 보인 YOLOv4 모델을 객체 인식 알고리즘 모델로 선택하였다. 제안된 알고리즘인 YOLOv4가 YOLOv3보다 추론속도와FPS의 성능 측면에서 낮은 성능을 보이기는 했지만, 분류 정확도와 검출 정확도에서 강력한 성능을 보임을 증명하였다.","Incorrectly loaded containers can easily knock down by strong winds. Container collapse accidents can lead to material damage andparalysis of the port system. In this paper, We propose a deep learning-based container loading state and accident risk detection technique.Using Darknet-based YOLO, the container load status identifies in real-time through corner casting on the top and bottom of the container,and the risk of accidents notifies the manager. We present criteria for classifying container alignment states and select efficient learningalgorithms based on inference speed, classification accuracy, detection accuracy, and FPS in real embedded devices in the sameenvironment. The study found that YOLOv4 had a weaker inference speed and performance of FPS than YOLOv3, but showed strongperformance in classification accuracy and detection accuracy."
다중 객체 추적 알고리즘을 이용한 가공품 흐름 정보 기반 생산 실적 데이터 자동 수집,2022,"['인공지능', '다중 객체 추적', '제조 데이터 수집', '흐름 생산 공정', 'Artificial Intelligence', 'Multi-Object Tracking', 'Manufacturing Data Collection', 'Flow Shop']","최근 제조업에서의 디지털 전환이 가속화되고 있다. 이에 따라 사물인터넷(internet of things: IoT) 기반으로 현장 데이터를 수집하는 기술의 중요성이 증대되고 있다. 이러한 접근법들은 주로 각종 센서와 통신 기술을 활용하여 특정 제조 데이터를 확보하는 것에 초점을 맞춘다. 현장 데이터 수집의 채널을 확장하기 위해 본 연구는 비전(vision) 인공지능 기반으로 제조 데이터를 자동 수집하는 방법을 제안한다. 이는 실시간 영상 정보를 객체 탐지 및 추적 기술로 분석하고, 필요한 제조 데이터를 확보하는 것이다. 연구진은 객체 탐지 및 추적 알고리즘으로 YOLO(You Only Look Once)와 딥소트(DeepSORT)를 적용하여 프레임별 객체의 움직임 정보를 수집한다. 이후, 움직임 정보는 후보정을 통해 두 가지 제조 데이터(생산 실적, 생산 시간)로 변환된다. 딥러닝을 위한 학습 데이터를 확보하기 위해 동적으로 움직이는 공장 모형이 제작되었다. 또한, 실시간 영상 정보가 제조 데이터로 자동 변환되어 데이터베이스에 저장되는 상황을 재현하기 위해 운영 시나리오를 수립하였다. 운영 시나리오는 6개의 설비로 구성된 흐름 생산 공정(flow-shop)을 가정한다. 운영 시나리오에 따른 제조 데이터를 수집한 결과 96.3%의 정확도를 보였다.","Recently, digital transformation in manufacturing has been accelerating. It results in that the data collection technologies from the shop-floor is becoming important. These approaches focus primarily on obtaining specific manufacturing data using various sensors and communication technologies. In order to expand the channel of field data collection, this study proposes a method to automatically collect manufacturing data based on vision-based artificial intelligence. This is to analyze real-time image information with the object detection and tracking technologies and to obtain manufacturing data. The research team collects object motion information for each frame by applying YOLO (You Only Look Once) and DeepSORT as object detection and tracking algorithms. Thereafter, the motion information is converted into two pieces of manufacturing data (production performance and time) through post-processing. A dynamically moving factory model is created to obtain training data for deep learning. In addition, operating scenarios are proposed to reproduce the shop-floor situation in the real world. The operating scenario assumes a flow-shop consisting of six facilities. As a result of collecting manufacturing data according to the operating scenarios, the accuracy was 96.3%."
AI를 이용한 홈CCTV 영상의 반려묘 행동 패턴 분석 및 질병 예측 시스템 연구,2022,"['Abnormal Detection', 'Pose Estimation', 'Object Detection', 'Home CCTV', '이상 탐지', '자세 추정', '객체 인식', '홈 카메라']","반려동물 중 반려묘의 비중이 2012년 이후 연평균 25.4%의 증가율을 보이며 증가하는 추세이다. 고양이는 강아지에 비해 야생성이 강하게 남아있기 때문에 질병이 생기면 잘 숨기는 특성이 있다. 보호자가 반려묘가 질병이 있음을 알게 되었을 때는 병이 이미 악화되어진 상태일 수 있다. 반려묘의 식욕부진(식사회피), 구토, 설사, 다음, 다뇨 등과 같은 현상은 당뇨, 갑상선기능항진증, 신부전증, 범백혈구감소증 등 고양이 질병 시 나타나는 증상 중 일부이다. 반려묘의 다뇨(소변 양이 많음), 다음(물 많이 마심), 빈뇨(소변을 자주 봄) 현상을 보호자가 보다 빨리 알아차릴 수 있다면 반려묘의 질병 치료에 크게 도움이 될 것이다. 본 논문에서는 인공지능 디바이스에서 작동하는 1) 자세 예측 DeepLabCut의 Efficient 버전, 2) 객체 검출 YOLO v4, 3) 행동 예측 LSTM 4) 객체 추적은 BoT-SORT를 사용한다. 인공지능 기술을 이용하여 홈 CCTV의 영상에서 반려묘의 행동 패턴 분석과 물그릇의 무게 센서를 통해 반려묘의 다음, 다뇨 및 빈뇨를 예측한다. 그리고, 반려묘 행동 패턴 분석을 통해, 질병 예측 및 이상행동 결과를 보호자에게 리포트 하는, 메인 서버시스템과 보호자의 모바일로 전달하는 애플리케이션을 제안한다.","Cats have strong wildness so they have a characteristic of hiding diseases well. The disease may have already worsened when the guardian finds out that the cat has a disease. It will be of great help in treating the cat's disease if the owner can recognize the cat's polydipsia, polyuria, and frequent urination more quickly. In this paper, 1) Efficient version of DeepLabCut for pose estimation, 2) YOLO v4 for object detection, 3) LSTM is used for behavior prediction, and 4) BoT-SORT is used for object tracking running on an artificial intelligence device. Using artificial intelligence technology, it predicts the cat's next, polyuria and frequency of urination through the analysis of the cat's behavior pattern from the home CCTV video and the weight sensor of the water bowl. And, through analysis of cat behavior patterns, we propose an application that reports disease prediction and abnormal behavior to the guardian and delivers it to the guardian's mobile and the server system."
인공지능을 활용한 도주경로 예측 및 추적 시스템,2022,"['영상분석', '인공지능', '도주경로예측', '자동상황전파', '스마트시티 통합플랫폼', 'Intelligent image analysis', 'Escape route prediction', 'Automatic situation propagation', 'Smart city Integrate platform']","서울특별시는 25개 구청에 7만5천여대의 CCTV가 설치되어 있다. 각 구청은 CCTV관제를 위한 관제센터를 구축하고 시민의 안전을 위해 24시간 CCTV영상관제를 수행하고 있다. 서울특별시는 유관기관과 MOU를 체결하여 긴급/응급 상황에 신속한 대응이 가능하도록 구청의 CCTV영상을 제공하여 시민이 안전한 스마트시티통합플랫폼을 구축하고 있다. 본 논문에서는, 서울특별시 관할구청에서 사건 발생 시, CCTV영상에 대해 인공지능 DNN 기반의 Template Matching 기술, MLP 알고리즘과 CNN 기반으로 YOLO SPP DNN모델을 사용하여 사람과 차량을 판별하여 도주경로를 예측한다. 또한, 관할구청을 이탈하여, 차량 및 사람이 도주 시, 인접 구청에 영상정보와 상황정보를 자동전파 하도록 설계한다. 인공지능을 활용한 도주경로 예측 및 추적 시스템은 스마트시티 통합플랫폼을 전국으로 확장시킬 수 있다.","In Seoul, about 75,000 CCTVs are installed in 25 district offices. Each ward office has built a control center for CCTV control and is performing 24-hour CCTV video control for the safety of citizens. Seoul Metropolitan Government is building a smart city integrated platform that is safe for citizens by providing CCTV images of the ward office to enable rapid response to emergency/emergency situations by signing an MOU with related organizations. In this paper, when an incident occurs at the Seoul Metropolitan Government Office, the escape route is predicted by discriminating people and vehicles using the AI ​​DNN-based Template Matching technology, MLP algorithm and CNN-based YOLO SPP DNN model for CCTV images. . In addition, it is designed to automatically disseminate image information and situation information to adjacent ward offices when vehicles and people escape from the competent ward office. The escape route prediction and tracking system using artificial intelligence can expand the smart city integrated platform nationwide."
인공지능 객체 탐지를 활용한 스마트 공장 안전 시스템,2022,"['스마트 공장', '지능형 영상 분석', '객체 추적', '객체 탐지', 'YOLOv5', 'DeepSORT', 'smart factory', 'intelligent video analysis', 'object tracking', 'object detection', 'YOLOv5', 'DeepSORT']","공장 내 안전사고 중 부딪힘, 물체에 맞음, 교통사고와 같이 작업자와 위험물체의 충돌로 인한 재해사고가 높은 비율을 차지하고 있다. 이러한 예기치 못한 안전사고를 예방하기 위해 공장의 위험 상황을 미리 파악하고 작업자에게 최대한 빠르게 알리는 것이 중요하다. 본 논문에서는 인공지능 객체 탐지 기술을 활용하여 공장 내 작업자와 위험물체의 실시간 위치를 판별하고, 작업자와 위험물체의 위치에 따라 실시간으로 변동하는 위험지역을 계산한다. 또한 움직이는 물체만 탐지하는 알고리즘을 사용하여 충돌 위험을 감지할 수 있다. 실시간 객체 탐지를 위해 다른 객체 탐지 알고리즘보다 처리 속도가 빠른 YOLO(You Only Look Once) 알고리즘을 사용하였다. 실험은 실제 공장 환경에 CCTV를 설치하여 데이터를 수집하고 안전 시스템을 구축하였다. 학습된 객체 탐지 모델의 성능을 평가한 결과, 객체 탐지의 성능의 지표로 사용되는 mAP는 0.985로 높은 성능을 보여주었다.","Colliding between workers and dangerous objects take up a huge proportion of accidents in factories. Thus, it is important to analyze factory situation in real-time in order to prevent such unexpected accidents and inform workers as quickly as possible. The objective of this paper is to introduce an artificial intelligence object detection technology that can distinguish locations of workers and dangerous objects in real time and calculate the shifting danger zone based on their locations. It can also sense the risk by using algorithm capable of detecting mobile objects only. To detect object real time, YOLO (You Only Look Once) algorithm with faster inference time than other algorithms was selected. The learned object detection model showed high performance, with a mean average precision (an indicator of object detection performance) of 0.985."
이미지 인식을 통한 AI 기반 소방 시설 설계 기술 개발에 관한 연구,2022,"['fire safety design', 'fire safety design', 'image learning', 'deep learning', 'Fire fighting Design', '화재안전설계', '인공지능', '이미지 학습', '딥러닝', '소방설계 솔루션']","연구목적:  현재 국내 소방시설설계의 경우 낮은 설계단가와 업체 간 과열 경쟁으로 고급 인력에 대한 확보가 어려워 건축물의 화재안전성능을 향상시키는데 한계가 있다. 이에 이러한 문제를 해소하고 선도적인 소방엔지니어링 기술을 확보하기 위해 AI 기반 소방설계솔루션을 연구하였다. 연구방법:  기존 소방설계에 많이 사용되는 AutoCAD를 통해 기본 설계 및 실시 설계에 필요한 절차를 프로세스화 하고 YOLO v4 객체 인식 딥러닝 모델을 통해 AI기술을 활용하였다. 연구결과: 소방시설에 대한 설계프로세스를 통해 설비의 결정과 도면 설계 자동화를 진행하였다. 또한 문 및 기둥에 대한 이미지를 학습시켜 인공지능이 해당 부분을 인식하여 경계구역 선정, 배관 및 소방시설을 설치하는 기능을 구현하였다.  결론: 인공지능 기술을 기반으로 건축물 화재방호 설비에 대한 기본 및 실시 설계 도면 작성 시 인적 및 물적 자원을 저감시킬 수 있을 것으로 확인되었으며 선행적인 기술 개발을 통해 인공지능 기반 소방설계에 기술력을 확보하였다.","Purpose: Currently, in the case of domestic fire fighting facility design, it is difficult to secure high-quality manpower due to low design costs and overheated competition between companies, so there is a limit to improving the fire safety performance of buildings. Accordingly, AI-based firefighting design solutions were studied to solve these problems and secure leading fire engineering technologies. Method: Through AutoCAD, which is widely used in existing fire fighting design, the procedures required for basic design and implementation design were processed, and AI technology was utilized through the YOLO v4 object recognition deep learning model. Result: Through the design process for fire fighting facilities, the facility was determined and the drawing design automation was carried out. In addition, by learning images of doors and pillars, artificial intelligence recognized the part and implemented the function of selecting boundary areas and installing piping and fire fighting facilities. Conclusion: Based on artificial intelligence technology, it was confirmed that human and material resources could be reduced when creating basic and implementation design drawings for building fire protection facilities, and technology was secured in artificial intelligence-based fire fighting design through prior technology development."
이미지와 센서 데이터를 활용한 딥러닝 기반 반려동물 이상행동 탐지 서비스,2022,"['이상행동 탐지', '행동패턴 분석', '멀티모달 분석', '딥 러닝', '웨어러블 디바이스', 'Abnormal Behavior Detection', 'Behavior Pattern Analysis', 'Multimodal Analysis', 'Deep Learning', 'Wearable Device']","본 논문에서는 영상 데이터와 센서 데이터를 활용한 딥러닝 기반의 반려동물 이상행동 탐지 서비스를 제안한다. 최근 반려동물 보유 가구의 증가로 인해 기존 푸드 및 의료 중심의 반려동물 시장에서 인공지능을 더한 펫테크(Pet Tech) 산업이 성장하고 있다. 본 연구에서는 인공지능을 통한 반려동물의 건강관리를 위해 영상 및 센서 데이터를 활용한 딥러닝 모델을 기반으로 반려동물의 행동을 분류하고, 이상행동을 탐지하였다. 자택의 CCTV와 직접 제작한 펫 웨어러블 디바이스를 활용하여 반려동물의 영상 데이터 및 센서 데이터를 수집하고, 모델의 입력 데이터로 활용한다. 행동의 분류를위해 본 연구에서는 반려동물의 객체를 검출하기 위한 YOLO(You Only Look Once) 모델과 관절 좌표를 추출하기 위한 DeepLabCut을 결합하여 영상 데이터를 처리하였고, 센서 데이터를 처리하기 위해 각 센서 별 연관관계 및 특징을 파악할 수 있는 GAT(Graph Attention Network)를 활용하였다.","In this paper, we propose the Deep Learning-Based Companion Animal Abnormal Behavior Detection Service, which using video and sensor data. Due to the recent increase in households with companion animals, the pet tech industry with artificial intelligence is growing in the existing food and medical-oriented companion animal market. In this study, companion animal behavior was classified and abnormal behavior was detected based on a deep learning model using various data for health management of companion animals through artificial intelligence. Video data and sensor data of companion animals are collected using CCTV and the manufactured pet wearable device, and used as input data for the model. Image data was processed by combining the YOLO(You Only Look Once) model and DeepLabCut for extracting joint coordinates to detect companion animal objects for behavior classification. Also, in order to process sensor data, GAT(Graph Attention Network), which can identify the correlation and characteristics of each sensor, was used."
Mask R-CNN-based Occlusion Anomaly Detection Considering Orientation in Manufacturing Process Data,2022,"['Manufacturing process', 'Orientation', 'Object detection', 'Mask R-CNN', 'Anomaly detection']",,"In a manufacturing process, data analysis is conducted to identify defective products in real time to lower their massive production and improve the rate of efficient production. In the production process, it is difficult to find defective products mixed with normal products. Therefore, it is necessary to detect defective products generated in the production process and reduce the risk of their production. Consequently, this study proposes the Mask R-CNN-based occlusion anomaly detection method in consideration of the orientation of manufacturing process data. The proposed method uses Mask R-CNN to find abnormal objects, such as occluded objects, in a manufacturing process line. In the manufacturing process, some products are hidden. Accordingly, preprocessing in consideration of multiple orientations is applied to generate data. The generated data is performed to detect occlusions and anomalies using Mask R-CNN. The mean of IoU was compared to evaluate the detection accuracy of YOLO and Mask R-CNN. YOLO showed excellent performance when there was a constant distance and orientation and no occluded object. However, Mask R-CNN performed excellently when there was any occluded object and the orientation was considered. Therefore, for occlusion anomaly detection in a manufacturing process, Mask R-CNN can reduce the production rate of defective products."
데이터 증강 학습 이용한 딥러닝 기반 실시간 화재경보시스템 구현,2022,"['Deep Learning', 'Real-time Detection', 'Fire Alarm', 'Object Detection', 'Data Augmentation']","본 논문에서는 딥러닝을 이용하여 실시간 화재경보 시스템을 구현하는 방법을 제안한다. 화재경보를 위한 딥러닝 학습 이미지 데이터셋은 인터넷을 통하여 1500장을 취득하였다. 일상적인 환경에서 취득된 다양한 이미지를 그대로 학습하게 되면 학습 정확도가높지 않은 단점이 있다. 본 논문에서는 학습 정확도 향상을 위해 화재 이미지 데이터 확장 방법을 제안한다. 데이터증강 방법은 밝기 조절, 블러링, 불꽃사진 합성을 이용해 학습 데이터 600장을 추가해 총 2100장을 학습했다. 불꽃 이미지 합성방법을 이용하여확장된 데이터는 정확도 향상에 큰 영향을 주었다. 실시간 화재탐지 시스템은 영상 데이터에 딥러닝을 적용하여 화재를 탐지하고사용자에게 알림을 전송하는 시스템이다. Edge AI시스템에 적합한 YOLO V4 TINY 모델을 custom 학습한 모델을 이용해 실시간으로 영상을 분석해 화재를 탐지하고 그 결과를 사용자에게 알리는 웹을 개발하였다. 제안한 데이터를 사용하였을 때 기존 방법에비하여 약 10%의 정확도 향상을 얻을 수 있다.","In this paper, we propose a method to implement a real-time fire alarm system using deep learning. The deep learningimage dataset for fire alarms acquired 1,500 sheets through the Internet. If various images acquired in a daily environmentare learned as they are, there is a disadvantage that the learning accuracy is not high. In this paper, we propose a fireimage data expansion method to improve learning accuracy. The data augmentation method learned a total of 2,100sheets by adding 600 pieces of learning data using brightness control, blurring, and flame photo synthesis. The expandeddata using the flame image synthesis method had a great influence on the accuracy improvement. A real-time firedetection system is a system that detects fires by applying deep learning to image data and transmits notifications to users.An app was developed to detect fires by analyzing images in real time using a model custom-learned from the YOLO V4TINY model suitable for the Edge AI system and to inform users of the results. Approximately 10% accuracy improvementcan be obtained compared to conventional methods when using the proposed data."
실주행 영상 자료 기반의 교통안전표지 인식 거리 산출 연구,2022,"['Traffic Sign', 'YOLOv5', 'Image Data', 'Autonomous Vehicle', 'Camera']","본 연구에서는 자율주행차의 주행 안전성을 확보하기 위한 방법으로써, 도로시설물 중에서 교통안전표지를 대상으로 선정하고, 교통안전표지의 형태 및 내용의 인식 성능을 향상 시킬 수 있는 모델 개발 연구를 수행하였다. 카메라가 부착된 차량을 이용하여 국도의 영상 정보를 수집했으며, 영상에 존재하는 교통안전표지를 인식하고 정확도를 분석하였다. 교통안전표지가 존재하는 3,215개의 영상 자료 중에서, 차량의 주행 안전성과 직접적으로 관련된 17개를 분석 대상으로 선정하였다. 모델 개발에 사용된 전체 영상 자료를 학습 데이터(80%), 평가 데이터(20%)로 구분하여 분석했으며, You Only Look Once (YOLO)v5 모델을 교통안전표지의 인식 모델로 사용하였다. 분석 결과, 차량과 교통안전표지와의 거리가 25m 이하에서는 mean Average Precision (mAP)는 89.4로 나타났으며, 차량과 교통안전표지의 거리가 25m 이상이 되면 mAP는 급격히 감소하여 약 33m 부근에서는 약 0.73으로 mAP가 낮아지는 것으로 분석되었다. 본 연구의 결과는 높은 자율주행 성능의 기술 수준을 확보하는 상황에서, 자율주행차의 인식 성능을 검증하는 연구에 활용될 것으로 기대된다.","Accurate perception of surroundings is a key component of autonomous vehicles to ensure efficient and safe navigation. Traffic safety signs are road facilities that have to be recognized with high precision. In this study, an algorithm was developed to improve the recognition of the shape and content of traffic signs. The accuracy of traffic sign recognition was verified using data collected after conducting a field survey using a camera-equipped vehicle along an arterial road. A total of 3,215 images of traffic safety signs in different locations were analyzed, and the signs were visually identified. To develop a model for road sign recognition, the data were analyzed by dividing the total dataset into 80% training data and 20 % validation data. The widely used ""You Only Look Once"" (YOLO)v5 image recognition technique was employed. As a result of the analysis, the mean Average Precision (mAP) was 89.4 when the distance between the vehicle and the traffic safety sign was 25 m or less. When the distance was more than 25 m, the mAP rapidly decreased at around 33 m. The research was limited to analyzing the accuracy of recognizing the shape and content of traffic signs. The results are expected to be applied in autonomous vehicles in the future when a high level of autonomous driving performance is needed."
노상 주차 차량 탐지를 위한 YOLOv4 그리드 셀 조정 알고리즘,2022,"['YOLOv4', 'YOLO Custom Training', 'Vehicle Detection', 'Cell Shift Algorithm']",,"YOLOv4 can be used for detecting parking vehicles in order to check a vehicle in out-door parking space. YOLOv4 has 9 anchor boxes in each of 13x13 grid cells for detecting a bounding box of object. Because anchor boxes are allocated based on each cell, there can be existed small observational error for detecting real objects due to the distance between neighboring cells. In this paper, we proposed YOLOv4 grid cell shift algorithm for improving the out-door parking vehicle detection accuracy. In order to get more chance for trying to object detection by reducing the errors between anchor boxes and real objects, grid cells over image can be shifted to vertical, horizontal or diagonal directions after YOLOv4 basic detection process.The experimental results show that a combined algorithm of  a custom trained YOLOv4 and a cell shift algorithm has 96.6% detection accuracy compare to 94.6% of a custom trained YOLOv4 only for out door parking vehicle images."
ANOMALY DETECTION FOR AN ORAL HEALTH CARE APPLICATION USING ONE CLASS YOLOV3,2022,"['anomaly detection', 'object detection', 'YOLO.']",,"In this report, we apply an anomaly detection algorithm to a mobile oral health care application. In particular, we have investigated one class YOLOv3 as an anomaly detec- tion model to classify pictures of mouths which will be used as inputs in the following machine learning model. We have achieved outstanding performances by proposing appropriate anno- tation strategies for our data sets and modifying the loss function. Moreover, the model can classify not only oral and non-oral pictures but also output preprocessed pictures that only con- tain the area around the lips by using the predicted bounding box. Thus, the model performs prediction and preprocessing simultaneously."
YOLOv4 기반의 소형 물체탐지기법을 이용한 건설도면 내 철강 자재 문자 검출 및 인식기법,2022,"['Construction Drawings', 'Text Recognition', 'YOLO', 'Data Augmentation', 'Spatial Attention']","최근 딥러닝 기반의 객체 검출 및 인식 연구가 발전해가면서 산업 및 실생활에 적용되는 범위가 넓어지고 있다. 건설 분야에도 딥러닝 기반의 시스템이 도입되고 있지만 아직은 미온적이다. 건설 도면에서 자재 산출이 수작업으로 이뤄지고 있어 많은 소요시간과 부정확한 적산 결과로 잘못된 물량산출의 거래가 생길 수 있다. 이를 해결하기 위해서 빠르고 정확한 자동 도면 인식시스템이 필요하다. 따라서 본 논문은 건설도면 내 철강 자재를 검출하고 인식하는 인공지능기반 자동 도면 인식 적산 시스템을 제안한다. 빠른 속도의 YOLOv4 기반에 소형 객체 검출성능을 향상하기 위한 복제 방식의 데이터 증강기법과 공간집중 모듈을 적용하였다. 검출한 철강 자재 영역을 문자 인식한 결과를 토대로 철강 자재를 적산한다. 실험 결과 제안한 방식은 기존 YOLOv4 대비 정확도와 정밀도를 각각 1.8%, 16% 증가시켰다. 제안된 방식의 Precision은 0.938, Recall은 1, 는 99.4%, 68.8%의 향상된 결과를 얻었다. 문자 인식은 기존 데이터를 사용한 인식률 75.6%에 비해 건설도면에 사용되는 폰트에 맞는 데이터 세트를 구성하여 학습한 결과 99.9%의 인식률을 얻었다. 한 이미지 당 평균 소요시간은 검출 단계는 0.013초, 문자 인식은 0.65초, 적산 단계는 0.16초로 총 0.84초의 결과를 얻었다.",
Intelligent Activity Recognition based on Improved Convolutional Neural Network,2022,"['Action Recognition', 'Deep Learning', 'Target Detection', 'Convolutional Neural Network', 'LSTM']",,
YOLOv5와 YOLOv7 모델을 이용한 해양침적쓰레기 객체탐지 비교평가,2022,"['Deposited marine debris', 'YOLO', 'Object detection', 'Deep learning']",,"Deposited Marine Debris(DMD) can negatively affect marine ecosystems, fishery resources, and maritime safety and is mainly detected by sonar sensors, lifting frames, and divers. Considering the limitation of cost and time, recent efforts are being made by integrating underwater images and artificial intelligence (AI). We conducted a comparative study of You Only Look Once Version 5 (YOLOv5) and You Only Look Once Version 7 (YOLOv7) models to detect DMD from underwater images for more accurate and efficient management of DMD. For the detection of the DMD objects such as glass, metal, fish traps, tires, wood, and plastic, the two models showed a performance of over 0.85 in terms of Mean Average Precision (mAP@0.5). A more objective evaluation and an improvement of the models are expected with the construction of an extensive image database."
인공지능 기반 객체인식 기법에 관한 연구,2022,"['Artificial Intelligence', 'Object Recognition', 'YOLO', 'R-CNN']",최근 들어 차산업 4 연관기술인 사이버물리시스템(CPS) 구축을 위해 물리 모델과 제어회로 시뮬레이션을 위한 가상제어시스템 구축 작업이 다양한 산업 분야에서 요구가 점점 증가하고 있다. 전자 문서화 되지 않은 문서들에 대한 직접입력을 통한 변환은 시간과 비용이 많이 소모된다. 이를 위해 이미 출력된 대량의 도면을 인공지능을 이용한 객체 인식을 통해 디지털화 작업은 매우 중요하다고 할 수 있다. 본 논문에서는 도면내 객체를 정확하게 인식하고 이를 다양한응용에 활용할 수 있도록 하기 위하여 도면내 객체의 특징을 분석하여 인공지능을 활용한 인식 기법을 제안하였다. 객체 인식의 성능을 높이기 위하여 객체별 인식 후 그 정보를 저장하는 중간 파일을 생성하게 하였다. 그리고 인식 결과를 도면에서 삭제하여 다음 인식 대상의 인식률을 향상시켰다. 그리고 그 인식 결과를 표준화 포맷 문서로 저장하여 이를 제어시스템의 다양한 분야에 활용할 수 있도록 하였다. 본 논문에서 제안한 기법의 우수한 성능은 위해 실험을 통해확인할 수 있었다.,"Recently, in order to build a cyber physical system(CPS) that is a technology related to the 4th industry, the construction of the virtual control system for physical model and control circuit simulation is increasingly required in various industries. It takes a lot of time and money to convert documents that are not electronically documented through direct input. For this, it is very important to digitize a large number of drawings that have already been printed through object recognition using artificial intelligence. In this paper, in order to accurately recognize objects in drawings and to utilize them in various applications, a recognition technique using artificial intelligence by analyzing the characteristics of objects in drawing was proposed. In order to improve the performance of object recognition, each object was recognized and then an intermediate file storing the information was created. And the recognition rate of the next recognition target was improved by deleting the recognition result from the drawing. In addition, the recognition result was stored as a standardized format document so that it could be utilized in various fields of the control system. The excellent performance of the technique proposed in this paper was confirmed through the experiments."
무인기로 취득한 RGB 영상과 YOLOv5를 이용한 수수 이삭 탐지,2022,"['Sorghum', 'UAV', 'RGB', 'YOLO', 'Detection']","본 연구는 수수의 수확량 추정을 위해 무인기로 취득한 RGB 영상과 YOLOv5를 이용하여 수수 이삭 탐지 모델을 개발하였다. 이삭이 가장 잘 식별되는 9월 2일의 영상 중 512×512로 분할된 2000장을 이용하여 모델의 학습, 검증 및 테스트하였다. YOLOv5의 모델 중 가장 파라미터가 적은 YOLOv5s에서 mAP@50=0.845로 수수 이삭을 탐지할 수 있었다. 파라미터가 증가한 YOLOv5m에서는 mAP@50=0.844로 수수 이삭을 탐지할 수 있었다. 두 모델의 성능이 유사하나 YOLOv5s (4시간 35분)가 YOLOv5m (5시간 15분)보다 훈련시간이 더 빨라 YOLOv5s가 수수 이삭 탐지에 효율적이라고 판단된다. 개발된 모델을 이용하여 수수의 수확량 예측을 위한 단위면적당 이삭 수를 추정하는 알고리즘의 기초자료로 유용하게 활용될 것으로 판단된다. 추가적으로 아직 개발의 초기 단계를 감안하면 확보된 데이터를 이용하여 성능 개선 및 다른 CNN 모델과 비교 검토할 필요가 있다고 사료된다.","The purpose of this study is to detect the sorghum panicle using YOLOv5 based on RGB images acquired by a unmanned aerial vehicle (UAV) system. The high-resolution images acquired using the RGB camera mounted in the UAV on September 2, 2022 were split into 512×512 size for YOLOv5 analysis. Sorghum panicles were labeled as bounding boxes in the split image. 2,000images of 512×512 size were divided at a ratio of 6:2:2 and used to train, validate, and test the YOLOv5 model, respectively. When learning with YOLOv5s, which has the fewest parameters among YOLOv5 models, sorghum panicles were detected with mAP@50=0.845. In YOLOv5m with more parameters, sorghum panicles could be detected with mAP@50=0.844. Although the performance of the two models is similar, YOLOv5s (4 hours 35 minutes) has a faster training time than YOLOv5m (5 hours 15 minutes). Therefore, in terms of time cost, developing the YOLOv5s model was considered more efficient for detecting sorghum panicles. As an important step in predicting sorghum yield, a technique for detecting sorghum panicles using high-resolution RGB images and the YOLOv5 model was presented."
A study on Detecting the Safety helmet wearing using YOLOv5-S model and transfer learning,2022,"['Safety Helmet', 'Object Detection', 'Yolo', 'Safety Accidents', 'Personal Protective Equipment']",,"Occupational safety accidents are caused by various factors, and it is difficult to predict when and why they occur, and it is directly related to the lives of workers, so the interest in safety accidents is increasing every year. Therefore, in order to reduce safety accidents at industrial fields, workers are required to wear personal protective equipment. In this paper, we proposes a method to automatically check whether workers are wearing safety helmets among the protective equipment in the industrial field. It detects whether or not the helmet is worn using YOLOv5, a computer vision-based deep learning object detection algorithm. We transfer learning the s model among Yolov5 models with different learning rates and epochs, evaluate the performance, and select the optimal model. The selected model showed a performance of 0.959 mAP."
자율주행 차량의 자동차 번호 인식 시스템 설계,2022,"['ALPR', 'autonomous vehicle', 'computer vision', 'Darknet YOLO', 'Capstone design']",,"The ALPR(automatic license plate recognition) technology is used in many fields, and the high recognition rate and the fast processing speed are important factors. The accuracy and speed of object detection and recognition are improving by recent research on the deep learning area."
딥러닝기반 도로 포트홀 탐지에 관한 연구,2022,"['Deep learning', 'Object detection', 'Porthole', 'YOLO', 'One-stage detector']",‘도로위의 지뢰’라고 불리는 포트홀(Pothole)은 운전에 심각한 장애를 유발하고 있어 한국도로공사 뿐만아니라 지자체에서도 도로에서 발생하는 포트홀을 조기 발견하기 위한 조사 차량을 구입하는 등의 많은 노력을 기울이고 있다. 본 논문에서는 딥러닝 기술을 이용하여 기존에 지자체 및 도로관리기관의 고가 조사 차량이 아닌 상대적으로 가격이 저렴하고 쉽게 접할 수 있는 블랙박스 영상 데이터를 기반으로 도로위의 포트홀을 탐지하고 모니터링할 수 있는 객체 탐지 기술을 구현 및 검증하고자 한다.,
Study On Masked Face Detection And Recognition using transfer learning,2022,"['Masked Face Detection', 'Mask Detection', 'Object Detection', 'Yolo', 'Masked Face Recognition']",,"COVID-19 is a crisis with numerous casualties. The World Health Organization (WHO) has declared the use of masks as an essential safety measure during the COVID-19 pandemic. Therefore, whether or not to wear a mask is an important issue when entering and exiting public places and institutions. However, this makes face recognition a very difficult task because certain parts of the face are hidden. As a result, face identification and identity verification in the access system became difficult. In this paper, we propose a system that can detect masked face using transfer learning of Yolov5s and recognize the user using transfer learning of Facenet. Transfer learning preforms by changing the learning rate, epoch, and batch size, their results are evaluated, and the best model is selected as representative model. It has been confirmed that the proposed model is good at detecting masked face and masked face recognition."
A Study on Image Labeling Technique for Deep-Learning-Based Multinational Tanks Detection Model,2022,"['Convolutional Neural Network (CNN)', 'Computer Vision', 'Deep Learning', 'YOLO Network']",,"Recently, the improvement of computational processing ability due to the rapid development of computing technology has greatly advanced the field of artificial intelligence, and research to apply it in various domains is active. In particular, in the national defense field, attention is paid to intelligent recognition among machine learning techniques, and efforts are being made to develop object identification and monitoring systems using artificial intelligence. To this end, various image processing technologies and object identification algorithms are applied to create a model that can identify friendly and enemy weapon systems and personnel in real-time. In this paper, we conducted image processing and object identification focused on tanks among various weapon systems. We initially conducted processing the tanks' image using a convolutional neural network, a deep learning technique. The feature map was examined and the important characteristics of the tanks crucial for learning were derived. Then, using YOLOv5 Network, a CNN-based object detection network, a model trained by labeling the entire tank and a model trained by labeling only the turret of the tank were created and the results were compared. The model and labeling technique we proposed in this paper can more accurately identify the type of tank and contribute to the intelligent recognition system to be developed in the future."
MZ세대의 특성과 언어 사용 연구,2022,"['MZ generation', 'digital native', 'flex', 'work-life balance', 'yolo', 'fire', 'echoist', 'meme', 'multi persona', 'MZ세대', '디지털 네이티브', '플렉스', '워라밸', '욜로', '파이어', '에코이스트', '밈', '멀티 페르소나']",,.
SHOMY: Detection of Small Hazardous Objects using the You Only Look Once Algorithm,2022,"['Computer vision', 'detection of hazardous items', 'small-object detection', 'YOLO', 'air transport', 'security industries']",,"Research on the advanced detection of harmful objects in airport cargo for passenger safety against terrorism has increased recently. However, because associated studies are primarily focused on the detection of relatively large objects, research on the detection of small objects is lacking, and the detection performance for small objects has remained considerably low. Here, we verified the limitations of existing research on object detection and developed a new model called the Small Hazardous Object detection enhanced and reconstructed Model based on the You Only Look Once version 5 (YOLOv5) algorithm to overcome these limitations. We also examined the performance of the proposed model through different experiments based on YOLOv5, a recently launched object detection model. The detection performance of our model was found to be enhanced by 0.3 in terms of the mean average precision (mAP) index and 1.1 in terms of mAP (.5:.95) with respect to the YOLOv5 model. The proposed model is especially useful for the detection of small objects of different types in overlapping environments where objects of different sizes are densely packed. The contributions of the study are reconstructed layers for the Small Hazardous Object detection enhanced and reconstructed Model based on YOLOv5 and the non-requirement of data preprocessing for immediate industrial application without any performance degradation."
임베디드 보드에서 영상 처리 및 딥러닝 기법을 혼용한 돼지 탐지 정확도 개선,2022,"['Real-Time Video Monitoring', 'Video Object Detection', 'Pig Detection', 'Image Processing', 'Deep Learning', 'YOLO']",,
딥러닝 기반의 가금류 객체 탐지 알고리즘,2022,"['스마트팜', '딥러닝', '객체 검출', '영상 분석', '욜로', 'Smart Farm', 'Deep Learning', 'Object Detection', 'Image Analysis', 'YOLO']","가금의 평균 체중을 구하기 위해서는 닭이 저울 위로 올라가면 측정된 무게 값 데이터를 쌓아 원시 데이터로 닭의 성장 그래프를 그려 이를 예측한다. 하지만 저울에 닭이 여러 마리가 올라가 무게에 편차가 발생하여 평균 체중 예측에 혼란을 준다. 저울의 고도화와 성능검증, 가금의 평균 체중 예측값을 더 정확하게 교정하기 위해 가금의 개체 수 측정하는 것을 목적으로 객체 인식 모델을 비교하는 실험을 진행한다. 연구 결과 Modified YOLOv5가 98.8%, YOLOv5가 98.5%, YOLOv4가 96%, Mask R-CNN가 90%의 정확도를 보였다. 속도는 Modified YOLOv5가 33분 32초, YOLOv5가 25분 40초, YOLOv4가 66분 67초, Mask-RCNN가 172분 8초가 걸렸다. YOLOv5가 가장 빠른 검출 속력을 보였지만 Modified YOLOv5가 가장 높은 정확도를 보여 닭 개체에 가장 정확한 객체 검출 모델임을 알 수 있었다. 향후 객체 인식 모델을 보완하여 좀 더 정밀한 가금의 개체 수를 측정하고 결과 오차에 대해서 개선할 계획이다.","In order to obtain the average weight of a poultry, when the chicken goes up on the scale, it accumulates the measured weight value data and draws a growth graph of the chicken with raw data to predict it. However, several chickens rise on the scale, causing variations in weight, which confuses average weight prediction. Experiments are conducted to compare object recognition models with the aim of measuring the number of individuals to accurately correct the scale's advancement and performance verification, and the average weight prediction. As a result of the study, Modified YOLOv5 98.8%, YOLOv5 98.5%, YOLOv4 96%, and Mask R-CNN showed 90%. The speed took 33m 32s Modified YOLOv5, 25m 40s YOLOv5, 66m 67s YOLOv4, and 172m 8s for Mask-RCNN. Although YOLOv5 showed the fastest detection speed, Modified YOLOv5 showed the highest accuracy, indicating that it was the most accurate object detection model for chicken objects. In the future, we plan to supplement the object recognition model to measure the population of more precise poultry and improve it against the result error."
딥러닝 기반의 객체 검출 및 거리 추정을 위한 카메라 센서 구현에 관한 연구,2022,"['ADAS(Advanced Driver Assistance System', '첨단 운전자 보조 시스템)', 'AEB(Autonomous Emergency Braking', '긴급 제동 장치)', 'Deep learning(딥러닝)', 'YOLO(You Only Look Once', '딥러닝 객체 검출 알고리즘)', 'Camera calibration(카메라 캘리브레이션)', 'Prescan(ADAS 시뮬레이션 프로그램)']",,
카메라와 라이다의 센서융합을 이용한 객체 추적 시스템 개발,2022,"['센서융합', '객체 추적', '객체 인식', '칼만 필터', '포인트 클라우드', 'Sensor fusion', 'Object tracking', 'Object recognition', 'YOLO', 'Point cloud']","본 논문에서는 도로를 주행하는 자동차를 추적하기 위한 실시간 객체 추적 시스템 개발을소개한다. 본 시스템은 객체의 기하학적, 위치 정보를 얻을 수 있는 LiDAR 센서와 물체의종류를 인식할 수 있는 카메라 센서 정보를 융합하여 높은 수준의 물체 위치 정보를 얻는다.LiDAR 포인트 클라우드 클러스터링 연산은 ROS(Robot Operating System) 기반의Autoware를 이용해 실시간으로 수행됐으며, RGB-D 카메라는 YOLOv5를 이용해 영상에서네 가지 객체(자동차, 트럭, 야드트랙터, 사람)를 학습하고 인식하는데 활용됐다. 본 논문에서는 이러한 센서 융합을 위한 카메라 캘리브레이션이 새롭게 제안되는데, 이는 두 가지의센서 데이터를 결합하는 데 필요하다. 객체의 위치는 이전 프레임의 클러스터 중심점과 현재 프레임의 클러스터 중심점을 칼만 필터에 의해 예측되며, 추적된 데이터 기록을 통해 이전 정보와 비교하여 객체가 동일한지 판단한다. 본 시스템은 대학 체육관 앞에서 자동차를추적하는 실험을 통해 검증했다",
심층신경망을 이용한 스마트 양식장용 어류 크기 자동 측정 시스템,2022,"['Deep neural network', 'YOLOv3', 'Object detection', 'Fish size', 'Smart fish farm', 'LabVIEW']",,"To measure the size and weight of the fish, we developed an automatic fish size measurement system using a deep neural network, where the YOLO (You Only Look Once)v3 model was used. To detect fish, an IP camera with infrared function was installed over the fish pool to acquire image data and used as input data for the deep neural network. Using the bounding box information generated as a result of detecting the fish and the structure for which the actual length is known, the size of the fish can be obtained. A GUI (Graphical User Interface) program was implemented using LabVIEW and RTSP (Real-Time Streaming protocol). The automatic fish size measurement system shows the results and stores them in a database for future work."
다중스펙트럼을 이용한 횡단보도 보행자 검지에 관한 연구,2022,"['딥러닝', '객체 검지', 'YOLOv5', '보행자 감지', '멀티 스펙트럼', 'Deep Learning', 'Object Detection', 'YOLOv5', 'Pedestrian Detection', 'Multi-spectrum']",주간 및 야간의 보행자 감지를 위해서는 다중 스펙트럼 활용이 필수적이다. 본 논문에서는 교통사고의 위험성이 높은 교차로에서 횡단보도 근처의 보행자를 24시간 검출하기 위해 컬러 카메라 및 열화상 적외선 카메라를 사용하였다. 보행자 탐지를 위해서 YOLO v5 객체 검출기를 사용하였으며 컬러 이미지와 열화상 이미지를 동시에 사용하여 감지 성능을 향상 시켰다. 제안된 시스템은 실제 횡단보도 현장에서 확보한 주·야간 다중 스펙트럼(색상 및 열화상) 보행자 데이터 셋에서 Iou 0.5 기준 0.94 mAP의 높은 성능을 보였다.,
간선화물의 상자 하차를 위한 외팔 로봇 시스템 개발,2022,"['Object Recognition', 'Robotic Arm', 'Kinematics', 'Task And Motion Planning', 'Image Processing']",,"In this paper, the developed trunk cargo unloading automation system is introduced, and the RGB-D sensor-based box loading situation recognition method and unloading plan applied to this system are suggested. First of all, it is necessary to recognize the position of the box in a truck. To do this, we first apply CNN-based YOLO, which can recognize objects in RGB images in real-time. Then, the normal vector of the center of the box is obtained using the depth image to reduce misrecognition in parts other than the box, and the inner wall of the truck in an image is removed. And a method of classifying the layers of the boxes according to the distance using the recognized depth information of the boxes is suggested. Given the coordinates of the boxes on the nearest layer, a method of generating the optimal path to take out the boxes the fastest using this information is introduced. In addition, kinematic analysis is performed to move the conveyor to the position of the box to be taken out of the truck, and kinematic analysis is also performed to control the robot arm that takes out the boxes. Finally, the effectiveness of the developed system and algorithm through a test bed is proved."
Color Barcode Detection of Complementary Color Barcode-based Optical Camera Communications with a Deep Neural Network,2022,"['Display-to-camera communication', 'Complementary color barcode-based optical camera communications', 'Deep neural network']",,"Complementary color barcode-based optical camera communications (CCB-OCC), which uses electronic displays and cameras as data transmitters and receivers, can offer a simple and short-range communications interface. In this paper, we enhance the data rate of a CCB-OCC scheme by using deep neural network (DNN)-based color barcode detection and adaptive colorvalue extraction. Unlike a conventional scheme, the proposed method extracts a color barcode region using a You Only Look Once (YOLO) real-time detection model that provides reliable barcode region extraction from various viewing angles between the display and the camera. In addition, the proposed scheme extracts accurate color values from color histograms using adaptive peak positions that express consecutive signals between packets. Experimental results verify data rate improvement in the proposed CCB-OCC scheme using DNN-based barcode detection and adaptive color-value extraction in a display-to-camera (D2C) communications link."
Steel Surface Defect Detection using the RetinaNet Detection Model,2022,"['Defect Detection', 'Deep Learning', 'Steel Defect Detection', 'RetinaNet model', 'One-Stage Detector']",,"Some surface defects make the weak quality of steel materials. To limit these defects, we advocate a onestage detector model RetinaNet among diverse detection algorithms in deep learning. There are several backbones in the RetinaNet model. We acknowledged two backbones, which are ResNet50 and VGG19. To validate our model, we compared and analyzed several traditional models, one-stage models like YOLO and SSD models and two-stage models like Faster-RCNN, EDDN, and Xception models, with simulations based on steel individual classes. We also performed the correlation of the time factor between one-stage and twostage models. Comparative analysis shows that the proposed model achieves excellent results on the dataset of the Northeastern University surface defect detection dataset. We would like to work on different backbones to check the efficiency of the model for real world, increasing the datasets through augmentation and focus on improving our limitation."
객체 인식과 객체 추적을 활용한 고속도로 주행 영상에서의 돌발 상황 인식 방법,2022,"['machine learning', 'object detection', 'object tracking', 'RNN', 'LSTM']",,"The aim of this study is to recognize unexpected situations in road driving images using object detection and object tracking. Object detection is performed for each frame of the road driving image captured through the vehicles black box, and the vehicles movement path is learned using object tracking. Using the learned movement path, predict next vehicles position, and the unexpected situation is detecting by using the difference between predicted position and the actual position. YOLO (You Only Look Once) is used for object recognition, Deep SORT (Deep Simple Online and Realtime Tracking) for object tracking, and RNN (Recurrent Neural Network) and LSTM (Long Short-Term Memory) for path learning. We used 3 types of training and test data set obtained from the entire videos, driving videos, or from the highway driving videos."
스마트 자율배송을 위한 클래스 분류와 객체별 학습데이터 유형,2022,"['딥러닝', '주행 환경 인식', 'AI 학습용 데이터', '객체인식', '자율주행', 'Deep Learning', 'Perception', 'AI training data', 'Object Detection', 'Autonomous Driving']","자율배송 운행 데이터는 코로나 시대의 라스트마일 배송에 대한 패러다임 변화를 주도하는 핵심이다. 국내자율배송로봇과 해외 기술선도국가 간의 기술격차 해소를 위해서는 인공지능 학습에 사용 가능한 대규모 데이터 수집과 검증이 최우선으로 요구된다. 따라서 해외 기술선도국가에서는 인공지능 학습데이터를 누구든사용가능한 공공데이터 형태로 오픈하여 검증과 기술발전에 기여하고 있다. 본 논문은 자율배송로봇 학습을 목적으로 326개의 객체를 수집하고 Mask r-cnn, Yolo v3 등의 인공지능 모델을 학습하고 검증하였다.추가적으로 두 모델을 기반으로 비교하고 향후 자율배송로봇 연구에 요구되는 요소를 고찰하였다.",
Transfer learning in a deep convolutional neural network for implant fixture classification: A pilot study,2022,"['Artificial Intelligence', 'Deep Learning', 'Dental Implants', 'Dental Radiography']",,"Purpose: This study aimed to evaluate the performance of transfer learning in a deep convolutional neural network for classifying implant fixtures. Materials and Methods: Periapical radiographs of implant fixtures obtained using the Superline (Dentium Co. Ltd., Seoul, Korea), TS III(Osstem Implant Co. Ltd., Seoul, Korea), and Bone Level Implant(Institut Straumann AG, Basel, Switzerland) systems were selected from patients who underwent dental implant treatment. All 355 implant fixtures comprised the total dataset and were annotated with the name of the system. The total dataset was split into a training dataset and a test dataset at a ratio of 8 to 2, respectively. YOLOv3 (You Only Look Once version 3, available at https://pjreddie.com/darknet/yolo/), a deep convolutional neural network that has been pretrained with a large image dataset of objects, was used to train the model to classify fixtures in periapical images, in a process called transfer learning. This network was trained with the training dataset for 100, 200, and 300 epochs. Using the test dataset, the performance of the network was evaluated in terms of sensitivity, specificity, and accuracy. Results: When YOLOv3 was trained for 200 epochs, the sensitivity, specificity, accuracy, and confidence score were the highest for all systems, with overall results of 94.4%, 97.9%, 96.7%, and 0.75, respectively. The network showed the best performance in classifying Bone Level Implant fixtures, with 100.0% sensitivity, specificity, and accuracy. Conclusion: Through transfer learning, high performance could be achieved with YOLOv3, even using a small amount of data."
YOLOv5를 활용한 야생동물 탐지 및 분류 모델에 대한 소고,2022,"['YOLOv5', 'wild animals', 'object detection', 'learning data', 'deep learning', 'feature map']",,"Although the AI classification model using the YOLOv5 model has better performance than the existing image classification models such as EfficientDet, EfficientNet, and YOLOv4, there are few model use cases. The model for classifying images of wild animals in a laboratory or staged environment differs from the actual situation in which resolution, angle, illuminance, and weather conditions vary widely, so there are limitations in existing studies. This study can contribute to reducing the number of roadkill accidents caused by wild animals appearing on the road of recent vehicles. In addition to the injury or death of wild animals, the accident causes vehicle damage and human casualties. This article confirmed the excellent performance by applying the YOLO 5 modeling technique, which plays a key role in the development of a service that detects wild animals at a superior level compared to the naked eye and prevents accidents."
Transfer learning in a deep convolutional neural network for implant fixture classification: A pilot study,2022,"['Artificial Intelligence', 'Deep Learning', 'Dental Implants', 'Dental Radiography']",,"Purpose: This study aimed to evaluate the performance of transfer learning in a deep convolutional neural network for classifying implant fixtures.Materials and Methods: Periapical radiographs of implant fixtures obtained using the Superline (Dentium Co. Ltd., Seoul, Korea), TS III (Osstem Implant Co. Ltd., Seoul, Korea), and Bone Level Implant (Institut Straumann AG, Basel, Switzerland) systems were selected from patients who underwent dental implant treatment. All 355 implant fixtures comprised the total dataset and were annotated with the name of the system. The total dataset was split into a training dataset and a test dataset at a ratio of 8 to 2, respectively. YOLOv3 (You Only Look Once version 3, available at https:// pjreddie.com/darknet/yolo/), a deep convolutional neural network that has been pretrained with a large image dataset of objects, was used to train the model to classify fixtures in periapical images, in a process called transfer learning. This network was trained with the training dataset for 100, 200, and 300 epochs. Using the test dataset, the performance of the network was evaluated in terms of sensitivity, specificity, and accuracy.Results: When YOLOv3 was trained for 200 epochs, the sensitivity, specificity, accuracy, and confidence score were the highest for all systems, with overall results of 94.4%, 97.9%, 96.7%, and 0.75, respectively. The network showed the best performance in classifying Bone Level Implant fixtures, with 100.0% sensitivity, specificity, and accuracy. Conclusion: Through transfer learning, high performance could be achieved with YOLOv3, even using a small amount of data."
딥러닝을 위한 마스크 착용 유형별 데이터셋 구축 및 검출 모델에 관한 연구,2022,"['Mask detection', 'Deep learning', 'Object classification', 'Object detection']",,"Due to COVID-19, Correct method of wearing mask is important to prevent COVID-19 and the other respiratory tract infections. And the deep learning technology in the image processing has been developed. The pur- pose of this study is to create the type of mask wearing dataset for deep learning models and select the deep learning model to detect the wearing mask correctly. The Image dataset is the 2,296 images acquired using a web crawler. Deep learning classification models provided by tensorflow are used to validate the dataset. And Object detection deep learning model YOLOs are used to select the detection deep learning model to detect the wearing mask cor- rectly. In this process, this paper proposes to validate the type of mask wearing datasets and YOLOv5 is the effective model to detect the type of mask wearing. The experimental results show that reliable dataset is acquired and the YOLOv5 model effectively recognize type of mask wearing."
소성가공 분야에서 인공지능을 이용한 절단면 이물질 검출,2022,"['drone', 'flight algorithm', 'air pollution', 'arduino']",,"The aging operation method of the root industry (plastic processing industry) causes problems such as aging of professional personnel, difficulty in transferring know-how at production sites, decreasing productivity of unskilled workers, inaccuracy and quality of visual inspection-based systems. In line with the fourth industrial revolution, it is a trend to solve the above root industry problems by establishing a smart factory applying artificial intelligence technology. In this paper, cutting surfaces foreign material detection techniques are implemented through artificial intelligence object detection to reduce the occurrence of defects in forging processes in the plastic processing field. In addition, acurancy and mean Average Precision (mAP) were compared with the detection results of Fast-RCNN, SSD, and Yolo to prove the possibility of establishing a smart factory optimized for the plastic processing industry."
깊이 이미지를 이용한 타이어 표면 결함 검출 방법에 관한 연구,2022,"['Tire Defect Detection', 'Depth Image', 'Deep Learning', 'Computer Vision', 'Image Processing', '타이어 결함 검출', '깊이 이미지', '딥러닝', '컴퓨터비전', '영상처리']",,"Recently, research on smart factories triggered by the 4th industrial revolution is being actively conducted. Accordingly, themanufacturing industry is conducting various studies to improve productivity and quality based on deep learning technology with robustperformance. This paper is a study on the method of detecting tire surface defects in the visual inspection stage of the tire manufacturingprocess, and introduces a tire surface defect detection method using a depth image acquired through a 3D camera. The tire surfacedepth image dealt with in this study has the problem of low contrast caused by the shallow depth of the tire surface and the differencein the reference depth value due to the data acquisition environment. And due to the nature of the manufacturing industry, algorithmswith performance that can be processed in real time along with detection performance is required. Therefore, in this paper, we studieda method to normalize the depth image through relatively simple methods so that the tire surface defect detection algorithm does notconsist of a complex algorithm pipeline. and conducted a comparative experiment between the general normalization method and thenormalization method suggested in this paper using YOLO V3, which could satisfy both detection performance and speed. As a resultof the experiment, it is confirmed that the normalization method proposed in this paper improved performance by about 7% based onmAP 0.5, and the method proposed in this paper is effective."
Real-time Steel Surface Defects Detection Appliocation based on Yolov4 Model and Transfer Learning,2022,"['Surface Defects', 'Object Detection', 'YOLOv4', 'real-time detection', '표면 결함', '물체 검출', '욜로', '실시간 검출']",,"Steel is one of the most fundamental components to mechanical industry. However, the quality of products are greatly impacted by the surface defects in the steel. Thus, researchers pay attention to the need for surface defects detector and the deep learning methods are the current trend of object detector. There are still limitations and rooms for improvements, for example, related works focus on developing the models but don’t take into account real-time application with practical implication on industrial settings. In this paper, a real-time application of steel surface defects detection based on YOLOv4 is proposed. Firstly, as the aim of this work to deploying model on real-time application, we studied related works on this field, particularly focusing on one-stage detector and YOLO algorithm, which is one of the most famous algorithm for real-time object detectors. Secondly, using pre-trained Yolov4-Darknet platform models and transfer learning, we trained and test on the hot rolled steel defects open-source dataset NEU-DET. In our study, we applied our application with 4 types of typical defects of a steel surface, namely patches, pitted surface, inclusion and scratches.Thirdly, we evaluated YOLOv4 trained model real-time performance to deploying our system with accuracy of 87.1 % mAP@0.5 and over 60 fps with GPU processing."
뉴노멀 시대 MZ세대의 라이프스타일 변화 유형에 관한 연구,2022,"['뉴노멀', 'MZ세대', '라이프스타일', 'Q 방법론', 'New Normal', 'Generation MZ', 'Lifestyle', 'Q Methodology']","본 논문은 Q 방법론과 MBTI 유형 이론을 적용하여 팬데믹 이후 뉴노멀 시대의 MZ세대 라이프스타일 변화 유형을 탐색한 해석적 연구이다. 전 세계적으로 MZ세대가 주력 소비자층이자 사회계층으로 위상이 높아지고 새로운 트렌드를 주도하면서 관련 연구도 증가하는 추세이다. ‘팬데믹이 나의 라이프스타일을 어떻게 변화시켰는가’의 연구문제에 대해 Q 모집단 진술문으로부터 최종 34개의 Q 표본을 구성하였고, 16개의 MBTI 유형별로 선정된 총 31명의 P 표본 응답자들이 Q 분류에 참여하였다. 가설생성적 Q 연구를 통한 데이터 분석 결과, 4개의 유형을 발견하였다. 제1유형은 집콕템(실내생활을 즐기기 위한 아이템) 가치소비 형, 제2유형은 헬시라이프 챌린저(healthy-life challenger) 형, 제3유형은 횰로(H-YOLO) 형, 제4유형은 카우치 포테이토(couch potato) 형으로 명명하였다. 본 연구는 MZ세대의 자아개념을 기초한 라이프스타일 변화 유형의 개념 및 특성을 이론화함으로써 후속 연구나 실용적 활용의 선험적 기초자료가 될 것으로 기대한다.","This interpretative Q study aims at exploring typologies of the MZ’s lifestyle change according to respondents’ MBTI types under the pandemic environment in the new normal era. As the millenials and generation Z become a major social class or consumer group in the market worldwide, related academic studies also tend to increase. Different from previous generations, their consumption behavior and lifestyle are creating new trends. 31 P-sample respondents for each of the 16 MBTI types participated in the Q-sorting of 34 Q samples collected from Q-population statements on ‘How the pandemic has changed my lifestyle?’. As a result, four types were discovered as a result of data analysis based on abductory Q research. The first type was named the value consumption of ‘Zipcoktem’ (A term referring to items necessary to enjoy indoor life) type, the second type is a healthy-life challenger, the third type was named H-YOLO tribe, and the last is couch potato type. The new theoretical definition of this study can contribute as the basis for further researches or industrial application."
Lightweight object detection network model suitable for indoor mobile robots,2022,"['Indoor mobile robot', 'Real-time performance', 'SSD network model', 'ShuffleNet network', 'S-SSD lightweight network model']",,"This work proposes a lightweight object detection network model ShuffleNetSSD (S-SSD) to solve the problem of single shot multibox detector (SSD) network model where it cannot meet the real-time performance requirement in the task of object detection and recognition of indoor mobile robot. This model is suitable for indoor mobile robot by improving the SSD network model based on ShuffleNet network. The main idea of the improvement is that SSSD replaces VGG-16 network as the basic feature extraction network of SSD network model with ShuffleNet network. The proposed model is based on the design of deep separable convolution, point-by-point grouping convolution, and channel rearrangement. It retains the design idea of multiscale feature graph detection of SSD network model. This model ensures a slight decline in detection accuracy while greatly reduces the amount of computation generated by the network operation, thereby greatly improving the detection rate. A data set for the task of object detection and recognition of indoor mobile robot is made. The S-SSD lightweight network model is superior to the original SSD network model and tiny-YOLO lightweight network model in terms of detection accuracy and detection rate, and can simultaneously meet the requirement of detection accuracy and real-time performance in the task of indoor object detection and recognition of mobile robot. These findings are verified through the comparative experiments of object detection accuracy and detection rate and real-time object detection and recognition of mobile robot under the actual indoor scene."
