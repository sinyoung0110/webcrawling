title,date,keywords,abstract,multilingual_abstract
YOLO-v5를 이용한 등검은말벌집 탐색 기술 연구,2022,"['Artificial intelligence', 'Vespa velutina nest', 'Detection']",국문 초록 정보 없음,"Vespa velutina, such as ecological disturbance wildlife introduced into Busan through Shanghai, China in 2003, is an ecologicla disturbance wildlife and difficult to find with the naked eye due to the nature of creating wasp nests in high places in the forest. In addition, its population increases every year, causing the economical damage to beekiipers (about 170 billion won).Therefore, the purpose of this study is to acquire images and explore the location of Vespa velutina based on artificial intelligence (AI) to easily remove Vespa velutina using drones.Differently from the ground images, aerial images have the characteristic that the objects become very small as the altitude rises, so it is necessary to study the appropriate image size that can be mounted on drones and can search Vespa velutina with AI. The AI model YOLO-v5 using four image sizes (640×384 px, 1,280×736, 1,920×1,088, 3,840×2,176) was applied in this study and the original size of the image (3,840×2,160) was used for learining and verification.When confidence was higher than 0.7, F1 score of YOLO-v5s-default (640) learned with image size 640×384 was 2.4%, YOLO-v5s-1280 was 36.5%, YOLO-v5s-1920 was 64.2% and YOLOv5s- 3840 obtained the best detection performance at 96.1%. In addition, the performance was confirmed when the verification image size was 3,840×2,176 in four AI learned with different image sizes. In this case, YOLO-v5s-default (640) had F1 score of 4.4%, YOLO-v5s-1280 was 7.1% and YOLO-v5s-1920 was 16.4% with no performance improvement. Therefore, this study found that the networks that are learned and validated using the aerial images larger than 640 showed the better performance. Continuous research on real-time information sharing and estimation of the location of the occurrence of Vespa velutina through data collection using drone systems will be carried out."
실내 방범 로봇에서 YOLO와 VMD를 활용한 실내 침입자 탐지,2022,"['Intruder detection', 'Autonomous robots', 'Motion detection']",국문 초록 정보 없음,"Today, security has become an important issue in all areas of life. Recently, the intruder response method is changing to using CCTV or thermal imaging equipment to search for intruders with a small number of people and respond to security companies when they are caught. However, the fixed CCTV has the disadvantage that it can respond to intrusions only in a limited area and there may be blind spots.Therefore, in this paper, we propose an indoor intruder detection system through YOLO and VMD based on an indoor crime prevention robot capable of autonomous driving to solve the shortcomings of the existing fixed CCTV. The autonomous driving of the robot proceeds by sequentially moving the coordinates designated by the manager through the multi-point cruise function. Using the YOLO v3 Tiny model that can be used even in low-spec environments among various YOLO models, if an object corresponding to the Person class is detected, it is determined as the first intruder detection. VMD detects the movement of an object by comparing the three frames, and when a movement is detected, it is finally determined as an intruder. An experiment was conducted to compare the mAP and FPS of YOLO v3 and YOLO v3 Tiny, and it was confirmed that the FPS of YOLO v3 Tiny was 223, far superior to YOLO v3."
YOLO에 기반한 유해 야생동물 피해방지 및 퇴치 시스템 구현,2022,"['Wild animals', 'AI-based image analysis', 'YOLO(You Only Look Once', 'High-luminance LEDs', 'Ultrasonic Frequency Speakers', '야생동물', 'AI기반 영상분석', 'YOLO', '고휘도 LED', '초음파 스피커']","해마다 야생동물이 인간의 거주지에 출몰하는 횟수가 증가하여 재산 및 인명 피해가 증가하고 있다. 특히, 고속도로나 농가에 야생동물이 출몰하는 경우에 그 피해가 더 심하다. 이런 문제점을 해결하기 위해 고속도로에는 생태통로와 유도펜스를 설치하였다. 또한, 농가에서도 문제를 해결하기 위해 센서를 이용한 경적 퇴치기, 그물망 설치, 배설물로 퇴치 하는 등방법을 쓰고 있으나 고가의 비용이 들며 그 효과가 높지 않다. 본 논문에서는 AI 기반 영상분석 방법인 YOLO(You Only Live Once)를 이용하여 유해동물을 실시간 분석하여 오작동을 줄였고, 퇴치장치로 고휘도 LED와 초음파 주파수 스피커를 이용였다. 스피커는 동물들만 들을 수 있는 가청주파수를 출력하여 야생동물만 퇴치하도록 효율성을 높였다. 제안하는 시스템은, 경제적으로 설치할 수 있도록 범용 보드를 사용하여 설계되어 있으며 기존의 센서를 이용한 장치들보다 감지 성능이 높다.","Every year, the number of wild animals appearing in human settlements increases, resulting in increased damage to property and human life. In particular, the damage is more severe when wild animals appear on highways or farmhouses. To solve this problem, ecological pathways and guide fences are being installed on highways. In addition, in order to solve the problem in farms, horn repelling using sensors, installing a net, and repelling by smell of excrement are being used. However, these methods are expensive and their effectiveness is not high. In this paper, we used YOLO (You Only Look Once), an AI-based image analysis method, to analyze harmful animals in real time to reduce malfunctions, and high-brightness LEDs and ultrasonic frequency speakers were used as extermination devices. The speaker outputs an audible frequency that only animals can hear, increasing the efficiency to only exterminate wild animals. The proposed system is designed using a general-purpose board so that it can be installed economically, and the detection performance is higher than that of the devices using the existing sensor."
카메라 영상의 기하학적 해석을 통한 YOLO 알고리즘 기반 해상물체탐지시스템 개발에 관한 연구,2022,"['자율운항선박', '물표탐지', 'YOLO', '기하학', '카메라 캘리브레이션', 'Autonomous ship', 'Object detection', 'YOLO', 'Geometry', 'Camera calibration']","자율운항선박이 상용화되어 연안을 항해하기 위해서는 해상의 장애물을 탐지할 수 있어야 한다. 연안에서 가장 많이 볼 수 있는 장애물 중의 하나는 양식장의 부표이다. 이에 본 연구에서는 YOLO 알고리즘을 이용하여 해상의 부표를 탐지하고, 카메라 영상의 기하학적 해석을 통해 선박으로부터 떨어진 부표의 거리와 방위를 계산하여 장애물을 시각화하는 해상물체탐지시스템을 개발하였다. 1,224장의 양식장 부표 사진으로 해양물체탐지모델을 훈련시킨 결과, 모델의 Precision은 89.0%, Recall은 95.0% 그리고 F1-score는 92.0%이었다. 얻어진 영상좌표를 이용하여 카메라로부터 떨어진 물체의 거리와 방위를 계산하기 위해 카메라 캘리브레이션을 실시하고 해상물체탐지시스템의 성능을 검증하기 위해 Experiment A, B를 설계하였다. 해상물체탐지시스템의 성능을 검증한 결과 해상물체탐지시스템이 레이더보다 근거리 탐지 능력이 뛰어나서 레이더와 더불어 항행보조장비로 사용이 가능할 것으로 판단된다.","For autonomous ships to be commercialized and be able to navigate in coastal water, they must be able to detect maritime obstacles. One of the most common obstacles seen in coastal area are the farm buoys. In this study, a maritime object detection system was developed that detects buoys using the YOLO algorithm and visualizes the distance and bearing between buoys and the ship through geometric interpretation of camera images. After training the maritime object detection model with 1,224 pictures of buoys, the precision of the model was 89.0%, the recall was 95.0%, and the F1-score was 92.0%. Camera calibration had been conducted to calculate the distance and bearing of an object away from the camera using the obtained image coordinates and Experiment A and B were designed to verify the performance of the maritime object detection system. As a result of verifying the performance of the maritime object detection system, it can be seen that the maritime object detection system is superior to radar in its short-distance detection capability, so that it can be used as a navigational aid along with the radar."
YOLO 기반 꿀벌 응애 인식 딥러닝 모델 개발,2022,"['YOLO', '객체 인식', '꿀벌 응애', '모니터링', '스마트 양봉']","꿀벌 응애는 양봉 유해 해충으로 꿀벌 및 애벌레에 기생하는 진드기다. 짧은 생애 주기를 가진 응애는 발생시 관리자의 방제가 없다면 봉군을 붕괴시킬 수 있다. 또한 날개기형바이러스의 전파자 및 꿀벌 군집붕괴현상의 주요한 원인으로 추정된다. 체외에서 기생하는 꿀벌 응애는 내검활동시 발견될 수 있지만 1.1 mm x 1.6 mm의 작은 크기와 보호색으로 인해 육안 식별의 한계가 존재한다. 최근 응애 식별을 위해 영상 기반의 연구가 시도되고 있으나 현장 측정 데이터가 아닌 공공데이터를 사용하거나 벌통 입구 측정 데이터에 국한되는 한계가 존재한다. 따라서, 본 연구에서는 YOLO 기반 꿀벌응애 인식 알고리즘을 개발하고자 한다. 전처리 방법에 따른 영상 데이터의 픽셀 및 특징수 변화를 바탕으로 최적의 전처리 방법을 구명하고 적용 전/후의 데이터에 따른 객체 인식 알고리즘의 성능을 비교하고자 한다. 사용된 데이터셋은 전라북도 완주군 국립농업과학원과 강원도 춘천시의 양봉 농가에서 획득한 영상 데이터로 구축되었다. 데이터셋 왜곡 보정에 따른 이미지, 꿀벌 및 꿀벌 응애의 이미지로 구성되었다. 이미지의 픽셀을 측정하기 위해 ImageJ(National Institutes of Health, USA)가 사용되었으며 왜곡 보정 유무에 따른 픽셀수 변화를 분석했다. 또한 색상 모델 변경, 히스토그램 정규화 및 평활화 방법에 따른 30개 경우에 대해 특징점 검출 알고리즘 Oriented FAST and Rotated BRIEF(ORB)를 적용하여 특징점 검출 성능을 비교했다. 가장 높은 특징점 검출 성능이 나타난 영상처리 방법이 적용된 데이터와 원본 데이터에 객체 인식 알고리즘 YOLO를 적용하고 인식 성능을 비교했다. 그 결과 꿀벌 응애 인식 부분에서 전처리된 데이터의 객체인식 모델이 원본 데이터 기반의 인식 모델보다 우수한 성능을 보였다.",다국어 초록 정보 없음
NRP-Sys: YOLO 기반 동일 물체 분리 검출을 위한 비선형 회귀 예측 시스템,2022,"['deep learning', 'object detection', 'regression', 'prediction', 'YOLO', '.']","최근 4차 산업혁명이 가속됨에 따라 딥러닝은 제조업과의 융합이 두드러지고 있다. 제조업의 공정 과정은 대부분 수동적인 작업으로 이루어지고 있고 숙련된 작업자에 의존도가 매우 높다. 그로 인해 사람에 의한 실수나 오류 때문에 작업의 속도와 생산성이 저하되고 있다. 이러한 실수를 보완하기 위해서 딥러닝의 기술을 접목하여 개선을 할 수 있다. 본 논문에서는 YOLO 기반 철근 끝점 인식 및 추적을 통한 자동 철근 교정 작업을 하는 철근 끝점 예측 검출 모델 NRP-Sys(Nonlinear Regression Prediction System)를 제안한다. 비전 카메라로부터 철근 끝점 검출 및 추적을 수행한다. 이를 통해 수집한 좌표 정보를 회귀 분석 중 급격한 변화에 덜 민감한 2차 회귀 함수로 끝점 위치를 예측한다. 제안하는 방법은 둘 이상의 끝점의 시작점을 설정하여 위치를 분리하고 각각을 예측하는 방법으로 예측값과 실제값을 비교하여 out-cell의 평균 정확도 94.51%, in-cell의 평균 정확도 95.53%를 보인다.","As the 4th Industrial Revolution accelerates recently, convergence with the manufacturing industry is emerging. Most of the manufacturing process processes are passive and highly dependent on skilled workers. As a result, the speed and productivity of work are deteriorating due to human mistakes or errors. In order to compensate for these mistakes, improvement can be made by combining deep learning technology. In this paper, we propose a reinforcement endpoint prediction detection model NRP-Sys(Nonlinear Regression Prediction System) that automatically corrects rebar through YOLO-based reinforcement endpoint recognition and tracking. The reinforcement endpoint is detected and tracked from the vision camera. Through this, the location of the endpoint is predicted with a quadratic regression function that is less sensitive to rapid changes during regression analysis. The proposed method shows 94.51% average accuracy of out-cell and 95.53% average accuracy of In-cell by comparing the predicted and actual values by setting the starting point of two or more endpoints to separate locations and predicting each."
YOLO 기반 금속 외관 결함영역 검출,2022,"['금속 외관', '결함 검출', '객체 검출', '합성곱신경망', '딥러닝', 'Metal Surface', 'Detection of Defects', 'Object Detection', 'Convolution Neural Network', 'Deep Learning']","최근 다양한 분야에 딥러닝 기술이 도입되었고, 특히 영상 처리에 특화된 합성곱신경망(CNN: Convolutional Neural Network)이 많이 활용되고 있다. 금속 외관의 결함영역을 검출하는 많은 응용 분야(예를 들어, 스마트 제조 및 스마트팩토리 분야)에서도 합성곱신경망을 활용한 연구가 활발하게 이루어지고 있다. 본 논문에서는 합성곱신경망 기반 객체 검출(Object Detection) 알고리즘 중 하나인 YOLOv4(YOLO 알고리즘의 4번째 버전)를 활용하여 금속 외관의 결함영역을 검출하는 연구를 수행하고자 한다. 특히, 본 논문에서는YOLOv4 네트워크 구조에 여러 후처리 기법들과 전이 학습을 적용하여 향상된 검출 성능을달성하는 방안을 제안한다. 두 가지 종류의 학습데이터셋((i)공용 데이터셋과 (ii)실측 데이터셋)에 대한 실험을 통해 제안한 방법의 성능을 검증하고 분석한다. 또한 성능 검증을 통해공용 데이터셋과 실측 데이터셋에서의 후처리 기법 및 전이학습에 대한 최적의 조합을 도출하였다.",다국어 초록 정보 없음
YOLO 기반 전동 킥보드 사진 인식 시스템 개발,2022,[],"최근 편리성과 경제성 등의 이유로 개인형 이동장치인 전동 킥보드의 사용이 증가하고 있다. 사용자들은 앱으로 주변의 전동 킥보드 위치를 확인한 뒤, 가까운 기기를 찾아 이용한다. 하지만 전동 킥보드의 위치는 GPS로 표시되기 때문에 10 m 이상의 오차가 날 수 있다. 이를 보완하기 위해 ㈜올룰로의 킥고잉은 사용자가 전동 킥보드 반납 시 촬영한 전동 킥보드 사진을 GPS 위치 정보와 함께 제공한다. 이 사진을 통해 다음 사용자는 더욱 정확히 전동 킥보드를 찾을 수 있다. 하지만 일부 사용자들은 전동 킥보드가 존재하지 않는 사진을 올리기도 하며, 따라서 사용자들이 촬영한 사진 중 실제 전동 킥보드가 존재하는 사진들만 제공하는 것은 매우 중요하다. 따라서 본 논문은 사용자들이 촬영한 사진 중 실제 전동 킥보드가 존재하는 사진들만 정확히 인식하는 YOLO 기반 시스템을 개발한다. 제안 방법은 (1) 전동 킥보드를 부분별로 탐지하는 기법과 (2) 전동 킥보드를 촬영된 각도에 따라 세분화하여 인식하는 기법을 사용한다. 실제 사용자들이 촬영한 사진을 사용한 실험 결과, 제안 방법은 기존 방법에 비해 더욱 정확히 전동 킥보드 사진을 인식하는 것을 확인하였다.",다국어 초록 정보 없음
YOLO 기반 딥러닝 객체 인식 무인계산대 개발에 관한 연구,2022,[],"우리는 일상 속에서 다양한 결제시스템을 접할 수 있다. 그중 무인계산 시스템은 소비자가 구매부터 결제까지 스스로 하는 방식이다. 발전된 기술이 편리함을 제공하지만, 일부 소비자들은 오히려 사용에 어려움을 겪고 사람이 계산을 해주는 기존의 시스템을 선호하는 경우가 많다. 본 논문에서는 소형 IOT 기기와 딥러닝 객체 인식 시스템을 기반으로 한 무인계산대를 설계하고 개발하였다. 계산대의 모습을 구현하기 위해 아두이노 컨베이어 벨트를 이용하고 라즈베리 파이와 파이 카메라를 이용하여 객체 인식 환경을 구현하였다. 파이카메라를 통해 영상을 인식하고 해당 영상을 실시간으로 전송하여 PC에서 YOLO를 통해 객체를 탐지한다. 이후 탐지된 객체는 소비자가 확인할 수 있도록 디스플레이에 시각화한다. 본 논문에서 제안한 딥러닝 객체 인식 무인계산 시스템은 공산품이 주를 이루는 무인상점에 활용할 수 있다.",다국어 초록 정보 없음
유통과정 작물의 질병 분류를 위한 YOLO 기반 객체탐지,2022,"['crop disease detection', 'computer vision', 'object detection']",국문 초록 정보 없음,"Most agricultural products in South Korea are cultivated in the open field and delivered to customers through the distribution channels. It is important to ensure that crops are not susceptible to pests and diseases during delivery. In this paper, we propose to detect diseases of crops in earlier time by using YOLOv4, which is a real-time object detection algorithm, to ensure the freshness of crops. We compared the proposed detector with the YOLOv3-based detector in terms of the accurate performance. The experimental results addressed that the proposed method clearly detects the types and stages of chili pepper diseases. We expect that the proposed approach can be used for a fast and accurate freshness monitoring system."
Yolo-v4 기반 초저지연 차량 식별과 통행량 추적 정밀도 개선,2022,"['cooperative driving infra sensor', 'deep learning', 'object detection', 'object tracking', 'self driving', '협력주행 인프라 센서', '딥러닝', '객체 검출', '객체 추적', '자율주행']","자율주행 기술의 고도화 및 상용화에 따라 차량 자체 센서의 인지 범위의 확장을 위한 인프라 기반 협력주행기술에 대한 수요가 증가하고 있다. 특히 노변에 설치되어 교통 상황을 실시간으로 파악하고 기록하여 차량에 제공할 수 있는 엣지 인프라 기술 연구가 활발하게 진행되고 있으며, 정보 수집을 위한 센서에 대한 연구가 활발한 상황이다. 이러한 흐름에 따라, 최근 CNN 기반의 영상분석을 통한 교통정보 수집 기술에 대한 연구도 활발히 진행되고 있는데, 이러한 CNN 기반의 알고리즘은 영상 내의 외양 특징을 기반으로 개별 객체를 식별할 수 있어 자율주행 자동차에서 인식하지 못하는 도로상의 객체 정보를 제공할 수 있어 인프라 구축에 활용이 가능할 것으로 주목받고 있다. 하지만 기존 C-ITS 사업 대부분은 딥러닝 알고리즘의 높은 요구 연산량으로 인하여 영상분석을 현장이 아닌 센터의 높은 사양 서버에서 처리하고 있는데, 이는 인프라 시스템에서의 정보 제공 지연에 따른 사고의 발생 위험을 증대시킬 위험이 있다. 따라서 이러한 위험을 최소화하기 위해서는 센터가 아닌 노변에서의 실시간 영상분석을 통해 통신 지연을 최소화할 필요가 있다. 본 연구에서는 노변에 위치하여 실시간으로 영상을 분석하여 도로에 위치한 객체 정보를 산출할 수 있는 차량검지 시스템을 설계하였으며, 알고리즘의 노변 환경 적용을 위해 신경망의 구성을 간소화하여 딥러닝 연산량을 줄일 수 있는 방법을 제시한다.",다국어 초록 정보 없음
Yolo V4 딥러닝 지능기술을 이용한 과일 불량 부위 검출,2022,"['automatic fruit quality screening system', 'fruit’s defective area detection', 'image processing                     technique', 'yolo v4', 'deep learning intelligent technology', '과일 품질 선별시스템', '과일 불량부위 검출', '영상처리 기법', 'Yolo V4', '딥러닝 지능 기술']","과일 품질 자동 선별 시스템에서 흠집이나 부패한 부위가 존재하는 불량 과일을 우선적으로 검출하여 제거하는 작업은 매우 중요하다. 본 연구에서는 기존의 영상처리 기법을 이용하여 불량 부위가 있는 과일 검출하는 방법의 한계점을 극복하기 위하여, 최신 인공지능 기술인 Yolo V4 딥러닝 지능기술을 이용하여 과일 불량 부위를 검출하는 방법을 제안한다. 본 연구에서는 흠집 또는 부패 부위가 존재하는 1,100개의 불량 사과 및 1,300개의 불량 배를 포함한 총 2,400개의 불량 과일에 대하여 Yolo V4 딥러닝 모델을 사용하여 학습하고 불량 부위 검출 실험을 하였다. 성능 실험 결과에 따르면 사과의 정확률은 0.80, 재현율은 0.76,  IoU는 69.92%, mAP는 65.27%이고, 배의 정확률은 0.86, 재현율은 0.81,  IoU는 70.54%, mAP는 68.75%의 성능을 나타내었다. 본 연구에서 제안한 방법은 기존 영상처리 기법을 이용한 방법보다 불량 부위가 있는 과일을 실시간으로 정확하게 선별하여 기존 과일 자동 품질 선별시스템의 성능을 획기적으로 개선할 수 있다.","It is very important to first detect and remove defective fruits with scratches or bruised areas in the automatic fruit quality screening system. This paper proposes a method of detecting defective areas in fruits using the latest artificial intelligence technology, the Yolo V4 deep learning model in order to overcome the limitations of the method of detecting fruit’s defective areas using the existing image processing techniques. In this study, a total of 2,400 defective fruits, including 1,000 defective apples and 1,400 defective fruits with scratch or decayed areas, were learned using the Yolo V4 deep learning model and experiments were conducted to detect defective areas. As a result of the performance test, the precision of apples is 0.80, recall is 0.76, IoU is 69.92% and mAP is 65.27%. The precision of pears is 0.86, recall is 0.81, IoU is 70.54% and mAP is 68.75%. The method proposed in this study can dramatically improve the performance of the existing automatic fruit quality screening system by accurately selecting fruits with defective areas in real time rather than using the existing image processing techniques."
"YOLO, EAST: 신경망 모델을 이용한문자열 위치 검출 성능 비교",2022,"['문자열 탐지', 'YOLO', 'EAST', '신경망', 'Scene Text Detection', 'YOLO', 'EAST', 'Neural Network']",국문 초록 정보 없음,"In this paper, YOLO and EAST models are tested to analyze their performance in text area detecting for real-world and normal textimages. The earl ier YOLO models which include YOLOv3 have been known to underperform in detecting text areas for given images,but the recently released YOLOv4 and YOLOv5 achieved promising performances to detect text area included in various images.Experimental results show that both of YOLO v4 and v5 models are expected to be widely used for text detection in the filed of scenetext recognition in the future."
YOLO 알고리즘 기반 국토위성영상의 선박 모니터링 가능성 평가 연구: 부산 신항과 캘리포니아 오클랜드항을 대상으로,2022,"['Ship detection', 'Ship classification', 'CAS500-1', 'KOMPSAT-3', 'AIS', 'YOLO']",국문 초록 정보 없음,"Maritime transport accounts for 99.7% of the exports and imports of the Republic of Korea; therefore, developing a vessel monitoring system for efficient operation is of significant interest. Several studies have focused on tracking and monitoring vessel movements based on automatic identification system (AIS) data; however, ships without AIS have limited monitoring and tracking ability. High-resolution optical satellite images can provide the missing layer of information in AIS-based monitoring systems because they can identify non-AIS vessels and small ships over a wide range. Therefore, it is necessary to investigate vessel monitoring and small vessel classification systems using high-resolution optical satellite images. This study examined the possibility of developing ship monitoring systems using Compact Advanced Satellite 500-1 (CAS500-1) satellite images by first training a deep learning model using satellite image data and then performing detection in other images. To determine the effectiveness of the proposed method, the learning data was acquired from ships in the Yellow Sea and its major ports, and the detection model was established using the You Only Look Once (YOLO) algorithm. The ship detection performance was evaluated for a domestic and an international port. The results obtained using the detection model in ships in the anchorage and berth areas were compared with the ship classification information obtained using AIS, and an accuracy of 85.5% and 70% was achieved using domestic and international classification models, respectively. The results indicate that high-resolution satellite images can be used in mooring ships for vessel monitoring. The developed approach can potentially be used in vessel tracking and monitoring systems at major ports around the world if the accuracy of the detection model is improved through continuous learning data construction."
YOLO v2를 이용한 항공영상에서의 태양광 발전 시설 객체 탐지,2022,"['딥러닝', '태양광 발전 시설', '토지이용', '항공영상', 'YOLO v2']","최근 신재생에너지 발전 비중을 높이기 위해 정부에서는 다양한 지원책을 추진하였으며, 그 결과 급격하게 증가한 태양광 시설로 인해 환경·생태계 훼손 논란을 비롯하여 지역 주민의 민원이 증가하고 있다. 태양광 시설 입지 적합성 및 문제점을 파악하기 위해서는 선행적으로 농촌 시설 현황 모니터링이 필요하다. 그러나 현재 태양광 발전 시설의 설치 현황에 관한 공간정보의 데이터 구축이 아직은 미흡하여 농촌 지역의 토지이용 모니터링에 활용하기에 어려움이 있다. 본 연구에서는 농촌 지역에 설치된 태양광 시설을 탐지하기 위해 인터넷에서 제공되는 고해상도 항공영상에 딥러닝 기술을 적용하여 태양광 시설 설치 여부를 판단하는 연구를 수행하였다. 딥러닝 모델 중 YOLO(You Only Look Once) v2 객체 검출기를 훈련하여 생성된 태양광 시설 검출기를 영상 분석에 활용하였다. 농촌지역에 분포하는 소규모 태양광 시설을 대상으로 AI 분석법을 적용하기에 적합한 최소한의 데이터 셋과 항공 영상의 축척의 크기를 산정하기 위해 축척이 1:5000에서 1:10000 규모인 항공 영상 이미지 약 800장을 수집하여 학습데이터를 구축하고, 이를 바탕으로 태양광 시설 탐지 모델을 생성하였다. 본 연구에서 적용한 모델중 가장 높은 성능을 보인 태양광 시설 객체 탐지 검출률은 약 93%로 나타났다. 향후 학습데이터의 양적인 보완을 통해 영상 분류모델의 객체 탐지 성능을 향상시켜 농촌 지역에 분포하는 다양한 농업시설물을 대상으로 토지이용 현황을 모니터링하는 데 활용하고자 한다.",다국어 초록 정보 없음
YOLO v2를 이용한 항공영상에서의 태양광 발전 시설 객체 탐지,2022,"['딥러닝', '태양광 발전 시설', '토지이용', '항공영상', 'YOLO v2']","최근 신재생에너지 발전 비중을 높이기 위해 정부에서는 다양한 지원책을 추진하였으며, 그 결과 급격하게 증가한 태양광 시설로 인해 환경·생태계 훼손 논란을 비롯하여 지역 주민의 민원이 증가하고 있다. 태양광 시설 입지 적합성 및 문제점을 파악하기 위해서는 선행적으로 농촌 시설 현황 모니터링이 필요하다. 그러나 현재 태양광 발전 시설의 설치 현황에 관한 공간정보의 데이터 구축이 아직은 미흡하여 농촌 지역의 토지이용 모니터링에 활용하기에 어려움이 있다. 본 연구에서는 농촌 지역에 설치된 태양광 시설을 탐지하기 위해 인터넷에서 제공되는 고해상도 항공영상에 딥러닝 기술을 적용하여 태양광 시설 설치 여부를 판단하는 연구를 수행하였다. 딥러닝 모델 중 YOLO(You Only Look Once) v2 객체 검출기를 훈련하여 생성된 태양광 시설 검출기를 영상 분석에 활용하였다. 농촌지역에 분포하는 소규모 태양광 시설을 대상으로 AI 분석법을 적용하기에 적합한 최소한의 데이터 셋과 항공 영상의 축척의 크기를 산정하기 위해 축척이 1:5000에서 1:10000 규모인 항공 영상 이미지 약 800장을 수집하여 학습데이터를 구축하고, 이를 바탕으로 태양광 시설 탐지 모델을 생성하였다. 본 연구에서 적용한 모델중 가장 높은 성능을 보인 태양광 시설 객체 탐지 검출률은 약 93%로 나타났다. 향후 학습데이터의 양적인 보완을 통해 영상 분류모델의 객체 탐지 성능을 향상시켜 농촌 지역에 분포하는 다양한 농업시설물을 대상으로 토지이용 현황을 모니터링하는 데 활용하고자 한다.",다국어 초록 정보 없음
조호환경 내 환자 탐지를 위한 YOLO 모델 기반 바운딩 박스 앙상블 기법,2022,[],"조호환경이란 환자의 지속적인 추적 및 관찰이 필요한 환경으로써, 병원 입원실, 요양원 등을 의미한다. 조호환경 내 환자의 이상 증세가 발생하는 시간 및 이상 증세의 종류는 예측할 수 없기에 인력을 통한 상시 관리는 필수적이다. 또한, 환자의 이상 증세 발견 시간은 발병 시점부터의 소요 시간이 생사와 즉결되기에 빠른 발견이 매우 중요하다. 하지만, 인력을 통한 상시 관리는 많은 경제적 비용을 수반하기에 독거 노인, 빈민층 등 요양 비용을 충당하지 못하는 환자들이 수혜받는 것은 어려우며, 인력을 통해 이루어지기 때문에 이상 증세 발병 즉시 발견에 한계를 가진다. 즉, 기존까지 조호환경 내 환자 관리 방식은 경제적 비용과 이상 증세 발병 즉시 발견에 한계를 가진다는 문제점을 가진다. 따라서 본 논문은 YOLO 모델의 조호환경 내 환자 탐지 성능 비교 및 바운딩 박스 앙상블 기법을 제안한다. 이를 통해, 딥러닝 모델을 통한 환자 상시 관리가 이루어지기에 높은 경제적 비용문제를 해소할 수 있다. 또한, YOLO 모델 바운딩 박스 앙상블 기법 WBF를 통해 폐색이 짙은 조호환경 영상 데이터 내에 객체 탐지 영역 정확도 향상 방법을 연구하였다.",다국어 초록 정보 없음
YOLO v2를 이용한 고해상도 항공영상에서의 태양광발전소 탐지 방법 연구,2022,"['Deep learning', 'Solar power plant', 'Land-use', 'Aerial Image', 'YOLO v2']",국문 초록 정보 없음,"As part of strengthening energy security and responding to climate change, the government has promoted various renewable energy measures to increase the development of renewable energy facilities. As a result, small-scale solar installations in rural areas have increased rapidly. The number of complaints from local residents is increasing. Therefore, in this study, deep learning technology is applied to high-resolution aerial images on the internet to detect solar power plants installed in rural areas to determine whether or not solar power plants are installed. Specifically, I examined the solar facility detector generated by training the YOLO(You Only Look Once) v2 object detector and looked at its usability. As a result, about 800 pieces of training data showed a high object detection rate of 93%. By constructing such an object detection model, it is expected that it can be utilized for land use monitoring in rural areas, and it can be utilized as a spatial data construction plan for rural areas using technology for detecting small-scale agricultural facilities."
딥러닝 모델에서 포트홀 데이터셋의 성능 향상을 위한 전처리 방법 제안과 YOLO 모델을 통한 검증,2022,"['포트홀 탐지', '전처리', 'YOLO', 'Superpixel', 'Sobel Edge detection', 'Intensity transformation', 'Pothole detection', 'Pre-processing', 'YOLO', 'Superpixel', 'Sobel edge detection', 'Intensity transformation']","포트홀은 아스팔트 포장도로의 구조적 결함을 나타내는 중요한 단서임과 동시에 많은 인명 피해와 재산 피해를 일으킨다. 따라서 정확한 포트홀 탐지는 도로 표면의 유지보수에 있어서 중요한 과제이다. 포트홀 탐지를 위해 많은 머신러닝 기술이 도입되고 있으며 딥러닝 모델의 효율성을 높이기 위해 데이터 전처리가 필요하다. 본 논문에서는 포트홀 데이터셋에서 중요한 질감과 형태를 강조하는 전처리 방법을 제안한다. 제안된 전처리 방법은 Intensity transformation을 사용해 도로의 불필요한 요소를 줄이고 포트홀의 질감과 형태를 부각한다. 또한 Superpixel, Sobel edge detection을 사용해 포트홀의 특징을 검출한다. 제안된 전처리 방법과 기존의 전처리 방법의 성능 비교를 통해 포트홀 검출에서 제안된 전처리 방법이 기존 방법보다 더 효과적인 방법이라는 것을 보여준다.","Potholes are an important clue to the structural defects of asphalt pavement and cause many casualties and property damage. Therefore, accurate pothole detection is an important task in road surface maintenance. Many machine learning technologies are being introduced for pothole detection, and data preprocessing is required to increase the efficiency of deep learning models. In this paper, we propose a preprocessing method that emphasizes important textures and shapes in pothole datasets. The proposed preprocessing method uses intensity transformation to reduce unnecessary elements of the road and emphasize the texture and shape of the pothole. In addition, the feature of the porthole is detected using Superpixel and Sobel edge detection. Through performance comparison between the proposed preprocessing method and the existing preprocessing method, it is shown that the proposed preprocessing method is a more effective method than the existing method in detecting potholes."
Non-Local Means 잡음 제거와 데이터 증강을 이용한 YOLO 기반 객체 특징 탐색,2022,"['Denoising', 'Crawling', 'Augmentation', 'Object Detection', 'YOLOv3', 'Smart Farms', 'Deep Learning', 'Data Analysis']",국문 초록 정보 없음,"When fruits are harvested in farms, most of them go through a manual sorting process and classify and distribute decomposed fruits.However, there is a limit to manually classifying large amounts in a situation where the number of workers is decreasing in farms.To solve this problem, it is important to divide normal and decomposed fruits in real time to minimize the proportion of manpower used in the screening process. We propose a method of YOLO based Object Features Detection Using Non-Local Means Denoising and Data Augmentation. The proposed method collects desired data through the Crawling method, and the preprocessing minimizes image noise through Non-Local Means Denoising. The built image dataset uses YOLOv3, an object detection algorithm, to distinguish and detect normal and decayed fruits. As a result of performance evaluation, object detection of YOLOv3 objects in a proposed method rather than detection results shows that Recall increases 10% performance and increases 9% in the remaining Recall and IoU. Therefore, the proposed method can increase screening efficiency by detecting decayed fruits well."
욜로(YOLO)족의 체험관광이 관광만족과 행동의도에 미치는 영향: 실존적 진정성 조절효과를 중심으로,2022,"['You Only Live Once', 'Existential authenticity', 'Tourist Satisfaction', 'Behavioral Intention)', '욜로', '실존적 진정성', '관광만족', '행동의도']",국문 초록 정보 없음,"The purpose of this study is to conduct an empirical analysis regarding the effect of experiential tourism on tourism satisfaction and behavioral intention, and the effect of controlling existential authenticity. In order to collect the data of this study, a survey was conducted on those who have traveled domestically and abroad for the past year, and thought of themselves to be YOLO even amongst COVID-19 social distancing measures. As a result of this study, experiential tourism was found to have a significant effect on tourism satisfaction. However, that deviant factors did not have a significant effect. In addition, as a result of verifying the effect of experiential tourism on behavioral intention and the effect of tourism satisfaction on behavioral intention, significant results were found. Finally, according to the results of the analysis of the authenticity control effect, it was found that all experiential tourism had a statistically significant effect on tourism satisfaction."
YOLO 네트워크를 사용한 다중 차선 인식,2022,"['자율주행 차량', '다중 차선 인식', '욜로', 'Autonomous vehichle', 'Multi-Lanes recognition', 'YOLO']",국문 초록 정보 없음,"Future autonomous vehicles need to recognize the ego lanes required for lane change and the side left and right lanes differently. Therefore, multi-lane recognition is needed. In this study, using the YOLO network, mainly used for object recognition, the proposed method recognizes the ego, left and right side lanes as different objects and identifies the correct lanes. As a result of the performance evaluation on the TuSimple test data, the proposed method recognized the ego lanes and the left and right side lanes differently. It showed very stable lane recognition results. And by detecting lanes that do not exist in the ground truth of TuSimple data, the proposed method is very robust in lanes detection. Nevertheless, studies related to learning data reinforcement in which lanes are located in the center or at the left and right edges of the image and accurate network learning for lanes are needed."
YOLO 알고리즘 기반 식재료 인식과 협업 필터링을 이용한 레시피 추천 애플리케이션 설계,2022,"['YOLO', '식재료 인식', '모델 기반 협업 필터링', '레시피 추천']","코로나19로 인하여 배달 빈도수가 높은 힘든 1인가구나 맞벌이가족에게는 식자재의 낭비 및 유통기한 관리의 문제점을 가지고 있다. 이런 문제점을 해결하기 위해 본 논문에서는 사용자가 식재료의 유통기한 을 관리하고 식재료 기반 또는 사용자 행동 양식 기반으로 레시피를 추천 받을 수 있게 해주는 애플리케 이션을 설계한다. 본 애플리케이션은 객체 인식 알고리즘인 YOLO를 이용하여 카메라로 식재료를 인식 하고, 협업 필터링을 이용한 레시피 추천 시스템으로 사용자가 원하는 레시피 정보를 제공한다. 사용자 는 본 애플리케이션을 사용하여 카메라로 식재료를 인식하여 레시피를 검색할 수 있고 사용자의 과거이 력이나 취향에 연관된 레시피를 추천 받을 수 있다.",다국어 초록 정보 없음
YOLO를 활용한 Object Pose Estimation,2022,"['YOLO', 'Object Detection', 'ROS']",국문 초록 정보 없음,다국어 초록 정보 없음
YOLO-based Traffic Signal Detection for Identifying the Violation of Motorbike Riders,2022,"['YOLO Object Detection', 'Traffic Signal Detection', 'Signal Colour Recognition', 'Violation Identification', 'Motorbike Rider']",국문 초록 정보 없음,다국어 초록 정보 없음
원격 운전 시스템에서의 YOLO를 활용한 실시간 객체 감지,2022,"['ToD(Tele-operated Driving)', 'YOLO(You Only Look Once)', 'Perspective projection']",국문 초록 정보 없음,다국어 초록 정보 없음
Yolo-v4 기반 초저지연 차량 식별과 통행량 추적 정밀도 개선,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
Yolo-pose를 이용한 장단기 메모리의 낙상감지 시스템 연구,2022,"['Tensorflow', 'Fall detection', 'The elderly', 'Long short-term memory (LSTM)']",국문 초록 정보 없음,다국어 초록 정보 없음
YOLO를 이용한 모션 블러된 금속 표면 영상의 결함 인식,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
Yolo-v3를 이용한 오토바이 번호판 추출 및 인식에 관한 연구,2022,"['Motorcycles', 'Highway Accident', 'Darknet', 'YOLOv3']",국문 초록 정보 없음,다국어 초록 정보 없음
DETR 과 Yolo-v3 를 사용한 해양 침적 쓰레기 탐지 성능 비교,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
LSTM Autoencoder 신경망을 이용한 YOLO의 오류 탐지,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
Dynamic Beehive Detection and Tracking System Based on YOLO V5 and Unmanned Aerial Vehicle,2022,"['Automatic control', 'Beehive', 'Edge computing', 'Object detection', 'YOLO']",국문 초록 정보 없음,"Purpose With urban development and improvements in human living conditions, wild beehives in densely populated areas present a threat to human safety. The traditional manual method of clear beehives may result in secondary injury to humans.Methods This paper proposes a beehive detection model based on YOLO V5 by introducing the Shufe Block V2 and depthwise separable convolution (DSC) modules to decrease the original model parameters. The model can be deployed on edge computation devices such as Raspberry 4B with good detection accuracy. The PID algorithm and dual servo motors were combined with the object detection model to track the beehive automatically. The results of experiments showed that the inference speed of the improved beehive detection model was 92.5% faster than the original YOLO V5s model, although the detection accuracy and other indicators were not signifcantly diferent.Results The accuracy of the system in this study was as high as 96% in real-time detection, and the maximum recognition distance was 2.5 m. The performance test results of the system deployed on an unmanned aerial vehicle (UAV) showed that 90% of the beehive tracking process could be completed within 2 s, positioning the object in the center of the images collected by the camera. At the same time, when the UAV was moving at random, the detection and tracking system could still follow the beehive quickly and automatically.Conclusion The detection model and tracking system established in this paper provide important support to reduce the secondary damage to the rescue workers that may occur in beehive governance."
A Fine-dust Measurement Method using YOLO Algorithm,2022,"['YOLO', 'CCTV', 'Fine-dust']",국문 초록 정보 없음,다국어 초록 정보 없음
Yolo v2와 특징정보 매칭 기반의 전방 주행 자동차 검출 및 종류 분류 방안 연구,2022,"['Advanced Driver Asistence System(안전운전지원시스템)', 'Intelligent Transportation System(지능형 교통 시스템)', 'Vehicle Detection(자동차 검출)', 'Vehicle Type Classification (자동차 종류 분류)', 'Deep Learning(딥 러닝)', 'Bag of Visual Feature(시각적 특징 정보)']","본 논문에서는 고속도로에서 전방 주행 중인 자동차의 검출과 종류를 실시간으로 분류하는 방안을 제안한다. 제안한 방안에서는 전방 주행인 자동차의 후면 영상들을 획득하여 Yolo v2 딥러닝 방법으로 학습하여 자동차 검출기를 생성한다. 그리고 검출된 자동차 영역에 포함된 자동차종류를 분류하기 위해 자동차 종류 클래스별로 특징 정보를 학습하고 이를 매칭하여 가장 유사도가 높은 클래스인 자동차 종류를 분류한다. 자동차 검출을 위해 고속도로에서 획득한 자동차 영상에서 자동차 영역을 레이블링하여 Yolo v2 딥러닝 알고리즘을 사용하여 학습한 후 자동차 검출기를 생성한다. 그리고 검출된 자동차 영역에 자동차 종류를 분류하기 위해 검출된 자동차 영역에 시각적 특징 정보인 Bag of Visual Feature를 추출하고 이를 학습하여 자동차 종류를 분류하는 방안을 제안한다. 제안한 방안에서는 고속도로에서 전방 주행 중인 자동차를 후방 자동차의 블랙박스에서 획득한 영상으로부터 자동차를 검출하고 종류를 분류함으로써 고속주행 중 자동차 충돌 방지, 안전거리 확보, 자동차추적 및 식별 등에 활용할 수 있다.",다국어 초록 정보 없음
Integrated YOLO and CNN algorithms for Evaluating Degree of Walkway Breakage,2022,"['Walkway', 'YOLO algorithm', 'Image deep learning', 'Breakage detection', 'Walking environment assessment', 'Pedestrian safety', 'Evaluation indicators']",국문 초록 정보 없음,"The focus of policymaking in Korea has changed from vehicle-centric road environments to people-centric environments. As the importance of walking has increased, the construction of pedestrian paths and interest in pedestrian environments have also increased. However, problem recognition and resolution require considerable time in the event of a problem in a pedestrian path. People with reduced mobility tend to resist changes in roads that they use. Thus, damaged pedestrian paths and obstacles pose a considerable risk and economic loss to transportation. In this study, we aimed to minimize the time and cost required for the evaluation of pedestrian paths by developing an automatic system for determining damage using integrated You Only Look Once (YOLO) and convolutional neural network (CNN) image deep learning algorithms. We constructed a model using image deep learning by dividing the steps into walkway breakage detection and score evaluation according to the degree of breakage. The accuracy of the model was determined to be 92%. In the future, the evaluation of pedestrian path damage is expected to be automated using images and videos, thereby reducing the time required for the detection and restoration of damage."
카메라 영상의 기하학적 해석을 통한 YOLO 알고리즘 기반 해상물체탐지시스템 개발에 관한 연구,2022,"['자율운항선박', '물표탐지', 'YOLO', '기하학', '카메라 캘리브레이션/Autonomous ship', 'Object detection', 'YOLO', 'Geometry', 'Camera calibration']",국문 초록 정보 없음,다국어 초록 정보 없음
YOLO v3 라이브러리를 이용한 CCTV 저장공간 확보 모델 제안,2022,"['YOLO v3', '객체탐지(Object Detection)', '객체인식(Object Recognition)', 'CCTV', '컴퓨터비전(Computer Vision)']",국문 초록 정보 없음,다국어 초록 정보 없음
Yolo 기반 고속도로 돌발상황 인식 방법론 도출,2022,"['YOLO', '알고리즘', '객체인식', 'b-box', '고속도로']",국문 초록 정보 없음,다국어 초록 정보 없음
Yolo 기반 고속도로 돌발상황 인식 방법론 도출,2022,"['YOLO', '알고리즘', '객체인식', 'b-box', '고속도로']",국문 초록 정보 없음,다국어 초록 정보 없음
YOLO 네트워크를 이용한 단자 구분,2022,[],"최근 인공지능 기반 객체 탐지 기술이 발전함에 따라 영상 감시, 얼굴 인식, 로봇 제어, IoT, 자율주행, 제조업, 보안 등 다양한 분야에 활용되고 있다. 이에 본 논문은 발전된 객체 탐지 알고리즘을 이용하여 비전문가에겐 생소한 컴퓨터나 전기 장치 등의 단자(terminal) 모양을 구별하는 방법을 제안한다. 이를 위해 객체 탐지 프로그램인 You Only Look Once (YOLO) 알고리즘을 이용하여 입력한 단자들의 모양을 검출하는 알고리즘을 구성하였다. 일상에서 쉽게 볼 수 있는 단자들의 이미지(VGA, DVI, HDMI, DP, USB-A, USB-C)를 라벨링하여 데이터셋을 구축하였고, YOLOv4와 YOLOv5 두 버전의 알고리즘을 사용하여 성능을 검증하였다. 실험 결과 mean Average Precision(mAP) 기준 최대 92.9%의 정확도를 얻을 수 있었다. 전기 장치에 따라 단자의 모양이 다양하고, 그 종류 또한 많기 때문에 본 연구가 방송 기술 등의 여러 분야에 응용될 것으로 기대된다.",다국어 초록 정보 없음
YOLO v3를 활용한 미디어 내 운송기기 탐지 모델 구현,2022,[],"최근 퍼스널 모빌리티의 수요 증가와 공유PM 업체의 등장으로 공유형 모빌리티 관련 사고도 급증하였다. 이를 감소시키기 위해 공유PM 불법 주행 단속을 위한 인력이 투입되었음에도 단속되지 않은 사례가 훨씬 많은 것으로 추정된다. 이러한 문제를 해결하고자 본 연구에서는 미디어 내 운송기기 탐지 모델을 제안한다. 미디어 내 즉각적인 탐지를 위해 빠른 속도와 높은 성능으로 인정받는 YOLO v3를 활용하였으며, 최종적으로 객체 위치 검출 정확도와 클래스 예측값의 곱인 Class Specific Confidence Score는 각 클래스에 대해 0.90, 0.98, 0.93, 0.98을 얻었다.",다국어 초록 정보 없음
CCTV 이미지와 YOLO 를 활용한 도로 객체 인식 모델 개발,2022,[],"CCTV 는 우리의 일상생활에서 흔하게 접할 수 있으며 다양한 장소에서 활용되고 있다. CCTV 설치 대수는 날이 갈수록 급격하게 증가하고 있지만 이를 관리하고 활용하는 인력은 매우 부족한 현실이다. 따라서 CCTV 를 통해 제공되는 이미지를 분석하고 객체를 탐지하여 업무를 자동화 하는 기술이 요구된다. 따라서 본 연구는 CCTV 이미지와 YOLO 를 활용하여 도로 객체 인식 모델을 개발한다. 제안한 모델은 전이 학습을 통해 개발되었으며, 검증데이터에서 40%의 mAP 를 달성하는 것을 확인하였다.",다국어 초록 정보 없음
딥러닝(Deep Learning) 기반의 YOLO v5를 활용한 위장군인 객체 탐지(Object Detection)에 관한 연구,2022,"['딥러닝(Deep Learning)', 'YOLO v5 인공지능', '객체탐지(Object Detection)']",국문 초록 정보 없음,다국어 초록 정보 없음
YOLO 기반의 학술논문 표와 그림 자동 검출 모델,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
YOLO 모델을 이용한 동영상 하이라이트 추출기,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
YOLO 알고리즘을 활용한 해상에서의 항로표지 탐지 및 분류모형 개발,2022,"['항로표지', '물표탐지', '컴퓨터비전', '영상처리', '머신러닝/Aids to Navigation', 'Object Detection', 'Computer Vision', 'Image Processing', 'Machine Learning']",국문 초록 정보 없음,다국어 초록 정보 없음
YOLO 기반 마스크 착용 감지시스템의 성능 비교,2022,[],"본 논문은 이전 연구에서 발생한 실시간으로 마스크 착용 여부를 감지할 때 지연되는 문제점을 해결하고자 YOLOv3-tiny 커스텀 모델을 통해 마스크 착용 감지시스템을 제안하여 성능을 비교하고자 한다. 이전 연구와 동일하게 학습용 이미지 데이터는 500장을 이용하여 이미지 학습을 진행하였다. 실험결과, YOLOv3가 YOLOv3-tiny보다 평균 손실율이 낮게 측정되고 정확도가 높게 나왔다. 향후에는 계속적인 실험을 하여 실험결과를 토대로 성능을 비교하여 확인할 것이며 부가적으로 사람의 체온을 측정하고 마스크 미착용과 발열유무에 따라 음성을 출력하는 최종적인 시제품을 완성 할 예정이다.",다국어 초록 정보 없음
An Improved YOLO model for Large Object Detection for Black Ice Detection,2022,"['Black ice', 'YOLOv5', 'deep learning']",국문 초록 정보 없음,다국어 초록 정보 없음
Vision transformer 와 YOLO 의 잠재변수를 이용한 Glioblastoma 환자군 생존 분석 성능 비교,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
사용자 요구에 따른 YOLO 알고리즘을 이용한 객체 인식,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
가스사고조사 업무 자동화를 위한 YOLO 및 CNN 기반 로봇비젼 알고리즘 개발,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
[지역정책 ➏ 부산광역시] 가즈아~ 부산 YOLO 갈맷길 10,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
회원작품 - 욜로.192,2022,[],국문 초록 정보 없음,다국어 초록 정보 없음
헬멧 착용 여부 및 쓰러짐 사고 감지를 위한 AI 영상처리와 알람 시스템의 구현,2022,"['Convolutional Neural Network (CNN)', 'YOLO', 'Object detection', 'Deep learning', 'Industrial site', '합성곱 신경망', 'YOLO', '객체 검출', '딥러닝', '산업현장']","본 논문은 실시간 영상 분석을 통해서 산업현장에서 활동하는 여러 근로자의 영상 객체를 추출해 내고, 추출된 이미지로 부터 개별 영상 분석을 통해 헬멧의 착용 여부와 낙상 사고 여부를 확인하는 방법을 구현한다. 근로자의 영상 객체를 탐지하기 위해서 딥러닝 기반 컴퓨터 비전 모델인 YOLO를 사용하였으며, 추출된 이미지를 이용하여 헬멧의 착용여부를 판단하기 위해 따로 5,000장의 다양한 헬멧 학습 데이터 이미지를 만들어서 사용하였다. 또한, 낙상사고 여부를 판단하기 위해서 Mediapipe의 Pose 실시간 신체추적 알고리즘을 사용하여 머리의 위치를 확인하고 움직이는 속도를 계산하여 쓰러짐 여부를 판단하였다. 결과에 신뢰성을 주기위한 방법으로 YOLO의 바운딩 박스의 크기를 구하여 객체의 자세를 유추하는 방법을 추가하고 구현하였다. 최종적으로 관리자에게 알림 서비스를 위하여 텔레그램 API Bot과 Firebase DB 서버를 구현하였다.","This paper presents an implementation of detecting whether a helmet is worn and there is a fall accident through individual image analysis in real-time from extracting the image objects of several workers active in the industrial field. In order to detect image objects of workers, YOLO, a deep learning-based computer vision model, was used, and for whether a helmet is worn or not, the extracted images with 5,000 different helmet learning data images were applied. For whether a fall accident occurred, the position of the head was checked using the Pose real-time body tracking algorithm of Mediapipe, and the movement speed was calculated to determine whether the person fell. In addition, to give reliability to the result of a falling accident, a method to infer the posture of an object by obtaining the size of YOLO's bounding box was proposed and implemented. Finally, Telegram API Bot and Firebase DB server were implemented for notification service to administrators."
다중 신경망을 이용한 객체 탐지 효율성 개선방안,2022,"['Tensorflow', 'Darknet', 'YOLO']","기존의 Tensorflow CNN 환경에서 Object 탐지 방식은 Tensorflow 자체적으로 Object 라벨링 작업과 탐지를 하는 방식이다. 그러나 현재 YOLO의 등장으로 이미지 객체 탐지의 효율성이 높아졌다. 그로 인하여 기존 신경망보다 더 많은 심층 레이어를 구축할 수 있으며 또한 이미지 객체 인식률을 높일 수 있다.  따라서 본 논문에서는 Darknet, YOLO를 기반으로 한 Object 탐지 시스템을 설계하고 기존에 사용하던 합성곱 신경망에 기반한 다중 레이어 구축과 학습을 수행함으로써 탐지능력과 속도를 비교, 분석하였다. 이로 인하여 본 논문에서는 Darknet의 학습을 효율적으로 이용하는 신경망 방법론을 제시하였다.","In the existing Tensorflow CNN environment, the object detection method is a method of performing object labeling and detection by Tensorflow itself. However, with the advent of YOLO, the efficiency of image object detection has increased. As a result, more deep layers can be built than existing neural networks, and the image object recognition rate can be increased.  Therefore, in this paper, the detection ability and speed were compared and analyzed by designing an object detection system based on Darknet and YOLO and performing multi-layer construction and learning based on the existing convolutional neural network. For this reason, in this paper, a neural network methodology that efficiently uses Darknet’s learning presented."
실시간 객체추적 알고리즘을 적용한 화재감시 시스템 개발에 관한 연구,2022,"['Realtime', 'Fire recognition', 'Fire detector', 'CCTV', 'YOLO']","화재 발생시 화재를 알리는 화재감지기는 급격한 온도변화를 감지하여 경보가 울리는 시스템으로 일정 온도 이상이 되면 화재경보가 발생하게 된다. 화재는 초기 진압이 중요하며, 화재 골든 타임인 화재 발생 10분 이내 화재진압에 실패하면 화재가 급격히 확산되어 피해 면적이 급증하게 된다. 최근 건축 구조물 내에서 사용되는 스마트 화재 감지 CCTV는 화재와 연기를 인식하여 화재를 탐지하는 방식이 아닌 CCTV에 설치된 온도 감지 센서를 이용하여 주위 온도가 센서의 설정 온도보다 높은 경우에 화재로 판단하여 화재 신호를 알리는 방식이다. 이러한 방식은 CCTV의 실시간 동영상 촬영의 장점을 활용하여 화재를 감지하는 것이 아니고, 단순하게 온도 센서에 의해 화재를 감지하고 화재 현장에 대해서만 동영상을 송출한다. 본 연구에서는 실내용 스마트 화재감지 CCTV의 문제점을 개선하고자 불꽃, 연기, 사람 등의 객체들을 추적하고 인식할 수 있는 YOLO 기반의 알고리즘을 CCTV 등의 실시간 감시장비에 적용하였다. 딥러닝 알고리즘 중 하나인 CNN의 경우 Fast-RCNN이 0.5fps, Faster-RCNN이 7fps 수준인 것에 반해 일반적으로 YOLO 알고리즘은 다른 딥러닝 알고리즘들에 비해 FPS(Frame Per Second)가 높다고 알려져 있다. YOLO의 FPS는 45~155fps 수준이며, 높은 FPS는 초당 얼마나 많은 이미지를 인식하는지를 의미한다. 화재는 초기 발견이 중요한 만큼 FPS 역시 매우 중요한 요소이다. 본 연구에서는 높은 수준의 FPS 객체추적 알고리즘인 YOLO 모델을 적용하여 CCTV등 영상을 이용한 실시간 화재감시 시스템에 관한 연구이다.",다국어 초록 정보 없음
ShortcutFusion++: Optimizing an End-to-End CNN Accelerator for High PE Utilization,2022,"['CNN accelerator', 'Processing element', 'Hardware utilization', 'FPGA', 'YOLO-v3']",국문 초록 정보 없음,"ShorcutFusion [1] is an end-to-end framework that effectively maps many well-known deep neural networks (DNNs), such as MobileNet-v2, EfficientNet-B0, ResNet-50, and YOLO-v3, to a generic CNN accelerator on FPGA. Nevertheless, its processing elements are not fully utilized when supporting various networks, leading to relatively low hardware utilization (e.g., 68.42% for YOLO-v3). This study aimed to enhance the performance of ShortcutFusion and introduce ShortcutFusion++ by proposing two simple but effective techniques for eliminating unnecessary stalls in conventional design. First, the prefetching scheme was re-designed to avoid bubble cycles when feeding data to the PE array. Second, the output buffer was reconstructed to pipeline the operations of PEs and the process of writing output feature maps to off-chip memory. The experimental results show that ShortcutFusion++ achieves a PE utilization of 80.95% for the wellknown object detection network YOLO-v3, outperforming its baseline by 12.53%."
딥러닝을 이용한 병징에 최적화된 딸기 병충해 검출 기법,2022,"['데이터 증강', '빅데이터', '스마트팜', 'CNN', 'YOLO', 'big data', 'CNN', 'data augmentation', 'smart farm', 'YOLO']",본 논문은 딥러닝 알고리즘을 이용하여 딸기 영상 데이터의 병충해 존재 여부를 자동으로 검출할 수 있는 서비스 모델을 제안한다. 또한 병징에 특화된 분할 이미지 데이터 세트를 제안하여 딥러닝 모델의 병충해 검출 성능을 향상한다. 딥러닝모델은 CNN 기반 YOLO를 선정하여 기존의 R-CNN 기반 모델의 느린 학습속도와 추론속도를 개선하였다. 병충해 검출 모델을 학습하기 위해 일반적인 데이터 세트와 제안하는 분할 이미지 데이터 세트를 구축하였다. 딥러닝 모델이 일반적인 학습 데이터 세트를 학습했을 때 병충해 검출률은 81.35%이며 병충해 검출 신뢰도는 73.35%이다. 반면 딥러닝 모델이 분할 이미지 학습 데이터 세트를 학습했을 때 병충해 검출률은 91.93%이며 병충해 검출 신뢰도는 83.41%이다. 따라서 분할 이미지 데이터를 학습한 딥러닝 모델의 성능이 우수하다는 것을 증명할 수 있었다.,"This study aimed to develop a service model that uses a deep learning algorithm for detecting diseases and pests in strawberries through image data. In addition, the pest detection performance of deep learning models was further improved by proposing segmented image data sets specialized in disease and pest symptoms. The CNN-based YOLO deep learning model was selected to enhance the existing R-CNN-based model's slow learning speed and inference speed. A general image data set and a proposed segmented image dataset was prepared to train the pest and disease detection model. When the deep learning model was trained with the general training data set, the pest detection rate was 81.35%, and the pest detection reliability was 73.35%. On the other hand, when the deep learning model was trained with the segmented image dataset, the pest detection rate increased to 91.93%, and detection reliability was increased to 83.41%. This study concludes with the possibility of improving the performance of the deep learning model by using a segmented image dataset instead of a general image dataset."
AI를 이용한 농작물 피해 완화 시스템,2022,"['YOLO', 'Difference Image Technique', 'Notifying to user', 'convenience of crop cultivation']","해가 증가할수록 유해 동물로 인해 농작물 피해가 증가하고 있다. 이를 예방하기 위해 본 논문에서는 AI를 활용한 농작물 피해 완화 시스템을 제안한다. 제안된 시스템에서는 AI, 특히 객체 인식 기술(YOLO)을 활용하여 동물, 새, 사람으로 구분하고 동물 또는 새가 농경지 인근 혹은 내로 침입했을 경우 퇴치 과정을 진행 한다. 학습한 사람, 동물, 새중 동물과 새는 퇴출대상으로 분류되며, 효율적인 탐지를 위해 기존배경과 현재 입력 형상의 차영상을 이용하며 차이 발생 시 YOLO를 실행한다. 퇴치 단계는 1단계 조명 출력, 2단계 퇴치 신호 출력, 3단계 고주파수 출력, 4단계 조명 및 고주파수 출력으로 구분된다. 또한 퇴치 대상 식별 및 퇴치 단계, 퇴치 여부를 실시간으로 어플리케이션을 통해 주인에게 알리는 편의성을 제공한다",다국어 초록 정보 없음
객체인식을 이용한 스마트 북카트 개발,2022,"['object recognition', 'following robot', 'YOLO', 'book cart']",자율주행기술의 발전으로 무인 이동체 기술의 관심이 높아졌다. 이를 실생활에 활용하고자 도서관의 북카트와 무인 이동체를 결합한다. 본 연구는 편리한 서가 정리를 위한 스마트 북카트를 만들기 위해 객체인식을 연구한다. 객체인식 기술인 YOLO는 신뢰도 시스템을 이용한 연산의 간편화로 속도가 빠르다. 실시간 연산처리를 통해 물체의 영상 내 좌표값을 연산하여 항상 가운데에 위치하도록 하여 움직임을 추적한다. 또한 ZED 2i 카메라의 거리 데이터를 이용해 객체와의 거리를 일정하게 유지하도록 한다. 그리고 하단 장애물에 취약한 점을 보안하기 위해 초음파 센서를 이용하여 충돌 방지 기능을 구현한다. 추가적으로 도서관리의 편의성을 제공하기 위해 도서관리 시스템을 구축한다.,"With the development of autonomous driving technology, interest in unmanned vehicle technology has increased. In order to use this in real life, the librarys book cart and unmanned moving objects are combined. This study studies object recognition to create a smart book cart for convenient bookkeeping. YOLO, an object recognition technology, is fast due to the simplification of operations using a reliability system. The movement is tracked by calculating the coordinate value in the image of the object through real-time operation processing and always positioning it in the center. In addition, the distance data of the ZED 2i camera is used to keep the distance from the object constant. In addition, a collision prevention function is implemented using an ultrasonic sensor to secure a vulnerable point to a lower obstacle. In addition, a book management system is established to provide convenience of library."
시각 장애인의 보행 보조를 위한 점자블록 인식 정확도 향상 방안: YOLOv5와 꼭짓점 좌표 분석 활용,2022,"['시각 장애인', '보행 보조', '점자블록', 'YOLO', '꼭짓점', 'visually impaired', 'walking assistance', 'braille block', 'YOLO', 'vertices']","본 논문에서는 시각장애인의 보행에 도움을 주기 위하여 점자블록을 하나의 카메라로 정확하게 인식할 수 있는 정확도 향상 방안을 제안한다. 본 논문은 YOLO와 이진화 처리, 꼭짓점 검출 알고리즘을 조합하여 점자블록을 실시간 검출하여 관심 영역을 추출하는 정확도 향상 기법을 제안한다. 추출된 관심 영역을 정확하고 효율적인 이진화 작업을 수행할 수 있도록 프레임마다 유동적인 색상 범위를 설정함으로써 강인한 이진화 처리가 가능하다. 이진화된 영상에서 꼭짓점을 검출한 뒤 꼭짓점의 개수와 매칭되는 테이블 정보에 따라 점자블록 상태를 판단한다. 실험 결과, 이전 기존 연구보다 정확한 점자블록 패턴 정보를 제공하며, 성능이 가장 우수하게 나타났다. 본 논문에서 제안한 점자블록 인식 기술을 활용하면, 시각 장애인의 안정적인 보행에 도움을 줄 수 있는 보조 장치 개발에 기여할 수 있을 것이다.",다국어 초록 정보 없음
객체 인식 모델 기반 실시간 교통신호 정보 인식,2022,"['차량 신호 인식', '자율주행', '딥러닝', 'YOLO', '객체탐지', 'Traffic Light Recognition', 'Autonomous Driving', 'Deep Learning', 'YOLO', 'Object Detection']","최근 자율주행 기술에서 차량 주변 객체 인식과 교통표지판 및 차량 신호 인식을 위한 연구가 활발히 수행되고 있으며, 특히 차량 신호 인식은 자율주행 기술에 있어서 핵심 요소로 평가되고 있다. 이에 차량 신호 인식을 위한 다양한 연구가 진행되어 왔으며, 최근에는 딥러닝 기반 객체 인식 모델을 활용한 차량 신호 인식 연구가 크게 증가하고 있다. 또한 AIHub에서 음성, 비전, 자율주행 등을 위한 양질의 국내 인공지능 학습데이터 셋이 공개됨에 따라 이들 데이터를 활용한 국내 환경에 적합한 차량 신호 인식 모델의 개발도 가능하게 되었다. 이에 본 연구에서는 AIHub의 학습데이터와 객체 인식모델 YOLO를 적용한 국내 차량 신호 인식 모델을 개발하였다. 특히 차량 신호의 인식 성능을 개선하기 위하여 YOLOv4와 YOLOv5의 다양한 모델을 적용하였으며 학습데이터의 클래스도 다양하게 분류하여 실험을 수행하였다. 결론적으로 YOLOv5가 YOLOv4보다 차량 신호 인식에 조금 더 적합함을 확인할 수 있었으며, 두 모델의 아키텍처 비교를 통하여 YOLOv5 성능이 우수한 이유를 확인할 수 있었다.",다국어 초록 정보 없음
딥러닝 기반 알고리즘을 활용한 산불 객체 탐지,2022,"['딥러닝', '객체 검출', '분류', '욜로', '산림', '화재', 'Deep Learning', 'Object Detection', 'Classification', 'YOLO', 'Forest', 'Fire']","우리는 산불로 인한 피해로 직, 간접적인 피해를 받고 있는데 피해를 줄이기 위해서는 초기에 산불을 검출하는 것이 중요하다. 기존 산불 검출 방법으로는 촬영 이미지를 영상처리 기술을 통해 감지하거나 센서를 일정 구간별로 설치하여 모니터링하는 방법을 사용했다. 본 논문은 유지비용이 많이 들어가는 기존 방법을 개선하기 위해 객체 탐지 인공지능 기술, YOLO를 사용하여 객체 검출을 하고 인공지능 모델을 통해 나온 검출 결과를 제공하는 시스템 구현을 진행한다. 연구 결과 주요 성능지표인 mAP가 Proposed LFire 0.959, YOLOv5 0.931, YOLOv4 0.943, R-CNN 0.879가 나왔다. 본 논문에서 제안하는 모델인 Proposed LFire가 가장 높은 것을 통해 산불 검출 데이터에 적합한 객체 검출모델로 볼 수 있다. 향후 보편적으로 사용할 수 있는 RGB 채널 산림 이미지 특징에 맞는 이미지 전처리 및 모델 학습을 통해 검출 성능을 높이는 방향으로 연구할 계획이다.","We are suffering direct and indirect damage from forest fires, and it is essential to detect them early to reduce the damage. Existing forest fire detection methods used a method of detecting photographed images through image processing technology or installing sensors at certain intervals to monitor them. To improve the existing process that is expensive to maintain, this paper conducts object detection using object detection artificial intelligence technology, YOLO. It implements a system that provides detection results from artificial intelligence models. As a result of the study, the main performance indicators, mAP, were Proposed LFire 0.959, YOLOv5 0.931, YOLOv4 0.943, and R-CNN 0.879. The proposed model in this paper, Proposed LFire, is the highest, which can be seen as an object detection model suitable for forest fire detection data. In the future, we plan to study in the direction of increasing detection performance through image preprocessing and model learning suitable for RGB channel forest image features that can be used universally."
엣지 컴퓨팅 환경에서 적용 가능한 딥러닝 기반 라벨 검사 시스템 구현,2022,"['Edge-Computing System', 'Deep Learning', 'Machine Vision', 'Vision Inspection', 'Object Detection']",국문 초록 정보 없음,"In this paper, the two-stage object detection approach is proposed to implement a deep learning-based label inspection system on edge computing environments. Since the label printed on the products during the production process contains important information related to the product, it is significantly to check the label information is correct. The proposed system uses the lightweight deep learning model that able to employ in the low-performance edge computing devices, and the two-stage object detection approach is applied to compensate for the low accuracy relatively. The proposed Two-Stage object detection approach consists of two object detection networks, Label Area Detection Network and Character Detection Network. Label Area Detection Network finds the label area in the product image, and Character Detection Network detects the words in the label area. Using this approach, we can detect characters precise even with a lightweight deep learning models. The SF-YOLO model applied in the proposed system is the YOLO-based lightweight object detection network designed for edge computing devices. This model showed up to 2 times faster processing time and a considerable improvement in accuracy, compared to other YOLO-based lightweight models such as YOLOv3-tiny and YOLOv4-tiny. Also since the amount of computation is low, it can be easily applied in edge computing environments."
선박 종류 및 항로표지 구분이 가능한 인공지능 카메라,2022,"['선교상황인식', '선박분류', '합성곱신경망', 'YOLO']","선교 상황 인식 시스템을 개발하기 위한 합성곱 신경망 기반의 인공지능카메라를 개발한다. 부이 등의 항로표지를 포함한 컨테이너선, 유조선, 자동차 운반선 등 선박 종류 구분이 가능하도록 YOLO5를 이용하여 학습을 수행하고 그 결과를 보인다.",다국어 초록 정보 없음
Robust Object Detection Algorithm for Occlusion Area using YOLOv5 and Dual Kalman Filter,2022,[],연구의 목표 : 폐색 영역에서 YOLO의 검출 성능이 저하되는 것을 보완하는 것 YOLOv5와 Dual Kalman Filter를 결합하여 폐색 영역에 강건한 객체 검출 알고리즘 제안 드론이 폐색 영역에 진입하는 검증 영상에 제안 알고리즘을 적용하여 실험 진행 여러 가지 크기의 YOLO에 모두 적용하여 제안 알고리즘의 강건함을 검증함,다국어 초록 정보 없음
해상풍력발전기 조류환경 영향평가를 위한 인공지능 조류충돌방지 시스템,2022,"['해상풍력발전', '합성곱신경망', '이미지 분류', '이미지 탐지', 'YOLO']","해상풍력발전단지 환경평가를 위한 조류충돌저감장치를 개발하기 위하여, 천연기념물 조류를 구부할 수 있는 인공지능 카메라를 개발한다. 보호해야 할 조류를 90프로 이상 정확하게 구분하기 위한 계층구조 라벨링 방법을 고안하고 YOLO5 모델을 사용하여 학습을 수행하고, 그 결과를 보인다.",다국어 초록 정보 없음
세포 계수 측정을 위한 딥러닝 기반 객체 탐지 시스템 연구 개발,2022,"['object detection', 'deep-learning', 'classification', 'mobile', 'microservice architecture', 'amazon cloud']","본 논문에서는 세포 계수 기술을 활용하여 세포 배양액 사진 속에 있는 세포의 계수 및 Viability를 알려주는 모바일 애플리케이션 서비스를 제안한다. 세포 배양액 사진을 업로드 하면, YOLO-R 모델을 통해 세포 배양액의 영상 속 객체를 탐지하고 그 결과로 Total Cell, Live Cell, Dead Cell, Cell Viability의 정보를 추출하여 세포 계수 정보를 사용자에게 빠르게 제공할 수 있다.","In this paper, we propose a mobile application service that utilizes cell counting techniques to inform the coefficient and viability of cells in a photograph of a cell culture. Uploading a photograph of a cell culture fluid allows the YOLO-R model to detect objects in the image of the cell culture and extract information from Total Cell, Live Cell, Dead Cell, and Cell Visibility as a result to quickly provide cell coefficient information to the user."
딥러닝 기반 객체 인식을 통한 철계 열처리 부품의 인지에 관한 연구,2022,"['Heat Treatment', 'Object Detection', 'Transfer Learning', 'Real-Time', 'Deep Learning']",국문 초록 정보 없음,"In this study, a model for automatically recognizing several steel parts through a camera before charging materials was developed under the assumption that the temperature distribution in the pre-air atmosphere was known. For model development, datasets were collected in random environments and factories. In this study, the YOLO-v5 model, which is a YOLO model with strengths in real-time detection in the field of object detection, was used, and the disadvantages of taking a lot of time to collect images and learning models was solved through the transfer learning methods. The performance evaluation results of the derived model showed excellent performance of 0.927 based on mAP 0.5. The derived model will be applied to the model development study, which uses the model to accurately recognize the material and then match it with the temperature distribution in the atmosphere to determine whether the material layout is suitable before charging materials."
합성곱 신경망과 비전 트랜스포머를 활용한 포트홀과 맨홀 감지 성능 비교,2022,[],"본 논문은 도로 위의 포트홀(Pothole)과 맨홀(Manhole)을 감지하는 과업을 위해 합성곱 신경망을 이용한 모델과 최근 많은 연구가 이뤄지고 있는 트랜스포머(Transformer) 구조를 활용한 모델의 성능 비교에 관하여 서술하였다. 학습과 검증에 사용된 데이터로는 과학기술정보통신부와 한국지능정보사회진흥원의「지능정보산업 인프라 조성」사업의 목적으로 구축한 도로 장애물 및 표면 인지(Detection) 영상 데이터 집합을 사용하였고 그 중 포트홀과 맨홀 데이터만을 선별하여 사용하였다. 합성곱 신경망을 이용한 모델로는 Yolo-v3를 사용하였고 트랜스포머 구조를 활용한 모델로는 Meta Research 에서 발표한 DEtection TRansformer(DE:TR)을 사용하였다. 실험 결과 DE:TR은 bbox_mAP가 0.306, Yolo-v3는 bbox_mAP가 0.231로 DE:TR이 0.075 더 높은 성능을 보여주었다.",다국어 초록 정보 없음
공공 다중CCTV 기반에서 재식별 기술을 활용한 특정대상 탐지 및 추적기법 구현,2022,"['AI', 'Deep Learning', 'Re-identification', 'Algorithm', 'CCTV']","정부에서는 전국에 설치된 공공 CCTV를 이용하여 실종아동 등 범죄 예방을 위하여 많은 노력을 하고 있다.하지만, 운용인력의 부족과 장시간 집중에 따른 집중력 약화 그리고 추적의 어려움 등이 나타나고 있다. 또한, 딥러닝알고리즘을 통하여 실시간 객체 탐색 및 재인식 그리고 추적을 적용하는 것은 복잡한 신경망 분석의 사유로 파라미터가증가하고 속도감소 메모리 부족이라는 현상을 나타냈다. 본 논문에서는 실시간 객체 인식이 가능한 Yolo의 적용과Batch 및 TensorRT 기술 적용을 통하여 신경망을 경량화를 통하여 속도 개선 및 메모리 절약이 가능하도록 설계하였다. 이 논문에서는 이러한 발전된 알고리즘의 연구를 바탕으로 K-reciprocal nearest neighbor 알고리즘, Jaccard distance 비유사도 측정 알고리즘, 산출물 알고리즘 등을 개발하여 공공 CCTV 식별추적시스템 구축을 제시하였다. 그결과, 비교분석을 통한 알고리즘 조합을 통해 공공 다중CCTV환경에서 실시간으로 객체를 인식하고 재식별하여 객체를추적할 수 있는 한국형 공공 추적시스템을 제안하였다.","The government is making great efforts to prevent crimes such as missing children by using public CCTVs. However, there is a shortage of operating manpower, weakening of concentration due to long-term concentration, and difficulty in tracking. In addition, applying real-time object search, re-identification, and tracking through a deep learning algorithm showed a phenomenon of increased parameters and insufficient memory for speed reduction due to complex network analysis. In this paper, we designed the network to improve speed and save memory through the application of Yolo v4, which can recognize real-time objects, and the application of Batch and TensorRT technology. In this thesis, based on the research on these advanced algorithms, OSNet re-ranking and K-reciprocal nearest neighbor for re-identification, Jaccard distance dissimilarity measurement algorithm for correlation, etc.are developed and used in the solution of CCTV national safety identification and tracking system. As a result, we propose a solution that can track objects by recognizing and re-identification objects in real-time within situation of a Korean public multi-CCTV environment through a set of algorithm combinations."
임베디드 보드에서 차량 감지 및 추적을 위한 딥러닝 모델 최적화,2022,"['Vehicle detection', 'Vehicle tracking', 'embedded board', 'SSD', 'MobileNet', 'convolutional neural network', '차량 감지', '차량 추적', '임베디드 보드', 'SSD', 'MobileNet', 'CNN']","본 논문은 임베디드 보드에서 차량을 감지하고 추적하기 위한 딥러닝 모델을 제안한다. 딥러닝이 기존 이미지 처리 방법에서 높은 정확도를 보여주고 있기 때문에 기존 객체 검출기로 거리나 교량에서 차량을 감지할 수 있다. 그러나, 범용 PC를 사용하는 경우 GPU를 사용하여 프로그램을 실시간으로 동작하는 것이 가능하지만, 임베디드 보드에서는 GPU를 사용하기 어렵고 낮은 성능의 CPU를 사용하므로 프로그램의 실시간 처리가 불가능하다. 본 논문에서는 양자화, edge TPU와 같은 방법을 이용해서 에지 컴퓨팅 기반 딥러닝을 이용한 객체 감지의 정확도와 성능 향상을 시도하였다. Yolo와 같은 다른 네트워크보다 MobileNet을기반한 SSDLite가 빠른 추론시간과 높은 정확도를 보여줘 선정했다. SSDMobileNetV2를 객체 감지기로 사용한 DeepSORT로 모델을 학습하여 차량을 추적할 수 있도록 하였다. 본 논문에서는 H6 CPU를 이용하여 자체 제작한 보드를 통해 차량 감지 및 추적을 위한 딥러닝모델의 성능을 확인하였다","This paper proposes a deep learning model to detect and track the vehicle on an embedded device. Since deep learning has achieved high accuracy over the classical image processing method, object detectors can detect vehicles in the street and highway. It can be normal to run the computer detection program with graphic processor unit (GPU) support, but it is challenging to run it on the embedded board with no GPU support and low central processing unit (CPU) performance. This paper focuses on balancing edge-computing-based deep learning object detection's accuracy and performance using additional techniques such as quantization, edge TPU. SSDLite with MobileNet backbone is chosen due to its lighter than other networks but still obtain good performance compare with Yolo. The model was learned with DeepSORT using SSDMobileNetV2 as an object detector so that the vehicle could be tracked. This paper evaluates the performance of deep learning model to detect and track the vehicle through the developed board using H6 CPU."
딥러닝 기반 실시간 이미지 검출 시스템에 의한 한국 전통회화 객체 인식 연구,2022,"['디지털 콘텐츠', '홀로그래픽', '딥러닝', '이미지 검출', '객체 인식', '한국 전통회화', 'Digital Content', 'Holographic', 'Deep Learning', 'Image Detection', 'Object Recognition', 'Korean Traditional Picture']",국문 초록 정보 없음,다국어 초록 정보 없음
4족 보행 로봇 기반의 실시간 사람 검출 방법,2022,[],"본 논문은 강화학습 POMDP(Partially Observable Markov Decision Process) 알고리즘을 사용하여 자갈밭과 같은 비평탄 지형을 극복하는 4족 보행 지능로봇을 설계하고 딥러닝 기법을 사용하여 사람을 검출한다. 로봇의 임베디드 환경에서 1단계 검출 알고리즘인 YOLO-v7과 SSD의 기본 모델, 경량 또는 네트워크 교체 모델의 성능을 비교하고 선정된 SSD MobileNet-v2의 검출 속도를 개선하기 위해 TensorRT를 사용하여 최적화를 진행하였다",다국어 초록 정보 없음
Pessimism Transformed to Hope:  Applying Transformative Learning  to Assist Young People in Korea,2022,"['Transformative learning', 'church education', 'eschatology', 'pessimism', 'Korean Christianity']",국문 초록 정보 없음,"This study presents the increasing pessimism of young people in South Korea as they are confronted with societal situations that cause them to be disoriented. Young people’s pessimistic perspectives, attitudes, and responses to societal challenges are found when examining the following terms: Chosun Hell, Spoon Class Theory, and YOLO. Moreover, this study presents that pessimism has penetrated into the church through its neglect of eschatology. Transformative learning theory is a useful tool to address young people’s disoriented dilemmas and provide possible ways for Christian educators to foster them to have transformed perspectives rooted in the Bible. Especially, critical thinking and discourse have their value to enable young people in Korea faced with their particular difficulties to find hope and purpose through God’s Word and His kingdom, become more like Christ, and shine in the midst of all that is happening."
AI 기반 쓰레기 분리수거 자동화 시스템 설계 및 구현에 관한 연구,2022,[],"현재 사회적 문제로 잘못된 자원 재활용 방법 및 경비 노동자 근로 환경 개선 필요성이 지속해서 대두되고 있으며, 최근 발생한 코로나바이러스로 인하여 배달 음식의 수요가 증가하여 각 가정에서 배출되는 쓰레기의 양이 매우 증가하였다. 이러한 사회적 문제를 효율적으로 대처하기 위하여 본 논문에서는 분리수거가 가능한 사물을 인식하여 AI 모듈로 객체 정보를 전송하고 전송된 정보에 따라 적절한 분리수거를 수행하는 스마트 분리수거 자동화 시스템을 개발하였다. 본 연구에서는 잘못된 객체 정보 전송을 최소화하고, 객체 인식률의 정확도를 높이기 위하여 많은 종류의 Custom dataset을 Yolo_Mark, Scaling Annoter Tool을 이용하여 직접 라벨링 하였으며 K-means Clustering 알고리즘을 적용하여 더욱 정확한 분리수거 자동화 시스템을 구현하였다. 본 연구를 바탕으로 불필요한 자원과 인력 낭비를 줄일 수 있으며, 인간이 아닌 시스템에 의해 통제되므로 더욱 정확한 분리수거가 가능하다.",다국어 초록 정보 없음
횡단보도 보행자 인지 향상을 위한 ByteTrack 기반 다중객체추적,2022,"['Pedestrian Recognition', 'Multi-Object Tracking', 'Autonomous Vehicle', 'ByteTrack', 'CDNet', '.']",국문 초록 정보 없음,"According to traffic accident statistics, 42% of traffic accidents between 2017 and 2021 were crossing accidents. To reduce these accidents, the research on the collision avoidance assistance for pedestrian safety is in the spotlight in machine learning field. However, there are few studies to improve the accuracy of recognizing the crossing multiple pedestrians and estimating the residual time to the crossing. We here propose using hybrid approach combining Yolo-X and ByteTrack to obtain the accurate detector of pedestrians. We gathered the actual data set of the pedestrian crossing for the accurate multi-pedestrian tracking model. The proposed approach can detect and track the crossing pedestrians in real time. Furthermore, we can estimate the pedestrian’s walking direction, speed, acceleration, and distance to the crosswalk for inferring the motion of pedestrians entering the crosswalk. The experimental results present that the proposed approach outperforms the alternatives in terms of tracking accuracy and computation cost."
오픈소스 하드웨어와 딥러닝 기반 객체 탐지 알고리즘을 활용한 교내 유동인구 분석,2022,"['Floating Population', 'Deep Learning', 'Remote Sensing', 'Object-Detection', 'OSHW', '유동인구', '딥러닝', '원격탐사', '객체 탐지', '오픈소스 하드웨어']",국문 초록 정보 없음,"In this study, the floating population survey and analysis of Pukyong National University campus were conducted using images through an object detection algorithm based on the open source hardware Raspberry Pi and deep learning technology. For the study, images were collected for a total of 5 days from May 10th to May 14th using Raspberry Pi. After that, people were detected from the collected images using YOLO3's IMAGEAI and YOLOv5 models, and Haar-like features and HOG models were used for accuracy comparison analysis. As a result of comparison, the smallest floating population was observed on the 10th day, the anniversary of the opening of the school, and the largest floating population was observed on the 12th day for the entrance and the 14th for the exit. If the spatial and temporal scope of the study is expanded, it is expected that more accurate floating population analysis will be possible."
에지 디바이스를 활용한 실시간 말벌 모니터링  시스템의 설계 및 구현,2022,"['Deep Learning', 'Wasp Monitoring System', 'Edge Device', 'Real-Time Processing']",국문 초록 정보 없음,"In this paper, an edge-enabled wasps monitoring system based on state of the art deep learning model is proposed to classify wasps species and transmit their information to clients for pest control and ecology research. We utilized and evaluated the lightweight models of YOLOv5, YOLOX, and YOLOv7 series to select the optimal object detection model for wasps. In order to improve the recognition performance of small objects such as wasps, a new tiling method is proposed which can reclassify objects located on boundary area between tiles. Our monitoring system is composed by local GPU-based edge computers, Server, and Web-based reporting system. In our experiment, the YOLOX- nano model showed the highest performance among YOLO-based models above in terms of recall, precision, Fi-score, and mAP@IOUs for our custom test data set. However, even the YOLOX-nano model also requires the tiling process for a better bounding box generation for small objects under the real environment. As a result, the proposed wasps monitoring system showed meaningful efficiency for applying in the field of pest control and ecology research."
국내 도로 환경에 특화된 자율주행을 위한 멀티카메라 데이터 셋 구축 및 유효성 검증,2022,"['2D Dataset', 'Camera', 'Autonomous driving']",국문 초록 정보 없음,"Along with the advancement of deep learning technology, securing high-quality dataset for verification of developed technology is emerging as an important issue, and developing robust deep learning models to the domestic road environment is focused by many research groups. Especially, unlike expressways and automobile-only roads, in the complex city driving environment, various dynamic objects such as motorbikes, electric kickboards, large buses/truck, freight cars, pedestrians, and traffic lights are mixed in city road. In this paper, we built our dataset through multi camera-based processing (collection, refinement, and annotation) including the various objects in the city road and estimated quality and validity of our dataset by using YOLO-based model in object detection. Then, quantitative evaluation of our dataset is performed by comparing with the public dataset and qualitative evaluation of it is performed by comparing with experiment results using open platform. We generated our 2D dataset based on annotation rules of KITTI/COCO dataset, and compared the performance with the public dataset using the evaluation rules of KITTI/COCO dataset. As a result of comparison with public dataset, our dataset shows about 3 to 53% higher performance and thus the effectiveness of our dataset was validated."
A Study on Algorithm Selection and Comparison for Improving the Performance of an  Artificial Intelligence Product Recognition Automatic Payment System,2022,"['Self-Service Technology', 'Automatic payment system', 'Artificial Intelligence', 'Object detection', 'YOLO']",국문 초록 정보 없음,"This study is to select an optimal object detection algorithm for designing a self-checkout counter to improve the inconvenience of payment systems for products without existing barcodes. To this end, a performance comparison analysis of YOLO v2, Tiny YOLO v2, and the latest YOLO v5 among deep learning-based object detection algorithms was performed to derive results. In this paper, performance comparison was conducted by forming learning data as an example of 'donut' in a bakery store, and the performance result of YOLO v5 was the highest at 96.9% of mAP. Therefore, YOLO v5 was selected as the artificial intelligence object detection algorithm to be applied in this paper. As a result of performance analysis, when the optimal threshold was set for each donut, the precision and reproduction rate of all donuts exceeded 0.85, and the majority of donuts showed excellent recognition performance of 0.90 or more. We expect that the results of this paper will be helpful as the fundamental data for the development of an automatic payment system using AI self-service technology that is highly usable in the non-face-to-face era."
딥러닝 적용 선별 모델 비교 및 프로토타입 개발: 파프리카 중심으로,2022,"['선별기', '딥러닝', 'Faster R-CNN', 'YOLO', '파프리카']","소비자의 생활 수준이 향상됨에 따라 고품질 농산물에 대한 수요가 증가하고 있다. 과실의 선별은 상품성과 직결되기 때문에 현 소비 트렌드를 따라가기 위해 고려해야 할 주요한 요인 중 하나이다. 중량 선별기의 경우 과실의 중량만을 이용하여 선별하기 때문에 과실의 완숙도 및 장해 여부 선별에 한계가 있고, 광학 선별기의 경우 NIR 카메라 및 다수의 고가 장비를 통해 중량 선별기의 한계를 극복하였으나, 비용적 측면에서 농가에 부담이 따른다. 본 연구에서는 넓은 선별 스펙트럼을 유지하는 동시에 투입되는 장비의 비용을 줄일 수 있는 선별기 제작을 위해 딥러닝 알고리즘인 Faster R-CNN과 YOLO v5를 비교하고, 선별기 프로토타입을 개발하였다. CNN(Convolutional Neural Network)은 이미지 분류에 특화된 딥러닝 알고리즘으로 다중 클래스 분류가 가능하다. Faster R-CNN은 기존 CNN 알고리즘에 별도의 영역 제안 네트워크(RPN, Region Proposal Network)를 적용하여 학습 및 수행 속도가 개선되었다. YOLO(You Only Look Once)는 실시간 객체 인식에 특화된 딥러닝 알고리즘으로 Faster R-CNN과 달리 영역 제안을 위한 별도의 네트워크를 사용하지 않아 처리속도가 빠르다. 코코넛 성숙 단계 분류 연구(Kim et al.등, 2020)에서 Faster R-CNN 모델인 ResNet-50으로 코코넛 이미지 2,000장을 학습한 결과 mAP(평균 정밀도, mean Average Precision)이 89.4% 정확도로 분류하였다. YOLO v3를 이용한 사과 장해 여부 검출 연구(Valdez et al.등, 2020)는 웹으로부터 모은 사과 이미지 452장을 학습한 결과 mAP 74.3%의 정확도를 보고하였다. 본 연구에서 선별 모델로 적합하다고 판단되는 Faster R-CNN의 ResNet-50과 YOLO 모델 중 경량화 특징이 있는 YOLO v5를 이용한 선별 알고리즘을 개발하여 라즈베리파이4 (Raspberry Pi 4, 8GB RAM) 에 구현하여 성능을 비교하였다. 전라북도 부안군 계화면 소재의 ‘파프리카’ 온실에서 파프리카(machay)를 수확하였다. 수확한 파프리카를 촬영하여 학습에 사용할 이미지 데이터를 확보하였고, 웹크롤링을 통해 부족한 이미지 데이터를 추가로 확보하였다. 구득한 이미지 데이터는 ‘성숙과’, ‘미성숙과’, ‘판정보류’, 그리고 ‘비정상과’로 분류하였고, 바운딩 박스를 추가한 라벨데이터를 구축하였다. 전체 이미지 및 라벨 데이터의 80%와, 20%를 각각 학습, 검증에 사용하였다. 카메라 모듈을 통해 실시간으로 촬영하는 영상에 학습한 모델을 적용하여 객체의 클래스를 판별하고, 서보모터가 판별 결과에 따라 레버를 지정한 각도로 움직이도록 설계하였다. 모델의 성능은 mAP, 판별 소요 시간을 평가하였다. 본 연구는 딥러닝을 이용하여 과실의 완숙도 및 장해 여부를 선별하는 데에 그쳤지만, 향후 연구에서 다양한 종류의 이미지 데이터를 확보한다면 병해, 충해, 냉해, 한해 등의 다양한 작물피해 또한 선별하여 범용적으로 적용 가능할 것으로 기대한다.",다국어 초록 정보 없음
A Study on Algorithm Selection and Comparison for Improving the Performance of an Artificial Intelligence Product Recognition Automatic Payment System,2022,"['Self-Service Technology', 'Automatic payment system', 'Artificial Intelligence', 'Object detection', 'YOLO']",국문 초록 정보 없음,"This study is to select an optimal object detection algorithm for designing a self-checkout counter to improve the inconvenience of payment systems for products without existing barcodes. To this end, a performance comparison analysis of YOLO v2, Tiny YOLO v2, and the latest YOLO v5 among deep learning-based object detection algorithms was performed to derive results. In this paper, performance comparison was conducted by forming learning data as an example of 'donut' in a bakery store, and the performance result of YOLO v5 was the highest at 96.9% of mAP. Therefore, YOLO v5 was selected as the artificial intelligence object detection algorithm to be applied in this paper. As a result of performance analysis, when the optimal threshold was set for each donut, the precision and reproduction rate of all donuts exceeded 0.85, and the majority of donuts showed excellent recognition performance of 0.90 or more. We expect that the results of this paper will be helpful as the fundamental data for the development of an automatic payment system using AI self-service technology that is highly usable in the non-face-to-face era."
경량화된 임베디드 시스템에서 의미론적인 픽셀 분할 마스킹을 이용한 효율적인 영상 객체 인식 기법,2022,"['객체 인식', 'OpenCV', 'ENet', 'YOLO', '딥러닝', 'Object detection', 'OpenCV', 'ENet', 'YOLO', 'Deep learning']","카메라를 이용한 영상 처리와 그에 따른 인공지능 기술의 발달로 다양한 분야의 기술이 발전하기 시작했다. 하지만 보드가 가벼울수록 연산이 많이 필요한 영상 처리 알고리즘을 구현하기 힘들다. 본 논문에서는 경량 임베디드 보드에서 물체 인식 알고리즘을 위한 딥러닝을 사용하는 방법을 제안한다. 비교적 적은 양의 계산으로 segmentation을 처리하는 딥러닝 알고리즘을 사용하여 ROI(Region of Interest)를 결정할 수 있다. 영역을 마스킹한 후, 더 정확한 딥러닝 알고리즘을 사용해 물체 감지를 할 수 있다. Python에서 입력 이미지를 처리하기 위해 OpenCV를 사용했고 ENet과 YOLO(You Only Look Once)를 사용하여 이미지를 처리했다. 이 알고리즘을 실행함으로써 평균 오차가 절반으로 감소해 정확한 객체 검출을 처리할 수 있고 경량 임베디드 보드에서 실시간으로 객체 인식을 실행할 수 있다.이 연구는 자율주행과 IoT에서 저가격 경량화된 응용에 활용될 수 있을 것으로 기대된다.","AI-based image processing technologies in various fields have been widely studied. However, the lighter the board, the more difficult it is to reduce the weight of image processing algorithm due to a lot of computation. In this paper, we propose a method using deep learning for object recognition algorithm in lightweight embedded boards. We can determine the area using a deep neural network architecture algorithm that processes semantic segmentation with a relatively small amount of computation. After masking the area, by using more accurate deep learning algorithm we could operate object detection with improved accuracy for efficient neural network (ENet) and You Only Look Once (YOLO) toward executing object recognition in real time for lightweighted embedded boards. This research is expected to be used for autonomous driving applications, which have to be much lighter and cheaper than the existing approaches used for object recognition."
혼재된 환경에서의 효율적 로봇 파지를 위한 3차원 물체 인식 알고리즘 개발,2022,"['3D Object Recognition', 'Cluttered Environment', 'YOLO', 'Mask R-CNN']",국문 초록 정보 없음,"3D object detection pipelines often incorporate RGB-based object detection methods such as YOLO, which detects the object classes and bounding boxes from the RGB image. However, in complex environments where objects are heavily cluttered, bounding box approaches may show degraded performance due to the overlapping bounding boxes. Mask based methods such as Mask R-CNN can handle such situation better thanks to their detailed object masks, but they require much longer time for data preparation compared to bounding box-based approaches. In this paper, we present a 3D object recognition pipeline which uses either the YOLO or Mask R-CNN real-time object detection algorithm, K-nearest clustering algorithm, mask reduction algorithm and finally Principal Component Analysis (PCA) alg orithm to efficiently detect 3D poses of objects in a complex environment. Furthermore, we also present an improved YOLO based 3D object detection algorithm that uses a prioritized heightmap clustering algorithm to handle overlapping bounding boxes. The suggested algorithms have successfully been used at the Artificial-Intelligence Robot Challenge (ARC) 2021 competition with excellent results."
저속 특장차의 도심 자율주행을 위한 신호등 인지 알고리즘 적용 및 검증,2022,"['저속 무인 특장차', '딥러닝', '신호등 인지 알고리즘', '실시간 사물 감지', 'Low-speed unmanned special vehicle', 'Deep Learning', 'Traffic light recognition Algorithm', 'Real-Time Object Detection', 'YOLO algorithm']",국문 초록 정보 없음,"In this study, a traffic light recognition algorithm was implemented and validated for low-speed special purpose vehicles in an urban environment. Real-time image data using a camera and YOLO algorithm were applied. Two methods were presented to increase the accuracy of the traffic light recognition algorithm, and it was confirmed that the second method had the higher accuracy according to the traffic light type. In addition, it was confirmed that the optimal YOLO algorithm was YOLO v5m, which has over 98% mAP values and higher efficiency. In the future, it is thought that the traffic light recognition algorithm can be used as a dual system to secure the platform safety in the traffic information error of C-ITS."
드론과 인공지능을 활용한 실종자 탐색에 관한 연구,2022,"['Drone', 'YOLO algorithm', 'Object detection']","본 연구는 4차산업혁명 시대를 대표하는 인공지능을 드론에 탑재하여 실시간 이미지 정보를 획득하고 건강상, 또는 실신 등 응급을 요 하는 사람을 탐색함으로써 사각지대를 최소화하고 탐색의 효율성을 높이는데 그 목적이 있다. 본 연구는 드론에 영상정보 획득 장치를 탑재하고 미디어 서버에 전송 후 프레임 단위의 인공지능 학습 알고리즘을 적용하여 사람 인식 결과를 분석 후 해당 GPS 정보를 획득하는 절차로 진행된다. 최근 소개된 여러 인공지능 알고리즘 중에서 대표되는 YOLO 알고리즘을 적용하여 마네킹 또는 실제 이미지를 학습함으로써 신뢰도 높은 실험 결과를 보였으며 드론의 활용범위가 확대됨에 따라 인간의 접근 사각지대에서 그 역할이 확대될 것으로 기대된다. 논문의 구성은 임무 수행을 위한 드론의 사양을 소개하고 인공지능의 개념 및 활용 방법, 실제 드론 비행을 통한 이미지 획득 및 결과 분석 그리고 향후 활용범위로 기술하였다.","This study provides several methods to minimize dead zone and to detect missing person using combined DRONE and AI especially called 4th Industrial Revolution. That is composed of image acquisition for a person who is in needed of support. The procedure is DRONE that is made of image acquisition and transfer system. after that can be shown GPS information. Currently representative AI algorithm is YOLO (You Only Look Once) that can be adopted to find manikin or real image by learning with dataset. The output was reached in reliable and efficient results. As the trends of DRONE is expanded widely that will provide various roll. This paper was composed of three parts. the first is DRONE specification, the second is the definition of AI and procedures, the third is the methods of image acquisition using DRONE, the last is the future of DRONE with AI."
Comparison of Deep Learning-Based Object Classification Methods for Detecting Tomato Ripeness,2022,"['SSD', 'Faster R-CNN', 'YOLO', 'Object detection']",국문 초록 정보 없음,"Examination of the technological development in agriculture reveals that not many applicationsuse cameras to detect tomato ripeness; therefore, tomato maturity is still determined manually.Currently, technological advances and developments are occurring rapidly, and are, therefore,also inseparable from the agricultural sector. Object detection can help determining tomatoripeness. In this research, faster region-based convolutional neural network (Faster R-CNN),single shot multibox detector (SSD), and you only look once (YOLO) models were tested torecognize or detect tomato ripeness using input images. The model training process required 5hours and produced a total loss value <0.5, and as the total loss became smaller, the predictedresults improved. Tests were conducted on a training dataset, and average accuracy values of99.55%, 89.3%, and 94.6% were achieved using the Faster R-CNN, SSD, and YOLO models,respectively"
인공지능을 활용한 드론테러 대응방안,2022,"['드론', '테러', '드론탐지', '인공지능', 'YOLO', 'Drones', 'Terrorism', 'Drone Detection', 'Artificial Intelligence', 'YOLO']","드론은 휴대하기 쉽고, 접근성이 좋아 군사적으로 상업적으로 많이 활용되면서 최근 새로운 테러수단으로 등장하고 있다. 실제 드론을 이용한 테러는 증가하고 있으며, 드론의 낮은 가격, 쉬운 개조방법, 크기나 무게의 다운사이징을 통해 테러리스트들에게는 최적의 수단으로 각광받고 있다. 드론이 테러수단으로 사용된 사례를 알아보고, 드론을 탐지하기 위한 방법으로 인공지능기술을 적용한 YOLO 드론탐지 기법을 소개한다.",다국어 초록 정보 없음
CNN 기반 CCTV 동영상 내 보행자 응급 상황 자동 감지 기술 연구,2022,"['응급상황', '영상인식', 'Deep Learning', 'YOLO', 'Emergency', 'Image Recognition', 'CCTV', '딥러닝']",국문 초록 정보 없음,"Since most medical emergencies including cardiac arrest and stroke happen unexpectedly, it is critical to recognize and respond to the situations immediately. In this paper, we propose an AI-based system which recognizes automatically medical emergencies where pedestrians fall unexpectedly due to their health problems captured in real-time video clips from CCTVs and locates the geometric position on a map on a web page to provide with prompt first aids. To this end, we extend the YOLO (You Only Look Once) network, a variant of the Convolutional Neural Network (CNN) which is suitable for 2D still images, not video. Though many researchers have studied on the methods dedicated to recognize objects in video, with a belief that CNN is not enough to recognize motions, we show that it is possible to build a robust but simple medical emergency detection system by extending the YOLO network - a variant of CNN - that only handles 2D images. Also, we report the performance of the proposed system in four performance measures in this paper."
기울기 보정 알고리즘을 이용한 측면에서의 차량 번호 인식 기술 연구,2022,"['Vehicle number recognition', 'Slope correction', 'YOLO', 'Deep Learning']","교통사고 발생률은 매년 증가하고 있으며 대한민국은 OECD 국가 중에서 상위권에 속한다. 이를 개선하기 위해 다양한 도로교통법이 시행되고 있으며 무인 속도 카메라, 교통단속 카메라 등의 장비를 사용한 다양한 교통단속 방법이 적용되고 있다. 그러나 운전자는 네비게이션을 통해 교통단속 카메라의 위치를 사전 감지하여 단속을 회피함에 따라 불시 단속이 가능한 이동식 단속시스템이 필요하며, 정확한 단속을 위해 도로 측면에서 차량 번호판 인식률을 높일 수 있는 연구가 필요하다. 본 논문에서는 영상처리를 이용한 기울기 보정 알고리즘를 적용하여 도로 측면에서의 차량 번호 인식률을 향상을 위한 방법을 제안한다. 또한 문자 이식 정확도 향상을 위해 CNN 기반의 YOLO 알고리즘을 이용하여 커스텀 데이터 학습을 진행하였다. 해당 알고리즘을 설치 장소에 대한 제약이 없는 이동식 교통단속 카메라 등 에 활용 가능할 것으로 기대된다.","The incidence of traffic accidents is increasing every year, and Korea is among the top OECD countries. In order to improve this, various road traffic laws are being implemented, and various traffic control methods using equipment such as unmanned speed cameras and traffic control cameras are being applied. However, as drivers avoid crackdowns by detecting the location of traffic control cameras in advance through navigation, a mobile crackdown system that can be cracked down is needed, and research is needed to increase the recognition rate of vehicle license plates on the side of the road for accurate crackdown. This paper proposes a method to improve the vehicle number recognition rate on the road side by applying a gradient correction algorithm using image processing. In addition, custom data learning was conducted using a CNN-based YOLO algorithm to improve character recognition accuracy. It is expected that the algorithm can be used for mobile traffic control cameras without restrictions on the installation location."
YOLOv5 및 OpenPose를 이용한 건설현장 근로자 탐지성능 향상에 대한 연구,2022,"['건설업', '근로자 탐지', '자세 추정', '딥러닝', 'YOLO', 'OpenPose', 'Construction', 'Work Detection', 'Pose Estimation', 'Deep Learning', 'YOLO', 'OpenPose']","건설업은 사망자 수가 가장 많이 발생하는 산업이며, 다양한 제도 개선에도 사망자는 크게 줄어들지 않고 있다. 이에 따라, CCTV 영상에 인공지능(AI)을 적용한 실시간 안전관리가 부각되고 있다. 건설현장의 영상에 대한 AI를 적용한 근로자 탐지연구가 진행되고 있지만, 건설업의 특성상 복잡한 배경 등의 문제로 인해 성능 발현에 제한이 있다. 본 연구에서는 근로자의 탐지 및 자세 추정에 대한 성능 향상을 위해 YOLO 모델과 OpenPose 모델을 융합하여, 복잡 다양한 조건에서의 근로자에 대한 탐지 성능을 향상시켰다. 이는 향후 근로자의 불안전안 행동 및 건강관리 측면에서 활용도가 높을 것으로 예상된다.",다국어 초록 정보 없음
딥러닝 기반의 객체 검출을 이용한 상대적 거리 예측 및 접촉 감지,2022,"['영상분석', '인공신경망', '딥러닝', '접촉 감지', 'YOLO', 'Image Analysis', 'Artificial Neural Network', 'Deep Learning', 'Contact Detection', 'YOLO']",국문 초록 정보 없음,다국어 초록 정보 없음
산림병해충 피해의심목 자동탐지 알고리즘 개발 연구,2022,"['dep learning', 'drone', 'ortho-image', 'forest disaster', 'automatic detection', 'YOLO', '딥러닝', '드론', '정사영상', '산림재해', '자동탐지', 'YOLO']",국문 초록 정보 없음,"Recently, the forests in Korea have acumulated damage due to continuous forest disasters, and the ned for technologies to monitor forest managements is being isued.The size of the afected area is large terain, technologies using drones, artificial inteligence, and big data are being studied. In this study, a standard dataset were conducted to develop an algorithm that automaticaly detects suspicious tres damaged by forest pests using dep learning and drones. Experiments using the YOLO model among object detection algorithm models, the YOLOv4-P7 model showed the highest recal rate of 69.69% and precision of 69.15%. It was confirmed that YOLOv4-P7 should be used as an automatic detection algorithm model for tres suspected of being damaged by forest pests, considering the detection target is an ortho-image with a large image size."
Development of Integrated Algorithm Based on Deep Learning and Stereo Vision Technology for Real Time Worker Tracking in Decommissioning Site,2022,"['Object detection', 'Object tracking', 'Stereo vision', 'Computer vision', 'Decommissioning site', 'YOLO', 'Deep sort']",국문 초록 정보 없음,"It is important to ensure worker’s safety from radiation hazard in decommissioning site. Real-time tracking of worker’s location is one of the factors necessary to detect radiation hazard in advance. In this study, the integrated algorithm for worker tracking has been developed to ensure the safety of workers. There are three essential techniques needed to track worker’s location, which are object detection, object tracking, and estimating location (stereo vision). Above all, object detection performance is most important factor in this study because the performance of tracking and estimating location is depended on worker detection level. YOLO (You Only Look Once version 5) model capable of real-time object detection was applied for worker detection. Among the various YOLO models, a model specialized for person detection was considered to maximize performance. This model showed good performance for distinguishing and detecting workers in various occlusion situations that are difficult to detect correctly. Deep SORT (Simple Online and Realtime Tracking) algorithm which uses deep learning technique has been considered for object tracking. Deep SORT is an algorithm that supplements the existing SORT method by utilizing the appearance information based on deep learning. It showed good tracking performance in the various occlusion situations. The last step is to estimate worker’s location (x-y-z coordinates). The stereo vision technique has been considered to estimate location. It predicts xyz location using two images obtained from stereo camera like human eyes. Two images are obtained from stereo camera and these images are rectified based on camera calibration information in the integrated algorithm. And then workers are detected from the two rectified images and the Deep SORT tracks workers based on worker’s position and appearance between previous frames and current frames. Two points of workers having same ID in two rectified images give xzy information by calculating depth estimation of stereo vision. The integrated algorithm developed in this study showed sufficient possibility to track workers in real time. It also showed fast speed to enable real-time application, showing about 0.08 sec per two frames to detect workers on a laptop with high-performance GPU (RTX 3080 laptop version). Therefore, it is expected that this algorithm can be sufficiently used to track workers in real decommissioning site by performing additional parameter optimization."
객체 탐지를 활용한 근로자 충돌 안전관리 시스템,2022,"['YOLO', '객체 탐지', '데이터 모델링', '산업안전', '충돌위험', 'Data modeling', 'Collision risk', 'Industrial safety', 'Object detection', 'YOLO']",국문 초록 정보 없음,"Recently, AI, big data, and IoT technologies are being used in various solutions such as fire detection and gas or dangerous substance detection for safety accident prevention. According to the status of occupational accidents published by the Ministry of Employment and Labor in 2021, the accident rate, the number of injured, and the number of deaths have increased compared to 2020. In this paper, referring to the dataset construction guidelines provided by the National Intelligence Service Agency(NIA), the dataset is directly collected from the field and learned with YOLOv4 to propose a collision risk object detection system through object detection. The accuracy of the dangerous situation rule violation was 88% indoors and 92% outdoors. Through this system, it is thought that it will be possible to analyze safety accidents that occur in industrial sites in advance and use them to intelligent platforms research."
딥러닝 기반의 객체 탐지 모델을 활용한 과수 생육 단계 판별 시스템,2022,"['딥러닝', '컴퓨터비전', '객체탐지', 'YOLO', '모바일 시스템', 'Deep learning', 'Computer Vision', 'Object Detection', 'YOLO', 'Mobile system']","인공지능 기술의 발전으로 다양한 분야에서 AI가 접목된 시스템에 대한 관심이 급증하고 있다. 농업에서도 정보통신 기술을 적용한 스마트팜이 활용되고 있으며, 자율주행, 인공위성, 빅데이터 등의 다양한 첨단 기술을 접목하여 데이터 기반의 정밀 농업이 상용화되고 있다. 국내의 경우 시설농업 분야 스마트농업의 상용화 사례가 증가하고 있으나 시설원예 분야에 투자 편증이 심하여, 시설농업과 노지 농업의 투자 격차가 지속해서 벌어지고 있다. 특히, 과수, 식물공장 분야는 투자 규모가 작다. 또한, 빅데이터 수집, 활용 체계가 미흡하다는 문제점이 있다. 이에 본 논문에서는 농업의 빅데이터를 활용하는 방안으로 딥러닝 기반의 객체 탐지 모델을 활용한 과수 생육 단계 판별 시스템을 제안한다. 해당 시스템은 농업 현장에서 사용할 수 있도록 하이브리드 앱을 설계 및 구현하며 과수 생육단계 판별을 위한 객체 탐지 기능을 제공한다.","Recently, research and system using AI is rapidly increasing in various fields. Smart farm using artificial intelligence and information communication technology is also being studied in agriculture. In addition, data-based precision agriculture is being commercialized by convergence various advanced technology such as autonomous driving, satellites, and big data. In Korea, the number of commercialization cases of facility agriculture among smart agriculture is increasing. However, research and investment are being biased in the field of facility agriculture. The gap between research and investment in facility agriculture and open-air agriculture continues to increase. The fields of fruit trees and plant factories have low research and investment. There is a problem that the big data collection and utilization system is insufficient. In this paper, we are proposed the system for determining the fruit tree growth stage using a deep learning-based object detection model. The system was proposed as a hybrid app for use in agricultural sites. In addition, we are implemented an object detection function for the fruit tree growth stage determine."
실시간 객체 감지 기술로 다중 바코드와 QR코드 인식 시스템 설계,2022,"['barcode', 'QR code', 'YOLO', 'object detection', 'smart factory']",국문 초록 정보 없음,"In today’s smart factory sites, barcodes and QR codes are used to manage various parts. When many parts are mixed at the production site, it takes a lot of time to individually scan and process barcodes and QR codes for each part. In such a situation, after capturing images of parts in a certain area, barcodes and QR codes are detected using YOLO algorithm, a real-time detection technology, and cut into individual images. In the next step, it is designed to be rotated into an image in a state that the scanner can recognize, and then decoded with the Pyzbar library, a barcode and QR code reader, through the image correction step. According to the degree of damage or contamination of barcodes or QR codes by process, the recognition rate could be improved by applying the deblur library to improve and decode."
합성곱신경망(CNN) 기반의 선박 객체 인식 기술 개발,2022,"['자율운항선박', '객체 인식 알고리즘', 'YOLO', '라벨링', 'Maritime Autonomous Surface Ship', 'Object Detection Algorthm', 'YOLO', 'Labeling']",국문 초록 정보 없음,다국어 초록 정보 없음
Jetson Xavier NX 기반 3차원 토마토 검출 시스템 구현,2022,"['객체검출', '임베디드 시스템', 'YOLO', 'Jetson']","농업인구의 감소와 고령화에 따른 노동력 및 숙련된 노동자 부족 문제를 해소하기 위하여 인공지능 및 로봇을 농업 분야에 적용하는 농업 자동화 기술에 관한 연구가 많은 관심을 받고 있다. 최근에는 작물의 모니터링을 위한 딥러닝 기반의 단일 스테이지 구조의 YOLO 모델을 적용한 연구가 활발히 진행되고 있다. 하지만, 딥러닝 기반 시스템은 고가의 GPU가 탑재된 노트북 또는 데스크톱으로 구축된 환경이 요구되기 때문에 실제 농가에 보급하기 위해서는 저비용, 저전력의 소형 임베디드 시스템이 요구된다. 따라서 본 연구에서는 대표적 시설작물인 토마토의 인식 및 3차원 위치 검출을 위한 임베디드 시스템을 제안한다. 토마토 검출 임베디드 시스템을 구축하기 위하여 소형 임베디드 장비와 스테레오 카메라로 구성된 시스템을 구현하고 실제 환경에서의 적용 가능성 확인을 목적으로 한다. 구현된 시스템은 STREOLABS의 ZED2 카메라와 NVIDIA의 소형 임베디드 모듈인 Jetson Xavier NX와 AVerMedia의 EN715 보드로 구성되며, 토마토 객체검출을 위하여 4가지 크기의 YOLOv5 모델을 학습시키고 시스템에 적용하여 토마토의 검출과 3차원 위치정보를 얻는다. 시스템의 성능은 각 모델의 평균 정밀도(Average Precision)와 FPS(Frame Per Second) 관점에서 평가된다. IoU 50에서의 최고 AP는 YOLOv5m과 YOLOv5l 모델이 각각 95.46%와 95.41%로 제일 높은 AP를 보이는 결과를 얻었다. 또한, 이미지 처리시간의 차이를 비교한 결과로 네트워크 크기가 작고 가벼운 YOLOv5n과 YOLOv5s 모델은 초당 평균 7.21, 7.47 프레임의 처리를 보이고, YOLOv5l 모델은 평균 5.81 프레임으로 상대적으로 느린 처리속도를 확인할 수 있다. 성능평가 결과로 제안한 시스템이 높은 정밀도로 토마토 객체를 탐지하고 3차원 위치 검출을 실시간으로 처리할 수 있음을 확인하였다.",다국어 초록 정보 없음
딥러닝 모델을 기반한 화재감시 시스템 개발에 관한 연구,2022,"['Deep learning', 'Algorithms', 'Fire detectors', 'YOLO']","산업화 시대 이후 건축기술의 발달에 따라 점진적으로 건축물은 고층화, 대형화되어가고 있으며 이러한 발달에 상응하듯 건축물 화재로 인한 인명과 재산의 피해 규모는 점차 심각해지고 있다. 건축물에서의 화재 방지를 위한 다양한 연구가 진행되어왔으며 CCTV와 연동된 실시간 객체 탐지 알고리즘(Algorithm) 기반의 화재 감시 장비 등이 연구되었다. 기존의 실시간 객체 추적 화재 감시 장비는 YOLO 알고리즘 등을 적용하는 방식으로 하나의 이미지 내에서 객체의 경계 상자(Bounding box) 및 클래스(Class)를 인지한다. 하지만 건축물 내에서 화재가 발생했을 때 연기가 CCTV 내의 화면을 가득 채우게 되면 명확한 객체 추적이 어려운 점이 있다. 본 연구에서는 기존 실시간 객체 추적 알고리즘 기반의 화재 감시 장비의 문제점을 개선하고자 다양한 딥러닝(Deep learning) 알고리즘들을 분석하였고, 분석 결과를 토대로 최적의 딥러닝 모델을 영상 추적 시스템에 적용하여 화재 연기에 의한 객체 추적의 어려움을 해결하고자 하였다. 본 연구에서는 정상 이미지와 화염, 연기 등의 다양한 연소생성물들이 포함된 이미지의 데이터 세트를 구성하였고, 다양한 컨볼루션 신경망 학습 모델들에 대해 합성곱 연산, 여러 가지 활성화 함수 등을 반영하여 학습을 진행하였다. 다양한 컨볼루션 신경망 알고리즘들에 대한 화재 탐지 결과들로부터 정확도, 학습 속도, 탐지 속도 등을 비교하였고, 여러 종류의 연소생성물들을 감지하기 위한 최적의 모델을 찾고자 하였다. 또한, 모델 내의 특정 옵션이 모델 성능에 끼치는 영향 등에 대해서도 분석을 진행하였다.",다국어 초록 정보 없음
Identifying threatening drone based on deep learning with SWIR camera,2022,"['Drone', 'Deep Learning', 'Drone Identification', 'YOLO', 'SWIR camera']",국문 초록 정보 없음,"Small drones of various sizes are used in numerous fields, including commerce, reconnaissance, and offensive attacks. Major facilities such as security areas of port, power, and offshore plants urgently need to develop solutions for detecting drones as an active countermeasure against small drone attacks because small drones used for military and terrorism pose a significant threat. It is not easy to detect various drones such as invasive or threatening ones, though recent developments have made it possible to detect them using three-dimensional radar. Therefore, this paper develops threatening drone identification system, which consists of two components: One is a software component for identifying threatening drones among various ones and the other is a hardware component for the system. The former uses well-known YOLO(You Look Only Once) (v7) model and the latter comprises a PC for running the model and an SWIR (Short-Wave InfraRed) camera for surveillance. Datasets for training and evaluation are constructed by hand from air-borne videos taken drones including threating one and is labelled by two types: normal and threatening. The datasets are comprised of 3,992 color images and 4,410 thermal images, which are trained separately. Through experiments, we have shown that mAP@.5 and mAP@.95 are 0.999 and 0.753 (0.999 and 0.760) for color images (for thermal images), respectively. Consequently the proposed system is helpful in identifying threating drones."
장애인을 위한 영아 보육 도움 시스템 설계,2022,"['IoT', '인공지능', '영아 보육 시스템', 'YOLO', 'CNN']","본 논문은 4차 산업혁명의 핵심기술인 인공지능과 IoT를 이용해 장애인과 비장애인이 영아를 보육하는 데 있어서 도움을 줄 수 있는 시스템을 설계하였다. 본 시스템은 Raspberry pi를 기반으로 Raspberry pi의 여러 센서를 통해 실시간 영상, 음성, 온도 등 여러 가지 데이터를 수집한 뒤 음성데이터를 벡터화 시켜 CNN 분류 모델을 통해 울음소리를 감지하고 배고픔, 트림, 복통, 피곤, 불편 의 5가지 상태로 분류한다. 또한, YOLO 모델을 이용해 아기 얼굴 상태를 감지하여 질식사를 방지한다. 장애인을 위한 영아 보육 도움 시스템은 시각 장애인이나 청각 장애인 부모가 아이의 돌연사를 방지할 수 있게 도움을 준다.",다국어 초록 정보 없음
Smart Management of Recyclables Separate Collection and Trash Bins Monitoring,2022,"['Smart Management', 'Monitoring System', 'Separating Recyclable Trash', 'YOLO object detection', 'Firebase Database', 'Web and Mobile Applications']",국문 초록 정보 없음,"This paper proposed a concept of smart management and monitoring system for separating recyclable trash by utilizing a camera attached to Raspberry Pi and a YOLO object detection algorithm to detect and classify recyclable trash. A set of sensors measured both weight and volume to detect the trash bin’s capacity and GPS to get the trash bin’s location coordinate. The capacity information is then uploaded to Firebase Realtime Database via Long Range (LoRa) communication module to be retrieved by web and mobile applications to provide monitoring capability in real-time. Both applications will show the capacity detail, the location as well as the history graph of each trash bin"
라즈베리파이를 이용한 객체검출방안에 관한 연구,2022,"['라즈베리파이', '비정형 데이터', '카메라 센서', '인체감지 센서', '컨볼루션 신경망 네트워크', 'YOLO 알고리즘', 'Raspberry Pi', 'Unstructured data', 'Camera sensor', 'Passive infrared sensor', 'CNN', 'YOLO algorithm']",국문 초록 정보 없음,다국어 초록 정보 없음
발전설비제조공장의 작업 안전 유스케이스 분석을 통한 영상기반 안전관리기술 개발,2022,"['Heat exchanger rod', 'Work environment safety', 'Vision recognition', 'Yolo', 'Personal protective equipment']",국문 초록 정보 없음,다국어 초록 정보 없음
영상 처리를 이용한 IoT 기반 웨어러블 스마트 안전장비,2022,"['Kickboard sharing services', 'Single-person transportation', 'Object detection', 'YOLO v5', 'Driving assistance']",국문 초록 정보 없음,"With the recent expansion of electric kickboards and bicycle sharing services, more and more people use them. In addition, the rapid growth of the delivery business due to the COVID-19 has significantly increased the use of two-wheeled vehicles and personal mobility. As the accident rate increases, the rule related to the two-wheeled vehicles is changed to 'mandatory helmets for kickboards and single-person transportation' and was revised to prevent boarding itself without driver's license. In this paper, we propose a wearable smart safety equipment, called SafetyHelmet, that can keep helmet-wearing duty and lower the accident rate with the communication between helmets and mobile devices. To make this function available, we propose a safe driving assistance function by notifying the driver when an object that interferes with driving such as persons or other vehicles are detected by applying the YOLO v5 object detection algorithm. Therefore it is intended to provide a safer driving assistance by reducing the failure rate to identify dangers while driving single-person transportation."
Pseudo-LiDAR를 활용한 자율주행 영상인식 시스템의 3D 객체 검출 성능향상 연구,2022,"['3D Object Detection', 'Autonomous driving', 'Perception', 'Deep learning', 'Pseudo-LiDAR', 'Complex YOLO']",국문 초록 정보 없음,"With the rise of artificial intelligence (AI) and the success of various deep neural network (DNN) applications, the autonomous driving has gained significant interest as one of promising research fields in both industry and academia. Autonomous driving technologies are largely divided into three stages which are perception, decision and control, and AI is making great research achievements in the perception. So far, the LiDAR sensor has been considered as a primary sensing media since it provides accurate depth information. Nevertheless, researchers have sought the alternative of the LiDAR due to the high cost and power consumption, as well as its unattractive design. In this work, we present an alternative, cost-effective and highly accurate 3D object detection mechanism built upon a simple stereo camera sensor, while providing performance comparable to the one based on LiDAR sensor. By converting images into point cloud called Pseudo-LiDAR and using it, then we can achieve 3.6x greater accuracy than image based algorithms. In terms of speed, we can achieve 18x faster inference time than MV3D or F-PointNet. In conclusion, an accurate and cost-effective object detector can be made by combining Complex-YOLO and the Pseudo-LiDAR method."
‘싱글 라이프’ 미디어 콘텐츠의 시청이  비혼 의지와 여가활동 라이프스타일에 미치는 영향,2022,"['싱글 라이프', '비혼', '관찰 리얼리티', '브이로그', '욜로', '라이프스타일', 'Single Household', 'Singlehood Life', 'Reality TV', 'YouTube Vlog', 'YOLO', 'Lifestyle']","본 연구는 1인 가구의 확산과 비혼의 증가라는 사회 트렌드의 요인으로 엔터테인먼트 미디어 콘텐츠의 영향을 살펴보고자 했다. ‘싱글 라이프’를 보여주는 관찰 리얼리티 및 유튜브 브이로그 콘텐츠의 증가는 1인 가구 확산이라는 현상을 반영한 것이기도 하지만, 이미 주류가 된 1인 가구들은 미디어 이용을 통해 이러한 라이프스타일에 대한 의지를 공고히 할 수도 있다. “라이프스타일 변형적 리얼리티 콘텐츠” 관점에 따르면, 근래의 리얼리티 영상 콘텐츠는 단순히 오락과 재미에 그치는 것이 아니라 수용자의 현실 삶의 방식을 변화시킬 의미있는 경험을 제공한다. 최근 ‘욜로(YOLO)’에서 ‘갓생’으로 변화하는 라이프스타일에 대한 논의들은 주로 인구사회학적 변인들을 중심으로 그 원인을 설명해온 가운데, 1인 가구 시청자들에게 ‘싱글 라이프’ 관련 미디어 콘텐츠가 갖는 의미를 분석했다. 미혼 성인남녀를 대상으로 설문조사 실시 결과, ‘싱글 라이프’를 보여주는 관찰 리얼리티 프로그램과 유튜브 브이로그의 이용이 많을수록 수용자의 동일시와 비혼 의지가 높았으며, 현재중심적인 라이프스타일과 미래지향적인 라이프스타일이 모두 유의미하게 높은 것으로 나타났다. 이를 바탕으로, 엔터테인먼트 콘텐츠의 최근 경향이 청년층의 삶의 방식에 미치는 영향의 함의에 대해 논했다.","This study explored the effects of recent ‘single life’ media contents on the spread of singlehood culture for Korean youth. Extant research on the changing trends across present-centered vs. future-oriented lifestyles had focused mainly on demographic or sociological factors. “Lifestyle transforming (entertainment) reality contents” perspective suggests that reality contents revealing one’s personal daily life provides not just entertaining enjoyment but also and more importantly meaningful life-changing experiences for viewers. Given the dependency of single household youth on media use, it is expected that ‘singlehood life’ media contents such as reality television and YouTube Vlog would have greater influence on viewers’ own reality and lifestyles. Survey results indicate that viewership of ‘singlehood life’ contents showed significant impacts on youth viewers’ identification and unmarriedness, as well as present-centered and future-oriented lifestyles. Theoretical and practical implications of these results were discussed."
정밀 밀링가공시 딥러닝 기법을 이용한 절삭공구 적정성 연구,2022,"['Artificial Intelligence(인공지능)', 'Milling Operation(밀링작업)', 'T Groove Dovetail Assembly(T글루브 도브테일 조립체)', 'Cutting Tool(절삭공구)', 'Adequacy(적정성)', 'Deep Learning(딥러닝)', 'You Only Look Once(YOLO)(욜로)']",국문 초록 정보 없음,"Recently, the applicability of artificial intelligence, one of the core technologies of the 4th Industrial Revolution, has gradually in the manufacturing sector. The cutting tools used in the milling process require careful inspections to prevent unsuspected interruptions in the manufacturing process. In this study, deep learning image processing technology was used to determine the cutting tool adequacy for the T-groove dovetail assembly milling process. Here, adequacy refers to checking for tool breakage and an appropriate set-up length. This approach involves the application of deep learning techniques on tool images acquired during the cutting process. For this purpose, YOLO, a fast image-processing object-detection technique, was used. Through the images acquired during the working process, the type of cutting tool, tool breakage, and appropriateness of the setup length could be determined."
딥러닝 기반 컨테이너 적재 정렬 상태 및 사고 위험도 검출 기법,2022,"['컨테이너', 'YOLOv4', '딥러닝', '객체인식', 'Shipping Container', 'YOLOv4', 'Deep Learning', 'Object Detection']","최근 항만에서는 부정확한 컨테이너 적재로 인해 컨테이너가 강풍에 쉽게 쓰러지는 컨테이너 붕괴 사고가 빈번이 발생하고 있으며 이는 물적피해와 항만 시스템 마비로 이어지고 있다. 본 논문에서는 이런 사고를 미연에 방지하기 위해 딥러닝 기반 컨테이너 적재 상태 및 사고 위험도검출 시스템을 제안한다. 제안된 시스템은 darknet 기반 YOLO 모델을 활용하여 컨테이너 상하의 코너캐스팅을 통해 컨테이너 정렬 상태를 실시간으로 파악하고 관리자에게 사고 위험도를 알리는 시스템이다. 제안된 시스템은 추론 속도, 분류 정확도, 검출 정확도 등을 성능 지표와 실제 구현환경에서 최적의 성능을 보인 YOLOv4 모델을 객체 인식 알고리즘 모델로 선택하였다. 제안된 알고리즘인 YOLOv4가 YOLOv3보다 추론속도와FPS의 성능 측면에서 낮은 성능을 보이기는 했지만, 분류 정확도와 검출 정확도에서 강력한 성능을 보임을 증명하였다.","Incorrectly loaded containers can easily knock down by strong winds. Container collapse accidents can lead to material damage andparalysis of the port system. In this paper, We propose a deep learning-based container loading state and accident risk detection technique.Using Darknet-based YOLO, the container load status identifies in real-time through corner casting on the top and bottom of the container,and the risk of accidents notifies the manager. We present criteria for classifying container alignment states and select efficient learningalgorithms based on inference speed, classification accuracy, detection accuracy, and FPS in real embedded devices in the sameenvironment. The study found that YOLOv4 had a weaker inference speed and performance of FPS than YOLOv3, but showed strongperformance in classification accuracy and detection accuracy."
다중 객체 추적 알고리즘을 이용한 가공품 흐름 정보 기반 생산 실적 데이터 자동 수집,2022,"['인공지능', '다중 객체 추적', '제조 데이터 수집', '흐름 생산 공정', 'Artificial Intelligence', 'Multi-Object Tracking', 'Manufacturing Data Collection', 'Flow Shop']","최근 제조업에서의 디지털 전환이 가속화되고 있다. 이에 따라 사물인터넷(internet of things: IoT) 기반으로 현장 데이터를 수집하는 기술의 중요성이 증대되고 있다. 이러한 접근법들은 주로 각종 센서와 통신 기술을 활용하여 특정 제조 데이터를 확보하는 것에 초점을 맞춘다. 현장 데이터 수집의 채널을 확장하기 위해 본 연구는 비전(vision) 인공지능 기반으로 제조 데이터를 자동 수집하는 방법을 제안한다. 이는 실시간 영상 정보를 객체 탐지 및 추적 기술로 분석하고, 필요한 제조 데이터를 확보하는 것이다. 연구진은 객체 탐지 및 추적 알고리즘으로 YOLO(You Only Look Once)와 딥소트(DeepSORT)를 적용하여 프레임별 객체의 움직임 정보를 수집한다. 이후, 움직임 정보는 후보정을 통해 두 가지 제조 데이터(생산 실적, 생산 시간)로 변환된다. 딥러닝을 위한 학습 데이터를 확보하기 위해 동적으로 움직이는 공장 모형이 제작되었다. 또한, 실시간 영상 정보가 제조 데이터로 자동 변환되어 데이터베이스에 저장되는 상황을 재현하기 위해 운영 시나리오를 수립하였다. 운영 시나리오는 6개의 설비로 구성된 흐름 생산 공정(flow-shop)을 가정한다. 운영 시나리오에 따른 제조 데이터를 수집한 결과 96.3%의 정확도를 보였다.","Recently, digital transformation in manufacturing has been accelerating. It results in that the data collection technologies from the shop-floor is becoming important. These approaches focus primarily on obtaining specific manufacturing data using various sensors and communication technologies. In order to expand the channel of field data collection, this study proposes a method to automatically collect manufacturing data based on vision-based artificial intelligence. This is to analyze real-time image information with the object detection and tracking technologies and to obtain manufacturing data. The research team collects object motion information for each frame by applying YOLO (You Only Look Once) and DeepSORT as object detection and tracking algorithms. Thereafter, the motion information is converted into two pieces of manufacturing data (production performance and time) through post-processing. A dynamically moving factory model is created to obtain training data for deep learning. In addition, operating scenarios are proposed to reproduce the shop-floor situation in the real world. The operating scenario assumes a flow-shop consisting of six facilities. As a result of collecting manufacturing data according to the operating scenarios, the accuracy was 96.3%."
AI를 이용한 홈CCTV 영상의 반려묘 행동 패턴 분석 및 질병 예측 시스템 연구,2022,"['Abnormal Detection', 'Pose Estimation', 'Object Detection', 'Home CCTV', '이상 탐지', '자세 추정', '객체 인식', '홈 카메라']","반려동물 중 반려묘의 비중이 2012년 이후 연평균 25.4%의 증가율을 보이며 증가하는 추세이다. 고양이는 강아지에 비해 야생성이 강하게 남아있기 때문에 질병이 생기면 잘 숨기는 특성이 있다. 보호자가 반려묘가 질병이 있음을 알게 되었을 때는 병이 이미 악화되어진 상태일 수 있다. 반려묘의 식욕부진(식사회피), 구토, 설사, 다음, 다뇨 등과 같은 현상은 당뇨, 갑상선기능항진증, 신부전증, 범백혈구감소증 등 고양이 질병 시 나타나는 증상 중 일부이다. 반려묘의 다뇨(소변 양이 많음), 다음(물 많이 마심), 빈뇨(소변을 자주 봄) 현상을 보호자가 보다 빨리 알아차릴 수 있다면 반려묘의 질병 치료에 크게 도움이 될 것이다. 본 논문에서는 인공지능 디바이스에서 작동하는 1) 자세 예측 DeepLabCut의 Efficient 버전, 2) 객체 검출 YOLO v4, 3) 행동 예측 LSTM 4) 객체 추적은 BoT-SORT를 사용한다. 인공지능 기술을 이용하여 홈 CCTV의 영상에서 반려묘의 행동 패턴 분석과 물그릇의 무게 센서를 통해 반려묘의 다음, 다뇨 및 빈뇨를 예측한다. 그리고, 반려묘 행동 패턴 분석을 통해, 질병 예측 및 이상행동 결과를 보호자에게 리포트 하는, 메인 서버시스템과 보호자의 모바일로 전달하는 애플리케이션을 제안한다.","Cats have strong wildness so they have a characteristic of hiding diseases well. The disease may have already worsened when the guardian finds out that the cat has a disease. It will be of great help in treating the cat's disease if the owner can recognize the cat's polydipsia, polyuria, and frequent urination more quickly. In this paper, 1) Efficient version of DeepLabCut for pose estimation, 2) YOLO v4 for object detection, 3) LSTM is used for behavior prediction, and 4) BoT-SORT is used for object tracking running on an artificial intelligence device. Using artificial intelligence technology, it predicts the cat's next, polyuria and frequency of urination through the analysis of the cat's behavior pattern from the home CCTV video and the weight sensor of the water bowl. And, through analysis of cat behavior patterns, we propose an application that reports disease prediction and abnormal behavior to the guardian and delivers it to the guardian's mobile and the server system."
이미지와 센서 데이터를 활용한 딥러닝 기반 반려동물 이상행동 탐지 서비스,2022,"['이상행동 탐지', '행동패턴 분석', '멀티모달 분석', '딥 러닝', '웨어러블 디바이스', 'Abnormal Behavior Detection', 'Behavior Pattern Analysis', 'Multimodal Analysis', 'Deep Learning', 'Wearable Device']","본 논문에서는 영상 데이터와 센서 데이터를 활용한 딥러닝 기반의 반려동물 이상행동 탐지 서비스를 제안한다. 최근 반려동물 보유 가구의 증가로 인해 기존 푸드 및 의료 중심의 반려동물 시장에서 인공지능을 더한 펫테크(Pet Tech) 산업이 성장하고 있다. 본 연구에서는 인공지능을 통한 반려동물의 건강관리를 위해 영상 및 센서 데이터를 활용한 딥러닝 모델을 기반으로 반려동물의 행동을 분류하고, 이상행동을 탐지하였다. 자택의 CCTV와 직접 제작한 펫 웨어러블 디바이스를 활용하여 반려동물의 영상 데이터 및 센서 데이터를 수집하고, 모델의 입력 데이터로 활용한다. 행동의 분류를위해 본 연구에서는 반려동물의 객체를 검출하기 위한 YOLO(You Only Look Once) 모델과 관절 좌표를 추출하기 위한 DeepLabCut을 결합하여 영상 데이터를 처리하였고, 센서 데이터를 처리하기 위해 각 센서 별 연관관계 및 특징을 파악할 수 있는 GAT(Graph Attention Network)를 활용하였다.","In this paper, we propose the Deep Learning-Based Companion Animal Abnormal Behavior Detection Service, which using video and sensor data. Due to the recent increase in households with companion animals, the pet tech industry with artificial intelligence is growing in the existing food and medical-oriented companion animal market. In this study, companion animal behavior was classified and abnormal behavior was detected based on a deep learning model using various data for health management of companion animals through artificial intelligence. Video data and sensor data of companion animals are collected using CCTV and the manufactured pet wearable device, and used as input data for the model. Image data was processed by combining the YOLO(You Only Look Once) model and DeepLabCut for extracting joint coordinates to detect companion animal objects for behavior classification. Also, in order to process sensor data, GAT(Graph Attention Network), which can identify the correlation and characteristics of each sensor, was used."
이미지 인식을 통한 AI 기반 소방 시설 설계 기술 개발에 관한 연구,2022,"['fire safety design', 'fire safety design', 'image learning', 'deep learning', 'Fire fighting Design', '화재안전설계', '인공지능', '이미지 학습', '딥러닝', '소방설계 솔루션']","연구목적:  현재 국내 소방시설설계의 경우 낮은 설계단가와 업체 간 과열 경쟁으로 고급 인력에 대한 확보가 어려워 건축물의 화재안전성능을 향상시키는데 한계가 있다. 이에 이러한 문제를 해소하고 선도적인 소방엔지니어링 기술을 확보하기 위해 AI 기반 소방설계솔루션을 연구하였다. 연구방법:  기존 소방설계에 많이 사용되는 AutoCAD를 통해 기본 설계 및 실시 설계에 필요한 절차를 프로세스화 하고 YOLO v4 객체 인식 딥러닝 모델을 통해 AI기술을 활용하였다. 연구결과: 소방시설에 대한 설계프로세스를 통해 설비의 결정과 도면 설계 자동화를 진행하였다. 또한 문 및 기둥에 대한 이미지를 학습시켜 인공지능이 해당 부분을 인식하여 경계구역 선정, 배관 및 소방시설을 설치하는 기능을 구현하였다.  결론: 인공지능 기술을 기반으로 건축물 화재방호 설비에 대한 기본 및 실시 설계 도면 작성 시 인적 및 물적 자원을 저감시킬 수 있을 것으로 확인되었으며 선행적인 기술 개발을 통해 인공지능 기반 소방설계에 기술력을 확보하였다.","Purpose: Currently, in the case of domestic fire fighting facility design, it is difficult to secure high-quality manpower due to low design costs and overheated competition between companies, so there is a limit to improving the fire safety performance of buildings. Accordingly, AI-based firefighting design solutions were studied to solve these problems and secure leading fire engineering technologies. Method: Through AutoCAD, which is widely used in existing fire fighting design, the procedures required for basic design and implementation design were processed, and AI technology was utilized through the YOLO v4 object recognition deep learning model. Result: Through the design process for fire fighting facilities, the facility was determined and the drawing design automation was carried out. In addition, by learning images of doors and pillars, artificial intelligence recognized the part and implemented the function of selecting boundary areas and installing piping and fire fighting facilities. Conclusion: Based on artificial intelligence technology, it was confirmed that human and material resources could be reduced when creating basic and implementation design drawings for building fire protection facilities, and technology was secured in artificial intelligence-based fire fighting design through prior technology development."
인공지능 객체 탐지를 활용한 스마트 공장 안전 시스템,2022,"['스마트 공장', '지능형 영상 분석', '객체 추적', '객체 탐지', 'YOLOv5', 'DeepSORT', 'smart factory', 'intelligent video analysis', 'object tracking', 'object detection', 'YOLOv5', 'DeepSORT']","공장 내 안전사고 중 부딪힘, 물체에 맞음, 교통사고와 같이 작업자와 위험물체의 충돌로 인한 재해사고가 높은 비율을 차지하고 있다. 이러한 예기치 못한 안전사고를 예방하기 위해 공장의 위험 상황을 미리 파악하고 작업자에게 최대한 빠르게 알리는 것이 중요하다. 본 논문에서는 인공지능 객체 탐지 기술을 활용하여 공장 내 작업자와 위험물체의 실시간 위치를 판별하고, 작업자와 위험물체의 위치에 따라 실시간으로 변동하는 위험지역을 계산한다. 또한 움직이는 물체만 탐지하는 알고리즘을 사용하여 충돌 위험을 감지할 수 있다. 실시간 객체 탐지를 위해 다른 객체 탐지 알고리즘보다 처리 속도가 빠른 YOLO(You Only Look Once) 알고리즘을 사용하였다. 실험은 실제 공장 환경에 CCTV를 설치하여 데이터를 수집하고 안전 시스템을 구축하였다. 학습된 객체 탐지 모델의 성능을 평가한 결과, 객체 탐지의 성능의 지표로 사용되는 mAP는 0.985로 높은 성능을 보여주었다.","Colliding between workers and dangerous objects take up a huge proportion of accidents in factories. Thus, it is important to analyze factory situation in real-time in order to prevent such unexpected accidents and inform workers as quickly as possible. The objective of this paper is to introduce an artificial intelligence object detection technology that can distinguish locations of workers and dangerous objects in real time and calculate the shifting danger zone based on their locations. It can also sense the risk by using algorithm capable of detecting mobile objects only. To detect object real time, YOLO (You Only Look Once) algorithm with faster inference time than other algorithms was selected. The learned object detection model showed high performance, with a mean average precision (an indicator of object detection performance) of 0.985."
인공지능을 활용한 도주경로 예측 및 추적 시스템,2022,"['영상분석', '인공지능', '도주경로예측', '자동상황전파', '스마트시티 통합플랫폼', 'Intelligent image analysis', 'Escape route prediction', 'Automatic situation propagation', 'Smart city Integrate platform']","서울특별시는 25개 구청에 7만5천여대의 CCTV가 설치되어 있다. 각 구청은 CCTV관제를 위한 관제센터를 구축하고 시민의 안전을 위해 24시간 CCTV영상관제를 수행하고 있다. 서울특별시는 유관기관과 MOU를 체결하여 긴급/응급 상황에 신속한 대응이 가능하도록 구청의 CCTV영상을 제공하여 시민이 안전한 스마트시티통합플랫폼을 구축하고 있다. 본 논문에서는, 서울특별시 관할구청에서 사건 발생 시, CCTV영상에 대해 인공지능 DNN 기반의 Template Matching 기술, MLP 알고리즘과 CNN 기반으로 YOLO SPP DNN모델을 사용하여 사람과 차량을 판별하여 도주경로를 예측한다. 또한, 관할구청을 이탈하여, 차량 및 사람이 도주 시, 인접 구청에 영상정보와 상황정보를 자동전파 하도록 설계한다. 인공지능을 활용한 도주경로 예측 및 추적 시스템은 스마트시티 통합플랫폼을 전국으로 확장시킬 수 있다.","In Seoul, about 75,000 CCTVs are installed in 25 district offices. Each ward office has built a control center for CCTV control and is performing 24-hour CCTV video control for the safety of citizens. Seoul Metropolitan Government is building a smart city integrated platform that is safe for citizens by providing CCTV images of the ward office to enable rapid response to emergency/emergency situations by signing an MOU with related organizations. In this paper, when an incident occurs at the Seoul Metropolitan Government Office, the escape route is predicted by discriminating people and vehicles using the AI ​​DNN-based Template Matching technology, MLP algorithm and CNN-based YOLO SPP DNN model for CCTV images. . In addition, it is designed to automatically disseminate image information and situation information to adjacent ward offices when vehicles and people escape from the competent ward office. The escape route prediction and tracking system using artificial intelligence can expand the smart city integrated platform nationwide."
Mask R-CNN-based Occlusion Anomaly Detection Considering Orientation in Manufacturing Process Data,2022,"['Manufacturing process', 'Orientation', 'Object detection', 'Mask R-CNN', 'Anomaly detection']",국문 초록 정보 없음,"In a manufacturing process, data analysis is conducted to identify defective products in real time to lower their massive production and improve the rate of efficient production. In the production process, it is difficult to find defective products mixed with normal products. Therefore, it is necessary to detect defective products generated in the production process and reduce the risk of their production. Consequently, this study proposes the Mask R-CNN-based occlusion anomaly detection method in consideration of the orientation of manufacturing process data. The proposed method uses Mask R-CNN to find abnormal objects, such as occluded objects, in a manufacturing process line. In the manufacturing process, some products are hidden. Accordingly, preprocessing in consideration of multiple orientations is applied to generate data. The generated data is performed to detect occlusions and anomalies using Mask R-CNN. The mean of IoU was compared to evaluate the detection accuracy of YOLO and Mask R-CNN. YOLO showed excellent performance when there was a constant distance and orientation and no occluded object. However, Mask R-CNN performed excellently when there was any occluded object and the orientation was considered. Therefore, for occlusion anomaly detection in a manufacturing process, Mask R-CNN can reduce the production rate of defective products."
데이터 증강 학습 이용한 딥러닝 기반 실시간 화재경보시스템 구현,2022,"['Deep Learning', 'Real-time Detection', 'Fire Alarm', 'Object Detection', 'Data Augmentation']","본 논문에서는 딥러닝을 이용하여 실시간 화재경보 시스템을 구현하는 방법을 제안한다. 화재경보를 위한 딥러닝 학습 이미지 데이터셋은 인터넷을 통하여 1500장을 취득하였다. 일상적인 환경에서 취득된 다양한 이미지를 그대로 학습하게 되면 학습 정확도가높지 않은 단점이 있다. 본 논문에서는 학습 정확도 향상을 위해 화재 이미지 데이터 확장 방법을 제안한다. 데이터증강 방법은 밝기 조절, 블러링, 불꽃사진 합성을 이용해 학습 데이터 600장을 추가해 총 2100장을 학습했다. 불꽃 이미지 합성방법을 이용하여확장된 데이터는 정확도 향상에 큰 영향을 주었다. 실시간 화재탐지 시스템은 영상 데이터에 딥러닝을 적용하여 화재를 탐지하고사용자에게 알림을 전송하는 시스템이다. Edge AI시스템에 적합한 YOLO V4 TINY 모델을 custom 학습한 모델을 이용해 실시간으로 영상을 분석해 화재를 탐지하고 그 결과를 사용자에게 알리는 웹을 개발하였다. 제안한 데이터를 사용하였을 때 기존 방법에비하여 약 10%의 정확도 향상을 얻을 수 있다.","In this paper, we propose a method to implement a real-time fire alarm system using deep learning. The deep learningimage dataset for fire alarms acquired 1,500 sheets through the Internet. If various images acquired in a daily environmentare learned as they are, there is a disadvantage that the learning accuracy is not high. In this paper, we propose a fireimage data expansion method to improve learning accuracy. The data augmentation method learned a total of 2,100sheets by adding 600 pieces of learning data using brightness control, blurring, and flame photo synthesis. The expandeddata using the flame image synthesis method had a great influence on the accuracy improvement. A real-time firedetection system is a system that detects fires by applying deep learning to image data and transmits notifications to users.An app was developed to detect fires by analyzing images in real time using a model custom-learned from the YOLO V4TINY model suitable for the Edge AI system and to inform users of the results. Approximately 10% accuracy improvementcan be obtained compared to conventional methods when using the proposed data."
실주행 영상 자료 기반의 교통안전표지 인식 거리 산출 연구,2022,"['Traffic Sign', 'YOLOv5', 'Image Data', 'Autonomous Vehicle', 'Camera']","본 연구에서는 자율주행차의 주행 안전성을 확보하기 위한 방법으로써, 도로시설물 중에서 교통안전표지를 대상으로 선정하고, 교통안전표지의 형태 및 내용의 인식 성능을 향상 시킬 수 있는 모델 개발 연구를 수행하였다. 카메라가 부착된 차량을 이용하여 국도의 영상 정보를 수집했으며, 영상에 존재하는 교통안전표지를 인식하고 정확도를 분석하였다. 교통안전표지가 존재하는 3,215개의 영상 자료 중에서, 차량의 주행 안전성과 직접적으로 관련된 17개를 분석 대상으로 선정하였다. 모델 개발에 사용된 전체 영상 자료를 학습 데이터(80%), 평가 데이터(20%)로 구분하여 분석했으며, You Only Look Once (YOLO)v5 모델을 교통안전표지의 인식 모델로 사용하였다. 분석 결과, 차량과 교통안전표지와의 거리가 25m 이하에서는 mean Average Precision (mAP)는 89.4로 나타났으며, 차량과 교통안전표지의 거리가 25m 이상이 되면 mAP는 급격히 감소하여 약 33m 부근에서는 약 0.73으로 mAP가 낮아지는 것으로 분석되었다. 본 연구의 결과는 높은 자율주행 성능의 기술 수준을 확보하는 상황에서, 자율주행차의 인식 성능을 검증하는 연구에 활용될 것으로 기대된다.","Accurate perception of surroundings is a key component of autonomous vehicles to ensure efficient and safe navigation. Traffic safety signs are road facilities that have to be recognized with high precision. In this study, an algorithm was developed to improve the recognition of the shape and content of traffic signs. The accuracy of traffic sign recognition was verified using data collected after conducting a field survey using a camera-equipped vehicle along an arterial road. A total of 3,215 images of traffic safety signs in different locations were analyzed, and the signs were visually identified. To develop a model for road sign recognition, the data were analyzed by dividing the total dataset into 80% training data and 20 % validation data. The widely used ""You Only Look Once"" (YOLO)v5 image recognition technique was employed. As a result of the analysis, the mean Average Precision (mAP) was 89.4 when the distance between the vehicle and the traffic safety sign was 25 m or less. When the distance was more than 25 m, the mAP rapidly decreased at around 33 m. The research was limited to analyzing the accuracy of recognizing the shape and content of traffic signs. The results are expected to be applied in autonomous vehicles in the future when a high level of autonomous driving performance is needed."
VEHICLE NUMBER DETECTION AI SYSTEM FOR PEDESTRIAN SAFETY,2022,"['YOLO', 'CNN', 'OCR', 'Deep Learning', 'Accuracy']",국문 초록 정보 없음,다국어 초록 정보 없음
스테레오 비전 기반 토마토 3차원 위치 검출 시스템 구현,2022,"['YOLO', 'Deep learning', 'Object detection', 'Stereo vision', 'Harvesting']",국문 초록 정보 없음,다국어 초록 정보 없음
방역수칙 위반 감시를 위한 자율주행 서비스 로봇 개발,2022,"['SLAM', 'YOLO', 'Service Robot', '자율주행(Self-driving)']",국문 초록 정보 없음,다국어 초록 정보 없음
노상 주차 차량 탐지를 위한 YOLOv4 그리드 셀 조정 알고리즘,2022,"['YOLOv4', 'YOLO Custom Training', 'Vehicle Detection', 'Cell Shift Algorithm']",국문 초록 정보 없음,"YOLOv4 can be used for detecting parking vehicles in order to check a vehicle in out-door parking space. YOLOv4 has 9 anchor boxes in each of 13x13 grid cells for detecting a bounding box of object. Because anchor boxes are allocated based on each cell, there can be existed small observational error for detecting real objects due to the distance between neighboring cells. In this paper, we proposed YOLOv4 grid cell shift algorithm for improving the out-door parking vehicle detection accuracy. In order to get more chance for trying to object detection by reducing the errors between anchor boxes and real objects, grid cells over image can be shifted to vertical, horizontal or diagonal directions after YOLOv4 basic detection process.The experimental results show that a combined algorithm of  a custom trained YOLOv4 and a cell shift algorithm has 96.6% detection accuracy compare to 94.6% of a custom trained YOLOv4 only for out door parking vehicle images."
YOLOv5와 Kalman Filter를 이용한 화재 검출 및 추적 연구,2022,"['Artificial intelligence', 'YOLO', 'Kalman Filter', 'Detection']","화재가 어느 곳에서나 발생하고, 최근에 화재가 발생하면서 사람들의 생명과 재산피해를 일으킨다. 화재 발생 초기에는 작은 불씨에서 시작되어 연기가 생성되고, 대형화재가 발생한다. 초기에 사람들이 화재를 바로 알아채지 못해 발생하는 화재가 큰 영향을 미친다. 연기는 화재 초기에 발생하므로 초기 검출이 매우 중요하다. 화재가 발생할 때 신속하게 연기와 불꽃을 감지하고 화재가 발생하여도 최대한 빠르게 화재를 감지할 수 있는 불꽃 및 연기 판별이 필요하다. 본 연구는 YOLOv5와 Kalman Filter를 통하여 불꽃 및 연기를 판별하고, 추정하는 연구를 진행하였다.","Fires occur everywhere, and recent fires cause damage to peoples lives and property. In the early stages of the fire, smoke is generated from small embers, and large fires occur. In the early days, fires caused by people not being able to immediately notice the fire have a big impact. Since smoke occurs early in the fire, initial detection is very important. It is necessary to quickly detect smoke and flames when a fire occurs, and to determine flames and smoke that can detect a fire as soon as possible even if a fire occurs. This study conducted a study to determine and estimate flame and smoke through YOLOv5 and Kalman Filter."
도시철도 안전관리를 위한 역사내 LSTM 기반 이상행동 감지,2022,"['딥러닝', '이상행동', 'YOLO', 'LSTM', 'GRU']",국문 초록 정보 없음,다국어 초록 정보 없음
영상 인식 및 인공지능 기반 군사용 탐사 로봇,2022,"['Camera vision', 'Yolo', 'Manipulator', 'Auto driving', 'Remote driving']",국문 초록 정보 없음,다국어 초록 정보 없음
E-scooter Detection in Media using Deep Learning,2022,"['E-Scooter', 'Yolo v3', 'Object Detection', 'Computer Vision', 'Deep Learning']",국문 초록 정보 없음,다국어 초록 정보 없음
ANOMALY DETECTION FOR AN ORAL HEALTH CARE APPLICATION USING ONE CLASS YOLOV3,2022,"['anomaly detection', 'object detection', 'YOLO.']",국문 초록 정보 없음,"In this report, we apply an anomaly detection algorithm to a mobile oral health care application. In particular, we have investigated one class YOLOv3 as an anomaly detec- tion model to classify pictures of mouths which will be used as inputs in the following machine learning model. We have achieved outstanding performances by proposing appropriate anno- tation strategies for our data sets and modifying the loss function. Moreover, the model can classify not only oral and non-oral pictures but also output preprocessed pictures that only con- tain the area around the lips by using the predicted bounding box. Thus, the model performs prediction and preprocessing simultaneously."
YOLOv5와 YOLOv7 모델을 이용한 해양침적쓰레기 객체탐지 비교평가,2022,"['Deposited marine debris', 'YOLO', 'Object detection', 'Deep learning']",국문 초록 정보 없음,"Deposited Marine Debris(DMD) can negatively affect marine ecosystems, fishery resources, and maritime safety and is mainly detected by sonar sensors, lifting frames, and divers. Considering the limitation of cost and time, recent efforts are being made by integrating underwater images and artificial intelligence (AI). We conducted a comparative study of You Only Look Once Version 5 (YOLOv5) and You Only Look Once Version 7 (YOLOv7) models to detect DMD from underwater images for more accurate and efficient management of DMD. For the detection of the DMD objects such as glass, metal, fish traps, tires, wood, and plastic, the two models showed a performance of over 0.85 in terms of Mean Average Precision (mAP@0.5). A more objective evaluation and an improvement of the models are expected with the construction of an extensive image database."
실시간 객체 및 글자 인식을 통한 식자재 관리 애플리케이션,2022,"['Real time detection', 'YOLO', 'OCR', 'Application', 'Convolution nural network']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝 기반 제품 포장 불량탐지 시스템,2022,"['포장 불량탐지', '딥러닝', 'YOLO 알고리즘', '품질관리']","제조 현장에서 제품의 품질을 관리하는 것은 사업의 수익과도 연관되어 중요한 문제이다. 품질을 개선하기 위한 다양한 접근방법들은 각각의 장점과 한계점을 가지지만, 공통적인 목적은 생산라인의 제품 품질을 가장 효율적으로 관리하는 것이다. 본 연구는 딥러닝 기법을 사용하여 실시간으로 제품 포장의 불량을 탐지하는 시스템의 개발에 관한 것으로, 최종 포장된 제품 외관의 품질 상태를 자동으로 인식하는 것을 목적으로 한다. 이를 위해 YOLOv5 알고리즘을 사용하여 컨베이어 벨트 위로 이동하는 제품의 영상으로부터 품질의 불량을 자동으로 분류하기 위한 모델과 정보 시스템을 제시한다. 향후 생산라인에 설치하여 공장의 다른 시스템에 접목할 수 있도록 하고자 하며, 현장 적용 시 운영비 절감 등에 기여할 수 있을 것이다.",다국어 초록 정보 없음
무인기로 취득한 RGB 영상으로 수수 Panicle 탐지,2022,"['수수', '무인기', 'RGB', 'YOLO']","수수는 국내에서 생산 및 소비량이 적고 수급 안정성이 낮아 해마다 가격 변동이 심하기 때문에 정확한 재배면적과 수확량을 예측할 필요가 있다. 최근 고해상도 영상장치 및 인공지능 기술의 발달로 다량의 비정형 데이터를 이용하여 작물 분류 및 타겟 검출이 가능하게 되었다. 따라서 본 연구는 무인기로 취득한 RGB 영상과 딥러닝을 이용하여 수수의 수확량을 예측하기 위해 Panicle 개수를 추정하였다.실험지역은 경상북도 안동시 남후면 고상리에 위치한 수수 재배지(36°30'20.3N 128°36'27.6E)를 대상으로 수행하였다. 회전익 무인기(Matrice 300 RTK, DJI Technology Inc, China)에 RGB 카메라(Zenmuse P1, DJI Technology Inc, China)를 탑재하여 2022년 9월 2일 고도 25m GSD 0.31cm/pixel로 RGB 영상을 취득하였다. 취득한 다수의 고해상도 8192×5460 이미지를 512×512로 자른 뒤 Label-studio를 이용하여 수수 Panicle 부분을 Bounding Box로 라벨링 후 YOLOv5s를 사용해 학습을 진행하였다.라벨링 작업이 진행된 1200장의 이미지를 6:2:2(Train : Validation : Test) 비율로 나눈 뒤 훈련 횟수는 1000 Epoch로 설정하였으나 Early Stopping 기능으로 127 Epoch 훈련되었다. 모델은 27 Epoch에서 box_loss=0.053, obj_loss=0.172, mAP_0.5=0.789의 높은 성능을 나타내었다. Test 데이터를 이용하여 mAP_50=0.804의 수수 Panicle 탐지 가능성을 볼 수 있었으며 추후 수집해놓은 데이터와 시계열 영상 데이터의 활용으로 수수 Panicle 탐지 모델의 성능을 향상시킬 계획이다.",다국어 초록 정보 없음
딥러닝 영상인식을 이용한 헬멧 미착용 검출 시스템,2022,"['딥러닝(DeepLearning)', '욜로(YOLO)', '객체검출(Object Detection)']",국문 초록 정보 없음,다국어 초록 정보 없음
영상처리를 통한 마스크 및 비마스크 사용자 인식을 위한 연구,2022,"['Face detection', 'Object detection', 'Yolo', 'Quantization']",국문 초록 정보 없음,다국어 초록 정보 없음
인공지능 기반 객체인식 기법에 관한 연구,2022,"['Artificial Intelligence', 'Object Recognition', 'YOLO', 'R-CNN']",최근 들어 차산업 4 연관기술인 사이버물리시스템(CPS) 구축을 위해 물리 모델과 제어회로 시뮬레이션을 위한 가상제어시스템 구축 작업이 다양한 산업 분야에서 요구가 점점 증가하고 있다. 전자 문서화 되지 않은 문서들에 대한 직접입력을 통한 변환은 시간과 비용이 많이 소모된다. 이를 위해 이미 출력된 대량의 도면을 인공지능을 이용한 객체 인식을 통해 디지털화 작업은 매우 중요하다고 할 수 있다. 본 논문에서는 도면내 객체를 정확하게 인식하고 이를 다양한응용에 활용할 수 있도록 하기 위하여 도면내 객체의 특징을 분석하여 인공지능을 활용한 인식 기법을 제안하였다. 객체 인식의 성능을 높이기 위하여 객체별 인식 후 그 정보를 저장하는 중간 파일을 생성하게 하였다. 그리고 인식 결과를 도면에서 삭제하여 다음 인식 대상의 인식률을 향상시켰다. 그리고 그 인식 결과를 표준화 포맷 문서로 저장하여 이를 제어시스템의 다양한 분야에 활용할 수 있도록 하였다. 본 논문에서 제안한 기법의 우수한 성능은 위해 실험을 통해확인할 수 있었다.,"Recently, in order to build a cyber physical system(CPS) that is a technology related to the 4th industry, the construction of the virtual control system for physical model and control circuit simulation is increasingly required in various industries. It takes a lot of time and money to convert documents that are not electronically documented through direct input. For this, it is very important to digitize a large number of drawings that have already been printed through object recognition using artificial intelligence. In this paper, in order to accurately recognize objects in drawings and to utilize them in various applications, a recognition technique using artificial intelligence by analyzing the characteristics of objects in drawing was proposed. In order to improve the performance of object recognition, each object was recognized and then an intermediate file storing the information was created. And the recognition rate of the next recognition target was improved by deleting the recognition result from the drawing. In addition, the recognition result was stored as a standardized format document so that it could be utilized in various fields of the control system. The excellent performance of the technique proposed in this paper was confirmed through the experiments."
무인기로 취득한 RGB 영상과 YOLOv5를 이용한 수수 이삭 탐지,2022,"['Sorghum', 'UAV', 'RGB', 'YOLO', 'Detection']","본 연구는 수수의 수확량 추정을 위해 무인기로 취득한 RGB 영상과 YOLOv5를 이용하여 수수 이삭 탐지 모델을 개발하였다. 이삭이 가장 잘 식별되는 9월 2일의 영상 중 512×512로 분할된 2000장을 이용하여 모델의 학습, 검증 및 테스트하였다. YOLOv5의 모델 중 가장 파라미터가 적은 YOLOv5s에서 mAP@50=0.845로 수수 이삭을 탐지할 수 있었다. 파라미터가 증가한 YOLOv5m에서는 mAP@50=0.844로 수수 이삭을 탐지할 수 있었다. 두 모델의 성능이 유사하나 YOLOv5s (4시간 35분)가 YOLOv5m (5시간 15분)보다 훈련시간이 더 빨라 YOLOv5s가 수수 이삭 탐지에 효율적이라고 판단된다. 개발된 모델을 이용하여 수수의 수확량 예측을 위한 단위면적당 이삭 수를 추정하는 알고리즘의 기초자료로 유용하게 활용될 것으로 판단된다. 추가적으로 아직 개발의 초기 단계를 감안하면 확보된 데이터를 이용하여 성능 개선 및 다른 CNN 모델과 비교 검토할 필요가 있다고 사료된다.","The purpose of this study is to detect the sorghum panicle using YOLOv5 based on RGB images acquired by a unmanned aerial vehicle (UAV) system. The high-resolution images acquired using the RGB camera mounted in the UAV on September 2, 2022 were split into 512×512 size for YOLOv5 analysis. Sorghum panicles were labeled as bounding boxes in the split image. 2,000images of 512×512 size were divided at a ratio of 6:2:2 and used to train, validate, and test the YOLOv5 model, respectively. When learning with YOLOv5s, which has the fewest parameters among YOLOv5 models, sorghum panicles were detected with mAP@50=0.845. In YOLOv5m with more parameters, sorghum panicles could be detected with mAP@50=0.844. Although the performance of the two models is similar, YOLOv5s (4 hours 35 minutes) has a faster training time than YOLOv5m (5 hours 15 minutes). Therefore, in terms of time cost, developing the YOLOv5s model was considered more efficient for detecting sorghum panicles. As an important step in predicting sorghum yield, a technique for detecting sorghum panicles using high-resolution RGB images and the YOLOv5 model was presented."
119 소방차 출동 시 실시간 교통상황 분석 및 화재유형 인공지능 적용 연구,2022,"['Drone', 'Movement Search', 'YOLO', 'Real-time Analysis', 'Type of Fire', 'Scene of a Fire', '119 Firefighting', 'CRNN']",국문 초록 정보 없음,다국어 초록 정보 없음
RGB-D 이미지를 이용한 축 대칭 물체의 파지 알고리즘,2022,"['Grasping pose', 'Object detection', 'Yolo v4', 'ICP', 'RGB-D image']",국문 초록 정보 없음,다국어 초록 정보 없음
YOLOv4 기반의 소형 물체탐지기법을 이용한 건설도면 내 철강 자재 문자 검출 및 인식기법,2022,"['Construction Drawings', 'Text Recognition', 'YOLO', 'Data Augmentation', 'Spatial Attention']","최근 딥러닝 기반의 객체 검출 및 인식 연구가 발전해가면서 산업 및 실생활에 적용되는 범위가 넓어지고 있다. 건설 분야에도 딥러닝 기반의 시스템이 도입되고 있지만 아직은 미온적이다. 건설 도면에서 자재 산출이 수작업으로 이뤄지고 있어 많은 소요시간과 부정확한 적산 결과로 잘못된 물량산출의 거래가 생길 수 있다. 이를 해결하기 위해서 빠르고 정확한 자동 도면 인식시스템이 필요하다. 따라서 본 논문은 건설도면 내 철강 자재를 검출하고 인식하는 인공지능기반 자동 도면 인식 적산 시스템을 제안한다. 빠른 속도의 YOLOv4 기반에 소형 객체 검출성능을 향상하기 위한 복제 방식의 데이터 증강기법과 공간집중 모듈을 적용하였다. 검출한 철강 자재 영역을 문자 인식한 결과를 토대로 철강 자재를 적산한다. 실험 결과 제안한 방식은 기존 YOLOv4 대비 정확도와 정밀도를 각각 1.8%, 16% 증가시켰다. 제안된 방식의 Precision은 0.938, Recall은 1, 는 99.4%, 68.8%의 향상된 결과를 얻었다. 문자 인식은 기존 데이터를 사용한 인식률 75.6%에 비해 건설도면에 사용되는 폰트에 맞는 데이터 세트를 구성하여 학습한 결과 99.9%의 인식률을 얻었다. 한 이미지 당 평균 소요시간은 검출 단계는 0.013초, 문자 인식은 0.65초, 적산 단계는 0.16초로 총 0.84초의 결과를 얻었다.",다국어 초록 정보 없음
A study on Detecting the Safety helmet wearing using YOLOv5-S model and transfer learning,2022,"['Safety Helmet', 'Object Detection', 'Yolo', 'Safety Accidents', 'Personal Protective Equipment']",국문 초록 정보 없음,"Occupational safety accidents are caused by various factors, and it is difficult to predict when and why they occur, and it is directly related to the lives of workers, so the interest in safety accidents is increasing every year. Therefore, in order to reduce safety accidents at industrial fields, workers are required to wear personal protective equipment. In this paper, we proposes a method to automatically check whether workers are wearing safety helmets among the protective equipment in the industrial field. It detects whether or not the helmet is worn using YOLOv5, a computer vision-based deep learning object detection algorithm. We transfer learning the s model among Yolov5 models with different learning rates and epochs, evaluate the performance, and select the optimal model. The selected model showed a performance of 0.959 mAP."
Intelligent Activity Recognition based on Improved Convolutional Neural Network,2022,"['Action Recognition', 'Deep Learning', 'Target Detection', 'Convolutional Neural Network', 'LSTM']",국문 초록 정보 없음,다국어 초록 정보 없음
무인 배달을 위한 거리 추정 및 자율 회피 기술 연구,2022,"['Autonomous Driving', 'Unmanned Delivery', 'YOLO Distance Estimation', 'ODG-PF', 'Adaptive Threshold']",국문 초록 정보 없음,다국어 초록 정보 없음
Quantification of Dicentric Chromosomes Using Object Detection Method via Deep Neural Network,2022,"['Chromosome aberration', 'object detection', 'dicentric chromosome classification', 'YOLO']",국문 초록 정보 없음,다국어 초록 정보 없음
Hepatic steatosis screening analysis study applying artificial intelligence to rats,2022,"['AI model', 'DeepLab', 'Mask R-CNN', 'YOLO', 'Hepatic steatosis']",국문 초록 정보 없음,다국어 초록 정보 없음
OCR과 딥러닝을 활용한 인공지능 항공감시시스템 개발,2022,"['Deep Learning(딥러닝)', 'Object Detecting(객체탐지)', 'YOLO(욜로)', 'OpenCV', 'OCR(광학문자인식)']",국문 초록 정보 없음,다국어 초록 정보 없음
Remote Reading of Surgical Monitor's Physiological Readings: An Image Processing Approach,2022,"['Detectron', 'ICU Monitor', 'Object Detection', 'Perspective Transformation', 'YOLO']",국문 초록 정보 없음,"As a result of the global effect of infectious diseases like COVID-19, remote patient monitoring has become a vital need. Surgical ICU monitors are attached around the clock for patients in critical care. Most ICU monitor systems, on the other hand, lack an output port for transferring data to an auxiliary device for post-processing. Similarly, strapping a slew of wearables to a patient for remote monitoring creates a great deal of discomfort and limits the patient's mobility. Hence, an unique remote monitoring technique for the ICU monitor's physiologically vital readings has been presented, recognizing this need as a research gap. This mechanism has been put to the test in a variety of modes, yielding an overall accuracy of close to 90%."
시각장애인을 위한 음성안내 네비게이션 시스템의 심층신경망 성능 비교,2022,"['The blind', 'navigation', 'deep learning network', 'YOLO', 'faster-rcnn', 'embedded board']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝기반 도로 포트홀 탐지에 관한 연구,2022,"['Deep learning', 'Object detection', 'Porthole', 'YOLO', 'One-stage detector']",‘도로위의 지뢰’라고 불리는 포트홀(Pothole)은 운전에 심각한 장애를 유발하고 있어 한국도로공사 뿐만아니라 지자체에서도 도로에서 발생하는 포트홀을 조기 발견하기 위한 조사 차량을 구입하는 등의 많은 노력을 기울이고 있다. 본 논문에서는 딥러닝 기술을 이용하여 기존에 지자체 및 도로관리기관의 고가 조사 차량이 아닌 상대적으로 가격이 저렴하고 쉽게 접할 수 있는 블랙박스 영상 데이터를 기반으로 도로위의 포트홀을 탐지하고 모니터링할 수 있는 객체 탐지 기술을 구현 및 검증하고자 한다.,다국어 초록 정보 없음
Study On Masked Face Detection And Recognition using transfer learning,2022,"['Masked Face Detection', 'Mask Detection', 'Object Detection', 'Yolo', 'Masked Face Recognition']",국문 초록 정보 없음,"COVID-19 is a crisis with numerous casualties. The World Health Organization (WHO) has declared the use of masks as an essential safety measure during the COVID-19 pandemic. Therefore, whether or not to wear a mask is an important issue when entering and exiting public places and institutions. However, this makes face recognition a very difficult task because certain parts of the face are hidden. As a result, face identification and identity verification in the access system became difficult. In this paper, we propose a system that can detect masked face using transfer learning of Yolov5s and recognize the user using transfer learning of Facenet. Transfer learning preforms by changing the learning rate, epoch, and batch size, their results are evaluated, and the best model is selected as representative model. It has been confirmed that the proposed model is good at detecting masked face and masked face recognition."
딥 러닝 기반 이미지 생성 모델을 활용한 객체 인식 사례 연구,2022,[],"본 논문에서는 생성된 이미지에 대한 YOLO 모델의 객체 인식의 성능을 확인하고 사례를 연구하는 것을 목적으로 한다. 최근 영상 처리 기술이 발전함에 따라 적대적 공격의 위험성이 증가하고, 이로 인해 객체 인식의 성능이 현저히 떨어질 수 있는 문제가 발생하고 있다. 본 연구에서는 앞서 언급한 문제를 해결하기 위해 text-to-image 모델을 활용하여 기존에 존재하지 않는 새로운 이미지를 생성하고, 생성된 이미지에 대한 객체 인식을 사례 별로 연구한다. 총 8가지의 동물 카테고리로 분류한 후 객체 인식 성능을 확인한 결과 86.46%의 정확도로 바운딩 박스를 생성하였고, 동물에 대한 116개의 60.41%의 정확도를 보여주었다.",다국어 초록 정보 없음
자율주행 차량의 자동차 번호 인식 시스템 설계,2022,"['ALPR', 'autonomous vehicle', 'computer vision', 'Darknet YOLO', 'Capstone design']",국문 초록 정보 없음,"The ALPR(automatic license plate recognition) technology is used in many fields, and the high recognition rate and the fast processing speed are important factors. The accuracy and speed of object detection and recognition are improving by recent research on the deep learning area."
신발 갑피 표면의 결함 탐지를 위한 검출 알고리즘 설계,2022,"['Deep Learning', 'Detection', 'Defect Detection', 'YOLO', 'Smart Factory']",국문 초록 정보 없음,다국어 초록 정보 없음
초광각 카메라 기반 왜곡된 객체검출을 위한 심층신경망의 성능 비교 연구,2022,"['Blind Spot Detection(사각지대 감지)', 'Fisheye Lens(어안렌즈)', 'Camera Calibration(카메라 캘리브레이션)', 'YOLO-v3(욜로)']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝 기반 자동차 모델 및 번호판 인식 시스템 구현,2022,"['딥러닝(Deep Learning)', '객체검출(Object Detection)', '광학 문자 인식(OCR)', '욜로(YOLO)']",국문 초록 정보 없음,다국어 초록 정보 없음
Qualitative Analysis of Single Object and Multi Object Tracking Models,2022,"['Single object tracking', 'Multi-object tracking', 'SiamMask', 'CenterNet', 'SORT', 'YOLO', 'DeepSort', 'TensorFlow', 'OpenCV', 'PyTorch', 'DarkNet', 'Person tracking', 'and Vehicle Tracking']",국문 초록 정보 없음,"Tracking the object(s) of interest in the real world is one of the most salient research areas that has gained widespread attention due to its applications. Although different approaches based on traditional machine learning and modern deep learning have been proposed to tackle the single and multi-object tracking problems, these tasks are still challenging to perform. In our work, we conduct a comparative analysis of eleven object trackers to determine the most robust single object tracker (SOT) and multi-object tracker (MOT). The main contributions of our work are (1) employing nine pre-trained tracking algorithms to carry out the analysis for SOT that include: SiamMask, GOTURN, BOOSTING, MIL, KCF, TLD, MedianFlow, MOSSE, CSRT; (2) investigating MOT by integrating object detection models with object trackers using YOLOv4 combined with DeepSort, and CenterNet coupled with SORT; (3) creating our own testing videos dataset to perform experiments; (4) performing the qualitative analysis based on the visual representation of results by considering nine significant factors that are appearance and illumination variations, speed, accuracy, scale, partial and full-occlusion, report failure, and fast motion. Experimental results demonstrate that SiamMask tracker overcomes most of the environmental challenges for SOT while YOLOv+DeepSort tracker obtains good performance for MOT. However, these trackers are not robust enough to handle full occlusion in real-world scenarios and there is always a trade-off between tracking accuracy and speed."
"AI를 이용한 모자이크 처리의 자동화, ‘B.A.M.O.S’",2022,"['인공지능(Artificial intelligence)', '객체 탐지(Object Detection)', '모자이크(Mosaic)', 'YOLO(You only look once', '실시간 객체 탐지 알고리즘)']",국문 초록 정보 없음,다국어 초록 정보 없음
WAAM 공정에서의 YOLOv7 기반 이상 탐지 알고리즘 개발 및 성능 비교,2022,"['Wire arc additive manufacturing', 'Anomaly detection', 'Quality monitoring', 'YOLO']",국문 초록 정보 없음,다국어 초록 정보 없음
MZ세대의 특성과 언어 사용 연구,2022,"['MZ generation', 'digital native', 'flex', 'work-life balance', 'yolo', 'fire', 'echoist', 'meme', 'multi persona', 'MZ세대', '디지털 네이티브', '플렉스', '워라밸', '욜로', '파이어', '에코이스트', '밈', '멀티 페르소나']",국문 초록 정보 없음,.
SHOMY: Detection of Small Hazardous Objects using the You Only Look Once Algorithm,2022,"['Computer vision', 'detection of hazardous items', 'small-object detection', 'YOLO', 'air transport', 'security industries']",국문 초록 정보 없음,"Research on the advanced detection of harmful objects in airport cargo for passenger safety against terrorism has increased recently. However, because associated studies are primarily focused on the detection of relatively large objects, research on the detection of small objects is lacking, and the detection performance for small objects has remained considerably low. Here, we verified the limitations of existing research on object detection and developed a new model called the Small Hazardous Object detection enhanced and reconstructed Model based on the You Only Look Once version 5 (YOLOv5) algorithm to overcome these limitations. We also examined the performance of the proposed model through different experiments based on YOLOv5, a recently launched object detection model. The detection performance of our model was found to be enhanced by 0.3 in terms of the mean average precision (mAP) index and 1.1 in terms of mAP (.5:.95) with respect to the YOLOv5 model. The proposed model is especially useful for the detection of small objects of different types in overlapping environments where objects of different sizes are densely packed. The contributions of the study are reconstructed layers for the Small Hazardous Object detection enhanced and reconstructed Model based on YOLOv5 and the non-requirement of data preprocessing for immediate industrial application without any performance degradation."
A Study on Image Labeling Technique for Deep-Learning-Based Multinational Tanks Detection Model,2022,"['Convolutional Neural Network (CNN)', 'Computer Vision', 'Deep Learning', 'YOLO Network']",국문 초록 정보 없음,"Recently, the improvement of computational processing ability due to the rapid development of computing technology has greatly advanced the field of artificial intelligence, and research to apply it in various domains is active. In particular, in the national defense field, attention is paid to intelligent recognition among machine learning techniques, and efforts are being made to develop object identification and monitoring systems using artificial intelligence. To this end, various image processing technologies and object identification algorithms are applied to create a model that can identify friendly and enemy weapon systems and personnel in real-time. In this paper, we conducted image processing and object identification focused on tanks among various weapon systems. We initially conducted processing the tanks' image using a convolutional neural network, a deep learning technique. The feature map was examined and the important characteristics of the tanks crucial for learning were derived. Then, using YOLOv5 Network, a CNN-based object detection network, a model trained by labeling the entire tank and a model trained by labeling only the turret of the tank were created and the results were compared. The model and labeling technique we proposed in this paper can more accurately identify the type of tank and contribute to the intelligent recognition system to be developed in the future."
Computer Vision-based System Design for Classifying Workplace Dangerous Situation,2022,"['Dangerous situation', 'Distance estimation', 'Industrial safety', 'Object Detection', 'YOLO']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝 기반의 가금류 객체 탐지 알고리즘,2022,"['스마트팜', '딥러닝', '객체 검출', '영상 분석', '욜로', 'Smart Farm', 'Deep Learning', 'Object Detection', 'Image Analysis', 'YOLO']","가금의 평균 체중을 구하기 위해서는 닭이 저울 위로 올라가면 측정된 무게 값 데이터를 쌓아 원시 데이터로 닭의 성장 그래프를 그려 이를 예측한다. 하지만 저울에 닭이 여러 마리가 올라가 무게에 편차가 발생하여 평균 체중 예측에 혼란을 준다. 저울의 고도화와 성능검증, 가금의 평균 체중 예측값을 더 정확하게 교정하기 위해 가금의 개체 수 측정하는 것을 목적으로 객체 인식 모델을 비교하는 실험을 진행한다. 연구 결과 Modified YOLOv5가 98.8%, YOLOv5가 98.5%, YOLOv4가 96%, Mask R-CNN가 90%의 정확도를 보였다. 속도는 Modified YOLOv5가 33분 32초, YOLOv5가 25분 40초, YOLOv4가 66분 67초, Mask-RCNN가 172분 8초가 걸렸다. YOLOv5가 가장 빠른 검출 속력을 보였지만 Modified YOLOv5가 가장 높은 정확도를 보여 닭 개체에 가장 정확한 객체 검출 모델임을 알 수 있었다. 향후 객체 인식 모델을 보완하여 좀 더 정밀한 가금의 개체 수를 측정하고 결과 오차에 대해서 개선할 계획이다.","In order to obtain the average weight of a poultry, when the chicken goes up on the scale, it accumulates the measured weight value data and draws a growth graph of the chicken with raw data to predict it. However, several chickens rise on the scale, causing variations in weight, which confuses average weight prediction. Experiments are conducted to compare object recognition models with the aim of measuring the number of individuals to accurately correct the scale's advancement and performance verification, and the average weight prediction. As a result of the study, Modified YOLOv5 98.8%, YOLOv5 98.5%, YOLOv4 96%, and Mask R-CNN showed 90%. The speed took 33m 32s Modified YOLOv5, 25m 40s YOLOv5, 66m 67s YOLOv4, and 172m 8s for Mask-RCNN. Although YOLOv5 showed the fastest detection speed, Modified YOLOv5 showed the highest accuracy, indicating that it was the most accurate object detection model for chicken objects. In the future, we plan to supplement the object recognition model to measure the population of more precise poultry and improve it against the result error."
사과 과수화상병 예찰을 위한 사과꽃 생물계절 단계 분류 연구,2022,"['prevention of fire blight disease', 'prediction of flowering time', 'floral differentiation', 'deep learning', 'YOLO']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝 기반의 카메라 센서 구현에 관한 연구,2022,"['ADAS(첨단 운전자 보조 시스템', 'Advanced Driver Assistance System)', 'AEB(긴급 제동 장치', 'Autonomous Emergency Braking)', 'Deep Learning(딥러닝)', 'YOLO(You only look once)', 'Camera Calibration(카메라 캘리브레이션)', 'Prescan(ADAS 시뮬레이션 프로그램)']",국문 초록 정보 없음,다국어 초록 정보 없음
임베디드 보드에서 영상 처리 및 딥러닝 기법을 혼용한 돼지 탐지 정확도 개선,2022,"['Real-Time Video Monitoring', 'Video Object Detection', 'Pig Detection', 'Image Processing', 'Deep Learning', 'YOLO']",국문 초록 정보 없음,다국어 초록 정보 없음
카메라와 라이다의 센서융합을 이용한 객체 추적 시스템 개발,2022,"['센서융합', '객체 추적', '객체 인식', '칼만 필터', '포인트 클라우드', 'Sensor fusion', 'Object tracking', 'Object recognition', 'YOLO', 'Point cloud']","본 논문에서는 도로를 주행하는 자동차를 추적하기 위한 실시간 객체 추적 시스템 개발을소개한다. 본 시스템은 객체의 기하학적, 위치 정보를 얻을 수 있는 LiDAR 센서와 물체의종류를 인식할 수 있는 카메라 센서 정보를 융합하여 높은 수준의 물체 위치 정보를 얻는다.LiDAR 포인트 클라우드 클러스터링 연산은 ROS(Robot Operating System) 기반의Autoware를 이용해 실시간으로 수행됐으며, RGB-D 카메라는 YOLOv5를 이용해 영상에서네 가지 객체(자동차, 트럭, 야드트랙터, 사람)를 학습하고 인식하는데 활용됐다. 본 논문에서는 이러한 센서 융합을 위한 카메라 캘리브레이션이 새롭게 제안되는데, 이는 두 가지의센서 데이터를 결합하는 데 필요하다. 객체의 위치는 이전 프레임의 클러스터 중심점과 현재 프레임의 클러스터 중심점을 칼만 필터에 의해 예측되며, 추적된 데이터 기록을 통해 이전 정보와 비교하여 객체가 동일한지 판단한다. 본 시스템은 대학 체육관 앞에서 자동차를추적하는 실험을 통해 검증했다",다국어 초록 정보 없음
딥러닝을 이용한 도로의 포트홀 검출,2022,"['Deep learning(딥러닝)', 'Pothole(포트홀)', 'Object Detection(객체 검출)', 'Convolutional Neural Network(합성곱 신경망)', 'YOLO(You Only Look at Once', '욜로)', 'Advanced Driver assistance system(첨단 운전자 보조 시스템)']",국문 초록 정보 없음,다국어 초록 정보 없음
각도 마진 손실 함수를 적용한 객체 분류,2022,[],"객체 분류는 입력으로 주어진 이미지에 포함된 객체의 종류를 판단하는 기술이다. 대표적인 딥러닝 기반의 객체 분류 방법으로서 Faster R-CNN[2], YOLO[3] 등의 모델이 개발되었으나, 여전히 성능 향상의 여지가 있다. 본 연구에서는 각도 마진 손실 함수를 기존의 몇 가지 객채 분류 모델에 적용하여 성능 향상을 유도한다. 각도 마진 손실 함수는 얼굴 인식 모델인 SphereFace[4]에서 제안한 방법으로, 얼굴 인식과 같이 단일 도메인의 데이터셋을 분류하는 문제를 풀기 위해 제안되었다. 이는 기존 소프트맥스 함수에서 클래스 결정 경계선에 마진을 주는 방식으로 클래스 간의 구분 능력을 향상시킨다. 본 논문은 각도 마진 손실함수를 CIFAR10, CIFAR100 데이터셋의 분류 문제에 적용하였으며 ResNet, EfficientNet, MobileNet 등의 백본 네트워크로 실험하여 평균적으로 mAP 성능이 향상되는 것을 확인하였다.",다국어 초록 정보 없음
전기차 충전소 불법주차 탐지 시스템 개발,2022,"['영상 인식(Image Recognition)', '불법주차 탐지(Illegal Parking Detection)', '전기차 충전소(Electric Vehicle Charging Station)', 'YOLO(You Only Look Once)']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝 기반의 객체 검출 및 거리 추정을 위한 카메라 센서 구현에 관한 연구,2022,"['ADAS(Advanced Driver Assistance System', '첨단 운전자 보조 시스템)', 'AEB(Autonomous Emergency Braking', '긴급 제동 장치)', 'Deep learning(딥러닝)', 'YOLO(You Only Look Once', '딥러닝 객체 검출 알고리즘)', 'Camera calibration(카메라 캘리브레이션)', 'Prescan(ADAS 시뮬레이션 프로그램)']",국문 초록 정보 없음,다국어 초록 정보 없음
심층신경망을 이용한 스마트 양식장용 어류 크기 자동 측정 시스템,2022,"['Deep neural network', 'YOLOv3', 'Object detection', 'Fish size', 'Smart fish farm', 'LabVIEW']",국문 초록 정보 없음,"To measure the size and weight of the fish, we developed an automatic fish size measurement system using a deep neural network, where the YOLO (You Only Look Once)v3 model was used. To detect fish, an IP camera with infrared function was installed over the fish pool to acquire image data and used as input data for the deep neural network. Using the bounding box information generated as a result of detecting the fish and the structure for which the actual length is known, the size of the fish can be obtained. A GUI (Graphical User Interface) program was implemented using LabVIEW and RTSP (Real-Time Streaming protocol). The automatic fish size measurement system shows the results and stores them in a database for future work."
딥러닝 기반 조난자 수색 및 추적 드론 시스템,2022,[],"본 논문은 지정된 경로를 비행하며 조난자 수색 및 추적하는 무인 드론 시스템을 제안한다. 본 논문에서는 딥러닝 기반 객체 인식 알고리즘 YOLO(You Only Look Once)를 사용하여 실시간 영상으로부터 조난자를 검출하고, Depth 카메라를 사용하여 조난자와의 거리를 측정해 조난자를 실시간으로 추적하는 시스템을 ROS(Robot Operating System)를 통해 개발한다. 기존의 조난자 수색 시스템은 드론 전문가의 수동 제어로 이루어진다. 이러한 드론 전문가를 양성하는 것은 상당한 양의 비용과 시간이 필요하다는 단점이 있다. 본 논문에서 제안하는 방식은 무인으로 조난자를 수색함으로써 비용 절감과 시간 절약의 장점이 있다.",다국어 초록 정보 없음
KCF-YOLOv3 기반 UAV 추적 시스템 구현 및 성능 평가,2022,[],"본 논문은 UAV (Unmanned Aerial Vehicle) 방어시스템 중 UAV 추적 시스템을 구현하고 성능을 평가하였다. 해당 연구는 이를 위해 KCF(Kernelized Correlation Filter) 추적기와 YOLO(You Only Look Once)v3-416을 접목하여 KCF 추적기가 추적에 실패해도 추적을 계속할 수 있는 알고리즘을 제안한다. 조건부-KCF 추적기는 KCF 추적기가 추적에 실패한 경우 YOLOv3-416을 통해 eUAV(evader UAV) 위치를 탐지하고 그 값을 사용해 KCF 추적기가 계속해서 추적을 진행하는 알고리즘이다. 주기적-KCF 추적기는 주기적으로 YOLOv3-416을 실행하여, 조건부-KCF 추적기보다 실시간으로 움직이는 eUAV에 맞는 경계상자를 구성하는 알고리즘이다. 제안한 알고리즘 추적 성능 평가를 위해 다양한 환경에서 추적 정밀도와 성공률을 비교하였고, 복잡도 또한 비교하였다. 그 결과 모든 데이터 세트에서 주기적-KCF 추적기가 조건부-KCF 추적기 대비 다소 복잡하나 우수한 추적 성능을 내는 것을 확인하였다. 해당 연구를 기반으로 향후 다양한 추적기와 YOLOv3-416을 접목한 알고리즘을 개발 및 추적 성능과 복잡도를 평가하여 가장 우수한 UAV 추적 알고리즘을 제안하는 것을 목표로 한다.",다국어 초록 정보 없음
다중스펙트럼을 이용한 횡단보도 보행자 검지에 관한 연구,2022,"['딥러닝', '객체 검지', 'YOLOv5', '보행자 감지', '멀티 스펙트럼', 'Deep Learning', 'Object Detection', 'YOLOv5', 'Pedestrian Detection', 'Multi-spectrum']",주간 및 야간의 보행자 감지를 위해서는 다중 스펙트럼 활용이 필수적이다. 본 논문에서는 교통사고의 위험성이 높은 교차로에서 횡단보도 근처의 보행자를 24시간 검출하기 위해 컬러 카메라 및 열화상 적외선 카메라를 사용하였다. 보행자 탐지를 위해서 YOLO v5 객체 검출기를 사용하였으며 컬러 이미지와 열화상 이미지를 동시에 사용하여 감지 성능을 향상 시켰다. 제안된 시스템은 실제 횡단보도 현장에서 확보한 주·야간 다중 스펙트럼(색상 및 열화상) 보행자 데이터 셋에서 Iou 0.5 기준 0.94 mAP의 높은 성능을 보였다.,다국어 초록 정보 없음
컨테이너 적재 상태 모니터링을 위한 딥러닝 모델 연구,2022,[],"부두 내 컨테이너를 적재하는 과정에서 정렬 상태가 부정확한 경우 강풍으로 인한 안전사고가 발생할 가능성이 있다. 본 논문에서는 컨테이너 안전사고를 예방하기 위한 딥러닝 기반의 컨테이너 정렬상태 분류 알고리즘을 제안한다. 제안하는 알고리즘은 정렬을 분류하는 기준을 제시하고 YOLO 기반의 모델을 구현했다. 추론 속도, 검출 정확도, 분류 정확도를 기준으로 각 모델의 성능을 평가했으며 성능 결과는 YOLOv4모델이 YOLOv3모델에 비해서 추론 속도는 느리지만, 검출 정확도와 분류 정확도는 높음을 보인다.",다국어 초록 정보 없음
스마트팜 이미지 분석을 위한 딥러닝 기반 객체 탐지 기술 연구,2022,[],최근 농가를 관리하는 인력에 비해 농가 인구 감소와 고령화로 인하여 농작물의 생산성이 감소하고 있다. 이러한 종합적인 문제들을 해결하기 위하여 스마트 농업 기술 도입이 필요하다. 농작물의 생육 객체를 탐지하는 기술을 통해 효과적인 농작물 관리 및 고품질 제품을 수확할 수 있다. 따라서 본 논문에서는 처리 속도가 빠르고 정확도가 높은 YOLO (You Only Look Once) v5의 4가지 모델을 이용하여 스마트팜 농작물 이미지의 객체 탐지 실험 및 모델 분석을 진행하였다. 실험 결과 YOLOv5m 모델이 스마트팜 농작물의 생육 객체 탐지에 우수한 성능을 가지는 것을 확인하였다.,다국어 초록 정보 없음
밀리미터파 통신에서 비전 정보를 활용한 LSTM 기반 발사각 예측,2022,[],"본 논문에서는 비전 정보를 활용한 장단기 메모리(long term short memory, LSTM) 기반 발사각 예측 알고리즘을 제안한다. 밀리미터파 통신에서 안테나의 수가 증가할수록 beam training 오버헤드가 증가하고 이는 링크 지연을 발생시킨다. 제안하는 알고리즘은 카메라에서 얻은 비전 정보에 YOLO(you only look once)를 이용한 물체 추적 알고리즘을 적용하여 사용자를 추적하고, LSTM으로 다음 타임 슬롯에서 사용자에 대한 발사각을 예측한다. 기지국에서 예측한 발사각으로 빔을 미리 형성하여 beam training 오버헤드와 링크 지연을 줄일 수 있다. 실험을 통해 실측 데이터를 수집하고, LSTM 네트워크와 예측된 발사각의 오차를 평가한다.",다국어 초록 정보 없음
센서 기반 자율주행 자동차 구현 연구,2022,[],"본 논문에서는 라이다, 카메라, 초음파 센서를 이용한 자율주행 자동차를 구현 및 성능을 검증하였다. Robot Operating System (ROS)를 활용하여 1) 카메라 및 라이다 기반 주행 방향 제어 알고리즘 2) 초음파 센서 기반 돌발상황 제어 3) YOLO 기반 교통 표지판 인지 알고리즘을 구현하였다. 구현된 자율주행 시스템을 다양한 주행환경에서 테스트하였고 관찰된 문제점을 극복하기 위한 몇 가지 방안을 제시하였다.",다국어 초록 정보 없음
딥러닝 기반 손톱 하부 모세혈관 인식,2022,[],"손톱 하부 모세혈관(Nailfold Capillary)의 형태와 분포 특징으로부터 다양한 질병을 밝혀내려는 시도가 꾸준히 있어 왔다. 손톱 하부 모세혈관은 그의 대표적인 형태 특징을 따라 몇 가지로 분류할 수 있고, 이 분포와 질병과의 상관관계가 밝혀진 종래 연구들도 다수 존재한다. 현재는 진단하는 과정을 의료 전문가가 직접 촬영된 모세혈관 사진을 보고 주관적인 평가를 하게 되는데, 이러한 분석 방법은 많은 시간과 휴먼 에러가 발생한다는 문제점이 있다. 이를 자동화하기 위하여 본 논문은 손톱 하부 모세혈관의 모세혈관들을 YOLO 객체 인식 모델을 활용하여 모세혈관을 탐지하고 모세혈관의 종류에 따라 분류하는 방법을 제안하고, 그 유효성을 검증하였다.",다국어 초록 정보 없음
객체 인식과 객체 추적을 활용한 고속도로 주행 영상에서의 돌발 상황 인식 방법,2022,"['machine learning', 'object detection', 'object tracking', 'RNN', 'LSTM']",국문 초록 정보 없음,"The aim of this study is to recognize unexpected situations in road driving images using object detection and object tracking. Object detection is performed for each frame of the road driving image captured through the vehicles black box, and the vehicles movement path is learned using object tracking. Using the learned movement path, predict next vehicles position, and the unexpected situation is detecting by using the difference between predicted position and the actual position. YOLO (You Only Look Once) is used for object recognition, Deep SORT (Deep Simple Online and Realtime Tracking) for object tracking, and RNN (Recurrent Neural Network) and LSTM (Long Short-Term Memory) for path learning. We used 3 types of training and test data set obtained from the entire videos, driving videos, or from the highway driving videos."
Steel Surface Defect Detection using the RetinaNet Detection Model,2022,"['Defect Detection', 'Deep Learning', 'Steel Defect Detection', 'RetinaNet model', 'One-Stage Detector']",국문 초록 정보 없음,"Some surface defects make the weak quality of steel materials. To limit these defects, we advocate a onestage detector model RetinaNet among diverse detection algorithms in deep learning. There are several backbones in the RetinaNet model. We acknowledged two backbones, which are ResNet50 and VGG19. To validate our model, we compared and analyzed several traditional models, one-stage models like YOLO and SSD models and two-stage models like Faster-RCNN, EDDN, and Xception models, with simulations based on steel individual classes. We also performed the correlation of the time factor between one-stage and twostage models. Comparative analysis shows that the proposed model achieves excellent results on the dataset of the Northeastern University surface defect detection dataset. We would like to work on different backbones to check the efficiency of the model for real world, increasing the datasets through augmentation and focus on improving our limitation."
스마트 자율배송을 위한 클래스 분류와 객체별 학습데이터 유형,2022,"['딥러닝', '주행 환경 인식', 'AI 학습용 데이터', '객체인식', '자율주행', 'Deep Learning', 'Perception', 'AI training data', 'Object Detection', 'Autonomous Driving']","자율배송 운행 데이터는 코로나 시대의 라스트마일 배송에 대한 패러다임 변화를 주도하는 핵심이다. 국내자율배송로봇과 해외 기술선도국가 간의 기술격차 해소를 위해서는 인공지능 학습에 사용 가능한 대규모 데이터 수집과 검증이 최우선으로 요구된다. 따라서 해외 기술선도국가에서는 인공지능 학습데이터를 누구든사용가능한 공공데이터 형태로 오픈하여 검증과 기술발전에 기여하고 있다. 본 논문은 자율배송로봇 학습을 목적으로 326개의 객체를 수집하고 Mask r-cnn, Yolo v3 등의 인공지능 모델을 학습하고 검증하였다.추가적으로 두 모델을 기반으로 비교하고 향후 자율배송로봇 연구에 요구되는 요소를 고찰하였다.",다국어 초록 정보 없음
연속적인 이미지를 이용한 원거리 객체 검출 연구,2022,[],"본 논문에서는 CCTV 설치 비용 혹은 위치의 제약으로 인해 한 카메라에서 넓은 구역을 감시해야 할 때 원거리에 존재하는 객체를 검출하기 위해, 앵커를 사용하지 않고 객체의 중심점을 추정하는 CenterNet과 전후 프레임의 변위를 이용하는 CenterTrack을 활용하여 작은 객체 검출에 유리한 STTNet(Short Term Tracklet Network)을 제안하였다. 또한, 항만 데이터 세트에서 사람 객체 수가 부족한 문제를 해결하기 위해 데이터 증강기법을 사용하였다. 실험 결과, STTNet 모델의 성능이 39%로 기존의 객체 검출기인 YOLO V3 모델의 성능보다 16%만큼 높았으며, 작은 객체 검출에 적합한 모델이 STTNet임을 확인하였다. 또한, 항만 CCTV 테스트 데이터를 통해 150m 이상 떨어진 사람 객체도 검출하는 것을 확인하였다.",다국어 초록 정보 없음
스테레오 비전과 YOLOv5 모델을 이용한 실시간 토마토 위치 검출 시스템,2022,"['객체검출', 'YOLOv5', '스테레오 비전']","본 연구는 토마토 수확 및 모니터링 로봇을 위한 실시간 3차원 토마토 위치 검출 시스템을 제안한다. 제안한 시스템은 영상 및 이미지로부터 토마토 수확 및 모니터링 로봇의 작업 수행에 필요한 토마토 객체 탐지와 3차원 위치정보를 추출하는 역할을 한다. 이를 위하여 STREOLABS의 스테레오 비전 카메라인 ZED2 카메라를 이용하여 영상을 취득하며, 실시간 토마토 객체 검출을 위하여 케글(Kaggle)에서 제공하는 오픈 토마토 데이터셋을 이용하여 YOLO 모델 시리즈의 최신 버전인 YOLOv5 모델을 학습시키고 시스템에 적용한다. 스테레오 비전 카메라에서 촬영된 이미지에서 학습된 모델이 토마토의 2차원 위치를 나타내는 바운딩박스를 검출하고, 2차원 바운딩박스의 위치정보를 바탕으로 해당 바운딩박스의 각 픽셀의 3차원 정보를 추출하여 토마토의 위치정보를 얻는다. 시스템의 성능은 GPU를 탑재된 데스크톱 환경에서 각 모델의 평균 정밀도(Average Precision)와 이미지 처리능력의 관점에서 평가된다. IoU 50에서의 최고 AP는 YOLOv5n 및 YOLOv5s, YOLOv5m, YOLOv5l 모델이 각각 92.71%, 94.58%, 95.46%, 95.41%의 높은 정밀도를 보였다. 또한, 이미지 처리능력 관점에서 각 모델은 초당 평균 29.16, 29.23, 27.62, 24.26 프레임의 처리능력을 보여, 제안한 시스템이 높은 정밀도로 토마토 탐지하고 실시간 위치정보를 추출할 수 있는 능력과 적용 가능성을 확인하였다.",다국어 초록 정보 없음
Color Barcode Detection of Complementary Color Barcode-based Optical Camera Communications with a Deep Neural Network,2022,"['Display-to-camera communication', 'Complementary color barcode-based optical camera communications', 'Deep neural network']",국문 초록 정보 없음,"Complementary color barcode-based optical camera communications (CCB-OCC), which uses electronic displays and cameras as data transmitters and receivers, can offer a simple and short-range communications interface. In this paper, we enhance the data rate of a CCB-OCC scheme by using deep neural network (DNN)-based color barcode detection and adaptive colorvalue extraction. Unlike a conventional scheme, the proposed method extracts a color barcode region using a You Only Look Once (YOLO) real-time detection model that provides reliable barcode region extraction from various viewing angles between the display and the camera. In addition, the proposed scheme extracts accurate color values from color histograms using adaptive peak positions that express consecutive signals between packets. Experimental results verify data rate improvement in the proposed CCB-OCC scheme using DNN-based barcode detection and adaptive color-value extraction in a display-to-camera (D2C) communications link."
간선화물의 상자 하차를 위한 외팔 로봇 시스템 개발,2022,"['Object Recognition', 'Robotic Arm', 'Kinematics', 'Task And Motion Planning', 'Image Processing']",국문 초록 정보 없음,"In this paper, the developed trunk cargo unloading automation system is introduced, and the RGB-D sensor-based box loading situation recognition method and unloading plan applied to this system are suggested. First of all, it is necessary to recognize the position of the box in a truck. To do this, we first apply CNN-based YOLO, which can recognize objects in RGB images in real-time. Then, the normal vector of the center of the box is obtained using the depth image to reduce misrecognition in parts other than the box, and the inner wall of the truck in an image is removed. And a method of classifying the layers of the boxes according to the distance using the recognized depth information of the boxes is suggested. Given the coordinates of the boxes on the nearest layer, a method of generating the optimal path to take out the boxes the fastest using this information is introduced. In addition, kinematic analysis is performed to move the conveyor to the position of the box to be taken out of the truck, and kinematic analysis is also performed to control the robot arm that takes out the boxes. Finally, the effectiveness of the developed system and algorithm through a test bed is proved."
YOLOv5를 활용한 야생동물 탐지 및 분류 모델에 대한 소고,2022,"['YOLOv5', 'wild animals', 'object detection', 'learning data', 'deep learning', 'feature map']",국문 초록 정보 없음,"Although the AI classification model using the YOLOv5 model has better performance than the existing image classification models such as EfficientDet, EfficientNet, and YOLOv4, there are few model use cases. The model for classifying images of wild animals in a laboratory or staged environment differs from the actual situation in which resolution, angle, illuminance, and weather conditions vary widely, so there are limitations in existing studies. This study can contribute to reducing the number of roadkill accidents caused by wild animals appearing on the road of recent vehicles. In addition to the injury or death of wild animals, the accident causes vehicle damage and human casualties. This article confirmed the excellent performance by applying the YOLO 5 modeling technique, which plays a key role in the development of a service that detects wild animals at a superior level compared to the naked eye and prevents accidents."
딥러닝을 위한 마스크 착용 유형별 데이터셋 구축 및 검출 모델에 관한 연구,2022,"['Mask detection', 'Deep learning', 'Object classification', 'Object detection']",국문 초록 정보 없음,"Due to COVID-19, Correct method of wearing mask is important to prevent COVID-19 and the other respiratory tract infections. And the deep learning technology in the image processing has been developed. The pur- pose of this study is to create the type of mask wearing dataset for deep learning models and select the deep learning model to detect the wearing mask correctly. The Image dataset is the 2,296 images acquired using a web crawler. Deep learning classification models provided by tensorflow are used to validate the dataset. And Object detection deep learning model YOLOs are used to select the detection deep learning model to detect the wearing mask cor- rectly. In this process, this paper proposes to validate the type of mask wearing datasets and YOLOv5 is the effective model to detect the type of mask wearing. The experimental results show that reliable dataset is acquired and the YOLOv5 model effectively recognize type of mask wearing."
Transfer learning in a deep convolutional neural network for implant fixture classification: A pilot study,2022,"['Artificial Intelligence', 'Deep Learning', 'Dental Implants', 'Dental Radiography']",국문 초록 정보 없음,"Purpose: This study aimed to evaluate the performance of transfer learning in a deep convolutional neural network for classifying implant fixtures. Materials and Methods: Periapical radiographs of implant fixtures obtained using the Superline (Dentium Co. Ltd., Seoul, Korea), TS III(Osstem Implant Co. Ltd., Seoul, Korea), and Bone Level Implant(Institut Straumann AG, Basel, Switzerland) systems were selected from patients who underwent dental implant treatment. All 355 implant fixtures comprised the total dataset and were annotated with the name of the system. The total dataset was split into a training dataset and a test dataset at a ratio of 8 to 2, respectively. YOLOv3 (You Only Look Once version 3, available at https://pjreddie.com/darknet/yolo/), a deep convolutional neural network that has been pretrained with a large image dataset of objects, was used to train the model to classify fixtures in periapical images, in a process called transfer learning. This network was trained with the training dataset for 100, 200, and 300 epochs. Using the test dataset, the performance of the network was evaluated in terms of sensitivity, specificity, and accuracy. Results: When YOLOv3 was trained for 200 epochs, the sensitivity, specificity, accuracy, and confidence score were the highest for all systems, with overall results of 94.4%, 97.9%, 96.7%, and 0.75, respectively. The network showed the best performance in classifying Bone Level Implant fixtures, with 100.0% sensitivity, specificity, and accuracy. Conclusion: Through transfer learning, high performance could be achieved with YOLOv3, even using a small amount of data."
Transfer learning in a deep convolutional neural network for implant fixture classification: A pilot study,2022,"['Artificial Intelligence', 'Deep Learning', 'Dental Implants', 'Dental Radiography']",국문 초록 정보 없음,"Purpose: This study aimed to evaluate the performance of transfer learning in a deep convolutional neural network for classifying implant fixtures.Materials and Methods: Periapical radiographs of implant fixtures obtained using the Superline (Dentium Co. Ltd., Seoul, Korea), TS III (Osstem Implant Co. Ltd., Seoul, Korea), and Bone Level Implant (Institut Straumann AG, Basel, Switzerland) systems were selected from patients who underwent dental implant treatment. All 355 implant fixtures comprised the total dataset and were annotated with the name of the system. The total dataset was split into a training dataset and a test dataset at a ratio of 8 to 2, respectively. YOLOv3 (You Only Look Once version 3, available at https:// pjreddie.com/darknet/yolo/), a deep convolutional neural network that has been pretrained with a large image dataset of objects, was used to train the model to classify fixtures in periapical images, in a process called transfer learning. This network was trained with the training dataset for 100, 200, and 300 epochs. Using the test dataset, the performance of the network was evaluated in terms of sensitivity, specificity, and accuracy.Results: When YOLOv3 was trained for 200 epochs, the sensitivity, specificity, accuracy, and confidence score were the highest for all systems, with overall results of 94.4%, 97.9%, 96.7%, and 0.75, respectively. The network showed the best performance in classifying Bone Level Implant fixtures, with 100.0% sensitivity, specificity, and accuracy. Conclusion: Through transfer learning, high performance could be achieved with YOLOv3, even using a small amount of data."
소성가공 분야에서 인공지능을 이용한 절단면 이물질 검출,2022,"['drone', 'flight algorithm', 'air pollution', 'arduino']",국문 초록 정보 없음,"The aging operation method of the root industry (plastic processing industry) causes problems such as aging of professional personnel, difficulty in transferring know-how at production sites, decreasing productivity of unskilled workers, inaccuracy and quality of visual inspection-based systems. In line with the fourth industrial revolution, it is a trend to solve the above root industry problems by establishing a smart factory applying artificial intelligence technology. In this paper, cutting surfaces foreign material detection techniques are implemented through artificial intelligence object detection to reduce the occurrence of defects in forging processes in the plastic processing field. In addition, acurancy and mean Average Precision (mAP) were compared with the detection results of Fast-RCNN, SSD, and Yolo to prove the possibility of establishing a smart factory optimized for the plastic processing industry."
비전 인공지능 기반 작업시간 분포 함수 자동 생성 방법,2022,[],"[연구 배경] 그동안 시뮬레이션 모델을 정의할 때, 주로 전문가의 경험에 의존해왔다. 이에 따라 시뮬레이션 모델을 수동으로 정의하는 데에 필요 이상의 시간과 비용이 소요되었다.[연구 목적] 본 연구는 시뮬레이션 입력 모델을 비전 인공지능 기술로 자동 생성하는 방법을 제안한다.[연구 범위] 연구진은 시뮬레이션 입력 모델 중 작업 시간에 대한 분포함수와 파라미터에 초점을 맞춘다.[연구 방법] 딥러닝(deep learning)을 위한 영상 데이터를 수집하기 위해 공장 모형이 제작되었다. 그리고 영상 데이터에서 작업 시간을 추출하기 위해 객체 탐지 및 추적 알고리즘(YOLO 및 DeepSORT)이 적용되었다. 자동으로 축적된 작업 시간은 적합도 검정을 통해 적합한 분포 함수를 찾는 데에 사용된다.",다국어 초록 정보 없음
무인항공기 초분광 이미지 기반 배추 노균병 조기진단을 위한 딥러닝 모델 개발,2022,"['Downy midlew', 'Diagnosis', 'UAV', 'Hyperspectral', 'Deep learning']",국문 초록 정보 없음,"Downy mildew is one of the most common plant diseases in Korea that could easily infect plants such as cabbage, cucumber, and garlic. Particularly on Chinese cabbage, the disease is identified by yellow-tan spots on the upper leaf surface, causing infected leaves to drop off and eventually plant death. An early diagnosis of the disease with minimum physical damage to the plant could highly reduce crop losses. Hyperspectral imaging as one of the non-destructive evaluation methods has recently become more popular due to its capability to capture a wide spectral range. The combination of a UAV and hyperspectral imaging system offers abundant data resources that could provide adequate information for early diagnosis of downy mildew infection on the Chinese cabbage farm fields. Based on hyperspectral image data, the diagnosis system employs a deep learning algorithm that computes complex relations and finds a pattern in the data to detect the disease and its location. Similar algorithms such as R-CNN, Faster R-CNN, and YOLO have been implemented in many fields of study and are able to deliver results with good accuracy and robustness."
MZ세대와 성경적 노동관을 위한 교양교육,2022,"['MZ세대', '직업', '노동관', '기독교세계관', 'MZ Generation', 'Job', 'Labor', 'Christian World View']",국문 초록 정보 없음,"A tick-tock video posted by Zaidleppelin, the 20th American engineer, in July 2022, is shaking the world. It is Quiet Quitting. It is a new keyword that connects trends such as Hustle, which forced past loyalty, and Work-life balance, which emphasized night. In the video, he defined quiet resignation as stopping the idea of doing more than what has been given. He said, Work is not your whole life. Your value is not defined only as the result of what you do. This video has quickly spread and become a big topic, and since then, MZ generations in the United States have expressed sympathy by referring to quiet resignation as a hashtag, but this is not a sudden occurrence. The phenomena that have already appeared in the older generation have appeared as quiet resignation in the same flow as Work-life balance, Yolo, and Hustle.  However, this secular view of labor and the flow of the times are concerned that they will misunderstand Gods teachings taught and guided in the Bible. Like the evangelists words, the values and trends of history always change, as ‘there is nothing new under the sun’. Even if this secular view of labor now feels like truth, it changes again someday. Therefore, this paper briefly introduces the truth of the view of occupation and the view of labor in the Bible, and aims to discuss the right Christian culture education for them by combining the values and the view of labor of the MZ generation."
깊이 이미지를 이용한 타이어 표면 결함 검출 방법에 관한 연구,2022,"['Tire Defect Detection', 'Depth Image', 'Deep Learning', 'Computer Vision', 'Image Processing', '타이어 결함 검출', '깊이 이미지', '딥러닝', '컴퓨터비전', '영상처리']",국문 초록 정보 없음,"Recently, research on smart factories triggered by the 4th industrial revolution is being actively conducted. Accordingly, themanufacturing industry is conducting various studies to improve productivity and quality based on deep learning technology with robustperformance. This paper is a study on the method of detecting tire surface defects in the visual inspection stage of the tire manufacturingprocess, and introduces a tire surface defect detection method using a depth image acquired through a 3D camera. The tire surfacedepth image dealt with in this study has the problem of low contrast caused by the shallow depth of the tire surface and the differencein the reference depth value due to the data acquisition environment. And due to the nature of the manufacturing industry, algorithmswith performance that can be processed in real time along with detection performance is required. Therefore, in this paper, we studieda method to normalize the depth image through relatively simple methods so that the tire surface defect detection algorithm does notconsist of a complex algorithm pipeline. and conducted a comparative experiment between the general normalization method and thenormalization method suggested in this paper using YOLO V3, which could satisfy both detection performance and speed. As a resultof the experiment, it is confirmed that the normalization method proposed in this paper improved performance by about 7% based onmAP 0.5, and the method proposed in this paper is effective."
Preliminary study of AR navigation-guided core-needle breast biopsy,2022,"['augmented reality', 'navigation', 'needle', 'tracking', 'deep learning', 'hololens']",국문 초록 정보 없음,"Accurate tumor localization has remained to be one of the biggest challenges in core-needle biopsy due to the malleability and texture-heterogeneity of tissues surrounding a tumor. To overcome these limitations, we explored the effectiveness of augmented reality (AR)-guidance to navigate the core-needle insertion in breast biopsy thanks to the enhanced technology of AR. Our proposed framework consists of two independent functions: tumor localization and needle pose tracking in real-time. First, tumor localization was achieved by employing the two-front environmental sensors of HoloLens 2 (HL2) for tracking the passive-reflective markers. Given the geometrical information of the reference markers, the stereo-correspondences and the marker pose can be calculated efficiently for overlaying the corresponding virtual models in HL2. Second, an external RGB camera was used to track the pose of a needle. A You-Only-Look-Once (YOLO) model with a customized training set of 200 images was employed to detect the collinear pinkt-ape points attached to the needle. The interpoint-distance between these points will be utilized to estimate the pose of a needle that will be sent to HL2 using TCP/IP communication. Finally, real-time navigation of needle insertion can be rendered in HL2 using a more accurate transformation to assist the breast biopsy. Overall, the preliminary results demonstrate that the whole process can be executed in a reasonable running time of less than two seconds."
Real-time Steel Surface Defects Detection Appliocation based on Yolov4 Model and Transfer Learning,2022,"['Surface Defects', 'Object Detection', 'YOLOv4', 'real-time detection', '표면 결함', '물체 검출', '욜로', '실시간 검출']",국문 초록 정보 없음,"Steel is one of the most fundamental components to mechanical industry. However, the quality of products are greatly impacted by the surface defects in the steel. Thus, researchers pay attention to the need for surface defects detector and the deep learning methods are the current trend of object detector. There are still limitations and rooms for improvements, for example, related works focus on developing the models but don’t take into account real-time application with practical implication on industrial settings. In this paper, a real-time application of steel surface defects detection based on YOLOv4 is proposed. Firstly, as the aim of this work to deploying model on real-time application, we studied related works on this field, particularly focusing on one-stage detector and YOLO algorithm, which is one of the most famous algorithm for real-time object detectors. Secondly, using pre-trained Yolov4-Darknet platform models and transfer learning, we trained and test on the hot rolled steel defects open-source dataset NEU-DET. In our study, we applied our application with 4 types of typical defects of a steel surface, namely patches, pitted surface, inclusion and scratches.Thirdly, we evaluated YOLOv4 trained model real-time performance to deploying our system with accuracy of 87.1 % mAP@0.5 and over 60 fps with GPU processing."
뉴노멀 시대 MZ세대의 라이프스타일 변화 유형에 관한 연구,2022,"['뉴노멀', 'MZ세대', '라이프스타일', 'Q 방법론', 'New Normal', 'Generation MZ', 'Lifestyle', 'Q Methodology']","본 논문은 Q 방법론과 MBTI 유형 이론을 적용하여 팬데믹 이후 뉴노멀 시대의 MZ세대 라이프스타일 변화 유형을 탐색한 해석적 연구이다. 전 세계적으로 MZ세대가 주력 소비자층이자 사회계층으로 위상이 높아지고 새로운 트렌드를 주도하면서 관련 연구도 증가하는 추세이다. ‘팬데믹이 나의 라이프스타일을 어떻게 변화시켰는가’의 연구문제에 대해 Q 모집단 진술문으로부터 최종 34개의 Q 표본을 구성하였고, 16개의 MBTI 유형별로 선정된 총 31명의 P 표본 응답자들이 Q 분류에 참여하였다. 가설생성적 Q 연구를 통한 데이터 분석 결과, 4개의 유형을 발견하였다. 제1유형은 집콕템(실내생활을 즐기기 위한 아이템) 가치소비 형, 제2유형은 헬시라이프 챌린저(healthy-life challenger) 형, 제3유형은 횰로(H-YOLO) 형, 제4유형은 카우치 포테이토(couch potato) 형으로 명명하였다. 본 연구는 MZ세대의 자아개념을 기초한 라이프스타일 변화 유형의 개념 및 특성을 이론화함으로써 후속 연구나 실용적 활용의 선험적 기초자료가 될 것으로 기대한다.","This interpretative Q study aims at exploring typologies of the MZ’s lifestyle change according to respondents’ MBTI types under the pandemic environment in the new normal era. As the millenials and generation Z become a major social class or consumer group in the market worldwide, related academic studies also tend to increase. Different from previous generations, their consumption behavior and lifestyle are creating new trends. 31 P-sample respondents for each of the 16 MBTI types participated in the Q-sorting of 34 Q samples collected from Q-population statements on ‘How the pandemic has changed my lifestyle?’. As a result, four types were discovered as a result of data analysis based on abductory Q research. The first type was named the value consumption of ‘Zipcoktem’ (A term referring to items necessary to enjoy indoor life) type, the second type is a healthy-life challenger, the third type was named H-YOLO tribe, and the last is couch potato type. The new theoretical definition of this study can contribute as the basis for further researches or industrial application."
Lightweight object detection network model suitable for indoor mobile robots,2022,"['Indoor mobile robot', 'Real-time performance', 'SSD network model', 'ShuffleNet network', 'S-SSD lightweight network model']",국문 초록 정보 없음,"This work proposes a lightweight object detection network model ShuffleNetSSD (S-SSD) to solve the problem of single shot multibox detector (SSD) network model where it cannot meet the real-time performance requirement in the task of object detection and recognition of indoor mobile robot. This model is suitable for indoor mobile robot by improving the SSD network model based on ShuffleNet network. The main idea of the improvement is that SSSD replaces VGG-16 network as the basic feature extraction network of SSD network model with ShuffleNet network. The proposed model is based on the design of deep separable convolution, point-by-point grouping convolution, and channel rearrangement. It retains the design idea of multiscale feature graph detection of SSD network model. This model ensures a slight decline in detection accuracy while greatly reduces the amount of computation generated by the network operation, thereby greatly improving the detection rate. A data set for the task of object detection and recognition of indoor mobile robot is made. The S-SSD lightweight network model is superior to the original SSD network model and tiny-YOLO lightweight network model in terms of detection accuracy and detection rate, and can simultaneously meet the requirement of detection accuracy and real-time performance in the task of indoor object detection and recognition of mobile robot. These findings are verified through the comparative experiments of object detection accuracy and detection rate and real-time object detection and recognition of mobile robot under the actual indoor scene."
