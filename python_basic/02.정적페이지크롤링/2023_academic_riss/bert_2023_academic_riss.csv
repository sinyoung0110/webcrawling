title,date,keywords,abstract,multilingual_abstract
법률 인공지능 연구 활성화를 위한 판례 데이터셋 자동 라벨링 및 BERT를 활용한 판례 유사성 분석,2023,"['법률 인공지능', '사전학습 언어 모델', '노동법 판례', '법률 데이터셋', '판례 유사도', 'Legal Technology', 'BERT', 'Labor Legal Precedents', 'Legal Datasets', 'Case Similarity']","본 연구의 목적은 법률 인공지능 연구 활성화에 필수적인 학습용 대법원 판례 데이터셋 구축을 위한 자동 라벨링 방안을 마련하고, 해당 데이터셋을 활용하여 효과적인 판례 유사도 분석 방법들을 검증하는 데에 있다. 특히, 문장의 의미적 인식을 높이기 위해 문장 간 맥락까지 학습할 수 있는 BERT를 활용하는 방법을 제안하고자 한다. 학습 데이터로는 해고무효확인소송 등 고용관계 종료와 관련된 판례 데이터(1962.2 ~ 2021.2)를 사용하였다. 학습용 판례 데이터셋 구축 방안의 성능 비교 실험을 위해 판결문의 특정 요소 간의 비교 분석과, 판결문에서 추출한 사실관계로 주제 분류 실험을 수행하였다. 특히, 판례 유사도 분석 실험은 빈도 기반의 자카드분석, 확률 기반의 Doc2Vec 및 BERT 모델을 활용하여 유사도 성능을 비교하였고, 평가 방법으로는 코사인 유사도(Cosine similarity)와 의미론적 분석을 수행하였다. 연구 결과로, 학습용 판례 데이터셋 구축 시 판결 결과 라벨링에는 당사자 및 주문 정보를 함께 활용하는 것이 효과적이고, 판례에서 추출한 사실관계 문장으로 효과적으로 주제를 분류할 수 있었음을 밝혔다. 또한 판례 유사도 분석 시 확률 기반의 Doc2Vec 보다는 BERT 로 분석한 결과가 의미론적 관점에서 보다 효과적임을 보였다. 특히, 본 연구에서는 판례 전문을 이용하여 판례 유사도 분석 방안을 연구했다는 점에서 기존 연구들과 차별성을 지닌다.","This study established an automatic labeling method for the construction of a legal precedents dataset for training, an essential component for advancing legal artificial intelligence research. Also, it validated a method for case similarity analysis using the dataset built. To recognize semantics of sentences, we employed BERT, a pre-training language model capable of learning the order of words in a sentence. For the experiment, a labor legal precedent data related to termination of employment relationships was used, such as wrongful termination lawsuits. The reserachers extracted elements of the judgment text, labeled the verdict results of the cases using BERT, and confirmed that the subject of a case could be automatically classified using the factual circumstances extracted from the judgment text. Our case similarity analysis experiment utilized 1) frequency-based Jaccard analysis, 2) probability-based Doc2Vec, and 3) the BERT-based model. The performance of each model was compared through quantitative evaluation methods, such as Cosine similarity, and qualitative evaluation methods, such as semantic analysis. This research verified that combining party and order information is an effective approach when labeling verdict results during the construction of a learning case dataset. The study also demonstrated that subject classification for the relevant case is possible using the factual circumstances extracted from the case. Additionally, in terms of case similarity analysis, the results of the BERT model proved more semantically appropriate than the probability-based Doc2Vec approach. Consequently, it was identified that the type of information necessary for dataset construction from judgment texts, proposed a method to include judgment results, factual circumstances, and case subject classification attributes in the learning case dataset, and demonstrated that sentence-based case searches, which can supplement the limitations of existing keyword-based similar case searches, are a feasible approach."
긴 문서를 위한 BERT 기반의 End-to-End 한국어 상호참조해결,2023,"['coreference resolution', 'BERT', 'deep learning', 'natural language processing', '상호참조해결', 'BERT', '딥 러닝', '자연어처리']","상호참조해결은 상호참조해결 대상이 되는 멘션(mention)을 식별하고, 동일한 개체(entity)를 의미하는 멘션들을 찾아 그룹화하는 자연어처리 태스크이다. 최근 상호참조해결에서는 BERT를 이용하여 단어의 문맥 표현을 얻은 후, 멘션 탐지와 상호참조해결을 동시에 진행하는 end-to-end 모델이 주로 연구되었으나, BERT의 입력 길이 제한으로 긴 문서에 대해서는 성능이 낮아지는 문제가 있다. 따라서, 본 논문에서는 다음의 모델을 제안하였다. 우선 긴 문서를 512 이하의 토큰으로 쪼개어 기존의 Local BERT에서 단어의 1차 문맥 표현을 얻고, 이를 다시 연결하여 원래 문서에 대한 Global Positional Embedding 값을 계산하여 더해준다. 그리고 이렇게 연결된 문맥 표현을 Global BERT layer를 통해 최종적으로 전체 문맥 표현 계산하여 상호참조해결을 수행하였다. 실험 결과, 본 논문에서 제안한 모델이 기존 모델과 유사한 성능을 보이면서, GPU 메모리 사용량은 1.4배 감소하고 속도는 2.1배 향상되었다.",다국어 초록 정보 없음
BERT 기반 금융 텍스트셋 구현을 위한 전이 학습 연구,2023,"['Natural language processing', 'Named entity recognition', 'BERT', 'Transfer learning', 'Financial dataset']","한국어 자연어 처리 분야는 구글에서 공개한 BERT 언어모델을 중심으로 활발한 연구가 진행되고 있으나, 한국어의 특성상 많은 제약을 갖고 있다. 개체명 인식(NER)은 정형화되지 않은 방대한 텍스트에 숨어있는 개체명을 검출하고, 이를 미리 정의한 개체명 클래스에 따라 분류하는 자연어 처리(NLP) 태스크 중 하나이다. 개체명 정보는 텍스트 내에서 특정 도메인과 관련된 지식을 이해하는 데에 실마리를 제공하는 어휘 특징(Lexical Feature) 중 하나로 먼저 텍스트 문서로 부터 정보를 추출(Information Extraction)하여 토큰화(Tokenization)와 품사 태깅과 같은 전처리 작업이 필요하다. 본 연구에서는 한국어 처리에 앞서 금융에 특화한 영문 코퍼스를 제시하고자 한다. Financial_phrasebank 데이터셋와 IIRC 회원 약 83개 글로벌 기업의 재정보고서에서 약 8천개의 금융 텍스트를 추출, 통합하여 총 약 12.7천개 문장으로 구성된 데이터셋을 구축하였으며, 전이학습 과정에서 분류되는 개체명 클래스를 기존의 7개 클래스 분류에서 15개 클래스로 분류, 확장한 언어 모델을 제안한다. 레이블링을 거쳐 BERT_base 모델을 결합하여 모델 학습을 진행한 후 정확도, 재현율, F1 스코어 등의 검사를 통해 금융 분야에서의 최적의 데이터셋을 제안한다.","In the field of Natural Language Processing (NLP) for Korean, research has been actively conducted centering on the BERT language model introduced by Google. However, its application to Korean still has some limitations due to the nature of this language. Named Entity Recognition (NER) is one of the NLP tasks that detects entity names represented in large amounts of unstructured text and classifies them according to predefined entity classes. As one of the lexical features, entity information provides a clue to understanding of domain-specific knowledge within a text. Extracting the entity information in text typically requires preprocessing, including tokenization and part-of-speech tagging. In this study, we present an English corpus specialized in finance for Korean language processing. We extracted and integrated about 8,000 financial texts from the Financial_phrasebank dataset and financial reports of about 83 global companies that are members of IIRC to build a dataset consisting of a total of about 12.7 thousand sentences. We propose a language model that extends the classification of object names from 7 classes to 15 classes in the process of transfer learning. After labeling and training the model by combining the BERT_base model, we propose an optimal dataset for the financial field through accuracy, recall, and F1 score."
BERT의 문맥 정보에 미치는 특이 차원의 영향,2023,"['자연어 처리', 'BERT', '아니소트로피', '클러스터링', '특이 차원', 'natural language processing', 'BERT', 'anisotropy', 'clustering', 'outlier dimensions']","최근 자연어 처리에서 트랜스포머 계열의 네트워크가 뛰어난 성능을 발휘하고 있다. 그에 따라 트랜스포머의 구조를 일부 변형하여 만든 언어 모델인 BERT 또한 많은 자연어 처리 태스크에서 사용되고, 좋은 결과를 보여주고 있다. BERT는 셀프 어텐션을 통해 문맥 정보를 담아서 임베딩 벡터를 인코딩하는데, 이 과정에서 관련 있는 단어의 임베딩 벡터들이 유사해진다. 이는 단어들 사이의 코사인 유사도를 통해 알 수 있는데, BERT의 초기 계층에서는 문맥 정보가 담기지 않아 단어 사이의 코사인 유사도가 낮지만, 뒤쪽 계층으로 갈수록 셀프 어텐션을 통해 문맥 정보가 추가되면서 단어 사이의 코사인 유사도가 높게 나오는 것을 알 수 있다. 하지만 높은 코사인 유사도 값을 가지게 되는 것에 있어서 임베딩 벡터의 특정 차원이 지배적인 역할을 한다는 연구가 존재한다. 본 연구에서는 그러한 차원이 문맥 정보를 포함하는 것에 어떤 영향을 미치는지를 확인하기 위해 그러한 차원을 지우기 전과 후의 단어 임베딩 벡터를 클러스터링한 후 두 결과를 비교하여 확인하였다.",다국어 초록 정보 없음
BERT 모형을 이용한 주제명 자동 분류 연구,2023,"['자동 분류', '딥러닝', 'BERT 모형', '주제명 자동 부여', '자동 주제 분류', 'Automatic Classification', 'Deep Learning', 'BERT Model', 'Automated Subject Indexing', 'Automated Subject Classification']","이 연구는 딥러닝 기법의 전이학습 모형인 BERT를 이용하여 주제명의 자동 분류를 실험하고 그 성능을 평가하였으며, 더 나아가 주제명이 부여된 KDC 분류체계와 주제명의 범주 유형에 따른 성능을 분석하였다. 실험 데이터는 국가서지를 이용하여 주제명의 부여 횟수에 따라 6개의 데이터셋을 구축하고 분류 자질로 서명을 이용하였다. 그 결과, 분류 성능으로 3,506개의 주제명이 포함된 데이터셋(레코드 1,539,076건)에서 마이크로 F1과 매크로 F1 척도가 각각 0.6059와 0.5626 값을 보였다. 또한 KDC 분류체계에 따른 분류 성능은 총류, 자연과학, 기술과학, 그리고 언어 분야에서 좋은 성능을 보이며 종교와 예술 분야는 낮은 성능을 보였다. 주제명의 범주 유형에 따른 성능은 ‘식물’, ‘법률명’, ‘상품명’이 높은 성능을 보인 반면, ‘국보/보물’ 유형의 주제명에서 낮은 성능을 보였다. 다수의 주제명을 포함하는 데이터셋으로 갈수록 분류기가 주제명을 제대로 부여하지 못하는 비율이 늘어나 최종 성능의 하락을 가져오기 때문에, 저빈도 주제명에 대한 분류 성능을 높이기 위한 개선방안이 필요하다.","This study experimented with automatic classification of subject headings using BERT-based transfer learning model, and analyzed its performance. This study analyzed the classification performance according to the main class of KDC classification and the category type of subject headings. Six datasets were constructed from Korean national bibliographies based on the frequency of the assignments of subject headings, and titles were used as classification features. As a result, classification performance showed values of 0.6059 and 0.5626 on the micro F1 and macro F1 score, respectively, in the dataset (1,539,076 records) containing 3,506 subject headings. In addition, classification performance by the main class of KDC classification showed good performance in the class General works, Natural science, Technology and Language, and low performance in Religion and Arts. As for the performance by the category type of the subject headings, the categories of plant, legal name and product name showed high performance, whereas national treasure/treasure category showed low performance. In a large dataset, the ratio of subject headings that cannot be assigned increases, resulting in a decrease in final performance, and improvement is needed to increase classification performance for low-frequency subject headings."
한국어 기반 BERT를 활용한 전투명령 자동 분류 모델 제안 및 평가,2023,"['AI military staff', 'NLP', 'BERT', 'multi classification', 'future warfare', '인공지능 참모', '자연어 처리', 'BERT', '다중분류', '미래전']","변화하는 국제 정세와 안보 상황에서 지능화 전쟁이라는 새로운 전쟁 패러다임이 떠오르고 있다. 지능화 전쟁은 인공지능 기술을 기반으로 육·해·공·우주, 전자기·사이버, 인지 영역에서 진행되는 제반 합동 전력에 의한 통합 전쟁이며, 국방 분야에서는 이를 대비해 대용량의 정보를 처리하고 분석하여 지휘관의 의사결정을 지원하는 인공지능 참모를 구현하려고 노력하고 있다. 인공지능 참모에 있어서 핵심 기술 중 하나인 자연어 처리는 지휘관의 언어를 분석하여 동시다발적으로 명령을 하달하게 함으로써 지휘통제를 더 정확하고 빠르게 하도록 지원할 수 있다. 본 연구에서는 한국어 데이터로 학습된 BERT를 이용하여 전투명령에 대한 전투수행기능을 예측하는 딥러닝 모델을 제안하고, 그 성능을 평가하였다. 제안한 딥러닝 모델은 지휘관의 명령이 입력되면 해당 문장이 6대 전투수행기능(지휘통제, 정보, 화력, 지속지원, 방호, 기동) 중 어느 기능에 해당하는지 자동 분류하여 의사결정의 속도를 향상시킬 수 있는 특징이 있다. 실험 결과, 모델은 전투명령의 기능별 분류에 대해 평균 정확도 78%, 정밀도 79%, 재현율 80%, F-1점수 79%로 높은 성능을 보였으며, 한국어 BERT 모델의 군사적 적용 가능성을 확인할 수 있었다.",다국어 초록 정보 없음
ChatGPT와 다국어 BERT를 이용한 코로나-19 감염병 다국어 기사 자동 색인 및 분류,2023,"['COVID-19', 'BERT', 'ChatGPT', 'Multilingual', 'News classification']","본 논문에서는 코로나-19 감염병의 국제적인 전파 및 해결방안의 도출을 위하여 다국어 기사들을 미리 정의한 연관 사건들로 자동 분류하는 방법을 제안한다. 기존의 자동 분류 방법들은 대량의 학습자료 수집 및 전문가에 의한 색인이 요구되며, 이는 빠르게 변이되고 확산되는 코로나-19 및 신종 감염병의 대처에 적합하지 않다. 본 연구는 색인되지 않은 다국어 기사들은 유료 서비스인 ChatGPT와 Google 번역기를 이용해 연관 사건들로 분류 및 확장하여 대규모 학습자료를 구축하는 방법을 제안한다. 구축된 다국어 학습자료를 이용하여 감염병 기사에 연관된 사건들로 자동 분류하는 다국어 버트(BERT) 기반 모델을 제안하였으며, 이를 이용하여 온라인 기사 기반 감염병 감시 체계를 구축하고, 최소한으로 유료 서비스 활용을 통해 매우 높은 정확도의 감염병 관련 사건 발생의 조기 예측을 가능하게 한다. 실험 결과 5,898건의 학습자료를 제안된 자동 색인 및 확장 없이 다국어 버트에 적용하였을 때 평균 정확도와 F1 점수가 85.85%, 67.57%로 실용화하기 부족한 성능을 보였으나, 제안된 방법을 사용하여 47,183건의 학습자료로 확장하여 구축하였을 때 평균 정확도와 F1 점수가 98.21%와 95.71%로 향상되었다.","In this paper, we propose a method of automatically classifying multilingual new articles into predefined relevant events to help prevent international spread of the COVID-19. Conventional automatic classification methods require large amounts of learning data and human labeling, which are not suitable for coping with rapidly mutating and spreading COVID-19 and similar infectious diseases. We proposes a method for constructing large-scale training dataset by automatic article classification by ChatGPT and multilingual data augmentation by Google Translator, which are both paid services. Using the constructed multilingual training dataset, we proposed a model that automatically classifies news articles into the predefined categories using multilingual BERT. The proposed method enables early prediction of various types of COVID-19 events with decent accuracy. According to the experiments, with 5,898 news articles as training data the multilingual BERT without the proposed automatic indexing and augmentation, the average accuracy and F1 score were 85.85% and 67.57%, which were insufficient for practical applications. However, with 47,183 news articles using the proposed method, the average accuracy and F1 score improved to 98.21% and 95.71%."
효과적인 개인화 결합 방식 및 BERT를 활용한 리뷰 기반 개인화 추천시스템,2023,"['personalized recommendation', 'review-based recommendation', 'recommendation system', 'natural language processing', 'BERT', '개인화 추천', '리뷰 기반 추천', '추천시스템', '자연어처리', 'BERT']","일반적으로 리뷰 텍스트에는 사용자의 주관적인 정보들이 포함되어 있으며 사용자가 작성한 리뷰는 같은 표현이더라도 사용자별로 서로 다른 의미를 가질 수 있다. 이런 리뷰의 특징을 이용하여 데이터 희소에 취약한 협업 필터링의 단점을 보완할 수 있으며 개인화 추천시스템을 위한 정보로도 사용할 수 있다. 하지만 자연어처리 분야에서 사전 학습 언어 모델의 성공에도 불구하고, BERT를 활용하여 리뷰를 통해 개별 사용자 특징을 풍부하게 표현하고자 하는 개인화 추천시스템 연구는 많이 이루어지고 있지 않다. 따라서 본 연구에서는 BERT를 사용하여 리뷰로부터 사용자 및 상품별 특징을 깊이 학습하고, 이를 사용자 및 상품 ID와 긴밀하게 결합함으로써 개인화된 사용자 및 상품 표현을 나타내는 평점 예측 모델을 제안한다. 실험을 통해 아마존 벤치마크 데이터셋에 대해 제안하는 모델이 베이스라인보다 향상된 성능을 얻을 수 있음을 보인다.",다국어 초록 정보 없음
BERT를 활용한 전자정부표준프레임워크 코드 생성 모델 구축,2023,"['BERT', 'CodeBERT', 'KoBERT', 'e-government Framework', 'Spring MVC pattern', 'Source code generation']","전자정부프레임워크에 기반하여 다양한 프로젝트를 수행하면서 코드 작성에 많은 어려움이 있다. 이에 인공지능 기반의 딥 러닝(Deep Learning)을 활용하여 사람이 대화를 위해 사용하는 자연어를 컴퓨터가 이해할 수 있게 변환하는 다양한 사례가 증가하고 있다. OpenAI의 Codex 모델을 사용하여 Github가 보유한 소스 코드를 학습시켜 개발자가 통합 개발 환경(Integrated Development Environment, IDE)에서 GitHub Copilot Extension을 설치하고 주석이나 함수명을 입력하면 인공지능이 작성해야 할 소스 코드를 자동 완성하여 제시해 주어 개발자의 생산성을 높여주고 있다. 다만 인공지능이 학습하지 않은 코드에 대해서는 완벽한 코드를 제시하지 못하며 간혹 AI가 개발자의 의도를 잘못 이해하고 많은 부분을 수정해야 하는 코드를 제시하기도 한다. 그렇게 되면 오히려 생산성에 마이너스가 될 수도 있다. 본 논문에서는 Github의 Copilot이 Github repository를 이용하여 코드를 학습시켰듯이 전자정부표준프레임워크를 기반으로 한 프로젝트에서 사용하고 있는 소스 코드를 BERT(Bidirectional Encoder Representations from Transformers) 모델을 통해 학습시켜 소스 코드를 자동으로 생성하는 코드 생성 모델을 제안한다. 이를 통해 프로젝트의 생산성 향상 도구로 활용되어 코드 작성 시간을 줄여줄 뿐만 아니라, 개발 과정의 노하우를 모델에 축적하여 개발자의 의사소통 도구로 다양한 분야에 활용할 수 있을 것으로 사료된다.","There are many difficulties in writing code while performing various projects based on the e-government framework. Therefore, artificial intelligence(AI)-based software development tools, various cases of converting natural language used when talking to people into a programming language that computers can understand are increasing. By using OpenAI's Codex model to learn the source code owned by Github, developers install GitHub Copilot Extension in an integrated development environment(IDE) and enter annotations or function names, automatically completing and presenting the source code to be written by artificial intelligence to increase developer productivity. However, for codes that artificial intelligence has not learned, it does not present perfect codes, and sometimes AI misunderstands the developer's intentions and presents codes that need to be modified in large part. If that happens, it could rather negatively affect productivity. In this paper, we propose a code generation model that automatically generates the source code by learning the source code used in projects based on the e-government standard framework to the BERT model, as Github Copilot learned the code using the Github repository. Through this, it is believed that it can be used as a tool to improve the productivity of the project, reducing code writing time, and accumulating know-how in the development process in the model to be used in various application cases as a communication tool for developers."
BERT를 활용한 뉴스 기사 감성분석과 블랙-리터만 모형을 결합한 자산 배분 전략 제안,2023,"['딥러닝', 'BERT', '뉴스 기사', '감성분석', '블랙-리터만 모형', '자산 배분 전략', 'Deep Learning', 'BERT', 'News Article', 'Sentiment Analysis', 'Black-Litterman Model', 'Asset Allocation Strategy']",국문 초록 정보 없음,"This study introduces an asset allocation strategy that utilize sentiment analysis from news articles through a deep learning model. The derived sentiments are then integrated into the Black-Litterman model, offering a systematic approach to mitigate the inherent subjectivity in investor decisions. Empirical findings from this study reveal the superiority of this proposed approach compared with conventional benchmark portfolios such as market, equal-weighted, and mean-variance portfolios. In particular, the exclusion of articles generating neutral sentiment (neither positive nor negative) further enhances the profitability of the portfolio. In addition, the study shows that constructing portfolios based on the polarity of sentiment, rather than considering its positive or negative intensity , improves profitability. The significance of this study lies in its introduction of a novel framework for constructing asset allocation strategies. By utilizing objective information from publicly available news articles, it effectively circumvents the limitations tied to subjective investor judgment in predicting expected returns. The demonstrated feasibility and superiority of this data-driven approach in asset allocation strategies underscore its potential to revolutionize current practices."
SMART-ID: R&D 기관 식별을 위한 BERT 응용 기반 시멘틱 매칭,2023,"['BERT', 'R&D data', 'Text similarity', 'Semantic similarity', 'Data verification']","국가R&D(Research & Development) 과제를 수행하는 기관이 증가함에 따라 과제 수행기관별로 R&D정보를 제공하는 분석 서비스에 대한 수요가 증가하고 있다. R&D과제 중심으로 구축된 데이터를 수행기관 중심으로 변경하여 정보를 제공하기 위해서는 수행기관의 식별작업이 필수적이다. 기존에는 사업자등록번호, 법인번호, 시스템별 관리용 기업 코드와 같은 식별 코드를 활용하거나 사용자가 입력한 기관명의 문자열 매칭을 기반으로 식별작업을 수행하였다. 그러나 기존 방법은 사용자의 오기 및 이형명을 고려하지 못하는 문제점으로 인하여 오식별 하는 문제가 발생하였다. 본 연구는 BERT를 활용한 의미론적 유사도와 최장 공통 부분 문자열(Longest Common Substring, LCS) 알고리즘 기반의 문자열 유사도를 적용한 하이브리드 시스템인 SMART-ID를 구축하여 문제점을 개선하고자 한다. SMART-ID는 R&D 수행기관 식별정보 갱신 자동화 및 R&D 연구과제데이터의 기관명 검증, R&D 연구과제 데이터의 수행기관 식별 코드 자동할당, 텍스트 기반 수행기관 검색 작업을 수행할 수있다. 국가과학기술지식정보서비스(NTIS)의 실제 데이터를 기반으로 위 3가지의 작업에서 SMART-ID의 우수한 성능을 입증하였다. SMART-ID은 향후 국가과학기술지식정보서비스의 챗봇 내 기관명 인식 모듈로 활용하여 더욱 정확한 기관별 통계및 검색 정보를 제공하는데 활용될 것이다.",다국어 초록 정보 없음
BERT로 측정한 경영자의 낙관성과 투자 의사결정의 관계,2023,"['경영자의 낙관성', '과신', '투자', '성과', '머신러닝', 'Managerial Optimism', 'Overconfidence', 'Investment', 'Performance', 'Machine Learning']",국문 초록 정보 없음,"This paper aims to investigate the effect of managerial optimism on corporate investment and performance. BERT’s methodology, a machine learning method developed by Google, was used to measure managerial optimism for companies listed on KSE (Korea Stock Exchange) and KOSDAQ from 2009 to 2019. Optimism, when there are capital constraints of companies, is defined as overconfidence, and unlike previous studies, the meaning of managerial optimism and overconfidence is distinguished. The empirical analysis revealed the following: higher the manager’s optimism, higher the cash flow, smaller the size of the firm, larger the debt ratio and lastly, higher the growth potential, higher the investment. Furthermore, in analyzing the relationship between performance and investment, higher optimism and investment was associated with higher corporate performance. Finally, when a company is in a capital constraint state, it was found that managerial optimism negatively affected corporate performance. These findings are consistent with previous studies that showed that more optimistic managers have higher investment and that excessive optimism is not good for corporate value."
Sentence BERT를 이용한 내용 기반 국문 저널추천 시스템,2023,"['Deep learning', 'Document similarity', 'Recommendation system', 'Research papers', 'SBERT(Sentence Bidirectional Encoder Representations from Transformers)', '딥러닝', '문서유사도', '추천시스템', '논문', 'SBERT']",국문 초록 정보 없음,"With the development of electronic journals and the emergence of various interdisciplinary studies, the selection of journals for publication has become a new challenge for researchers. Even if a paper is of high quality, it may face rejection due to a mismatch between the paper’s topic and the scope of the journal. While research on assisting researchers in journal selection has been actively conducted in English, the same cannot be said for Korean journals. In this study, we propose a system that recommends Korean journals for submission. Firstly, we utilize SBERT (Sentence BERT) to embed abstracts of previously published papers at the document level, compare the similarity between new documents and published papers, and recommend journals accordingly. Next, the order of recommended journals is determined by considering the similarity of abstracts, keywords, and title. Subsequently, journals that are similar to the top recommended journal from previous stage are added by using a dictionary of words constructed for each journal, thereby enhancing recommendation diversity. The recommendation system, built using this approach, achieved a Top-10 accuracy level of 76.6%, and the validity of the recommendation results was confirmed through user feedback. Furthermore, it was found that each step of the proposed framework contributes to improving recommendation accuracy. This study provides a new approach to recommending academic journals in the Korean language, which has not been actively studied before, and it has also practical implications as the proposed framework can be easily applied to services."
장애인 시위 관련 뉴스 댓글의 비윤리성 측정과 정치 성향에 따른 차이 비교: BERT 기반 딥러닝 분류기 개발과 적용,2023,"['뉴스 댓글', '비윤리성', '장애인', '차별', '정치 성향', '딥러닝', 'comments', 'ethics', 'discrimination', 'political orientation', 'deep-learning']",국문 초록 정보 없음,"This study collected 50,875 news comments on the subway protests for the disabled and measured the ethical levels across five dimensions such as discrimination, abuse, violence, and sexual expression. Based on this analysis, the difference of ethical levels and empathy-inducing influence between the comments of the conservative and progressive media. First of all, this research team developed a deep-learning model for measuring ethical levels through BERT-based transfer-learning. As a result of the analysis, 39.95% of all comments were classified as ‘no problem.’ On the other hand, ‘discrimination’ and ‘abuse’ appeared frequently enough to account for 37.07% and 17.05% of the total. In addition, it was found that comments from progressive media (MBC, Pressian, Hankyoreh newspaper) had relatively few ethical problems compared to the comments from conservative media (TV-Chosun, Dailian, ChosunIlbo). The problem of ‘discrimination’, which was observed the most, also appeared more in the conservative media than in the progressive media. Moreover, in the conservative media, a high rate of empathy was observed for comments classified as discrimination and violence, and a tendency was observed that the higher the level of discrimination and violence in comments, the higher the rate of empathy was observed. It it time to make an effort to revive the comment space of our media, especially the conservative media, into a democratic public sphere where deliberation and agonism take effect."
BERT 기반 혐오성 텍스트 필터링 시스템 - 대학 청원 시스템을 중심으로,2023,[],국문 초록 정보 없음,다국어 초록 정보 없음
BERT Q&A 모델을 활용한 장학금 정보 추출 및 추천 시스템,2023,[],국문 초록 정보 없음,다국어 초록 정보 없음
An Ensemble Model for Credit Default Discrimination: Incorporating BERT-based NLP and Transformer,2023,[],국문 초록 정보 없음,다국어 초록 정보 없음
PGB: BERT 프루닝을 위한 순서 변경 규칙 및 그룹화,2023,"['BERT compression', 'task-specific pruning', 'structured pruning', 'head pruning', 'BERT 압축', '과제별 프루닝', '구조화된 프루닝', '헤드 프루닝']","최근 사전 학습된 트랜스포머 계열의 모델은 자연어 처리, 이미지 인식 등 다양한 인공지능 분야에서 활발히 사용되고 있다. 그러나 해당 모델들은 수십억 개의 파라미터를 가지고 있어 추론 시에 상당한 연산량을 필요로 하며 자원이 제한된 환경에서 사용하기에는 많은 제약이 따른다. 이러한 문제들을 해결하기 위해 본 논문은 트랜스포머 모델에 대한 그룹화 기반의 새로운 구조화된 프루닝 방법인 PGB(Permutation Grouped BERT pruning)를 제안한다. 제안된 방법은 자원 제약 조건에 따라 최적의 어텐션 순서를 변경하는 방법을 찾고, 모델의 정보 손실을 최소화하기 위해 헤드의 중요도를 기반으로 불필요한 헤드에 대해 프루닝한다. 다양한 비교 실험을 통해 사전 학습된 BERT 모델에 대한 기존의 구조화된 프루닝 방법보다 본 논문에서 제안한 방법이 추론 속도 및 정확도 손실 측면에서 더 우수한 성능을 보임을 확인한다.",다국어 초록 정보 없음
CEFRに対応した日本語例文自動分類システムのBERT適用による精度改善の試み,2023,"['CEFR', 'Can-Do Statements', 'example sentences', 'automatic classification', 'BERT', '유럽언어공통기준(CEFR)', 'Can-Do Statements', '예문', '자동분류', 'BERT']",국문 초록 정보 없음,"The Common European Framework of Reference for Languages (CEFR) is an example of a Can-Do language proficiency scale that has attracted large attention in recent years and has been introduced in foreign language education worldwide. On the other hand, there are a few examples of CEFR research related to Japanese language education. As far as the present authors investigated, there is no Japanese CEFR-compliant text corpus. In the current research, to create a corpus, we focused on the implementation of automatic classification in order to reduce the effort of adding Can-Do Statement (CDS), thereby enhancing the reading comprehension of CEFR in the example sentences. Document type, specialty, sentence length, and Kanji rate are commonly used as the parameters for classification; however, the current version of the aforementioned implementation uses fastText to identify document type and specialty. The present study attempted to apply the Bidirectional Encoder Representations from Transformers (BERT) algorithm, which has been confirmed to work effectively in many natural language processing tasks. The findings of the research showed that prediction accuracy was improved and it was possible to suppress the number of CDSs for more appropriate prediction. Prospects include improving the precision by further narrowing down the number of predictions, creating more compelling features, and collecting more data using CDS information. The targets in this study were CEFR proficiency levels A1, A2, B1, B2, and PreA1 for Reading skill items (34 CDSs correspond to those levels)."
에세이 평가 자동화를 위한대조 학습 기반 다중계층 BERT 모델 손실함수에 관한 연구,2023,"['automated essay scoring', 'BERT', 'multi-task loss function', 'contrastive learning', 'sampling', '.']",국문 초록 정보 없음,"Essay writing is the most populary used method to evaluate students achievement in the class. However, the usage of essay writing is limited by the labor intensive and subjective nature of the essay scoring process. To overcome the latter, many researches have been done to automate essay scoring process. However, the performance of automated essay scoring is not suitable in practical usage. In this paper, we are proposing a contrastive learning-based Multi-scale BERT model to improve the performance of automated essay scoring. We applied many different loss functions to generate the positive and negative samples for contrastive learning, and experimented with ASAP benchmark dataset. According to our experiments, the constrastive learning based Multi-scale BERT model shows 3% improvement in QWK, and 4.5% improvement in Pearson according to the loss functions."
Sentence-BERT를 활용한 YouTube 가짜뉴스 탐지 시스템 연구,2023,[],"IT 기술의 발달로 인해 뉴스를 제공하는 플랫폼들이 다양해 졌고 최근 해외 인터뷰 영상, 해외 뉴스를 Youtube Shorts형태로 제작하여 화자의 의도와는 다른 자막을 달며 가짜 뉴스가 생성되는 문제가 대두되고 있다. 이에 본 논문에서는 Sentence-BERT를 활용한 YouTube 가짜 뉴스 탐지 시스템을 제안한다. 제안하는 시스템은 Python 라이브러리를 사용해 유튜브 영상에서 음성과 영상 데이터를 분류하고 분류된 영상 데이터는 EasyOCR을 사용해 자막 데이터를 텍스트로 추출 후 Sentence-BERT를 활용해 문자 유사도를 분석한다. 분석결과 음성 데이터와 영상 자막 데이터가 일치한 경우 일치하지 않은 경우보다 약 62% 더 높은 문장 유사도를 보였다.",다국어 초록 정보 없음
형태소 수준의 BERT 임베딩을 통한 한국어 상호참조해결,2023,"['상호참조해결', 'end-to-end', 'BERT', '스팬 표현', 'coreference resolution', 'end-to-end', 'BERT', 'span representation']","상호참조해결은 주어진 문서에서 상호참조해결 대상이 되는 멘션(mention)을 식별하고, 동일한 개체(entity)를 의미하는 멘션들을 찾아 그룹화하는 자연어처리 태스크이다. 최근 한국어 상호참조해결은 End-to-End 방식으로 주로 연구가 되고 있으며, 이를 위해 모든 스팬을 잠재적인 멘션으로 간주해야 되기 때문에 메모리 사용량과 시간 복잡도가 상승하는 문제가 있다. 본 논문에서는 서브 토큰을 다시 단어 단위로 매핑하여 상호참조해결을 수행하는 워드 레벨 상호참조해결 모델을 한국어에 적용하였으며, 한국어 특성을 반영하기 위해 워드 레벨 상호참조해결 모델의 토큰 표현을 CorefBERT를 통해 계산한 후 개체명 자질과 의존 구문 분석 자질을 추가하였다. 실험 결과, ETRI 질의응답 도메인 평가 셋에서 F1 70.68%로, 기존 End-to-End 방식의 상호참조해결 모델 대비 1.67% 성능 향상을 보이면서 메모리 사용량은 2.4배 좋아졌고, 속도는 1.82배 빨라졌다.",다국어 초록 정보 없음
원거리 감독 방법을 이용한 BERT 기반 한국어 관계 추출 방법,2023,"['자연어 처리', '지식 그래프', '관계 추출', '원거리 감독', 'Natural Language Processing', 'Knowledge Graph', 'Relation Extraction', 'Distant Supervision']","관계 추출 작업은 다양한 자연어 처리 분야에서 사용되며, 특히, 지식 그래프 구축의 필수 작업 중 하나이며 개체 간의 올바른 관계 정의가 지식 그래프의 성능에 영향을 미치기 때문에 높은 성능이 요구되는 작업이다. 그 중, 최근 활발히 연구되고 있는 신경망 모델을 이용하는 관계 추출 작업 방법은 원거리 감독 방법을 이용해 학습 데이터를 손쉽게 구축할 수 있다. 본 논문에서는 개체명 인식 처리 방법을 이용하여 한국어에 적합한 원거리 감독 방법과 BERT 모델을 이용한 한국어 관계 추출 방법을 제안한다. 그 결과, 개체명 인식 처리 작업과 원거리 학습 방법을 통해 생성된 총 362개의 관계로 정의된 183,535개의 학습 데이터를 이용하여 학습한 경우, Focal 손실 함수가 74.17%의 성능으로 70.75%의 교차 엔트로피 손실 함수 성능에 비해 높은 성능을 보였음을 확인하였다.","Relation extraction task are used in various natural language processing tasks, and in particular, this task are one of the essential tasks of building knowledge graph and is one of the tasks requiring high performance because the correct definition of relation between entities affects the performance of the knowledge graph. Among them, the relation extraction task using the neural network model require a large amount of learning data can be easily constructed using the distant supervision methods. In this paper, we propose a distant supervision method suitable for Korean using the named entity recognition processing and a Korean relation extraction method using the BERT model. As a result, when training using 183,535 data defined by a total of 362 relation generated through named entity recognition processing and distant supervision, the focal loss function showed performance of 74.12% and higher performance than the cross entropy loss performance of 70.75%."
주거환경에 대한 거주민의 만족도와 영향요인 분석 - 직방 아파트 리뷰 빅데이터와 딥러닝 기반 BERT 모형을 활용하여 -,2023,"['주거환경', '주거환경 만족 영향요인', '아파트 리뷰', '빅데이터', '감정분석', 'Residential Environment', 'Determining Factors of Residential Environment Satisfaction', 'Apartment Reviews', 'Big Data', 'Sentiment Analysis']",국문 초록 정보 없음,"Satisfaction on the residential environment is a major factor influencing the choice of residence and migration, and is directly related to the quality of life in the city. As online services of real estate increases, people’s evaluation on the residential environment can be easily checked and it is possible to analyze their satisfaction and its determining factors based on their evaluation. This means that a larger amount of evaluation can be used more efficiently than previously used methods such as surveys. This study analyzed the residential environment reviews of about 30,000 apartment residents collected from ‘Zigbang’, an online real estate service in Seoul. The apartment review of Zigbang consists of an evaluation grade on a 5-point scale and the evaluation content directly described by the dweller. At first, this study labeled apartment reviews as positive and negative based on the scores of recommended reviews that include comprehensive evaluation about apartment. Next, to classify them automatically, developed a model by using Bidirectional Encoder Representations from Transformers(BERT), a deep learning-based natural language processing model. After that, by using SHapley Additive exPlanation(SHAP), extract word tokens that play an important role in the classification of reviews, to derive determining factors of the evaluation of the residential environment. Furthermore, by analyzing related keywords using Word2Vec, priority considerations for improving satisfaction on the residential environment were suggested. This study is meaningful that suggested a model that automatically classifies satisfaction on the residential environment into positive and negative by using apartment review big data and deep learning, which are qualitative evaluation data of residents, so that it’s determining factors were derived. The result of analysis can be used as elementary data for improving the satisfaction on the residential environment, and can be used in the future evaluation of the residential environment near the apartment complex, and the design and evaluation of new complexes and infrastructure."
도메인 특화 사전학습 언어모델 개발 전략: 자동차 분야 언어모델 V-BERT 개발 사례,2023,"['사전학습 언어모델', '도메인 특화 언어모델', '딥러닝', 'pre-trained language model', 'domain-specific language model', 'BERT', 'deep learning']","최근 방대한 텍스트 데이터에 대해 사전학습을 수행한 모델인 사전학습 언어모델이 다양한 텍스트 분석에 활용되며 성과를 거두고 있다. 하지만 BERT와 같은 범용 사전학습 언어모델은 전문 도메인의 말뭉치에 대해서는 비교적 낮은 성능을 보인다는 한계를 가지며, 이에 따라 전문 도메인에 맞게 도메인 특화 사전학습 언어모델을 새롭게 개발하고자 하는 수요가 증가하고 있다. 하지만 이러한 수요에 비해 도메인 특화 사전학습 언어모델을 개발하기 위한 체계적인 전략 및 접근법에 대한 논의는 부족한 실정이다. 이에 본 연구에서는 도메인 특화 언어모델 개발 시 고려해야할 사항을 정리하여 제안하였으며, 이러한 개발 전략에 따라 자동차 분야 언어모델인 V-BERT를 개발한 사례를 소개하였다. 또한 자동차 분야의 전문 문서에 대한 실험을 통해 V-BERT 기반 CPC 분류 모델이 일반 BERT 기반 모델에 비해 우수한 성능을 보임을 확인하였다.","Recently, pre-trained language models created through pre-training on vast text data have been used for various text analyses. However, general-purpose pre-trained language models, such as BERT, have a limitation as they show relatively low performance for a corpus of specialized domains. Therefore, the demand for newly developing domain-specific pre-trained language models suitable for specialized domains is increasing. However, compared to this demand, more discussion is needed on systematic strategies and approaches to develop domain-specific pre-trained language models. Therefore, in this study, we summarized the critical factors to be considered when developing a domain-specific language model, and introduced an example of developing V-BERT, a language model for the automotive sector, according to this development strategy. In addition, through experiments using patents and papers in the automotive field, we confirmed that the V-BERT-based CPC classification model performed better than the general BERT-based model."
Decoding BERT’s Internal Processing of Garden-Path Structures through Attention Maps,2023,"['attention map', 'Natural Language Processing', 'Psycholinguistics', 'Transformers', 'garden-path structure']",국문 초록 정보 없음,"Recent advancements in deep learning neural models, such as BERT, have demonstrated remarkable performance in natural language processing tasks, yet understanding their internal processing remains a challenge. This study employs the method of examining attention maps to uncover the internal processing of BERT, specifically when dealing with garden-path sentences. The analysis focuses on BERT's utilization of linguistic cues, such as transitivity, plausibility, and the presence of a comma, and evaluates its capacity for reanalyzing misinterpretations. The results revealed that BERT exhibits human-like syntactic processing by attending to the presence of a comma, showing sensitivity to transitivity, and reanalyzing misinterpretations, despite initially lacking sensitivity to plausibility. By concentrating on attention maps, the present study provides valuable insights into the inner workings of BERT and contributes to a deeper understanding of how advanced neural language models acquire and process complex linguistic structures."
CLES-BERT: 에세이 점수 예측을 위한 대조학습 기반 BERT 모델,2023,"['automated essay scoring', 'BERT', 'multi-task loss function', 'contrastive learning', 'sampling']",국문 초록 정보 없음,"Creativity is an important ability in the 4th industrial revolution so writing is one of educational tools to improve creativity. However, student’s essays have been mainly evaluated subjectively in schools. To address this problem, Automated Essay Evaluation(AES) plays an important role in objective evaluation in addition to reducing the time and effort of instructors. This paper presents a novel AES model in which contrastive learning-based loss function is added to BERT. Furthermore, for contrastive learning, positive and negative samples are selected based on mean embedding vectors per essay score. The experimental results show that the proposed Contrastive Learning Essay Scoring-Bidirectional Encoder Representations from Transformers(CLES-BERT) improved average accuracy up to 3%, compared to main AES models, in Automated Student Assessment Prize(ASAP) data set."
Grammatical illusions in BERT: Attraction effects of subject-verb agreement and reflexive-antecedent dependencies,2023,"['xAI', 'DNN language models', 'BERT', 'Masked Language Model', 'cue-combinatoric scheme', 'attraction effects']",국문 초록 정보 없음,"The phenomenon of attraction effects, whereby a verb erroneously retrieves a syntactically inaccessible but feature-matching noun, is a type of grammatical illusions (Phillips, Wagers, and Lau 2011) that can occur in long-distance subject-verb agreement in human sentence processing (Wagers et al. 2009). In contrast, reflexive-antecedent dependencies have been claimed to lack attraction effects when the reflexive and the antecedent mismatch (Dillon et al. 2013). Yet, some other studies have shown that attraction effects have been observed in reflexive-antecedent dependencies, when the number of feature mismatch between the reflexive and the antecedent increases (Parker and Philips 2017). These findings suggest that there are different cue weightings based on the predictability of the dependency, and these cues are combined according to different cue-combination scheme, such as a linear or a non-linear cue-combination rule (Parker 2019). These linguistic phenomena can be used to analyze how linguistic features are accessed and combined within the internal states of Deep Neural Network (DNN) language models. In the linguistic representations of BERT (Devlin et al. 2018), one of the pre-trained DNN language models, various types of linguistic information are encoded in each layer (Jawahar et al. 2019) and combined while passing through the layers. By measuring the performance of Masked Language Model (MLM), this study finds that both subject-verb agreement and reflexive-antecedent dependencies show attraction effects and follow the linear-combinatoric rule in BERT. The different results from human sentence processing suggest that the self-attention mechanism of BERT may not be able to capture the differences in the predictability of the dependency as effectively as memory retrieval mechanisms in humans. These findings have important implications for developing more understandable and interpretable explainable-AI (xAI) systems that better capture the complexities of human language processing."
언론의 정치 성향에 따른 기업 보도 태도의 차이와 기업인 경기평가 심리에 미치는 영향 분석 : BERT 기반 딥러닝 모형을 적용한 빅데이터 분석,2023,"['Economic Journalism', 'Corporate News', 'Political Orientation', 'BERT Deep-Learning', 'Granger Causality', '경제 저널리즘', '기업 보도', '정치 성향', 'BERT 딥러닝', '그랜저 인과관계']",국문 초록 정보 없음,"This study collected 154,876 corporate news articles and measured their positive or negative attitude using a BERT-based deep-learning model. The attitude scores were then compared among various factors such as topics, media’s political orientation, and governments political orientation. Additionally, this study analyzed the relationship between corporate news attitude and businessmen’s economic evaluation.First of all, topic modeling analysis revealed that corporate reporting was comprised of 7 dimensions: product-sales, economy-policy, technology-new product, investment-business, management-share, personnel-employment, and suspicion-investigation. These dimensions encompass most activities of corporations and demonstrate the suitability of this classification for corporate news analysis.Furthermore, the research team developed a training dataset (n = 3,198) for positive-negative classification based on the YTN and Yonhap Infomax’s corporate news. After the team trained a BERT-based deep-learning model several times, the final model showed an accuracy rate of 94.69%.This model measured the attitude of every corporate news article and showed that the majority of the news coverage was generally positive. Nearly two-thirds (62.64%) were classified as positive, and the average attitude scores of analyzed news media were higher than 0.5 (closer to 0 is negative, and closer to 1 is positive). It implies that the trend of market-driven journalism has been strengthened as the number of news media increases and their competition intensifies.Additionally, there was a significant difference in the attitude of corporate news between conservative and progressive media. Conservative media showed more positive coverage of companies than progressive media. Even in the news on corporate scandals and investigations, conservative media were less critical than progressive media. According to previous research, there is a claim that pro-business bias is a main discourse strategy for conservative groups. Since the 1990s, neo-liberalism has been accepted as an important value in our society, and competition and deregulation have been highly valued. Economically, businesses in their pursuit of freedom and profits should be positively considered with the expectation of the trickle-down effects. On the other hand, progressive groups have emphasized government’s intervention to decrease economic polarization and have been critical of businesses. Nowadays conservative and progressive media also maintain these different perspectives and make significant differences in their corporate news.The relationship between corporate news attitudes and businessmen’s economic evaluation has shown various results. Corporate news affected the businessmen’s economic evaluation in the topics of technology-new products and suspicion-investigation while it was vice versa in the topics of product-sales, management-share, and personnel-employment. Such inter-relationship was more significant in conservative media than progressive media and in large companies rather than small companies. To improve corporate news coverage, the voice of progressive media needs to increase and there should be more interest in small companies."
BERT-Based Logits Ensemble Model for Gender Bias and Hate Speech Detection,2023,"['BERT Embedding Model', 'Gender Bias', 'Hate Speech Detection', 'Logistics Ensemble']",국문 초록 정보 없음,"Malicious hate speech and gender bias comments are common in online communities, causing social problemsin our society. Gender bias and hate speech detection has been investigated. However, it is difficult becausethere are diverse ways to express them in words. To solve this problem, we attempted to detect malicious commentsin a Korean hate speech dataset constructed in 2020. We explored bidirectional encoder representationsfrom transformers (BERT)-based deep learning models utilizing hyperparameter tuning, data sampling, andlogits ensembles with a label distribution. We evaluated our model in Kaggle competitions for gender bias,general bias, and hate speech detection. For gender bias detection, an F1-score of 0.7711 was achieved usingan ensemble of the Soongsil-BERT and KcELECTRA models. The general bias task included the gender biastask, and the ensemble model achieved the best F1-score of 0.7166."
자율주행 차량 환경에서 BERT와 GPT 비교 연구,2023,"['autonomous vehicle', 'GPT', 'artificial nural ntwork', 'BERT', 'encoder', 'decoder']",국문 초록 정보 없음,다국어 초록 정보 없음
XAI 이용한 BERT기반 감성인식 모델 예측 분석,2023,"['XAI', 'BERT', 'SHAP', 'captum', 'emotional recognition']",국문 초록 정보 없음,다국어 초록 정보 없음
Bert와 K-means를 활용한 제조 서비스 연구 동향 분석,2023,[],국문 초록 정보 없음,"Manufacturing service, which provides added value to customers with products as a platform, is receiving attention. Research on manufacturing services is being conducted across various fields, but comprehensive analysis of research trends is still insufficient. This study analyzed the research trends of manufacturing and identified the major areas. A total of 7,061 related papers were collected through a Manufacturing service search on Web of Science, and were analyzed using BERT, K-means clustering, and TF-IDF. As a result of the analysis, the research fields of manufacturing service were classified into a total of 5 clusters, and cluster 0 (process control and supply chain management), 1 (cost-efficient design and quality control), 2 (product development and energy efficiency), and 4 (efficiency improvement in industrial product) increased or maintained research interest, while cluster 3 (quality control and cost management in raw material process) decreased research interest. This study identified the research trends of manufacturing service and can provide insights that can contribute to future research."
BERT를 활용한 사이버 범죄 관련 텔레그램 메시지 주제 분류,2023,[],국문 초록 정보 없음,다국어 초록 정보 없음
BERT를 활용한 사건 관계 추출에서 하위 단어 Pooling 방법에 따른 성능 비교,2023,[],국문 초록 정보 없음,다국어 초록 정보 없음
BERT를 활용한 로그 시퀀스 내 로그 단위 이상탐지를 위한 프레임워크,2023,[],국문 초록 정보 없음,다국어 초록 정보 없음
추가학습 없는 BERT를 활용한 시스템 로그 이상치 탐지,2023,[],국문 초록 정보 없음,다국어 초록 정보 없음
다중 계층 BERT를 활용한 낚시성 기사 탐지 모델,2023,"['natural language processing', 'unsupervised learning', 'pre-training']",국문 초록 정보 없음,다국어 초록 정보 없음
추가학습 없는 BERT를 활용한 시스템 로그 이상치 탐지,2023,[],국문 초록 정보 없음,다국어 초록 정보 없음
Identifying topics and future trends of CCUS technology: a BERT-based iterative topic modeling,2023,"['CCUS', 'BECCS', 'Topic modeling', 'BERTopic', 'Hydrogen']",국문 초록 정보 없음,다국어 초록 정보 없음
Improving US IPO Underpricing Prediction with FinBERT and BERT-Based Topic Modeling,2023,[],국문 초록 정보 없음,다국어 초록 정보 없음
Improving US IPO Underpricing Prediction with FinBERT and BERT-Based Topic Modeling,2023,[],국문 초록 정보 없음,다국어 초록 정보 없음
"Unveiling the Power of Deep Learning: A Comparative Study of LSTM, BERT, and GRU for Disaster Tweet Classification",2023,"['Text mining', 'Text classification', 'Sentiment analysis', 'Supervised machine learning', 'BERT', 'GRU', 'LSTM']",국문 초록 정보 없음,"Disasters have serious effects on peoples lives and buildings. Therefore, social media platforms, such as Twitter, have become more critical. They are crucial tools for responding to and managing disasters effectively. This study examined the effectiveness of various deep learning models, such as bidirectional encoder representations from transformers (BERT), gated recurrent units (GRU), and long short-term memory (LSTM) for classifying disaster-related tweets. Twitter data related to different disasters were collected using hashtags. The data were then cleaned, preprocessed, and manually annotated by a team. The annotated data were divided into training, validation, and testing sets. The data were used to train three models based on BERT, GRU, and LSTM for the categorical classification of disaster tweets. Finally, the three models were evaluated and compared using the test data. BERT achieved an accuracy of 96.2%, making it the most effective model. In contrast, the LSTM and GRU models achieved an accuracy of 93.2% and 88.4%, respectively. These findings underscore the potential effectiveness of deep learning models in classifying disaster-related tweets, offering insights that could enhance disaster management strategies, refine social media monitoring processes, bolster public safety, and provide directions for future research."
BERT 기반 국내 스타트업-해외 바이어간 B2B 매칭 모델,2023,"['B2B Matching', 'BERT', 'Recommender Systems', 'K-Startups', 'NLP']","국내 스타트업이 자사의 시장 확대를 위해 글로벌 시장으로 진출하기 위해서는 적합한 해외 바이어를 효과적으로 발굴하는 작업이 필수적이다. 이에 본 논문은 자연어처리 사전학습 모델인 BERT 기반의 국내 스타트업-해외 바이어간 B2B 매칭 모델을 제안한다. 제안 모델은 국내 스타트업 및 바이어 홈페이지, 상담일지 등에서 수집한 비정형 텍스트 데이터를 입력 데이터로 사용했고, 출력층에서 적합/부적합 파트너를 이진분류하도록 설계했다. 기업정보는 국내 스타트업 2,860개사, 해외 바이어 2,316개사의 데이터를 수집했고, 매칭 정보는 30,456건의 상담데이터 중 긍정 케이스 6,458건(21.2%), 부정 케이스 23,998건(78.8%)의 데이터를 활용했다. 제안모델의 성능평가를 위한 기준모델은 Word2Vec을 양방향 LSTM으로 학습시킨 콘텐츠기반 필터링 모델이다. 실험결과 제안모델은 기준모델에 비해 정확도 (1.7%p), 정밀도 (3.1%p), 재현율(5.2%p), f1-score(4.1%p) 등에서 고르게 더 높은 성능을 보여주었다. 국내 스타트업이 이 모델을 활용해 적합한 바이어를 보다 효과적으로 발굴할 수 있을 것이다.","For K-Startups to advance into the global market for their business expansion, it is critical to find suitable overseas buyers effectively. This paper proposes a business-to-business (B2B) matching model between K-Startups and overseas buyers based on BERT, a pre-trained NLP model. The proposed model was designed to classify binary classification for right or non-right business partners in the output layer using unstructured text data collected from home pages of K-Startups and overseas buyers and business meeting records. For corporate information, data from 2,860 startups and 2,316 overseas buyers were collected, and for matching information, out of 30,456 business meeting records data, 6,458 positive cases (21.2%), and 23,998 negative cases (78.8%) were used. The base model for evaluating the proposed model is a content-based filtering model trained by bidirectional LSTM with Word2Vec. Based on the experimental results, the proposed model demonstrated better performance compared to the comparative model in accuracy (1.7%p), precision (3.1%p), recall (5.2%p), and f1-score (4.1%p). Using this model, K-Startups can find overseas buyers more effectively."
BERT 기반 리뷰 카테고리 분류 시스템,2023,"['BERT', 'KR-SBERT', '카테고리', '리뷰', '텍스트 마이닝']","현재 소비자들은 리뷰를 통해 기업에 대한 이미지를 확립한다. 이에 따라 리뷰 데이터를 분석하여 대중 의 평가를 알아내는 것이 중요하다. 원하는 정보를 가독성 높게 얻기 위해서는 명확한 카테고리를 바탕 으로 리뷰들을 분류하는 것이 중요하다. 그러나 기존의 한국어 문장 임베딩 알고리즘인 KR-SBERT는 유사도를 기반으로 한 카테고리 분류에서 정확도가 한계를 보인다. 이러한 한계를 극복하기 위해 본 논 문에서는 KR-SBERT에 지도 학습 분류기 모델을 추가하여 리뷰 카테고리 분류 성능을 향상시켰다. 실 험 결과, 이를 통해 분류 성능이 57% 향상되었다.",다국어 초록 정보 없음
한국어 에세이 점수 예측을 위한 BERT 기반 모델 성능 비교,2023,"['Automated Korean Essay Scoring', 'BERT', 'Longformer', 'QWK']",국문 초록 정보 없음,다국어 초록 정보 없음
BERT 기반 트윗 감정분석을 통한 영화 추천 시스템,2023,"['Sentiment Analysis', 'Hybrid Recommendation System', 'BERT', 'Tweet']",국문 초록 정보 없음,다국어 초록 정보 없음
Discovering AI-enabled convergences based on BERT and topic network,2023,"['AI', 'BERT', 'Emerging topics', 'Convergences', 'Shortest path']",국문 초록 정보 없음,"Various aspects of artificial intelligence (AI) have become of significant interest to academia and industry in recent times. To satisfy these academic and industrial interests, it is necessary to comprehensively investigate trends in AI-related changes of diverse areas. In this study, we identified and predicted emerging convergences with the help of AI-associated research abstracts collected from the SCOPUS database. The bidirectional encoder representations obtained via the transformers-based topic discovery technique were subsequently deployed to identify emerging topics related to AI. The topics discovered concern edge computing, biomedical algorithms, predictive defect maintenance, medical applications, fake news detection with block chain, explainable AI and COVID-19 applications. Their convergences were further analyzed based on the shortest path between topics to predict emerging convergences. Our findings indicated emerging AI convergences towards healthcare, manufacturing, legal applications, and marketing. These findings are expected to have policy implications for facilitating the convergences in diverse industries. Potentially, this study could contribute to the exploitation and adoption of AI-enabled convergences from a practical perspective."
A BERT MODEL APPROACH ON A LARGE ONLINE REVIEWS DATASET: THE ROLE OF CONTEXT IN EVALUATION,2023,"['BERTopic', 'Topic modellin', 'Online reviews', 'Ewom', 'Restaurant industry']",국문 초록 정보 없음,"Online communities are identified as people gathering online and communicating through the internet to share ideas, objectives, goals, without any geographical boundary. The growth of user-generated content created in online communities has transformed the way consumers search for and share information, particularly in the hospitality industry. Particularly, in the restaurant and food sectors due to the intangible nature of hospitality services, online reviews play an important role on consumer decisions. Furthermore, online reviews on restaurants are not only informational but also, they impact consumers’ choices regarding restaurants. Consequently, the nature of such user-generated content that is produced at a high speed and is diverse and rich should be treated and understood. This study proposes the first tailored BERTopic model together with sentiment analysis based on pre-trained BERT model that takes advantage of its novel sentence embedding for creating interpretable topics into the analysis of restaurant online reviews to determine how the customers elaborate their criteria in the context of certain experiences. An exploratory analysis is presented involving a large-scale review data set of 261,531 restaurant online reviews from 4 different countries retrieved from the eWOM community thefork.com. A broad list of the topics discussed by customers post-dining in restaurants is built. Insights into the behavior, experience, and satisfaction of the customers across the different restaurants are discovered. This approach and findings are encouraging hospitality managers in understanding customers’ perception, through which applicable marketing can be developed to attract and retain potential customers."
CNN-BiLSTM과 BERT 기반 연구 논문 분류 기법의 설계,2023,"['NLP', 'CNN', 'BiLSTM', 'BERT', 'fine-tuning']",국문 초록 정보 없음,다국어 초록 정보 없음
법률 판례 검색을 위한 BERT 및 유사도 기반 모델 연구,2023,"['Machine Learning', 'Deep Learning', 'BERT', 'Data Mining']",국문 초록 정보 없음,다국어 초록 정보 없음
2차전지 기술 특허분석을 통한 토픽모델링: BERT 모델을 이용하여,2023,"['2차전지', '토픽모델링', '특허분석', 'BERT', '태양광 패널']",국문 초록 정보 없음,다국어 초록 정보 없음
Bio-BERT와 GCN을 결합한 텍스트 분류 모델,2023,[],국문 초록 정보 없음,다국어 초록 정보 없음
MIL-BERT: 군사 도메인 특화 한국어 사전학습 언어모델,2023,"['자연어처리(Natural Language Processing)', '군사 언어(Military Corpus)', '사전학습 언어모델(Pre-trained language model)', '문장 분류(Sentence Classification)', '심층 학습(Deep Learning)']",국문 초록 정보 없음,다국어 초록 정보 없음
BERT 기반 문장 분류모델을 이용한 연구 논문의 추출적 요약,2023,[],국문 초록 정보 없음,다국어 초록 정보 없음
BERT 기반의 개인 맞춤형 수강 과목 추천 시스템 구축,2023,[],국문 초록 정보 없음,다국어 초록 정보 없음
BERT 기반의 개인 맞춤형 수강 과목 추천 시스템 구축,2023,[],국문 초록 정보 없음,다국어 초록 정보 없음
BERT 모델 최적화를 위한 NPU내 이종하드웨어의 비순차 스케줄링,2023,[],국문 초록 정보 없음,다국어 초록 정보 없음
BERT 기반의 모델을 이용한 무기체계 소프트웨어 정적시험 거짓경보 분류 모델 개발 방법 연구,2023,[],국문 초록 정보 없음,다국어 초록 정보 없음
BERT 를 활용한 FOMC 회의록에 의한 미국 국채 금리 커브 변동 예측,2023,[],국문 초록 정보 없음,다국어 초록 정보 없음
BERT 기반 토큰 감성 점수기를 통한 문맥 흐름에 따른 감성 변화 파악과 모호한 분장 분석,2023,[],국문 초록 정보 없음,다국어 초록 정보 없음
지식 증류 BERT 기반 Grapheme-to-Phoneme 경량화,2023,[],국문 초록 정보 없음,다국어 초록 정보 없음
감정 이진 분류를 위한 BERT 모델 비교,2023,[],국문 초록 정보 없음,다국어 초록 정보 없음
텍스트-평점 상호작용을 반영한 Bert 기반 리뷰 유용성 예측에 관한 연구,2023,[],국문 초록 정보 없음,다국어 초록 정보 없음
오류 패턴을 이용한 BERT 기반 OCR 오류 수정,2023,[],국문 초록 정보 없음,다국어 초록 정보 없음
텍스트-평점 상호작용을 반영한 Bert 기반 리뷰 유용성 예측에 관한 연구,2023,[],국문 초록 정보 없음,다국어 초록 정보 없음
형태소 분석기를 이용한 BERT 기반의 마스크드 언어 모델,2023,"['morpheme analysis', 'natural language processing', 'language model']",국문 초록 정보 없음,다국어 초록 정보 없음
Entity Name Recognition Model in Receipt using BERT,2023,[],국문 초록 정보 없음,다국어 초록 정보 없음
구조 해석 모형 정의를 위한 BERT 기반 자연어 처리 모델 개발,2023,"['자연어처리', '사전 학습 모델', '구조해석 모형 정보 추출', 'Natural Language Processing', 'Pre-training model', 'Structural Analysis Model Information Extraction']",국문 초록 정보 없음,다국어 초록 정보 없음
항목의 순서와 부가 정보를 반영한 BERT 기반의 순차적 추천 시스템,2023,[],국문 초록 정보 없음,다국어 초록 정보 없음
Quantization 및 Kernel Fusion 을 적용한 BERT 모델 분석,2023,[],국문 초록 정보 없음,다국어 초록 정보 없음
우크라이나 전쟁 보도에서 일화-주제 프레임이 뉴스 평가와 참여에 미치는 영향 - BERT 기반 프레임 자동 분류기의 개발과 적용 -,2023,[],국문 초록 정보 없음,다국어 초록 정보 없음
Sentence-BERT 기반 음식 및 식재료 임베딩 및 클러스터링을 활용한 음식 다양성 추천 시스템,2023,[],국문 초록 정보 없음,다국어 초록 정보 없음
소셜 빅데이터 분석에서 지도 학습을 이용한 노이즈 리뷰 필터링,2023,"['Social big data', 'Noise review filtering', 'Supervised learning', 'LSTM', 'BERT', '소셜 빅데이터', '노이즈 리뷰 필터링', '지도 학습', 'LSTM', 'BERT']","검색 API를 통해 수집된 소셜 리뷰에는 주어진 검색어와 상관없는 리뷰가 다수 포함되어 있을수 있으며, 이들 리뷰는 왜곡된 분석 결과를 초래할 수 있어 노이즈 리뷰로 지칭된다. 본 논문에서는 노이즈 리뷰를 효과적으로 필터링하기 위한 지도 학습 알고리즘들을 소개하고, 실험을 통해 이들의 성능을 비교한다. 실험에는 울산광역시의 관광지를 대상으로 수집된 2만여 개의 리뷰가 이용되었으며, 학습 알고리즘으로는 텍스트 처리에 높은 정확도를 제공하는 것으로 알려진 LSTM과BERT를 이용하였다. 실험 결과, BERT의 정확도가 LSTM에 비해 우수했으며, 두 알고리즘의 f1-스코어는 각각 90.1%와 95.2%로 조사되었다. 반면, 실행시간 측면에서는 LSTM이 BERT에 비해 5배정도 빠른 성능을 제공하였다. 따라서 노이즈 리뷰 필터링 문제에 있어 정확도가 중요한 경우BERT가, 성능이 중요하거나 컴퓨팅 자원이 부족한 경우는 LSTM이 보다 적절하게 이용될 수 있다.","Social reviews collected through the search API may include a large number of reviews unrelated to a given search term, and these reviews are referred to as noise reviews because they may lead to distorted analysis results. In this paper, we discuss supervised learning algorithms to conduct filtering of the noise reviews efficiently, and compare their performance through experiments. About 20,000 reviews collected for tourist attractions in the Ulsan metropolitan city were used for the experiments, and LSTM and BERT, which are known to provide high accuracy in text processing, were adopted for training and testing the reviews. As a result, BERT provided better accuracy than LSTM, where f1-scores of the two algorithms were 90.1% and 95.2%, respectively. On the other hand, in terms of execution time, LSTM was about 5 times faster than BERT. The result shows that, in the noise review filtering, BERT can be used more properly when accuracy is important, whereas LSTM can be used more properly when performance is important or computation resources are insufficient."
한글 텍스트 감정 이진 분류 모델 생성을 위한 미세 조정과 전이학습에 관한 연구,2023,"['트랜스포머', '사전 학습된 버트', '미세조정', '전이학습', '한글 문장 감정분류', 'Transformer', 'pre-trained BERT', 'fine-tuning', 'transfer learning', 'Korean text sentiment classification']","근래에 트랜스포머(Transformer) 구조를 기초로 하는 ChatGPT와 같은 생성모델이 크게 주목받고 있다. 트랜스포머는 다양한 신경망 모델에 응용되는데, 구글의 BERT(bidirectional encoder representations from Transformers) 문장생성 모델에도 사용된다. 본 논문에서는, 한글로 작성된 영화 리뷰에 대한 댓글이 긍정적인지 부정적인지를 판단하는 텍스트 이진 분류모델을 생성하기 위해서, 사전 학습되어 공개된 BERT 다국어 문장생성 모델을 미세조정(fine tuning)한 후, 새로운 한국어 학습 데이터셋을 사용하여 전이학습(transfer learning) 시키는 방법을 제안한다. 이를 위해서 104개 언어, 12개 레이어, 768개 hidden과 12개의 집중(attention) 헤드 수, 110M 개의 파라미터를 사용하여 사전 학습된 BERT-Base 다국어 문장생성 모델을 사용했다. 영화 댓글을 긍정 또는 부정 분류하는 모델로 변경하기 위해, 사전 학습된 BERT-Base 모델의 입력 레이어와 출력 레이어를 미세 조정한 결과, 178M개의 파라미터를 가지는 새로운 모델이 생성되었다. 미세 조정된 모델에 입력되는 단어의 최대 개수 128, batch_size 16, 학습 횟수 5회로 설정하고, 10,000건의 학습 데이터셋과 5,000건의 테스트 데이터셋을 사용하여 전이 학습시킨 결과, 정확도 0.9582, 손실 0.1177, F1 점수 0.81인 문장 감정 이진 분류모델이 생성되었다. 데이터셋을 5배 늘려서 전이 학습시킨 결과, 정확도 0.9562, 손실 0.1202, F1 점수 0.86인 모델을 얻었다.","Recently, generative models based on the Transformer architecture, such as ChatGPT, have been gaining significant attention. The Transformer architecture has been applied to various neural network models, including Google's BERT(Bidirectional Encoder Representations from Transformers) sentence generation model. In this paper, a method is proposed to create a text binary classification model for determining whether a comment on Korean movie review is positive or negative. To accomplish this, a pre-trained multilingual BERT sentence generation model is fine-tuned and transfer learned using a new Korean training dataset. To achieve this, a pre-trained BERT-Base model for multilingual sentence generation with 104 languages, 12 layers, 768 hidden, 12 attention heads, and 110M parameters is used. To change the pre-trained BERT-Base model into a text classification model, the input and output layers were fine-tuned, resulting in the creation of a new model with 178 million parameters. Using the fine-tuned model, with a maximum word count of 128, a batch size of 16, and 5 epochs, transfer learning is conducted with 10,000 training data and 5,000 testing data. A text sentiment binary classification model for Korean movie review with an accuracy of 0.9582, a loss of 0.1177, and an F1 score of 0.81 has been created. As a result of performing transfer learning with a dataset five times larger, a model with an accuracy of 0.9562, a loss of 0.1202, and an F1 score of 0.86 has been generated."
Investigation and Analysis of AI Language Models for the Development of the Nuclear Export and Import Control Associated Search System,2023,"['Nuclear export', 'Nuclear import', 'Associated search system', 'Language model', 'NEPS']",국문 초록 정보 없음,"The Nuclear Export and Import Control System (NEPS) is currently in operation for nuclear export and import control. To ensure consistent and efficient control, various computational systems are either already in place or being developed. With numerous scattered systems, it becomes crucial to integrate the databases from each to maximize their utility. In order to effectively utilize these scattered computer systems, it is necessary to integrate the databases of each system and develop an associated search system that can be used for integrated databases, so we investigated and analyzed the AI language model that can be applied to the associated search system. Language Models (LM) are primarily divided into two categories: understanding and generative. Understanding Language Models aim to precisely comprehend and analyze the provided text’s meaning. They consider the text’s bidirectional context to understand its deeper implications and are used in tasks such as text classification, sentiment analysis, question answering, and named entity recognition. In contrast, Generative Language Models focus on generating new text based on the given context. They produce new textual content continuously and are beneficial for text generation, machine translation, sentence completion, and storytelling. Given that the primary purpose of our associated search system is to comprehend user sentences or queries accurately, understanding language models are deemed more suitable. Among the understanding language models, we examined BERT and its derivatives, RoBERTa and DeBERTa. BERT (Bidirectional Encoder Representations from Transformers) uses a Bidirectional Transformer Encoder to understand the sentence context and engages in pre-training by predicting ‘MASKED’ segments. RoBERTa (A Robustly Optimized BERT Pre-training Approach) enhances BERT by optimizing its training methods and data processing. Although its core architecture is similar to BERT, it incorporates improvements such as eliminating the NSP (Next Sentence Prediction) task, introducing dynamic masking techniques, and refining training data volume, methodologies, and hyperparameters. DeBERTa (Decoding-enhanced BERT with disentangled attention) introduces a disentangled attention mechanism to the BERT architecture, calculating the relative importance score between word pairs to distribute attention more effectively and improve performance. In analyzing the three models, RoBERTa and DeBERTa demonstrated superior performance compared to BERT. However, considering factors like the acquisition and processing of training data, training time, and associated costs, these superior models may require additional efforts and resources. It’s therefore crucial to select a language model by evaluating the economic implications, objectives, training strategies, performance-assessing datasets, and hardware environments. Additionally, it was noted that by fine-tuning with methods from RoBERTa or DeBERTa based on pre-trained BERT models, the training speed could be significantly improved."
AI를 활용한 비정형 문서정보의 공간정보화,2023,"['비공간 데이터', 'BERT', '공간정보', '자연어 처리', '개체명 인식', 'Non-Spatial data', 'BERT', 'Spatial Information', 'Natural Language Processing', 'Named Entity Recognition']","도시현상의 해석을 위해 공간정보는 필수적이다. 위치정보가 부족한 도시정보를 공간정보로 변환하기 위한 공간정보화 방법론이 꾸준히 개발되어왔다. 정형화된 주소정보나 지명 등을 이용한 Geocoding이나 이미 위치정보가 있는 공간정보와의 공간결합, 참조데이터를 활용한 수작업 형태 등이 대표적이다. 그러나 아직도 행정기관에서 작성되는 수많은 문서정보들은 비정형화된 문서형태로 인해 공간정보화의 수요가 있음에도 그동안 깊이 있게 다루어지지 못하였다. 본 연구는 자연어 처리 모델인 BERT를 활용하여 도시계획과 관련된 공개문서의 공간정보화를 진행한다. 주소가 포함된 문장 요소를 문서로부터 추출하고, 이를 정형화된 데이터로 변환하는 과정을 중점적으로 다룬다. 18년 동안의 도시계획 고시공고문을 학습 데이터로 사용하여 BERT 모델을 학습시켰으며, 모델의 하이퍼파라미터를 직접 조정하여 성능을 향상시켰다. 모델 학습 후의 테스트 결과, 도시계획시설의 유형을 분류하는 모델은 96.6%, 주소 인식 모델은 98.5%, 주소 정제 모델은 93.1%의 정확도를 보였다. 결과 데이터를 GIS 상에 맵핑하였을 때, 특정 지점의 도시계획시설에 관한 변경 이력을 효과적으로 표출할 수 있었다. 본 연구로 도시계획 문서의 공간적 맥락에 대한 깊은 이해를 제공하며, 이를 통해 이해관계자들이 더욱 효과적인 의사결정을 할 수 있게 지원하기를 기대한다.","Spatial information is essential for interpreting urban phenomena. Methodologies for spatializing urban information, especially when it lacks location details, have been consistently developed. Typical methods include Geocoding using structured address information or place names, spatial integration with existing geospatial data, and manual tasks utilizing reference data. However, a vast number of documents produced by administrative agencies have not been deeply dealt with due to their unstructured nature, even when there's demand for spatialization. This research utilizes the natural language processing model BERT to spatialize public documents related to urban planning. It focuses on extracting sentence elements containing addresses from documents and converting them into structured data. The study used 18 years of urban planning public announcement documents as training data to train the BERT model and enhanced its performance by manually adjusting its hyperparameters. After training, the test results showed accuracy rates of 96.6% for classifying urban planning facilities, 98.5% for address recognition, and 93.1% for address cleaning. When mapping the result data on GIS, it was possible to effectively display the change history related to specific urban planning facilities. This research provides a deep understanding of the spatial context of urban planning documents, and it is hoped that through this, stakeholders can make more effective decisions."
정치인의 바른 언어 사용 평가를 위한 연구 : 상임위원회 회의록 중심의 공론장 발언 평가 측정 방법의 개발,2023,"['정치인', '바른 언어', '상임위원회', '회의록', '품위어', 'BERT', 'Politician', 'Proper Language', 'Standing Committee', 'Speech', 'Minutes', 'BERT']","본 연구는 국회의원으로 대변되는 정치인의 바른 언어 사용을 평가 측정하는 방법을 개발하여 공유하는 연구이다. 개발한 방법은 상임위원회 회의록을 중심으로 국회의원의 바른 언어 사용을 평가에 활용되었고, 본 논문은 바른 정치 언어 확산을 위한 정치인의 발화 분석 방법의 설명서(매뉴얼) 성격을 지닌다. 정치인의 바른 언어 사용을 평가하는 객관적인 기준이 부재한 상황에서 본 연구는 품격있는 언어 사용을 평가하는 긍정 품위어 평가 방법과 비속어, 막말 등 좋지 않은 부정 발화 평가 방법을 결합하는 방식을 개발하였다. 실제 분석에서는 부정 발화 평가 방법을 먼저 적용하고, 이후 긍정 발화 평가에 기반한 순위 리스트를 만드는 방식으로 진행했다. 부정 발화 분석은 국립국어원의 표준대백과사전에 기반하여 비속어 용례를 국회의원들의 발언 속에서 찾아보는 단어 기반 평가에서 시작하여, 텍스트 마이닝 빅데이터 분석을 통해서 실제로 발언된 단어 색인화 분석, 연구진의 무작위 추출 검토 및 뉴스와 유튜브 검색, BERT라 불리는 딥러닝 자연어 처리 기법을 순차적으로 수행하여 문장에서 문단에 이르기까지 발언 내용이 가지는 맥락을 파악하는 방식을 동원하였다. 긍정 발화 분석은 구절 수준에서 가장 많이 발화된 표현을 찾고, 품위성과 소통성에 해당하는 ‘예의와 존중’, ‘당부’, ‘의견질의’, ‘사실확인’, ‘진술문 형식’의 5개 영역의 16개의 표현을 통해 평가하였다. 마지막으로 발화 빈도와 함께 품위어 발화 가중치로 계산하여 각 정치인의 바른 언어 사용을 순위화하는 절차를 만들었다. 이러한 연구 절차를 통해 도출된 측정 방법은 정치인의 바른 언어 사용의 문화가 확산되는데 기여할 것으로 생각된다.","The primary objective of this study is to devise and disseminate a methodology for assessing and quantifying the employment of civil language by politicians, specifically focusing on members of the National Assembly. This study examines the utilization of civil language by members during standing committee meetings, with a specific focus on the minutes. The objective is to analyze politicians’ speeches and utilize the findings to encourage the adoption of civil political language in public discourse. This study presents a novel approach that integrates the assessment of positive and respectful language with the evaluation of negative speech, encompassing the use of profanity and impolite comments. This approach was produced after thorough theoretical deliberations. The initial phase of the investigation was the implementation of the negative speech evaluation approach, which was subsequently followed by the development of a hierarchical list based on positive speech assessment. The initial phase of the negative speech analysis involved employing a methodology to assess the utilization of profanity in the politicians’ statements. This methodology was derived from the Standard Encyclopedia Dictionary published by the National Institute of Korean Language. Subsequently, the analysis progressed by employing text mining techniques to index the precise verbal expressions used. Additionally, the researchers conducted a random sampling review and conducted searches on news articles and YouTube to further augment the analysis. Furthermore, a contextual approach was utilized in the study, employing deep learning natural language processing algorithms, specifically BERT, to effectively comprehend the contextual nuances of the speech, ranging from individual sentences to entire paragraphs. The analysis of positive speech entailed identifying the most commonly used phrases and assessing them based on 16 expressions across five theoretical dimensions related to dignity and communicability. These dimensions include ‘courtesy and respect’, ‘advice’, ‘opinion inquiry’, ‘fact verification’‘ and ‘statement format’. The ultimate ranking was determined by considering both the frequency of speech and the weighted value assigned to dignified discourse. This study is anticipated to provide a valuable contribution towards the advancement of methodologies for assessing the utilization of civil language by politicians and the dissemination of a culture that promotes civil language use."
데이터가 부족한 플레이스를 대상으로 한 노이즈 리뷰 필터링 정확도 향상,2023,"['Social review', 'Noise review filtering', 'Group learning', 'LSTM', 'BERT', '소셜 리뷰', '노이즈 리뷰 필터링', '그룹 학습']","소셜 리뷰를 수집하는 과정에서 주어진 검색어와 상관없는 노이즈 리뷰가 검색 결과에 다수 포함될 수 있으며, 이들을 필터링하기 위해 기계 학습이 이용될 수 있다. 그러나 분석하고자 하는 대상의 리뷰 수가 부족한 경우, 학습 데이터 부족으로 인한 정확도 저하 문제가 발생할 수 있다. 본 논문에서는 리뷰 수가 부족한 플레이스를 대상으로 노이즈 리뷰 필터링의 정확도를 높이기 위한 지도 학습 방법을 소개한다. 제안 방법에서는 개별 플레이스 단위로 학습을 수행하지 않고, 특성이 유사한 여러 플레이스를 그룹으로 묶어 학습을 수행한다. 학습을 통해 얻은 분류기는 그룹에 속한 임의의 플레이스에 공통으로 적용함으로써 학습 데이터 부족 문제를 해결하고자 하였다. 제안 방법의 검증을 위해, LSTM과 BERT를 이용하여 노이즈 리뷰 필터링 모델을 구현하고, 온라인에서 수집된 실제 데이터를 활용한 실험을 통해 필터링 정확도를 체크하였다. 실험 결과, 제안 방법의 정확도는 평균 92.4% 수준이었으며, 리뷰 수가 100개 미만인 플레이스를 대상으로 할 경우 87.5%의 정확도를 제공하였다.","In the process of collecting social reviews, a number of noise reviews irrelevant to a given search keyword can be included in the search results. To filter out such reviews, machine learning can be used. However, if the number of reviews is insufficient for a target place to be analyzed, filtering accuracy can be degraded due to the lack of training data. To resolve this issue, we propose a supervised learning method to improve accuracy of the noise review filtering for the places with insufficient reviews. In the proposed method, training is not performed by an individual place, but by a group including several places with similar characteristics. The classifier obtained through the training can be used for the noise review filtering of an arbitrary place belonging to the group, so the problem of insufficient training data can be resolved. To verify the proposed method, a noise review filtering model was implemented using LSTM and BERT, and filtering accuracy was checked through experiments using real data collected online. The experimental results show that the accuracy of the proposed method was 92.4% on the average, and it provided 87.5% accuracy when targeting places with less than 100 reviews."
기초 언어자원을 활용한 군집화된 의미 레이블의 품질 향상,2023,"['단어 의미 모호성 해소', '의미 레이블', '군집화', '희소 데이터', 'Word Sense Disambiguation', 'Sense Label', 'Clustering', 'Sparse Data', 'BERT']","지도학습 기반의 단어 의미 모호성 해소 연구에서는 사전이나 시소러스 등을 활용하여 희소 데이터 문제를 효과적으로 처리하고 있다. 이 중에서, 군집화된 의미 레이블을 시퀀스 레이블링 기반 모델에 사용하는 방법이 높은 성능과 빠른 처리속도를 보였다. 본 연구에서는, 시소러스 등의 언어자원보다 비교적 쉽게 구할 수 있는 기초 언어자원을 사용해 군집화된 의미 레이블의 품질을 개선하는 방법을 제안한다. 이를 위해, 어휘의 의미 분류를 군집 초기화에 사용하고, 원시문장 말뭉치를 사용해 벡터의 품질을 향상시켰다. 이 개선된 의미 레이블을 BERT 기반 단어 의미 모호성 해소 모델에 적용하여 성능을 평가했다. 실험 결과, 제안 방법을 사용한 모델은 F1 70.6%의 성능을 보여 제안 방법을 사용하지 않은 기존 모델의 F1 69.1% 보다 높은 성능을 보였다. 따라서, 기초 언어자원을 추가로 사용하여 군집화된 의미 레이블의 품질을 향상시킬 수 있음을 보였다.","In word sense disambiguation(WSD), supervised learning methods have been complemented by using thesaurus or dictionary to process sparse data effectively. In particular, high evaluation score and fast processing speed are attained by using clustered sense labels for WSD model. This study proposes a method to improve further the quality of clustered sense labels by using basic language resources instead of other costly language resources such as thesaurus. The method uses the category of lexical senses to initialize the sense label clusters more appropriately, and uses the context information of raw texts to improve the quality of sense vectors for clustering. We made clustered sense labels using proposed method and applied them to BERT-based WSD model. As a result of experiment, it showed that the performance of our model is F1 70.6%, which is higher than F1 69.1% the one of the existing model not using our method. Therefore, it showed that the quality of clustered sense labels can be improved by using basic language resources."
Online Unstructured Data Analysis Models with KoBERT and Word2vec: A Study on Sentiment Analysis of Public Opinion in Korean,2023,"['KoBERT', 'Word2vec', 'Public opinion analysis', 'Sentiment classification']",국문 초록 정보 없음,"Online news articles and comments play a vital role in shaping public opinion. Numerous studies have conducted online opinion analyses using these as raw data. Bidirectional encoder representations from transformer (BERT)-based sentiment analysis of public opinion have recently attracted significant attention. However, owing to its limited linguistic versatility and low accuracy in domains with insufficient learning data, the application of BERT to Korean is challenging. Conventional public opinion analysis focuses on term frequency; hence, low-frequency words are likely to be excluded because their importance is underestimated. This study aimed to address these issues and facilitate the analysis of public opinion regarding Korean news articles and comments. We propose a method for analyzing public opinion using word2vec to increase the word-frequency-centered analytical limit in conjunction withKoBERT, which is optimized for Korean language by improving BERT. Naver news articles and comments were analyzed using a sentiment classification model developed on the KoBERT framework. The experiment demonstrated a sentiment classification accuracy of over 90%. Thus, it yields faster and more precise results than conventional methods. Words with a low frequency of occurrence, but high relevance, can be identified using word2vec."
Reasoning Ability of Deep Learning Models on Tautological Expressions in Korean,2023,"['tautological expression', 'abductive reasoning', 'implicature', 'artificial intelligene', 'BERT', 'Chat-GPT', '항진적 표현', '가추적 추론', '함축', '인공지능', '버트', '챗GPT']",국문 초록 정보 없음,"The purpose of this paper is to evaluate the abductive reasoning capability of deep learning-based language models, with a specific focus on their ability to infer the meaning of tautological expressions. To achieve this, we conducted two experiments that required language models to understand the meaning of tautological expressions in different contexts. The first experiment was a binary classification task in which the models were presented with preceding sentences as contexts along with a tautological expression, and evaluated the adequacy of the tautological sentence. We employed three BERT-based models and assessed their capability based on the results of human evaluation. The second experiment involved having ChatGPT generate a coherent sentence that followed the preceding sentence and tautological expression. We categorized certain types of errors from the generated sentences that were deemed inappropriate. This study is significant in revealing the limitations of contemporary deep learning-based language models in terms of abductive reasoning and suggests a new task for standardized model evaluation."
자연어처리 기계학습 기법을 이용한 공시문서의 자동분류: Confidential treatment를 가진 8-K 문서를 중심으로,2023,"['Natural Language Processing', 'Machine Learning', 'Document Classification', 'Form 8-K', 'Confidential Treatment', '자연어처리', '기계학습', '문서판별', '8-K양식', '비밀처리']","기업에 대한 방대한 정보를 제공하는 공시자료는 기업간 거래 및 투자 결정에 있어 필수적인 정보 원천이며 기업 및 산업에 대한 중요 연구자료이다. 본 논문에서는 기계학습에 기반한 자연어처리 기법을 활용하여 공시자료의 분류를 자동화하는 방법에 대해 다룬다. 특히 비밀처리(confidential treatment, CT)를 가지는 미국 수시공시 회계문서 8-K 양식의 자동판별을 위한 자연어처리(natural language processing, NLP) 기계학습 모델을 제안한다. CT란 경쟁우위의 저하를 유발할 수 있는 배타적 정보를 공시자료에서 비공개 하도록 허용하는 제도를 말한다. 문서의 분류를 위해 의사결정나무 기반의 XGBoost 모형과 인공신경망 기반의 EmbedMixed, BERT 모형을 비교하였다. 그 결과 가장 우수한 성능을 보인 모형은 XGBoost 모형으로 재현율과 정밀도가 80%～90% 사이에서 서로 상쇄하는 수준을 보였다. 본 모델을 통해 비밀처리 문서 탐색의 효율성을 크게 높일 수 있으며 다른 유형의 공시문서 분류에도 유사한 접근법을 적용해 볼 수 있을 것으로 기대한다.","Mandatory SEC filings provide crucial information to investors and other stakeholders, offering detailed financial statements and insights into a company's financial condition and material events. These filings also serve as valuable research data for firms and industries. This study investigates the application of machine learning techniques, specifically natural language processing, to automate the classification of disclosure documents. The primary focus is on developing a model for effectively filtering Form 8-Ks that request Confidential treatment (CT), enabling firms to redact proprietary information from mandatory filing forms. The paper compares the performance of a decision tree-based model (XGBoost) with two artificial neural network-based models, EmbedMixed and BERT. The results indicate that the XGBoost model outperforms the others, achieving a balanced trade-off between recall and precision of approximately 80-90%. The proposed model significantly enhances the efficiency of classifying CTs and holds potential for application to other types of SEC filing documents."
딥러닝(Deep Learning)모델을 활용한 범죄사실 구성요소 자동 추출 방안 연구,2023,"['Deep Learning', 'Natural Language Processing', 'Crime Facts', 'Key Information', 'Information Extraction.', '딥러닝', '자연어처리', '범죄사실', '구성요건', '정보추출']","2021년 검경수사권 조정에 따라 경찰기관은 독립성을 확보하였고, 이에 따라 경찰은 국민의 신뢰를 확보하기 위해 국가수사본부 신설 등 수사 전문성을 강화시키고 투명성을 제고시키는 데 노력을 기울이고 있다. 한편, 최근 법률 분야에 AI가 도입되면서 판결문 검색, 계약서 관리 그리고 법률 문서 번역 등 AI 모델을 통해 많은 도움을 받고 있다. 하지만 수사 문서를 자동으로 분석하고 보고서를 작성해주는 AI 기술은 국내에 없는 거의 실정이다.따라서 본 연구에서는 수사 및 법률 문서에서 주요 정보를 자동으로 추출하여 수사결과보고서 작성에 도움을 줄 수 있는 딥러닝 모델을 개발하고자 한다. 본 연구를 통해 형사 1심 살인 판결문에서 추출할 수 있는 범죄사실 구성요소를 정의하였다. 또한 최근 자연어분야에서 높은 관심을 받고 있는 GPT-3.5 API의 한계점을 살펴보았고 이를 보완한 BERT 기반 모델을 개발하였다. 또한 개발된 모델을 사용하여 범죄사실에서 단어 단위의 정보와 구절 단위의 정보를 17개 추출하였다.그 결과, 단어 단위 정보는 F1-score 83.85%, 구절 단위 정보는 F1-score 64.2%의 성능을 내었다. 결과 분석을 통해 성능을 향상 시킬 수 있는 방안을 모색하였다. 본 연구에서 개발된 AI 모델을 수사 환경에 적용하면 수사결과보고서 작성을 지원하고, 유사 판례를 검색하는 등 수사관이 투명하고 객관적인 수사를 할 수 있도록 도와줄 수 있을 것이다. 또한 본 연구의 결과가 딥러닝 모델이 법률 분야에서 발전할 수 있는 기반이 될 수 있을 것을 기대한다.","In accordance with the adjustment of investigative and prosecutorial powers in 2021, police agencies have been working to enhance their independence, while also aiming to secure the public's trust through initiatives such as the establishment of a National Investigation Headquarters. These efforts are geared towards reinforcing the investigative expertise and improving transparency. Meanwhile, with the recent integration of AI in legal domain, AI models have provided significant assistance in tasks like searching for legal judgments, managing contracts, and translating legal documents. However, there is no AI technology available to automatically analyze investigation documents and generate reports. Therefore, the purpose of this study is to develop a deep learning model that can automatically extract key information from crime investigation and legal documents, aiming to assist in generating investigation reports. Through this study, we defined key informations related to crime facts that can be automatically extracted from the Court Decision of murder case. We also examined the limitations of GPT-3.5 and developed a BERT-based model to address these limitations. Additionally, the developed model was utilized to extract 17 information, both at the word and phrase levels, from crime facts.As a result, the word-level information achieved a performance of F1-score 83.85%, while the phrase-level information achieved a performance of F1-score 64.2%. If the AI model developed in this study is applied in the investigative environment, it would enable to generate investigation reports and enable the search for similar legal precedents. This could assist investigators in conducting transparent and objective investigations."
인공지능 기술의 정치학적 적용에 대한 연구 - 온라인 여론 측정 방법을 중심으로,2023,"['인공지능', '감성분석', '여론', '연구방법', 'Artificial Intelligence', 'public opinion', 'sentiment analysis', 'research methods']","세계가 인공지능 기술에 집중하고 있다. 미래에 적응하고 리드하기 위해 다양한 산업에서 인공지능 기술을 적용하기 위해 노력하고 있다. IT 기술과 인터넷의 발전은 사람들의 삶을 크게 바꿔 놓았다. 사람들이 온라인 공간에 남기는 매일의 디지털 흔적을 활용하기 위한 노력은 여전히 부족하다. 이는 온라인에 존재하는 엄청난 양의 데이터를 다루기 위해서는 많은 리소스와 기술을 요구하기 때문이다. 본 연구는 여론 측정 방식에 있어 방법의 변화를 설명하고 인공지능과 같은 신기술의 적용으로 인해 발생할 수 있는 문제를 설명한다. 여론은 정치학에서 매우 중요한 주제이다. 연구자들은 서베이를 통해 여론을 측정하였고 인공지능을 활용한 방법을 탐구하기 시작했다. 오피니언 마이닝 방법 중 하나인 감성분석방법을 통해 텍스트에서 감성을 추출할 수 있다. 이전에는 감성사전을 활용해 감성분석을 수행했고 최근에는 BERT와 같이 훈련된 인공지능을 활용한 감성분석 방법을 활용한다. 하지만, 인공지능을 활용함에 있어 여러 어려움이 존재한다. 온라인 상의 텍스트는 일반적인 형태가 아닌 독특한 모습을 띄기 때문에 이를 고려한 학습이 이루어져야 하고 적용 가능한 데이터셋을 만들기 위해서는 큰 비용을 지불해야한다. 현재는 텍스트 데이터만을 활용하지만 온라인 상에는 이미지 및 비디오와 같은 형태의 데이터도 존재한다. 이와 더불어 인공지능 모델에 대한 분석이 어렵다. 모델은 입력한 데이터를 통해 스스로 알고리즘을 학습하고, 이러한 과정을 연구자가 세부적으로 분석할 수 없다. 학습을 수행하기 위해서는 높은 연산능력을 보유한 컴퓨터 장비가 필요하고 이는 일반 연구자에게 큰 장애물로 존재할 수 있다. 하지만 인공지능은 이미 우리에 삶에 크게 들어와 있다. 정치현상에 대한 보다 깊은 이해를 위해 연구자들은 인공지능 기술의 적용을 위해 적극적으로 노력해야 한다.","Artificial intelligence has become a critical issue across the world.  Various industries attempt to incorporate technology to adapt and lead the future.  People’s daily life has changed dramatically as information technology and the internet advance.  There is digital evidence of people left untouched in cyberspace because collecting and utilizing the data require specific resources and techniques.  This article explains how measuring public opinion has changed and identifies possible difficulties in incorporating emerging technology.  Public opinion is a crucial subject in political science.  Researchers use a survey to measure public opinion and seek to utilize new technology like artificial intelligence.  Sentiment analysis is a type of opinion mining that extracts attitudes from texts.  Previously the analysis used frequency based on a dictionary and, in recent days, utilizes artificial intelligence and pre-trained models like BERT.   Online public opinion can be measured through this analytical technique.  However, there are difficulties to handle when researchers use artificial intelligence.  The styles of online texts are unique.  It is expensive to build a dataset for training artificial intelligence.  There are many other formats of data available besides texts.    In addition, the application of artificial intelligence poses challenges.  It does not allow researchers to understand an algorithm as they do not provide a model like a typical statistical analysis.  It also requires significant computing power, which can be unavailable to individual researchers.  Nevertheless, artificial intelligence is already a part of our everyday life.  It is left to political scientists to utilize the technique to gain deeper insight into political phenomena."
Design and Implementation of AI Recommendation Platform for Commercial Services,2023,"['Recommendation Platform', 'DNN', 'RNN', 'GRU4Rec BERT4Rec', 'GPT4Rec']",국문 초록 정보 없음,"In this paper, we discuss the design and implementation of a recommendation platform actually built in the field. We survey deep learning-based recommendation models that are effective in reflecting individual user characteristics. The recently proposed RNN-based sequential recommendation models reflect individual user characteristics well. The recommendation platform we proposed has an architecture that can collect, store, and process big data from a company's commercial services. Our recommendation platform provides service providers with intuitive tools to evaluate and apply timely optimized recommendation models. In the model evaluation we performed, RNN-based sequential recommendation models showed high scores."
감성 분석을 위한 FinBERT 미세 조정: 데이터 세트와 하이퍼파라미터의 효과성 탐구,2023,"['FinBERT', 'Financial Sentiment Analysis', 'Fine-Tuning hyperparameters', 'FinBERT', '금융 분야 감성 분석', '하이퍼파라미터 미세 조정']",국문 초록 정보 없음,"This research paper explores the application of FinBERT, a variational BERT-based model pre-trained on financial domain, for sentiment analysis in the financial domain while focusing on the process of identifying suitable training data and hyperparameters. Our goal is to offer a comprehensive guide on effectively utilizing the FinBERT model for accurate sentiment analysis by employing various datasets and fine-tuning hyperparameters. We outline the architecture and workflow of the proposed approach for fine-tuning the FinBERT model in this study, emphasizing the performance of various datasets and hyperparameters for sentiment analysis tasks.Additionally, we verify the reliability of GPT-3 as a suitable annotator by using it for sentiment labeling tasks. Our results show that the fine-tuned FinBERT model excels across a range of datasets and that the optimal combination is a learning rate of 5e-5 and a batch size of 64, which perform consistently well across all datasets. Furthermore, based on the significant performance improvement of the FinBERT model with our Twitter data in general domain compared to our news data in general domain, we also express uncertainty about the model being further pre-trained only on financial news data. We simplify the complex process of determining the optimal approach to the FinBERT model and provide guidelines for selecting additional training datasets and hyperparameters within the fine-tuning process of financial sentiment analysis models."
생의학 분야 키워드 추출 모델에 대한 비교 연구,2023,"['Keyword Extraction', 'NLP', 'DeepLearning', 'Biomedicine', '키워드 추출', '자연어처리', '딥러닝', '생의학']",국문 초록 정보 없음,"Given the growing volume of biomedical papers, the ability to efficiently extract keywords has become crucial for accessing and responding to important information in the literature. In this study, we conduct a comprehensive evaluation of different unsupervised learning-based models and BERT-based models for keyword extraction in the biomedical field. Our experimental findings reveal that the BioBERT model, trained on biomedical-specific data, achieves the highest performance. This study offers precise and dependable insights to guide forthcoming research in biomedical keyword extraction. By establishing a well-suited experimental framework and conducting thorough comparisons and analyses of diverse models, we have furnished essential information. Furthermore, we anticipate extending our contributions to other domains by providing comparative experiments and practical guidelines for effective keyword extraction."
EDAD: 도메인 적응과 지식 증류를 통합한 효율적 도메인 적응 증류,2023,"['Named Entity Recognition', 'Natural Language Processing', 'Domain Adaptation', 'Knowledge Distillation']",국문 초록 정보 없음,"In the field of natural language processing, a lot of progress has been made with the advent of Transformer having a self-attention mechanism. At the same time, the recently increasing model size causes difficulties in deploying the model for online serving that requires fast inference. To address this issue, one can employ model compression techniques when a target domain is coherent with the training corpus (i.e., a general domain) of pre-trained models such as BERT. However, the additional domain adaptation step is required along with model compression when we leverage such pre-trained models for special target domains such as medicine, law, finance, etc. In this paper, we propose an Efficient Domain Adaptive Distillation (EDAD) method to efficiently create a lightweight model capable of fast inference for a target domain by integrating knowledge distillation, which is one of the popular model compression methods, and domain adaptation processes. Experimental results demonstrate that EDAD can train a compact model for a target domain with much lower computational costs by integrating the two individual processes, adaptation and compression, into a single process and shows comparable performance with existing methods for named entity recognition (NER) tasks in the medical domain."
치과적 정의에 대한 고찰: 뉴스 댓글 빅데이터 분석을 중심으로,2023,"['Dental Overtreatment', 'Big Data Analysis', 'Network Analysis', 'Topic Modeling', 'Deep Learning', 'Medical Justice']",국문 초록 정보 없음,"Purpose: To seek a new approach to dental justice, this paper identifies public opinions on dental-related social and ethical issues and reviews countermeasures based on them.Methods: Naver news comments, with search term “dental overtreatment” from 2011 (when articles appear as meaningful numbers) to 2022 (present), collected and analyzed by frequency analysis, word network analysis, topic modeling, and BERT-based sentiment analysis.Results: A total of 483 articles and 26, 601 comments (excluding 9,737 comments that do not include text) were collected and analyzed. Comments were biased toward specific articles and events. Word networks and topic modeling presented complaints about medical reality, criticism for the medical community, and medical expenses. Negative emotions related to the issue were increasing.Discussion: Big data analysis of news comments is a tool that allows researchers to check the flow of public opinion related to issues beyond the examination of individual comments, which is often meaningless. The issue of “dental overtreatment” has not been represented much in the media, but the number of related articles and comments is gradually increasing. As confirmed by the categories of the comments, the response to the issue is not focused solely on medical expenses, however, there is a demand for “proper treatment.” Therefore, based on the recent theoretical discussion on the theory of justice, this study presents a different perspective for ap-proaching the issue in dentistry."
도메인 지식 증류: 도메인 지식 이전을 위한 증류 방법론,2023,[],국문 초록 정보 없음,"In this paper, we propose with a novel knowledge distillation learning methodology that extracts the representation of a pre-trained model in a specific domain and trains it on a model that solves the problem of a specific task. The main motivation of our proposed model is to transfer domain knowledge. We implemented and experimented with the BERT-based method, and expanded the use and universality of pre-trained models by learning additional domains (language, expertise, etc.) that were not included in the pre-training data of the language model."
인과추론을 이용한 공정한 분류기,2023,[],"Transformer 기반 자연어처리 언어모델의 성능이 빠르게 증가함에 따라 공정성에 대한 문제가 제기되었다. 예를 들어 혐오 발언 탐지 모델에서는 인종, 성별 같은 identity term의 영향을 강하게 받아 심각한 편향을 유발한다. 따라서 본 논문에서는 여러 민감한 속성에 대한 Word Confounder dictionary을 만들고 인과적 개입을 통해 identity term에 과적합하는 것을 방지하는 새로운 인과 추론 기반텍스트 분류 프레임 워크(CIT)를 제안한다. 우리는 CIT를 통해 bert를 fine-tuning하고 결과 모델이 benchmark corpora에 대해서 bias metrics한 결과가 다른 주류 접근법과 일치하거나 초과함을 보여준다.",다국어 초록 정보 없음
Multi-GPU 기반 분산 딥러닝을 위한 효율적인 집합 통신 기법 연구,2023,[],국문 초록 정보 없음,"This paper demonstrates a scheme that can efficiently use collective communication, which is mainly used in multi-GPU-based distributed deep learning environments, through experiments in various environments. We propose a novel buckerting function by referring to the Bucketing scheme proposed for efficient communication in the PyTorch DDP (Distributed Data Parallel) module. In addition, we implemented a communication backend that could handle communication requested by PyTorch through NCCL (NVIDIA Collective Communication Library), and evaluated its performance by applying it to an environment consisting of various types of multiple GPUs. The proposed Bucketing scheme we implemented improved performance by up to about 11% compared to PyTorch DDP and up to about 10.8% compared to Horovod when fine-tuning Bert-base-cased models with GLUE MNLI in the same environment."
임상의학 언어이해 성능향상을 위한 Discharge Summary CRPT 모델 연구,2023,"['대조적 표상 사전훈련', '대조 손실', 'BERT-base', 'Contrastive Representation Pre-training', 'Contrastive Loss', 'Clinical BERT']","BERT 모델은 자연어이해 작업에서 높은 성능을 나타냈으며 의생명 분야를 포함한 다양한 도메인에서 적용되고 있는 사전학습 언어모델이다. 임상의학에서 환자의 의료기록과 임상 정보를 정확하게 이해하기 위해서는 전문용어를 포함한 자연어로 구성된 문장들 간의 의미론적 관계를 정확하게 추론하는 것이 매우 중요하다. 그러나 BERT 모델을 임상의학 분야의 대용량 데이터로 사전학습 시키고 문장 수준의 의미 이해 정확도를 향상시키기 위한 연구는 아직 활발하게 이루어지지 않고 있다. 이러한 문제를 해결하기 위해 본 연구에서는 대조적 표상 사전 훈련 방법을 이용해 BERT 모델의 성능을 향상시키는 방법을 제안하고자 한다. 제안된 Discharge Summary CRPT 모델은 퇴원요약 기록으로 BERT 모델을 사전 훈련시키는 과정에서 다음 2가지를 개선하여 의학언어이해 성능을 향상시켰다. 다음 문장 예측 단계의 교차 엔트로피 손실을 대조 손실로 대체함으로써 문장 간 문맥적 의미추론 정확도를 향상시켰다. 또한, 기존 무작위 마스킹을 단어 전체 마스킹 방법으로 개선해 임상의학 텍스트에 대한 자연어이해 성능이 향상되는지 확인하였다. 제안된 모델은 BLUE 벤치마크 데이터셋(MedNLI, BioSSES)으로 검증한 결과 임상의학 텍스트에 대한 자연어추론 정확도(Accuracy = 0.825) 및 문장 유사도(sentence similarity = 0.775)에서 기존 BERT 모델에 비해 성능 향상을 나타냈다.","Recently BERT(Bidirectional Encoder Representation from Transformer) has shown tremendous improvement in performance for various NLP tasks. BERT has been applied to many domains including biomedical field. Especially clinical domain, the semantic relationship between sentences is very important to understand patient’s medical record and health history in physical examination. However, in current Clinical BERT model, the pre-training method is difficult to capture sentence level semantics. To address this problem, we propose a Discharge Summary CRPT(contrastive representations pre-training) model, which can enhance contextual meanings between sentences by replacing cross-entropy loss to contrastive loss in next sentence prediction (NSP) task. Also we tried to improve the performance by changing random masking technique to whole word masking (WWM) for masked language model (MLM). Especially, we focus on enhancing language representations of BERT model by pre-training with Discharge Summaries Notes to optimize in clinical text understanding. We demonstrate that our Discharge Summary CRPT model yields improvements in performance of clinical NLP task with BLUE (Biomedical Language Understanding Evaluation) Benchmark dataset (MedNLI and BioSSES)."
Robust Sentiment Classification of Metaverse Services Using a Pre-trained Language Model with Soft Voting,2023,"['BERT', 'metaverse', 'natural language processing', 'pre-trained language model', 'ubiquitous computing']",국문 초록 정보 없음,"Metaverse services generate text data, data of ubiquitous computing, in real-time to analyze user emotions. Analysis of user emotions is an important task in metaverse services. This study aims to classify user sentiments using deep learning and pre-trained language models based on the transformer structure. Previous studies collected data from a single platform, whereas the current study incorporated the review data as “Metaverse” keyword from the YouTube and Google Play Store platforms for general utilization. As a result, the Bidirectional Encoder Representations from Transformers (BERT) and Robustly optimized BERT approach (RoBERTa) models using the soft voting mechanism achieved a highest accuracy of 88.57%. In addition, the area under the curve (AUC) score of the ensemble model comprising RoBERTa, BERT, and A Lite BERT (ALBERT) was 0.9458. The results demonstrate that the ensemble combined with the RoBERTa model exhibits good performance. Therefore, the RoBERTa model can be applied on platforms that provide metaverse services. The findings contribute to the advancement of natural language processing techniques in metaverse services, which are increasingly important in digital platforms and virtual environments. Overall, this study provides empirical evidence that sentiment analysis using deep learning and pre-trained language models is a promising approach to improving user experiences in metaverse services."
다국어 사용자 후기에 대한 속성기반 감성분석 연구,2023,"['BERT', 'multilingual BERT', 'natural language process', 'transformer  encoder', 'XLM-RoBERTa', 'BERT', '다국어 BERT', '자연어 처리', '트랜스포머 인코더', 'XLM-RoBERTa']","전자상거래 시장의 성장과 더불어 소비자들은 상품 및 서비스 구매 시 다른 사용자가 작성한 후기 정보에 기반하여 구매 의사를 결정하게 되며 이러한 후기를 효과적으로 분석하기 위한 연구가 활발히 이루어지고 있다.특히, 사용자 후기에 대해 단순 긍/부정으로 감성분석하는 것이 아니라 다면적으로 분석하는 속성기반 감성분석 방법이 주목받고 있다.속성기반 감성분석을 위한 다양한 방법론 중 최신 자연어 처리 기술인 트랜스포머 계열 모델을 활용한 분석 방법이 있다.본 논문에서는 최신 자연어 처리 기술 모델에 두 가지 실제 데이터를 활용하여 다국어 사용자 후기에 대한 속성기반 감성분석을 진행하였다.공개된 데이터 셋인 SemEval 2016의 Restaurant 데이터와 실제 화장품 도메인에서 작성된 다국어 사용자 후기 데이터를 활용하여 속성기반 감성분석을 위한 트랜스포머 계열 모델의 성능을 비교하였고 성능 향상을 위한 다양한 방법론도 적용하였다.다국어 데이터를 활용한 모델을 통해 언어별로 별도의 모델을 구축하지 않고 한가지 모델로 다국어를 분석할 수 있다는 점에서 효용 가치가 클 것으로 예상된다.","With the growth of the e-commerce market, consumers increasingly rely on user reviews to make purchasing decisions.Consequently, researchers are actively conducting studies to effectively analyze these reviews.Among the various methods of sentiment analysis, the aspect-based sentiment analysis approach, which examines user reviews from multiple angles rather than solely relying on simple positive or negative sentiments, is gaining widespread attention.Among the various methodologies for aspect-based sentiment analysis, there is an analysis method using a transformer-based model, which is the latest natural language processing technology.In this paper, we conduct an aspect-based sentiment analysis on multilingual user reviews using two real datasets from the latest natural language processing technology model.Specifically, we use restaurant data from the SemEval 2016 public dataset and multilingual user review data from the cosmetic domain.We compare the performance of transformer-based models for aspect-based sentiment analysis and apply various methodologies to improve their performance.Models using multilingual data are  expected to be highly useful in that they can analyze multiple languages in one model without building separate models for each language."
사전학습모델을 활용한 온라인 뉴스 감성이 투자자별 거래강도에 미치는 영향 분석에 관한 연구,2023,"['Online New Sentiment', 'Pre-Trained Model', 'BERT', 'KOPSI', 'Net Buying Amount by Investor Type', 'Trading Intensity', '온라인 뉴스', '온라인 뉴스 감성', '사전학습 모델', 'BERT', 'KOSPI', '투자자별 순매수 대금', '거래강도']","본 연구는 온라인 뉴스 감성이 투자자별 거래강도에 미치는 영향을 분석하여, 투자자별 거래행태의 다름을 실증적으로 검증한다. 투자자별 거래강도를 측정하기 위한 대용변수로 투자자별 순매수 대금을 종속변수로 사용하였다. 독립변수는 온라인 뉴스의 감성을 사용하였다. 온라인 뉴스의 텍스트데이터에 대한 한글 전처리 프로세스를 수행 후 사전학습 모델인 KB-BERT를 활용하여 온라인 뉴스의 감성을 추출하였다. 실증분석 결과 개인은 온라인 뉴스 감성에 기관과 외국인보다 큰 영향을 받음을 확인하였다. 또한, 변동성 지수에 기관과 외국인은 음의 영향을 받았으며, 개인투자자는 양의 영향을 받음을 확인하였다. 이는 기관과 외국인은 시장심리를 객관적으로 활용하였으나, 개인은 시장심리를 역방향으로 활용한 것으로 개인의 역투자 행태를 설명할 수 있다. 연구결과를 통해 개인은 기관과 외국인보다 온라인 뉴스 감성에 큰 영향을 받는 것을 확인하여 개인투자자의 비이성적 행태와 관련한 연구결과를 실증적으로 뒷받침한다.","This study delves into the intricate relationship between online news sentiment and the trading intensity of various types of investors, while empirically investigating the divergent trading behaviors exhibited by these investor groups. To gauge the trading intensity of each investor, the study employs the net purchase price as a proxy variable, which serves as the dependent variable. As the independent variable, the study leverages the emotional content of online news articles. The research methodology encompasses a thorough preprocessing phase for the text data extracted from online news sources in the Korean language. This preprocessing stage is pivotal in ensuring the data's quality and consistency. Subsequently, the study utilizes KB-BERT, a state-of-the-art pre-trained model, to extract sentiment or sensibility from the online news articles. This advanced natural language processing technique enables a nuanced understanding of the emotional content, providing valuable insights into the affective dimension of the news. The findings of this research substantiate that individual investors are more susceptible to the emotional sway of online news than institutional investors and foreign investors. This empirical evidence reinforces existing research outcomes that highlight the irrational behaviors often exhibited by individual investors in response to emotional stimuli from news sources. In essence, the study underscores the pivotal role of online news sentiment in shaping investor decision-making processes and market dynamics, shedding light on the nuanced interplay between information, emotions, and financial markets. These insights contribute to a deeper understanding of market behavior and can inform strategies for more informed and rational investing."
북스캔을 이용한 도서 손상 단계에 따른 딥 러닝 기반 도서 복구 방법에 관한 연구,2023,"['Book Scan', 'OCR', 'BERT', 'Book Damage Levels', 'Book Recovery']",국문 초록 정보 없음,"Recently, with the activation of eBook services, books are being published simultaneously as physical books and digitized eBooks. Paper books are more expensive than e-books due to printing and distribution costs, so demand for relatively inexpensive e-books is increasing. There are cases where previously published physical books cannot be digitized due to the circumstances of the publisher or author, so there is a movement among individual users to digitize books that have been published for a long time. However, existing research has only studied the advancement of the pre-processing process that can improve text recognition before applying OCR technology, and there are limitations to digitization depending on the condition of the book. Therefore, support for book digitization services depending on the condition of the physical book is needed. need. In this paper, we propose a method to support digitalization services according to the status of physical books held by book owners. Create images by scanning books and extract text information from the images through OCR. We propose a method to recover text that cannot be extracted depending on the state of the book using BERT, a natural language processing deep learning model. As a result, it was confirmed that the recovery method using BERT is superior when compared to RNN, which is widely used in recommendation technology."
SBERT 임베딩을 활용한 행렬 분해 추천 방법론,2023,"['recommender system', 'collaborative filtering', 'matrix factorization', 'sentence-bert', '.']","본 논문은 SBERT(Sentence-BERT) 임베딩을 MF(Matrix Factorization)모델에 통합한 영화 추천 방식을 제안한다. 전통적으로 MF 기반 추천 방식은 사용자 아이템 상호 작용 데이터에만 의존하기 때문에 영화의 메타데이터(제목, 장르, 개요 등)를 활용하지 않는다. 본 연구에서는 MF에서의 아이템 잠재 벡터의 표현을 SBERT 임베딩으로 대체하여 의미 정보를 효과적으로 활용할 수 있는 방식을 제안한다. 제안 방식에 대한 정확도 검증을 실제 영화 데이터에 대한 실험을 수행하고 SBERT를 활용한 메타데이터 벡터를 MF 방법에 주입한 모델과 전통적인 MF 모델과 비교한다. 그리고 실험 결과 분석을 통해 제안 방식의 우수성을 입증한다. 본 연구는 아이템의 메타데이터를 대상으로 SBERT 임베딩을 활용하여 협업 필터링 기술의 성능을 향상하는데 새로운 가능성을 제시한다.","We propose a movie recommendation approach that integrates Sentence-BERT(SBERT) embeddings into Matrix Factorization(MF) models. Conventional MF-based recommender systems rely solely on rating data and do not utilize metadata such as titles, genres, or summaries. In this study, we suggest a method to effectively leverage semantic information by replacing item latent vectors in MF with SBERT embeddings. To validate the accuracy for the proposed approach, experiments are conducted on real movie dataset. We also compare the model incorporating metadata vectors generated by SBERT with conventional MF models. Through the analysis of experimental results, the superiority of the proposed approach is demonstrated. This research introduces new possibilities for enhancing the performance of collaborative filtering techniques using SBERT embeddings for item metadata."
KoGPT2를 활용한 P-tuning의 효과적 성능 향상 기법 연구,2023,"['GPT-2', 'P-tuning', 'BERT', 'Transformer', '자연어처리', '인공지능', 'GPT-2', 'P-tuning', 'BERT', 'transformer', 'natural language processing', 'AI']",국문 초록 정보 없음,"Recently, various models of natural language processing using deep learning have been introduced, and transformer-based pre-trained models, such as BERT and GPT, have become the basic models. Fine-tuning transformer-based deep learning models can achieve excellent performance by updating the parameters of the entire model. Meanwhile, the P-tuning method, which can improve performance by updating a small number of parameters, has been introduced. In this study, we propose a method of changing the prompt-encoder from the P-tuning method, which could achieve performance similar to the existing fine-tuning method, even if only a small number of parameters were updated by freezing the learning of the model parameters. KoGPT2 was used as the GPT-2 model for performance verification. As a result of classifying using NSMC and KorNLI datasets, the proposed method showed enhanced performance using NSMC and KorNLI datasets, with an improved accuracy of 4.56% and 11%, respectively, compared to the existing P-tuning method."
Detecting Suicide Notes with the Probability of Positive Sentiment and Interquartile Range,2023,"['suicide notes', 'sentiment analysis', 'BERT', 'probability of positive sentiment', 'IQR']",국문 초록 정보 없음,"This paper proposes a new algorithm for detecting suicide notes using sentiment analysis. As suicides increase nowadays, it is important to detect the suicide signs before the actual suicides are committed. Detecting suicide signs is not so easy, because suicide notes are usually short. This study proposes a modified algorithm of sentiment analysis which is based on the probability of positive sentiments (PPS), not on the categorical classifications. The original BERT model is revised so that the model calculates the PPS values for each sentence. A total of 8 corpora are constructed, among which 4 are the corpora of suicide notes, and the others are novels. For each sentence in the corpora, the PPS values are calculated using the revised BERT model. Then, the distributions of PPSs are statistically analyzed with Interquartile Range (IQR). The suicide notes are distinguished with more than 30 IQR values. In the experiments with the corpora of suicide notes and ordinary texts, the developed method achieves about 86% of accuracy. The proposed algorithm can make use of the sentiment properties of suicide notes, and it is effective not only for large-size corpora but also for small-size suicide notes."
과신성향 경영자의 자사주매입과 시장의 과소반응,2023,"['Stock Repurchase', 'Undervaluation hypothesis', 'Managerial Overconfidence', 'Underreaction', 'BERT', '자사주매입', '저평가 가설', '경영자 과신', '과소반응', 'BERT']",국문 초록 정보 없음,"This study examined the market reaction that occurs when overconfidence managers make the disclosure of stock repurchases. Unlike the market’s positive response at the time of disclosure of stock repurchase based on the undervalued hypothesis, an empirical analysis was conducted on how the market response changes when managerial overconfidence makes a disclosure of stock repurchase. The results of the study are as follows. The market response to the disclosure of stock repurchases was found to positively support the undervalued hypothesis. The higher the manager’s overconfidence, the lower the short-term response at the time of disclosure, the higher the long-term response after disclosure. There are the negative relation between manager’s overconfidence and CAR(-5,+5) and positive relation with BHAR for 12 and 24 months after disclosure.These results showed that the market underestimated the manager’s overconfidence and mis-valuated the disclosure of stock repurchases, but in the long run, the value of overconfidence did not decline or disappear, meaning that the manager does not send false signals or mis-valuate the value of stock repurchases. This study analyzed the manager’s overconfidence measured by textual analysis using BERT, one of the machine learning methods, and compared it with the manager’s overconfidence variable measured by financial information to increase credibility of the overconfidence variable."
국방 IoT의 사이버보안 강화를 위한 침입탐지 모델 제안,2023,"['Intrusion Detection', 'MQTT', 'IoT', 'LDA', 'LightGBM', 'BERT']","IoT 기술은 민간 및 국방 분야에서 매우 광범위하게 활용되고 있다. 특히 국방분야에서는 IoT 기술이 전장에서의 상황인식 개선을 위한 핵심 기반기술로 부각되면서 관련 기술개발 및 적용을위한 다양한 시도가 전개되고 있다. 그러나 IoT 기술의 확대 적용과 함께 새로운 사이버위협도획기적으로 증가하고 있고 다양한 피해가 발생하고 있어 IoT 환경에 대한 사이버보안 강화 차원의 대책이 시급하게 마련되어야 한다. 이에 본 연구에서는 국방 IoT 환경에서 활용 가능한 인공지능 기술 기반의 침입탐지 모델을 2가지 형태로 구분하여 제시하였다. 첫 번째 모델은 IoT 환경의 자원제약적 특성을 고려하여 경량화에 중점을 둔 모델로서, 특성 추출 기법인 LDA를 통해모델에 입력되는 특성의 차원을 축소하고 Gradient Boosting 계열의 모델 중 가장 빠르고 경량화된 LightGBM 모델로 침입탐지를 수행한다. 두 번째 모델은 모델 구축 및 유지보수의 용이성보장에 중점을 두고 설계된 모델로서, 자연어처리를 기반으로 다양한 특성을 하나의 문장으로병합해 데이터 전처리를 획기적으로 간소화하면서 언어모델인 BERT 모델로 침입탐지를 수행한다. 두 모델에 대한 성능평가는 현재 국방 IoT 환경에서 실제로 사용되고 있는 MQTT 프로토콜을 기반으로 생성된 데이터세트인 MQTTset를 활용하였다.실험 결과 LDA와 LightGBM 결합모델은 이진분류 정확도 99.08%, F1_Score 99.07%, 다중분류에서는 정확도 99.76%, F1_Score 97.42%를 달성하였다. BERT 모델은 이진분류 정확도 99.96%, 다중분류 정확도99.6%를 달성하였고, F1_Score는 모두 100%로 나타나 선행연구보다 전반적으로 향상되었다. 그리고 모델 구축 및 침입탐지에 소요되는 시간 역시 단축됨을 확인하였다.",다국어 초록 정보 없음
메신저 데이터 저자 프로파일링을 위한 한국어 구어체 텍스트 기반 성별 분류 모델,2023,"['자연어처리', 'SNS 데이터', '디지털포렌식', '프로파일링', 'BERT', '도메인 적응', 'nlp', 'sns data', 'digital forensic', 'profiling', 'bert', 'domain adaptation']",국문 초록 정보 없음,"With explosive social network services (SNS) growth, there has been an extensive generation of text data through messenger services. In addition, various applications such as Sentiment Analysis, Abusive text Detection, and Chatbot have been developed and provided due to the recent development of Natural Language Processing. However, there has not been an attempt to classify various characteristics of authors such as the gender and age of speakers in Korean colloquial texts. In this study, I propose a gender classification model for author profiling using Korean colloquial texts. Based on Kakao Talk data for the gender classification of the speaker, the Domain Adaptation is carried out by additionally learning ‘Nate Pan’ data to KcBERT(Korean Comments BERT) which is learned by Korean comments. Results of experimenting with a model that combines External Lexical Information showed that the performance was improved by achieving an accuracy of approximately 95%. In this study, the self-collected ‘Nate Pan’ data and the 'daily conversation' data provided by the National Institute of the Korean Language were used for domain adaptation, and the ‘Korean SNS’ data of AI HUB was used for model learning and evaluation."
Implementation of Deep Learning Model-based Korean Sentence Syntactic Complexity Assessment Model,2023,"['Syntactic Complexity', 'Automatic Assessment', 'Deep Learning', 'BERT', '통사적 복잡도', '자동 측정', '딥러닝', 'BERT']",국문 초록 정보 없음,"This study developed a method to assess the text level automatically regarding syntactic complexity. The new method was developed by improving the method of measuring the syntactic complexity of large-scale texts with various types. We implemented a Korean sentence syntactic complexity assessment model based on the deep learning models, especially the Korean BERT models. In particular, the KcBERT-based model, fine-tuned through the “National Institute of Korean Language Dependency-Parsed Corpus (v.2.0)”, showed excellent performance with an accuracy of 0.949. This model is expected to contribute to establishing an integrated model to assess the text level as the sub-factor model. By segmenting the text assessment model by factors, it could overcome the limitations of the existing research using unexplainable deep learning models to provide a direction for more sophisticated educational treatment."
기초 언어자원을 활용한 군집화된 의미 레이블의 품질 향상,2023,"['Word Sense Disambiguation', 'Sense Label', 'Clustering', 'Sparse Data', 'BERT', '단어 의미 모호성 해소', '의미 레이블', '군집화', '희소 데이터', 'BERT']","지도학습 기반의 단어 의미 모호성 해소 연구에서는 사전이나 시소러스 등을 활용하여 희소 데이터 문제를 효과적으로 처리하고 있다. 이 중에서, 군집화된 의미 레이블을 시퀀스 레이블링 기반 모델에 사용하는 방법이 높은 성능과 빠른 처리속도를 보였다. 본 연구에서는, 시소러스 등의 언어자원보다 비교적 쉽게 구할 수 있는 기초 언어자원을 사용해 군집화된 의미 레이블의 품질을 개선하는 방법을 제안한다. 이를 위해, 어휘의 의미 분류를 군집 초기화에 사용하고, 원시문장 말뭉치를 사용해 벡터의 품질을 향상시켰다. 이 개선된 의미 레이블을 BERT 기반 단어 의미 모호성 해소 모델에 적용하여 성능을 평가했다. 실험 결과, 제안 방법을 사용한 모델은 F1 70.6%의 성능을 보여 제안 방법을 사용하지 않은 기존 모델의 F1 69.1% 보다 높은 성능을 보였다. 따라서, 기초 언어자원을 추가로 사용하여 군집화된 의미 레이블의 품질을 향상시킬 수 있음을 보였다.",다국어 초록 정보 없음
공간 질의응답 시스템에서의 개체링킹과 딥러닝 모델을 활용한 멘션 탐지,2023,"['Question-answering(QA) Systems', 'KBQA System', 'GeoKBQA', 'Entity Linking', 'Mention Detection(MD)', '질의응답QA 시스템', 'KBQA 시스템', '개체 링킹', 'GeoKBQA', '멘션 탐지(Mention Detection)']",국문 초록 정보 없음,"With the rapid advancements in artificial intelligence and natural language processing technologies, the significance of question-answering (QA) systems between humans and machines has been on the rise. In this context, Knowledge Base Question Answering (KBQA) systems play a pivotal role in addressing diverse information needs of users. A KBQA system provides answers to user queries based on information stored in a Knowledge Base (KB). The typical pipeline of a standard KBQA system involves processing the natural language input, performing Entity linking to identify and link entities to their corresponding entries in the Knowledge Base, and subsequently generating a Logical Form. However, an extended domain of KBQA, known as Geographic Information-Based Question Answering (GeoKBQA), transforms spatially related queries into Logical Forms without the process of Entity linking. This research proposes a novel methodology to incorporate Entity linking in GeoKBQA to overcome such limitations. For this endeavor, deep learning models namely BERT, RoBERTa, and ChatGPT were utilized to carry out the initial process of Entity linking, which is Mention Detection (MD). Specifically, the BERT and RoBERTa models were fine-tuned with the NLMAPS dataset, comprised of geographic queries, for the specialized MD task concerning geographic inquiries. Conversely, ChatGPT employed a Few-shot prompting approach to perform MD. Experimental results indicated that the fine-tuned BERT and RoBERTa models achieved an F1 score of 0.96 and 0.97, while the ChatGPT model recorded an F1 score of 0.99."
A Secret Path to Acquiring Wisdom and Compassion: The Sandplay Therapist as a Five Headed Sea Serpent(The Therapeutic Relationship in Sandplay Therapy),2023,"['Five headed sea serpents', 'therapeutic roles', 'therapeutic relationship', 'Sandplay therapy', 'compassion and wisdom', 'healing and transformation']",국문 초록 정보 없음,다국어 초록 정보 없음
프라이버시 보호를 위한 오프사이트 튜닝 기반 언어모델 미세 조정 방법론,2023,"['딥러닝', '언어모델', '언어모델 프라이버시', '미세 조정', '오프사이트 튜닝', '텍스트 분류', 'Deep Learning', 'Language Model', 'Language Model Privacy', 'Fine-Tuning', 'Offsite-Tuning', 'Text Classification']","최근 구글의 BERT, OpenAI의 GPT 등, 언어모델(Language Model)을 사용한 비정형 텍스트 데이터에 대한 딥러닝 (Deep Learning) 분석이 다양한 응용에서 괄목할 성과를 나타내고 있다. 대부분의 언어모델은 사전학습 데이터로부터 범용적인 언어정보를 학습하고, 이후 미세 조정(Fine-Tuning) 과정을 통해 다운스트림 태스크(Downstream Task)에 맞추어 갱신되는 방식으로 사용되고 있다. 하지만 최근 이러한 언어모델을 사용하는 과정에서 프라이버시가 침해될 수 있다는 우려가 제기되고 있다. 즉 데이터 소유자가 언어모델의 미세 조정을 수행하기 위해 다량의 데이터를 모델 소유자에게 제공 하는 과정에서 데이터의 프라이버시가 침해될 수 있으며, 반대로 모델 소유자가 모델 전체를 데이터 소유자에게 공개하면 모델의 구조 및 가중치가 공개되어 모델의 프라이버시가 침해될 수 있다는 것이다. 이러한 상황에서 프라이버시를 보호하며 언어모델의 미세 조정을 수행하기 위해 최근 오프사이트 튜닝(Offsite Tuning)의 개념이 제안되었으나, 해당 연구는 제안 방법론을 텍스트 분류 모델에 적용하는 구체적인 방안을 제시하지 못했다는 한계를 갖는다. 이에 본 연구에서는 한글 문서에 대한 다중 분류 미세 조정 수행 시, 모델과 데이터의 프라이버시를 보호하기 위해 분류기를 추가한 오프사이트 튜닝을 적용하는 구체적인 방법을 제시한다. 제안 방법론의 성능을 평가하기 위해 AIHub에서 제공하는 ICT, 전기, 전자, 기계, 그리고 의학 총 5개의 대분야로 구성된 약 20만건의 한글 데이터에 대해 실험을 수행한 결과, 제안하는 플러그인 모델이 제로 샷 모델 및 오프사이트 모델에 비해 분류 정확도 측면에서 우수한 성능을 나타냄을 확인하였다.","Recently, Deep learning analysis of unstructured text data using language models, such as Google’s BERT and OpenAI’s GPT has shown remarkable results in various applications. Most language models are used to learn generalized linguistic information from pre-training data and then update their weights for downstream tasks through a fine-tuning process. However, some concerns have been raised that privacy may be violated in the process of using these language models, i.e., data privacy may be violated when data owner provides large amounts of data to the model owner to perform fine-tuning of the language model. Conversely, when the model owner discloses the entire model to the data owner, the structure and weights of the model are disclosed, which may violate the privacy of the model. The concept of offsite tuning has been recently proposed to perform fine-tuning of language models while protecting privacy in such situations. But the study has a limitation that it does not provide a concrete way to apply the proposed methodology to text classification models. In this study, we propose a concrete method to apply offsite tuning with an additional classifier to protect the privacy of the model and data when performing multi-classification fine-tuning on Korean documents. To evaluate the performance of the proposed methodology, we conducted experiments on about 200,000 Korean documents from five major fields, ICT, electrical, electronic, mechanical, and medical, provided by AIHub, and found that the proposed plug-in model outperforms the zero-shot model and the offsite model in terms of classification accuracy."
NLP 기계 학습을 사용한 한글 요구사항 문서에서의 요구사항 자동 생성 프로세스,2023,"['Korean document', 'BERT', 'Chatbot', 'NLP', 'Requirement diagram', 'Requirement specification']",국문 초록 정보 없음,"In software engineering, requirement analysis is an important task throughout the process and takes up a high proportion. However, factors that fail to analyze requirements include communication failure, different understanding of the meaning of requirements, and failure to perform requirements normally. To solve this problem, we derived actors and behaviors using morpheme analysis and BERT algorithms in the Korean requirement document and constructed them as ontologies. A chatbot system with ontology data is constructed to derive a final system event list through Q&A with users. The chatbot system generates the derived system event list as a requirement diagram and a requirement specification and provides it to the user. Through the above system, diagrams and specifications with a level of coverage complied with Korean requirement documents were created."
RNN과 트랜스포머 기반 모델들의 한국어 리뷰 감성분류 비교,2023,"['딥러닝', '트랜스포머', 'BERT', 'GPT', '감성 분석', '자연어 처리', 'Deep Learning', 'Transformer', 'BERT', 'GPT', 'Sentiment Analysis', 'Natural Language Processing']",국문 초록 정보 없음,다국어 초록 정보 없음
GPT-3와 KoBERT를 활용한 감정 분석 기반 AI 챗봇 시스템,2023,"['챗봇(Chatbot)', 'KoBERT(Korean BERT)', 'GPT(Generative Pre-trained Transformer)', '감정 분석(Emotion Analysis)', 'BERT(Bidirectional Encoder Representations from Transformers)']",국문 초록 정보 없음,다국어 초록 정보 없음
영화확산에 대한 온라인구전의 차원 및 영향력 분석,2023,"['Movie', 'eWOM', 'Sentiment', 'BERT Model', 'Panel Error Correction Model']",국문 초록 정보 없음,"In this study, using Korean movie box office data and online review data, we explore the 4 dimensions of eWOM(electronic(or online) word-of-mouth) (volume, valence, variance, and sentiment), and their effects on the number of audiences according to the analysis method. The volume, valence, and variance of eWOM were measured by the number of reviews, average rating, and rating variance, respectively, while the sentiment of eWOM was measured by the average sentiment scores derived by the BERT(Bidirectional Encoder Representations from Transformers) model. As a result, it was recognized that we have to be careful in interpreting the analysis results using secondary data, because the units of measurement of the 4 dimensions(the number of reviews, average rating, rating variance, and average sentiment) of eWOM are not all same, and the 4 dimensions are highly correlated with each other. By comparing the estimation results of three analysis models: regression model for aggregate data, panel regression model and panel error correction model for weekly panel data, it was found that the effects of 4 dimensions of eWOM may differ depending on the analysis method. The analysis result from the panel error correction model showed that only the volume of eWOM(number of reviews) had a significant effect on the number of audiences. The results of this study empirically show that considering the characteristics of the data used and the selection of an appropriate research method are important for accurate analysis, especially when we are trying to analyze the effects of the dimensions of eWOM on the movie box office success using secondary data about online movie reviews."
Research on the Financial Data Fraud Detection of Chinese Listed Enterprises by Integrating Audit Opinions,2023,"['Audit opinion on financial statements', 'Bert model', 'data imbalance', 'LightGBM model', 'fraud financial data']",국문 초록 정보 없음,"Financial fraud undermines the sustainable development of financial markets. Financial statements can be regarded as the key source of information to obtain the operating conditions of listed companies. Current research focuses more on mining financial digital data instead of looking into text data. However, text data can reveal emotional information, which is an important basis for detecting financial fraud. The audit opinion of the financial statement is especially the fair opinion of a certified public accountant on the quality of enterprise financial reports. Therefore, this research was carried out by using the data features of 4,153 listed companies' financial annual reports and audits of text opinions in the past six years, and the paper puts forward a financial fraud detection model integrating audit opinions. First, the financial data index database and audit opinion text database were built. Second, digitized audit opinions with deep learning Bert model was employed. Finally, both the extracted audit numerical characteristics and the financial numerical indicators were used as the training data of the LightGBM model. What is worth paying attention to is that the imbalanced distribution of sample labels is also one of the focuses of financial fraud research. To solve this problem, data enhancement and Focal Loss feature learning functions were used in data processing and model training respectively. The experimental results show that compared with the conventional financial fraud detection model, the performance of the proposed model is improved greatly, with Area Under the Curve (AUC) and Accuracy reaching 81.42% and 78.15%, respectively."
선박무선통신 음성인식 기술 개발 연구,2023,"['선박통신', '음성인식', '항해', 'Wav2vec 2.0', 'BERT', 'VTS', 'Ship Communication', 'Voice Recognition', 'Navigation', 'Wav2vec 2.0', 'BERT', 'VTS']",국문 초록 정보 없음,다국어 초록 정보 없음
Text Mining을 활용한 북한의 도발 수준 및 형태 예측,2023,"['Text Mining', 'North Korea', 'Provocation', 'Heatmap', 'BERT', 'KoBERT', 'KCNA']",국문 초록 정보 없음,"Research into the feasibility of predicting specific events using Text Mining techniques has been actively pursued in conjunction with the advancement of Machine Learning. Consequently, the potential for predicting North Korea's provocations utilizing Text Mining methods has emerged. However, the field lags behind other domains due to challenges in acquiring high-quality training data and the complexity associated with event classification. This study addresses these limitations by leveraging a Pre-trained BERT model to establish a comprehensive classification framework for North Korea's provocative behavior, moving beyond binary classifications (provocation or peace) used in previous research. Original data from the Korean Central News Agency (KCNA) and domestic media sources were gathered and analyzed as training data. Notably, the findings demonstrated that employing original data from the KCNA increased prediction accuracy compared to utilizing data from domestic media. This study offers a way to enhance the informational value of North Korea's provocations through scientific predictions, ultimately bolstering the reliability of qualitative expert judgments."
지도학습 기반의 부정·불량 식품 기사 자동 분류에 관한 연구,2023,"['인공 신경망 (Artificial Neural Network)', 'BERT(Bidirectional Encoder Representation from Transformers)', '지도 학습 (Supervised Learning)', '자연어 처리(Natural Language Process)']","최근 식품 공급망의 다양화와 생산, 유통, 소비 방식의 변화로 인해 부정·불량 식품이 증가하고 있어 이에 대한 새로운 대응책이 필요하다. 현재까지는 사람이 직접 부정·불량 식품 관련 기사를 모니터링하고 분석했으나, 처리해야 할 정보의 양이 많아지면서 기사 분석을 위한 비용이 크게 증가하고 있다. 이러한 문제를 해결하기 위해 본 연구에서는 지도학습 기반 모델을 사용한 부정·불량 식품 자동 분류 시스템을 제안한다. 해당 시스템에는 여러 BERT[1] 모델의 앙상블(Ensemble)을 적용하여 과적합(Overfitting)과 편향성(Bias)을 방지하였으며 동시에 분류(Classification) 성능을 향상시켰다. 모델의 분류학습과 성능 평가에는 사전에 수집된 1250개의 기사 데이터를 사용하여 실험을 수행했다. 실험 결과 자연어 처리 분야에서 여러 모델의 앙상블 기법은 단일 모델 대비 적은 데이터로 더 높은 분류 성능을 보이는 것을 확인했다.",다국어 초록 정보 없음
KoBert를 이용한 문학 감정분류,2023,"['Artifitial Intelligence', 'Literature', 'Emotion Analysis', 'Emotion Classification', 'BERT', 'KoBERT', 'DeepLearning', '인공지능', '문학', '감정 분석', '감정 분류', 'BERT', 'KoBERT', '딥러닝']","인공지능(AI) 기술을 중심으로 한 과학기술의 비약적인 발전으로 다양한 학문 분야에서 이를 시도하고 있다. 문학 영역에서도 인공지능을 활용해 문학 작품을 분석하고 생성하는 등 다양한 움직임을 보인다. 문학에서 감정은 중요하기 때문에 인공지능 기술이 감정을 어디까지 이해하고 있는지에 대한 확인이 필요하다. 따라서 본 논문에서는 최첨단 인공지능 감정 분석 모델인 KoBERT를 사용하여 한국어 문학 텍스트의 감정을 분류해 본다. 기존의 연구들과는 달리 모델의 성능을 평가하는 것에서 나아가, 감정 분류 결괏값 자체를 분석하고 개선점을 찾으려 한다. 이러한 분석은 향후 문학과 인공지능의 고도화된 융합 과정에서 인공지능이 갖추어야 할 역량을 재고하는 데 좋은 지표가 될 것이다.","With AI's rapid advancements, its applications are being explored across various fields. Even AI is used to analyze and create literary works. Due to the importance of emotions in literature, it is necessary to confirm the extent to which AI technology understands emotions. This paper focuses on classifying emotions in Korean literary texts using KoBERT. Our approach not only evaluates the model's performance, but also analyzes the emotion classification results and seeks improvements. This analysis will be helpful in reconsidering the capabilities that AI must have in the future convergence of literature and AI."
얼굴 영상과 다차원 감정 기반의 텍스트를 이용한 멀티모달 감정인식 시스템,2023,"['multimodal', 'emotional recognition', 'VAD', 'CNN', 'BERT']",국문 초록 정보 없음,"Emotional recognition in the existing computer field was conducted based on one form and normal human emotions. For accurate emotion recognition, various forms and emotions must be recognized on a continuous line. In this paper, to solve this problem, we propose multimodal emotion recognition through VAD that recognizes various forms and emotions as multidimensional spaces. The proposed multimodal configuration combines CNN and BERT models. To demonstrate the superiority of the proposed method, a single emotion recognition model and existing multimodal were compared. As a result of the comparison, the multimodal proposed in this paper showed a contribution to accurate emotional recognition in that emotional recognition showed improved 6% performance."
어휘의미망을 이용한 주제 분류 및 감성 표현 영역 추출 모델,2023,"['extraction of sentimental expression', 'sentiment analysis', 'lexical semantic network', 'BERT', 'UWordMap', '감성 표현 영역 추출', '감성 분석', '어휘의미망', 'BERT', 'UWordMap']",국문 초록 정보 없음,"The majority of the previous sentiment analysis studies classified a single sentence or document into only a single sentiment. However, more than one sentiment can exist in one sentence.In this paper, we propose a method that extracts sentimental expression for word units. The structure of the proposed model is a UBERT model that uses morphologically analyzed sentences as input and adds layers to predict topic classification and sentimental expression. The proposed model uses topic feature of a sentence predicted by topic dictionary. The topic dictionary is built at the beginning of machine learning. The learning module collects topic words from a training corpus and expands them using the lexical semantic network. The evaluation is performed with the word unit F1-Score. The proposed model achieves an F1-Score of 58.19%, an improvement of 0.97% point over the baseline."
"EU GDPR 위반사례 토픽 분석 및 시사점 연구: 금융, 의료, 산업 및 상거래 부문을 중심으로",2023,"['GDPR', 'Personal Information Protection', 'Keyword Network', 'Topic Modeling', 'BERT', 'GDPR', '개인정보보호', '키워드 네트워크', '토픽 모델링', 'BERT']","본 연구는 유럽연합에서 ｢개인정보보호규정(GDPR)｣을 위반하여 제재 받은 사례 중 (1) 금융, (2) 의료, (3) 산업 및 상거래 부문의 사례를 텍스트 마이닝 기법으로 분석하여 국내 관련 산업 부문에 대한 시사점을 도출하였다. 구체적으로GDPR 집행기록부(GDPR Enforcement Tracker)에서 제공하는 GDPR 위반에 따른 과징금부과처분 결정문 데이터 총 994개를 수집하고, 금융, 의료, 산업 및 상거래에 해당하는 사례를 선별 및 분류한 후, 각 부문별로 키워드 네트워크 분석과 텍스트 마이닝 기법을 통해 분석을 수행하였다. 먼저, 각 부문별로 일반적인 위반 사유를 파악하고, 각 부문의 위반 기업 규모를 기준으로 소, 중, 대로 구분하여 기업 규모별 법 위반 특징을 분석하여 위반 사례의 경향성을 다층적으로 비교하였다. 이러한 분석 결과를 바탕으로 해당 산업부문의 국내 기업이 데이터 기반 사업을 추진할 때 고려해야 하는 사항과 이들의 국내외 개인정보 규제 준수를 지원하기 위한 정책적, 학술적 시사점을 도출하였다.","This study aims to learn lessons from the sanctioned cases in violation of the EU General Data Protection Regulation (hereinafter the ‘GDPR’) in (1) finance, (2) health and (3) commerce sectors in the EU. We collected 994 cases in which fines were imposed for violation of the GDPR from the GDPR Enforcement Tracker and analyzed them using the keyword network and text mining analysis methods. First, we identified general causes of sanctions in each sector, and second, characterized and compared the causes of sanctions according to sizes of companies categorized into small, medium, and large in each sector. Through the examination of these analyses, a set of pragmatic implications has been deduced, pertinent to Korean enterprises operating within similar sectors. Furthermore, implications also extend to the Korean governmental sphere, offering insights for policy formulation, as well as to the academic community, serving as a basis for subsequent theoretical investigations."
BERTopic과 소셜 네트워크 분석 기반 고령화 단계별 판례분석을 통한 분쟁 유형 도출에 관한 연구,2023,"['Elderly', 'Legislation', 'Text Mining', 'Topic Modeling', 'Guardianship System', 'BERT', 'BERTopic', 'Deep Learning', 'Social Network Analysis', '고령자', '법률', '텍스트 마이닝', '토픽 모델링', '후견 제도', 'BERT', 'BERTopic', '딥러닝', '소셜 네트워크 분석']","대한민국은 1999년에 고령자의 비율이 7%가 넘으면서 고령화 사회가 되었고, 2017년에는 고령자의 비율이 14%가 넘어 고령 사회가 되었다. 현재 많은 전문가들은 가까운 미래에 대한민국은 고령자들의 비율이 20%가 넘어 초고령 사회가 될 것으로 전망한다. 고령 사회가 되면서 이전에는 발생하지 않았던 다양한 문제들이 발생하고 있으며 그 빈도 또한 가속화되는 고령화와 함께 가파르게 증가하고 있다. 고령화의 진행에 대비하여 현재 우리나라는 2013년 개정된 민법에 따라 후견제도를 도입하여 운영하고 있다. 그러나, 여전히 고령자 관련 분쟁은 꾸준히 증가하고 있다. 따라서 고령자 관련 분쟁 및 피해 사례에 대해 다양한 유형을 파악하여 관련법과 정책 수립이 필요한 시점이다. 이에 본 연구는 고령화 단계에 따른 ‘고령자’와 관련된 판례를 분석하여 분쟁 사례들을 유형화한다. 이를 위해 ‘후견’, ‘고령’, ‘의사결정’, ‘부양’, ‘노인’을 키워드로 판례를 수집하여 분석하였다. 본 연구에서는 법률 전문가에 자문을 통해 토픽 모델링 결과에서 분쟁 유형을 도출하였다. 법률 전문가가 토픽 모델링 결과에서 효과적으로 분쟁 유형을 도출할 수 있도록 문장 임베딩 기술을 활용한 BERTopic을 이용하여 토픽 모델링을 진행하였다. 또한 소셜 네트워크 분석을 통해 토픽 모델링 결과를 보완하고 해석을 진행하였다. 많은 양의 판례 데이터에 텍스트 마이닝 기법을 활용하여 분석함으로써 주요한 분쟁 유형을 고령화의 진행 단계에 따라 도출하였다. 텍스트 마이닝을 통해 도출된 결과의 해석은 분석가의 주관이 들어가게 되는데, 토픽 모델링의 결과 해석을 법률 전문가를 통해 진행하여 그러한 단점을 보완할 수 있었다. 본 연구의 결과로 도출된 분쟁 유형들을 활용하여 추후 법률 제정 및 정책 수립에 활용될 것으로 기대된다.","In 1999, the proportion of the elderly in Korea exceeded 7%, marking the country as an aging society. By 2017, the proportion had exceeded 14%, and experts predict it will surpass 20% in the near future, making Korea a super-aged society. Consequently, various problems are emerging, and their frequency is rapidly increasing. In response, Korea introduced and operates a guardianship system in accordance with the 2013 revised civil law, but disputes related to the elderly are still on the rise. To address this, this study analyzes dispute cases by collecting and analyzing precedents related to the 'elderly' according to the aging stage. The type of dispute was derived from the results of topic modeling conducted using BERTopic and sentence embedding technology, with input from legal experts. Social network analysis was used to supplement and analyze the topic modeling results. By analyzing a large amount of case data using text mining techniques, major types of disputes were identified according to the progression stage of aging. The interpretation of the results of topic modeling was conducted through legal experts to compensate for any shortcomings. It is expected to be used for legislation and policy establishment in the future by utilizing the types of disputes derived as a result of this study."
다양한 뉴스데이터를 이용한 자연어 처리모델 성능 비교,2023,"['performance comparison', 'NLP', 'fake news classification', 'dataset analysis']",국문 초록 정보 없음,"Natural Language Processing is one of the fields that attracts a lot of attention in deep learning, and with the introduction of transformer-based GPT[1] and BERT[2], it is showing tremendous performance improvement. In this paper, we compared and analyzed the performance of word embedding, neural network, and pre-trained language model, dependent othe model and data type of the news. ISOT, Kaggle, and Politifact datasets were used for fake news dataset as a result, BERT showed best performance in this study, however in Politifact Dataset, it showed relatively poor performance. We analyzed the structure of dataset and from the model perspectives to find out the reason why the performance differences were occurred."
딥러닝 언어 모델과 인공신경망 기계 번역을 활용한 담화 조응 현상과 한정 명사구 연구,2023,"['담화 조응사', '한정명사구', '당나귀 구문', '인공지능', '인공신경망 기계번역', '버트', '챗지피티', 'discourse anaphora', 'definite NP', 'donkey sentence', 'AI', 'neural machine translations', 'Bert', 'ChatGPT']",국문 초록 정보 없음,"In this preliminary study, we investigate the phenomena of discourse anaphora and definite descriptions within the framework of the so-called “donkey sentence.” Unlike English, Korean allows for the expression of donkey anaphora using either the pronoun kukes ‘it’ or definite noun phrases (bare NP or ku+NP). Employing neural machine translations and deep learning models, we examine the appropriateness of these two types of donkey sentences in Korean through the following procedure: Firstly, utilizing ChatGPT, we generate 60 sentences with donkey structures containing both pronouns and definite noun phrases. Secondly, we employ Google Translation and Papago to translate these sentences. Thirdly, we use KR-BERT to evaluate the acceptability of the translations. Finally, we conduct a statistical analysis based on the obtained acceptability scores. The results reveal that definite noun phrases are a more natural expression than pronouns in Korean donkey sentences. This novel finding suggests that the E-type approach would provide a better theoretical account than DRT (Discourse Representation Theory)."
다중목표 대화형 추천시스템을 위한 사전 학습된 언어모델들에 대한 성능 평가,2023,"['추천시스템', '대화형추천시스템', '다이얼로그', '언어모델', 'recommender systems', 'conversational recommender systems', 'dialogue', 'language model']","본 연구는 대화형 추천 시스템인 다중 목표 대화형 추천 시스템(MG-CRS)에서 사용되는 다양한 사전 학습된 언어 모델들을 고찰하고, 각 언어모델 성능을 비교분석한다. 특히, 언어 모델의 크기가 다중 목표 대화형 추천 시스템의 성능에 어떤 영향을 미치는지에 대. BERT, GPT2, 그리고 BART의 세 종류의 언어 모델을 대상으로 하여, 대표적인 다중 목표 대화형 추천 시스템 데이터셋인 DuRecDial 2.0에서 '타입 예측'과 '토픽 예측'의 정확도를 측정하고 비교한다. 실험 결과, 타입 예측에서는 모든 모델이 뛰어난 성능을 보였지만, 토픽 예측에서는 모델 간에 혹은 사이즈에 따라 성능 차이가 관찰되었다. 이러한 결과를 바탕으로 다중 목표 대화형 추천 시스템의 성능 향상을 위한 방향을 제시한다.","In this paper, we examine pre-trained language models used in Multi-Goal Conversational Recommender Systems (MG-CRS), comparing and analyzing their performances of various pre-trained language models. Specifically, we investigate the impact of the sizes of language models on the performance of MG-CRS. The three types of language models of BERT, GPT2, and BART, and compare their accuracy in two tasks of 'type prediction and topic prediction on the MG-CRS dataset, DuRecDial 2.0. Experimental results show that all models demonstrate excellent performance in the type prediction task, but provide significant in performance depending on models or their sizes in the topic prediction task. Based on these findings, the study provides directions for improving the performance of MG-CRS."
‘AI 이육사’ 실현 가능성에 대한 시론(1) —인공지능과 문학적 담화 기능 구축 사례 제언,2023,"['AI', '대화형 인공지능', '이육사', '챗봇', '초거대 언어모델', 'ChatGPT', 'AI', 'conversational AI', 'Yi Yuksa', 'chatbots', 'super large language model', 'ChatGPT']","최근 인공지능 기반 대화 모델(Language Model)이 공학 및 연구의 범주를 넘어 교육학·언어학·콘텐츠학 등 다양한 학문에서 영향력을 미치고 있다. 특히 연산 능력의 증폭과 딥러닝 방법론의 발견으로 AI는 예술창작의 지점까지 그 범위를 확장한다. 한국의 기업들 역시 앞다투어 언어모델(GPT-2, GPT-3, BERT 등)에 한국어를 학습시키는 등 변화하는 시장에 적응하려는 움직임을 보여왔다.AI에 의한 문예창작이 예견되는 것을 뛰어넘어 실제로 문학을 창작하고, 출간하는 이 시대에서 문학 연구자·교육자는 어떠한 입장을 가져야 하는가? 본 연구는 초거대 언어모델을 기반으로 구축된 대화형 인공지능의 실질적인 기능을 확인하고, 현재 기술로 도달 가능한 지점과 앞으로 도달 가능할 것으로 예측되는 지점을 확인하여 문학 콘텐츠 분야에서의 향후 활용 방안을 검토하고자 한다.해당 연구를 통해 우선 확인하고자 하는 사항은 현재 성능 면에서 가장 앞선 대화형 인공지능인 ChatGPT를 통한 ‘AI 이육사’의 실현 가능성과 한계, 개선 가능성을 지닌 수단이다. 이와 같은 ‘AI 이육사’ 실현에 관한 연구는 AI 문인 모델링 제언이라는 피상적 분석에서 그치는 것이 아니라, 동일 세션에서 프롬프트 입력이 진행된다는 가정에 따라, ChatGPT의 인컨텍스트 러닝은 시 텍스트의 학습이 가능한가? ChatGPT는 작가 정보와 시 텍스트 학습을 통해 이전 응답보다 더 정확한 텍스트 출력이 가능한가? 이와 같은 출력이 가능하다면, 그 수준은 어느 정도인가? 비평적 수준인가? 교양적 수준인가? GPT-4의 동일 세션 내 지속성 수준은 어느 정도인가? ChatGPT를 통해서, 혹은 그 이후의 기술을 통해서 향후 ‘AI 이육사’와 같은 대화형 인공지능의 실현 가능성이 있는가? 등의 검증을 거친다. 이를 통해, 본 연구는 향후 AI 산업과 문학의 실질적 연계를 위한 기초 분석으로 기능하는 시발적 접근이 될 것이다.","In recent years, AI-based Language Models have been influencing various disciplines such as education, linguistics, and content studies beyond the scope of engineering and research. In particular, with the amplification of computing power and the discovery of deep learning methodologies, AI is expanding its scope to the point of artistic creation. Korean companies are also making moves to adapt to the changing market, such as learning Korean in language models (GPT-2, GPT-3, BERT, etc.).In this era, when the creation of literature by AI goes beyond what is predicted and actually creates and publishes literature, what stance should literary researchers and educators take? This paper aims to examine the practical capabilities of conversational AI built on super-large language models, identify the points that can be reached with current technology and the points that are predicted to be reached in the future, and examine future applications in the field of literary content.The first thing we want to check through this research is the feasibility and limitations of ‘AI Yi Yuksa’ through ChatGPT, which is currently the most advanced conversational AI in terms of performance, and the means to improve it. The research on the realization of such an AI Yi Yuksa is not limited to a superficial analysis of AI literary modeling proposals, but also includes the following questions: Is ChatGPT’s in-context learning capable of learning poetry texts under the assumption that prompted input is performed in the same session? Can ChatGPT output more accurate text than the previous response by learning author information and poetry text? If so, what is the level of output? Is it a critical level or a liberal arts level? What is the level of persistence within the same session of GPT-4? This study aims to be a pioneering approach that functions as a basic analysis for the practical connection between the AI industry and literature in the future by verifying the feasibility of interactive AI such as an ‘AI tutor’ through ChatGPT or later technologies."
대규모 언어모델을 활용한 리걸 마인드 개발의 현황과 전망,2023,"['대규모 언어모델', '리걸 마인드', '법률 인공지능 서비스', '리걸테크', 'Large Language Model', 'Legal Mind', 'Legal AI Service', 'Legal Tech']","본 논문은 대규모 언어모델이 리걸 마인드(Legal Mind)를 가질 수 있는지에 관하여, 특히 변호사 시험 문제를 해결하기 위한 능력을 가질 수 있는지에 대한 물음을 통해 그 현황을 살펴보고 전망을 제시한다. 본 연구는 먼저, 자연어 인공지능 모델의 발전사를 소개한다. 순환신경망(Recurrent Neural Network, RNN)부터 임베딩(Embedding)을 위한 단어의 벡터 전환(Word to Vector) 기술, 트랜스포머(Transformer) 구조를 활용한 BERT(Bidirectional Encoder Representations from Transformers)를 거쳐, 1,750억 개의 파라미터를 가진 GPT 같은 대규모 언어모델들의 발전 과정을 서술하고, 최근 법률 분야에 자연어 인공지능 모델의 활용이 화두가 되고 있는 이유를 설명한다.다음으로 ChatGPT 프롬프터(Prompter)에 한국의 민법 규정과 대법원 판례를 입력함으로써 새로운 학습과정 없이도 ChatGPT에게 점진적으로 리걸 마인드를 형성시킬 수 있음을 보여준다.마지막으로 법률 인공지능 서비스의 발전 전망을 소개하고, 리걸 마인드를 탑재한 대규모 언어모델이 법률 시장에 미치는 영향을 논의한다. 대규모 언어모델에 리걸 마인드를 형성시키는 연구는 법률 시장에 혁신적인 변화를 가져올 것으로 기대되며, 본 논문에서는 기술 발전에 따른 앞으로의 법률 시장 변화를 제안한다.","This paper presents an assessment and outlook on whether large-scale language models can possess Legal Mind, the capability to solve attorney exam questions. Initially, it introduces the developmental history of natural language artificial intelligence models, traversing from Recurrent Neural Networks (RNNs) to Word to Vector techniques for Embedding, and the application of the Transformer architecture in BERT (Bidirectional Encoder Representations from Transformers). It delineates the developmental trajectory of large-scale language models like ChatGPT with 175 billion parameters and elucidates the recent focus on the utilization of natural language AI models in the legal domain.Subsequently, it demonstrates the incremental formation of Legal Mind within ChatGPT without the need for new learning processes by inputting South Korean civil law provisions and Supreme Court precedents into the ChatGPT Prompter.Finally, it outlines the developmental prospects of legal AI services and discusses the impact of integrating Legal Mind into large-scale language models on the legal market. Research aimed at instilling Legal Mind within large-scale language models is expected to bring innovative changes to the legal market, and this paper proposes future changes in the legal market in line with technological advancements."
공사일지의 텍스트 마이닝을 통한 우천 공기지연 리스크 정량화,2023,"['Construction log', 'Unstructured data', 'Text mining', 'Schedule delay risk', 'Quantification', '공사일지', '비정형데이터', '텍스트마이닝', '공기지연 리스크', '정량화']","건설공사에서의 공기지연은 공사금액 증가, 발주처 클레임, 무리한 공기단축에 따른 건설공사의 질 하락 등 건설프로젝트에 악영향을 끼치는 주요 리스크 요인이다. 기존 연구에서는 공기지연 리스크의 중요도 및 우선순위를 파악하고 중요도에 따라 공정을 관리하였으나, 공기지연 리스크의 심도는 데이터 수집의 한계 등으로 정량화 연구가 미흡하다. 따라서 본 연구에서는 BERT (Bidirectional Encoder Representations fromTransformers) 언어 모델을 활용하여 비정형데이터로 저장된 공사일지의 작업내용을 분석 가능한 WBS (Work Breakdown Structure) 기반의 정형데이터로 변환하고 리스크 분류 및 도출 체계, 공정계획에 사용가능한 리스크 발생확률, 리스크 확률분포(심도)의 정량화 방안을 제시하였다. 제안된 프로세스를 고속도로공사 8개 공구에 적용하여, 39개 세부 공중 중 8개의 세부 공종에서 75건의 우천 공기지연 리스크를 도출하였다. K-S 검정을 통해 4개 공종에서 유의미한 확률분포를 도출하였으며 위험도를 비교하였다. 향후 본 연구에서 제시된 프로세스는 시공단계에서 발생하는 다양한 공기지연 요인의 도출 및 심도 정량화에 적용될 수 있을 것으로 기대된다.","Schedule delays present a major risk factor, as they can adversely affect construction projects, such as through increasing constructioncosts, claims from a client, and/or a decrease in construction quality due to trims to stages to catch up on lost time. Risk managementhas been conducted according to the importance and priority of schedule delay risk, but quantification of risk on the depth of scheduledelay tends to be inadequate due to limitations in data collection. Therefore, this research used the BERT (Bidirectional EncoderRepresentations from Transformers) language model to convert the contents of aconstruction log, which comprised unstructured data,into WBS (Work Breakdown Structure)-based structured data, and to form a model of classification and quantification of risk. Aprocess was applied to eight highway construction sites, and 75 cases of rain schedule delay risk were obtained from 8 out of 39 detailedwork kinds. Through a K-S test, a significant probability distribution was derived for fourkinds of work, and the risk impact wascompared. The process presented in this study can be used to derive various schedule delay risks in construction projects and to quantifytheir depth."
텍스트 요약 품질 향상을 위한 의미적 사전학습 방법론,2023,"['딥러닝', '추상 요약', '트랜스포머', '사전학습 언어 모델', 'Deep Learning', 'Abstract Summary', 'Transformer', 'Pre-trained Language Model', 'GSG']","최근 사용자에게 의미있는 정보만을 자동으로 간추리는 텍스트 자동 요약이 꾸준히 연구되고 있으며, 특히 인공신경망 모델인 트랜스포머를 활용한 텍스트 요약 연구가 주로 수행되고 있다. 다양한 연구 중 특히 문장 단위 마스킹을 통해 모델을 학습시키는 GSG 방식이 가장 주목을 받고 있지만, 전통적인 GSG는 문장의 의미가 아닌 토큰의 중복 정도에 기반을 두어 마스킹 대상 문장을 선정한다는 한계를 갖는다. 따라서 본 연구에서는 텍스트 요약의 품질을 향상시키기 위해, 문장의 의미를 고려하여 GSG의 마스킹 대상 문장을 선정하는 SbGSG(Semantic-based GSG) 방법론을 제안한다. 뉴스기사 370,000건과 요약문 및 레포트 21,600건을 사용하여 실험을 수행한 결과, ROUGE와 BERT Score 측면에서 제안 방법론인 SbGSG가 전통적인 GSG에 비해 우수한 성능을 보임을 확인하였다.","Recently, automatic text summarization, which automatically summarizes only meaningful information for users, is being studied steadily. Especially, research on text summarization using Transformer, an artificial neural network model, has been mainly conducted. Among various studies, the GSG method, which trains a model through sentence-by-sentence masking, has received the most attention. However, the traditional GSG has limitations in selecting a sentence to be masked based on the degree of overlap of tokens, not the meaning of a sentence. Therefore, in this study, in order to improve the quality of text summarization, we propose SbGSG (Semantic-based GSG) methodology that selects sentences to be masked by GSG considering the meaning of sentences. As a result of conducting an experiment using 370,000 news articles and 21,600 summaries and reports, it was confirmed that the proposed methodology, SbGSG, showed superior performance compared to the traditional GSG in terms of ROUGE and BERT Score."
대체 토큰 감지 모델을 통한 대체어 추출,2023,"['대체어 추출', '대체어', '언어 모델', 'lexical substitution', 'alternative word', 'language model']","대체어란 한 문장에서 특정 단어를 대신하여 사용해도 문장의 의미를 훼손하지 않는 단어이며, 이를 추출하는 기술은 데이터 증강 등 다양한 자연어처리 문제에 활용할 수 있다. 기존 대체어 추출 방법은 문맥에 부자연스러운 대체어를 추출할 수 있다는 문제가 있다. 이를 해결하기 위해 본 논문에서는 말뭉치에서 목표 단어가 포함된 문장을 샘플링하여 사전학습 BERT 기반 대체어 후보 생성 모델에 입력하고, 대체 토큰 감지 모델로 부적합한 대체어를 제외하여 대체어를 추출하는 방법을 제안한다. 국립국어원 문어 말뭉치 및 ㈜낱말 기본유의어 사전을 통해 검증한 결과, 본 제안 방법은 기존 방법에 비해 더 정확한 대체어를 추출한다. 또한 부적합한 대체어를 제외하는 모델로 사료될 수 있는 문법성 판단 모델보다 본 연구에서 제안한 대체 토큰 감지 모델의 대체어 추출 성능이 더 뛰어난 것을 확인하였다.","Substitutes in a sentence are words that do not change the meaning of the sentence if substituted. The task of substitution, also known as lexical substitution, can be applied to various natural language processing tasks, such as data augmentation. Traditional methods for lexical substitution may generate unnatural substitutes. To solve this problem, we propose a new method of lexical substitution. Our method samples sentences containing the target word from a corpus, inputs these sentences to the substitutes generator, which is based on the pretrained BERT, and excludes unacceptable candidates with the replaced token detection model. Verifying the proposed method with the open corpus provided by the National Institute of Korean Language and the Natmal synonym dictionary, our method extracts more accurate substitutes than traditional methods. Also, it is found that the replaced token detection model, which is proposed for lexical substitution, performs better in our experiment than the model learned by using the CoLA dataset, which can be considered to exclude unacceptable candidates."
딥러닝을 활용한 크라우드 펀딩 성공 예측 모델 연구,2023,"['Crowdfunding', 'Deep Learning', 'Language Model', 'Predictive Model', 'Text Analysis', 'Multimodal', '크라우드 펀딩', '딥러닝', '언어모델', '예측모델', '텍스트 분석', '멀티모달']",국문 초록 정보 없음,"Crowdfunding platforms have grown as a means of initial funding for startups, and they are also being used for various purposes beyond funding, such as pre-selling products for market assessment and selling the works of creators. Existing research on crowdfunding has mainly used quantitative data such as video views, image counts, and duration as variables. Some studies have incorporated unstructured text variables, utilizing metrics like the number of parts of speech, sentence length, or topics extracted through topic analysis. However, these variables often lack the contextual meaning of the text or provide limited reflection.In this study, language models are employed to extend the use of text and incorporate contextual meaning. Two models, DNN prediction models and classification models, were employed for the research. For text variables, pretrained BERT models released in 2017 and Transformer Encoder models trained directly on text data were utilized. Unlike previous research, the dependent variable was set as the number of funding supporters, and DNN was constructed using both text and numeric data. Furthermore, data featuring the increase in supporters on a daily basis was also utilized.This study collected data from Wadiz, a crowdfunding site, spanning from January 2021 to January 2023, encompassing a total of 9,755 completed funding projects. The collected data includes project categories, funding names, descriptions, main text, funding duration, funding amount, number of supporters, achievement rate, option prices, option quantities, counts of main images and videos, counts of images and videos in the main text, scroll length, and daily funding amount. By employing text in DNN models, using data analyzed by BERT and Transformer Encoder alongside numeric data, a different structural form from traditional regression models was achieved, resulting in improved outcomes. This study presents a new approach for both platform users and operators to understand and predict crowdfunding success."
ChatGPT를 활용한 AI 시인의 구현(2)-‘AI 이육사’의 생성과 시적 대화의 가능성을 중심으로,2023,"['대화형 인공지능', '챗지피티', 'AI', '이육사', '인공지능 창작물', 'Interactive artificial intelligence', 'ChatGPT', 'AI', 'Yi Yuk-sa', 'AI creation']","튜링이 ‘생각하는 기계를 만들 수는 없다’라는 전제를 부정한 이후, 다트머스의 석학들에 의해 제언된 인공지능은 몇 차례의 존폐 위기(AI Winter)에도 불구하고 혁신적인 발전을 이루었다. 생활·연구·스포츠 등 다양한 방면에서의 인공지능의 발전은 사용자 데이터의 급증, 연산 장치 능력의 약진, 그리고 딥러닝 방법론의 제안에 힘입은 바가 컸다.2022년 인공지능 SIA의 󰡔시를 쓰는 이유󰡕 발간은 지금까지 불가능하다고(혹은, 아주 오랜 시간이 필요할 것이라고) 판단되었던 인공지능의 시 창작 가능성에 대한 실제적인 답변이었다. 물론 SIA의 창작물 역시 이전까지의 인공지능 창작물에 대한 지적을 완전히 피하지는 못했으나 기반이 된 초거대 언어 모델 KoGPT의 뛰어난 성능과 12,000여 편의 방대한 사전 교육 자료를 통해 많은 부분이 개선된 것을 확인할 수 있었다.이와 같이 발전하고 있는 ‘시를 쓰는 AI’의 관점에서, 본고는 대화형 인공지능(ChatGPT)에 대한 교육을 시도한다. Bard나 ChatGPT 등 웹사이트를 통해 제공되고 있는 대화형 인공지능의 경우 SIA가 기반으로 하는 GPT-3나 이전 모델인 GPT-2, 구분되는 모델인 BERT 등과 달리 사전 교육 모델이 공개되지 않아 모델링을 통한 교육은 불가능하지만, 접근성과 범용성이 뛰어나다는 장점을 갖는다. 또, 동일 세션 내에서 입력된 프롬프트의 맥락을 읽고 유지하는 능력 또한 뛰어나다.본고는 ChatGPT(GPT-4)에 대한 ‘AI 이육사’ 교육 과정을 통해 대화형 인공지능에서 ‘AI를 이용한 시적 대화’의 가능성을 검토한다. 그리고 더 나아가 문학/창작 수업에서의 활용 가능성과 기대효과 그리고 향후 AI 이육사의 정교한 시 창작의 방향성에 대한 설정을 제언한다.","After Alan Turing disproved the premise that ""thinking machines cannot be made,"" artificial intelligence proposed by Dartmouth scholars has made innovative progress despite a number of existential crises(AI Winter). The development of artificial intelligence in various fields, such as life, research, and sports, is largely due to the increase of user data, the improvement of the performance of computing devices, and the proposal of deep learning methodology.The publication of SIA's ""The Reason for Writing Poetry"" in 2022 was a practical answer to the possibility of AI-created poetry, which was previously considered impossible (or would take a very long time). Of course, SIA's creations were not completely free from criticism of previous AI creations, but it was confirmed that many aspects were improved by the excellent performance of the underlying super-large language model KoGPT and a huge amount of pre-training data of over 12,000 pieces.From the perspective of ""AI that writes poetry"", which is developed in this way, this paper tries to train conversational AI(Chat GPT). In the case of conversational AI provided by websites such as Bard or Chat GPT, unlike GPT-3 on which SIA is based, or previous models such as GPT-2, and distinguished models such as BERT, pre-trained models are not publicly available, so training by modeling is not possible. However, it has the advantage of being highly accessible and versatile. It is also excellent at reading and maintaining the context of the prompt entered in the same session.Through the process of attempting to train “AI Yi Yuk-sa” through Chat GPT (GPT-4), this paper explores the possibility of “AI-based poetic dialog” in conversational language models. Furthermore, it suggests the possibility and expected effects of using it in literature/creative education, and setting the direction of sophisticated poetry creation of AI Yi Yuk-sa in the future."
텍스트 마이닝 기반의 모바일 화장품 앱 사용자 인식 분석,2023,"['BERT', '감성분석', '모바일 화장품앱', '텍스트마이닝', '토픽모델링']",국문 초록 정보 없음,다국어 초록 정보 없음
ALBERT 기반 감성분석을 통한 딥러닝 기업부도 예측,2023,"['A Lite BERT', 'Bidirectional and Auto-Regressive Transformers', 'bankruptcy Prediction', 'Deep Learning', 'Long Short-Term Memory', 'ALBERT', 'BART', '기업부도 예측', '딥러닝', 'LSTM']","과거 기업부도 예측에 있어서 재무정보와 주식시장 정보를 기반으로 많은 연구가 활발히 진행되어왔다. 재무정보는 공시된 정보를 활용하므로 기업의 현황을 객관적이고 표준화된 형태의 자료로 활용할 수 있다는 큰 장점이 있지만, 재무정보의 경우 분기 또는 연단위로 작성되고 각 기업의 결산 시점 이후 공시까지 일정 시간이 소요되므로 적시성이 떨어지는 한계점이 있다. 이에 본 연구에서는 각 기업의 최신 정보를 반영할 수 있는 뉴스데이터를 수집하여 정형데이터뿐만 아니라 비정형데이터까지 분석하여 인공지능 기반 기업부도 예측을 실증하였다.",다국어 초록 정보 없음
온라인 리뷰 데이터 기반의 조직몰입도 측정 체계 구축에 대한 연구,2023,"['Engagement', 'HR Analytics', 'Sentence-BERT', 'Online Review', 'Survey']",국문 초록 정보 없음,"People want to work for companies with good organizational cultures. Organizational culture is the overall atmosphere of a company, including the ways employees work and the company's operational policy. Organizational culture is the result of transferring core values containing the CEO's beliefs and management philosophy to employees. It is an intangible competitive edge that can differentiate the company from its competitors. In addition, the higher the engagement of employees in strong organizational culture, the better the management performance. Therefore, CEOs want high organizational engagement of employees and want to manage the level of engagement of employees. However, the definition of organizational engagement and the criteria to measure it differs across measuring agencies. This makes it almost impossible to compare the organizational engagement levels among peer companies and difficult to manage or improve them. Furthermore, employee surveys, the most widely used current way to measure the organizational engagement level, have some structural limitations, including the risk of potential distortion and biased answers. To address this problem, we propose a new organizational engagement measurement system using machine learning techniques on online review data about corporates. Using a large amount of data collected from a global corporate review online site, where employees voluntarily and anonymously make posts about their companies, we show that our proposed model is effective compared to the traditional survey-based methods. This new approach to measuring the organizational engagement level does not only enable employees to constantly understand their perception of the company and explain essential phenomena, but also complements the high-cost survey-based diagnostic methods."
GPT를 이용한 Git의 커밋메시지 분류모델 제안,2023,"['커밋 메시지(Commit Message)', 'BERT(Bidirectional Encoder Representations from Transformers)', 'GPT(Generative Pre-trained Transformer)']",국문 초록 정보 없음,다국어 초록 정보 없음
Self-supervised Learning Applied to Understand the Genomic Elements,2023,"['Virus classification', 'Deep learning', 'BERT model', 'Viral genome', 'Metagenome']",국문 초록 정보 없음,다국어 초록 정보 없음
공사시방서 자동 작성 프레임워크,2023,"['공사시방서', '자동 작성', 'BERT', '질의응답']",국문 초록 정보 없음,다국어 초록 정보 없음
특허 문서에서 IPC 코드 예측을 위한 2단계 딥러닝 기반 NLP 모델,2023,"['자연어 처리', '특허', 'IPC 코드', '인공지능', 'KoBART', 'BERT', 'Top-K 방법론']",국문 초록 정보 없음,다국어 초록 정보 없음
정확한 로그 객체 인식 기술,2023,"['Log Analysis', 'Pattern Recognition', 'GROK', 'Text classification', 'BERT', '로그 분석', '패턴 인식', '텍스트 분류']",국문 초록 정보 없음,다국어 초록 정보 없음
동일 주소 식별을 위한 거리 기반 유사도 알고리즘 비교,2023,"['Cosine similarity', 'Jaccard Similarity', 'Euclidean Similarity', 'Sentence-BERT']",국문 초록 정보 없음,다국어 초록 정보 없음
자연어 처리 기법을 활용한 판례 기반 모욕성 문장 분석 시스템,2023,"['insult case', 'classification', 'machine learning', 'BERT model', 'text similarity']",국문 초록 정보 없음,"With the advent of social media, there has been a significant rise in the number of individuals openly engaging in online insults, thereby emerging as a notable social issue. In order to protect users from unpleasant experiences, online portal sites employ database-driven profanity filters to render offensive content invisible. However, these filters often fall short in preventing instances where individuals insult others by judging certain words, not classified as profanity, as offensive within a specific context. Therefore, this paper aims to propose a precedent-based insult sentence analysis system, utilizing advanced natural language processing techniques. The system leverages a deep learning model, rooted in precedents, to infer the likelihood of guilt associated with an insult sentence. Furthermore, the system presents users with comparable precedents through similarity analysis. The ultimate model was chosen based on the accuracy of the test dataset and the training dataset while ensuring enhanced accessibility by deploying it on the web."
불균형 데이터 처리를 통한 소프트웨어 요구사항 분류 모델의 성능 개선에 관한 연구,2023,"['Requirements Classification', 'Imbalanced Data', 'Data Augmentation', 'Undersampling', 'BERT', '요구사항 분류', '불균형 데이터', '데이터 증강', '언더샘플링']",국문 초록 정보 없음,"Software requirements written in natural language may have different meanings from the stakeholders’ viewpoint. When designing an architecture based on quality attributes, it is necessary to accurately classify quality attribute requirements because the efficient design is possible only when appropriate architectural tactics for each quality attribute are selected. As a result, although many natural language processing models have been studied for the classification of requirements, which is a high-cost task, few topics improve classification performance with the imbalanced quality attribute datasets. In this study, we first show that the classification model can automatically classify the Korean requirement dataset through experiments. Based on these results, we explain that data augmentation through EDA(Easy Data Augmentation) techniques and undersampling strategies can improve the imbalance of quality attribute datasets, and show that they are effective in classifying requirements. The results improved by 5.24%p on F1-score, indicating that handling imbalanced data helps classify Korean requirements of classification models. Furthermore, detailed experiments of EDA illustrate operations that help improve classification performance."
자율주행차량 서비스에서 할루시네이션 보안에 대한 소고 (인공환각의 오답과 편향적 판단을 예방하는 측면에서),2023,"['autonomous vehicle', 'GPT', 'artificial nural ntwork', 'BERT', 'Hallucination']",국문 초록 정보 없음,다국어 초록 정보 없음
지속 가능한 비즈니스와 기술 혁신을 위한 스마트 컨설팅 접근법: 국내 건설 업종과 IT 업종 사례 분석,2023,"['Business Model', 'Business Model Canvas', 'BERT Model', 'Deep learning', 'Text Mining']",국문 초록 정보 없음,다국어 초록 정보 없음
Exploring Current Trends of MIS Profession in Egypt,2023,"['MIS professionals', 'Job ads', 'Egypt', 'BERT', 'Topic modeling']",국문 초록 정보 없음,다국어 초록 정보 없음
리뷰 데이터 분석을 통한 중소기업 해외수출 시장 추천에 대한 연구,2023,"['리뷰 분석', '중소기업 수출', '해외시장 추천', '자연어 처리', 'Bert', '레이더 차트']",국문 초록 정보 없음,다국어 초록 정보 없음
한국어 데이터를 활용한 data augmentation,2023,"['데이터 증강', '딥러닝', 'Data Augmentation', 'Deep Learning', 'transformer', 'BERT', 'GPT']","오늘날 자연어 처리 분야의 발달에 따라 text 데이터 증강의 중요성이 강조되고 있다. 왜냐하면 모델의 정확도를 향상시키고 싶을 때, 자원이 한정된 현실에서 데이터 증강은 필수적이기 때문이다. 그러나 text 데이터 증강은 단어의 위치를 바꾸고 단어를 제거하는 등의 데이터를 변형하는 과정에서 원래의 뜻과 달라질 위험이 있다. 또한, 구어체로 이루어진 데이터의 경우, 문법에 맞지 않는 데이터가 많기 때문에 학습이 끝난 후 모델이 표준어가 아닌 문장을 입력으로 받았을 때 문장을 이해하지 못하는 경우가 있다. 따라서 본 논문에서는 이러한 문제점들을 해결하기 위해, 문장 데이터의 라벨을 보존하며 데이터를 증강하고, 문법에 맞지 않는 문장을 원본 데이터에 추가하는 증강 방법을 제안한다.","With the development of natural language processing today, the importance of text data augmentation is being emphasized. This is because when you want to improve the accuracy of the model, data augmentation is essential in a reality with limited resources. However, text data augmentation risks being different from the original meaning in the process of transforming data, such as changing the position of words and removing words. In addition, in the case of colloquial data, there are many non-grammatical data, so after learning, the model may not understand the sentence when it receives a sentence that is not a standard language as an input. Therefore, in order to solve these problems, this paper proposes an augmented method that preserves the label of sentence data, enhances data, and adds non-grammatical sentences to the original data."
PatentQ&A: 트랜스포머 모델을 이용한 신경망 검색 시스템 제안,2023,"['신경망 검색', '트랜스포머', '특허 도메인', '버트', 'neural search', 'transformer', 'patent domain', 'BERT']",최근 신경망 검색은 통계적 방법에 기반한 검색을 뛰어넘어 의미에 기반한 검색을 가능하게 하며 오타가 있어도 정확한 검색 결과를 찾을 수 있게 한다. 본 논문에서는 특허에 전문 지식이 없는 일반인이 일반 용어를 사용하여 특허 정보를 검색할 경우 사용자 질문 의도에 가장 근접한 답변을 보여주는 신경망 기반 특허 Q&A 검색 시스템을 제안한다. 특허청 홈페이지에 게시된 특허고객 상담 데이터로 특허 데이터 셋을 구축하였다. 사용자가 입력한 질문에 대한 유사한 질문을 추출하고 우선순위를 다시 지정하기 위해 특허 데이터 셋으로 미세조정한 Patent-KoBERT(Triplet)과 Patent-KoBERT(CrossEntropy)를 사용하였다. 실험 결과 Mean Reciprocal Rank(MRR)과 Mean Average Precision(MAP)의 수치는 0.96으로 사용자가 입력한 질문 의도와 가장 유사한 답변을 잘 선정한다는 것을 확인할 수 있다.,"Recent neural network search has enabled semantic search beyond search based on statistical methods, and finds accurate search results even with typos. This paper proposes a neural network-based patentQ&A search system that provides the closest answer to the user's question intention when a general public without patent expertise searches for patent information using general terms. A patent dataset was constructed using patent customer consultation data posted on the Korean Intellectual Property Office website. Patent-KoBERT (Triplet) and Patent-KoBERT (CrossEntropy) were fine-tuned as patent datasets were used to extract similar questions to questions entered by the user and re-rank them. As a result of the experiment, values of Mean Reciprocal Rank (MRR) and Mean Average Precision (MAP) were 0.96, confirming that answers most similar to the intention of the user input were well selected."
법률 약관조항의 유리성 판단을 위한 모델 성능 비교 연구,2023,"['Legal clause provisions', 'Favorability assessment', 'Linear SVM', 'Random Forest', 'XGBoost', 'BERT', 'Bi-LSTM', 'GRU']",국문 초록 정보 없음,다국어 초록 정보 없음
Framework for Creating Private LLM and performing Multi document Q&A on Safety Manuals,2023,"['AI', 'Llama2', 'T5', 'Databricks', 'Azure', 'Private LLM', 'PEFT', 'Document Retrieval']",국문 초록 정보 없음,"Open-source large language models, including llama2, Zephyr, T5, and BERT, have emerged as transformative tools with vast potential across diverse industries. These models empower organizations to leverage the capabilities of natural language understanding and generation in unprecedented ways. As large language models (LLMs) continue to revolutionize sectors such as healthcare, education, and beyond, they are being deployed to automate various tasks and enhance customer service. The principal hurdles encountered by enterprises in their utilization of open-source Large Language Models (LLMs) pertain to the domains of Data Privacy and Security. LLMs necessitate the acquisition of extensive datasets for proficient training, frequently encompassing data of a sensitive and confidential nature. Safeguarding this data and ensuring adherence to data privacy regulations is paramount. Moreover, the intricacy lies in the substantial computational resources essential for the training and deployment of LLMs, which engender significant financial costs and mandate specialized infrastructure and expertise.This paper introduces a framework for hosting private Large Language Models (LLMs) by fine-tuning opensource models through the application of the PEFT quantization method within the Databricks platform. Furthermore, we have developed a question-answering system for safety manuals capable of providing answers to inquiries, even when the supporting evidence is dispersed across multiple documents, some of which may be quite extensive."
딥러닝 언어모델을 활용한 구조적토픽모델링(STM) 기반의 지식그래프 탐색적 연구,2023,"['인공지능', '지식그래프', '구조적토픽모델(STM)', 'Topic-based Knowledge graph BERT 모델']",국문 초록 정보 없음,다국어 초록 정보 없음
데이터로 판소리 읽기: 完板本 「沈淸傳」을 대상으로,2023,"['Pansori', 'Shimchung-jeon', 'data', 'emotion part', 'whole', 'narrative structure', 'digital humanity', '판소리', '심청전', '데이터', '감정', '부분', '전체', '서사 구조', '디지털 인문학']",국문 초록 정보 없음,"This article presents an analysis of “Shimchung-jeon” using digitalized data. The initial focus involves employing the BERT model to investigate whether the narrative features of Pansori, traditionally considered lacking complete plot structures, are evident on the actual digitalized data. The analysis reveals that the 10 narrative paragraphs of “Shimchung-jeon” exhibit the ‘independence of the part,’ a characteristic of Pansosi, as they lack predictability and connection between paragraphs. However, they move toward a predictable ending through the narrative chain of these paragraphs, demonstrating that the ‘parts’ of pansori, while independent function within the overall narrative.To delve deeper into this, the article employs ‘emotion data’ analysis. The emotion data derived from “Shimchung-jeon” illustrates that the narrative chain within the work is more oriented toward securing a sense of narrative rhythm while harmonizing positive and negative emotions than in following internal cause and effect. Emotions serve as a mechanism to secure the uniqueness of the narrative paragraph while driving the narrative of the entire “Shimchungjeon” to a complete formality."
오토인코더 기반 키워드 임베딩을 통한 문서 분류 방법론,2023,"['Deep Learning', 'Document Classification', 'Keyword Embedding', 'Document Embedding', 'Pre-Trained Language Model', '딥러닝', '문서 분류', '단어 임베딩', '문서 임베딩', '사전학습언어모델']",국문 초록 정보 없음,"In this study, we propose a Dual Approach methodology to enhance the accuracy of document classifiers by utilizing both contextual and keyword information. Firstly, contextual information is extracted using Google's BERT, a pre-trained language model known for its outstanding performance in various natural language understanding tasks. Specifically, we employ KoBERT, a pre-trained model on the Korean corpus, to extract contextual information in the form of the CLS token. Secondly, keyword information is generated for each document by encoding the set of keywords into a single vector using an Autoencoder. We applied the proposed approach to 40,130 documents related to healthcare and medicine from the National R&D Projects database of the National Science and Technology Information Service (NTIS). The experimental results demonstrate that the proposed methodology outperforms existing methods that rely solely on document or word information in terms of accuracy for document classification."
사회적 약자를 위한 법률 사각지대 탐지 프레임워크,2023,[],국문 초록 정보 없음,다국어 초록 정보 없음
Analysis of Impact Between Data Analysis Performance and Database,2023,"['Data Analysis', 'Database Performance', 'Data Statistics', 'Data Visualization', 'Digital Humanities']",국문 초록 정보 없음,"Engineering or humanities data are stored in databases and are often used for search services. While the latest deep-learningtechnologies, such like BART and BERT, are utilized for data analysis, humanities data still rely on traditional databases.Representative analysis methods include n-gram and lexical statistical extraction. However, when using a database, performancelimitation is often imposed on the result calculations. This study presents an experimental process using MariaDB on a PC,which is easily accessible in a laboratory, to analyze the impact of the database on data analysis performance. The findingshighlight the fact that the database becomes a bottleneck when analyzing large-scale text data, particularly over hundreds ofthousands of records. To address this issue, a method was proposed to provide real-time humanities data analysis web servicesby leveraging the open source database, with a focus on the Seungjeongwon-Ilgy, one of the largest datasets in the humanitiesfields."
감정 인지를 위한 음성 및 텍스트 데이터 퓨전: 다중 모달 딥 러닝 접근법,2023,[],국문 초록 정보 없음,"Speech emotion recognition(SER) is one of the interesting topics in the machine learning field. By developing multi-modal speech emotion recognition system, we can get numerous benefits. This paper explain about fusing BERT as the text recognizer and CNN as the speech recognizer to built a multi-modal SER system."
초거대 AI의 기반모델(Foundation Model) 개념 및 표준화 동향,2023,[],"초거대 인공지능(이하 초거대 AI)은 자연어처리, 이미지인식, 의사결정 등에서 인간 수준의 복잡한 작업을 수행하기 위하여 방대한 양의 파라미터와 데이터로 학습한 대규모 AI 시스템 혹은 서비스를 말한다. 일반적으로 수천억개 이상의 파라미터를 가지는 대규모 인공신경망을 사용할 때 초거대 AI라고 부르며 GPT-3, GPT-4, BERT, LaMDA, CLIP 등이 대표적인 초거대 인공신경망이다.  초거대 AI의 개발은 기존 딥러닝 기반의 AI 개발과는 다르게 기반모델(Foundation Model)이라고 불리는 사전학습된 초거대 인공신명망 모델을 구축하고 이를 다양한 도메인의 데이터로 전이학습하여 새로운 도메인 혹은 태스크에 적용하는 방식의 개발 방법론이 사용되고 있다. 이러한 개발 방법론은 기존 딥러닝 기반의 AI 개발이 특정 태스크 혹은 한정된 태스크에 특화된 훈련 방식을 사용하는 것과 달리 하나의 인공신경망이 여러 태스크를 해결할 수 있도록 훈련한다는 개념적 차이가 있다.  본 고에서는 이와 같은 특징의 초거대 AI와 기반모델이 등장하게 된 배경과 기본 개념, 동향 등을 살펴보고 관련 표준화 동향을 소개하고자 한다.",다국어 초록 정보 없음
유튜브 댓글을 통해 살펴본 버추얼 인플루언서에 대한 인식 연구 -캐릭터 디자인에 대한 긍부정 감성 반응을 중심으로-,2023,"['버추얼 인플루언서', '캐릭터 디자인', '유튜브 댓글', '텍스트마이닝', '감성분석', 'Virtual influencer (VI)', 'Character design', 'YouTube comments', 'Text-mining', 'Sentiment analysis']",국문 초록 정보 없음,"This study analyzed users' emotional responses to VI character design through YouTube comments. The researchers applied text-mining to analyze 116,375 comments, focusing on terms related to character design and characteristics of VI. Using the BERT model in sentiment analysis, we classified comments into extremely negative, negative, neutral, positive, or extremely positive sentiments. Next, we conducted a co-occurrence frequency analysis on comments with extremely negative and extremely positive responses to examine the semantic relationships between character design and emotional characteristic terms. We also performed a content analysis of comments about Miquela and Shudu to analyze the perception differences regarding the two character designs. The results indicate that form elements (e.g., voice, face, and skin) and behavioral elements (e.g., speaking, interviewing, and reacting) are vital in eliciting users' emotional responses. Notably, in the negative responses, users focused on the humanization aspect of voice and the authenticity aspect of behavior in speaking, interviewing, and reacting. Furthermore, we found differences in the character design elements and characteristics that users expect based on the VI's field of activity. As a result, this study suggests applications to character design to accommodate these variations."
산업현장 오프라인 문서의 디지털화를 위한 딥러닝 기반 문장 분리,2023,[],"본 연구는 산업현장 오프라인 문서로부터 텍스트를 추출하여 양질의 학습 데이터를 생성 하기 위한 문서 디지털화(Document Digitization) 연구의 일부로, Optical Character Recognition(OCR)으로 문서로부터 인식한 연속적인 단어들 중 어디까지가 개별적인 문장인지 분리하는 기술을 개발함. 자연어처리 분야에서 좋은 성능을 보이는 Word2Vec. BERT, GPT 등의 모델을 활용하여 단어를 숫자 벡터로 인베딩 하고, RNN과 CNN 등 딥러닝 아키텍처를 활용하여 문장 분리를 수행함.",다국어 초록 정보 없음
확률적 소프트 프롬프트: 프롬프트를 통한 저자원 NLI의 강인성 향상,2023,[],국문 초록 정보 없음,"In environments with limited resources, conventional techniques such as Pretrained Language Models(PLMs) frequently encounter overfitting, leading to suboptimal performance. This paper presents Stochastic Soft Prompt Tuning(SSPT), an innovative method that leverages stochasticity in soft prompts to improve model robustness and better navigate low-resource scenarios. We evaluated SSPT’s effectiveness using the Cross-Lingual Natural Language Inference (XNLI) dataset, a low-resource corpus containing English, German, and French entries. SSPT demonstrated a remarkable performance, outpacing a fine-tuned Multilingual BERT by 8%p, 11%p, and 5%p in English, Germa, and French respectively. These results accentuate the robustness and adaptability of SSPT in low-resource environments, marking it as a promising strategy for enhancing performance in these challenging situations."
Text Mining을 활용한 북한의 도발 수준 및 형태 예측,2023,[],"Text Mining을 활용하여 특정 이벤트의 발생 가능성을 파악하기 위한 연구는 Machine Learning의 발달과 더불어 활발히 진행되어 왔으며, 북한의 도발 또한 Text Mining을 활용하여 예측하는 것이 가능할 것으로 보인다. 그러나 양질의 학습데이터 확보 어려움과 이벤트 분류의 난이도로 인해 이에 대한 연구는 다른 분야에 비해 미흡한 수준이다. 이 과정에서 본 연구는 pre-trained BERT 모델을 활용하여 북한의 도발행태를 기존의 연구와 같은 이진분류(도발징후 또는 평시)가 아닌 다차원으로 분류할 수 있는 기준을 정립하고 학습데이터를 북한의 ‘조선중앙통신’ 원문과 ‘국내언론지’ 기사로 구분하여 비교 분석했다. 이를통해 국내언론지 기사를 활용하는 것보다 ‘조선중앙통신’ 원문 자료를 활용하는 것이 예측의 정확도를 높일 수 있다는 점을 확인했다. 본 연구는 북한의 도발에 대한 과학적 예측을 통해 정보로서의 가치를 높이고 정성적인 전문가 판단의 신뢰도를 향상시킬수 있는 방안을 제시했다는 점에서 의의가 있다.",다국어 초록 정보 없음
패킷 페이로드 분석을 활용한 트랜스포머 기반 침입탐지시스템,2023,"['자연어 처리', '침입탐지시스템', '패킷 페이로드', '트랜스포머', 'UNSW-NB15', 'Natural Language Processing', 'IDS', 'Packet Payload', 'Transformer', 'UNSW-NB15']",국문 초록 정보 없음,"Intrusion detection systems that learn metadata of network packets have been proposed recently.However these approaches require time to analyze packets to generate metadata for model learning, and time to pre-process metadata before learning. In addition, models that have learned specific metadata cannot detect intrusion by using original packets flowing into the network as they are. To address the problem, this paper propose a natural language processing-based intrusion detection system that detects intrusions by learning the packet payload as a single sentence without an additional conversion process.To verify the performance of our approach, we utilized the UNSW-NB15 and Transformer models. First, the PCAP files of the dataset were labeled, and then two Transformer (BERT, DistilBERT) models were trained directly in the form of sentences to analyze the detection performance. The experimental results showed that the binary classification accuracy was 99.03% and 99.05%, respectively, which is similar or superior to the detection performance of the techniques proposed in previous studies. Multi-class classification showed better performance with 86.63% and 86.36%, respectively."
컴퓨터언어학 분야 한국어 구문 연구의 현황,2023,"['Computational Linguistics', 'dependency parsing', 'language model', 'Transformer', 'corpus', '컴퓨터언어학', '의존 구문 분석', '언어 모델', '트랜스포머', '말뭉치']","본 논의에서는 컴퓨터언어학 분야에서 고려되는 ‘구문’의 정의를 살펴보고 이들이 연구에서 다루어지는 양상을 확인하였다. 컴퓨터언어학 및 자연언어처리 분야의 연구에서의 구문은 다른 언어학 분야와 크게 다른 정의를 내리고 있지는 않으나, 특히 문장을 이루는 통사적, 의미적 구조 정보와 깊은 관련이 있다고 볼 수 있다. 문장 내의 단어 혹은 다른 단위의 구성 성분들이 서로 만나 이루는 관계를 학습한 언어 모델이 그 지식을 활용해 다양한 언어 데이터를 처리하는 것이다. 본고에서는 ‘구문 분석 말뭉치’라는 이름으로 제공되어 한국어 컴퓨터언어학 연구에서 주로 분석 및 활용되는 데이터에 대해 설명하고, 이와 관련하여 이루어지고 있는 한국어 구문 분석 연구 및 배포된 라이브러리를 소개하였다. 또한 이러한 데이터가 포함하는 구문 정보를 학습하고 활용하는 BERT, GPT 등 언어 모델의 원리인 어텐션 메커니즘이 곧 문장 혹은 문서 내 구성 성분 사이의 관계성에 기반한 것임을 살펴보았다.",다국어 초록 정보 없음
낯선 데이터를 활용한 과잉신뢰 완화 텍스트 증강 기법,2023,"['딥러닝', '자연어처리', '데이터 증강']",최근 자연어 처리 모델은 대용량 데이터를 기반으로 사전학습(pretrain) 후 미세조정(fine tuning)을 하는 방식을 통해서 좋은 성과를 보이고 있다. 미세조정 과정에서 사용되는 데이터 수가 부족할 때 학습 데이터에 지나치게 의존하는 과적합 문제를 데이터 증강을 통해서 완화 할 수 있다. 하지만 기존의 데이터 분포와 크게 벗어나지 않는 증강은 모델이 높은 확신을 가지고 잘못된 예측을 하는 문제를 발생시킬 수 있다. 본 논문에서는 과잉확신 문제를 해결하기 위해 기존 데이터세트와 유사도가 적은 다른 데이터세트을 추가로 활용하는 데이터 증강 기법을 제안한다. Sentence BERT(SBERT)를 활용하여 한글 딥러닝 데이터 세트간의 유사도를 측정하는 방식을 통하여 낯선 데이터 세트를 규정한다. 제안된 기법은 다른 데이터 증강 기법들에 비해 과잉확신 완화에 효과가 있음을 확인할 수 있었다. 해당 기법을 통해 Korean hate speech 분류 작업에서 기준치 대비 3.98%P 향상되었으며 기존 기법과 비교해 2.39%p 의 성능 향상을 확인할 수 있었다.,다국어 초록 정보 없음
Unveiling the Enigma through Deep Learning : Exploring Multifaceted Human Personality Traits,2023,"['Personality Traits', 'Convolutional Neural network', 'Deep Learning', 'word embedding']",국문 초록 정보 없음,"In response to the demand for impartial and precise personality testing, this study presents a unique multi-modal method for predicting personality traits in collaborative settings. Conventional approaches that depend on surveys frequently create biases, which has led to the investigation of raw, subconscious open writing as a rich source of personality information. This study uses deep learning algorithms in conjunction with the stream of consciousness storytelling approach to uncover personality traits by utilizing both textual and gestural data. We use BERT word embedding to improve contextual understanding and convolutional networks for the textual component. Compared to earlier methods, this methodology offers a more dependable way for text-based personality evaluation. Moreover, we present facial recognition as an extra factor for personality evaluation, providing a whole framework with a wide range of uses. We conducted studies in a collaborative setting to assess the effectiveness of our strategy, and we obtained encouraging findings. This multimodal method changes the way people collaborate and opens doors to a wide range of applications, such as mental health diagnosis, job interviews, and forensic investigations. A thorough grasp of personality features is expected to improve personalization and cooperation, leading to more efficient collaboration and improved decision-making."
이미지 캡셔닝 기반의 새로운 위험도 측정 모델,2023,"['Intelligent Surveillance Systems', 'Image Captioning', 'Risk Level Assessment']",국문 초록 정보 없음,"Purpose We introduce a groundbreaking surveillance system explicitly designed to overcome the limitations typically associated with conventional surveillance systems, which often focus primarily on object-centric behavior analysis.Design/methodology/approach The study introduces an innovative approach to risk assessment in surveillance, employing image captioning to generate descriptive captions that effectively encapsulate the interactions among objects, actions, and spatial elements within observed scenes. To support our methodology, we developed a distinctive dataset comprising pairs of [image-caption-danger score] for training purposes. We fine-tuned the BLIP-2 model using this dataset and utilized BERT to decipher the semantic content of the generated captions for assessing risk levels.Findings In a series of experiments conducted with our self-constructed datasets, we illustrate that these datasets offer a wealth of information for risk assessment and display outstanding performance in this area. In comparison to models pre-trained on established datasets, our generated captions thoroughly encompass the necessary object attributes, behaviors, and spatial context crucial for the surveillance system. Additionally, they showcase adaptability to novel sentence structures, ensuring their versatility across a range of contexts."
GeoQA를 위한 자연어-쿼리 데이터셋 분류에 관한 연구,2023,"['자연어처리', '공간관련 지식베이스 질의응답시스템', '의미분석', '데이터셋 구축', 'Natural Language Processing', 'Knowledge-base', 'Geographical Questions Answering', 'Dataset Constriction']",국문 초록 정보 없음,"Recent advancements in the field of Natural Language Processing (NLP) have led to active research in QA (Question Answering) systems. In the domain of geographic information as well, research is ongoing on Geographic Knowledge Base Question Answering(GeoKBQA) systems, which can answer user's spatial queries through a KB (Knowledge-Base). In this study, we focused on semantic parsing, one of the essential technologies for GeoKBQA. To construct a natural language-query dataset necessary for semantic parsing, we utilized the Mintaka and NLMAPS datasets, which are labeled on spatial natural language questions. We trained a BERT model using these datasets to classify spatial questions. Through the model, we collected spatial-related data from the WebQuestionsSP and ComplexWebQuestions datasets, which consist of natural questions and queries. The quality of the dataset was assessed using various evaluation techniques."
트랜스포머 기반 효율적인 자연어 처리 방안 연구,2023,"['machine learning', 'natural language processing', 'transformer', 'artificial intelligence']",국문 초록 정보 없음,"The natural language processing models used in current artificial intelligence are huge, causing various difficulties in processing and analyzing data in real time. In order to solve these difficulties, we proposed a method to improve the efficiency of processing by using less memory and checked the performance of the proposed model. The technique applied in this paper to evaluate the performance of the proposed model is to divide the large corpus by adjusting the number of attention heads and embedding size of the BERT[1] model to be small, and the results are calculated by averaging the output values of each forward. In this process, a random offset was assigned to the sentences at every epoch to provide diversity in the input data. The model was then fine-tuned for classification. We found that the split processing model was about 12% less accurate than the unsplit model, but the number of parameters in the model was reduced by 56%."
MoodChartBot: AI 챗봇을 활용한 기분기록지  어플리케이션 설계 및 구현,2023,"['Human Computer Interaction', 'Chatbot', 'Artificial Intelligence', 'Mood Chart', 'Mood Detection']",국문 초록 정보 없음,"The overall level of depression in Korean society has become substantially high. It suggests  the urgency of preventing the prognosis of severe depression as well as detecting at-risk populations. The previous studies showed that reporting a mood chart regularly is essential for the early detection of depressive disorder. In this regard, the current study aims to design and implement a mobile application which makes it easier to access mood charts than the traditional paper-based method. Specifically, the application includes an AI Chatbot based on the BERT model for reporting mood charts on a regular basis. Additionally, our system adopted  mood charts which are now officially utilized in Seoul National University Bundang Hospital. We expect that our system provides an opportunity for at-risk people to identify their emotional state while lowering psychosocial burden prior to officially diagnosed with the disorder. Furthermore, we hope it can help users to feel less burdened and familiar with the task of filling out their mood state."
효율적인 Transformer 모델 경량화를 위한 구조화된 프루닝,2023,"['Transformer', '-']",국문 초록 정보 없음,"With the recent development of Generative AI technology by IT giants, the size of the transformer model is increasing exponentially over trillion won. In order to continuously enable these AI services, it is essential to reduce the weight of the model. In this paper, we find a hardware-friendly structured pruning pattern and propose a lightweight method of the transformer model. Since compression proceeds by utilizing the characteristics of the model algorithm, the size of the model can be reduced and performance can be maintained as much as possible. Experiments show that the structured pruning proposed when pruning GPT-2 and BERT language models shows almost similar performance to fine-grained pruning even in highly sparse regions. This approach reduces model parameters by 80% and allows hardware acceleration in structured form with 0.003% accuracy loss compared to fine-tuned pruning."
사회문제 해결 연구보고서 기반 문장 의미 식별 데이터셋 구축,2023,"['사회문제 해결 연구', '자연어처리', '데이터구축', '사전학습 언어모델', 'Social Problem-Solving Research', 'Natural Language Process', 'Data Building', 'Pre-trained Language Model']","일반적으로 사회문제 해결 연구는 과학기술을 활용하여 다양한 사회적 현안들에 의미있는 해결 방안을 제시함으로써 중요한 사회적 가치를창출하는 것을 연구 목표로 한다. 그러나 사회문제와 쟁점을 완화하기 위하여 많은 연구들이 국가적으로 수행되었음에도 불구하고 여전히 많은사회문제가 남아 있는 상황이다. 사회문제 해결 연구의 전 과정을 원활하게 하고 그 효과를 극대화하기 위해서는 사회적으로 시급한 현안들에대한 문제를 명확하게 파악하는 것이 중요하다. 사회문제 해결과 관련된 기존 R&D 보고서와 같은 자료에서 중요한 사안을 자동으로 식별할 수있다면 사회문제 파악 단계가 크게 개선될 수 있다. 따라서 본 논문은 다양한 국가 연구보고서에서 사회문제와 해결방안을 자동으로 감지하기위한 기계학습 모델을 구축하는 데에 필수적인 데이터셋을 제안하고자 한다. 우선 데이터를 구축하기 위해 사회문제와 쟁점을 다룬 연구보고서를총 700건 수집하였다. 수집된 연구보고서에서 사회문제, 목적, 해결 방안 등 사회문제 해결과 관련된 내용이 담긴 문장을 추출 후 라벨링을 수행하였다. 또한 4개의 사전학습 언어모델을 기반으로 분류 모델을 구현하고 구축된 데이터셋을 통해 일련의 성능 실험을 수행하였다. 실험 결과 KLUE-BERT사전학습 언어모델을 미세조정한 모델이 정확도 75.853%, F1 스코어 63.503%로 가장 높은 성능을 보였다.",다국어 초록 정보 없음
삼중항 손실 기반 사용자 분석을 통한 추천 시스템 개선,2023,"['User analysis', 'Natural language processing', 'Metric learning', 'Triplet loss', '사용자 분석', '자연어 처리', '메트릭 학습', '삼중항 손실']","서비스 운영주체가 사용자들 각각에 맞는 제품을 추천하기 위해 사용자의 특징을 아는 것은 중요하다. 사용자의 특징이 될 수 있는 요소들은 성격, 사회계층, 취미 등이 존재한다. 사용자들의 정확한 특징 정보를 얻는 데에는 설문 조사가 유용하다. 하지만, 개인정보와 관련된 이유로 공개를 꺼리는 경우가 많다. 반면, 사용자들은 블로그나 소셜 네트워크 서비스의 게시물을 통해 개인의 특징을 자연스레 드러낸다. 본 연구에서는 삼중항 손실을 기반으로 게시된 블로그 글에서 사용자들의 특징 정보의 추출 가능성을 확인하였다. 거대 언어 처리 모델인 Sentence-BERT를 통해 블로그 게시글의 정보를 잠재공간에 투영하였다. 투영된 정보들을 삼중항 손실함수를 이용해 비슷한 특징일수록 가깝게, 다른 특징일수록 멀게 위치하게 하여 사용자들의 특징이 구별되도록 학습을 진행하였다. 이러한 게시물을 통한 사용자의 특성 분석은 개인화된 추천 시스템의 개선에 활용될 수 있을 것으로 기대된다.","A service provider must understand the unique characteristics of the users to recommend appropriate products. Factors such as personality, social class, and hobbies can be used to identify the user and improve recommendations. This information can be obtained through direct questioning or analyzing user-generated content such as blog posts. This study uses a large language model and transfer learning to extract specific information, such as taste and knowledge, from text. The author’s characteristics are then embedded using a recurrent neural network and a triplet loss metric learning methodology to distinguish between users. Qualitative insights into their similarities were then obtained from analyzing the label distribution in the embedding space."
긴급재난 대응용 5G 이동 기지국을 위한 대기공간 광통신 장치의 제작과 특성평가,2023,"['Wireless Optical Communication', 'FSO', 'PAT']",국문 초록 정보 없음,"In this paper, a free space optical communication device that can be used in a mobile base station of several km or less was fabricated and its characteristics were investigated. To overcome the loss due to atmospheric transmission, an optical fiber amplifier (EDFA) with an output of 23 dBm or more was used. In order to increase the focusing speed and miniaturization of the laser beam, an optical lens was manufactured, and a transmission lens was designed to have beam divergence within the range of 1.5 to 1.8 [mrad]. A PT module that controls PAN/TILT was fabricated in order to reduce pointing errors and effective automatic alignment between transceiver devices. In this study, Reed-Solomon (RS) code was used to maintain the transmission quality above a certain level. It was manufactured to be able to communicate at a wireless distance of 300m in a weather situation with visibility of 300m. For performance measurement, it was measured using BERT and eye pattern analyzer, and it was confirmed that BER can be maintained at 2.5Gbps."
Korean Text to Gloss: Self-Supervised Learning approach,2023,"['Sign Language Production', 'Neural Machine Translation', 'Korean Corpus']",국문 초록 정보 없음,"Natural Language Processing (NLP) has grown tremendously in recent years. Typically, bilingual, and multilingual translation models have been deployed widely in machine translation and gained vast attention from the research community. On the contrary, few studies have focused on translating between spoken and sign languages, especially non-English languages. Prior works on Sign Language Translation (SLT) have shown that a mid-level sign gloss representation enhances translation performance. Therefore, this study presents a new large-scale Korean sign language dataset, the Museum-Commentary Korean Sign Gloss (MCKSG) dataset, including 3828 pairs of Korean sentences and their corresponding sign glosses used in Museum-Commentary contexts. In addition, we propose a translation framework based on self-supervised learning, where the pretext task is a text-to-text from a Korean sentence to its back-translation versions, then the pre-trained network will be fine-tuned on the MCKSG dataset. Using self-supervised learning help to overcome the drawback of a shortage of sign language data. Through experimental results, our proposed model outperforms a baseline BERT model by 6.22%."
RelCurator: a text mining-based curation system for extracting gene–phenotype relationships specific to neurodegenerative disorders,2023,['Curation system · Deep learning · Gene–phenotype relationship · Neurodegenerative disorders'],국문 초록 정보 없음,"Background The identification of gene–phenotype relationships is important in medical genetics as it serves as a basis for precision medicine. However, most of the gene-phenotype relationship data are buried in the biomedical literature in textual form.Objective We propose RelCurator, a curation system that extracts sentences including both gene and phenotype entities related to specific disease categories from PubMed articles, provides rich additional information such as entity taggings, and predictions of gene–phenotype relationships.Methods We targeted neurodegenerative disorders and developed a deep learning model using Bidirectional Gated Recurrent Unit (BiGRU) networks and BioWordVec word embeddings for predicting gene–phenotype relationships from biomedical texts. The prediction model is trained with more than 130,000 labeled PubMed sentences including gene and phenotype entities, which are related to or unrelated to neurodegenerative disorders.Results We compared the performance of our deep learning model with those of Bidirectional Encoder Representations from Transformers (BERT), Support Vector Machine (SVM), and simple Recurrent Neural Network (simple RNN) models. Our model performed better with an F1-score of 0.96. Furthermore, the evaluation done using a few curation cases in the real scenario showed the effectiveness of our work. Therefore, we conclude that RelCurator can identify not only new causative genes, but also new genes associated with neurodegenerative disorders’ phenotype.Conclusion RelCurator is a user-friendly method for accessing deep learning-based supporting information and a concise web interface to assist curators while browsing the PubMed articles. Our curation process represents an important and broadly applicable improvement to the state of the art for the curation of gene–phenotype relationships."
행정형법의 특성,2023,"['행정형법', '행정범', '형법총칙', '과실범', '양벌규정', '통고처분', 'Verwaltungsstrafrecht', 'Verwaltungsübertretung', 'Allgemeines Strafrecht', 'Fahrlässige Straftat', 'Doppelte Strafbarkeit', 'Einen Bescheid ausstellen']",국문 초록 정보 없음,"Verwaltungsstrafrecht ist per definitionem die Gesamtheit der Gesetze   und Verordnungen, die Verstöße gegen Verwaltungspflichten unter Strafe stel-len. Eine dem Verwaltungsstrafrecht unterliegende Verwaltungsübertretung   wird als Straftat geahndet, weil diese gegen ein gesetzliches Gebot oder Ver-bot zur Verwirklichung von Verwaltungszwecken verstößt, im Gegensatz zu  einer Straftat, die ohne gesetzliche Vorschrift oder Verbot strafrechtlich ver-  folgt wird, weil die Handlung selbst sittenwidrig, asozial oder kriminell ist. Das Verwaltungsstrafrecht bestraft die „strafrechtlich vorgeschriebene Strafe“  für das Delikt „Verletzung von Verwaltungspflichten“. Dieses hat Charakter  und Wesen des Verwaltungsrechts, aber gleichzeitig auch des Strafrechts,   weil bei der Strafverfolgung die Grundsätze des Strafrechts zur Anwendung  kommen. Im Zusammenhang mit der Anwendung von strafrechtlichen Grund-sätzen stellt sich die Frage nach dem Umfang des Verschuldens bei fahrläs- sigen Straftaten. Auch Verwaltungsübert- retungen setzen Vorsatz voraus, und fahrlässige Straftaten werden nur bei besonderen gesetzlichen Bestimmungen unter Strafe gestellt. Wir widersprechen dieser Auffassung und sind der Mei-nung, dass es selbst ohne ausdrückliche Vorschriften eine Bestrafung für     fahrlässige Straftaten gibt, da diese entsprechend der Art des Delikts oder   Auslegung der Vorschrift geahndet werden können. Anders als das Strafrecht, das die Strafbarkeit juristischer Personen nicht anerkennt, hat die doppelte   Strafbarkeit im Verwaltungsstrafrecht eine allgemeine gesetzliche Regelung,  welche die Strafbarkeit von juristischen Personen anerkennt. Die Haftbarkeit  einer juristischen Person infolge der doppelten Strafbarkeit im Falle einer   Verletzung verwaltungsrechtlicher Vorschriften durch einen Mitarbeiter, einsch-ließlich Vertreter einer juristischen Person, wird als Fahrlässigkeitshaftung   bezeichnet. Im System der Strafverfügung, das Strafverfahren speziell für   Ordnungswidrigkeiten darstellt, wird davon ausgegangen, dass nicht nur Geld-strafen und Geldbußen, die ohne rechtmäßige Strafverfügung gezahlt, sondern auch solche, die durch eine rechtswidrige Strafverfügung gezahlt wurden, zu Unrecht erlangt wurden und deshalb zurückgezahlt werden müssen. Daher ist es wünschenswert, den Rechtsbehelf im Verwaltungsgrundgesetz, im Verwal- tungsverfahrensgesetz oder in einschlägigen Einzelverwaltungsvorschriften aus-drücklich zu regeln. Darüber hinaus halten wir es zum Schutz der Rechte   und Interessen der Bürgerinnen und Bürger für erforderlich, dass Ordnungs- widrigkeiten, die nicht mit Freiheitsentzug geahndet werden und durch Geld- bußen abgegolten werden können, durch eine gesonderte gesetzliche Regelung mit einem Bußgeldbescheid geahndet werden können, damit Bürgerinnen und Bürger, die Verstöße gegen Verwaltungsvorschriften zugeben, dem sonst dro-henden Rechtszug rasch entgehen können. Die Frage, ob die Verletzung einer durch einen rechtswidrigen Bescheid angeordneten Verwaltungspflicht verwalt- ungsstrafrechtlich geahndet werden kann, ist in Theorie und Praxis des Ver- waltungsstrafrechts von zentraler Bedeutung, da sie mit dem Bestand des Art. 15 GG zusammenhängt."
Emotion Corpus Study Using an Emotional Lexicon Dictionary in Design Scenarios  -Focusing on the eVolo Architecture Competition Scenario-,2023,"['감정분석', '조형언어', '디자인 시나리오', '감정사전', '텍스트마이닝', 'Sentiment Analysis', 'Formative Language', 'Design Scenario', 'Emotion Dictionary', 'Text mining']",국문 초록 정보 없음,"(Research Background and Purpose) The linguistic understanding of Design is an important insight that can lead to the interpretation and creation of formal elements. Although early philosophy distinguishes between what can be said and what cannot be said, and what cannot be said should be kept silent, the interpretation of Design phenomena is possible through Design Scenarios, which are the spoken results of Design and formal elements. Moreover, both Design and language are embedded with emotions, and understanding the structure of emotions is important as a point of contact for all cognition. This study aims to improve the linguistic understanding of Design by structuring a Corpus of Design language derived from Sentiment Analysis, targeting the language of the eVolo architectural competition, which describes Design Scenarios for global conflict resolution and future spatial living. (Method) In order to recognize Design emotions in the language structure, we analyse the previous research on big data-based sentiment analysis and natural language processing. For the Sentiment Analysis experiment, the scenarios of 115 winning works from the five years of the eVolo competition are selected as the scope of the study. Analyse the emotions reflected in the language using the BERT and NRC emotion dictionaries. Classify Design emotions in a linguistic Corpus using the frequency of emotion words in the pre-processed data, and define a Design topic Corpus using topic modelling. By applying structured language research methods to Design research, we confirm the possibility of effective interpretation and creation through understanding the emotional structure implied in the Design of future architecture and space. (Results) This study used techniques from linguistic research to analyse and structure the complex emotional structure of the Design Scenarios. The resulting keywords can be organised into 9 emotion categories and 10 topic corpora, suggesting that in the future, Designs with similar emotional and topic structures can be structured based on language in Design and moulding production. (Conclusion) There's a lot to think about when it comes to why language is important in Design. As Ray Zekendorf said, nothing is communicated without language, we can clearly recognize the essence of meaning through language, and that is important. Moreover, in the era of realised generative AI, Designers also need considerable linguistic understanding for effective prompt input, and the attempt to recognize the emotional Corpus structure of Design languages through Sentiment Analysis presented in this study is effective. However, as this study focuses on the language used around the emotional structure rather than the specific formative language, the relationship between form and language needs to be more clearly supported by future research, such as the discovery of formative language dictionaries based on big data."
Microvascular flow imaging to differentiate focal hepatic lesions: the spoke-wheel pattern as a specific sign of focal nodular hyperplasia,2023,"['Focal nodular hyperplasia', 'Microvascular Doppler ultrasound', 'Focal liver lesion', 'Diagnostic sign']",국문 초록 정보 없음,"Microvascular flow imaging (MVFI) is an advanced Doppler ultrasound technique designed to detect slow-velocity blood flow in small-caliber microvessels. This technique is capable of realtime, highly detailed visualization of tumor vessels without using a contrast agent. MVFI has been recently applied for the characterization of focal liver lesions and has revealed typical vascularity distributions in multiple types thereof. Focal nodular hyperplasia (FNH) constitutes an important differential diagnosis of malignant liver tumors. In this essay, we provide iconographic documentation of the MVFI appearance of FNH and other common solid liver lesions. Identifying the typical patterns of vascularity, including the spoke-wheel pattern with MVFI, can expedite the diagnosis, spare patients from unnecessary procedures, and save costs."
Temperature-induced Artifacts in Tau Phosphorylation: Implications for Reliable Alzheimer’s Disease Research,2023,"['Tau phosphorylation', 'Neuronal cells', 'Temperature', 'C57BL6 mice', 'Anesthesia', 'Alzheimer’s disease']",국문 초록 정보 없음,"In preclinical research on Alzheimer’s disease and related tauopathies, tau phosphorylation analysis is routinely employed in both cellular and animalmodels. However, recognizing the sensitivity of tau phosphorylation to various extrinsic factors, notably temperature, is vital for experimentalaccuracy. Hypothermia can trigger tau hyperphosphorylation, while hyperthermia leads to its dephosphorylation. Nevertheless, the rapidity of tauphosphorylation in response to unintentional temperature variations remains unknown. In cell cultures, the most significant temperature changeoccurs when the cells are removed from the incubator before harvesting, and in animal models, during anesthesia prior to euthanasia. In this study,we investigate the kinetics of tau phosphorylation in N2a and SH-SY5Y neuronal cell lines, as well as in mice exposed to anesthesia. We observedchanges in tau phosphorylation within the few seconds upon transferring cell cultures from their 37°C incubator to room temperature conditions.However, cells placed directly on ice post-incubation exhibited negligible phosphorylation changes. In vivo, isoflurane anesthesia rapidly resultedin tau hyperphosphorylation within the few seconds needed to lose the pedal withdrawal reflex in mice. These findings emphasize the critical importanceof preventing temperature variation in researches focused on tau. To ensure accurate results, we recommend avoiding anesthesia beforeeuthanasia and promptly placing cells on ice after removal from the incubator. By controlling temperature fluctuations, the reliability and validity oftau phosphorylation studies can be significantly enhanced."
진단 프로세스 기반 설명 가능한 전문가 지식 모델링에 관한 연구,2023,"['Dataset', 'Diagnostic process', 'Multi modality', 'Expert knowledge', 'Causality']",국문 초록 정보 없음,"This paper notes that the diagnostic process of asking why the patient's symptoms lead to the doctor's diagnostic decision for final treatment is made through questions and answers made at each stage. Accordingly, we present a model that creates a question for each step. This model consists of questions at each stage by reflecting the flow of clinical diagnosis only by specialists. It was performed to infer the causal relationship of the diagnostic process and included the analysis process of a specialist to construct various tasks. This is a diagnostic decision made by a doctor for each patient's symptoms, which can guarantee the explanability of the data, and an inferential approach is possible. Finally, we compare and evaluate reports on doctor's questions and answers with reports through manual commentary by experts. The evaluation uses Visual commonsense reasoning model, VI-bert, and Biobert as baseline models. As a result, the average performance of BLEU-1 to 2 was 3.5904, 2.8007, and 3.4627, respectively, and the average performance of Rogue-1, 2, and l was 0.1606, 0.3428, and 0.0797, respectively. This shows that medical knowledge is required for the data in report generation, and can be viewed as Explainable data that can be applied to models for learning causality."
EPC 프로젝트의 위험 관리를 위한 ITB 문서 조항 분류 모델 연구: 딥러닝 기반 PLM 앙상블 기법 활용,2023,"['EPC 프로젝트', 'ITB 문서', '딥러닝', '사전학습 언어 모델', 'ELECTRA', 'EPC Projects', 'ITB Documents', 'Deep Learning', 'PLM', 'ELECTRA']",국문 초록 정보 없음,"The Korean construction order volume in South Korea grew significantly from 91.3 trillion won in public orders in 2013 to a totalof 212 trillion won in 2021, particularly in the private sector. As the size of the domestic and overseas markets grew, the scale andcomplexity of EPC (Engineering, Procurement, Construction) projects increased, and risk management of project management and ITB(Invitation to Bid) documents became a critical issue. The time granted to actual construction companies in the bidding process followingthe EPC project award is not only limited, but also extremely challenging to review all the risk terms in the ITB document due to manpowerand cost issues. Previous research attempted to categorize the risk terms in EPC contract documents and detect them based on AI, butthere were limitations to practical use due to problems related to data, such as the limit of labeled data utilization and class imbalance.Therefore, this study aims to develop an AI model that can categorize the contract terms based on the FIDIC Yellow 2017(FederationInternationale Des Ingenieurs-Conseils Contract terms) standard in detail, rather than defining and classifying risk terms like previousresearch. A multi-text classification function is necessary because the contract terms that need to be reviewed in detail may vary dependingon the scale and type of the project. To enhance the performance of the multi-text classification model, we developed the ELECTRAPLM (Pre-trained Language Model) capable of efficiently learning the context of text data from the pre-training stage, and conducteda four-step experiment to validate the performance of the model. As a result, the ensemble version of the self-developed ITB-ELECTRAmodel and Legal-BERT achieved the best performance with a weighted average F1-Score of 76% in the classification of 57 contract terms."
