title,date,keywords,abstract,multilingual_abstract
단일 원형 경계상자를 사용한 YOLO 기반 궐련 담배 검출 시스템,2023,"['공장자동화', '궐련 담배 검출', 'YOLO', '원형 경계상자', '데이터 증강', 'Factory automation', 'Cigarette Detection', 'YOLO', 'Circle Bounding Box', 'Data Augmentation']","현대의 공장자동화 분야에서는 생산효율 증대와 생산 제품의 품질 향상을 위해 제조 공정에서 기계, 전기, 전자, 컴퓨터 공학 등의 다양한 최신 기술이 적용되고 있다. 본 연구에서는 궐련 담배 생산 공정에서 궐련 담배의 누락이나 역방향 정렬과 같은 불량 포장을 정확하게 검출하기 위해 단일 원형 경계상자를 사용한 YOLO 기반 궐련 담배 검출 시스템을 제안하였다. 특히, Proposed-Net2는 성능 면에서 YOLOv4-Tiny 네트워크와 유사한 평균 정밀도를 나타내며, 기존 대비 10% 수준의 메모리를 사용하며 약 2배 정도의 빠른 처리 시간으로 궐련 담배를 검출하였다. 그리고 부족한 학습 데이터는 객체 기반으로 잘라낸 이미지를 회전 및 무작위로 생성한 경계상자에 합성하여 적은 수의 학습 이미지만으로 다양한 형태의 데이터를 증강하여 효과적인 학습이 가능함을 확인하였다. 이는 임베디드 환경과 같은 하드웨어 사양이 낮은 곳에서도 적용할 수 있는 장점이 있다.","In modern factory automation, various cutting-edge technologies such as mechanical, electrical, electronic, and computer engineering are applied in the manufacturing process to increase production efficiency and improve product quality. In this study, a YOLO-based cigarette detection system using a single circular bounding box is proposed to accurately detect defective packaging, such as missing cigarettes or reverse alignment in the cigarette production process. In particular, Proposed-Net2 shows an average precision similar to that of the YOLOv4-Tiny network in terms of performance, uses 10% of memory compared to the existing ones, and detects cigarettes with about twice as fast processing time. And it was confirmed that effective learning is possible by augmenting various types of data with only a small number of training images by combining object-based cropped images with rotation and randomly generated bounding boxes for insufficient training data. This is applicable even when hardware specifications are low, such as an embedded environment."
카메라 트래핑 기법과 YOLO-X 알고리즘 기반의 도시 야생동물 탐지 및 분석방법론 개발,2023,"['Deep learning', 'Object detection', 'Wildlife monitoring', 'Urban ecosystem', 'Ecological camera trap']",,"Camera trapping has been used as a non-invasive survey method that minimizes anthropogenic disturbance to ecosystems. Nevertheless, it is labor-intensive and time-consuming, requiring researchers to quantify species and populations. In this study, we aimed to improve the preprocessing of camera trapping data by utilizing an object detection algorithm. Wildlife monitoring using unmanned sensor cameras was conducted in a forested urban forest and a green space on a university campus in Cheonan City, Chungcheongnam-do, Korea. The collected camera trapping data were classified by a researcher to identify the occurrence of species. The data was then used to test the performance of the YOLO-X object detection algorithm for wildlife detection. The camera trapping resulted in 10,500 images of the urban forest and 51,974 images of green spaces on campus. Out of the total 62,474 images, 52,993 images (84.82%) were found to be false positives, while 9,481 images (15.18%) were found to contain wildlife. As a result of wildlife monitoring, 19 species of birds, 5 species of mammals, and 1 species of reptile were observed within the study area. In addition, there were statistically significant differences in the frequency of occurrence of the following species according to the type of urban greenery: Parus varius(t = -3.035, p < 0.01), Parus major(t = 2.112, p < 0.05), Passer montanus(t = 2.112, p < 0.05), Paradoxornis webbianus(t = 2.112, p < 0.05), Turdus hortulorum(t = -4.026, p < 0.001), and Sitta europaea(t = -2.189, p < 0.05). The detection performance of the YOLO-X model for wildlife occurrence was analyzed, and it successfully classified 94.2% of the camera trapping data. In particular, the number of true positive predictions was 7,809 images and the number of false negative predictions was 51,044 images. In this study, the object detection algorithm YOLO-X model was used to detect the presence of wildlife in the camera trapping data.In this study, the YOLO-X model was used with a filter activated to detect 10 specific animal taxa out of the 80 classes trained on the COCO dataset, without any additional training. In future studies, it is necessary to create and apply training data for key occurrence species to make the model suitable for wildlife monitoring."
YOLO와 OpenCV기술을 활용한 현수막 단속 자동화 시스템 방안,2023,"['Banner', 'Object detection', 'YOLO', 'OpenCV', 'HSV']",,"From the past to the present, banners are consistently used as effective advertising means. In the case of Korea, there are frequent situations in which hidden advertisements are installed. As a result, such hidden advertisement materials may damage urban aesthetics and moreover, incur unnecessary manpower consumption and waste of money. The proposed method classifies the detected banners into good banner and bad banner. The classification results are based on whether the relevant banners are installed in compliance with legal guidelines. In the process, YOLO and Open Computer Vision library are used to determine from various perspectives whether banners in CCTV images comply with the guidelines. YOLO is used to detect the banner area in CCTV images, and OpenCV is used to detect the color values in the area for color comparison. If a banner is detected in the video, the proposed method calculates the location of the banner and the distance from the designated bulletin to determine whether it was installed within the designated location, and then compares whether the color used in the banner is complied with local government guidelines."
Yolo와 후처리 알고리즘을 이용한 실시간 적재/과적차량 판단 시스템,2023,"['Deep Learning', 'Overloaded Vehicle', 'Object Detection', 'Post-processing Algorithm', 'YOLO', '객체 인식', '딥러닝', '적재불량', '후처리 알고리즘', 'YOLO']","화물차 사고의 매월 10%의 비율을 차지하는 낙하물의 주원인은 과적, 적재불량, 불법개조차량이다. 이러한 차량들을 단속하기 위해 화물차는 고속도로 진입 시 측정차로를 이용해야하지만 이를 위반하는 사례가 증가하고 있고, 사람이 직접 확인하기 때문에 많은 노동력이필요해 과적/적재불량 차량을 단속하는 자동화 시스템에 관한 연구가 필요하다. 본 논문에서는 과적/적재불량 탐지하기 위해 yolov5, yolov7, yolov8을 AI-Hub에서 제공하는 데이터로학습하고, 차량의 일부만보고 탐지하는 문제를 해결하기 위해 후처리 알고리즘을 적용한다.후처리 알고리즘을 적용 전과 후를 비교한 결과 가장 성능이 낮았던 Yolov7-E6모델에서mAP(0.5) 2.2, mAP(0.5:0.95) 3.7만큼 상승했다. 후처리 알고리즘을 적용해 시스템을 구축한다면 차량의 일부만 보고 탐지하는 문제를 해결해 더욱 정확한 예측이 가능할 것으로 기대된다.","The main causes of falling objects, which represent 10% of truck accidents eachmonth, are overload, poor loading and illegal refurbished vehicles. In order to crackdown on these vehicles, trucks must use measurement lanes when entering thehighway, but the number of violations is increasing, and a lot of labor is neededbecause people directly check them. In this paper, we learn yolov5, yolov7, andyolov8 from data provided by AI-Hub to detect overload/loading defects, and applya post-processing algorithm to solve the problem of detecting only a part of thevehicle. As a result of comparing the processing algorithm before and afterapplication, it rose by mAP (0.5):2.2 and mAP(0.5:0.95):3.7 in the Yolov7-E6 model,which had the lowest performance. If the system is built by applying thepost-processing algorithm, it is expected that more accurate prediction will bepossible by solving the problem of detecting only a part of the vehicle."
YOLO 기반 실종자 수색 AI 응용 시스템 구현,2023,"['실종자 수색', '드론', '객체 탐지', 'Missing Person', 'Drone', 'Object Detection', 'YOLOv5']","실종자 수색은 많은 시간과 인력이 필요하다. 그 해결책의 일환으로 YOLO 기반 모델을 활용하여 실종자 수색 AI 시스템을 구현하였다. 객 객체 탐지 모델을 훈련하기 위해 AI-Hub에서 드론 이동체 인지 영상(도로 고정)을 수집하고 모델을 학습하였다. 또한, 훈련 데이터 세트와 상이한 환경에서의 성능을 평가하기 위해 산악 환경 데이터 세트를 추가 수집하였다. 실종자 수색 AI 시스템의 최적화를 위해 모델 크기 및 하이퍼파라미터에 따른 성능평가, 과대적합 우려에 대한 추가 성능평가를 시행하였다. 성능평가 결과 YOLOv5-L 모델이 우수한 성능을 보이는 것을 확인할 수 있었으며 데이터 증강 기법을 적용함에 따라 모델의 성능이 보다 향상되었다. 이후 웹 서비스에는 데이터 증강 기법을 적용한 YOLOv5-L 모델을 적용하여 실종자 수색의 효율성을 높였다.","It takes a lot of time and manpower to search for the missing. As part of the solution, a missing person search AI system was implemented using a YOLO-based model. In order to train object detection models, the model was learned by collecting recognition images (road fixation) of drone mobile objects from AI-Hub. Additional mountainous terrain datasets were also collected to evaluate performance in training datasets and other environments. In order to optimize the missing person search AI system, performance evaluation based on model size and hyperparameters and additional performance evaluation for concerns about overfitting were conducted. As a result of performance evaluation, it was confirmed that the YOLOv5-L model showed excellent performance, and the performance of the model was further improved by applying data augmentation techniques. Since then, the web service has been applied with the YOLOv5-L model that applies data augmentation techniques to increase the efficiency of searching for missing people."
YOLO를 이용한 SAR 영상의 선박 객체 탐지: 편파별 모델 구성과 정확도 특성 분석,2023,[],,"Ship detection at sea can be performed in various ways. In particular, satellites can provide wide-area surveillance, and Synthetic Aperture Radar (SAR) imagery can be utilized day and night and in all weather conditions. To propose an efficient ship detection method from SAR images, this study aimed to apply the You Only Look Once Version 5 (YOLOv5) model to Sentinel-1 images and to analyze the difference between individual vs. integrated models and the accuracy characteristics by polarization. YOLOv5s, which has fewer and lighter parameters, and YOLOv5x, which has more parameters but higher accuracy, were used for the performance tests (1) by dividing each polarization into HH, HV, VH, and VV, and (2) by using images from all polarizations. All four experiments showed very similar and high accuracy of 0.977 ≤ AP@0.5 ≤ 0.998. This result suggests that the polarization integration model using lightweight YOLO models can be the most effective in terms of real-time system deployment. 19,582 images were used in this experiment. However, if other SAR images,such as Capella and ICEYE, are included in addition to Sentinel-1 images, a more flexible and accurate model for ship detection can be built."
택배 배송 서비스 품질향상을 위한 YOLO 기반 택배 상자 파손 탐지 및 DCGAN 기반 데이터 증강,2023,"['Parcel Delivery Service', 'Damage Detection', 'Data Augmentation', 'Generative Adversarial Network', 'DCGAN']",,"The damage to parcel not only diminishes customer satisfaction with parcel delivery services but also incurs return logistics costs, and this problem can be addressed by detecting damage before parcels reach the customers. Therefore, various deep learning researches related to the parcel damage detection are being conducted. In this study, we introduce a method for parcel box damage detection that not only identifies the presence of damage but also determines its specific type. To achieve this, we employ DCGAN-based data augmentation and use the YOLOv5s-cls and YOLOv5m models for damage classification and detection, respectively. The proposed method was validated using a dataset reflecting real-world logistics situations, demonstrated its potential to enhance the quality of parcel delivery services."
YOLO V5의 생성 데이터를 이용한 병렬 U-Net 기반 의미론적 분할 방법,2023,"['YOLO V5', 'Parallel U-Net', 'semantic segmentation', 'BDD100K', 'mIoU', 'YOLO V5', '병렬 U-Net', '의미론적 분할', 'BDD100K', 'mIoU']","본 연구에서는 객체 인식 모델인 YOLO(You Only Look Once) V5로 바운딩 박스 이미지를 생성하고 이 이미지를 병렬 U-Net에 학습 데이터로 사용하여 의미론적 분할을 수행하는 시스템을 제안 및 구현한다. YOLO V5 학습에는 yolov5s 모델을 사용하고 차량 및 보행자를 바운딩 박스의 형태로 검출하여 이미지를 생성한다. 이렇게생성된 이미지 데이터는 병렬 U-Net의 학습 데이터로 사용한다. 제안한 병렬 U-Net은 원본 이미지와 YOLO V5 에서 출력한 이미지를 병렬 형태로 입력받아 학습하여 의미론적 분할을 수행한다. 제안한 시스템의 검출 성능을평가하기 위해 기존의 U-Net 및 U-Net3+의 의미론적 분할 결과와 비교하였다. YOLO V5의 학습 데이터로는BDD100K(Berkeley Deep Drive 100K)를 사용하였으며 실험 결과, 병렬 U-Net이 기존의 단일 U-Net보다0.1~0.2, U-Net3+보다 0.03~0.15 향상된 mIoU(Mean Intersection over Union)를 얻을 수 있었다.",
YOLO v3를 이용한 CCTV 영상파일 저장공간 확보 모델,2023,"['CCTV', 'YOLO', 'Computer Vision', 'Object Detection', 'Object Recognition', 'CCTV', 'YOLO', '컴퓨터 비전', '객체 탐지', '객체 인식']","본 논문에서는 YOLO v3를 이용한 CCTV 저장공간 확보 모델을 제안한다. CCTV는 방범, 화재예방, 감시 등 재난·재해 및 안전을 위해 사회 곳곳에 설치·운영되며, 개수의 증가와 화질의 개선이 함께 이뤄지고 있다. 이로 인해 영상파일의 개수와 크기가 증가하면서 기존의 저장공간으로는이를 감당하기 어려움을 느끼고 있다. 이를 해소하기 위해 CCTV 영상 속의 특정 객체를 YOLO v3를 이용하여 탐지하여 해당 프레임만을 저장하여 불필요한 프레임을 삭제하는 모델을 제안하여영상파일의 크기를 줄임으로써 저장공간을 확보하고, 그로 인해 더 오랜 기간 영상을 저장·관리할 수 있도록 하였다. 제안 모델 적용 후 평균 94.9% 영상파일의 크기가 절감됨을 확인하였으며, 제안 모델을 적용하기 전보다 약 20배의 보관 기간이 증가했음을 확인할 수 있었다.",
YOLO 알고리즘을 활용한 Planetscope 위성영상 기반 비닐하우스 탐지,2023,"['Greenhouse', 'Planetscope satellite image', 'YOLO', 'Deep learning', '비닐하우스', 'Planetscope 위성영상', 'YOLO 알고리즘', '딥러닝']",,"Detecting greenhouses from the remote sensing datasets is useful in identifying the illegal agricultural facilities and predicting the agricultural output of the greenhouses. This research proposed a methodology for automatically detecting greenhouses from a given Planetscope satellite imagery acquired in the areas of Gimje City using the deep learning technique through a series of steps. First, multiple training images with a fixed size that contain the greenhouse features were generated from the five training Planetscope satellite imagery. Next, the YOLO(You Only Look Once) model was trained using the generated training images. Finally, the greenhouse features were detected from the input Planetscope satellite image. Statistical results showed that the 76.4% of the greenhouse features were detected from the input Planetscope satellite imagery by using the trained YOLO model. In future research, the high-resolution satellite imagery with a spatial resolution less than 1m should be used to detect more greenhouse features."
UAV 이미지와 수치지형도를 이용한 지상 객체의 다중 클래스에 대한 YOLO 모델 기반의 인스턴스 분할,2023,"['인스턴스 분할', 'YOLO', 'UAV', '수치지형도', '공간 분석', 'Instance Segmentation', 'YOLO', 'UAV', 'Digital Topographic Maps', 'Spatial Analysis']","지금까지 항공영상을 활용한 공간 객체에 대한 탐지는 대부분 물류, 운송 수단에 대한 객체 탐지 및 도로, 건물의 시맨틱 분할이 주를 이루었다. 본 연구에서는 지상 객체의 다중 클래스에 대한 객체 탐지 및 인스턴스 분할을 목적으로 한다. 이를 위해 YOLO (You Only Look Once) v8 모델을 이용하였고, UAV (Unmanned Aerial Vehicle)로 촬영한 고해상도 이미지를 사용하였다. 학습데이터는 과속방지턱, 횡단보도, 태양광 패널과 같은 일정한 패턴을 갖고 있는 객체유형1과 건물같이 일정한 패턴을 갖고 있지 않은 객체 유형2로 나누었으며 국토지리정보원에서 제작하는 수치지형도 V2.0 데이터를 활용하여 학습데이터를 구축하였다. 학습 후 유형별 전체 클래스에 대한 mAP (mean Average Precision)는 객체 유형1은 0.993, 유형2는 0.881로 좋은 성능을 보였다. 예측에는 총 5가지 데이터를 사용하여 학습된 모델의 예측 정확도가 데이터의 축척의 변화, 공간해상도의 변화에 따라서 어떻게 변화하는지 분석하였다. 분석 결과 축척이 100%일 때는 객체를 탐지 못하거나 예측 확률이 50%로 낮았던것이 축척이 125%로 확대될 때 예측확률은 90% 이상으로 올라갔으며 또한 공간해상도가 25cm로 낮아지는 경우에는 일부 객체를 탐지 못하거나 실제값과 맞지 않는 잘못된 예측 및 분활이 되었다.","Until now, detection of spatial objects using aerial images has mainly focused on object detection for logistics and transportation, and semantic segmentation of roads and buildings. The objective of this study is to perform object detection and instance segmentation for various classes of ground objects. To this end, a YOLO (You Only Look Once) v8 model was used, and high-resolution images taken with an UAV (Unmanned Aerial Vehicle) were used. For the construction of learning data, The training dataset was divided into two categories: object type 1, characterised by regular patterns such as speed bumps, crosswalks, and solar panels, and object type 2, which lacks regular patterns like buildings. The training dataset was built using the digital topographic map V2.0 data produced by the NGII (National Geographic Information Institute). After training, mAP(mean average precision) for all class types demonstrated strong performance, of 0.993 for data type 1 and 0.881 for type 2, and Five different types of data were used for prediction and how the prediction accuracy of the trained model changed according to changes in data scale and spatial resolution was analyzed. As a result of the analysis, when the scale was 100%, the object could not be detected or the prediction probability was low at 50%, but when the scale was enlarged to 125%, The analysis results showed that when the scale was at 100%, objects couldn’t be detected. However, when the scale was increased to 125%, the prediction probability which was as low as 50% rose to over 90%. Additionally, in cases where the spatial resolution decreased to 25cm, certain objects couldn’t be detected, and incorrect predictions and segmentations that didn’t match the actual values occurred."
수중영상을 이용한 저서성 해양무척추동물의 실시간 객체 탐지: YOLO 모델과 Transformer 모델의 비교평가,2023,"['Benthic marine invertebrates', 'Deep learning', 'Real-time object detection', 'YOLO', 'DETR', '저서성 해양무척추동물', '딥러닝', '실시간 객체 탐지']",,"Benthic marine invertebrates, the invertebrates living on the bottom of the ocean, are an essential component of the marine ecosystem, but excessive reproduction of invertebrate grazers or pirate creatures can cause damage to the coastal fishery ecosystem. In this study, we compared and evaluated You Only Look Once Version 7 (YOLOv7), the most widely used deep learning model for real-time object detection, and detection tansformer (DETR), a transformer-based model, using underwater images for benthic marine invertebrates in the coasts of South Korea. YOLOv7 showed a mean average precision at 0.5 (mAP@0.5) of 0.899, and DETR showed an mAP@0.5 of 0.862, which implies that YOLOv7 is more appropriate for object detection of various sizes. This is because YOLOv7 generates the bounding boxes at multiple scales that can help detect small objects. Both models had a processing speed of more than 30 frames per second (FPS), so it is expected that real-time object detection from the images provided by divers and underwater drones will be possible. The proposed method can be used to prevent and restore damage to coastal fisheries ecosystems, such as rescuing invertebrate grazers and creating sea forests to prevent ocean desertification."
택배 화물 파손 분류를 위한 YOLO 및StyleGAN 기반 학습 데이터 증강,2023,"['택배 배송 서비스', '파손 분류', '데이터 증강', '적대적 생성 신경망', 'StyleGAN3', 'Parcel Delivery Service', 'Damage Classification', 'Data Augmentation', 'Generative Adversarial Network', 'StyleGAN3']","택배 화물의 파손은 택배 배송 서비스 품질 저하를 초래하는 주요 요인이며, 택배 화물의 파손 분류를 통해 택배 배송 과정을 추적 및 개선함으로써 택배 서비스 품질 향상이 가능하다.따라서 택배 화물의 파손 분류와 관련된 다양한 딥러닝 기술의 연구개발이 수행되고 있다.본 연구는 택배 화물 파손 형태 분류를 위한 적대적 생성 신경망 기반의 학습 데이터셋 구축 방법을 제안한다. 이를 위하여 YOLOv5 기반 택배 화물 탐지를 수행하고 크롭하는 과정을 거쳐, 영상 내 분류 모델 성능 저하 요인를 배제하였다. 또한, ADA 기법을 사용한StyleGAN3 모델을 사용하여 적은 수의 영상으로도 데이터의 다양성을 확보하였다. 제안한방법으로 구축된 데이터셋으로 학습한 택배 화물 파손 형태 분류 모델의 성능을 검증하였으며, 이를 통해 제안한 방법이 택배 서비스 품질 향상에 기여할 수 있음을 확인하였다.","Parcel damage is a primary factor contributing to the decline in the quality of parceldelivery services. Implementing the classification of damaged parcels can fosterenhanced service quality by improving the tracking and delivery process.Consequently, a wide range of research efforts are underway in the realm of deeplearning, focusing on the classification of parcel damages. This study introduces amethod to build a training dataset employing adversarial generative neuralnetworks, specifically targeting the classification forms of parcel damages. To thisend, we utilized the YOLOv5 algorithm for object detection, which helps eliminateelements that could potentially diminish the efficacy of the classification modelwithin images. Additionally, we adopted the ADA technique within the StyleGAN3model, ensuring a diverse dataset even with a limited number of images. Weverified the performance of the parcel damage forms classification model trainedwith the dataset built through the proposed method. Through this, we confirmedthat the proposed method can contribute to improve the quality of parcel deliveryservices."
드론 영상의 YOLO 딥러닝 기법 적용을 통한 개인형 이동장치 탐지,2023,"['드론 영상', 'PM', 'YOLOv3', '객체 탐지', 'Drone Image', 'PM', 'YOLOv3', 'Object Detection']","최근 단거리 교통수단으로 개인형 이동장치와 이를 사용하는 사용자의 이용률이 빠르게 증가하고 있다. 또한, 현대도시의 소비 형태가 공유경제의 형태로 변화하며 관련 공유 플랫폼이 개발됨에 따라 개인형 이동장치인 PM(Personal Mobility)이 공유 전동킥보드 형태로 나타났으며, 이와 동시에 공유 PM 서비스를 제공하는 업체도 같이 증가하고 있다. 그러나 PM이 서비스 제공 업체마다 종류가 다르고, 지역마다 그 업체의 수가 달라 통합적인 관리가 더욱 어려운 상황이다. 따라서 본 논문에서는 드론을 통해 수집한 영상에서 YOLOv3 알고리즘으로 여러 업체의 PM 객체를 탐지하여, 통합적인 관리의 활용 가능성이 있는지 분석하고 정확도 평가를 수행하였다. 실험지역 내 PM이 포함된 드론 영상을 수집하고 PM 객체를 레이블링하여 딥러닝 모델을 학습시켜 PM을 탐지하였다. 정확도 평가 결과 재현율 80%, 정밀도 87%의 탐지 정확도와 0.73의 AP값을 얻었으며 이를 통해 드론 영상에서 YOLOv3 알고리즘을 활용하여 PM 검출을 수행하는 것이 가능함을 확인하였다.","Recently, the utilization rate of PM (Personal Mobility) and its users has been rapidly increasing as a short distance transportation option. As the consumption patterns in modern cities shift towards the sharing economy, various shared mobility platforms have been developed, leading to the emergence of PM in the form of shared electric scooters. Consequently, there has been a simultaneous increase in companies providing shared PM services. However, due to the diverse types of shared PM offered by different service providers and variations in the number of providers across regions, the comprehensive management of PMs has become more challenging. Therefore, this paper aims to evaluate the feasibility of utilizing the YOLOv3 algorithm to detect shared PM objects from drone images and to assess accuracy, thereby verifying the potential for integrated PM management of PMs. PM images within the experimental area were collected using drones, and individual objects were labeled to train a deep learning model for PM detection. Subsequently, an accuracy evaluation was conducted to validate the feasibility of the approach. The experimental results demonstrated 80% recall and 87% precision accuracy, and an AP (average precision) value of 0.73, confirming the viability of utilizing the YOLOv3 algorithm on drone images for PM detection."
RGB 채널 영상을 이용한 YOLO 모델 기반의 MWIR 영상 탐지 성능평가,2023,"['deep learning', 'infrared image', 'object detection', 'medium wave infrared (MWIR)']",,"Recently, artificial intelligence is being used in many business fields. In the field of image, it is used in many different forms, starting with simple object detection, tracking, synthetic image generation, and style conversion. In particular, the object detection field has already been applied and used in many fields such as national defense, product defect detection, and security thanks to tremendous development. However, current object detection models are mainly performed with RGB images. Due to this direction of research, a separate study is underway for a model for IR image. Because of this, the development of deep learning models for IR images is much slower than RGB images. In addition, due to the lack of IR image data, research on IR image deep learning models is becoming more and more laggy compared to other deep learning studies. This paper proposes that the model trained on RGB images shows excellent performance in IR images. The object detection deep learning model learns shape information by using feature extraction. Our results show that IR images showing the shape of an object and images learned as RGB images can be sufficiently inferred. As a result, the model trained with RGB images shows robustness even in IR images."
YOLO기반의 객체인식을 통한 딸기 수확 로봇 시스템에 대한 연구,2023,"['Agricultural robot', 'RGB-depth camera', 'YOLO', 'Object detection', 'Strawberry harvesting']",,"Recently, interest in intelligent agricultural robots has surged due to the aging of rural workers, leading to active research on agricultural automation. We designed a strawberry harvesting robot that moves along a rail, equipped with a 3-axis linear actuator, an RGB-Depth camera for object detection, and a rotary gripper for branch cutting. Our research focused on developing algorithms for strawberry maturity classification using an AI vision system, calculating cutting points for fruit acquisition, and implementing these algorithms in a robot. A convolutional neural network based on YOLO was employed for object detection, and representation learning was used to determine the picking point with an ROI(Region Of Interest) image derived from object detection. Our strawberry harvesting robot system boasts an average harvesting success rate of 90% for ripe fruits."
Development of YOLO-based apple quality sorter,2023,"['apple sorting system', 'Jetson Nano', 'object detection', 'YOLO (You Only Look Once)']",,"The task of sorting and excluding blemished apples and others that lack commercial appeal is currently performed manually by human eye sorting, which not only causes musculoskeletal disorders in workers but also requires a significant amount of time and labor. In this study, an automated apple-sorting machine was developed to prevent musculoskeletal disorders in apple production workers and to streamline the process of sorting blemished and nonmarketable apples from the better quality fruit. The apple-sorting machine is composed of an arm-rest, a main body, and a height-adjustable part, and uses object detection through a machine learning technology called ‘You Only Look Once (YOLO)’ to sort the apples. The machine was initially trained using apple image data, RoboFlow, and Google Colab, and the resulting images were analyzed using Jetson Nano. An algorithm was developed to link the Jetson Nano outputs and the conveyor belt to classify the analyzed apple images. This apple-sorting machine can immediately sort and exclude apples with surface defects, thereby reducing the time needed to sort the fruit and, accordingly, achieving cuts in labor costs.Furthermore, the apple-sorting machine can produce uniform quality sorting with a high level of accuracy compared with the subjective judgment of manual sorting by eye. This is expected to improve the productivity of apple growing operations and increase profitability."
Exploring the Challenges Faced by Contemporary Christian Youth in Navigating the Hedonistic YOLO Lifestyle,2023,"['욜로(YOLO)', '현대 라이프 스타일 트렌드', '쾌락주의 도전', '크리스천 청년', '교회의 역할과 책임', 'YOLO', 'contemporary lifestyle trend', 'hedonism challenges', 'Christian youth', 'church’s role and responsibility']",,"This study analyzes the ‘YOLO’ lifestyle (You Only Live Once) that is in vogue today, addresses the problems faced by Christian youth in such a culture, and discusses how the church can protect Christian youth and grow and mature their faith. In particular, through an analysis of the characteristics of the current youth generation and the impact of this lifestyle on Christian spirituality, the writer suggests how the church can support Christian leaders in a changed society by providing them with data to understand and help Christian youth to mature in their faith. This lifestyle, with its focus on instant gratification and indulgence, is not compatible with the ongoing commitment necessary for spiritual growth. The appeal of YOLO culture often leads young Christians to prioritize temporary pleasures over spiritual needs. The YOLO lifestyle can undermine commitment to spirituality and pose a threat to each youth’s direction and purpose in life. Christian youth should try to balance their physical and spiritual needs to overcome these obstacles. Strengthening their faith and developing discernment in navigating conflicting situations is of utmost importance. Christian communities play an important supporting role in these goals, and churches and spiritual disciplines can leverage social media to provide relevant resources. Moreover, young people can also establish their own organizations that promote mutual support and promote moral principles. Young people need the ability to exercise self-control against immediate needs and maintain a delicate balance between their faith and personal goals. Effective spiritual leadership, the use of technology, and the fostering of supportive communities requires collaboration between churches, leaders, and young people."
ANALYSIS OF THE FLOOR PLAN DATASET WITH YOLO V5,2023,"['Floor plan dataset', 'Object detection', 'Faster R-CNN', 'YOLO v5.']",,"This paper introduces the industrial problem, the solution, and the results of the research conducted with Define Inc. The client company wanted to improve the performance of an object detection model on the floor plan dataset. To solve the problem, we analyzed the operational principles, advantages, and disadvantages of the existing object detection model, identified the characteristics of the floor plan dataset, and proposed to use of YOLO v5 as an appropriate object detection model for training the dataset. We compared the performance of the existing model and the proposed model using mAP@60, and verified the object detection results with real test data, and found that the performance increase of mAP@60 was 0.08 higher with a 25% shorter inference time. We also found that the training time of the proposed YOLO v5 was 71% shorter than the existing model because it has a simpler structure. In this paper, we have shown that the object detection model for the floor plan dataset can achieve better performance while reducing the training time. We expect that it will be useful for solving other industrial problems related to object detection in the future. We also believe that this result can be extended to study object recognition in 3D floor plan dataset."
A Method for Reducing False Negative Rate in Non-Maximum Suppression of YOLO Using Bounding Box Density,2023,"['Non-Maximum Suppression', 'Object Detection', 'False Negative Error', 'YOLO.']",,"In the previous non-maximum suppression (NMS) in you only look once (YOLO) v5, false negative error happens even when there are many bounding boxes for an object because all bounding boxes have lower confidence score. This work finds that a lot of bounding boxes near an object of false negative error are removed because of low confidence score. This paper proposes a new modified confidence score that is increased when bounding boxes with the same class prediction are located densely. The proposed method reduces the false negative error caused by low confidence score effectively. Experimental results show that the proposed method detects 25.33% more objects than conven-tional NMS at mAP@0.5."
YOLO 알고리즘을 활용한 터널 GPR 이미지 내 강지보재 탐지,2023,"['Convolutional neural network', 'Data augmentation', 'Ground penetrating rader', 'Tunnel maintenance', 'YOLO']",,
YOLO 및 DeepSORT를 활용한 학교안전보행 모니터링 시스템 개발,2023,"['School safety', 'Safety walking', 'Deep learning', 'YOLO', 'DeepSORT', 'Monitoring system']",,"In order to prevent safety accidents while walking in schools, a monitoring system using object recognition technology was developed for corridors and stairs. Using a fixed webcam and computer, the function of detecting and tracking the human body in real time and calculating the movement speed of the student was implemented. The object detection model was trained using COCO dataset and YOLOv7 network training architecture. Using the object tracking model and Python, it created an object speed estimation system through real-time video analysis. A custom model for human body detection was developed, and the accuracy of the model was mAP_0.5: 0.7387, mAP_0.5_0.95: 0.4314."
소형 UAV의 장애물 충돌 회피를 위한 YOLO 및 IR 센서 기반 장애물 크기 예측 방법,2023,"['Small UAV(소형 무인 항공기)', 'Collision Avoidance(충돌 회피)', 'Obstacle Detection(장애물 감지)', 'Size Prediction(크기 예측)']",,"With the growing demand for unmanned aerial vehicles (UAVs), various collision avoidance methods have been proposed, mainly using LiDAR and stereo cameras. However, it is difficult to apply these sensors to small UAVs due to heavy weight or lack of space. The recently proposed methods use a combination of object recognition models and distance sensors, but they lack information on the obstacle size. This disadvantage makes distance determination and obstacle coordination complicated in an early-stage collision avoidance. We propose a method for estimating obstacle sizes using a monocular camera-YOLO and infrared sensor. Our experimental results confirmed that the accuracy was 86.39% within the distance of 40 cm. In addition, the proposed method was applied to a small UAV to confirm whether it was possible to avoid obstacle collisions."
Estimating vegetation index for outdoor free-range pig production using YOLO,2023,"['Outdoor', 'Pig', 'Production', 'Vegetation index', 'Image analysis']",,"The objective of this study was to quantitatively estimate the level of grazing area damage in outdoor free-range pig production using a Unmanned Aerial Vehicles (UAV) with an RGB image sensor. Ten corn field images were captured by a UAV over approximately two weeks, during which gestating sows were allowed to graze freely on the corn field measuring 100 × 50 m2. The images were corrected to a bird’s-eye view, and then divided into 32 segments and sequentially inputted into the YOLOv4 detector to detect the corn images according to their condition. The 43 raw training images selected randomly out of 320 segmented images were flipped to create 86 images, and then these images were further augmented by rotating them in 5-degree increments to create a total of 6,192 images. The increased 6,192 images are further augmented by applying three random color transformations to each image, resulting in 24,768 datasets. The occupancy rate of corn in the field was estimated efficiently using You Only Look Once (YOLO). As of the first day of observation (day 2), it was evident that almost all the corn had disappeared by the ninth day. When grazing 20 sows in a 50 × 100 m2 cornfield (250 m2/sow), it appears that the animals should be rotated to other grazing areas to protect the cover crop after at least five days. In agricultural technology, most of the research using machine and deep learning is related to the detection of fruits and pests, and research on other application fields is needed. In addition, large-scale image data collected by experts in the field are required as training data to apply deep learning. If the data required for deep learning is insufficient, a large number of data augmentation is required."
건축물 점검을 위한 딥러닝 기반의 도메인 적응적 균열 검출 시스템,2023,"['Crack Detection', 'Artificial Intelligence', 'YOLO', 'Dataset Construction', 'Crack Inspection System', '균열 탐지', '인공지능', 'YOLO', '데이터셋 구축', '균열 점검 시스템']","건축물 안전 점검은 점검자가 육안으로 건축물을 조사하는 방식이며, 특히 건물의 위험을 직관적으로 나타내는균열에 대한 점검이 핵심적이다. 최근에는 이를 보조할 수 있도록 균열 점검의 자동화를 위한 인공지능 기반의 연구가 활발히 이루어지고 있다. 균열은 벽면의 종류와 발생 위치 등에 따라 그 형태가 매우 달라지기 때문에 학습데이터의 폭이 넓어야 하나, 대부분 공인된 데이터셋들은 제한적인 환경과 낮은 해상도로 구성되어 있어 실제 현장에 적용하기엔 실효성이 부족하다. 본 연구에서는 건물 내 균열 점검 현장에 적합한 검출 시스템을 개발하였다.이를 위해 균열 조사 현장과 같은 이미지 데이터셋 POC를 11,466장을 구축하였고, 데이터의 특성과 분포를 고려한 층화 표집 방법을 통해 구축 데이터셋의 높은 다양성을 보장하였다. 또한, 딥러닝 기반 객체 검출 모델인YOLO 계열의 모델들로 균열 검출 성능을 비교하였고, 최종적으로 YOLO-Cr 모델을 개발하여 mAP(mean Average Precision) 91.5%라는 높은 균열 검출 성능을 보였다. 더 나아가, YOLO-Cr을 토대로 실제 현장점검에서실시간 스캐닝과 UAV를 활용하는 검출 시스템을 설계함으로써 기존 육안 검사의 개선 방법을 제시한다. 본 연구를 통해 다양한 구조물의 안전 점검 자동화에 기여하고 점검의 객관성 및 효율성이 증대될 수 있길 기대한다.",
회랑 감시를 위한 딥러닝 알고리즘 학습 및 성능분석,2023,"['Deep Learning', 'K-Uam', 'Object Detecting', 'R-Cnn', 'Yolo']","K-UAM은 2035년까지의 성숙기 이후 상용화될 예정이다. UAM 회랑은 기존의 헬리콥터 회랑을 수직 분리하여 사용될 예정이기에 회량 사용량이 증가할 것으로 예상된다. 따라서 회랑을 모니터링하는 시스템도 필요하다. 최근 객체 검출 알고리즘이 크게 발전하였다. 객체 검출 알고리즘은 1단계 탐지와, 2단계 탐지 모델로 나뉜다. 실시간 객체 검출에 있어서 2단계 모델은 너무 느리기에 적합하지 않다. 기존 1단계 모델은 정확도에 문제가 있었지만, 버전 업그레이드를 통해 성능이 향상되었다. 1단계 모델 중 YOLO-V5는 모자이크 기법을 통한 소형 객체 검출 성능을 향상시킨 모델이다. 따라서 YOLO-V5는 넓은 회랑의 실시간 모니터링에 가장 적합하다고 판단된다. 본 논문에서는 YOLO-V5 알고리즘을 학습시켜 궁극적으로 회랑 모니터링 시스템에 대한 적합도를 분석한다.","K-UAM will be commercialized through maturity after 2035. Since the Urban Air Mobility(UAM) corridor will be used vertically separating the existing helicopter corridor, the corridor usage is expected to increase. Therefore, a system for monitoring corridors is also needed. In recent years, object detection algorithms have developed significantly. Object detection algorithms are largely divided into one-stage model and two-stage model. In real-time detection, the two-stage model is not suitable for being too slow. One-stage models also had problems with accuracy, but they have improved performance through version upgrades. Among them, YOLO-V5 improved small image object detection performance through Mosaic. Therefore, YOLO-V5 is the most suitable algorithm for systems that require real-time monitoring of wide corridors. Therefore, this paper trains YOLO-V5 and analyzes whether it is ultimately suitable for corridor monitoring.K-uam will be commercialized through maturity after 2035."
딥러닝 기반 지하공동구 제어반 문열림 인식,2023,"['지하공동구', '딥러닝', '제어반', '객체인식', 'YOLO', 'Underground Utility Tunnel', 'Deep Learning', 'Panel', 'Object Detection', 'YOLO']","연구목적: 지하공동구는 도시 지하에 전기, 수도, 가스 등의 인프라를 공동 수용하는 시설로 공기 흐름이 부족하여 계절에 상관없이 결로가 자주 발생한다. 결로는 전기 설비의 누전 화재를 일으키는 원인이 되므로 지하공동구 내의 조명 등 각종 시설물 관리를 위해 필요한 제어반은 결로에 노출되지 않도록 문이 닫힌 상태로 관리되어야 한다. 본 논문에서는 딥러닝 객체인식 기술을 활용하여 수km 거리에 반복 배치된 공동구 제어반의 문 열림 여부를 이동 카메라 조건과 조명이 꺼진 조건에서도 인식하고자 한다. 연구방법: 지하공동구를 순찰하는 로봇이 촬영한 영상데이터를 이용하여 딥러닝 객체인식 모델인 YOLO를 모자이크 이미지 증강기법으로 학습시켜 제어반 문 열림과 문 닫힘을 인식한다. 연구결과: 모자이크 이미지 증강기법으로 학습시킨 모델과 사용하지 않은 모델의 성능을 비교한 결과, 모자이크 학습 모델이 더 우수한 성능(모든 클래스에 대한 mAP가 0.994 이상임)을 보이는 것을 확인하였다. 결론: 지하공동구의 조명이 꺼진 상태에서도, 공동구 내부 시설물이 복잡한 환경에서도 제어반의 문열림 여부를 우수한 성능으로 인식하여 지하공동구 재난안전관리에 도움이 될 것으로 기대된다.","Purpose: Underground utility tunnel is facility that is jointly house infrastructure such as electricity, water and gas in city, causing condensation problems due to lack of airflow. This paper aims to prevent electricity leakage fires caused by condensation by detecting whether the control panel door in the underground utility tunnel is open using a deep learning model. Method: YOLO, a deep learning object recognition model, is trained to recognize the opening and closing of the control panel door using video data taken by a robot patrolling the underground utility tunnel. To improve the recognition rate, image augmentation is used. Result: Among the image enhancement techniques, we compared the performance of the YOLO model trained using mosaic with that of the YOLO model without mosaic, and found that the mosaic technique performed better. The mAP for all classes were 0.994, which is high evaluation result. Conclusion: It was able to detect the control panel even when there were lights off or other objects in the underground cavity. This allows you to effectively manage the underground utility tunnel and prevent disasters."
딥러닝 YOLOv5 객체 인식을 이용한 반려동물 품종 분류 방법에 대한 연구,2023,"['딥러닝', 'IoU임계값', '반려동물', '욜로v5', 'Deep Learning', 'IoU threshold', 'Pet breed', 'YOLOv5']","이세돌과 알파고의 바둑경기 이후 딥러닝에 대한 관심이 폭발적으로 증가하였다. 현재는 챗GPT를 비롯하여 딥러닝의 많은 기술이 우리 생활 속에 깊이 들어와 있고 연구자 뿐만 아니라 일반인도 딥러닝을 사용할 만큼 많은 분야에 응용되고 있다. 딥러닝은 CNN, YOLO 등 많은 모델이 발표 되고 있다. 특히, YOLO는 이미지를 사용한 객체 인식분야에 우수한 성능을 보이고 있어서 불량품인식, 쓰레기분리, 몰고기 인식 등 다양한 분야에 응용되고 있다. 일반적으로 딥러닝의 객체 인식은 많은 양의 데이터를 사용하여 학습한다. 본 연구는 반려동물을 대상으로 적은 수의 데이터를 학습한 후 인식방법에 대해 연구하였다. YOLO는 IoU를 기본으로 동작하기 때문에 반려동물 인식에 적합한 IoU를 설정하여 인식하는 방법을 제안하였다.","After the Go match between Sedol Lee and AlphaGo, interest in deep learning exploded. Recently, many technologies of deep learning, including ChatGPT, are deeply embedded in our lives, and not only researchers but also the general public are using deep learning in many fields. In deep learning, many models such as CNN and YOLO are being introduced in these days. In particular, YOLO shows excellent performance in the object recognition field using images, so it is applied to various fields such as defective product recognition, garbage separation, and driving meat recognition. In general, object recognition in deep learning is learned using a large amount of data. This study studied the recognition method after learning a more smaller number of data than previous works for companion animals. Since YOLO operates based on IoU, we proposed a recognition method by setting IoU suitable for companion animal recognition."
독거노인을 위한 YOLOv5 기반 낙상사고 인식 연구,2023,"['낙상사고 인식', '딥러닝', 'YOLO', '객체검출', 'Fall Detection', 'Deep Learning', 'YOLO', 'Object Detection']",,"There is currently an increase in lonely deaths due to the rise in single-person households and the aging population. The biggest problem here is the lack of communication after an incident occurs in the home, resulting in late detection. Therefore, it is necessary to recognize human falling behavior so that emergencies can be quickly notified and acted upon. YOLO (You Only Look Once) is a representative object detection technique and has shown excellent performance with similar accuracy compared to other object detection techniques and fast speed. Therefore, this paper proposes a method for recognizing falling situations from images using YOLO. For the experiment, a dataset was built by collecting and labeling images of falling situations and a model was trained. The performance was evaluated with mAP, precision, and recall, and the experimental results showed good performance and proved practicality by recognizing most falling situations. In the future, it is expected that the proposed method will be applied to outdoor CCTV instead of indoor CCTV to recognize human fall situations from various causes and make a lot of changes."
실내 사람 위치 추적 기반 LSTM 모델을 이용한 고객 혼잡 예측 연구,2023,"['LSTM', 'Indoor human location tracking', 'Congestion prediction', 'YOLO tracking', 'LSTM', '실내 사람 위치 추적', '혼잡도 예측', 'YOLO 트래킹']","본 연구는 실내 상업적 공간, 특히 카페에서 보안 카메라를 이용해 방문자 수와 위치를 실시간으로 파악하고, 이를 통해 사용 가능한 좌석 정보와 혼잡도 예측을 제공하는 시스템의 개발을 목표로 한다. 우리는 실시간 객체 탐지 및 추적 알고리즘인 YOLO를 활용하여 방문자 수와 위치를 실시간으로 파악하며, 이 정보를 카페 실내 지도에 업데이트하여 카페 방문자가 사용 가능한 좌석을 확인할 수 있도록 한다. 또한, 우리는 vanishing gradient문제를 해결한 장단기 메모리(Long Short Term Memory, LSTM)와 시간적인 관계를 가지는 데이터를 처리하는데 유용한 시퀀스-투-시퀀스(Sequence-to-Sequence, Seq2Seq)기법을 활용해 다양한 시간 간격에 따른 방문자 수와 움직임 패턴을 학습하고, 이를 바탕으로 카페의 혼잡도를 실시간으로 예측하는 시스템을 개발하였다. 이 시스템은 카페의 관리자와 이용자 모두에게 예상 혼잡도를 제공함으로써, 카페의 운영 효율성을 향상시키고, 고객 만족도를 높일 수 있다. 본 연구에서는 보안 카메라를 활용한 실내 위치 추적 기술의 효용성을 입증하며, 상업적 공간에서의 활용 가능성과 더불어 미래 연구 방향을 제시한다.","In this detailed and comprehensive study, our primary focus has been placed on accurately gauging the number of visitors and their real-time locations in commercial spaces. Particularly, in a real cafe, using security cameras, we have developed a system that can offer live updates on available seating and predict future congestion levels. By employing YOLO, a real-time object detection and tracking algorithm, the number of visitors and their respective locations in real-time are also monitored. This information is then used to update a cafe’s indoor map, thereby enabling users to easily identify available seating. Moreover, we developed a model that predicts the congestion of a cafe in real time. The sophisticated model, designed to learn visitor count and movement patterns over diverse time intervals, is based on Long Short Term Memory (LSTM) to address the vanishing gradient problem and Sequence-to-Sequence (Seq2Seq) for processing data with temporal relationships. This innovative system has the potential to significantly improve cafe management efficiency and customer satisfaction by delivering reliable predictions of cafe congestion to all users. Our groundbreaking research not only demonstrates the effectiveness and utility of indoor location tracking technology implemented through security cameras but also proposes potential applications in other commercial spaces."
Bigdata 분석과 인공지능을 적용한 시설물 건립 GIS 최적화 연구,2023,"['Bigdata', '시설물 건립', 'GIS 접근성', '인공지능', 'YOLO', 'Fast R-CNN', 'Bigdata', 'Facility construction', 'GIS accessibility', 'artificial intelligence', 'YOLO', 'Fast R-CNN']","한국에서는 시설물을 건립하기 위하여 타당성 분석을 한다. 현재 시설물의 후보지나 미흡지 분석을 하기 위한 기초데이터는 인력을 이용하여 가공하고 전문가의 알고리즘분석을 통한 도출된 결과를 이용하여 최종 시설물 허가가 진행되는 방법으로 수행하고 있다. 만약, 모바일이나 Web을 접속하여 시설물 건립의 타당성을 분석할 수 있도록 예상 시설물의 GIS 데이터를 수집에서 분석까지 자동화하여 서비스를 한다면, 의사결정이 신속하게 이루어질 것이다. 본 연구는 시설물 건립에 대한 모바일이나 Web에서 미흡지 Bigdata를 분석하고 최적의 지점을 도출하여, 시설물 허가를 온라인으로 수행하는 것을 목표로 한다. 인구 정보 데이터와 네트워크 데이터를 기반으로 Bigdata 분석한 정보와 항공영상 등 공간데이터를 활용한 최적 지점 분석을 위해 객체 검출 딥러닝 알고리즘인 YOLO와 Faster R-CNN의 적용 가능성을 탐구하며, 웹과 모바일 환경에서 사용자 친화적으로 최적 지점 분석 결과를 제공하는 방안을 제시한다.","In Korea, feasibility analysis is conducted to build facilities. Currently, basic data for analyzing the candidate sites of the facility or the lack of land is processed using manpower and final facility permission is carried out using the results derived from algorithm analysis by experts. If GIS data of expected facilities is automated from collection to analysis to analyze the validity of facility construction by accessing mobile or the web, decision-making will be made quickly. The goal of this study is to conduct facility permits online by analyzing Big Data on mobile or web for facility construction and deriving optimal points. It explores the applicability of YOLO and Fast R-CNN, object detection deep learning algorithms, and suggests ways to provide user-friendly optimal point analysis results in web and mobile environments for optimal point analysis using big data analysis information and spatial data such as aerial images."
3D 모델 기반 합성 이미지 생성을 이용한 장애인 교통약자 탐지 성능 개선,2023,"['3D Model-based data', 'Synthetic image', 'Object detection', 'Impaired pedestrians', 'YOLO']","학습 데이터 확보가 매우 제한적인 기존 응용 분야의 경우, 객체에 대한 데이터 구축 시 데이터 불균형과 데이터 부족 등의 문제점이 발생할 수 있다. 본 논문은 3D 모델을 이용한 이미지를 이용하여 실제와 유사한 합성이미지 생성 방법을 제안한다. 제안하는 기법은 다음과 같다. 첫째, 블렌더 프로그램(Blender Program)를 이용하여 3D모델을 렌더링하고, 2D 이미지 투영 후 영상 분할 모델인 SegFormer를 사용하여 지면 마스킹 정보를 획득한다. 둘째, 객체에 대한 라벨링 정보를 생성하고 실제와 유사하게 배경 이미지를 합성한다. 생성된 데이터는 실시간 탐지를 위한 YOLO 계열의 모델과 학습 데이터셋의 수를 각각 다르게 하였을 때의 정밀도, 재현율을 비교 평가하였다. 실험 데이터셋과 대조 데이터셋에 이미지를 2,000장씩 순차 추가했을 때, 대조 데이터셋 대비 제안한 방법으로 생성한 데이터셋의 YOLOv4의 탐지 결과 mAP 16.73%p, 휠체어, 사람 클래스에서 각 28.5%p, 26.19%p 증가하였으나, 시각장애인 클래스에서 4.3%p 감소하였다.","When learning about objects in applications where securing existing learning data is very limited, problems such as data imbalance and lack of learning data can occur. This paper presents a method for generating real-life synthetic images using 3D models. The proposed technique is as follows. First, we render 3D models using a Blender, and obtain ground masking information using SegFormer, an image segmentation model after 2D image projection. Second, we generate labeling information and synthesize images similar to reality. The generated datasets were compared with the precision and recall when the YOLO-based models for real-time detection and the number of datasets were different, respectively. When 2,000 images were added sequentially to the experimental dataset and the contrast dataset, the detection of YOLOv4 in the proposed method compared to the contrast dataset increased by 16.73%p in mAP, 28.5%p, 26.19%p in Wheelchair and Person classes, respectively, but decreased by 4.3%p in Whitecane class."
드론 스트리밍 영상 이미지 분석을 통한 실시간 산불 탐지 시스템,2023,"['Drone', 'YOLO', 'Object Detection', 'Fire-Detection', 'Vision Analysis']",,"The proposed system in the study aims to detect forest fires in real-time stream data received from the drone-camera.  Recently, the number of wildfires has been increasing, and also the large scaled wildfires are frequent more and more.  In order to prevent forest fire damage, many experiments using the drone camera and vision analysis are actively conducted, however there were many challenges, such as network speed, pre-processing, and model performance, to detect forest fires from real-time streaming data of the flying drone. Therefore, this study applied image data processing works to capture five good image frames for vision analysis from whole streaming data and then developed the object detection model based on YOLO_v2. As the result, the classification model performance of forest fire images reached upto 93% of accuracy, and the field test for the model verification detected the forest fire with about 70% accuracy."
YOLOv8n에서 2인 탑승 전동 킥보드 탐지 개선을 위한 새로운 라벨링 방법 제안,2023,"['객체 탐지', '라벨링', '전처리', '딥러닝', 'YOLO', 'Object Detection', 'Labeling', 'Preprocessing', 'Deep-Learning']",,"The use of an electric kickboard, which is a personal mobile device, is increasing due to its convenience and economic feasibility. An electric kickboard has a much smaller size of wheels than other two-wheeled vehicles such as bicycles and motorcycles, and due to the specificity of riding while standing, there is a greater risk than other two-wheeled vehicles in the same accident. For this reason, an electric kickboard is prohibited from boarding two or more people, but in reality, this practice is difficult to crack down on. Therefore, this paper proposes a new labeling method that becomes a learning target in the process of configuring a YOLO-based system that generates a notification when a kickboard with two or more people is detected on a monitoring screen using a camera. Through the tests with images, which are not included in the training dataset, we confirmed that the proposed method had an approximately 18% improvement in accuracy."
가상환경 및 카메라 이미지를 활용한 실시간 속도 표지판 인식 방법,2023,"['Speed Limit Sign(속도 제한 표지판)', 'Camera Image(카메라 이미지)', 'Deep Learning(딥러닝)', 'Labeling(라벨링)', 'Virtual Environment(가상환경)', 'Real-time(실시간)', 'Sensor Fusion(센서퓨전)']",,"Autonomous vehicles should recognize and respond to the specified speed to drive in compliance with regulations. To recognize the specified speed, the most representative method is to read the numbers of the signs by recognizing the speed signs in the front camera image. This study proposes a method that utilizes YOLO-Labeling-Labeling-EfficientNet. The sign box is first recognized with YOLO, and the numeric digit is extracted according to the pixel value from the recognized box through two labeling stages. After that, the number of each digit is recognized using EfficientNet (CNN) learned with the virtual environment dataset produced directly. In addition, we estimated the depth of information from the height value of the recognized sign through regression analysis. We verified the proposed algorithm using the virtual racing environment and GTSRB, and proved its real-time performance and efficient recognition performance."
객체 식별 및 추적을 위한 히스토그램 기반 특이값 분해,2023,"['객체 탐지', '객체 추적', '히스토그램', '특이값 분해', 'Object Detection', 'Object Tracking', 'Histogram', 'Singular Value Decomposition']","CCTV는 범죄 예방, 공공 안전 강화, 교통 관리 등 다양한 목적으로 사용된다. 그러나 카메라의 범위와 해상도가 향상됨에 따라영상에서 개인의 신상정보가 노출되는 위험성이 있다. 따라서 영상에서 개인 정보를 보호함과 동시에 개인을 식별할 수 있는 새로운기술의 필요성이 존재한다. 본 논문에서는 객체 식별 및 추적을 위한 히스토그램 기반 특이값 분해를 제안한다. 제안하는 방법은 객체의 색상 정보를 이용하여 영상에 존재하는 서로 다른 객체를 구분한다. 객체 인식을 위하여 YOLO와 DeepSORT를 이용해 영상에존재하는 사람을 탐지 및 추출한다. 탐지된 사람의 위치 정보를 이용해 흑백 히스토그램으로 색상 값을 추출한다. 추출한 색상 값중 유의미한 정보만을 추출하여 사용하기 위해 특이값 분해를 이용한다. 특이값 분해를 이용할 때 결과에서 상위 특이값의 평균을이용함으로 객체 색상 추출의 정확도를 높인다. 특이값 분해를 이용해 추출한 색상 정보를 다른 영상에 존재하는 색상과 비교하며서로 다른 영상에 존재하는 동일 인물을 탐지한다. 색상 정보 비교를 위해 유클리드 거리를 이용하며 정확도 평가는 Top-N을 이용한다. 평가 결과 흑백 히스토그램과 특이값 분해를 사용하여 동일 인물을 탐지할 때 최대 100%에서 최소 74%를 기록하였다.","CCTV is used for various purposes such as crime prevention, public safety reinforcement, and traffic management. However, as the range and resolution of the camera improve, there is a risk of exposing personal information in the video. Therefore, there is a need for new technologies that can identify individuals while protecting personal information in images. In this paper, we propose histogram-based singular value decomposition for object identification and tracking. The proposed method distinguishes different objects present in the image using color information of the object. For object recognition, YOLO and DeepSORT are used to detect and extract people present in the image. Color values are extracted with a black-and-white histogram using location information of the detected person. Singular value decomposition is used to extract and use only meaningful information among the extracted color values. When using singular value decomposition, the accuracy of object color extraction is increased by using the average of the upper singular value in the result. Color information extracted using singular value decomposition is compared with colors present in other images, and the same person present in different images is detected. Euclidean distance is used for color information comparison, and Top-N is used for accuracy evaluation. As a result of the evaluation, when detecting the same person using a black-and-white histogram and singular value decomposition, it recorded a maximum of 100% to a minimum of 74%."
복합형 카메라 시스템을 이용한 자율주행 차량 플랫폼,2023,"['Autonomous Driving Platform', 'Multi-view Camera', 'Depth Information Matching', 'Hybrid Camera System', '자율주행 플랫폼', '다시점 카메라', '깊이정보 매칭', '복합형 카메라 시스템']","본 논문에서는 자율주행 인지 기술의 핵심 요소인 객체 인식과 거리 측정을 위해 서로 다른 초점거리를 가진 다시점 카메라와 라이다(LiDAR) 센서를 결합한 복합형 카메라 시스템을 제안한다. 제안한 복합형 카메라 시스템을 이용해 장면 안의 객체를 추출하고, 추출한 객체의 정확한 위치와 거리 정보를 생성한다. 빠른 계산 속도와 높은 정확도, 실시간 처리가 가능하다는 장점 때문에 자율주행 분야에서 많이 사용하고 있는 YOLO7 알고리즘을 이용해 장면 안의 객체를 추출한다. 그리고 객체의 위치와 거리 정보를 생성하기 위해 다시점 카메라를 이용해 깊이맵을 생성한다. 마지막으로 거리 정확도를 향상시키기 위해 라이다 센서에서 획득한 3차원 거리 정보와 생성한 깊이맵을 하나로 결합한다. 본 논문에서는 제안한 복합형 카메라 시스템을 기반으로 주행 중인 주변 환경을 더욱 정확하게 인식함과 동시에 3차원 공간상의 정확한 위치와 거리 정보까지 생성할 수 있는 자율주행 차량 플랫폼을 제안하였으며, 이를 통해 자율주행 차량의 안전성과 효율성을 향상시킬 수 있을 것으로 기대한다.","In this paper, we propose a hybrid camera system that combines cameras with different focal lengths and LiDAR (Light Detection and Ranging) sensors to address the core components of autonomous driving perception technology, which include object recognition and distance measurement. We extract objects within the scene and generate precise location and distance information for these objects using the proposed hybrid camera system. Initially, we employ the YOLO7 algorithm, widely utilized in the field of autonomous driving due to its advantages of fast computation, high accuracy, and real-time processing, for object recognition within the scene. Subsequently, we use multi-focal cameras to create depth maps to generate object positions and distance information. To enhance distance accuracy, we integrate the 3D distance information obtained from LiDAR sensors with the generated depth maps. In this paper, we introduce not only an autonomous vehicle platform capable of more accurately perceiving its surroundings during operation based on the proposed hybrid camera system, but also provide precise 3D spatial location and distance information. We anticipate that this will improve the safety and efficiency of autonomous vehicles."
딥러닝 기반 육상기인 부유쓰레기 탐지 모델 성능 비교 및 현장 적용성 평가,2023,"['부유쓰레기', '객체 탐지 모델', '드론', '딥러닝', '공간분포', 'Floating debris', 'Object detection model', 'Drone', 'Deep learning', 'Spatial distribution']",,"A large amount of floating debris from land-based sources during heavy rainfall has negativesocial, economic, and environmental impacts, but there is a lack of monitoring systems for floating debrisaccumulation areas and amounts. With the recent development of artificial intelligence technology, thereis a need to quickly and efficiently study large areas of water systems using drone imagery and deeplearning-based object detection models. In this study, we acquired various images as well as drone imagesand trained with You Only Look Once (YOLO)v5s and the recently developed YOLO7 and YOLOv8sto compare the performance of each model to propose an efficient detection technique for land-basedfloating debris. The qualitative performance evaluation of each model showed that all three models aregood at detecting floating debris under normal circumstances, but the YOLOv8s model missed orduplicated objects when the image was overexposed or the water surface was highly reflective of sunlight.The quantitative performance evaluation showed that YOLOv7 had the best performance with a meanAverage Precision (intersection over union, IoU 0.5) of 0.940, which was better than YOLOv5s (0.922)and YOLOv8s (0.922). As a result of generating distortion in the color and high-frequency componentsto compare the performance of models according to data quality, the performance degradation of theYOLOv8s model was the most obvious, and the YOLOv7 model showed the lowest performancedegradation. This study confirms that the YOLOv7 model is more robust than the YOLOv5s andYOLOv8s models in detecting land-based floating debris. The deep learning-based floating debrisdetection technique proposed in this study can identify the spatial distribution of floating debris bycategory, which can contribute to the planning of future cleanup work."
딥러닝 기반 배추 심 중심 영역 및 깊이 분류 모델 개발,2023,"['Cabbage', 'Deep learning', 'Robot-automation', 'Core detection', 'Core depth classification']","본 논문에서는 김치 제조 공정 중 배추 심 제거 공정의 로봇 자동화를 위한 배추 심 영역 및 깊이를 판별하는 딥러닝 모델을 제안하는 것이다. 또한 계측된 배추의 심 깊이를 예측하는 것이 아닌 discrete 클래스로 변환하여 영역 검출 및 분류를 동시에 하는 모델을 제시하였다. 딥러닝 모델 학습 및 검증을 위하여 전처리 과정을 거지치 않고 수확된 배추 522 포기에 대한 RGB 영상을 획득하였다. 획득한 영상으로부터 심 영역 및 깊이 라벨링 그리고 데이터 증강 기법을 적용하였다. 제안하는 YOLO-v4 딥러닝 모델 기반 배추 심 영역 검출 및 분류 모델의 성능을 평가하기 위하여 mAP, IoU, accuracy, sensitivity, specificity 그리고 F1-score로 선정하였다. 그 결과 배추 심 영역 검출은 mAP 그리고 IoU 값이 각각 0.97 그리고 0.91로 나타났으며, 심 깊이 분류의 경우 accuracy 그리고 F1-score 값이 각각 96.2% 그리고 95.5%로 나타났다. 본 연구 결과를 통하여 배추의 심 영역 검출 및 깊이 정보 분류가 가능하며, 추후 배추 심 제거 공정의 로봇-자동화 시스템 개발에 활용될 수 있는 가능성을 확인하였다.","This paper proposes a deep learning model to determine the region and depth of cabbage cores for robotic automation of the cabbage core removal process during the kimchi manufacturing process. In addition, rather than predicting the depth of the measured cabbage, a model was presented that simultaneously detects and classifies the area by converting it into a discrete class. For deep learning model learning and verification, RGB images of the harvested cabbage 522 were obtained. The core region and depth labeling and data augmentation techniques from the acquired images was processed. MAP, IoU, acuity, sensitivity, specificity, and F1-score were selected to evaluate the performance of the proposed YOLO-v4 deep learning model-based cabbage core area detection and classification model. As a result, the mAP and IoU values were 0.97 and 0.91, respectively, and the acuity and F1-score values were 96.2% and 95.5% for depth classification, respectively. Through the results of this study, it was confirmed that the depth information of cabbage can be classified, and that it can be used in the development of a robot-automation system for the cabbage core removal process in the future."
무인 점포 사용자 이상행동을 탐지하기 위한 지능형 모션 패턴 인식 알고리즘,2023,"['Unmanned Stores', 'Sensors', 'Low Costs', 'Abnormal Behaviors', 'Detect', 'Fusion Algorithm', '무인 점포', '센서', '저비용', '이상행동', '탐지', '융합 알고리즘']","최근 최저시급의 가파른 인상으로 인건비에 대한 부담이 늘어남과 함께 코로나19의 여파로 무인 상점의 점유율이 높아지고 있는 추세이다. 그로 인해 무인 점포를 타겟으로 하는 도난 범죄들도 같이 늘어나고 있어 이러한 도난 사고를 방지하기 위해 Just-Walk -Out 시스템을 도입하고 고비용의 LiDAR 센서, 가중치 센서 등을 사용하거나 수동으로 지속적인 CCTV 감시를 통해서 확인하고 있다. 하지만 이런 고가의 센서를 많이 사용할수록 점포 운영에 있어 비용 부담이 늘어나게 되고, CCTV 확인은 관리자가 24시간 내내 감시하기 어려워서 사용이 제한적이다. 본 연구에서는 이런 센서들이나 사람에 의지하는 부분을 해결할 수 있고 무인점포에서 사용할 수 있는 저비용으로 도난 등의 이상행동을 하는 고객을 탐지하여 클라우드 기반의 알림을 제공하는 인공지능 영상 처리 융합 알고리즘을 제안하고자 한다. 또한 본 연구에서는 mediapipe를 이용한 모션캡쳐, YOLO를 이용한 객체탐지 그리고 융합 알고리즘을 통해 무인 점포에서 수집한 행동 패턴 데이터를 바탕으로 각 알고리즘들에 대한 정확도를 확인하며 다양한 상황 실험을 통해 융합 알고리즘의 성능을 증명했다.","The recent steep increase in the minimum hourly wage has increased the burden of labor costs, and the share of unmanned stores is increasing in the aftermath of COVID-19. As a result, theft crimes targeting unmanned stores are also increasing, and the ""Just Walk Out"" system is introduced to prevent such thefts, and LiDAR sensors, weight sensors, etc. are used or manually checked through continuous CCTV monitoring. However, the more expensive sensors are used, the higher the initial cost of operating the store and the higher the cost in many ways, and CCTV verification is difficult for managers to monitor around the clock and is limited in use. In this paper, we would like to propose an AI image processing fusion algorithm that can solve these sensors or human-dependent parts and detect customers who perform abnormal behaviors such as theft at low costs that can be used in unmanned stores and provide cloud-based notifications. In addition, this paper verifies the accuracy of each algorithm based on behavior pattern data collected from unmanned stores through motion capture using mediapipe, object detection using YOLO, and fusion algorithm and proves the performance of the convergence algorithm through various scenario designs."
가스 누출 탐지 모델 개발을 위한 딥러닝 기반 초음파 이미지 학습 연구,2023,[],"가스는 눈에 보이지 않아 가스 누출 사고가 발생하는 경우 누출 위치 확인 및 사고 규모 예측이 어렵다. 본 연구에서는 가스 누출 시 발생하는 초음파를 시각화하는 기술을 이용하여 가스 누출 여부 뿐만 아니라 가스 누출 위치, 누출 유량 정보를 획득할 수 있는 딥러닝 기반의 가스 누출 탐지 모델을 개발하였다. 연구 방법은 크게 데이터 수집 및 모델 학습으로 구분된다. 먼저 데이터 수집은 초음파 카메라를 이용하여 측정 거리( 1, 3 m ) 및 가스 누출 유량(0~8 L/min)에 따른 초음파 이미지를 수집하였다. 이미지 학습은 YOLO를 이용하였으며 가스 누출 유량 범위에 따라 Class를 설정한 후 모델을 학습하였다. 수집한 초음파 이미지는 측정 거리가 멀어질수록 선명도가 낮아지고, 누출 유량에 따른 이미지의 차이가 거의 없어 육안으로 구분하기 어려웠다. 그러나 모델 학습 결과 precision 0.960, recall 0.967, mAP (IoU 50%) 0.987로 높은 성능을 나타내었으므로 향후 산업현장의 가스 안전 관리 기술로 적용하는 경우 가스 누출로 발생하는 사고를 탐지하고 누출 위치, 누출 유량 등의 정보 전달을 통해 적절한 사고 대응을 제시할 수 있을 것으로 기대된다.","If a gas leak occurs in an industrial area, identifying the location of the gas leak and predicting the scale of the accident are challenging owing to the invisible nature of the gas. In this study, we developed a deep learning-based gas leak detection model that can obtain not only the gas leak status, but also the gas leak location and flow rate information, by using technology to visualize the ultrasonic waves generated during gas leaks. Research methods are broadly categorized into data collection and model learning methods. First, data was collected using an ultrasonic camera to capture ultrasonic images at different measurement distances (1 and 3 m) and gas leak flow rates (0-8 L/min). YOLO (You Only Look Once) was used for image learning, and the model was trained after setting the class according to the gas-leak flow range. The clarity of the collected ultrasonic images decreased as the measurement distance increased. In addition, there was little difference between the images for each leakage flow rate, posing challenges in distinguishing them with the naked eye. However, the model learning results showed high accuracy, with a precision of 0.960, recall of 0.967, and mAP (IoU (Intersection over Union) 50%) of 0.987. Applying this model as a gas safety management technology at industrial sites, enables the accurate determination of gas leak status, gas leak location, and gas leakage flow. This information is expected to guide appropriate accident responses for workers."
객체 검출 기반 클라우드 시스템 : 데이터베이스를 통한 효율적인 병해 모니터링,2023,"['Disease Monitoring', 'Object Detection', 'Cloud System', 'Database', 'Greenhouse']","농촌 인구의 감소와 고령화로 인한 노동력 부족, 비닐하우스 내의 악화된 환경과 위험에 따른 사망 사례가 발생하고 있다. 이에 따라, 비닐하우스에서의 작물 재배와 병해 검출을 자동화하여 인력 손실을 막는 시스템이 필요하다. 본 논문에서는 비닐하우스에서 작물의 병해를 검출하기 위해 객체 검출 기반의 모델을 활용한다. 또한, 클라우드에서 인공지능 모델의 환경을 구성하여 안정성을 확보한다. 제안하는 시스템은 비닐하우스 내에서 촬영한 영상을 데이터베이스에 저장하고, 클라우드에서 영상을 다운로드한 후 Yolo-v4를 기반으로 추론한 검출 결과를 JSON 파일로 생성한다. 이 파일을 분석하여 데이터베이스로 전송하여 저장한다. 실험 결과로 객체 검출을 통한 병해 감지는 비닐하우스와 같은 실제 환경에서 높은 성능을 나타냄을 확인할 수 있고 데이터베이스를 통하여 효율적인 모니터링이 가능함을 확인하였다.","The decline in the rural populace and an aging workforce have led to fatalities due to worsening environments and hazards within vinyl greenhouses. Therefore, it is necessary to automate crop cultivation and disease detection system in greenhouses to prevent labor loss. In this paper, an object detection-based model is used to detect diseased crop in greenhouses. In addition, the system proposed configures the environment of the artificial intelligence model in the cloud to ensure stability. The system captures images taken inside the vinyl greenhouse and stores them in a database, and then downloads the images to the cloud to perform inference based on Yolo-v4 for detection, generating JSON files for the results. Analyze this file and send it to the database for storage. From the experimental results, it was confirmed that disease detection through object detection showed high performance in real environments like vinyl greenhouses. It was also verified that efficient monitoring is possible through the database"
인공지능 학습용 토공 건설장비 영상 데이터셋 구축 및 타당성 검토,2023,"['Civil-engineering dataset', 'Construction equipment', 'Deep learning', 'Image processing', '토목 현장 데이터', '건설 장비', '딥러닝', '영상처리']","최근 건설 현장의 안전사고 비율은 전체 산업에서 가장 높은 비중을 차지한다. 인공지능 기술을 건설 현장에 접목하기 위해서는 기초 학습 자료로 활용될 수 있는 데이터셋 확보가 필수적이다. 본 논문에서는 실제 현장 확보를 통해 원천 데이터를 수집하였으며, 토목 현장에서 주로 운용되고 있는 주요 건설장비 객체를 선정하고 약 9만장의 정지영상 데이터셋 가공을 통해 최적의 학습 데이터셋 구축을 완료하였다. 또한, 객체 인식분야의 대표적인 모델인 YOLO를 활용하여 구축된 데이터의 검증 작업을 수행하였고 90 % 근접한 검출 성능을 확인해 데이터 신뢰성을 확보하였다. 본 연구에서 사용되는 학습 데이터셋은 공공데이터포털에서 활용 가능하도록 공개를 완료하였다. 본 데이터셋은 향후 건설안전 분야의객체 인식 기술의 건설현장 적용을 위한 기반 데이터로 활용 가능하리라 판단된다.","Recently, the rate of death and safety accidents at construction sites is the highest among all kinds of industries. In order to applyartificial intelligence technology to construction sites, it is essential to secure a dataset which can be used as a basic training data. In thispaper, a number of image data were collected through actual construction site, for which major construction equipment objects mainlyoperated in civil engineering sites were defined. The optimal training dataset construction was completed by annotation process ofabout 90,000 image dataset. Reliability of the dataset was verified with the mAP of over 90 % in use of YOLO, a representative modelin the field of object detection. The construction equipment training dataset built in this study has been released which is currentlyavailable on the public data portal of the Ministry of Public Administration and Security. This dataset is expected to be freely used forany application of object detection technology on construction sites especially in the field of construction safety in the future."
화재 탐지 영역의 이미지와 동영상 인식 사이 인공지능 모델 성능 비교 연구,2023,"['fire detection', 'fire situation recognition', 'fire training dataset', 'an artificial intelligence model', 'false-detection rate', '화재감지', '화재상황인식', '화재훈련 데이터 집합', '인공지능 모델', '오탐지율']",,"Purpose: We would like to confirm that the false positive rate of flames/smoke is high when detecting fires. Propose a method and dataset to recognize and classify fire situations to reduce the false detection rate.  Method: Using the video as learning data, the characteristics of the fire situation were extracted and applied to the classification model. For evaluation, the model performance of Yolov8 and Slowfast were compared and analyzed using the fire dataset conducted by the National Information Society Agency (NIA). Result: YOLO's detection performance varies sensitively depending on the influence of the background, and it was unable to properly detect fires even when the fire scale was too large or too small. Since SlowFast learns the time axis of the video, we confirmed that detects fire excellently even in situations where the shape of an atypical object cannot be clearly inferred because the surrounding area is blurry or bright. Conclusion: It was confirmed that the fire detection rate was more appropriate when using a video-based artificial intelligence detection model rather than using image data."
다중 카메라와 객체 탐지를 활용한 건설 현장 사고 감지 시스템,2023,"['object detection', 'AI', 'accident detection', '객체 탐지', '인공지능', '사고 감지']",,"Accidents at construction sites have a very high rate of fatalities due to the nature of being prone to severe injury patients. In order to reduce the mortality rate of severely injury patients, quick response is required, and some systems that detect accidents using AI technology and cameras have been devised to respond quickly to accidents. However, since existing accident detection systems use only a single camera, there are blind spots, Thus, they cannot detect all accidents at a construction site. Therefore, in this paper, we present the system that minimizes the detection blind spot by using multiple cameras. Our implemented system extracts feature points from the images of multiple cameras with the YOLO-pose library, and inputs the extracted feature points to a Long Short Term Memory-based recurrent neural network in order to detect accidents. In our experimental result, we confirme that the proposed system shows high accuracy while minimizing detection blind spots by using multiple cameras."
6자유도 자세 추정을 위한 대용량 3D 객체 데이터 구축,2023,"['large-scale object dataset', 'monocular 3D object detection', '6-DoF object pose estimation']",,"Given the growing necessity of substantial human annotations in deep learning systems to enhance functionality and performance, it is imperative for researchers to scrutinize existing databases and develop their own datasets with custom labels, particularly for target applications such as object detection and pose estimation. This study introduces a large-scale 3D object dataset tailored for six degrees of freedom pose estimation in real-world scenarios. We describe the key features of our datasets available in the AI hub, emphasizing the expansive 3D object collection. Our methodology involves establishing a correspondence between eight points of an object cube in a 2D image, with the object’s pose determined using the conventional perspective-n-point (PnP) algorithm. To analyze the reprojection error, we employed a high-quality 3D mesh model and a binary mask of the target object in the RGB image. For database validation, all object categories were tested using a representative YOLO-like convolutional neural network architecture, such as real-time singleshot pose estimation. In addition, we conduct an in-depth analysis of the current database’s limitations. In the AI hub, we meticulously released all information regarding our new database, presenting it in a format consistent with our baseline database, LINEMOD. A comparative analysis against this baseline was conducted. To overcome the scalability concerns associated with unseen object categories, we explored an effective methodology that leverages vision and language knowledge distillation."
지능형 관제시스템을 위한 딥러닝 기반의 다중 객체 분류 및 추적에 관한 연구,2023,"['객체 분류', '객체 추적', '딥러닝', '지능형', '관제시스템', 'Object Classification', 'Object Tracking', 'Deep Learning', 'Intelligent', 'Manager System']","최근 지능형 관제 시스템은 다양한 응용 분야에서 빠르게 발전하고 있으며, 딥러닝, IoT, 클라우드 컴퓨팅 등의 기술이 지능형 관제 시스템에 활용하는 방안이 연구되고 있다. 지능형 관제 시스템에서 중요한 기술은 영상에서 객체를 인식하고 추적하는 것이다. 그러나 기존의 다중 객체 추적 기술은 정확도 및 속도에서 문제점을 가지고 있다. 본 논문에서는 객체 추적의 정확성을 높이고, 객체가 서로 겹쳐있거나 동일한 클래스에 속하는 객체들이 많을 경우에도 빠르고 정확하게 추적 가능한 원샷 아키텍처 기반의 YOLO v5와 YOLO v6을 사용하여 실시간 지능형 관제시스템을 구현하였다. 실험은 YOLO v5와 YOLO v6를 비교하여 평가하였다. 실험결과 YOLO v6 모델이 지능형 관제시스템에 적합한 성능을 보여주고 있다. 실험결과 YOLO v6 모델이 지능형 관제시스템에 적합한 성능을 보여주고 있다.","Recently, intelligent control systems are developing rapidly in various application fields, and methods for utilizing technologies such as deep learning, IoT, and cloud computing for intelligent control systems are being studied. An important technology in an intelligent control system is recognizing and tracking objects in images. However, existing multi-object tracking technology has problems in accuracy and speed. In this paper, a real-time intelligent control system was implemented using YOLO v5 and YOLO v6 based on a one-shot architecture that increases the accuracy of object tracking and enables fast and accurate tracking even when objects overlap each other or when there are many objects belonging to the same class. The experiment was evaluated by comparing YOLO v5 and YOLO v6. As a result of the experiment, the YOLO v6 model shows performance suitable for the intelligent control system."
시각 장애인을 위한 상품 영양 정보 안내 시스템,2023,"['Product nutrition information system', 'Visually impaired people', 'YOLO v5', 'Data augmentation', 'Hyperparameter tuning']",,"Nutrition information about food is written on the label paper, which is very inconvenient for visually impaired people to recognize. In order to solve the inconvenience of visually impaired people with nutritional information recognition, this paper proposes a product nutrition information guide system for visually impaired people. In the proposed system, user’s image data input through UI, and object recognition is carried out through YOLO v5. The proposed system is a system that provides voice guidance on the names and nutrition information of recognized products. This paper constructs a new dataset that augments the 319 classes of canned/late-night snack product image data using rotate matrix techniques, pepper noise, and salt noise techniques. The proposed system compared and analyzed the performance of YOLO v5n, YOLO v5m, and YOLO v5l models through hyperparameter tuning and learned the dataset built with YOLO v5n models. This paper compares and analyzes the performance of the proposed system with that of previous studies."
이미지 객체 및 메타정보 기반 GPT 활용 SNS 문장 작성 보조 시스템,2023,"['GPT', 'YOLO', '메타정보', 'SNS', '보조시스템', 'GPT', 'YOLO', 'Meta data', 'SNS', 'Supporting system']",,"In this study, we propose an SNS sentence writing assistance system that utilizes YOLO and GPT to assist users in writing texts with images, such as SNS. We utilize the YOLO model to extract objects from images inserted during writing, and also extract meta-information such as GPS information and creation time information, and use them as prompt values for GPT. To use the YOLO model, we trained it on form image data, and the mAP score of the model is about 0.25 on average. GPT was trained on 1,000 blog text data with the topic of ‘restaurant reviews’, and the model trained in this study was used to generate sentences with two types of keywords extracted from the images. A survey was conducted to evaluate the practicality of the generated sentences, and a closed-ended survey was conducted to clearly analyze the survey results. There were three evaluation items for the questionnaire by providing the inserted image and keyword sentences. The results showed that the keywords in the images generated meaningful sentences. Through this study, we found that the accuracy of image-based sentence generation depends on the relationship between image keywords and GPT learning contents."
딥러닝 기반 조류 탐지 모형의 입력 이미지 자료 특성에 따른 성능 변화 분석,2023,"['객체탐지모형', '딥러닝', '수질관리', '조류 대발생', '조류 탐지', 'YOLO 알고리즘', 'algal bloom', 'algal detection', 'deep learning', 'water quality management', 'You-Only-Look-Once algorithm']","조류는 생태계를 구성하는 중요한 요소이다. 그러나 남조류의 과도한 성장은 하천환경에 다양한 악영향을 발생시키고규조류는 상수원과 정수장 공정관리에 영향을 미친다. 지속적이고 효율적인 조류 관리를 위해 조류 모니터링이 중요하다. 본 연구에서는 You Only Look Once (YOLO)의 최신 알고리즘 YOLO v8을 사용하여 조류경보제 기준에 사용하는 유해 남조류 4종과 정수처리공정에 영향이 큰 규조류 1종 총 5종의 이미지를 분류하는 이미지 분류모형을 구축하였다. 기본모형의 mAP는 64.4로 분석되었다. 모형의 학습에 사용된 원본 이미지에 회전, 확대, 축소를 수행하여이미지의 다양성을 높인 5가지 모형을 구축하여 입력자료로 사용된 이미지의 구성에 따른 모형 성능의 변화를 비교하였다. 분석결과 회전, 확대, 축소를 모두 적용한 모형이 mAP 86.5로 가장 좋은 성능을 보이는 것을 확인하였다. 이미지의 회전만을 적용한 모형, 회전과 확대를 적용한 모형, 이미지의 회전과 축소만를 적용한 모형의 mAP는 각각85.3, 82.3, 83.8로 분석되었다.","Algae  are  an  important  component  of  the  ecosystem.  However,  the  excessive  growth  of  cyanobacteria  has various harmful effects on river environments, and diatoms affect the management of water supply processes.Algal monitoring is essential for sustainable and efficient algae management. In this study, an object detection model was developed that detects and classifies images of four types of harmful cyanobacteria used for the criteria of the algae alert system, and one diatom, Synedra sp.. You Only Look Once(YOLO) v8, the latest version of the YOLO model, was used for the development of the model. The mean average precision (mAP) of the base model was analyzed as 64.4. Five models were created to increase the diversity of the input images used for model training by performing rotation, magnification, and reduction of original images. Changes in model  performance  were  compared  according  to  the  composition  of  the  input  images.  As  a  result  of  the analysis, the model that applied rotation, magnification, and reduction showed the best performance with mAP 86.5. The mAP of the model that only used image rotation, combined rotation and magnification, and combined image rotation and reduction were analyzed as 85.3, 82.3, and 83.8, respectively."
데이터 증강 및 앙상블 기법을 이용한 딥러닝 기반 GPR 공동 탐지 모델 성능 향상 연구,2023,"['GPR', '객체 탐지', 'YOLO', '데이터 증강', '자체 앙상블', 'GPR', 'Object detection', 'YOLO', 'Data augmentation', 'Self-ensemble']","방조제의 모니터링에는 지구물리학적 비파괴 검사인 GPR (Ground Penetrating Radar) 탐사가 주로 이용된다. GPR 반응은 상황에 따라 복잡한 양상을 보이므로 자료의 처리와 해석은 전문가의 주관적 판단에 의존하며, 이는 오 탐지의 가능성을 불러옴과 동시에 시간이 오래걸린다는 단점이 있다. 따라서 딥 러닝을 이용하여 GPR 탐사자료의 공동을 탐지하는 다양한 연구들이 수행되고 있다. 딥 러닝 기반 방법은 데이터 기반 방법으로써 풍부한 자료가 필요하나 GPR 탐사의 경우 비용 등의 이유로 학습에 이용할 현장 자료가 부족하다. 따라서 본논문에서는 데이터 증강 전략을 이용하여 딥 러닝 기반 방조제 GPR 탐사자료 공동 탐지 모델을 개발하였다. 다년간 동일한 방조제에서탐사 자료를 사용하여 데이터 세트를 구축하였으며, 컴퓨터 비전 분야의 객체 탐지 모델 중 YOLO (You Look Only Once) 모델을 이용하였다. 데이터 증강 전략을 비교 및 분석함으로써 최적의 데이터 증강 전략을 도출하였고, 초기 모델 개발 후 앵커 박스 클러스터링, 전이학습, 자체 앙상블, 모델 앙상블 기법을 단계적으로 적용하여 최종 모델 도출 후 성능을 평가하였다.","Ground-penetrating radar (GPR) surveys are commonly used to monitor embankments, which is a nondestructive geophysical method.The results of GPR surveys can be complex, depending on the situation, and data processing and interpretation are subject to expert experiences, potentially resulting in false detection. Additionally, this process is time-intensive. Consequently, various studies have been undertaken to detect cavities in GPR survey data using deep learning methods. Deep-learning-based approaches require abundant data for training, but GPR field survey data are often scarce due to cost and other factors constaining field studies. Therefore, in this study, a deep- learning-based model was developed for embankment GPR survey cavity detection using data augmentation strategies. A dataset was constructed by collecting survey data over several years from the same embankment. A you look only once (YOLO) model, commonly used in computer vision for object detection, was employed for this purpose. By comparing and analyzing various strategies, the optimal data augmentation approach was determined. After initial model development, a stepwise process was employed, including box clustering, transfer learning, self-ensemble, and model ensemble techniques, to enhance the final model performance. The model performance was evaluated, with the results demonstrating its effectiveness in detecting cavities in embankment GPR survey data."
Recognition and Identification of College Students' Classroom Behaviors through Deep Learning,2023,"['Classroom behavior', 'Deep learning', 'YOLO v5s']",,"Recognizing and managing college students' classroom behavior in a timely manner is of great help in improving teaching quality and strengthening classroom management. This paper builds a model based on the You Only Look Once Version 5 Small (YOLO v5s) algorithm using deep learning to detect and identify college students' classroom behaviors. The LabelImg annotation tool was used to process the dataset images, and the labeled dataset was the input for the object detection model to recognize college students' classroom behaviors. Although the precision, recall, mean average precision (mAP), and detection speed of the YOLO v5s model were slightly lower with large classroom densities, compared to medium classroom densities, the difference was negligible. At the same time, the mAP values of the proposed model under three different intersection-over-union thresholds were higher than the single shot multibox detector and region-based convolutional neural network models, reaching 95.8, 94.3, and 92.9. This paper proves that YOLO v5s can effectively and accurately recognize classroom behavior in real time."
시각장애인을 위한 딥러닝 기반 음료수 캔 인식 시스템,2023,"['Visually Impaired', 'Beverage Can Recognition', 'CNN', 'YOLO']",,"Recently, deep learning has been used in the development of various institutional devices and services to help the visually impaired people in their daily lives. This is because not only are there few products and facility guides written in braille, but less than 10% of the visually impaired can use braille. In this paper, we propose a system that recognizes beverage cans in real time and outputs the beverage can name with sound for the convenience of the visually impaired. Five commercially available beverage cans were selected, and a CNN model and a YOLO model were designed to recognize the beverage cans. After augmenting the image data, model training was performed. The accuracy of the proposed CNN model and YOLO model is 91.2% and 90.8%, respectively. For practical verification, a system was built by attaching a camera and speaker to a Raspberry Pi. In the system, the YOLO model was applied. It was confirmed that beverage cans were recognized and output as sound in real time in various environments."
Human Detection using Real-virtual Augmented Dataset,2023,"['Data augmentation', 'Human detection', 'Semi-synthetic data', 'YOLO etc.']",,"This paper presents a study on how augmenting semi-synthetic image data improves the performance of human detection algorithms. In the field of object detection, securing a high-quality data set plays the most important role in training deep learning algorithms. Recently, the acquisition of real image data has become time consuming and expensive; therefore, research using synthesized data has been conducted. Synthetic data haves the advantage of being able to generate a vast amount of data and accurately label it. However, the utility of synthetic data in human detection has not yet been demonstrated. Therefore, we use You Only Look Once (YOLO), the object detection algorithm most commonly used, to experimentally analyze the effect of synthetic data augmentation on human detection performance. As a result of training YOLO using the Penn-Fudan dataset, it was shown that the YOLO network model trained on a dataset augmented with synthetic data provided high-performance results in terms of the Precision-Recall Curve and F1-Confidence Curve."
로봇 작업장 환경의 작업자 안전 시스템 개발,2023,"['safety system', 'robot safety system', 'human safety', 'YOLO', 'YOLO v2', 'deep-learning', 'CNN', '.']","공장의 생산 라인에 다양한 로봇들이 점점 더 적용됨으로 로봇 작업 환경에서 작업자의 안전이 더 중요하게 고려되고 있다. 본 연구는 이러한 작업 공간에 대한 실시간 모니터링을 통하여 작업자 안전을 제공할 수 있는 안전 시스템의 개발을 목표로 하였다. 안전 시스템의 구현은 여러 대의 카메라를 여러 방향에 설치하여 사각지대 없이 작업 환경을 실시간으로 촬영하였으며 실제 상황에서의 물체 검출에 많이 쓰이는 YOLO 알고리즘을 사용하여 작업자에 대한 검출을 수행하였다. 본 논문에서는 검출 위치 마스크와 작업 영역 마스크 설정 방법을 제시하고 이를 이용한 안전 감지 방법을 제안하였다. 로봇 작업 환경을 구성하고 획득한 영상을 통하여 작업자 검출 성능을 평가하였고 실제 작업 환경에서의 감지 성능을 확인하였다. 여러 대의 카메라를 사용하는 경우, 구현된 시스템은 보다 안정적으로 작업자의 안전을 제공하였다.","Various robots are increasingly being applied to production lines in factories, and the human safety is considered more important in robot work-places. This study aimed at developing a safety system that can provide the human safety through real-time monitoring of work-places. The safety system was implemented by installing multiple cameras in multiple directions to capture the working environment in real time without blind spots, and the detection of human was performed using the YOLO algorithm, which is widely used for object detection in real situations. This paper presents methods for setting the position mask and the zone mask, and proposes a method of safety detection using the settings. The robot work environment was configured, the performance to detect human was evaluated through the acquired images and the performance of the safety system was confirmed. In the case of using multiple cameras, the implemented system provided human safety more reliably."
유치의 치근단 방사선 사진에서 딥 러닝 알고리즘을 이용한 모델의 인접면 우식증 객체 탐지 능력의 평가,2023,"['.', 'Object Detection', 'Dental Caries', 'Deep Learning', 'Radiographs']","이 연구의 목적은 소아의 치근단 방사선 사진에서 인접면 우식증 객체 탐지 의 객체 탐지를 위해 YOLO (You Only Look Once)를 사용한 모델의 성능을 평가하는 것이다. M6 데이터베이스에서 학습자료군으로 2016개의 치근단 방사선 사진이 선택되었고 이 중 1143 개는 한 명의 숙련된 치과의사가 주석 도구를 사용하여 인접면 우식증을 표시하였다. 표시한 주석을 데이터 세트로 변환한 후 단일 합성곱 신경망(CNN) 모델을 기반으로 하는YOLO를 데이터 세트에 학습시켰다. 187개의 평가자료군에서 객체 탐지 모델 성능 평가를위해 정확도, 재현율, 특이도, 정밀도, NPV, F1-score, PR 곡선 및 AP를 계산하였다. 결과로 정확도 0.95, 재현율 0.94, 특이도 0.97, 정밀도 0.82, NPV 0.96, F1-score 0.81, AP 0.83 으로 인접면 우식증 탐지에 좋은 성능을 보였다. 이 모델은 치과의사에게 치근단 방사선 사진에서 인접면 우식증 병변을 객체 탐지하는 도구로 유용하게 사용될 수 있다.","The purpose of this study was to evaluate the performance of a model using You Only Look Once (YOLO) for object detection of proximal caries in periapical radiographs of children. A total of 2016 periapical radiographs in primary dentition were selected from the M6 database as a learning material group, of which 1143 were labeled as proximal caries by an experienced dentist using an annotation tool. After converting the annotations into a training dataset, YOLO was trained on the dataset using a single convolutional neural network (CNN) model. Accuracy, recall, specificity, precision, negative predictive value (NPV), F1-score, Precision-Recall curve, and AP (area under curve) were calculated for evaluation of the object detection model’s performance in the 187 test datasets. The results showed that the CNN-based object detection model performed well in detecting proximal caries, with a diagnostic accuracy of 0.95, a recall of 0.94, a specificity of 0.97, a precision of 0.82, a NPV of 0.96, and an F1-score of 0.81. The AP was 0.83. This model could be a valuable tool for dentists in detecting carious lesions in periapical radiographs."
AIoT 기반의 영상처리를 통한 근로자 스마트 안전관리 플랫폼,2023,"['Internet of Things', 'Yolo V5', 'Sensor', 'Safety Management', 'Image Processing']","본 연구는 인공지능과 사물인터넷 기술을 결합한 AIoT 기반의 영상처리 기술을 활용하여, 제조 현장에서 근로자의 안전을 위한 스마트 안전관리 플랫폼을 개발하는 것을 목표로 한다. 이 플랫폼은 산업 현장의 다양한 안전사고를 예방하는 데 목적이 있으며, 근로자의 안전 및 생산성 향상에 도움이 될 수 있도록 설계한다. 플랫폼 개발을 위해 영상처리 기술로부터 얻은 정보를 인공지능(AI) 알 고리즘에 적용하고, 이를 기반으로 산업 현장에서 발생할 수 있는 위험 요소를 실시간으로 감지한다. 또한, 사물인터넷(IoT) 기술을 활용하여, 안전 장비 및 기기들과의 연동을 통하여 산업 현장에서 보다 효과적인 안전관리가 이루어질 수 있도록 한다. 화재와 연기 감지를 중점으로 한 연구에서는 Yolo v5 알고리즘을 활용하였다. 학습 결과로서 'all' 클래스의 mAP50 값은 0.96으로, 'fire' 클래스의 mAP 값은 0.97로, 그리고 'smoke' 클래스의 mAP 값은 0.95로 측정되었다. 이러한 스마트 안전관리 플랫폼의 구현은 근로자들이 산업 현장에서 위험을 회피하고 안전사고 발생 가능성을 줄이는데 큰 도움이 될 것으로 기대되며, 이를 통해 기업뿐만 아니라 사회 전반의 안전 문화 확산에 기여할 수 있는 플랫폼을 제안하였다.","This research aims to utilize AIoT-based video processing technology that combines artificial intelligence and Internet of Things technology to develop a smart safety management platform for worker safety at manufacturing sites. The platform aims to prevent various safety incidents on manufacturing sites and is designed to help improve worker safety and productivity. To develop the platform, information obtained from image processing technology is applied to artificial intelligence (AI) algorithms, and based on this, risk factors that may occur at industrial sites are detected in real-time. Additionally, by utilizing Internet of Things (IoT) technology, more effective safety management will be possible at manufacturing sites by linking safety devices and devices. In a study emphasizing fire and smoke detection, the Yolo v5 algorithm was used. As a result of the training, the mAP50 value for the 'all' class was measured at 0.96, the mAP value for the 'fire' class was 0.97, and for the 'smoke' class, it was 0.95. The implementation of such an intelligent safety management platform is expected to be of great help to workers in avoiding hazards at industrial sites and reducing the possibility of safety accidents, which will benefit not only companies but also society as a whole. A platform was proposed to contribute to the spread of safety culture."
차량 내 영상 센서 기반 고속도로 돌발상황 검지 정밀도 평가,2023,"['Dash cam', 'AI', 'Computer Vision', 'YOLO', 'Incident Detection Time', '대쉬보드 카메라', 'AI', '컴퓨터 비전', 'YOLO', '돌발상황 검지시간']",,"With the development of computer vision technology, video sensors such as CCTV are detecting incident. However, most of the current incident have been detected based on existing fixed imaging equipment. Accordingly, there has been a limit to the detection of incident in shaded areas where the image range of fixed equipment is not reached. With the recent development of edge-computing technology, real-time analysis of mobile image information has become possible. The purpose of this study is to evaluate the possibility of detecting expressway emergencies by introducing computer vision technology to dash cam. To this end, annotation data was constructed based on 4,388 dash cam still frame data collected by the Korea Expressway Corporation and analyzed using the YOLO algorithm. As a result of the analysis, the prediction accuracy of all objects was over 70%, and the precision of traffic accidents was about 85%. In addition, in the case of mAP(mean Average Precision), it was 0.769, and when looking at AP(Average Precision) for each object, traffic accidents were the highest at 0.904, and debris were the lowest at 0.629."
딥러닝 기반의 자동차 분류 및 추적 알고리즘,2023,"['Vehicle Classification', 'Moving Object Tracking', 'Deep Learning', 'YOLO']",,"One of the difficult works in an autonomous driving system is detecting road lanes or objects in the road boundaries. Detecting and tracking a vehicle is able to play an important role on providing important information in the framework of advanced driver assistance systems such as identifying road traffic conditions and crime situations. This paper proposes a vehicle detection scheme based on deep learning to classify and tracking vehicles in a complex and diverse environment. We use the modified YOLO as the object detector and polynomial regression as object tracker in the driving video. With the experimental results, using YOLO model as deep learning model, it is possible to quickly and accurately perform robust vehicle tracking in various environments, compared to the traditional method."
딥러닝 알고리즘 기반 교통법규 위반 공익신고 영상 분석 시스템,2023,"['딥러닝', '컴퓨터 비전', '공익 신고', '차선변경 위반', 'Deep Learning', 'Computer Vision', 'YOLO', 'Lanenet', 'public interest report', 'Lane change Violation']","고화질 블랙박스의 확산과 ‘스마트 국민제보’, ‘안전신문고’ 등 모바일 애플리케이션의 도입에 따른 영향으로 교통법규 위반 공익신고가 급증하였으며, 이로 인해 이를 처리할 담당 경찰 인력은 부족한 상황이 되었다. 본 논문에서는 교통법규 위반 공익신고 영상 중, 가장 많은 비중을 차지하는 차선위반에 대해 딥러닝 알고리즘을 활용하여 자동 검출할 수 있는 시스템의 개발내용에 관해 기술한다. 본 연구에서는 YOLO 모델과 Lanenet 모델을 사용하여 차량과 실선 객체를 인식하고 deep sort 알고리즘을 사용하여 객체를 개별로 추적하는 방법, 그리고 차량 객체의 바운딩 박스와 실선 객체의 범위가 겹치는 부분을 인식하여 진로변경 위반을 검출하는 방법을 제안한다. 본 시스템을 통해 신고된 영상에 대해 교통법규 위반 여부를 자동 분석해줌으로써 담당 경찰 인력 부족난을 해소할 수 있을 것으로 기대한다.","Due to the spread of high-definition black boxes and the introduction of mobile applications such as 'Smart Citizens Report' and 'Safety Report', the number of public interest reports for violations of Traffic Law has increased rapidly, resulting in shortage of police personnel to handle them. In this paper, we describe the development of a system that can automatically detect lane violations which account for the largest proportion of public interest reporting videos for violations of traffic laws, using deep learning algorithms. In this study, a method for recognizing a vehicle and a solid line object using a YOLO model and a Lanenet model, a method for tracking an object individually using a deep sort algorithm, and a method for detecting lane change violations by recognizing the overlapping range of a vehicle object's bounding box and a solid line object are described. Using this system, it is expected that the shortage of police personnel in charge will be resolved."
Lightweight high-precision pedestrian tracking algorithm in complex occlusion scenarios,2023,"['object tracking', 'attention mechanism', 'object detection', 'non-maximum suppression', 'lightweight neural network']",,"Aiming at the serious occlusion and slow tracking speed in pedestrian target tracking and recognition in complex scenes, a target tracking method based on improved YOLO v5 combined with Deep SORT is proposed. By merging the attention mechanism ECA-Net with the Neck part of the YOLO v5 network, using the CIoU loss function and the method of CIoU non-maximum value suppression, connecting the Deep SORT model using Shuffle Net V2 as the appearance feature extraction network to achieve lightweight and fast speed tracking and the purpose of improving tracking under occlusion. A large number of experiments show that the improved YOLO v5 increases the average precision by 1.3% compared with other algorithms. The improved tracking model, MOTA reaches 54.3% on the MOT17 pedestrian tracking data, and the tracking accuracy is 3.7% higher than the related algorithms and The model presented in this paper improves the FPS by nearly 5 on the fps indicator."
Dynamic Framerate SlowFast Network for Improving Autonomous Driving Performance,2023,"['YOLO', 'SlowFast network', 'Action recognition', 'Autonomous driving']",,"Computer vision technology is used for autonomous driving and road traffic safety. Accordingly, studies on deep learning models that detect and analyze objects through images or videos are ongoing. On the other hand, deep learning algorithms that detect even the action of things require high computing performance. In addition, the computing performance of autonomous driving vehicles for processing such tasks is inferior. These classification processes are not used for recognizing and determining autonomous driving vehicles because it is impossible to process the classification of the action of autonomous driving vehicles in an autonomous driving vehicle on a real-time basis. This paper proposes a Dynamic Framerate SlowFast network for improving autonomous driving performance. Unlike pre-existing studies, the proposed model includes a cropping process through the YOLO model. In addition, it measures the similarity between unit frames through the SSIM and skips the input when the similarity exceeds a certain level. This process made it possible to reduce the number of frames entered into the model. Compared to the existing SlowFast Network, the performance evaluation compared the time required to analyze one image and the AUC of classification results when the number of input frames was reduced through similarity analysis techniques. The similarity analysis technique achieved the highest AUC when the SSIM was applied. The Dynamic Framerate SlowFast network proposed in this study achieved an AUC of 0.7126 and took an FPS of 0.7912 to analyze the entire verification video data. Compared to the pre-existing SlowFast network, which took an FPS of 0.5285 to achieve an AUC of 0.7531, the Dynamic Framerate SlowFast network achieved faster and more accurate results. Therefore, using the proposed technique, it is possible to achieve faster detection results while maintaining the object action detection AUC of the SlowFast network."
해상물체탐지시스템 거리오차 보정에 관한 연구,2023,"['자율운항선박', 'YOLO', '거리오차', '평균필터', '이동평균필터', 'Autonomous ship', 'YOLO', 'Distance error', 'Average filter', 'Moving average filter']","양식장 부표 등과 같은 해상의 소형 장애물을 탐지하고 거리와 방위를 시각화시켜 주는 해상물체탐지시스템은 선체운동으로 인한 오차를 보정하기 위해 3축 짐벌이 장착되어 있지만, 파도 등에 의한 카메라와 해상물체의 상하운동으로 발생하는 거리오차를 보정하지 못하는 한계가 있다. 이에 본 연구에서는 외부환경에 따른 수면의 움직임으로 발생하는 해상물체탐지시스템의 거리오차를 분석하고, 이를 평균필터와 이동평균필터로 보정하고자 한다. 가우시안 표준정규분포를 따르는 난수를 이미지 좌표에 가감하여 불규칙파에 의한 부표의 상승 또는 하강을 재현하였다. 이미지 좌표의 변화에 따른 계산거리, 평균필터와 이동평균필터를 통한 예측거리 그리고 레이저 거리측정기에 의한 실측거리를 비교하였다. phase 1,2에서 불규칙파에 의한 이미지 좌표의 변화로 오차율이 최대 98.5%로 증가하였지만, 이동평균필터를 사용함으로써 오차율은 16.3%로 감소하였다. 오차보정 능력은 평균필터가 더 좋았지만 거리변화에 반응하지 못하는 한계가 있었다. 따라서 해상물체탐지시스템 거리오차 보정을 위해 이동평균필터를 사용함으로써 실시간 거리변화에 반응하고 오차율을 크게 개선할 수 있을 것으로 판단된다.",
YOLOv5와 Dual Kalman Filter 기반의 폐색영역에 강건한 객체 추적 프레임워크,2023,"['occlusion area', 'YOLO', 'kalman filter', 'dual kalman filter', 'object tracking', 'object detection']",,"Although YOLO(You Only Look Once) is a widely used algorithm in real-time object detection, it has a limitation in that its performance significantly deteriorates in occlusion areas where a detection target is obscured by another object or surrounding background. In this study, we propose a robust object tracking framework that utilizes YOLOv5 and a Dual Kalman Filter(KF) consisting of Detection and Inference KFs to address this issue. The proposed framework uses the Detection KF updated with a high weight on the detection results of YOLOv5 when YOLOv5 fails to detect objects. If the object is not detected over successive frames, the proposed framework attempts to track the object using the Inference KF updated with a high weight on the prediction results of KF. Through experiments using data with occluded regions, we confirmed that the proposed framework outperformed existing approaches in terms of detection accuracy while sacrificing less computation speed."
Insulator Defects Detection for Aerial Photography of the Power Grid Using You Only Look Once Algorithm,2023,"['Insulator defects detection', 'YOLO algorithm', 'Data augmentation', 'Object detection', 'Aerial images']",,"The safe operation of the power grid system depends partly on regular inspections of transmission lines, in which the insulator is one of the most important inspections objects. The manual inspection of transmission lines is a chaotic process that is both time and cost-consuming since it involves an accurate manual inspection by an expert. For insulator defect detection, an improved YOLOv4 algorithm is proposed. First, a new data augmentation method is proposed to solve the problem of insufficient sample size. Then, the size of the anchor boxes is redesigned base on the K-means algorithm to further improve the detection precision. Finally, an insulator defects detection network is constructed based on YOLOv4. Experimental results show that the detection precision of the improved network is 37.2% higher after data enhancement and anchor boxes redesign. In addition, the detection method proposed in this paper is superior to other popularity detection algorithms, including the single shot detector, region-convolutional neural networks (Faster-RCNN) and released version of you only look once (YOLO). The value of mean average precision is 99.08% and frame per second is 56. The robustness test results demonstrate that our proposed algorithm performs well under different light intensities and complex environmental backgrounds, and can accurately detect all targets, which is significantly better than other comparative algorithms. In terms of detection accuracy, test speed and robustness, our proposed algorithm meets the requirements of industrial field applications of insulator defect detection."
인공지능 기반 컨테이너 적재 안전관리 시스템 연구,2023,"['지능형 항만 안전 기술', '컨테이너', '객체인식', '딥러닝', 'YOLO', 'Intelligent Port Safety Technology', 'Shipping Container', 'Object Detection', 'Deep Learning', 'YOLO']","최근 스마트항만을 구축하기 위해 ICT 기술이 적용된 물류 자동화, 항만 운영 자동화 등 다양한 기술이 개발 중이다. 하지만 항만 안전과 안전사고를 예방하기 위한 기술 개발은 부족한 상황이다. 이에 본 논문에서는 항만 내 컨테이너 적재 공간에서 발생할 수 있는 안전사고를 예방하기 위한인공지능 기반 컨테이너 적재 안전관리 시스템을 제안한다. 이 시스템은 인공지능 기반 컨테이너 안전사고 위험도 분류 및 저장 기능과 실시간안전사고 모니터링 기능으로 구성되어 있다. 이 시스템은 실시간으로 현장의 사고 위험도를 모니터링하며 이를 통해 컨테이너 붕괴사고를 예방할수 있다. 제안된 시스템은 프로토타입으로 개발되어 직접 항만에 적용하여 시스템을 평가하였다",
교통사고 저감을 위한 인공지능 기반 인캐빈 모니터링 시스템,2023,"['Drowsy Driving Detection', 'Recognition', 'Arduino', 'Traffic Safety', 'YOLO', '졸음운전감지', '객체 인식', '아두이노', '교통안전', 'YOLO']",,"Vision contains the majority of the information necessary for humans to interact with their surrounding environment. For these reasons, visually impaired individuals face significant limitations in terms of information access compared to non-visually impaired individuals. This paper proposes a system to enhance information accessibility for the visually impaired by extracting and translating text from images into Braille, enabling real-time implementation. The proposed system utilizes optical character recognition technology, specifically EasyOCR, and a Korean language recognition model to recognize and digitize text after separating phonemes. The hardware-implemented system operates through a relay and solenoid-based Braille system, allowing individuals with visual impairments to recognize the outputted Braille using tactile senses. This approach aims to reduce barriers to information access for the visually impaired, providing them with equal opportunities in various aspects compared to sighted individuals and fostering their active participation in society."
딥러닝 모델을 통한 포유기 모돈과 자돈 실시간 행동 탐지,2023,"['Deep Learning', 'Object Detection', 'Smart Farm', 'YOLO', '모돈', '자돈', '딥러닝', '객체 탐지', '스마트팜', 'YOLO']",,"On pig farms, the highest mortality rate is observed among nursing piglets. To reduce this mortality rate, farmers need to carefully observe the piglets to prevent accidents such as being crushed and to maintain a proper body temperature. However, observing a large number of pigs individually can be challenging for farmers. Therefore, our aim was to detect the behavior of piglets and sows in real-time using deep learning models, such as YOLOv4-CSP and YOLOv7-E6E, that allow for real-time object detection. YOLOv4-CSP reduces computational cost by partitioning feature maps and utilizing Cross-stage Hierarchy to remove redundant gradient calculation. YOLOv7-E6E analyzes and controls gradient paths such that the weights of each layer learn diverse features. We detected standing, sitting, and lying behaviors in sows and lactating and starving behaviors in piglets, which indicate nursing behavior and movement to colder areas away from the group. We optimized the model parameters for the best object detection and improved reliability by acquiring data through experts. We conducted object detection for the five different behaviors. The YOLOv4-CSP model achieved an accuracy of 0.63 and mAP of 0.662, whereas the YOLOv7-E6E model showed an accuracy of 0.65 and mAP of 0.637. Therefore, based on mAP, which includes both class and localization performance, YOLOv4-CSP showed the superior performance. Such research is anticipated to be effectively utilized for the behavioral analysis of fattening pigs and in preventing piglet crushing in the future."
실시간 수어 AI 번역 프로그램 구현,2023,"['Deep Learning', 'Object Detection', 'Sign Language', 'YOLO', 'YOLOv7', '딥러닝', '객체 탐지', '수어', 'YOLO', 'YOLOv7']",,"In many countries worldwide, sign language is highly valued, with some even designating it as an official language to enhancesocial inclusion opportunities. However, despite these efforts, communication barriers between spoken language and sign languagepersist. In this paper, we aim to address these issues by implementing a real-time sign language translation AI program using theYOLOv7 deep learning algorithm, known for its speed and relatively high accuracy. Our goal is to translate Korean SignLanguage into Korean in real-time, thus bridging the communication gap between sign language and spoken language. We utilize a total of 35 data categories, and the training results yield an mAP@0.5:0.95 value of 0.818. The recognition rate using the testdataset showed an accuracy of over 80%. It is expected that the implemented real-time sign language translation AI program willcontribute to reducing the communication gap between sign language and spoken language."
CNN과 GRU 모델을 활용한 음주상태 판별시스템 설계 및 구현,2023,"['Convolution Neural Networks(CNN)', 'Gated Recurrent Unit(GRU)', 'You Only Look Once(YOLO)', 'Motion Detection', 'CNN', 'GRU', 'YOLO', '움직임 검출']","음주운전은 전 세계적으로 심각한 문제로 인식되고 있으며, 특히 최근 5년 동안 한국에서는 일일 평균 48건의 음주운전 사고가 발생하여 많은 사망자와 부상자를 초래하는 등 교통 안전에 대한 중요한 문제로 부상하였다. 이를 해결하기 위해 본 논문에서는 CNN(Convolutional Neural Network)과 GRU(Gated Recurrent Unit)를 결합한 인공지능 모델을 활용하여 음주상태를 식별하는 방법을 제시하였다. 제안한 모델은 이미지에서의 복잡한 특징과 특징들 사이의 시간적 연속성을 인식하므로, 음주 상태 판단에 효과적이다. 본 연구는 교통 안전에 대한 새로운 관점을 제시하며, 향후 인공지능을 활용한 차량 운전자의 음주 상태 감지와 그에 따른 교통사고 예방에 있어 중요한 기초자료를 제공한다. 또한, 제안한 모델은 실시간 모니터링 및 조기 경보 시스템에 적용될 경우 음주운전과 관련된 교통사고 등을 사전에 방지할 수 있을 것으로 기대한다.","Drunk driving is recognized as a serious problem worldwide, and especially in Korea, it has emerged as a crucial issue for traffic safety with an average of 48 daily alcohol-related accidents resulting in numerous fatalities and injuries over the past five years. In this paper, a new method for identifying an alcohol intoxication by combining CNN(Convolutional Neural Network) and GRU(Gated Recurrent Unit) models is proposed. The proposed model effectively captures the complex features in images and their temporal continuity, making it effective in determining alcohol intoxication. In the training phase, data collection and storage, video segmentation and preprocessing, labeling of alcohol consumption status, traing of YOLOv4 model, and utilization of a hybrid CNN-GRU model steps are composed. In the classification phase, user video input reception, video segmentation, image preprocessing and feature extraction, and alcohol intoxication status determination steps are composed. As a result, we have developed a model for alcohol intoxication classification based on CNN, YOLOv4, and GRU, and constructed a system that provides a web environment. Furtheremore, the proposed system demonstrates outstanding scalability by offering web services to enhance user-friendliness. The proposed method provides a new perspective on traffic safety and serves as important foundational material for application of AI-based detection of alcohol-intoxicated drivers and prevention of associated accidents. Furthermore, the proposed model is expected to proactively prevent alcohol-related accidents when applied to real-time monitoring and early warning systems."
딥러닝 신경망을 사용하는 벤더-게슈탈트 검사의 자동채점 : 도형의 배열순서,2023,"['벤더-게슈탈트 검사(BGT)', '자동 채점', '패턴인식', '객체탐지', 'YOLO', 'Bender-Gestalt Test', 'Automatic Scoring', 'Pattern Recognition', 'Object Detection', 'YOLO']",,
건설 근로자 안전모 실시간 감지를 위한 딥러닝 적용 연구,2023,"['Safety helmet', 'Construction safety', 'Construction worker', 'Deep learning', 'Real-time object detections']",,"This study explored the applicability of deep learning models for real-time safety helmet detection of construction workers. The performance and speed of RCNN-based model and YOLO model, which are representative models of object recognition among deep learning models, were compared. Faster-RCNN model of RCNN series was used, and Yolov3 and Yolov5 of YOLO model were applied. As a result, the Yolov5 model showed the highest performance and fastest processing speed. Among them, Yolov5x showed the highest performance, and Yolov5n showed the fastest processing speed. As a result of this experiment, Yolov5x can be fully utilized for real-time detection of safety helmet."
Car detection area segmentation using deep learning system,2023,"['Image processing', 'QT', 'Deep learning segmentation', 'Object detection.']",,"A recently research, object detection and segmentation have emerged as crucial technologies widely utilized in various fields such as autonomous driving systems, surveillance and image editing. This paper proposes a program that utilizes the QT framework to perform real-time object detection and precise instance segmentation by integrating YOLO(You Only Look Once) and Mask R CNN. This system provides users with a diverse image editing environment, offering features such as selecting specific modes, drawing masks, inspecting detailed image information and employing various image processing techniques, including those based on deep learning.The program advantage the efficiency of YOLO to enable fast and accurate object detection, providing information about bounding boxes. Additionally, it performs precise segmentation using the functionalities of Mask R CNN, allowing users to accurately distinguish and edit objects within images. The QT interface ensures an intuitive and user-friendly environment for program control and enhancing accessibility.Through experiments and evaluations, our proposed system has been demonstrated to be effective in various scenarios. This program provides convenience and powerful image processing and editing capabilities to both beginners and experts, smoothly integrating computer vision technology. This paper contributes to the growth of the computer vision application field and showing the potential to integrate various image processing algorithms on a user-friendly platform"
물고기의 성장도를 예측하는 FGRS(Fish Growth Regression System),2023,"['fish growth', 'deeplearning', 'fish detection', 'fish farm automation', 'cnn']","양식장에서 물고기의 성장을 측정하는 작업은 아직도 사람의 손이 많이 가는 방식을 사용한다. 이 방식은 많은 노동력이 필요하고, 물고기가 스트레스를 받아 폐사율에 악영향을 준다. 이러한 문제를 해결하기 위해  물고기의 성장도를 자동화하기 위한 시스템 FGRS(Fish Growth Regression System)를 제안한다. FGRS는 두 개의 모듈로 구성된다. 첫째는 Yolo v8 기반의 물고기를 디텍팅하는 모듈이고, 둘째는 물고기 영상 데이터를 CNN 기반의 신경망 모델을 이용하여 물고기의 성장도를 예측하는 모듈로 구성된다. 시뮬레이션 결과 학습전에는 예측 오차가 평균 134.2일로 나왔지만 학습 이후 평균 오차가 39.8일 까지 감소했다. 본 논문에서 제안한 시스템을 이용해 생육일을 예측하여 물고기의 성장예측을 활용해 양식장에서의 자동화에 기여할 수 있고, 많은 노동력 감소와 비용 절감 효과를 가져 올 수 있을 것이라 기대한다.","Measuring the growth of fish in fish farms still uses a laborious method. This method requires a lot of labor and causes stress to the fish, which has a negative impact on mortality. To solve this problem, we propose the Fish Growth Regression System (FGRS), a system to automate the growth of fish. FGRS consists of two modules. The first is a module that detects fish based on Yolo v8, and the second consists of a module that predicts the growth of fish using fish image data and a CNN-based neural network model. As a result of the simulation, the average prediction error before learning was 134.2 days, but after learning, the average error decreased to 39.8 days. It is expected that the system proposed in this paper can be used to predict the growing date and use the growth prediction of fish to contribute to automation in fish farms, resulting in a significant reduction in labor and cost savings."
조식동물 탐지 및 모니터링을 위한 딥러닝 기반 객체 탐지 모델의 강인성 평가,2023,"['Deep learning', 'Object detection', 'Invertebrate grazers', 'Robustness tes', '딥러닝', '객체 탐지', '조식동물', '강인성 평가']","최근 조식동물로 인한 갯녹음 현상으로 인해 연안 생태계 및 어장환경의 황폐화가 가속화되고 있다. 이러한 갯녹음 현상을 모니터링하고 방지대책을 세우기 위해서는 광범위한 해역에 대한 원격탐사 기반의 모니터링 기술 도입이 필요하다. 본 연구에서는 수중에서 촬영된 동영상으로부터 조식동물을 탐지하고 모니터링하기위한 딥러닝 기반 객체 탐지 모델의 강인성(robustness)을 비교 분석하였다. 우리나라 연안의 대표적인 조식동물7종을 대상으로 이미지 데이터셋을 구축하였으며, 이를 활용하여 딥러닝 기반 객체 탐지 모델인 You Only LookOnce (YOLO)v7과 YOLOv8을 훈련시켰다. 총 6개의 YOLO 모델(YOLOv7, YOLOv7x, YOLOv8s, YOLOv8m,YOLOv8l, YOLOv8x)에 대해 탐지 성능과 탐지 속도를 평가하였으며, 수중환경에서 촬영 시 발생할 수 있는 다양한 이미지 왜곡에 대해서 강인성 평가를 실시하였다. 평가결과 YOLOv8 계열 모델이 파라미터(parameter) 수대비 더 높은 탐지 속도(약 71–141 FPS [frame per second])를 보였다. 탐지 성능에 있어서도 YOLOv8 계열 모델(mean average precision [mAP] 0.848–0.882)이 YOLOv7 계열 모델(mAP 0.847–0.850)에 비해 더 높은 성능을 보이는 것을 확인하였다. 모델의 강인함에 있어서 형태 왜곡에 대해서는 YOLOv7 계열 모델이 YOLOv8 계열 모델에 비해 강인한 것을 확인하였으며, 색상 왜곡에 대해서는 YOLOv8 계열 모델이 상대적으로 강인한 것을 확인하였다. 따라서 실해역에서 수중 영상 촬영 시, 형태 왜곡은 발생 빈도가 낮으며 색상 왜곡은 연안에서 빈번하게 발생한다는 점을 고려했을 때, 연안해역에서 조식동물 탐지와 모니터링을 위해서는 YOLOv8 계열 모델을활용하는 것이 타당한 것으로 판단된다.",
기계학습  기반  회절파  분리  적용을  통한   GPR 탐사  자료의  도로  하부  공동  및  구조물  탐지  성능  향상,2023,"['Ground penetrating radar', 'Underground cavity', 'Machine learning', 'Object detection', 'Diffraction separation', '지표투과레이더', '도로 하부 공동', '기계학습', '객체탐지', '회절파 분리']","최근 도심지 도로에서 빈번하게 발생하는 도로 파임의 주원인인 지하 공동의 발생을 파악하기 위해, 차량 부착형 지표투과레이더(GPR) 를 통해 얻은 대량의 취득 자료를 효율적으로 처리하기 위한 기계학습 기반 공동 탐지 기술이 활발하게 연구되고 있다. 그러나 기계학습자료 생성 시 단순한 영상 처리 기법들만 활용되고 있고, 탄성파 탐사나 GPR 자료 처리에 시도되었던 여러 기법들은 충분히 활용되지 못하고 있다. 이 연구에서는 지하 공동의 탐지가 대부분 회절파의 탐지에 의해 이루어진다는 점에 착안하여 GPR 자료로부터 회절파를 분리하여 YOLO v5 모델을 이용한 도로 하부 공동 탐지 모델의 성능을 향상시켰다. 탄성파에서 개발된 기계학습 기반 회절파 분리 기법을GPR 자료에 맞게 변형한 후, GPR 현장 자료에서 회절파를 분리하여 공동 탐지 모델의 입력으로 사용하였다. 서울시 공공 개방 GPR 자료를 이용하여 제안된 방법의 성능을 검증한 결과, 회절파 분리를 이용했을 때 더 정확하게 공동 및 지하 구조물을 탐지하는 것을 확인하였다. 또한 제안된 회절파 분리 기법은 향후 GPR 탐사가 이용되는 다양한 분야에서 활용될 수 있을 것으로 기대된다.","Machine learning (ML)-based cavity detection using a large amount of survey data obtained from vehicle-mounted ground penetrating radar (GPR) has been actively studied to identify underground cavities. However, only simple image processing techniques have been used for preprocessing the ML input, and many conventional seismic and GPR data processing techniques, which have been used for decades, have not been fully exploited. In this study, based on the idea that a cavity can be identified using diffraction, we applied ML-based diffraction separation to GPR data to increase the accuracy of cavity detection using the YOLO v5 model. The original ML-based seismic diffraction separation technique was modified, and the separated diffraction image was used as the input to train the cavity detection model. The performance of the proposed method was verified using public GPR data released by the Seoul Metropolitan Government. Underground cavities and objects were more accurately detected using separated diffraction images. In the future, the proposed method can be useful in various fields in which GPR surveys are used."
초해상도 모델 구조 기반 항공 영상 내 다중 크기 객체 검출 신경망,2023,"['Ariel Image', 'Object Detection', 'Super Resolution Network', '항공 영상', '객체 탐지기', '초해상도 신경망']","다양한 비행 고도와 도심 환경에서 촬영된 항공 영상은 다양의 크기의 객체와 밀집된 다수의 소형 객체를 포함한다. 즉 항공 영상은 객체 크기의 다양성, 객체 간 중첩성, 객체와 배경 간 유사성, 배경 복잡성을 가진다. 따라서 YOLO (You Only Look Once) 계열 신경망과 같은 일반 객체 검출기는 항공 영상 특성 고려할 때, 관심 객체 미탐지율이 높다. 특히 복잡한 배경의 항공 영상 내 높은 객체 분포도를 해결하고자 제안된 얇은 특징 추출 신경망은 소형 객체 검출정확도는 높으나, 대형 객체 검출정확도 성능은 좋지 못하다. 따라서 본 논문에서는 초해상도 복원 신경망과 유사한 구조의 YOLOv5U 신경망과 공간 정보 왜곡을 최소화하는 Skip Connection을 제안하여, 모든 객체 크기의 탐지율 향상을 통해 전체 객체 검출정확도를 향상하였다. 또한 영역 분할 손실 함수를 객체 검출기 신경망 학습과 결합하여 비교 실험을 통해 성능을 평가하였다. 실험 결과, 제안하는 YOLOv5U 신경망은 소형 객체 검출기 YOLOv5-TA 신경망 대비 FPS (Frame Per Second) 성능과 대형 객체(Large, 96×96 화소 이상)의  (mean Average Precision) 성능이 40%, 143% 증가하였다. 또한 Visdrone-DET2021 Challenge에서 우수한  성능을 달성한 TPH-YOLOv5 신경망 대비  성능이 7.4% 향상하였다.","Aerial images captured at various flight altitudes and in urban environments contain objects of various sizes and large numbers of small objects in dense locations. In other words, objects and background in aerial images have a variety of object sizes, superposition between objects, similarity between objects and backgrounds, and background complexity. Object detectors such as YOLO (You Only Look Once)-based networks have a high misdetection ratio when considering aerial image characteristics. Especially the shallow backbone network proposed to solve the high object distribution in aerial images with a complex background has high detection accuracy at small objects, but poor detection accuracy at large object. In this paper, we propose a YOLOv5U network, which is similar to the super resolution network and skip connection that reduces spatial information distortion to improve the detection accuracy performance by improving the detection ratio of all object sizes. Additionally, we evaluate the network performance by conducting experiments that combine segmentation loss with object detection network learning. The results of the experiment show, the proposed YOLOv5U network achieves FPS (Frame Per Second) and  (mean Average Precision) in large object performance 40%, 143% higher than the YOLOv5-TA network. Futhermore, mAP performance improved by 7.4% over TPH-YOLOv5 networks that recorded outstanding performance in visdrone-DET2021 Challenge."
생활 폐기물 다중 객체 검출과 분류를 위한 i-YOLOX 구조에 관한 연구,2023,[],"생활 폐기물 쓰레기는 기후 변화, 자원 부족, 환경 오염을 불러오는 대표적인 문제로서, 이러한 문제를 해결하기 위해 지능적으로 쓰레기를 분류하는 방식을 연구하였고, 전통적인 분류 알고리즘부터 기계학습, 신경망에 이르기까지 많은 연구가 진행되고 있다. 그러나, 다양한 환경과 조건에서 쓰레기를 분류하기에는 여전히 데이터셋이 부족하고, 신경망 네트워크 구성 복잡도가 증가하며, 성능 측면에서도 실생활에 적용하기에 아직 미흡하다. 따라서 본 논문에서는 신속한 분류와 정확도 향상을 위해 i-YOLOX를 제안하고, 네트워크 매개변수, 검출속도, 정확도 등을 평가한다. 이를 위해 17개의 폐기물 범주를 포함하는 10,000개의 가정용 쓰레기 대상 샘플로 데이터 세트를 구성하고, YOLOX 구조에 Involution 채널 컨볼루션 연산자와 CBAM(Convolution Branch Attention Module)을 도입하여 i-YOLOX를 구성하고, 기존의 YOLO 구조와 성능을 비교한다. 실험 결과 복잡한 장면에서 쓰레기 객체 검출 속도와 정확도가 기존의 신경망에 비해 향상되어, 제안한 i-YOLOX 구조가 생활 폐기물 다중 객체 검출과 분류에 효과적임을 확인하였다.","In addressing the prominent issues of climate change, resource scarcity, and environmental pollution associated with household waste, extensive research has been conducted on intelligent waste classification methods. These efforts range from traditional classification algorithms to machine learning and neural networks. However, challenges persist in effectively classifying waste in diverse environments and conditions due to insufficient datasets, increased complexity in neural network architectures, and performance limitations for real-world applications. Therefore, this paper proposes i-YOLOX as a solution for rapid classification and improved accuracy. The proposed model is evaluated based on network parameters, detection speed, and accuracy. To achieve this, a dataset comprising 10,000 samples of household waste, spanning 17 waste categories, is created. The i-YOLOX architecture is constructed by introducing the Involution channel convolution operator and the Convolution Branch Attention Module (CBAM) into the YOLOX structure. A comparative analysis is conducted with the performance of the existing YOLO architecture. Experimental results demonstrate that i-YOLOX enhances the detection speed and accuracy of waste objects in complex scenes compared to conventional neural networks. This confirms the effectiveness of the proposed i-YOLOX architecture in the detection and classification of multiple household waste objects."
BIM 모델 활용을 위한 360° 카메라 이미지의 객체 탐지 알고리즘 정확성 비교 연구,2023,['$360^{\\circ}$'],,"Recently, with the widespread adoption of Building Information Modeling (BIM) technology in the construction industry, various object detection algorithms have been used to verify errors between 3D models and actual construction elements. Since the characteristics of objects vary depending on the type of construction facility, such as buildings, bridges, and tunnels, appropriate methods for object detection technology need to be employed. Additionally, for object detection, initial object images are required, and to obtain these, various methods, such as drones and smartphones, can be used for image acquisition. The study uses a 360° camera optimized for internal tunnel imaging to capture initial images of the tunnel structures of railway and road facilities. Various object detection methodologies including the YOLO, SSD, and R-CNN algorithms are applied to detect actual objects from the captured images. And the Faster R-CNN algorithm had a higher recognition rate and mAP value than the SSD and YOLO v5 algorithms, and the difference between the minimum and maximum values of the recognition rates was small, showing equal detection ability. Considering the increasing adoption of BIM in current railway and road construction projects, this research highlights the potential utilization of 360° cameras and object detection methodologies for tunnel facility sections, aiming to expand their application in maintenance."
딥러닝 기반의 국토모니터링 웹 서비스 개발,2023,"['Land monitoring', 'Deep learning', 'Object detection', 'Web service', 'Spatial information']",,"Land monitoring involves systematically understanding changes in land use, leveraging spatial information such as satellite imagery and aerial photographs. Recently, the integration of deep learning technologies, notably object detection and semantic segmentation, into land monitoring has spurred active research. This study developed a web service to facilitate such integrations, allowing users to analyze aerial and drone images using CNN models. The web service architecture comprises AI, WEB/WAS, and DB servers and employs three primary deep learning models: DeepLab V3, YOLO, and Rotated Mask R-CNN. Specifically, YOLO offers rapid detection capabilities, Rotated Mask R-CNN excels in detecting rotated objects, while DeepLab V3 provides pixel-wise image classification. The performance of these models fluctuates depending on the quantity and quality of the training data. Anticipated to be integrated into the LX Corporation's operational network and the Land-XI system, this service is expected to enhance the accuracy and efficiency of land monitoring."
Resource Efficient AI Service Framework Associated with a Real-Time Object Detector,2023,"['Adaptive AI Service', 'Multichannel Streaming', 'Object Detection', 'Real-Time', 'Resource Efficient']",,"This paper deals with a resource efficient artificial intelligence (AI) service architecture for multi-channel videostreams. As an AI service, we consider the object detection model, which is the most representative for videoapplications. Since most object detection models are basically designed for a single channel video stream, theutilization of the additional resource for multi-channel video stream processing is inevitable. Therefore, wepropose a resource efficient AI service framework, which can be associated with various AI service models.Our framework is designed based on the modular architecture, which consists of adaptive frame control (AFC)Manager, multiplexer (MUX), adaptive channel selector (ACS), and YOLO interface units. In order to run onlya single YOLO process without regard to the number of channels, we propose a novel approach efficientlydealing with multi-channel input streams. Through the experiment, it is shown that the framework is capableof performing object detection service with minimum resource utilization even in the circumstance of multichannel streams. In addition, each service can be guaranteed within a deadline."
ROS 기반 지능형 무인 배송 로봇 시스템의 구현,2023,"['Mobile Manipulator', 'ROS', 'Autonomous Navigation', 'SCARA manipulator', 'Web server']","본 논문에서는 Robot Operating System(ROS) 기반의 모바일 매니퓰레이터(Manipulator)를 이용한 무인 배송 로봇 시스템을구현하고 시스템 구현을 위해 사용된 기술에 대해 소개한다. 로봇은 엘리베이터를 이용해 건물 내부에서 자율주행이 가능한 모바일로봇과 진공 펌프를 부착한 Selective Compliance Assembly Robot Arm(SCARA)-Type의 매니퓰레이터로 구성된다. 로봇은 매니퓰레이터에 부착된 카메라를 이용하여 이미지 분할과 모서리 검출을 통해 배송물을 들어올리기 위한 위치와 자세를 결정할 수 있다. 제안된 시스템은 스마트폰 앱 및 ROS와 연동된 웹서버를 통해 배송 현황을 조회하고 로봇의 실시간 위치를 파악할 수 있도록사용자 인터페이스를 가지고 있으며, You Only Look Once(YOLO)와 Optical Character Recognition(OCR)을 통해 배송 스테이션에서 배송물과 주소지를 인식한다. 아울러 4층 건물 내부에서 진행한 배송 실험을 통해 시스템의 유효성을 검증하였다","In this paper, we implement an unmanned delivery robot system with Robot Operating System(ROS)-based mobilemanipulator, and introduce the technologies employed for the system implementation. The robot consists of a mobilerobot capable of autonomous navigation inside the building using an elevator and a Selective Compliance AssemblyRobot Arm(SCARA)-Type manipulator equipped with a vacuum pump. The robot can determines the position andorientation for picking up a package through image segmentation and corner detection using the camera on themanipulator. The proposed system has a user interface implemented to check the delivery status and determine thereal-time location of the robot through a web server linked to the application and ROS, and recognizes the shipmentand address at the delivery station through You Only Look Once(YOLO) and Optical Character Recognition(OCR). Theeffectiveness of the system is validated through delivery experiments conducted within a 4-story building."
말벌 검출의 정확성 향상을 위한 YOLOX의  개선된 구조 제안,2023,"['Deep Learning', 'YOLO', 'Real Time', 'Hornet Detection', 'Monitoring System']",,"In this paper, an advanced backbone structure for YOLOX is proposed to obtain better detection accuracy in small object detection such as hornet by replacing CSPLayer with ShuffleLayer. By this replacement, numbers of convolution operation are reduced in each layer of the backbone. This can conserve spatial information of small objects in each layer and through layers in backbone, reducing processing time. In order to evaluate the proposed method, four types of experiments were executed such as mAP comparison for our hornet dataset, another mAP comparison for the standard dataset VEDAI dedicated small objects, generalization test for RTMDet, and detection speed between the default YOLOX model and the proposed YOLOX model. As a result, the first mAP under 50% IoU condition for the hornet dataset showed 86.21% and 87.35% for the default and the proposed, respectively. The experiment, mAP test for the standard VEDAI, represented 47% and 41.7% for each model and also showed better accuracy by 5.3%. In the generalization test with RTMDet, the proposed model showed similar or higher accuracy according to IoU. In addition, in terms of speed the proposed ShuffleLayer- based backbone was faster than the default by 1.35 times due to reduced convolution parameters. Thus, experiments above verified that the proposed backbone structure for YOLOX can be effectively utilized to enhance accuracy and inference speed in real-time detection for small objects."
Mobile Phone-based Real-time Dangerous Object Recognition for the Visually Impaired,2023,"['Android', 'Object recognition', 'SSD', 'YOLO', 'Visually impaired', 'Real-time']",,"This paper proposes a dangerous object recognition Android application for the visually impaired using a smartphone. Among the one-stage and two-stage detectors, which are representative object recognition methods, the one-stage method is more suitable for real-time object recognition. Among them, more accurate object recognition is possible using the SSD network. In addition, the visually impaired cannot see the screen or the front properly in their daily life, so it informs them of dangerous situations in advance through sound. The system helps the visually impaired using a priority queue that notifies the visually impaired with a different sound according to a high-priority object. The experiment results of the proposed system are expected to bring positive results when applied to the smartphones of visually impaired people."
객체 탐지 기법 적용 YCbCr 컬러모델의 화염 영역 검출 특성에 관한 연구,2023,"['Flame segmentation', 'YCbCr', 'YOLO', 'Image processing', 'Performance evaluation']","화염 영역 검출을 위한 기존 YCbCr 컬러모델은 다양한 색상의 화염에 대한 낮은 검출 성능과 화염과 유사한 색상의 객체에 대한 오검출 특성을 갖는다. 따라서 본 연구에서는 YCbCr 컬러모델의 화염 영역 검출 성능을 개선하기 위하여 객체 탐지 기법 적용 개선된 YCbCr 컬러모델을 제안하였다. 화염과 유사한 색상을 갖는 객체 영역에 대한 검출을 방지하기 위해 객체 탐지 딥러닝 모델인 YOLOv8을 적용하여 화염 객체 영역을 탐지하고 해당 영역 내에서 화염을 검출하도록 하였다. 또한 화염 영역 검출 성능을 개선하기 위하여 적색 지배형 화염과 황색 지배형 화염을 구분하여 화염을 검출하는 YCbCr 규칙을 적용하였다. 화염 영역 검출 성능을 평가한 결과, 제안된 모델의 intersection over union (IoU) 값이 기존 YCbCr 모델 대비 약 15.4% 향상되었다. 또한 화재 및 비화재 예측성능의 경우 제안된 모델의 정밀도, 재현율, F1-score 값이 기존 YCbCr 모델 대비 각각 15.9%, 28.2%, 24.7%로 개선되었다.","The existing YCbCr color model for flame segmentation has a low segmentation performance for various colored flames and mis-segmentation for flame-like colored-object regions. An improved YCbCr color model using an object detection technique is proposed in this study to improve the flame segmentation performance of the existing YCbCr color model. YOLOv8, a deep learning model for object detection, was used to form a bounding box for the flame to prevent the segmentation of the flame-like colored-object region, and flame segmentation in the bounding box was performed. In addition, YCbCr rules were proposed to segment red and yellow flames to improve flame segmentation performance. The performance evaluation showed that the proposed model increased the intersection over union value by approximately 15.4% compared to that of the existing YCbCr model. In terms of the fire prediction performance evaluation, the precision, recall, and F1-score of the proposed model increased by approximately 15.9%, 28.2%, and 24.7%, respectively."
적대적 회피 공격에 대응하는 안전한 자율주행 자동차 시스템,2023,"['Self-Driving Car', 'YOLO', 'Adversarial Evasion Attack', 'Morphology']",,
FMICW 레이다에서 기계 학습을 활용한 다수 표적 탐지 기법 연구,2023,"['FMICW Radar', 'Detection', 'YOLO', 'Machine Learning', 'Maximum Likelihood Estimation']",,"This study proposes an effective method for detecting multiple targets in frequency-modulated interrupted continuous wave (FMICW) radar by using periodic signal characteristics and applying machine learning. FMICW radars are typically used for detecting a single target, but this method overcomes the challenges of range-Doppler coupling and spurious wave generation caused by the switching of transmit and receive signals, to detect multiple targets. The method first uses FMICW radar to generate an RD-Map by applying MLE (maximum likelihood estimation) , and then enhances the targets by identifying the intersection of lines generated by range-Doppler coupling. Thus, by applying a machine-learning-based object detection algorithm to the enhanced images, multiple target detection be- comes possible."
화재발생 시 AI소방드론과 인공지능 적용,2023,"['AI소방드론', '인공지능', '열화상 카메라', '연기센서', '화재분석', 'YOLO', 'Drone', 'Movement Search', 'Real-time Analysis', 'Type of Fire', 'Scene of a Fire', '119 Firefighting', 'R-CNN']","대한민국은 2020년 20,419건 화재사고와 인명피해 1,145명, 2021년 19,300건 화재사고와 1,221명의 인명피해가발생하였다. 화재 발생 시에 119 소방차가 화재현장에 진입할 때, 장애물로 교통이 지연되어 화재 피해가 늘어난다. 본 연구는 소방차가 화재현장에 도착하기 전에 AI소방드론이 화재현장 진입도로를 실시간 영상 이미지를 판독사용하도록 설계한다. AI소방드론의 영상은 소방서버에서 인공지능 YOLOv5를 사용하여 실시간 판독 결과를 분류하고, 장애물 차량소유주에게 push call 알람 문자로 전파하고, 장애물에 방송을 직접 전파한다. AI소방드론은화재현장을 촬영하여, 소방서버에서 인공지능 RCNN으로 분석하고, 화재규모와 화재유형을 판단하도록 설계한다.AI소방드론은 IoT 연기 센서를 통하여, 소방서버에서 연기 성분을 분석하여 119 소방차에게 화재유형별 대응을위한 정보를 전파한다. 인공지능과 AI소방드론은 화재진압시간을 단축 시킬 수 있어, 인명피해와 재산피해를 최소화 할 수 있다.","In 2020, 20,419 fire accidents and casualties occurred in Korea, and 19,300 fire accidents and 1,221 casualties occurred in 2021. When 119 fire trucks enter the fire site in the event of a fire, traffic is delayed due to obstacles, increasing fire damage. This study designs AI fire drones to read and use real-time image images of fire site access roads before the fire truck arrives at the fire site. The video of the AI fire drone classifies real-time reading results using artificial intelligence YOLOv5 on the fire server, spreads them as push call alarm text to the owner of the obstacle vehicle, and directly spreads the broadcast to the obstacle. The AI fire drone is designed to photograph the fire site, analyze it with an artificial intelligence RCNN in the fire server, and determine the size of the fire and the type of fire. AI fire drones analyze smoke components from fire servers through IoT smoke sensors and spread information for response by fire type to 119 fire trucks.Artificial intelligence and AI fire drones can shorten the fire extinguishing time, minimizing human life and property damage."
학습 데이터셋에 따른 딥러닝 모델의 말벌 검출 정확도 비교,2023,"['Deep learning', 'Training dataset', 'Vespa', 'YOLO']",,"Training data configuration is critical for object detection based on supervised deep learning.Namely, the characteristics of training data should be very similar to an actual test environment to raise expected inference accuracy. However, a Vespa object size in pixels in a natural capture environment is not constant and is smaller than the Vespa object size of images in a training set. This study compares the inference accuracy of deep learning models YOLOv5, YOLOX, and YOLOv7 according to training datasets. As training data, the three types of datasets were prepared as follows. First, A basic dataset, composed of five species of Vespa and one bee, is produced for the Vespa training data set. Next, The 0.3% dataset, in which Hornet object size is approximately 0.3% ratio to the whole image size in pixels, is prepared using the basic dataset for tiny object detection. Finally, images are selected from the basic and the 0.3% datasets in the same proportions in a Mixed dataset. After configuring three types of training datasets, the three deep learning models above were trained using the three training datasets, the basic, the 0.3%, and the Mixed dataset, and calculated the training and test mAP. In cases where the training and test data environments are similar, YOLOv7 demonstrated the highest mAP at 95.4%. However, in a test result experiment for actual environments using trained weights by the basic dataset, the mAP@50 scores are 30%, 14%, and 85% for YOLOv5, YOLOv7, and YOLOX, respectively. That is, YOLOX, an Anchor-free model, is overwhelmingly excellent. The organization of the training dataset is essential to match the inputs of the actual detection environment to obtain the best accuracy in object detection, and YOLOv7 is the best model for a tailored training dataset among state of the art models."
딥러닝 기반의 열화상 카메라를 이용한 화점 추적 팬-틸트 시스템 구현,2023,"['딥러닝', '욜로', '열화상 카메라', '팬-틸트', '자율 추적', '소화', 'Deep learning', 'YOLO', 'Thermal camera', 'Pan-tilt', 'Autonomous tracking', 'Firefighting']",,"There have been frequent fatal accidents of firefighters at fire scenes. A firefighting robot can be an alternative to humans at a fire scene to reduce accidents. As a critical function of the firefighting robot, it is mandatory to autonomously detect a fire spot and shoot water. In this research, a deep learning model called YOLOv7 was employed based on thermal images to recognize the shape and temperature information of the fire. Based on the results of the test images, which were not used for learning purposes, a recognition rate of 99% was obtained. To track the recognized fire spot, a 2-DOF pan-tilt actuation system with cameras was developed. By using the developed system, a moving target can be tracked with an error of 5%, and a variable target tracking test by alternately covering two target braziers showed that it takes about 1.5 seconds to track changing targets. Through extinguishment experiments with a water spray mounted on the pan-tilt system, it was observed that the temperature of the brazier dropped from 600 degrees to 13 degrees. Based on the obtained data, the feasibility of a robotic firefighting system using image recognition was confirmed."
딥러닝 기반의 객체 탐지 모델을 활용한  어종 및 어병 탐지 시스템,2023,"['Computer Vision', 'Object Detection', 'Deep Learning', 'Faster R-CNN', 'YOLO']",,"In fish farms, the overuse of feed can lead to residue and fish excrement polluting the water quality environment, thereby increasing the probability of pathogen proliferation and disease incidence in fish. In order to minimize the occurrence of diseases, it is crucial to administer an appropriate amount of feed and manage breeding diligently while mitigating any stress factors affecting the fish. This study involves the development of a fish species and disease detection system, where models are trained to identify different types of fish and their diseases. The system is designed to be used by fish farmers, offering a user-friendly interface through the Web. In the model training, the YOLOv7 model demonstrated high performance, achieving over 0.9 accuracy in detecting fish species. Meanwhile, for fish disease detection, the YOLOv5l model exhibited overall superior performance. However, there was a limitation in the dataset for fish disease detection, with only a small number of samples available. To overcome this, the fish species and disease detection system, developed in conjunction with the YOLOv5l model, was incorporated into the web page. This system aims to help identify the species, disease status, and specific affected regions in the fish population."
Development of a Deep Learning Model for Pothole Detection on Roads to Prevent Traffic Accidents,2023,"['교통사고', '물체 검출', '포트홀', '욜로', '딥러닝', 'Deep Learning', 'Object detection', 'Pothole', 'YOLO', 'Traffic Accident']",,
Hot Spot Detection of Thermal Infrared Image of Photovoltaic Power Station Based on Multi-Task Fusion,2023,"['DeepLab v3+', 'Geometric Location', 'Hot Spot Location', 'Hot Spot Recognition', 'YOLO v3']",,"The manual inspection of photovoltaic (PV) panels to meet the requirements of inspection work for large-scalePV power plants is challenging. We present a hot spot detection and positioning method to detect hot spots inbatches and locate their latitudes and longitudes. First, a network based on the YOLOv3 architecture wasutilized to identify hot spots. The innovation is to modify the RU_1 unit in the YOLOv3 model for hot spotdetection in the far field of view and add a neural network residual unit for fusion. In addition, because of themisidentification problem in the infrared images of the solar PV panels, the DeepLab v3+ model was adoptedto segment the PV panels to filter out the misidentification caused by bright spots on the ground. Finally, thelatitude and longitude of the hot spot are calculated according to the geometric positioning method utilizingknown information such as the drone's yaw angle, shooting height, and lens field-of-view. The experimentalresults indicate that the hot spot recognition rate accuracy is above 98%. When keeping the drone 25 m off theground, the hot spot positioning error is at the decimeter level."
딥러닝 기반의 실시간 상품 진열 상황 추정 시스템,2023,"['딥러닝', '상품 전시', 'Deep Learning', 'Plan-o-gram', 'Product Display', 'YOLO']",,"In this paper, we developed a store management system that detects the display status of products in real time and manages them to comply with the plan-o-gram using real-time product recognition and display status estimation technology based on deep learning. To achieve this, we input store shelf images, localize each product using the YOLOv8 deep learning model trained with the SKU110K data set, and generate an image feature vector using an em-bedder that fine-tunes the ResNet-50 model, combining the pre-registered reference image feature vector and Compare and identify and classify products. The plan-o-gram compliance control algorithm has been supplemented so that the plan-o-gram compliance status generated through sequence alignment of the modified Needleman-Wunsch(NW) algorithm can be utilized in actual store situations. Previously, there were many errors by judging the four states: exact match(MT), missing item(MI), added item in the correct position(ME), and added or misplaced item or empty space(NM). Accordingly, in this paper, we subdivide NM into 5 states (addition, deletion, location change, remote placement, and position shift), expand it to a total of 8 states, and present an algorithm that can handle various characteristic cases."
사용자 추종을 위한 AI기반의 이동로봇 시스템 구현,2023,"['이동로봇', '사용자 추종', '욜로', '딥러닝', '탐지', 'Mobile Robot', 'User Following', 'YOLO', 'Deep Learning', 'Detection']",,
열화상 카메라를 이용한 전통시장 화재 감지에서 YOLOv8 객체 탐지 모델의 성능 비교 분석,2023,"['Fire Detection', 'Thermal Image', 'Traditional Market', 'Object Detection', 'YOLO']",,"Traditional markets, formed naturally, often feature aged buildings and facilities that are susceptible to fire. However, the lack of adequate fire detection systems in these markets can easily lead to large-scale fires upon ignition. Therefore, this study was conducted with the aim of detecting fires in traditional markets, utilizing thermal imaging cameras for data collection and the YOLOv8 model for object detection experiments. Data were collected in the night markets within traditional markets of xx city and by simulating fire scenarios. A comparative analysis of the Nano and XL models of YOLOv8 revealed that the XL model is more effective in detecting fires. The XL model not only demonstrated higher accuracy in correctly identifying flames but also tended to miss fewer fires compared to the Nano model. In the case of objects other than flames, the XL model showed superior performance over the Nano model. Taking all these factors into account, it is anticipated that with further data collection and improvement in model performance, a suitable fire detection system for traditional markets can be developed."
3D 렌더링 및 딥러닝을 활용한 기뢰매몰률 측정,2023,"['Mine', 'Burial Rate', 'AUV', '3D Rendering', 'Deep Learning', 'Object Detection', 'YOLO', 'Accuracy']",,"In this study, we developed a method to measure mine burial rates using 3D rendering and deep learning. Mines pose a significant threat to the navy and are difficult to detect when buried in the seabed. Since the in-situ measurement of mine burial rates is subject to various constraints and costs, an efficient alternative method is needed. For this purpose, we trained a YOLOv8s deep learning model using 1,246 3D rendering images of an MDM-1 mine and achieved a high accuracy with an mAP@0.5 score of 0.995. Additionally, we validated it using 20 test videos and achieved an average accuracy of 72.75%. This study shows the possibility of measuring mine burial rates using 3D rendering and deep learning, even with limited data. The study is meaningful as basic research that could be used for mine detection combined with an AUV."
IoT 기반 재활용품 분리수거 및 전자상거래 활용 시스템,2023,"['한-아세안', '스마트시티', '솔루션', '민관 네트워크', '스마트시티 수출 거점 HUB 플랫폼', 'Internet of things', 'YOLO object recognition', 'separate collection of recyclables', 'e-commerce']",,"Recently, ASEAN is not only a new production base but also a consumer market for Korea, and interest in the utilization of production networks in each region is increasing. In particular, urbanization in ASEAN countries is progressing at a relatively fast pace. Each country is promoting smart city projects combined with ICT to improve outdated basic infrastructure facilities such as housing, transportation, logistics, crime prevention, and disaster prevention. The purpose of this study is to develop a web-based smart city export HUB platform so that companies with excellent domestic smart city solutions can participate in smart city construction through networks with ASEAN countries. These platforms can secure the demand for smart city construction in ASEAN countries, and through the establishment of the Korea-ASEAN public-private network, smart cities planned in ASEAN countries can be promoted more innovative. In addition, it is expected to be positioned as a Global smart city platform model by applying to real cities through collaboration with excellent domestic companies."
제조업 노동자 근골격계 부담요인 데이터셋 클래스 분류와 유효성 검증,2023,"['딥러닝', '작업자세 분류', '근골격계 질환', '포즈추론', '인간공학기반', 'Deep Learning', 'Perception', 'AI training data', 'Object Detection', 'Autonomous Driving']","제조업의 안전보건 기준은 다양한 항목이 존재하지만, 질병 재해자 기준에서 업무상 질병과 근골격계 질환으로 나눌 수 있다. 이 중 근골격계 질환은 제조업에서 가장 많이 발생하며, 나아가서 제조 현장의 노동생산성 감소 및 경쟁력 약화까지 유발할 수 있어서 이를 사전에 확인할 수 있는 시스템이 필요한 실정이다. 본논문에서는 제조업 노동자의 근골격계 유해 요인을 검출하기 위하여 근골격계 부담작업 요인 분석 데이터 속성, 유해 요인 작업자세, 관절 키포인트를 정의하고 인공지능 학습용 데이터를 구축하였다. 구축한 데이터의 유효성을 판단하기 위해서 YOLO, Dite-HRNet, EfficientNet 등의 AI 알고리즘을 활용하여 학습하고 검증하였다. 실험 결과 사람 탐지 정확도는 99%, 탐지된 사람의 관절 위치 추론 정확도는 @AP0.5 88%, 추론된 관절 위치를 종합하여 자세를 평가한 정확도는 LEGS 72.2%, NECT 85.7%, TRUNK 81.9%, UPPERARM 79.8%, LOWERARM 92.7%를 도출하였으며, 추가로 딥러닝 기반의 근골격계 질병을 예방할수 있는 연구에 필요한 요소를 고찰하였다.",
짐벌 카메라 각도 제어와 객체 인식을 사용한 UAV 자동착륙 시스템,2023,"['무인 이동체', '자동 착륙', 'GPS', '객체 인식', '딥러닝', 'UAV (Unmmand Aerial Vehicle)', 'Auto landing', 'GPS (Global Positioning System)', 'Object Detection', 'Deep Learning']","본 논문은 짐벌 카메라의 각도 제어 및 딥러닝 기반 객체 인식을 활용한 UAV 자동 착륙 시스템을 제안한다.UAV에 장착된 카메라를 사용하여 딥러닝 기반 객체 인식을 통해 목적지 착륙 패드를 둘러싸는 표시 영역(Bounding box)을 기준으로 운용 중인 UAV의 위치를 제어하도록 한다. 제안된 방식에서는 별도의 카메라가 필요없이 기존의 UAV 임무 장비 중의 하나인 짐벌 카메라를 사용해 카메라 각도를 하단을 바라보게끔 제어하고, UAV에 장착된 컴패니언 컴퓨터를 사용해 UAV을 제어한다. 제안된 방식에서 딥러닝 기반 객체인식은 Yolo v4 tiny를 사용했고, 드론제어를 위해 ROS를 사용하여 구현되었고, 성능 평가를 위해 착륙 지점과 착륙 패드 간의거리를 측정하였고 모의실험과 실제 실험을 통해 효율성을 입증하였다.",
AWS 기반 행위와 객체 인식을 통한 위협 상황 판단 시스템,2023,"['위협 상황 판단', 'AWS-based', '객체 인식', '행위 인식', 'Danger Situation Determination', 'AWS-based', 'Object Recognition', 'Behavior Recognition']",,"As crimes frequently occur on the street, the spread of CCTV is increasing. However, due to the shortcomings of passively operatedCCTV, the need for intelligent CCTV is attracting attention. Due to the heavy system of such intelligent CCTV, high-performance devicesare required, which has a problem in that it is expensive to replace the general CCTV. To solve this problem, an intelligent CCTV systemthat recognizes low-quality images and operates even on devices with low performance is required. Therefore, this paper proposes aSaying CCTV system that can detect threats in real time by using the AWS cloud platform to lighten the system and convert images intotext. Based on the data extracted using YOLO v4 and OpenPose, it is implemented to determine the risk object, threat behavior, andthreat situation, and calculate the risk using machine learning. Through this, the system can be operated anytime and anywhere as longas the network is connected, and the system can be used even with devices with minimal performance for video shooting and imageupload. Furthermore, it is possible to quickly prevent crime by automating meaningful statistics on crime by analyzing the video andusing the data stored as text."
산업용 로봇 작업장 안전시스템 개발에 대한 연구,2023,"['Artificial intelligence', 'Industrial robot', 'Safety camera']",,"As the importance of artificial intelligence grows rapidly and emerges as a leader in technology, it is becoming an important variable in the next-generation industrial system along with the robot industry.In this study, a safety system was developed using deep learning technology to provide worker safety in a robot workplace environment.The implemented safety system has multiple cameras installed with various viewing directions to avoid blind spots caused by interference.Workers in various scenario situations were detected, and appropriate robot response scenarios were implemented according to the worker's risk level through IO communication.For human detection, the YOLO algorithm, which is widely used in object detection, was used, and a separate robot class was added and learned to compensate for the problem of misrecognizing the robot as a human.The performance of the implemented system was evaluated by operator detection performance by applying various operator scenarios, and it was confirmed that the safety system operated stably."
Estimation of the Movable Position of the Robot based on the Object Recognition and GVG Update,2023,"['Optimal Positioning', 'Object Recognition', 'Generalized Voronoi Graph', 'Location-based Service', 'Mobile Robot']",,"Recently, some research has been attended to estimate the moving destination automatically from a recognized object in order to run a users errands in an indoor environment. In this paper, we propose a process for estimating optimal position for manipulating the object through real-time object recognition and the generalized Voronoi graph (GVG) update on the map. First, an initial node is created through the GVG based on a pre-written grid map. When and when the robot moves to the target node, the identity and size of the object are estimated by the robot through the RGB-D sensor and object recognition (YOLO v4). At the same time, it receives obstacle data around objects from the LiDAR sensor and calculates the workspace that the robot can serve on the map using the hybrid approach of the AT and the COG method. Then, according to the geometric distance relationship with the existing node to estimate the optimal position, the GVG is updated as a final node creation or movement procedure. While the robot located in the actual multiple spaces moves to the node, it is confirmed that it can move to the optimal position in the workspace."
딥러닝을 활용한 딸기 생육지표 인식,2023,"['Deep Learning', 'Monitoring System', 'Object Detection', 'Strawberry Detection']",,"As the risks of securing stable food resources increase due to climate change and a decrease in the agricultural workforce, agricultural technologies are being developed to address this issue. In particular, many strawberries are grown in South Korea and require accurate and fast monitoring technology for stable profits. The reason is that many agricultural tasks are required depending on the cultivation period. This study attempted to find a suitable model for detecting the strawberry growth index during the reproductive growth period using an RGB image and deep learning. Among algorithms used for training, the YOLO v5-Large algorithm showed an mAP50 of 0.66 and FPS of 89.29 in the object detection results for a total of six classes (flowers, fruits, etc.). In addition, the Mask R-CNN algorithm's performance was similar with an mAP50 of 0.59, but the FPS was decreased to 26.04. The model that showed high performance to detect the growth index can be used in monitoring technology that supports decision making for appropriate resources and manpower input during growth. Future studies will improve the performance of detection."
Automatic identification and analysis of multi-object cattle rumination based on computer vision,2023,"['Cattle', 'Rumination', 'YOLOv4', 'KCF', 'Frame difference']",,"Rumination in cattle is closely related to their health, which makes the automatic monitoring of rumination an important part of smart pasture operations. However, manual monitoring of cattle rumination is laborious and wearable sensors are often harmful to animals. Thus, we propose a computer vision-based method to automatically identify multi-object cattle rumination, and to calculate the rumination time and number of chews for each cow. The heads of the cattle in the video were initially tracked with a multi-object tracking algorithm, which combined the You Only Look Once (YOLO) algorithm with the kernelized correlation filter (KCF). Images of the head of each cow were saved at a fixed size, and numbered. Then, a rumination recognition algorithm was constructed with parameters obtained using the frame difference method, and rumination time and number of chews were calculated. The rumination recognition algorithm was used to analyze the head image of each cow to automatically detect multi-object cattle rumination. To verify the feasibility of this method, the algorithm was tested on multi-object cattle rumination videos, and the results were compared with the results produced by human observation. The experimental results showed that the average error in rumination time was 5.902% and the average error in the number of chews was 8.126%. The rumination identification and calculation of rumination information only need to be performed by computers automatically with no manual intervention. It could provide a new contactless rumination identification method for multi-cattle, which provided technical support for smart pasture."
딥러닝 모델을 활용한 포트홀 검출 및 성능 개선을 위한 전처리 방법론 연구,2023,"['Deep learning', 'Object detection', 'Pothole detection', 'Pothole', 'Computer vision', 'EfficientDet', 'CLAHE', 'Sobel edge detection', 'Image preprocessing', 'FPN', 'BiFPN', 'YOLOv5']",,"In recent years, the number of potholes has been increasing due to the high frequency of heavy rainfall. In addition, road surface damage is inevitable due to the aging of roads, and damaged roads (potholes and cracks) interfere with drivers' driving, causing various safety accidents. To efficiently solve this problem, various road damage detection studies have been conducted using artificial neural networks. However, previous studies have been limited by a lack of understanding of potholes. Furthermore, the need for research is growing as the number of risk factors that can cause potholes is rapidly increasing. To overcome the limitations of previous studies, this study proposes an image preprocessing technique that can effectively reflect the characteristics of potholes and an optimal structure for pothole detection based on EfficientDet. The proposed preprocessing technique combines two algorithms, CLAHE and Sobel Edge detection, to identify and learn potholes in road surface images by maximizing the boundaries of potholes through contour detection and contrast thresholding for the entire image, rather than solely relying on contrast. In addition, we designed the optimal number of BiFPN layers for the pothole dataset so that the module can clearly detect potholes. The methodology proposed in this study was applied to EfficientDet and YOLO v5 models to experimentally prove the feasibility of the methodology."
Road Boundary Detection Using Multi-channel LiDAR Based on Disassemble-reassemble-merge Algorithm for Autonomous Driving,2023,"['DRM', 'multi-channel LiDAR', 'risk map', 'road boundary', 'road segmentation.']",,"To ensure the safe operation of self-driving cars, it is necessary to identify the location and layout of the road around the vehicle. Moreover, because road accidents pose a considerable risk to human life, accurate environmental awareness is paramount in autonomous driving, especially under unfavorable ambient conditions. Various sensors have been employed to realize road area recognition under such conditions. Among these sensors, multi-channel LiDAR has recently attracted attention as it is robust against illumination changes and can obtain accurate distance information. However, this system requires a large amount of data, rendering real-time processing difficult. To overcome this limitation, feature extraction methods have been used that can extract meaningful implicit information from a large amount of data. However, the application of feature extraction to small areas of the road for real-time processing can result in reduced accuracy. To enhance the level of accuracy, an algorithm was adopted in this study that can apply feature extraction to large areas of the road. This algorithm disassembles the LiDAR data for prompt processing at a low level and then reassembles the data to manage the exceptional parts in each scan line. Subsequently, the algorithm merges the road area parts in each scan line and distinguishes the road areas, sidewalks, and obstacles in real-time. To realize these three computational processes, the algorithm is termed a disassemblereassemble-merge (DRM) algorithm. The DRM algorithm is unique as it only uses the LiDAR sensor, which differs from existing algorithms that employ LiDAR sensors for road boundary detection. To demonstrate the effectiveness of the proposed method, we conducted an experiment using the KITTI Road Benchmark authorized dataset. Using the proposed method, accuracy was 10% higher compared to other algorithms. To validate the developed algorithm and its utility, we applied it to the Complex Yolo and obstacle-dependent Gaussian (ODG) algorithm. The ODG risk maps, which can eventually be extended to the control part of subsequent studies, were derived by applying the ODG algorithm to the outcomes and could be applied as a guideline map for actual vehicle driving."
