title,date,keywords,abstract,multilingual_abstract
영상신호를 입력으로 하는 3D ResNet기반 유아 행동 인식 기법,2023,"['유아 행동 인식', '딥러닝', 'ResNet', '영상신호', 'Children behavior recognition', 'deep learning', 'ResNet', 'video input']","본 연구에서는 다수의 유아가 등장하는 영상 내의 행동을 인식하기 위하여 딥러닝 기반의 유아 행동 인식 기술을 개발하였다. 유아들의 경우 동일한 행동이라도 표현과 방법이 다양하여 다양한 종류의 입력에 강건하게 분석될 수 있는 딥러닝 모델에 대한 개발이 필요하다. 본 연구에서는 입력 신호를 딥러닝의 입력에 맞도록 처리하고 3D ResNet을 사용하여 행동 인식 알고리즘을 제안하였다. 50명의 유아를 대상으로 13개 행동을 수행하는 영상 자료를 수집하였으며, 실험결과 13개의 행동 인식에 평균 72.21% 정확도를 보였다. 행동 중 서 있기 90.74%, 밀고 당기기 88.89%, 앉기 90.74%의 행동 인식률을 보였다. 향후 본 연구 결과물을 통해 일상생활에서 유아들의 행동 패턴을 자동으로 분석하고 서비스하는 연구에 활용될 수 있다.",
흉부 X선 영상을 이용한 작은 층수 ResNet 기반 폐렴 진단 모델의 성능 평가,2023,"['딥러닝', '흉부 X선 영상', '폐렴 진단', '학습 가능 파라미터', 'Residual 블록', 'Deep learning', 'Chest X-ray image', 'Pneumonia detection', 'Trainable parameter', 'Residual block']",,
SwinResNet: Swin Transformer와 ResNet 융합을 통한 Volumetric 의료 영상 분할,2023,"['Convolutional neural network', 'Medical image segmentation', 'ResNet', 'Swin Trans- former']",,"Volumetric medical image segmentation is critical in diagnosing diseases and planning subse- quent treatment. The convolutional neural network (CNN)-based U-Net was proposed for con- ducting accurate and robust medical image segmentation since the skip connection of U-Net and deep feature representation significantly improved its performance. However, since CNN-based models mainly focus on local and low-level features, they cannot extract global and high-level features effectively. Meanwhile, the Vision Transformer developed in natural language process- ing is proposed to improve image classification performance by splitting an input image into patches and conducting linear embeddings of the patches, which can extract global features. However, the Vision Transformer has difficulty in handling detailed and low-level features. This study proposes SwinResNet which can effectively conduct volumetric medical image segmenta- tion by fusing the Swin Transformer and CNN models. The combination can take advantage of both models and complement each other. Swin Transformer and ResNet are used as encoders, and the receptive field blocks and aggregation modules are applied to the multi-level features extracted from both encoders. Comprehensive evaluation shows that the proposed approach out- performs well-known previous studies."
밀 종자 품종 및 물성 분류를 위한 ResNet50 모델 기반의 이미지 분석,2023,"['Classification', 'Image Processing', 'ResNet50', 'Variety', 'Wheat']","밀은 대표적인 식량 작물 중 하나이지만 최근 국내 밀 자급률은 1%에 불과하다. 밀의 자급량을 높이기 위해서는 밀 종자의 품종순도를 높여 고품질의 가공물을 얻을 수 있도록 품질 관리를 해야 한다. 본 연구에서는 밀의 품질을 자동으로 판정하는 기술을 마련하기 위하여 딥러닝 알고리즘을 활용하여 밀의 품종과 경질, 연질 여부를 분류하는 모델을 개발하고자 하였다. 우리나라 주요 보급 품종인 금강, 백강, 새금강, 조경, 황금알에 대하여 개발한 이미지 획득 시스템을 이용하여 총 21,256개의 밀 종자 낱알 이미지를 획득하였다. 획득한 이미지에서 낱알의 장축, 단축 길이와 RGB 각각의 평균 색상 값을 계산해 품종, 경도별로 비교하였다. 또한, ResNet50 모델을 이용하여 밀 종자 5품종과 경질, 연질을 분류하는 모델을 개발하였다. 그 결과, 학습, 검증, 테스트 그룹의 분류 정확도는 각각 98.17%, 96.68%, 96.40%를 나타냈다. 테스트 그룹의 혼동행렬을 확인한 결과, 대부분 성공적으로 분류가 이루어졌고 동일 품종에 대해서는 경질, 연질이 100% 정확도로 분류되는 것을 확인하였다. 이를 통해 딥러닝 알고리즘을 이용하여 밀 종자 품종 및 경질, 연질 여부를 판별할 수 있을 것으로 판단된다.","Wheat is one of the major food crops, but the domestic self-sufficiency rate is only 1%. To increase self-sufficiency, it is essential to manage the quality of wheat seeds by classifying the seed quality grades. This study used deep learning algorithms to classify wheat varieties and distinguish hard and soft wheat. Five wheat varieties used in the South were employed, and 21,256 images of individual wheat seeds were acquired using an image acquisition system. The length of the axes and the average values in the RGB channels were then calculated. Furthermore, the ResNet50 architecture was used to classify the five wheat varieties and hardness. The results revealed high classification performances for the training, validation, and test groups, with rates of 98.17%, 96.68%, and 96.40%, respectively. The confusion matrix of the test group indicated successful classification, and hardness was classified with 100% accuracy for the same varieties. Deep learning algorithms enable the determination of wheat seed varieties and hardness."
ResNet/SVM 기반 GNSS 재밍 식별 기법,2023,"['GNSS', 'Jamming', 'Classification', 'Transfer Learning', 'ResNet', 'SVM']",,
3D Object Generation and Renderer System based on VAE ResNet-GAN,2023,"['variational autoencoder', 'generative adversarial network', 'residual learning', 'generation', 'reconstruction', 'voxel.']",,"We present a method for generating 3D structures and rendering objects by combining VAE (Variational Autoencoder) and GAN (Generative Adversarial Network). This approach focuses on generating and rendering 3D models with improved quality using residual learning as the learning method for the encoder. We deep stack the encoder layers to accurately reflect the features of the image and apply residual blocks to solve the problems of deep layers to improve the encoder performance. This solves the problems of gradient vanishing and exploding, which are problems when constructing a deep neural network, and creates a 3D model of improved quality. To accurately extract image features, we construct deep layers of the encoder model and apply the residual function to learning to model with more detailed information. The generated model has more detailed voxels for more accurate representation, is rendered by adding materials and lighting, and is finally converted into a mesh model. 3D models have excellent visual quality and accuracy, making them useful in various fields such as virtual reality, game development, and metaverse."
Improving the Cyber Security over Banking Sector by Detecting the Malicious Attacks Using the Wrapper Stepwise Resnet Classifier,2023,"['Cyber security', 'Malicious attacks', 'Cyber-physical systems', 'banking sector', 'Hierarchical network feature extraction', 'Wrapper stepwise ResNet']",,"With the advancement of information technology, criminals employ multiple cyberspaces to promote cybercrime. To combat cybercrime and cyber dangers, banks and financial institutions use artificial intelligence (AI). AI technologies assist the banking sector to develop and grow in many ways. Transparency and explanation of AI's ability are required to preserve trust. Deep learning protects client behavior and interest data. Deep learning techniques may anticipate cyber-attack behavior, allowing for secure banking transactions. This proposed approach is based on a user-centric design that safeguards people's private data over banking. Here, initially, the attack data can be generated over banking transactions. Routing is done for the configuration of the nodes. Then, the obtained data can be preprocessed for removing the errors. Followed by hierarchical network feature extraction can be used to identify the abnormal features related to the attack. Finally, the user data can be protected and the malicious attack in the transmission route can be identified by using the Wrapper stepwise ResNet classifier. The proposed work outperforms other techniques in terms of attack detection and accuracy, and the findings are depicted in the graphical format by employing the Python tool."
Reversible Multipurpose Watermarking Algorithm Using ResNet and Perceptual Hashing,2023,"['Deep Residual Network', 'Multipurpose Watermarking', 'Perceptual Hashing', 'Reversible Visible Watermarking']",,"To effectively track the illegal use of digital images and maintain the security of digital image communicationon the Internet, this paper proposes a reversible multipurpose image watermarking algorithm based on a deepresidual network (ResNet) and perceptual hashing (also called MWR). The algorithm first combines perceptualimage hashing to generate a digital fingerprint that depends on the user’s identity information and imagecharacteristics. Then it embeds the removable visible watermark and digital fingerprint in two different regionsof the orthogonal separation of the image. The embedding strength of the digital fingerprint is computed usingResNet. Because of the embedding of the removable visible watermark, the conflict between the copyrightnotice and the user’s browsing is balanced. Moreover, image authentication and traitor tracking are realizedthrough digital fingerprint insertion. The experiments show that the scheme has good visual transparency andwatermark visibility. The use of chaotic mapping in the visible watermark insertion process enhances thesecurity of the multipurpose watermark scheme, and unauthorized users without correct keys cannot effectivelyremove the visible watermark."
다양한 CNN 모델을 이용한 얼굴 영상의 나이 인식 연구,2023,"['Facial age estimation', 'CNN', 'AlexNet', 'VGG', 'ResNet']","얼굴 영상으로부터 나이를 인식하는 기술의 응용분야가 증가함에 따라 이에 대한 연구가활발히 진행되고 있다. 얼굴 영상으로부터 나이를 인식하기 위해서는 나이를 표현하는 특징을추출하고, 추출된 특징으로 나이를 정확하게 분류하는 기술이 필요하다. 최근 영상 인식분야에서 다양한 CNN 기반 딥러닝 모델이 적용되어 성능이 크게 개선되고 있으며, 얼굴 나이인식 분야에서도 성능 개선을 위해 다양한 CNN 기반 딥러닝 모델이 적용되고 있다. 본논문에서는 다양한 CNN 기반 딥러닝 모델의 얼굴 나이 인식 성능을 비교하는 연구를 수행하였다.영상 인식 분야에서 많이 활용되고 있는 AlexNet, VGG-16, VGG-19, ResNet-18, ResNet-34, ResNet-50, ResNet-101, ResNet-152를 활용하여 얼굴 나이 인식을 위한 모델을 구성하고 성능을비교하였다. 실험 결과에서 ResNet-34를 이용한 얼굴 나이 인식 모델의 성능이 가장 우수하다는것을 확인하였다.","There is a growing interest in facial age estimation because many applications require age estimation techniques from facial images. In order to estimate the exact age of a face, a technique for extracting aging features from a face image and classifying the age according to the extracted features is required.Recently, the performance of various CNN-based deep learning models has been greatly improved in the image recognition field, and various CNN-based deep learning models are being used to improve performance in the field of facial age estimation. In this paper, age estimation performance was compared by learning facial features based on various CNN-based models such as AlexNet, VGG-16, VGG-19, ResNet-18, ResNet-34, ResNet-50, ResNet-101, ResNet-152. As a result of experiment, it was confirmed that the performance of the facial age estimation models using ResNet-34 was the best."
위내시경 영상에서의 위 병변 자동 검출 모델 개발을 위한 RetinaNet 기반 backbone 네트워크에 따른 학습 성능 비교,2023,"['Gastroscopy image', 'gastric lesion', 'detection', 'deep learning', 'RetinaNet', '위내시경 영상', '위 병변', '검출', '딥러닝', '레티나넷']","본 연구에서는 위내시경 검사 시에 보조 시스템으로 활용할 수 있도록 RetinaNet 네트워크를 사용하여 위내시경 영상에서의 위 병변의 위치를 자동으로 검출하는 모델을 개발하였다. 위암은 한국이나 일본 등의 아시아권에서 대부분 발생한다. 그러나 위내시경 검사는 동시에 진단이나 치료할 수 있으며, 조기 발견 시 치료 성공확률이 매우 높다. 그러나 실시간으로 진행되는 검사 특성상 숙련도나 경험이 결과에 영향을 주며, 업무의 피로도 상승과 집중력 하락으로 인해 검사의 정확도가 낮아지게 된다. RetinaNet 기반의 backbone 네트워크로 ResNet50, ResNet152, EfficientNetB0, EfficientNetB4 네트워크를 사용하여 학습한 모델의 검출 성능을 확인하고, 각 모델 간의 성능을 비교하였다. RetinaNet 기반 backbone 네트워크별 모델들의 평균 민감도(FP/images)는 ResNet50 73.72%(0.0489), ResNet152 78.26%(0.0458), EfficinetNetB0 79.67%(0.3268), EfficientNetB4 62.66%(0.0448)를 보였다. EfficientNetB0 네트워크는 가장 높은 민감도를 나타냈으나 FP/images가 매우 높게 나타나 두 성능치를 모두 만족하는 네트워크는 ResNet152였다.","Gastric cancer occurs mostly in Asian countries such as Korea and Japan. Gastroscopy allows diagnosis and treatment of gastric cancer at the same time, and the probability of successful treatment is very high at early detection. However, due to the nature of the inspection which progresses in real time, proficiency and experience of the clinician affect the results, and the accuracy of the inspectioncan decrease due to increased work fatigue and decreased concentration. In this study, we developed a model that automatically detects the regions of gastric lesion in gastroscopic images using the RetinaNet network so that it can be used as an auxiliary system during gastroscopy. We confirmed the detection performance of models trained using ResNet50, ResNet152, EfficientNetB0, and EfficientNetB4 networks in a RetinaNet-based backbone network, and compared the performance between each model. The average sensitivities (FP/images) of RetinaNet-based backbone network-models were 73.72% (0.0489) for ResNet50, 78.26% (0.0458) for ResNet152, 79.67% (0.3268) for EfficinetNetB0, and 79.67% (0.3268) for EfficientNetB4. The EfficientNetB0 network showed the highest sensitivity, but the FP/images were very high, so the network satisfying both performance values was ResNet152."
심층 네트워크 모델에 기반한 어선 횡동요 시계열 예측,2023,"['fishing boat', 'capsizing accident', 'deep learning model', 'Xception', 'ResNet50', 'CRNN', '어선', '전복 사고', '딥러닝 모델', 'Xception', 'ResNet50', 'CRNN']","통계에 따르면 어선의 전복 사고는 전체 전복 사고의 절반 이상을 차지한다. 이는 미숙한 조업, 기상 악화, 정비 미흡 등 다양한 원인으로 발생할 수 있다. 업계 규모와 영향도, 기술 복잡성, 지역적 다양성 등으로 인해 어선은 상선에 비해 상대적으로 연구가 부족한 실정이다. 본 연구에서는 이미지 기반 딥러닝 모델을 활용하여 어선의 횡동요 시계열을 예측하고자 한다. 이미지 기반 딥러닝은 시계열의 다양한 패턴을 학습하여 높은 성능을 낼 수 있다. 이를 위해 Xception, ResNet50, CRNN의 3가지의 이미지 기반 딥러닝 모델을 활용하였다. Xception과 ResNet50은 각각 177, 184개의 층으로 구성되어 있으며 이에 반해 CRNN은 22개의 비교적 얇은 층으로 구성되어 있다. 실험 결과 Xception 딥러닝 모델이 가장 낮은 0.04291의 sMAPE와 0.0198의 RMSE를 기록하였다. ResNet50과 CRNN은 각각 0.0217, 0.022의 RMSE를 기록하였다. 이를 통해 상대적으로 층이 더 깊은 모델의 정확도가 높음을 확인할 수 있다.","Fishing boat capsizing accidents account for more than half of all capsize accidents. These can occur for a variety of reasons, including inexperienced operation, bad weather, and poor maintenance. Due to the size and influence of the industry, technological complexity, and regional diversity, fishing ships are relatively under-researched compared to commercial ships. This study aimed to predict the rolling motion time series of fishing boats using an image-based deep learning model. Image-based deep learning can achieve high performance by learning various patterns in a time series. Three image-based deep learning models were used for this purpose: Xception, ResNet50, and CRNN. Xception and ResNet50 are composed of 177 and 184 layers, respectively, while CRNN is composed of 22 relatively thin layers. The experimental results showed that the Xception deep learning model recorded the lowest Symmetric mean absolute percentage error(sMAPE) of 0.04291 and Root Mean Squared Error(RMSE) of 0.0198. ResNet50 and CRNN recorded an RMSE of 0.0217 and 0.022, respectively. This confirms that the models with relatively deeper layers had higher accuracy."
인공지능 기반 화자 식별 기술의 불공정성 분석,2023,"['Speaker Identification', 'Biased dataset', 'AI Fairness', 'CNN', 'VoxCeleb1']","Covid-19으로 인한 디지털화는 인공지능 기반의 음성인식 기술을 급속하게 발전시켰다. 그러나 이 기술은 데이터셋이 일부 집단에 편향될 경우 인종 및 성차별과 같은 불공정한 사회적 문제를 초래하고 인공지능 서비스의 신뢰성과 보안성을 열화시키는 요인이 된다. 본 연구에서는 대표적인 인공지능의 CNN(Convolutional Neural Network) 모델인 VGGNet(Visual Geometry Group Network), ResNet(Residual neural Network), MobileNet을 활용한 편향된 데이터 환경에서 정확도에 기반한 불공정성을 비교 및 분석한다. 실험 결과에 따르면 Top1-accuracy에서 ResNet34가 여성과 남성이 91%, 89.9%로 가장 높은 정확도를 보였고, 성별 간 정확도 차는 ResNet18이 1.8%로 가장 작았다. 모델별 성별 간의 정확도 차이는 서비스 이용 시 남녀 간의 서비스 품질에 대한 차이와 불공정한 결과를 야기한다.","Digitalization due to COVID-19 has rapidly developed artificial intelligence-based voice recognition technology. However, this technology causes unfair social problems, such as race and gender discrimination if datasets are biased against some groups, and degrades the reliability and security of artificial intelligence services. In this work, we compare and analyze accuracy-based unfairness in biased data environments using VGGNet (Visual Geometry Group Network), ResNet (Residual Neural Network), and MobileNet, which are representative CNN (Convolutional Neural Network) models of artificial intelligence. Experimental results show that ResNet34 showed the highest accuracy for women and men at 91% and 89.9% in Top1-accuracy, while ResNet18 showed the slightest accuracy difference between genders at 1.8%. The difference in accuracy between genders by model causes differences in service quality and unfair results between men and women when using the service."
단시간 수중음향 신호를 활용한 합성곱 신경망 기반의 선박 소음 탐지,2023,"['Underwater acoustics', 'Shipping noise', 'Deep learning', 'Convolutional neural network (CNN)']","해양에서 인간에 의해 발생하는 대부분의 소음은 어업 및 상업 운송과 관련된 선박 방사소음이 주요한 원인이다. 최근 선박소음을 자동으로 탐지하기 위한 방법으로 딥러닝 기술이 활용되고 있다. 본 연구에서는 1분 단위로 분할한 선박소음 신호 기반의 스펙트로그램 이미지를 합성곱 신경망 기반 학습을 수행하여 근거리 선박소음 및 배경소음을 자동으로 탐지하는 연구를 수행하였다. 현재까지 많이 사용되고 있는 합성곱 신경망 모델인 Inception-V3, ResNet-50, VGG-16와 본 연구에서 제안한 모델을 이용하여 1분 단위의 선박소음을 학습 및 평가를 수행하였다. 분석 결과 F1 점수는 모델별로 각각 Inception-V3 97.42%, ResNet-50 98.42%, VGG-16 98.16%, 제안된 모델은 97.88%로 나타나 선박소음을 탐지함에 있어 준수한 성능이 나타났다. 이 때, 제안된 모델은 F1 점수가 가장 높게 나타난 ResNet-50 모델에 비해 약 1/8의 적은 파라미터로 동등한 탐지 성능을 보이는 것을 확인할 수 있었다. 추후에는 다양한 선박소음 및 선박자동식별장치(AIS, Automatic Identification System) 자료를 동시에 활용하여 원거리 선박소음 또한 자동으로 탐지가 가능할 것으로 판단된다.","Most of the noise generated by humans in the ocean is ship radiated noise caused to fishing and commercial shipping. Recently, deep learning technology has been used to detect shipping noise. In this study, the convolutional neural network is trained by a shipping noise spectrogram divided into 1-minute units to detect a near distance ship. Inception-V3, ResNet-50, VGG-16 and the proposed model were used to learn and evaluate 1-minute shipping noise. As a result, the F1 scores were 97.42%, 98.42%, 98.16% and 97.88% for Inception-V3, ResNet-50, VGG-16 and the proposed model, respectively. These models showed satisfactory performance in detecting shipping noise. It was confirmed that the proposed model showed equivalent detection performance with about 1/8 parameters compared to ResNet-50. For future works, it is expected that it will be possible to detect long-distance shipping noise by using additional noise data and AIS(Automatic Identification System)."
딥러닝을 이용한 의류 이미지의 텍스타일 소재 분류,2023,"['Clothing Textile', 'Material Classification', 'Image Deep Learning', 'ResNet', 'Vision Transformer', '의류 텍스타일', '소재 분류', '이미지 딥러닝', 'ResNet', 'Vision Transformer']",,"As online transactions increase, the image of clothing has a great influence on consumer purchasing decisions. The importance of image information for clothing materials has been emphasized, and it is important for the fashion industry to analyze clothing images and grasp the materials used. Textile materials used for clothing are difficult to identify with the naked eye, and much time and cost are consumed in sorting. This study aims to classify the materials of textiles from clothing images based on deep learning algorithms. Classifying materials can help reduce clothing production costs, increase the efficiency of the manufacturing process, and contribute to the service of recommending products of specific materials to consumers. We used machine vision-based deep learning algorithms ResNet and Vision Transformer to classify clothing images. A total of 760,949 images were collected and preprocessed to detect abnormal images. Finally, a total of 167,299 clothing images, 19 textile labels and 20 fabric labels were used. We used ResNet and Vision Transformer to classify clothing materials and compared the performance of the algorithms with the Top-k Accuracy Score metric. As a result of comparing the performance, the Vision Transformer algorithm outperforms ResNet."
템플릿 매칭 및 딥러닝 모델을 이용한 공정 결함 탐지 방법,2023,"['결함 탐지', '템플릿 매칭', '딥러닝', '공장 자동화', 'ResNet34', 'Defect detection', 'Template Matching', 'Deep learning', 'Factory automation', 'ResNet34']",,
전이학습을 이용한 UNet 기반 건물 추출 딥러닝 모델의 학습률에 따른 성능 향상 분석,2023,"['Semantic building segmentation', 'UNet', 'VGG19', 'ResNet50', '의미론적 영상 분할']",,"In recent times, semantic image segmentation methods using deep learning models have been widely used for monitoring changes in surface attributes using remote sensing imagery. To enhance the performance of various UNet-based deep learning models, including the prominent UNet model, it is imperative to have a sufficiently large training dataset. However, enlarging the training dataset not only escalates the hardware requirements for processing but also significantly increases the time required for training. To address these issues, transfer learning is used as an effective approach, enabling performance improvement of models even in the absence of massive training datasets. In this paper we present three transfer learning models, UNet-ResNet50, UNet-VGG19, and CBAM-DRUNet-VGG19, which are combined with the representative pretrained models of VGG19 model and ResNet50 model. We applied these models to building extraction tasks and analyzed the accuracy improvements resulting from the application of transfer learning. Considering the substantial impact of learning rate on the performance of deep learning models, we also analyzed performance variations of each model based on different learning rate settings. We employed three datasets, namely Kompsat-3A dataset, WHU dataset, and INRIA dataset for evaluating the performance of building extraction results. The average accuracy improvements for the three dataset types, in comparison to the UNet model, were 5.1% for the UNet-ResNet50 model, while both UNet-VGG19 and CBAM-DRUNet-VGG19 models achieved a 7.2% improvement."
백본 네트워크에 따른 사람 속성 검출 모델의 성능 변화 분석,2023,"['Pedestrian attribute recognition', 'Deep neural networks', 'Backbone networks', 'Resnet', 'Swin']",,"Recently, with the development of deep learning technology, research on pedestrian attribute recognition technology using deep neural networks has been actively conducted. Existing pedestrian attribute recognition techniques can be obtained in such a way as global-based, regional-area-based, visual attention-based, sequential prediction-based, and newly designed loss function-based, depending on how pedestrian attributes are detected. It is known that the performance of these pedestrian attribute recognition technologies varies greatly depending on the type of backbone network that constitutes the deep neural networks model. Therefore, in this paper, several backbone networks are applied to the baseline pedestrian attribute recognition model and the performance changes of the model are analyzed. In this paper, the analysis is conducted using Resnet34, Resnet50, Resnet101, Swin-tiny, and Swinv2-tiny, which are representative backbone networks used in the fields of image classification, object detection, etc. Furthermore, this paper analyzes the change in time complexity when inferencing each backbone network using a CPU and a GPU."
명함 이미지 회전 판단을 위한 딥러닝 모델 비교,2023,"['명함', '이미지 회전', '인공 신경망', '스마트 프린팅 시스템', 'business cards', 'image rotation', 'artificial neural networks', 'smart printing system']","고객이 온라인으로 요청한 명함을 자동으로 명함을 인쇄하는 스마트 명함 인쇄 시스템이 활성화되고 있다. 이때, 문제는 고객이 시스템에 제출한 명함이 비정상일 수 있다는 것이다. 본 논문에서는 인공 지능 기술을 도입하여 명함의 이미지가 비정상적으로 회전됐는지 여부를 판정하는 문제를 다룬다. 명함은 0도, 90도, 180도, 270도 회전한다고 가정하였다. 특별한 인공신경망을 설계하지 않고 기존의 VGG, ResNet, DenseNet 인공신경망을 적용하여 실험하였는데 모든 신경망이 97% 정도의 정확도로 이미지 회전을 분별할 수 있었다. DenseNet161은 97.9%의 정확도를 보였고 ResNet34도 97.2%의 정밀도를 보였다. 이는 문제가 단순할 경우, 복잡한 인공신경망이 아니어도 충분히 좋은 결과를 낼 수 있음을 시사한다.","A smart business card printing system that automatically prints business cards requested by customers online is being activated. What matters is that the business card submitted by the customer to the system may be abnormal. This paper deals with the problem of determining whether the image of a business card has been abnormally rotated by adopting artificial intelligence technology. It is assumed that the business card rotates 0 degrees, 90 degrees, 180 degrees, and 270 degrees. Experiments were conducted by applying existing VGG, ResNet, and DenseNet artificial neural networks without designing special artificial neural networks, and they were able to distinguish image rotation with an accuracy of about 97%. DenseNet161 showed 97.9% accuracy and ResNet34 also showed 97.2% precision. This illustrates that if the problem is simple, it can produce sufficiently good results even if the neural network is not a complex one."
MEMS 라이다 센서를 활용한 심층학습 기반 조적벽체 결함 인식 기술,2023,"['Deep Learning', 'MEMS LiDAR', '3D Laser Scanner', 'Masonry Wall', 'Defect Classification', '심층학습', 'MEMS 라이다', '3D 레이저 스캐너', '조적벽체', '결함 인식']","건축물의 유지관리 및 안전점검은 대부분 점검자의 육안으로 진행하여 많은 시간과 인력이 소모된다는 문제점이 있다. 이를 보완하기 위해 영상처리기술 및 인공지능을 활용한 결함 인식 기술 개발이 활발하게 진행되고 있다. 하지만 기존의 영상처리 기법은 카메라를 통해 얻은 이미지를 분석하는 방식으로 주변 환경에 따라 성능이 변하는 한계가 있다. 최근 이를 해결하기 위해 3D 레이저 스캐닝 센서를 이용한 결함인식 방법을 개발하였으나 장치의 가격이 비싸 활발한 활용이 어렵다는 단점이 있다. 이에 본 연구는 기존 스캐닝 장치보다 가격이 저렴하고 신뢰할만한 성능을 보이고 있는 MEMS 라이다 센서를 이용해 조적벽체의 결함을 인식할 수 있는 기술을 개발하였다. 해당 연구는 조적벽체를 대상으로 하였으며, 실험실 환경에서 여러 종류의 결함을 가진 시험체를 제작하여 데이터를 획득하였다. 조적벽체 결한 인식 방법으로 인공지능을 활용한 연구에서 많이 사용하고 있는 ResNet-50과 VGG16 모델을 사용하여 결함을 인식하였으며, 성능평가 결과 ResNet-50은 98.75%, VGG16은 96.88%의 정확도를 보여주었다. 해당 연구 결과는 모바일 3D 레이저 스캐닝 장치와 결합하여 조적벽체의 실시간 결함 인식 기술 개발에 활용될 수 있을 것으로 판단된다.","Most of the maintenance and safety inspections of buildings are performed with visual assessment of the inspector, which consumes a lot oftime and cost. With the development of computer vision and digital technologies such as 3D Laser scanners, automatic defect recognitionusing image processing and artificial intelligence has been widely studied. Current approach is largely relying on the image obtained from thecamera and the recognition performance could be varied depending on the surrounding environment. Recently, studies using 3D Laser scannerare being conducted to solve these problems. However, terrestrial laser scanners are expensive, so it is difficult to apply at the constructionsite. Therefore, this study proposed a method that can recognize masonry wall defects using a Microelectromechanical systems based LightDetection and Ranging sensor that having much lower price and reliable performance. This study was performed using masonry wallstructures and data were collected from samples having various types of defects in a laboratory environment. Masonry wall defects wererecognized using ResNet-50 and VGG16 models, which are widely used in previous studies. As a result of the classification, ResNet-50 andVGG16 achieved 98.75% and 96.88% accuracy, respectively. The results of this study can be utilized in the development of real-time defectrecognition method for a masonry wall at construction sites."
AI-Based Vehicle Damage Repair Price Estimation System,2023,"['차량 손상', '객체 탐지', '차량 제작 및 모델 분류', '이미지 분류', 'Vehicle Damage', 'Object Detection', 'Vehicle Make and Model Classification', 'ResNet50', 'Image Classification']",,"Artificial intelligence-based estimation of repair costs for damaged vehicles is an emerging field that relies on artificial intelligence and computer vision systems to automatically generate accurate cost estimates. This area of research is becoming increasingly important owing to its potential to streamline the automotive repair industry, enhance overall transparency, improve the accuracy of cost estimation, and expedite insurance claims processing. This paper proposes the identification of the make and model of a vehicle, classification of the damaged vehicle type, and estimation of repair costs based on prices from various vehicle manufacturers. The proposed method for achieving state-of-the-art performance and time-saving in this system is through the use of ResNet50 and transfer learning. We propose a vehicle make and model classification module as well as a damaged vehicle classification module based on ResNet50 and transfer learning to improve the accuracy of the results. The accuracy of vehicle make and model classification module is 88%, which is approximately 11% higher than that of other studies. The accuracy of damaged vehicle classification module in this study is 86%, which is 67% higher than that of other studies."
Transfer Learning for Effective Urolithiasis Detection,2023,"['Urolithiasis', 'Urinary Calculi', 'Deep learning', 'Machine learning', 'Artificial intelligence']",,"Purpose: Urolithiasis is a common disease that can cause acute pain and complications. The objective of this study was to develop a deep learning model utilizing transfer learning for the rapid and accurate detection of urinary tract stones. By employing this method, we aim to improve the efficiency of medical staff and contribute to the progress of deep learning-based medical image diagnostic technology.Methods: The ResNet50 model was employed to develop feature extractors for detecting urinary tract stones. Transfer learning was applied by utilizing the weights of pretrained models as initial values, and the models were fine-tuned with the provided data. The model’s performance was evaluated using accuracy, precision-recall, and receiver operating characteristic curve metrics.Results: The ResNet-50-based deep learning model demonstrated high accuracy and sensitivity, outperforming traditional methods. Specifically, it enabled a rapid diagnosis of the presence or absence of urinary tract stones, thereby assisting doctors in their decision-making process.Conclusions: This research makes a meaningful contribution by accelerating the clinical implementation of urinary tract stone detection technology utilizing ResNet-50. The deep learning model can swiftly identify the presence or absence of urinary tract stones, thereby enhancing the efficiency of medical staff. We expect that this study will contribute to the advancement of medical imaging diagnostic technology based on deep learning."
딥러닝 기반 토마토 성숙도 판별 시스템,2023,"['HSV', 'RGB', 'ResNet-50', 'Deep Learning', 'Ripe degree', 'Color', 'Noise cancellation']",,"Currently, farmers are showing problems such as aging and rising labor costs, and the development of smart agriculture that combines cutting-edge technologies such as AI, video analysis, and big data is essential to solve these problems. In this study, a deep learning-based tomato maturity determination system was studied for the development of smart agriculture. In order to preprocess tomato images, colors were extracted for each image with RGB and HSV color models, and the extracted images were preprocessed into images that were easier to learn through noise removal using Gaussian filters and data normalization through Standard Scaler. The pretreated tomato image learned a tomato maturity discrimination image according to color using a deep learning model called ResNet-50 and a tomato maturity discrimination model was obtained. If a tomato maturity determination model is stored separately and then combined with a camera to take an image, the rating of the captured tomato can be immediately checked, and the captured image is also stored in the database for future model updates. It is expected to contribute to the great development of smart agriculture by using this tomato maturity determination system to prevent damage that may occur due to missed harvest time and to produce a system that can determine maturity by using the system."
Localization of lung abnormalities on chest X-rays using self-supervised equivariant attention,2023,"['Self-supervised equivariant attention', 'ResNet50', 'Siamese network', 'Weak supervision', 'Pixel correlation module', 'Self-attention', 'CAM']",,"Chest X-Ray (CXR) images provide most anatomical details and the abnormalities on a 2D plane. Therefore, a 2D view of the 3D anatomy is sometimes sufficient for the initial diagnosis. However, close to fourteen commonly occurring diseases are sometimes difficult to identify by visually inspecting the images. Therefore, there is a drift toward developing computer-aided assistive systems to help radiologists. This paper proposes a deep learning model for the classification and localization of chest diseases by using image-level annotations. The model consists of a modified Resnet50 backbone for extracting feature corpus from the images, a classifier, and a pixel correlation module (PCM). During PCM training, the network is a weight-shared siamese architecture where the first branch applies the affine transform to the image before feeding to the network, while the second applies the same transform to the network output. The method was evaluated on CXR from the clinical center in the ratio of 70:20 for training and testing. The model was developed and tested using the cloud computing platform Google Colaboratory (NVidia Tesla P100 GPU, 16 GB of RAM). A radiologist subjectively validated the results. Our model trained with the configurations mentioned in this paper outperformed benchmark results."
딥러닝 기법을 이용한 농업용저수지 CCTV 영상 기반의 수위계측 방법 개발,2023,"['CCTV', 'deep  learning', 'ResNet-50', 'water  level']",,"This study aimed to evaluate the performance of water level classification from CCTV images in agricultural facilities such as reservoirs. Recently, theCCTV system, widely used for facility monitor or disaster detection, can automatically detect and identify people and objects from the images bydeveloping new technologies such as a deep learning system. Accordingly, we applied the ResNet-50 deep learning system based on ConvolutionalNeural Network and analyzed the water level of the agricultural reservoir from CCTV images obtained from TOMS (Total Operation ManagementSystem) of the Korea Rural Community Corporation. As a result, the accuracy of water level detection was improved by excluding night and rainfallCCTV images and applying measures. For example, the error rate significantly decreased from 24.39 % to 1.43 % in the Bakseok reservoir. We believethat the utilization of CCTVs should be further improved when calculating the amount of water supply and establishing a supply plan according tothe integrated water management policy."
CT 정도관리에서 ACR 팬텀을 이용한 딥러닝 모델 적용에 관한 연구,2023,"['딥러닝', '컴퓨터단층촬영', 'ACR 팬텀', '정도관리', 'Deep learning', 'ResNet18', 'Computed tomography', 'ACR phantom', 'Quality control']",,"This study aimed to implement a deep learning model that can perform quantitative quality control through ACTS software used for quantitative evaluation of ACR phantom in CT quality control and evaluate its usefulness. By changing the scanning conditions, images of three modules of the ACR phantom's slice thickness (ST), low contrast resolution (LC), and high contrast resolution (HC) were obtained and classified as ACTS software. The deep learning model used ResNet18, implementing three models in which ST, HC, and LC were learned with epoch 50 and an integrated model in which three modules were learned with Epoch 10, 30, and 50 at once. The performance of each model was evaluated through Accuracy and Loss. When comparing and evaluating the accuracy and loss function values of the deep learning models by ST, LC, and HC modules, the Accuracy and Loss of the HC model were the best with 100% and 0.0081, and in the integrated model according to the Epoch value, Accuracy and Loss with epoch 50 were the best with 96.29% and 0.1856. This paper showed that quantitative quality control is possible through a deep learning model, and it can be used as a basis and evidence for applying deep learning to the CT quality control."
시계열 이미지 데이터 기반 상품추천을 위한 CNN 모델 성능 비교 연구,2023,"['CNN-based product recommendation model', 'Time series image data', 'AlexNet', 'VGG16', 'ResNet50', 'MobileNet']",,"In the modern world, advances in information technology have led to the expansion of e-commerce, making it important for automated recommendation systems to efficiently gather the flood of information and data to present consumers with their favorite products and services. Various techniques are used to improve the accuracy of product recommendation in existing e-commerce. Among them, there are chronic problems that use RNN, a multi classification-based product recommendation model. RNN is a deep learning model suitable for time series classification tasks, but it suffers from issues such as gradient vanishing and gradient exploding. To Compensate for these issues, CNN models are often used to effectively detect local patterns through kernels. In this study, we compare the performance of recommendation models based on an architecture that generates product recommendation models by training CNN models with time series data through three different imaging encodings: GAF, MTF and RP. In our experiments, we split the 540,000 published transaction dataset into train and test. The splitted data is constructed as time series data and zero-padded to equalize the size of the model’s input image. We train AlexNet, VGG16, ResNet50, and MobileNet models on images generated by the three imaging algorithms and compare their product recommendation accuracy with the performance of existing RNN recommendation models. We can see that the CNN models perform better than the LSTM. When imaged with the GAF algorithm and trained on the MobileNet model, the highest recommendation accuracy was achieved, and the learning time was also shortened, improving efficiency. Future research will include the advancement of imaging algorithms to improve the performance of product recommendation models and the development of CNN models optimized for time series image data."
Classification of Short Circuit Marks in Electric Fire Case with Transfer Learning and Fine-Tuning the Convolutional Neural Network Models,2023,"['Electric fire', 'Short-circuit', 'Convolutional neural network', 'VGG16', 'VGG19', 'Resnet50', 'InceptionV3', 'Xception']",,"One of the most essential substances for detecting electric fire is electric fire short-circuit marks. The traces of which can be found before and after the electric fire as the short circuit occurs. There are different kinds of electric fire short circuit marks, for instance, grounded, primary, and secondary molten marks these are categorized into the different types of short-circuit marks primary short circuit marks appear before the electric fire occurrence, and secondary short circuit marks appear after an electric fire to identify and classify them is crucial and time-consuming steps and procedures are needed for that purpose in this study we have used five convolutional neural network models such as VGG16, VGG19, Xception, InceptionV3, and Resnet50 to classify the short-circuit marks image data. Furthermore, according to our experiment on dataset among these five models, the best result was of VGG16 because the model performed well without any overfitting problems when we trained the sets of electric fire short circuit image data by applying the data augmentation, transfer learning, and fine-tuning techniques. The validation accuracy result of the VGG16 model at 50 epochs was 92.7% with a validation loss rate of 0.2."
예술 작품 아티스트 분류의 정확도 향상을 위한 CNN 구조 최적화,2023,"['컴퓨터 비전', '합성곱 신경망', '예술 작품 아티스트 분류', '미세 조정', 'ResNet50', 'Computer Vision', 'CNN', 'Artwork Classification', 'Fine-tuning', 'ResNet50']",,"Metaverse is a modern new technology that is advancing quickly. The goal of this study is to investigate this technique from the perspective of computer vision as well as general perspective. A thorough analysis of computer vision related Metaverse topics has been done in this study. Its history, method, architecture, benefits, and drawbacks are all covered. The Metaverse's future and the steps that must be taken to adapt to this technology are described. The concepts of Mixed Reality (MR), Augmented Reality (AR), Extended Reality (XR) and Virtual Reality (VR) are briefly discussed. The role of computer vision and its application, advantages and disadvantages and the future research areas are discussed."
단락흔 및 열흔 판별을 위한 CNN 기반 알고리즘의 모델별 성능 비교 분석에 관한 연구,2023,"['1차 단락흔', '2차 단락흔', '열흔', 'Inception v3', 'Googlenet', 'Vgg16', 'Resnet50', 'Primary Arc-bead', 'Secondary Arc-bead', 'Molten mark Inception v3', 'Googlenet', 'Vgg16', 'Resnet50']",,
아크페이스에 지식 증류를 적용한 얼굴인식,2023,"['AI', 'Face Recognition', 'ArcFace', 'Knowledge Distillation', 'Deep Learning']",,"This paper studied the model lightening and speed improvement of face recognition. To this end, we propose a method of training with MobileNetV2 through knowledge distillation as a student model and based on ArcFace and ResNet50 as a teacher model. ArcFace is face recognition model using Additive Angular Margin Loss. The main objective was to compare the performance of the student model against that of the teacher model in terms of similarity results. The findings indicated that the student model outperformed the teacher model in terms of similarity results. These results suggest that the MobileNetV2-based student model can achieve comparable face recognition performance to the more complex ResNet50-based teacher model, while being computationally more efficient."
딥 러닝 분류 모델을 이용한 직하방과 경사각 영상 기반의 벼 출수기 판별,2023,"['Rice heading date', 'CNN', 'Deep learning', 'Classification model', 'Image processing', 'Paddy field monitoring']","벼의 출수기를 추정하는 것은 농업생산성과 관련된 중요한 과정 중 하나이지만 세계적인 이상기후의 증가로 벼의 출수기를 추정하는 것이 어려워지고 있다. 본 연구에서는 CNN 분류모델을 사용하여 다양한 영상 데이터에서 벼의 출수기를 추정하려고 시도하였다. 드론과 타워형 영상관측장치 그리고 일반 RGB 카메라로 촬영된 직하방과 경사각 영상을 수집하였다. 수집 한 영상은 CNN 모델의 입력데이터로 사용하기 위해서 전처리를 진행하였고, 사용된 CNN 아키텍처는 이미지 분류 모델에서 일반적으로 사용되는 ResNet50, InceptionV3 그리고 VGG19 를 사용하였다. 각각의 아키텍처는 모델의 종류, 영상의 유형과 관계없이 0.98 이상의 정확도를 나타내었다. 또한 CNN 분류 모델이 영상의 어떤 특징을 보고 분류하였는지 시각적으로 확인하기 위해서 Grad-CAM 을 사용하였다. Grad-CAM 결과 CNN 분류 모델은 벼의 출수를 이삭의 형태에 높은 가중치를 두어 분류 하는 것을 확인하였다. 다음으로 작성된 모델이 실제 논 포장 모니터링 이미지에서 벼의 출수기를 정확하게 추정하는지 확인하였다. 각각 다른 지역 4 개의 벼 포장에서 벼의 출수 기를 약 하루정도의 차이로 추정하는 것을 확인하였다. 이 방법을 통해서 다양한 논 포장의 모니터링 이미지를 활용하여 자동적이고 정량적으로 벼의 출수기를 추정 할 수 있다고 판단된다.","Estimating the rice heading date is one of the most crucial agricultural tasks related to productivity. However, due to abnormal climates around the world, it is becoming increasingly challenging to estimate the rice heading date. Therefore, a more objective classification method for estimating the rice heading date is needed than the existing methods. This study, we aimed to classify the rice heading stage from various images using a CNN classification model. We collected top-view images taken from a drone and a phenotyping tower, as well as slanted-view images captured with a RGB camera. The collected images underwent preprocessing to prepare them as input data for the CNN model. The CNN architectures employed were ResNet50, InceptionV3, and VGG19, which are commonly used in image classification models. The accuracy of the models all showed an accuracy of 0.98 or higher regardless of each architecture and type of image. We also used Grad-CAM to visually check which features of the image the model looked at and classified. Then verified our model accurately measure the rice heading date in paddy fields. The rice heading date was estimated to be approximately one day apart on average in the four paddy fields. This method suggests that the water head can be estimated automatically and quantitatively when estimating the rice heading date from various paddy field monitoring images."
상추잎 너비와 길이 예측을 위한 합성곱 신경망 모델 비교,2023,"['data augmentation', 'lettuce imaging', 'plant growth', 'transfer learning', 'vertical farming', '데이터 증강', '상추이미지', '수직농장', '식물 생장', '전이학습']","식물의 잎의 크기나 면적을 아는 것은 생장을 예측하고 실내농장의 생산성의 향상에 중요한 요소이다. 본 연구에서는 상추 잎 사진을 이용해 엽장과 엽폭을 예측할 수 있는 CNN기반모델을 연구하였다. 데이터의 한계와 과적합 문제를 극복하기 위해 콜백 함수를 적용하고, 모델의 일반화 능력을 향상시키기 위해 K겹 교차 검증을 사용했다. 또한 데이터 증강을 통한 학습데이터의 다양성을 높이기 위해 image generator를 사용하였다. 모델 성능을 비교하기 위해 VGG16, Resnet152, NASNetMobile 등 사전학습된 모델을 이용하였다. 그 결과너비 예측에서 R2 값 0.9436, RMSE 0.5659를 기록한 NASNetMobile이가장 높은 성능을 보였으며 길이 예측에서는 R2 값이 0.9537, RMSE가 0.8713로 나타났다. 최종 모델에는NASNetMobile 아키텍처, RMSprop 옵티마이저, MSE 손실 함수, ELU 활성화함수가 사용되었다. 모델의 학습 시간은Epoch당 평균 73분이 소요되었으며, 상추 잎 사진 한 장을 처리하는 데 평균 0.29초가 걸렸다. 본 연구는 실내 농장에서 식물의 엽장과 엽폭을 예측하는 CNN 기반 모델을 개발하였고이를 통해 단순한 이미지 촬영만으로도 식물의 생장 상태를신속하고 정확하게 평가할 수 있을 것으로 기대된다. 또한 그결과는 실시간 양액 조절 등의 적절한 농작업 조치를 하는데 활용됨으로써 농장의 생산성 향상과 자원 효율성을 향상시키는데 기여할 것이다.","Determining the size or area of a plant's leaves is an important factor in predicting plant growth and improving the productivity of indoor farms. In this study, we developed a convolutional neural network (CNN)-based model to accurately predict the length and width of lettuce leaves using photographs of the leaves. A callback function was applied to overcome data limitations and overfitting problems, and K-fold cross-validation was used to improve the generalization ability of the model. In addition, ImageDataGenerator function was used to increase the diversity of training data through data augmentation. To compare model performance, we evaluated pre-trained models such as VGG16, Resnet152, and NASNetMobile. As a result, NASNetMobile showed the highest performance, especially in width prediction, with an R_squared value of 0.9436, and RMSE of 0.5659. In length prediction, the R_squared value was 0.9537, and RMSE of 0.8713. The optimized model adopted the NASNetMobile architecture, the RMSprop optimization tool, the MSE loss functions, and the ELU activation functions. The training time of the model averaged 73 minutes per Epoch, and it took the model an average of 0.29 seconds to process a single lettuce leaf photo. In this study, we developed a CNN-based model to predict the leaf length and leaf width of plants in indoor farms, which is expected to enable rapid and accurate assessment of plant growth status by simply taking images. It is also expected to contribute to increasing the productivity and resource efficiency of farms by taking appropriate agricultural measures such as adjusting nutrient solution in real time."
컴퓨터 단층촬영 영상에서 3번 요추부 슬라이스 검출을 위한 최적화 기반 딥러닝 모델,2023,"['Medical image', 'Optimization', 'Computerized Tomography Data', 'Artificial intelligence']","본 논문에서는 근감소증의 발병 여부와 정도를 확인하기 위해 3번 요추부 (L3) CT 영상을 검출하는 딥러닝 모델을 제안하는 것이다. 또한, CT 데이터 내에 L3 레벨과 L3 레벨이 아닌 부분의 데이터 불균형으로 인한 성능 저하의 문제점을 오버샘플링 비율과 클래스 가중치를 설계변수로 하는 최적화 기법을 제시하고자 한다. 모델 학습 및 검증을 위하여 강릉아산병원에 내원한 전립선암 환자 104명, 방광암 환자 46명의 총 150명의 전신 CT 영상이 활용되었다. 딥러닝 모델은 ResNet50을 활용하였으며, 최적화기법의 설계변수로는 모델 하이퍼파라미터 5종과 데이터 증강비율 및 클래스 가중치로 선정하였다. 제안하는 최적화 기반의 L3 레벨 추출 모델은 대조군 (하이퍼파라미터 5종만을 최적화한 모델)과 비교하여 중간 L3 오차가 약  1.0 슬라이스 감소한 것을 확인할 수 있었다. 본 연구결과를 통하여 정확한 L3 슬라이스 검출이 가능하며, 추가적으로 데이터 증강을 통한 오버 샘플링과 클래스 가중치 조절을 통해 데이터 불균형 문제를 효과적으로 해결할 수 있는 가능성을 제시할 수 있다.","In this paper, we propose a deep learning model to detect lumbar 3 (L3) CT images to determine the occurrence and degree of sarcopenia. In addition, we would like to propose an optimization technique that uses oversampling ratio and class weight as design parameters to address the problem of performance degradation due to data imbalance between L3 level and non-L3 level portions of CT data. In order to train and test the model, a total of 150 whole-body CT images of 104 prostate cancer patients and 46 bladder cancer patients who visited Gangneung Asan Medical Center were used. The deep learning model used ResNet50, and the design parameters of the optimization technique were selected as six types of model hyperparameters, data augmentation ratio, and class weight. It was confirmed that the proposed optimization-based L3 level extraction model reduced the median L3 error by about 1.0 slices compared to the control model (a model that optimized only 5 types of hyperparameters). Through the results of this study, accurate L3 slice detection was possible, and additionally, we were able to present the possibility of effectively solving the data imbalance problem through oversampling through data augmentation and class weight adjustment."
범용 AI 컴파일러의 비공개 NPU 코드생성을 위한 공통 인터페이스 설계 및 검증,2023,"['Nueral processing unit', 'Compiler', 'Deep learning']","본 논문에서는 NPU(Neural Processing Units)의 제조사별 비공개 백엔드 컴파일러와 범용 AI 컴파일러를 연결할 수 있는 공통 인터페이스를 제안한다. 이를 통해 다양한 AI 모델에 대한 지원과 기업 자산 보호가 가능하다. 제안된 인터페이스는 ONNX 표준을 따르며, ETRI의 NEST-C 컴파일러와 오픈엣지의 ENLIGHT 컴파일러를 해당 인터페이스로 통합했다. 실험 결과, 통합된 컴파일러는 ENLIGHT만을 사용한 것과 Resnet50과 MobileNetV2 두 종류의 모델에 대해서 100% 결과가 일치했다. 따라서 제안된 인터페이스는 NPU 백엔드 컴파일러의 범용성을 향상하면서도 비공개성을 유지할 수 있는 유용한 방안을 제공한다.","This paper proposes a common interface for connecting proprietary back-end compilers of NPU (Neural Processing Units) manufacturers with general-purpose AI compilers, enabling support for various AI models while protecting corporate assets. The proposed interface adheres to the ONNX standard and integrates ETRI's NEST-C compiler with OPENEDGES's ENLIGHT compiler through this interface. Experimental results showed that the integrated compiler achieved 100% result consistency for two types of models, ResNet50 and MobileNetV2, compared to using ENLIGHT alone. Therefore, the proposed interface offers a valuable solution for enhancing the versatility of NPU back-end compilers while maintaining their proprietary nature."
X-ray 및 초음파 영상을 활용한 고관절 이형성증 진단을  위한 특징점 검출 딥러닝 모델 비교 연구,2023,"['영유아 고관절 이형성증', '초음파', 'X-ray', '딥러닝', '특징점 검', 'Developmental Dysplasia of Hip (DDH)', 'Ultrasound', 'X-ray', 'Deep-learning', 'Keypoint detection']","고관절 이형성증(Developmental Dysplasia of Hip, DDH)은 영유아 성장기에 흔히 발생하는 병리학적 상태로, 영유아의 성장을 방해하고 잠재적인 합병증을 유발하는 원인 중 하나이며 이를 조기에 발견하고 치료하는 것은 매우 중요하다. 기존의 DDH 진단 방법으로는 촉진법과 X-ray 또는 초음파 영상 기반 고관절에서의 특징점 검출을 이용한 진단 방법이 있지만 특징점 검출 시 객관성과 생산성에 제한점이 존재한다. 본 연구에서는 X-ray 및 초음파 영상을이용한 딥러닝 모델 기반 특징점 검출 방법을 제시하고, 다양한 딥러닝 모델을 이용하여 특징점 검출의 성능을 비교분석하였다. 또한, 부족한 의료 데이터를 보완하는 방법인 다양한 데이터 증강 기법을 제시하고 비교 평가하였다. 본연구에서는 Residual Network 152(ResNet152) 및 Simple & Complex augmentation 기법을 적용하였을 때 가장 높은 특징점 검출 성능을 보여주었으며, X-ray 영상에서 평균 Object Keypoint Similarity(OKS)가 약 95.33 %, 초음파영상에서는 약 81.21 %로 각각 측정되었다. 이러한 결과는 고관절 초음파 및 X-ray 영상에서 딥러닝 모델을 적용함으로써 DDH 진단 시 특징점 검출에 관한 객관성과 생산성을 향상시킬 수 있음을 보여준다.","Developmental Dysplasia of the Hip (DDH) is a pathological condition commonly occurring during the growth phase of infants. It acts as one of the factors that can disrupt an infant's growth and trigger potential complications. Therefore, it is critically important to detect and treat this condition early. The traditional diagnostic methods for DDH involve palpation techniques and diagnosis methods based on the detection of keypoints in the hip joint using X-ray or ultrasound imaging. However, there exist limitations in objectivity and productivity during keypoint detection in the hip joint. This study proposes a deep learning model-based keypoint detection method using X-ray and ultrasound imaging and analyzes the performance of keypoint detection using various deep learning models. Additionally, the study introduces and evaluates various data augmentation techniques to compensate the lack of medical data. This research demonstrated the highest keypoint detection performance when applying the residual network 152 (ResNet152) model with simple & complex augmentation techniques, with average Object Keypoint Similarity (OKS) of approximately 95.33 % and 81.21 % in X-ray and ultrasound images, respectively. These results demonstrate that the application of deep learning models to ultrasound and X-ray images to detect the keypoints in the hip joint could enhance the objectivity and productivity in DDH diagnosis."
도로 침수 탐지를 위한 딥러닝 모델 구현 및 성능 비교,2023,"['road flooding prediction', 'road flooding detection', 'deep learning', 'pre-trained models', 'CNN network layer', '.']",,"Existing road flooding systems using a single sensor give an alarm when the water level reaches a certain value, making it difficult to determine road flooding and take first action. Therefore, in this paper, 8 models based on CNN were implemented to develop a real-time road flooding system using CCTV, and their performance was compared through learning and verification. Each learning model was trained with a batch size of 16 and 120 epochs, and as a result of the experiment, the deep learning models showed an average accuracy of 90%. In particular, in terms of accuracy, the ShuffleNet V1, SqueezeNet, and ResNet-50 models performed best in order. However, for real-time road flood detection and prediction, an appropriate number of parameters and short inference time are required for each model. Assuming that each CCTV is analyzed once every 10 seconds, it was analyzed that the ResNet-50 model could accommodate up to 800 CCTVs."
농업용 저수지 CCTV 영상자료 기반 수위 인식 모델 적용성 검토,2023,"['Machine learning', 'Water level recognition', 'Reservoir', 'CCTV', 'Image processing', '기계학습', '수위 인식', '저수지', 'CCTV', '이미지 처리']","농업용 저수지는 농업용수 공급에 있어서 매우 중요한 생산기반시설로, 우리나라 농업용수의 60% 정도를 공급하고 있다. 다만, 여러 문제로 인해 농업용수의 효율적인 공급에 어려움이 발생하고 있으며, 효과적인 공급 및 관리 체계 구현을 위한 정확한 실시간 저수위 혹은 저수량 추정이 필요하다. 본 연구에서는 영상정보를 활용한 딥러닝 기반 농업용 저수지 수위 인식 모델을 제안하였다. 개발한 모델은 (1) CCTV 영상정보 자료 수집 및 분석, (2) U-Net 이미지 분할 방법을 통한 입력 자료 생성, 그리고 (3) CNN과 ResNet 모델을 통한 수위 인식 세 단계로 구성된다. 모델은 두 농업용 저수지(G저수지와 M저수지)의 영상자료와 저수위 시계열자료를 활용하여 구현하였다. 적용 결과 이미지 분할 모델의 성능은 매우 우수한 것으로 나타났으며, 수위 인식 모델의 경우 수위 분류 계급구간에 따라 성능이 상이한 것으로 나타났다. 특히 영상자료의 픽셀 변동이 클수록 정확도 80% 이상이 확보 가능한 것으로 확인되었으나, 그렇지 않은 경우, 정확도가 50% 수준인 것으로 나타났다. 본 연구에서 개발한 모델은 향후 이미지 자료가 추가로 확보될 경우, 그 활용도 및 정확도가 더 높아질 것으로 기대한다.","The agricultural reservoir is a critical water supply system in South Korea, providing approximately 60% of the agricultural water demand. However, the reservoir faces several issues that jeopardize its efficient operation and management. To address this issues, we propose a novel deep-learning-based water level recognition model that uses CCTV image data to accurately estimate water levels in agricultural reservoirs. The model consists of three main parts: (1) dataset construction, (2) image segmentation using the U-Net algorithm, and (3) CCTV-based water level recognition using either CNN or ResNet. The model has been applied to two reservoirs G-reservoir and M-reservoir with observed CCTV image and water level time series data. The results show that the performance of the image segmentation model is superior, while the performance of the water level recognition model varies from 50 to 80% depending on water level classification criteria (i.e., classification guideline) and complexity of image data (i.e., variability of the image pixels). The performance of the model can be improved if more numbers of data can be collected."
기계학습을 이용한 스마트 공장 자료의 불량 분류 모형 개발,2023,"['스마트 공장', '제조 데이터', '빅데이터', '기계학습', '딥러닝', 'Smart factory', 'Manufacturing data', 'Big data', 'Machine learning', 'Deep learning']","정보기술의 발전으로 인해 현대사회의 다양한 분야에서 ICT 기술과의 융합이 가속화되면서 제조업 분야에서도 인공지능과 자동화 기술을 활용한 스마트 공장이 등장하였다. 스마트 공장은 실시간으로 자료를 수집하고 이를 분석하여 최적의 의사결정을 진행함으로써 생산 과정의 문제점을 개선하고 생산성과 효율성을 향상시키는 것을 목표로 한다. 본 연구에서는 스마트 공장에서 수집된 자료에 기계학습과 딥러닝 모형을 적용하여 제조공정의 생산성과 효율성을 향상시킬 수 있는 프레임워크를 구축하고자 한다. 먼저 생산 과정에서 발생하는 온도와 압력에 관련된 공정 환경 자료를 기계학습 방법인 로지스틱 회귀, 랜덤 포레스트, 그래디언트 부스티드 트리, 지지벡터기계를 사용하여 불량을 1차적으로 탐지한다. 다음으로 용접을 마치고 난 후 촬영된 제품의 용접 이미지 자료에 딥러닝 기법을 적용하여 불량을 탐지한다. 이를 위해 AlexNet, VGG-16, ResNet과 같은 합성곱 신경망 기반 모형을 사용하였다. 이후 각 자료에 대해 정확도, 정밀도, 재현율 등의 성능평가지표를 사용하여 구현된 모형들의 성능을 비교하고, 각 자료에 대해 가장 우수한 성능을 보이는 모형을 최종 모형으로 선택하였다. 공정 환경 및 이미지 자료에서 선택된 최적의 모형은 높은 정확도로 불량을 탐지해 낼 수 있었으며 이를 실제 제조공정에 적용하여 자동화된 불량 탐지 시스템을 구축한다면 공정의 생산성과 효율성을 크게 향상시킬 수 있을 것이라 기대된다.","The rapid convergence of ICT (Information and Communication Technology) with various fields in modern society has led to the emergence of smart factories in the manufacturing industry. These factories leverage artificial intelligence and automation technology to enhance productivity and efficiency by collecting real-time data and making optimal decisions through analysis. In this study, we aimed to develop machine learning and deep learning models to improve manufacturing processes in smart factories. Firstly, we implemented a model using logistic regression, random forest, gradient boosted trees, and support vector machine to classify defects based on process environment data, including temperature and pressure. Next, we applied convolutional neural network models such as AlexNet, VGG-16, and ResNet to classify defective welding images captured after the welding process. We evaluated the performance of these models using metrics like accuracy, precision, and recall for each dataset and selected the top-performing model as the final choice."
GPS 및 딥러닝을 이용한 스마트 시티 투어 모바일 애플리케이션,2023,"['스마트 투어', '위치 기반 서비스', '딥러닝', '모바일 애플리케이션', '이미지 분류', 'Smart tourism', 'Location-based services', 'Deep learning', 'Mobile applications', 'Image classification']","본 논문에서는 GPS 및 딥러닝 기반의 스마트 시티 투어 모바일 애플리케이션을 제안한다. 제안된 애플리케이션은 딥러닝을 이용하여 랜드마크 이미지 인식 기능을 제공하고 위치기반 서비스를 통해 현재 사용자의 위치에 기반하여 주변 관광지 정보를 제공한다. 이미지 인식 서비스는 사용자가 애플리케이션에 랜드마크 이미지를 업로드하면 딥러닝 모델을 통해 이미지를 식별하고, 해당 랜드마크의 세부 정보를 제공한다. 랜드마크 이미지는 ResNet-D 모델을 사용하여 서울시에 있는 13개의 랜드마크에 대해 학습을 진행하여 최종 모델의 평균 분류 정확도는 약 0.957, 평균 F1-Score는 약 0.938로 좋은 성능을 얻었다. 또한 애플리케이션 내에서 위치기반 서비스를 통해 사용자의 현재 위치로부터 가까운 랜드마크의 정보를 알 수 있으며, 각 랜드마크의 정보를 다른 사용자에게 공유할 수 있다. 본 애플리케이션을 통해 여행 중이거나 여행을 계획 중인 외국인들에게 수도 서울에 대한 정보를 신속하게 제공하여 여행에 도움을 줄 수 있다.","In this study, we propose a smart city tour mobile application based on GPS and deep learning. The proposed application provides the landmark image recognition service using deep learning and provides information on nearby tourist attractions based on the current user’s location through location-based services. The image recognition service identifies the image through a deep learning model when a user uploads a landmark image to the application and provides a detailed description of the landmark. We trained landmark images using the ResNet-D model on 13 landmarks in Seoul and achieved good performance of the final model with average classification accuracy and F1-score of around 0.957 and 0.938, respectively. In addition, location-based services within the application allow users to know information about landmarks close to their current location and share the information with other users. Foreigners who are traveling or planning to travel can easily obtain information about the capital Seoul with this application to aid their travel."
Evaluation of Deep Learning Model for Scoliosis Pre-Screening Using Preprocessed Chest X-ray Images,2023,"['Scoliosis', 'Chest X-ray', 'Deep learning model', 'Preprocessed image', 'Data augmentation']",,"Scoliosis is a three-dimensional deformation of the spine that is a deformity induced by physical or disease-related causes as the spine is rotated abnormally. Early detection has a significant influence on the possibility of nonsurgical treatment. To train a deep learning model with preprocessed images and to evaluate the results with and without data augmentation to enable the diagnosis of scoliosis based only on a chest X-ray image. The preprocessed images in which only the spine, rib contours, and some hard tissues were left from the original chest image, were used for learning along with the original images, and three CNN(Convolutional Neural Networks) models (VGG16, ResNet152, and EfficientNet) were selected to proceed with training. The results obtained by training with the preprocessed images showed a superior accuracy to those obtained by training with the original image. When the scoliosis image was added through data augmentation, the accuracy was further improved, ultimately achieving a classification accuracy of 93.56% with the ResNet152 model using test data. Through supplementation with future research, the method proposed herein is expected to allow the early diagnosis of scoliosis as well as cost reduction by reducing the burden of additional radiographic imaging for disease detection."
준지도 학습과 전이 학습을 이용한 선로 체결 장치 결함 검출,2023,"['Fastener', 'Semi-supervised', 'Pretrained', 'Cost', '선로 체결 장치', '준지도 학습', '전이 학습', '비용']",오늘날 인공지능 산업이 발전함에 따라 여러 분야에 걸쳐 인공지능을 통한 자동화 및 최적화가 이루어지고 있다. 국내의 철도 분야 또한 지도 학습을 이용한 레일의 결함을 검출하는 연구들을 확인할 수 있다. 그러나 철도에는 레일만이 아닌 다른 구조물들이 존재하며 그중 선로 체결 장치는 레일을 다른 구조물에 결합시켜주는 역할을 하는 장치로 안전사고의 예방을 위해서 주기적인 점검이 필요하다. 본 논문에는 선로 체결 장치의 데이터를 이용하여 준지도 학습(semi-supervised learning)과 전이 학습(transfer learning)을 이용한 분류기를 학습시켜 선로 안전 점검에 사용되는 비용을 줄이는 방안을 제안한다. 사용된 네트워크는 Resnet50이며 imagenet으로 선행 학습된 모델이다. 레이블이 없는 데이터에서 무작위로 데이터를 선정 후 레이블을 부여한 뒤 이를 통해 모델을 학습한다. 학습된 모델의 이용하여 남은 데이터를 예측 후 예측한 데이터 중 클래스 별 확률이 가장 높은 데이터를 정해진 크기만큼 훈련용 데이터에 추가하는 방식을 채택하였다. 추가적으로 초기의 레이블된 데이터의 크기가 끼치는 영향력을 확인해보기 위한 실험을 진행하였다. 실험 결과 최대 92%의 정확도를 얻을 수 있었으며 이는 지도 학습 대비 5% 내외의 성능 차이를 가진다. 이는 제안한 방안을 통해 추가적인 레이블링 과정 없이 비교적 적은 레이블을 이용하여 분류기의 성능을 기존보다 향상시킬 수 있을 것으로 예상된다.,"Recently, according to development of artificial intelligence, a wide range of industry being automatic and optimized. Also we can find out some research of using supervised learning for deteceting defect of railway in domestic rail industry. However, there are structures other than rails on the track, and the fastener is a device that binds the rail to other structures, and periodic inspections are required to prevent safety accidents. In this paper, we present a method of reducing cost for labeling using semi-supervised and transfer model trained on rail fastener data. We use Resnet50 as the backbone network pretrained on ImageNet. At first we randomly take training data from unlabeled data and then labeled that data to train model.  After predict unlabeled data by trained model, we adopted a method of adding the data with the highest probability for each class to the training data by a predetermined size.  Futhermore, we also conducted some experiments to investigate the influence of the number of initially labeled data. As a result of the experiment, model reaches 92% accuracy which has a performance difference of around 5% compared to supervised learning. This is expected to improve the performance of the classifier by using relatively few labels without additional labeling processes through the proposed method."
그래프 트랜스포머 기반 농가 사과 품질 이미지의 그래프 표현 학습 연구,2023,"['딥 러닝', '그래프 표현 학습', '사과 품질 분류', '랜덤워크 위치 인코딩', 'Deep learning', 'Graph representation learning', 'Apple Quality Classification', 'Randomwalk positional encoding']","최근 농가의 사과 품질 선별 작업에서 인적자원의 한계를 극복하기 위해 합성곱 신경망(CNN) 기반 시스템이 개발되고 있다. 그러나 합성곱 신경망은 동일한 크기의 이미지만을 입력받기 때문에 샘플링 등의 전처리 과정이 요구될 수 있으며, 과도 샘플링의 경우 화질 저하, 블러링 등 원본 이미지의 정보손실 문제가 발생한다. 본 논문에서는 위 문제를 최소화하기 위하여, 원본 이미지의 패치 기반 그래프를 생성하고 그래프 트랜스포머 모델의 랜덤워크 기반 위치 인코딩 방법을 제안한다. 위 방법은 랜덤워크 알고리즘 기반 위치정보가 없는 패치들의 위치 임베딩 정보를 지속적으로 학습하고, 기존 그래프 트랜스포머의 자가 주의집중 기법을 통해 유익한 노드정보들을 집계함으로써 최적의 그래프 구조를 찾는다. 따라서 무작위 노드 순서의 새로운 그래프 구조와 이미지의 객체 위치에 따른 임의의 그래프 구조에서도 강건한 성질을 가지며, 좋은 성능을 보여준다. 5가지 사과 품질 데이터셋으로 실험하였을 때, 다른 GNN 모델보다 최소 1.3%에서 최대 4.7%의 학습 정확도가 높았으며, ResNet18 모델의 23.52M보다 약 15% 적은 3.59M의 파라미터 수를 보유하여 연산량 절감에 따른 빠른 추론 속도를 보이며 그 효과를 증명한다.","Recently, a convolutional neural network (CNN) based system is being developed to overcome the limitations of human resources in the apple quality classification of farmhouse. However, since convolutional neural networks receive only images of the same size, preprocessing such as sampling may be required, and in the case of oversampling, information loss of the original image such as image quality degradation and blurring occurs. In this paper, in order to minimize the above problem, to generate a image patch based graph of an original image and propose a random walk-based positional encoding method to apply the graph transformer model. The above method continuously learns the position embedding information of patches which don`t have a positional information based on the random walk algorithm, and finds the optimal graph structure by aggregating useful node information through the self-attention technique of graph transformer model. Therefore, it is robust and shows good performance even in a new graph structure of random node order and an arbitrary graph structure according to the location of an object in an image. As a result, when experimented with 5 apple quality datasets, the learning accuracy was higher than other GNN models by a minimum of 1.3% to a maximum of 4.7%, and the number of parameters was 3.59M, which was about 15% less than the 23.52M of the ResNet18 model. Therefore, it shows fast reasoning speed according to the reduction of the amount of computation and proves the effect."
초소형 IoT 장치에 구현 가능한 딥러닝 양자화 기술 분석,2023,"['Internet of Things', 'Deep Learning', 'Quantization', 'Model Training', 'Experimental Configuration', '사물인터넷', '딥러닝', '양자화', '모델 훈련', '실험 구성']",많은 연산량을 가진 딥러닝은 초소형 IoT 장치나 모바일 장치에 구현하기가 어렵다. 최근에는 이러한 장치에서도 딥러닝을 구현할 수 있도록 모델의 연산량을 줄이는 딥러닝 경량화 기술이 소개되었다. 양자화는 연속적인 분포를가지는 파라미터 값들을 고정된 비트의 이산 값으로 표현하여 모델의 메모리 및 크기 등을 줄여 효율적으로 사용할수 있는 경량화 기법이다. 그러나 양자화로 인한 이산 값 표현으로 인해 모델의 정확도가 낮아지게 된다. 본 논문에서는정확도를 개선할 수 있는 다양한 양자화 기술을 소개한다. 먼저 기존 양자화 기술 중 APoT와 EWGS를 선택하여 동일한 환경에서 실험을 통해 결과를 비교 분석하였다. 선택된 기술은 ResNet모델에서 CIFAR-10 또는 CIFAR-100 데이터 세트로 훈련되고 테스트 되었다. 실험 결과 분석을 통해 기존 양자화 기술의 문제점을 파악하고 향후 연구에 대한방향성을 제시하였다.,"Deep learning with large amount of computations is difficult to implement on micro-sized IoT devices or moblie devices. Recently, lightweight deep learning technologies have been introduced to make sure that deep learning can be implemented even on small devices by reducing the amount of computation of the model. Quantization is one of lightweight techniques that can be efficiently used to reduce the memory and size of the model by expressing parameter  values  with  continuous distribution as discrete values of fixed bits. However, the accuracy of the model is reduced due to discrete  value  representation  in  quantization.  In  this  paper,  we  introduce  various  quantization techniques to correct the accuracy. We selected APoT and EWGS from existing quantization techniques, and comparatively analyzed the results through experimentations The selected techniques were trained and tested with CIFAR-10 or CIFAR-100 datasets in the ResNet model. We found out problems with them through experimental results analysis and presented directions for future research."
Dog-Species Classification through CycleGAN and Standard Data Augmentation,2023,"['CycleGAN', 'Data Augmentation', 'DNN', 'GAN', 'Image Classification']",,"In the image field, data augmentation refers to increasing the amount of data through an editing method suchas rotating or cropping a photo. In this study, a generative adversarial network (GAN) image was created usingCycleGAN, and various colors of dogs were reflected through data augmentation. In particular, dog data fromthe Stanford Dogs Dataset and Oxford-IIIT Pet Dataset were used, and 10 breeds of dog, corresponding to 300images each, were selected. Subsequently, a GAN image was generated using CycleGAN, and four learninggroups were established: 2,000 original photos (group I); 2,000 original photos + 1,000 GAN images (groupII); 3,000 original photos (group III); and 3,000 original photos + 1,000 GAN images (group IV). The amountof data in each learning group was augmented using existing data augmentation methods such as rotating,cropping, erasing, and distorting. The augmented photo data were used to train the MobileNet_v3_Large,ResNet-152, InceptionResNet_v2, and NASNet_Large frameworks to evaluate the classification accuracy andloss. The top-3 accuracy for each deep neural network model was as follows: MobileNet_v3_Large of 86.4%(group I), 85.4% (group II), 90.4% (group III), and 89.2% (group IV); ResNet-152 of 82.4% (group I), 83.7%(group II), 84.7% (group III), and 84.9% (group IV); InceptionResNet_v2 of 90.7% (group I), 88.4% (groupII), 93.3% (group III), and 93.1% (group IV); and NASNet_Large of 85% (group I), 88.1% (group II), 91.8%(group III), and 92% (group IV). The InceptionResNet_v2 model exhibited the highest image classificationaccuracy, and the NASNet_Large model exhibited the highest increase in the accuracy owing to dataaugmentation."
Biometric identification of Black Bengal goat: unique iris pattern matching system vs deep learning approach,2023,"['Biometric Identification', 'Black Bengal Goat', 'Deep Learning', 'Goat Identification', 'Iris Image', 'Iris Pattern Matching']",,"Objective: Iris pattern recognition system is well developed and practiced in human, however, there is a scarcity of information on application of iris recognition system in animals at the field conditions where the major challenge is to capture a high-quality iris image from a constantly moving non-cooperative animal even when restrained properly. The aim of the study was to validate and identify Black Bengal goat biometrically to improve animal management in its traceability system.Methods: Forty-nine healthy, disease free, 3 months±6 days old female Black Bengal goats were randomly selected at the farmer’s field. Eye images were captured from the left eye of an individual goat at 3, 6, 9, and 12 months of age using a specialized camera made for human iris scanning. iGoat software was used for matching the same individual goats at 3, 6, 9, and 12 months of ages. Resnet152V2 deep learning algorithm was further applied on same image sets to predict matching percentages using only captured eye images without extracting their iris features.Results: The matching threshold computed within and between goats was 55%. The accuracies of template matching of goats at 3, 6, 9, and 12 months of ages were recorded as 81.63%, 90.24%, 44.44%, and 16.66%, respectively. As the accuracies of matching the goats at 9 and 12 months of ages were low and below the minimum threshold matching percentage, this process of iris pattern matching was not acceptable. The validation accuracies of resnet152V2 deep learning model were found 82.49%, 92.68%, 77.17%, and 87.76% for identification of goat at 3, 6, 9, and 12 months of ages, respectively after training the model.Conclusion: This study strongly supported that deep learning method using eye images could be used as a signature for biometric identification of an individual goat."
PartitionTuner: An operator scheduler for deep-learning compilers supporting multiple heterogeneous processing units,2023,"['deep neural network', 'deep-learning compiler', 'parallel processing', 'partitioning']",,"Recently, embedded systems, such as mobile platforms, have multiple processing units that can operate in parallel, such as centralized processing units (CPUs) and neural processing units (NPUs). We can use deep-learning compilers to generate machine code optimized for these embedded systems from a deep neural network (DNN). However, the deep-learning compilers proposed so far generate codes that sequentially execute DNN operators on a single processing unit or parallel codes for graphic processing units (GPUs). In this study, we propose PartitionTuner, an operator scheduler for deep-learning compilers that supports multiple heterogeneous PUs including CPUs and NPUs. PartitionTuner can generate an operator-scheduling plan that uses all available PUs simultaneously to minimize overall DNN inference time. Operator scheduling is based on the analysis of DNN architecture and the performance profiles of individual and group operators measured on heterogeneous processing units. By the experiments for seven DNNs, PartitionTuner generates scheduling plans that perform 5.03% better than a static type-based operator-scheduling technique for SqueezeNet. In addition, PartitionTuner outperforms recent profiling-based operator-scheduling techniques for ResNet50, ResNet18, and SqueezeNet by 7.18%, 5.36%, and 2.73%, respectively."
CT 정도관리를  위한  인공지능  모델  적용에  관한  연구,2023,"['CT', 'Artificial intelligence', 'Quality control', 'AAPM CT phantom', 'Quantitative evaluation']",,"CT is a medical device that acquires medical images based on Attenuation coefficient of human organs related to X-rays. In addition, using this theory, it can acquire sagittal and coronal planes and 3D images of the human body. Then, CT is essential device for universal diagnostic test. But Exposure of CT scan is so high that it is regulated and managed with special medical equipment. As the special medical equipment, CT must implement quality control.In detail of quality control, Spatial resolution of existing phantom imaging tests, Contrast resolution and clinical image evaluation are qualitative tests. These tests are not objective, so the reliability of the CT undermine trust. Therefore, by applying an artificial intelligence classification model, we wanted to confirm the possibility of quantitative eval- uation of the qualitative evaluation part of the phantom test. We used intelligence classification models (VGG19, DenseNet201, EfficientNet B2, inception_resnet_v2, ResNet50V2, and Xception). And the fine-tuning process used for learning was additionally performed. As a result, in all classification models, the accuracy of spatial resolution was 0.9562 or higher, the precision was 0.9535, the recall was 1, the loss value was 0.1774, and the learning time was from a maximum of 14 minutes to a minimum of 8 minutes and 10 seconds. Through the experimental results, it was concluded that the artificial intelligence model can be applied to CT implements quality control in spatial res- olution and contrast resolution."
포장층 이상구간에서 획득한 열화상 이미지 해석을 위한 CNN 알고리즘의 적용성 평가,2023,"['CNN', 'Infrared camera', 'Res Net 101', 'Squeeze Net']",,"The presence of abnormalities in the subgrade of roads poses safety risks to users and results in significant maintenance costs. In this study, we aimed to experimentally evaluate the temperature distributions in abnormal areas of subgrade materials using infrared cameras and analyze the data with machine learning techniques. The experimental site was configured as a cubic shape measuring 50 cm in width, length, and depth, with abnormal areas designated for water and air. Concrete blocks covered the upper part of the site to simulate the pavement layer. Temperature distribution was monitored over 23 h, from 4 PM to 3 PM the following day, resulting in image data and numerical temperature values extracted from the middle of the abnormal area. The temperature difference between the maximum and minimum values measured 34.8°C for water, 34.2°C for air, and 28.6°C for the original subgrade. To classify conditions in the measured images, we employed the image analysis method of a convolutional neural network (CNN), utilizing ResNet-101 and SqueezeNet networks. The classification accuracies of ResNet-101 for water, air, and the original subgrade were 70%, 50%, and 80%, respectively. SqueezeNet achieved classification accuracies of 60% for water, 30% for air, and 70% for the original subgrade. This study highlights the effectiveness of CNN algorithms in analyzing subgrade properties and predicting subsurface conditions."
과수화상병 판별을 위한 AI 모델 신뢰성 평가 연구,2023,"['Trustworthiness', 'Grad-CAM', 'XAI', 'ResNet50V2', 'InceptionV3', 'Xception', 'Fireblight']",,
CNN 기술을 적용한 침수탐지 학습모델 개발,2023,"['Flooded Road', 'Deep Learning', 'Image Classification', 'CNN']",,"This paper developed a training model to classify normal roads and flooded roads using artificial intelligence technology. We expanded the diversity of learning data using various data augmentation techniques and implemented a model that shows good performance in various environments. Transfer learning was performed using the CNN-based Resnet152v2 model as a pre-learning model. During the model learning process, the performance of the final model was improved through various parameter tuning and optimization processes. Learning was implemented in Python using Google Colab NVIDIA Tesla T4 GPU, and the test results showed that flooding situations were detected with very high accuracy in the test dataset."
Identification of seed coat sculptures using deep learning,2023,['Allium seed coat deep learning image recognition seed coat sculpture'],,"Seed coat sculptures, including anticlinal and periclinal walls, are of great taxonomic importance. In this study, we identified seed coat patterns of Allium seeds using five deep learning methods namely, CNN, AlexNet, GoogleNet, ResNet50, and VGG16 for the first time. Selected images of seed coat patterns from over 100 Allium species reported in previously published literature and data from our samples were classified into seven types of anticlinal (irregular curved, irregular curved to nearly straight, straight, S, U, UO, and omega) and five types of periclinal walls (granule, small verruca, large verruca, marginal verruca, and verrucate verruca). The results revealed that GoogleNet and VGG16 achieved the highest classifi cation accuracy of 90.4% for the anticlinal wall, and VGG16 achieved the highest classification accuracy of 98.1% for the periclinal wall. Moreover, more than three, four, and five methods were combined, and their performance was investigated. Combining more than three methods was the most advantageous. The models achieved a suitable anticlinal wall classification using GoogleNet and periclinal wall classification using VGG16. In conclusion, using the machine-based method, we studied the seed coat of species of Allium on our own samples to see if the results of the machine-based method match with the human based classification."
A study on the effectiveness of intermediate features in deep learning on facial expression recognition,2023,"['Intermediate Feature', 'Artificial Intelligence', 'Facial Expression Recognition']",,"The purpose of this study is to evaluate the impact of intermediate features on FER performance. To achieve this objective, intermediate features were extracted from the input images at specific layers (FM1~FM4) of the pre-trained network (Resnet-18). These extracted intermediate features and original images were used as inputs to the vision transformer (ViT), and the FER performance was compared. As a result, when using a single image as input, using intermediate features extracted from FM2 yielded the best performance (training accuracy: 94.35%, testing accuracy: 75.51%). When using the original image as input, the training accuracy was 91.32% and the testing accuracy was 74.68%. However, when combining the original image with intermediate features as input, the best FER performance was achieved by combining the original image with FM2, FM3, and FM4 (training accuracy: 97.88%, testing accuracy: 79.21%). These results imply that incorporating intermediate features alongside the original image can lead to superior performance. The findings can be referenced and utilized when designing the preprocessing stages of a deep learning model in FER. By considering the effectiveness of using intermediate features, practitioners can make informed decisions to enhance the performance of FER systems."
딥러닝과 XGBoost를 이용한 뇌졸중전조증상진단 애플리케이션,2023,"['뇌졸중 진단', '입술 특징추출', '딥러닝', '의미론적 영상 분할', 'XGBoost', 'Stroke', 'Lips Feature Extraction', 'Deep Learning', 'Semantic Segmentation', 'XGBoost']",,"In this paper, after segmenting the lip area in the facial image, using the featurepoints of the lip, it is determined whether there is a precursor symptom of stroke.UNet and FCN, which are semantic image segmentation models, were used forsegmentation of the lip region, and at this moment, VGGNet16, ResNet101, andDenseNet121 were used as backbone networks. As a result of the experiment, themIoU of UNet using DenseNet121 was the highest at 92.5%. And, as a result oflearning with XGBoost using the feature map of the lip area and diagnosing astroke, it showed 98.8% accuracy. As a result of comparison with the existingstroke diagnosis method, the accuracy improved by 7.74~10.8%."
파편 탐지 성능 향상을 위한 딥러닝 초해상도화 효과 분석,2023,[],,"The Arena Fragmentation Test(AFT) is designed to analyze warhead performance by measuring fragmentation data. In order to evaluate the results of the AFT, a set of AFT images are captured by high-speed cameras. To detect objects in the AFT image set, ResNet-50 based Faster R-CNN is used as a detection model. However, because of the low resolution of the AFT image set, a detection model has shown low performance. To enhance the performance of the detection model, Super-resolution(SR) methods are used to increase the AFT image set resolution. To this end, The Bicubic method and three SR models: ZSSR, EDSR, and SwinIR are used. The use of SR images results in an increase in the performance of the detection model. While the increase in the number of pixels representing a fragment flame in the AFT images improves the Recall performance of the detection model, the number of pixels representing noise also increases, leading to a slight decreases in Precision performance. Consequently, the F1 score is increased by up to 9 %, demonstrating the effectiveness of SR in enhancing the performance of the detection model."
전이 학습과 데이터 증강을 이용한 너구리와 라쿤 분류,2023,"['딥러닝', '머신러닝', '전이 학습', '데이터 증강', '동물 분류', 'Deep learning', 'Machine Learning', 'Transfer Learning', 'Data Augmentation', 'Animal Classification']","최근 인간의 활동 범위가 증가함에 따라 외래종의 유입이 잦아지고 있고 환경에 적응하지 못해 유기된 외래종 중 2020년부터 유해 지정 동물로 지정된 라쿤이 문제가 되고 있다. 라쿤은 국내 토종 너구리와 크기나 생김새가 유사하여 일반적으로 포획하는데 있어서 구분이 필요하다. 이를 해결하기 위해서 이미지 분류에 특화된 CNN 딥러닝 모델인 VGG19, ResNet152V2, InceptionV3, InceptionResNet, NASNet을 사용한다. 학습에 사용할 파라미터는 많은 양의 데이터인 ImageNet으로 미리 학습된 파라미터를 전이 학습하여 이용한다. 너구리와 라쿤 데이터셋에서 동물의 외형적인 특징으로 분류하기 위해서 이미지를 회색조로 변환한 후 밝기를 정규화하였으며, 조정된 데이터셋에 충분한 학습을 위한 데이터를 만들기 위해 좌우 반전, 회전, 확대/축소, 이동을 이용하여 증강 기법을 적용하였다. 증강하지 않은 데이터셋은 FCL을 1층으로, 증강된 데이터셋은 4층 으로 구성하여 진행하였다. 여러 가지 증강된 데이터셋의 정확도를 비교한 결과, 증강을 많이 할수록 성능이 증가함을 확인하였다.",
Self-Gated Rectified Linear Unit for Performance Improvement of Deep Neural Networks,2023,['Image classificationActivation functionDeep neural networkAccuracyTime complexity'],,"This technical paper proposes an activation function, self-gated rectified linear unit (SGReLU), to achieve high classification accuracy, low loss, and low computational time. Vanishing gradient problem, dying ReLU, noise vulnerability are also resolved in our proposed SGReLU function. SGReLU’s performance is evaluated on MNIST, Fashion-MNIST, and Imagenet datasets and compared with seven highly effective activation functions. We obtained that the proposed SGReLU outperformed other activation functions in most cases in VGG16, Inception v3, and ResNet50. In VGG16 and Inception v3, it achieved an accuracy of 90.87% and 95.01%, respectively, exceeding other functions with the second-fastest computing time in these networks."
딥러닝 기반의 실시간 상품 진열 상황 추정 시스템,2023,"['딥러닝', '상품 전시', 'Deep Learning', 'Plan-o-gram', 'Product Display', 'YOLO']",,"In this paper, we developed a store management system that detects the display status of products in real time and manages them to comply with the plan-o-gram using real-time product recognition and display status estimation technology based on deep learning. To achieve this, we input store shelf images, localize each product using the YOLOv8 deep learning model trained with the SKU110K data set, and generate an image feature vector using an em-bedder that fine-tunes the ResNet-50 model, combining the pre-registered reference image feature vector and Compare and identify and classify products. The plan-o-gram compliance control algorithm has been supplemented so that the plan-o-gram compliance status generated through sequence alignment of the modified Needleman-Wunsch(NW) algorithm can be utilized in actual store situations. Previously, there were many errors by judging the four states: exact match(MT), missing item(MI), added item in the correct position(ME), and added or misplaced item or empty space(NM). Accordingly, in this paper, we subdivide NM into 5 states (addition, deletion, location change, remote placement, and position shift), expand it to a total of 8 states, and present an algorithm that can handle various characteristic cases."
CNN과 학습 가능한 상관필터를 결합한  객체 추적 알고리즘,2023,"['Computer Vision', 'Object Tracking', 'Correlation Filter', 'Convolution Neural Networks', 'Deep Learning']",,"Object tracking is considered a challenging problem due to various environmental changes contained in the video sequence. Object tracking is the use of information given in the first frame to estimate the area and trajectory of a target object in a video sequence. In this paper, we propose an algorithm for object tracking using multi-scale feature maps of Resnet-50 and correlation filters. To accommodate changes in object scale, we create an appearance model using different sized feature maps extracted from each block in the network. In order to maintain the robustness of the appearance model, it is adaptively updated according to the peak value of the response map when occlusion occurs due to obstacles. Experiments result using the OTB2015 dataset showed that the proposed algorithm achieved competitive results on several image attribution such as low resolution, scale variation, occlusion and out of view."
데이터 재사용을 지원하는 HLS 기반 효율적인 합성곱 가속기의 설계,2023,"['CNN acceleration', 'high-level synthesis', 'FPGA', 'data reuse', 'CNN 가속기', 'high-level synthesis', 'FPGA', '데이터 재사용']","본 논문에서는 HLS(High Level Synthesis)를 사용하여 개발, 검증이 쉬우면서 확장 가능한 CNN(Convolution Neural Network) 가속기를 설계하였다. DRAM 접근량을 줄이기 위한 타일 버퍼와 2차원 PE 배열을 가지는 weight stationary 가속기 구조를 설계하고, HLS의 디렉티브을 통해 PE 및 태스크 병렬성을 효율적으로 활용하는 가속기를 구현하였다. 한편, DRAM 접근을 생략할 수 있는 경우, 동적으로 타일 버퍼에서 데이터 재사용할 수 있도록 HLS 라이브러리의 Stream(FIFO)을 이용하여 구현하였다. 이를 통해 32×32 PE에서 13.7% 가속하여, Xilinx Alveo U200 FPGA에서 ResNet50 추론을 49 ms까지 가속하였다. Vitis HLS를 통해 PE의 개수를 손쉽게 확장하여, 서버 수준인 64×64 PE까지 835 GOPS의 성능 및 35.3 GOPS/W의 전력효율을 보이는 것을 확인하였다.",
A dual-experience pool deep reinforcement learning method and its application in fault diagnosis of rolling bearing with unbalanced data,2023,['· Deep reinforcement learning · Dual-experience pool · Unbalanced data · Rolling bearing · Fault diagnosis'],,"A dual-experience pool deep reinforcement learning (DEPDRL) model is proposed for rolling bearing fault diagnosis with unbalanced data. In this method, a dualexperience pool structure is designed to store the sample data of majority and minority classes.A parallel double residual network model is established to extract deep features of the majority and minority input samples, respectively. In the process of training, the proposed balanced cross-sampling technique is used to randomly select samples from dual-experience pool in a certain proportion to realize the training of a double residual network model. We show the effectiveness of our method on three standard data sets, and compared with Resnet18, DCNN, DQN and DQNimb methods, the results show that DEPDRL has the best performance. Finally, with wavelet time-frequency graph as input, DEPDRL is applied to rolling bearing fault diagnosis with unbalanced test data. The results show that on a variety of unbalanced data sets, both the diagnostic accuracy and the G-means value of the DEPDRL are more than 5 % higher than other algorithms, which fully indicates that the DEPDRL has a very high fault diagnosis ability of rolling bearing with unbalanced data."
심층신경망을 이용한 스마트 양식장용 사료 공급 시점 감지 시스템 구현,2023,"['Smart fish farm', 'LabVIEW', 'Automatic detection', 'Deep neural network', 'Classification']",,"In traditional fish farming way, the workers have to observe all of the pools every time and every day to feed at the right timing. This method causes tremendous stress on workers and wastes time. To solve this problem, we implemented an automatic detection system for feeding time using deep neural network. The detection system consists of two steps: classification of the presence or absence of feed and checking DO (Dissolved Oxygen) of the pool. For the classification, the pretrained ResNet18 model and transfer learning with custom dataset are used. DO is obtained from the DO sensor in the pool through HTTP in real time. For better accuracy, the next step, checking DO proceeds when the result of the classification is absence of feed several times in a row. DO is checked if it is higher than a DO reference value that is set by the workers. These actions are performed automatically in the UI programs developed with LabVIEW."
SAM Optimizer를 통한 위내시경 이미지 분류 CADx의 성능 향상 연구,2023,"['CADx', 'Gastric Diagnosis', 'Classification', 'Convolution Neural Network', 'Deep learning', 'Vision Transformer']",,"Gastric cancer has a high incidence in East Asians, and the risk increases over time. Often, gastric cancer presents no early symptoms, leading to missed treatments. Consequently, in Korea, support is provided to individuals over 40 years of age who undergo gastroscopy. However, as the number of gastroscopy patients increases, doctors' fatigue rises, becoming a factor that can lead to misdiagnosis. Therefore, this paper proposes a CADx (Computer-Aided Diagnosis) system for gastric lesion classification based on ConvNeXt and ViT (Vision Transformer), applying the SAM (Sharpness Aware Minimization) optimizer. ConvNeXt is a network that achieves high performance by incorporating techniques from Swin Transformer and the latest advancements, with ResNet-50 as the base model. ViT divides the image into smaller patches and uses these patches as input to the Transformer. This allows for learning relationships between patches and ultimately leads to image classification. To address the issue of limited data in medical images, the gastric abnormal dataset was augmented using the AutoAugment policy. The SAM Optimizer is an optimization technique that detects and minimizes the ""sharpness"" of the loss function that may occur during the deep learning model's learning process. Using this method, the sensitivity of classifying abnormal and normal gastroscopy images in ConvNeXt increased from 0.7167 to 0.9583 for the original dataset and from 0.7583 to 0.9833 for the augmented dataset. ViT exhibited a significant decrease from 0.9500 to 0.7750 in the original dataset but increased from 0.9500 to 0.9583 in the augmented dataset. This demonstrates that the SAM Optimizer can effectively enhance CADx performance."
내시경 영상에서의 딥러닝 기반 상부 위장관 랜드마크 식별,2023,"['deep learning', 'artificial intelligence', 'endoscopic image']",,"Accurate identification of landmarks is critical for effective diagnosis and treatment in endoscopy, particularly in the upper gastrointestinal tract. However, there are many similar structures inside the stomach, and it might be difficult to accurately locate landmarks in camera images because of other factors such as air bubbles and the narrow field of view of wired endoscopic images. This study presents a comparative analysis experiment conducted with a model that can identify anatomical landmarks of the upper gastrointestinal tract with high accuracy through small-scale data-based local augmentation. We used five classes captured by esophagogastroduodenoscopy criterion, preprocessed medical image data to address the class imbalance, and compared the accuracies of ResNet50, MobileNetV2, and DensNet265 models. We used a dataset comprising 2,546 images of patients who underwent upper gastrointestinal endoscopy at Yonsei Severance Hospital. We augmented 4,632 images and evenly distributed them across five classes. Our results indicate that this is the most accurate model for improving diagnosis and treatment in upper gastrointestinal endoscopy. The ReseNet50 model achieved the highest accuracy at 74.88%, followed by the MobileNetV2 model at 78.91% and DensNet265 at 84.70%."
뇌졸중 동물 모델의 분할 및 분류를 위한 방사광 영상 딥러닝 모델 분석,2023,"['Stroke', 'Synchrotron Radiation Imaging', 'Biomedical', 'CNN', 'Deep Learning']",,"Stroke causes muscle dysfunction in lower limb depending on the brain damage. Therefore, it is important to identify the degree of muscle damaged and perform rehabilitation training for appropriate time of treatment. However, there is a limitation in that analysis using existing imaging techniques and artificial intelligence cannot analyze disease mechanisms.This paper aims to develop an AI GUI system using SRI to acquire damaged muscle regions, segment them into fiber and space areas, and classify them. For the segmentation, Attention U-Net performed best accuracy 95.32%. For the classification, ResNet50 with Attention U-Net performed best accuracy 99.07%. As a result of this, we designated the best performing network as suitable for stroke animal models. As an auxiliary tool for diagnosing the degree of stroke muscle damage in clinical practice, we constructed a system to analyze the degree of stroke fiber distribution on SRI images using pixel intensity values to show the results. Through this study, it is system that uses deep learning in the stroke animal model can be applied as a basic study for objective muscle tissue evaluation."
엑스선 이미지 기반 결핵 예측 시스템을 위한 데이터 증강 전처리 조합법,2023,"['딥러닝', '헬스케어', '데이터 증강', 'X-선 이미지', '웹 프레임워크', 'Deep Learning', 'Health Care', 'Data Augmentation', 'X-ray Image', 'Web Framework']","최근 헬스케어 및 의료 분야에서 컨볼루션 신경망(CNN) 모델을 활용한 X-선 이미지 분석 연구가 활발히 이루어지고 있다. X 선은 폐렴, 결핵, 유방암 등 다양한 흉부 질환을 비침습적으로 검사하는 주요 도구로서, 비용 효율적이며 많은 검사가 가능하다는장점을 갖는다. 하지만 기존의 X-선 이미지 기반 질환 진단 인공지능 모델은 복잡한 아키텍처를 가지며 많은 파라미터와 대량의데이터가 필요한 한계를 가진다. 본 연구에서는 이러한 문제를 해결하기 위해 적은 양의 X-선 이미지 데이터로 높은 결핵 예측 정확도를 달성할 수 있는 효과적인 전처리 조합법을 탐색하고 제안한다. 본 연구에서는 대표적인 데이터 증강법인 Random Erase,Random Flip, Random Augmentation을 함께 사용하는 전처리 조합법을 제안하였으며, 이를 ResNet50 모델과 EfficientNet-b0 모델에 적용하여 각 평균 11%, 9%의 성능 향상을 확인할 수 있었다. 또한, 전처리 조합이 적용된 모델을 쉽게 사용할 수 있도록 웹 프레임워크를 개발하였다. 사용자는 웹 프레임워크를 통해 입력 이미지를 수정할 수 있으며, 인공지능 결핵 판별 결과를 얻을 수 있다.",
딥러닝 기반 농경지 속성분류를 위한 TIF 이미지와 ECW 이미지 간 정확도 비교 연구,2023,"['AI', 'deep  learning', 'agricultural  land', 'FarmMap']",,"In this study, We conduct a comparative study of deep learning-based classification of agricultural field attributes using Tagged Image File (TIF) andEnhanced Compression Wavelet (ECW) images. The goal is to interpret and classify the attributes of agricultural fields by analyzing the differencesbetween these two image formats. “FarmMap,” initiated by the Ministry of Agriculture, Food and Rural Affairs in 2014, serves as the first digital mapof agricultural land in South Korea. It comprises attributes such as paddy, field, orchard, agricultural facility and ginseng cultivation areas. For thepurpose of comparing deep learning-based agricultural attribute classification, we consider the location and class information of objects, as well as theattribute information of FarmMap. We utilize the ResNet-50 instance segmentation model, which is suitable for this task, to conduct simulatedexperiments. The comparison of agricultural attribute classification between the two images is measured in terms of accuracy. The experimental resultsindicate that the accuracy of TIF images is 90.44%, while that of ECW images is 91.72%. The ECW image model demonstrates approximately 1.28%higher accuracy. However, statistical validation, specifically Wilcoxon rank-sum tests, did not reveal a significant difference in accuracy between thetwo images."
Deep Learning-Based Feature Extraction from Whole-Body PET/CT Employing Maximum Intensity Projection Images: Preliminary Results of Lung Cancer Data,2023,['Deep learning · PET/CT · Maximum intensity projection · Convolutional neural network · FDG'],,"Purpose Deep learning (DL) has been widely used in various medical imaging analyses. Because of the difficulty in processingvolume data, it is difficult to train a DL model as an end-to-end approach using PET volume as an input for variouspurposes including diagnostic classification. We suggest an approach employing two maximum intensity projection (MIP)images generated by whole-body FDG PET volume to employ pre-trained models based on 2-D images.Methods As a retrospective, proof-of-concept study, 562 [18F]FDG PET/CT images and clinicopathological factors oflung cancer patients were collected. MIP images of anterior and lateral views were used as inputs, and image features wereextracted by a pre-trained convolutional neural network (CNN) model, ResNet-50. The relationship between the imageswas depicted on a parametric 2-D axes map using t-distributed stochastic neighborhood embedding (t-SNE), with clinicopathologicalfactors.Results A DL-based feature map extracted by two MIP images was embedded by t-SNE. According to the visualizationof the t-SNE map, PET images were clustered by clinicopathological features. The representative difference between theclusters of PET patterns according to the posture of a patient was visually identified. This map showed a pattern of clusteringaccording to various clinicopathological factors including sex as well as tumor staging.Conclusion A 2-D image-based pre-trained model could extract image patterns of whole-body FDG PET volume by usinganterior and lateral views of MIP images bypassing the direct use of 3-D PET volume that requires large datasets andresources. We suggest that this approach could be implemented as a backbone model for various applications for wholebodyPET image analyses."
인공지능 의료 영상인식 기술을 활용한 유방암 영상 진단 기법 연구,2023,"['유방암', '이미지 분류', '이미지 분할', '데이터 증강', 'Breast cancer', 'Image recognition', 'segmentation', 'Classification']","본 논문은 인공지능 의료영상인식 기술을 활용하여 유방암 진단을 하는 기법에 대해 연구하였다. 이를 위해 맘모그래피 이미지, 초음파 이미지, 조직병리 이미지를 사용하여, 이미지 분류 기법과 이미지 분할 기법을 통해 유방암 분류와 해당 환부 위치를 추론하는 과정의 정확도 향상을 위한 전략들에 대해 연구하였다. 즉, 성능 최적화를 위해 여러 이미지 분류 기술 및 이미지 분할 기법들과 관련 손실함수들 중에 각 의료영상 데이터 별 최적의기술을 선별하였고, 해당 성능 최적화를 위한 데이터 증강 기법을 제시하였다. 제시된 방법들을 통해 분석한 결과, 필터 기반의 데이터 증강 기술을 활용하면 이미지 분류 기술에서는 ResNet50이 가장 좋은 성능을, 이미지 분할기술로는 맘모그래피 영상과 초음파 영상 모두 UNet 기술이 가장 좋은 성능을 나타내었다. 해당 기술을 적용한결과, 맘모그래피 영상에서의 이미지 분할 작업에서는 33.3%, 초음파 영상에서의 이미지 분할 작업에서는 29.9%, 조직병리 이미지에서의 이미지분류 작업에서는 22.8%의 성능 향상을 나타내었다.",
A Taekwondo Poomsae Movement Classification Model Learned Under Various Conditions,2023,"['Pose Estimation', 'Machine Learning', 'Deep Learning', 'Convolutional Neural Network', 'Deep Convolutional Neural Network', '자세 분류', '머신러닝', '딥러닝', '합성곱 신경망', '심층 합성곱 신경망']","태권도 겨루기의 전자호구, 축구의 VAR 등 스포츠에서 기술 발전이 고도화되고 있다. 하지만태권도 품새는 사람이 직접 자세를 눈으로 보고 판단하며 지도하기 때문에 때로는 대회의 현장에서 판정시비가 일어난다. 본 연구는 인공지능을 이용하여 태권도 동작을 더 정확하게 판단하고평가할 수 있는 인공지능 모델을 제안한다. 본 연구에서는 촬영 및 수집한 데이터를 전처리한 후학습, 테스트, 검증 세트로 분리한다. 분리한 데이터를 각 모델과 조건을 적용하여 학습한 후 비교하여 가장 좋은 성능의 모델을 제시한다. 각 조건의 모델은 정확도, Precision, Recall, F1-Score, 학습 소요 시간, Top-n error의 값을 비교하였고 그 결과 ResNet50과 Adam을 사용한 조건에서 학습한 모델의 성능이 가장 우수한 것으로 나타났다. 본 연구에서 제시한 모델을 활용하여 교육 현장이나 대회 등 다양한 방면에서 활용할 수 있을 것으로 기대한다.",
뇌성마비 환자의 자세 불균형 탐지를 위한 스마트폰 동영상 기반 보행 분석 시스템,2023,"['Gait analysis', 'Postural imbalance detection', 'Human pose estimation', 'Tilt correction', 'Temporal smoothing']",,"Gait analysis is an important tool in the clinical management of cerebral palsy, allowing for the assessment of condition severity, identification of potential gait abnormalities, planning and evaluation of interventions, and providing a baseline for future comparisons. However, traditional methods of gait analysis are costly and time-consuming, leading to a need for a more convenient and continuous method. This paper proposes a method for analyzing the posture of cerebral palsy patients using only smartphone videos and deep learning models, including a ResNet-based image tilt correction, AlphaPose for human pose estimation, and SmoothNet for temporal smoothing. The indicators employed in medical practice, such as the imbalance angles of shoulder and pelvis and the joint angles of spine-thighs, knees and ankles, were precisely examined. The proposed system surpassed pose estimation alone, reducing the mean absolute error for imbalance angles in frontal videos from 4.196° to 2.971° and for joint angles in sagittal videos from 5.889° to 5.442°."
Automatically Diagnosing Skull Fractures Using an Object Detection Method and Deep Learning Algorithm in Plain Radiography Images,2023,['Deep learning · Artificial intelligence · Radiography · Skull fractures · Traumatic brain injury'],,"Objective : Deep learning is a machine learning approach based on artificial neural network training, and object detection algorithm using deep learning is used as the most powerful tool in image analysis. We analyzed and evaluated the diagnostic performance of a deep learning algorithm to identify skull fractures in plain radiographic images and investigated its clinical applicability.Methods : A total of 2026 plain radiographic images of the skull (fracture, 991; normal, 1035) were obtained from 741 patients. The RetinaNet architecture was used as a deep learning model. Precision, recall, and average precision were measured to evaluate the deep learning algorithm’s diagnostic performance.Results : In ResNet-152, the average precision for intersection over union (IOU) 0.1, 0.3, and 0.5, were 0.7240, 0.6698, and 0.3687, respectively. When the intersection over union (IOU) and confidence threshold were 0.1, the precision was 0.7292, and the recall was 0.7650. When the IOU threshold was 0.1, and the confidence threshold was 0.6, the true and false rates were 82.9% and 17.1%, respectively. There were significant differences in the true/false and false-positive/false-negative ratios between the anteriorposterior, towne, and both lateral views (p=0.032 and p=0.003). Objects detected in false positives had vascular grooves and suture lines. In false negatives, the detection performance of the diastatic fractures, fractures crossing the suture line, and fractures around the vascular grooves and orbit was poor.Conclusion : The object detection algorithm applied with deep learning is expected to be a valuable tool in diagnosing skull fractures."
A Defect Detection Algorithm of Denim Fabric Based on Cascading Feature Extraction Architecture,2023,"['Cascading Feature Extraction Architecture', 'Denim Defect Detection', 'ImageNet', 'Robustness', 'Transfer Learning']",,"Defect detection is one of the key factors in fabric quality control. To improve the speed and accuracy of denimfabric defect detection, this paper proposes a defect detection algorithm based on cascading feature extractionarchitecture. Firstly, this paper extracts these weight parameters of the pre-trained VGG16 model on the largedataset ImageNet and uses its portability to train the defect detection classifier and the defect recognitionclassifier respectively. Secondly, retraining and adjusting partial weight parameters of the convolution layerwere retrained and adjusted from of these two training models on the high-definition fabric defect dataset. Thelast step is merging these two models to get the defect detection algorithm based on cascading architecture.Then there are two comparative experiments between this improved defect detection algorithm and otherfeature extraction methods, such as VGG16, ResNet-50, and Xception. The results of experiments show thatthe defect detection accuracy of this defect detection algorithm can reach 94.3% and the speed is also increasedby 1–3 percentage points."
데이터 증강을 위한 클래스 활성화 맵  기반 Random Erasing,2023,"['Data Augmentation', 'Class Activation Map', 'Random Erasing', 'CNN', 'Generalization']",,"Random erasing offers various levels of occlusion for data augmentation. However, due to its uniform distribution of random selection, it sometimes occludes regions that are unrelated to the object of interest. In this paper, we propose a novel method that utilizes Gradient Weighted Class Activation Mapping (Grad-CAM) for estimating the location of the object of interest and selectively erasing the surrounding areas. By utilizing Grad-CAM, we improve random erasing for CNN models without requiring additional modules or architectural changes. We generate Grad-CAM after the intermediate epochs where CNN models have sufficient representational power for the training data. The hyperparameter that restrict the erasing to the vicinity of the object is set based on Grad-CAM, and experiments were conducted accordingly. As a result of our experiments, we observed a 0.33% decrease in error-rate for image classification tasks using ResNet-20 on the CIFAR-10 dataset."
Determination of the stage and grade  of periodontitis according to the  current classification of periodontal  and peri-implant diseases and  conditions (2018) using machine  learning algorithms,2023,"['Classification', 'Deep learning', 'Machine learning', 'Periodontitis']",,"Purpose: The current Classification of Periodontal and Peri-Implant Diseases and Conditions, published and disseminated in 2018, involves some difficulties and causes diagnostic conflicts due to its criteria, especially for inexperienced clinicians. The aim of this study was to design a decision system based on machine learning algorithms by using clinical measurements and radiographic images in order to determine and facilitate the staging and grading of periodontitis.Methods: In the first part of this study, machine learning models were created using the Python programming language based on clinical data from 144 individuals who presented to the Department of Periodontology, Faculty of Dentistry, Süleyman Demirel University. In the second part, panoramic radiographic images were processed and classification was carried out with deep learning algorithms.Results: Using clinical data, the accuracy of staging with the tree algorithm reached 97.2%, while the random forest and k-nearest neighbor algorithms reached 98.6% accuracy. The best staging accuracy for processing panoramic radiographic images was provided by a hybrid network model algorithm combining the proposed ResNet50 architecture and the support vector machine algorithm. For this, the images were preprocessed, and high success was obtained, with a classification accuracy of 88.2% for staging. However, in general, it was observed that the radiographic images provided a low level of success, in terms of accuracy, for modeling the grading of periodontitis.Conclusions: The machine learning-based decision system presented herein can facilitate periodontal diagnoses despite its current limitations. Further studies are planned to optimize the algorithm and improve the results."
딥러닝을 이용한 농경지 팜맵 판독 적용 방안,2023,"['Deep Learning', 'Agricultural Land', 'FarmMap', 'Aviation Image', '딥러닝', '농경지', '팜맵', '항공영상']",,"The Ministry of Agriculture, Food and Rural Affairs established the FarmMap, an digital map of agricultural land. In this study, using deep learning, we suggest the application of farm map reading to farmland such as paddy fields, fields, ginseng, fruit trees, facilities, and uncultivated land. The farm map is used as spatial information for planting status and drone operation by digitizing agricultural land in the real world using aerial and satellite images. A reading manual has been prepared and updated every year by demarcating the boundaries of agricultural land and reading the attributes. Human reading of agricultural land differs depending on reading ability and experience, and reading errors are difficult to verify in reality because of budget limitations. The farmmap has location information and class information of the corresponding object in the image of 5 types of farmland properties, so the suitable AI technique was tested with ResNet50, an instance segmentation model. The results of attribute reading of agricultural land using deep learning and attribute reading by humans were compared. If technology is developed by focusing on attribute reading that shows different results in the future, it is expected that it will play a big role in reducing attribute errors and improving the accuracy of digital map of agricultural land."
CNN 기반 딥러닝 모델을 통한 폐암 컴퓨터 보조 진단 시스템 개발,2023,"['CADx', 'Cancer Diagnosis', 'Classification', 'Convolution Neural Network', 'Deep learning', 'Lung cancer', 'Malignant Tumor']",,"Lung cancer ranked second in Korea domestic cancer incidence in 2020 and second in death rate. Lung cancer often has no early symptoms, so patients often miss the time of treatment. Accordingly, in Korea, lung cancer has been included in the national cancer screening since 2019. However, among misdiagnosis cases, lung cancer had the highest misdiagnosis rate, and the accuracy of screening may vary depending on the medical specialist's skill level and fatigue. Accordingly, this paper proposed a lung cancer CADx(Computer-Aided Diagnosis) system based on EfficientNetV2-L and ConvNeXt-B. EfficientNetV2 is a model that can have high classification performance with a small number of parameters using the Training-Aware NAS (Neural Architecture Search) method. ConvNeXt is a network that achieves higher performance than ViT(Vision Transformer) by combining the latest techniques with ResNet-50 as a base model. Medical imaging generally suffers from a data shortage problem. Therefore, we augmented the lung cancer dataset using AutoAugment using the ImageNet augmentation policy. Through this method, the sensitivity in classifying malignant(lung cancer) and normal improved from 0.8354 to 0.9638 in EfficientNetV2 and from 0.9796 to 0.9963 in ConvNeXt.AUC (Area Under the ROC Curve) also improved from 0.9967 to 0.9974 for EfficientNetV2 and from 0.9973 to 1.0000 for ConvNeXt. Additionally, noise that may generally occur in CT images was added and compared through Gaussian noise.EfficientNetV2's Sensitivity was 0.7417 in the original model and 0.8954 in the model to which AutoAugment was applied, representing a decrease of 9.37% and 6.84%, respectively. In contrast, ConvNeXt exhibited a Sensitivity of 0.9796 in the original model and 0.9963 in the model to which AutoAugment was applied, showing no decrease in performance. This led to the development of a CADx system that demonstrates excellent performance."
저비용 비전 시스템과 의미론적 이미지분할을 이용한 포장 패치 자동  탐지 시스템,2023,"['Pavement patch detection', 'U-net', 'Automated pavement monitoring system', 'Inverse perspective mapping']",,"Local road management agencies, which require frequent road surface inspections to maintain a safe driving environment, face difficulties in manually assessing road conditions. Moreover, stopping on the shoulder of a high-speed highway to inspect the road surface is extremely dangerous for inspectors. To overcome these challenges, there have been many efforts to automate road surface image acquisition, assessment, and analysis. However, existing methods mainly focus on detecting damage such as potholes and cracks, and have limitations in monitoring the condition of road surfaces, such as the need for repairs or the status of maintenance. This study proposed an automatic pavement patch detection method incorporating image processing and deep neural network image segmentation to provide a global view of the road surface. The panoramic image of the road is obtained by converting the video images captured by the omnidirectional camera of vehicles into top-view images using inverse perspective and affixing the images together. Next, the U-Net-architecture-based deep neural network image segmentation technique is applied to detect patches. Testing using actual highway driving videos revealed performances of 0.827 and 0.821 in the U-Net model based on ResNet152 and EfficientNetb7 backbones."
CenterNet Based on Diagonal Half-length and Center Angle Regression for Object Detection,2023,"['Object detection', 'CenterNet', 'Prediction stability', 'Accuracy consistency', 'Convergence speed']",,"CenterNet, a novel object detection algorithm without anchor based on key points, regards the object as a single center point for prediction and directly regresses the object’s height and width. However, because the objects have different sizes, directly regressing their height and width will make the model difficult to converge and lose the intrinsic relationship between object’s width and height, thereby reducing the stability of the model and the consistency of prediction accuracy. For this problem, we proposed an algorithm based on the regression of the diagonal half-length and the center angle, which significantly compresses the solution space of the regression components and enhances the intrinsic relationship between the decoded components. First, encode the object’s width and height into the diagonal half-length and the center angle, where the center angle is the angle between the diagonal and the vertical centreline. Secondly, the predicted diagonal half-length and center angle are decoded into two length components. Finally, the position of the object bounding box can be accurately obtained by combining the corresponding center point coordinates. Experiments show that, when using CenterNet as the improved baseline and resnet50 as the Backbone, the improved model achieved 81.6% and 79.7% mAP on the VOC 2007 and 2012 test sets, respectively. When using Hourglass-104 as the Backbone, the improved model achieved 43.3% mAP on the COCO 2017 test sets. Compared with CenterNet, the improved model has a faster convergence rate and significantly improved the stability and prediction accuracy."
딥러닝을 이용한 음식 이미지 분류 기술 개발,2023,"['Deep Learning', 'ResNet', 'Food Image Classification', '딥러닝', 'ResNet', '음식 이미지 분류']","본 연구는 20대와 한국인을 대상으로 한 건강관리 애플리케이션의 음식 이미지 분류 모델을 개선하는 것을 목표로 진행되었다. AI Hub에서 546,194개의 이미지를 수집하여 175개의 음식 클래스를 구성하였으며, ResNet 인공지능 모델을 학습하고 검증하였다. 추가적으로, 실제 촬영한 음식 이미지에 대한 인식 정확도가 상대적으로 낮게 나타나는 원인에 대해 고찰하고, 이를 해결하기 위한 방안으로 모델 성능을 최적화를 위한 다양한 방법을 분석하였다.","This study was conducted with the aim of improving the food image classification model of a health care application targeting Koreans in their twenties. 546,194 images were collected from the Public Data Portal and AI Hub, and 175 food classes were constructed. The ResNet artificial intelligence model was trained and validated. Additionally, we deeply investigated the reasons for the relatively lower recognition accuracy of the actual food images, and we attempted various methods to optimize the model’s performance as a solution."
Medical Diagonosis System Using AI Evolution Algorithms - CNN Based Chest X-ray Classification -,2023,"['Medical diagnosis', 'CNN', 'ResNet', 'Pneumonia', 'Transfer learning', 'Chest x-ray']",,"The application of artificial intelligence techniques, specifically evolution algorithms in medical diagnosis has shown promising potential to enhance the accuracy and efficiency of disease identification. These days the trend is evolutional algorithms be on the turn CNN((Conversion Neural Network) algorithms. As a result of that this paper research applied to medical devices using CNN technology is being actively carried out around the world. In this study, chest x-ray image classification is performed using CNN-based ResNet as a medical image reading assistance technology. In this study, we will classify pneumonia. A total of 5,863 x-ray images are used, and the data is divided into pneumonia and normal, and consists of 3,875 pneumonia image data and 1,341 normal image data. Shortcut is connected to a cnn composed of convolutional layers, pooling layers, and fully connected layers to improve performance using fine tuning on CNN-ResNet, which has been learned to minimize residual. In this paper, only the use of the pre-learning model was considered as fine tuning, but the batch size and learning rate also affect the learning of the model. It is expected that further research to find the appropriate proportions will allow the performance of the model to be maintained more stable."
Comparative Analysis of Swin Transformer and Residual Neural Network for Pneumonia Classification,2023,"['Swin Transformer', 'ResNet', '딥러닝 모델', '폐렴 감지', '흉부 엑스레이', 'Swin Transformer', 'ResNet', 'Deep learning models', 'Pneumonia detection', 'Chest X-ray']",,"PPneumonia is a respiratory infectious disease that causes fluids to fill the lungs. It is considered one of the leading causes of infection-related deaths in children and seniors worldwide. Clinicians usually use chest X-ray images to diagnose pneumonia. However, pneumonia is prone to be misdiagnosed because it overlaps with cold and flu, causing severe and critical medical complications. Consequently, alternative supportive diagnostic methods are needed to minimize human errors and assist clinicians. Several attempts have used artificial intelligence systems, mainly in deep learning methods, to assist clinicians in early pneumonia diagnoses. However, further studies are required to consolidate the use of deep learning as an assistant tool to diagnose pneumonia accurately. In this study, we examine the Swin Transformer and the Residual Neural Network’s performance in classifying pneumonia and healthy chest X-ray images using the Guangzhou Women and Children’s Medical Center dataset and the COVID19, Pneumonia and Normal Chest X-ray Posteroanterior dataset. The experiment results demonstrate that the Swin Transformer achieves an accuracy of 98.9% in the Chest X-ray images dataset and 92.35% in the COVID19, Pneumonia and Normal Chest X-ray Posteroanterior dataset, while the Residual Neural Network achieves an accuracy of 97.9% and 88.8% respectively in classifying pneumonia. These results indicate that the Swin Transformer outperforms the Residual Neural Network as a tool for assisting clinicians in diagnosing pneumonia. Thus, the Swin Transformer may help in early decision-making, leading to treatment initiation and improving patient's health."
A Study on the Development of Deep Learning Algorithm for Determining External Quality of Welded Parts Using Transfer Learning,2023,"['Weld quality', 'Weld appearance', 'Deep learning', 'CNN (Convolution Neural Network)', 'ResNet']",,"Recently, deep learning has been applied to various welding techniques, such as laser welding, gas metal arc welding (GMAW), and resistance spot welding, and research on automation and quality prediction is being conducted.Even for GMAW, many researchers have attempted to predict quality through X-ray, current, and voltage measurements. If judgment in real time is not necessary, it is most effective to judge the quality of a welded part using an exterior image. Therefore, in this study, a welded appearance quality judgment model was analyzed using image deep learning. Welding defects were classified into pores, overlaps, craters, melting of the base material, cracks, and undercuts, and were divided into 7 categories including normal ones. In constructing the deep-learning model, transfer learning was performed using existing networks, such as ResNet and AlexNet. To improve the accuracy of deep learning, tests were performed while the optimization technique, maximum number of epochs, and minibatch size were changed. It was confirmed that the accuracy of weld defect prediction improved as the minibatch size increased, and the stochastic gradient descent model had the highest accuracy. Increasing the number of data for learning should make the technique of using images to judge the quality of GMAW welds using the proposed model more widely applicable."
Research on Damage Identification of Buried Pipeline Based on Fiber Optic Vibration Signal,2023,"['Distributed fiber optic vibration sensing', 'Pattern recognition', 'Residual network']",,"Pipelines play an important role in urban water supply and drainage, oil and gas transmission, etc.This paper presents a technique for pattern recognition of fiber optic vibration signals collected by a distributed vibration sensing (DVS) system using a deep learning residual network (ResNet). The optical fiber is laid on the pipeline, and the signal is collected by the DVS system and converted into a 64 × 64 single-channel grayscale image. The grayscale image is input into the ResNet to extract features, and finally the K-nearest-neighbors (KNN) algorithm is used to achieve the classification and recognition of pipeline damage."
다중모드 특징융합 기반 배관계 누출판별 앙상블 모델 연구,2023,"['deep learning', 'multi-mode feature fusion', 'ensemble', 'pipe leak detection', 'weight redistribution', '.']","본 논문은 플랜트 배관계의 노후화 문제로 인해 발생하는 미세 누출을 탐지하기 위한 다중모드 특징융합을 이용한 가중치 재분배 앙상블 모델을 제안한다. 수집된 데이터는 2D 주파수 패턴 특징과 2D RMS 패턴 특징으로 변환되었으며, 여러 센서에서 추출된 다양한 도메인 특징들이 서로 결합되어 볼륨 특징으로 구성하였다. 실험을 위해 ResNet 기반의 단일 모델을 설계하여 다양한 볼륨 특징들을 이용한 앙상블 구조를 조합하였다. 또한, 다수의 예측 모델을 결합하는 과정에서 발생할 수 있는 성능 불균형 문제를 해결하기 위해, 소프트맥스 함수를 기반으로 한 가중치 재분배를 적용하였다. 실험 결과, 주파수 및 RMS 볼륨 특징을 활용한 센서별 앙상블 모델이 98.91%라는 가장 높은 분류 정확도를 제공하는 것을 실험적으로 관찰할 수 있었다.","This paper proposes a weight redistribution ensemble model using multi-mode feature fusion for detecting micro leaks arising from aging problems in the power plant piping systems. The collected data was transformed into 2D frequency and RMS pattern features, and various domain features extracted from multiple sensors were combined to form volume features. For the experiment, a single model based on ResNet was designed, and an ensemble structure using various volume features was composed. Additionally, in order to resolve the performance imbalance problem that could arise in the process of combining multiple predictive models, we applied a softmax function-based weight redistribution. Experimental results showed that the ensemble model for each sensor, using frequency and RMS volume features, provided the highest classification accuracy of 98.91%."
이미지 인식 기반 국내 자생종 소나무 종 분류,2023,"['Pine Tree', 'Image Classification', 'CNN', 'Data Labeling', 'Feature Importance']","국내 소나무과 나무는 국내 자생 침엽수의 절반을 차지할 만큼 종 다양성이 가장 높다. 소나무가 국내 산림의 60% 이상을 차지한 적도 있었지만, 현재는 재선충, 산불 등으로 그 비율이 25%로 감소하였다. 국내 자생종 소나무의 종 분류를 위해 국립생물자원관에서 보유 중인 표준 이미지 데이터셋을 사용하여 3종의 소나무를 분류하였다. 또한, 성능이 검증된 ResNet 50과 같은 사전 학습모델을 변형하는 대신 이미지 인식 모델을 직접 구현하여 종 분류를 진행 85%의 정확도를 나타내었고, 이후, 인식 과정에서 도출되는 특징들을 판별하였다. 이미지 크기 및 증식이 분류에 미치는 영향을 파악하고자 이미지 크기 및 이미지 증식을 통한 성능 평가를 수행 이미지 크기는 약 3% 그리고 이미지 증식의 경우는 약 6.4% 성능 향상을 가져왔다. 또한, 데이터 레이블링 방식의 기계학습 모델과도 분류 성능을 비교 정리하였다. 이미지 인식 과정에서 종 분류에 가중치가 높게 반영된 특징을 추출하였으며, 이를 레이블링 기법에 사용된 특징 중요도와 비교, 레이블링 기법과 이미지 인식 기반에서 종 분류에 가장 유효하게 나타난 특징은 유사한 것으로 나타났다.","Pine trees in Korea are the tree species with the highest diversity, accounting for half of the native coniferous trees. Pine trees once accounted for more than 60% of the nations forests, but the proportion has decreased to 25% due to infestations and wildfires. To classify Koreas native pine trees, we use the standard image dataset held by the National Institute of Biological Resources to classify three species. Instead of modifying a pre-trained model like ResNet 50, which has been proven to perform well, we instead directly implement an image recognition model to perform species classification, which showed an accuracy of 85%, and then determined the features derived from the recognition process. To understand the impact of image size and growth on classification, we evaluated performance of the model through image size and image growth. The performance improvement was about 3% for image size and 6.4% for image growth. We also compare its performance with a machine learning model based on data labeling. We extract the most weighted features for species classification from the image recognition process and compare them with feature importance used in the labeling method, finding that the most effective features for species classification in the labeling method and image recognition are similar."
모델 내부/외부 특징량 상관 학습을 통한 지식 증류,2023,"['Knowledge distillation', 'model compression', 'transformer', 'correlation learning', 'Image classification', '지식 증류', '모델 압축', '트랜스포머', '상관관계 학습', '이미지 분류']","본 논문에서는 이종 모델의 특징맵 간 상관관계인 외부적 상관관계와 동종 모델 내부 특징맵 간 상관관계인 내부적 상관관계를 활용하여 교사 모델로부터 학생 모델로 지식을 전이하는 Internal/External Knowledge Distillation (IEKD)를 제안한다. 두 상관관계를 모두 활용하기 위하여 특징맵을 시퀀스 형태로 변환하고, 트랜스포머를 통해 내부적/외부적 상관관계를 고려하여 지식 증류에 적합한 새로운 특징맵을 추출한다. 추출된 특징맵을 증류함으로써 내부적 상관관계와 외부적 상관관계를 함께 학습할 수 있다. 또한 추출된 특징맵을 활용하여 feature matching을 수행함으로써 학생 모델의 정확도 향상을 도모한다. 제안한 지식 증류 방법의 효과를 증명하기 위해, CIFAR-100 데이터 셋에서 “ResNet-32×4/VGG-8” 교사/학생 모델 조합으로 최신 지식 증류 방법보다 향상된 76.23% Top-1 이미지 분류 정확도를 달성하였다.","In this paper, we propose an Internal/External Knowledge Distillation (IEKD), which utilizes both external correlations between feature maps of heterogeneous models and internal correlations between feature maps of the same model for transferring knowledge from a teacher model to a student model. To achieve this, we transform feature maps into a sequence format and extract new feature maps suitable for knowledge distillation by considering internal and external correlations through a transformer. We can learn both internal and external correlations by distilling the extracted feature maps and improve the accuracy of the student model by utilizing the extracted feature maps with feature matching. To demonstrate the effectiveness of our proposed knowledge distillation method, we achieved 76.23% Top-1 image classification accuracy on the CIFAR-100 dataset with the “ResNet-32×4/VGG-8” teacher and student combination and outperformed the state-of-the-art KD methods."
열화상 영상을 활용한 CNN-Transformer 네트워크의 공장 설비 이상 진단 방법,2023,"['CNN', 'Transformer', 'Thermal imaging', 'Abnormality diagnosis', 'Factory facility']","본 논문에서는 열화상 영상을 이용한 공장 설비 이상 진단에 최적화된 딥러닝 알고리즘을 제안한다. 이를 위하여 대조도 향상 알고리즘으로 열화상 영상의 대조도를 명확하게 변환하여 가장자리 정보를 강화하여 준다. 그 후에 Convolution Neural Network(CNN)와 Transformer Network 각각의 장점만을 이용하여 개발된 CvT(Convolutional vision Transformer)를 열화상 영상 기반의 고장 설비 이상 진단에 적합하게 수정한 modified CvT 개발을 통하여 공장 설비의 이상을 진단한다. AI Hub에서 제공되는 열화상 영상 중에서 공장 설비의 정상 및 이상 영상들을 추출하여 실험을 진행하였으며, 이를 통하여 기존 컴퓨터 비전 분야에서 보편적으로 사용되고 있는 CNN 기반의 ResNet, EfficientNet 그리고 Transformer 기반의 ViT(Vision Transformer), SwinT(Swin Transformer)보다 높은 정확도인 98.79%의 우수한 성능을 확인하였다. 결론적으로 CNN과 Transformer 융합 네트워크를 활용하였을 때 다른 열화상 영상을 이용한 공장 설비 이상 진단 알고리즘보다 우수한 성능을 보여준다는 것을 확인하였다.","In this paper, we propose a deep learning algorithm optimized for diagnosing factory facility abnormalities using thermal imaging. For this purpose, the contrast of the thermal image is clearly converted with the contrast enhancement algorithm to enhance the edge information. After that, the Convolution Vision Transformer (CvT) developed using only the advantages of Convolution Neural Network (CNN) and Transformer Network is modified to suit the diagnosis of thermal image-based failure facility abnormalities. Experiments were conducted by extracting normal and abnormal images of factory facilities from the thermal image provided by AI Hub. Through this, we confirmed the excellent performance of 98.79% which is higher accuracy than CNN-based ResNet, EfficientNet, and Transformer-based Vision Transformer (ViT), SwinT (Swin Transformer), which are commonly used in the existing computer vision field. In conclusion, it was confirmed that when using the CNN and Transformer fusion network, it shows better performance than the factory facility failure diagnosis algorithm using other thermal imaging images."
수경재배 환경에서 머신러닝 기반 불량 모종 진단을 위한 증강 데이터 활용 연구,2023,"['hydroponic conditions', 'anti-caner leaf lettuce', 'machine learning', 'deep learning', 'data augmentation', '.']",,"The need for big data analysis and artificial intelligence for smart agriculture is continuously requested. It is essential to collect and label large amounts of quality data for artificial intelligence research, but there is a relative lack of data in the hydroponic cultivation area. In this paper the performance of growth diagnostic ML model with original anti-cancer leaf lettuce data set was checked. Then ML model development and model performance improvement experiment was proceeded with augmented data. First, ML model learning and testing was conducted using DCGAN data only. As a result, the accuracy of ResNet was 61.2, DenseNet was 62.4. And model performance improvement experiment was proceeded by adding augmented data to the original data. As a result, the accuracy of ResNet increase from 86.5 to 88.2 and DenseNet from 92.9 to 94.7. In these experiments the possibility of using augmented data and its influence are studied for developing and improving the performance of diagnostic ML model."
학습 데이터가 없는 모델 탈취 방법에 대한 분석,2023,[],"딥뉴럴네트워크 모델의 취약점으로 모델 탈취 방법이 있다. 이 방법은 대상 모델에 대하여 여러번의 반복된 쿼리를 통해서 유사 모델을 생성하여 대상 모델의 예측값과 동일하게 내는 유사 모델을 생성하는 것이다. 본 연구에서, 학습 데이터가 없이 대상 모델을 탈취하는 방법에 대해서 분석을 하였다. 생성 모델을 이용하여 입력 데이터를 생성하고 대상 모델과 유사 모델의 예측값이 서로 가까워지도록 손실함수를 정의하여 유사 모델을 생성한다. 이 방법에서 대상 모델의 입력 데이터에 대한 각 클래스의 logit(로직) 값을 이용하여 경사하강법으로 유사 모델이 그것과 유사하도록 학습하는 과정을 갖는다. 실험 환경으로 pytorch 머신러닝 라이브러리를 이용하였으며, 데이터셋으로 CIFAR10과 SVHN을 사용하였다. 대상 모델로 ResNet 모델을 이용하였다. 실험 결과로써, 모델 탈취방법은 CIFAR10에 대해서 86.18%이고 SVHN에 대해서 96.02% 정확도로 대상 모델과 유사한 예측값을 내는 유사 모델을 생성하는 것을 볼 수가 있었다. 추가적으로 모델 탈취 방법에 대한 고려사항와 한계점에 대한 고찰도 분석하였다.","In this study, we analyzed how to steal the target model without training data. Input data is generated using the generative model, and a similar model is created by defining a loss function so that the predicted values of the target model and the similar model are close to each other. At this time, the target model has a process of learning so that the similar model is similar to it by gradient descent using the logit (logic) value of each class for the input data. The tensorflow machine learning library was used as an experimental environment, and CIFAR10 and SVHN were used as datasets. A similar model was created using the ResNet model as a target model. As a result of the experiment, it was found that the model stealing method generated a similar model with an accuracy of 86.18% for CIFAR10 and 96.02% for SVHN, producing similar predicted values to the target model. In addition, considerations on the model stealing method, military use, and limitations were also analyzed."
Indoor Environment Drone Detection through DBSCAN and Deep Learning,2023,"['DBSCAN', 'Deep learning', 'FMCW radar', 'Object detection', 'UAV']",,"In an era marked by the increasing use of drones and the growing demand for indoor surveillance, the development of a robust application for detecting and tracking both drones and humans within indoor spaces becomes imperative. This study presents an innovative application that uses FMCW radar to detect human and drone motions from the cloud point. At the outset, the DBSCAN (Density-based Spatial Clustering of Applications with Noise) algorithm is utilized to categorize cloud points into distinct groups, each representing the objects present in the tracking area. Notably, this algorithm demonstrates remarkable efficiency, particularly in clustering drone point clouds, achieving an impressive accuracy of up to 92.8%. Subsequently, the clusters are discerned and classified into either humans or drones by employing a deep learning model. A trio of models, including Deep Neural Network (DNN), Residual Network (ResNet), and Long Short-Term Memory (LSTM), are applied, and the outcomes reveal that the ResNet model achieves the highest accuracy. It attains an impressive 98.62% accuracy for identifying drone clusters and a noteworthy 96.75% accuracy for human clusters."
합성곱 신경 회로망 모델을 활용한 흑색종 피부암 진단,2023,"['피부암', '흑색종', 'Skin Cancer', 'Melanoma', 'VGG-16', 'ResNet 50', 'DenseNet 121', 'Inception V3', 'WideResnet50']",,
합리적 가격결정을 위한 전이학습모델기반 아보카도 분류 및 출하 예측 시스템,2023,"['딥러닝', '전이 학습', 'Deep Learning', 'Transfer Learning', 'ImageNet', 'VGG16', 'ResNet', 'DenseNet']","타임지가 선정한 슈퍼푸드이며, 후숙 과일 중 하나인 아보카도는 현지가격과 국내 유통 가격이 크게 차이가 나는 식품 중 하나이다. 이러한 아보카도의 분류과정을 자동화한다면 다양한 분야에서 인건비를 줄여 가격을 낮출 수 있을 것이다. 본 논문에서는 아보카도의 데이터셋을 크롤링을 통하여 제작하고, 딥러닝 기반 전이학습모델을 다수 사용하여, 최적의 분류모델을 만드는 것을 목표로 한다. 실험은 제작한 데이터셋에서 분리한 데이터셋에서 딥러닝 기반 전이학습모델에 직접 대입하고, 해당 모델의 하이퍼 파라미터를 Fine-tuning하며 진행하였다. 제작된 모델은 아보카도의 이미지를 입력하였을 때, 해당 아보카도의 익은 정도를 99% 이상의 정확도로 분류하였으며, 아보카도 생산 및 유통가정의 인력감소 및 정확성을 높일 수 있는 데이터셋 및 알고리즘을 제안한다.","Avocado, a superfood selected by Time magazine and one of the late ripening fruits, is one of the foods with a big difference between local prices and domestic distribution prices. If this sorting process of avocados is automated, it will be possible to lower prices by reducing labor costs in various fields. In this paper, we aim to create an optimal classification model by creating an avocado dataset through crawling and using a number of deep learning-based transfer learning models. Experiments were conducted by directly substituting a deep learning-based transfer learning model from a dataset separated from the produced dataset and fine-tuning the hyperparameters of the model. When an avocado image is input, the model classifies the ripeness of the avocado with an accuracy of over 99%, and proposes a dataset and algorithm that can reduce manpower and increase accuracy in avocado production and distribution households."
기술 분석과 환경요소를 이용한 주가 예측률 향상을 위한 딥러닝 병렬 모델,2023,"['stock forecast', 'deep neural network', 'parallel model', '1D-CNN', 'ResNet', '.']","본 연구는 주가 데이터, 기술 분석 데이터, 환경요소 데이터를 이용하여, 주가예측을 위한 딥러닝 병렬 모델을 제안하였다. 예측을 위한 데이터 셋은 3개로 나누었으며, 데이터 셋 1은 시가, 고가, 저가, 종가, 거래량이며, 데이터 셋 2는 기술 분석 데이터를 추가하였으며, 데이터 셋 3은 주가에 영향을 줄 수 있는 환율, 전산업생산지수를 추가하였다. 딥러닝 모델은 기본 모델로서 DNN, LSTM, 1D-CNN 모델과 병렬 모델로서 DNN 모델을 기본으로 1D-CNN을 병합한 DCNN 모델과 LSTM을 병합한 DLSTM 모델을 제안하였다. 실험 결과, DNN과 CNN 보다는 LSTM과 BiLSTM 모델의 성능이 높았으며, 특히 병렬모델인 DLSTM 모델이 가장 성능이 좋았다. 병렬 모델인 DLSTM 모델에 대한 데이터 셋 1의 RMSE는 0.0091, 데이터 셋 2의 RMSE는 0.0080, 데이터 셋 3의 RMSE는 0.0071로서 모든 데이터가 합쳐진 데이터 셋 3의 성능이 가장 좋았다.","This study proposed a deep learning parallel model for stock price prediction using stock price data, technical analysis data, and environmental factor data. The data set for prediction was divided into three, data set 1 is the opening price, high price, low price, closing price, and trading volume, data set 2 added technical analysis data, and data set 3 is the exchange rate that can affect the stock price. the overall industrial production index was added. The deep learning model proposed DNN, LSTM, and 1D-CNN models as basic models, and a DCNN model that merged 1D-CNN based on the DNN model as a parallel model, and a DLSTM model that merged LSTM as a parallel model. As a result of the experiment, the performance of LSTM and BiLSTM models was higher than that of DNN and CNN, and in particular, the DLSTM model, a parallel model, performed the best. For the DLSTM model, which is a parallel model, the RMSE of data set 1 was 0.0091, the RMSE of data set 2 was 0.0080, and the RMSE of data set 3 was 0.0071. Data set 3, which combined all data, had the best performance."
기상 요소 데이터를 이용한 단기 강수량예측 향상을 위한 딥러닝 병렬 모델,2023,"['precipitation forecast', 'deep neural network', 'parallel model', '1D-CNN', 'ResNet', '.']","강수량예측은 누적 강수량보다는 짧은 시간에 얼마나 많은 비가 집중적으로 내렸는지 알려주는 시간당 강수량에 따라서 피해 정도가 달라진다. 본 연구는 딥러닝 기본모델인 DNN, LSTM, BiLSTM, 1D-CNN 모델과 성능 향상을 위해 기본모델을 병합한 병렬 구조를 이용하여 단기 강수예측을 하였다. 병렬모델은 DNN 모델과 1D-CNN을 병합한 DCNN과 DNN 모델과 LSTM을 병합한 DLSTM 모델이다. 데이터셋은 강수일 만을 구축한 데이터셋, 6월부터 9월까지의 데이터셋, 5월부터 10월끼지의 데이터셋 등 3개의 데이터셋을 이용하였으며, 각 데이터셋에 대해서 세부적으로 7개의 데이터셋으로 구분하여, 총 21개의 데이터셋에 대하여 강수량을 예측하고 비교 평가하였다. 실험 결과, 세 번째 데이터셋이 가장 예측 결과가 좋았다. 특히, 5 번째 세부 데이터셋인 DLSTM 병렬 모델의 RMSE가 0.25로서, 다른 모델보다 10배 정도 월등히 예측 결과가 좋았다.","In precipitation forecasting, the degree of damage varies according to the amount of precipitation per hour, which tells how much rain has fallen intensively in a short period of time, rather than the cumulative amount of precipitation. In this study, short-term precipitation prediction was performed using deep learning basic models such as DNN, LSTM, BiLSTM, and 1D-CNN models and a parallel structure merging the basic models to improve performance. Parallel models include DCNN, which combines DNN and 1D-CNN, and DLSTM, which combines DNN and LSTM. As for the data set, three data sets were used: a data set built with only rainy days, a data set from June to September, and a data set from May to October. Each data set was divided into seven data sets in detail. The precipitation was predicted and compared for a total of 21 data sets. As a result of the experiment, the third data set had the best prediction results. In particular, the RMSE of the 5th detailed data set, the DLSTM   parallel model, was 0.25, which was about 10 times better than other models."
차량 단말기 기반 돌발상황 검지 알고리즘 개발,2023,"['Highway', 'Emergency situations', 'Detection', 'Scene classification', 'Artificial intelligence', 'Vehicle terminal', '고속도로', '돌발상황', '검지', '상황분류', '인공지능', '차량단말기']","전방 낙하물과 같은 돌발상황이 발생했을 때 신속하고 적절한 정보 제공은 도로 위 이용자들의 편의를 가져다주고 2차 교통사고 또한 효과적으로 줄일 수 있다. 도로 상의 돌발상황은현재 국내에서 루프 검지기나 CCTV 등 ITS 기반 검지 체계를 사용하여 주로 검지하고 있다. 이러한 방식은 검지기의 검지 구간에서의 도로 위 데이터만을 얻을 수 있다. 때문에, 기존 ITS 기반 검지체계의 공간적 음영구간에서 돌발상황을 찾아내기 위하여 새로운 검지 수단이 필요하다. 이에 본 연구에서는 차량 내 설치된 단말기에서 촬영된 영상으로부터 돌발상황을 검지및 분류하는 ResNet 기반 알고리즘을 제안한다. 국내 고속도로 전방 주행영상을 수집하였고, 돌발상황 유형을 클래스로 정의하여 각 데이터를 라벨링한 후, 제안한 알고리즘으로 데이터를학습시켰다. 학습 결과, 개발한 알고리즘은 데이터 수가 상대적으로 적었던 일부 클래스를 제외하고 정의한 돌발상황 클래스에 대하여 높은 검지율을 보였다.",
An Intercomparison of Deep‑Learning Methods for Super‑Resolution Bias‑Correction (SRBC) of Indian Summer Monsoon Rainfall (ISMR) Using CORDEX‑SA Simulations,2023,['Regional climate · Indian monsoon · Climate change · Deep learning'],,"The Indian Summer Monsoon Rainfall (ISMR) plays a significant role in India’s agriculture and economy. Our understandingof the climate dynamics of the Indian summer monsoon has been enriched with general circulation models (GCMs)and regional climate models (RCMs). Systematic bias associated with these numerical simulations, however, needs to becorrected before we can obtain accurate or reliable projections of the future. Therefore, this study applies two state-of-theartdeep-learning (DL)-based super-resolution bias correction (SRBC) methods, viz. Autoencoder-Decoder (ACDC) and adeeper network Residual Neural Network (ResNet) to perform spatial downscaling and bias-correction on high-resolutionCORDEX-SA climatic simulations of precipitation. To do so, we obtained eight meteorological variables from CORDEXSARCM simulations along with a digital elevation model at a spatial resolution of 0.25°×0.25° as input. Indian MonsoonData Assimilation and Analysis, precipitation reanalysis re-grided to 0.05°×0.05° spatial resolution is chosen as output forthe training period 1979–2005. To evaluate the DL algorithms, the RCP 2.6 scenario of CORDEX-SA future simulationsfor the period 2006–2020 is chosen. Moreover, we also conducted a performance assessment of the representation of mean,variability, extreme, and frequency of rainfall associated with ISMR. The results of the experiments show that the DL methodResNet a highly efficient in (i) improving the spatial resolution of the climatic simulations from 0.25°×0.25° to 0.05°×0.05°,(ii) reducing the systematic biases of the extreme rainfall of ISMR from 21.18 mm to -7.86 mm, and (iii) providing a robustbias-corrected climate simulation of ISMR for future climate mitigation and adaptation studies."
콘볼루션 신경망의 학습 성능 강화를 위한 그레디언트의 복합적 분석 및 활용 방법,2023,"['convolutional neural network', 'optimization', 'first-order optimization', 'gradient descent']",,"A convolutional neural network(CNN) is a deep neural network which is composed of many layers with convolution filters and sub-sampling operations. Because such complex structure of CNNs makes its effective train difficult, it is necessary to study more complicated and stable methods to train the CNNs than the existing ones. Therefore, in this paper, we introduce various methods utilizing gradients complicatedly and propose a new optimizer for CNNs, called CGAU-CNN, based on the methods. In the practical experiments, we trained two CNN models, i.e, ResNet and DenseNet, by utilizing CGAU-CNN and evaluated its image classification accuracy. As a result, we found that CGAU-CNN could train them with faster convergence and better accuracy than the existing optimizers such as Adam."
압축센싱 수신기를 이용한 무선 주파수 지문식별 시스템 구현,2023,"['compressed sensing', 'radio frequency fingerprint identification', 'convolutional neural network', '.']",,"The spectrum dominance strategy, which has recently been emphasized in the field of electronic warfare, requires pervasive spectrum awareness. However, the ability to continuously monitor all critical portions of the spectrum and identify specific threats, which is a key requirement for pervasive spectrum awareness, is still weak. In this paper, we implemented a radio frequency fingerprint identification system and presented the performance of two key functions for pervasive spectrum awareness. The implemented system applies a compressed sensing receiving technique that can simultaneously detect radio frequency signals existing in different frequency bands for continuous monitoring of the spectrum. To implement a specific emitter identification function, the 2-D ResNet model based on the convolutional neural network was converted into a 1-D model and applied to radio frequency signal identification."
딥러닝을 활용한 콘텐츠 내 텍스트 폰트  저작권 검출 모델 연구,2023,"['Deep-Learning', 'Hangul Font', 'Classification', 'Segmentation', 'Text Detection']",,"Despite the diverse forms and designs in which fonts are widely utilized in our daily lives, including videos, print materials, products, websites, and mobile sites, numerous copyright issues continue to arise. Despite efforts to address these concerns and take measures for improvement, a variety of issues persist. This research serves as a preliminary study to enhance this situation. The goal was to implement a detection model for fonts used in texts within challenging media such as images and videos, aiming to mitigate font copyright issues that arise across various mediums. As a preliminary step, a model for recognizing fonts used within videos, image, pdf was developed. The model consists of two primary components: a text detection and background removal model within images, and a font recognition model used within the text. The text detection model was refined through various approaches such as image processing and deep learning to identify the optimal model. For the font recognition model, comparisons were made between CNN and ResNet models to select the most suitable one. As a result, an integrated 2-stage model was constructed. Validation was performed using arbitrary video data, revealing a top-1 rate is 76% and a top-5 rate is 94%."
Cross‑domain health status assessment of three‑phase inverters using improved DANN,2023,"['Health status assessment', 'Transfer learning', 'Deep residual network', 'Domain adversarial neural network']",,"Information and large number of fault labels are required to achieve intelligent health status assessment of three-phase inverters. However, the current signals of inverters cannot be sufficiently collected since open-circuit faults (OCFs) occur briefly, which makes it difficult to determine the OCF mode of the various power switches. A transfer learning model that effectively uses a small amount of sample data to achieve domain adaptation is proposed to address this problem. First, collected fault-sensitive signals are subjected to a continuous wavelet transform (CWT) to obtain two-dimensional image data with more abundant fault feature information. Second, the source domain and target domain features are projected into the same feature space through a domain adversarial neural network (DANN) to achieve multi-domain feature extraction and adaptation. Then, in the feature extraction module of the DANN, the deep residual network (Resnet) structure is used to replace the typical convolutional neural network (CNN) structure. Finally, an intelligent diagnosis network is used to identify the health status of the inverter samples under variable conditions. Experimental results show that the proposed model can accurately and effectively realize the cross-domain health assessment of three-phase inverters in the case of small samples. The accuracy of the proposed model is better than that of other classical transfer learning models."
딥러닝 기반 의미론적 분할 기법을 통한 건물 자동추출 연구: 모델의 가중치 경중과 전이학습에 따른 정확도 변화 중심으로,2023,"['Semantic Segmentation', 'Building Detection', 'Weight of the Model', 'Transfer Learning', '의미론적 분할', '건물 탐지', '모델 가중치', '전이학습']",,"Building objects are an essential spatial information source that can be used in fields such as 3D modeling, urban expansion, and environmental analysis. They are one of the geographical features for which continuous information construction is essential but are not easy to construct automatically. As a solution to this problem, methods have been proposed to develop new heavy neural networks or utilize transfer learning, but there are still limitations. This study conducted an experiment to determine the models classification performance according to the weight and the possibility of using the transfer learning technique using ImageNet weights in remote sensing. For this purpose, AiHubs land cover map learning dataset was used, and U-Net and Deeplab V3+ classification models using MobileNet and ResNet as backbone neural networks were utilized. As a result of the experiment, the classification accuracy was found to be highest when transfer learning was not performed with the MobileNet-based U-Net model (f1-score: 0.8483). Additionally, visually, it was confirmed that the model learned from scratch rather than transfer learning depicted the building closer to the ground truth. This means that a variety of methods can be used to perform transfer learning without the need to limit the neural network, and it suggests that if there is an amount of data at the level provided by AiHub, a model with a certain level of classification accuracy can be created."
섬유 제조 장비 최적화를 위한 딥러닝 기반 결함 분류 시스템 구축,2023,"['딥러닝', '합성곱 신경망', '다중 클래스', '이미지 분류', '결함 검사', '섬유', 'Deep learning', 'CNN', 'Multi Class', 'Image classification', 'Defect inspection', 'Textile']",,"In this paper, we propose a process of increasing productivity by applying a deep learning-based defect detection and classification system to the prepreg fiber manufacturing process, which is in high demand in the field of producing composite materials. In order to apply it to toe prepreg manufacturing equipment that requires a solution due to the occurrence of a large amount of defects in various conditions, the optimal environment was first established by selecting cameras and lights necessary for defect detection and classification model production. In addition, data necessary for the production of multiple classification models were collected and labeled according to normal and defective conditions. The multi-classification model is made based on CNN and applies pre-learning models such as VGGNet, MobileNet, ResNet, etc. to compare performance and identify improvement directions with accuracy and loss graphs. Data augmentation and dropout techniques were applied to identify and improve overfitting problems as major problems. In order to evaluate the performance of the model, a performance evaluation was conducted using the confusion matrix as a performance indicator, and the performance of more than 99% was confirmed. In addition, it checks the classification results for images acquired in real time by applying them to the actual process to check whether the discrimination values are accurately derived."
An effective deep learning model for ship detection from satellite images,2023,['Maritime monitoring · Optical satellite imagery · CNN · Remote sensing · Marine traffic'],,"Detecting ships from satellite images is a challenging task in the domain of remote sensing. It is very important for security, traffic management and to avoid smuggling etc. SAR (Synthetic Aperture Radar) is mostly used technology for Maritime monitoring but now researchers are increasingly studying Optical Satellite Images based technologies. Image processing and Computer Vision techniques were previously used to detect ships. In this work, Convolutional Neural Network based approach is used to detect ships from the satellite imagery. Several Deep Learning models have been used and tested for this kind of task. We used state of art model Inception-Resnet that is pre trained on Image-Net dataset. We used the dataset ""Ships in Satellite Imagery"" to detect the presence of ships in an image. The dataset is publicly available on Kaggle.The results indicate adoption of transfer learning and data augmentation yields a successful detection of ships with an accuracy of more than 99%. Similarly, exploring different deep learning models for this task provide results with high accuracy for less training time."
"Related-key Neural Distinguisher on Block Ciphers SPECK-32/64, HIGHT and GOST",2023,"['Related-key Attack', 'Neural Cryptanalysis', 'Distinguisher', 'Deep Learning', 'Lightweight Block Ciphers']",,"With the rise of the Internet of Things, the security of such lightweight computing environments has become a hot topic. Lightweight block ciphers that can provide efficient performance and security by having a relatively simpler structure and smaller key and block sizes are drawing attention. Due to these characteristics, they can become a target for new attack techniques. One of the new cryptanalytic attacks that have been attracting interest is Neural cryptanalysis, which is a cryptanalytic technique based on neural networks. It showed interesting results with better results than the conventional cryptanalysis method without a great amount of time and cryptographic knowledge. The first work that showed good results was carried out by Aron Gohr in CRYPTO'19, the attack was conducted on the lightweight block cipher SPECK-/32/64 and showed better results than conventional differential cryptanalysis. In this paper, we first apply the Differential Neural Distinguisher proposed by Aron Gohr to the block ciphers HIGHT and GOST to test the applicability of the attack to ciphers with different structures. The performance of the Differential Neural Distinguisher is then analyzed by replacing the neural network attack model with five different models (Multi-Layer Perceptron, AlexNet, ResNext, SE-ResNet, SE-ResNext). We then propose a Related-key Neural Distinguisher and apply it to the SPECK-/32/64, HIGHT, and GOST block ciphers. The proposed Related-key Neural Distinguisher was constructed using the relationship between keys, and this made it possible to distinguish more rounds than the differential distinguisher."
