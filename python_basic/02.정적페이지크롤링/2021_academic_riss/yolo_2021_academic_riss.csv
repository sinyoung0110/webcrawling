title,date,keywords,abstract,multilingual_abstract
YOLO 기반 나방 유충 탐지 모델의 연구,2021,"['Moth larvae', 'Moth larva detection', 'YOLO', 'Moth larvae control', 'YOLO model comparison.']",,"Moth pests are pests that cause a lot of damage to food crops. Moth larvae are similar in shape and shape. In addition, even moth larvae have different colors depending on the environment and consummation, so it is difficult for skilled farmers to accurately identify moth larvae. However, accurate identification of moth larvae is very important because moth larvae have different control methods. The main user of the moth larva detection model is a farmer without computer knowledge. Thus, the most important factor is not the time or accuracy to detect larvae of moths. How little false positive or false negative is a more important factor. It prevents waste of labor and financial losses of farmers who have misrepresented by error detection. This is because it can improve the credibility of smart agricultural technology. The YOLO v2, YOLO v3, and YOLO v4 models were learned as the same moth larvae image and the performance between models was compared. As a result of the experiment, the YOLO v4 model showed Precision, Recall, and F1-Score as 1.00. In addition, it was confirmed that the performance was superior to other YOLO models with 88.39% of IoU and 79.96% of mAP. False Positive or False Negative is also less than other YOLO models. It was confirmed that the YOLO v4 model was suitable as a moth larva detection model."
YOLO 기반 차선검출 시스템,2021,"['객체인식', '자율주행', 'CSI-Camera', 'YOLO', 'Object recognition', 'Autonomous driving', 'CSI-Camera', 'YOLO']",자동차는 단순한 이동 수단으로 사용되었지만 최근 지능화 및 스마트화가 급속하게 진행되고 자동차 선호도가 증가하면서 운전자의 편의 및 안전 등 고성능 기능을 요구하면서 IT 기술 융합 연구가 진행되고 있다. 이로 인해 자율주행과 반자율주행 자동차가 개발되고 이러한 기술들은 주변 환경 문제로 인하여 차선 이탈 경우와 자율주행 자동차에서 판단하지 못하는 상황이 생기고 차선 검출기에서는 차선을 인식하지 못하는 경우가 있다. 이러한 문제점인 자율주행 자동차의 차선검출 시스템의 차선 이탈에 대한 성능을 향상하기 위해 본 논문에서는 YOLO(You only look once)의 특성인 빠른 인식을 사용하고 CSI- Camera를 사용하여 주변 환경으로부터 영향을 받는 상황을 인지하고 주행 데이터 수집하여 관심 영역을 추출하는 차선검출 시스템을 제안한다.,"Automobiles have been used as simple means of transportation, but recently, as automobiles are rapidly becoming intelligent and smart, and automobile preferences are increasing, research on IT technology convergence is underway, requiring basic high-performance functions such as driver's convenience and safety. As a result, autonomous driving and semi-autonomous vehicles are developed, and these technologies sometimes deviate from lanes due to environmental problems, situations that cannot be judged by autonomous vehicles, and lane detectors may not recognize lanes. In order to improve the performance of lane departure from the lane detection system of autonomous vehicles, which is such a problem, this paper uses fast recognition, which is a characteristic of YOLO(You only look once), and is affected by the surrounding environment using CSI-Camera. We propose a lane detection system that recognizes the situation and collects driving data to extract the region of interest."
YOLO알고리즘을 활용한 시각장애인용 식사보조 시스템 개발,2021,"['컴퓨터 비전', '딥러닝', 'YOLO', '시각 장애인', '공통 영역', '안드로이드', '음성 합성 시스템', 'Computer Vision', 'Deep Learning', 'YOLO', 'Visually Impaired', 'Intersection over Union(IoU)', 'Android', 'Text-to-Speech']","시각이 온전한 사람들은 식사를 할 때 시각에 대한 의존도를 깊게 인지하지 못한다. 그러나 시각장애인은 식단에 어떤 음식이 있는지 알지 못하기 때문에 옆에 있는 보조인이 시각장애인 수저로 음식의 위치를 시계 방향 또는 전후좌우 등 일정한 방향으로 설명하여 그릇 위치를 확인한다. 본 논문에서는 시각장애인이 스마트폰의 카메라를 이용하여 자신의 식단을 비추면 각각의 음식 이미지를 인식하여 음성으로 음식의 이름을 알려 주는 식사보조 시스템의 개발 내용에 대해 기술한다. 이 시스템은 음식과 식기도구(숟가락)의 이미지를 학습한 YOLO모델을 통해 숟가락이 놓인 음식을 추출해 내고, 이 음식이 무엇인지를 인식하여 이를 음성으로 알려준다. 본 시스템을 통해 시각장애인은 식사보조인의 도움없이 식사를 할 수 있음으로써 자립의지와 만족도를 높일 수 있을 것으로 기대한다.","Normal people are not deeply aware of their dependence on sight when eating. However, since the visually impaired do not know what kind of food is on the table, the assistant next to them holds the blind spoon and explains the position of the food in a clockwise direction, front and rear, left and right, etc. In this paper, we describe the development of a meal assistance system that recognizes each food image and announces the name of the food by voice when a visually impaired person looks at their table using a smartphone camera. This system extracts the food on which the spoon is placed through the YOLO model that has learned the image of food and tableware (spoon), recognizes what the food is, and notifies it by voice. Through this system, it is expected that the visually impaired will be able to eat without the help of a meal assistant, thereby increasing their self-reliance and satisfaction."
YOLO와 OCR 알고리즘에 기반한 시각 장애우를 위한 유통기한 알림 시스템,2021,"['시각 장애우', '유통기한', '인공지능', '객체 인식', '광학 문자 인식', 'Visually Impaired Person', 'Expiration Date', 'Artificial Intelligence', 'You Only Look Once', 'Optical Character Recognition']","점자를 제외한 시각 장애우들이 유통기한을 확인할 수 있는 효과적인 방법이 거의 개발되어 있지 않으며, 이로 인하여 시각 장애우들의 식품 안전성이 위협받고 있다. 본 연구에서는 시각 장애우의 식품 안전성 확보를 위해 실시간 객체 인식 알고리즘(you only look once, YOLO) 및 광학 문자 인식 (optical character recognition, OCR)에 기반한 유통기한 알림 시스템을 개발했다. 제안하는 시스템은 총 4가지 단계로 시각 장애우에게 유통기한 정보를 전달한다: (1) 표적 제품의 바코드 스캔을 통한 제품 확인 (2) 실시간으로 입력되는 제품 영상에서 YOLO 알고리즘을 활용하여 유통기한이 표기된 이미지 영역 검출; (3) 검출된 이미지 영역에서 OCR 알고리즘을 활용하여 유통기한 문자 인식; (4) Text to Speech (TTS) 기술을 활용하여 유통기한 정보를 사용자에게 전달. 성능 평가를 위한 온라인 실험 결과, 앞이 보이지 않는 피험자가 개발한 시스템을 사용해서 제품의 유통기한을 평균 86%의 높은 정확도로 확인할 수 있음이 검증되었다. 이러한 결과는 제안하는 시스템이 저시력자를 포함한 시각 장애우들의 식품 안전성 확보에 이바지할 수 있음을 보여준다.","There are rarely effective methods to help visually impaired people when they want to know the expiration date of products excepted to only Braille. In this study, we developed an expiration date notification system based on YOLO and OCR for visually impaired people. The handicapped people can automatically know the expiration date of a specific product by using our system without the help of a caregiver, fast and accurately. The proposed system is worked by four different steps: (1) identification of a target product by scanning its barcode; (2) segmentation of an image area with the expiration date using YOLO; (3) classification of the expiration date by OCR: (4) notification of the expiration date by TTS. Our system showed an average classification accuracy of about 86.00% when blindfolded subjects used the proposed system in real-time. This result validates that the proposed system can be potentially used for visually impaired people."
아두이노와 YOLO를 이용한 졸음 방지 시스템 구현,2021,[],,"In modern society, deaths and property damage due to drowsiness occur every year enormously. Methods to reduce such damage are being studied a lot in all walks of life, and research on preventing drowsy driving is particularly active in automobiles. In this paper, as an Arduino-based water gun firing system that learns open and closed eyes using YOLO, we propose a drowsy prevention system that fires a water gun when the duration of the closed eye exceeds a certain time. This system can be applied and used in various fields, but especially when applied to a car, it is not necessary to purchase expensive specifications and if you pay a little attention, you can reduce accidents caused by drowsy driving by 100% at a very low cost. In addition, it can be said that it is an independent system that overcomes different specifications for each company."
선택적 주의집중 모델과 YOLO를 이용한 선행 차량 정지등 검출 시스템 구현,2021,[],,"A ADAS(Advanced Driver Assistance System) for the safe driving is an important area in autonumous car. Specially, a ADAS software using an image sensors attached in previous car is low in building cost, and utilizes for various purpose. A algorithm for detecting the break-lamp from the tail-lamp of preceding vehicle is proposed in this paper. This method can perceive the driving condition of preceding vehicle. Proposed method uses the YOLO techinicque that has a excellent performance in object tracing from real scene, and extracts the intensity variable region of break-lamp from HSV image of detected vehicle ROI(Region Of Interest). After detecting the candidate region of break-lamp, each isolated region is labeled. The break-lamp region is detected finally by using the proposed selective-attention model that percieves the shape-similarity of labeled candidate region. In order to evaluate the performance of the preceding vehicle break-lamp detection system implemented in this paper, we applied our system to the various driving images. As a results, implemented system showed successful results."
적외선 카메라와 YOLO를 사용한 블랙아이스 탐지 방법,2021,[],,"Black ice, which occurs mainly on the road, vehicle traffic bridges and tunnel entrances due to the sub-zero temperature due to the slip of the road due to heavy snow, is not recognized because the image of asphalt is transmitted in the driver's view, so the vehicle loses braking power because it causes serious loss of life and property. In this paper, we propose a method to identify the black ice by using infrared camera and to identify the road condition by using deep learning to compensate for the disadvantages of existing black ice detection methods (artificial satellite imaging, checking the pattern of slip by ultrasonic reception, measuring the temperature of the road surface, and checking the difference in friction force of the tire during vehicle driving) and to reduce the size of the sensor to detect black ice."
수정된 YOLO v4를 활용한 해상에서 객체 탐지 및 분류 모형 개발,2021,"['Deep learning', 'Detection of warships', 'Object detection', 'YOLO v4', 'Modified YOLO v4']","본 연구의 목적은 해상에서 군함의 영상장비로 획득한 영상에 딥러닝을 적용하여 군함을 객체로 탐지하고 분류하는 모형을 개발하는 것이다. 본 연구에서는 한반도 해상과 관련된 5개국의 군함을 대상으로 하였다. 모형의 알고리즘은 기존 YOLO v4 모형의 SPP 영역을 수정하여 구현한 것을 제안하였고, 기존 YOLO v4 모형과 본 연구에서 제안한 수정된 YOLO v4 모형을 비교하였다. 두 모형에 대한 평가는 mAP(mean Average Precision) 와 IoU(Intersection over Union)로 하였으며, 평가 결과 수정된 YOLO v4 모형이 mAP 면에서 YOLO v4 모형보다 0.28% 더 우수한 성능을 보였다. 또한, 테스트 영상을 이용한 실험에서도 영상의 크기에 관계없이 제안한 모형이 기존 모형보다 객체 분류 면에서 우수한 성능을 보였다.",
PP-YOLO를 이용한 실시간 두피 각질 검출 기법,2021,"['PP-YOLO', '두피 관리', '두피 질병', 'Real-time object detection', 'PP-YOLO', 'Haircare', 'Scalp disease']","두피 질병은 대개 각질과 통증을 유발하며, 증상을 방치하면 탈모나 모낭염으로 진행될 수 있다. 따라서, 질병의 조기 발견과 치료가 중요하지만, 정기적으로 전문 기관을 방문하는 것은 많은 시간과 비용을 초래한다. 최근, 스마트폰에 현미경 카메라를 연동한 두피 상태의 자가진단이 가능해지면서, 딥러닝 기반의 두피 질병 진단 기법이 제안되고 있다. 그러나, 이러한 기법들은 높은 연산량이 요구되어 스마트폰과 같은 제한적인 하드웨어 환경에서는 만족스러운 성능을 얻기가 어려워, 실시간 두피 상태 진단과 같은 현실적인 요구에 부합하지 못하고 있다. 이러한 문제를 해결하고자, 본 논문에서는 두피 질병에서 공통으로 발생하는 각질의 유무와 위치를 실시간으로 추출할 수 있는 기법을 제안한다. 이를 위해, 각질 검출에 PP-YOLO 모델을 사용하였으며, 기존에 제안된 연구들과 검출 정확도 및 처리 속도를 비교하였다. 실험결과, 본 논문에서 제안하는 기법은 실시간 수준의 검출 속도를 만족할 뿐만 아니라, 기존 연구보다 정확하게 두피 각질을 검출할 수 있음을 보인다.",
YOLO 기반의 광학 음악 인식 기술 및 가상현실 콘텐츠 제작 방법,2021,"['딥러닝', '가상현실', '컴퓨터 비전', 'Deep Learning', 'Virtual Reality', 'Optical Music Recognition(OMR)', 'Computer Vision']","딥러닝에 기반한 광학 음악 인식 기술(Optical Music Recognition, OMR)을 사용하여 도출된 결과를 가상현실 (Virtual Reality, VR) 게임에 적용시킨 것을 제안한다. 딥러닝 모델은 YOLO v5를 사용했으며 검출되지 않은 객체를 검출하기 위해 Hough transform 사용, 보표 크기 수정 등을 수행한다. 출력된 결과 파일을 사용하여 VR 게임에서 BPM, 최대 콤보 수, 음정과 박자를 분석하여 사용하고 리소스 관리를 위한 Object Pooling 기술을 통해 노트가 밀리는 현상을 방지한다. 광학 음악 인식 기술을 통해 나온 음악 요소로 VR 게임을 제작하여 VR 콘텐츠 제공과 함께 광학 음악 인식의 활용성을 넓히는 것을 확인하였다.","Using optical music recognition technology based on deep learning, we propose to apply the results derived to VR games. To detect the music objects in the music sheet, the deep learning model used YOLO v5, and Hough transform was employed to detect undetected objects, modifying the size of the staff. It analyzes and uses BPM, maximum number of combos, and musical notes in VR games using output result files, and prevents the backlog of notes through Object Pooling technology for resource management. In this paper, VR games can be produced with music elements derived from optical music recognition technology to expand the utilization of optical music recognition along with providing VR contents."
YOLO V3 기반의 시각장애인을 위한 유도 블록 인식 알고리즘,2021,"['YOLO', '영상인식', '머신러닝', '합성곱 신경망', '평균 정밀도', 'Object detection', 'Machine learning', 'Convolutional neurual network', 'Mean average precision']","현재 우리나라에 설치된 유도 블록 중에서 일부는 설치 후에 관리가 미흡한 편이며 파손된 경우 보수도 잘 이루어지지 않아 시각장애인들의 보행에 부정적인 영향을 미치는 경우가 많다. 시각장애인들에게 유도 블록의 위치와 의미를 전달하는 시스템에 관한 연구가 필요한 상황이며 이를 위해서 휴대하기 편하고 스마트폰에서도 계산이 가능한 알고리즘이 요구된다. 이에 본 논문은 실시간 물체 검출이 가능하고, 준수한 FPS(frame per second)를 유지할 수 있는 YOLO를 기반으로 한 시각장애인을 위한 유도 블록 인식 알고리즘을 제안한다. 그리고 영상인식 영역의 성능을 여러 가지 수치로 비교하여 최선의 알고리즘을 선택했고 해당 알고리즘은 mAP와 YOLO-Loss, AP, Precision 등의 수치를 이용하여 성능을 평가하였다. 제안한 알고리즘은 연산량을 줄여주고 그에 따른 정확도의 하락을 방지하는 방법도 제시했다.","Currently, some of the induction blocks in the case of in Korea are poorly managed when some of the induction blocks are installed, and there is a visual impairment because neither case nor maintenance is well done. There is a need for research on a system that delivers the location and meaning of guidance blocks to visually impaired people, and an algorithm that is easy to perform and that can be calculated on a smartphone is required. Therefore, this paper proposes an induction block recognition algorithm for the visually impaired based on YOLO, which enables real-time detection and uses compliant FPS (frame per second). Then, the best algorithm was selected by comparing the performance of the image recognition area with various numbers, and the performance was evaluated using mAP, YOLO-Loss, AP, and Precision. The proposed algorithm flows the computational load and also suggests a method to prevent its degradation."
YOLO와 CNN을 이용한 강인한 차량 번호판 인식 시스템 구현,2021,"['you only look once', 'license plate', 'object detection', 'optical character recognition', 'convolution neural network']",,"In recent years, with the development of intelligent transportation systems, research on license plate recognition is drawing attention. Domestic license plate recognition is frequently misrecognized due to image quality and Korean language problems. This study implemented a real-time license plate recognition system robust against environmental changes using YOLO and CNN. YOLO was used to extract only a specific license plate area, and CNN was used to recognize license plates. License plate recognition extracted numbers and letters from the actual license plate drawing. Then, it was transformed and multiplied to be robust to the environment, and learned with CNN. In addition, three algorithms were used for recognizing Korean characters with many misrecognitions, such as detection of separated consonants and vowel regions using erosion and average regions, and extraction of syllable regions when there is no Korean syllable. Finally, the proposed license plate recognition system and the existing OCR algorithm were compared. As a result of the experiment, the easy OCR has an accuracy of 62.5%, the algorithm using only erosion is 82.5%, and the proposed algorithm has an accuracy of 97.5%."
"사람에서 컴퓨터 자동화로의 연결을 위한 탐색 : 객체 인식(Object Detection) 딥러닝 알고리즘 YOLO4, 자세 인식(Pose Detection) 프레임워크 MediaPipe를 활용한 음악 프로그램의 여성 신체 대상화, 선정적 화면 검출 연구",2021,"['Body Objectification', 'Object Detection', 'Pose Detection', 'YOLO4', 'MediaPipe', '객체 동작 감지', '여성 신체 대상화', '선정적 화면']",,"The goal of this research is to examine patterns of objectification and sexualization of the female body in music programs on television. The study’s goal is to identify rules for automated visual image detection of body objectification and sexualization. To do so, previous qualitative study findings were used to identify target images and the cutting-edge object-detection deep learning algorithm, YOLO4 (You Only Look Once), and MediaPipe, a framework for deep learning-based pose detection, were used to search for patterns. As this is a one-of-a-kind study linking body objectification and algorithm-based object detection, the case for analysis must be carefully chosen, taking into account random effects from unplanned camera movements caused by real-time broadcasting. The dance to the song ’Rollin’ by the female group ’Brave Girls’ had already been broadcasted earlier in 2017. Thus, the on-stage choreography and camera movements associated with the song were already known, making them suitable for research data. The study used music programs that aired on three broadcasting networks, KBS, MBC, and SBS, during the second week of March, 2021. To fine-tune the patterns, 12 screen images were selected by extracting keyframes from the song’s original music videos. The study’s findings are summarized below. To begin, when the scene transition is associated with a significant decrease in the number of people in the visual frame in comparison to the previous frame, it is frequently associated with female body objectification. Because body objection is associated with an emphasis on a specific body-part in the absence of a face, this is essentially a zoom-in technique transited from a wide-angle view of the scene. This rule, however, is insufficient for detecting objectified visual images; it can also be applied to screen images that avoid sexualized images in the given dance choreography. As a result, an additional rule is required to exclusively find images of female body objectification, and it is discovered that detecting human faces on the screen appears to be a good measure. In other words, unless the human faces on the screen do not appear with the scene transition that shows a dramatic decrease in the number of humans in the scene, a visual flow of images can be considered female body objectification. The study also compared the levels of objectification across broadcasting networks and found that MBC has a lower proportion of sexualized images than that of other networks. On MBC’s music program, the MediaPipe framework for pose detection discovered fewer scene images with lower body parts than others. The findings of this study suggest that computer vision research can be used to detect female objectified bodies and sexual images in television programs."
YOLO와 CRNN을 사용한 전기 계량기 이미지에서의 카운터 숫자 인식,2021,"['Meter Reading', 'Object Detection', 'OCR', 'YOLO', 'CRNN']",,"This study proposes a method for automatically recognizing digits in power meter images. Our targets are analog power meters that display usage with four counters. We employed object detection to find the numeric domain in the meter image. And optical character recognition was performed to recognize digits in the detected numeric area. Two types of deep neural network models are used for object detection and optical character recognition. To train the model and evaluate its performance, we generated datasets from meter images. In this paper, we propose a model in which two types of deep neural networks are connected, and this model has more than 98% recognition performance."
잎사귀 질병 검출을 위한 관심 영역 특징 추출 기반의 어텐션 강화 YOLO 모델,2021,"['attention YOLO model', 'object detection', 'image segmentation', 'deep convolutional neural networks', 'smart farm']",,"The YOLO model, which is widely used in the existing object detection, excludes the attention function that can learn which feature vectors are more important. Therefore, in this paper, we propose an attention YOLO model that can improve the object detection performance of the existing YOLO model. The proposed attention model was conceived from the fact that there is no information on diseases in the background area of the input leaf image, and spots and color information that can determine the presence or absence of the diseases exist only inside the leaf. By combining the YOLOs feature extraction subnetwork with the image segmentation subnetwork capable of dividing the background, leaf, and disease areas from the input leaf, it is intended to improve the ability to distinguish features in the region of interest. In other words, a new attention model that can spatially reinforce the importance of disease-related features in the YOLO model is introduced. In addition, through the experimental results, it is shown that the proposed attention YOLO model can improve the detection performance by about 0.06 in the mean Averaged Precision（mAP) evaluation compared to the existing YOLO model."
YOLO v4 기반 혼잡도로에서의 움직이는 물체 검출 및 식별,2021,"['person', 'motocycle', 'bicycle', 'bus', 'car', 'detection', 'YOLO v4']","일부 네거리나 혼잡도로에서 특정 시간대에 행인이 많고 도로가 막혀서 발생하는 교통사고가 적지 않다. 특히 인근에 학교교차로가 있어 바쁜 시간에 학생들의 교통안전을 지키는 것이 중요하다. 과거에는 교통 신호등을 설 계 했을 때 행인의 안전성을 고려하지 않고 자동차 인식과 교통 최적화에 대하여 연구 했다. 행인, 특히 학생들의 안전을 확보하 는 전제에서 가능한 한 도로의 소통을 유지하는 것이 본 연구의 중점적인 연구 방향이다. 본 연구는 사람, 오토바이, 자전거, 자동차, 버스의 식별문제를 중점적으로 연구할 것이다. 조사와 비교를 통해 본 연구는 YOLO v4 네트워크로 목표물의 위치와 수량을 식별하는 것을 제시한다. YOLO v4는 작은 목표물의 식별 능력이 강하고 정밀도가 높으며 처리 속도가 빠르다는 특징을 가지고 있으며, 데이터 수집 대상을 설정하여 이미지 집합을 훈련하고 테스트 한다. 움직이는 영상에서 목표물의 정확도, 실수율과 누락율에 대한 통계를 사용하여, 본 연구에서 훈련된 네트워크는 움직이는 이미지 속의 사람, 오토바이, 자전거, 자동차와 버스를 정확하게 식별 할 수 있다.","In some intersections or busy traffic roads, there are more pedestrians in a specific period of time, and there are many traffic accidents caused by road congestion. Especially at the intersection where there are schools nearby, it is particularly important to protect the traffic safety of students in busy hours. In the past, when designing traffic lights, the safety of pedestrians was seldom taken into account, and the identification of motor vehicles and traffic optimization were mostly studied. How to keep the road smooth as far as possible under the premise of ensuring the safety of pedestrians, especially students, will be the key research direction of this paper. This paper will focus on person, motorcycle, bicycle, car and bus recognition research. Through investigation and comparison, this paper proposes to use YOLO v4 network to identify the location and quantity of objects. YOLO v4 has the characteristics of strong ability of small target recognition, high precision and fast processing speed, and sets the data acquisition object to train and test the image set. Using the statistics of the accuracy rate, error rate and omission rate of the target in the video, the network trained in this paper can accurately and effectively identify persons, motorcycles, bicycles, cars and buses in the moving images."
YOLO 알고리즘을 이용한 전차 국적 식별 및 평가,2021,"['객체탐지', 'YOLO(You Only Look Once) 알고리즘', '딥러닝', '데이터셋', '전차', '피아식별 시스템', 'object detection', 'YOLO(You Only Look Once) algorithm', 'deep learning', 'dataset', 'tank', 'Identification of Friend or Foe', 'mAP', 'IoU']","인공지능 딥러닝 기술이 적용된 무기체계가 지속적으로 개발된다. 기존의 전차 피아식별 시스템은 사람의 눈으로 표적을 획득하고 공격 여부를 판단한다. 따라서 신속성과 정확성 측면에서 한계가 존재한다. 본 연구에서는 이러한 제한사항을 개선하기 위해 YOLO(You Only Look Once) 알고리즘 기반의 전차 국적 식별 방법을 제안한다. 먼저, 한국, 미국, 일본, 북한의 4개국의 주력 전차 사진을 수집한다. 특히, 실제 기갑 전투의 상황과 유사하도록 노이즈를 추가하고 이미지 전처리 작업을 한다. 이후 데이터셋은 학습 데이터의 적절한 규모를 확인하기 위해 8개의 그룹으로 구성한다. 마지막으로 평가 척도인 mAP와 IoU를 기반으로 적절한 데이터 규모를 분석한다.","Advanced weapon systems with artificial intelligence deep learning technology will be continuously. The existing identification system of friend or foe on tank targets with human eyes determine whether to attack. Therefore, there are limitations in terms of speed and accuracy. In this paper, we propose a YOLO(You Only Look Once) Algorithm-based tank nationality identification method to improve these limitations. First, we collect photos of the main tank from four countries South Korea, the United States, Japan and North Korea. In particular, similar to the actual armored battle, we add noise and do image preprocessing. Afterward, the dataset organized into eight groups to check the appropriate size of the learning data. Finally, we analyze the appropriate data size based on the evaluation scales, mAP and IoU."
결함검출 적용을 위한 YOLO 딥러닝 알고리즘 비교,2021,"['YOLO', 'Deep learning', 'Object detection', 'Defect detection', 'CNN']",,"Recently, metal 3D printing technology has developed and has been widely applied in fields such as mechanical parts and construction sites. However, the problem of output defects must be resolved. These defects appear as pores and microcracks in the output, which can be confirmed through microscopic analysis of the output. In addition, if the understanding of pores or cracks is unclear or many images need to be checked in a short time, an error might occur. Therefore, this study aims to develop a precision object detection algorithm using deep learning. The purpose is to automatically detect defects using deep learning-based You Only Look Once (YOLO). Through comparison using YOLO v3 and v5 algorithms, the accuracy and speed were compared to analyze which YOLO model was efficient in the defect detection process."
허프변환과 YOLO 기반의 골프공 궤적 추적,2021,"['골프 공', '추적', '차영상', '임계값', '허프 변환', '욜로-V3', 'Golf ball', 'Tracking', 'Frame Differencing', 'Threshold', 'Hough Transform', 'YOLO-V3']","드라이브나 티샷을 할 때 육안을 통해 수동적으로 골프공의 궤적을 시각화하는 것은 어려운 작업이 될 수 있는데, 그 이유는 공의 크기가 작고 공이 이동하는 속도가 빠르기 때문이다. 이러한 작업의 특성으로 인해 값비싼 센서 및 구성 요소를 사용하여 제조된 복잡한 장치가 항상 요구되어 왔습니다. 본 논문에서는 골프 티샷중 골프공의 궤적을 추적하는 시스템을 제안한다. 제안하는 시스템은 기존의 컴퓨터 비전 기술과 현대적인 심층 신경망을 결합하여 모노 스테레오 비디오에 궤적을 추적한다. 골프 볼 추적에 앞서, 골프공과 플레이어의 위치를 특정 짓기 위해 YOLO(You Only Look Once) V3 딥 신경망 모델을 사용한다. 우리는 클럽과 공 사이의 초기 충격 지점을 추적 하기 위해 허프 변환을 사용한다. 또한 볼을 추적하기 위해 차영상을 이용하여 비디오의 모션 정보를 추출한다. 제 안하는 시스템의 효과를 검증하기 위해 다수의 비디오에서 테스트되었으며 각각의 결과를 보여준다.","Manually visualizing the golf ball's trajectories during a drive or a tee shot could be an unsettling task for viewers, the reason being the small size of the ball and the high speed at which it travels. This nature of the job has always required intricate systems manufactured using an expensive set of sensors and components. In this paper, we propose a system to draw the trajectory of a golf ball during a drive. The proposed system combines the classical computer vision techniques and a modern deep neural network to project the trajectories over videos taken from monocular cameras. Before starting to track the ball, the system uses YOLO(You Only Look Once) V3, deep neural network model to perform localization of the golf ball and the player. To track the initial point of impact between the club and the ball the system uses Hough transform. Finally to track the ball, the system extracts motion information of the video by using frame differencing. Unto the information received from frame differencing, the system applies filters based on a few assumptions, size and direction of movement to obtain the detections of the golf ball. The proposed system was tested on a multitude of videos to verify its effectiveness and the respective results are presented."
SMD Detection and Classification Using YOLO Network Based on Robust Data Preprocessing and Augmentation Techniques,2021,"['PCB inspection', 'SMD inspection', 'Classification', 'Detection', 'YOLO']",,"The process of inspecting SMDs on the PCB boards improves the product quality, performance and reduces frequent issues in this field. However, undesirable scenarios such as assembly failure and device breakdown can occur sometime during the assembly process and result in costly losses and time-consuming. The detection of these components with a model based on deep learning may be effective to reduce some errors during the inspection in the manufacturing process. In this paper, YOLO models were used due to their high speed and good accuracy in classification and target detection. A SMD detection and classification method using YOLO networks based on robust data preprocessing and augmentation techniques to deal with various types of variation such as illumination and geometric changes is proposed. For 9 different components of data provided from a PCB manufacturer company, the experiment results show that YOLOv4 is better with fast detection and classification than YOLOv3."
YOLO v3를 이용한 높은 정확도의 차량 계수 방법,2021,"['Vehicle detection(차량 검출)', 'Deep learning(딥러닝)', 'Convolutional neural network(합성곱신경망)', 'Traffic surveillance data(교통감시데이터)', 'YOLO(You Only Look Once', '욜로)']",,
욜로(YOLO)족의 여행경험에 관한 실존적 진정성 척도개발 및 타당성 연구,2021,"['YOLOs', 'Existential authenticity', 'Introspection', 'Kierkegaard', 'Scale development', '욜로(YOLO)', '실존적 진정성', '자아성찰', '키에르케고르', '척도개발']",,
Real-Time License Plate Detection for Non-Helmeted Motorcyclist Using YOLO,2021,"['YOLO', 'Helmet detection', 'LP detection', 'Centroid tracking']",,"Nowadays, detection of license plate (LP) for non-helmeted motorcyclist has become mandatory to ensure the safety of the motorcyclists. This paper presents the real-time detection of LP for non-helmeted motorcyclist using the real-time object detector YOLO (You Only Look Once). In this proposed approach, a single convolutional neural network was deployed to automatically detect the LP of a non-helmeted motorcyclist from the video stream. The centroid tracking method with a horizontal reference line was used to eliminate the false positive generated by the helmeted motorcyclist as they leave the video frames. The overall LP detection rate was 98.52%."
경기 불황과 욜로(YOLO) : 지각된 부정적 경제 상황이 소비자의 현재에 편향된 선호에 미치는 영향,2021,"['경기 불황', '욜로', '현재 편향 소비', '암묵적 이론', 'MZ 세대', 'Recession', 'YOLO', 'Present-Biased Consumption', 'Implicit Theory', 'MZ Generation']",,
YOLO 신경망 기반의 UAV 영상을 이용한 건물 객체 탐지 분석,2021,"['Object Detection', 'Building Object Detection', 'YOLO', 'UAV', 'Spatial Analysis', '객체탐지', '건물탐지', '공간분석']",,
YOLO 를 이용한 CNN 기반의 물체 인식과 파지 중심점 위치오차 최소화 알고리즘 연구 및 파지 성능 평가,2021,"['Machine Vision', 'Visual Servoing', 'Object Detection', 'Convolutional Neural Network', 'Transformation Matrix']",,"In the last few years, the use of robot manipulators has attracted increasing attention in various industries. Accordingly. Researchers have proposed unique ideas for co-robot control using vision sensors. In this study, you only look once (YOLO) based on convolutional neural network (CNN), and grasping center point position error minimization algorithms were proposed to reduce object misrecognition and increase the performance for grasping an object. In addition, a gripping algorithm was designed for six degree of freedom (DOF) robot manipulators. In addition, machine vision algorithms, including a Grayscale, Gaussian filter, Canny edge, and Contouring, were implemented to detect objects features, such as centroids and orientation. Furthermore, the coordinate system of the vision sensor was converted into a coordinate system of the robot manipulator using a transformation matrix to accurately move the end effector of the robot arm to the center point of the object. The logic implemented in this study not only detected the trained object on the workstation, but also minimized the positional error of the transformation matrix. Additionally, experiments were performed on the 6-DOF robot manipulators. The results revealed that the end effector of the 6-DOF manipulators successfully moved to the center of the detected object, and each of the eight objects was normally gripped."
"욜로(YOLO)가 소비행복에 미치는 영향 : 감정적 충동구매, 인지적 충동 구매 및 개인주의적 가치소비의 매개 효과",2021,"['욜로', '소비행복', '감정적 충동구매', '인지적 충동구매', '개인주의적 가치소비', 'YOLO', 'Consumption Happiness', 'Affective Impulse Buying', 'Cognitive  Impulse Buying', 'Egoistic Value Consumption']",,
A Study on Fruit Quality Identification Using YOLO V2 Algorithm,2021,"['YOLOV2', 'Region Of Interest', 'Bound Box', 'R-CNN', 'Artificial Intelligence']",,"Currently, one of the fields leading the 4th industrial revolution is the image recognition field of artificial intelligence, which is showing good results in many fields. In this paper, using is a YOLO V2 model, which is one of the image recognition models, we intend to classify and select into three types according to the characteristics of fruits. To this end, it was designed to proceed the number of iterations of learning 9000 counts based on 640 mandarin image data of 3 classes. For model evaluation, normal, rotten, and unripe mandarin oranges were used based on images. We as a result of the experiment, the accuracy of the learning model was different depending on the number of learning. Normal mandarin oranges showed the highest at 60.5% in 9000 repetition learning, and unripe mandarin oranges also showed the highest at 61.8% in 9000 repetition learning. Lastly, rotten tangerines showed the highest accuracy at 86.0% in 7000 iterations. It will be very helpful if the results of this study are used for fruit farms in rural areas where labor is scarce."
PCB 검사를 위한 YOLO 네트워크 기반의 PCB 부품 분류 알고리즘,2021,"['PCB Inspection', 'Defect Detection', 'AOI', 'Classification', 'Deep Learning', 'CNN']",,
욜로 성향이 소비자의 충동성과 자기통제에 미치는 영향,2021,"['욜로', '현재-지향적', '시간관', '충동성', '자기통제', 'YOLO', 'Present-Oriented', 'Time Perspective', 'Impulsivity', 'Self-Control']",,"This study focuses on the positive aspects of YOLO(You Only Live Once; Drake 2011, track 19) that has oftentimes been associated with impulsive and unplanned consumption behaviors. YOLO has a present-oriented time perspective that emphasizes current happiness, and also implies a philosophy of life that if you live faithfully to each day that you face now, you could be happy tomorrow as well. To better understand the concept of YOLO and its impact on consumption behavior, this study aims to investigate the effect of YOLO disposition on consumer impulsivity and self-control. We hypothesize that consumers who have YOLO disposition expect to achieve their current goals and pursue current happiness through consumption only if they meet their goals through self-control processes. To test our predictions, we conducted two experiments. The results of experiment 1 demonstrated that when the reason for saving was to spend money on travel rather than to keep money, yolo-oriented consumers put more money compared to control group. The findings of experiment 2 further revealed a significant relationship between YOLO, impulsivity, and self-control in choice context. The results demonstrated that consumers who were primed by travel(hedonic) or learning(utilitarian) goals to pursue their current well-being had a tendency to choose a third or fifth category through a process of selfcontrol, which is consistent with the goal. This suggested that present-oriented consumers had a middle or high level of self-control. These findings contribute to research on new perspectives of YOLO and offer novel insights into the relationship between YOLO disposition and self-control."
딥러닝 기반의 연기 확산거리 예측을 위한 알고리즘 개발 기초연구,2021,"['딥러닝', '연기검출', '연기 확산거리 예측', 'YOLO', 'LSTM', 'Deep learning', 'Smoke detection', 'Smoke spread distance prediction', 'YOLO', 'LSTM']","본 연구는 화재진압 및 피난활동을 지원하는 딥러닝 기반의 알고리즘 개발에 관한 기초 연구로 선박 화재 시 연기감지기가 작동하기 전에 검출된 연기 데이터를 분석 및 활용하여 원격지까지 연기가 확산 되기 전에 연기 확산거리를 예측하는 것이 목적이다. 다음과 같은 절차에 따라 제안 알고리즘을 검토하였다. 첫 번째 단계로, 딥러닝 기반 객체 검출 알고리즘인 YOLO(You Only Look Once)모델에 화재시뮬레이션을 통하여 얻은 연기 영상을 적용하여 학습을 진행하였다. 학습된 YOLO모델의 mAP(mean Average Precision)은 98.71%로 측정되었으며, 9 FPS(Frames Per Second)의 처리 속도로 연기를 검출하였다. 두 번째 단계로 YOLO로부터 연기 형상이 추출된 경계 상자의 좌표값을 통해 연기 확산거리를 추정하였으며 이를 시계열 예측 알고리즘인 LSTM(Long Short-Term Memory)에 적용하여 학습을 진행하였다. 그 결과, 화재시뮬레이션으로부터 얻은 Fast 화재의 연기영상에서 경계 상자의 좌표값으로부터 추정한 화재발생~30초까지의 연기 확산거리 데이터를 LSTM 학습모델에 입력하여 31초~90초까지의 연기 확산거리 데이터를 예측하였다. 그리고 추정한 연기 확산거리와 예측한 연기 확산거리의 평균제곱근 오차는 2.74로 나타났다.","This is a basic study on the development of deep learning-based algorithms to detect smoke before the smoke detector operates in the event of a ship fire, analyze and utilize the detected data, and support fire suppression and evacuation activities by predicting the spread of smoke before it spreads to remote areas. Proposed algorithms were reviewed in accordance with the following procedures. As a first step, smoke images obtained through fire simulation were applied to the YOLO (You Only Look Once) model, which is a deep learning-based object detection algorithm. The mean average precision (mAP) of the trained YOLO model was measured to be 98.71%, and smoke was detected at a processing speed of 9 frames per second (FPS). The second step was to estimate the spread of smoke using the coordinates of the boundary box, from which was utilized to extract the smoke geometry from YOLO. This smoke geometry was then applied to the time series prediction algorithm, long short-term memory (LSTM). As a result, smoke spread data obtained from the coordinates of the boundary box between the estimated fire occurrence and 30 s were entered into the LSTM learning model to predict smoke spread data from 31 s to 90 s in the smoke image of a fast fire obtained from fire simulation. The average square root error between the estimated spread of smoke and its predicted value was 2.74."
클라우드 플랫폼을 이용한 딥러닝 기반 장애인 주차구역 관리 시스템 구현,2021,"['Cloud platform', 'YOLO', 'CNN', 'Raspberry pi', 'Android phone', 'Deep learning']","본 연구는 딥러닝과 클라우드 플랫폼을 이용하여 장애인 복지 증진을 위한 장애인 주차 공간을 관리하는 시스템을 제안하였다. 딥러닝은 주차 영역의 자동차 영상에서 번호판 검출을 위하여 YOLO (you only look once)를 사용하였으며, 추출된 숫자 및 문자 영상에서 번호판 문자 인식을 위하여 CNN (convolutional neural network)을 사용하였다. 본 시스템은 실시간 관리가 가능하고, 동영상만으로 관리할 수 있도록 간소화하였다. 또한 기존 OCR (optical character recognition)보다 한글 문자 인식률을 높임으로서 안정성 및 정확성이 있으며, CCTV (closed circuit television)만 설치하면 주차관리가 가능하도록 함으로서 관리 영역의 확장성의 특장점을 가진다. 본 시스템은 기징 중요한 요소인 정확한 번호판 인식률을 높이는 연구와 다소 성능이 낮은 라즈베리 파이 환경에서 YOLO와 CNN 알고리즘 등을 실행하기 위한 처리속도 문재에 대한 지속적 연구가 필요하다.","This study proposed a system that manages parking spaces for the disabled, this will lead to the promotion of welfare for those who are disabled by using deep learning and cloud platforms. Deep learning used you only look once (YOLO) for license plate detection concerning car images in parking areas, and convolutional neural network (CNN) was used for license plate character recognition from extracted numbers and text images. This system can be managed in real time, and it has been simplified so that it can be managed only with video. In addition, it is recognized and accurate by increasing the recognition rate of Korean characters compared to the existing optical character recognition (OCR), and it has the advantage of scalability in the management area by enabling parking management but only if closed circuit television (CCTV) is installed. This system requires a study to increase the accurate license plate recognition rate. This is an important factor, and a continuous study on the processing speed problem to execute YOLO and CNN algorithms in a somewhat low performance raspberry environment."
제조업 근로자 안전관리를 위한 데이터셋 구축과 모델 학습,2021,[],"최근 ""중대재해 등에 관한 법률""이 제정되고 안전사고에 관한 제도적, 사회적 관심이 높아지고 있다. 본 논문에서는 제조업 현장에서 발생한 안전사고에 대해 정부 기관에서 발간한 통계 자료를 분석하고, 안전사고 발생을 줄이기 위해 위험 상황을 판정하는 모델을 구축하기 위한 딥러닝 기반에 다양한 객체 탐지 모델을 학습시켜 비교 분석하였다. 제조업 현장에 있는 CCTV에서 영상을 수집하여 직접 데이터셋을 구축하였으며, YOLO-v4, SSD, CenterNet 모델에 훈련 데이터와 검증 데이터로 이를 활용하고 학습을 진행하였다. 그 결과 YOLO-v4 모델이 mAP 81%의 수치를 얻었다. 산업 현장에서 클래스를 선정하고 데이터셋을 직접 구축하여 모델 학습을 하는 데 의의가 있으며 이를 통해 위험 상황을 판정하고 이를 추론하는 시스템의 초기 연구자료로 활용할 수 있을 것으로 사료된다.","Recently, the ""Act of Serious Disasters, etc"" was enacted and institutional and social interest in safety accidents is increasing. In this paper, we analyze statistical data published by government agency on safety accidents that occur in manufacturing sites, and compare various object detection models based on deep learning to build a model to determine dangerous situations to reduce the occurrence of safety accidents. The data-set was directly constructed by collecting images from CCTVs at the manufacturing site, and the YOLO-v4, SSD, CenterNet models were used as training data and evaluation data for learning. As a result, the YOLO-v4 model obtained a value of 81% of mAP. It is meaningful to select a class in an industrial field and directly build a dataset to learn a model, and it is thought that it can be used as an initial research data for a system that determines a risk situation and infers it."
YOLOv5에서 자동차 번호판 및 문자 정렬 알고리즘에 관한 연구,2021,"['Vehicle License Plate', 'YOLO(You Only Look Once)', 'LPR(License Plate Recognition)', 'Character Recognition', 'Object Detection']",,"In this paper, we propose a sorting method for extracting accurate license plate information, which is currently used in Korea, after detecting objects using YOLO. We propose sorting methods for the five types of vehicle license plates managed by the Ministry of Land, Infrastructure and Transport by classifying the plates with the number of lines, Korean characters, and numbers. The results of experiments with 5 license plates show that the proposed algorithm identifies all license plate types and information by focusing on the object with high reliability score in the result label file presented by YOLO and deleting unnecessary object information. The proposed method will be applicable to all systems that recognize license plates."
딥러닝 사물 인식 알고리즘(YOLOv3)을 이용한 미세조류 인식 연구,2021,"['Deep learning', 'Microalgae', 'Object detection', 'Water supply system', 'YOLOv3']",,"Algal bloom is an important issue in maintaining the safety of the drinking water supply system. Fast detection and classification of algae images are essential for the management of algal blooms. Conventional visual identification using a microscope is a labor-intensive and time-consuming method that often requires several hours to several days in order to obtain analysis results from field water samples. In recent decades, various deep learning algorithms have been developed and widely used in object detection studies. YOLO is a state-of-the-art deep learning algorithm. In this study the third version of the YOLO algorithm, namely, YOLOv3, was used to develop an algae image detection model. YOLOv3 is one of the most representative one-stage object detection algorithms with faster inference time, which is an important benefit of YOLO. A total of 1,114 algae images for 30 genera collected by microscope were used to develop the YOLOv3 algae image detection model. The algae images were divided into four groups with five, 10, 20, and 30 genera for training and testing the model. The mean average precision (mAP) was 81, 70, 52, and 41 for data sets with five, 10, 20, and 30 genera, respectively. The precision was higher than 0.8 for all four image groups. These results show the practical applicability of the deep learning algorithm, YOLOv3, for algae image detection."
인조 번호판을 이용한 자동차 번호인식 성능 향상 기법,2021,"['Synthetic license plate', 'Data augmentation', 'Style transformation', 'DeblurGANv2', 'YOLO-V5']",,"A lot of license plate data is required for car number recognition. License plate data needs to be balanced from past license plates to the latest license plates. However, it is difficult to obtain data from the actual past license plate to the latest ones. In order to solve this problem, a license plate recognition study through deep learning is being conducted by creating a synthetic license plates. Since the synthetic data have differences from real data, and various data augmentation techniques are used to solve these problems. Existing data augmentation simply used methods such as brightness, rotation, affine transformation, blur, and noise. In this paper, we apply a style transformation method that transforms synthetic data into real-world data styles with data augmentation methods. In addition, real license plate data are noisy when it is captured from a distance and under the dark environment. If we simply recognize characters with input data, chances of misrecognition are high. To improve character recognition, in this paper, we applied the DeblurGANv2 method as a quality improvement method for character recognition, increasing the accuracy of license plate recognition. The method of deep learning for license plate detection and license plate number recognition used YOLO-V5. To determine the performance of the synthetic license plate data, we construct a test set by collecting our own secured license plates. License plate detection without style conversion recorded 0.614 mAP. As a result of applying the style transformation, we confirm that the license plate detection performance was improved by recording 0.679mAP. In addition, the successul detection rate without image enhancement was 0.872, and the detection rate was 0.915 after image enhancement, confirming that the performance improved."
자율주행을 위한 동적 객체 인식 방법에 관한 연구,2021,"['Deep Learning', 'Faster R-CNN', 'Machine Learning', 'Support Vector Machine', 'Object Detection', 'Unmanned Vehicle', 'YOLO']",,"Dynamic object recognition is an important task for autonomous vehicles. Since dynamic objects exhibit a higher collision risk than static objects, our own trajectories should be planned to match the future state of moving elements in the scene. Time information such as optical flow can be used to recognize movement. Existing optical flow calculations are based only on camera sensors and are prone to misunderstanding in low light conditions. In this regard, to improve recognition performance in low-light environments, we applied a normalization filter and a correction function for Gamma Value to the input images. The low light quality improvement algorithm can be applied to confirm the more accurate detection of Object's Bounding Box for the vehicle. It was confirmed that there is an important in object recognition through image prepocessing and deep learning using YOLO."
ROS 기반의 실내자율 주행 로봇의 자기위치 인식 및 딥러닝에 의한 제어 시스템,2021,"['Robot Operating System(로봇 운영 체제)', 'Indoor Self-driving(실내 자율 주행)', 'Automated Guided Vehicle(무인 운반차)', 'LiDAR Sensor(라이다 센서)', 'Inertial Measurement Unit(관성 측정 센서)']","본 연구는 물류 센터 무인화를 위해 상자를 지역, 회사에 따라 분류하고 장애물을 실시간으로 회피하며 목표지점까지 운송하는 로봇 시스템을 개발하는 것을 목표로 하고 있다. 전체 제어 시스템은 ROS(robot operating system)로 구성하였으며, 모터 제어 및 기타 센서 처리를 위해 하부제어기로 OpenCR을 추가하였다. 또한 IMU 센서와 encoder를 결합한 odometry를 기반으로 AMCL(adaptive Monte Carlo localization) 알고리즘을 사용하여 로봇 위치를 추정 및 보정하였다. 또한 이를 LiDAR와 결합하여 맵핑 및 주행(navigation)을 진행하였다. 상자 분류는 YOLO를 통해 진행하였다. 그 결과 상자 분류를 통해 스스로 목표지점을 설정하고 라이더로 장애물을 인식하여 실시간으로 회피하는 자율주행 로봇을 구현하였다.","In this study, an indoor self-driving automated guided vehicle that recognizes objects in a logistics center and transports them to their destinations is introduced. The robot must be aware of its location while it moves and must be able to recognize its surroundings in real time to operate in the self-driving mode. The control system is composed of a robot operating system (ROS) with OpenCR used as a lower controller for motor control and other sensor processing. The robot position is estimated by combining the adaptive Monte Carlo localization algorithm (AMCL) with odometry using an inertial measurement unit sensor and an encoder, and mapping and navigation are performed by combining it with LiDAR. In addition, box classification is conducted through you-only-look-once (YOLO) object detection. Consequently, we implement a self-driving robot that sets its own target point through box classification and avoids obstacles in real time by recognizing obstacles with LiDAR."
자율주행 차량 영상 기반 객체 인식 인공지능 기술 현황,2021,"['객체 인식', '자율주행 차량', '영상 기반 인공지능', '단일 단계 검출', '두 단계 검출', 'Object detection', 'Autonomous vehicle', 'Image-based AI', 'Single-step detection', 'Two-step detection.']","객체 인식이란 하나의 특정 이미지를 입력했을 때, 주어진 이미지를 분석하여 특정한 객체(object)의 위치(location)와 종류(class)를 파악하는 것이다. 최근 객체 인식 기술이 적극적으로 접목되는 분야 중 하나는 자율주행 차량이라 할 수 있고, 본 논문에서는 자율주행 차량에서 영상 기반의 객체 인식 인공지능 기술에 대해 기술한다. 영상 기반 객체 검출 알고리즘은 최근 두 가지 방법(단일 단계 검출 방법 및 두 단계 검출 방법)으로 좁혀지고 있는데, 이를 중심으로 분석 정리하고자 한다. 두 가지 검출 방법의 장단점을 분석 제시하고, 단일 단계 검출 방법에 속하는 YOLO/SSD 알고리즘과 두 단계 검출 방법에 속하는 R-CNN/Faster R-CNN 알고리즘에 대해 분석 기술한다. 이를 통해 자율주행에 필요한 각 객체 인식 응용에 적합한 알고리즘이 선별적으로 선택되어 연구개발 되어질 수 있기를 기대한다.","Object recognition is to identify the location and class of a specific object by analyzing the given image when a specific image is input. One of the fields in which object recognition technology is actively applied in recent years is autonomous vehicles, and this paper describes the trend of image-based object recognition artificial intelligence technology in autonomous vehicles. The image-based object detection algorithm has recently been narrowed down to two methods (a single-step detection method and a two-step detection method), and we will analyze and organize them around this. The advantages and disadvantages of the two detection methods are analyzed and presented, and the YOLO/SSD algorithm belonging to the single-step detection method and the R-CNN/Faster R-CNN algorithm belonging to the two-step detection method are analyzed and described. This will allow the algorithms suitable for each object recognition application required for autonomous driving to be selectively selected and R&D."
"광주광역시 AI 산업 생태계를 위한 연합학습, 추천시스템 및 객체 인식의 사전 연구 및 테스트 분석",2021,"['AI', 'Federated Learning', 'Recommendation System', 'Object Recognition', 'AI industry ecosystem in GwangJu Metro-city']","4차 산업혁명의 열풍이 사그라들며 현실성이 떨어지는 상황에서 기업은 디지털 트랜스포메이션이 필요하다. 본 연구에서는 광주광역시 AI 산업 생태계의 디지털 트랜스포메이션을 위한 기술인 연합학습, 추천시스템 및 객체 인식을 소개 및 테스트를 진행하였다. 연합학습에서는 다수의 클라이언트로 Jetson Xavier NX을 사용하여 클라이언트가 늘어날수록 학습 모델의 정확도가 증가하는가를 검증하기 위한 테스트를 진행하였다. 추천시스템은 종류별로 소개 및 테스트를진행하였으며 객체 인식의 경우 Yolo를 사용하여 사과이미지 학습 및 객체 인식 테스트를 진행하였다.","Enterprises need digital transformation in a situation where the 4th industrial revolution's craze is fading and reality is declining. In this study, federated learning, recommendation system, and object recognition, which are technologies for digital transformation of AI industry ecosystem in Gwangju metro-city, were introduced and tested. In federated learning, tests were performed using multiple clients as Jetson Xavier NX to verify the accuracy of the training model increases as the number of clients increases. The recommendation system was introduced and tested by type, and in the case of object recognition, apple image learning and object recognition tests were performed using YOLO."
다중화면 감시 영상에서의 인물 재인식 기술에 관한 연구,2021,"['K-mean', '다중화면 영상', '객체 인식', 'Bhattacharyya distance', 'Mask-RCNN', 'K-mean', 'multi-view videos', 'object recognition', 'Bhattacharyya distance', 'Mask-RCNN']","감시 카메라는 모니터링, 스마트 시티, 화상 회의 등 여러 가지 도메인에 설치되어 사용되고 있다. 영상데이터에서 객체 탐지, 추적 및 인식과 같은 여러 작업을 수행하기 위해서는 분산 네트워크를 사용하여 알고리즘을 개발하는 것 이 필수적이다. 이를 위해 컴퓨터 영상 분야에서 단일화면에서의 이미지 및 영상분석을 위한 수많은 기술이 개발되 었다. 그러나 영상데이터 분석 분야의 논문을 살펴보면 다중화면에서의 영상분석 기술에 대한 연구는 드물다. 따라 서 본 논문에서는 일반적으로 단일화면 영상분석에 적용되는 여러 기법의 하이브리드 접근을 통해 다중화면 영상에 서 사람을 재식별하고 추적하는 방법을 제안하였다. 먼저 자체 데이터 세트를 생성하였으며, 전처리 단계를 거친 이 미지에서 YOLO를 사용하여 인물을 감지하고 Mask-RCNN을 통해 배경을 삭제하였다. 다음으로 K-Means Clustering 알고리즘을 적용하여 각각의 이미지에서 색상 특징을 추출하였다. 마지막으로 Bhattacharyya distance에 가중치를 추가하여 두 개의 이미지 클러스터 간의 유사성을 측정하는 새로운 거리 지정 알고리즘을 제 안하였다. 제안된 방법은 실험결과 86.23 평균 정밀도를 얻었으며 제안된 방법의 효과를 검증 및 확인하였다.","Nowadays, surveillance cameras are widely installed at every edge due to their largescale applications ranging from monitoring to smart city and indoor offices for video conferencing. However, to perform several tasks such as detection, tracking, and identification of persons in video data, it is an essential step to develop an algorithm specifically using a distributed network. For this purpose, numerous techniques have been developed in the field of computer vison for single-view images/video analysis. However, overviewing the literature of video data analytics, the techniques for multi-view analysis are missing on extreme level. Therefore, in this paper, we propose a method for person re-identification and tracking in multi-view images through hybrid approach of several techniques that are usually applied for a single-view image. At first, we generate our own dataset and pass the images into a preprocessing step to detect person using YOLO and subtract the background through Mask-RCNN. Next, the color features are extracted from the images which are fed into K-mean clustering algorithm. We introduce a novel distancing formula by adding weights to Bhattacharyya’s distance to measure the similarity between the clusters of two multi-view input images. The conducted experiments verify and confirm the affectiveness of the proposed method by obtaining 86.23 average precision."
딥러닝 기반 이미지 처리를 이용한 통행 차량 높이검출 시스템,2021,"['Deep Learning', 'Height Detection', 'Image Process', 'RCNN', 'Yolo V3']","4차 산업 혁명의 시대가 열리면서, 인공지능을 활용한 연구에 관심이 증가하고 있다. 본 연구에서는 최근 들어 차량의 높이가 점차적으로 높아짐에 따라 발생하는 충돌 사고를 방지하고자 인공지능을 활용하여 차량의 높이를 사전에 정확히 측정하는 시스템을 개발하고자 한다. 본 연구에서는 Yolo V3, Mask RCNN 등을 사용한 딥러닝 방식으로 차량의 높이 측정 시스템을 개발하였다. Yolo V3를 사용하여 픽셀을 대상 영역을 추출하였다. 또한, 픽셀의 대상 영역과 빈 영역에 대한 학습은 Mask RCNN을 사용하여 수행하였다. 특히, 기존 차량의 높이 데이터(1300~2000 mm, 총 63679 개)와 보정계수를 사용하여 측정 시스템의 정확도가 98 % 이상임을 확인하였다. 본 연구 결과는 차량의 높이를 미리 정확히 예측함으로써, 지하차도, 다리 등에서의 충돌 사고를 사전에 방지하는 시스템 또는 구조물을 설치할 수 있을 것으로 예상한다. 또한, 제조업체는 진입하는 차량의 높이를 사전에 예측하는 시스템 개발 시, 시행착오를 방지하고 개발 시간 및 비용을 절감할 수 있을 것으로 예상한다.","As the era of the 4th industrial revolution opens, interest in research using artificial intelligence is increasing. In this study, we developed a system that accurately measures the height of a vehicle using artificial intelligence in order to prevent collisions that occur as the heights of vehicles have gradually increased in recent years. In this study, a vehicle height-measurement system was developed using a deep learning method with Yolo V3, Mask RCNN, etc. The target area was extracted from a pixel by Yolo V3. In addition, learning for the target area and the empty area of a pixel was performed using Mask RCNN. It was confirmed that the accuracy of the measurement system was 98% or higher by using the height data of existing vehicles (1300-2000 mm, 63679 units in total) and a correction factor. The results of this study are expected to be used to install a system or structure that prevents collisions in underground roadways and bridges by accurately predicting the height of the vehicle. In addition, when developing a system that predicts the height of an entering vehicle, manufacturers are expected to avoid trial and error as well as reduce development time and cost."
보행자검출을 통한 상권 분석 알고리즘,2021,"['보행자 검출', 'YOLO', '상권', '빅데이터', '딥러닝', 'Pedestrian-Detection', 'YOLO', 'business district', 'big data', 'deep learning']",,"In this paper, we propose an algorithm that provide services to consumers who want to conduct business by scientifically and systematically analyzing the number of pedestrians in a specific area over a specific period of time. In this paper, we proposed the algorithm to analyze the commercial area using the pedestrian-detect algorithm in the particular region using YOLO, one of the deep learning techniques. And with one image per minute in the images, the number of pedestrians is identified and this information is used for the analysis of business district on interesting area and time, systematically and objectively."
2차사고 방지를 위한 차량 간 커뮤니케이션 시스템 구현,2021,"['grouping', 'cloud server', 'object detection', 'YOLO', 'GPS']",,"In this paper, we implement a vehicle-to-vehicle communication system to reduce secondary accidents in vehicles using YOLO and GPS based on a cloud environment. When an accident occurs, the client recognizes the accident through YOLO and transmits the event video data related to the accident to the cloud server. The server calculates the distance of each subscribed client based on the GPS coordinates from the accident location. In addition, clients close to the accident point are grouped, and the accident data is shared within the same group members. In this way, this paper implements a system that can apply the theoretically researched technologies to actual vehicles by comprehensively utilizing technologies such as image recognition, GPS, Cloud Server and IoT networking, as well as the newly proposed grouping technique."
딥러닝 기반 제조 공장 내 AGV 객체 인식에 대한 연구,2021,[],,"In this research, the accuracy of YOLO v3 algorithm in object detection during AGV (Automated Guided Vehicle) operation was investigated. First of all, AGV with 2D LiDAR and stereo camera was prepared. AGV was driven along the route scanned with SLAM (Simultaneous Localization and Mapping) using 2D LiDAR while front objects were detected through stereo camera. In order to evaluate the accuracy of YOLO v3 algorithm, recall, AP (Average Precision), and mAP (mean Average Precision) of the algorithm were measured with a degree of machine learning. Experimental results show that mAP, precision, and recall are improved by 10%, 6.8%, and 16.4%, respectively, when YOLO v3 is fitted with 4000 training dataset and 500 testing dataset which were collected through online search and is trained additionally with 1200 dataset collected from the stereo camera on AGV."
스마트폰 사진촬영을 통한 정보유출 보호시스템에 관한 연구,2021,"['YOLO', 'Image processing', 'Object detection', 'Machine learning', 'Deep learning', 'Information leakage']",,"In general, information leakage security can be divided into areas that respond to threats from outsiders such as hacking or malicious code, and areas that respond to threats from insiders such as data leakage from inside to outside. Various solutions such as firewalls, VPNs, and virtualization systems are introduced to respond to threats from outsiders, and as a result, the number of cases of information leakage caused by threats from outsiders is greatly reduced. However, information leakage through threats from insiders is more damaging than threats from outsiders, making it difficult to detect in advance, and the amount of damage after information leakage can be much larger. In order to prevent information leakage through smartphone filming, which is one of insider's information leakage path, it currently uses hardware, smartphone camera security stickers, screen security films, and software uses smartphone MDM (Mobile Device Management) solutions to limit functions such as smartphone photography and data communication. In this paper, we propose a study on the information leakage protection system through smartphone shooting by installing a camera on a PC with access to sensitive information, collecting video information from cameras and designing a smartphone object detection algorithm. For this purpose, the camera is installed at the top of the center of the screen. Image frames are transmitted in real time from camera. In addition, real-time object detection is possible using YOLO, which has fast computational speed. The purpose of this paper is to develop a system for detecting smartphone objects from video information inputted from cameras. As a result, information leakage can be protected by taking pictures of smartphones."
Deep learning-based oil spill detection with LWIR camera,2021,"['Oil spill detection', 'YOLO', 'Object detection', 'Infrared imaging']",,"The ocean covers approximately 71% of the total surface area of Earth and plays a significant role in maintaining the envi-ronment and ecosystems. Oil spills are the largest source of pollution in the ocean, mainly Bunker C oil and diesel oil used as vessel fuels. Therefore, oil spill detection is essential for marine protection, which motivated this study. Detection with radar, which is based on electromagnetic waves, is achieved using satellite synthetic aperture radar (SAR); thus, real-time detection over a small range is difficult. Hence, in this study, an oil spill detection system based on thermal imaging using a long-wave infrared (LWIR) camera is proposed. The oil spill detection algorithm utilizes the You Only Look Once (YOLO) model, which is widely used for object detection. In addition, 1,644 thermal images were labeled to evaluate the proposed system. The training and test results showed an accuracy of 96.91% and false alarm rate of 8.33%. An improved detection performance can be expected from subsequent experiments using larger image datasets."
Development of IoT System Based on Context Awareness to Assist the Visually Impaired,2021,"['IoT System', 'Object Detection', 'Walking Aids', 'Yolo-v3', 'Visually Impaired']",,"As the number of visually impaired people steadily increases, interest in independent walking is also increasing. However, there are various inconveniences in the independent walking of the visually impaired at present, reducing the quality of life of the visually impaired. The white cane, which is an existing walking aid for the visually impaired, has difficulty in recognizing upper obstacles and obstacles outside the effective distance. In addition, it is inconvenient to cross the street because the sound signal to help the visually impaired cross the crosswalk is lacking or damaged. These factors make it difficult for the visually impaired to walk independently. Therefore, we propose the design of an embedded system that provides traffic light recognition through object recognition technology, voice guidance using TTS, and upper obstacle recognition through ultrasonic sensors so that blind people can realize safe and high-quality independent walking."
머신러닝 기반의 물체 인식을 이용한 실시간 주차장 정보 제공 서비스,2021,"['Computer vision', 'Object detection', 'Real-Time', 'Yolo']",,"In this thesis, we intend to use CCTVs installed in existing parking lots to understand the current status of parking lots and provide real-time information to users through Android applications. It describes how to set the ROI in the parking area using YOLO V3 and how to provide the number of vacancies that change in real time through the set ROI, and describes how to link CCTV-server-user using IMAGE ZMQ and FIREBASE. The user can know the real-time situation of the parking lot near the destination before arriving through the application and can come up with various measures accordingly."
금속 3D 프린팅 공정의 결함 분석,2021,"['Metal 3D printing', 'Melting pool tomography', 'Cross-sectional analysis', 'Object detection', 'YOLO']",,"Metal 3D printing is attracting attention as a new production technology. However, various problems need to be solved regarding it. In particular, defects occurring in the process of melting and solidification are relatively serious than those occurring in the traditional casting or cutting process. To solve this problem, this study introduced a tomography using a high-speed camera that can monitor the melting pool. This confirmed the possibility of finding defects by detecting an abnormality in the melting pool. In addition, if it is combined with the YOLO model, which is the latest object detection algorithm, it is judged that the integrity of the parts produced by the casting or cutting process can be secured by stopping or recovering the process through real-time inspection."
블랙박스 영상 기반 차량 및 배경 대체 영상을 이용한 실시간 MR 콘텐츠의 설계,2021,"['차량용 블랙박스', '차량 검출', '대체 영상', 'MR', '딥러닝', 'YOLO', 'Vehicle Black Box', 'Vehicle Detection', 'Substitute Video', 'MR', 'Deep Learning', 'YOLO']",,
딥러닝 기반 도로위험객체 자동 인식 및 분류에 관한 연구,2021,"['객체 인식', '객체 분류', '딥러닝', '도로위험객체', 'Recognition', 'Classificatioin', 'Deep Learning', 'Road Dangerous Object', 'YOLO']",,"Various dangerous road objects such as potholes, falling objects, roadkills occur frequently on road, and the best way to prevent accidents from these dangers is to find them as soon as possible. A lot of mobile applications to report the road problems have been developed and in service worldwide both in public and private sectors. It is not safe, however, to report the problem using those apps in road environment, and it is necessary to develop a technology to minimize the time to make a report using the apps. For this purpose, a method to recognize and classify the road dangerous objects automatically from road images using deep learning algorithm was proposed and implemented, and the performance of the proposed model(YOLO v3) was tested, which shows 95% success rate on average to detect the four categories of road dangers including pavement, drainage, road facility, and roadkill, and demonstrates the possibility of the proposed method."
선삭공정에서 딥러닝 영상처리 기법을 이용한 작업자 위험 감소 방안 연구,2021,"['Deep Learning(딥러닝)', 'Vision System(영상처리 시스템)', 'Negligent Accident(안전사고)', 'Convolutional Neural Network(CNN)(컨볼루션신경망)', 'You Only Look Once(YOLO)(욜로)']",,"The deep learning image processing technique was used to prevent accidents in lathe work caused by worker negligence. During lathe operation, when the chuck is rotated, it is very dangerous if the operator""s hand is near the chuck. However, if the chuck is stopped during operation, it is not dangerous for the operator’s hand to be in close proximity to the chuck for workpiece measurement, chip removal or tool change. We used YOLO (You Only Look Once), a deep learning image processing program for object detection and classification. Lathe work images such as hand, chuck rotation and chuck stop are used for learning, object detection and classification. As a result of the experiment, object detection and class classification were performed with a success probability of over 80% at a confidence score 0.5. Thus, we conclude that the artificial intelligence deep learning image processing technique can be effective in preventing incidents resulting from worker negligence in future manufacturing systems."
다양한 배경에서 도형과 색상을 활용한 얼굴 검출,2021,"['Facial Region Detection', 'Face Detection', 'Open CV', 'Image Processing', 'Character Classification', '얼굴 영역 감지', '얼굴 탐지', '이미지 처리', '인물 분류']","본 논문에서는 영상 속 인물을 탐지하고 얼굴 영역을 검출하는 방법을 제안하며, 이 방법은 2가지 작업으로 구성한다. 첫째, 서로 다른 두 명의 인물을 구분하여 프레임 내 인물의 얼굴 위치를 탐지한다. 빠른 탐지를 위해 영상 내 물체를 실시간으로 검출하는 YOLO(You Only Look Once)를 이용하여 얼굴의 위치를 탐지하고 객체탐지상자로 나타낸다. 둘째, 객체탐지상자를 바탕으로 정확한 얼굴 면적을 검출하기 위해 3가지 영상처리 방법을 제시한다. 각 방법은 검출 도형으로 추정한 영역에서 추출한 HSV 값을 이용하여 인물의 얼굴 영역을 검출하였으며 검출 도형의 크기와 모양을 바꾸어 각 방법의 정확도를 비교하였다. 각 얼굴 검출 방법은 신뢰성 검증을 위해 비교 데이터와 영상처리 데이터로 비교 및 분석하였다. 그 결과 원형, 직사각형, 분할 직사각형 방법 중 분할된 직사각형 방법을 사용했을 때 87%로 가장 높은 정확도를 달성하였다.","In this paper, we propose a method for detecting characters in images and detecting facial regions, which consists of two tasks. First, we separate two different characters to detect the face position of the characters in the frame. For fast detection, we use You Only Look Once (YOLO), which finds faces in the image in real time, to extract the location of the face and mark them as object detection boxes. Second, we present three image processing methods to detect accurate face area based on object detection boxes. Each method uses HSV values extracted from the region estimated by the detection figure to detect the face region of the characters, and changes the size and shape of the detection figure to compare the accuracy of each method. Each face detection method is compared and analyzed with comparative data and image processing data for reliability verification. As a result, we achieved the highest accuracy of 87% when using the split rectangular method among circular, rectangular, and split rectangular methods."
심층학습 기반의 자동 객체 추적 및 핸디 모션 제어 드론 시스템 구현 및 검증,2021,"['Deep learning', 'Handy motion control', 'Object detection and tracking', 'Intelligent drone system']",,"In this paper, we implemented a deep learning-based automatic object tracking and handy motion control drone system and analyzed the performance of the proposed system. The drone system automatically detects and tracks targets by analyzing images obtained from the drone's camera using deep learning algorithms, consisting of the YOLO, the MobileNet, and the deepSORT. Such deep learning-based detection and tracking algorithms have both higher target detection accuracy and processing speed than the conventional color-based algorithm, the CAMShift. In addition, in order to facilitate the drone control by hand from the ground control station, we classified handy motions and generated flight control commands through motion recognition using the YOLO algorithm. It was confirmed that such a deep learning-based target tracking and drone handy motion control system stably track the target and can easily control the drone."
Object-wise Secure Image Display Method for Screen Capture Protection,2021,"['Screen capture', 'Secure image display', 'Object detection', 'Screen shot', 'Virtual fence']",,"In this study, we propose an image copyright protection technology to prevent analog hole attacks using a deep object detection network. Instead of applying a virtual fence to the whole image, only a region of copyright is protected with fences. The region of copyright interest is called the protection zone and is generated by merging bounding boxes found with a YOLO network. The protection zone is adjusted to satisfy the fence generation rules, and then the virtual fence is finally applied. The main goal of this study is to attenuate the image degradation caused by virtual fences while preserving copyright protection capability. Since the virtual fence method uses the afterimage effect of the human visual system, it is necessary to generate images perceived by a human eye at every moment in order to calculate the objective image quality compared to the original unprotected image. Perceived images are generated at every 0.001 seconds using the mathematical model of the afterimage effect. The protection zone is found using object bounding boxes detected using a YOLO deep neural network. We applied the proposed method to four animation images, and the simulation results show that it achieves image quality that is about 3dB better than that of other methods."
카메라-라이다 센서 융합을 통한 VRU 분류 및 추적 알고리즘 개발,2021,[],,"This paper presents an vulnerable road user (VRU) classification and tracking algorithm using vision and LiDAR sensor fusion method for urban autonomous driving. The classification and tracking for vulnerable road users such as pedestrian, bicycle, and motorcycle are essential for autonomous driving in complex urban environments. In this paper, a real-time object image detection algorithm called Yolo and object tracking algorithm from LiDAR point cloud are fused in the high level. The proposed algorithm consists of four parts. First, the object bounding boxes on the pixel coordinate, which is obtained from YOLO, are transformed into the local coordinate of subject vehicle using the homography matrix. Second, a LiDAR point cloud is clustered based on Euclidean distance and the clusters are associated using GNN. In addition, the states of clusters including position, heading angle, velocity and acceleration information are estimated using geometric model free approach (GMFA) in real-time. Finally, the each LiDAR track is matched with a vision track using angle information of transformed vision track and assigned a classification id. The proposed fusion algorithm is evaluated via real vehicle test in the urban environment."
실내 비행용 소형 충돌회피 멀티콥터 시스템 개발,2021,"['UAV', 'Drone', 'Collision Avoidance', 'Obstacle Avoidance', 'Pixhawk', 'Multicopter', '무인항공기', '드론', '충돌회피', '장애물회피', '픽스호크', '멀티콥터']","최근 멀티콥터는 비행 안정성 향상을 위해 다양한 충돌회피 센서를 탑재하고 있다. LiDAR를 이용해 3차원 위치를 인식하거나 다수 카메라와 실시간 SLAM 기술을 이용해 장애물과의 상대 위치를 계산하기도 한다. 또한 소형 프로세스와 카메라로 구성된 3D 깊이 센서를 사용하기도 한다. 본 연구에서는 충돌회피 소프트웨어 기술 개발을 위한 플랫폼으로써 상용 부품을 활용해 실내 비행이 가능한 소형 충돌회피 멀티콥터 시스템을 개발하였다. 멀티콥터 시스템은 LiDAR, RealSense, GPU 보드를 탑재하였고, 비행시험을 통해 YOLO 알고리즘 기반의 사물 인식 및 충돌회피 기능을 검증하였다. 이 논문에서는 시스템 설계/제작 및 탑재 장비 선정과정, 비행시험 결과에 관해 기술하였다.","Recently, multi-copters equipped with various collision avoidance sensors have been introduced to improve flight stability. LiDAR is used to recognize a three-dimensional position. Multiple cameras and real-time SLAM technology are also used to calculate the relative position to obstacles. A three-dimensional depth sensor with a small process and camera is also used. In this study, a small collision-avoidance multi-copter system capable of in-door flight was developed as a platform for the development of collision avoidance software technology. The multi-copter system was equipped with LiDAR, 3D depth sensor, and small image processing board. Object recognition and collision avoidance functions based on the YOLO algorithm were verified through flight tests. This paper deals with recent trends in drone collision avoidance technology, system design/manufacturing process, and flight test results."
인공지능 기반 EL 이미지의 태양전지 및 모듈의 결함검출 연구,2021,"['태양전지(Solar Cells)', '태양광 모듈(PV Modules)', '전계발광(Electroluminescence', 'EL)', '인공지능(Artificial Intelligence', 'AI)', '결함 검출(Detect Detection)']",,"Currently, investment is being made in renewable energy for the transition to a low-carbon economy and society, and interest in solar energy is also increasing. In addition to the technological development of solar cells and photovoltaic (PV) modules, research in the field of convergence with artificial intelligence technology is being actively conducted. Defects occurring in the manufacturing process of solar cells and modules can be detected through electroluminescence (EL) measurements. In this study, we propose an artificial intelligence technology that can automatically detect defects in cells and modules in real time using EL image data of solar cells and modules in the manufacturing process. For EL defect detection, we propose an algorithm with high suitability in terms of speed and accuracy by applying deep learning-based object detection models and comparing and evaluating detection performance. In the case of the YOLO (you only look once) algorithm, which belongs to a one-step detector, it learns In the case of the YOLO (you only look once) algorithm, which belongs to a one-step detector, it learns through an optimization process to find information about the defect and the location information of the corresponding failure in the form of a bounding box, and then detects the failure based on this information. The introduction of a deep learning-based defect detection model in the manufacturing process is expected to reduce the time required for defect detection by solar cell and PV module manufacturers and contribute to productivity improvement."
An Improvement of Deep Learning-based Object Detection Scheme for Game Scenes,2021,"['object detection', 'game scene', 'deep learning', 'YOLOv2']","본 연구에서는 게임 영상과 같은 생성된 영상으로부터 물체를 인식하는 심층 학습 기반 모델의 성능을 향상시키는 방법을 제시한다. 특히, 실제 영상으로 훈련된 물체 인식 모델에 대해서 게임 영상으로 추가 훈련을 수행함으로써 물체 인식 성능이 향상됨을 검증한다. 본 연구에서는 심층 학습 기반의 물체 인식 모델들 중에서 가장 널리 사용되는 YoloV2 모델을 이용한다. 이 모델에 대해서 8 종류의 다양한 게임에서 샘플링한 160장의 게임 영상을 적용해서 물체 인식 모델을 다시 훈련하고, IoU와 정확도를 측정해서 본 연구에서 주장하는 게임영상을 이용한 훈련이 효과적임을 입증한다.","We present a framework that improves the performance of deep learning-based object detection model for generated images including game scenes. In particular, we aim to verify that the additional training using images sampled from game scenes can improve the performance of the object detection model, which was pre-trained using photographs. Among the various object detection schemes including Yolo V1, Yolo V2 and SSD, we employ YoloV2 model, which is one of the most widely used deep learning-based object detection model. YoloV2 model is pretrained using diverse photographs. This model is further trained through 160 game scene images sampled from eight different kinds of games. We select the games that range from realistic scenes and highly deformed scenes. We measure IoU (intersection over union) and accuracy using this model. The comparison between our re-trained model and the original model demonstrates the effectiveness of our strategy."
딥러닝 기반 활주로 청소 로봇 개발,2021,"['YOLO', 'Deep Learning', 'Real Time Object Detection', 'FOD (Foreign Object Debris)', 'Runway Cleaning Robot']",,"This paper deals with the development of a deep-learning-based runway cleaning robot using an optical camera. A suitable model to realize real-time object detection was investigated, and the differences between the selected YOLOv3 and other deep learning models were analyzed. In order to check whether the proposed system is applicable to the actual runway, an experiment was conducted by making a prototype of the robot and a runway model. As a result, it was confirmed that the robot was well developed because the detection rate of FOD (Foreign Object Debris) and cracks was high, and the collection of foreign substances was carried out smoothly."
스트리트뷰 영상의 객체탐지를 활용한 보행 장애물 정보 갱신,2021,"['Object Detection', 'Deep Learning', 'YOLO', 'OpenStreetMap', 'Pedestrian Network', 'Map Update', '객체탐지', '딥러닝', '욜로', '오픈스트리트맵', '보행 네트워크', '지도 갱신']",,
Honeybee In-Out Monitoring System by Object Recognition and Tracking from Real-Time Webcams,2021,"['Honeybee', 'Monitoring', 'Beehive gate', 'YOLO', 'DeepSORT']",,"A new honeybee in-out monitoring system is proposed using real-time deep-learning based image recognition and tracking. The specific design of beehive gate is turned out to be an important factor for accurate bee movement monitoring. We check a series of beehive gate designs for the monitoring system. A novel gate design employing heart valve structure is proposed for ensuring one-way traffic for the bees as well as one-at-a-time gate passing, resulting in an improved bee detection accuracy. As for the deep-learning based image recognition framework, YOLOv4 is used in the proposed system for a better honeybee-detection accuracy as well as a faster detection in comparison to YOLOv3 which was employed for our previous study. In addition, DeepSORT algorithm is employed for a reliable tracking of the detected honeybees. In our experiments the proposed honeybee monitoring system exhibited 99.5% detection accuracy, while our previous system resulted in 97.5% in the same settings."
Aerial Dataset Integration For Vehicle Detection Based on YOLOv4,2021,"['Vehicle Detection', 'Aerial Image', 'YOLO', 'VAID', 'UAVD', 'DOTA']",,"With the increasing application of UAVs in intelligent transportation systems, vehicle detection for aerial images has become an essential engineering technology and has academic research significance. In this paper, a vehicle detection method for aerial images based on the YOLOv4 deep learning algorithm is presented. At present, the most known datasets are VOC (The PASCAL Visual Object Classes Challenge), ImageNet, and COCO (Microsoft Common Objects in Context), which comply with the vehicle detection from UAV. An integrated dataset not only reflects its quantity and photo quality but also its diversity which affects the detection accuracy.The method integrates three public aerial image datasets VAID, UAVD, DOTA suitable for YOLOv4. The training model presents good test results especially for small objects, rotating objects, as well as compact and dense objects, and meets the real-time detection requirements. For future work, we will integrate one more aerial image dataset acquired by our lab to increase the number and diversity of training samples, at the same time, while meeting the real-time requirements."
운전자 및 동승자 머리 자세 추정 및 딥러닝을 이용한 교통사고 모니터링 시스템,2021,"['Car Accident Detection', 'Deep Learning', 'YOLO', 'Head Pose Estimation', 'HSV']",,
객체 검출을 위한 통계치 적응적인 선형 회귀 기반 객체 크기 예측,2021,"['Object Detection', 'Statistics Adaptive Linear Regression', 'YOLO']",,"This paper proposes statistics adaptive linear regression-based object size prediction method for object detection. YOLOv2 and YOLOv3, which are typical deep learning-based object detection algorithms, designed the last layer of a network using statistics adaptive exponential regression model to predict the size of objects. However, an exponential regression model can propagate a high derivative of a loss function into all parameters in a network because of the property of an exponential function. We propose statistics adaptive linear regression layer to ease the gradient exploding problem of the exponential regression model. The proposed statistics adaptive linear regression model is used in the last layer of the network to predict the size of objects with statistics estimated from training dataset. We newly designed the network based on the YOLOv3tiny and it shows the higher performance compared to YOLOv3 tiny on the UFPR-ALPR dataset."
딥러닝 기반 객체 탐지 알고리즘을 이용한 대장내시경 용종 탐지 시스템,2021,"['Colonoscopy', 'AutoAugment', 'CADｘ', 'Polyp Detection', 'YOLO']",,"In Korea, colon cancer is increasing due to westernized eating habits. Colonoscopy is being used to reduce deaths from colon cancer and studies of CADx(Computer-aided Diagnosis) are being developed to improve accuracy. Due to the nature of medical data, it was difficult to collect a lot of data, so data was increased 25 times using AutoAugment’s CIFAR-10 policy, and YOLOv4(You Only Look Once), a real-time object detection algorithm, was used to detect lesions. A new object detection algorithm, YOLOv4, use new eight features such as Weighted-Residual-Connections, Cross-Stage-Partial-connections, Cross mini-Batch Normalization and Self-Adversarial-Training. The performance of augmented data had a maximum mAP of 27.44 higher than the original data. The average IoU(Intersection over Union) was 11.44 higher than the original data. When the IoU value is 0.5, the F1-scores of the original data and the augmented data are 0.9 and 0.97 respectively."
멧돼지에 의한 농작물 피해 방지를 위한 유해조수 퇴치 시스템,2021,"['Wild Animals', 'Wild Boars', 'Repellent', 'Real-Time', 'YOLO', 'Deep Learning', 'Pattern Recognition']",,
딥러닝을 이용한 육불화텅스텐(WF6) 제조 공정의 지능형 영상 감지 시스템 구현,2021,"['object detection', 'you only look once (YOLO)', 'tungsten hexafluoride (WF6)', 'reduction', 'defect detection.']",,"Through the process of chemical vapor deposition, Tungsten Hexafluoride (WF6) is widely used by the semiconductor industry to form tungsten films. Tungsten Hexafluoride (WF6) is produced through manufacturing processes such as pulverization, wet smelting, calcination and reduction of tungsten ores. The manufacturing process of Tungsten Hexafluoride (WF6) is required thorough quality control to improve productivity. In this paper, a real-time detection system for oxidation defects that occur in the manufacturing process of Tungsten Hexafluoride (WF6) is proposed. The proposed system is implemented by applying YOLOv5 based on Convolutional Neural Network (CNN); it is expected to enable more stable management than existing management, which relies on skilled workers. The implementation method of the proposed system and the results of performance comparison are presented to prove the feasibility of the method for improving the efficiency of the WF6 manufacturing process in this paper. The proposed system applying YOLOv5s, which is the most suitable material in the actual production environment, demonstrates high accuracy (mAP@0.5 99.4 %) and real-time detection speed (FPS 46)."
스테레오 비전과 YOLOv3 를 이용한 드론의 3 차원 실내 위치 추정 알고리즘 개발,2021,"['Position estimation', 'YOLOv3', 'Stereo vision', 'Depth map', 'Kalman filter', 'Object detection']",,"In this paper, we propose a three-dimensional indoor position estimation algorithm for drones using stereo vision and YOLOv3. First, we find the bounding box of a drone in the image using a deep-learning-based object detection algorithm called YOLOv3. To this end, we collect the training dataset consisting of drone images. In addition, the object detection performance of the YOLOv3 algorithm is improved by dividing object class labels of the same drone based on the angle of the drone seen from the camera. Then, the three-dimensional relative position of the drone is estimated based on the camera internal parameters, the bounding box information, and the depth map taken by the stereo vision. In addition, the Kalman filter is employed to estimate the position of the drone continuously. Finally, the position estimation performance of the proposed algorithm is evaluated through the experiments."
RAVIP: Real-Time AI Vision Platform for Heterogeneous Multi-Channel Video Stream,2021,"['Multi-Channel', 'Multi-Stream', 'Object Detection', 'Surveillance Systems', 'Vision']",,"Object detection techniques based on deep learning such as YOLO have high detection performance and precision in a single channel video stream. In order to expand to multiple channel object detection in real-time, however, high-performance hardware is required. In this paper, we propose a novel back-end server framework, a real-time AI vision platform (RAVIP), which can extend the object detection function from single channel to simultaneous multi-channels, which can work well even in low-end server hardware. RAVIP assembles appropriate component modules from the RODEM (real-time object detection module) Base to create perchannel instances for each channel, enabling efficient parallelization of object detection instances on limited hardware resources through continuous monitoring with respect to resource utilization. Through practical experiments, RAVIP shows that it is possible to optimize CPU, GPU, and memory utilization while performing object detection service in a multi-channel situation. In addition, it has been proven that RAVIP can provide object detection services with 25 FPS for all 16 channels at the same time."
특징 융합과 공간 강조를 적용한 딥러닝 기반의 개선된 YOLOv4S,2021,"['Object Detection', 'Spatial attention', 'Deep learning', 'Feature fusion', 'PAN', 'YOLO', '객체 검출', '공간 강조', '딥러닝', '특징 융합', '특징 피라미드', '욜로']","본 논문은 특징 융합과 공간 강조를 적용하여 작고 페색된 객체 검출을 위한 개선된 YOLOv4S를 제안하였다. 기존 YOLOv4S은 경량 네트워크로 깊은 네트워크 대비 특징 추출 능력 부족하다. 제안하는 방법은 먼저 feature fusion으로 서로 다른 크기의 특징맵을 결합하여 의미론적 정보 및 저수준 정보를 개선하였다. 또한, dilated convolution으로 수용 영역을 확장하여 작고 폐색된 객체에 대한 검출 정확도를 향상시켰다. 두 번째로 spatial attention으로 기존 공간 정보 개선하여 객체간 구분되어 폐색된 객체의 검출 정확도를 향상시켰다. 제안하는 방법의 정량적 평가를 위해 PASCAL VOC 및 COCO 데이터세트를 사용하였다. 실험을 통해 제안하는 방법은 기존 YOLOv4S 대비 PASCAL VOC 데이터세트에서 mAP 2.7% 및 COCO 데이터세트에서 mAP 1.8% 향상되었다.","In this paper proposed a feature fusion and spatial attention-based modified YOLOv4S for small and occluded detection. Conventional YOLOv4S is a lightweight network and lacks feature extraction capability compared to the method of the deep network. The proposed method first combines feature maps of different scales with feature fusion to enhance semantic and low-level information. In addition expanding the receptive field with dilated convolution, the detection accuracy for small and occluded objects was improved. Second by improving the conventional spatial information with spatial attention, the detection accuracy of objects classified and occluded between objects was improved. PASCAL VOC and COCO datasets were used for quantitative evaluation of the proposed method. The proposed method improved mAP by 2.7% in the PASCAL VOC dataset and 1.8% in the COCO dataset compared to the Conventional YOLOv4S."
딥러닝 기반 앙상블을 이용한 마스크 착용 상태 검출 기술 연구,2021,"['콘볼루션 신경망', '마스크 검출', '앙상블', 'Convolutional Neural Network', 'YOLO', 'Mask Detection', 'Ensemble', 'FPN']",,"Due to the COVID-19 incident, demand for a quarantine system that can prevent the spread of the virus has increased. In this paper, a mask wearing state detection technology based on a deep learning-based ensemble is proposed. A model that can detect mask wearing status was created using a deep learning algorithm based on a convolutional neural network. Afclassifying wearing a mask into mask, improper mask, and no mask, the accuracy was improved by constructing learning data for various poses. In addition, the combination of deep learning models through ensemble techniques increased accuracy, and among the methods of diversifying the size of feature maps, FPN techniques were used to increase object detection performance while reducing computation volume. In the future, this study will be used as an efficient quarantine system in indoor environments where ventilation is difficult, and in particular, it will be contributed to establish a quarantine environment so that users can safely use cultural facilities such as performance halls."
YOLOv5에서 가상 번호판 생성을 통한 차량 번호판 인식 시스템에 관한 연구,2021,"['License Plate', 'License Plate Generator', 'LPR(License Plate Recognition)', 'YOLO(You Only Look Once)', 'Object Detection', 'Deep Learning']",,"Existing license plate recognition system is used as an optical character recognition method, but a method of using deep learning has been proposed in recent studies because it has problems with image quality and Korean misrecognition. This requires a lot of data collection, but the collection of license plates is not easy to collect due to the problem of the Personal Information Protection Act, and labeling work to designate the location of individual license plates is required, but it also requires a lot of time. Therefore, in this paper, to solve this problem, five types of license plates were created using a virtual Korean license plate generation program according to the notice of the Ministry of Land, Infrastructure and Transport. And the generated license plate is synthesized in the license plate part of collectable vehicle images to construct 10,147 learning data to be used in deep learning. The learning data classifies license plates, Korean, and numbers into individual classes and learn using YOLOv5. Since the proposed method recognizes letters and numbers individually, if the font does not change, it can be recognized even if the license plate standard changes or the number of characters increases. As a result of the experiment, an accuracy of 96.82% was obtained, and it can be applied not only to the learned license plate but also to new types of license plates such as new license plates and eco-friendly license plates."
비디오 모니터링 환경에서 정확한 돼지 탐지,2021,"['Real-Time Video Monitoring', 'Video Object Detection', 'Pig Detection', 'Image Processing', 'Deep Learning', 'YOLO']",,
YOLOv4와 라즈베리파이 기반 쓰레기 분리배출 자동화 시스템,2021,"['딥러닝', '라즈베리파이', '재활용 쓰레기', '욜로', '욜로 버전4', 'Deep Learning', 'Rasberry Pi', 'Recycling Waste', 'YOLO', 'YOLOv4']",,"This paper proposes an automatic segregation system that classifies waste into 9 classes (can, pet, pen, mouse, paper box, clip, key, vinyl, coffee wrapping plastic alike stick), using the YOLOv4 model and Raspberry Pie. Our system consists of three parts, (1) Waste Classification based on YOLOv4, (2) Waste Disposal based on Rasberry Pie, and (3) Waste Management Application for inspection and retrain. We construct a big waste dataset by crawling data, using public data and making self-product data and improve the model accuracy up to 90%, maintaining the real-time performance of the YOLOv4 model. Our system is optimized in a real environment through various experiments on parameter optimization, data augmentation, and effect on the iteration number of the model train."
딥러닝 기법을 이용한 주차 공간 자동 식별 시스템,2021,"['전이 학습', '텐서플로우 라이트', '티처블 머신', '안드로이드 스튜디오', 'Transfer Learning', 'TensorFlow Lite', 'Teachable Machine', 'Android Studio']","본 논문에서는 촬영된 주차장 사진으로부터 빈 주차 공간을 자동 식별할 수 있는 주차 공간 자동 식별 시스템 에 대해 설명한다. 이 시스템은 딥러닝 기법에 기반한 시스템으로, 다양한 주차장 사진들을 토대로 학습을 진행하여 식별 결과의 정확도가 높으며, 기존의 주차 관리 시스템에 적용할 수 있다. 한편, 본 시스템은 손쉬운 적용 테스트를 위해, 스마트폰용 애플리케이션으로도 개발되었다. 따라서 스마트폰 카메라를 통해 주차장 사진을 찍으면, 촬영된 이 미지를 자동 인식하며 빈 주차 공간을 자동 식별할 수 있다.","In this paper, we describe a parking space identification system that can automatically identify empty parking lot spaces from a parking lot photo. This system is based on a deep learning technique, and the accuracy of the identification result is good by learning various existing parking lot images. It could be applied to the existing parking management system. This system was also developed as a smartphone application for easy testing. Therefore, if you take a picture of a parking lot through a smartphone camera, the captured image is automatically recognized and an empty parking space can be automatically identified."
Vehicle Orientation Detection Using CNN,2021,"['Vehicle Orientation', 'Vehicle Detection', 'Real-Time', 'Convolutional Neural Network(CNN)']",,"Vehicle orientation detection is a challenging task because the orientations of vehicles can vary in a wide range in captured images. The existing methods for oriented vehicle detection require too much computation time to be applied to a real-time system. We propose Rotate YOLO, which has a set of anchor boxes with multiple scales, ratios, and angles to predict bounding boxes. For estimating the orientation angle, we applied angle-related IoU with CIoU loss to solve the underivable problem from the calculation of SkewIoU. Evaluation results on three public datasets DLR Munich, VEDAI and UCAS-AOD demonstrate the efficiency of our approach."
Detection and tracking for the awareness of surroundings of a ship based on deep learning,2021,"['ship awareness', 'object detection', 'deep learning', 'object tracking', 'Kalman filter']",,"To prevent maritime accidents, it is crucial to be aware of the surrounding environment near ships. The images recorded by a camera mounted on a ship could be used for the awareness of other ships surrounding it. In this study, ship awareness was performed using three procedures: detection, localization, and tracking. Initially, ship detection was performed using the deep learning-based detection model, YOLO (You Only Look Once) v3, based on the camera image. A virtual image dataset was constructed using Unity to overcome the difficulty of obtaining camera images onboard with various sizes of ships, and to improve the detection performance. This was followed by the localization procedure in which the position of the horizon on the image was calculated using the orientation information from the ship. Subsequently, the position of the detected ship in the spatial coordinate system was calculated using the horizon information. Following this, the position, course over ground, and speed over ground of the target ships were tracked in the time domain using the extended Kalman filter. A deep learning model that determines the heading of the ship in the image was proposed to utilize abundant information of cameras, and it was used to set the initial value of the Kalman filter. Finally, the proposed method for the awareness of ships was validated using an actual video captured from a camera installed on an actual ship with various encountering scenarios. The tracking results were compared with actual automatic identification system data obtained from other ships. As a result, the entire detection, localization, and tracking procedures showed good performance, and it was estimated that the proposed method for the awareness of the surroundings of a ship, based on camera images, could be used in the future."
Action Recognition Model to Monitor Illegal Dumping using Zoom-In Image Sequence Data,2021,"['Action recognition', 'Distance between camera and human', 'Human detection', 'Object detection', 'Deep learning']",,"In this study, we propose an action recognition model that provides generalized performance regardless of camera location and distance between the camera and human. The proposed model consists of two-stage networks, namely, human detection and action recognition. The proposed method operates on video frames that are resized by a new zoom-in method using pretrained Yolo v3. To use temporal information, which is regarded as a critical factor in action recognition, we adopt the R(2+1)D model, which is a factorized model capable of representing more complex networks. The proposed Zoom-In method yields generalized performance regardless of distance. In an experiment, the proposed method exhibited accuracies of 96.07%, 96.61%, and 94.55% in the short, medium, and long ranges in which our datasets were employed, respectively."
국민안전을 위한 강력범죄 수배차량 검거시스템,2021,[],,"The final goal of this study is to develop a system that can analyze whether a wanted vehicle is a criminal vehicle from images collected from black boxes, smartphones, CCTVs, and so on. Data collection was collected using a self-developed black box. The used data in this study has used a total of 83,753 cases such as the eight vehicle types(truck, RV, passenger car, van, SUV, bus, sports car, electric vehicle) and 434 vehicle models. As a result of vehicle recognition using YOLO v5, mAP was found to be 80%. As a result of identifying the vehicle model with ReXNet using the self-developed black box, the accuracy was found to be 99%. The result was verified by surveying field police officers. These results suggest that improving the accuracy of data labeling helps to improve vehicle recognition performance."
CNN 모델의 최적 양자화를 위한 웹 서비스 플랫폼,2021,"['Convolutional Neural Network', 'Deep Learning Accelerator', 'Quantization', 'Web Service']",,"Low-end IoT devices do not have enough computation and memory resources for DNN learning and inference. Integer quantization of real-type neural network models can reduce model size, hardware computational burden, and power consumption. This paper describes the design and implementation of a web-based quantization platform for CNN deep learning accelerator chips. In the web service platform, we implemented visualization of the model through a convenient UI, analysis of each step of inference, and detailed editing of the model. Additionally, a data augmentation function and a management function of files that store models and inference intermediate results are provided. The implemented functions were verified using three YOLO models."
Real-Time Earlobe Detection System on the Web,2021,"['Computer vision', 'Deep learning', 'Image processing', 'Object detection']",,"This paper proposed a real-time earlobe detection system using deep learning on the web. Existing deep learning-based detection methods often find independent objects such as cars, mugs, cats, and people. We proposed a way to receive an image through the camera of the user device in a web environment and detect the earlobe on the server. First, we took a picture of the user's face with the user's device camera on the web so that the user's ears were visible. After that, we sent the photographed user's face to the server to find the earlobe. Based on the detected results, we printed an earring model on the user's earlobe on the web. We trained an existing YOLO v5 model using a dataset of about 200 that created a bounding box on the earlobe. We estimated the position of the earlobe through a trained deep learning model. Through this process, we proposed a realtime earlobe detection system on the web. The proposed method showed the performance of detecting earlobes in real-time and loading 3D models from the web in real-time."
Real-Time Earlobe Detection System on the Web,2021,"['Computer vision', 'Deep learning', 'Image processing', 'Object detection']",,"This paper proposed a real-time earlobe detection system using deep learning on the web. Existing deep learning-based detection methods often find independent objects such as cars, mugs, cats, and people. We proposed a way to receive an image through the camera of the user device in a web environment and detect the earlobe on the server. First, we took a picture of the user's face with the user's device camera on the web so that the user's ears were visible. After that, we sent the photographed user's face to the server to find the earlobe. Based on the detected results, we printed an earring model on the user's earlobe on the web. We trained an existing YOLO v5 model using a dataset of about 200 that created a bounding box on the earlobe. We estimated the position of the earlobe through a trained deep learning model. Through this process, we proposed a real-time earlobe detection system on the web. The proposed method showed the performance of detecting earlobes in real-time and loading 3D models from the web in real-time."
A deep learning-based approach for feeding behavior recognition of weanling pigs,2021,"['Convolutional neural network', 'Deep learning', 'Behavior detection', 'Processing', 'Weanling pig']",,"Feeding is the most important behavior that represents the health and welfare of weanling pigs. The early detection of feed refusal is crucial for the control of disease in the initial stages and the detection of empty feeders for adding feed in a timely manner. This paper proposes a real-time technique for the detection and recognition of small pigs using a deep-leaning-based method. The proposed model focuses on detecting pigs on a feeder in a feeding position. Conventional methods detect pigs and then classify them into different behavior gestures. In contrast, in the proposed method, these two tasks are combined into a single process to detect only feeding behavior to increase the speed of detection. Considering the significant differences between pig behaviors at different sizes, adaptive adjustments are introduced into a you-only-look-once (YOLO) model, including an angle optimization strategy between the head and body for detecting a head in a feeder. According to experimental results, this method can detect the feeding behavior of pigs and screen non-feeding positions with 95.66%, 94.22%, and 96.56% average precision (AP) at an intersection over union (IoU) threshold of 0.5 for YOLOv3, YOLOv4, and an additional layer and with the proposed activation function, respectively. Drinking behavior was detected with 86.86%, 89.16%, and 86.41% AP at a 0.5 IoU threshold for YOLOv3, YOLOv4, and the proposed activation function, respectively. In terms of detection and classification, the results of our study demonstrate that the proposed method yields higher precision and recall compared to conventional methods."
A Study on Pagoda Image Search Using Artificial Intelligence (AI) Technology for Restoration of Cultural Properties,2021,"['Enter key words or phrases in alphabetical order', 'separated by commas']",,"The current cultural assets are being restored depending on the opinions of experts (craftsmen). We intend to introduce digitalized artificial intelligence techniques, excluding the personal opinions of experts on reconstruction of such cultural properties. The first step toward restoring digitized cultural properties is separation. The restoration of cultural properties should be reorganized based on recorded documents, period historical backgrounds and regional characteristics. The cultural properties in the form of photographs or images should be collected by separating the background. In addition, when restoring cultural properties most of them depend a lot on the tendency of the restoring person workers. As a result, it often occurs when there is a problem in the accuracy and reliability of restoration of cultural properties. In this study, we propose a search method for learning stored digital cultural assets using AI technology. Pagoda was selected for restoration of Cultural Properties. Pagoda data collection was collected through the Internet and various historical records. The pagoda data was classified by period and region, and grouped into similar buildings. The collected data was learned by applying the well-known CNN algorithm for artificial intelligence learning. The pagoda search used Yolo Marker to mark the tower shape. The tower was used a total of about 100-10,000 pagoda data. In conclusion, it was confirmed that the probability of searching for a tower differs according to the number of pagoda pictures and the number of learning iterations. Finally, it was confirmed that the number of 500 towers and the epochs in training of 8000 times were good. If the test result exceeds 8,000 times, it becomes overfitting. All so, I found a phenomenon that the recognition rate drops when the enemy repeatedly learns more than 8,000 times. As a result of this study, it is believed that it will be helpful in data gathering to increase the accuracy of tower restoration."
