title,date,keywords,abstract,multilingual_abstract
YOLO 기반 나방 유충 탐지 모델의 연구,2021,"['Moth larvae', 'Moth larva detection', 'YOLO', 'Moth larvae control', 'YOLO model comparison.']",국문 초록 정보 없음,"Moth pests are pests that cause a lot of damage to food crops. Moth larvae are similar in shape and shape. In addition, even moth larvae have different colors depending on the environment and consummation, so it is difficult for skilled farmers to accurately identify moth larvae. However, accurate identification of moth larvae is very important because moth larvae have different control methods. The main user of the moth larva detection model is a farmer without computer knowledge. Thus, the most important factor is not the time or accuracy to detect larvae of moths. How little false positive or false negative is a more important factor. It prevents waste of labor and financial losses of farmers who have misrepresented by error detection. This is because it can improve the credibility of smart agricultural technology. The YOLO v2, YOLO v3, and YOLO v4 models were learned as the same moth larvae image and the performance between models was compared. As a result of the experiment, the YOLO v4 model showed Precision, Recall, and F1-Score as 1.00. In addition, it was confirmed that the performance was superior to other YOLO models with 88.39% of IoU and 79.96% of mAP. False Positive or False Negative is also less than other YOLO models. It was confirmed that the YOLO v4 model was suitable as a moth larva detection model."
YOLO알고리즘을 활용한 시각장애인용 식사보조 시스템 개발,2021,"['컴퓨터 비전', '딥러닝', 'YOLO', '시각 장애인', '공통 영역', '안드로이드', '음성 합성 시스템', 'Computer Vision', 'Deep Learning', 'YOLO', 'Visually Impaired', 'Intersection over Union(IoU)', 'Android', 'Text-to-Speech']","시각이 온전한 사람들은 식사를 할 때 시각에 대한 의존도를 깊게 인지하지 못한다. 그러나 시각장애인은 식단에 어떤 음식이 있는지 알지 못하기 때문에 옆에 있는 보조인이 시각장애인 수저로 음식의 위치를 시계 방향 또는 전후좌우 등 일정한 방향으로 설명하여 그릇 위치를 확인한다. 본 논문에서는 시각장애인이 스마트폰의 카메라를 이용하여 자신의 식단을 비추면 각각의 음식 이미지를 인식하여 음성으로 음식의 이름을 알려 주는 식사보조 시스템의 개발 내용에 대해 기술한다. 이 시스템은 음식과 식기도구(숟가락)의 이미지를 학습한 YOLO모델을 통해 숟가락이 놓인 음식을 추출해 내고, 이 음식이 무엇인지를 인식하여 이를 음성으로 알려준다. 본 시스템을 통해 시각장애인은 식사보조인의 도움없이 식사를 할 수 있음으로써 자립의지와 만족도를 높일 수 있을 것으로 기대한다.","Normal people are not deeply aware of their dependence on sight when eating. However, since the visually impaired do not know what kind of food is on the table, the assistant next to them holds the blind spoon and explains the position of the food in a clockwise direction, front and rear, left and right, etc. In this paper, we describe the development of a meal assistance system that recognizes each food image and announces the name of the food by voice when a visually impaired person looks at their table using a smartphone camera. This system extracts the food on which the spoon is placed through the YOLO model that has learned the image of food and tableware (spoon), recognizes what the food is, and notifies it by voice. Through this system, it is expected that the visually impaired will be able to eat without the help of a meal assistant, thereby increasing their self-reliance and satisfaction."
YOLO 기반 차선검출 시스템,2021,"['객체인식', '자율주행', 'CSI-Camera', 'YOLO', 'Object recognition', 'Autonomous driving', 'CSI-Camera', 'YOLO']",자동차는 단순한 이동 수단으로 사용되었지만 최근 지능화 및 스마트화가 급속하게 진행되고 자동차 선호도가 증가하면서 운전자의 편의 및 안전 등 고성능 기능을 요구하면서 IT 기술 융합 연구가 진행되고 있다. 이로 인해 자율주행과 반자율주행 자동차가 개발되고 이러한 기술들은 주변 환경 문제로 인하여 차선 이탈 경우와 자율주행 자동차에서 판단하지 못하는 상황이 생기고 차선 검출기에서는 차선을 인식하지 못하는 경우가 있다. 이러한 문제점인 자율주행 자동차의 차선검출 시스템의 차선 이탈에 대한 성능을 향상하기 위해 본 논문에서는 YOLO(You only look once)의 특성인 빠른 인식을 사용하고 CSI- Camera를 사용하여 주변 환경으로부터 영향을 받는 상황을 인지하고 주행 데이터 수집하여 관심 영역을 추출하는 차선검출 시스템을 제안한다.,"Automobiles have been used as simple means of transportation, but recently, as automobiles are rapidly becoming intelligent and smart, and automobile preferences are increasing, research on IT technology convergence is underway, requiring basic high-performance functions such as driver's convenience and safety. As a result, autonomous driving and semi-autonomous vehicles are developed, and these technologies sometimes deviate from lanes due to environmental problems, situations that cannot be judged by autonomous vehicles, and lane detectors may not recognize lanes. In order to improve the performance of lane departure from the lane detection system of autonomous vehicles, which is such a problem, this paper uses fast recognition, which is a characteristic of YOLO(You only look once), and is affected by the surrounding environment using CSI-Camera. We propose a lane detection system that recognizes the situation and collects driving data to extract the region of interest."
YOLO와 OCR 알고리즘에 기반한 시각 장애우를 위한 유통기한 알림 시스템,2021,"['시각 장애우', '유통기한', '인공지능', '객체 인식', '광학 문자 인식', 'Visually Impaired Person', 'Expiration Date', 'Artificial Intelligence', 'You Only Look Once', 'Optical Character Recognition']","점자를 제외한 시각 장애우들이 유통기한을 확인할 수 있는 효과적인 방법이 거의 개발되어 있지 않으며, 이로 인하여 시각 장애우들의 식품 안전성이 위협받고 있다. 본 연구에서는 시각 장애우의 식품 안전성 확보를 위해 실시간 객체 인식 알고리즘(you only look once, YOLO) 및 광학 문자 인식 (optical character recognition, OCR)에 기반한 유통기한 알림 시스템을 개발했다. 제안하는 시스템은 총 4가지 단계로 시각 장애우에게 유통기한 정보를 전달한다: (1) 표적 제품의 바코드 스캔을 통한 제품 확인 (2) 실시간으로 입력되는 제품 영상에서 YOLO 알고리즘을 활용하여 유통기한이 표기된 이미지 영역 검출; (3) 검출된 이미지 영역에서 OCR 알고리즘을 활용하여 유통기한 문자 인식; (4) Text to Speech (TTS) 기술을 활용하여 유통기한 정보를 사용자에게 전달. 성능 평가를 위한 온라인 실험 결과, 앞이 보이지 않는 피험자가 개발한 시스템을 사용해서 제품의 유통기한을 평균 86%의 높은 정확도로 확인할 수 있음이 검증되었다. 이러한 결과는 제안하는 시스템이 저시력자를 포함한 시각 장애우들의 식품 안전성 확보에 이바지할 수 있음을 보여준다.","There are rarely effective methods to help visually impaired people when they want to know the expiration date of products excepted to only Braille. In this study, we developed an expiration date notification system based on YOLO and OCR for visually impaired people. The handicapped people can automatically know the expiration date of a specific product by using our system without the help of a caregiver, fast and accurately. The proposed system is worked by four different steps: (1) identification of a target product by scanning its barcode; (2) segmentation of an image area with the expiration date using YOLO; (3) classification of the expiration date by OCR: (4) notification of the expiration date by TTS. Our system showed an average classification accuracy of about 86.00% when blindfolded subjects used the proposed system in real-time. This result validates that the proposed system can be potentially used for visually impaired people."
YOLO 기반 과실 분류 모델 설계 및 구현,2021,[],"일반적으로, 과실 재배 농가에서의 과실 분류 작업은 많은 노동력을 필요로 한다. 최근 코로나19 방역조치로 외국인 근로자 입국 제한으로 인해 농가에서는 인력 수급에 어려움을 겪고 있다. 본 연구에서는 이러한 농가 피해 상황을 해소하고 수급 문제를 해결하기 위해 YOLO 기반 과실 분류 모델 설계 및 구현을 소개한다. 본 모델을 기반으로 여러 과실 중 사과에 적용하여 인력이 많이 동원되는 선별과정을 YOLO의 객체 인식을 통해 해결하고 적은 비용으로 효율성 있는 분류 모델을 구축한다.",다국어 초록 정보 없음
아두이노와 YOLO를 이용한 졸음 방지 시스템 구현,2021,[],국문 초록 정보 없음,"In modern society, deaths and property damage due to drowsiness occur every year enormously. Methods to reduce such damage are being studied a lot in all walks of life, and research on preventing drowsy driving is particularly active in automobiles. In this paper, as an Arduino-based water gun firing system that learns open and closed eyes using YOLO, we propose a drowsy prevention system that fires a water gun when the duration of the closed eye exceeds a certain time. This system can be applied and used in various fields, but especially when applied to a car, it is not necessary to purchase expensive specifications and if you pay a little attention, you can reduce accidents caused by drowsy driving by 100% at a very low cost. In addition, it can be said that it is an independent system that overcomes different specifications for each company."
선택적 주의집중 모델과 YOLO를 이용한 선행 차량 정지등 검출 시스템 구현,2021,[],국문 초록 정보 없음,"A ADAS(Advanced Driver Assistance System) for the safe driving is an important area in autonumous car. Specially, a ADAS software using an image sensors attached in previous car is low in building cost, and utilizes for various purpose. A algorithm for detecting the break-lamp from the tail-lamp of preceding vehicle is proposed in this paper. This method can perceive the driving condition of preceding vehicle. Proposed method uses the YOLO techinicque that has a excellent performance in object tracing from real scene, and extracts the intensity variable region of break-lamp from HSV image of detected vehicle ROI(Region Of Interest). After detecting the candidate region of break-lamp, each isolated region is labeled. The break-lamp region is detected finally by using the proposed selective-attention model that percieves the shape-similarity of labeled candidate region. In order to evaluate the performance of the preceding vehicle break-lamp detection system implemented in this paper, we applied our system to the various driving images. As a results, implemented system showed successful results."
이미지 속 문자열 탐지에 대한 YOLO와 EAST 신경망의 성능 비교,2021,[],"본 논문에서는 최근 다양한 분야에서 많이 활용되고 있는 YOLO와 EAST 신경망을 이미지속 문자열 탐지문제에 적용해보고 이들의 성능을 비교분석 해 보았다. YOLO 신경망은 v3 이전 모델까지는 이미지 속 문자영역 탐지에 낮은 성능을 보인다고 알려졌으나, 최근 출시된 YOLOv4와 YOLOv5의 경우 다양한 형태의 이미지 속에 있는 한글과 영문 문자열 탐지에 뛰어난 성능을 보여줌을 확인하고 향후 문자 인식 분야에서 많이 활용될 것으로 기대된다.",다국어 초록 정보 없음
YOLO 기반 영상 비식별화 도구 개발,2021,[],"영상 매체의 발달과 영상 미디어의 쉬운 공유는 많은 이점을 가지고 왔다. 하지만 영상이 인터넷 상에서 쉽게 공유되면서 개인이 원치 않는 모습 및 정보가 자신도 모르게 공개되는 초상권 문제나 사생활 침해 문제가 발생하고 있다. 이를 막기 위해 영상의 인물을 비식별화 하고 있지만 수작업으로 진행되는 영상의 비식별화는 많은 시간과 비용이 들어간다. 이에 본 논문에서는 자동으로 영상의 인물을 탐지, 추적하여 비식별화 영상처리를 진행할 수 있는 YOLO 기반 비식별화 시스템을 제안한다.",다국어 초록 정보 없음
적외선 카메라와 YOLO를 사용한 블랙아이스 탐지 방법,2021,[],국문 초록 정보 없음,"Black ice, which occurs mainly on the road, vehicle traffic bridges and tunnel entrances due to the sub-zero temperature due to the slip of the road due to heavy snow, is not recognized because the image of asphalt is transmitted in the driver's view, so the vehicle loses braking power because it causes serious loss of life and property. In this paper, we propose a method to identify the black ice by using infrared camera and to identify the road condition by using deep learning to compensate for the disadvantages of existing black ice detection methods (artificial satellite imaging, checking the pattern of slip by ultrasonic reception, measuring the temperature of the road surface, and checking the difference in friction force of the tire during vehicle driving) and to reduce the size of the sensor to detect black ice."
수정된 YOLO v4를 활용한 해상에서 객체 탐지 및 분류 모형 개발,2021,"['Deep learning', 'Detection of warships', 'Object detection', 'YOLO v4', 'Modified YOLO v4']","본 연구의 목적은 해상에서 군함의 영상장비로 획득한 영상에 딥러닝을 적용하여 군함을 객체로 탐지하고 분류하는 모형을 개발하는 것이다. 본 연구에서는 한반도 해상과 관련된 5개국의 군함을 대상으로 하였다. 모형의 알고리즘은 기존 YOLO v4 모형의 SPP 영역을 수정하여 구현한 것을 제안하였고, 기존 YOLO v4 모형과 본 연구에서 제안한 수정된 YOLO v4 모형을 비교하였다. 두 모형에 대한 평가는 mAP(mean Average Precision) 와 IoU(Intersection over Union)로 하였으며, 평가 결과 수정된 YOLO v4 모형이 mAP 면에서 YOLO v4 모형보다 0.28% 더 우수한 성능을 보였다. 또한, 테스트 영상을 이용한 실험에서도 영상의 크기에 관계없이 제안한 모형이 기존 모형보다 객체 분류 면에서 우수한 성능을 보였다.",다국어 초록 정보 없음
PP-YOLO를 이용한 실시간 두피 각질 검출 기법,2021,"['PP-YOLO', '두피 관리', '두피 질병', 'Real-time object detection', 'PP-YOLO', 'Haircare', 'Scalp disease']","두피 질병은 대개 각질과 통증을 유발하며, 증상을 방치하면 탈모나 모낭염으로 진행될 수 있다. 따라서, 질병의 조기 발견과 치료가 중요하지만, 정기적으로 전문 기관을 방문하는 것은 많은 시간과 비용을 초래한다. 최근, 스마트폰에 현미경 카메라를 연동한 두피 상태의 자가진단이 가능해지면서, 딥러닝 기반의 두피 질병 진단 기법이 제안되고 있다. 그러나, 이러한 기법들은 높은 연산량이 요구되어 스마트폰과 같은 제한적인 하드웨어 환경에서는 만족스러운 성능을 얻기가 어려워, 실시간 두피 상태 진단과 같은 현실적인 요구에 부합하지 못하고 있다. 이러한 문제를 해결하고자, 본 논문에서는 두피 질병에서 공통으로 발생하는 각질의 유무와 위치를 실시간으로 추출할 수 있는 기법을 제안한다. 이를 위해, 각질 검출에 PP-YOLO 모델을 사용하였으며, 기존에 제안된 연구들과 검출 정확도 및 처리 속도를 비교하였다. 실험결과, 본 논문에서 제안하는 기법은 실시간 수준의 검출 속도를 만족할 뿐만 아니라, 기존 연구보다 정확하게 두피 각질을 검출할 수 있음을 보인다.",다국어 초록 정보 없음
수집·운반형 양파 수확기의 양파 개수 및 위치 분석을 위한 YOLO 기반 양파 검출 알고리즘,2021,"['RGB-D 센서', '양파', '객체 검출', '최적 위치 추정']","ICT·IoT 등 첨단기술과의 융복합을 통해 농작업기술이 발전함에 따라 파종, 시비, 입제 살포, 수확 등 밭농업기계화·자동화 연구가 활발히 이루어지고 있다. 특히 양파 작물의 경우 굴취, 이송 및 수집 등 생산 전과정기계화 기술이 개발되고 있지만 여전히 운전자가 직접 작물을 확인하고 양파수확기의 주행 방향과 속도를 제어한다. 본 연구에서는 운전자를 보조할 수 있도록 양파를 인식하고 개체 개수를 분석하는 YOLO 기반 객체 검출 알고리즘을 제안했다. 탐지 대상은 수확 후 두둑에 널려 있는 양파이며 알고리즘의 객체 검출 성능을 높이기 위해 양파의 분포 상태와 조도 조건에 따라 다양한 데이터를 수집했다. RGB-D 카메라를 활용해 영상을 획득했고 사용된 객체 검출 알고리즘은 Darknet-53과 FPN로 이루어진 YOLO v3이다. 탐지 대상의 작은 크기를 고려하여 정확도와 속도가 균형적인 성능을 통해 실시간으로 양파를 검출하도록 백본 네트워크의 저해상도 feature map으로부터의 객체 검출 연산을 제거하여 알고리즘을 간편화했다. 개선된 알고리즘을 10,000여 개의 양파 데이터를 학습시키고 1,500여 개의 데이터로 실험한 결과 96%이상의 정확도를 보였다. 제안한 알고리즘을 통해 검출된 양파의 bounding box를 기준으로 영상 내 양파의 개수와 위치를 분석했으며 실측에 근사한 정확도를 보였다.",다국어 초록 정보 없음
YOLO 기반의 광학 음악 인식 기술 및 가상현실 콘텐츠 제작 방법,2021,"['딥러닝', '가상현실', '컴퓨터 비전', 'Deep Learning', 'Virtual Reality', 'Optical Music Recognition(OMR)', 'Computer Vision']","딥러닝에 기반한 광학 음악 인식 기술(Optical Music Recognition, OMR)을 사용하여 도출된 결과를 가상현실 (Virtual Reality, VR) 게임에 적용시킨 것을 제안한다. 딥러닝 모델은 YOLO v5를 사용했으며 검출되지 않은 객체를 검출하기 위해 Hough transform 사용, 보표 크기 수정 등을 수행한다. 출력된 결과 파일을 사용하여 VR 게임에서 BPM, 최대 콤보 수, 음정과 박자를 분석하여 사용하고 리소스 관리를 위한 Object Pooling 기술을 통해 노트가 밀리는 현상을 방지한다. 광학 음악 인식 기술을 통해 나온 음악 요소로 VR 게임을 제작하여 VR 콘텐츠 제공과 함께 광학 음악 인식의 활용성을 넓히는 것을 확인하였다.","Using optical music recognition technology based on deep learning, we propose to apply the results derived to VR games. To detect the music objects in the music sheet, the deep learning model used YOLO v5, and Hough transform was employed to detect undetected objects, modifying the size of the staff. It analyzes and uses BPM, maximum number of combos, and musical notes in VR games using output result files, and prevents the backlog of notes through Object Pooling technology for resource management. In this paper, VR games can be produced with music elements derived from optical music recognition technology to expand the utilization of optical music recognition along with providing VR contents."
항공영상으로부터 농경지 환경에서의 실시간 객체 검출을 위한 Pruning 기법 기반 YOLO 알고리즘 경량화,2021,"['항공영상', '심층 신경망', '객체 탐지', '다중 스케일', 'Pruning 기법']","드론 기반 영상 인식 기술이 발전함에 따라 자율주행 농기계의 안정성과 제어 기능의 역할을 분담할 수 있는 시스템 연구가 활발히 진행되고 있다. 이에 따라 드론과의 협업을 통해 자율주행 농기계의 시야를 광대역으로 확대하고 실시간으로 다양한 크기의 객체를 높은 정확도로 구분하는 알고리즘 설계가 요구되고 있다. 본 연구에서는 드론의 항공 영상으로부터 농경지에 존재하는 다양한 크기의 객체를 높은 정확도로 실시간 검출하기 위해 개선된 YOLO 알고리즘을 제안한다. 제안하는 알고리즘의 기본적인 구성은 convolutional layer, residual block로 이루어진 Darknet53을 백본(backbone)으로 YOLOv3를 사용했다. 드론에서 실시간으로 다양한 크기의 객체를 검출하기 위해 알고리즘을 경량화하면서도 효율성을 유지하는 방법으로 모델의 크기를 줄이기 위해 Pruning 기법을 적용했다. 그리고 객체를 판별하는 feature map을 구성할 때에 세밀함을 보완하기 위해 다양한 학습 데이터를 농업 환경에 맞도록 구성하였다. 학습 데이터에서 객체 판별을 위한 feature map을 구성 할 때, 각 feature map layer를 통합하여 정확도를 향상시켰다. 또한 객체 분류별 앵커 박스의 설정을 다르게 하여 다양한 크기의 객체에서도 높은 검출 성능을 유지하도록 하였다. 기존의 YOLO v3과 비교한 결과, 제안한 알고리즘의 모델 크기는 줄었으며 실시간 객체 검출 성능도 개선되었다. 객체 검출 정확도 역시 우수한 성능을 보였으며 다양한 크기의 객체를 대부분 검출했다. 이를 통해 설계한 알고리즘이 드론과 자율주행 농기계의 협업 시스템에서 요구하는 다양한 크기의 객체 검출 정확성과 실시간성을 만족하는 것을 확인하였다.",다국어 초록 정보 없음
YOLO 를 이용한 유해조수 침입 감지 모델,2021,[],"유해조수에 의한 농작물 피해규모는 2015 년 106 억원, 2017 년 126 억원에 이어 2019 년 137 억원으로 해마다 늘어나고 있다. 유해조수 중 조류에 의한 피해는 농작물 외에도 항공기, 전기/통신망, 양식장에 이르기 까지 다양한 산업분야에서 발생한다. ICT 기술은 유해조수에 의한 농작물 및 시설물의 피해를 줄이기 위한 효과적인 방안을 제시할 수 있다. 본 연구에서는 이미지 인식 및 분석 기술을 이용하여 유해조수 감지 및 피해방지를 위한 YOLO 기반의 감지 모델을 설계 후 유해조수 중 조류에 적용하여 테스트했다. 제안하는 모델은 여러 산업분야에서 유해조수 피해 방지를 위한 다양한 응용개발에 활용될 수 있다.",다국어 초록 정보 없음
YOLO V3 기반의 시각장애인을 위한 유도 블록 인식 알고리즘,2021,"['YOLO', '영상인식', '머신러닝', '합성곱 신경망', '평균 정밀도', 'Object detection', 'Machine learning', 'Convolutional neurual network', 'Mean average precision']","현재 우리나라에 설치된 유도 블록 중에서 일부는 설치 후에 관리가 미흡한 편이며 파손된 경우 보수도 잘 이루어지지 않아 시각장애인들의 보행에 부정적인 영향을 미치는 경우가 많다. 시각장애인들에게 유도 블록의 위치와 의미를 전달하는 시스템에 관한 연구가 필요한 상황이며 이를 위해서 휴대하기 편하고 스마트폰에서도 계산이 가능한 알고리즘이 요구된다. 이에 본 논문은 실시간 물체 검출이 가능하고, 준수한 FPS(frame per second)를 유지할 수 있는 YOLO를 기반으로 한 시각장애인을 위한 유도 블록 인식 알고리즘을 제안한다. 그리고 영상인식 영역의 성능을 여러 가지 수치로 비교하여 최선의 알고리즘을 선택했고 해당 알고리즘은 mAP와 YOLO-Loss, AP, Precision 등의 수치를 이용하여 성능을 평가하였다. 제안한 알고리즘은 연산량을 줄여주고 그에 따른 정확도의 하락을 방지하는 방법도 제시했다.","Currently, some of the induction blocks in the case of in Korea are poorly managed when some of the induction blocks are installed, and there is a visual impairment because neither case nor maintenance is well done. There is a need for research on a system that delivers the location and meaning of guidance blocks to visually impaired people, and an algorithm that is easy to perform and that can be calculated on a smartphone is required. Therefore, this paper proposes an induction block recognition algorithm for the visually impaired based on YOLO, which enables real-time detection and uses compliant FPS (frame per second). Then, the best algorithm was selected by comparing the performance of the image recognition area with various numbers, and the performance was evaluated using mAP, YOLO-Loss, AP, and Precision. The proposed algorithm flows the computational load and also suggests a method to prevent its degradation."
임베디드 디바이스 상에서 작은 물체 탐지를 위한 주성분 분석기반 YOLO,2021,"['YOLO', 'Small object detection', 'PCA', 'Embedded device', 'drone image']","물체 감지는 컴퓨터 비전 분야에서 활발한 연구 분야로 남아 있으며 물체 감지를 해결하기 위한 심층 컨볼루션 신경망 설계를 통해 이 분야에서 상당한 발전과 성공을 거두었다. 이러한 성공에도 불구하고 임베디드 시나리오에서 작은 물체 감지를 위한 네트워크 개발에 가장 큰 장애물 중 하나는 작은 물체에 대한 특징 추출의 어려움이다. 이 작업에서는 작은 물체 감지 작업을 위해 고도로 세분화 된 특징을 추출하는 심층 컨볼루션 신경망 인 PCA 기반 YOLO를 제안한다. 일반적으로 이미지 특징 추출을 위한 컨볼루션 레이어는 이미지의 공통된 특징을 추출하고 정보를 완전 연결 계층으로 전달한다. 여기서 작은 물체에 대한 대부분의 정보가 손실되어 분류가 매우 어렵기 때문에 입력 데이터에 대한 정보를 증폭하여 정보 손실 문제를 해결하기 위해 PCA를 이 프로세스에 통합하여 PCA 기반 YOLO 네트워크를 구축한다. Jetson AGX Xavier 임베디드 모듈에 해당 네트워크를 구축하고, 실험 섹션에서는 총 9가지, 4783개의 드론 이미지를 사용하여 다양한 실험을 수행하여 방법론을 보여준다.","Object detection remains an active research area in the field of computer vision, and has achieved significant advances and successes in this field through the design of deep convolutional neural networks to address object detection. Despite this success, one of the biggest obstacles to the development of networks for small object detection in edge and embedded scenarios is the difficulty of feature extraction for small objects. In this work, we introduce PCA-based YOLO, a deep convolutional neural network that extracts highly granular features for small object detection tasks. In general, convolutional layers for feature extraction of images extract common features of images and pass information to fully connected layers, where most of the information on small objects is lost, making classification very difficult. We build a PCA-based YOLO network by integrating PCA into this process to solve the information loss problem by amplifying information about input data. We build the corresponding network on the Jetson AGX Xavier embedded module, and in the experimental section, we perform various experiments using a total of 4783 drone images of nine kinds, showing the methodology."
플라스틱 재활용을 위한 YOLO기반의 자동 분류시스템,2021,"['Object detection', 'YOLOv5', 'recycling mark']","본 연구에서는 실시간 물체 인식 알고리즘인 YOLO (You Only Look Once)를 이용하여 플라스틱의 종류를 자동으로 분류하는 시스템을 구현하였다. 시스템은 Nvidia 사에서 만든 딥러닝, 컴퓨터비전용 소형 컴퓨터인 Jetson Nano에 YOLO를 이용하여 플라스틱 분리배출 마크를 인식할 수 있도록 훈련시킨 모델을 탑재하여 구성하였다. 웹캠을 이용해서 플라스틱 쓰레기의 분리배출 마크를 PET, HDPE, PP 세종류로 인식하고 모터를 조절하여 종류에 따라 분류될 수 있도록 하였다. 이 자동 분류기를 구현함으로써 사람이 직접 플라스틱 분리배출 마크를 확인하여 분리배출하는 수고를 덜어줄 수 있다는 점에서 편의성을 가지며 정확한 분리수거를 통해 재활용의 효율성을 높일 수 있다.","In this study, we implement a system that automatically classifies types of plastics using YOLO (You Only Look Once), a real-time object recognition algorithm. The system consists of Nvidia jetson nano, a small computer for deep learning and computer vision, with model trained to recognize plastic separation emission marks using YOLO. Using a webcam, recycling marks of plastic waste were recognized as PET, HDPE, and PP, and motors were adjusted to be classified according to the type. By implementing this automatic classifier, it is convenient in that it can reduce the labor of separating and discharging plastic separation marks by humans and increase the efficiency of recycling through accurate recycling."
YOLO-v4를 활용한 작업장의 위험 객체와 작업자 간 거리 예측 모델의 구현,2021,"['Distance estimation', 'Forklift', 'Industrial safety', 'Object detection', 'YOLO']",산업재해로 인한 사망사고와 함께 시민재해로 인한 사망사고 발생 등이 사회적 문제로 지적됨에 따라 작업장에서 발생하는 중대재해 처벌 등에 관한 법률이 제정되어 시민의 안전권 보장과 중대재해를 사전에 방지하기 위한 노력이 요구되는 실정이다. 본 논문에서는 지게차와 같은 중장비에 작업자가 치이는 경우와 관련해 거리 예측 모델을 제안한다. 데이터는 실제 지게차와 작업자가 배회하는 환경을 CCTV로 직접 촬영한 영상을 사용했으며 유클리디안 거리 기반으로 진행하였다. 산업 현장에서 데이터셋을 직접 구축해 YOLO-v4를 학습하고 이를 통해 거리를 예측하여 위험한 상황인지 판정하는 모델을 구현하여 종합 위험 상황 판단 모델의 기초 자료로 활용할 수 있을 것으로 사료된다.,"As fatal accidents due to industrial accidents and deaths due to civil accidents were pointed out as social problems, the Act on Punishment of Serious Accidents Occurred in the Workplace was enacted to ensure the safety of citizens and to prevent serious accidents in advance. Effort is required. In this paper, we propose a distance prediction model in relation to the case where an operator is hit by heavy equipment such as a forklift. For the data, actual forklift trucks and workers roaming environments were directly captured by CCTV, and it was conducted based on the Euclidean distance. It is thought that it will be possible to learn YOLO-v4 by directly building a data-set at the industrial site, and then implement a model that predicts the distance and determines whether it is a dangerous situation, which can be used as basic data for a comprehensive risk situation judgment model."
GPC: YOLO 기반 철근 형상에 대한 그립 위치 좌표 검출 모델,2021,"['deep learning', 'yolo', 'vision processing', 'image processing', 'smart factory']","기존의 그립 방식은 그립 위치에서 철근 형상을 잡을 수 있는지 판단이 불가능하며 오류가 발생하면 수동작업을 필수적으로 이루어져야 한다. 이러한 문제점을 해결하기 위해서는 적재 전 로봇팔에 의해 철근 형상이 그립이 가능한지 그립 여부 판단을 먼저 수행함으로써 방지할 수 있다. 철근 형상의 이미지를 확보하기 위해 그립 작동 시 사용되는 로봇팔의 그리퍼 위치에 비전 카메라를 설치하여 입력 정보를 확보한다. 철근 형상 데이터셋을 YOLO를 통해 학습 수행 뒤 검출되는 철근 형상 바운딩 박스의 정보를 분석하여 철근의 위치와 폭을 파악하고 철근 형상에 대해 그립 여부를 판단하고 기존의 그립 위치와의 차이를 계산하여 새로운 위치의 그립 가능 위치 좌표를 도출하는 알고리즘을 제안한다. 제안하는 방법은 철근 형상 인식률이 95~100%를 보여주며, 그립이 가능한 좌표 도출 시 철근 위치에 표시되는 것을 확인할 수 있다.","It is impossible to determine whether the existing grip method can hold the shape of a rebar at the grip point and manual work must be performed in the event of an error occurs. In order to solve this problem, it is possible to prevent the robot arm before loading by first determining whether the shape of the rebar can be gripped or not. In order to secure a rebar-shaped image, a vision camera is installed with the gripper position of the robot arm that used to motion grip operation generate. We propose an algorithm to analyze the information on the rebar-shape that bounding box and detected after learning through YOLO. Also, the process determine the location and width of the rebar, determine whether to grip the rebar shape, and calculate the difference from the existing grip position to derive grip position coordinates. The proposed method shows that the rebar shape recognition rate is 95-100%, and it can be confirmed that it is displayed at the rebar position when deriving gripping coordinates."
클라우드와 YOLO를 이용한 지능적인 COVID 방역 시스템 구현,2021,"['COVID', 'QR code', 'TTS', 'STT', 'YOLO', 'EC2', 'RDS', 'Monitoring system']","COVID 사태는 방역 관리에 따른 개인 프라이버시 침해라는 문제점을 발생했다. 또한, 실내는 온습도에 따라 전파속도가 다르기 때문에, 실내 인원에 따른 적절한 온습도와 공기정화가 필요하다. 본 시스템은 자동화된 체온측정으로 출입자를 통제하고, 개인의 프라이버시를 위해 QR 코드와 음성으로 전화번호만을 저장하였으며, 일정 기간이 지나면 개인 정보를 삭제할 수 있도록 하였다. 또한, YOLO를 이용하여 실내의 인원을 자동으로 카운팅하고, 온도와 습도를 측정하여, COVID 방역에 적합한 온도와 습도를 유지할 수 있도록 구현하였다.","The COVID outbreak has caused a problem of personal privacy infringement due to quarantine management. In addition, since the propagation speed differs according to the temperature and humidity in the room, it is necessary to properly purify the temperature and humidity according to the number of people in the room. This system controls entry and exit through automated body temperature measurement, stores only phone numbers with QR codes and voices for personal privacy, and allows personal information to be deleted after a certain period of time. In addition, it is designed to automatically count the number of people indoors using YOLO and measure the temperature and humidity to maintain the temperature and humidity suitable for COVID prevention."
YOLO-based robotic grasping,2021,"['Deep learning', 'object detection', 'robotic grasping', 'bin picking']",국문 초록 정보 없음,"Waste is causing a lot of problems around the world and there is a problem of poor recycling. To separate garbage collection, various wastes shall be detected and recognized, which shall be carried out in real time. To address these issues, this paper proposes YOLO-based robotic grasping methods. The limitations of existing deep learning-based robotic grasping methods predict grasping points in all images and do not recognize objects. Considering this, we perform object detection and capture point derivation by processing images with the proposed area restriction method after detection and recognition based on YOLO, an one-stage object detection."
YOLO-v3 을 활용한 고속도로 진입 상황 인지와 번호판 인식,2021,"['Ai', 'Deep learning', 'Jetson Nano', 'YOLO', 'OCR']",국문 초록 정보 없음,"Statistics show that a significant proportion of highway traffic accidents are caused by deliberately or unconsciously entering the highway by motorcycle. In this paper, Real-time motorcycle detection and license plate recognition algorithm was developed using Yolo-v3 algorithm. Specifically, it uses the Yolov-3 algorithm based on Jetson Nano's embedded system to detect motorcycles and license plates with one camera to perform real-time operations. The research results developed in this study are expected to be used to prevent motorcycling accidents from entering the highway when there is without any restraint"
KCF-YOLO 기반 무인 비행체 추적 알고리즘 개발,2021,[],"본 논문에서는 무인 비행체 (UAV: Unmanned Aerial Vehicle) 공격/침입으로부터 방어하기 위한 UAV 방어 시스템의 요소 기술인 UAV 추적 알고리즘을 다룬다. 이를 위해 YOLO (You Only Look Once) v3-tiny를 사용해 공격 evader UAV(eUAV)를 탐지한다. 탐지 후 방어/추적pUAV(pursuer UAV)를 통한 연속적 추적을 위해 KCF (Kernelized Correlation Filter) 추적기 사용을 제안한다. 이때, 단순히 KCF 추적기를 사용하여 eUAV를 추적하는 경우 탐지를 위한 추적 경계상자(bounding box)가 실시간으로 적응(adaptation)하지 않기 때문에 실시간 추적에 어려움이 있으며, 추적 복잡도가 매우 증가한다. 이러한 기존 YOLOv3-tiny만 사용한 Type-I 방식의 문제를 해결하기 위해, YOLO를 통해 탐지 성공시, KCF 추적기만 사용한 Type-II, KCF를 바탕으로 주기적으로 YOLOv3-tiny를 수행하는 Type-III 방식을 제안하고, 각각 500개 eUAV 이미지 프레임을 통해 추적성능과 복잡도를 비교한다. 그 결과 기존 Type-I 대비, Type-II는 정지 eUAV 추적에, Type-III는 이동하는 eUAV 추적에 낮은 복잡도로 우수한 성능을 보임을 확인하였다. 해당 연구를 기반으로 향후 다양한 eUAV 탐지 및 분류 알고리즘을 개발하고, 이를 pUAV에 탑재하는 것을 목표로 한다.",다국어 초록 정보 없음
YOLO를 이용한 드론탐지 시스템,2021,"['욜로(Yolo-mark)', '데이터셋(Dataset)', 'AI(ARTICIFIAL INTELLIGENCE)', '다크넷(Darknet)', '드론인식(Drone recognition)']",본 논문에서는 국내 드론 사용량이 증가하고 있으나 드론을 제재하기 위한 수단과 AI를 활용한 드론 콘텐츠가 부족하다. 상기 문제점을 해결하기 위해 Darknet 과 YOLO_mark를 사용하여 디바이스를 학습시켜 손쉽게 드론 인식 및 구별을 할 수 있게 구현하였다. 이를 통해 기존 드론 제재 수단의 한계를 극복하고 손쉽게 이용할 수 있다. 나아가 본 논문을 이용하여 군◦경에서 드론 식별 등으로 활용할 수 있다.,다국어 초록 정보 없음
YOLO와 CNN을 이용한 강인한 차량 번호판 인식 시스템 구현,2021,"['you only look once', 'license plate', 'object detection', 'optical character recognition', 'convolution neural network']",국문 초록 정보 없음,"In recent years, with the development of intelligent transportation systems, research on license plate recognition is drawing attention. Domestic license plate recognition is frequently misrecognized due to image quality and Korean language problems. This study implemented a real-time license plate recognition system robust against environmental changes using YOLO and CNN. YOLO was used to extract only a specific license plate area, and CNN was used to recognize license plates. License plate recognition extracted numbers and letters from the actual license plate drawing. Then, it was transformed and multiplied to be robust to the environment, and learned with CNN. In addition, three algorithms were used for recognizing Korean characters with many misrecognitions, such as detection of separated consonants and vowel regions using erosion and average regions, and extraction of syllable regions when there is no Korean syllable. Finally, the proposed license plate recognition system and the existing OCR algorithm were compared. As a result of the experiment, the easy OCR has an accuracy of 62.5%, the algorithm using only erosion is 82.5%, and the proposed algorithm has an accuracy of 97.5%."
"사람에서 컴퓨터 자동화로의 연결을 위한 탐색 : 객체 인식(Object Detection) 딥러닝 알고리즘 YOLO4, 자세 인식(Pose Detection) 프레임워크 MediaPipe를 활용한 음악 프로그램의 여성 신체 대상화, 선정적 화면 검출 연구",2021,"['Body Objectification', 'Object Detection', 'Pose Detection', 'YOLO4', 'MediaPipe', '객체 동작 감지', '여성 신체 대상화', '선정적 화면']",국문 초록 정보 없음,"The goal of this research is to examine patterns of objectification and sexualization of the female body in music programs on television. The study’s goal is to identify rules for automated visual image detection of body objectification and sexualization. To do so, previous qualitative study findings were used to identify target images and the cutting-edge object-detection deep learning algorithm, YOLO4 (You Only Look Once), and MediaPipe, a framework for deep learning-based pose detection, were used to search for patterns. As this is a one-of-a-kind study linking body objectification and algorithm-based object detection, the case for analysis must be carefully chosen, taking into account random effects from unplanned camera movements caused by real-time broadcasting. The dance to the song ’Rollin’ by the female group ’Brave Girls’ had already been broadcasted earlier in 2017. Thus, the on-stage choreography and camera movements associated with the song were already known, making them suitable for research data. The study used music programs that aired on three broadcasting networks, KBS, MBC, and SBS, during the second week of March, 2021. To fine-tune the patterns, 12 screen images were selected by extracting keyframes from the song’s original music videos. The study’s findings are summarized below. To begin, when the scene transition is associated with a significant decrease in the number of people in the visual frame in comparison to the previous frame, it is frequently associated with female body objectification. Because body objection is associated with an emphasis on a specific body-part in the absence of a face, this is essentially a zoom-in technique transited from a wide-angle view of the scene. This rule, however, is insufficient for detecting objectified visual images; it can also be applied to screen images that avoid sexualized images in the given dance choreography. As a result, an additional rule is required to exclusively find images of female body objectification, and it is discovered that detecting human faces on the screen appears to be a good measure. In other words, unless the human faces on the screen do not appear with the scene transition that shows a dramatic decrease in the number of humans in the scene, a visual flow of images can be considered female body objectification. The study also compared the levels of objectification across broadcasting networks and found that MBC has a lower proportion of sexualized images than that of other networks. On MBC’s music program, the MediaPipe framework for pose detection discovered fewer scene images with lower body parts than others. The findings of this study suggest that computer vision research can be used to detect female objectified bodies and sexual images in television programs."
YOLO를 이용한 자율비행 드론의 모바일 로봇 Detection 및 Tracking 시스템,2021,[],국문 초록 정보 없음,"The conventional quadcopter tracking system is a system that tracks the GPS signal of an object. It also has the potential for quadcopters to detect and track objects to evolve in a variety of fields, including crime prevention and landing at the desired location. The experiment performed in this work implements an object tracking algorithm for an autonomous flying quadcopter using YOLO, Pixhawk4-mini, Single Board Computer (SBC) without following GPS signals."
YOLO와 CRNN을 사용한 전기 계량기 이미지에서의 카운터 숫자 인식,2021,"['Meter Reading', 'Object Detection', 'OCR', 'YOLO', 'CRNN']",국문 초록 정보 없음,"This study proposes a method for automatically recognizing digits in power meter images. Our targets are analog power meters that display usage with four counters. We employed object detection to find the numeric domain in the meter image. And optical character recognition was performed to recognize digits in the detected numeric area. Two types of deep neural network models are used for object detection and optical character recognition. To train the model and evaluate its performance, we generated datasets from meter images. In this paper, we propose a model in which two types of deep neural networks are connected, and this model has more than 98% recognition performance."
Darknet YOLO 버전 별 도심로 객체 검출 성능 비교,2021,"['DeepLearning(딥러닝)', 'Darknet', 'YOLOv3', 'Object Detection(객체검출)', 'Recognition(인식)']","자율주행 기술을 구성하는 세 단계의 파트인 인식, 판단, 제어 중 인식 파트는 라이다, 레이다, 초음파, 카메라 등의 센서가 차량의 전방향을 향해 정보를 수집하도록 골고루 장착되어 각 센서의 특성에 맞는 정보를 받아들인다. 카메라 센서는 영상정보를 받아 객체를 검출하는 역할을 한다. 카메라 센서를 통해 받아들인 영상 정보는 영상처리를 통해 필요한 정보를 획득하는 방법이 사용되어 왔으나 최근 딥러닝을 이용한 CNN기반 객체검출 알고리즘을 접목하여 성능을 향상시키는 연구가 증가하고 있다. 자율주행에서의 객체검출은 실시간성이 중요한 요소이다. 딥러닝 기반 객체 검출 알고리즘은 기본적으로 많은 계산량을 요구한다. 여러 객체 검출 알고리즘 가운데 Darknet은 One-stage Detection 모델 중의 하나로 획기적으로 연산 속도를 줄여 실시간에 근접한 검출 속도를 내는 것이 특징이다. 본 논문은 Darknet의 객체 검출모델 YOLO의 최근 버전 세 가지 모델 v3, v4, v5를 비교하는 실험을 진행하였다. 차이점과 구조, 그리고 같은 데이터셋에서 보이는 성능의 차이를 실험을 통해 비교해보았다. 실험에 사용된 데이터셋은 국내 화성, 대구 등의 도심로에서 직접 취득한 11,500장의 이미지로 이루어져 있다. 검출 대상의 클래스는 도심로 주행 시 공사구간에서 마주칠 수 있는 객체 및 신호등 신호를 포함한 10가지 객체로 선정하였다. 꼬깔콘, 차선 스틱, PE드럼 등이 포함되어 있다. 실험은 동일한 PC와 실차 상에 탑재하여 진행하였고 그 결과를 고찰하였다.",다국어 초록 정보 없음
Actvie SLAM과 YOLO를 이용한 탐사용 UGV,2021,[],"경제 성장으로 건축물의 대형화, 밀집화, 지하화, 미로화 현상의 증가로 화재 발생 시 구조에 어려움이 증대되었다. 건물 내의 화재 발생 때 자동탐사 로봇을 활용하면 탐사 시간을 단축할 수 있다. 인적 피해를 최소화할 수 있다. Active SLAM(Simultaneous localization and mapping)를 사용하여 자동탐사를 하고 YOLO(You Only Look Once)를 사용하여 사람을 탐지하는 탐사용 로봇을 만들었다.",다국어 초록 정보 없음
교통사고 경감을 위한 적외선 카메라와 YOLO를 사용한 블랙아이스 탐지 방법 제안,2021,"['Black-Ice', 'Artificial Intelligence', 'YOLO', 'infrared cameras']","폭설로 인한 도로 미끄러짐과 기온이 0도 이하로 낮아졌을 때, 도로와 차량 통행용 다리, 터널 출입구 쪽에서 주로 발생하는 블랙아이스는 운전자의 시야에서는 아스팔트의 이미지가 투과되어 보이기에 인식되지 않아서 자동차들이 미끄러지는 상황(슬립 현상)이 발생하고, 이로 인하여 대형 교통사고로 이어져 인명 물적 손실이 대량으로 발생하기에 적외선 카메라를 이용하여 도로 상태를 확인하고 딥러닝을 통하여 블랙아이스를 판별하는 방법을 제안하고자 한다.","In case of the road slips due to heavy snow and the temperature drops below 0 degrees, black ice which mainly occurs on the road, bridges for vehicles, and tunnel entrances, is not recognized by the driver’s view because the image of the asphalt is transmitted through it. So cars” slip situation occurs, which leads to a big traffic accident and a large amount of loss of life and property. This study proposes a method to check the road condition using an infrared camera and to identify black ice through deep learning."
YOLO를 활용한 오토바이 교통법규 위반 감지 시스템 개발,2021,[],본 논문에서는 도로환경에서 CCTV 영상을 사용하여 교통법규를 위반한 오토바이 운전자 및 동승자를 자동 감지하기 위한 시스템을 제안한다. 여기서 교통법규 위반 사항은 운전자 및 동승자의 헬멧 착용 유무와 초과탑승 하였는지 대한 여부이다. 실시간 도로 CCTV 영상에서 헬멧 착용 유무를 감지하는 경우 오토바이가 겹쳐있거나 하여 교통법규를 위반한 오토바이를 정확하게 검출하기 어려운 경우가 많다. 이러한 문제를 해결하기 위하여 먼저 오토바이를 먼저 검출 후 헬멧의 착용 유무를 검출하는 2단계 방식을 제안한다. 또한 Python 기반 프레임워크에서 개발 및 학습을 진행하고 실제 운용되고 있는 CCTV 관제 시스템에 해당 알고리즘을 넣기 위해 C# 기반 프레임워크에서 이미 학습된 가중치 파일을 사용하여 추론하는 방식으로 시스템을 구성하였다. 실험 결과 이러한 시스템으로 제안된 알고리즘에 대한 성능이 프레임워크에 무관하게 유사한 성능을 가짐을 보인다.,다국어 초록 정보 없음
YOLO를 이용한 수중 그물 손상 탐지 기법 설계,2021,"['Deep Learning', 'Defect Detection', 'Underwater Vision', 'ROV']",국문 초록 정보 없음,다국어 초록 정보 없음
YOLO를 이용한 불건전 객체 모자이크 서비스,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
YOLO를 이용한 공사 현장 작업자의 보호장구 착용여부 및 위험지역 진입여부 검출,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
YOLO-v5 모델을 이용한 실시간 도난 감지 시스템,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
YOLO를 이용한 공사 현장 작업자의 보호장구 착용여부 및 위험지역 진입여부 검출,2021,[],"공사장에서 허술한 안전관리로 인해 안전모나 마스크 등의 안전장비를 착용하지 않아 발생하는 사망사고가 지속적으로 발생하고 있다. 본 연구에서는 YOLOv5를 이용하여 공사장 CCTV 영상을 분석하여 작업자의 안전모와 마스크 착용을 실시간 검사할 수 있는 모델을 제시한다. 기존 연구가 안전모와 마스크의 객체검출에 초점을 둔 반면, 본 연구에서는 안전모와 마스크의 검출뿐만 아니라 그것들이 각각 머리와 얼굴에 올바로 착용되었는지까지 판단하였다. 또한 작업자가 위험지역에 진입했는지 여부도 실시간으로 탐지하여 안전사고를 방지하도록 하였다. 이를 위해 안전모와 마스크는 Kaggle Datasets을 이용하고, 인체(사람, 머리, 얼굴) 데이터는 Open Image Dataset을 활용하였다. 안전모 검출 위치와 마스크 검출 위치 및 착용여부 판정을 위한 인체 검출 위치를 종합한 안전모 및 마스크 착용 여부 검사 정확도는 95%, 속도는 40fps로 실시간 검사가 가능한 것으로 나타났다.",다국어 초록 정보 없음
YOLO를 활용한 오토바이 교통법규 위반 감지 시스템 개발,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
YOLO모델기반 영상 속 축구 선수의 위치 검출 및 분석 시스템,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
화재예방 감시 시스템의 YOLO를 기반으로 한 실시간 화재 영상 검출,2021,"['fire', 'rtsp camera', 'object detection', 'edge computing']",국문 초록 정보 없음,다국어 초록 정보 없음
자율주행차량에 적용가능한 AI모델링 연구에 대한 소고 (Yolo5를 중심으로),2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
잎사귀 질병 검출을 위한 관심 영역 특징 추출 기반의 어텐션 강화 YOLO 모델,2021,"['attention YOLO model', 'object detection', 'image segmentation', 'deep convolutional neural networks', 'smart farm']",국문 초록 정보 없음,"The YOLO model, which is widely used in the existing object detection, excludes the attention function that can learn which feature vectors are more important. Therefore, in this paper, we propose an attention YOLO model that can improve the object detection performance of the existing YOLO model. The proposed attention model was conceived from the fact that there is no information on diseases in the background area of the input leaf image, and spots and color information that can determine the presence or absence of the diseases exist only inside the leaf. By combining the YOLOs feature extraction subnetwork with the image segmentation subnetwork capable of dividing the background, leaf, and disease areas from the input leaf, it is intended to improve the ability to distinguish features in the region of interest. In other words, a new attention model that can spatially reinforce the importance of disease-related features in the YOLO model is introduced. In addition, through the experimental results, it is shown that the proposed attention YOLO model can improve the detection performance by about 0.06 in the mean Averaged Precision（mAP) evaluation compared to the existing YOLO model."
YOLO 인공지능 플랫폼을 이용한 이상행동 감시 시스템,2021,"['이상행동 감시', 'one-shot 감지', 'Abnormal Behavior Monitoring', 'YOLO', 'one-shot-detection']","본 논문에서는 YOLO 인공 지능 플랫폼을 이용하는 이상행동 감시 시스템을 구현하였으며, YOLO 시스템의 one-shot 감지 시스템 사용으로 기존 감시 시스템에 비해 우수한 응답 특성을 갖는다. YOLO 인공 플랫폼은 폭행, 절도, 방화와 같은 이상행동들로 구성된 이미지 세트로 학습되었다. 이상행동 감시 시스템은 서버와 클라이언트로 구성되어 있으며, 상용화될 경우 각종 범죄 문제를 풀기 위해 스마트시티에 적용이 가능하다.","In this paper, abnormal behavior monitoring system using YOLO AI platform was implemented and had superior response characteristics compared to the conventional monitoring system using two-shot detection by using one-shot detection of YOLO system. The YOLO platform was trained using image dataset composed of abnormal behaviors such as assault, theft, and arson. The abnormal behavior monitoring system consists of client and server and can be applicable to smart cities to solve various crime problems if it is commercialized."
YOLO v4 기반 혼잡도로에서의 움직이는 물체 검출 및 식별,2021,"['person', 'motocycle', 'bicycle', 'bus', 'car', 'detection', 'YOLO v4']","일부 네거리나 혼잡도로에서 특정 시간대에 행인이 많고 도로가 막혀서 발생하는 교통사고가 적지 않다. 특히 인근에 학교교차로가 있어 바쁜 시간에 학생들의 교통안전을 지키는 것이 중요하다. 과거에는 교통 신호등을 설 계 했을 때 행인의 안전성을 고려하지 않고 자동차 인식과 교통 최적화에 대하여 연구 했다. 행인, 특히 학생들의 안전을 확보하 는 전제에서 가능한 한 도로의 소통을 유지하는 것이 본 연구의 중점적인 연구 방향이다. 본 연구는 사람, 오토바이, 자전거, 자동차, 버스의 식별문제를 중점적으로 연구할 것이다. 조사와 비교를 통해 본 연구는 YOLO v4 네트워크로 목표물의 위치와 수량을 식별하는 것을 제시한다. YOLO v4는 작은 목표물의 식별 능력이 강하고 정밀도가 높으며 처리 속도가 빠르다는 특징을 가지고 있으며, 데이터 수집 대상을 설정하여 이미지 집합을 훈련하고 테스트 한다. 움직이는 영상에서 목표물의 정확도, 실수율과 누락율에 대한 통계를 사용하여, 본 연구에서 훈련된 네트워크는 움직이는 이미지 속의 사람, 오토바이, 자전거, 자동차와 버스를 정확하게 식별 할 수 있다.","In some intersections or busy traffic roads, there are more pedestrians in a specific period of time, and there are many traffic accidents caused by road congestion. Especially at the intersection where there are schools nearby, it is particularly important to protect the traffic safety of students in busy hours. In the past, when designing traffic lights, the safety of pedestrians was seldom taken into account, and the identification of motor vehicles and traffic optimization were mostly studied. How to keep the road smooth as far as possible under the premise of ensuring the safety of pedestrians, especially students, will be the key research direction of this paper. This paper will focus on person, motorcycle, bicycle, car and bus recognition research. Through investigation and comparison, this paper proposes to use YOLO v4 network to identify the location and quantity of objects. YOLO v4 has the characteristics of strong ability of small target recognition, high precision and fast processing speed, and sets the data acquisition object to train and test the image set. Using the statistics of the accuracy rate, error rate and omission rate of the target in the video, the network trained in this paper can accurately and effectively identify persons, motorcycles, bicycles, cars and buses in the moving images."
잎사귀 질병 검출을 위한 어텐션 YOLO 모델,2021,"['Attention YOLO Model', 'Object Detection', 'Image Segmentation', 'CNN', 'Smart Farm']","기존 객체 검출에서 사용되고 있는 YOLO 모델은 특칭 추출과 분류를 한 번에 진행하여 빠르고 간단한 것이 특징이다. 실시간 객체 검출에서 사용할 수 있을 정도의 성능을 보이지만, 정확도 측면에서는 조금 아쉬운 것이 사실이다. 이러한 YOLO 모델을 잎사귀 질병 검출에서 활용할 때, 어텐션 기법을 활용해 잎사귀 질병의 특징을 적용한 모델과 기존 객체 검출 모델들의 성능을 비교하고자 한다.","The YOLO model is characterized by a simple feature extraction and classification at once. Although it shows performance enough to be used in real-time object detection, It is true that it is a bit disappointing in terms of accuracy. When using this YOLO model for leaf disease detection, we intend to create and apply a feature map for the region of interest to improve accuracy. Also, we want to compare the performance of the applied model and the existing object detection models."
YOLO 알고리즘을 이용한 전차 국적 식별 및 평가,2021,"['객체탐지', 'YOLO(You Only Look Once) 알고리즘', '딥러닝', '데이터셋', '전차', '피아식별 시스템', 'object detection', 'YOLO(You Only Look Once) algorithm', 'deep learning', 'dataset', 'tank', 'Identification of Friend or Foe', 'mAP', 'IoU']","인공지능 딥러닝 기술이 적용된 무기체계가 지속적으로 개발된다. 기존의 전차 피아식별 시스템은 사람의 눈으로 표적을 획득하고 공격 여부를 판단한다. 따라서 신속성과 정확성 측면에서 한계가 존재한다. 본 연구에서는 이러한 제한사항을 개선하기 위해 YOLO(You Only Look Once) 알고리즘 기반의 전차 국적 식별 방법을 제안한다. 먼저, 한국, 미국, 일본, 북한의 4개국의 주력 전차 사진을 수집한다. 특히, 실제 기갑 전투의 상황과 유사하도록 노이즈를 추가하고 이미지 전처리 작업을 한다. 이후 데이터셋은 학습 데이터의 적절한 규모를 확인하기 위해 8개의 그룹으로 구성한다. 마지막으로 평가 척도인 mAP와 IoU를 기반으로 적절한 데이터 규모를 분석한다.","Advanced weapon systems with artificial intelligence deep learning technology will be continuously. The existing identification system of friend or foe on tank targets with human eyes determine whether to attack. Therefore, there are limitations in terms of speed and accuracy. In this paper, we propose a YOLO(You Only Look Once) Algorithm-based tank nationality identification method to improve these limitations. First, we collect photos of the main tank from four countries South Korea, the United States, Japan and North Korea. In particular, similar to the actual armored battle, we add noise and do image preprocessing. Afterward, the dataset organized into eight groups to check the appropriate size of the learning data. Finally, we analyze the appropriate data size based on the evaluation scales, mAP and IoU."
결함검출 적용을 위한 YOLO 딥러닝 알고리즘 비교,2021,"['YOLO', 'Deep learning', 'Object detection', 'Defect detection', 'CNN']",국문 초록 정보 없음,"Recently, metal 3D printing technology has developed and has been widely applied in fields such as mechanical parts and construction sites. However, the problem of output defects must be resolved. These defects appear as pores and microcracks in the output, which can be confirmed through microscopic analysis of the output. In addition, if the understanding of pores or cracks is unclear or many images need to be checked in a short time, an error might occur. Therefore, this study aims to develop a precision object detection algorithm using deep learning. The purpose is to automatically detect defects using deep learning-based You Only Look Once (YOLO). Through comparison using YOLO v3 and v5 algorithms, the accuracy and speed were compared to analyze which YOLO model was efficient in the defect detection process."
허프변환과 YOLO 기반의 골프공 궤적 추적,2021,"['골프 공', '추적', '차영상', '임계값', '허프 변환', '욜로-V3', 'Golf ball', 'Tracking', 'Frame Differencing', 'Threshold', 'Hough Transform', 'YOLO-V3']","드라이브나 티샷을 할 때 육안을 통해 수동적으로 골프공의 궤적을 시각화하는 것은 어려운 작업이 될 수 있는데, 그 이유는 공의 크기가 작고 공이 이동하는 속도가 빠르기 때문이다. 이러한 작업의 특성으로 인해 값비싼 센서 및 구성 요소를 사용하여 제조된 복잡한 장치가 항상 요구되어 왔습니다. 본 논문에서는 골프 티샷중 골프공의 궤적을 추적하는 시스템을 제안한다. 제안하는 시스템은 기존의 컴퓨터 비전 기술과 현대적인 심층 신경망을 결합하여 모노 스테레오 비디오에 궤적을 추적한다. 골프 볼 추적에 앞서, 골프공과 플레이어의 위치를 특정 짓기 위해 YOLO(You Only Look Once) V3 딥 신경망 모델을 사용한다. 우리는 클럽과 공 사이의 초기 충격 지점을 추적 하기 위해 허프 변환을 사용한다. 또한 볼을 추적하기 위해 차영상을 이용하여 비디오의 모션 정보를 추출한다. 제 안하는 시스템의 효과를 검증하기 위해 다수의 비디오에서 테스트되었으며 각각의 결과를 보여준다.","Manually visualizing the golf ball's trajectories during a drive or a tee shot could be an unsettling task for viewers, the reason being the small size of the ball and the high speed at which it travels. This nature of the job has always required intricate systems manufactured using an expensive set of sensors and components. In this paper, we propose a system to draw the trajectory of a golf ball during a drive. The proposed system combines the classical computer vision techniques and a modern deep neural network to project the trajectories over videos taken from monocular cameras. Before starting to track the ball, the system uses YOLO(You Only Look Once) V3, deep neural network model to perform localization of the golf ball and the player. To track the initial point of impact between the club and the ball the system uses Hough transform. Finally to track the ball, the system extracts motion information of the video by using frame differencing. Unto the information received from frame differencing, the system applies filters based on a few assumptions, size and direction of movement to obtain the detections of the golf ball. The proposed system was tested on a multitude of videos to verify its effectiveness and the respective results are presented."
SMD Detection and Classification Using YOLO Network Based on Robust Data Preprocessing and Augmentation Techniques,2021,"['PCB inspection', 'SMD inspection', 'Classification', 'Detection', 'YOLO']",국문 초록 정보 없음,"The process of inspecting SMDs on the PCB boards improves the product quality, performance and reduces frequent issues in this field. However, undesirable scenarios such as assembly failure and device breakdown can occur sometime during the assembly process and result in costly losses and time-consuming. The detection of these components with a model based on deep learning may be effective to reduce some errors during the inspection in the manufacturing process. In this paper, YOLO models were used due to their high speed and good accuracy in classification and target detection. A SMD detection and classification method using YOLO networks based on robust data preprocessing and augmentation techniques to deal with various types of variation such as illumination and geometric changes is proposed. For 9 different components of data provided from a PCB manufacturer company, the experiment results show that YOLOv4 is better with fast detection and classification than YOLOv3."
YOLO v3를 이용한 높은 정확도의 차량 계수 방법,2021,"['Vehicle detection(차량 검출)', 'Deep learning(딥러닝)', 'Convolutional neural network(합성곱신경망)', 'Traffic surveillance data(교통감시데이터)', 'YOLO(You Only Look Once', '욜로)']",국문 초록 정보 없음,다국어 초록 정보 없음
Real-Time License Plate Detection for Non-Helmeted Motorcyclist Using YOLO,2021,"['YOLO', 'Helmet detection', 'LP detection', 'Centroid tracking']",국문 초록 정보 없음,"Nowadays, detection of license plate (LP) for non-helmeted motorcyclist has become mandatory to ensure the safety of the motorcyclists. This paper presents the real-time detection of LP for non-helmeted motorcyclist using the real-time object detector YOLO (You Only Look Once). In this proposed approach, a single convolutional neural network was deployed to automatically detect the LP of a non-helmeted motorcyclist from the video stream. The centroid tracking method with a horizontal reference line was used to eliminate the false positive generated by the helmeted motorcyclist as they leave the video frames. The overall LP detection rate was 98.52%."
YOLO 환경에서 손가락 방향감지 알고리즘 설계 및 구현,2021,"['Finger Direction Recognition', 'Object Detection', 'Training Data']","본 논문에서는 YOLO (You Only Look Once) 라이브러리를 이용하여 사용자의 손가락 방향을 감지하는 알고리즘을 제안하였다. 제안한 손가락 방향감지 알고리즘의 처리단계는 학습 데이터 관리단계, 데이터 학습 단계, 그리고 손가락 방향감지 단계로 구성된다. 실험 결과, 카메라와 손가락 간의 거리는 손가락 방향 감지 정확도에 매우 큰 영향을 미침을 알 수 있었다. 차후 제안 알고리즘의 정확도 및 신뢰도의 개선 후에 이 기능을 커틀봇3 (Turtlebot3)에 적용할 예정이다.","In this paper, an algorithm that detects the user's finger direction using the YOLO (You Only Look Once) library was proposed. The processing stage of the proposed finger direction detection algorithm consists of a learning data management stage, a data learning stage, and a finger direction detection stage. As a result of the experiment, it was found that the distance between the camera and the finger had a very large influence on the accuracy of detecting the direction of the finger. We plan to apply this function to Turtlebot3 after improving the accuracy and reliability of the proposed algorithm in the future."
욜로(YOLO)족의 여행경험에 관한 실존적 진정성 척도개발 및 타당성 연구,2021,"['YOLOs', 'Existential authenticity', 'Introspection', 'Kierkegaard', 'Scale development', '욜로(YOLO)', '실존적 진정성', '자아성찰', '키에르케고르', '척도개발']",국문 초록 정보 없음,다국어 초록 정보 없음
단안카메라와 YOLO V3 네트워크를 활용한 객체 거리 추정 알고리즘,2021,"['Self-Driving Cars(자율주행자동차)', 'Monocular camera(단안카메라)', 'YOLO V3 Network(욜로 V3 네트워크)', 'Depth Estimation(거리 추정)', 'Proportional Expression(비례식)']",국문 초록 정보 없음,"For self-driving, measuring the distance of forward object is used to several area such as preventing rear-end collisions. Currently, LiDAR in self-drving cars measure distance with high accuracy, but it is difficult to commercialize due to the high cost. In this paper, we propose an algorithm for estimating depth at a low cost using a monocular camera. The algorithm use the video of a monocular camera as input to YOLO V3 Network and use the object detection result data to calculate the pixel unit distance. We define the proportional expression using pixel unit and calculate the depth to object by inverse perspective mapping. The depth estimated by a monocular camera is similar to the distance measured by LiDAR in a specific road section."
경기 불황과 욜로(YOLO) : 지각된 부정적 경제 상황이 소비자의 현재에 편향된 선호에 미치는 영향,2021,"['경기 불황', '욜로', '현재 편향 소비', '암묵적 이론', 'MZ 세대', 'Recession', 'YOLO', 'Present-Biased Consumption', 'Implicit Theory', 'MZ Generation']",국문 초록 정보 없음,다국어 초록 정보 없음
불선명 UAV 환경에서 고도와 속도에 따른 YOLO 성능 변화 분석,2021,[],"탐색 및 구조활동에서부터 적을 탐지, 타격하는 등의 군사작전까지 다양하게 활용되고 있는 UAV는 고도와 속도에 따라 다른 영상을 취득하게 된다. 따라서 목표로 하는 물체가 영상에서는 불선명 또는 작아지는 현상을 볼 수 있다. 본 논문에서는 UAV의 비행 제원(고도, 속도)에 따라 취득되는 불선명 또는 작은 물체의 영상을 YOLO Image Detection 과정을 통해 변화하는 성능을 분석한다. 이 분석결과를 통해 80%이상의 YOLO 검출 성능을 보장하는 UAV의 비행 제원을 도표로 제시한다.",다국어 초록 정보 없음
YOLO 알골리즘 성능 비교를 통한 미세조류 이미지 분류 적용성 평가,2021,"['미세조류', '딥러닝(Deep learning)', 'Object detection', 'YOLO', 'tiny 모델']",국문 초록 정보 없음,다국어 초록 정보 없음
YOLO 를 이용한 CNN 기반의 물체 인식과 파지 중심점 위치오차 최소화 알고리즘 연구 및 파지 성능 평가,2021,"['Machine Vision', 'Visual Servoing', 'Object Detection', 'Convolutional Neural Network', 'Transformation Matrix']",국문 초록 정보 없음,"In the last few years, the use of robot manipulators has attracted increasing attention in various industries. Accordingly. Researchers have proposed unique ideas for co-robot control using vision sensors. In this study, you only look once (YOLO) based on convolutional neural network (CNN), and grasping center point position error minimization algorithms were proposed to reduce object misrecognition and increase the performance for grasping an object. In addition, a gripping algorithm was designed for six degree of freedom (DOF) robot manipulators. In addition, machine vision algorithms, including a Grayscale, Gaussian filter, Canny edge, and Contouring, were implemented to detect objects features, such as centroids and orientation. Furthermore, the coordinate system of the vision sensor was converted into a coordinate system of the robot manipulator using a transformation matrix to accurately move the end effector of the robot arm to the center point of the object. The logic implemented in this study not only detected the trained object on the workstation, but also minimized the positional error of the transformation matrix. Additionally, experiments were performed on the 6-DOF robot manipulators. The results revealed that the end effector of the 6-DOF manipulators successfully moved to the center of the detected object, and each of the eight objects was normally gripped."
YOLO v2 Tiny에서 하드웨어 가속화를 위한 Convolution 구조,2021,[],국문 초록 정보 없음,"In this paper, we propose a convolution operation structure to accelerate the operation of convolution in YOLO v2 Tiny model. When a deep learning model is operated in hardware through a GPU, there is a problem of accessing and calculating the same data multiple times due to the small memory capacity of the hardware. To compensate for this problem, we propose a channel convolution method and a pipelining operation structure in the proposed convolution operation structure. Through channel convolution, the result is output without storing the partial sum generated during the convolution operation, and the access time for storing and loading in DDR memory and block ram is minimized. In addition, through pipeline convolution, the operation speed is improved by 2.57 times compared to general convolution."
YOLO 기반 제주 연안 괭생이모자반 유입 모니터링 시스템,2021,"['machine learning', 'object detection', 'YOLO']",국문 초록 정보 없음,다국어 초록 정보 없음
YOLO 신경망 기반의 UAV 영상을 이용한 건물 객체 탐지 분석,2021,"['Object Detection', 'Building Object Detection', 'YOLO', 'UAV', 'Spatial Analysis', '객체탐지', '건물탐지', '공간분석']",국문 초록 정보 없음,다국어 초록 정보 없음
"욜로(YOLO)가 소비행복에 미치는 영향 : 감정적 충동구매, 인지적 충동 구매 및 개인주의적 가치소비의 매개 효과",2021,"['욜로', '소비행복', '감정적 충동구매', '인지적 충동구매', '개인주의적 가치소비', 'YOLO', 'Consumption Happiness', 'Affective Impulse Buying', 'Cognitive  Impulse Buying', 'Egoistic Value Consumption']",국문 초록 정보 없음,다국어 초록 정보 없음
화질 선명도에 따른 YOLO 객체 탐지 비교 및 분석,2021,[],"딸기 성숙도를 분류하기 위한 학습 모델의 프로토타입을 설계 및 구현하였지만, 흐릿한 객체는 탐지하지 못하고 선명한 객체만 탐지 및 판별하는 것을 확인하였다. 이를 해결하기 위해 이미지 처리 기술의 Sharpening을 이용하여 이미지의 객체 선명도를 높인다면 인식될 것이라 추측하였다. 따라서 본 연구에서는 딸기의 Blur 이미지 처리와 객체 탐지를 위해 OpenCV와 YOLO v3를 이용하였으며, 선명도의 다양한 변경에 따른 Blur 이미지의 객체 탐지 성능을 비교 및 분석하였다.",다국어 초록 정보 없음
레이더 데이터를 이용한 YOLO 기반 3차원 Object Detection,2021,[],"비가시 공간의 물체를 탐지하는 기술은 군사적, 인명 구조, 자율주행 등의 다양한 목적에서 주목받고 있다. RF 레이더 신호는 벽을 투과하여 물체를 측정할 수 있으므로 이 일을 수행하기 적합한 센서 형태로 꼽히고 있다. 본 논문에서는 MIMO 안테나의 UWB 레이더 칩을 통해 수집한 신호를 복셀화하여 데이터셋을 만든 뒤, YOLO 기반 네트워크에 학습시켜 비가시 공간의 물체를 3D Object Detection을 수행하여 분류하고 위치를 추정하는 방법을 제시하였다.",다국어 초록 정보 없음
A Study on Fruit Quality Identification Using YOLO V2 Algorithm,2021,"['YOLOV2', 'Region Of Interest', 'Bound Box', 'R-CNN', 'Artificial Intelligence']",국문 초록 정보 없음,"Currently, one of the fields leading the 4th industrial revolution is the image recognition field of artificial intelligence, which is showing good results in many fields. In this paper, using is a YOLO V2 model, which is one of the image recognition models, we intend to classify and select into three types according to the characteristics of fruits. To this end, it was designed to proceed the number of iterations of learning 9000 counts based on 640 mandarin image data of 3 classes. For model evaluation, normal, rotten, and unripe mandarin oranges were used based on images. We as a result of the experiment, the accuracy of the learning model was different depending on the number of learning. Normal mandarin oranges showed the highest at 60.5% in 9000 repetition learning, and unripe mandarin oranges also showed the highest at 61.8% in 9000 repetition learning. Lastly, rotten tangerines showed the highest accuracy at 86.0% in 7000 iterations. It will be very helpful if the results of this study are used for fruit farms in rural areas where labor is scarce."
YOLO 알고리즘과 point cloud data를 활용한 어린이보호구역에서의 운전자 주변 정보 제공 방안,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
YOLO 기반의 실시간 안전장비 착용 및 이상행동 감지 시스템,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
YOLO 기반 효율적인 인간 추적 프레임워크,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
YOLO 기반 항공 영상 소형 표적 검출 특성 분석,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
YOLO(v5)네트워크를 활용한 열화상 기반의 객체 인식 알고리즘 성능 분석,2021,"['Object Detection(객체 인식)', 'Thermal Image(열화상)', 'Deep Learning(심층 학습)']",국문 초록 정보 없음,다국어 초록 정보 없음
YOLO v4를 기반으로 한 플레어 스택 객체 탐지 모델,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
YOLO 알고리즘을 이용한 전차 국적 식별 방법,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
Darknet YOLO 객체 검출기의 복수 카메라 구현,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
임베디드 보드에서의 YOLO 기반 드론 탐지,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
AP-NPU 임베디드 시스템에서의 Yolo v3 응용 최적화,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
PCB 검사를 위한 YOLO 네트워크 기반의 PCB 부품 분류 알고리즘,2021,"['PCB Inspection', 'Defect Detection', 'AOI', 'Classification', 'Deep Learning', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
2021 욜로 라이프(YOLO Life) 관련 인식 조사,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
Global Tone Mapping 기반의 영상정보 증강에 의한 YOLO 네트워크 성능 향상,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
캠코딩 및 Black-Border 변형 동영상에서 YOLO CNN 모델을 이용한 원본 영상 영역 검출 방법,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
Apple Fruit Detection for Estimating Yield using Deep Learning Algorithm (YOLO v5),2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
객체 검출을 위한 트랜스포머와 공간 피라미드 풀링 기반의 YOLO 네트워크,2021,[],"일반적으로 딥러닝 기반의 객체 검출(Object Detection)기법은 합성곱 신경망(Convolutional Neural Network, CNN)을 통해 입력된 영상의 특징(Feature)을 추출하여 이를 통해 객체 검출을 수행한다. 최근 자연어 처리 분야에서 획기적인 성능을 보인 트랜스포머(Transformer)가 영상 분류, 객체 검출과 같은 컴퓨터 비전 작업을 수행하는데 있어 경쟁력이 있음이 드러나고 있다. 본 논문에서는 YOLOv4-CSP의 CSP 블록을 개선한 one-stage 방식의 객체 검출 네트워크를 제안한다. 개선된 CSP 블록은 트랜스포머(Transformer)의 멀티 헤드 어텐션(Multi-Head Attention)과 CSP 형태의 공간 피라미드 풀링(Spatial Pyramid Pooling, SPP) 연산을 기반으로 네트워크의 Backbone과 Neck에서의 feature 학습을 돕는다. 본 실험은 MSCOCO test-dev2017 데이터 셋으로 평가하였으며 제안하는 네트워크는 YOLOv4-CSP의 경량화 모델인 YOLOv4s-mish에 대하여 평균 정밀도(Average Precision, AP)기준 2.7% 향상된 검출 정확도를 보인다.",다국어 초록 정보 없음
욜로 성향이 소비자의 충동성과 자기통제에 미치는 영향,2021,"['욜로', '현재-지향적', '시간관', '충동성', '자기통제', 'YOLO', 'Present-Oriented', 'Time Perspective', 'Impulsivity', 'Self-Control']",국문 초록 정보 없음,"This study focuses on the positive aspects of YOLO(You Only Live Once; Drake 2011, track 19) that has oftentimes been associated with impulsive and unplanned consumption behaviors. YOLO has a present-oriented time perspective that emphasizes current happiness, and also implies a philosophy of life that if you live faithfully to each day that you face now, you could be happy tomorrow as well. To better understand the concept of YOLO and its impact on consumption behavior, this study aims to investigate the effect of YOLO disposition on consumer impulsivity and self-control. We hypothesize that consumers who have YOLO disposition expect to achieve their current goals and pursue current happiness through consumption only if they meet their goals through self-control processes. To test our predictions, we conducted two experiments. The results of experiment 1 demonstrated that when the reason for saving was to spend money on travel rather than to keep money, yolo-oriented consumers put more money compared to control group. The findings of experiment 2 further revealed a significant relationship between YOLO, impulsivity, and self-control in choice context. The results demonstrated that consumers who were primed by travel(hedonic) or learning(utilitarian) goals to pursue their current well-being had a tendency to choose a third or fifth category through a process of selfcontrol, which is consistent with the goal. This suggested that present-oriented consumers had a middle or high level of self-control. These findings contribute to research on new perspectives of YOLO and offer novel insights into the relationship between YOLO disposition and self-control."
딥러닝 기반의 연기 확산거리 예측을 위한 알고리즘 개발 기초연구,2021,"['딥러닝', '연기검출', '연기 확산거리 예측', 'YOLO', 'LSTM', 'Deep learning', 'Smoke detection', 'Smoke spread distance prediction', 'YOLO', 'LSTM']","본 연구는 화재진압 및 피난활동을 지원하는 딥러닝 기반의 알고리즘 개발에 관한 기초 연구로 선박 화재 시 연기감지기가 작동하기 전에 검출된 연기 데이터를 분석 및 활용하여 원격지까지 연기가 확산 되기 전에 연기 확산거리를 예측하는 것이 목적이다. 다음과 같은 절차에 따라 제안 알고리즘을 검토하였다. 첫 번째 단계로, 딥러닝 기반 객체 검출 알고리즘인 YOLO(You Only Look Once)모델에 화재시뮬레이션을 통하여 얻은 연기 영상을 적용하여 학습을 진행하였다. 학습된 YOLO모델의 mAP(mean Average Precision)은 98.71%로 측정되었으며, 9 FPS(Frames Per Second)의 처리 속도로 연기를 검출하였다. 두 번째 단계로 YOLO로부터 연기 형상이 추출된 경계 상자의 좌표값을 통해 연기 확산거리를 추정하였으며 이를 시계열 예측 알고리즘인 LSTM(Long Short-Term Memory)에 적용하여 학습을 진행하였다. 그 결과, 화재시뮬레이션으로부터 얻은 Fast 화재의 연기영상에서 경계 상자의 좌표값으로부터 추정한 화재발생~30초까지의 연기 확산거리 데이터를 LSTM 학습모델에 입력하여 31초~90초까지의 연기 확산거리 데이터를 예측하였다. 그리고 추정한 연기 확산거리와 예측한 연기 확산거리의 평균제곱근 오차는 2.74로 나타났다.","This is a basic study on the development of deep learning-based algorithms to detect smoke before the smoke detector operates in the event of a ship fire, analyze and utilize the detected data, and support fire suppression and evacuation activities by predicting the spread of smoke before it spreads to remote areas. Proposed algorithms were reviewed in accordance with the following procedures. As a first step, smoke images obtained through fire simulation were applied to the YOLO (You Only Look Once) model, which is a deep learning-based object detection algorithm. The mean average precision (mAP) of the trained YOLO model was measured to be 98.71%, and smoke was detected at a processing speed of 9 frames per second (FPS). The second step was to estimate the spread of smoke using the coordinates of the boundary box, from which was utilized to extract the smoke geometry from YOLO. This smoke geometry was then applied to the time series prediction algorithm, long short-term memory (LSTM). As a result, smoke spread data obtained from the coordinates of the boundary box between the estimated fire occurrence and 30 s were entered into the LSTM learning model to predict smoke spread data from 31 s to 90 s in the smoke image of a fast fire obtained from fire simulation. The average square root error between the estimated spread of smoke and its predicted value was 2.74."
클라우드 플랫폼을 이용한 딥러닝 기반 장애인 주차구역 관리 시스템 구현,2021,"['Cloud platform', 'YOLO', 'CNN', 'Raspberry pi', 'Android phone', 'Deep learning']","본 연구는 딥러닝과 클라우드 플랫폼을 이용하여 장애인 복지 증진을 위한 장애인 주차 공간을 관리하는 시스템을 제안하였다. 딥러닝은 주차 영역의 자동차 영상에서 번호판 검출을 위하여 YOLO (you only look once)를 사용하였으며, 추출된 숫자 및 문자 영상에서 번호판 문자 인식을 위하여 CNN (convolutional neural network)을 사용하였다. 본 시스템은 실시간 관리가 가능하고, 동영상만으로 관리할 수 있도록 간소화하였다. 또한 기존 OCR (optical character recognition)보다 한글 문자 인식률을 높임으로서 안정성 및 정확성이 있으며, CCTV (closed circuit television)만 설치하면 주차관리가 가능하도록 함으로서 관리 영역의 확장성의 특장점을 가진다. 본 시스템은 기징 중요한 요소인 정확한 번호판 인식률을 높이는 연구와 다소 성능이 낮은 라즈베리 파이 환경에서 YOLO와 CNN 알고리즘 등을 실행하기 위한 처리속도 문재에 대한 지속적 연구가 필요하다.","This study proposed a system that manages parking spaces for the disabled, this will lead to the promotion of welfare for those who are disabled by using deep learning and cloud platforms. Deep learning used you only look once (YOLO) for license plate detection concerning car images in parking areas, and convolutional neural network (CNN) was used for license plate character recognition from extracted numbers and text images. This system can be managed in real time, and it has been simplified so that it can be managed only with video. In addition, it is recognized and accurate by increasing the recognition rate of Korean characters compared to the existing optical character recognition (OCR), and it has the advantage of scalability in the management area by enabling parking management but only if closed circuit television (CCTV) is installed. This system requires a study to increase the accurate license plate recognition rate. This is an important factor, and a continuous study on the processing speed problem to execute YOLO and CNN algorithms in a somewhat low performance raspberry environment."
제조업 근로자 안전관리를 위한 데이터셋 구축과 모델 학습,2021,[],"최근 ""중대재해 등에 관한 법률""이 제정되고 안전사고에 관한 제도적, 사회적 관심이 높아지고 있다. 본 논문에서는 제조업 현장에서 발생한 안전사고에 대해 정부 기관에서 발간한 통계 자료를 분석하고, 안전사고 발생을 줄이기 위해 위험 상황을 판정하는 모델을 구축하기 위한 딥러닝 기반에 다양한 객체 탐지 모델을 학습시켜 비교 분석하였다. 제조업 현장에 있는 CCTV에서 영상을 수집하여 직접 데이터셋을 구축하였으며, YOLO-v4, SSD, CenterNet 모델에 훈련 데이터와 검증 데이터로 이를 활용하고 학습을 진행하였다. 그 결과 YOLO-v4 모델이 mAP 81%의 수치를 얻었다. 산업 현장에서 클래스를 선정하고 데이터셋을 직접 구축하여 모델 학습을 하는 데 의의가 있으며 이를 통해 위험 상황을 판정하고 이를 추론하는 시스템의 초기 연구자료로 활용할 수 있을 것으로 사료된다.","Recently, the ""Act of Serious Disasters, etc"" was enacted and institutional and social interest in safety accidents is increasing. In this paper, we analyze statistical data published by government agency on safety accidents that occur in manufacturing sites, and compare various object detection models based on deep learning to build a model to determine dangerous situations to reduce the occurrence of safety accidents. The data-set was directly constructed by collecting images from CCTVs at the manufacturing site, and the YOLO-v4, SSD, CenterNet models were used as training data and evaluation data for learning. As a result, the YOLO-v4 model obtained a value of 81% of mAP. It is meaningful to select a class in an industrial field and directly build a dataset to learn a model, and it is thought that it can be used as an initial research data for a system that determines a risk situation and infers it."
증강현실을 위한 객체인식 기술 성능 비교,2021,"['YOLO', 'SSD', 'AR', '객체인식']",증강현실의 핵심기술은 객체인식기술이다. 최근 CNN등 다양한 인공지능 알고리즘의 개발로 인하여 영상s에서 특정 객체를 효과적으로 구분하는 것이 가능해졌다. 객체를 빠르고 정확하게 인식하는 기술이 확보되어야 더욱 현실감 있고 몰입감 있는 증강현실 콘텐츠의 구현이 가능해진다. 본 연구에서는 SSD(single shot multibox detector)를 이용한 객체인식 모델과 YOLO를 이용한 객체 인식 모델의 비교평가를 수행하였다.,"The core technology of augmented reality is object recognition technology. Recently, due to the development of various artificial intelligence algorithms such as CNN, it has become possible to effectively distinguish specific objects from images. It is possible to realize more realistic and immersive augmented reality contents only when technology for recognizing objects quickly and accurately is secured. In this study, an object recognition model using SSD (single shot multibox detector) and an object recognition model using YOLO were compared and evaluated."
객체인식을 이용한 사물 트래킹 로봇,2021,"['object recognition', 'following robot', 'YOLO']",본 연구는 사물을 직접 인식하고 따라다니는 지능형 로봇을 만들기 위해 객체인식을 연구하였다. 객체인식 프로그램은 YOLO로 신뢰도 시스템을 이용한 연산의 간편화로 속도가 빠르다. 실시간 연산처리를 통해 물체의 영상 내 좌표값을 연산하여 항상 가운데에 위치하도록 하여 움직임을 추적한다. 라이다 센서를 이용하여 가운데 위치한 물체와의 거리를 측정하며 일정한 거리를 유지하도록 한다.,"This study studied object recognition to create an intelligent robot that directly recognizes and follows objects. The object recognition program is YOLO, which simplifies the operation using the reliability system and is fast. The motion is tracked by calculating the coordinate value in the image of the object through real-time calculation processing, and always placing it in the center. Use the LiDAR sensor to measure the distance to the object located in the middle and keep a certain distance."
YOLOv5에서 자동차 번호판 및 문자 정렬 알고리즘에 관한 연구,2021,"['Vehicle License Plate', 'YOLO(You Only Look Once)', 'LPR(License Plate Recognition)', 'Character Recognition', 'Object Detection']",국문 초록 정보 없음,"In this paper, we propose a sorting method for extracting accurate license plate information, which is currently used in Korea, after detecting objects using YOLO. We propose sorting methods for the five types of vehicle license plates managed by the Ministry of Land, Infrastructure and Transport by classifying the plates with the number of lines, Korean characters, and numbers. The results of experiments with 5 license plates show that the proposed algorithm identifies all license plate types and information by focusing on the object with high reliability score in the result label file presented by YOLO and deleting unnecessary object information. The proposed method will be applicable to all systems that recognize license plates."
"반도체 칩 이미지검출 및 인식 기술을 이용한 계수 정확도 향상에 관한 연구 (openCV, YOLOv4)",2021,[],"본 논문은 x-ray머신으로 이미지를 확보하여 반도체 칩 인식 정확도 향상을 위해 openCV, YOLO v4 알고리즘을 사용하였다. 칩 릴 테이프를 선검출 후 칩 영역을 검출하기 위해 3가지 방법으로 이미지인식을 진행한 이유는 openCV Match, labelling,, YOLOv4의 각각 활용하여 결과를 알아보고 장점과 단점을 알고자 하였다. 가장 계수능력이 좋은 방법을 찾아 설득력이 있는 방법을 찾고자 한 것이다. 생산현장에서 릴 형태의 반도체 칩을 검출하는 것은 창고관리와 재고관리를 하는데 자재관리 시간을 절약하고 계수 정확도 향상하는 데 있어 매우 중요한 개선방법이다. 따라서, 반도체 릴에 있는 수량파악을 정확하게 해낼 수 있다면 인력과 시간을 줄일 수 있는 중요한 포인트이다. 스마트 공장의 일환으로 x-ray머신을 이용한 계수기를 도입하였으나 계수 정확도 면에서 만족할 만한 성과를 보이지 못했으며 오차가 발생하였다. 현재 update를 하고 있으나 각 릴마다의 오차는 재고관리에서 수량의 오차를 발생하게 되어 실물과 일치하지 않는다. 이미지를 읽고 계수의 능력을 향상하기 위해서 최적의 방법을 찾는 것은 중요한 연구과제이다. coding을 실시하여 결과를 검토하였다. openCV매칭 ,openCV 라벨링으로서는 인식능력에 한계를 보였으며, 상용화단계에 이르기까지는 많은 단계의 프로그램 구성이 필요하였다. YOLO-V4를 이용하여 반도체 칩 릴 테이프 인식 과정을 모의실험한 결과, openCV매칭,openCV라벨링에서 수작업했던 부분의 단점을 보완하여 계수를 정확하게 할 수 있었다. 본 논문의 연구 결과를 통해 알 수 있듯, YOLO 기반 X-ray 머신 이미지 반도체 칩 검출 및 인식 기술은 반도체 릴 테이프 칩 계수 속도 향상에 이바지할 수 있을 것으로 기대한다.",다국어 초록 정보 없음
비디오 Object Detection에서의 연산량 감소를 위한 방법,2021,"['Object Detection', 'Object Tracking', 'Video']",현재 단일 이미지에서 Object Detection 성능은 매우 좋은 편이다. 하지만 동영상에서는 처리 속도가 너무 느리고 임베디드 시스템에서는 real-time이 힘든 상황이다. 연구 논문에서는 하이엔드 GPU에서 다른 기능 없이 YOLO만 구동했을 때 real-time이 가능하다고 하지만 실제 사용자들은 상대적으로 낮은 사양의 GPU를 사용하거나 CPU를 사용하기 때문에 일반적으로는 자연스러운 real-time을 하기가 힘들다. 본 논문에서는 이러한 제한점을 해결하고자 계산량이 많은 Object Detection model 사용을 줄이는 방안은 제시하였다. 현재 Video영상에서 Object Detection을 수행할 때 매 frame마다 YOLO모델을 구동하는 것에서 YOLO 사용을 줄임으로써 계산 효율을 높였다. 본 논문의 알고리즘은 카메라가 움직이거나 배경이 바뀌는 상황에서도 사용이 가능하다. 속도는 최소2배에서 ~10배이상까지 개선되었다.,다국어 초록 정보 없음
딥러닝 사물 인식 알고리즘(YOLOv3)을 이용한 미세조류 인식 연구,2021,"['Deep learning', 'Microalgae', 'Object detection', 'Water supply system', 'YOLOv3']",국문 초록 정보 없음,"Algal bloom is an important issue in maintaining the safety of the drinking water supply system. Fast detection and classification of algae images are essential for the management of algal blooms. Conventional visual identification using a microscope is a labor-intensive and time-consuming method that often requires several hours to several days in order to obtain analysis results from field water samples. In recent decades, various deep learning algorithms have been developed and widely used in object detection studies. YOLO is a state-of-the-art deep learning algorithm. In this study the third version of the YOLO algorithm, namely, YOLOv3, was used to develop an algae image detection model. YOLOv3 is one of the most representative one-stage object detection algorithms with faster inference time, which is an important benefit of YOLO. A total of 1,114 algae images for 30 genera collected by microscope were used to develop the YOLOv3 algae image detection model. The algae images were divided into four groups with five, 10, 20, and 30 genera for training and testing the model. The mean average precision (mAP) was 81, 70, 52, and 41 for data sets with five, 10, 20, and 30 genera, respectively. The precision was higher than 0.8 for all four image groups. These results show the practical applicability of the deep learning algorithm, YOLOv3, for algae image detection."
노인 모니터링 로봇을 위한 실시간 객체 인식 및 쓰러짐 감지,2021,"['Object Detection', 'Fall Detection', 'Senior Monitoring Robot', 'YOLO', 'ROS']",국문 초록 정보 없음,"In an aging society, the number of elderly people living alone has been increased and it becomes significantly more important to monitor their condition. A quick response to an emergency is critical, especially for the old population, since it may lead to severe pain, functional impairment, and death. A monitoring system that can detect an emergency or an accident would be a good solution to prevent any delayed first aid. In this paper, we present the senior monitoring robots that track the motion of users and detect falls. The paper focuses on the implementation of object detection and fall detection that can be applied in real-time on the mobile monitoring system. The location of the user was detected by using the YOLO-based object detection algorithm and the user’s fall was captured by using MobileNetV2."
인조 번호판을 이용한 자동차 번호인식 성능 향상 기법,2021,"['Synthetic license plate', 'Data augmentation', 'Style transformation', 'DeblurGANv2', 'YOLO-V5']",국문 초록 정보 없음,"A lot of license plate data is required for car number recognition. License plate data needs to be balanced from past license plates to the latest license plates. However, it is difficult to obtain data from the actual past license plate to the latest ones. In order to solve this problem, a license plate recognition study through deep learning is being conducted by creating a synthetic license plates. Since the synthetic data have differences from real data, and various data augmentation techniques are used to solve these problems. Existing data augmentation simply used methods such as brightness, rotation, affine transformation, blur, and noise. In this paper, we apply a style transformation method that transforms synthetic data into real-world data styles with data augmentation methods. In addition, real license plate data are noisy when it is captured from a distance and under the dark environment. If we simply recognize characters with input data, chances of misrecognition are high. To improve character recognition, in this paper, we applied the DeblurGANv2 method as a quality improvement method for character recognition, increasing the accuracy of license plate recognition. The method of deep learning for license plate detection and license plate number recognition used YOLO-V5. To determine the performance of the synthetic license plate data, we construct a test set by collecting our own secured license plates. License plate detection without style conversion recorded 0.614 mAP. As a result of applying the style transformation, we confirm that the license plate detection performance was improved by recording 0.679mAP. In addition, the successul detection rate without image enhancement was 0.872, and the detection rate was 0.915 after image enhancement, confirming that the performance improved."
자율주행을 위한 동적 객체 인식 방법에 관한 연구,2021,"['Deep Learning', 'Faster R-CNN', 'Machine Learning', 'Support Vector Machine', 'Object Detection', 'Unmanned Vehicle', 'YOLO']",국문 초록 정보 없음,"Dynamic object recognition is an important task for autonomous vehicles. Since dynamic objects exhibit a higher collision risk than static objects, our own trajectories should be planned to match the future state of moving elements in the scene. Time information such as optical flow can be used to recognize movement. Existing optical flow calculations are based only on camera sensors and are prone to misunderstanding in low light conditions. In this regard, to improve recognition performance in low-light environments, we applied a normalization filter and a correction function for Gamma Value to the input images. The low light quality improvement algorithm can be applied to confirm the more accurate detection of Object's Bounding Box for the vehicle. It was confirmed that there is an important in object recognition through image prepocessing and deep learning using YOLO."
한강공원 혼잡도 측정 및 시각화 시스템,2021,"['YOLOv4', 'OpenCV', 'RaspberryPi', 'Congestion Algorithm', 'Object Detection']","최근 COVID-19로 인하여 실내 혼잡 시설을 기피하고, 야외 시설을 선호함에 따라 한강공원에 대한 시민들의 수요가 늘어나고 있다. 본 연구는 On-Board 상에서 일정 시간마다 YOLO를 통하여 한강공원의 사람 및 텐트 객체를 인식 및 계수하여 실시간 혼잡도를 시각화하여 제공하는 시스템을 개발한다. 이를 통해 한강공원을 이용하는 시민들의 쏠림 현상을 방지하고, CX(Customer Experience)를 향상시키는 것을 목표로 한다.","Recently, due to COVID-19, citizens"" demand for using Hangang Park has been increasing as they avoid indoor congestion facilities and prefer outdoor facilities. This study develops a system that provides real-time congestion by detecting and counting people and tent objects in Hangang Park through YOLO on the board. As a result, it aims to prevent the concentration of citizens using Hangang Park and improve Customer Experience (CX)."
ROS 기반의 실내자율 주행 로봇의 자기위치 인식 및 딥러닝에 의한 제어 시스템,2021,"['Robot Operating System(로봇 운영 체제)', 'Indoor Self-driving(실내 자율 주행)', 'Automated Guided Vehicle(무인 운반차)', 'LiDAR Sensor(라이다 센서)', 'Inertial Measurement Unit(관성 측정 센서)']","본 연구는 물류 센터 무인화를 위해 상자를 지역, 회사에 따라 분류하고 장애물을 실시간으로 회피하며 목표지점까지 운송하는 로봇 시스템을 개발하는 것을 목표로 하고 있다. 전체 제어 시스템은 ROS(robot operating system)로 구성하였으며, 모터 제어 및 기타 센서 처리를 위해 하부제어기로 OpenCR을 추가하였다. 또한 IMU 센서와 encoder를 결합한 odometry를 기반으로 AMCL(adaptive Monte Carlo localization) 알고리즘을 사용하여 로봇 위치를 추정 및 보정하였다. 또한 이를 LiDAR와 결합하여 맵핑 및 주행(navigation)을 진행하였다. 상자 분류는 YOLO를 통해 진행하였다. 그 결과 상자 분류를 통해 스스로 목표지점을 설정하고 라이더로 장애물을 인식하여 실시간으로 회피하는 자율주행 로봇을 구현하였다.","In this study, an indoor self-driving automated guided vehicle that recognizes objects in a logistics center and transports them to their destinations is introduced. The robot must be aware of its location while it moves and must be able to recognize its surroundings in real time to operate in the self-driving mode. The control system is composed of a robot operating system (ROS) with OpenCR used as a lower controller for motor control and other sensor processing. The robot position is estimated by combining the adaptive Monte Carlo localization algorithm (AMCL) with odometry using an inertial measurement unit sensor and an encoder, and mapping and navigation are performed by combining it with LiDAR. In addition, box classification is conducted through you-only-look-once (YOLO) object detection. Consequently, we implement a self-driving robot that sets its own target point through box classification and avoids obstacles in real time by recognizing obstacles with LiDAR."
"광주광역시 AI 산업 생태계를 위한 연합학습, 추천시스템 및 객체 인식의 사전 연구 및 테스트 분석",2021,"['AI', 'Federated Learning', 'Recommendation System', 'Object Recognition', 'AI industry ecosystem in GwangJu Metro-city']","4차 산업혁명의 열풍이 사그라들며 현실성이 떨어지는 상황에서 기업은 디지털 트랜스포메이션이 필요하다. 본 연구에서는 광주광역시 AI 산업 생태계의 디지털 트랜스포메이션을 위한 기술인 연합학습, 추천시스템 및 객체 인식을 소개 및 테스트를 진행하였다. 연합학습에서는 다수의 클라이언트로 Jetson Xavier NX을 사용하여 클라이언트가 늘어날수록 학습 모델의 정확도가 증가하는가를 검증하기 위한 테스트를 진행하였다. 추천시스템은 종류별로 소개 및 테스트를진행하였으며 객체 인식의 경우 Yolo를 사용하여 사과이미지 학습 및 객체 인식 테스트를 진행하였다.","Enterprises need digital transformation in a situation where the 4th industrial revolution's craze is fading and reality is declining. In this study, federated learning, recommendation system, and object recognition, which are technologies for digital transformation of AI industry ecosystem in Gwangju metro-city, were introduced and tested. In federated learning, tests were performed using multiple clients as Jetson Xavier NX to verify the accuracy of the training model increases as the number of clients increases. The recommendation system was introduced and tested by type, and in the case of object recognition, apple image learning and object recognition tests were performed using YOLO."
자율주행 차량 영상 기반 객체 인식 인공지능 기술 현황,2021,"['객체 인식', '자율주행 차량', '영상 기반 인공지능', '단일 단계 검출', '두 단계 검출', 'Object detection', 'Autonomous vehicle', 'Image-based AI', 'Single-step detection', 'Two-step detection.']","객체 인식이란 하나의 특정 이미지를 입력했을 때, 주어진 이미지를 분석하여 특정한 객체(object)의 위치(location)와 종류(class)를 파악하는 것이다. 최근 객체 인식 기술이 적극적으로 접목되는 분야 중 하나는 자율주행 차량이라 할 수 있고, 본 논문에서는 자율주행 차량에서 영상 기반의 객체 인식 인공지능 기술에 대해 기술한다. 영상 기반 객체 검출 알고리즘은 최근 두 가지 방법(단일 단계 검출 방법 및 두 단계 검출 방법)으로 좁혀지고 있는데, 이를 중심으로 분석 정리하고자 한다. 두 가지 검출 방법의 장단점을 분석 제시하고, 단일 단계 검출 방법에 속하는 YOLO/SSD 알고리즘과 두 단계 검출 방법에 속하는 R-CNN/Faster R-CNN 알고리즘에 대해 분석 기술한다. 이를 통해 자율주행에 필요한 각 객체 인식 응용에 적합한 알고리즘이 선별적으로 선택되어 연구개발 되어질 수 있기를 기대한다.","Object recognition is to identify the location and class of a specific object by analyzing the given image when a specific image is input. One of the fields in which object recognition technology is actively applied in recent years is autonomous vehicles, and this paper describes the trend of image-based object recognition artificial intelligence technology in autonomous vehicles. The image-based object detection algorithm has recently been narrowed down to two methods (a single-step detection method and a two-step detection method), and we will analyze and organize them around this. The advantages and disadvantages of the two detection methods are analyzed and presented, and the YOLO/SSD algorithm belonging to the single-step detection method and the R-CNN/Faster R-CNN algorithm belonging to the two-step detection method are analyzed and described. This will allow the algorithms suitable for each object recognition application required for autonomous driving to be selectively selected and R&D."
다중화면 감시 영상에서의 인물 재인식 기술에 관한 연구,2021,"['K-mean', '다중화면 영상', '객체 인식', 'Bhattacharyya distance', 'Mask-RCNN', 'K-mean', 'multi-view videos', 'object recognition', 'Bhattacharyya distance', 'Mask-RCNN']","감시 카메라는 모니터링, 스마트 시티, 화상 회의 등 여러 가지 도메인에 설치되어 사용되고 있다. 영상데이터에서 객체 탐지, 추적 및 인식과 같은 여러 작업을 수행하기 위해서는 분산 네트워크를 사용하여 알고리즘을 개발하는 것 이 필수적이다. 이를 위해 컴퓨터 영상 분야에서 단일화면에서의 이미지 및 영상분석을 위한 수많은 기술이 개발되 었다. 그러나 영상데이터 분석 분야의 논문을 살펴보면 다중화면에서의 영상분석 기술에 대한 연구는 드물다. 따라 서 본 논문에서는 일반적으로 단일화면 영상분석에 적용되는 여러 기법의 하이브리드 접근을 통해 다중화면 영상에 서 사람을 재식별하고 추적하는 방법을 제안하였다. 먼저 자체 데이터 세트를 생성하였으며, 전처리 단계를 거친 이 미지에서 YOLO를 사용하여 인물을 감지하고 Mask-RCNN을 통해 배경을 삭제하였다. 다음으로 K-Means Clustering 알고리즘을 적용하여 각각의 이미지에서 색상 특징을 추출하였다. 마지막으로 Bhattacharyya distance에 가중치를 추가하여 두 개의 이미지 클러스터 간의 유사성을 측정하는 새로운 거리 지정 알고리즘을 제 안하였다. 제안된 방법은 실험결과 86.23 평균 정밀도를 얻었으며 제안된 방법의 효과를 검증 및 확인하였다.","Nowadays, surveillance cameras are widely installed at every edge due to their largescale applications ranging from monitoring to smart city and indoor offices for video conferencing. However, to perform several tasks such as detection, tracking, and identification of persons in video data, it is an essential step to develop an algorithm specifically using a distributed network. For this purpose, numerous techniques have been developed in the field of computer vison for single-view images/video analysis. However, overviewing the literature of video data analytics, the techniques for multi-view analysis are missing on extreme level. Therefore, in this paper, we propose a method for person re-identification and tracking in multi-view images through hybrid approach of several techniques that are usually applied for a single-view image. At first, we generate our own dataset and pass the images into a preprocessing step to detect person using YOLO and subtract the background through Mask-RCNN. Next, the color features are extracted from the images which are fed into K-mean clustering algorithm. We introduce a novel distancing formula by adding weights to Bhattacharyya’s distance to measure the similarity between the clusters of two multi-view input images. The conducted experiments verify and confirm the affectiveness of the proposed method by obtaining 86.23 average precision."
작업자 안전을 위한 영상센서 활용 인원 계수 시스템 개발,2021,[],"인원 계수 시스템은 산업 현장 등 복잡한 구조 내에서 다양한 형태의 작업자(짐을 지고 있는 경우, 양 방향에서 오가는 경우 등)의 출입 및 재실인원 정보를 파악하기 위해 만든 안전장치이다. 본 논문에서는 이 시스템의 정확한 작동을 위해 CMOS 이미지 센서를 활용한 영상데이터 라벨링 기법, YOLO를 통한 영상AI학습 방법(Making Box), People Counting 알고리즘을 소개한다.",다국어 초록 정보 없음
수소 충전소 영상 정보를 이용한 AI 모델 기반의 실시간 차량 카운팅 시스템에 관한 연구,2021,"['bject detection', 'deep learning', 'API Gateway', 'image roi', 'image crop']","본 논문은 수소충전소의 대기 차량 정보 제공올 위해 카메라 영상 정보를 수집하여 AI 모델 기반으로 객체를 검출하고 인식된 차량의 대수를 사용자 어플리게이션에 노출시키는 것을 목적으로 한다. 시스템 구성은 수소 충전소내 영상 정보를 기반으로 하며 객채 검출 모델은 YOLO-v4를 사용하였고, 외부 정보 제공을 위한 API Gateway로 구생하였다. 영상 처리는 전처리 단계에서 관심 영역을 설정 하였으며, 모델 학습을 위한 데이터는 Training data set 과 Test dataset 의 비율을 8:2 로 진행하였다. 이를 통해 충전소 대기 차량, 도로 위를 달리는 차량 그리고 주차된 차량을 구분하여 검출함으로써 정확도가 Pre-train 모델 대비 큰 폭으로 증가하였다.",다국어 초록 정보 없음
건설현장 작업자 안전관리를 위한 딥러닝 기반 객체탐지 알고리즘 분석,2021,"['건설현장 영상', '객체탐지', '딥러닝', 'Construction Site Image', 'Object Detection', 'Deep Learning']","건설 산업은 자동으로 생산성을 분석하고 안전의 측면에서 활동을 모니터링하기 위하여 현장 카메라 영상을 알고리즘과 연결함으로써 기계 지능으로부터 잠재적으로 이점을 얻을 수 있다. 하지만, 건설현장 영상에의 제한된 접근성, 수동적인 주석작업으로 인한 노동력 및 시간 소모 등의 문제로 효과적인 영상 데이터 구축이 어려운 실정이다. 본 논문에서는 건설현장장비로 구성된 이미지 데이터 세트의 구축을 위한 사례 연구를 보여준다. 10 종류의 건설현장 장비의 대량의 이미지를 수집한 후 장비의 종류 및 위치에 대하여 이미지에 주석작업을 한다. 구축된 데이터 세트의 효율성을 검증하기 위해 YOLO-v3, Inception-SSD의 알고리즘을 이용하여 데이터를 학습시킨 후, 대표적인 객체 알고리즘 성능평가 방법인 mAP(mean Average Precision) 수치 및 탐지 속도를 구한다. 최종적으로 건설현장의 객체들을 실시간 탐지하기 위한 가장 효율적인 객체 탐지 알고리즘을 분석한다.",다국어 초록 정보 없음
딥러닝 기반 건설 현장 작업자 안전관리 시스템 개발,2021,[],각종 건설 현장에서 안전모 미착용은 주된 위험 요인 중 하나이다. 현장에서 관리자가 직접 작업자들의 안전모 착용 여부를 감독할 수 있지만 관리자가 항상 관리가 가능한 장소에 있어야 하는 한계가 있다. 본 연구에서는 안전모 착용 여부를 딥러닝 기반으로 인식하여 건설 현장에서의 안전 관리를 할 수 있도록 하는 시스템을 제안한다. 이를 위해 대표적인 객체 인식 알고리즘인 YOLO를 사용하여 현장에서의 안전모 착용 여부를 인식한다. 다음으로는 인식된 결과를 바탕으로 위험 상황을 판단하는 알고리즘을 제안한다. 제안된 시스템을 활용하면 효율적으로 건설 현장의 위험 상황을 관리할 수 있을 것으로 기대된다.,다국어 초록 정보 없음
산불 연기 데이터셋 구축 및 심층 신경망 기반 검출 기술 비교 분석,2021,[],"최근 화재 재해를 예방하기 위해 CCTV 를 이용한 화재 감지 기술의 필요성이 증대되고 있다. 화재를 감지하기 위해, 열 연기 및 불꽃에 대한 여러 센서기반 감지 장치가 사용되고 있으나, 제한적인 감지 범위 및 주변 환경의 요소에 따라 사용이 제한되는 단점이 있다. 이 문제들을 해결하기 위해 영상기반 화재 연기 감지 기술이 개발되고 있다. 본 논문에서는 영상기반 산불 연기 검출의 효율적 연구를 위해 객체검출 방법 중 잘 알려진 YOLO-v3, Faster R-CNN, Retina-Net, Corner-Net, Center-Net 에 대해 성능 비교를 진행하였다.",다국어 초록 정보 없음
A Study of Data Collection Methods for Monocular 3D Object Detection,2021,"['Deep Learning', 'Monocular 3D Object Detection', '6-DoF Object Pose Estimation']",국문 초록 정보 없음,"We address data collection issues in monocular 3D object detection. Since deep learning based object detection systems often require a variety of human annotations for advanced functionalities and also a lot of training datasets for better performance, it is increasingly important for researchers to review currently available databases, and prepare their own datasets with customized labels for target applications such as monocular 3D object detection. On top of the survey of related datasets, we study two different methods of collecting new datasets. As an example of our methods, we present five realworld object instances for pure RGB-based cuboid detection, and simulate random scenes with the objects for training and testing. In order to improve detection accuracy, all the simulated objects with limitless numbers and varied sizes can appear in high resolution images. As a baseline model, we validate our datasets using the YOLO-like standard deep learning architecture. In a coarse-to-fine manner, annotations such as cuboid, segmentation masks, and 3D models are first accessible on a down-sampled version of the simulated image and then on a sequence of higher resolution sub-images possibly utilized. Finally, we discuss experimental results and future directions."
딥러닝 기반 이미지 처리를 이용한 통행 차량 높이검출 시스템,2021,"['Deep Learning', 'Height Detection', 'Image Process', 'RCNN', 'Yolo V3']","4차 산업 혁명의 시대가 열리면서, 인공지능을 활용한 연구에 관심이 증가하고 있다. 본 연구에서는 최근 들어 차량의 높이가 점차적으로 높아짐에 따라 발생하는 충돌 사고를 방지하고자 인공지능을 활용하여 차량의 높이를 사전에 정확히 측정하는 시스템을 개발하고자 한다. 본 연구에서는 Yolo V3, Mask RCNN 등을 사용한 딥러닝 방식으로 차량의 높이 측정 시스템을 개발하였다. Yolo V3를 사용하여 픽셀을 대상 영역을 추출하였다. 또한, 픽셀의 대상 영역과 빈 영역에 대한 학습은 Mask RCNN을 사용하여 수행하였다. 특히, 기존 차량의 높이 데이터(1300~2000 mm, 총 63679 개)와 보정계수를 사용하여 측정 시스템의 정확도가 98 % 이상임을 확인하였다. 본 연구 결과는 차량의 높이를 미리 정확히 예측함으로써, 지하차도, 다리 등에서의 충돌 사고를 사전에 방지하는 시스템 또는 구조물을 설치할 수 있을 것으로 예상한다. 또한, 제조업체는 진입하는 차량의 높이를 사전에 예측하는 시스템 개발 시, 시행착오를 방지하고 개발 시간 및 비용을 절감할 수 있을 것으로 예상한다.","As the era of the 4th industrial revolution opens, interest in research using artificial intelligence is increasing. In this study, we developed a system that accurately measures the height of a vehicle using artificial intelligence in order to prevent collisions that occur as the heights of vehicles have gradually increased in recent years. In this study, a vehicle height-measurement system was developed using a deep learning method with Yolo V3, Mask RCNN, etc. The target area was extracted from a pixel by Yolo V3. In addition, learning for the target area and the empty area of a pixel was performed using Mask RCNN. It was confirmed that the accuracy of the measurement system was 98% or higher by using the height data of existing vehicles (1300-2000 mm, 63679 units in total) and a correction factor. The results of this study are expected to be used to install a system or structure that prevents collisions in underground roadways and bridges by accurately predicting the height of the vehicle. In addition, when developing a system that predicts the height of an entering vehicle, manufacturers are expected to avoid trial and error as well as reduce development time and cost."
A Study on the Detection of Dangerous Objects by Virtual Reality HMD Users,2021,"['Virtual Reality', 'HMD', 'Object Detection', 'OpenCV', 'YOLO v4']",국문 초록 정보 없음,"Since the VR HMD completely blocks the wearer's field of view, accidents can be prevented in advance by removing surrounding risk factors. In general, when using VR HMD content, a method of deploying safety personnel or securing an experience space is used. However, when an individual uses content, there is a problem that the method cannot be used. In this paper, the OpenCV library and the YOLO v4 algorithm were used to improve the above problems. An object may be detected from an input real-time image using the YOLO algorithm. Object detection was implemented using the front camera of the HTC VIVE Pro Eye equipment. Through the implemented technology, VR experiencers whose eyes were blocked were able to identify risk factors through the front camera."
칫솔모 상태 판별을 위한 객체 탐지 시스템에 관한 연구,2021,"['YOLO', 'abnormal toothbrush cap', 'deep learning', 'determine']","칫솔모가 마모될 경우 치면세균막 제거율이 많이 떨어지고 세균의 수도 증가하게 된다. 칫솔모의 상태는 치아 관리에 영향을 미치므로 새로운 칫솔로 교환해야 한다 이에 본 연구에서는 칫솔모의 상태를 확인하여 변경을 권고하는 시스템을 연구 개발하였다. 학습 과정은 약 3970개의 칫솔모 이미지를 수집하고 YOLO 신경망을 활용하여 학습 결과물을 도출하였다 본 시스템은 모델 성능 평가(mAP) 99.67%, 정밀도(precision) 99% 정도로 우수한 성능을 보여준다.","If the toothbrush cap is worn out, the tooth biofilm removal rate drops a lot and the number of bacteria increases, so the condition of the toothbrush cap affects the care of the teeth, so it must be replaced with a new toothbrush. As the bristles wear, the removal rate of bacterial film on the tooth surface decreases and the number of bacteria increases. The condition of your bristles will affect your dental care and will need to be replaced with new bristles. In this research, we research and develop a system that checks the status of toothbrush hats and recommends changes. The learning process collects about 3970 toothbrush cap images and utilizes the YOLO neural network to derive the learning outputs. This system shows good earning results with values of 99.67% for model performance evaluation (mAP) and 99% for Precision (precision)."
딥러닝을 이용한 AR 환경에서의 효과적인 실시간 손 추적 시스템에 관한 연구,2021,"['증강현실', '가상현실', 'YOLO', 'HSV']","증강현실(AR: Augmented Reality) 및 가상현실(VR: Virtual Reality)은 현대인에게 매우 친숙한 기술이 되 어가고 있으며 이러한 기술의 발전에 맞추어 점점 경량화된 HMD(Head Mounted Display)도 등장하고 있다. 대표적인 조작방식은 컨트롤러의 버튼을 누르거나 스크린을 터치하는 방식이 있다. 이러한 방식 은 보조적인 장비를 통해 AR 환경에서 물체를 조작하기 때문에 직접 손으로 조작하는 방식보다는 현 실감이 떨어진다. 본 논문에서는 이러한 장비 없이 손으로만 AR 환경 내의 물체를 직접 조작하기 위 한 새로운 시스템을 제안한다. 이 시스템은 주변 환경 변화에 강인한 대응을 위해 YOLO 알고리즘을 사용하여 손을 인식하고, 실시간의 빠른 속도로 손의 모양을 인식하고 추적하기 위해 HSV(Hue Saturation Value) 색상 모델을 사용한다. 추가적으로 가상의 3D 공간 내에서 손을 움직일 수 있도록 가상 손을 생성한다. 제안한 방식은 의료, 국방, 교육 분야 내 AR/VR 장비를 이용할 수 없는 환경에서 도 고도화된 작업에 적용할 수 있다고 기대한다.",다국어 초록 정보 없음
보행자검출을 통한 상권 분석 알고리즘,2021,"['보행자 검출', 'YOLO', '상권', '빅데이터', '딥러닝', 'Pedestrian-Detection', 'YOLO', 'business district', 'big data', 'deep learning']",국문 초록 정보 없음,"In this paper, we propose an algorithm that provide services to consumers who want to conduct business by scientifically and systematically analyzing the number of pedestrians in a specific area over a specific period of time. In this paper, we proposed the algorithm to analyze the commercial area using the pedestrian-detect algorithm in the particular region using YOLO, one of the deep learning techniques. And with one image per minute in the images, the number of pedestrians is identified and this information is used for the analysis of business district on interesting area and time, systematically and objectively."
2차사고 방지를 위한 차량 간 커뮤니케이션 시스템 구현,2021,"['grouping', 'cloud server', 'object detection', 'YOLO', 'GPS']",국문 초록 정보 없음,"In this paper, we implement a vehicle-to-vehicle communication system to reduce secondary accidents in vehicles using YOLO and GPS based on a cloud environment. When an accident occurs, the client recognizes the accident through YOLO and transmits the event video data related to the accident to the cloud server. The server calculates the distance of each subscribed client based on the GPS coordinates from the accident location. In addition, clients close to the accident point are grouped, and the accident data is shared within the same group members. In this way, this paper implements a system that can apply the theoretically researched technologies to actual vehicles by comprehensively utilizing technologies such as image recognition, GPS, Cloud Server and IoT networking, as well as the newly proposed grouping technique."
딥러닝 기반 제조 공장 내 AGV 객체 인식에 대한 연구,2021,[],국문 초록 정보 없음,"In this research, the accuracy of YOLO v3 algorithm in object detection during AGV (Automated Guided Vehicle) operation was investigated. First of all, AGV with 2D LiDAR and stereo camera was prepared. AGV was driven along the route scanned with SLAM (Simultaneous Localization and Mapping) using 2D LiDAR while front objects were detected through stereo camera. In order to evaluate the accuracy of YOLO v3 algorithm, recall, AP (Average Precision), and mAP (mean Average Precision) of the algorithm were measured with a degree of machine learning. Experimental results show that mAP, precision, and recall are improved by 10%, 6.8%, and 16.4%, respectively, when YOLO v3 is fitted with 4000 training dataset and 500 testing dataset which were collected through online search and is trained additionally with 1200 dataset collected from the stereo camera on AGV."
손가락 방향 감지를 위한 이미지 데이터셋 설계 및 구축,2021,"['Deep Learning', 'Image', 'Dataset', 'Object Detection', 'YOLO', 'Labelling']","본 논문에서는 욜로(You Only Look Once, YOLO) 기반의 손가락 방향 감지 알고리즘을 이용하여 손가락 방향 감지 정확도 향상을 위한 데이터셋을 설계 및 구축하였다. 손가락 방향 감지 성능 향상을 위해 약 200개의 손가락 이미지 데이터셋을 학습하였으며, 손바닥의 각도에 따른 손가락 방향 감지 정확도를 확인하기 위해 서로 다른 각도의 비교군을 각각 50개씩 구성하여 실험하였다. 실험결과, 수평기준 90°도에 근접한 방향에 위치한 손가락 방향 감지 정확도는 다른 각도의 경우보다 더 높게 나옴을 확인하였다.","In this paper, a dataset was designed and built to improve the accuracy of finger direction detection using an object detection algorithm based on You Only Look Once (YOLO). In order to improve the object detection performance, about 200 finger image data sets were trained, and to confirm that the detection accuracy differs from each other according to the angle of the palm, 50 comparison groups of different angles were configured and tested. As a result of the experiment, it was confirmed that the detection accuracy of palm located in a direction close to 90° is higher than that of other angles."
골프공 궤적 추적을 위한 영상처리 기반의 자동화 시스템,2021,"['Golf ball', 'Frame differencing', 'Thresholding', 'Hough lines algorithm', 'YOLO.']",국문 초록 정보 없음,"Tracking a golf ball to visualize its trajectory had previously been done with complex and expensive systems. Those systems are not in the reach of every people. Here we suggest a more straightforward approach for the same purpose but utilizing only golf shots videos. The proposed system uses image processing and a deep neural network model, YOLO (You Only Live Once) V3. To achieve the goal of tracking the golf ball, the YOLO V3 network and Hough transform localize the ball’s initial position and the frame differencing technique tracks the golf ball. Upon implementation of the method to multiple videos, an acceptable result was obtained."
Application of object detection deep learning algorithms for automated detection of infiltration of mononuclear cell in SD rat liver,2021,"['Deep learning', 'Object detection', 'Infiltration mononuclear cell', 'Non-clinical study']",국문 초록 정보 없음,"The development of deep learning has shown outstanding performance in image analysis, and it has been accelerating the attempt to apply the technique to detect the pathological lesion automatically from the whole slide image (WSI) in the non-clinical study, as well as clinical study. We applied three deep learning-based algorithms including Mask R-CNN, DeepLab, and YOLO to detect mononuclear cell infiltration in SD rat liver which is one of the toxicological evidence in a non-clinical study. The lesion classified into two subtypes, lymphocytes and histiocytes infiltration, according to distinct features, therefore, trained separately. Total 4,191 tile images including the lesion were obtained from 44 WSIs for the analysis. The pathological lesions were labeled by VGG annotator 2.0.1.0, and the procedure that related to AI method, including train, validation, and test, was conducted by Tensor flow 2.1.0 powered by NVIDA 2080 Ti GPU. The dataset was divided with the ratio 7: 2: 1 using train_test_split function of scikit-learn. After the dataset division, the training dataset was augmented by 8 times using image augmentation techniques (reverse, rotation, and controlling brightness). The accuracy of prediction is determined by mean average precision (mAP), which can be inferred from the intersection of union (IoU) that measures the ratio of overlap area between the union of predictions and ground truth. After the training, the detection test accuracy rates were followed up by in order Mask R-CNN (96.74%), of DeepLab (92.07%), and last YOLO (70.16%). YOLO, the algorithm which detects the object using a bounding box, showed lower accuracy than the other two algorithms which detect the object by pixel segmentation. And Mask R-CNN, which showed the highest accuracy, might be an appropriate algorithm for the precise detection of infiltration mononuclear cell. In conclusion, we suggest pixel segmentation technique might be appropriate for more accurate detection of the lesions in WSIs."
시각장애인의 안전한 요리를 위한 주방 비전 센싱 시스템,2021,"['비전 센싱', '시각장애인', '요리', '딥러닝']","Objective: 시각장애인이 화구 사용을 안전하게 할 수 있도록 화구, 냄비, 팬 등의 조리 가열 도구, 그리고 손을 인식하여 이들의 위치 관계 정보를 알려주는 비전 센싱 기반의 요리 보조 시스템을 제안한다.Background: 한국의 장애인 1인 가구의 비율은 2011년 17.4%에서 2020년 27.2%로 증가하는 추세를 보이고 있으며, 그 수는 약 71.3만 명에 달한다(2020 장애인 실태 조사, 보건복지부). 하지만 일상생활의 필수 요소인 ‘식사 준비’는 장애인에게 ‘자립 정도가 낮은 일상생활 수행 동작’ 2순위로 선정되었다. 시각장애인은 잘 보이지 않는 상태에서 요리를 하기 때문에 화상, 화재의 두려움을 느끼지만, 조리 가열 제품 사용을 도와주는 솔루션은 고안되어 있지 않다는 점을 발견했다.Method: 시각장애인 3명을 대상으로 요리에 대한 인식, 요리 횟수, 방식, 시각을 대신하여 어떻게 정보를 파악하는지 등 요리 경험의 전반을 묻는 원격 인터뷰를 진행했다. 주방 비전 센싱 시스템은 YOLO v2 기반 딥 러닝(Matlab version)을 이용하여 구현하였다. MATLAB 기반 Image Procession을 통하여 원형의 화구와 냄비의 중심, 반지름을 인식하였다. 이미지에서 손 검출을 위해 약 3300장의 다양한 손 이미지 데이터를 YOLO v2 네트워크 detector로 학습시켰다. Detector 성능을 평가하기 위해, 250장의 테스트 이미지에서 detector 통해 계산한 손의 중심과 직접 구한 손의 중심 사이 거리를 비교했으며, 656장의 테스트 이미지로 Average Precision을 계산했다.Results: 인터뷰에 의하면 시각장애인은 주변 사물을 직접 만지고 그 위치를 기억하는 방식으로 요리를 한다. 그러나 고온의 물체는 만질 수 없기에 직접 접촉 없이 고온의 화구, 조리도구와 손의 상대적 위치를 알고 싶어 한다는 요구가 있다. 정안인에게 익숙한 직접적인 거리 수치 정보는 시각장애인에게 이해하기 어려운 형태의 정보이며, 더듬거리는 행위를 통해 사물에 대한 정보를 얻는 것이 시각장애인에게 익숙하다는 점을 바탕으로 다음 기능을 제안한다. (1) ‘화구-조리도구 정 위치 알림’ 기능은 가열 조리도구를 화구 위 정위치에 놓을 수 있도록 도와준다. (2) ‘손-조리도구 위치 알림’ 기능은 손과 조리도구 간의 좌표 관계를 파악하여 재료를 안정적으로 넣을 수 있는 위치와 냄비 주변 공간감을 알려준다. 화구 위 단안 카메라를 설치하여 얻은 영상을 YOLO v2 기반 detector를 포함한 알고리즘의 입력 데이터로 이용한다. 알고리즘을 통해 화구, 조리도구, 그리고 손의 위치정보를 비교 및 계산하고 상대적 위치를 파악해서 사용자에게 효과음 형태의 청각정보로 전달해 준다. Detector 성능 평가 결과, 중심거리 평균 오차는 27.4631px, Detection Probability는 84.8%, Average Precision은 0.8이다.Conclusion: 시각장애인이 얻기 힘든 정보를 딥러닝 기반 비전 센싱을 통해 전달하여 확실한 정보를 가지고 안전하게 요리할 수 있게끔 돕고자 하였다. 정제된 환경에서 단순화된 데이터로 실험을 했다는 한계점이 있지만, 더 많은 데이터를 학습시켜 실제 요리 상황에서도 원활하게 작동할 수 있도록 보완 및 개선할 예정이다.",다국어 초록 정보 없음
스마트폰 사진촬영을 통한 정보유출 보호시스템에 관한 연구,2021,"['YOLO', 'Image processing', 'Object detection', 'Machine learning', 'Deep learning', 'Information leakage']",국문 초록 정보 없음,"In general, information leakage security can be divided into areas that respond to threats from outsiders such as hacking or malicious code, and areas that respond to threats from insiders such as data leakage from inside to outside. Various solutions such as firewalls, VPNs, and virtualization systems are introduced to respond to threats from outsiders, and as a result, the number of cases of information leakage caused by threats from outsiders is greatly reduced. However, information leakage through threats from insiders is more damaging than threats from outsiders, making it difficult to detect in advance, and the amount of damage after information leakage can be much larger. In order to prevent information leakage through smartphone filming, which is one of insider's information leakage path, it currently uses hardware, smartphone camera security stickers, screen security films, and software uses smartphone MDM (Mobile Device Management) solutions to limit functions such as smartphone photography and data communication. In this paper, we propose a study on the information leakage protection system through smartphone shooting by installing a camera on a PC with access to sensitive information, collecting video information from cameras and designing a smartphone object detection algorithm. For this purpose, the camera is installed at the top of the center of the screen. Image frames are transmitted in real time from camera. In addition, real-time object detection is possible using YOLO, which has fast computational speed. The purpose of this paper is to develop a system for detecting smartphone objects from video information inputted from cameras. As a result, information leakage can be protected by taking pictures of smartphones."
물류센터의 자율 운반 시스템을 위한 팔레트 인식 알고리즘,2021,"['AGV', 'YOLO v3', 'Depth Camera', 'Pallet', 'World Coordinate']",국문 초록 정보 없음,"In this paper, a pallet recognition algorithm is developed for logistic AGV. The proposed algorithm is based on YOLO v3. The processed 2D data in camera coordinate system is changed into the corresponding 3D data with the aid of depth data from RGB-D camera. Experiment results show the developed algorithm is applicable to autonomous driving of AGV for logistics."
A pallet recognition and rotation algorithm for autonomous logistics vehicle system of a distribution center,2021,"['Pallet', 'YOLO v3', 'AGV', 'Orientation', 'World Coordinate']",국문 초록 정보 없음,"This paper introduces a pallet recognition and rotation measurement algorithm for logistic AGV, Based on YOLO v3 and depth camera. From the camera 2D data is collected and the coordinate system from the image is changed into the corresponding world coordination system with the aid of depth data from RealSense camera. Furthermore, by processing point cloud and RANSAC algorithm, we can get the precise orientation and direction of the pallet. Finally, in the experimental result, the autonomous driving AGV with the proposed algorithm shows the results of path planning, loading, and unloading the pallet. It also shows that the developed algorithm is applicable to autonomous driving of AGV for logistics."
SLAM 기반 전동 휠체어의 자연사물을 이용한 전동 휠체어의 위치 추종 방법,2021,"['SLAM', 'Localization', 'Natural landmark', 'YOLO']","종래 기술에서는 이동로봇(또는 자율주행 휠체어)의 현재 자기 위치를 알기 위하여, 고가의 GPS 를 장착하여 해당 센서로부터 전달받은 위치정보를 받아 Localization 을 하거나, Beacon 또는 무선통신기기의 신호 세기를 이용하는 등의 부가적인 센서를 이용하여 위치 현지화(Localization)를 하는 방식을 사용하였다. 하지만 이 방식들은 공통적으로 위치 정밀도를 높이기 위하여 고가의 센서를 사용해야 하고, Beacon 방식의 경우 실제 현장에 장비들을 일일이 설치해야 하기 때문에 실생활에 적용하기에는 많은 비용과 시간이 들어가는 문제가 있다. 따라서, 이동체의 위치현지화에서는 고가의 장비 및 번거로운 작업이 필요 없이 시스템 구축이 용이하면서 유연성 있는 위치 현지화이 가능한 기술에 대한 니즈가 있다. 본 연구에서는 종래 기술의 문제점을 해결하기 위하여, SLAM (Simultaneous Localization and Mapping)기반 이동체에 장착된 카메라에서 인식 가능한 자연사물(Natural Landmark)을 이용한 위치 현지화 기법에 대하여 소개하고자 한다. 본 연구에서 자연사물을 이용한 위치현지화 방법은 총 3 가지의 단계로 구성되어 있는데, 그 첫번째가 이동체에 장착된 2D LiDAR 를 기반으로 한 SLAM을 이용하여 환경지도를 작성하는 단계이며, 두번째로는 환경지도 작성 중에 이동체에 장착된 3D Camera (RGBD)를 이용해 영상 이미지를 획득하고, 상기 획득된 영상 이미지로부터 자연사물을 인식(YOLO 를 이용한 Object Detection 기법을 사용)하여, 상기 작성된 환경지도에 기초하여 그 위치를 랜드마크로 저장하는 단계이며, 마지막으로는 2 가지의 단계를 통하여 생성된 환경지도를 기반으로 자율주행(Navigation)을 실시할 때, 환경 지도에 저장된 자연사물이 인식될 때마다 해당 자연사물을 기반으로 위치를 보정하는 단계를 진행한다.",다국어 초록 정보 없음
Deep learning-based oil spill detection with LWIR camera,2021,"['Oil spill detection', 'YOLO', 'Object detection', 'Infrared imaging']",국문 초록 정보 없음,"The ocean covers approximately 71% of the total surface area of Earth and plays a significant role in maintaining the envi-ronment and ecosystems. Oil spills are the largest source of pollution in the ocean, mainly Bunker C oil and diesel oil used as vessel fuels. Therefore, oil spill detection is essential for marine protection, which motivated this study. Detection with radar, which is based on electromagnetic waves, is achieved using satellite synthetic aperture radar (SAR); thus, real-time detection over a small range is difficult. Hence, in this study, an oil spill detection system based on thermal imaging using a long-wave infrared (LWIR) camera is proposed. The oil spill detection algorithm utilizes the You Only Look Once (YOLO) model, which is widely used for object detection. In addition, 1,644 thermal images were labeled to evaluate the proposed system. The training and test results showed an accuracy of 96.91% and false alarm rate of 8.33%. An improved detection performance can be expected from subsequent experiments using larger image datasets."
머신러닝 기반의 물체 인식을 이용한 실시간 주차장 정보 제공 서비스,2021,"['Computer vision', 'Object detection', 'Real-Time', 'Yolo']",국문 초록 정보 없음,"In this thesis, we intend to use CCTVs installed in existing parking lots to understand the current status of parking lots and provide real-time information to users through Android applications. It describes how to set the ROI in the parking area using YOLO V3 and how to provide the number of vacancies that change in real time through the set ROI, and describes how to link CCTV-server-user using IMAGE ZMQ and FIREBASE. The user can know the real-time situation of the parking lot near the destination before arriving through the application and can come up with various measures accordingly."
Development of IoT System Based on Context Awareness to Assist the Visually Impaired,2021,"['IoT System', 'Object Detection', 'Walking Aids', 'Yolo-v3', 'Visually Impaired']",국문 초록 정보 없음,"As the number of visually impaired people steadily increases, interest in independent walking is also increasing. However, there are various inconveniences in the independent walking of the visually impaired at present, reducing the quality of life of the visually impaired. The white cane, which is an existing walking aid for the visually impaired, has difficulty in recognizing upper obstacles and obstacles outside the effective distance. In addition, it is inconvenient to cross the street because the sound signal to help the visually impaired cross the crosswalk is lacking or damaged. These factors make it difficult for the visually impaired to walk independently. Therefore, we propose the design of an embedded system that provides traffic light recognition through object recognition technology, voice guidance using TTS, and upper obstacle recognition through ultrasonic sensors so that blind people can realize safe and high-quality independent walking."
건설기계 자율주행을 위한 칼만필터 기반 시스템 상태 추정,2021,"['객체 인식(Object Detection)', '객체 추적(Object Tracking)', 'YOLO v4(욜로 버전4)', 'Scaled YOLO v4(스케일드 욜로 버전4)', 'Kalman Filter(칼만 필터)', 'Sensor Fusion(센서 퓨전)', 'Autonomous Driving(자율 주행)', 'ROS(로봇 오퍼레이팅 시스템)']",국문 초록 정보 없음,"Nowadays, construction sites lack skilled workers due to aging. In addition, as construction work increases in extreme environments, safety must be considered. The automation of construction vehicles provides a solution to this problem. However, this automation requires a localization function to accurately estimate the state of the vehicle and a perception function to estimate the surrounding state. This paper presents sensor fusion and object tracking based on kalman filter to improve the performance of localization and perception functions of unmanned construction vehicles. The algorithm was evaluated using experimental datas and the experimental result shows good performances of state estimator."
블랙박스 영상 기반 차량 및 배경 대체 영상을 이용한 실시간 MR 콘텐츠의 설계,2021,"['차량용 블랙박스', '차량 검출', '대체 영상', 'MR', '딥러닝', 'YOLO', 'Vehicle Black Box', 'Vehicle Detection', 'Substitute Video', 'MR', 'Deep Learning', 'YOLO']",국문 초록 정보 없음,다국어 초록 정보 없음
금속 3D 프린팅 공정의 결함 분석,2021,"['Metal 3D printing', 'Melting pool tomography', 'Cross-sectional analysis', 'Object detection', 'YOLO']",국문 초록 정보 없음,"Metal 3D printing is attracting attention as a new production technology. However, various problems need to be solved regarding it. In particular, defects occurring in the process of melting and solidification are relatively serious than those occurring in the traditional casting or cutting process. To solve this problem, this study introduced a tomography using a high-speed camera that can monitor the melting pool. This confirmed the possibility of finding defects by detecting an abnormality in the melting pool. In addition, if it is combined with the YOLO model, which is the latest object detection algorithm, it is judged that the integrity of the parts produced by the casting or cutting process can be secured by stopping or recovering the process through real-time inspection."
Design of an Enhanced Object Detection Algorithm through Image Scaling,2021,"['Image scaling algorithm', 'object detection', 'You Only Look Once Algorithm (YOLO)']",국문 초록 정보 없음,"This paper proposes the implementation of an image scaling algorithm with the use of an object detection algorithm. You Only Look Once (YOLO) algorithm is a quick object detection algorithm that only needs to scan an image once, before detecting objects of interest; however, there are some inaccuracies in the detection of small objects, given the limitation of the clustering boxes generated by the algorithm. Through the implementation of a scaling algorithm, the researchers investigate the increase in detection rates and the design is deemed ready for implementation."
선삭공정에서 딥러닝 영상처리 기법을 이용한 작업자 위험 감소 방안 연구,2021,"['Deep Learning(딥러닝)', 'Vision System(영상처리 시스템)', 'Negligent Accident(안전사고)', 'Convolutional Neural Network(CNN)(컨볼루션신경망)', 'You Only Look Once(YOLO)(욜로)']",국문 초록 정보 없음,"The deep learning image processing technique was used to prevent accidents in lathe work caused by worker negligence. During lathe operation, when the chuck is rotated, it is very dangerous if the operator""s hand is near the chuck. However, if the chuck is stopped during operation, it is not dangerous for the operator’s hand to be in close proximity to the chuck for workpiece measurement, chip removal or tool change. We used YOLO (You Only Look Once), a deep learning image processing program for object detection and classification. Lathe work images such as hand, chuck rotation and chuck stop are used for learning, object detection and classification. As a result of the experiment, object detection and class classification were performed with a success probability of over 80% at a confidence score 0.5. Thus, we conclude that the artificial intelligence deep learning image processing technique can be effective in preventing incidents resulting from worker negligence in future manufacturing systems."
딥러닝 기반 도로위험객체 자동 인식 및 분류에 관한 연구,2021,"['객체 인식', '객체 분류', '딥러닝', '도로위험객체', 'Recognition', 'Classificatioin', 'Deep Learning', 'Road Dangerous Object', 'YOLO']",국문 초록 정보 없음,"Various dangerous road objects such as potholes, falling objects, roadkills occur frequently on road, and the best way to prevent accidents from these dangers is to find them as soon as possible. A lot of mobile applications to report the road problems have been developed and in service worldwide both in public and private sectors. It is not safe, however, to report the problem using those apps in road environment, and it is necessary to develop a technology to minimize the time to make a report using the apps. For this purpose, a method to recognize and classify the road dangerous objects automatically from road images using deep learning algorithm was proposed and implemented, and the performance of the proposed model(YOLO v3) was tested, which shows 95% success rate on average to detect the four categories of road dangers including pavement, drainage, road facility, and roadkill, and demonstrates the possibility of the proposed method."
CNN을 이용한 지진 재난 상황에서의 지능형 교통 시스템,2021,"['ITS : Intelligent Transportation System', 'Artificial Intelligent', 'Citizen safety', 'National safety', 'Convolution Neural Network']",지진 재난 상황에서 CNN을 이용한 효과적인 지능형 도로교통 관제 시스템 (ITS : Intelligent Transportation System) 이 새롭게 제안되었다. 제안된 기술은 YOLO detector를 활용하여 지진 재난 상황에서 빠르고 정확한 도로 위험 요소를 인식하여 차량 사고로 인한 2차 재난 피해를 최소화하는데 기여할 수 있다. 아울러 정확한 인식을 위해 본 논문에서는 수동으로 구축된 사고 이미지 데이터를 사용하여 정확하고 빠른 탐지가 가능하다. 훈련된 모델은 CCTV 영상에서 획득한 이미지를 사용하여 훈련됨으로서 CCTV를 활용한 통합 관제 시스템에서 범용적으로 적용가능한 장점이 있다.,"An effective intelligent road traffic control system (ITS) using CNN in earthquake disaster situations has been newly proposed. The proposed technology can minimize secondary disaster damage caused by vehicle accidents by recognizing fast and accurate road risk factors in earthquake disaster situations using the YOLO detector. Additionally, this paper enables accurate and rapid detection using manually constructed accident image data for precise recognition. The trained model can be universally applicable in an integrated control system using CCTV as it is trained using images obtained from CCTV images."
전동 킥보드 헬멧 착용 탐지,2021,[],"최근 전동 킥보드 사용량이 크게 늘었으나, 다른 이동수단 대비 낮은 안정성과 사용자들의 헬멧 착용에 대한 인식 부족으로 인해 사고의 위험성이 큰 상황이다. 이에 대하여 정부는 헬멧 착용을 강제하는 법률을 제정하였으나, 경찰력의 한계에 따른 단속 미비로 여전히 헬멧 착용율은 낮다. 본 연구는 YOLO v3 알고리즘을 통해 학습시킨 딥러닝 모델을 활용하여 도로 상황을 촬영한 동영상 내에서 헬멧 착용자와 미착용자를 구분하고 미착용자 탐지 시 알람을 제공하는 시스템을 제시한다. 기존 YOLO 알고리즘 및 신경망을 적용하되, 전동 킥보드 데이터를 새로 수집하고 클래스를 구분하여 학습시켰다. 소수의 탐지 및 분류 오류를 보정하기 위해, 히스토그램 간 유사도를 측정해 최종적으로 객체를 추적 및 확정하고, 객체에 대한 헬멧 착용 여부를 통계적으로 확인한다.",다국어 초록 정보 없음
심층학습 기반의 자동 객체 추적 및 핸디 모션 제어 드론 시스템 구현 및 검증,2021,"['Deep learning', 'Handy motion control', 'Object detection and tracking', 'Intelligent drone system']",국문 초록 정보 없음,"In this paper, we implemented a deep learning-based automatic object tracking and handy motion control drone system and analyzed the performance of the proposed system. The drone system automatically detects and tracks targets by analyzing images obtained from the drone's camera using deep learning algorithms, consisting of the YOLO, the MobileNet, and the deepSORT. Such deep learning-based detection and tracking algorithms have both higher target detection accuracy and processing speed than the conventional color-based algorithm, the CAMShift. In addition, in order to facilitate the drone control by hand from the ground control station, we classified handy motions and generated flight control commands through motion recognition using the YOLO algorithm. It was confirmed that such a deep learning-based target tracking and drone handy motion control system stably track the target and can easily control the drone."
다양한 배경에서 도형과 색상을 활용한 얼굴 검출,2021,"['Facial Region Detection', 'Face Detection', 'Open CV', 'Image Processing', 'Character Classification', '얼굴 영역 감지', '얼굴 탐지', '이미지 처리', '인물 분류']","본 논문에서는 영상 속 인물을 탐지하고 얼굴 영역을 검출하는 방법을 제안하며, 이 방법은 2가지 작업으로 구성한다. 첫째, 서로 다른 두 명의 인물을 구분하여 프레임 내 인물의 얼굴 위치를 탐지한다. 빠른 탐지를 위해 영상 내 물체를 실시간으로 검출하는 YOLO(You Only Look Once)를 이용하여 얼굴의 위치를 탐지하고 객체탐지상자로 나타낸다. 둘째, 객체탐지상자를 바탕으로 정확한 얼굴 면적을 검출하기 위해 3가지 영상처리 방법을 제시한다. 각 방법은 검출 도형으로 추정한 영역에서 추출한 HSV 값을 이용하여 인물의 얼굴 영역을 검출하였으며 검출 도형의 크기와 모양을 바꾸어 각 방법의 정확도를 비교하였다. 각 얼굴 검출 방법은 신뢰성 검증을 위해 비교 데이터와 영상처리 데이터로 비교 및 분석하였다. 그 결과 원형, 직사각형, 분할 직사각형 방법 중 분할된 직사각형 방법을 사용했을 때 87%로 가장 높은 정확도를 달성하였다.","In this paper, we propose a method for detecting characters in images and detecting facial regions, which consists of two tasks. First, we separate two different characters to detect the face position of the characters in the frame. For fast detection, we use You Only Look Once (YOLO), which finds faces in the image in real time, to extract the location of the face and mark them as object detection boxes. Second, we present three image processing methods to detect accurate face area based on object detection boxes. Each method uses HSV values extracted from the region estimated by the detection figure to detect the face region of the characters, and changes the size and shape of the detection figure to compare the accuracy of each method. Each face detection method is compared and analyzed with comparative data and image processing data for reliability verification. As a result, we achieved the highest accuracy of 87% when using the split rectangular method among circular, rectangular, and split rectangular methods."
Human recognition in a cluttered indoor environment by sensor fusion,2021,"['Human detection', 'YOLOv3', 'Sensor fusion', 'RGB-D camera', 'LiDAR']",국문 초록 정보 없음,"The detection of human in a cluttered space is an incumbent requirement for a mobile robot functioning in an indoor environment. This paper addresses this issue in a threefold approach method to solve the human detection in an indoor environment by a mobile robot. Firstly, the distance information is obtained from the RGB-D camera and the LiDAR sensor and then it is evaluated with an extrinsic calibration method for an accurate tracking. Then, an object detector YOLO v3 is used for the human classification and detection from the image generated by the RGB-D camera. YOLO then returns the region of interest (ROI) which will be selected for the depth data for generating the human position. Lastly, the selected depth information of human is added to the position information of LiDAR sensor for more accurate localization of the human. The proposed approach shows effective human tracking result for small mobile robot interacting with human."
카메라-라이다 센서 융합을 통한 VRU 분류 및 추적 알고리즘 개발,2021,[],국문 초록 정보 없음,"This paper presents an vulnerable road user (VRU) classification and tracking algorithm using vision and LiDAR sensor fusion method for urban autonomous driving. The classification and tracking for vulnerable road users such as pedestrian, bicycle, and motorcycle are essential for autonomous driving in complex urban environments. In this paper, a real-time object image detection algorithm called Yolo and object tracking algorithm from LiDAR point cloud are fused in the high level. The proposed algorithm consists of four parts. First, the object bounding boxes on the pixel coordinate, which is obtained from YOLO, are transformed into the local coordinate of subject vehicle using the homography matrix. Second, a LiDAR point cloud is clustered based on Euclidean distance and the clusters are associated using GNN. In addition, the states of clusters including position, heading angle, velocity and acceleration information are estimated using geometric model free approach (GMFA) in real-time. Finally, the each LiDAR track is matched with a vision track using angle information of transformed vision track and assigned a classification id. The proposed fusion algorithm is evaluated via real vehicle test in the urban environment."
Object-wise Secure Image Display Method for Screen Capture Protection,2021,"['Screen capture', 'Secure image display', 'Object detection', 'Screen shot', 'Virtual fence']",국문 초록 정보 없음,"In this study, we propose an image copyright protection technology to prevent analog hole attacks using a deep object detection network. Instead of applying a virtual fence to the whole image, only a region of copyright is protected with fences. The region of copyright interest is called the protection zone and is generated by merging bounding boxes found with a YOLO network. The protection zone is adjusted to satisfy the fence generation rules, and then the virtual fence is finally applied. The main goal of this study is to attenuate the image degradation caused by virtual fences while preserving copyright protection capability. Since the virtual fence method uses the afterimage effect of the human visual system, it is necessary to generate images perceived by a human eye at every moment in order to calculate the objective image quality compared to the original unprotected image. Perceived images are generated at every 0.001 seconds using the mathematical model of the afterimage effect. The protection zone is found using object bounding boxes detected using a YOLO deep neural network. We applied the proposed method to four animation images, and the simulation results show that it achieves image quality that is about 3dB better than that of other methods."
실내 비행용 소형 충돌회피 멀티콥터 시스템 개발,2021,"['UAV', 'Drone', 'Collision Avoidance', 'Obstacle Avoidance', 'Pixhawk', 'Multicopter', '무인항공기', '드론', '충돌회피', '장애물회피', '픽스호크', '멀티콥터']","최근 멀티콥터는 비행 안정성 향상을 위해 다양한 충돌회피 센서를 탑재하고 있다. LiDAR를 이용해 3차원 위치를 인식하거나 다수 카메라와 실시간 SLAM 기술을 이용해 장애물과의 상대 위치를 계산하기도 한다. 또한 소형 프로세스와 카메라로 구성된 3D 깊이 센서를 사용하기도 한다. 본 연구에서는 충돌회피 소프트웨어 기술 개발을 위한 플랫폼으로써 상용 부품을 활용해 실내 비행이 가능한 소형 충돌회피 멀티콥터 시스템을 개발하였다. 멀티콥터 시스템은 LiDAR, RealSense, GPU 보드를 탑재하였고, 비행시험을 통해 YOLO 알고리즘 기반의 사물 인식 및 충돌회피 기능을 검증하였다. 이 논문에서는 시스템 설계/제작 및 탑재 장비 선정과정, 비행시험 결과에 관해 기술하였다.","Recently, multi-copters equipped with various collision avoidance sensors have been introduced to improve flight stability. LiDAR is used to recognize a three-dimensional position. Multiple cameras and real-time SLAM technology are also used to calculate the relative position to obstacles. A three-dimensional depth sensor with a small process and camera is also used. In this study, a small collision-avoidance multi-copter system capable of in-door flight was developed as a platform for the development of collision avoidance software technology. The multi-copter system was equipped with LiDAR, 3D depth sensor, and small image processing board. Object recognition and collision avoidance functions based on the YOLO algorithm were verified through flight tests. This paper deals with recent trends in drone collision avoidance technology, system design/manufacturing process, and flight test results."
An Improvement of Deep Learning-based Object Detection Scheme for Game Scenes,2021,"['object detection', 'game scene', 'deep learning', 'YOLOv2']","본 연구에서는 게임 영상과 같은 생성된 영상으로부터 물체를 인식하는 심층 학습 기반 모델의 성능을 향상시키는 방법을 제시한다. 특히, 실제 영상으로 훈련된 물체 인식 모델에 대해서 게임 영상으로 추가 훈련을 수행함으로써 물체 인식 성능이 향상됨을 검증한다. 본 연구에서는 심층 학습 기반의 물체 인식 모델들 중에서 가장 널리 사용되는 YoloV2 모델을 이용한다. 이 모델에 대해서 8 종류의 다양한 게임에서 샘플링한 160장의 게임 영상을 적용해서 물체 인식 모델을 다시 훈련하고, IoU와 정확도를 측정해서 본 연구에서 주장하는 게임영상을 이용한 훈련이 효과적임을 입증한다.","We present a framework that improves the performance of deep learning-based object detection model for generated images including game scenes. In particular, we aim to verify that the additional training using images sampled from game scenes can improve the performance of the object detection model, which was pre-trained using photographs. Among the various object detection schemes including Yolo V1, Yolo V2 and SSD, we employ YoloV2 model, which is one of the most widely used deep learning-based object detection model. YoloV2 model is pretrained using diverse photographs. This model is further trained through 160 game scene images sampled from eight different kinds of games. We select the games that range from realistic scenes and highly deformed scenes. We measure IoU (intersection over union) and accuracy using this model. The comparison between our re-trained model and the original model demonstrates the effectiveness of our strategy."
인공지능 기반 EL 이미지의 태양전지 및 모듈의 결함검출 연구,2021,"['태양전지(Solar Cells)', '태양광 모듈(PV Modules)', '전계발광(Electroluminescence', 'EL)', '인공지능(Artificial Intelligence', 'AI)', '결함 검출(Detect Detection)']",국문 초록 정보 없음,"Currently, investment is being made in renewable energy for the transition to a low-carbon economy and society, and interest in solar energy is also increasing. In addition to the technological development of solar cells and photovoltaic (PV) modules, research in the field of convergence with artificial intelligence technology is being actively conducted. Defects occurring in the manufacturing process of solar cells and modules can be detected through electroluminescence (EL) measurements. In this study, we propose an artificial intelligence technology that can automatically detect defects in cells and modules in real time using EL image data of solar cells and modules in the manufacturing process. For EL defect detection, we propose an algorithm with high suitability in terms of speed and accuracy by applying deep learning-based object detection models and comparing and evaluating detection performance. In the case of the YOLO (you only look once) algorithm, which belongs to a one-step detector, it learns In the case of the YOLO (you only look once) algorithm, which belongs to a one-step detector, it learns through an optimization process to find information about the defect and the location information of the corresponding failure in the form of a bounding box, and then detects the failure based on this information. The introduction of a deep learning-based defect detection model in the manufacturing process is expected to reduce the time required for defect detection by solar cell and PV module manufacturers and contribute to productivity improvement."
딥러닝 기반 활주로 청소 로봇 개발,2021,"['YOLO', 'Deep Learning', 'Real Time Object Detection', 'FOD (Foreign Object Debris)', 'Runway Cleaning Robot']",국문 초록 정보 없음,"This paper deals with the development of a deep-learning-based runway cleaning robot using an optical camera. A suitable model to realize real-time object detection was investigated, and the differences between the selected YOLOv3 and other deep learning models were analyzed. In order to check whether the proposed system is applicable to the actual runway, an experiment was conducted by making a prototype of the robot and a runway model. As a result, it was confirmed that the robot was well developed because the detection rate of FOD (Foreign Object Debris) and cracks was high, and the collection of foreign substances was carried out smoothly."
RFID·영상처리 기반 전기차 충전소 자동화 시스템,2021,"['RFID', 'YOLO', 'Electric Vehicle', 'EV Station']","본 논문에서는 전기차 충전소 이용에 불편함을 겪는 전기차 사용자들을 위한 RFID·영상처리 기반의 전기 차 충전소 자동화 시스템을 제안한다. 전기차 충전소 자동화 시스템은 진입부, 충전부, 어플리케이션 부로 구성된다. 진입부에서는 일반 차량의 접근을 차단하고 전기차량의 출입을 통제한다. 충전부에서는 전기차량 출입 판단 · 충전요금 및 초과 주차 차량에 대한 과태료 자동 결제 · 실시간 충전소 사용 여부 판단을 진행한다. 어플리케이션 부에서는 앱을 통해 사용자에게 실시간 충전소 사용 현황 및 결제 정보를 알려준다. 진입부의 구성은 적외선 거리센서 · RFID 리더기와 결합된 NodeMCU 보드, Web Camera와 결합된 Jetson Nano 보드, 서보 모터와 결합된 Arduino Uno 보드이다. 충전부의 구성은 Raspberry Pi 3B+, MySQL, FireBase Realtime DB 이며, 어플리케이션 부의 구성은 Android Application이다.",다국어 초록 정보 없음
딥러닝과 교통정보 Open API를 이용한 시각장애인 버스 탑승 보조 시스템에서 딥러닝 알고리즘 성능 비교,2021,"['Tensorflow', 'YOLO', 'embedded board', 'NFC', 'Open API']","본 논문은 키패드, 도트매트릭스, 라이다센서, NFC 리더기를 부착한 임베디드 보드와 공공데이터포털 Open API 시스템과 딥러닝 알고리즘(YOLOv5)를 사용하여 시각장애인의 버스 탑승에 도움을 줄 수 있는 시스템을 소개한다. 이용자는 NFC 리더기 및 키패드를 통해 희망하는 버스번호를 입력한 뒤, Open API 실시간 데이터를 통해 해당 버스의 위치 및 도착예정시간 정보를 시스템에 입력해놓은 음성출력을 통해 얻는다. 또한 도트매트릭스로 버스번호를 출력하여 기사와의 상호작용을 대기함과 동시에 딥러닝 알고리즘(YOLOv5)은 정차하는 버스 번호를 실시간 인식하고 거리센서로 버스와의 거리를 감지하여 정차유무정보를 확인, 전달하는 시스템을 제안한다.","This paper introduces a system that can help visually impaired people to board a bus using an embedded board with keypad, dot matrix, lidar sensor, NFC reader, a public data portal Open API system, and deep learning algorithm (YOLOv5). The user inputs the desired bus number through the NFC reader and keypad, and then obtains the location and expected arrival time information of the bus through the Open API real-time data through the voice output entered into the system. In addition, by displaying the bus number as the dot matrix, it can help the bus driver to wait for the visually impaired, and at the same time, a deep learning algorithm (YOLOv5) recognizes the bus number that stops in real time and detects the distance to the bus with a distance detection sensor such as lidar sensor."
스트리트뷰 영상의 객체탐지를 활용한 보행 장애물 정보 갱신,2021,"['Object Detection', 'Deep Learning', 'YOLO', 'OpenStreetMap', 'Pedestrian Network', 'Map Update', '객체탐지', '딥러닝', '욜로', '오픈스트리트맵', '보행 네트워크', '지도 갱신']",국문 초록 정보 없음,다국어 초록 정보 없음
Aerial Dataset Integration For Vehicle Detection Based on YOLOv4,2021,"['Vehicle Detection', 'Aerial Image', 'YOLO', 'VAID', 'UAVD', 'DOTA']",국문 초록 정보 없음,"With the increasing application of UAVs in intelligent transportation systems, vehicle detection for aerial images has become an essential engineering technology and has academic research significance. In this paper, a vehicle detection method for aerial images based on the YOLOv4 deep learning algorithm is presented. At present, the most known datasets are VOC (The PASCAL Visual Object Classes Challenge), ImageNet, and COCO (Microsoft Common Objects in Context), which comply with the vehicle detection from UAV. An integrated dataset not only reflects its quantity and photo quality but also its diversity which affects the detection accuracy.The method integrates three public aerial image datasets VAID, UAVD, DOTA suitable for YOLOv4. The training model presents good test results especially for small objects, rotating objects, as well as compact and dense objects, and meets the real-time detection requirements. For future work, we will integrate one more aerial image dataset acquired by our lab to increase the number and diversity of training samples, at the same time, while meeting the real-time requirements."
물체 인식에 의한 카메라의 시각 위치 및 거리 추출,2021,"['VPS(Visual Positioning System)', 'YOLO(You Only Look Once)', 'Local based position', 'Smartphone', 'Tensorflow-Lite']",국문 초록 정보 없음,다국어 초록 정보 없음
금속 정밀 주조제품의 소형 결함검사를 위한 딥러닝 모델 성능 비교연구,2021,"['딥러닝', 'Object Detection', 'YOLO', '부품 검사', '소형 결함검사', '스마트 팩토리', '머신 비전', 'HCI']","금속 정밀 주조제품의 결함 검사 자동화는 스마트 팩토리 확산에 아주 중요한 요소이며 인력에 의존한 검사 공정을 자동화 하기 위해 이미지 분석 영역에서 큰 성과를 올리고 있는 딥러닝 기법의 적용이 필수적이다. 본문에서는 금속 정밀 주조제품의 소형 결함검사를 위한 딥러닝 모델 YOLOv3 와 v5 의 성능을 비교분석함으로써 v5 의 정확도, 판단속도가 v3 보다 더 뛰어난 것을 알 수 있으며, 이는 소형 결함 검사에 적합한 딥러닝 솔루션을 제공한다. 또한 작업자가 사용하기 편리한 UI 를 제공함으로써 본 시스템에 HCI 를 적용한다.",다국어 초록 정보 없음
고속도로 졸음쉼터 내 안전예방을 위한 객체검출 방법 및 서비스 연구,2021,"['Deep learning', 'Object detection', 'Yolo v3', 'Rest area']",국문 초록 정보 없음,다국어 초록 정보 없음
YOLOv3를 이용한 Jetson Nano 기반의 도로 반사경 시스템,2021,"['Road reflector mirror', 'YOLO', 'Jetson Nano', 'TCP/IP', 'Python']",국문 초록 정보 없음,"According to statistics for the last three years, the mortality rate on curved roads is higher than on straight roads. To prevent accidents on the curved roads, reflection mirrors for roads are used. This paper proposes Jetson Nano-based reflection mirror system for road using the YOLOv3 model to overcome the functional limitations of reflection mirrors for the road. The real-time image captured by a webcam installed at the intersection is inferred by the YOLOv3 model, and if the object is a car or a pedestrian, the OLED display is displayed images that representing the object. In order to evaluate the proposed system, we measure the recognition rate of the real-time image being filmed with the webcam. The experimental result shows that the recognition rate is 100%."
Honeybee In-Out Monitoring System by Object Recognition and Tracking from Real-Time Webcams,2021,"['Honeybee', 'Monitoring', 'Beehive gate', 'YOLO', 'DeepSORT']",국문 초록 정보 없음,"A new honeybee in-out monitoring system is proposed using real-time deep-learning based image recognition and tracking. The specific design of beehive gate is turned out to be an important factor for accurate bee movement monitoring. We check a series of beehive gate designs for the monitoring system. A novel gate design employing heart valve structure is proposed for ensuring one-way traffic for the bees as well as one-at-a-time gate passing, resulting in an improved bee detection accuracy. As for the deep-learning based image recognition framework, YOLOv4 is used in the proposed system for a better honeybee-detection accuracy as well as a faster detection in comparison to YOLOv3 which was employed for our previous study. In addition, DeepSORT algorithm is employed for a reliable tracking of the detected honeybees. In our experiments the proposed honeybee monitoring system exhibited 99.5% detection accuracy, while our previous system resulted in 97.5% in the same settings."
딥러닝을 이용한 육불화텅스텐(WF6) 제조 공정의 지능형 영상 감지 시스템 구현,2021,"['object detection', 'you only look once (YOLO)', 'tungsten hexafluoride (WF6)', 'reduction', 'defect detection.']",국문 초록 정보 없음,"Through the process of chemical vapor deposition, Tungsten Hexafluoride (WF6) is widely used by the semiconductor industry to form tungsten films. Tungsten Hexafluoride (WF6) is produced through manufacturing processes such as pulverization, wet smelting, calcination and reduction of tungsten ores. The manufacturing process of Tungsten Hexafluoride (WF6) is required thorough quality control to improve productivity. In this paper, a real-time detection system for oxidation defects that occur in the manufacturing process of Tungsten Hexafluoride (WF6) is proposed. The proposed system is implemented by applying YOLOv5 based on Convolutional Neural Network (CNN); it is expected to enable more stable management than existing management, which relies on skilled workers. The implementation method of the proposed system and the results of performance comparison are presented to prove the feasibility of the method for improving the efficiency of the WF6 manufacturing process in this paper. The proposed system applying YOLOv5s, which is the most suitable material in the actual production environment, demonstrates high accuracy (mAP@0.5 99.4 %) and real-time detection speed (FPS 46)."
딥러닝을 이용한 운전자 졸음운전 감지,2021,"['deep learning', 'drowsy driving', 'Object recognition', 'tiny-YOLO']",졸음운전은 교통사고의 주요 원인이 되고 있다. 운전자의 졸음 여부를 확인하는 방법으로 눈과 하품의 동작을 통해 구분할 수 있다. 본 논문에서는 딥러닝 모델을 이용하여 운전자의 눈 모양과 하품 동작을 검출하고 졸음 여부를 판단하고 경고음으로 알려주는 연구를 제안한다.,"Drowsy driving is a major cause of traffic accidents. As a way to check whether the driver is drowsy, it can be distinguished through eye and yawning motions. In this paper, we propose a study using a deep learning model to detect the driver's eye shape and yawning behavior, determine whether a driver is drowsy, and notify with a warning sound."
딥러닝 기반 객체 탐지 알고리즘을 이용한 대장내시경 용종 탐지 시스템,2021,"['Colonoscopy', 'AutoAugment', 'CADｘ', 'Polyp Detection', 'YOLO']",국문 초록 정보 없음,"In Korea, colon cancer is increasing due to westernized eating habits. Colonoscopy is being used to reduce deaths from colon cancer and studies of CADx(Computer-aided Diagnosis) are being developed to improve accuracy. Due to the nature of medical data, it was difficult to collect a lot of data, so data was increased 25 times using AutoAugment’s CIFAR-10 policy, and YOLOv4(You Only Look Once), a real-time object detection algorithm, was used to detect lesions. A new object detection algorithm, YOLOv4, use new eight features such as Weighted-Residual-Connections, Cross-Stage-Partial-connections, Cross mini-Batch Normalization and Self-Adversarial-Training. The performance of augmented data had a maximum mAP of 27.44 higher than the original data. The average IoU(Intersection over Union) was 11.44 higher than the original data. When the IoU value is 0.5, the F1-scores of the original data and the augmented data are 0.9 and 0.97 respectively."
운전자 및 동승자 머리 자세 추정 및 딥러닝을 이용한 교통사고 모니터링 시스템,2021,"['Car Accident Detection', 'Deep Learning', 'YOLO', 'Head Pose Estimation', 'HSV']",국문 초록 정보 없음,다국어 초록 정보 없음
표적 정보를 포함하는 2차원 지도 생성 시스템,2021,"['Object Detection', 'Drone', 'De ep Learning', 'SLAM', 'YOLO V5', 'Cartographer']",국문 초록 정보 없음,다국어 초록 정보 없음
객체 검출을 위한 통계치 적응적인 선형 회귀 기반 객체 크기 예측,2021,"['Object Detection', 'Statistics Adaptive Linear Regression', 'YOLO']",국문 초록 정보 없음,"This paper proposes statistics adaptive linear regression-based object size prediction method for object detection. YOLOv2 and YOLOv3, which are typical deep learning-based object detection algorithms, designed the last layer of a network using statistics adaptive exponential regression model to predict the size of objects. However, an exponential regression model can propagate a high derivative of a loss function into all parameters in a network because of the property of an exponential function. We propose statistics adaptive linear regression layer to ease the gradient exploding problem of the exponential regression model. The proposed statistics adaptive linear regression model is used in the last layer of the network to predict the size of objects with statistics estimated from training dataset. We newly designed the network based on the YOLOv3tiny and it shows the higher performance compared to YOLOv3 tiny on the UFPR-ALPR dataset."
멧돼지에 의한 농작물 피해 방지를 위한 유해조수 퇴치 시스템,2021,"['Wild Animals', 'Wild Boars', 'Repellent', 'Real-Time', 'YOLO', 'Deep Learning', 'Pattern Recognition']",국문 초록 정보 없음,다국어 초록 정보 없음
Image Data Augmentation 기반 Vehicle Part 검출 자동화 AI 네트워크 성능 향상,2021,"['Image Data Augmentation', 'Vehicle part detection', 'YOLO']",국문 초록 정보 없음,다국어 초록 정보 없음
보행자작동신호기 지능화를 위한 YOLOv4 기반 보행자 판별 및 속도 검출방안 연구,2021,"['보행자작동신호기', '보행자 판별', '보행 속도 검출', 'YOLO']",국문 초록 정보 없음,다국어 초록 정보 없음
인공지능(AI)를 활용한 보조보행기구 식별에 따른 자동문 속도 조절 설계에 대한 연구,2021,"['보조 보행 기구(auxiliary walker)', 'YOLO', 'Raspberry Pi', 'OpenCV', 'CUDA']",국문 초록 정보 없음,다국어 초록 정보 없음
내시경 수술영상에서 수술도구 인식을 위한 물체인식 딥러닝 모델의 성능 비교,2021,[],"본 연구에서는 내시경 수술 영상에서 총 6종의 수술도구를 인식하기 위하여 YOLO 계열의 모델과 R-CNN 계열의 모델 간 성능 차이를 비교 분석하기 위한 연구를 수행하였다. 두 계열에는 방법의 차이가 존재하므로 주어진 영상과 문제마다 적합한 모델이 무엇인지 분석해보고자 한다. 본 연구에 적용된 방법은 YOLOv3와 Faster R-CNN이며, 그 결과 YOLOv3는 속도가 빠르지만 정확도가 조금 떨어지는 경향을 보였고, Faster R-CNN의 경우 YOLOv3대비 속도가 2.6배 느리지만 3.59%의 정확도가 더 높은 것을 확인하였다. 의료영상의 특성상 속도보다는 정확도가 더 중요하므로 Faster R-CNN을 적용하는 것이 바람직한 것으로 판단된다.",다국어 초록 정보 없음
특징 융합과 공간 강조를 적용한 딥러닝 기반의 개선된 YOLOv4S,2021,"['Object Detection', 'Spatial attention', 'Deep learning', 'Feature fusion', 'PAN', 'YOLO', '객체 검출', '공간 강조', '딥러닝', '특징 융합', '특징 피라미드', '욜로']","본 논문은 특징 융합과 공간 강조를 적용하여 작고 페색된 객체 검출을 위한 개선된 YOLOv4S를 제안하였다. 기존 YOLOv4S은 경량 네트워크로 깊은 네트워크 대비 특징 추출 능력 부족하다. 제안하는 방법은 먼저 feature fusion으로 서로 다른 크기의 특징맵을 결합하여 의미론적 정보 및 저수준 정보를 개선하였다. 또한, dilated convolution으로 수용 영역을 확장하여 작고 폐색된 객체에 대한 검출 정확도를 향상시켰다. 두 번째로 spatial attention으로 기존 공간 정보 개선하여 객체간 구분되어 폐색된 객체의 검출 정확도를 향상시켰다. 제안하는 방법의 정량적 평가를 위해 PASCAL VOC 및 COCO 데이터세트를 사용하였다. 실험을 통해 제안하는 방법은 기존 YOLOv4S 대비 PASCAL VOC 데이터세트에서 mAP 2.7% 및 COCO 데이터세트에서 mAP 1.8% 향상되었다.","In this paper proposed a feature fusion and spatial attention-based modified YOLOv4S for small and occluded detection. Conventional YOLOv4S is a lightweight network and lacks feature extraction capability compared to the method of the deep network. The proposed method first combines feature maps of different scales with feature fusion to enhance semantic and low-level information. In addition expanding the receptive field with dilated convolution, the detection accuracy for small and occluded objects was improved. Second by improving the conventional spatial information with spatial attention, the detection accuracy of objects classified and occluded between objects was improved. PASCAL VOC and COCO datasets were used for quantitative evaluation of the proposed method. The proposed method improved mAP by 2.7% in the PASCAL VOC dataset and 1.8% in the COCO dataset compared to the Conventional YOLOv4S."
딥러닝 기반 앙상블을 이용한 마스크 착용 상태 검출 기술 연구,2021,"['콘볼루션 신경망', '마스크 검출', '앙상블', 'Convolutional Neural Network', 'YOLO', 'Mask Detection', 'Ensemble', 'FPN']",국문 초록 정보 없음,"Due to the COVID-19 incident, demand for a quarantine system that can prevent the spread of the virus has increased. In this paper, a mask wearing state detection technology based on a deep learning-based ensemble is proposed. A model that can detect mask wearing status was created using a deep learning algorithm based on a convolutional neural network. Afclassifying wearing a mask into mask, improper mask, and no mask, the accuracy was improved by constructing learning data for various poses. In addition, the combination of deep learning models through ensemble techniques increased accuracy, and among the methods of diversifying the size of feature maps, FPN techniques were used to increase object detection performance while reducing computation volume. In the future, this study will be used as an efficient quarantine system in indoor environments where ventilation is difficult, and in particular, it will be contributed to establish a quarantine environment so that users can safely use cultural facilities such as performance halls."
스테레오 비전과 YOLOv3 를 이용한 드론의 3 차원 실내 위치 추정 알고리즘 개발,2021,"['Position estimation', 'YOLOv3', 'Stereo vision', 'Depth map', 'Kalman filter', 'Object detection']",국문 초록 정보 없음,"In this paper, we propose a three-dimensional indoor position estimation algorithm for drones using stereo vision and YOLOv3. First, we find the bounding box of a drone in the image using a deep-learning-based object detection algorithm called YOLOv3. To this end, we collect the training dataset consisting of drone images. In addition, the object detection performance of the YOLOv3 algorithm is improved by dividing object class labels of the same drone based on the angle of the drone seen from the camera. Then, the three-dimensional relative position of the drone is estimated based on the camera internal parameters, the bounding box information, and the depth map taken by the stereo vision. In addition, the Kalman filter is employed to estimate the position of the drone continuously. Finally, the position estimation performance of the proposed algorithm is evaluated through the experiments."
Development of Monitoring Technique for Real Time Worker Tracking in Decommissioning Site,2021,"['Object detection', 'Worker tracking', 'Stereo camera', 'Decommissioning site', 'YOLO', 'Deepsort']",국문 초록 정보 없음,다국어 초록 정보 없음
컴퓨터 비전 및 머신러닝을 이용한 웨이퍼 노치 감지 시스템 연구,2021,"['Channeling Effect(채널링 현상)', '웨이퍼 노치', '머신러닝', 'Jetson Xavier', '컴퓨터 비전', 'Yolo(You look only once)']",국문 초록 정보 없음,다국어 초록 정보 없음
UAV 영상기반 도로 손상 검출 및 정량화를 이용한 도로면 자동 모니터링 시스템 개발,2021,"['무인비행체(Unmanned Aerial Vehicle', 'UAV)', '균열', '포트홀', 'You Only Look Once(YOLO)']",국문 초록 정보 없음,다국어 초록 정보 없음
RAVIP: Real-Time AI Vision Platform for Heterogeneous Multi-Channel Video Stream,2021,"['Multi-Channel', 'Multi-Stream', 'Object Detection', 'Surveillance Systems', 'Vision']",국문 초록 정보 없음,"Object detection techniques based on deep learning such as YOLO have high detection performance and precision in a single channel video stream. In order to expand to multiple channel object detection in real-time, however, high-performance hardware is required. In this paper, we propose a novel back-end server framework, a real-time AI vision platform (RAVIP), which can extend the object detection function from single channel to simultaneous multi-channels, which can work well even in low-end server hardware. RAVIP assembles appropriate component modules from the RODEM (real-time object detection module) Base to create perchannel instances for each channel, enabling efficient parallelization of object detection instances on limited hardware resources through continuous monitoring with respect to resource utilization. Through practical experiments, RAVIP shows that it is possible to optimize CPU, GPU, and memory utilization while performing object detection service in a multi-channel situation. In addition, it has been proven that RAVIP can provide object detection services with 25 FPS for all 16 channels at the same time."
YOLOv5에서 가상 번호판 생성을 통한 차량 번호판 인식 시스템에 관한 연구,2021,"['License Plate', 'License Plate Generator', 'LPR(License Plate Recognition)', 'YOLO(You Only Look Once)', 'Object Detection', 'Deep Learning']",국문 초록 정보 없음,"Existing license plate recognition system is used as an optical character recognition method, but a method of using deep learning has been proposed in recent studies because it has problems with image quality and Korean misrecognition. This requires a lot of data collection, but the collection of license plates is not easy to collect due to the problem of the Personal Information Protection Act, and labeling work to designate the location of individual license plates is required, but it also requires a lot of time. Therefore, in this paper, to solve this problem, five types of license plates were created using a virtual Korean license plate generation program according to the notice of the Ministry of Land, Infrastructure and Transport. And the generated license plate is synthesized in the license plate part of collectable vehicle images to construct 10,147 learning data to be used in deep learning. The learning data classifies license plates, Korean, and numbers into individual classes and learn using YOLOv5. Since the proposed method recognizes letters and numbers individually, if the font does not change, it can be recognized even if the license plate standard changes or the number of characters increases. As a result of the experiment, an accuracy of 96.82% was obtained, and it can be applied not only to the learned license plate but also to new types of license plates such as new license plates and eco-friendly license plates."
컴퓨터 비전 및 머신러닝을 이용한 웨이퍼 노치 감지 시스템 연구,2021,"['Channeling Effect(채널링 현상)', '웨이퍼 노치', '머신러닝', 'Jetson Xavier', '컴퓨터 비전', 'Yolo(You look only once)']",국문 초록 정보 없음,다국어 초록 정보 없음
비디오 모니터링 환경에서 정확한 돼지 탐지,2021,"['Real-Time Video Monitoring', 'Video Object Detection', 'Pig Detection', 'Image Processing', 'Deep Learning', 'YOLO']",국문 초록 정보 없음,다국어 초록 정보 없음
과채류 수확 로봇 개발을 위한 깊이 추정 기법의 온실 환경으로의 적용,2021,"['깊이 영상', '딥러닝', '시설 온실']","과채류 수확 로봇을 온실에 적용하기 위해서는 대상이 되는 작물에 대한 객체 인식이 필요하다. 현재 Faster R-CNN, Yolo, SSD 등 딥러닝 기반 객체 검출 모델들이 농업에 적용되는 사례가 많으며, 위 기술들은 장면에 포함된 모든 객체를 검출한다. 그러나 온실 내 배지 사이의 레일을 따라 작동하는 로봇 특성상, 작업 중인 구역의 객체만 인식하는 것이 유리하다. 때문에, 최근 RGB-D 카메라나 스테레오 카메라 등을 이용해 영상의 깊이를 함께 활용하는 연구가 시도되고 있지만, 별도의 깊이 카메라 장착이 필요하고 외부광으로 인한 깊이 영상 노이즈 발생 등의 문제가 있다. 본 논문은 온실에서 별도의 깊이 센서 없이 2D 영상에서 깊이를 추정하는 방식을 제안한다. 깊이 추정(Depth estimation)은 싱글 카메라로 촬영한 RGB 영상을 입력했을 때 깊이 맵이 출력되도록 하는 기법이다. 본 논문에서는 의미론적 분할(Semantic Segmantation) 기법의 하나인 UNet을 응용하는 방식으로 접근한다. 토마토 배지 재배 온실에서 촬영한 데이터를 기반으로 UNet을 학습했으며, Intel RealSense D435 카메라를 이용해 RGB 영상과 깊이 영상을 동시에 수집했다. 카메라를 모바일 로봇에 탑재해 레일을 따라 선형으로 촬영했으며, 생육 생장을 마친 토마토가 촬영 대상이기 때문에 지면으로부터 1m, 배지로부터 0.6m 떨어진 곳에 카메라를 설치했다. 촬영된 실제 깊이 맵은 16bit의 값을 가지지만, UNet 학습 시 입력과 정답 영상 모두 8bit 영상 형식을 요구하기 때문에 8bit로 압축해서 적용했다. 위와 같은 이유로 정답 영상에 손실된 정보가 많아 학습 결과 깊이 맵이 제대로 형성되지 않은 것을 확인했다. 향후 UNet의 학습 시 정답 영상을 손실 없이 압축하거나 16bit 배열 형식으로 학습할 수 있도록 해 한계점을 해결하고 수확 로봇 개발 시 2D 카메라만 사용하여 비용 및 연산량 절감을 이루고자 한다.",다국어 초록 정보 없음
Smart Parking 최근 기술 동향,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
YOLOv4와 라즈베리파이 기반 쓰레기 분리배출 자동화 시스템,2021,"['딥러닝', '라즈베리파이', '재활용 쓰레기', '욜로', '욜로 버전4', 'Deep Learning', 'Rasberry Pi', 'Recycling Waste', 'YOLO', 'YOLOv4']",국문 초록 정보 없음,"This paper proposes an automatic segregation system that classifies waste into 9 classes (can, pet, pen, mouse, paper box, clip, key, vinyl, coffee wrapping plastic alike stick), using the YOLOv4 model and Raspberry Pie. Our system consists of three parts, (1) Waste Classification based on YOLOv4, (2) Waste Disposal based on Rasberry Pie, and (3) Waste Management Application for inspection and retrain. We construct a big waste dataset by crawling data, using public data and making self-product data and improve the model accuracy up to 90%, maintaining the real-time performance of the YOLOv4 model. Our system is optimized in a real environment through various experiments on parameter optimization, data augmentation, and effect on the iteration number of the model train."
멀티쓰레드 객체 탐지 응용의 종단 간 지연 시간 단축,2021,"['Object Detection(객체 탐지)', 'Multithreaded Application(multithreaded 응용)', 'End-to-end Delay(종단 간 시간)', 'Darknet-YOLO(다크넷-욜로)']",국문 초록 정보 없음,다국어 초록 정보 없음
금융자동화기기에서의 객체검출에 관한 연구,2021,[],"최근 다양한 산업분야에서 객체인식을 통한 자동화 서비스가 활발히 이루어지고 있다. 금융분야에서 금융자동화기기와 같이 신뢰성과 신속성이 요구되는 분야에서는 인식정확도와 실시간 객체 검출이 요구된다. 따라서 본 논문에서는 YOLO LITE 방식을 활용하여 이 두 요소를 달성하고, 객체 검출이 실패할 경우 이미지처리 기법으로 보완하는 기술을 구현 하였다.",다국어 초록 정보 없음
딥러닝 기법을 이용한 주차 공간 자동 식별 시스템,2021,"['전이 학습', '텐서플로우 라이트', '티처블 머신', '안드로이드 스튜디오', 'Transfer Learning', 'TensorFlow Lite', 'Teachable Machine', 'Android Studio']","본 논문에서는 촬영된 주차장 사진으로부터 빈 주차 공간을 자동 식별할 수 있는 주차 공간 자동 식별 시스템 에 대해 설명한다. 이 시스템은 딥러닝 기법에 기반한 시스템으로, 다양한 주차장 사진들을 토대로 학습을 진행하여 식별 결과의 정확도가 높으며, 기존의 주차 관리 시스템에 적용할 수 있다. 한편, 본 시스템은 손쉬운 적용 테스트를 위해, 스마트폰용 애플리케이션으로도 개발되었다. 따라서 스마트폰 카메라를 통해 주차장 사진을 찍으면, 촬영된 이 미지를 자동 인식하며 빈 주차 공간을 자동 식별할 수 있다.","In this paper, we describe a parking space identification system that can automatically identify empty parking lot spaces from a parking lot photo. This system is based on a deep learning technique, and the accuracy of the identification result is good by learning various existing parking lot images. It could be applied to the existing parking management system. This system was also developed as a smartphone application for easy testing. Therefore, if you take a picture of a parking lot through a smartphone camera, the captured image is automatically recognized and an empty parking space can be automatically identified."
인공지능 기반 치주염 진단지원 모델 개발을 위한 후보모델 탐색 연구,2021,[],"본 연구에서는 치과 엑스레이 파노라마 이미지를 기반으로 인공지능 기술을 활용한 치주염 진단 지원 모델 개발을 위한 탐색 연구를 수행하였다. 치과 분야 인공지능 연구 현황과 적용할 후보 모델 알고리즘을 검토하였다. 샘플데이터를 기반으로 YOLO, Efficient Det, Faster-R CNN 알고리즘을 활용한 파일럿 연구를 수행하였다. 연구결과 적은 규모의 학습데이터임에도 불구하고 Faster R-CNN 기반알고리즘의 성능이 우수하였으며, 타 알고리즘과의 비교를 통해 RoI 예측이 치아의 치주염 수준별 객체 탐지에 있어 주요한 영향을 미침을 알 수 있었다. 이를 통해 향후 전체 데이터 셋을 대상으로 학습한 정교한 모델 구측 가능성을 확인하였다.",다국어 초록 정보 없음
인공지능 기반 후두암 진단지원 모델 개발을 위한 후보모델 탐색 연구,2021,[],"본 연구는 후두내시경 이미지를 활용하여 인공지능 기술을 통한 후두암 진단 지원모델 개발을 위한 탐색 연구를 수행하였다. 두경부 분야 인공지능 연구 현황과 적용할 후보모델 알고리즘을 검토하였다. 샘플데이터를 기반으로 YOLO, Faster R-CNN, CNN+GradCAM 알고리즘 기반 모델을 활용한 파일럿 모델을 구축하고 성능을 평가하였다. VGG19를 활용한 CNN+GradCAM 알고리즘 모델이 준수한 성능과 임상적 유효성 평가 및 진단지원 모델적용시의 높은 활용적 이점을 나타내어, 이를 기반으로 향후 본 데이터셋 구축과 최적 학습을 통해 강건하고 우수한 성능의 모델 개발이 가능할 것이다.",다국어 초록 정보 없음
착용형 증강현실 장치의 인터페이스를 위한 비전 AI 기반의 손 위치 추적,2021,"['HMD', 'AR Glass', 'Hand Position Tracking', 'Object Detection']",본 논문에서는 HMD(Head Mounted Display)에서 손의 인식을 통한 사용자 입력 인터페이스로 활용하는 비전 AI 기술을 제안한다. 모바일 및 임베디드 시스템에서 사용되는 5가지의 딥러닝 모델을 30 FPS 기준으로 실시간 동작이 되도록 파라미터를 제한하고 이를 Yolo v1 사물인식모델에 적용한다. 사물인식의 손 검출 결과는 오차 행렬의 정밀도-재현율곡선 그래프에서 면적 AP(Average Precision)로 5가지의 모델들을 비교 분석한다.,다국어 초록 정보 없음
보조보행기구 AI 서비스 구축을 위한 데이터셋 설계 및 구현,2021,"['AI(ARTICIFIAL INTELLIGENCE)', '이미지 크롤링(Image crawling)', '데이터셋(Dataset)', 'Node Js', '보조보행기구']","본 논문에서는 노약자 및 장애인의 증가로 인한 조행보조기구 사용량이 증가하고 있으나 물리적인 보조기구는 있지만 AI를 통한 서비스와 보조보행기구에 관한 AI 데이터셋이 부족하다. 이러한 문제점을 보안하기위해 본 논문에서는 상기 데이터셋을 설계 및 구축하기 위해 Node JS를 사용하여 이미지 크롤링 프로그램을 구현하여 이미지 데이터를 수집했으며, Yolo Maker를 활용하여 수집된 이미지를 데이터셋으로 변환시켰다. 이를 통해 노약자 및 장애인을 위한 AI 서비스 구축에 필요한 데이터를 손쉽게 설계 및 구축한다.",다국어 초록 정보 없음
Vehicle Orientation Detection Using CNN,2021,"['Vehicle Orientation', 'Vehicle Detection', 'Real-Time', 'Convolutional Neural Network(CNN)']",국문 초록 정보 없음,"Vehicle orientation detection is a challenging task because the orientations of vehicles can vary in a wide range in captured images. The existing methods for oriented vehicle detection require too much computation time to be applied to a real-time system. We propose Rotate YOLO, which has a set of anchor boxes with multiple scales, ratios, and angles to predict bounding boxes. For estimating the orientation angle, we applied angle-related IoU with CIoU loss to solve the underivable problem from the calculation of SkewIoU. Evaluation results on three public datasets DLR Munich, VEDAI and UCAS-AOD demonstrate the efficiency of our approach."
YOLOv5 모델에 따른 결과 분석,2021,"['YOLOv5', 'Object detection', 'Deep learning']","최근 객체 탐지의 수요가 많아지면서 자율 주행, 보안, 분류 작업 등 컴퓨터 비전 분야에 적용되고 있다. 하지만 많은 모델들 가운데 어떤 모델을 쓸 때 본인의 연구에 최적의 결과가 나오는지에 대한 비교가 필요하다. 따라서 본 연구에서는 객체 탐지 알고리즘인 YOLO (You Only Look Once)v5 를 가중치 별로 나누어 모델 간의 비교 분석을 통해 어떤 알고리즘이 가장 효율적인지 비교 및 분석하였다. 비교 분석 모델로는 YOLOv5s, m, l 총 세 가지이며 실험 조건은 데이터 셋 5,982 개, 이미지 사이즈, 416 × 416, Epochs 500 으로 동일하게 설정했다. 또한 이미지 데이터를 Train, Validation, Test 로 나누었고 각각 70, 20, 10%이다. 실험 결과 YOLOv5s 의 객체 탐지 속도가 140 fps 로 가장 빨랐다. YOLOv5m, l 은 객체 탐지 속도에서 비슷한 결과를 보였다. Precision 은 YOLOv5l 이 96.24%로 YOLOv5m 보다 0.9%, YOLOv5s 보다 2%가량 높았다. Recall 도 마찬가지로 YOLOv5l 이 92.61%로 가장 높았다. 결과적으로 객체 탐지 속도를 중점적으로 본다면 YOLOv5s 를 이용한다면 좋은 결과가 나올 것으로 예상되고 YOLOv5l 의 정확도가 다른 모델보다 1-2%가량 높았기 때문에 객체 탐지의 정확도를 중점적으로 보았을 때 가장 알맞은 모델이라고 볼 수 있다.",다국어 초록 정보 없음
시각장애인을 위한 모바일 기반 장애물 탐지 연구,2021,[],"사물 인식이란 컴퓨터에 입력되는 이미지에서 사용자가 정의한 사물들을 컴퓨터 비전 기술을 이용하여 인식하는 과정으로, 사물 인식을 이용하면 컴퓨터가 카메라를 통하여 입력되는 이미지에서 장애물 등 특정 사물의 인식 결과를 사용자에게 알려줄 수 있다. 본 논문에서는 YOLO 사물 인식 알고리즘을 이용하여 시각장애인에게 전방의 장애물을 인식하여 알려줄 수 있는 기술을 제시한다. 해당 기술은 실용성을 고려하여 모바일 환경에서 이용할 수 있으며, 서버와의 연동을 통해 실시간으로 사용자에게 사물 인식의 결과를 알려줄 수 있다.",다국어 초록 정보 없음
스마트시티에서 활용 가능한 LoRa기반 화재 대피 경로 안내 시스템,2021,[],최근 국내에서 스마트시티 조성이 활성화됨에 따라 이에 적합한 LoRa 통신을 중심으로 연구를 진행하였다. 본 논문에서는 현재 사용 중인 수동형 대피체계의 한계를 보완하고자 화재 상황에 따른 방향 지시 서비스를 구현하였다. 저전력 장거리 통신이 가능한 LoRa 모듈을 이용해 통신망을 구축하였다. 화재 발생 시 CSI 카메라 모듈을 이용한 YOLO 객체 탐지와 온습도 센서를 통해 건물 내부의 혼잡도와 상황을 파악한다. 이러한 데이터를 바탕으로 총 대피시간을 단축시킬 수 있는 대피알고리즘에 적용해 최적의 대피 경로를 안내하는 화재 대피 경로 안내 시스템 개발을 제안한다.,다국어 초록 정보 없음
객체 탐지 딥러닝 모델을 활용한 무기고 감시 시스템에 대한 연구,2021,[],최근 딥러닝 기술을 이용하여 객체 탐지 분야에서 좋은 성능을 보여주고 있다. 국방 분야에서도 이러한 딥러닝 기술을 이용한 31가지 인공지능 모델에 대하여 연구를 진행중에 있으며 무기체계에 대한 객체 인식 및 탐지 기술이 중요하다. 본 연구에서는 딥러닝 기술을 이용하여 총기 및 사람을 추적하는 방법에 대하여 분석하였다. 딥러닝 모델로 YOLO 모델을 사용하였고 추가적으로 감시장비에 적용한 무기고 보안 시스템 설계 방안에 대하여 고찰하였다.,다국어 초록 정보 없음
밀리미터파 하향링크 빔포밍을 위한 비전 기반 다중 사용자 그룹화 및 각도 추정,2021,[],"본 논문에서는 비전 정보를 활용한 다중 사용자 그룹화 및 각도 추정 알고리즘을 제안한다. 밀리미터파 하향링크 상황에서 기지국과 단말 사이의 beam training 과정이 필요하다. 하지만 기존의 수신신호 기반 beam training 방법은 사용자의 수가 늘어날수록 큰 오버헤드가 발생한다. 제안하는 알고리즘은 비전정보, YOLO(you only look once) 알고리즘을 이용하여 사용자를 인식하고 -평균 그룹화를 통하여 다중 사용자를 그룹화하고, 그룹 중심(centroid) 좌표를 이용하여 방위각과 고각을 추정하는 순서로 구성된다. 기지국에서 보이는 사용자 그룹의 위치로 빔을 형성하기 때문에 beam training overhead를 줄일 수 있다. 시뮬레이션을 통해 제안하는 기법의 성능을 평가한다.",다국어 초록 정보 없음
Thermal Array Sensor를 이용한 낙상 감지 시스템,2021,[],본 논문은 Thermal Array Sensor를 이용한 실내에서의 인간의 낙상을 감지하는 시스템을 구현하였다. 다른 센서보다 저렴하면서도 사생활 보호 측면에서는 우수한 성능을 보여주는 Thermal Array Sensor를 Jetson nano와 연결하여 원격으로 제어한다. 시스템 구현과정에서 정확도를 높이기 위해 정규화를 적용하였으며 객체 인식 프레임워크인 YOLO v3를 이용하여 실험을 하였다. 정규화를 적용한 데이터는 적용하지 않은 데이터보다 학습 결과 더 높은 정확도를 보여주었으며 두가지 클래스를 낙상감지에 사용하였으며 높은 정확도를 보여주었다.,다국어 초록 정보 없음
Deep Learning-based Colorectal Cancer Detection in Endoscopic Images,2021,[],국문 초록 정보 없음,"Colorectal cancer (CRC) is the most prevalent cancer found in the small bowel of the human gastrointestinal (GI) tract. Polyps are antecedents to CRC and are detected in approximately half of the people at age 50 within the GI. In this paper, an improved version of You Only Live Once (YOLO) is presented for the detection of polyp within the endoscopic images. We have improved the YOLOv3-tiny model by adding more convolutional layers to extract enriched and deeper features. For fair benchmarking, the efficacy of the proposed model is evaluated against the default version of YOLOv3-tiny in terms of recall, precision, F1-score, and F2-score."
Action Recognition Model to Monitor Illegal Dumping using Zoom-In Image Sequence Data,2021,"['Action recognition', 'Distance between camera and human', 'Human detection', 'Object detection', 'Deep learning']",국문 초록 정보 없음,"In this study, we propose an action recognition model that provides generalized performance regardless of camera location and distance between the camera and human. The proposed model consists of two-stage networks, namely, human detection and action recognition. The proposed method operates on video frames that are resized by a new zoom-in method using pretrained Yolo v3. To use temporal information, which is regarded as a critical factor in action recognition, we adopt the R(2+1)D model, which is a factorized model capable of representing more complex networks. The proposed Zoom-In method yields generalized performance regardless of distance. In an experiment, the proposed method exhibited accuracies of 96.07%, 96.61%, and 94.55% in the short, medium, and long ranges in which our datasets were employed, respectively."
임베디드 실시간 객체 인식을 위한 Low-level Feature Aggregation 및 Attention 기반 검출 모델 개발,2021,[],자율 주행(Autonomous Driving) 환경에서 실시간 객체 인식과 정확한 객체 인식은 차량의 안전 주행을 위한 핵심 요소이다. 최근 One-stage Detector 기반의 경량화된 모델들은 실시간 객체 인식이가능하나 성능 면에서는 좋지 않은 결과를 보여왔다. 이에 본 논문에서는 YOLOv4-tiny 기반의 새로운 모델을 제안한다. 빠른 추론 속도는 유지하면서 성능 향상을 위해 본 논문에서는 3가지 기법을 적용한다. 첫 번째로는 작은 물체의 검출 성능을 높이기 위해 YOLO Head를 하나 더 추가하였다. 두 번째로는 Low-level의 특징들을 더 깊은 층으로 전달하기 위해 Low-level Feature Aggregation(LFA) 기법을 사용하였다. 그리고 세 번째로는 관심 객체의 특징에 더 집중할 수 있도록 Attention 모듈을 사용하였다. 안전 주행 및 주행 경로 안내를 위해 실제 차량 주행 영상에서의노면 마크(Roadmark)와 색깔 유도선(Colored-guideline)을 검출 대상으로 선정하였으며 Jetson Tx2 임베디드 환경에서 실험을 진행하였다. 그 결과 해당 환경에서 기존 방법 대비 가장 좋은 성능을 보임을 확인하였다.,다국어 초록 정보 없음
Detection and tracking for the awareness of surroundings of a ship based on deep learning,2021,"['ship awareness', 'object detection', 'deep learning', 'object tracking', 'Kalman filter']",국문 초록 정보 없음,"To prevent maritime accidents, it is crucial to be aware of the surrounding environment near ships. The images recorded by a camera mounted on a ship could be used for the awareness of other ships surrounding it. In this study, ship awareness was performed using three procedures: detection, localization, and tracking. Initially, ship detection was performed using the deep learning-based detection model, YOLO (You Only Look Once) v3, based on the camera image. A virtual image dataset was constructed using Unity to overcome the difficulty of obtaining camera images onboard with various sizes of ships, and to improve the detection performance. This was followed by the localization procedure in which the position of the horizon on the image was calculated using the orientation information from the ship. Subsequently, the position of the detected ship in the spatial coordinate system was calculated using the horizon information. Following this, the position, course over ground, and speed over ground of the target ships were tracked in the time domain using the extended Kalman filter. A deep learning model that determines the heading of the ship in the image was proposed to utilize abundant information of cameras, and it was used to set the initial value of the Kalman filter. Finally, the proposed method for the awareness of ships was validated using an actual video captured from a camera installed on an actual ship with various encountering scenarios. The tracking results were compared with actual automatic identification system data obtained from other ships. As a result, the entire detection, localization, and tracking procedures showed good performance, and it was estimated that the proposed method for the awareness of the surroundings of a ship, based on camera images, could be used in the future."
영상 객체 인식을 이용한 꿀벌 모니터링 시스템 구현,2021,[],"꿀벌은 농작물 화수분에서 매우 중요한 역할을 한다. 그런데 벌통 근처의 환경 변화나 날씨 변화, 일련의 사건 등으로 벌통 내의 개체 수가 감소해도 소유자가 그 사실을 쉽게 파악하기 힘들다. 본 논문에서는 꿀벌통의 실시간 영상 모니터링 및 분석을 통해 꿀벌의 개체를 인식하여 꿀벌통을 출입하는 꿀벌들의 개체 수를 파악할 수 있는 시스템을 제안하고 구현한다. 이 시스템은 리눅스 운영체제를 기반으로 하며 YOLO V3의 Darknet 프레임워크를 통해 벌 한 마리당의 객체를 식별 및 추적하여 하루마다 출입하는 꿀벌의 수를 파악한 후, 일정 이상의 개체 수가 돌아오지 않으면 벌통의 소유주에게 알림 메시지를 송신한다. 이 시스템을 통해 꿀벌통의 소유주들이 꿀벌 개체의 급격한 변화에 대한 문제들에 조금 더 빠르게 대응할 수 있을 것으로 기대된다.",다국어 초록 정보 없음
드론비행영상을 활용한 도로 혼잡도 분석,2021,"['Deep Learning', 'Traffic Analysis', 'Drone', 'CNN', 'Image Processing']",국문 초록 정보 없음,"Analysis of traffic consegstion is an important role in traffic management and distribution. Drone flight image is searching on the wide view of road information at once. This paper aims to analyze how congested the roads are detecting vehicles on the road using drone flight images taken in the city. Based on the YOLO architecture, the congestion analysis process is conducted with 83.3% accuracy for vehicle detection and 87.5% accuracy for lane detection. The information obtains through this is expected to analyze the traffic volume and navigation performance of roads. Furthermore, as it is a study that analyzes actual road condition, it is a helpful for traffic management and traffic signal systems."
적층제조 공정의 이미지학습 기반 실시간 이상 탐지 시스템 개발,2021,"['스마트제조', '적층제조', '실시간 검측', '이미지 학습', '합성곱신경망']","선재아크형 적층제조(WAAM: Wire Arc Additive Manufacturing)는 용접기술을 적층제조에 접목한 공정이다. WAAM은 높은 적층률과 낮은 재료원가에 대한 장점이 있으나, 공정 특성상 품질 문제가 취약하다. 이러한 품질 문제를 극복하기 위하여, 본 연구에서는 합성곱신경망을 이용하여 WAAM 공정의 영상 이미지로부터 실시간으로 정상과 이상을 탐지 하는 시스템을 개발한다. 본 시스템은 모델 생성 모듈과 모델 활용 모듈로 구성된다. 모델 생성 모듈에서는 과거 WAAM 공정의 영상 이미지 데이터를 수집하고, 합성곱신경망을 이용하여 이 데이터를 학습한 이상 탐지 모델을 생성한다. 모델 활용 모듈에서는 기생성된 이상 탐지 모델을 적용하여 현재 WAAM 공정에서 획득된 영상 이미지 데이터로부터 정상과 이상을 판별한다. 사례 연구에서는 고가 소재인 몰리브덴합금을 대상으로 개발된 시스템의 기능성과 유효성을 확인한다. 또한, 객체탐지 기법 중 하나인 Yolo 기반 모델과의 성능 비교를 수행한다.",다국어 초록 정보 없음
국민안전을 위한 강력범죄 수배차량 검거시스템,2021,[],국문 초록 정보 없음,"The final goal of this study is to develop a system that can analyze whether a wanted vehicle is a criminal vehicle from images collected from black boxes, smartphones, CCTVs, and so on. Data collection was collected using a self-developed black box. The used data in this study has used a total of 83,753 cases such as the eight vehicle types(truck, RV, passenger car, van, SUV, bus, sports car, electric vehicle) and 434 vehicle models. As a result of vehicle recognition using YOLO v5, mAP was found to be 80%. As a result of identifying the vehicle model with ReXNet using the self-developed black box, the accuracy was found to be 99%. The result was verified by surveying field police officers. These results suggest that improving the accuracy of data labeling helps to improve vehicle recognition performance."
Implementation of a Mobile Multi-Target Search System with 3D SLAM and Object Localization in Indoor Environments,2021,"['3D SLAM', 'Object recognition', 'Object localization']",국문 초록 정보 없음,"This paper addresses the problem of the recognition and localization of multiple targets while building a three-dimensional map using 3D SLAM (Simultaneous Localization and Mapping) in indoor environments. Since stationary target search systems have the limitations that the target search is conducted passively, this paper presents an implementation of a multi-target search system with a mobile robot and multiple sensors. The mobile multi-target search system consists of a 3D LiDAR and a depth camera on top of a two-wheel mobile robot. Multiple targets are recognized by YOLO (You Only Look Once), and the relative position between the mobile robot and the recognized target is measured by the depth information obtained by the depth camera. The 3D SLAM is implemented with LeGO-LOAM (Lightweight and Ground Optimized Lidar Odometry and Mapping), and the positions of the recognized multiple targets are described with the 3D map. The mobile multi-target search system was implemented on ROS (Robot Operating System) and tested in multiple indoor environments."
Real-Time Earlobe Detection System on the Web,2021,"['Computer vision', 'Deep learning', 'Image processing', 'Object detection']",국문 초록 정보 없음,"This paper proposed a real-time earlobe detection system using deep learning on the web. Existing deep learning-based detection methods often find independent objects such as cars, mugs, cats, and people. We proposed a way to receive an image through the camera of the user device in a web environment and detect the earlobe on the server. First, we took a picture of the user's face with the user's device camera on the web so that the user's ears were visible. After that, we sent the photographed user's face to the server to find the earlobe. Based on the detected results, we printed an earring model on the user's earlobe on the web. We trained an existing YOLO v5 model using a dataset of about 200 that created a bounding box on the earlobe. We estimated the position of the earlobe through a trained deep learning model. Through this process, we proposed a real-time earlobe detection system on the web. The proposed method showed the performance of detecting earlobes in real-time and loading 3D models from the web in real-time."
Real-Time Earlobe Detection System on the Web,2021,"['Computer vision', 'Deep learning', 'Image processing', 'Object detection']",국문 초록 정보 없음,"This paper proposed a real-time earlobe detection system using deep learning on the web. Existing deep learning-based detection methods often find independent objects such as cars, mugs, cats, and people. We proposed a way to receive an image through the camera of the user device in a web environment and detect the earlobe on the server. First, we took a picture of the user's face with the user's device camera on the web so that the user's ears were visible. After that, we sent the photographed user's face to the server to find the earlobe. Based on the detected results, we printed an earring model on the user's earlobe on the web. We trained an existing YOLO v5 model using a dataset of about 200 that created a bounding box on the earlobe. We estimated the position of the earlobe through a trained deep learning model. Through this process, we proposed a realtime earlobe detection system on the web. The proposed method showed the performance of detecting earlobes in real-time and loading 3D models from the web in real-time."
"영상인식 기반 성별, 연령대 추정 연구",2021,"['Human robot interaction', 'Vision', 'Deep learning']","최근 소비자 분석을 통한 맞춤형 콘텐츠 제공에 대한 연구가 활발히 진행되고 있다. 이러한 맞춤형 콘텐츠를 전시관에서 적용하기 위해서는 특정 전시물이나 디자인에 대한 성별 및 연령대 정보 수집이 필요하며 현재 정보의 수집을 위해서는 설문을 통하여 사용자가 직접 정보를 제공하는 방법이 사용되지만 정보 수집과 가공이 번거롭고 설문자의 적극적인 참여가 필요하기 때문에 자동으로 통계자료를 획득할 수 있는 알고리즘이 요구 된다. 본 연구는 특정 전시물에 대한 관람객의 성별 및 연령대별 관심도 분석을 위하여 합성곱 신경망을 적용한 영상 기반의 성별, 연령대 추정 알고리즘을 연구하였다. 알고리즘은 YOLO v4 기반의 검출 알고리즘을 적용하여 우선적으로 관람객의 전체 이미지로부터 얼굴 이미지를 검출한 뒤, 검출한 이미지를 식별 신경망에 적용하여 성별과 연령대 추정이 가능하게 하였다. 식별에 사용된 EfficientNet 신경망 모델의 학습을 위하여 AI Hub 의 오픈 소스 데이터 중 한국인 감정인식 데이터 셋으로부터 얻은 18,967 장의 이미지 데이터 셋을 구성하였고 K-fold Cross Validation 기법을 적용하여 전체 알고리즘을 실험 및 검증하였다. 본 개발 알고리즘을 기반으로 향후에는 특정 전시물에 대한 관람객의 성별 및 연령대별 관심도 분석을 위한 추가적인 실증 연구를 수행할 예정이다.",다국어 초록 정보 없음
CNN 모델의 최적 양자화를 위한 웹 서비스 플랫폼,2021,"['Convolutional Neural Network', 'Deep Learning Accelerator', 'Quantization', 'Web Service']",국문 초록 정보 없음,"Low-end IoT devices do not have enough computation and memory resources for DNN learning and inference. Integer quantization of real-type neural network models can reduce model size, hardware computational burden, and power consumption. This paper describes the design and implementation of a web-based quantization platform for CNN deep learning accelerator chips. In the web service platform, we implemented visualization of the model through a convenient UI, analysis of each step of inference, and detailed editing of the model. Additionally, a data augmentation function and a management function of files that store models and inference intermediate results are provided. The implemented functions were verified using three YOLO models."
A deep learning-based approach for feeding behavior recognition of weanling pigs,2021,"['Convolutional neural network', 'Deep learning', 'Behavior detection', 'Processing', 'Weanling pig']",국문 초록 정보 없음,"Feeding is the most important behavior that represents the health and welfare of weanling pigs. The early detection of feed refusal is crucial for the control of disease in the initial stages and the detection of empty feeders for adding feed in a timely manner. This paper proposes a real-time technique for the detection and recognition of small pigs using a deep-leaning-based method. The proposed model focuses on detecting pigs on a feeder in a feeding position. Conventional methods detect pigs and then classify them into different behavior gestures. In contrast, in the proposed method, these two tasks are combined into a single process to detect only feeding behavior to increase the speed of detection. Considering the significant differences between pig behaviors at different sizes, adaptive adjustments are introduced into a you-only-look-once (YOLO) model, including an angle optimization strategy between the head and body for detecting a head in a feeder. According to experimental results, this method can detect the feeding behavior of pigs and screen non-feeding positions with 95.66%, 94.22%, and 96.56% average precision (AP) at an intersection over union (IoU) threshold of 0.5 for YOLOv3, YOLOv4, and an additional layer and with the proposed activation function, respectively. Drinking behavior was detected with 86.86%, 89.16%, and 86.41% AP at a 0.5 IoU threshold for YOLOv3, YOLOv4, and the proposed activation function, respectively. In terms of detection and classification, the results of our study demonstrate that the proposed method yields higher precision and recall compared to conventional methods."
목재 표면 검사를 위한 기계 학습 적용,2021,[],"최근 딥러닝을 비롯한 기계 학습의 눈부신 발전에 힘입어 많은 연구 분야는 기계 학습을 새로운 연구 방법론으로서 채택하고 있다. 목재 과학에서도 수종 식별, 정량적 해부학, 표면 품질 검사 등 방대한 데이터를 다루거나 노동 집약적인 분야에 기계 학습을 적용하기 위한 연구가 수행되고 있다. 목재의 표면 품질을 평가하기 위한 시각 검사는 숙련된 검사자의 주관적 판단에 의존하고 있으며 반복 작업으로 인한 신체적 피로 및 권태감은 판단 정확도를 감소시키는 요인이 된다. 표면 검사의 정확도 향상 및 연속 공정 도입을 위해 컴퓨터 비전과 기계 학습이 적용되었다. 초기에는 화상에서 수동으로 특징을 추출하는 특징 공학적 기법들이 적용되었다. Semantic segmentation에 기반하여 표면 이미지에서 결함 영역을 추출하고 유형을 분류하는 이 작업은 다수의 연구로부터 좋은 결과가 보고되었으나 사용자의 수동 작업이 여전히 큰 비중을 차지하였다. 최근에는 주로 딥러닝이 표면 검사에 적용되고 있다. Region-based Convolutional Neural Networks(R-CNN) 및 You Only Look Once(YOLO) 시리즈에 기반한 객체 탐지 모델이 표면 검사에 적용되었으며 기존의 특징 공학적 모델을 능가하는 성능이 보고되었다. 컴퓨터 하드웨어의 발전은 더욱더 깊은 backbone 네트워크 사용의 부담을 줄임으로써 성능 향상에 기여하고 있으며 instance segmentation은 표면 결함의 개체별 정확한 분획을 구현한다. 이제는 기계 학습이 목재 과학에서 생소한 분야가 아니다. 인공지능 기반 연구 환경 조성 및 이니셔티브 확장을 위해서는 대형 데이터베이스 구축, 이용 및 인력 양성을 위한 목재 과학 및 산업의 적극적 대응이 필요하다.",다국어 초록 정보 없음
세라믹 3D 프린팅 형상 측정 및 결함 감지를 위한 층간 모니터링 방법,2021,"['3D printing', 'Ceramics', 'Selective reaction hardening', 'Monitoring', 'Machine learning']","세라믹은 전기·전자, 광학, 의료 등 여러 분야에서 요구되는 특성을 구현하는 우수한 소재이지만, 절삭 가공이 어려운 난삭재로 분류되며 3D 프린팅 제조 또한 기술의 난이도가 높은 실정이다. 특히 3D 프린팅 제조를 통해 생산된 제품은 절삭 공정에 비해 낮은 형상 정밀도를 가지며, 반응 경화 시 결함으로 인한 내부 기공은 세라믹 제품에 있어 치명적이다. 낮은 형상정밀도의 문제는 연마 등의 후처리 공정의 비중이 커지고 비용의 증가로 이어지게 된다. 또한 내부 기공의 경우 취성 재료인 세라믹의 특성상, 직접 균열의 원인이 되거나 기공에 집중되는 응력으로 인해 미세균열의 원인이 될 수 있다. 따라서 한 층씩 적층되는 3D 프린팅 제조에서 있어서 층간 모니터링은 매우 중요하다. 본 연구에서는 선택적 반응 경화 기반 세라믹 3D 프린팅 공정에서 비전 센서를 이용한 층간 형상 모니터링 및 머신 러닝(Machine Learning)을 이용한 결함 탐지 시스템을 제안하였다. 제안된 모니터링 시스템은 상단에 고정된 비전센서를 통해 데이터를 확보하고 결함을 감지하는 방식이다. 제안된 모니터링 시스템을 이용할 경우 층간 형상은 선택적으로 반응된 경화물의 색상을 통해 추출하며, 적층 중 결함은 머신 러닝 알고리즘 중 하나인 YOLO (You only Look Once)를 이용하여 탐지한다. 본 연구에서 제안된 모니터링 시스템을 통해 세라믹 3D 프린팅의 형상 최적화 및 세라믹 제조품의 불량률을 감소시킬 수 있을 것이다.",다국어 초록 정보 없음
K-city 자율주행 경진대회 참가를 위한 자율주행 플랫폼 개발,2021,"['자율주행(Autonomous driving)', 'ROS(Robot Operating System)', 'SLAM(Simultaneous Localization And Mapping)', '차선 인식(Lane detection)', '물체 인식(Object detection)']",국문 초록 정보 없음,"In this paper, a ROS-based autonomous driving framework designed by team ACCA from the School of Mechanical Engineering, Soongsil University, for the 2021 international college student creative car challenge held in K-city. The autonomous vehicle’s chassis used in this challenge is equipped with Velodyne 3D lidar, a Sick down-looking 2D lidar, Xsens MTi-30 AHRS, CCD camera, webcam, and PC-based controller. First, before the challenge in K-city, we evaluated the ROS-package-based SLAM such as LIO-SAM in a ring-shaped road environment on the campus of Soongsil University. After the successful SLAN and mapping process, the hdl_localization, which is a 3D lidar-based real-time 3D localization package, is used to estimate the global pose with respect to the global frame using NDT scan matching. For lane detection, traffic sign, and traffic signal recognition, the two well-known DNN models are utilized. Based on experimental results from both simulation and an actual autonomous vehicle platform, the Point Instance Network (PINet) for lane detection shows 88% of test accuracy, and the YOLO V4 for the traffic light and sign recognition offers 95% test accuracy."
RGB 영상 기반 감자 부피 추정,2021,"['수확량 모니터링', '감자 부피', '영상처리']","감자는 세계 4대 식량 작물 중 하나로서 국내 농가의 주요 소득 작물이다. 최근 시설에서 노지로 디지털농업이 확산되고 있다. 노지 디지털농업 실현에 있어 수확량 정보는 변량처방을 위한 기초적인 자료로서 수확량을 정확히 파악하는데 많은 관심이 대두되고 있다. 본 연구는 감자의 수확량 모니터링 기술 개발을 위한 기초연구로 RGB 영상을 이용한 감자의 부피를 추정하기 위해 수행되었다. 실험실 환경에서 감자 3품종(수미, 대서, 조풍), 5 등급의 크기별로 각 20개씩 총 300개의 시료를 스마트폰 카메라를 사용하여 정면, 측면 영상을 취득하였으며, 영상 취득 시 보정을 위해 한 변의 길이가 50mm인 검은색 정사각형을 함께 촬영하였다. 이후 촬영된 영상은 IDL v8.8(Harris, USA) 프로그래밍 언어를 이용하여 감자와 배경을 분리하고, 영상 내 정사각형을 이용한 픽셀의 보정을 수행한 후, 감자 단면적의 넓이와 둘레를 계산하였다. 감자의 실제 부피 측정은 종자치환법을 사용하였으며, SAS v9.4(SAS Institute Inc., USA) 소프트웨어를 사용하여 단면적의 넓이 및 둘레와 실측 부피 간의 회귀분석을 수행하였다. 분석 결과 단면적의 넓이-부피 간의 회귀모델의 결정계수(R2)가 정면, 측면 각각 0.952, 0.957로 둘레-부피 회귀모델의 R2 정면, 측면 각각 0.93, 0.9265보다 상대적으로 높게 나타났다. 정면과 측면을 혼합한 데이터의 경우, 넓이-부피 회귀모델과 둘레-부피 회귀모델의 R2는 각각 0.8941, 0.9028로 단일 방향 모델에 비하여 설명력이 감소하였으나 두 모델 모두 높은 설명력을 지닌 것으로 나타났다. 실제 포장 내에는 감자 외에도 흙, 돌 등의 이물질이 함께 존재하므로, 이를 분류하기 위한 YOLO 등의 딥러닝 기술을 함께 접목하면 추후 실시간 수확량 모니터링 및 지도 작성을 위한 기술로써 사용될 수 있을 것으로 판단된다.",다국어 초록 정보 없음
A Study on Pagoda Image Search Using Artificial Intelligence (AI) Technology for Restoration of Cultural Properties,2021,"['Enter key words or phrases in alphabetical order', 'separated by commas']",국문 초록 정보 없음,"The current cultural assets are being restored depending on the opinions of experts (craftsmen). We intend to introduce digitalized artificial intelligence techniques, excluding the personal opinions of experts on reconstruction of such cultural properties. The first step toward restoring digitized cultural properties is separation. The restoration of cultural properties should be reorganized based on recorded documents, period historical backgrounds and regional characteristics. The cultural properties in the form of photographs or images should be collected by separating the background. In addition, when restoring cultural properties most of them depend a lot on the tendency of the restoring person workers. As a result, it often occurs when there is a problem in the accuracy and reliability of restoration of cultural properties. In this study, we propose a search method for learning stored digital cultural assets using AI technology. Pagoda was selected for restoration of Cultural Properties. Pagoda data collection was collected through the Internet and various historical records. The pagoda data was classified by period and region, and grouped into similar buildings. The collected data was learned by applying the well-known CNN algorithm for artificial intelligence learning. The pagoda search used Yolo Marker to mark the tower shape. The tower was used a total of about 100-10,000 pagoda data. In conclusion, it was confirmed that the probability of searching for a tower differs according to the number of pagoda pictures and the number of learning iterations. Finally, it was confirmed that the number of 500 towers and the epochs in training of 8000 times were good. If the test result exceeds 8,000 times, it becomes overfitting. All so, I found a phenomenon that the recognition rate drops when the enemy repeatedly learns more than 8,000 times. As a result of this study, it is believed that it will be helpful in data gathering to increase the accuracy of tower restoration."
