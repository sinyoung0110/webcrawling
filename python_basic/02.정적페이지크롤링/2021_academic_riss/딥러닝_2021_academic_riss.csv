title,date,keywords,abstract,multilingual_abstract
SystemC 기반 스토리지와 버퍼 및 딥러닝 가속기 시뮬레이터 시스템 구현,2021,"['엣지 디바이스', '낸드 플래시 메모리', '데이터 버퍼', '딥러닝 가속기', '인공지능 응용', 'Edge Device', 'NAND Flash Memory', 'Data Buffers', 'Deep Learning  Accelerator', 'AI Applications']","최근 IoT 시스템에서 엣지 디바이스를 이용한 데이터 저장 및 분산 처리 연산을 수행하기 위해서 다양한 연구가 진 행되고 있다. 인공지능 추론 연산도 그중 하나로써 임베디드 장치에서 인공지능 연산을 수행하기 위해서 소프트웨어 또는 하드웨어 레벨에서 많은 연구가 진행 중이다. 특히, 하드웨어 레벨에서 임베디드 프로세서나 임베디드 GPU를 이용한 연산 처리는 한계가 있어서 독립적인 하드웨어 딥러닝 가속기를 추가하는 추세이다. 이러한 딥러닝 가속기는 복잡한 신경망 연산을 하드웨어에서 독립적으로 수행하기 위해서 많은 데이터 저장 및 이동이 필요하며, 내부적으로 는 반복 병렬 연산을 수행하기 때문에 내부 저장 시스템 및 버퍼 구조와 데이터 이동 경로에 대한 분석과 최적화가 필요하다. 딥러닝 가속기의 데이터 사용성에 대한 분석을 통하여 딥러닝 가속기의 최적화 설계를 돕기 위해서, 본 논문에서는 RISC-V 기반 가상 플랫폼에서 SystemC 기반으로 ESL 수준에서 딥러닝 가속기와 낸드 플래시 메모 리 시스템으로 구성된 가상 엣지 디바이스 플랫폼을 제공하고, RISC-V 기반 가상 플랫폼에서 딥러닝 가속기를 이 용한 응용 프로그램을 실행하고 분석하는 환경을 제공하였다. 구현한 딥러닝 가속기 시뮬레이터를 이용해서 딥러닝 가속기의 저장장치 및 내부 버퍼의 사용성과 딥러닝 연산에 따른 데이터 이동량 및 버퍼링 효과를 분석할 수 있는 기반을 마련하였다.","Recently many researches are being conducted to perform data distributed processing with embedded edge devices in IoT systems, and artificial intelligence inference is one of them. Many studies are underway at the software or hardware level to perform artificial intelligence operations in embedded systems. In particular, the hardware-supported deep learning operations, such as GPU, in embedded system are limited, so a hardware deep learning accelerator is considered to be added in the architecture. Since such a deep learning accelerator performs a lot of data storage and movement and iterative parallel operation internally to perform complex neural network computation, it is required to analyze and optimize a precise internal buffer and data movement path management for efficient design of deep learning accelerator. In this paper, to model and analyze a deep learning accelerator in a virtual platform based on RISC-V, a deep learning accelerator is designed and implemented at the ESL level based on SystemC as well as main memory and NAND flash controller, then the data movement with storage and buffering effect were analyzed and examined on the developed deep learning accelerator. Using the implemented deep learning accelerator simulator, the usability of the internal buffer of the deep learning accelerator and the data movement amount and buffering effect according to the deep learning operation can be analyzed."
딥러닝을 이용한 정삼투 막모듈의 플럭스 예측,2021,"['Forward osmosis', 'FO', 'Membrane module', 'Flux prediction', 'Deep learning', '정삼투', '막모듈', '플럭스 예측', '딥러닝']",,"Forward osmosis (FO) process is a chemical potential driven process, where highly concentrated draw solution (DS) is used to take water through semi-permeable membrane from feed solution (FS) with lower concentration. Recently, commercial FO membrane modules have been developed so that full-scale FO process can be applied to seawater desalination or water reuse. In order to design a real-scale FO plant, the performance prediction of FO membrane modules installed in the plant is essential. Especially, the flux prediction is the most important task because the amount of diluted draw solution and concentrate solution flowing out of FO modules can be expected from the flux. Through a previous study, a theoretical based FO module model to predict flux was developed. However it needs an intensive numerical calculation work and a fitting process to reflect a complex module geometry. The idea of this work is to introduce deep learning to predict flux of FO membrane modules using 116 experimental data set, which include six input variables (flow rate, pressure, and ion concentration of DS and FS) and one output variable (flux). The procedure of optimizing a deep learning model to minimize prediction error and overfitting problem was developed and tested. The optimized deep learning model (error of 3.87%) was found to predict flux better than the theoretical based FO module model (error of 10.13%) in the data set which were not used in machine learning."
딥러닝 기반 피사체 시선 추적을 통한 자동 주석 생성 시스템,2021,"['딥러닝', '시선 추적', '시선 추정', '주석 생성', 'deep learning', 'gaze following', 'gaze estimation', 'annotation generation']","피사체의 시선 추적(Gaze Following)은 단일 이미지에서 피사체의 시선이 응시하는 지점을 탐지한다. 딥러닝 기반의 기존 연구는 단순히 시선의 각도를 추정하거나, 스마트폰과 같은 기기 스크린 내부의 응시점을 추정하므로 어떤 객체를 보는지에 대한 정보를 얻을 수 없다는 한계가 있다. 본 논문에서는 최초로 딥러닝 모델을 활용하여 피사체의 시선을 추적하고 ‘J가 넥타이를 본다.’와 같이 자동으로 주석을 생성하는 시스템을 제안한다. 시스템은 전처리 모듈, 시선 추적 모듈, 후처리 모듈로 구성되며, 전처리 모듈에서 인물을 인식하고 딥러닝 모델의 입력을 생성한다. 시선 추적 모듈에서는 딥러닝 모델이 피사체의 응시 지점이 표시된 히트맵(heatmap)을 생성한다. 후처리 모듈에서는 우리가 제안하는 객체 선택 알고리즘에 의해 응시 지점에 있는 객체를 인식하고 주석을 생성한다. 제안된 시스템은 리테일링 및 학술 목적의 대규모 메타데이터를 효율적으로 생성하는 데 활용될 수 있다.","Gaze following is the task of detecting the point of attention in a single image at which a subject""s gaze is staring. The existing deep learning methods have a limitation in that they cannot determine which specific object is the target of the gaze angle, because these methods simply estimate the gaze angle, or estimate the gaze point within the screen of a device, such as a smart phone. In this paper, we propose a novel system that infers where a subject is looking by using a deep learning model and automatically generating annotations such as ""J is looking at the tie."" The proposed system consists of a pre-processing module, a gaze following module, and a post-processing module. In the pre-processing module, our system recognizes faces and generates inputs for the deep learning model. In the gaze following module, the deep neural network generates a heatmap for the point at which the subject is looking. In the post-processing module, the proposed object selection algorithm determines the object of the gaze point, and annotations are then generated. The proposed system can be used to generate large-scale metadata for retailing and academic purposes."
딥러닝 모델과 Kinect 카메라를 이용한 실시간 관절 애니메이션 제작 및 표출 시스템 구축에 관한 연구,2021,"['Kinect', 'deep learning', '3D animation', 'skeleton', 'human pose estimation']","증강현실과 가상현실 같은 3차원 콘텐츠 보급이 증가함에 따라 실시간 컴퓨터 애니메이션 기술의 중요성이 높아지고 있다. 하지만 컴퓨터 애니메이션 제작 과정은 대부분 수작업 혹은 마커를 부착하는 모션캡쳐 방식으로 이루어져 있다. 때문에 사실적인 영상을 얻기 위해서는 숙련된 전문가에게도 매우 오랜 시간이 필요하다. 이러한 문제점을 해결하기 위해 최근에는 딥러닝 모델과 센서를 기반으로 하는 애니메이션 제작 시스템과 알고리즘이 나오고 있다. 이에 본 논문에서는 딥러닝과 Kinect 카메라 기반 FBX 형식의 애니메이션 제작 시스템에서 자연스러운 인체 움직임을 구현하는 4가지 방법에 대해 연구했다. 각 방법은 환경적 특성과 정확도를 고려하여 선택된다. 첫 번째 방법은 Kinect 카메라를 사용한다. 두 번째 방법은 Kinect 카메라와 보정 알고리즘을 사용한다. 세 번째 방법은 딥러닝 모델을 사용한다. 네 번째 방법은 딥러닝 모델과 Kinect를 사용한다. 제안 방법을 오차와 처리 속도를 실험한 결과, 네 번째 딥러닝 모델과 Kinect를 동시에 사용하는 방법이 다른 방법에 비해 가장 좋은 결과를 보였다.",
딥러닝 형상관리를 위한 블록체인 시스템 설계,2021,"['BlockChain', 'Configuration Management System', 'Deep Learning', 'Ethereum', 'Tensor Flow']","머신러닝의 한 종류인 딥러닝은 각 학습 과정을 진행할 때, 가중치를 변경하면서 학습을 수행한다. 딥러닝을 수행할때 대표적으로 사용되는 Tensor Flow나 Keras의 경우 학습이 종료된 결과를 그래프 형태로 제공한다. 이에 과다 학습으로 인한 퇴화 현상 또는 가중치의 잘못된 설정으로 인해 학습 결과에 오류가 발생하는 경우, 해당 학습 결과를 폐기해야한다. 이에 기존 기술은 학습 결과를 롤백하는 기능을 제공하고 있지만, 롤백 기능은 최대 5회 이내의 결과로 제한된다. 또한, 딥러닝의 모든 과정을 기록하고 있는 것이 아니기 때문에 값을 추적하기 어렵다. 이를 해결하기 위해 MLOps의 개념을 적용한 기술이 존재하지만. 해당 기술에서는 이전 시점으로 롤백하는 기능을 제공하지 않는다. 본 논문에서는 기존 기술의 문제점을 해결하기 위해 학습 과정의 중간 값을 블록체인으로 관리하여 학습 중간 과정을 기록하고, 오류가 발생할 경우 롤백할 수 있는 시스템을 구성한다. 블록체인의 기능 수행을 위해서 딥러닝 과정 및 학습 결과 롤백은 Smart Contract를 작성하여 동작하도록 설계하였다. 성능평가는 기존의 딥러닝 방식의 롤백 기능을 평가하였을 때, 제안방식은 100%의 복구율을 가지는 것에 비교하여 기존 기법에서는 6회 이후에 복구율이 감소되어 50회일 때 10%까지 감소하는 것을 확인하였다. 또한, 이더리움 블록체인의 Smart Contract를 사용할 때, 블록 1회 생성 시 157만원의 금액이 지속적으로 소모되는 것을 확인하였다.","Deep learning, a type of machine learning, performs learning while changing the weights as it progresses through each learning process. Tensor Flow and Keras provide the results of the end of the learning in graph form. Thus, If an error occurs, the result must be discarded. Consequently, existing technologies provide a function to roll back learning results, but the rollback function is limited to results up to five times. Moreover, they applied the concept of MLOps to track the deep learning process, but no rollback capability is provided. In this paper, we construct a system that manages the intermediate value of the learning process by blockchain to record the intermediate learning process and can rollback in the event of an error. To perform the functions of blockchain, the deep learning process and the rollback of learning results are designed to work by writing Smart Contracts. Performance evaluation shows that, when evaluating the rollback function of the existing deep learning method, the proposed method has a 100% recovery rate, compared to the existing technique, which reduces the recovery rate after 6 times, down to 10% when 50 times. In addition, when using Smart Contract in Ethereum blockchain, it is confirmed that 1.57 million won is continuously consumed per block creation."
기상 데이터와 기상 위성 영상을 이용한 다중 딥러닝 모델 기반 일사량 예측,2021,"['Satellites Image', 'Weather Data', 'Multi Deep Learning Model', 'Radiation Prediction', 'Artificial Intelligence']","딥러닝은 데이터의 품질과 모델에 따라 예측 성능에 차이를 보인다. 본 연구는 발전량 예측에 가장 영향을 주는 일사량 예측을 위한 최적의 딥러닝 모델을 구축하기 위해 다양한 입력 데이터와 다중 딥러닝 모델을 사용하였다. 입력 데이터는 기상청의 기상 데이터와 천리안 기상영상을 기상청 지역의 영상을 분할하여 사용하였다, 본 연구는 기본적인 딥러닝 모델인 DNN, LSTM, CNN 모델에 대해 중간층의 깊이와 노드를 변경하여 일사량을 예측하여, 비교 평가하였다, 또한, 각 모델에서 가장 좋은 오차율을 가진 모델을 연결한 다증 딥러닝 모델을 구축하여 일사량을 예측하였다. 실험 결과로서 다중 딥러닝 모델인 모델 A의 RMSE는 0.0637이며, 모델 B의 RMSE는 0.07062이며, 모델 C의 RMSE는 0.06052로서 단일 모델보다 모델 A 그리고 모델 C의 오차율이 좋았다. 본 연구는 실험을 통해 두 개 이상의 모델을 연결한 모델이 향상된 예측률과 안정된 학습 결과를 보였다.","Deep learning shows differences in prediction performance depending on data quality and model. This study uses various input data and multiple deep learning models to build an optimal deep learning model for predicting solar radiation, which has the most influence on power generation prediction. did. As the input data, the weather data of the Korea Meteorological Administration and the clairvoyant meteorological image were used by segmenting the image of the Korea Meteorological Agency. , comparative evaluation, and predicting solar radiation by constructing multiple deep learning models connecting the models with the best error rate in each model. As an experimental result, the RMSE of model A, which is a multiple deep learning model, was 0.0637, the RMSE of model B was 0.07062, and the RMSE of model C was 0.06052, so the error rate of model A and model C was better than that of a single model. In this study, the model that connected two or more models through experiments showed improved prediction rates and stable learning results."
병원 외래환자수의 예측을2 위한 시계열 데이터처리 딥러닝 시스템,2021,"['딥러닝', '시계열 데이터', '빅데이터', '성능평가', 'Deep Learning', 'Time Series Data Processing', 'Performance Evaluation']",딥러닝 기술의 도래로 인하여 수많은 산업과 일반적인 응용에 적용됨으로써 우리의 생활에 큰 영향을 발휘하고 있다. 특정한 분야의 문제를 해결하기 위해서는 그 문제에 적합한 딥러닝 모델을 작성해야 한다. 근래에는 COVID-19 사태로 인하여 다양한 문제들을 딥러닝으로 해결하고자 하는 사례들이 늘고 있다. 이러한 일환으로 본 논문에서는 갑자기 급증할 수 있는 병원의 외래환자들을 미리 예측을 위한 시계열의 딥러닝 모델을 제시하고자 한다. 제시하는 딥러닝 모델은 주피터 노트북에서 케라스로 작성하였다. 예측결과는 실제 데이터와 그래프로 비교하며 유효성 데이터를 활용하여 과소적합과 과대적합의 여부를 손실률로 분석할 수 있도록 하였다.,"The advent of the Deep Learning has applied to many industrial and general applications having an impact on our lives these days. Certain type of machine learning model is needed to be designed for a specific problem of field. Recently, there are many instances to solve the various COVID-19 related problems using deep learning model. Therefore, in this paper, a deep learning model for predicting number of outpatients of a hospital in advance is suggested. The suggested deep learning model is designed by using the Keras in Jupyter Notebook. The prediction result is being analyzed with the real data in graph, as well as the loss rate with some validation data to verify either for the underfitting or the overfitting."
딥러닝을 이용한 공간예측,2021,"['지리통계학적 데이터', '딥러닝', '공간상관', '공간예측', 'geostatistical data', 'deep learning', 'spatial correlation', 'spatial prediction']","공간상에서 얻어지는 데이터는 일반통계학과 다르게 얻어지는 관측값들은 서로 상관되어 있다는 전제하에서 분석이 행해진다. 공간통계학에서 공간데이터는 (1) 경험 베리오그램 추정, (2) 추정된 경험베리오그램을 이용한 이론베리오그램 적합, 그리고 (3) 이론베리오그램을 이용하여 기지(旣知)의 위치에서 측정된 관측값을 이용하여 미지(味知)의 위치에서의 관측값을 예측하는 크리깅의 과정을 거쳐 분석된다. 최근 이슈화되고 있는 인공지능 기법의 하나인 딥러닝이 역시 예측의 한 방법으로 널리 적용되고 있다. 전기한 두 방법 모두 예측을 한다는 측면에서는 유사 하지만, 공간통계학의 분석과정을 거쳐 예측하는 방법은 분석자의 주관이 개입될 수 있을 뿐만 아니라 분석과정은 그리 간단하지 않다. 그리고 공간데이터 분석의 가정을 만족하지 못하는 경우도 있다. 그러나 딥러닝은 이론적으로는 복잡할 수 있으나 공간통계학에서 행해지는 분석방법 보다 훨씬 사용하기가 간단하다는 장점이 있다. 본 연구에서는 시뮬레이션을 이용하여 두 방법을 사용하여 분석을 수행하고, 어느 방법이 더 예측적인 측면에서 우월한가에 대해서 알아보고, 실제 적용 예를 통해서 본 연구의 타당성을 알아본다. 예측력의 기준으로 RMSE를 사용하였고, 분석결과 기존의 공간통계학 예측방법과 딥러닝 기법에 따른 예측력은 비슷한 결과를 보였다. 따라서 공간데이터를 분석함에 있어 공간예측의 단점을 보완할 수 있는 딥러닝을 적용한 공간예측 분석을 제안한다.","Unlike general statistics, spatial data is analyzed on the premise that they are spatially correlated. In general, spatial data is analyzed by kriging method as follow stages: (1) Estimating an empirical variogram, (2) Fitting a theoretical variogram using the estimated empirical variogram, (3) Predicting the value in the unknown location using the observations from the known location with the fitted theoretical variogram. Deep learning, one of the artificial intelligence techniques that have recently become an issue, is also widely applied as a way of prediction. Although both methods are similar in terms of making predictions, not only can the subject of the analyst be involved in the method of predicting through the analysis process of kriging method, but the analysis process is not very simple. However, deep learning can be complex to design, but it has the advantage of being much simpler to use than analytical methods conducted in kriging method. In this work, we use both methods to conduct our analysis and to find out which methods are superior in terms of more spatial predictive aspects. The RMSE was used as the criteria for prediction performance. The result of the prediction comparison showed that kriging method and deep learning have similar power for spatial prediction. Therefore, we propose to perform spatial analysis by applying deep learning that can compensate for the disadvantages of spatial prediction by triple stages of kriging method."
딥러닝 기반 부실기업 예측모형에 관한 연구,2021,"['기업 부실화', '딥러닝 기법', '머신러닝', '앙상블 모형', '한계기업 예측', 'Corporate Insolvency', 'Deep Learning', 'Machine Learning', 'Ensemble Model', 'Marginal Company Prediction']","부실기업 예측은 회계와 재무 분야에서 중요하게 다루어져 온 연구 주제이다. 특히, 급변하는 기업 환경과 최근 COVID-19 대유행으로 국내의 많은 기업이 기업 부실화로 재무적 어려움에 직면하고 있어 그 연구의 필요성이 더욱 강조되고 있다. 대표적인 관련 연구로는 기업부도 예측이 있지만, 부도기업은 사실상 사업활동을 중단한 기업으로 계속기업 간에 어떠한 기업이 부실 징후를 보이는지를 판단하는 기준으로 부적합하다는 한계점이 존재한다. 본 연구는 부실기업의 범주 중 하나인 한계기업을 그 예측대상으로 선정하였다. 한계기업은 3개년도 연속 이자보상비율이 1 미만인 기업으로, 사업활동을 영위하고 있으나 적정 수준의 이익을 지속적으로 확보하지 못하고 있는 부실기업을 의미한다. 본 연구에서는 한계기업 예측을 위한 방법으로 딥러닝 기법을 활용하였다. 딥러닝은 다양한 분야에서 그 우수성을 인정받아 최근 주목받고 있는 머신러닝 기법의 하나이지만 한계기업 예측을 위한 연구에서는 적용된 바가 없다. 본 연구는 여러 재무비율 변수를 독립변수로 하여 딥러닝 기법 중 RNN과 CNN를 적용하고, 선행연구에서 예측력이 뛰어나다고 보고된 머신러닝 앙상블 모형들과 그 성과를 비교하였다. 2017~2019년의 기업 데이터를 학습용 및 테스트용 데이터로 설정하여 분석한 결과, RNN-LSTM, RNN-GRU, CNN이 재현율(Recall)의 관점에서 우수한 성과를 보이는 것으로 나타났다. 그러므로 딥러닝 모형이 한계기업 예측에서도 널리 사용될 수 있는 분석방법이 될 것으로 기대된다.","Predicting insolvent companies is a research topic that has been important in accounting and finance. Especially, due to the rapidly changing business environments and the recent COVID-19 pandemic, many domestic companies are facing financial adversity. Thus, the necessity of research on corporate insolvency is being emphasized. As a related research, there is a prediction of corporate bankruptcy, however, a bankrupt company is the company whose business activities have been suspended, and there is a limitation in which it is inappropriate to determine which companies show signs of bankruptcy among continuing companies. Therefore, marginal company, one of the categories of insolvent companies, is selected as the prediction target. Marginal companies are the firms that are operating income interest compensation ratio are less than 1 for three consecutive years, and are engaged in business activities but have not consistently secured adequate profits. In this study, deep learning techniques are used to predict them. It is one of the machine learning techniques that has recently attracted attention because of its excellence in various fields. Nonetheless, has not been applied in research to predict marginal companies. This study applies RNN and CNN among deep learning techniques using several financial ratios as independent variables. Their performance are compared with machine learning ensemble models that have been reported to have excellent predictive power in previous studies. As a result of analysis on corporate data from 2017 to 2019 as training and test data, deep learning models such as RNN-LSTM, RNN-GRU, and CNN are better in forecasting of marginal companies than the ensemble models in terms of Recall score. Therefore, the deep learning models are expected to become widely used in the prediction of marginal companies in the future."
딥러닝 기반 불량노면 객체 인식 모델 개발,2021,"['딥러닝', '전동 이동보조 장치', '교통약자', 'YOLOv5', '불량 노면객체', 'Electric mobility', 'Transportation handicapped', 'YOLOv5', 'Poor road surface objects', 'Deep learning']","본 연구에서는 전동이동기기를 이용하는 교통약자의 이동을 제한하는 노면 불량 요소를 딥러닝을 이용해 자동 검출하는 불량 노면객체 인식모델을 개발하고자 한다. 이를 위하여 부산시 관내 5개 지역에서 실제 전동 이동보조 장치가 이동할 것으로 예상되는 보행로, 주행로를 대상으로 하여 노면정보를 수집하였으며 이때 도로정보 수집은 데이터 수집을 보다 용이하게 하기 위하여 소형 차량을 이용 하였다. 데이터는 노면과 주변을 그 주변을 구성하는 객체로 구분하여 영상을 수집하였다. 수집된 데이터로 부터 교통약자의 이동을 저해하는 정도에 따라 분류하여 보도블럭의 파손등급 검출과 같은 일련의 인식 항목을 정의하였고, YOLOv5 딥러닝 알고리즘을 해당 데이터에 적용하여 실시간으로 객체를 인식하는 불량노면 객체 인식 딥러닝 모델을 구현 하였다. 연구의 최종단계에서 실제 주행을 통해 객체 단위로 분리 수집된 영상 데이터의 가공, 정제 및 어노테이션 과정을 수행한 후 모델 학습과 검증을 거쳐 불량노면객체를 자동으로 검출하는 딥러닝 모델의 성능 검증 과정을 진행 하였다.","In this paper, poor road surface objects that hinder the movement of the transportation handicapped were identified as 7 items consisting of curb, road holes, gutter, manholes, broken blocks, braille blocks, and road cracks after performing movement verification in 5 areas within the city of Busan using an electric mobility aid device, and then a deep learning model for recognizing poor road surfaces was developed that recognizes objects in real time by applying the YOLOv5 deep learning algorithm. For model development, the image of the object was directly collected using a road information collection vehicle, and after processing, refining, and annotating the data, a deep learning model was trained and verified to be able to detect poor road surface objects"
스몰 딥러닝을 이용한 아스팔트 도로 포장의 균열 탐지에 관한 연구,2021,"['Deep learning', 'Crack detection', 'Asphalt', 'Road maintenance', '경량 딥러닝', '균열 탐지', '아스팔트', '도로 관리']","아스팔트 포장의 균열은 날씨의 변화나 차량에 의한 충격으로 발생하며, 균열을 방치할 경우 포장 수명이 단축되고 각종 사고를 불러 일으킬 수 있다. 따라서 아스팔트 도로 포장의 균열을 빠르게 감지하여 보수조치를 취하기 위하여 이미지를 통해 균열을 자동으로 탐지하기 위한 연구들이 지속되어 왔다. 특히 최근들어 Convolutional Neural Network를 사용하여 아스팔트 도로 포장의 균열을 탐지하려는 모델들이 많이 연구되고 있으나, 고성능의 컴퓨팅 파워를 요구하기 때문에 실제 활용에는 한계가 있다. 이에 본 논문에서는 모바일 기기에 적용 가능한 스몰 딥러닝 모델을 적용하여 아스팔트 도로 포장의 균열을 탐지하는 모델의 개발을 위한 프레임워크를 제안한다. 사례연구를 통해 제안한 스몰 딥러닝 모델은 일반적인 딥러닝 모델들과 비교 연구되었으며, 상대적으로 적은 파라미터를 가지는 모델임에도 일반적인 딥러닝 모델들과 유사한 성능을 보였다. 개발된 모델은 모바일 기기나 IoT에 임베디드 되어 사용될 수 있을 것으로 기대된다.","Cracks in asphalt pavement occur due to changes in weather or impact from vehicles, and if cracks are left unattended, the life of the pavement may be shortened, and various accidents may occur. Therefore, studies have been conducted to detect cracks through images in order to quickly detect cracks in the asphalt pavement automatically and perform maintenance activity. Recent studies adopt machine-learning models for detecting cracks in asphalt road pavement using a Convolutional Neural Network. However, their practical use is limited because they require high-performance computing power. Therefore, this paper proposes a framework for detecting cracks in asphalt road pavement by applying a small deep learning model applicable to mobile devices. The small deep learning model proposed through the case study was compared with general deep learning models, and although it was a model with relatively few parameters, it showed similar performance to general deep learning models. The developed model is expected to be embedded and used in mobile devices or IoT for crack detection in asphalt pavement."
임베디드 보드에서의 딥러닝 사용 효율성 분석 연구,2021,"['임베디드 시스템', '개발 보드', '싱글보드 컴퓨터', '딥러닝', 'Embedded System', 'Development Board', 'Singleboard Computer', 'Deeplearning']","4차산업혁명이 본격화됨에 따라 관련 기술들이 화두가 되고 있다. 고속 무선통신과 같은 기술을 최대한으로 활 용하기 위한 하드웨어 개발이 가속화되고 있으며, 관련 기업들이 급격히 성장하고 있다. 인공지능의 경우 관련 연구 를 위해서 일반적으로 데스크톱을 사용하는 경우가 많지만, 주로 딥러닝의 학습 과정을 위해 사용되고 있으며 생성된 모델을 프로그램 등에 포함하여 사용할 기기에 이식하는 경우가 많다. 하지만, 학습량이 과도하거나 데스크톱의 성능 만큼 제작된 모델을 사용하게 되어 전원공급이 따로 이루어지지 않는 기기의 경우 전력이 부족하거나 성능이 충분하 지 못하기 때문에 제 결과를 내기 어렵다. 본 논문에서는 딥러닝의 성능을 임베디드 보드에 맞추어 개발하기 전에 판 매되고 있는 몇 가지 Neural Process Unit을 탑재한 보드와 USB로 딥러닝 수행 성능을 높일 수 있는 딥러닝 액셀 러레이터를 사용하여 효율성을 비교하여 임베디드 보드로 가능한 개발 방향을 제시한다.","As the fourth industrial revolution begins in earnest, related technologies are becoming a hot topic. Hardware development is accelerating to make the most of technologies such as high-speed wireless communication, and related companies are growing rapidly. Artificial intelligence often uses desktops in general for related research, but it is mainly used for the learning process of deep learning and often transplants the generated models into devices to be used by including them in programs, etc. However, it is difficult to produce results for devices that do not have sufficient power or performance due to excessive learning or lack of power due to the use of models built to the desktop's performance. In this paper, we analyze efficiency using boards with several Neural Process Units on sale before developing the performance of deep learning to match embedded boards, and deep learning accelerators that can increase deep learning performance with USB, and present a simple development direction possible using embedded boards."
도로 CCTV 데이터를 활용한 딥러닝 기반 차량 이상 감지,2021,"['도로 교통', '딥러닝', '객체탐지', '이상탐지', '도로 CCTV 데이터', '배경 추출', 'Road Traffic', 'Deep Learning', 'Object Detection', 'Anomaly Detection', 'CCTV', 'Extraction']",현대사회에서는 차량을 소유하는 사람들이 증가하면서 교통문제가 발생하고 있다. 특히 고속도로 교통사고 문 제는 발생률이 낮지만 치사율은 높다. 따라서 차량의 이상을 탐지하는 기술이 연구되고 있다. 이 중에는 딥러닝을 이용 한 차량 이상탐지 기술이 있다. 이는 사고 및 엔진고장으로 인한 정차차량 등의 차량 이상을 탐지한다. 그러나 도로에 서 이상이 발생할 경우 운전자의 위치를 파악할 수 있어야 빠른 대처가 가능하다. 따라서 본 연구에서는 도로 CCTV 데이터를 활용한 딥러닝 기반 차량 이상 감지 방법을 제안한다. 제안하는 방법은 먼저 도로 CCTV 데이터를 전처리한 다. 전처리는 배경 추출 알고리즘인 MOG2를 이용하여 배경과 전경을 분리한다. 전경은 변위가 존재하는 차량을 의미 하며 도로 위에서 이상이 존재하는 차는 변위가 없어 배경으로 판단된다. 배경이 추출된 이미지는 이상을 탐지하기 위해 YOLOv4를 이용하여 객체를 탐지한다. 해당 차량은 이상이 있음으로 판단한다.,"In the modern society, traffic problems are occurring as vehicle ownership increases. In particular, the incidence of highway traffic accidents is low, but the fatality rate is high. Therefore, a technology for detecting an abnormality in a vehicle is being studied. Among them, there is a vehicle anomaly detection technology using deep learning. This detects vehicle abnormalities such as a stopped vehicle due to an accident or engine failure. However, if an abnormality occurs on the road, it is possible to quickly respond to the driver's location. In this study, we propose a deep learning-based vehicle anomaly detection using road CCTV data. The proposed method preprocesses the road CCTV data. The pre-processing uses the background extraction algorithm MOG2 to separate the background and the foreground. The foreground refers to a vehicle with displacement, and a vehicle with an abnormality on the road is judged as a background because there is no displacement. The image that the background is extracted detects an object using YOLOv4. It is determined that the vehicle is abnormal."
ResNet과 Unet을 결합한 딥러닝 모델을 이용한 분광 신호에서 ROI 검출,2021,"['Peak Detection', 'Region of Interest', 'Deep Learning', 'CNN', 'Raman Spectroscopy']","본 연구에서는 딥러닝 기술(deep learning technology)을 이용하여 분광 신호의 ROI(region of interest)를 찾는 방법을 제안한다. 제안한 방법은 모의실험 데이터로 학습된 딥러닝 모델을 이용하여 분광 신호의 ROI를 검출하는 방법이다. 분광 신호의 피크는 물질의 물리 화학적인 정보를 포함하고 있으므로 정확한 피크 검출은 분석 시스템의 성능에 영향을 미치는 중요한 과정이다. 지금까지 가장 많이 사용되는 방법은 진폭을 기반으로 피크 검출을 진행하는 것이다. 하지만 이런 방법들은 전처리 과정을 포함하거나 분광 신호에 따라 파라미터를 육안 검사로 선택하여 추정하므로 복잡하고 주관적이다. 이러한 문제점 개선을 위해 딥러닝 모델을 통해 분광 신호의 ROI 검출을 수행하였다. 제안한 방법은 전처리 과정이 없고 파라미터를 설정하지 않아도 되는 장점을 갖는다. 또한 검출한 ROI에 따라 분광 신호에 후처리(post-processing)를 수행하여 피크를 얻을 수 있다. 디폴트 손실 함수에 3만개 테스트 데이터를 적용하여 얻은 손실값을 통해 성능 평가를 수행하였다. 제안된 ResNet과 Unet을 결합한 딥러닝 모델은 일반적인 컨볼루션 신경망(CNN: Convolutional Neural Network), ResNet, 그리고 Unet에 비해 각각 76.5%, 69.8%, 5.9%의 성능 향상을 보였으며, 실제 라만 분광 신호의 ROI 검출에도 효과적으로 적용될 수 있음을 확인하였다.","This study proposes a method to find the ROI (region of interest) of spectral signals using deep learning technology. The proposed method detects the ROI of spectral signals using a deep learning model trained with simulated data. Since the peak of the spectral signal contains physical and chemical information of the substance, accurate peak detection is an important process affecting the performance of the analyzed system. The widely used method for peak detection is the one based on the amplitude. However, this method is complex and subjective because it involves pre-processing or select and estimate parameters using visual inspection according to spectral signals. To overcome this problem, ROI detection of the spectral signal was performed through a deep learning model. The proposed method has the advantage of requiring no pre-processing and parameter setting. In addition, a peak may be obtained by performing post-processing of the spectral signal according to the detected ROI. Performance evaluation was performed through loss values obtained by applying 30,000 test data to the custom loss function. The proposed deep learning model combining ResNet and Unet showed performance improvements of 76.5%, 69.8%, and 5.9% compared to the general convolutional neural network (CNN), ResNet, and Unet, respectively. It was also confirmed that the proposed method could be effectively applied to measured spectral signals."
블록체인 기반의 분산형 딥러닝 시스템 설계 및 구현,2021,"['블록체인', '분산 시스템', '딥러닝', 'P2P', 'blockchain', 'distributed system', 'deep learning']","다양한 형태의, 그리고 다량의 데이터가 점차 축적되어가면서 이를 해석하고 활용하기 위한 딥러닝 학습의 중요성이 더욱 커졌다. 딥러닝 학습 시 필요한 연산이 점차 복잡해짐에 따라 이에 필요한 컴퓨팅 능력을 분산하여 처리하고자 하는 분산형 딥러닝 시스템이 등장하게 되었고, 이때 각 학습 노드 간에 학습 결과인 가중치 데이터를 교환하는 방법에 대한 논의가 다양하게 되어왔다. 그러나 기존에 제시되어왔던 가중치 교환 방식은 제3 관리자를 필요로 하는 중앙 집중형 방식이거나, 혹은 각 노드간 데이터 무결성의 침해 위험이 잔재하는 P2P 기반의 방식이었다. 이에 본 연구에서는 P2P 환경에서도 데이터의 무결성을 보장하면서 가중치 데이터를 교환할 수 있는 블록체인 기반의 분산형 딥러닝 시스템 Chainlearn을 제안하며, 이에 대한 활용 사례를 보이고 기존 시스템과 비교한 Chainlearn만의 특장점을 분석한다.","With gradual accumulation of various forms and large quantities of data, the importance of deep learning process to interpret and utilize them has increased. The increasing complexity of computations required for deep learning has led to the emergence of distributed deep learning systems to deal with the computing power in part, resulting in discussions on how to exchange weighted data, the result of training between learning nodes. Previously proposed weight exchange methods were either centralized, requiring third-party administrators, or P2P-based. They show a risk of infringing data integrity between nodes. Thus, in this work, we proposed a blockchain-based distributed deep learning system called Chainlearn. It allows for exchanging weighted data while ensuring data integrity even in P2P environments. This study also used cases and analyzed characteristics of Chainlearn compared to existing systems."
국내학회지 논문 리뷰를 통한 원격탐사 분야 딥러닝 연구 동향 분석,2021,"['Remote Sensing', 'Deep Learning', 'Analysis of Research Trend', 'Image Acquisition Platform', 'Open Source Data', '원격탐사', '딥러닝', '연구동향분석', '영상 취득 탑재체', '오픈소스데이터']",,
NOMA 시스템에서 SINR 정보 피드백을 이용한 딥러닝 기반 송신 전력 제어의 성능 분석,2021,"['Deep learning', 'Transmit power control', 'Non-orthogonal multiple access', 'Channel feedback', '딥러닝', '송신 전력 제어', '비직교 다중 접속', '채널 피드백']","본 논문에서는 하향링크 비직교 다중 접속 시스템에서 최소 데이터 전송률을 만족하며 데이터 전송률의 총합을 최대화 할 수 있는 딥러닝 기반의 송신 전력 제어 기법을 제안한다. 하향링크 비직교 다중 접속 시스템에서 사용자가 위치한 셀 이외의 기지국으로부터 발생할 수 있는 동일 채널 간섭을 고려하고, 시스템 피드백 오버헤드를 줄이기 위하여 사용자는 채널 상태 정보 대신에 신호 대 간섭 및 잡음비 정보를 피드백 한다. 따라서 기지국은 신호 대 간섭 및 잡음비 정보만을 이용하여 송신 전력을 제어한다. 함축적 신호 대 간섭 및 잡음비 정보의 이용은 정보 차원을 감소시키는 장점은 있지만 데이터 전송률을 감소시킬 수 있는 단점이 있다. 본 논문에서는 딥러닝 기반의 학습 방식으로 이 문제를 해결하고, 딥러닝 입력의 차원을 효과적으로 축소할 경우 학습의 성능을 향상시킬 수 있음을 보여준다. 시뮬레이션을 통해서 제안된 딥러닝 기반의 송신 전력 제어 기법이 최소 데이터 전송률을 만족하며 데이터 전송률의 총합을 향상시킬 수 있음을 입증한다.","In this paper, we propose a deep learning-based transmit power control scheme to maximize the sum-rates while satisfying the minimum data-rate in downlink non-orthogonal multiple access (NOMA) systems. In downlink NOMA, we consider the co-channel interference that occurs from a base station other than the cell where the user is located, and the user feeds back the signal-to-interference plus noise power ratio (SINR) information instead of channel state information to reduce system feedback overhead. Therefore, the base station controls transmit power using only SINR information. The use of implicit SINR information has the advantage of decreasing the information dimension, but has disadvantage of reducing the data-rate. In this paper, we resolve this problem with deep learning-based training methods and show that the performance of training can be improved if the dimension of deep learning inputs is effectively reduced. Through simulation, we verify that the proposed deep learning-based power control scheme improves the sum-rate while satisfying the minimum data-rate."
다각형 용기의 품질 향상을 위한 딥러닝 구조 개발,2021,"['Deep Learning', 'Machine Vision', 'Convolution Layer', 'Bottleneck Layer', 'Fully Connect Layer', 'Softmax Layer']","본 논문에서는 다각형 용기의 품질 향상을 위한 딥러닝 구조 개발을 제안한다. 딥러닝 구조는 convolution 층, bottleneck 층, fully connect 층, softmax 층 등으로 구성된다. Convolution 층은 입력 이미지 또는 이전 층의 특징 이미지를 여러 특징 필터와 convolution 3x3 연산하여 특징 이미지를 얻어 내는 층이다. Bottleneck 층은 convolution 층을 통해 추출된 특징 이미지상의 특징들 중에서 최적의 특징들만 선별하여 convolution 1x1 ReLU로 채널을 감소시키고convolution 3x3 ReLU를 실시한다. Bottleneck 층을 거친 후에 수행되는 global average pooling 연산과정은 convolution 층을 통해 추출된 특징 이미지의 특징들 중에서 최적의 특징들만 선별하여 특징 이미지의 크기를 감소시킨다. Fully connect 층은 6개의 fully connect layer를 거쳐 출력 데이터가 산출된다. Softmax 층은 입력층 노드의 값과 연산을 진행하려는 목표 노드 사이의 가중치와 곱을 하여 합하고 활성화 함수를 통해 0～1 사이의 값으로 변환한다. 학습이 완료된 후에 인식 과정에서는 학습 과정과 마찬가지로 카메라를 이용한 이미지 획득, 측정 위치 검출, 딥러닝을 활용한 비원형 유리병 분류 등을 수행하여 비원형 유리병을 분류한다. 제안된 다각형 용기의 품질 향상을 위한 딥러닝 구조의 성능을 평가하기 위하여 공인시험기관에서 실험한 결과, 양품/불량 판별 정확도 99%로 세계최고 수준과 동일한 수준으로 산출되었다. 검사 소요 시간은 평균 1.7초로 비원형 머신비전 시스템을 사용하는 생산 공정의 가동 시간 기준 내로 산출되었다. 따라서 본 본문에서 제안한 다각형 용기의 품질 향상을 위한 딥러닝 구조의 성능의 그 효용성이 입증되었다.","In this paper, we propose the development of deep learning structure to improve quality of polygonal containers. The deep learning structure consists of a convolution layer, a bottleneck layer, a fully connect layer, and a softmax layer. The convolution layer is a layer that obtains a feature image by performing a convolution 3x3 operation on the input image or the feature image of the previous layer with several feature filters. The bottleneck layer selects only the optimal features among the features on the feature image extracted through the convolution layer, reduces the channel to a convolution 1x1 ReLU, and performs a convolution 3x3 ReLU. The global average pooling operation performed after going through the bottleneck layer reduces the size of the feature image by selecting only the optimal features among the features of the feature image extracted through the convolution layer. The fully connect layer outputs the output data through 6 fully connect layers. The softmax layer multiplies and multiplies the value between the value of the input layer node and the target node to be calculated, and converts it into a value between 0 and 1 through an activation function. After the learning is completed, the recognition process classifies non-circular glass bottles by performing image acquisition using a camera, measuring position detection, and non-circular glass bottle classification using deep learning as in the learning process. In order to evaluate the performance of the deep learning structure to improve quality of polygonal containers, as a result of an experiment at an authorized testing institute, it was calculated to be at the same level as the world’s highest level with 99% good/defective discrimination accuracy. Inspection time averaged 1.7 seconds, which was calculated within the operating time standards of production processes using non-circular machine vision systems. Therefore, the effectiveness of the performance of the deep learning structure to improve quality of polygonal containers proposed in this paper was proven."
딥러닝을 이용한 유방조영술의 종양 분할,2021,"['유방조영술', '딥러닝', '의미론적 분할', 'CNN', 'Mammography', 'Deep Learning', 'Semantic Segmentation']","유방 종양은 유방암의 증상 중 하나이며 유방암은 여성에게서 흔히 발병하는 질병이다. 유방 종양은 초기 검사인 유방조영술에서 발견되므로 초기 진단이 매우 중요하다. 하지만 유방 종양을 탐지하는 것은 전문가에게도 어려운 일이다. 최근 딥러닝을 사용하여 유방조영술영상에서 병변을 찾으려는 노력이 이루어지고 있으며 본 논문에서는 딥러닝을 사용하여 유방조영술 영상에서 유방 종양을 분할하고자 한다. CBIS-DDSM(Curated Breast Image Subset of Digital Database for Screening Mammography) 데이터를 수집하고 데이터에 전처리를 시행한다. 의미론적 분할 모델인 FCN(Fully Convolutional Network), U-Net과 CNN(Convolutional Neural Network) 백본망인 VGGNet(Visual Geometry Group Net), EfficientNet 모델의 조합으로 4개의 모델을 구성하여 학습 기법을 사용하여 학습한다. 평가 데이터를 통해 유방 종양이 예측된 마스크와 유방 종양을 나타내는 실제 마스크를 사용하여 얼마나 유사하게 분할하였는지 시각화하고 구성한 모델의 성능을 비교한다. U-Net-EfficientNet 모델이 85.91%로 가장 높은 성능을 보여주었고, U-Net-VGG-Net 모델이 63.56%로 가장 낮은 성능을 보여주었다.","Breast tumor is one of the symptoms of breast cancer. And breast cancer is a common disease in women. Initial diagnosis is very important because breast tumors are found by mammography, which is an initial examination. However, detecting breast tumor is difficult even for experts. Efforts have recently been made to use deep learning to look for lesions in mammographic images. Many papers used deep learning to isolate breast tumors from mammographic images. We collect CBISDDSM(Curated Breast Image Subset of Digital Database for Screening Mammography) data and preprocess the data. Semantic segmentation model, which is FCN(Fully Convolutional Network) and U-Net, is combined with CNN(Convolutional Neural Network) backbone, which is VGGNet(Visual Geometry Group Net) and EfficientNet, to construct four models. The four models are trained using learning methods. The evaluation data are used to visualize the similarity between the segmented result using a predicted mask and the actual mask showing breast tumors. The performances of the constructed models are compared. The U-Net-EfficientNet model showed the highest performance at 85.91%, and the U-Net-VGGNet showed the lowest performance at 63.56%."
딥러닝 기반 지능형 기술가치평가에 관한 연구: 심층신경망 학습을 통한 정성평가 지표 예측 모형,2021,"['기술가치평가', '딥러닝', '기술금융', '기보 특허가치평가시스템', '심층신경망', 'Technology valuation', 'Deep learning', 'Technology finance', 'Kibo Patent Appraisal System', 'Deep Neural Networks']","최근 전 세계적으로 주목받고 있는 기술금융 지원정책은 저성장 기조의 경제 현황을 극복하기 위한 정부 부처 및 유관기관의 기업혁신 지원전략으로 부상하고 있다. 이에 힘입어 최근에는 기술가치 평가체계의 한계(장기간 · 고비용)를 개선한 웹 기반 지능형 평가시스템이 일부 평가기관을 중심으로 제공 중에 있으나, 여전히 사용자에게 전문적인 평가 지식을 요구한다는 점에서 한계가 존재한다.  본 논문에서는 기존 시스템의 정성평가 항목에 딥러닝 기반 추정을 적용, 현금흐름 산출로직에 연계하는 방안을 제시한다. 이는 일반적으로 준용되는 기술가치평가 방법론을 기반으로 이론적 타당성은 유지하되, 전문적 지식을 요구하는 세부지표점수들을 딥러닝 기반 추정을 적용함으로써 비전문가 수준에서도 손쉽게 보유 기술의 가치를 확인할 수 있는 수요자 편의성을 제공한다.  최종적으로 본 논문에서는 제안하는 인공신경망 기반 알고리즘을 통해 기업이 보유하고 있는 특허 또는 기술에 대해 객관적이고 신속한 평가를 수행할 수 있도록 하며, 기존 방법론이 내포하고 있던 장시간 · 고비용의 한계를 최소화하고 적시에 기술 기반 금융 활동에 대한 의사 결정을 지원할 수 있다는 점에서 그 활용성이 기대된다.","The technology finance is emerging as a corporate innovation support strategy of government sectors in line with the low-growth economic trends. Therefore, some evaluation agencies are providing a web-based intelligent technology valuation framework, but there still exist limitations.  In this study, we propose how to associate deep learning-based estimation results with cash flow calculation logics and how to automate them, without waiting until scoring qualitative factors among experts group. While holding theoretical validity based on technology valuation methodology generally accepted, it provides the demanders"" convenience in that it enables commercialization support non-experts to easily identify the values of a technology, by deep learning-based estimation and automated calculation which required expertise knowledge regarding technology assessment.  Ultimately, by deep learning-based algorithms we propose the objective, prompt valuation for a firm""s technologies or patents will be feasible and it is expected that they minimize the limitations in terms of long-term and high-cost in valuation and support decision-making for technology-driven finance activities."
딥러닝 기반의 연기 확산거리 예측을 위한 알고리즘 개발 기초연구,2021,"['딥러닝', '연기검출', '연기 확산거리 예측', 'YOLO', 'LSTM', 'Deep learning', 'Smoke detection', 'Smoke spread distance prediction', 'YOLO', 'LSTM']","본 연구는 화재진압 및 피난활동을 지원하는 딥러닝 기반의 알고리즘 개발에 관한 기초 연구로 선박 화재 시 연기감지기가 작동하기 전에 검출된 연기 데이터를 분석 및 활용하여 원격지까지 연기가 확산 되기 전에 연기 확산거리를 예측하는 것이 목적이다. 다음과 같은 절차에 따라 제안 알고리즘을 검토하였다. 첫 번째 단계로, 딥러닝 기반 객체 검출 알고리즘인 YOLO(You Only Look Once)모델에 화재시뮬레이션을 통하여 얻은 연기 영상을 적용하여 학습을 진행하였다. 학습된 YOLO모델의 mAP(mean Average Precision)은 98.71%로 측정되었으며, 9 FPS(Frames Per Second)의 처리 속도로 연기를 검출하였다. 두 번째 단계로 YOLO로부터 연기 형상이 추출된 경계 상자의 좌표값을 통해 연기 확산거리를 추정하였으며 이를 시계열 예측 알고리즘인 LSTM(Long Short-Term Memory)에 적용하여 학습을 진행하였다. 그 결과, 화재시뮬레이션으로부터 얻은 Fast 화재의 연기영상에서 경계 상자의 좌표값으로부터 추정한 화재발생~30초까지의 연기 확산거리 데이터를 LSTM 학습모델에 입력하여 31초~90초까지의 연기 확산거리 데이터를 예측하였다. 그리고 추정한 연기 확산거리와 예측한 연기 확산거리의 평균제곱근 오차는 2.74로 나타났다.","This is a basic study on the development of deep learning-based algorithms to detect smoke before the smoke detector operates in the event of a ship fire, analyze and utilize the detected data, and support fire suppression and evacuation activities by predicting the spread of smoke before it spreads to remote areas. Proposed algorithms were reviewed in accordance with the following procedures. As a first step, smoke images obtained through fire simulation were applied to the YOLO (You Only Look Once) model, which is a deep learning-based object detection algorithm. The mean average precision (mAP) of the trained YOLO model was measured to be 98.71%, and smoke was detected at a processing speed of 9 frames per second (FPS). The second step was to estimate the spread of smoke using the coordinates of the boundary box, from which was utilized to extract the smoke geometry from YOLO. This smoke geometry was then applied to the time series prediction algorithm, long short-term memory (LSTM). As a result, smoke spread data obtained from the coordinates of the boundary box between the estimated fire occurrence and 30 s were entered into the LSTM learning model to predict smoke spread data from 31 s to 90 s in the smoke image of a fast fire obtained from fire simulation. The average square root error between the estimated spread of smoke and its predicted value was 2.74."
마이크로스코프 이미지의 딥러닝 기반 이상검출,2021,"['딥러닝', '마이크로스코프', '이상검출', '흡연', '혓바닥', 'abnormal detection', 'deep learning', 'microscope', 'tongue surface', 'smoke']","흡연자 중에서 담배가 인체에 유해하다는 사실을 모르는 사람은 없을 것임에도 불구하고, 정작 금연 성공률은 높지 않다. 금연을 위한 의지를 지속적으로 굳건하게 다지기 위하여 병원에서 실시하는 건강검진과 PET(positron emission tomography) 이미지를 통한 암 검사의 결과가 도움이 되지만, 일상생활 중에 간단히 실시할 수 있는 방법이 아니다. 본 연구에서는 일상생활 중에 관찰 가능한 흡연자의 신체 부위를 딥러닝 기반 마이크로스코프 이미지 측정 및 분석을 통하여 흡연자와 비흡연자의 차이를 검출할 수 있는 비침습적 방법을 제안하였다. 우선, 관찰 부위를 흡연시 직접적인 접촉을 하는 혓바닥 표면으로 설정하였다. 다음으로, 마이크로스코프로 혓바닥 표면(410배 확대)을 흡연자 10명과 비흡연자 10명의 실험 참가자를 통하여 데이터 셋(총 1,000장)을 구축하여 그 중 80%를 딥러닝 모델의 학습에 사용하였고, 나머지 20%는 예측에 사용하였다. 딥러닝 모델을 스케일링하는 방법(width scaling, depth scaling, resolution scaling) 중 한 가지 방법만 적용하는 VGG, ResNet, DenseNet과 세 가지를 모두 적용하여 스케일링하는 EfficientNet의 성능을 비교하여 모세혈관 이미지 처리에 EfficientNet의 우수성을 확인해 볼 수 있었다.","The success rate of the no-smoking campaign has been low, although everybody knows that cigarettes are harmful to the human health. The results of both regular health and cancer checks in the hospital are useful for strengthening the human intention for quitting the smoking, however, those methods are difficult to use in daily life because of the use of large-scaled particular devices such as PET(positron emission tomography). Thus, this study proposed a non-invasive method that detects the difference between smokers and non-smokers through deep-learning-based analysis. At first, observing parts were decided to the tongue surface. Then, a data set(total 1,000) was made through the experiment to measure the tongue surface(410 times magnification) with the participants of 10 smokers and 10 non-smokers. The 80% ratio of data set was used for the train, and the left 20% was for the prediction. As a result, it was found that the classification through EfficientNet with the compound scaling including three scaling methods of width scaling, depth scaling and resolution scaling was much better than other models including VGG, ResNet, and DenseNet with the only one scaling."
딥러닝 기반 Wi-Fi 핑거프린트 실내 측위 기법 동향 및 전망,2021,"['실내 측위', 'Wi-Fi 핑거프린트', '머신러닝', '딥러닝', 'Indoor localization', 'Wi-Fi fingerprint', 'Machine learning', 'Deep learning']","최근 5G 시대를 맞이하여 스마트 기기와 함께 사물인터넷 기술의 급속한 발전과 활용 분야의 확대에 따라, 무선 신호를 이용한 실내 측위 기법이 활발히 연구되고 있다. 다양한 실내 환경에서 높은 위치 추정 정확도와 낮은복잡성을 가지는 실내 측위 기법을 개발하는 것은 매우 어려운 일이다. 여러 실내 측위 기법 중에서 Wi-Fi 신호를 활용한 핑거프린트 기법은 별도의 장비 설치 및 인프라 구축이 필요 없이, 위치 추정이 가능하므로 최근 학계및 산업체로부터 많은 주목을 받고 있다. 최근에는 비약적으로 발전한 머신러닝 및 딥러닝 기술들이 Wi-Fi 핑거프린트 방식에도 접목되면서, 실내 측위 정확도가 대폭 향상되고 있다. 따라서 본 논문에서는 머신러닝 및 딥러닝기술을 활용한 Wi-Fi 핑거프린트 실내 측위 기법에 대한 최신 기술 동향 및 장단점에 대해 소개한다. 또한, 기술된 Wi-Fi 핑거프린트 실내 측위 기술 동향을 기반으로 새로운 연구 방향 및 이슈들에 관해 논한다.","In the recent 5G era, according to the rapid development of Internet-of-Things technologies along with smart devices and expansion of its application, the indoor localization techniques using wireless signals have been extensively studied. It is a very challenging task to develop an indoor localization technique with high location accuracy and low complexity in various indoor environments. Among many indoor localization techniques, fingerprint technique using Wi-Fi signals has been received the greatest interest from academia and industry because location estimation is possible without the need for installing separate equipment and constructing infrastructure. Recently, the accuracy of indoor localization has been largely improved as machine learning and deep learning technologies, which have been rapidly developed, have been incorporated into Wi-Fi fingerprints.Therefore, in this paper, we introduce the state-of-the-art trends and pros-and-cons of indoor localization techniques based on Wi-Fi fingerprint utilizing machine learning and deep learning technologies. Furthermore, we discuss new research directions and issues based on the described trends of indoor localization techniques for Wi-Fi fingerprint."
딥러닝 기반 차량 경로예측 모델의 전파과정 간소화를 통한 트레이드오프 성능 검증 연구,2021,"['Trajectory Prediction', 'Deep-learning', 'Trade-off', 'Dynamic Motion', 'Interdependency']","본 논문에서는 딥러닝 기반의 차량 경로예측 모델의 예측 정확도와 예측시간 사이의 Trade-off 관계에서 성능을 개선하기 위한 전파과정 간소화 방안을 제안하였다. 차량 경로예측 문제에서 딥러닝 기술을 활용하면서 점점높은 정확도의 예측이 가능해지고 있지만, 반면에 모델의 복잡도가 증가하면서 예측시간이 길어지는 Trade-off 문제를 발생시킨다. 이 문제를 해결하기 위해 기존의 딥러닝 기반 state-of-the-art 차량 경로예측 모델에 여러 가지전파과정 간소화 방안을 적용하고 실험을 통해 예측 정확도와 예측시간을 측정하였다. PC 및 임베디드 환경에서의 검증을 통하여 주변차량의 Dynamic Motion 특성을 추출하는 과정을 간소화할 경우, 예측 정확도 손실 없이예측시간을 PC 환경에서는 15.7%, 임베디드 환경에서는 2.1% 단축했다.","In this paper, a method of simplifying the propagation process to improve the performance in the trade-off relationship between prediction accuracy and prediction time of vehicle trajectory prediction model based on deep learning is proposed. In vehicle trajectory prediction tasks, it is possible to predict increasingly high accuracy by using deep learning technology, but on the other hand, a trade-off problem occurred because of the increasing the prediction time of the model according to increased complexity. To solve this problem, various simplifying methods of propagation process were applied to the existing deep learning based state-of-the-art vehicle trajectory prediction model and the prediction accuracy and prediction time were measured through the experiments. In case of simplifying from the process to extract the Dynamic Motion features of neighboring vehicles, the predicted time was reduced by 15.7% in the PC environment and 2.1% in the embedded environment without any loss of the predicted accuracy."
머신러닝과 딥러닝 기법을 이용한 부산 전략산업과 수출에 의한 고용과 소득 예측,2021,"['Strategic Industry', 'Export', 'Machine Learning', 'Deep Learning']",,
입력 변이에 따른 딥러닝 모델 취약점 연구 및 검증,2021,"['Deep learning', 'Mutation', 'Adversarial machine learning']","딥러닝 모델은 변이를 통해 훈련 데이터에서 벗어난 입력으로부터 잘못된 예측 결과를 산출할 수 있으며 이는 자율주행, 보안 분야 등에서 치명적인 사고로 이어질 수 있다. 딥러닝 모델의 신뢰성 보장을 위해서는 다양한 변이를 통해 예외적인 상황에 대한 모델의 처리 능력이 검증되어야 한다. 하지만, 기존 연구가 제한된 모델을 대상으로만 수행되었으며, 여러 입력 변이 유형에 구분을 짓지 않고 사용했다. 본 연구에서는 딥러닝 검증 데이터 세트로 널리 사용되고 있는 CIFAR10 데이터 세트를 기반으로 다양한 상용화된 모델과 추가 버전을 포함하여 총 6개의 모델에 대한 신뢰성 검증을 수행한다. 이를 위해 실생활에서 발생할 수 있는 6가지 유형의 입력 변이 알고리즘을 다양한 파라미터와 함께 데이터 세트에 개별적으로 적용하여 각각에 대한 모델의 정확도를 비교함으로써 특정 변이 유형과 관련된 모델의 취약점을 구체적으로 파악한다.","The deep learning model can produce false prediction results due to inputs that deviate from training data through variation, which leads to fatal accidents in areas such as autonomous driving and security. To ensure reliability of the model, the model""s coping ability for exceptional situations should be verified through various mutations. However, previous studies were carried out on limited scope of models and used several mutation types without separating them. Based on the CIFAR10 data set, widely used dataset for deep learning verification, this study carries out reliability verification for total of six models including various commercialized models and their additional versions. To this end, six types of input mutation algorithms that may occur in real life are applied individually with their various parameters to the dataset to compare the accuracy of the models for each of them to rigorously identify vulnerabilities of the models associated with a particular mutation type."
딥러닝과 데이터마이닝에 있어서의 데이터베이스권의 범위와 제한에 관한 고찰,2021,"['저작권', '인공지능', '딥러닝', '데이터마이닝', '공정이용', '데이터베이스', 'copyright', 'artificial intelligence', 'deep learning', 'data mining', 'fair use', 'database']","딥러닝과 데이터마이닝이 일정한 분야에서 괄목할 만한 성과를 내면서 인류에게새로운 미래를 가져 올 기술로 각광받고 있다. 그러나 딥러닝과 데이터마이닝을 위해서는 대량의 데이터를 복제하는 과정이 필수적이므로 저작권법과의 충돌을 피하기어렵다. 이에 따라 기술의 발전을 위축시키지 않도록 저작권법 상의 권리를 제한해야 한다는 논의가 활발히 진행되고 있다. 이러한 논의에서 주의할 점은, 기술 발전이라는 정책적 목표는 권리자의 보호와 이용자의 이익 사이의 균형을 전제로 하여야 한다는 것이다. 현재의 균형 상태에 대한 분석과 검증 없이 정책적 목적만을 기준으로 하여서는 균형 잡힌 해석을 도출하기 어렵고, 그때 그때의 사정에 따라 균형의 중심을 옮겨법적 혼란만 가중하게 되기 쉽다. 본고에서 주로 살펴 볼 데이터베이스는 저작물과 달리 창작성을 보호 요건으로 하지 않지만, 그 대신 소재의 배열·구성을 통해 접근·검색 가능성을 제공할 것을 요건으로 한다. 이는 저작권법의 데이터베이스 관련 규정의 해석에 있어 구심점이 되어야 하며, 이를 통하여 문언에 충실하면서도 저작물에 관한 표현-아이디어 이분법의원칙과 일관된 해석론을 도출할 수 있다. 이러한 해석에 의할 때, 저작물의 표현이 아닌 아이디어만을 차용하는 행위가 복제에 해당하지 않는 것과 마찬가지로 데이터베이스의 복제 행위(저작권법 제93조 제1항)는 그 대상이 되는 데이터베이스의 배열·구성을 일부나마 포함하고 있어야 하고, 소재의 체계적·반복적 복제 행위(동조 제2 항 단서)는 원래의 데이터베이스와 최소한 부분적으로 동등한 접근·검색 가능성을제공하여야 비로소 데이터베이스의 통상적인 이용과 충돌하거나 데이터베이스제작자의 이익을 부당하게 침해하는 것이라 평가할 수 있을 것이다. 이러한 해석론에 의하면, 딥러닝 및 데이터마이닝을 위한 데이터의 수집 행위는 애초에 데이터베이스제작자의 권리에 저촉되지 않거나, 공정이용의 법리에 의해 권리 침해를 구성하지 않는경우가 많을 것으로 보인다. 이러한 해석론을 구체화한 권리 제한 규정을 도입함으로써 불확실성을 감소시키는것은 의미 있는 일이다. 실제로 여러 국가에서 이러한 시도가 이루어지고 있으나, 유럽은 관련 유럽위원회 지침 상 회원국이 권리 제한 규정을 둘 수 있는 요건이 경직되어 있다가 최근에서야 완화되었으므로 우리나라의 상황에서 참고할 만한 입법례는아직 보이지 않는다. 일본은 그에 비하여 훨씬 발전된 권리 제한 규정을 두고 있고, 최근 우리나라의 저작권법전부개정법률안(도종환 의원 대표발의, 의안번호 2107440) 도 이에 영향을 받은 것으로 보인다. 그러나 위 법률안은 몇 가지 문제점을 안고 있어개정의 목적을 달성할 수 있는지 의문이 있다. 새로운 권리 제한 규정은 저작물에 대해서는 표현을 중심으로, 데이터베이스권에 대해서는 배열·구성과 이를 통한 접근·검색 가능성을 중심으로 보다 명확한 요건을 두어야 할 것이다","As deep learning and data mining show astonishing achievements in certain areas, they are expected to open a bright future that we never anticipated before. However, they will probably conflict with the Copyright Act as copying of massive data is inevitable to implement these new technologies. There have been voices that the rights under the Copyright Act should be restricted to avoid chilling effects on these new technologies. Such arguments seemingly overlook that the policy of technological advancement should have a firm ground on the balance between the exclusive rights and the interest of the public in using the works. Without careful study and verification of the current balance, driving technological advancement would hardly lead to a well-balanced reading of the statutes. It would more likely bring more confusion by shifting the equilibrium as the need arises. Sui generis database rights, which are the main subject of this paper, do not require creativity as copyrights to works of authorship do. Instead, databases must have an arrangement or structure that enables access and search of individual data. This characteristic of databases must be the core in understanding the statutory provisions to derive a logical and robust interpretation that is faithful to the language and consistent with the idea-expression dichotomy prevailing throughout the Copyright Act. After an analysis based on the proposition above, this paper suggests that a “reproduction of a database” under Article 93(1) of the Copyright Act must include at least a part of the arrangement or structure in the original database, as copying a work of authorship requires copying the expression in the original work. In addition, a “systematic and repetitive reproduction of individual data” should enable access and search that is at least partially equivalent to those provided by the original database to “conflict with the ordinary use of the database” or to “unfairly infringe on the interest to the database” as stipulated in Article 93(2) of the Copyright Act. According to the interpretation suggested above, collecting data for deep learning and data mining in most cases would not be subject to the database rights or exempted under the law of fair use. That said, introducing new statutory provisions that incorporate the discussion in this paper is still relevant as they would reduce ambiguities. The Database Directive (96/9/EC) has been maintaining relatively narrow requirements for restriction of rights until amended by the Digital Single Market Directive (Directive (EU) 2019/790) recently. As a result, we do not yet see any amendments in European countries noteworthy for the legal situation in South Korea. Japanese Copyright Act has more advanced provisions restricting copyrights to allow new technologies such as deep learning and data mining, which apparently influenced the bill for the amendment of the Copyright Act in South Korea. However, the bill does not seem to address the issues properly to achieve the desired outcome. The new provisions should have clearer requirements that are formed around the ‘expression’ for works of authorship and the ‘arrangement or structure’ that enables ‘access and search’ for databases."
딥러닝 기반 한국어 실시간 TTS 기술 비교,2021,"['딥러닝', 'Text-to-Speech(TTS)', '실시간', '비-자기회귀 방식', 'deep learning', 'Text-to-Speech(TTS)', 'real-time', 'non-autoregressive method']","딥러닝 기반 종단간 TTS 시스템은 텍스트에서 스펙트로그램을 생성하는 Text2Mel 과정과 스펙트로그램에서 음성신호를 합성하는 보코더 등 두 가지 과정으로 구성되어 있다. 최근 TTS 시스템에 딥러닝 기술을 적용함에 따라 합성음의 명료도와 자연성이 사람의 발성과 유사할 정도로 향상되고 있다. 그러나 기존의 방식과 비교하여 음성을 합 성하는 추론 속도가 매우 느리다는 단점을 갖고 있다. 최근 제안되고 있는 비-자기회귀 방식은 이전에 생성된 샘플에 의존하지 않고 병렬로 음성 샘플을 생성할 수 있어 음성 합성 처리 속도를 개선할 수 있다. 본 논문에서는 비-자기 회귀 방식을 적용한 Text2Mel 기술인 FastSpeech, FastSpeech 2, FastPitch와, 보코더 기술인 Parallel WaveGAN, Multi-band MelGAN, WaveGlow를 소개하고, 이를 구현하여 실시간 처리 여부를 검증한다. 실험 결과 구한 RTF로 부터 제시된 방식 모두 실시간 처리가 충분히 가능함을 알 수 있다. 그리고 WaveGlow를 제외하고 학습 모델 크기 가 수십에서 수백 MB 정도로, 메모리가 제한되어 있는 임베디드 환경에 적용 가능함을 알 수 있다.","The deep learning based end-to-end TTS system consists of Text2Mel module that generates spectrogram from text, and vocoder module that synthesizes speech signals from spectrogram. Recently, by applying deep learning technology to the TTS system the intelligibility and naturalness of the synthesized speech is as improved as human vocalization. However, it has the disadvantage that the inference speed for synthesizing speech is very slow compared to the conventional method. The inference speed can be improved by applying the non-autoregressive method which can generate speech samples in parallel independent of previously generated samples. In this paper, we introduce FastSpeech, FastSpeech 2, and FastPitch as Text2Mel technology, and Parallel WaveGAN, Multi-band MelGAN, and WaveGlow as vocoder technology applying non-autoregressive method. And we implement them to verify whether it can be processed in real time. Experimental results show that by the obtained RTF all the presented methods are sufficiently capable of real-time processing. And it can be seen that the size of the learned model is about tens to hundreds of megabytes except WaveGlow, and it can be applied to the embedded environment where the memory is limited."
딥러닝을 이용한 공압형 인공근육의 모델링 및 정밀제어에 대한 연구,2021,"['Deep Learning(딥러닝)', 'Neural Network(신경망)', 'Pneumatic Artificial Muscle(공압형 인공근육)', 'Client/Server(클라이언트/서버)']",본 연구에서는 특성데이타를 가지고 딥러닝 기법을 이용하여 수학적 모델링이 어려운 공압형 인공근육의 동특성을 정확하게 모델링하였다. 제안된 신경망 모델은 학습이 완료된 가중치로 구동력을 빠른 시간에 계산하므로 모델에 기초한 피드포오드 제어기법에 활용이 가능하다. 그리고 신경망 모델을 실시간 제어에 적용하기 위해서 딥러닝이 수행되는 파이썬 프로그램을 서버로 기계시스템의 운동제어를 수행하는 랩뷰 프로그램을 클라이언트로 사용하는 분산된 제어기법을 제시하였다. 실제 공압형 인공근육으로 구동되는 동적시스템에 제안된 제어기법을 적용하여 우수한 궤적추종성능을 보였다.,"In this study, the dynamic behaviors of pneumatic artificial muscles, which cannot be easily mathematically modeled were accurately predicted using a deep learning technique with characteristic data. As the proposed neural network model calculates the driving force with the weights of the neural network trained off-line, it can be applied to a model-based feedforward control scheme in real-time. In addition, a distributed control architecture, where a Python program for deep learning had the role of a server and a LabVIEW program for motion control had the role of a client, was implemented to a dynamic system driven by a single pneumatic artificial muscle. Experimental results showed that the proposed server/client control architecture with the deep learning model could yield a higher performance in trajectory following."
딥러닝 기반 감정인식 성능향상 방법,2021,"['감정인식', '감정인식 성능향상', '다중 감정인식', 'Emotion Recognition', 'Improve Emotion Recognition Performance', 'Multi Emotion Recognition']",인터넷의 발달과 비대면 서비스의 증가로 사용자들 간에 문자나 SNS로 소통하는 경우가 늘어나고 있다. 사용자에 의한 대량의 데이터가 발생하면서 사용자 정보나 의견을 분석하여 감정을 인식하는 연구가 활발하게 진행되고 있다. 그중에서도 텍스트 감정인식은 대부분 단어나 문장의 단일 감정을 인식하고 있다. 그러나 하나의 문장에도 여러 감 정이 복합적으로 존재하기 때문에 다중 감정인식 방법이 필요하다. 따라서 본 논문에서는 더욱 정확한 텍스트 감정 인식을 위해 데이터를 보정하는 방법과 딥러닝 기반의 다중 감정인식 방법을 적용한 감정인식 성능향상 방법을 제안 한다. 제안한 모델의 유용성을 확인하기 위해 딥러닝 모델을 비교 실험한 결과 Attention 모델을 사용했을 때 Accuracy가 76.7%로 가장 좋은 성능을 보였다.,"With the development of the Internet and the increase of non-face-to-face services, the number of users communicating through text messages or SNS is increasing. As a large amount of data is generated by users, research on recognizing emotions by analyzing user information or opinions is being actively conducted. Among them, most of the text emotion recognition recognizes a single emotion of a word or sentence. However, since multiple emotions exist complexly in a single sentence, a multi-emotion recognition method is required. Therefore, in this paper, we propose a data correction method for more accurate text emotion recognition and a method to improve emotion recognition performance by applying a deep learning-based multi-emotion recognition method. As a result of comparing deep learning models to confirm the usefulness of the proposed model, when the attention model was used, Accuracy showed the best performance with 76.7%."
딥러닝 기반의 Multi Scale Attention을 적용한 개선된 Pyramid Scene Parsing Network,2021,"['딥러닝', '멀티 스케일', '영상 처리', '의미론적 분할', 'ResNeXt', 'Deep learning', 'Image processing', 'Multi scale', 'Semantic segmentation', 'ResNeXt']","딥러닝의 발전으로 인하여 의미론적 분할 방법은 다양한 분야에서 연구되고 있다. 의료 영상 분석과 같이 정확성을 요구하는 분야에서 분할 정확도가 떨어지는 문제가 있다. 본 논문은 의미론적 분할 시 특징 손실을 최소화하기 위해 딥러닝 기반 분할 방법인 PSPNet을 개선하였다. 기존 딥러닝 기반의 분할 방법은 특징 추출 및 압축 과정에서 해상도가 낮아져 객체에 대한 특징 손실이 발생한다. 이러한 손실로 윤곽선이나 객체 내부 정보에 손실이 발생하여 객체 분류 시 정확도가 낮아지는 문제가 있다. 이러한 문제를 해결하기 위해 의미론적 분할 모델인 PSPNet을 개선하였다. 기존 PSPNet에 제안하 는 multi scale attention을 추가하여 객체의 특징 손실을 방지하였다. 기존 PPM 모듈에 attention 방법을 적용하여 특징 정제 과정을 수행하였다. 불필요한 특징 정보를 억제함으로써 윤곽선 및 질감 정보가 개선되었다. 제안하는 방법은 Cityscapes 데이터 셋으로 학습하였으며, 정량적 평가를 위해 분할 지표인 MIoU를 사용하였다. 실험을 통해 기존 PSPNet 대비 분할 정확도가 약 1.5% 향상되었다.","With the development of deep learning, semantic segmentation methods are being studied in various fields. There is a problem that segmenation accuracy drops in fields that require accuracy such as medical image analysis. In this paper, we improved PSPNet, which is a deep learning based segmentation method to minimized the loss of features during semantic segmentation. Conventional deep learning based segmentation methods result in lower resolution and loss of object features during feature extraction and compression. Due to these losses, the edge and the internal information of the object are lost, and there is a problem that the accuracy at the time of object segmentation is lowered. To solve these problems, we improved PSPNet, which is a semantic segmentation model. The multi-scale attention proposed to the conventional PSPNet was added to prevent feature loss of objects. The feature purification process was performed by applying the attention method to the conventional PPM module. By suppressing unnecessary feature information, eadg and texture information was improved. The proposed method trained on the Cityscapes dataset and use the segmentation index MIoU for quantitative evaluation. As a result of the experiment, the segmentation accuracy was improved by about 1.5% compared to the conventional PSPNet."
딥러닝 기반 가시광 통신 시스템의 성능 향상 기법,2021,"['Visible Light Communication', 'Smart Building', 'Interference Cancellation', 'Deep Learning', 'Channel Estimation']","본 논문은 스마트 빌딩을 위한 가시광 통신 시스템에서 데이터 신뢰성을 향상시키는 딥러닝 기반의 간섭 제거 알고리즘에 대해 연구하였다. 본 논문에서 제안한 기법은 딥러닝 기술을 적용하여 채널에서 발생하는 잡음을 예측하여 제거하는 기술로서 수신단에서 딥러닝에 의해 학습된 잡음들을 활용하여 효과적으로 잡음을 제거함으로써 신호의 품질을 향상시킬 수 있다. 딥러닝 기술의 잡음 예측 정확도를 향상시키기 위해 기존의 잡음 형태를 데이터베이스화하여 활용하였다. 모의실험을 통해 간섭 제거 기법이 적용된 시스템 모델의 성능을 검증하였으며, 제안하는 시스템이 잡음을 효과적으로 제거하여 신호의 품질 성능을 향상시킬 수 있음을 확인하였다. 제안한 시스템 모델은 가시광 통신뿐만 아니라 일반적인 통신 시스템에서도 신호의 품질을 향상시킬 수 있도록 다양하게 적용이 가능하다.",
2차원 변환 및 딥러닝 기반 초전형 적외선 센서를 이용한 침입감지 시스템,2021,"['딥러닝', '2차원 변환', '학습', '분류', '침입감지', 'PIR', 'Deep Learning', 'Train', 'Classification', 'Intrusion Detection']","최근 딥러닝 기술들이 많이 발달한 시대에 여러 가지 센서들을 사용하여 특정 상황에 맞게 제어할 수 있는 시스템들을 구축할 수 있게 되었다. 본 논문에서는 여러 가지 센서 중에 PIR(Pyroelectric Infrared Sensor) 센서를 사용하여 배경, 사람, 불, 동물을 감지하여 침입 등의 위험 상황을 판별하는 시스템을 고안했다. 센서로부터 입력되는 신호들은 해당 상황들에 대해 딥러닝 알고리즘을 사용하여 미리 학습한 후 판단할 수 있도록 설계하였다. 기존에 PIR 기반 침입탐지 방법들과 탐지 정확도를 비교하는 실험을 수행한 결과, 제안된 방법이 정확도 향상이 가능함을 확인하였다.","In an era where deep learning technologies have been developed a lot in recent years, various sensors can be used to build systems that can be controlled according to specific situations. In this paper, we propose a system that uses a Pyroelectric Infrastructure Sensor (PIR) to detect backgrounds, people, animal, and fire, and then recognizes risky situation such as intrusion. It is designed so that signal inputs from the sensor can be classified after learning in advance using deep learning algorithm. Experimental results show that the proposed deep learning method improves the classification accuracy in comparison to the previous methods for PIR-based intrusion detection."
딥러닝을 활용한 이미지 기반 교량 구성요소 자동분류 네트워크 개발,2021,"['BIM', 'Deep learning', 'CNN', 'Bridge component classification', '딥러닝', '교량 구성요소 분류']","우리나라의 교량은 대부분이 건설된 지 20년 이상이 지나 현재 노후화로 인하여 많은 문제점이 제기되고 있으며, 교량의 안전점검은 대부분 전문 인력의 주관적인 평가로 이루어지고 있다. 최근 교량 안전점검의 데이터의 체계적인 관리를 위해 BIM 등을 활용한 데이터 기반의 유지관리기술들이 개발되고 있지만, BIM과 구조물의 유지관리 데이터를 연동을 위해서 영상정보를 직접 라벨링하는 수작업을 필요로한다. 따라서 본 논문에서는 이미지 기반의 자동 교량 구성요소 분류 네트워크를 개발하고자 한다. 본 연구에서 제안한 방법은 두 개의 CNN 네트워크로 구성되었다. 첫 번째 네트워크에서 특정 교량 이미지에 대하여 교량의 형식을 자동으로 분류한 뒤, 두 번째 네트워크에서 교량의 형식별로 구성요소를 분류함으로써 정확도와 효율성을 향상시키고자 한다. 본 연구에서 개발한 시스템을 검증한 결과, 847개의 교량 이미지에 대해서 98.1 %의 정확도로 교량의 구성요소를 자동으로 분류 할 수 있었다. 본 연구에서 개발한 교량의 구성요소 자동분류 기술은 향후 교량의 유지관리에 기여를 할 수 있을 것으로 기대된다.","Most bridges in Korea are over 20 years old, and many problems linked to their deterioration are being reported. The current practice for bridge inspection mainly depends on expert evaluation, which can be subjective. Recent studies have introduced data-driven methods using building information modeling, which can be more efficient and objective, but these methods require manual procedures that consume time and money. To overcome this, this study developed an image-based automatic bridge component classification network to reduce the time and cost required for converting the visual information of bridges to a digital model. The proposed method comprises two convolutional neural networks. The first network estimates the type of the bridge based on the superstructure, and the second network classifies the bridge components. In avalidation test, the proposed system automatically classified the components of 461 bridge images with 96.6 % of accuracy. The proposed approach is expected to contribute toward current bridge maintenance practice."
머신러닝과 딥러닝을 이용한 저수지 유해 남조류 발생 예측,2021,"['녹조', '유해 남조류', '머신러닝', '딥러닝', '수온', '랜덤 포레스트', 'Algae', 'Cyanobacteria', 'Machine learning', 'Deep learning', 'Water temperature', 'Random forest']","녹조 현상과 관련하여 독성물질을 배출하는 남조류 4종의 경우 유해 남조류로 지정하여 관리하고 있으며, 물리적인 모형을 이용한 예측 정보도 함께 발표하고 있다. 그러나 조류는 살아 있는 생명체로 물리 역학에 따른 예측에 어려움이 있으며, 기상, 수리․수문, 수질 등 수많은 인자에 의한 영향을 고려하기가 쉽지 않다. 따라서, 최근 머신러닝을 이용한 녹조발생 예측 연구가 많이 진행되고 있다. 본 연구에서는 경북 영천에 소재한 보현산댐과 영천댐을 대상으로 랜덤 포레스트 모형을 이용하여 유해남조류 발생에 영향을 미치는 수질인자의 특성중요도를 분석해 보았으며, 이 중 가장 높은 특성중요도를 나타낸 수온을 이용하여 머신러닝과 딥러닝을 이용하여 유해남조류 발생을 예측하고 그 정확성을 확인하였다. 특성중요도 분석 결과, 수온과 총질소(T-N)이 공통적으로 높게 나왔으며, 인공신경망(ANN)을 이용한 유해남조류 발생예측에서도 실제와 근접한 값이 예측되어 앞으로 녹조관리를 위해 유해남조류 예측이 필요한 저수지의 경우 이를 활용할 수 있음을 확인하였다.","In relation to the algae bloom, four types of blue-green algae that emit toxic substances are designated and managed as harmful Cyanobacteria, and prediction information using a physical model is being also published. However, as algae are living organisms, it is difficult to predict according to physical dynamics, and not easy to consider the effects of numerous factors such as weather, hydraulic, hydrology, and water quality. Therefore, a lot of researches on algal bloom prediction using machine learning have been recently conducted. In this study, the characteristic importance of water quality factors affecting the occurrence of Cyanobacteria harmful algal blooms (CyanoHABs) were analyzed using the random forest (RF) model for Bohyeonsan Dam and Yeongcheon Dam located in Yeongcheon-si, Gyeongsangbuk-do and also predicted the occurrence of harmful blue-green algae using the machine learning and deep learning models and evaluated their accuracy. The water temperature and total nitrogen (T-N) were found to be high in common, and the occurrence prediction of CyanoHABs using artificial neural network (ANN) also predicted the actual values closely, confirming that it can be used for the reservoirs that require the prediction of harmful cyanobacteria for algal management in the future."
딥러닝을 이용한 외해 해양기상자료로부터의 항내파고 예측,2021,"['딥러닝', '머신러닝', '파랑 예측', '자료 전처리', 'deep learning', 'machine learning', 'wave prediction', 'pre-processing']","본 연구에서는 항내 파고를 신속하고 비교적 정확하게 예측할 수 있는 딥러닝 모델을 구축하였다.다양한 머신러닝 기법들을 외해파랑의 항내로 전파 변형 특성을 감안하여 모델에 적용하였으며 스웰로 인해 하역중단 문제가 심각했던 포항신항을 모델적용 대상지로 선정하였다. 모델의 입력 자료는 외해의 파고, 주기, 파향 그리고 출력 및 예측 자료로는 항내 파고자료로 하여 모델을 학습시켰다. 이때 자료의 전처리 과정으로 항내·외 파랑 시계열자료의 상관성을 감안하여 파향 자료를 분리하는 방법을 적용하고 딥러닝 기법을 이용하여 모델을 학습하였다. 결과적으로 모델을 통해 예측한 값이 항내관측치의 파고 시계열자료를 잘 재현하였으며 모델의 안정성을 크게 향상시켰다.","In this study, deep learning model was set up to predict the wave heights inside a harbour. Various machine learning techniques were applied to the model in consideration of the transformation characteristics of offshore waves while propagating into the harbour. Pohang New Port was selected for model application, which had a serious problem of unloading due to swell and has lots of available wave data. Wave height, wave period, and wave direction at offshore sites and wave heights inside the harbour were used for the model input and output, respectively, and then the model was trained using deep learning method. By considering the correlation between the time series wave data of offshore and inside the harbour, the data set was separated into prevailing wave directions as a pre-processing method. As a result, It was confirmed that accuracy and stability of the model prediction are considerably increased."
딥러닝을 이용한 음향 고유 모드와 고유 주파수 예측,2021,"['Deep Learning(딥러닝)', 'Acoustic Natural Mode(음향 고유 모드)', 'Acoustic Natural Frequency(음향 고유 주파수)', 'Convolutional Neural Network(합성곱 신경망)', 'Partition(격벽)', 'Vehicle Compartment (차실)']","본 연구에서는 형상 정보만 주어지면 해당 구조물의 음향 고유 모드와 고유 주파수를 예측할 수 있는 딥러닝 기반 음향 해석 방법을 개발하고, 차실의 음향 특성 파악에 적용하여 제시한 방법의 유효성을 입증한다. 닫힌 공간의 음향 특성은 내부에 존재하는 격벽들의 형상, 크기와 위치 등에 따라 달라진다. 음향 이론이나 음향 해석 프로그램에 대한 지식이 없더라도 후보군에 있는 형상들의 음향 특성을 알 수 있다면, 자동차와 같은 기계 구조물의 재설계 시간을 설계자가 극단적으로 단축시킬 수 있다. 이를 위해, 2차원 음향 공동 모델에 대해 이 작업을 수행할 수 있는 딥러닝 모델을 제안한다. 알맞은 입력과 출력 데이터로 딥러닝 모델을 학습시켜서 가능성을 파악한 후에, 2차원 차실 모델에 적용하여 제안한 방법의 유효성을 입증한다.","In this study, a deep learning-based acoustic analysis method is proposed to predict the acoustic natural modes and natural frequencies of a structure given only its shape information. The effectiveness of the proposed method is proved by applying it to identification of the acoustic characteristics of a vehicle. The acoustic characteristics of a closed space vary depending on the shape, size, and location of the partitions existing therein. Although a designer may possess no knowledge of acoustic theory or acoustic analysis programs, the redesigning time of a mechanical structure, such as a vehicle, can be dramatically shortened if the acoustic characteristics of the candidate shape can be identified. A deep learning model is developed to perform this task on a two-dimensional acoustic cavity. It is trained with appropriate input and output data to verify the feasibility, and subsequently applied to the two-dimensional vehicle model to demonstrate its validity."
딥러닝과 의미론적 영상분할을 이용한 자동차 번호판의 숫자 및 문자영역 검출,2021,"['딥러닝', '합성곱 신경망(CNN)', '의미론적 분할', '자동차 번호판', '영상분할 및 인식', 'Deep Learning', 'Convolution Neural Network(CNN)', 'Semantic Segmentation', 'License Plate', 'Image Segmentation and Recognition']","자동차 번호판 인식은 지능형 교통시스템에서 핵심적인 역할을 담당한다. 따라서 효율적으로 자동차 번호판의 숫자 및 문자영역을 검출하는 것은 매우 중요한 과정이다. 본 연구에서는 딥러닝과 의미론적 영상분할 알고리즘을 적용 하여 효과적으로 자동차 번호판의 번호영역을 검출하는 방법을 제안한다. 제안된 방법은 화소 투영과 같은 전처리과정 없이 번호판 영상에서 바로 숫자 및 문자영역을 검출하는 알고리즘이다. 번호판 영상은 도로 위에 설치된 고정 카메라로 부터 획득한 영상으로 날씨 및 조명변화 등을 모두 포함한 다양한 실제 상황에서 촬영된 것을 사용하였다. 입력 영상은 색상변화를 줄이기 위해 정규화하고 실험에 사용된 딥러닝 신경망 모델은 Vgg16, Vgg19, ResNet18 및 ResNet50이 다. 제안방법의 성능을 검토하기 위해 번호판 영상 500장으로 실험하였다. 학습을 위해 300장을 할당하였으며 테스트용 으로 200장을 사용하였다. 컴퓨터모의 실험결과 ResNet50을 사용할 때 가장 우수하였으며 95.77% 정확도를 얻었다.","License plate recognition plays a key role in intelligent transportation systems. Therefore, it is a very important process to efficiently detect the number and character areas. In this paper, we propose a method to effectively detect license plate number area by applying deep learning and semantic image segmentation algorithm. The proposed method is an algorithm that detects number and text areas directly from the license plate without preprocessing such as pixel projection. The license plate image was acquired from a fixed camera installed on the road, and was used in various real situations taking into account both weather and lighting changes. The input images was normalized to reduce the color change, and the deep learning neural networks used in the experiment were Vgg16, Vgg19, ResNet18, and ResNet50. To examine the performance of the proposed method, we experimented with 500 license plate images. 300 sheets were used for learning and 200 sheets were used for testing. As a result of computer simulation, it was the best when using ResNet50, and 95.77% accuracy was obtained."
딥러닝 기반의 분할과 객체탐지를 활용한 도로균열 탐지시스템 개발,2021,"['도로 균열 탐지', '균열 심각도', '객체 탐지', '균열부위 분할', '포장 관리', 'Road Crack Detection', 'Crack Severity', 'Object Detection', 'Crack Segmentation', 'Pavement Management']","최근 도로균열 탐지에 대한 많은 연구에서 딥러닝 기반의 접근법을 활용하면서 과거 알고리즘 기반의 접근법을 활용한 연구들보다 높은 성능과 성과를 보이고 있다. 그러나 딥러닝 기반의 많은 연구가 여전히 균열의 유형을 분류하는 것에 집중되어 있다. 균열 유형의 분류는 현재 수작업에 의존하고 있는 균열탐지 프로세스를 획기적으로 개선해 줄 수 있다는 점에서 상당한 기대를 받고 있다. 그러나 실제 도로의 유지보수 작업에 있어서는 균열의 유형뿐만 아니라 균열의 심각도에 관한 판단이 필수적이지만, 아직까지 도로균열 탐지와 관련된 연구들이 균열의 심각도에 대한 자동화된 산출까지 진전되지 못하고 있다. 균열의 심각도를 산출하기 위해서는 균열의 유형과 이미지 속 균열의 부위가 함께 파악되어야 한다. 본 연구에서는 균열 유형과 균열 부위의 동시적 탐지를 효과적으로 자동화하기 위해 딥러닝 기반의 객체탐지 모델인 Mobilenet-SSD를 활용하는 방법을 다루고 있다. 균열탐지의 정확도를 개선하기 위해 U-Net을 활용해 입력 이미지를 자동 분할하고, 이를 객체탐지 기법과 결합하기 위한 여러 실험을 진행하여 그 결과를 정리하였다. 결과적으로 U-Net을 활용한 이미지 의 자동 마스킹을 통해 객체탐지의 성능을 mAP 값이 0.9315가 되도록 향상시킬 수 있었다. 본 연구의 결과를 참고하여 도로포장 관리시스템의 구현에 균열탐지 기능의 자동화가 더욱 진전될 수 있다고 기대된다.","Many recent studies on deep learning-based road crack detection have shown significantly more improved performances than previous works using algorithm-based conventional approaches. However, many deep learning-based studies are still focused on classifying the types of cracks. The classification of crack types is highly anticipated in that it can improve the crack detection process, which is currently relying on manual intervention. However, it is essential to calculate the severity of the cracks as well as identifying the type of cracks in actual pavement maintenance planning, but studies related to road crack detection have not progressed enough to automated calculation of the severity of cracks. In order to calculate the severity of the crack, the type of crack and the area of the crack in the image must be identified together. This study deals with a method of using Mobilenet-SSD that is deep learning-based object detection techniques to effectively automate the simultaneous detection of crack types and crack areas. To improve the accuracy of object-detection for road cracks, several experiments were conducted to combine the U-Net for automatic segmentation of input image and object-detection model, and the results were summarized. As a result, image masking with U-Net is able to maximize object-detection performance with 0.9315 mAP value. While referring the results of this study, it is expected that the automation of the crack detection functionality on pave management system can be further enhanced."
LSTM 기반 딥러닝 기법을 이용한 섬진강 구례교 지점의 홍수위 예측,2021,"['머신러닝', '딥러닝', 'LSTM', '홍수위 예측', 'Machine Learning', 'Deep Learning', 'LSTM', 'Flood Stage Forecasting']","기후변화와 기후변동으로 인한 극한 호우의 발생으로 홍수 피해는 증가하는 추세에 있다. 특히, 인명 손실을 포함한 하천홍수 피해 저감을 위해 비구조적 방법인 홍수예경보시스템은 매우 중요하게 인식되고 있으며, 홍수예경보는 물리적 모형인 강우-유출 모형에 의한 홍수량 및 홍수위 예측을 통해 이루어져 왔다. 그러나 최근에는 기존 물리적 기반의 홍수위 예측 모형의 단점을 보완한 머신러닝 기반의 홍수위 예측 모형을 적용한 연구들이 진행되고 있으나 다양한 사례에 대한 적용 연구가 지속적으로 필요한 실정이다. 따라서 본 연구에서는 Long Short-Term Memory (LSTM) 기반의 딥러닝 기법을 적용하여 섬진강 수계 구례 지점의 하천 수위를 1, 3, 6시간 선행 예측하고, 선행 예측 시간에 따른 예측 정확도를 비교 분석하고자 한다. 또한 기존의 서포트벡터머신(SVM) 모형, 다층퍼셉트론(MLP) 모형을 적용한 결과와의 비교 분석을 통해 LSTM 모형의 적용성을 평가하고자 하였다. 평가 결과, LSTM 모형이 다른 모형 보다 우수한 예측 성능을 보이고 있음을 알 수 있었으며, 향후 홍수 예측을 위해 LSTM 모형의 적용성을 보다 심층적으로 연구할 필요가 있다.","Instances of flood damage caused by extreme storm rainfall due to climate change and variability have been showing an increasing trend. Particularly, a flood forecasting and warning system has been recognized as an important nonstructural measure for flood damage reduction, including loss of life. Flood forecasting and warning have been performed by the forecasts of flood discharge and flood stage using the physically based rainfall-runoff models. However, recently, studies involving the application of a machine learning-based flood forecasting models, which addresses the limitations of extant physically based flood stage forecasting models, have been performed. We may require various case studies to determine more accurate methods. Therefore, this study performed the real-time forecasting of the river water level or stage at the Gurye station of the Sumjin river with lead times of 1, 3, and 6 h by applying a long short-term memory (LSTM)-based deep learning model. In addition, the applicability of the LSTM model was evaluated by comparing the results with those from widely used models based on support vector machine and multilayer perceptron. Consequently, we noted that the LSTM model exhibited a relatively better forecasting performance. Therefore, the applicability of the LSTM model should be extensively studied for flood forecasting applications."
드론 및 등반 로봇을 활용한 교량의 딥러닝 기반 균열 평가,2021,"['딥러닝', '자동화 균열 평가', '구조물 건전도 모니터링', '드론', '등반 로봇', '고교각', 'Deep Learning', 'Automated Crack Evaluation', 'Structural Health Monitoring (SHM)', 'Drone', 'Climbing Robot', 'High-rise Bridge Pier']","본 연구는 드론 및 등반 로봇을 활용하여 취득한 사회기반시설물 영상에 대해 딥러닝 기반으로 균열을 평가하는 기법을 제안한다. 디지털 카메라를 부착한 드론과 등반 로봇 시스템을 구축 및 활용하여 교량의 고교각에 발생한 균열을 계측하기 위한 각 시스템의 장단점을 비교 분석하였으며, 분석한 장단점을 기반으로 각 시스템에 적합한 딥러닝 네트워크를 개발하여 균열을 자동으로 검출 및 평가하였다. 본 제안 기술은 강원도 춘천시에 있는 등선교와 강릉시에 있는 장덕교에서 각각 드론과 등반 로봇을 활용하여 실험적으로 검증하였다.","This paper presents a deep learning-based crack evaluation of civil infrastructures using drone and robot. Digital camera-embedded drone and climbing robot systems were developed for the automated crack evaluation of high-rise bridge piers. The optimal deep learning networks for the drone and climbing robot were proposed by analyzing the advantages and disadvantages of each system. The proposed techniques were experimentally validated using the drone and climbing robot systems at the Deung-Seon bridge in Chuncheon city and the Jang-Duck bridge in Gangneung city, South Korea."
신뢰성있는 딥러닝 기반 분석 모델을 참조하기 위한 딥러닝 기술 언어,2021,"['Trusted Deep Learning', 'Model Reference', 'Deep Learning Description Language', 'Traffic Situation Analysis Model', '신뢰성있는 딥러닝', '모델 참조', '딥러닝 기술 언어', '교통상황 분석 모델']",,"With the recent advancements of deep learning, companies such as smart home, healthcare, and intelligent transportation systems are utilizing its functionality to provide high-quality services for vehicle detection, emergency situation detection, and controlling energy consumption. To provide reliable services in such sensitive systems, deep learning models are required to have high accuracy. In order to develop a deep learning model for analyzing previously mentioned services, developers should utilize the state of the art deep learning models that have already been verified for higher accuracy. The developers can verify the accuracy of the referenced model by validating the model on the dataset. For this validation, the developer needs structural information to document and apply deep learning models, including metadata such as learning dataset, network architecture, and development environments. In this paper, we propose a description language that represents the network architecture of the deep learning model along with its metadata that are necessary to develop a deep learning model. Through the proposed description language, developers can easily verify the accuracy of the referenced deep learning model. Our experiments demonstrate the application scenario of a deep learning description document that focuses on the license plate recognition for the detection of illegally parked vehicles."
영상처리와 딥러닝 네트워크를 결합한 자동차 번호판 인식시스템,2021,"['자동차 번호판 인식', '딥러닝', '영상처리 결합', '임베디드', '경량화', 'License plate recognition', 'Deep learning', 'Image processing combination', 'Embedded', 'Lightening']","자동차 번호판인식 시스템은 기존에는 영상처리만을 이용한 방식으로 매우 빠른 실시간 처리가 가능하나 다양한 번호판에는 적용하기 어렵다는 한계가 있었고, 딥러닝을 이용하는 경우 다양성과 정확성이 좋아지나 고성능의 그래픽카드가 필요하고 처리하는 데 시간이 매우 오래 걸리는 문제점이 있었다. 본 논문은 각 방식의 장점을 살려 그래픽카드가 없는 일반 사무용 PC에서도 실시간 처리가 가능하며 높은 정확성을 가진 자동차 번호판인식 시스템을 제안하며 더 나아가 사무용 PC가 아닌 임베디드 환경에서도 사용할 수 있도록 경량화한 시스템을 제안한다. 제안하는 시스템은 기존의 번호판인식 시스템과 동일하게 [번호판검출]-[문자영역 분할]-[문자인식]의 3단계 과정을 거치며 각 과정에는 딥러닝 모델로서는 SSD-MobileNet, ResNet 네트워크를 사용하였고, 영상처리 기법으로는 Edge를 검출한 후 수직, 수평으로 전파하면서 관심 영역을 찾는 CLNF 알고리즘을 사용하였다. 제안하는 시스템으로 지하주차장 및 톨게이트 등의 장소에서 얻은 4,389장의 이미지로 테스트하였을 때 충분히 레이어가 깊은 경우 98.2% 정확성을 보여 주었고, 레이어가 얕아질수록 영상처리 결합 여부에 따른 정확성 차이가 커짐을 확인할 수 있었다.","In the previous vehicle license plate recognition(LPR) systems, image processing method is able to process very fast in real time, but there is a limitation that it is difficult to apply to various license plates. Deep learning enables the variety and accuracy of LPR to be good, but ir reauires high-performance graphic cards and very long time processing time. In order to get around the advantages and disadvantages of both approaches, this paper proposes a light-weight vehicle license plate recognition system that can be processed in real time even using an embedded board or a general office PC without graphic cards. The proposed system consists of the three steps [license plate detection]-[character segmentation]-[character recognition] in the same with the conventional license plate recognition system. For each step, SSD-MobileNet and ResNet networks were used as deep learning models. As an image processing technique, the CLNF algorithm was used to detect an edge and to propagate vertically and horizontally for finding an ROI(region of interest). In the experiments for testing of the proposed system using 4,389 images obtained at places such as underground parking lots and toll gates, the accuracy was 98.2%. As the layer became shallower, the accuracy difference according to the image processing combination was bigger."
영상장비와 딥러닝을 이용한 고속도로 터널 균열 탐지 시스템 개발,2021,"['Tunnel crack detection', 'Deep learning', 'Cascade mask R-CNN', 'Negative sample training', '터널 균열 탐지', '딥러닝', 'Cascade Mask R-CNN', '비균열 학습']","빠르게 증가하는 노후 터널을 효율적으로 관리하기 위하여 최근 영상장비를 이용한 점검 방법론들이 많이 제안되고 있다. 하지만 기존의 방법론들은 대부분 국한된 영역에서 검증을 수행하였을 뿐 아니라, 다른 물체들이 존재하지 않는 깨끗한 콘크리트 표면에서 검증되어 실제 현장에 대한 적용성을 검증하기 어려웠다. 따라서 본 논문에서는 이러한 한계를 극복하기 위하여 비균열 물체 학습에 기반한 6단계 터널 균열 탐지 딥러닝 모델 개발 프레임워크를 제안한다. 제안된 프레임워크는 터널에서 취득된 이미지 내 균열 탐색, 픽셀 단위 균열 라벨링, 딥러닝 모델 학습, 비균열 물체 수집, 비균열 물체 재학습, 최종 학습 데이터 구축의 총 6단계로 이루어진다. 제안된 프레임워크를 이용하여 개발된 균열 탐지 딥러닝 모델 개발을 수행하였으며, 일반 균열 1561장, 비균열 206장으로 개별 물체 세분화(Instance Segmentation) 모델인 Cascade Mask R-CNN을 학습시켰다. 학습된 모델의 현장 적용성을 검토하기 위하여 전선, 전등 등을 포함하는 약 200m 길이의 실제 터널에서 균열 탐지를 수행하였다. 실험 결과 학습된 모델은 99% 정밀도와 92%의 재현율을 나타내며 뛰어난 현장 적용성을 나타내었다.","In order to efficiently inspect rapidly increasing old tunnels in many well-developed countries, many inspection methodologies have been proposed using imaging equipment and image processing. However, most of the existing methodologies evaluated their performance on a clean concrete surface with a limited area where other objects do not exist. Therefore, this paper proposes a 6-step framework for tunnel crack detection deep learning model development. The proposed method is mainly based on negative sample (non-crack object) training and Cascade Mask R-CNN. The proposed framework consists of six steps: searching for cracks in images captured from real tunnels, labeling cracks in pixel level, training a deep learning model, collecting non-crack objects, retraining the deep learning model with the collected non-crack objects, and constructing final training dataset. To implement the proposed framework, Cascade Mask R-CNN, an instance segmentation model, was trained with 1561 general crack images and 206 non-crack images. In order to examine the applicability of the trained model to the real-world tunnel crack detection, field testing is conducted on tunnel spans with a length of about 200m where electric wires and lights are prevalent. In the experimental result, the trained model showed 99% precision and 92% recall, which shows the excellent field applicability of the proposed framework."
잠재적 오분류 데이터를 고려한 이미지 분류 딥러닝 모델의 정확도 평가 방법,2021,"['잠재적 오분류 데이터', '강건 정확도', '경계 비용', '이미지 분류 딥러닝 모델', 'potentially misclassified data', 'robust accuracy', 'boundary cost', 'image classification deep learning model']","이미지 분류 딥러닝 모델은 이미지가 변형되었을 때 이미지의 유형을 잘못 분류하는 문제가 발생한다. 기존 정확도 평가 방법은 이미지가 변형되어 잠재적으로 잘못 분류될 수 있는 이미지들을 고려하지 않아 이미지의 유형을 정확하게 분류했다고 하더라도 평가 결과를 신뢰하기 어렵다. 본 연구는 잠재적으로 잘못 분류될 수 있는 데이터를 고려한 이미지 분류 딥러닝 모델의 정확도 평가 방법을 제안하였다. 모델과 데이터 셋 별로 잠재적 오분류 데이터를 식별하기 위한 경계 비용을 측정하고, 경계 비용을 바탕으로 잠재적 오분류 데이터를 식별하였다. 그리고 잠재적 오분류 데이터를 고려한 정확도를 측정하였다. 잠재적 오분류 데이터 식별 결과, 0.1～4.2%의 데이터가 잠재적 오분류 데이터로 식별되었으며, 이 중 18 ～60%가 실제로 잘못 분류되었다. 정확도 평가 결과, 정확도가 높은 모델은 이미지 변형에 대해 강건하며, 정확도가 낮은 모델일수록 이미지 변형에 대해 강건하지 못한 것으로 판단되었다.","Image classification deep learning models have a problem of misclassifying the type of image when the image is modified. As the existing accuracy evaluation methods do not take into account images that can potentially be misclassified due to modification of the image, it becomes to trust the evaluation result even if the type of image is accurately classified. In this study, we have proposed a method for evaluating the accuracy of image classification deep learning models considering the potentially misclassified data. We have measured the boundary cost to identify potentially misclassified data for each model and data set and identified potentially misclassified data based on the boundary cost. Also, we have measured the accuracy considering the potentially misclassified data.As a result of identifying potentially misclassified data, 0.1～4.2% of the data were identified as potentially misclassified data, of which approximately 18～60% were actually misclassified. As a result of the accuracy evaluation, it was estimated that the higher-accuracy model was more robust to image modification, and the lower-accuracy model was less robust to image modification."
영상 처리와 딥러닝을 이용한 악보 코드 변환 프로그램,2021,"['Music Score', 'Chord Conversion', 'MIDI', 'OpenCV', 'Deep Learning']","본 논문은 사용자가 입력한 PDF 악보를 사용자가 원하는 조(chord)의 MIDI 파일로 제공하는 앱의 개발을 다룬 다. 이 앱은 사용자가 PDF 악보 파일과 바꾸고자 하는 조를 입력하면 조 변환을 위해 PDF 파일을 PNG 파일로 변환한 다. 이를 영상 처리 알고리즘을 통해 악보의 음계를 인식하여 구분하고, 딥러닝을 통해 악보 음표의 박자를 인식하여 구분한다. 이를 통해 사용자가 원하는 조와 기존 악보의 MIDI 파일을 제공한다. 개발한 영상 처리 알고리즘과 딥러닝은 2, 4, 8, 16분 음표, 2, 4, 8, 16분 쉼표, 잇단 음표, 화음 음표가 인식 가능하다. 실험결과 악보의 음표 인식률 100%, 딥러닝 모델을 통한 박자 인식률은 90% 이상인 것을 확인하였다.","This paper deals with the development of an application that converts the PDF music score entered by the user into a MIDI file of the chord the user wants. This application converts the PDF file into a PNG file for chord conversion when the user enters the PDF music score file and the chord which the user wants to change. After recognizing the melody of sheet music through image processing algorithm and recognizing the tempo of sheet music notes through deep learning, then the MIDI file of chord for existing sheet music is produced. The OpenCV algorithm and deep learning can recognize minim note, quarter note, eighth note, semi-quaver note, half rest, eighth rest, quarter rest, semi-quaver rest, successive notes and chord notes. The experiment shows that the note recognition rate of the music score was 100% and the tempo recognition rate was 90% or more."
펄스 와전류 시계열 데이터 딥러닝을 통한 배관 두께 추정,2021,"['와전류', '데이터처리', '딥러닝', '감육배관', '두께측정', 'Eddy current', 'Data processing', 'Deep learning', 'Thinned pipe', 'Thickness measurement']","와전류 탐상법은 전도성이 있는 검사체에 대한 비파괴평가에 효과적이지만, 신호를 판독함에 있어 검사자의 높은 숙련도를 요구한다. 본 연구는 펄스 와전류 탐상으로 획득한 시계열 데이터 기반 딥러닝을 통해 배관 두께를 추정함으로써 검사자의 의존성이 보완될 수 있음을 확인하였다. 이를 위해, 9단계의 배관 두께에 대해 각 배관 두께별로 8개 동경 지점에서 10회씩 측정하여 총 720개 데이터를 수집하였다. 이를 9:1 비율로 분리해 각각 학습과 평가에 사용하였다. 심층신경망은 2차원 이미지 데이터 분류에 활용되는 인셉션 모델을 1차원 시계열 데이터를 입력 받아 연산하도록 구성했다. 평균 절대 오차를 평가지표로 삼았고, 샘플링 길이와 이동 평균 적용 여부, 학습 시의 배치 크기에 따른 평균 절대 오차를 비교했다. 이로부터 시계열 데이터 기반 딥러닝을 통해 펄스 와전류 신호로부터 배관 두께를 추정할 수 있음을 확인했다.","Eddy current testing is effective in the nondestructive evaluation of conductive specimens; however, high proficiency of an inspector is required in signal interpretation. This study confirmed that the dependence of the inspector can be complemented by estimating the pipe thickness via deep learning based on time series data acquired by pulse eddy current detection. In this study, a total of 720 data were collected by measuring ten times at eight longitude points for each of nine pipe thicknesses. They were separated by a 9:1 ratio and used for learning and evaluation, respectively. A deep neural network was built by modifying the Inception model used for classifying two-dimensional image data to input and operate one-dimensional time series data. Mean absolute error (MAE) was used as an evaluation index, and MAE values were compared according to the sampling length, moving averaging, and batch size in deep learning. Consequently, it was confirmed that the pipe thickness could be estimated from the pulsed eddy current signal by deep learning based on time series data."
무인항공기를 이용한 딥러닝 기반의 소나무재선충병 감염목 탐지,2021,"['UAV', 'Pine wilt disease', 'YOLOv2', 'SegNet', 'Deep learning', '무인항공기', '소나무재선충병', '이미지 분할방법', '이미지 검출방법', '딥러닝']","1988년 부산에서 처음 발병된 소나무재선충병(Pine Wilt Disease, PWD)은 우리나라 소나무에 막대한 피해를 주고 있는 심각한 질병이다. 정부에서는 2005년 소나무재선충병 방제특별법을 제정하고 피해지역의 소나무 이동 금지와 방제를 시행하고 있다. 하지만, 기존의 예찰 및 방제 방법은 산악지형에서 동시다발적이고 급진적으로 발생하는 소나무재선충병을 줄이기에는 물리적, 경제적 어려움이 있다. 따라서 본 연구에서는 소나무재선충병 감염의심목을 효율적으로 탐지하기 위해 무인항공기를 이용한 영상자료를 바탕으로 딥러닝 객체인식 예찰 방법의 활용가능성을 제시하고자 한다. 소나무재선충병 피해목을 관측하기 위해서 항공촬영을 통해 영상 데이터를 획득하고 정사영상을 제작하였다. 그 결과 198개의 피해목이 확인되었으며, 이를 검증하기 위해서 접근이 불가한 급경사지나 절벽과 같은 곳을 제외하고 현장 조사를 진행하여 84개의 피해목을 확인할 수 있었다. 검증된 데이터를 가지고 분할방법인 SegNet과 검출방법인 YOLOv2를 이용하여 분석한 결과 성능은 각각 0.57, 0.77로 나타났다.","Pine wilt disease first appeared in Busan in 1998; it is a serious disease that causes enormous damage to pine trees. The Korean government enacted a special law on the control of pine wilt disease in 2005, which controls and prohibits the movement of pine trees in affected areas. However, existing forecasting and control methods have physical and economic challenges in reducing pine wilt disease that occurs simultaneously and radically in mountainous terrain. In this study, the authors present the use of a deep learning object recognition and prediction method based on visual materials using an unmanned aerial vehicle (UAV) to effectively detect trees suspected of being infected with pine wilt disease. In order to observe pine wilt disease, an orthomosaic was produced using image data acquired through aerial shots. As a result, 198 damaged trees were identified, while 84 damaged trees were identified in field surveys that excluded areas with inaccessible steep slopes and cliffs. Analysis using image segmentation (SegNet) and image detection (YOLOv2) obtained a performance value of 0.57 and 0.77, respectively."
교량 손상 관리를 위한 딥러닝 기반의 교량이미지 전처리 및 손상객체 자동검출 모델,2021,"['Deep learning', 'old bridge management', 'image analysis', 'image processing', 'super-resolution', '딥러닝', '노후 교량 관리', '이미지 분석', '이미지 처리', '화질 개선']","교량에서 표면 결함은 가능한 구조적 열화 또는 손상의 가장 관찰 가능한 지표이다. 그러나 대부분 인력에 의한 수동적인 검사로 지표를 생성하고 있는데 이는 구조 요소의 내부 상태는 시각적 기술에만 의존하여 평가될 수 없다는 점과 수동적인 촬영, 직관에 의한 판단만이 평가 요소인 점이 문제점으로 지적된다. 본 논문에서는 교량 손상 점검의 자동화를 위해 딥러닝 기반의 이미지 전처리 및 교량 손상 객체 자동화 기술을 제안한다. 이기종의 촬영기기로 촬영된 교량 이미지의 전처리를 위해 딥러닝 기반의 SR(Super-Resolution)을 이용하여 up/down-sampling을 통해 탐지모델에 가장 적합한 형태의 이미지로 정규화를 하는 기술을 제안하였다. 처리된 이미지는 레이블러를 통해 레이블링 되고, 구축된 이미지넷이 탐지모델의 학습에 사용되어 현장에 최적화된 교량 손상 객체 탐지 모델을 구축할 수 있다. 또한 기존의 교량 손상 탐지 모델들과 성능적으로 유사하거나 우수한 성능을 나타내었으며, 전문현장 데이터를 사용하였기 때문에 모델의 신뢰성을 확보할 수 있었다. 실험을 통해 교량 손상 객체 중 백태에 대한 탐지 성능을 측정하였으며, 전처리된 이미지넷을 활용한 경우 성능이 개선되는 것을 확인할 수 있었다.","Surface defects in bridges are the most observable indicators of possible structural degradation or damage. However, most of them generate indicators through passive inspections by manpower. This method is pointed out as a problem that the internal state of the structural element cannot be evaluated solely on visual technology, and that only passive photographing and intuition judgment are evaluation elements. In this paper, deep learning-based image preprocessing and bridge damage object automation technology are proposed for automation of bridge damage inspection. For preprocessing of bridge images photographed with heterogeneous photographing devices, a technology for normalizing into images of the most suitable form for detection models through up/down-sampling using deep learning-based SR (Super-Resolution) was proposed. The processed image is labeled through the labeler, and the constructed image net is used for learning the detection model to build a bridge damage object detection model optimized for the field. In addition, it showed similar or excellent performance to the existing bridge damage detection models, and because professional field data were used, the reliability of the model could be secured. Through the experiment, it was confirmed that the detection performance of white pollack among bridge damaged objects was measured, and the performance was improved when the preprocessed image net was used."
차량탑승인원 탐지를 위한 딥러닝 영상처리 기술 연구,2021,"['Object detection', 'HOV(High-occupancy vehicle) lane', 'Deep learning', 'Vehicle occupant detection', '객체 인식', '다인승 전용차로', '딥러닝', '차량탑승인원 탐지']",세계 자동차 기술의 발전과 시장 규모의 확대로 차량 수요가 증가하고 있으며 이로 인해 차량탑승 인원은 감소하고 도로의 차량 수는 증가하는 추세이다. 이는 교통체증의 원인이 되며 이러한 문제를 해결하기 위해 다인승 전용차로 제도를 시행하고 있으나 불법 이용 차량은 계속 증가하고 있다. 이러한 불법 행위를 단속하기 위한 다양한 기술이 연구되고 있다. 기존에 개발된 시스템은 트리거 장비를 이용하여 차량을 인식하고 적외선 카메라를 통해 차량을 촬영하여 차량 탑승 인원을 감지한다. 본 논문에서는 기존 시스템 적용된 트리거 장비를 이용하지 않고 딥러닝 모델 기술을 적용한 차량탑승 인원탐지 시스템을 제안한다. 제안된 기술은 영상 내에 트리거를 설정하여 차량을 탐지하고 딥러닝 객체 인식모델을 적용하여 실시간 탑승 인원을 감지하는 시스템을 제안한다.,"With the development of global automotive technology and the expansion of market size, demand for vehicles is increasing, which is leading to a decrease in the number of passengers on the road and an increase in the number of vehicles on the road. This causes traffic jams, and in order to solve these problems, the number of illegal vehicles continues to increase. Various technologies are being studied to crack down on these illegal activities. Previously developed systems use trigger equipment to recognize vehicles and photograph vehicles using infrared cameras to detect the number of passengers on board. In this paper, we propose a vehicle occupant detection system with deep learning model techniques without exploiting existing system-applied trigger equipment. The proposed technique proposes a system to detect vehicles by establishing triggers within images and to apply deep learning object recognition models to detect real-time boarding personnel."
DNN 및 LSTM 기반 딥러닝 모형을 활용한 태화강 유역의 수위 예측,2021,"['Deep learning', 'Deep neural network', 'Long short-term memory', 'Water level prediction', '딥러닝', 'DNN', 'LSTM', '수위 예측']","최근 이상 기후로 인해 극한 호우 및 국지성 호우의 규모 및 빈도가 증가하여 하천 주변의 홍수 피해가 증가하고 있다. 이에 따라 하천 또는 유역 내 수문학적 시스템의 비선형성이 증가하고 있으며, 기존의 물리적 기반의 수문 모형을 활용하여 홍수위를 예측하기에는 선행시간이 부족한 한계점이 존재한다. 본 연구에서는 Deep Neural Network (DNN) 및 Long Short-Term Memory (LSTM)기반의 딥러닝 기법을 적용하여 울산시(태화교) 지점의 수위를 0, 1, 2, 3, 6, 12시간에 대해 선행 예측을 수행하였고 예측 정확도를 비교 분석하였다. 그 결과 sliding window 개념을 적용한 DNN 모형이 선행시간 12시간까지 상관계수 0.97, RMSE 0.82 m로 가장 높은 정확도를 보이고 있음을 확인하였다. 향후 DNN 모형을 활용하여 딥러닝 기반의 수위 예측을 수행한다면 기존의 물리적 모형을 통한 홍수위 예측보다 향상된 예측 정확도와 충분한 선행시간을 확보할 수 있을 것으로 판단된다.","Recently, the magnitude and frequency of extreme heavy rains and localized heavy rains have increased due to abnormal climate, which caused increased flood damage in river basin. As a result, the nonlinearity of the hydrological system of rivers or basins is increasing, and there is a limitation in that the lead time is insufficient to predict the water level using the existing physical-based hydrological model. This study predicted the water level at Ulsan (Taehwagyo) with a lead time of 0, 1, 2, 3, 6, 12 hours by applying deep learning techniques based on Deep Neural Network (DNN) and Long Short-Term Memory (LSTM) and evaluated the prediction accuracy. As a result, DNN model using the sliding window concept showed the highest accuracy with a correlation coefficient of 0.97 and RMSE of 0.82 m. If deep learning-based water level prediction using a DNN model is performed in the future, high prediction accuracy and sufficient lead time can be secured than water level prediction using existing physical-based hydrological models."
보안 환경에서 병렬학습된 딥러닝 모형의 통합에 관한 연구,2021,"['Security', 'Distributed Learning', 'Data Parallel', 'Deep Learning', '보안', '데이터병렬화', '분산학습', '딥러닝']","최근 인공지능 분야에서 가장 많이 사용하는 딥러닝은 그 구조가 점차 크고 복잡해지고 있다. 딥러닝 모델이 커질수록 이를 학습시키기 위해서는 대용량의 데이터가 필요하지만 데이터가 여러 소유 주체별로 분산되어 있고 보안 문제로 인해 이를 통합하여 학습시키기 어려운 경우가 발생한다. 우리는 동일한 딥러닝 모형이 필요하지만 보안 문제로 인해 데이터가 여러곳에 분산되어 처리될 수 밖에 없는 상황에서 데이터를 소유하고 있는 주체별로 분산 학습을 수행한 후 이를 통합하는 방법을 연구하였다. 이를 위해 보안 상황을 V-환경과 H-환경으로 가정하여 소유 주체별로 분산학습을 수행했으며 Average, Max, AbsMax를 사용하여 분산학습된 결과를 통합하였다. mnist-fashion 데이터에 이를 적용해 본 결과 V-환경에서는 정확도 면에서 데이터를 통합시켜 학습한 결과와 큰 차이가 없음을 확인할 수 있었으며, H-환경에서는 차이는 존재하지만 의미있는 결과를 얻을 수 있었다.","Recently, deep learning, which is the most used in the field of artificial intelligence, has a structure that is gradually becoming larger and more complex. As the deep learning model grows, a large amount of data is required to learn it, but there are cases in which it is difficult to integrate and learn the data because the data is distributed among several owners and security issues. In that situation we conducted parallel learning for each users that own data and then studied how to integrate it. For this, distributed learning was performed for each owner assuming the security situation as V-environment and H-environment, and the results of distributed learning were integrated using Average, Max, and AbsMax. As a result of applying this to the mnist-fashion data, it was confirmed that there was no significant difference from the results obtained by integrating the data in the V-environment in terms of accuracy. In the H-environment, although there was a difference, meaningful results were obtained."
시간 연속성을 고려한 딥러닝 기반 레이더 강우예측,2021,"['레이더', '강우예측', '합성곱 신경망', '장단기메모리', '딥러닝', 'Radar', 'Rainfall prediction', 'Convolutional neural network', 'Long short-term memory', 'Deep learning']","본 연구에서는 시계열 순서의 의미가 희석될 수 있는 기존의 U-net 기반 딥러닝 강우예측 모델의 성능을 개선하고자 하였다. 이를 위해서 데이터의 연속성을 고려한 ConvLSTM2D U-Net 신경망 구조를 갖는 모델을 적용하고, RainNet 모델 및 외삽 기반의 이류모델을 이용하여 예측정확도 개선 정도를 평가하였다. 또한 신경망 기반 모델 학습과정에서의 불확실성을 개선하기 위해 단일 모델뿐만 아니라 10개의 앙상블 모델로 학습을 수행하였다. 학습된 신경망 강우예측모델은 현재를 기준으로 과거 30분 전까지의 연속된 4개의 자료를 이용하여 10분 선행 예측자료를 생성하는데 최적화되었다. 최적화된 딥러닝 강우예측모델을 이용하여 강우예측을 수행한 결과, ConvLSTM2D U-Net을 사용하였을 때 예측 오차의 크기가 가장 작고, 강우 이동 위치를 상대적으로 정확히 구현하였다. 특히, 앙상블 ConvLSTM2D U-Net이 타 예측모델에 비해 높은 CSI와 낮은 MAE를 보이며, 상대적으로 정확하게 강우를 예측하였으며, 좁은 오차범위로 안정적인 예측성능을 보여주었다. 다만, 특정 지점만을 대상으로 한 예측성능은 전체 강우 영역에 대한 예측성능에 비해 낮게 나타나, 상세한 영역의 강우예측에 대한 딥러닝 강우예측모델의 한계도 확인하였다. 본 연구를 통해 시간의 변화를 고려하기 위한 ConvLSTM2D U-Net 신경망 구조가 예측정확도를 높일 수 있었으나, 여전히 강한 강우영역이나 상세한 강우예측에는 공간평활로 인한 합성곱 신경망 모델의 한계가 있음을 확인하였다.","In this study, we tried to improve the performance of the existing U-net-based deep learning rainfall prediction model, which can weaken the meaning of time series order. For this, ConvLSTM2D U-Net structure model considering temporal consistency of data was applied, and we evaluated accuracy of the ConvLSTM2D U-Net model using a RainNet model and an extrapolation-based advection model. In addition, we tried to improve the uncertainty in the model training process by performing learning not only with a single model but also with 10 ensemble models. The trained neural network rainfall prediction model was optimized to generate 10-minute advance prediction data using four consecutive data of the past 30 minutes from the present. The results of deep learning rainfall prediction models are difficult to identify schematically distinct differences, but with ConvLSTM2D U-Net, the magnitude of the prediction error is the smallest and the location of rainfall is relatively accurate. In particular, the ensemble ConvLSTM2D U-Net showed high CSI, low MAE, and a narrow error range, and predicted rainfall more accurately and stable prediction performance than other models. However, the prediction performance for a specific point was very low compared to the prediction performance for the entire area, and the deep learning rainfall prediction model also had limitations. Through this study, it was confirmed that the ConvLSTM2D U-Net neural network structure to account for the change of time could increase the prediction accuracy, but there is still a limitation of the convolution deep neural network model due to spatial smoothing in the strong rainfall region or detailed rainfall prediction."
최적화된 차량 탑승인원 감지시스템 개발을 위한 딥러닝 모델 분석,2021,[],"현재 국내외 여러 국가에서 한 가정의 차량의 수요가 증가하여 차량의 탑승 인원은 적어지고 도로의 차량 수는 증가하고 있는 추세이다. 이에 따른 문제점인 교통 체증을 해결하기 위해 이용 가능한 다인승 전용차로 제도가 시행되고 있다. 이 제도는 경찰들이 빠르게 움직이는 차량을 직접 눈으로 감시하여 불법 차량을 단속하는 실정이며, 이는 정확성이 낮고 사고의 위험성을 동반된다. 이러한 문제점을 해결하기 위해 도로 현장의 영상을 이용한 딥러닝 객체 인식 기술을 적용한다면 앞서 말한 문제점들이 해결될 것이다. 따라서, 본 논문에서는 기존의 딥러닝 모델의 성능을 비교·분석하여, 영상을 통해 실시간 차량 탑승 인원을 파악할 수 있는 딥러닝 모델을 선정하고 객체 인식 모델의 문제점을 보완한 차량 탑승 인원 감지 알고리즘을 제안한다.",
오픈소스 기반 지도 서비스를 이용한 딥러닝 실시간 가상 전력수요예측 가시화 웹 시스템,2021,"['Power demand monitoring', 'Power demand prediction', 'Deep learning', 'Location information', 'Data visualization', '전력수요모니터링', '전력수요예측', '딥러닝', '위치정보', '데이터 가시화']",최근 웹에서 지도(Map)를 이용한 Location based Services 기반의 다양한 위치정보시스템 활용이 점점 확대되고 있으며 에너지 절약을 위한 대안으로 전력 수요 현황을 실시간으로 확인할 수 있는 모니터링 시스템의 필요성이 요구되고 있다. 본 연구에서는 딥러닝과 같은 기계학습을 이용하여 전력 수요 데이터의 특성을 분석하고 예측하는 모듈을 개발하여 지역 단위별 전력 에너지 사용 현황과 예측 추세를 실시간으로 확인할 수 있는 오픈소스 기반 지도 서비스를 이용한 딥러닝 실시간 가상 전력수요예측 웹 시스템을 개발하였다. 특히 제안한 시스템은 LSTM 딥러닝 모델을 이용하여 지역적으로 전력 수요량과 예측 분석이 실시간으로 가능하고 분석된 정보를 가시화하여 제공한다. 향후 제안된 시스템을 통해 지역별 에너지의 수급 및 예측 현황을 확인하고 분석하는데 활용될 수 있을 뿐만 아니라 다른 산업 에너지에도 적용될 수 있을 것이다.,"Recently, the use of various location-based services-based location information systems using maps on the web has been expanding, and there is a need for a monitoring system that can check power demand in real time as an alternative to energy saving. In this study, we developed a deep learning real-time virtual power demand prediction web system using open source-based mapping service to analyze and predict the characteristics of power demand data using deep learning. In particular, the proposed system uses the LSTM(Long Short-Term Memory) deep learning model to enable power demand and predictive analysis locally, and provides visualization of analyzed information. Future proposed systems will not only be utilized to identify and analyze the supply and demand and forecast status of energy by region, but also apply to other industrial energies."
함포 사격 정확도 향상을 위한 딥러닝 기반 사격제원 계산 모델 설계,2021,"['Deep learning', 'Ballistic calculation', 'IMM Kalman filter', 'Reinforcement learning', 'Impact point correction', '딥러닝', '사격제원 계산', 'IMM 칼만 필터', '강화 학습', '탄착 수정']","본 논문에서는 함포 사격 정확도를 향상시키기 위해 표적 위치 예측과 사격 오차 도출에서의 딥러닝 알고리즘 적용 가능성을 연구하였다. 표적 위치 예측 시 딥러닝 알고리즘의 하나인 LSTM 모델과 RN 구조를 적용했을 때 좀 더 정밀한 표적 위치를 예측할 수 있다는 가능성을 확인하고 모델을 설계하였다. 사격 오차 도출 시 사격제원 계산에 영향을 끼치는 요소들을 데이터 셋으로 관리하며, GAN을 사용하여 데이터 셋을 생성 후 강화 학습을 진행하여 사격 오차를 줄일 수 있는 모델을 설계하였다. 2가지 모델을 결합하여 사격 정확도를 향상시키기 위한 딥러닝 기반의 사격제원 계산 모델을 설계하였다.","This paper shows the applicability of deep learning algorithm in predicting target position and getting correction value of impact point in order to improve the accuracy of naval gun firing. Predicting target position, the proposed model using LSTM model and RN structure is expected to be more accurate than existing method using kalman filter. Getting correction value of impact point, the another proposed model suggests a reinforcement model that manages factors which is related in ballistic calculation as data set, and learns using the data set. The model is expected to reduce error of naval gun firing. Combining two models, a ballistic calculation model for improving accuracy of naval gun firing based on deep learning algorithm was designed."
공연예술에서 광고포스터의 이미지 특성을 활용한 딥러닝 기반 관객예측,2021,"['공연예술', '흥행 예측', 'CNN', 'VGG-16', 'Inception-v3', 'ResNet50', 'Performing Arts', 'Box Office Prediction']","공연예술 기관에서의 공연에 대한 흥행 예측은 공연예술 산업 및 기관에서 매우 흥미롭고도 중요한 문제이다. 이를 위해 출연진, 공연장소, 가격 등 정형화된 데이터를 활용한 전통적인 예측방법론, 데이터마이닝 방법론이 제시되어 왔다. 그런데 관객들은 공연안내 포스터에 의하여 관람 의도가 소구되는 경향이 있음에도 불구하고, 포스터 이미지 분석을 통한 흥행 예측은 거의 시도되지 않았다. 그러나 최근 이미지를 통해 판별하는 CNN 계열의 딥러닝 방법이 개발되면서 포스터 분석의 가능성이 열렸다. 이에 본 연구의 목적은 공연 관련 포스터 이미지를 통해 흥행을 예측할 수 있는 딥러닝 방법을 제안하는 것이다. 이를 위해 KOPIS 공연예술 통합전산망에 공개된 포스터 이미지를 학습데이터로 하여 Pure CNN, VGG-16, Inception-v3, ResNet50 등 딥러닝 알고리즘을 통해 예측을 수행하였다. 또한 공연 관련 정형데이터를 활용한 전통적 회귀분석 방법론과의 앙상블을 시도하였다. 그 결과 흥행 예측 정확도 85%를 상회하는 높은 판별 성과를 보였다. 본 연구는 공연예술 분야에서 이미지 정보를 활용하여 흥행을 예측하는 첫 시도이며 본 연구에서 제안한 방법은 연극 외에 영화, 기관 홍보, 기업 제품 광고 등 포스터 기반의 광고를 하는 영역으로도 적용이 가능할 것이다.","The prediction of box office performance in performing arts institutions is an important issue in the performing arts industry and institutions. For this, traditional prediction methodology and data mining methodology using standardized data such as cast members, performance venues, and ticket prices have been proposed. However, although it is evident that audiences tend to seek out their intentions by the performance guide poster, few attempts were made to predict box office performance by analyzing poster images. Hence, the purpose of this study is to propose a deep learning application method that can predict box office success through performance-related poster images. Prediction was performed using deep learning algorithms such as Pure CNN, VGG-16, Inception-v3, and ResNet50 using poster images published on the KOPIS as learning data set. In addition, an ensemble with traditional regression analysis methodology was also attempted. As a result, it showed high discrimination performance exceeding 85% of box office prediction accuracy. This study is the first attempt to predict box office success using image data in the performing arts field, and the method proposed in this study can be applied to the areas of poster-based advertisements such as institutional promotions and corporate product advertisements."
라벨 임베딩 분포를 사용한 효율적인 딥러닝 앙상블 방법,2021,"['Deep Ensemble Learning', 'Clustering', 'Multi-class classification', 'Label embedding', 'Stacking Ensemble Model', '앙상블 학습', '군집화', '다중 분류 문제', '레이블 임베딩', '스태킹 앙상블 모형']","본 연구에서는 레이블 임베딩의 분포를 반영하는 딥러닝 모형을 위한 새로운 스태킹 앙상블 방법론을 제안하였다. 제안된 앙상블 방법론은 기본 딥러닝 분류기를 학습하는 과정과 학습된 모형으로 부터 얻어진 레이블 임베딩을 이용한 군집화 결과로부터 소분류기들을 학습하는 과정으로 이루어져 있다. 본 방법론은 주어진 다중 분류 문제를 군집화 결과를 활용하여 소 문제들로 나누는 것을 기본으로 한다. 군집화에 사용되는 레이블 임베딩은 처음 학습한 기본 딥러닝 분류기의 마지막 층의 가중치로부터 얻어질 수 있다. 군집화 결과를 기반으로 군집화 내의 클래스들을 분류하는 소분류기들을 군집의 수만큼 구축하여 학습한다. 실험 결과 기본 분류기로부터의 레이블 임베딩이 클래스 간의 관계를 잘 반영한다는 것을 확인하였고, 이를 기반으로 한 앙상블 방법론이 CIFAR 100 데이터에 대해서 분류 성능을 향상시킬 수 있다는 것을 확인할 수 있었다.","In this paper, we propose a new stacking ensemble framework for deep learning models which reflects the distribution of label embeddings. Our ensemble framework consists of two phases: training the baseline deep learning classifier, and training the sub-classifiers based on the clustering results of label embeddings. Our framework aims to divide a multi-class classification problem into small sub-problems based on the clustering results. The clustering is conducted on the label embeddings obtained from the weight of the last layer of the baseline classifier. After clustering, sub-classifiers are constructed to classify the sub-classes in each cluster. From the experimental results, we found that the label embeddings well reflect the relationships between classification labels, and our ensemble framework can improve the classification performance on a CIFAR 100 dataset."
정밀도로지도 제작을 위한 모바일매핑시스템 기반 딥러닝 학습데이터의 자동 구축,2021,"['PointNet', 'Deep Learning', 'Automatic Construction of Training Data', 'High-Definition Road Maps', 'Point Cloud', '딥러닝', '학습데이터 자동 구축', '정밀도로지도', '포인트 클라우드']",,
머신러닝과 딥러닝을 활용한 악성 패킷 탐지 기술 연구,2021,"['Machine Learning', 'Deep Learning', 'Reinforcement learning', 'Guidance Learning', 'Malicious Code Detection System']","현재, 5G 및 IoT 기술의 발달함에 따라 실생활에 사용하는 사물들에 네트워크로 연결되어 사용되고 있다. 하지만, 네트워크로 연결된 컴퓨터를 악의적인 목적으로 사용하려는 시도가 증가하고 있으며, 사용자 정보의 기밀성 및 무결성 을 침해하는 악성코드를 이용한 공격은 더욱 지능화되고 있다. 이에 대응하기 위한 방안으로 보안관제 시스템과 AI 기술인 지도 학습을 이용한 악성 패킷 탐지 방법에 대한 연구가 진행되고 있다. 사이버보안 관제 시스템 운영상 인력 및 비용 측면에서 비효율적으로 운영되고 있다. 또한, 코로나19 팬데믹 시대에 원격 근무가 증가하여 즉각적인 대응에 어려움이 있다. 그리고 기존 AI 기술인 지도 학습을 이용한 악성코드 탐지에는 변종 악성코드를 탐지하지 못하고 데 이터의 양과 질에 따라 부정확한 악성코드 탐지율을 가진다. 따라서, 본 연구에서는 다양한 머신러닝과 딥러닝 모델을 통해 악성 패킷 탐지 기술을 융합하여 악성 패킷 탐지 정확도를 높이고 오탐률과 미탐률을 감소시키며 새로운 유형의 악성 패킷이 침입시 이를 효율적으로 탐지 할 수 있는 악성 패킷 탐지 기술을 제안 한다.","Currently, with the development of 5G and IoT technology, it is being used in connection with the things used in real life through a network. However, attempts to use networked computers for malicious purposes are increasing, and attacks using malicious codes that infringe the confidentiality and integrity of user information are becoming more intelligent. As a countermeasure to this, research is being conducted on a method of detecting malicious packets using a security control system and AI technology, supervised learning. The cyber security control system is being operated inefficiently in terms of manpower and cost. In addition, in the era of the COVID-19 pandemic, remote work has increased, making it difficult to respond immediately. In addition, malicious code detection using the existing AI technology, supervised learning, does not detect variant malicious code, and has an inaccurate malicious code detection rate depending on the quantity and quality of data. Therefore, in this study, by converging malicious packet detection technologies through various machine learning and deep learning models, the accuracy of malicious packet detection is increased, the false positive rate and the false positive rate are reduced, and a new type of malicious packet can be efficiently detected when intrusion. We propose a malicious packet detection technology."
딥러닝 기반 언어모델을 이용한 한국어 학습자 쓰기 평가의 자동 점수 구간 분류 - KoBERT와 KoGPT2를 중심으로 -,2021,"['딥러닝', '언어모델', '한국어 쓰기 답안지', 'KoBERT', 'KoGPT2', '자동 점수 구간 분류', 'Deep Learning', 'Language Model', 'Korean Essays', 'KoBERT', 'KoGPT2', 'Automatic Score Range Classification']","이 연구에서는 '한국어 딥러닝 모델'이 '한국어 학습자의 쓰기 자료에 대한 한국어 교사의 평가 점수'를 어느 정도 유사하게 예측할 수 있는지 살펴보았다. 구체적으로 이 연구에서는 304편의 한국어 쓰기 자료와 각각에 대한 평가 점수를 KoBERT와 KoGPT2로 학습시킨 후 그것이 인간 채점자(한국어 교사)의 평가 점수를 어느 정도 유사하게 예측하는지 실험하였다. 학습 데이터는 주제에 따라 '직업'과 '행복'으로 구분하였고, 점수에 따라 4종 레이블을 부착하였다. 7겹 교차 검증을 통한 실험 결과, KoBERT에서는 '직업' 데이터에서 48.8%, '행복' 데이터에서 65.2%의 분류 정확도를 나타냈다. KoGPT2에서는 같은 데이터에 대해 각각 50.6%와 58.9%의 분류 정확도를 나타냈다. 더불어, 모든 주제를 통합한 데이터에서는 KoBERT와 KoGPT2에 대해 각각 54.5%와 46.5%의 분류 정확도를 확인할 수 있었다. 이 연구를 통해 한국어 쓰기 자료에 대한 자동 채점 시스템의 가능성을 확인할 수 있었다. 향후 GPT-3의 한국어 모델이 개발되는 등의 기술 발전이 이루어진다면, 이 연구에서 시도한 한국어 자동 채점 시스템도 충분히 가능할 것으로 기대한다.","Automatic Score Range Classification of Korean Essays Using Deep Learning-based Korean Language Models-The Case of KoBERT & KoGPT2-. We investigate the performance of deep learning-based Korean language models on a task of automatically classifying Korean essays written by foreign students. We construct an experimental data set containing a total of 304 essays, which include essays discussing the criteria for choosing a job (‘job’), conditions of a happy life (‘happiness’), relationship between money and happiness, and definition of success. These essays were divided into four scoring levels, and using this 4-class data set, we fine-tuned two Korean deep learning-based language models, namely, KoBERT and KoGPT2, to use them in the automatic essay classification experiment. The 7-fold cross validation classification accuracies of ‘job’ and ‘happiness’ essays were 48.8% and 65.2% respectively for KoBERT, and 50.6% and 58.9% respectively for KoGPT2. Furthermore, the 7-fold cross validation classification accuracies of the integrated dataset that combined all essays were 54.5% and 46.5% for KoBERT and KoGPT2 respectively."
딥러닝 기반 포즈 인식 및 교정을 통한 효율적인 홈 트레이닝 시스템 개발,2021,"['딥러닝', '포즈 인식', '홈 트레이닝', '미디어파이프', 'Deep-Learning', 'Pose Recognition', 'Home Training', 'MediaPipe']","COVID-19 확산으로 인해 헬스장이나 야외보다는 집에서 운동하는 것을 선호하는 사람들이 늘어나고 있다. 홈 트 레이닝을 할 때 잘못된 방법으로 운동을 하게 되면 다칠 수도 있고 운동의 효과가 절감될 수 있는 문제가 있다. 본 논문은 학습에 기반한 포즈 분류 모델을 통해 실시간으로 사용자의 포즈를 분류하고, 사람의 관절 점을 기반으로 포즈를 분석하여 잘못된 포즈를 교정할 수 있도록 도와주는 홈 트레이닝 시스템을 제안한다. 트레이너의 비디오 영상 과 웹캠을 통하여 직접 입력받은 운동 영상을 MediaPipe Pose API를 사용하여 포즈의 관절 좌표를 추출하고, 이 를 데이터 세트로 학습하여 포즈 분류 모델을 구성한다. 사용자는 실시간으로 인식된 본인의 포즈를 확인하면서 운 동할 수 있고 잘못된 포즈에 대해서는 올바른 어드바이스를 제공받을 수 있다. 또한 사용자가 올바른 포즈로 운동을 한 경우 운동 횟수가 증가되어 보다 효율적인 운동이 가능하도록 한다. 맨몸 운동의 대표적 운동인 스쿼트와 푸쉬업 에 대해 본 시스템의 성능을 실험한 결과 스쿼트는 96%이고, 푸쉬업은 95%의 정확도를 보였고 포즈 추론 속도는 평균 31ms가 소요되어 실시간으로 활용 가능함을 알 수 있었다.","Due to the spread of COVID-19, more and more people prefer to exercise at home rather than at gyms or outdoors. If you exercise in the wrong way during home training, you may get hurt and the effectiveness of the exercise may be reduced. This paper proposes a home training system that helps correct wrong posture by classifying user posture in real time through a deep learning-based posture classification model and analyzing posture based on human joint points. The joint coordinates of the pose are extracted using the MediaPipe Pose API for the video images of the trainer and the exercise input images obtained directly from the webcam, and the pose classification model is constructed by learning them as a dataset. The user can exercise while checking his or her pose recognized in real time, and can be provided with the right advice for the wrong pose. In addition, when the user exercises in the right pose, the number of exercises increases, enabling more efficient exercise. As a result of testing the performance of this system for squats and push-ups, which are representative exercises of bare-body exercise, it was found that squats were 96%, push-ups showed 95% accuracy, and pose inference speed took an average of 31 ms, making it available in real-time."
딥러닝을 이용한 폐 기능 검사지의 정형화,2021,"['Text Detection', 'Text Recognition', 'Image Classification', 'Data Structuring', 'Deep Learning', '글자 검출', '글자 분류', '이미지 분류', '데이터 정형화', '딥러닝']","본 논문에서는 문자 검출 및 인식 기술을 활용하여 비정형의 폐 기능 검사지 이미지로부터 연구를 위한 관련 정보들을 추출하여 정형화하는 방법을 제안한다. 또한 문자 인식 오차율을 줄이기 위한 후처리 방법 또한 개발하고자 한다. 제안하는 정형화 방법은 폐 기능 검사지 이미지에 대해 문자 검출 모델을 사용해 검사지 내에 존재하는 모든 문자를 검출하고, 검출된 문자 이미지를 문자 인식 모델에 통과시켜 문자열을 얻어낸다. 얻어낸 문자열에 대해 문자열 매칭을 이용한 유효성 검토를 진행하고 정형화를 마무리한다. 제안하는 정형화 시스템의 오차율은 약 1% 이내, 검사지 당 처리속도는 2초 이내로 전문인력의 수작업을 통한 정형화 방법보다 더 효율적이고 안정적인 방식이라는 것을 확인할 수 있다.","In this paper, we propose a method of extracting and recognizing related information for research from images of the unstructured pulmonary function test papers using character detection and recognition techniques. Also, we develop a post-processing method to reduce the character recognition error rate. The proposed structuring method uses a character detection model for the pulmonary function test paper images to detect all characters in the test paper and passes the detected character image through the character recognition model to obtain a string. The obtained string is reviewed for validity using string matching and structuring is completed. We confirm that our proposed structuring system is a more efficient and stable method than the structuring method through manual work of professionals because our system’s error rate is within about 1% and the processing speed per pulmonary function test paper is within 2 seconds."
딥러닝에 의한 항공사진 구름 분류 및 탐지 비교 실험,2021,"['Deep Learning', 'Classification', 'Detection', 'GoogLeNet', 'VGG16', 'Faster R-CNN', 'YOLOv3', '딥러닝', '분류', '탐지']",,
딥러닝 기반의 Semantic Segmentation을 위한 Residual U-Net에 관한 연구,2021,['-'],"본 논문에서는 U-Net 기반의 semantic segmentation 방법에서 정확도를 향상시키기 위해 residual learning을 활용한 인코더-디코더 구조의 모델을 제안하였다. U-Net은 딥러닝 기반의 semantic segmentation 방법이며 자율주행 자동차, 의료 영상 분석과 같은 응용 분야에서 주로 사용된다. 기존 U-Net은 인코더의 얕은 구조로 인해 특징 압축 과정에서 손실이 발생한다. 특징 손실은 객체의 클래스 분류에 필요한 context 정보 부족을 초래하고 segmentation 정확도를 감소시키는 문제가 있다. 이를 개선하기 위해 제안하는 방법은 기존 U-Net에 특징 손실과 기울기 소실 문제를 방지하는데 효과적인 residual learning을 활용한 인코더를 통해 context 정보를 효율적으로 추출하였다. 또한, 인코더에서 down-sampling 연산을 줄여 특징맵에 포함된 공간 정보의 손실을 개선하였다. 제안하는 방법은 Cityscapes 데이터셋 실험에서 기존 U-Net 방법에 비해 segmentation 결과가 약 12% 향상되었다.","In this paper, we proposed an encoder-decoder model utilizing residual learning to improve the accuracy of the U-Net-based semantic segmentation method. U-Net is a deep learning-based semantic segmentation method and is mainly used in applications such as autonomous vehicles and medical image analysis. The conventional U-Net occurs loss in feature compression process due to the shallow structure of the encoder. The loss of features causes a lack of context information necessary for classifying objects and has a problem of reducing segmentation accuracy. To improve this, The proposed method efficiently extracted context information through an encoder using residual learning, which is effective in preventing feature loss and gradient vanishing problems in the conventional U-Net. Furthermore, we reduced down-sampling operations in the encoder to reduce the loss of spatial information included in the feature maps. The proposed method showed an improved segmentation result of about 12% compared to the conventional U-Net in the Cityscapes dataset experiment."
딥러닝 기반의 Semantic Segmentation을 위한 DeepLabv3+에서 강조 기법에 관한 연구,2021,['-'],"본 논문에서는 정밀한 semantic segmentation을 위해 강조 기법을 활용한 DeepLabv3+ 기반의 인코더-디코더 모델을 제안하였다. DeepLabv3+는 딥러닝 기반 semantic segmentation 방법이며 자율주행 자동차, 적외선 이미지 분석 등의 응용 분야에서 주로 사용된다. 기존 DeepLabv3+는 디코더 부분에서 인코더의 중간 특징맵 활용이 적어 복원 과정에서 손실이 발생한다. 이러한 복원 손실은 분할 정확도를 감소시키는 문제를 초래한다. 따라서 제안하는 방법은 하나의 중간 특징맵을 추가로 활용하여 복원 손실을 최소화하였다. 또한, 추가 중간 특징맵을 효과적으로 활용하기 위해 작은 크기의 특징맵부터 계층적으로 융합하였다. 마지막으로, 디코더에 강조 기법을 적용하여 디코더의 중간 특징맵 융합 능력을 극대화하였다. 본 논문은 거리 영상 분할연구에 공통으로 사용되는 Cityscapes 데이터셋에서 제안하는 방법을 평가하였다. 실험 결과는 제안하는 방법이 기존 DeepLabv3+와 비교하여 향상된 분할 결과를 보였다. 이를 통해 제안하는 방법은 높은 정확도가 필요한 응용 분야에서 활용될 수 있다.",
딥러닝 기반 GNSS 천정방향 대류권 습윤지연 추정 연구,2021,"['Deep Learning', 'Global Navigation Satellite System', 'Zenith Tropospheric Wet Delay', 'Meteorological Data', '딥러닝', '범지구항법위성시스템', '천정방향 대류권 습윤지연', '기상 데이터']",,
딥러닝을 통한 드론의 비정상 진동 예측,2021,"['딥러닝', '드론', '모터', '진동', 'deep learning', 'RNN', 'LSTM', 'drone', 'motor', 'vibration']","본 논문에서는 드론의 추락을 예방하기 위해 드론의 프로펠러와 연결된 모터로부터 진동 데이터를 수집하고 순환 신경망(recurrent neural network, RNN)과 long short term memory (LSTM)을 사용하여 드론의 비정상 진동을 예측하는 연구를 진행하였다. 드론의 비정상 진동 데이터를 수집하기 위해 드론의 프로펠러와 연결된 모터에 진동 센서를 부착하여 정상, 바(bar) 손상, 로터(rotor) 손상, 축 휨에 대한 진동 데이터를 수집하고 LSTM과 RNN을 통해 비정상 진동을 예측한 결과의 평균 제곱근 오차 (root mean square error, RMSE) 값을 비교분석 하였다. 시뮬레이션 비교 결과, RNN과 LSTM을 통해 예측한 결과 모두 비정상 진동 패턴을 매우 정확하게 예측하는 것을 확인하였으며 LSTM을 통해 예측한 진동이 RNN을 통해 예측한 진동보다 RMSE값이 평균 15.4% 낮은 것을 확인하였다.","In this paper, in order to prevent the fall of the drone, a study was conducted to collect vibration data from the motor connected to the propeller of the drone, and to predict the abnormal vibration of the drone using recurrent neural network (RNN) and long short term memory (LSTM). In order to collect the vibration data of the drone, a vibration sensor is attached to the motor connected to the propeller of the drone to collect vibration data on normal, bar damage, rotor damage, and shaft deflection, and abnormal vibration data are collected through LSTM and RNN. The root mean square error (RMSE) value of the vibration prediction result were compared and analyzed. As a result of the comparative simulation, it was confirmed that both the predicted result through RNN and LSTM predicted the abnormal vibration pattern very accurately. However, the vibration predicted by the LSTM was found to be 15.4% lower on average than the vibration predicted by the RNN."
딥러닝을 통한 문서 내 표 항목 분류 및 인식 방법,2021,"['Optical character recognition', 'Image recognition', 'Deep learning', 'Intelligent document processing', 'Convolutional neural network']",,
딥러닝 기반의 소비자 데이터를 응용한 외식업체 추천 시스템 구현에 관한 연구,2021,"['추천 시스템', '인공지능', '딥러닝', '분류', '감성 분석', '외식업체', 'Recommendation System', 'Artificial Intelligence', 'Deep Learning', 'Classification', 'Sentiment Analysis', 'Restaurant']",본 연구에서는 소비자 데이터를 딥러닝 기반의 분류(Classification) 모델을 학습 시켜 추천 알고리즘을 구현하였다. 이를 위하여 사용자 데이터를 이미지로 변환 시켜 분류 과제에서 보편적으로 사용되는 ResNet50을 사용하여 학습한 결과로서 유의미한 결과에 대하여 제시함,"In this study, a recommendation algorithm was implemented by learning a deep learning-based classification model for consumer data. For this purpose, a meaningful result is presented as a result of learning using ResNet50, which is commonly used in classification tasks by converting user data into images."
딥러닝 기반 객체 인식과 최적 경로 탐색을 통한 멀티 재난 드론 시스템 설계 및 구현에 대한 연구,2021,"['ACO', 'Swarm', 'Drone', 'Deep Learning', 'Path Planning', '군집', '드론', '딥러닝', '경로 설정']",,"In recent years, human damage and loss of money due to various disasters such as typhoons, earthquakes, forest fires, landslides, and wars are steadily occurring, and a lot of manpower and funds are required to prevent and recover them. In this paper, we designed and developed a disaster drone system based on artificial intelligence in order to monitor these various disaster situations in advance and to quickly recognize and respond to disaster occurrence. In this study, multiple disaster drones are used in areas where it is difficult for humans to monitor, and each drone performs an efficient search with an optimal path by applying a deep learning-based optimal path algorithm. In addition, in order to solve the problem of insufficient battery capacity, which is a fundamental problem of drones, the optimal route of each drone is determined using Ant Colony Optimization (ACO) technology. In order to implement the proposed system, it was applied to a forest fire situation among various disaster situations, and a forest fire map was created based on the transmitted data, and a forest fire map was visually shown to the fire fighters dispatched by a drone equipped with a beam projector. In the proposed system, multiple drones can detect a disaster situation in a short time by simultaneously performing optimal path search and object recognition. Based on this research, it can be used to build disaster drone infrastructure, search for victims (sea, mountain, jungle), self-extinguishing fire using drones, and security drones."
딥러닝 기반 전차 조준선 정렬 시스템,2021,"['Tank', 'Aiming Inspection', 'Deep Learning', 'Target Detection', 'Computer Vision']",기존의 조준 감사는 외국에서 수입한 조준 감사기재를 사용하는 실정이다. 하지만 그 수량이 매우 부족해서 조준 감사에 많은 시간이 소요되고 유지보수가 어렵다. 때문에 시스템을 국산화 시켜 조준 감사시간을 줄이고 유지보수와 보급을 원활하게 하는 것이 목적이다. 본 논문에서는 표적 탐지 딥러닝 모델을 통해 표적을 탐지하고 사격 결과에 대한 모니터링이 가능한 시스템을 개발하였다. 이 시스템은 표적의 실시간 탐지가 가능하고 먼 표적에 대한 여러 전처리를 통해 식별률을 크게 상승시켰다. 또한 사용자 인터페이스를 구성하여 사용자의 카메라 조작과 훈련결과 데이터의 저장 및 관리를 용이하게 하였다. 이 시스템으로 현재 사용되고 있는 조준 감사기재와 비사격 훈련을 대체할 수 있다.,"The existing aiming inspection use foreign-made aiming inspection equipment. However, the quantity is insufficient and the difficult to maintain. So it takes a lot of time to inspect the target. This system can reduces the time of aiming inspection and be maintained and distributed smoothly because it is a domestic product. In this paper, we develop a system that can detect targets and monitor shooting results through a target detection deep learning model. The system is capable of real-time detection of targets and has significantly increased the identification rate through several preprocessing of distant targets. In addition, a graphical user interface is configured to facilitate user camera manipulation and storage and management of training result data. Therefore the system can replace the currently used aiming inspection equipment and non-fire training."
딥러닝 기반 멀티모달 정보 분석을 활용한 라이브커머스 영상 요약 기법,2021,"['딥러닝', '라이브커머스', '멀티모달', '영상 처리', '영상 요약', 'Deep learning', 'Live-commerce', 'Multimodal', 'Video Processing', 'Video Summarization']",,"Recently, Live-commerce is one of the services that are growing rapidly with untact service by COVID-19. Live-commerce includes a real-time service and Video On Demand(VOD) service about past broadcasts. In this paper, we propose video summarization technique using Deep Learning for providing summarized video including main contents such as product information or events and so on. This is for offering high impact of past broadcast. After multi-modal information composed of Audio, image, text is analyzed by Deep Learning, we extract impact score per section about each multi-modal information. Section with high impact score is selected by summing each multi-modal score. It reduces the editing time and costs required for summarizing video so that retains proper timing by creating the effective summary video containing characteristics of Live-commerce automatically."
딥러닝 언어모델의 한국어 학습자 말뭉치 원어민성 판단 결과 분석 연구,2021,"['deep learning', '딥러닝', 'BERT', '버트', 'nativelikeness judgment', '원어민성 판단', 'classification', '분류', 'Korean learner corpus', '한국어 학습자 말뭉치', 'error-tagged corpus', '오류 주석 말뭉치']",,"The present study aims to analyze how deep learning judges nativelikeness in the corpus of native Korean speakers and Korean learners. To this end, a deep learning model that classifies sentences of native Korean speakers and Korean learners was built, and the criteria for determining nativelikeness between deep learning and humans were compared and analyzed in terms of error analysis. As a result of the analysis, the accuracy of the deep learning model built in this study was found to be 91%, which means that 91 sentences out of 100 sentences were accurately classified whether they were written by the native speaker or by the learner. In addition, since the error annotation result of the learner corpus is a projected result of human judgment of nativelikeness, the similarities and differences of the criteria for determining nativelikeness were described in detail by comparing it with the test data verification result of deep learning. The results of this study will be an important basis for clarifying what the nativelikeness of native Korean speakers is and for objectively judging the nativelikeness of the language produced by Korean learners.(Yonsei University)"
딥러닝 기법을 활용한 북한의 대외인식 분석 연구 - 『로동신문』(2016-2019) 빅데이터를 중심으로 -,2021,"['북한', '로동신문', '빅데이터', '딥러닝', '대남 인식', 'North Korea', 'Rodong sinmun', 'Big data', 'Deep learning', 'perception on South Korea']",,"This article analyzed the changes in North Korea’s internal and external perceptions using the deep learning-based analysis about Rodong Sinmun from 2016 to 2019. Even if the growing peace mood that had stayed for a while on the Korean Peninsula now disappeared, the change in North Korea’s attitude over a short period of time was very unusual. It was attempted to provide a more detailed understanding about the possibility of future changes in North Korea by tracking changes in North Korea’s perceptions of South Korea and its perceptions of peace and threats. As a result, the main threat was the US for North Korea’s perspective, and it was also confirmed that South Korea could be perceived as a threat by insulting on the dignity of the supreme leader-Kim Jongeun. The fact whether South Korea’s governments consist of progressive or conservative party doesn’t seem to have significant impacts on North Korea’s perception. Expectations for improvement in inter-Korean relations in 2018 are highly likely to have been perceived by North Korea as an escape from the crisis through the ease of economic sanctions. The reason is that North Korea’s perception about the threat has returned to the same level as before after the severance of US-DPRK dialogue, and it could be revealed by ordering slogans for domestic economic development. This study applied the machine learning technique to the full text of the Rodong Sinmun for 4 years, confirming the changes in the main vocabulary of the Rodong Sinmun."
딥러닝 기반 손 그림 심리분석 알고리즘 연구,2021,"['그림 심리 검사', '객체 분류', '딥러닝', '객체 검출', '계층적 구조', 'Art Therapy', 'Classification', 'Deep learning', 'Object detection', 'Hierarchical structure']",,"From simple scribbles of children to paintings by world-class artists, human psychology is melted into drawings. They express the concept, experience, desire, and attitude to the environment they have acquired, and can identify the persons tendency and personalities. This can be used as a medium for psychotherapy, called art therapy. We devise an efficient scheme to analyze the hand drawings based on a hierarchical structure, which allows us to produce certain results. First, we extract some separated parts which is consisted of whole objects by object detection. With the extracted parts, we perform the classification task based on 2D CNN to define key attribute. For the given image, the analyzed report is constructed based on the key attributes. The proposed algorithm is applied to tree test and cat test among many drawing psychological tests, and achieves an analysis accuracy of about 93% and 96%, respectively."
딥러닝 기법을 이용한 주차 공간 자동 식별 시스템,2021,"['전이 학습', '텐서플로우 라이트', '티처블 머신', '안드로이드 스튜디오', 'Transfer Learning', 'TensorFlow Lite', 'Teachable Machine', 'Android Studio']","본 논문에서는 촬영된 주차장 사진으로부터 빈 주차 공간을 자동 식별할 수 있는 주차 공간 자동 식별 시스템 에 대해 설명한다. 이 시스템은 딥러닝 기법에 기반한 시스템으로, 다양한 주차장 사진들을 토대로 학습을 진행하여 식별 결과의 정확도가 높으며, 기존의 주차 관리 시스템에 적용할 수 있다. 한편, 본 시스템은 손쉬운 적용 테스트를 위해, 스마트폰용 애플리케이션으로도 개발되었다. 따라서 스마트폰 카메라를 통해 주차장 사진을 찍으면, 촬영된 이 미지를 자동 인식하며 빈 주차 공간을 자동 식별할 수 있다.","In this paper, we describe a parking space identification system that can automatically identify empty parking lot spaces from a parking lot photo. This system is based on a deep learning technique, and the accuracy of the identification result is good by learning various existing parking lot images. It could be applied to the existing parking management system. This system was also developed as a smartphone application for easy testing. Therefore, if you take a picture of a parking lot through a smartphone camera, the captured image is automatically recognized and an empty parking space can be automatically identified."
딥러닝 기반 분류 모델의 성능 분석을 통한 건설 재해사례 텍스트 데이터의 효율적 관리방향 제안,2021,"['Construction Safety', 'CNN', 'Deep Learning', 'Classification Model', 'Disaster Data', '건설 안전', 'CNN', '딥러닝', '분류 모델', '재해 데이터']",,"This study proposes an efficient management direction for Korean construction accident cases through a deep learning-based text data classification model. A deep learning model was developed, which categorizes five categories of construction accidents: fall, electric shock, flying object, collapse, and narrowness, which are representative accident types of KOSHA. After initial model tests, the classification accuracy of fall disasters was relatively high, while other types were classified as fall disasters. Through these results, it was analyzed that 1) specific accident-causing behavior, 2) similar sentence structure, and 3) complex accidents corresponding to multiple types affect the results. Two accuracy improvement experiments were then conducted: 1) reclassification, 2) elimination. As a result, the classification performance improved with 185.7% when eliminating complex accidents. Through this, the multicollinearity of complex accidents, including the contents of multiple accident types, was resolved. In conclusion, this study suggests the necessity to independently manage complex accidents while preparing a system to describe the situation of future accidents in detail."
딥러닝 기반 장애물 인식을 위한 가상환경 및 데이터베이스 구축,2021,"['Database(데이터베이스)', 'Object Detection(객체 인식)', 'Image Segmentation(이미지 세그멘테이션)', 'Deep Learning(딥러닝)', 'Relational Database Management System(관계형 데이터베이스 관리 시스템)']",,"This study proposes a method for creating learning datasets to recognize obstacles using deep learning algorithms in automated construction machinery or an autonomous vehicle. Recently, many researchers and engineers have developed various recognition algorithms based on deep learning following an increase in computing power. In particular, the image classification technology and image segmentation technology represent deep learning recognition algorithms. They are used to identify obstacles that interfere with the driving situation of an autonomous vehicle. Therefore, various organizations and companies have started distributing open datasets, but there is a remote possibility that they will perfectly match the user""s desired environment. In this study, we created an interface of the virtual simulator such that users can easily create their desired training dataset. In addition, the customized dataset was further advanced by using the RDBMS system, and the recognition rate was improved."
딥러닝 기반 자동 변조 인식 성능 분석,2021,"['Automatic modulation classification', 'Deep learning', 'Neural network', 'SNR', 'FFT', '자동변조인식', '딥러닝', '신경망', '신호대잡음비', '고속푸리에변환']","본 논문에서는 미상의 통신신호에 대한 자동 변조 인식을 위하여 심층신경망인 딥뉴럴네트워크를 적용하여 변조형태를 식별하고 그 성능을 분석하였다. 신경망 입력 데이터는 변조된 신호의 시간영역 디지털샘플 데이터, FFT(Fast Fourier Transform)를 적용한 주파수영역 데이터, 시간 및 주파수영역 혼합데이터를 사용하여 각각의 변조인식 성능을 확인하였다. 아날로그 변조 및 디지털 변조 신호 11종에 대하여 –20~18 dB 까지 다양한 SNR(Signal to Noise Ratio) 환경에서 변조인식 성능을 확인하고 그 성능을 분석하였으며, 입력 데이터의 종류에 따른 학습 속도를 확인함으로써 제안한 방법이 실제적인 자동변조 인식 시스템 구축에 효과적인 방법임을 확인 하였다.","In this paper, we conduct performance analysis in automatic modulation classification of unknown communication signal to identify its modulation types based on deep neural network. The modulation classification performance was verified using time domain digital sample data of the modulated signal, frequency domain data to which FFT was applied, and time and frequency domain mixed data as neural network input data. For 11 types of analog and digitally modulated signals, the modulation classification performance was verified in various SNR environments ranging from -20 to 18 dB and reason for false classification was analyzed. In addition, by checking the learning speed according to the type of input data for neural network, proposed method is effective for constructing an practical automatic modulation recognition system that require a lot of time to learn."
실시간 분석을 위한 도커 컨테이너 기반의 딥러닝 모델 관리 시스템 설계 및 성능 비교,2021,"['딥러닝', '딥러닝 모델 관리', '실시간 분석', '서빙 아키텍처', '도커 컨테이너', 'Deep Learning', 'Deep Learning Model Management', 'Real-time Analysis', 'Serving Architecture', 'Docker Container']",,
딥러닝 기반 사용자 특징 정보 모델링을 통한 사용자 안전 프로파일링,2021,"['user profiling', 'feature modeling', 'deep learning', 'artificial intelligence system', 'big data analysis', '사용자 프로파일링', '특징 모델링', '딥러닝', '인공지능시스템', '빅데이터 분석']",,"There is a need for an artificial intelligent technology that can reduce various types of safety accidents by analyzing the risk factors that cause safety accidents in industrial site. In this paper, user safety profiling methods are proposed that can prevent safety accidents in advance by specifying and modeling user information data related to safety accidents. User information data is classified into normal and abnormal conditions through deep learning based artificial intelligence analysis. As a result of verifying user safety profiling technology using more than 10 types of industrial field data, 93.6% of user safety profiling accuracy was obtained."
딥러닝 기반의 최적 R2 증산 모델을 통한 식물 성장과 환경적 요인 간의 영향 연구,2021,"['증산', '인공지능', '딥러닝', '다층 퍼셉트론', '결정 계수 R2', 'Transpiration', 'Artificial Intelligence', 'Deep Learning', 'Multi Layer Perceptron', 'Coefficient of Determination']",,
딥러닝 모형을 이용한 신호교차로 대기행렬길이 예측,2021,"['다중회귀', '딥러닝', 'LSTM', '대기행렬길이', '예측', 'Multiple Regression', 'Deep Learning', 'LSTM', 'Queue Length', 'Forecasting']",,
딥러닝과 앙상블 머신러닝 모형의 하천 탁도 예측 특성 비교 연구,2021,"['Deep learning', 'Drinking water supply systems', 'Ensemble machine learning', 'Recurrent neural network', 'Turbidity management', '딥러닝', '정수 공급 시스템', '앙상블 머신러닝', '순환신경망', '탁도 관리']",,"The increased turbidity in rivers during flood events has various effects on water environmental management, including drinking water supply systems. Thus, prediction of turbid water is essential for water environmental management. Recently, various advanced machine learning algorithms have been increasingly used in water environmental management. Ensemble machine learning algorithms such as random forest (RF) and gradient boosting decision tree (GBDT) are some of the most popular machine learning algorithms used for water environmental management, along with deep learning algorithms such as recurrent neural networks. In this study GBDT, an ensemble machine learning algorithm, and gated recurrent unit (GRU), a recurrent neural networks algorithm, are used for model development to predict turbidity in a river. The observation frequencies of input data used for the model were 2, 4, 8, 24, 48, 120 and 168 h. The root-mean-square error-observations standard deviation ratio (RSR) of GRU and GBDT ranges between 0.182~0.766 and 0.400~0.683, respectively. Both models show similar prediction accuracy with RSR of 0.682 for GRU and 0.683 for GBDT. The GRU shows better prediction accuracy when the observation frequency is relatively short (i.e., 2, 4, and 8 h) where GBDT shows better prediction accuracy when the observation frequency is relatively long (i.e. 48, 120, 160 h). The results suggest that the characteristics of input data should be considered to develop an appropriate model to predict turbidity."
딥러닝 얼굴인식 기술을 활용한 방문자 출입관리 시스템 설계와 구현,2021,"['Face recognition', 'Deep learning', 'Access control', 'OpenCV', 'Dlib', 'Design and Implementation.', '얼굴인식', '딥러닝', '출입관리', '오픈소스', '설계 및 구현.']","1,2인 가구가 꾸준하게 늘어나고 있는 추세에 비어 있는 시간대에 집을 방문하는 외부인이 누구인지 확인하고 싶은 요구가 증가하고 있다. 얼굴인식 기술은 많은 연구를 통해 여러 가지 모델이 제안되었는데 OpenCV의 Harr Cascade와 Dlib의 Hog가 대표적인 오픈소스 모델이다. 두 모델은 사용 환경에 따른 장단점을 가지고 있는데, 본 연구에서 초점을 둔 실내 현관 앞과 제한된 거리에서는 Dlib의 Hog가 강점을 가진다. 본 논문에서는 딥러닝 오픈 소스인 Dlib에 기반을 둔 얼굴인식 방문자 출입관리 시스템을 설계하고 구현하였다. 전체 시스템은 프론트 모듈과 서버모듈, 모바일모듈로 구성되며 세부적으로는 얼굴등록, 얼굴인식, 실시간 방문자 확인 및 원격제어, 동영상 저장 기능을 포함한다. 인터넷에서 공개된 사진을 이용하여 거리임계 값의 변화에 따른 정밀도, 특이도, 정확도를 구하고 선행연구 결과와 비교하였다. 실험 결과 구현된 시스템이 정상적으로 동작하는 것을 확인 하였으며 Dlib에서 보고한 것과 비슷한 결과를 보이는 것을 확인 하였다.","As the trend of steadily increasing the number of single or double household, there is a growing demand to see who is the outsider visiting the home during the free time. Various models of face recognition technology have been proposed through many studies, and Harr Cascade of OpenCV and Hog of Dlib are representative open source models. Among the two modes, Dlib's Hog has strengths in front of the indoor and at a limited distance, which is the focus of this study. In this paper, a face recognition visitor access system based on Dlib was designed and implemented. The whole system consists of a front module, a server module, and a mobile module, and in detail, it includes face registration, face recognition, real-time visitor verification and remote control, and video storage functions. The Precision, Specificity, and Accuracy according to the change of the distance threshold value were calculated using the error matrix with the photos published on the Internet, and compared with the results of previous studies. As a result of the experiment, it was confirmed that the implemented system was operating normally, and the result was confirmed to be similar to that reported by Dlib."
딥러닝 기반 LSTM 모형을 이용한 저수지 수위자료 이상치 탐지,2021,"['농업용수', '수위 자료', '품질관리', '딥러닝', '이상 탐지', 'Agricultural Water', 'Water Level', 'Quality Control', 'Deep Learning', 'Anomaly Detection']","최근 국지성 가뭄 발생 및 집중 호우;평년 대비 강수량이 30% 이상 감소하는 등 기상 및 수문 현상이 변화하고 있다. 논벼 작물재배를 위한 용수를 공급하는 농업용 저수지의 경우 이상기후 발생으로 2013년부터 2017년까지 저수율이 0%에 도달한 저수지가 99개에 이르러 농업용수의 안정적 확보가 불확실해지고 있다. 농업환경의 변화와 기후변화에 대응하기 위해 농업용수 관리 정보화 및 과학화의 필요성이 증대되고 있으며;실시간으로 저수지 저수량과 농업용수 공급량을 파악하기 위해 자동 수위계측시설이 도입되었다. 농림축산식품부의 저수지 자동수위측정기 설치 및 운영지침에 따라 현재 농어촌공사 관리 저수지 1,734개소 및 수로부 1,880개소에 자동수위계가 설치되어 있으며;저수지와 수로에서 10분 간격으로 수위자료가 생성되고 있다. 농업용 저수지 수문자료의 공인지점은 2016년 6개소에서 2019년 49개소로 증가하고 있으며;데이터 품질 저하의 최소화 및 신뢰성 있는 수문자료 생성의 필요성이 증가함에 따라 농업용 저수지의 특성을 반영한 저수지 수위 오결측 데이터 보정 방안 및 수문 자료 품질관리 방안이 요구된다. 최근 인공신경망(Artificial Neural Network;ANN) 등의 모형을 이용하여 비선형적인 수문해석이 가능해짐에 따라 농업용 저수지의 수위 변화 및 강우-유출 현상을 기상;지형 등 영향 인자와 수위(또는 유출)와의 상관관계로부터 해석이 가능하다. 본 연구에서는 농업용수의 정량적 정보 관리를 위하여 시계열 자료의 학습에 효과적인 모형으로 다른 신경망과의 결합 등 다양한 분야에서 이용되고 있는 딥러닝(Deep Learning) 모형 중 하나인 LSTM (Long Short-Term Memory) 모형을 이용하여;저수지 수위 자료의 오⋅결측 자료에 대한 이상 탐지 알고리즘을 제시하고자 한다.","Weather and hydrological phenomena have been changing due to climate change as evidenced by localized torrential rainfall and precipitation falling by more than 30% compared to the annual average. From 2013 to 2017 the ninety-nine reservoirs reached a water storage rate of 0%;making a secure stable water supply for agriculture uncertain. There is an increased need for information regarding agricultural water management to respond to the changes in the agricultural environment and climate. Therefore;automatic water level measurement facilities have been introduced to determine the real-time reservoir storage capacity and agricultural water supply. According to the Ministry of Agriculture;Food and Rural Affairs guidelines for the installation and operation of water level measurement instruments;automatic water level facilities are currently installed at 1,734 reservoirs and 1,880 irrigation canals;with water level data generated at 10-minute intervals. The official recognition of hydrological water level data for agricultural reservoirs increased from six in 2016 to forty-nine in 2019. Anomaly detection algorithm methods for data regarding the agricultural reservoir level as well as quality control measures based on agricultural reservoir characteristics are required to minimize data quality degradation and generate reliable hydrological data over time. Though it was practically impossible to analyze the correlation between the water level or run-off and influential factors such as weather and terrain;recently a non-linear hydrological analysis has been possible using models such as Artificial Neural Networks (ANNs). This study aims to present an anomaly detection algorithm for reservoir level data using deep learning based LSTM (Long Short-Term Memory) models;in combination with other neural networks for managing quantitative information of agricultural water supply."
딥러닝을 이용한 온실의 환경에서 토마토 화방 및 과실 객체 검출 모델 연구,2021,"['토마토', '이미지 처리', '객체 검출', '딥러닝 기계학습', 'Tomato', 'Image Processing', 'Object Detection', 'Deep Learning', 'Machine Vision']",,
딥러닝을 이용해 유의어의 변별 요소를 찾아보기 -여러 모델의 비교를 중심으로-,2021,"['어휘 의미', '유의어 변별', '딥러닝', '변별 요소', '금방', '방금', 'lexical meaning', 'synonym distinction', 'deep learning', 'distinctive facotrs']",,"This paper aims to find the distinctive factors of synonyms using various models of deep learning, what are the distinctive factors found in various models in common, and what it means to the research on synonyms.In the meantime, when we look at the flow of Korean lexical meaning research, from using the target word to create grammatically appropriate and non-grammatical sentences to distinguish their meaning, to using the corpus to find out what words the target word collocates with. In recent years, it has continued to identify the usage environment of target words from a large amount of data by applying a deep learning methodology.However, when introducing a methodology different from the previous one in this research flow, there are few discussions about why a new methodology should be introduced, and what the new methodology suggests and what its significance is.This paper examines what the semantic distinctive factors were identified in previous studies for '금방' and '방금', which have a synonyms relationship, and how the results of previous studies and the results of applying the deep learning methodology are the same and different. And by comparing the results, we will show the advantages of the deep learning method in the study of synonym distinction."
적대적 생성 신경망과 딥러닝을 이용한 교량 상판의 균열 감지,2021,"['딥러닝', '이미지 생성 모델', '균열 감지', '교량 점검', '콘크리트 교량', 'Deep learning', 'Image generative model', 'Crack detection', 'Bridge deck monitoring', 'Concrete bridge']",,
딥러닝을 활용한 지가적정성 검증모형: DCGAN 적용을 중심으로,2021,"['인공지능', '딥러닝', '개별공시지가', 'GAN', 'DCGAN AI', 'Deep Learning', 'Individual land Price', 'Generative Adversarial Nets', 'Deep Convolutional GAN']",,"Recently, artificial intelligence has become widely utilized in all industries. The field of real estate property is not an exemption, and in private sectors, efficiency is optimized through the integration between big data and computer technology. This study analyzed the applicability of DCGAN paired with deep learning as a new verification measure. Land price errors occur for public land prices despite repeated annual verification.Based on the research findings, first, there was a stabilizing trend in D and G after steady learning where the accuracy of DCGAN was identified at 78.8%. Second, as a result of adjusting the extinction ratio within the 90%-30% range, the appropriate extinction ratio was analyzed at 60%. Third, the accuracy of land use was analyzed based on the appropriate extinction ratio, and was displayed in the order of 'residential area>industrial area>green area>commercial area' Fourth, the accuracy of the model was improved based on the learning process. To apply DCGAN as the land price verification model, it is necessary to consider the policy appropriateness and apply sufficient inserted data to improve the accuracy of the model. This study is meaningful because it identified the potential of new measurements for land price verification. There are, however, limits to this study requiring additional research with enlarged spatial and temporal ranges."
딥러닝 기반 적외선 객체 검출을 위한 적대적 공격 기술 연구,2021,"['Adversarial Attack', 'Infrared Object Detection', 'Deep Learning', '적대적 공격', '적외선 객체 검출', '딥러닝']",,"Recently, infrared object detection(IOD) has been extensively studied due to the rapid growth of deep neural networks(DNN). Adversarial attacks using imperceptible perturbation can dramatically deteriorate the performance of DNN. However, most adversarial attack works are focused on visible image recognition(VIR), and there are few methods for IOD. We propose deep learning-based adversarial attacks for IOD by expanding several state-of-the-art adversarial attacks for VIR. We effectively validate our claim through comprehensive experiments on two challenging IOD datasets, including FLIR and MSOD."
딥러닝 기반 OpenPose를 이용한 한국 수화 동작 인식에 관한 연구,2021,"['딥러닝', '한국 수화', '수화인식', 'Deep Learning', 'CNN', 'OpenPose', 'Korea Sign Language', 'Sign Language Recognition']",,"Most of the studies on the existing sign language use expensive equipment or do not consider non-manual signals. In order to improve this problem, we intend to acquire an image using an RGB camera and recognize sign language by including non-manual signals, which take a considerable weight in sign language, beyond recognizing only the existing hand shape. By using the OpenPose library, hand gestures, body gestures, and facial expressions were represented in the data as key points and were included as the non-manual signals. In addition, we propose a method of learning data using a deep learning neural network model and recognizing sign language motion through the trained model. In this paper, the goal is to increase the recognition rate for each sign language motion without the help of a specific sensor or wearable device because it learns data including non-manual elements and recognizes sign language motions."
딥러닝 전이학습의 가능성 검토: 부동산 분야를 사례로,2021,"['딥러닝', '전이학습', '신경망 모형', '부동산', '은닉층', 'Deep Learning', 'Transfer Learning', 'Neural Network', 'Real Estate', 'Hidden Layer']",,"It is generally not a good idea to train a deep learning algorithm from scratch because it demands significantly large amount of data. Transfer learning technique is exploited in this study to overcome a sparse data problem in real estate industry. A dense neural network (DNN) is a universal algorithm to process structured data, and was utilized to estimate property price. In this case, the transfer learning did not show acceptable performance. In addition, a convolutional neural network (CNN), an algorithm specialized for unstructured data such as imagery data, was employed to classify a building usage based on the front-view of photographs collected. It was found that the transfer learning of CNN worked relatively well in image classification tasks. For structured data, the poor performance of the DNN could be attributed to the inefficiency of hidden layers and insufficient number of hidden layers used. In contrast, this study attributed excellent performance of the CNN to the efficiency of convolutional layers, and sufficient number of hidden layers used (50 layers)."
딥러닝을 이용한 자율 이륙 드론 알고리즘 제안,2021,"['Drone', 'Deep learning', 'Free space detection', 'Autonomous flight', '드론', '딥러닝', '빈 공간 검출', '자율 비행']","본 연구는 객체 검출기를 이용하여 숲 혹은 그에 준하는 복잡한 환경에서의 이륙에 대한 시스템을 제안한다. 시뮬레이터에서 대각선상의 모터간 550mm의 길이를 갖는 쿼드콥터에 라즈베리파이를 장착하여 엣지 컴퓨팅 기반으로 실험을 진행한다. 학습에 사용될 이미지는 군산대학교 내부의 세 지점을 선정하여 640*480 사이즈의 이미지를 150장 내외 정도 획득하였으며, 이들을 흑백으로 변환한 다음, 127의 경계값을 두어 이진화 전처리를 하였다. 이후 SSD_Inception 모델을 학습 하였다. 시뮬레이션상에서 검증용 영상을 입력으로 학습한 모델을 통해 드론을 이륙시키는 실험 결과, 라벨을 이용하여 이륙했을 때와 유사한 궤적을 그려내었다.","This study proposes a system for take-off in a forest or similar complex environment using an object detector. In the simulator, a raspberry pi is mounted on a quadcopter with a length of 550mm between motors on a diagonal line, and the experiment is conducted based on edge computing. As for the images to be used for learning, about 150 images of 640*480 size were obtained by selecting three points inside Kunsan University, and then converting them to black and white, and pre-processing the binarization by placing a boundary value of 127. After that, we trained the SSD_Inception model. In the simulation, as a result of the experiment of taking off the drone through the model trained with the verification image as an input, a trajectory similar to the takeoff was drawn using the label."
딥러닝과 LDA 모델링을 통한 AI 분야 장기특허 예측,2021,"['인공지능', '기계학습', '장기특허', '딥러닝 모델', '토픽 모델링', 'Artificial intelligence', 'Machine learning', 'Long-term patents', 'Deep-learning model', 'Topic modeling']","본 논문에서는 최근 10년간 등록된 인공지능과 기계학습 분야 특허들을 대상으로 향후 20년간 특허 권리가 유지될 장기특허를 판별, 예측하고 이들의 내용을 LDA 모델링으로 분석하여 인공지능 분야의 기술정책 방향을 제시한다. 딥러닝 모델을 통해 약 16만 건의 미국 특허청 등록 특허의 장기특허 여부를 학습하였으며, 학습된 모델을 3,281개의 인공지능과 기계학습 분야 특허들에 적용하여 장기특허로 예측되는 2,004개의 특허를 판별하였다. 도출된 2004개의 장기특허에 대한 LDA 모델링을 수행하였으며, 장기전략적으로 중요해질 6개의 주요 토픽들을 확인하였다. 또한, 기술통계치와 통계 분석을 통해 인공지능분야 내 장기특허와 단기특허 간 차이점에 대해 알아보았으며, LDA 토픽 모델링을 통해 도출된 결과와 함께, 향후 인공지능 분야에서 고려되어야 할 정책적 함의들에 대해 종합적으로 논의하였다.","This study predicts the long-term continuance of patents and analyzes their content based on deep-learning and latent Dirichlet allocation modeling. To predict the long-term continuance of patents, we develop a deep-learning model based on 160 thousand patents submitted to the United States Patent and Trademark Office. The model is applied to 3,281 patents for artificial intelligence of which 2,004 are predicted to remain registered long-term. The long-term patents are analyzed using the latent Dirichlet allocation modeling, and are contrasted with short-term patents. The analysis leads to the discovery of six major topics associated with log-term patents. Several policy implications are drawn."
딥러닝 기반 LNGC 화물창 스캐닝 점군 데이터의 비계 시스템 객체 탐지 및 후처리,2021,"['PointNet(포인트넷)', 'Deep learning(딥러닝)', 'Point cloud(스캐닝 점군 데이터)', 'Object classification(객체 분류)', 'Object segmentation(객체 분할)']",,"Recently, quality control of the Liquefied Natural Gas Carrier (LNGC) cargo hold and block-erection interference areas using 3D scanners have been performed, focusing on large shipyards and the international association of classification societies. In this study, as a part of the research on LNGC cargo hold quality management advancement, a study on deep-learning-based scaffolding system 3D point cloud object detection and post-processing were conducted using a LNGC cargo hold 3D point cloud. The scaffolding system point cloud object detection is based on the PointNet deep learning architecture that detects objects using point clouds, achieving 70% prediction accuracy. In addition, the possibility of improving the accuracy of object detection through parameter adjustment is confirmed, and the standard of Intersection over Union (IoU), an index for determining whether the object is the same, is achieved. To avoid the manual post-processing work, the object detection architecture allows automatic task performance and can achieve stable prediction accuracy through supplementation and improvement of learning data. In the future, an improved study will be conducted on not only the flat surface of the LNGC cargo hold but also complex systems such as curved surfaces, and the results are expected to be applicable in process progress automation rate monitoring and ship quality control."
딥러닝 기반의 다중 클라우드 환경에서 빅 데이터의 안전성을 보장하기 위한 비대칭 데이터 저장 관리 기법,2021,"['클라우드', '빅 데이터', '비대칭', '딥러닝', '연계 정보', '로드 밸런스', 'Cloud', 'Big data', 'Asymmetry', 'Deep learning', 'Link information', 'Load balance']",,
딥러닝 기술을 이용한 캐비테이션 자동인식에 대한 연구,2021,"['Tip Vortex Cavitation(TVC', '날개 끝 보텍스 캐비테이션)', 'Cavitation Inception Speed(CIS', '캐비테이션 초생속력)', 'Convolution Neural Network(CNN', '합성곱 신경망)', 'Deep learning(딥러닝)', 'Image recognition(영상인식)']",,"The main source of underwater radiated noise of ships is cavitation generated by propeller blades. After the Cavitation Inception Speed (CIS), noise level at all frequencies increases severely. In determining the CIS, it is based on the results observed with the naked eye during the model test, however accuracy and consistency of CIS values are becoming practical issues. This study was carried out with the aim of developing a technology that can automatically recognize cavitation images using deep learning technique based on a Convolutional Neural Network (CNN). Model tests on a three-dimensional hydrofoil were conducted at a cavitation tunnel, and tip vortex cavitation was strictly observed using a high-speed camera to obtain analysis data. The results show that this technique can be used to quantitatively evaluate not only the CIS, but also the amount and rate of cavitation from recorded images."
딥러닝 기법을 활용한 컨테이너선 운임 예측 모델,2021,[],"해운 시황을 예측하는 것은 중요한 문제이다. 투자 방식의 결정, 선대 편성 방법, 운임 등을 결정하기 위한 판단 근거가 되며 이는 기업의 이익과 생존에 큰 영향을 미치기 때문이다. 이를 위해 본 연구에서는 기계학습 모델인 장단기 메모리 및 간소화된 장단기 메모리 구조의 Gated Recurrent Units를 활용하여 컨테이너선의 해상운임 예측 모델을 제안한다. 운임 예측 대상은 중국 컨테이너 운임지수(CCFI)이며, 2003년 3월부터 2020년 5월까지의 CCFI 데이터를 학습에 사용하였다. 각 모델에 따라 2020년 6월 이후의 CCFI를 예측한 후 실제 CCFI와 비교, 분석하였다. 실험 모델은 하이퍼 파라메터의 설정에 따라 총 6개의 모델을 설계하였다. 또한 전통적인 분석 방법과의 성능을 비교하기 위해 ARIMA 모델도 실험에 추가하였다. 최적 모델은 두 가지 방법에 따라 선정하였다. 첫 번째 방법으로 각 모델을 10회 반복 실험하여 얻은 RMSE의 평균값이 가장 작은 모델을 선정하는 것이다. 두 번째 방법으로는 모든 실험에서 가장 낮은 RMSE를 기록한 모델을 선정하는 것이다. 실험 결과 전통적 시계열 예측모델인 ARIMA 모델과 비교하여 딥러닝 모델의 정확도를 입증하였으며, 정확한 예측모델을 통해 운임 변동의 위험관리 능력을 제고시키는데 기여했다. 반면 코로나19와 같은 외부 효과에 따른 운임의 급격한 변화상황이 발생한 경우, 예측모델의 정확도가 감소하는 한계점을 나타냈다. 제안된 모델 중 GRU1 모델이 두 가지 평가 방법 모두에서 가장 낮은 RMSE(69.55, 49.35)를 기록하며 최적 모델로 선정되었다.",
고해상도 정사영상을 이용한 딥러닝 기반의 산림수종 분류에 관한 연구,2021,"['딥러닝', '컨볼루션 신경망', '드론', '정사영상', '수종분류', 'Deep learning', 'CNN', 'Drone', 'Orthophoto', 'Species classification']",,"In this study, we evaluated the accuracy of deep learning-based tree species classification model trained by using high-resolution images. We selected five species classed, i.e., pine, birch, larch, korean pine, mongolian oak for classification. We created 5,000 datasets using high-resolution orthophoto and forest type map. CNN deep learning model is used to tree species classification. We divided training data, verification data, and test data by a 5:3:2 ratio of the datasets and used it for the learning and evaluation of the model. The overall accuracy of the model was 89%. The accuracy of each species were pine 95%, birch 89%, larch 80%, korean pine 86% and mongolian oak 98%."
딥러닝 기반의 한글 폰트 연구를 위한 한글 폰트 데이터셋,2021,"['Deep Learning', 'Font Data', 'Automatic Font Generation', 'Hangul Font Dataset', 'Hangul Font', '딥러닝', '폰트데이터', '폰트자동생성', '한글데이터셋', '한글폰트']",,"Recently, as interest in deep learning has increased, many researches in various fields using deep learning techniques have been conducted. Studies on automatic generation of fonts using deep learning-based generation models are limited to several languages such as Roman or Chinese characters. Generating Korean font is a very time-consuming and expensive task, and can be easily created using deep learning. For research on generating Korean fonts, it is important to prepare a Korean font dataset from the viewpoint of process automation in order to keep pace with deep learning-based generation models. In this paper, we propose a Korean font dataset for deep learning-based Korean font research and describe a method of constructing the dataset. Based on the Korean font data set proposed in this paper, we show the usefulness of the proposed dataset configuration through the process of applying it to a deep learning Korean font generation application."
딥러닝 기반 영상처리 기법 및 표준 운동 프로그램을 활용한 비대면 온라인 홈트레이닝 어플리케이션 연구,2021,[],"최근 AR, VR 및 스마트 디바이스 기술의 발전에 따라 피트니스 산업에서도 비대면 환경을 기반으로 한 서비스 수요가 증가하고 있다. 비대면 온라인 홈트레이닝 서비스는 기존의 오프라인 서비스에 비해 시간과 장소의 제약이 없다는 장점이 있으나 운동 기구의 부재 및 사용자의 정확한 운동 자세 유지여부, 운동량의 측정이 어려운 단점이 존재한다. 본 연구에서는 이러한 단점을 보완할 수 있는 표준 운동 프로그램을 개발하고 딥러닝 기반 신체 자세 추정 영상처리를 통하여 새로운 비대면 홈트레이닝 어플리케이션 알고리즘을 제안한다. 본 연구의 알고리즘 기반 어플리케이션을 활용한다면 표준 운동 프로그램 영상의 트레이너를 사용자가 직접 보고 따라하면서 사용자 스스로 자세를 교정하며 정확한 운동이 가능하다. 나아가 본 연구의 알고리즘을 용도에 맞게 커스터마이징 한다면 공연, 영화, 동아리 활동, 컨퍼런스 분야로의 적용도 가능할 것이다.",
딥러닝 중심의 자연어 처리 기술 현황 분석,2021,"['자연어 처리', '기계학습', '딥러닝', '데이터셋', '평가지표', 'NLP', 'machine learning', 'deep learning', 'data set', 'evaluation measures']",,"The performance of natural language processing is rapidly improving due to the recent development and application of machine learning and deep learning technologies, and as a result, the field of application is expanding. In particular, as the demand for analysis on unstructured text data increases, interest in NLP(Natural Language Processing) is also increasing. However, due to the complexity and difficulty of the natural language preprocessing process and machine learning and deep learning theories, there are still high barriers to the use of natural language processing.In this paper, for an overall understanding of NLP, by examining the main fields of NLP that are currently being actively researched and the current state of major technologies centered on machine learning and deep learning, We want to provide a foundation to understand and utilize NLP more easily. Therefore, we investigated the change of NLP in AI(artificial intelligence) through the changes of the taxonomy of AI technology. The main areas of NLP which consists of language model, text classification, text generation, document summarization, question answering and machine translation were explained with state of the art deep learning models. In addition, major deep learning models utilized in NLP were explained, and data sets and evaluation measures for performance evaluation were summarized.We hope researchers who want to utilize NLP for various purposes in their field be able to understand the overall technical status and the main technologies of NLP through this paper."
딥러닝 기반 교재 문항 검출 실험 연구,2021,"['Deep Learning', 'Textbook Questionnaires Detection Model', 'Detection Model', 'Computer Vision', '딥러닝', '문항인식모형', '검출모형', '컴퓨터 비전']",,"Recently, research on edutech, which combines education and technology in the e-learning field called learning, education and training, has been actively conducted, but it is still insufficient to collect and utilize data tailored to individual learners based on learning activity data that can be automatically collected from digital devices. Therefore, this study attempts to detect questions in textbooks or problem papers using artificial intelligence computer vision technology that plays the same role as human eyes. The textbook or questionnaire item detection model proposed in this study can help collect, store, and analyze offline learning activity data in connection with intelligent education services without digital conversion of textbooks or questionnaires to help learners provide personalized learning services even in offline learning."
딥러닝을 활용한 시조의 유형 고찰 - 영남가단과 호남가단의 시조를 중심으로,2021,"['AI(Artificial intelligence)', 'Deep Learning', 'Sijo', 'Yeongnam-Gadan(嶺南歌壇)', 'Honam- Gadan(湖南 歌壇)', 'Korean Sijo Dictionary', '인공지능(AI)', '딥러닝', '시조', '영남가단', '호남가단', '한국시조대사전']",,"Artificial intelligence is rapidly developing day by day. Now it is becoming a part of our lives, not just business sites or engineers’ labs. The role of artificial intelligence is becoming increasingly important in literary research, and the necessity and possibility of artificial intelligence is increasingly proven in fields that target a variety of writers and works created over a long period of time, such as the founder. And artificial intelligence, ‘classification’ is often used regardless of life and research. Classification is used in many parts of everyday life, and classification is a very important methodology in literary research. Thus, this study attempted to analyze the Sijo by combining deep learning of artificial intelligence with the methodology of classification.Using a deep learning classification algorithm, 299 and 290 works of Yeongnam and Honam were trained, and 4,736 works of the “Korean Sijo Dictionary” were classified in earnest. As a result, 3,758 works (79.4%) were closely related to the two bands. This shows the status of the two bands in the history of Sijo literature. According to deep learning analysis of 299 works by artists from Yeongnam Gadan and 290 works by artists from Honam Gadan, 281 works for the former and 229 works for the latter were highly related to each band. This confirmed the potential for deep learning to be utilized in the Sijo study.On the other hand, although the frequency was not high, the 7th number of Yeongnam Gadan and 35th number of Honam Gadan were the opposite. This reflects differences in the relationship and creative environment of authors not included in the deep learning classification algorithm, which is a meaningful conclusion in that it suggests that external factors as well as internal characteristics of the work should be considered. Other writers who did not belong to any of the two bands were also able to be understood as a result of a combination of the writer’s life, friendship, and entering and leaving office.This study still remains level of attempt that examines classical literature as a new methodology called artificial intelligence. We will make up for this in the future."
딥러닝을 이용한 하천 유량 예측 알고리즘,2021,"['중기 단기 기억', '유량', '예측', '딥러닝', '알고리즘', 'Long Term Short Term Memory', 'Flow Rate', 'Prediction', 'Deep Learning', 'Algorithm']","본 논문은 학문적인 이해를 기반을 둔 예측을 수행하기 위해 FDNN(: Flood drought index neural network) 알고리즘을 제시한다. 데이터에 의존한 예측이 아닌 학문적인 이해를 기반을 둔 예측을 딥러닝에 적용하기 위해, 알고리즘을 수리, 수문학을 기반으로 구성하였다. 강수량의 입력으로 하천의 유량을 예측하는 모델을 구성하여 K-교차검증을 통해 모델의 성능을 측정한다. 제시한 알고리즘의 성능을 증명하기 위해 시계열 예측에서 가장 많이 사용되는 LSTM(: Long short term memory) 알고리즘의 예측 성능과 비교하여 제시한 알고리즘의 우수성을 나타낸다.","In this paper, we present FDNN algorithm to perform prediction based on academic understanding. In order to apply prediction based on academic understanding rather than data-dependent prediction to deep learning, we constructed algorithm based on mathematical and hydrology. We construct a model that predicts flow rate of a river as an input of precipitation, and measure the model s performance through K-fold cross validation."
딥러닝 기법과 잔차 크리깅을 이용한 지가 예측,2021,"['공간적 상관성', '심층신경망', '잔차 크리깅', '지가', 'Deep neural network', 'land price', 'residual kriging', 'spatial autocorrelation']","본 연구에서는 지가 예측의 고도화를 위하여 딥러닝 기법과 잔차 크리깅을 결합한 DNNRK 모형을 제안하고 그 성능을 검증하였다. 연구지역은 서울시 강남 3구이며 가격자료는 감정평가사가 평가한 표준지 공시지가를 기반으로 하였다. 제안된 모형의 성능은 검증 데이터에 대한 선형회귀모형, 회귀크리깅, 딥러닝의 예측결과를 통계적 지표 (MAE, RMSE, MAPE, COD) 비교를 통해 평가하였다. 모형 성능을 비교한 결과, DNNRK 모형의 가격 예측력이 다른 모형과 비교하여 우수함을 확인할 수 있었다. 본 연구에서는 지가가 물리적 속성 정보뿐만 아니라 위치 정보에 영향을 받는다는 개념을 고려하여 제안된 DNNRK 모형을 적용되었다. 따라서 이러한 결과는 지역 요인으로 대표되는 공간적 상관성을 모형에 투입할 경우 지가 예측력의 상승 효과를 가져온다는 것을 의미한다.","This study is propose the conjunction models of deep neural network and residual kriging (DNNRK) for advancement of land price estimation and validate its performance. Seoul (Gangnam 3 District) was chosen as a study area and we collected land prices of standard lots estimated by appraiser. When inspecting the model performance based on the test data, we confirmed that the land price accuracy form the DNNRK model was improved substantially compared with that of the OLS, DNN and RK. Therefore, these results indicate that introducing spatial autocorrelation as a location factor to models can improve the performance of land price prediction significantly. Furthermore, DNNRK model coupling DNN and residual kriging can be an effective alternative for estimating the land price accurately."
딥러닝을 활용한 모바일 어플리케이션 리뷰 분류에 관한 연구,2021,"['모바일 배달 어플리케이션', '사용자 리뷰 분류', '사용자 리뷰 분류법', 'Mobile Delivery Application', 'User review classification', 'User Reviews Taxonomy']","스마트폰과 태블릿과 같은 스마트 기기의 발달과 사용이 증가함에 따라, 모바일 기기를 기반으로 한 모바일 어플리케이션 시장이 급속도로 커지고 있다. 모바일 어플리케이션 사용자는 어플리케이션을 사용 경험을 공유하고자 리뷰를 남기는데, 이를 분석하면 소비자들의 다양한 니즈를 파악할 수 있고 어플리케이션 개발자들은 소비자들이 작성한 리뷰를 통해 애플리케이션의 개선을 위한 유용한 피드백을 받을 수 있다. 그러나 소비자들의 남기는 많은 양의 리뷰를 수작업으로 분석하기 위해서는 많은 시간과 비용을 지불해야하기 때문에 이를 최소화 할 방안을 마련할 필요성이 존재한다. 이에 본 연구에서는 구글 플레이스토어(Google PlayStore)의 배달 어플리케이션 사용자 리뷰를 수집한 후 머신러닝과 딥러닝 기법을 활용하여 어플리케이션 기능 장점, 단점, 기능 개선 요청, 버그 보고의 4가지 범주로 분류하는 방법을 제안한다. 연구 결과, Hugging Face의 pretrain된 BERT기반 Transformer모델의 성능의 경우 위의 4개의 범주에 대한 f1 score값은 차례대로 0.93, 0.51, 0.76, 0.83으로 LSTM, GRU보다 뛰어난 성능을 보인 것을 확인할 수 있었다.","With the development and use of smart devices such as smartphones and tablets increases, the mobile application market based on mobile devices is growing rapidly. Mobile application users write reviews to share their experience in using the application, which can identify consumers various needs and application developers can receive useful feedback on improving the application through reviews written by consumers. However, there is a need to come up with measures to minimize the amount of time and expense that consumers have to pay to manually analyze the large amount of reviews they leave. In this work, we propose to collect delivery application user reviews from Google PlayStore and then use machine learning and deep learning techniques to classify them into four categories like application feature advantages, disadvantages, feature improvement requests and bug report. In the case of the performance of the Hugging Face s pretrained BERT-based Transformer model, the f1 score values for the above four categories were 0.93, 0.51, 0.76, and 0.83, respectively, showing superior performance than LSTM and GRU."
전이학습기반 앙상블 딥러닝을 이용한 COVID-19 환자 영상 분류,2021,"['딥러닝', '스태킹 앙상블', '전이학습', 'X-ray/CT 영상', 'COVID-19', 'deep learning', 'stacking ensemble', 'transfer learning', 'X-ray/CT image']","COVID-19 팬데믹으로 인한 피해는 공중 보건적 측면 뿐 만 아니라 정치, 경제, 사회, 문화 전반에 심각한 영향을 미치고 있다. 현재까지 COVID-19 표준 진단검사인 RT-PCR 검사는 검체의 종류, 검체 채취 방법 및 보관에 따라 검사 결과가 달라질 수 있고 코로나바이러스 (SARS-CoV-2) 감염 후 검사 시점에도 영향을 받는다. 본 논문은 전이학습 (transfer learning) 기반 앙상블 딥러닝을 사용하여 COVID-19 환자 X-ray/CT 영상을 분류하고자 한다. 여기서 사용된 전이학습은 CNN (convolutional neural network) 기반인 AlexNet, ResNet, Inception V3, DenseNet 모형이다. 본 연구에서 제안한 스태킹 앙상블 (stacking ensemble) 모형은 세 단계에 걸쳐 이루어진다. 첫 번째 단계에서는 기본모형 (base model)로서 여러 전이학습 모형을 이용하여 예측된 결과들을 얻고, 두 번째 단계에서는 concatenate layer를 통해 이들 결과들을 결합한 다음, 세 번째 단계에서는 메타모형(meta model), 여기서는 DNN (deep neural network) 모형을 적용하여 최종 분류한다. 본 논문에서 제안된 앙상블 모형의 성능평가를 위해 3가지 실제 COVID-19 환자의 X-ray/CT 영상데이터셋을 고려하였으며 여러 가지 성능평가 지표를 가지고 기존의 전이학습 모형과 앙상블 모형과 비교 분석하였다. 성능실험결과, 전반적으로 제안된 앙상블 모형이 기존의 전이학습 모형과 앙상블 모형보다 우수함을 보였다.","The damage caused by the COVID-19 pandemic has a serious impact not only on public health but also on politics, economy, society, and culture as a whole. To date, the RT-PCR test, a COVID-19 standard diagnostic test, may vary depending on the type of sample, sample collection method, and storage, and is also affected by the time of the test after infection with COVID-19. This paper attempts to classify COVID-19 patients with X-ray/CT images using transfer learning-based ensemble deep learning. The transfer learning used here is the AlexNet, ResNet, Inception V3, and DenseNet models based on the convolutional neural network (CNN). The stacking ensemble model proposed in this study takes place over three stages. In the first step, predicted results are obtained using several transfer learning models, in the second step, they are combined through a concatenate layer, and in the third step, a deep neural network (DNN) model is applied and finally classified. For the performance evaluation of the ensemble model proposed in this paper, three actual COVID-19 X-ray/CT image datasets were considered, and various performance evaluation indicators were compared and analyzed with the transfer learning model and the existing ensemble model. As a result of the performance experiment, the overall proposed ensemble model was superior to the transfer learning model and the existing ensemble model."
딥러닝 기반 한우 승가행위 검출 시스템,2021,"['승가행위', '딥러닝 모델', '객체인식', '텐서플로우', '전이학습', 'Mounting', 'Deep Learning Model', 'Object Detection', 'TensorFlow', 'Transfer Learning']",,
"딥러닝 경량화를 위한 구조, 가지치기, 지식증류 비교",2021,"['Deep learning', 'Structure Reduction', 'Pruning', 'Knowledge Distillation', 'CIFAR10/100', 'ResNet56/110']",,"We compare three approaches of structure reduction, pruning, and knowledge distillation for lightning of a deep learning network. Structure reduction eliminates a set of layers of the model, but pruning deletes filters within a layer. Knowledge distillation effectively learns a small student model from a large teacher model using KL Divergence. Therefore, it has a similar effect of reduction of the model. The above three methods for lightning are rarely compared to each other in terms of performance. To compare these approaches for network reduction problem, we investigate the accuracy and flops of the methods on CIFAR10 and CIFAR100 data for ResNet models. A systematic analysis for the fundamental orientations and differences of each method is supplemented."
딥러닝을 이용한 풍력 발전량 예측,2021,"['풍력발전', '예측', '머신 러닝', '다중 퍼셉트론', '재귀 신경망', '중기 단기 기억', '인공지능', '전력량', 'Wind power', 'prediction', 'LSTM(:Long short term memory)', 'CNN(:Cellular neural network)', 'Artificial intelligence']","본 연구는 풍력발전의 합리적인 운영 계획과 에너지 저장창치의 용량산정을 위한 풍력 발전량을 예측한다. 예측을 위해 물리적 접근법과 통계적 접근법을 결합하여 풍력 발전량의 예측 방법을 제시하고 풍력 발전의 요인을 분석하여 변수를 선정한다. 선정된 변수들의 과거 데이터를 수집하여 딥러닝을 이용해 풍력 발전량을 예측한다. 사용된 모델은 Bidirectional LSTM(:Long short term memory)과 CNN(:Convolution neural network) 알고리즘을 결합한 하이브리드 모델을 구성하였으며, 예측 성능 비교를 위해 MLP 알고리즘으로 이루어진 모델과 오차를 비교하여, 예측 성능을 평가하고 그 결과를 제시한다.","This study predicts the amount of wind power generation for rational operation plan of wind power generation and capacity calculation of ESS. For forecasting, we present a method of predicting wind power generation by combining a physical approach and a statistical approach. The factors of wind power generation are analyzed and variables are selected. By collecting historical data of the selected variables, the amount of wind power generation is predicted using deep learning. The model used is a hybrid model that combines a bidirectional long short term memory (LSTM) and a convolution neural network (CNN) algorithm. To compare the prediction performance, this model is compared with the model and the error which consist of the MLP(:Multi Layer Perceptron) algorithm, The results is presented to evaluate the prediction performance."
딥러닝 기반 특징 앙상블을 사용한 MRI 영상의 뇌종양 분류,2021,"['Artificial intelligence', 'Machine learning', 'Deep learning', 'Brain tumor classification', 'Transfer learning', 'Ensemble learning', '인공지능', '기계학습', '딥러닝', '뇌 종양 분류', '전이 학습', '앙상블 학습']",뇌 MRI 영상의 자동 분류는 뇌종양의 조기 진단을 하는 데 있어 중요한 역할을 한다. 본 연구에서 우리는 심층 특징 앙상블을 사용한 MRI 영상에서의 딥 러닝 기반 뇌종양 분류 모델을 제안한다. 우선 사전 학습된 3개의 합성 곱 신경망을 사용하여 입력 MRI 영상에 대한 심층 특징들을 추출한다. 그 이후 추출된 심층 특징들은 완전 연결 계층들로 구성된 분류 모듈의 입력 값으로 들어간다. 분류 모듈에서는 우선 3개의 서로 다른 심층 특징들 각각에 대해 먼저 완전 연결 계층을 거쳐 특징 차원을 줄인다. 그 이후 3개의 차원이 준 특징들을 결합하여 하나의 특징 벡터를 생성한 뒤 다시 완전 연결 계층의 입력값으로 들어가서 최종적인 분류 결과를 예측한다. 우리가 제안한 모델을 평가하기 위해 웹상에 공개된 뇌 MRI 데이터 셋을 사용하였다. 실험 결과 우리가 제안한 모델이 다른 기계학습 기반 모델보다 더 좋은 성능을 나타냄을 확인하였다.,"Automatic classification of brain MRI images play an important role in early diagnosis of brain tumors. In this work, we present a deep learning-based brain tumor classification model in MRI images using ensemble of deep features. In our proposed framework, three different deep features from brain MR image are extracted using three different pre-trained models. After that, the extracted deep features are fed to the classification module. In the classification module, the three different deep features are first fed into the fully-connected layers individually to reduce the dimension of the features. After that, the output features from the fully-connected layers are concatenated and fed into the fully-connected layer to predict the final output. To evaluate our proposed model, we use openly accessible brain MRI dataset from web. Experimental results show that our proposed model outperforms other machine learning-based models."
딥러닝 기반 탄성파 단층 해석을 위한 합성 학습 자료 생성,2021,"['딥 러닝', '학습 자료', '단층 해석', '합성곱 신경망', '합성 탄성파 자료', 'deep learning', 'training data', 'fault interpretation', 'convolutional neural network', 'synthetic seismic data']",,"Fault detection in seismic data is well suited to the application of machine learning algorithms. Accordingly, various machine learning techniques are being developed. In recent studies, machine learning models, which utilize synthetic data, are the particular focus when training with deep learning. The use of synthetic training data has many advantages; Securing massive data for training becomes easy and generating exact fault labels is possible with the help of synthetic training data. To interpret real data with the model trained by synthetic data, the synthetic data used for training should be geologically realistic. In this study, we introduce a method to generate realistic synthetic seismic data. Initially, reflectivity models are generated to include realistic fault structures, and then, a one-way wave equation is applied to efficiently generate seismic stack sections. Next, a migration algorithm is used to remove diffraction artifacts and random noise is added to mimic actual field data. A convolutional neural network model based on the U-Net structure is used to verify the generated synthetic data set. From the results of the experiment, we confirm that realistic synthetic data effectively creates a deep learning model that can be applied to field data."
딥러닝을 활용한 실내 사람 수 추정을 위한 WiFi CSI 데이터 전처리와 증강 기법,2021,[],"사람 수 추정은 스마트 홈, 스마트 빌딩, 스마트 자동차 등과 같은 응용 서비스를 제공하기 위해 중요한 기술이다. 최근 COVID-19의 영향으로 사회적 거리두기가 시행되면서 사람 수 추정 기술은 새롭게 주목받고 있다. 사람 수 추정 시스템은 서비스 요구사항에 따라 카메라, 센서, 무선 등과 같은 다양한 방법으로 구현 가능하다. WiFi AP를 활용한 사람 수 추정 방식은 다중경로 정보를 반영하는 WiFi CSI를 활용하는 기술로 낮은 비용으로 실내에서 사용하기에 효과적이다. 기존에 제안된 WiFi CSI 기반 사람 수 추정 시스템은 정확도가 낮아 고품질 서비스를 제공하기 어렵다. 본 논문은 WiFi CSI 데이터에 기반한 딥러닝 사람 수 추정 시스템을 제안한다. 오토인코더를 활용한 데이터 전처리 방식, WiFi CSI 데이터를 변형하는 데이터 증강 기법, 그리고 딥러닝 모델링을 통해 추정 정확도를 높인다. 실험 결과 제안하는 시스템은 최대 6명에 대해 89.29%의 정확도를 보였다.",
딥러닝의 반복적 예측방법을 활용한 철근 가격 장기예측에 관한 실험적 연구,2021,"['Recursive prediction method', 'Long term prediction', 'Rebar price prediction', '반복적 예측방식', '장기예측', '철근 가격예측']","본 연구는 딥러닝의 반복적 예측방식을 활용하여 5개월의 철근 가격 예측방법을 제안한다. 이 방식은 입력데이터의 특성을 모두 단기예측하여 원 데이터에 추가하고, 추가된 데이터로 다음의 시점을 예측하는 과정을 반복하여 장기 예측한다. 본 연구에서 제시하는 방식으로 1개월에서 5개월까지 예측한 철근 가격의 예측 평균 정확도는 약 97.24%이다. 제안된 방식을 통해 인간의 경험과 판단을 통한 가격 추정방법의 체계성을 보완하여 기존의 방식보다 정확한 비용계획이 가능할 것으로 사료된다. 또 철근 이외의 건축재료를 비롯하여 시계열 데이터로 가격을 장기예측하는 연구에서 본 연구에서 제시한 방법이 활용될 수 있을 것으로 기대한다.",
딥러닝 기반 이미지 처리를 이용한 통행 차량 높이검출 시스템,2021,"['Deep Learning', 'Height Detection', 'Image Process', 'RCNN', 'Yolo V3']","4차 산업 혁명의 시대가 열리면서, 인공지능을 활용한 연구에 관심이 증가하고 있다. 본 연구에서는 최근 들어 차량의 높이가 점차적으로 높아짐에 따라 발생하는 충돌 사고를 방지하고자 인공지능을 활용하여 차량의 높이를 사전에 정확히 측정하는 시스템을 개발하고자 한다. 본 연구에서는 Yolo V3, Mask RCNN 등을 사용한 딥러닝 방식으로 차량의 높이 측정 시스템을 개발하였다. Yolo V3를 사용하여 픽셀을 대상 영역을 추출하였다. 또한, 픽셀의 대상 영역과 빈 영역에 대한 학습은 Mask RCNN을 사용하여 수행하였다. 특히, 기존 차량의 높이 데이터(1300~2000 mm, 총 63679 개)와 보정계수를 사용하여 측정 시스템의 정확도가 98 % 이상임을 확인하였다. 본 연구 결과는 차량의 높이를 미리 정확히 예측함으로써, 지하차도, 다리 등에서의 충돌 사고를 사전에 방지하는 시스템 또는 구조물을 설치할 수 있을 것으로 예상한다. 또한, 제조업체는 진입하는 차량의 높이를 사전에 예측하는 시스템 개발 시, 시행착오를 방지하고 개발 시간 및 비용을 절감할 수 있을 것으로 예상한다.","As the era of the 4th industrial revolution opens, interest in research using artificial intelligence is increasing. In this study, we developed a system that accurately measures the height of a vehicle using artificial intelligence in order to prevent collisions that occur as the heights of vehicles have gradually increased in recent years. In this study, a vehicle height-measurement system was developed using a deep learning method with Yolo V3, Mask RCNN, etc. The target area was extracted from a pixel by Yolo V3. In addition, learning for the target area and the empty area of a pixel was performed using Mask RCNN. It was confirmed that the accuracy of the measurement system was 98% or higher by using the height data of existing vehicles (1300-2000 mm, 63679 units in total) and a correction factor. The results of this study are expected to be used to install a system or structure that prevents collisions in underground roadways and bridges by accurately predicting the height of the vehicle. In addition, when developing a system that predicts the height of an entering vehicle, manufacturers are expected to avoid trial and error as well as reduce development time and cost."
딥러닝 기반의 오토 튜닝 PID 제어를 이용한 차량 경로 제어 모델 개발,2021,"['Vehicle path control(차량경로제어)', 'Deep learning(딥러닝)', 'Neural network(신경망)', 'Auto-tuning PID(오토 튜닝 PID)', 'Vehicle dynamics simulation(차량 동적 시뮬레이션)']",,
딥러닝 기반 도로위험객체 자동 인식 및 분류에 관한 연구,2021,"['객체 인식', '객체 분류', '딥러닝', '도로위험객체', 'Recognition', 'Classificatioin', 'Deep Learning', 'Road Dangerous Object', 'YOLO']",,"Various dangerous road objects such as potholes, falling objects, roadkills occur frequently on road, and the best way to prevent accidents from these dangers is to find them as soon as possible. A lot of mobile applications to report the road problems have been developed and in service worldwide both in public and private sectors. It is not safe, however, to report the problem using those apps in road environment, and it is necessary to develop a technology to minimize the time to make a report using the apps. For this purpose, a method to recognize and classify the road dangerous objects automatically from road images using deep learning algorithm was proposed and implemented, and the performance of the proposed model(YOLO v3) was tested, which shows 95% success rate on average to detect the four categories of road dangers including pavement, drainage, road facility, and roadkill, and demonstrates the possibility of the proposed method."
딥러닝을 이용한 통합형 취업사진 생성 앱 개발,2021,"['딥러닝', '생성적 적대 신경망', '영상 생성', '얼굴 합성', '모바일 앱', 'Deep learning', 'Generative adversarial network', 'Image generation', 'Face synthesis', 'Mobile application']",,"While the standard resume without photos has increasingly become common in South Korea, many companies still require applicants to include a personal photo in their resume. In recent years, many mobile applications have been released to take ID photos for resume. However, due to the lack of high-quality image support and the inability to synthesize hair-styles and suit-styles, these mobile applications cannot generate special purpose photos suitable for resume. In this paper, to generate high-quality and consolidated ID photos for resume, we propose a mobile application that can generate ID photos to synthesis hair-styles and suit-styles using the deep-learning algorithm, starGAN-v2, and that can retouch faces with simple makeup and background compositing. The proposed face synthesis algorithm can synthesize more natural faces through face area adjustment preprocessing and the generated face shows a high similarity of over 85.3% on average to the original face."
딥러닝 기반 단어 임베딩을 적용한 사진 자막 영작문 채점 시스템,2021,"['컴퓨터 언어보조학습', 'computer assisted language learning', '딥러닝', 'deep learning', '영작문', 'English writing', '단어 임베딩', 'word embedding', '준거참조검사', 'criterion-referenced test', '채점', 'scoring']",,"Since human grading of English writing requires substantial resources, many researchers in the area of Computer-Assisted Language Learning (CALL) have been focusing on automatic scoring systems based on natural language processing systems, machine learning, and other automatic processing mechanisms. English Testing Services (ETS) announced several automatic scoring systems for English writing. In this paper, we suggest using a deep learning based automatic scoring system for an English caption writing test. Our method involves using a sentence similarity measurement, which compares different levels of answer sentences with user writing input. We chose different word embedding types (Word2Vec, Word Mover‘s Distance (WMD), Bidirectional Encoder Representations from Transformers (BERT)) and Abstract Meaning Representation (AMR), a linguistic model for comparing semantic differences between two sentences based on semantic representation. Scoring systems should not only satisfy the requirements of complicated scoring rubrics but also meet the conditions of a language proficiency test. Our results show that BERT outperforms three competitive models in predicting accurate scoring levels and also shows the characteristics of the criterion reference which could theoretically express the standards of a language proficiency test."
딥러닝 기반 한국어 맞춤법 교정을 위한 오류 유형 분류 및 분석,2021,"['한국어 맞춤법 교정', '기계 번역', '인공신경망 기계번역', '오류 분석', '자연어처리', 'Korean spelling correction', 'Machine translation', 'Artificial neural network machine translation', 'Error analysis', 'Natural language processing']","최근 기계 번역 기술과 자동 노이즈 생성 방법론을 기반으로 한국어 맞춤법 교정 연구가 활발히 이루어지고 있다. 해당 방법론들은 노이즈를 생성하여 학습 셋과 데이터 셋으로 사용한다. 이는 학습에 사용된 노이즈 외의 노이즈가 테스트 셋에 포함될 가능성이 낮아 정확한 성능 측정이 어렵다는 한계점이 존재한다. 또한 실제적인 오류 유형 분류 기준이 없어 연구마다 사용하는 오류 유형이 다르므로 질적 분석에 어려움을 겪고 있다. 이를 해결하기 위해 본 논문은 딥러닝 기반 한국어 맞춤법 교정 연구를 위한 새로운 ’오류 유형 분류 체계‘를 제안하며 이를 바탕으로 기존 상용화 한국어 맞춤법 교정기(시스템 A, 시스템 B, 시스템 C)에 대한 오류 분석을 수행하였다. 분석결과, 세 가지 교정 시스템들이 띄어쓰기 오류 외에 본 논문에서 제시한 다른 오류 유형은 교정을 잘 수행하지 못했으며 어순 오류나 시제 오류의 경우 오류 인식을 거의 하지 못함을 알 수 있었다.","Recently, studies on Korean spelling correction have been actively conducted based on machine translation and automatic noise generation. These methods generate noise and use as train and data set. This has limitation in that it is difficult to accurately measure performance because it is unlikely that noise other than the noise used for learning is included in the test set In addition, there is no practical error type standard, so the type of error used in each study is different, making qualitative analysis difficult. This paper proposes new 'error type classification' for deep learning-based Korean spelling correction research, and error analysis perform on existing commercialized Korean spelling correctors (System A, B, C). As a result of analysis, it was found the three correction systems did not perform well in correcting other error types presented in this paper other than spacing, and hardly recognized errors in word order or tense."
딥러닝 기반의 기술가치평가와 평가변수 추정,2021,"['Technology Valuation', 'Deep Learning', 'Artificial Intelligence', 'Technology Assessment System', 'Sales Prediction', 'Qualitative Evaluation Indicators', '기술가치평가', '딥러닝', '인공지능', '기술평가시스템', '매출추정', '정성평가지표']","국내 산업성장의 동력이 되는 기업의 기술 및 사업역량 확보를 위해, 2014년 이후 정부기관을 중심으로 『기술거래 시장 활성화』, 『기술금융 기반의 R&D 사업화지원』등 다양한 형태로 사업화 성과창출을 위한 정책 프로그램이 수행되어 왔다. 현재까지 기술가치평가 이론과 평가변수에 관한 다양한 연구가 각계 전문가들에 의해 수행되고 기술사업화 현업에서 이용되어 왔으나, 평가현장에서는 평가목적 상의 기대보다 기술가치평가 금액이 적게 산출되는 등의 한계점이 존재하여, 그 실용성에 의문이 제기되어 왔다. 또한 미래에 대한 정성적 추정에 기반한 현행 기술가치평가 프로세스는 평가결과에 대한 객관성과 신뢰성 확보를 위해 데이터에 근거한 참조 인프라 구축이 필요한 시기에 이르렀다. 본 연구에서는 기관별로 구축된 평가인프라를 살펴보고, 최신의 인공신경망 및 딥러닝 기술을 기술가치평가 시스템에 탑재하기 위해 핵심변수 기반의 가치금액 추정 시뮬레이션과 매출액 및 정성평가점수의 예측을 위한 적용 가능성을 살펴본다.","For securing technology and business competences of companies that is the engine of domestic industrial growth, government-supported policy programs for the creation of commercialization results in various forms such as 『Technology Transaction Market Vitalization』 and 『Technology Finance-based R&D Commercialization Support』have been carried out since 2014. So far, various studies on technology valuation theories and evaluation variables have been formalized by experts from various fields, and have been utilized in the field of technology commercialization. However, Their practicality has been questioned due to the existing constraint that valuation results are assessed lower than the expectation in the evaluation sector. Even considering that the evaluation results may differ depending on factors such as the corporate situation and investment environment, it is necessary to establish a reference infrastructure to secure the objectivity and reliability of the technology valuation results. In this study, we investigate the evaluation infrastructure built by each institution and examine whether the latest artificial neural networks and deep learning technologies are applicable for performing predictive simulation of technology values based on principal variables, and predicting sales estimates and qualitative evaluation scores in order to embed onto the technology valuation system."
딥 러닝을 이용한 단일 카메라 SLAM에서 스케일 드리프트 감소,2021,"['Monocular SLAM', 'Scale Drift', 'Deep Learning', 'Convolutional Neural Network']",,"Monocular SLAM(Simultaneous Localization and Mapping) systems have such advantages as low cost and light weight compared to stereo or laser range finder based SLAM systems. However they also have relatively large errors when they measure the distances between a vehicle and some distinct objects, which can lead to scale ambiguity or scale drift. In this paper, we suggest a scale drift-aware monocular SLAM system using CNN(Convolutional Neural Network) which is one of the key technologies of Deep Learning. CNN nowadays has proved its performances especially in computer vision. We have trained the system with plenty of images of some predetermined objects using CNN. And then we can measure the absolute distances between a vehicle and already known objects and resolve the scale drift problems. The suggested system has been evaluated by several experiments."
딥러닝을 이용한 군 내외 거수자 행동 인식: 키포인트 2D 스케일링을 중심으로,2021,"['defense and security technology', 'surveillance camera', 'suspicious person', 'behavior recognition', 'OpenPose', '국방보안기술', '감시카메라', '거수자', '행동 인식', '오픈포즈']","본 연구는 딥러닝을 통해 군 내외에서 거수자의 행동을 인식하여 국방 보안 체계를 강화하는 데 목적을 두고 있다. 감시 카메라는 범죄자, 수상한 행동을 하는 사람을 찾아내는데 도움이 된다. 하지만 관리자가 카메라에서 전송되는 많은 영상을 모두 모니터링해야 한다는 점에서 비효율적이다. 큰 비용이 발생하며, 인적 오류에 취약하다. 따라서 본 연구에서는 감시카메라 영상만으로 주의 있게 봐야 할 행동을 하는 사람을 찾아내는 방법을 제안한다. 이를 위해 거수자 영상 데이터를 수집하였다. 또한, 입력 영상에서 사람마다 다른 신장, 동작을 일반화하는 알고리즘을 적용한 후 CNN, 양방향 LSTM, DNN을 결합한 모델을 통해 학습하였다. 실험 결과, 거수자의 행동 인식의 정확도를 향상시켰다. 따라서 기존 감시 카메라에 딥러닝을 접목한다면 거수자를 효율적으로 찾아낼 수 있을 것으로 기대한다.","The purpose of this study is to reinforce the defense and security system by recognizing the behaviors of suspicious person both inside and outside the military using deep learning. Surveillance cameras help detect criminals and people who are acting unusual. However, it is inefficient in that the administrator must monitor all the images transmitted from the camera. It incurs a large cost and is vulnerable to human error. Therefore, in this study, we propose a method to find a person who should be watched carefully only with surveillance camera images. For this purpose, the video data of doubtful behaviors were collected. In addition, after applying a algorithm that generalizes different heights and motions for each person in the input images, we trained through a model combining CNN, bidirectional LSTM, and DNN. As a result, the accuracy of the behavior recognition of suspicious behaviors was improved. Therefore, if deep learning is applied to existing surveillance cameras, it is expected that it will be possible to find the dubious person efficiently."
딥러닝 기반 녹조 세포 계수 미세 유체 기기 개발,2021,"['Green algae(녹조)', 'Cell counting(세포 계수)', 'Microfluidic device(미세 유체 기기)', 'Deep learning(딥러닝)', 'Droplet generator(액적 생성기)']",,
블록체인과 딥러닝을 이용한 악성코드 탐지에 관한 연구,2021,"['Malicious Code', 'Code Detection', 'Blockcahin', 'Deep Learning', '악성코드', '코드 탐지', '블록체인', '딥러닝']",,"Damages by malware have recently been increasing. Conventional signature-based antivirus solutions are helplessly vulnerable to unprecedented new threats such as Zero-day attack and ransomware. Despite that, many enterprises have retained signature-based antivirus solutions as part of the multiple endpoints security strategy. They do recognize the problem. This paper proposes a solution using the blockchain and deep learning technologies as the next-generation antivirus solution. It uses the antivirus software that updates through an existing DB server to supplement the detection unit and organizes the blockchain instead of the DB for deep learning using various samples and forms to increase the detection rate of new malware and falsified malware."
보행교통사고 다발지역 예측을 위한 딥러닝의 적용 : 수도권 노인과 어린이 보행교통사고를 중심으로,2021,"['보행교통사고', '딥러닝', '노인', '어린이', 'Pedestrian Crash', 'Deep Learning', 'The Elderly', 'Child']",,
감성분석과 딥러닝을 적용한 재중동포 서신 빅데이터 분석,2021,"['재중동포 서신 빅데이터', '감성분석', '설명가능 인공지능', '로컬 대리 분석', '인공지능과 인문학 융합', 'Correspondence Big Data', 'Sentiment Analysis', 'Explainable Artificial Intelligence', 'Local Surrogate Analysis', 'Artificial Intelligence and Humanities']","본 논문은 빅데이터 분석 기술을 재중 동포 서신 빅데이터에 적용하여 인공지능 기반의 인문학 연구를 위한 새로운 방법을 제시하였다. 연구에 사용된 서신 빅데이터는 1974년도에서 2008년도까지 진행된 KBS 한민족 방송 가족 찾기 프로그램으로 발송된 재중 동포 서신 약 8만 여 통이다. 서신의 주 내용은 고향에 있는 가족을 찾는 내용이지만, 본 연구에서 초점을 둔 것은 중국과의 공식 수교가 단절되었던 시기에 재중 동포의 삶과 문화를 서신으로부터 찾아내는 것이다. 이를 위해 8만 여통의 서신을 데이터베이스로 구축하여 운영하고 있으며, 감성 분석, 딥러닝, 그리고 설명가능 인공지능 기술을 적용하여 서신 내용을 분석하였다. 감성 분석은 서신에 등장한 형용사만 추출하여 긍정 형용사와 부정 형용사로 나눈 다음, 텍스트의 내용이 긍정적인 내용인지 부정적인 내용인지 판별한다. 긍정 및 부정 형용사를 점수화하기 위해서 공개된 한국어 감성사전에 본 서신에서 사용된 형용사들을 추가하여 처리하였고, 정규화하여 점수를 산출하였다. 한국, 중국, 그리고 일본을 언급한 서신 내용에 대해 감성 분석을 시기별로 분석한 결과 한국에 대한 긍정 점수가 가장 높고 지속적으로 증가함을 알 수 있었다. 부정 점수의 경우는 일본이 초기에는 가장 높았으나 후반부로 갈수록 급격히 하락하였으며, 이는 한중 수교 이후 재중 동포의 관심이 한국으로 집중되었기 때문이라고 할 수 있다. 서신의 내용을 분석하기 위해서 딥러닝을 적용하여 서신을 주제별로 학습시키고 자동 분류를 하도록 하였으며, 설명가능 인공지능 기술인 로컬 대리 분석을 적용하여 주제를 분류하는데 중요한 역할을 한 주요 단어들을 제시하였다. 정치 분야에서는 한중수교, 문화혁명 등이, 그리고 경제 분야에서는 무역, 사업 등이 주요 키워드로 등장하였다. 본 연구는 빅데이터 분석 기술이 인문학 연구에서도 성공적으로 활용될 수 있다는 것을 보여준다.","In this paper, we presented a new approach to do research in the humanities based on artificial intelligence. A correspondence database was built using letters from ethnic Koreans living in China sent to Korea Broadcasting System (KBS) for finding separated families. Sentiment of Koreans living in China related to Korea, China, and Japan is analyzed according to the time period. Korea has the highest positive score, and Japan has the lowest positive score. The positive scores of South Korea and China increase, but Japan’s positive score decreases according to the time periods. Deep learning and explainable artificial intelligence are applied to the correspondence database to analyze content of letters,. In the subject of politics, Korea-China diplomatic relation and Cultural revolution are extracted, and in the subject of economy, business and trade are extracted. This research shows that the technology of the big data analysis are successfully applied to humanities studies."
샤인머스캣과 청포도 자동 분류 딥러닝 시스템 개발,2021,"['분류', '딥러닝', '인공지능', '스마트 팜', '샤인머스캣', '청포도', 'CNN', 'Classification', 'Deep Learning', 'Artificial Intelligence', 'Smart Farm', 'Shine-muscat', 'Green-grape']",,"In this paper, in order to develop an artificial intelligence system for automatic classification of shine muscats and green grapes with similar characteristics, an image dataset of the two fruits and a feature-based numerical dataset were constructed. Two CNN models were applied to the constructed image dataset and the accuracy of automatic classification was calculated using verification data. As a result, the VGGNET model showed 25% accuracy, and the CNN deep learning model proposed to minimize overfitting showed 84% accuracy. In addition, when the linear regression deep learning model was applied to feature-based numerical datasets, the accuracy of automatic classification was 94%. It is expected that the dataset construction method and deep learning method proposed in this paper can be applied to the implementation of artificial intelligence-based smart farm systems by automatically classifying fruits or agricultural products of different varieties."
CNN 기반 딥러닝을 이용한 패션 아이템 분류 및 결합,2021,"['인공지능', '딥러닝', '머신러닝', '합성곱 신경망', '생성적 적대 신경망', '패션', 'Artificial Intelligence', 'Deep Learning', 'Machine Learning', 'Convolutional Neural Network', 'Generative Adversarial Network', 'Fashion']",,"In this paper, in order to implement an artificial intelligence system that can appropriately match fashion items according to the situation, a deep learning model based on convolutional neural network was designed after labeling with 10 fashion items based on fashion-MNIST. Based on the designed deep learning model, 45,000 fashion images were used as a training dataset, and 15,000 fashion images were used as a verification dataset, and deep learning was performed with a total of 15 epochs. As a result of the deep learning execution, the training data learning accuracy 96% and the verification data learning accuracy 94% were output in the accuracy evaluation of fashion item classification. In this paper, we constructed a dataset that can provide 7 types of fashion matching based on the implemented artificial intelligence fashion item classification system. The established dataset is expected to become the basis of an artificial intelligence fashion matching service that can satisfy various fashion needs of individuals in the future."
증강현실 게임에서 딥러닝을 활용한 배경객체 분석에 관한 연구,2021,"['증강현실', '딥러닝', 'Tensorflow Lite', '증강현실배경', '증강현실게임', '객체탐지', 'AR', 'DeepLearning', 'Tensorflow Lite', 'AR background', 'AR game', 'Oobject detection']",,
인공지능 딥러닝을 이용한 색보정 기술 동향 : Colourlab Ai 소프트웨어 중심으로,2021,"['색보정', '인공지능', '딥러닝', '색', '영화', 'DI(Digital Intermediate)', 'AI(Artificial Intelligence)', 'Deep Learning', 'Color', 'Film']","본 논문에서는 영화 영상 색보정 분야 중심으로 인공지능 기술 동향을 반영하여 최근에 개발된 인공지능 색보정 애플리케이션인 Colourlab Ai의 활용에 대하여 살펴보았다. 색보정 과정 의 프라이머리를 중심으로 딥러닝 기반의 색보정 영상처리 분석기술 중에서 매칭 샷 (Matching Shot)에 대하여 알아보고자 한다. 영화, 영상 프로젝트의 색보정을 개선하는 참조 스틸(Reference still) 컷 활용 사례를 제시하여, 영화 후반 제작자와 컬러리스트의 제작 속도를 높여 줄 수 있고 새로운 룩을 빠르게 찾을 수 있도록 영화 후반 제작에 Colourlab Ai의 효율적으로 적용하는 방법을 제시하였다. 그 결과로서 데이터 축적을 기초로 한 인공지능 기술의 영화 후반 제작에서의 활용은 DI 프로세스에서 창의적이며 제작시간이 절감된 가속화된 워크플로우의 대안방식이 될 수 있을 것이다.","Today, artificial intelligence technology is also influencing film-making. In this paper, we experimented with the use of the artificial intelligence application Colourlab Ai in color grading. This application was recently developed by reflecting the trend of AI technology in the field of color grading for film post production. In the digital intermediate process, we experimented Raw files with the matching shot based on the deep learning as color grading analysis technologies. The example of the use of reference still cuts can help colorists create a quick look in the process, so that directors and producers can focus on the feel and atmosphere they are pursuing in the films. This allows post film-makers to focus on more creative areas in the DI process.  As a result, the use of AI technology based on data accumulation in post-film production will be a creative, time-saving, and accelerated workflow alternative to the DI process."
온-보드에서의 딥러닝을 활용한 드론의 실시간 객체 인식 연구,2021,"['Deep Learning(딥러닝)', 'Object Detection(객체 인식)', 'Data Augmentation(데이터 증강)', 'Transfer Learning(전이 학습)', 'Class Imbalance(클래스 불균형)', 'Inference Acceleration(추론 가속화)']","본 논문에서는 드론을 활용한 감시정찰 임무의 효율성을 향상하기 위해 드론 탑재장비에서 실시간으로 구동 가능한 딥러닝 기반의 객체 인식 모델을 개발하는 연구를 수행하였다. 드론 영상 내 객체 인식 성능을 높이는 목적으로 학습 단계에서 학습 데이터 전처리 및 증강, 전이 학습을 수행하였고 각 클래스 별 성능 편차를 줄이기 위해 가중 크로스 엔트로피 방법을 적용하였다. 추론 속도를 개선하기 위해 양자화 기법이 적용된 추론 가속화 엔진을 생성하여 실시간성을 높였다. 마지막으로 모델의 성능을 확인하기 위해 학습에 참여하지 않은 드론 영상 데이터에서 인식 성능 및 실시간성을 분석하였다.","This paper provides a process for developing deep learning-based aerial object detection models that can run in realtime on onboard. To improve object detection performance, we pre-process and augment the training data in the training stage. In addition, we perform transfer learning and apply a weighted cross-entropy method to reduce the variations of detection performance for each class. To improve the inference speed, we have generated inference acceleration engines with quantization. Then, we analyze the real-time performance and detection performance on custom aerial image dataset to verify generalization."
선삭공정에서 딥러닝 영상처리 기법을 이용한 작업자 위험 감소 방안 연구,2021,"['Deep Learning(딥러닝)', 'Vision System(영상처리 시스템)', 'Negligent Accident(안전사고)', 'Convolutional Neural Network(CNN)(컨볼루션신경망)', 'You Only Look Once(YOLO)(욜로)']",,"The deep learning image processing technique was used to prevent accidents in lathe work caused by worker negligence. During lathe operation, when the chuck is rotated, it is very dangerous if the operator""s hand is near the chuck. However, if the chuck is stopped during operation, it is not dangerous for the operator’s hand to be in close proximity to the chuck for workpiece measurement, chip removal or tool change. We used YOLO (You Only Look Once), a deep learning image processing program for object detection and classification. Lathe work images such as hand, chuck rotation and chuck stop are used for learning, object detection and classification. As a result of the experiment, object detection and class classification were performed with a success probability of over 80% at a confidence score 0.5. Thus, we conclude that the artificial intelligence deep learning image processing technique can be effective in preventing incidents resulting from worker negligence in future manufacturing systems."
SinGAN 딥러닝 모델을 이용한 넙치 질병 이미지 증강,2021,"['수산 양식', '질병 예측', '질병 이미지 생성', '이미지 증강', 'Aqua Farm', 'GAN', 'Disease Prediction', 'Disease Image Generation', 'Image Augmentation']","수산 양식장에서 어류 질병을 초기에 발견하지 못하는 경우 밀폐된 공간 안에서 확산하기 때문에 집단 폐사로 이어질 확률이 매우 높다. 이런 이유로 질병의 조기 발견은 양식업에서 매우 중요하다. 양식장에서 질병의 확산을 막기 위해서는 초기에 병이 든 어류를 자동식별이 가능한 방법이 필요하다. 최근 딥러닝 기반의 어류질병 자동식별 방법이 많이 사용되고 있는데, 어류의 질병 이미지가 충분하지 않아 객체 식별에 많은 어려움이 있다. 본 논문은 질병 자동식별 예측을 위한 질병 이미지의 부족 문제를 해결하기 위해서 SinGAN 딥러닝 모델을 이용하여 정상 이미지와 질병 이미지를 합성해 다양한 어류 질병 이미지를 자동 생성하는 방법을 제안한다. 넙치에서 가장 빈번히 발생하는 3가지 질병 스쿠티카병, 비브리오증, 림포시스티스에 대해서 SinGAN 기반으로 질병 이미지를 증강한다. 본 연구에서는 넙치 정상 이미지 11장에 각 질병 패턴 10가지를 합성하여서 스쿠티카병 110장, 비브리오증 110장, 림포시스티스 110장으로 총 330장을 만들었고 이를 통해 생성된 이미지는 4배수 하여 1,320장의 이미지를 생성할 수 있었다.","In modern aquaculture, mass mortality is a very important issue that determines the success of aquaculture business. If a fish disease is not detected at an early stage in the farm, the disease spreads quickly because the farm is a closed environment. Therefore, early detection of diseases is crucial to prevent mass mortality of fish raised in farms. Recently deep learning-based automatic identification of fish diseases has been widely used, but there are many difficulties in identifying objects due to insufficient images of fish diseases. Therefore, this paper suggests a method to generate a large number of fish disease images by synthesizing normal images and disease images using SinGAN deep learning model in order to to solve the lack of fish disease images. We generate images from the three most frequently occurring Paralichthys Olivaceus diseases such as Scuticociliatida, Vibriosis, and Lymphocytosis and compare them with the original image. In this study, a total of 330 sheets of scutica disease, 110 sheets of vibrioemia, and 110 sheets of limphosis were made by synthesizing 10 disease patterns with 11 normal halibut images, and 1,320 images were produced by quadrupling the images."
스마트폰 사용자의 이동 변화량 예측을 위한 딥러닝 기반 보행자 관성항법 기법,2021,"['보행자 관성항법', '딥러닝', '지도 학습', '스마트폰 기반 실내 측위', '범 지구 위성항법 시스템', 'Pedestrian dead reckoning', 'Deep learning', 'Supervised learning', 'Smartphone-based indoor localization', 'Global navigation satellite system']",,
영상의 연속성 기반 Key 개념 도입을 통해 인식 성능을 향상시킨 딥러닝 네트워크 개선 연구,2021,"['Deep leraning(딥러닝)', 'Average precision(평균 정밀도)', 'Recall(재현율)', 'Bounding box(경계 상자)', 'Loss function(손실 함수)', 'Convolution(합성곱)']",,
항공영상을 이용한 딥러닝 기반 건물객체 추출 기법들의 비교평가,2021,"['Deep Learning', 'Semantic Segmentation', 'Aerial Photo', 'Building Extraction', '딥러닝', '의미론적 분할', '항공사진', '건물객체 추출']",,
비디오 기반 딥러닝 융합 알고리즘에 의한 화재 감지 시스템에 관한 연구,2021,"['화재 감지', '연기 감지', '딥러닝', '객체 인식', 'CNN', 'Fire detection', 'smoke detection', 'deep learning', 'object detection', 'tracking', 'CNNs']",,
국방의료 데이터기반의 딥러닝을 활용한 질병 진단 연구,2021,"['인공지능', '인공신경망', '국방의료 데이터', '질병진단', '딥러닝', 'Artificial intelligence', 'Neural network', 'Military medical data', 'Disease diagnosis', 'Deep learning']",,"According to the rapid development of artificial intelligence and medical technology, recent researches show that artificial neural networks can diagnose various diseases with high accuracy. In particular, if a disease can be diagnosed with high accuracy from the time of medical examination or physical examination, it is possible to prevent delay of diagnosis results due to a shortage of military medical staff and to treat patients through early screening. In addition, through early detection and screening of asympotomatic patients, it can be expected to enhance combat power through early treatment and prevention. In this paper, a study was conducted to diagnose major military medical diseases(pneumonia, tuberculosis, rhabdomyolysis) by using deep learning on military medical data. The experiment results show the predictability of the diseases using military medical data. In the future, it can be used for early detection and diagnosis system development of other major diseases."
영상 기반 딥러닝을 통한 배관 누설 가시화 기술,2021,"['Video(영상)', 'Deep Learning(딥러닝)', 'Pipe Leakage(배관 누설)', 'Visualization(가시화)']",,"Piping is a part of industrial structures that acts like human blood vessels. Since pipe leakages are a threat to the integrity of a structure, it is one of the major monitoring targets. If inspectors are unaware of leakages, access to pipes for inspection can cause serious injury to the human body. Therefore, it is necessary to operate a monitoring system that detects pipe leakage regions for the safety of not only facilities but also inspectors. In this study, a multi-kernel neural network was introduced to visualize the pipe leakage regions through deep learning of the characteristics of pixel- wise color variation in normal and leakage regions from camera footage. Furthermore, we present the results of properly adjusting the visualization properties through an analysis of precision and recall according to the threshold for leakage judgment based on the output of deep learning. The results show that leakage areas can be visualized in accordance with the leakage diagnosis environment and purpose by adjusting the threshold."
LSTM Networks 딥러닝 기법과 SWAT을 이용한 유량지속곡선 도출 및 평가,2021,"['LSTM', 'Deep learning', 'SWAT', 'Flow duration curve', 'Rainfall-runoff', 'LSTM', '딥러닝', 'SWAT', '유량지속곡선', '강우-유출']",,"Climate change brought on by global warming increased the frequency of flood and drought on the Korean Peninsula, along with the casualties and physical damage resulting therefrom. Preparation and response to these water disasters requires national-level planning for water resource management. In addition, watershed-level management of water resources requires flow duration curves (FDC) derived from continuous data based on long-term observations. Traditionally, in water resource studies, physical rainfall-runoff models are widely used to generate duration curves. However, a number of recent studies explored the use of data-based deep learning techniques for runoff prediction. Physical models produce hydraulically and hydrologically reliable results. However, these models require a high level of understanding and may also take longer to operate. On the other hand, data-based deep-learning techniques offer the benefit if less input data requirement and shorter operation time. However, the relationship between input and output data is processed in a black box, making it impossible to consider hydraulic and hydrological characteristics. This study chose one from each category. For the physical model, this study calculated long-term data without missing data using parameter calibration of the Soil Water Assessment Tool (SWAT), a physical model tested for its applicability in Korea and other countries. The data was used as training data for the Long Short-Term Memory (LSTM) data-based deep learning technique. An anlysis of the time-series data fond that, during the calibration period (2017-18), the Nash-Sutcliffe Efficiency (NSE) and the determinanation coefficient for fit comparison were high at 0.04 and 0.03, respectively, indicating that the SWAT results are superior to the LSTM results. In addition, the annual time-series data from the models were sorted in the descending order, and the resulting flow duration curves were compared with the duration curves based on the observed flow, and the NSE for the SWAT and the LSTM models were 0.95 and 0.91, respectively, and the determination coefficients were 0.96 and 0.92, respectively. The findings indicate that both models yield good performance. Even though the LSTM requires improved simulation accuracy in the low flow sections, the LSTM appears to be widely applicable to calculating flow duration curves for large basins that require longer time for model development and operation due to vast data input, and non-measured basins with insufficient input data."
클라우드 플랫폼을 이용한 딥러닝 기반 장애인 주차구역 관리 시스템 구현,2021,"['Cloud platform', 'YOLO', 'CNN', 'Raspberry pi', 'Android phone', 'Deep learning']","본 연구는 딥러닝과 클라우드 플랫폼을 이용하여 장애인 복지 증진을 위한 장애인 주차 공간을 관리하는 시스템을 제안하였다. 딥러닝은 주차 영역의 자동차 영상에서 번호판 검출을 위하여 YOLO (you only look once)를 사용하였으며, 추출된 숫자 및 문자 영상에서 번호판 문자 인식을 위하여 CNN (convolutional neural network)을 사용하였다. 본 시스템은 실시간 관리가 가능하고, 동영상만으로 관리할 수 있도록 간소화하였다. 또한 기존 OCR (optical character recognition)보다 한글 문자 인식률을 높임으로서 안정성 및 정확성이 있으며, CCTV (closed circuit television)만 설치하면 주차관리가 가능하도록 함으로서 관리 영역의 확장성의 특장점을 가진다. 본 시스템은 기징 중요한 요소인 정확한 번호판 인식률을 높이는 연구와 다소 성능이 낮은 라즈베리 파이 환경에서 YOLO와 CNN 알고리즘 등을 실행하기 위한 처리속도 문재에 대한 지속적 연구가 필요하다.","This study proposed a system that manages parking spaces for the disabled, this will lead to the promotion of welfare for those who are disabled by using deep learning and cloud platforms. Deep learning used you only look once (YOLO) for license plate detection concerning car images in parking areas, and convolutional neural network (CNN) was used for license plate character recognition from extracted numbers and text images. This system can be managed in real time, and it has been simplified so that it can be managed only with video. In addition, it is recognized and accurate by increasing the recognition rate of Korean characters compared to the existing optical character recognition (OCR), and it has the advantage of scalability in the management area by enabling parking management but only if closed circuit television (CCTV) is installed. This system requires a study to increase the accurate license plate recognition rate. This is an important factor, and a continuous study on the processing speed problem to execute YOLO and CNN algorithms in a somewhat low performance raspberry environment."
망 분리를 이용한 딥러닝 학습시간 단축에 대한 연구,2021,"['Deep Learning', 'Machine Learning', 'Convolution Neural Networks', 'Multi Layer Perceptrons', 'Learning Time']","본 논문에서는 딥러닝 구조를 분할을 이용한 개별 학습을 수행하여 학습시간을 단축하는 알고리즘을 제안한다. 제안하는 알고리즘은 망 분류 기점 설정 과정, 특징 벡터 추출 과정, 특징 노이즈 제거 과정, 클래스 분류 과정 등의 4가지 과정으로 구성된다. 첫 번째로 망 분류 기점 설정 과정에서는 효과적인 특징 벡터 추출을 위한 망 구조의 분할 기점을 설정한다. 두번째로 특징 벡터 추출 과정에서는 기존에 학습한 가중치를 사용하여 추가 학습 없이 특징 벡터를 추출한다. 세 번째로 특징 노이즈 제거 과정에서는 추출된 특징 벡터를 입력받아 각 클래스의 출력값을 학습하여 데이터의 노이즈를 제거한다. 네 번째로 클래스 분류 과정에서는 노이즈가 제거된 특징 벡터를 입력받아 다층 퍼셉트론 구조에 입력하고 이를 출력하고 학습한다. 제안된 알고리즘의 성능을 평가하기 위하여 Extended Yale B 얼굴 데이터베이스를 사용하여 실험 하였다. 실험 결과, 1회 학습에 소요되는 시간의 경우 제안하는 알고리즘이 기존 알고리즘 기준 40.7% 단축하였다. 또한 목표 인식률까지 학습 횟수가 기존 알고리즘과 비교하여 단축하였다. 실험결과를 통해 1회 학습시간과 전체 학습시간을 감소시켜 기존의 알고리즘보다 향상됨을 확인하였다.","In this paper, we propose an algorithm that shortens the learning time by performing individual learning using partitioning the deep learning structure. The proposed algorithm consists of four processes: network classification origin setting process, feature vector extraction process, feature noise removal process, and class classification process. First, in the process of setting the network classification starting point, the division starting point of the network structure for effective feature vector extraction is set. Second, in the feature vector extraction process, feature vectors are extracted without additional learning using the weights previously learned. Third, in the feature noise removal process, the extracted feature vector is received and the output value of each class is learned to remove noise from the data. Fourth, in the class classification process, the noise-removed feature vector is input to the multi-layer perceptron structure, and the result is output and learned. To evaluate the performance of the proposed algorithm, we experimented with the Extended Yale B face database. As a result of the experiment, in the case of the time required for one-time learning, the proposed algorithm reduced 40.7% based on the existing algorithm. In addition, the number of learning up to the target recognition rate was shortened compared with the existing algorithm. Through the experimental results, it was confirmed that the one-time learning time and the total learning time were reduced and improved over the existing algorithm."
텍스트 마이닝과 딥러닝 알고리즘을 이용한 가짜 뉴스 탐지 모델 개발,2021,"['가짜 뉴스', '한국어 뉴스', '자연어 처리', '딥러닝', '텍스트 마이닝', 'Fake News', 'Korean News', 'Natural Language Processing', 'Deep Learning', 'Text Mining']",,
감성분석을 이용한 뉴스정보와 딥러닝 기반의 암호화폐 수익률 변동 예측을 위한 통합모형,2021,"['암호화폐', '감성분석', '딥러닝', 'LSTM', '통합모형', 'Cryptocurrency', 'Sentiment Analysis', 'Deep Learning', 'Integrated Model']","암호화폐 중 대표적인 비트코인은 전 세계적으로 많은 관심을 받고 있으며 비트코인의 가격은 등·하락을 거듭하며 높은 변동성을 보이고 있다. 높은 변동성은 투자자들에게 위험 요인으로 작용하며 무분별한 투자로 인한 사회적 문제를 야기시킨다. 비트코인의 가격은 세계의 환경변화에 영향을 받으며 신속하게 반응하기 때문에 실시간으로 다양한 정보를 제공하는 뉴스 정보는 비트코인 가격의 변동성 예측에 유용한 정보를 제공한다. 즉, 긍정적인 뉴스는 투자심리를 자극할 것이며 반대로 부정적인 뉴스는 투자심리를 위축시킬 것이다. 따라서 본 연구에서는 비트코인의 수익률 변동을 예측하기 위해 뉴스의 감성정보와 딥러닝을 적용하였다. 로짓, 인공신경망, SVM, LSTM을 적용하여 단일 예측모형을 구축하였으며 예측성과를 향상시키기 위한 방법으로 통합모형을 제안하였다. 과거의 가격정보를 기반으로 구축한 예측모형과 뉴스의 감성정보를 반영한 예측모형의 성과를 비교한 결과 뉴스의 감성정보를 반영한 예측모형의 성과가 우수하게 나타났으며 통합모형의 성과가 가장 우수한 것으로 나타났다. 본 연구는 비트코인 수익률 변동에 대한 예측모형을 통해 무분별한 투자를 예방하고 투자자들의 현명한 투자가 이루어질 수 있도록 유용한 정보를 제공할 수 있을 것이다.","Bitcoin, a representative cryptocurrency, is receiving a lot of attention around the world, and the price of Bitcoin shows high volatility. High volatility is a risk factor for investors and causes social problems caused by reckless investment. Since the price of Bitcoin responds quickly to changes in the world environment, we propose to predict the price volatility of Bitcoin by utilizing news information that provides a variety of information in real-time. In other words, positive news stimulates investor sentiment and negative news weakens investor sentiment. Therefore, in this study, sentiment information of news and deep learning were applied to predict the change in Bitcoin yield. A single predictive model of logit, artificial neural network, SVM, and LSTM was built, and an integrated model was proposed as a method to improve predictive performance. As a result of comparing the performance of the prediction model built on the historical price information and the prediction model reflecting the sentiment information of the news, it was found that the integrated model based on the sentiment information of the news was the best. This study will be able to prevent reckless investment and provide useful information to investors to make wise investments through a predictive model."
물리검층자료를 활용한 딥러닝 기반 수포화도 예측,2021,"['Well log data', 'Water saturation', 'Long Short-Term Memory', 'Sensitivity analysis', '물리검층자료', '수포화도', '장단기메모리학습법', '민감도 분석']","이 연구는 다양한 물리검층자료를 학습한 딥러닝 알고리듬을 이용하여 저류층의 수포화도를 예측하는 대리 모델을 구축한다. 딥러닝 알고리듬으로 계산한 수포화도 추정치를 Archie 방정식 결과와비교함으로써 개발 모델의 성능 평가를 수행하였다. 이 연구는 4가지 물리검층자료(밀도, 공극률, 비저항, 감마선)를 심층신경망의 입력인자로 활용하여 수포화도를 평가하였다, 심층신경망 기법으로는 장단기메모리학습법을 사용하였으며 전형적인 다층 인공신경망과의 비교를 통해 성능을확인하였다. 장단기메모리학습법을 기반으로 수포화도를 예측한 결과, 결정계수의 값이 0.7 이상으로 우수한 성능을 보이는 것으로 확인하였다. 모델의 민감도 분석으로는 시퀀스 조정, 유정 역할전환, k-폴드 교차검증을 시행하였다. 모델의 적용 가능성은 북해 Volve 유전과 베트남 해상 유전에적용하여 성능을 검증하였다.","This study develops a surrogate model to predict water saturation from well log data using neural-network-based deep learning algorithms. The model performance is evaluated by comparing the water saturation estimates obtained using deep learning algorithms and Archie’s law. The surrogate model evaluates the water saturation of a target reservoir using four well-log data types (density, porosity, resistivity, and gamma ray). Long Short-Term Memory (LSTM) is employed as the deep neural network algorithm, and its performance is compared with that of a multi-layer artificial neural network. Prediction via the LSTM based model showed outstanding results with the coefficient of determination above 0.7. Sensitivity analysis is conducted through sequence tuning, switching of well type, and k-fold cross-validation. The applicability of the model has been validated for the Volve oilfield in the North Sea and an offshore oilfield in Vietnam."
평면 스케치 딥러닝 학습모델 구축과 공간디자인 활용 - 평면 스케치 인식 기반 설계초기 BIM 모델 자동생성 모듈 개발 중심으로 -,2021,"['Floorplan Sketch', 'Floorplan recognition', 'Deep-learning', 'Generative Adversarial Network', 'GAN', 'Building Information Modeling', 'BIM', '평면스케치', '도면 인식', '딥러닝', '생성적 적대 신경망', '건물정보모델링']",,"(Background and Purpose) As the construction industry requires the use of technologies related to the fourth industrial revolution, the field's data-based digital technology is highlighted. Currently utilized data in architecture exists in various forms, making it difficult to manage and use the accumulated design information for other reasons. Therefore, this study proposes developing and utilizing technologies that recognize floorplan sketches, one of the analog media, and convert them into digital media, BIM, that computers can understand. (Method) This study is conducted in two parts: 1) floorplan sketch recognition, 2) utilization of recognized floorplan sketches. In the floorplan sketch recognition phase, we propose an approach that applies Generative Adversarial Network-based deep learning techniques to transform human-drawn floorplan sketch styles into one unified form. Specifically, to recognize the floorplan sketches, the deep learning model learns various forms of floorplan sketches and the styles it needs to transform in pairs. The consistent style has essential architectural elements labeled on it : wall, floor, door and window objects. The study uses apartment floorplan images as learning data for floorplan sketch recognition deep-learning model. The apartment floor plan dataset provided by the Ministry of Land, Infrastructure and Transport Seumteo(e-ais) consists of scanned floorplan images of apartments, houses, and row houses in Seoul. In the phase of the utilization of perceived floorplan sketches, BIM models were generated based on the recognized floorplan sketches. They were subdivided and vectorized by object to extract coordinates, and this enabled BIM models to be obtained by using them as input values for Revit API. (Results) The floorplan sketches labeled with essential architectural elements were the output for the floorplan sketch recognition module, and it was successfully printed out. For the analysis of the study, the predicted image was compared by the ground truth image and showed success. For the second phase, the BIM model prototype made on the Autodesk Revit platform created a fast and accurate 3D BIM model when the recognized floorplan sketches were given input. The created model is low in detail, but it contains the geometry information and the property information, making it an easier way for future use. (Conclusion) This research and development is a sub-development of the overall intelligent design system. It identifies whether computers can recognize one of the design information, floorplan sketches as human beings, and suggests its potentials. Subsequent studies are believed to obtain a BIM model with a high level of detail if recognition is achieved by scaling out of the current recognizable target range."
스마트 양식을 위한 딥러닝 기반 어류 검출 및 이동경로 추적,2021,"['스마트 양식', '딥러닝', '객체 검출', '이동경로 추적', '이미지 증강', 'Smart Aqua Farm', 'Deep Learning', 'Object Detection', 'Path Tracking', 'Image Augmentation']","현재 국내 수산 양식업은 스마트화를 추진하고 있지만, 여전히 양식 단계의 많은 과정에서 사람의 주관적인 판단으로 진행되고 있다. 수산 양식업 스마트화를 위해서 선행되어야 할 부분은 양식장 내 물고기들의 상태를 효과적으로 파악하는 것이다. 어류 개체 수, 크기, 이동경로, 이동속도 등을 파악하여 실시간 모니터링 할 수 있게 된다면 사료 자동 급이, 질병유무판단 등 다양한 양식자동화를 진행할 수 있을 것이다. 본 연구에서는 수중 촬영한 어류비디오 데이터를 이용하여 실시간으로 어류의 상태를 파악 할 수 있는 알고리즘을 제안하였다. 어류 객체검출을 위해 딥러닝 기반 최신 객체검출 모델들을 적용하여 검출 성능을 비교 평가 하였고, 검출결과를 이용하여 비디오내의 연속적인 이미지 프레임에서 어류 객체 ID부여, 이동경로 추적 및 이동속도를 측정할 수 있는 알고리즘을 제안하였다. 제안한 알고리즘은 객체 검출 성능 92%(F1-score 기준)를 보였으며, 실제 테스트비디오 상에서 실시간으로 다수의 어류 객체를 효과적으로 추적하는 것을 확인하였다. 본 논문에서 제안하는 알고리즘을 이용하여 향후 사료 자동 급이, 어류 질병 예측 등 다양한 스마트양식 기술에 효과적으로 활용될 수 있을 것으로 기대한다.","Currently, the domestic aquaculture industry is pursuing smartization, but it is still proceeding with human subjective judgment in many processes in the aquaculture stage. The prerequisite for the smart aquaculture industry is to effectively grasp the condition of fish in the farm. If real-time monitoring is possible by identifying the number of fish populations, size, pathways, and speed of movement, various forms of automation such as automatic feed supply and disease determination can be carried out. In this study, we proposed an algorithm to identify the state of fish in real time using underwater video data. The fish detection performance was compared and evaluated by applying the latest deep learning-based object detection models, and an algorithm was proposed to measure fish object identification, path tracking, and moving speed in continuous image frames in the video using the fish detection results. The proposed algorithm showed 92% object detection performance (based on F1-score), and it was confirmed that it effectively tracks a large number of fish objects in real time on the actual test video. It is expected that the algorithm proposed in this paper can be effectively used in various smart farming technologies such as automatic feed feeding and fish disease prediction in the future."
홍채 이미지를 이용한 뇌질환 바이오 마커 분류 딥러닝 알고리즘,2021,"['이미지 전처리', '딥러닝 알고리즘', '치매', '홍채', '뇌 질환', 'Brain Disease', 'Deep learning', 'Dementia', 'Iris', 'Preprocessing']",,"With the rapid development of ICT technology along with the 4th industrial revolution, in the field of Traditional Korean medicine. we also analyze data on obesity and complications for preventive management of yoyo phenomenon, custom medical treatment such as improvement of complications, and medical examination. Various ICT technologies have been introduced and studied. From the viewpoint of Traditional Korean medicine, iris is an institution that expresses the singularity of the human body. Iris is directly connected to the brain, and the biomarkers displayed on the body are reflected in the iris. In this study, we try to classify the brain disease-related biomarkers indicated by the iris by learning the iris image-based map of the causes of dementia induction in brain diseases. As a result of the experiment using the proposed algorithm, the learning time is about 26 minutes, the learning accuracy is 99%, the loss rate is 1%, the accuracy of the test data is 91%, and the loss rate is 17.4%."
국방의료데이터를 활용한 딥러닝 기반의 폐렴 진단 모델 연구,2021,"['인공지능', '국방의료데이터', '딥러닝', '의료정보 분석', '폐렴', 'AI(Artificial intelligence)', 'Defense medical data', 'Deep-learning', 'Medical information analysis', 'Pneumonia']",,"As medical technology advances and artificial intelligence technology develops rapidly, recent research results show that it is possible to diagnose various diseases with high accuracy. Early identification of pneumonia is important to prevent outbreaks of major infections associated with long-term hospitalization and high mortality. In this paper, we conduct research on a deep learning-based pneumonia diagnosis model using military medical data. The experiment results show the possibility of diagnosis and predictability using military medical data. In the future, it can be used for early detection and predictive model development of other major diseases."
Google Street View와 딥러닝을 활용한 서울시 녹지 형평성 분석 : NDVI와 가로이미지 기반 녹지 산출방법과의 비교를 중심으로,2021,"['녹지 형평성', '가로녹시율', '구글 가로 이미지', '딥러닝', '의미론적 분할', 'Green Equity', 'Green View Index', 'Google Street View', 'Deep Learning', 'Semantic Segmentation']",,
엣지 컴퓨팅 기반의 딥러닝 서비스 모델을 위한 직교 특징벡터 추출 기법,2021,"['Edge computing', 'Deep learning', 'Autoencoder', 'Orthogonal Feature Vector', 'End Devices']",,
악성코드의 이미지화 방법이 딥러닝 기반의 악성코드 분류 성능에 미치는 영향 분석,2021,"['Malware classification', 'Deep learning', 'Visualized malware', 'Interpolation', 'Image size', '악성코드 분류', '딥러닝', '악성코드 이미지화', '보간법', '이미지 크기']",,"In this paper, we present the effect of the interpolation method and image size, which are an essential process for pre-processing in deep learning, on the performance of deep learning-based malware classification. The classifier uses a deep learning model to classify malware, and the visualized malware samples are used as train and test datasets. The malware images should be the same size to be used as input data in the deep learning model. Then, the malware size is not the same, so that resizing of images is necessary. When the image is resized, the image features can be distorted depending on the interpolation methods and the target size of the image. We conduct experiments to understand the impact on the deep learning model’s classification performance under various conditions. The results of the experiments can guide for selecting interpolation method and image size for the deep learning-based malware classifier."
다변수 LSTM 순환신경망 딥러닝 모형을 이용한 미술품 가격 예측에 관한 실증연구,2021,"['미술품 가격', '기계학습', '비모수 추청', '딥러닝', '다변수 장단기 기억 순환신경망', 'Art Price', 'Machine Learning', 'Non-parametric Prediction', 'Deep Learning', 'Multivariate LSTM RNN']","새로운 미술품 유통방식의 발달로 미술품의 미적 효용을 넘어 투자재로서 바라보는 시각이 활성화되고 있다. 미술품의 가격은 주식이나 채권 등과 달리 객관적 요소와 주관적 요소들이 모두 반영되어 결정되는 이질적 특성이 있기 때문에 가격 예측에 있어서 그 불확실성이 높다. 본 연구에서는 LSTM(장단기 기억) 순환신경망 딥러닝 모형을 활용하여 낙찰총액 순위 1위부터 10위까지의 한국 작가의 회화 작품을 대상으로 작가의 특성, 작품의 물리적 특성, 판매적 특성 등을 입력으로 하여 경매 낙찰가의 예측을 시도하였다. 연구 결과, 모델에 의한 예측 가격과 실제 낙찰 가격의 차이를 설명하는 RMSE 값이 0.064 수준이었으며 작가별로는 이대원 작가의 예측력이 가장 높았고, 이중섭 작가의 예측력이 가장 낮았다. 투자재로서 미술품 시장이 더욱 활성화되고 경매 낙찰 가격의 예측 수요가 높아지면서 본 연구의 결과가 활용될 수 있을 것이다.","With the recent development of the art distribution system, interest in art investment is increasing rather than seeing art as an object of aesthetic utility. Unlike stocks and bonds, the price of artworks has a heterogeneous characteristic that is determined by reflecting both objective and subjective factors, so the uncertainty in price prediction is high. In this study, we used LSTM Recurrent Neural Network deep learning model to predict the auction winning price by inputting the artist, physical and sales charateristics of the Korean artist. According to the result, the RMSE value, which explains the difference between the predicted and actual price by model, was 0.064. Painter Lee Dae Won had the highest predictive power, and Lee Joong Seop had the lowest. The results suggest the art market becomes more active as investment goods and demand for auction winning price increases."
SegNet과 ResNet을 조합한 딥러닝에 기반한 횡단보도 영역 검출,2021,"['Deep Learning', 'Semantic Segmentation', 'Zebra-crossing Detection', 'Neural Network', '딥러닝', '시맨틱 분할', '횡단보도 검출', '신경 네트워크']",,
확장된 프레임을 적용한 딥러닝 기반 자동 변조 분류 설계,2021,"['Automatic Modulation Classification', 'Convolutional Neural Network', 'Cognitive Radio Network', 'Frame Extension', 'Predicted Accuracy']",,
운전자의 주의분산 연구동향 및 딥러닝 기반 동작 분류 모델,2021,"['Driver’s Behavior', 'Driver’s Distraction', 'Behavior Recognition', 'ResNet-101', 'CAM', '운전자의 동작', '운전자의 주의 분산', '동작 인식']","본 논문에서는 운전자의 주의산만을 유발하는 운전자, 탑승자의 동작을 분석하고 핸드폰과 관련된 운전자의 행동 10가지를 인식하였다. 먼저 주의산만을 유발하는 동작을 환경 및 요인으로 분류하고 관련 최근 논문을 분석하였다. 분석된 논문을 기반으로 주의산만을 유발하는 주요 원인인 핸드폰과 관련된 10가지 운전자의 행동을 인식하였다. 약 10만 개의 이미지 데이터를 기반으로 실험을 진행하였다. SURF를 통해 특징을 추출하고 3가지 모델(CNN, ResNet-101, 개선된 ResNet-101)로 실험하였다. 개선된 ResNet-101 모델은 CNN보다 학습 오류와 검증 오류가 8.2배, 44.6배가량 줄어들었으며 평균적인 정밀도와 f1-score는 0.98로 높은 수준을 유지하였다. 또한 CAM(class activation maps)을 활용하여 딥러닝 모델이 운전자의 주의 분산 행동을 판단할 때, 핸드폰 객체와 위치를 결정적 원인으로 활용했는지 검토하였다.","In this paper, we analyzed driver""s and passenger""s motions that cause driver""s distraction, and recognized 10 driver""s behaviors related to mobile phones. First, distraction-inducing behaviors were classified into environments and factors, and related recent papers were analyzed. Based on the analyzed papers, 10 driver""s behaviors related to cell phones, which are the main causes of distraction, were recognized. The experiment was conducted based on about 100,000 image data. Features were extracted through SURF and tested with three models (CNN, ResNet-101, and improved ResNet-101). The improved ResNet-101 model reduced training and validation errors by 8.2 times and 44.6 times compared to CNN, and the average precision and f1-score were maintained at a high level of 0.98. In addition, using CAM (class activation maps), it was reviewed whether the deep learning model used the cell phone object and location as the decisive cause when judging the driver""s distraction behavior."
특권 정보를 이용하는 딥러닝 모델을 통한 폐렴 검출,2021,"['deep learning', 'privileged information', 'pneumonia detection']",,
명화 하브루타 지원을 위한 딥러닝 기반 동양화 인물 분석,2021,"['명화 하브루타', '미세조정', '성별 분류', '질문 생성', 'Famous Painting Habruta', 'Fine-Tuning', 'VGG16', 'Gender Classification', 'Question Generation']","하브루타 교육은 짝을 지어 대화하고 토론하고 논쟁하는 방식의 질문 중심 교육이며, 특히 명화 하브루타는 명화에 대한 질문과 답변을 통해 그림의 감상 능력을 증진하고 표현력을 풍부하게 하기 위한 목적으로 시행되고 있다. 본 연구에서는 동양화를 대상으로 한 명화 하브루타를 지원하기 위해, 최신 딥러닝 기술을 활용하여 동양화 등장인물의 성별 관점에서 질문을 자동으로 생성하는 방안을 제시한다. 구체적으로 본 연구에서는 사전학습모델인 VGG16을 바탕으로 동양화 인물 중심의 미세조정을 수행하여 동양화의 인물 분석을 효과적으로 수행할 수 있는 모델을 제안한다. 또한 질문의 유형을 명화 하브루타에서 사용되는 사실 질문, 상상 질문, 그리고 적용 질문의 3가지 유형으로 분류하고, 각 질문을 등장인물에 따라 세분화하여 총 9가지의 질문 패턴을 도출하였다. 제안 방법론의 활용 가능성을 확인하기 위해 실제 동양화의 등장인물 300건을 분석한 실험을 수행하였으며, 실험 결과 제안 방법론에 따른 성별 분류 모델이 기존 모델에 비해 높은 정확도를 나타냄을 확인하였다.","Habruta is a question-based learning that talks, discusses, and argues in pairs. In particular, the famous painting Habruta is being implemented for the purpose of enhancing the appreciation ability of paintings and enriching the expressive power through questions and answers about the famous paintings. In this study, in order to support the famous painting Habruta for oriental paintings, we propose a method of automatically generating questions from the gender perspective of oriental painting characters using the current deep learning technology. Specifically, in this study, based on the pre-trained model, VGG16, we propose a model that can effectively analyze the features of Asian paintings by performing fine-tuning. In addition, we classify the types of questions into three types: fact, imagination, and applied questions used in the famous Habruta, and subdivide each question according to the character to derive a total of 9 question patterns. In order to verify the feasibilityof the proposed methodology, we conducted an experiment that analyzed 300 characters of actual oriental paintings. As a result of the experiment, we confirmed that the gender classification model according to our methodology shows higher accuracy than the existing model."
댐 방류 의사결정지원을 위한 딥러닝 기법의 적용성 평가,2021,"['남강댐', '댐 운영', '수위 예측', '딥러닝', 'LSTM 모형', 'Nam river dam', 'Dam operation', 'Water level prediction', 'Deep learning', 'LSTM model']","기후변화에 따른 집중호우, 태풍 등의 발생빈도의 증가로 인하여 댐 운영의 고도화가 요구되고 있다. 일반적으로 댐 운영의 경우 강우예측, 강우-유출, 홍수추적 등 다양한 수리수문학적 요소들을 반영하여 수행되나 기 계획된 특정 규칙에 기반한 댐 운영 모형의 경우, 때때로 개별 모듈들의 불확실성과 복합적인 인자들로 인하여 댐의 방류량을 능동적으로 제어하는데 제약이 있을 수 있다. 본 연구는 남강댐 직하류 홍수피해 예방을 위하여 댐의 방류량 결정 등 효율적인 댐 운영을 지원하기 위해 딥러닝 기반 LSTM (Long Short-Term Memory) 모형을 구축하고, 선행시간별 댐직하류 수위예측 정확도를 분석하는 것을 목적으로 한다. LSTM 모형의 입력자료는 댐 운영에 사용되는 기초자료 및 하류 장대동 수위관측소의 수위 자료를 시 단위로 2009년부터 2021년 7월까지 수집하였다. 2009년부터 2018년 자료는 모형의 학습과 검증 및 2019년부터 2021년 7월 자료는 선행시간을 7개(1 h, 3 h, 6 h, 9 h, 12 h, 18 h, 24 h)로 구분하여 관측 수위와 예측 수위를 비교·분석하였다. 그 결과, 선행시간 1시간의 예측결과는 평균적으로 MAE가 0.01 m, RMSE가 0.015 m, NSE가 0.99 로 관측 수위에 매우 근접한 예측 결과를 나타내었다. 또한, 선행시간이 길어질수록 예측 정확도는 근소하게 감소하였지만, 관측 수위의 시간적 패턴을 유사하게 안정적으로 예측하는 것으로 분석되었다. 따라서 수리수문학적 비선형의 복잡한 자료간의 특징을 자동으로 추출하여 예측 자료를 생산하는 LSTM 모형은 댐 방류량 의사결정에 있어 활용이 가능할 것으로 판단된다.","The advancement of dam operation is further required due to the upcoming rainy season, typhoons, or torrential rains. Besides, physical models based on specific rules may sometimes have limitations in controlling the release discharge of dam due to inherent uncertainty and complex factors. This study aims to forecast the water level of the nearest station to the dam multi-timestep-ahead and evaluate the availability when it makes a decision for a release discharge of dam based on LSTM (Long Short-Term Memory) of deep learning. The LSTM model was trained and tested on eight data sets with a 1-hour temporal resolution, including primary data used in the dam operation and downstream water level station data about 13 years (2009~2021). The trained model forecasted the water level time series divided by the six lead times: 1, 3, 6, 9, 12, 18-hours, and compared and analyzed with the observed data. As a result, the prediction results of the 1-hour ahead exhibited the best performance for all cases with an average accuracy of MAE of 0.01m, RMSE of 0.015 m, and NSE of 0.99, respectively. In addition, as the lead time increases, the predictive performance of the model tends to decrease slightly. The model may similarly estimate and reliably predicts the temporal pattern of the observed water level. Thus, it is judged that the LSTM model could produce predictive data by extracting the characteristics of complex hydrological non-linear data and can be used to determine the amount of release discharge from the dam when simulating the operation of the dam."
UAV 항공 영상에서의 딥러닝 기반 잣송이 검출,2021,"['Unmanned aerial vehicle', 'Pine nut', 'Segmentation', 'Detection']","잣은 우리나라 대표적인 견과류 임산물이자 수익형 작물이다. 그러나 잣송이는 사람이 직접 나무 위로 올라가 수확하기 때문에 위험성이 높다. 이러한 문제를 해결하기 위해서 로봇 또는 UAV(unmanned aerial vehicle)를 이용한 잣송이 수확이 필요하다. 본 논문에서는 UAV를 이용한 잣송이 수확을 위해 UAV 항공 영상에서 딥러닝(deep learning) 기반의 잣송이 검출 기법을 제안한다. 이를 위해, UAV를 이용하여 실제 잣나무 숲에서 동영상을 촬영했으며, 적은 수의 데이터 보완을 위해 데이터 증강기법을 사용했다. 3D 검출을 위한 데이터로는 Unity3D을 이용하여 가상 잣송이 및 가상환경을 3D 모델링 하였으며 라벨링은 좌표계의 3차원 변환법을 이용해 구축했다. 잣 분포 영역 검출, 잣 객체에 대한 2D 및 3D 검출을 위한 딥러닝 알고리즘은 DeepLabV3, YOLOv4, CenterNet을 각각 이용하였다. 실험 결과, 잣송이 분포 영역 검출률은 82.15%, 2D 검출률은 86.93%, 3D 검출률은 59.45%이었다.","Pine nuts are Korea's representative nut forest products and profitable crops. However, pine nuts are harvested by climbing the trees themselves, thus the risk is high. In order to solve this problem, it is necessary to harvest pine nuts using a robot or an unmanned aerial vehicle(UAV). In this paper, we propose a deep learning based detection method for harvesting pine nut in UAV aerial images. For this, a video was recorded in a real pine forest using UAV, and a data augmentation technique was used to supplement a small number of data. As the data for 3D detection, Unity3D was used to model the virtual pine nut and the virtual environment, and the labeling was acquired using the 3D transformation method of the coordinate system. Deep learning algorithms for detection of pine nuts distribution area and 2D and 3D detection of pine nuts objects were used DeepLabV3+, YOLOv4, and CenterNet, respectively. As a result of the experiment, the detection rate of pine nuts distribution area was 82.15%, the 2D detection rate was 86.93%, and the 3D detection rate was 59.45%."
네트워크 분석을 활용한 딥러닝 기반 전공과목 추천 시스템,2021,"['교육 빅데이터', '노드 임베딩', '네트워크 분석', '딥러닝', '추천 시스템', 'Big data in Education', 'Deep learning', 'Network analysis', 'Node embedding', 'Recommendation system']",,"In university education, the choice of major class plays an important role in students careers. However, in line with the changes in the industry, the fields of major subjects by department are diversifying and increasing in number in university education. As a result, students have difficulty to choose and take classes according to their career paths. In general, students choose classes based on experiences such as choices of peers or advice from seniors. This has the advantage of being able to take into account the general situation, but it does not reflect individual tendencies and considerations of existing courses, and has a problem that leads to information inequality that is shared only among specific students. In addition, as non-face-to-face classes have recently been conducted and exchanges between students have decreased, even experience-based decisions have not been made as well. Therefore, this study proposes a recommendation system model that can recommend college major classes suitable for individual characteristics based on data rather than experience. The recommendation system recommends information and content (music, movies, books, images, etc.) that a specific user may be interested in. It is already widely used in services where it is important to consider individual tendencies such as YouTube and Facebook, and you can experience it familiarly in providing personalized services in content services such as over-the-top media services (OTT). Classes are also a kind of content consumption in terms of selecting classes suitable for individuals from a set content list. However, unlike other content consumption, it is characterized by a large influence of selection results. For example, in the case of music and movies, it is usually consumed once and the time required to consume content is short. Therefore, the importance of each item is relatively low, and there is no deep concern in selecting. Major classes usually have a long consumption time because they have to be taken for one semester, and each item has a high importance and requires greater caution in choice because it affects many things such as career and graduation requirements depending on the composition of the selected classes. Depending on the unique characteristics of these major classes, the recommendation system in the education field supports decision-making that reflects individual characteristics that are meaningful and cannot be reflected in experience-based decision-making, even though it has a relatively small number of item ranges. This study aims to realize personalized education and enhance students educational satisfaction by presenting a recommendation model for university major class. In the model study, class history data of undergraduate students at University from 2015 to 2017 were used, and students and their major names were used as metadata. The class history data is implicit feedback data that only indicates whether content is consumed, not reflecting preferences for classes. Therefore, when we derive embedding vectors that characterize students and classes, their expressive power is low. With these issues in mind, this study proposes a Net-NeuMF model that generates vectors of students, classes through network analysis and utilizes them as input values of the model. The model was based on the structure of NeuMF using one-hot vectors, a representative model using data with implicit feedback. The input vectors of the model are generated to represent the characteristic of students and classes through network analysis. To generate a vector representing a student, each student is set to a node and the edge is designed to connect with a weight if the two students take the same class. Similarly, to generate a vector representing the class, each class was set as a node, and the edge connected if any students had taken the classes in common. Thus, we utilize Node2Vec, a representation learning methodology that quantifies the charac"
반도체 장비 센서데이터와 딥러닝을 활용한 불량예측모델에 관한 연구,2021,"['반도체 불량예측', '센서 데이터', '딥러닝', 'FDC 시스템', 'Semiconductor defect prediction', 'Sensor data', 'Deep learning', 'FDC system']",,"This study proposes a model that predicts product quality based on AI by using deep learning from sensor data generated in facilities during the semiconductor manufacturing process. In semiconductor factories, there is a system for predicting defects called FDC (Fault Detection and Classification), but there is a limitation in setting and managing sensor standards for process managers due to the large number of alarm frequencies and high complexity automation systems. It is proposed to automatically provide sensor reference information by learning sensor data using deep learning of sensor data. The judgment result using the facility sensor data for one year for the same recipe of the same facility in one process is Accuracy, Precision, Recall, and F1-score were provided, and it was confirmed that the performance is superior to the existing FDC system."
전기화재 원인분석을 위한 용융흔 외형 판별 딥러닝 알고리즘 설계,2021,"['전기 화재', '단락흔', '열흔', 'CNN', 'Resnet 알고리즘', 'Electric fire', 'Arc beads', 'Molten mark', 'CNN', 'Resnet']",,
젯슨 나노 기반의 OpenCV 및 딥러닝을 사용한 스마트 도어 구현,2021,"['스마트 도어', '얼굴 인식', '딥러닝', '보안', '오픈씨브이', 'Smart Door', 'Facial Recognition', 'Deep Learning', 'Security', 'OpenCV']",,
악성코드의 특성 이미지화를 통한 딥러닝 기반의 탐지 모델,2021,"['악성코드', '지능화', '악성코드 변종', '딥러닝', '탐지 모델', 'Malware', 'Intelligence', 'Malware Variants', 'Deeplearning', 'Detection Model']",,
재난문자 분류를 위한 딥러닝 모델,2021,"['Disaster Alerts', 'Text Classification', 'Deep Learning', 'Word Embedding', 'BERT', '재난문자', '텍스트 분류', '딥러닝', '단어 임베딩']","재난문자는 재난 발생 시 국가에서 해당 지역에 있는 시민들에게 보내는 문자 메시지다. 재난문자의 발송 건수는 점점 증가하여, 불필요한 재난문자가 많이 수신됨에 따라 재난문자를 차단하는 사람들이 증가하고 있다. 이와 같은 문제를 해결하기 위하여, 본 연구에서는 재난문자를 재난 유형별로 자동으로 분류하고 수신자에 따라 필요한 재난의 재난문자만 수신하게 하는 딥러닝 모델을 제안한다. 제안 모델은 재난문자를 KoBERT를 통해 임베딩하고, LSTM을 통해 재난 유형별로 분류한다. [명사], [명사 + 형용사 + 동사], [모든 품사]의 3가지 품사 조합과 제안 모델, 키워드 분류, Word2Vec + 1D-CNN 및 KoBERT + FFNN의 4종류 분류 모델을 활용하여 재난문자를 분류한 결과, 제안 모델이 0.988954의 정확도로 가장 높은 성능을 달성하였다.","Disaster alerts are text messages sent by government to people in the area in the event of a disaster. Since the number of disaster alerts has increased, the number of people who block disaster alerts is increasing as many unnecessary disaster alerts are being received. To solve this problem, this study proposes a deep learning model that automatically classifies disaster alerts by disaster type, and allows only necessary disaster alerts to be received according to the recipient. The proposed model embeds disaster alerts via KoBERT and classifies them by disaster type with LSTM. As a result of classifying disaster alerts using 3 combinations of parts of speech: [Noun], [Noun + Adjective + Verb] and [All parts], and 4 classification models: Proposed model, Keyword classification, Word2Vec + 1D-CNN and KoBERT + FFNN, the proposed model achieved the highest performance with 0.988954 accuracy."
온사이트 지진조기경보를 위한 딥러닝 기반 실시간 오탐지 제거,2021,"['Earthquake early warning', 'Onsite warning', 'False-pick', 'False alarm', 'Deep learning', 'Convolutional neural network']",,"This paper presents a real-time, false-pick filter based on deep learning to reduce false alarms of an onsite Earthquake Early Warning (EEW) system. Most onsite EEW systems use P-wave to predict S-wave. Therefore, it is essential to properly distinguish P-waves from noises or other seismic phases to avoid false alarms. To reduce false-picks causing false alarms, this study made the EEWNet Part 1 'False-Pick Filter' model based on Convolutional Neural Network (CNN). Specifically, it modified the Pick_FP (Lomax et al.) to generate input data such as the amplitude, velocity, and displacement of three components from 2 seconds ahead and 2 seconds after the P-wave arrival following one-second time steps. This model extracts log-mel power spectrum features from this input data, then classifies P-waves and others using these features. The dataset consisted of 3,189,583 samples: 81,394 samples from event data (727 events in the Korean Peninsula, 103 teleseismic events, and 1,734 events in Taiwan) and 3,108,189 samples from continuous data (recorded by seismic stations in South Korea for 27 months from 2018 to 2020). This model was trained with 1,826,357 samples through balancing, then tested on continuous data samples of the year 2019, filtering more than 99% of strong false-picks that could trigger false alarms. This model was developed as a module for USGS Earthworm and is written in C language to operate with minimal computing resources."
고해상도 영상의 군집형 차량 검출을 위한 앙상블 딥러닝 네트워크 구성 방법,2021,"['Ensemble Deep-Learning Network', 'Voting Map', 'Dense Small Object Detection', 'High Resolution Image', 'Dynamic Windows', '앙상블 딥러닝 네트워크', '투표 맵', '밀집형 소형 물체 검출', '고해상도 이미지', '동적 윈도우']","본 논문은 고해상도를 가지는 영상에서 겹쳐져있는 소형 물체를 효과적으로 검출하고 추적하는 알고리즘을 제안한다. Coarse to Fine 방식을 기본으로 하는 두 개의 Deep-Learning Network을 앙상블 형태로 구성하여 차량이 존재할 위치를 미리 판단하고 서브영역으로 선택한 이미지로부터 차량을 정확하게 검출한다. Coarse 단계에서는 서로 다른 다수의 Deep-Learning Network 에 대한 각각의 결과로 Voting Space를 생성한다. 각 Voting Space 의 조합을 통해 Voting Map을 만들고 차량이 존재할 위치를 선택한다. Fine 단계에서는 Coarse 단계에서 선택된 영역을 기준으로 서브영역을 추출하고 해당 영역을 최종 Deep-Learning Network 에 입력한다. 서브 영역은 Voting Map을 이용하여 영상에서의 높이에 적합한 크기의 동적 윈도우를 생성함으로써 정의되며, 본 논문에서는 원거리에서 근거리로 접근하는 도로의 이미지를 대상으로 미리 계산된 매핑테이블을 적용하였다. 각 서브 영역 간 이동하는 차량의 동일성 판단은 검출된 영역의 하단 중심점에 대한 근접성을 기반으로 하였으며, 이를 통해 이동하는 차량의 정보를 트래킹 하였다. 실제 주야간 도로 CCTV를 통해 획득한 실시간 영상에서 처리 속도 및 검출 성능을 비교 실험하여 제안한 알고리즘을 평가하였다.","This paper has proposed an algorithm that detecting for dense small vehicle in large image efficiently. It is consisted of two Ensemble Deep-Learning Network algorithms based on Coarse to Fine method. The system can detect vehicle exactly on selected sub image. In the Coarse step, it can make Voting Space using the result of various Deep-Learning Network individually. To select sub-region, it makes Voting Map by to combine each Voting Space. In the Fine step, the sub-region selected in the Coarse step is transferred to final Deep-Learning Network. The sub-region can be defined by using dynamic windows. In this paper, pre-defined mapping table has used to define dynamic windows for perspective road image. Identity judgment of vehicle moving on each sub-region is determined by closest center point of bottom of the detected vehicle""s box information. And it is tracked by vehicle""s box information on the continuous images. The proposed algorithm has evaluated for performance of detection and cost in real time using day and night images captured by CCTV on the road."
차량 내·외부 데이터 및 딥러닝 기반 차량 위기 감지 시스템 설계,2021,"['Autonomous vehicles', 'Convolutional Neural Networks', 'You Only Look Once', 'Crisis Detection', 'Pedestrian recognition']","현재 자율주행차량 시장은 3레벨 자율주행차량을 상용화하고 있으나, 안정성의 문제로 완전 자율주행 중에도 사고가 발생할 가능성이 있다. 실제로 자율주행차량은 81건의 사고를 기록하고 있다. 3레벨과 다르게 4레벨 이후의 자율주행차량은 긴급상황을 스스로 판단하고 대처해야 하기 때문이다. 따라서 본 논문에서는 CNN을 통하여 차량 외부의 정보를 수집하여 저장하고, 저장된 정보와 차량 센서 데이터를 이용하여 차량이 처한 위기 상황을 0~1 사이의 수치로 출력하는 차량 내.외부 데이터 및 딥러닝 기반 차량 위기 감지 시스템을 제안한다. 차량 위기 감지 시스템은 CNN기반 신경망 모델을 사용하여 주변 차량과 보행자 데이터를 수집하는 차량 외부 상황 수집 모듈과 차량 외부 상황 수집 모듈의 출력과 차량 내부 센서 데이터를 이용하여 차량이 처한 위기 상황을 수치화하는 차량 위기 상황 판단 모듈로 구성된다. 실험 결과, VESCM의 평균 연산 시간은 55ms 였고, R-CNN은 74ms, CNN은 101ms였다. 특히, R-CNN은 보행자 수가 적을 때 VESCM과 비슷한 연산 시간을 보이지만, 보행자 수가 많아 질수록 VESCM보다 많은 연산 시간을 소요했다. 평균적으로 VESCM는 R-CNN보다 25.68%, CNN보다 45.54% 더 빠른 연산 시간을 가졌고, 세 모델의 정확도는 모두 80% 이하로 감소하지 않으며 높은 정확도를 보였다.","Currently, autonomous vehicle markets are commercializing a third-level autonomous vehicle, but there is a possibility that an accident may occur even during fully autonomous driving due to stability issues. In fact, autonomous vehicles have recorded 81 accidents. This is because, unlike level 3, autonomous vehicles after level 4 have to judge and respond to emergency situations by themselves. Therefore, this paper proposes a vehicle crisis detection system(VCDS) that collects and stores information outside the vehicle through CNN, and uses the stored information and vehicle sensor data to output the crisis situation of the vehicle as a number between 0 and 1. The VCDS consists of two modules. The vehicle external situation collection module collects surrounding vehicle and pedestrian data using a CNN-based neural network model. The vehicle crisis situation determination module detects a crisis situation in the vehicle by using the output of the vehicle external situation collection module and the vehicle internal sensor data. As a result of the experiment, the average operation time of VESCM was 55ms, R-CNN was 74ms, and CNN was 101ms. In particular, R-CNN shows similar computation time to VESCM when the number of pedestrians is small, but it takes more computation time than VESCM as the number of pedestrians increases. On average, VESCM had 25.68% faster computation time than R-CNN and 45.54% faster than CNN, and the accuracy of all three models did not decrease below 80% and showed high accuracy."
자동화 균열 탐지 시스템을 위한 딥러닝 모델에 관한 연구,2021,"['Surface Inspection', 'Crack Detection', 'Computer Vision', 'Deep Learning', '표면 검사', '균열 탐지', '컴퓨터 비전', '딥러닝']",,"Cracks affect the robustness of infrastructures such as buildings, bridge, pavement, and pipelines. This paper presents an automatedcrack detection system which detect cracks in diverse surfaces. We first constructed the combined crack dataset, consists of multiplecrack datasets in diverse domains presented in prior studies. Then, state-of-the-art deep learning models in computer vision tasks includingVGG, ResNet, WideResNet, ResNeXt, DenseNet, and EfficientNet, were used to validate the performance of crack detection. We dividedthe combined dataset into train (80%) and test set (20%) to evaluate the employed models. DenseNet121 showed the highest accuracyat 96.20% with relatively low number of parameters compared to other models. Based on the validation procedures of the advanced deeplearning models in crack detection task, we shed light on the cost-effective automated crack detection system which can be appliedto different surfaces and structures with low computing resources."
해외지수와 투자자별 매매 동향에 따른 딥러닝 기반 주가 등락 예측,2021,"['Stock Price Fluctuation Prediction', 'Deep Learning', 'Overseas Indices', 'Trading Trends by Investor', '주가 등락 예측', '딥러닝', '해외 지수', '투자자별 매매 동향']",,"Stock price prediction is a subject of research in various fields such as economy, statistics, computer engineering, etc. In recent years, researches on predicting the movement of stock prices by learning artificial intelligence models from various indicators such as basic indicators and technical indicators have become active. This study proposes a deep learning model that predicts the ups and downs of KOSPI from overseas indices such as S&P500, past KOSPI indices, and trading trends by KOSPI investors. The proposed model extracts a latent variable using a stacked auto-encoder to predict stock price fluctuations, and predicts the fluctuation of the closing price compared to the market price of the day by learning an LSTM suitable for learning time series data from the extracted latent variable to decide to buy or sell based on the value. As a result of comparing the returns and prediction accuracy of the proposed model and the comparative models, the proposed model showed better performance than the comparative models."
온라인 호텔 리뷰와 평점 불일치 문제 해결을 위한 딥러닝 기반 개인화 추천 서비스 연구,2021,"['개인화 추천 서비스', '협업 필터링', '감성분석', '딥러닝', 'Personalized recommendation services', 'collaborative filtering', 'sentiment analysis', 'deep learning']",,
수입물품의 HS 코드 자동 분류를 위한 자연어처리 기반의 딥러닝 모델 개발,2021,"['텍스트 마이닝', '문서분류', 'HS 코드', '딥러닝', '기계학습', 'Text Mining', 'Documents Classification', 'HS Code', 'Deep Learning', 'Machine Learning']",,"The Korean Customs Law requires the owner to directly classify items on imported goods and pay customs duties at the tax rate of the declared HS code. However, the rapid changes in the industrial environment, the expansion of trade, and the emergence of new convergence products have caused the lack of the owners’ knowledge on the classification of the imported goods. And this leads to the trade friction in both domestic and abroad. Therefore, this study aims to establish a deep learning model based on natural language processing that can classify HS codes automatically. The proposed model in this study recommends the HS code of imported goods using word embedding and deep learning techniques based soley on an item name, which is expected to help the owners cost reduction and accurate import declaration, thus helping to secure the national tax finance."
특징 융합과 공간 강조를 적용한 딥러닝 기반의 개선된 YOLOv4S,2021,"['Object Detection', 'Spatial attention', 'Deep learning', 'Feature fusion', 'PAN', 'YOLO', '객체 검출', '공간 강조', '딥러닝', '특징 융합', '특징 피라미드', '욜로']","본 논문은 특징 융합과 공간 강조를 적용하여 작고 페색된 객체 검출을 위한 개선된 YOLOv4S를 제안하였다. 기존 YOLOv4S은 경량 네트워크로 깊은 네트워크 대비 특징 추출 능력 부족하다. 제안하는 방법은 먼저 feature fusion으로 서로 다른 크기의 특징맵을 결합하여 의미론적 정보 및 저수준 정보를 개선하였다. 또한, dilated convolution으로 수용 영역을 확장하여 작고 폐색된 객체에 대한 검출 정확도를 향상시켰다. 두 번째로 spatial attention으로 기존 공간 정보 개선하여 객체간 구분되어 폐색된 객체의 검출 정확도를 향상시켰다. 제안하는 방법의 정량적 평가를 위해 PASCAL VOC 및 COCO 데이터세트를 사용하였다. 실험을 통해 제안하는 방법은 기존 YOLOv4S 대비 PASCAL VOC 데이터세트에서 mAP 2.7% 및 COCO 데이터세트에서 mAP 1.8% 향상되었다.","In this paper proposed a feature fusion and spatial attention-based modified YOLOv4S for small and occluded detection. Conventional YOLOv4S is a lightweight network and lacks feature extraction capability compared to the method of the deep network. The proposed method first combines feature maps of different scales with feature fusion to enhance semantic and low-level information. In addition expanding the receptive field with dilated convolution, the detection accuracy for small and occluded objects was improved. Second by improving the conventional spatial information with spatial attention, the detection accuracy of objects classified and occluded between objects was improved. PASCAL VOC and COCO datasets were used for quantitative evaluation of the proposed method. The proposed method improved mAP by 2.7% in the PASCAL VOC dataset and 1.8% in the COCO dataset compared to the Conventional YOLOv4S."
영상 데이터 특징 커버리지 기반 딥러닝 모델 검증 기법,2021,"['Deep Learning', 'Coverage Testing', 'Image Feature Extraction', 'Validation Method', 'Dataset Splitting Method', '딥러닝', '모델 테스팅', '영상 특징 추출', '검증 기법', '데이터 셋 분할 기법']",,"Deep learning techniques have been proven to have high performance in image processing and are applied in various fields. The most widely used methods for validating a deep learning model include a holdout verification method, a k-fold cross verification method, and a bootstrap method. These legacy methods consider the balance of the ratio between classes in the process of dividing the data set, but do not consider the ratio of various features that exist within the same class. If these features are not considered, verification results may be biased toward some features. Therefore, we propose a deep learning model validation method based on data feature coverage for image classification by improving the legacy methods. The proposed technique proposes a data feature coverage that can be measured numerically how much the training data set for training and validation of the deep learning model and the evaluation data set reflects the features of the entire data set. In this method, the data set can be divided by ensuring coverage to include all features of the entire data set, and the evaluation result of the model can be analyzed in units of feature clusters. As a result, by providing feature cluster information for the evaluation result of the trained model, feature information of data that affects the trained model can be provided."
봇 넷 트래픽 식별을 위한 스택구조 딥러닝 접근 방식,2021,"['Botnet', 'Botnet Detection System', 'Deep Learning', 'Convolutional Neural Network', 'CTU-13 Dataset', '넷', '봇 넷 검출 시스템', '딥러닝', 'CTU-13 데이터 셋']","봇 넷의 악의적인 행위는 인터넷 서비스 제공자뿐만 아니라 기업, 정부, 그리고 심지어 가정의 일반 사용자에 이르기까지 엄청난 경제적 손실을 끼치고 있다. 본 논문에서는 CTU-13 봇 넷 트래픽 데이터 셋을 사용하여 딥러닝 모델 Convolutional Neural Network(CNN)을 적용한 봇 넷 트래픽 검출에 대한 가능성을 확인하고자한다. 특히 알려진 봇 넷과 알려지지 않은 봇 넷 트래픽에 대해 C&C 서버를 검출하기 위한 봇과 C&C 서버 사이 트래픽, 봇을 검출하기 위한 C&C 통신 이외에 봇이 발생하는 트래픽, 그리고 정상 트래픽을 분류하는 멀티클래스 분류(multi-class classification)를 시도하였다. 성능검증을 위한 지표는 정확도, 정밀도, 재현율, 그리고 F1 점수를 제시하였다. 한편 확장성과 운영을 고려하여 봇 넷 타입 별로 모듈을 적재할 수 있는 스택구조의 봇 넷 검출 시스템을 제안함으로써 실제 네트워크의 적용 가능성을 제시하였다.","Malicious activities of Botnets are responsible for huge financial losses to Internet Service Providers, companies, governments and even home users. In this paper, we try to confirm the possibility of detecting botnet traffic by applying the deep learning model Convolutional Neural Network (CNN) using the CTU-13 botnet traffic dataset. In particular, we classify three classes, such as the C&C traffic between bots and C&C servers to detect C&C servers, traffic generated by bots other than C&C communication to detect bots, and normal traffic. Performance metrics were presented by accuracy, precision, recall, and F1 score on classifying both known and unknown botnet traffic. Moreover, we propose a stackable botnet detection system that can load modules for each botnet type considering scalability and operability on the real field."
대장 종양의 현미부수체 불안정성 검사에서 딥러닝의 유용성,2021,[],"대장 종양의 현미부수체 불안정성(microsatellite instability, MSI)과 부적합 결합 DNA 교정 기능 소실(mismatch repair deficiency, dMMR) 검사는 대장암 환자 치료제 선택의 중요한 고려 요소이다. MSI 검사는 Bethesda 패널 polymerase chain reaction (PCR)을 이용하며, MMR 검사는 MLH1, MSH2, MSH6, PMS2를 포함한 immunohistochemistry 패널을 이용한다. 이러한 검사를 위해서는 추가적인 조직 샘플 획득이 필요하며, 기존의 조직 슬라이드 검사 비용 외에 추가적인 비용이 발생하게 된다. 이 연구에서는 딥러닝 기법을 이용하여 일반적인 조직 슬라이드에서 MSI와 dMMR의 분석을 가능하게 하였고, 추가 분석에 따로 필요한 비용과 시간을 절약할 수 있게 하였다.저자들은 독일, 네덜란드, 영국, 미국의 MSDETECT 컨소시엄 스터디에서 총 8,836개 대장 종양의 헤마톡실린/에오진 염색 슬라이드와 분자 분석 결과를 수집하였고, 모든 슬라이드를 리뷰하여 슬라이드의 종양 조직 포함 유무 및 이미지 퀄리티를 확인하였다. 딥러닝 시스템이 헤마톡실린/에오진 염색 슬라이드에서 MSI 또는 dMMR 결과를 예측하도록 학습시켰고, 예측 정확도를 다기관 코호트를 이용하여 검증하였다. 그 결과 평균 area under the receiver operating characteristics 값이 0.92, 민감도가 95%, 특이도가 67%로 확인 되었다. 특히 슬라이드 이미지의 색 보정(color normalization) 후의 dMMR 예측에 대한 area under the receiver operating characteristics 값은 0.96이었다. 저자들은 이러한 시스템이 실제 임상에서 대장암 조직 검체를 분석을 위한 비용 절감 및 효율 증대 효과를 보일 것으로 기대하였다.",
음성학적 과학수사 용도의 달팽이관 모사 스펙트럼을 이용하는 딥러닝에 기반한 대화자 식별 알고리즘,2021,"['Deep learning', 'Speaker identification', 'Forensic science', 'Phonetics', 'Biomimetics']","제한된 증거를 바탕으로 하는 과학수사 분야에서는 최소한의 데이터로부터 최선의 결과를 얻을 수있는 알고리즘의 개발이 필요하다. 본 연구에서는 평균 0.556초의 짧은 음성을 이용하는 화자인식 딥러닝알고리즘을 개발하였다. 개발에 사용된 달팽이관 모사 스펙트럼은 음성 신호의 기존 파형을 최대한 유지하면서 인간이 청각 신호를 받아드리는 전처리 과정을 모사하여 딥러닝 네트워크가 분류에 집중하여 학습할수 있도록 하였다. 그 결과, 2차원 합성곱 신경망에 71명의 화자 중 1명의 음성을 무작위로 제시하였을 때교차검증 평균 정확도 96.2%로 1명의 화자를 식별하였다. 본 연구에서 수집한 데이터베이스는 거짓말탐지자극검사를 활용하여 추후 거짓말 탐지 연구에도 활용할 수 있을 뿐 아니라, 개발한 알고리즘은 전과자 데이터베이스를 활용하여 용의자를 특정하는 데에 활용할 수 있을 것으로 기대된다.",
열차자율주행을 위한 차상중심 환경인지 프레임워크 및 딥러닝 알고리즘 설계,2021,"['Environmental recognition', 'Artificial intelligence', 'Deep learning', 'Autonomous train control system', '환경인지', '인공지능', '딥러닝', '열차자율주행']",,
운전자 및 동승자 머리 자세 추정 및 딥러닝을 이용한 교통사고 모니터링 시스템,2021,"['Car Accident Detection', 'Deep Learning', 'YOLO', 'Head Pose Estimation', 'HSV']",,
웨어러블 기기를 위한 광혈류 데이터 기반 혈압 측정 하이브리드 딥러닝 시스템의 구축,2021,"['Blood Pressure Estimation', 'Hybrid Deep Learning', 'Photoplethysmography', 'Wearable']",,"In this work, we developed a PPG-based blood pressure estimation hybrid deep learning model built into wearable devices and used by hypertension patients to monitor blood pressure in real-time in their daily lives. The model is a deep-learning model that combines data preprocessing, Autoencoder deep learning model for feature extraction, and RAN regression model developed by this research team. We conducted experiments to compare the blood pressure prediction performance of the proposed model with other deep learning models and find out how the objective blood pressure prediction performance is. We conducted experiments on an open dataset with the vital signs of 32 subjects. After models trained on 24 subjects’ data and are tested on eight other people’s data, we could see that using deep-learning regression models combined with an Autoencoder (hybrid deep-learning) performs better than using a deep learning model alone, and RAN accurately predicts blood pressure than the comparable deep-learning models. The study found that the average error for actual and predicted blood pressure in the proposed hybrid deep-learning models was 4.67 mmHg, and the standard deviation of error was 6.37 mmHg. It satisfies the accuracy criteria presented by the Korean National Institute of Food and Drug Safety Evaluation."
코로나19 2차 유행기 “사회적 거리두기” 보도 분석 : 딥러닝을 중심으로 한 언론사 선정 주요 뉴스 분석을 중심으로,2021,"['COVID-19', 'Social Distancing', 'Risk Communication', 'Deep Learning', 'Featured News', '코로나19', '사회적 거리두기', '위험 커뮤니케이션', '딥러닝', '언론사 주요뉴스']",,"This study analyzed news articles on “social distancing” during the second wave of the COVID-19 pandemic in order to explain how the media sets the agenda on the pandemic crisis and the government’s response, focusing on the news articles featured in the news portals. This study first analyzed confirmed cases of COVID-19 infection and government announcements during the second wave of COVID-19 spread and divided the period into five phases. Then, news articles of 12 media companies were collected from online news portals and pre-processed into a 14,011 news corpus. The analysis methods were frequency analysis, keyword co-occurrence network, and Top2Vec modeling that uses deep learning embedding for time-series visualization. As a result, the articles related to “Social Distancing” showed a higher featured news ratio than “COVID-19.” The newspapers had a higher ratio of featured news preference than television. For featured news, the proportion of national, politics, economy sections and phase 1, 2 were higher than other sections and phases. However, the proportion of non-featured news showed more diverse section and increase in fifth phase as social distancing was mitigated to level 1. Regarding keyword network, featured and non-featured news shared many keywords related to the confirmed cases and social distancing policies. Still, keywords in non-featured news showed more diverse topic keywords. We found the keywords related to the confirmed cases and social distancing in whole phases. In terms of unique keywords, each phase reflected conflicts in social distancing and concerns about re-proliferation of COVID-19. For the news sections, information about confirmed cases and social distancing were found in whole sections. However, except for the national section, all sections showed unique keywords linked to conflicts and criticism about social distancing. The embedding topic model indicated an imbalance in the featured and non-featured news among some topics. For featured news topics, conflicts about social distancing and government announcements were found as major issues. For non-featured news, confirmed cases in the local community and various problems related to social distancing comprised major issues. In featured news topics, the social and political sections were influential in the first and second phases, and non-featured news provided more diverse sections and phases. For visualization, topics linked to conflict were concentrated in the first and second phases, and effects of policy changes were mostly found in the fourth and fifth phases. Topics that had lower correlation with social distancing showed irregular patterns. The results suggest that the news companies showed contradictory tendencies in their coverage of social distancing in the second wave of COVID-19, in the portal news environment and “featured news.”"
HSV 컬러 모델 및 코너 검출 알고리즘을 이용한 딥러닝 기반의 화염 감지에 관한 연구,2021,"['Artificial intelligence', 'Deep learning', 'HSV color model', 'Corner detection algorithm', 'CNN']","최근 딥러닝 기법을 이용한 이미지 분류 모델이나 객체 감지 모델이 많이 연구되고 있지만 적절한 전처리 방법을설계하지 않을 경우 성능 평가 결과 낮은 정확도를 얻을 수 있다. 따라서 본 연구에서 제안하는 효과적인 화염검출전처리 방법으로는 HSV 컬러 모델과 Harris 코너 검출 알고리즘을 적용한 이미지 전처리 방법이다. HSV 컬러 모델을 통해 화염이 존재하는 색상영역을 필터링하고, 필터링된 결과물에 대해 Harris 코너 검출 방법을 적용할 경우 화염 이미지의 거친 질감 특성 때문에 화염 주변에 집중적으로 코너가 검출되게 된다. 이러한 특성을 통해 코너가 다수발생한 영역을 관심영역으로 검출하여 딥러닝 기반의 합성곱신경망(Convolutional neural network, CNN) 모델을 통해최종적으로 화염 여부를 분류하도록 하였다. 그 결과 본 연구에서 제안한 모델의 화염 검출 결과 정확도는 97.5%정밀도는 97%로 나타났다.","Recently, many image classification or object detection models that use deep learning techniques have been studied;however, in an actual performance evaluation, flame detection using these models may achieve low accuracy. Therefore,the flame detection method proposed in this study is image pre-processing with HSV color model conversion and the Harriscorner detection algorithm. The application of the Harris corner detection method, which filters the output from the HSVcolor model, allows the corners to be detected around the flame owing to the rough texture characteristics of the flameimage. These characteristics allow for the detection of a region of interest where multiple corners occur, and finally classifythe flame status using deep learning-based convolutional neural network models. The flame detection of the proposed modelin this study showed an accuracy of 97.5% and a precision of 97%."
서울시 가로환경 요소의 시각적 특성이 보행만족도에 미치는 영향 분석 - 구글 가로이미지와 딥러닝 의미론적 분할 기법을 활용하여,2021,"['Street Environment', 'Walking Satisfaction', 'Google Street View', 'Computer Vision', 'Deep Learning', 'Semantic Segmentation', '가로환경', '보행만족도', '구글 가로이미지', '컴퓨터 비전', '딥러닝', '의미론적 분할']","본 연구는 미시적 가로환경 요소를 구글 가로이미지와 컴퓨터 비전 기법을 적용하여 정량화하고,􀀁 보행자가 느끼는 보행만족도와의􀀁 관계를 분석하였다.􀀁 주요 연구결과는 다음과 같다.􀀁 정량화된가로환경 요소는 보행만족도와 통계적으로 유의한 상관관계가 있는 것으로 나타났다.􀀁 첫째,􀀁 건물,􀀁 자동차,􀀁 표지판은 보행만족도에 부정적인 영향을 주는 것으로 나타났으며,􀀁 해당 요소들은 보행자에게 폐쇄감,􀀁 낮은 심미성을 제공하기 때문인 것으로 해석된다.􀀁 따라서 보차􀀁 분리를 통한 차량과보행자와의 이격,􀀁 간판 개선사업을 통한 옥외광고물 개선 및 정비를 통해 보행환경을 개선할 수있을 것으로 판단된다.􀀁 둘째,􀀁 가로변 녹지(교목,􀀁 관목,􀀁 초화)는 보행만족도에 긍정적인 영향을 주는 것으로 나타나 가로수 식재를 통한 띠녹지 조성,􀀁 건물녹화 정책들을 통해 보행만족도를 향상시킬 수 있을 것으로 기대된다.􀀁 셋째,􀀁 시각적 복잡도는 보행만족도와 역 U자형 관계를 갖는􀀁 것으로 나타났다.􀀁 이는 단조로운 가로환경이나􀀁 과도하게 복잡한 가로환경은 보행만족도에 부정적인영향을 미치는 것으로 적정수준의 시각적 복잡도가 보행만족도에 중요함을 시사한다.","This study focuses on the quantification of urban street elements, and the analysis of the relationship between urban street elements and walking satisfaction. The result of the study shows that quantified street elements have significant relationships with walking satisfaction. First, buildings, automobiles, and signboards have negative associations with walking satisfaction due to the closedness and lack of aesthetic impression. This finding indicates that the walking environment can be improved through the separation of pedestrians from vehicles and the maintenance of complex signboards. Second, street trees (e.g., trees, shrubs, flowers) have positive associations with walking satisfaction.This finding suggests that walking satisfaction can be improved through the implementation of greenery strategies for roadways and buildings. Third, this study finds that visual complexity has an inverted U-shaped relationship with walking satisfaction.In other words, a monotonous street environment or an excessively complex street environment has a negative association with walking satisfaction, suggesting that an appropriate level of visual complexity is important for walking satisfaction."
딥러닝 및 토픽모델링 기법을 활용한 소셜 미디어의 자살 경향 문헌 판별 및 분석,2021,[],,"This study aims to create a deep learning-based classification model to classify suicide tendency by suicide corpus constructed for the present study. Also, to analyze suicide factors, the study classified suicide tendency corpus into detailed topics by using topic modeling, an analysis technique that automatically extracts topics. For this purpose, 2,011 documents of the suicide-related corpus collected from social media naver knowledge iN were directly annotated into suicide-tendency documents or non-suicide-tendency documents based on suicide prevention education manual issued by the Central Suicide Prevention Center, and we also conducted the deep learning model(LSTM, BERT, ELECTRA) performance evaluation based on the classification model, using annotated corpus data. In addition, one of the topic modeling techniques, LDA identified suicide factors by classifying thematic literature, and co-word analysis and visualization were conducted to analyze the factors in-depth."
딥러닝을 이용한 마스크 착용 여부 검사 시스템,2021,[],,"Recently, due to COVID-19, studies have been popularly worked to apply neural network to mask wearing automatic detection system. For applying neural networks, the 1-stage detection or 2-stage detection methods are used, and if data are not sufficiently collected, the pretrained neural network models are studied by applying fine-tuning techniques. In this paper, the system is consisted of 2-stage detection method that contain MTCNN model for face recognition and ResNet model for mask detection. The mask detector was experimented by applying five ResNet models to improve accuracy and fps in various environments. Training data used 17,217 images that collected using web crawler, and for inference, we used 1,913 images and two one-minute videos respectively. The experiment showed a high accuracy of 96.39% for images and 92.98% for video, and the speed of inference for video was 10.78fps."
딥러닝을 활용한 피부 발적의 경계 판별,2021,"['Skin prick test', 'Erythema', 'U-Net', 'Small computer']",,
딥러닝을 활용한 마스크 착용 얼굴 체온 측정 시스템,2021,"['Deep Learning', 'Face Recognition', 'Detect Wearing Mask', 'Temperature Check', 'Contactless System']",,
딥러닝 기반 Deraining 기법 비교 및 연구 동향,2021,"['Attention', 'Deraining', 'Generalization', 'Rain removal', 'Unsupervised learning']",,Deraining is one of the image restoration tasks and should consider a tradeoff between local details and broad contextual information while recovering images. Current studies adopt an attention mechanism which has been actively researched in natural language processing to deal with both global and local features. This paper classifies existing deraining methods and provides comparative analysis and performance comparison by using several datasets in terms of generalization.
딥러닝 기반의 반려묘 모니터링 및 질병 진단 시스템,2021,"['Cat Monitoring and Disease Diagnosis System', 'LSTM', 'GAN', 'Multi-Species Sensor', 'Veterinary Science']",,
딥러닝을 이용한 비트코인 투자전략의 성과 분석,2021,[],,"Bitcoin prices have been soaring recently as investors flock to cryptocurrency exchanges. The purpose of this study is to predict the Bitcoin price using a deep learning model and analyze whether Bitcoin is profitable through investment strategy. LSTM is utilized as Bitcoin prediction model with nonlinearity and long-term memory and the profitability of MA cross-over strategy with predicted prices as input variables is analyzed. Investment performance of Bitcoin strategy using LSTM forecast prices from 2013 to 2021 showed return improvement of 5.5% and 46% more than market price MA cross-over strategy and benchmark Buy & Hold strategy, respectively. The results of this study, which expanded to recent data, supported the inefficiency of the cryptocurrency market, as did previous studies, and showed the feasibility of using the deep learning model for Bitcoin investors. In future research, it is necessary to develop optimal prediction models and improve the profitability of Bitcoin investment strategies through performance comparison of various deep learning models."
딥러닝 모델의 압축 방법에 따른 엣지 장치에서의 성능 평가 연구,2021,"['Compression', 'Edge device', 'Knowledge Distillation', 'Pruning', 'Quantization']",,
딥러닝 기반 활주로 청소 로봇 개발,2021,"['YOLO', 'Deep Learning', 'Real Time Object Detection', 'FOD (Foreign Object Debris)', 'Runway Cleaning Robot']",,"This paper deals with the development of a deep-learning-based runway cleaning robot using an optical camera. A suitable model to realize real-time object detection was investigated, and the differences between the selected YOLOv3 and other deep learning models were analyzed. In order to check whether the proposed system is applicable to the actual runway, an experiment was conducted by making a prototype of the robot and a runway model. As a result, it was confirmed that the robot was well developed because the detection rate of FOD (Foreign Object Debris) and cracks was high, and the collection of foreign substances was carried out smoothly."
딥러닝 기반의 PCB 부품 문자인식을 위한 코어 셋 구성,2021,"['Deep Learning', 'Coreset', 'PCB Inspection', 'OCR', 'ResNet']",,
딥러닝 언어모델과 중국어 문법 ―BERT를 활용한 방향보어의 예측 모형을 중심으로,2021,"['Deep learning', 'Language model', 'BERT', 'Directional complement', 'Transfer learning', 'Pre-training', 'Fine-tuning']",,"In this study, we investigated how accurately the BERT model can predict Chinese directional complement. In addition, we analyzed which words the BERT model uses as an important clue in the Chinese directional complement inference process. According to the results of this study, it can be seen that the BERT model shows excellent performance in inferring distributional features and grammatical relationships based on transfer learning. Results of experiments with five Chinese directional complements show that the accuracy rate of predictions is quite high. In addition, as a result of analysis using the masked language model, it was found that the BERT model appropriately uses important clues to determine Chinese directional complement in context.We believe that this study is not only meaningful in the field of NLP, but also provides insight into Chinese grammar research or language education. If this methodology is properly utilized, it will be possible to establish an application system for Chinese grammar research and education. In Neural network models, sufficient language data learning allows us to predict which language expressions are more natural to use. Proper use of these advantages will give us insight into Chinese grammatical functions. This Chinese grammar prediction system will also help Chinese learners improve their skills by showing them what expressions are grammatically correct."
딥러닝 기반 언어모델을 이용한 언론과 주택가격의 상관관계 연구,2021,"['빅데이터', '언론', 'KoBERT', 'VAR 모형', '그랜저 인과관계', '충격반응함수', 'Big data', 'Media', 'VAR model', 'Granger causality test', 'Impulse-response function']",,"This study compiles data set with approximately 3 million rows by scraping news content in six categories (financial, security, industrial/business, real estate, global economy, and economy general) among news articles on Naver Portal. The KoBERT model, a deep learning-based natural language processing model, is applied to the compiled datasets to classify polarity values (positive, neutral, and negative), and is empirically analyzed through the VAR model of the Korea Real Estate Agency's housing price index. The temporal range of the news article is from July 2011 to June 2021, and the spatial range consists of the metropolitan areas, local areas, Seoul, Gangnam, and Gangbuk, Seoul, and the content range is set as apartments, multi-family houses, and detached houses. Among the news categories, the real estate and financial media indexes have a significant impact on housing prices in the metropolitan area and Seoul, while the media indexes in the general categories of security, industrial business, global economy, and economy have a significant effect on housing prices in national or local cities."
딥러닝 기반의 TSV Hole TCD 계측 방법,2021,"['TSV', 'Deep Learning', 'Metrology']",,"The TCD is used as one of the indicators for determining whether TSV Hole is defective. If the TCD is not normal size, it can lead to contamination of the CMP equipment or failure to connect the upper and lower chips. We propose a deep learning model for measuring the TCD. To verify the performance of the proposed model, we compared the prediction results of the proposed model for 2461 via holes with the CD-SEM measurement data and the prediction results of the existing model. Although the number of trainable parameters in the proposed model was about one two-thousandth of the existing model, the results were comparable. The experiment showed that the correlation between CD-SEM and the prediction results of the proposed model measured 98%, the mean absolute difference was 0.051um, the standard deviation of the absolute difference was 0.045um, and the maximum absolute difference was 0.299um on average."
딥러닝을 이용한 육불화텅스텐(WF6) 제조 공정의 지능형 영상 감지 시스템 구현,2021,"['object detection', 'you only look once (YOLO)', 'tungsten hexafluoride (WF6)', 'reduction', 'defect detection.']",,"Through the process of chemical vapor deposition, Tungsten Hexafluoride (WF6) is widely used by the semiconductor industry to form tungsten films. Tungsten Hexafluoride (WF6) is produced through manufacturing processes such as pulverization, wet smelting, calcination and reduction of tungsten ores. The manufacturing process of Tungsten Hexafluoride (WF6) is required thorough quality control to improve productivity. In this paper, a real-time detection system for oxidation defects that occur in the manufacturing process of Tungsten Hexafluoride (WF6) is proposed. The proposed system is implemented by applying YOLOv5 based on Convolutional Neural Network (CNN); it is expected to enable more stable management than existing management, which relies on skilled workers. The implementation method of the proposed system and the results of performance comparison are presented to prove the feasibility of the method for improving the efficiency of the WF6 manufacturing process in this paper. The proposed system applying YOLOv5s, which is the most suitable material in the actual production environment, demonstrates high accuracy (mAP@0.5 99.4 %) and real-time detection speed (FPS 46)."
딥러닝을 활용한 과학관 전시품 선호도 분석 방법 개발,2021,"['Science Museum', 'TensorFlow', 'Visitor Preference', 'Data Collection']",,
딥러닝을 이용한 포트홀 검출 시스템,2021,"['Deep Learning', 'Machine Learning', 'Object Detection', 'Pothole Detection', 'Road Defect Detection']",,"The automotive industry is developing day by day. Among them, it is very important to prevent accidents while driving. However, despite the importance of developing automobile industry technology, accidents due to road defects increase every year, especially in the rainy season. To this end, we proposed a road defect detection system for road management by converging deep learning and raspberry pi, which show various possibilities. In this paper, we developed a system that visually displays through a map after analyzing the images captured by the Raspberry Pi and the route GPS. The deep learning model trained for this system achieved 96% accuracy. Through this system, it is expected to manage road defects efficiently at a low cost."
딥러닝을 이용한 핸드크림의 마찰 시계열 데이터 분류,2021,"['Time Series Classification', 'Deep Learning', 'Tribology', 'Cosmetics']",,"The sensory stimulation of a cosmetic product has been deemed to be an ancillary aspect until a decade ago. That point of view has drastically changed on different levels in just a decade. Nowadays cosmetic formulators should unavoidably meet the needs of consumers who want sensory satisfaction, although they do not have much time for new product development. The selection of new products from candidate products largely depend on the panel of human sensory experts. As new product development cycle time decreases, the formulators wanted to find systematic tools that are required to filter candidate products into a short list. Traditional statistical analysis on most physical property tests for the products including tribology tests and rheology tests, do not give any sound foundation for filtering candidate products. In this paper, we suggest a deep learning-based analysis method to identify hand cream products by raw electric signals from tribological sliding test. We compare the result of the deep learning-based method using raw data as input with the results of several machine learning-based analysis methods using manually extracted features as input. Among them, ResNet that is a deep learning model proved to be the best method to identify hand cream used in the test. According to our search in the scientific reported papers, this is the first attempt for predicting test cosmetic product with only raw time-series friction data without any manual feature extraction. Automatic product identification capability without manually extracted features can be used to narrow down the list of the newly developed candidate products."
딥러닝 기법을 활용한 산업/직업 자동코딩 시스템,2021,['/'],,"An Automated Industry and Occupation Coding System assigns statistical classification code to the enormous amount of natural language data collected from people who write about their industry and occupation. Unlike previous studies that applied information retrieval, we propose a system that does not need an index database and gives proper code regardless of the level of classification. Also, we show our model, which utilized KoBERT that achieves high performance in natural language downstream tasks with deep learning, outperforms baseline. Our method achieves 95.65%, 91.51%, and 97.66% in Occupation/Industry Code Classification of Population and Housing Census, and Industry Code Classification of Census on Basic Characteristics of Establishments. Moreover, we also demonstrate future improvements through error analysis in the respect of data and modeling."
딥러닝을 활용한 철도 터널 객체 분할에 학습 데이터가 미치는 영향,2021,"['Deep learning', 'Point cloud data', 'Railroad tunnel', 'Scan-to-BIM', 'Semantic segmentation']",,
딥러닝 기반 객체 인식을 활용한 퍼스널 모빌리티 안전 보조 시스템 개발,2021,"['Deep learning', 'Driver safety', 'Object detection', 'Personal mobility']",,"Recently, the demand for the use of personal mobility vehicles, such as an electric kickboard, is increasing explosively because of its high portability and usability. However, the number of traffic accidents caused by personal mobility vehicles has also increased rapidly in recent years. To address the issues regarding the driver’s safety, we propose a novel approach that can monitor context information around personal mobility vehicles using deep learning-based object detection and smartphone captured videos. In the proposed framework, a smartphone is attached to a personal mobility device and a front or rear view is recorded to detect an approaching object that may affect the driver's safety. Through the detection results using YOLOv5 model, we report the preliminary results and validated the feasibility of the proposed approach."
딥러닝 모델을 이용한 휴대용 무선 초음파 영상에서의 경동맥 내중막 두께 자동 분할 알고리즘 개발,2021,"['IMT', 'Segmentation', 'U-Net', 'Attention U-Net', 'Pretrained U-Net', 'Preprocessing']",,"Measuring Intima-media thickness (IMT) with ultrasound images can help early detection of coronary artery disease. As a result, numerous machine learning studies have been conducted to measure IMT. However, most of these studies require several steps of pre-treatment to extract the boundary, and some require manual intervention, so they are not suitable for on-site treatment in urgent situations. in this paper, we propose to use deep learning networks U-Net, Attention U-Net, and Pretrained U-Net to automatically segment the intima-media complex. This study also applied the HE, HS, and CLAHE preprocessing technique to wireless portable ultrasound diagnostic device images. As a result, The average dice coefficient of HE applied Models is 71% and CLAHE applied Models is 70%, while the HS applied Models have improved as 72% dice coefficient. Among them, Pretrained U-Net showed the highest performance with an average of 74%. When comparing this with the mean value of IMT measured by Conventional wired ultrasound equipment, the highest correlation coefficient value was shown in the HS applied pretrained U-Net."
딥러닝 이미지 인식 기술을 활용한 소고기 등심 세부 부위 분류,2021,"['Deep learning', 'Image recognition', 'Classification', 'Data augmentation', 'Beef section']",,"This research examines deep learning based image recognition models for beef sirloin classification. The sirloin of beef can be classified as the upper sirloin, the lower sirloin, and the ribeye, whereas during the distribution process they are often simply unified into the sirloin region. In this work, for detailed classification of beef sirloin regions we develop a model that can learn image information in a reasonable computation time using the MobileNet algorithm. In addition, to increase the accuracy of the model we introduce data augmentation methods as well, which amplifies the image data collected during the distribution process. This data augmentation enables to consider a larger size of training data set by which the accuracy of the model can be significantly improved. The data generated during the data proliferation process was tested using the MobileNet algorithm, where the test data set was obtained from the distribution processes in the real-world practice. Through the computational experiences we confirm that the accuracy of the suggested model is up to 83%. We expect that the classification model of this study can contribute to providing a more accurate and detailed information exchange between suppliers and consumers during the distribution process of beef sirloin."
딥러닝 기반 제조 공장 내 AGV 객체 인식에 대한 연구,2021,[],,"In this research, the accuracy of YOLO v3 algorithm in object detection during AGV (Automated Guided Vehicle) operation was investigated. First of all, AGV with 2D LiDAR and stereo camera was prepared. AGV was driven along the route scanned with SLAM (Simultaneous Localization and Mapping) using 2D LiDAR while front objects were detected through stereo camera. In order to evaluate the accuracy of YOLO v3 algorithm, recall, AP (Average Precision), and mAP (mean Average Precision) of the algorithm were measured with a degree of machine learning. Experimental results show that mAP, precision, and recall are improved by 10%, 6.8%, and 16.4%, respectively, when YOLO v3 is fitted with 4000 training dataset and 500 testing dataset which were collected through online search and is trained additionally with 1200 dataset collected from the stereo camera on AGV."
딥러닝을 이용한 달 크레이터 탐지,2021,[],,"The exploration of the solar system is carried out through various payloads, and accordingly, many research results are emerging. We tried to apply deep-learning as a method of studying the bodies of solar system. Unlike Earth observation satellite data, the data of solar system differ greatly from celestial bodies to probes and to payloads of each probe. Therefore, it may be difficult to apply it to various data with the deep-learning model, but we expect that it will be able to reduce human errors or compensate for missing parts. We have implemented a model that detects craters on the lunar surface. A model was created using the Lunar Reconnaissance Orbiter Camera (LROC) image and the provided shapefile as input values, and applied to the lunar surface image. Although the result was not satisfactory, it will be applied to the image of the permanently shadow regions of the Moon, which is finally acquired by ShadowCam through image pre-processing and model modification. In addition, by attempting to apply it to Ceres and Mercury, which have similar the lunar surface, it is intended to suggest that deep-learning is another method for the study of the solar system."
딥러닝 학습을 위한 초분광 영상 데이터 관리 소프트웨어 개발,2021,"['Hyper-Spectral Image', 'Deep Learning', 'Dataset Training', 'Data Management']",,"The hyper-spectral image is data obtained by dividing the electromagnetic wave band in the infrared region into hundreds of wavelengths. It is used to find or classify objects in various fields. Recently, deep learning classification method has been attracting attention. In order to use hyper-spectral image data as deep learning training data, a processing technique is required compared to conventional visible light image data. To solve this problem, we developed a software that selects specific wavelength images from the hyper-spectral data cube and performs the ground truth task. We also developed software to manage data including environmental information. This paper describes the configuration and function of the software."
딥러닝 합성곱에서 데이터 재사용에 최적화된 GPGPU 설계,2021,"['Data Reuse', 'CNN', 'GPGPU', 'Row stationary', 'SIMT', 'Warp', 'Register bank']","본 논문은 합성곱 신경망에 데이터 재사용 방법을 효과적으로 적용하여 연산 횟수와 메모리 접근 횟수를 줄일 수 있는 GPGPU구조를 제안한다. 합성곱은 kernel과 입력 데이터를 이용한 2차원 연산으로 kernel이 slide하는 방법으로 연산이 이루어 진다. 이때, 합성곱 연산이 완료될 때 까지 kernel을 캐시메모리로 부터 전달 받는 것이 아니고 내부 레지스터를 이용하는 재사용 방법을 제안한다. SIMT방법으로 명령어가 실행되는 GPGPU의 원리 이용하여 데이터 재사용의 효과를 높이기 위해 합성곱에 직렬 연산 방식을 적용하였다. 본 논문에서는 레지스터기반 데이터 재사용을 위하여 kernel을 4x4로 고정하고 이를 효과적으로 지원하기 위한 warp 크기와 레지스터 뱅크를 갖는 GPGPU를 설계하였다. 설계된 GPGPU의 합성곱 신경망에 대한 성능을 검증하기 위해 FPGA로 구현한 뒤 LeNet을 실행시키고 TensorFlow를 이용한 비교 방법으로 AlexNet에 대한 성능을 측정하였다. 측정결과 AlexNet기준 1회 학습 속도는 0.468초이며 추론 속도는 0.135초이다.","This paper proposes a GPGPU structure that can reduce the number of operations and memory access by effectively applying a data reuse method to a convolutional neural network(CNN). Convolution is a two-dimensional operation using kernel and input data, and the operation is performed by sliding the kernel. In this case, a reuse method using an internal register is proposed instead of loading kernel from a cache memory until the convolution operation is completed. The serial operation method was applied to the convolution to increase the effect of data reuse by using the principle of GPGPU in which instructions are executed by the SIMT method. In this paper, for register-based data reuse, the kernel was fixed at 4x4 and GPGPU was designed considering the warp size and register bank to effectively support it. To verify the performance of the designed GPGPU on the CNN, we implemented it as an FPGA and then ran LeNet and measured the performance on AlexNet by comparison using TensorFlow. As a result of the measurement, 1-iteration learning speed based on AlexNet is 0.468sec and the inference speed is 0.135sec."
딥러닝을 이용한 기형도 시의 핵심 이미지 분석,2021,[],,It's possible to get the word-vector by the statistical SVD or deep-learning CBOW and LSTM methods and theses ones learn the contexts of forward/backward words or the sequence of following words. It's used to analyze the poems by Ki Hyung-do with similar words recommended by the word-vector showing the core images of the poetry. It seems at first sight that the words don't go well with the images but they express the similar style described by the reference words once you look close the contexts of the specific poems. The word-vector can analogize the words having the same relations with the ones between the representative words for the core images of the poems. Therefore you can analyze the poems in depth and in variety with the similarity and analogy operations by the word-vector estimated with the statistical SVD or deep-learning CBOW and LSTM methods.
딥블록: 웹 기반 딥러닝 교육용 플랫폼,2021,"['Artificial Intelligence', 'Block Coding', 'Cloud Service', 'Deep Learning', 'Education Platform']",,"Recently, researches and projects of companies based on artificial intelligence have been actively carried out. Various services and systems are being grafted with artificial intelligence technology. They become more intelligent. Accordingly, interest in deep learning, one of the techniques of artificial intelligence, and people who want to learn it have increased. In order to learn deep learning, deep learning theory with a lot of knowledge such as computer programming and mathematics is required. That is a high barrier to entry to beginners. Therefore, in this study, we designed and implemented a web-based deep learning platform called DeepBlock, which enables beginners to implement basic models of deep learning such as DNN and CNN without considering programming and mathematics. The proposed DeepBlock can be used for the education of students or beginners interested in deep learning."
딥러닝 기반 초음파 홀로그램 생성 알고리즘 개발,2021,[],,"Recently, an ultrasound hologram and its applications have gained attention in the ultrasound research field. However, the determination technique of transmit signal phases, which generate a hologram, has not been significantly advanced from the previous algorithms which are time-consuming iterative methods. Thus, we applied the deep learning technique, which has been previously adopted to generate an optical hologram, to generate an ultrasound hologram. We further examined the Deep learning-based Holographic Ultrasound Generation algorithm (Deep-HUG). We implement the U-Net-based algorithm and examine its generalizability by training on a dataset, which consists of randomly distributed disks, and testing on the alphabets (A-Z). Furthermore, we compare the Deep-HUG with the previous algorithm in terms of computation time, accuracy, and uniformity. It was found that the accuracy and uniformity of the Deep-HUG are somewhat lower than those of the previous algorithm whereas the computation time is 190 times faster than that of the previous algorithm, demonstrating that Deep-HUG has potential as a useful technique to rapidly generate an ultrasound hologram for various applications."
딥러닝 기반의 모바일 얼굴 영상을 이용한 실시간 심박수 측정 시스템,2021,"['Remote Photoplethysmography', 'Heart Rate', 'Deep Learning', 'Mobile Application', 'Healthcare system']",,
딥러닝 기반 한국어 개체명 인식의 평가와 오류 분석 연구,2021,"['named entity recognition', 'Korean language', 'natural language processing', 'proper name', 'terminology']",,"Named entity recognition is a natural language processing task that recognizes and classifies named entities in an unstructured text. The targets of NER are not limited to typical proper names for persons, locations and organizations, but also date, time and quantity expressions and can be further expanded to names of events, animals, plants, materials and other encyclopedic entities. A real-world NER system is also expected to be tuned to process domain-specific terminologies. In this study, the researchers built and tested a BERT based Korean NER system and proposed methods for evaluation and error analysis. The study trained the system with 140K word NER corpus and evaluated with 60K test. Error types are proposed to be categorized into four classes: detection, boundary, segmentation, and labelling. Error rates are found to vary greatly from 1% to 30% between entity labels, which are grouped into the most accurate time and quantity expressions, relatively accurate proper names, and highly erroneous terminologies. We expect that the error analysis will provide insights for finding a better way of data collection and post-processing correction."
딥러닝과 최대 색차를 이용한 인간 행동 인식기,2021,"['Artificial intelligence', 'Convolution neural network', 'Color difference', 'Color space', 'Deep learning', 'Human activity recognition (HAR)', 'Sensors', 'Time series data']",,"Human activity recognition (HAR) is to detect human activities and the task might be categorized into vision and sensor based HAR. In the vision based HAR, monocular or binocular cameras capture human activities successively, and the introduced image streams are analyzed and categorized into corresponding activities. In the sensor based HAR, several sensors attached in human body, collects sensor data, and the data are analyzed and categorized into corresponding activities. Traditionally, the sensor based HAR has utilized machine learning technique such as support vector machine. In this paper, deep learning based HAR is proposed. The collected sensor data are converted into images, the proposed neural network is trained and evaluated with the measured data. In the image conversion, we propose a method to increase the performance by maximizing the color difference in the color space. The color difference is a Euclidian distance of the two colors, which can represent the image differences, resulting in performance enhancements in neural network. With this motivation, for feasible tests, a base line experiment is performed using a simple neural network, and we confirmed that the proposed method is effective and valid. In addition, we design HAR based on a neural network. From experimental results, we achieved f1-score=0.93 and minimum AUC (area under curve) = 0.98 at jogging activity."
딥러닝을 활용한 고위험 질병 관리를 예측하는 실시간 헬스케어 플렛폼 시스템,2021,"['Diabetes', 'Real-time', 'Continuous glucose monitoring(CGM)', 'MQTT', 'Deep learning', 'IoT', 'Prediction', 'Feed forward neural network']",,"In recent years, diabetic patients attach CGM (Continuous Glucose Monitoring) devices to continuously monitor the patient's blood sugar level. Attached to the patient's body in the form of a patch, it provides blood glucose levels and trends in capillaries every 5 minutes, while simultaneously providing hyperglycemia and hypoglycemia alarm functions for continuous blood glucose monitoring through CGM. Recently, research on blood sugar prediction and treatment methods by applying such continuous blood sugar data to deep learning is being actively studied. In this paper, a deep learning-based real-time, high-risk prediction healthcare platform for diabetic high-risk patients for quick action and efficient management is designed and implemented. Blood glucose data of patients is collected through the CGM(Continuous Glucose Monitoring) device and the collected data is delivered to the deep learning predictive model stored in the platform using the IoT gateway and MQTT broker. The deep learning prediction model receives the transmitted blood glucose level data and learns from FFNN(Feed Forward Neural Network) to predict the blood glucose level after PH 5, 15, 30 and 45 minutes. If the prediction results are in a high-risk state, push notification is sent to the healthcare worker's device. Also, blood glucose data is saved in a repository and healthcare workers can retrieve patient's historical blood glucose data. In the future, the neural network used in the deep learning prediction model will be replaced with RNN or LSTM, which is a neural network more suitable for time series data such as blood sugar data."
딥러닝 기반의 철강 표면의 결함 검출기,2021,"['Artificial intelligence', 'Convolutional neural network', 'Deep learning', 'Image classification', 'Metal surface defect', 'Surface defect detection (SDD)']",,"Steel surface defect should be detected and repaired in steel industry. Therefore, automatic detection of the steel surface defects plays a vital role in the steel manufacturing process. For the defect detection, machine learning based classification methods have been widely used such as HAAR feature-based cascade classifiers and support vector machines (SVM). As deep learning methods have been popular, the neural network based surface defect detection has been recently introduced. As for the methods, many researchers, in general, adopt a trained neural network, which is mainly winner in the recent ILSVRC (ImageNet Large Scale Visual Recognition Challenge). Then, the weights and last layers are modified to be used for surface defect detection (SDD), which is called transfer learning. In the previous researches, ResNet152 (winner in ILSVRC 2015) was used and the resulting performances were F1=0.975 and F1=0.912 in two different studies, respectively. However, the neural network used in their research has very wide and deep. Therefore, huge memories to save the trained weights and many multiplier–accumulators (MAC) are necessary, which means expensive hardware systems are essential to predict surface defect on the steel surface. This paper suggests a small neural network dedicated to surface defect detection. The proposed network has only three convolution layers and two fully connected layers. From the experimental results, we obtained F1=0.931 and minimum AUC (area under the curve)=0.995."
딥러닝과 PDF 객체분석을 이용한 문서형 악성코드 탐지,2021,"['PDF', 'keyword analysis', 'malware detection', 'benign', 'deep learning']",,"Document-type malware is mainly used for APT(Advanced Persistent Threats) attacks using document files, and malicious code threats targeting PDF documents have been rapidly increasing recently by phishing mail related to Covid-19. Recently, document type malware is easy to bypass existing security programs, so we propose detecting malware using static analysis and deep learning. In this paper, we construct a malicious PDF detection model into deep learning by extracting the information and frequency of keywords that exist between objects in normal, malicious PDF files. Evaluation of the classification performance metrics for the proposed method showed 98.75% accuracy for the Random Forest model and 98.33% accuracy for the Support Vector Machine model. The keywords of PDFs used as feature information in this study are insufficient to change, can extract information even when compressed or obfuscated and can respond effectively to variant malware because deep learning is used."
딥러닝 기반 실시간 얼굴 모자이크 기법을 활용한 초상권 보호 시스템,2021,"['Machine learning', 'Deep learning', 'Face mosaic', 'Portrait rights', 'Yolov3', 'Facenet', 'R-CNN']",,"Recently, the number of cases uploading videos taken by individuals on the Internet has increased. Uploading a video that includes not only yourself but also people around you can cause infringement of portrait rights and privacy issues. In general, The portrait rights of others are protected by manually blurring faces of people moving over time using a video editing program. However, this is a very cumbersome task and the existing automatic mosaic system also has limitations because it does not detect all identifiable faces properly in videos and it misses tracked faces frequently. Therefore, to prevent the problem of infringement of portrait rights, this paper proposes a portrait rights protection system using deep learning. The system uses YOLOv3, Face-Net, and SORT algorithm to protect the portrait rights by blurring faces of other people except the users registered in the system. Compared to the existing automatic mosaic system, It can detect all identifiable faces and blur faces more accurately. It can operate in real-time by skipping a certain frame and performing face verification. It is also possible to flexibly respond to various changes of the face reflected on the camera by applying the SORT object tracking algorithm. The proposed system can improve convenience for users by automating the task of manually blurring faces of people and it shows superior performance compared to the existing automatic mosaic system."
딥러닝 기술을 이용한 3차원 객체 추적 기술 리뷰,2021,['3'],,"Accurate 3D object tracking with camera images is a key enabling technology for augmented reality applications. Motivated by the impressive success of convolutional neural networks (CNNs) in computer vision tasks such as image classification, object detection, image segmentation, recent studies for 3D object tracking have focused on leveraging deep learning. In this paper, we review deep learning approaches for 3D object tracking. We describe key methods in this field and discuss potential future research directions."
딥러닝 기반 거리 영상의 Semantic Segmentation을 위한 Atrous Residual U-Net,2021,['-'],,"In this paper, we proposed an Atrous Residual U-Net (AR-UNet) to improve the segmentation accuracy of semantic segmentation method based on U-Net. The U-Net is mainly used in fields such as medical image analysis, autonomous vehicles, and remote sensing images. The conventional U-Net lacks extracted features due to the small number of convolution layers in the encoder part. The extracted features are essential for classifying object categories, and if they are insufficient, it causes a problem of lowering the segmentation accuracy. Therefore, to improve this problem, we proposed the AR-UNet using residual learning and ASPP in the encoder. Residual learning improves feature extraction ability and is effective in preventing feature loss and vanishing gradient problems caused by continuous convolutions. In addition, ASPP enables additional feature extraction without reducing the resolution of the feature map. Experiments verified the effectiveness of the AR-UNet with Cityscapes dataset. The experimental results showed that the AR-UNet showed improved segmentation results compared to the conventional U-Net. In this way, AR-UNet can contribute to the advancement of many applications where accuracy is important."
딥러닝 사물 인식 알고리즘(YOLOv3)을 이용한 미세조류 인식 연구,2021,"['Deep learning', 'Microalgae', 'Object detection', 'Water supply system', 'YOLOv3']",,"Algal bloom is an important issue in maintaining the safety of the drinking water supply system. Fast detection and classification of algae images are essential for the management of algal blooms. Conventional visual identification using a microscope is a labor-intensive and time-consuming method that often requires several hours to several days in order to obtain analysis results from field water samples. In recent decades, various deep learning algorithms have been developed and widely used in object detection studies. YOLO is a state-of-the-art deep learning algorithm. In this study the third version of the YOLO algorithm, namely, YOLOv3, was used to develop an algae image detection model. YOLOv3 is one of the most representative one-stage object detection algorithms with faster inference time, which is an important benefit of YOLO. A total of 1,114 algae images for 30 genera collected by microscope were used to develop the YOLOv3 algae image detection model. The algae images were divided into four groups with five, 10, 20, and 30 genera for training and testing the model. The mean average precision (mAP) was 81, 70, 52, and 41 for data sets with five, 10, 20, and 30 genera, respectively. The precision was higher than 0.8 for all four image groups. These results show the practical applicability of the deep learning algorithm, YOLOv3, for algae image detection."
딥러닝 기반 경매 알고리즘과 데이터 과학 플랫폼 응용,2021,"['Auction Algorithm', 'Deep Learning', 'Data Science']",,
딥러닝 기반 실시간 도시가스 누출량 예측 모니터링 시스템,2021,"['Deep learning', 'Gas Leakage Prediction', 'Monitoring System']",,"Gas leak accidents can easily lead to fires and explosions, and result in conflagration. A gas leak monitoring system, that can detect gas leaks in advance, is therefore needed. In general, gas leak detection at home depends on a gas sensor. However, the gas sensor only detects the gas leak after it passes a certain threshold, which makes it difficult to take precautionary action. In this study, a system for predicting the amount of gas leaked and monitoring the gas leakage situation through a deep learning model, based on gas data collected in real life, is proposed. To determine the risk level when a gas leakage occurs, the explosion risk level is divided into five stages. The current risk, predicted risk, and absolute leakage amount can be checked through the monitoring platform. It is hoped that this model will help in establishing a gas safety management system for implementation."
딥러닝 모델을 이용한 비전이미지 내의 대상체 분류에 관한 연구,2021,"['Deep Learning Recognition Model', 'Image Processing', 'Target-object Recognition', 'Classification', 'Real-time Recognition']","본 논문은 Deep-learning 기반의 검출모델을 이용하여 연속적으로 입력되는 비디오 이미지 내의 해당 대상체를 의미별로 분류해야하는 문제에 대한 구현방법에 관한 논문이다. 기존의 대상체 검출모델은 Deep-learning 기반의 검출모델로서 유사한 대상체 분류를 위해서는 방대한 DATA의 수집과 기계학습과정을 통해서 가능했다. 대상체 검출모델의 구조개선을 통한 유사물체의 인식 및 분류를 위하여 기존의 검출모델을 이용한 분류 문제를 분석하고 처리구조를 변경하여 개선된 비전처리 모듈개발을 통해 이를 기존 인식모델에 접목함으로써 대상체에 대한 인식모델을 구현하였으며, 대상체의 분류를 위하여 검출모델의 구조변경을 통해 고유성과 유사성을 정의하고 이를 검출모델에 적용하였다. 실제 축구경기 영상을 이용하여 대상체의 특징점을 분류의 기준으로 설정하여 실시간으로 분류문제를 해결하여 인식모델의 활용성 검증을 통해 산업에서의 활용도를 확인하였다. 기존의 검출모델과 새롭게 구성한 인식모델을 활용하여 실시간 이미지를 색상과 강도의 구분이 용이한 HSV의 칼라공간으로 변환하는 비전기술을 이용하여 기존모델과 비교 검증하였고, 조도 및 노이즈 환경에서도 높은 검출률을 확보할 수 있는 실시간 환경의 인식모델 최적화를 위한 선행연구를 수행하였다.","The target-object classification method was implemented using a deep-learning-based detection model in real-time images. The object detection model was a deep-learning-based detection model that allowed extensive data collection and machine learning processes to classify similar target-objects. The recognition model was implemented by changing the processing structure of the detection model and combining developed the vision-processing module. To classify the target-objects, the identity and similarity were defined and applied to the detection model. The use of the recognition model in industry was also considered by verifying the effectiveness of the recognition model using the real-time images of an actual soccer game. The detection model and the newly constructed recognition model were compared and verified using real-time images. Furthermore, research was conducted to optimize the recognition model in a real-time environment."
딥러닝 기반 이미지 아웃페인팅 기술의 현황 및 최신 동향,2021,"['image completion', 'image restoration', 'image outpainting', 'extrapolation']",,"Image outpainting is a very interesting problem in that it can continuously fill the outside of a given image by considering the context of the image. There are two main challenges in this work. The first is to maintain the spatial consistency of the content of the generated area and the original input. The second is to generate high quality large image with a small amount of adjacent information. Existing image outpainting methods have difficulties such as generating inconsistent, blurry, and repetitive pixels. However, thanks to the recent development of deep learning technology, deep learning-based algorithms that show high performance compared to existing traditional techniques have been introduced. Deep learning-based image outpainting has been actively researched with various networks proposed until now. In this paper, we would like to introduce the latest technology and trends in the field of outpainting. This study compared recent techniques by analyzing representative networks among deep learning-based outpainting algorithms and showed experimental results through various data sets and comparison methods."
딥러닝 기반 신호등 인식 시스템에 대한 특수 신호등의 영향 평가,2021,"['Traffic light recognition', 'Deep learning', 'Object detection', 'Image classification', 'Autonomous driving']",,
딥러닝 기반 분류 모델의 준 지도 학습 기법 분석,2021,"['convolutional neural network', 'image classification', 'semi-supervised learning']",,"In this paper, we analysis the semi-supervised learning (SSL), which is adopted in order to train a deep learning-based classification model using the small number of labeled data. The conventional SSL techniques can be categorized into consistency regularization, entropy-based, and pseudo labeling. First, we describe the algorithm of each SSL technique. In the experimental results, we evaluate the classification accuracy of each SSL technique varying the number of labeled data. Finally, based on the experimental results, we describe the limitations of SSL technique, and suggest the research direction to improve the classification performance of SSL."
딥러닝과 확률모델을 이용한 실시간 토마토 개체 추적 알고리즘,2021,"['Tomato Instance Tracking Algorithm', 'Object Detection', 'Kalman Filter', 'Probability Robot', 'Automatic Harvesting Robot', 'Smart Farm']",,"Recently, a smart farm technology is drawing attention as an alternative to the decline of farm labor population problems due to the aging society. Especially, there is an increasing demand for automatic harvesting system that can be commercialized in the market. Pre-harvest crop detection is the most important issue for the harvesting robot system in a real-world environment. In this paper, we proposed a real-time tomato instance tracking algorithm by using deep learning and probability models. In general, It is hard to keep track of the same tomato instance between successive frames, because the tomato growing environment is disturbed by the change of lighting condition and a background clutter without a stochastic approach. Therefore, this work suggests that individual tomato object detection for each frame is conducted by YOLOv3 model, and the continuous instance tracking between frames is performed by Kalman filter and probability model. We have verified the performance of the proposed method, an experiment was shown a good result in real-world test data."
딥러닝 기반 Local Climate Zone 분류체계를 이용한 지표면온도와 도시열섬 분석: 수원시와 대구광역시를 대상으로,2021,"['Local Climate Zone', 'Deep Learning', 'Convolutional Neural Network', 'Urban Heat Island', 'Urban Climate']",,"Urbanization increases the amount of impervious surface and artificial heat emission, resulting in urban heat island (UHI) effect. Local climate zones (LCZ) are a classification scheme for urban areas considering urban land cover characteristics and the geometry and structure of buildings, which can be used for analyzing urban heat island effect in detail. This study aimed to examine the UHI effect by urban structure in Suwon and Daegu using the LCZ scheme. First, the LCZ maps were generated using Landsat 8 images and convolutional neural network (CNN) deep learning over the two cities. Then, Surface UHI (SUHI), which indicates the land surface temperature (LST) difference between urban and rural areas, was analyzed by LCZ class. The results showed that the overall accuracies of the CNN models for LCZ classification were relatively high 87.9% and 81.7% for Suwon and Daegu, respectively. In general, Daegu had higher LST for all LCZ classes than Suwon. For both cities, LST tended to increase with increasing building density with relatively low building height. For both cities, the intensity of SUHI was very high in summer regardless of LCZ classes and was also relatively high except for a few classes in spring and fall. In winter the SUHI intensity was low, resulting in negative values for many LCZ classes. This implies that UHI is very strong in summer, and some urban areas often are colder than rural areas in winter. The research findings demonstrated the applicability of the LCZ data for SUHI analysis and can provide a basis for establishing timely strategies to respond urban on-going climate change over urban areas."
딥러닝 알고리즘 기반의 초미세먼지(PM2.5) 예측 성능 비교 분석,2021,"['딥런닝', '초미세먼지(PM2.5)', 'CNN', 'LSTM', 'GAN', '시계열데이터', 'Deep Learning', 'Fine particulate Matter(PM2.5)', 'Convolutional Neural Network', 'Long Short-Term Memory', 'Generative Adversarial Networks', 'Time Series Data']",,
딥러닝을 이용한 방사선학적 골 손실과 치주염 단계 분류의 자동적 진단 방법,2021,"['Deep learning', 'Computer-aided diagnosis(CAD)', 'Periodontitis', 'Radiographic bone loss', 'Dental panoramic radiograph', 'Multi-device study']",,"In this study, a deep learning hybrid framework was developed to automatically stage periodontitis in dental panoramic radiographs. The framework was proposed to automatically quantify the periodontal bone loss and classify periodontitis for each individual tooth into four stages according to the criteria that was proposed at the 2017 World Workshop. Radiographic bone level (or CEJ level) was detected using deep learning with a simple structure of the entire jaw in panoramic radiographs. Next, the percent ratio analysis of the radiographic bone loss combined the tooth long-axis with periodontal bone and CEJ levels. The percentage ratios can be used to automatically classify periodontal bone loss. Additionally, the number of missing teeth was quantified by detecting the position of the missing teeth in the panoramic radiographs. A multi-device study was also performed to verify the generality of the developed method. The mean absolute difference (MAD) between periodontitis stages by the automatic method and by the radiologists was 0.31 overall for all the teeth in the whole jaw. The MADs for the images from the multiple devices were 0.25, 0.34, and 0.35 for devices 1, 2, and 3, respectively. The developed method had a high accuracy, reliability, and generality when automatically diagnosing periodontal bone loss and the staging of periodontitis by the multi-device study."
딥러닝 기반 실시간 교통사고 유형 및 과실 정보 제공 서비스,2021,"['Artificial Intelligence', 'Deep Learning', 'Traffic accident']",,"Determining the percentage of negligence between the parties in the event of road traffic accidents is a significant problem. In order to provide users with more accurate criteria for determining the percentage of negligence, several companies are providing services. However, services currently available are limited to immediate use at the scene of an accident. Generally, the service that determines the percentage of negligence can be used after all accident handling procedures have been completed. This paper provides a real-time traffic accident type and fault rate information provision service utilizing a deep learning-based predictive model to overcome these limitations. Users can immediately identify accident types and fault information by taking pictures at the accident site and check actual precedents of the same accident type. Users will be able to use the service to more accurately and reliably determine the percentage of negligence and handle incidents."
딥러닝을 이용한 벼 도복 면적 추정,2021,"['area estimation', 'cnn', 'deep learning', 'lodging', 'machine learning', 'rice']",,"Rice lodging is an annual occurrence caused by typhoons accompanied by strong winds and strong rainfall, resulting in damage relating to pre-harvest sprouting during the ripening period. Thus, rapid estimations of the area of lodged rice are necessary to enable timely responses to damage. To this end, we obtained images related to rice lodging using a drone in Gimje, Buan, and Gunsan, which were converted to 128 × 128 pixels images. A convolutional neural network (CNN) model, a deep learning model based on these images, was used to predict rice lodging, which was classified into two types (lodging and non-lodging), and the images were divided in a 8:2 ratio into a training set and a validation set. The CNN model was layered and trained using three optimizers (Adam, Rmsprop, and SGD). The area of rice lodging was evaluated for the three fields using the obtained data, with the exception of the training set and validation set. The images were combined to give composites images of the entire fields using Metashape, and these images were divided into 128 × 128 pixels. Lodging in the divided images was predicted using the trained CNN model, and the extent of lodging was calculated by multiplying the ratio of the total number of field images by the number of lodging images by the area of the entire field. The results for the training and validation sets showed that accuracy increased with a progression in learning and eventually reached a level greater than 0.919. The results obtained for each of the three fields showed high accuracy with respect to all optimizers, among which, Adam showed the highest accuracy (normalized root mean square error: 2.73%). On the basis of the findings of this study, it is anticipated that the area of lodged rice can be rapidly predicted using deep learning."
딥러닝을 이용한 팔레트 위치 측정 시스템의 성능 개선에 관한 연구,2021,"['unmanned logistics systems', 'pallet positioning system', 'deep learning', 'vision-based image processing']",,"Recently, the logistics system environment is in the trend of unmanned and automated. In addition, most of the unmanned logistics systems have advanced technology that can identify the location by sensors and load or move goods without operator support or interference. And the unmanned logistics system requires a prerequisite that the pallet position is always in the correct position. However, since not all logistics processes can be automated, there are areas where this assumption does not apply. Various studies have been conducted to implement an unmanned automation system in these environments. Traditional vision-based image processing techniques have a fast processing speed, but there is a weak problem in the disturbance of images. On the other hand, the deep learning technique has a disadvantage in that the object extraction speed is slow due to the large amount of computation. Therefore, in this study, we proposed a method that can measure the exact position of the pallet by verifying the object at high speed while being strong against disturbance by appropriately utilizing the advantages of the two methods."
딥러닝 기반 자동작곡에서 구성을 갖춘 곡 생성방법,2021,"['자동작곡', '동적 데이터와 정적 데이터 결합', '곡 구성', 'Automatic composition', 'Combining dynamic data and static data', 'Song structure', 'METEOR', 'BLEU']",,"Although many deep learning based automatic music composition systems have been studied, it is hard to find a song generation system with the structure of songs. This paper addresses a method for generating songs with the structure of songs in deep learning-based automatic music generation by learning the structure together. We use a deep learning model that learns dynamic information which changes with the progress of the song and static information which is given according to the structure of the song together to learn the structure of the song. When a song is learned using the proposed method, it is possible to create a more natural song by using the composition information of the song when creating the song. We use METEOR and BLEU, which are used in natural language processing, to evaluate how similar the generated song is to a composers. The results showed that they were more similar to the song created by a composer when a song was generated with the proper structure of songs."
딥러닝 기반 지능형 멧돼지 퇴치기,2021,"['YOLOv4', 'deep learning', 'wild boar repellent', 'jetson nano']",,"Recently, wild animals such as wild boars have been causing severe crop damage not only in urban areas but also in rural areas. Therefore, farmers have installed wild animal repelling devices on farmland to drive out the animals with LED lights and sounds. Existing wild animal repelling devices mostly rely on PIR and Doppler sensors. So, even when wild animals do not appear, repelling action is performed. In this paper, we propose a method that utilizes deep learning-based intelligent wild boar repellent device to implement repelling operation after determining whether it is wild boar with trained YOLOv4 model via camera. Existing wild animal repellent devices perform repelling action to both human and wild boar when human and wild boar appear. Deep learning-based intelligent wild boar repellent device repels only wild boar when human and wild boar appear. By installing deep learning-based intelligent wild boar repellent device, we can prevent unnecessary repelling action and more effectively repel the wild animals."
딥러닝 기반 앙상블을 이용한 마스크 착용 상태 검출 기술 연구,2021,"['콘볼루션 신경망', '마스크 검출', '앙상블', 'Convolutional Neural Network', 'YOLO', 'Mask Detection', 'Ensemble', 'FPN']",,"Due to the COVID-19 incident, demand for a quarantine system that can prevent the spread of the virus has increased. In this paper, a mask wearing state detection technology based on a deep learning-based ensemble is proposed. A model that can detect mask wearing status was created using a deep learning algorithm based on a convolutional neural network. Afclassifying wearing a mask into mask, improper mask, and no mask, the accuracy was improved by constructing learning data for various poses. In addition, the combination of deep learning models through ensemble techniques increased accuracy, and among the methods of diversifying the size of feature maps, FPN techniques were used to increase object detection performance while reducing computation volume. In the future, this study will be used as an efficient quarantine system in indoor environments where ventilation is difficult, and in particular, it will be contributed to establish a quarantine environment so that users can safely use cultural facilities such as performance halls."
딥러닝 모델 기반 시멘틱 세그멘테이션을 이용한 벼 도복 추정,2021,"['Deep Learning', 'Rice Lodging', 'Semantic Segmentation', 'Unmanned Aviation Vehicle', 'RGB Image']","벼 도복은 매년 태풍 및 장마로 인해 벼 생산에 막대한 피해를 주는 원인이며, 조기 발견을 통해 벼 수확량 및 수발아와 관련된 피해를 예방하기 위핸 효과적인 방법이 필요하다. 본 논문에서는 무인 항공기를 이용하여 촬영된 영상에서 벼 도복을 추정하는 방법을 제안한다. 제안하는 방법은 ResNetV2 101백본 네트워크 기반 DeepLabV3+ 시멘틱 세그멘테이션 모델로, 도복(lodging), 일반 벼(non-lodging), 그리고 배경(background) 영역에 대해 추정한다. 제안한 모델의 학습 및 평가를 위해 경상도, 전라도, 충청도 일대에서 무인 항공기를 이용하여 벼 도복 관련된 816장 영상을 수집하였다. 수집한 데이터는 748개의 학습 데이터, 40개의 검증 데이터, 28개의 평가 데이터로 나눈 후, 추정 성능 향상을 위해 전이학습, Focal Loss 손실 함수 등 다양한 방법을 적용하였다. 평가 데이터 28장에 대해 성능을 평가한 결과, Focal Loss 손실 함수를 적용한 DeepLabV3+ 시멘틱 세그멘테이션 모델이 93.16%의 픽셀 정확도와 87.75%의 mIoU로 좋은 결과를 보였다. 추정된 결과를 통해 도복과 일반벼의 분포를 파악할 뿐만 아니라, 도복의 확산 경향과 피해, 형태 등을 분석하는데 사용할 수 있다고 사료된다.","Rice lodging is an annual occurrence that causes enormous damage to rice production by typhoons and rainy seasons. Therefore, it is necessary to find an effective method to prevent the damage to rice yield and pre-harvest sprouting through early detection. This paper proposes an estimation method for rice lodging based on RGB images captured by unmanned aviation vehicles. The proposed method constructs the DeepLabV3+ semantic segmentation model based on ResNetV2 101 backbone network and estimates the area of lodging, non-lodging, and background. To train and evaluate the proposed model, we captured 816 images related to rice lodging using an unmanned aerial vehicle in Gyeongsang-do, Jeolla-do, and Chungcheong-do. The collected dataset was divided into 748 training data, 40 validation data, and 28 evaluation data, which were then used in various methods such as transfer learning and focal loss function for the improved estimation performance. The evaluation of performance using 28 evaluation data shows that the DeepLab V3+ semantic segmentation model, to which the focal loss function was applied, yields the best results with 93.16% pixel accuracy and 87.75% mIoU. Furthermore, the estimation result can be used to find the distribution of lodging and non-lodging and analyze the trend of spreading lodging, damage, and shape."
딥러닝 기반 객체 탐지 알고리즘을 이용한 대장내시경 용종 탐지 시스템,2021,"['Colonoscopy', 'AutoAugment', 'CADｘ', 'Polyp Detection', 'YOLO']",,"In Korea, colon cancer is increasing due to westernized eating habits. Colonoscopy is being used to reduce deaths from colon cancer and studies of CADx(Computer-aided Diagnosis) are being developed to improve accuracy. Due to the nature of medical data, it was difficult to collect a lot of data, so data was increased 25 times using AutoAugment’s CIFAR-10 policy, and YOLOv4(You Only Look Once), a real-time object detection algorithm, was used to detect lesions. A new object detection algorithm, YOLOv4, use new eight features such as Weighted-Residual-Connections, Cross-Stage-Partial-connections, Cross mini-Batch Normalization and Self-Adversarial-Training. The performance of augmented data had a maximum mAP of 27.44 higher than the original data. The average IoU(Intersection over Union) was 11.44 higher than the original data. When the IoU value is 0.5, the F1-scores of the original data and the augmented data are 0.9 and 0.97 respectively."
딥러닝 자동 분류 모델을 위한 공황장애 소셜미디어 코퍼스 구축 및 분석,2021,[],,"This study is to create a deep learning based classification model to examine the characteristics of panic disorder and to classify the panic disorder tendency literature by the panic disorder corpus constructed for the present study. For this purpose, 5,884 documents of the panic disorder corpus collected from social media were directly annotated based on the mental disease diagnosis manual and were classified into panic disorder-prone and non-panic-disorder documents. Then, TF-IDF scores were calculated and word co-occurrence analysis was performed to analyze the lexical characteristics of the corpus. In addition, the co-occurrence between the symptom frequency measurement and the annotated symptom was calculated to analyze the characteristics of panic disorder symptoms and the relationship between symptoms. We also conducted the performance evaluation for a deep learning based classification model. Three pre-trained models, BERT multi-lingual, KoBERT, and KcBERT, were adopted for classification model, and KcBERT showed the best performance among them. This study demonstrated that it can help early diagnosis and treatment of people suffering from related symptoms by examining the characteristics of panic disorder and expand the field of mental illness research to social media."
관절점 딥러닝을 이용한 쓰레기 무단 투기 적발 시스템,2021,"['Articular Point', 'Deep Learning', 'Neural Network', 'Garbage Dumping Detection', 'CCTV']",,
분산 딥러닝에서 통신 오버헤드를 줄이기 위해 레이어를 오버래핑하는 하이브리드 올-리듀스 기법,2021,"['Distributed Deep Learning', 'Synchronization', 'Layer Overlapping', 'Allreduce', '분산딥러닝', '동기화', '레이어 오버래핑', '올리듀스']",,"Since the size of training dataset become large and the model is getting deeper to achieve high accuracy in deep learning, the deep neural network training requires a lot of computation and it takes too much time with a single node. Therefore, distributed deep learning is proposed to reduce the training time by distributing computation across multiple nodes. In this study, we propose hybrid allreduce strategy that considers the characteristics of each layer and communication and computational overlapping technique for synchronization of distributed deep learning. Since the convolution layer has fewer parameters than the fully-connected layer as well as it is located at the upper, only short overlapping time is allowed. Thus, butterfly allreduce is used to synchronize the convolution layer. On the other hand, fully-connecter layer is synchronized using ring all-reduce. The empirical experiment results on PyTorch with our proposed scheme shows that the proposed method reduced the training time by up to 33% compared to the baseline PyTorch."
음성인식과 딥러닝 기반 객체 인식 기술이 접목된 모바일 매니퓰레이터 통합 시스템,2021,"['Mobile Manipulator', 'Service Robot', 'Speech Recognition', 'Object Detection']",,"Most of the initial forms of cooperative robots were intended to repeat simple tasks in a given space. So, they showed no significant difference from industrial robots. However, research for improving worker’s productivity and supplementing human’s limited working hours is expanding. Also, there have been active attempts to use it as a service robot by applying AI technology. In line with these social changes, we produced a mobile manipulator that can improve the worker’s efficiency and completely replace one person. First, we combined cooperative robot with mobile robot. Second, we applied speech recognition technology and deep learning based object detection. Finally, we integrated all the systems by ROS (robot operating system). This system can communicate with workers by voice and drive autonomously and perform the Pick & Place task."
병렬 딥러닝 기법에 관한 연구 동향 분석,2021,"['Deep Learning', 'Parallel Deep Learning', 'Federated Learning', 'Data Parallelism', 'Model Parallelism', 'Hybrid Parallelism', 'Pipeline Parallelism']",,
경량 딥러닝 가속기를 위한 희소 행렬 압축 기법 및 하드웨어 설계,2021,"['Accelerator', 'Bitmap', 'Compression', 'Decompression', 'Sparse Matrix']",,"Deep learning models such as convolutional neural networks and recurrent neual networks process a huge amounts of data, so they require a lot of storage and consume a lot of time and power due to memory access. Recently, research is being conducted to reduce memory usage and access by compressing data using the feature that many of deep learning data are highly sparse and localized. In this paper, we propose a compression-decompression method of storing only the non-zero data and the location information of the non-zero data excluding zero data. In order to make the location information of non-zero data, the matrix data is divided into sections uniformly. And whether there is non-zero data in the corresponding section is indicated. In this case, section division is not executed only once, but repeatedly executed, and location information is stored in each step. Therefore, it can be properly compressed according to the ratio and distribution of zero data. In addition, we propose a hardware structure that enables compression and decompression without complex operations. It was designed and verified with Verilog, and it was confirmed that it can be used in hardware deep learning accelerators."
VGG-16 딥러닝 알고리즘을 활용한 우식치아와 건전치아 분류,2021,"['CNN', 'Convolutional neural network', 'Deep learning', 'Dental caries classification', 'VGG-16']",,"Objectives: Diagnosis of dental caries is based on the dentist’s observation and subjective judgment; therefore, a reliable and objective approach for diagnosing caries is required. Intraoral camera images combined with deep learning technology can be a useful tool to diagnose caries. This study aimed to evaluate the accuracy of the VGG-16 convolutional neural network (CNN) model in detecting dental caries in intraoral camera images.Methods: Images were obtained from the Internet and websites using keywords linked to teeth and dental caries. The 670 images that were obtained were categorized by an investigator as either sound (404 sound teeth) or dental caries (266 dental caries), and used in this study. The training and test datasets were divided in the ratio of 7:3 and a four-fold cross validation was performed. The Tensorflow-based Python package Keras was used to train and validate the CNN model. Accuracy, Kappa value, sensitivity, specificity, positive predictive value, negative predictive value, ROC (receiver operating characteristic) curve and AUC (area under curve) values were calculated for the test datasets.Results: The accuracy of the VGG-16 deep learning model for the four datasets, through random sampling, was between 0.77 and 0.81, with 0.81 being the highest. The Kappa value was 0.51- 0.60, indicating moderate agreement. The resulting positive predictive values were 0.77-0.82 and negative predictive values were 0.80-0.85. Sensitivity, specificity, and AUC values were 0.66-0.74, 0.81-0.88, and 0.88-0.91, respectively.Conclusions: The VGG-16 CNN model showed good discriminatory performance in detecting dental caries in intraoral camera images. The deep learning model can be beneficial in monitoring dental caries in the population."
AI 딥러닝을 이용한 싸움(다툼) 행동 인식 방법,2021,"['Fight recognition', 'AI deep-learning', 'intelligent CCTV', 'feature extraction', 'multi-instance learning']",,"In this study, we developed an AI deep learning-based fighting behavior recognition method for a video surveillance system and proved its effectiveness through various experiments. The proposed method consists of a two-step fighting behavior recognition framework. First, continuous video frames of the target surveillance video are transmitted to the Inflated 3D ConvNet (I3D) network, which shows a good behavior-recognition performance, to extract the spatiotemporal features. These extracted 3D features are then used as the inputs in the next step, where a fight situation is detected using a classification model consisting of a fully connected layer. To use the proposed aggressive behavior detection framework effectively, first, it is necessary to train the fight detection model. However, it is not possible to collect sufficient fighting videos in various outdoor environments. To overcome this limitation, we generated a large amount of learning data through data augmentation. Therefore, instead of directly learning from the training videos transmitted to the I3D network, the classifier trains itself to recognize various fighting actions using the Kinetics video dataset. That is, the action features are extracted from the transmitted consecutive frames using the pretrained I3D network and subsequently used to train the fully connected layer classification model. In addition, we proposed a learning method that includes recognizing ambiguous conflict boundaries using multiple instance learning to mitigate the ambiguous starting and ending of the contention videos. The effectiveness of the proposed method was verified through several experiments by drawing comparisons between the present results and those of the previously reported studies."
무인이동체와 딥러닝 기반 이미지 분석 기술을 활용한 철도교량 자동 손상 분석 방법 연구,2021,[],,"Purpose: In this study, various methods of deep learning-based automatic damage analysis technology were reviewed based on images taken through Unmanned Aerial Vehicle to more efficiently and reliably inspect the exterior inspection and inspection of railway bridges using Unmanned Aerial Vehicle. Method: A deep learning analysis model was created by defining damage items based on the acquired images and extracting deep learning data. In addition, the model that learned the damage images for cracks, concrete and paint scaling·spalling, leakage, and Reinforcement exposure among damage of railway bridges was applied and tested with the results of automatic damage analysis. Result: As a result of the analysis, a method with an average detection recall of 95% or more was confirmed. This analysis technology enables more objective and accurate damage detection compared to the existing visual inspection results. Conclusion: through the developed technology in this study, it is expected that it will be possible to analysis more accurate results, shorter time and reduce costs by using the automatic damage analysis technology using Unmanned Aerial Vehicle in railway maintenance."
경량화된 딥러닝 구조를 이용한 실시간 초고해상도 영상 생성 기술,2021,"['hardware accelerator', 'super-resolution', 'FPGA', 'deep learning']",,"Recently, deep learning technology is widely used in various computer vision applications, such as object recognition, classification, and image generation. In particular, the deep learning-based super-resolution has been gaining significant performance improvement. Fast super-resolution convolutional neural network (FSRCNN) is a well-known model as a deep learning-based super-resolution algorithm that output image is generated by a deconvolutional layer. In this paper, we propose an FPGA-based convolutional neural networks accelerator that considers parallel computing efficiency. In addition, the proposed method proposes Optimal-FSRCNN, which is modified the structure of FSRCNN. The number of multipliers is compressed by 3.47 times compared to FSRCNN. Moreover, PSNR has similar performance to FSRCNN. We developed a real-time image processing technology that implements on FPGA."
CoS: 딥러닝을 위한 시그모이드로 구성한 강조된 부드러운 비단조성 활성 함수,2021,"['activation function', 'deep learning', 'CNN', 'neural network', 'object detection']",,"Activation functions are important components that affect the performance of neural networks. Activation functions such as Step, Sigmoid, Tanh, and ReLU have problems such that the important differentiation is not possible or the gradient is vanishing. Activation function Swish solved the problem with Characteristic of a smooth non-monotonic curves and boundary value of negative. Based on these characteristics, in this paper, we propose a Consisting of Sigmoid(CoS) function adding a smooth emphasized non-monotonic curves part and reducing negative results on negative inputs and improving the flow of information within the neural network. Through the proposed method, it was certain that accuracy is improved by 0.46%~0.77% and 0.38%~0.54% over the existing ReLU and Swish."
무인항공기 영상과 딥러닝 기반의 의미론적 분할 기법을 활용한 야적퇴비 탐지 연구,2021,"['Compost', 'UAV', 'Semantic Segmentation', 'Deep Learning']",,"Field compost is a representative non-point pollution source for livestock. If the field compost flows into the water system due to rainfall, nutrients such as phosphorus and nitrogen contained in the field compost can adversely affect the water quality of the river. In this paper, we propose a method for detecting field compost using unmanned aerial vehicle images and deep learning-based semantic segmentation. Based on 39 ortho images acquired in the study area, about 30,000 data were obtained through data augmentation. Then, the accuracy was evaluated by applying the semantic segmentation algorithm developed based on U-net and the filtering technique of Open CV. As a result of the accuracy evaluation, the pixel accuracy was 99.97%, the precision was 83.80%, the recall rate was 60.95%, and the F1-Score was 70.57%. The low recall compared to precision is due to the underestimation of compost pixels when there is a small proportion of compost pixels at the edges of the image. After, It seems that accuracy can be improved by combining additional data sets with additional bands other than the RGB band."
LSTM 기반 딥러닝 알고리즘을 적용한 상수도시스템 누수인지 모델 개발,2021,[],,"Water Distribution Networks, one of the social infrastructures buried underground, has the function of transporting and supplying purified water to customers. In recent years, as measurement capability is improved, a number of studies related to leak recognition and detection by applying a deep learning technique based on flow rate data have been conducted. In this study, a cognitive model for leak occurrence was developed using an LSTM-based deep learning algorithm that has not been applied to the waterworks field until now. The model was verified based on the assumed data, and it was found that all cases of leaks of 2% or more can be recognized. In the future, based on the proposed model, it is believed that more precise results can be derived in the prediction of flow data."
U-Net 기반 딥러닝 모델을 이용한 다중시기 계절학적 토지피복 분류 정확도 분석 - 서울지역을 중심으로 -,2021,"['Classification', 'Deep Learning', 'Multi Series', 'Vegetation Phenology']",,"The land cover map is a very important data that is used as a basis for decision-making for land policy and environmental policy. The land cover map is mapped using remote sensing data, and the classification results may vary depending on the acquisition time of the data used even for the same area. In this study, to overcome the classification accuracy limit of single-period data, multi-series satellite images were used to learn the difference in the spectral reflectance characteristics of the land surface according to seasons on a U-Net model, one of the deep learning algorithms, to improve classification accuracy. In addition, the degree of improvement in classification accuracy is compared by comparing the accuracy of single-period data. Seoul, which consists of various land covers including 30% of green space and the Han River within the area, was set as the research target and quarterly Sentinel-2 satellite images for 2020 were aquired. The U-Net model was trained using the sub-class land cover map mapped by the Korean Ministry of Environment. As a result of learning and classifying the model into singleperiod, double-series, triple-series, and quadruple-series through the learned U-Net model, it showed an accuracy of 81%, 82% and 79%, which exceeds the standard for securing land cover classification accuracy of 75%, except for a single-period. Through this, it was confirmed that classification accuracy can be improved through multi-series classification."
텍스트 마이닝과 딥러닝을 활용한 암호화폐 가격 예측 : 한국과 미국시장 비교,2021,"['분리 학습', '빈도 기반 텍스트 분석', '순환 신경망', '시계열 분석', '암호화폐', 'Cryptocurrency', 'Frequency based Text Analysis', 'Recurrent Neural Networks', 'Separate Learning', 'Time series analysis']","본 연구에서는 한국과 미국의 대표적인 거래소인 빗썸과 코인베이스의 비트코인 가격을 ARIMA와 순환 신경망(Recurrent Neural Network)을 이용해 예측하고, 이후 각 국가의 뉴스 기사를 이용해 분리 학습에 기반한 separated RNN 모형을 제안한다. separated RNN 모형은 학습 데이터를 가격의 추세 변화 점을 기준으로 분리해 학습시킨 후, 추세 변화점 별 뉴스 데이터를 활용해 용어 기반 사전을 구축한다. 이후 용어 기반 사전과 평가 데이터 기간의 뉴스 데이터를 이용해 예측할 데이터의 가격 추세 변화 점을 찾아낸 후, 매칭되는 모형을 적용해 예측 결과를 산출한다. 2017년 5월 22일부터 2020년 9월 16일까지의 가격 데이터를 사용해 분석한 결과, 제안된 separated RNN을 이용해 예측한 결과가 한국과 미국의 비트코인 가격 예측 모두에서 순환 신경망(RNN)을 이용해 예측한 결과보다 높은 예측 성과를 보였다. 본 연구는 시계열 예측 기법의 한계를 뉴스 데이터를 이용한 추세 변화 점 탐색을 통해 극복할 수 있고, 성과 향상을 위한 추후 다양한 시계열 예측 기법 및 추세 변화 점 탐색을 위한 다양한 텍스트 마이닝 기법을 적용해볼 필요가 있음을 시사한다.","In this study, we predicted the bitcoin prices of Bithum and Coinbase, a leading exchange in Korea and USA, using ARIMA and Recurrent Neural Networks(RNNs). And we used news articles from each country to suggest a separated RNN model. The suggested model identifies the datasets based on the changing trend of prices in the training data, and then applies time series prediction technique(RNNs) to create multiple models. Then we used daily news data to create a term-based dictionary for each trend change point. We explored trend change points in the test data using the daily news keyword data of testset and term-based dictionary, and apply a matching model to produce prediction results. With this approach we obtained higher accuracy than the model which predicted price by applying just time series prediction technique. This study presents that the limitations of the time series prediction techniques could be overcome by exploring trend change points using news data and various time series prediction techniques with text mining techniques could be applied to improve the performance of the model in the further research."
합성곱 신경망기반 딥러닝의 용접연구 적용 Part I: 모델과 활용사례,2021,[],,
드론을 이용한 딥러닝 기반 식물 이상 탐지 시스템,2021,"['Deep Learning', 'Machine Learning', 'Object Detection', 'Drone', 'Plant Anomaly']",,"As the world's population grows, the food industry becomes increasingly important. Among them, agriculture is an industry that produces stocks of people all over the world, which is very important food industry. Despite the growing importance of agriculture, however, a large number of crops are lost every year due to pests and malnutrition. So, we propose a plant anomaly detection system for managing crops incorporating deep learning and drones with various possibilities. In this paper, we develop a system that analyzes images taken by drones and GPS of the drone's movement path and visually displays them on a map. Our system detects plant anomalies with 97% accuracy. The system is expected to enable efficient crop management at low cost."
CNN 기반 딥러닝을 이용한 인공지지체의 외형 변형 불량 검출 모델에 관한 연구,2021,"['3D Printing Scaffold', 'CNN', 'Deep Learning', 'Defect Detection Model', 'Scaffold Warpage']",,"Warpage defect detecting of scaffold is very important in biosensor production. Because warpaged scaffold cause problem in cell culture. Currently, there is no detection equipment to warpaged scaffold. In this paper, we produced detection model for shape warpage detection using deep learning based CNN. We confirmed the shape of the scaffold that is widely used in cell culture. We produced scaffold specimens, which are widely used in biosensor fabrications. Then, the scaffold specimens were photographed to collect image data necessary for model manufacturing. We produced the detecting model of scaffold warpage defect using Densenet among CNN models. We evaluated the accuracy of the defect detection model with mAP, which evaluates the detection accuracy of deep learning. As a result of model evaluating, it was confirmed that the defect detection accuracy of the scaffold was more than 95%."
합성곱 신경망기반 딥러닝의 용접연구 적용 Part II: 모델의 평가와 시각화,2021,[],,
Z세대 학습자의 딥러닝 메카니즘 연구,2021,"['Deep learning', 'Surface learning', 'Shallow learning', 'Generation Z']",,"The purpose of this study was to analyze of deep learning mechanism of Gen Z learners. Based on results from literature review, this study clarifies a theoretical ground for ‘deep learning’. Initial items to measure this concept were verified by content analysis and then finalized. After a pilot test done with 678 college students, gathered data were analyzed by item selection and exploratory factor analysis to verify their validity. Next, the main test implemented with 1,541 college students was analyzed with confirmatory factor analysis using the method for rotation based on principle component analysis and varimax for validating the final items to measure ‘deep learning mechanism’. As a result, the ‘deep learning mechanism’ consists of 30 items to measure the following four factors: abstraction of meaning, understanding reality in a different way, acquisition of facts for subsequent use, memorizing and storing. Criterion-related validity were performed at last to check this sub-factor’s theoretical construct. In conclusion, this study concluded that the constructs for deep learning could be generalized and applicable to other samples."
오토인코더를 이용한 딥러닝 기반 추천시스템 모형의 비교 연구,2021,[],,"Recommender systems use data from customers to suggest personalized products. The recommender systems can be categorized into three cases; collaborative filtering, contents-based filtering, and hybrid recommender system that combines the first two filtering methods. In this work, we introduce and compare deep learning-based recommender system using autoencoder. Autoencoder is an unsupervised deep learning that can effective solve the problem of sparsity in the data matrix. Five versions of autoencoder-based deep learning models are compared via three real data sets. The first three methods are collaborative filtering and the others are hybrid methods. The data sets are composed of customers' ratings having integer values from one to five. The three data sets are sparse data matrix with many zeroes due to non-responses."
이질적 이미지의 딥러닝 분석을 위한 적대적 학습기반 이미지 보정 방법론,2021,"['Adversarial Learning', 'Color Constancy', 'Heterogeneous Images', 'Illumination Estimation', 'Image Correction', '적대적 학습', '색 항상성', '이질적 이미지', '조명 추정', '이미지 보정']",,"The advent of the big data era has enabled the rapid development of deep learning that learns rules by itself from data. In particular, the performance of CNN algorithms has reached the level of self-adjusting the source data itself. However, the existing image processing method only deals with the image data itself, and does not sufficiently consider the heterogeneous environment in which the image is generated. Images generated in a heterogeneous environment may have the same information, but their features may be expressed differently depending on the photographing environment. This means that not only the different environmental information of each image but also the same information are represented by different features, which may degrade the performance of the image analysis model. Therefore, in this paper, we propose a method to improve the performance of the image color constancy model based on Adversarial Learning that uses image data generated in a heterogeneous environment simultaneously. Specifically, the proposed methodology operates with the interaction of the ‘Domain Discriminator’ that predicts the environment in which the image was taken and the ‘Illumination Estimator’ that predicts the lighting value. As a result of conducting an experiment on 7,022 images taken in heterogeneous environments to evaluate the performance of the proposed methodology, the proposed methodology showed superior performance in terms of Angular Error compared to the existing methods."
인공지지체 불량 검출을 위한 딥러닝 모델 성능 비교에 관한 연구,2021,"['Algorithm Evaluate', 'Classification Performance Compare', 'CNN', 'Defect Detection Model', 'Scaffold Defect']",,"When we inspect scaffold defect using sight, inspecting performance is decrease and inspecting time is increase. We need for automatically scaffold defect detection method to increase detection accuracy and reduce detection times. In this paper. We produced scaffold defect classification models using densenet, alexnet, vggnet algorithms based on CNN. We photographed scaffold using multi dimension camera. We learned scaffold defect classification model using photographed scaffold images. We evaluated the scaffold defect classification accuracy of each models. As result of evaluation, the defect classification performance using densenet algorithm was at 99.1%. The defect classification performance using VGGnet algorithm was at 98.3%. The defect classification performance using Alexnet algorithm was at 96.8%. We were able to quantitatively compare defect classification performance of three type algorithms based on CNN."
음향 데이터를 활용한 딥러닝 기반 긴급차량 우선 신호 시스템,2021,"['Deep learning', 'traffic control system', 'sound-based learning', 'emergency vehicle', 'intelligent traffic system']",,
감시 카메라를 이용한 딥러닝 기반의 화재 경보 시스템,2021,"['AUC', 'Convolution neural network', 'Cross validation', 'Deep learning', 'Fire detect', 'ROC curve', 'Surveillance camera']","센서 기반의 기존의 화재 검출기는 먼지나 습도에 의하여 오작동을 하여 유지 관리에 많은 비용이 들며, 경험적 파라미터에 크게 의존하기 때문에 조직적인 설계가 이루어질 수 없다. 또한, 프레임 차분을 통한 화재 검출 방식은 카메라의 통신 상태가 좋지 못한 곳에서는 그 성능이 떨어질 수밖에 없다. 이 논문에서는 CNN기반의 새로운 화재 감지 시스템을 보인다. 작은 화재까지도 검출하기 위하여 최소의 수용장 영역 (receptive filed)을 선택하였다. 또한, 매 프레임에서 화재를 검출하는 방식을 취하기 때문에 통신 환경 상태와 무관한 일정한 성능을 보인다. 정확한 검증을 위하여 교차 검증을 하여, 96.2%의 f1—score, 0.98의 최소 AUC를 얻었다.",
스마트폰 촬영 영상을 이용한 딥러닝 기반 위조 지폐 판별,2021,"['counterfeit bills identification', 'deep learning', 'convolutional neural network', 'smartphone', 'majority voting']",,"Counterfeit bills identification studies use expensive equipments or high-quality scanners. However, the image quality of the current smartphone camera is excellent enough to acquire images with sufficient resolution. This paper proposes a counterfeit bill identification method based on deep learning using smartphone camera shooting images. A convolutional neural network model composed of 3 convolutional layers and 2 fully-connected layers is designed and optimized. A training data collection and a patch unit processing technique to train high-resolution images in limited memory are applied. In addition, an identification method in image units using majority voting of the patch unit identification results is adapted. Through experiments using counterfeit bills forged by 4 printers, the proposed method shows an accuracy of 95.85% in patch units and 100% in images units. Results support that the proposed method can identify counterfeit bills only with smartphone images without the use of UV or optical equipments."
Semantic Segmentation 기반 딥러닝을 활용한 건축 Building Information Modeling 부재 분류성능 개선 방안,2021,[],,"In order to maximize the use of BIM, all data related to individual elements in the model must be correctly assigned, and it is essential to check whether it corresponds to the IFC entity classification. However, as the BIM modeling process is performed by a large number of participants, it is difficult to achieve complete integrity. To solve this problem, studies on semantic integrity verification are being conducted to examine whether elements are correctly classified or IFC mapped in the BIM model by applying an artificial intelligence algorithm to the 2D image of each element. Existing studies had a limitation in that they could not correctly classify some elements even though the geometrical differences in the images were clear. This was found to be due to the fact that the geometrical characteristics were not properly reflected in the learning process because the range of the region to be learned in the image was not clearly defined. In this study, the CRF-RNN-based semantic segmentation was applied to increase the clarity of element region within each image, and then applied to the MVCNN algorithm to improve the classification performance. As a result of applying semantic segmentation in the MVCNN learning process to 889 data composed of a total of 8 BIM element types, the classification accuracy was found to be 0.92, which is improved by 0.06 compared to the conventional MVCNN."
미세먼지 농도 예측을 위한 딥러닝 알고리즘별 성능 비교,2021,"['Neural network', 'Deep neural network', 'Recurrent neural network', 'Long short-term memory', 'Particulate matter']","미세먼지에 대한 심각성이 사회적으로 대두됨에 따라 대중들은 미세먼지 예보에 대한 정보의 높은 신뢰성을 요구하고 있다. 이에 따라 다양한 신경망 알고리즘을 이용하여 미세먼지 예측을 위한 연구가 활발히 진행되고 있다. 본 논문에서는 미세먼지 예측을 위해 다양한 알고리즘으로 연구되고 있는 신경망 알고리즘들 중 대표적인 알고리즘들의 예측 성능 비교를 진행하였다. 신경망 알고리즘 중 DNN(deep neural network), RNN(recurrent neural network), LSTM(long short-term memory)을 이용하였으며, 하이퍼 파라미터 탐색을 이용하여 최적의 예측 모델을 설계하였다. 각 모델의 예측 성능 비교 분석 결과, 실제 값과 예측 값의 변화 추이는 전반적으로 좋은 성능을 보였다. RMSE와 정확도를 기준으로 한 분석에서는 DNN 예측 모델이 다른 예측 모델에 비해 예측 오차에 대한 안정성을 갖는 것을 확인하였다.","The growing concerns on the emission of particulate matter has prompted a demand for highly reliable particulate matter forecasting. Currently, several studies on particulate matter prediction use various deep learning algorithms. In this study, we compared the predictive performances of typical neural networks used for particulate matter prediction. We used deep neural network(DNN), recurrent neural network, and long short-term memory algorithms to design an optimal predictive model on the basis of a hyperparameter search. The results of a comparative analysis of the predictive performances of the models indicate that the variation trend of the actual and predicted values generally showed a good performance. In the analysis based on the root mean square error and accuracy, the DNN-based prediction model showed a higher reliability for prediction errors compared with the other prediction models."
재활 의료 보조를 위한 딥러닝 기반 무인 의료 시스템의 설계 및 성능평가,2021,[],,"With the recent COVID-19 situation, countries are seriously feeling the need for medical personnel and their technologies. PDepending on the aging society, the number of medical staff is actually decreasing, and in order to solve this problem, research is needed to replace the part that does not require high expertise among actual medical practices performed by doctors. This paper describes and proposes actual research methods related to unmanned medical systems that use various deep learning image processing-based technologies to check the recovery status applicable to rehabilitation areas where medical staff should face patients directly. The proposed method replaces passive calculations such as a protractor or a method of drawing a line in a photograph, which is the method used for actual motion comparison. Since it is performed in real time, it helps to diagnose quickly, and it is easy for medical staff to provide necessary information because data on the degree of match of motion performance can be checked."
특허문서 자동분류를 위한 딥러닝 개별 모델 분류기와 앙상블 분류기의 성능비교,2021,"['Patent classification', 'Ensemble', 'Deep learning']",,
비디오 인코더를 통한 딥러닝 모델의 정수 가중치 압축,2021,"['Deep Learning Model Parameter Quantization', 'Weight compression', 'Lightweight model']",,"Recently, various lightweight methods for using Convolutional Neural Network(CNN) models in mobile devices have emerged. Weight quantization, which lowers bit precision of weights, is a lightweight method that enables a model to be used through integer calculation in a mobile environment where GPU acceleration is unable. Weight quantization has already been used in various models as a lightweight method to reduce computational complexity and model size with a small loss of accuracy. Considering the size of memory and computing speed as well as the storage size of the device and the limited network environment, this paper proposes a method of compressing integer weights after quantization using a video codec as a method. To verify the performance of the proposed method, experiments were conducted on VGG16, Resnet50, and Resnet18 models trained with ImageNet and Places365 datasets. As a result, loss of accuracy less than 2% and high compression efficiency were achieved in various models. In addition, as a result of comparison with similar compression methods, it was verified that the compression efficiency was more than doubled."
교량 안전점검을 위한 딥러닝 균열 검출분석 SW 탑재 드론 구현,2021,"['industrial drone', 'deep-learning', 'bridge management', 'visual-safety inspection', 'bridge brack']",,"Since cracks inevitably occur in concrete structures, those must be inspected and managed for structure safety. The existing crack inspection method for bridges depends on special safety equipment and the naked eye of professionals, but the reliability of the method is low given cost and risk. Therefore, this paper proposes and implements a bridge-crack automatic inspection method combined with a drone and image-processing technology. The drone body is designed to be able to fly at 12m/s based on wind resistance in consideration of the gusts under bridges, and a special camera gimbal is manufactured for shooting the front and top of the drone. Image processing is performed on a small mission computer mounted on the drone, and the performance of bridge crack detection based on U-Net gets an IoU value of 0.9125, and the devised method based on rule-based automatically measures the degree, length, branching point and the number of cracks to analyze the crack shape."
혼잡 환경에서 강인한 딥러닝 기반 인간 추적 프레임워크,2021,"['Detectron2', 'Human Tracking', 'Crowded Environment', 'Kalman Filter']",,"This paper presents a robust deep learning-based human tracking framework in crowded environments. For practical human tracking applications, a target must be robustly tracked even in undetected or overcrowded situations. The proposed framework consists of two parts: robust deep learning-based human detection and tracking while recognizing the aforementioned situations. In the former part, target candidates are detected using Detectron2, which is one of the powerful deep learning tools, and their weights are computed and assigned. Subsequently, a candidate with the highest weight is extracted and is utilized to track the target human using a Kalman filter. If the bounding boxes of the extracted candidate and another candidate are overlapped, it is regarded as a crowded situation. In this situation, the center information of the extracted candidate is compensated using the state estimated prior to the crowded situation. When candidates are not detected from Detectron2, it means that the target is completely occluded and the next state of the target is estimated using the Kalman prediction step only. In two experiments, people wearing the same color clothes and having a similar height roam around the given place by overlapping one another. The average error of the proposed framework was measured and compared with one of the conventional approaches. In the error result, the proposed framework showed its robustness in the crowded environments."
산불 진압을 위한 딥러닝 기반 소화탄 투하지점 자동 추천 시스템 가능성 연구,2021,"['drone', 'forest fire', 'semantic segmentation', 'UAV', 'automatic estimation of release point', 'deep learning']",,"For suppression of wildfire, unmanned aerial vehicles (UAVs) have paid attention. Individual UAV for the fire suppression is generally controlled by human; however, it is difficult to utilize it for the environment including loss of communications as well as requiring large human resources for controlling multiple UAVs. This study aims at developing an automatic estimation system of release point for overcoming the operation problems of UAV in wildfire. For the automatic detection and localization of wildfire, semantic segmentation, which is one of the deep learning techniques, is used; the recommendation algorithm of the release point is proposed using the locailization information. After conducting the machine learning, the accuracy on the proposed release point was estimated over 90%, which agrees well with the location proposal of human. It is expected that the algorithm proposed in this study can be utilized for developing fully-automatic system of fire suppression with UAV."
건물 안전 진단을 위한 딥러닝 기반의 외벽 균열 검출 방법,2021,"['Crack Detection', 'Deep Learning', 'Aritificial Intelligence']",,"The crack damage inspection of structures is generally conducted by visual inspection, and the inspector's subjective judgement cannot but be involved. Accordingly, research on automatically and objectively detecting cracks has been conducted. In this study, we introduce deep learning based wall crack detection model from crack image. The following work was performed to develop a crack detection model; 1. A variety of certified crack datasets were established, and labeling for crack detection was first performed by dividing into Loose/Tight according to the characteristics of dataset and dangerous cracks. 2. The crack detection was comparatively performed with the existing detection models, and the YOLOv5-L6 model was finally selected. 3. A high-level detection result of an average value of 97.4 mAP was derived through training for each dataset. It is expected that it can be used as a practical inspection tool by being developed that can detect cracks in real environment."
소음 신호를 이용한 딥러닝 이용 파워 드라이빙 시스템의 건전성 감시,2021,"['Convolutional Neural Network(합성곱 신경망)', 'Continuous Wavelet Transform(연속 웨이블렛 변환)', 'Power Driving System(동력 구동 시스템)']",,"The power driving system (PDS) comprises parts such as the chain, sprocket, gear, bearing, and rotating shaft. The purpose of this study is to develop a condition-monitoring device that diagnoses component defects early by using a convolutional neural network to prevent complete damage due to component defects. For this study, eight types of defects are artificially manufactured in various parts and assembled to build a PDS. A convolutional neural network is developed to classify and diagnose the eight types of defects. A feature for faults is successfully extracted, and fault classification is achieved with 90 % accuracy."
VGG-13 기반의 경량화된 딥러닝 기법을 이용한 차선 이탈 경고 시스템 구현,2021,"['Lane Detection', 'Adas', 'Image Segmentation', 'Lane Departure Warning']",,
결함검출 적용을 위한 YOLO 딥러닝 알고리즘 비교,2021,"['YOLO', 'Deep learning', 'Object detection', 'Defect detection', 'CNN']",,"Recently, metal 3D printing technology has developed and has been widely applied in fields such as mechanical parts and construction sites. However, the problem of output defects must be resolved. These defects appear as pores and microcracks in the output, which can be confirmed through microscopic analysis of the output. In addition, if the understanding of pores or cracks is unclear or many images need to be checked in a short time, an error might occur. Therefore, this study aims to develop a precision object detection algorithm using deep learning. The purpose is to automatically detect defects using deep learning-based You Only Look Once (YOLO). Through comparison using YOLO v3 and v5 algorithms, the accuracy and speed were compared to analyze which YOLO model was efficient in the defect detection process."
갯벌 생태계 모니터링을 위한 딥러닝 기반의 영상 분석 기술 연구 - 신두리 갯벌 달랑게 모니터링을 중심으로 -,2021,"['The tidal flat', 'Ecosystem monitoring', 'deep learning', 'an unmanned aerial vehicle', 'UAV']",,"In this study, a deep-learning image analysis model was established and validated for AI-based monitoring of the tidal flat ecosystem for marine protected creatures Ocypode stimpsoni and their habitat. The data in the study was constructed using an unmanned aerial vehicle, and the U-net model was applied for the deep learning model. The accuracy of deep learning model learning results was about 0.76 and about 0.8 each for the Ocypode stimpsoni and their burrow whose accuracy was higher. Analyzing the distribution of crabs and burrows by putting orthomosaic images of the entire study area to the learned deep learning model, it was confirmed that 1,943 Ocypode stimpsoni and 2,807 burrow were distributed in the study area. Through this study, the possibility of using the deep learning image analysis technology for monitoring the tidal ecosystem was confirmed. And it is expected that it can be used in the tidal ecosystem monitoring field by expanding the monitoring sites and target species in the future."
기상 테이터를 이용한 딥러닝 기반 풍력 발전량 예측에 관한 연구,2021,"['Deep-Learning', 'LSTM', 'Prediction', 'Wind Power']",,"Although the proportion of wind energy sources in the system is increasing, the variability and stochastic characteristics of wind power have a negative effect on system stability and on the rescheduling of the system’s power generation. Therefore, an accurate prediction of wind power generation is necessary for stable power distribution in the power system. High-precision wind power forecasting provides a reliable basis for dispatching of power system. Since wind power data is time series data with uncertainty, a suitable model, the LSTM algorithm of Keras, was proposed to predict a short-term wind power generation. The LSTM has memory to store past states, so it is suitable for the problem of predicting time series data. This paper proposes a forecasting procedure using an LSTM neural network to forecast wind power. First, Pearson correlation coefficient method is utilized to determine the parameters of LSTM forecasting model. Then a case study was performed using real data collected from a wind farm in Yeongheung to confirm that the LSTM model was suitable for wind power prediction."
이동형 디바이스를 이용한 딥러닝 기반의 돼지 무게 추정 알고리즘,2021,"['3D classification', 'PointNet', '3D point cloud']",,"This paper proposes a deep learning algorithm for estimating pig weight. The proposed algorithm estimates the weight of a pig using the point cloud obtained through a mobile device. The proposed model is based on the PointNet which is widely used in the point cloud data. Through the optimization of the PointNet, the proposed method not only improves the accuracy, but also reduces the computational complexity. The accuracy (82.4 %) of the proposed method was about 3 % higher than that of the conventional method (79.4 %). Also, the numbers of the trainable parameters for the PointNet and the proposed method were 3,114,771 and 150,554, respectively. That is, the proposed method used only 5 % of trainable parameters compared to the PointNet. The developed model makes it easier and faster to measure the weight of a pig than the conventional method."
CFD 해석용 형상 스케치 딥러닝을 이용한 OpenFOAM 연동,2021,"['CFD', 'Sketch Recognition', 'Deep Learning', 'Keras', 'OpenFOAM']",,"This focuses on the possibility of automatically performing CFD (computational fluid dynamics) analysis with hand-written sketches on paper(i.e. the easier way). The sketch is recognized and predicted as the target of the CFD analysis model by applying Deep Convolutional Neural Network suitable for classification of abstract sketch images. The sketch is only possible within the range of primitive geometric shapes in the field of CFD. The CFD analysis model needs to be prepared in advance in parametric format. This study shows that one-stop solution of CFD analysis is possible with the composition of the following procedures: 1) Sketch image recognition, 2) Sketch intention prediction for CFD analysis by using deep learning A.I., 3) Adaptation of reusable OpenFOAM case, 4) Interoperation with CFD application. Reusable OpenFOAM cases are coded in a parametric template format. Through this study, it was confirmed that the CFD analysis can be performed well by recognizing sketch written on paper. In this study, an elbow shape sample case at the prototype level was created and tested. As a result of the performance evaluation of the sketch recognition artificial neural network model, the accuracy of the sketch intention decision was relatively good at 87.5% (0.8750), and the loss was 37.3% (0.3729)."
토픽 모델링 기반 비대면 강의평 분석 및 딥러닝 분류 모델 개발,2021,"['19', 'LDA']",,"Due to the global pandemic caused by COVID-19 in 2020, there have been major changes in the education sites. Universities have fully introduced remote learning, which was considered as an auxiliary education, and non-face-to-face classes have become commonplace, and professors and students are making great efforts to adapt to the new educational environment. In order to improve the quality of non-face-to-face lectures amid these changes, it is necessary to study the factors affecting lecture satisfaction. Therefore, This paper presents a new methodology using big data to identify the factors affecting university lecture satisfaction changed before and after COVID-19. We use Topic Modeling method to analyze lecture reviews before and after COVID-19, and identify factors affecting lecture satisfaction. Through this, we suggest the direction for university education to move forward. In addition, we can identify the factors of satisfaction and dissatisfaction of lectures from multiangle by establishing a topic classification model with an F1-score of 0.84 based on KoBERT, a deep learning language model, and further contribute to continuous qualitative improvement of lecture satisfaction."
LPR 시스템 트리거 신호 생성을 위한 딥러닝 슬라이딩 윈도우 방식의 객체 탐지 및 추적,2021,"['Vehicle Detection', 'Vehicle Tracking', 'Deep-learning', 'LPR Trigger Signal']",,"The LPR system’s trigger sensor makes problem occasionally due to the heave weight of vehicle or the obsolescence equipment. If we replace the hardware sensor to the deep-learning based software sensor in order to generate the trigger signal, LPR system maintenance would be a lot easier. In this paper we proposed the deep-learning sliding window based object detection and tracking algorithm for the LPR system’s trigger signal generation. The gate passing vehicle’s license plate recognition results are combined into the normal tracking algorithm to catch the position of the vehicle on the trigger line. The experimental results show that the deep learning sliding window based trigger signal generating performance was 100% for the gate passing vehicles including the 5.5% trigger signal position errors due to the minimum bounding box location errors in the vehicle detection process."
차량 센서 데이터 조합을 통한 딥러닝 기반 차량 이상탐지,2021,"['Anomaly detection', 'CNN', 'LSTM', 'Vehicle', 'Deep learning']","4차산업혁명 시대에는 대량의 데이터를 학습하여 예측과 분류의 정확성을 향상시킬 수 있는 인공지능의 활용이 핵심적이다. 그러나, 기존 이상탐지를 위한 방법은 제한된 데이터를 다루는 전통적인 통계 방법에 의존하고 있어, 정확한 이상탐지가 어렵다. 그러므로, 본 연구는 인공지능 기반 이상탐지 방법을 제시하여 예측 정확도를 높이고, 새로운 데이터 패턴을 정의하는 것을 목적으로 한다. 특히, 자동차의 경우 공회전 기간의 센서 데이터가 이상 탐지에 활용될 수 있다는 관점에서 데이터를 수집하고 분석하였다. 이를 위해, 예측 모델에 입력되는 데이터의 적정 시간 길이를 결정하고, 공회전 기간 데이터와 전체 운행 데이터의 분석 결과를 비교하며, 다양한 센서 데이터 조합에 의한 최적 예측 방법을 도출하였다. 또한, 인공지능 방법으로 선택된 CNN의 예측 정확성을 검증하기 위해 LSTM 결과와 비교하였다. 분석 결과, 공회전 데이터를 이용하고, 공회전 기간보다 1.5배 많은 기간의 데이터를 이용하며 LSTM보다는 CNN을 활용하는 것이 더 좋은 예측결과를 보였다.","In the Industry 4.0 era, artificial intelligence has attracted considerable interest for learning mass data to improve the accuracy of forecasting and classification. On the other hand, the current method of detecting anomalies relies on traditional statistical methods for a limited amount of data, making it difficult to detect accurate anomalies. Therefore, this paper proposes an artificial intelligence-based anomaly detection methodology to improve the prediction accuracy and identify new data patterns. In particular, data were collected and analyzed from the point of view that sensor data collected at vehicle idle could be used to detect abnormalities. To this end, a sensor was designed to determine the appropriate time length of the data entered into the forecast model, compare the results of idling data with the overall driving data utilization, and make optimal predictions through a combination of various sensor data. In addition, the predictive accuracy of artificial intelligence techniques was presented by comparing Convolutional Neural Networks (CNN) and Long Short Term Memory (LSTM) as the predictive methodologies. According to the analysis, using idle data, using 1.5 times of the data for the idling periods, and using CNN over LSTM showed better prediction results."
불규칙 3차원 데이터를 위한 기하학정보를 이용한 딥러닝 기반 기법 분석,2021,"['3D deep learning', 'Irregular data', 'Mesh', 'Point cloud', 'Classification', 'Segmentation']",,"3D data can be categorized into two parts : Euclidean data and non-Euclidean data. In general, 3D data exists in the form of non-Euclidean data. Due to irregularities in non-Euclidean data such as mesh and point cloud, early 3D deep learning studies transformed these data into regular forms of Euclidean data to utilize them. This approach, however, cannot use memory efficiently and causes loses of essential information on objects. Thus, various approaches that can directly apply deep learning architecture to non-Euclidean 3D data have emerged. In this survey, we introduce various deep learning methods for mesh and point cloud data. After analyzing the operating principles of these methods designed for irregular data, we compare the performance of existing methods for shape classification and segmentation tasks."
드론 활용 교량 안전점검을 위한 딥러닝 균열 분석에 관한 연구,2021,"['deep-learning', 'drone', 'crack', 'visual inspection', 'image-processing', 'visual-safety']",,"Visual-safety inspection and investigation of existing bridges have problems with low objectivity and reliability because of the inspectors subjectivity. As the visual inspection technology for deteriorated infrastructure becomes important, research of inspection technology using drones has been proposed. In this study, We propose an alternative method to detect and analyze crack using drones. The drone is equipped with a special camera and gymbal in the forward and upward directions. For crack analysis, the study was conducted in two layers: extraction and analysis. Crack is segmented by learned U-NET model in real time and the Intersection-over-Union (IoU) value was 0.9125 (91%). After, through post-processing image processing of 8 steps, the crack is isolated, clustered, analyzed and visualized."
항공 LiDAR 및 RGB 정사 영상을 이용한 딥러닝 기반의 도시녹지 분류,2021,"['도시녹지', '영상 분류', '항공 LiDAR', 'RGB 정사영상', '토지피복지도', 'Urban green space', 'Image classification', 'Airborne LiDAR', 'RGB ortho imagery', 'Land cover map', 'U-Net']",,"Urban green space is an important component for enhancing urban ecosystem health. Thus, identifying the spatial structure of urban green space is required to manage a healthy urban ecosystem. The Ministry of Environment has provided the level 3 land cover map(the highest (1m) spatial resolution map) with a total of 41 classes since 2010. However, specific urban green information such as street trees was identified just as grassland or even not classified them as a vegetated area in the map. Therefore, this study classified detailed urban green information(i.e., tree, shrub, and grass), not included in the existing level 3 land cover map, using two types of high-resolution(<1m) remote sensing data(i.e., airborne LiDAR and RGB ortho imagery) in Suwon, South Korea. U-Net, one of image segmentation deep learning approaches, was adopted to classify detailed urban green space. A total of three classification models(i.e., LRGB10, LRGB5, and RGB5) were proposed depending on the target number of classes and the types of input data. The average overall accuracies for test sites were 83.40% (LRGB10), 89.44%(LRGB5), and 74.76%(RGB5). Among three models, LRGB5, which uses both airborne LiDAR and RGB ortho imagery with 5 target classes(i.e., tree, shrub, grass, building, and the others), resulted in the best performance. The area ratio of total urban green space(based on trees, shrub, and grass information) for the entire Suwon was 45.61%(LRGB10), 43.47%(LRGB5), and 44.22%(RGB5). All models were able to provide additional 13.40% of urban tree information on average when compared to the existing level 3 land cover map. Moreover, these urban green classification results are expected to be utilized in various urban green studies or decision making processes, as it provides detailed information on urban green space."
핵 활동 분석을 위한 다시기 · 다종 위성영상의 딥러닝 모델 기반 객체탐지의 활용성 평가,2021,"['Deep Learning', 'Object Detection', 'Change Detection']",,"In order to monitor nuclear activity in inaccessible areas, it is necessary to establish a methodology to analyze changes in nuclear activity-related objects using high-resolution satellite images. However, traditional object detection and change detection techniques using satellite images have difficulties in applying detection results to various fields because effects of seasons and weather at the time of image acquisition. Therefore, in this paper, an object of interest was detected in a satellite image using a deep learning model, and object changes in the satellite image were analyzed based on object detection results. An initial training of the deep learning model was performed using an open dataset for object detection, and additional training dataset for the region of interest were generated and applied to transfer learning. After detecting objects by multitemporal and multisensory satellite images, we tried to detect changes in objects in the images by using them. In the experiments, it was confirmed that the object detection results of various satellite images can be directly used for change detection for nuclear activity-related monitoring in inaccessible areas."
조선 네스팅 문제의 부재 페어링을 위한 딥러닝 기반 부재 분류 방법,2021,"['Convolutional neural network(CNN)', 'Deep learning', 'Nesting', 'No-fit polygon(NFP)', 'Pairing', 'Part Classification']",,"With the rapid development of artificial intelligence technology, deep learning-based classification techniques have had enough reliability to be applied to industrial sites. However, while the study of the object classification on data acquired with 3D scanners or cameras has made remarkable progress, research activity based on geometric data sets is still in its infancy. In particular, in order to improve the classification performance of ship parts based on deep learning in the nesting problem to increase productivity in shipbuilding, the study of the construction of part datasets and data pre-processing is necessary. In this paper, we introduce a method to apply the artificial neural network technology of deep learning to the nesting algorithm for shipbuilding. Labeled with histogram-based shape contexts for constructing a dataset for classifying ship parts using Convolutional Neural Networks (CNNs). In addition, we introduce the preprocessing method of the geometric information of the ship parts for learning and the no-fit polygon (NFP) method for classified parts to pair up. To train the classification model for the 23,201 ship parts, a data set of 842 classes was constructed through the shape matching algorithm. The trained CNN model was able to classify those parts with an accuracy of 85.13%."
물 사용량 예측을 위한 선형 모형과 딥러닝 알고리즘의 비교 분석,2021,"['Water usage', 'Nonlinear feature', 'K-means', 'Wavelet', 'Deep learning', '물 사용량', '비선형적 특성', 'K-means', 'Wavelet', 'Deep learning']","물 사용량 예측은 최적의 용수 공급 운영 방안을 수립하고 전력 소비량 절감을 위하여 꼭 필요한 과정이라고 할 수 있다. 그러나 수용가 단위의 물 사용량은 용도, 사용자의 패턴, 날씨 등의 다양한 요인으로 인해 변화하는 비선형적 특성을 지니고 있다. 따라서 본 연구에서는 비선형적인 수용가 단위의 물 사용량을 예측하기 위하여 다양한 기법들을 연계한 KWD 프레임워크를 제안하고자 하였다. 즉, 먼저 개별 수용가 마다 용도에 따른 유사한 패턴을 파악하기 위해 K-means (K) 군집분석을 수행하였고, 잡음성분을 제거함으로써 핵심적인 주기패턴을 파악하기 위해 Wavelet (W) 방법을 적용하였다. 또한 비선형적 특성을 학습시키기 위해 Deep learning (D) 알고리즘을 적용하였다. 그리고 기존의 선형 시계열 모형인 ARMA 모형과 비교하여 KWD 프레임워크의 성능을 분석하였다. 그 결과 제안된 모형의 상관성은 92%, ARMA 모형은 약 39%로 KWD 프레임워크가 2배 이상의 성능을 가지는 것으로 분석되었다. 따라서 본 연구에서 제안한 방법을 활용할 경우 정확한 물 사용량 예측이 가능해질 것이며, 상황에 따른 최적의 공급 방안을 수립할 수 있을 것이다.","It is an essential to predict water usage for establishing an optimal supply operation plan and reducing power consumption. However, the water usage by consumer has a non-linear characteristics due to various factors such as user type, usage pattern, and weather condition. Therefore, in order to predict the water consumption, we proposed the methodology linking various techniques that can consider non-linear characteristics of water use and we called it as KWD framework. Say, K-means (K) cluster analysis was performed to classify similar patterns according to usage of each individual consumer; then Wavelet (W) transform was applied to derive main periodic pattern of the usage by removing noise components; also, Deep (D) learning algorithm was used for trying to do learning of non-linear characteristics of water usage. The performance of a proposed framework or model was analyzed by comparing with the ARMA model, which is a linear time series model. As a result, the proposed model showed the correlation of 92% and ARMA model showed about 39%. Therefore, we had known that the performance of the proposed model was better than a linear time series model and KWD framework could be used for other nonlinear time series which has similar pattern with water usage. Therefore, if the KWD framework is used, it will be possible to accurately predict water usage and establish an optimal supply plan every the various event."
도시림의 경관 회복 기능 평가를 위한 딥러닝 적용 가능성 모색: 문헌 및 방법론 리뷰를 중심으로,2021,"['합성곱 계층', '이미지 분류 및 분할', '지도학습', 'Convolutional Neural Network', 'CNN', 'Image classification and segmentation', 'Supervised learning']",,"This study examines the feasibility of developing a model for evaluating urban landscapes based on deep learning as a preliminary study. The principal methodology of the study is literature analysis; to explore the possibility of applying the deep learning algorithm to landscape evaluation, we intensively reviewed researches regarding ‘urban forest landscape research’, ‘landscape evaluation scale’, and ‘feasibility of deep learning in landscape studies’. The results derived from this study are composed mainly of two contents. First, it is ‘Necessity to select images considering landscape composition and standardize evaluation indicators and scales’. The data to be evaluated for measuring the recovery effect of urban forests were found to be insufficient to be applied as a model. However, since the landscape elements and composition to be evaluated in existing studies were simply set, it will contribute to reducing the complexity of the model. When developing the model in the future, influence variables that have been proven several times in previous studies can be used as main input data. The evaluation results of existing studies that will be applied as input data to future evaluation models are composed of various scales and need to be adjusted to a level that can be compared to each other through standardization, moreover high resolution for the development and use of landscape evaluation algorithms in various fields. Second, ‘Proving of the possibility and feasibility of evaluating existing algorithms’. It is judged that the validity of the landscape evaluation model based on deep learning is high, and rather than a method of newly developing the evaluation algorithm itself, the basic data is constructed to improve the model's reliability by utilizing and partially correcting the already established landscape evaluating algorithm. This study is meaningful because it suggests directions and limitations for the future urban forest landscape evaluation model development."
제조 공정에서의 실시간 불량 탐지를 위한 딥러닝 모델 적용 연구 - 라벨 인쇄 공정에서 불량 탐지 사례 -,2021,"['Computer Vision', 'Deep learning', 'Object detection', 'Semi supervised learning', 'One class convolutional neural network']",,
EEG를 이용한 LSTM 기반의 행동 식별 딥러닝 알고리즘,2021,"['EEG Signals', 'LSTM', 'STFT', 'Deep Learning', 'PCA', 'Data Mining', 'GAN', 'Pearson Correlation']",,"Precise measurement and analysis of EEG required expensive specialized equipment and experts. In this study, a solution to this problem is proposed using a deep learning algorithm. First, the EEG signal data are learned using a 2-CH single-electrode sensor in the frontal lobe and an LSTM deep learning model. A data mining algorithm is used to select high-quality data from the measured data. In this process, the data shortage caused by data removal is supplemented by multiplying data using IOU GAN. With the Pearson correlation analysis algorithm, the frequency domain where common features between data occur is identified. From this, the data capacity is reduced and the learning speed is improved. As a result, it was confirmed that behavior identification using EEG is possible with a small number of sensors and the proposed algorithm."
원격 탐사 영상 정합을 위한 딥러닝 기반 특징점 필터링,2021,"['Computer Vision', 'Deep Learning', 'Image Registration', 'Remote Sensing Image', 'Image Segmentation']",,"In this paper, DLKF (Deep Learning Keypoint Filtering), the deep learning-based keypoint filtering method for the rapidization of the image registration method for remote sensing images is proposed. The complexity of the conventional feature-based image registration method arises during the feature matching step. To reduce this complexity, this paper proposes to filter only the keypoints detected in the artificial structure among the keypoints detected in the keypoint detector by ensuring that the feature matching is matched with the keypoints detected in the artificial structure of the image. For reducing the number of keypoints points as preserving essential keypoints, we preserve keypoints adjacent to the boundaries of the artificial structure, and use reduced images, and crop image patches overlapping to eliminate noise from the patch boundary as a result of the image segmentation method. the proposed method improves the speed and accuracy of registration. To verify the performance of DLKF, the speed and accuracy of the conventional keypoints extraction method were compared using the remote sensing image of KOMPSAT-3 satellite. Based on the SIFT-based registration method, which is commonly used in households, the SURF-based registration method, which improved the speed of the SIFT method, improved the speed by 2.6 times while reducing the number of keypoints by about 18%, but the accuracy decreased from 3.42 to 5.43. Became. However, when the proposed method, DLKF, was used, the number of keypoints was reduced by about 82%, improving the speed by about 20.5 times, while reducing the accuracy to 4.51."
뇌파기반 정신적 피로 판별을 위한 딥러닝 모델,2021,[],"개인의 정신적 피로는 인지능력 및 업무 수행능력을 감소시킬 뿐만 아니라 일상에서 발생하는 크고 작은 사고의 주요 요인이 된다. 본 논문에서는 EEG 기반의 정신적 피로 판별을 위한 CNN 모델을 제안하였다. 이를 위해 안정 상태와 작업 상태에서의 뇌파를 수집하여 제안한 CNN 모델에 적용한 후 모델 성능을 분석하였다. 실험에 참여한 피험자들은 모두 대학교에 재학 중인 오른손잡이 남학생들이며 평균 나이는 25.5세이다. 각 상태에서의 측정된 뇌파에 대해 스펙트럼분석을 수행하였으며, CNN 모델의 입력데이터로써 원시 EEG 신호, 절대파워, 상대파워를 사용하여 CNN모델의 성능을 비교 분석하였다. 그 결과, 알파대역 후두엽 위치의 상대파워가 가장 좋은 성능을 나타내었다. 모델정확도는 훈련데이터 85.6%, 검증데이터 78.5%, 시험데이터 95.7%이다. 제안한 모델은 정신적 피로 판별을 위한 자동화시스템 개발에 적용될 수 있다.","Individual mental fatigue not only reduces cognitive ability and work performance, but also becomes a major factor in large and small accidents occurring in daily life. In this paper, a CNN model for EEG-based mental fatigue discrimination was proposed. To this end, EEG in the resting state and task state were collected and applied to the proposed CNN model, and then the model performance was analyzed. All subjects who participated in the experiment were right-handed male students attending university, with and average age of 25.5 years. Spectral analysis was performed on the measured EEG in each state, and the performance of the CNN model was compared and analyzed using the raw EEG, absolute power, and relative power as input data of the CNN model. As a result, the relative power of the occipital lobe position in the alpha band showed the best performance. The model accuracy is 85.6% for training data, 78.5% for validation, and 95.7% for test data. The proposed model can be applied to the development of an automated system for mental fatigue detection."
디노이징 오토인코더와 그래프 컷을 이용한 딥러닝 기반 바이오-셀 영상 분할,2021,"['Bio-cell Informatics', 'Bacterial Cell Segmentation', 'Denoising Autoencoder', 'Hybrid Feature', 'Artificial Neural Network', 'Deep Learning', 'Graph Cuts']",,
CAPS : CCTV 영상을 이용한 자율형 딥러닝 기반 아동학대 감지 시스템,2021,"['Child Abuse Protection System', 'Face Detection', 'Mosaic Generation', 'Deep Learning']",,"Though the mandatory policy of installing CCTV in the childhood care facilities of public institutions such as kindergarten and daycare center, the criminal of child abuse cases is gradually increasing due to the lack of awareness of violent acts and the difficulty in understanding the reporting processes. This paper proposes a novel Child Abuse Protection System (CAPS) to solve the above social problem. The proposed CAPS is composed of three functional software modules to implement a deep-learning-based system that autonomously detects violent acts against children. First, the clip creator module divides long CCTV videos into several pieces of short video clips. Second, the violence detector module classifies the abuse behaviors from the generated clips. Finally, the face detector module automatically processes the witnessed suspect’s face being blurred out by mosaic. Experimental evaluation results show that the most suitable feature extractor for detecting the child abuse behaviors is the MobileNetV2+LSTM model among several candidates of the proposed CNN+LSTM violence detection module, which has the best at 92.51% accuracy. Furthermore, the recall rate can be increased up to 6% by exploiting the proposed data augmentation technique. Codes are available at https://github.com/learningsteady0J0/ CAPS-Child-Abuse-Protection-System."
패션 요소 검출을 위한 Mask R-CNN 딥러닝,2021,"['인공지능', '패션', 'R-CNN', 'Fast R-CNN', 'Faster R-CNN', 'Mask R-CNN', 'Artificial Intelligence', 'Fashion']",,"In this paper, in order to prepare a framework that can provide personalized artificial intelligence fashion coordination services, fashion elements were detected using the Mask R-CNN deep learning algorithm targeting the fashion image data set provided in the iMaterialist Fashion Attribute Dataset. As a result of performing deep learning to detect fashion elements with a total of 8 epochs, the loss of training data was found to be Lcls 0.53, Lbox 0.38, and Lmask 0.35. And the loss of Validation data was Lcls 0.54, Lbox 0.33, Lmask 0.36. Effective personal artificial intelligence fashion when fine-tuning using the deep learning method implemented in this paper after adding various conditions such as color, season, material, trend, and brand name based on the fashion image data set owned by an individual It is expected that it will be a coordination service."
전이학습 기반 무인수색차량의 표적 탐지 및 식별 딥러닝 모델 분석,2021,"['Unmanned recon vehicle', 'Intelligent target process', 'Identification of friend and foe', 'Target detection']",,"Research on unmanned combat systems is being actively conducted around the world. Republic of Korea Army has been researching on unmanned recon vehicles in order to minimize damage to the troops of mechanized units as well as to support various missions such as leading reconnaissance, search, and security. ​ For the intelligent system of unmanned recon vehicles, this paper proposes deep learning models that can detect and identify targets using imagery and identify enemy and friendly weapon systems. To cope with, ten weapon systems of South Korean and North Korean that the unmanned recon vehicle will face on the battlefield were selected and about 3,000 image data were collected. By applying transfer learning, the size of AI ​ ​ model was minimized and the detection and identification performance was maximized. As a result, the accuracy for the verification dataset was 78.19% to 86.66%, the accuracy for the Top 3 was 94.50% to 98.15%, the average precision was 79.50% to 86.00%, and the accuracy for the identification of friend and foe was 89.29% to 92.11%."
가구당 기기별 에너지 사용량 예측을 위한 딥러닝 모델의 설계 및 구현,2021,"['에너지 모니터링', '에너지 사용량 예측', '에너지 관리 시스템', '머신러닝 모델', 'Energy Moniotring', 'Energy consumption prediction', 'Energy Management System', 'Machine Learning Model']",,"Korea is both a resource-poor country and a energy-consuming country. In addition, the use and dependence on electricity is very high, and more than 20% of total energy use is consumed in buildings. As research on deep learning and machine learning is active, research is underway to apply various algorithms to energy efficiency fields, and the introduction of building energy management systems (BEMS) for efficient energy management is increasing. In this paper, we constructed a database based on energy usage by device per household directly collected using smart plugs. We also implement algorithms that effectively analyze and predict the data collected using RNN and LSTM models. In the future, this data can be applied to analysis of power consumption patterns beyond prediction of energy consumption. This can help improve energy efficiency and is expected to help manage effective power usage through prediction of future data."
다채널 라이다의 주행 및 가상 데이터셋에 대한 딥러닝 기반 차량 검출 알고리즘의 학습 및 성능 비교 연구,2021,"['Vehicle detection(차량 검출)', 'Deep learning(심층 학습)', '3D LiDAR(3차원 라이다)', 'Fine tuning(세부 튜닝)', 'Sensor simulator(센서 시뮬레이터)', 'Virtual data(가상 데이터)']",,
해수 이용 LNG 재기화 공정의 딥러닝과 AutoML을 이용한 동적모델링,2021,"['Machine learning', 'Dynamic modeling', 'Operations decision support', 'AutoML']",,"First principle-based modeling studies have been performed to improve the heat exchange efficiency of ORV and optimize operation, but the heat transfer coefficient of ORV is an irregular system according to time and location, and it undergoes a complex modeling process. In this study, FNN, LSTM, and AutoML-based modeling were performed to confirm the effectiveness of data-based modeling for complex systems. The prediction accuracy indicated high performance in the order of LSTM > AutoML > FNN in MSE. The performance of AutoML, an automatic design method for machine learning models, was superior to developed FNN, and the total time required for model development was 1/15 compared to LSTM, showing the possibility of using AutoML. The prediction of NG and seawater discharged temperatures using LSTM and AutoML showed an error of less than 0.5K. Using the predictive model, real-time optimization of the amount of LNG vaporized that can be processed using ORV in winter is performed, confirming that up to 23.5% of LNG can be additionally processed, and an ORV optimal operation guideline based on the developed dynamic prediction model was presented."
군사용 SAR 이미지 초해상화를 위한 딥러닝 기반의 네트워크 구조에 관한 연구,2021,"['Deep learning', 'Super-resolution', 'Synthetic aperture radar image']",,"The Republic of Korea military is using SAR(Synthetic Aperture Radar) geographic intelligence to deal with security threats. However, human experts have difficulty on analyzing acquired SAR images and identifying military targets due to low resolution. In this paper, we study the deep learning-based network architecture fit for the super-resolution of military SAR images. Previous military SAR image super-resolution studies mainly conducted on improving the results of super-resolution, but it was difficult to find studies on network architecture. The proposed neural network is a deep learning-based super-resolution networks. And it consists of input, learning, upsampling, and output layers with real military SAR images. We show and experiment with networks for super-resolution of military SAR images, while focusing on the input and upsampling layers. Experiment results show that we able to find a suitable architecture of input and upsampling layers is discussed."
보행 역학 데이터를 활용한 대퇴 의지 실시간 제어를 위한 딥러닝 모델 구조 연구,2021,"['deep learning model', 'above-knee prosthesis', 'gait dynamics data', 'sliding window algorithm', 'width and depth']",,"Training data of the deep learning model for the control of the above-knee prosthesis should have a sufficient amount of data to fit with the model. Also, this data can be used for gait classification to control the prosthesis. However, in real-time control, the number of the gait dynamics data counted by the sensor is only measured to the level that the deep learning model is difficult to learn., In this study, the most efficient deep learning model case was developed to resolve this problem in the case of a real-time control situation where data measurement time is insufficient. The data is collected through a hall sensor, load cell and Inertial Measurement Unit (IMU) mounted on the above-knee prosthesis. Subsequently, the collected data is divided into 5 phases (Loading Response (LR), Mid Stance (MS), Push Off (PO), Early Swing (ES), and Late Swing (LS)) of the gait cycle according to the point of inflection of hall sensors and load cells. Afterward, training data of the deep learning were generated by sliding window algorithm and the treated data was exercised on four deep learning models by changing the value of width and depth configurations. The results are assessed on accuracy, loss and F1-Score. In conclusion, the loss function statistically decreased in the case of the values of width and depth of the deep learning model were low. Accuracy and F1-Score were not shown significant difference statistically. Therefore, the results provided an efficient deep learning model for above-knee prosthesis to gait analysis and expected to lead to a more reasonable gait model for the control of the above-knee prosthesis via a more detailed gait classification study in the future."
Domain Shift 문제를 해결하기 위해 안개 특징을 이용한 딥러닝 기반 안개 제거 방법,2021,"['De-fogging', 'Deep learning', 'Domain shift', 'U-net', 'Loss function']",,
ROS 기반의 실내자율 주행 로봇의 자기위치 인식 및 딥러닝에 의한 제어 시스템,2021,"['Robot Operating System(로봇 운영 체제)', 'Indoor Self-driving(실내 자율 주행)', 'Automated Guided Vehicle(무인 운반차)', 'LiDAR Sensor(라이다 센서)', 'Inertial Measurement Unit(관성 측정 센서)']","본 연구는 물류 센터 무인화를 위해 상자를 지역, 회사에 따라 분류하고 장애물을 실시간으로 회피하며 목표지점까지 운송하는 로봇 시스템을 개발하는 것을 목표로 하고 있다. 전체 제어 시스템은 ROS(robot operating system)로 구성하였으며, 모터 제어 및 기타 센서 처리를 위해 하부제어기로 OpenCR을 추가하였다. 또한 IMU 센서와 encoder를 결합한 odometry를 기반으로 AMCL(adaptive Monte Carlo localization) 알고리즘을 사용하여 로봇 위치를 추정 및 보정하였다. 또한 이를 LiDAR와 결합하여 맵핑 및 주행(navigation)을 진행하였다. 상자 분류는 YOLO를 통해 진행하였다. 그 결과 상자 분류를 통해 스스로 목표지점을 설정하고 라이더로 장애물을 인식하여 실시간으로 회피하는 자율주행 로봇을 구현하였다.","In this study, an indoor self-driving automated guided vehicle that recognizes objects in a logistics center and transports them to their destinations is introduced. The robot must be aware of its location while it moves and must be able to recognize its surroundings in real time to operate in the self-driving mode. The control system is composed of a robot operating system (ROS) with OpenCR used as a lower controller for motor control and other sensor processing. The robot position is estimated by combining the adaptive Monte Carlo localization algorithm (AMCL) with odometry using an inertial measurement unit sensor and an encoder, and mapping and navigation are performed by combining it with LiDAR. In addition, box classification is conducted through you-only-look-once (YOLO) object detection. Consequently, we implement a self-driving robot that sets its own target point through box classification and avoids obstacles in real time by recognizing obstacles with LiDAR."
기상정보 예측 성능 개선을 위한 빅데이터 병합 및 딥러닝 모델 최적화,2021,"['Weather forecast', 'Time-series data', 'Deep learning', 'LSTM']","급속한 산업화의 영향으로 많은 형태의 대기오염이 증가하고 있으며, 특히 미세먼지는 심장 및 폐 관련 질환을 발생시키거나 악화시키는 등 인체에 악영향을 끼친다. 본 연구에서는 미세먼지 피해를 줄이기 위한 해결방안으로 사전에 대응할 수 있도록 8시간 후의 미세먼지 수치를 예측한다. 우리는 정확한 예측을 위해 다양한 dataset을 구성하였고 시계열 데이터 예측에서 좋은 성능을 보여주는 LSTM 계열의 모델인 Stacked LSTM, LSTM AutoEncoder, LSTM Variational AutoEncoder를 이용한다. 연구 결과 데이터 수의 증가는 모델의 성능을 향상시키지 못했으나 feature 수의 증가는 모델의 성능을 향상시켰다. 또한, feature 수가 많은 dataset일수록 LSTM AutoEncoder가 가장 좋은 성능을 보였다.","Due to the rapid industrialization, many forms of air pollution are increasing, especially particulate matter has an adverse effect on the human body, such as causing or worsening heart and lung-related diseases. This research predicts particulate matter levels in 8-hours so that it can respond in advance as a solution to reduce fine dust damage. We construct various datasets for accurate prediction and utilize Stacked LSTM, LSTM AutoEncoder, and LSTM Variational AutoEncoder, models of the LSTM family that show good performance in time series data prediction. Research show that the increase in the number of data did not improve the performance of the model, but the increase in the number of features improved the performance of the model. Furthermore, the higher the number of features, the better the LSTM AutoEncoder performance."
드론 영상으로부터 월동 작물 분류를 위한 의미론적 분할 딥러닝 모델 학습 최적 공간 해상도와 영상 크기 선정,2021,"['Drone image', 'Semantic segmentation', 'Deeplabv3+', 'Winter vegetation', 'Spatial resolution']",,"A Drone image is an ultra-high-resolution image that is several or tens of times higher in spatial resolution than a satellite or aerial image. Therefore, drone image-based remote sensing is different from traditional remote sensing in terms of the level of object to be extracted from the image and the amount of data to be processed. In addition, the optimal scale and size of data used for model training is different depending on the characteristics of the applied deep learning model. However, most studies do not consider the size of the object to be found in the image, the spatial resolution of the image that reflects the scale, and in many cases, the data specification used in the model is applied as it is before. In this study, the effect of spatial resolution and image size of drone image on the accuracy and training time of the semantic segmentation deep learning model of six wintering vegetables was quantitatively analyzed through experiments. As a result of the experiment, it was found that the average accuracy of dividing six wintering vegetables increases as the spatial resolution increases, but the increase rate and convergence section are different for each crop, and there is a big difference in accuracy and time depending on the size of the image at the same resolution. In particular, it was found that the optimal resolution and image size were different from each crop. The research results can be utilized as data for getting the efficiency of drone images acquisition and production of training data when developing a winter vegetable segmentation model using drone images."
그린레이저를 이용한 Al-Cu 이종소재 레이저 용접 연구 및 딥러닝에 의한 품질판정,2021,"['Dissimilar joining', 'Al welding', 'Copper welding', 'Green laser', 'Battery welding']",,"This study reports on Al-6061 and oxygen-free copper C1020P joining results and analysis using cross-sectional metallography and a weld bead deep learning algorithm. The state-of-the-art green laser in the visible region (λ = 515 nm) was used as a welding heat source, and the reliability of the bonding interface was analyzed. Remarkable spatter reduction was achieved in the full scan-speed range of 180 - 220 mm/s and output of 800–1200 W. Using a green laser with 40% absorption, we achieved high-quality joining without employing any additional mechanical processes such as weaving, wobble, or oscillation. In the case of an IR laser, we determined that it was sensitive to the state of the surface (e.g., scratched or rough). By contrast, in the case of the green laser, it was relatively insensitive, and a homogeneous bead was formed. Over 98% accuracy was found for the welded parts, and 66% accuracy was observed for the failed welding parts. The welding quality was derived as a deterministic rather than stochastic result, and it was confirmed that image-based deep learning technology was effectively applied and could be used for non-destructive welding quality inspection."
"사람에서 컴퓨터 자동화로의 연결을 위한 탐색 : 객체 인식(Object Detection) 딥러닝 알고리즘 YOLO4, 자세 인식(Pose Detection) 프레임워크 MediaPipe를 활용한 음악 프로그램의 여성 신체 대상화, 선정적 화면 검출 연구",2021,"['Body Objectification', 'Object Detection', 'Pose Detection', 'YOLO4', 'MediaPipe', '객체 동작 감지', '여성 신체 대상화', '선정적 화면']",,"The goal of this research is to examine patterns of objectification and sexualization of the female body in music programs on television. The study’s goal is to identify rules for automated visual image detection of body objectification and sexualization. To do so, previous qualitative study findings were used to identify target images and the cutting-edge object-detection deep learning algorithm, YOLO4 (You Only Look Once), and MediaPipe, a framework for deep learning-based pose detection, were used to search for patterns. As this is a one-of-a-kind study linking body objectification and algorithm-based object detection, the case for analysis must be carefully chosen, taking into account random effects from unplanned camera movements caused by real-time broadcasting. The dance to the song ’Rollin’ by the female group ’Brave Girls’ had already been broadcasted earlier in 2017. Thus, the on-stage choreography and camera movements associated with the song were already known, making them suitable for research data. The study used music programs that aired on three broadcasting networks, KBS, MBC, and SBS, during the second week of March, 2021. To fine-tune the patterns, 12 screen images were selected by extracting keyframes from the song’s original music videos. The study’s findings are summarized below. To begin, when the scene transition is associated with a significant decrease in the number of people in the visual frame in comparison to the previous frame, it is frequently associated with female body objectification. Because body objection is associated with an emphasis on a specific body-part in the absence of a face, this is essentially a zoom-in technique transited from a wide-angle view of the scene. This rule, however, is insufficient for detecting objectified visual images; it can also be applied to screen images that avoid sexualized images in the given dance choreography. As a result, an additional rule is required to exclusively find images of female body objectification, and it is discovered that detecting human faces on the screen appears to be a good measure. In other words, unless the human faces on the screen do not appear with the scene transition that shows a dramatic decrease in the number of humans in the scene, a visual flow of images can be considered female body objectification. The study also compared the levels of objectification across broadcasting networks and found that MBC has a lower proportion of sexualized images than that of other networks. On MBC’s music program, the MediaPipe framework for pose detection discovered fewer scene images with lower body parts than others. The findings of this study suggest that computer vision research can be used to detect female objectified bodies and sexual images in television programs."
이미지 기반 실시간 건설 현장 장비 및 작업자 모니터링을 위한 딥러닝 플랫폼 아키텍처 도출,2021,[],,"Recently, starting with smart construction research, interest in technology that automates construction site management using artificial intelligence technology is increasing. In order to automate construction site management, it is necessary to recognize objects such as construction equipment or workers, and automatically analyze the relationship between them. For example, if the relationship between workers and construction equipment at a construction site can be known, various use cases of site management such as work productivity, equipment operation status monitoring, and safety management can be implemented. This study derives a real-time object detection platform architecture that is required when performing construction site management using deep learning technology, which has recently been increasingly used. To this end, deep learning models that support real-time object detection are investigated and analyzed. Based on this, a deep learning model development process required for real-time construction site object detection is defined. Based on the defined process, a prototype that learns and detects construction site objects is developed, and then platform development considerations and architecture are derived from the results."
유사 이미지 분류를 위한 딥 러닝 성능 향상 기법 연구,2021,"['분류', '딥 러닝', '유사 이미지', '컨볼루셔널 뉴럴 네트워크', '혼동률', 'Classification', 'Deep Learning', 'Similar Image', 'CNN', 'Confusion Rate']","딥 러닝을 활용한 컴퓨터 비전 연구는 여전히 대규모의 학습 데이터와 컴퓨팅 파워가 필수적이며, 최적의 네트워크 구조를 도출하기 위해 많은 시행착오가 수반된다. 본 연구에서는 네트워크 최적화나 데이터를 보강하는 것과 무관하게 데이터 자체의 특성만을 고려한 CR(Confusion Rate)기반의 유사 이미지 분류 성능 향상 기법을 제안한다. 제안 방법은 유사한 이미지 데이터를 정확히 분류하기 위해 CR을 산출하고 이를 손실 함수의 가중치에 반영함으로서 딥 러닝 모델의 성능을 향상시키는 기법을 제안한다. 제안 방법은 네트워크 최적화 결과와 독립적으로 이미지 분류 성능의 향상을 가져올 수 있으며, 클래스 간의 유사성을 고려해 유사도가 높은 이미지 식별에 적합하다. 제안 방법의 평가결과 HanDB에서는 0.22%, Animal-10N에서는 3.38%의 성능향상을 보였다. 제안한 방법은 다양한 Noisy Labeled 데이터를 활용한 인공지능 연구에 기반이 될 것을 기대한다.","Deep learning in computer vision has made accelerated improvement over a short period but large-scale learning data and computing power are still essential that required time-consuming trial and error tasks are involved to derive an optimal network model. In this study, we propose a similar image classification performance improvement method based on CR (Confusion Rate) that considers only the characteristics of the data itself regardless of network optimization or data reinforcement. The proposed method is a technique that improves the performance of the deep learning model by calculating the CRs for images in a dataset with similar characteristics and reflecting it in the weight of the Loss Function. Also, the CR-based recognition method is advantageous for image identification with high similarity because it enables image recognition in consideration of similarity between classes. As a result of applying the proposed method to the Resnet18 model, it showed a performance improvement of 0.22% in HanDB and 3.38% in Animal-10N. The proposed method is expected to be the basis for artificial intelligence research using noisy labeled data accompanying large-scale learning data."
"2개의 비전 센서 및 딥 러닝을 이용한 도로 속도 표지판 인식, 자동차 조향 및 속도제어 방법론",2021,"['자율 주행', '딥 러닝', '교통 표지판', '허프 변환', '라즈베리 파이', 'Autonomous Driving', 'Deep Learning', 'Traffic Sign', 'Hough Transform', 'Raspberry Pi']","본 논문에서는 2개의 비전 센서와 딥 러닝을 이용한 자율주행 차량의 속도제어 알고리즘을 제시하였다. 비전 센서 A로부터 제공되는 도로 속도 표지판 영상에 딥 러닝 프로그램인 텐서플로우를 이용하여 속도 표지를 인식한 후, 자동차가 인식된 속도를 따르도록 하는 자동차 속도 제어 알고리즘을 제시하였다. 동시에 비전 센서 B부터 전송되는 도로 영상을 실시간으로 분석하여 차선을 검출하고 조향 각을 계산하며 PWM 제어를 통해 전륜 차축을 제어, 차량이 차선을 추적하도록 하는 조향 각 제어 알고리즘을 개발하였다. 제안된 조향 각 및 속도 제어 알고리즘의 유효성을 검증하기 위해서 파이썬 언어, 라즈베리 파이 및 Open CV를 기반으로 하는 자동차 시작품을 제작하였다. 또한, 시험 제작한 트랙에서 조향 및 속도 제어에 관한 시나리오를 검증함으로써 정확성을 확인할 수 있었다.","In this paper, a steering control and speed control algorithm was presented for autonomous driving based on two vision sensors and road speed sign board. A car speed control algorithm was developed to recognize the speed sign by using TensorFlow, a deep learning program provided by Google to the road speed sign image provided from vision sensor B, and then let the car follows the recognized speed. At the same time, a steering angle control algorithm that detects lanes by analyzing road images transmitted from vision sensor A in real time, calculates steering angles, controls the front axle through PWM control, and allows the vehicle to track the lane. To verify the effectiveness of the proposed algorithm s steering and speed control algorithms, a car’s prototype based on the Python language, Raspberry Pi and OpenCV was made. In addition, accuracy could be confirmed by verifying various scenarios related to steering and speed control on the test produced track."
딥 러닝을 이용한 문서 스캔 이미지 탐색 기술,2021,"['문서 스캔 이미지', '이미지 탐색', '딥 러닝', '컨볼루셔널 뉴럴 네트워크', '디지털포렌식', 'Document Scan Image', 'Image Searching', 'Deep Learning', 'Convolutional Neural Network', 'Digital Forensics']",,
딥 러닝을 이용한 새로운 다중 객체 구별 방법,2021,"['Class-Agnostic Object Detection', 'Image Retrieval', 'Deep Learning']",,"In this paper, we propose a novel multi-object distinction method with class-agnostic object detection and class retreival. Multi-object distinction is usually divided into the processes of detecting and classifying an object. Since it is common for industrial applications to add new kinds of objects to be recognized, it is inefficient to re-train the system every time the new object is added. Thus, the propose method employs two deep learning models to solve this problem. 1) Class agnostic object detection model to predict the bounding boxes regardless of the classes of objects and 2) Class retrieval model to determine the classes of the objects. The experimental results show that the proposed method successfully detects and classifies the both experienced and inexperienced objects: the final classification accuracy for 15 learned objects was 98.0%, and for the other 30 new objects that had not been learned. the accuracy was 87.7% on average."
딥 러닝을 이용한 인공지능 구성방정식 모델의 개발,2021,"['Finite Element Method', 'Artificial Intelligence', 'Deep Learning', 'Constitutive Equation']",,
음악 소리가 딥 러닝의 음향 분류 성능에 미치는 영향,2021,"['Sound classification', 'Deep learning', 'Music genre', 'UrbanSound8K', 'GTZAN']",,"Sound classification is a computer technology that involves learning to classify sounds and to predict the category of that sound. Recently, the machine learning based approach is being actively conducted for improving recognition accuracy. In this approach, a deep neural network is trained using a sound dataset, and then the actual sound is applied to identify the sound category. In the identification stage, the recognition accuracy of the machine learning is degraded due to the ambient noise. In other words, unlike the experimental environment, various sounds are input into the microphone along with the target sound. Since these ambient sounds are not trained, they could lower the classification performance. However, there are only a few research results on the relation between the noise and the recognition performance despite of the practical importance. In this paper, we study the performance degradation of sound classification in the space where the music is playing with considering the music genre and the volume level. For this, we use CNN, UrbanSound8K dataset consisting of 10 kinds of environmental sounds, and GTZAN data set containing 10 kinds of music genres. First, CNN is trained to recognize the sounds of UrbanSound8K, and then five songs for each genre were selected from GTZAN and mixed to the UrbanSound8K so that the signal-to-noise ratio are -20dB, 0dB, 5dB, 10dB, and 20dB. Then we test the accuracy with the mixed sound input and compare with the noise-free target sound. As a result, there is 2.8% to 22% difference in the recognition accuracy by music genre and sound level. The result show that the SNR should be 20dB or more in order for music not to have a significant effect on the recognition accuracy."
흉부 X-ray 기반 딥 러닝 손실함수 성능 비교·분석,2021,"['딥 러닝', '바이오 마커', '손실함수', '인공지능', '의료 영상', 'Deep learning', 'Biomarker', 'Loss function', 'Artificial intelligence', 'Medical image']","4차 산업의 발전과 고성능의 컴퓨팅 환경 구축으로 다양한 산업분야에서 인공지능이 적용되고 있다. 의료분야에서는 X-Ray, MRI, PET 등의 의료 영상 및 임상 자료를 이용하여 암, COVID-19, 골 연령 측정 등의 딥 러닝 학습이 진행되었다. 또한 스마트 의료기기, IoT 디바이스와 딥 러닝 알고리즘을 적용하여 ICT 의료 융합 기술 등이 연구되고 있다. 이러한 기술 중 의료 영상 기반 딥 러닝 학습은 의료 영상의 바이오마커를 정확히 찾아내고, 최소한의 손실률과 높은 정확도가 필요하다. 따라서 본 논문은 흉부 X-Ray 이미지 기반 딥 러닝 학습 과정에서 손실률을 도출하는 손실함수 중 영상분류 알고리즘에서 사용되는 Cross-Entropy 함수들의 성능을 비교·분석하고자 한다.","Artificial intelligence is being applied in various industrial fields to the development of the fourth industry and the construction of high-performance computing environments. In the medical field, deep learning learning such as cancer, COVID-19, and bone age measurement was performed using medical images such as X-Ray, MRI, and PET and clinical data. In addition, ICT medical fusion technology is being researched by applying smart medical devices, IoT devices and deep learning algorithms. Among these techniques, medical image-based deep learning learning requires accurate finding of medical image biomarkers, minimal loss rate and high accuracy. Therefore, in this paper, we would like to compare and analyze the performance of the Cross-Entropy function used in the image classification algorithm of the loss function that derives the loss rate in the chest X-Ray image-based deep learning learning process."
딥 러닝 기반 설명 가능한 인공지능과 무인기의 다중 이미지 센서를 활용한 무 시들음병 탐지 프레임워크,2021,"['무 시들음병', '딥 러닝', '설명가능한 인공지능', '무인비행체', 'RGB', '근적외선', 'Fusarium wilt', 'Deep learning', 'XAI', 'UAV', 'RGB', 'NIR']","전 세계적으로 사랑받고 있는 채소인 무는 뿌리채소 중 하나로 다양한 요리에 주재료로 사용되고 있어 많은 양이 생 산되고 소비된다. 무는 또한 한국의 음식 문화에서도 중요한 역할을 하는데, 대표적인 한국의 음식 중 하나인 김치 에도 무가 사용된다. 하지만 최근 급격한 기후 변화로 인해 무가 시들음병에 쉽게 노출될 수 있는 환경이 만들어져 무의 품질과 수확량이 크게 저하되는 문제가 생기고 있다. 무 시들음병 문제를 해결하기 위한 기존의 식물 대상의 질병 식별 방식은 수집한 컬러 이미지에서 수동으로 특징을 추출했기 때문에 많은 시간과 비용을 소모했다. 하지만 최근 근적외선 센서의 개발로 인해 식물의 질병 식별을 시간적, 금전적으로 보다 효율적으로 판별할 수 있도록 발전 하였다. 본 논문에서는 다중 이미지 센서를 기반으로 무인 비행체인 드론을 사용하여 무 시들음병을 식별할 수 있는 컬러 및 근적외선 이미지에 대한 딥 러닝 프레임워크를 제안하고 비교한다. 또한 사용자가 딥 러닝 모델의 결과를 시각적으로 이해할 수 있도록 설명가능한 인공지능(XAI) 접근 방식을 사용한다. 다양한 실험에서 얻은 결과로 제안 하는 프레임워크는 정확도, 계산 복잡성 측면에서 기존 탐지 시스템에 비해 더 나은 성능을 보인다는 것을 보여주었 고, 근적외선 데이터셋은 식생 지수 계산을 통해 무 시들음병을 식별하는데 효과가 있음을 보여주었다.","Radish, loved worldwide, is one of the root vegetables and is used as a main ingredient in various dishes, so it has a lot of production and consumption. Radish is also used in kimchi, one of the most popular Korean foods. Due to rapid climate change in recent years, it can be easily exposed to the radish fusarium wilt disease, which greatly reduces the quality and yield of radishes. Traditional plant disease identification methods used to solve the Fusarium Wilt problem are time-consuming and costly because they rely on manually extracting features from collected RGB images. Recent developments in near-infrared sensors have made it possible to determine plant health more efficiently, both in time and money. In this paper, we propose and compare Deep Learning Framework for RGB and NIR(Near-infrared) images that can identify radish fusarium wilt disease using Drone, Unmanned Aerial Vehicle based on multiple image sensors. It also uses an XAI(eXplainable Artificial Intelligence) approach that allows users to visually understand the results of the Deep Learning model. As a result of the various experiments, the proposed Framework showed better performance compared to existing detection systems in terms of accuracy and computational complexity, while NIR Dataset showed that it was effective in identifying the radish fusarium wilt disease through the Vegetation index calculation."
딥 러닝 기반의 메신저 캡처 이미지 검출 기술,2021,"['메신저 캡처', '이미지 검출', '딥 러닝', '컨볼루셔널 신경망', '디지털 포렌식', 'Messenger Capture', 'Image Detection', 'Deep Learning', 'Convolutional Neural Network', 'Digital Forensics']",,
생성 딥 러닝 모델을 이용한 근 미래 차량 속도 프로파일 예측 기술 개발,2021,"['Vehicle speed prediction(차량 속도 예측)', 'Predictive gear-shifting(예측 기어 변속)', 'Powertrain control(파워트레인 제어)', 'Generative deep learning(생성 딥 러닝)', 'CVAE(조건적 배리에이셔널 오토 인코더)', 'Neural network (뉴럴 네트워크)']",,
자율 운항 선박을 위한 딥 러닝 기반 선박 이미지 분류 방법,2021,"['Image Classification', 'Object Detection', 'Convolutional Neural Network', 'Deep Learning', 'Heatmap', 'Autonomous Ship']",,"In the last few years, researches on autonomous ships have attracted attention. One of the essential techniques required for autonomous ships is the awareness of surroundings, including detection and classification of objects. Although researches on computer vision regarding the classification of ship images are still making progress, it is challenging to encounter a lack of enough database that was adequately labeled for ship classification. In this study, data obtained from Singapore Maritime Dataset (SMD) and public datasets such as MARVEL, FleetMon, and VesselFinder were labeled and integrated into a unified dataset for further study for ship classification. The ship image dataset was classified into seven classes, including bulk carrier, container ship, cruise ship, naval surface ship, tanker, tug boat, and buoy. Subsequently, Convolutional Neural Networks (CNNs) based on GoogleNet, VGG16, and ResNet were implemented for ship image classification, and a comparative test was done. As a result, the CNNs which were trained with the unified dataset showed high accuracy. The classification results were analyzed by the heatmap visualization with Grad-CAM, which indicates critical features best activating each class of ships, and further discussion was made."
딥 러닝 기반 미상 레이다 대응 재밍 알고리듬,2021,"['jamming', 'unknown radar', 'electronic attack', 'deep learning']",,"The conventional method of predicting a jamming technique in jammer uses a library containing radar-signal information and matched jamming technique. The library is produced by analysis and identification of radar-signals for a long period. This method has a limitation that a jammer can not select a proper jamming technique against unknown radar signals such as mode changing or new radar. To resolve the problem, a method for jamming against an unknown radar, based on deep learning is proposed in this study. The proposed method uses co-occurrence matrix as features with conventional features in electronic warfare. The proposed method shows more than 10% better performance than a method, not using a co-occurrence matrix. And as in the case of actual electronic attack equipment operation, the jamming technique prediction performance is more than 88%even when the collected data is 10% less than the learning data."
딥 러닝 기반의 팬옵틱 분할 기법 분석,2021,"['Panoptic segmentation', 'Thing', 'Stuff', 'Top-down method', 'Bottom-up method']",,"Panoptic segmentation, which is now widely used in computer vision such as medical image analysis, and autonomous driving, helps understanding an image with holistic view. It identifies each pixel by assigning a unique class ID, and an instance ID. Specifically, it can classify 'thing' from 'stuff', and provide pixel-wise results of semantic prediction and object detection. As a result, it can solve both semantic segmentation and instance segmentation tasks through a unified single model, producing two different contexts for two segmentation tasks. Semantic segmentation task focuses on how to obtain multi-scale features from large receptive field, without losing low-level features. On the other hand, instance segmentation task focuses on how to separate 'thing' from 'stuff' and how to produce the representation of detected objects. With the advances of both segmentation techniques, several panoptic segmentation models have been proposed. Many researchers try to solve discrepancy problems between results of two segmentation branches that can be caused on the boundary of the object. In this survey paper, we will introduce the concept of panoptic segmentation, categorize the existing method into two representative methods and explain how it is operated on two methods: top-down method and bottom-up method. Then, we will analyze the performance of various methods with experimental results."
딥 러닝 기반의 눈 랜드마크 위치 검출이 통합된 시선 방향 벡터 추정 네트워크,2021,"['Gaze Estimation', 'Eye Landmark Localization', 'Eye Landmark Detection']",,"In this paper, we propose a gaze estimation network in which eye landmark position detection and gaze direction vector estimation are integrated into one deep learning network. The proposed network uses the Stacked Hourglass Network as a backbone structure and is largely composed of three parts: a landmark detector, a feature map extractor, and a gaze direction estimator. The landmark detector estimates the coordinates of 50 eye landmarks, and the feature map extractor generates a feature map of the eye image for estimating the gaze direction. And the gaze direction estimator estimates the final gaze direction vector by combining each output result. The proposed network was trained using virtual synthetic eye images and landmark coordinate data generated through the UnityEyes dataset, and the MPIIGaze dataset consisting of real human eye images was used for performance evaluation. Through the experiment, the gaze estimation error showed a performance of 3.9, and the estimation speed of the network was 42 FPS (Frames per second)."
문학 텍스트의 머신러닝 활용방안 연구 - 화자 지시어 분석을 위한 규칙 선별을 중심으로 -,2021,"['문학 텍스트', '화자 지시어', '영어 대명사', '대용화', '머신 러닝', 'Literature', 'Speaker-directed Terminology', 'English Pronoun', 'Pronominalization', 'Machine Learning']","본 연구는 문학 텍스트를 활용한 머신러닝 기반 가상 캐릭터(virtual character) 구현을 위해 텍스트 내의 화자 지시어가 지시하는 화자를 판별할 수 있는 규칙을 제안하는 것을 목적한다. 선행 연구에서, 본 연구자는 문학 텍스트 를 기계 학습에 적용할 때, 별칭, 별명, 대명사와 같은 화자 지시어들이 특정한 분석 규칙 없이는 기계가 화자를 제대 로 파악하지 못하여 학습을 제대로 수행할 수 없다는 점을 발견하였다. 본 연구는 이를 해결하는 방법으로 ‘화자 지 시어(대명사 포함)가 지시하는 화자를 찾는 9가지 규칙'을 소개한다: 위치, 거리, 대명사, 가주어/진주어, 인용문, 화자 수, 등장인물 외 지시, 복합 단어 지시, 화자명 분산이 그것이다. 문학 텍스트 내의 등장인물을 가상 캐릭터로 활용하 기 위해서는 기계가 이해할 수 있는 방식으로 학습 텍스트를 제공해야 한다. 본 연구자는 본 논문을 통해 제안한 화 자 찾기 규칙이 문학 텍스트를 머신러닝에 활용할 때 발생할 수 있는 시행착오를 줄이고, 원활한 학습을 수행하게 하 여 질적으로 우수한 학습 결과를 산출할 수 있게 해 줄 것으로 기대한다.","The purpose of this study is to propose rules that can identify the speaker referred by the speaker directive in the text for the realization of a machine learning-based virtual character using a literary text. Through previous studies, we found that when applying literary texts to machine learning, the machine did not properly discriminate the speaker without any specific rules for the analysis of speaker directives such as other names, nicknames, pronouns, and so on. As a way to solve this problem, this study proposes ‘nine rules for finding a speaker indicated by speaker directives (including pronouns)’: location, distance, pronouns, preparatory subject/preparatory object, quotations, number of speakers, non-characters directives, word compound form, dispersion of speaker names. In order to utilize characters within a literary text as virtual ones, the learning text must be presented in a machine-comprehensible way. We expect that the rules suggested in this study will reduce trial and error that may occur when using literary texts for machine learning, and enable smooth learning to produce qualitatively excellent learning results."
마케팅 분야의 머신러닝 연구 동향 분석,2021,"['머신러닝', '기계학습', '딥러닝', '토픽모델링', '잠재 디리클레 할당', '자연어 분석', '감성 분석', 'Machine Learning', 'Deep Neural Networks', 'Topic Modeling', 'Latent Dirichlet Allocation', 'Natural Language Processing', 'Sentiment Analysis']","최근 ICT 기술의 발달로 고성능 컴퓨팅과 데이터 저장 기술이 발전하고 다양한 데이터가 생성, 공유, 저장되는 것이 가능해짐에 따라 머신러닝을 활용하여 마케팅 인사이트를 얻는 사례가 크게 늘어났다. 본 연구는 마케팅 연구자들에게 머신러닝 기법의 기초적인 개념들을 소개하고 어떠한 마케팅 연구에 적용될 수 있는지 정리하여 머신러닝 연구를 활성화하는 데 목적이 있다. 먼저, 머신러닝의 기초적인 개념들과 머신러닝 방법론의 종류를 간략하게 소개한다. 그리고, 마케팅과 경영학의 최우수 저널에서 머신러닝을 다루는 연구를 찾아내어 여섯 가지 유형으로 정리하였는데, 그 유형들은 다음과 같다. 1) 머신러닝을 이용하여 데이터에서 마케팅 변수를 추출하여 다른 변수와의 관계를 살펴보는 연구, 2) 머신러닝을 이용하여 새로운 데이터를 활용하는 연구, 3) 새로운 방법론이나 현존하는 방법론의 개선을 제안하는 연구, 4) 머신러닝을 이용하여 마케팅 현상의 패턴을 설명하는 연구, 5) 머신러닝을 이용하여 마케팅 현상을 예측하고, 예측력 향상에 영향을 미치는 변수들을 살펴보는 연구, 6) 마케팅 문제에 대한 해결책을 제시하고 인과관계를 규명하는 연구이다. 마지막으로, 마케팅 분야에서 머신러닝 활성화를 위한 제언과 마케팅 연구자들을 위한 함의를 제공한다.","Machine learning methods have gained popularity in marketing academia due to the proliferation of ICT technology. This research aims to introduce marketing academics to methods in machine learning and how they can be applied to research in marketing. We first introduce basic concepts and methodologies in machine learning. Then we examine a list of literature from top marketing and business journals, identify a list of papers that apply machine learning, and categorize them into six types of research. (1) research which extracts marketing variables from data and examines the relationship with other variables, (2) research which uncovers ways to analyze new types of data, (3) research which proposes new methodologies or ways to improve current methodologies, (4) research which aims to describe patterns in marketing phenomena rather than identifying relationships between variables, (5) research which aim to predict marketing phenomena and identify variables that aid prediction, and (6) research which aims to tackle marketing problems and identify causal relationships. We conclude the study with a summary of the advantages and disadvantages of machine learning methods and implications for marketing academics."
머신러닝 알고리즘을 이용한 표준문서의 ICS 코드 자동분류(ICAC),2021,"['ICAC system', 'automatic classification system', 'automatic text classification', 'machine learning', 'deep learning', 'ICAC 시스템', '자동분류 시스템', '자동문서분류', 'ICS', '머신러닝', '딥러닝']","4차 산업혁명 이후, 표준의 범위가 확대되어 가고 있다. 새로운 용어나 유사한 용어들이 표준의 제목에 사용됨에 따라, 표준문서의 분류 및 검색이 복잡해지고 있다. 현재, 표준문서들의 효율적인 검색 및 관리를 위해 국제표준화기구인 ISO에서 운영하는 국제표준분류체계(ICS) 코드가 있으나, 아직도 ISO와 IEC를 제외한 다른 표준 개발 기구들이 ICS 코드체계를 채택하지 않은 설정이다. 더욱이 ICS 코드가 필요에 따라 새로이 수정되면, 이에 따라 ICS코드를 할당받은 기존 표준들도 새로이 ICS 코드를 재할당 받아야 한다. 그러므로 수정되는 ICS 코드 체계에 따라 자동적으로 표준문서를 분류할 수 있는 시스템이 필요한 실정이다. 본 연구는 이러한 표준 문서 분류 시스템을 구축하기 위하여 연구단계를 두 단계로 나누었다. 첫 번째 단계로, 현재의 ICS가 있는 표준들을 가지고 ICS 할당 시스템을 만들어 정확도를 검증하는 것이고, 두 번째 단계로, ICS 코드를 채택하지 않은 표준문서들에 ICS 코드를 할당하도록 하는 것이다. 특별히, 본 논문은 위에서 언급한 첫 번째 단계에 해당하는ICS 분류 및 할당 시스템을 머신러닝 알고리즘을 이용한 구조를 제안하고 이를 구현한 것을 보이는 것이다. 최선의 알고리즘을 선택하여 표준문서들의 ICS 코드를 분류하기 위해 잘 알려진 GRU 알고리즘을 비롯한 여러 알고리즘을 가장 최적의 결과를 보이는 파라미터를 사용하여 시험하였다. 결과적으로 머신러닝 알고리즘 보다 단어의 종속성을 학습하여 분류를 진행하는 딥러닝 알고리즘이 높은 성능을 보였으며, 딥러닝 알고리즘 중 GRU 알고리즘이 가장 높은 성능을 보였다.",
딥 씽킹(Deep Thinking) 전략을 활용한 고전 읽기 교과 설계,2021,"['텍스트로서 고전', '인공지능', '딥 러닝과 딥 씽킹', '인성', '교양교육', '대학 교육', '4차산업혁명', '생애 주기', '정체성', '대화적 상상력', 'convergence subjects', 'classics as text', 'artificial Intelligence', 'deep learning and deep thinking', 'personality', 'liberal arts education', 'university education', '4th Industrial revolution', 'life cycle', 'dialogic Imagination']","본 연구는 4차 산업혁명 시대에 인공지능의 ‘딥 러닝’ 능력과 변별되는 인간의 능력 중 ‘딥 씽킹(Deep﻿Thinking)’에 주목하여,﻿‘딥 씽킹’ 능력 계발을 위한 방법으로<고전 읽기와 대화적 상상력>﻿교양 교과목의 수업 내용을 제안한다.﻿사고하는 인간이인공지능 시대를 이끄는 인간으로 남을 것이며,﻿이 사고하는 힘의 원천은 고전에 있다는 점이 이 교과목이 주는 핵심 메시지이다.﻿구체적으로 대학생들의 생애 주기에맞는 생각거리를 주제로 선정하고,﻿그에 맞는 고전을 선별하여 읽기-토론-쓰기의 과정을 통해 교양과 인성을 함양하고자 한다.﻿이는 4차 산업혁명 시대에 필요한 ‘딥 씽킹’ 능력의 계발이라는 거시적인 목표뿐만 아니라,﻿현재 대학생 스스로가 갖는 현실적이고 다양한 고민들을 고전을 통해 풀어갈 수 있는 해법을 제시할 수 있을 것이다.본 교과목은 독립적이면서 관계적 주제를 통해 연쇄적 질문과 딜레마를 통해 대학생의 정체성 탐색을 제안했다는 점에서 다른 교과목들과 차별화된다.﻿본 교과목을 통해대학생 자신의 정체성 탐색과 함께 ‘사람의 인문학’ 혹은 ‘트랜스 인문학’의 가치를공유하길 기대해 본다.","This study focused on ‘Deep Thinking’ among human abilities that differentiate artificial intelligence’s ‘deep learning’ ability in the era of the fourth industrial revolution, and proposed <the Classic Reading and Dialogic Imagination> as a way to develop ‘Deep Thinking’ abilities. The core message of this subject is that thinking humans will remain the leaders of the artificial intelligence era, and the source of thinking power lies in classics. It was intended to cultivate culture and character through the process of reading-discussion-writing by selecting ideas that fit the life cycle of college students. This subject is the selection of topics according to the life cycle of college students and the selection of appropriate classical texts; the independent and relational serialization of each subject. Through this course, we want to share the value of ‘human humanities’ or ‘trans humanities’ along with the search for the identity of college students through classical reading in the age of artificial intelligence."
머신러닝 기법을 이용한 미계측 유역에 적용 가능한 지역화 유황곡선 산정,2021,"['DNN', '머신러닝', '유황곡선', '미계측', '유역특성인자', 'DNN', 'Machine learning', 'Flow duration curve (FDC)', 'Ungauged', 'Watershed characteristic factor']","Low flow는 하천수의 공급관리 및 계획, 관개용수 등 다양한 분야에 영향을 미친다. 이러한 유황곡선을 산정하기 위해서는 30년 이상의 충분한 기간의 유량자료의 확보가 필수적이다. 하지만 국가하천 단위 이하의 하천의 경우 장기간의 유량자료가 없거나 중간에 일정기간 동안 결측된 관측소가 있어 하천별 유황 곡선을 산정하기에 한계가 있다. 이에 과거에는 미계측 유역의 유황을 예측하기 위해 다중회귀분석(Multiple Regression Analysis), ARIMA 모형 등 통계학적 기반의 기법들을 사용하였지만, 최근에는 머신러닝, 딥러닝 모형의 수요가 증가하고 있다. 이에 본 연구에서는 최신 패러다임에 맞는 머신러닝 기법인 DNN기법을 제시한다. DNN기법은 ANN기법의 단점인 학습과정에서 최적 매개변수 값을 찾기 어렵고, 학습시간이 느린 단점을 보완한 방법이다. 따라서 본연구에서는 DNN 모형을 이용하여 미계측 유역에 적용 가능한 유황곡선을 산정하고자 한다. 먼저, 유황곡선에 영향을 미치는 인자들을 수집하고 인자들 간의 다중공선성 분석을 통해 통계적으로 유의한 변수를 선정하여, 머신러닝 모형에 입력자료를 구축하였다. 통계적 검증을 통해 머신러닝 기법의 효용성을 검토하였다.","Low flow affects various fields such as river water supply management and planning, and irrigation water. A sufficient period of flow data is required to calculate the Flow Duration Curve. However, in order to calculate the Flow Duration Curve, it is essential to secure flow data for more than 30 years. However, in the case of rivers below the national river unit, there is no long-term flow data or there are observed data missing for a certain period in the middle, so there is a limit to calculating the Flow Duration Curve for each river. In the past, statistical-based methods such as Multiple Regression Analysis and ARIMA models were used to predict sulfur in the unmeasured watershed, but recently, the demand for machine learning and deep learning models is increasing. Therefore, in this study, we present the DNN technique, which is a machine learning technique that fits the latest paradigm. The DNN technique is a method that compensates for the shortcomings of the ANN technique, such as difficult to find optimal parameter values ​​in the learning process and slow learning time. Therefore, in this study, the Flow Duration Curve applicable to the unmeasured watershed is calculated using the DNN model. First, the factors affecting the Flow Duration Curve were collected and statistically significant variables were selected through multicollinearity analysis between the factors, and input data were built into the machine learning model. The effectiveness of machine learning techniques was reviewed through statistical verification."
말뚝지지력 예측을 위한 머신러닝 모델 연구,2021,"['Artificial Intelligence', 'Machine Learning', 'Pile Load Capacity', 'Random Forest', 'Gradient Boosting']","이론적, 경험적 방법으로 예측한 말뚝지지력은 현장 재하시험을 통해 신뢰도를 검증해야 한다. 하지만 일반적으로 말뚝재하시험은 비용이 많이 소요되므로 시험횟수에 제약이 따른다. 최근에는 말뚝지지력 예측의 보조수단으로서 머신러닝이나 딥러닝 등 인공지능 모델을 이용한 연구가 수행되고 있다. 인공지능 알고리즘, 개발플랫폼과 하드웨어, 데이터 등의 매우 빠른 변화와 발전을 감안하면 보다 명확하고 타당한 모델의 개발과 적용 가능성은 무한하다. 이 연구에서는 다음의 목적으로 말뚝 지지력 추정을 위한 선형회귀 및 결정트리 알고리즘에 기반한 앙상블 머신러닝 모델들의 적용성을 평가하였다. 1) 오픈소스 파이선 플랫폼, 구글코랩, 쥬피터노트북 등 인공지능모델 개발을 위한 최신 개발 환경구축, 2) 말뚝지지력 예측을 위한 머신러닝 모델의 평가, 3) 말뚝기초 인공지능 모델 개발을 위한 기존 말뚝재하시험 데이터베이스 검토 및 활용, 4) 향후 말뚝기초의 침하, 하중-변위 추정까지 모델을 확장하기 위한 기반연구로서 수행하였다. 검토한 머신러닝모델들은 검증데이터셋트에 대해서 결정계수 0.5 이상의 점수로 말뚝지지력을 예측할 수 있는 것으로 평가되었다. 앙상블모델 중 말뚝지지력 예측 적합성이 높은 모델로서 그라디언트부스팅과 XG 부스팅 모델의 적용을 제안하였다. 향후 연구로서 과적합의 효율적 배제 방안, 적정한 하이퍼파라미터 결정, 추가 데이터 축적 등의 문제를 제안할 수 있었다.","Field pile load tests are essential to ensure the reliability of pile capacities determined using theoretical and empirical methods. However, the number of such tests is generally restricted due to their high cost. Recently, artificial intelligence (AI) models involving machine learning and deep learning are being developed as supplemental methods to estimate pile capacities. Clearer and more reliable models need to be developed on an ongoing basis, considering the rapid evolution of artificial intelligence algorithms, hardware and developing platforms, and data. The applicability of machine learning models using linear regression and decision tree ensemble algorithms to estimate pile bearing capacities were evaluated in this study for the following purposes: 1) building up the environment for developing artificial intelligence models, such as the open-source Python platform, Google Colab, Jupyter Notebook, etc., 2) evaluation of machine learning models for estimating a pile load capacity, 3) reviewing and utilizing the existing pile load test databases for developing AI models of pile foundations, 4) conducting base studies for the future extension of models for the estimation of the settlement and load-displacement of piles. The investigated machine learning models were found to estimate pile load capacities with scores in terms of the coefficient of determinant over 0.5. The most appropriate ensemble models for the pile load estimation were the gradient boosting and XB boosting models. Further studies could include subjects such as eliminating overfitting, deciding on the proper hyperparameters, and accumulating additional data."
머신러닝기반 간 경화증 진단을 위한 웹 서비스 개발,2021,"['DICOM', 'Medical Bigdata', 'Artificial Intelligence Training Platform', 'Machine Learning', 'Deep Learning', '의료용 디지털 영상 및 통신 표준', '의료빅데이터', '인공지능 학습 플랫폼', '머신러닝', '딥러닝']",,"In the medical field, disease diagnosis and prediction research using artificial intelligence technology is being actively conducted. It is being released as a variety of products for disease diagnosis and prediction, which are most widely used in the application of artificial intelligence technology based on medical images. Artificial intelligence is being applied to diagnose diseases, to classify diseases into benign and malignant, and to separate disease regions for use in identification or reading according to the risk of disease. Recently, in connection with cloud technology, its utility as a service product is increasing. Among the diseases dealt with in this paper, liver disease is a disease with very high risk because it is difficult to diagnose early due to the lack of pain. Artificial intelligence technology was introduced based on medical images as a non-invasive diagnostic method for diagnosing these diseases. We describe the development of a web service to help the most meaningful clinical reading of liver cirrhosis patients. Then, it shows the web service process and shows the operation screen of each process and the final result screen. It is expected that the proposed service will be able to diagnose liver cirrhosis at an early stage and help patients recover through rapid treatment."
머신러닝을 이용한 학업중단 위기학생 관리시스템의 설계,2021,"['딥러닝', '머신러닝', '다변수 분석', '학업 중단', '학생 관리 시스템', 'Deep Learning', 'Machine Learning', 'Multivariable Analysis', 'School Dropout', 'Student Management System']",학업을 중단하는 학생들의 비율이 해마다 증가하고 있어 대학은 학업중단을 막기 위하여 위험요소를 파악하고 이를 사전에 제거하기 위해 노력하고 있다. 그러나 특정 위험요소의 단변수 분석을 통해 위기학생을 관리하고 있어 예측이 부정확한 문제가 발생하고 있다. 본 연구에서는 이러한 문제점을 해결하기 위하여 학업중단 위험요소를 파악하고 학업중단 예측을 위해 머신러닝 방법을 통해 다변수 분석을 실시한다. 또한 다양한 예측방법별로 성능평가를 수행하여 최적화 방법을 도출하고 학업중단을 발생시키는 위험요소간의 연관성과 기여도를 평가한다.,"The proportion of students dropping out of universities is increasing year by year, and they are trying to identify risk factors and eliminate them in advance to prevent dropouts. However, there is a problem in the management of students at risk of dropping out and the forecast is inaccurate because crisis students are managed through the univariable analysis of specific risk factors. In this paper, we identify risk factors for university dropout and analyze multivariables through machine learning method to predict university dropout. In addition, we derive the optimization method by evaluation performance for various prediction methods and evaluate the correlation and contribution between risk factors that cause university dropout."
Evaluation of the Usefulness of Detection of Abdominal CT Kidney and Vertebrae using Deep Learning,2021,"['Computed Tomography', '장기', '딥러닝', 'YOLOv3', '객체 검출', 'Computed Tomography', 'Organ', 'Deep learning', 'YOLOv3', 'Object detection']","전산화단층촬영은 질병 진단 등 의료분야에 중요한 역할을 담당하고 있지만, 검사 건수 및 검사 별 영상 증가가 지속되고 있다. 최근 의료분야에 딥러닝 이용이 활발히 이루어지고 있으며, 의료영상을 이용한 딥러닝 중 객체 검출을 통해 보조적 질병 진단에 활용되고 있다. 본 연구는 객체 검출 딥러닝 중 YOLOv3 모델을 이용하여 복부 CT 중 콩팥과 척추를 검출하여 정확도를 평가하고자 한다. 연구 결과 콩팥과 척추의 검출 정확도는 83.00%와 82.45% 였으며, 이를 통해 딥러닝을 이용한 의료영상 객체 검출에 대한 기초자료로 활용될 수 있을 것이라 사료된다.","CT is important role in the medical field, such as disease diagnosis, but the number of examination and CT images are increasing. Recently, deep learning has been actively used in the medical field, and it has been used to diagnose auxiliary disease through object detection during deep learning using medical images. The purpose of study to evaluate accuracy by detecting kidney and vertebrae during abdominal CT using object detection deep learning in YOLOv3. As a results of the study, the detection accuracy of the kidney and vertebrae was 83.00%, 82.45%, and can be used as basic data for the object detection of medical images using deep learning."
기계학습을 위한 색 추적 기반 데이터셋 구축 자동화 기법,2021,"['딥러닝', '데이터셋', '훈련 도구', '꽃 이미지', 'deeplearning', 'data set', 'training tool', 'flower image']","기계학습을 통한 문제 해결을 위한 단계에서 가장 중요한 부분 중의 하나가 데이터셋을 구축하는 것이다. 기존의 데 이터셋 구축 방법은 트레이닝 과정에서 소량의 이미지에 변화를 주어 데이터를 부풀리는 명령어를 사용하는 것과 ‘google 이미지 검색’에서 이미지 크롤링을 사용하는 것이 대부분이다. 하지만 이러한 방법들은 데이터로서 이미지 의 신뢰성이 보장되어 있지 않는 경우가 자주 발생한다. 기계학습 중 딥러닝 트레이닝을 위해서는 신뢰성이 보장된 데이터셋이 구축되어야 한다. 이에 따라 본 연구에서는 신뢰성을 보장받을 수 있는 데이터셋을 구축하기 위한 도구 를 설계 및 구현한다. 적은 노력으로 큰 데이터셋을 구축할 수 있는 방안을 고려하고, 그 방안을 통해 구축된 데이터 셋의 신뢰성을 테스트한다. 신뢰성을 보증하기 위한 예시로 꽃 이미지 데이터셋을 구축하여 ‘이미지 검색 꽃 사전’에 적용한다. 적용 결과로, 사용자는 딥러닝 트레이닝 과정에서 필요한 데이터셋을 보다 쉽고 경제적으로 구축할 수 있 고, 구축된 데이터셋을 통한 트레이닝에서의 신뢰성과 효율성이 있음을 보인다. 또한 본 연구의 아이디어를 기본으 로 활용한다면, 데이터셋을 구축하고자 하는 대상의 특성이 변하더라도 대량의 이미지 데이터셋을 생산할 수 있을 것이다.","One of the most important steps for solving problems through machine learning is to build a data set. Most previous methods of the data set generation are using commands to inflate data by changing small amounts of images during training, and image crawling in Google Image Search. However, these methods often do not guarantee the reliability of the image as data. For deeplearning training among methods of machine learning, a reliable data set must be established. Accordingly, in this study, a novel tool is designed and implemented to build a data set that can ensure reliability. We propose ways to build large data sets with little effort, and test the reliability of data sets built through them. As an example to ensure reliability, a set of flower image data is established and applied to ‘image search flower dictionary’. As a result, users can more easily and cost-effectively build the data sets needed in the deep-learning training process, and ensure reliability and efficiency in training through the generated data set. In addition, the underlying use of the ideas proposed in this study will enable the production of large sets of image data, even if the characteristics of the target to build the data set will be changed."
ConvLSTM-Based COVID-19 Outbreak Prediction using Feature Combination of Multivariate Dataset,2021,"['딥러닝', '시공간 데이터', 'deep learning', 'ConvLSTM', 'spatiotemporal dataset', 'COVID-19']",,
ELMo 임베딩 기반 문장 중요도를 고려한 중심 문장 추출방법,2021,"['추출 요약', '중심 문장', '문장 중요도', '중심 문장 특성', '임베딩', 'Extractive Summarization', 'Topic Sentence', 'Sentence Importance', 'Topic Sentence Feature', 'Embedding']","본 연구는 뉴스 기사에서 기사문을 구성하는 문장별 중요도를 고려하여 요약문을 추출하는 방법에 관한 것으로 문장 중요도에 영향을 주는 특성으로 중심 문장(Topic Sentence)일 확률, 기사 제목 및 다른 문장과의 유사도, 문장 위치에 따른 가중치를 추출하여 문장 중요도를 계산하는 방법을 제안한다. 이때, 중심 문장(Topic Sentence)은 일반 문장과는 구별되는 특징을 가질 것이라는 가설을 세우고, 딥러닝 기반 분류 모델을 학습시켜 입력 문장에 대한 중심 문장 확률값을 구한다. 또한 사전학습된 ELMo 언어 모델을 활용하여 문맥 정보를 반영한 문장 벡터값을 기준으로 문장간 유사도를 계산하여 문장 특성으로 추출한다. LSTM 및 BERT 모델의 중심 문장 분류성능은 정확도 93%, 재현율 96.22%, 정밀도 89.5%로 높은 분석 결과가 나왔으며, 이렇게 추출된 문장 특성을 결합하여 문장별 중요도를 계산한 결과, 기존 TextRank 알고리즘과 비교하여 중심 문장 추출 성능이 10% 정도 개선된 것을 확인할 수 있었다.","This study is about a method of extracting a summary from a news article in consideration of the importance of each sentence constituting the article. We propose a method of calculating sentence importance by extracting the probabilities of topic sentence, similarity with article title and other sentences, and sentence position as characteristics that affect sentence importance. At this time, a hypothesis is established that the Topic Sentence will have a characteristic distinct from the general sentence, and a deep learning-based classification model is trained to obtain a topic sentence probability value for the input sentence. Also, using the pre-learned ELMo language model, the similarity between sentences is calculated based on the sentence vector value reflecting the context information and extracted as sentence characteristics. The topic sentence classification performance of the LSTM and BERT models was 93% accurate, 96.22% recall, and 89.5% precision, resulting in high analysis results. As a result of calculating the importance of each sentence by combining the extracted sentence characteristics, it was confirmed that the performance of extracting the topic sentence was improved by about 10% compared to the existing TextRank algorithm."
이미지 보정을 통한 야간의 유해 동물 인식률 향상,2021,"['Deep-Learning', 'Harmful animal', 'Image Processing', 'Image Calibration']",,
빅데이터 분석기법을 활용한 숙박업체 운영 개선 방안에 대한 연구,2021,"['빅데이터', '데이터마이닝', '비정형데이터', '필터링', '공실률', 'Big Data', 'Data Mining', 'Unstructured Data', 'Filtering', 'Vacant Ratio']","빅데이터의 장점은 인터넷상의 대량의 데이터를 수집하여 가치 있는 데이터를 정제하여 사용하는 것이다. 즉, 비정형 데이터를 사용자가 필요한 관점에서 분석하여 활용할 수 있도록 가공하는 것이다. 본 논문은 실생활에 밀접하 게 적용되어 마케팅에 활용할 수 있는 비정형 데이터를 기반으로 하며 실험 대상은 서울에서 한 시간 거리의 수도권 에 있는 숙박업체를 모델로 하여 빅데이터를 사용자가 필요한 관점에서 분석하여 매출 증대, 비용 감소 및 수익률 증 가 등의 효과를 나타낸 실험으로 소셜네트워크 등의 빅데이터를 분석하는 과정에서 입력되는 데이터가 숙박 정보로 써 활용할 수 있는 데이터인지를 판별하여 필터링하는 시스템을 제안하여 숙박률의 향상 및 공실률을 감소시킬 수 있는 마케팅 전략을 구축하고자 한다.","The advantage of big data is to collect a large amount of data on the Internet and refine and use valuable data. That is, the unstructured data is processed so that the user can analyze and utilize it from a necessary point of view. This paper is a relatively small project and is based on unstructured data that can be closely applied to real life and used for marketing. The subjects of the experiment were modeled on lodging companies in the Seoul metropolitan area an hour away from Seoul, and analyzed for the increase in lodging rates before and after marketing using big data. As an experiment that shows the effects of increasing sales, reducing costs, and increasing returns by users, we propose a system to determine and filter whether data input in the process of analyzing big data such as social networks can be used as accommodation-related information."
개인별 생활 루틴을 반영한 초개인화 추천 시스템,2021,"['초개인화', 'OTT 서비스', '미디어 패널', 'BSR 방법', '와이드 앤 딥러닝', 'Hyper-personalization', 'OTT service', 'media panel', 'BSR method', 'wide and deep learning']","초개인화 추천 시스템은 과거 구매기록과 평점 등을 활용하여 추천하는 서비스인 ‘개인화’를 넘어서 소비자가 처한 상황과 맥락까지도 반영하는 시스템이다. 각자의 취향을 존중하는 취향의 시대로 접어들고 코로나19의 여파로 집에 있는 시간이 늘어 소비의 중심이 오프라인에서 온라인으로 전환되고 있기 때문에 다양한 연령대의 고객층을 만족시켜 소비를 유도하기 위한 초개인화 추천 시스템은 더욱더 중요한 역할을 할 것이다. OTT 서비스는 포스트 코로나 시대가 지속되면서 성장한 대표적인 산업 중 하나이고, 어느 디바이스에서도 접속 가능한 쉬운 접근성으로 이용자 수가 늘어나 비대면 문화를 이끌어가고 있다. 본 연구의 목적은 유료 OTT 서비스를 추천받고 싶어하는 소비자들에게 초개인화 추천 시스템을 사용하여 소비자들의 성향에 맞는 최적의 OTT 서비스를 추천해주는 것이다. 이를 위해, 한국미디어패널조사 데이터의 개인의 특성을 알 수 있는 개인 데이터와 초개인화 추천을 위한 개인의 생활 루틴을 알 수 있는 다이어리 데이터를 사용하여 데이터를 구축하였다. 본 연구는 개인의 성향과 특성을 잘 파악하기 위해 BSR 방법을 이용하여 유의한 변수를 선택하였고, 선택된 유의한 변수만을 사용하여 와이드 앤 딥러닝 추천 알고리즘에 적용한 추천 시스템을 제안한다. 전체 변수를 적용한 결과와 정확도를 비교해 본 결과, BSR 방법을 사용한 추천 알고리즘의 결과가 더 좋은 것으로 확인되었다.","Hyper-personalization recommender system (HPRS) is a system providing a service that reflects the situation and context of consumers, in addition to past purchase records and ratings. As the center of consumption is shifting from offline to online due to COVID-19, HPRS to satisfy customers of various ages is playing an important role. The OTT service is one of the representative industries that have grown as the post-COVID-19 era continues and lead to a non-face-to-face culture. The purpose of this study is to recommend optimal OTT services tailored to consumers preferences by using a HPRS to consumers who want to be recommended for paid OTT services. To this end, we use Korean media panel survey data constructed using personal data with the characteristics of individuals and diary data with individual life routines. This study selects significant variables using the BSR method to grasp individual characteristics, and proposes a recommender system applied to a wide & deep learning algorithmin using selected significant variables. The numerical results indicate that the proposed method produces much more accurate prediction than the method including all variables."
어텐션 메커니즘 기반 Long-Short Term Memory Network를 이용한 EEG 신호 기반의 감정 분류 기법,2021,"['EEG', '감정 분류', 'Long-Short Term Memory Network', '어텐션 메커니즘', 'Emotion classification', 'Attention mechanism']","본 연구에서는 EEG 신호를 기반으로 감정 인식에 유용한 딥러닝 기법을 제안한다. 감정이 시간에 따라 변화하는 특성을 반영하기 위해 Long-Short Term Memory 네트워크를 사용하였다. 또한, 특정 시점의 감정적 상태가 전체 감정 상태에 영향을 미친다는 이론을 기반으로 특정 순간의 감정 상태에 가중치를 주기 위해 어텐션 메커니즘을 적용했다. EEG 신호는 DEAP 데이터베이스를 사용하였으며, 감정은 긍정과 부정의 정도를 나타내는 정서가(Valence)와 감정의 정도를 나타내는 각성(Arousal) 모델을 사용하였다. 실험 결과 정서가(Valence)와 각성(Arousal)을 2단계(낮음, 높음)로 나누었을 때 분석 정확도는 정서가(Valence)의 경우 90.1%, 각성(Arousal)의 경우 88.1%이다. 낮음, 중간, 높음의 3단계로 감정을 구분한 경우 정서가(Valence)는 83.5%, 각성(Arousal)은 82.5%의 정확도를 보였다.","This study proposed a Long-Short Term Memory network to consider changes in emotion over time, and applied an attention mechanism to give weights to the emotion states that appear at specific moments. We used 32 channel EEG data from DEAP database. A 2-level classification (Low and High) experiment and a 3-level classification experiment (Low, Middle, and High) were performed on Valence and Arousal emotion model. As a result, accuracy of the 2-level classification experiment was 90.1% for Valence and 88.1% for Arousal. The accuracy of 3-level classification was 83.5% for Valence and 82.5% for Arousal."
다수 가전기기 유효전력의 스팩토그램 분석 및 LSTM기반의 전력 분해 알고리즘,2021,"['에너지 분해', '비침입 부하 모니터링(NILM)', 'LSTM', '스마트 그리드 시스템', '스팩토그램', 'Energy disaggregation', 'NILM(Non-Intrusive Load Monitoring)', 'LSTM', 'Smart Grid System', 'Spectogram']","본 연구에서는 가전기기 5종에 대해 실제 측정 전력 데이터를 이용하여 딥러닝 기반의 NILM 기법을 제안하고 그 효용성을 검증 하고자 한다. 약 3주간 중앙 전력 측정 장치 및 5종 가전기기(냉장고, 인덕션, TV, 세탁기, 공기청정 기)의 유효전력을 개별 측정하였다. 실측 데이터의 전처리 방법을 소개하고 Spectogram 분석을 통해 가전 기기별 특징 을 분석하였다. 가전기기별 특징을 학습 데이터셋으로 구성하였다. 중앙 전력 측정 기기와 가전기기 5종에서 측정된 모든 전력 데이터를 시계열 매핑하여 시계열 데이터 분석에 우수한 RNN 계열의 LSTM 신경망을 이용해 학습을 수행하 였다. 메인 중앙 전력 측정 장치의 전력 데이터만으로도 5종 전력 신호를 분해해낼 수 있는 알고리즘을 제안하였다.","In this study, we propose a deep learning-based NILM technique using actual measured power data for 5 kinds of home appliances and verify its effectiveness. For about 3 weeks, the active power of the central power measuring device and five kinds of home appliances (refrigerator, induction, TV, washing machine, air cleaner) was individually measured. The preprocessing method of the measured data was introduced, and characteristics of each household appliance were analyzed through spectogram analysis. The characteristics of each household appliance are organized into a learning data set. All the power data measured by the central power measuring device and 5 kinds of home appliances were time-series mapping, and training was performed using a LSTM neural network, which is excellent for time series data prediction. An algorithm that can disaggregate five types of energies using only the power data of the main central power measuring device is proposed."
지능형 교통 시스템을 위한 Graph Neural Networks 기반 교통 속도 예측,2021,"['지능형 교통 시스템', '교통 속도 예측', 'Graph Neural Network', 'Jensen-Shannon divergence', '스펙트럴 클러스터링', 'Intelligent transport systems', 'Traffic forecasting', 'Graph neural network', 'Jensen- Shannon divergence', 'Spectral clustering']",,
시멘틱 궤적과 GRU 모델을 활용한 개별 관광객의 다음 목적지 예측 모델링,2021,"['위치기반 SNS', '시멘틱 궤적', '개별 관광객', '다음 목적지 예측', 'GRU 모델', 'LBSNS', 'Semantic Trajectory', 'Individual Tourists', 'Next Destination Prediction', 'GRU Model']","위치기반 소셜 네트워크 서비스(location based social network service, LBSNS)는 사진, 텍스트 등 다양한 맥락을 내포하는 시멘틱 궤적으로 활용될 수 있다. 최근 연구되는 딥러닝을 활용한 다음 목적지 예측연구에서 맥락정보의 중요성을 인식하고 이를 반영한 모델을 구축하기는 하였지만 다양한 맥락정보를 하나로 결합하여 학습하지는 않고 있다. 본 연구의 목적은 이동 예측에 영향을 미치는 시멘틱 정보를 규정하고, 시멘틱 궤적 데이터를 구축한 후, 이에 기반하여 관광객의 다음 목적지를 예측하는 모델을 구축하는 것이다. 본 연구에서는 관광객의 다음 목적지에 영향을 미치는 시멘틱 정보로 시공간 정보, 관광지별 맥락정보, 관광객이 게시한 사진을 통한 관광객 유형 정보 등을 구축하고, gated recurrent unit(GRU)를 활용한 다음 목적지 예측모델을 구축하였다. 구축된 모델은 top 1 정확도 0.703, top 5 정확도 0.802, f1-score 0.577의 성능을 나타냈다. 학문적 측면에서 관광객의 다음 목적지에 영향을 미치는 시공간 규칙성, 관광지별 맥락정보, 관광객의 개인적 선호도 요인의 복합적인 상호 작용을 고려하였으며, 궤적의 여러 정보를 하나의 궤적 속성으로 모델에 반영하였다는 점에서 의의가 있다. 사회·경제적 측면에서는 관광객의 다음 목적지 예측모델을 통해 관광객이 이동할 도착지를 확인함으로써 관광객 서비스를 적절한 장소에 사전에 제공할 수 있다는 점에서 가치가 있다.","Location based social networking service (LBSNS) can be used as a semantic trajectory that includes various contexts such as photos and texts. Although the recent study of deep learning has been used to recognize the importance of contextual information in destination prediction research and to build a model that reflects it, it does not learn by combining various contextual information into one. The purpose of this study is to define semantic information that affects movement prediction, construct semantic trajectory data, and build a deep learning model to predict the tourist""s next destination. In this study, we built a model for predicting tourists"" next tourist destination using GRU in consideration of the complex interaction of the spatio-temporal regularity, contextual information by tourist destination, and personal preferences of the tourist. The performance of the final model is top 1 accuracy 0.703, top 5 accuracy 0.802, and f1-score 0.577. From an academic point of view, it is significant in that it considered the complex interaction of the spatio-temporal regularity, contextual information by tourist, and personal preference factors affecting tourists"" next destination, and reflected various information of trajectories in the model as one trajectory attribute. In terms of social and economic aspects, it is valuable in that tourist services can be provided in advance to appropriate places by identifying the destination where tourists will move through the next destination prediction model."
이항 분류 모델링을 적용한 실시간 낙상 예측 데이터 분석,2021,"['낙상 예측', '이항 분류', '아담 함수', '온도 센서', '심박 센서', '모션 센서', 'Fall prediction', 'Binary classification', 'Adam function', 'Temperature sensor', 'Heart rate  sensor', 'Motion sensor']",,
가변적인 블록 기반의 모자이크 생성과 적용,2021,"['Block Size', 'Mosaic', 'Object Protection', 'Computer Vision', 'Face Detection']","초고속의 컬러 영상 콘텐츠로부터 개인 정보가 노출된 사람의 얼굴 영역들을 블록 단위의 모자이크를 기반으로 자연스럽게 블로킹하는 작업은 상당히 어려운 일이다. 본 논문에서는 입력 받은 고속의 영상에서 사적인 정보를 대표하는 얼굴 영역을 가변적인 크기의 모자이크를 적용하여 효과적으로 블로킹하는 알고리즘을 기술한다. 본 논문에서는 우선 입력 받은 컬러 영상 데이터로부터 중요 특징 기반의 모델을 이용하여 얼굴 영역을 추출한다. 그런 다음, 크기 가변적인 블록 기반의 모자이크를 생성하여 이전 단계에서 추출된 얼굴 영역을 자연스럽게 블로킹한다. 실험 결과는 본 논문에서 소개한 접근 방법이 입력되는 다양한 고속의 영상 데이터로부터 가변 블록 기반의 모자이크를 통해 목표 영역을 효과적으로 블로킹한다는 것을 보여준다. 본 논문에서 소개된 가변 블록 모자이크 기반의 목표 영역 블로킹 접근 방법은 자동차의 안전 운전, 지능형 상호작용, 신원 확인, 그리고 모바일 소셜 네트워크와 같은 형태 인식과 관련 있는 실제적인 응용분야에서 중요한 기술로 유용하게 사용될 것으로 기대된다.","It is quite difficult to naturally block the face region of a person whose personal information is exposed in a high-speed color image content, based on a block-based mosaic. In this paper, we describe an algorithm that effectively blocks the face region representing private information in a high-speed image by applying a mosaic of variable size. As part of this research, the face region is first extracted from the color image data using a model, based on important features. Then, a block-based mosaic of variable size is generated to naturally block the face region extracted in the previous step. Experimental results show that this approach effectively blocks the target area through variable block-based mosaics in various high-speed image data. The variable size block-based mosaic target area blocking approach introduced in this paper is useful in practical applications related to pattern recognition such as safe driving of cars, intelligent interaction, identification, and mobile social networks."
오토인코더를 이용한 작업 데이터 정상 여부 판단 알고리즘,2021,"['autoencoder', 'reconstruction error', 'time series', 'deep learning', 'gas work']",본 연구에서는 오토인코더의 재구성 오류의 임계값을 이용하여 가스 시설에서의 작업이 정상 작업인지 비정상 작업인지를 판단하는 알고리즘을 구축하였다. 이 알고리즘은 정상 작업의 시계열 데이터만으로 오토 인코더를 학습하여 최적화된 정상 작업의 재구성 오류의 임계값을 도출한다. 이 알고리즘을 새로운 작업의 시계열 데이터에 적용하여 재구성 오류를 구한 다음 이것을 정상 작업의 재구성 오류 임계값과 비교하여 정상작업인지 비정상 작업인지를 판별한다. 이 알고리즘을 학습하고 검증하기 위해서 가상의 가스 시설에서의 작업을 규정하고 정상 작업 데이터로만 이루어진 학습 데이터 세트와 정상 작업과 비정상 작업 데이터를 모두 포함한 검증 데이터 세트를 구축하였다.,"In this study, we established an algorithm to determine whether the work in the gas facility is a normal work or an abnormal work using the threshold of the reconstruction error of the autoencoder. This algorithm do deep learning the autoencoder only with time-series data of a normal work, and derives the optimized threshold of the reconstruction error of the normal work. We applied this algorithm to the time series data of the new work to get the reconstruction error, and then compare it with the reconstruction error threshold of the normal work to determine whether the work is normal work or abnormal work. In order to train and validate this algorithm, we defined the work in a virtual gas facility, and constructed the training data set consisting only of normal work data and the validation data set including both normal work and abnormal work data."
혼합 2단계 합성 신경망을 이용한 단감 분류,2021,"['Deep Neural Network', 'Convolutional Neural Network Classifier', 'Persimmon Image Classification', 'Class Activation Mapping']",,
AI를 활용한 시추주상도 자동 디지털 DB화 방안에 관한 연구,2021,"['AI (Artificial Intelligence)', 'Automatic DB program', 'Boring log', 'Geotechnical information', 'Standard penetration test']",,
인터뷰 형식의 오디오 데이터를 이용한 전이 학습모델 기반 우울증 진단,2021,"['AI technology', 'Depression diagnosis', 'Transfer Learning', 'Interview-type audio data', 'two-dimensional images']",,"Depression can lead to serious mental and physical illness, so early detection is important. Currently, a system to help early detection of depression using AI technology is being developed in various ways. In particular, research on diagnosing depression through voices that can be easily encountered in daily life is being actively conducted. In this paper, we compare and analyze the depression diagnosis performance of transfer learning models using interview-type audio data. Data use the DAIC-WOZ Depression Database, which contains audio files in interview-type. As the transfer learning model, it uses VGGish and YAMNet built based on Convolutional Neural Network(CNN) among deep learning models that are widely being used for audio classification. The characteristics of speech data are extracted to black-and-white and color two-dimensional images using the Bark spectrogram, Mel spectrogram, and Log Mel-spectrogram methods. The performance of the depression diagnosis model is higher in YAMNet than in VGGish. In case that black-and-white images are input, YAMNet’s performance was the highest with 94.48% when mel spectrogram features were used.On the other hand, in case that color images are input, YAMNet’s performance was the highest at 97.34% when bark spectrogram features were used proving that it is most suitable for diagnosing depression."
"전기화재 원인분석을 위한 실험실 데이터를 활용한 1차, 2차 단락흔 및 열흔 판별용 CNN 알고리즘 설계",2021,"['Electrical fire', 'Arc beads', 'Molten mark', 'Convolution neural network']",,"In this paper, a new CNN algorithm is proposed to determine the direct cause of electric fires. We create 10,000-15,000 three types of data that can occur at a fire scene in our laboratory, and then train and verify it through the proposed CNN algorithm. As a result of the experiment and analysis, the classification accuracy of the primary and secondary arc beads was 86.2%, the accuracy of arc beads and molten marks was 93.6%. And also, the classification accuracy of the primary and secondary arc beads and molten marks was 92.4%. The results of this study are meaningful in that fire forensics can provide accurate identification results in a shorter time through artificial intelligence algorithms compared to the existing methods of identification through visual classification and physicochemical material analysis methods. In particular, the classification between primary and secondary arc beads is known to be a very difficult problem. However, the results of this study provided more than 86% classification ability."
4차 산업혁명 시대 스포츠의 사회・철학적 함의,2021,"['동작감지 시스템', '빅데이터', 'ICT 스포츠융합', 'Motion detection system', 'Big data', 'ICT sports convergence']","이 연구에서는 인공지능에 기반한 동작감지 시스템 훈련, 인공지능과 스포츠의 융합, 경기력 향상을 위한 빅데이 터에, ICT기술과 증강현상(VR, AR) 융합스포츠, 인공지능과 스포츠와의 대결 사례 등 4차 산업혁명 시대의 스포츠의 사회ㆍ철학적 함의를 탐색하였다. 이 연구의 시사점은 다음과 같다. 첫째. 스포츠 경기는 승패가 동등한 확률로 발생하는 상황도 많고, 사람이 하는 것이고, 선수의 컨디션 등 정량화할 수 없는 변수들이 많다. 이점이 인공지능이 기계학습이라는 데이터를 학습시켜서 예측을 하는 분야의 가장 큰 단점이고 따라서 너무 맹신하면 안 되는 것이다. 둘째, 인공지능의 혜택 을 보지 못하는 선수나 가난한 나라의 선수와의 경쟁은 공정한 경쟁이 아닐 것이다. 셋째, 로봇 심판의 출현으로 오심에 대한 논쟁과 심판판정에 대한 불복 사례는 줄어들고는 있지만, 한편에서는 로봇에게 일자리를 내주어서 실직자 수 가 많이 생길 것이라는 위기감도 생기고 있다. 넷째, 인간과 로봇의 대결에서 승패를 기준으로 한다면, 스포츠가 주는 감동은 사라지고 쾌감만 남게 될 것이다. 다섯째, 인공지능이 국민들에게 스포츠를 좀 더 편하고, 즐겁고, 친숙하게 받아들여서 건강에 도움이 될 수 있는 방향으로 가야 할 것이다. 여섯째, 인공지능은 인간의 예술적, 철학적 감동을 연출 할 수 없다는 것이 일반적인 학계의 주장이다. 스포츠에는 인간의 철학이 담겨 있다. 마음이 없는 인공지능은 그냥 스포츠의 부수적인 요소로 스포츠의 진정한 정신을 담지 못할 것이다.","In this study, artificial intelligence-based motion detection system training, artificial intelligence and sports fusion, big data for improving performance, ICT technology and augmented phenomena (VR, AR) fusion sports, artificial intelligence and sports competition, etc. The trend of the new paradigm of sports in the age of intelligence was explored. The implications of this study are as follows. first. In sports events, there are many situations in which wins or losses occur with equal probability, and there are many variables that cannot be quantified, such as a player's condition and a person playing it. This is the biggest drawback of the field where artificial intelligence makes predictions by learning data called machine learning, so you shouldn't be too blind. Second, competition with players from poor countries or players who do not benefit from artificial intelligence will not be fair competition. Third, with the advent of robot referees, controversy over misappropriation and cases of dissatisfaction with the referee's decision are decreasing, but there is also a sense of crisis that the number of unemployed people will be increased by giving up jobs to robots. Fourth, if the competition between humans and robots is based on win or loss, the emotions of sports will disappear and only pleasure will remain. Fifth, it is a general academic argument that artificial intelligence cannot direct human artistic and philosophical impressions. Sports contain human philosophy. Artificial intelligence without a mind is just a side element of sports and will not be able to contain the true spirit of sports."
신한복 커스터마이징 온라인 플랫폼에 적합한 의상 추천 알고리즘 연구,2021,"['추천 알고리즘', '신한복', 'Recommendation algorithm', 'New hanbok']",,
양자화 기반의 모델 압축을 이용한 ONNX 경량화,2021,"['CIFAR-10', 'Deep learning', 'MNIST', 'Memory Useage', 'ONNX', 'ONNXRuntime', 'Quantization', 'TFLite']","딥 러닝의 발전으로 다양한 AI 기반의 응용이 많아지고, 그 모델의 규모도 매우 커지고 있다. 그러나 임베디드 기기와 같이 자원이 제한적인 환경에서는 모델의 적용이 어렵거나 전력 부족 등의 문제가 존재한다. 이를 해결하기 위해 서 클라우드 기술 또는 오프로딩 기술을 활용하거나, 모델의 매개변수 개수를 줄이거나 계산을 최적화하는 등의 경량화 방법이 제안되었다. 본 논문에서는 다양한 프레임워크들의 상호 교환 포맷으로 사용되고 있는 ONNX(개방형 신경망 교환 포맷) 포맷에 딥러닝 경량화 방법 중 학습된 모델의 양자화를 적용한다. 경량화 전 모델과의 신경망 구조와 추론 성능을 비교하고, 양자화를 위한 다양한 모듈 방식를 분석한다. 실험을 통해 ONNX의 양자화 결과, 정확도는 차이가 거의 없으며 기존 모델보다 매개변수 크기가 압축되었으며 추론 시간 또한 전보다 최적화되었음을 알 수 있었다.","Due to the development of deep learning and AI, the scale of the model has grown, and it has been integrated into other fields to blend into our lives. However, in environments with limited resources such as embedded devices, it is exist difficult to apply the model and problems such as power shortages. To solve this, lightweight methods such as clouding or offloading technologies, reducing the number of parameters in the model, or optimising calculations are proposed. In this paper, quantization of learned models is applied to ONNX models used in various framework interchange formats, neural network structure and inference performance are compared with existing models, and various module methods for quantization are analyzed. Experiments show that the size of weight parameter is compressed and the inference time is more optimized than before compared to the original model."
Evaluation of Classification Performance of Inception V3 Algorithm for Chest X-ray Images of Patients with Cardiomegaly,2021,"['심장비대증', '인공지능', '딥 러닝', '흉부 X선 촬영영상', '분류', 'Cardiomegaly', 'Artificial Intelligence', 'Deep learning', 'Chest X-ray Image', 'Classification']","심장비대증은 흉부 X선 영상에서 흔히 보이는 질병 중 하나이지만 조기에 발견을 하지 못하면 심각한 합병증을 유발할 수도 있다. 이러한 점을 고려하여 최근에는 여러 과학기술 분야의 발전으로 인공지능을 이용한 딥러닝 알고리즘을 의료에 접목시키는 영상 분석 연구들이 많이 진행되고 있다. 본 논문에서는 Inception V3 딥러닝 모델을 흉부 X선 영상을 이용하여 심장비대증의 분류에 유용한 모델인지 평가하고자 한다. 사용된 영상의 경우 총 1026장의 경북대학교병원 내 정상 심장 진단을 받은 환자와 심장비대증 진단을 받은 환자의 흉부 X선 영상을 사용하였다. 실험결과 Inception V3 딥러닝 모델의 심장비대증 유무에 따른 분류 정확도와 손실도 결과값은 각각 96.0%, 0.22%의 결과값을 나타내었다. 연구결과를 통해 Inception V3 딥러닝 모델은 흉부 영상 데이터의 특징 추출 및 분류에 있어 우수한 딥러닝 모델인 것을 알 수 있었다. Inception V3 딥러닝 모델의 경우 흉부 질환의 분류에 있어 유용한 딥러닝 모델이 될 것으로 판단되며 조금 더 다양한 의료 영상 데이터를 이용한 연구를 진행하여 이와 같은 우수한 연구결과를 얻게 된다면 향후 임상의의 진단 시 많은 도움을 줄 수 있을 것으로 사료된다.","Cardiomegaly is one of the most common diseases seen on chest X-rays, but if it is not detected early, it can cause serious complications. In view of this, in recent years, many researches on image analysis in which deep learning algorithms using artificial intelligence are applied to medical care have been conducted with the development of various science and technology fields. In this paper, we would like to evaluate whether the Inception V3 deep learning model is a useful model for the classification of Cardiomegaly using chest X-ray images. For the images used, a total of 1026 chest X-ray images of patients diagnosed with normal heart and those diagnosed with Cardiomegaly in Kyungpook National University Hospital were used. As a result of the experiment, the classification accuracy and loss of the Inception V3 deep learning model according to the presence or absence of Cardiomegaly were 96.0% and 0.22%, respectively. From the research results, it was found that the Inception V3 deep learning model is an excellent deep learning model for feature extraction and classification of chest image data. The Inception V3 deep learning model is considered to be a useful deep learning model for classification of chest diseases, and if such excellent research results are obtained by conducting research using a little more variety of medical image data, I think it will be great help for doctor’s diagnosis in future."
VGGNet을 활용한 석재분류 인공지능 알고리즘 구현,2021,"['딥러닝', '미리 학습된 모델', '데이터 전처리', '케라스', '파이썬', 'DeepLearning', 'VGG16', 'Data Preprocessing', 'Keras', 'Python']","사진 이미지에서의 딥러닝 학습을 통한 이미지 분류는 지난 수년간 매우 활발한 연구 분야로 자리하고 있다. 본 논문에서는 국내산 석재 이미지로부터 딥러닝 학습을 통해 자동으로 석재를 판별하는 방법을 제안한다. 제안된 방법은 300x300픽셀의 황등석, 고흥석, 포천석의 사진 이미지들을 파이썬의 해시 라이브러리를 이용하여 석재별 중복된 이미지를 검사하고, 검사 결과로 해시값이 같은 중복된 이미지를 제거하여 석재별 딥러닝 학습이미지를 만드는 데이터 전처리 과정을 수행한다. 또한 미리 학습된 모델인 VGGNet을 활용하기 위해 학습된 이미지 사이즈인 224x224픽셀로 석재별 이미지들의 사이즈를 재조정하고, 학습데이터와 학습을 위한 검증데이터의 비율을 80% 대 20%로 나누어 딥러닝 학습을 수행한다. 딥러닝 학습을 수행한 후 손실 함수 그래프와 정확도 그래프를 출력하고 세 종류의 석재 이미지에 대해 딥러닝 학습 모델의 예측 결과를 출력하였다.","Image classification through deep learning on the image from photographs has been a very active research field for the past several years. In this paper, we propose a method of automatically discriminating stone images from domestic source through deep learning, which is to use Python s hash library to scan 300x300 pixel photo images of granites such as Hwangdeungseok, Goheungseok, and Pocheonseok, performing data preprocessing to create learning images by examining duplicate images for each stone, removing duplicate images with the same hash value as a result of the inspection, and deep learning by stone. In addition, to utilize VGGNet, the size of the images for each stone is resized to 224x224 pixels, learned in VGG16 where the ratio of training and verification data for learning is 80% versus 20%. After training of deep learning, the loss function graph and the accuracy graph were generated, and the prediction results of the deep learning model were output for the three kinds of stone images."
Accelerating a Deep Learning Application by Parallelization and Pipelining on Heterogeneous Processors,2021,"['딥 러닝', '이기종 프로세서', '파이프라이닝', '병렬화', 'deep learning', 'heterogeneous processors', 'pipelining', 'parallelization']","임베디드 시스템에서 딥 러닝 응용에 대한 필요가 증가함에 따라, 응용을 가속하는 데에 있어서 CPU가 아닌 처리 요소(processing element)를 임베디드 기기에 포함되고 있다. NVIDIA Jetson AGX Xavier는 대표적인 예제로 8-core CPU 뿐만 아니라 GPU와 2개의 딥러닝 가속기를 함께 갖고 있어서 자원이 제한된 환경에서 딥 러닝 응용의 성능을 끌어올리는 데에 활용된다. 임베디드 기기가 이기종처리 요소를 제공한다고 하여도, 이런 다양한 요소들을 함께 활용하여 성능을 올리는 것은 상당한 노력을 필요로 한다. 본 논문에서는 기존의 존재하는 여러 기법들과 우리가 제안하는 네트워크 파이프라이닝 기법을 함께 조합하여 이기종 처리요소를 가진 Xavier에서 딥 러닝 응용의 처리량을 최대화 하는 기법을 제안한다. 여러 개의 이미지 분류 예제와 사물 인식 예제를 통해 하나의 GPU를 사용하는 기존의 방법 대비 최대 355%까지 성능이 향상되는 것을 확인하였다.","Since the need of deep learning applications in embedded systems is increasing, non-CPU processing elements are equipped on an embedded device to accelerate those applications. NVIDIA Jetson AGX Xavier (Xavier) is a representative example which not only has an octa-core CPU, but also has one powerful GPU and two deep learning accelerators to enhance the performance of deep learning inference on resource-constrained environments. Although an embedded device provides heterogeneous processing elements, utilizing diverse computation units is burdensome to increase performance. In this paper, we proposed a technique that combines multiple existing methods and our proposed network pipelining method to maximize the throughput of deep learning applications. Our network pipelining method is made for utilizing heterogeneous processing elements on the Xavier. Results of experiments with image classification and object detection examples revealed up to 355% improvement compared to baseline Frames Per Second (FPS) with a single GPU."
Comparative Analysis by Batch Size when Diagnosing Pneumonia on Chest X-Ray Image using Xception Modeling,2021,"['딥러닝', '배치 사이즈', '폐렴', '폐렴 유무 자동진단', '흉부 X선 영상', 'Deep learning', 'batch size', 'pneumonia', 'Pneumonia', 'Automatic Diagnosis of Pneumonia', 'chest X-ray imaging']","흉부 X선 영상의 폐렴을 신속하고 정확하게 진단하기 위하여 동일한 Xception 딥러닝 모델에 배치 사이즈를 4, 8, 16, 32로 다르게 적용하여 각각 3회의 모델링을 실시하였다. 그리고 성능평가 및 metric 평가에 대한 결과값을 3회 평균값으로 산출하여 배치 사이즈별 흉부 X선 영상의 폐렴 특징 추출과 분류의 정확도 및 신속성을 비교 평가하였다. 딥러닝 모델링의 성능평가 결과 배치 사이즈 32를 적용한 모델링의 경우 정확도, 손실함수 값, 평균제곱오차, 1 epoch 당 학습 소요 시간의 결과가 가장 우수한 결과를 나타내었다. 그리고 Test Metric의 정확도 평가는 배치 사이즈 8을 적용한 모델링이 가장 우수한 결과를 나타내었으며, 정밀도 평가는 모든 배치 사이즈에서 우수한 결과를 나타내었다. 재현율 평가는 배치 사이즈 16을 적용한 모델링이 가장 우수한 결과를 나타내었으며, F1-score는 배치 사이즈 16을 적용한 모델링이 가장 우수한 결과를 나타내었다. 그리고 AUC score 평가는 모든 배치 사이즈의 결과가 동일하였다. 이러한 결과를 바탕으로 배치 사이즈 32를 적용한 딥러닝 모델링이 높은 정확도, 안정적인 인공신경망 학습 및 우수한 신속성의 결과를 나타내었다. 향후 딥러닝을 이용한 흉부 X선 영상의 폐렴에 대한 특징 추출 및 분류에 관하여 자동진단 연구 시 배치 사이즈를 32로 적용한다면 정확하면서도 신속한 병변 검출이 가능할 것이라고 사료된다.","In order to quickly and accurately diagnose pneumonia on a chest X-ray image, different batch sizes of 4, 8, 16, and 32 were applied to the same Xception deep learning model, and modeling was performed 3 times, respectively. As a result of the performance evaluation of deep learning modeling, in the case of modeling to which batch size 32 was applied, the results of accuracy, loss function value, mean square error, and learning time per epoch showed the best results. And in the accuracy evaluation of the Test Metric, the modeling applied with batch size 8 showed the best results, and the precision evaluation showed excellent results in all batch sizes. In the recall evaluation, modeling applied with batch size 16 showed the best results, and for F1-score, modeling applied with batch size 16 showed the best results. And the AUC score evaluation was the same for all batch sizes. Based on these results, deep learning modeling with batch size 32 showed high accuracy, stable artificial neural network learning, and excellent speed. It is thought that accurate and rapid lesion detection will be possible if a batch size of 32 is applied in an automatic diagnosis study for feature extraction and classification of pneumonia in chest X-ray images using deep learning in the future."
데이터 예측 클래스 기반 적대적 공격 탐지 및 분류 모델,2021,"['Adversarial Attack', 'Evasion Attack', 'Deep Learning', 'Adversarial Example Detection']","딥러닝 분류 모델에 대한 공격 중 하나인 적대적 공격은 입력 데이터에 인간이 구별할 수 없는 섭동을 추가하여 딥러닝 분류 모델이 잘못 분류하도록 만드는 공격이며, 다양한 적대적 공격 알고리즘이 존재한다. 이에 따라 적대적 데이터를 탐지하는 연구는 많이 진행되었으나 적대적 데이터가 어떤 적대적 공격 알고리즘에 의해 생성되었는지 분류하는 연구는 매우 적게 진행되었다. 적대적 공격을 분류할 수 있다면, 공격 간의 차이를 분석하여 더욱 견고한 딥러닝 분류 모델을 구축할 수 있을 것이다. 본 논문에서는 공격 대상 딥러닝 모델이 예측하는 클래스를 기반으로 은닉층의 출력값에서 특징을 추출하고 추출된 특징을 입력으로 하는 랜덤 포레스트 분류 모델을 구축하여 적대적 공격을 탐지 및 분류하는 모델을 제안한다. 실험 결과 제안한 모델은 최신의 적대적 공격 탐지 및 분류 모델보다 정상데이터의 경우 3.02%, 적대적 데이터의 경우 0.80% 높은 정확도를 보였으며, 기존 연구에서 분류하지 않았던 새로운 공격을 분류한다.","Adversarial attack, one of the attacks on deep learning classification model, is attack that add indistinguishable perturbations to input data and cause deep learning classification model to misclassify the input data. There are various adversarial attack algorithms. Accordingly, many studies have been conducted to detect adversarial attack but few studies have been conducted to classify what adversarial attack algorithms to generate adversarial input. if adversarial attacks can be classified, more robust deep learning classification model can be established by analyzing differences between attacks. In this paper, we proposed a model that detects and classifies adversarial attacks by constructing a random forest classification model with input features extracted from a target deep learning model. In feature extraction, feature is extracted from a output value of hidden layer based on class predicted by the target deep learning model. Through Experiments the model proposed has shown 3.02% accuracy on clean data, 0.80% accuracy on adversarial data higher than the result of pre-existing studies and classify new adversarial attack that was not classified in pre-existing studies."
단어 계층 기반 텍스트 데이터 증강 방법론,2021,"['Deep Learning', 'Generative Adversarial Network', 'Text to Image Synthesis', 'Data Augmentation', 'WordNet', '딥 러닝', '생성적 적대 신경망', '이미지 합성', '데이터 증강', '워드넷']","최근 딥 러닝(Deep Learning) 분석에 이질적인 데이터를 함께 사용하는 멀티모달(Multi-modal) 딥러닝 기술이 많이 활용되고 있으며, 특히 텍스트로부터 자동으로 이미지를 생성해내는 Text to Image 합성에 관한 연구가 활발하게 수행되고 있다. 이미지 합성을 위한 딥러닝 학습은 방대한 양의 이미지와 이미지를 설명하는 텍스트의 쌍으로 구성된 데이터를 필요로 하므로, 소량의 데이터로부터 다량의 데이터를 생성하기 위한 데이터 증강 기법이 고안되어 왔다. 텍스트 데이터 증강의 경우 유의어 대체에 기반을 둔 기법들이 다수 사용되고 있지만, 이들 기법은 명사 단어의 유의어 대체 시 이미지의 내용과 상이한 텍스트를 생성할 가능성이 있다는 한계를 갖는다. 따라서 본 연구에서는 단어가 갖는 품사별 특징을 활용하는 텍스트 데이터 증강 방안, 즉 일부 품사에 대해 단어 계층 정보를 활용하여 단어를 대체하는 방안을 제시하였다. 또한 제안 방법론의 성능을 평가하기 위해 MSCOCO 데이터를 사용하여 실험을 수행하여 결과를 제시하였다.","Recently, multi-modal deep learning techniques that combine heterogeneous data for deep learning analysis have been utilized a lot. In particular, studies on the synthesis of Text to Image that automatically generate images from text are being actively conducted. Deep learning for image synthesis requires a vast amount of data consisting of pairs of images and text describing the image. Therefore, various data augmentation techniques have been devised to generate a large amount of data from small data. A number of text augmentation techniques based on synonym replacement have been proposed so far. However, these techniques have a common limitation in that there is a possibility of generating a incorrect text from the content of an image when replacing the synonym for a noun word. In this study, we propose a text augmentation method to replace words using word hierarchy information for noun words. Additionally, we performed experiments using MSCOCO data in order to evaluate the performance of the proposed methodology."
Faster-RCNN을 이용한 열화상 이미지 처리 및 합성 기법,2021,"['이미지 합성', '딥러닝', '열화상 이미지', '이미지 처리', '이상 진단', 'Image Fusion', 'Deep Learning', 'Thermal Image', 'Image Processing', 'Abnormal Diagnosis']","본 논문에서는 열화상 이미지에서의 열 데이터 추출 및 해당 데이터를 사용한 발열 설비 탐지 향상 기법을 제안한다. 주요 목표는 열화상 이미지에서 바이트 단위로 데이터를 해석하여 열 데이터와 실화상 이미지를 추출하고 해당 이미지와 데이터를 합성한 합성 이미지를 딥러닝 모델에 적용하여 발열 설비의 탐지 정확도를 향상 시키는 것이다. 데이터는 한국수력원자력발전소 설비 데이터를 사용하였으며, 학습 모델로는 Faster-RCNN을 사용하여 각 데이터 그룹에 따른 딥러닝 탐지 성능을 비교 평가한다. 제안한 방식은 Average Precision 평가에서 기존 방식에 비해 평균 0.17 향상 되었다.본 연구는 이로서 국가 데이터 기반 열화상 데이터와 딥러닝 탐지의 접목을 시도하여 유효한 데이터 활용도 향상을 이루었다.","In this paper, we propose a method for extracting thermal data from thermal image and improving detection of heating equipment using the data. The main goal is to read the data in bytes from the thermal image file to extract the thermal data and the real image, and to apply the composite image obtained by synthesizing the image and data to the deep learning model to improve the detection accuracy of the heating facility. Data of KHNP was used for evaluation data, and Faster-RCNN is used as a learning model to compare and evaluate deep learning detection performance according to each data group. The proposed method improved on average by 0.17 compared to the existing method in average precision evaluation.As a result, this study attempted to combine national data-based thermal image data and deep learning detection to improve effective data utilization."
합성곱 신경망 모델을 이용한 진동 응답의 모드 기여도 추정,2021,"['Deep Learning(딥러닝)', 'Mode Participation Factor(모드 기여도 계수)', 'Convolutional Neural Network(합성곱 신경망)', 'Natural Mode(고유 모드)', 'Mode Superposition Method(모드 중첩법)']","본 연구에서는 모드 중첩법으로 표현된 구조물의 강제 진동 응답에서 각 고유 모드의 기여도를 합성곱 신경망 모델을 이용하여 추정하는 방법론을 제시하고, 외팔보에 적용하여 제시한 방법론의 유효성을 입증한다. 과도 응답이 사라진 후에 조화 가진력에 의한 구조물의 강제 진동 거동은 해당 구조물이 갖는 고유 모드들의 선형 조합으로 표현할 수 있다. 각 고유 모드의 기여도는 가진력의 주파수, 가진 위치와 크기의 분포 등에 따라 달라지기 때문에 기여도가 큰 몇 개의 고유 모드만 사용하여 강제 진동거동을 근사적으로 표현할 수 있다. 이런 기여도를 추정할 수 있는 딥러닝 모델을 제안하고, 알맞은 입력과 출력 데이터를 사용하여 딥러닝 모델을 학습시킨다. 학습이 완료된 딥러닝 모델은 높은 정확도를 갖는 것을 알 수 있었고, 이런 결과가 응용될 수 있는 분야를 살펴본다.","In this study, a method based on a convolutional neural network was proposed to estimate the participation factor of each vibration mode in forced vibration response, expressed by the mode superposition method, and the effectiveness of the method was validated by applying it to a cantilever beam. After the transient response decays out, the forced vibration behaviour of a structure due to a harmonic excitation force can be expressed as a linear combination of its vibration modes. Since the participation factor of each vibration mode varies depending on the frequency of the excitation force, its location, and distribution, only a few vibration modes with large participation factors can be used to approximate the forced vibration behaviour. To estimate this participation factor, a convolutional neural network model was trained using appropriate input and output data. The proposed and trained deep learning model showed high accuracy against test data. Furthermore, its areas of application were discussed."
CNN기반 상품분류 딥러닝모델을 위한 학습데이터 영향 실증 분석,2021,"['상품분류', 'CNN 모델', '딥러닝', '학습데이터', '사전처리', 'Product Classification', 'CNN Model', 'Deep Learning', 'Training Data', 'Preprocessing']","전자상거래에서 상품 정보에 따른 신속하고 정확한 자동 상품 분류는 중요하다. 최근의 딥러닝 기술 발전은 자동 상품 분류에도 적용이 시도되고 있다. 성능이 우수한 딥러닝 모델 개발에 있어, 학습 데이터의 품질과 모델에 적합한 데이터 전처리는 중요하다. 본 연구에서는, 텍스트 상품 데이터를 기반으로 카테고리를 자동 유추할 때, 데이터의 전처리 정도에 따른 영향력과 학습 데이터 선택 범위 영향력을 CNN모델을 사례 모델로 이용하여 비교 분석한다. 실험 분석에 사용한 데이터는 실제 데이터를 사용하여 연구 결과의 실증을 담보하였다. 본 연구가 도출한 실증 분석 및 결과는 딥러닝 상품 분류 모델 개발 시 성능 향상을 위한 레퍼런스로서 의의가 있다.","In e-commerce, rapid and accurate automatic product classification according to product information is important. Recent developments in deep learning technology have been actively applied to automatic product classification. In order to develop a deep learning model with good performance, the quality of training data and data preprocessing suitable for the model are crucial. In this study, when categories are inferred based on text product data using a deep learning model, both effects of the data preprocessing and of the selection of training data are extensively compared and analyzed. We employ our CNN model as an example of deep learning model. In the experimental analysis, we use a real e-commerce data to ensure the verification of the study results. The empirical analysis and results shown in this study may be meaningful as a reference study for improving performance when developing a deep learning product classification model."
Sequence to Sequence based LSTM (LSTM-s2s)모형을 이용한 댐유입량 예측에 대한 연구,2021,"['댐 유입량 예측', '딥러닝', 'LSTM with Sequence-to-Sequence learning', 'Dam inflow forecasting', 'Deep learning', 'LSTM with Sequence-to-Sequence learning']","효율적인 댐 운영을 위해서는 높은 신뢰도를 기반으로 하는 유입량 예측이 요구된다. 본 연구에서는 최근 다양한 분야에서 사용되고 있는 데이터 기반의 예측 방법 중 하나인 딥러닝을 댐 유입량 예측에 활용하였다. 그 중 시계열 자료 예측에 높은 성능을 보이는 Sequence-to-Sequence 구조 기반의 Long Short-Term Memory 딥러닝 모형(LSTM-s2s)을 이용하여 소양강 댐의 유입량을 예측하였다. 모형의 예측 성능을 평가하기 위해 상관계수, Nash–Sutcliffe 효율계수, 평균편차비율, 그리고 첨두값 오차를 이용하였다. 그 결과, LSTM-s2s 모형은 댐 유입량 예측에 대한 높은 정확도를 보였으며, 단일 유량 수문곡선 기반의 예측 성능에서도 높은 신뢰도를 보였다. 이를 통해 홍수기와 이수기에 수자원 관리를 위한 효율적인 댐 운영에 딥러닝 모형의 적용 가능성을 확인할 수 있었다.","Forecasting dam inflow based on high reliability is required for efficient dam operation. In this study, deep learning technique, which is one of the data-driven methods and has been used in many fields of research, was manipulated to predict the dam inflow. The Long Short-Term Memory deep learning with Sequence-to-Sequence model (LSTM-s2s), which provides high performance in predicting time-series data, was applied for forecasting inflow of Soyang River dam. Various statistical metrics or evaluation indicators, including correlation coefficient (CC), Nash-Sutcliffe efficiency coefficient (NSE), percent bias (PBIAS), and error in peak value (PE), were used to evaluate the predictive performance of the model. The result of this study presented that the LSTM-s2s model showed high accuracy in the prediction of dam inflow and also provided good performance for runoff event based runoff prediction. It was found that the deep learning based approach could be used for efficient dam operation for water resource management during wet and dry seasons."
Automatic Fracture Detection in CT Scan Images of Rocks Using Modified Faster R-CNN Deep-Learning Algorithm with Rotated Bounding Box,2021,"['Fracture detection', 'Computed tomography', 'Deep learning', 'Faster R-CNN', 'Rotated bounding box', '균열 탐지', '컴퓨터 단층촬영', '딥러닝 알고리즘', '회전 경계박스']","본 논문에서는 암석시료의 CT 촬영 이미지상의 균열을 자동으로 탐지하는 새로운 인공지능 딥러닝 기법을 제안한다. 본 제안 기법은 2단계 딥러닝 객체인식 알고르즘인 Faster R-CNN을 기반으로 회전 가능한 경계박스(bounding box) 개념을 도입하여 알고리즘을 개조하였다. 회전 경계박스의 도입은 관심 균열 영역 밖의 배경의 불균질성 및 균열의 크기와 형태에 영향을 받는 딥러닝 객체인식기법 상의 고유한 어려움을 극복하기 위한 핵심 역할을 한다. 본 회전형 경계박스의 사용은 일반적으로 사용되는 영상 수평 축과 평행한 경계박스 사용의 경우와 비교하여 긴 형태의 균열 형상 특성에 매우 잘 부합된다. 즉, 좋지 않은 영향을 끼치는 경계박스 내 균열 이외 배경영역의 비율을 최소화 시킬 수 있다. 이외에도, 회전 경계 박스의 추가적인 이점은 인식된 균열의 방향에 따라 회전하여 추론되는 경계박스를 통해 균열의 방향과 길이에 대한 정보를 직접적으로 얻을 수 있다. 본 제안기법의 적용성을 검증하기 위하여, 이미지상에서 매우 불균질한 화강암 시료에 인공적으로 균열을 발생시킨 다수의 암석시료 영상을 딥러닝 학습에 사용하고 추론 성능 실험을 진행하였다. 그 외에도, 동일 조건에서 사암과 셰일 암석 시료에도 적용하여 검증하였다. 결론적으로, 제안된 기법을 통해 균열 객체 인식의 평균 추론정확도(mAP)값이 0.89 정도 수준의 우수한 추론 성능을 보였으며, 기존 기법에 비해 추론된 경계박스 내 균열과 배경 영역의 비율 측면에 서 배경의 비율이 획기적으로 최소화되는 유리한 추론 검증 결과를 보였다.","In this study, we propose a new approach for automatic fracture detection in CT scan images of rock specimens. This approach is built on top of two-stage object detection deep learning algorithm called Faster R-CNN with a major modification of using rotated bounding box. The use of rotated bounding box plays a key role in the future work to overcome several inherent difficulties of fracture segmentation relating to the heterogeneity of uninterested background (i.e., minerals) and the variation in size and shape of fracture. Comparing to the commonly used bounding box (i.e., axis-align bounding box), rotated bounding box shows a greater adaptability to fit with the elongated shape of fracture, such that minimizing the ratio of background within the bounding box. Besides, an additional benefit of rotated bounding box is that it can provide relative information on the orientation and length of fracture without the further segmentation and measurement step. To validate the applicability of the proposed approach, we train and test our approach with a number of CT image sets of fractured granite specimens with highly heterogeneous background and other rocks such as sandstone and shale. The result demonstrates that our approach can lead to the encouraging results on fracture detection with the mean average precision (mAP) up to 0.89 and also outperform the conventional approach in terms of background-to-object ratio within the bounding box."
"LSTM을 이용한 주가 예측: 기술 지표, 거시 경제 지표, 시장 심리의 조합을 중심으로",2021,"['Artificial intelligence', 'Machine learning', 'Deep learning', 'LSTM', 'Stock price prediction']","주가 예측 시 가장 큰 장애 요인은 거시 환경 및 시장의 변동성이라 할 수 있겠다. 이론적으로 주가의 무작위성은 딥러닝 알고리즘으로 어느 정도 해소가 가능하지만, 주가를 둘러싼 거시 환경과 시장의 급변과 같은 외부 충격은 주가 예측을 어렵게 만드는 요인이며, 이를 어떻게 해소하는가 하는 것이 주가 예측의 관건이라 할 수 있겠다. 이에 전통적인 기술적 지표나 거시 경제 지표 뿐만 아니라, 시장에 충격을 주는 상황을 이해하기 위한 뉴스 정보나 투자자들의 심리를 반영하기 위해서 주식 종목 관련 단어검색, SNS 주식 커뮤니티에서의 감성 분석 등을 통하여 해결하고자 하는 추세이다. 따라서 본 연구의 목적은 주가에 영향을 미치는 내부 요소와 외부 요소들을 모두 이용하여, 주가 예측 요소의 조합을 통해 보다 높은 예측력을 만드는 딥러닝 모델을 찾는 것이다. 딥러닝 알고리즘으로는 시계열 데이터 학습에 적합한 LSTM을 사용하였으며, 딥러닝 실험 결과 예상대로 모든 종목에 적용할 수 있는 범용 모델은 찾을 수 없었지만, 업종이나 가격대 등에 따라 예측력을 높이는 조합이 존재하며, 현재 시점에서 먼 과거의 데이터보다는 최근의 데이터가 예측력을 높인다는 결과가 나왔다.","In predicting stock prices, the biggest obstacle is macro-environment and market volatility. Randomness of stock prices can be resolved to some extent with deep learning algorithms, but external impacts such as the macro-environment surrounding stock prices and rapid changes in the market are factors that make it difficult to predict stock prices, and how to resolve them is the key to the stock price prediction model. Existing stock price prediction research has often used technical indicators. Recently, macroeconomic indicators have also been taken into consideration, and in order to understand the market impact, news information or investor psychology is reflected. There is also a trend to analyze sentiment in the stock community. Therefore, the purpose of this study is to find a deep learning model that uses both internal and external factors that affect stock prices and creates higher predictive power through the inclusion of specific factors or combinations of factors. As a deep learning algorithm, LSTM suitable for time-series data learning was used. As a result of deep learning experiments, it does not seem possible to find a general-purpose model that can be applied to all stocks, but there are combinations of factors that increase the predictive power depending on the industry or price range, and results also shows that the recent data had better predictive power than the past data."
Balanced Attention Mechanism을 활용한 CG/VR 영상의 초해상화,2021,"['Attention mechanism', 'Super-resolution', 'CG/VR', 'BAM', 'Deep learning', '어텐션 메커니즘', '초해상화', 'CG/VR', 'BAM', '딥러닝']","어텐션(Attention) 메커니즘은 딥러닝 기술을 활용한 다양한 컴퓨터 비전 시스템에서 활용되고 있으며, 초해상화(Super-resolution)를 위한 딥러닝 모델에도 어텐션 메커니즘을 적용하고 있다. 하지만 어텐션 메커니즘이 적용된 대부분의 초해상화 기법들은 Real 영상의 초해상화에만 초점을 맞추어서 연구되어, 어텐션 메커니즘을 적용한 초해상화가 CG나 VR 영상 초해상화에도 유효한지는 알기 어렵다. 본 논문에서는 최근에 제안된 어텐션 메커니즘 모듈인 BAM(Balanced Attention Mechanism) 모듈을 12개의 초해상화 딥러닝 모델에 적용한 후, CG나 VR 영상에서도 성능 향상 효과를 보이는지 확인하는 실험을 진행하였다. 실험 결과, BAM 모듈은 제한적으로 CG나 VR 영상의 초해상화 성능 향상에 기여하였으며, 데이터 특징과 크기, 그리고 네트워크 종류에 따라 성능 향상도가 달라진다는 것을 확인할 수 있었다.","Attention mechanisms have been used in deep learning-based computer vision systems, including single image super-resolution (SISR) networks. However, existing SISR networks with attention mechanism focused on real image super-resolution, so it is hard to know whether they are available for CG or VR images. In this paper, we attempt to apply a recent attention module, called balanced attention mechanism (BAM) module, to 12 state-of-the-art SISR networks, and then check whether the BAM module can achieve performance improvement in CG or VR image super-resolution. In our experiments, it has been confirmed that the performance improvement in CG or VR image super-resolution is limited and depends on data characteristics, size, and network type."
유방촬영술에서 인공지능의 적용: 알고리즘 개발 및 평가 관점,2021,"['Mammography', 'Artificial Intelligence', 'Breast Cancer']","유방촬영술은 유방암 검진 및 진단을 위한 기본적인 영상 검사이지만, 판독이 어려우며 높은숙련도를 필요로 한다고 잘 알려져 있다. 이러한 어려움을 극복하기 위해 최근 몇 년 사이에인공지능을 이용한 유방암 검출 알고리즘들이 활발히 연구되고 있다. 본 종설에서 저자는 고전적인 computer-aided detection 소프트웨어 대비 최근 많이 사용되는 딥러닝의 특징을알아보고, 딥러닝 알고리즘의 개발 방법과 임상적 검증 방법에 대해서 기술하였다. 또한 딥러닝 기반의 검진 유방촬영술의 판독 방법 분류, 유방 치밀도 평가, 그리고 유방암 위험도 예측 모델 등을 위한 딥러닝 연구들도 소개하였다. 마지막으로 유방촬영술 관련 인공지능 기술들에 대한 영상의학과 전문의의 관심과 의견의 필요성을 기술하였다.","Mammography is the primary imaging modality for breast cancer detection; however, a high level of expertise is needed for its interpretation. To overcome this difficulty, artificial intelligence (AI) algorithms for breast cancer detection have recently been investigated. In this review, we describe the characteristics of AI algorithms compared to conventional computer-aided diagnosis software and share our thoughts on the best methods to develop and validate the algorithms. Additionally, several AI algorithms have introduced for triaging screening mammograms, breast density assessment, and prediction of breast cancer risk have been introduced.Finally, we emphasize the need for interest and guidance from radiologists regarding AI research in mammography, considering the possibility that AI will be introduced shortly into clinical practice."
인공지능 시대의 사전과 데이터 ‒ 한국역사인물사전(데이터)을 위한 탐색 ‒,2021,"['Digital Humanities', 'Dictionary', 'Data', 'Artificial Intelligence', 'Historical  Figures', '디지털인문학', '사전', '데이터', '인공지능', '역사인물']","본 논문은 인공지능 시대 사전의 미래는 인간을 위해서 컴퓨터가 이해할 수 있는 방식으로 여러 가지 사항을모아 일정한 순서로 배열하고 그 각각에 해설을 붙인 내용인 ‘기계가독형 데이터’에 있다고 판단했다. 사전학의데이터학으로의 전환 가능성을 타진하기 위해서, 인공지능 통합 플랫폼인 AIHUB에 공개된 레이블드 데이터, 병렬코퍼스(말뭉치) 데이터, 스쿼드 데이터의 구조와 내용의 장단점을 살펴보았다. 데이터 설계와 전문 도메인영역의 데이터 구축에서는 충분히 기존 사전학의 연구 성과를 계승할 수 있다고 판단했다. 그리고 딥러닝을 위한 데이터의 한계를 타파하기 위한 또 다른 인공지능 데이터인 시맨틱 데이터의 구조와 내용에 대해서 탐색했고, 기존 사전학의 연구 성과가 온톨로지 설계와 시맨틱 데이터 구축에서 충분히 활용될 수 있다고 판단했다.이를 토대로 실제적인 사례 연구를 위해서, 한국역사인물사전을 주제로 딥러닝을 위한 데이터와 온톨로지설계를 통한 시맨틱 데이터를 각각 실험적으로 구축했다. 우선 딥러닝의 객체명식별(NER) 방법을 활용하여, 조선왕조실록데이터를 토대로 하는 객체명식별(NER) 학습 데이터를 구축하고 실험했다. 딥러닝을 통한 객체명식별(NER)의 객체 식별이 객체의 속성만을 식별할 뿐, 객체의 고유성을 인지하지 못한다는 문제를 확인했다. 이에 객체의 시간, 공간, 인물 등과의 관계를 통한 다양한 고유성을 내재하고 있는 지식으로서의 시맨틱데이터를 구축하기 위한 실험적인 온톨로지 설계를 통해서 시맨틱 데이터의 가능성을 살펴보았다.결론적으로 전통적인 사전학에서 기계가독형 데이터에 대한 개념과 이해가 더해질 수 있다면 딥러닝을 위한 데이터와 온톨로지를 통한 시맨틱 데이터 모두에서 충분히 경쟁력이 있다고 본다.","This paper concludes that the future of the artificial intelligence era dictionary is in the ‘machine readable data’, which is a collection of various things in a way that computers can understand for human beings and arranged in a certain order and commentary on each of them.In order to explore the possibility of transition to the data of dictionary studies, researcher examined the advantages and disadvantages of labeled data, parallel corpus data, and squad data released on AIHUB, an artificial intelligence integration platform. In data design and data construction in the specialized domain area, it was decided that it could inherit the research results of existing dictionary studies. And researcher searched the structure and contents of semantic data, another artificial intelligence data to overcome the limitations of data for deep learning, and decided that the results of existing dictionaries could be fully utilized in ontology design and semantic data construction.Based on this, for practical case study, data for deep learning and semantic data through ontology design were experimentally constructed on the theme of Korean historical character dictionary. First, researcher constructed and experimented with the learning data of object name identification (NER) based on the annals data of the Joseon Dynasty using the object name identification (NER) method of deep learning. The problem that object identification of object name identification (NER) through deep learning only identifies the attribute of the object and does not recognize the uniqueness of the object is confirmed. Therefore, the possibility of semantic data was examined through experimental ontology design to build semantic data as knowledge that has various uniqueness through the relationship with the object’s time, space, and characters. In conclusion, if the concept and understanding of machine-readable data can be added in traditional dictionary studies, it is considered to be competitive enough in both deep learning data and semantic data through ontology."
인공신경망 기계번역에서 디코딩 전략에 대한 연구,2021,"['인공신경망 기계번역', '디코딩', '딥러닝', '빔 서치', '자연어 생성', '언어융합', 'Neural machine translation', 'Decoding', 'Deep learning', 'Beam search', 'Natural language generation', 'Language convergence']","딥러닝 모델을 활용한 인공신경망 기계번역 (Neural machine translation)이 주류 분야로 떠오르면서 최고의 성능을 위해 모델과 데이터 언어 쌍에 대한 많은 투자와 연구가 활발하게 진행되고 있다. 그러나, 최근 대부 분의 인공신경망 기계번역 연구들은 번역 문장의 품질을 극대화하는 자연어 생성을 위한 디코딩 전략 (Decoding strategy)에 대해서는 미래 연구 과제로 남겨둔 채 다양한 실험과 구체적인 분석이 부족한 상황이다. 기계번역에서 디코딩 전략은 번역 문장을 생성하는 과정에서 탐색 경로를 최적화 하고, 모델 변경 및 데이터 확장 없이도 성능 개선이 가능하다. 본 논문은 시퀀스 투 시퀀스 (Sequence to Sequence) 모델을 활용한 신경망 기반의 기계번역 에서 고전적인 그리디 디코딩 (Greedy decoding)부터 최신의 방법론인 Dynamic Beam Allocation (DBA)까지 비교 분석하여 디코딩 전략의 효과와 그 의의를 밝힌다.","Neural machine translation using deep neural network has emerged as a mainstream research, and an abundance of investment and studies on model structure and parallel language pair have been actively undertaken for the best performance. However, most recent neural machine translation studies pass along decoding strategy to future work, and have insufficient a variety of experiments and specific analysis on it for generating language to maximize quality in the decoding process. In machine translation, decoding strategies optimize navigation paths in the process of generating translation sentences and performance improvement is possible without model modifications or data expansion. This paper compares and analyzes the significant effects of the decoding strategy from classical greedy decoding to the latest Dynamic Beam Allocation (DBA) in neural machine translation using a sequence to sequence model."
혼합형 데이터 보간을 위한 디노이징 셀프 어텐션 네트워크,2021,"['머신러닝', '딥러닝', '데이터 품질', '결측값', '데이터 정제', '어텐션', 'Machine Learning', 'Deep Learning', 'Data Quality', 'Missing Values', 'Data Imputation', 'Attention']","최근 데이터 기반 의사결정 기술이 데이터 산업을 이끄는 핵심기술로 자리 잡고 있는바, 이를 위한 머신러닝 기술은 고품질의 학습데이터를 요구한다. 하지만 실세계 데이터는 다양한 이유에 의해 결측값이 포함되어 이로부터 생성된 학습된 모델의 성능을 떨어뜨린다. 이에 실세계에 존재하는 데이터로부터 고성능 학습 모델을 구축하기 위해서 학습데이터에 내재한 결측값을 자동 보간하는 기법이 활발히 연구되고 있다. 기존 머신러닝 기반 결측 데이터 보간 기법은 수치형 변수에만 적용되거나, 변수별로 개별적인 예측 모형을 만들기 때문에 매우 번거로운 작업을 수반하게 된다. 이에 본 논문은 수치형, 범주형 변수가 혼합된 데이터에 적용 가능한 데이터 보간 모델인 Denoising Self-Attention Network(DSAN)를 제안한다. DSAN은 셀프 어텐션과 디노이징 기법을 결합하여 견고한 특징 표현 벡터를 학습하고, 멀티태스크 러닝을 통해 다수개의 결측치 변수에 대한 보간 모델을 병렬적으로 생성할 수 있다. 제안 모델의 유효성을 검증하기 위해 다수개의 혼합형 학습데이터에 대하여 임의로 결측 처리한 후 데이터 보간 실험을 수행한다. 원래 값과 보간 값 간의 오차와 보간된 데이터를 학습한 이진 분류 모델의 성능을 비교하여 제안 기법의 유효성을 입증한다.","Recently, data-driven decision-making technology has become a key technology leading the data industry, and machine learning technology for this requires high-quality training datasets. However, real-world data contains missing values for various reasons, which degrades the performance of prediction models learned from the poor training data. Therefore, in order to build a high-performance model from real-world datasets, many studies on automatically imputing missing values in initial training data have been actively conducted. Many of conventional machine learning-based imputation techniques for handling missing data involve very time-consuming and cumbersome work because they are applied only to numeric type of columns or create individual predictive models for each columns. Therefore, this paper proposes a new data imputation technique called ‘Denoising Self-Attention Network (DSAN)’, which can be applied to mixed-type dataset containing both numerical and categorical columns. DSAN can learn robust feature expression vectors by combining self-attention and denoising techniques, and can automatically interpolate multiple missing variables in parallel through multi-task learning. To verify the validity of the proposed technique, data imputation experiments has been performed after arbitrarily generating missing values for several mixed-type training data. Then we show the validity of the proposed technique by comparing the performance of the binary classification models trained on imputed data together with the errors between the original and imputed values."
SRCNN과 VDSR의 구조와 방법 및 개선된 성능평가 함수,2021,"['딥러닝', '저해상도', '초 해상도', 'SRCNN', 'VDSR', 'Deep learning', 'Low-resolution', 'Super-resolution', 'SRCNN', 'VDSR']","이미지는 해상도가 높을수록 이미지를 시청하는 사람들의 만족도가 높아지며 초고해상도 이미지화는 컴퓨터 비전이나 영상처리 분야 중에서도 연구 가치가 꽤 높아지고 있다. 본 연구에서는 주로 딥 러닝 초 해상도 모델을 사용하여 저해상도 이미지 LR의 주요 특징을 추출한다. 추출된 특징을 학습 및 재구성하고, 고해상도 이미지 HR을 생성하는 재구성 기반 알고리즘에 중점을 둔다. 본 논문에서는 재구성에 기반을 둔 초 해상도 알고리즘 모델에서 SRCNN과 VDSR에 대하여 알아보도록 한다. SRCNN과 VDSR모델의 구조 및 알고리즘 프로세스를 간략하게 소개하고 개선된 성능평가 함수에서도 다중 채널과 특수한 형태에 대하여 알아보도록 하며, 실험을 통하여 각 알고리즘의 성능을 이해하도록 한다. 실험에서는 SRCNN 및 VDSR 모델의 결과와 피크 신호 대 잡음 비 및 이미지 구조 유사도를 비교하는 실험을 수행하여 결과를 한눈에 볼 수 있도록 하였다.","The higher the resolution of the image, the higher the satisfaction of the viewers of the image, and the super-resolution imaging has a considerable increase in research value among the fields of computer vision and image processing. In this study, the main features of low-resolution image LR are extracted mainly using deep learning super-resolution models. It learns and reconstructs the extracted features, and focuses on reconstruction-based algorithms that generate high-resolution image HR. In this paper, we investigate SRCNN and VDSR in a super-resolution algorithm model based on reconstruction. The structure and algorithm process of the SRCNN and VDSR model are briefly introduced, and the multi-channel and special form are also examined in the improved performance evaluation function, and understand the performance of each algorithm through experiments. In the experiment, an experiment was performed to compare the results of the SRCNN and VDSR models with the peak signal-to-noise ratio and image structure similarity, so that the results can be easily judged."
CNN-based Android Malware Detection Using Reduced Feature Set,2021,"['CNN', 'Android', 'Malware', 'Feature selection', 'Binary classification', 'Multiclass classification', '안드로이드', '악성코드', '특성추출', '이진분류', '다중분류']","딥러닝 기반 악성코드 탐지 및 분류모델의 성능은 특성집합을 어떻게 구성하느냐에 따라 크게 좌우된다. 본 논문에서는 CNN 기반의 안드로이드 악성코드 탐지 시 탐지성능을 극대화할 수 있는 최적의 특성집합(feature set)을 선정하는 방법을 제안한다. 특성집합에 포함될 특성은 기계학습 및 딥러닝에서 특성추출을 위해 널리 사용되는 Chi-Square test 알고리즘을 사용하여 선정하였다. CICANDMAL2017 데이터세트를 대상으로 선정된 36개의 특성을 이용하여 CNN 모델을 학습시킨 후 악성코드 탐지성능을 측정한 결과 이진분류에서는 99.99%, 다중분류에서는 98.55%의 Accuracy를 달성하였다.","The performance of deep learning-based malware detection and classification models depends largely on how to construct a feature set to be applied to training. In this paper, we propose an approach to select the optimal feature set to maximize detection performance for CNN-based Android malware detection. The features to be included in the feature set were selected through the Chi-Square test algorithm, which is widely used for feature selection in machine learning and deep learning. To validate the proposed approach, the CNN model was trained using 36 characteristics selected for the CICANDMAL2017 dataset and then the malware detection performance was measured. As a result, 99.99% of Accuracy was achieved in binary classification and 98.55% in multiclass classification."
소형 임베디드 장치를 위한 경량 컨볼루션 모듈 기반의 검출 모델,2021,[],"딥러닝을 이용한 객체 검출의 경우 정확도와 실시간성을 모두 요구한다. 그러나, 한정된 자원 환경에서는 수 많은 양의 데이터를 처리하는 딥러닝 모델을 사용하기 어렵다. 이러한 문제 해결을 위해 본 논문에서는 소형임베디드 장치를 위한 객체 검출을 모델을 제안하였다. 일반적인 검출 모델과 달리 사전 학습된 특징 추출기를 제거한 구조를 사용하여 모델 크기를 최소화하였다. 모델의 구조는 경량화된 컨볼루션 블록을 반복해서 쌓는 구조로 설계하였다. 또한, 검출 오버헤드를 줄이기 위해 영역 제안 횟수를 크게 줄였다. 제안하는 모델은 공개 데이터 셋인 PASCAL VOC를 사용하여 학습 및 평가하였다. 모델의 정량적 평가를 위해 검출 분야에서 사용하는 average precision으로 검출 성능을 측정하였다. 그리고 실제 임베디드 장치와 유사한 라즈베리 파이에서 검출 속도를 측정하였다. 실험을 통해 기존 검출 방법 대비 향상된 정확도와 빠른 추론 속도를 달성하였다.",
시계열 생성적 적대 신경망을 이용한 비행체 궤적 합성 데이터 생성 및 비행체 궤적 예측에서의 활용에 관한 연구,2021,"['Generative adversarial network', 'Synthetic data generation', 'Trajectory data', 'Flight vehicles', 'Trajectory prediction']","딥러닝을 포함한 머신러닝 기법을 기반으로 비행체의 궤적 설계, 제어, 최적화, 예측 등의 작업을 수행하기 위해서는 일정한 양 이상의 비행체 궤적 데이터를 필요로 한다. 그러나 다양한 이유(예를 들어 비행체 궤적 데이터셋 구축에 필요한 비용, 시간, 인력 등)로 일정한 양 이상의 비행체 궤적 데이터를 확보하기 어려운 경우가 존재한다. 이러한 경우 합성 데이터 생성이 머신러닝을 가능하게 하는 방법 중 하나가 될 수 있다. 본 논문에서는 이와 같은 가능성을 탐구하기 위하여 시계열 생성적 적대 신경망을 이용하여 비행체 궤적 합성 데이터를 생성하고 평가하였다. 또한 비행체의 상태를 인식하기 위한 비행체 궤적 예측 작업에서 합성 데이터의 활용 가능성을 탐구하기 위하여 다양한 ablation study(비교 실험)를 수행하였다. 본 논문에서 제시된 생성 평가 및 비교 실험 결과는 비행체 궤적 합성 데이터 생성 및 비행체 궤적 관련 작업에서 합성 데이터의 활용 가능성에 대한 연구를 수행하고자 하는 연구자들에게 실질적인 도움이 될 것으로 예상한다.","In order to perform tasks such as design, control, optimization, and prediction of flight vehicle trajectories based on machine learning techniques including deep learning, a certain amount of flight vehicle trajectory data is required. However, there are cases in which it is difficult to secure more than a certain amount of flight vehicle trajectory data for various reasons. In such cases, synthetic data generation could be one way to make machine learning possible. In this paper, to explore this possibility, we generated and evaluated synthetic flight vehicle trajectory data using time-series generative adversarial neural network. In addition, various ablation studies (comparative experiments) were performed to explore the possibility of using synthetic data in the aircraft trajectory prediction task. The experimental results presented in this paper are expected to be of practical help to researchers who want to conduct research on the possibility of using synthetic data in the generation of synthetic flight vehicle trajectory data and the work related to flight vehicle trajectories."
비디오 감시에서 심층 컨볼루션 신경망을 사용한 폭력 활동 감지,2021,"['딥러닝', '감시 카메라', '비정상적인 활동', '컨볼루션 뉴럴 네트워크', 'Deep learning', 'surveillance cameras', 'abnormal activity', 'convolutional neural network']","최근에는 전세계적으로 범죄 예방을 위한 감시 시스템이 설치되어 방대한 양의 비디오 데이터를 생성하는 개인 및 공공장소를 모두 모니터링하고 있다. 이 설정에서 전문가가 진행 중인 활동을 지속적으로 관찰하고 모니터링해야 한 다. 이 지루한 작업을 처리하기 위해 실시간으로 실행 가능한 폭력 활동 감지(VAD) 기술이 큰 과제이다. 따라서 본 논문에서는 실시간 VAD을 위한 3단계 딥러닝 지원 프레임워크를 제안한다. 첫번째 단계에서는 프레임 차이 알고리즘을 통해 비디오 데이터에서 가장 중요한 모션 프레임을 획득하기 위한 사전 처리 단계를 적용한다. 이러한 프 레임은 경량 컨볼루션 신경 네트워크(CNN)가 가장 차별적인 특징을 추출하는 두 번째 단계로 제공된다. 마지막으 로 CNN 모델은 활동을 폭력적인 장면과 비폭력적인 장면으로 분류한다. 폭력적인 행위가 발생할 경우, 가장 가까 운 보안 부서와 경찰서에 신고하여 신속한 조치를 취하도록 한다. 제안된 방법은 공개적으로 사용 가능한 데이터 세 트에서 96%의 정확도를 달성하고 최신 방법보다 성능이 우수하다.","Recently, surveillance systems are globally installed for crime prevention by monitoring both private and public places which generate a massive amount of video data. This setup requires human experts to observe and monitor the ongoing activities continuously. To handle this tedious task, an automatic technique workable in real-time for violent activity detection (VAD) is a big challenge. Thus, this paper proposes a three-phase deep learning assisted framework for real-time VAD. In the first phase, a preprocessing step is applied to obtain the salient motion frames from the video data through frame differencing algorithm. These frames are fed into the second phase where a lightweight convolutional neural network (CNN) extracts the most discriminative features. Finally, a CNN model classifies the activity into violent and non-violent scene. In case of violent activity, the activity is reported to notify the nearest security departments and police stations for the prompt action. The proposed method achieves 96% accuracy on the publicly available dataset and outperforms over state-of-the-art methods."
YOLO 기반의 광학 음악 인식 기술 및 가상현실 콘텐츠 제작 방법,2021,"['딥러닝', '가상현실', '컴퓨터 비전', 'Deep Learning', 'Virtual Reality', 'Optical Music Recognition(OMR)', 'Computer Vision']","딥러닝에 기반한 광학 음악 인식 기술(Optical Music Recognition, OMR)을 사용하여 도출된 결과를 가상현실 (Virtual Reality, VR) 게임에 적용시킨 것을 제안한다. 딥러닝 모델은 YOLO v5를 사용했으며 검출되지 않은 객체를 검출하기 위해 Hough transform 사용, 보표 크기 수정 등을 수행한다. 출력된 결과 파일을 사용하여 VR 게임에서 BPM, 최대 콤보 수, 음정과 박자를 분석하여 사용하고 리소스 관리를 위한 Object Pooling 기술을 통해 노트가 밀리는 현상을 방지한다. 광학 음악 인식 기술을 통해 나온 음악 요소로 VR 게임을 제작하여 VR 콘텐츠 제공과 함께 광학 음악 인식의 활용성을 넓히는 것을 확인하였다.","Using optical music recognition technology based on deep learning, we propose to apply the results derived to VR games. To detect the music objects in the music sheet, the deep learning model used YOLO v5, and Hough transform was employed to detect undetected objects, modifying the size of the staff. It analyzes and uses BPM, maximum number of combos, and musical notes in VR games using output result files, and prevents the backlog of notes through Object Pooling technology for resource management. In this paper, VR games can be produced with music elements derived from optical music recognition technology to expand the utilization of optical music recognition along with providing VR contents."
텍스트 마이닝을 활용한 실질 국내총생산의 실시간 예측,2021,"['딥러닝', '실시간 예측', '실질 국내총생산', '텍스트 마이닝', 'Deep Learning', 'Real Gross Domestic Product', 'Real-Time Forecasting', 'Text Mining']","본 연구는 실질 GDP(RGDP: Real GDP)를 실시간으로 예측하는 모형을 개발하는 것을 목적으로 한다. 이를 위해 본 연구는 RGDP를 실시간으로 예측하는 것과 RGDP 예측의 설명변수로 선정된 심리 지표들을 실시간으로 예측하는 것으로 구분한다. 경제주체들의 심리지수들은 실물지표의 움직임을 잘 반영하기 때문에 RGDP 예측의 설명변수로 기업경기실사지수와 소비자동향지수를 활용한다. 또한 기업경기실사지수와 소비자동향조사를 예측하기 위해 온라인 뉴스의 비정형 텍스트 데이터를 활용한다. 본 연구는 기업경기실사지수와 소비자동향지수를 바탕으로 RGDP를 실시간으로 예측하기 위해 다음과 같은 2단계 절차를 수행한다. 1단계에서는 기업경기실사지수와 소비자동향지수에 영향을 미치는 요인을 빠르게 반영하기 위해 온라인 뉴스의 비정형 데이터로부터 정보를 수집하는 텍스트 마이닝 기법을 활용한다. 이렇게 텍스트 마이닝을 통해 비정형 데이터를 정량화한 후, 이를 바탕으로 딥러닝 기법을 활용하여 기업경기실사지수와 소비자동향지수를 추정한다. 2단계에서는 선행연구에서 활용된 RGDP 예측 방법인 시차회귀모형(LR: Lagged Regression), 자기회귀 동적요소모형(AR-DFM: Autoregressive Dynamic factor model), 혼합자료샘플링(MIDAS: Mixed-Data Sampling) 모형을 활용한다. 이 중에서 RGDP 예측의 최종 모형을 선정하기 위해 각 모형에 대한 추정 오차의 RMSE(Root Mean Squared Error)를 산출한다. 분석 결과, 시차회귀모형이 실시간 예측에 가장 적합한 것으로 나타났다.","This study is trying to develop a model that predicts real GDP (RGDP) in real time. To this end, this study is divided into the real-time prediction of RGDP and the real-time prediction of ESI(Economic Sentiment indicator) selected as explanatory variables for RGDP prediction. Since the sentiment indices of economic agents reflect the movement of real economy well, they use BSI(Business Survey Index) and CSI(Consumer Survey Index) as explanatory variables for RGDP prediction. In addition, unstructured data from online news are used to predict BSI and CSI. This study performs the following two-step procedure to predict RGDP in real time based on the BSI and the CSI. In the first stage, text mining techniques are used to collect information from unstructured data in online news to analyze the factors affecting them. After quantifying unstructured data through text mining in this way, a deep learning technique is utilized to estimate the BSI and the CSI. In the second stage, the lagged regression(LR) model, the autoregressive dynamic factor model (AR-DFM) model, and the mixed-data sampling (MIDAS) model, which are methods of predicting RGDP used in previous studies, are used. Among them, Mean Absolute Error (MAE), Root Mean Square Error (RMSE), and Relative Mean Absolute Error (RMAE) of estimation errors for each model are calculated to select the final model of RGDP prediction. The analysis results show that the LR model is most suitable for the real-time prediction of RGDP."
Improving Parallelism for Video Action Recognition Model Using One-dimensional Convolutional Neural Network,2021,"['비디오 분류', '비디오 행동 인식', '1차원 CNN', '딥러닝', 'video classification', 'video action recognition', '1D convolutional neural network', 'deep learning']",딥러닝 프레임워크는 컴퓨터 비전 많은 분야에서 괄목할 만한 성과를 보여주고 있다. 비디오 행동 인식 분야 역시 딥러닝 모델을 적용하기 위한 많은 연구들이 수행되었다. 한 선행연구는 2차원 CNN을 이용해 공간적 피쳐를 학습하고 이를 RNN에 입력으로 전달해 이용해 공간적 피쳐 사이의 시간적 상호 관계를 학습하는 모델 구조를 제안했다. 본 논문에서는 RNN 대신 1차원 CNN을 이용해 시간적 상호관계를 학습하도록 선행 연구의 모델 구조를 개선하는 연구를 수행한다. 이러한 구조 변경을 통해 RNN의 순차적 연산 과정을 제거해 향상된 GPU 활용도를 기대할 수 있다. 본 논문은 수정된 모델이 정확도를 비슷하게 유지하면서 연산 시간이 줄어드는 것을 보여주는 실험 결과를 제시함으로써 이러한 주장을 뒷받침한다.,"The deep learning framework has shown remarkable results on numerous computer vision tasks. Many studies have been performed for video action recognition tasks to apply deep learning models to the task. One of the previous works suggested the model architecture, where spatial features are learned from 2D Convolutional Neural Networks (CNNs) and then passed to Recurrent Neural Networks (RNNs) to learn about temporal dependency among them. In this paper, we study the improved model architecture where the temporal relationship of spatial features is processed with 1D CNN instead of RNN. From this modification, we can expect better utilization of GPU by removing sequential operations of RNN. We support the argument based on the experiment results that show that it leads to the reduction in computation time and maintains a similar classification accuracy."
다양한 동작 학습을 위한 깊은 신경망 구조 비교,2021,"['딥러닝', '동작 생성', '컴퓨터 애니메이션', '시뮬레이션', 'Deep Learning', 'Motion Generation', 'Computer Animation', 'Simulation']","최근 컴퓨터 애니메이션 분야에서는 기존의 유한상태기계나 그래프 기반의 방식들에서 벗어나 딥러닝을 이용한 동작 생성방식이 많이 연구되고 있다. 동작 학습에 요구되는 네트워크의 표현력은 학습해야 하는 동작의 단순한 길이보다는 그 안에 포함된 동작의 다양성에 더 큰 영향을 받는다. 본 연구는 이처럼 학습해야 하는 동작의 종류가 다양한 경우에 효율적인 네트워크 구조를 찾는것을 목표로 한다. 기본적인 fully-connected 구조, 여러개의 fully-connected 레이어를 병렬적으로 사용하는 mixture of experts구조, seq2seq처리에 널리 사용되는 순환신경망(RNN), 그리고 최근 시퀀스 형태의 데이터 처리를 위해 자연어 처리 분야에서 사용되고 있는 transformer구조의 네트워크들을 각각 학습하고 비교한다.","Recently, in the field of computer animation, a method for generating motion using deep learning has been studied away from conventional finite-state machines or graph-based methods. The expressiveness of the network required for learning motions is more influenced by the diversity of motion contained in it than by the simple length of motion to be learned. This study aims to find an efficient network structure when the types of motions to be learned are diverse. In this paper, we train and compare three types of networks: basic fully-connected structure, mixture of experts structure that uses multiple fully-connected layers in parallel, recurrent neural network which is widely used to deal with seq2seq, and transformer structure used for sequence-type data processing in the natural language processing field."
시맨틱 확산 기법을 활용한 헤어스타일 변환 이미지 생성 기법,2021,"['딥러닝', '이미지 합성', '시맨틱 확산', 'deep learning', 'StyleGAN', 'IndomainGAN', 'image synthesis', 'semantic diffusion']","사람의 얼굴은 이목구비의 크기, 모양, 위치 등 다양한 요소에 의해 그 형태가 결정된다. 이는 사람의 얼굴과 관련된 이미지를 생성 또는 합성하는데 있어서 큰 장애요인으로 작용한다. 최근에는 이러한 한계점을 딥러닝 기반의 모델을 활용하여 해결하려는 움직임이 다양한 연구들을 통하여 나타나고 있다. 그 중 두 이미지(타겟 이미지, 컨텍스트 이미지)의 합성을 통해 새로운 이미지를 생성하는 Indomain GAN의 시맨틱 확산 기법이 일반적으로 우수한 성능을 나타내지만, 이미지 합성 비율에 따라 생성된 이미지에서 왜곡이 발생하는 문제가 존재한다. 본 논문에서는 이런 문제점을 해결하기 위해 타겟 이미지의 얼굴 외곽을 고려한 새로운 시맨틱 확산 기법을 제안하며 이를 기반으로 입력 이미지의 헤어스타일을 변환시키는 웹 어플리케이션을 개발하였다. 또한, 본 논문에서는 다양한 실험을 통해 제안하는 시맨틱 확산 기법이 기존 기법에 비해 우수한 성능을 나타내는 것을 확인하였다.","A human face is made up of different features with individual facial characteristics, such as, size, shape, and location of features. This is the main problem in creating or synthesizing an image related to a human face. Recently, a variety of studies have been carried out to solve this problem by using deep learning-based models. Among them, semantic diffusion used in Indomain GAN, which creates a new image using the synthesis of two images (target and context images), shows excellent performance. However, visual distortion is an issue, which occurs in the generated image depending on the image synthesis ratio. In order to address this problem, we proposed a new semantic diffusion method which takes into account the facial contour of the person in the target image. Based on this, we also developed a web application that changes a person""s hairstyle in the input image. The experiment clearly shows that the proposed semantic diffusion method generates better synthesized images than conventional semantic diffusion method."
사과 품종 분류를 위한 CNN기반 모델링 및 분류 기법 연구,2021,"['스마트팜', '딥러닝', 'ResNet', '신경망', 'Smart Farm', 'Deep Learning', 'ResNet', 'Convolution Neural Network']","농장주들이 과일을 분류하는 데까지의 시간소모를 줄이고 향후 과일의 등급 판정 기준을 정량화하기 위하여 우리나라의 대표적인 과일이며 다양한 품종을 가지고 있는 사과를 대상으로 신경망 기반 분류 자동화 시스템을 제안한다. 컨베이어 벨트를 통해 지나가는 객체를 카메라모듈로 촬영하여 이를 통신 및 연산을 수행하는 라즈베리파이 기반 시스템을 설계, 구현한다. 깊은 네트워크와 나머지(residual)를 학습하는 ResNet 기반 알고리즘이 구동되는 딥러닝 서버와는 SSH통신을 통해 이미지와 학습된 모델을 주고받는다. 향후 품종뿐만 아니라 등급까지 분류 자동화한다면 다양한 품종의 과일을 대상으로 한 출하 자동화 시스템으로의 적용이 가능하다.","This paper propose a neural network-based classification automation system for apples, which are representative fruits of Korea and have a variety of varieties, in order to reduce the consumption of time for farmers to classify fruits and to quantify the criteria for grading the fruits. Raspberry Pi-based system that communicates and performs calculations by photographing objects passing through a conveyor belt with a camera module is designed and implemented. Then it receive the trained model using ResNet-based algorithm that runs on the deep-learning server. In the future, if classifying not only varieties but also grades is automated, it can be applied as a shipping automation system targeting various varieties of fruit."
유가증권 시장에서의 동적 포트폴리오 최적화를 위한 모듈식 강화학습,2021,"['강화학습', '딥러닝', '시계열', '코스피', '포트폴리오', 'Deep learning', 'KOSPI', 'portfolio', 'reinforcement learning', 'time series']","주식 투자와 자산 관리에서 포트폴리오 분배와 최적화는 위험을 관리하고 수익률을 극대화하기 위해 필수적인 부분으로 금융분야에서 해결해야 할 전통적인 문제였다. 한편 최근 딥러닝이 많은 연구가 이루어지고 큰 성과를 이루었고 그와 함께 강화학습 또한 큰 발전을 이루고 있다. 이에 따라 최근 포트폴리오 관리에 강화학습 방법론을 적용하려는 시도가 이루어졌지만 연구의 대부분은 거래 규모가 큰 암호화폐에 한정되어 이루어 진 것이 대부분이다. 본 논문에서는 유가증권시장의 상위 종목 중 대표성이 높은 종목으로 선정되는 KOSPI200을 구성하는 종목 중 투자 대상 주식을 선정하는 가치 추정 모듈 (evaluation stock module, ESM)과 선정된 주식을 배분하는 자산 배분 모듈 (asset allocation module, AAM) 두가지를 통해 포트폴리오를 구성하는 신경망을 구현하었다.","In stock investment and asset management, portfolio distribution and optimization are essential parts to manage risk and maximize returns, and have been traditional problems to be solved in the financial sector. Meanwhile, a lot of research have been conducted on deep learning in recent years, and reinforcement learning is also making great progress. Accordingly, attempts have been made to apply the reinforcement learning methodology to portfolio management in recent years, but most of the research is limited to cryptocurrencies with large transactions. In this paper, we implemented a neural network that composes a portfolio through two types of an Evaluation Stock module (ESM) that selects stocks for investment and an Asset Allocation module (AAM) that allocates the selected stocks. The constituent stocks of the KOSPI 200 were considered for investment."
인공신경망 기계번역에서 말뭉치 간의 균형성을 고려한 성능 향상 연구,2021,"['기계번역', '병렬말뭉치', '휴먼번역', '고품질 데이터', '딥러닝', '언어융합', 'Machine Translation', 'Parallel Corpus', 'Human Translation', 'High Quality Data', 'Deep Learning', 'Language Conversion']","최근 딥러닝 기반 자연언어처리 연구들은 다양한 출처의 대용량 데이터들을 함께 학습하여 성능을 올리고자 하는 연구들을 진행하고 있다. 그러나 다양한 출처의 데이터를 하나로 합쳐서 학습시키는 방법론은 성능 향상을 막게 될 가능성이 존재한다. 기계번역의 경우 병렬말뭉치 간의 번역투(의역, 직역), 어체(구어체, 문어체, 격식체 등), 도메인 등의 차이로 인하여 데이터 편차가 발생하게 되는데 이러한 말뭉치들을 하나로 합쳐서 학습을 시키게 되면 성능의 악영 향을 미칠 수 있다. 이에 본 논문은 기계번역에서 병렬말뭉치 간의 균형성을 고려한 Corpus Weight Balance (CWB) 학습 방법론을 제안한다. 실험결과 말뭉치 간의 균형성을 고려한 모델이 그렇지 않은 모델보다 더 좋은 성능을 보였다. 더불어 단일 말뭉치로도 고품질의 병렬 말뭉치를 구축할 수 있는 휴먼번역 시장과의 상생이 가능한 말뭉치 구축 프로세 스를 추가로 제안한다.","Recent deep learning-based natural language processing studies are conducting research to improve performance by training large amounts of data from various sources together. However, there is a possibility that the methodology of learning by combining data from various sources into one may prevent performance improvement. In the case of machine translation, data deviation occurs due to differences in translation(liberal, literal), style(colloquial, written, formal, etc.), domains, etc. Combining these corpora into one for learning can adversely affect performance. In this paper, we propose a new Corpus Weight Balance(CWB) method that considers the balance between parallel corpora in machine translation. As a result of the experiment, the model trained with balanced corpus showed better performance than the existing model. In addition, we propose an additional corpus construction process that enables coexistence with the human translation market, which can build high-quality parallel corpus even with a monolingual corpus."
YOLO 알고리즘을 이용한 전차 국적 식별 및 평가,2021,"['객체탐지', 'YOLO(You Only Look Once) 알고리즘', '딥러닝', '데이터셋', '전차', '피아식별 시스템', 'object detection', 'YOLO(You Only Look Once) algorithm', 'deep learning', 'dataset', 'tank', 'Identification of Friend or Foe', 'mAP', 'IoU']","인공지능 딥러닝 기술이 적용된 무기체계가 지속적으로 개발된다. 기존의 전차 피아식별 시스템은 사람의 눈으로 표적을 획득하고 공격 여부를 판단한다. 따라서 신속성과 정확성 측면에서 한계가 존재한다. 본 연구에서는 이러한 제한사항을 개선하기 위해 YOLO(You Only Look Once) 알고리즘 기반의 전차 국적 식별 방법을 제안한다. 먼저, 한국, 미국, 일본, 북한의 4개국의 주력 전차 사진을 수집한다. 특히, 실제 기갑 전투의 상황과 유사하도록 노이즈를 추가하고 이미지 전처리 작업을 한다. 이후 데이터셋은 학습 데이터의 적절한 규모를 확인하기 위해 8개의 그룹으로 구성한다. 마지막으로 평가 척도인 mAP와 IoU를 기반으로 적절한 데이터 규모를 분석한다.","Advanced weapon systems with artificial intelligence deep learning technology will be continuously. The existing identification system of friend or foe on tank targets with human eyes determine whether to attack. Therefore, there are limitations in terms of speed and accuracy. In this paper, we propose a YOLO(You Only Look Once) Algorithm-based tank nationality identification method to improve these limitations. First, we collect photos of the main tank from four countries South Korea, the United States, Japan and North Korea. In particular, similar to the actual armored battle, we add noise and do image preprocessing. Afterward, the dataset organized into eight groups to check the appropriate size of the learning data. Finally, we analyze the appropriate data size based on the evaluation scales, mAP and IoU."
자동-레이블링 기반 영상 학습데이터 제작 시스템,2021,"['영상 학습데이터셋', '이미지 레이블링 도구', '자동 레이블링', 'Image Training Dataset', 'Image Labeling Tool', 'Automatic Labeling']","최근 딥러닝 기술의 급속한 발전과 함께 학습데이터가 크게 주목을 받고 있다. 일반적으로 딥러닝 방식에서는 모델을 훈련시키기 위해 충분한 학습데이터가 준비되어 있어야 한다. 하지만, 딥러닝 모델 설계 작업과 달리 데이터셋을 제작하는 데 상당한 시간과 노력이 필요하다. 영상 데이터를 주로 다루는 시각지능 분야에서도 학습데이터 제작자들은 전문적인 학습데이터 제작 도구를 사용해 이미지 단위로 레이블링을 수작업으로 하고 있어 여전히 많은 시간과 노력이 필요한 상황이다. 따라서, 다양한 분야에서 필요한 충분한 영상 학습데이터셋을 확보하기 위해 기존의 수작업 방식을 대체할 수 있는 레이블링 기술이 필요하다. 본 논문에서는, 영상 학습데이터셋 동향을 소개하고, 학습데이터 제작 환경에 대해 분석한다 특히, 수작업으로 이루어지는 반복적이고 수고스러운 레이블링 과정을 자동화하여, ‘확인과 수정’의 단계를 비약적으로 단축시킬 수 있는 ‘스마트 영상 학습데이터 제작 시스템’을 제안한다. 그리고, 실험을 통해 영상 학습데이터 제작 과정에서 이미지에 박스형 및 폴리곤형 객체영역을 지정하여 레이블링하는 데 소요되는 시간을 크게 줄이기 위한 자동레이블링 방식의 효과를 검증한다. 마지막으로, 제안하는 시스템의 실험에서 추가적으로 검증되어야 하는 부분과 함께 이를 개선하기 위한 향후 연구 계획에 대해 논의한다.","The drastic advance of recent deep learning technologies is heavily dependent on training datasets which are essential to train models by themselves with less human efforts. In comparison with the work to design deep learning models, preparing datasets is a long haul; at the moment, in the domain of vision intelligent, datasets are still being made by handwork requiring a lot of time and efforts, where workers need to directly make labels on each image usually with GUI-based labeling tools. In this paper, we overview the current status of vision datasets focusing on what datasets are being shared and how they are prepared with various labeling tools. Particularly, in order to relieve the repetitive and tiring labeling work, we present an interactive smart image annotating system with which the annotation work can be transformed from the direct human-only manual labeling to a correction-after-checking by means of a support of automatic labeling. In an experiment, we show that automatic labeling can greatly improve the productivity of datasets especially reducing time and efforts to specify regions of objects found in images. Finally, we discuss critical issues that we faced in the experiment to our annotation system and describe future work to raise the productivity of image datasets creation for accelerating AI technology."
오토인코더 기반의 잡음에 강인한 계층적 이미지 분류 시스템,2021,"['이미지 분류', '딥러닝', '머신러닝', '오토인코더', '잡음', 'Image classification', 'Deep learning', 'Machine learning', 'Autoencoder', 'Noise']",본 논문은 다수의 오토인코더 모델들을 이용한 잡음에 강인한 이미지 분류 시스템을 제안한다. 딥러닝 기술의 발달로 이미지 분류의 정확도는 점점 높아지고 있다. 하지만 입력 이미지가 잡음에 의해서 오염된 경우에는 이미지 분류 성능이 급격히 저하된다. 이미지에 첨가되는 잡음은 이미지의 생성 및 전송 과정에서 필연적으로 발생할 수밖에 없다. 따라서 실제 환경에서 이미지 분류기가 사용되기 위해서는 잡음에 대한 처리 및 대응이 반드시 필요하다. 한편 오토인코더는 입력값과 출력값이 유사하도록 학습되어지는 인공신경망 모델이다. 입력데이터가 학습데이터와 유사하다면 오토인코더의 출력데이터와 입력데이터 사이의 오차는 작을 것이다. 하지만 입력 데이터가 학습데이터와 유사성이 없다면 오토인코더의 출력데이터와 입력데이터 사이의 오차는 클 것이다. 제안하는 시스템은 오토인코더의 입력데이터와 출력데이터 사이의 관계를 이용한다. 제안하는 시스템의 이미지 분류 절차는 2단계로 구성된다. 1단계에서 분류 가능성이 가장 높은 클래스 2개를 선정하고 이들 클래스의 분류 가능성이 서로 유사하면 2단계에서 추가적인 분류 절차를 거친다. 제안하는 시스템의 성능 분석을 위해 가우시안 잡음으로 오염된 MNIST 데이터셋을 대상으로 분류 정확도를 실험하였다. 실험 결과 잡음 환경에서 제안하는 시스템이 CNN(Convolutional Neural Network) 기반의 분류 기법에 비해 높은 정확도를 나타냄을 확인하였다.,"This paper proposes a noise-tolerant image classification system using multiple autoencoders. The development of deep learning technology has dramatically improved the performance of image classifiers. However, if the images are contaminated by noise, the performance degrades rapidly. Noise added to the image is inevitably generated in the process of obtaining and transmitting the image. Therefore, in order to use the classifier in a real environment, we have to deal with the noise. On the other hand, the autoencoder is an artificial neural network model that is trained to have similar input and output values. If the input data is similar to the training data, the error between the input data and output data of the autoencoder will be small. However, if the input data is not similar to the training data, the error will be large. The proposed system uses the relationship between the input data and the output data of the autoencoder, and it has two phases to classify the images. In the first phase, the classes with the highest likelihood of classification are selected and subject to the procedure again in the second phase. For the performance analysis of the proposed system, classification accuracy was tested on a Gaussian noise-contaminated MNIST dataset. As a result of the experiment, it was confirmed that the proposed system in the noisy environment has higher accuracy than the CNN-based classification technique."
심전도 신호 분류를 위한 1D CNN 모델 구성 요소의 최적화,2021,"['Deep learning', 'Electrocardiogram', 'CNN', 'ResNet', 'Arrhythmia Detection', '딥러닝', '심전도', '부정맥 검출']","본 논문에서는 딥러닝 모델을 이용하여 모바일 기기의 심전도 신호 측정 데이터를 분류한다. 비정상 심장박동을 높은 정확도로 분류하기 위해 딥러닝 모델의 구성 요소 세 가지를 선정하고 요소의 조건 변화에 따른 분류 정확도를 비교한다. 심전도 신호 데이터의 특징을 스스로 추출할 수 있는 CNN 모델을 적용하고 모델을 구성하는 모델의 깊이, 최적화 방법, 활성화 함수의 조건을 변경하여 총 48개의 조합의 성능을 비교한다. 가장 높은 정확도를 보이는 조건의 조합을 도출한 결과 컨볼루션 레이어 19개, 최적화 방법 SGD, 활성화 함수 Mish를 적용하였을 때 정확도 97.88%로 모든 조합 중 가장 높은 분류 정확도를 얻었다. 이 실험에서 CNN을 활용한 1-채널 심전도 신호의 특징 추출과 비정상 박동 검출의 적합성을 확인하였다.","In this paper, we classify ECG signal data for mobile devices using deep learning models. To classify abnormal heartbeats with high accuracy, three factors of the deep learning model are selected, and the classification accuracy is compared according to the changes in the conditions of the factors. We apply a CNN model that can self-extract features of ECG data and compare the performance of a total of 48 combinations by combining conditions of the depth of model, optimization method, and activation functions that compose the model. Deriving the combination of conditions with the highest accuracy, we obtained the highest classification accuracy of 97.88% when we applied 19 convolutional layers, an optimization method SGD, and an activation function Mish. In this experiment, we confirmed the suitability of feature extraction and abnormal beat detection of 1-channel ECG signals using CNN."
모바일 플랫폼 교육 콘텐츠 지원을 위한 손 글씨 기반 텍스트 인터페이스 설계,2021,"['텍스트 인터페이스', '딥 러닝', '모바일', '영어 교육 콘텐츠', 'text interface', 'EMNIST', 'CNN', 'deep learning', 'mobile', 'English education contents']","본 연구는 모바일 플랫폼 환경에서 언어 기반의 교육 콘텐츠 지원을 위한 텍스트 인터페이스를 제안한다. 이는 손 글씨를 통해 단어를 작성하는 입력 구조로 딥 러닝을 활용한다. 모바일 플랫폼 콘텐츠의 버튼, 메뉴 등을 활용한 GUI (Graphical User Interface)와 화면 터치, 클릭, 드래그 등의 입력 방식을 기반으로 손 글씨를 사용자로부터 직접 입력하여 처리할 수 있는 텍스트 인터페이스를 설계한다. 이는 EMNIST (Extended Modified National Institute of Standards and Technology database) 데이터 셋과 훈련된 CNN (Convolutional Neural Network)을 사용하여 알파벳 텍스트를 분류하고 조합하여 단어를 완성한다. 최종적으로 영어 단어 교육 콘텐츠를 직접 제작하여 제안하는 인터페이스의 학습 지원 효과를 분석하고 만족도를 비교하기 위한 실험을 진행한다. 동일한 교육 환경에서 기존의 키 패드 방식의 인터페이스와 제안하는 손 글씨 기반 텍스트 인터페이스를 서로 체험한 사용자들이 제시하는 영어 단어를 학습하는 능력을 비교하고, 인터페이스를 조작하여 단어를 작성하는 과정에서의 전체적인 만족도를 분석, 확인하도록 한다.","This study proposes a text interface for support of language-based educational contents in a mobile platform environment. The proposed interface utilizes deep learning as an input structure to write words through handwriting. Based on GUI (Graphical User Interface) using buttons and menus of mobile platform contents and input methods such as screen touch, click, and drag, we design a text interface that can directly input and process handwriting from the user. It uses the EMNIST (Extended Modified National Institute of Standards and Technology database) dataset and a trained CNN (Convolutional Neural Network) to classify and combine alphabetic texts to complete words. Finally, we conduct experiments to analyze the learning support effect of the interface proposed by directly producing English word education contents and to compare satisfaction. We compared the ability to learn English words presented by users who have experienced the existing keypad-type interface and the proposed handwriting-based text interface in the same educational environment, and we analyzed the overall satisfaction in the process of writing words by manipulating the interface."
딥러닝기반 실내와 실외 환경에서의 광원 추출,2021,"['광원 추출', '딥러닝', 'HDR 환경 맵', '실내 광원', '실외 광원', 'lighting estimation', 'deep learning', 'HDR environment map', 'indoor lighting', 'outdoor lighting']","본 연구에서는 딥러닝을 기반으로 하여 실내와 실외 이미지 모두에서 알맞은 광원을 추출하는 방법론을 소개한다. 네트워크는 단일 LDR 이미지로부터 실내 혹은 실외 배경에 맞는 광원을 low dynamic range (LDR) 환경 맵으로 추출하는 Crop-to-PanoLDR 네트워크와 추출된 LDR 환경 맵을 빛의 정보를 담은 high dynamic range (HDR) 환경 맵으로 생성하는 LDR-to-HDR 네트워크 두 단계로 구성된다. 이와 같은 과정을 통해 최종적으로 생성된 HDR 환경 맵은 주어진 이미지에서 가상 객체를 렌더링할 때 적용되어 가상 객체를 조명하는 빛의 방향과 주변광 등을 확인함으로써 자연스러운 렌더링을 가능하게 하는지 검증한다. 본 연구에서 제안한 방법론의 우수성은 실내를 배경으로 한 이미지로만 구성한 데이터로 학습한 결과와 실외를 배경으로 한 이미지로만 학습한 결과 등과 비교하여 검증하였다. 또한, 실내와 실외를 구분하는 역할을 수행하는 손실함수가 학습 결과에 미치는 영향을 실험, 검증하였다. 최종적으로 본 연구에서 생성된 환경 맵을 기존의 연구 결과와 비교실험하는 사용자 테스트를 진행하였고 더 좋은 결과를 확인할 수 있었다.","We propose a deep learning-based method that can estimate an appropriate lighting of both indoor and outdoor images. The method consists of two networks: Crop-to-PanoLDR network and LDR-to-HDR network. The Crop-to-PanoLDR network predicts a low dynamic range (LDR) environment map from a single partially observed normal field of view image, and the LDR-to-HDR network transforms the predicted LDR image into a high dynamic range (HDR) environment map which includes the high intensity light information. The HDR environment map generated through this process is applied when rendering virtual objects in the given image. The direction of the estimated light along with ambient light illuminating the virtual object is examined to verify the effectiveness of the proposed method. For this, the results from our method are compared with those from the methods that consider either indoor images or outdoor images only. In addition, the effect of the loss function, which plays the role of classifying images into indoor or outdoor was tested and verified. Finally, a user test was conducted to compare the quality of the environment map created in this study with those created by existing research."
재범의 위험성 예측 알고리즘과 설명가능성 및 공정성의 문제,2021,"['재범의 위험성 예측 알고리즘', '블랙박스', '설명 가능성', '공정성', '법 분야 의사 결정 대체', 'recidivism Algorithm', 'Black Box', 'Explainability', 'Fairness', 'Legal Decision Substitution']","인공지능 특히 머신러닝 알고리즘은 의료 분야나 금융 분야뿐만 아니라 법 분야에서 재범의 위험성 예측과 범죄 예측 등에 활용되고 있다. 이러한 인공지능에서 가장 문제되는 것은  블랙박스 속성으로, 인공지능의 작동 기제를 인간이 제대로 이해하지 못한다는 것이다. 재범의 위험성 예측 등에 사용되는 딥러닝 또는 머신러닝 아키텍처의 내부 작동은 점점 더 복잡하고 불투명해지고 있다. 다른 분야도 마찬가지이지만, 법 분야에서 이러한 인공지능의 의사 결정 과정의 투명성을 보장하고 나아가, 그 의사결정과정을 비전문가들에게 설명할 수 있는 체계가 필수적이다. 법 분야에서의 의사결정은 그 결과뿐만 아니라, 그 절차적 정당성이 매우 중요하기 때문이다. 법 분야 의사결정 알고리즘의 대표 격으로 거론되는 재범 위험성 예측 알고리즘 COMPAS는 피고인의 석방 여부 결정이나 형량 결정 등에 사용되고 있다. COMPAS의 도입･시행 이후, 이 알고리즘을 둘러싼 논란과 여러 비판에서 보듯 미국에서 널리 사용되고 있는 COMPAS는 인종차별적인 결과를 내는 등 문제점이 많은 것으로 드러났다. 인공지능의 블랙박스 속성 때문에 COMPAS의 작동 기제를 알지 못한다. 편향적 결과로 인해 피해를 본 사람도 이와 같은 블랙박스 속성 때문에 그 결과를 탄핵할 수 없다. 이러한 블랙박스로 인한 인공지능 알고리즘의 문제점을 해결하려는 해법이 필요하다. 그 해법의 가장 큰 줄기가 바로 ‘설명 가능한 인공지능’이다. 설명가능 인공지능은 인공지능이 내린 의사결정의 이유를 사람이 이해할 수 있는 방식으로 제시하는 인공지능을 일컫는다. 인공지능의 발전에 상당한 기여를 했다는 평가를 받고 있는 미 방위고등연구계획국은 몇 년 전부터 이러한 설명 가능한 인공지능 연구에 대해 막대한 지원을 하고 있다.물론 인공지능 연구자 중에는 설명 가능한 인공지능의 가치에 대해 의문을 던지고 있는 이도 있다. 심지어 인간의 의사결정과정도 쉽게 설명될 수 있는 것이 아니라며, 인공지능의 의사결정 과정의 설명 가능성과 실용성 모두를 의문시한다. 이런 회의론 에도 불구하고, 법 분야에서 인간의 의사결정을 대체하는 수준의 인공지능 알고리즘이 개발되고, 자리 잡기 위해서는 설명 가능한 인공지능 과제는 반드시 해결되어야 한다. 따라서 본 연구에서는 이러한 설명 가능한 인공지능의 개념과 그것이 법 분야 인공지능 알고리즘 구현과 활용에 얼마나 중요한지를 따져보고, 그것의 실현가능성을 점쳐 본다.이런 설명 가능한 인공지능으로 인하여 편향성이나 차별 등 공정성 가치를 저해하는 등 여러 가지 문제점이 해결될 것으로 기대한다.","Artificial intelligence, in particular, machine learning algorithms are used not only in the medical field or finance field, but also in the law field to predict the risk of recidivism, predict crime, and improve legal services. The most problematic aspect of such artificial intelligence is the black box problem, which is that humans do not properly understand the mechanism of operation of artificial intelligence. The inner workings of deep learning or machine learning architectures are becoming increasingly complex and opaque. As is the case in other fields, in the field of law, a system is essential to ensure transparency in the decision-making process of artificial intelligence, and to explain the decision-making process to non-experts. Decision-making in the field of law is because not only the outcome, but also its procedural justification is very important. The recidivism risk prediction algorithm COMPAS, which is mentioned as a representative case of decision-making algorithms in the legal field, is used for determining whether to release a defendant or determining a sentence. Since the introduction and implementation of COMPAS, as seen in the controversy and criticisms surrounding this algorithm, COMPAS, which is widely used in the United States, has been found to have many problems, such as racist results. Due to the black box nature of artificial intelligence, we do not know the mechanism of COMPAS. Even those who have suffered damage due to the biased result cannot challenge the result because of the black box property. There is a need for a solution to solve the problem of artificial intelligence algorithms caused by such black boxes. The biggest stem of the solution is ‘explainable artificial intelligence'. Explainable artificial intelligence refers to artificial intelligence that presents the reasons for decisions made by artificial intelligence in a way that humans can understand. The U.S. Defense Advanced Research Projects Agency (Darpa), which is considered to have made a significant contribution to the advancement of artificial intelligence, began to provide enormous support for such explanatory artificial intelligence research several years ago.Of course, some of the AI researchers are questioning the value of explainable AI. Even the human decision-making process cannot be explained easily, and they question both the explanatory feasibility and practicality of the decision-making process of artificial intelligence. Despite this skepticism, in order to develop and establish an artificial intelligence algorithm at a level that replaces human decision-making in the field of law, an explainable AI task must be solved. Therefore, in this study, the concept of explainable artificial intelligence and how important it is to the implementation and application of artificial intelligence algorithms in the legal field, and its feasibility are examined.It is expected that a large number of problems that hinder fairness values such as bias and discrimination will be solved by such explainable artificial intelligence. Apart from that, I would like to discuss with you whether there is a way to solve the problem of impairing fairness value caused by artificial intelligence algorithms."
인공지능기반 보안관제 구축 및 대응 방안,2021,"['인공지능', '플랫폼', '빅데이터', '딥러닝', '보안체계', '알고리즘', 'Artificial Intelligence', 'Platform', 'Big Data', 'Deep Learning', 'Security System', 'Algorithm']","사이버 상의 공격과 범죄가 기하급수적으로 증가와 해킹 공격들이 지능화, 고도화되면서 해킹 공격방법 및 루트가 복자하고 예측 불가능하게 진화하고 있어 실시간으로 범죄 발생을 예측, 예방과 대규모의 지능적인 해킹 공격에 대한 선제적 대응력 강화하기 위해 스스로 학습해 이상 징후를 감시 및 공격을 차단하여 대응하는 인공지능을 활용한 차세대 보안 시스템 구축을 통한 인공지능기반 보안관제 플랫폼 개발 방안을 제시하고자 한다. 인공지능기반 보안관제 플랫폼은 데이터 수집, 데이터 분석, 차세대 보안체계 운영, 보안체계 관리 등의 기반으로 개발되어야 한다. 빅데이터 기반과 관제시스템, 외부위협정보를 통한 데이터 수집 단계, 수집된 데이터를 전처리 후 정형화시켜 딥러닝 기반 알고리즘을 통해 정·오탐 선별과 이상행위 분석 등을 수행하는 데이터 분석 단계, 분석된 데이터로 통해 예방 · 관제 · 대응 · 분석과 유기적 순환구조의 보안체계를 운영하여 신규위협에 대한 처리범위 및 속도향상을 높이고 정상기반과 비정상행위 식별 등을 강화시키는 차세대 보안체계 운영, 그리고 보안위협 대응 체계 관리, 유해IP 관리, 탐지정책 관리, 보안업무 법제도 관리이다. 이를 통해 방대한 데이터를 통합적으로 분석하고 빠른 시간에 선제적으로 대처가 될 수 있도록 방안을 모색하고자 한다.","As cyber attacks and crimes increase exponentially and hacking attacks become more intelligent and advanced, hacking attack methods and routes are evolving unpredictably and in real time. In order to reinforce the enemys responsiveness, this study aims to propose a method for developing an artificial intelligence-based security control platform by building a next-generation security system using artificial intelligence to respond by self-learning, monitoring abnormal signs and blocking attacks. The artificial intelligence-based security control platform should be developed as the basis for data collection, data analysis, next-generation security system operation, and security system management. Big data base and control system, data collection step through external threat information, data analysis step of pre-processing and formalizing the collected data to perform positive/false detection and abnormal behavior analysis through deep learning-based algorithm, and analyzed data Through the operation of a security system of prevention, control, response, analysis, and organic circulation structure, the next generation security system to increase the scope and speed of handling new threats and to reinforce the identification of normal and abnormal behaviors, and management of the security threat response system, Harmful IP management, detection policy management, security business legal system management. Through this, we are trying to find a way to comprehensively analyze vast amounts of data and to respond preemptively in a short time."
인공지능기술의 IoT 통합보안관제를 위한 데이터모델링,2021,"['인공지능', '통합보안관제', '데이터모델링', '머신러닝', 'Artificial Intelligence', 'IoT', 'Integrated Security Control', 'Data Modeling', 'Machine Learning']","산업 전 분야에 4차 산업혁명의 신기술인 IoT(Internet of Things), AI(Artificial Intelligence), Bigdata 등이 융합되어 새로운 가치를 창출하는 초연결 지능정보사회가 도래되고 있다. 모든 것이 네트워크에 연결되어 데이터가 폭발적으로 증가하고, 인공지능이 스스로 학습하여 지적 판단 기능까지도 가능하다. 특히 사물인터넷은 언제 어디서나 어느 것과도 연결될 수 있는 새로운 통신환경을 제공함에 따라 모든 것들이 연결되는 초 연결을 가능케 하고 있다. 인공지능 기술은 인간이 가진 지각, 학습, 추론, 자연어처리 등의 능력을 컴퓨터가 실행할 수 있도록 구현되고 있다. 인공지능은 기계학습, 딥러닝(Deep leearning), 자연어처리, 음성인식, 시각인식 등 첨단기술을 개발하는 방향으로 발전되고 있으며, 안전, 의료, 국방, 금융, 복지 등의 다양한 응용분야에 특화된 소프트웨어와 머신러닝(Machine learning), 클라우드(Cloud) 기술을 포함하고 있다. 이를 통해 인간의 편의와 새로운 가치를 제공하기 위해 산업 전반의 다양한 분야에 활용된다. 하지만, 이와는 반대로 지능적이고 정교해진 사이버 위협들이 증가하고 신기술의 기술적 안전성 확보와 같은 잠재적 역기능들을 동반함에 따라 이에 대한 대응이 필요한 시점이다. 본 논문에서는 이러한 역기능을 해결하기 위한 하나의 방안으로 인공지능기술을 활용하여 IoT 통합보안관제 가능하도록 새로운 데이터모델링(Data modelling) 방안을 제안하였다.","A hyper-connected intelligence information society is emerging that creates new value by converging IoT, AI, and Bigdata, which are new technologies of the fourth industrial revolution, in all industrial fields. Everything is connected to the network and data is exploding, and artificial intelligence can learn on its own and even intellectual judgment functions are possible. In particular, the Internet of Things provides a new communication environment that can be connected to anything, anytime, anywhere, enabling super-connections where everything is connected. Artificial intelligence technology is implemented so that computers can execute human perceptions, learning, reasoning, and natural language processing. Artificial intelligence is developing advanced technologies such as machine learning, deep learning, natural language processing, voice recognition, and visual recognition, and includes software, machine learning, and cloud technologies specialized in various applications such as safety, medical, defense, finance, and welfare. Through this, it is utilized in various fields throughout the industry to provide human convenience and new values. However, on the contrary, it is time to respond as intelligent and sophisticated cyber threats are increasing and accompanied by potential adverse functions such as securing the technical safety of new technologies. In this paper, we propose a new data modeling method to enable IoT integrated security control by utilizing artificial intelligence technology as a way to solve these adverse functions."
Diabetic Retinopathy Diagnosis Based on Deep Learning and Independent Subspace Analysis,2021,"['당뇨성 망막변증 진단', '딥러닝', '독립 부분 공간 분석', '전이 학습', '자기 지도 학습', 'Diabetic Retinopathy Diagnosis', 'Deep Learning', 'Independent Subspace Analysis', 'Transfer Learning', 'Self-supervised Learning']","당뇨성 망막변증 진단 시스템을 개발하기 위해서 안저 영상과 인공지능 기법을 사용하는 것은 산업계에서 유망한 분야중의 하나이다. 당뇨성 망막변증의 검출은 영상의 색깔, 해상도, 밝기의 큰 변동과 클래스간의 불균형 분포를 갖는 데이터, 영상내의 병변이 아주 작아서 힘든 작업이다. 이 논문의 목적은 당뇨성 망막변증의 검출을 위한 더 좋은 방법을 찾는 것이다. 합성곱 신경회로망에 기반한 딥러닝과 독립 부분 공간 알고리즘을 표현을 학습하고 안저 데이터로부터 특징들을 추출하기 위해서 구현하였다. 이렇게 추출된 특징들은 당뇨성 망막변증을 검출하기 위해 분류기에 입력된다. 감독학습을 사용하여 당뇨성 망막변증을 검출하는데 최상의 결과를 얻었다.","Using fundus images and artificial intelligence(AI) technology to develop a Diabetic Retinopathy(DR) diagnostic system has been one of the hot research topics in the industry. DR detection is a challenging task due to tiny lesions in the images, inter-class imbalanced data distribution, and a huge variation in the brightness, resolution, and color of images. The aim of this paper is to explore better ways for DR detection. Convolutional neural network(CNN) based deep learning and independent subspace analysis(ISA) algorithm are implemented to learn representation and extract features from fundus data. Then these extracted features go through a classification to detect DR. We achieved the best result of DR detection performed using supervised learning."
제품-기술로드맵 개발을 강화하기 위한 예측모델링에 관한 실증 연구,2021,"['기술기획', '제품-기술로드맵', '데이터마이닝', '딥러닝', '기술예측', 'Technical planning', 'Product-Technical roadmap', 'Data mining', 'Technology forecasting']","최근 시스템 반도체 발전으로 인하여 자동차 산업의 전장(電装)에 대한 기술혁신이 빠르게 진행되고 있다. 특히, 자동차의 전장화는 자동차 부품업체들의 기술개발 경쟁을 가속화시키고 있으며, 개발 주기 또한 빠르게 변화하고 있다. 이러한 변화로 인하여 연구개발에 대한 전략과 기획의 중요성은 더욱 강화되고 있다. 자동차 산업의 패러다임 변화로 인하여, 연구개발 전략 중의 하나인 제품-기술로드맵(P/TRM)은 기획 단계에서 기술예측, 기업의 기술수준평가, 기술획득방법(Make/Collaborate/Buy) 등의 분석을 통하여 개발이 이루어져야 한다.제품-기술로드맵은 제품과 기술의 고객 니즈를 파악하고 기술의 선정, 개발방향을 설정하는 툴(Tool)로써, 미래의 발전방향 추세를 예측하고 매크로(Macro) 트랜드의 전략적 방향성과 목표를 설정하는데 사용된다. 하지만, 대부분의 기업에서는 해당 기술의 논문이나 특허 분석, 전문가 델파이에 주로 의존하는 정성적인 방법을 통하여 제품-기술로드맵을 개발하고 있다.본 연구는 가트너의 하이프 사이클과 누적이동평균 기반 데이터 전처리, 딥러닝(LSTM) 시계열 분석 기법을 융합하여 자동차 산업 중심으로 제품-기술로드맵을 보완하고 강화시킬 수 있는 시뮬레이션을 통하여 실증 연구를 진행하였다. 본 논문에서 제시한 실증 연구는 자동차 산업 뿐만 아니라, 범용적으로 타제조업 분야에서도 사용 가능할 수 있다.또한, 기업적인 측면에서는 그동안 정성적인 방법에 의존하던 로드맵 작성 방법에서 탈피하여 좀 더 정확한 제품-기술로드맵을 통하여 적기에 시장에 제품을 제공함으로써 선도업체로 나아가기 위한 밑거름이 될 것이라고 사료된다.","Due to the recent development of system semiconductors, technical innovation for the electric devices of the automobile industry is rapidly progressing. In particular, the electric device of automobiles is accelerating technology development competition among automobile parts makers, and the development cycle is also changing rapidly. Due to these changes, the importance of strategic planning for R&D is further strengthened. Due to the paradigm shift in the automobile industry, the Product-Technical Roadmap (P/TRM), one of the R&D strategies, analyzes technology forecasting, technology level evaluation, and technology acquisition method (Make/Collaborate/Buy) at the planning stage.The product-technical roadmap is a tool that identifies customer needs of products and technologies, selects technologies and sets development directions. However, most companies are developing the product-technical roadmap through a qualitative method that mainly relies on the technical papers, patent analysis, and expert Delphi method.In this study, empirical research was conducted through simulations that can supplement and strengthen the product-technical roadmap centered on the automobile industry by fusing Gartner's hype cycle, cumulative moving average-based data preprocessing, and deep learning (LSTM) time series analysis techniques. The empirical study presented in this paper can be used not only in the automobile industry but also in other manufacturing fields in general.In addition, from the corporate point of view, it is considered that it will become a foundation for moving forward as a leading company by providing products to the market in a timely manner through a more accurate product-technical roadmap, breaking away from the roadmap preparation method that has relied on qualitative methods."
전라남도 섬 지역의 난온대 상록활엽수림 복원을 위한 적합지 예측,2021,"['Sentinel-2 위성영상', '딥러닝', '내성 범위', '1km 기후 격자', 'SENTINEL-2 SATELLITE IMAGE', 'DEEP LEARNING', 'TOLERANCE RANGE', '1-km CLIMATE GRID']","국내 섬 지역은 감독 부실과 관광 등으로 인해 산림 훼손이 심각한 상황이다. 한반도 서남해안 지역의 난온대 기후대 원식생은 상록활엽수림이라서, 이곳을 원식생으로 복원이 바람직하다. 따라서 본 연구에서는 전남의 섬 지역 산지를 대상으로, 현존 상록활엽수림의 환경 요인을 분석하여 상록활엽수림 북원 적합지를 도출하였다. 이를 위해 딥러닝(deep learning) 알고리즘을 이용하여 Sentinel-2 위성영상에서 연구 대상지의 식생 유형을 6가지로 분류하였고, 분류된 식생 유형의 위치 및 지형, 기후 속성을 측정하여 상록활엽수림의 내성 범위(tolerance range)를 분석하였다. 분석 결과, 현존 상록활엽수림은 인간의 간섭이 적은, 고도가 높고 경사가 급한 지역에 상대적으로 높은 비율로 분포하였다. 이와 같은 인위적인 간섭으로 현존 상록활엽수림은 타 식생 유형보다 오히려 연평균기온이 낮은 곳에 분포하는 경향을 보였는데, 이는 고도가 높을수록 기온은 낮아지기 때문이다. 여러 환경 요인 중 인간의 간섭에 따른 영향을 배제하고, 상록활엽수림의 복원 적합지를 파악할 수 있는 환경 요인에는 위도와 최한월 평균기온(1월)이 있었다. 상록활엽수림 내성 범위 분석 결과, 위도 34.7° 이남, 최한월평균기온 1.7°C 이상인 지역에 주로 생육하는 것으로 나타나, 이 조건에 맞는 지역을 상록활엽수림 복원 적합지로 예측하였다. 전남 섬 지역의 산지 중 상록활엽수림 복원 적합지 면적은 614.5㎢로 전체 연구 대상지의 59.0%, 연구 대상지 중 농경지 등을 제외한 산림 식생 지역의 73.4%를 차지하였다. 본 연구의 결과를 바탕으로 향후 구체적인 섬 지역 산림복원계획과 예산을 수립해야 할 것이다.","Poor supervision and tourism activities have resulted in forest degradation in islands in Korea. Since the southern coastal region of the Korean peninsula was originally dominated by warm-temperate evergreen broad-leaved forests, it is desirable to restore forests in this region to their original vegetation. In this study, we identified suitable areas to be restored as evergreen broad-leaved forests by analyzing the environmental factors of existing evergreen broad-leaved forests in the islands of Jeollanam-do. We classified forest lands in the study area into six vegetation types from Sentinel-2 satellite images using a deep learning algorithm and analyzed the tolerance ranges of existing evergreen broad-leaved forests by measuring the locational, topographic, and climatic attributes of the classified vegetation types. Results showed that evergreen broad-leaved forests were distributed more in areas with a high altitudes and steep slope, where human intervention was relatively low. The human intervention has led to a higher distribution of evergreen broad-leaved forests in areas with lower annual average temperature, which was an unexpected but understandable result because an area with higher altitude has a lower temperature. Of the environmental factors, latitude and average temperature in the coldest month (January) were relatively less contaminated by the effects of human intervention, thus enabling the identification of suitable restoration areas of the evergreen broad-leaved forests. The tolerance range analysis of evergreen broad-leaved forests showed that they mainly grew in areas south of the latitude of 34.7° and a monthly average temperature of 1.7°C or higher in the coldest month. Therefore, we predicted the areas meeting these criteria to be suitable for restoring evergreen broad-leaved forests. The suitable areas cover 614.5 ㎢, which occupies 59.0% of the total forest lands on the islands of Jeollanamdo, and 73% of actual forests that exclude agricultural and other non-restorable forest lands. The findings of this study can help forest managers prepare a restoration plan and budget for island forests."
웹 서버 기반의 홀로그램 영상 제작 파이프라인 시스템 구현,2021,"['홀로그램 이미지', '홀로그램 초상화', '딥러닝', '웹서버', '파이프라인', 'Hologram image', 'Hologram portraits', 'Deep learning', 'Web server', 'Pipeline']",본 논문은 웹 서버 기반 환경에서 홀로그램 영상 제작을 위한 파이프라인 시스템을 제안하였다. 기존 홀로그램 영상 제작을 위해 시간 및 공간적인 제약이 존재한다. 제안하는 시스템을 통해 사용자에게 접근성을 높여 고품질의 홀로그램 영상을 획득하는 것을 목적으로 하였다. 웹 환경에서 사용자가 촬영한 동영상을 서버로 전송하여 후반 작업 을 거쳐 홀로그램 영상 제작을 위한 프레임으로 변환하는 구조이다. 고품질 홀로그램 영상 획득을 위해 후반 작업은 딥러닝 기반의 알고리즘을 사용하였다. 제안하는 시스템은 사용자 편의를 위해 웹 환경에서 다양한 서비스 도구를 제 공하였다. 이 방법을 통하여 제약된 공간이 아닌 웹 환경에서 영상을 촬영하기 때문에 홀로그램 영상 제작 시 사용자 접근성을 높였다.,"In this paper, we proposed a pipeline system for holographic image production in a web server-based environment. There are time and spatial constraints for the existing holographic image production. The purpose of the proposed system is to obtain high-quality holographic images by reducing accessibility to users. It is a structure in which a video captured by a user in a web environment is transmitted to a server and converted into a frame for holographic image production through post-production. For high-quality holographic image acquisition, post-processing uses a deep learning-based algorithm. The proposed system provides various service tools in the web environment for user convenience. Through this method, the user's accessibility is improved when producing holographic images because images are taken in a web environment rather than in a limited space."
인공지능과 도덕적 기계 -칸트적 모델과 흄적 모델,2021,"['인공지능', '도덕적 기계', '인공적 도덕 행위자', '초지능', '인간지능', '자연지능', '인공지능 로봇', '규칙 기반 윤리', '알고리즘', '딥러닝', '빅데이터', '기계학습 알고리즘', '인공신경망', 'Artificial Intelligence', 'Moral Machine', 'Artificial Moral Agent', 'Robot', 'Human Intelligence', 'Superintelligence', 'Natural Intelligence', 'Artificial Neural Network', 'Artificial species', 'Rule-based system', 'Deep Learning', 'Big Data', 'Machine studying algorithm']","인공지능은 정보와 규칙의 체계이며, 코딩과 프로그래밍, 딥러닝 알고리즘의 형식 체계이다. 딥러닝 2.0 버전은 인공신경망 구조를 기반으로 빅데이터를 스스로 학습하며 정밀하고 정확한 계산과 신속한 판단으로 막힘 없이 일을 처리한다. 심지어는 자기 의견을 만들고 주저없이 실천한다. 마치 이론이성과 실천이성이 하나로 통합되어 있는 이상적인 존재처럼 보인다. 인간의 경우에는 유능하면서도 나쁜 사람이 존재하지만, 도덕적으로 옳은 일만 선택하는 인공지능을 도덕적으로 진보한 인공적 행위자로서 도덕적 기계로 볼 수 있다. 그러나 우리는 일반적으로 ‘도덕적’이라는 말을 스스로 생각하고 판단하는 의지적 선택이 가능한 존재에게 적용한다. 인간은 이러한 의미의 도덕적 자율성을 지닌 존재로 간주된다. 이에 의하면, 도덕적 기계는 원칙적으로 불가능하다. 그러므로 인공적 도덕 행위자는 자동기계의 자동성에 지나지 않는 공학적 자율성만을 지닌 존재로 보아야 한다. 그러나 이는 특정한 도덕적 관점을 채택한 경우에만 타당하다는 시각도 존재한다. 이 글은 ‘도덕’을 이해하는 다양한 관점이 존재할 수 있다는 입장에서 도덕적 기계의 가능한 모델을 설계해보려는 시도이다.","Artificial intelligence is a system of information and rules, and a formal system of coding, programming, and deep learning algorithms. Deep Learning 2.0 version is an algorithmic operating system based on artificial neural network structure, and it learns big data on its own and handles things without being blocked by precise and accurate calculations and quick judgments. It seems like an ideal being that combines theoretical and practicality into one. In the case of humans, there are capable and bad people, but artificial intelligence, which chooses only morally right things, can be seen as artificial moral agents or moral machines. However, we generally apply the term ""moral"" to those who are free to choose to think and judge for themselves. Human beings are considered to have this sense of moral autonomy. According to this, moral machines are impossible in principle. Thus, artificial moral agents should be viewed as beings with only engineering autonomy, which is nothing more than the automation of automatic machines. However, there is also a view that this is only reasonable if a particular moral view of moral autonomy is adopted. This article attempts to design the possible models of the moral machine in the position that there may be a variety of perspectives understanding ‘moral’."
로봇 주행을 위한 아웃도어 환경에서의 노면 인식 시스템,2021,"['주행로 인식', '의미론적 객체 분할', '딥러닝', 'Road Recognition', 'Semantic Segmentation', 'Deep Learing']","오늘날 정확한 노면 인식 시스템 구축을 위해서는 딥러닝 기반의 의미론적 객체분할 기술의 적용이 필수적이다. 하 지만 실세계에서 충분히 존재할 수 있는 야지 장면에서 노면인식을 위한 의미론적 객체분할 데이터 셋은 아직까지도 개발되지 않았고, 그렇기 때문에 의미론적 객체분할 기술이 야지 노면 인식 시스템에서 적용된 연구 사례도 매우 적 다. 우리는 이러한 문제를 해결하기 위하여 야지 환경에서의 노면 인식 데이터 셋을 구축하고, 지금까지 적용되지 못했던 의미론적 객체분할 기술들을 적용 및 최적하고 분석한다. 실험 결과 우리는 우리의 야지 노면 인식 데이터 셋에서 980FPS의 연산속도로 89.34 mIoU를 달성하였다.","Embedding technology into robot platforms is a very challenging task. In this work, we study a realistic road recognition system based on deep learning for robot embeddings. In particular, deep learning-based road recognition research is accessible with semantic segmentation techniques. However, Semantic segmentation datasets for road recognition also do not exist, and there are very few related studies. For this reason, developing algorithms for real-world platform configurations becomes very difficult. To solve problem, we build our own road recognition dataset in an outdoor environment and describe and analyze the realistic issues encountered while learning Road Recognition algorithms. Furthermore, we apply acceleration methodologies that are essential for robot embedding. As a result, we achieve road recognition accuracy of 89.34 mIoU and computational speed of 980 FPS."
Lasso 회귀분석을 활용한 농산물 가격예측 모델 변수 선정 연구,2021,"['농산물 가격예측', 'LSTM', 'Lasso회귀분석', '변수선정', 'Selection of variables', 'Forecasting Model of Agricultural Products Price using', 'LSTM', 'Lasso regression']","농산물 가격 파동 문제를 해결하기 위해 딥러닝 모델을 연구하였다. 선행연구를 기반으로 기본변수를 선정 후, lasso 회귀분석을 적용해 최적 변수를 선정하여 LSTM모델에 적용하여 RMSE로 성능을 비교하였다. 최적 변수를 이용했을 때, 양파와 대파의 1, 3, 5, 7일 후 가격 예측의 RMSE가 평균적으로0.0229, 0.0019씩 감소하였다. lasso 회귀분석을 활용해 최적 변수 선정은 모델의 정확도를 향상시키며, lasso 회귀분석을 이용해 선정된 최적 변수들을 이용한 딥러닝 농산물 가격 예측 모델은 가격 파동을 완화에 활용될 수 있을 것으로 예상된다.","A deep learning model was studied to solve the problem of agricultural product price fluctuations. After selecting the basic variable based on previous studies, the optimal variable was selected by applying laso regression and applied to the LSTM model to compare the performance with RMSE. When using the optimal variable, the RMSE of the price prediction decreased by 0.0229, 0.0019 on average after 1, 3, 5, and 7 days of onions and leek price The selection of optimal variables using lasso regression was effective, and the LSTM agricultural product price prediction model using the optimal variables selected using lasso regression is expected to be used to alleviate price fluctuations."
질환 예측 서비스를 위한 의학지식 융합시스템 설계와 구현,2021,"['질환 예측', '의학지식 융합', '의학지식 추론', '머신러닝', '딥러닝', '생체신호분석', 'disease prediction', 'medical knowledge convergence', 'medical knowledge inference', 'machine learning', 'deep learning', 'bio-signal analysis']","최근 코로나 팬데믹 상황으로 인하여 비대면 원격진료를 통한 질환 예측 서비스에 대한 관심이 커지고 있다. 기존의 질환 예측 및 헬스케어 서비스에서는 환자의 건강, 기저질환, 생활습관 등 관련 의학지식 등을 고려하지 않고, 오직 실시간으로 수집하는 생체신호 데이터만을 사용하였다. 또한, 의학지식 베이스 기반의 질환 예측 큐레이션 서비스는 환자의 생체데이터를 고려하지 않는 일반적인 의학지식만을 사용하였다. 이러한 질환 예측 및 헬스 서비스의 한계를 해결하기 위해, 본 논문에서는 실시간 생체신호 데이터와 의학지식베이스를 결합한 새로운 질환 예측 및 헬스 서비스를 지원할 수 있는 의학지식 융합시스템을 제안한다. 제안하는 시스템은 생체신호를 통한 기계학습 및 딥러닝 기반 방법과 온톨로지 형태의 의학지식베이스 기반 방법을 융합하였다. 이를 위해서 생체신호 데이터의 예측모델 학습 시, 의학지식베이스를 통한 피처확장 방법과 예측모델기반 예측결과의 의학지식베이스 연계를 통한 의학지식베이스 증강방법을 설계에 반영하였다. 따라서, 제안한 시스템은 보다 일반적이고 의료현장에서의 활용성이 높은 시스템이라고 할 수 있다. 본 논문에서는 제안한 시스템의 성능과 활용 가능성을 검증하기 위해, 뇌혈관 질환 예측 서비스를 대상으로 시스템을 설계 및 개발하였다.","Due to the COVID-19 pandemic, there has been an increasing interest in digital healthcare technologies, such as telemedicine and early disease prediction systems. Current disease prediction and healthcare services used only bio-signals data collected in real-time without considering the patient""s state of health, underlying disease, lifestyle, etc. Also, medical knowledge-based disease prediction services do not utilize bio-signals data. To overcome these limitations, we propose a new medical knowledge convergence system that combines a medical knowledge-based system with real-time bio-signals data. The proposed system uses various machine learning and deep learning algorithms with bio-signals data and medical ontologies. Feature extension and data augmentation methods were applied to the medical knowledge base and real-time bio-signals data to train the prediction model. The new system is more general and has great practical utility in the medical field. In this paper, the system performance and usability of the new system were verified for prediction of stroke."
Deep Learning-based Target Masking Scheme for Understanding Meaning of Newly Coined Words,2021,"['Target Masking', 'Deep Learning', 'BERT', 'Newly Coined Words', 'Sentiment Analysis', '표적 마스킹', '딥러닝', '신조어', '감성분석']","최근 대량의 텍스트 분석을 위해 딥 러닝(Deep Learning)을 활용하는 연구들이 활발히 수행되고 있으며, 특히 대량의 텍스트에 대한 학습 결과를 특정 도메인 텍스트의 분석에 적용하는 사전 학습 언어 모델(Pre-trained Language Model)이 주목받고 있다. 다양한 사전 학습 언어 모델 중 BERT(Bidirectional Encoder Representations from Transformers) 기반 모델이 가장 널리 활용되고 있으며, 최근에는 BERT의 MLM(Masked Language Model)을 활용한 추가 사전 학습(Further Pre-training)을 통해 분석 성능을 향상시키기 위한 방안이 모색되고 있다. 하지만 전통적인 MLM 방식은 신조어와 같이 새로운 단어가 포함된 문장의 의미를 충분히 명확하게 파악하기 어렵다는 한계를 갖는다. 이에 본 연구에서는 기존의 MLM을 보완하여 신조어에 대해서만 집중적으로 마스킹을 수행하는 신조어 표적 마스킹(NTM: Newly Coined Words Target Masking)을 새롭게 제안한다. 제안 방법론을 적용하여 포털 ‘N’사의 영화 리뷰 약 70만 건을 분석한 결과, 제안하는 신조어 표적 마스킹이 기존의 무작위 마스킹에 비해 감성 분석의 정확도 측면에서 우수한 성능을 보였다.","Recently, studies using deep learning to analyze a large amount of text are being actively conducted. In particular, a pre-trained language model that applies the learning results of a large amount of text to the analysis of a specific domain text is attracting attention. Among various pre-trained language models, BERT(Bidirectional Encoder Representations from Transformers)-based model is the most widely used. Recently, research to improve the performance of analysis is being conducted through further pre-training using BERT""s MLM(Masked Language Model). However, the traditional MLM has difficulties in clearly understands the meaning of sentences containing new words such as newly coined words. Therefore, in this study, we newly propose NTM(Newly coined words Target Masking), which performs masking only on new words. As a result of analyzing about 700,000 movie reviews of portal ""N"" by applying the proposed methodology, it was confirmed that the proposed NTM showed superior performance in terms of accuracy of sensitivity analysis compared to the existing random masking."
데이터 재사용 기법을 이용한 저 면적 DNN Core,2021,"['Data Reuse', 'Round Robin', 'BSPE', 'Demux by index', 'Deep Learning']",임베디드 환경에서의 NPU는 적은 하드웨어 자원으로 딥러닝 알고리즘을 수행한다. 데이터를 재사용하는 기법을 활용하면 적은 자원으로 딥러닝 알고리즘을 효율적으로 연산할 수 있다. 선행연구에서는 데이터 재사용을 위해 ScratchPad에서 shifter를 사용해 데이터를 재사용한다. 하지만 ScratchPad의 Bandwidth가 커짐에 따라 shifter 역시 많은 자원을 소모한다. 따라서 Buffer Round Robin방식을 사용한 데이터 재사용 기법을 제시한다. 본 논문에서 제시하는 Buffer Round Robin 방식을 사용하여 기존의 방식보다 약 4.7%의 Chip Area를 줄일 수 있었다.,"NPU in an embedded environment performs deep learning algorithms with few hardware resources. By using a technique that reuses data, deep learning algorithms can be efficiently computed with fewer resources. In previous studies, data is reused using a shifter in ScratchPad for data reuse. However, as the ScratchPad’s bandwidth increases, the shifter also consumes a lot of resources. Therefore, we present a data reuse technique using the Buffer Round Robin method. By using the Buffer Round Robin method presented in this paper, the chip area could be reduced by about 4.7% compared to the conventional method."
불균형 자료의 분류분석 방법별 성능 비교와 접근 전략 연구,2021,"['불균형 자료', '로지스틱 회귀모형', '서포트벡터 머신', '딥러닝', 'Tukey의 다중비교', 'imbalanced data', 'logistics regression model', 'support vector machine', 'deep learning', 'Tukey multiple comparison']","불균형 자료에 대한 분류분석을 하기 위해서는 두 가지 선택의 문제에 직면하게 된다. 하나는 분류분석을 위한 모형의 선택이고 또 다른 하나는 불균형 문제를 해결하기 위한 방법의 선택이다. 그래서 이 논문에서는 훈련표본의 규모나 독립변수의 수, 불균형 정도 등과 같은 데이터의 특징을 고려한 불균형 자료에 대한 순차적인 접근 전략 문제를 다루었다. 이를 위해 이진 분류 분석의 대표적인 모형인 로지스틱 회귀모형, 서포트벡터 머신, 딥러닝 방법을 자료의 특성에 따른 분류 성능을 비교하기 위한 이론적 고찰과 모의실험을 시행하였다. 그리고 자료의 불균형을 해결하기 위한 개선 방법들과 조합했을 때 Tukey의 다중비교를 통하여 분류 성능이 좋은 최적의 결과를 얻기 위한 접근 전략을 식별하기 위한 모의실험을 하였다. 모의실험 결과 자료의 특성중 훈련표본의 수량과 불균형 여부가 지배적인 요소로 작동되는 것을 확인할 수 있었으며, 훈련 표본이 적은 경우는 로지스틱 회귀모형으로 접근하여 과대추출 방법으로 자료의 불균형 문제를 해결하는 방법이 좋고, 훈련표본이 많은 경우는 딥러닝 방법으로 접근하여 가중치 방법이나 과소추출 방법으로 자료의 불균형을 개선하는 방법이 성능이 우수한 추정 결과를 얻을 수 있는 접근 전략임을 확인하였다.","In order to perform a classification analysis on imbalanced data, we are faced with two choices. One is the selection of a model for classification analysis, and the other is the selection of a method to solve the imbalance problem. Therefore, in this paper, I dealt with the problem of sequential approach to imbalanced data, taking into account the characteristics of the data such as the size of the training sample, the number of independent variables, and the degree of imbalance. A simulation is conducted to compare the logistic regression model, support vector machine, and deep learning, which are representative models used for binary classification analysis, to compare the classification performance according to the characteristics of the data. In addition, a simulation was performed to identify the approach strategy for obtaining the optimal result with good classification performance through Tukey s multiple comparison when combined with the methods to resolve the imbalance problem. As a result of the simulation, it was confirmed that the number of acquired samples and the presence of imbalance among the characteristics of the data operate as the dominant factors. In the case of small data, the logistic regression model is the best when combine with the over-sampling method to solve the data imbalance problem. In the case of big data, it was confirmed that the deep learning is the best when combine with the weighed estimation or the under sampling method to resolve the data imbalance problem."
단노출 플래시 스마트폰 영상에서 저속 동조 영상 생성,2021,"['저속 동조', '저조도 영상 개선', '딥러닝', 'Slow sync', 'low-light image enhancement', 'deep learning']","저속 동조는 촬영자가 장노출과 카메라 플래시를 동시에 이용해서 전경과 배경을 밝게 하는 촬영 기법이다. 단노출 플래시 촬영과 플래시 없는 장노출 촬영과는 달리 저속 동조는 어두운 환경에서의 밝은 전경과 배경을 보장한다. 하지만 스마트폰으로 저속 동조 촬영은 어려운데, 이는 스마트폰 카메라의 플래시는 약한 지속 광이고 노출 시간이 길어지면 플래시를 켜지 못하기 때문이다. 본 연구에서는 단노출 플래시 영상에서 저속 동조 영상을 만드는 딥러닝 방법을 제안한다. 본 연구에서는 공간상에서 가변적인 영상 밝기 개선을 위해 가중치 맵을 적용한 네트워크를 제안한다. 본 연구에서는 지도 학습을 위한 스마트폰 단노출 플래시 영상과 저속 동조 영상 데이터 세트도 제안한다. RAW 영상의 선형성을 이용해 단노출 플래시 영상과 플래시 없는 장노출 영상으로부터 저속 동조 영상을 생성해서 데이터 세트를 구축한다. 실험을 통해 본 연구의 방법이 저속 동조 영상을 효과적으로 생성하는 것을 볼 수 있다.","Slow sync is a photography technique where a user takes an image with long exposure and a camera flash to enlighten the foreground and background. Unlike short exposure with flash and long exposure without flash, slow sync guarantees the bright foreground and background in the dim environment. However, taking a slow sync image with a smartphone is difficult because the smartphone camera has continuous and weak flash and can not turn on flash if the exposure time is long. This paper proposes a deep learning method that input is a short exposure flash image and output is a slow sync image. We present a deep learning network with a weight map for spatially varying enlightenment. We also propose a dataset that consists of smartphone short exposure flash images and slow sync images for supervised learning. We utilize the linearity of a RAW image to synthesize a slow sync image from short exposure flash and long exposure no-flash images. Experimental results show that our method trained with our dataset synthesizes slow sync images effectively."
Research on the Detection of Image Tampering,2021,"['Image', 'Tampering', 'Forensics', 'Deep learning', 'CNN', '이미지', '변조', '포렌식', '딥러닝']","정보의 주요 전달체로서 디지털 이미지는 점점 더 중요해지고 있다. 그러나 이미지 획득 장비의 대중화와 이미지 편집 소프트웨어의 급속한 발전으로 인해, 최근 몇 년간 디지털 이미지 위조사건이 잇따라 발생해 이미지의 신뢰도를 떨어뜨릴 뿐만 아니라 사회와 개인에게도 큰 악영향을 미치고 있다. 이미지 복사-붙여넣기 변조(image copy-paste tampering)는 가장 일반적인 유형의 이미지 변조 중 하나이며, 조작이 쉽고 효과적이기 때문에 디지털 이미지 의미 정보 변경에 자주 사용된다. 본 논문에서는 이미지 복사 및 붙여넣기의 변조 탐지 방법을 연구하여 이미지 콘텐츠의 진정성과 무결성을 보호하는 방법이 제안되었다. 딥러닝의 우수한 학습과 분석능력을 감안해 영상처리작업이 남긴 흔적을 활용해 영상 속 원본 영역과 변조된 영역을 구분하는 딥러닝 기반 변조 검출법 2가지가 제안되었다. 또한 실험을 통해 이론적 근거의 합리성, 변조 탐지, 위치 및 분류의 정확성을 검증하였다.","As the main carrier of information, digital image is becoming more and more important. However, with the popularity of image acquisition equipment and the rapid development of image editing software, in recent years, digital image counterfeiting incidents have emerged one after another, which not only reduces the credibility of images, but also brings great negative impacts to society and individuals. Image copy-paste tampering is one of the most common types of image tampering, which is easy to operate and effective, and is often used to change the semantic information of digital images. In this paper, a method to protect the authenticity and integrity of image content by studying the tamper detection method of image copy and paste was proposed. In view of the excellent learning and analysis ability of deep learning, two tamper detection methods based on deep learning were proposed, which use the traces left by image processing operations to distinguish the tampered area from the original area in the image. A series of experimental results verified the rationality of the theoretical basis, the accuracy of tampering detection, location and classification."
SKU-Net: Improved U-Net using Selective Kernel Convolution for Retinal Vessel Segmentation,2021,"['Deep Learning', 'Retinal Vessel Segmentation', 'Convolutional Neural Network', 'Selective Kernel Convolution', 'U-Net', '딥러닝', '망막 혈관 분할', '합성곱 신경망', '선택적 커널 합성곱']","본 논문에서는 안저영상의 다중 스케일 정보를 다루기 위한 딥러닝 기반의 망막 혈관 분할 모델을 제안한다. 제안 모델은 이미지 분할 딥러닝 모델인 U-Net과 선택적 커널 합성곱을 통합한 합성곱 신경망으로 안저영상에서 눈과 관련된 질병을 진단하는데 중요한 정보가 되는 망막 혈관의 다양한 모양과 크기를 갖는 특징 정보를 추출하고 분할한다. 제안 모델은 일반적인 합성곱과 선택적 커널 합성곱으로 구성된다. 일반적인 합성곱 층은 같은 크기 커널 크기를 통해 정보를 추출하는 반면, 선택적 커널 합성곱은 다양한 커널 크기를 갖는 브랜치들에서 정보를 추출하고 이를 분할 주의집중을 통해 적응적으로 조정하여 결합한다. 제안 모델의 성능 평가를 위해 안저영상 데이터인 DRIVE와 CHASE DB1 데이터셋을 사용하였으며 제안 모델은 두 데이터셋에 대하여 F1 점수 기준 82.91%, 81.71%의 성능을 보여 망막 혈관 분할에 효과적임을 확인하였다.","In this paper, we propose a deep learning-based retinal vessel segmentation model for handling multi-scale information of fundus images. we integrate the selective kernel convolution into U-Net-based convolutional neural network. The proposed model extracts and segment features information with various shapes and sizes of retinal blood vessels, which is important information for diagnosing eye-related diseases from fundus images. The proposed model consists of standard convolutions and selective kernel convolutions. While the standard convolutional layer extracts information through the same size kernel size, The selective kernel convolution extracts information from branches with various kernel sizes and combines them by adaptively adjusting them through split-attention. To evaluate the performance of the proposed model, we used the DRIVE and CHASE DB1 datasets and the proposed model showed F1 score of 82.91% and 81.71% on both datasets respectively, confirming that the proposed model is effective in segmenting retinal blood vessels."
임베디드용 저해상도 적외선 영상 딥컨볼루션신경망,2021,"['Deep Learning', 'CNN', 'VGG', 'Low Resolution', 'Infrared', 'Synthesize Image', '딥러닝', '컨볼루션 신경망', '저해상도', '적외선', '합성영상']","본 논문은 저해상도 적외선영상을 사양이 낮은 임베디드 시스템에서 추론 가능하도록 강화된 VGG 스타일과 Global Average Pooling 조합으로 정확도를 증가시키면서 연산량을 최소화하는 딥러닝 컨볼루션 신경망을 이용한 저해상도 적외선 표적 분류 방법을 제안한다. 제안한 알고리즘은 OKTAL-SE로 생성한 합성영상 클래스 9개 3,723,328개를 분류하였다. 최초 임베디드 추론 가능하도록 파라메터 수가 최소화된 최대풀링 레이어 기준 입력단 8개와 출력단 8개 조합에 비해 강화된 VGG 스타일을 적용한 입력단 4개와 출력단 16개 필터수 조합을 이용하여 연산량은 약 34% 감소시켰으며, 정확도는 약 2.4% 증가시켜 최종 정확도 96.1%을 획득하였다. 추가로 C 코드로 포팅하여 수행시간을 확인하였으며, 줄어든 연산량 만큼 수행 시간이 약 32% 줄어든 것을 확인할 수 있었다.","In this paper, we propose reinforced VGG style network structure for low performance embedded system to classify low resolution infrared image. The combination of reinforced VGG style network structure and global average pooling makes lower computational complexity and higher accuracy. The proposed method classify the synthesize image which have 9 class 3,723,328ea images made from OKTAL-SE tool. The reinforced VGG style network structure composed of 4 filters on input and 16 filters on output from max pooling layer shows about 34% lower computational complexity and about 2.4% higher accuracy then the first parameter minimized network structure made for embedded system composed of 8 filters on input and 8 filters on output from max pooling layer. Finally we get 96.1% accuracy model. Additionally we confirmed the about 31% lower inference lead time in ported C code."
인공지능 기반 사회에 대비한 한국의 현황과 전략,2021,"['인공지능(AI)', '4차 산업혁명', '사람중심', '국가적 차원', '선허용-후규제', '딥러닝', 'Artificial Intelligence (AI)', 'Human-Centered', 'National level', 'the Fourth Industrial Revolution', 'Deep Learning', 'Pre-allowed Post-regulated']","이 글은 인공지능(AI) 기반 사회에 대비한 우리나라의 현황과 국가전략을 분석한 것이다. 2016년 3월 이세돌과 알파고의 바둑 대결에서 딥러닝의 기술이 승리하면서 인공지능은 21세기 4차산업혁명의 핵심 동력으로 부상하였고, 이와 관련하여 최근 세계 주요국은 국가적 차원에서 인공지능 전략과 정책들을 내놓기 시작했다. 우리나라는 2016년 박근혜 정부가 인간중심의 인공지능을 육성하기 위한 기반을 마련하였다. 이어 2019년 말 문재인 정부가 IT 강국을 넘어 AI 강국으로! 의 비전으로 2030년까지 3대 분야에 걸쳐 9가지 인공지능 국가전략을 제시하였으며, 현재 이를 본격적으로 실행하고 있다. 따라서 이 글은 우리나라의 인공지능의 내용과 전략을 체계적으로 분석함으로써 이에 대한 시사점과 의의를 제공하고자 한다.","This article analyzes the current situation and national strategy of Korea in preparation for an artificial intelligence (AI)-based society. Artificial intelligence emerged as the core driving force of the 4th industrial revolution in the 21st century since AI beat humans in the game of Go between Sedol Lee and AlphaGo with ‘Deep Learning’ technology in 2016 in Seoul Korea. Since then, Countries have recently started to come up with artificial intelligence strategies and policies at the national level. In Korea, the Park Geun-hye administration laid the foundation for fostering human-centered artificial intelligence in 2016. ” Then at the end of 2019, the Moon Jae-in government presented national nine strategies in three fields developed by AI within the year of 2030 with the vision of “Going from an IT powerhouse to an AI powerhouse: AI for Everyone, AI of Everything!” Therefore, this paper provides it’s implications by systematically analyzing the contents and strategies of artificial intelligence in Korea."
Automatic Anatomical Classification Model of Esophagogastroduodenoscopy Images Using Deep Convolutional Neural Networks for Guiding Endoscopic Photodocumentation,2021,"['Deep Learning', 'Medical Image Analysis', 'EsophagoGastroDuodenoscopy', 'Stomach Anatomy Site Classification', 'Image Processing', '딥러닝', '의료영상분석', '상부위장관내시경', '해부학적 위치 분류', '영상처리']","위내시경 촬영은 조기에 위 병변을 진단하기 위해서 주로 사용한다. 하지만 위내시경을 했음에도 불구하고 위 내부를 자세히 관찰하지 못해서 10~20% 위 병변을 놓치는 경우가 생기는 것으로 보고되고 있다. 미국, 영국, 일본 등의 일부 국가와 세계내시경협회(Wold Endoscopy Organization)에서는 위내시경 시에 맹점 없는 관찰을 위해서 반드시 촬영해야 할 부위에 대한 촬영지침을 제안한 바 있다. 이에 본 논문에서는 수련의가 내시경을 하는 데 있어 위 내부를 자동으로 맹점 없이 관찰하는데 필요한 딥러닝 기술인 해부학적 분류모델을 제안한다. 제안한 모델은 위내시경 이미지에 적합한 전처리 모듈과 데이터 증강 기술들을 사용한다. 실험결과를 통해 최대 F1 점수 99.6% 분류 성능을 확인하였다. 또한, 실제 데이터를 통한 실험결과에서도 에러율이 4% 미만을 보였다. 이러한 성능을 바탕으로 설명 가능한 모델임을 보여 임상에서의 사용 가능성을 확인하였다.","Esophagogastroduodenoscopy is a method commonly used for early diagnosis of upper gastrointestinal lesions. However, 10-20 percent of the gastric lesions are reported to be missed, due to human error. And countries including the US, the UK, and Japan, the World Endoscopy Organization (WEO) suggested guidelines about essential gastrointestinal parts to take pictures of so that all gastric lesions are observed. In this paper, we propose deep learning techniques for classification of anatomical sites, aiming for the system that informs practitioners whether they successfully did the gastroscopy without blind spots. The proposed model uses pre-processing modules and data augmentation techniques suitable for gastroscopy images. Not only does the experiment result with a maximum F1 score of 99.6%, but it also shows a error rate of less than 4% based on the actual data. Given the performance results, we found the model to be explainable with the potential to be utilized in the clinical area."
Performance Comparison of Korean Dialect Classification Models Based on Acoustic Features,2021,"['Machine Learning', 'Deep Learning', 'MFCC', 'Dialect Classification', 'Speech Analysis', '머신 러닝', '딥러닝', '방언 분류', '성능 비교', '음성 분석']","말소리의 음향 특징을 이용하여 화자에 대한 중요한 사회, 언어학적 정보를 얻을 수 있는데 그 중 한 가지 핵심 특징은 방언이다. 화자의 방언 사용은 컴퓨터와의 상호작용을 방해하는 주요 요소이다. 방언은 발화의 음소, 음절, 단어, 문장 및 구와 같이 다양한 수준에서 구분할 수 있지만 이를 하나하나 식별하여 방언을 구분하기는 어렵다. 이에 본 논문에서는 음성 데이터의 특성 중 MFCC만 사용하는 경량화된 한국어 방언 분류 모델을 제안한다. 한국인 대화 음성 데이터를 통해 MFCC 특징을 활용하는 최적의 방법을 연구하고, 8가지 머신 러닝 및 딥러닝 분류 모델에서 경기/서울, 강원, 충청, 전라, 경상 5개의 한국어 방언 분류 성능을 비교한다. MFCC를 정규화하는 방법으로 대부분의 분류 모델에서 성능을 향상시켰으며, MFCC를 정규화하기 전 분류 모델의 최고 성능과 비교하여 정확도는 1.07%, F1-score는 2.04% 향상된 성능을 기록하였다.","Using the acoustic features of speech, important social and linguistic information about the speaker can be obtained, and one of the key features is the dialect. A speaker""s use of a dialect is a major barrier to interaction with a computer. Dialects can be distinguished at various levels such as phonemes, syllables, words, phrases, and sentences, but it is difficult to distinguish dialects by identifying them one by one. Therefore, in this paper, we propose a lightweight Korean dialect classification model using only MFCC among the features of speech data. We study the optimal method to utilize MFCC features through Korean conversational voice data, and compare the classification performance of five Korean dialects in Gyeonggi/Seoul, Gangwon, Chungcheong, Jeolla, and Gyeongsang in eight machine learning and deep learning classification models. The performance of most classification models was improved by normalizing the MFCC, and the accuracy was improved by 1.07% and F1-score by 2.04% compared to the best performance of the classification model before normalizing the MFCC."
LSTM과 GRU를 활용한 도시공간 특성 기반의 평균기온 예측 모델: 강원도 원주시를 대상으로,2021,"['Prediction of Average temperature', 'Deep-Learning', 'LSTM', 'GRU', 'Wonju', '평균기온 예측 딥러닝', 'LSTM', 'GRU', '원주시']","지구온난화로 인한 기후변화로 연평균기온이 계속해서 상승하는 추세를 보이면서 온열질환 발생률과 사망자 수도 증가하고 있어 이를 위한 다양한 대안과연구가 수행될 필요가 있다. 이에 본 논문에서는 연평균기온 상승률 및 변화량이 높은 원주시를 대상으로 통계분석을 통해 평균기온 상승 관련 변수를 추출하고, 추출된 변수를 토대로 딥러닝 기반의 LSTM과GRU를 활용하여 평균기온을 예측하자 한다. 선행연구 고찰을 토대로 수집한 26개의 변수에 대해 상관분석 및 회귀분석을 통해 3가지 모형을 추출하였고, 이를 바탕으로 LSTM과 GRU 분석을 진행하였다. 분석결과, 변수가 12개인 세 번째 모형에서 테스트 데이터 MSE가 LSTM – 0.4399(2.94°C), GRU – 0.4444 (2.97°C)로 가장 낮게 나타났고, 검증 데이터와 테스트 데이터 간의 MAE 차이가 거의 발생하지 않았다.본 논문은 연평균기온 상승 문제 적응을 위한 데이터확보 방안으로 통계분석을 통해 변수를 추출하고, 딥러닝을 활용해 평균기온을 예측하였다는 점에서 의의가 있다. 또한, 평균기온 변화 추세 예측과 함께 원주시의 평균기온 상승에 영향을 미치는 도시공간 요소를 추출하여, 획일화된 기후변화 적응방안이 아닌지역별 영향 요소를 고려한 적절한 방안을 마련할 수있을 것으로 기대된다.","As the annual average temperature continues to rise due to climate change caused by global warming, the incidence of heat diseases and the number of deaths are also increasing, which is expected to require various alternatives and research. In this study, the average temperature rise-related variables are extracted through statistical analysis for Wonju City, where the average temperature increase rate and change are high, and the average temperature is predicted by utilizing deep learning-based LSTM and GRU based on the extracted variables. Three models were extracted through correlation and regression analysis for 26 variables collected based on prior research consideration, based on which LSTM and GRU analysis were conducted. The analysis showed the lowest MSE of LSTM – 0.4399(2.94°C), GRU – 0.4444(2.97°C) in the third model with 12 variables, with little MAE difference between validation and test data. This study is significant in that it extracted variables through statistical analysis and predicted average temperature rise using deep learning as a data acquisition method for adapting the annual average temperature rise problem. In addition, it is expected that urban space factors that affect the average temperature rise in Wonju City will be extracted along with predicting the trend of average temperature change, and appropriate measures will be prepared to take into account regional impact factors, not uniform climate change adaptation."
다중속성 LSTM 모델 기반 TV 시청 패턴 분석 시스템,2021,"['Deep learning', 'Future prediction', 'Watching management', 'Pattern analysis', 'LSTM', '딥러닝', '미래 예측', '시청 관리', '패턴 분석', 'LSTM']","스마트 TV는 인터넷을 기반으로 기존의 TV에 비해 다양한 서비스와 정보를 제공하고 있다. 보다 개인화된 서비스나 정보를 제공하기 위해서는 사용자의 시청 패턴을 분석하고 이를 기반으로 맞춤형 서비스나 정보를 제공해야한다. 제안하는 시스템은 사용자의 TV 시청 패턴을 입력받고 이를 분석하여 사용자에게 맞춤형 정보로써 TV 프로그램이나 영화를 추천한다. 이를 위해 전처리기와 딥러닝(deep learning) 모델로 시스템을 구성하였다. 전처리기는 사용자가 시청한 TV 프로그램의 이름과 해당 TV 프로그램을 시청한 날짜, 시청한 시간 등을 입력하면 이를 정제한다. 그리고 정제된 데이터를 다중속성 LSTM 모델이 학습하고 예측을 수행하게 된다. 제안하는 시스템은 사용자에게 맞춤형 정보를 제공하는 시스템으로써 기존의 IoT 기술과 딥러닝 기술을 융합한 디지털 컨버전스(convergence)의 선도 기술이 될 것으로 사료된다.","Smart TVs provide a variety of services and information compared to existing TVs based on the Internet. In order to provide more personalized services or information, it is necessary to analyze users' viewing patterns and provide customized services or information based on them. The proposed system receives the user's TV viewing pattern, analyzes it, and recommends a TV program or movie as customized information to the user. For this, the system was constructed with a preprocessor and a deep learning model. The preprocessor refines the name of the TV program watched by the user, the date the TV program was watched, and the watched time. Then, the multi-attribute LSTM model trains the refined data and performs prediction.The proposed system is a system that provides customized information to users, and is believed to be a leading technology in digital convergence that combines existing IoT technology and deep learning technology."
미세먼지 위험 단계 예측을 위한 1-D CRNN 모델 설계,2021,"['Fine dust', 'Deep learning', 'CNN', 'RNN', 'Data prediction', '미세먼지', '딥러닝', 'CNN', 'RNN', '데이터 예측']","최근 국내 미세먼지 발생의 증가에 따라 발생하는 인체에 유해한 영향을 줄이기 위하여, 미세먼지 수치를 예측하고 사전 조치를 취할 수 있도록 돕는 기술이 필요해지고 있다. 본 논문에서는 국내 미세먼지 위험 수준을 예측하기 위한 1D Convolutional to Recurrent Neural Network (1-D CRNN) 모델을 제안한다. 제안 된 모델은 딥러닝 신경망의 CNN과 RNN을 결합한 구조이며, 다른 종류의 데이터로 구성된 시계열 데이터 세트에서 데이터 예측을 수행 할 수 있다. 데이터 예측을 위해 국내·외 미세먼지, 풍향, 풍속 데이터를 사용한다. 제안된 모델은 약 76%(부분 최대 84%)의 정확도를 달성했으며, 일반 RNN 모델(53%)보다 정확한 예측 결과를 얻었을 수 있었다. 제안된 모델은 향후 여러 개의 시계열 데이터 세트를 고려해야 하는 데이터 예측 모델 학습 및 실험을 목표로 한다.","In order to reduce the harmful effects on the human body caused by the recent increase in the generation of fine dust in Korea, there is a need for technology to help predict the level of fine dust and take precautions. In this paper, we propose a 1D Convolutional-Recurrent Neural Network (1-D CRNN) model to predict the level of fine dust in Korea. The proposed model is a structure that combines the CNN and the RNN, and uses domestic and foreign fine dust, wind direction, and wind speed data for data prediction. The proposed model achieved an accuracy of about 76%(Partial up to 84%). The proposed model aims to data prediction model for time series data sets that need to consider various data in the future."
치주질환 예측을 위한 치과 X-선 영상에서의 초해상화 알고리즘 적용 가능성 연구,2021,"['치주질환', '치과 X-선 영상', '영상처리', '초해상화 알고리즘', '딥러닝', 'Periodontal disease', 'Dental X-ray image', 'Image processing', 'Super-resolution algorithm', 'Deep learning']","치주질환의 조기 진단률 및 예측 정확도 향상을 위한 X-선 영상 분석은 매우 중요한 분야이다. 이러한 치과 X-선 영상의 화질 개선을 위한 인공 지능 기반의 알고리즘 개발 및 적용에 관한 연구는 전 세계적으로 널리 수행 중이다. 따라서 본 연구의 목표는 치주질환 예측을 위한 치과 X-선 영상에서의 초해상화 알고리즘의 모델링 및 적용 가능성에 관하여 평가하는 것이다. 초해상화 알고리즘은 convolution layer와 ReLU를 기반으로 구성하였고, 저해상도 영상을 2배로 업샘플링 한 영상을 입력으로 사용하였다. 딥러닝 훈련을 위해 사용한 치과 X-선 데이터는 1,500장을 사용하였다. 영상의 정량적 평가는 2가지 영상의 비교를 통해 유사도를 측정할 수 있는 인자인 root mean square error와 structural similarity를 사용하였다. 이와 더불어 최근에 개발된 no-reference 기반으로 사용되는 natural image quality evaluator 와 blind/referenceless image spatial quality evaluator를 추가적으로 분석하였다. 결과적으로 기존에 사용되던 bicubic 기반의 업샘플링 기법을 사용하였을 때에 비하여 제안하는 방법이 치과 X-선 영상에서 평균적으로 유사도와 no-reference 기반의 평가 인자가 각각 1.86 그리고 2.14배 향상됨을 확인하였다. 결론적으로 치주질환의 예측을 위한 초해상화 알고리즘의 치과 X-선 영상에서의 유용성을 증명하였고 향후 다양한 분야에서의 적용 가능성이 높을 것으로 기대된다.","X-ray image analysis is a very important field to improve the early diagnosis rate and prediction accuracy of periodontal disease. Research on the development and application of artificial intelligence-based algorithms to improve the quality of such dental X-ray images is being widely conducted worldwide. Thus, the aim of this study was to design a super-resolution algorithm for predicting periodontal disease and to evaluate its applicability in dental X-ray images. The super-resolution algorithm was constructed based on the convolution layer and ReLU, and an image obtained by up-sampling a low-resolution image by 2 times was used as an input data. Also, 1,500 dental X-ray data used for deep learning training were used. Quantitative evaluation of images used root mean square error and structural similarity, which are factors that can measure similarity through comparison of two images. In addition, the recently developed no-reference based natural image quality evaluator and blind/referenceless image spatial quality evaluator were additionally analyzed. According to the results, we confirmed that the average similarity and no-reference-based evaluation values ​​were improved by 1.86 and 2.14 times, respectively, compared to the existing bicubic-based upsampling method when the proposed method was used. In conclusion, the super-resolution algorithm for predicting periodontal disease proved useful in dental X-ray images, and it is expected to be highly applicable in various fields in the future."
Tongue Segmentation Using the Receptive Field Diversification of U-net,2021,"['Tongue', 'Segmentation', 'Deep Learning', 'U-net', 'Receptive Field', '혀', '분할', '딥러닝', 'U-네트', '수용 영역']","본 논문에서는 U-네트에서 수용 영역을 다양화하여 기존의 모델보다 정확도가 개선된 새로운 혀 영역 분할을 위한 딥러닝 모델을 제안한다. 수용 영역 다양화를 위하여 병렬 컨볼루션, 팽창된 컨볼루션, 상수 채널 증가 등의 방법을 사용하였다. 제안된 딥러닝 모델에 대하여, 학습 영상과 테스트 영상이 유사한 TestSet1과 그렇지 않은 TestSet2의 두 가지 테스트 데이터에 대해 혀 영역검출 실험을 진행하였다. 수용 영역이 다양화됨에 따라 혀 영역 분할 성능이 향상되는 것을 실험결과에서 확인할 수 있었다. 제안한 방법의 mIoU 값은 TestSet1의 경우 98.14%, TestSet2의 경우 91.90%로 U-net, DeepTongue, TongueNet 등 기존 모델의 결과보다 높았다.","In this paper, we propose a new deep learning model for tongue segmentation with improved accuracy compared to the existing model by diversifying the receptive field in the U-net. Methods such as parallel convolution, dilated convolution, and constant channel increase were used to diversify the receptive field. For the proposed deep learning model, a tongue region segmentation experiment was performed on two test datasets. The training image and the test image are similar in TestSet1 and they are not in TestSet2. Experimental results show that segmentation performance improved as the receptive field was diversified. The mIoU value of the proposed method was 98.14% for TestSet1 and 91.90% for TestSet2 which was higher than the result of existing models such as U-net, DeepTongue, and TongueNet."
Deep Learning-based Pes Planus Classification Model Using Transfer Learning,2021,"['Pes planus', 'Deep learning', 'Convolutional neural network(CNN)', 'Transfer learning', 'Data Augmentation', '편평발', '딥러닝', '합성곱 신경망', '전이학습', '데이터 증폭']","본 연구는 기존 편평발 측정을 위해 사용되던 다양한 방법의 한계를 보완할 수 있는 새로운 측정 방법으로 전이학습을 적용한 딥러닝 기반 편평발 분류 방법론을 제안한다. 편평발 88장, 정상발 88장으로 이루어진 총 176장의 이미지 데이터를 활용하여, 적은 데이터로도 우수한 예측 모델을 생성할 수 있는 데이터 증폭 기술과 사전학습 모델인 VGG16 구조를 활용하는 전이학습 기술을 적용하여 제안 모델의 학습을 진행하였다. 제안 모델의 우수성을 확인하기 위하여 기본 CNN 기반 모델과 제안 방법론의 예측 정확도를 비교하는 실험을 수행하였다. 기본 CNN 모델의 경우 훈련 정확도는 77.27%, 검증 정확도는 61.36%, 그리고 시험 정확도는 59.09%로 나타났으며, 제안모델의 경우 훈련 정확도는 94.32%, 검증 정확도는 86.36%, 그리고 시험 정확도는 84.09%로 나타나 기본 CNN 모델에 비해 제안 모델의 정확도가 큰 폭으로 향상된 것을 확인하였다.","This study proposes a deep learning-based flat foot classification methodology using transfer learning. We used a transfer learning with VGG16 pre-trained model and a data augmentation technique to generate a model with high predictive accuracy from a total of 176 image data consisting of 88 flat feet and 88 normal feet. To evaluate the performance of the proposed model, we performed an experiment comparing the prediction accuracy of the basic CNN-based model and the prediction model derived through the proposed methodology. In the case of the basic CNN model, the training accuracy was 77.27%, the validation accuracy was 61.36%, and the test accuracy was 59.09%. Meanwhile, in the case of our proposed model, the training accuracy was 94.32%, the validation accuracy was 86.36%, and the test accuracy was 84.09%, indicating that the accuracy of our model was significantly higher than that of the basic CNN model."
지역 차분 프라이버시를 이용한 프라이버시 보존 교통량 예측,2021,"['Local difference privacy', 'Traffic volume estimation', 'Deep learning', 'Data Privacy', '지역 차분 프라이버시', '교통량 예측', '딥러닝', '데이터 프라이버시']","본 논문에서는 지역 차분 프라이버시(Local Differential Privacy, LDP) 기법을 이용하여 프라이버시를 보호하면서 수집한 차량 위치 데이터와 딥러닝 기법을 이용하여 교통량을 예측하기 위한 기법을 제시한다. 제시한 기법은 데이터를 수집하는 과정과 수집한 데이터를 이용하여 교통량을 예측하는 과정으로 구성된다. 첫 번째 단계에서는 데이터 수집 과정 중에 발생할 수 있는 프라이버시 침해 문제를 해결하기 위해 LDP 기법을 적용하여 차량의 위치 데이터를 수집한다. LDP 기법은 데이터 수집 시 원본 데이터에 노이즈를 추가해 사용자의 민감한 데이터가 외부에 노출되는 것을 방지한다. 이를 통해 운전자의 프라이버시를 보존하면서 차량의 위치 데이터를 수집할 수 있다. 두 번째 단계에서는 첫 번째 단계에서 수집한 데이터에 딥러닝 기법을 적용하여, 교통량을 예측한다. 또한, 본 논문에서 제안한 기법의 우수성을 입증하기 위해, 실데이터를 이용한 성능 평가를 진행한다. 성능 평가 결과는 본 논문에서 제안한 기법이 사용자의 프라이버시를 보호하면서 수집된 데이터를 이용하여 효과적으로 교통량을 예측할 수 있음을 입증한다.","In this paper, we present a method for effectively predicting traffic volume based on vehicle location data that are collected by using LDP (Local Differential Privacy). The proposed solution in this paper consists of two phases: the process of collecting vehicle location data in a privacy-presering manner and the process of predicting traffic volume using the collected location data. In the first phase, the vehicle’s location data is collected by using LDP to prevent privacy issues that may arise during the data collection process. LDP adds random noise to the original data when collecting data to prevent the data owner’s sensitive information from being exposed to the outside. This allows the collection of vehicle location data, while preserving the driver’s privacy. In the second phase, the traffic volume is predicted by applying deep learning techniques to the data collected in the first stage. Experimental results with real data sets demonstrate that the method proposed in this paper can effectively predict the traffic volume using the location data that are collected in a privacy-preserving manner."
인공지능을 이용한 영화제작 : 시각효과를 중심으로,2021,"['Film Production', 'Visual Effects', 'Artificial Intelligence', 'Pipeline', 'Machine Learning', 'Deep Learning', '영화제작', '시각효과', '인공지능', '파이프라인', '머신러닝', '딥러닝']","영화는 대중에게 처음 소개된 이래로 테크놀로지의 발전과 변화 과정을 함께하고 있다. 영화 제작 과정에 시각효과를 중심으로 한 포스트 프로덕션과 디지털 기술들이 본격적으로 적용되면서 영화 산업은 제작 방식에 있어서 큰 변화를 겪었을 뿐만 아니라 최신 기술들을 폭넓게 수용하며 산업적 기회의 폭을 넓혀가고 있다. 디지털 영화로 변화한 지 오래지 않은 지금, 영화의 디지털화가 시작되기도 전인 1956년 다트머스 회의에서 처음 알려진 인공지능이란 개념이 다시 영화 산업의 큰 변화를 가져올 것으로 예상된다. 디지털 영화의 제작 파이프라인은 거대한 디지털 데이터를 체계적으로 운용하고 만들어 내기 때문에 머신러닝과 딥러닝으로 대표되는 최근 인공지능기술들을 적용하기 용이하고 시각효과 제작 과정에는 반복적인 작업과 분석을 통한 재현이 많고 계산시간이 오래 걸리는 과정들이 있기 때문에 최근 주요 시각효과 스튜디오들을 중심으로 인공지능 기술의 활용이 두드러지고 있다. 본 연구에서는 제작 도구로서 인공지능 기술을 이용한 영화 시각효과 제작 사례에 대한 분석을 통해서 향후 인공지능 기술이 영화 산업을 어떻게 바꿔놓을지 예측하고 시각효과기술로서 인공지능의 산업적 가능성을 조망해 보고자 한다.","After the first to present projected moving pictures to audiences, the film industry has been reshaping along with technological advancements. Through the full-scale introduction of visual effects-oriented post-production and digital technologies in the film-making process, the film industry has not only undergone significant changes in the production, but is also embracing the cutting edge technologies broadly and expanding the scope of industry. Not long after the change to digital cinema, the concept of artificial intelligence, first known at the Dartmouth summer research project in 1956, before the digitalization of film, is expected to bring about a big transformation in the film industry once again. Large volume of clear digital data from digital film-making makes easy to apply recent artificial intelligence technologies represented by machine learning and deep learning. The use of artificial intelligence techniques is prominent around major visual effects studios due to automate many laborious, time-consuming tasks currently performed by artists. This study aims to predict how artificial intelligence technology will change the film industry in the future through analysis of visual effects production cases using artificial intelligence technology as a production tool and to discuss the industrial potential of artificial intelligence as visual effects technology."
인공지능 기법(CNN)을 이용한 음성과 음악구분,2021,"['Speech-Music Discrimination', 'Fingerprint', 'Deep Learning', 'CNN', 'Mel-Spectrum', 'Transfer Learning']","음성, 음악 구분 방법은 전통적으로 퓨리에 분석치의 특성치를 직접 이용하는 방법이 사용되어 왔다. 하지만 딥러닝을 이용하면 end-to-end 방식으로 특성치를 별도로 부여하는 과정을 거치지 않고 구분이 가능하다. 본고에 사용된 자료는 국내 음악방송(FM 89.8MHz)에서 추출된 약 389만개의 음성, 음악 파일이다. 송출된 소리를 5초 단위로 구분하여 음성 2,401,040개 파일, 음악 1,489,168 총 3,890,208개의 파일을 구성했다. 5초 단위로 소리를 끊는 것은 일반적으로 음악 핑거프린팅이 5초 단위 소리를 사용하여 구분하기 때문이다. 이러한 자료에 대해 딥러닝 분석 기법인 CNN분석을 적용하되 기존의 이미지 학습을 이용한 전이학습(transfer learning)을 적용했다. 실험결과 모형의 복잡성을 높이지 않고도 기존 학습 모형을 응용해 약 89.6% 전후 정확도가 나왔다. 또한 혼동 행렬을 이용하면 음성을 음악으로 판단하는 오류는 12.3%, 음악을 음성으로 판단하는 오류는 12.2%를 보였다.","Traditionally, a method of directly using the characteristic value of the Fourier analysis has been used to distinguish voice and music. However, if deep learning is used, it is possible to distinguish voice and music with an end-to-end method without the need for the process of characteristic featuring. The data used in this paper are about 3.89 million voice and music files extracted from a domestic music broadcasting (FM 89.8MHz). The transmitted sound is divided into 5-second units. Breaking down sound into 5-second increments is applied because music fingerprinting generally uses 5-second increments to distinguish sounds. The CNN analysis, a deep learning analysis technique, was applied to these data, and transfer learning was performed using existing image learning models. An accuracy of about 89.6% was obtained in the existing learning model without increasing the complexity of the deep learning model. In addition, while using the confusion matrix, the error of judging voice as music was 12.3%, and the error in judging music as voice was 12.2%."
FPN(Feature Pyramid Network)을 이용한 고지서 양식 인식,2021,"['Bill form', 'Feature pyramid network', 'Small object detection', 'Deep learning', 'Optical character recognition', '고지서 양식', 'FPN', '작은 객체 검출', '딥러닝', 'OCR']","4차산업 혁명 시대를 맞아, 기술의 변화가 다양한 분야에 적용되고 있다. 고지서 분야에서도 자동화, 디지털화, 데이터관리가 되고 있다. 사회에서 유통되는 고지서의 형태는 수만 가지 이상이며, 이를 자동화, 디지털화, 데이터관리를 위해서는 고지서 인식이 필수적이다. 현재 다양한 고지서들을 관리하기 위해서 OCR(Optical Character Recognition) 기술을 활용한다. 이때, 정확도를 높이기 위해, 먼저 고지서 양식을 인식하면, OCR 인식 시 더 높은 인식률을 가질 수 있다. 본 논문에서는 고지서 양식을 구분하기 위해 인덱스로 사용할 수 있는 로고를 객체 인식하였으며, 이때 로고의 크기가 전체 고지서 대비 작으므로 딥러닝 기술 중 FPN(Feature Pyramid Network)을 작은 객체 검출에 활용하였다. 결과적으로, 제안하는 알고리즘을 통해서 자원 낭비를 줄이고, OCR 인식 정확도를 높일 수 있었다.","In the era of the Fourth Industrial Revolution, technological changes are being applied in various fields. Automation digitization and data management are also in the field of bills. There are more than tens of thousands of forms of bills circulating in society and bill recognition is essential for automation, digitization and data management. Currently in order to manage various bills, OCR technology is used for character recognition. In this time, we can increase the accuracy, when firstly recognize the form of the bill and secondly recognize bills. In this paper, a logo that can be used as an index to classify the form of the bill was recognized as an object. At this time, since the size of the logo is smaller than that of the entire bill, FPN was used for Small Object Detection among deep learning technologies. As a result, it was possible to reduce resource waste and increase the accuracy of OCR recognition through the proposed algorithm."
음향 장면 분류를 위한 경량화 모형 연구,2021,"['acoustic scene classification', 'light-weight model', 'deep learning', 'convolutional neural network', '음향 장면 분류', '경량화 모델', '딥러닝', '합성곱 신경망']","음향 장면 분류는 오디오 파일이 녹음된 환경이 어디인지 분류하는 문제이다. 이는 음향 장면 분류와 관련한 대회인 DCASE 대회에서 꾸준하게 연구되었던 분야이다. 실제 응용 분야에 음향 장면 분류 문제를 적용할 때, 모델의 복잡도를 고려하여야 한다. 특히 경량 기기에 적용하기 위해서는 경량 딥러닝 모델이 필요하다. 우리는 경량 기술이 적용된 여러 모델을 비교하였다. 먼저 log mel-spectrogram, deltas, delta-deltas 피쳐를 사용한 합성곱 신경망(CNN) 기반의 기본 모델을 제안하였다. 그리고 원래의 합성곱 층을 depthwise separable convolution block, linear bottleneck inverted residual block과 같은 효율적인 합성곱 블록으로 대체하고, 각 모델에 대하여 Quantization를 적용하여 경량 모델을 제안하였다. 경량화 기술을 고려한 모델은 기본 모델에 대비하여 성능이 비슷하거나 조금 낮은 성능을 보였지만, 모델 사이즈는 503KB에서 42.76KB로 작아진 것을 확인하였다.","Acoustic scene classification (ASC) categorizes an audio file based on the environment in which it has been recorded. This has long been studied in the detection and classification of acoustic scenes and events (DCASE). In this study, we considered the problem that ASC faces in real-world applications that the model used should have low-complexity. We compared several models that apply light-weight techniques. First, a base CNN model was proposed using log mel-spectrogram, deltas, and delta-deltas features. Second, depthwise separable convolution, linear bottleneck inverted residual block was applied to the convolutional layer, and Quantization was applied to the models to develop a low-complexity model. The model considering low-complexity was similar or slightly inferior to the performance of the base model, but the model size was significantly reduced from 503 KB to 42.76 KB."
다중 선형 회귀 모델을 적용한 채소 가격 예측 시스템 : 기상 변인 중심으로,2021,"['Forecasting system', 'Multiple Linear Regression', 'Deep Learning', 'Public Data', 'TensorFlow', '예측 시스템', '다중 선형회귀', '딥러닝', '공공 데이터', '덴서플로우']","채소 가격의 상승과 하락은 기상 여건에 의한 변동이 가장 크다. 특히 최근 48일째 이어진 장마철 집중호우와 태풍에 의한 채소 가격 상승은 가정의 장바구니 물가와 가공 및 외식업체의 경영상 위험요인이 된다. 따라서 본 논문은 기상 변인 중심의 채소 품목별 가격 예측 시스템을 제안한다. 예측 시스템은 사용자가 웹 사이트에 접속하여 기후 정보를 입력하면 예측한 채소 가격 정보를 사용자에게 제공한다. 제안하는 예측 시스템을 다중 선형회귀(Multiple Linear Regression) 모델을 적용한 딥러닝(Deep Learning) TensorFlow Library, Flask Web Server, MDBootstrap Design Framework, 기상청과 한국농수산식품유통공사 공공 데이터를 활용해 구현하고 실제 환경에서 적용 가능하다.",
Deep learning based Person Re-identification with RGB-D sensors,2021,"['person re-identification', 'surveillance system', 'deep learning', 'human action recognition', 'multi class identification', '사람 재인식', '감시 시스템', '딥러닝', '합성곱신경망', '사람 행동 인식', '다중 분류 인식']","본 연구에서는 3차원 RGB-D Xtion2 카메라를 이용하여 보행자의 골격좌표를 추출한 결과를 바탕으로 동적인 특성(속도, 가속도)을 함께 고려하여 딥러닝 모델을 통해 사람을 인식하는 방법을 제안한다. 본 논문의 핵심목표는 RGB-D 카메라로 손쉽게 좌표를 추출하고 새롭게 생성한 동적인 특성을 기반으로 자체 고안한 1차원 합성곱 신경망 분류기 모델(1D-ConvNet)을 통해 자동으로 보행 패턴을 파악하는 것이다. 1D-ConvNet의 인식 정확도와 동적인 특성이 정확도에 미치는 영향을 알아보기 위한 실험을 수행하였다. 정확도는 F1 Score를 기준으로 측정하였고, 동적인 특성을 고려한 분류기 모델(JCSpeed)과 고려하지 않은 분류기 모델(JC)의 정확도 비교를 통해 영향력을 측정하였다. 그 결과 동적인 특성을 고려한 경우의 분류기 모델이 그렇지 않은 경우보다 F1 Score가 약 8% 높게 나타났다.","In this paper, we propose a deep learning-based person re-identification method using a three-dimensional RGB-Depth Xtion2 camera considering joint coordinates and dynamic features(velocity, acceleration). The main idea of the proposed identification methodology is to easily extract gait data such as joint coordinates, dynamic features with an RGB-D camera and automatically identify gait patterns through a self-designed one-dimensional convolutional neural network classifier(1D-ConvNet). The accuracy was measured based on the F1 Score, and the influence was measured by comparing the accuracy with the classifier model (JC) that did not consider dynamic characteristics. As a result, our proposed classifier model in the case of considering the dynamic characteristics(JCSpeed) showed about 8% higher F1-Score than JC."
3D GPR 탐사 데이터와 심층 합성곱 신경망을 이용한 지하 관로 자동 탐색 시스템,2021,"['Underground Pipe', 'GPR', 'Deep Learning', '3D Image Segmentation', 'Automatic Detection System of Underground Pipe', '지하 관로', '지표 투과 레이더', '딥 러닝', '3D 이미지 분할', '지하 관로 자동 탐색 시스템']","본 논문에서는 관로를 자동으로 검출하는 지하 관로 자동 탐색 시스템을 제안한다. 시간에 따른 지반변화, 관로 시공 불일치 등 여러 가지 요인으로 실제 관로의 위치가 지하 관로 도면과 일치하지 않는다. 이로 인하여 굴착공사나 관로 노후화에 의한 여러 사고가 발생한다. 사고를 방지하기 위해 GPR(지표 투과 레이더, Ground Penetrating Radar) 탐사를 통해 지하시설물을 찾아내는 작업이 이루어지고 있지만, 분석을 담당할 수 있는 전문가의 수가 부족하다. GPR 데이터는 매우 방대하며 분석과정에도 오랜 시간이 걸리기 때문이다. 이에 본 논문에서는 3D GPR 데이터를 자동으로 분석하기 위해 딥 러닝기술인 3D 이미지 분할을 사용하고, 이에 적합한 데이터 생성 알고리즘을 제안한다. 또한 GPR 데이터 특성에 맞는 데이터 증강 기법, 데이터 전처리 모듈을 제안한다. 실험 결과를 통해 제안한 시스템은 F1 Score 40.4%의 성능을 보였으며 이를 통해 이미지 분할을 이용한 관로 분석의 가능성을 확인하였다.","In this paper, we propose Automatic detection system of underground pipe which automatically detects underground pipe to help experts. Actual location of underground pipe does not match with blueprint due to various factors such as ground changes over time, construction discrepancies, etc. So, various accidents occur during excavation or just by ageing. Locating underground utilities is done through GPR exploration to prevent these accidents but there are shortage of experts, because GPR data is enormous and takes long time to analyze. In this paper, To analyze 3D GPR data automatically, we use 3D image segmentation, one of deep learning technique, and propose proper data generation algorithm. We also propose data augmentation technique and pre-processing module that are adequate to GPR data. In experiment results, we found the possibility for pipe analysis using image segmentation through our system recorded the performance of F1 score 40.4%."
전라남도 섬 지역의 난온대 상록활엽수림 복원을 위한 적합지 예측,2021,"['SENTINEL-2 SATELLITE IMAGE', 'DEEP LEARNING', 'TOLERANCE RANGE', '1-km CLIMATE GRID', 'Sentinel-2 위성영상', '딥러닝', '내성 범위', '1km 기후 격자']","국내 섬 지역은 감독 부실과 관광 등으로 인해 산림 훼손이 심각한 상황이다. 한반도 서남해안 지역의 난온대 기후대 원식생은 상록활엽수림이라서, 이곳을 원식생으로 복원이 바람직하다. 따라서 본 연구에서는 전남의 섬 지역 산지를 대상으로, 현존 상록활엽수림의 환경 요인을 분석하여 상록활엽수림 북원 적합지를 도출하였다. 이를 위해 딥러닝(deep learning) 알고리즘을 이용하여 Sentinel-2 위성영상에서 연구 대상지의 식생 유형을 6가지로 분류하였고, 분류된 식생 유형의 위치 및 지형, 기후 속성을 측정하여 상록활엽수림의 내성 범위(tolerance range)를 분석하였다. 분석 결과, 현존 상록활엽수림은 인간의 간섭이 적은, 고도가 높고 경사가 급한 지역에 상대적으로 높은 비율로 분포하였다. 이와 같은 인위적인 간섭으로 현존 상록활엽수림은 타 식생 유형보다 오히려 연평균기온이 낮은 곳에 분포하는 경향을 보였는데, 이는 고도가 높을수록 기온은 낮아지기 때문이다. 여러 환경 요인 중 인간의 간섭에 따른 영향을 배제하고, 상록활엽수림의 복원 적합지를 파악할 수 있는 환경 요인에는 위도와 최한월 평균기온(1월)이 있었다. 상록활엽수림 내성 범위 분석 결과, 위도 34.7° 이남, 최한월평균기온 1.7°C 이상인 지역에 주로 생육하는 것으로 나타나, 이 조건에 맞는 지역을 상록활엽수림 복원 적합지로 예측하였다. 전남 섬 지역의 산지 중 상록활엽수림 복원 적합지 면적은 614.5㎢로 전체 연구 대상지의 59.0%, 연구 대상지 중 농경지 등을 제외한 산림 식생 지역의 73.4%를 차지하였다. 본 연구의 결과를 바탕으로 향후 구체적인 섬 지역 산림복원계획과 예산을 수립해야 할 것이다.","Poor supervision and tourism activities have resulted in forest degradation in islands in Korea. Since the southern coastal region of the Korean peninsula was originally dominated by warm-temperate evergreen broad-leaved forests, it is desirable to restore forests in this region to their original vegetation. In this study, we identified suitable areas to be restored as evergreen broad-leaved forests by analyzing the environmental factors of existing evergreen broad-leaved forests in the islands of Jeollanam-do. We classified forest lands in the study area into six vegetation types from Sentinel-2 satellite images using a deep learning algorithm and analyzed the tolerance ranges of existing evergreen broad-leaved forests by measuring the locational, topographic, and climatic attributes of the classified vegetation types. Results showed that evergreen broad-leaved forests were distributed more in areas with a high altitudes and steep slope, where human intervention was relatively low. The human intervention has led to a higher distribution of evergreen broad-leaved forests in areas with lower annual average temperature, which was an unexpected but understandable result because an area with higher altitude has a lower temperature. Of the environmental factors, latitude and average temperature in the coldest month (January) were relatively less contaminated by the effects of human intervention, thus enabling the identification of suitable restoration areas of the evergreen broad-leaved forests. The tolerance range analysis of evergreen broad-leaved forests showed that they mainly grew in areas south of the latitude of 34.7° and a monthly average temperature of 1.7°C or higher in the coldest month. Therefore, we predicted the areas meeting these criteria to be suitable for restoring evergreen broad-leaved forests. The suitable areas cover 614.5 ㎢, which occupies 59.0% of the total forest lands on the islands of Jeollanamdo, and 73% of actual forests that exclude agricultural and other non-restorable forest lands. The findings of this study can help forest managers prepare a restoration plan and budget for island forests."
무인기 영상 기반 옥수수 재배필지 추출을 위한 Attention U-NET 적용 및 평가,2021,"['Unmanned Aerial Vehicle', 'Attention U-Net', 'Corn', 'Cultivation Field Extraction', '무인기', '어텐션 유넷', '옥수수', '경작지 추출']","본 연구에서는 위성영상 촬영 한계를 극복하고 재배 필지 현황 파악 기술 발전에 기여하고자 무인기 영상 및 딥러닝 모형을 이용하여 옥수수 재배 필지 추출 방법을 제안하였다. 연구대상지역은 충북 괴산군 감물면 이담리 일대로 설정하고, 무인기 촬영을 통해 해당지역의 정사영상을 취득하였다. 모형에 필요한 학습자료는 현장조사 자료와 팜맵을 이용하여 구축하였다. 본 연구에 적용한 딥러닝 모형은 의미론적 분할 모형인 Attention U-Net을 이용하였다. 모형의 성능 평가는 학습과정을 거친 후 비학습 자료를 이용하여 옥수수 재배 필지 추출에 대해서 실시 하였다. 모형 성능평가 결과 정밀도는 0.94, 재현율은 0.96 및 F1-Score는 0.92로 나타났다. 본 연구에 적용한 Attention U-Net방법은 옥수수 재배 필지를 효과적으로 추출할 수 있는 방법임을 확인하였다. 따라서 본 연구 방법은 옥수수는 물론 다른 작물에 대한 재배 필지 구분에도 유용하게 활용될 수 있을 것으로 기대된다.","In this study, crop cultivation filed was extracted by using Unmanned Aerial Vehicle (UAV) imagery and deep learning models to overcome the limitations of satellite imagery and to contribute to the technological development of understanding the status of crop cultivation field. The study area was set around Chungbuk Goesan-gun Gammul-myeon Yidam-li and orthogonal images of the area were acquired by using UAV images. In addition, study data for deep learning models was collected by using Farm Map that modified by fieldwork. The Attention U-Net was used as a deep learning model to extract feature of UAV in this study. After the model learning process, the performance evaluation of the model for corn cultivation extraction was performed using non-learning data. We present the model""s performance using precision, recall, and F1-score; the metrics show 0.94, 0.96, and 0.92, respectively. This study proved that the method is an effective methodology of extracting corn cultivation field, also presented the potential applicability for other crops."
심층 CNN 기반 구조를 이용한 토마토 작물 병해충 분류 모델,2021,"['Convolutional Neural Networks', 'Deep Learning', 'Transfer Learning', 'Fine Tuning', 'Plant Diseases Classification']","토마토 작물은 병해충의 영향을 많이 받기 때문에 이를 예방하지 않으면 농업 경제에 막대한 손실을 초래할 수 있다. 따라서 토마토의 다양한 병해충의 진단을 빠르고 정확하게 진단하는 시스템이 요구된다. 본 논문에서는 ImageNet 데이터 셋 상에서 다양하게 사전 학습된 딥러닝 기반 CNN 모델을 적용하여 토마토의 9가지 병해충 및 정상인 경우의 클래스를 분류하는 시스템을 제안한다. PlantVillage 데이터 셋으로부터 발췌한 토마토 잎의 이미지 셋을 3가지 딥러닝 기반 CNN 구조를 갖는 ResNet, Xception, DenseNet의 입력으로 사용한다. 기본 CNN 모델 위에 톱-레벨 분류기를 추가하여 제안 모델을 구성하였으며, 훈련 데이터 셋에 대해 5-fold 교차검증 기법을 적용하여 학습시켰다. 3가지 제안 모델의 학습은 모두 기본 CNN 모델의 계층을 동결하여 학습시키는 전이 학습과 동결을 해제한 후 학습률을 매우 작은 수로 설정하여 학습시키는 미세 조정 학습 두 단계로 진행하였다. 모델 최적화 알고리즘으로는 SGD, RMSprop, Adam을 적용하였다. 실험 결과는 RMSprop 알고리즘이 적용된 DenseNet CNN 모델이 98.63%의 정확도로 가장 우수한 결과를 보였다.","Tomato crops are highly affected by tomato diseases, and if not prevented, a disease can cause severe losses for the agricultural economy. Therefore, there is a need for a system that quickly and accurately diagnoses various tomato diseases. In this paper, we propose a system that classifies nine diseases as well as healthy tomato plants by applying various pretrained deep learning-based CNN models trained on an ImageNet dataset. The tomato leaf image dataset obtained from PlantVillage is provided as input to ResNet, Xception, and DenseNet, which have deep learning-based CNN architectures. The proposed models were constructed by adding a top-level classifier to the basic CNN model, and they were trained by applying a 5-fold cross-validation strategy. All three of the proposed models were trained in two stages: transfer learning (which freezes the layers of the basic CNN model and then trains only the top-level classifiers), and fine-tuned learning (which sets the learning rate to a very small number and trains after unfreezing basic CNN layers). SGD, RMSprop, and Adam were applied as optimization algorithms. The experimental results show that the DenseNet CNN model to which the RMSprop algorithm was applied output the best results, with 98.63% accuracy."
YOLOv3 객체 검출을 이용한 AR 관광 서비스 프레임워크,2021,"['AR', 'Deep Learning', 'Object Detection', 'Tourism Service', 'YOLOv3']","교통 수단과 모바일의 발전으로 관광 여행 수요가 증가하고 관련 산업 또한 크게 발전하고 있다. 디지털 미디어 기술 중 한 분야인 증강현실과 관광 콘텐츠의 접목 또한 활발하게 연구 중이며 인공지능은 이미 관광 산업과 다양한 방향으로 접목되어 관광객의 여행 경험을 풍부하게 만들어준다. 본 논문에서는 관광지역을 축소해 제작한 미니어처 모형 을 스캔하면, 사전에 딥러닝을 이용해 학습된 모델을 기반으로 해당 관광지를 찾은 뒤 관련 정보와 3D 모델을 AR 서비 스로 제공하는 시스템을 제안한다. 다양한 딥러닝 신경망 중 하나인 YOLOv3 신경망을 사용해 모델 학습과 객체 검출을 진행하므로, 빠른 속도로 물체 검출이 이루어져 실시간으로 서비스를 제공할 수 있다.","With the development of transportation and mobiles demand for tourism travel is increasing and related industries are also developing significantly. The combination of augmented reality and tourism contents one of the areas of digital media technology, is also actively being studied, and artificial intelligence is already combined with the tourism industry in various directions, enriching tourists' travel experiences. In this paper, we propose a system that scans miniature models produced by reducing tourist areas, finds the relevant tourist sites based on models learned using deep learning in advance, and provides relevant information and 3D models as AR services. Because model learning and object detection are carried out using YOLOv3 neural networks, one of various deep learning neural networks, object detection can be performed at a fast rate to provide real-time service."
Catboost 알고리즘을 통한 교통흐름 예측에 관한 연구,2021,"['Machine Learning', 'Artificial Intelligence', 'Catboost', 'Deep Learning', 'LSTM']","자동차 등록대수와 비례하여 증가하는 교통 혼잡은 도시의 사회경제 발전의 저해 요소로 작용하고 있다. 본 논문은 VDS(Vehicle Detection System)을 통한 데이터를 입력 변수로 사용한다. 본 연구의 목적은 교통 흐름을 단순히 2단계(원할, 정체)가 아닌 5단계(원할, 다소 지체, 지체, 다소 정체, 정체)로 더 정교하게 예측하고, 이 예측에서 가장 정확도가 높은 모델인 Catboost 모델과 다른 모델들을 비교하는 것이다. 이를 위해 본 논문에서는 머신러닝 알고리즘인 Catboost 모델을 통해 5가지 단계를 예측하고 정확도를 다른 머신러닝 알고리즘들과 비교, 분석한다. 또한, 하이퍼 파라미터(Hyper Parameter) 튜닝 및 원-핫 인코딩(One-Hot Encoding) 전처리를 거치지 않은 Catboost 모델과 랜덤선택(RandomizedSearchcv)을 통해 튜닝 및 데이터 전처리를 거친 모델을 비교, 분석한다. 분석 결과 하이퍼 파라미터 튜닝을 하지 않은 초기 Catboost 모델이 정확도 93%를 보이며 가장 높은 정확도를 기록하였다. 따라서 본 연구는 두가지 의의를 가진다. 첫번째로, 초기 세팅된 파라미터들이 적용된 Catboost 모델이 다수의 범주형 변수를 포함하는 교통흐름 예측에서 다른 머신러닝, 딥러닝 모델들보다 성능이 높다는 결론을 도출했다는 점에서 의의가 있다. 두번째로, 기존 2단계로 예측하던 교통 흐름을 5단계로 예측함으로써 더욱 정교한 교통 흐름 예측 모델을 제안한다는 점에서 의의를 가진다.","As the number of registered vehicles increases, traffic congestion will worsen worse, which may act as an inhibitory factor for urban social and economic development. Through accurate traffic flow prediction, various AI techniques have been used to prevent traffic congestion. This paper uses the data from a VDS (Vehicle Detection System) as input variables. This study predicted traffic flow in five levels (free flow, somewhat delayed, delayed, somewhat congested, and congested), rather than predicting traffic flow in two levels (free flow and congested). The Catboost model, which is a machine-learning algorithm, was used in this study. This model predicts traffic flow in five levels and compares and analyzes the accuracy of the prediction with other algorithms. In addition, the preprocessed model that went through RandomizedSerachCv and One-Hot Encoding was compared with the naive one. As a result, the Catboost model without any hyper-parameter showed the highest accuracy of 93%. Overall, the Catboost model analyzes and predicts a large number of categorical traffic data better than any other machine learning and deep learning models, and the initial set parameters are optimized for Catboost."
Xception과 양방향 LSTM을 통한 뇌종양 진단에 관한 연구,2021,"['Deep Learning', 'Artificial Intelligence', 'Diagnosis', 'CNN', 'LSTM', 'Xception', 'Brain Tumor']","뇌종양은 전체 종양 중 세 번째로 많을 뿐만 아니라 우리나라에서도 환자 수가 늘어나는 추세이다. 하지만 영상기반 검사가 주로 이루어지는 뇌종양의 경우, 전문의가 판단하기 때문에 판독 결과에 오류가 생길 가능성이 있다. 이를 방지하고자 인공지능 기반의 진단 방법이 도입되고 있다. 본 연구의 목적은 뇌종양을 단순히 2가지(정상, 비정상)가 아닌 4가지(교종, 뇌수막종, 뇌수하체 종양, 정상)로 더 정교하게 진단하고, 다른 모델들과 정확도를 비교하는 것이다. 또한, 단순 분류가 아닌 이미지 분할을 통해 환자로 분류한 근거를 시각화한다. 이를 위해 본 논문에서는 Xception과 양방향 LSTM을 활용한 모델을 통해 MRI 사진을 4가지로 분류하고 정확도를 다른 딥러닝 알고리즘들과 비교, 분석한다. 또한, CAM(Class Activation Map)을 통해 이상 부위를 시각화한다. 분석 결과 본 연구에서 제안하는 모델이 정확도 86%를 보이며 가장 높은 정확도를 기록하였다. 특히, 단순히 Xception 모델을 사용하였을 때 보다 8%가 증가하였다. 따라서 본 연구는 두 가지 의의를 가진다. 첫번째로, 단순 Xception 모델보다 Xception 모델에 양방향 LSTM을 추가하였을 때, VGG16, MobileNet과 같은 다른 CNN기반의 사전 훈련된 딥러닝 모델들보다 성능이 높다는 결론을 도출했다는 점에서 의의가 있다. 두번째로, 기존 2단계로 예측하던 뇌종양 진단을 4단계로 분류함과 동시에 이상 부위를 시각화하여 더욱 정교한 뇌종양 진단 모델을 개발하였다는 점에 의의가 있다.","Brain tumors have the third-largest incidence among tumors, and the number of patients is increasing continuously in Korea. On the other hand, as the diagnosis of brain tumor is conducted mainly through a vision-based inspection by doctors, there is a possibility of errors in the stage of inspection. Artificial intelligence-based diagnostic methods are being introduced to prevent this problem. This study attempted to classify patients into more sophisticated stages (normal, glioma, pituitary, and meningioma) than previous research, which classified them into two stages (normal and patient). The accuracy of the proposed model was compared, and the anomalous part of the brain was visualized. To this end, MRI pictures were classified into four categories through Xception + Bi-directional LSTM and compared to the other pretrained models. Furthermore, the anomalous part of the brain was visualized through CAM (Class Activation Map). The proposed model achieved 86%, which is 8% higher than the simple Xception model. This research is significant in finding that the Xception + Bi-directional LSTM model showed higher accuracy than other pretrained models, such as simple Xception, VGG16, and MobileNet. Furthermore, this research is also worthwhile because the patients could be classified into four categories with high accuracy, and the anomaly parts could be visualized."
상담 챗봇의 다차원 감정 인식 모델,2021,"['감정 인식', '차원 감정', '다차원 감정 인식', 'Emotion recognition', 'Dimensional emotion', 'Multi-Dimensional emotion recognition']","최근 COVID-19로 인한 코로나 블루로 상담의 중요성이 높아지고 있다. 또한 비대면 서비스의 증가로 상담 매체에 변화를 준 챗봇에 관한 연구들이 활발하게 진행되고 있다. 챗봇을 통한 비대면 상담에서는 내담자의 감정을 정확하게 파악하는 것이 가장 중요하다. 하지만 내담자가 작성한 문장만으로 감정을 인식하는 데는 한계가 있으므로 더 정확한 감정 인식을 위해서는 문장에 내제되어있는 차원 감정을 인식하는 것이 필요하다. 따라서 본 논문에서는 상담 챗봇의 감정 인식 개선을 위해 원본 데이터를 데이터의 특성에 맞게 보정한 후 Word2Vec 모델을 학습하여 생성된 벡터와 문장 VAD(Valence, Arousal, Dominance)를 딥러닝 알고리즘으로 학습한 다차원 감정 인식 모델을 제안한다. 제안한 모델의 유용성 검증 방법으로 3가지 딥러닝 모델을 비교 실험한 결과로 Attention 모델을 사용했을 때 R-squared가 0.8484로 가장 좋은 성능을 보인다.","Recently, the importance of counseling is increasing due to the Corona Blue caused by COVID-19. Also, with the increase of non-face-to-face services, researches on chatbots that have changed the counseling media are being actively conducted. In non-face-to-face counseling through chatbot, it is most important to accurately understand the client s emotions. However, since there is a limit to recognizing emotions only in sentences written by the client, it is necessary to recognize the dimensional emotions embedded in the sentences for more accurate emotion recognition. Therefore, in this paper, the vector and sentence VAD (Valence, Arousal, Dominance) generated by learning the Word2Vec model after correcting the original data according to the characteristics of the data are learned using a deep learning algorithm to learn the multi-dimensional We propose an emotion recognition model. As a result of comparing three deep learning models as a method to verify the usefulness of the proposed model, R-squared showed the best performance with 0.8484 when the attention model is used."
기계학습을 이용한 회화 감성 예측 모델에 관한 분석 연구,2021,"['Painting Analysis', 'Machine Learning', 'Affective Computing', 'Emotion Extraction', 'Emotion Predicting Model', '회화 분석', '기계학습', '감성 컴퓨팅', '감성 추출', '감성 예측 모델']","이미지에서 감성을 예측하는 기술들은 많이 연구되어 지고 있다. 기계학습 및 딥러닝 기술들이 발전함에 따라서, 더 많은 연구들이 진행되었다. 이미지중에서도 특히 예술작품들은 감성과의 연관이 매우 크다. 일반적으로 예술가들이 자신의 감성을 작품에 넣는 경우가 많기 때문이다. 이런 감성들은 색상, 질감 등의 물리적 요소들이 결합된 대칭성, 구도 등의 예술적 요소들로 제어가 된다. 본 연구에서는 이런 특징들을 회화로부터 추출 및 분석한다. 회화에서 감성에 영향을 미칠 것으로 예상되는 특징들을 추출하여 이를 감성 예측에 활용한다. 주어진 회화로부터 색상, 선, 질감등의 물리적 특징과, 대칭성, 색상조합 등과 같은 예술적 특징을 추출하여, 다양한 기계학습 모델을 제작한다. 제작된 기계학습 모델들을 통해 회화-감성 예측에서 가장 관련이 깊은 특징들 및 감성 추출에 어울리는 기계학습 모델이 무엇인지 분석한다. 최종적으로 딥러닝 기반의 예측 모델과의 비교를 통해 기계학습 모델의 정당성 및 정확도에 대해 검증한다.","Techniques for predicting emotions in images have been studied a lot. As machine learning and deep learning technologies developed, more studies were conducted. Among the images, artworks in particular are very related to emotions. In general, artists often put their emotions into their works. Emotions are controlled by artistic features such as symmetry and composition, which combine physical elements such as color and texture. In this study, these features are extracted and analyzed from paintings. Features that are expected to affect emotions in paintings are extracted and used to predict emotions. Various machine learning models are built by extracted physical features such as color, line, texture, etc. and artistic features such as symmetry and color combination from a given painting. Through the built machine learning models, this paper analyze which machine learning models are suitable for the most relevant characteristics and emotional extraction in conversation-emotional predictions. Finally, we verify the legitimacy and accuracy of machine learning models by comparing them with predictive models based on deep learning."
Explanation segments 기반 설명 가능한 지식 완성 모델,2021,"['knowledge graph', 'explainable knowledge completion', 'embedding', 'attention mechanism', '지식 그래프', '설명 가능한 지식 완성', '임베딩', '어텐션 메커니즘']","최근 딥러닝을 활용하여 불완전한 지식 그래프를 대상으로 새로운 링크를 예측하는 연구가 많이 진행되고 있지만, 딥러닝을 활용한 링크 예측은 추론 결과에 대한 설명이 불가능하다는 한계점이 있다. 따라서 본 논문에서는 링크 예측 후, 추론 결과를 뒷받침하는 증거로서 설명 가능한 추론 경로를 제공하여 지식 완성의 효용성이 높은 모델을 제안한다. 이를 위해 우선 지식 그래프의 주어를 시작으로 목적어로 도달하는 또 다른 경로를 Path Ranking Algorithm 활용하여 생성하며, 이를 explanation segment라 정의하였다. 이 후 생성된 explanation segment를 CNN과 양방향 LSTM을 결합한 방식을 적용하여 임베딩 한다. 마지막으로 임베딩 된 explanation segment들과 추론할 후보 술어와의 의미적 유사성 계산을 기반으로 한 어텐션 메커니즘을 적용하여, 링크 예측 모델을 학습하였다. 모델 학습 후 링크 예측 설명에 적합한 explanation segment를 어텐션 점수에 기반으로 선정하여 제공한다. 제안하는 방법의 성능을 측정하기 위해 링크 예측 비교 실험 및 링크 예측 결과에 대한 설명으로 적합한 explanation segment의 비율을 측정하는 정확성 검증 실험을 진행하였다. 실험 데이터는 벤치마크 데이터인 NELL-995, FB15K-237, Countries를 대상으로 진행하였으며, 정확성 검증 실험에서 평균 89%. 44%, 97% 정확성을 보였고, 기존 연구와 비교했을 때, NELL-995는 평균 35%p, FB15K-237은 평균 21%p 높은 성능을 보였다.","Recently, a large number of studies that used deep learning have been conducted to predict new links in incomplete knowledge graphs. However, link prediction using deep learning has a major limitation as the inferred results cannot be explained. We propose a high-utility knowledge graph prediction model that yields explainable inference paths supporting the inference results. We define paths to the object from the knowledge graph using a path ranking algorithm and define them as the explanation segments. Then, the generated explanation segments are embedded using a Convolutional neural network (CNN) and a Bidirectional Long short-term memory (BiLSTM). The link prediction model is then trained by applying an attention mechanism, based on the calculation of the semantic similarity between the embedded explanation segments and inferred candidate predicates to be inferred. The explanation segment suitable for link prediction explanation is selected based on the measured attention scores. To evaluate the performance of the proposed method, a link prediction comparison experiment and an accuracy verification experiment are performed to measure the proportion of the explanation segments suitable to explain the link prediction results. We used the benchmark datasets NELL-995, FB15K-237, and countries for the experiment, and accuracy verification experiments showed the accuracies of 89%, 44%, and 97%, respectively. Compared with the existing method, the NELL-995, FB15K-237 data exhibited 35%p and 21%p higher performance on average."
Xception과 양방향 LSTM을 통한 뇌종양 진단에 관한 연구,2021,"['Deep Learning', 'Artificial Intelligence', 'Diagnosis', 'CNN', 'LSTM', 'Xception', 'Brain Tumor']","뇌종양은 전체 종양 중 세 번째로 많을 뿐만 아니라 우리나라에서도 환자 수가 늘어나는 추세이다. 하지만 영상기반 검사가 주로 이루어지는 뇌종양의 경우, 전문의가 판단하기 때문에 판독 결과에 오류가 생길 가능성이 있다. 이를 방지하고자 인공지능 기반의 진단 방법이 도입되고 있다. 본 연구의 목적은 뇌종양을 단순히 2가지(정상, 비정상)가 아닌 4가지(교종, 뇌수막종, 뇌수하체 종양, 정상)로 더 정교하게 진단하고, 다른 모델들과 정확도를 비교하는 것이다. 또한, 단순 분류가 아닌 이미지 분할을 통해 환자로 분류한 근거를 시각화한다. 이를 위해 본 논문에서는 Xception과 양방향 LSTM을 활용한 모델을 통해 MRI 사진을 4가지로 분류하고 정확도를 다른 딥러닝 알고리즘들과 비교, 분석한다. 또한, CAM(Class Activation Map)을 통해 이상 부위를 시각화한다. 분석 결과 본 연구에서 제안하는 모델이 정확도 86%를 보이며 가장 높은 정확도를 기록하였다. 특히, 단순히 Xception 모델을 사용하였을 때 보다 8%가 증가하였다. 따라서 본 연구는 두 가지 의의를 가진다. 첫번째로, 단순 Xception 모델보다 Xception 모델에 양방향 LSTM을 추가하였을 때, VGG16, MobileNet과 같은 다른 CNN기반의 사전 훈련된 딥러닝 모델들보다 성능이 높다는 결론을 도출했다는 점에서 의의가 있다. 두번째로, 기존 2단계로 예측하던 뇌종양 진단을 4단계로 분류함과 동시에 이상 부위를 시각화하여 더욱 정교한 뇌종양 진단 모델을 개발하였다는 점에 의의가 있다.","Brain tumors have the third-largest incidence among tumors, and the number of patients is increasing continuously in Korea. On the other hand, as the diagnosis of brain tumor is conducted mainly through a vision-based inspection by doctors, there is a possibility of errors in the stage of inspection. Artificial intelligence-based diagnostic methods are being introduced to prevent this problem. This study attempted to classify patients into more sophisticated stages (normal, glioma, pituitary, and meningioma) than previous research, which classified them into two stages (normal and patient). The accuracy of the proposed model was compared, and the anomalous part of the brain was visualized. To this end, MRI pictures were classified into four categories through Xception + Bi-directional LSTM and compared to the other pretrained models. Furthermore, the anomalous part of the brain was visualized through CAM (Class Activation Map). The proposed model achieved 86%, which is 8% higher than the simple Xception model. This research is significant in finding that the Xception + Bi-directional LSTM model showed higher accuracy than other pretrained models, such as simple Xception, VGG16, and MobileNet. Furthermore, this research is also worthwhile because the patients could be classified into four categories with high accuracy, and the anomaly parts could be visualized."
데이터베이스 내부자 공격탐지를 위한 사용자 질의의 분리표현 학습,2021,"['딥러닝', '표현형 학습', '심층 삼중항 신경망', '데이터베이스 보안', '내부자 침입탐지', '사용자 질의 특징추출', 'deep learning', 'metric learning', 'triplet network', 'database security', 'insider intrusion detection', 'user query feature extraction']","역할기반 접근 제어를 기반으로 하는 데이터베이스 관리 시스템은 정보 저장 및 분석에 널리 사용되지만 여러 보안 이슈 중에서도 내부자 공격에 특히 취약하다는 것이 여러 연구를 통해 밝혀져 있다. 구문 분석을 통한 전통적인 침입탐지의 한계로 인해 최근의 연구결과는 적응형 시스템으로 요약될 수 있으며, 이러한 관점에서 우리의 연구는 데이터베이스에 접근하는 사용자 질의에 대한 분류예측을 수행하여 실제 데이터베이스 시스템에 의해 수행된 내용 비교를 통해 예측값과 상이한 경우 내부자 공격으로 판단하는 방법을 제안한다. 제안하는 모델은 상호 유사성이 큰 사용자 질의에 대한 분류라는 문제 해결을 위해 입력의 유의미한 특징을 모형이 잘 추출하고, 신경망을 사용하여 유사성의 척도를 직접적으로 학습하는 계층적 구조를 가지는 심층 표현 학습 신경망으로, 학습모델은 온라인 거래 벤치마크인 TPC-E 공개 설계구조를 활용하여 각각의 역할로 구분된 11개의 분류모형당 1,000개의 질의를 생성하여 학습되었으며, 기존 선행연구와 비교했을 때 가장 높은 성능인 94.17%의 분류정확도를 달성하였다. 제안하는 방법의 정량적 성능을 10겹 교차 검증으로 평가하였고, 정성적 성능 분석을 위해 신경망으로 임베딩한 특징공간을 시각화하여 결함간의 압축 벡터의 군집화 분석을 수행하였다.","Database management systems employing role-based access control are widely used for information storage and analysis, but several studies have revealed that such systems are particularly vulnerable to insider attacks, among various other security issues. Our study proposes a method that can verify an event as an insider attack when the predicted value is different from the actual value by performing classification prediction on the user query accessing the database and comparing it with the log performed by the actual database system. Our model for solving the problem of classification of user queries with high mutual similarity is a deep representation learning architecture with a hierarchical structure, in which the model extracts meaningful features and directly learns the measure of similarity using a network. The model was trained by generating 1,000 queries per 11 roles classified using the TPC-E public schema as an online transaction benchmark, and it achieved higher performance than any of the previous works, with a classification accuracy of 94.17%. The quantitative performance was evaluated by 10-fold cross-validation to verify the validity of the intrusion detection model, while for qualitative performance analysis, a clustering analysis of compression vectors between defects was conducted by visualizing the embedded feature space."
특정인에 대한 범죄예측 시스템의 문제점과 개선방안,2021,"['범죄예측 시스템', '특정인', '인공지능', '알고리즘', '범죄예방', '범죄자 예측', 'Crime Prediction System', 'specific person', 'artificial intelligence', 'algorithms', 'crime prevention', 'criminal prediction']","머신러닝 및 딥러닝 기술에 근거한 인공지능이 빅데이터라는 방대한 자료 속에서 숨겨진 정보들 간의 상관관계를 찾아내고 이를 바탕으로 미래에 어떤 일이 발생할 것인지를 통계적으로 예측하고 있다. 이를 활용하여 사회의 많은 분야에서 상당히 높은 수준의 예측을 하고 있다. 이러한 높은 예측력은 범죄예방분야에서도 활용되고 있는데, 이미 선진국에서는 범죄발생률이 높은 대도시를 중심으로 빅 데이터와 인공지능을 이용한 범죄예측 시스템을 도입함으로써 범죄율이 감소하는 등 가시적인 효과를 보고 있다. 이러한 범죄예측 시스템의 방법은 범죄 예측, 범죄 피해자 예측, 범죄자 예측 등 크게 3가지로 구분할 수 있다. 특정한 범죄자와 피해자와 같은 특정인의 범죄를 전망하는 범죄자 예측과 피해자 예측은 개인의 Privacy가 침해된다는 점과 민감한 개인정보의 수집 범위가 제한적이라는 점에서 연구 및 활용이 제한되었다. 이 때문에 범죄예측 시스템은 장소별, 지역별 범죄 위험도를 기반으로 한 범죄발생의 시간과 장소를 전망하는 시공간 범죄예측이 주를 이루고 있다. 이러한 상황에서 본 연구는 특정인에 대한 범죄예측 시스템에서 발생할 수 있는 문제점을 제기하고 이에 대한 신속한 대처방안을 모색하는데 목표를 두고자 한다. 특정인에 대한 범죄예측 시스템은 특정인의 개인정보를 다루기 때문에 필연적으로 헌법상 보장된 사생활의 비밀과 자유 및 개인정보자기결정권 등의 기본권을 침해할 수밖에 없다. 특정인을 대상자로 할 경우 일반인과의 형평성의 문제가 제기될 수 있다. 또한 대상범죄를 어느 범위까지 허용할 것인지 명확한 한계를 설정하기 어렵다. 범죄예측 시스템에 사용되는 인공지능 알고리즘은 불명투명성, 편향성, 부정확성의 문제가 있다. 인공지능 알고리즘의 불투명성은 부정확한 범죄예측으로 인한 피해나 그 책임의 소재를 찾는데 어려움을 줄 수 있다. 또한 인공지능 알고리즘이 지닌 잠재적 편향성과 부정확성 때문에 범죄예측이 공정하지 못하다는 비판을 받고 있다. 그리고 범죄예측 시스템은 시민들에게 새로운 통제수단이 되고 있다. 이러한 문제점을 해결하기 위해서는 먼저, 개인정보보호법 제15조 1항 1호에 의해 정보주체의 사전 동의를 반드시 받도록 하여야 할 것이다. 범죄예측을 위한 특정인에 대한 개인정보수집은 합목적적 범위 내에서 필요최소한에 그쳐야 할 것이고, 잘못된 결과가 발생할 경우를 회피 내지 개선할 수 있는 적당한 조치를 사전에 보장하여야 한다. 모든 개인정보수집은 감독기관의 적절한 감독을 받을 것을 보장하여야 한다. 알고리즘의 불투명성을 해결하는 방법으로는 정보 주체나 일반인을 대신하여 알고리즘의 적절성을 심사하고 감시하는 조직이나 기관을 설치하는 방법을 제시할 수 있다. 편향성 및 부정확성 해결방안으로 범죄예측 시스템을 통한 범죄예방의 효과성이 입증되어 공개되어야 하며 범죄예측 시스템의 알고리즘의 정확성이 담보되어야 할 것이다. 범죄예측 시스템의 적용대상범죄와 대상자의 선정을 위해서는 재범의 중대성과 위험성이 중요한 판단 기준이 될 것이다. 범죄예측 시스템을 사용한 범죄예측은 살인, 강도, 강간, 방화와 같은 중대범죄여야 할 것이다. 범죄예측 시스템이 시민에 대한 통제장치로서 악용될 우려를 불식시키기 위해서는 범죄예측 시스템도 보안처분과 같이 비례성의 원칙에 의하여 대상자의 권리침해를 최소화하여야 한다. 범죄예측 시스템은 형벌이나 다른 보안처분에 의하여 목적을 달성할 수 없는 최후수단으로서 사용되어야 할 것이다. 대상자의 재범위험성을 근거로 개별적으로 사용하여야 한다. 범죄예측시스템은 행정처분에 의하여 행해져서는 안되고 법원의 사법심사에 의하여 부과되어야 한다.","Artificial intelligence based on machine learning and deep learning technology finds correlations between hidden information in the vast data of big data and statistically predicts what will happen in the future. Using AI, there are high-level predictions in many fields of society. This high predictive power of AI is also being used in the field of crime prevention. In developed countries, crime prediction systems using big data and artificial intelligence have been introduced intensively in large cities with high crime rates. And they are producing tangible effects such as a decrease in the crime rate. The methods of such a crime prediction system can be broadly divided into 3 categories: ① crime prediction, ② criminal prediction, ③ crime victim prediction. Because of the limited scope of collection of sensitive personal information and protection of personal privacy, crime prediction, which predicts the time and place of a crime based on the crime risk by region and location, is mainly used rather than predicting criminals and victims. In this situation, the purpose of this study is to raise the problems that may appear in the crime prediction system for a specific person and to find a quick response method. Therefore, in this study, the problem of infringement of individual constitutional and legal rights that may occur when the crime prediction system is used for a specific person, the problem of opacity, inaccuracy and bias of the algorithm of the crime prediction system, and the problem of the crime prediction system as a new control means. We will review the potential problems and seek solutions to them. Since the crime prediction system for a specific person deals with the personal information of a specific person, it inevitably violates the basic rights such as privacy and freedom and the right to self-determination of personal information guaranteed by the Constitution. When targeting a specific person, the issue of equity with the general public may be raised. In addition, it is difficult to set clear limits on the extent to which target crimes are permitted. Artificial intelligence algorithms used in crime prediction systems have problems of opacity, bias, and inaccuracy. The opacity of artificial intelligence algorithms can make it difficult to find the cause of damage or responsibility due to inaccurate crime prediction. In addition, due to the potential bias and inaccuracy of artificial intelligence algorithms, crime prediction is being criticized for being unfair. And the crime prediction system is becoming a new means of control for citizens. In order to solve this problem, it is necessary to first obtain the prior consent of the information subject according to Article 15 (1) 1 of the Personal Information Protection Act. The collection of personal information for a specific person for crime prediction should be limited to the minimum necessary within the scope of the purpose of the crime, and appropriate measures to avoid or improve the occurrence of erroneous results should be ensured in advance. It should be ensured that all personal information collection is subject to appropriate supervision by the supervisory authority. As a method of solving the opacity of the algorithm, it can be suggested to establish an organization or institution that examines and monitors the adequacy of the algorithm on behalf of the data subject or the general public. As a solution to bias and inaccuracy, the effectiveness of crime prevention through the crime prediction system should be proven and disclosed, and the accuracy of the crime prediction system algorithm should be guaranteed. The seriousness and risk of recidivism will be an important criterion for the selection of target crimes and targets for the crime prediction system. Crime prediction using the crime prediction system should be serious crimes such as murder, robbery, rape,"
Attention U-Net 신경망을 활용한 유체의 미래 상태 예측 기법,2021,"['딥러닝', '합성곱 신경망', '전산 유체 역학', '나비에-스토크스 방정식', '유체 시뮬레이션', 'Computational fluid dynamics', 'Navier Stokes equation', 'Deep learning', 'Convolutional Neural network', 'Fluid simulation.']","전산 유체 역학 시뮬레이션은 항공기, 건물, 자동차 등 유체와 관련된 다양한 디자인 분야에서 활용이 되어지고 있으나, 오랜 실행 시간과 많은 비용이 발생하는 나비에-스토크스 방정식의 사용으로 인해 개발에 많은 시간이 소요된다. 또한 위험 물질이 확산되는 환경과 같이 즉각적인 유체 흐름의 분석이 필요한 분야에서는활용이 어렵기 때문에 최대한 정확도를 보존하면서 빠르게 예측하는 기술이 매우 중요하게 여겨지고 있다.이를 위해 본 연구에서는 Attention U-Net 신경망을 기반으로 유체의 흐름을 예측하는 방법론을 제안하고테스트한다. 장애물을 인식하여 빠르게 7초 후 미래의 유체 흐름을 예측하는 방법으로 테스트를 진행하였고, 그 결과 기존 시뮬레이션 소프트웨어 및 CNN모델을 사용하였을 때 대비 정확도는 최대한 보존하면서 실행속도는 약 85배 빠른 결과를 얻을 수 있었다.","Computational Fluid Dynamics (CFD) simulation is used in various fluid-related fields such as aircrafts, buildings, or automobiles design and it consumes a lot of development time due to the use of Navier Stokes equation, which incur a long execution time with high cost. In addition, it is difficult to use it in such environments as the hazardous substance or epidemic diffusion where the fluid flow must be predicted immediately. In the situations, it is important and critical to predict as quickly as possible while preserving accuracy. Hence in this study, to address the issues, we suggest and test a method that uses Attention U-Net neural network to predict the future state of the fluid in a terrain with obstacles. As a result, compared to the existing simulation software or simple CNN method, the suggested approach shows the execution speed is 85 times faster while preserving the competitive accuracy."
병렬 말뭉치 필터링을 적용한 Filter-mBART기반 기계번역 연구,2021,"['딥러닝', '자연어처리', '기계번역', '병렬 말뭉치 필터링', '사전학습 모델', 'Deep Learning', 'Natural Language Process', 'Machine Translation', 'Parallel Corpus Filtering', 'Pretrained model']","최신 기계번역 연구 동향을 살펴보면 대용량의 단일말뭉치를 통해 모델의 사전학습을 거친 후 병렬 말뭉치로 미세조정을 진행한다. 많은 연구에서 사전학습 단계에 이용되는 데이터의 양을 늘리는 추세이나, 기계번역 성능 향상을 위해 반드시 데이터의 양을 늘려야 한다고는 보기 어렵다. 본 연구에서는 병렬 말뭉치 필터링을 활용한 mBART 모델 기반의 실험을 통해, 더 적은 양의 데이터라도 고품질의 데이터라면 더 좋은 기계번역 성능을 낼 수 있음을 보인다. 실험결과 병렬 말뭉치 필터링을 거친 사전학습모델이 그렇지 않은 모델보다 더 좋은 성능을 보였다. 본 실험결과를 통 해 데이터의 양보다 데이터의 질을 고려하는 것이 중요함을 보이고, 해당 프로세스를 통해 추후 말뭉치 구축에 있어 하나의 가이드라인으로 활용될 수 있음을 보였다.","In the latest trend of machine translation research, the model is pretrained through a large mono lingual corpus and then finetuned with a parallel corpus. Although many studies tend to increase the amount of data used in the pretraining stage, it is hard to say that the amount of data must be increased to improve machine translation performance. In this study, through an experiment based on the mBART model using parallel corpus filtering, we propose that high quality data can yield better machine translation performance, even utilizing smaller amount of data. We propose that it is important to consider the quality of data rather than the amount of data, and it can be used as a guideline for building a training corpus."
사전학습 언어 모델을 활용한 트랜스포머 기반 텍스트 요약,2021,"['딥러닝', '자동 문서 요약', '트랜스포머', '사전학습 언어 모델', 'Deep Learning', 'Automatic Text Summarization', 'Transformer', 'Pre-trained Language Model']","소셜 미디어의 등장으로 많은 양의 텍스트 데이터가 온라인상에서 생산 및 유통되면서, 정보 이용자가 방대한 정 보로부터 필요한 정보만을 추려내는 작업은 더욱 어려워지게 되었다. 이로 인해 많은 양의 텍스트를 자동으로 요약 하기 위한 다양한 시도가 이루어지고 있으며, 특히 최근에는 풍부한 표현의 요약문을 새롭게 생성할 수 있는 추상 요약 접근법에 대한 연구가 활발히 수행되고 있다. 추상 요약 분야에서는 신경망 기반의 트랜스포머 모델이 우수한 성능을 보이며 널리 활용되고 있지만, 충분한 양의 학습 데이터가 확보되지 않으면 트랜스포머를 구성하고 있는 매 개변수의 학습이 충분히 이루어지지 않아서 양질의 요약문을 생성하기 어렵다는 한계를 갖는다. 따라서 본 연구는 소량의 학습 데이터가 주어진 상황에서도 양질의 요약문을 생성하기 위해, 한국어 사전학습 언어 모델인 KoBERT의 일부 요소를 추출하여 트랜스포머 기반의 추상 요약 모델에 적용하는 문서 요약 방안을 제시한다. 제안 방법론의 우 수성을 검증하기 위해 Dacon의 한국어 문서 생성 요약 데이터 42,803건에 대한 요약 실험을 수행한 결과, 제안 방법 론이 비교 방법론에 비해 요약 품질을 평가하는 지표인 ROUGE 기준으로 우수한 성능을 보임을 확인하였다.","As a large amount of text data is produced and distributed online with the advent of social media, it has become more difficult for users to extract only necessary information from a vast amount of information. As a result, various attempts have been made to automatically summarize a large amount of text. In particular, the abstractive summarization approach is being actively studied because it can create a new summary with rich contextual expressions. In the abstractive summarization task, neural network-based transformer models show high-performance and are used widely. However, if a sufficient amount of training data is not provided, it is difficult to generate a high-quality summary because the parameters constituting the transformer are not sufficiently learned. In this work, we proposes a text summarization method that generates a high-quality summary given a small amount of training data. Specifically, we extract some elements of KoBERT and apply them to a transformer-based abstractive summarization model. We conducted an experiment on 42,803 cases of Dacon's summary data to evaluate the performance of the proposed methodology. As a result of the experiment, it was confirmed that the proposed methodology showed superior performance based on the ROUGE index compared to the comparative method."
YOLOv4와 라즈베리파이 기반 쓰레기 분리배출 자동화 시스템,2021,"['딥러닝', '라즈베리파이', '재활용 쓰레기', '욜로', '욜로 버전4', 'Deep Learning', 'Rasberry Pi', 'Recycling Waste', 'YOLO', 'YOLOv4']",,"This paper proposes an automatic segregation system that classifies waste into 9 classes (can, pet, pen, mouse, paper box, clip, key, vinyl, coffee wrapping plastic alike stick), using the YOLOv4 model and Raspberry Pie. Our system consists of three parts, (1) Waste Classification based on YOLOv4, (2) Waste Disposal based on Rasberry Pie, and (3) Waste Management Application for inspection and retrain. We construct a big waste dataset by crawling data, using public data and making self-product data and improve the model accuracy up to 90%, maintaining the real-time performance of the YOLOv4 model. Our system is optimized in a real environment through various experiments on parameter optimization, data augmentation, and effect on the iteration number of the model train."
Double-Averaging Acceleration with Synchronization Barrier Repositioning and Pipelining in Deep Learning,2021,"['딥러닝', '분산학습', 'deep learning', 'distributed training', 'local SGD', 'double-averaging']",,
MI 센서기반의 금속탐지를 위한 RNN 알고리즘 설계에 관한연구,2021,"['딥러닝', '전자기유도', '자기임피던스센서', '다중센서', '순환신경망', 'Deep Learning', 'Electromagnetic Induction', 'MI Sensor', 'Multi Sensor', 'RNN']",,"This paper is a study of metal detection methods using multiple MI sensors using deep learning. The MI sensor is a sensor that measures the impedance change of an atypical wire by the electrical conduction and transmittance of a detector. Simple principles, small power consumption, and compact manufacturing are possible. This is a field-available sensor that requires limited weight and power, such as a mobile environment. However, sensors are generally weak in strength due to the nature of sensors that detect changes in magnetic fields. This paper compares and analyzes the detection performance with the depth of each network for location detection via RNN on 16-channel raw data extracted from sensors in a self-impedance manner."
Generative Adversarial Networks Using Pre-trained Generator for Effective Auditory Noise Suppression,2021,"['딥러닝', '음향잡음 제거', '사전훈련', '적대적 생성망', 'deep learning', 'auditory noise suppression', 'pre-training', 'generative adversarial network']",,
BERT 기반 감성분석을 이용한 추천시스템,2021,"['딥러닝', '추천시스템', '감성분석', 'BERT', 'deep learning', 'recommender system', 'sentiment analysis', 'CRM']",,"If it is difficult for us to make decisions, we ask for advice from friends or people around us. When we decide to buy products online, we read anonymous reviews and buy them. With the advent of the Data-driven era, IT technologys development is spilling out many data from individuals to objects. Companies or individuals have accumulated, processed, and analyzed such a large amount of data that they can now make decisions or execute directly using data that used to depend on experts. Nowadays, the recommender system plays a vital role in determining the users preferences to purchase goods and uses a recommender system to induce clicks on web services (Facebook, Amazon, Netflix, Youtube). For example, Youtubes recommender system, which is used by 1 billion people worldwide every month, includes videos that users like, like and videos they watched. Recommended system research is deeply linked to practical business. Therefore, many researchers are interested in building better solutions. Recommender systems use the information obtained from their users to generate recommendations because the development of the provided recommender systems requires information on items that are likely to be preferred by the user. We began to trust patterns and rules derived from data rather than empirical intuition through the recommender systems. The capacity and development of data have led machine learning to develop deep learning. However, such recommender systems are not all solutions. Proceeding with the recommender systems, there should be no scarcity in all data and a sufficient amount. Also, it requires detailed information about the individual. The recommender systems work correctly when these conditions operate. The recommender systems become a complex problem for both consumers and sellers when the interaction log is insufficient. Because the sellers perspective needs to make recommendations at a personal level to the consumer and receive appropriate recommendations with reliable data from the consumers perspective.  In this paper, to improve the accuracy problem for appropriate recommendation to consumers, the recommender systems are proposed in combination with context-based deep learning. This research is to combine user-based data to create hybrid Recommender Systems. The hybrid approach developed is not a collaborative type of Recommender Systems, but a collaborative extension that integrates user data with deep learning. Customer review data were used for the data set. Consumers buy products in online shopping malls and then evaluate product reviews. Rating reviews are based on reviews from buyers who have already purchased, giving users confidence before purchasing the product. However, the recommendation system mainly uses scores or ratings rather than reviews to suggest items purchased by many users. In fact, consumer reviews include product opinions and user sentiment that will be spent on evaluation. By incorporating these parts into the study, this paper aims to improve the recommendation system. This study is an algorithm used when individuals have difficulty in selecting an item. Consumer reviews and record patterns made it possible to rely on recommendations appropriately. The algorithm implements a recommendation system through collaborative filtering. This studys predictive accuracy is measured by Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE). Netflix is strategically using the referral system in its programs through competitions that reduce RMSE every year, making fair use of predictive accuracy. Research on hybrid recommender systems combining the NLP approach for personalization recommender systems, deep learning base, etc. has been increasing.  Among NLP studies, sentiment analysis began to take shape in the mid-2000s as user review data increased. Sentiment analysis is a text classification task based on machine learning. The machine learning-based sentiment analysis has a disadvan"
가상 환경과 실제 환경의 병행 강화학습을 통한 실내 자율주행,2021,"['딥러닝', '가상 환경', '실제 환경', '병행 학습', '센서', '특징점 검출', 'Deep Learning', 'Virtual Environment', 'Real Environment', 'Parallel Learning', 'Sensor', 'Feature Point Detection']","강화 학습을 통한 실내 자율주행을 위해 가상 환경과 실제 환경에서 학습을 병행하는 방법을 제안한다. 실제 환경에서만 학습을 진행했을 경우 80시간 정도의 소요 시간이 필요하지만, 실제 환경과 가상 환경을 병행하며 학습을 진행했을 경우 50시간의 소요 시간이 필요하다. 가상 환경과 실제 환경에서 학습을 병행하면서 빠른 학습으로 다양한 실험을 거쳐 최적화된 파라미터를 얻을 수 있는 이점이 있다. 실내복도 이미지를 이용하여 가상 환경을 구성한 후 데스크톱으로 선행학습을 진행하였고 실제 환경에서의 학습은 Jetson Xavier를 기반으로 다양한 센서와 연결하여 학습을 진행하였다. 또한, 실내복도 환경의 반복되는 텍스처에 따른 정확도 문제를 해결하기 위해 복도 벽의 아랫선을 강조하는 특징점 검출을 학습하여 복도 벽 객체를 판단하고 정확도를 높일 수 있었다. 학습을 진행할수록 실험 차량은 실내복도 환경에서 복도 중앙을 기준으로 주행하며 평균 70회의 조향 명령을 통해 움직인다.","We propose a method that combines learning in a virtual environment and a real environment for indoor autonomous driving through reinforcement learning. In case of learning only in the real environment, it takes about 80 hours, but in case of learning in both the real and virtual environments, it takes 40 hours. There is an advantage in that it is possible to obtain optimized parameters through various experiments through fast learning while learning in a virtual environment and a real environment in parallel. After configuring a virtual environment using indoor hallway images, prior learning was carried out on the desktop, and learning in the real environment was conducted by connecting various sensors based on Jetson Xavier. In addition, in order to solve the accuracy problem according to the repeated texture of the indoor corridor environment, it was possible to determine the corridor wall object and increase the accuracy by learning the feature point detection that emphasizes the lower line of the corridor wall. As the learning progresses, the experimental vehicle drives based on the center of the corridor in an indoor corridor environment and moves through an average of 70 steering commands."
효율적인 객체 검출을 위해 Attention Process를 적용한 경량화 모델에 대한 연구,2021,"['딥러닝', '특징 피라미드', '경량화', '객체 검출', 'SSD', 'Deep Learning', 'Feature Pyramid', 'Lightweight', 'Object Detection', 'SSD']",,
저화질 공공 CCTV의 영상 화질 개선 방안 연구,2021,"['딥러닝', '공공 CCTV', '화질 개선', '범죄 예방', '저화질 영상', 'Deep Learning', 'Public CCTV', 'Quality Improvement', 'Crime Prevention', 'Low-Quality Video']",,"The number of CCTV installed in Korea is over 1.3 million, increasing by more than 15% annually. However, due to the limited budget compared to the installation demand, the infrastructure is composed of 500,000 pixel low-quality CCTV, and there is a limits on identification of objects in the video. Public CCTV has high utility in various fields such as crime prevention, traffic information collection (control), facility management, and fire prevention. Especially, since installed in high height, it works as its role in solving diverse crime and is in increasing trend. However, the current public CCTV field is operated with potential problems such as inability to identify due to environmental factors such as fog, snow, and rain, and the low-quality of collected images due to the installation of low-quality CCTV. Therefore, in this study, in order to remove the typical low-quality elements of public CCTV, the method of attenuating scattered light in the image caused by dust, water droplets, fog, etc and algorithm application method which uses deep-learning algorithm to improve input video into videos over quality over 4K are suggested."
3축 가속도 센서 스트림에 대한 유한차분 및 합성곱 신경망 기반의 뇌전증 발작 감지 기법,2021,"['딥러닝', '합성곱 신경망', '다변량 분석', '유한차분법', 'IoT', '스트림 데이터', 'Deep Learning', 'CNN', 'Multivariate Analysis', 'Finite Difference Method', 'IoT', 'Stream Data']","뇌전증은 발작을 동반하는 만성 뇌질환이다. 뇌전증 발작 감지에는 일반적으로 뇌파를 활용한다. 뇌전증 발작은 불규칙한 시점에 발생하며, 지속적일 경우 뇌손상 또는 사망에 이를 수 있는 응급 상황이다. 따라서 신속한 대처를 위한 일상생활 중 뇌전증 발작의 실시간 감지가 중요하다. 그러나 센서 민감도와 같은 기술적 한계로 인하여, 현재까지는 전문 장비를 갖춘 병원에서조차 정확한 뇌파의 측정이 어렵다. 또한, 실시간으로 뇌파를 측정할 수 있는 웨어러블 기기로의 상용화는 더욱 어려운 상황이다. 따라서 3축 가속도 센서 스트림 기반 동작 인식은 일상생활 중 실시간 뇌전증 발작 감지를 위한 현실적인 대안이다. 본 논문에서는 스마트폰, 스마트워치 등에 내장된 3축 가속도 센서 데이터에 대한 유한차분 및 합성곱 신경망 기반의 뇌전증 발작 감지 기법을 제안한다. 제안하는 기법은 뇌전증 발작의 의학적 특성에 근거하여, 유한차분을 통해 각 축 값의 변화율을 구하고, 합성곱 신경망 기반의 다변량 분석을 수행하여 각 축 값 변화율 간의 관계를 통합적으로 고려한다. 제안하는 기법은 걷기, 뛰기와 같은 대표 동작 외에도 양치질, 톱질 등 뇌전증 발작과 유사한 짧은 주기의 반복 동작을 포함한 17가지 일상 상황들로부터 99% 이상의 확률로 뇌전증 발작을 감지할 수 있음을 실험을 통해 확인하였다.","Epilepsy is a chronic brain disease causing repetitive seizures. Epileptic seizures occur irregularly and are emergency situations that can lead to brain damage or even death if happen continuously. Therefore, real-time detection of epileptic seizures is important for rapid treatment. However, due to some technical limitations like sensitivity of sensors, it is difficult to accurately measure EEG even in hospitals. Also, it is even more difficult to commercialize wearable devices. Therefore, human activity recognition on 3-axis accelerometer streams is a realistic alternative for real-time detection of epileptic seizures. In this paper, we propose a epileptic seizure detection method based on finite difference and CNN for 3-axis accelerometer streams measured from smart devices. The proposed method considers the medical characteristics of epileptic seizures to calculate the finite difference of each axis, and carries out multivariate analysis based on CNN to integratively consider the relationship between rate of changes of each. Our experiments show that our method can detect the epileptic seizures with a probability of more than 99% from 17 types of daily activities including repetitive activities in short cycles being thought to be similar to epileptic seizures such as brushing teeth and sawing besides typical movements like walking or running."
GLOW 기반 에지 탐지 기법,2021,"['딥러닝', '인코더', '디코더', '에지 탐지', '계층적 표현자', 'Deep learning', 'Encoder', 'Decoder', 'GLOW', 'Edge detection', 'Hierarchical representation']",,"Since objects in images exist in various sizes, it is important to learn hierarchical representation for edge detection. In addition, since edge detection requires detailed operation at the pixel level, content leak in an image should be minimized. To this end, the traditional edge detection methods consist of a structure in which an encoder and a decoder are densely connected. However, content leak in an image occurs through pooling and convolution of encoding. In this paper, we propose an edge detection method based on GLOW to solve the problem. As GLOW consists of reversible functions, reducing content leak in an image. In order to evaluate the proposed method, BSDS500 dataset and BIPED dataset were respectively trained and comparatively analyzed. The experimental results showed that the proposed method detected reasonable edges in images. Furthermore, it was confirmed that when the proposed method was applied to a painting work image, which is a domain other than a photographic image, the proposed method detected edges more precisely than the existing method."
심층신경망 모델을 이용한 대기오염망 자료확정 알고리즘 연구,2021,"['대기질', '딥러닝', '이상탐지', '대기오염측정망', '기계학습', 'Air Quality', 'Deep Learning', 'Abnormal Detection', 'Air Pollution Monitoring Network', 'Machine Learning.']",,
추가 사전학습 기반 지식 전이를 통한 국가 R&D 전문 언어모델 구축,2021,"['국가 R&D', '지식 전이', '사전학습 모델', 'BERT', '추가 사전학습', 'National R&D', 'Knowledge Transfer', 'Pre-trained Language Model', 'Further Pre-training']","최근 딥러닝 기술이 빠르게 발전함에 따라 국가 R&D 분야의 방대한 텍스트 문서를 다양한 관점에서 분석하기 위한 수요가 급증하고 있다. 특히 대용량의 말뭉치에 대해 사전학습을 수행한 BERT(Bidirectional Encoder Representations from Transformers) 언어모델의 활용에 대한 관심이 높아지고 있다. 하지만 국가 R&D와 같이 고도로 전문화된 분야에서 높은 빈도로 사용되는 전문어는 기본 BERT에서 충분히 학습이 이루어지지 않은 경우가 많으며, 이는 BERT를 통한 전문 분야 문서 이해의 한계로 지적되고 있다. 따라서 본 연구에서는 최근 활발하게 연구되고 있는 추가 사전학습을 활용하여, 기본 BERT에 국가 R&D 분야 지식을 전이한 R&D KoBERT 언어모델을 구축하는 방안을 제시한다. 또한 제안 모델의 성능 평가를 위해 보건의료, 정보통신 분야의 과제 약 116,000건을 대상으로 분류 분석을 수행한 결과, 제안 모델이 순수한 KoBERT 모델에 비해 정확도 측면에서 더 높은 성능을 나타내는 것을 확인하였다.","With the recent rapid development of deep learning technology, the demand for analyzing huge text documents in the national R&D field from various perspectives is rapidly increasing. In particular, interest in the application of a BERT(Bidirectional Encoder Representations from Transformers) language model that has pre-trained a large corpus is growing. However, the terminology used frequently in highly specialized fields such as national R&D are often not sufficiently learned in basic BERT. This is pointed out as a limitation of understanding documents in specialized fields through BERT. Therefore, this study proposes a method to build an R&D KoBERT language model that transfers national R&D field knowledge to basic BERT using further pre-training. In addition, in order to evaluate the performance of the proposed model, we performed classification analysis on about 116,000 R&D reports in the health care and information and communication fields. Experimental results showed that our proposed model showed higher performance in terms of accuracy compared to the pure KoBERT model."
인공지능(AI) 기반 치매 조기진단 방법론에 관한 연구,2021,"['인공지능', '딥러닝', '치매', '치매 조기진단', '아밀로이드 플라크', 'AI', 'Deep learning', 'Dementia', 'Early diagnosis of dementia', 'Amyloid-plaques']",,"The number of dementia patients in Korea is estimated to be over 800,000, and the severity of dementia is becoming a social problem. However, no treatment or drug has yet been developed to cure dementia worldwide. The number of dementia patients is expected to increase further due to the rapid aging of the population. Currently, early detection of dementia and delaying the course of dementia symptoms is the best alternative. This study presented a methodology for early diagnosis of dementia by measuring and analyzing amyloid plaques. This vital protein can most clearly and early diagnose dementia in the retina through AI-based image analysis. We performed binary classification and multi-classification learning based on CNN on retina data. We also developed a deep learning algorithm that can diagnose dementia early based on pre-processed retinal data. Accuracy and recall of the deep learning model were verified, and as a result of the verification, and derived results that satisfy both recall and accuracy. In the future, we plan to continue the study based on clinical data of actual dementia patients, and the results of this study are expected to solve the dementia problem."
Cross-Validated Ensemble Methods in Natural Language Inference,2021,"['앙상블', '딥러닝', '자연어처리', '자연어 추론', 'ensemble', 'deep learning', 'natural language processing', 'natural language inference']",,
Feature Pyramid Network-based Long-Distance Drone Detection Method,2021,"['CNN', '딥러닝', '드론', 'FPN', '객체 탐지', 'deep learning', 'drone', 'object detection']",,
CNN(Convolutional Neural Network) 알고리즘을 활용한 음성신호 중 비음성 구간 탐지 모델 연구,2021,"['음성인식', '딥러닝', '합성곱신경망', '인공지능', 'NLP', 'Speech Recognition', 'Deep-Learning', 'CNN', 'Artificial-Intelligence', 'NLP']",,
파운드 푸티지 장르가 결합된 StyleGAN 이미지 기반 영상 제작,2021,"['인공지능', '딥러닝', '영화', '파운드 푸티지', '융합', 'Artificial Intelligence', 'Deep Learning', 'Movie', 'Found Footage', 'Convergence']",,"This study describes the process of the video production based on StyleGAN image combined with the found footage. We informed by the situation in which wearing a mask has become a routine and it symbolizes the change before and after COVID-19, cause of difference. In order to express this change, ‘Communication Gap’ was expressed through dialogues between characters in two opposite situations based on Artificial Intelligence, and maximize the sense of difference, we produced a work that re-illuminates the appearance by combining the genre. In addition, we can objectively examine our ‘change’ by showing the communication barriers between the two beings divided on the ‘Zoom meeting’, and it provided the opportunity. Finally the study has produced implication of Art and Technology, in that shows the work using Artificial Intelligence."
의미론적 영상 분할의 정확도 향상을 위한 에지 정보 기반 후처리 방법,2021,"['컴퓨터비전', '머신러닝', '딥러닝', '영상처리', '의미론적 분할', 'Computer Vision', 'Machine Learning', 'Deep Learning', 'Image Processing', 'Semantic Segmentation']","컴퓨터 비전 분야의 의미론적 영상 분할(Semantic Image Segmentation) 기술은 이미지를 픽셀 단위로 분할 하여 클래스를 나누는 기술이다. 이 기술도 기계 학습을 이용한 방법으로 성능이 빠르게 향상되는 중이며, 픽셀 단위의 정보를 활용할 수 있는 높은 활용성이 주목받는 기술이다. 그러나 이 기술은 초기부터 최근까지도 계속 ‘세밀하지 못한 분할’에 대한 문제가 제기되어 왔다. 이 문제는 레이블 맵의 크기를 계속 늘리면서 발생한 문제이기 때문에, 자세한 에지 정보가 있는 원본 영상의 에지 맵을 이용해 레이블 맵을 수정하여 개선할 수 있을 것으로 예상할 수 있었다. 따라서 본 논문은 기존 방법대로 학습 기반의 의미론적 영상 분할을 유지하되, 그 결과인 레이블 맵을 원본 영상의 에지 맵 기반으로 수정하는 후처리 알고리즘을 제안한다. 기존의 방법에 알고리즘의 적용 한 뒤 전후의 정확도를 비교했을 때 평균적으로 약 1.74% 픽셀 정확도와 1.35%의 IoU(Intersection of Union) 정확도가 향상되었으며, 결과를 분석했을 때 성공적으로 본래 목표한 세밀한 분할 기능을 개선했음을 보였다.","Semantic image segmentation technology in the field of computer vision is a technology that classifies an image by dividing it into pixels. This technique is also rapidly improving performance using a machine learning method, and a high possibility of utilizing information in units of pixels is drawing attention. However, this technology has been raised from the early days until recently for ‘lack of detailed segmentation’ problem. Since this problem was caused by increasing the size of the label map, it was expected that the label map could be improved by using the edge map of the original image with detailed edge information. Therefore, in this paper, we propose a post-processing algorithm that maintains semantic image segmentation based on learning, but modifies the resulting label map based on the edge map of the original image. After applying the algorithm to the existing method, when comparing similar applications before and after, approximately 1.74% pixels and 1.35% IoU (Intersection of Union) were applied, and when analyzing the results, the precise targeting fine segmentation function was improved."
MI 센서기반의 금속탐지용 뉴럴네트워크 성능비교에 관한연구,2021,"['합성곱신경망', '딥러닝', '전자기유도', '자기임피던스센서', '순환신경망', 'CNN', 'Deep Learning', 'Electromagnetic Induction', 'MI sensor', 'RNN']",,"This paper is a study on the efficiency of the filtering method of signal processing and the metal detection method using deep learning for data obtained from multiple MI sensors. The MI sensor is a principle that detects changes in magnetic field and is a passive sensor that detects metal objects. However, when detecting a metal object, the amount of change in the magnetic field caused by the metal is small, so there is a limit to the detectable distance. In order to effectively detect and analyze this, a method using deep learning was applied. In addition, the performance of the deep learning model was compared and analyzed using the filtering method of signal processing. In this paper, the detection performance of CNN and RNN networks was compared and analyzed from the data extracted from the self-impedance sensor. The RNN model showed higher performance than the CNN model. However, in the shallow stage, the CNN model showed higher performance than the RNN model."
아동 그림 심리분석을 위한 인공지능 기반 객체 탐지 알고리즘 응용,2021,"['인공지능', '딥러닝', '객체 탐지', '영상처리', '아동 그림분석', 'Artificial Intelligence', 'Deep Learning', 'Object detection', 'Image Processing', 'Child drawing analysis']",아동 그림은 내면의 감정을 표현할 수 있는 수단으로 아동 심리 진단에 널리 이용되고 있다. 본 논문에서는 아동 그림 분석에 적용할 수 있는 아동 그림 기반의 객체 탐지 알고리즘을 제안한다. 먼저 사진에서의 그림 영역을 추출하였고 데이터 라벨링 과정을 수행하였다. 이후 라벨링된 데이터 셋를 사용하여 Faster R-CNN 기반 객체 탐지모델을 학습하고 평가하였다. 탐지된 객체 결과를 기반으로 그림 면적 및 위치 또는 색상 정보를 계산하여 그림에 대한 기초정보를 쉽고 빠르게 분석할 수 있도록 설계하였다. 이를 통해 아동 그림을 이용한 심리분석에 있어 인공지능 기반 객체 탐지 알고리즘의 활용성을 보였다.,"Children""s drawings are widely used in the diagnosis of children""s psychology as a means of expressing inner feelings. This paper proposes a children""s drawings-based object detection algorithm applicable to children""s psychology analysis. First, the sketch area from the picture was extracted and the data labeling process was also performed. Then, we trained and evaluated a Faster R-CNN based object detection model using the labeled datasets. Based on the detection results, information about the drawing""s area, position, or color histogram is calculated to analyze primitive information about the drawings quickly and easily. The results of this paper show that Artificial Intelligence-based object detection algorithms were helpful in terms of psychological analysis using children""s drawings."
장면 복잡도 기반 적응적 얼굴 마스크 탐지 모델,2021,"['인공지능', '딥러닝', '기계학습', '객체 감지', '마스크 감지', '코로나바이러스-19', 'Artificial intelligence', 'Machine learning', 'Object detection', 'Deep learning', 'Mask detection', 'COVID-19']","코로나바이러스-19(COVID-19)의 대유행에 따라 전 세계 수많은 확진자가 발생하고 있으며 국민을 불안에 떨게 하고 있다. 바이러스 감염 확산을 방지하기 위해서는 마스크를 제대로 착용하는것이 필수적이지만 몇몇 사람들은 마스크를 쓰지 않거나 제대로 착용하지 않고 있다. 본 논문에서는 영상 이미지에서의 효율적인 마스크 감지 시스템을 제안한다. 제안 방법은 우선 입력 이미지의 모든 얼굴의 영역을 YOLOv5를 사용하여 감지하고 감지된 얼굴의 수에 따라 3가지의 장면복잡도(Simple, Moderate, Complex) 중 하나로 분류한다. 그 후 장면 복잡도에 따라 3가지ResNet(ResNet-18, 50, 101) 중 하나를 기반으로 한 Faster-RCNN을 사용하여 얼굴 부위를 감지하고마스크를 제대로 착용하였는지 식별한다. 공개 마스크 감지 데이터셋을 활용하여 실험한 결과 제안한 장면 복잡도 기반 적응적인 모델이 다른 모델에 비해 가장 성능이 뛰어남을 확인하였다.","Coronavirus disease 2019 (COVID-19) has affected the world seriously. Every person is required for wearing a mask properly in a public area to prevent spreading the virus. However, many people are not wearing a mask properly. In this paper, we propose an efficient mask detection system. In our proposed system, we first detect the faces of input images using YOLOv5 and classify them as the one of three scene complexity classes (Simple, Moderate, and Complex) based on the number of detected faces. After that, the image is fed into the Faster-RCNN with the one of three ResNet (ResNet-18, 50, and 101) as backbone network depending on the scene complexity for detecting the face area and identifying whether the person is wearing the mask properly or not. We evaluated our proposed system using public mask detection datasets. The results show that our proposed system outperforms other models."
"인공지능 시대, 문화예술 분야로의 확장",2021,"['인공지능', '딥러닝', '생성모델', '문화예술콘텐츠', '인공지능-문화예술 융합연구', 'Artificial intelligence', 'Deep learning', 'Generative models', 'Arts and culture contents', 'Convergence research on AI-arts and culture']",,"The super human performance of deep learning gives rise to the drastic advances in Artificial Intelligence (AI). People in modern society are in turn likely to enjoy the latest AI-driven applications such as autonomous vehicles, neural translations, AI chat-bot and so on. The domain of art and culture research is also one of the active areas to which AI has paid much attention. In particular, AI has been highly contributed to exhibiting the interesting outcomes of generation on the artistic and cultural contents with respect to writing, painting, composing and dancing by themselves which are known to be the unique capacity of human beings. Within this context, we first introduce the foundation of AI and deep learning technology in brief which learn to generate the contents. Next, we present representative examples of the interdisciplinary research domain in order of (i) generation of painting based upon vision-based deep learning, (ii) generation of text-based contents such as novel, poem and essay and (iii) generation of music, motion and dancing contents based upon language-based deep learning. In doing so, we would like to investigate the potential of AI and future works to consider in the interdisciplinary research in art and culture."
인공지능 기반 개인 맞춤형 의류 추천 서비스 개발,2021,"['인공지능', '딥러닝', '감성 인식', '패션 코드', '의류 추천', 'TPO', 'Artificial intelligence', 'Deep Learning', 'Sensibility recognition', 'Fashion code', 'Clothing recommendation']","온라인 패션 시장의 빠른 성장과 이로 인한 온라인 선택의 확대로 인해 소비자들은 더욱 개인화된 추천 서비스에 대해 요구가 커지고 있음에도 불구하고 판매자는 수많은 소비자를 개별적으로 직접 대응할 수 없다는 문제점이 있다. 소비자의 이러한 개인화 니즈를 충족시키는 방안으로 이미지에 대한 태깅이 이루어지고 있으나 사람이 태깅하는 경우 사람마다 태깅이 매우 주관적으로 이뤄지고 있고 인공지능 태깅은 단어가 매우 제한적으로 사용자의 니즈를 충족시켜주지 못하고 있다. 이러한 문제를 해결하기 위해 인공지능으로 이미지에 포함된 제품의 형태, 속성, 감성 정보를 인식하고 이러한 정보를 코드화하고 코드의 조합으로 그 이미지가 가지고 있는 모든 정보를 나타낼 수 있는 알고리즘을 설계하였다. 이 알고리즘을 통해서 지금까지 획득이 불가능했던 패션 이미지의 감성, 패션 이미지가 표현하는 TPO 정보 등 이미지가 가지고 있는 다양한 정보를 실시간으로 획득하는 것이 가능하게 되었다. 이러한 정보를 기반으로 소비자의 취향을 분석하는 단계에서 넘어가 소비자의 취향에 당시의 유행, TPO 정보까지 결합하는 초개인화된 의류 추천이 가능해진다.","Due to the rapid growth of the online fashion market and the resulting expansion of online choices, there is a problem that the seller cannot directly respond to a large number of consumers individually, although consumers are increasingly demanding for more personalized recommendation services. Images are being tagged as a way to meet consumer s personalization needs, but when people tagging, tagging is very subjective for each person, and artificial intelligence tagging has very limited words and does not meet the needs of users. To solve this problem, we designed an algorithm that recognizes the shape, attribute, and emotional information of the product included in the image with AI, and codes this information to represent all the information that the image has with a combination of codes. Through this algorithm, it became possible by acquiring a variety of information possessed by the image in real time, such as the sensibility of the fashion image and the TPO information expressed by the fashion image, which was not possible until now. Based on this information, it is possible to go beyond the stage of analyzing the tastes of consumers and make hyper-personalized clothing recommendations that combine the tastes of consumers with information about trends and TPOs."
심층 합성곱 신경망을 사용한 인스타그램 위조품 판매 게시물 탐지,2021,"['위조품 탐지', '딥러닝', '심층 합성곱 신경망', '특징 추출', '인스타그램', 'Counterfeit detection', 'Deep learning', 'DCNN', 'Feature extraction', 'Instagram']",,"This study proposed a detection algorithm using a deep learning method to help detect counterfeit sales posts that hinder the SNS environment and further curb the widespread production of counterfeit. We analyzed 382,790 data collected from Instagram using a deep convolutional neural network (DCNN) and identified the characteristics of counterfeit sales posts. As a result of comparing detection performance using five pre-trained DCNN models, the best performance model was able to detect counterfeit sales posts with 92% performance only with images. In addition, the lightweight model also performed 90% which demonstrates the practical availability of counterfeit sales post detection algorithms in the mobile environment."
A Study on the Forecasting of Bunker Price Using Recurrent Neural Network,2021,"['Bunker price forecasting', 'RNN', 'LSTM', 'GRU', '선박 연료유 가격 예측']","본 논문에서는 딥러닝 기반의 순환신경망을 이용하여 선박 연료유 예측을 시도하였다. 해운업에서는 선박 운항비에서 연료유가 차지하는 비중이 가장 크고 가격 변동성도 크기 때문에, 해운기업은 합리적이고 과학저인 방법으로 연료유를 예측하여 시장경쟁력을 확보할 수 있다. 본 논문에서는 순환신경망 모델 3가지(RNN, LSTM, GRU)를 이용하여 싱가폴의 HSFO 380CST 벙커유 가격을 단기 예측하였다. 예측결과, 첫째, 선박 연료유 단기적 예측을 위해서는 장기 메모리를 사용하는 LSTM, GRU보다는 일반적인 RNN 모델의 성능이 우수한 것으로 분석되어, 장기적 정보의 예측 기여가 낮은 것으로 분석되었다. 둘째, 계량경제학 모델을 사용한 선행연구와 비교하여 순환신경망 모델의 예측성능이 우수한 것으로 분석되어 연료유가의 비선형적 특성을 고려한 순환신경망 모델을 통한 예측 연구의 필요성을 확인하였다. 연구의 결과는 선박 연료유의 단기 예측을 통하여 해운기업의 선박 연료유 수급 결정과 같은 의사결정에 도움이 될 수 있을 것으로 기대된다.","In this paper, we propose the deep learning-based neural network model to predict bunker price. In the shipping industry, since fuel oil accounts for the largest portion of ship operation costs and its price is highly volatile, so companies can secure market competitiveness by making fuel oil purchasing decisions based on rational and scientific method. In this paper, short-term predictive analysis of HSFO 380CST in Singapore is conducted by using three recurrent neural network models like RNN, LSTM, and GRU. As a result, first, the forecasting performance of RNN models is better than LSTM and GRUs using long-term memory, and thus the predictive contribution of long-term information is low. Second, since the predictive performance of recurrent neural network models is superior to the previous studies using econometric models, it is confirmed that the recurrent neural network models should consider nonlinear properties of bunker price. The result of this paper will be helpful to improve the decision quality of bunker purchasing."
교사교육을 위한 인공신경망 이미지인식원리 교육사례연구,2021,"['인공지능교육', '인공신경망', '딥러닝', '지도학습', '스프레드시트', 'Artificial intelligence education', 'Artificial neural network', 'Deep learning', 'Supervised learning', 'Spreadsheet']","본 논문은 예비교사와 현직교사를 위한 인공지능 소양 교육으로 적용할 수 있는 교육 사례를 연구하였다. 이 를 위해, 이미지를 인식하는 인공신경망의 동작 원리를 교육하는 사례를 제안하였다. 본 교육 사례는 인공신경망 동작 및 구현의 기초 원리 교육에 초점을 맞추어, 인공신경망 구현에 필요한 매개변수 최적화 해들을 스프레드 시트로 찾는 방법을 적용하였다. 본 논문에서는 지도학습 방식의 인공신경망에 초점을 맞추었다. 첫 번째로, 인 공신경망 원리 교육 사례로서 2종 이미지를 인식하는 인공신경망 교육 사례를 제안하였다. 두번째로 인공신경망 확장 교육 사례로서 3종 이미지를 인식하는 인공신경망 교육 사례를 제안하였다. 마지막으로 인공신경망 교육 사례를 분석한 결과와 교육 만족도 분석 결과를 제시하였다. 제안한 교육 사례를 통해, 인공신경망 동작 원리, 학습 데이터 작성 방법, 학습 데이터양에 따라 실행되는 매개변수 계산 회수 그리고 매개변수 최적화에 대해 학 습할 수 있다. 예비교사와 현직교사에 대한 교육 만족도 조사 결과는 각 조사 항목에 대해 모두 70%이상 긍정적 인 응답 결과를 나타내어, 높은 수업 적용 적합성을 나타내었다.","In this paper, an educational case that can be applied as artificial intelligence literacy education for preservice teachers and incumbent teachers was studied. To this end, a case of educating the operating principle of an artificial neural network that recognizes images is proposed. This training case focuses on the basic principles of artificial neural network operation and implementation, and applies the method of finding parameter optimization solutions required for artificial neural network implementation in a spreadsheet. In this paper, we focused on the artificial neural network of supervised learning method. First, as an artificial neural network principle education case, an artificial neural network education case for recognizing two types of images was proposed. Second, as an artificial neural network extension education case, an artificial neural network education case for recognizing three types of images was proposed. Finally, the results of analyzing artificial neural network training cases and training satisfaction analysis results are presented. Through the proposed training case, it is possible to learn about the operation principle of artificial neural networks, the method of writing training data, the number of parameter calculations executed according to the amount of training data, and parameter optimization. The results of the education satisfaction survey for preservice teachers and incumbent teachers showed a positive response result of over 70% for each survey item, indicating high class application suitability."
YOLO알고리즘을 활용한 시각장애인용 식사보조 시스템 개발,2021,"['컴퓨터 비전', '딥러닝', 'YOLO', '시각 장애인', '공통 영역', '안드로이드', '음성 합성 시스템', 'Computer Vision', 'Deep Learning', 'YOLO', 'Visually Impaired', 'Intersection over Union(IoU)', 'Android', 'Text-to-Speech']","시각이 온전한 사람들은 식사를 할 때 시각에 대한 의존도를 깊게 인지하지 못한다. 그러나 시각장애인은 식단에 어떤 음식이 있는지 알지 못하기 때문에 옆에 있는 보조인이 시각장애인 수저로 음식의 위치를 시계 방향 또는 전후좌우 등 일정한 방향으로 설명하여 그릇 위치를 확인한다. 본 논문에서는 시각장애인이 스마트폰의 카메라를 이용하여 자신의 식단을 비추면 각각의 음식 이미지를 인식하여 음성으로 음식의 이름을 알려 주는 식사보조 시스템의 개발 내용에 대해 기술한다. 이 시스템은 음식과 식기도구(숟가락)의 이미지를 학습한 YOLO모델을 통해 숟가락이 놓인 음식을 추출해 내고, 이 음식이 무엇인지를 인식하여 이를 음성으로 알려준다. 본 시스템을 통해 시각장애인은 식사보조인의 도움없이 식사를 할 수 있음으로써 자립의지와 만족도를 높일 수 있을 것으로 기대한다.","Normal people are not deeply aware of their dependence on sight when eating. However, since the visually impaired do not know what kind of food is on the table, the assistant next to them holds the blind spoon and explains the position of the food in a clockwise direction, front and rear, left and right, etc. In this paper, we describe the development of a meal assistance system that recognizes each food image and announces the name of the food by voice when a visually impaired person looks at their table using a smartphone camera. This system extracts the food on which the spoon is placed through the YOLO model that has learned the image of food and tableware (spoon), recognizes what the food is, and notifies it by voice. Through this system, it is expected that the visually impaired will be able to eat without the help of a meal assistant, thereby increasing their self-reliance and satisfaction."
자기조직화지도를 통한 아파트 가격의 패턴 분석,2021,"['자기조직화지도', '클러스터링', '데이터마이닝', '아파트 가격', '부동산', 'Self-Organization Map', 'Clustering', 'Data Mining', 'Apartment prices', 'Property']","최근 인공지능, 딥러닝, 빅데이터 등 4차 산업의 핵심 분야에 대한 관심이 커지면서 기존의 의사결정 문제 를 전통적인 방법론의 한계점을 최소화하는 과학적 접근 방식이 대두되고 있다. 특히 이런 과학적인 기법들은 주 로 금융 상품의 방향성을 예측하는데 사용되는데 본 연구에서는 사회적으로 관심이 높은 아파트 가격의 요인을 자기조직화지도를 통해 분석하고자 한다. 이를 위해 아파트 가격의 실질 가격을 추출하고 아파트 가격에 영향을 주는 총 16개의 입력 변수를 선정한다. 실험 기간은 1986년 1월부터 2021년 6월까지이며 아파트 가격의 상승 및 횡보 구간을 나눠 각 구간 별 변수들의 특징을 살펴본 결과, 상승 구간과 횡보 구간의 입력 변수의 통계적 성향이 뚜렷하게 구분되는 것을 알 수 있었다. 더불어 U1~U3 구간이 N1~N3 구간에 비해서 변수들의 표준편차 가 상대적으로 크게 나왔다. 본 연구는 중장기적으로 상승과 하락이라는 큰 주기를 갖고 있는 부동산에 대해서 현재 시점의 현황을 정량적으로 분석한 것에 의미가 있으며 향후 이미지 학습을 통해 미래 방향성을 예측하는 연구에 도움이 되기를 기대한다.","With increasing interest in key areas of the 4th industrial revolution such as artificial intelligence, deep learning and big data, scientific approaches have developed in order to overcome the limitations of traditional decision-making methodologies. These scientific techniques are mainly used to predict the direction of financial products. In this study, the factors of apartment prices, which are of high social interest, were analyzed through SOM. For this analysis, we extracted the real prices of the apartments and selected a total of 16 input variables that would affect these prices. The data period was set from 1986 to 2021. As a result of examining the characteristics of the variables during the rising and faltering periods of the apartment prices, it was found that the statistical tendencies of the input variables of the rising and the faltering periods were clearly distinguishable. I hope this study will help us analyze the status of the real estate market and study future predictions through image learning."
A Study on Acoustic Signal Characterization for Al and Steel Machining by Audio Deep Learning,2021,"['Deep Learning(딥러닝)', 'Machining(기계 가공)', 'Audio Discrimination(오디오 판별)']",,
서울시 가로경관 이미지에 대한 주관적 인지에 영향을 미치는 가로환경 요인 분석 : Deep Learning 의미론적 분할과 YOLOv3 객체 검출기법을 적용하여,2021,"['보행만족도', '가로경관', '딥러닝', '객체 검출', '의미론적 분할', 'Pedestrian Satisfaction', 'Streetscape', 'Deep Learning', 'Object Detection', 'Semantic Segmentation']",,
Predicting Chemical Structure of Drugs Using Deep Learning,2021,"['기계 학습', '딥러닝', '강화학습', '신약 개발', 'machine learning', 'deep learning', 'reinforcement learning', 'drug design']",,
흉부 X-선 영상에서 심장비대증 분류를 위한 합성곱 신경망 모델 제안,2021,"['합성곱 신경망', '딥러닝', '흉부 X-선', '분류', 'Convolutional Neural Network', 'Deep learning', 'Chest X-ray', 'Classification']","본 논문에서는 흉부 X선 영상에서 정상 심장과 비정상 심장(심장비대)을 분류할 수 있는 합성곱 신경망 모델을 제안하고자 한다. 학습 및 테스트 데이터로는 경북대학교병원에 내원하여 정상과 심장비대를 진단받은 환자들의 흉부 X-선 이미지를 획득하여 사용하였다. 제안된 합성곱 신경망 모델을 이용하였을 때의 정상 심장 및 비정상 심장(심장비대) 분류 정확도는 99.88%였다. 정상 심장 영상을 테스트 데이터로 사용하였을 때의 정확도, 정밀도, 재현율 및 F1 Score는 95%, 100%, 90%, 96%였다. 비정상 심장(심장비대) 영상을 테스트 데이터로 사용하였을 때의 정확도, 정밀도, 재현율 및 F1 Score는 95%, 92%, 100% 및 96%였다. 이러한 학습 및 테스트 분류 결과로 제안된 합성곱 신경망 모델은 흉부 X-선 영상의 특징 추출 및 분류에서 매우 우수한 성능을 보여주고 있다고 판단된다. 본 논문에서 제안하는 합성곱 신경망 모델은 흉부 X-선 영상의 질환 분류에 있어 유용한 결과를 보여줄 것으로 판단되며, 다른 의료 영상에서도 동일한 결과를 나타내는지 알아보기 위하여 추가적인 연구가 이루어져야 할 것이다.","The purpose of this study is to propose a convolutional neural network model that can classify normal and abnormal(cardiomegaly) in chest X-ray images. The training data and test data used in this paper were used by acquiring chest X-ray images of patients diagnosed with normal and abnormal(cardiomegaly). Using the proposed deep learning model, we classified normal and abnormal(cardiomegaly) images and verified the classification performance. When using the proposed model, the classification accuracy of normal and abnormal(cardiomegaly) was 99.88%. Validation of classification performance using normal images as test data showed 95%, 100%, 90%, and 96% in accuracy, precision, recall, and F1 score. Validation of classification performance using abnormal(cardiomegaly) images as test data showed 95%, 92%, 100%, and 96% in accuracy, precision, recall, and F1 score. Our classification results show that the proposed convolutional neural network model shows very good performance in feature extraction and classification of chest X-ray images. The convolutional neural network model proposed in this paper is expected to show useful results for disease classification of chest X-ray images, and further study of CNN models are needed focusing on the features of medical images."
Distributed Processing of Deep Learning Inference Models for Data Stream Classification,2021,"['데이터 스트림', '딥러닝 추론', '스태킹', '분산 처리', '아파치 스톰', 'data stream', 'deep learning inference', 'stacking', 'distributed processing', 'Apache Storm']",,
WaveNet과 Work Forward Validation을 활용한 시계열 데이터 분석,2021,"['시계열 예측', '딥러닝', '웨이브넷', '워크포워드 검증', 'time series forecasting', 'deep learning', 'WaveNet', 'work forward validation']",,
"비정형, 정형 데이터의 이미지 학습을 활용한 시장예측",2021,"['감정분석', '시장예측', '딥러닝', 'Sentiment analysis', 'Time series analysis', 'Market prediction', 'Deep learning']","금융 시계열 분석은 현대 사회의 경제적, 사회적으로 매우 중요한 역할을 하며 세계 발전에 영향을 미치는 중요한 과제지만 많은 잡음(noise)과 불확실성 등의 어려움으로 인해 금융 시계열 분석 예측은 어려운 연구 주제이다. 본 논문에서는 비정형 데이터와 정형 데이터를 함께 이미지로 변환하여 시장을 예측 하는 방법(MPIL)을 제안한다. 시장 예측을 위해 n일 기간의 비정형 데이터인 SNS, 뉴스 데이터를 감정분석하고 정형 데이터인 시장 데이터를 GADF 알고리즘으로 이미지 변환하고 이미지 학습을 통해 n+1일의 가격을 예측하는 초단기 시장을 예측한다. MPIL은 평균 정확도 56%로 기존 시장예측에 사용되던 감정분석을 활용하여 LSTM으로 시장을 예측하는 모델 평균 정확도 50%보다 높은 정확도를 보였다.","Financial time series analysis plays a very important role economically and socially in modern society and is an important task affecting global development, but due to difficulties such as a lot of noise and uncertainty, financial time series analysis prediction is a difficult research topic. In this paper, we propose a market prediction method (MPIL) by converting unstructured data and structured data into images. For market prediction, it analyzes SNS and news data, which is unstructured data for n days, and converts the market data, which is structured data, to an image with the GADF algorithm, and predicts an ultra-short market that predicts the price of n+1 days through image learning. MPIL has an average accuracy of 56%, which is higher than the 50% average accuracy of the model that predicts the market with LSTM by using sentiment analysis used for existing market forecasting."
Knowledge Completion System using Neuro-Symbolic-based Rule Induction and Inference Engine,2021,"['지식 그래프', '딥러닝', '로직 시스템', '추론 엔진', '지식 추론', 'knowledge graphs', 'deep learning', 'logic system', 'inference engine', 'knowledge inference']",,
Improving Performance of Recurrent Neural Network based Recommendations by Utilizing Personal Preferences,2021,"['추천 시스템', '딥러닝', '순환 신경망', '임베딩', 'recommendation system', 'deep learning', 'recurrent neural networks', 'embedding', 'LSTM']",,
교차소거법을 이용한 Non-IID 환경에서의 연합학습 프레임워크 설계,2021,"['연합학습', '비독립동일 분포', '교차소거', '딥러닝', '데이터프라이버시', 'Federated Learning', 'Non-Independent Identically Distributed', 'Cross-Elimination', 'Deep Learning', 'Data Privacy']","기존의 연합학습 방법론들은 중앙 서버가 학습에 참여하는 모든 로컬 클라이언트 모델의 파라미터들을 일괄적으로 통합하는 방식으로 글로벌 모델을 업데이트 하기 때문에, Non-Independent Identically Distributed (Non-IID) 환경에서 치명적인 성능 저하가 일어난다. 본 논문에서는 첫 번째 Communication round 시 각 로컬 클라이언트 내에서 충분히 수렴된 모델들로 교차성능평가를 통해 학습에 방해되는 로컬 클라이언트를 제거해나가는 CE-method(Cross Elimination method)를 제안한다. 또한, 기존 연구들에서 통일되어있지 않은 Non-IID 환경을 정의하였다. CE-method는 중앙 서버가 로컬 클라이언트의 데이터에 직접 접근하지 않고도 학습에 방해되는 로컬 클라이언트를 제거함으로써 보다 효과적이고 효율적인 연합학습을 할 수 있도록 한다. 실험 결과 CE-method를 적용한 연합학습 알고리즘은 MNIST, FashionMNIST, SVHN, CIFAR-10 이미지 분류 task에 대해 기존 대비 높은 정확도와 Communication round 단축을 보장한다.","In a Non-Independent Identically Distributed (Non-IID) environment, the existing federated learning algorithms cause fatal performance degradation, because the central sever updates the global model iteratively by aggregating the parameters of all local client models participating in training. In this paper, we proposed a CE-method(Cross Elimination method) that removes parameters of local clients in the first Communication round that interfere with training through cross-performance evaluation with sufficiently converged models within each local clients. And we defined a Non-IID environment that is not unified. CE-method perform more effective and efficient federated learning by eliminating local clients that interferes with learning without central server accessing the data of local clients. As a result of the experiment, the federated learning algorithm with CE-method is applied guarantees a significant performance improved compare to the typical federated learning for the MNIST, Fashion MNIST, SVHN, and CIFAR-10 image classification tasks."
Scan-to-BIM 자동화 기술을 활용한 건축물 단위의 BIM 모델 생성 : 강원소방학교 BIM 모델링 실증을 중심으로,2021,"['Scan-to-BIM', '자동화', '딥러닝', '파라메트릭 알고리즘', '다이나모', '공간관계', 'Scan-to-BIM', 'Automation', 'Deep Learning', 'Parametric Algorithm', 'Dynamo', 'Spatial Relationship']",,"The successful implementation of Scan-to-BIM automation depends on the entire process from scanning of buildings, including indoor facilities and furniture, to generating BIM models. However, the conventional Scan-to-BIM process requires a lot of time, manpower, and cost for the manual generation of BIM models including indoor objects. To solve this problem, this study applied a Scanto- BIM automation process using a deep learning model and parametric algorithm to an existing building, Kangwon Fire Service Academy. To improve the accuracy of the BIM model, after object data was extracted from the scan data, the data was corrected according to actual object-specific conditions. As a result, the accuracy of the BIM model created by the proposed Scan-to-BIM automation process was 91% compared to the actual area of the construction drawings. In addition, it was confirmed that the BIM objects were automatically generated for 10 object classes."
Back TranScription(BTS)기반 데이터 구축 검증 연구,2021,"['기계번역', 'BackTranScription', '병렬말뭉치', '음성인식', '딥러닝', '언어융합', 'Machine translation', 'BackTranscription', 'Parallel corpus', 'Speech recognition', 'Deep learning', 'Language convergence']",최근 인간과 컴퓨터의 상호작용(HCI)을 위한 수단으로 음성기반 인터페이스의 사용률이 높아지고 있다. 이에 음성인식 결과에 오류를 교정하기 위한 후처리기에 대한 관심 또한 높아지고 있다. 그러나 sequence to sequence(S2S)기반의 음성인식 후처리기를 제작하기 위해서는 데이터 구축을 위해 human-labor가 많이 소요된다. 최근 기존의 구축 방법론의 한계를 완화하기 위하여 음성인식 후처리기를 위한 새로운 데이터 구축 방법론인 Back TranScription(BTS)이 제안되었다. BTS란 TTS와 STT 기술을 결합하여 pseudo parallel corpus를 생성하는 기술을 의미한다. 해당 방법론은 전사자(phonetic transcriptor)의 역할을 없애고 방대한 양의 학습 데이터를 자동으로 생성 할 수 있기에 데이터 구축에 있어서 시간과 비용을 단축할 수 있다. 본 논문은 기존의 BTS 연구를 확장하여 어떠한 기준 없이 데이터를 구축하는 것보다 어투와 도메인을 고려하여 데이터 구축을 해야함을 실험을 통해 검증을 진행하였다.,"Recently, the use of speech-based interfaces is increasing as a means for human-computer interaction (HCI). Accordingly, interest in post-processors for correcting errors in speech recognition results is also increasing. However, a lot of human-labor is required for data construction. in order to manufacture a sequence to sequence (S2S) based speech recognition post-processor. To this end, to alleviate the limitations of the existing construction methodology, a new data construction method called Back TranScription (BTS) was proposed. BTS refers to a technology that combines TTS and STT technology to create a pseudo parallel corpus. This methodology eliminates the role of a phonetic transcriptor and can automatically generate vast amounts of training data, saving the cost. This paper verified through experiments that data should be constructed in consideration of text style and domain rather than constructing data without any criteria by extending the existing BTS research."
AdaBoost-GRU 앙상블 모형을 이용한 금융 시계열 예측,2021,"['AdaBoost-GRU 앙상블', '금융시계열', '딥러닝', 'AdaBoost-GRU ensemble', 'deep learning', 'financial time series']","일반적으로 금융 시계열 (financial time series) 예측은 비선형성 (non-linearity)과 불규칙성(irregularity)으로 인해 매우 어려운 일이다. 본 논문에서는 금융 시계열 예측을 위해 AdaBoost 알고리즘과 GRU 모형을 결합한 하이브리드 앙상블 학습 방법 (hybrid ensemble learning approach)을 제안하고자 한다. 여기서 GRU 모형은 LSTM (long short term memory) 모형과 함께 시계열 예측에 널리 사용되는 RNN (recurrent neural network)의 변형 모형이다. 우리는 KOSPI 데이터와 원/달러 환율과 같은 금융 시계열 데이터를 가지고 제안된 모델을 평가하고자 한다. 성능실험 결과 제안된 AdaBoost-GRU 앙상블은 3가지 척도 즉, MAE, MSE 및 RMSE 척도에서 기존의 ARIMA 모형, LSTM 모형, GRU 모형, 그리고 Adaboost-LSTM 앙상블보다 좋은 성능을 보였다. 그리고 Adaboost-LSTM 모형과의 처리속도 면에서 제안된 AdaBoost-GRU 모형이 빠름을 알 수 있었다.","In general, forecasting an financial time series is very difficult due to non-linearity and irregularity. In this paper, we propose a hybrid ensemble learning approach that combines the AdaBoost algorithm and GRU model for financial time series forecasting. Here, the GRU model is a modified structure of a recurrent neural network (RNN) widely used for time series forecasting along with a long short term memory (LSTM) model. We evaluated the proposed model with two financial time series data: KOSPI data, and won/dollar exchange rate data. As a result of performance tests, the proposed AdaBoost-GRU ensemble showed better performance than ARIMA model, single LSTM model, single GRU model, and Adaboost-LSTM ensemble in three scales: MAE, MSE and RMSE. In addition, the proposed AdaBoost-GRU ensemble was found to be fast in terms of processing speed with the Adaboost-LSTM model."
자율주행 차량의 돌발사고 방지를 위한 V2I 기반의 사고 방지체계 연구,2021,"['V2I', '자율주행자동차', '지능형교통체계', '교차로충돌방지', '딥러닝', 'V2I', 'Autonomous Vehicle', 'Intelligent transport systems', 'Intersection collision avoidance', 'Deep learning']","본 연구는 V2I통신을 이용하여 교차로 등의 사각지대로 인해 발생할 수 있는 충돌 사고를 예방하기 위한 충돌 방지체계를 제안한다. 교차로의 인프라에 위치한 Vision센서와 LiDAR센서 가 물체를 인식하고 사고 위험이 있는 차량에게 경고함으로써 사고를 미연에 방지한다. 딥러 닝 기반의 YOLOv4를 이용하여 교차로에 진입하는 물체를 인식하고 LiDAR 센서와의 Calibration을 통해 대상 물체와의 맨하탄 거리값을 이용하여 충돌 예상시간과 제동거리에 대한 가중치를 계산하고 안전거리를 확보한다. 차량-인프라간 통신은 ROS통신을 이용하였으며 충 돌 경고 외에도 진입 물체의 Class, 거리, 진행속도 등의 다양한 정보를 차량에 전달함으로써 사고를 미연에 방지하고자 하였다.","This research proposes the Accident Prevention System to prevent collision accident that can occur due to blind spots such as crossway or school zone using V2I communication. Vision sensor and LiDAR sensor located in the infrastructure of crossway somewhere like that recognize objects and warn vehicles at risk of accidents to prevent accidents in advance. Using deep learning-based YOLOv4 to recognize the object entering the intersection and using the Manhattan Distance value with LiDAR sensors to calculate the expected collision time and the weight of braking distance and secure safe distance. V2I communication used ROS (Robot Operating System) communication to prevent accidents in advance by conveying various information to the vehicle, including class, distance, and speed of entry objects, in addition to collision warning."
Wav2vec을 이용한 오디오 음성 기반의 파킨슨병 진단,2021,"['파킨슨병', '오디오음성', 'wav2vec', '딥러닝', '분류', 'Parkinson’s disease', 'human audio voice', 'wav2vec', 'deep learning', 'classification']",,
인공신경망을 이용한 교통사고 건수 예측,2021,"['교통 사고 건수', '딥러닝', '평균절대비오차', '정규화', 'Traffic accidents', 'Deep learning', 'MAPE', 'Normalization']","우리나라는 많은 교통사고로 인하여 큰 사회적 부담을 가지고 있다. 이러한 사회적 부담을 줄여주기 위한 방안을 마련하기 위해서는 정확한 교통사고 횟수에 대한 예측이 필요하다. 본 논문은 교통사고의 횟수를 줄이기 위한 교통사고 건수를 예측하기 위해, 교통사고에 주요한 영향을 미치는 상황을 확인하여 변수 데이터를 선정한 후 MLP 알고리즘을 적용한다. 또한 선정된 변수들을 지정하고 각각 다른 단위의 값을 통일하기 위해 정규화를 사용하였다. 또한 특정구간 데이터 학습을 위해 ReLU 활성화 함수를 사용하였고 계절적 패턴(강수량, 적설량, 가시성)과 예측 성능을 높이기 위해 1년 전의 교통사고 발생건수를 변수로 사용하였다. MLP(Multi-layer perceptron) 알고리즘을 적용한 모델을 구성하여 2006～2018년의 교통사고 발생건수를 예측하였고 알고리즘의 예측 성능을 평가하기 위해서 MAPE(Mean absolute percentage error)를 사용하였다. 예측 결과 MAPE가 평균 5.79으로 측정되었으며 예측값이 관측 데이터와의 오차가 7월사이에 가장 크게 발생하였고 12～3월 오차가 가장 적게 발생하였다.","Our country has a large social burden due to many traffic accident. In order to reduce and prepare social burden with its solution, we need prediction for number of exact traffic accident. This paper identifies the situation which is affecting main influence by selecting the variable data and we apply MLP(multi-layer perceptron) algorithm to predict number of traffic accident to reduce the traffic accident. We also designate choosing variables and we use normalization in order to unify values for each different unit. Then we use ReLU as an activation function to learn data for certain interval. We also use the number of traffic accident in one year ago and seasonal pattern(Rainfall, Snow, Visibility) as a variable to improve seasonal pattern prediction performance. We organize the model which is applying MLP algorithm, and we predict the number of traffic accident from 2006 to 2018. To evaluate the prediction performance, we use MAPE (mean absolute percentage error). As a result of prediction, MAPE have an average 5.79. We recognize that error between prediction and observation data was large in March through July, while error between prediction and observation data was small in December through March."
전이학습과 그래프 합성곱 신경망 기반의 다중 패션 스타일 인식,2021,"['다중 레이블 인식', '레이블 종속성', '전이학습', '그래프 합성곱 신경망', 'Multi-Label Recognition', 'Label Dependency', 'Transfer Learning', 'Graph Convolution Network']","최근 패션업계에서는 급속도로 발전하는 딥러닝 방법론을 활용하려는 시도가 늘고 있다. 이에 따라 다양한 패션 관련 문제들을 다루는 연구들이 제안되었고, 우수한 성능을 달성하였다. 하지만 패션 스타일 분류 문제의 경우, 기존 연구들은 한 옷차림이 여러 스타일을 동시에 포함할 수 있다는 패션 스타일의 특성을 반영하지 못하였다. 따라서 본 연구에서는 동시에 존재하는 레이블 간의 종속성을 모델링하고, 이를 반영하여 패션 스타일의 다중 분류 문제를 해결하고자 한다. 패션 스타일 사이의 종속성을 포착하고 탐색하기 위해 GCN(graph convolution network) 기반의 다중 레이블 인식 모델을 적용하였다. 또한 전이학습을 통해 모델의 학습 속도 및 성능을 향상시켰다. 제안하는 모델은 웹 크롤링을 통해 수집한 SNS 이미지 데이터를 이용하여 검증하였으며, 비교 모델 대비 우수한 성능을 기록하였다.","Recently, there are increasing attempts to utilize deep learning methodology in the fashion industry. Accordingly, research dealing with various fashion-related problems have been proposed, and superior performances have been achieved. However, the studies for fashion style classification have not reflected the characteristics of the fashion style that one outfit can include multiple styles simultaneously. Therefore, we aim to solve the multi-label classification problem by utilizing the dependencies between the styles. A multi-label recognition model based on a graph convolution network is applied to detect and explore fashion styles dependencies. Furthermore, we accelerate model training and improve the models performance through transfer learning. The proposed model was verified by a dataset collected from social network services and outperformed baselines."
Cryptocurrency automatic trading research by using facebook deep learning algorithm,2021,"['인공지능', '예측 시스템', 'fbprophet', '딥러닝', '기계학습', 'Artificial intelligence', 'prediction system', 'fbprophet', 'deep learning', 'machine learning']",,
Unknown 악성코드 분석을 위한 AI 기반 시각화 플랫폼,2021,"['알려지지 않은 악성코드 탐지', '딥러닝', '시각화', 'Virustotal', 'Unknown Malware Detection', 'Deep Learning', 'Visualization', 'Virustotal']",,"AI-based malware analysis is a method for analyzing and detecting numerous variants and new types of malware that were not detected by existing pattern-based vaccine engines using artificial intelligence technology. AI-based malware analysis and detection technology does not need to pre-define malware patterns, so the vaccine engines can be relatively lightweight. In this paper, we propose a deep learning-based detection system for analyzing and detecting variants and new malwares, and a web-based malware analysis platform that can check the detection results. By showing the results obtained from the AI detection system through a visualization platform, it is possible to determine how likely a file to be scanned is malicious, and to help analysts set the need and priority for analysis. Through the pre-trained model, it is possible to derive the detection result without external leakage of the file, and as the AI detection model can be changed and added as needed, the utility of the malware analysis platform is expected to be high."
경주마의 파행 분석 및 판독 인공지능 Modeling 연구,2021,"['경주마', '파행', '동작인식', '인공지능', '딥러닝', 'Racehorse', 'Lameness', 'Objective Detection', 'Motion Recognition', 'Skeleton', 'Artificial Intelligence', 'Deep Learning']",,
효율적인 병원보건관리를 위한 태아건강분류 모델,2021,"['태아건강', '분류모델', '랜덤 포레스트', '딥러닝', '리샘플링', '병원경영', 'Fetal health', 'Classification model', 'random forest', 'deep learning', 'Hosiptal Management']",,
질의문과 지식 그래프 관계 학습을 통한 지식 완성 시스템,2021,"['지식 완성', '지식 그래프', '딥러닝', '인공지능', '임베딩', '쿼리', '트리플', 'knowledge completion', 'knowledge graph', 'deep learning', 'artificial intelligence', 'embedding', 'query', 'triple']",지식 그래프는 개체들 사이의 관계로 구성된 네트워크를 뜻한다. 이러한 지식 그래프에서 특정 개체들에 대한 관계가 누락되거나 잘못된 관계 연결과 같은 문제로 불완전한 지식 그래프의 문제점이 존재한다. 불완전한 지식 그래프의 문제를 해결하기 위한 많은 연구는 자연어 임베딩 기반으로 인공 신경망을 이용한 학습 방법들을 제안했다. 이러한 방법들로 다양한 지식 그래프 완성 시스템들이 연구되고 있는데 본 논문에서는 특정 질의와 지식 그래프를 활용해 누락된 지식을 추론하는 시스템을 제안하였다. 먼저 의문형의 Query로부터 topic을 자동으로 추출하여 해당 topic 임베딩을 지식 그래프 임베딩 모듈로부터 얻는다. 그 다음 Query 임베딩과 지식 그래프 임베딩을 활용하여 지식 그래프로부터의 topic과 질의문 사이의 관계를 학습하여 새로운 트리플을 추론한다. 이와 같은 방식을 통해 누락된 지식들을 추론하고 좋은 성능을 위해 특정 질의와 관련된 지식 그래프의 술어부 임베딩을 같이 활용하였고 기존 방법보다 더 좋은 성능을 보임을 증명하기 위해 MetaQA 데이터셋을 사용하여 실험을 진행하였다. 지식 그래프는 영화를 도메인으로 갖는 지식 그래프를 사용하였다. 실험 결과로 지식 그래프 전체와 누락된 지식 그래프를 가정하여 트리플들을 임의로 50% 누락시킨 지식 그래프에서 실험하여 기존 방법보다 더 좋은 성능을 얻었다.,"The knowledge graph is a network comprising of relationships between the entities. In a knowledge graph, there exists a problem of missing or incorrect relationship connection with the specific entities. Numerous studies have proposed learning methods using artificial neural networks based on natural language embedding to solve the problems of the incomplete knowledge graph.Various knowledge graph completion systems are being studied using these methods. In this paper, a system that infers missing knowledge using specific queries and knowledge graphs is proposed.First, a topic is automatically extracted from a query, and topic embedding is obtained from the knowledge graph embedding module. Next, a new triple is inferred by learning the relationship between the topic from the knowledge graph and the query by using Query embedding and knowledge graph embedding. Through this method, the missing knowledge was inferred and the predicate embedding of the knowledge graph related to a specific query was used for good performance. Also, an experiment was conducted using the MetaQA dataset to prove the better performance of the proposed method compared with the existing methods. For the experiment, we used a knowledge graph having movies as a domain. Based on the assumption of the entire knowledge graph and the missing knowledge graph, we experimented on the knowledge graph in which 50% of the triples were randomly omitted.Apparently, better performance than the existing method was obtained."
얼굴인식 기술을 적용한 실종자 식별 시스템 설계 및 구현,2021,"['Face recognition', 'Image Processing', 'Key point extraction', 'Missing Person', 'Similarity', 'Mobile', '얼굴인식', '영상처리', '특징점 검출', '실종자', '유사도', '모바일']","본 논문에서는 비전 기술과 딥러닝 기반의 얼굴인식을 통해 실종자를 식별하는 방법을 제안하였다. 모바일 디바이스에서 전송된 원본 이미지에 대해 얼굴인식에 적합하도록 이미지를 전처리한 후, 얼굴인식의 정확도 향상을 위한 이미지 데이터 증식과 CNN 기반 얼굴학습 및 검증을 통해 실종자를 인식하였다. 본 논문의 구현 결과를 이용하여 가상의 실종자 이미지를 식별한 결과, 원본 데이터와 블러 처리한 데이터를 함께 학습한 모델의 성능이 가장 우수하게 나왔다. 또한 사전학습된 가중치를 사용한 학습 모델은 사용하지 않은 모델보다 높은 성능을 보였지만, 편향과 분산이 높게 나오는 한계를 확인할 수 있었다.","In this paper proposes a method of finding missing persons based on face-recognition technology and deep learning. In this paper, a real-time face-recognition technology was developed, which performs face verification and improves the accuracy of face identification through data fortification for face recognition and convolutional neural network(CNN)-based image learning after the pre-processing of images transmitted from a mobile device. In identifying a missing person’s image using the system implemented in this paper, the model that learned both original and blur-processed data performed the best. Further, a model using the pre-learned Noisy Student outperformed the one not using the same, but it has had a limitation of producing high levels of deflection and dispersion."
인공지능 융합교육을 위한 데이터 기반 교육자료 개발: 감쇠진동을 중심으로,2021,"['AI 융합교육', '과학교육', '딥러닝', '지도학습', 'AI Convergence Education', 'Science Education', 'Deep Learning', 'Supervised Learning']",,"In preparation for the era of automation led by Artificial Intelligence(AI), we need to restruct science · mathematics · informatics curriculum and convergence education. However, data-driven teaching materials that teachers can utilize into school science classes are still insufficient. In this study, we have developed data-driven teaching materials for AI convergence education which can be applied to science classes. The teaching materials were developed by Google Colaboratory, which can be easily distributed online, and used the deep supervised learning method that is widely used in machine learning in recent years. Furthermore, we explained the learning process and code in detail for processes for learning and teaching and visualized the results to help users to understand intuitively."
Prediction of Fine Dust in Gyeonggi-do Industrial Complex using Machine Learning Methods,2021,"['미세먼지', '반월시화산업단지', '예측', '인공지능', '딥러닝', 'fine dust', 'PM&lt', 'SUB&gt', '2.5&lt', '/SUB&gt', 'Banwol Shihwa National Industrial Complex', 'prediction', 'artificial intelligence', 'deep learning']",,
심탄도와 인공지능을 이용한 혈당수치 예측모델 연구,2021,"['혈당수치 예측', 'MLP', '딥러닝', '심박변이도', 'IoT 디지털기기', 'ICT 융복합', 'Blood glucose level prediction', 'MLP', 'Deep Learning', 'Heart Rate Variability', 'IoT  Digital device', 'ICT Convergence']",,
3차원 형상 복원을 위한 점진적 점유 예측 네트워크,2021,"['3차원 복원', '음함수', '딥러닝', '점유 네트워크', '3D reconstruction', 'implicit function', 'deep learning', 'Occupancy network']","3차원 형상 복원(3D reconstruction)은 이미지 또는 영상 속 물체를 3차원 형상으로 복원하는 것을 말한다. 본 연구는 물체의 전반적 형상을 넘어 세부적인 모습까지 복원할 수 있는 표현력을 가진 3차원 형상 복원 네트워크인, 점진적점유 네트워크를 제안한다. 본 연구가 제안하는 네트워크는 이미지 전체의 정보를 담고 있는 특징(feature)을 사용하는 기존 점유 네트워크와 달리, 수용영역(receptive field)의 크기에 따라 다양한 수준의 이미지 특징을 추출해서 사용한다. 그리고, 다양한 수준의 이미지 특징을 디코더(decoder) 내 디코더 블록(decoder block)들에 순차적으로 반영하여, 형상 복원의 품질이 단계적으로 개선하는 네트워크 구조를 제안한다. 본 연구는 또한, 다양한 수준의 이미지 특징을 적절히 조합하여 사용하는 디코더 블록 구조를 제안한다. 본 연구는 제안하는 네트워크의 성능 검증을 위해 ShapeNet 데이터 세트를 사용하였으며, 기존의 점유 네트워크(ONet) 및 다양한 수준의 이미지 특징을 사용하는 최신 연구(DISN)와 성능 비교하였다. 그 결과, 기존점유 네트워크 대비 세 가지 검증지표 모두에서 높은 성능을 달성하였으며, DISN과는 대등한 수준의 성능을 보여주었다. 그리고 복원 형상의 시각적 비교 결과, 본 연구의 점진적 점유 네트워크가 기존 점유 네트워크 대비, 물체의 세부 모습을 잘 복원하는 것을 확인하였다. 또한, DISN이 복원 실패한 물체의 얇은 부분 또는 이미지에서 가려진 부분을 본 연구의 네트워크는 잘 잡아내는 결과를 확인할 수 있었다. 이러한 결과는 본 연구가 제안하는 점진적 점유 네트워크의 유용성을 검증하는 결과다.","3D reconstruction means that reconstructing the 3D shape of the object in an image and a video. We proposed a progressive occupancy network architecture that can recover not only the overall shape of the object but also the local details. Unlike the original occupancy network, which uses a feature vector embedding information of the whole image, we extract and utilize the different levels of image features depending on the receptive field size. We also propose a novel network architecture that applies the image features sequentially to the decoder blocks in the decoder and improves the quality of the reconstructed 3D shape progressively. In addition, we design a novel decoder block structure that combines the different levels of image features properly and uses them for updating the input point feature. We trained our progressive occupancy network with ShapeNet. We compare its representation power with two prior methods, including prior occupancy network(ONet) and the recent work(DISN) that used different levels of image features like ours. From the perspective of evaluation metrics, our network shows better performance than ONet for all the metrics, and it achieved a little better or a compatible score with DISN. For visualization results, we found that our method successfully reconstructs the local details that ONet misses. Also, compare with DISN that fails to reconstruct the thin parts or occluded parts of the object, our progressive occupancy network successfully catches the parts. These results validate the usefulness of the proposed network architecture."
GPT-2 for Knowledge Graph Completion,2021,"['지식 완성', '지식 그래프', '딥러닝', '인공지능', '임베딩', '트리플', 'knowledge completion', 'knowledge graph', 'deep learning', 'artificial intelligence', 'word embedding', 'triple']",,
임베디드 시스템에서 효율적인 차량 번호판 인식 시스템,2021,"['차량 번호판 인식', '딥러닝', '임베디드 시스템', '객체 검출', '합성곱 신경망', 'License Plate Recognition', 'Deep learning', 'Object detection', 'CNN']",,
드론 및 AI를 이용한 해안 쓰레기 모니터링 체계: 제주도 사례 중심으로,2021,"['해안 쓰레기', '모니터링', '드론', '딥러닝', 'Coastal Garbage', 'Monitoring', 'Drone', 'Deep Learning']","현재 해안 쓰레기 모니터링은 국가 통계자료 구축을 위해 조사자에 의하여 수행되고 있으나, 그 결과가 지자체의 수거 및 처리 업무에 활용되지 못하고 있다. 본 연구에서는 모니터링의 효율성을 제고하고, 수거 및 처리 실무를 지원할 수 있도록 드론 시스템과 AI 탐지 기술을 융합한 해안 쓰레기 모니터링 체계를 제안한다. 이를 위해 국가 해안 쓰레기 모니터링 사업과 지자체의 해안 쓰레기 관리 업무를 각각 분석하여 한계점을 도출하였다. 도출된 한계점을 극복하며 통계자료 구축과 실무를 모두 지원할 수 있는 드론 데이터 수집 시스템, AI 활용 자동 데이터 처리 및 분석 시스템, 수집 데이터 및 분석 정보 공유 시스템으로 구성된 모니터링 체계를 구상하였다. 제안한 체계의 효용성을 확인하고자 핵심적인 데이터 수집과 쓰레기 탐지 영역에 대하여 시범 적용하였다. 그 결과 자동으로 드론 항공 영상을 수집하고 83.2%의 정확도를 갖고 해안 쓰레기를 탐지할 수 있었다. 향후 정확도 개선을 통해 관리 사각지대를 해소하며, 수거 체계의 효율성 향상에 기여할 수 있을 것으로 판단된다.","Currently, coastal garbage monitoring is being conducted by investigators to build national statistical data, and the results are not being utilized in the garbage collection and disposal of local governments. In this study, we propose a coastal garbage monitoring system that combines a drone system and AI detection technology to improve monitoring efficiency and support the collection and disposal tasks. To this end, the limitations were drawn by analyzing the national coastal waste monitoring project and the local government""s coastal garbage management work, respectively. While overcoming the derived limitations, a monitoring system was devised to support both statistical data research and collection work. The monitoring system consists of a drone data acquisition system, an automatic data processing and analysis system using AI, and a system for sharing the collected data and analysis information. In order to confirm the effectiveness of the proposed system, the data collection and garbage detection areas, which are the core parts, were pilot-applied. As a result, it was able to automatically acquire drone aerial images and detect coastal garbage with an accuracy of 83.2%. By introducing the system, it will be possible to reduce management blind spots and improve the efficiency of the collection and disposal tasks in the future."
강화학습 기반 주식 투자 웹 서비스,2021,"['주가 분석', '강화학습', '딥러닝', '웹서비스', 'Stock Price Analysis', 'Reinforcement Learning', 'Deep Learning', 'Web Service']","코로나-19로 인해 경제 활동이 낮아지고 주식 시장이 침체하면서 주식 투자를 통해 또 다른 소득을 마련하기 위해 많은 사람이 주식 시장에 뛰어들고 있다. 사람들의 관심이 높아지면서 더 많은 수익을 얻기 위한 주가 분석 연 구가 많이 진행되고 있다. 주가는 종목별 변동의 흐름이 다르므로 각 주가 종목별로 독립적이며 일관적으로 분석할 필요가 있다. 이러한 문제를 해결하고자 본 논문에서는 강화학습 기법 중 하나인 Asynchronous Advantage Actor- Critic(A3C)를 이용하여 주가를 분석할 수 있는 모델 및 서비스를 설계 및 구현하였다. 주식 시장 데이터로 종목별 주가 및 국채, 코스피와 같은 외부 요인들을 반영하였다. 또한 웹페이지 제작을 통해 시각화한 정보를 제공하여 투자 자들이 투자 기업에 대한 재무제표를 비롯하여 국내외 경제 및 정치의 흐름을 모두 분석하지 않고도 안전한 투자를 할 수 있도록 서비스를 제공한다.","As economic activities decrease, and the stock market decline due to COVID-19, many people are jumping into stock investment as an alternative source of income. As people's interest increases, many stock price analysis studies are underway to earn more profits. Due to the variance observed in the stock markets, it is necessary to analyze each stock independently and consistently. To solve this problem, we designed and implemented models and services that analyze stock prices using a reinforcement learning technique called Asynchronous Advantage Actor-Critic(A3C). Stock market data reflected external factors such as government bonds and KOSPI (Korea Composite Stock Price Index) as well as stock prices. Our proposed work provides a web service with a visual representation of predictions of stocks and stock information through which directions are given to investors to make safe investments without analyzing domestic and foreign stock market trends."
인공지능의 개념 소유에 관한 고찰,2021,"['인공지능', '개념 소유', '개념의 구조', '챗봇 테이', '개념 이론', 'artificial intelligence', 'concepts possession', 'structure of concepts', 'Chatbot Tay', 'theory of concepts']","챗봇 테이(Tay)는 딥러닝을 통해 스스로 학습하면서 사람들과 대화가 가능한 인공지능이다. 이러한 인공지능은 일상 언어를 잘 사용하는 듯 하지만 편향된 방식으로 학습할 경우 개념을 결여한 듯 보이는 발언을 하기도 한다. 이에 대해 필자는 약한 의미의 개념 소유와 강한 의미의 개념 소유를 구분한 다음, 테이가 약한 의미에서는 개념을 소유하지만 강한 의미에서는 개념을 소유하지 않음을 논증한다. 이는 생각하며 대화하는 인공지능이 가능한가에 대한 비판적 접근의 일환이다.","Chatbot Tay is the artificial intelligence that performs autonomously deep learning and can communicate with people. This artificial intelligence seems to use ordinary languages very well but sometimes it also shows speeching acts that are suspected to lack of concepts. In this point, I argue that, after separating concepts possession in weak sense and strong sense, Tay possesses concepts in weak sense but doesn’t possess concepts in strong sense. This is a part of critical approach about the question of “Is it possible that artificial intelligence ponderingly speaks?”"
Relation Extraction based on Neural-Symbolic Structure,2021,"['뉴럴-심볼릭', '관계추출', '딥러닝', '자연어처리', 'neural-symbolic', 'relation extraction', 'deep learning', 'natural language processing']",,
텍스트 트랜스포머 모델에서 어텐션 맵을 이용한 경사도 기반 화이트 박스 적대적 예제 생성 방안,2021,"['트랜스포머', '적대적 예제', '딥러닝', '텍스트 데이터', '화이트박스', 'Transformer', 'Adversarial example', 'Deep learning', 'Text data', 'Whitebox']",,"Abstract should be placed here. These instructions give you guidelines for preparing papers for JDCS. The method of generating Adversarial examples for text data of the transformer model was mostly a black box attack method because of the discrete characteristics of text data. Recently, a gradient-based white box attack method targeting text data of a transformer model has been announced, which has the disadvantage that it takes a long time and is not efficient because it learns one distribution for each generation of an example. This paper improves the efficiency of the existing white box attack method by proposing an attention constraint using the attention structure of the transformer model. Through experiments, it has been proven that the generation time can be shortened by about 6.5% and the diversity of generated adversarial examples can be increased by 2.4% compared to the previous research results."
AlphaPose를 활용한 LSTM(Long Short-Term Memory) 기반 이상행동인식,2021,"['안전관리', '행동인식', 'Pose Estimation', 'LSTM', '딥러닝', 'Safety Management', 'Action Recognition', 'Pose Estimation', 'LSTM', 'Deep Learning']",,"A person's behavioral recognition is the recognition of what a person does according to joint movements. To this end, we utilizecomputer vision tasks that are utilized in image processing. Human behavior recognition is a safety accident response service that combinesdeep learning and CCTV, and can be applied within the safety management site. Existing studies are relatively lacking in behavioralrecognition studies through human joint keypoint extraction by utilizing deep learning. There were also problems that were difficult tomanage workers continuously and systematically at safety management sites. In this paper, to address these problems, we propose a methodto recognize risk behavior using only joint keypoints and joint motion information. AlphaPose, one of the pose estimation methods, wasused to extract joint keypoints in the body part. The extracted joint keypoints were sequentially entered into the Long Short-Term Memory(LSTM) model to be learned with continuous data. After checking the behavioral recognition accuracy, it was confirmed that the accuracyof the ""Lying Down"" behavioral recognition results was high."
보행자검출을 통한 상권 분석 알고리즘,2021,"['보행자 검출', 'YOLO', '상권', '빅데이터', '딥러닝', 'Pedestrian-Detection', 'YOLO', 'business district', 'big data', 'deep learning']",,"In this paper, we propose an algorithm that provide services to consumers who want to conduct business by scientifically and systematically analyzing the number of pedestrians in a specific area over a specific period of time. In this paper, we proposed the algorithm to analyze the commercial area using the pedestrian-detect algorithm in the particular region using YOLO, one of the deep learning techniques. And with one image per minute in the images, the number of pedestrians is identified and this information is used for the analysis of business district on interesting area and time, systematically and objectively."
인공지능으로 유교성인 만들기 ― 한국철학의 정초를 위한 실험철학적 시론 ―,2021,"['유교 성인', 'AI', '실험철학', '한국철학', '체화된 마음', '딥러닝', 'Confucian sage', 'experimental philosophy', 'Korean philosophy', 'embodied mind', 'deep learning']","이 글의 목적은 ‘유교 성인 AI 만들기’의 사고 실험을 통해 어떻게 한국철학이 가능할 것인지를 모색해보는 데 있다. 한국철학은 한국인이 부딪힌 구체적인 사회현실의 문제점들 속에서 보편적 해결방식을 모색해보는 것이다. 유교 성인 AI 만들기는 공정성 훼손, 부의 양극화, 이념적 대립의 한국문제를 유교 성인이라는 대안으로 해결해 나가는 과정을 가리킨다.이러한 사고가 가능한 것은 유교 성인의 교육프로그램과 AI의 학습과 정이 유사하기 때문이다. 그것은 중앙집권적이고, 연쇄적이며, 이성적인 것이 아니고, 국소적이고 통합적이며, 감정적인 것이다. 이러한 유사성의 지적은 덕의 행동주의적 해석, 감정의 기능주의적 해석, 깨달음에 대한 객관주의적 해석의 가정하에 이루어진다.‘유교 성인 AI 만들기’의 시도는 그 구현에 있어서 설사 실패로 돌아가더라도, 철학적이고 교육적인 측면에서는 많은 도움이 될 것이다. 결국 ‘유교 성인 AI 만들기’는 사회 문제 해결을 위한 집단 지성의 탐구 과정이 될 것이기 때문이다.","The purpose of this paper is to explore how Korean philosophy will be possible through the thought experiment of ‘Making Confucian Sage AI’. By Korean Philosophy, I mean the attempt to find universal solutions to the specific social realities faced by Koreans. Making Confucian Sage AI refers to the process of resolving the present Korean problems of the damage of fairness, the extreme wealth polarization, and ideological confrontation among Koreans. This kind of thinking is possible because the educational program for Confucian sage and the learning process of AI are similar. It is characterized not by centralized, sequential, and rational, but by local, integrated, and emotional. These similarities are pointed out under the assumption of a behaviorist interpretation of virtue, a functionalist interpretation of emotion, and an objectivist interpretation of enlightenment. Even if this attempt to 'make Confucian sage AI' fails in its implementation, it will be of great help in terms of philosophical and educational aspects. This is because, in the end, ‘making Confucian sage AI’ will be a process of exploration of collective intelligence to solve social problems."
Transformer 기반 비윤리적 문장 탐지,2021,"['인공지능', '문장분류', '자연어처리', '비윤리적 문장', '딥러닝', 'artificial intelligence', 'sentence classification', 'natural language processing', 'unethical sentence', 'deep learning']",,"Social network services (SNS) have spread due to the development of information and communication technology, but at the same time, they have caused serious social problems such as malicious comments. The number of arrests and incidents of cyber defamation and insults increased sharply from 8,880 in 2014 to 16,633 in 2019, and measures are required to solve the problem. However, existing regulations such as IP blacklist and slang filters make it difficult to detect malicious comments. Therefore, we need an artificial intelligence model optimized for unethical sentence detection. This paper proposes a Transformer-based unethical sentence detection model that has shown high performance in natural language processing. The model showed accuracy of 95.03% and will be utilized as an unethical sentence detection model. Also, it will be applied in various fields such as streaming services as well as comments on SNS."
객체 인식과 VR을 활용한 유아용 단어 학습 시스템,2021,"['유아 교육 시스템', '단어 학습', '딥러닝', '객체 인식', '증강현실', '안드로이드 앱', 'Infant Learning System', 'Word Learning', 'Deep Learning', 'Object Recognition', 'AR', 'Android App']",,"The traditional word learning system for infant has a structure in which words are learned through a fixed picture or the like. In this paper, the user can directly use the camera to take pictures of infinite objects that can be seen around them, and to learn by linking objects and words. To implement this, various objects that can be easily seen around can be learned using deep learning technology and recognized in real time. It was implemented to provide 3D content using AR technology for word learning for cases such as animals that do not exist around and are difficult to access. The entire system configuration is composed of an Android app, and the learning mode and the game mode are separated and implemented. In the learning mode, object recognition technology, TTS/STT technology, and AR technology were used to enable learning of words related to objects. In the learning mode, each function is appropriately arranged so that reading, speaking, and writing skills can be improved in a balanced way. In the game mode, interest was aroused through the game method, and the previously learned words were reviewed naturally. Education that incorporates such play is expected to increase the effect of learning words naturally while improving self-directed learning ability by enabling children to be interested in study."
농산물 단가와 산지 기상의 상관관계 분석 연구,2021,"['상관관계 분석', '농산물 단가 예측', '딥러닝', 'Correlation Analysis', 'Agriculture Products Unit Price Prediction', 'Deep Learning']","최근 농산물의 단가를 예측하는 연구들이 주목을 받고 있다. 농산물의 단가를 정확히 예측하면 공급량 조절이 가능하고 이는 수익 증대로 이어지기 때문이다. 미래의 농산물 단가의 형성에 영향을 미치는 요소에는 기상, 중량 등이 있다. 기존 기상 정보를 활용한 농산물 가격 예측 연구는 기상과 단가와의 관련성에 대한 분석 결과를 충분히 검토하지 않았다는 한계점이 있다. 본 논문에서는 10년간의 농산물 실 판매 데이터를 기반으로 이전에 연구되지 않았던 다양한 측면에서 단가와 기상의 상관관계를 분석한다. 이를 위한 먼저 농산물 상위 품종/세부 품종별 기상과의 상관관계 수치를 도출하여 정보를 제공한다. 또한 농산물의 생장주기 변화에 따른 단가와 기상 간의 상관관계 변화 추이 분석 실험을 진행한다. 실험을 통하여 농산물의 생장주기 중 단가에 영향을 크게 미치는 생장주기를 알 수 있다. 뿐만 아니라 본 논문에서는 단가와 관련성 높은 기상 요소를 선택하는 방법을 제안한다. 제안하는 방법은 단가-기상 상관계수를 구한 후에 기상-기상 상관계수를 구하기 때문에 단가-기상, 기상-기상 간의 관련성을 모두 고려하여 단가와 관련성 높은 기상 요소를 선택할 수 있다는 장점이 있다. 마지막으로 농산물 단가 예측 실험을 통하여 제안하는 방법의 효과를 검증한다.","Recently, studies on predicting the price of agricultural products are attracting attention. If the price of agricultural products is accurately predicted, it is possible to control the supply, which leads to an increase in profits. Various factors may influence the formation of future agricultural product prices, such as weather, weight. The main limitation of existing research is that they did not sufficiently investigate the relationship between weather and product price. Therefore, this paper analyzes the correlation between unit price and weather in various aspects based on ten years of real agricultural product sales dataset. To this end, we first derived a correlation between weather and top-ranked agricultural product. We also conducted a trend analysis experiment on the correlation between product price and weather according to the change in the growth cycle of agricultural products. Experiment results reveal that we could identify the growth cycles that significantly affect the product price. In addition, we propose a method to select a meteorological factor highly correlated to the product price, considering the relationship between product price and weather. Finally, we verified the effectiveness of the proposed methodology by conducting experiments on predicting agricultural product prices."
사망률의 계절성과 분석 모형에 관한 연구,2021,"['사망률', '계절효과', '시계열모형', '페이스북 프로펫', '딥러닝', 'Mortality rates', 'Seasonality', 'Time series model', 'Facebook Prophet', 'Deep learning']",,"In this study, models that can identify and reflect seasonal differences in mortality were explored based on monthly mortality data derived from MicroData Integrated Service (MDIS) provided by Statistics Korea for the seasonality of mortality identified by previous studies. Several models recently developed for time series analysis along with traditional time series models were applied to data defined by cause of death; disease, injury, cancer, cerebrovascular disease, and cardiovascular disease. Based on the time series model discussed in this study, changes in monthly or seasonal mortality rates can be modeled and the forecasting results are expected to derive better estimate on the cash flows within a year associated with various types of death benefit provided by insurers and costs of enterprises providing funeral services."
Evaluation of Deep Learning Based YOLOv3 Brain Tumor Classification Performance Using Magnetic Resonance Imaging,2021,"['Brain', 'Deep learning', 'MRI', 'Neoplasm', '뇌', '딥러닝', '자기공명영상', '종양']",,
뇌파를 활용한 IoT기반 스마트홈 시스템 구현,2021,"['스마트홈', '사물인터넷', '뇌-컴퓨터 인터페이스', '뇌파', '딥러닝', '합성곱신경망', 'Smart Home', 'Internet of Things (IoT)', 'Brain-Computer Interface (BCI)', 'Electroencephalography (EEG)', 'Deep learning', 'Convolutional Neural Network (CNN)']",,
YOLO v3를 이용한 높은 정확도의 차량 계수 방법,2021,"['Vehicle detection(차량 검출)', 'Deep learning(딥러닝)', 'Convolutional neural network(합성곱신경망)', 'Traffic surveillance data(교통감시데이터)', 'YOLO(You Only Look Once', '욜로)']",,
합성곱 신경망을 이용한 야생 매개모기 종의 분류,2021,"['매개 모기', '곤충 분류', '합성곱 신경망', '딥러닝', 'vector mosquitoes', 'insects classification', 'convolutional neural networks', 'deep learning']","최근 감염병을 매개하는 모기의 발생 분포가 확대됨에 따라 이들 개체의 신속한 방제를 위해 이들 개체의 분포를 빠르게 파악하는 것이 요구되고 있다. 그러나 기존 시스템에 적용된 모기 식별 알고리즘은 야생 모기의 종별 분류가 불가능하다는 한계가 있다. 이러한 문제를 해결하기 위해, 이 연구에서는 야생에서 나타나는 모기의 종 분류가 가능한 합성곱 신경망 모델을 학습하고 평가한다. 학습에 필요한 데이터를 취득하기 위해 살아있는 모기의 이미지를 야생에서 효율적으로 취득할 수 있는 포집기 형태의 촬영장치를 제작하였고 이를 사용하여 주요 감염병 매개 모기인 흰줄숲모기, 빨간집모기, 얼룩날개모기속을 포함한 1만 장 이상의 이미지를 취득하여 데이터 세트를 구성하였다. 그 결과, 학습한 모델에서 검증 데이터 세트에 대하여 최대 96.87%, 야생 데이터 세트에 대하여 최대 67.89%의 분류 정확도를 확인하여 지향하는 포집기 시스템에서의 적용 가능성과 개선 방향을 확인하였다.","The distribution of infectious mosquitoes has been constantly expanding, thus identifying the species is required for rapid pest control. However, the current mosquito identification algorithm could not apply to wild mosquito species classification. To solve this problem, we propose a convolutional neural network model for classifying vector mosquito species in the wild. To acquire data for training and evaluation, we developed a trap-shaped imaging device to efficiently acquire live mosquito images in the wild and built datasets including more than 10,000 images of Aedes albopictus, Culex pipiens, and Anopheles Spp. As a result, our model achieved up to 96.87% of validation accuracy and 67.89% of wild mosquito classification accuracy, which shows great prospects for the future trap system and a way for further improvement."
블랙박스 영상 기반 차량 및 배경 대체 영상을 이용한 실시간 MR 콘텐츠의 설계,2021,"['차량용 블랙박스', '차량 검출', '대체 영상', 'MR', '딥러닝', 'YOLO', 'Vehicle Black Box', 'Vehicle Detection', 'Substitute Video', 'MR', 'Deep Learning', 'YOLO']",,
영상분석 기술 기반 모듈러 건축 공장제작 공정 모니터링 자동화,2021,"['모듈러 건축 공장제작공정', '공정 모니터링', '컴퓨터비전', '딥러닝', '자동화', 'Modular Building Factory', 'Progress Monitoring', 'Computer Vision', 'Deep Learning', 'Automation']",,"The entire process from manufacturing in a factory to on-site assembly is running sequentially in modular building construction. Therefore, an unexpected delay in factory manufacturing would impede the overall construction schedule. Hence, the implementation of appropriate progress monitoring is essential in modular building construction. In this study, a method of vision-based progress monitoring for a modular building factory has been developed. Instead of actual images of modular unit manufacturing, videos created from 3D modeling were used to train a deep learning model. Then, videos recorded during modular manufacturing in a factory were used to test the system. Although the deep learning model was trained with the virtual model, the test results demonstrated that all six processes were successfully detected. Out of 225 image frames on average, the number of unrecognized frames was 28-53, resulting in an average recognition rate of 83.1%. The recognition accuracy of the developed progress monitoring system ranges from 62.5 to 100%, and the average value was 84.4%."
An Embedding Technique for Weighted Graphs using LSTM Autoencoders,2021,"['그래프 임베딩', '가중 그래프', 'LSTM 오토인코더', '딥러닝', '그래프 유사도', 'graph embedding', 'weighted graph', 'LSTM autoencoder', 'deep learning', 'graph similarity']",,
A Method for Cancer Prognosis Prediction Using Gene Embedding,2021,"['기계 학습', '암 예후 예측', '바이오마커', '딥러닝', 'machine learning', 'cancer prognosis prediction', 'biomarker', 'deep learning']",,
"Using Vertical and Horizonal Hidden Vector of BERT, Attention-based Separated Transfer Learning Model for Dialog Response Selection",2021,"['대화 응답 선택 시스템', '전이학습 모델', 'BERT', '딥러닝', 'dialog response selection system', 'transfer learning model', 'deep learning']",,
오토인코더를 사용한 이상탐지 모델의 비교분석 및 이상치 판별 기준 제안,2021,"['Deep Learning', 'Manufacture Process', 'Anomaly Detection', 'Autoencoder', '딥러닝', '제조 공정', '이상탐지', '오토인코더']","본 연구에선 제조 공정에서의 양/불량 판정을 위한 오토인코더(AE) 기반의 이상 탐지 방법들의 비교분석과 우수한 성능을 보인 이상치 판별 기준을 제시한다. 제조 현장의 특성상 불량 데이터의 수는 적고, 불량의 형태가 다양하다. 이러한 특성은 정상과 비정상 데이터를 모두 활용하는 인공지능 기반 양/불량 판정 모델의 성능을 저하시키고, 성능 향상을 위한 비정상 데이터의 추가 확보에 시간과 비용을 발생시킨다. 이러한 문제를 해결하기 위해서 정상 데이터만을 이용해 이상 탐지를 수행하는 AE, VAE 등 AE 기반의 모델에 관한 연구들이 진행되고 있다. 본 연구에서는 Convolutional AE, VAE, Dilated VAE 모델을 기반으로 잔차 이미지에 대한 통계치와 MSE, 정보 엔트로피를 이상치 판별 기준으로 선정하여 각 모델의 성능을 비교 분석했다. 특히 Convolutional AE 모델에 대해서 범위 값을 적용했을 때, AUC PRC 0.9570, F1 Score 0.8812, AUC ROC 0.9548, 정확도 87.60%의 가장 우수한 성능을 보였다. 이는 기존의 이상치 판별 기준으로 자주 사용되었던 MSE에 비해 정확도 기준 약 20%P(Percentage Point)의 성능 향상을 보이며, 이상치 판별 기준에 따른 모델 성능 향상이 가능함을 확인하였다.","In this study, we present a comparative analysis of major autoencoder(AE)-based anomaly detection methods for quality determination in the manufacturing process and a new anomaly discrimination criterion. Due to the characteristics of manufacturing site, anomalous instances are few and their types greatly vary. These properties degrade the performance of an AI-based anomaly detection model using the dataset for both normal and anomalous cases, and incur a lot of time and costs in obtaining additional data for performance improvement. To solve this problem, the studies on AE-based models such as AE and VAE are underway, which perform anomaly detection using only normal data. In this work, based on Convolutional AE, VAE, and Dilated VAE models, statistics on residual images, MSE, and information entropy were selected as outlier discriminant criteria to compare and analyze the performance of each model. In particular, the range value applied to the Convolutional AE model showed the best performance with AUC PRC 0.9570, F1 Score 0.8812 and AUC ROC 0.9548, accuracy 87.60%. This shows a performance improvement of an accuracy about 20%P(Percentage Point) compared to MSE, which was frequently used as a standard for determining outliers, and confirmed that model performance can be improved according to the criteria for determining outliers."
CNN 기반 리뷰 유용성 점수 예측을 통한 개인화 추천 서비스 성능 향상에 관한 연구,2021,"['개인화 추천 서비스', '리뷰 유용성', '협업 필터링', '딥러닝', 'Personalized Recommendation Service', 'Review Helpfulness', 'CF', 'Deep Learning', 'CNN']",,"Recently, various types of products have been launched with the rapid growth of the e-commerce market. As a result, many users face information overload problems, which is time-consuming in the purchasing decision-making process. Therefore, the importance of a personalized recommendation service that can provide customized products and services to users is emerging. For example, global companies such as Netflix, Amazon, and Google have introduced personalized recommendation services to support users purchasing decisions. Accordingly, the users information search cost can reduce which can positively affect the companys sales increase. The existing personalized recommendation service research applied Collaborative Filtering (CF) technique predicts user preference mainly use quantified information. However, the recommendation performance may have decreased if only use quantitative information. To improve the problems of such existing studies, many studies using reviews to enhance recommendation performance. However, reviews contain factors that hinder purchasing decisions, such as advertising content, false comments, meaningless or irrelevant content. When providing recommendation service uses a review that includes these factors can lead to decrease recommendation performance. Therefore, we proposed a novel recommendation methodology through CNN-based review usefulness score prediction to improve these problems. The results show that the proposed methodology has better prediction performance than the recommendation method considering all existing preference ratings. In addition, the results suggest that can enhance the performance of traditional CF when the information on review usefulness reflects in the personalized recommendation service."
Layer-wise Relevance Propagation (LRP) Based Technical and Macroeconomic Indicator Impact Analysis for an Explainable Deep Learning Model to Predict an Increase and Decrease in KOSPI,2021,"['KOSPI 예측', '거시경제지표', '기술적 지표', '딥러닝', 'LRP', 'KOSPI prediction', 'macroeconomic indicators', 'technical indicators', 'deep learning']",,
Improvement of Deep Learning Models to Predict the Knowledge Level of Learners based on the EdNet Data,2021,"['교육', '맞춤형 학습', '지식 추적', '딥러닝', '자기 주의 집중', 'education', 'personalized learning', 'knowledge tracing', 'deep learning', 'self-attention']",,
고해상도 위성영상을 이용한 농촌 도로 매핑을 위한 영상 분류 및 영상 분할 방법 비교에 관한 연구,2021,"['고해상도 위성영상', '영상 분류', '영상 분할', '딥러닝', '농촌 도로', 'High-resolution Satellite Image', 'Image Classification', 'Image Segmentation', 'Deep Learning', 'Rural Road']",,"Rural roads are the significant infrastructure for developing and managing the rural areas, hence the utilization of the remote sensing datasets for managing the rural roads is necessary for expanding the rural transportation infrastructure and improving the life quality of the rural residents. In this research, the two different methods such as image classification and image segmentation were compared for mapping the rural road based on the given high-resolution satellite image acquired in the rural areas. In the image classification method, the deep learning with the multiple neural networks was employed to the given high-resolution satellite image for generating the object classification map, then the rural roads were mapped by extracting the road objects from the generated object classification map. In the image segmentation method, the multiresolution segmentation was employed to the same satellite image for generating the segment image, then the rural roads were mapped by merging the road objects located on the rural roads on the satellite image. We used the 100 checkpoints for assessing the accuracy of the two rural roads mapped by the different methods and drew the following conclusions. The image segmentation method had the better performance than the image classification method for mapping the rural roads using the give satellite image, because some of the rural roads mapped by the image classification method were not identified due to the miclassification errors occurred in the object classification map, while all of the rural roads mapped by the image segmentation method were identified. However some of the rural roads mapped by the image segmentation method also had the miclassfication errors due to some rural road segments including the non-rural road objects. In future research the object-oriented classification or the convolutional neural networks widely used for detecting the precise objects from the image sources would be used for improving the accuracy of the rural roads using the high-resolution satellite image."
Conditional Generative Adversarial Network(CGAN) 기반 협업 필터링 추천 시스템,2021,"['추천 시스템', '협업 필터링', '오버샘플링', '딥러닝', 'Recommendation System', 'Collaborative filtering', 'Oversampling', 'Deep learning', 'GAN']",,"With the development of information technology, the amount of available information increases daily. However, having access to so much information makes it difficult for users to easily find the information they seek. Users want a visualized system that reduces information retrieval and learning time, saving them from personally reading and judging all available information. As a result, recommendation systems are an increasingly important technologies that are essential to the business.  Collaborative filtering is used in various fields with excellent performance because recommendations are made based on similar user interests and preferences. However, limitations do exist. Sparsity occurs when user-item preference information is insufficient, and is the main limitation of collaborative filtering. The evaluation value of the user item matrix may be distorted by the data depending on the popularity of the product, or there may be new users who have not yet evaluated the value. The lack of historical data to identify consumer preferences is referred to as data sparsity, and various methods have been studied to address these problems. However, most attempts to solve the sparsity problem are not optimal because they can only be applied when additional data such as users personal information, social networks, or characteristics of items are included.  Another problem is that real-world score data are mostly biased to high scores, resulting in severe imbalances. One cause of this imbalance distribution is the purchasing bias, in which only users with high product ratings purchase products, so those with low ratings are less likely to purchase products and thus do not leave negative product reviews. Due to these characteristics, unlike most users actual preferences, reviews by users who purchase products are more likely to be positive. Therefore, the actual rating data is over-learned in many classes with high incidence due to its biased characteristics, distorting the market. Applying collaborative filtering to these imbalanced data leads to poor recommendation performance due to excessive learning of biased classes.  Traditional oversampling techniques to address this problem are likely to cause overfitting because they repeat the same data, which acts as noise in learning, reducing recommendation performance. In addition, pre-processing methods for most existing data imbalance problems are designed and used for binary classes. Binary class imbalance techniques are difficult to apply to multi-class problems because they cannot model multi-class problems, such as objects at cross-class boundaries or objects overlapping multiple classes.  To solve this problem, research has been conducted to convert and apply multi-class problems to binary class problems. However, simplification of multi-class problems can cause potential classification errors when combined with the results of classifiers learned from other sub-problems, resulting in loss of important information about relationships beyond the selected items. Therefore, it is necessary to develop more effective methods to address multi-class imbalance problems.  We propose a collaborative filtering model using CGAN to generate realistic virtual data to populate the empty user-item matrix. Conditional vector y identify distributions for minority classes and generate data reflecting their characteristics. Collaborative filtering then maximizes the performance of the recommendation system via hyperparameter tuning. This process should improve the accuracy of the model by addressing the sparsity problem of collaborative filtering implementations while mitigating data imbalances arising from real data. Our model has superior recommendation performance over existing oversampling techniques and existing real-world data with data sparsity. SMOTE, Borderline SMOTE, SVM-SMOTE, ADASYN, and GAN were used as comparative models and we demonstrate the highest prediction accur"
CNN을 이용한 Cyclic Moment 기반 자동 변조 인식,2021,"['Automatic recognition modulation', 'Cyclic moment', 'Convolution neural network']",,
Anomaly Detection by a Surveillance System through the Combination of C3D and Object-centric Motion Information,2021,"['이상 탐지', '광학 흐름', '객체 중심', '딥러닝', '인공지능', 'anomaly detection', 'optical flow', 'object-centric', 'deep learning', 'artificial intelligence']",,
개인사업자 부도율 예측 모델에서 신용정보 특성 선택 방법,2021,"['신용정보', '개인사업자 부도율', '특성 선택', '딥러닝', '예측 성능', 'credit information', 'individual business default rate', 'feature selection', 'deep learning', 'prediction performance']",,
공공연구성과 실용화를 위한 데이터 기반의 기술 포트폴리오 분석: 빅데이터 및 인공지능 분야를 중심으로,2021,"['공공연구성과', '특허 포트폴리오', '기술사업화', '빅데이터', '인공지능', '딥러닝', '자연어처리', '토픽모델링', 'Public R&D Outcomes', 'Patent Portfolio', 'Technical Commercialization', 'Big Data', 'Artificial Intelligence', 'Deep Learning', 'Natural Language Processing', 'Topic Modeling']",,"Since small and medium-sized enterprises fell short of the securement of technological competitiveness in the field of big data and artificial intelligence (AI) field―core technologies of the Fourth Industrial Revolution, it is important to strengthen the competitiveness of the overall industry through technology commercialization. In this study, we aimed to propose a priority related to technology transfer and commercialization for practical use of public research results. We utilized public research performance information, improving missing values of 6T classification by deep learning model with an ensemble method. Then, we conducted topic modeling to derive the converging fields of big data and AI. We classified the technology fields into four different segments in the technology portfolio based on technology activity and technology efficiency, estimating the potential of technology commercialization for those fields. We proposed a priority of technology commercialization for 10 detailed technology fields that require long-term investment. Through systematic analysis, active utilization of technology, and efficient technology transfer and commercialization can be promoted."
"인공지능의 역사, 분류 그리고 발전 방향에 관한 연구",2021,"['인공 지능', '기계 학습', '신경망', '딥러닝', 'Artificial Intelligence', 'Machine Learning', 'Neural Network', 'Deep Learning']","인공지능은 오랜 역사가 있으며, 이미지 인식이나 자동번역 분야를 포함한 여러 분야에서 활용되고 있다. 그래서 처음 인공지능을 접하는 경우에 많은 용어와 개념, 기술 때문에 연구의 방향 설정이나 수행에 어려움을 겪는 경우가 많다. 이번 연구는 이러한 어려움을 겪는 연구자들에게 도움이 될 수 있도록 인공지능에 관련된 중요 개념을 정리하고, 지난 60년의 발전 과정을 요약한다. 이를 통하여 방대한 인공지능 기술 활용의 기초를 확립하고 올바른 연구의 방향성을 수립할 수 있다.","Artificial Intelligence has a long history and is used in various fields including image recognition and automatic translation. Therefore, when we first encounter artificial intelligence, many terms, concepts and technologies often have difficulty in setting or implementing research direction. This study summarized important concepts related to artificial intelligence and summarized the progress of the past 60 years to help researcher suffering from these difficulties. Through this, it is possible to establish the basis for the use of vast artificial intelligence technologies and establish the right direction for research."
An Improved Recommendation Algorithm Based on Two-layer Attention Mechanism,2021,"['Attention', 'Mechanism', 'Recommendation', 'Deep Learning', 'AMITI Algorithm', '주의', '메커니즘', '권장', '딥러닝', '아미티 알고리즘']","인터넷 기술의 발달로 기존의 추천 알고리즘은 사용자나 항목의 심층적인 특성을 학습할 수 없기 때문에 본 논문은 이 문제를 해결하기 위해 AMITI(주의 메커니즘 및 개선된 TF-IDF)에 기반한 추천 알고리즘을 제안했다. CNN(Convolutional Neural Network)에 2중 주의 메커니즘을 도입함으로써 CNN의 특징 추출 능력이 향상되고, 항목 특징에 다른 선호도 가중치가 할당되며, 사용자 선호도와 더 일치하는 권고사항이 달성되었다. 대상 사용자에게 항목을 추천할 때 점수 데이터와 항목 유형 데이터를 TF-IDF와 결합하여 권장 결과의 그룹화를 완료하였다. 본 논문에서 진행한 MovieLens-1M 데이터 세트에 대한 실험 결과는, AMITI 알고리즘이 권장 사항의 정확도를 향상시키고 프레젠테이션 방법의 순서와 선택성을 향상시킨다는 것을 보여준다.","With the development of Internet technology, because traditional recommendation algorithms cannot learn the in-depth characteristics of users or items, this paper proposed a recommendation algorithm based on the AMITI(attention mechanism and improved TF-IDF) to solve this problem. By introducing the two-layer attention mechanism into the CNN, the feature extraction ability of the CNN is improved, and different preference weights are assigned to item features, recommendations that are more in line with user preferences are achieved. When recommending items to target users, the scoring data and item type data are combined with TF-IDF to complete the grouping of the recommendation results. In this paper, the experimental results on the MovieLens-1M data set show that the AMITI algorithm improves the accuracy of recommendation to a certain extent and enhances the orderliness and selectivity of presentation methods."
설명 가능한 AI 학습 지원 시스템 개발,2021,"['Knowledge Tracing(KT)', 'eXplainableAI(XAI)', '학습자 진단', '맞춤형 학습', '딥러닝', 'Student Assessment', 'Individualized Learning', 'Deep Learning']",,"The majority of online education platforms are efficient in providing its service to a large number of students. However, these online platforms hardly achieve individualized learning. This paper proposes a framework of an explainable intelligent tutoring system for teachers. The system uses an individual student’s cognitive and environmental factors to assesses the student. The proposed framework uses DKT and XGBoost to model a student’s knowledge state and analyzes the model’s prediction with LRP and SHAP. Teachers receive the predicted knowledge state of a student as an interpretable form. Teachers may identify a student’s understanding of the subject and environmental factors that impact a student’s learning and provide individualized feedback. This paper contributes to an application of AI models and XAI techniques on education to achieve individualized learning."
수정된 YOLO v4를 활용한 해상에서 객체 탐지 및 분류 모형 개발,2021,"['Deep learning', 'Detection of warships', 'Object detection', 'YOLO v4', 'Modified YOLO v4']","본 연구의 목적은 해상에서 군함의 영상장비로 획득한 영상에 딥러닝을 적용하여 군함을 객체로 탐지하고 분류하는 모형을 개발하는 것이다. 본 연구에서는 한반도 해상과 관련된 5개국의 군함을 대상으로 하였다. 모형의 알고리즘은 기존 YOLO v4 모형의 SPP 영역을 수정하여 구현한 것을 제안하였고, 기존 YOLO v4 모형과 본 연구에서 제안한 수정된 YOLO v4 모형을 비교하였다. 두 모형에 대한 평가는 mAP(mean Average Precision) 와 IoU(Intersection over Union)로 하였으며, 평가 결과 수정된 YOLO v4 모형이 mAP 면에서 YOLO v4 모형보다 0.28% 더 우수한 성능을 보였다. 또한, 테스트 영상을 이용한 실험에서도 영상의 크기에 관계없이 제안한 모형이 기존 모형보다 객체 분류 면에서 우수한 성능을 보였다.",
디지털 성범죄 현황 및 수사 지원 기법으로서의 심리학적 프로파일링 방향성,2021,"['디지털 성범죄', '디지털 포렌식', '심리학적 프로파일링 모델', 'Technology Facilitated Sexual Violence', 'Digital Forensic', 'Psychological Profiling Model']","4차 산업 혁명이 가까워지면서 인공지능의 발달, 빅데이터 분 석 및 딥러닝의 활용 등 고도화 된 ICT 기술의 적용은 코로나 -19 재난 상황 이후 디지털 공간에서의 생활양식을 더욱 구체화 시켜 나갔다. 디지털 공간에서의 보편화 된 생활은 새로운 양상 의 범죄를 초래하였으며, 그 중 대표적인 범죄로서 디지털 성범 죄가 최근 심각한 사회적 문제로 부각되고 있다. 이와 관련한 대 응책으로 아동ㆍ청소년에 대한 온라인 그루밍 성범죄 처벌, 성착 취물 제작 범죄 공소시효 폐지, 사법경찰관의 위장수사 허용 등 을 포함한 아동ㆍ청소년의 성보호에 관한 법률 개정안이 2021년 3월 16일 국무회의를 통과하여, 2021년 9월 24일부터 시행될 예정이다. 이러한 국가적 대응 시기에 맞춰서 본 논문에서는 디 지털 성범죄 근절을 위한 적극적 대응전략 중 하나로서 수사 단 계에서의 디지털 성범죄 프로파일링 방향성에 관하여 논의하고 자 한다. 특히 디지털 포렌식 증거를 활용한 수사 지원 기법으로 서의 심리학적 프로파일링 모델 적용 사례를 소개하고자 한다.","As the fourth industrial revolution nears, the application of advanced ICT technology such as the development of artificial intelligence, big data analysis and the use of deep learning further embodied the lifestyle in digital space after the Covid-19 disaster situation. The universalized life in digital space has led to a new pattern of crime, and Technology Facilitated Sexual Violence as a representative crime have recently become a serious social problem. As a countermeasure, the amendment to the Act on the Protection of Sex of Children and Adolescents, including the punishment of online grooming sex crimes against children and adolescents, the abolition of the statute of limitations on the production of sexual exploitation crimes, and the permission of police officers to investigate camouflage, will be implemented on September 24, 2021. In accordance with the time of such national response, this paper discusses the direction of technology facilitated sexual violence offender profiling at the investigative stage as one of the active countermeasures for eradicating technology facilitated sexual violence. In particular, this study introduces the application of psychological profiling model as a technique of supporting investigation using digital forensic evidences."
자율비행드론의 사용의도에 영향을 미치는 요인에 관한 실증적 연구,2021,"['Autonomous flight', 'artificial intelligence', 'deep learning', 'UTAUT', 'TOE framework', '자율비행', '인공지능', '딥러닝', 'UTAUT', 'TOE 프레임워크']",,"The drone sector, a key growth engine of the fourth industrial revolution, has recently been converging with the development of artificial intelligence technology to develop autonomous flight technology, raising interest and utilization in various fields. In particular, countries around the world are expanding the use of autonomous flying drones based on accumulated know-how using drones, and the Korean government is preparing to create useful effects and commercialize them in various fields as the field of autonomous flying drones has great ripple effects on each field. In particular, since it can be used in various fields, it is necessary to analyze and actively introduce factors that affect the intention of using autonomous flying drones. Accordingly, this study integrated the TOE framework and UTAUT to set up modified and expanded models and verify factors affecting the intent of use through empirical research."
인공지능 규제의 법체계,2021,"['AI(AI)', '인공지능(Artificial Intelligence)', '인공지능 규제(regulation of AI)', '알고리즘 (algorithm)', '딥러닝(deep learning)', '빅데이터(big data)', '인공지능 규제기관(AI regulation agency)']","인공지능은 사람의 인식과 계산능력을 대체하는 점에서 다른 기계와는 분명 질적인 차이를 보일 중요한 수단이다. 현재 거대기업과 몇몇의 국가들은 인공지능 기술을 산업경쟁 력의 핵심으로 보고 대규모의 투자를 하고 있다. 인공지능의 활용분야에는 한계가 없으며 앞으로의 발전에 따른 능력은 무궁할 것으로 예측된다. 인공지능의 발전이 바둑 경기에 미치고 있는 영향을 토대로 나아가 사회 및 공동체에 미칠 영향을 예측해 볼 수 있다. 첫째로 인공지능이 발전하더라도 당분간 현재의 사회 제도는 크게 영향을 받지 않을 것으로 판단된다. 인공지능은 기계이기 때문에 사람이 이용할수 있는 도구이며 사람과 경쟁 상대는 아니다. 둘째로 인공지능의 계산력은 바둑의 기술 발전에 영향을 준다. 셋째로 인공지능의 발전은 새로운 행위규범을 요구한다. 바둑 기사들은 상대방 몰래 인공지능을 활용하여 경기에 이기려는 유혹을 받기 때문에 이를 적절히 예방 하고 통제하는 정책이 필요하다. 이 글에서는 인공지능의 규제에 관하여 그 필요성과 법적 구조 그리고 규제와 관련된 중요한 쟁점을 검토하였다. 인공지능은 기계에 의하여 인간의 인지능력과 계산능력을 대체 한다는 점에서, 그리고 과학 기술의 발전에 따라서 인공지능 기술의 발전과 그 응용분야가 급속도로 확산되는 점에서 그 파급력이 매우 크다. 인공지능이 담고 있는 유용성을 증대시 키고 잠재하는 해악을 축소하기 위하여 행정의 역할은 중요하다. 행정은 인공지능 기술의 발전을 위한 촉진자로서의 기능도 하여야 하지만 국민의 권익에 대한 침해를 방지하기 위한 감시자로서의 활동에도 부족함이 없어야 한다. 인공지능에 관련된 법은 거대기업을 중심으로 한 자율법이 중요하고, 국가의 규제도 법령보다는 가이드라인과 같은 연성법의 활용 공간이 크다. 인공지능의 작동방식인 알고리즘은 나름의 규칙에 의하는데 이를 조직하는 코드가 법령과 유사한 점이 있지만 그 은닉된 성격과 익명성 때문에 법적 절차에 의해서 형성되고 일반에 공포되는 국가법과는 다르다. 법률에 의한 지배가 코드에 의한 지배가 되지 않도록 주의를 기울여야 한다. 한편 행정은 도로교통, 조세, 행형 그리고 교육과 보건복지의 부문에서 인공지능을 활용 하는 조사, 진단과 규제를 이미 상당 부분 수행하고 있으며, 앞으로 인공지능 적용 분야가 점점 더 많아질 것으로 예상한다. 사생활의 보호와 차별금지는 거대 인공지능 기업에 대해 국가가 요구하고 감시한다. 그러나 국가가 직접 인공지능을 활용하여 행정을 펼칠 때에는 스스로 국민의 권익 침해를 하지 않도록 주의하여야 한다. 인공지능에 관련된 업무와 분쟁이 늘어나면 이를 전담하여 처리해야 하는 국가의 기관이 설치되어야 한다. 현재 조직되어 있는 4차산업혁명위원회는 인공지능의 개발과 적용에 주력하고 있어서 국민의 기본권 보호와 알고리즘의 투명성 보장 등 규제를 위한 기관으로는 부족하다고 평가된다. 향후 인공 지능에 관한 독립적이고 효율적인 규제기관이 설치되어야 할 것이다.","Artificial intelligence is an important means to show a qualitative difference from other machines in that it replaces human perception and computational abilities. Currently, large corporations and several countries are making large-scale investments, seeing AI technology as the core of their industrial competitiveness. There is no limit to the field of use of artificial intelligence, and its capabilities are expected to be endless in the future. Based on the impact of AI on the game of Go, we can predict the future impact of the development of artificial intelligence on society and communities. First, even if artificial intelligence develops, the current social system is not expected to be greatly affected for the time being. Because artificial intelligence is a machine, it is a tool that can be used by humans and is not a competitor to humans. Second, the computational power of artificial intelligence affects the technological development of Baduk. Third, the development of artificial intelligence requires a new code of conduct. Because Go players are tempted to win the game by using artificial intelligence without their opponents knowledge, policies to properly prevent and control this are necessary. In this article, the necessity, legal structure, and important issues related to the regulation of artificial intelligence are reviewed. Artificial intelligence has a great impact in that it replaces human cognitive and computational abilities by machines, and in that the development of artificial intelligence technology and its application fields are rapidly spread along with the development of science and technology. The role of administration is important to increase the usefulness of artificial intelligence and reduce potential harm. The administration should also function as a facilitator for the development of artificial intelligence technology, but there should be no shortages in its activity as a monitor to prevent infringement on the rights and interests of the people. As for laws related to artificial intelligence, autonomous laws centered on large corporations are important, and national regulations also have a larger space for use of soft laws such as guidelines rather than acts. Algorithms, which are the methods of operation of artificial intelligence, are based on their own rules. The codes that organize them are similar to laws, but because of their concealed nature and anonymity, they are different from national laws formed by congressional procedures and promulgated to the public. Care should be taken to ensure that ruled by law is not ruled by code. The administration has already carried out a significant part of the investigation, diagnosis and regulation using artificial intelligence in the areas of road traffic, taxation, punishment, education and health, and it is expected that there will be more and more applications of artificial intelligence in the future. The protection of privacy and non-discrimination are required and monitored by the state against large AI companies. However, when the state directly uses artificial intelligence to conduct administration, care must be taken not to infringe on the rights and interests of the people themselves. When the number of tasks and disputes related to artificial intelligence increase, a national organization that is responsible for dealing with them should be established. The 4th Industrial Revolution Committee, which is currently organized, focuses on the development and application of artificial intelligence, so it is evaluated that it is not enough as an institution for regulation such as protecting the basic rights of the people and ensuring transparency of algorithms. In the future, an independent and efficient agency on artificial intelligence should be established in Korea."
잡음 환경에서의 음성인식을 위한 온라인 빔포밍과 스펙트럼 감산의 결합,2021,[],"본 논문에서는 실제 환경에서의 연속 음성 강화를 위한 딥러닝 기반 온라인 빔포밍 알고리듬과 스펙트럼 감산을 결합한 빔포머를 제안한다. 기존 빔포밍 시스템은 컴퓨터에서 음성과 잡음을 완전히 겹친 방식으로 혼합하여 생성된 사전 분할 오디오 신호를 사용하여 대부분 평가되었다. 하지만 실제 환경에서는 시간 축으로 음성 발화가 띄엄띄엄 발성되기 때문에, 음성이 없는 잡음 신호가 시스템에 입력되면 기존 빔포밍 알고리듬의 성능이 저하된다. 이러한 효과를 경감하기 위하여, 심층 학습 기반 온라인 빔포밍 알고리듬과 스펙트럼 감산을 결합하였다. 잡음 환경에서 온라인 빔포밍 알고리듬을 평가하기 위해 연속 음성 강화 세트를 구성하였다. 평가 세트는 CHiME3 평가 세트에서 추출한 음성 발화와 CHiME3 배경 잡음 및 MUSDB에서 추출한 연속 재생되는 배경음악을 혼합하여 구성되었다. 음성인식기로는 Kaldi 기반 툴킷 및 구글 웹 음성인식기를 사용하였다. 제안한 온라인 빔포밍 알고리듬 과 스펙트럼 감산이 베이스라인 빔포밍 알고리듬에 비해 성능 향상을 보임을 확인하였다.",
이동 장애물을 고려한 DQN 기반의 Mapless Navigation 및 학습 시간 단축 알고리즘,2021,"['Reinforcement neural network', 'DQN', 'Mobile robot', 'Autonomous driving', 'Obstacle', '강화학습', '딥러닝', '모바일 로봇', '자율주행', '장애물']","최근 4차 산업혁명에 따라 공장, 물류창고, 서비스영역에서 유연한 물류이송을 위한 자율 이동형 모바일 로봇의 사용이 증가하고 있다. 대규모 공장에서는 Simultaneous Localization and Mapping(SLAM)을 수행하기 위하여 많은 수작업이 필요하기 때문에 개선된 모바일 로봇 자율 주행에 대한 필요성이 대두되고 있다. 이에 따라 본 논문에서는 고정 및 이동 장애물을 피해 최적의 경로로 주행하는 Mapless Navigation에 대한 알고리즘을 제안하고자 한다. Mapless Navigation을 위하여 Deep Q Network(DQN)을 통해 고정 및 이동 장애물을 회피하도록 학습하였고 두 종류의 장애물 회피에 대하여 각각 정확도 90%, 93%를 얻었다. 또한 DQN은 많은 학습 시간을 필요로 하는데 이를 단축하기 위한 목표의 크기 변화 알고리즘을 제안하고 이를 시뮬레이션을 통하여 단축된 학습시간과 장애물 회피 성능을 확인하였다.","Recently, in accordance with the 4th industrial revolution, The use of autonomous mobile robots for flexible logistics transfer is increasing in factories, the warehouses and the service areas, etc. In large factories, many manual work is required to use Simultaneous Localization and Mapping(SLAM), so the need for the improved mobile robot autonomous driving is emerging.Accordingly, in this paper, an algorithm for mapless navigation that travels in an optimal path avoiding fixed or moving obstacles is proposed. For mapless navigation, the robot is trained to avoid fixed or moving obstacles through Deep Q Network (DQN) and accuracy 90% and 93% are obtained for two types of obstacle avoidance, respectively. In addition, DQN requires a lot of learning time to meet the required performance before use. To shorten this, the target size change algorithm is proposed and confirmed the reduced learning time and performance of obstacle avoidance through simulation."
BRT의 자율주행을 위한 가상환경 기반의 학습데이터 생성에 관한 연구,2021,"['BRT', 'Autonomous vehicle', 'Deep learning', 'Virtual environment', 'Data set', '대용량 BRT', '자율주행', '딥러닝', '가상환경', '학습데이터']",,
RGBD 카메라 기반의 Human-Skeleton Keypoints와 2-Stacked Bi-LSTM 모델을 이용한 낙상 탐지,2021,"['Fall Detection', 'Deep-learning', 'Skeleton Keypoints', 'Stacked Bi-LSTM', '낙상 탐지', '딥러닝', '골격 정보', '다층 양방향 LSTM']",,"In this study, we propose a method for detecting fall behavior using MS Kinect v2 RGBD Camera-based Human-Skeleton Keypoints and a 2-Stacked Bi-LSTM model. In previous studies, skeletal information was extracted from RGB images using a deep learning model such as OpenPose, and then recognition was performed using a recurrent neural network model such as LSTM and GRU. The proposed method receives skeletal information directly from the camera, extracts 2 time-series features of acceleration and distance, and then recognizes the fall behavior using the 2-Stacked Bi-LSTM model. The central joint was obtained for the major skeletons such as the shoulder, spine, and pelvis, and the movement acceleration and distance from the floor were proposed as features of the central joint. The extracted features were compared with models such as Stacked LSTM and Bi-LSTM, and improved detection performance compared to existing studies such as GRU and LSTM was demonstrated through experiments."
기초학력 미달 학생 예측을 위한 심층인공신경망 모형의 활용 : 불균형 자료의 예측 모형 구축을 중심으로,2021,"['학업성취수준 예측', '기초학력 미달', '불균형 자료', '한국교육종단연구', '심층인공신경망', '딥러닝', 'prediction of academic performance', 'low academic achiever', 'imbalanced data', 'Korean Educational Longitudinal Study', 'deep neural network', 'deep learning']","교육 연구에서 기초 수준 이하로 낮은 성취를 보이는 기초학력 미달 학생들은 지속적인 관심의 대상이다. 학습 결손은 학년을 거듭할수록 누적되고 심화되는 특성을 보이기 때문에, 기초학력 미달 학생의 학습 결손 초기에 선제적인 교육적 지원을 제공하는 것은 중요하다고 할 수 있다. 하지만 기초학력 미달 학생들은 소수집단으로 불균형 자료의 특성을 지니고 있어 일반적인 통계모형을 적용하여 분석하는 데 한계를 지닌다. 이러한 점을 고려하여 본 연구에서는 자료의 구조나 모형의 특성에 상대적으로 유연한 심층인공신경망을 적용하여 기초학력 미달 학생을 예측하는 모형을 구축하고자 하였다. 이를 위하여 한국교육종단연구 2013의 중학교 시기 응답 정보를 활용하였으며, Sparse Group Lasso 방법을 적용하여 학생, 학부모, 학교 전반의 방대한 정보 중 주요 예측변수를 선정하고, 이를 예측모형에 활용하였다. 또한, 심층인공신경망 모형에서는 소수집단 정보를 반영할 수 있는 다양한 방법을 탐색하고 그 결과를 기저모형인 HGLM 모형과 비교하였다. 분석결과, 비용민감기법을 적용한 예측모형의 성능이 모든 과목에서 우수하게 나타났으며, 과대표집 모형과 HGLM 모형 성능은 과목에 따라 다르게 나타났다. 이상의 결과를 토대로 교육연구에서 심층인공신경망을 활용한 소수집단 예측 연구의 시사점을 논하였으며, 추후 연구를 제언하였다.","Low Academic Achievers’ learning deficit is gradually accumulated and deepened. Therefore, it is important to provide appropriate educational support to them before the learning deficit become severe. Educational Researchers have tried to figure out their cognitive, emotional and situational difficulties and build a system that identifies underachieving student early. However, since low academic achiever group is a minority class, it is hard to apply statistical prediction models. This study aims to predict low academic achievers by employing a deep neural network (DNN) that is relatively flexible model for both data structure and statistical assumptions when dealing with imbalanced data. Middle school students’ information in Korean Educational Longitudinal Study (KELS)2013 was used for analysis. Before specifying the predictive model, main predictors among all 364 variables in KELS2013 were selected by using Sparse Group Lasso technique. In predictive model using DNN, over-sampling and cost-sensitive methods that can reflect minority class information in model training were applied and the result of HGLM which is base model was also presented. The results showed that the cost-sensitive DNN model had a good performance in all subjects while the performance of the over-sampling DNN and the HGLM varied depending on subjects. Based on the results of this study, the implications for early predicting low academic achievers using DNN were discussed."
스트리트뷰 영상의 객체탐지를 활용한 보행 장애물 정보 갱신,2021,"['Object Detection', 'Deep Learning', 'YOLO', 'OpenStreetMap', 'Pedestrian Network', 'Map Update', '객체탐지', '딥러닝', '욜로', '오픈스트리트맵', '보행 네트워크', '지도 갱신']",,
부정적 감정 완화를 위한 BERGPT-chatbot,2021,"['Deep Learning', 'Sentiment Analysis', 'AI Chatbot', 'KR-BERT', 'KoGPT2-chatbot', '딥러닝', '감정 분석', 'AI챗봇']","본 연구에서는 ""레플리카""와 같은 텍스트 입력 기반의 부정적 감정 완화가 가능한 국내 인공지능 챗봇인 BERGPT-chatbot을 제안하고자 한다. BERGPT-chatbot은 KR-BERT와 KoGPT2-chatbot을 파이프라인으로 만들어 감정 완화 챗봇을 모델링하였다. KR-BERT를 통해 정제되지 않은 일상 데이터셋에 감정을 부여하고, 추가 데이터셋을 KoGPT2-chatbot을 통해 학습하는 방식이다. BERGPT-chatbot의 개발 배경은 다음과 같다. 현재 전 세계적으로 우울증 환자가 증가하고 있으며, 이는 COVID-19로 인해 장기적 실내 생활이나 대인 관계 제한으로 더욱 심각한 문제로 대두되었다. 그로 인해 부정적 감정 완화나 정신 건강 케어에 목적을 둔 국외의 인공지능 챗봇이 팬데믹 사태로 사용량이 증가하였다. 국내에서도 국외의 챗봇과 비슷한 심리 진단 챗봇이 서비스 되고 있으나, 국내의 챗봇은 텍스트 입력 기반 답변이 아닌 버튼형 답변 중심으로 국외 챗봇과 비교하였을 때 심리 진단 수준에 그쳐 아쉬운 실정이다. 따라서, BERGPT-chatbot을 통해 감정 완화에 도움을 주는 챗봇을 제안하였으며, BERGPT-chatbot과 KoGPT2-chatbot을 언어 모델의 내부 평가 지표인 ‘퍼플렉서티’를 통해 비교 분석하여 BERGPT-chatbot의 우수함을 보여주고자 한다.","In this paper, we propose a BERGPT-chatbot, a domestic AI chatbot that can alleviate negative emotions based on text input such as ‘Replika’. We made BERGPT-chatbot into a chatbot capable of mitigating negative emotions by pipelined two models, KR-BERT and KoGPT2-chatbot. We applied a creative method of giving emotions to unrefined everyday datasets through KR-BERT, and learning additional datasets through KoGPT2-chatbot. The development background of BERGPT-chatbot is as follows. Currently, the number of people with depression is increasing all over the world. This phenomenon is emerging as a more serious problem due to COVID-19, which causes people to increase long-term indoor living or limit interpersonal relationships. Overseas artificial intelligence chatbots aimed at relieving negative emotions or taking care of mental health care, have increased in use due to the pandemic. In Korea, Psychological diagnosis chatbots similar to those of overseas cases are being operated. However, as the domestic chatbot is a system that outputs a button-based answer rather than a text input-based answer, when compared to overseas chatbots, domestic chatbots remain at a low level of diagnosing human psychology. Therefore, we proposed a chatbot that helps mitigating negative emotions through BERGPT-chatbot. Finally, we compared BERGPT-chatbot and KoGPT2-chatbot through ‘Perplexity’, an internal evaluation metric for evaluating language models, and showed the superity of BERGPT-chatbot."
합성곱 신경망을 이용한 프로펠러 캐비테이션 침식 위험도 연구,2021,"['Convolutional Neural Network(CNN', '합성곱 신경망)', 'Deep learning(딥러닝)', 'Propeller(프로펠러)', 'Cavitation(캐비테이션)', 'Erosion(침식)']",,"Cavitation erosion is one of the major factors causing damage by lowering the structural strength of the marine propeller and the risk of it has been qualitatively evaluated by each institution with their own criteria based on the experiences. In this study, in order to quantitatively evaluate the risk of cavitation erosion on the propeller, we implement a deep learning algorithm based on a convolutional neural network. We train and verify it using the model tests results, including cavitation characteristics of various ship types. Here, we adopt the validated well-known networks such as VGG, GoogLeNet, and ResNet, and the results are compared with the expert’s qualitative prediction results to confirm the feasibility of the prediction algorithm using a convolutional neural network."
합성곱 오토인코더를 이용한 체인 전동 장치의 고장 결함 감지 및 진단,2021,"['Fault Detection(고장 검출)', 'Fault Diagnosis(고장 진단)', 'Deep Learning(딥러닝)', 'Convolutional Auto-encoder(합성곱 오토인코더)', 'Unsupervised Learning(비지도학습)', 'Convolutional Neural Network(합성곱 신경망)']",,"This paper presents a method to detect the mechanical faults of a chain drive power transmission system (CDPTS) using a convolutional auto-encoder (CAE). In previous research, it was known that the methods to detect faults of the CDPTS based on an artificial neural network (ANN) and convolutional neural network (CNN) were useful. In this paper, an advanced application of CNN, the CAE function of CNN is employed to detect faults. This method uses the characteristics of reconstruction of CAE. Difference of input images of the CNN and reconstructed images extracted by CAE were used as the guideline of fault detection. In the fault condition of the system, the difference was larger than the predetermined threshold of error. The encoder of CAE can be fine-tuned to classify the fault types of CDPTS. Finally, this method was well applied to diagnose the fault types of the test CDPTS installed in the laboratory."
A Fusion of CNN-based Frame Vector for Segment-level Video Partial Copy Detection,2021,"['비디오', '비디오 복사 검출', '비디오 부분 복사', '특징 융합', 'CNN', '딥러닝', 'video analysis', 'copy detection', 'partial-copy detection', 'feature fusion', 'deep learning']",,
LDAM 손실 함수를 활용한 클래스 불균형 상황에서의 옷차림 T.P.O 추론 모델 학습,2021,"['융합', '패션', 'T.P.O', '다중 레이블', '클래스 불균형', '딥러닝', 'Convergence', 'Fashion', 'T.P.O', 'Multi-label problem', 'Class imbalance problem', 'Deep learning']","의복을 착용하는데 있어 목적 상황에 부합하는 옷차림을 구성하는 것은 중요하다. 따라서 인공지능 기반의 다양 한 패션 추천 시스템에서 의복 착용의 T.P.O(Time, Place, Occasion)를 고려하고 있다. 하지만 옷차림으로부터 직접 T.P.O를 추론하는 연구는 많지 않은데, 이는 문제 특성 상 다중 레이블 및 클래스 불균형 문제가 발생하여 모델 학습을 어렵게 하기 때문이다. 이에 본 연구에서는 label-distribution-aware margin(LDAM) loss를 도입하여 옷차림의 T.P.O를 추론할 수 있는 모델을 제안한다. 모델의 학습 및 평가를 위한 데이터셋은 패션 쇼핑몰로부터 수집되었고 이를 바탕으로 성능을 측정한 결과, 제안 모델은 비교 모델 대비 모든 T.P.O 클래스에서 균형잡힌 성능을 보여주는 것을 확인할 수 있었다.","When a person wears clothing, it is important to configure an outfit appropriate to the intended occasion. Therefore, T.P.O(Time, Place, Occasion) of the outfit is considered in various fashion recommendation systems based on artificial intelligence. However, there are few studies that directly infer the T.P.O from outfit images, as the nature of the problem causes multi-label and class imbalance problems, which makes model training challenging. Therefore, in this study, we propose a model that can infer the T.P.O of outfit images by employing a label-distribution-aware margin(LDAM) loss function. Datasets for the model training and evaluation were collected from fashion shopping malls. As a result of measuring performance, it was confirmed that the proposed model showed balanced performance in all T.P.O classes compared to baselines."
도로 주변 지역의 CCTV영상을 이용한 야간시간대 미세먼지 농도 추정,2021,"['Particulate Matter', 'CCTV', 'Deep Learning', 'ROI', 'Weather data', '미세먼지', '딥러닝', '날씨자료']",,
End-to-end 비자기회귀식 가속 음성합성기,2021,"['deep learning', 'neural network', 'speech synthesis', 'Text-to-Speech (TTS)', '딥러닝', '인공신경망', '음성합성']","Autoregressive한 TTS 모델은 불안정성과 속도 저하라는 본질적인 문제를 안고 있다. 모델이 time step t의 데이터를 잘못 예측했을 때, 그 뒤의 데이터도 모두 잘못 예측하는 것이 불안정성 문제이다. 음성 출력 속도 저하 문제는 모델이 time step t의 데이터를 예측하려면 time step 1부터 t-1까지의 예측이 선행해야 한다는 조건에서 발생한다. 본 연구는 autoregression이 야기하는 문제의 대안으로 end-to-end non-autoregressive 가속 TTS 모델을 제안한다. 본 연구의 모델은 Tacotron 2 – WaveNet 모델과 근사한 MOS, 더 높은 안정성 및 출력 속도를 보였다. 본 연구는 제안한 모델을 토대로 non-autoregressive한 TTS 모델 개선에 시사점을 제공하고자 한다.","Autoregressive Text-to-Speech (TTS) models suffer from inference instability and slow inference speed. Inference instability occurs when a poorly predicted sample at time step t affects all the subsequent predictions. Slow inference speed arises from a model structure that forces the predicted samples from time steps 1 to t-1 to predict the sample at time step t. In this study, an end-to-end non-autoregressive fast text-to-speech model is suggested as a solution to these problems. The results of this study show that this model""s Mean Opinion Score (MOS) is close to that of Tacotron 2 - WaveNet, while this model""s inference speed and stability are higher than those of Tacotron 2 - WaveNet. Further, this study aims to offer insight into the improvement of non-autoregressive models."
순환 심층 신경망 모델을 이용한 전용회선 트래픽 예측,2021,"['Leased Line', 'Traffic Modeling', 'Time Series Analysis', 'Deep Learning', 'RNN', 'LSTM', '전용회선', '트래픽 모델링', '시계열분석', '딥러닝']",,"Since the leased line is a structure that exclusively uses two connected areas for data transmission, a stable quality level and security are ensured, and despite the rapid increase in the number of switched lines, it is a line method that is continuously used a lot in companies. However, because the cost is relatively high, one of the important roles of the network operator in the enterprise is to maintain the optimal state by properly arranging and utilizing the resources of the network leased line. In other words, in order to properly support business service requirements, it is essential to properly manage bandwidth resources of leased lines from the viewpoint of data transmission, and properly predicting and managing leased line usage becomes a key factor. Therefore, in this study, various prediction models were applied and performance was evaluated based on the actual usage rate data of leased lines used in corporate networks. In general, the performance of each prediction was measured and compared by applying the smoothing model and ARIMA model, which are widely used as statistical methods, and the representative models of deep learning based on artificial neural networks, which are being studied a lot these days. In addition, based on the experimental results, we proposed the items to be considered in order for each model to achieve good performance for prediction from the viewpoint of effective operation of leased line resources."
영어자원문법을 활용한 신경망 기계번역의 데이터 증강과 성능 평가,2021,"['machine translation', 'deep learning', 'data augmentation', 'ERG', 'paraphrasing', 'parallel corpus', 'evaluation metric', '기계번역', '딥러닝', '데이터 증강', '영어자원문법', '다시쓰기', '병렬 코퍼스', '평가 방법']",,"Machine translation commonly involves both analysis and generation across different human languages. This implies that parallel corpora of a large size are essential to create a theoretically reliable and practically robust translation model. However, as is well known, the parallel corpora between Korean and English are insufficient. In this respect, this study expands the data by means of English Resource Grammar (Flickinger 2000) to improve the translation model between the languages. Then, it looks at whether the neural machine translation model performs better with the augmented data. Unfortunately, it turns out the translation models based on augmented data exhibit rather lower BLEU scores. This study further discusses the reason for the unsatisfactory scores and raises the necessity of human evaluation as a next step."
인공지능 기반의 미생물 균총과 질병과의 연관성 예측을 위한 Data Augmentation 방법론,2021,"['Data Augmentation', 'Microbiome Community', 'Deep Learning Network', 'Genus', 'Species', 'Disease Prediction']",,
시계열 데이터를 기반으로 한 CNN의 성능 향상 방법에 대한 비교 연구,2021,"['Artificial intelligence', 'Convolutional neural network', 'Deep learning', 'Image classification', 'Human activity recognition', 'Time series data']","인간 행동 인식 기술은 전통적으로 서포트 벡터 머신과 같은 기계 학습 기술 분야이다. 그리고 딥 러닝의 발전과 함께 순환 신경망을 사용하여 이와 같은 작업이 수행되고 있다. 최근에는 시계열 데이터를 이미지로 변환한 후 CNN (Convolutional Neural Networks)에 적용할 수 있음이 확인되었다. 저자는 시계열 기반 CNN 신경망에서 정밀도 향상을 위해 에지 향상, 선 너비 제어 및 색상 코드 최적화와 같은 몇 가지 방법을 제안했다. 엣지 강화 방법은 사물을 인식한다는 것은 사물의 형태를 본다는 직관에서 나온 아이디어이다. 또한 시계열 데이터의 데이터를 이미지로 변환 할 때, 빠른 정착 시간과 높은 정확도를 포함하여 최상의 성능을 얻을 수 있는 최적의 선폭이 존재할 수 있고, 이것이 선폭 제어 방법을 고안하게 되었다. 색상 코드 최적화는 보색으로부터 동기가 부여되었는데, 색상 코드 최적화는 색상 공간에서 색상 거리를 최대화하여 얻을 수 있다. 보색은 이미지를 더 선명하고 모양으로 만들어 신경망의 성능을 향상시킨다. 이 논문에서는 위의 세 가지 방법을 자세히 비교하고 평가한다. 실험 결과로부터 시계열 데이터의 이미지 분류 작업에서 선폭 제어가 가장 효과적인 기법이며 색상 코드 최적화도 효과적인 방법이었다. 이 논문에서 선폭 제어는 원시 정보가 시계열 데이터인 선이기 때문에 효과가 떨어졌다. 그러나 원시 데이터에 이미지와 같은 공간 정보가 있는 경우 f1-score를 향상시키는 데 에지 강화 기법이 훨씬 더 효과적일 것이다.",
에지 컴퓨팅 환경에서의 상황인지 서비스를 위한 팻 클라이언트 기반 비정형 데이터 추상화 방법,2021,"['Edge Computing', 'Fat Client', 'Context Aware', 'Unstructured Data Abstraction', 'Deep Learning', '에지 컴퓨팅', '팻 클라이언트', '상황인지', '비정형 데이터 추상화', '딥러닝']",,"With the recent advancements in the Internet of Things, context-aware system that provides customized services become important to consider. The existing context-aware systems analyze data generated around the user and abstract the context information that expresses the state of situations. However, these datasets is mostly unstructured and have difficulty in processing with simple approaches. Therefore, providing context-aware services using the datasets should be managed in simplified method. One of examples that should be considered as the unstructured datasets is a deep learning application. Processes in deep learning applications have a strong coupling in a way of abstracting dataset from the acquisition to analysis phases, it has less flexible when the target analysis model or applications are modified in functional scalability. Therefore, an abstraction model that separates the phases and process the unstructured dataset for analysis is proposed. The proposed abstraction utilizes a description name Analysis Model Description Language(AMDL) to deploy the analysis phases by each fat client is a specifically designed instance for resource-oriented tasks in edge computing environments how to handle different analysis applications and its factors using the AMDL and Fat client profiles. The experiment shows functional scalability through examples of AMDL and Fat client profiles targeting a vehicle image recognition model for vehicle access control notification service, and conducts process-by-process monitoring for collection-preprocessing-analysis of unstructured data."
인공지능 관련 저작권 침해에 관한 시론,2021,"['AI(Artificial Intelligence)', 'Machine Learning', 'Deep Learning', 'Copyright', 'Open Source', 'GAN', 'NLP', '인공지능', '기계학습', '머신러닝', '심층학습', '딥러닝', '저작권', '오픈소스', 'GAN', 'NLP']","인공지능 관련 저작권 침해는 주요하게 인공지능의 학습단계와 이용단계에서 문제된다. 현재 인공지능 기술의 개발 정도를 고려할 때, 인공지능 학습단계에서 발생할 수 있는 저작권 침해의 문제는 인공지능 이용단계에서 발생할 수 있는 저작권 침해 문제보다 더 시급히 해결되어야 할 것으로 생각된다. 인공지능 학습단계는 대규모의 데이터 입력을 요구하고 데이터로 사용된 저작물을 거의 전부 이용하여야 하기 때문에 종래의 공정이용 법리로 해결하기 어려운 점이 있다. 그에 따라 우리나라를 비롯하여 각국의 입법례는 새로운 공정이용 조항 내지 TDM(Text Data Mining) 허용 조항을 두어 인공지능 학습단계에서 발생할 수 있는 저작권 침해 문제를 해결하려고 하고 있다. 반면, 인공지능 이용단계에서 발생할 수 있는 저작권 침해는 기존의 침해 법리, 불법행위 법리에 의해 상당 부분 해결될 수 있다고 본다. 다만 이 영역에 있어서도 ‘기술의 발전에 따라’ 기존의 법리가 해결하기 어려운 한계적 사안이 발생할 수 있을 것이다.인공지능 생성물이 창작성 내지 저작물성을 갖추고 있는지 여부는 인공지능 생성물이 타인의 저작권을 침해할 수 있는지 여부와 직접적으로 연결되는 문제이다. 인공지능 생성물의 저작물성을 부정해야 한다고 보는 견해의 일면에는 현행 인공지능 생성물의 수준이 주식 기사, 날씨 기사, 샘플링 음악 등 제한된 영역에서 활용될 수 있는 정도에 불과하다는 점이 고려되었다고 보이는데, 현재 GAN을 이용한 AI 미술품의 수준, NLP를 이용한 챗봇, 언어번역의 수준을 보면 해당 인공지능 기술이 의미론적(semantic) 관점에서 문맥, 맥락을 파악하는지, 그에 따라 창작적 개성이 발현되었는지를 구체적으로 검토해야 할 단계에 진입하였다고 생각된다. 인공지능 기술이 채택하고 있는 패턴인식, 특성의 수치벡터화, 확률적 모형 등이 인간의 표현을 구문론적(syntactic) 차원을 넘어서 의미론적(semantic)차원으로 이해하는지에 관하여 개별 기술 단위로 법률적으로 판단해야 할 시점에 이르렀다고 본다. 이러한 논의를 풍부하게 진행하여야 인공지능 생성물에 대해 법적인 보호를 할 것인지, 인공지능 생성물이 타인의 저작권 등을 침해하는 것으로 여겨지는 상황에 대해 누구에게 법적 책임을 부담시킬 것인지 등에 관한 적절한 결론을 도출할 수 있을 것이다.본고는 Edmond de Belamy 초상화 사례와 관련되어 있는 오픈소스 라이선스의 법적 성격에 대해서도 기본적인 사항을 논하였다. 인공지능 개발 과정에서 오픈소스는 TensorFlow와 같은 오픈소스 기반 개발플랫폼, 개발도구, PyTorch와 같은 기계학습 라이브러리 등의 형태로 널리 사용되고 있다. 인공지능 개발은 광범위한 인적, 물적 자원이 필요한 영역이므로 이를 위해 다양한 사람이 참여할 수 있는 오픈소스 커뮤니티 기반의 개발 방식을 취하고 있는 것이다. 인공지능의 성과물, 생성물에 대한 법적 취급과 관련하여, 개발 및 배포 과정에서 적용되는 오픈소스 라이선스의 법적 성격에도 유념할 필요가 있다.","Copyright infringement related to artificial intelligence needs to be addressed in terms of AI learning stage and use stage of AI output. Considering the current degree of development of AI technology, it is thought that the issue of copyright infringement occurring in AI learning stage should be solved more urgently than the issue of copyright infringement occurring in use stage of AI output. Artificial intelligence learning step requires large-scale data input and the use of almost all works as data, making it difficult to solve with conventional fair use law. Accordingly legislative cases in each country, including South Korea, are trying to solve the issue of copyright infringement that may occur in the AI ​​learning stage by placing a new fair use clause or a clause allowing text data mining (TDM). On the other hand, I am of the view that copyright infringement that may occur in the stage of using AI output can be largely resolved by the existing laws of infringement and tort liability. However, even in this area, ""depending on the development of technology,"" there could be marginal cases that are difficult for existing legal principles to solve.Whether an artificial intelligence output has creativity or copyright- ability is a matter that is directly related to whether an artificial intelligence output can infringe on other's copyright. On one side of the view that the copyrightability of artificial intelligence output should be denied, it seems that the current artificial intelligence output can only be used in limited areas such as stock articles, weather articles, and sampling music. Looking at the level of AI(GAN) artwork, chatbot and language translation using NLP, it is necessary to examine in detail whether the AI ​​technology grasps the context from a semantic point of view, and whether creative individuality is expressed accordingly. It is my view that whether pattern recognition, numerical vectorization of characteristics, and probabilistic models adopted by artificial intelligence technology have reached the point where AI can understand human expressions from the viewpoint of semantics not syntactics should be judged legally in the concrete case. An abundance of these discussions will lead to appropriate conclusions on whether to provide legal protection for artificial intelligence output or who to hold legally liable for situations in which artificial intelligence output is believed to infringe on other people's copyrights.This study also discusses the legal nature of open-source license associated with the Edmond de Belamy portrait case. In the AI development process, open source is widely used in the form of open source-based development platforms such as TensorFlow, development tools, and machine learning libraries such as PyTorch. Since AI development requires extensive human and material resources, it is taking an open source community-based development method in which various developers can participate. Regarding the legal treatment of artificial intelligence's achievements and output, it is also necessary to note the legal nature of open-source license applied in the development and distribution process of AI output."
AI창작물의 특허보호 방안,2021,"['AI발명', 'AI창작물', '발명의 성립성', '학습완료모델', '인간의 공헌', 'AI invention', 'AI creation', 'establishment of invention', 'learning completion model', 'human contribution']","오늘날 AI발명은 데이터구조 등의 데이터 전처리, 학습에 필요한 학습 모델 정의, 물리적 구현, 딥러닝(Deep Learning) 학습프로그램을 적용하여 수행되는 물리적 구현, 도출된 학습완료모델(AI기반 SW) 등이 알고리즘 형태로 컴퓨터 등의 하드웨어에서 구현되는 경우를 말하고, 이러한 AI발명은 발명의 성립성을 만족하여 특허대상이 될 수 있다. 그러나 학습완료모델(AI기반 SW)에 입력데이터를 입력하고, 그 입력 데이터에 의하여 AI가 생성한 창작물은 현행 특허법상 인간의 발명이 아니라 비자연인인 AI에 의하여 생성된 것이므로 특허를 받을 수 없다. 따라서 AI 기술은 현행 특허법으로 충분한 특허보호가 이루어지지 못한다는 문제점이 제기되고 있다. 특히 (ⅰ) AI에 의해 생성된 AI창작물은 인간(자연인)의 발명으로 볼 수 있는지, (ⅱ) 현재 인간만을 발명자로 인정하고 있는 데 AI도 발명자로 인정받을 수 있는지, (ⅲ) AI창작물을 인간의 발명으로 인정하기 위한 방안이 있는 것인지, (ⅳ) AI를 발명자로 인정하는 경우에 발생할 수 있는 권리자로서의 권한과 의무, 권리행사의 책임 등에 대한 당사자 역할을 할 수 있는 것인지 등 다양한 법적문제가 발생할 수 있다. 이 글에서는 이러한 문제점을 해결하기 방안으로 AI에 의하여 생성된 AI창작물에 대해서도 특허대상에 포함시키기 위한 특허법의 개정방안을 검토하였다. 그 결과로 특허법 제2조 제1호의 발명의 정의 규정은 미국 특허법 제101조와 같이 인간의 발명에 한정하는 것으로 특정하고, 인간의 인위적 행위가 아니라 AI가 창작할 수 있도록 실질적인 ‘인간의 개입’ 이 있는 경우, 그 ‘인간의 개입’을 전제로 AI가 생성한 AI창작물의 정의 규정을 도입하는 개정방안이 필요하다. 그리고 특허를 받을 수 있는 자에는 ‘인간의 개입’을 전제로 하는 AI창작물의 발명자를 인간으로 한다는 규정을 특허법 제33조에 도입할 필요가 있다.","Today's AI invention refers to cases where data preprocessing, such as data structures for learning which process collected data, learning model definitions required for learning, physical implementations, physical implementations performed by applying Deep Learning learning programs, and derived learning completion models (AI-based SW) are implemented in computer-like hardware in algorithmic form, and these AI inventions satisfy the establishment of invention and are included in a target to be patented. However, input data are input into the learning completion model (AI-based SW), and the AI creation in that the AI creates by the input data is not patentable because it is not the human invention but the invention generated by the AI, which is non-natural, under the current patent law. Therefore, there is a problem that the AI technology is not sufficiently patent-protected under the current patent law. In particular, there is various problems: (i) whether the AI creation created by the AI can be regarded as an invention created by humans (natural people), (ii) countries around the world recognize only humans as inventors, whether the AI can be recognized as an inventor, (iii) whether there is a way to recognize the AI as an inventor, (iv) whether there is a way to solve the problem of authority and duty as a rightful person, responsibility for exercise of rights, etc. that may arise if the AI is recognized as an inventor. In this article, we considered the revised plan of the Patent Act to include AI-generated creations as targets to be patented. As a result, the definition of invention under Article 2 of the Patent Act 1 will be specific to human inventions, such as Article 101 of the US Patent Act, and If there is a substantial ""human contribution"" for AI to create, not an artificial act of humans, the revised plan is needed to introduce AI-generated AI creations and definitions of AI inventions on the premise of that ""human contribution."" For those who are eligible for patents, it is needed to introduce a regulation in Article 33 of the Patent Act stating that the inventor for AI creations is to be the human on the premise of ""human contribution."""
Quantitative Analysis for Win/Loss Prediction of ‘League of Legends’ Utilizing the Deep Neural Network System through Big Data,2021,"['Neural network', 'AI', 'League of Legends', 'Deep learning', 'Big data', '신경망', '인공지능', '리그오브레전드', '딥러닝', '빅데이터']","이 논문은 League of Legends (LOL) 게임의 승패를 예측하기 위하여 Deep Neural Network Model 시스템을 제안한다. 이 모델은 다양한 LOL 빅데이터를 활용하여 TensorFlow 의 Keras에 의하여 설계하였다. 연구 방법으로 한국 서버의 챌린저 리그에서 행해진 약 26000 경기 데이터 셋을 분석하여, 경기 도중 데이터를 수집하여 그 중에서 드래곤 처치 수, 챔피언 레벨, 정령, 타워 처치 수가 게임 결과에 유의미한 영향을 끼치는 것을 확인하였다. 이 모델은 Sigmoid, ReLu 와 Logcosh 함수를 사용했을 때 더 높은 정확도를 얻을 수 있었다. 실제 LOL의 프로 게임 16경기를 예측한 결과 93.75%의 정확도를 도출했다. 게임 평균시간이 34분인 것을 고려하였을 때, 게임 중반 15분 정도에 게임의 승패를 예측할 수 있음이 증명되었다. 본 논문에서 설계한 이 프로그램은 전 세계 E-sports 프로리그의 활성화, 승패예측과 프로팀의 유용한 훈련지표로 활용 가능하다고 사료된다.","In this paper, we suggest the Deep Neural Network Model System for predicting results of the match of ‘League of Legends (LOL).’ The model utilized approximately 26,000 matches of the LOL game and Keras of Tensorflow. It performed an accuracy of 93.75% without overfitting disadvantage in predicting the ‘2020 League of Legends Worlds Championship’ utilizing the real data in the middle of the game. It employed functions of Sigmoid, Relu and Logcosh, for better performance. The experiments found that the four variables largely affected the accuracy of predicting the match --- ‘Dragon Gap’, ‘Level Gap’, ‘Blue Rift Heralds’, and ‘Tower Kills Gap,’ and ordinary users can also use the model to help develop game strategies by focusing on four elements. Furthermore, the model can be applied to predicting the match of E-sports professional leagues around the world and to the useful training indicators for professional teams, contributing to vitalization of E-sports."
다변량 데이터와 순환 신경망을 이용한 젖소의 유방염 진단예측 방법,2021,"['Mastitis Prediction', 'Multivariate data', 'ICT', 'Smart Farm', 'Deep Learnin', '유방염 예측', '다변량 데이터', '정보통신기술', '스마트팜', '딥러닝']",,"Mastitis in cows is a major factor that hinders dairy productivity of farms, and many attempts have been made to solve it. However, research on mastitis has been limited to diagnosis rather than prediction, and even this is mostly using a single sensor. In this study, a predictive model was developed using multivariate data including biometric data and environmental data. The data used for the analysis were collected from robot milking machines and sensors installed in farmhouses in Chungcheongnam-do, South Korea. The recurrent neural network model using three weeks of data predicts whether or not mastitis is diagnosed the next day. As a result, mastitis was predicted with an accuracy of 82.9%. The superiority of the model was confirmed by comparing the performance of various data collection periods and various models"
한국어 교육 어휘 선정과 빅데이터 활용 방안,2021,"['Korean Language Education', 'Vocabulary', 'Vocabulary List', 'Bigdata', 'Deep Learning', '한국어교육', '어휘', '어휘 목록', '빅데이터', '딥러닝']",,"The purpose of this article is to present a way to more effectively select vocabulary to be learned while noting that vocabulary selection is the foundation of vocabulary education in the Korean language curriculum. For this process, it was proposed to actively utilize big data and deep learning methods. Through this method, vocabulary existing on the Internet was extracted. Based on the data generated through the task of comparing and analyzing these results, it was possible to extract a common vocabulary list and vocabulary with a high frequency of use. In addition, by visualizing and expressing the selected vocabulary, I tried to prove that these techniques are very effective in vocabulary education. It is expected that the list of standard vocabulary necessary for Korean language education will be richer through repetition of such research processes in the future."
LIME 알고리즘을 이용한 한국어 감성 분류 모델 해석,2021,[],"한국어 감성 분류 작업은 챗봇, 사용자의 물건 구매 평 분석 등 실 서비스에서 사용되고 있으며, 현재 딥러닝 기술의 발달로 높은 성능을 가진 신경망 모델을 활발히 사용하여 감성 분류 작업을 수행하고 있다. 하지만 신경망 모델은 입력 문장이 어떤 단어들로 인해 결과가 예측되었는지 해석하는 것이 쉽지 않으며, 최근 신경망 모델의 해석을 위한 모델 해석 방법들이 활발히 제안되어지고 있다. 본 논문에서는 모델 해석 방법 중 LIME 알고리즘을 이용하여 한국어 감성 분류 데이터 셋으로 학습된 모델들의 입력 문장 내 단어들 중 어떤 단어가 결과에 영향을 미쳤는지 해석하고자 한다. 그 결과, 85.23%의 성능을 보인 양방향 순환 신경망 모델의 해석 결과, 총 25,283개의 긍정, 부정 단어를 포함했지만, 상대적으로 낮은 성능을 보인 84.20%의 Transformer 모델의 해석 결과, 총 26,447개의 긍정, 부정 단어가 포함되어 있어 양방향 순환 신경망 모델보다 Transformer 모델이 신뢰할 수 있는 모델임을 확인할 수 있었다.",
특이성 교란 문제의 해를 위한 신경회로망 접근 가능성,2021,"['Neural Network', 'Back Propagation', 'Singular Perturbed Problems', 'Integro-differential Boundary Value Problems', 'Training Algorithm', '신경회로망', '백프로파게이션', '특이성 교란 문제', '미적분 경계값 문제', '학습 알고리즘']","최근 특이성 교란 미적분 경계값 문제를 해결하기 위해 신경회로망 접근이 연구되고 있다. 특히 다양한 학습 알고리즘을 가진 백프로파게이션 알고리즘에 의해 훈련하는 피드-포워드 신경회로망의 이론적 모델이 제시되고 있으며, 딥러닝, 전이학습, 연합학습 등의 신경회로망 모델이 매우 빠르게 개발되고 있다. 본 논문의 목적은 특이성 교란 문제를 점근법적 방법과 함께 해결하기 위해 고도의 정확성과 속도를 가진 신경회로망 접근법에 관해 연구하는 것이다. 이를 위해 본 논문에서는 특이성 교란문제의 결과치와 교란되지 않은 문제의 결과치의 차이에 대해 신경회로망 접근 식을 사용하여 시뮬레이션 하였고 신경회로망 접근식의 효율성도 제시하였다. 결론적으로 특이성 교란 문제를 수식이 아닌 단순한 신경회로망 접근으로 효율적으로 해결할 수 있음을 제시한 것이 본 논문의 주요 기여사항이다.","Recentlly neural network approach for solving a singular perturbed integro-differential boundary value problem have been researched. Especially the model of the feed-forward neural network to be trained by the back propagation algorithm with various learning algorithms were theoretically substantiated, and neural network models such as deep learning, transfer learning, federated learning are very rapidly evolving. The purpose of this paper is to study the approaching method for developing a neural network model with high accuracy and speed for solving singular perturbed problem along with asymptotic methods. In this paper, we propose a method that the simulation for the difference between result value of singular perturbed problem and unperturbed problem by using neural network approach equation. Also, we showed the efficiency of the neural network approach. As a result, the contribution of this paper is to show the possibility of simple neural network approach for singular perturbed problem solution efficiently."
영유아 이상징후 감지를 위한 표정 인식 알고리즘 개선,2021,"['Expression Recognition', 'Selective Sharpening', 'Edge Map', 'Object Detection', 'Face Detection']","비접촉형 체온 측정 시스템은 광학 및 열화상 카메라를 활용하여 집단시설의 발열성 질병을 관리하는 핵심 요소 중 하나이다. 기존 체온 측정 시스템은 딥러닝 기반 얼굴검출 알고리즘이 사용되어 얼굴영역의 단순 체온 측정에는 활용할 수 있지만, 의사표현이 어려운 영유아의 이상 징후를 인지하는데 한계가 있다. 본 논문에서는 기존의 체온 측정 시스템에서 영유아의 이상징후 감지를 위해 표정인식 알고리즘을 개선한다. 제안된 방법은 객체탐지 모델을 사용하여 영상에서 영유아를 검출한 후 얼굴영역을 추출하고 표정인식의 핵심 요소인 눈, 코, 입의 좌표를 획득한다. 이후 획득된 좌표를 기반으로 선택적 샤프닝 필터를 적용하여 표정인식을 진행한다. 실험결과에 따르면 제안된 알고리즘은 UTK 데이터셋에서 무표정, 웃음, 슬픔 3가지 표정에 대해 각각 2.52%, 1.12%, 2.29%가 향상되었다.","The non-contact body temperature measurement system is one of the key factors, which is manage febrile diseases in mass facilities using optical and thermal imaging cameras. Conventional systems can only be used for simple body temperature measurement in the face area, because it is used only a deep learning-based face detection algorithm. So, there is a limit to detecting abnormal symptoms of the infants and young children, who have difficulty expressing their opinions. This paper proposes an improved facial expression recognition algorithm for detecting abnormal symptoms in infants and young children. The proposed method uses an object detection model to detect infants and young children in an image, then It acquires the coordinates of the eyes, nose, and mouth, which are key elements of facial expression recognition. Finally, facial expression recognition is performed by applying a selective sharpening filter based on the obtained coordinates. According to the experimental results, the proposed algorithm improved by 2.52%, 1.12%, and 2.29%, respectively, for the three expressions of neutral, happy, and sad in the UTK dataset."
지하공동 탐지를 위한 시뮬레이션 생성 데이터 기반 깊은 신경망 학습,2021,"['Underground cavity', 'Ground-penetrating radar', 'Simulation', 'VGGNet-16', 'Feature Visualization', 'Deep Learning', 'Explainable AI', '지하공동', '지표투과 레이다', '시뮬레이션', 'VGGNet-16', '특징 시각화', '딥러닝', '설명가능한 인공지능']","도심지 도로에 발생하는 지하공동은 최근 수년간 사람들의 안전을 위협하는 사회적 현안으로 대두된 바 있다.이에 따라 도심지 지하공동의 존재를 선제적으로 파악하는 일의 중요성이 증대되고 있다. 지하공동을 탐지하기 위해 일반적으로 지표투과 레이다 시스템을 사용하는데, 이는 지하에 전자기파 펄스 신호를 방사시킨 후, 지하의 불연속면에서 산란되어 돌아온 신호를 수신하여 영상화하는 기법이다. 실제 환경에서 GPR 데이터를 수집하고 지하에 공동이 존재하는지 판단하기 위해서는 많은 인력과 시간이 필요하고 수집된 데이터의 개수가 부족한 한계가있다. 따라서 파형 영상 분석에 사용되는 인력을 최소화하고 소요되는 시간을 절약하기 위해 실제 데이터를 대신할 가상 데이터를 생성하여 활용하고자 한다. 본 논문에서는 시뮬레이션을 통해 생성된 파형 영상들을 활용해 깊은 신경망 모델인 VGGNet-16을 학습하여, 지하 토양에 공동이 존재하는지 판단하는 방법을 제안한다. 우리는 시뮬레이션을 통해서 공동이 존재하는 지하 토양의 파형 영상과 존재하지 않는 지하 토양의 파형 영상을 생성하여학습 데이터로 사용하였다. 실험 결과, 공동의 특징을 학습한 VGGNet-16은 공동 모델이 있는 지하 토양과 공동모델이 없는 지하 토양을 분류하는데 92.3%의 정확도를 보였다. 더불어 학습된 모델이 공동의 특징을 적절히 학습했는지 확인하기 위해, 모델이 분류 시 입력 영상에서 어떤 부분을 보고 판단하는지 Score-CAM으로 시각화하였다. 이를 토대로 공동이 존재할 시 나타나는 특징을 깊은 신경망 모델이 적절히 학습하였다고 판단하였다. 향후연구에서는 시뮬레이션으로 생성된 데이터와 실제 공동 데이터 간의 유사도를 검증하고 실제 공동 데이터를 통해서 학습된 모델의 성능을 검증해볼 필요성이 있다고 판단된다.","Recently, underground cavities on urban roads have prompted safety concerns. To provide countermeasures, early detection and identification of cavities are essential. Ground-penetrating radar(GPR) is often used to detect cavity by transmitting electromagnetic pulses and receiving the backscattered radiation from subsurface discontinuities. Collecting data in real-world environment and determining whether cavity exists requires much manpower and time, and there is limitation due to the lack of numbers of cavity data. In this study, to minimize the manpower and save time, we simulate cavity data in place of real-world data. We propose a method of determining the existence of underground cavities by training deep neural network(DNN) model, VGGNet-16, with GPR images produced by simulation. Through simulation, GPR images with and without a cavity were created and used for training. Experimental result showed 92.3% test accuracy in classifying soils with and without cavity models. To ensure the trained model learned cavity features effectively, we use Score-CAM to visualize the model’s representation learning mechanism. Through visualization, we validated that the model learned features that indicate the existence of cavity. In future work, we will verify the similarity between simulated and real-world data and performance of the trained model using real-world data."
PP-YOLO를 이용한 실시간 두피 각질 검출 기법,2021,"['PP-YOLO', '두피 관리', '두피 질병', 'Real-time object detection', 'PP-YOLO', 'Haircare', 'Scalp disease']","두피 질병은 대개 각질과 통증을 유발하며, 증상을 방치하면 탈모나 모낭염으로 진행될 수 있다. 따라서, 질병의 조기 발견과 치료가 중요하지만, 정기적으로 전문 기관을 방문하는 것은 많은 시간과 비용을 초래한다. 최근, 스마트폰에 현미경 카메라를 연동한 두피 상태의 자가진단이 가능해지면서, 딥러닝 기반의 두피 질병 진단 기법이 제안되고 있다. 그러나, 이러한 기법들은 높은 연산량이 요구되어 스마트폰과 같은 제한적인 하드웨어 환경에서는 만족스러운 성능을 얻기가 어려워, 실시간 두피 상태 진단과 같은 현실적인 요구에 부합하지 못하고 있다. 이러한 문제를 해결하고자, 본 논문에서는 두피 질병에서 공통으로 발생하는 각질의 유무와 위치를 실시간으로 추출할 수 있는 기법을 제안한다. 이를 위해, 각질 검출에 PP-YOLO 모델을 사용하였으며, 기존에 제안된 연구들과 검출 정확도 및 처리 속도를 비교하였다. 실험결과, 본 논문에서 제안하는 기법은 실시간 수준의 검출 속도를 만족할 뿐만 아니라, 기존 연구보다 정확하게 두피 각질을 검출할 수 있음을 보인다.",
이산화 전처리 방식 및 컨볼루션 신경망을 활용한 네트워크 침입 탐지에 대한 연구,2021,"['NSL-KDD', '네트워크 이상 탐지', 'CNN', '연속형 변수 이산형화', 'Network Intrusion Detection', 'Discretization of Continuous']","새롭게 발생되는 사이버 공격으로 인해 개인, 민간 및 기업의 피해가 증가함에 따라, 이에 기반이 되는 네트워크 보안 문제는 컴퓨터 시스템의 주요 문제로 부각되었다. 이에 기존에 사용되는 네트워크 침입 탐지 시스템(Network Intrusion Detection System: NIDS)에서 발생되는 한계점을 개선하고자 기계 학습과 딥러닝을 활용한 연구 이뤄지고 있다. 이에 본 연구에서는 CNN(Convolution Neural Network) 알고리즘을 이용한 NIDS 모델 연구를 진행한다. 이미지 분류 기반의 CNN 알고리즘 학습을 위해 기존 사용되는 전처리 단계에서 연속성 변수 이산화(Discretization of Continuous) 알고리즘을 추가하여 예측 변수에 대해 선형 관계로 표현하여 해석에 용이한 데이터로 변환 후, 정사각형 행렬(Square Matrix) 구조에 매칭된 픽셀(Pixel) 이미지 구조를 모델에 학습한다. 모델의 성능 평가를 위해 네트워크 패킷 데이터인 NSL-KDD를 사용하였으며, 정확도(Accuracy), 정밀도(Precision), 재현율(Recall) 및 조화평균(F1-score)을 성능 지표로 사용하였다. 실험 결과 제안된 모델에서 85%의 정확도로 가장 높은 성능을 보였으며, 학습 표본이 적은 R2L 클래스의 조화평균이 71% 성능으로 다른 모델에 비해서 매우 좋은 성능을 보였다.","As damages to individuals, private sectors, and businesses increase due to newly occurring cyber attacks, the underlying network security problem has emerged as a major problem in computer systems. Therefore, NIDS using machine learning and deep learning is being studied to improve the limitations that occur in the existing Network Intrusion Detection System. In this study, a deep learning-based NIDS model study is conducted using the Convolution Neural Network (CNN) algorithm. For the image classification-based CNN algorithm learning, a discrete algorithm for continuity variables was added in the preprocessing stage used previously, and the predicted variables were expressed in a linear relationship and converted into easy-to-interpret data. Finally, the network packet processed through the above process is mapped to a square matrix structure and converted into a pixel image. For the performance evaluation of the proposed model, NSL-KDD, a representative network packet data, was used, and accuracy, precision, recall, and f1-score were used as performance indicators. As a result of the experiment, the proposed model showed the highest performance with an accuracy of 85%, and the harmonic mean (F1-Score) of the R2L class with a small number of training samples was 71%, showing very good performance compared to other models."
제조업 근로자 안전관리를 위한 데이터셋 구축과 모델 학습,2021,[],"최근 ""중대재해 등에 관한 법률""이 제정되고 안전사고에 관한 제도적, 사회적 관심이 높아지고 있다. 본 논문에서는 제조업 현장에서 발생한 안전사고에 대해 정부 기관에서 발간한 통계 자료를 분석하고, 안전사고 발생을 줄이기 위해 위험 상황을 판정하는 모델을 구축하기 위한 딥러닝 기반에 다양한 객체 탐지 모델을 학습시켜 비교 분석하였다. 제조업 현장에 있는 CCTV에서 영상을 수집하여 직접 데이터셋을 구축하였으며, YOLO-v4, SSD, CenterNet 모델에 훈련 데이터와 검증 데이터로 이를 활용하고 학습을 진행하였다. 그 결과 YOLO-v4 모델이 mAP 81%의 수치를 얻었다. 산업 현장에서 클래스를 선정하고 데이터셋을 직접 구축하여 모델 학습을 하는 데 의의가 있으며 이를 통해 위험 상황을 판정하고 이를 추론하는 시스템의 초기 연구자료로 활용할 수 있을 것으로 사료된다.","Recently, the ""Act of Serious Disasters, etc"" was enacted and institutional and social interest in safety accidents is increasing. In this paper, we analyze statistical data published by government agency on safety accidents that occur in manufacturing sites, and compare various object detection models based on deep learning to build a model to determine dangerous situations to reduce the occurrence of safety accidents. The data-set was directly constructed by collecting images from CCTVs at the manufacturing site, and the YOLO-v4, SSD, CenterNet models were used as training data and evaluation data for learning. As a result, the YOLO-v4 model obtained a value of 81% of mAP. It is meaningful to select a class in an industrial field and directly build a dataset to learn a model, and it is thought that it can be used as an initial research data for a system that determines a risk situation and infers it."
베이지안 확률 및 폐쇄 순차패턴 마이닝 방식을 이용한 설명가능한 로그 이상탐지 시스템,2021,"['설명가능한 인공지능', '로그 이상탐지 시스템', '베이지안 확률', '규칙 추출', 'Explainable AI', 'Log anomaly detection', 'Bayesian probability', 'Rule extraction']","인터넷과 개인용 컴퓨터가 발달하면서 다양하고 복잡한 공격들이 등장하기 시작했다. 공격들이 복잡해짐에 따라 기존에 사용하던 시그니처 기반의 탐지 방식으로 탐지가 어려워졌으며 이를 해결하기 위해 행위기반의 탐지를 위한 로그 이상탐지에 대한 연구가 주목 받기 시작했다. 최근 로그 이상탐지에 대한 연구는 딥러닝을 활용해 순서를 학습하는 방식으로 이루어지고 있으며 좋은 성능을 보여준다. 하지만 좋은 성능에도 불구하고 판단에 대한 근거를 제공하지 못한다는 한계점을 지닌다. 판단에 대한 근거 및 설명을 제공하지 못할 경우, 데이터가 오염되거나 모델 자체에 결함이 발생해도 이를 발견하기 어렵다는 문제점을 지닌다. 결론적으로 사용자의 신뢰성을 잃게 된다. 이를 해결하기 위해 본 연구에서는 설명가능한 로그 이상탐지 시스템을 제안한다. 본 연구는 가장 먼저 로그 파싱을 진행해 로그 전처리를 수행한다. 이후 전처리된 로그들을 이용해 베이지안 확률 기반 순차 규칙추출을 진행한다. 결과적으로 “If 조건 then 결과, 사후확률(θ)” 형식의 규칙집합을 추출하며 이와 매칭될 경우 정상, 매칭되지 않을 경우, 이상행위로 판단하게 된다. 실험으로는 HDFS 로그 데이터셋을 활용했으며, 그 결과 F1score 92.7%의 성능을 나타내었다.","With the development of the Internet and personal computers, various and complex attacks begin to emerge. As the attacks become more complex, signature-based detection become difficult. It leads to the research on behavior-based log anomaly detection. Recent work utilizes deep learning to learn the order and it shows good performance. Despite its good performance, it does not provide any explanation for prediction. The lack of explanation can occur difficulty of finding contamination of data or the vulnerability of the model itself. As a result, the users lose their reliability of the model. To address this problem, this work proposes an explainable log anomaly detection system. In this study, log parsing is the first to proceed. Afterward, sequential rules are extracted by Bayesian posterior probability. As a result, the ""If condition then results, post-probability"" type rule set is extracted. If the sample is matched to the ruleset, it is normal, otherwise, it is an anomaly. We utilize HDFS datasets for the experiment, resulting in F1score 92.7% in test dataset."
스태킹 앙상블을 이용한 병렬 네트워크 이상호흡음 분류 모델,2021,"['Respiratory Sound Classification', 'Wheezes', 'Crackles', 'Convolutional Neural Network(CNN)', 'Stacking Ensemble', '호흡음 분류', '천명음', '수포음', '병렬 합성곱 신경망', '스태킹 앙상블']","최근 코로나(Covid-19)의 영향으로 스마트 헬스케어 관련 산업과 비대면 방식의 원격 진단을 통한 질환 분류 예측 연구의 필요성이 증가하고 있다. 일반적으로 호흡기 질환의 진단은 비용이 많이 들고 숙련된 의료 전문가를 필요로 하여 현실적으로 조기 진단 및 모니터링에 한계가 있다. 따라서, 간단하고 편리한 청진기로부터 수집된 호흡음을 딥러닝 기반 모델을 활용하여 높은 정확도로 분류하고 조기 진단이 필요하다. 본 연구에서는 청진을 통해 수집된 폐음 데이터를 이용하여 이상 호흡음 분류모델을 제안한다. 데이터 전처리로는 대역통과필터(BandPassFilter)방법론을 적용하고 로그 멜 스펙트로그램(Log-Mel Spectrogram)과 Mel Frequency Cepstral Coefficient(MFCC)을 이용하여 폐음의 특징적인 정보를 추출하였다. 추출된 폐음의 특징에 대해서 효과적으로 분류할 수 있는 병렬 합성곱 신경망 네트워크(Parallel CNN network)모델을 제안하고 다양한 머신러닝 분류기(Classifiers)와 결합한 스태킹 앙상블(Stacking Ensemble) 방법론을 이용하여 이상 호흡음을 높은 정확도로 분류하였다. 본 논문에서 제안한 방법은 96.9%의 정확도로 이상 호흡음을 분류하였으며, 기본모델의 결과 대비 정확도가 약 6.1% 향상되었다.","As the COVID-19 pandemic rapidly changes healthcare around the globe, the need for smart healthcare that allows for remote diagnosis is increasing. The current classification of respiratory diseases cost high and requires a face-to-face visit with a skilled medical professional, thus the pandemic significantly hinders monitoring and early diagnosis. Therefore, the ability to accurately classify and diagnose respiratory sound using deep learning-based AI　models is essential to modern medicine as a remote alternative to the current stethoscope. In this study, we propose a deep learning-based respiratory sound classification model using data collected from medical experts. The sound data were preprocessed with BandPassFilter, and the relevant respiratory audio features were extracted with Log-Mel Spectrogram and Mel Frequency Cepstral Coefficient (MFCC). Subsequently, a Parallel CNN network model was trained on these two inputs using stacking ensemble techniques combined with various machine learning classifiers to efficiently classify and detect abnormal respiratory sounds with high accuracy. The model proposed in this paper classified abnormal respiratory sounds with an accuracy of 96.9%, which is approximately 6.1% higher than the classification accuracy of baseline model."
보행에 따른 대퇴사두근 부위별 근활성도의 착용형 관성센서 측정에 대한 영향 평가,2021,"['Wearable Inertial Sensor(착용형 관성센서)', 'Electromyogram(근전도)', 'Muscle Activity(근활성도)', 'Lower-Limb Part(대퇴부)', 'Quadriceps Femoris Muscle(대퇴사두근)']","본 논문에서는 착용형 관성센서를 기반으로 인체 하지부 운동분석을 수행할 때 대퇴부의 근활성도가 대퇴부에 부착된 센서 출력에 미치는 영향을 가속도 및 각속도 관점에서 분석하고 평가한다. 데이터 취득 시 발생하는 센서 노이즈 및 외란 요소들은 착용형 관성센서로 측정된 시계열 동작 데이터 분석 및 딥러닝 기술의 일반화 성능에 부정적인 영향을 미치게 된다. 따라서 본 논문에서는 근활성에 의한 센서 출력을 외란으로 정의하고 정량적으로 평가하였다. 순수 근활성에 의한 착용형 관성 센서 출력을 파악하기 위해 EMG 센서를 통해 보행 시 발생하는 근활성과 동일한 근활성이 이루어지는 새로운 실험 방법(MSRCR)을 제안하였으며, 제안된 실험을 통해 수집된 센서 데이터의 가속도와 각속도의 norm값을 분석하여 외측광근이 센서 출력에 가장 적은 영향을 주는 부위임을 확인하였다.","In this study, during the motion analysis of the human lower limb based on the wearable inertial sensor, the effects of the muscle activity of each quadriceps femoris muscle on the sensor output attached to it is analyzed and evaluated in terms of acceleration and angular velocity. Sensor noise and disturbance factors generated during data acquisition negatively affect the generalization performance of time series motion data analysis and deep learning technology measured by the wearable inertial sensor. Therefore, in this study, the sensor output by muscle activity was defined as disturbance and quantitatively evaluated. To grasp the wearable inertial sensor output by pure muscle activity, a new experimental method (MSRCR) was proposed in which the same muscle activity as that occurring during walking is achieved through the EMG sensor, and sensor data were collected through the proposed experiment. By analyzing the L2-norm values of the acceleration and angular velocity, it was confirmed that the lateral vastus muscle had the least effect on the sensor output."
PoseNet과 GRU를 이용한 Skeleton Keypoints 기반 낙상 감지,2021,"['Pose Estimation', 'Skeleton Keypoints', 'Fall Detection', 'Deep Learning', 'LSTM', 'PoseNet']","낙상 판단을 위한 최근 발표되는 연구는 RNN(Recurrent Neural Network)을 이용한 낙상 동작 특징 분석과 동작 분류에 집중되어 있다. 웨어러블 센서를 기반으로 한 접근 방식은 높은 탐지율을 제공하나 사용자의 착용 불편으로 보편화 되지 못했고 최근 영상이나 이미지 기반에 딥러닝 접근방식을 이용한 낙상 감지방법이 소개 되었다. 본 논문은 2D RGB 저가 카메라에서 얻은 영상을 PoseNet을 이용해 추출한 인체 골격 키포인트(Keypoints) 정보로 머리와 어깨의 키포인트들의 위치와 위치 변화 가속도를 추정함으로써 낙상 판단의 정확도를 높이기 위한 감지 방법을 연구하였다. 특히 낙상 후 자세 특징 추출을 기반으로 Convolutional Neural Networks 중 Gated Recurrent Unit 기법을 사용하는 비전 기반 낙상 감지 솔루션을 제안한다. 인체 골격 특징 추출을 위해 공개 데이터 세트를 사용하였고, 동작분류 정확도를 높이는 기법으로 코, 좌우 눈 그리고 양쪽 귀를 포함하는 머리와 어깨를 하나의 세그먼트로 하는 특징 추출 방법을 적용해, 세그먼트의 하강 속도와 17개의 인체 골격 키포인트가 구성하는 바운딩 박스(Bounding Box)의 높이 대 폭의 비율을 융합하여 실험을 하였다. 제안한 방법은 기존 원시골격 데이터 사용 기법보다 낙상 탐지에 보다 효과적이며 실험환경에서 약 99.8%의 성공률을 보였다.","A recent study of people physically falling focused on analyzing the motions of the falls using a recurrent neural network (RNN) and a deep learning approach to get good results from detecting 2D human poses from a single color image. In this paper, we investigate a detection method for estimating the position of the head and shoulder keypoints and the acceleration of positional change using the skeletal keypoints information extracted using PoseNet from an image obtained with a low-cost 2D RGB camera, increasing the accuracy of judgments about the falls. In particular, we propose a fall detection method based on the characteristics of post-fall posture in the fall motion-analysis method. A public data set was used to extract human skeletal features, and as a result of an experiment to find a feature extraction method that can achieve high classification accuracy, the proposed method showed a 99.8% success rate in detecting falls more effectively than a conventional, primitive skeletal data-use method."
인공지능 스피커의 세대별 온라인 리뷰 분석을 통한 사용자 경험 요인 탐색,2021,[],"인공지능 스피커 시장은 꾸준히 성장하고 있지만, 실제 스피커 사용자들의 만족도는 42%에 그치고 있다. 따라서, 본 연구에서는 인공지능 스피커의 세대별 토픽 변화와 감성 변화를 통해 사용자 경험을 저해하는 요소는 무엇인지 분석해 보고자 한다. 이를 위해 아마존 에코 닷 3세대와 4세대 모델에 대한 리뷰를 수집하였다. 토픽모델링 분석 기법을 사용하여 세대별로 리뷰를 이루는 주제 및 주제의 변화를 찾아내고, 딥러닝 기반 감성 분석을 통해 토픽에 대한 사용자 감성이 세대에 따라 어떻게 변화되었는지 살펴보았다. 토픽모델링 결과, 세대별로 5개의 토픽이 도출되었다. 3세대의 경우 스피커의 일반적 속성을 나타내는 토픽은 제품에 긍정적 반응 요인으로 작용했고, 사용자 편의 기능은 부정적 반응 요인으로 작용했다. 반대로 4세대에서는 일반적 속성은 부정적으로, 사용자 편의 기능은 긍정적으로 도출되었다. 이와 같은 분석은 방법론 측면에서 어휘적 특징뿐 아니라 문장 전체의 문맥적 특징이 고려된 분석결과를 제시할 수 있다는 것에 그 의의가 있다.",
인덱싱 및 요약을 위한 영화 장면 이해에 관한 연구,2021,"['영화 분석', '장면 이해', '영화 장면 전환', '상황별 분석', 'movie analysis', 'scene understanding', 'cinematography transitions', 'contextual analysis']","지난 10년 동안 엔터테인먼트 산업의 발전으로 인해 영화 데이터의 생산이 기하급수적으로 성장하여 색인 생성, 주 요장면 추천 및 장르 식별 등 다양한 연구 분야가 나타나게 되었다. 따라서 영화 콘텐츠를 분석하고 이해하는 것은 아주 중요한 분야로 자리 잡게 되었다. 본 논문에서는 시각적 요소와 텍스트 양식을 활용한 영화 문법과 맥락 분석 이라는 두 가지 측면에서 영화를 분석하는 지능형 프레임워크를 제안한다. 제안된 프레임워크는 확대/축소/배경/ 텍스트와 같이 영화에서 등장하는 장면을 감지하는 전처리 과정을 거친 후 상황별 분석을 위해 딥러닝 모델을 활용 한 객체와 텍스트 감지를 진행했다. 마지막으로 영화에서 나오는 대사를 추출하고 이를 영화 타임 스탬프를 기반으 로 각 씬에 대한 분석 결과와 영화에 등장하는 인물들의 대사를 저장함으로써 인덱싱 및 요약 등 다양한 용도로 활 용될 수 있게끔 만들었으며, 제안된 프레임워크는 주관적인 평가를 사용하여 평가를 진행하였다.","Over the past decade, advancements in the entertainment industry have caused exponential growth in video data production especially movies, leading to tiresome indexing, recommendation making, and genre identification. To overcome these challenges, analyzing and understanding the movie contents is the primary step. Therefore, in this paper we proposed an intelligent framework to analyze movies from two different aspects i.e., film grammar and contextual analysis using vision and textual modality. The proposed framework first preprocessed the movie for scene segmentation. Next, the cinematographic transitions are detected such as zoom, background and text related scenes. For contextual analysis, we used customized deep models for object and text detection. Finally, the detailed description of each scene over the movie timestamp is recorded which can be use for various application such as indexing and summarization etc. The proposed framework is evaluated using movie scripts and subjective evaluation."
AR에 적용 가능한 마커리스 기반의 실내 위치 측정 기법,2021,"['Markerless Positioning', 'Local Patch', 'AR', 'Indoor Positioning', 'Deeplearning']","본 논문에서는 AR에 적용 가능한 마커리스 기반의 실내 위치 측정 기법을 제안한다. 제안한 기법은 다음과 같은 독창성을 갖는다. 첫 번째는 특징점을 추출하고 이를 이용하여 지역 패치를 생성하여 전체 이미지를 학습하지 않고 주변보다 더 유용한 지역 패치만을 학습하고 사용함으로써 더 빠른 연산이 가능하도록 한다. 두 번째는 Convolution Neural Network 구조를 사용한 딥러닝을 통해 학습을 진행하여 오차율을 줄여 정확도를 향상시킨다. 세 번째는 기존의 특징점 매칭 기법과는 다르게 좌우 이동을 포함한 실내 위치 측정이 가능하도록 한다. 네 번째는 매 프레임마다 새롭게 실내 위치를 측정하기 때문에 이동중 앞쪽에서 발생한 오차가 누적되어 발생되는 것을 방지한다. 따라서 이동 거리가 길어져도 최종 도착점과 예측 실내 위치간의 오차가 증가하지 않는다는 장점을 갖는다. 본 논문에서 제안하는 AR에 적용 가능한 마커리스 기반의 실내 위치 측정기법의 소요시간과 정확도를 평가하기 위해 시행한 실험결과, 실제 실내 위치와 측정된 실내 위치의 차이가 평균 12.8㎝, 최대 21.2㎝로 측정되어서, 기존 IEEE 논문의 결과보다 우수한 실내 위치 측정 정확도를 나타내었다. 또한, 초당 20프레임으로 측정된 결과를 나타내어서 실시간으로 사용자의 실내 위치를 측정하는 것이 가능하다고 판단되었다.","In this paper, we propose a measurement technique of indoor location based on markerless applicable to AR. The proposed technique has the following originality. The first is to extract feature points and use them to generate local patches to enable faster computation by learning and using only local patches that are more useful than the surroundings without learning the entire image. Second, learning is performed through deep learning using the convolution neural network structure to improve accuracy by reducing the error rate. Third, unlike the existing feature point matching technique, it enables indoor location measurement including left and right movement. Fourth, since the indoor location is newly measured every frame, errors occurring in the front side during movement are prevented from accumulating. Therefore, it has the advantage that the error between the final arrival point and the predicted indoor location does not increase even if the moving distance increases. As a result of the experiment conducted to evaluate the time required and accuracy of the measurement technique of indoor location based on markerless applicable to AR proposed in this paper, the difference between the actual indoor location and the measured indoor location is an average of 12.8㎝ and a maximum of 21.2㎝. As measured, the indoor location measurement accuracy was better than that of the existing IEEE paper. In addition, it was determined that it was possible to measure the user’s indoor location in real time by displaying the measured result at 20 frames per second."
YOLOv4를 이용한 차량파손 검출 모델 개선,2021,"['Deep Learning', 'YOLOv4', 'Object Detection', 'Computer Vision', 'Vehicle Damage Detection']","본 논문에서는 YOLOv4를 이용하여 차량의 부위별 파손현황을 검출하는 기법을 제안한다. 제안 알고리즘은 YOLOv4를 통해 차량의 부위와 파손을 각각 학습시킨 후 검출되는 바운딩 박스의 좌표 정보들을 추출하여 파손과 차량부위의 포함관계를 판단하는 알고리즘을 적용시켜 부위별 파손현황을 도출한다. 또한 성능비교의 객관성을 위하여 동일분야의 VGGNet을 이용한 기법, 이미지 분할과 U-Net 모델을 이용한 기법, Weproove.AI 딥러닝 모델 등을 대조 모델로 포함한다. 이를 통하여 제안 알고리즘의 성능을 비교, 평가하고 검출 모델의 개선 방안을 제안한다.","This paper proposes techniques for detecting the damage status of each part of a vehicle using YOLOv4. The proposed algorithm learns the parts and their damages of the vehicle through YOLOv4, extracts the coordinate information of the detected bounding boxes, and applies the algorithm to determine the relationship between the damage and the vehicle part to derive the damage status for each part. In addition, the technique using VGGNet, the technique using image segmentation and U-Net model, and Weproove.AI deep learning model, etc. are included for objectivity of performance comparison. Through this, the performance of the proposed algorithm is compared and evaluated, and a method to improve the detection model is proposed."
합성곱신경망을 사용한 이미지 기반의 안드로이드 악성소프트웨어 패밀리 분류,2021,"['안드로이드 악성소프트웨어', '패밀리 분류', '회색조 이미지', '합성곱 신경망', '데이터 섹션', 'android malware', 'family classification', 'grayscale image', 'CNN', 'data section']","안드로이드 악성소프트웨어가 지속적으로 증가함에 따라, 기계학습을 사용한 안드로이드 악성소프트웨어 탐지 및 분류 기법이 많이 연구되고 있다. 악성소프트웨어 패밀리(malware family) 분류는, 악성소프트웨어 샘플들을 연관성 있는 그룹으로 분류하는 기법으로 컴퓨터 포렌식 분석, 위협 평가, 위협완화 계획에 중요한 역할을 한다. 본 논문에서는 실행파일 중의 일부를 회색조 이미지(grayscale image)로 변환한 후 변환된 영상들을 대상으로 딥러닝 기법을 적용하여 안드로이드 악성소프트웨어 패밀리를 분류하는 방법을 제안한다. 대표적인 안드로이드 악성소프트웨어 데이터 셋(dataset)인 Drebin에서 제공되는 악성소프트웨어 대표 패밀리들을 대상으로 합성곱신경망(Convolutional Neural Network, CNN) 모델을 적용하여 악성소프트웨어를 분류한다. 본 실험의 연구 결과를 기존 연구 결과와 비교하여, 데이터 경량화와 적절한 데이터 크기의 선정, 정확도에 있어 본 연구가 악성소프트웨어 분류에 더 효과적임을 보인다.","As Android malware continues to increase, Android malware detection and classification techniques using machine learning are being studied intensively. Malware family classification is a technique for classifying malware samples into related malware families and plays an important role in computer forensic analysis, threat assessment, and threat mitigation planning. In this paper, we propose a method to classify Android malware families by converting only part of an executable file into a gray scale image and applying deep learning to the converted images. The malware samples are classified from the representative families of the dataset from the Drebin project by applying the Convolutional Neural Network (CNN) model. The experimental results show that the proposed method is more effective in classifying malware families in terms of processing overhead and classification accuracy."
A Study on Brand Image Analysis of Gaming Business Corporation using KoBERT and Twitter Data,2021,"['Brand Image(브랜드이미지)', 'Machine Learning(기계학습)', 'Social Media(소셜미디어)', 'Transfer Learning(전이학습)', 'Sentiment Analysis(감성분석)', 'Natural Language Processing(자연어처리)']","브랜드 이미지는 고객, 이해관계자, 시장 전체가 해당 브랜드를 어떻게 보고 인지하는지를 뜻한다. 긍정적 브랜드 이미지는 계속적인 구매를 유발하지만, 부정적인 브랜드 이미지는 구매를 중단하게 만드는 등 소비자의 구매행동에 직결되기 때문에, 기업 입장에서는 빠르고 정확히 파악할 필요가 있다. 현재 브랜드 이미지를 조사하는 방법으로는 설문조사, SNS조사 등이 있는데, 표본의 수가 한정되고 시간과 비용이 많이 소요된다는 이슈가 있다. 따라서 본 연구에서는 딥러닝 기반의 KoBERT 모델을 활용하여 소셜미디어 상의 텍스트 데이터에 대한 감성분석을 실시한 후, 이를 브랜드 이미지 분석에 활용하는 방법을 제시하고, 이에 대한 성능을 검증하였다. 결과적으로, 다섯 개의 브랜드 이미지 순위를 매긴 결과가 한국기업평판연구소의 순위와 일치함으로써 본 연구의 사용성을 입증하였다.","Brand image refers to how customers, stakeholders and the market see and recognize the brand. A positive brand image leads to continuous purchases, but a negative brand image is directly linked to consumers"" buying behavior, such as stopping purchases, so from the corporate perspective, it needs to be quickly and accurately identified. Currently, methods of investigating brand images include surveys and SNS surveys, which have limited number of samples and are time-consuming and costly. Therefore, in this study, we are going to conduct an emotional analysis of text data on social media by utilizing the machine learning based KoBERT model, and then suggest how to use it for game corporate brand image analysis and verify its performance. The result has proved some degree of usability showing the same ranking within five brands when compared with the BRI Korea’s brand reputation ranking."
홈 트레이닝을 위한 관절 핵심점 검출 및 자세 유사도 측정,2021,"['Key points detect', 'Feature extractor', 'Pose estimation', 'Auto encoder', 'Pose similarity']",,
인공지능 기반 영어 발음 인식에 관한 연구,2021,"['인공지능', '동적 시간 워핑', '합성곱 신경망', '영어 발음', '영어 교육', 'AI', 'DTW', 'CNN', 'English Pronunciation', 'English Language Training']","최근 4차 산업혁명은 주요 선진국을 중심으로 세계의 국가들의 관심을 갖는 분야가 되고 있다. 4차 산업혁명 기술의 핵심기술인 인공지능기술은 다양한 분야에 융합하는 형태로 발전하고 있으며, 에듀테크 분야에도 많은 영향을 미치고 있으며 교육을 혁신적으로 변화하기 위해 많은 관심과 노력을 하고 있다. 본 논문은 DTW 음성인식 알고리즘을 이용하여 실험환경을 구축하고 다양한 원어민 데이터와 비원어민 데이터를 딥러닝 학습하고, CNN 알고리즘과의 비교를 통해 영어 발음의 유사도를 측정하여 비원어민이 원어민과 유사한 발음으로 교정할 수 있도록 연구한다.","Recently, the fourth industrial revolution has become an area of interest to many countries, mainly in major advanced countries. Artificial intelligence technology, the core technology of the fourth industrial revolution, is developing in a form of convergence in various fields and has a lot of influence on the edutech field to change education innovatively. This paper builds an experimental environment using the DTW speech recognition algorithm and deep learning on various native and non-native data. Furthermore, through comparisons with CNN algorithms, we study non-native speakers to correct them with similar pronunciation to native speakers by measuring the similarity of English pronunciation."
서울시 공공자전거 수요예측 모형 비교 연구,2021,"['공공자전거 운영 정책', '다변량 시계열 분석', '서포트 벡터 회귀 모형', '시계열 군집 분석', 'LSTM', 'public bicycle policy', 'support vector regression', 'time series clustering', 'vector autoregression']","최근 환경 및 교통 문제 현안의 대안으로서 공공자전거 이용 활성화 정책이 양산되고, 그 사용량이 증가하고 있다. 본 논문에서는 서울시에서 제공하는 공공자전거의 일별 대여이력을 바탕으로 공공 자전거 수요 예측을 위한 모형들을 비교 분석한다. 대여소별 시계열 데이터에 대한 상관성을 가정한 벡터 자기회귀 모형 (VAR)과 독립성 가정이 요구되지 않는 기계 학습모형인 서포트 벡터 회귀 모형 (SVR), 비독립 데이터에 특화된 딥러닝 기법인 LSTM 모형, 그리고 비유사성 측정방법에 따라 데이터를 군집화하는 시계열 군집 분석 기법을 활용한 SVR 모형과 VAR 모형을 이용하여 자전거 대여 데이터를 모델링하고 수요 예측에 사용하여 그 예측의 정확도를 비교한다.","Recently, as an alternative to environmental and transportation issues, the policy of activating the use of public bicycles has been mass-produced and the usage has increased. This paper compares and studies the model for predicting the demand of public bicycles based on the daily rental history of public bicycles in Seoul. VAR model which is extended from univariate autoregressive model to multivariate autoregressive model, the SVR model, which does not require independent assumptions, and the LSTM model, which is a deep learning technique specialized in dependent data are compared. In addition, a time series clustering analysis technique that clusters data according to a dissimilarity measure is used in SVR and VAR models. The performance is compared using RMSE and MAE. The predictive power of the LSTM model is the best, and the next is SVR. VAR model shows lowest predictive power compared to the other models."
인성人性과 물성物性에 대한 소고: 메타버스와 인성론을 중심으로,2021,"['인성人性', '물성物性', '메타버스', '인공지능', '인성론', 'Human Nature', 'Physical Property', 'Metaverse', 'Artificial Intelligence', 'Theory of Human Nature']","인문학의 주요 관심사 중 하나는 인성에 대한 탐구이다. 특히 동서양 철학 계의 인성론에서는 이데아idea, 이성, 존재, 인仁, 이理, 성선性善, 성악性惡 같은 개념을 통하여 인간의 본성을 탐구해 왔다. 이 같은 학문 동향에서 설명하기 힘든 메타버스 metaverse의 출현은 가히 혁명적 사태라고 하겠다. 인간이 현실과 가상 세계를 넘나들며 활동하는 메타버스에서는, 특정 인간을 표상하는 ‘디지털로 만들어진 가상 인물’이 타인을 표상하는 가상 인물과 인간관계를 하는 현상이 일어나고 있으며, 그 영역과 기능이 확대되고 있다. 알파고처럼 딥러닝을 통해 강화 학습을 하는 가상 인물은 인간을 모사하는 수준에서 벗어나 스스로 행동하는 단계로 발전해나가고 있다. 인간의 아바타로서 회의를 하고 업무를 하는 수동적 수준을 넘어서, 인공지능이 인간이 당면한 문제를 상담해 주거나 스스로 농담을 하거나 빅데이터를 기반으로 지식을 가르치는 활동을 하고 있다. 인공지능에 기반한 전자적 인간은 실제 인간보다 외모나 행동이 더 매력적인 경우가 늘어나고 있고, 강화 학습하는 전자적 인간이 인성 측면에서 인간에 비하여 부족한 면이 없는 현상도 나타나고 있다. 인공지능의 발전에 따라서 사회적 규율 측면에서 인간 범주가 기존의 ‘자연인’과 ‘법인’ 외에 ‘전자적 인간’이 추가되는 동향이 확산되고 있으며, 메타버스의 영역 확대와 기능 발전을 고려할 때 인성과 물성을 이항대립적 관점에서 벗어나 검토할 필요가 있으며 이에 대한 다양한 후속 연구가 필요하다.","One of the main interests of the humanities is the exploration of ‘human nature人性’ In particular, in the personality theory of Eastern and Western philosophical circles, human nature that is defined through concepts such as Ideas, reason, Sein, Ren仁, Li理, Good Nature性善, and Evil Nature性惡 has been exploring with being unlike ‘physical property物性’ The emergence of a metaverse that is difficult to explain in such an academic trend is truly a revolutionary event. In the metaverse, where humans cross the real world and the virtual world, a phenomenon is occurring in which ‘digitally created virtual characters’ representing a specific human being have a human relationship with a virtual character representing another person. A cyberperson who performs reinforcement learning through deep learning like AlphaGo is developing from the level of imitating humans to the stage of self-judgment and action. Artificial intelligence is engaged in activities such as consulting on problems facing humans, joking around with themselves, and teaching knowledge based on big data. Cyberpersons, based on AI, are increasingly attractive in appearance and behavior than real humans, and outperform humans in personality. In this regard, in terms of social discipline, as the human category is expanding, the addition of ‘electronic human’ in addition to the existing ‘natural person’ and ‘corporate person’ is spreading. It is necessary to review the modern personality theory that has been built without reflecting the metaverse and cyberperson, and various follow-up studies on this are needed."
x-vector를 이용한 다화자 음성합성 시스템,2021,"['x-vector', '화자 임베딩', '다화자', '음성합성', 'X-vector', 'Speaker embedding', 'Multi-speaker', 'Speech synthesis']","최근 인공지능 스피커 시장이 성장하면서 사용자와 자연스러운 대화가 가능한 음성합성 기술에 대한 수요가 증가하고 있다. 따라서 다양한 음색의 목소리를 생성할 수 있는 다화자 음성합성 시스템이 필요하다. 자연스러운 음 성을 합성하기 위해서는 대용량의 고품질 음성 DB로 학습하는 것이 요구된다. 그러나 많은 화자가 발화한 고품질의 대용량 음성 DB를 수집하는 것은 녹음 시간과 비용 측면에서 매우 어려운 일이다. 따라서 각 화자별로는 소량의 학 습 데이터이지만 매우 많은 화자의 음성 DB를 사용하여 음성합성 시스템을 학습하고, 이로부터 다화자의 음색과 운 율 등을 자연스럽게 표현하는 기술이 필요하다. 본 논문에서는 화자인식 기술에서 사용하는 딥러닝 기반 x-vector 기법을 적용하여 화자 인코더를 구성하고, 화자 인코더를 통해 소량의 데이터로 새로운 화자의 음색을 합성하는 기술 을 제안한다. 다화자 음성합성 시스템에서 텍스트 입력에서 멜-스펙트로그램을 합성하는 모듈은 Tacotron2로, 합성음 을 생성하는 보코더는 로지스틱 혼합 분포가 적용된 WaveNet으로 구성되어 있다. 학습된 화자 임베딩 신경망에서 추출한 x-vector를 Tacotron2에 입력으로 추가하여 원하는 화자의 음색을 표현한다.","With the recent growth of the AI speaker market, the demand for speech synthesis technology that enables natural conversation with users is increasing. Therefore, there is a need for a multi-speaker speech synthesis system that can generate voices of various tones. In order to synthesize natural speech, it is required to train with a large-capacity. high-quality speech DB. However, it is very difficult in terms of recording time and cost to collect a high-quality, large-capacity speech database uttered by many speakers. Therefore, it is necessary to train the speech synthesis system using the speech DB of a very large number of speakers with a small amount of training data for each speaker, and a technique for naturally expressing the tone and rhyme of multiple speakers is required. In this paper, we propose a technology for constructing a speaker encoder by applying the deep learning-based x-vector technique used in speaker recognition technology, and synthesizing a new speaker's tone with a small amount of data through the speaker encoder. In the multi-speaker speech synthesis system, the module for synthesizing mel-spectrogram from input text is composed of Tacotron2, and the vocoder generating synthesized speech consists of WaveNet with mixture of logistic distributions applied. The x-vector extracted from the trained speaker embedding neural networks is added to Tacotron2 as an input to express the desired speaker’s tone."
엣지카메라기반 실시간 도로위험 검지 및 정보 제공 시스템,2021,"['엣지카메라', '지역최적화', '도로위험검지', '돌발상황검지', 'C-ITS 서비스', 'edge camera', 'local optimization', 'traffic danger recognition', 'automatic incident detection', 'C-ITS services']","현재 C-ITS 서비스는 레이다 혹 카메라 기반으로 돌발상황을 검지하고 도로위험 정보를 운전자에게 제공한다. 레이다기반의 돌발상황검지기는 가격이 비싸고 교통 이상 상황을 확인하기 위해서는 별도의 카메라가 필요하다. 또한, 레이다는 차량과 보행자 검출이 가능하나 그 외 오토바이, 자전거, 낙하물과 같은 객체는 검출이 어렵다. 기존 C-ITS 시스템에서 카메라기반의 돌방상황검지의 경우, C-ITS 센터의 영상분석 서버에서 돌발상황을 검지하고 위험정보를 운전자에게 제공하기 때문에 실시간 서비스를 제공하기 어렵다. 이러한 문제를 해결하기 위해 본 논문은 엣지카메라기반 실시간 도로위험인식 및 정보제공시스템을 제안한다. 엣지카메라는 로컬에서 영상처리를 통해 객체를 인식하고 위험상황을 판단하여 RSU를 통해 운전자에게 위험정보를 제공한다. 제안 시스템은 실시간 처리를 위해 경량 딥러닝 네트워크를 사용하고, 정확도 향상을 위해 지역최적화를 수행한다. 그리고 기존 C-ITS 응용 표준 프로토콜을 수정 없이 사용할 수 있도록 엣지카메라와 RSU의 통신 인터페이스를 설계하였다. 실험을 통해 교통객체를 정확하게 인식하고 100ms 이내에 실시간으로 도로위험상황을 운전자에게 정보를 제공함을 확인할 수 있다.","Currently, cooperative intelligent transport systems (C-ITS) recognize traffic hazards using radar or camera based automatic incident detectors and provide drivers with hazard information. Radar-based automatic incident detectors are expensive and require a separate closed circuit television (CCTV) camera to detect and monitor traffic abnormalities. Despite these detector can identify vehicles and pedestrians, they have difficulty detecting other objects such as motorcycles, bicycles, and falling objects. In the case of the camera based automatic incident detectors, it is difficult to provide a real-time service because the CCTV image is transferred to the video analysis server of the C-ITS center which recognizes traffic hazards, whereby the hazard information is then provided to the driver. To overcome these limitations, this paper proposes an edge camera based real-time road hazard recognition and information provision system. The edge camera recognizes an object through image processing locally, determines a danger situation, and provides danger information to the driver through the roadside unit (RSU). The proposed system uses a lightweight deep learning network for real-time processing and performs local optimization to improve accuracy. In addition, the communication interface between the edge camera and RSU is designed so that the existing C-ITS application standard protocol can be used without modification. Experimental results show that traffic objects are accurately recognized and drives were able to be informed of road hazard situations in real time within 100ms."
사용자의 입력 의도를 반영한 음절 N-gram 기반 한국어 띄어쓰기 및 붙여쓰기 오류 교정 시스템,2021,"['자동 띄어쓰기', '한국어 띄어쓰기 및 붙여쓰기', '사용자 의도 반영 띄어쓰기', '음절 N-gram', 'automatic spacing', 'korean word segmentation', 'word segmentation reflecting user’s intent', 'syllable n-gram']","기존의 자동 띄어쓰기 시스템은 사용자의 띄어쓰기 정보를 활용하지 않고 띄어쓰기를 모두 제거한 문장에 대해 공백을 삽입하는 방식으로 띄어쓰기 오류를 수정한다. 이러한 방식으로 띄어쓰기 오류를 교정할 경우, 사용자가 올바르게 입력한 띄어쓰기를 수정하는 문제와 사용자의 의도를 충분히 반영하지 못하는 문제가 발생한다. 본 논문에서는 이러한 문제를 보완하기 위해 사용자가 입력한 의도를 반영한 음절 N-gram 기반 한국어 띄어쓰기 및 붙여쓰기 오류 교정 시스템을 제안한다. 실험 결과, 오류가 10% 포함된 문장에 대해서 음절 단위 정확률 99.05%, 어절 단위 F1 score 95.57%라는 높은 성능을 보였다. 이는 사용자의 띄어쓰기 정보를 활용하지 않은 기존 방식보다 음절 단위 정확률 1.85%, 어절 단위 F1 score 5.84% 향상된 결과이다. 또한, 딥러닝 방식이 아닌 음절 확률 통계정보만을 사용함으로써 초당 2691.69 문장의 빠른 교정 속도를 보였다.","Previous researches on automatic spacing corrected errors by inserting spaces in sentences without utilizing the user’s spacing information. The present approach involves modifying the user’s input incorrectly and a problem that does not sufficiently reflect user intent. In this paper, we propose a syllable N-gram based Korean word segmentation system that reflects the user’s intent. The comparison between the proposed model and the model using previous methods demonstrated an increase in the syllable accuracy from 97.20% to 99.05% and the word F1 score from 89.73% to 95.57% in the proposed model. Also, the proposed model was able to correct 2691.69 sentences per second."
코로나 이전과 이후의 4차 산업혁명과 광고의 뉴스기사 분석 : LDA와 Word2vec을 중심으로,2021,"['4차 산업혁명', '광고', '코로나 19', 'LDA', 'Word2vec', 'the 4th Industrial Revolution', 'Advertising', 'COVID 19']","4차 산업혁명이란 인공지능(AI), 사물인터넷(IoT), 로봇기술, 드론, 자율주행과 가상현실(VR) 등 정보통신 기술이 주도하는 차세대 산업혁명을 말하는 것으로, 광고 산업 발전에도 큰 영향을 미쳤다. 그러나 지금 전세계는 코로나 확산 방지를 위하여, 비접촉, 비대면 생활환경으로 급속도로 빠르게 변화하고 있다. 이에 따라 4차 산업혁명과 광고의 역할도 변화하고 있다. 따라서 본 연구에서는 코로나 19 이전과 이후의 4차산업 혁명과 광고의 변화를 살펴보기 위해 빅카인즈를 활용해서 텍스트 분석을 하였다. 코로나 19 이전인 2019년과 코로나 19 이후인 2020년을 비교하였다. LDA토픽 모형 분석과 딥러닝 기법인 Word2vec을 통해 주요 토픽과 문서분류를 하였다. 연구결과 코로나19 이전에는 정책, 콘텐츠, AI 등이 나타났으나, 코로나 이후에는 데이터를 활용한 금융, 광고, 배달 등으로 점차 영역이 확장되며, 더불어 인재양성 교육이 중요한 이슈로 나타난 것을 알 수 있었다. 또한, 코로나 19 이전에는 4차 산업혁명 기술과 관련된 광고를 활용하는 것이 주류를 이루었다면, 코로나 19 이후에는 참여, 협력, 일상 필요 등 좀 더 적극적으로 첨단기술 자체에 대한 교육과 인재양성 등에 대한 키워드가 두드러지게 나타나고 있다. 따라서 이러한 연구결과는 코로나 19 이후에 4차 산업혁명에서 광고의 나아갈 방향을 제시하면서, 이에 필요한 이론적, 실무적으로 적용할 수 있는 다각적인 전략을 제시하는 데 의의가 있다.","The 4th industrial revolution refers to the next-generation industrial revolution led by information and communication technologies such as artificial intelligence (AI), Internet of Things (IoT), robot technology, drones, autonomous driving and virtual reality (VR) and it also has made a significant impact on the development of the advertising industry. However, the world is rapidly changing to a non-contact, non-face-to-face living environment to prevent the spread of COVID 19. Accordingly, the role of the 4th industrial revolution and advertising is changing. Therefore, in this study, text analysis was performed using Big Kinds to examine the 4th industrial revolution and changes in advertising before and after COVID 19. Comparisons were made between 2019 before COVID 19 and 2020 after COVID 19. Main topics and documents were classified through LDA topic model analysis and Word2vec, a deep learning technique. As the result of the study showed that before COVID 19, policies, contents, AI, etc. appeared, but after COVID 19, the field gradually expanded to finance, advertising, and delivery services utilizing data. Further, education appeared as an important issue. In addition, if the use of advertising related to the 4th industrial revolution technology was mainstream before COVID 19, keywords such as participation, cooperation, and daily necessities, were more actively used for education on advanced technology, while talent cultivation appeared prominently. Thus, these research results are meaningful in suggesting a multifaceted strategy that can be applied theoretically and practically, while suggesting the future direction of advertising in the 4th industrial revolution after COVID 19."
지능형 사이버 공격 경로 분석 방법에 관한 연구,2021,"['Intelligent Cyber Attack', 'Cyber Attack Path', 'Attack Tree', 'RFI', 'Path Prediction']","지능형 사이버 공격으로 인한 피해는 시스템 운영 중단과 정보 유출뿐만 아니라 엄청난 규모의 경제적 손실을 동반한다. 최근 사이버 공격은 공격 목표가 뚜렷하며, 고도화된 공격 도구와 기법을 활용하여 정확하게 공격 대상으로 침투한다. 이러한 지능적인 사이버 공격으로 인한 피해를 최소화하기 위해서는 사이버 공격이 공격 대상의 핵심 시스템까지 침입하지 못하도록 공격 초기 또는 과정에서 차단해야 한다. 최근에는 빅데이터나 인공지능 기술을 활용하여 사이버 공격 경로를 예측하고 위험 수준을 분석하는 보안 기술들이 연구되고 있다. 본 논문에서는 자동화 사이버 공격 경로 예측 시스템 개발을 위한 기초 메커니즘으로 공격 트리와 RFI 기법을 활용한 사이버 공격 경로 분석 방법을 제안한다. 공격 트리를 활용하여 공격 경로를 가시화하고 각 공격 단계에서 RFI 기법을 이용하여 다음 단계로 이동할 수 있는 경로를 판단한다. 향후에 제안한 방법을 기반으로 빅데이터와 딥러닝 기술을 활용한 자동화된 사이버 공격 경로 예측 시스템의 메커니즘으로 활용할 수 있다.",
제품-기술로드맵 개발을 강화하기 위한 예측모델링에 관한 실증 연구,2021,['-'],"최근 시스템 반도체 발전으로 인하여 자동차 산업의 전장(電裝)에 대한 기술혁신이 빠르게 진행되고 있다. 특히, 자동차의 전장화는 자동차 부품업체들의 기술개발 경쟁을 가속화시키고 있으며, 개발 주기 또한 빠르게 변화하고 있다. 이러한 변화로 인하여 연구개발에 대한 전략과 기획의 중요성은 더욱 강화되고 있다. 자동차 산업의 패러다임 변화로 인하여, 연구개발 전략 중의 하나인 제품-기술로드맵(P/TRM)은 기획 단계에서 기술예측, 기업의 기술수준평가, 기술획득방법(Make/Collaborate/Buy) 등의 분석을 통하여 개발이 이루어져야 한다. 제품-기술로드맵은 제품과 기술의 고객 니즈를 파악하고 기술의 선정, 개발방향을 설정하는 툴(Tool)로써, 미래의 발전방향 추세를 예측하고 매크로(Macro) 트랜드의 전략적 방향성과 목표를 설정하는데 사용된다. 하지만, 대부분의 기업에서는 해당 기술의 논문이나 특허 분석, 전문가 델파이에 주로 의존하는 정성적인 방법을 통하여 제품-기술로드맵을 개발하고 있다. 본 연구는 가트너의 하이프 사이클과 누적이동평균 기반 데이터 전처리, 딥러닝(LSTM) 시계열 분석 기법을 융합하여 자동차 산업 중심으로 제품-기술로드맵을 보완하고 강화시킬 수 있는 시뮬레이션을 통하여 실증 연구를 진행하였다. 본 논문에서 제시한 실증 연구는 자동차 산업 뿐만 아니라, 범용적으로 타제조업 분야에서도 사용 가능할 수 있다. 또한, 기업적인 측면에서는 그동안 정성적인 방법에 의존하던 로드맵 작성 방법에서 탈피하여 좀 더 정확한 제품-기술로드맵을 통하여 적기에 시장에 제품을 제공함으로써 선도업체로 나아가기 위한 밑거름이 될 것이라고 사료된다.","Due to the recent development of system semiconductors, technical innovation for the electric devices of the automobile industry is rapidly progressing. In particular, the electric device of automobiles is accelerating technology development competition among automobile parts makers, and the development cycle is also changing rapidly. Due to these changes, the importance of strategic planning for R&D is further strengthened. Due to the paradigm shift in the automobile industry, the Product-Technical Roadmap (P/TRM), one of the R&D strategies, analyzes technology forecasting, technology level evaluation, and technology acquisition method (Make/Collaborate/Buy) at the planning stage. The product-technical roadmap is a tool that identifies customer needs of products and technologies, selects technologies and sets development directions. However, most companies are developing the product-technical roadmap through a qualitative method that mainly relies on the technical papers, patent analysis, and expert Delphi method. In this study, empirical research was conducted through simulations that can supplement and strengthen the product-technical roadmap centered on the automobile industry by fusing Gartner's hype cycle, cumulative moving average-based data preprocessing, and deep learning (LSTM) time series analysis techniques. The empirical study presented in this paper can be used not only in the automobile industry but also in other manufacturing fields in general. In addition, from the corporate point of view, it is considered that it will become a foundation for moving forward as a leading company by providing products to the market in a timely manner through a more accurate product-technical roadmap, breaking away from the roadmap preparation method that has relied on qualitative methods."
한류 콘텐츠의 간접/가상광고 활성화 전략에 관한 연구,2021,"['한류 콘텐츠', '간접광고', '가상광고', '코로나 19', '심층인터뷰', 'Korean Wave Content', 'PPL', 'Virtual advertising', 'Covid-19', 'Depth Interview']","지난 2019년 정부는 콘텐츠 강국으로의 성장을 적극적으로 지원하겠다는 의지로 ‘콘텐츠 산업 3대 혁신전략’을 발표하였다. 우리나라는 2018년 한해 100억 달러의 문화 콘텐츠 수출을 달성하며 세계 7위의 콘텐츠 강국으로 성장하였으며, 한류 콘텐츠 연관 소비재 및 관광 수출액도 50억 달러를 넘었다. 이에 본 논문에서는 콘텐츠의 교류를 통해 기업들의 해외 진출을 활성화할 방안을 제시하고자 한다. 구체적으로는 콘텐츠 확산에 힘입은 다양한 형태의 광고인 간접/가상광고를 통해 글로벌 기업의 경쟁력을 높이는데 미치는 영향을 파악해 보고자 한다. 따라서 본 연구는 코로나 이전과 이후의 한류를 통한 변화를 살펴보기 위해 뉴스 기사들을 텍스트 분석하였다. 빅카인즈를 통해 데이터를 수집하여 빈도분석 및 워드 클라우드를 파악했으며, R프로그램을 활용하여 LDA토픽모형 분석과 딥러닝 기법인 Word2vec을 통해 주요 토픽과 문서분류를 하였다. 또한, 한류와 간접/가상광고에 관한 전문가 8명과의 심층 인터뷰를 통해 OTT 등 미디어 소비환경에 대비한 간접/가상광고의 대응방안을 마련해 보았다. 아울러 드라마 중심의 한류에서 벗어나 다른 장르나 포맷에서의 간접가상광고의 가능성을 살펴보았다. 마지막으로 한류에서의 간접/가상광고 활성화를 위해서 정부/지원 기관과 방송사/PP 및 광고대행사의 역할을 제시하였다. 따라서 본 연구를 통한 연구결과는 국내 기업의 글로벌 입지를 다지는데 필요한 간접가상광고를 효과적으로 활용할 수 있는 방안에 대해 이론적 및 실무적으로 적용할 수 있는 다각적인 전략을 제시하는데 그 의의가 있다.","In 2019, the government announced the ‘Top 3 Innovation Strategies for the Content Industry’ with the intention of actively supporting growth as a content powerhouse. In 2018, Korea reached $10 billion in cultural content exports in 2018 and has grown to become the world s seventh-largest content powerhouse. Therefore, in this paper, I will suggest a way to promote companies overseas expansion through the exchange of contents. Specifically, I would like to understand the effect of increasing the competitiveness of global companies through PPL/virtual advertising, which are various types of advertising driven by content diffusion. Specifically, this research will examine the impact of enhancing the competitiveness of global companies through PPL/virtual advertising, which are various types of advertising driven by content diffusion. Therefore, this study text-analyzed news articles to examine the changes through the Korean Wave, PPL and virtual adverting before and after Covid-19. I collected data through Big Kinds to understand Frequency Analysis and Word Cloud. Using R program, LDA topic model analysis and deep learning method Word2vec were used to classify major topics and documents. In addition, through in-depth interview with eight experts on Korean Wave and PPL/virtual advertising, I prepared a countermeasure against PPL/virtual advertising in preparation for the media consumption environment such as OTT. I then explore the possibility of PPL/virtual advertising in different genres and formats, away from the Korean Wave centered on drama. Lastly, I suggest roles of government/support agencies, broadcasters/PP, and advertising agencies in order to promote PPL/virtual advertising in the Korean Wave. Therefore, the research results from this study have significance in presenting various strategies that can be applied theoretically and practically to a method to effectively utilize PPL/virtual advertising necessary to strengthen the global position of domestic companies."
텍스트 마이닝과 소셜네트워크분석을 통한 AI·빅데이터 기반 제조기술 트렌드 연구,2021,"['제조 인공지능', '제조 빅데이터', '텍스트 마이닝', '소셜네트워크분석', '제조기술 트렌트', 'Manufacturing Artificial Intelligent', 'Manufacturing Big Data', 'Text Mining', 'Social Network Analysis', 'Manufacturing Technology Trends']","최근 스마트공장 질적 고도화의 일환으로 제조 생태계에 AI·빅데이터 기술적용에 대한 관심이 고조되고 있다. 그러나 기존 제조기술 트렌드 연구는 스마트공장 구축을 위한 자동화·로봇화에 집중되어 제조 AI·빅데이터 중심의 제조기술 트렌드 연구 및 활용은 미비한 실정이다. 본 연구는 제조업에 적용되는 AI·빅데이터 기술에 대한 최근 6년 동안의 주요 이슈 및 트렌드를 분석하여 제조기업의 AI·빅데이터 기술도입의 방향성을 제시하고자 한다. 분석결과의 적시성과 정확도를 증대하기 위해 특허, 논문, 뉴스, 박람회, 인공지능 중소벤처 제조플랫폼(KAMP) 콘텐츠를 분석 데이터로 통합화하였다. 그리고 수집 데이터의 정제로 Python 3.6과 텍스트 마이닝 및 소셜네트워크분석은 KrKwic 2.0, UCINET 6.721을 활용하였다. 분석 결과, 시간의 흐름에 따라 제조 특화 AI, 딥러닝, 알고리즘 키워드의 연결중심성이 높아지는 것으로 나타났으며 이를 구현하기 위해 고성능 컴퓨팅 기술을 포함한 다수의 제조AI 기술군집이 형성되었다. 제조현장의 AI 적용목적에 따라 보다 다양하고 최적화된 제조 특화 AI 알고리즘 및 제조 빅데이터 융·복합기술의 중요도가 증가하고 있음을 관찰할 수 있었다.","Recently, there has been a surge of interest in manufacturing AI and big data technology application. Since current manufacturing technology trend research is focused on automation and robotization for the construction of smart factories, study and utilization of manufacturing technology trends centered on manufacturing AI and big data are insufficient. Therefore, this study examines major issues and trends in AI·big data technologies applied to the manufacturing industry over the last six years. To reflect the timeliness and accuracy of analysis results, patents, theses, news, fairs, and Korea AI Manufacturing Platform(KAMP) contents are integrated into analysis data, and data refinement is performed using Python 3.6, text mining, and social network analysis. KrKwic 2.0 and UCINET 6.721 were utilized for this purpose. It was discovered that the degree centrality of manufacturing AI keywords rose with time, prompting the formation of a number of manufacturing AI technology clusters. The significance of more diverse AI algorithms specialized in manufacturing and high-performance infra resources increases depending on the aim of AI application in the manufacturing site."
중학생을 위한 인공지능 핵심 개념 기반의 교육 프로그램 개발,2021,"['인공지능', '인공지능 교육', '인공지능의 정의', '인공지능의 핵심 개념', '인공지능 교육프로그램', 'Artificial Intelligence', 'Artificial Intelligence Education Program', 'Artificial Intelligence Core Concepts']","AIoT, AIX 등 인공지능 기술의 발달에 따라 인공지능 교육도 중요해지고 있다. 하지만, 인공지능 교육에서 무엇을 핵심 개념으로 학습할 지에 대한 연구가 부족한 상황이다. 따라서 이 연구는 인공지능 핵심 개념 기반의 교육 프로그램을 개발하여 중학생의 인공지능에 대한 이해를 향상시키는 것을 목적으로 한다. 이 연구는 분석, 설계, 개발, 실행, 평가의 5단계로 진행하였다. 이 연구를 통하여 얻은 결과는 다음과 같다. 첫째, 인공지능의 핵심 개념을 선정한 결과 인식, 추상화, 학습, 예측이었으며, 인공지능 전문가 검사 결과 리커트 5점 척도 전체 평균값 4.0점이었다. 핵심 개념의 하위 개념은 데이터수집, 패턴, 데이터전처리, 모델, 오차, 정확도, 딥러닝, 회귀, 분류였으며, 검사 결과값은 전체 평균값 4.2점이었다. 둘째, 인공지능의 핵심 개념을 중심으로 중학교에 적용하기 위한 교육프로그램을 8차시로 구성하였다. 셋째, 인공지능 교육프로그램을 적용하고 학생 평가 결과에서 인공지능의 핵심 개념 이해에 대한 검사 결과 전체 평균값 3.88점으로 유의미한 결과를 확인하였다. 넷째, 인공지능의 핵심 개념을 가장 잘 반영하는 과제는 공부시간으로 시험점수 예측하기였다. 이 과제는 추상화, 학습, 예측의 핵심 개념의 반영이 가장 높은 교육프로그램 평균값 3.96점이었다.","Artificial intelligence education is becoming more important as AI technologies such as AIoT, AIX, etc. are developed. However, there is a lack of research on what to learn as a core concept in artificial intelligence education. Therefore, The purpose of this study is to improve middle school students understanding of artificial intelligence by developing artificial intelligence education programs based on artificial intelligence core concepts. This study was conducted in five phases: analysis, design, development, execution, and evaluation. The results obtained from this study are as follows. First, the results of selecting the core concepts of artificial intelligence were recognition, abstraction, learning, prediction. The results of artificial intelligence expert tests was a total average of 4.0 points for the Likert 5-point scale. The subconcepts of the core concepts were data collection, pattern, data preprocessing, model, error, accuracy, deep learning, regression, and classification. the result of expert tests was a total average of 4.2 points. Second, we construct an eighth-order education program for applying it to middle schools, focusing on the core concept of artificial intelligence. Third, we applied an artificial intelligence education program and checked the student evaluation results for understanding the core concepts of artificial intelligence, and found significant results with a total average of 3.88 points. Fourth, the education program that best reflects the core concept of artificial intelligence was predicting test scores with study time. This education program was the average value of 3.96 points which has the highest reflection of the core concepts of abstraction, learning, and prediction."
AI를 활용한 미술작품 실감체험 서비스 개발에 관한 연구,2021,"['On-line museum', 'AI', 'Neural style transfer', 'Image transformation', 'Experience']","정보통신 기술의 발전은 사회, 문화 및 산업 전반에 크고도 빠른 변화를 가져오고 있다. 더불어 지능화로 대표되는 4차산업혁명의 진행과 코로나19로 인한 비대면의 강제적 도입은 기존의 오프라인 중심의 산업에 정보통신을 활용한 서비스의 적용 속도를 더욱 가속화하고 있다. 특히 이 연구에서 주로 다루어질 박물관의 경우 셧다운이 되었거나 사회적 거리두기로 인하여 방문을 꺼리는 기피장소가 되었다. 또한 어두운 터널의 끝에는 디지털의 적용이 일상화된 뉴노멀의 시대가 도래하여 관람객을 예전과 같은 방식으로 맞이할 수 없는 환경에 있을 것이다. 이러한 변화들은 갑작스러움이 아닌 지속되는 흐름이며, 코로나19로 인하여 도입의 속도가 빨라졌을 뿐이다. 따라서 박물관들은 사실감 있는 전시, 방문객과의 소통, 재미요인을 제공하여 방문객 만족도 제고와 재방문을 위한 온라인 서비스의 도입이 필수 불가결하다. 이 연구에서는 딥러닝의 한 방법인 NST를 적용하여 pre-trained된 모델을 기반으로 content image와 style image를 입력으로 이용해 이미지 변환 네트워크를 학습하는 방법을 적용, 실시간으로 전시 미술품 관련 온라인 체험요인을 제공하는 기술을 개발하여 제안함으로서 방문객의 흥미와 만족도를 높이는 방안을 제시하고자 한다.","The development of information and communication technology is bringing huge and rapid changes across society, culture and industry. In addition, the progress of the Fourth Industrial Revolution, represented by intelligence, and the forced introduction of non-face-to-face due to Covid-19 are accelerating the application of ICT applied services to existing offline industries. In particular, museums that will be mainly covered in this study have become places of avoidance due to shutdowns or social distancing. In addition, at the end of the dark tunnel, the era of New-Normal where digital has become commonplace will be in an environment where visitors cannot be treated in the same way as before. These changes are not sudden, but continuous flows, and the introduction speed has only been accelerated due to Covid-19. Therefore, it is essential for museums to provide realistic exhibitions, communication with visitors, and fun factors to enhance visitor satisfaction and revisit by introducing online services. In this study, some methods are proposed to increase the interest and satisfaction of visitors by developing and proposing a technology that provides online experience factors related to exhibition artworks in real time by applying NST, a method of deep learning of an image conversion network using content image and style image as inputs based on a pre-trained model."
폐기종의 시각적 분류 및 정량적 평가,2021,"['Emphysema', 'Tomography', 'X-Ray Computed', 'Quantitative Evaluation', 'Deep Learning']","폐기종은 만성 폐쇄성 폐질환을 유발하는 질환으로, CT는 폐기종을 정확하게 진단하는 데가장 유용한 검사이다. 폐기종의 중증도는 시각적 분류 혹은 정량적 분석 등의 방법으로 평가할 수 있으며, 최근에는 딥러닝을 활용한 폐기종 연구도 다양하게 이루어지고 있다. 이러한 폐기종의 중증도 분류 방법은 다양한 연구에서 그 임상적 유용성을 입증받고 있으며, 한계점으로 지적되고 있는 측정의 신뢰성을 향상시키려는 노력 또한 이어지고 있다.","Pulmonary emphysema is a cause of chronic obstructive pulmonary disease. Emphysema can be accurately diagnosed via CT. The severity of emphysema can be assessed using visual interpretation or quantitative analysis. Various studies on emphysema using deep learning have also been conducted. Although the classification of emphysema has proven clinically useful, there is a need to improve the reliability of the measurement."
드론과 Mobile Mapping System을 활용한 인공지능 기반 도로 균열 검출,2021,"['artificial intelligence', 'CNN', 'drone', 'mobile mapping system', 'mobilenetv2', 'road crack', '인공지능', '드론', '모바일매핑시스템', '도로 균열']","최근 5년간 중앙정부의 전체 예산은 매년 4.9%의 비율로 증가하고 있으나, 도로부문의 유지관리 예산은 매년 줄고 있다. 또한 도로법의 개정 및 지속가능한 기반시설 관리 기본법의 신설에 따라 모든 지자체에서 유지관리와 성능개선을 위해 5년 단위의 기본계획을 수립해야 한다. 하지만 상대적으로 예산이 적은 지자체에서 도로관리를 위한 고가의 장비를 도입하기는 현실적으로 어려운 실정이다. 이에 본 연구는 인공지능을 활용하여 상대적으로 가격이 저렴한 Mobile Mapping System(MMS)와 드론을 활용한 도로균열 검출 방법을 제시하는 것을 연구의 목적으로 한다. MMS와 드론을 활용하여 얻은 해상도 높은 도로 노면 사진데이터를 취득하고 데이터의 특성에 따라 인공지능을 학습시키기 위하여 전처리를 수행하였다. 딥러닝 학습을 위해 도로 파손 유형에 따라 균열이 있는 곳과 없는 곳, 또는 도로가 아닌 곳으로 라벨링을 진행하였고 Basic CNN모델과 Mobilenetv2신경망을 수정하여 학습을 진행하였다. Mobilenetv2의 알고리즘의 분류정확도는 MMS데이터 95%, 드론데이터 78%를 얻었다. 이는 MMS와 드론을 활용하여 정도 높은 균열 분류가 가능하다는 결론을 도출할 수 있었다. 향후 본 연구에서 개발된 알고리즘을 기반으로 지자체와 시설물 관리 기관에서 도로균열을 체계적으로 관리될 것이다. 또한 사용자 중심의 소프트웨어를 활용하여 도로를 이용하는 시민들에게도 도움이 될 것으로 기대된다.","In recent years, the total budget of the central government has been increasing at a rate of 4.9% per year, but the maintenance budget of the road sector has been decreasing annually. In addition, with the revision of the Road Act and the establishment of the Framework Act on Sustainable Infrastructure Management, all local governments shall establish a five-year master plan to improve maintenance and performance. However, it is difficult for local governments with relatively small budgets to introduce expensive equipment for road management. In response, the purpose of this study is to present a road crack detection method using mobile mapping system (MMS) and drones that are relatively inexpensive with the use of artificial intelligence. High-precision road surface photographic data could be acquired using MMS and drones. Pre-processing was carried out to train the artificial intelligence depending on the characteristics of the data. Labeling was conducted according to the type of road cracks and was labeled based on where cracks were present, where none were present, or where roads were not. The training was done by modifying the basic convolution network model and the mobilenetv2 neural network. As a result of the training, the data classification accuracy using the mobilenetv2 algorithm was able to achieve 95% on MMS data and 78% on drone data. It can be hypothesized that a more high-performance crack classification accuracy might be achieved by utilizing MMS and drone equipment. In the future, road cracks will be systematically managed by local governments and facility management agencies based on algorithms developed in this study. It is also expected to benefit citizens who use user-centered software to use roads."
암반공학분야에 적용된 인공지능 알고리즘 분석,2021,"['Rock engineering', 'Artificial intelligence', 'Machine learning', 'Artificial neural networks', 'Algorithm', '암반공학', '인공지능', '기계학습', '인공신경망', '터널']","4차 산업혁명 시대의 도래에 따라 암반공학분야에서도 인공지능을 활용한 연구가 점차 증가하고 있다. 본 논문에서는 인공지능에 대한 이해와 그 활용도를 더욱 증진시키기 위하여, 암반공학기술의 주된 적용대상인 터널, 발파, 광산과 관련된 최근의 국내외 연구 중 인공지능이 활용된 논문들에서 그 알고리즘의 종류와 적용방법을 분석하였다. 터널에서는 암반분류, TBM굴진율 및 막장전방 지질 예측, 발파에서는 암반의 파쇄도 및 비산거리, 광산에서는 폐광의 침하가능성 예측을 위해 주로 활용되고 있으며, 기계학습의 다양한 알고리즘 중 인공신경망이 압도적으로 많이 활용되고 있는 것으로 나타났다. 연구결과의 정확도와 신뢰성 제고를 위해 사용하고자 하는 인공지능 알고리즘에 대한 정확하고 상세한 이해가 필수적이며, 현재는 접근이나 분석이 난해한 암반공학 분야의 다양한 문제해결을 위해 기계학습뿐 아니라 CNN 또는 RNN과 같은 딥러닝을 활용한 연구 아이디어들이 점차 증가될 것으로 기대된다.","As the era of Industry 4.0 arrives, the researches using artificial intelligence in the field of rock engineering as well have increased. For a better understanding and availability of AI, this paper analyzed the types of algorithms and how to apply them to the research papers where AI is applied among domestic and international studies related to tunnels, blasting and mines that are major objects in which rock engineering techniques are applied. The analysis results show that the main specific fields in which AI is applied are rock mass classification and prediction of TBM advance rate as well as geological condition ahead of TBM in a tunnel field, prediction of fragmentation and flyrock in a blasting field, and the evaluation of subsidence risk in abandoned mines. Of various AI algorithms, an artificial neural network is overwhelmingly applied among investigated fields. To enhance the credibility and accuracy of a study result, an accurate and thorough understanding on AI algorithms that a researcher wants to use is essential, and it is expected that to solve various problems in the rock engineering fields which have difficulty in approaching or analyzing at present, research ideas using not only machine learning but also deep learning such as CNN or RNN will increase."
비행체의 궤적 예측을 위한 순환 신경망 기반 기법들의 정량적 비교 평가에 관한 연구,2021,"['Flight vehicles', 'Trajectory prediction', 'Recurrent neural network', 'Long short-term memory network', 'Objective evaluation']",본 논문에서는 비행체의 궤적 예측에 적절한 순환 신경망 기반 기법을 탐구하기 위하여 정량적인 비교 평가 연구를 수행하였다. 이를 위해 본 논문에서는 비행체의 궤적 예측 작업을 수행하기 위한 다양한 입력 및 출력 관계들을 정의하고 동일한 실험 환경에서 비교 평가하였다. 특히 비행체 위치의 상대값 기반 입출력 관계를 제안하여 비행체의 궤적 예측에 적합함을 보였다. 또한 비행체 궤적 예측에 효율적인 네트워크 구조 및 하이퍼파라미터를 결정하기 위한 다양한 ablation study(비교실험)를 진행하였다. 본 논문에서 제시된 정량적 비교 평가 결과는 비행체의 궤적 예측을 위해 순환 신경망 기반 기법을 이용하거나 비행체의 궤적 예측에 특화된 딥러닝 기법을 연구하고자 하는 연구자 및 개발자들에게 실질적인 도움이 될 것으로 예상된다.,"In this paper, we present an experimental comparative study of recurrent neural network based techniques for trajectory prediction of flight vehicles. We defined and investigated various relationships between input and output under the same experimental setup. In particular, we proposed a relationship based on the relative positions of flight vehicles. Furthermore, we conducted an ablation study on the network architectures and hyperparameters. We believe that this comprehensive comparative study serves as a reference point and guide for developers in choosing an appropriate recurrent neural network based techniques for building (flight) vehicle trajectory prediction systems."
주기적 행동 검출을 위한 멀티스케일 U-Net,2021,"['Multi-scale U-Net', '3D CNN', 'Periodicity', 'Repetition']",,
자율주행차용 우선순위 기반 다중 DNN 모델 스케줄링 프레임워크,2021,"['자율주행', '우선순위', '임베디드 시스템', 'DNN', '병렬처리', 'Autonomous vehicles', 'Priority', 'Embedded distributed system', 'Deep Neural Network', 'Parallel processing']",최근 딥러닝 기술이 발전함에 따라 자율 사물 기술이 주목받으면서 드론이나 자율주행차 같은 임베디드 시스템에서 DNN을 많이 활용하고 있다. 클라우드에 의지하지 않고 높은 인식 정확도를 위해서 큰 규모의 연산이 가능하고 다수의 DNN을 처리할 수 있는 임베디드 시스템들이 출시되고 있다. 이러한 시스템 내부에는 다양한 수준의 우선순위를 갖는 DNN들이 존재한다. 자율주행차의 안전 필수에 관련된 DNN들은 가장 높은 우선순위를 갖고 이들은 반드시 최우선적으로 처리되어야 한다. 본 논문에서는 다수의 DNN이 동시에 실행될 때 우선순위를 고려해서 DNN을 스케줄링하는 프레임워크를 제안한다. 낮은 우선순위의 DNN이 먼저 실행되고 있어도 높은 우선순위의 DNN이 이를 선점할 수 있어 자율주행차의 안전 필수 응용의 빠른 응답 특성을 보장한다. 실험을 통하여 확인한 결과 실제 상용보드에서 최대 76.6% 성능이 향상되었다.,"With the recent development of deep learning technology, autonomous things technology is attracting attention, and DNNs are widely used in embedded systems such as drones and autonomous vehicles. Embedded systems that can perform large-scale operations and process multiple DNNs for high recognition accuracy without relying on the cloud are being released. DNNs with various levels of priority exist within these systems. DNNs related to the safety-critical applications of autonomous vehicles have the highest priority, and they must be handled first. In this paper, we propose a priority-based scheduling framework for DNNs when multiple DNNs are executed simultaneously. Even if a low-priority DNN is being executed first, a high-priority DNN can preempt it, guaranteeing the fast response characteristics of safety-critical applications of autonomous vehicles. As a result of checking through extensive experiments, the performance improved by up to 76.6% in the actual commercial board."
AI 학습용 데이터의 보호에 관한 소고 - 지식재산법상의 보호를 중심으로 -,2021,"['AI-related Inventions', 'Data Ownership', 'Data Protection', 'Database', 'Data for training', 'Unfair Competition', 'AI 관련 발명', '데이터 소유권', '데이터 보호', '학습용 데이터', '부정경쟁']","데이터는 AI 기술과 밀접한 관계를 가진다. 데이터가 축적되면 될수록, 데이터가 정확하면 할수록 좋은 분석결과가 나온다. 이러한 분석에는 AI 기술(AI 소프트웨어)이 활용된다. 딥러닝과 머신러닝과 같은 AI 기술의 발전은 데이터를 더욱 가치 있게 만들어 왔다. 데이터는 AI 기술과 함께 거래되는 경우가 많아지게 되었고, 데이터와 AI 기술을 활용한 비즈니스도 더욱 활기를 띠고 있다. 이러한 관점에서 AI 학습용 데이터는 적절히 보호될 필요가 있다.","Data is closely related to AI technology. The more data is accumulated and the more accurate the data is, the better the analysis results come out. AI technology (AI software) is used for this analysis. Advances in AI technologies such as deep learning and machine learning have made data more valuable. Data is often traded with AI technology, and businesses using data and AI technology are also becoming more vibrant. From this point of view, AI learning data needs to be adequately protected. In the case of the domestic data industry, data creation and utilization is evaluated as relatively inadequate. Data required for data construction and utilization (distribution) is insufficient, and industrial and social use is poor due to a closed distribution system.This phenomenon is believed to be due to the limited use of data due to restrictions on personal information, and the lack of manpower responding to corporate demand. In particular, learning data essential for AI-related inventions is no exception. In this study, the following measures were proposed to protect AI learning data. First, a plan to strengthen protection under the patent law, second, a plan to protect data through the Unfair Competition Prevention Act, third, a plan to introduce a 'data patent' application system in preparation for the era of big data, and fourth, Fourth, similar to the microbial donation system, the introduction of the AI system for depositing data and learning completion models was suggested."
딥러닝분석을 이용한 고빈도 매매 최적화 성능평가,2021,"['인공지능', '비즈니스 애널리틱스', '핀테크', '국제 금융', '알고리즘 트레이딩', 'Artificial Intelligence', 'Business Analytics', 'FinTech', 'International Finance', 'Intelligent Algorithm Trading']","현대 금융 시장은 과거의 금융 시장과 달리 전 세계 투자자들이 장소에 구애받지 않고 금융 상품을 거래할 수 있게 되었으며 주문 및 체결도 백만분의 1초 단위에서 일어나는 이전과 비교할 수 없을 정도로 빠르게 움직이는 움직이고 있다. 이에 컴퓨터 알고리즘 트레이딩이 더욱 요구되고 진화하고 있지만, 변화하는 시장 데이터, 많은 종류의 시그널 값을 빠르고 지능적인 방식으로 변화시키는데 제한이 있을 뿐 아니라 최적의 속도와 정교함을 가진 실행 논리를 개발·유지하는 것은 매우 어렵고 복잡하다. 본 연구에서는 최적화 알고리즘에 따른 딥러닝 모형기반의 고빈도 매매성능을 비교 분석한다. 분석 결과, 심층 신경망에 의한 고빈도 매매전략 기반에 따른 총 누적 수익이 기초자산의 수익과 비교하여 높은 수익을 얻을 수 있었으며 장기간 지속하는 특성을 보여주었다. 둘째, 일반적으로 성능이 뛰어나다고 알려진 Adam이 유로/달러 환율 고빈도 데이터에 대한 심층 신경망 학습성능에서는 RMSprop과 AdaGrad에 비해 상대적으로 성능을 떨어지는 것으로 나타났다.","Compared to the past financial markets, large investment banks, hedge funds and institutional investors in modern financial markets use powerful computer programs to execute a large number of trades in less than a millionth of a second anywhere in the world. Even though more sophisticated computer algorithm trading systems should be available to market participants upon request, there are limitations to understand market dynamics and market signals and accurate execution logic with optimal speed. This study compares and analyzes the high-frequency trading performance based on the deep learning model according to the stochastic gradient descent algorithm. The main result shows that high-frequency trading performance based on deep learning was likely to learn trading rules. The total cumulative return based on the high-frequency trading strategy based on the deep neural network was able to obtain a high return compared to the return of the underlying asset and showed long-lasting characteristics. Second, Adam, which is generally known to have excellent performance, showed relatively poor performance compared to RMSprop and AdaGrad in deep neural network learning performance for high-frequency data of euro/dollar exchange rates."
대화형 AI 시스템과 비목적성 소통의 사용자 감성경험연구,2021,"['Human-AI인터랙션', 'AI EUX디자인', '비목적성 대화의 감성경험 구조모형', 'Human-AI Interaction', 'AI EUX Design', 'Non-purpose Interaction EUX System Model']","본 연구는 최근 대두되고 있는 음성기반 인터랙션에 관한 니즈를 반영하여 AI와 사람간의 대화에 관련된 사용자의 경험연구를 진행하였다. 연구에서는 AI 스피커와 스마트폰에 탑재된 AI 등의 구분을 두지 않고 대화가 가능한 AI 시스템과 사람(Human) 간의 인터랙션에 기반한 AI를 실험 대상으로 했다. 또한 한국어를 이용한 대화(Conversation)에서 지식 정보의 전달이나 계산 등 기존의 컴퓨터나 스마트폰에서 문자를 통해서도 해왔던 영역 이외에 빅데이터 딥러닝 기술 등의 발전에 힘입어 최근 시도되고 있는 AI와의 감성 혹은 감정 영역의 대화들을 시도하여 대화(Conversation)가 가지게 되는 인간의 감성적인 연결성 이외에 문화적인 특질들도 나타나는지에 대해서 알아보고자 하였다. 이를 위하여 사용자 감성 경험 연구(EUXR) 방법론을 적용하여 비목적성을 가진 대화를 20대 사용자를 대상으로 실험, 분석 하였다.AI 스피커 등이 지나치게 온라인 소비심리분석에 초점을 맞춘 자기화 서비스로 발전되고 있는 추세 속에서 발전된 AI 기술이 인간 자신의 삶에 도움이 되는 순수한 기능들도 개발되어 탑재할 수 있을 때 기술의 가치와 존재 이유가 더 탄탄하게 사람들의 삶에 자리 잡을 것으로 보인다는 관점에서 본 연구의 의의가 있다고 하겠다.","In this study, the research of user experience related to conversations with artificial intelligence which is reflected in the recent needs for voice-based interaction was performed. An AI system based on interactions between humans and an AI system that enables conversations such as AI speakers and AI mounted on smartphones was the subject of the experiment. Recently, in addition to the areas that were used in conventional computers or smartphones, such as the transfer of knowledge information and calculations, the emotional area through AI is being attempted with the development of big data deep learning technology.There was a process to find out the emotional connection with AI in the Korean-language conversations, as well as cultural qualities. To verify this, non-purpose conversations were tested and analyzed for users in their twenties by applying an emotional experience research methodology.Voice recognition technologies such as AI speakers are being developed as a self-contained service that focuses too much on online consumer psychological analysis, however, the significance of this study is from the point of view that values and reasons for the existence of technologies, which will be firmly established in people's lives if advanced AI technologies can also develop and install pure functions that help humans."
연관분석을 이용한 금융 상품 거래 동향의 빅데이터 분석,2021,"['Big data', 'Data analysis', 'Association analysis', 'Pattern analysis', 'Trading trend', '자기조직화지도', '클러스터링', '데이터마이닝', '아파트 가격', '부동산']","최근 인공지능, 딥러닝, 빅데이터 등 4차 산업의 핵심 분야에 대한 관심이 커지면서 기존의 의사결정 문제를 전통적인 방법론의 한계점을 최소화하는 과학적 접근 방식이 대두되고 있다. 특히 이런 과학적인 기법들은 주로 금융 상품의 방향성을 예측하는데 사용되는데 본 연구에서는 사회적으로 관심이 높은 아파트 가격의 요인을 자기조직화지도를 통해 분석하고자 한다. 이를 위해 아파트 가격의 실질 가격을 추출하고 아파트 가격에 영향을 주는 총 16개의 입력 변수를 선정한다. 실험 기간은 1986년 1월부터 2021년 6월까지이며 아파트 가격의 상승 및 횡보 구간을 나눠 각 구간 별 변수들의 특징을 살펴본 결과, 상승 구간과 횡보 구간의 입력 변수의 통계적 성향이 뚜렷하게 구분되는 것을 알 수 있었다. 더불어 U1~U3 구간이 N1~N3 구간에 비해서 변수들의 표준편차가 상대적으로 크게 나왔다. 본 연구는 중장기적으로 상승과 하락이라는 큰 주기를 갖고 있는 부동산에 대해서 현재 시점의 현황을 정량적으로 분석한 것에 의미가 있으며 향후 이미지 학습을 통해 미래 방향성을 예측하는 연구에 도움이 되기를 기대한다.","With the advent of the era of the fourth industry, more and more scientific techniques are being used to solve decision-making problems. In particular, big data analysis technology is developing as it becomes easier to collect numerical data. Therefore, in this study, in order to overcome the limitations of qualitatively analyzing investment trends, the association of various products was analyzed using associated analysis techniques. For the experiment, two experimental periods were divided based on the COVID-19 economic crisis, and sales information from individuals, institutions, and foreign investors was collected, and related analysis algorithms were implemented through r software. As a result of the experiment, institutions and foreigners recently invested in the KOSPI and KOSDAQ markets and bought futures and products such as ETF. Individuals purchased ETN and ETF products together, which is presumed to be the result of the recent great interest in sector investment. In addition, after COVID-19, all investors tended to be passive in investing in high-risk products of futures and options. This paper is thought to be a useful reference for product sales and product design in the financial field."
지능정보사회의 인공지능과 인권,2021,"['지능정보사회', '인공지능', '인권', '혁신', '유형', 'intelligent information society', 'artificial intelligence', 'human rights', 'innovation', 'type']","이 글은 지능정보사회에서 인공지능의 발전과 혁신에 따른 인권의 성찰을 추구한다. 지능정보사회는 빅데이터와 딥러닝을 기반으로 하는 인공지능기술을 핵심으로 한다. 지능정보사회는 정보통신기술을 활용한다는 점에서는 지식정보사회와 유사하지만, 기계학습을 통하여또 다른 지식을 생성하여 스스로 진화할 수 있는 인공지능기술의 혁신에 도달했다는 점에서다르다. 인공지능은 사람다운 삶을 구가할 수 있는 여유로운 시간과 공간을 창출할 수 있다.인간의 육체노동은 물론 정신노동까지 대체하는 기술의 구현이 가능해졌기 때문이다. 청소로봇은 가사를 도와주며, 사물인터넷 보안시스템은 안전한 생활을 보장해 준다. 무인자율자동차는 운전을 대행해 주고, 소셜로봇은 비서와 친구 역할을 수행한다. 이러한 인공지능의 유형에는 연결형, 융합형, 변환형이 있다. 연결형은 인간 보조적인 기능 중심의 약한 인공지능이며, 융합형은 인간 수준의 역할 수행이 가능한 강한 인공지능이고, 변환형은 자가학습 방식의 자율 진화가 가능한 인간을 넘어설 수 있는 초인공지능을 의미한다. 인공지능과 인권의 관계에서 연결형은 자유권과 평등권, 연대권을 침해할 가능성 낮으며, 융합형은 보통 이상의 침해가능성이 있고, 변환형은 비교적 높은 수준의 인권침해 가능성을 가진 것으로 판단할 수 있다.인공지능은 생활의 편리함과 고도의 안정성을 제공할 수 있다. 인공지능은 인간의 우연적 출신 요소들에 의한 차별과 격차를 크게 할 수도 있다. 인권을 신장하는 인간 친화적인 인공지능이 가능하도록 유념해야 할 시대이다.","This paper pursues to reflect on human rights according to development and innovation of artificial intelligence(AI). AI techniques are at the core of an intelligent information society based on big data and deep learning. An intelligent information society is similar to a knowledge information society in view of information communication technologies, but it is different from that it has a self evolution capability. AI makes for a comfortable time and space in behalf of a humanlike life because it is possible to embody substitute techniques for labors in body and soul. A clean robot assists housework, Internet of things security system guarantees a safe life, driverless autonomous vehicle drives a car replace for driver, and social robot takes a role of secretary and friend. Types of AI are connection, convergence, and transformation styles. A connection type is a weak AI for support for human, convergence type is a strong AI in level of human capacity, and transformation type is a super AI beyond human. In aspects of a violation of human rights, A connection type has low, convergence type has middle or more, and transformation type has high risks. AI can provide many utilities for decent lives and conveniences in elevated level, and cause discriminations and gaps originated in accidental elements. This time is a pivotal era for making human friendly AI."
온 디바이스 얼굴 라이트필드 합성 시스템,2021,"['Lightfield', 'multi-view synthesis', 'on-device', '3D modeling', 'Caffe', '라이트필드', '다중 뷰 합성', '온 디바이스', '3차원 모델링', 'Caffe']","본 논문에서는 온 디바이스 환경에서 단안의 얼굴 영상을 입력받아 라이트필드 영상을 합성하는 시스템을 제안한다. 제안하는 기법은 지도학습에서의 참값(ground truth) 얼굴 라이트필드 취득의 어려움을 극복하기 위해, 3차원 모델링 도구를 이용하여 다양한 얼굴에 대해 취득한 합성 라이트필드를 학습데이터로 이용한다. 또한, 온 디바이스 구현을 위해 네트워크 경량화 기법과 모바일에 최적화된 딥러닝 프레임워크를 사용한다. 제안하는 시스템은 취득한 라이트필드 영상에 적용될 수 있는 시점변환과 깊이추정 기능을 포함한다. 이를 위해, OpenCL기반 GPU 병렬처리를 적용하여 온 디바이스 환경에서 라이트필드 응용효과들이 신속히 처리될 수 있도록 하였다. 마지막으로, 본 논문은 제안하는 시스템을 GUI 프로그램으로 구현해 각 플랫폼에서의 동작결과 및 처리시간을 평가했다.","In this paper, we propose a light field synthesis system using a monocular facial image as input in an on-device environment. In order to overcome the difficulty of acquiring the ground truth facial light field in supervised learning, the proposed technique uses the synthesized light field acquired for various faces using a 3D modeling tool as learning data. In addition, a network compression method and mobile optimized deep learning framework are used for on-device implementation. The proposed system also includes viewpoint change and depth estimation functions that can be applied to the acquired light field image. For these, we apply OpenCL base GPU parallel processing so that these functions can be processed quickly in an on-device environment. Finally, this paper evaluates the operation results and processing time of our system implemented as GUI program on each platform."
인공지능(AI)을 활용한 한국어 듣기 교육 자료 제작 연구 -음성합성기술(TTS) 활용을 중심으로-,2021,"['인공지능', '한국어교육', '듣기 자료 평가', '음성합성', '교사 인식', 'Aartificial intelligence', 'AI', 'Korean education', 'Listening material assessment', 'Speech synthesis', 'Teachers’ perception']","최근 10년 사이 딥러닝 기술의 발전으로 인공지능(AI)의 성능은 크게 향상되었으며 관련 기술의 적용 범위도 여러 영역으로 확대되고 있다. 그러나 한국어교육에서의 이러한 최신기술 활용에 대한 연구는 미흡한 편이다. 따라서 본 연구에서는 TTS 시스템으로 제작한 음원의 교육적 활용 가능성을 탐색하고자 하였다. 우선 학습자를 대상으로 듣기 평가를 실시한 결과 전문 성우에 의해 녹음한 음원과 TTS 프로그램을 이용한 음원에는 유의미한 점수 차이가 없었다. 둘째, 한국어 교사를 대상으로 평가를 실시하였다. ‘발음’은 전반적으로 양호한 것으로 평가되었다. ‘억양 및 강세’는 화자의 감정을 비롯한 맥락 상황에 맞게 정교화 될 필요가 있으며  ‘시간 요인’은 대체적으로 자연스럽게 받아들여질 수 있으나 일부 문장에 대해서 어색하다고 지적했다. 셋째, STT 프로그램을 통해 제작한 음원의 정확도를 분석한 결과 96%로 음원의 발음은 대체로 명확하다고 평가할 수 있다. 종합적으로 TTS 시스템으로 제작한 음원을 평가한 결과 한국어교육 현장에서의 교육적 활용 가능성에 대해 긍정적으로 평가할 수 있다. 그러나 향후 TTS 프로그램의 활용 범위를 확대하기 위해서는 음원이 보다 실제성과 자연성을 확보할 수 있도록 지속적인 성능 개선 노력이 요구된다.","Although the scope of application of artificial intelligence(AI) related technologies has been expanding to various fields over the past decade, research on utilization in Korean language education has been minimal. Therefore, in this study, we sought to explore the educational use of listening material produced by the TTS program. First of all, as a result of the listening evaluation on learners, there was no significant difference between the sound source recorded by a professional voice actor and the listening material using the TTS program. Second, Listening materials were evaluated for Korean teachers. ‘Pronunciation’ could be considered good overall. 'Intonation and Accent' needs to be elaborated according to context of situations, including the speaker's feelings. and that ‘time factors’ can be accepted naturally in general, but some sentences were awkward. Third, after analyzing the accuracy of the listening material produced through the STT program, 96%, the pronunciation of the listening material was generally clear. Overall, the listening material produced by the TTS system has been evaluated in various ways, and the possibility of educational use in the Korean language education field can be evaluated positively. However, expanding the scope of the TTS program requires continuous performance improvement efforts."
"효율적인 웹 크롤링, 데이터 분석 및 시각화 서비스 연구",2021,"['웹 크롤링', '자연어 처리', '클러스터링', '시각화', 'Web Crawling', 'Natural Language Processing', 'Clustering', 'Visualization']","생활과 밀접한 서비스, 산업들뿐만 아니라 정보통신 산업을 비롯하여 기술과 거리가 멀다고 느껴졌던 농업까지 모든 산업에서 정보의 중요성은 점점 더 커지고 있다. 인터넷으로 정보를 검색하여 양질의데이터를 얻고 싶어 하지만, 다양한 사이트들을 방문해야 하고, 많은 양의 정보들을 일일이 재검색하거나 언어를 해독하여 그 관련성을 확인해야 하는 번거로움이 있기 때문에 정보를 검색하는데 그치지 않고, 관련성에 따라 이를 시각화까지 수행해주는 서비스가 필요하다. 본 연구에서는 크롤링한 데이터를가공하고, 자연어 처리를 통해 의미 있는 데이터로 추출한 후, 딥러닝 기반의 군집화 및 분류 과정을 수행한 후 그 결과를 다양한 시각화 기법을 적용하여 여러 가지 정보들을 한눈에 볼 수 있도록 하는 원스톱 서비스를 설계하고 구현한다.","The importance of information is increasing in all industries, from services and industries closely related to life, to the information and communication industry and agriculture, which seemed far from technology.A service that not only searches for information but also performs visualization according to relevance is needed, since there is a hassle of having to visit various sites, re-searching a large amount of information one by one or checking the relevance among data. In this study, we design and implement a one-stop service that enables various information can be viewed at a glance. After processing crawled data, we extract meaningful data through natural language processing, and conduct deep learning-based clustering and classification algorithm. Also, various visualization techniques are applied to the results."
이미지를 매개로 하는 멀티모달 반지도학습,2021,"['딥 러닝', '멀티모달 학습', '반지도학습', '가변 마진 랭킹 손실함수', '데이터 상호검색', 'deep learning', 'multimodal learning', 'half-supervised learning', 'versatile margin ranking loss', 'cross-modal retrieval']","멀티모달 데이터를 활용하는 학습 방법은 다양한 형태로 존재하는 데이터를 서로 연관 지어 상호검색을 위한 특징을 추출하거나, 다양한 형태의 데이터를 종합적으로 요구하는 새로운 태스크를 수행하기 위해 사용된다. 현재까지, 이미지와 텍스트 및 이미지와 소리 데이터 간의 멀티모달 학습을 수행하는 연구가 진행되어왔다. 이에 더 나아가, 본 논문에서는 이미지를 중심으로 소리 및 텍스트 데이터를 상호 고려하는 반지도학습 방법을 적용한 모델을 제시한다. 해당 모델은 이미지, 소리, 텍스트를 자유로이 수용하여 각각에 대한 특징을 추출할 수 있다. 덧붙여, 멀티모달 학습에 통상적으로 사용되는 단순 랭킹 손실함수의 한계점을 보완한, 마진값이 이미지 피처 간 유사도에 따라 변하는 가변 마진 랭킹 손실함수를 적용하여 모델을 학습시킨다. 최종적으로, 위 방법을 통해 학습한 모델의 표현력을 평가하기 위해, 제로-샷텍스트-비디오 검색 성능을 중심으로 이종 데이터 간 상호검색 성능을 정량적으로 분석한다.","Multimodal learning methods have been widely used to extract features from different modalities of data, targeting cross-modal retrieval or accomplishing novel tasks that require a comprehensive understanding of diverse modalities of data. Recent studies have focused on multimodal learning methods by correlating image-text or image-audio. In this paper, we propose a half-supervised learning procedure that alternatively feeds image-audio and image-text pairs. With this training strategy, the model can ingest and extract features from all the given modalities; image, text, and audio, using an image as a bridge. Furthermore, to overcome the limitation of vanilla ranking loss, we propose versatile margin ranking loss that scales the margin considering the similarity between image features. To evaluate the model""s representation quality with the proposed strategy, we analyze the quantitative results of cross-modal retrieval between different modalities, primarily focusing on zero-shot text-video retrieval."
다중 레이블 분류의 정확도 향상을 위한 스킵 연결 오토인코더 기반 레이블 임베딩 방법론,2021,"['딥 러닝', '다중 레이블 분류', '레이블 임베딩', '오토인코더', '스킵 연결', 'Deep Learning', 'Multi-Label Classification', 'Label Embedding', 'AutoEncoder', 'Skip-Connection']",,"Recently, with the development of deep learning technology, research on unstructured data analysis is being actively conducted, and it is showing remarkable results in various fields such as classification, summary, and generation. Among various text analysis fields, text classification is the most widely used technology in academia and industry. Text classification includes binary class classification with one label among two classes, multi-class classification with one label among several classes, and multi-label classification with multiple labels among several classes. In particular, multi-label classification requires a different training method from binary class classification and multi-class classification because of the characteristic of having multiple labels. In addition, since the number of labels to be predicted increases as the number of labels and classes increases, there is a limitation in that performance improvement is difficult due to an increase in prediction difficulty.  To overcome these limitations, (i) compressing the initially given high-dimensional label space into a low-dimensional latent label space, (ii) after performing training to predict the compressed label, (iii) restoring the predicted label to the high-dimensional original label space, research on label embedding is being actively conducted. Typical label embedding techniques include Principal Label Space Transformation (PLST), Multi-Label Classification via Boolean Matrix Decomposition (MLC-BMaD), and Bayesian Multi-Label Compressed Sensing (BML-CS). However, since these techniques consider only the linear relationship between labels or compress the labels by random transformation, it is difficult to understand the non-linear relationship between labels, so there is a limitation in that it is not possible to create a latent label space sufficiently containing the information of the original label. Recently, there have been increasing attempts to improve performance by applying deep learning technology to label embedding. Label embedding using an autoencoder, a deep learning model that is effective for data compression and restoration, is representative. However, the traditional autoencoder-based label embedding has a limitation in that a large amount of information loss occurs when compressing a high-dimensional label space having a myriad of classes into a low-dimensional latent label space.  This can be found in the gradient loss problem that occurs in the backpropagation process of learning. To solve this problem, skip connection was devised, and by adding the input of the layer to the output to prevent gradient loss during backpropagation, efficient learning is possible even when the layer is deep. Skip connection is mainly used for image feature extraction in convolutional neural networks, but studies using skip connection in autoencoder or label embedding process are still lacking.  Therefore, in this study, we propose an autoencoder-based label embedding methodology in which skip connections are added to each of the encoder and decoder to form a low-dimensional latent label space that reflects the information of the high-dimensional label space well. In addition, the proposed methodology was applied to actual paper keywords to derive the high-dimensional keyword label space and the low-dimensional latent label space. Using this, we conducted an experiment to predict the compressed keyword vector existing in the latent label space from the paper abstract and to evaluate the multi-label classification by restoring the predicted keyword vector back to the original label space.  As a result, the accuracy, precision, recall, and F1 score used as performance indicators showed far superior performance in multi-label classification based on the proposed methodology compared to traditional multi-label classification methods. This can be seen that the low-dimensional latent label space derived through the proposed methodology we"
외부 지식이 반영된 BERT를 활용한 검색 기반 대화 시스템,2021,"['딥 러닝', '자연어 처리', '검색 기반 대화 시스템', '사후 학습', '대화 응답 선택', 'deep learning', 'natural language processing', 'retrieval-based dialog system', 'BERT', 'post-training', 'response selection']","인간과 상호작용할 수 있는 대화시스템 개발은 인공지능 분야의 중요한 과제 중 하나이다. 이러한 문제를 해결하기 위해 대화 시스템에서 외부 지식을 활용하는 연구는 꾸준히 진행되어 왔다. 하지만 외부 지식을 학습하기 위해서는 구조화된 지식이 필요하며, 이를 생성하기 위해선 상당한 자원이 필요하다. 이러한 관점에서 본 연구는 검색 기반 대화 시스템에서 구조화 되지 않는 텍스트를 외부 지식으로 사용하는 모델을 제안한다. 기본 모델로 사전 학습된 언어 모델인 BERT를 사용하고 사후 학습을 통해 모델에 외부 지식을 학습시킨다. 이 후 사후 학습된 모델을 대화 응답 선택 태스크에 미세조정하여 문제를 해결한다. 기존 BERT 모델에 비해 외부 지식을 학습한 모델의 성능이 우분투 코퍼스에서 R10@1기준 1.3% 향상된 결과를 보였다.","Developing dialogue systems is a crucial aspect of artificial intelligence. Various studies have been advanced to improve the performance of the dialogue systems using external knowledge. However, well-structured external knowledge is required in order to be applied to the dialogue systems, and it needs a considerable amount of time and resources to be generated. From this point of view, this study proposes a model that uses unstructured texts as external knowledge for retrieval-based dialogue systems. We use a pre-trained language model, BERT as a base model for the response selection task, and then we train BERT with the external knowledge through post-training. Eventually, the post-trained model is fine-tuned for the dialogue response selection task. Compared to existing BERT models, the performance of the post-trained model with external knowledge is improved by 1.3% in R10@1 on ubuntu corpus."
Semi-Supervised Learning Exploiting Robust Loss Function for Sparse Labeled Data,2021,"['딥 러닝', '준 지도 학습', '데이터 증강', '강인 손실 함수', 'deep learning', 'semi-supervised learning', 'data augmentation', 'robust loss function']",,
다차원 색인 변조를 위한 신경망 기반 활성 안테나 추정을 통한 저복잡도 제로-포싱 검파기,2021,"['다중 안테나', '색인 변조', '딥 러닝', 'MIMO', 'Index Modulation', 'Deep Learning']",,
Ensemble Modeling with Convolutional Neural Networks for Application in Visual Object Tracking,2021,"['물체 추적 알고리즘', '딥 러닝', '앙상블 모델', '뉴럴 네트워크', '실시간 알고리즘', 'object tracking', 'deep learning', 'ensemble modeling', 'neural network', 'real-time algorithm']",,
SuperPoint-High Resolution Network (HRN); Interest Point Detection using HRNet,2021,"['수퍼포인트', '고해상도 신경망', '딥 러닝', '관심자 검출방법', 'SuperPoint', 'hig-resolution network', 'deep learning', 'Interest point detector']",,
다중 레이블 분류를 활용한 안면 피부 질환 인식에 관한 연구,2021,"['Deep Learning', 'Multi-Label Classification', 'Skin Diseases', '딥 러닝', '다중 레이블 분류', '피부 질환']",,"Recently, as people's interest in facial skin beauty has increased, research on skin disease recognition for facial skin beauty is being conducted by using deep learning. These studies recognized a variety of skin diseases, including acne. Existing studies can recognize only the single skin diseases, but skin diseases that occur on the face can enact in a more diverse and complex manner. Therefore, in this paper, complex skin diseases such as acne, blackheads, freckles, age spots, normal skin, and whiteheads are identified using the Inception-ResNet V2 deep learning mode with multi-label classification. The accuracy was 98.8%, hamming loss was 0.003, and precision, recall, F1-Score achieved 96.6% or more for each single class."
Automatic Segmentation of Lung Cancer in Chest CT Images through Capsule Network-based Dual-Window Ensemble Learning,2021,"['흉부 CT 영상', '폐암 분할', '캡슐 네트워크', '딥 러닝', 'chest CT images', 'lung cancer segmentation', 'capsule network', 'deep learning']",,
"19대 대선 TV토론에 대한 방송뉴스 영상의 균형성, 진실성 연구 : 심층학습 기반 동영상 처리 알고리즘을 통한 후보자들의 등장빈도, 표정, 응시방향 분석",2021,"['19대 대선', '선거보도', 'TV토론', '영상분석', '딥 러닝', '영상의 공정성', '균형성', '진실성', '19&lt', 'SUP&gt', 'th&lt', '/SUP&gt', 'Korean presidential election', 'TV debate', 'Visual analysis', 'Deep-learning', 'Visual bias', 'Visual truthfulness']",,
CNN(Convolutional Neural Network) 모델을 이용한 야구 경기 영상의 동작 분류 및 검색시스템,2021,"['Deep Learning', 'Convolutional Neural Network', 'Scene classification and retrieval', '딥 러닝', 'CNN 신경망', '영상 분류 및 검색']","본 연구에서는 CNN(Convolution Neural Network) 모델을 이용하여 야구 경기 영상에서 투구나 스윙과 같은 특정 영상이 출현하는 장면을 자동으로 분류하여 효과적으로 검색하는 방법을 제안한다. 또한, 특정 동작의 분류 결과와 경기 기록을 연계한 영상 장면 검색시스템을 제안한다. 제안 시스템의 효율성을 검정하기 위하여 2018년부터 2019년까지 진행된 한국프로야구 경기 영상을 대상으로 특정 장면별로 분류하는 실험을 진행하였다. 야구 경기 영상에서 투구 장면을 분류하는 실험에서는 경기별로 약 90%의 정확도를 보였다. 그리고 경기 영상 내에 포함된 스코어보드를 추출하여 경기 기록과 연계하는 영상 장면 검색 실험에서는 경기별로 약 80% 정도의 정확도를 보였다. 본 연구 결과는 한국프로야구 경기에서 과거 경기 영상을 체계적으로 분석하여 경기력 향상을 위한 전략 수립을 위하여 효과적으로 사용할 수 있으리라 기대한다.","In this paper, we propose a method to effectively search by automatically classifying scenes in which specific images such as pitching or swing appear in baseball game images using a CNN(Convolution Neural Network) model. In addition, we propose a video scene search system that links the classification results of specific motions and game records. In order to test the efficiency of the proposed system, an experiment was conducted to classify the Korean professional baseball game videos from 2018 to 2019 by specific scenes. In an experiment to classify pitching scenes in baseball game images, the accuracy was about 90% for each game. And in the video scene search experiment linking the game record by extracting the scoreboard included in the game video, the accuracy was about 80% for each game. It is expected that the results of this study can be used effectively to establish strategies for improving performance by systematically analyzing past game images in Korean professional baseball games."
A Study on an Evaluation of the Managed Residential Environment Improvement Project Using Deep-Learning Model,2021,"['Deep learning', 'Managed Residential Environment Improvement Project', 'Streetscape', 'Post-evaluation', 'Renewal Project', '딥 러닝', '관리형 주거환경개선사업', '가로경관', '사후평가', '정비사업']",,
Hybrid Feature Selection과 Data Balancing을 통한 효율적인 네트워크 침입 탐지 모델,2021,"['Intrusion Dectection', 'Deep Learning', 'Over Sampling', 'Feature Selection', '침입 탐지', '딥 러닝', '오버샘플링', '특징 선택']",,"Recently, attacks on the network environment have been rapidly escalating and intelligent. Thus, the signature-based network intrusion detection system is becoming clear about its limitations. To solve these problems, research on machine learning-based intrusion detection systems is being conducted in many ways, but two problems are encountered to use machine learning for intrusion detection. The first is to find important features associated with learning for real-time detection, and the second is the imbalance of data used in learning. This problem is fatal because the performance of machine learning algorithms is data-dependent. In this paper, we propose the HSF-DNN, a network intrusion detection model based on a deep neural network to solve the problems presented above. The proposed HFS-DNN was learned through the NSL-KDD data set and performs performance comparisons with existing classification models. Experiments have confirmed that the proposed Hybrid Feature Selection algorithm does not degrade performance, and in an experiment between learning models that solved the imbalance problem, the model proposed in this paper showed the best performance."
샴 네트워크 기반 객체 추적을 위한 표적 이미지 교환 모델,2021,"['Object tracking', 'Deep learning', 'Siamese network', 'Convolutional neural network', '객체 추적', '딥 러닝', '샴 네트워크', '컨볼루션 뉴럴 네트워크']",본 논문에서는 샴 네트워크 기반의 객체 추적 알고리즘의 성능 향상을 위한 표적 이미지 교환 모델을 제안한다. 샴 네트워크 기반의 객체 추적 알고리즘은 시퀀스의 첫 프레임에서 지정된 표적 이미지만을 사용하여 탐색 이미지 내에서 가장 유사한 부분을 찾아 객체를 추적한다. 첫 프레임의 객체와 유사도를 비교하기 때문에 추적에 한 번 실패하게 되면 오류가 축적되어 추적 객체가 아닌 부분에서 표류하게 되는 현상이 발생한다. 따라서 CNN(Convolutional Neural Network)기반의 모델을 설계하여 추적이 잘 진행되고 있는지 확인하고 샴 네트워크 기반의 객체 추적 알고리즘에서 출력되는 점수를 이용하여 표적 이미지 교환 시기를 정의하였다. 제안 모델은 VOT-2018 데이터 셋을 이용하여 성능을 평가하였고 최종적으로 정확도 0.611 견고도 22.816을 달성하였다.,"In this paper, we propose a target image exchange model to improve performance of the object tracking algorithm based on a Siamese network. The object tracking algorithm based on the Siamese network tracks the object by finding the most similar part in the search image using only the target image specified in the first frame of the sequence. Since only the object of the first frame and the search image compare similarity, if tracking fails once, errors accumulate and drift in a part other than the tracked object occurs. Therefore, by designing a CNN(Convolutional Neural Network) based model, we check whether the tracking is progressing well, and the target image exchange timing is defined by using the score output from the Siamese network-based object tracking algorithm. The proposed model is evaluated the performance using the VOT-2018 dataset, and finally achieved an accuracy of 0.611 and a robustness of 22.816."
Self-Attention을 적용한 문장 임베딩으로부터 이미지 생성 연구,2021,"['자연어 처리', '이미지 생성', '적대적 신경망', 'Natural Language Processing', 'Image generation', 'Generative Adversarial Network']","사람이 어떤 문장을 보고 그 문장에 대해 이해하는 것은 문장 안에서 주요한 단어를 이미지로 연상시켜 그 문장에 대해 이해한다. 이러한 연상과정을 컴퓨터가 할 수 있도록 하는 것을 text-to-image라고 한다. 기존 딥 러닝 기반 text-to-image 모델은 Convolutional Neural Network(CNN)-Long Short Term Memory(LSTM), bi-directional LSTM을 사용하여 텍스트의 특징을 추출하고, GAN에 입력으로 하여 이미지를 생성한다. 기존 text-to-image 모델은 텍스트 특징 추출에서 기본적인 임베딩을 사용하였으며, 여러 모듈을 사용하여 이미지를 생성하므로 학습 시간이 오래 걸린다. 따라서 본 연구에서는 자연어 처리 분야에서 성능 향상을 보인 어텐션 메커니즘(Attention Mechanism)을 문장 임베딩에 사용하여 특징을 추출하고, 추출된 특징을 GAN에 입력하여 이미지를 생성하는 방법을 제안한다. 실험 결과 기존 연구에서 사용되는 모델보다 inception score가 높았으며 육안으로 판단하였을 때 입력된 문장에서 특징을 잘 표현하는 이미지를 생성하였다. 또한, 긴 문장이 입력되었을 때에도 문장을 잘 표현하는 이미지를 생성하였다.","When a person sees a sentence and understands the sentence, the person understands the sentence by reminiscent of the main word in the sentence as an image. Text-to-image is what allows computers to do this associative process. The previous deep learning-based text-to-image model extracts text features using Convolutional Neural Network (CNN)-Long Short Term Memory (LSTM) and bi-directional LSTM, and generates an image by inputting it to the GAN. The previous text-to-image model uses basic embedding in text feature extraction, and it takes a long time to train because images are generated using several modules. Therefore, in this research, we propose a method of extracting features by using the attention mechanism, which has improved performance in the natural language processing field, for sentence embedding, and generating an image by inputting the extracted features into the GAN. As a result of the experiment, the inception score was higher than that of the model used in the previous study, and when judged with the naked eye, an image that expresses the features well in the input sentence was created. In addition, even when a long sentence is input, an image that expresses the sentence well was created."
Analyzing Correlations between Movie Characters Based on Deep Learning,2021,"['natural language processing', 'sentimental analysis', 'language style', 'movie scripts', 'LIWC', '자연어 처리', '감성 분석', '언어 스타일', '영화 대본']","인간은 사회적인 동물로서, 대화로써 정보를 얻거나 사회적인 교류를 해왔다. 대화는 두 사람 이상의 작은 모임에서 서로 말을 편하게 주고받는 것으로, 한 사람이 다른 사람에게 가지는 감성에 따라 그 말의 분위기가 달라질 수 있다. 영화에서 인물들과 인물들이 펼치는 이야기는 중요한 요소로 작용하며, 인물들 간의 관계는 이야기와 인물 간의 대사를 이해하는데 꼭 필요하다. 그러나 이런 정보를 영화에서 자동으로 추출하는 방법은 아직까지 연구되지 않아서 관객들에게 제공되고 있지 못하고 있다. 따라서, 영화 속 양상을 자동으로 분석하는 모델이 필요하다. 본 논문에서는 딥 러닝 기법을 활용하여 각 영화등장 인물들 간의 감성을 측정하여 영화 속 인물들 간의 관계를 효과적으로 분석하는 방법을 제안한다. 제안 방법은 먼저 영화 대본으로부터 주요 인물들을 추출하고, 주요 인물들 간의 대화를 효과적으로 찾는다. 그런 다음, 주요 인물들 간의 관계를 분석하기 위하여, 감성 분석을 수행하여 전체 시간 간격내 대사의 위치에 따라 가중치를 부여하고 점수를 수집한다. 또한, 실데이터를 이용한 실험을 통하여 제안 기법이 효과적으로 영화 등장 인물들 간의 감성을 분석할 수 있음을 보인다.","Humans are social animals that have gained information or social interaction through dialogue. In conversation, the mood of the word can change depending on the sensibility of one person to another. Relationships between characters in films are essential for understanding stories and lines between characters, but methods to extract this information from films have not been investigated. Therefore, we need a model that automatically analyzes the relationship aspects in the movie. In this paper, we propose a method to analyze the relationship between characters in the movie by utilizing deep learning techniques to measure the emotion of each character pair. The proposed method first extracts main characters from the movie script and finds the dialogue between the main characters. Then, to analyze the relationship between the main characters, it performs a sentiment analysis, weights them according to the positions of the metabolites in the entire time intervals and gathers their scores. Experimental results with real data sets demonstrate that the proposed scheme is able to effectively measure the emotional relationship between the main characters."
초ㆍ중등 AI 교육을 위한 데이터 리터러시 정의 및 구성 요소 연구,2021,"['SW/AI 교육', '정보교육', '데이터 리터러시', '데이터 교육', 'Word2Vec', 'SW/AI Education', 'Infomatics Education', 'Data Literacy', 'Data Education', 'Word2Vec']","AI 기술의 발달은 우리 삶의 큰 변화를 가져왔다. 생활에서부터 사회, 경제에 이르기까지 AI의 영향력이 커짐 에 따라 AI와 데이터 교육에 대한 중요성이 함께 커지고 있다. 이에 OECD 교육 연구 보고서 및 다양한 국내 정보과 교육과정 연구에서 데이터와 데이터 리터러시를 다루고 필수 역량으로 제시하고 있다. 하지만 국내외 관 련 연구를 살펴보면 데이터 리터러시에 대한 정의와 구성 요소의 내용과 범위가 연구자에 따라 다른 것을 알 수 있다. 이에 데이터 리터러시 관련 주요 연구의 정의와 구성 요소에 활용된 단어 빈도 분석과 함께 Word2Vec 딥 러닝 자연어 처리 방법을 통해 단어의 관계와 의미 유사도를 분석하여 객관적이고 포괄적인 정의와 구성 요소를 제시하였다. 그리고 전문가 검토를 통해 수정 보완하여 데이터 리터러시를 ‘문제를 해결하기 위해 데이터를 수집 하고 분석 및 활용하여 정보로 처리하는 지식 구성과 의사소통의 기초 능력’으로 정의하였으며, ‘지식, 기능, 가 치와 태도’로 각각의 구성 요소를 범주화하였다. 본 연구를 통해 도출된 데이터 리터러시의 정의와 구성 요소가 AI 교육 체계화와 학생들의 미래 역량 관련 교육 연구에 좋은 기초 자료가 될 수 있기를 기대한다.","The development of AI technology has brought about a big change in our lives. The importance of AI and data education is also growing as AI's influence from life to society to the economy grows. In response, the OECD Education Research Report and various domestic information and curriculum studies deal with data literacy and present it as an essential competency. However, the definition of data literacy and the content and scope of the components vary among researchers. Thus, we analyze the semantic similarity of words through Word2Vec deep learning natural language processing methods along with the definitions of key data literacy studies and analysis of word frequency utilized in components, to present objective and comprehensive definition and components. It was revised and supplemented by expert review, and we defined data literacy as the 'basic ability of knowledge construction and communication to collect, analyze, and use data and process it as information for problem solving'. Furthermore we propose the components of each category of knowledge, skills, values and attitudes. We hope that the definition and components of data literacy derived from this study will serve as a good foundation for the systematization and education research of AI education related to students' future competency."
인용·피인용 구절을 이용한 다주제 인용 분석 서비스 방법 연구,2021,"['Citing and Cited Phrases', 'Information Service', 'Citation Analysis', 'Citation Type', 'Citation Matching', '인용 구절', '정보 서비스', '인용 분석', '인용 유형', '인용 매칭']","인용 및 피인용 구절 분석은 정보 검색 위주의 단순 학술정보 서비스를 고도화시킬 기회를 제공한다. 그렇지만, 대부분의 연구가 커뮤니티, 연구자, 논문 간 인용 지수 중심의 분석에 초점을 맞추고 있어, 인용 구절 분석에 기반한 인용 기반 논문 정보 서비스를 제공하기에는 어려움이 있다. 본 연구는 “딥러닝”, “그린에너지”, “노령화”라는 세 개의 주제를 대상으로 논문 내 인용 구절 분석을 수행하고, 피인용 논문의 인용 특성을 구조적으로 설명한다. 이를 위해 구글 스칼라를 통해 각 주제에서 가장 많이 인용된 피인용 논문 각 네 편과 모든 인용 논문들을 수집하였으며, 이들을 대상으로 인용 유형 비율 분석과 인용 확산 분석을 수행하는 방식으로 피인용 논문 특성을 파악하고, 정보 서비스에 어떻게 반영할 수 있는지를 논하였다. 본 연구를 기반으로 다양한 인용 분석 연구와 정보 서비스가 개발될 수 있기를 기대한다.","The analysis of citing and cited phrases provides an opportunity to enhance search-centric academic information services. However, most current studies focus only on citation analysis among academic associations, researchers, and articles, making it challenging to develop higher citation-based information services. This study proposes citation analysis service methods using citing and cited phrases. First, to verify the feasibility of suggested services, we have collected the most highly cited articles with specific domain terms and followed their citing relationship; after that, we found formal citation types and ratios in the original articles. And we conducted structural analysis, especially with three topics, ""Deep Learning,"" ""Green Energy,"" and ""Aging,"" and then structurally illustrates the citation characteristics of related articles. Finally, we collected four most cited articles and all their citing ones for each subject from Google Scholar and analyzed the ratio of citation types and citation spread. We hope that various citation analysis studies and information services can be further developed based on our discussion for designing better information services."
토픽 모델링 기반의 국내외 공공데이터 연구 동향 비교 분석,2021,"['Public data', 'Research Trend', 'Text mining', 'Topic Modeling', 'LDA', '공공데이터', '연구 동향 분석', '텍스트 분석', '토픽 모델링', 'LDA']","최근 4차 산업혁명으로 빅데이터의 성장과 가치는 지속적으로 증가하고 있으며, 정부에서도 공공데이터 개방과 활용에 적극적으로 노력하고 있다. 하지만 여전히 시민들의 공공데이터 활용 요구수준에는 미치지 못하는 상황이며, 현 시점에서 공공데이터 분야의 연구동향 파악과 발전 방향을 모색할 필요가 있다. 이에 본 연구에서는 공공데이터와 관련된 연구 동향을 파악하기 위해서 텍스트 마이닝 기법에서 주로 활용되는 토픽 모델링을 활용하여 분석하였다. 이를 위해 국내외 학술논문 중 ‘공공데이터’, ‘Public Data'의 키워드가 포함된 논문(국내 1,437건, 국외 9,607건)을 수집하여 LDA 알고리즘 기반의 토픽 모델링을 수행하였으며, 국내외 공공데이터 연구 동향을 비교 분석하여 정책적 시사점을 제시하였다. 분석 결과 국내의 경우 공공분야 정책 연구가 주를 이루고 있으며, 국외는 의료, 건강 관련 연구가 높게 나타났다. 토픽별 시계열로 살펴보면 국내는 ‘개인정보보호’, ‘공공데이터 관리’, ‘도시 환경’ 분야의 연구가 증가하였으며, 국외는 ‘도시정책’, ‘세포 생물학’, ‘딥러닝’, ‘클라우드·보안’ 분야 연구가 활성화되고 있음을 확인할 수 있었다.","With the recent 4th Industrial Revolution, the growth and value of big data are continuously increasing, and the government is also actively making efforts to open and utilize public data. However, the situation still does not reach the level of demand for public data use by citizens, At this point, it is necessary to identify research trends in the public data field and seek directions for development. In this study, in order to understand the research trends related to public data, the analysis was performed using topic modeling, which is mainly used in text mining techniques. To this end, we collected papers containing keywords of ‘Public data' among domestic and foreign research papers (1,437 domestically, 9,607 overseas) and performed topic modeling based on the LDA algorithm, and compared domestic and foreign public data research trends. After analysis, policy implications were presented. Looking at the time series by topic, research in the fields of 'personal information protection', 'public data management', and 'urban environment' has increased in Korea. Overseas, it was confirmed that research in the fields of 'urban policy', 'cell biology', 'deep learning', and 'cloud · security' is active."
