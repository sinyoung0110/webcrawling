title,date,keywords,abstract,multilingual_abstract
ResNet-Variational AutoEncoder기반 변종 악성코드 패밀리 분류 연구,2021,"['변종 악성코드', '악성코드 분류', '변이 오토인코더', '전이학습', '앙상블 학습', 'Variant Malware', 'Malware Classification', 'Variational AutoEncoder', 'Tranfer Learning', 'Ensemble Learning']",전통적으로 대부분의 악성코드는 도메인 전문가에 의해 추출된 특징 정보를 활용하여 분석되었다. 하지만 이러한 특징 기반의 분석방식은 분석가의 역량에 의존적이며 기존의 악성코드를 변형한 변종 악성코드를 탐지하는 데 한계를 가지고 있다. 본 연구에서는 도메인 전문가의 개입 없이도 변종 악성코드의 패밀리를 분류할 수 있는 ResNet-Variational AutoEncder 기반 변종 악성코드 분류 방법을 제안한다. Variational AutoEncoder 네트워크는 입력값으로 제공되는 훈련 데이터의 학습 과정에서 데이터의 특징을 잘 이해하며 정규 분포 내에서 새로운 데이터를 생성하는 특징을 가지고 있다. 본 연구에서는 Variational AutoEncoder의 학습 과정에서 잠재 변수를 추출을 통해 악성코드의 중요 특징을 추출할 수 있었다. 또한 훈련 데이터의 특징을 더욱 잘 학습하고 학습의 효율성을 높이기 위해 전이 학습을 수행했다. ImageNet Dataset으로 사전학습된 ResNet-152 모델의 학습 파라미터를 Encoder Network의 학습 파라미터로 전이했다. 전이학습을 수행한 ResNet-Variational AutoEncoder의 경우 기존 Variational AutoEncoder에 비해 높은 성능을 보였으며 학습의 효율성을 제공하였다. 한편 변종 악성코드 분류를 위한 방법으로는 앙상블 모델인 Stacking Classifier가 사용되었다. ResNet-VAE 모델의 Encoder Network로 추출한 변종 악성코드 특징 데이터를 바탕으로 Stacking Classifier를 학습한 결과 98.66%의 Accuracy와 98.68의 F1-Score를 얻을 수 있었다.,"Traditionally, most malicious codes have been analyzed using feature information extracted by domain experts. However, this feature-based analysis method depends on the analyst's capabilities and has limitations in detecting variant malicious codes that have modified existing malicious codes. In this study, we propose a ResNet-Variational AutoEncder-based variant malware classification method that can classify a family of variant malware without domain expert intervention. The Variational AutoEncoder network has the characteristics of creating new data within a normal distribution and understanding the characteristics of the data well in the learning process of training data provided as input values. In this study, important features of malicious code could be extracted by extracting latent variables in the learning process of Variational AutoEncoder. In addition, transfer learning was performed to better learn the characteristics of the training data and increase the efficiency of learning. The learning parameters of the ResNet-152 model pre-trained with the ImageNet Dataset were transferred to the learning parameters of the Encoder Network. The ResNet-Variational AutoEncoder that performed transfer learning showed higher performance than the existing Variational AutoEncoder and provided learning efficiency. Meanwhile, an ensemble model, Stacking Classifier, was used as a method for classifying variant malicious codes. As a result of learning the Stacking Classifier based on the characteristic data of the variant malware extracted by the Encoder Network of the ResNet-VAE model, an accuracy of 98.66% and an F1-Score of 98.68 were obtained."
복소수 ResNet 네트워크 기반의 SAR 영상 물체 인식 알고리즘,2021,[],국문 초록 정보 없음,"Unlike optical equipment, SAR(Synthetic Aperture Radar) has the advantage of obtaining images in all weather, and object detection in SAR images is an important issue. Generally, deep learning-based object detection was mainly performed in real-valued network using only amplitude of SAR image. Since the SAR image is complex data consist of amplitude and phase data, a complex-valued network is required. In this paper, a complex-valued ResNet network is proposed. SAR image object detection was performed by combining the ROI transformer detector specialized for aerial image detection and the proposed complex-valued ResNet. It was confirmed that higher accuracy was obtained in complex-valued network than in existing real-valued network."
ResNet 정확도 향상을 위한 깊이별 Residual Connection 비율 조절 방법 제안,2021,"['ResNet', 'Residual Connection', 'Residual Learning', 'Variational Scaling', 'Degradation']","ResNet은 residual learning으로 학습 최적화를 용이하게 만들어 gradient vanishing과 상관없이 신경망이 깊어질 때 성능이 하락하는 degradation 문제를 해결한다. 하지만 기존 ResNet에서는 모든 residual block에 동일한 비율로 residual connection을 적용하여 residual learning의 최적화 효과를 극대화하지 못하는 한계가 있다. 따라서 본 논문에서는 residual learning의 최적화 효과를 극대화하기 위해 깊이 별 residual connection 비율을 달리하여 ResNet 정확도를 향상시키는 variational scaling 방법을 제안한다. 성능을 검증하기 위해 두가지 다른 데이터셋인 CIFAR-10과 CIFAR-100에서 다른 깊이를 갖는 ResNet-32, ResNet-56를 사용해 실험을 수행한다. 실험 결과 모든 케이스에서 기존 ResNet과 비교하여 연산량 증가 없이 정확도 향상을 이룬다.","ResNet resolves a degradation problem by residual learning which allows ease to the learning optimization. However, original ResNet has such a limitation that do not maximize the optimization of residual learning by applying residual connections with the constant scale. This paper suggests a variational scaling method that adjusts scales of residual connection by depth in order to maximize the optimization effect of residual learning hence to enhance the model accuracy. Experiments are conducted in two different datasets CIFAR-10 and CIFAR-100, and with 2 models with different depth, ResNet –32 and ResNet-56. As the result of experiments, the variational scaling method enhanced accuracy without the computational amount increased compared to the original ResNet in all cases."
ResNet-합성곱 오토인코더 기반 신경망을 이용한 스펙트럼 데이터 압축,2021,"['Data Compression', 'PCA', 'Autoencoder', 'ResNet', 'Raman Spectrum']","본 논문에서는 스펙트럼 저장 시 데이터용량을 줄이기 위해 합성곱 오토인코더(convolutional autoencoder) 구조에 ResNet(Residual Neural Network) 알고리즘을 적용한 스펙트럼 데이터 압축 신경망을 제안한다. 최근 분광법(spectroscopy)의 적용 분야가 넓어짐에 따라 스펙트럼 데이터베이스가 대용량화되어 효율적인 전송이 어렵고 많은 저장 공간을 필요로 한다. 이러한 대용량의 데이터베이스를 효율적으로 관리하기 위해 데이터 압축을 수행한다. 기존 데이터 압축에 주로 사용되는 PCA(Principal Component Analysis)는 주성분의 개수에 따라 압축률이 결정된다. 주성분 개수가 적을수록 압축률은 높아지지만 정보 손실이 보다 쉽게 발생하기 복원 시 원본 데이터와의 크게 오차가 발생한다. 이러한 한계점을 극복하기 위해 본 논문에서는 제안한 신경망인 CAER(Convolutional AutoEncoder+ResNet)을 통하여 데이터 압축을 수행하였다. 신경망 학습은 실제 스펙트럼 데이터를 묘사하여 생성한 모의실험 데이터를 통해 수행하였다. CAER 신경망의 성능 검증을 위해 라만 스펙트럼을 PCA와 신경망을 통하여 75%, 87.5%, 93.75%의 압축률로 압축과 복원을 수행한 후 각각의 결과를 비교 분석하였다. 원본과 복원 데이터의 오차 비교를 하였을 때 CAER 신경망은 PCA보다 평균 94.2%의 낮은 오차를 보인다. 이 결과를 통해 CAER 신경망이 스펙트럼 데이터 압축에 효과적으로 적용될 수 있음을 확인하였다.","In this paper, we propose a spectrum compression neural network that applied the ResNet (Residual Neural Network) algorithm to the convolutional autoencoder structure to reduce data capacity requirement in storing the spectrum. Recently, as the field of application of spectroscopy widens, the spectrum database is becoming larger, making efficient transmission difficult and requiring large amount of storage. Therefore, data compression is performed to manage large amounts of data efficiently. In PCA (Principal Component Analysis), which is mainly used for data compression, the compression ratio is determined by the number of principal components. As the number of principal components decreases, the compression rate increases, but at the same time, it is easier for information loss to occur. Hence, errors occur between reconstruction and the raw spectrum. To overcome these limitations, we perform compression through the proposed CAER (Convolutional AutoEncoder+ResNet) network. The training of the network was performed through simulated data describing the real spectrum. To verify the performance of the CAER network, the Raman spectrum was compressed and reconstructed at compression rates of 75%, 87.5%, and 93.75% through the PCA and CAER networks. Comparing the errors between raw and reconstructed data, the CAER network shows an average error of 94.2% lower than that of the PCA. The results obtained confirm that the CAER network can be effectively applied to spectrum compression."
ResNet과 Unet을 결합한 딥러닝 모델을 이용한 분광 신호에서 ROI 검출,2021,"['Peak Detection', 'Region of Interest', 'Deep Learning', 'CNN', 'Raman Spectroscopy']","본 연구에서는 딥러닝 기술(deep learning technology)을 이용하여 분광 신호의 ROI(region of interest)를 찾는 방법을 제안한다. 제안한 방법은 모의실험 데이터로 학습된 딥러닝 모델을 이용하여 분광 신호의 ROI를 검출하는 방법이다. 분광 신호의 피크는 물질의 물리 화학적인 정보를 포함하고 있으므로 정확한 피크 검출은 분석 시스템의 성능에 영향을 미치는 중요한 과정이다. 지금까지 가장 많이 사용되는 방법은 진폭을 기반으로 피크 검출을 진행하는 것이다. 하지만 이런 방법들은 전처리 과정을 포함하거나 분광 신호에 따라 파라미터를 육안 검사로 선택하여 추정하므로 복잡하고 주관적이다. 이러한 문제점 개선을 위해 딥러닝 모델을 통해 분광 신호의 ROI 검출을 수행하였다. 제안한 방법은 전처리 과정이 없고 파라미터를 설정하지 않아도 되는 장점을 갖는다. 또한 검출한 ROI에 따라 분광 신호에 후처리(post-processing)를 수행하여 피크를 얻을 수 있다. 디폴트 손실 함수에 3만개 테스트 데이터를 적용하여 얻은 손실값을 통해 성능 평가를 수행하였다. 제안된 ResNet과 Unet을 결합한 딥러닝 모델은 일반적인 컨볼루션 신경망(CNN: Convolutional Neural Network), ResNet, 그리고 Unet에 비해 각각 76.5%, 69.8%, 5.9%의 성능 향상을 보였으며, 실제 라만 분광 신호의 ROI 검출에도 효과적으로 적용될 수 있음을 확인하였다.","This study proposes a method to find the ROI (region of interest) of spectral signals using deep learning technology. The proposed method detects the ROI of spectral signals using a deep learning model trained with simulated data. Since the peak of the spectral signal contains physical and chemical information of the substance, accurate peak detection is an important process affecting the performance of the analyzed system. The widely used method for peak detection is the one based on the amplitude. However, this method is complex and subjective because it involves pre-processing or select and estimate parameters using visual inspection according to spectral signals. To overcome this problem, ROI detection of the spectral signal was performed through a deep learning model. The proposed method has the advantage of requiring no pre-processing and parameter setting. In addition, a peak may be obtained by performing post-processing of the spectral signal according to the detected ROI. Performance evaluation was performed through loss values obtained by applying 30,000 test data to the custom loss function. The proposed deep learning model combining ResNet and Unet showed performance improvements of 76.5%, 69.8%, and 5.9% compared to the general convolutional neural network (CNN), ResNet, and Unet, respectively. It was also confirmed that the proposed method could be effectively applied to measured spectral signals."
Distribution Analysis of Feature Map and Gradients in Mobilenet and Resnet Model Layers using Glorot and He`s initialization,2021,"['가중치 초기화', 'Glorot 초기화', 'He 초기화', '컨볼루션 신경망 네트워크', '잡초 분류', 'Weights initialization', 'Glorot initialization', 'He initialization', 'Convolutional neural network', 'Weeds classification']",국문 초록 정보 없음,"Initializing the weights plays an essential role in a convolutional neural network model. This paper investigates how Glorot and Hes initialization methods behave in Mobilenet and Resnet models on the weeds classification problem. Experiments show that pointwise and depthwise convolution in Mobilenet reduces the variance of feature maps from earlier layers. Using the He’s method, shortcut connection in Resnet saturate values in logistic classify layer. The accuracy of Mobilenet and Resnet, using Glorots method, are 0.9568 and 0.9711, respectively. While using Hes method, we obtain 0.9471 using Mobilenet and 0.9645 using Resnet. Also, both models converge faster and better generalization using Glorots method than using Hes method."
"Resnet 알고리즘을 이용한 1차, 2차 단락흔 판별",2021,[],"전기 화재현장에서 확보된 단락흔을 통하여 전기 화재 발생 원인을 판별하기 위한 연구를 진행하였다. 1,2차 단락흔 판별을 위해 Resnet 알고리즘을 제안하고 검증하였다. 학습을 위한 데이터는 Hiv 전선의 1, 2차 단락흔 시료를 현미경으로 촬영하고 학습 데이터와 검증 데이터로 확보하였다. Resnet기법을 활용하여 오차를 줄이기 위해 신경망의 파라미터를 학습하는 것과는 다르게 입력과 출력의 차이를 이용하는 잔차 학습(Residual learning)을 도입함으로써, 더욱 깊은 네트워크층을 사용하여 효율적으로 학습 가능한 구조를 나타내고 있다. 분석결과 Resnet 판별 정확도는 88.2%로 각각 얻었다.",다국어 초록 정보 없음
ResNet을 이용한 도로 네트워크 교통 데이터 예측,2021,"['합성곱 신경망', '잔차 학습', '전이 학습', '교통 속도 예측', 'Convolutional Neural Network', 'Residual Learning', 'ResNet', 'Transfer Learning', 'Traffic Speed Prediction']",국문 초록 정보 없음,다국어 초록 정보 없음
ResNet50을 이용한 냉연강판에서의 표면결함 자동분류,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
ResNet을 이용한 도로 네트워크 교통 데이터 예측,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
SegNet과 ResNet을 조합한 딥러닝에 기반한 횡단보도 영역 검출,2021,"['Deep Learning', 'Semantic Segmentation', 'Zebra-crossing Detection', 'Neural Network', '딥러닝', '시맨틱 분할', '횡단보도 검출', '신경 네트워크']",국문 초록 정보 없음,다국어 초록 정보 없음
Tiny-YOLOv3와 ResNet50을 이용한 실시간 마스크 표정인식,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
SSD ResNet기반 Take-out컵 자동분리수거함,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
CWRU 데이터셋을 이용한 ResNet기반의 베어링 결함 진단 모델 구현,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
학습 데이터 사진 보정을 통한 GPU 기반의 소형 무선 임베디드 궤륜 차량의 Resnet18 을 이용한 자율주행 성능 개선,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
스펙트럼 첨도를 이용한 ResNet 기반의 표적 분류 성능 분석,2021,[],국문 초록 정보 없음,"Micro-Doppler modulation is a target signature that represents micro-motion state for each individual movement, it is used in the technology of recognizing and classifying targets. The micro-Doppler frequency appears in the form of transition of the Doppler frequency by basic movement characteristics such as rotation and vibration of an object, and thus it can make it possible to track a target and classify it with high recognition accuracy. In this paper, we extract the micro-Doppler feature vector of the target by calculating the spectral kurtosis of micro-Doppler images according to drone, bird, and human targets. To classify targets performing micro-movement, we apply ResNet deep neural network to spectral kurtosis input. Through simulation, we analyze the classification performance of ResNet algorithm according to the radar measurement data input set of each target."
미세 도플러 영상을 이용한 ResNet 기반의 표적 분류 성능 분석,2021,[],"미세 도플러 (micro-Doppler) 변조는 각 개체의 구분 및 각각의 움직임에 대한 미세한 운동 상태를 나타내는 표적 특징으로서, 표적을 인식하고 분류하는 기술에 활용되고 있다. 미세 도플러 주파수는 물체의 회전과 진동 등의 기본적인 운동 특징에 의한 도플러 주파수의 변조 형태로 나타나며, 이를 이용하면 높은 표적 인식 정확도로 표적을 추적하고 분류할 수 있다. 본 논문에서는 드론, 조류, 사람 표적에 따른 미세 운동 신호를 모델링하고, 미세 도플러 영상을 통해 시간-주파수 영역에서 분석하여 표적의 미세 도플러 특징을 확인한다. 그리고 서로 다른 미세 운동을 하는 표적을 분류하기 위해 미세 도플러 영상을 입력으로 하는 ResNet 심층학습 알고리즘을 적용한다. 모의실험을 통해 각 표적의 레이더 실측 데이터 입력 세트에 따른 ResNet 알고리즘의 분류 성능을 분석한다.",다국어 초록 정보 없음
단락흔 및 용융흔 판별을 위한 CNN과 Resnet 알고리즘 비교 분석,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
Res-DualNet: Dual-Path Depthwise 컨볼루션 기반 ResNet 네트워크 경량화 연구,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
운전자의 주의분산 연구동향 및 딥러닝 기반 동작 분류 모델,2021,"['Driver’s Behavior', 'Driver’s Distraction', 'Behavior Recognition', 'ResNet-101', 'CAM', '운전자의 동작', '운전자의 주의 분산', '동작 인식']","본 논문에서는 운전자의 주의산만을 유발하는 운전자, 탑승자의 동작을 분석하고 핸드폰과 관련된 운전자의 행동 10가지를 인식하였다. 먼저 주의산만을 유발하는 동작을 환경 및 요인으로 분류하고 관련 최근 논문을 분석하였다. 분석된 논문을 기반으로 주의산만을 유발하는 주요 원인인 핸드폰과 관련된 10가지 운전자의 행동을 인식하였다. 약 10만 개의 이미지 데이터를 기반으로 실험을 진행하였다. SURF를 통해 특징을 추출하고 3가지 모델(CNN, ResNet-101, 개선된 ResNet-101)로 실험하였다. 개선된 ResNet-101 모델은 CNN보다 학습 오류와 검증 오류가 8.2배, 44.6배가량 줄어들었으며 평균적인 정밀도와 f1-score는 0.98로 높은 수준을 유지하였다. 또한 CAM(class activation maps)을 활용하여 딥러닝 모델이 운전자의 주의 분산 행동을 판단할 때, 핸드폰 객체와 위치를 결정적 원인으로 활용했는지 검토하였다.","In this paper, we analyzed driver""s and passenger""s motions that cause driver""s distraction, and recognized 10 driver""s behaviors related to mobile phones. First, distraction-inducing behaviors were classified into environments and factors, and related recent papers were analyzed. Based on the analyzed papers, 10 driver""s behaviors related to cell phones, which are the main causes of distraction, were recognized. The experiment was conducted based on about 100,000 image data. Features were extracted through SURF and tested with three models (CNN, ResNet-101, and improved ResNet-101). The improved ResNet-101 model reduced training and validation errors by 8.2 times and 44.6 times compared to CNN, and the average precision and f1-score were maintained at a high level of 0.98. In addition, using CAM (class activation maps), it was reviewed whether the deep learning model used the cell phone object and location as the decisive cause when judging the driver""s distraction behavior."
Identification of Indian butterflies using Deep Convolutional Neural Network,2021,"['Indian butterfly identification', 'ButterflyNet', 'Butterfly', 'classification CNN', 'Computer vision']",국문 초록 정보 없음,"The conventional butterfly identification method is based on their different morphological characters namely wing-venation, color, shape, patterns and through the dissection studies and molecular techniques which are tedious, expensive and highly time-consuming. To overcome the above aforesaid challenges, a new butterfly identification system using butterfly images has been designed to instantly identify the butterfly with high ac curacy. In this study, we construct a new butterfly dataset with 34,024 butterfly images belonging to 315 species from India. We propose and prove the effectiveness of new data augmentation techniques on our dataset. To identify butterflies using photographic images, we built eleven new Deep Convolutional Neural Network (DCNN) butterfly classifier models using eleven pre-trained architectures namely ResNet-18, ResNet-34, ResNet-50, ResNet-121, ResNet-152, Alex-Net, DenseNet-121, DenseNet-161, VGG-16, VGG-19 and SqueezeNet-v1.1. The different model’s classification results were compared and the proposed technique achieved a maximum top-1 accuracy(94.44%), top-3 accuracy(98.46%) and top-5 accuracy(99.09%) using ResNet-152 model, followed by DenseNet-161 model achieved the top-1 accuracy(94.31%), top-3 accuracy (98.07%) and top-5 accuracy (98.66%). The results suggest that models can be assertively used to identify butterflies in India."
딥러닝과 의미론적 영상분할을 이용한 자동차 번호판의 숫자 및 문자영역 검출,2021,"['딥러닝', '합성곱 신경망(CNN)', '의미론적 분할', '자동차 번호판', '영상분할 및 인식', 'Deep Learning', 'Convolution Neural Network(CNN)', 'Semantic Segmentation', 'License Plate', 'Image Segmentation and Recognition']","자동차 번호판 인식은 지능형 교통시스템에서 핵심적인 역할을 담당한다. 따라서 효율적으로 자동차 번호판의 숫자 및 문자영역을 검출하는 것은 매우 중요한 과정이다. 본 연구에서는 딥러닝과 의미론적 영상분할 알고리즘을 적용 하여 효과적으로 자동차 번호판의 번호영역을 검출하는 방법을 제안한다. 제안된 방법은 화소 투영과 같은 전처리과정 없이 번호판 영상에서 바로 숫자 및 문자영역을 검출하는 알고리즘이다. 번호판 영상은 도로 위에 설치된 고정 카메라로 부터 획득한 영상으로 날씨 및 조명변화 등을 모두 포함한 다양한 실제 상황에서 촬영된 것을 사용하였다. 입력 영상은 색상변화를 줄이기 위해 정규화하고 실험에 사용된 딥러닝 신경망 모델은 Vgg16, Vgg19, ResNet18 및 ResNet50이 다. 제안방법의 성능을 검토하기 위해 번호판 영상 500장으로 실험하였다. 학습을 위해 300장을 할당하였으며 테스트용 으로 200장을 사용하였다. 컴퓨터모의 실험결과 ResNet50을 사용할 때 가장 우수하였으며 95.77% 정확도를 얻었다.","License plate recognition plays a key role in intelligent transportation systems. Therefore, it is a very important process to efficiently detect the number and character areas. In this paper, we propose a method to effectively detect license plate number area by applying deep learning and semantic image segmentation algorithm. The proposed method is an algorithm that detects number and text areas directly from the license plate without preprocessing such as pixel projection. The license plate image was acquired from a fixed camera installed on the road, and was used in various real situations taking into account both weather and lighting changes. The input images was normalized to reduce the color change, and the deep learning neural networks used in the experiment were Vgg16, Vgg19, ResNet18, and ResNet50. To examine the performance of the proposed method, we experimented with 500 license plate images. 300 sheets were used for learning and 200 sheets were used for testing. As a result of computer simulation, it was the best when using ResNet50, and 95.77% accuracy was obtained."
사과 품종 분류를 위한 CNN기반 모델링 및 분류 기법 연구,2021,"['스마트팜', '딥러닝', 'ResNet', '신경망', 'Smart Farm', 'Deep Learning', 'ResNet', 'Convolution Neural Network']","농장주들이 과일을 분류하는 데까지의 시간소모를 줄이고 향후 과일의 등급 판정 기준을 정량화하기 위하여 우리나라의 대표적인 과일이며 다양한 품종을 가지고 있는 사과를 대상으로 신경망 기반 분류 자동화 시스템을 제안한다. 컨베이어 벨트를 통해 지나가는 객체를 카메라모듈로 촬영하여 이를 통신 및 연산을 수행하는 라즈베리파이 기반 시스템을 설계, 구현한다. 깊은 네트워크와 나머지(residual)를 학습하는 ResNet 기반 알고리즘이 구동되는 딥러닝 서버와는 SSH통신을 통해 이미지와 학습된 모델을 주고받는다. 향후 품종뿐만 아니라 등급까지 분류 자동화한다면 다양한 품종의 과일을 대상으로 한 출하 자동화 시스템으로의 적용이 가능하다.","This paper propose a neural network-based classification automation system for apples, which are representative fruits of Korea and have a variety of varieties, in order to reduce the consumption of time for farmers to classify fruits and to quantify the criteria for grading the fruits. Raspberry Pi-based system that communicates and performs calculations by photographing objects passing through a conveyor belt with a camera module is designed and implemented. Then it receive the trained model using ResNet-based algorithm that runs on the deep-learning server. In the future, if classifying not only varieties but also grades is automated, it can be applied as a shipping automation system targeting various varieties of fruit."
Black Pine Bast Scale Detection using Deep Learning,2021,"['Convolutional neural network', 'Deep learning', 'RetinaNet', 'ResNet101', 'Pest detection model']",국문 초록 정보 없음,"Pests play a major role in depletion of the agricultural resources. The pest detection can help to prevent the depletion. Even though there is a huge development in technologies, the current farm management devices and methods do not meet the required level to detect the precise pests in the farms and forests. Moreover, in practice, most of the pest detection methods are conventional in nature and depend on the professional workers. The drawbacks of the conventional methods are high cost, time consuming, knowledge dependency of the professional workers, etc. To overcome these drawbacks, a deep learning based pest detection model has been developed to detect the pest. In our research, the key focus is to detect the black pine bast scale. The pheromone traps are used to lure these pests. In order to capture the pheromone trap images effectively, an image capture set up has been developed. It is helpful in solving the problems such as non-uniform image capturing distance and the reflection caused by the outer vinyl present in the pheromone trap. In this experiment, the smartphone Huawei P30 Pro model is used to capture the images. In order to obtain better result from the captured smartphone images, the images were cropped into image segments. These image segments are given as input for the deep learning models. The pre-trained models used in this experiment are Fast-RCNN, Faster-RCNN, and RetinaNet. The ResNet50, ResNet101, and ResNext101 are used as the backbone layers. Among these developed model combinations, RetinaNet ResNet101 with a combination of the FPN as the backbone layer attains the highest F1 score of 0.78. Hence, this model can be used for automatic detection of black pine bast scale pests attached to the pheromone traps. Then, an image stitching algorithm is used to merge the image segments. Finally, a smartphone application is developed for Black Pine Bast Scale detection."
Transfer Learning Using Convolutional Neural Network Architectures for Glioma Classification from MRI Images,2021,"['Brain Tumor', 'Deep Learning', 'High-Grade Glioma', 'Low-Grade Glioma', 'MRI', 'ResNet']",국문 초록 정보 없음,"Glioma is one of the common types of brain tumors starting in the brain's glial cell. These tumors are classified into low-grade or high-grade tumors. Physicians analyze the stages of brain tumors and suggest treatment to the patient. The status of the tumor has an importance in the treatment. Nowadays, computerized systems are used to analyze and classify brain tumors. The accurate grading of the tumor makes sense in the treatment of brain tumors. This paper aims to develop a classification of low-grade glioma and high-grade glioma using a deep learning algorithm. This system utilizes four transfer learning algorithms, i.e., AlexNet, GoogLeNet, ResNet18, and ResNet50, for classification purposes. Among these algorithms, ResNet18 shows the highest classification accuracy of 97.19%."
The Classification of EEG-based Wink Signals: A CWT-Transfer Learning Pipeline,2021,"['BCI', 'CWT', 'EEG', 'Transfer Learning', 'SVM']",국문 초록 정보 없음,"Brain–Computer Interface technology plays a vital role in facilitating post-stroke patients’ ability to carry out their daily activities of living. The extraction of features and the classification of electroencephalogram (EEG) signals are pertinent parts in enabling such a system. This research investigates the efficacy of Transfer Learning models namely ResNet50 V2, ResNet101 V2, and ResNet152 V2 in extracting features from CWT converted wink-based EEG signals, prior to its classification via a fine-tuned Support Vector Machine (SVM) classifier. It was shown that ResNet152 V2-SVM pipeline could achieve an excellent accuracy on all train, test and validation datasets."
Application of convolutional neural networks for distal radio-ulnar fracture detection on plain radiographs in the emergency room,2021,"['Wrist', 'Fractures', 'bone', 'Deep learning', 'Neural networks', 'computer']",국문 초록 정보 없음,"Objective Recent studies have suggested that deep-learning models can satisfactorily assist in fracture diagnosis. We aimed to evaluate the performance of two of such models in wrist fracture detection. Methods We collected image data of patients who visited with wrist trauma at the emergency department. A dataset extracted from January 2018 to May 2020 was split into training (90%) and test (10%) datasets, and two types of convolutional neural networks (i.e., DenseNet-161 and ResNet-152) were trained to detect wrist fractures. Gradient-weighted class activation mapping was used to highlight the regions of radiograph scans that contributed to the decision of the model. Performance of the convolutional neural network models was evaluated using the area under the receiver operating characteristic curve. Results For model training, we used 4,551 radiographs from 798 patients and 4,443 radiographs from 1,481 patients with and without fractures, respectively. The remaining 10% (300 radiographs from 100 patients with fractures and 690 radiographs from 230 patients without fractures) was used as a test dataset. The sensitivity, specificity, positive predictive value, negative predictive value, and accuracy of DenseNet-161 and ResNet-152 in the test dataset were 90.3%, 90.3%, 80.3%, 95.6%, and 90.3% and 88.6%, 88.4%, 76.9%, 94.7%, and 88.5%, respectively. The area under the receiver operating characteristic curves of DenseNet-161 and ResNet-152 for wrist fracture detection were 0.962 and 0.947, respectively. Conclusion We demonstrated that DenseNet-161 and ResNet-152 models could help detect wrist fractures in the emergency room with satisfactory performance."
장면 복잡도 기반 적응적 얼굴 마스크 탐지 모델,2021,"['인공지능', '딥러닝', '기계학습', '객체 감지', '마스크 감지', '코로나바이러스-19', 'Artificial intelligence', 'Machine learning', 'Object detection', 'Deep learning', 'Mask detection', 'COVID-19']","코로나바이러스-19(COVID-19)의 대유행에 따라 전 세계 수많은 확진자가 발생하고 있으며 국민을 불안에 떨게 하고 있다. 바이러스 감염 확산을 방지하기 위해서는 마스크를 제대로 착용하는것이 필수적이지만 몇몇 사람들은 마스크를 쓰지 않거나 제대로 착용하지 않고 있다. 본 논문에서는 영상 이미지에서의 효율적인 마스크 감지 시스템을 제안한다. 제안 방법은 우선 입력 이미지의 모든 얼굴의 영역을 YOLOv5를 사용하여 감지하고 감지된 얼굴의 수에 따라 3가지의 장면복잡도(Simple, Moderate, Complex) 중 하나로 분류한다. 그 후 장면 복잡도에 따라 3가지ResNet(ResNet-18, 50, 101) 중 하나를 기반으로 한 Faster-RCNN을 사용하여 얼굴 부위를 감지하고마스크를 제대로 착용하였는지 식별한다. 공개 마스크 감지 데이터셋을 활용하여 실험한 결과 제안한 장면 복잡도 기반 적응적인 모델이 다른 모델에 비해 가장 성능이 뛰어남을 확인하였다.","Coronavirus disease 2019 (COVID-19) has affected the world seriously. Every person is required for wearing a mask properly in a public area to prevent spreading the virus. However, many people are not wearing a mask properly. In this paper, we propose an efficient mask detection system. In our proposed system, we first detect the faces of input images using YOLOv5 and classify them as the one of three scene complexity classes (Simple, Moderate, and Complex) based on the number of detected faces. After that, the image is fed into the Faster-RCNN with the one of three ResNet (ResNet-18, 50, and 101) as backbone network depending on the scene complexity for detecting the face area and identifying whether the person is wearing the mask properly or not. We evaluated our proposed system using public mask detection datasets. The results show that our proposed system outperforms other models."
User Interface Application for Cancer Classification using Histopathology Images,2021,"['Deep Learning', 'Histopathology images', 'ResNet-34', 'Digital Pathology', 'AI', 'CAD']",국문 초록 정보 없음,"User interface for cancer classification system is a software application with clinician's friendly tools and functions to diagnose cancer from pathology images. Pathology evolved from manual diagnosis to computer-aided diagnosis with the help of Artificial Intelligence tools and algorithms. In this paper, we explained each block of the project life cycle for the implementation of automated breast cancer classification software using AI and machine learning algorithms to classify normal and invasive breast histology images. The system was designed to help the pathologists in an automatic and efficient diagnosis of breast cancer. To design the classification model, Hematoxylin and Eosin (H&E) stained breast histology images were obtained from the ICIAR Breast Cancer challenge. These images are stain normalized to minimize the error that can occur during model training due to pathological stains. The normalized dataset was fed into the ResNet-34 for the classification of normal and invasive breast cancer images. ResNet-34 gave 94% accuracy, 93% F Score, 95% of model Recall, and 91% precision."
Jetson 임베디드 보드에서 도커 컨테이너를 사용한 연합 학습 기반 이미지 분류,2021,"['federated learning', 'image classification', 'Resnet 18', 'jetson embedded boards', 'docker container']",국문 초록 정보 없음,"In this research, we have studied a federated learning-based image classification algorithm. In this regard, we have used Resnet18 classifier as a backbone deep learning algorithm for image classification. The training process of this algorithm involved federated learning, such as training is performed at multiple clients (Jetson Nano and TX2) and is averaged at the server (Jetson Xavier). We have exploited the Nvidia Docker container image to deploy our algorithms for the training process. For our experiments, we have used only two clients and one server during the training process of the Resnet18 image classifier. The extension of the CIFAR10 (50K to 500K samples) dataset has been used for training, known as EC10, which contained 1000 subsets for IID client distribution. We have validated the accuracy for both using the federated learning process and traditional training at several strategies and have presented the results correspondingly."
텍스타일 디자인 분류 및 관심 영역 도출에 대한 연구,2021,"['텍스타일 디자인 분류', '관심 영역 도출', 'Textile design', 'VGG-16', 'ResNet-34', 'LIME', 'region of interest']","디자인에 있어서 유사한 디자인들을 그룹핑하여 분류하는 것은 관리적인 측면에서 효율성을 높여주고 사용적인 측면에서는 편의성을 제공한다. 본 연구는 인공지능 알고리즘을 이용하여 텍스타일 디자인을 도트, 꽃무늬, 줄무늬, 그리고 기하학으로 4개의 카테고리로 분류하고자 하였다. 특히, 인공지능의 관점에서 분류의 근거가 되는 관심 영역을 찾아내고 설명할 수 있는 지를 탐색하였다. 총 4,536개의 디자인을 8:2의 비율로 무작위 추출하여 학습용 데이터 3,629개와 테스트용 데이터 907개로 구성하였다. 분류에 사용된 모델은 VGG-16과 ResNet-34로 두 모델의 꽃무늬 디자인에 대한 정밀도는 각각 0.79%, 0.89%이며, 재현율은 0.95%, 0.38%로 우수한 분류 성과를 보였다. LIME(Local Interpretable Model-agnostic Explanation) 기법을 이용하여 분석한 결과에 따르면, 기하학과 꽃무늬 디자인의 경우 도형과 꽃잎 부분이 분류의 근거가 되는 관심 영역으로 도출되었다.","Grouping and classifying similar designs in design increase efficiency in terms of management and provide convenience in terms of use. Using artificial intelligence algorithms, this study attempted to classify textile designs into four categories: dots, flower patterns, stripes, and geometry. In particular, we explored whether it is possible to find and explain the regions of interest underlying classification from the perspective of artificial intelligence. We randomly extracted a total of 4,536 designs at a ratio of 8:2, comprising 3,629 for training and 907 for testing. The models used in the classification were VGG-16 and ResNet-34, both of which showed excellent classification performance with precision on flower pattern designs of 0.79%, 0.89% and recall of 0.95% and 0.38%. Analysis using the Local Interpretable Model-agnostic Explanation (LIME) technique has shown that geometry and flower-patterned designs derived shapes and petals from the region of interest on which classification was based."
공연예술에서 광고포스터의 이미지 특성을 활용한 딥러닝 기반 관객예측,2021,"['공연예술', '흥행 예측', 'CNN', 'VGG-16', 'Inception-v3', 'ResNet50', 'Performing Arts', 'Box Office Prediction']","공연예술 기관에서의 공연에 대한 흥행 예측은 공연예술 산업 및 기관에서 매우 흥미롭고도 중요한 문제이다. 이를 위해 출연진, 공연장소, 가격 등 정형화된 데이터를 활용한 전통적인 예측방법론, 데이터마이닝 방법론이 제시되어 왔다. 그런데 관객들은 공연안내 포스터에 의하여 관람 의도가 소구되는 경향이 있음에도 불구하고, 포스터 이미지 분석을 통한 흥행 예측은 거의 시도되지 않았다. 그러나 최근 이미지를 통해 판별하는 CNN 계열의 딥러닝 방법이 개발되면서 포스터 분석의 가능성이 열렸다. 이에 본 연구의 목적은 공연 관련 포스터 이미지를 통해 흥행을 예측할 수 있는 딥러닝 방법을 제안하는 것이다. 이를 위해 KOPIS 공연예술 통합전산망에 공개된 포스터 이미지를 학습데이터로 하여 Pure CNN, VGG-16, Inception-v3, ResNet50 등 딥러닝 알고리즘을 통해 예측을 수행하였다. 또한 공연 관련 정형데이터를 활용한 전통적 회귀분석 방법론과의 앙상블을 시도하였다. 그 결과 흥행 예측 정확도 85%를 상회하는 높은 판별 성과를 보였다. 본 연구는 공연예술 분야에서 이미지 정보를 활용하여 흥행을 예측하는 첫 시도이며 본 연구에서 제안한 방법은 연극 외에 영화, 기관 홍보, 기업 제품 광고 등 포스터 기반의 광고를 하는 영역으로도 적용이 가능할 것이다.","The prediction of box office performance in performing arts institutions is an important issue in the performing arts industry and institutions. For this, traditional prediction methodology and data mining methodology using standardized data such as cast members, performance venues, and ticket prices have been proposed. However, although it is evident that audiences tend to seek out their intentions by the performance guide poster, few attempts were made to predict box office performance by analyzing poster images. Hence, the purpose of this study is to propose a deep learning application method that can predict box office success through performance-related poster images. Prediction was performed using deep learning algorithms such as Pure CNN, VGG-16, Inception-v3, and ResNet50 using poster images published on the KOPIS as learning data set. In addition, an ensemble with traditional regression analysis methodology was also attempted. As a result, it showed high discrimination performance exceeding 85% of box office prediction accuracy. This study is the first attempt to predict box office success using image data in the performing arts field, and the method proposed in this study can be applied to the areas of poster-based advertisements such as institutional promotions and corporate product advertisements."
웹 크롤링을 통한 해양쓰레기 이미지 데이터세트 구축 및 Faster R-CNN 모델을 이용한 해양쓰레기 검출,2021,"['web crawling', 'object detection', 'Faster R-CNN', 'MobileNet', 'ResNet']",본 논문에서는 웹 크롤링을 통해 해양쓰레기 이미지 데이터셋을 구축한다. 또한 이를 이용해 Faster R-CNN 모델을 훈련시켜 이미지에서 해양쓰레기를 감지하는 능력을 평가한다. 이를 위해 웹 크롤링을 통해 바다에서 자주 발견되는 쓰레기 이미지를 Google에서 수집하고 레이블을 지정하여 훈련 데이터세트를 구축한다. 그리고 Faster R-CNN의 backbone 네트워크를 각각 MobileNet과 ResNet으로 구성한다. 마지막으로 구축한 데이터세트으로부터 두 개의 Faster R-CNN 모델을 학습하여 각 모델의 해양쓰레기의 탐지 성능을 평가한다.,"In this paper, a marine debris image dataset is constructed through web crawling. Also, the Faster R-CNN model is trained to detect marine debris in the image. To this end, images of garbage frequently found in the ocean are collected from Google through web crawling. We also label them to build a marine debris image dataset. And then, two Faster R-CNN models are constructed whose backbone network is chosen as MobileNet and ResNet, respectively. Finally, we evaluate the detection performance of marine debris by training the Faster R-CNN model using dataset."
Automated detection of corrosion in used nuclear fuel dry storage canisters using residual neural networks,2021,"['Convolutional neural networks', 'Corrosion', 'Deep learning', 'Dry storage canisters', 'Feature detection', 'Residual neural networks']",국문 초록 정보 없음,"Nondestructive evaluation methods play an important role in ensuring component integrity and safety in many industries. Operator fatigue can play a critical role in the reliability of such methods. This is important for inspecting high value assets or assets with a high consequence of failure, such as aerospace and nuclear components. Recent advances in convolution neural networks can support and automate these inspection efforts. This paper proposes using residual neural networks (ResNets) for real-time detection of corrosion, including iron oxide discoloration, pitting and stress corrosion cracking, in dry storage stainless steel canisters housing used nuclear fuel. The proposed approach crops nuclear canister images into smaller tiles, trains a ResNet on these tiles, and classifies images as corroded or intact using the per-image count of tiles predicted as corroded by the ResNet. The results demonstrate that such a deep learning approach allows to detect the locus of corrosion via smaller tiles, and at the same time to infer with high accuracy whether an image comes from a corroded canister. Thereby, the proposed approach holds promise to automate and speed up nuclear fuel canister inspections, to minimize inspection costs, and to partially replace human-conducted onsite inspections, thus reducing radiation doses to personnel."
A comparative study of fine-tuning deep learning models for apple and pear disease recognition,2021,"['CNN', 'Deep learning', 'Disease classification', 'Fire blight', 'Fine-tuning']",국문 초록 정보 없음,"As there is no cure for fire blight, which mainly affects pears and apples, effective and rapid detection is very important. Existing fire blight diagnostic studies usually used biotechnology, such as immunodiagnostic kits. With the development of deep learning-based image recognition technology, an image-based fire blight diagnosis method has been proposed. For the diagnosis of diseases that have similar symptoms, including fire blight, this study developed a disease recognition model using the deep convolutional neural network (CNN). Fine-tuning was performed on VGG16, VGG19, ResNet50, DenseNet121, Inception-ResNet v2, NASNet and EfficientNet models, which were pre-trained through ImageNet dataset. The experiment used 14,304 images of six diseases collected from pear and apple as the dataset. As a result of the experiment, all seven fine-tuned models achieved an accuracy of more than 90%, among which the ResNet50 model achieved the highest accuracy at 98.83%. It is anticipated that the proposed model can be valuably used at actual farmhouses to diagnose and prevent fire blight through appropriate services in the future."
심층 신경망 기반 객체 인식 기법의 유사 객체 분류 성능 분석,2021,"['Deep Neural Networks', 'ResNet', 'DenseNet', 'Smart Factory', 'Armored Fighting Vehicle']",국문 초록 정보 없음,"In this study, deep neural networks were applied to a similar object classification method, and the classification performance was analyzed. For the similar object classification performance analysis, ResNet50 and DenseNet169 models, which are known to show similar behaviors, were selected. To verify the performance of these deep neural networks, a bolt recognition for smart factories and an armored fighting vehicle recognition were performed. In addition, image preprocessing methods to improve the similar object classification performance were proposed. The experimental results confirmed that appropriate image preprocessing methods should be applied according to the type of similar object to be classified."
전이 학습을 이용한 얼굴 감정 인식 비전 기반 딥러닝 알고리즘 비교 연구,2021,"['face emotion recognition', 'MobileNetv2', 'GoogleNet', 'VGGNet19', 'ResNet19', 'Deep Emotion']",국문 초록 정보 없음,"In this research, we have explored state-of-the-art deep learning algorithms for face emotion recognition. In this regard, we utilize a transfer learning technique for recognizing seven classes of emotions using image classifiers such as MobileNetv2, GoogleNet, ResNet101, VGGNet19. In addition, we also compared our results with a specially designed deep learning model for face emotion recognition such as “Deep Emotion”. We have utilized the dataset FER2013 exploited by many researchers. We have analyzed the accuracy, time of training, complexity in terms of layers, and other parameters. After training on FER2013, we have deployed each model on a Korean dataset obtained from Korean dramas videos containing images of celebrities. Our ultimate goal was to label all unknown Korean dataset after training on FER2013. We have presented three different programs, i.e. (i) automatic labeling, (ii) transfer learning-based models for unknown images, (iii) deep-emotion model for face emotion recognition. We have presented a detailed analysis of all models and our corresponding programs."
평활화 알고리즘에 따른 자궁경부 분류 모델의 성능 비교 연구,2021,"['Cervical cancer', 'Histogram equalization', 'Classification', 'ResNet-50']",국문 초록 정보 없음,"We developed a model to classify the absence of cervical cancer using deep learning from the cervical image to which the histogram equalization algorithm was applied, and to compare the performance of each model. A total of 4259 images were used for this study, of which 1852 images were normal and 2407 were abnormal. And this paper applied Image Sharpening(IS), Histogram Equalization(HE), and Contrast Limited Adaptive Histogram Equalization(CLAHE) to the original image. Peak Signal-to-Noise Ratio(PSNR) and Structural Similarity index for Measuring image quality(SSIM) were used to assess the quality of images objectively. As a result of assessment, IS showed 81.75dB of PSNR and 0.96 of SSIM, showing the best image quality. CLAHE and HE showed the PSNR of 62.67dB and 62.60dB respectively, while SSIM of CLAHE was shown as 0.86, which is closer to 1 than HE of 0.75. Using ResNet-50 model with transfer learning, digital image-processed images are classified into normal and abnormal each. In conclusion, the classification accuracy of each model is as follows. 90.77% for IS, which shows the highest, 90.26% for CLAHE and 87.60% for HE. As this study shows, applying proper digital image processing which is for cervical images to Computer Aided Diagnosis(CAD) can help both screening and diagnosing."
Comparison of PoseNet Architectures for an AIoT Edge Device,2021,"['AIoT', 'Edge Device', 'MobileNet v1', 'PoseNet', 'ResNet-50']",국문 초록 정보 없음,"Unlike typical computer environments, Edge Devices have strict requirements such as very low latency and very high reliability. Due to these limitations, environmental improvement algorithms such as delay and reliability must be improved. Therefore, as a preliminary study to solve this problem, we confirm the performance of PoseNet architecture for AIoT Edge Device. AIoT Edge Device uses Google Coral USB Accelerator and Raspberry Pi 4 that support PoseNet, and is implemented through an algorithm that automatically detects the Google Coral USB Accelerator connected to the USB hub and checks the performance of pose estimation against inference time. Through the experi-mental results, the inference time of PoseNet architectures MobileNet v1 and ResNet-50 and the estimation probability of pose score were confirmed, and FPS(Frames Per Second) performance according to the video resolution was confirmed."
웹 검색을 이용한 새 품종 분류를 위한 전이학습에 대한 연구,2021,"['deep learning', 'transfer learning', 'bird breed recognition', 'web crawling', 'ResNet50', 'ImageNet']",국문 초록 정보 없음,"Recently, research on image recognition and object extraction has been actively carried out through deep learning. In addition, research on transfer learning, which is used for new neural network learning by maintaining or partially changing the neural network function of a deep learning model pre-trained in a specific field, is also being actively conducted. However, although a large number of datasets are required for image learning, it is difficult to obtain desired quantities of images. In this paper, a large number of images were collected through Google and bird-related professional website crawling for bird breed classification, and images that can be used for learning were selected through various preprocessing. Then, using the ResNet50 model pre-trained with ImageNet, fine-tuning transfer learning was performed to classify bird breeds. In addition, the trained model was tested using the CUB_200-2011 data set, which is a data set for classifying new breeds, and the reliability of the search image was obtained with an accuracy of 87.87%."
"딥러닝 경량화를 위한 구조, 가지치기, 지식증류 비교",2021,"['Deep learning', 'Structure Reduction', 'Pruning', 'Knowledge Distillation', 'CIFAR10/100', 'ResNet56/110']",국문 초록 정보 없음,"We compare three approaches of structure reduction, pruning, and knowledge distillation for lightning of a deep learning network. Structure reduction eliminates a set of layers of the model, but pruning deletes filters within a layer. Knowledge distillation effectively learns a small student model from a large teacher model using KL Divergence. Therefore, it has a similar effect of reduction of the model. The above three methods for lightning are rarely compared to each other in terms of performance. To compare these approaches for network reduction problem, we investigate the accuracy and flops of the methods on CIFAR10 and CIFAR100 data for ResNet models. A systematic analysis for the fundamental orientations and differences of each method is supplemented."
"시간별 가속도, 소음 데이터를 이용한 CNN기반 조향작동소음 예측모델 개발",2021,"['Electric Power Steering(전동식 조향장치)', 'Noise Prediction(소음예측)', 'Regression AI Model(회귀 인공지능 모델)', 'Spectrogram(스펙트로그램)', 'CNN Resnet(CNN Resnet모델)', 'Accerlerometer(가속도 센서)']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝 기반의 소비자 데이터를 응용한 외식업체 추천 시스템 구현에 관한 연구,2021,"['추천 시스템', '인공지능', '딥러닝', '분류', '감성 분석', '외식업체', 'Recommendation System', 'Artificial Intelligence', 'Deep Learning', 'Classification', 'Sentiment Analysis', 'Restaurant']",본 연구에서는 소비자 데이터를 딥러닝 기반의 분류(Classification) 모델을 학습 시켜 추천 알고리즘을 구현하였다. 이를 위하여 사용자 데이터를 이미지로 변환 시켜 분류 과제에서 보편적으로 사용되는 ResNet50을 사용하여 학습한 결과로서 유의미한 결과에 대하여 제시함,"In this study, a recommendation algorithm was implemented by learning a deep learning-based classification model for consumer data. For this purpose, a meaningful result is presented as a result of learning using ResNet50, which is commonly used in classification tasks by converting user data into images."
전이학습 기반의 해충 영상 분류 성능 비교,2021,"['Pest Classification', 'Deep Learning', 'CNN', 'Transfer Learning']","수많은 종류의 해충은 종류에 따라 물리적인 피해, 작물 수확의 피해 그리고 생태계 보전 가치를 해치는 피해를 준다. 하지만 해충은 작고 비슷하게 생겨 전문가가 아닌 사람이 육안으로 해충의 종류를 알고 분류하기란 쉽지 않다. 따라서 본 논문은 해충 영상을 분류를 위해 6개의 딥러닝 모델 ResNet50, VGG16, SqueezeNet, FPN(Feature Pyramid Network), Attention Gated Network, PVT(Pyramid Vision Transformer)의 분류 성능에 대한 비교 분석을 하려 한다 이를 통해 해충 영상 분류에 가장 우수한 모델을 찾아 해충의 종류에 따른 적합한 방제 시스템을 구축하고자 한다.","Numerous types of pests cause physical damage, damage to crop harvest, and damage that harms ecosystem conservation value depending on the type. However, since the pests are small and similar, it is not easy for non-experts to recognize and classify the types of pests with the naked eye. Therefore, this paper want to perform a comparative analysis on the classification performance of six deep learning models ResNet50, VGG16, SqueezeNet, FPN(Feature Pyramid Network), Attention Gated Network, and PVT(Pyramid Vision Transformer) to classify pest images. Through this, we want to find the best model for pest image classification and build an appropriate control system according to the pest type."
CNN에서 비슷한 깊이의 레이어를 묶는 그룹 필터 프루닝 기법,2021,[],국문 초록 정보 없음,"Filter pruning is considered one of the most effective methods. It is divided into local filter pruning and global filter pruning, and both methods have drawbacks. In this letter, we address the shortcomings of the two methods, by proposing a method of grouping some layers and then pruning them in groups. We conduct extensive experiments with VGG16 and ResNets on CIFAR-10, CIFAR-100, CUB-200-2011 and MIT-indoor datasets to validate the effectiveness of our filter pruning method. For CIFAR-100, our method decreases FLOPs by more than 52% on ResNet-110 with a 0.03% accuracy increase, which outperforms state-of- the art filter pruning methods."
영상 콘텐츠의 오디오 분석을 통한 메타데이터 자동 생성 방법,2021,"['Audio', 'AI', 'Metadata', 'Recommendation System', 'Voice Recognition']","영상 콘텐츠를 사용자에게 추천하기 위해서는 메타데이터가 필수적인 요소로 자리 잡고 있다. 하지만 이러한 메타데이터는 영상 콘텐츠 제공자에 의해 수동적으로 생성되고 있다. 본 논문에서는 기존 수동으로 직접 메타데이터를 입력하는 방식에서 자동으로 메타데이터를 생성하는 방법을 연구하였다. 기존 연구에서 감정 태그를 추출하는 방법에 추가로 영화 오디오를 통한 장르와 제작국가에 대한 메타데이터 자동 생성 방법에 대해 연구를 진행하였다. 전이학습 모델인 ResNet34 인공 신경망 모델을 이용하여 오디오의 스펙트로그램으로부터 장르를 추출하고, 영화 속 화자의 음성을 음성인식을 통해 언어를 감지하였다. 이를 통해 메타데이터를 생성 인공지능을 통해 자동 생성 가능성을 확인할 수 있었다.","A meatadata has become an essential element in order to recommend video content to users. However, it is passively generated by video content providers. In the paper, a method for automatically generating metadata was studied in the existing manual metadata input method. In addition to the method of extracting emotion tags in the previous study, a study was conducted on a method for automatically generating metadata for genre and country of production through movie audio. The genre was extracted from the audio spectrogram using the ResNet34 artificial neural network model, a transfer learning model, and the language of the speaker in the movie was detected through speech recognition. Through this, it was possible to confirm the possibility of automatically generating metadata through artificial intelligence."
Implementation and Performance Evaluation of Farm Waste Image Classification System using CNN-based Transfer Learning Models,2021,"['Artificial intelligence', 'Transfer-learning', 'CNN', 'Image classification', 'Farm waste collection']","영농 폐기물의 증가로 인해, 빠르고 효율적으로 수거할 수 있는 스마트 영농 폐기물 모니터링 시스템 개발이 필요하다. 본 논문에서는 영농 폐기물 분류 시스템을 제안하고 실제 지역 농촌에서 직접 수집한 영상을 이용하여 CNN 기반의 전이학습 모델들을 구현하고 비교하였다. 영농 폐기물 영상 분류에 적합한 모델과 학습 조건을 찾기 위해, 3가지의 학습 자료군 구성 조건 (2종 분류, 6종 분류, 6종 하위분류를 가진 2종 분류)을 달리하여 미세 조정된 6개의 사전 훈련 CNN 모델들의 검증 정확도를 비교하였다. 그 결과, ResNet-50 모델의 성능이 모든 학습 조건에서 평균 90.9%의 정확도로 가장 높았고, 폐기물 영상을 6종 분류했을 때보다 2종 분류로 했을 때의 검증 정확도가 10% 더 높았다. 특히, 학습 자료군 구성 방법 중 6종 하위분류를 가진 2종 분류했을 때의 검증 정확도는 2종 분류했을 때와 유사했다. 이를 통해 영농 폐기물은 한 종류만 모여 있지 않을뿐더러 다양한 폐기물들이 한데 섞여 있어서 영농 폐기물의 특정한 세부 종류로 분류하는 것보다 폐기물인지 아닌지를 이진 분류하는 것이 더 효과적임을 확인하였다. 나아가, 제안된 시스템의 동작을 확인하기 위해, 영농 환경 모니터링 서버와 영농 폐기물 영상 분류 서버 사이에 TCP / IP 기반의 통신 환경을 구축하고, 모의실험을 통해 구현한 영농 폐기물 영상 분류 시스템이 스마트 영농 폐기물 모니터링 시스템으로 사용될 가능성을 확인하였다. 본 연구의 결과는 정형화되지 않거나 여러 병변이 혼합된 의료 영상을 분류하는 경우에도 활용될 수 있을 것이다.","Due to the increase of farm waste in many countries, there’s a need to develop a smart farm waste monitoring system that can collect it promptly and efficiently. In this paper, we proposed, compared the performance of a convolutional neural network (CNN) -based transfer learning models and implement a farm waste image classification system, which is crucial component for the monitoring system. To find an appropriate model and labelling methods for farm waste image classification, we compared each validation accuracy of six different pre-trained CNN methods with three types of labelling scheme, using the waste images taken directly from the farming area. As a result, the ResNet-50 model performed best with an accuracy of 90.9% on average. Also, when classified into 2 categories, the accuracy was about 10% higher than that of the 6 categories. Furthermore, when the image was classified into 2 main categories with 6 sub-categories, the validation accuracy was similar to that of the 2 categories. Through these results, it seemed to be more effective to classify with binary labels such as ‘trash’ and ‘non-trash’, rather than with multiple labels of specific categories because farm waste is generated not only by single type of waste but also by various types of mixed waste. And a TCP / IP based communication environment between farm environment monitoring server and farm waste image classification server has been implemented. Experimental results using the system implemented for a smart farm waste monitoring showed that the proposed system can be used for a smart farm waste collection system. Also, the result of this study could be applied to classify medical images of unstructured and/or mixed lesion."
Five-Class Classification of Cervical Pap Smear Images: A Study of CNN-Error-Correcting SVM Models,2021,"['Cervix Uteri', 'Diagnosis', 'Nerve Net', 'Papanicolaou Test', 'Support Vector Network']",국문 초록 정보 없음,"Objectives: Different complex strategies of fusing handcrafted descriptors and features from convolutional neural network(CNN) models have been studied, mainly for two-class Papanicolaou (Pap) smear image classification. This paper explores asimplified system using combined binary coding for a five-class version of this problem. Methods: This system extracted featuresfrom transfer learning of AlexNet, VGG19, and ResNet50 networks before reducing this problem into multiple binarysub-problems using error-correcting coding. The learners were trained using the support vector machine (SVM) method. The outputs of these classifiers were combined and compared to the true class codes for the final prediction. Results: Despitethe superior performance of VGG19-SVM, with mean ± standard deviation accuracy and sensitivity of 80.68% ± 2.00% and80.86% ± 0.45%, respectively, this model required a long training time. There were also false-negative cases using both theVGGNet-SVM and ResNet-SVM models. AlexNet-SVM was more efficient in terms of running speed and prediction consistency. Our findings also showed good diagnostic ability, with an area under the curve of approximately 0.95. Further investigationalso showed good agreement between our research outcomes and that of the state-of-the-art methods, with specificityranging from 93% to 100%. Conclusions: We believe that the AlexNet-SVM model can be conveniently applied for clinicaluse. Further research could include the implementation of an optimization algorithm for hyperparameter tuning, as well asan appropriate selection of experimental design to improve the efficiency of Pap smear image classification."
고무제품 혼련 공정에서의 CNN기반 품질 지표 예측 모델 개발,2021,"['CNN', 'Mixing Process', 'Quality Indicator Prediction', 'Time Series Data']","고무 제품의 제조를 위한 공정 중 혼련 공정은 믹서에 원료와 배합제를 투입하여 혼합하는 공정이다. 대부분의 기업에서는 숙련된 작업자의 암묵지를 활용하여 재료의 투입 순서와 시간을 결정하며 이는 공정의 신뢰도와 품질의 균일성을 저해한다. 이를 체계화하기 위해 본 연구에서는 믹서의 온도, 전압, 램(Ram) 개폐 여부 등의 시계열 데이터에서 고무 물성을 예측할 수 있는 모델을 제안한다. 예측 정확도를 높이기 위해 합성곱 레이어의 다층 쌓기에 유리한 Residual Neural Network(ResNet)을 구축하였으나 검증 오차가 낮아지지 않는 문제가 발생하였다. 이에 본 연구에서는 레이어의 수를 역으로 줄이는 모델을 개발하였는데, 이 모델은 3개의 레이어로 구성된 1차원 Convolution Neural Network(CNN)이며, Zero-padding의 문제점을 개선한 Symmetric-padding을 적용하였다. 이러한 방법의 적용은 CNN과 ResNet34를 결합한 모델의 학습속도를 개선하고 검증 오차를 약 4% 감소시킬 수 있었다. 본 논문의 연구결과를 통하여 고무혼련공정 및 유사 공정의 품질 지표 예측모델의 다른 접근법에 대한 기초연구결과를 제공해줄 수 있을 것으로 기대한다.",다국어 초록 정보 없음
Detection of surface roughness of mechanical drawings with deep learning,2021,['· Mechanical drawings · Image analysis · Object detection · Image recognition · Deep learning models · Evaluation metrics'],국문 초록 정보 없음,"Engineering drawing inspection is important to CAD modeling of mechanical parts. Traditional inspection methods mainly rely on manual analysis by using the CAD software, which requires expert knowledge and massive time. In view of simplifying the analysis for non-experts and improving detection efficiency and accuracy, this study proposes a generic approach combining object detection and image recognition methods to identify surface roughness of mechanical drawings. For both the object detection and image recognition methods, deep learning models with different backbone networks are trained and tested independently.Experimental results show that a combination of Faster-RCNN with ResNet101 as backbone network, and SSD with ResNet50 as backbone network achieves the best performance under our evaluation metrics."
Waste Classification by Fine-Tuning Pre-trained CNN and GAN,2021,"['deep learning', 'image classification', 'convolutional neural networks', 'transfer learning', 'waste classification', 'recycling']",국문 초록 정보 없음,"Waste accumulation is becoming a significant challenge in most urban areas and if it continues unchecked, is poised to have severe repercussions on our environment and health. The massive industrialisation in our cities has been followed by a commensurate waste creation that has become a bottleneck for even waste management systems. While recycling is a viable solution for waste management, it can be daunting to classify waste material for recycling accurately. In this study, transfer learning models were proposed to automatically classify wastes based on six materials (cardboard, glass, metal, paper, plastic, and trash). The tested pre-trained models were ResNet50, VGG16, InceptionV3, and Xception. Data augmentation was done using a Generative Adversarial Network (GAN) with various image generation percentages. It was found that models based on Xception and VGG16 were more robust. In contrast, models based on ResNet50 and InceptionV3 were sensitive to the added machine-generated images as the accuracy degrades significantly compared to training with no artificial data."
"다양한 CNN 가속기에서 아키텍처에 따른 면적, 에너지, 성능 분석",2021,"['CNN 가속기', '아키텍처', '메모리 대역폭', '뉴럴 네트워크', 'CNN accelerators', 'architecture', 'memory bandwidth', 'neural networks']","Convolution Neural Network 가속기는 AI시대에 중요한 요소 중 하나로 떠오르게 되었다. CNN 가속기의 내부 구성을 몇 가지로 나눈다면 연산을 위한 Multiplier-Accumulator (MAC unit), 데이터 저장을 위한 SRAM, 데이터 이동을 위한 메모리 인터페이스 그리고 제어 로직으로 구분할 수 있다. 다양한 CNN 가속기들의 경우, 각기 다른 공정과 동작 주파수를 기준으로 제안되었으며, 또한 아키텍처 형태에 따라 내부 MAC unit의 수와 SRAM의 크기가 매우 큰 차이를 갖는 형태로 구성되어있다. 각 가속기들의 기본 사양으로 면적, 에너지, 성능을 비교하였을 때는 공정이나 동작 주파수 등 여러 조건들에 의해서 아키텍처에 따른 정량적인 비교가 용이하지 않게 된다. 따라서, 본 논문에서는 다양한 CNN 가속기에서 여러 조건들을 동일하게 재구성하였을 때, ResNet-50 추론 동작 시에 요구되는 면적, 에너지, 성능을 비교하여 아키텍처의 특징과 경향성을 분석하였다.","The Convolution Neural Network accelerator has emerged as an important element in the AI era. The primary components of a CNN accelerator include the Multiplier-Accumulator (MAC unit) for calculation, SRAM for data storage, memory interface for data movement, and control logic. Different CNN accelerators have been designed based on different assumptions regarding the process technologies and operating frequencies. In addition, the number of internal MAC units and the size of SRAM vary substantially between different types of architectures. These factors make it difficult to design a fair comparison of the area, energy, and performance of different CNN accelerators. In this paper, we attempt to compare the area, energy, and performance of different CNN accelerator architectures by constructing them all with the same fabrication process and operating frequency while making inferences using the ResNet-50 network."
Detection of Distracted Driving using Deep Learning,2021,"['Distracted driver', 'deep convolutional neural networks', 'transfer learning', 'pre-trained model', 'optimizers']",국문 초록 정보 없음,"As the population growth day by day, the need of transportation also increases. As the result, there are more accidents on the roads then before. According to the United States National Highway Traffic Safety Administration (NHTSA), the main reason of roadway injuries and deaths is distracted drivers. Driver distraction is a specific type of driver inattention on the road. In this case, a deep learning-based system can detect and distinguish the source of distractions in real-time, to avoid traffic crashes and make better transport safety. In this paper, we try to develop the system using transfer learning methods with ResNet50 model architecture and pre-trained weights, as well as, compare different optimizers to use with transfer learning. Adam, SGD and RMSprop optimizers were used with transfer learning methods to improve accuracy. At the end, the results show that transfer learning on ResNet50 with SGD optimizer is better model compared to Adam and RMSprop models getting 98,4% (492 out of 500) of accuracy on the unseen distracted drivers’ test dataset."
RGB영상 기반 시설오이 검출을 위한 딥러닝 개체분할 모델의 적용,2021,"['deep-learning', 'instance segmentation', 'harvesting robot', 'facility cucumbers']",국문 초록 정보 없음,"Since the advent of Convolutional Neural Networks (CNNs), crop monitoring and pattern recognition techniques using deep learning classification, detection, and segmentation models became promising alternatives for the development of harvest robot vision systems. In this paper, we propose deep learning based facility cucumber instance segmentation system for advancing the performance of cucumber harvesting robots. Cucumbers have long and curved shape unlike other crops which makes difficult for box based object detection models to detect detailed shape of cucumbers. Using pixel based instance segmentation models is expected to show higher performance for recognition of cucumber fruits. For the instance segmentation task, Mask RCNN model with Resnet backbones with 50 and 101 layers and different input sizes were used. The segmentation model have reached up to average precision of 88.64 with the Resnet50 backbone and input size 1024X1024. It is expected that our instance segmentation model could improve performance of facility cucumber harvesting robots which may reduce laborious harvesting works and lead to increase of farm productivity."
Semantic Segmentation of Outcrop Images using Deep Learning Networks Toward Realization of Carbon Capture and Storage,2021,"['backbones', 'carbon capture and storage', 'deep learning', 'Outcrop images', 'semantic segmentation']",국문 초록 정보 없음,"This study was conducted to classify outcrop images using semantic segmentation methods based on deep learning algorithms. Carbon capture and storage (CCS) is an epoch-making approach to reduce greenhouse gases in the atmosphere. This study specifically examines outcrops because geological layer measurements can lead to production of a highly accurate geological model for feasible CCS inspections. Using a digital monocular RGB camera, we obtained 13 outcrop images annotated with four classes along with strata. Subsequently, we compared segmentation accuracies with changing input image sizes of three types and semantic segmentation methods of four backbones: SegNet, U-Net, ResNet-18, and Xception-65. The ResNet-18 and Xception-65 backbones were implemented using DeepLabv3+. Experimentally obtained results demonstrated that data expansion with random sampling improved the accuracy. Regarding evaluation metrics, global accuracy and local accuracy are higher than the mean intersection over union (mIoU) for our outcrop image dataset with unequal numbers of pixels in the respective classes. These experimentally obtained results revealed that resizing for input images is unnecessary for our method."
비디오 인코더를 통한 딥러닝 모델의 정수 가중치 압축,2021,"['Deep Learning Model Parameter Quantization', 'Weight compression', 'Lightweight model']",국문 초록 정보 없음,"Recently, various lightweight methods for using Convolutional Neural Network(CNN) models in mobile devices have emerged. Weight quantization, which lowers bit precision of weights, is a lightweight method that enables a model to be used through integer calculation in a mobile environment where GPU acceleration is unable. Weight quantization has already been used in various models as a lightweight method to reduce computational complexity and model size with a small loss of accuracy. Considering the size of memory and computing speed as well as the storage size of the device and the limited network environment, this paper proposes a method of compressing integer weights after quantization using a video codec as a method. To verify the performance of the proposed method, experiments were conducted on VGG16, Resnet50, and Resnet18 models trained with ImageNet and Places365 datasets. As a result, loss of accuracy less than 2% and high compression efficiency were achieved in various models. In addition, as a result of comparison with similar compression methods, it was verified that the compression efficiency was more than doubled."
이미지 감성분류를 위한 CNN과 K-means RGB Cluster 이-단계 학습 방안,2021,"['이미지 감성분류', '색감', '이-단계 학습', 'Sentiment Analysis of Image', 'Sense of Color', 'CNN', 'Two-stage learning']",국문 초록 정보 없음,"The biggest reason for using a deep learning model in image classification is that it is possible to consider the relationship between each region by extracting each regions features from the overall information of the image. However, the CNN model may not be suitable for emotional image data without the images regional features. To solve the difficulty of classifying emotion images, many researchers each year propose a CNN-based architecture suitable for emotion images. Studies on the relationship between color and human emotion were also conducted, and results were derived that different emotions are induced according to color. In studies using deep learning, there have been studies that apply color information to image subtraction classification. The case where the images color information is additionally used than the case where the classification model is trained with only the image improves the accuracy of classifying image emotions.  This study proposes two ways to increase the accuracy by incorporating the result value after the model classifies an images emotion. Both methods improve accuracy by modifying the result value based on statistics using the color of the picture. When performing the test by finding the two-color combinations most distributed for all training data, the two-color combinations most distributed for each test data image were found. The result values were corrected according to the color combination distribution. This method weights the result value obtained after the model classifies an images emotion by creating an expression based on the log function and the exponential function.  Emotion6, classified into six emotions, and Artphoto classified into eight categories were used for the image data. Densenet169, Mnasnet, Resnet101, Resnet152, and Vgg19 architectures were used for the CNN model, and the performance evaluation was compared before and after applying the two-stage learning to the CNN model.  Inspired by color psychology, which deals with the relationship between colors and emotions, when creating a model that classifies an images sentiment, we studied how to improve accuracy by modifying the result values based on color. Sixteen colors were used: red, orange, yellow, green, blue, indigo, purple, turquoise, pink, magenta, brown, gray, silver, gold, white, and black. It has meaning. Using Scikit-learns Clustering, the seven colors that are primarily distributed in the image are checked. Then, the RGB coordinate values of the colors from the image are compared with the RGB coordinate values of the 16 colors presented in the above data. That is, it was converted to the closest color. Suppose three or more color combinations are selected. In that case, too many color combinations occur, resulting in a problem in which the distribution is scattered, so a situation fewer influences the result value. Therefore, to solve this problem, two-color combinations were found and weighted to the model. Before training, the most distributed color combinations were found for all training data images. The distribution of color combinations for each class was stored in a Python dictionary format to be used during testing. During the test, the two-color combinations that are most distributed for each test data image are found. After that, we checked how the color combinations were distributed in the training data and corrected the result. We devised several equations to weight the result value from the model based on the extracted color as described above.  The data set was randomly divided by 80:20, and the model was verified using 20% of the data as a test set. After splitting the remaining 80% of the data into five divisions to perform 5-fold cross-validation, the model was trained five times using different verification datasets. Finally, the performance was checked using the test dataset that was previously separated. Adam was used as the activation function, and the learning rate"
Enhancing Domain Generalization Performance on Lightweight Convolutional Neural Network,2021,[],국문 초록 정보 없음,"Recently, researches have been conducted on domain generalization (DG) to make a robust model against domain-shift. However, they were conducted only on AlexNet and ResNet. In this study, we apply RSC, a state-of-the-art DG technique, to MobileNetV2 to improve DG performance and confirm performance improvement. We obtain the optimal random grayscale ratio by changing several ratios and confirm performance improvement. We visualize features for each image via Grad-CAM to ensure that the model extracts domain invariant features. In future work, we will verify the performance improved by applying the DG technique to models using MobileNetV2 in other tasks."
전단 융합 기반 멀티모달 심층학습을 이용한 손동작 분류,2021,"['Hand Gesture Classification', 'Deep Learning', 'EMG', 'Multimodal Learning', 'Ninapro DB']",국문 초록 정보 없음,"In this paper, we propose a new hand gesture classification strategy using early fusion based multimodal deep learning. The structure and parameters of the state-of-the-art deep learning models such as ResNet152, DenseNet201, EfficientNetB0 for the source task of image classification are reused in the target task of hand gesture classification using surface electromyograph(EMG) and finger""s kinematic data. The time-domain EMG and kinematic signals are normalized and then transformed into combined 2-D images for the early-fusion network. The experimental results support the superiority of the proposed method in terms of classification accuracy. The transfer learning model with the EfficientNetB0 shows the 93.94% accuracy for 40 gestures of 40 participants in the Ninapro DB2."
Medical Image Classification using Pre-trained Convolutional Neural Networks and Support Vector Machine,2021,"['Pre-trained convolution neural networks', 'medical image classification', 'support vector machine']",국문 초록 정보 없음,"Recently, pre-trained convolutional neural network CNNs have been widely used and applied for medical image classification. These models can utilised in three different ways, for feature extraction, to use the architecture of the pre-trained model and to train some layers while freezing others. In this study, the ResNet18 pre-trained CNNs model is used for feature extraction, followed by the support vector machine for multiple classes to classify medical images from multi-classes, which is used as the main classifier. Our proposed classification method was implemented on Kvasir and PH2 medical image datasets. The overall accuracy was 93.38% and 91.67% for Kvasir and PH2 datasets, respectively. The classification results and performance of our proposed method outperformed some of the related similar methods in this area of study."
음성감정 신호로부터 전이학습기반 딥러닝을 이용한 감정인식,2021,[],"최근 인공지능 기술의 발전으로 개인화 서비스가 증가함으로써 감정인식 기술이 중요하게 다뤄지고 있다. 감정인식 기술의 분야중 음성 감정인식은 사람의 목소리를 분석하여 감정 상태를 파악하는 기술이다. 본 논문에서는 한국어 음성데이터를 이용하여 특징 추출 방법에 따른 CNN 기반 전이 학습모델 중 하나인 ResNet18의 감정인식 성능을 비교한다. 데이터는 직접 구축한 한국어 음성 감정 데이터를 사용했고 감정 상태는 행복, 무감정, 화남, 슬픔 총 4가지로 분류된다. 특징추출 방법은 ERB 스펙트로그램과 로그 멜-스펙트로그램을 사용했고, 데이터를 4가지 경우로 나누어 성능을 비교한다. 이 중 모든 데이터를 사용했을 때, ERB 스펙트로그램을 사용한 경우 성능이 89.91%이고 로그 멜 스펙트로그램을 사용한 경우는 96.05%로 후자가 음성 감정인식에 더 적합하다는 것을 증명한다.",다국어 초록 정보 없음
"Multimodal, Deep Learning-based Cybersickness Prediction in Virtual Reality",2021,"['Virtual reality', 'Cybersickness', 'Machine learning', 'User characteristics']",국문 초록 정보 없음,"Cybersickness is one of the factors that deteriorates user experience in virtual reality (VR). To understand how cybersickness is presented through human reactions and responses, we conducted a user study with 13 participants and built a ResNet-BiLSTM-based model that learns visual factors, eye movement, head movement, and physiological signals. The study results show that the model using all modalities yielded a performance of 0.88 F1-score. In particular, the model using the data that can be collected by HMD (Head Mounted Display) showed 0.87 F1-score, comparable to the model using all modalities, which indicates that cybersickness can be sufficiently well predicted through basic VR equipment (HMD). Finally, we present the importance of individual characteristics in cybersickness modeling."
트랜스포머 기반 객체 검출,2021,[],DETR 등 트랜스포머 기반 객체 검출에서는 백본에서 출력된 특징맵을 트랜스포머의 인코더와 디코더를 통해 멀티헤드 어텐션(Multi Head 셀프 어텐션)을 수행하여 우수한 검출  성능을 얻고 있다. 본 논문에서는 멀티헤드 어텐션중 일부 연산을 CNN으로 대체하여 검출 성능의 향상을 시도한다. NEU 결함 데이터를 사용하여 ResNet에 대한 비교 실험을 수행한다.,다국어 초록 정보 없음
Apple Detection Algorithm based on an Improved SSD,2021,"['RFB', 'Attention Model', 'SSD', 'Apple detection', 'Objection detection', 'CNN']",국문 초록 정보 없음,"Under natural conditions, Apple detection has the problems of occlusion and small object detection difficulties. This paper proposes an improved model based on SSD. The SSD backbone network VGG16 is replaced with the ResNet50 network model, and the receptive field structure RFB structure is introduced. The RFB model amplifies the feature information of small objects and improves the detection accuracy of small objects. Combined with the attention mechanism (SE) to filter out the information that needs to be retained, the semantic information of the detection objectis enhanced. An improved SSD algorithm is trained on the VOC2007 data set. Compared with SSD, the improved algorithm has increased the accuracy of occlusion and small object detection by 3.4% and 3.9%. The algorithm has improved the false detection rate and missed detection rate. The improved algorithm proposed in this paper has higher efficiency."
영상 기반 광용적맥파에서 데이터 불균형을 고려하는 심층 심박수 추정기,2021,[],국문 초록 정보 없음,"Deep heart rate estimator considering data imbalance is proposed in this paper. The proposed estimator is mainly made up of three parts: 1) video-based photoplethysmography extractor, 2) 1-dimensional heart rate estimator with ResNet-50 backbone, and 3) heart rate focal loss. By applying a different loss value between a heart rate that is easy to predict and otherwise heart rate, the proposed estimator focuses on a heart rate that is hard to predict. The proposed estimator was validated showing 6.61 mean absolute error on VIPL-HR database."
RVC 정규화와 전이학습을 이용한 손동작 인식,2021,"['Transfer Learning', 'Reference Voluntary Contraction', 'Hand Gesture Recognition', 'EMG', 'Ninapro DB']",국문 초록 정보 없음,"In this paper, we propose a new hand gesture recognition strategy using network-based transfer learning(TL) and reference voluntary contraction(RVC) normalization. The structure and parameters of the state-of-the-art deep learning models such as VGG19, ResNet152 and DenseNet121 for source task of image classification are reused in the target task of hand gesture recognition based on surface electromyography(EMG) signals. To mitigate the difficulty in handling the subject-dependent EMG signals, the RVC normalization is adopted in the signal pre-processing. The time-domain EMG signals are transformed into 2-D images for TL networks. The experimental results verify the validity of the proposed method in terms of recognition accuracy. The TL using VGG19, RVC normalization and gray image transformation shows 99.78% accuracy for the data from 15 participants performing 20 different gestures."
Former Unmanned Surface Vehicle Detection Based on Improved Convolutional Neural Network,2021,"['Object detection', 'Accuracy', 'Tracking system', 'Monocular camera']",국문 초록 정보 없음,"This paper proposes an approach to the real-time implementation of a convolutional neural network (CNN)-based object detector for a former Unmanned Surface Vehicle (USV). The original network VGG-16 of the Single Shot MultiBox Detector (SSD) is first replaced with ResNet-18, as the basic feature extraction network. The classifying network is then redesigned by reducing half of the convolutional kernel numbers, where kernel sizes of 1×1 and 3×3 are mainly used. Simultaneously, a monocular camera installed on the tracking system, is used to calculate the distance and azimuth of the former USV. The experimental results show that the proposed method has advantages of higher accuracy and lower computational complexity, compared with other existing approaches. Therefore, the proposed approach can be efficiently used on real-time tracking systems."
Rice Fungal Diseases Recognition Using Modern Computer Vision Techniques,2021,"['Convolutional neural networks', 'Machine learning', 'Computer vision', 'Rice', 'Fungal diseases']",국문 초록 정보 없음,"In the article, the authors study the possibility of detecting some fungal diseases of rice using visual computing and machine learning techniques. Leaf blast and brown spot diseases are considered. Modern computer vision methods based on convolutional neural networks are used to identify a particular disease on an image. The authors compare the four most successful and compact convolutional neural network architectures: GoogleNet, ResNet-18, SqueezeNet-1.0, and DenseNet-121. The authors show that in the dataset used for the analysis, the disease can be detected with an accuracy of at least 95%. Testing the algorithm on real data not used in training showed an accuracy of up to 95.6%. This is a good indicator of the reliability and stability of the obtained solution even to a change in the data distribution. Data not used in training showed an accuracy of up to 95.6%. This is a good indicator of the reliability and stability of the obtained solution even to a change in the data distribution."
Comparison of Pre-processed Brain Tumor MR Images Using Deep Learning Detection Algorithms,2021,"['Brain Tumor', 'RetinaNet', 'Deep Learning', 'Histogram Equalization']",국문 초록 정보 없음,"Detecting brain tumors of different sizes is a challenging task. This study aimed to identify brain tumors using detection algorithms. Most studies in this area use segmentation; however, we utilized detection owing to its advantages. Data were obtained from 64 patients and 11,200 MR images. The deep learning model used was RetinaNet, which is based on ResNet152. The model learned three different types of pre-processing images: normal, general histogram equalization, and contrast-limited adaptive histogram equalization (CLAHE). The three types of images were compared to determine the pre-processing technique that exhibits the best performance in the deep learning algorithms. During pre-processing, we converted the MR images from DICOM to JPG format. Additionally, we regulated the window level and width. The model compared the pre-processed images to determine which images showed adequate performance; CLAHE showed the best performance, with a sensitivity of 81.79%. The RetinaNet model for detecting brain tumors through deep learning algorithms demonstrated satisfactory performance in finding lesions. In future, we plan to develop a new model for improving the detection performance using well-processed data. This study lays the groundwork for future detection technologies that can help doctors find lesions more easily in clinical tasks."
Deepfake Detection using Supervised Temporal Feature Extraction model and LSTM,2021,[],국문 초록 정보 없음,"As deep learning technologies becoming developed, realistic fake videos synthesized by deep learning models called “Deepfake” videos became even more difficult to distinguish from original videos. As fake news or Deepfake blackmailing are causing confusion and serious problems, this paper suggests a novel model detecting Deepfake videos. We chose Residual Convolutional Neural Network (Resnet50) as an extraction model and Long Short-Term Memory (LSTM) which is a form of Recurrent Neural Network (RNN) as a classification model. We adopted cosine similarity with hinge loss to train our extraction model in embedding the features of Deepfake and original video. The result in this paper demonstrates that temporal features in the videos are essential for detecting Deepfake videos."
GAN 기반 데이터 증강을 통한 반려동물 종 분류,2021,[],"영상처리에서 데이터 증강(Data augmentation)은 단순히 사진을 편집하여 사진의 개수를 증강하는 것이다. 단순 데이터 증강은 동물의 반점이나 다양한 색깔을 반영하지 못하는 한계가 있다. 본 논문에서는 GAN을 통한 데이터 증강 기법을 제안한다. 제안하는 방법은 CycleGAN을 사용하여 GAN 이미지를 생성한 뒤, 데이터 증강을 거쳐 동물의 종 분류 정확도를 측정한다. 정확도 비교를 위해 일반 사진으로만 구성한 집단과 GAN 사진을 추가한 두 집단으로 나누었다. ResNet50을 사용하여 종 분류 정확도를 측정한다.",다국어 초록 정보 없음
단안 이미지의 수상 물체 거리 추정,2021,"['distance estimation', 'monocular image', 'deep neural network', 'DistanceNet']",국문 초록 정보 없음,"Distance estimation of objects on a monocular image is a challenging task. Many studies do not show high performance in estimating the distance of objects using only monocular images. Through this study, we propose DistanceNet, a deep neural network that estimates the distance of objects in a monocular image. Our dataset consists of 10339 images acquired by photographing water surface vehicles with an optical camera at Jangseong Lake in South Korea. Our distance estimation method has a part for input generation and a prediction model. The input is cropped from the image based on the detection results of the object detection model, and the input is generated using zero-padding. DistanceNet is a model based on ResNet-50 that estimates the distance of objects using the input. The distance estimation performance is evaluated by 3 criteria : absoluted relative difference (Abs Rel), squared relative difference (Squa Rel), and root of mean square errors (RMSE). We achieved an Abs Rel of 0.556, a Squa Rel of 16.016, and a RMSE of 20.077 for distance estimation of objsects. We demonstrate that a deep neural network can estimate the distance of objects in monocular images."
합성곱 신경망의 Channel Attention 모듈 및 제한적인 각도 다양성 조건에서의 SAR 표적영상 식별로의 적용,2021,[],국문 초록 정보 없음,"In the field of automatic target recognition(ATR) with synthetic aperture radar(SAR) imagery, it is usually impractical to obtain SAR target images covering a full range of aspect views. When the database consists of SAR target images with limited angular diversity, it can lead to performance degradation of the SAR-ATR system. To address this problem, this paper proposes a deep learning-based method where channel attention modules(CAMs) are inserted to a convolutional neural network(CNN). Motivated by the idea of the squeeze-and-excitation(SE) network, the CAM is considered to help improve recognition performance by selectively emphasizing discriminative features and suppressing ones with less information. After testing various CAM types included in the ResNet18-type base network, the SE CAM and its modified forms are applied to SAR target recognition using MSTAR dataset with different reduction ratios in order to validate recognition performance improvement under the limited angular diversity condition."
고성능 CNN 기반 정밀 요검사 판별 기법,2021,"['CNN', 'Urinalysis', 'Image Discrimination']","요검사는 물리적 성상 검사, 화학적 검사, 현미경 검사 세 가지가 있다. 이 중에서 화학적 요검사는 일반인이 쉽게 접근하는 방법으로 요검사지의 화학반응을 눈으로 표준비색표와 비교하거나 휴대용 요검사기를 별도로 구매하여 검사를 진행한다. 현재는 스마트폰의 보급이 대중화되어 스마트폰을 활용한 요검사 서비스 연구가 높아지고 있다. 요검사 스크리닝 애플리케이션은 스마트폰을 활용한 요검사 서비스 중 하나이다. 그러나 요검사 스크리닝 애플리케이션으로 촬영한 요검사 패드 RGB 값은 조명영향으로 인해 큰 편차가 발생한다. 요검사 패드 RGB 값의 편차는 요검사 판별의 정확도를 떨어뜨린다. 따라서 본 논문에서는 스마트폰 기반 요검사 스크리닝 애플리케이션으로 촬영한 요검사지를 검사 항목별 요검사 패드로 분류한 후 CNN을 통해 요검사 패드 이미지 판별의 정확도를 높인다. 요검사지는 다양한 배경에서 촬영하여 CNN 이미지를 생성하였으며 ResNet-50 CNN 모델을 사용하여 요검사 판별을 분석하였다.",다국어 초록 정보 없음
이미지와 메타데이터를 활용한 CNN 기반의 악성코드 패밀리 분류 기법,2021,[],"본 논문에서는 딥러닝의 CNN(Convolution Neural Network) 학습을 통하여 악성코드를 실행시키지 않고서 악성코드 변종을 패밀리 그룹으로 분류하는 방법을 연구한다. 먼저 데이터 전처리를 통해 3가지의 서로 다른 방법으로 악성코드 이미지와 메타데이터를 생성하고 이를 CNN으로 학습시킨다. 첫째, 악성코드의 byte 파일을 8비트 gray-scale 이미지로 시각화하는 방법이다. 둘째, 악성코드 asm 파일의 opcode sequence 정보를 추출하고 이를 이미지로 변환하는 방법이다. 셋째, 악성코드 이미지와 메타데이터를 결합하여 분류에 적용하는 방법이다. 이미지 특징 추출을 위해서는 본고에서 제안한 CNN을 통한 학습 방식과 더불어 3개의 Pre-trained된 CNN 모델을 (InceptionV3, Densnet, Resnet-50) 사용하여 전이학습을 진행한다. 전이학습 시에는 마지막 분류 레이어층에서 본 논문에서 선택한 데이터셋에 대해서만 학습하도록 파인튜닝하였다. 결과적으로 가공된 악성코드 데이터를 적용하여 9개의 악성코드 패밀리로 분류하고 예측 정확도를 측정해 비교 분석한다.",다국어 초록 정보 없음
피쳐 피라미드 구조 기반 얼굴 검출 네트워크에서의 디컨볼루션 적용,2021,[],"최근 피쳐 피라미드 구조 기반의 네트워크들이 얼굴 객체 검출 분야에서 좋은 성과를 내고 있다. 일반적인 피쳐 피라미드 구조에서는 한 컨볼루션 층에서 추출한 특징 맵을 이전 층에서 추출한 특징 맵에 더해주기 전 최근접 보간법을 이용하여 업스케일링을 한다. 본 논문은 이 업스케일링 단계에서 보간법이 아닌 디컨볼루션 네트워크를 사용할 것을 제안한다. 이는 상위층의 특징 맵이 하위층의 특징 맵에 비해 더욱 풍부한 특징 정보를 가지고 있다는 점에 착안한 것이며, 제안된 피쳐 피라미드 구조는 이와 같은 의도와 일치한다. 실제 WIDER FACE 데이터셋으로 학습하여 제안한 구조를 적용했을 때, ResNet50을 백본으로 한 경우 기존 90.88AP에서 91.26AP로, MobileNet-0.25를 백본으로 한 경우에는 기존 85.29AP에서 85.6AP로 성능이 향상됨을 확인할 수 있었다.",다국어 초록 정보 없음
Automatic Detection of Injection and Press Mold Parts on 2D Drawing Using Deep Neural Network,2021,"['deep neural network', '2D Drawing', 'image patch', 'mold parts', 'industrial product design']",국문 초록 정보 없음,"This paper proposes a deep learning–based method to automatically detect the injection mold parts (i.e., hook or boss) and press mold parts (i.e., DPS or Embo) in 3D CAD models of commercial TV. We first converted the 3D CAD models into 2D drawings and cropped them into a smaller image patch for the training efficiency of a deep neural network. Then, we found the position and type of mold parts using Cascade R-CNN and estimated the orientation of the detected mold parts using ResNet-50. Finally, we converted the 2D position of the mold parts to the 3D position of the original image. We obtained detection accuracy of injection mold parts with an average precision (AP) of 84.1% and an average recall (AR) of 91.2% and detection accuracy of press mold parts with an AP of 72.0% and an AR of 87.0%, as well as an orientation accuracy of injection and press mold parts with 94.4% and 92.0%, respectively, which can facilitate faster industrial product design."
Automated Fall Detection on Smart Factory based on Deep Learning Approach,2021,"['Convolutional Neural Network (CNN)', 'Fall-detection']",국문 초록 정보 없음,"The emergence of the smart environment and the Internet of Things paradigms with the increasing number of cameras in daily life, forms an optimal context for vision-based systems. This paper proposes a model to detect human falling by using deep learning algorithm for vision-based system. To improve fall-detection accuracy, a deep learning technique such as Convolutional Neural Network (CNN) combined with data augmentation and dropout layer to avoid over-fitting is proposed. It compared with existing convolutional-based architecture such as AlexNet, SqueezeNet, GoogleNet, and ResNet-18. The per-formance of the proposed algorithm is verified by using UR Fall Detection data set. The simulation result showed that the proposed algorithm achieves an accuracy 96.88% with validation loss 0.0638."
MAT-AGCA: Multi Augmentation Technique on small dataset for Balinese character recognition using Convolutional Neural Network,2021,"['Balinese character', 'Lontar manuscript', 'Data augmentation', 'Adaptive Gaussian Thresholding', 'Convolutional Autoencoder']",국문 초록 정보 없음,"The lontar manuscript is an ancient Balinese cultural heritage written using Balinese characters on palm leaves. The recognition of Balinese characters in lontar is challenging because it has noise and limited data availability. To solve these problems, data augmentation is needed to increase the variety and amount of data to improve recognition performance. In this study, we collected Balinese character images from 50 lontar manuscript writers. We proposed MAT-AGCA that combines Adaptive Gaussian Thresholding and Convolutional Autoencoder for data augmentation. Based on experiments using InceptionResnetV2, DenseNet169, ResNet152V2, VGG19, and MobileNetV2, our proposed method achieved the best performance with 96.29% accuracy."
Autonomous Driving Based on Modified SAC Algorithm through Imitation Learning Pretraining,2021,"['Autonomous Driving', 'Imitation Learning', 'Reinforcement Learning', 'SAC Algorithm']",국문 초록 정보 없음,"In this paper, we implement a modified SAC algorithm for autonomous driving tasks using the simulator AirSim’s environment API which provides various weather, collision, and lighting choices. Given current image state and car velocity as our inputs, the task outputs the throttle, brake, and steering angle data and gives the vehicle action instruction through the AirSim control outputs. As autonomous vehicles are more likely to be accepted if they drive like how human would, we at first train our model by imitation learning to provides the pre-trained human-like policy and weights to SAC. During the reinforcement learning, in order to increase the feasible policy’s robustness, we use ResNet-34 as our actor and critic network architecture in the SAC algorithm."
Deep Convolutional Neural Network를 적용한 피하 종괴의 초음파적 진단: 실험적 연구,2021,"['Deep learning', 'Epidermal cyst', 'Lipoma', 'Ultrasonography']",국문 초록 정보 없음,"Background: Ultrasonography is an effective noninvasive imaging modality for the diagnosis of subcutaneous masses. To date, few studies have reported skin ultrasonography using deep convolutional neural networks (DCNNs). We investigated the accuracy of DCNNs for the diagnosis of epidermal cysts, lipomas, and other subcutaneous masses.Objective: The purpose of this study was to evaluate whether DCNNs could diagnose subcutaneous masses with ultrasonographic images at level of competence comparable to dermatologists.Methods: We created a dataset of 1,361 skin ultrasonography images obtained from 202 patients diagnosed with epidermal cysts, lipomas, and other subcutaneous masses, to train the DCNNs using ResNet18. Performance was compared with another set of 93 ultrasonographic images (24 epidermal cysts, 25 lipomas, and 44 other subcutaneous masses) from open-access articles.Results: The DCNNs yielded 87.10% classification accuracy and 86.10% F1-scores. The area under the curve, sensitivity, and specificity were 0.92 (95% confidence interval [CI] 0.86∼0.98), 75.00%, and 98.55% for epidermal cysts; 0.93 (95% CI 0.88∼0.98), 80.00%, and 94.12% for lipomas; and 0.97 (95% CI 0.93∼1.00), 97.73%, and 85.71% for other subcutaneous masses, respectively. Analysis using gradient-weighted class activation mapping revealed that the DCNNs could detect specific ultrasonographic findings of epidermal cysts and lipomas.Conclusion: We propose that DCNNs combined with ultrasonography may aid in the diagnosis of subcutaneous masses in outpatient settings. (Korean J Dermatol 2021;59(7):513∼520)"
심층 합성곱 신경망 압축을 위한 텐서 곱셈 기반 필터 선택 기법,2021,[],국문 초록 정보 없음,"The success of convolutional neural networks in various computer vision applications is accompanied by a significant increase in parameter storage and computation costs. To solve this problem, we present a multilinear algebra-based filter pruning method by identifying less important convolutional filters. More specifically, the proposed algorithm predicts the expected accuracy loss through a novel tensor multiplication-based importance quantification. In experimental results on image classification benchmark, our algorithm demonstrates its effectiveness and strengths. Notably, on CIFAR-100, the proposed pruned ResNet-18 achieves 86% the number of parameters reduction with 4.93% top-1 accuracy drop, which is better performance than previous norm-based filter pruning algorithms."
컨볼루션 신경망 모델을 이용한 분류에서 입력 영상의 종류가 정확도에 미치는 영향,2021,"['X-ray', 'Convolutional neural network', 'Classification', 'Deep learning']",국문 초록 정보 없음,"The purpose of this study is to classify TIFF images, PNG images, and JPEG images using deep learning, and to compare the accuracy by verifying the classification performance. The TIFF, PNG, and JPEG images converted from chest X-ray DICOM images were applied to five deep neural network models performed in image recognition and classification to compare classification performance. The data consisted of a total of 4,000 X-ray images, which were converted from DICOM images into 16-bit TIFF images and 8-bit PNG and JPEG images. The learning models are CNN models - VGG16, ResNet50, InceptionV3, DenseNet121, and EfficientNetB0. The accuracy of the five convolutional neural network models of TIFF images is 99.86%, 99.86%, 99.99%, 100%, and 99.89%. The accuracy of PNG images is 99.88%, 100%, 99.97%, 99.87%, and 100%. The accuracy of JPEG images is 100%, 100%, 99.96%, 99.89%, and 100%. Validation of classification performance using test data showed 100% in accuracy, precision, recall and F1 score. Our classification results show that when DICOM images are converted to TIFF, PNG, and JPEG images and learned through preprocessing, the learning works well in all formats. In medical imaging research using deep learning, the classification performance is not affected by converting DICOM images into any format."
Gender Prediction from Masked Face Images using Deep Learning towards Smart Store Customer Management,2021,"['Deep Learning', 'Gender Prediction', 'Masked Face', 'Smart Store']",국문 초록 정보 없음,"In this study, authors aimed to predict the gender of a customer with face mask to manage the customer data, targeted advertisement, and future of retail. Amid the COVID-19 pandemic situation, a customer must wear a face mask, avoid contacts with store staffs and should stay for short period of times while shopping. Smart store can meet the requirements by knowing the customer gender to find the right item. Predicting gender from faces with mask is a perplexing task due to two main reasons: 1) the lack of large benchmark datasets of masked faces, and 2) the deficiency of facial cues from the masked regions. Faces in the unconstraint environment have various orientations and occlusion degrees, where no less than one part of each face is occluded by mask. The traditional machine learning approaches are suffering in performance with the heterogeneity of the images in the non-benchmark dataset. This research proposes an automatic gender prediction system deploying deep learning networks; GoogleNet and ResNet50 those are pretrained with huge amount of image data. The extensive experiments demonstrate a noteworthy prediction accuracy (83%) even though the amount of available masked face data is very limited. Furthermore, this is the first work of gender prediction with the real masked face dataset heretofore."
Wood Classification of Japanese Fagaceae using Partial Sample Area and Convolutional Neural Networks,2021,"['wood', 'microscopic image', 'sample selection', 'classification', 'convolutional neural network']",국문 초록 정보 없음,"Wood identification is regularly performed by observing the wood anatomy, such as colour, texture, fibre direction, and other characteristics. The manual process, however, could be time consuming, especially when identification work is required at high quantity. Considering this condition, a convolutional neural networks (CNN)-based program is applied to improve the image classification results. The research focuses on the algorithm accuracy and efficiency in dealing with the dataset limitations. For this, it is proposed to do the sample selection process or only take a small portion of the existing image. Still, it can be expected to represent the overall picture to maintain and improve the generalisation capabilities of the CNN method in the classification stages. The experiments yielded an incredible F1 score average up to 93.4% for medium sample area sizes (200 × 200 pixels) on each CNN architecture (VGG16, ResNet50, MobileNet, DenseNet121, and Xception based). Whereas DenseNet121-based architecture was found to be the best architecture in maintaining the generalisation of its model for each sample area size (100, 200, and 300 pixels). The experimental results showed that the proposed algorithm can be an accurate and reliable solution."
주행 환경의 안개 이미지에서 패치 구분자를 이용한 의미론적 분할,2021,"['Deep Learning(딥러닝)', 'Semantic Segmentation(의미론적 분할)', 'Discriminator(구분자)', 'Camera image(카메라 이미지)', 'ADAS(첨단운전보조시스템)']","딥러닝이 활발하게 연구됨에 따라, ADAS(Advanced Driver Assistance Systems)을 위해 카메라 이미지 기반의 정보를 활용하여 장면에 대한 깊은 이해를 요구하는 네트워크의 설계가 중요한 이슈로 떠오르고 있다. 예를 들어, 물체 감지(Object Detection)를 이용해 물체의 위치 및 종류를 판별하거나, 의미론적 분할(Semantic Segmentation)과 같은 기법을 활용하여 물체의 종류 및 형상을 이미지 픽셀별로 파악할 수 있다. 특히, 자율주행을 위한 의미론적 분할을 위해 물체의 경계선에서 뚜렷하게 픽셀별로 구분할 수 있는 능력이 요구된다. 이러한 이미지 기반의 의미론적 분할은 주로 맑은 날에서 훈련 및 테스트가 이루어지지만, 주행환경은 맑은 날 뿐만이 아니라 안개와 같은 날씨를 포함할 수 있다. 그러나, 날씨정보가 추가된 이미지는 네트워크의 성능저하를 불러오는 요인이 될 수 있다. 따라서, 자율주행을 위해서는 날씨에도 영향을 받지 않는 네트워크 모델이 필요하다. 본 연구에서는 Cityscapes 데이터셋에서 합성 안개 이미지를 통해 의미론적 장면 분할에 대한 성능 저하를 시험한다. 의미론적 분할을 위해 네트워크는 인코더(Encoder)-디코더(Decoder)로 구성된다. 인코더는 ResNet50을 이용하며, 각 단에서 나온 피쳐맵(Feature Map)을 의미론적 분할을 위한 디코더를 통해 결과물을 출력한다. 또한, 패치 구분자(Patch-Discriminator)를 결과물에 이용하여 이미지의 학습을 돕는다. 네트워크 성능 평가를 위해 Cityscapes의 Validation 이미지를 사용했으며, 평가지표는 Cityscapes의 19개 클래스에 대해서 성능을 측정한 뒤 평균을 낸 mIoU(mean Intersection over Union)와 전체 결과에 대한 Pixel Accuracy를 활용한다. 이를 통해, 기존 성능과 개선 성능을 비교한다.",다국어 초록 정보 없음
딥러닝 기반의 철강 표면의 결함 검출기,2021,"['Artificial intelligence', 'Convolutional neural network', 'Deep learning', 'Image classification', 'Metal surface defect', 'Surface defect detection (SDD)']",국문 초록 정보 없음,"Steel surface defect should be detected and repaired in steel industry. Therefore, automatic detection of the steel surface defects plays a vital role in the steel manufacturing process. For the defect detection, machine learning based classification methods have been widely used such as HAAR feature-based cascade classifiers and support vector machines (SVM). As deep learning methods have been popular, the neural network based surface defect detection has been recently introduced. As for the methods, many researchers, in general, adopt a trained neural network, which is mainly winner in the recent ILSVRC (ImageNet Large Scale Visual Recognition Challenge). Then, the weights and last layers are modified to be used for surface defect detection (SDD), which is called transfer learning. In the previous researches, ResNet152 (winner in ILSVRC 2015) was used and the resulting performances were F1=0.975 and F1=0.912 in two different studies, respectively. However, the neural network used in their research has very wide and deep. Therefore, huge memories to save the trained weights and many multiplier–accumulators (MAC) are necessary, which means expensive hardware systems are essential to predict surface defect on the steel surface. This paper suggests a small neural network dedicated to surface defect detection. The proposed network has only three convolution layers and two fully connected layers. From the experimental results, we obtained F1=0.931 and minimum AUC (area under the curve)=0.995."
Automated Gastrointestinal Tract Classification Via Deep Learning and The Ensemble Method,2021,"['Gastrointestinal tract', 'Colorectal cancer', 'Deep learning', 'CNN', 'Transfer learning', 'Ensemble']",국문 초록 정보 없음,"Colorectal cancer is a leading cause of death among the cancer family with a record of almost a million moralities in 2020 alone. While the treatment of colorectal cancer is very difficult, early diagnosis can help immensely with treatment, eliminating the risks, and recovery. In most cases early diagnosis is possible by catching any of the precursors of the disease, many of which appear on the Gastrointestinal tract. The use of machine learning to automate the process of gastrointestinal tract examination could accelerate the process of diagnosis, and increase its efficiency. This study suggests the use of the stacking ensemble method with multiple pre-trained CNN models for an accurate classification of GI tract using the publicly available dataset Kvasir. The pre-trained models used in this study were ResNet50, MobileNetV2, and Xception, all of which were ensembled and trained on a subset of the data and tested on another to eliminate bias, and evaluates the model’s capacity for generalization. Overall, the model demonstrated impressive performance at 99.2% accuracy, 0.9977 AUC, and 99.29% F1-score, especially compared to the individual constituent models and other models discussed in the review section of the study."
A Lightweight Deep Learning Model for Early Fire Detection using UAV Imagery,2021,"['Fire detection', 'Deep learning', 'Unmanned aerial vehicle']",국문 초록 정보 없음,"Fire is an extremely catastrophic disaster that leads to the destruction of forests, human assets, reduced soil fertility, land resources, and the cause of global warming. In the current decade, fire detection and its management are the major concern of several researchers to prevent social, ecological, and economic damages. To overcome such kind of losses, early fire detection, and the automatic response is very significant. Moreover, achieving high accuracy with reducing inference time and model size is also challenging for the Unmanned Aerial Vehicle (UAVs). Therefore, in this work, we enabled the VGG16 architecture for UAV in terms of reducing its learning parameters from 138 million to 11.4 million for early fire detection. The proposed system is inexpensive in terms of computation and size. The performance of our proposed work is evaluated over the custom dataset. We performed comprehensive experiments using various deep learning architectures such as VGG16, ResNet50, and the proposed CNN model. The experimental results based on the proposed model achieved an accuracy of 98% on 50 epochs."
Novel Image Classification Method Based on Few-Shot Learning in Monkey Species,2021,"['Deep learning', 'Feature extraction', 'Few-shot learning', 'Image classification']",국문 초록 정보 없음,"This paper proposes a novel image classification method based on few-shot learning, which is mainly used to solve model overfitting and non-convergence in image classification tasks of small datasets and improve the accuracy of classification. This method uses model structure optimization to extend the basic convolutional neural network (CNN) model and extracts more image features by adding convolutional layers, thereby improving the classification accuracy. We incorporated certain measures to improve the performance of the model. First, we used general methods such as setting a lower learning rate and shuffling to promote the rapid convergence of the model. Second, we used the data expansion technology to preprocess small datasets to increase the number of training data sets and suppress over-fitting. We applied the model to 10 monkey species and achieved outstanding performances. Experiments indicated that our proposed method achieved an accuracy of 87.92%, which is 26.1% higher than that of the traditional CNN method and 1.1% higher than that of the deep convolutional neural network ResNet50."
High-Throughput Plant Phenotyping for the Chilling Stress of Watermelon Plants,2021,"['High-throughput phenotyping', 'hyperspectral imaging', 'image analysis', 'deep learning']",국문 초록 정보 없음,"Plant phenotyping methods are essential tools for the production of demanded crops for a growing population. Access to large-scale high-throughput screening systems are a critical barrier for early quantification of plants states in real-time. For this purpose, we developed an automated high throughput plant screening system which consists of two imaging chambers. The first chamber is equipped with two RGB cameras (top and side view), and a near-infrared hyperspectral imaging (NIR-HSI) system in the wavelength range of 900-1700 nm installed in the second screening chamber. Initially, the system was tested for early detection of chilling stress watermelon plants, a total of 350 watermelon plants were scanned before and after exposure to chilling stress conditions (-5℃) while moving through the chambers on the conveyor belt. An automatic image processing algorithm was developed for image segmentation and data augmentation. The color images applied to a transfer leaning of ResNet50 basis resulted in 90% classification accuracy. While the hyperspectral images were used to extract from each single plant leaves for the development of a partial least square discrimination analysis (PLS-DA) model which displayed over a 95% accuracy for the validation set. The overall results highlight that the high-throughput screen of plants on a combination of machine learning and deep learning has potential to quantify the plants' states under chilling stress condition."
유사 이미지 분류를 위한 딥 러닝 성능 향상 기법 연구,2021,"['분류', '딥 러닝', '유사 이미지', '컨볼루셔널 뉴럴 네트워크', '혼동률', 'Classification', 'Deep Learning', 'Similar Image', 'CNN', 'Confusion Rate']","딥 러닝을 활용한 컴퓨터 비전 연구는 여전히 대규모의 학습 데이터와 컴퓨팅 파워가 필수적이며, 최적의 네트워크 구조를 도출하기 위해 많은 시행착오가 수반된다. 본 연구에서는 네트워크 최적화나 데이터를 보강하는 것과 무관하게 데이터 자체의 특성만을 고려한 CR(Confusion Rate)기반의 유사 이미지 분류 성능 향상 기법을 제안한다. 제안 방법은 유사한 이미지 데이터를 정확히 분류하기 위해 CR을 산출하고 이를 손실 함수의 가중치에 반영함으로서 딥 러닝 모델의 성능을 향상시키는 기법을 제안한다. 제안 방법은 네트워크 최적화 결과와 독립적으로 이미지 분류 성능의 향상을 가져올 수 있으며, 클래스 간의 유사성을 고려해 유사도가 높은 이미지 식별에 적합하다. 제안 방법의 평가결과 HanDB에서는 0.22%, Animal-10N에서는 3.38%의 성능향상을 보였다. 제안한 방법은 다양한 Noisy Labeled 데이터를 활용한 인공지능 연구에 기반이 될 것을 기대한다.","Deep learning in computer vision has made accelerated improvement over a short period but large-scale learning data and computing power are still essential that required time-consuming trial and error tasks are involved to derive an optimal network model. In this study, we propose a similar image classification performance improvement method based on CR (Confusion Rate) that considers only the characteristics of the data itself regardless of network optimization or data reinforcement. The proposed method is a technique that improves the performance of the deep learning model by calculating the CRs for images in a dataset with similar characteristics and reflecting it in the weight of the Loss Function. Also, the CR-based recognition method is advantageous for image identification with high similarity because it enables image recognition in consideration of similarity between classes. As a result of applying the proposed method to the Resnet18 model, it showed a performance improvement of 0.22% in HanDB and 3.38% in Animal-10N. The proposed method is expected to be the basis for artificial intelligence research using noisy labeled data accompanying large-scale learning data."
딥러닝 컬러 영상분석 기반 씨없는 수박종자 품종 선별,2021,"['watermelon', 'triploid seed', 'image analysis', 'deep learning', 'color image']",국문 초록 정보 없음,"Watermelon growers face various problems in acquiring accurate seed germination and varietal mixing of 3x, 2x and 4x seeds, thus hampering the watermelon sector due to seed-ploid nomenclature confusion given the fact that seeds tend to look alike on attempt of the human eye. These circumstances indirectly inflict negative effects on the farmer income and the development of watermelon seed company. Therefore, seed purity is a prerequisite for all seed breeders and companies, as the performance of a given seed variety can be known and standardized from the rest. In this study we employed color camera techniques to discriminate triploid watermelon seeds from diploid and tetraploid seeds nondestructively. Seed-ploid images were acquired by both a digital canon and mvBlue fox3 USB3.0 camera and discrimination models constructed with multivariate machine learning methods of one class classification with DD-SIMCA and SVM quadratic. And to improve the accuracy obtained, a deep learning model was also developed. The models constructed on one class classification with DD-SIMCA, and SVM-quadratic method yielded triploid discrimination accuracy of 69.5% and 85.5% respectively when a digital canon camera was used. To further improve the class-ploid discrimination accuracy, a deep learning model of deeplabv3+ and Resnet18, gave an accuracy of 95.5%. Deep learning model results demonstrated a higher discrimination accuracy and thus these results can be potentially automated and applied on online system for real time seed-ploid discrimination and sorting."
Enabling on-board deep learning model training for mobile and embedded systems,2021,"['Mobile model training', 'Deep learning']",국문 초록 정보 없음,"On-device deep neural network model training holds the potential to enable a rich set of data privacy-aware and infrastructure-independent personalized mobile applications [1-3]. However, despite recent advancements in mobile and embedded platform's hardware, locally training a complex deep neural network is still a non-trivial task given its resource demands. Such capability can be used to exploit new machine learning concepts which include federated learning and distributed learning. In this work we show that the limited dynamic memory budgets on mobile platforms is the main constraint, and propose meMon as a framework for efficiently managing mobile memory resources for deep neural network training. Specifically, meMon is cored on a heuristic objective function that identifies neural network activations that are i) easy-to-recompute, ii) consumes large memory spaces, and iii) with weak dependency, so that they are prioritized to be removed from the memory when memory resources are scarce. meMon is implemented in CUDA and will be provided as open source for the research community. We evaluate meMon via hardware benchmark-based emulations and real implementations on the Samsung Galaxy S10 (Android 10) and NVIDIA Jetson TX2. Our evaluations show that meMon enables local training for five state-of-the-art deep learning models (BERT, ResNet-152, DenseNet-169, Stacked LSTM, DCGAN) by reducing the required memory by more than five-fold and speeds up the training process by two-fold compared to a baseline approach. We also show that meMon successfully adapts to dynamic memory budget variations, suggesting its robustness in real-world use cases."
변환학습을 이용한 장면 분류,2021,"['multiclass image scene classification method', 'ResNet', 'ImageNet', 'CNN model']",본 논문에서는 변환 학습을 기반으로 한 다중 클래스 이미지 장면 분류 방법을 제안한다. 이미지 분류를 위해 대형 이미지 데이터 세트 ImageNet에 대해 사전 학습한 ResNet (ResNet) 모델을 사용하는 방법이다. CNN 모델의 이미지 분류 방법에 비해 분류 정확도 및 효율성을 크게 향상시킬 수 있다.,"In this paper, we proposed a multiclass image scene classification method based on transform learning. The method using the Residual Network (ResNet) model which pre-trained on the large image dataset ImageNet for image classification. Compared with the image classification method of the CNN model, it can greatly improve the classification accuracy and efficiency"
변형 Residual Convolutional Neural Network 모델을 이용한 고효율 심전도 데이터 분석 기법,2021,"['MIT-BIH arrhythmia 데이터베이스', 'ResNet', 'ResNeXt', 'Adabound', '주입기법']",국문 초록 정보 없음,다국어 초록 정보 없음
다중 클래스의 이미지 장면 분류,2021,"['multi-class image scene classification method', 'transformation learning', 'image datasets', 'ResNet']",본 논문에서는 변한 학습에 기반을 둔 다중 클래스 영상 장면 분류 방법을 제시한다. ImageNet 대형 이미지 데이터 세트에서 사전 훈련된 네트워크 모델에 의존하여 다중 클래스의 자연 장면 이미지를 분류한다. 실험에서는 최적화된 ResNet 모델을 Kaggle의 Intel Image Classification 데이터 셋에 분류하여 우수한 결과를 얻었다.,"In this paper, we present a multi-class image scene classification method based on transformation learning. ImageNet classifies multiple classes of natural scene images by relying on pre-trained network models on large image datasets. In the experiment, we obtained excellent results by classifying the optimized ResNet model on Kaggle’s Intel Image Classification data set."
암세포 영상분류를 위한 심층학습 모델 연구,2021,"['Cancer Cell', 'Classification', 'CNN', 'Deep Learning']","특정 질병 진단을 위한 병리 검사는 필수적이며, 최근 이러한 분야의 시간적, 인적 자원의 필요성을 줄이기 위해 인공 지능을 활용한 암세포의 자동분류가 가능한 시스템 구축에 관련된 연구가 활발하게 진행되고 있다. 하지만, 이전 연구에서는 제한적인 심층학습 알고리즘에 기인한 비교적 낮은 정확도로 데이터 처리에 한계가 존재하였다. 본 연구에서는 심층 학습의 일종인 Convolution Neral Network를 통해 4종류의 암세포를 4 Class Classification을 시행하는 방법을 제안한다. EfficientNet, ResNet, Inception을 사용하였으며 여러 하이퍼 파라미터 튜닝을 통해 얻은 모델을 앙상블 하여 최종적으로 97.26의 정확도를 얻을 수 있었다.","Additional pathological tests using imaging equipment are essential before diagnosing cancer cells. Recently, in order to reduce the need for time and human resources in these fields, research related to the establishment of a system capable of automatic classification of cancer cells using artificial intelligence is being actively conducted. However, in both previous studies, there were relatively limited deep learning algorithms and cell types, and limitations existed with low accuracy at the same time. In this study, a method of performing 4class Classification on four types of cancer cells through the Convolution Neral Network, a type of in-depth learning. EfficientNet, ResNet, and Inception were used, and finally Resnet was used to obtain an accuracy of 96.11 on average for k-fold."
합성곱 신경망을 이용한 컨포멀 코팅 PCB에 발생한 문제성 기포 검출 알고리즘,2021,"['Problematic Bubble', 'Bubble Detection', 'Conformal Coating', 'CNN', 'ResNet']",국문 초록 정보 없음,"Conformal coating is a technology that protects PCB(Printed Circuit Board) and minimizes PCB failures. Since the defects in the coating are linked to failure of the PCB, the coating surface is examined for air bubbles to satisfy the successful conditions of the conformal coating. In this paper, we propose an algorithm for detecting problematic bubbles in high-risk groups by applying image signal processing. The algorithm consists of finding candidates for problematic bubbles and verifying candidates. Bubbles do not appear in visible light images, but can be visually distinguished from UV(Ultra Violet) light sources. In particular the center of the problematic bubble is dark in brightness and the border is high in brightness. In the paper, these brightness characteristics are called valley and mountain features, and the areas where both characteristics appear at the same time are candidates for problematic bubbles. However, it is necessary to verify candidates because there may be candidates who are not bubbles. In the candidate verification phase, we used convolutional neural network models, and ResNet performed best compared to other models. The algorithms presented in this paper showed the performance of precision 0.805, recall 0.763, and f1-score 0.767, and these results show sufficient potential for bubble test automation."
깊은 합성곱 신경망 모델에 따른 유방 초음파 영상 분류 성능 비교,2021,"['Breast Ultrasound', 'Breast Cancer', 'Tumor', 'Classification', 'VGG', 'ResNet', 'InceptionNet', 'DenseNet', 'EfficientNet', 'Convolutional Neural Network']",국문 초록 정보 없음,"Breast ultrasound has been widely utilized for classifying tumors into benignancy and malignancy. The limitations of traditional breast ultrasound are the handcrafted features obtained by well-trained sonographers and subjective decision according to different individual experiences. Recently, CNN-based deep learning techniques have exhibited better performance in medical images. However, most research for deep learning in medical ultrasound adopts CNN models developed for natural images due to the lack of common standard and dataset. In this paper, we compare six DCNN models which exhibit good performance for natural images - VGGNet, ResNet, InceptionNet, DenseNet, and EfficientNet. Our classification results demonstrate that CNN models of relatively lower performance on natural images show better performance on gray-scale ultrasound images and further study of CNN models are needed focusing on the features of medical images."
LDCSIR: Lightweight Deep CNN-based Approach for Single Image Super-Resolution,2021,"['Image super-resolution', 'Convolutional neural network', 'PSNR', 'ResNet block']",국문 초록 정보 없음,"Single image super-resolution (SISR) is an image processing technique, and its main target is to reconstruct the high-quality or high-resolution (HR) image from the low-quality or low-resolution (LR) image. Currently, deep learning-based convolutional neural network (CNN) image super-resolution approaches achieved remarkable improvement over the previous approaches. Furthermore, earlier approaches used hand designed filter to upscale the LR image into HR image. The design architecture of such approaches is easy, but it introduces the extra unwanted pixels in the reconstructed image. To resolve these issues, we propose novel deep learning-based approach known as Lightweight deep CNN-based approach for Single Image Super-Resolution (LDCSIR). In this paper, we propose a new architecture which is inspired by ResNet with Inception blocks, which significantly drop the computational cost of the model and increase the processing time for reconstructing the HR image. Compared with the other state of the art methods, LDCSIR achieves better performance in terms of quantitively (PSNR/SSIM) and qualitatively."
LDCSIR: Lightweight Deep CNN-based Approach for Single Image Super-Resolution,2021,"['Image super-resolution', 'Convolutional neural network', 'PSNR', 'ResNet block']",국문 초록 정보 없음,"Single image super-resolution (SISR) is an image processing technique, and its main target is to reconstruct the high-quality or high-resolution (HR) image from the low-quality or low-resolution (LR) image. Currently, deep learning-based convolutional neural network (CNN) image super-resolution approaches achieved remarkable improvement over the previous approaches. Furthermore, earlier approaches used hand designed filter to upscale the LR image into HR image. The design architecture of such approaches is easy, but it introduces the extra unwanted pixels in the reconstructed image. To resolve these issues, we propose novel deep learning-based approach known as Lightweight deep CNN-based approach for Single Image Super-Resolution (LDCSIR). In this paper, we propose a new architecture which is inspired by ResNet with Inception blocks, which significantly drop the computational cost of the model and increase the processing time for reconstructing the HR image. Compared with the other state of the art methods, LDCSIR achieves better performance in terms of quantitively (PSNR/SSIM) and qualitatively."
전기화재 원인분석을 위한 용융흔 외형 판별 딥러닝 알고리즘 설계,2021,"['전기 화재', '단락흔', '열흔', 'CNN', 'Resnet 알고리즘', 'Electric fire', 'Arc beads', 'Molten mark', 'CNN', 'Resnet']",국문 초록 정보 없음,다국어 초록 정보 없음
Multistage Transfer Learning for Breast Cancer Early Diagnosis via Ultrasound,2021,"['Multistage transfer learning', 'breast cancer', 'ultrasound']","인공지능 알고리즘을 이용한 유방암의 조기진단에 관련된 연구는 최근 들어 활발하게 진행되고 있다. 이는 연구용으로 공개된 초음파 유방 이미지를 활용하여 다양하게 개발되고 있으나, 사용자의 목적에 맞는 처리 속도 및 정확도 등에 다양한 한계점을 보인다. 이러한 문제를 해결하기 위해, 본 논문에서는 ImageNet에서 학습된 ResNet 모델을 현미경 기반 암세포 이미지에서 활용이 가능한 다단계 전이 학습을 제안하고, 이를 다시 전이 학습하여 초음파 유방암 영상을 양성 및 악성으로 분류하는 실험을 진행하였다. 실험을 위한 영상은 양성과 악성이 포함된 250장의 유방암 초음파 영상과 27,200장의 암 세포주 영상으로 구성되었다. 제안된 다단계 전이 학습 알고리즘은 초음파 유방암 영상을 분류하였을 때 96% 이상의 정확도를 보였으며, 향후 암 세포주 및 실시간 영상처리 등의 추가를 통해 보다 높은 활용도와 정확도를 보일 것으로 기대한다.","Research related to early diagnosis of breast cancer using artificial intelligence algorithms has been actively conducted in recent years. Although various algorithms that classify breast cancer based on a few publicly available ultrasound breast cancer images have been published, these methods show various limitations such as, processing speed and accuracy suitable for the user's purpose. To solve this problem, in this paper, we propose a multi-stage transfer learning where ResNet model trained on ImageNet is transfer learned to microscopic cancer cell line images, which was again transfer learned to classify ultrasound breast cancer images as benign and malignant. The images for the experiment consisted of 250 breast cancer ultrasound images including benign and malignant images and 27,200 cancer cell line images. The proposed multi-stage transfer learning algorithm showed more than 96% accuracy when classifying ultrasound breast cancer images, and is expected to show higher utilization and accuracy through the addition of more cancer cell lines and real-time image processing in the future."
안면 연령 예측을 위한 CNN기반의 히트 맵을 이용한 랜드마크 선정,2021,[],국문 초록 정보 없음,"The purpose of this study is to improve the performance of the artificial neural network system for facial image analysis through the image landmark selection technique. For landmark selection, a CNN-based multi-layer ResNet model for classification of facial image age is required. From the configured ResNet model, a heat map that detects the change of the output node according to the change of the input node is extracted. By combining a plurality of extracted heat maps, facial landmarks related to age classification prediction are created. The importance of each pixel location can be analyzed through facial landmarks. In addition, by removing the pixels with low weights, a significant amount of input data can be reduced."
심층 CNN 기반 구조를 이용한 토마토 작물 병해충 분류 모델,2021,"['Convolutional Neural Networks', 'Deep Learning', 'Transfer Learning', 'Fine Tuning', 'Plant Diseases Classification']","토마토 작물은 병해충의 영향을 많이 받기 때문에 이를 예방하지 않으면 농업 경제에 막대한 손실을 초래할 수 있다. 따라서 토마토의 다양한 병해충의 진단을 빠르고 정확하게 진단하는 시스템이 요구된다. 본 논문에서는 ImageNet 데이터 셋 상에서 다양하게 사전 학습된 딥러닝 기반 CNN 모델을 적용하여 토마토의 9가지 병해충 및 정상인 경우의 클래스를 분류하는 시스템을 제안한다. PlantVillage 데이터 셋으로부터 발췌한 토마토 잎의 이미지 셋을 3가지 딥러닝 기반 CNN 구조를 갖는 ResNet, Xception, DenseNet의 입력으로 사용한다. 기본 CNN 모델 위에 톱-레벨 분류기를 추가하여 제안 모델을 구성하였으며, 훈련 데이터 셋에 대해 5-fold 교차검증 기법을 적용하여 학습시켰다. 3가지 제안 모델의 학습은 모두 기본 CNN 모델의 계층을 동결하여 학습시키는 전이 학습과 동결을 해제한 후 학습률을 매우 작은 수로 설정하여 학습시키는 미세 조정 학습 두 단계로 진행하였다. 모델 최적화 알고리즘으로는 SGD, RMSprop, Adam을 적용하였다. 실험 결과는 RMSprop 알고리즘이 적용된 DenseNet CNN 모델이 98.63%의 정확도로 가장 우수한 결과를 보였다.","Tomato crops are highly affected by tomato diseases, and if not prevented, a disease can cause severe losses for the agricultural economy. Therefore, there is a need for a system that quickly and accurately diagnoses various tomato diseases. In this paper, we propose a system that classifies nine diseases as well as healthy tomato plants by applying various pretrained deep learning-based CNN models trained on an ImageNet dataset. The tomato leaf image dataset obtained from PlantVillage is provided as input to ResNet, Xception, and DenseNet, which have deep learning-based CNN architectures. The proposed models were constructed by adding a top-level classifier to the basic CNN model, and they were trained by applying a 5-fold cross-validation strategy. All three of the proposed models were trained in two stages: transfer learning (which freezes the layers of the basic CNN model and then trains only the top-level classifiers), and fine-tuned learning (which sets the learning rate to a very small number and trains after unfreezing basic CNN layers). SGD, RMSprop, and Adam were applied as optimization algorithms. The experimental results show that the DenseNet CNN model to which the RMSprop algorithm was applied output the best results, with 98.63% accuracy."
딥러닝을 이용한 마스크 착용 여부 검사 시스템,2021,[],국문 초록 정보 없음,"Recently, due to COVID-19, studies have been popularly worked to apply neural network to mask wearing automatic detection system. For applying neural networks, the 1-stage detection or 2-stage detection methods are used, and if data are not sufficiently collected, the pretrained neural network models are studied by applying fine-tuning techniques. In this paper, the system is consisted of 2-stage detection method that contain MTCNN model for face recognition and ResNet model for mask detection. The mask detector was experimented by applying five ResNet models to improve accuracy and fps in various environments. Training data used 17,217 images that collected using web crawler, and for inference, we used 1,913 images and two one-minute videos respectively. The experiment showed a high accuracy of 96.39% for images and 92.98% for video, and the speed of inference for video was 10.78fps."
전이학습기반 앙상블 딥러닝을 이용한 COVID-19 환자 영상 분류,2021,"['딥러닝', '스태킹 앙상블', '전이학습', 'X-ray/CT 영상', 'COVID-19', 'deep learning', 'stacking ensemble', 'transfer learning', 'X-ray/CT image']","COVID-19 팬데믹으로 인한 피해는 공중 보건적 측면 뿐 만 아니라 정치, 경제, 사회, 문화 전반에 심각한 영향을 미치고 있다. 현재까지 COVID-19 표준 진단검사인 RT-PCR 검사는 검체의 종류, 검체 채취 방법 및 보관에 따라 검사 결과가 달라질 수 있고 코로나바이러스 (SARS-CoV-2) 감염 후 검사 시점에도 영향을 받는다. 본 논문은 전이학습 (transfer learning) 기반 앙상블 딥러닝을 사용하여 COVID-19 환자 X-ray/CT 영상을 분류하고자 한다. 여기서 사용된 전이학습은 CNN (convolutional neural network) 기반인 AlexNet, ResNet, Inception V3, DenseNet 모형이다. 본 연구에서 제안한 스태킹 앙상블 (stacking ensemble) 모형은 세 단계에 걸쳐 이루어진다. 첫 번째 단계에서는 기본모형 (base model)로서 여러 전이학습 모형을 이용하여 예측된 결과들을 얻고, 두 번째 단계에서는 concatenate layer를 통해 이들 결과들을 결합한 다음, 세 번째 단계에서는 메타모형(meta model), 여기서는 DNN (deep neural network) 모형을 적용하여 최종 분류한다. 본 논문에서 제안된 앙상블 모형의 성능평가를 위해 3가지 실제 COVID-19 환자의 X-ray/CT 영상데이터셋을 고려하였으며 여러 가지 성능평가 지표를 가지고 기존의 전이학습 모형과 앙상블 모형과 비교 분석하였다. 성능실험결과, 전반적으로 제안된 앙상블 모형이 기존의 전이학습 모형과 앙상블 모형보다 우수함을 보였다.","The damage caused by the COVID-19 pandemic has a serious impact not only on public health but also on politics, economy, society, and culture as a whole. To date, the RT-PCR test, a COVID-19 standard diagnostic test, may vary depending on the type of sample, sample collection method, and storage, and is also affected by the time of the test after infection with COVID-19. This paper attempts to classify COVID-19 patients with X-ray/CT images using transfer learning-based ensemble deep learning. The transfer learning used here is the AlexNet, ResNet, Inception V3, and DenseNet models based on the convolutional neural network (CNN). The stacking ensemble model proposed in this study takes place over three stages. In the first step, predicted results are obtained using several transfer learning models, in the second step, they are combined through a concatenate layer, and in the third step, a deep neural network (DNN) model is applied and finally classified. For the performance evaluation of the ensemble model proposed in this paper, three actual COVID-19 X-ray/CT image datasets were considered, and various performance evaluation indicators were compared and analyzed with the transfer learning model and the existing ensemble model. As a result of the performance experiment, the overall proposed ensemble model was superior to the transfer learning model and the existing ensemble model."
영상처리와 딥러닝 네트워크를 결합한 자동차 번호판 인식시스템,2021,"['자동차 번호판 인식', '딥러닝', '영상처리 결합', '임베디드', '경량화', 'License plate recognition', 'Deep learning', 'Image processing combination', 'Embedded', 'Lightening']","자동차 번호판인식 시스템은 기존에는 영상처리만을 이용한 방식으로 매우 빠른 실시간 처리가 가능하나 다양한 번호판에는 적용하기 어렵다는 한계가 있었고, 딥러닝을 이용하는 경우 다양성과 정확성이 좋아지나 고성능의 그래픽카드가 필요하고 처리하는 데 시간이 매우 오래 걸리는 문제점이 있었다. 본 논문은 각 방식의 장점을 살려 그래픽카드가 없는 일반 사무용 PC에서도 실시간 처리가 가능하며 높은 정확성을 가진 자동차 번호판인식 시스템을 제안하며 더 나아가 사무용 PC가 아닌 임베디드 환경에서도 사용할 수 있도록 경량화한 시스템을 제안한다. 제안하는 시스템은 기존의 번호판인식 시스템과 동일하게 [번호판검출]-[문자영역 분할]-[문자인식]의 3단계 과정을 거치며 각 과정에는 딥러닝 모델로서는 SSD-MobileNet, ResNet 네트워크를 사용하였고, 영상처리 기법으로는 Edge를 검출한 후 수직, 수평으로 전파하면서 관심 영역을 찾는 CLNF 알고리즘을 사용하였다. 제안하는 시스템으로 지하주차장 및 톨게이트 등의 장소에서 얻은 4,389장의 이미지로 테스트하였을 때 충분히 레이어가 깊은 경우 98.2% 정확성을 보여 주었고, 레이어가 얕아질수록 영상처리 결합 여부에 따른 정확성 차이가 커짐을 확인할 수 있었다.","In the previous vehicle license plate recognition(LPR) systems, image processing method is able to process very fast in real time, but there is a limitation that it is difficult to apply to various license plates. Deep learning enables the variety and accuracy of LPR to be good, but ir reauires high-performance graphic cards and very long time processing time. In order to get around the advantages and disadvantages of both approaches, this paper proposes a light-weight vehicle license plate recognition system that can be processed in real time even using an embedded board or a general office PC without graphic cards. The proposed system consists of the three steps [license plate detection]-[character segmentation]-[character recognition] in the same with the conventional license plate recognition system. For each step, SSD-MobileNet and ResNet networks were used as deep learning models. As an image processing technique, the CLNF algorithm was used to detect an edge and to propagate vertically and horizontally for finding an ROI(region of interest). In the experiments for testing of the proposed system using 4,389 images obtained at places such as underground parking lots and toll gates, the accuracy was 98.2%. As the layer became shallower, the accuracy difference according to the image processing combination was bigger."
딥러닝을 활용한 가정 에너지 사용량 데이터로부터 재실자 행동 패턴 식별,2021,[],"재실자 행동(설정온도, 환기, 조명 조절 등)은 건물 에너지 사용량에 큰 영향을 미치며, 실제 사용량과 시뮬레이션 예측의 차이(Performance gap)를 유발한다. 최근 건물 시뮬레이션 학계는 데이터 기반 재실자 행동 모델을 개발하려는 노력이 활발하다. 재실자 행동 모델 개발을 위해서는 냉방 설정 온도, 냉방 개시 온도, 창문 개폐 등의 데이터 수집이 필요하지만, 이러한 데이터는 사생활 침해, 센서 설치 등의 문제로 수집이 쉽지 않다. 본 연구에서는 가정 전기 사용량 데이터에서 재실자 행동 패턴을 식별하는 딥러닝 기반 방법론을 제안한다. 서울 공동 주택 건물의 한 세대를 대상으로 동적 건물 시뮬레이션 툴인 EnergyPlus로 모델링 하였다. 실내 환경에 따른 3가지 재실자 행동 패턴(냉방 설정 온도[˚C], 냉방 개시 온도[˚C], 실내 CO<sub>2</sub> 농도[ppm]에 따른 창문 개폐)을 건물 에너지 모델과 연동하여 42,000개 샘플을 생성하였다. 생성된 데이터 셋으로 ResNet(Residual network) 모델을 훈련하고 검증하였다. 개발된 ResNet 모델은 시간별 전기 사용량 데이터로부터 재실자 행동 패턴을 충분히 정확히 식별할 수 있음을 보였다(정확도 = 86.5%).",다국어 초록 정보 없음
마이크로스코프 이미지의 딥러닝 기반 이상검출,2021,"['딥러닝', '마이크로스코프', '이상검출', '흡연', '혓바닥', 'abnormal detection', 'deep learning', 'microscope', 'tongue surface', 'smoke']","흡연자 중에서 담배가 인체에 유해하다는 사실을 모르는 사람은 없을 것임에도 불구하고, 정작 금연 성공률은 높지 않다. 금연을 위한 의지를 지속적으로 굳건하게 다지기 위하여 병원에서 실시하는 건강검진과 PET(positron emission tomography) 이미지를 통한 암 검사의 결과가 도움이 되지만, 일상생활 중에 간단히 실시할 수 있는 방법이 아니다. 본 연구에서는 일상생활 중에 관찰 가능한 흡연자의 신체 부위를 딥러닝 기반 마이크로스코프 이미지 측정 및 분석을 통하여 흡연자와 비흡연자의 차이를 검출할 수 있는 비침습적 방법을 제안하였다. 우선, 관찰 부위를 흡연시 직접적인 접촉을 하는 혓바닥 표면으로 설정하였다. 다음으로, 마이크로스코프로 혓바닥 표면(410배 확대)을 흡연자 10명과 비흡연자 10명의 실험 참가자를 통하여 데이터 셋(총 1,000장)을 구축하여 그 중 80%를 딥러닝 모델의 학습에 사용하였고, 나머지 20%는 예측에 사용하였다. 딥러닝 모델을 스케일링하는 방법(width scaling, depth scaling, resolution scaling) 중 한 가지 방법만 적용하는 VGG, ResNet, DenseNet과 세 가지를 모두 적용하여 스케일링하는 EfficientNet의 성능을 비교하여 모세혈관 이미지 처리에 EfficientNet의 우수성을 확인해 볼 수 있었다.","The success rate of the no-smoking campaign has been low, although everybody knows that cigarettes are harmful to the human health. The results of both regular health and cancer checks in the hospital are useful for strengthening the human intention for quitting the smoking, however, those methods are difficult to use in daily life because of the use of large-scaled particular devices such as PET(positron emission tomography). Thus, this study proposed a non-invasive method that detects the difference between smokers and non-smokers through deep-learning-based analysis. At first, observing parts were decided to the tongue surface. Then, a data set(total 1,000) was made through the experiment to measure the tongue surface(410 times magnification) with the participants of 10 smokers and 10 non-smokers. The 80% ratio of data set was used for the train, and the left 20% was for the prediction. As a result, it was found that the classification through EfficientNet with the compound scaling including three scaling methods of width scaling, depth scaling and resolution scaling was much better than other models including VGG, ResNet, and DenseNet with the only one scaling."
적응형 이진화와 Convex Hull 전처리 및 합성곱 신경망 학습 방법을 적용한 고무 오링 불량 판별,2021,"['Defection detect', 'Resnet-50', 'Pre-processing', 'Adaptive binarization', 'Convex hull algorithm']",고무 오링은 일반적인 사출 성형 방식으로 생산된다. 이때 정상적으로 성형되지 않은 제품은 무조건 불량으로 판별한다. 그러나 영상기반 판독 시 획득한 영상을 원본 그대로 판독할 경우 정확도가 떨어지는 문제가 발생한다. 이에 획득한 영상을 적응형 이진화와 Convex Hull 알고리즘을 사용한 전처리를 통해 원본영상에서 고무 오링 부분만 추출하여 합성곱 신경망에 학습하였다. 테스트 과정에서 제안하는 전처리를 적용한 학습방법의 불량검출 성능이 제시한 기준치 보다 나은 성능을 보이는 것을 확인할 수 있었다.,"Rubber o-rings are produced by conventional injection molding methods. In this case, products that are not normally molded are determined to be defective. However, if images acquired during image-based reading are read as original, there is a problem of poor accuracy. We have thus learned from convolutional neural networks using adaptive binarization and Convex Hull algorithms by extracting only rubber oring parts from the original images through pre-processing. During the test process, it was confirmed that the defect detection performance of the learning method applied pre-processing was better than the standard suggested."
학습을 이용한 영상 분류 방법,2021,"['변환학습(transform learning)', 'ImageNet', 'ResNet']",국문 초록 정보 없음,다국어 초록 정보 없음
심전도 신호 분류를 위한 1D CNN 모델 구성 요소의 최적화,2021,"['Deep learning', 'Electrocardiogram', 'CNN', 'ResNet', 'Arrhythmia Detection', '딥러닝', '심전도', '부정맥 검출']","본 논문에서는 딥러닝 모델을 이용하여 모바일 기기의 심전도 신호 측정 데이터를 분류한다. 비정상 심장박동을 높은 정확도로 분류하기 위해 딥러닝 모델의 구성 요소 세 가지를 선정하고 요소의 조건 변화에 따른 분류 정확도를 비교한다. 심전도 신호 데이터의 특징을 스스로 추출할 수 있는 CNN 모델을 적용하고 모델을 구성하는 모델의 깊이, 최적화 방법, 활성화 함수의 조건을 변경하여 총 48개의 조합의 성능을 비교한다. 가장 높은 정확도를 보이는 조건의 조합을 도출한 결과 컨볼루션 레이어 19개, 최적화 방법 SGD, 활성화 함수 Mish를 적용하였을 때 정확도 97.88%로 모든 조합 중 가장 높은 분류 정확도를 얻었다. 이 실험에서 CNN을 활용한 1-채널 심전도 신호의 특징 추출과 비정상 박동 검출의 적합성을 확인하였다.","In this paper, we classify ECG signal data for mobile devices using deep learning models. To classify abnormal heartbeats with high accuracy, three factors of the deep learning model are selected, and the classification accuracy is compared according to the changes in the conditions of the factors. We apply a CNN model that can self-extract features of ECG data and compare the performance of a total of 48 combinations by combining conditions of the depth of model, optimization method, and activation functions that compose the model. Deriving the combination of conditions with the highest accuracy, we obtained the highest classification accuracy of 97.88% when we applied 19 convolutional layers, an optimization method SGD, and an activation function Mish. In this experiment, we confirmed the suitability of feature extraction and abnormal beat detection of 1-channel ECG signals using CNN."
Generating 3D texture models of vessel pipes using 2D texture transferred by object recognition,2021,"['augmented reality', 'CycleGAN', 'ResNet', 'normalization', 'texture', '3D model']",국문 초록 정보 없음,"Research and development of smart vessels has progressed significantly in recent years, and ships have become high-value technology-intensive resources. These ships entail high production costs and long-life cycles. Thus, modernized technical design, professional training, and aggressive maintenance are important factors in the efficient management of ships. With the continuing digital revolution, the industrial shipbuilding applicability of augmented reality (AR) and virtual reality (VR) technologies as well as related 3D system modeling and processes has increased. However, resolving the differences between AR/VR and real-world models remains burdensome. This problem is particularly evident when mapping various texture characteristics to virtual objects. To mitigate the burden and improve the performance of such technologies, it is necessary to directly define various texture characteristics or to express them using expensive equipment. The use of deep-learning-based CycleGAN, however, has gained attention as a method of learning and automatically mapping real-object textures. Thus, we seek to use CycleGAN to improve the immersive capacities of AR/VR models and to reduce production costs for shipbuilding. However, when applying CycleGAN’s textures to pipe structures, the performance is insufficient for direct application to industrial piping networks. Therefore, this study investigates an improved CycleGAN algorithm that can be specifically applied to the shipbuilding industry by combining a modified object-recognition algorithm with a double normalization method. Thus, we demonstrate that basic knowledge on the production of AR industrial pipe models can be applied to virtual models through machine learning to deliver low-cost and high-quality textures. Our results provide an on-ramp for future CycleGAN studies related to the shipbuilding industry."
MRI 이미지 기반의 알츠하이머 치매분류 알고리즘,2021,"['Alzheimer’s disease', 'Resnet-50', 'Classification modeling', 'Activation', 'Pre-processing']","최근 고령화 사회가 지속됨에 따라, 치매(Dementia)에 대한 관심이 높아지고 있다. 그 중에서 알츠하이머병(Alzheimer’s disease)는 전체 치매 환자의 50~60%로 가장 많은 비율을 차지하는 퇴행성 뇌질환으로, 현재 의료계에선 알츠하이머병에 대한 명확한 예방법 및 치료법에 대해 내놓지 못하고 있으며, 치매 발병 전 조기 치료 및 조기 예방법에 대한 중요성이 강조되고 있다. 본 논문에서는 정상인과 알츠하이머병에 걸린 환자의 MRI 데이터셋을 활용하여 컨볼루션 신경망을 중심으로 여러 가지 활성화 함수를 접목시켜, 가장 효율적인 활성화 함수를 찾고자 한다. 또한 알츠하이머 치매분류 모델링을 통해 향후 의료분야에 적합한 치매 구분 모델링으로 활용하고자 한다.","As the aging society continues in recent years, interest in dementia is increasing. Among them, Alzheimer’s disease is a degenerative brain disease that accounts for the largest percentage of all dementia patients, with the medical community currently not offering clear prevention and treatment for Alzheimer’s disease, and the importance of early treatment and early prevention is emphasized. In this paper, we intend to find the most efficient activation function by combining various activation functions centering on convolutional neural networks using MRI datasets of normal people and patients with Alzheimer’s disease. In addition, it is intended to be used as a dementia classification modeling suitable for the medical field in the future through Alzheimer’s dementia classification modeling."
딥러닝 기반의 PCB 부품 문자인식을 위한 코어 셋 구성,2021,"['Deep Learning', 'Coreset', 'PCB Inspection', 'OCR', 'ResNet']",국문 초록 정보 없음,다국어 초록 정보 없음
CycleGAN을 이용한 감자 병충해 이미지 생성 방안,2021,"['potato crops', 'potato pests', 'CycleGAN', 'Resnet-50']",국문 초록 정보 없음,다국어 초록 정보 없음
Neural Network Based Simulation of Poisson Boltzmann Equation,2021,"['Poisson Boltzmann equation', 'Neural network', 'ResNet', 'Finite Element Method']","본 논문에서 뉴럴 네트워크를 활용하여 포아즌 볼츠만 방정식을 푸는 방법을 소개하려 한다. 기존의 유한요소방법을 사용하여 샘플을 생성하고, 생성된 샘플을 이용하여 뉴럴 네트워크를 훈련시킨다. 결과적으로 얻어진 뉴럴 네트워크의 성능을 소개한다.","This work introduces neural network based simulation for Poisson Boltzmann equation. First, samples are generated via a finite element method, whose pairs are used to train neural network. We report the performance of the neural network."
한글 폰트 인식을 위한 데이터 수집 및 분류 기법 적용,2021,"['Font Recognition', 'CNN', 'Deep Learning', 'LeNet', 'ResNet']","딥러닝의 여러 모델 중 이미지 인식과 관련된 CNN(Convolutional Neural Network)을 기반으로 한 심층학습이 다양한 분야에서 진행되고 있다. 최근 COVID-19 상황으로 인한 비대면 방식의 수업 및 업무가 활성화되면서 디지털 문서 사용량이 많아지는 추세이다. 이에 따라 폰트에 대한 관심도와 종류도 증가하면서 분류 체계의 필요성도 늘어나고 있다. 본 논문에서는 한글 폰트 인식을 위한 데이터를 분석하고, 대표적인 CNN 모델들을 적용하여 폰트 인식성능을 테스트한다. 그리고 인식성능 향상 및 확대 데이터 구축을 위한 방법론을 제안한다.","Among the various models of deep learning, deep learning based on CNN(Convolutional Neural Network) related to image recognition is in progress in various fields. Recently, as non-face-to-face classes and work have been activated due to the COVID-19 situation, the use of digital documents is increasing. Accordingly, as the interest and types of fonts increase, the need for a classification system is also increasing. In this paper, we analyze the data for Korean font recognition and test the font recognition performance by applying representative CNN models. And we propose a methodology for improving recognition performance and constructing expanded data."
자궁경부 영상에서의 라디오믹스 기반 판독 불가 영상 분류 알고리즘 연구,2021,"['Cervical cancer', 'Radiomics', 'Laplacian variance', 'Euclidean distance', 'ResNet-50']",국문 초록 정보 없음,"Recently, artificial intelligence for diagnosis system of obstetric diseases have been actively studied. Artificial intelligence diagnostic assist systems, which support medical diagnosis benefits of efficiency and accuracy, may experience problems of poor learning accuracy and reliability when inappropriate images are the model's input data. For this reason, before learning, We proposed an algorithm to exclude unread cervical imaging. 2,000 images of read cervical imaging and 257 images of unread cervical imaging were used for this study. Experiments were conducted based on the statistical method Radiomics to extract feature values of the entire images for classification of unread images from the entire images and to obtain a range of read threshold values. The degree to which brightness, blur, and cervical regions were photographed adequately in the image was determined as classification indicators. We compared the classification performance by learning read cervical imaging classified by the algorithm proposed in this paper and unread cervical imaging for deep learning classification model. We evaluate the classification accuracy for unread Cervical imaging of the algorithm by comparing the performance. Images for the algorithm showed higher accuracy of 91.6% on average. It is expected that the algorithm proposed in this paper will improve reliability by effectively excluding unread cervical imaging and ultimately reducing errors in artificial intelligence diagnosis."
데이터 분석을 통한 지역별 고령친화도 시각화,2021,"['고령친화도시', '인구고령화', '지표', 'GIS', 'Smart Farm', 'Deep Learning', 'ResNet', 'Convolution Neural Network']","전 세계적인 인구고령화 현상이 사회적으로 문제가 되고 있다. 우리나라 역시 초고령화 사회에 급속도로 진입하면서 사회적 생활공간의 실질적 변화가 필요하게 되었다. 이에 본 연구에서는 WHO가 제시한 ‘고령친화도시’ 개념과 가이드라인을 중심으로 군집분석과 EDA를 활용해 국내 고령친화도 현황을 분석하였다. 더불어 경기도의 이천시와 안성시를 중심으로 관련 데이터를 비교·분석 후 GIS 기반 데이터 시각화를 수행하였다. 분석 결과 B등급인 이천시에 비교하여 안성시의 고령친화도는 인구, 면적 등의 조건이 비슷함에도 불구하고 D등급으로 측정되어 매우 낮은 것으로 나타났다. 본 연구의 결과를 통해 정책적으로는 전국 단위의 고령친화도를 파악하여 효과적인 복지 정책 가이드라인 제시와 더불어, 한정된 정부예산에서 정비가 시급한 부분에 대한 우선적 고려가 가능할 것으로 기대된다.","The population aging around the world is becoming a social problem. As Korea also entered a super-aged society rapidly, a substantial change in social living space became necessary. Therefore, this study analyzes the current status of elderly affinity in Korea using cluster analysis and EDA, focusing on the WHO's concept of ‘aged-friendly city’ and eight area guidelines. In addition, GIS-based data visualization carries after comparing and analyzing related data, centering on Icheon and Anseong in Gyeonggi province. As a result of the analysis, compared to Icheon, which is grade B, the elderly affinity of Anseong was measured as grade D despite similar conditions such as population and area. Through the results of this study, it is expected that it will be possible to identify the relative Age-Friendliness the country in terms of policy, present effective welfare policy guidelines, and prioritize areas where maintenance is urgent in the limited government budget"
A comparative study of deep convolutional neural networks for dicentric chromosome image identification,2021,"['automated dicentric chromosome scoring', 'convolutional neural network', 'VGG19', 'ResNet', 'biological dosimetry']",국문 초록 정보 없음,다국어 초록 정보 없음
Proper Base-model and Optimizer Combination Improves Transfer Learning Performance for Ultrasound Breast Cancer Classification,2021,"['Transfer learning', 'breast cancer', 'ultrasound', 'classification', 'EfficientNetB2', 'Adam']","인공지능 알고리즘을 이용한 유방암의 조기진단에 관련된 연구는 최근들어 활발하게 진행되고 있으나, 사용자의 목적에 맞는 처리속도 및 정확도 등에 다양한 한계점을 보인다. 이러한 문제를 해결하기 위해, 본 논문에서는 ImageNet에서 학습된 ResNet 모델을 현미경 기반 암세포 이미지에서 활용이 가능한 다단계 전이 학습을 제안하고, 이를 다시 전이 학습하여 초음파 유방암 영상을 양성 및 악성으로 분류하는 실험을 진행하였다. 제안된 다단계 전이 학습 알고리즘은 초음파 유방암 영상을 분류하였을 때 96% 이상의 정확도를 보였으며, 향후 암 세포주 및 실시간 영상처리 등의 추가를 통해 보다 높은 활용도와 정확도를 보일 것으로 기대한다.","It is challenging to find breast ultrasound image training dataset to develop an accurate machine learning model due to various regulations, personal information issues, and expensiveness of acquiring the images. However, studies targeting transfer learning for ultrasound breast cancer images classification have not been able to achieve high performance compared to radiologists. Here, we propose an improved transfer learning model for ultrasound breast cancer classification using publicly available dataset. We argue that with a proper combination of ImageNet pre-trained model and optimizer, a better performing model for ultrasound breast cancer image classification can be achieved. The proposed model provided a preliminary test accuracy of 99.5%. With more experiments involving various hyperparameters, the model is expected to achieve higher performance when subjected to new instances."
Deep Convolutional Neural Network Architectures for Tonal Frequency Identification in a Lofargram,2021,"['Convolutional neural networks', 'lofar analysis', 'sonar analysis', 'underwater recognition.']",국문 초록 정보 없음,"Advances in convolutional neural networks (CNNs) have driven the development of computer vision. Recent CNN architectures, such as those with skip residual connections (ResNets) or densely connected architectures (DenseNets), have facilitated backpropagation and improved the performance of feature extraction and classification. Detecting objects in underwater environments by analyzing sound navigation and ranging (sonar) signals is considered an important process that should be automated. Several previous approaches have addressed this challenge; however, there has been no in-depth study of CNN architectures that effectively analyze sonar grams. In this paper, we have presented the identification of tonal frequencies in lofargrams using recent CNN architectures. Our study includes 175 CNN models that are derived from five different CNN architectures and 35 different input patch sizes. The study results showed that the accuracy of the best model was as high as 96.2% for precision and 99.5% for recall, with an inference time of 0.184 s."
LDAM 손실 함수를 활용한 클래스 불균형 상황에서의 옷차림 T.P.O 추론 모델 학습,2021,"['융합', '패션', 'T.P.O', '다중 레이블', '클래스 불균형', '딥러닝', 'Convergence', 'Fashion', 'T.P.O', 'Multi-label problem', 'Class imbalance problem', 'Deep learning']","의복을 착용하는데 있어 목적 상황에 부합하는 옷차림을 구성하는 것은 중요하다. 따라서 인공지능 기반의 다양 한 패션 추천 시스템에서 의복 착용의 T.P.O(Time, Place, Occasion)를 고려하고 있다. 하지만 옷차림으로부터 직접 T.P.O를 추론하는 연구는 많지 않은데, 이는 문제 특성 상 다중 레이블 및 클래스 불균형 문제가 발생하여 모델 학습을 어렵게 하기 때문이다. 이에 본 연구에서는 label-distribution-aware margin(LDAM) loss를 도입하여 옷차림의 T.P.O를 추론할 수 있는 모델을 제안한다. 모델의 학습 및 평가를 위한 데이터셋은 패션 쇼핑몰로부터 수집되었고 이를 바탕으로 성능을 측정한 결과, 제안 모델은 비교 모델 대비 모든 T.P.O 클래스에서 균형잡힌 성능을 보여주는 것을 확인할 수 있었다.","When a person wears clothing, it is important to configure an outfit appropriate to the intended occasion. Therefore, T.P.O(Time, Place, Occasion) of the outfit is considered in various fashion recommendation systems based on artificial intelligence. However, there are few studies that directly infer the T.P.O from outfit images, as the nature of the problem causes multi-label and class imbalance problems, which makes model training challenging. Therefore, in this study, we propose a model that can infer the T.P.O of outfit images by employing a label-distribution-aware margin(LDAM) loss function. Datasets for the model training and evaluation were collected from fashion shopping malls. As a result of measuring performance, it was confirmed that the proposed model showed balanced performance in all T.P.O classes compared to baselines."
360 카메라를 이용한 디지털 트윈 강의실,2021,[],"본 논문에서는 딥러닝 얼굴 인식을 이용하여 실시간 360 공간 Classroom 과 실시간을 기반으로 한 가상 360 공간 Classroom 을 제안한다. MTCNN 을 이용한 얼굴 검출 및 Inception Resnet V1 모델을 이용한 딥러닝 기법을 통해 얼굴인식을 진행하고 HSV 색공간 기반의 화자 판별, 아바타 Rendering, 출석 체크 등을 진행한다. 이후 시각화를 위해 제작한 Web UI/UX 를 통해 사용자에게 현실과 가상 공간을 넘나드는 Twin Classroom 을 제공한다. 따라서 사용자는 새로운 화상 교육 플랫폼에서 보다 개선되고 생동감 있는 Classroom 에서 교육을 받을 수 있다.",다국어 초록 정보 없음
Image Scene Classification of Multiclass,2021,"['multiclass image scene classification method', 'transform learning', 'Kaggle', 'ImageNet']",국문 초록 정보 없음,"In this paper, we proposed a multiclass image scene classification method based on transform learning. It relied on a pre-trained network model on the ImageNet large image dataset to classify multiclass of natural scene images. In the experiment, the optimized the ResNet model was classified on Kaggle""s Intel Image Classification dataset and achieved excellent results."
투사적 그림검사 분야로의 트랜스포머 기반의 이미지 분류 모델 적용에 관한 연구,2021,"['미술치료', '인간과 컴퓨터 상호작용', '딥러닝', '이미지 분류', '트랜스포머']","본 논문에서는 심리진단을 위한 그림검사(Drawing Test) 과정에서 미술치료사의 객관적인 의사결정을 지원하기 위한 이미지 분류 모델인 VQ-ViT(Vector Quantization-Vision Transformer)을 제안한다. 사전학습을 위해 대규모의 레이블링 데이터셋이 필요한 기존의 이미지 분류 모델(e.g., Resnet, Vision Transformer)에 비해 VQ-ViT는 레이블링되지 않은 데이터에 대하여 비지도학습으로 임베딩을 진행한다. 우리는 CIFAR-10, TU-Berlin 그리고 직접 수집한 빗 속의 사람 그림 검사(PITR, Person-In-The-Rain) 데이터셋에 대하여 VQ-ViT와 기존의 이미지 분류 모델들과의 성능 비교실험을 진행하였다. 그 결과 VQ-ViT는 비지도 학습의 이미지 임베딩 기법과 적은 파라미터 수로 그림검사 분야에서의 발전 가능성을 보였다. 이를 기반으로 우리는 딥러닝 기반의 이미지 분류 모델의 한계점 파악 및 발전 방향을 논의한다.",다국어 초록 정보 없음
자동화 균열 탐지 시스템을 위한 딥러닝 모델에 관한 연구,2021,"['Surface Inspection', 'Crack Detection', 'Computer Vision', 'Deep Learning', '표면 검사', '균열 탐지', '컴퓨터 비전', '딥러닝']",국문 초록 정보 없음,"Cracks affect the robustness of infrastructures such as buildings, bridge, pavement, and pipelines. This paper presents an automatedcrack detection system which detect cracks in diverse surfaces. We first constructed the combined crack dataset, consists of multiplecrack datasets in diverse domains presented in prior studies. Then, state-of-the-art deep learning models in computer vision tasks includingVGG, ResNet, WideResNet, ResNeXt, DenseNet, and EfficientNet, were used to validate the performance of crack detection. We dividedthe combined dataset into train (80%) and test set (20%) to evaluate the employed models. DenseNet121 showed the highest accuracyat 96.20% with relatively low number of parameters compared to other models. Based on the validation procedures of the advanced deeplearning models in crack detection task, we shed light on the cost-effective automated crack detection system which can be appliedto different surfaces and structures with low computing resources."
Experimental Investigation and Machine Learning Based Prediction of Flexural Strength of Geopolymer Composites,2021,[],국문 초록 정보 없음,"In this study, the prediction and validation of flexural response of fiber reinforced geopolymer composites are investigated by experiment and machine learning approaches. The input variables, including fly ash and slag content, liquid/solid ratio, curing temperature, curing time, volume fraction, length and diameter of fibers as well as tensile strength of fiber, were used to train and validate the predicted and actual flexural strength. The proposed models artificial neural network ANN, deep neural network DNN and ResNet were successfully trained to predict and analyze the flexural strength with the highly accuracy."
Cerebral hemorrhage detection and localization with medical imaging for cerebrovascular disease diagnosis and treatment using explainable deep learning,2021,['Cerebral hemorrhage prediction · Cerebrovascular disease · Explainable artificial intelligence'],국문 초록 정보 없음,"Cerebral hemorrhages require rapid diagnosis and intensive treatment. This study aimed to detect cerebral hemorrhages and their locations in images using a deep learning model applying explainable deep learning. Normal brain images with no hemorrhages and images with subarachnoid, intraventricular, subdural, epidural, and intraparenchymal hemorrhages according to computed tomography (CT) (n = 200) were analyzed. A ResNet deep learning model, including image processing, was utilized. The visual explanation from a heatmap was made at the hemorrhage location using a gradient-class activation map (Grad-CAM). To evaluate the performance of the deep learning system, the accuracy, sensitivity, and specificity were determined. A hemorrhage prediction system for images of normal brains and brains with subarachnoid, intraventricular, subdural, epidural, and intraparenchymal hemorrhages was built. The Grad-CAM representation indicated the location of the hemorrhages in these images. In the prediction results, accurate predictions of the hemorrhage areas were made and visualizations of the corresponding locations overlapped in the images within (− 4, 1) pixel difference. The evaluation of the system performance showed an accuracy of 0.81 with a sensitivity of 0.67 and specificity of 0.86. These results constitue a proof of concept for the use of explainable artificial intelligence (XAI) to detect cerebral hemorrhages and visualize their locations in medical images, which will allow rapid diagnosis and treatment."
고성능 CNN 기반 지정맥 인증 시스템 구현,2021,"['AI', 'Biometric authentication', 'Finger vein recognizer']",국문 초록 정보 없음,"Biometric technology using finger veins is receiving a lot of attention due to its high security, convenience and accuracy. And the recent development of deep learning technology has improved the processing speed and accuracy for authentication. However, the training data is a subset of real data not in a certain order or method and the results are not constant. so the amount of data and the complexity of the artificial neural network must be considered. In this paper, the deep learning model of Inception-Resnet-v2 was used to improve the high accuracy of the finger vein recognizer and the performance of the authentication system, We compared and analyzed the performance of the deep learning model of DenseNet-201. The simulations used data from MMCBNU_6000 of Jeonbuk National University and finger vein images taken directly. There is no preprocessing for the image in the finger vein authentication system, and the results are checked through EER."
Convolutional Neural Network 기반 EBG 구조 설계를 통한 고속 PCB 노이즈 저감,2021,"['Simultaneous Switching Noise', 'Electromagnetic Band Gap', 'Machine Learning', 'Convolutional Neural Network']","기술이 빠르게 발전하여 디지털 시스템의 동작 주파수는 수 GHz 대역까지 증가했다. 이로 인하여 Simultaneous Switching Noise 문제가 증가했고, 이를 줄이기 위해 Electromagnetic Band Gap(EBG) 구조가 많이 연구된다. EBG 구조 설계에서 중요한 과정 중 하나는 노이즈를 저감하는 Stopband 대역을 예측하는 것이다. 기존에 3차원 전자장 시뮬레이션 프로그램을 이용하는 방법과 Floquet 이론 기반의 수식을 이용하는 방법이 있으나, 한계점이 존재한다. 본 논문에서는 Convolutional Neural Network(CNN)을 이용하여 EBG 구조의 Stopband 대역을 예측하는 새로운 방법을 제안한다. 또한 기본 CNN 구조, GoogLeNet, ResNet, DenseNet과 같은 CNN Architecture 모델을 활용하여 어떤 CNN 구조가 Stopband 대역 예측에 높은 성능을 보이는지 분석한다. 900개의 EBG 구조 모델에 대해서 학습시킨 후 CNN 구조의 mean absolute error를 비교한 결과, DenseNet이 가장 우수한 성능을 보임을 확인하였다.","With rapid advances in technology, the operating frequencies of digital systems have increased to several GHz bands. This has led to an increase in simultaneous switching noise(SSN). To reduce SSN, electromagnetic bandgap(EBG) structures have been intensively studied. One of the critical steps in the design of an EBG structure is to predict the stopband that reduces SSN. Existing methods include using a 3D electromagnetic field simulation program or equations based on the Floquet theory. However, these have limitations. In this study, we verified a new method for predicting the stopband using a convolutional neural network(CNN). Specifically, a CNN architectural model was used to compare structures that perform well in predicting the stopband. It was also used to confirm that the DenseNet showed high performance."
합성곱 신경망을 이용한 프로펠러 캐비테이션 침식 위험도 연구,2021,"['Convolutional Neural Network(CNN', '합성곱 신경망)', 'Deep learning(딥러닝)', 'Propeller(프로펠러)', 'Cavitation(캐비테이션)', 'Erosion(침식)']",국문 초록 정보 없음,"Cavitation erosion is one of the major factors causing damage by lowering the structural strength of the marine propeller and the risk of it has been qualitatively evaluated by each institution with their own criteria based on the experiences. In this study, in order to quantitatively evaluate the risk of cavitation erosion on the propeller, we implement a deep learning algorithm based on a convolutional neural network. We train and verify it using the model tests results, including cavitation characteristics of various ship types. Here, we adopt the validated well-known networks such as VGG, GoogLeNet, and ResNet, and the results are compared with the expert’s qualitative prediction results to confirm the feasibility of the prediction algorithm using a convolutional neural network."
자율 운항 선박을 위한 딥 러닝 기반 선박 이미지 분류 방법,2021,"['Image Classification', 'Object Detection', 'Convolutional Neural Network', 'Deep Learning', 'Heatmap', 'Autonomous Ship']",국문 초록 정보 없음,"In the last few years, researches on autonomous ships have attracted attention. One of the essential techniques required for autonomous ships is the awareness of surroundings, including detection and classification of objects. Although researches on computer vision regarding the classification of ship images are still making progress, it is challenging to encounter a lack of enough database that was adequately labeled for ship classification. In this study, data obtained from Singapore Maritime Dataset (SMD) and public datasets such as MARVEL, FleetMon, and VesselFinder were labeled and integrated into a unified dataset for further study for ship classification. The ship image dataset was classified into seven classes, including bulk carrier, container ship, cruise ship, naval surface ship, tanker, tug boat, and buoy. Subsequently, Convolutional Neural Networks (CNNs) based on GoogleNet, VGG16, and ResNet were implemented for ship image classification, and a comparative test was done. As a result, the CNNs which were trained with the unified dataset showed high accuracy. The classification results were analyzed by the heatmap visualization with Grad-CAM, which indicates critical features best activating each class of ships, and further discussion was made."
딥러닝을 이용한 핸드크림의 마찰 시계열 데이터 분류,2021,"['Time Series Classification', 'Deep Learning', 'Tribology', 'Cosmetics']",국문 초록 정보 없음,"The sensory stimulation of a cosmetic product has been deemed to be an ancillary aspect until a decade ago. That point of view has drastically changed on different levels in just a decade. Nowadays cosmetic formulators should unavoidably meet the needs of consumers who want sensory satisfaction, although they do not have much time for new product development. The selection of new products from candidate products largely depend on the panel of human sensory experts. As new product development cycle time decreases, the formulators wanted to find systematic tools that are required to filter candidate products into a short list. Traditional statistical analysis on most physical property tests for the products including tribology tests and rheology tests, do not give any sound foundation for filtering candidate products. In this paper, we suggest a deep learning-based analysis method to identify hand cream products by raw electric signals from tribological sliding test. We compare the result of the deep learning-based method using raw data as input with the results of several machine learning-based analysis methods using manually extracted features as input. Among them, ResNet that is a deep learning model proved to be the best method to identify hand cream used in the test. According to our search in the scientific reported papers, this is the first attempt for predicting test cosmetic product with only raw time-series friction data without any manual feature extraction. Automatic product identification capability without manually extracted features can be used to narrow down the list of the newly developed candidate products."
"전산화 단층 촬영(Computed tomography, CT) 이미지에 대한 EfficientNet 기반 두개내출혈 진단 및 가시화 모델 개발",2021,"['Deep-learning', 'EfficientNet', 'Intracranial hemorrhage', 'Computed tomography images']",국문 초록 정보 없음,"Intracranial hemorrhage (ICH) refers to acute bleeding inside the intracranial vault. Not only does this devastating disease record a very high mortality rate, but it can also cause serious chronic impairment of sensory, motor, and cognitive functions. Therefore, a prompt and professional diagnosis of the disease is highly critical. Noninvasive brain imaging data are essential for clinicians to efficiently diagnose the locus of brain lesion, volume of bleeding, and subsequent cortical damage, and to take clinical interventions. In particular, computed tomography (CT) images are used most often for the diagnosis of ICH. In order to diagnose ICH through CT images, not only medical specialists with a sufficient number of diagnosis experiences are required, but even when this condition is met, there are many cases where bleeding cannot be successfully detected due to factors such as low signal ratio and artifacts of the image itself. In addition, discrepancies between interpretations or even misinterpretations might exist causing critical clinical consequences. To resolve these clinical problems, we developed a diagnostic model predicting intracranial bleeding and its subtypes (intraparenchymal, intraventricular, subarachnoid, subdural, and epidural) by applying deep learning algorithms to CT images. We also constructed a visualization tool highlighting important regions in a CT image for predicting ICH. Specifically, 1) 27,758 CT brain images from RSNA were pre-processed to minimize the computational load. 2) Three different CNN-based models (ResNet, EfficientNet-B2, and EfficientNet-B7) were trained based on a training image data set. 3) Diagnosis performance of each of the three models was evaluated based on an independent test image data set: As a result of the model comparison, EfficientNet-B7's performance (classification accuracy = 91%) was a way greater than the other models. 4) Finally, based on the result of EfficientNet-B7, we visualized the lesions of internal bleeding using the Grad-CAM. Our research suggests that artificial intelligence-based diagnostic systems can help diagnose and treat brain diseases resolving various problems in clinical situations."
다중 레이블 분류를 활용한 안면 피부 질환 인식에 관한 연구,2021,"['Deep Learning', 'Multi-Label Classification', 'Skin Diseases', '딥 러닝', '다중 레이블 분류', '피부 질환']",국문 초록 정보 없음,"Recently, as people's interest in facial skin beauty has increased, research on skin disease recognition for facial skin beauty is being conducted by using deep learning. These studies recognized a variety of skin diseases, including acne. Existing studies can recognize only the single skin diseases, but skin diseases that occur on the face can enact in a more diverse and complex manner. Therefore, in this paper, complex skin diseases such as acne, blackheads, freckles, age spots, normal skin, and whiteheads are identified using the Inception-ResNet V2 deep learning mode with multi-label classification. The accuracy was 98.8%, hamming loss was 0.003, and precision, recall, F1-Score achieved 96.6% or more for each single class."
