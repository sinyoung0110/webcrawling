title,date,keywords,abstract,multilingual_abstract
ResNet-Variational AutoEncoder기반 변종 악성코드 패밀리 분류 연구,2021,"['변종 악성코드', '악성코드 분류', '변이 오토인코더', '전이학습', '앙상블 학습', 'Variant Malware', 'Malware Classification', 'Variational AutoEncoder', 'Tranfer Learning', 'Ensemble Learning']",전통적으로 대부분의 악성코드는 도메인 전문가에 의해 추출된 특징 정보를 활용하여 분석되었다. 하지만 이러한 특징 기반의 분석방식은 분석가의 역량에 의존적이며 기존의 악성코드를 변형한 변종 악성코드를 탐지하는 데 한계를 가지고 있다. 본 연구에서는 도메인 전문가의 개입 없이도 변종 악성코드의 패밀리를 분류할 수 있는 ResNet-Variational AutoEncder 기반 변종 악성코드 분류 방법을 제안한다. Variational AutoEncoder 네트워크는 입력값으로 제공되는 훈련 데이터의 학습 과정에서 데이터의 특징을 잘 이해하며 정규 분포 내에서 새로운 데이터를 생성하는 특징을 가지고 있다. 본 연구에서는 Variational AutoEncoder의 학습 과정에서 잠재 변수를 추출을 통해 악성코드의 중요 특징을 추출할 수 있었다. 또한 훈련 데이터의 특징을 더욱 잘 학습하고 학습의 효율성을 높이기 위해 전이 학습을 수행했다. ImageNet Dataset으로 사전학습된 ResNet-152 모델의 학습 파라미터를 Encoder Network의 학습 파라미터로 전이했다. 전이학습을 수행한 ResNet-Variational AutoEncoder의 경우 기존 Variational AutoEncoder에 비해 높은 성능을 보였으며 학습의 효율성을 제공하였다. 한편 변종 악성코드 분류를 위한 방법으로는 앙상블 모델인 Stacking Classifier가 사용되었다. ResNet-VAE 모델의 Encoder Network로 추출한 변종 악성코드 특징 데이터를 바탕으로 Stacking Classifier를 학습한 결과 98.66%의 Accuracy와 98.68의 F1-Score를 얻을 수 있었다.,"Traditionally, most malicious codes have been analyzed using feature information extracted by domain experts. However, this feature-based analysis method depends on the analyst's capabilities and has limitations in detecting variant malicious codes that have modified existing malicious codes. In this study, we propose a ResNet-Variational AutoEncder-based variant malware classification method that can classify a family of variant malware without domain expert intervention. The Variational AutoEncoder network has the characteristics of creating new data within a normal distribution and understanding the characteristics of the data well in the learning process of training data provided as input values. In this study, important features of malicious code could be extracted by extracting latent variables in the learning process of Variational AutoEncoder. In addition, transfer learning was performed to better learn the characteristics of the training data and increase the efficiency of learning. The learning parameters of the ResNet-152 model pre-trained with the ImageNet Dataset were transferred to the learning parameters of the Encoder Network. The ResNet-Variational AutoEncoder that performed transfer learning showed higher performance than the existing Variational AutoEncoder and provided learning efficiency. Meanwhile, an ensemble model, Stacking Classifier, was used as a method for classifying variant malicious codes. As a result of learning the Stacking Classifier based on the characteristic data of the variant malware extracted by the Encoder Network of the ResNet-VAE model, an accuracy of 98.66% and an F1-Score of 98.68 were obtained."
복소수 ResNet 네트워크 기반의 SAR 영상 물체 인식 알고리즘,2021,[],,"Unlike optical equipment, SAR(Synthetic Aperture Radar) has the advantage of obtaining images in all weather, and object detection in SAR images is an important issue. Generally, deep learning-based object detection was mainly performed in real-valued network using only amplitude of SAR image. Since the SAR image is complex data consist of amplitude and phase data, a complex-valued network is required. In this paper, a complex-valued ResNet network is proposed. SAR image object detection was performed by combining the ROI transformer detector specialized for aerial image detection and the proposed complex-valued ResNet. It was confirmed that higher accuracy was obtained in complex-valued network than in existing real-valued network."
ResNet 정확도 향상을 위한 깊이별 Residual Connection 비율 조절 방법 제안,2021,"['ResNet', 'Residual Connection', 'Residual Learning', 'Variational Scaling', 'Degradation']","ResNet은 residual learning으로 학습 최적화를 용이하게 만들어 gradient vanishing과 상관없이 신경망이 깊어질 때 성능이 하락하는 degradation 문제를 해결한다. 하지만 기존 ResNet에서는 모든 residual block에 동일한 비율로 residual connection을 적용하여 residual learning의 최적화 효과를 극대화하지 못하는 한계가 있다. 따라서 본 논문에서는 residual learning의 최적화 효과를 극대화하기 위해 깊이 별 residual connection 비율을 달리하여 ResNet 정확도를 향상시키는 variational scaling 방법을 제안한다. 성능을 검증하기 위해 두가지 다른 데이터셋인 CIFAR-10과 CIFAR-100에서 다른 깊이를 갖는 ResNet-32, ResNet-56를 사용해 실험을 수행한다. 실험 결과 모든 케이스에서 기존 ResNet과 비교하여 연산량 증가 없이 정확도 향상을 이룬다.","ResNet resolves a degradation problem by residual learning which allows ease to the learning optimization. However, original ResNet has such a limitation that do not maximize the optimization of residual learning by applying residual connections with the constant scale. This paper suggests a variational scaling method that adjusts scales of residual connection by depth in order to maximize the optimization effect of residual learning hence to enhance the model accuracy. Experiments are conducted in two different datasets CIFAR-10 and CIFAR-100, and with 2 models with different depth, ResNet –32 and ResNet-56. As the result of experiments, the variational scaling method enhanced accuracy without the computational amount increased compared to the original ResNet in all cases."
ResNet-합성곱 오토인코더 기반 신경망을 이용한 스펙트럼 데이터 압축,2021,"['Data Compression', 'PCA', 'Autoencoder', 'ResNet', 'Raman Spectrum']","본 논문에서는 스펙트럼 저장 시 데이터용량을 줄이기 위해 합성곱 오토인코더(convolutional autoencoder) 구조에 ResNet(Residual Neural Network) 알고리즘을 적용한 스펙트럼 데이터 압축 신경망을 제안한다. 최근 분광법(spectroscopy)의 적용 분야가 넓어짐에 따라 스펙트럼 데이터베이스가 대용량화되어 효율적인 전송이 어렵고 많은 저장 공간을 필요로 한다. 이러한 대용량의 데이터베이스를 효율적으로 관리하기 위해 데이터 압축을 수행한다. 기존 데이터 압축에 주로 사용되는 PCA(Principal Component Analysis)는 주성분의 개수에 따라 압축률이 결정된다. 주성분 개수가 적을수록 압축률은 높아지지만 정보 손실이 보다 쉽게 발생하기 복원 시 원본 데이터와의 크게 오차가 발생한다. 이러한 한계점을 극복하기 위해 본 논문에서는 제안한 신경망인 CAER(Convolutional AutoEncoder+ResNet)을 통하여 데이터 압축을 수행하였다. 신경망 학습은 실제 스펙트럼 데이터를 묘사하여 생성한 모의실험 데이터를 통해 수행하였다. CAER 신경망의 성능 검증을 위해 라만 스펙트럼을 PCA와 신경망을 통하여 75%, 87.5%, 93.75%의 압축률로 압축과 복원을 수행한 후 각각의 결과를 비교 분석하였다. 원본과 복원 데이터의 오차 비교를 하였을 때 CAER 신경망은 PCA보다 평균 94.2%의 낮은 오차를 보인다. 이 결과를 통해 CAER 신경망이 스펙트럼 데이터 압축에 효과적으로 적용될 수 있음을 확인하였다.","In this paper, we propose a spectrum compression neural network that applied the ResNet (Residual Neural Network) algorithm to the convolutional autoencoder structure to reduce data capacity requirement in storing the spectrum. Recently, as the field of application of spectroscopy widens, the spectrum database is becoming larger, making efficient transmission difficult and requiring large amount of storage. Therefore, data compression is performed to manage large amounts of data efficiently. In PCA (Principal Component Analysis), which is mainly used for data compression, the compression ratio is determined by the number of principal components. As the number of principal components decreases, the compression rate increases, but at the same time, it is easier for information loss to occur. Hence, errors occur between reconstruction and the raw spectrum. To overcome these limitations, we perform compression through the proposed CAER (Convolutional AutoEncoder+ResNet) network. The training of the network was performed through simulated data describing the real spectrum. To verify the performance of the CAER network, the Raman spectrum was compressed and reconstructed at compression rates of 75%, 87.5%, and 93.75% through the PCA and CAER networks. Comparing the errors between raw and reconstructed data, the CAER network shows an average error of 94.2% lower than that of the PCA. The results obtained confirm that the CAER network can be effectively applied to spectrum compression."
ResNet과 Unet을 결합한 딥러닝 모델을 이용한 분광 신호에서 ROI 검출,2021,"['Peak Detection', 'Region of Interest', 'Deep Learning', 'CNN', 'Raman Spectroscopy']","본 연구에서는 딥러닝 기술(deep learning technology)을 이용하여 분광 신호의 ROI(region of interest)를 찾는 방법을 제안한다. 제안한 방법은 모의실험 데이터로 학습된 딥러닝 모델을 이용하여 분광 신호의 ROI를 검출하는 방법이다. 분광 신호의 피크는 물질의 물리 화학적인 정보를 포함하고 있으므로 정확한 피크 검출은 분석 시스템의 성능에 영향을 미치는 중요한 과정이다. 지금까지 가장 많이 사용되는 방법은 진폭을 기반으로 피크 검출을 진행하는 것이다. 하지만 이런 방법들은 전처리 과정을 포함하거나 분광 신호에 따라 파라미터를 육안 검사로 선택하여 추정하므로 복잡하고 주관적이다. 이러한 문제점 개선을 위해 딥러닝 모델을 통해 분광 신호의 ROI 검출을 수행하였다. 제안한 방법은 전처리 과정이 없고 파라미터를 설정하지 않아도 되는 장점을 갖는다. 또한 검출한 ROI에 따라 분광 신호에 후처리(post-processing)를 수행하여 피크를 얻을 수 있다. 디폴트 손실 함수에 3만개 테스트 데이터를 적용하여 얻은 손실값을 통해 성능 평가를 수행하였다. 제안된 ResNet과 Unet을 결합한 딥러닝 모델은 일반적인 컨볼루션 신경망(CNN: Convolutional Neural Network), ResNet, 그리고 Unet에 비해 각각 76.5%, 69.8%, 5.9%의 성능 향상을 보였으며, 실제 라만 분광 신호의 ROI 검출에도 효과적으로 적용될 수 있음을 확인하였다.","This study proposes a method to find the ROI (region of interest) of spectral signals using deep learning technology. The proposed method detects the ROI of spectral signals using a deep learning model trained with simulated data. Since the peak of the spectral signal contains physical and chemical information of the substance, accurate peak detection is an important process affecting the performance of the analyzed system. The widely used method for peak detection is the one based on the amplitude. However, this method is complex and subjective because it involves pre-processing or select and estimate parameters using visual inspection according to spectral signals. To overcome this problem, ROI detection of the spectral signal was performed through a deep learning model. The proposed method has the advantage of requiring no pre-processing and parameter setting. In addition, a peak may be obtained by performing post-processing of the spectral signal according to the detected ROI. Performance evaluation was performed through loss values obtained by applying 30,000 test data to the custom loss function. The proposed deep learning model combining ResNet and Unet showed performance improvements of 76.5%, 69.8%, and 5.9% compared to the general convolutional neural network (CNN), ResNet, and Unet, respectively. It was also confirmed that the proposed method could be effectively applied to measured spectral signals."
Distribution Analysis of Feature Map and Gradients in Mobilenet and Resnet Model Layers using Glorot and He`s initialization,2021,"['가중치 초기화', 'Glorot 초기화', 'He 초기화', '컨볼루션 신경망 네트워크', '잡초 분류', 'Weights initialization', 'Glorot initialization', 'He initialization', 'Convolutional neural network', 'Weeds classification']",,"Initializing the weights plays an essential role in a convolutional neural network model. This paper investigates how Glorot and Hes initialization methods behave in Mobilenet and Resnet models on the weeds classification problem. Experiments show that pointwise and depthwise convolution in Mobilenet reduces the variance of feature maps from earlier layers. Using the He’s method, shortcut connection in Resnet saturate values in logistic classify layer. The accuracy of Mobilenet and Resnet, using Glorots method, are 0.9568 and 0.9711, respectively. While using Hes method, we obtain 0.9471 using Mobilenet and 0.9645 using Resnet. Also, both models converge faster and better generalization using Glorots method than using Hes method."
ResNet을 이용한 도로 네트워크 교통 데이터 예측,2021,"['합성곱 신경망', '잔차 학습', '전이 학습', '교통 속도 예측', 'Convolutional Neural Network', 'Residual Learning', 'ResNet', 'Transfer Learning', 'Traffic Speed Prediction']",,
SegNet과 ResNet을 조합한 딥러닝에 기반한 횡단보도 영역 검출,2021,"['Deep Learning', 'Semantic Segmentation', 'Zebra-crossing Detection', 'Neural Network', '딥러닝', '시맨틱 분할', '횡단보도 검출', '신경 네트워크']",,
운전자의 주의분산 연구동향 및 딥러닝 기반 동작 분류 모델,2021,"['Driver’s Behavior', 'Driver’s Distraction', 'Behavior Recognition', 'ResNet-101', 'CAM', '운전자의 동작', '운전자의 주의 분산', '동작 인식']","본 논문에서는 운전자의 주의산만을 유발하는 운전자, 탑승자의 동작을 분석하고 핸드폰과 관련된 운전자의 행동 10가지를 인식하였다. 먼저 주의산만을 유발하는 동작을 환경 및 요인으로 분류하고 관련 최근 논문을 분석하였다. 분석된 논문을 기반으로 주의산만을 유발하는 주요 원인인 핸드폰과 관련된 10가지 운전자의 행동을 인식하였다. 약 10만 개의 이미지 데이터를 기반으로 실험을 진행하였다. SURF를 통해 특징을 추출하고 3가지 모델(CNN, ResNet-101, 개선된 ResNet-101)로 실험하였다. 개선된 ResNet-101 모델은 CNN보다 학습 오류와 검증 오류가 8.2배, 44.6배가량 줄어들었으며 평균적인 정밀도와 f1-score는 0.98로 높은 수준을 유지하였다. 또한 CAM(class activation maps)을 활용하여 딥러닝 모델이 운전자의 주의 분산 행동을 판단할 때, 핸드폰 객체와 위치를 결정적 원인으로 활용했는지 검토하였다.","In this paper, we analyzed driver""s and passenger""s motions that cause driver""s distraction, and recognized 10 driver""s behaviors related to mobile phones. First, distraction-inducing behaviors were classified into environments and factors, and related recent papers were analyzed. Based on the analyzed papers, 10 driver""s behaviors related to cell phones, which are the main causes of distraction, were recognized. The experiment was conducted based on about 100,000 image data. Features were extracted through SURF and tested with three models (CNN, ResNet-101, and improved ResNet-101). The improved ResNet-101 model reduced training and validation errors by 8.2 times and 44.6 times compared to CNN, and the average precision and f1-score were maintained at a high level of 0.98. In addition, using CAM (class activation maps), it was reviewed whether the deep learning model used the cell phone object and location as the decisive cause when judging the driver""s distraction behavior."
Identification of Indian butterflies using Deep Convolutional Neural Network,2021,"['Indian butterfly identification', 'ButterflyNet', 'Butterfly', 'classification CNN', 'Computer vision']",,"The conventional butterfly identification method is based on their different morphological characters namely wing-venation, color, shape, patterns and through the dissection studies and molecular techniques which are tedious, expensive and highly time-consuming. To overcome the above aforesaid challenges, a new butterfly identification system using butterfly images has been designed to instantly identify the butterfly with high ac curacy. In this study, we construct a new butterfly dataset with 34,024 butterfly images belonging to 315 species from India. We propose and prove the effectiveness of new data augmentation techniques on our dataset. To identify butterflies using photographic images, we built eleven new Deep Convolutional Neural Network (DCNN) butterfly classifier models using eleven pre-trained architectures namely ResNet-18, ResNet-34, ResNet-50, ResNet-121, ResNet-152, Alex-Net, DenseNet-121, DenseNet-161, VGG-16, VGG-19 and SqueezeNet-v1.1. The different model’s classification results were compared and the proposed technique achieved a maximum top-1 accuracy(94.44%), top-3 accuracy(98.46%) and top-5 accuracy(99.09%) using ResNet-152 model, followed by DenseNet-161 model achieved the top-1 accuracy(94.31%), top-3 accuracy (98.07%) and top-5 accuracy (98.66%). The results suggest that models can be assertively used to identify butterflies in India."
딥러닝과 의미론적 영상분할을 이용한 자동차 번호판의 숫자 및 문자영역 검출,2021,"['딥러닝', '합성곱 신경망(CNN)', '의미론적 분할', '자동차 번호판', '영상분할 및 인식', 'Deep Learning', 'Convolution Neural Network(CNN)', 'Semantic Segmentation', 'License Plate', 'Image Segmentation and Recognition']","자동차 번호판 인식은 지능형 교통시스템에서 핵심적인 역할을 담당한다. 따라서 효율적으로 자동차 번호판의 숫자 및 문자영역을 검출하는 것은 매우 중요한 과정이다. 본 연구에서는 딥러닝과 의미론적 영상분할 알고리즘을 적용 하여 효과적으로 자동차 번호판의 번호영역을 검출하는 방법을 제안한다. 제안된 방법은 화소 투영과 같은 전처리과정 없이 번호판 영상에서 바로 숫자 및 문자영역을 검출하는 알고리즘이다. 번호판 영상은 도로 위에 설치된 고정 카메라로 부터 획득한 영상으로 날씨 및 조명변화 등을 모두 포함한 다양한 실제 상황에서 촬영된 것을 사용하였다. 입력 영상은 색상변화를 줄이기 위해 정규화하고 실험에 사용된 딥러닝 신경망 모델은 Vgg16, Vgg19, ResNet18 및 ResNet50이 다. 제안방법의 성능을 검토하기 위해 번호판 영상 500장으로 실험하였다. 학습을 위해 300장을 할당하였으며 테스트용 으로 200장을 사용하였다. 컴퓨터모의 실험결과 ResNet50을 사용할 때 가장 우수하였으며 95.77% 정확도를 얻었다.","License plate recognition plays a key role in intelligent transportation systems. Therefore, it is a very important process to efficiently detect the number and character areas. In this paper, we propose a method to effectively detect license plate number area by applying deep learning and semantic image segmentation algorithm. The proposed method is an algorithm that detects number and text areas directly from the license plate without preprocessing such as pixel projection. The license plate image was acquired from a fixed camera installed on the road, and was used in various real situations taking into account both weather and lighting changes. The input images was normalized to reduce the color change, and the deep learning neural networks used in the experiment were Vgg16, Vgg19, ResNet18, and ResNet50. To examine the performance of the proposed method, we experimented with 500 license plate images. 300 sheets were used for learning and 200 sheets were used for testing. As a result of computer simulation, it was the best when using ResNet50, and 95.77% accuracy was obtained."
사과 품종 분류를 위한 CNN기반 모델링 및 분류 기법 연구,2021,"['스마트팜', '딥러닝', 'ResNet', '신경망', 'Smart Farm', 'Deep Learning', 'ResNet', 'Convolution Neural Network']","농장주들이 과일을 분류하는 데까지의 시간소모를 줄이고 향후 과일의 등급 판정 기준을 정량화하기 위하여 우리나라의 대표적인 과일이며 다양한 품종을 가지고 있는 사과를 대상으로 신경망 기반 분류 자동화 시스템을 제안한다. 컨베이어 벨트를 통해 지나가는 객체를 카메라모듈로 촬영하여 이를 통신 및 연산을 수행하는 라즈베리파이 기반 시스템을 설계, 구현한다. 깊은 네트워크와 나머지(residual)를 학습하는 ResNet 기반 알고리즘이 구동되는 딥러닝 서버와는 SSH통신을 통해 이미지와 학습된 모델을 주고받는다. 향후 품종뿐만 아니라 등급까지 분류 자동화한다면 다양한 품종의 과일을 대상으로 한 출하 자동화 시스템으로의 적용이 가능하다.","This paper propose a neural network-based classification automation system for apples, which are representative fruits of Korea and have a variety of varieties, in order to reduce the consumption of time for farmers to classify fruits and to quantify the criteria for grading the fruits. Raspberry Pi-based system that communicates and performs calculations by photographing objects passing through a conveyor belt with a camera module is designed and implemented. Then it receive the trained model using ResNet-based algorithm that runs on the deep-learning server. In the future, if classifying not only varieties but also grades is automated, it can be applied as a shipping automation system targeting various varieties of fruit."
The Classification of EEG-based Wink Signals: A CWT-Transfer Learning Pipeline,2021,"['BCI', 'CWT', 'EEG', 'Transfer Learning', 'SVM']",,"Brain–Computer Interface technology plays a vital role in facilitating post-stroke patients’ ability to carry out their daily activities of living. The extraction of features and the classification of electroencephalogram (EEG) signals are pertinent parts in enabling such a system. This research investigates the efficacy of Transfer Learning models namely ResNet50 V2, ResNet101 V2, and ResNet152 V2 in extracting features from CWT converted wink-based EEG signals, prior to its classification via a fine-tuned Support Vector Machine (SVM) classifier. It was shown that ResNet152 V2-SVM pipeline could achieve an excellent accuracy on all train, test and validation datasets."
Application of convolutional neural networks for distal radio-ulnar fracture detection on plain radiographs in the emergency room,2021,"['Wrist', 'Fractures', 'bone', 'Deep learning', 'Neural networks', 'computer']",,"Objective Recent studies have suggested that deep-learning models can satisfactorily assist in fracture diagnosis. We aimed to evaluate the performance of two of such models in wrist fracture detection. Methods We collected image data of patients who visited with wrist trauma at the emergency department. A dataset extracted from January 2018 to May 2020 was split into training (90%) and test (10%) datasets, and two types of convolutional neural networks (i.e., DenseNet-161 and ResNet-152) were trained to detect wrist fractures. Gradient-weighted class activation mapping was used to highlight the regions of radiograph scans that contributed to the decision of the model. Performance of the convolutional neural network models was evaluated using the area under the receiver operating characteristic curve. Results For model training, we used 4,551 radiographs from 798 patients and 4,443 radiographs from 1,481 patients with and without fractures, respectively. The remaining 10% (300 radiographs from 100 patients with fractures and 690 radiographs from 230 patients without fractures) was used as a test dataset. The sensitivity, specificity, positive predictive value, negative predictive value, and accuracy of DenseNet-161 and ResNet-152 in the test dataset were 90.3%, 90.3%, 80.3%, 95.6%, and 90.3% and 88.6%, 88.4%, 76.9%, 94.7%, and 88.5%, respectively. The area under the receiver operating characteristic curves of DenseNet-161 and ResNet-152 for wrist fracture detection were 0.962 and 0.947, respectively. Conclusion We demonstrated that DenseNet-161 and ResNet-152 models could help detect wrist fractures in the emergency room with satisfactory performance."
장면 복잡도 기반 적응적 얼굴 마스크 탐지 모델,2021,"['인공지능', '딥러닝', '기계학습', '객체 감지', '마스크 감지', '코로나바이러스-19', 'Artificial intelligence', 'Machine learning', 'Object detection', 'Deep learning', 'Mask detection', 'COVID-19']","코로나바이러스-19(COVID-19)의 대유행에 따라 전 세계 수많은 확진자가 발생하고 있으며 국민을 불안에 떨게 하고 있다. 바이러스 감염 확산을 방지하기 위해서는 마스크를 제대로 착용하는것이 필수적이지만 몇몇 사람들은 마스크를 쓰지 않거나 제대로 착용하지 않고 있다. 본 논문에서는 영상 이미지에서의 효율적인 마스크 감지 시스템을 제안한다. 제안 방법은 우선 입력 이미지의 모든 얼굴의 영역을 YOLOv5를 사용하여 감지하고 감지된 얼굴의 수에 따라 3가지의 장면복잡도(Simple, Moderate, Complex) 중 하나로 분류한다. 그 후 장면 복잡도에 따라 3가지ResNet(ResNet-18, 50, 101) 중 하나를 기반으로 한 Faster-RCNN을 사용하여 얼굴 부위를 감지하고마스크를 제대로 착용하였는지 식별한다. 공개 마스크 감지 데이터셋을 활용하여 실험한 결과 제안한 장면 복잡도 기반 적응적인 모델이 다른 모델에 비해 가장 성능이 뛰어남을 확인하였다.","Coronavirus disease 2019 (COVID-19) has affected the world seriously. Every person is required for wearing a mask properly in a public area to prevent spreading the virus. However, many people are not wearing a mask properly. In this paper, we propose an efficient mask detection system. In our proposed system, we first detect the faces of input images using YOLOv5 and classify them as the one of three scene complexity classes (Simple, Moderate, and Complex) based on the number of detected faces. After that, the image is fed into the Faster-RCNN with the one of three ResNet (ResNet-18, 50, and 101) as backbone network depending on the scene complexity for detecting the face area and identifying whether the person is wearing the mask properly or not. We evaluated our proposed system using public mask detection datasets. The results show that our proposed system outperforms other models."
User Interface Application for Cancer Classification using Histopathology Images,2021,"['Deep Learning', 'Histopathology images', 'ResNet-34', 'Digital Pathology', 'AI', 'CAD']",,"User interface for cancer classification system is a software application with clinician's friendly tools and functions to diagnose cancer from pathology images. Pathology evolved from manual diagnosis to computer-aided diagnosis with the help of Artificial Intelligence tools and algorithms. In this paper, we explained each block of the project life cycle for the implementation of automated breast cancer classification software using AI and machine learning algorithms to classify normal and invasive breast histology images. The system was designed to help the pathologists in an automatic and efficient diagnosis of breast cancer. To design the classification model, Hematoxylin and Eosin (H&E) stained breast histology images were obtained from the ICIAR Breast Cancer challenge. These images are stain normalized to minimize the error that can occur during model training due to pathological stains. The normalized dataset was fed into the ResNet-34 for the classification of normal and invasive breast cancer images. ResNet-34 gave 94% accuracy, 93% F Score, 95% of model Recall, and 91% precision."
텍스타일 디자인 분류 및 관심 영역 도출에 대한 연구,2021,"['텍스타일 디자인 분류', '관심 영역 도출', 'Textile design', 'VGG-16', 'ResNet-34', 'LIME', 'region of interest']","디자인에 있어서 유사한 디자인들을 그룹핑하여 분류하는 것은 관리적인 측면에서 효율성을 높여주고 사용적인 측면에서는 편의성을 제공한다. 본 연구는 인공지능 알고리즘을 이용하여 텍스타일 디자인을 도트, 꽃무늬, 줄무늬, 그리고 기하학으로 4개의 카테고리로 분류하고자 하였다. 특히, 인공지능의 관점에서 분류의 근거가 되는 관심 영역을 찾아내고 설명할 수 있는 지를 탐색하였다. 총 4,536개의 디자인을 8:2의 비율로 무작위 추출하여 학습용 데이터 3,629개와 테스트용 데이터 907개로 구성하였다. 분류에 사용된 모델은 VGG-16과 ResNet-34로 두 모델의 꽃무늬 디자인에 대한 정밀도는 각각 0.79%, 0.89%이며, 재현율은 0.95%, 0.38%로 우수한 분류 성과를 보였다. LIME(Local Interpretable Model-agnostic Explanation) 기법을 이용하여 분석한 결과에 따르면, 기하학과 꽃무늬 디자인의 경우 도형과 꽃잎 부분이 분류의 근거가 되는 관심 영역으로 도출되었다.","Grouping and classifying similar designs in design increase efficiency in terms of management and provide convenience in terms of use. Using artificial intelligence algorithms, this study attempted to classify textile designs into four categories: dots, flower patterns, stripes, and geometry. In particular, we explored whether it is possible to find and explain the regions of interest underlying classification from the perspective of artificial intelligence. We randomly extracted a total of 4,536 designs at a ratio of 8:2, comprising 3,629 for training and 907 for testing. The models used in the classification were VGG-16 and ResNet-34, both of which showed excellent classification performance with precision on flower pattern designs of 0.79%, 0.89% and recall of 0.95% and 0.38%. Analysis using the Local Interpretable Model-agnostic Explanation (LIME) technique has shown that geometry and flower-patterned designs derived shapes and petals from the region of interest on which classification was based."
공연예술에서 광고포스터의 이미지 특성을 활용한 딥러닝 기반 관객예측,2021,"['공연예술', '흥행 예측', 'CNN', 'VGG-16', 'Inception-v3', 'ResNet50', 'Performing Arts', 'Box Office Prediction']","공연예술 기관에서의 공연에 대한 흥행 예측은 공연예술 산업 및 기관에서 매우 흥미롭고도 중요한 문제이다. 이를 위해 출연진, 공연장소, 가격 등 정형화된 데이터를 활용한 전통적인 예측방법론, 데이터마이닝 방법론이 제시되어 왔다. 그런데 관객들은 공연안내 포스터에 의하여 관람 의도가 소구되는 경향이 있음에도 불구하고, 포스터 이미지 분석을 통한 흥행 예측은 거의 시도되지 않았다. 그러나 최근 이미지를 통해 판별하는 CNN 계열의 딥러닝 방법이 개발되면서 포스터 분석의 가능성이 열렸다. 이에 본 연구의 목적은 공연 관련 포스터 이미지를 통해 흥행을 예측할 수 있는 딥러닝 방법을 제안하는 것이다. 이를 위해 KOPIS 공연예술 통합전산망에 공개된 포스터 이미지를 학습데이터로 하여 Pure CNN, VGG-16, Inception-v3, ResNet50 등 딥러닝 알고리즘을 통해 예측을 수행하였다. 또한 공연 관련 정형데이터를 활용한 전통적 회귀분석 방법론과의 앙상블을 시도하였다. 그 결과 흥행 예측 정확도 85%를 상회하는 높은 판별 성과를 보였다. 본 연구는 공연예술 분야에서 이미지 정보를 활용하여 흥행을 예측하는 첫 시도이며 본 연구에서 제안한 방법은 연극 외에 영화, 기관 홍보, 기업 제품 광고 등 포스터 기반의 광고를 하는 영역으로도 적용이 가능할 것이다.","The prediction of box office performance in performing arts institutions is an important issue in the performing arts industry and institutions. For this, traditional prediction methodology and data mining methodology using standardized data such as cast members, performance venues, and ticket prices have been proposed. However, although it is evident that audiences tend to seek out their intentions by the performance guide poster, few attempts were made to predict box office performance by analyzing poster images. Hence, the purpose of this study is to propose a deep learning application method that can predict box office success through performance-related poster images. Prediction was performed using deep learning algorithms such as Pure CNN, VGG-16, Inception-v3, and ResNet50 using poster images published on the KOPIS as learning data set. In addition, an ensemble with traditional regression analysis methodology was also attempted. As a result, it showed high discrimination performance exceeding 85% of box office prediction accuracy. This study is the first attempt to predict box office success using image data in the performing arts field, and the method proposed in this study can be applied to the areas of poster-based advertisements such as institutional promotions and corporate product advertisements."
Automated detection of corrosion in used nuclear fuel dry storage canisters using residual neural networks,2021,"['Convolutional neural networks', 'Corrosion', 'Deep learning', 'Dry storage canisters', 'Feature detection', 'Residual neural networks']",,"Nondestructive evaluation methods play an important role in ensuring component integrity and safety in many industries. Operator fatigue can play a critical role in the reliability of such methods. This is important for inspecting high value assets or assets with a high consequence of failure, such as aerospace and nuclear components. Recent advances in convolution neural networks can support and automate these inspection efforts. This paper proposes using residual neural networks (ResNets) for real-time detection of corrosion, including iron oxide discoloration, pitting and stress corrosion cracking, in dry storage stainless steel canisters housing used nuclear fuel. The proposed approach crops nuclear canister images into smaller tiles, trains a ResNet on these tiles, and classifies images as corroded or intact using the per-image count of tiles predicted as corroded by the ResNet. The results demonstrate that such a deep learning approach allows to detect the locus of corrosion via smaller tiles, and at the same time to infer with high accuracy whether an image comes from a corroded canister. Thereby, the proposed approach holds promise to automate and speed up nuclear fuel canister inspections, to minimize inspection costs, and to partially replace human-conducted onsite inspections, thus reducing radiation doses to personnel."
심층 신경망 기반 객체 인식 기법의 유사 객체 분류 성능 분석,2021,"['Deep Neural Networks', 'ResNet', 'DenseNet', 'Smart Factory', 'Armored Fighting Vehicle']",,"In this study, deep neural networks were applied to a similar object classification method, and the classification performance was analyzed. For the similar object classification performance analysis, ResNet50 and DenseNet169 models, which are known to show similar behaviors, were selected. To verify the performance of these deep neural networks, a bolt recognition for smart factories and an armored fighting vehicle recognition were performed. In addition, image preprocessing methods to improve the similar object classification performance were proposed. The experimental results confirmed that appropriate image preprocessing methods should be applied according to the type of similar object to be classified."
평활화 알고리즘에 따른 자궁경부 분류 모델의 성능 비교 연구,2021,"['Cervical cancer', 'Histogram equalization', 'Classification', 'ResNet-50']",,"We developed a model to classify the absence of cervical cancer using deep learning from the cervical image to which the histogram equalization algorithm was applied, and to compare the performance of each model. A total of 4259 images were used for this study, of which 1852 images were normal and 2407 were abnormal. And this paper applied Image Sharpening(IS), Histogram Equalization(HE), and Contrast Limited Adaptive Histogram Equalization(CLAHE) to the original image. Peak Signal-to-Noise Ratio(PSNR) and Structural Similarity index for Measuring image quality(SSIM) were used to assess the quality of images objectively. As a result of assessment, IS showed 81.75dB of PSNR and 0.96 of SSIM, showing the best image quality. CLAHE and HE showed the PSNR of 62.67dB and 62.60dB respectively, while SSIM of CLAHE was shown as 0.86, which is closer to 1 than HE of 0.75. Using ResNet-50 model with transfer learning, digital image-processed images are classified into normal and abnormal each. In conclusion, the classification accuracy of each model is as follows. 90.77% for IS, which shows the highest, 90.26% for CLAHE and 87.60% for HE. As this study shows, applying proper digital image processing which is for cervical images to Computer Aided Diagnosis(CAD) can help both screening and diagnosing."
웹 검색을 이용한 새 품종 분류를 위한 전이학습에 대한 연구,2021,"['deep learning', 'transfer learning', 'bird breed recognition', 'web crawling', 'ResNet50', 'ImageNet']",,"Recently, research on image recognition and object extraction has been actively carried out through deep learning. In addition, research on transfer learning, which is used for new neural network learning by maintaining or partially changing the neural network function of a deep learning model pre-trained in a specific field, is also being actively conducted. However, although a large number of datasets are required for image learning, it is difficult to obtain desired quantities of images. In this paper, a large number of images were collected through Google and bird-related professional website crawling for bird breed classification, and images that can be used for learning were selected through various preprocessing. Then, using the ResNet50 model pre-trained with ImageNet, fine-tuning transfer learning was performed to classify bird breeds. In addition, the trained model was tested using the CUB_200-2011 data set, which is a data set for classifying new breeds, and the reliability of the search image was obtained with an accuracy of 87.87%."
"딥러닝 경량화를 위한 구조, 가지치기, 지식증류 비교",2021,"['Deep learning', 'Structure Reduction', 'Pruning', 'Knowledge Distillation', 'CIFAR10/100', 'ResNet56/110']",,"We compare three approaches of structure reduction, pruning, and knowledge distillation for lightning of a deep learning network. Structure reduction eliminates a set of layers of the model, but pruning deletes filters within a layer. Knowledge distillation effectively learns a small student model from a large teacher model using KL Divergence. Therefore, it has a similar effect of reduction of the model. The above three methods for lightning are rarely compared to each other in terms of performance. To compare these approaches for network reduction problem, we investigate the accuracy and flops of the methods on CIFAR10 and CIFAR100 data for ResNet models. A systematic analysis for the fundamental orientations and differences of each method is supplemented."
딥러닝 기반의 소비자 데이터를 응용한 외식업체 추천 시스템 구현에 관한 연구,2021,"['추천 시스템', '인공지능', '딥러닝', '분류', '감성 분석', '외식업체', 'Recommendation System', 'Artificial Intelligence', 'Deep Learning', 'Classification', 'Sentiment Analysis', 'Restaurant']",본 연구에서는 소비자 데이터를 딥러닝 기반의 분류(Classification) 모델을 학습 시켜 추천 알고리즘을 구현하였다. 이를 위하여 사용자 데이터를 이미지로 변환 시켜 분류 과제에서 보편적으로 사용되는 ResNet50을 사용하여 학습한 결과로서 유의미한 결과에 대하여 제시함,"In this study, a recommendation algorithm was implemented by learning a deep learning-based classification model for consumer data. For this purpose, a meaningful result is presented as a result of learning using ResNet50, which is commonly used in classification tasks by converting user data into images."
Implementation and Performance Evaluation of Farm Waste Image Classification System using CNN-based Transfer Learning Models,2021,"['Artificial intelligence', 'Transfer-learning', 'CNN', 'Image classification', 'Farm waste collection']","영농 폐기물의 증가로 인해, 빠르고 효율적으로 수거할 수 있는 스마트 영농 폐기물 모니터링 시스템 개발이 필요하다. 본 논문에서는 영농 폐기물 분류 시스템을 제안하고 실제 지역 농촌에서 직접 수집한 영상을 이용하여 CNN 기반의 전이학습 모델들을 구현하고 비교하였다. 영농 폐기물 영상 분류에 적합한 모델과 학습 조건을 찾기 위해, 3가지의 학습 자료군 구성 조건 (2종 분류, 6종 분류, 6종 하위분류를 가진 2종 분류)을 달리하여 미세 조정된 6개의 사전 훈련 CNN 모델들의 검증 정확도를 비교하였다. 그 결과, ResNet-50 모델의 성능이 모든 학습 조건에서 평균 90.9%의 정확도로 가장 높았고, 폐기물 영상을 6종 분류했을 때보다 2종 분류로 했을 때의 검증 정확도가 10% 더 높았다. 특히, 학습 자료군 구성 방법 중 6종 하위분류를 가진 2종 분류했을 때의 검증 정확도는 2종 분류했을 때와 유사했다. 이를 통해 영농 폐기물은 한 종류만 모여 있지 않을뿐더러 다양한 폐기물들이 한데 섞여 있어서 영농 폐기물의 특정한 세부 종류로 분류하는 것보다 폐기물인지 아닌지를 이진 분류하는 것이 더 효과적임을 확인하였다. 나아가, 제안된 시스템의 동작을 확인하기 위해, 영농 환경 모니터링 서버와 영농 폐기물 영상 분류 서버 사이에 TCP / IP 기반의 통신 환경을 구축하고, 모의실험을 통해 구현한 영농 폐기물 영상 분류 시스템이 스마트 영농 폐기물 모니터링 시스템으로 사용될 가능성을 확인하였다. 본 연구의 결과는 정형화되지 않거나 여러 병변이 혼합된 의료 영상을 분류하는 경우에도 활용될 수 있을 것이다.","Due to the increase of farm waste in many countries, there’s a need to develop a smart farm waste monitoring system that can collect it promptly and efficiently. In this paper, we proposed, compared the performance of a convolutional neural network (CNN) -based transfer learning models and implement a farm waste image classification system, which is crucial component for the monitoring system. To find an appropriate model and labelling methods for farm waste image classification, we compared each validation accuracy of six different pre-trained CNN methods with three types of labelling scheme, using the waste images taken directly from the farming area. As a result, the ResNet-50 model performed best with an accuracy of 90.9% on average. Also, when classified into 2 categories, the accuracy was about 10% higher than that of the 6 categories. Furthermore, when the image was classified into 2 main categories with 6 sub-categories, the validation accuracy was similar to that of the 2 categories. Through these results, it seemed to be more effective to classify with binary labels such as ‘trash’ and ‘non-trash’, rather than with multiple labels of specific categories because farm waste is generated not only by single type of waste but also by various types of mixed waste. And a TCP / IP based communication environment between farm environment monitoring server and farm waste image classification server has been implemented. Experimental results using the system implemented for a smart farm waste monitoring showed that the proposed system can be used for a smart farm waste collection system. Also, the result of this study could be applied to classify medical images of unstructured and/or mixed lesion."
Five-Class Classification of Cervical Pap Smear Images: A Study of CNN-Error-Correcting SVM Models,2021,"['Cervix Uteri', 'Diagnosis', 'Nerve Net', 'Papanicolaou Test', 'Support Vector Network']",,"Objectives: Different complex strategies of fusing handcrafted descriptors and features from convolutional neural network(CNN) models have been studied, mainly for two-class Papanicolaou (Pap) smear image classification. This paper explores asimplified system using combined binary coding for a five-class version of this problem. Methods: This system extracted featuresfrom transfer learning of AlexNet, VGG19, and ResNet50 networks before reducing this problem into multiple binarysub-problems using error-correcting coding. The learners were trained using the support vector machine (SVM) method. The outputs of these classifiers were combined and compared to the true class codes for the final prediction. Results: Despitethe superior performance of VGG19-SVM, with mean ± standard deviation accuracy and sensitivity of 80.68% ± 2.00% and80.86% ± 0.45%, respectively, this model required a long training time. There were also false-negative cases using both theVGGNet-SVM and ResNet-SVM models. AlexNet-SVM was more efficient in terms of running speed and prediction consistency. Our findings also showed good diagnostic ability, with an area under the curve of approximately 0.95. Further investigationalso showed good agreement between our research outcomes and that of the state-of-the-art methods, with specificityranging from 93% to 100%. Conclusions: We believe that the AlexNet-SVM model can be conveniently applied for clinicaluse. Further research could include the implementation of an optimization algorithm for hyperparameter tuning, as well asan appropriate selection of experimental design to improve the efficiency of Pap smear image classification."
영상 콘텐츠의 오디오 분석을 통한 메타데이터 자동 생성 방법,2021,"['Audio', 'AI', 'Metadata', 'Recommendation System', 'Voice Recognition']","영상 콘텐츠를 사용자에게 추천하기 위해서는 메타데이터가 필수적인 요소로 자리 잡고 있다. 하지만 이러한 메타데이터는 영상 콘텐츠 제공자에 의해 수동적으로 생성되고 있다. 본 논문에서는 기존 수동으로 직접 메타데이터를 입력하는 방식에서 자동으로 메타데이터를 생성하는 방법을 연구하였다. 기존 연구에서 감정 태그를 추출하는 방법에 추가로 영화 오디오를 통한 장르와 제작국가에 대한 메타데이터 자동 생성 방법에 대해 연구를 진행하였다. 전이학습 모델인 ResNet34 인공 신경망 모델을 이용하여 오디오의 스펙트로그램으로부터 장르를 추출하고, 영화 속 화자의 음성을 음성인식을 통해 언어를 감지하였다. 이를 통해 메타데이터를 생성 인공지능을 통해 자동 생성 가능성을 확인할 수 있었다.","A meatadata has become an essential element in order to recommend video content to users. However, it is passively generated by video content providers. In the paper, a method for automatically generating metadata was studied in the existing manual metadata input method. In addition to the method of extracting emotion tags in the previous study, a study was conducted on a method for automatically generating metadata for genre and country of production through movie audio. The genre was extracted from the audio spectrogram using the ResNet34 artificial neural network model, a transfer learning model, and the language of the speaker in the movie was detected through speech recognition. Through this, it was possible to confirm the possibility of automatically generating metadata through artificial intelligence."
Detection of surface roughness of mechanical drawings with deep learning,2021,['· Mechanical drawings · Image analysis · Object detection · Image recognition · Deep learning models · Evaluation metrics'],,"Engineering drawing inspection is important to CAD modeling of mechanical parts. Traditional inspection methods mainly rely on manual analysis by using the CAD software, which requires expert knowledge and massive time. In view of simplifying the analysis for non-experts and improving detection efficiency and accuracy, this study proposes a generic approach combining object detection and image recognition methods to identify surface roughness of mechanical drawings. For both the object detection and image recognition methods, deep learning models with different backbone networks are trained and tested independently.Experimental results show that a combination of Faster-RCNN with ResNet101 as backbone network, and SSD with ResNet50 as backbone network achieves the best performance under our evaluation metrics."
"다양한 CNN 가속기에서 아키텍처에 따른 면적, 에너지, 성능 분석",2021,"['CNN 가속기', '아키텍처', '메모리 대역폭', '뉴럴 네트워크', 'CNN accelerators', 'architecture', 'memory bandwidth', 'neural networks']","Convolution Neural Network 가속기는 AI시대에 중요한 요소 중 하나로 떠오르게 되었다. CNN 가속기의 내부 구성을 몇 가지로 나눈다면 연산을 위한 Multiplier-Accumulator (MAC unit), 데이터 저장을 위한 SRAM, 데이터 이동을 위한 메모리 인터페이스 그리고 제어 로직으로 구분할 수 있다. 다양한 CNN 가속기들의 경우, 각기 다른 공정과 동작 주파수를 기준으로 제안되었으며, 또한 아키텍처 형태에 따라 내부 MAC unit의 수와 SRAM의 크기가 매우 큰 차이를 갖는 형태로 구성되어있다. 각 가속기들의 기본 사양으로 면적, 에너지, 성능을 비교하였을 때는 공정이나 동작 주파수 등 여러 조건들에 의해서 아키텍처에 따른 정량적인 비교가 용이하지 않게 된다. 따라서, 본 논문에서는 다양한 CNN 가속기에서 여러 조건들을 동일하게 재구성하였을 때, ResNet-50 추론 동작 시에 요구되는 면적, 에너지, 성능을 비교하여 아키텍처의 특징과 경향성을 분석하였다.","The Convolution Neural Network accelerator has emerged as an important element in the AI era. The primary components of a CNN accelerator include the Multiplier-Accumulator (MAC unit) for calculation, SRAM for data storage, memory interface for data movement, and control logic. Different CNN accelerators have been designed based on different assumptions regarding the process technologies and operating frequencies. In addition, the number of internal MAC units and the size of SRAM vary substantially between different types of architectures. These factors make it difficult to design a fair comparison of the area, energy, and performance of different CNN accelerators. In this paper, we attempt to compare the area, energy, and performance of different CNN accelerator architectures by constructing them all with the same fabrication process and operating frequency while making inferences using the ResNet-50 network."
비디오 인코더를 통한 딥러닝 모델의 정수 가중치 압축,2021,"['Deep Learning Model Parameter Quantization', 'Weight compression', 'Lightweight model']",,"Recently, various lightweight methods for using Convolutional Neural Network(CNN) models in mobile devices have emerged. Weight quantization, which lowers bit precision of weights, is a lightweight method that enables a model to be used through integer calculation in a mobile environment where GPU acceleration is unable. Weight quantization has already been used in various models as a lightweight method to reduce computational complexity and model size with a small loss of accuracy. Considering the size of memory and computing speed as well as the storage size of the device and the limited network environment, this paper proposes a method of compressing integer weights after quantization using a video codec as a method. To verify the performance of the proposed method, experiments were conducted on VGG16, Resnet50, and Resnet18 models trained with ImageNet and Places365 datasets. As a result, loss of accuracy less than 2% and high compression efficiency were achieved in various models. In addition, as a result of comparison with similar compression methods, it was verified that the compression efficiency was more than doubled."
이미지 감성분류를 위한 CNN과 K-means RGB Cluster 이-단계 학습 방안,2021,"['이미지 감성분류', '색감', '이-단계 학습', 'Sentiment Analysis of Image', 'Sense of Color', 'CNN', 'Two-stage learning']",,"The biggest reason for using a deep learning model in image classification is that it is possible to consider the relationship between each region by extracting each regions features from the overall information of the image. However, the CNN model may not be suitable for emotional image data without the images regional features. To solve the difficulty of classifying emotion images, many researchers each year propose a CNN-based architecture suitable for emotion images. Studies on the relationship between color and human emotion were also conducted, and results were derived that different emotions are induced according to color. In studies using deep learning, there have been studies that apply color information to image subtraction classification. The case where the images color information is additionally used than the case where the classification model is trained with only the image improves the accuracy of classifying image emotions.  This study proposes two ways to increase the accuracy by incorporating the result value after the model classifies an images emotion. Both methods improve accuracy by modifying the result value based on statistics using the color of the picture. When performing the test by finding the two-color combinations most distributed for all training data, the two-color combinations most distributed for each test data image were found. The result values were corrected according to the color combination distribution. This method weights the result value obtained after the model classifies an images emotion by creating an expression based on the log function and the exponential function.  Emotion6, classified into six emotions, and Artphoto classified into eight categories were used for the image data. Densenet169, Mnasnet, Resnet101, Resnet152, and Vgg19 architectures were used for the CNN model, and the performance evaluation was compared before and after applying the two-stage learning to the CNN model.  Inspired by color psychology, which deals with the relationship between colors and emotions, when creating a model that classifies an images sentiment, we studied how to improve accuracy by modifying the result values based on color. Sixteen colors were used: red, orange, yellow, green, blue, indigo, purple, turquoise, pink, magenta, brown, gray, silver, gold, white, and black. It has meaning. Using Scikit-learns Clustering, the seven colors that are primarily distributed in the image are checked. Then, the RGB coordinate values of the colors from the image are compared with the RGB coordinate values of the 16 colors presented in the above data. That is, it was converted to the closest color. Suppose three or more color combinations are selected. In that case, too many color combinations occur, resulting in a problem in which the distribution is scattered, so a situation fewer influences the result value. Therefore, to solve this problem, two-color combinations were found and weighted to the model. Before training, the most distributed color combinations were found for all training data images. The distribution of color combinations for each class was stored in a Python dictionary format to be used during testing. During the test, the two-color combinations that are most distributed for each test data image are found. After that, we checked how the color combinations were distributed in the training data and corrected the result. We devised several equations to weight the result value from the model based on the extracted color as described above.  The data set was randomly divided by 80:20, and the model was verified using 20% of the data as a test set. After splitting the remaining 80% of the data into five divisions to perform 5-fold cross-validation, the model was trained five times using different verification datasets. Finally, the performance was checked using the test dataset that was previously separated. Adam was used as the activation function, and the learning rate"
전단 융합 기반 멀티모달 심층학습을 이용한 손동작 분류,2021,"['Hand Gesture Classification', 'Deep Learning', 'EMG', 'Multimodal Learning', 'Ninapro DB']",,"In this paper, we propose a new hand gesture classification strategy using early fusion based multimodal deep learning. The structure and parameters of the state-of-the-art deep learning models such as ResNet152, DenseNet201, EfficientNetB0 for the source task of image classification are reused in the target task of hand gesture classification using surface electromyograph(EMG) and finger""s kinematic data. The time-domain EMG and kinematic signals are normalized and then transformed into combined 2-D images for the early-fusion network. The experimental results support the superiority of the proposed method in terms of classification accuracy. The transfer learning model with the EfficientNetB0 shows the 93.94% accuracy for 40 gestures of 40 participants in the Ninapro DB2."
RVC 정규화와 전이학습을 이용한 손동작 인식,2021,"['Transfer Learning', 'Reference Voluntary Contraction', 'Hand Gesture Recognition', 'EMG', 'Ninapro DB']",,"In this paper, we propose a new hand gesture recognition strategy using network-based transfer learning(TL) and reference voluntary contraction(RVC) normalization. The structure and parameters of the state-of-the-art deep learning models such as VGG19, ResNet152 and DenseNet121 for source task of image classification are reused in the target task of hand gesture recognition based on surface electromyography(EMG) signals. To mitigate the difficulty in handling the subject-dependent EMG signals, the RVC normalization is adopted in the signal pre-processing. The time-domain EMG signals are transformed into 2-D images for TL networks. The experimental results verify the validity of the proposed method in terms of recognition accuracy. The TL using VGG19, RVC normalization and gray image transformation shows 99.78% accuracy for the data from 15 participants performing 20 different gestures."
Former Unmanned Surface Vehicle Detection Based on Improved Convolutional Neural Network,2021,"['Object detection', 'Accuracy', 'Tracking system', 'Monocular camera']",,"This paper proposes an approach to the real-time implementation of a convolutional neural network (CNN)-based object detector for a former Unmanned Surface Vehicle (USV). The original network VGG-16 of the Single Shot MultiBox Detector (SSD) is first replaced with ResNet-18, as the basic feature extraction network. The classifying network is then redesigned by reducing half of the convolutional kernel numbers, where kernel sizes of 1×1 and 3×3 are mainly used. Simultaneously, a monocular camera installed on the tracking system, is used to calculate the distance and azimuth of the former USV. The experimental results show that the proposed method has advantages of higher accuracy and lower computational complexity, compared with other existing approaches. Therefore, the proposed approach can be efficiently used on real-time tracking systems."
Apple Detection Algorithm based on an Improved SSD,2021,"['RFB', 'Attention Model', 'SSD', 'Apple detection', 'Objection detection', 'CNN']",,"Under natural conditions, Apple detection has the problems of occlusion and small object detection difficulties. This paper proposes an improved model based on SSD. The SSD backbone network VGG16 is replaced with the ResNet50 network model, and the receptive field structure RFB structure is introduced. The RFB model amplifies the feature information of small objects and improves the detection accuracy of small objects. Combined with the attention mechanism (SE) to filter out the information that needs to be retained, the semantic information of the detection objectis enhanced. An improved SSD algorithm is trained on the VOC2007 data set. Compared with SSD, the improved algorithm has increased the accuracy of occlusion and small object detection by 3.4% and 3.9%. The algorithm has improved the false detection rate and missed detection rate. The improved algorithm proposed in this paper has higher efficiency."
Comparison of Pre-processed Brain Tumor MR Images Using Deep Learning Detection Algorithms,2021,"['Brain Tumor', 'RetinaNet', 'Deep Learning', 'Histogram Equalization']",,"Detecting brain tumors of different sizes is a challenging task. This study aimed to identify brain tumors using detection algorithms. Most studies in this area use segmentation; however, we utilized detection owing to its advantages. Data were obtained from 64 patients and 11,200 MR images. The deep learning model used was RetinaNet, which is based on ResNet152. The model learned three different types of pre-processing images: normal, general histogram equalization, and contrast-limited adaptive histogram equalization (CLAHE). The three types of images were compared to determine the pre-processing technique that exhibits the best performance in the deep learning algorithms. During pre-processing, we converted the MR images from DICOM to JPG format. Additionally, we regulated the window level and width. The model compared the pre-processed images to determine which images showed adequate performance; CLAHE showed the best performance, with a sensitivity of 81.79%. The RetinaNet model for detecting brain tumors through deep learning algorithms demonstrated satisfactory performance in finding lesions. In future, we plan to develop a new model for improving the detection performance using well-processed data. This study lays the groundwork for future detection technologies that can help doctors find lesions more easily in clinical tasks."
Rice Fungal Diseases Recognition Using Modern Computer Vision Techniques,2021,"['Convolutional neural networks', 'Machine learning', 'Computer vision', 'Rice', 'Fungal diseases']",,"In the article, the authors study the possibility of detecting some fungal diseases of rice using visual computing and machine learning techniques. Leaf blast and brown spot diseases are considered. Modern computer vision methods based on convolutional neural networks are used to identify a particular disease on an image. The authors compare the four most successful and compact convolutional neural network architectures: GoogleNet, ResNet-18, SqueezeNet-1.0, and DenseNet-121. The authors show that in the dataset used for the analysis, the disease can be detected with an accuracy of at least 95%. Testing the algorithm on real data not used in training showed an accuracy of up to 95.6%. This is a good indicator of the reliability and stability of the obtained solution even to a change in the data distribution. Data not used in training showed an accuracy of up to 95.6%. This is a good indicator of the reliability and stability of the obtained solution even to a change in the data distribution."
MAT-AGCA: Multi Augmentation Technique on small dataset for Balinese character recognition using Convolutional Neural Network,2021,"['Balinese character', 'Lontar manuscript', 'Data augmentation', 'Adaptive Gaussian Thresholding', 'Convolutional Autoencoder']",,"The lontar manuscript is an ancient Balinese cultural heritage written using Balinese characters on palm leaves. The recognition of Balinese characters in lontar is challenging because it has noise and limited data availability. To solve these problems, data augmentation is needed to increase the variety and amount of data to improve recognition performance. In this study, we collected Balinese character images from 50 lontar manuscript writers. We proposed MAT-AGCA that combines Adaptive Gaussian Thresholding and Convolutional Autoencoder for data augmentation. Based on experiments using InceptionResnetV2, DenseNet169, ResNet152V2, VGG19, and MobileNetV2, our proposed method achieved the best performance with 96.29% accuracy."
Deep Convolutional Neural Network를 적용한 피하 종괴의 초음파적 진단: 실험적 연구,2021,"['Deep learning', 'Epidermal cyst', 'Lipoma', 'Ultrasonography']",,"Background: Ultrasonography is an effective noninvasive imaging modality for the diagnosis of subcutaneous masses. To date, few studies have reported skin ultrasonography using deep convolutional neural networks (DCNNs). We investigated the accuracy of DCNNs for the diagnosis of epidermal cysts, lipomas, and other subcutaneous masses.Objective: The purpose of this study was to evaluate whether DCNNs could diagnose subcutaneous masses with ultrasonographic images at level of competence comparable to dermatologists.Methods: We created a dataset of 1,361 skin ultrasonography images obtained from 202 patients diagnosed with epidermal cysts, lipomas, and other subcutaneous masses, to train the DCNNs using ResNet18. Performance was compared with another set of 93 ultrasonographic images (24 epidermal cysts, 25 lipomas, and 44 other subcutaneous masses) from open-access articles.Results: The DCNNs yielded 87.10% classification accuracy and 86.10% F1-scores. The area under the curve, sensitivity, and specificity were 0.92 (95% confidence interval [CI] 0.86∼0.98), 75.00%, and 98.55% for epidermal cysts; 0.93 (95% CI 0.88∼0.98), 80.00%, and 94.12% for lipomas; and 0.97 (95% CI 0.93∼1.00), 97.73%, and 85.71% for other subcutaneous masses, respectively. Analysis using gradient-weighted class activation mapping revealed that the DCNNs could detect specific ultrasonographic findings of epidermal cysts and lipomas.Conclusion: We propose that DCNNs combined with ultrasonography may aid in the diagnosis of subcutaneous masses in outpatient settings. (Korean J Dermatol 2021;59(7):513∼520)"
합성곱 신경망의 Channel Attention 모듈 및 제한적인 각도 다양성 조건에서의 SAR 표적영상 식별로의 적용,2021,[],,"In the field of automatic target recognition(ATR) with synthetic aperture radar(SAR) imagery, it is usually impractical to obtain SAR target images covering a full range of aspect views. When the database consists of SAR target images with limited angular diversity, it can lead to performance degradation of the SAR-ATR system. To address this problem, this paper proposes a deep learning-based method where channel attention modules(CAMs) are inserted to a convolutional neural network(CNN). Motivated by the idea of the squeeze-and-excitation(SE) network, the CAM is considered to help improve recognition performance by selectively emphasizing discriminative features and suppressing ones with less information. After testing various CAM types included in the ResNet18-type base network, the SE CAM and its modified forms are applied to SAR target recognition using MSTAR dataset with different reduction ratios in order to validate recognition performance improvement under the limited angular diversity condition."
고성능 CNN 기반 정밀 요검사 판별 기법,2021,"['CNN', 'Urinalysis', 'Image Discrimination']","요검사는 물리적 성상 검사, 화학적 검사, 현미경 검사 세 가지가 있다. 이 중에서 화학적 요검사는 일반인이 쉽게 접근하는 방법으로 요검사지의 화학반응을 눈으로 표준비색표와 비교하거나 휴대용 요검사기를 별도로 구매하여 검사를 진행한다. 현재는 스마트폰의 보급이 대중화되어 스마트폰을 활용한 요검사 서비스 연구가 높아지고 있다. 요검사 스크리닝 애플리케이션은 스마트폰을 활용한 요검사 서비스 중 하나이다. 그러나 요검사 스크리닝 애플리케이션으로 촬영한 요검사 패드 RGB 값은 조명영향으로 인해 큰 편차가 발생한다. 요검사 패드 RGB 값의 편차는 요검사 판별의 정확도를 떨어뜨린다. 따라서 본 논문에서는 스마트폰 기반 요검사 스크리닝 애플리케이션으로 촬영한 요검사지를 검사 항목별 요검사 패드로 분류한 후 CNN을 통해 요검사 패드 이미지 판별의 정확도를 높인다. 요검사지는 다양한 배경에서 촬영하여 CNN 이미지를 생성하였으며 ResNet-50 CNN 모델을 사용하여 요검사 판별을 분석하였다.",
컨볼루션 신경망 모델을 이용한 분류에서 입력 영상의 종류가 정확도에 미치는 영향,2021,"['X-ray', 'Convolutional neural network', 'Classification', 'Deep learning']",,"The purpose of this study is to classify TIFF images, PNG images, and JPEG images using deep learning, and to compare the accuracy by verifying the classification performance. The TIFF, PNG, and JPEG images converted from chest X-ray DICOM images were applied to five deep neural network models performed in image recognition and classification to compare classification performance. The data consisted of a total of 4,000 X-ray images, which were converted from DICOM images into 16-bit TIFF images and 8-bit PNG and JPEG images. The learning models are CNN models - VGG16, ResNet50, InceptionV3, DenseNet121, and EfficientNetB0. The accuracy of the five convolutional neural network models of TIFF images is 99.86%, 99.86%, 99.99%, 100%, and 99.89%. The accuracy of PNG images is 99.88%, 100%, 99.97%, 99.87%, and 100%. The accuracy of JPEG images is 100%, 100%, 99.96%, 99.89%, and 100%. Validation of classification performance using test data showed 100% in accuracy, precision, recall and F1 score. Our classification results show that when DICOM images are converted to TIFF, PNG, and JPEG images and learned through preprocessing, the learning works well in all formats. In medical imaging research using deep learning, the classification performance is not affected by converting DICOM images into any format."
Novel Image Classification Method Based on Few-Shot Learning in Monkey Species,2021,"['Deep learning', 'Feature extraction', 'Few-shot learning', 'Image classification']",,"This paper proposes a novel image classification method based on few-shot learning, which is mainly used to solve model overfitting and non-convergence in image classification tasks of small datasets and improve the accuracy of classification. This method uses model structure optimization to extend the basic convolutional neural network (CNN) model and extracts more image features by adding convolutional layers, thereby improving the classification accuracy. We incorporated certain measures to improve the performance of the model. First, we used general methods such as setting a lower learning rate and shuffling to promote the rapid convergence of the model. Second, we used the data expansion technology to preprocess small datasets to increase the number of training data sets and suppress over-fitting. We applied the model to 10 monkey species and achieved outstanding performances. Experiments indicated that our proposed method achieved an accuracy of 87.92%, which is 26.1% higher than that of the traditional CNN method and 1.1% higher than that of the deep convolutional neural network ResNet50."
딥러닝 기반의 철강 표면의 결함 검출기,2021,"['Artificial intelligence', 'Convolutional neural network', 'Deep learning', 'Image classification', 'Metal surface defect', 'Surface defect detection (SDD)']",,"Steel surface defect should be detected and repaired in steel industry. Therefore, automatic detection of the steel surface defects plays a vital role in the steel manufacturing process. For the defect detection, machine learning based classification methods have been widely used such as HAAR feature-based cascade classifiers and support vector machines (SVM). As deep learning methods have been popular, the neural network based surface defect detection has been recently introduced. As for the methods, many researchers, in general, adopt a trained neural network, which is mainly winner in the recent ILSVRC (ImageNet Large Scale Visual Recognition Challenge). Then, the weights and last layers are modified to be used for surface defect detection (SDD), which is called transfer learning. In the previous researches, ResNet152 (winner in ILSVRC 2015) was used and the resulting performances were F1=0.975 and F1=0.912 in two different studies, respectively. However, the neural network used in their research has very wide and deep. Therefore, huge memories to save the trained weights and many multiplier–accumulators (MAC) are necessary, which means expensive hardware systems are essential to predict surface defect on the steel surface. This paper suggests a small neural network dedicated to surface defect detection. The proposed network has only three convolution layers and two fully connected layers. From the experimental results, we obtained F1=0.931 and minimum AUC (area under the curve)=0.995."
Wood Classification of Japanese Fagaceae using Partial Sample Area and Convolutional Neural Networks,2021,"['wood', 'microscopic image', 'sample selection', 'classification', 'convolutional neural network']",,"Wood identification is regularly performed by observing the wood anatomy, such as colour, texture, fibre direction, and other characteristics. The manual process, however, could be time consuming, especially when identification work is required at high quantity. Considering this condition, a convolutional neural networks (CNN)-based program is applied to improve the image classification results. The research focuses on the algorithm accuracy and efficiency in dealing with the dataset limitations. For this, it is proposed to do the sample selection process or only take a small portion of the existing image. Still, it can be expected to represent the overall picture to maintain and improve the generalisation capabilities of the CNN method in the classification stages. The experiments yielded an incredible F1 score average up to 93.4% for medium sample area sizes (200 × 200 pixels) on each CNN architecture (VGG16, ResNet50, MobileNet, DenseNet121, and Xception based). Whereas DenseNet121-based architecture was found to be the best architecture in maintaining the generalisation of its model for each sample area size (100, 200, and 300 pixels). The experimental results showed that the proposed algorithm can be an accurate and reliable solution."
유사 이미지 분류를 위한 딥 러닝 성능 향상 기법 연구,2021,"['분류', '딥 러닝', '유사 이미지', '컨볼루셔널 뉴럴 네트워크', '혼동률', 'Classification', 'Deep Learning', 'Similar Image', 'CNN', 'Confusion Rate']","딥 러닝을 활용한 컴퓨터 비전 연구는 여전히 대규모의 학습 데이터와 컴퓨팅 파워가 필수적이며, 최적의 네트워크 구조를 도출하기 위해 많은 시행착오가 수반된다. 본 연구에서는 네트워크 최적화나 데이터를 보강하는 것과 무관하게 데이터 자체의 특성만을 고려한 CR(Confusion Rate)기반의 유사 이미지 분류 성능 향상 기법을 제안한다. 제안 방법은 유사한 이미지 데이터를 정확히 분류하기 위해 CR을 산출하고 이를 손실 함수의 가중치에 반영함으로서 딥 러닝 모델의 성능을 향상시키는 기법을 제안한다. 제안 방법은 네트워크 최적화 결과와 독립적으로 이미지 분류 성능의 향상을 가져올 수 있으며, 클래스 간의 유사성을 고려해 유사도가 높은 이미지 식별에 적합하다. 제안 방법의 평가결과 HanDB에서는 0.22%, Animal-10N에서는 3.38%의 성능향상을 보였다. 제안한 방법은 다양한 Noisy Labeled 데이터를 활용한 인공지능 연구에 기반이 될 것을 기대한다.","Deep learning in computer vision has made accelerated improvement over a short period but large-scale learning data and computing power are still essential that required time-consuming trial and error tasks are involved to derive an optimal network model. In this study, we propose a similar image classification performance improvement method based on CR (Confusion Rate) that considers only the characteristics of the data itself regardless of network optimization or data reinforcement. The proposed method is a technique that improves the performance of the deep learning model by calculating the CRs for images in a dataset with similar characteristics and reflecting it in the weight of the Loss Function. Also, the CR-based recognition method is advantageous for image identification with high similarity because it enables image recognition in consideration of similarity between classes. As a result of applying the proposed method to the Resnet18 model, it showed a performance improvement of 0.22% in HanDB and 3.38% in Animal-10N. The proposed method is expected to be the basis for artificial intelligence research using noisy labeled data accompanying large-scale learning data."
변형 Residual Convolutional Neural Network 모델을 이용한 고효율 심전도 데이터 분석 기법,2021,"['MIT-BIH arrhythmia 데이터베이스', 'ResNet', 'ResNeXt', 'Adabound', '주입기법']",,
깊은 합성곱 신경망 모델에 따른 유방 초음파 영상 분류 성능 비교,2021,"['Breast Ultrasound', 'Breast Cancer', 'Tumor', 'Classification', 'VGG', 'ResNet', 'InceptionNet', 'DenseNet', 'EfficientNet', 'Convolutional Neural Network']",,"Breast ultrasound has been widely utilized for classifying tumors into benignancy and malignancy. The limitations of traditional breast ultrasound are the handcrafted features obtained by well-trained sonographers and subjective decision according to different individual experiences. Recently, CNN-based deep learning techniques have exhibited better performance in medical images. However, most research for deep learning in medical ultrasound adopts CNN models developed for natural images due to the lack of common standard and dataset. In this paper, we compare six DCNN models which exhibit good performance for natural images - VGGNet, ResNet, InceptionNet, DenseNet, and EfficientNet. Our classification results demonstrate that CNN models of relatively lower performance on natural images show better performance on gray-scale ultrasound images and further study of CNN models are needed focusing on the features of medical images."
합성곱 신경망을 이용한 컨포멀 코팅 PCB에 발생한 문제성 기포 검출 알고리즘,2021,"['Problematic Bubble', 'Bubble Detection', 'Conformal Coating', 'CNN', 'ResNet']",,"Conformal coating is a technology that protects PCB(Printed Circuit Board) and minimizes PCB failures. Since the defects in the coating are linked to failure of the PCB, the coating surface is examined for air bubbles to satisfy the successful conditions of the conformal coating. In this paper, we propose an algorithm for detecting problematic bubbles in high-risk groups by applying image signal processing. The algorithm consists of finding candidates for problematic bubbles and verifying candidates. Bubbles do not appear in visible light images, but can be visually distinguished from UV(Ultra Violet) light sources. In particular the center of the problematic bubble is dark in brightness and the border is high in brightness. In the paper, these brightness characteristics are called valley and mountain features, and the areas where both characteristics appear at the same time are candidates for problematic bubbles. However, it is necessary to verify candidates because there may be candidates who are not bubbles. In the candidate verification phase, we used convolutional neural network models, and ResNet performed best compared to other models. The algorithms presented in this paper showed the performance of precision 0.805, recall 0.763, and f1-score 0.767, and these results show sufficient potential for bubble test automation."
전기화재 원인분석을 위한 용융흔 외형 판별 딥러닝 알고리즘 설계,2021,"['전기 화재', '단락흔', '열흔', 'CNN', 'Resnet 알고리즘', 'Electric fire', 'Arc beads', 'Molten mark', 'CNN', 'Resnet']",,
안면 연령 예측을 위한 CNN기반의 히트 맵을 이용한 랜드마크 선정,2021,[],,"The purpose of this study is to improve the performance of the artificial neural network system for facial image analysis through the image landmark selection technique. For landmark selection, a CNN-based multi-layer ResNet model for classification of facial image age is required. From the configured ResNet model, a heat map that detects the change of the output node according to the change of the input node is extracted. By combining a plurality of extracted heat maps, facial landmarks related to age classification prediction are created. The importance of each pixel location can be analyzed through facial landmarks. In addition, by removing the pixels with low weights, a significant amount of input data can be reduced."
딥러닝을 이용한 마스크 착용 여부 검사 시스템,2021,[],,"Recently, due to COVID-19, studies have been popularly worked to apply neural network to mask wearing automatic detection system. For applying neural networks, the 1-stage detection or 2-stage detection methods are used, and if data are not sufficiently collected, the pretrained neural network models are studied by applying fine-tuning techniques. In this paper, the system is consisted of 2-stage detection method that contain MTCNN model for face recognition and ResNet model for mask detection. The mask detector was experimented by applying five ResNet models to improve accuracy and fps in various environments. Training data used 17,217 images that collected using web crawler, and for inference, we used 1,913 images and two one-minute videos respectively. The experiment showed a high accuracy of 96.39% for images and 92.98% for video, and the speed of inference for video was 10.78fps."
심층 CNN 기반 구조를 이용한 토마토 작물 병해충 분류 모델,2021,"['Convolutional Neural Networks', 'Deep Learning', 'Transfer Learning', 'Fine Tuning', 'Plant Diseases Classification']","토마토 작물은 병해충의 영향을 많이 받기 때문에 이를 예방하지 않으면 농업 경제에 막대한 손실을 초래할 수 있다. 따라서 토마토의 다양한 병해충의 진단을 빠르고 정확하게 진단하는 시스템이 요구된다. 본 논문에서는 ImageNet 데이터 셋 상에서 다양하게 사전 학습된 딥러닝 기반 CNN 모델을 적용하여 토마토의 9가지 병해충 및 정상인 경우의 클래스를 분류하는 시스템을 제안한다. PlantVillage 데이터 셋으로부터 발췌한 토마토 잎의 이미지 셋을 3가지 딥러닝 기반 CNN 구조를 갖는 ResNet, Xception, DenseNet의 입력으로 사용한다. 기본 CNN 모델 위에 톱-레벨 분류기를 추가하여 제안 모델을 구성하였으며, 훈련 데이터 셋에 대해 5-fold 교차검증 기법을 적용하여 학습시켰다. 3가지 제안 모델의 학습은 모두 기본 CNN 모델의 계층을 동결하여 학습시키는 전이 학습과 동결을 해제한 후 학습률을 매우 작은 수로 설정하여 학습시키는 미세 조정 학습 두 단계로 진행하였다. 모델 최적화 알고리즘으로는 SGD, RMSprop, Adam을 적용하였다. 실험 결과는 RMSprop 알고리즘이 적용된 DenseNet CNN 모델이 98.63%의 정확도로 가장 우수한 결과를 보였다.","Tomato crops are highly affected by tomato diseases, and if not prevented, a disease can cause severe losses for the agricultural economy. Therefore, there is a need for a system that quickly and accurately diagnoses various tomato diseases. In this paper, we propose a system that classifies nine diseases as well as healthy tomato plants by applying various pretrained deep learning-based CNN models trained on an ImageNet dataset. The tomato leaf image dataset obtained from PlantVillage is provided as input to ResNet, Xception, and DenseNet, which have deep learning-based CNN architectures. The proposed models were constructed by adding a top-level classifier to the basic CNN model, and they were trained by applying a 5-fold cross-validation strategy. All three of the proposed models were trained in two stages: transfer learning (which freezes the layers of the basic CNN model and then trains only the top-level classifiers), and fine-tuned learning (which sets the learning rate to a very small number and trains after unfreezing basic CNN layers). SGD, RMSprop, and Adam were applied as optimization algorithms. The experimental results show that the DenseNet CNN model to which the RMSprop algorithm was applied output the best results, with 98.63% accuracy."
전이학습기반 앙상블 딥러닝을 이용한 COVID-19 환자 영상 분류,2021,"['딥러닝', '스태킹 앙상블', '전이학습', 'X-ray/CT 영상', 'COVID-19', 'deep learning', 'stacking ensemble', 'transfer learning', 'X-ray/CT image']","COVID-19 팬데믹으로 인한 피해는 공중 보건적 측면 뿐 만 아니라 정치, 경제, 사회, 문화 전반에 심각한 영향을 미치고 있다. 현재까지 COVID-19 표준 진단검사인 RT-PCR 검사는 검체의 종류, 검체 채취 방법 및 보관에 따라 검사 결과가 달라질 수 있고 코로나바이러스 (SARS-CoV-2) 감염 후 검사 시점에도 영향을 받는다. 본 논문은 전이학습 (transfer learning) 기반 앙상블 딥러닝을 사용하여 COVID-19 환자 X-ray/CT 영상을 분류하고자 한다. 여기서 사용된 전이학습은 CNN (convolutional neural network) 기반인 AlexNet, ResNet, Inception V3, DenseNet 모형이다. 본 연구에서 제안한 스태킹 앙상블 (stacking ensemble) 모형은 세 단계에 걸쳐 이루어진다. 첫 번째 단계에서는 기본모형 (base model)로서 여러 전이학습 모형을 이용하여 예측된 결과들을 얻고, 두 번째 단계에서는 concatenate layer를 통해 이들 결과들을 결합한 다음, 세 번째 단계에서는 메타모형(meta model), 여기서는 DNN (deep neural network) 모형을 적용하여 최종 분류한다. 본 논문에서 제안된 앙상블 모형의 성능평가를 위해 3가지 실제 COVID-19 환자의 X-ray/CT 영상데이터셋을 고려하였으며 여러 가지 성능평가 지표를 가지고 기존의 전이학습 모형과 앙상블 모형과 비교 분석하였다. 성능실험결과, 전반적으로 제안된 앙상블 모형이 기존의 전이학습 모형과 앙상블 모형보다 우수함을 보였다.","The damage caused by the COVID-19 pandemic has a serious impact not only on public health but also on politics, economy, society, and culture as a whole. To date, the RT-PCR test, a COVID-19 standard diagnostic test, may vary depending on the type of sample, sample collection method, and storage, and is also affected by the time of the test after infection with COVID-19. This paper attempts to classify COVID-19 patients with X-ray/CT images using transfer learning-based ensemble deep learning. The transfer learning used here is the AlexNet, ResNet, Inception V3, and DenseNet models based on the convolutional neural network (CNN). The stacking ensemble model proposed in this study takes place over three stages. In the first step, predicted results are obtained using several transfer learning models, in the second step, they are combined through a concatenate layer, and in the third step, a deep neural network (DNN) model is applied and finally classified. For the performance evaluation of the ensemble model proposed in this paper, three actual COVID-19 X-ray/CT image datasets were considered, and various performance evaluation indicators were compared and analyzed with the transfer learning model and the existing ensemble model. As a result of the performance experiment, the overall proposed ensemble model was superior to the transfer learning model and the existing ensemble model."
영상처리와 딥러닝 네트워크를 결합한 자동차 번호판 인식시스템,2021,"['자동차 번호판 인식', '딥러닝', '영상처리 결합', '임베디드', '경량화', 'License plate recognition', 'Deep learning', 'Image processing combination', 'Embedded', 'Lightening']","자동차 번호판인식 시스템은 기존에는 영상처리만을 이용한 방식으로 매우 빠른 실시간 처리가 가능하나 다양한 번호판에는 적용하기 어렵다는 한계가 있었고, 딥러닝을 이용하는 경우 다양성과 정확성이 좋아지나 고성능의 그래픽카드가 필요하고 처리하는 데 시간이 매우 오래 걸리는 문제점이 있었다. 본 논문은 각 방식의 장점을 살려 그래픽카드가 없는 일반 사무용 PC에서도 실시간 처리가 가능하며 높은 정확성을 가진 자동차 번호판인식 시스템을 제안하며 더 나아가 사무용 PC가 아닌 임베디드 환경에서도 사용할 수 있도록 경량화한 시스템을 제안한다. 제안하는 시스템은 기존의 번호판인식 시스템과 동일하게 [번호판검출]-[문자영역 분할]-[문자인식]의 3단계 과정을 거치며 각 과정에는 딥러닝 모델로서는 SSD-MobileNet, ResNet 네트워크를 사용하였고, 영상처리 기법으로는 Edge를 검출한 후 수직, 수평으로 전파하면서 관심 영역을 찾는 CLNF 알고리즘을 사용하였다. 제안하는 시스템으로 지하주차장 및 톨게이트 등의 장소에서 얻은 4,389장의 이미지로 테스트하였을 때 충분히 레이어가 깊은 경우 98.2% 정확성을 보여 주었고, 레이어가 얕아질수록 영상처리 결합 여부에 따른 정확성 차이가 커짐을 확인할 수 있었다.","In the previous vehicle license plate recognition(LPR) systems, image processing method is able to process very fast in real time, but there is a limitation that it is difficult to apply to various license plates. Deep learning enables the variety and accuracy of LPR to be good, but ir reauires high-performance graphic cards and very long time processing time. In order to get around the advantages and disadvantages of both approaches, this paper proposes a light-weight vehicle license plate recognition system that can be processed in real time even using an embedded board or a general office PC without graphic cards. The proposed system consists of the three steps [license plate detection]-[character segmentation]-[character recognition] in the same with the conventional license plate recognition system. For each step, SSD-MobileNet and ResNet networks were used as deep learning models. As an image processing technique, the CLNF algorithm was used to detect an edge and to propagate vertically and horizontally for finding an ROI(region of interest). In the experiments for testing of the proposed system using 4,389 images obtained at places such as underground parking lots and toll gates, the accuracy was 98.2%. As the layer became shallower, the accuracy difference according to the image processing combination was bigger."
마이크로스코프 이미지의 딥러닝 기반 이상검출,2021,"['딥러닝', '마이크로스코프', '이상검출', '흡연', '혓바닥', 'abnormal detection', 'deep learning', 'microscope', 'tongue surface', 'smoke']","흡연자 중에서 담배가 인체에 유해하다는 사실을 모르는 사람은 없을 것임에도 불구하고, 정작 금연 성공률은 높지 않다. 금연을 위한 의지를 지속적으로 굳건하게 다지기 위하여 병원에서 실시하는 건강검진과 PET(positron emission tomography) 이미지를 통한 암 검사의 결과가 도움이 되지만, 일상생활 중에 간단히 실시할 수 있는 방법이 아니다. 본 연구에서는 일상생활 중에 관찰 가능한 흡연자의 신체 부위를 딥러닝 기반 마이크로스코프 이미지 측정 및 분석을 통하여 흡연자와 비흡연자의 차이를 검출할 수 있는 비침습적 방법을 제안하였다. 우선, 관찰 부위를 흡연시 직접적인 접촉을 하는 혓바닥 표면으로 설정하였다. 다음으로, 마이크로스코프로 혓바닥 표면(410배 확대)을 흡연자 10명과 비흡연자 10명의 실험 참가자를 통하여 데이터 셋(총 1,000장)을 구축하여 그 중 80%를 딥러닝 모델의 학습에 사용하였고, 나머지 20%는 예측에 사용하였다. 딥러닝 모델을 스케일링하는 방법(width scaling, depth scaling, resolution scaling) 중 한 가지 방법만 적용하는 VGG, ResNet, DenseNet과 세 가지를 모두 적용하여 스케일링하는 EfficientNet의 성능을 비교하여 모세혈관 이미지 처리에 EfficientNet의 우수성을 확인해 볼 수 있었다.","The success rate of the no-smoking campaign has been low, although everybody knows that cigarettes are harmful to the human health. The results of both regular health and cancer checks in the hospital are useful for strengthening the human intention for quitting the smoking, however, those methods are difficult to use in daily life because of the use of large-scaled particular devices such as PET(positron emission tomography). Thus, this study proposed a non-invasive method that detects the difference between smokers and non-smokers through deep-learning-based analysis. At first, observing parts were decided to the tongue surface. Then, a data set(total 1,000) was made through the experiment to measure the tongue surface(410 times magnification) with the participants of 10 smokers and 10 non-smokers. The 80% ratio of data set was used for the train, and the left 20% was for the prediction. As a result, it was found that the classification through EfficientNet with the compound scaling including three scaling methods of width scaling, depth scaling and resolution scaling was much better than other models including VGG, ResNet, and DenseNet with the only one scaling."
심전도 신호 분류를 위한 1D CNN 모델 구성 요소의 최적화,2021,"['Deep learning', 'Electrocardiogram', 'CNN', 'ResNet', 'Arrhythmia Detection', '딥러닝', '심전도', '부정맥 검출']","본 논문에서는 딥러닝 모델을 이용하여 모바일 기기의 심전도 신호 측정 데이터를 분류한다. 비정상 심장박동을 높은 정확도로 분류하기 위해 딥러닝 모델의 구성 요소 세 가지를 선정하고 요소의 조건 변화에 따른 분류 정확도를 비교한다. 심전도 신호 데이터의 특징을 스스로 추출할 수 있는 CNN 모델을 적용하고 모델을 구성하는 모델의 깊이, 최적화 방법, 활성화 함수의 조건을 변경하여 총 48개의 조합의 성능을 비교한다. 가장 높은 정확도를 보이는 조건의 조합을 도출한 결과 컨볼루션 레이어 19개, 최적화 방법 SGD, 활성화 함수 Mish를 적용하였을 때 정확도 97.88%로 모든 조합 중 가장 높은 분류 정확도를 얻었다. 이 실험에서 CNN을 활용한 1-채널 심전도 신호의 특징 추출과 비정상 박동 검출의 적합성을 확인하였다.","In this paper, we classify ECG signal data for mobile devices using deep learning models. To classify abnormal heartbeats with high accuracy, three factors of the deep learning model are selected, and the classification accuracy is compared according to the changes in the conditions of the factors. We apply a CNN model that can self-extract features of ECG data and compare the performance of a total of 48 combinations by combining conditions of the depth of model, optimization method, and activation functions that compose the model. Deriving the combination of conditions with the highest accuracy, we obtained the highest classification accuracy of 97.88% when we applied 19 convolutional layers, an optimization method SGD, and an activation function Mish. In this experiment, we confirmed the suitability of feature extraction and abnormal beat detection of 1-channel ECG signals using CNN."
Generating 3D texture models of vessel pipes using 2D texture transferred by object recognition,2021,"['augmented reality', 'CycleGAN', 'ResNet', 'normalization', 'texture', '3D model']",,"Research and development of smart vessels has progressed significantly in recent years, and ships have become high-value technology-intensive resources. These ships entail high production costs and long-life cycles. Thus, modernized technical design, professional training, and aggressive maintenance are important factors in the efficient management of ships. With the continuing digital revolution, the industrial shipbuilding applicability of augmented reality (AR) and virtual reality (VR) technologies as well as related 3D system modeling and processes has increased. However, resolving the differences between AR/VR and real-world models remains burdensome. This problem is particularly evident when mapping various texture characteristics to virtual objects. To mitigate the burden and improve the performance of such technologies, it is necessary to directly define various texture characteristics or to express them using expensive equipment. The use of deep-learning-based CycleGAN, however, has gained attention as a method of learning and automatically mapping real-object textures. Thus, we seek to use CycleGAN to improve the immersive capacities of AR/VR models and to reduce production costs for shipbuilding. However, when applying CycleGAN’s textures to pipe structures, the performance is insufficient for direct application to industrial piping networks. Therefore, this study investigates an improved CycleGAN algorithm that can be specifically applied to the shipbuilding industry by combining a modified object-recognition algorithm with a double normalization method. Thus, we demonstrate that basic knowledge on the production of AR industrial pipe models can be applied to virtual models through machine learning to deliver low-cost and high-quality textures. Our results provide an on-ramp for future CycleGAN studies related to the shipbuilding industry."
딥러닝 기반의 PCB 부품 문자인식을 위한 코어 셋 구성,2021,"['Deep Learning', 'Coreset', 'PCB Inspection', 'OCR', 'ResNet']",,
자궁경부 영상에서의 라디오믹스 기반 판독 불가 영상 분류 알고리즘 연구,2021,"['Cervical cancer', 'Radiomics', 'Laplacian variance', 'Euclidean distance', 'ResNet-50']",,"Recently, artificial intelligence for diagnosis system of obstetric diseases have been actively studied. Artificial intelligence diagnostic assist systems, which support medical diagnosis benefits of efficiency and accuracy, may experience problems of poor learning accuracy and reliability when inappropriate images are the model's input data. For this reason, before learning, We proposed an algorithm to exclude unread cervical imaging. 2,000 images of read cervical imaging and 257 images of unread cervical imaging were used for this study. Experiments were conducted based on the statistical method Radiomics to extract feature values of the entire images for classification of unread images from the entire images and to obtain a range of read threshold values. The degree to which brightness, blur, and cervical regions were photographed adequately in the image was determined as classification indicators. We compared the classification performance by learning read cervical imaging classified by the algorithm proposed in this paper and unread cervical imaging for deep learning classification model. We evaluate the classification accuracy for unread Cervical imaging of the algorithm by comparing the performance. Images for the algorithm showed higher accuracy of 91.6% on average. It is expected that the algorithm proposed in this paper will improve reliability by effectively excluding unread cervical imaging and ultimately reducing errors in artificial intelligence diagnosis."
데이터 분석을 통한 지역별 고령친화도 시각화,2021,"['고령친화도시', '인구고령화', '지표', 'GIS', 'Smart Farm', 'Deep Learning', 'ResNet', 'Convolution Neural Network']","전 세계적인 인구고령화 현상이 사회적으로 문제가 되고 있다. 우리나라 역시 초고령화 사회에 급속도로 진입하면서 사회적 생활공간의 실질적 변화가 필요하게 되었다. 이에 본 연구에서는 WHO가 제시한 ‘고령친화도시’ 개념과 가이드라인을 중심으로 군집분석과 EDA를 활용해 국내 고령친화도 현황을 분석하였다. 더불어 경기도의 이천시와 안성시를 중심으로 관련 데이터를 비교·분석 후 GIS 기반 데이터 시각화를 수행하였다. 분석 결과 B등급인 이천시에 비교하여 안성시의 고령친화도는 인구, 면적 등의 조건이 비슷함에도 불구하고 D등급으로 측정되어 매우 낮은 것으로 나타났다. 본 연구의 결과를 통해 정책적으로는 전국 단위의 고령친화도를 파악하여 효과적인 복지 정책 가이드라인 제시와 더불어, 한정된 정부예산에서 정비가 시급한 부분에 대한 우선적 고려가 가능할 것으로 기대된다.","The population aging around the world is becoming a social problem. As Korea also entered a super-aged society rapidly, a substantial change in social living space became necessary. Therefore, this study analyzes the current status of elderly affinity in Korea using cluster analysis and EDA, focusing on the WHO's concept of ‘aged-friendly city’ and eight area guidelines. In addition, GIS-based data visualization carries after comparing and analyzing related data, centering on Icheon and Anseong in Gyeonggi province. As a result of the analysis, compared to Icheon, which is grade B, the elderly affinity of Anseong was measured as grade D despite similar conditions such as population and area. Through the results of this study, it is expected that it will be possible to identify the relative Age-Friendliness the country in terms of policy, present effective welfare policy guidelines, and prioritize areas where maintenance is urgent in the limited government budget"
LDAM 손실 함수를 활용한 클래스 불균형 상황에서의 옷차림 T.P.O 추론 모델 학습,2021,"['융합', '패션', 'T.P.O', '다중 레이블', '클래스 불균형', '딥러닝', 'Convergence', 'Fashion', 'T.P.O', 'Multi-label problem', 'Class imbalance problem', 'Deep learning']","의복을 착용하는데 있어 목적 상황에 부합하는 옷차림을 구성하는 것은 중요하다. 따라서 인공지능 기반의 다양 한 패션 추천 시스템에서 의복 착용의 T.P.O(Time, Place, Occasion)를 고려하고 있다. 하지만 옷차림으로부터 직접 T.P.O를 추론하는 연구는 많지 않은데, 이는 문제 특성 상 다중 레이블 및 클래스 불균형 문제가 발생하여 모델 학습을 어렵게 하기 때문이다. 이에 본 연구에서는 label-distribution-aware margin(LDAM) loss를 도입하여 옷차림의 T.P.O를 추론할 수 있는 모델을 제안한다. 모델의 학습 및 평가를 위한 데이터셋은 패션 쇼핑몰로부터 수집되었고 이를 바탕으로 성능을 측정한 결과, 제안 모델은 비교 모델 대비 모든 T.P.O 클래스에서 균형잡힌 성능을 보여주는 것을 확인할 수 있었다.","When a person wears clothing, it is important to configure an outfit appropriate to the intended occasion. Therefore, T.P.O(Time, Place, Occasion) of the outfit is considered in various fashion recommendation systems based on artificial intelligence. However, there are few studies that directly infer the T.P.O from outfit images, as the nature of the problem causes multi-label and class imbalance problems, which makes model training challenging. Therefore, in this study, we propose a model that can infer the T.P.O of outfit images by employing a label-distribution-aware margin(LDAM) loss function. Datasets for the model training and evaluation were collected from fashion shopping malls. As a result of measuring performance, it was confirmed that the proposed model showed balanced performance in all T.P.O classes compared to baselines."
Deep Convolutional Neural Network Architectures for Tonal Frequency Identification in a Lofargram,2021,"['Convolutional neural networks', 'lofar analysis', 'sonar analysis', 'underwater recognition.']",,"Advances in convolutional neural networks (CNNs) have driven the development of computer vision. Recent CNN architectures, such as those with skip residual connections (ResNets) or densely connected architectures (DenseNets), have facilitated backpropagation and improved the performance of feature extraction and classification. Detecting objects in underwater environments by analyzing sound navigation and ranging (sonar) signals is considered an important process that should be automated. Several previous approaches have addressed this challenge; however, there has been no in-depth study of CNN architectures that effectively analyze sonar grams. In this paper, we have presented the identification of tonal frequencies in lofargrams using recent CNN architectures. Our study includes 175 CNN models that are derived from five different CNN architectures and 35 different input patch sizes. The study results showed that the accuracy of the best model was as high as 96.2% for precision and 99.5% for recall, with an inference time of 0.184 s."
Cerebral hemorrhage detection and localization with medical imaging for cerebrovascular disease diagnosis and treatment using explainable deep learning,2021,['Cerebral hemorrhage prediction · Cerebrovascular disease · Explainable artificial intelligence'],,"Cerebral hemorrhages require rapid diagnosis and intensive treatment. This study aimed to detect cerebral hemorrhages and their locations in images using a deep learning model applying explainable deep learning. Normal brain images with no hemorrhages and images with subarachnoid, intraventricular, subdural, epidural, and intraparenchymal hemorrhages according to computed tomography (CT) (n = 200) were analyzed. A ResNet deep learning model, including image processing, was utilized. The visual explanation from a heatmap was made at the hemorrhage location using a gradient-class activation map (Grad-CAM). To evaluate the performance of the deep learning system, the accuracy, sensitivity, and specificity were determined. A hemorrhage prediction system for images of normal brains and brains with subarachnoid, intraventricular, subdural, epidural, and intraparenchymal hemorrhages was built. The Grad-CAM representation indicated the location of the hemorrhages in these images. In the prediction results, accurate predictions of the hemorrhage areas were made and visualizations of the corresponding locations overlapped in the images within (− 4, 1) pixel difference. The evaluation of the system performance showed an accuracy of 0.81 with a sensitivity of 0.67 and specificity of 0.86. These results constitue a proof of concept for the use of explainable artificial intelligence (XAI) to detect cerebral hemorrhages and visualize their locations in medical images, which will allow rapid diagnosis and treatment."
자동화 균열 탐지 시스템을 위한 딥러닝 모델에 관한 연구,2021,"['Surface Inspection', 'Crack Detection', 'Computer Vision', 'Deep Learning', '표면 검사', '균열 탐지', '컴퓨터 비전', '딥러닝']",,"Cracks affect the robustness of infrastructures such as buildings, bridge, pavement, and pipelines. This paper presents an automatedcrack detection system which detect cracks in diverse surfaces. We first constructed the combined crack dataset, consists of multiplecrack datasets in diverse domains presented in prior studies. Then, state-of-the-art deep learning models in computer vision tasks includingVGG, ResNet, WideResNet, ResNeXt, DenseNet, and EfficientNet, were used to validate the performance of crack detection. We dividedthe combined dataset into train (80%) and test set (20%) to evaluate the employed models. DenseNet121 showed the highest accuracyat 96.20% with relatively low number of parameters compared to other models. Based on the validation procedures of the advanced deeplearning models in crack detection task, we shed light on the cost-effective automated crack detection system which can be appliedto different surfaces and structures with low computing resources."
Convolutional Neural Network 기반 EBG 구조 설계를 통한 고속 PCB 노이즈 저감,2021,"['Simultaneous Switching Noise', 'Electromagnetic Band Gap', 'Machine Learning', 'Convolutional Neural Network']","기술이 빠르게 발전하여 디지털 시스템의 동작 주파수는 수 GHz 대역까지 증가했다. 이로 인하여 Simultaneous Switching Noise 문제가 증가했고, 이를 줄이기 위해 Electromagnetic Band Gap(EBG) 구조가 많이 연구된다. EBG 구조 설계에서 중요한 과정 중 하나는 노이즈를 저감하는 Stopband 대역을 예측하는 것이다. 기존에 3차원 전자장 시뮬레이션 프로그램을 이용하는 방법과 Floquet 이론 기반의 수식을 이용하는 방법이 있으나, 한계점이 존재한다. 본 논문에서는 Convolutional Neural Network(CNN)을 이용하여 EBG 구조의 Stopband 대역을 예측하는 새로운 방법을 제안한다. 또한 기본 CNN 구조, GoogLeNet, ResNet, DenseNet과 같은 CNN Architecture 모델을 활용하여 어떤 CNN 구조가 Stopband 대역 예측에 높은 성능을 보이는지 분석한다. 900개의 EBG 구조 모델에 대해서 학습시킨 후 CNN 구조의 mean absolute error를 비교한 결과, DenseNet이 가장 우수한 성능을 보임을 확인하였다.","With rapid advances in technology, the operating frequencies of digital systems have increased to several GHz bands. This has led to an increase in simultaneous switching noise(SSN). To reduce SSN, electromagnetic bandgap(EBG) structures have been intensively studied. One of the critical steps in the design of an EBG structure is to predict the stopband that reduces SSN. Existing methods include using a 3D electromagnetic field simulation program or equations based on the Floquet theory. However, these have limitations. In this study, we verified a new method for predicting the stopband using a convolutional neural network(CNN). Specifically, a CNN architectural model was used to compare structures that perform well in predicting the stopband. It was also used to confirm that the DenseNet showed high performance."
합성곱 신경망을 이용한 프로펠러 캐비테이션 침식 위험도 연구,2021,"['Convolutional Neural Network(CNN', '합성곱 신경망)', 'Deep learning(딥러닝)', 'Propeller(프로펠러)', 'Cavitation(캐비테이션)', 'Erosion(침식)']",,"Cavitation erosion is one of the major factors causing damage by lowering the structural strength of the marine propeller and the risk of it has been qualitatively evaluated by each institution with their own criteria based on the experiences. In this study, in order to quantitatively evaluate the risk of cavitation erosion on the propeller, we implement a deep learning algorithm based on a convolutional neural network. We train and verify it using the model tests results, including cavitation characteristics of various ship types. Here, we adopt the validated well-known networks such as VGG, GoogLeNet, and ResNet, and the results are compared with the expert’s qualitative prediction results to confirm the feasibility of the prediction algorithm using a convolutional neural network."
고성능 CNN 기반 지정맥 인증 시스템 구현,2021,"['AI', 'Biometric authentication', 'Finger vein recognizer']",,"Biometric technology using finger veins is receiving a lot of attention due to its high security, convenience and accuracy. And the recent development of deep learning technology has improved the processing speed and accuracy for authentication. However, the training data is a subset of real data not in a certain order or method and the results are not constant. so the amount of data and the complexity of the artificial neural network must be considered. In this paper, the deep learning model of Inception-Resnet-v2 was used to improve the high accuracy of the finger vein recognizer and the performance of the authentication system, We compared and analyzed the performance of the deep learning model of DenseNet-201. The simulations used data from MMCBNU_6000 of Jeonbuk National University and finger vein images taken directly. There is no preprocessing for the image in the finger vein authentication system, and the results are checked through EER."
자율 운항 선박을 위한 딥 러닝 기반 선박 이미지 분류 방법,2021,"['Image Classification', 'Object Detection', 'Convolutional Neural Network', 'Deep Learning', 'Heatmap', 'Autonomous Ship']",,"In the last few years, researches on autonomous ships have attracted attention. One of the essential techniques required for autonomous ships is the awareness of surroundings, including detection and classification of objects. Although researches on computer vision regarding the classification of ship images are still making progress, it is challenging to encounter a lack of enough database that was adequately labeled for ship classification. In this study, data obtained from Singapore Maritime Dataset (SMD) and public datasets such as MARVEL, FleetMon, and VesselFinder were labeled and integrated into a unified dataset for further study for ship classification. The ship image dataset was classified into seven classes, including bulk carrier, container ship, cruise ship, naval surface ship, tanker, tug boat, and buoy. Subsequently, Convolutional Neural Networks (CNNs) based on GoogleNet, VGG16, and ResNet were implemented for ship image classification, and a comparative test was done. As a result, the CNNs which were trained with the unified dataset showed high accuracy. The classification results were analyzed by the heatmap visualization with Grad-CAM, which indicates critical features best activating each class of ships, and further discussion was made."
딥러닝을 이용한 핸드크림의 마찰 시계열 데이터 분류,2021,"['Time Series Classification', 'Deep Learning', 'Tribology', 'Cosmetics']",,"The sensory stimulation of a cosmetic product has been deemed to be an ancillary aspect until a decade ago. That point of view has drastically changed on different levels in just a decade. Nowadays cosmetic formulators should unavoidably meet the needs of consumers who want sensory satisfaction, although they do not have much time for new product development. The selection of new products from candidate products largely depend on the panel of human sensory experts. As new product development cycle time decreases, the formulators wanted to find systematic tools that are required to filter candidate products into a short list. Traditional statistical analysis on most physical property tests for the products including tribology tests and rheology tests, do not give any sound foundation for filtering candidate products. In this paper, we suggest a deep learning-based analysis method to identify hand cream products by raw electric signals from tribological sliding test. We compare the result of the deep learning-based method using raw data as input with the results of several machine learning-based analysis methods using manually extracted features as input. Among them, ResNet that is a deep learning model proved to be the best method to identify hand cream used in the test. According to our search in the scientific reported papers, this is the first attempt for predicting test cosmetic product with only raw time-series friction data without any manual feature extraction. Automatic product identification capability without manually extracted features can be used to narrow down the list of the newly developed candidate products."
"전산화 단층 촬영(Computed tomography, CT) 이미지에 대한 EfficientNet 기반 두개내출혈 진단 및 가시화 모델 개발",2021,"['Deep-learning', 'EfficientNet', 'Intracranial hemorrhage', 'Computed tomography images']",,"Intracranial hemorrhage (ICH) refers to acute bleeding inside the intracranial vault. Not only does this devastating disease record a very high mortality rate, but it can also cause serious chronic impairment of sensory, motor, and cognitive functions. Therefore, a prompt and professional diagnosis of the disease is highly critical. Noninvasive brain imaging data are essential for clinicians to efficiently diagnose the locus of brain lesion, volume of bleeding, and subsequent cortical damage, and to take clinical interventions. In particular, computed tomography (CT) images are used most often for the diagnosis of ICH. In order to diagnose ICH through CT images, not only medical specialists with a sufficient number of diagnosis experiences are required, but even when this condition is met, there are many cases where bleeding cannot be successfully detected due to factors such as low signal ratio and artifacts of the image itself. In addition, discrepancies between interpretations or even misinterpretations might exist causing critical clinical consequences. To resolve these clinical problems, we developed a diagnostic model predicting intracranial bleeding and its subtypes (intraparenchymal, intraventricular, subarachnoid, subdural, and epidural) by applying deep learning algorithms to CT images. We also constructed a visualization tool highlighting important regions in a CT image for predicting ICH. Specifically, 1) 27,758 CT brain images from RSNA were pre-processed to minimize the computational load. 2) Three different CNN-based models (ResNet, EfficientNet-B2, and EfficientNet-B7) were trained based on a training image data set. 3) Diagnosis performance of each of the three models was evaluated based on an independent test image data set: As a result of the model comparison, EfficientNet-B7's performance (classification accuracy = 91%) was a way greater than the other models. 4) Finally, based on the result of EfficientNet-B7, we visualized the lesions of internal bleeding using the Grad-CAM. Our research suggests that artificial intelligence-based diagnostic systems can help diagnose and treat brain diseases resolving various problems in clinical situations."
다중 레이블 분류를 활용한 안면 피부 질환 인식에 관한 연구,2021,"['Deep Learning', 'Multi-Label Classification', 'Skin Diseases', '딥 러닝', '다중 레이블 분류', '피부 질환']",,"Recently, as people's interest in facial skin beauty has increased, research on skin disease recognition for facial skin beauty is being conducted by using deep learning. These studies recognized a variety of skin diseases, including acne. Existing studies can recognize only the single skin diseases, but skin diseases that occur on the face can enact in a more diverse and complex manner. Therefore, in this paper, complex skin diseases such as acne, blackheads, freckles, age spots, normal skin, and whiteheads are identified using the Inception-ResNet V2 deep learning mode with multi-label classification. The accuracy was 98.8%, hamming loss was 0.003, and precision, recall, F1-Score achieved 96.6% or more for each single class."
