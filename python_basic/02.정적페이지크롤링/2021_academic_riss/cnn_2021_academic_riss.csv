title,date,keywords,abstract,multilingual_abstract
Cross-Domain Text Sentiment Classification Method Based on the CNN-BiLSTM-TE Model,2021,"['Bidirectional Long Short-Term Memory', 'Convolutional Neural Network', 'Deep Learning', 'Sentiment Analysis', 'Topic Extraction']",국문 초록 정보 없음,"To address the problems of low precision rate, insufficient feature extraction, and poor contextual ability in existing text sentiment analysis methods, a mixed model account of a CNN-BiLSTM-TE (convolutional neural network, bidirectional long short-term memory, and topic extraction) model was proposed. First, Chinese text data was converted into vectors through the method of transfer learning by Word2Vec. Second, local features were extracted by the CNN model. Then, contextual information was extracted by the BiLSTM neural network and the emotional tendency was obtained using softmax. Finally, topics were extracted by the term frequency-inverse document frequency and K-means. Compared with the CNN, BiLSTM, and gate recurrent unit (GRU) models, the CNN-BiLSTM-TE model’s F1-score was higher than other models by 0.0147, 0.006, and 0.0052, respectively. Then compared with CNN-LSTM, LSTM-CNN, and BiLSTM-CNN models, the F1-score was higher by 0.0071, 0.0038, and 0.0049, respectively. Experimental results showed that the CNN-BiLSTM-TE model can effectively improve various indicators in application. Lastly, performed scalability verification through a takeaway dataset, which has great value in practical applications."
WiFi 신호를 활용한 CNN 기반 사람 행동 인식 시스템 설계 및 구현,2021,"['Accelerator', 'CNN', 'FPGA', 'Human Activity Recognition', 'WiFi signal']","기존의 사람 행동 인식 시스템은 웨어러블 센서, 카메라와 같은 장치를 통해 행동을 탐지하였다. 그러나, 이와 같은 방법들은 추가적인 장치와 비용이 요구되고, 특히 카메라 장치의 경우 사생활 침해 문제가 발생한다. 이미 설치되어 있는 WiFi 신호를 사용한다면 해당 문제를 해결할 수 있다는 장점이 있다. 본 논문에서는 WiFi 신호의 채널 상태 정보를 활용한 CNN 기반 사람 행동 인식 시스템을 제안하고, 가속 하드웨어 구조 설계 및 구현 결과를 제시한다. 해당 시스템은 실내 공간에서 학습 중 나타날 수 있는 네 가지 행동에 대해 정의하였고, 그에 대한 WiFi의 채널 상태 정보를 CNN으로 분류하여 평균 정확도는 91.86%를 보였다. 또한, 가속화를 위해 CNN 분류기에서 연산량이 가장 많은 완전 연결 계층에 대한 가속 하드웨어 구조 설계 결과를 제시하였다. FPGA 디바이스 상에서 성능 평가 결과, 기존 software 기반 시스템 대비 4.28배 빠른 연산 시간을 보임을 확인하였다.","Existing human activity recognition systems detect activities through devices such as wearable sensors and cameras. However, these methods require additional devices and costs, especially for cameras, which cause privacy issue. Using WiFi signals that are already installed can solve this problem. In this paper, we propose a CNN-based human activity recognition system using channel state information of WiFi signals, and present results of designing and implementing accelerated hardware structures. The system defined four possible behaviors during studying in indoor environments, and classified the channel state information of WiFi using convolutional neural network (CNN), showing and average accuracy of 91.86%. In addition, for acceleration, we present the results of an accelerated hardware structure design for fully connected layer with the highest computation volume on CNN classifiers. As a result of performance evaluation on FPGA device, it showed 4.28 times faster calculation time than software-based system."
Sentienl-1 SAR 영상을 활용한 유류 분포특성과 CNN 구조에 따른 유류오염 탐지모델 성능 평가,2021,"['Sentinel-1 SAR', 'Oil Spill Detection', 'CNN', 'U-net', 'Oil spill distribution characteristics']",국문 초록 정보 없음,"Detecting oil spill area using statistical characteristics of SAR images has limitations in that classification algorithm is complicated and is greatly affected by outliers. To overcome these limitations, studies using neural networks to classify oil spills are recently investigated. However, the studies to evaluate whether the performance of model shows a consistent detection performance for various oil spill cases were insufficient. Therefore, in this study, two CNNs (Convolutional Neural Networks) with basic structures (Simple CNN and U-net) were used to discover whether there is a difference in detection performance according to the structure of CNN and distribution characteristics of oil spill. As a result, through the method proposed in this study, the Simple CNN with contracting path only detected oil spill with an F1 score of 86.24% and U-net, which has both contracting and expansive path showed an F1 score of 91.44%. Both models successfully detected oil spills, but detection performance of the U-net was higher than Simple CNN. Additionally, in order to compare the accuracy of models according to various oil spill cases, the cases were classified into four different categories according to the spatial distribution characteristics of the oil spill (presence of land near the oil spill area) and the clarity of border between oil and seawater. The Simple CNN had F1 score values of 85.71%, 87.43%, 86.50%, and 85.86% for each category, showing the maximum difference of 1.71%. In the case of U-net, the values for each category were 89.77%, 92.27%, 92.59%, and 92.66%, with the maximum difference of 2.90%. Such results indicate that neither model showed significant differences in detection performance by the characteristics of oil spill distribution. However, the difference in detection tendency was caused by the difference in the model structure and the oil spill distribution characteristics. In all four oil spill categories, the Simple CNN showed a tendency to overestimate the oil spill area and the U-net showed a tendency to underestimate it. These tendencies were emphasized when the border between oil and seawater was unclear."
Faster R-CNN을 활용한 소방도면의 설비 심벌 탐지,2021,"['Faster R-CNN', 'AI', 'Object Detection', 'Fire Fighting Drawings']","본 연구는 인공지능 알고리즘을 활용하여 건축설계도면에 소방설비 심벌을 배치하여 소방도면을 자동으로 생성하는 연구의 과정이며, 학습을 위한 데이터를 생성하기 위한 단계이다. 승인된 소방도면에서 심벌을 자동으로 제거하여 학습-테스트용 데이터를 생성하기 위해 도면 내 심벌을 탐지하는 연구를 진행하였다. 소방도면은 일반적으로 도면에 활용된 심벌들의 모양과 내용을 정리한 소방 범례와 건축물의 층마다 설치된 소방 설비가 간략하게 표현된 간선 계통도, 각 층의 건축설계도면의 평면도 위에 소방 설비의 심벌을 배치하여 작성한 소방 설비 평면도로 구성된다. 소방도면에서 활용되는 심벌은 해당 설비를 간단하게 기호로 표기한 것이다. 심벌은 소방도면마다 매우 유사하게 표현되지만 일부 심벌은 조금씩 다르게 표기되기도 하며, 목적에 따라 문자로 추가적인 표기한다. Faster R-CNN은 R-CNN, Fast R-CNN 알고리즘에 비해 속도와 정확도를 개선한 알고리즘이며, 이미지 내에서 여러 사물을 탐지하고 구분한다. 입력으로 주어지는 이미지에 CNN을 적용하여 Feature Map을 추출하고, Anchor를 기준으로 찾고자하는 객체의 존재여부를 판단한다. 선정된 앵커 박스에 대한 객체를 구분하여 최종적인 결과를 출력한다. Faster R-CNN을 적용한 결과로, 소방도면에서 심벌을 탐지하여 객체가 존재한다고 판단한 관심영역들을 사각형 영역으로 출력하였다. 동일한 영역 내에 여러 앵커 박스가 생성될 경우, 하나의 사각형 영역으로 통합하여 심벌의 위치를 출력하였다. 건축설계도면은 일반적으로 고해상도의 이미지이므로 메모리가 부족한 현상이 발생한다. 또한 알고리즘의 탐지영역 대비 심벌이 지나치게 작아서 탐지하기 어려운 문제점도 있었다. 향후 영상처리의 적용과 많은 학습 데이터를 확보하여 이러한 문제점을 극복하고자 한다.",다국어 초록 정보 없음
고성능 CNN 기반 정밀 요검사 판별 기법,2021,"['CNN', 'Urinalysis', 'Image Discrimination']","요검사는 물리적 성상 검사, 화학적 검사, 현미경 검사 세 가지가 있다. 이 중에서 화학적 요검사는 일반인이 쉽게 접근하는 방법으로 요검사지의 화학반응을 눈으로 표준비색표와 비교하거나 휴대용 요검사기를 별도로 구매하여 검사를 진행한다. 현재는 스마트폰의 보급이 대중화되어 스마트폰을 활용한 요검사 서비스 연구가 높아지고 있다. 요검사 스크리닝 애플리케이션은 스마트폰을 활용한 요검사 서비스 중 하나이다. 그러나 요검사 스크리닝 애플리케이션으로 촬영한 요검사 패드 RGB 값은 조명영향으로 인해 큰 편차가 발생한다. 요검사 패드 RGB 값의 편차는 요검사 판별의 정확도를 떨어뜨린다. 따라서 본 논문에서는 스마트폰 기반 요검사 스크리닝 애플리케이션으로 촬영한 요검사지를 검사 항목별 요검사 패드로 분류한 후 CNN을 통해 요검사 패드 이미지 판별의 정확도를 높인다. 요검사지는 다양한 배경에서 촬영하여 CNN 이미지를 생성하였으며 ResNet-50 CNN 모델을 사용하여 요검사 판별을 분석하였다.",다국어 초록 정보 없음
CNN 기반 딥러닝을 이용한 인공지지체의 외형 변형 불량 검출 모델에 관한 연구,2021,"['3D Printing Scaffold', 'CNN', 'Deep Learning', 'Defect Detection Model', 'Scaffold Warpage']",국문 초록 정보 없음,"Warpage defect detecting of scaffold is very important in biosensor production. Because warpaged scaffold cause problem in cell culture. Currently, there is no detection equipment to warpaged scaffold. In this paper, we produced detection model for shape warpage detection using deep learning based CNN. We confirmed the shape of the scaffold that is widely used in cell culture. We produced scaffold specimens, which are widely used in biosensor fabrications. Then, the scaffold specimens were photographed to collect image data necessary for model manufacturing. We produced the detecting model of scaffold warpage defect using Densenet among CNN models. We evaluated the accuracy of the defect detection model with mAP, which evaluates the detection accuracy of deep learning. As a result of model evaluating, it was confirmed that the defect detection accuracy of the scaffold was more than 95%."
산업용 로봇 원격제어를 위한 CNN기반 손 제스처 인식 방법,2021,"['Industrial robot', 'ROS', 'EMG', 'Teleoperation', 'CNN']",국문 초록 정보 없음,"This paper introduces a teleoperation control system of an industrial robot based on hand gestures using the convolutional neural network (CNN). The proposed system employs the gesture data obtained from an EMG sensor and considers a CNN-based deep learning method. Using the proposed CNN model, we develop a real-time teleoperation control system for the industrial robot. Finally, it is confirmed that the proposed system is reliable in real system since it can be applied to the teleoperation control of a real industrial robot."
도로교통 이머징 리스크 탐지를 위한 AutoML과 CNN 기반 소프트 보팅 앙상블 분류 모델,2021,[],겨울철 도로 결빙으로 인한 사고는 대부분 큰 사고로 이어진다. 이는 운전자가 도로의 결빙을 사전에 자각하기 어렵기 때문이다. 본 연구에서는 AutoML과 CNN의 앙상블 모델을 이용하여 도로교통 이머징 리스크를 정확하게 탐지하는 방법을 연구한다. 비정형 데이터인 이미지를 이용한 CNN 이미지 특징 추출 기반 도로교통 이머징 리스크 분류 모델과 정형 데이터인 기상 데이터를 이용한 AutoML 기반 도로교통 이머징 리스크 분류 모델을 각각 학습시킨다. 그 후 모델들에서 도출된 확률값을 입력하여 CNN 기반 분류 모델을 보완하도록 앙상블 모델을 설계한다. 이를 통해 도로교통 이머징 리스크 분류 성능을 향상하고 더 정확하고 빠르게 운전자에게 경고하여 안전한 주행이 가능하도록 한다.,다국어 초록 정보 없음
이미지와 메타데이터를 활용한 CNN 기반의 악성코드 패밀리 분류 기법,2021,[],"본 논문에서는 딥러닝의 CNN(Convolution Neural Network) 학습을 통하여 악성코드를 실행시키지 않고서 악성코드 변종을 패밀리 그룹으로 분류하는 방법을 연구한다. 먼저 데이터 전처리를 통해 3가지의 서로 다른 방법으로 악성코드 이미지와 메타데이터를 생성하고 이를 CNN으로 학습시킨다. 첫째, 악성코드의 byte 파일을 8비트 gray-scale 이미지로 시각화하는 방법이다. 둘째, 악성코드 asm 파일의 opcode sequence 정보를 추출하고 이를 이미지로 변환하는 방법이다. 셋째, 악성코드 이미지와 메타데이터를 결합하여 분류에 적용하는 방법이다. 이미지 특징 추출을 위해서는 본고에서 제안한 CNN을 통한 학습 방식과 더불어 3개의 Pre-trained된 CNN 모델을 (InceptionV3, Densnet, Resnet-50) 사용하여 전이학습을 진행한다. 전이학습 시에는 마지막 분류 레이어층에서 본 논문에서 선택한 데이터셋에 대해서만 학습하도록 파인튜닝하였다. 결과적으로 가공된 악성코드 데이터를 적용하여 9개의 악성코드 패밀리로 분류하고 예측 정확도를 측정해 비교 분석한다.",다국어 초록 정보 없음
CNN을 활용한 Tor 네트워크 트래픽 분류,2021,"['Tor', 'CNN', 'Binary Classification', 'Multiclass classification']","Onion Router라고 알려진 Tor는 강한 익명성을 보장하기 때문에 각종 범죄행위뿐만 아니라 신속한 포트 검색 및 인증정보의 외부 유출 등 해킹 시도에도 활발하게 이용되고 있다. 따라서 범죄 시도를 조기에 차단하고 해킹으로부터 조직의 정보시스템을 안전하게 보호하기 위해서는 Tor 트래픽의 빠르고 정확한 탐지가 상당히 중요하다. 이에 본 논문에서는 CNN(Convolutional Neural Network)을 기반으로 Tor 트래픽을 탐지하고 트래픽의 유형을 분류하는 분류모델을 제안한다. 제안하는 분류모델의 성능 검증에는 UNB Tor 2016 데이터세트가 사용되었다. 실험을 진행한 결과, 제안하는 접근방법은 Tor 및 Non-Tor 트패픽을 탐지하는 이진분류에서는 99.98%, Tor 트래픽의 유형을 구분하는 다중분류에서는 97.27%의 정확도를 보여주었다.",다국어 초록 정보 없음
하천 홍수 예측을 위한 CNN 기반의 수위 예측 모델 구현,2021,[],"수해는 홍수나 해일을 유발하여 막대한 인명과 재산의 피해를 초래할 수 있다. 이에 대해 홍수 예측을 통한 빠른 대피 결정으로 피해를 줄일 수 있으며, 해당 분야에서는 시계열 데이터를 활용하여 홍수를 예측하려는 연구들도 많이 진행되고 있다. 본 논문에서는 CNN 기반의 시계열 예측 모델을 제안한다. 하천의 수위와 강수량을 사용하여 CNN 기반의 수위 예측 모델을 구현하였고, 시계열 예측에 많이 사용되는 LSTM, GRU 모델과 비교하여 성능을 확인하였다. 또한 입력 데이터의 크기에 따른 성능 차이를 확인하여 보완해야 할 점을 찾을 수 있었고, LSTM과 GRU보다 더 좋은 성능을 낼 수 있다는 것을 확인하였다. 이를 통해 홍수 예측을 위한 초기 연구로서 활용할 수 있을 것으로 사료된다.",다국어 초록 정보 없음
유도전동기의 고정자 고장 진단을 위한 CNN의 활성화 함수 선정,2021,"['ReLu', '활성화 함수', '행렬화 이미지', '컨볼루션 인공 신경망', '3상 유도 전동기', '고장 진단', 'ReLu', 'Matrix image', 'CNN', '3-phase induction motor', 'Fault Diagnosis']","본 논문에서는 유도전동기 고정자 고장 진단에 있어서 활성화 함수가 미치는 영향을 분석하여 효율적인 CNN 활용 방법을 제안하였다. 일반적으로 유도전동기 고정자 고장 진단의 주된 목적은 미세한 턴 단락을 빠르게 진단함으로 고장을 미리 방지함에 있다. 이에 활성화 함수 활용에 있어서 전반적인 고정자 고장에는 ReLu가 우수성을 보임을 알 수 있었으나, 미세한 턴 단락인 2턴 단락에 있어서는 Sigmoid 함수가 ReLu 함수보다 진단의 정확도에 있어서 23.23% 유용함을 실험을 통해 확인할 수 있었다.","In this paper, we propose an efficient CNN application method by analyzing the effect of activation function on the failure diagnosis of the inductive motor stator. Generally, the main purpose of the inductive motor stator failure diagnosis is to prevent the failure by rapidly diagnosing the minute turn short. In the application of activation function, experiments show that the Sigmoid function is 23.23% more useful in accuracy of diagnosis than the ReLu function, although it is shown that ReLu has superiority in overall fixer failure in utilizing the activation function."
CNN의 SoftMax 연산을 위한 연속 근사 방식의 로그 연산 회로,2021,"['Accelerator', 'CNN', 'Logarithm', 'SoftMax']",국문 초록 정보 없음,"In a CNN for image classification, a SoftMax layer is usually placed at the end. The exponentinal and logarithmic operations in the SoftMax layer are not adequate to be implemented in an accelerator circuit. The operations are usually implemented with look-up tables, and the exponential operation can be implemented in an iterative method. This paper proposes a successive approximation method to calculate a logarithm to remove a very large look-up table. By substituing the large table with two very small tables, the circuit can be reduced much. The experimental results show that the 85% area reduction can be reached with a small error degradation."
단동형 온실 내의 온도변화 실시간 예측을 위한 CNN 기반 모델의 적용성 평가,2021,"['CNN', '단동형 온실', '온도 예측']","온실을 제어함에 있어 온도 변화는 매우 중요한 지표이다. 하지만 온실 내부 환경은 여러 요인들이 복합적으로 얽혀있고, 비선형성을 띄기에 온실 내부 온도 변화를 알기란 쉽지 않다. 이렇게 사람들의 눈으로 확인하기 어려운 온실 내부 변화를 알기위해 온실 내외부 데이터를 활용한 인공지능 연구가 강력한 해결책을 제시할 수 있다. 본 연구에서는 convolutional neural network (CNN)를 이용하여 온도 예측 모델을 형성하였다. 개발된 모델은 외부온도, 외부습도, 일사량, 풍향, 풍속, 내부온도, 내부습도, 내부 CO2 등 8가지 요인을 입력으로 사용하여, 30분, 1시간 뒤의 온실 내부 온도를 각각 예측하였다. 예측모델은 수원에 위치한 서울대학교 부속 농장의 단동형 비닐온실의 4월 9일에서 4월 29일까지 약 20일의 데이터를 사용하여 개발하였다. 이후 개발된 모델의 적용성 평가를 위해 학습에 쓰이지 않은 5월, 6월의 데이터를 사용하여 적용성 평가를 실시하였다. 실제 계측한 온도 값과의 비교를 통해 온도 예측 성능을 평가한 결과 30분, 1시간 뒤의 온도 예측에 대해 결정계수(R2)는 각각 0.94, 0.91이 나왔으며, root mean squared error (RMSE)는 각각 1.19℃, 1.16℃의 결과를 보였다. 본 연구에서 개발된 모델을 실험 온실에 적용하여 실시간으로 취득되는 데이터를 통해 온도예측을 실시하였고 그 예측 성능을 검토하였다. 추후 연구에서는 작동기의 제어이력 데이터를 추가 학습한다면 더욱 정밀한 온도예측이 가능할 것으로 예상된다.",다국어 초록 정보 없음
CNN기반의 청각장애인을 위한 수화번역 프로그램,2021,"['수화', '청각장애', 'AlexNet', 'U-Net', '의사소통', 'Sign Language', 'Deaf', 'AlexNet', 'U-Net', 'Communication']","사회가 점점 발전하면서 의사소통 방법이 다양한 형태로 발전하고 있다. 그러나 발전한 의사소통은 비장애인을 위한 방법이며, 청각장애인에게는 아무런 영향을 미치지 않는다. 따라서 본 논문에서는 청각장애인의 의사소통을 돕기 위한 CNN 기반의 수화번역 프로그램을 설계 및 구현한다. 수화번역 프로그램은 웹캠을 통해 입력된 수화 영상 데이터를 기반으로 의미에 맞게 번역한다. 수화번역 프로그램은 직접 제작한 24,000개의 한글 자모음 데이터를 사용하였으며, 효과적인 분류모델의 학습을 위해 U-Net을 통한 Segmentation을 진행한다. 전처리가 적용된 데이터는 19,200개의 Training Data와 4,800개의 Test Data를 통하여 AlexNet을 기반으로 학습을 진행한다. 구현한 수화번역 프로그램은 ‘ㅋ’이 97%의 정확도와 99%의 F1-Score로 모든 수화데이터 중에서 가장 우수한 성능을 나타내었으며, 모음 데이터에서는 ‘ㅣ’가 94%의 정확도와 95.5%의 F1-Score로 모음 데이터 중에서 가장 높은 성능을 보였다.","Society is developing more and more, and communication methods are developing in many ways. However, developed communication is a way for the non-disabled and has no effect on the deaf. Therefore, in this paper, a CNN-based sign language translation program is designed and implemented to help deaf people communicate. Sign language translation programs translate sign language images entered through WebCam according to meaning based on data. The sign language translation program uses 24,000 pieces of Korean vowel data produced directly and conducts U-Net segmentation to train effective classification models. In the implemented sign language translation program, ’ㅋ‘ showed the best performance among all sign language data with 97% accuracy and 99% F1-Score, while ’ㅣ‘ showed the highest performance among vowel data with 94% accuracy and 95.5% F1-Score."
CNN - LSTM 모델 기반 음성 감정인식,2021,[],"사람은 표정, 음성, 말 등을 통해 감정을 표출한다. 본 논문에서는 화자의 음성데이터만을 사용하여 감정을 분류하는 방법을 제안한다. 멜 스펙트로그램(Mel-Spectrogram)을 이용하여 음성데이터를 시간에 따른 주파수 영역으로 변화한다. 멜 스펙트로그램으로 변환된 데이터를 CNN을 이용하여 특징 벡터화한 후 Bi-Directional LSTM을 이용하여 화자의 발화 시간 동안 변화되는 감정을 분석한다. 마지막으로 완전 연결 네트워크를 통해 전체 감정을 분류한다. 감정은 Anger, Excitement, Fear, Happiness, Sadness, Neutral로, 총 6가지로 분류하였으며 데이터베이스로는 상명대 연구팀에서 구축한 한국어 음성 감정 데이터베이스를 사용하였다. 실험 결과 논문에서 제안한 CNN-LSTM 모델의 정확도는 88.89%로 측정되었다.",다국어 초록 정보 없음
시계열 데이터를 기반으로 한 CNN의 성능 향상 방법에 대한 비교 연구,2021,"['Artificial intelligence', 'Convolutional neural network', 'Deep learning', 'Image classification', 'Human activity recognition', 'Time series data']","인간 행동 인식 기술은 전통적으로 서포트 벡터 머신과 같은 기계 학습 기술 분야이다. 그리고 딥 러닝의 발전과 함께 순환 신경망을 사용하여 이와 같은 작업이 수행되고 있다. 최근에는 시계열 데이터를 이미지로 변환한 후 CNN (Convolutional Neural Networks)에 적용할 수 있음이 확인되었다. 저자는 시계열 기반 CNN 신경망에서 정밀도 향상을 위해 에지 향상, 선 너비 제어 및 색상 코드 최적화와 같은 몇 가지 방법을 제안했다. 엣지 강화 방법은 사물을 인식한다는 것은 사물의 형태를 본다는 직관에서 나온 아이디어이다. 또한 시계열 데이터의 데이터를 이미지로 변환 할 때, 빠른 정착 시간과 높은 정확도를 포함하여 최상의 성능을 얻을 수 있는 최적의 선폭이 존재할 수 있고, 이것이 선폭 제어 방법을 고안하게 되었다. 색상 코드 최적화는 보색으로부터 동기가 부여되었는데, 색상 코드 최적화는 색상 공간에서 색상 거리를 최대화하여 얻을 수 있다. 보색은 이미지를 더 선명하고 모양으로 만들어 신경망의 성능을 향상시킨다. 이 논문에서는 위의 세 가지 방법을 자세히 비교하고 평가한다. 실험 결과로부터 시계열 데이터의 이미지 분류 작업에서 선폭 제어가 가장 효과적인 기법이며 색상 코드 최적화도 효과적인 방법이었다. 이 논문에서 선폭 제어는 원시 정보가 시계열 데이터인 선이기 때문에 효과가 떨어졌다. 그러나 원시 데이터에 이미지와 같은 공간 정보가 있는 경우 f1-score를 향상시키는 데 에지 강화 기법이 훨씬 더 효과적일 것이다.",다국어 초록 정보 없음
안면 연령 예측을 위한 CNN기반의 히트 맵을 이용한 랜드마크 선정,2021,[],국문 초록 정보 없음,"The purpose of this study is to improve the performance of the artificial neural network system for facial image analysis through the image landmark selection technique. For landmark selection, a CNN-based multi-layer ResNet model for classification of facial image age is required. From the configured ResNet model, a heat map that detects the change of the output node according to the change of the input node is extracted. By combining a plurality of extracted heat maps, facial landmarks related to age classification prediction are created. The importance of each pixel location can be analyzed through facial landmarks. In addition, by removing the pixels with low weights, a significant amount of input data can be reduced."
The Method for Generating Recommended Candidates through Prediction of Multi-Criteria Ratings Using CNN-BiLSTM,2021,"['Bidirectional Long Short-Term Memory', 'BiLSTM', 'Convolutional Neural Network', 'CNN', 'Multi-Criteria Recommendation System', 'Recommendation System']",국문 초록 정보 없음,"To improve the accuracy of the recommendation system, multi-criteria recommendation systems have been widely researched. However, it is highly complicated to extract the preferred features of users and items from the data. To this end, subjective indicators, which indicate a user’s priorities for personalized recommendations, should be derived. In this study, we propose a method for generating recommendation candidates by predicting multi-criteria ratings from reviews and using them to derive user priorities. Using a deep learning model based on convolutional neural network (CNN) and bidirectional long short-term memory (BiLSTM), multi-criteria prediction ratings were derived from reviews. These ratings were then aggregated to form a linear regression model to predict the overall rating. This model not only predicts the overall rating but also uses the training weights from the layers of the model as the user’s priority. Based on this, a new score matrix for recommendation is derived by calculating the similarity between the user and the item according to the criteria, and an item suitable for the user is proposed. The experiment was conducted by collecting the actual “TripAdvisor” dataset. For performance evaluation, the proposed method was compared with a general recommendation system based on singular value decomposition. The results of the experiments demonstrate the high performance of the proposed method."
CNN 알고리즘 기반 2단계 차종 분류 모델,2021,[],"범죄차량 판독 시스템, 지능화된 CCTV 등 차량과 관련된 시각지능에 관한 연구가 큰 관심을 받고 있다. 이 중 차량 분류 기술은, 특정 차량을 인식하는 핵심기술이다. 이와 관련한 기존 연구들은 큰 차종으로만 분류하거나, 분류 가능한 차종의 수, 정확도 등이 낮아 실용성 및 신뢰성이 떨어진다는 단점이 있다. 따라서, 본 논문에서는 차종을 정확하게 분류할 수 있는 2단계 차종 분류 알고리즘을 제안한다. 제안 시스템은 CNN으로 학습된 모델을 기반으로 1차로 차량의 유형을 분류하고, 2차로 정확한 차종을 분류한다. 실험 결과, 52개의 차종을 분류함에 있어 단일 분류 모델에 비해 5.3%p 더 높은 90.2%의 분류 정확도를 보였다. 이를 통해, 더욱 정확한 차종 분류가 가능하다.",다국어 초록 정보 없음
CNN기반의 딥러닝 모델을 활용한 잔골재 조립률 예측에 관한 기초적 연구,2021,"['딥러닝', '잔골재 조립률', '잔골재', 'deep learning', 'fineness modulus', 'fine aggregate']",국문 초록 정보 없음,"Recently, as concrete is used in many construction works in Korea, the use of aggregates is also increasing. However, the depletion of aggregate resources is making it difficult to supply and demand high-quality aggregates, and the use of defective aggregates is causing problems such as poor performance such as the liquidity and strength of concrete pouring out in the field. As a result, quality tests such as sieve analysis test is conducted on their own, but this study was conducted to improve time and manpower by using the CNN-based Deep Learning Model for the fineness modulus."
웨어러블 디바이스를 이용한 1D-CNN-LSTM 기반 반려동물 행동 분류,2021,[],"최근 반려동물 시장이 커짐으로 인해, 반려동물들의 헬스케어를 위한 제품들이 증가하고 있다. 이에 따라 펫 웨어러블 디바이스를 통한 연구가 활발히 진행되고 있지만, 웨어러블 디바이스를 통해 수집되는 센싱 데이터는 변칙적인 반려동물의 특징 때문에 연구의 한계를 갖는다. 이를 위해 본 논문에서는 1-Dimensional CNN과 LSTM 하이브리드 모델을 기반으로 한 반려동물 행동 분류를 제안한다. 웨어러블 디바이스를 이용해 자이로와 가속도 센서를 수집하여 걸음수를 측정하고, 이후 수집된 센싱 데이터로 반려동물의 행동을 4가지로 분류한다. 행동 분류는 걷기, 뛰기, 앉기, 서기로 분류한다.",다국어 초록 정보 없음
1D CNN과 기계 학습을 사용한 낙상 검출,2021,"['Machine Learning', 'Deep Learning', 'Fall Detection', '1D Convolutional Neural Network', '기계 학습', '심층 학습', '낙상 검출', '1차원 합성곱 신경망']",국문 초록 정보 없음,"In this paper, fall detection using individual wearable devices for older people is considered. To design a low-cost wearable device for reliable fall detection, we present a comprehensive analysis of two representative models. One is a machine learning model composed of a decision tree, random forest, and Support Vector Machine(SVM). The other is a deep learning model relying on a one-dimensional(1D) Convolutional Neural Network(CNN). By considering data segmentation, preprocessing, and feature extraction methods applied to the input data, we also evaluate the considered models’ validity. Simulation results verify the efficacy of the deep learning model showing improved overall performance."
사과 품종 분류를 위한 CNN기반 모델링 및 분류 기법 연구,2021,"['스마트팜', '딥러닝', 'ResNet', '신경망', 'Smart Farm', 'Deep Learning', 'ResNet', 'Convolution Neural Network']","농장주들이 과일을 분류하는 데까지의 시간소모를 줄이고 향후 과일의 등급 판정 기준을 정량화하기 위하여 우리나라의 대표적인 과일이며 다양한 품종을 가지고 있는 사과를 대상으로 신경망 기반 분류 자동화 시스템을 제안한다. 컨베이어 벨트를 통해 지나가는 객체를 카메라모듈로 촬영하여 이를 통신 및 연산을 수행하는 라즈베리파이 기반 시스템을 설계, 구현한다. 깊은 네트워크와 나머지(residual)를 학습하는 ResNet 기반 알고리즘이 구동되는 딥러닝 서버와는 SSH통신을 통해 이미지와 학습된 모델을 주고받는다. 향후 품종뿐만 아니라 등급까지 분류 자동화한다면 다양한 품종의 과일을 대상으로 한 출하 자동화 시스템으로의 적용이 가능하다.","This paper propose a neural network-based classification automation system for apples, which are representative fruits of Korea and have a variety of varieties, in order to reduce the consumption of time for farmers to classify fruits and to quantify the criteria for grading the fruits. Raspberry Pi-based system that communicates and performs calculations by photographing objects passing through a conveyor belt with a camera module is designed and implemented. Then it receive the trained model using ResNet-based algorithm that runs on the deep-learning server. In the future, if classifying not only varieties but also grades is automated, it can be applied as a shipping automation system targeting various varieties of fruit."
CNN-LSTM 기반 유해 텍스트 필터링 크롬 플러그인,2021,[],최근 온라인 매체에서 무분별한 비속어나 욕설 사용이 늘어남에 따라 유해한 텍스트를 자동으로 필터링하는 시스템의 필요성이 증가하고 있다. 유해 텍스트 필터링 관련 기존의 접근방법은 채팅 프로그램 등 특정 프로그램에 한하여 적용이 되거나 특정 포탈의 웹페이지에 국한되어 적용이 되는 한계가 있다. 따라서 본 연구에서는 AI를 활용하여 모든 웹 페이지의 유해 텍스트를 필터링할 수 있는 Chrome Extension을 구현하고 그 유효성을 검증한다.,다국어 초록 정보 없음
CNN기반의 딥러닝 모델을 활용한 잔골재 조립률 예측에 관한 실험적 연구,2021,"['딥러닝', '잔골재 조립률', '잔골재', 'deep learning', 'finess modulus', 'fine aggregate']",국문 초록 정보 없음,"As concrete is used in many construction works, the use of aggregates is increasing. However, supply and demand of high-quality aggregates has become difficult recently, and although circular aggregates that recycle construction waste are used, the performance of concrete, such as liquidity and strength, are being reduced due to defective aggregates. As a result, quality tests such as sieve analysis test are conducted, but a lot of waste occurs such as time and manpower. To solve this problem, this study was conducted to measure the assembly rate of fine aggregate, which accounts for about 35% of the concrete volume, using Deep Learning."
CNN 잡음감쇠기에서 필터 수의 최적화,2021,"['잡음 감쇠', '심층 학습', '합성곱 신경망', '오차 역전파', '평균 제곱 오차', '평균 절대값 오차', 'Noise Attenuation', 'Deep Learning', 'CNN', 'Error Back Propagation', 'MSE', 'MAE']","본 논문은 잡음감쇠기에서 CNN(Convolutional Neural Network) 계층의 필터 수가 성능에 미치는 영향을 연구하였다 이 시스템은 적응필터 대신 신경망 예측필터를 이용하며 심층학습방법으로 잡음을 감쇠한다. 64-뉴런, 16-커널 CNN 필터와 오차 역전파 알고리즘을 이용하여 잡음이 포함된 음성신호로부터 음성을 추정한다. 본 연구에서 필터 수에 대한 잡음감쇠기의 성능을 검증하기 위하여 Keras 라이브러리를 사용한 프로그램을 작성하고 시뮬레이션을 실시하였다. 시뮬레이션 결과, 본 시스템은 필터 수가 16일 때 MSE(Mean Squared Error) 및 MAE(Mean Absolute Error) 값이 가장 작은 것으로 나타났으며 필터가 4개 일 때 성능이 가장 낮은 것을 볼 수 있다. 그리고 필터가 8개 이상이 되면 필터 수에 따라 MSE 및 MAE 값이 크게 차이나지 않는 것을 보여주었다. 이러한 결과로부터 음성신호의 주요 특징을 표현하기 위해서는 약 8개 이상의 필터를 사용해야 한다는 것을 알 수 있다.","This paper studies the effect of the number of filters in the CNN (Convolutional Neural Network) layer on the performance of a noise attenuator. Speech is estimated from a noised speech signal using a 64-neuron, 16-kernel CNN filter and an error back-propagation algorithm. In this study, in order to verify the performance of the noise attenuator with respect to the number of filters, a program using Keras library was written and simulation was performed. As a result of simulation, it can be seen that this system has the smallest MSE (Mean Squared Error) and MAE (Mean Absolute Error) values when the number of filters is 16, and the performance is the lowest when there are 4 filters. And when there are more than 8 filters, it was shown that the MSE and MAE values do not differ significantly depending on the number of filters. From these results, it can be seen that about 8 or more filters must be used to express the characteristics of the speech signal."
초분광데이터 3차원 CNN 분류 모델 활용한 딸기의 잿빛곰팡이병 조기진단 기술 개발,2021,"['딸기 잿빛곰팡이', '조기진단', '초분광', 'CNN']","잿빛곰팡이병은 딸기에서 가장 발생빈도가 높은 병 중 하나이며 증식이 빠르기 때문에 조기진단 기술 개발을 통한 빠른 대처가 필요하다. 본 연구에서는 잿빛곰팡이균을 접종하여 병을 발생시킨 딸기 잎을 중심으로 초분광 영상을 측정하였고, 초분광 이미지에서 육안으로 건강한 부위(Healthy)와, 감염된 부위(Infected)를 식별, 시간경과 후 감염이 전파되는 부위는 무증상 감염 부위(Asymptomatic)로 클래스를 분류하였다. 학습데이터로 획득한 16 x 16 x 150의 정사각형 ROI는 각각 1358, 1056, 696개를 수집하였고 2D 데이터와 3D 데이터를 CNN 분류 모델 개발에 활용하였다. CNN 분류 모델 개발에 앞서 수행한 분류 유효파장 분석에서는 740-760nm 사이에서 -0.6의 음의 상관관계를 나타냈다. CNN 분류 모델 개발의 경우 2D 형태로 학습데이터로 개발한 분류모델은 검증오차가 0.76, 3D 데이터를 학습데이터로 활용한 모델은 0.81로 나타났다. 특히 조기진단 기술 개발에 필요한 Healthy 클래스와 Asymptomatic 클래스 구분의 경우 두가지 CNN 모델의 경우 Asymptomatic를 Healthy 판단하는 오차가 0.22 수준으로 이를 낮출 수 있는 방법에 대한 고찰이 필요할 것으로 보인다. 또한 유효파장대역분석에서 나타난 -0.6 수준으로는 필터영상(멀티카메라 활용)으로 활용한 센서개발에의 활용에는 정확도가 높지 않아 저가 초분광을 직접 활용하여 정밀도 높은 CNN 인공지능 예측 모델을 탑재한 조기진단 센서 개발이 가능할 것으로 판단된다.",다국어 초록 정보 없음
뇌파의 중첩 분할에 기반한 CNN 앙상블 모델을 이용한 뇌전증 발작 검출,2021,"['Epileptic Seizure', 'EEG', 'CNN', 'Ensemble Model', '뇌전증 발작', '뇌파', '합성곱 신경망', '앙상블 모델']",국문 초록 정보 없음,"As the diagnosis using encephalography(EEG) has been expanded, various studies have been actively performed for classifying EEG automatically. This paper proposes a CNN model that can effectively classify EEG signals acquired from healthy persons and patients with epilepsy. We segment the EEG signals into sub-signals with smaller dimension to augment the EEG data that is necessary to train the CNN model. Then the sub-signals are segmented again with overlap and they are used for training the CNN model. We also propose ensemble strategy in order to improve the classification accuracy. Experimental result using public Bonn dataset shows that the CNN can detect the epileptic seizure with the accuracy above 99.0%. It also shows that the ensemble method improves the accuracy of 3-class and 5-class EEG classification."
CNN 추론 연산 가속기를 위한 곱셈기 최적화 설계,2021,['AI'],국문 초록 정보 없음,"Recently, FPGA-based AI processors are being studied actively. Deep convolutional neural networks (CNN) are basic computational structures performed by AI processors and require a very large amount of multiplication. Considering that the multiplication coefficients used in CNN inference operation are all constants and that an FPGA is easy to design a multiplier tailored to a specific coefficient, this paper proposes a methodology to optimize the multiplier. The method utilizes 2's complement and distributive law to minimize the number of bits with a value of 1 in a multiplication coefficient, and thereby reduces the number of required stacked adders. As a result of applying this method to the actual example of implementing CNN in FPGA, the logic usage is reduced by up to 30.2% and the propagation delay is also reduced by up to 22%. Even when implemented with an ASIC chip, the hardware area is reduced by up to 35% and the delay is reduced by up to 19.2%."
MAC과 Pooling Layer을 최적화시킨 소형 CNN 가속기 칩,2021,['SoC'],국문 초록 정보 없음,"This paper proposes a CNN accelerator which is optimized Pooling layer operation incorporated in Multiplication And Accumulation(MAC) to reduce the memory size. For optimizing memory and data path circuit, the quantized 8bit integer weights are used instead of 32bit floating-point weights for pre-training of MNIST data set. To reduce chip area, the proposed CNN model is reduced by a convolutional layer, a 4*4 Max Pooling, and two fully connected layers. And all the operations use specific MAC with approximation adders and multipliers. 94% of internal memory size reduction is achieved by simultaneously performing the convolution and the pooling operation in the proposed architecture. The proposed accelerator chip is designed by using TSMC65nmGP CMOS process. That has about half size of our previous paper, 0.8*0.9 = 0.72mm<sup>2</sup>. The presented CNN accelerator chip achieves 94% accuracy and 77us inference time per an MNIST image."
Pointwise CNN for 3D Object Classification on Point Cloud,2021,"['Point Clouds', 'Pointwise CNN', '3D Object Classification']",국문 초록 정보 없음,"Three-dimensional (3D) object classification tasks using point clouds are widely used in 3D modeling, face recognition, and robotic missions. However, processing raw point clouds directly is problematic for a traditional convolutional network due to the irregular data format of point clouds. This paper proposes a pointwise convolution neural network (CNN) structure that can process point cloud data directly without preprocessing. First, a 2D convolutional layer is introduced to percept coordinate information of each point. Then, multiple 2D convolutional layers and a global max pooling layer are applied to extract global features. Finally, based on the extracted features, fully connected layers predict the class labels of objects. We evaluated the proposed pointwise CNN structure on the ModelNet10 dataset. The proposed structure obtained higher accuracy compared to the existing methods. Experiments using the ModelNet10 dataset also prove that the difference in the point number of point clouds does not significantly influence on the proposed pointwise CNN structure."
얼굴 열화상 기반 감정인식을 위한 CNN 학습전략,2021,"['얼굴 감정인식', '열화상', 'CNN 학습전략', '분할 정복법', 'Facial emotion recognition', 'Thermal image', 'CNN training strategy', 'Divide and Conquer']","감정인식은 응용 분야의 다양성으로 많은 연구가 이루어지고 있는 기술이며, RGB 영상은 물론 열화상을이용한 감정인식의 필요성도 높아지고 있다. 열화상의 경우는 RGB 영상과 비교해 조명 문제에 거의 영향을받지 않는 장점이 있으나 낮은 해상도로 성능 높은 인식 기술을 필요로 한다. 본 논문에서는 얼굴 열화상 기반 감정인식의 성능을 높이기 위한 Divide and Conquer 기반의 CNN 학습전략을 제안하였다. 제안된 방법은먼저 분류가 어려운 유사 감정 클래스를 confusion matrix 분석을 통해 동일 클래스 군으로 분류하도록 학습시키고, 다음으로 동일 클래스 군으로 분류된 감정 군을 실제 감정으로 다시 인식하도록 문제를 나누어서 해결하는 방법을 사용하였다. 실험을 통하여, 제안된 학습전략이 제시된 모든 감정을 하나의 CNN 모델에서 인식하는 경우보다 모든 실험에서 높은 인식성능을 보이는 것을 확인하였다.",다국어 초록 정보 없음
Two-stage Deep Learning Model with LSTM-based Autoencoder and CNN for Crop Classification Using Multi-temporal Remote Sensing Images,2021,"['Autoencoder', 'Convolutional neural network', 'Crop classification', 'Long short-term memory', 'Multi-temporal images']",국문 초록 정보 없음,"This study proposes a two-stage hybrid classification model for crop classification using multi-temporal remote sensing images; the model combines feature embedding by using an autoencoder (AE) with a convolutional neural network (CNN) classifier to fully utilize features including informative temporal and spatial signatures. Long short-term memory (LSTM)-based AE (LAE) is fine-tuned using class label information to extract latent features that contain less noise and useful temporal signatures. The CNN classifier is then applied to effectively account for the spatial characteristics of the extracted latent features. A crop classification experiment with multi-temporal unmanned aerial vehicle images is conducted to illustrate the potential application of the proposed hybrid model. The classification performance of the proposed model is compared with various combinations of conventional deep learning models (CNN, LSTM, and convolutional LSTM) and different inputs (original multi-temporal images and features from stacked AE). From the crop classification experiment, the best classification accuracy was achieved by the proposed model that utilized the latent features by fine-tuned LAE as input for the CNN classifier. The latent features that contain useful temporal signatures and are less noisy could increase the class separability between crops with similar spectral signatures, thereby leading to superior classification accuracy. The experimental results demonstrate the importance of effective feature extraction and the potential of the proposed classification model for crop classification using multi-temporal remote sensing images."
CNN 모델을 이용한 프로그램 코드 변경 예측,2021,[],국문 초록 정보 없음,"A software system is required to change during its life cycle due to various requirements such as adding functionalities, fixing bugs, and adjusting to new computing environments. Such program code modification should be considered as carefully as a new system development becase unexpected software errors could be introduced. In addition, when reusing open source programs, we can expect higher quality software if code changes of the open source program are predicted in advance. This paper proposes a Convolutional Neural Network (CNN)-based deep learning model to predict source code changes. In this paper, the prediction of code changes is considered as a kind of a binary classification problem in deep learning and labeled datasets are used for supervised learning. Java projects and code change logs are collected from GitHub for training and testing datasets. Software metrics are computed from the collected Java source code and they are used as input data for the proposed model to detect code changes. The performance of the proposed model has been measured by using evaluation metrics such as precision, recall, F1-score, and accuracy. The experimental results show the proposed CNN model has achieved 95% in terms of F1-Score and outperformed the multilayer percept-based DNN model whose F1-Score is 92%."
Efficient Visual Place Recognition by Adaptive CNN Landmark Matching,2021,"['visual place recognition', 'CNN', 'adaptive', 'landmark', 'matching']",국문 초록 정보 없음,"Visual place recognition (VPR) is a fundamental yet challenging task of mobile robot navigation and localization. The existing VPR methods are usually based on some pairwise similarity of image descriptors, so they are sensitive to visual appearance change and also computationally expensive. This paper proposes a simple yet effective four-step method that achieves adaptive convolutional neural network (CNN) landmark matching for VPR. First, based on the features extracted from existing CNN models, the regions with higher significance scores are selected as landmarks. Then, according to the coordinate positions of potential landmarks, landmark matching is improved by removing mismatched landmark pairs. Finally, considering the significance scores obtained in the first step, robust image retrieval is performed based on adaptive landmark matching, and it gives more weight to the landmark matching pairs with higher significance scores. To verify the efficiency and robustness of the proposed method, evaluations are conducted on standard benchmark datasets. The experimental results indicate that the proposed method reduces the feature representation space of place images by more than 75% with negligible loss in recognition precision. Also, it achieves a fast matching speed in similarity calculation, satisfying the real-time requirement."
Crossbred pig recognition using Convolutional Neural Network(CNN) Algorithm,2021,"['image analysis', 'convolutional neural network', 'crossbred pigs', 'deep learning']",국문 초록 정보 없음,"YLD ((Yorkshire × Landrace) × Duroc) and LYD ((Landrace × Yorkshire) × Duroc) are common types of three-way crossbreds in Korean pig farm. Yorkshire can be used as a maternal line (YLD) or paternal line (LYD), which might affect final production. However, most pig farmers ignored it because it is difficult to distinguish one from the whole. The aim of this study is to classify two types of three-way crossbred pigs by learning pig facial data using CNN algorithm. Facial image data of three-way crossbred YLD((Y×L)×D) and LYD((L×Y)×D) were collected, and model training was sufficiently performed to prevent overfitting through data augmentation and dropout. The collected images were divided into training set and test set in an 8:2 ratio, and one-quarter of training data were used for validation. A data standardization process was performed to train the neural network algorithm smoothly. Convolutional neural network(CNN) were chosen for analysis, which is suitable for image-based classification. The architecture of the model is as follows: convolutional layer, rectified linear unit(ReLU) as activation function, max pooling layer, flatten layer, dense Layer. Then we compiled model using ‘adam’ optimizer and ‘categorical crossentropy’ loss value. Moreover, we used ‘early_stopping’ method in order to optimal learning rate adjustment. From the results of learning model, final accuracy and loss function were 0.9257, 0.2695 respectively. The confusion matrices for training, validating, and testing were performed for measuring modeling results. The accuracy of training, validating, and testing was 99.7%, 90.7%, 92.6% respectively, indicating that the model performance was remarkable. These results suggested that the CNN could be used to identity the breed line of pigs. Further research will be needed, in particular, there is need for sufficient data collection for the entire pig feeding period and additional research in the field of individual recognition."
CNN 알고리즘을 이용한 인공지지체의 3D프린터 출력 시 실시간 출력 불량 탐지 시스템에 관한 연구,2021,"['3D Printing Scaffold', 'Defect Shape Comparison', 'Densenet Algorithm', 'Real-Time Detection', 'Scaffold Defect Detection']",국문 초록 정보 없음,"Scaffold is used to produce bio sensor. Scaffold is required high dimensional accuracy. 3D printer is used to manufacture scaffold. 3D printer can't detect defect during printing. Defect detection is very important in scaffold printing. Real-time defect detection is very necessary on industry. In this paper, we proposed the method for real-time scaffold defect detection. Real-time defect detection model is produced using CNN(Convolution Neural Network) algorithm. Performance of the proposed model has been verified through evaluation. Real-time defect detection system are manufactured on hardware. Experiments were conducted to detect scaffold defects in real-time. As result of verification, the defect detection system detected scaffold defect well in real-time."
CNN 기반의 준지도학습을 활용한 GPR 이미지 분류,2021,"['GPR', '이미지 분류', 'CNN', '준지도학습', '이미지 클러스터링', 'Image classification', 'Semi-supervised learning', 'Image clustering']",국문 초록 정보 없음,"GPR data is used for underground exploration. The data gathered are interpreted by experts based on experience as the underground facilities often reflect GPR. In addition, GPR data are different in the noise and characteristics of the data depending on the equipment, environment, etc. This often results in insufficient data with accurate labels. Generally, a large amount of training data have to be obtained to apply CNN models that exhibit high performance in image classification problems. However, due to the characteristics of GPR data, it makes difficult to obtain sufficient data. Finally, this makes neural networks unable to learn based on general supervised learning methods.This paper proposes an image classification method considering data characteristics to ensure that the accuracy of each label is similar. The proposed method is based on semi-supervised learning, and the image is classified using clustering techniques after extracting the feature values of the image from the neural network. This method can be utilized not only when the amount of the labeled data is insufficient, but also when labels that depend on the data are not highly reliable."
DeepLabCut과 Mask R-CNN 기반 반려동물 행동 분류 설계,2021,[],"최근 펫팸족(Pet-Family)과 같이 반려동물을 가족처럼 생각하는 가구가 증가하면서 반려동물 시장이 크게 성장하고 있다. 이러한 이유로 본 논문에서는 반려동물의 객체 식별을 통한 객체 분할과 신체 좌표추정에 기반을 둔 반려동물의 행동 분류 방법을 제안한다. 이 방법은 CCTV를 통해 반려동물 영상 데이터를 수집한다. 수집된 영상 데이터는 반려동물의 인스턴스 분할을 위해 Mask R-CNN(Region Convolutional Neural Networks) 모델을 적용하고, DeepLabCut 모델을 통해 추정된 신체 좌푯값을 도출한다. 이 결과로 도출된 영상 데이터와 추정된 신체 좌표 값은 CNN(Convolutional Neural Networks)-LSTM(Long Short-Term Memory) 모델을 적용하여 행동을 분류한다. 본 모델을 바탕으로 행동을 분석 및 분류하여, 반려동물의 위험 상황과 돌발 행동에 대한 올바른 대처를 제공할 수 있는 기반을 제공할 것이라 기대한다.",다국어 초록 정보 없음
CNN 기법의 이미지 학습을 통한 팔굽혀펴기 자세 정확도 측정,2021,"['Image processing', 'Convolution Neural Network', 'Posture Measurement', 'Push-up', 'Machine Learning']",국문 초록 정보 없음,"Push-ups are one of the body exercises that can be easily measured anytime, anywhere. As one of the most widely used techniques as a test tool for evaluating physical strength, they are broadly used in various fields, especially in fields that require physical ability to estimate, such as military, police, and firefighters. However, social distancing is currently being implemented, and the issue of fairness has been steadily raised due to subtle differences between measurement. Accordingly, in this paper, the correct posture for each individual was photographed and learned by a high-performance computer, and the result was derived by comparing it with the case of performing the incorrect posture of the individual. If method is introduced into the physical fitness evaluation through the proposed method, the individual takes the correct posture and learns the photographed photo, and measures the posture with several images taken during a given time. Through this, it is possible to measure more objectively because it measures with the merit that can be measured even in the present situation and with one's correct posture."
CNN 모델의 최적 양자화를 위한 웹 서비스 플랫폼,2021,"['Convolutional Neural Network', 'Deep Learning Accelerator', 'Quantization', 'Web Service']",국문 초록 정보 없음,"Low-end IoT devices do not have enough computation and memory resources for DNN learning and inference. Integer quantization of real-type neural network models can reduce model size, hardware computational burden, and power consumption. This paper describes the design and implementation of a web-based quantization platform for CNN deep learning accelerator chips. In the web service platform, we implemented visualization of the model through a convenient UI, analysis of each step of inference, and detailed editing of the model. Additionally, a data augmentation function and a management function of files that store models and inference intermediate results are provided. The implemented functions were verified using three YOLO models."
고성능 CNN 기반 지정맥 인증 시스템 구현,2021,"['AI', 'Biometric authentication', 'Finger vein recognizer']",국문 초록 정보 없음,"Biometric technology using finger veins is receiving a lot of attention due to its high security, convenience and accuracy. And the recent development of deep learning technology has improved the processing speed and accuracy for authentication. However, the training data is a subset of real data not in a certain order or method and the results are not constant. so the amount of data and the complexity of the artificial neural network must be considered. In this paper, the deep learning model of Inception-Resnet-v2 was used to improve the high accuracy of the finger vein recognizer and the performance of the authentication system, We compared and analyzed the performance of the deep learning model of DenseNet-201. The simulations used data from MMCBNU_6000 of Jeonbuk National University and finger vein images taken directly. There is no preprocessing for the image in the finger vein authentication system, and the results are checked through EER."
콘볼루션 신경망(CNN)과 다양한 이미지 증강기법을 이용한 혀 영역 분할,2021,"['Tongue segmentation', 'Tongue diagnosis', 'Image augmentation', 'Transfer learning', 'Convolutional neural network']",국문 초록 정보 없음,"In Korean medicine, tongue diagnosis is one of the important diagnostic methods for diagnosing abnormalities in the body. Representative features that are used in the tongue diagnosis include color, shape, texture, cracks, and tooth marks. When diagnosing a patient through these features, the diagnosis criteria may be different for each oriental medical doctor, and even the same person may have different diagnosis results depending on time and work environment. In order to overcome this problem, recent studies to automate and standardize tongue diagnosis using machine learning are continuing and the basic process of such a machine learning-based tongue diagnosis system is tongue segmentation. In this paper, image data is augmented based on the main tongue features, and backbones of various famous deep learning architecture models are used for automatic tongue segmentation. The experimental results show that the proposed augmentation technique improves the accuracy of tongue segmentation, and that automatic tongue segmentation can be performed with a high accuracy of 99.12%."
CCTV 이미지와 CNN 딥러닝을 이용한 농업용수로 수위 계측,2021,"['수위계측', 'CCTV 영상', 'CNN 딥러닝', '이미지 분리']",국문 초록 정보 없음,다국어 초록 정보 없음
Cascade Mask R-CNN을 이용한 도로 균열 탐지,2021,"['균열 탐지', '딥러닝', '콘크리트 도로', 'Crack Detection', 'Deep Learning', 'Concrete Pavement']","딥러닝 기술을 이용하여 구조물의 균열을 탐지하는 기술에 대한 연구가 활발하게 이루어지고 있다. 기존 연구에서는 탐지대상이 되는 균열의 라벨링을 실제 균열 크기보다 두껍게 하여, 딥러닝 모델이 탐지한 영역이 실제 균열보다 두껍게 나타난다. 이 경우 손상 정량화 단계에서 균열 폭의 계산을 위한 추가적인 영상처리가 필요하며, 이를 실무에서 적용하는 데 여러 어려움이 발생한다. 이에 본 연구에서는 균열의 폭에 딱 맞는 라벨링을 수행한 학습데이터를 이용하여, 탐지 영역이 실제 균열의 폭과 거의 근사하는 딥러닝 모델을 개발하였다. 딥러닝 모델로는 Instance Segmentation 모델인 Cascade Mask R-CNN 모델이 사용되었으며, 콘크리트 교면포장 사진 1,767장을 이용하여 학습하였다. 콘크리트 교면에서 발생한 0.2mm 균열들을 포함하는 18,592*10,000(pixel)이미지들을 대상으로 해당 모델의 성능을 검증하였다.",다국어 초록 정보 없음
간병 로봇을 위한 합성곱 신경망 (CNN) 기반 의약품 인식기 설계,2021,"['Convolutional Neural Network', 'Medicine classification', 'EfficientNet', 'Nursing robot', 'Autonomous mobile robot', 'Collaborative robot']",국문 초록 정보 없음,"Our final goal is to implement nursing robots that can recognize patient's faces and their medicine on prescription. They can help patients to take medicine on time and prevent its abuse for recovering their health soon. As the first step, we proposed a medicine classifier with a low computational network that is able to run on embedded PCs without GPU in order to be applied to universal nursing robots. We confirm that our proposed model called MedicineNet achieves an 99.99% accuracy performance for classifying 15 kinds of medicines and background images. Moreover, we realize that the calculation time of our MedicineNet is about 8 times faster than EfficientNet-B0 which is well known as ImageNet classification with the high performance and the best computational efficiency."
CNN Based Face Tracking and Re-identification for Privacy Protection in Video Contents,2021,[],국문 초록 정보 없음,"Recently there is sharply increasing interest in watching and creating video contents such as YouTube. However, creating such video contents without privacy protection technique can expose other people in the background in public, which is consequently violating their privacy rights. This paper seeks to remedy these problems and proposes a technique that identifies faces and protecting portrait rights by blurring the face. The key contribution of this paper lies on our deep-learning technique with low detection error and high computation that allow to protect portrait rights in real-time videos. To reduce errors, an efficient tracking algorithm was used in this system with face detection and face recognition algorithm. This paper compares the performance of the proposed system with and without the tracking algorithm. We believe this system can be used wherever the video is used."
잡음과 스펙트럼 이동에 강인한 CNN 기반 라만 분광 알고리즘,2021,"['Raman Spectroscopy', 'Convolutional Neural Network', 'Machine Learning', 'Spectral Shift Robustness', 'Noise Robustness', '라만 분광기', '합성곱 신경망', '기계학습', '스펙트럼 이동 강인성', '잡음 강인성']",국문 초록 정보 없음,"Raman spectroscopy is an equipment that is widely used for classifying chemicals in chemical defense operations. However, the classification performance of Raman spectrum may deteriorate due to dark current noise, background noise, spectral shift by vibration of equipment, spectral shift by pressure change, etc. In this paper, we compare the classification accuracy of various machine learning algorithms including k-nearest neighbor, decision tree, linear discriminant analysis, linear support vector machine, nonlinear support vector machine, and convolutional neural network under noisy and spectral shifted conditions. Experimental results show that convolutional neural network maintains a high classification accuracy of over 95 % despite noise and spectral shift. This implies that convolutional neural network can be an ideal classification algorithm in a real combat situation where there is a lot of noise and spectral shift."
Lightweight CNN based Meter Digit Recognition,2021,"['Automatic meter reading', 'Lightweight Deep Neural Network', 'Image processing', 'Convolutional neural network']",국문 초록 정보 없음,"Image processing is one of the major techniques that are used for computer vision. Nowadays, researchers are using machine learning and deep learning for the aforementioned task. In recent years, digit recognition tasks, i.e., automatic meter recognition approach using electric or water meters, have been studied several times. However, two major issues arise when we talk about previous studies: first, the use of the deep learning technique, which includes a large number of parameters that increase the computational cost and consume more power; and second, recent studies are limited to the detection of digits and not storing or providing detected digits to a database or mobile applications. This paper proposes a system that can detect the digital number of meter readings using a lightweight deep neural network (DNN) for low power consumption and send those digits to an Android mobile application in real-time to store them and make life easy. The proposed lightweight DNN is computationally inexpensive and exhibits accuracy similar to those of conventional DNNs."
Residual Learning Based CNN for Gesture Recognition in Robot Interaction,2021,"['Convolutional Neural Network', 'Feature Redundancy', 'Full Connection Layer', 'Gesture Recognition', 'Human-Computer Interaction', 'Residual Learning']",국문 초록 정보 없음,"The complexity of deep learning models affects the real-time performance of gesture recognition, thereby limiting the application of gesture recognition algorithms in actual scenarios. Hence, a residual learning neural network based on a deep convolutional neural network is proposed. First, small convolution kernels are used to extract the local details of gesture images. Subsequently, a shallow residual structure is built to share weights, thereby avoiding gradient disappearance or gradient explosion as the network layer deepens; consequently, the difficulty of model optimisation is simplified. Additional convolutional neural networks are used to accelerate the refinement of deep abstract features based on the spatial importance of the gesture feature distribution. Finally, a fully connected cascade softmax classifier is used to complete the gesture recognition. Compared with the dense connection multiplexing feature information network, the proposed algorithm is optimised in feature multiplexing to avoid performance fluctuations caused by feature redundancy. Experimental results from the ISOGD gesture dataset and Gesture dataset prove that the proposed algorithm affords a fast convergence speed and high accuracy."
RISC-V 플랫폼 기반 CNN 모듈의 버퍼링 분석,2021,[],"최근 임베디드 엣지 컴퓨팅 디바이스에서 AI와 같은 인공지은 연산을 수행하여 AI 추론 연산의 가속화 및 분산화가 많이 이루어지고 있다. 엣지 디바이스는 임베디드 프로세서를 기반으로 AI의 가속 연산을 위해서 내부에 딥러닝 가속기를 포함하여 가속화시키는 시스템 구성을 하고 있다. 딥러닝 가속기는 복잡한 Neural Network 연산을 위한 데이터 이동이 많으며 외부 메모리와 내부 딥러닝 가속기 간의 효율적인 데이터 이동 및 버퍼링이 필요하다. 본 연구에서는 엣지 디바이스 딥러닝 가속기 내부의 버퍼 구조를 모델링하고, 버퍼의 크기에 따른 버퍼링 효과를 분석해 보았다. 딥러닝 가속기버퍼 구조는 RISC-V 프로세서 기반 가상 플랫폼에 구현되었다. 이를 통해서 딥러닝 모델에 따른 딥러닝 가속기 버퍼의 사용성을 분석할 수 있다.",다국어 초록 정보 없음
Stylized Image Generation based on Music-image Synesthesia Emotional Style Transfer using CNN Network,2021,"['Affective Computing', 'Image Style Transfer', 'Deep Convolutional Neural Networks']",국문 초록 정보 없음,"Emotional style of multimedia art works are abstract content information. This study aims to explore emotional style transfer method and find the possible way of matching music with appropriate images in respect to emotional style. DCNNs (Deep Convolutional Neural Networks) can capture style and provide emotional style transfer iterative solution for affective image generation. Here, we learn the image emotion features via DCNNs and map the affective style on the other images. We set image emotion feature as the style target in this style transfer problem, and held experiments to handle affective image generation of eight emotion categories, including dignified, dreaming, sad, vigorous, soothing, exciting, joyous, and graceful. A user study was conducted to test the synesthesia emotional image style transfer result with ground truth user perception triggered by the music-image pairs’ stimuli. The transferred affective image result for music-image emotional synesthesia perception was proved effective according to user study result."
2D-CNN 기반 우울증 감지를 위한 음성데이터 전처리,2021,[],"세계보건기구(WHO)에 따르면 전 세계적으로 우울증 장애를 앓고 있는 사람이 3 억 2,200 만명에 달하며, 매년마다 빠르게 늘어나는 환자로 인해 전세계적으로 문제가 되고 있다. 이에 따라 우울증을 감지하기 위한 시스템에 대한 연구가 진행되어지고 있다. 본 논문에서는 우울증 감지에 있어 높은 정확도를 얻을 수 있는 최적의 음성 세그먼트 길이와 멜 밴드의 수를 확인하고자 한다. DAIC-WOZ(Distress Analysis Interview Corpus Wizard of Oz) 데이터셋을 기반으로 2D-CNN(2Dimension - Convolutional Neural Network)를 사용하여 음성 세그먼트 길이와 멜 밴드의 수에 변화를 주며 테스트를 진행하였다. 최종적으로 12 초 길이의 음성 세그먼트와 512 개의 멜 밴드에서 86.3%의 정확도로 최적의 결과를 확인하였다.",다국어 초록 정보 없음
Mask R-CNN 과 zi2zi 모델을 활용하여 탐지된 객체의 스타일을 변환시키는 신경망 모델,2021,[],"스타일 변환 모델은 이미지 전체나 이미지 내에서 사용자가 지정한 영역을 대상으로 스타일을 변환시킨다. 이런 방식은 이미지 내의 다수의 객체에 대해 스타일 변환을 시행할 때 일일이 영역을 지정해 줘야 한다는 불편함과 결과물의 전체 해상도가 떨어진다는 한계를 가지고 있다. 본 논문에서는 이런 한계들을 극복하기 위해 객체탐지 모델과 스타일변환 모델을 연동한 객체스타일변환모델을 제안하고 모델 간 연동방법에 대해 자세히 서술한다. 객체탐지모델인 Mask R-CNN 을 통해 필요한 객체를 탐지하고 탐지한 객체의 특징맵들을 스타일변환 모델인 zi2zi 의 입력 값으로 전달하여 이미지 내의 필요한 객체들만 스타일변환이 이루어지도록 모델이 동작한다. 이러한 모델은 기존에 있는 두 모델을 재사용함으로써 모델을 처음부터 새로 설계할 필요가 없다는 장점이 있으며, 공개된 다양한 모델들을 서로 융합하여 사용할 수 있는 방법을 제시하는데 도움을 줄 것이다.",다국어 초록 정보 없음
컴퓨터 텍스트 분석 툴(Tool)을 활용한 글로벌 뉴스 미디어의 싱가포르 북미정상회담 뉴스 프레임 분석 : BBC와 CNN을 중심으로,2021,"['싱가포르 북미정상회담', 'BBC', 'CNN', '비핵화', '뉴스프레임', 'Trump-Kim Singapore Summit', 'BBC', 'CNN', 'Denuclearization', 'News frame']","본 연구는 BBC와 CNN이 2018년 싱가포르 북미정상회담을 어떤 뉴스 프레임으로 보도했는지 비교 분석했다. 코퍼스 언어학을 기반으로 하는 키 워드분석방식인 워드스미스 툴(Tool)을 활용해, BBC와 CNN의 정상회담 에 관한 뉴스데이터에서 핵심 워드를 추출했다. 추출한 키워드를 중심으로 글로벌 뉴스 미디어가 가장 강조한 핵심키워드를 밝혀내 그 의제를 어떻게 보도했는지 귀납적 프레임 분석을 실시했다. 분석결과 데이터에서 두 언론 사가 공통으로 강조한 핵심어는 ‘비핵화’였다, BBC는 중국(China), 일본 (Japan) 핵심어를 사용하여 중국 전문가와 일본 정부를 주요정보원으로 인 용해 지정학적이고 거시적인 시각으로 정상회담에 관한 뉴스를 구성한 것으 로 나타났고, CNN은 언론사 자체의 의견, 공화당 의원의 인용을 정보원으 로 사용해 한미연합훈련중지, 주한 미군 철수와 같은 당시 트럼프 미국 대통 령의 발언을 비판하는 내용을 중심으로 비핵화 문제를 정치적으로 해석하려 는 경향을 보였다.","This study comparatively analyzed the ways in which BBC and CNN framed the 2018 North Korea-United States Singapore Summit. Using a corpus- based text analysis software Wordsmith, keywords in news data were extracted to identify the primary agendas that BBC and CNN highlighted. Drawing on these keywords, this article conducted an inductive frame analysis. The findings show that the main agenda that both BBC and CNN news made salient was the ‘denuclearization’ issue. The BBC cited Chinese experts and the Japanese government as main news sources using keywords such as ‘China’ and ‘Japan’ and reported the Trump-Kim meeting from the geopolitical and macro perspectives. CNN, however, included the media institution’s own views and the quotations of Republican senators as major news sources and underscored issues such as the suspension of the ROK-UK joint military drills and the withdrawal of US troops in Korea in news stories. Additionally, a keyword analysis shows that CNN tended to report the Trump-Kim meeting in a political way and constructed news by rebuking Trump’s remarks. Given the impact of international news coverage of conflict issues in the Korean Peninsula, this study shows the necessity of revisiting the role of global news media."
CNN 기반 악성코드 탐지에서 이미지 형식이 탐지성능과 자원 사용에 미치는 영향 분석,2021,"['CNN', 'Image', 'Malware', 'Detection', 'Classification', 'Resource Usage']","CNN 기반의 악성코드 탐지모델을 활용하기 위해 다양한 이미지 형식을 사용할 수 있다. 하지만 대부분의 기존 연구들은 최종적인 악성코드 탐지 및 분류 성능을 주로 강조하고 있으며, CNN에 입력되는 이미지의 형식이 모델의 성능과 자원 사용 량에 미칠 수 있는 영향은 거의 고려하지 않는다. 이에 본 논문에서는 CNN을 기반으로 안드로이드 악성코드를 탐지하는 모 델을 구축함에 있어 입력되는 이미지 형식이 탐지성능과 학습에 소요되는 자원의 사용량에 어떠한 영향을 미치는지를 분석하 였다. CICAndMal2017 데이터세트를 사용하여 BMP, JPG, PNG 및 TIFF 4가지 형식의 이미지로 변환하고, 자체적으로 구축 한 CNN 모델에 학습시킨 후 악성코드 탐지성능과 자원 사용량을 측정하였다. 그 결과 이미지 형식에 따른 이진분류 및 다중 분류 성능과 GPU 및 RAM 사용량은 큰 차이를 보이지 않았다. 그러나 생성된 이미지의 파일 크기는 이미지 형식에 따라 최 대 6배까지 차이가 났으며, 학습에 소요되는 시간에서도 유의미한 차이가 발생함을 확인하였다.","Various image formats are being used when attempting to construct a malware detection model based on CNN. However, most previous studies emphasize only the detection or classification performance, and do not take into account the possible impact of image format on detection performance and resource usage. Therefore, in this paper, we analyze how the input image formats affect detection performance and resources usage when detecting android malware based on CNN. The dataset used in the experiment is the CICAndMal2017 Dataset. Subdataset extracted from the CICAndMal2017 Dataset were converted into images in four formats: BMP, JPG, PNG, and TIFF. We then trained our CNN model and measured malware detection performance and resource usage. As a result, there was no sifnificant difference between detection performance and the GPU/RAM usage, even if the image format changed. However, we found that the file size of the generated images varied by up to six times depending on the image format, and that significant differences occurred in the training time."
CNN 기반 숫자지화 인식을 위한 근전도 신호의 전처리 방법,2021,"['CNN', 'time series sEMG signals', 'frequency domain', 'sEMG pre-processing', 'visual data', 'finger number recognition']","지화의 이미지 데이터를 패턴 인식 기술에 적용하여 지화를 인식하는 기존 방식과는 달리, 표면근전도 신호를 활용하여 지화를 인식하려는 연구가 최근에 많이 진행되고 있다. 표면근전도 신호가 CNN 기반한 지화제스쳐 인식에 적용하기 위해서는 전처리를 하고 난 뒤에 이미지 데이터로 변환된다. 따라서, 표면근전도 신호의 전처리 방법에 따라 CNN에 입력되는 이미지 데이터가 달라지므로, 지화제스쳐 인식 성능에 영향을 미치게 된다. 본 연구에서는 향후 연구 과제로 표면근전도 신호를 주파수 영역에서 활용하는 방법을 제안한다.","Unlike conventional method which recognize finger number gesture by pattern recognition technique with image data of finger gesture, sEMG signals based technique has recently drown attention from researchers. To apply sEMG signals to CNN based finger number recognition, it should be converted to image data to CNN following pre-processing of sEMG. Thus, pre-processing of sEMG signals affect CNN’s performance to recognize finger number gesture since image data relies on pre-processing of sEMG signals. This work proposes use of sEMG in frequency domain as input to CNN learning algorithm for future research."
CNN-based Fast Split Mode Decision Algorithm for Versatile Video Coding (VVC) Inter Prediction,2021,"['Versatile Video Coding (VVC)', 'Inter Prediction', 'Fast algorithm', 'Convolutional Neural Network (CNN)', 'Deep learning']",국문 초록 정보 없음,"Versatile Video Coding (VVC) is the latest video coding standard developed by Joint Video Exploration Team (JVET). In VVC, the quadtree plus multi-type tree (QT+MTT) structure of coding unit (CU) partition is adopted, and its computational complexity is considerably high due to the brute-force search for recursive rate-distortion (RD) optimization. In this paper, we aim to reduce the time complexity of inter-picture prediction mode since the inter prediction accounts for a large portion of the total encoding time. The problem can be defined as classifying the split mode of each CU. To classify the split mode effectively, a novel convolutional neural network (CNN) called multi-level tree (MLT-CNN) architecture is introduced. For boosting classification performance, we utilize additional information including inter-picture information while training the CNN. The overall algorithm including the MLT-CNN inference process is implemented on VVC Test Model (VTM) 11.0. The CUs of size 128×128 can be the inputs of the CNN. The sequences are encoded at the random access (RA) configuration with five QP values {22, 27, 32, 37, 42}. The experimental results show that the proposed algorithm can reduce the computational complexity by 11.53% on average, and 26.14% for the maximum with an average 1.01% of the increase in Bjøntegaard delta bit rate (BDBR). Especially, the proposed method shows higher performance on the sequences of the A and B classes, reducing 9.81%~26.14% of encoding time with 0.95%~3.28% of the BDBR increase."
부분방전 데이터 처리 방법에 따른 CNN 기반 패턴 분류기의 비교 연구,2021,"['Data Processing', 'Partial Discharge', 'CNN', 'Projection', 'Pattern Recognition']",국문 초록 정보 없음,"This study is focused on solution to the problem that may occur due to noise signals when using the image obtained through the conventional partial discharge preprocessing methods as inputs to the CNN-based partial discharge pattern classifier. To solve such problem, a new data preprocessing method is proposed by considering a projection technique. In the data information obtained through the conventional partial discharge preprocessing methods, data information of useless noise signal leads to the problem of performance degradation when constructing highly qualified pattern classifier based on the data information of partial discharge signal. The proposed preprocessing method called as ‘Projection’ in this study is designed to solve this problem and improve a classification performance of CNN-based partial discharge pattern classifier. First of all, through GIS simulation, one-dimensional partial discharge data is obtained as five cases such as corona discharge, floating discharge, insulator discharge, free particle discharge, and steady state (noise) in an environment with a noise signal by using a UHF sensor. After that, by applying the two conventional partial discharge preprocessing methods such as PRPS(Phase Resolved Pulse Sequence), PRPD(Phase Resolved Partial Discharge) and the proposed partial discharge preprocessing method, one-dimensional partial discharge data is transformed into 3 data types such as image set of PRPS, image set of PRPD, and image set of Projection. Finally each image set is used as inputs to the designed CNN-based partial discharge pattern classifier. Through the comparative analysis of the feature maps of each layer in CNN as well as the performance accuracy of partial discharge pattern classification for each image set, the superiority of the proposed preprocessing method is demonstrated."
CNN 기반 실시간 영상처리를 통한 시각장애인 스마트 보조기구,2021,"['Deep learning', 'Object detection', 'CNN', 'Opencv']","시각장애인을 위한 국제 사회의 노력과 관심은 지속되고 있다. 하지만 아직까지 시각장애인의 안전을 위협하는 요소는 많다. 본 논문은 wearable 카메라로 실시간 영상처리를 통해 시각장애인의 근거리와 원거리에서 장애물을 검출하고 그에 대한 물체의 정보를 읽어 음성으로 전달하도록 구현하였다. 이에 더해 정확한 의약품 복용, 주의사항 그리고 복용 방법을 전달하는 기능을 구현하였다. 본 논문에서는 딥 러닝 모델 중 CNN과 하드웨어 및 소프트웨어 구현에 대한 내용을 기술하였으며, 특히 시각장애인에게 적합한 웨어러블 보조 기구를 개발해서 시각장애인들의 시각을 대체하고 안전한 의약품 복용을 돕고자 하는 것을 목표로 연구하였다. 개발 구현결과 본 논문에서 제안한 방법이 기존 시각장애인용 지팡이의 단점인 약한 내구성의 문제를 해결할 수 있다는 것을 입증하였다. 또한 CNN기반 실시간 영상처리를 통해 더욱 안전한 보행을 할 수 있다는 것과 약물오용의 경우를 방지할 수 있다는 것을 입증하였다.","The attention of the international community for the visually-impaired has been increased in recent years. However, there are still many factors that threaten the safety of the blind. In this paper, through real-time image processing with a wearable camera, obstacles are detected at short and long distances from blind people and information on objects is read and delivered by mechanical voice. CNN is one of the models of deep learning, hardware and software implementation are described. In particular, we develop wearable aids suitable for blind people to replace the perspective of blind people and to help them take safe medicines. As a result of the development implementation, it was proved that the method proposed in this paper that could solve the problem of weak durability, which is a disadvantage of the existing cane for the blind. Also, it proved that CNN-based real-time image processing enables safer walking and prevents drug misuse."
PC-Crash의 EES-CNN 유효성 검증에 대한 연구,2021,"['CNN(Convolutional Neural Network)', 'EES(Energy Equivalnet Speed)', 'PC-Crash(교통사고재연 프로그램)', 'delta-V(고정 좌표계에서 차량 무게 중심의 속도 변화)', '머신러닝', '교통사고']","머신러닝은 사람이 하기 어려운 작업을 대신 학습을 통해 수행하는 것을 뜻한다. 작업 방법은 학습 모델(값이 정확한 정답)과 비학습 모델(구해야 하는 값)들을 비교하고, 강화 학습을 통해 결과를 얻어 내는 것이다. PC-Crash의 EES-CNN 기능은 DSD사에서 3년 전부터 진행하고 있는 프로젝트이다. CNN-EES의 data는 EES값이 5~85km/h인 4,000개의 이미지로 기초 데이터의 바탕으로 예상한다. 본 연구의 필요한 차량 사진들은 NHTSA의 Database를 활용했다. 국내 판매량이 가장 높은 현대자동차, 기아의 차량 위주로 전방 충돌, 측면 충돌의 사진을 다운받고, NHTSA에서 제공한 사고 당시의 delta-V 값과 EES-CNN에서 예측한 속도를 비교 정리하였다. 제공한 delta-V data와 EES-CNN data와 비교 했을 때 정확히 일치하는 data는 없었지만 5km/h이하 차이가 나는 차량은 45건 중 5건으로 약 11%가 나왔고, 10km/h이하는 40%가 나왔다. 차종별로 분석했을 땐 SUV의 5km/h 이하는 25%, 10km/h 이하는 50%로 차의 크기가 클수록 손상 부위의 면적이 상대적으로 커지기 때문에 파손 인식 정확도가 더 높을 것이라고 판단된다. 실제 data와 비교했을 때 정확성은 떨어지지만 data가 없고, PC-Crash같은 프로그램으로 교통사고재연 할  때 실제 사고와 비슷한 시나리오의 구성을 위한 초기 data로 사용하거나 지속적인 업데이트를 통해 신뢰성이 높아지길 기대해본다.",다국어 초록 정보 없음
CNN-based Android Malware Detection Using Reduced Feature Set,2021,"['CNN', 'Android', 'Malware', 'Feature selection', 'Binary classification', 'Multiclass classification', '안드로이드', '악성코드', '특성추출', '이진분류', '다중분류']","딥러닝 기반 악성코드 탐지 및 분류모델의 성능은 특성집합을 어떻게 구성하느냐에 따라 크게 좌우된다. 본 논문에서는 CNN 기반의 안드로이드 악성코드 탐지 시 탐지성능을 극대화할 수 있는 최적의 특성집합(feature set)을 선정하는 방법을 제안한다. 특성집합에 포함될 특성은 기계학습 및 딥러닝에서 특성추출을 위해 널리 사용되는 Chi-Square test 알고리즘을 사용하여 선정하였다. CICANDMAL2017 데이터세트를 대상으로 선정된 36개의 특성을 이용하여 CNN 모델을 학습시킨 후 악성코드 탐지성능을 측정한 결과 이진분류에서는 99.99%, 다중분류에서는 98.55%의 Accuracy를 달성하였다.","The performance of deep learning-based malware detection and classification models depends largely on how to construct a feature set to be applied to training. In this paper, we propose an approach to select the optimal feature set to maximize detection performance for CNN-based Android malware detection. The features to be included in the feature set were selected through the Chi-Square test algorithm, which is widely used for feature selection in machine learning and deep learning. To validate the proposed approach, the CNN model was trained using 36 characteristics selected for the CICANDMAL2017 dataset and then the malware detection performance was measured. As a result, 99.99% of Accuracy was achieved in binary classification and 98.55% in multiclass classification."
심전도 신호 분류를 위한 1D CNN 모델 구성 요소의 최적화,2021,"['Deep learning', 'Electrocardiogram', 'CNN', 'ResNet', 'Arrhythmia Detection', '딥러닝', '심전도', '부정맥 검출']","본 논문에서는 딥러닝 모델을 이용하여 모바일 기기의 심전도 신호 측정 데이터를 분류한다. 비정상 심장박동을 높은 정확도로 분류하기 위해 딥러닝 모델의 구성 요소 세 가지를 선정하고 요소의 조건 변화에 따른 분류 정확도를 비교한다. 심전도 신호 데이터의 특징을 스스로 추출할 수 있는 CNN 모델을 적용하고 모델을 구성하는 모델의 깊이, 최적화 방법, 활성화 함수의 조건을 변경하여 총 48개의 조합의 성능을 비교한다. 가장 높은 정확도를 보이는 조건의 조합을 도출한 결과 컨볼루션 레이어 19개, 최적화 방법 SGD, 활성화 함수 Mish를 적용하였을 때 정확도 97.88%로 모든 조합 중 가장 높은 분류 정확도를 얻었다. 이 실험에서 CNN을 활용한 1-채널 심전도 신호의 특징 추출과 비정상 박동 검출의 적합성을 확인하였다.","In this paper, we classify ECG signal data for mobile devices using deep learning models. To classify abnormal heartbeats with high accuracy, three factors of the deep learning model are selected, and the classification accuracy is compared according to the changes in the conditions of the factors. We apply a CNN model that can self-extract features of ECG data and compare the performance of a total of 48 combinations by combining conditions of the depth of model, optimization method, and activation functions that compose the model. Deriving the combination of conditions with the highest accuracy, we obtained the highest classification accuracy of 97.88% when we applied 19 convolutional layers, an optimization method SGD, and an activation function Mish. In this experiment, we confirmed the suitability of feature extraction and abnormal beat detection of 1-channel ECG signals using CNN."
Implementation and Performance Evaluation of Farm Waste Image Classification System using CNN-based Transfer Learning Models,2021,"['Artificial intelligence', 'Transfer-learning', 'CNN', 'Image classification', 'Farm waste collection']","영농 폐기물의 증가로 인해, 빠르고 효율적으로 수거할 수 있는 스마트 영농 폐기물 모니터링 시스템 개발이 필요하다. 본 논문에서는 영농 폐기물 분류 시스템을 제안하고 실제 지역 농촌에서 직접 수집한 영상을 이용하여 CNN 기반의 전이학습 모델들을 구현하고 비교하였다. 영농 폐기물 영상 분류에 적합한 모델과 학습 조건을 찾기 위해, 3가지의 학습 자료군 구성 조건 (2종 분류, 6종 분류, 6종 하위분류를 가진 2종 분류)을 달리하여 미세 조정된 6개의 사전 훈련 CNN 모델들의 검증 정확도를 비교하였다. 그 결과, ResNet-50 모델의 성능이 모든 학습 조건에서 평균 90.9%의 정확도로 가장 높았고, 폐기물 영상을 6종 분류했을 때보다 2종 분류로 했을 때의 검증 정확도가 10% 더 높았다. 특히, 학습 자료군 구성 방법 중 6종 하위분류를 가진 2종 분류했을 때의 검증 정확도는 2종 분류했을 때와 유사했다. 이를 통해 영농 폐기물은 한 종류만 모여 있지 않을뿐더러 다양한 폐기물들이 한데 섞여 있어서 영농 폐기물의 특정한 세부 종류로 분류하는 것보다 폐기물인지 아닌지를 이진 분류하는 것이 더 효과적임을 확인하였다. 나아가, 제안된 시스템의 동작을 확인하기 위해, 영농 환경 모니터링 서버와 영농 폐기물 영상 분류 서버 사이에 TCP / IP 기반의 통신 환경을 구축하고, 모의실험을 통해 구현한 영농 폐기물 영상 분류 시스템이 스마트 영농 폐기물 모니터링 시스템으로 사용될 가능성을 확인하였다. 본 연구의 결과는 정형화되지 않거나 여러 병변이 혼합된 의료 영상을 분류하는 경우에도 활용될 수 있을 것이다.","Due to the increase of farm waste in many countries, there’s a need to develop a smart farm waste monitoring system that can collect it promptly and efficiently. In this paper, we proposed, compared the performance of a convolutional neural network (CNN) -based transfer learning models and implement a farm waste image classification system, which is crucial component for the monitoring system. To find an appropriate model and labelling methods for farm waste image classification, we compared each validation accuracy of six different pre-trained CNN methods with three types of labelling scheme, using the waste images taken directly from the farming area. As a result, the ResNet-50 model performed best with an accuracy of 90.9% on average. Also, when classified into 2 categories, the accuracy was about 10% higher than that of the 6 categories. Furthermore, when the image was classified into 2 main categories with 6 sub-categories, the validation accuracy was similar to that of the 2 categories. Through these results, it seemed to be more effective to classify with binary labels such as ‘trash’ and ‘non-trash’, rather than with multiple labels of specific categories because farm waste is generated not only by single type of waste but also by various types of mixed waste. And a TCP / IP based communication environment between farm environment monitoring server and farm waste image classification server has been implemented. Experimental results using the system implemented for a smart farm waste monitoring showed that the proposed system can be used for a smart farm waste collection system. Also, the result of this study could be applied to classify medical images of unstructured and/or mixed lesion."
1다중 데이터 합성을 이용한 CNN 기반 신원확인 기법 연구,2021,"['identification', 'face recognition', 'digital watermarking', 'face security', 'artificial intelligence', 'CNN']","신원확인을 위한 convolutional neural network(CNN) 기반 얼굴인식 알고리즘은 정확도가 우수하지만, 일반사진으로도 인증이 되는 문제점이 존재한다. 이에 본 논문에서는 디지털 워터마킹 기반 다중 데이터 합성 알고리즘을 결합한 신원확인 시스템을 제안한다. 제안하는 기법은 인증용 음성 및 얼굴 데이터를 주파수 영역에서 데이터를 합성한다. 그리고 이를 CNN의 입력으로 사용해 학습 및 추론을 수행하여 신원확인 동작 여부를 확인하였다. 실험 결과 인증용 음성 및 얼굴 데이터가 합성된 이미지는 신원확인이 정상적으로 이뤄짐을 확인하였으며, 얼굴 및 인증용 음성 데이터가 서로 다른 실험의 경우 신원확인이 정상적으로 이뤄지지 않음을 확인했다. 이를 통해 제안하는 기법이 신원확인을 정상적으로 수행함을 확인하였다.","The convolutional neural network (CNN)-based face recognition algorithm for identification has excellent accuracy, but there is a problem in that it can be authenticated even with a general picture. Therefore, in this paper, we propose an identification system that combines a digital watermarking-based multi-data synthesis algorithm. The proposed scheme synthesizes the authentication voice and face data in the frequency domain. Then, using this as an input of the CNN, training and inference were performed to check whether the identity check was working. As a result of the experiment, it was confirmed that the image in which the voice for authentication and the face data were synthesized was normally identified, and in the case of experiments where the face and the voice data for authentication were different, it was confirmed that the identification was not performed. Through this, it was confirmed that the proposed method normally performs identification."
이미지 감성분류를 위한 CNN과 K-means RGB Cluster 이-단계 학습 방안,2021,"['이미지 감성분류', '색감', '이-단계 학습', 'Sentiment Analysis of Image', 'Sense of Color', 'CNN', 'Two-stage learning']",국문 초록 정보 없음,"The biggest reason for using a deep learning model in image classification is that it is possible to consider the relationship between each region by extracting each regions features from the overall information of the image. However, the CNN model may not be suitable for emotional image data without the images regional features. To solve the difficulty of classifying emotion images, many researchers each year propose a CNN-based architecture suitable for emotion images. Studies on the relationship between color and human emotion were also conducted, and results were derived that different emotions are induced according to color. In studies using deep learning, there have been studies that apply color information to image subtraction classification. The case where the images color information is additionally used than the case where the classification model is trained with only the image improves the accuracy of classifying image emotions.  This study proposes two ways to increase the accuracy by incorporating the result value after the model classifies an images emotion. Both methods improve accuracy by modifying the result value based on statistics using the color of the picture. When performing the test by finding the two-color combinations most distributed for all training data, the two-color combinations most distributed for each test data image were found. The result values were corrected according to the color combination distribution. This method weights the result value obtained after the model classifies an images emotion by creating an expression based on the log function and the exponential function.  Emotion6, classified into six emotions, and Artphoto classified into eight categories were used for the image data. Densenet169, Mnasnet, Resnet101, Resnet152, and Vgg19 architectures were used for the CNN model, and the performance evaluation was compared before and after applying the two-stage learning to the CNN model.  Inspired by color psychology, which deals with the relationship between colors and emotions, when creating a model that classifies an images sentiment, we studied how to improve accuracy by modifying the result values based on color. Sixteen colors were used: red, orange, yellow, green, blue, indigo, purple, turquoise, pink, magenta, brown, gray, silver, gold, white, and black. It has meaning. Using Scikit-learns Clustering, the seven colors that are primarily distributed in the image are checked. Then, the RGB coordinate values of the colors from the image are compared with the RGB coordinate values of the 16 colors presented in the above data. That is, it was converted to the closest color. Suppose three or more color combinations are selected. In that case, too many color combinations occur, resulting in a problem in which the distribution is scattered, so a situation fewer influences the result value. Therefore, to solve this problem, two-color combinations were found and weighted to the model. Before training, the most distributed color combinations were found for all training data images. The distribution of color combinations for each class was stored in a Python dictionary format to be used during testing. During the test, the two-color combinations that are most distributed for each test data image are found. After that, we checked how the color combinations were distributed in the training data and corrected the result. We devised several equations to weight the result value from the model based on the extracted color as described above.  The data set was randomly divided by 80:20, and the model was verified using 20% of the data as a test set. After splitting the remaining 80% of the data into five divisions to perform 5-fold cross-validation, the model was trained five times using different verification datasets. Finally, the performance was checked using the test dataset that was previously separated. Adam was used as the activation function, and the learning rate"
iEnhancer-CNN: Identifying Enhancers using Convolutional Neural Networks,2021,"['Convolutional neural network', 'DNA sequence', 'deep learning', 'enhnacers']",국문 초록 정보 없음,"The identification and strength of enhancers is vital because they play a critical role in modulating gene expression. Although several bioinformatics techniques have been created, they are only capable of distinguishing enhancers from non-enhancers. Recently, in this study A novel predictor named ""iEnhancer-CNN"" was proposed. This CNN-based technique employs a one-hot encoding scheme to identify enhancers. Three convolution layers, followed by max-pooling and a dropout layer, comprise the CNN model. The tool architecture was trained and tested on a benchmark and an independent dataset. We used four assessment measures to determine prediction performance. In achieved accuracy, and the area under the receiver operating characteristic curve was 96.10% and 0.99, respectively. iEnhancer-CNN outperforms the current approaches for defining enhancers, according to the comparative results."
CNN-LSTM 모형을 활용한 토양 습도 예측,2021,"['토양 습도', '장단기 메모리', '다변량 시계열 데이터']","토양 습도는 작물의 생장에 영향을 미치는 주요 요인 중 하나로 작물이 성장하는 중에 토양습도를 정확하게 예측하여 관수 시기를 지정하는 것은 농업 생산량 증대에 큰 영향을 미친다. 그러나 토양습도의 정확한 예측을 위해서는 토양습도와 환경데이터와의 관계에 대한 연구가 필요하다.본 연구에서는 농업기술원에서 제공하는 전남, 경남 지역의 양파 데이터를 활용하였으며, 관측기간은 2019년 12월 31일부터 2021년 6월 5일로 한시간 단위 데이터로 구성되어 있다. 2019년 12월 31일부터 2021년 4월 30일까지의 데이터를 학습시켜 2021년 5월 1일부터 2021년 6월 5일까지의 토양습도를 예측한다. 예측 모형으로는 장단기 메모리(long short term memory : LSTM)와 CNN-LSTM을 사용한다. CNN-LSTM은 대용량 데이터 처리에 우수한 성능을 보이는 딥러닝 기법이며, 딥러닝 중 CNN과 LSTM의 조합 모델을 이용하여 극성분석의 정확도를 개선하는 것을 목적으로 한다. 이를 통해 여러 매개 변수가 존재하기 때문에 그 수치와 정밀도의 관계에 대해 고찰하여 최적의 조합을 찾아 정확도 등 예측 성능 개선을 시도한다. 그 결과, LSTM모형에 비해 CNN-LSTM 모형의 예측력이 더 향상된 것을 확인할 수 있었다. 향후 연구과제로는 좀 더 다양한 딥러닝 기법을 활용한다면 예측력을 향상시킬 수 있을 것으로 기대된다.",다국어 초록 정보 없음
시계열 데이터의 Denoising CNN 적용을 통한 물리 모델 기반 베어링의 잔여수명 추정,2021,"['CNN', 'Time-Series Data (시계열 데이터)', 'Denoising (노이즈 제거)', 'Remaining Useful Life (잔여수명)', 'Fault Diagnosis (고장 진단)']","많은 산업 분야에서 시스템 또는 구성 요소 고장을 방지하는 것이 중요하며, 갑작스러운 고장을 방지하기 위해 기존의 정기적 보수를 통한 방식이 널리 사용되지만 효율성 및 신뢰성 요구를 충족하지 못한다. 이에 따라서 지능형 예지보전 (PHM) 기술이 중요해지고 있으며, 해당 분야의 가장 주요영역 중 하나는 잔여수명 (RUL) 추정이다. 전통적으로, RUL의 추정은 물리적 속성에 대한 충분한 사전 지식에 달려 있으나, 구성 요소에 대한 사전 지식을 얻는 것은 복잡하거나 많은 경우에 불가능하기 때문에, 확보된 데이터만을 사용하여 잔여 수명을 예측하는 데이터 중심 접근법이 많은 영역에서 제안되고 있다. 그러나 데이터 중심의 접근 방식을 사용하여 구성 요소의 수명을 예측하는 것은 과적합 문제와 모델의 학습 과정에서 과도한 리소스를 사용하기 때문에 한계가 존재한다. 학습과 현장에서의 적용 사이의 정확성과 학습 시간에 영향을 끼치는 이러한 문제를 극복하기 위하여 본 논문에서는 물리 모델에 기반한 노이즈 제거 단계와 잔여수명 추정 및 고장 진단 단계로 구성된 CNN 모델을 제안한다. 본 연구를 통하여 물리 모델 기반의 시뮬레이션 데이터를 통하여 고장 신호만을 출력할 수 있도록 학습된 CNN을 통하여 베어링의 잔여 수명 추정 문제에 접근함으로써 빠르고 정확한 추정이 가능함을 시사한다.","Preventing system or component breakdown is critical in many industry areas. To prevent sudden failures, traditional approach of scheduled maintenance is used widely but fails to meet the demands of efficiency and reliability, thus the approach of intelligent prognostic and health management (PHM) technology is becoming important, and one of the most important areas of PHM is estimating remaining useful life of a component. Traditionally, estimating the RUL depends on sufficient prior knowledge of degradation process. However, acquiring the prior knowledge of the component is complicated or even not possible in many cases, thus data-driven approach, which predicts the remaining useful life by only using the acquired data, is proposed in many areas. But the accuracy of estimating the lifespan of the component using data-driven approach is still not satisfactory due to overfitting issues and using excessive resources during the process of training the model. To overcome these issues, which affects the accuracy and time gap between off-line training and on-line estimation, multi-stage convolutional neural networks comprised of two stages, denoising stage and estimating stage, is proposed in this paper. The result of this study suggests that, by approaching the problem of estimating the RUL of bearings using multi-stage CNN trained with simulated physics-based model, faster and accurate estimation is possible."
CNN기반 상품분류 딥러닝모델을 위한 학습데이터 영향 실증 분석,2021,"['상품분류', 'CNN 모델', '딥러닝', '학습데이터', '사전처리', 'Product Classification', 'CNN Model', 'Deep Learning', 'Training Data', 'Preprocessing']","전자상거래에서 상품 정보에 따른 신속하고 정확한 자동 상품 분류는 중요하다. 최근의 딥러닝 기술 발전은 자동 상품 분류에도 적용이 시도되고 있다. 성능이 우수한 딥러닝 모델 개발에 있어, 학습 데이터의 품질과 모델에 적합한 데이터 전처리는 중요하다. 본 연구에서는, 텍스트 상품 데이터를 기반으로 카테고리를 자동 유추할 때, 데이터의 전처리 정도에 따른 영향력과 학습 데이터 선택 범위 영향력을 CNN모델을 사례 모델로 이용하여 비교 분석한다. 실험 분석에 사용한 데이터는 실제 데이터를 사용하여 연구 결과의 실증을 담보하였다. 본 연구가 도출한 실증 분석 및 결과는 딥러닝 상품 분류 모델 개발 시 성능 향상을 위한 레퍼런스로서 의의가 있다.","In e-commerce, rapid and accurate automatic product classification according to product information is important. Recent developments in deep learning technology have been actively applied to automatic product classification. In order to develop a deep learning model with good performance, the quality of training data and data preprocessing suitable for the model are crucial. In this study, when categories are inferred based on text product data using a deep learning model, both effects of the data preprocessing and of the selection of training data are extensively compared and analyzed. We employ our CNN model as an example of deep learning model. In the experimental analysis, we use a real e-commerce data to ensure the verification of the study results. The empirical analysis and results shown in this study may be meaningful as a reference study for improving performance when developing a deep learning product classification model."
CNN을 이용한 Cyclic Moment 기반 자동 변조 인식,2021,"['Automatic recognition modulation', 'Cyclic moment', 'Convolution neural network']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 손짓 인식기술 정확도 향상 연구,2021,[],"인간과 기계간의 상호작용에서 인간의 손짓은 중요한 의미를 지니고 있다. 이러한 인간의 손짓은 점차 중요성이 증가하고 있지만, 복잡한 손짓의 입력이나 주변의 환경적 요인에 의한 잡음 등은 손짓 인식 기술 정확도 향상에 있어 해결해야 할 중요한 과제이다. 본 논문에서는 이러한 상황을 해결할 수 있는 기술로 Convolutional Neural Networks(CNN)을 제안한다. CNN은 이미지 데이터 학습에 유용하다는 장점을 가지고 있으며, 이 기술은 인간과 기계간의 상호작용에서 정확도를 매우 향상시킬 것이다. 5가지 수화동작을 7.4-9.0GHz의 주파수대역폭, 8dB의 이득 특성을 가진 Vivaldi안테나를 이용하여 데이터를 추출하였고, 전처리과정을 거친 데이터를 CNN을 통해 학습시켰다. 제안된 CNN의 분류 결과는 약 96%의 정확도를 보였다.",다국어 초록 정보 없음
이미지 분류에서의 CNN 최적화 모델 설계,2021,"['Convolutional Neural Network', 'Image Classification', 'Tensorflow', 'Deep learning Artificial intelligence', 'Neural Net', 'Machine Learning', 'Supervised Learning']",이미지 인식에 주로 사용되는 구글의 Tensorflow기반으로 한 CNN(Convolutional Neural Network)을 적용 시킨 이미지 분류에서의 최적화 모델을 설계한다.  CNN모델에서 적용가능한 방법론과 Hyper_Parameter의 최적의 값을 실험을 통해 선별하고 이미지 분류 모델을 설계하는데 기준을 제시하여 효율적인 모델 설계의 바탕이 되고자 한다.,"Based on Google""s Tensorflow, which is mainly used for image recognition, the company will design an optimized model in image classification that applies CNN (Convolutional Natural Network).  We want to set the basis for efficient model design by screening the optimal values of the methodology and Hyper_Parameter available in the CNN model through experiments and providing criteria for designing image classification models."
Review on the Recent Welding Research with Application of CNN-Based Deep Learning Part I: Models and Applications,2021,"['Deep learning', 'Convolution Neural Network', 'Image', 'Welding', 'Model', 'Application']",국문 초록 정보 없음,"During machine learning algorithms, deep learning refers to a neural network containing multiple hidden layers. Welding research based upon deep learning has been increasing due to advances in algorithms and computer hardwares. Among the deep learning algorithms, the convolutional neural network (CNN) has recently received the spotlight for performing classification or regression based on image input. CNNs enables end-to-end learning without feature extraction and in-situ estimation of the process outputs. In this paper, 18 recent papers were reviewed to investigate how to apply CNN models to welding. The papers was classified into 5 groups: four for supervised learning models and one for unsupervised learning models. The classification of supervised learning groups was based on the application of transfer learning and data augmentation. For each paper, the structure and performance of its CNN model were described, and also its application in welding was explained."
무선 네트워크 침입탐지를 위해 개선된 CNN 분석,2021,"['Wireless network', 'Intrusion detection', 'Convolution neural network', 'Detection accuracy', 'True positive rate', 'False positive rate']","최근 5G기술과 함께 공중 및 사설 WiFi 서비스 영역이 크게 확대되면서 사용자 트래픽의 종류와 크기도 폭발적으로 증가하고 있다. 이와 함께 무선 네트워크의 보안 취약성을 이용한 인가되지 않은 악의적인 사용자의 침입/공격 트래픽도 크게 증가하고 있다. 침입/공격특성 또한 다양화되고 있어 기존 무선 네트워크 침입 탐지 시스템은 오탐률이 높고 탐지 효율성이 낮으며 침입 및 공격 트래픽에 대한 일반화 능력이 약하다. 본 논문에서는 과대적합 문제를 피하면서 일반화 능력을 개선하기 위한 방안으로 CNN의 커널 크기를 축소하고 콘볼루션 계층을 이중화하여 병렬 연산을 하는 구조를 제안한다. 테스트 데이터 세트로NSL-KDD CUP 데이터 세트를 사용하여, 실험 및 분석 결과 제안한 CNN은 침입/공격을 탐지하기 위한 샘플 테스트 수행에서 정확도와 참양성률(true positive rate)은 96.38%, 96.75%이며 이것은 기존 DBN과 RNN보다 2%이상 향상된 결과이다. 또한 위양성율(false positive rate)은 0.88%와 0.91% 보다 낮은 0.64%을 보여주었다.","Recently, along with 5G technology public and private WiFi service areas have been greatly expanded. Also, the types and sizes of user traffic are increasing explosively. At the same time, the frequency of intrusion/attack by unauthorized malicious users using security vulnerabilities of wireless networks is also increasing significantly. Intrusion/attack characteristics are also diversifying, so the existing wireless network intrusion detection system has a high false positive rate, low detection efficiency, and weak generalization ability for intrusion and attack traffic. In this paper, as a method to improve generalization ability while avoiding the overfitting problem, we propose a structure that reduces the size of the CNN kernel and duplicates the convolutional layer for parallel operation. The NSL-KDD CUP data set was used as the test data set. As a result of experiments and analysis, the proposed CNN show 96.38% and 96.75% accuracy and true positive rates in performing sample tests to detect intrusion/attack.This showed an improvement of more than 2% compared to the existing DBN and RNN. Also, the false positive rate was 0.64%, lower than 0.88% and 0.91%."
CNN을 이용한 성인과 노인의 행동특성분석,2021,"['Convolutional neural network', 'behavior characteristics', 'grad-CAM', 'Kinect’s skeleton']",국문 초록 정보 없음,"Due to the advance of medical technology, human can live more longer than past. The elderly population relative to young population is increasing. It is needed to investigate elderly characteristics to cope with future. In this paper, we analyze the behavior characteristics of young and elderly adults using CNN(Convolutional Neural Network) and grad-CAM(Class Activation Mapping). There are some differences in behavior pattern of young and elderly adults because of changes in state of physical body by aging. First, skeleton is transformed to PEI(Pose Evolution Image) and it enters CNN to classify young and elderly adult. Secondly, the trained CNN model is analyzed using grad-CAM. For experiment, ETRI-Activity3D dataset is used to analyze behavior characteristics."
고무제품 혼련 공정에서의 CNN기반 품질 지표 예측 모델 개발,2021,"['CNN', 'Mixing Process', 'Quality Indicator Prediction', 'Time Series Data']","고무 제품의 제조를 위한 공정 중 혼련 공정은 믹서에 원료와 배합제를 투입하여 혼합하는 공정이다. 대부분의 기업에서는 숙련된 작업자의 암묵지를 활용하여 재료의 투입 순서와 시간을 결정하며 이는 공정의 신뢰도와 품질의 균일성을 저해한다. 이를 체계화하기 위해 본 연구에서는 믹서의 온도, 전압, 램(Ram) 개폐 여부 등의 시계열 데이터에서 고무 물성을 예측할 수 있는 모델을 제안한다. 예측 정확도를 높이기 위해 합성곱 레이어의 다층 쌓기에 유리한 Residual Neural Network(ResNet)을 구축하였으나 검증 오차가 낮아지지 않는 문제가 발생하였다. 이에 본 연구에서는 레이어의 수를 역으로 줄이는 모델을 개발하였는데, 이 모델은 3개의 레이어로 구성된 1차원 Convolution Neural Network(CNN)이며, Zero-padding의 문제점을 개선한 Symmetric-padding을 적용하였다. 이러한 방법의 적용은 CNN과 ResNet34를 결합한 모델의 학습속도를 개선하고 검증 오차를 약 4% 감소시킬 수 있었다. 본 논문의 연구결과를 통하여 고무혼련공정 및 유사 공정의 품질 지표 예측모델의 다른 접근법에 대한 기초연구결과를 제공해줄 수 있을 것으로 기대한다.",다국어 초록 정보 없음
CNN을 이용한 Molybdenum 적층제조의 실시간 모니터링 알고리즘 개발,2021,"['스마트제조', '적층제조', '실시간 검측', '이미지 학습', '합성곱신경망']","Molybdenum은 높은 융점, 높은 경도 등 우수한 기계적 특성을 가지고 있다. 적층제조는 Molybdenum의 기계적 특성으로 인한 절삭 가공의 어려움을 해결하지만, 적층 과정에서 불량이 발생할 경우 재료가 낭비되며, 불량을 탐지한 시점이 늦어질 수록 낭비되는 재료로 인해 비용이 증가한다. 특히, Molybdenum은 고가의 재료임으로 적층제조과정에서 발생하는 불량을 적시에 발견할 수 있는 실시간 모니터링 및 불량 탐지 시스템을 개발하는 것이 중요하다. 본 연구에서는 수집이 용이한 전압 데이터를 wave form 이미지로 변환하고, Convolutional Neural Network(CNN) 기반의 모델을 학습하여 불량여부를 분류한 뒤, 분류 결과를 사용자가 확인 가능하도록 이미지화하는 실시간 모니터링 알고리즘을 제안한다. 실험 사례에서는 아크를 통해 공급된 선재를 녹인 후 굳혀 생산하는 WAAM 공정(Wire + Arc Additive Manufacturing)을 통해 만들어진 19개 Molybdenum bead의 전압 데이터를 이용하였다. 실시간 탐지 및 데이터 증식을 위해 전압데이터에 대한 간격 및 구간을 설정하고 설정된 간격 및 구간에 따라 wave form 이미지로 변환하였다. 이 과정에서 다양한 간격과 구간의 조합을 고려하였으며, 조합별로 CNN 분류기를 학습하고 그 결과를 비교하여 최적의 간격 및 구간을 탐색하였다. 사례 연구 결과, CNN 분류기는 정확도 95%의 높은 분류 성능을 보여주었으며, 이를 테스트 데이터에 적용하여 실시간 모니터링이 가능함을 확인하였다.",다국어 초록 정보 없음
CNN-LSTM 기반 위치 측위를 이용한 영상 내 비승인자 추적 시스템,2021,"['CNN-LSTM', 'Location Positioning', 'Fingerprinting', 'Object Recognition', 'Object Tracking', '위치 측위', '핑거프린팅', '객체 인식', '객체 추적']","본 논문에서는 영상 데이터, 비콘 데이터의 결합을 통해 집단시설에서 출입이 허용된 승인자와 비승인자를 구분하는 시스템을 제안한다. IP 카메라를 통해 수집된 영상 데이터는 YOLOv4를 사용하여 사람 객체를 추출하고, 애플리케이션을 통해 비콘의 신호 데이터(UUID, RSSI)를 수집하여 핑거프린팅 기반의 라디오 맵을 구성한다. 비콘은 신호의 불안전성을 보완해 위치 파악의 정확도를 향상하기 위하여 CNN-LSTM 기반의 학습을 진행한 후 사용자 위치 데이터를 추출한다. 이후 도출된 위치 데이터와 사람 객체가 추출된 영상 데이터를 매핑해 실시간으로 비승인자를 추적한다. 본 논문의 결과로 93.47%의 정확도를 보였으며, 향후 코로나19로 사용이 증가한 QR코드 등의 출입 인증 절차와 융합해 인증 절차를 거치지 않은 사람을 추적하는 확장성까지 기대할 수 있다.","In this paper, we propose a system that uses image data and beacon data to classify authorized and unauthorized perosn who are allowed to enter a group facility. The image data collected through the IP camera uses YOLOv4 to extract a person object, and collects beacon signal data (UUID, RSSI) through an application to compose a fingerprinting-based radio map. Beacon extracts user location data after CNN-LSTM-based learning in order to improve location accuracy by supplementing signal instability. As a result of this paper, it showed an accuracy of 93.47%. In the future, it can be expected to fusion with the access authentication process such as QR code that has been used due to the COVID-19, track people who haven""t through the authentication process."
YOLO와 CNN을 이용한 강인한 차량 번호판 인식 시스템 구현,2021,"['you only look once', 'license plate', 'object detection', 'optical character recognition', 'convolution neural network']",국문 초록 정보 없음,"In recent years, with the development of intelligent transportation systems, research on license plate recognition is drawing attention. Domestic license plate recognition is frequently misrecognized due to image quality and Korean language problems. This study implemented a real-time license plate recognition system robust against environmental changes using YOLO and CNN. YOLO was used to extract only a specific license plate area, and CNN was used to recognize license plates. License plate recognition extracted numbers and letters from the actual license plate drawing. Then, it was transformed and multiplied to be robust to the environment, and learned with CNN. In addition, three algorithms were used for recognizing Korean characters with many misrecognitions, such as detection of separated consonants and vowel regions using erosion and average regions, and extraction of syllable regions when there is no Korean syllable. Finally, the proposed license plate recognition system and the existing OCR algorithm were compared. As a result of the experiment, the easy OCR has an accuracy of 62.5%, the algorithm using only erosion is 82.5%, and the proposed algorithm has an accuracy of 97.5%."
1D CNN을 활용한 금형 실린더 온도 사이클의 이상탐지,2021,[],"본 논문의 분석 대상은 단일 온도 센서 만을 보유한 금형 주조 공정이다. 해당 금형 주조사에서는 금형의 온도 패턴을 사용해 자동으로 완성 제품의 양불 판정을 하길 원한다. 주조 사이클마다 단일 센서의 패턴이 존재하고 패턴의 계층적 구조를 파악하는 것이 이상 탐지에 핵심인 태스크이기 때문에 이상 탐지를 딥러닝 모델을 만들어서 해결해보고자 한다. 시계열 데이터에 주로 사용되는 1D CNN으로 지역 패턴을 학습하여 양불 판정을 할 수 있는 모델을 사용하였다. 비교를 위해 완전 연결층으로만 구성된 모델과 1D CNN 모델을 실험했으며 실험 결과, 완전 연결층 모델의 정확도는 98.20%, 1D CNN을 활용한 모델의 정확도는 99%가 나왔다.",다국어 초록 정보 없음
Faster R-CNN을 이용한 갓길차로 위반 차량 검출,2021,[],"기존 갓길 차로 위반 차량 시스템은 센서와 같은 장비가 필요하거나 영상의 전처리가 필요하여 성능의 한계를 보였다. 이에 본 연구는 자동화 시스템의 부재에 따른 한계를 극복하기 위하여 CNN기반의 Faster R-CNN 기법을 활용하여 입력 영상에 대한 별도의 전처리 없이 빠르게 갓길 차로 위반 차량을 검출할 수 있는 방법을 제안한다. 본 제안 방법은 Faster R-CNN 기법을 기반으로 하는 탐지 모듈과 탐지 된 차량 중 갓길 위반 여부를 판단하는 판독 모듈로 구성되어 있다. 탐지 모듈에서 영상 내 모든 차량을 식별하면 판독 모듈에서 해당 클래스의 예측 점수와 Threshold를 비교하여 최종적으로 갓길 차로 위반 차량임을 결정할 수 있다. 실험 및 평가를 위해 현실세계와 유사하게 상황을 재현할 수 있는 시뮬레이션 게임인 GTAV에서 이미지 형태의 학습데이터 1,800장과 평가데이터 800장을 가공 및 생성하여 ZFNet과 VGG16에서 Threshold 값의 변화에 따른 성능을 측정하였다.",다국어 초록 정보 없음
Mammogram 특징 추출을 위한 maskSLIC 기반 CNN 분류 모델,2021,"['Deep learning', 'CNN', 'SLIC', 'Superpixel', 'Medical imaging']",국문 초록 정보 없음,다국어 초록 정보 없음
스펙트로그램을 통한 신호 분류 시 가중치 초기화 방법에 따른 CNN의 성능 비교,2021,[],본 논문은 CNN을 사용하여 스펙트로그램 데이터를 통한 신호 분류 시 가중치 초기화 방법이 CNN 분류기의 성능에 어떠한 영향을 끼치는지 비교하며 최적의 초기화 방법을 찾는다. 모의 실험의 결과를 통해 He 초기화 방법이 다른 초기화 방법에 비해 손실 값의 수렴 속도가 더 빠르고 학습이 반복될수록 손실 값이 더 적은 것으로 확인되었다. 이를 통해 많은 신호 분류 연구에 있어 CNN 구축에 많은 도움이 될 것으로 예상된다.,다국어 초록 정보 없음
전이학습 기반 CNN을 통한 풀림 방지 코팅 볼트 이진 분류에 관한 연구,2021,"['Bolts With Anti-loosening Coating', 'Convolutional Neural Networks', 'Transfer Learning', 'Fine-tuning', 'Fully Connected Layer']","풀림 방지 코팅 볼트는 주로 자동차 안전 관련 부품을 결합하는 데 사용되므로 안전성 유지를 위해 코팅 결함을 사전에 감지해야 한다. 이를 위해 이전 연구 [CNN 및 모델 시각화 기법을 사용한 코팅 볼트 불량 판별]에서는 합성곱신경망을 사용했다. 이때 합성곱 신경망은 데이터 수가 많을수록 이미지 패턴 및 특성 분석 정확도가 증가하지만 그에 따라 학습시간이 증가한다. 또한 확보 가능한 코팅 볼트 샘플이 한정적이다. 본 연구에서는 이전 연구에 전이학습을 추가적으로 적용해 데이터 개수가 적은 경우에도 코팅 결함에 대해 정확한 분류를 하고자 한다. 전이학습을 적용할 때 학습데이터 수와 사전 학습 데이터 ImageNet 간의 유사성을 고려해 분류층만 학습했다. 데이터 학습에는 전역 평균 풀링, 선형 서포트 벡터 머신 및 완전 연결 계층과 같은 분류층을 적용했으며, 고려한 모델 중 완전 연결 계층 방법의 분류층이 가장 높은 95% 정확도를 가진다. 추가적으로 마지막 합성곱층과 분류층을 미세 조정하면 정확도는 97%까지 향상된다. 전이학습 및 미세 조정을 이용하면 선별 정확도를 향상시킴은 물론 이전보다 학습 소요시간을 절반으로 줄일 수 있음을 보였다.","Because bolts with anti-loosening coatings are used mainly for joining safety-related components in automobiles, accurate automatic screening of these coatings is essential to detect defects efficiently. The performance of the convolutional neural network (CNN) used in a previous study [Identification of bolt coating defects using CNN and Grad-CAM] increased with increasing number of data for the analysis of image patterns and characteristics. On the other hand, obtaining the necessary amount of data for coated bolts is difficult, making training time-consuming. In this paper, resorting to the same VGG16 model as in a previous study, transfer learning was applied to decrease the training time and achieve the same or better accuracy with fewer data. The classifier was trained, considering the number of training data for this study and its similarity with ImageNet data. In conjunction with the fully connected layer, the highest accuracy was achieved (95%). To enhance the performance further, the last convolution layer and the classifier were fine-tuned, which resulted in a 2% increase in accuracy (97%). This shows that the learning time can be reduced by transfer learning and fine-tuning while maintaining a high screening accuracy."
인공지능 기법(CNN)을 이용한 음성과 음악구분,2021,"['Speech-Music Discrimination', 'Fingerprint', 'Deep Learning', 'CNN', 'Mel-Spectrum', 'Transfer Learning']","음성, 음악 구분 방법은 전통적으로 퓨리에 분석치의 특성치를 직접 이용하는 방법이 사용되어 왔다. 하지만 딥러닝을 이용하면 end-to-end 방식으로 특성치를 별도로 부여하는 과정을 거치지 않고 구분이 가능하다. 본고에 사용된 자료는 국내 음악방송(FM 89.8MHz)에서 추출된 약 389만개의 음성, 음악 파일이다. 송출된 소리를 5초 단위로 구분하여 음성 2,401,040개 파일, 음악 1,489,168 총 3,890,208개의 파일을 구성했다. 5초 단위로 소리를 끊는 것은 일반적으로 음악 핑거프린팅이 5초 단위 소리를 사용하여 구분하기 때문이다. 이러한 자료에 대해 딥러닝 분석 기법인 CNN분석을 적용하되 기존의 이미지 학습을 이용한 전이학습(transfer learning)을 적용했다. 실험결과 모형의 복잡성을 높이지 않고도 기존 학습 모형을 응용해 약 89.6% 전후 정확도가 나왔다. 또한 혼동 행렬을 이용하면 음성을 음악으로 판단하는 오류는 12.3%, 음악을 음성으로 판단하는 오류는 12.2%를 보였다.","Traditionally, a method of directly using the characteristic value of the Fourier analysis has been used to distinguish voice and music. However, if deep learning is used, it is possible to distinguish voice and music with an end-to-end method without the need for the process of characteristic featuring. The data used in this paper are about 3.89 million voice and music files extracted from a domestic music broadcasting (FM 89.8MHz). The transmitted sound is divided into 5-second units. Breaking down sound into 5-second increments is applied because music fingerprinting generally uses 5-second increments to distinguish sounds. The CNN analysis, a deep learning analysis technique, was applied to these data, and transfer learning was performed using existing image learning models. An accuracy of about 89.6% was obtained in the existing learning model without increasing the complexity of the deep learning model. In addition, while using the confusion matrix, the error of judging voice as music was 12.3%, and the error in judging music as voice was 12.2%."
Implementation of CNN-based Masking Algorithm for Post Processing of Aerial Image,2021,"['Aerial Image', 'Mask R-CNN', 'CNN', 'Digital Twin', 'Smart City']",국문 초록 정보 없음,"Eunsoo CHOI;Zhixuan QUAN;Sangwoo JUNGPurpose: To solve urban problems, empirical research is being actively conducted to implement a smart city based on various ICT technologies, and digital twin technology is needed to effectively implement a smart city. A digital twin is essential for the realization of a smart city. A digital twin is a virtual environment that intuitively visualizes multidimensional data in the real world based on 3D. Digital twin is implemented on the premise of the convergence of GIS and BIM, and in particular, a lot of time is invested in data pre-processing and labeling in the data construction process. In digital twin, data quality is prioritized for consistency with reality, but there is a limit to data inspection with the naked eye. Therefore, in order to improve the required time and quality of digital twin construction, it was attempted to detect a building using Mask R-CNN, a deep learning-based masking algorithm for aerial images. If the results of this study are advanced and used to build digital twin data, it is thought that a high-quality smart city can be realized."
전이학습 기반의 CNN을 이용한 컨포멀 코팅 PCB에 발생한 기포 검출 방법,2021,"['Transfer Learning', 'CNN', 'Bubble Detection', 'Conformal Coating', 'VGGNet']",국문 초록 정보 없음,"Air bubbles which may be generated during the PCB coating process can be a major cause of malfunction. so it is necessary to detect the bubbles in advance. In previous studies, candidates for bubbles were extracted using the brightness characteristics of bubbles, and the candidates were verified using CNN(Convolutional Neural Networks). In this paper, we propose a bubble detection method using a transfer learning-based CNN model. The VGGNet is adopted and sigmoid is used as a classification layer, and the last convolutional layer and classification layer are trained together when transfer learning is applied. The performance of the proposed method is F1-score 0.9044, which shows an improvement of about 0.17 compared to the previous study."
"전기화재 원인분석을 위한 실험실 데이터를 활용한 1차, 2차 단락흔 및 열흔 판별용 CNN 알고리즘 설계",2021,"['Electrical fire', 'Arc beads', 'Molten mark', 'Convolution neural network']",국문 초록 정보 없음,"In this paper, a new CNN algorithm is proposed to determine the direct cause of electric fires. We create 10,000-15,000 three types of data that can occur at a fire scene in our laboratory, and then train and verify it through the proposed CNN algorithm. As a result of the experiment and analysis, the classification accuracy of the primary and secondary arc beads was 86.2%, the accuracy of arc beads and molten marks was 93.6%. And also, the classification accuracy of the primary and secondary arc beads and molten marks was 92.4%. The results of this study are meaningful in that fire forensics can provide accurate identification results in a shorter time through artificial intelligence algorithms compared to the existing methods of identification through visual classification and physicochemical material analysis methods. In particular, the classification between primary and secondary arc beads is known to be a very difficult problem. However, the results of this study provided more than 86% classification ability."
CNN을 활용한 영상기반 케이블 진동 측정 자동화,2021,"['CNN', '객체 추적', '진동 측정', '자동화']",사장교에서 케이블은 굉장히 중요한 구조요소 중 하나이다. 케이블의 건전성을 파악하고 대응하기 위해서는 발생한 진동의 측정을 필요로 한다. 케이블의 동적 진동을 측정하기 위해서 다양한 연구들이 수행되고 있다. 최근에는 Computer Vision 기술을 이용하여 구조물의 변위를 측정하는 연구들이 진행되고 있다. 하지만 기존의 영상 기반 변위 측정을 케이블에 적용하기에는 몇 가지 문제점이 발생한다. 본 연구에서는 Computer Vision 기술을 기반으로 CNN(Convolutional Neural Network)을 활용하여 사장교 케이블의 거동을 장기간 측정하는데 발생하는 문제점들을 해결하고자 한다.,다국어 초록 정보 없음
CNN을 이용한 거북목 증후군 진단기의 구현,2021,"['거북목 증후군(turtle neck syndrome)', 'CNN(Convolutional Neural Networks)']","최근 스마트폰과 컴퓨터 등의 비중이 커지면서 거북목 증후군의 관심사가 커졌다. 거북목 증후군은 잘못된 자세로 인해 어깨의 근육과 인대가 늘어나 통증이 생기는 증상을 의미한다. 이러한 잘못된 자세에는 대표적으로 일자목과 역c자목이 있으며 일자목은 7개의 목뼈로 이루어진 경추라인이 c자 라인에서 일직선으로 뼈의 형태가 바뀌어 디스크가 일어나 통증을 유발하는 증상이고 역c자목은 정상의 목뼈 구조를 잃어버린 형태로 곧 디스크를 보이며 고개를 드는 것이 힘드며 구부정한 자세를 취하게 되는 증상이다. 본 연구에서는 컨볼루션 신경망 (CNN) 학습 모델을 구현하여 주어진 자세가 올바른 자세인지 일자목인지 c자목인지를 진단할 수 있는 분류기를 구현하였다. 또한, 최근 코로나 사태로 인해 마스크 장착이 일상화되고 있는데, 추가데이터를 보강하여, 마스크 착용상태에서도 적용가능한 모델로 확장하였다.",다국어 초록 정보 없음
CNN 모델을 활용한 홍수 위험도 판별 시스템 구현,2021,"['DNN', 'Flood', 'Flood management', 'Flood risk Determination', 'Time seires data']","홍수 피해는 세계 각지에서 발생하고 있으며, 홍수에 취약한 지역에 사는 사람이 2000년에 비해 25% 증가한 8,600만 명에 이른다. 이러한 홍수는 인명과 재산에 막대한 피해를 남기며, 피해를 줄이기 위해선 적절한 시기에 대피를 결정하는 것이 필수적이다. 홍수를 예상하고 대피하는 것에도 많은 비용이 발생하며, 홍수 예측에 오류가 발생하여 대피하지 않는 경우에는 더 큰 비용이 발생한다. 따라서 본 논문에선 시계열 데이터인 강수량과 수위를 활용하여 적절한 시기에 대피가 이루어질 수 있도록 하기 위한 CNN모델을 활용하여 홍수 위험도 판별 모델을 제안한다. 이를 통해 최적의 대피시기를 결정하여 불필요한 대피를 막고, 적절한 시기에 대피가 이루어질 수 있도록 하는 초기 연구로서 활용할 수 있을 것으로 사료된다.","Flood damage is occurring all over the world, and the number of people living in flood-prone areas reached 86 million, a 25% increase compared to 2000. These floods cause enormous damage to life and property, and it is essential to decide on an appropriate evacuation in order to reduce the damage. Evacuation in anticipation of a flood also incurs a IoT of cost, and if an evacuation is not performed due to an error in the flood prediction, a greater cost is incurred. Therefore, in this paper, we propose a flood risk determination model using the CNN model to enable evacuation at an appropriate time by using the time series data of precipitation and water level. Through this, it is thought that it can be utilized as an initial study to determine the time of flood evacuation to prevent unnecessary evacuation and to ensure that evacuation can be carried out at an appropriate time."
CNN 기반의 국내 스타트업-해외 바이어간 추천시스템 설계,2021,"['CNN', 'word2vec', 'doc2vec', '시각정보', '추천시스템']","본 논문은 국내 스타트업의 상품/서비스에 적합한 해외 바이어를 찾아 맟춤형으로 추천해주는 시스템을 설계하고자 한다. 추천 알고리즘은 CNN기반의 Word2Vec과 Doc2Vec 알고리즘을 활용하며, 정확도를 높이기 위해 시각정보를 활용한다. 추천 시스템에 사용되는 데이터는 비정형 데이타인 회사 소개 및 상품/서비스 소개 문장 데이터이며, 제품 사진을 시각정보로 이용한다. 유사도가 높은 순으로 추천하기 위해 문장데이타를 키워드 리스트로 변환하고, Word2vec 모델에 이식시켜 키워드 좌표를 만들어 벡터화한다. 그리고, 문장의 중심점간 거리를 계산해 기업간 유사성 및 연관성을 도출한다. 이를 바탕으로 국내 스타트업의 문장데이타 및 시각정보와 유사도가 높은 순으로 해외바이어를 추천한다.",다국어 초록 정보 없음
CNN 영상 회귀 기반의 산란계수 추정을 통한 연무제거,2021,"['image dehazing', 'CNN', 'LiDAR', 'dark channel prior', 'scattering coefficient', 'image regression']",국문 초록 정보 없음,"The estimation of the scattering coefficient in depth image-based dehazing is of paramount importance. Since scattering coefficients are used to estimate the transmission image for dehazing, the optimal scattering coefficients for effective dehazing must be obtained depending on the level of haze and fog generation. In this study, we performed a CNN-based image regression to obtain the optimal scattering coefficients for each image with fog and haze. A three-channel image was used as the input data, and the learning was performed with approximately 2,000 labeled synthetic haze and fog datasets. Subsequently, the transmission image was estimated using the scattering coefficient obtained for the input image through the learned model, and the depth image was obtained through the LiDAR point cloud projection for performing the dehazing. This paper presents a qualitative and quantitative comparison of the results obtained using the proposed dehazing technique with those obtained using the existing dehazing algorithms."
CNN-LSTM 모델 기반의 감성분석을 이용한 상품기획 모델,2021,"['상품(Product)', 'CNN(Convolutionl Neural Network)', '기법(Technique)', 'LSTM(Long Short Term Memory)', '텍스트마이닝(Text Mining)', '딥러닝(Deep Learning)', '크롤링(Crawling)']","정보통신기술의 발달로 전자상거래의 증가와 소비자들의 제품에 대한 경험과 지식의 공유가 활발하게 진행됨에 따라 소비자는 제품을 구매하기 위한 자료수집, 활용을 진행하고 있다. 따라서 기업은 다양한 기능들을 반영한 제품이 치열하게 경쟁하고 있는 현 시장에서 우위를 점하고자 소비자 리뷰를 분석하여 소비자의 정확한 소비자의 요구사항을 분석하여 제품기획 프로세스에 반영하고자 텍스트마이닝(Text Mining) 기술과 딥러닝(Deep Learning) 기술을 통한 연구가 이루어지고 있다. 본 논문의 기초자료가 되는 데이터셋은 포털사이트의 구매사이트와 오픈마켓 사이트의 소비자 리뷰를 웹크롤링하고 자연어 처리하여 진행한다. 감성분석은 딥러닝기술 중 CNN(Convolutional Neural Network), LSTM(Long Short Term Memory) 조합의 모델을 구현한다. 이는 딥러닝을 이용한 제품기획 프로세스로 소비자 요구사항 반영, 경제적인 측면, 제품기획 시간단축 등 긍정적인 영향을 미칠 것으로 기대한다.",다국어 초록 정보 없음
CNN Auto-Encoder Network Using Dilated Inception for Image Steganography,2021,"['Information security', 'Image steganography', 'Dilated convolution', 'CNN', 'Autoencoder']",국문 초록 정보 없음,"Numerous studies have used convolutional neural networks (CNNs) in the field of information concealment as well as steganalysis, achieving promising results in terms of capacity and invisibility. In this study, we propose a CNN-based steganographic model to hide a color image within another color image. The proposed model consists of two sub-networks: the hiding network is used by the sender to conceal the secret image; and the reveal network is used by the recipient to extract the secret image from the stego image. The architecture of the concealment sub-network is inspired by the U-Net auto-encoder and benefits from the advantages of the dilated convolution. The reveal sub-network is inspired by the auto-encoder architecture. To ensure the integrity of the hidden secret image, the model is trained end to end: rather than training separately, the two sub-networks are trained simultaneously a pair of networks. The loss function is elaborated in such a way that it favors the quality of the stego image over the secret image as the stego image is the one that comes under steganalysis attacks. To validate the proposed model, we carried out several tests on a range of challenging publicly available image datasets such as ImageNet, Labeled Faces in the Wild (LFW), and PASCAL-VOC12. Our results show that the proposed method can dissimulate an image into another one with the same size, reaching an embedding capacity of 24 bit per pixel without generating visual or structural artefacts on the host image. In addition, the proposed model is generic, that is, it does not depend on the image’s size or the database source."
CNN 기반 리뷰 유용성 점수 예측을 통한 개인화 추천 서비스 성능 향상에 관한 연구,2021,"['개인화 추천 서비스', '리뷰 유용성', '협업 필터링', '딥러닝', 'Personalized Recommendation Service', 'Review Helpfulness', 'CF', 'Deep Learning', 'CNN']",국문 초록 정보 없음,"Recently, various types of products have been launched with the rapid growth of the e-commerce market. As a result, many users face information overload problems, which is time-consuming in the purchasing decision-making process. Therefore, the importance of a personalized recommendation service that can provide customized products and services to users is emerging. For example, global companies such as Netflix, Amazon, and Google have introduced personalized recommendation services to support users purchasing decisions. Accordingly, the users information search cost can reduce which can positively affect the companys sales increase. The existing personalized recommendation service research applied Collaborative Filtering (CF) technique predicts user preference mainly use quantified information. However, the recommendation performance may have decreased if only use quantitative information. To improve the problems of such existing studies, many studies using reviews to enhance recommendation performance. However, reviews contain factors that hinder purchasing decisions, such as advertising content, false comments, meaningless or irrelevant content. When providing recommendation service uses a review that includes these factors can lead to decrease recommendation performance. Therefore, we proposed a novel recommendation methodology through CNN-based review usefulness score prediction to improve these problems. The results show that the proposed methodology has better prediction performance than the recommendation method considering all existing preference ratings. In addition, the results suggest that can enhance the performance of traditional CF when the information on review usefulness reflects in the personalized recommendation service."
CNN을 이용한 지진 재난 상황에서의 지능형 교통 시스템,2021,"['ITS : Intelligent Transportation System', 'Artificial Intelligent', 'Citizen safety', 'National safety', 'Convolution Neural Network']",지진 재난 상황에서 CNN을 이용한 효과적인 지능형 도로교통 관제 시스템 (ITS : Intelligent Transportation System) 이 새롭게 제안되었다. 제안된 기술은 YOLO detector를 활용하여 지진 재난 상황에서 빠르고 정확한 도로 위험 요소를 인식하여 차량 사고로 인한 2차 재난 피해를 최소화하는데 기여할 수 있다. 아울러 정확한 인식을 위해 본 논문에서는 수동으로 구축된 사고 이미지 데이터를 사용하여 정확하고 빠른 탐지가 가능하다. 훈련된 모델은 CCTV 영상에서 획득한 이미지를 사용하여 훈련됨으로서 CCTV를 활용한 통합 관제 시스템에서 범용적으로 적용가능한 장점이 있다.,"An effective intelligent road traffic control system (ITS) using CNN in earthquake disaster situations has been newly proposed. The proposed technology can minimize secondary disaster damage caused by vehicle accidents by recognizing fast and accurate road risk factors in earthquake disaster situations using the YOLO detector. Additionally, this paper enables accurate and rapid detection using manually constructed accident image data for precise recognition. The trained model can be universally applicable in an integrated control system using CCTV as it is trained using images obtained from CCTV images."
CNN 기반 주행 중인 차량 간 상대속도 추정 알고리즘,2021,"['mobile robot', 'deep learning', 'object detection', 'convolutional neural network', 'self-driving vehicle']",국문 초록 정보 없음,"In this paper, we proposed an estimation algorithm of the relative velocity between two driving vehicles based on CNN(Convolutional Neural Network), as the perception of the surrounding environment around an autonomous car, such as distance and speed of other vehicles, is important. The proposed algorithm estimated the velocity of a target vehicle by using a stereo camera without any other sensors. A stereo camera is a sensor that acquires simultaneously RGB images and depth maps, and it is widely used for autonomous vehicles to obtain various information. The developed CNN-based semantic segmentation model with high speed and accuracy was used to recognize the target vehicle, detecting the shape of the target object and omitting background information around it. Due to this effect, the distance between the autonomous vehicle and target vehicle is more accurately estimated. The relative speed between each vehicle was estimated using the distance and time difference between frames. The performance of the proposed algorithm was compared with conventional methods and it was confirmed that the speed of the target vehicle was more accurately estimated using only the stereo camera."
CNN기반의 온라인 수어통역 상담 시스템에 관한 연구,2021,"['OpenCV', '합성곱 신경망', '수어', '청각장애인', '영상처리', 'OpenCV(Open Source Computer Vision)', 'CNN(Convolutional Neural  Networks)', 'Sign Language', 'Hearing-Impaired Person', 'Image Processing']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN Auto-Encoder Network Using Dilated Inception for Image Steganography,2021,"['Information security', 'Image steganography', 'Dilated convolution', 'CNN', 'Auto-encoder']",국문 초록 정보 없음,"Numerous studies have used convolutional neural networks (CNNs) in the field of information concealment as well as steganalysis, achieving promising results in terms of capacity and invisibility. In this study, we propose a CNN-based steganographic model to hide a color image within another color image. The proposed model consists of two sub-networks: the hiding network is used by the sender to conceal the secret image; and the reveal network is used by the recipient to extract the secret image from the stego image. The architecture of the concealment sub-network is inspired by the U-Net auto-encoder and benefits from the advantages of the dilated convolution. The reveal sub-network is inspired by the auto-encoder architecture. To ensure the integrity of the hidden secret image, the model is trained end to end: rather than training separately, the two sub-networks are trained simultaneously a pair of networks. The loss function is elaborated in such a way that it favors the quality of the stego image over the secret image as the stego image is the one that comes under steganalysis attacks. To validate the proposed model, we carried out several tests on a range of challenging publicly available image datasets such as ImageNet, Labeled Faces in the Wild (LFW), and PASCAL-VOC12. Our results show that the proposed method can dissimulate an image into another one with the same size, reaching an embedding capacity of 24 bit per pixel without generating visual or structural artefacts on the host image. In addition, the proposed model is generic, that is, it does not depend on the image’s size or the database source."
CNN-LSTM for Smart Grid Energy Consumption Prediction,2021,"['CNN-LSTM', 'Demand Response', 'Energy', 'Prediction', 'Smart grid']",국문 초록 정보 없음,"This paper aims to forecast monthly electricity across different kinds of consumers such as Residential, Industrial, Official and Commercial sectors. To achieve this, a CNN-LSTM prediction framework for energy demand in smart grid is proposed. Efficient consumption prediction is essential for effective Demand Response (DR) which can enable consumers to minimize their energy usage through proper load curtailment, consumption shift over time, or energy generation and storage at certain times to offer flexibility in the grid."
CNN을 활용한 카오스 신호 분류 검증,2021,"['Convolutional Neural Network(합성곱 신경망)', 'Lyapunov Exponent(리아푸노브 지수)', 'Recurrence Plot(리커런스 플롯)', 'Chaos(카오스)']",국문 초록 정보 없음,"The aim of the study was to classify the chaotic time-series data with the nonlinear problem using the convolutional neural network (CNN), and to determine and verify the chaotic characteristics from a deterministic system. The classical nonlinear differential equation established by the Rossler model was used, and the chaotic characteristics were determined by the Lyapunov exponent. The chaotic properties was visualized using an unthresholded recurrence plot through the proposed procedure. A simple CNN model was developed to learn the extracted image using the proposed feature-visualization technique. As a result, the chaotic characteristics were classified with an accuracy of 99 % or more."
밀리미터파 확산 경로 채널에서 CNN 기반 도래각 및 시간지연 스펙트럼 추정,2021,[],"본 논문에서는 밀리미터파 통신 SIMO(single-input multiple-output) 확산 경로 채널에서 합성곱 신경망(convolutional neural network,CNN) 기반 도래각 및 시간지연 스펙트럼 추정 알고리즘을 제안한다. 밀리미터파 통신은 원활한 통신을 위한 신호의 도래각 및 시간지연 확산 추정이 필수적이다. 기존의 도래각 스펙트럼 추정 알고리즘은 신호의 도래각 및 시간지연의 스펙트럼를 동시에 추정하는 것이 불가능 하다. 제안하는 알고리즘은 주어진 입력에서 특성 획득에 유리한 CNN을 이용하여 다중안테나로 수신한 OFDM(orthogonal frequency division multiplexing)신호에서 도래각 및 시간지연 스펙트럼 추정이 가능하다. 시뮬레이션을 통해 도래각 및 시간지연 스펙트럼 추정을 확인하고 성능을 분석한다.",다국어 초록 정보 없음
뇌전증 발작 탐지를 위한 CNN 기반 앙상블 모델,2021,[],국문 초록 정보 없음,"In this paper, A CNN-based ensemble model for epileptic seizure detection is proposed. The proposed model improves seizure detection performance through a structure that merges the training results of AlexNet, VGG16, VGG19 models and retrains the merged data into the MLP model. In addition, the proposed model rearrange the learning results of the three models used in the merge phase into one-dimensional data, learn the merged data in the re-learning phase into an MLP model with a fully connected layer, and derive the final results through the softmax function. As a result of the CPSM experiment using the CHB-MIT Scalp EEG Database with the proposed model, the average sensitivity of 92% and the FPR of 0.36 were obtained."
비침습적 말초동맥질환 진단을 위한 CNN 기반 앙상블 모델,2021,"['말초동맥질환(Peripheral Arterial Disease)', '전송라인 모델(transmission line model)', '혈압 파형분석(Blood Pressure Waveforms Analysis)', '합성곱 신경망(Convolutional Neural Network)', '앙상블(Ensemble)']",국문 초록 정보 없음,"In order to develop affordable and non-invasive peripheral arterial disease (PAD) screening methods, machine learning-based diagnostic techniques are receiving increasing interest. A recent study of CNN-based pulse waveform analysis techniques for PAD diagnosis demonstrated promise and potential as a diagnostic tool. Accordingly, in this study, Bayesian hyperparameter optimization and ensemble techniques are applied to enhance the performance of CNN-based PAD diagnosis models. For training and evaluation of the PAD diagnosis model, the blood pressure waveform data of virtual PAD patients were generated from a validated transmission line model. The trained diagnostic model was evaluated by various evaluation metrics of the classification performance according to the severity and location of the disease."
YOLO 를 이용한 CNN 기반의 물체 인식과 파지 중심점 위치오차 최소화 알고리즘 연구 및 파지 성능 평가,2021,"['Machine Vision', 'Visual Servoing', 'Object Detection', 'Convolutional Neural Network', 'Transformation Matrix']",국문 초록 정보 없음,"In the last few years, the use of robot manipulators has attracted increasing attention in various industries. Accordingly. Researchers have proposed unique ideas for co-robot control using vision sensors. In this study, you only look once (YOLO) based on convolutional neural network (CNN), and grasping center point position error minimization algorithms were proposed to reduce object misrecognition and increase the performance for grasping an object. In addition, a gripping algorithm was designed for six degree of freedom (DOF) robot manipulators. In addition, machine vision algorithms, including a Grayscale, Gaussian filter, Canny edge, and Contouring, were implemented to detect objects features, such as centroids and orientation. Furthermore, the coordinate system of the vision sensor was converted into a coordinate system of the robot manipulator using a transformation matrix to accurately move the end effector of the robot arm to the center point of the object. The logic implemented in this study not only detected the trained object on the workstation, but also minimized the positional error of the transformation matrix. Additionally, experiments were performed on the 6-DOF robot manipulators. The results revealed that the end effector of the 6-DOF manipulators successfully moved to the center of the detected object, and each of the eight objects was normally gripped."
Al/Cu 레이저 용접에서 Multi-sensor CNN 모델을 이용한 용입깊이 예측,2021,"['Laser welding', 'Convolution neural network', 'Multi-sensor', 'Battery']","전기 자동차 베터리에 적용되는 Al/Cu 겹치기 레이저 용접에서 용접부에서 생성되는 금속 간상(inter-metallic phases)은 용접부의 강도 및 전기 전도도에 큰 영향을 미친다. 이러한 금속 간상은 용입깊에 따라 달라진다. 결국 Al/Cu 겹치기 레이저 용접에서 용입 깊이를 예측하여 용접부의 용접성을 평가할 수 있다. 본 연구에서는 고속 카메라 영상과 포토다이오드 신호를 이용하여 용입 깊이를 예측하기 위해 다중 센서 CNN(Convolution Neural Network) 모델을 사용하였다. 고속 카메라 이미지는 레이저와 동축으로 촬영되었으며, 포토다이오드는 레이저 헤드에 비동축으로 장착되어 데이터를 얻었다. CNN에서 사용되는 데이터는 용접 속도와 레이저 출력을 변수로 사용하여 총 25개의 용접조건의 데이터를 사용하였다. 모델링을 위해 각각 2115개의 이미지와 포토다이오드 데이터가 수집되었다. 그리고 모델의 학습, 검증 및 테스트에 1480, 317 및 317개의 데이터가 사용되었다. 모델은 10ms 마다 용입깊이를 예측하였으며, 테스트 결과는 95% 이상의 정확도를 보여주었다. 그리고 레이저 출력이 점차 증가하는 용접조건을 사용하여 모델을 검증한 결과, 90% 이상의 정확도를 보여주었다.",다국어 초록 정보 없음
LDCSIR: Lightweight Deep CNN-based Approach for Single Image Super-Resolution,2021,"['Image super-resolution', 'Convolutional neural network', 'PSNR', 'ResNet block']",국문 초록 정보 없음,"Single image super-resolution (SISR) is an image processing technique, and its main target is to reconstruct the high-quality or high-resolution (HR) image from the low-quality or low-resolution (LR) image. Currently, deep learning-based convolutional neural network (CNN) image super-resolution approaches achieved remarkable improvement over the previous approaches. Furthermore, earlier approaches used hand designed filter to upscale the LR image into HR image. The design architecture of such approaches is easy, but it introduces the extra unwanted pixels in the reconstructed image. To resolve these issues, we propose novel deep learning-based approach known as Lightweight deep CNN-based approach for Single Image Super-Resolution (LDCSIR). In this paper, we propose a new architecture which is inspired by ResNet with Inception blocks, which significantly drop the computational cost of the model and increase the processing time for reconstructing the HR image. Compared with the other state of the art methods, LDCSIR achieves better performance in terms of quantitively (PSNR/SSIM) and qualitatively."
LDCSIR: Lightweight Deep CNN-based Approach for Single Image Super-Resolution,2021,"['Image super-resolution', 'Convolutional neural network', 'PSNR', 'ResNet block']",국문 초록 정보 없음,"Single image super-resolution (SISR) is an image processing technique, and its main target is to reconstruct the high-quality or high-resolution (HR) image from the low-quality or low-resolution (LR) image. Currently, deep learning-based convolutional neural network (CNN) image super-resolution approaches achieved remarkable improvement over the previous approaches. Furthermore, earlier approaches used hand designed filter to upscale the LR image into HR image. The design architecture of such approaches is easy, but it introduces the extra unwanted pixels in the reconstructed image. To resolve these issues, we propose novel deep learning-based approach known as Lightweight deep CNN-based approach for Single Image Super-Resolution (LDCSIR). In this paper, we propose a new architecture which is inspired by ResNet with Inception blocks, which significantly drop the computational cost of the model and increase the processing time for reconstructing the HR image. Compared with the other state of the art methods, LDCSIR achieves better performance in terms of quantitively (PSNR/SSIM) and qualitatively."
SPR 접합 품질 분류를 위한 CNN 기반의 딥러닝에 관한 연구,2021,"['Convolution Neural Network', 'Classification', 'Self Piercing Rivet']","최근 컴퓨터와 여러 알고리즘의 발전으로 딥러닝을 기반으로 한 용접 연구가 증가하고 있다. 이러한 딥러닝 알고리즘 중 Convolution Neural Network(CNN)은 이미지 데이터를 기반으로 하여 분류 또는 회귀를 처리하는 데 주로 사용되고 있다. 본 연구에서는 CNN을 기반으로 하여 학습 알고리즘을 개발하였고, 이를 최상판에서 pre-hole을 가진 3겹 Self-Piercing Riveting(SPR) 접합에서 품질 예측을 위한 13가지의 조건 별 분류를 실시하였다. 첫 번째 알고리즘에서 SPR 장비로부터 접합 공정에서 추출된 load와 displacement 2가지 데이터를 사용하여 분류 작업을 하였다. 2번째 알고리즘에서 load, displacement 데이터에 직접 측정한 acoustic 데이터를 추가하여 총 3가지 데이터를 사용하여 분류를 한 뒤 2가지 결과를 비교하였다. 2가지 데이터를 사용한 경우에는 정확도 95.38%, 3가지 데이터를 사용한 경우는 정확도 90.0%가 나오는 것을 확인하였다.",다국어 초록 정보 없음
"시간별 가속도, 소음 데이터를 이용한 CNN기반 조향작동소음 예측모델 개발",2021,"['Electric Power Steering(전동식 조향장치)', 'Noise Prediction(소음예측)', 'Regression AI Model(회귀 인공지능 모델)', 'Spectrogram(스펙트로그램)', 'CNN Resnet(CNN Resnet모델)', 'Accerlerometer(가속도 센서)']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 소둔로 가열대의 스트립 온도 대푯값 추정 모델,2021,"['소둔', '강판', '예측 모델', 'CNN', '딥러닝']","본 논문은 소둔로 가열대의 스트립 온도 대푯값 추정 모델을 제안한다. 소둔의 물리적 특성을 고려하여 입력 데이터를 설계하고, 이를 통해 출측 온도를 정확하게 예측할 수 있는 convolution neural network를 설계한다. 설게된 모델은 실제 조업 데이터를 이용하여 학습되며, 실제 조업 데이터를 통해 모델 정확성을 보여준다.",다국어 초록 정보 없음
CNN을 활용한 새싹삼의 품질 예측 모델 개발,2021,"['합성곱신경망', '새싹삼', '품질예측', '이미지 인식', 'convolutional neural network (CNN)', 'Ginseng Sprouts', 'Quality Prediction', 'Image Recognition']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN-based Unwanted UAV Detection System,2021,"['Convolutional neural network', 'deep learning', 'unmanned aerial vehicle (UAV) detection']",국문 초록 정보 없음,"Applications using Unmanned Aerial Vehicles (UAV)s are growing rapidly because of its easy-availability and is in trend, but with this growth, people also became creative in using it for doing unlawful things. To mitigate this, a lot of UAV detection systems emerged using different technologies. This pa-per proposes a UAV detection system exploiting a Convolutional Neural Network (CNN) for detection and show its advantage compared with other Deep Learning (DL) algorithms."
CNN기반 차량 헤드라이트 불량검사 시스템,2021,[],"본 논문에서는 차량 헤드라이트의 불량 유무를 판별하기 위하여 생산된 헤드라이트의 위치를 보정한 후 검사대상의 ROI(Region of Interest)를 검출 하여 CNN(Convolutional Neural Network)을 기반으로 ROI영역의 불량 유무를 판단하는 방법을 제안한다. 실험을 목적으로 2개 차종에 대하여 헤드라이트 원본영상을 각 100장 확보 하였고, ROI영역 불량 판별을 목적으로 위치가 보정된 영상에서 이동 및 회전 변환을 적용하여 20,000개의 양품영상 및 20,000개의 불량영상을 확보하였다. 실험결과, 본 논문에서 제안한 방법의 확장 가능성을 확인할 수 있었다.",다국어 초록 정보 없음
DNN-CNN과 DRL 알고리즘을 활용한 빅데이터 웹크롤러 기반의 심층정보 예측 모형,2021,[],"본 논문은 뉴스나 SNS으로부터 웹크롤러를 통해 수집된 데이터를, GAN(Generative Adversarial Networks)과 DRL(Deep Reinforced Learning) 알고리즘에 피딩(feeding)하여 학습시키고, 이로부터 사회흐름을 분석한 객관적 정보의 심층분석 결과를 제공하는 예측 모형을 개발 및 제안한다. 예측 모형의 실용적 검증을 위해 GAN의 생성자에 LSTM, N-ODE(Neural Ordinary Differential Equation)와 DNN을 각각 탑재하고, 감별자에는 CNN을 탑재한 후 키워드 감정도 기반의 미래 예측 결과를 비교한 후 가장 높은 정확도를 도출하는 모형을 제시하는데 목표를 둔다.",다국어 초록 정보 없음
CNN을 이용한 세포영상 자동분류 알고리즘에 관한 연구,2021,"['Automatic classification', 'HeLa cell', 'CCD-986SK', 'OpenCV', 'Convolutional Neural Network', 'Deep learning']",국문 초록 정보 없음,"Recently, artificial intelligence can be used in various fields, especially for medical purposes. For example, it can help diagnose lung diseases and cancer accurately and quickly, thereby reducing the time and cost of medical treatment. In this study, image data were acquired using cultured cervical cancer cells and skin fibroblast cells. The acquired images were pre-processed using OpenCV and enabled the creation of input data optimized for training. In addition, an optimal deep learning algorithm was designed to classify cells by type using transfer learning methods. As a result, the CNN-based learning and automatic classification method proposed in this experiment showed a high accuracy of over 98% and is expected to be used for accurate diagnosis and treatment of diseases in the future."
CNN을 이용한 시대별 서양화 분류 프로그램,2021,[],"본 논문은 convolutional neural network (CNN) 알고리즘을 사용하여 전문가 대신 미술 작품의 생성 시기를 사용자에게 알려주는 것을 목적으로 하는 프로그램을 제안한다. 제안한 프로그램은 사용자에게 미술작품의 생성시기를 알려줄 수 있다. 또한 현재의 미술 작품 또는 사용자가 그린 미술 작품이 어느 시대의 작품인지 확인할 수 있게 도움을 준다. 본 논문에서는 서양화를 10가지 시대별로 분류하여 정확도를 판단하고, 현재의 미술 작품 또한 10가지 시대별 특징에 맞추어 분류한다.",다국어 초록 정보 없음
CNN을 활용한 코일 이송상태 이상 감지,2021,[],국문 초록 정보 없음,"There have been many attempts to introduce smart factory and process automation, however, current conveying monitoring systems are completely depending on visual examination and manned system which increasing the fatigue of worker. This paper proposes an abnormal detection of coil conveying system which exploits instance segmentation network of convolutional neural network(CNN) and early warning system. By doing so, we are trying to automate the operation of factories and reduce costs."
Improved CNN-based Path Planning So an Autonomous UAV Can Climb Stairs By using a LiDAR Sensor,2021,"['UAVs', 'CNN', 'Path planning', 'Stair climbing', 'LiDAR sensor']",국문 초록 정보 없음,"Unmanned aerial vehicles (UAVs) have tremendous potential in civil and public areas. These are especially beneficial in applications where human lives are threatened. Autonomous navigation in unknown environments is a challenging issue for UAVs where decision-based navigation is required. In this paper, a deep learning (DL) approach is presented that aids autonomous navigation for UAVs in completely unknown, GPS-denied indoor environments. The UAV is equipped with a monocular camera and a light detection and ranging (LiDAR) sensor to determine each next maneuver and distance calculation, respectively. For deeper feature extraction, a version of You Only Look Once (YOLOv3-tiny) is improved by adding a convolution layer with different filter sizes. The process is observed as an exercise where the DL model classifies the targeted image as stairs or not stairs. We created our dataset considering the indoor scenario for specific implementation. Comprehensive experimental results are compared with YOLOv3-tiny, indicating better performance in terms of accuracy, recall, F1-score, precision, and maneuvering movements."
CWT와 CNN을 활용한 리튬 이온 배터리의 SOH 추정 방안 연구,2021,[],"전기 자동차의 다양한 운행 조건에서 리튬 이온 배터리의 안정적인 사용을 위해서 배터리의 열화에 따른 건강상태(SOH)를 추정하는 것은 필수적이다. 리튬 이온 배터리의 열화는 다양한 조건들에 의해 성능이 저하된다. 따라서 SOH를 정확하게 추정하는 알고리즘이 필요하다. 본 논문에서는 배터리의 실험적 데이터를 이용하여 SOH 추정하는 방안을 제시한다. 배터리 전압과 온도 데이터의 특징점을 추출하기 위해 전처리 기법인 CWT(Continuous Wavelet Transform) 적용했다. 전처리된 데이터의 SOH를 추정하기 위해서 CNN(Convolutional Neural Network)에 학습기법에 적용하였고, 배터리의 온도 데이터와 전압 데이터의 SOH 추정 정확도를 비교하였다.",다국어 초록 정보 없음
1D CNN을 이용한 마이크로컨트롤러기반 제스처 인식,2021,"['인공지능', '신경망', '임베디드 시스템', '텐서플로우']",본 논문에서는 마이크로컨트롤러에서 6축 IMU 센서를 사용한 제스쳐를 인식하기 위한 최적화된 학습 방법을 제안한다. 6축 센서값을 119번 샘플링할 경우 특징 차원이 매우 크기 때문에 다층 신경망을 이용할 경우 학습 파라미터가 마이크로컨트롤러의 메모리 허용량을 초과하게 된다. 본 논문은 성능은 유지하며 학습 파라미터 개수를 효과적으로 줄이기 위한 마이크로컨트롤러에 최적화된 1D CNN을 제안한다.,다국어 초록 정보 없음
3D CNN을 활용한 CAD 모델의 기계가공 특징 형상 인식,2021,"['Machining Feature', 'Recognition', 'Machine Learning', '3D CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
영상 처리와 CNN을 이용한 애완동물 영상 세부 분류 비교,2021,"['fine grained classification', 'object recognition', 'image processing', 'Convolutional Neural Network']",국문 초록 정보 없음,"The study of the fine grained classification of images continues to develop, but the study of object recognition for animals with polymorphic properties is proceeding slowly. Using only pet images corresponding to dogs and cats, this paper aims to compare methods using image processing and methods using deep learning among methods of classifying species of animals, which are fine grained classifications. In this paper, Grab-cut algorithm is used for object segmentation by method using image processing, and method using Fisher Vector for image encoding is proposed. Other methods used deep learning, which has achieved good results in various fields through machine learning, and among them, Convolutional Neural Network (CNN), which showed outstanding performance in image recognition, and Tensorflow, an open-source-based deep learning framework provided by Google. For each method proposed, 37 kinds of pet images, a total of 7,390 pages, were tested to verify and compare their effects."
A Fusion of CNN-based Frame Vector for Segment-level Video Partial Copy Detection,2021,"['비디오', '비디오 복사 검출', '비디오 부분 복사', '특징 융합', 'CNN', '딥러닝', 'video analysis', 'copy detection', 'partial-copy detection', 'feature fusion', 'deep learning']",국문 초록 정보 없음,다국어 초록 정보 없음
스마트시티 시범구역 주차점유현황 예측을 위한 CNN기반 알고리즘 기초 연구,2021,[],"스마트시티 시범구역에서는 운전자의 편의를 위해 실시간으로 주차여유공간 및 위치정보 제공시스템을 개발하는 것이 하나의 주요과제다. 이에 따라 본 연구에서는 시범구역 CCTV에서 취득된 일부 교통정보로부터 인근 주차공간의 점유현황을 예측하는 알고리즘을 제안하고자 한다. 모든 구역의 주차정보를 기 설치된 CCTV로 관측하기는 불가하고, 실데이터 부족으로 인해 소수의 라벨링된 데이터를 기반으로 재현데이터를 생성하여 가상학습데이터를 구축하였다. 예측모델은 CNN 구조로 설계되어 지도학습되었으며, 성능평가를 통해 한정된 라벨데이터로부터 주차점유현황예측 가능성을 재단한다.",다국어 초록 정보 없음
심전도와 광체적 신호로부터 혈압 추정을 위한 CNN-LSTM 네트워크 기반 멀티태스킹 알고리즘,2021,[],본 논문은 비침습적/ 연속적으로 혈압을 추정하기 위해 심전도와 광체적 변화 신호의 차이 신호를 사용한 CNN-LSTM 네워크 기반 멀티 태스킹 알고리즘을 제안하였다. 제안된 모델을 통한 수축기 혈압과 확장기 혈압의 예측 오차는 각각 0.017±1.624 mmHg와 0.164±1.297mmHg으로 혈압계 인증 기준인 BHS와 AAMI기준의 A등급을 만족하는 정확도를 내었다.,다국어 초록 정보 없음
Review on the Recent Welding Research with Application of CNN-Based Deep Learning Part II: Model Evaluation and Visualizations,2021,"['Deep learning', 'Convolution Neural Network', 'Image', 'Welding', 'Evaluation', 'Visualization']",국문 초록 정보 없음,"With the development of deep learning technology, research on classification and regression models on welding phenomena using convolution neural networks (CNNs) are gradually increasing. Part 1 of this study introduced the characteristics of deep learning models using CNNs and their application to welding studies. In this paper, we reviewed recent welding research papers to analyze how to evaluate CNN models and visualize the modeling output, and details of evaluation index, comparison models, and visiualization methods were explained."
Five-Class Classification of Cervical Pap Smear Images: A Study of CNN-Error-Correcting SVM Models,2021,"['Cervix Uteri', 'Diagnosis', 'Nerve Net', 'Papanicolaou Test', 'Support Vector Network']",국문 초록 정보 없음,"Objectives: Different complex strategies of fusing handcrafted descriptors and features from convolutional neural network(CNN) models have been studied, mainly for two-class Papanicolaou (Pap) smear image classification. This paper explores asimplified system using combined binary coding for a five-class version of this problem. Methods: This system extracted featuresfrom transfer learning of AlexNet, VGG19, and ResNet50 networks before reducing this problem into multiple binarysub-problems using error-correcting coding. The learners were trained using the support vector machine (SVM) method. The outputs of these classifiers were combined and compared to the true class codes for the final prediction. Results: Despitethe superior performance of VGG19-SVM, with mean ± standard deviation accuracy and sensitivity of 80.68% ± 2.00% and80.86% ± 0.45%, respectively, this model required a long training time. There were also false-negative cases using both theVGGNet-SVM and ResNet-SVM models. AlexNet-SVM was more efficient in terms of running speed and prediction consistency. Our findings also showed good diagnostic ability, with an area under the curve of approximately 0.95. Further investigationalso showed good agreement between our research outcomes and that of the state-of-the-art methods, with specificityranging from 93% to 100%. Conclusions: We believe that the AlexNet-SVM model can be conveniently applied for clinicaluse. Further research could include the implementation of an optimization algorithm for hyperparameter tuning, as well asan appropriate selection of experimental design to improve the efficiency of Pap smear image classification."
CNN을 이용한 고속 메모리 파형 분류,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 활용한 불꽃 및 연기 감지를 위한 영상분석 알고리즘에 관한 연구,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN에서 비슷한 깊이의 레이어를 묶는 그룹 필터 프루닝 기법,2021,[],국문 초록 정보 없음,"Filter pruning is considered one of the most effective methods. It is divided into local filter pruning and global filter pruning, and both methods have drawbacks. In this letter, we address the shortcomings of the two methods, by proposing a method of grouping some layers and then pruning them in groups. We conduct extensive experiments with VGG16 and ResNets on CIFAR-10, CIFAR-100, CUB-200-2011 and MIT-indoor datasets to validate the effectiveness of our filter pruning method. For CIFAR-100, our method decreases FLOPs by more than 52% on ResNet-110 with a 0.03% accuracy increase, which outperforms state-of- the art filter pruning methods."
CNN기반 욕창 유발 위험 부위 감지 시스템,2021,"['bedsores nursing', 'artificial intelligence', 'Detecting the risk of causing', 'COVID-19']",매년 고령화 사회로 인해 욕창환자가 증가하고 있으며 COVID-19의 팬데믹 상황으로 간호인의 업무 부하로 욕창 관리의 중요성이 대두되고 있다. 욕창은 부동자세로 인해 궤양이 생기는 질병으로 간호인이 주기적으로 체위변경을 해줘야 하기에 간호 부담이 큰 질병이다. 이에 본 연구에서는 인공지능이 욕창 유발 위험을 검출하고 호발 현황을 실시간 모니터링 해줌으로써 간호인의 업무 부담을 줄일 수 있는 시스템을 제시한다. 본 시스템을 통하여 간호인의 욕창 간호의 어려움을 해소시켜 간호 업무의 증대할수 있을 것이다.,"The number of bedsores patients is increasing every year due to the aging society, and the importance of bedsores management is emerging as a burden on nurses due to the pandemic situation of COVID-19. Curses are a disease that causes ulcers due to floating posture, and it is a disease that is burdensome for nurses to periodically change their body position. Therefore, this study proposes a system that can reduce the burden on nurses by detecting the risk of inducing bedsores and monitoring the status of calls in real time. Through this system, it will be possible to increase nursing work by solving the difficulties of nursing in the bedsores of nurses."
CNN의 추론 정확도 향상을 위한 하드웨어 구조 연구,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN의 유사 채널 가지치기 알고리즘,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 활용한 용융흔 판별 기법,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN-LSTM 모델 기반 RSE검지기 교통량 데이터 보정연구,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 활용한 유도전동기 성능 예측,2021,"['Artificial intelligence', 'Deep learning', 'Convolution neural network', 'Induction motor']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN의 점진 학습을 위한 가중치 변조 연구,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 활용한 미세구조 특성에 따른 시멘트 기반 재료 응답 평가,2021,"['기계학습', '미세구조 특성', '재료응답', '마이크로-CT']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN과 모바일 센서 데이터 기반의 Interlocking 오각형 그리기 검사 이미지 자동 스코어링,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 이미지 데이터기반의 충격파 구조 예측에 대한 연구,2021,"['Supersonic Flow(초음속 유동)', 'Shock Wave-Boundary Layer Interaction(충격파 경계층 간섭)', 'Machine Learning(기계학습)', 'Convolution Neural Network(합성곱 신경망)', 'Shock Wave Structure Prediction(충격파 구조 예측)']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN-RNN 기반의 DNN을 활용한 DP 선박의 전력부하 예측,2021,"['심층 신경망(Deep Neural Network)', 'DP 선박(Dynamic Positioning Ship)', '전력부하 예측(Electric Power Load Forecasting)']",국문 초록 정보 없음,다국어 초록 정보 없음
Optimal CNN-based Bearing Fault Monitoring for Embedded System,2021,"['Vibration signal', 'time-frequency representation', 'noise cancellation', 'convolution neural network']",국문 초록 정보 없음,"Tracking bearing health status prevents motor from being broken down, thus saving money and maintenance efforts. However, vibration signals of bearing often contain noises due to the vibration of other components and the position of sensors. Although bearing fault diagnosis has achieved significant results due to the improvement of signal analysis techniques and Machine learning (ML) algorithms, it remains challenging tasks in the embedded system as these methods require huge memory and computational resources. This paper proposes a novel approach that can efficiently deploy on embedded computers. First, signals are noise-cancelling by Discrete Wavelet transform (WT) before converting these noise-free signals from 1-D representation to 2-D representation using Short-time Fourier Transform (STFT). Finally, we reduce the conventional Lenet5 model complexity by using the Depthwise Separable Convolution technique. According to our experiment results, our approach achieves classification result"
3D CNN을 활용한 기계가공 특징 형상의 장면 분할,2021,"['Machining feature', 'segmentation', 'deep learning', 'voxel']",국문 초록 정보 없음,다국어 초록 정보 없음
1-D CNN을 활용한 ECG 데이터 분류 기법,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
LSTM 및 CNN-LSTM 신경망을 활용한 도시부 간선도로 속도 예측,2021,"['교통속도 예측', '교통류 분석', '유고 영향권', '인공신경망', '연속류 도로', 'Traffic prediction', 'Traffic analysis', 'Traffic incident impact area', 'Artificial neural network', 'Uninterrupted flow']",국문 초록 정보 없음,다국어 초록 정보 없음
전기화재 원인 분석을 위한 CNN기반 용융흔 및 단락흔 판별,2021,[],"합성곱 신경망 기법을 활용하여 1,2차 단락흔 및 3차 용융흔을 각각 판별하는 알고리즘을 제안하고 검증하였다. 학습을 위한 데이터는 Hiv 전선의 1,2차 단락흔 및 3차 용융흔 시료를 Nikon SMZ25 현미경으로 촬영하고 학습 데이터와 검증 데이터로 확보하였다. 텐서플로어를 활용하여 입력 이미지는 64×64(pixel)에 RGB 컬러로 구성하였다. 3개의 합성곱 Layer와 3개의 풀링 Layer을 활용하여 다운 샘플링 하였다. 과적합 문제를 줄이고자 30%의 가중값 탈락률을 갖는 드롭아웃을 추가하였고, 최종 Layer의 활성화 함수는 Softmax를 사용하였다. 최종 분석 결과 95.5%의 판별 정확도를 얻었다.",다국어 초록 정보 없음
계절적 특성을 고려한 CNN-LSTM 알고리즘 기반의 건물 단기 전력부하 예측,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
스마트시티 시범구역 주차점유현황 예측을 위한 CNN기반 알고리즘 기초 연구,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
차량 센서 데이터를 이용한 Recurrence Plot과 CNN을 통한 운전자 구분 기법,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
조산 예측을 위한 신호 전처리 및 CNN-LSTM 모델 설계,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
단락흔 및 용융흔 판별을 위한 CNN과 Resnet 알고리즘 비교 분석,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
Partial discharge detection of insulated conductors based on CNN-LSTM of attention mechanisms,2021,"['Partial discharge', 'Convolutional neural network', 'Long short-term memory', 'Attention mechanism', 'Fast Fourier transform']",국문 초록 정보 없음,"Under the condition of a strong electric field, partial discharge often occurs when insulated wire is damaged. The recognition of partial discharge is an effective method for the fast and accurate detection of high voltage insulated wire faults. This paper proposes a PD recognition algorithm based on a convolutional neural network and long short-term memory (LSTM). In addition, attention mechanisms are introduced to give separate weights to LSTM hidden states through a mapping, weighting, and learning parameter matrix. This is done to reduce the loss of historical information and to strengthen the influence of important information. The complex relationship between the voltage signal change and the grid operation state response has been established. The proposed method is verified by the ENET data set published by VSB University. The recognition accuracy is 95.16% for no-PD and 94.44% for PD. Results from the proposed algorithm show that this method has a higher detection accuracy."
심층 CNN 기반 구조를 이용한 토마토 작물 병해충 분류 모델,2021,"['Convolutional Neural Networks', 'Deep Learning', 'Transfer Learning', 'Fine Tuning', 'Plant Diseases Classification']","토마토 작물은 병해충의 영향을 많이 받기 때문에 이를 예방하지 않으면 농업 경제에 막대한 손실을 초래할 수 있다. 따라서 토마토의 다양한 병해충의 진단을 빠르고 정확하게 진단하는 시스템이 요구된다. 본 논문에서는 ImageNet 데이터 셋 상에서 다양하게 사전 학습된 딥러닝 기반 CNN 모델을 적용하여 토마토의 9가지 병해충 및 정상인 경우의 클래스를 분류하는 시스템을 제안한다. PlantVillage 데이터 셋으로부터 발췌한 토마토 잎의 이미지 셋을 3가지 딥러닝 기반 CNN 구조를 갖는 ResNet, Xception, DenseNet의 입력으로 사용한다. 기본 CNN 모델 위에 톱-레벨 분류기를 추가하여 제안 모델을 구성하였으며, 훈련 데이터 셋에 대해 5-fold 교차검증 기법을 적용하여 학습시켰다. 3가지 제안 모델의 학습은 모두 기본 CNN 모델의 계층을 동결하여 학습시키는 전이 학습과 동결을 해제한 후 학습률을 매우 작은 수로 설정하여 학습시키는 미세 조정 학습 두 단계로 진행하였다. 모델 최적화 알고리즘으로는 SGD, RMSprop, Adam을 적용하였다. 실험 결과는 RMSprop 알고리즘이 적용된 DenseNet CNN 모델이 98.63%의 정확도로 가장 우수한 결과를 보였다.","Tomato crops are highly affected by tomato diseases, and if not prevented, a disease can cause severe losses for the agricultural economy. Therefore, there is a need for a system that quickly and accurately diagnoses various tomato diseases. In this paper, we propose a system that classifies nine diseases as well as healthy tomato plants by applying various pretrained deep learning-based CNN models trained on an ImageNet dataset. The tomato leaf image dataset obtained from PlantVillage is provided as input to ResNet, Xception, and DenseNet, which have deep learning-based CNN architectures. The proposed models were constructed by adding a top-level classifier to the basic CNN model, and they were trained by applying a 5-fold cross-validation strategy. All three of the proposed models were trained in two stages: transfer learning (which freezes the layers of the basic CNN model and then trains only the top-level classifiers), and fine-tuned learning (which sets the learning rate to a very small number and trains after unfreezing basic CNN layers). SGD, RMSprop, and Adam were applied as optimization algorithms. The experimental results show that the DenseNet CNN model to which the RMSprop algorithm was applied output the best results, with 98.63% accuracy."
"다양한 CNN 가속기에서 아키텍처에 따른 면적, 에너지, 성능 분석",2021,"['CNN 가속기', '아키텍처', '메모리 대역폭', '뉴럴 네트워크', 'CNN accelerators', 'architecture', 'memory bandwidth', 'neural networks']","Convolution Neural Network 가속기는 AI시대에 중요한 요소 중 하나로 떠오르게 되었다. CNN 가속기의 내부 구성을 몇 가지로 나눈다면 연산을 위한 Multiplier-Accumulator (MAC unit), 데이터 저장을 위한 SRAM, 데이터 이동을 위한 메모리 인터페이스 그리고 제어 로직으로 구분할 수 있다. 다양한 CNN 가속기들의 경우, 각기 다른 공정과 동작 주파수를 기준으로 제안되었으며, 또한 아키텍처 형태에 따라 내부 MAC unit의 수와 SRAM의 크기가 매우 큰 차이를 갖는 형태로 구성되어있다. 각 가속기들의 기본 사양으로 면적, 에너지, 성능을 비교하였을 때는 공정이나 동작 주파수 등 여러 조건들에 의해서 아키텍처에 따른 정량적인 비교가 용이하지 않게 된다. 따라서, 본 논문에서는 다양한 CNN 가속기에서 여러 조건들을 동일하게 재구성하였을 때, ResNet-50 추론 동작 시에 요구되는 면적, 에너지, 성능을 비교하여 아키텍처의 특징과 경향성을 분석하였다.","The Convolution Neural Network accelerator has emerged as an important element in the AI era. The primary components of a CNN accelerator include the Multiplier-Accumulator (MAC unit) for calculation, SRAM for data storage, memory interface for data movement, and control logic. Different CNN accelerators have been designed based on different assumptions regarding the process technologies and operating frequencies. In addition, the number of internal MAC units and the size of SRAM vary substantially between different types of architectures. These factors make it difficult to design a fair comparison of the area, energy, and performance of different CNN accelerators. In this paper, we attempt to compare the area, energy, and performance of different CNN accelerator architectures by constructing them all with the same fabrication process and operating frequency while making inferences using the ResNet-50 network."
ANN 모델링 및 CNN 기반 예측모델을 이용한 탄소섬유강화 단방향 복합재료의 가로방향 기계적 거동 예측 성능 비교,2021,"['Unidirectional composites (단방향 복합재료)', 'Representative volume element (대표 체적 요소)', 'Random sequential expansion (무작위 순차 확장)', 'Artificial neural network (인공 신경망)', 'Convolutional neural network (합성곱 신경망)']","본 연구에서는 단 방향 (UD) 합성물 (E-glass / MY750)의 가로 탄성 계수를 예측하기 위하여 섬유 위치 및 체적비를 사용한 인공 신경망 (ANN) 모델링 및 이미지 처리 기법을 사용한 합성곱 신경망 (CNN) 모델링의 접근 방식을 제안하고 성능을 비교하였다. 이 예측을 위해 RSE 알고리즘<sup>(1,2)</sup>에 의해 40 %, 50 % 및 60 %의 각 섬유 체적비에 대해 300 개의 RVE 샘플이 생성되었으며, 전산 균질화 기법에 의해 E2, G12 및 G23의 세 가지 가로 탄성 계수를 얻었다. 첫번째로, ANN 모델링의 경우 입력 데이터 (섬유 체적비 및 위치) 및 전산 균질화 기법 (CHS)에 의해 계산된 출력 데이터 (등가 탄성 계수)로 구성된 훈련 데이터 세트를 사용하여 역 전파 알고리즘에 의해 적절한 가중치와 편향을 갖도록 ANN 모델을 훈련하였다. 두 번째로, 각 섬유 체적비에 대해 300 개의 RVE를 사용하여 미세 구조 이미지를 기반으로 등가 탄성 계수를 예측하는 CNN 모델링 방법을 개발하였다. 제안된 ANN 및 CNN 모델의 성능을 비교하기 위해 CHS에서 가로 탄성 계수를 알고 있는 다양한 테스트 데이터 세트의 가로 탄성 계수 예측을 수행하였다. 예측 정확도는 평균 제곱 오차 (MSE), 상관 계수 (R) 및 상대 오차 측면에서 검증하였다. 예측 결과는 테스트 데이터 세트와 우수한 일치를 보였으며 임의의 미세 구조를 갖는 가로 탄성 계수를 신속하게 예측하였다. 이를 통해 제안된 ANN 모델은 CNN 모델에 비해 상당히 단순하고 강력하고 복합 재료의 미세 구조와 기계적 물성 간의 상관 관계를 효율적으로 제공할 수 있음을 확인했습니다.","To predict the transverse elastic modulus of unidirectional (UD) composites (E-glass / MY750) in this study, we proposed an approach of artificial neural network (ANN) modeling using fiber position and volume ratio, and compare its performance with conventional convolutional neural network (CNN) modeling using image processing technique. For this prediction, 300 RVE samples for each volume ratio of 40%, 50%, and 60% were generated by the random sequential expansion (RSE) algorithm<sup>(1,2)</sup>, and they were analyzed by computational homogenization scheme (CHS) to evaluate the three transverse elastic moduli: E2, G12, and G23. First, a training dataset consisting of input data (the fiber volume ratio and locations) and output data (the effective elastic modulus) was used to develop the ANN model to have proper weight and bias by the backpropagation algorithm. Second, a CNN modeling method that predicts the equivalent elastic modulus based on microstructure images using 300 RVEs for each fiber volume ratio was developed. To compare the performance of the proposed ANN and CNN model, prediction of the transverse elastic modulus of various test datasets whose transverse elastic moduli are known by CHS was conducted. The prediction accuracy was verified in terms of the mean squared error (MSE), correlation coefficient (R), and relative error. The prediction results showed excellent agreement with the test dataset and quickly predicted the transverse elastic modulus having random microstructures. Through this, it was confirmed that the proposed ANN model can efficiently provide an reliable correlation between the microstructure and the effective mechanical properties of composite materials with complex structures not to mention that it is quite simple and powerful compared to the CNN model."
웹 크롤링을 통한 해양쓰레기 이미지 데이터세트 구축 및 Faster R-CNN 모델을 이용한 해양쓰레기 검출,2021,"['web crawling', 'object detection', 'Faster R-CNN', 'MobileNet', 'ResNet']",본 논문에서는 웹 크롤링을 통해 해양쓰레기 이미지 데이터셋을 구축한다. 또한 이를 이용해 Faster R-CNN 모델을 훈련시켜 이미지에서 해양쓰레기를 감지하는 능력을 평가한다. 이를 위해 웹 크롤링을 통해 바다에서 자주 발견되는 쓰레기 이미지를 Google에서 수집하고 레이블을 지정하여 훈련 데이터세트를 구축한다. 그리고 Faster R-CNN의 backbone 네트워크를 각각 MobileNet과 ResNet으로 구성한다. 마지막으로 구축한 데이터세트으로부터 두 개의 Faster R-CNN 모델을 학습하여 각 모델의 해양쓰레기의 탐지 성능을 평가한다.,"In this paper, a marine debris image dataset is constructed through web crawling. Also, the Faster R-CNN model is trained to detect marine debris in the image. To this end, images of garbage frequently found in the ocean are collected from Google through web crawling. We also label them to build a marine debris image dataset. And then, two Faster R-CNN models are constructed whose backbone network is chosen as MobileNet and ResNet, respectively. Finally, we evaluate the detection performance of marine debris by training the Faster R-CNN model using dataset."
저계수 행렬 근사 및 CP 분해 기법을 이용한 CNN 압축,2021,"['CNN', 'Neural Network Compression', 'Low-Rank Approximation', 'Canonical polyadic decomposition']",국문 초록 정보 없음,"In recent years, Convolutional Neural Networks (CNNs) have achieved outstanding performance in the fields of computer vision such as image classification, object detection, visual quality enhancement, etc. However, as huge amount of computation and memory are required in CNN models, there is a limitation in the application of CNN to low-power environments such as mobile or IoT devices. Therefore, the need for neural network compression to reduce the model size while keeping the task performance as much as possible has been emerging. In this paper, we propose a method to compress CNN models by combining matrix decomposition methods of LR (Low-Rank) approximation and CP (Canonical Polyadic) decomposition. Unlike conventional methods that apply one matrix decomposition method to CNN models, we selectively apply two decomposition methods depending on the layer types of CNN to enhance the compression performance. To evaluate the performance of the proposed method, we use the models for image classification such as VGG-16, RestNet50 and MobileNetV2 models. The experimental results show that the proposed method gives improved classification performance at the same range of 1.5 to 12.1 times compression ratio than the existing method that applies only the LR approximation."
Effect of Input Data Video Interval and Input Data Image Similarity on Learning Accuracy in 3D-CNN,2021,"['3D-CNN', 'Gesture recognition', 'RNN', '2D-Cross correlation']",국문 초록 정보 없음,"3D-CNN is one of the deep learning techniques for learning time series data. However, these three-dimensional learning can generate many parameters, requiring high performance or having a significant impact on learning speed. We will use these 3D-CNNs to learn hand gesture and find the parameters that showed the highest accuracy, and then analyze how the accuracy of 3D-CNN varies through input data changes without any structural changes in 3D-CNN. First, choose the interval of the input data. This adjusts the ratio of the stop interval to the gesture interval. Secondly, the corresponding interframe mean value is obtained by measuring and normalizing the similarity of images through interclass 2D cross correlation analysis. This experiment demonstrates that changes in input data affect learning accuracy without structural changes in 3D-CNN. In this paper, we proposed two methods for changing input data. Experimental results show that input data can affect the accuracy of the model."
패션 요소 검출을 위한 Mask R-CNN 딥러닝,2021,"['인공지능', '패션', 'R-CNN', 'Fast R-CNN', 'Faster R-CNN', 'Mask R-CNN', 'Artificial Intelligence', 'Fashion']",국문 초록 정보 없음,"In this paper, in order to prepare a framework that can provide personalized artificial intelligence fashion coordination services, fashion elements were detected using the Mask R-CNN deep learning algorithm targeting the fashion image data set provided in the iMaterialist Fashion Attribute Dataset. As a result of performing deep learning to detect fashion elements with a total of 8 epochs, the loss of training data was found to be Lcls 0.53, Lbox 0.38, and Lmask 0.35. And the loss of Validation data was Lcls 0.54, Lbox 0.33, Lmask 0.36. Effective personal artificial intelligence fashion when fine-tuning using the deep learning method implemented in this paper after adding various conditions such as color, season, material, trend, and brand name based on the fashion image data set owned by an individual It is expected that it will be a coordination service."
지루성 두피염 진단을 위한 Faster R-CNN과 Atrous 컨볼루션 기반의 두피 각질 검출 기법,2021,"['지루성 두피염', '두피 관리', 'Atrous 컨볼루션', '객체 검출', 'seborrheic scalpitis', 'hair care', 'faster R-CNN', 'atrous convolution', 'object detection']","지루성 두피염은 과도한 스트레스나 화학제품의 남용, 불균형한 영양 섭취 등 다양한 요인으로 인해 발생하는 질병이다. 두피염의 대표적인 증상은 두피의 각질과 통증이며, 증상이 심해지면 탈모가 발생할 수 있다. 이에 각질 검출을 통해 두피염을 초기에 진단할 수 있는 스마트폰 기반의 애플리케이션이 다수 개발되었다. 하지만, 대부분은 수치로 된 분석 결과만을 제공할 뿐, 그 수치에 관한 근거를 확인하기 어렵다. 따라서, 본 논문에서는 지루성 두피염 진단을 위한 근거를 시각적으로 보여주기 위해 두피 영상에서 각질의 유무와 위치를 추출하는 기법을 제안한다. 이를 위해, 각질 검출에 Faster R-CNN (Faster Regions with Convolutional Neural Network) 모델을 사용하였으며, 모델의 성능을 더욱 향상하기 위해 Atrous 컨볼루션 연산을 적용하였다. 기존 컨볼루션과 Atrous 컨볼루션을 적용한 Faster R-CNN의 비교를 통해 우리가 제안하는 기법이 효과적으로 두피 각질을 검출할 수 있음을 보인다.","Seborrheic scalpitis can be caused by various factors, such as excessive stress, abuse of chemicals, and unbalanced nutrition. Typical symptoms of this disease entity are keratin and pain over the scalp, and when the symptoms become severe, hair loss may occur. Although various smartphone applications have been developed for early detection of scalpitis, it is difficult to ascertain the rationale for the results because they only provide numerical analysis. Therefore, in this paper, we propose a method for detection of keratin from scalp images to visualize the basis for diagnosing seborrheic scalpitis. In particular, we use the Faster Regions with Convolutional Neural Network (Faster R-CNN) model for keratin detection and apply atrous convolution to further improve the detection performance. By comparing our proposed method to the original Faster R-CNN method, we show that our method can effectively diagnose the symptoms of seborrheic scalpitis."
Automated Detection of Age-Related Macular Degeneration from OCT Images Using Multipath CNN,2021,"['Age-related macular degeneration', 'Multipath CNN', 'Sigmoid', 'Macular region']",국문 초록 정보 없음,"Age-related macular degeneration (AMD) is an eye disorder that can have harmful effects on older people. AMD affects the macula, which is the core portion of the retina. Hence, early diagnosis is necessary to prevent vision loss in the elderly. To this end, this paper proposes a novel multipath convolutional neural network (CNN) architecture for the accurate diagnosis of AMD. The architecture proposed is a multipath CNN with five convolutional layers used to classify AMD or normal images. The multipath convolution layer enables many global structures to be generated with a large filter kernel. In this proposed network, the sigmoid function is used as the classifier. The proposed CNN network is trained on the Mendeley dataset and evaluated on four datasets-the Mendeley, OCTID, Duke, and SD-OCT Noor datasets- and it achieved accuracies of 99.60%, 99.61%, 96.67%, and 93.87%, respectively. Although the proposed model is only trained on the Mendeley dataset, it achieves good detection accuracy when evaluated with other datasets. This indicates that the proposed model has the capacity to detect AMD. These results demonstrate the efficiency of the proposed algorithm in detecting AMD compared to other approaches. The proposed CNN can be applied in real-time due to its reduced complexity and learnable parameters."
CNN 보조 손실을 이용한 차원 기반 감성 분석,2021,"['온라인 리뷰 분석', '차원 기반 감성 분석', 'Online review analysis', 'ABSA', 'TASD', 'CNN', 'BERT']",국문 초록 정보 없음,"Aspect Based Sentiment Analysis (ABSA), which analyzes sentiment based on aspects that appear in the text, is drawing attention because it can be used in various business industries. ABSA is a study that analyzes sentiment by aspects for multiple aspects that a text has. It is being studied in various forms depending on the purpose, such as analyzing all targets or just aspects and sentiments. Here, the aspect refers to the property of a target, and the target refers to the text that causes the sentiment. For example, for restaurant reviews, you could set the aspect into food taste, food price, quality of service, mood of the restaurant, etc. Also, if there is a review that says, The pasta was delicious, but the salad was not, the words steak and salad, which are directly mentioned in the sentence, become the “target.”  So far, in ABSA, most studies have analyzed sentiment only based on aspects or targets. However, even with the same aspects or targets, sentiment analysis may be inaccurate. Instances would be when aspects or sentiment are divided or when sentiment exists without a target. For example, sentences like, Pizza and the salad were good, but the steak was disappointing. Although the aspect of this sentence is limited to “food,” conflicting sentiments coexist. In addition, in the case of sentences such as Shrimp was delicious, but the price was extravagant, although the target here is “shrimp,” there are opposite sentiments coexisting that are dependent on the aspect. Finally, in sentences like The food arrived too late and is cold now. there is no target (NULL), but it transmits a negative sentiment toward the aspect service. Like this, failure to consider both aspects and targets – when sentiment or aspect is divided or when sentiment exists without a target – creates a dual dependency problem.  To address this problem, this research analyzes sentiment by considering both aspects and targets (Target-Aspect-Sentiment Detection, hereby TASD). This study detected the limitations of existing research in the field of TASD: local contexts are not fully captured, and the number of epochs and batch size dramatically lowers the F1-score. The current model excels in spotting overall context and relations between each word. However, it struggles with phrases in the local context and is relatively slow when learning. Therefore, this study tries to improve the models performance.  To achieve the objective of this research, we additionally used auxiliary loss in aspect-sentiment classification by constructing CNN(Convolutional Neural Network) layers parallel to existing models. If existing models have analyzed aspect-sentiment through BERT encoding, Pooler, and Linear layers, this research added CNN layer-adaptive average pooling to existing models, and learning was progressed by adding additional loss values for aspect-sentiment to existing loss. In other words, when learning, the auxiliary loss, computed through CNN layers, allowed the local context to be captured more fitted. After learning, the model is designed to do aspect-sentiment analysis through the existing method.  To evaluate the performance of this model, two datasets, SemEval-2015 task 12 and SemEval-2016 task 5, were used and the f1-score increased compared to the existing models. When the batch was 8 and epoch was 5, the difference was largest between the F1-score of existing models and this study with 29 and 45, respectively. Even when batch and epoch were adjusted, the F1-scores were higher than the existing models. It can be said that even when the batch and epoch numbers were small, they can be learned effectively compared to the existing models. Therefore, it can be useful in situations where resources are limited.  Through this study, aspect-based sentiments can be more accurately analyzed. Through various uses in business, such as development or establishing marketing strategies, both consumers and sellers will be able to"
손동작 기반의 인증 방식에 활용하기 CNN 위한 모델 학습,2021,"['cnn', 'hand gesture-detection', 'authentication', 'data processing', 'normalization']","스마트 기기의 사용자 인증 방식은 비밀번호를 직접 입력하는 것부터 시작하여 지문인식, 홍채인식, 얼굴인식 등 그 방식이 점점 다양해졌고 고도화되었으며 신뢰도가 높아졌다. 그러나 코로나 시대에 진입한 이후부터 현재까지 얼굴인식 기반의 기기 인증 방법은 마스크로 인해 얼굴이 인식되지 않아 비밀번호 또는 패턴을 직접 입력해야만 잠금이 풀리는 불편함을 감수해야 한다. 이러한 문제점들에 착안하여 어떤 상황에서든 사용자 인증이 가능한 방식에 대하여 고민하였고, 이에 따라 본 논문에서는 사용자 인증 방식에 활용 가능한, ‘특정 손동작’을 인식하도록 CNN 모델을 학습시키는 방법에 대해 제안한다.","The user authentication method of a smart device started with the direct input of a password, and the methods such as fingerprint recognition, iris recognition, and face recognition have been diversified, advanced, and reliability increased. However, from the time we entered the Corona era to the present, the face recognition-based device authentication method has to suffer the inconvenience of unlocking the device only by entering a password or pattern directly because the face is not recognized due to the mask. With these problems in mind, I considered a method that allows user authentication in any situation, and this paper proposes a method for training a CNN model to recognize ‘Specific Hand Gestures’ that can be used in user authentication methods."
LSTM과 CNN 기반의 공기압축기 이상감지,2021,"['공기압축기(air compressor)', '이상감지(anormaly detection)', 'LSTM(long short-term memory)', 'CNN(convolutional neural network)']",국문 초록 정보 없음,"Deep learning algorithms such as LSTM and CNN that can classify timeseries data can be applied to an air compressor to detect anomalies. In the encoder-decoder structure, the encoder compresses the original data and the decoder reconstructs the characteristic of the original data from the compressed data. In this paper, actual raw data from the sensors attached in a screw air compressor of a railway vehicle is preprocessed by using a moving window and normalization, and then LSTM encoder-decoder and CNN encoder-LSTM decoder logics are examined for detecting anomalies exising in the sensor data. The CNN encoder-LSTM decoder logic showed slightly better performance than the LSTM encoder-decoder logic. The validity of the logics is demonstrated by using Python codes."
Analysis of the influence of 3D-CNN on spatial random information in hyperspectral image classification,2021,"['Hyperspectral imgae', '3D-CNN', 'Deeplearning', 'Random spatial information']",국문 초록 정보 없음,"In the hyperspectral image, the type of material can be known by using the spectral information. Recently, hyperspectral image classification using deep learning has been developed. Among them, 3D-CNN, which learns spatial information and spectral information together, has excellent performance. However, since 3D-CNN learns spatial information and spectral information together, there is a possibility that the spectral information is diluted. This does not correspond to the hyperspectral image in which the spectral information is significant. This paper suggests that 3D-CNN is not doing the right thing to learn about spectral information in hyperspectral image classification. In addition, hyperspectral data with random spatial information is verified through experiments."
An Automatic Cardiac Arrhythmia Classification System Based on ECG Signal Processing using 1-D Convolutional Neural Network (CNN),2021,"['Arrhythmia Classification', 'ECG', '1D-CNN']",국문 초록 정보 없음,"Cardiac arrhythmia is characterized by irregular electrical activities of the heart, which can be detected by changes in the electrocardiogram (ECG) characteristics. ECG analysis is frequently used by cardiologists to monitor cardiac health. Many previous methods have been developed to detect cardiac arrhythmia by extracting the features of the ECG signal manually. However, the result of feature extraction does not represent perfectly the characteristics of the ECG signal. Therefore, this study proposed an automatic classification system of cardiac arrhythmia using 1-D Convolutional Neural Network (1D-CNN). The 1D-CNN consists of five convolution layers with a kernel size of 7 for each layer and the number of the filters for convolution layer 1 through 5 consists of 8, 16,32, 64, and 128, respectively. For comparison purposes, the other classifier methods, including K-Nearest Neighbor (K-NN), Support Vector Machine (SVM), and Artificial Neural Network (ANN) also investigated to classify the ECG signal. This research used 150 datasets of raw ECG signals that consist of three conditions which are Normal Sinus Rhythm (NSR), Atrial Fibrillation (AF), and Congestive Heart Failure (CHF). The proposed method outperformed the previous method by performing 100% accuracy using 1D-CNN to classify raw data of ECG signal into three conditions."
실시간 적용을 위한 CNN 모델 기반 보행 이벤트 검출 알고리즘,2021,"['보행 이벤트(Gait event)', '실시간(Real-time)', '합성곱 신경망(CNN)', '관성센서(IMU)']",국문 초록 정보 없음,"It is important to apply the control algorithm for gait assistance according to the appropriate gait cycle. Therefore, a gait event detection algorithm that can be applied in real time is required. When an inertial measurement unit (IMU) is attached to the waist to reduce the number of sensors, it becomes difficult to detect a gait event compared to the lower body. We intend to utilize a convolutional neural network (CNN) that can automatically select and learn distinguishable signals. In this study, we proposed a gait event detection algorithm based on a convolutional artificial neural network model using a moving window to enable real-time application. Eight participants walked at three walking speeds on a treadmill to collect data for algorithm development and validation. Acceleration and angular velocity signals were measured from the IMU attached to the waist, and the ground reaction force was measured using force plates. Time points of heel strike and toe-off were detected using the gait events classified by the CNN model. 92.3% of heel strikes and 89.9% of toe-offs were detected among the total gait event time points, and the heel strike and toe-off were estimated with mean absolute errors of 14.5ms and 12.5ms, respectively. These results imply that the CNN model-based gait event detection algorithm can be applied in real time."
An FPGA Implementation of Quantized CNN Hardware for IoT Devices,2021,"['Convolutional Neural Network', 'Quantization', 'Integer Arithmetic', 'FPGA', 'IoT']",국문 초록 정보 없음,"Due to the recent improvement in the computational power of hardware and the growth of data, a deep learning-based approach that optimizes parameters using massive data showed excellent performance. In computer vision, research using a convolutional neural network(CNN) is being actively conducted. However, it is challenging to apply to IoT devices due to the high computational complexity and massive memory usage required. In this paper, we propose a quantized CNN hardware for IoT devices that optimized memory usage and computation complexity. In addition, we present a quantization framework for the proposed hardware design. The presented framework includes floating-point training, quantization, fully integer arithmetic inference, and hardware design processes. As a result of implementing the quantized CNN on the Xilinx ZC702 evaluation board, power consumption and inference speed improved by 4.86× and 2.58×, respectively, compared to 32-bit floating-point hardware."
Korean Finger Number Gesture Recognition Based on CNN Using Surface Electromyography Signals,2021,['Convolutionary Neural Network  · Korean fi nger number gesture  · Surface electromyography signal'],국문 초록 정보 없음,"This study proposes a recognition strategy for Korean fi nger number gestures based on convolutional neural network (CNN) using surface electromyography (sEMG) signals. A few studies have reported Chinese fi nger number gesture recognition using sEMG signals. However, fi nger number gestures vary across diff erent regions, prompting the need to investigate fi nger number gesture recognition specifi c to Koreans. To this end, six Korean fi nger number gestures ranging from zero to fi ve were selected and recognized by CNN using sEMG signals acquired from four pairs of electrodes on forearm muscles. In this study, we investigated the feasibility of CNN in fi nger number gesture recognition using sEMG time series data. The experimental results show that CNN achieved a 100% recognition rate over six Korean fi nger number gestures using sEMG time-series data. A comparative analysis of diff erent studies indicates that the proposed approach may be at least comparable to the existing studies selected in this work. It is therefore a more convenient and promising platform for recognition of fi nger number gestures."
리튬이온 배터리 열분포 이미지를 활용한 CNN 기반 SOC 추정 연구,2021,"['Lithium-ion battery', 'Convolutional neural network', 'State-of-charge', 'Heat distribution image']",국문 초록 정보 없음,다국어 초록 정보 없음
실시간 IOT 장치 제어를 위한 다중 스트림 CNN 기반 음원위치추정 모델,2021,"['Sound Source Localization', 'Convolutional Neural Networks', 'Real-Time', 'IOT Device']",국문 초록 정보 없음,"Sound source localization (SSL) has been widely researched in many areas due to its importance. Recent research shows that Convolutional Neural Network (CNN) can process multi-channel acoustic data efficiently and estimate the sound source direction precisely without considering the complex microphone array geometry. This data driven SSL can make it easy to enable SSL capability in small Internet of Things (IOT) devices. However, it is a big challenge to implement a reasonably accurate and fast CNN based SSL model in a small IOT device with limited computation power. In this paper, we propose a Multi-Stream CNN based SSL for IOT devices. Each CNN stream processes the low, mid and high frequency components to capture the unique delay pattern and classify from which microphone array the sound comes from. This simple classifier-based localization achieves 170ms processing time for 1s audio data with 82.99% accuracy on the Raspberry Pi 4B. If ± 1 mic location error is allowed, the accuracy can be as high as 95.14%."
An Inference Time Efficient 3D Printer Fault Detection using CNN,2021,"['3D printer', 'fault detection', 'convolutional neural network (CNN)']",국문 초록 정보 없음,"The rapid engagement of 3D printing in the in-dustry, manufacturing, and medicine provides advantages for fewer waste materials. However, the increasing use of 3D printing leads to failure in the performance of the 3D printers. In this research we implement a convolutional neural network (CNN) fault diagnosis in a 3D printer is proposed. We used an online repository of a set of data streams collected from 3D printers. The CNN was used to detect, process, and classify the anomalies in 3D printing. The proposed CNN outperformed the peer methods in terms of classification accuracy and inference time."
CNN 강우여부 분류기를 적용한 ANN 기반 X-Band 레이다 유의파고 보정,2021,"['X-band 레이다', '유의파고', '머신러닝', '인공신경망', '합성곱신경망', 'X-band marine radar', 'significant wave heights', 'machine learning', 'artificial neural network(ANN)', 'convolutional neural network(CNN)']",항해용 X-band 레이다를 이용한 파랑관측은 해수면에 후방산란 된 전자기파 이미지를 분석하여 이루어진다. 1분당 42개의 해수면 시계열 이미지로부터 3차원 FFT를 계산하고 변조전달함수(Modulation Transfer Function)를 구하여 파랑정보를 추출한다. 따라서 레이다 파고계로 계측한 유의파고의 정확도는 X-band 레이다 영상의 상태에 따라 결정된다. 2020년 여름 태풍 마이삭과 하이선 내습 시 강릉 안인 해안에 설치된 X-band 레이다 파고계로 관측한 유의파고의 오차가 크게 발생하였다. 이는 태풍 내습 시 급격히 유의파고가 증가하는 한편 강한 강우가 동반되어 X-band 레이다 영상의 품질이 저하되었기 때문이다. 최대 오차 발생 이전까지 많은 강우가 있었음이 확인된다. 본 연구에서는 convolution neural network(CNN)을 이용하여 레이다 이미지로부터 강우 여부를 분류하고 강우여부에 따라 강우시 인공신경망 모델을 적용하여 태풍 시 유의파고 관측 정확도를 향상시켰다. 폭우를 동반한 태풍 시 레이다 자료 특성에 기반하여 인공신경망 유의파고 산출 알고리즘을 개선하고 이를 통해 X-band 레이다 파고계의 정확도를 향상시키는 방법을 제시하였다.,"Wave observations using a marine X-band radar are conducted by analyzing the backscattered radar signal from sea surfaces. Wave parameters are extracted using Modulation Transfer Function obtained from 3D wave number and frequency spectra which are calculated by 3D FFT of time series of sea surface images (42 images per minute). The accuracy of estimation of the significant wave height is, therefore, critically dependent on the quality of radar images. Wave observations during Typhoon Maysak and Haishen in the summer of 2020 show large errors in the estimation of the significant wave heights. It is because of the deteriorated radar images due to raindrops falling on the sea surface. This paper presents the algorithm developed to increase the accuracy of wave heights estimation from radar images by adopting convolution neural network(CNN) which automatically classify radar images into rain and non-rain cases. Then, an algorithm for deriving the Hs is proposed by creating different ANN models and selectively applying them according to the rain or non-rain cases. The developed algorithm applied to heavy rain cases during typhoons and showed critically improved results."
CNN 기반 뇌전도 스펙트로그램 이미지를 이용한 사용자 인식,2021,"['EEG', 'user recognition', 'spectrogram', 'CNN']","최근 웨어러블 기기의 발달로 생체신호를 이용한 기기제어, 헬스케어, 사용자 인식 기술이 연구되고 있다. 특히, 뇌전도 신호는 사용자의 인지 및 감정 상태를 나타내 이를 적용하기 위한 많은 연구가 진행되고 있다. 본 논문에서는 뇌전도 신호에 시간 주파수 특징 분석 방법을 적용한 사용자 인식 알고리즘을 제안한다. 먼저 뇌전도 신호에 포함된 잡음을 제거하고 스펙트로그램 이미지로 변환한 후 CNN(Convolution Neural Networks) 에 적용하여 사용자를 인식한다. 실험결과, 본 논문에서 제안한 방법의 경우 사용자 인식 성능은 80.45%의 성능을 나타냈으며, 1차원 뇌전도 신호를 이용한 방법에 비해 20.95% 성능이 향상됨을 확인하였다.","Recently, with the development of wearable devices, device control using biosignals, healthcare, and user recognition technologies are being studied. In particular, since EEG signals represent the cognitive and emotional states of the user, many studies have been conducted to apply them. In this paper, we propose a user recognition algorithm that applies the time-frequency feature analysis method to the EEG signal. First, noise included in the EEG signal is removed, converted into a spectrogram, and then applied to the Convolution Neural Networks (CNN) to recognize the user. The experiments prove that the user recognition performance was 80.45% for the method proposed in this paper, while the performance was improved 20.95% better than previous studies using the 1D-EEG signal."
CNN(Convolutional Neural Network) 모델을 이용한 야구 경기 영상의 동작 분류 및 검색시스템,2021,"['Deep Learning', 'Convolutional Neural Network', 'Scene classification and retrieval', '딥 러닝', 'CNN 신경망', '영상 분류 및 검색']","본 연구에서는 CNN(Convolution Neural Network) 모델을 이용하여 야구 경기 영상에서 투구나 스윙과 같은 특정 영상이 출현하는 장면을 자동으로 분류하여 효과적으로 검색하는 방법을 제안한다. 또한, 특정 동작의 분류 결과와 경기 기록을 연계한 영상 장면 검색시스템을 제안한다. 제안 시스템의 효율성을 검정하기 위하여 2018년부터 2019년까지 진행된 한국프로야구 경기 영상을 대상으로 특정 장면별로 분류하는 실험을 진행하였다. 야구 경기 영상에서 투구 장면을 분류하는 실험에서는 경기별로 약 90%의 정확도를 보였다. 그리고 경기 영상 내에 포함된 스코어보드를 추출하여 경기 기록과 연계하는 영상 장면 검색 실험에서는 경기별로 약 80% 정도의 정확도를 보였다. 본 연구 결과는 한국프로야구 경기에서 과거 경기 영상을 체계적으로 분석하여 경기력 향상을 위한 전략 수립을 위하여 효과적으로 사용할 수 있으리라 기대한다.","In this paper, we propose a method to effectively search by automatically classifying scenes in which specific images such as pitching or swing appear in baseball game images using a CNN(Convolution Neural Network) model. In addition, we propose a video scene search system that links the classification results of specific motions and game records. In order to test the efficiency of the proposed system, an experiment was conducted to classify the Korean professional baseball game videos from 2018 to 2019 by specific scenes. In an experiment to classify pitching scenes in baseball game images, the accuracy was about 90% for each game. And in the video scene search experiment linking the game record by extracting the scoreboard included in the game video, the accuracy was about 80% for each game. It is expected that the results of this study can be used effectively to establish strategies for improving performance by systematically analyzing past game images in Korean professional baseball games."
Denoising CNN 기반 시계열 데이터의 스펙트로그램 이미지를 이용한 리튬 이온 배터리 잔여수명 예측,2021,"['잔여수명 추정', '디노이징', 'CNN', '리튬 이온 배터리', '스펙트로그램']","많은 산업 분야에서 시스템 또는 구성 요소 고장을 방지하는 것이 중요하며, 갑작스러운 고장을 방지하기 위하여 기존의 정기적 보수를 통한 방식이 널리 사용되지만 효율성 및 신뢰성의 요구를 충족하지 못한다. 이에 따라 지능형 예지보전 (PHM) 기술이 중요하며, 해당 분야의 주요영역 중 하나는 잔여수명 (RUL)의 추정이다. 통상적으로, RUL의 추정은 물리적 속성에 대한 충분한 사전 지식에 달려 있으나, 구성 요소에 대한 사전 지식을 얻는 것은 복잡하거나 많은 경우에 불가능하기 때문에, 확 보된 데이터만을 사용하여 잔여 수명을 예측하는 데이터 중심 접근법이 많은 영역에서 제안되고 있다. 그러나 데이터 중심의 접근 방식을 사용하여 구성 요소의 수명을 예측하는 것은 과적합 문제와 모델의 학습 과정에서 과도한 리소스를 사용하기 때문에 한계가 존재한다. 학습과 현장에서의 적용 사이의 정확성과 학습 시간에 영향을 끼치는 이러한 문제를 극복하기 위하여 본 논문에서는 1차원 시계열 데이터를 2차원 스펙트로그램으로 변환하고, 변환된 데이터에 기반한 노이즈 제거 단계와 잔여수명 추정 단계로 구성된 CNN 모델을 제안한다. 본 연구를 통하여 노이즈를 제거하고 고장 신호만을 포함한 스펙트로그램 데이터를 출력할 수 있도록 학습된 CNN 을 통하여 리튬 이온 배터리의 잔여 수명 추정 문제에 접근함으로써 빠르고 정확한 추정이 가능함을 시사한다.",다국어 초록 정보 없음
Embedded 시스템을 위한 Faster R-CNN 기반의 해양쓰레기 검출 모델 개발,2021,"['Faster R-CNN', 'MobileNetV3', 'marine debris detection', 'object detection', 'embedded system']",국문 초록 정보 없음,"In this study, we propose a Faster R-CNN-based marine debris detection algorithm for an embedded system. First, the trash annotations in context (TACO) dataset, which is an open image dataset of waste in the wild, is used to build a training image dataset of marine debris. To enhance the amount of our training dataset, we included images of the TACO unofficial dataset, which has not been reviewed by the TACO research team. To this end, we manually screened the appropriately annotated images from the TACO unofficial dataset. In addition, only seven most frequently discovered classes in the ocean are selected from the TACO datasets to enable efficient learning. The utilization of MobileNet as the backbone network of the proposed Faster R-CNN model enables a faster inference time compared to those of conventional models. In addition, the backbone network was fine-tuned on the TACO dataset to improve the feature extraction performance of the model. Lastly, the real-time operability of the proposed algorithm was verified by porting the model to Jetson Xavier NX."
Speech Emotion Recognition Using 2D-CNN with Mel-Frequency Cepstrum Coefficients,2021,"['Convolutional neural network', 'Deep learning', 'Mel-frequency cepstrum coefficients', 'Speech emotion recognition']",국문 초록 정보 없음,"With the advent of context-aware computing, many attempts were made to understand emotions. Among these various attempts, Speech Emotion Recognition (SER) is a method of recognizing the speaker's emotions through speech information. The SER is successful in selecting distinctive 'features' and 'classifying' them in an appropriate way. In this paper, the performances of SER using neural network models (e.g., fully connected network (FCN), convolutional neural network (CNN)) with Mel-Frequency Cepstral Coefficients (MFCC) are examined in terms of the accuracy and distribution of emotion recognition. For Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS) dataset, by tuning model parameters, a two-dimensional Convolutional Neural Network (2D-CNN) model with MFCC showed the best performance with an average accuracy of 88.54% for 5 emotions, anger, happiness, calm, fear, and sadness, of men and women. In addition, by examining the distribution of emotion recognition accuracies for neural network models, the 2D-CNN with MFCC can expect an overall accuracy of 75% or more."
MPEG-7 서술자 이진화를 이용한 CNN 추론 결과 압축,2021,[],"본 논문은 물체 검출(Object Detection)과 물체영역분할(Object Segmentation)의 CNN 추론 결과를 MPEG-7 서술자 이진화를 통해 표현함으로써 원본과의 용량을 비교한다. 영상의 사용 목적에 따라 CNN 추론 결과를 압축하여 활용할 시 원본 영상 대비 용량을 측정하여 그 효율성을 판단하는 것이 목표이다. 물체 검출과 물체영역분할에 대한 추론 결과를 MPEG-7 서술자를 이용해 압축하였으며, 비교를 위해 원본 영상, CNN 추론 결과 파일, MPEG-7 서술자, MPEG-7 서술자 이진화 파일의 크기를 측정하였다. 실험 결과, MPEG-7 서술자를 이진화를 통한 표현 방식이 원본 영상 및 추론 결과 파일에 비해 효율적임을 알 수 있었다.",다국어 초록 정보 없음
Traffic Classification for Imbalanced Data Using CNN,2021,"['Convolutional Neural Network (CNN)', 'Traffic Classification', 'Feature Selection', 'Undersampling']",국문 초록 정보 없음,"Deep learning comes with the ability of automatic feature learning, some studies try to apply it in network traffic classification to get better accuracy. The uses of public datasets sometimes suffer from the condition of the imbalanced dataset. This paper proposes a model to classify the network traffic using a Convolutional Neural Network (CNN). To improve the accuracy, the feature selection process is employed and random undersampling is used to balance the dataset. It compared with regular CNN and Long Short-Term Memory (LSTM). The performance of the proposed algorithm is verified by using ISCX VPN-nonVPN dataset. The simulation result showed that the proposed algorithm achieves an accuracy of 97.38% with a validation loss of 0.0783."
Pseudo Colorization Using CNN Model For X-ray Baggage Scan Image,2021,"['X-ray inspection', 'pseudo-colorization', 'Convolutional Neural Network']",국문 초록 정보 없음,"The X-ray scanner displays an image that contains the different levels of radiation absorbed by the materials based on atomic numbers, so it forms a grayscale image that shows the shapes of the items being examined. For that, we use a convolutional neural network (CNN) to separate the material by colorization such as organic, non-organic, and metal to facilitate the process of inspections for luggage or cargoes. in this paper we propose a CNN network for pseudo-colorization, we use a dataset of Rapiscan scanner which contain 129275 images with encoder-decoder CNN architecture."
Pattern Classification for Small-Sized Defects Using Multi-Head CNN in Semiconductor Manufacturing,2021,['Automatic defect classification (ADC) · Convolutional neural network (CNN) · Modified median filtering · Rotated defects (RoD) transform'],국문 초록 정보 없음,"To improve the quality of semiconductor manufacturing, defects need to be detected and their root causes controlled. Because the root causes can vary depending on defect patterns, classifying the patterns accurately is important. Several recent studies have investigated automatic defect classification using a convolutional neural network (CNN) with wafer map images. CNNs are excellent tools for classifying images of different shapes and sizes. However, the detection of small-sized defects that have small clusters and linear patterns is difficult. Therefore, this study focuses on patterns that are difficult to detect. We propose three steps for pattern classification. First, modified median filtering is used to preserve the original shapes of patterns. Second, a rotated defects (RoD) transform is performed by applying the rotational properties of wafer maps. The RoD transform augments the defect proportion and improves the detection of small-sized defects. Third, a multi-head CNN is used to extract and combine the features from the original and transformed maps. The combined features are then used to classify the defect patterns. Overall classification performance of defects can be improved by accurately classifying small clusters and linear patterns. The proposed model was evaluated using WM-811K wafer maps, and small-sized defects were accurately classified. Such an accurate defect classification model will enable effective root cause analysis and quality improvement in semiconductor manufacturing."
"실시간 감정인식을 위한 파형 단위PPG, GSR 신호 기반 1D CNN 기법",2021,"['Real-time', 'PPG', 'GSR', '1D CNN', 'Pulse unit']",국문 초록 정보 없음,"Emotion recognition technology, a core for human-robot interaction, must have fast data processing speed and real-time characteristics. This paper proposes an emotion classification method using two bio-signals for real-time emotion recognition. The proposed method is a technique to classify human emotions into three (high or low, neutral arousal / valence) emotions by extracting features from one pulse of PPG(Photoplethysmogram) signal and GSR(Galvanic Skin Response) signal through a 1D CNN model. For real-time emotion recognition, input data requires a short length from 1 to 3 seconds and fast preprocessing. Therefore, in this paper, we use three preprocessing processes and one short pulse of Window size 1.1s without feature extraction, and the label of each pulse uses annotation labeling. The Experiments show that average accuracy is 71.1% arousal and 71.8% valence, confirming the possibility of emotion recognition with pulse-wise data and a real-time possibility with 0.17 seconds of preprocessing time per sample data."
Activity Object Detection Based on Improved Faster R-CNN,2021,"['Human activity object', 'Faster R-CNN', 'Dense-Net', 'Soft-NMS']",국문 초록 정보 없음,다국어 초록 정보 없음
프레임 확장 방식을 적용한 자동 변조 분류 CNN 모델 설계,2021,[],본 논문은 인지 통신망에서 강인한 자동 변조 분류를 위해 프레임 확장 방식의 CNN 모델을 제안하였다. 일반적으로 자동 변조 분류를 위한 CNN 모델은 입력값을 복소신호에서 실수성분와 허수성분으로 분리하여 2×N 크기로 사용하지만 본 논문에서는 2×을 복사하여 2×에 연결하는 방식으로 4× 입력을 적용하였다. 제안된 방식을 통한 CNN 모델의 정확도 성능은 최신 모델인 LCNN과 비교하여 우수함을 나타내었다.,다국어 초록 정보 없음
Automatic Fracture Detection in CT Scan Images of Rocks Using Modified Faster R-CNN Deep-Learning Algorithm with Rotated Bounding Box,2021,"['Fracture detection', 'Computed tomography', 'Deep learning', 'Faster R-CNN', 'Rotated bounding box', '균열 탐지', '컴퓨터 단층촬영', '딥러닝 알고리즘', '회전 경계박스']","본 논문에서는 암석시료의 CT 촬영 이미지상의 균열을 자동으로 탐지하는 새로운 인공지능 딥러닝 기법을 제안한다. 본 제안 기법은 2단계 딥러닝 객체인식 알고르즘인 Faster R-CNN을 기반으로 회전 가능한 경계박스(bounding box) 개념을 도입하여 알고리즘을 개조하였다. 회전 경계박스의 도입은 관심 균열 영역 밖의 배경의 불균질성 및 균열의 크기와 형태에 영향을 받는 딥러닝 객체인식기법 상의 고유한 어려움을 극복하기 위한 핵심 역할을 한다. 본 회전형 경계박스의 사용은 일반적으로 사용되는 영상 수평 축과 평행한 경계박스 사용의 경우와 비교하여 긴 형태의 균열 형상 특성에 매우 잘 부합된다. 즉, 좋지 않은 영향을 끼치는 경계박스 내 균열 이외 배경영역의 비율을 최소화 시킬 수 있다. 이외에도, 회전 경계 박스의 추가적인 이점은 인식된 균열의 방향에 따라 회전하여 추론되는 경계박스를 통해 균열의 방향과 길이에 대한 정보를 직접적으로 얻을 수 있다. 본 제안기법의 적용성을 검증하기 위하여, 이미지상에서 매우 불균질한 화강암 시료에 인공적으로 균열을 발생시킨 다수의 암석시료 영상을 딥러닝 학습에 사용하고 추론 성능 실험을 진행하였다. 그 외에도, 동일 조건에서 사암과 셰일 암석 시료에도 적용하여 검증하였다. 결론적으로, 제안된 기법을 통해 균열 객체 인식의 평균 추론정확도(mAP)값이 0.89 정도 수준의 우수한 추론 성능을 보였으며, 기존 기법에 비해 추론된 경계박스 내 균열과 배경 영역의 비율 측면에 서 배경의 비율이 획기적으로 최소화되는 유리한 추론 검증 결과를 보였다.","In this study, we propose a new approach for automatic fracture detection in CT scan images of rock specimens. This approach is built on top of two-stage object detection deep learning algorithm called Faster R-CNN with a major modification of using rotated bounding box. The use of rotated bounding box plays a key role in the future work to overcome several inherent difficulties of fracture segmentation relating to the heterogeneity of uninterested background (i.e., minerals) and the variation in size and shape of fracture. Comparing to the commonly used bounding box (i.e., axis-align bounding box), rotated bounding box shows a greater adaptability to fit with the elongated shape of fracture, such that minimizing the ratio of background within the bounding box. Besides, an additional benefit of rotated bounding box is that it can provide relative information on the orientation and length of fracture without the further segmentation and measurement step. To validate the applicability of the proposed approach, we train and test our approach with a number of CT image sets of fractured granite specimens with highly heterogeneous background and other rocks such as sandstone and shale. The result demonstrates that our approach can lead to the encouraging results on fracture detection with the mean average precision (mAP) up to 0.89 and also outperform the conventional approach in terms of background-to-object ratio within the bounding box."
Railway sleeper crack recognition based on edge detection and CNN,2021,"['convolutional neural network', 'edge detection', 'mathematical morphology operations', 'neighborhood range algorithm', 'railway sleeper cracks']",국문 초록 정보 없음,"Cracks in railway sleeper are an inevitable condition and has a significant influence on the safety of railway system. Although the technology of railway sleeper condition monitoring using machine learning (ML) models has been widely applied, the crack recognition accuracy is still in need of improvement. In this paper, a two-stage method using edge detection and convolutional neural network (CNN) is proposed to reduce the burden of computing for detecting cracks in railway sleepers with high accuracy. In the first stage, the edge detection is carried out by using the 3×3 neighborhood range algorithm to find out the possible crack areas, and a series of mathematical morphology operations are further used to eliminate the influence of noise targets to the edge detection results. In the second stage, a CNN model is employed to classify the results of edge detection. Through the analysis of abundant images of sleepers with cracks, it is proved that the cracks detected by the neighborhood range algorithm are superior to those detected by Sobel and Canny algorithms, which can be classified by proposed CNN model with high accuracy."
CNN based classifi cation of motor imaginary using variational mode decomposed EEG-spectrum image,2021,['.'],국문 초록 정보 없음,"A novel approach of preprocessing EEG signals by generating spectrum image for eff ective Convolutional Neural Network(CNN) based classifi cation for Motor Imaginary (MI) recognition is proposed. The approach involves extracting the VariationalMode Decomposition (VMD) modes of EEG signals, from which the Short Time Fourier Transform (STFT) of allthe modes are arranged to form EEG spectrum images. The EEG spectrum images generated are provided as input image toCNN. The two generic CNN architectures for MI classifi cation (EEGNet and DeepConvNet) and the architectures for patternrecognition (AlexNet and LeNet) are used in this study. Among the four architectures, EEGNet provides average accuracies of91.37%, 94.41%, 85.67% and 90.21% for the four datasets used to validate the proposed approach. Consistently better resultsin comparison with results in recent literature demonstrate that the EEG spectrum image generation using VMD-STFT is apromising method for the time frequency analysis of EEG signals."
CNN 기반 근전도의 2D 스펙트로그램 이미지를 이용한 사용자 인식,2021,"['EMG', 'user recognition', 'spectrogram', 'CNN']",국문 초록 정보 없음,"Recently, user recognition using biometric information has become a social issue due to forgery, alteration, and accidents, and research on user recognition using biometric signals is actively underway. Biometric signals are electrical signals that occur inside the body and generate individual-specific signals according to behavioral characteristics. Bio-signals typically include musculature, electrocardiogram, and cerebral conduction. Among the biometric signals the EMG signal is applied in the field of user recognition using features measured in different signal patterns according to an individual’s unique strength. In this paper, transform pre-processed one-dimensional EMG signals into two-dimensional EMG spectrogram images, extract features using CNN, and finally recognize the user to analyze the performance of the user recognition system. As a result of the experiment, user awareness of 40 people was analyzed to be 95.4%(±1.7%) when using 12 channels and the window length R of STFT was 256."
CNN 기반 특징맵 사용에 따른 특징점 가시화와 에러율,2021,"['CNN', 'Robustness', 'Deep learning', 'Image processing', 'Sparse Connection']",국문 초록 정보 없음,"In this paper, we presented the experimental basis for the theoretical background and robustness of the Convolutional Neural Network for object recognition based on artificial intelligence. An experimental result was performed to visualize the weighting filters and feature maps for each layer to determine what characteristics CNN is automatically generating. experimental results were presented on the trend of learning error and identification error rate by checking the relevance of the weight filter and feature map for learning error and identification error. The weighting filter and characteristic map are presented as experimental results. The automatically generated characteristic quantities presented the results of error rates for moving and rotating robustness to geometric changes."
에너지 효율적인 CNN 가속기의 주요 기술 및 연구 동향,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
영상정보를 활용한 CNN 기반 다수 재실자 행동 분류 모델 개발,2021,"['재실자 행동', '영상정보', 'CNN', 'Occupant Behaviour', 'Image Data', 'Convolutional Neural Network']",국문 초록 정보 없음,"Occupants’ activities in buildings have meaningful impact on indoor environment and energy conservation due to variable patterns of occupancy and their use of electric devices. Therefore occupant behaviour detecting methods based on sensor were suggested in previous studies which resulted low accuracy in detecting multiple occupants while required additional installation. In this reason, this paper proposes a multiple occupants’ activity classification model based on CNN using the existing infrastructre(CCTV). We trained the model using collected 27,000 images of occupants’ activities(e.g. eating, cooking) within the Smart Living Testbed(SLT) at Dankook University. As a result, the experiments test showed overall F1-Score of 0.86. This study showed the possibility of proposed model in classifying multiple occupant’s activities."
Human Face Recognition Based on improved CNN Model with Multi-layers,2021,"['Face Recognition', 'CNN Model', 'ORL Database', 'AR Face Database', 'Residual Network']",국문 초록 정보 없음,다국어 초록 정보 없음
임베디드 환경에서의 CNN 기반 실시간 객체 및 차선 검출에 관한 연구,2021,"['FCW(전방 충돌 경고)', 'LDW(차선 이탈 경고)', 'ADAS(첨단 자율 주행 시스템)', 'CNN(합성곱 신경망)', 'Deep Learning(딥러닝)', 'Vehicle Detection(차량 검출)', 'Lane Detection(차선 검출)', 'Embedded System', 'SSD']",국문 초록 정보 없음,"While most approaches to object detection and recognition have focused on improving performance of the detection ratio, in this paper we describe a method for implementing real time Lane Detection and Object Detection using CNN on embedded system. The model used for vehicle and pedestrian detection was generated by referring to SSD network structure. In addition, we use a segmentation method based on deep learning as a pre-processing for lane detection. To reduce the parameter size of the deep learning model, the final model was generated through the sparsity technique. The proposed object and lane detection algorithm were implemented on the embedded board. The processing time was about 30.2 fps and the precision 94(vehicle)% respectively."
ConvXGB: A new deep learning model for classification problems based on CNN and XGBoost,2021,"['Convolutional neural network (CNN)', 'Classification algorithms', 'Deep learning', 'Extreme gradient boosting', 'XGBoost', 'Machine learning', 'Pattern recognition']",국문 초록 정보 없음,"We describe a new deep learning model - Convolutional eXtreme Gradient Boosting (ConvXGB) for classification problems based on convolutional neural nets and Chen et al.'s XGBoost. As well as image data, ConvXGB also supports the general classification problems, with a data preprocessing module. ConvXGB consists of several stacked convolutional layers to learn the features of the input and is able to learn features automatically, followed by XGBoost in the last layer for predicting the class labels. The ConvXGB model is simplified by reducing the number of parameters under appropriate conditions, since it is not necessary re-adjust the weight values in a back propagation cycle. Experiments on several data sets from UCL Repository, including images and general data sets, showed that our model handled the classification problems, for all the tested data sets, slightly better than CNN and XGBoost alone and was sometimes significantly better."
Edge Data를 활용한 CNN 기반의 자율주행자동차 학습데이터 경량화 방안,2021,"['자율주행자동차', 'Edge Data', 'CNN', '학습데이터', '스토리지 용량']",국문 초록 정보 없음,다국어 초록 정보 없음
Filter Combination Learning for CNN Model Compression,2021,"['Deep learning', 'Model compression', 'Filter combination']",국문 초록 정보 없음,"In this paper, we propose a new method for generating convolution filters of a convolutional neural network (CNN) model as linear combinations of only a few basis filters that are provided as input features. In our approach, best coefficients of the linear combinations are searched (trained) with the given input basis filters (IBFs) to reconstruct the convolution filter parameters. Since all the convolution filters can be generated by the linear combinations of the IBFs, the size of a CNN model can be compressed if the number of coefficients for the linear combinations is less than that of filter parameters. Our primary goal is to investigate the possibility of expressing filters with a small set of IBFs by linear combinations. The second goal is to compress a model so that it can be beneficial when the model is distributed and stored (particularly downloaded to mobile devices through Wi-Fi)."
직접 볼륨 렌더링을 위한 CNN 기반 TF 색상 매핑,2021,"['직접 볼륨 렌더링', 'TF 색상화', 'Direct Volume Rendering', 'CNN', 'TF colorization']",직접 볼륨 렌더링은 볼륨 표면의 연산 없이 2차원 공간에 투영하여 렌더링 한다. 직접 볼륨 렌더링에서 전이함수(TF)는 볼륨에 색상과 투명도와 같은 광원 특성을 할당하는데 활용된다. 하지만 초보자가 TF를 조작하여 볼륨데이터를 파악하고 색상을 할당하기까지 오랜 시간이 필요합니다. 본 논문에서는 직관적인 볼륨 렌더링을 위해 인터넷에서 수집한 이미지를 사용하여 TF에 볼륨의 색상을 매핑하는 접근 방식을 제안한다. 또한 우리는 K-means 클러스터링을 활용한 색상 추출 방법을 토의한다.,"Direct Volume Rendering(DVR) renders by projecting data into a two-dimensional space without calculating the volume surfaces. In DVR, the transfer function(TF) assigns light properties such as color and transparency to the volume. However, it takes a long time for beginners to manipulate TF to understand volume data and assign colors. This paper proposes an approach to colorize the volume using sample images for intuitive volume rendering. We also discuss color extraction methods using K-means clustering."
RGB-D 센서 및 CNN 을 이용한 실시간 손 제스처 인식,2021,"['RGB-D Sensor', 'Hand gesture recognition', 'CNN', 'Human-Computer-Interaction', 'Kinect']",국문 초록 정보 없음,"This paper propose real-time hand gesture recognition as a key technology to overcome may difficulties and provide convenience for human. For natural interaction, we propose non-contact and vision-based system using Kinect V2. It collects RGB, Depth and RGB-D information about the hand from the sensor. To extract only valid image information, locate the hand and obtain only the surrounding hand information by using the pose estimation technology provided by the Kinect SDK. There are four types of hand gestures that you want to recognize, each comprising more than 4,000 datasets. Hand image classification algorithm is based on a deep learning CNN model. The performance of the proposed system was assessed using the Kinect SDK, which is the most commonly used one, and the system has a higher recognition rate than the existing system by more than 20%."
77GHz 차량용 레이더의 세그웨이 데이터에 대한 CNN 분류기 성능 분석,2021,[],"본 논문은 convolutional neural network (CNN) 분류기를 이용하여 레이더에 감지된 타깃을 분류하는 방안을 제시하고, 측정 데이터를 바탕으로 결과를 분석하였다. 하나의 거리-속도 평면 데이터에 두 개 이상의 타깃이 존재할 때, 감지된 타깃 데이터에 해당하는 영역을 추출하여 분류기의 입력으로 이용한다. 도로에서 감지 가능한 타깃들을 고려하여 사람, 자전거, 세그웨이를 타는 사람에 대한 데이터를 측정하여 특성을 분석하였다. 세 타깃의 신호 패턴차이가 있었으며, 간단한 CNN 분류기를 이용하였을 때 약 90.77% 정확도로 구분이 가능함을 확인했다.",다국어 초록 정보 없음
엔지니어링 구조물의 균열 모사를 통한 CNN 기반 실시간 건전성 진단 장치 설계,2021,"['Prognostics and health management', 'Additive manufacturing', 'Mimic crack', 'Real-time object detection', 'Convolutional neural network']","엔지니어링 구조물 및 시스템은 시간에 따라 균열, 누수, 박리, 부식, 마모 등의 결함이 발생하고 이러한 구조물의 국부적인 결함은 파괴로 이어져 인적, 경제적 피해가 발생한다. 이를 예방하기 위해 건전성예측관리 기술 도입이 요구된다. 본 연구에서는 엔지니어링 구조물의 모사된 균열 이미지 데이터를 수집하여 합성 곱 신경망(CNN, Convolutional Neural Network)을 기반으로 균열 진단 모델을 생성하고 Jetson-nano 소형 인공지능 처리 장치에 학습시켜 균열 진단 및 실시간 검출이 동시에 가능한 장치 설계를 수행하였다. 이를 위해 엔지니어링 구조물 균열 이미지를 수집하고 균열 부 너비에 따른 위험도 기준을 선정하였다. 이를 기반으로 3 차원 모델링을 수행하여 적층 제조를 통해 모사하였다. 이어 모사된 균열 구조물로부터 다양한 각도의 이미지 데이터를 수집해 클래스와 클래스의 위치좌표를 입력하는 전 처리 작업을 수행하여 CNN 기반 진단 모델 생성을 위한 훈련 데이터 셋을 형성하였다. 구조물 균열 진단 및 객체 탐지 모델은 VGG (Visual Geometry Group)기반의 객체 탐지 모델인 SSD (Single Shot Detector)로 선정하여 생성하였다. 이를 Jetson-nano 에 학습시켜 원격조종이 가능한 실시간 건전성 진단장치를 설계하였다. 이를 통해 선정한 균열 위험도 기준으로 모사된 균열을 90%이상의 확률로 검출하는 결과를 얻었으며, 이를 바탕으로 상태 기반 유지보수 전략을 세우고 이미지 데이터를 기반으로 하는 공학 분야의 범용성 있는 문제 해결 가능성을 제시하였다.",다국어 초록 정보 없음
리튬이온 배터리 노화상태 추정을 위한 건전성 지표 추출 및 CNN 적용,2021,"['Health indicator', 'Lithium-ion battery', 'Convolutional neural network', 'Urban dynamometer driving schedule', 'State-of-health estimation']",국문 초록 정보 없음,"Due to the output characteristics of lithium-ion batteries used in electric vehicles (EVs) vary according to battery aging, accurate prediction of the state-of-health (SOH) reflecting the aging state is important. However, it is difficult to consider factors affecting battery characteristics, such as frequent charging and discharging, operating temperature, and state of charge, so there is a limitation in predicting battery SOH. Even in a model that considers the aging state of the battery under these various conditions, there is also a problem in that the complexity of the calculation process and parameters becomes serious. Therefore, in this paper, in order to research on the estimation of the aging state during operation of the INR18650-25R battery, a health indicator (HI) that can reflect the internal state of the battery according to aging is extracted. This research produce a learning image through the extracted HI and build a model study that enables algorithm learning through the image. The experimental profile used for model training and validation was an Urban Dynamometer Driving Schedule (UDDS), and a Convolutional Neural Network (CNN) with strength in image learning was applied for the estimation algorithm."
Disasters Scenes Classification Based on Unmanned Aerial Vehicles Using Lightweight CNN,2021,"['Unmanned aerial vehicles', 'Drone applications', 'Disaster management systems', 'Deep learning', 'Convolutional neural network']",국문 초록 정보 없음,"Nowadays, due to natural disasters the world is facing huge challenges such as economical, climatic, and losses a lot of precious human life. The traditional emergency response and rescue teams are physically visit different affected areas for inspection and save human lives. In this manual monitoring system created various problems such as human resources, time-consuming, and in real-time unable to accurately analyze the nature of the disaster. Therefore, there is an urgent need for an automatic real-time system to intelligently identified different disaster scenes and analyze the affected areas for quick response. Therefore, in this paper, an Unmanned Aerial Vehicles (UAVs) inspired framework is proposed for disaster scenes classification using a lightweight Convolution Neural Network (CNN). To validate the strength of the proposed framework a comparative analysis is conducted to show its superiority against different state-of-the-art models in terms of computational complexity and performance."
재난 환경에서 UWB 측위를 위한 설명 가능한 인공지능 기반 CNN 경량화 알고리즘,2021,"['UWB Localization', 'XAI', 'Disaster Environment', 'Deep Learningv']","본 논문은 재난 환경에 적합한 경량화된 UWB 측위에 대한 연구를 소개한다. UWB는 디바이스간 정 밀한 거리 측정 기능을 제공하여 고정밀 측위에 활용된다. 하지만 재난 환경과 같이 무선 채널이 복잡 한 경우, UWB 측위 성능이 급격히 하락하는 문제가 발생한다. 최근 UWB 신호에 딥러닝 기술을 이용 하여 성능 하락 문제를 해결하는 연구들이 제안된다. 하지만 딥러닝 기술은 고성능 컴퓨팅 자원을 요 구하여 자원 제약이 있는 재난 상황에서 활용되기 어렵다. 본 논문에서는 XAI 기술을 적용하여 딥러 닝 기술의 높은 정확도를 유지하면서 동시에 연산 복잡도를 낮추기 위한 XLNet을 제안한다.",다국어 초록 정보 없음
Performance Analysis of Object-based Scene Recognition Algorithm using Mask R-CNN,2021,[],국문 초록 정보 없음,"In this paper, an object-based scene recognition algorithm was proposed by applying the mask region-based convolutional neural network (Mask R-CNN) framework, and the accuracy of the proposed algorithm was analyzed. The proposed algorithm is designed based on a deep learning model consisting of a convolutional neural network (CNN), region proposal network (RPN), and region of interest (RoI) align, and detects objects scattered in the surrounding environment. The average object-based scene recognition accuracy was measured to be about 95% and 93% in 1<sup>st</sup> and 2<sup>nd</sup> experiments, respectively."
CNN 을 이용한 동전 분류,2021,"['CNN', 'machine learning', 'coin', 'coin classification', 'currency']",국문 초록 정보 없음,다국어 초록 정보 없음
Gradient Flow Analysis and Performance Comparison of CNN Models,2021,"['CNN', '그래디언트 소실', '그래디언트 플로우', '성능 비교', '오류율', 'gradient vanishing problem', 'gradient flow', 'performance comparison', 'error rate']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반의 한약재 이미지 비교학습 알고리즘,2021,[],국문 초록 정보 없음,"This study is about automatic classification and information delivery of herbal medicines and in more detail, we use big data analysis techniques and deep learning techniques to analyze information about herbal medicines, providing systems for accurate information delivery to patients using herbal medicines.In particular, this invention concerns how to analyze images (algorithms) into two piles to compare image classification accuracy differences according to differences in data collection methods and to produce more accurate results through image data classification evaluation.Furthermore, images can be learned and classified using CNN techniques on VGGNet using data preprocessing and aggregation methods based on each collected image to output accuracy and loss functions each time the validation process proceeds, and image data can be trained, validated, and tested in more detail."
1D-CNN을 이용한 초분광 이미지 분류에서 Dilated Convolution의 영향 분석,2021,[],국문 초록 정보 없음,"Recently, studies on hyperspectral image classification using deep learning are being conducted. Among these studies, the extraction of features of spectral information can be considered as the best match for the meaning of hyperspectral images. One Dimensional Convolution Neural Network is one of the most widely applied methods. In this paper, we investigate the effect of the Dilated Convolution Layer on the hyperspectral 1DCNN by applying the Dilated Convolution Layer instead of the pooling layer in 1D-CNN. Experiments were conducted using a public hyperspectral image dataset. The experimental results confirmed that Dilated Convolution has a good effect."
CNN 을 활용한 수박 당도 예측,2021,[],"수박의 이미지와 수박의 무게 데이터를 활용해 수박의 당도를 예측하고 모델의 정확도를 측정한다. 과피가 얇고, 부피가 작은 과일의 경우 휴대용 비파괴 당도 측정기를 통해 비교적 간편하게 당도 측정이 가능하다. 하지만 수박은 과피도 두껍고, 부피도 크기 때문에 넓은 장소와 비용을 부담해야 하는 선별장에만 당도를 측정할 수 있는 실정이다. 본 논문에서는 줄무늬가 끊어지지 않고, 원형이 아닌 타원형이 맛있는 수박이라는 속설에 부합하는 수박이 실제로 맛있는 수박인지를 확인하고자 수박 이미지를 수집하여 당도에 따라 이미지를 분류한 다음, CNN 을 적용하여 수박 당도 예측을 실시하였다. 실험 결과 타원형 수박은 당도가 높은 것으로 나타났으나 줄무늬가 끊어진 수박과 끊어지지 않은 수박 간의 당도 차이는 없는 것으로 나타났다. 향후 수박의 당도에 영향을 미칠 수 있는 다양한 변수를 활용하여 정확도를 높인다면 현재 사용되고 있는 비파괴 당도 측정기를 보완할 수 있을 것으로 기대된다.",다국어 초록 정보 없음
CNN 기반의 음성 잔향 제거 기술에서 음성 품질 고도화를 위한 다양한 뉴럴 보코더의 성능 비교,2021,"['Convolutional Neural Network(CNN)', 'Neural vocoder', 'Reverberation', 'Room Related Transfer Function', 'Speech Dereverberation']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반 리뷰 유용성 점수 예측을 통한 개인화 추천 서비스 성능 향상에 관한 연구,2021,"['개인화 추천 서비스', '리뷰 유용성', '협업 필터링', '딥러닝', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN(Convolutional Neural Network) 알고리즘을 활용한 음성신호 중 비음성 구간 탐지 모델 연구,2021,"['음성인식', '딥러닝', '합성곱신경망', '인공지능', 'NLP', 'Speech Recognition', 'Deep-Learning', 'CNN', 'Artificial-Intelligence', 'NLP']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반 오디오 분류를 이용한 유도 전동기의 고장 진단,2021,[],"기계시스템과 연결된 유도 전동기 구동 시 베어링 손상으로 인한 고장과 축의 오정렬에 의한 고장이 발생할 수 있다. 고장 상황 시 소리 신호의 패턴의 차이가 나타나게 된다. 본 연구에서는 이 소리 신호들을 멜 스펙트로그램으로 변환 후, CNN(Convolutional Neural Network)을 활용해 고차원 특징을 추출하는 모델 구조를 제안한다. 또한, 추출된 특징을 기반으로 FNN(Feedforward Neural Network) 분류기를 활용하여 고장 진단을 하는 모델을 제안한다. 특징 추출 모델과 분류기 모델은 종단간 학습되며, 모델의 성능으로 668개 평가 데이터에 대해 99.85%의 진단 정확도를 얻었다.",다국어 초록 정보 없음
CNN 기반 깊이 추정을 이용한 실시간 장애물 회피,2021,"['path planning', 'deep learning', 'monocular depth estimation', 'collision avoidance']",국문 초록 정보 없음,"The purpose of autonomous navigation is to reach the destination without collision. Traditionally, mobile robots have used LIDAR, sonar sensors, or stereo cameras to avoid obstacles. However, UAVs suffer from the selection of sensors due to payload capacity. To resolve this issue, we design the method using the only a monocular camera for obstacle avoidance on a quadrotor. In order to obtain the depth images, we use a CNN (Convolutional Neural Network). To improve the depth estimation performance, we develop a data augmentation algorithm of the magnified images especially ranging from 0.5~1 meters. By using the estimated depth image, the desired direction of the quadrotor is set. To validate our proposed algorithm, we conduct experiments with real drones in indoor environments. An analysis of the experiments shows that the proposed method can be utilized for navigation in cluttered environments."
Multi-CNN을 이용한 건축 구조물 손상도 식별 지표 제안,2021,"['손상도 식별', '평균 제곱근 편차', '누적 확률 분포', 'Multi-CNN', 'Damage Identification', 'Root Mean Square Error', 'Cumulative Distribution Function']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반 장르 소분류 모델을 활용한 실시간 음악 장르 분류 모델 연구,2021,"['Music Genre Classification', 'CNN', 'Machine Learning', 'Ensemble model']",국문 초록 정보 없음,"In this paper, we propose an N-genre music classification model and ensemble models that can more accurately classify 10 music genres based on the proposed N-genre model. The GTZAN data set is used as the music data set, and different MFCC-based color maps are compared to identify the one that produces the best classification accuracy. Two methods of model learning are used: (i) using a 30 s long music image and (ii) using a 5 s long music image, wherein the latter utilizes the voting method. The classification accuracy of these two methods is compared. Among the various types of MFCC-based color maps, the gist-rainbow method with better classification accuracy is chosen, and the 3-genre classification model is actually selected among several N-genre classification models. Furthermore, ensemble models overlapped for four genres is proposed and their classification accuracies are compared. Ensemble Model II, using the voting method, obtains an accuracy of 92.0% for the GTZAN data set. The classification accuracy of the proposed ensemble model II is compared with the those of the other reported models."
CNN(Convolution Neural Network)을 이용한 심전도 데이터 기반 건강상태 모니터링 기술,2021,[],"최근 건강상태를 확인하고 싶은 소비자들의 욕구를 바탕으로 웨어러블 기기를 이용해 심전도, 심박수 등 생체신호를 측정하여 건강상태를 실시간으로 모니터링해주는 헬스케어 시장이 성장하고 있다. 한편, 기기 제조사에서도 심전도, 심박수, 산소포화도, 체성분 분석 등 모니터링 가능한 생체신호를 추가하면서 소비자의 관심도 더욱 더 증가할 것으로 예상되고 있다. 본 논문은 1차원 심전도 데이터를 바탕으로 CNN(Convolutional Neural Network) 의 컨볼루션 연산을 이용한 특징 추출을 통해 15종류의 부정맥 징후를 학습시켜 부정맥을 정확하게 탐지할 수 있는 방법을 제안한다. 컨볼루션 계층에 적용할 다양한 커널 크기와 개수에 대해 실험을 통해 최적의 조합을 선정하였고, 그 결과 15종의 부정맥 유형에 대한 분류 결과 99.3%의 정확한 예측성능을 보여주었다.",다국어 초록 정보 없음
CNN 보조 손실을 이용한 차원 기반 감성 분석,2021,"['온라인 리뷰 분석', '차원 기반 감성 분석', 'TASD', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
Study on Application of Regions With Convolutional Neural Networks (R-CNN) and X-Ray Image-Based Object Detection Model to Identification of Trigger List Items,2021,"['R-CNN', 'Object Detection', 'X-ray image', 'Trigger List Items']",국문 초록 정보 없음,다국어 초록 정보 없음
계층적 CNN 기반 스테가노그래피 알고리즘의 6진 분류,2021,"['Steganography', 'Steganalysis', 'Hierarchical CNN', 'Senary Classification']",국문 초록 정보 없음,다국어 초록 정보 없음
Lightweight CNN Model for Detection of Unauthorized UAV in Military Reconnaissance Operations,2021,"['Deep Learning', 'Drone', 'Military', 'Reconnaissance', 'Detection']",국문 초록 정보 없음,"In any warfare, success is a function of innovative tactics and strategic deployment of limited resource. This paper develops a lightweight deep neural network that can track and disarm illegal invasion of a territory by drones using radio frequency technology. The dataset consist of RF signals generated from 17 drones at different instances and sources. The result shows that the proposed model achieved a high a prediction accuracy and sensitivity of 95% than existing CNN (80%) and DNN (75%) with low computational complexity."
경량화 CNN 딥러닝 모델을 이용한 CCTV 안전보안 방법,2021,"['CCTV', '경량화', 'CNN', '안전', '보안']",국문 초록 정보 없음,다국어 초록 정보 없음
HM-Prom: CNN based Prediction of TATA Promoters from Human and Mouse Sequences,2021,"['Promoters', 'Convolutional Neural Network (CNN)', 'Computational Biology', 'Bioinformatics']",국문 초록 정보 없음,"A promoter is a DNA element that is found surrounding the transcription start site and can regulate gene transcription. The detection of promoters is critical in defining transcription units, examining gene structure, assessing gene regulatory mechanisms, and annotating gene functional information. Many methods for predicting promoters have previously been proposed. However, these approaches’ performance still has to be improved. In this paper, we present HM-Prom, a strong deep learning model for analysing the properties of short eukaryotic promoter sequences and properly recognizing human and mouse promoter sequences. We performed experiments on a benchmark dataset and compared our results to four cutting-edge tools to demonstrate our superiority in 5-fold cross-validation. Furthermore, we put our classifier through its paces on an independent test dataset. Comparative results show that our method outperforms other approaches for recognizing promoters."
mmWave 레이더와 CNN 기반 자율주행 차량 운전자 센싱,2021,[],"자율주행 기술의 발달과 다양한 운전자 지원 시스템의 개발됨이 따라, 현대의 운전자들은 기술에 의존하여 운전자의 부주의로 발생하는 교통사고 사례가 있다. 본 논문에서는 자율주행의 기술을 보다 강화하기 위한 방안으로 mmWave 레이더와 CNN 을 이용해 측정 정확도를 향상시킨 방식을 제한한다. 제안하는 방식은 94.9%의 정확도로 운전자의 핸들조작 여부를 인식함을 확인하였다.",다국어 초록 정보 없음
전류 신호를 이용한 1D CNN 기반 전기 분무 모드 감지,2021,"['Electrospray', '1D CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
Vehicle Orientation Detection Using CNN,2021,"['Vehicle Orientation', 'Vehicle Detection', 'Real-Time', 'Convolutional Neural Network(CNN)']",국문 초록 정보 없음,"Vehicle orientation detection is a challenging task because the orientations of vehicles can vary in a wide range in captured images. The existing methods for oriented vehicle detection require too much computation time to be applied to a real-time system. We propose Rotate YOLO, which has a set of anchor boxes with multiple scales, ratios, and angles to predict bounding boxes. For estimating the orientation angle, we applied angle-related IoU with CIoU loss to solve the underivable problem from the calculation of SkewIoU. Evaluation results on three public datasets DLR Munich, VEDAI and UCAS-AOD demonstrate the efficiency of our approach."
Loss Compensation Faster R-CNN을 이용한 문서 이미지 내 표 검출 정확도 향상,2021,"['Table Detection', 'Deep Learning', 'Faster R-CNN', 'Loss Compensation Training']",국문 초록 정보 없음,다국어 초록 정보 없음
VVC 를 위한 CNN 기반의 변환계수 적응적 화질개선 기법,2021,[],"최근 VVC(Versatile Video Coding) 표준 완료 이후 JVET(Joint Video Experts Team)은 NNVC(Neural Network-based Video Coding) AhG(Ad-hoc Group)을 구성하고 인공지능을 이용한 비디오 압축 기술들을 탐색하고 있다. 본 논문에서는 VVC 복원 영상의 DCT 계수를 기반으로 복원 영상을 분류하고, 분류된 각 클래스에 따라 적응적으로 CNN(Convolutional Neural Network) 기반의 화질 개선을 수행하는 VVC 후처리 기법을 제안한다. 실험결과, 제안기법은 AI(All Intra) 부호화 모드에서 1.23% BD-rate 이득을 보였다.",다국어 초록 정보 없음
일반화 능력이 향상된 CNN 기반 위조 영상 식별,2021,"['Fake Image Identification', 'Generative Adversarial Networks', 'Image Forensics', 'CNN', 'Generalization']",국문 초록 정보 없음,다국어 초록 정보 없음
ANN 모델링 및 CNN 기반 예측모델을 이용한 단방향 복합재료의 가로방향 기계적 거동 예측 성능 비교,2021,"['Unidirectional composites (단방향 복합재료', 'UD)', 'Representative volume element (대표체적 요소)', 'Random sequential expansion (무작위 순차 확장)', 'Artificial neural network (인공 신경망', 'ANN)', 'Convolutional neural network (합성곱 신경망', 'CNN)']",국문 초록 정보 없음,다국어 초록 정보 없음
Structural damage detection in presence of temperature variability using 2D CNN integrated with EMD,2021,"['Convolutional Neural Network (CNN)', 'damage detection', 'Deep Learning (DL)', 'Empirical Mode Decomposition (EMD)', 'Structural Health Monitoring (SHM)']",국문 초록 정보 없음,"Traditional approaches for structural health monitoring (SHM) seldom take ambient uncertainty (temperature, humidity, ambient vibration) into consideration, while their impacts on structural responses are substantial, leading to a possibility of raising false alarms. A few predictors model-based approaches deal with these uncertainties through complex numerical models running online, rendering the SHM approach to be compute-intensive, slow, and sometimes not practical. Also, with model-based approaches, the imperative need for a precise understanding of the structure often poses a problem for not so well understood complex systems. The present study employs a data-based approach coupled with Empirical mode decomposition (EMD) to correlate recorded response time histories under varying temperature conditions to corresponding damage scenarios. EMD decomposes the response signal into a finite set of intrinsic mode functions (IMFs). A two-dimensional Convolutional Neural Network (2DCNN) is further trained to associate these IMFs to the respective damage cases. The use of IMFs in place of raw signals helps to reduce the impact of sensor noise while preserving the essential spatio-temporal information less-sensitive to thermal effects and thereby stands as a better damage-sensitive feature than the raw signal itself. The proposed algorithm is numerically tested on a single span bridge under varying temperature conditions for different damage severities. The dynamic strain is recorded as the response since they are frame-invariant and cheaper to install. The proposed algorithm has been observed to be damage sensitive as well as sufficiently robust against measurement noise."
복부 CT 영상에서 밝기값 정규화 및 Faster R-CNN을 이용한 자동 췌장 검출,2021,"['Object Detection', 'Faster R-CNN', 'Inception V2', 'Abdominal CT Images', 'Pancreas']",국문 초록 정보 없음,다국어 초록 정보 없음
고정밀지도(HD-Map) 갱신을 위한 CNN 기반 도로교통안전표지판 분류 모델,2021,[],"고정밀지도는 자율 차량에서 아주 중요한 의미를 가지고 있다. 자율자동차가 안전한 주행을 위해서는 센서들의 고장이나, 눈, 비, 안개, 일출, 일몰 등 환경적 제약이 발생하는 경우, 주변상황을 인지하기 위해 고정밀지도가 필수적이다. 중요한 데이터인 만큼 지도데이터 갱신 주기가 중요하다. 현재는 mobile mapping system(MMS)장비 또는 카메라 영상비전기술로 지도 갱신에 적용하고 있으며, 최근 인식 기술은 딥러닝 기술이 보편화 되고 있다. 딥러닝 기술이 적용이 활발해지면서 양질의 데이터셋과 데이터의 양이 더욱 더 중요해지고 있다. 본 논문에서는 오픈데이터셋이 아닌 한국형 데이터 116 종의 객체에 대한 데이터셋을 구축하고, 객체분류를 위해 Darknet-53 기반의 CNN 알고리즘을 적용 테스트를 진행하였다. 테스트를 위해 경기도 성남시 판교동 지역 일부를 테스트 베드로 선정하여, 다양한 환경적조건(일출, 일몰, 오전, 오후 등)의 영상으로 모델에 대한 성능 평가를 진행하였다.",다국어 초록 정보 없음
자유 공간 광통신 시스템에서 CNN 기반 링크 방위 추정 시 광센서의 해상도에 따른 성능 변화 분석,2021,[],"수백 THz의 높은 주파수 대역의 광신호는 강한 직진성과 넓은 대역폭을 가진다. 이러한 이유로 자유 공간 광통신(FSO) 시스템은 수십 km이상의 초장거리 통신 네트워크의 해법으로 떠오르고 있다. 또한, 광통신 링크 형성과 링크 유지를 위한 positioning, acquisition, and tracking (PAT)시스템 또한 먼 통신 거리와 높은 직진성으로 인하여 그 중요성이 부각되고 있다. 본 논문은 링크 유지를 위한 입사광 방위 추정 과정에 convolutional neural network(CNN) 기법을 도입하고, 광센서의 개수 증가에 따른 정확도와 시스템 복잡도의 변화를 프로세싱 해상도에 따라 비교 분석하였다.",다국어 초록 정보 없음
Continuous Wavlet Transform 을 활용한 CNN 기반 인접부재 변형율 예측 기법,2021,"['연속웨이블릿 변환', '구조물의 응답 예측', 'CNN', 'Continous Wavlet Tranform', 'Prediction of structure response']",국문 초록 정보 없음,다국어 초록 정보 없음
건설 재해사례 텍스트 데이터의 효과적 분류를 위한 CNN 및 RNN 알고리즘 비교,2021,"['건설 안전', '비정형 데이터', '텍스트 분류', '딥러닝', 'Construction Safety', 'Unstructured Data', 'Text Classification', 'Deep Learning', 'CNN', 'RNN']",국문 초록 정보 없음,다국어 초록 정보 없음
드론을 통한 산불 감지를 위한 효율적인 CNN 아키텍처,2021,"['Convolution neural network', 'Drones', 'Forest fire detection', 'Unmanned aerial vehicles']",국문 초록 정보 없음,"Forest fire is one of the most dangerous disasters worldwide, due to which its management is a key concern of the research community to prevent social, ecological, and economic damages. Wildfires are extremely catastrophic disasters that lead to the destruction of forests, human assets, reduction of soil fertility and cause global warming. To overcome such kind of losses early fire detection and quick response is the key concern of research community. Therefore, in this paper, we propose a lightweight convolution neural network (CNN) method to efficiently detect the forest fire for unmanned aerial vehicles (UAVs) or drones. For the experimental evaluations, we develop an aerial images dataset from YouTube, movies, and google images. The results of the proposed architecture reveal its good performance in terms of 96% accuracy."
Pixel level detection of rat liver fibrosis using Mask R-CNN,2021,"['Digital pathology', 'Deep learning', 'Liver fibrosis', 'Non-clinical study', 'Mask R-CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
X-ray Fluorescence (XRF) 물질분석을 위한 물질별 Convolution Neural Network (CNN) 모델 성능 평가,2021,"['정량화', 'XRF imaging', 'Deep-Learning', 'Convolutional Neural Network (CNN)']",국문 초록 정보 없음,다국어 초록 정보 없음
Detection and quantification of bolt loosening using RGB-D camera and Mask R-CNN,2021,"['bolt-loosening detection', 'bolt-loosening quantification', 'RGB-depth camera', 'Mask R-CNN', 'deep learning']",국문 초록 정보 없음,"Bolt loosening is one of the most common types of damage for bolt-connected plates. Existing vision techniques detect bolt loosening based on the measurement of bolt rotation or the exposure of bolt threads. However, these techniques examine bolt tightness only in a qualitative manner, or require a reference measurement at the initially tightened state of the bolt for quantitative estimation. In this study, the exposed shank length of a bolt is quantitatively measured using an RGB-depth camera and a mask-region-based convolutional neural network but without requiring any measurement from the initial state of the bolt. The performance of the proposed technique is validated by conducting lab-scale experiments, in which the angle and distance of the camera are varied with respect to a target inspection area. The proposed technique successfully detects bolt loosening at exposed shank length over 3 mm with a resolution of 1 mm and 97% accuracy at different camera angles (40°–90°) and distances (up to 65 cm)."
CNN 모델을 활용한 미국 주식시장에서의 가치투자 분석,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 딥러닝을 이용한 범죄 유형별 거리의 물리적 요소 비교,2021,"['범죄예방 환경설계', '합성곱신경망', '5대범죄', '도시환경', 'CPTED', 'Convolutional neural network', '5 Major Crimes', 'Urban Environment']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN 모델을 이용한 실시간 미술전시 웹 플랫폼,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반 딥러닝을 이용한 패션 아이템 분류 및 결합,2021,"['인공지능', '딥러닝', '머신러닝', '합성곱 신경망', '생성적 적대 신경망', '패션', 'Artificial Intelligence', 'Deep Learning', 'Machine Learning', 'Convolutional Neural Network', 'Generative Adversarial Network', 'Fashion']",국문 초록 정보 없음,"In this paper, in order to implement an artificial intelligence system that can appropriately match fashion items according to the situation, a deep learning model based on convolutional neural network was designed after labeling with 10 fashion items based on fashion-MNIST. Based on the designed deep learning model, 45,000 fashion images were used as a training dataset, and 15,000 fashion images were used as a verification dataset, and deep learning was performed with a total of 15 epochs. As a result of the deep learning execution, the training data learning accuracy 96% and the verification data learning accuracy 94% were output in the accuracy evaluation of fashion item classification. In this paper, we constructed a dataset that can provide 7 types of fashion matching based on the implemented artificial intelligence fashion item classification system. The established dataset is expected to become the basis of an artificial intelligence fashion matching service that can satisfy various fashion needs of individuals in the future."
CNN 기반의 이미지 회귀 모델 학습을 위한 전처리 기법 분석,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반의 FMCW 레이더 신호 식별,2021,[],"최근 자율주행 자동차를 위한 기술들이 활발히 연구되고 있다. 그중에서 긴급상황 자동 브레이크 시스템은 라이다, 레이더 등을 사용하여 주변 환경을 인식하고 사고를 방지한다. 기존의 딥 러닝을 사용한 분류기들은 거리-도플러맵, 마이크로도플러 등을 사용한다. 이러한 이미지는 객체가 레이더를 바라보는 각도에 따른 이미지의 변화가 크다. 따라서 본 논문에서는 분류성능을 향상시키기 위해서 거리-도플러맵과 포인트클라우드맵을 사용한 식별기를 제안한다. 거리-도플러맵을 사용했을 때는 평균 85%의 분류 성능을 얻었으며, 제안한 거리-도플러맵과 포인트클라우드맵을 같이 사용했을 때는 평균 92%의 향상된 성능을 얻었다.",다국어 초록 정보 없음
CNN 기반 저조도 영상 화질 개선 및 색상 보정,2021,[],국문 초록 정보 없음,"Recently, the end-to-end deep learning based methods have been successfully employed in the field of denoising in low-light environment. However these methods tend to cause color distortion artifact.  To solve this problem, In this paper we present a lowlight image enhancement network with color correction sub-network. In addition, we introduce a loss function for the proposed network. Experimental results demonstrate that the proposed network and loss functions can effectively enhance a quality of low light image."
CNN 기반 실시간 객체 탐지 및 광학 문자 인식을 활용한 쓰레기 수거 시스템,2021,"['Untact area', 'Deep learning', 'Embedded system', 'Garbage dumping']","코로나 바이러스의 영향으로 언택트 시대가 도래하며 택배, 배달 음식 등의 수요가 증가함에 따라 생활 쓰레기의 불법 투기가 급증하고 있다 최근에는 딥러닝을 활용하여 투기 행위를 감지하는 방법도 제안되고 있지만, 모델의 복잡성으로 인해 단일 임베디드 시스템으로 운용되기 어렵다는 한계점을 가진다 이에 따라 본 논문에서는 투기지역을 촬영하는 각각의 CCTV에 연결되는 단일 임베디드 시스템에서 활용 가능한 딥러닝 기반의 쓰레기 수거 시스템을 제안한다.","With the advent of the untact era due to the corona virus, illegal dumping of household waste is increasing rapidly as the demand for home delivery service increases. Recently, To recognize dumping action using deep learning has been proposed, but it has a limitation in that it is difficult to operate as a single embedded system due to the model complexity. Thus, in this paper, we propose garbage collection system based on deep learning that can be used in a single embedded system connected to each CCTV with the dumping area."
CNN 을 이용한 Molybdenum 적층제조의 실시간 모니터링 알고리즘 개발,2021,"['Real-time monitoring', 'Molybdenum', 'Wire+arc additive manufacturing', 'Image transformation', 'Convolutional neural network']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN 추론 연산 가속을 위한 곱셈 최적화,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 과 LSTM 을 활용한 교차로에서의 운전자 의도 예측,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN Attention 네트워크 기반 다중 질병을 가진 환자 유사성 측정 연구,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
Mask R-CNN을 이용한 평직 복합재료 단면 이미지 분할,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
Denoising CNN 기반 시계열 데이터의 스펙트로그램 이미지를 이용한 리튬 이온 배터리 잔여수명 예측,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
Mask R-CNN을 이용한 드론 영상에서의 비닐하우스 탐지,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
OpenPose와 CNN 기반 수어 영상 번역 서비스 개발,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
도심지에서의 CNN 기반 5G 밀리미터파 경로손실 모델,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
PIR과 CNN 딥러닝을 이용한 위험상황 탐지에 관한 연구,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
경량 CNN 모델의 데이터 분포 다양성에 강인한 초저정밀도 채널별 양자화 인식 훈련 기법,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
Bilingual Char-CNN을 이용한 Out-of-domain 한·영 병렬 코퍼스 필터링,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
Cascade Mask R-CNN을 이용한 화학 문서 내 표 검출,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
라벨링오류에 강인한 CNN 모델 학습기법,2021,[],"본 논문은 노이즈 레이블이 섞인 데이터세트에 대해 오직 한개의 네트워크만 사용하여 강인한 학습을 하는 기법을 제안한다. 제안된 방법은 학습단계에서 알맞게 라벨링된 샘플을 알아내기 위해 두 종류의 샘플 선택 기준을 사용한다. 첫번째 기준은 이전 시간들의 모델 앙상블의 손실함수값이다. 시간적으로 분리된 모델 앙상블을 만들기 위해 주기적 학습률을 적용한다. 이전 시간적 앙상블에 대한 손실함수값은 깨끗한 샘플을 감지하는 기준을 제공한다. 두 번째 기준은, 데이터 변형을 적용하여 다시점으로 예측을 하게하여, 이 예측들의 일치가 학습과 샘플 선택을 하는데 둘다 사용되게 한다. 이러한 기준들을 같이 사용함으로 써 알맞게 라벨링된 샘플을 정확하게 감지할 수 있고, 여러 개의 네트워크를 사용한 방법보다 더 나은 성능을 도달할 수 있다. 본 연구는 CIFAR-10, CIFAR-100, MNIST 등 일반적으로 널리 사용되는 데이터세트를 이용하여 수행되었으며, 기존 방법들에 비해 높은 성능을 도출하는 것을 확인하였다.",다국어 초록 정보 없음
전처리를 이용한 CNN 악성코드 탐지 기법 소개,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
Complex-valued를 사용한 CNN 구조를 이용하여 Remote PPG 예측 모델 구현,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
Music Genre Classification using CNN architecture with feature concatenation,2021,"['Convolutional Neural Network', 'Music Genre Classification', 'Mel Spectrogram', 'Mel-frequency Cepstral Coefficient']",국문 초록 정보 없음,다국어 초록 정보 없음
소량의 학습 데이터에 대한 CNN 분류 성능 향상 방법,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
소량의 학습 데이터에 대한 CNN 분류 성능 향상 방법,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
재실자 착의량 산출을 위한 CNN 기반 의복 분류 모델 성능 분석,2021,"['예상평균온열감', '착의량', '합성곱신경망', '분류모델', 'Predicted Mean Vote', 'Clothing Insulation', 'Convolutional Neural Network', 'Classification Model']",국문 초록 정보 없음,다국어 초록 정보 없음
Near Zero-Skipping을 활용한 저전력 CNN 네트워크,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
Lightweight Convolutional Neural Network (CNN) based COVID-19 Detection using X-ray Images,2021,"['Coronavirus', 'Computer Tomography', 'Convolutional Neural Network', 'X-ray']",국문 초록 정보 없음,"In 2019, a novel coronavirus (COVID-19) outbreak started in China and spread all over the world. The countries went into lockdown and closed their borders to minimize the spread of the virus. Shortage of testing kits and trained clinicians, motivate researchers and computer scientists to look for ways to automatically diagnose the COVID-19 patient using X-ray and ease the burden on the healthcare system. In recent years, multiple frameworks are presented but most of them are trained on a very small dataset which makes clinicians adamant to use it. In this paper, we have presented a lightweight deep learning base automatic COVID-19 detection system. We trained our model on more than 22,000 dataset X-ray samples. The proposed model achieved an overall accuracy of 96.88% with a sensitivity of 91.55%."
강건 HSV 필터를 적용한 CNN 기반의 인간행동복제를 통한 서비스 로봇차량 제어 알고리즘 구현,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
높은 정밀도를 위한 CNN 기반의 개선된 모션 인식기,2021,"['Artificial intelligence', 'Convolution neural network', 'Deep learning', 'Motion recognition', 'Human activity recognition (HAR)', 'Sensors', 'Time series data']",국문 초록 정보 없음,"Motion recognition (MR) is to understand and analyze the movements of things. This technique can categorize the movements into several activities and enables us understand the movements. Among the MR, human activity recognition (HAR) is to recognize what a person is doing. HAR has various applications such as rehabilitation engineering, health care, human machine interactive, security based on vision. HAR can be achieved with the help of sensor data or camera based vision information. The vision information results from monocular/binocular cameras, whereas the sensor data in general are from wearable sensors or sensors embedded in smartphones. The measured data are analyzed to carry out HAR. The data analysis methods include machine learning and neural networks. In the neural network based data analysis, the introduced time series data are converted into images, and the images are used for training of neural networks. In this paper, a new accuracy enhanced method is proposed in convolution neural network based HAR. If two images have their unique features, person may recognize the difference between the two images. Motivated from this intuition, this paper suggests a new method to add the unique feature, resulting in more precise accuracy. In this paper, firstly an optimal image conversion method is found via base line tests and secondly a reasonable neural network without overfitting is designed by trimming hyper parameters. From the experimental results, it is verified that the proposed method is valid and effective."
이미지로 변환한 악성코드 CNN 탐지,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
A Study on a Model of Multi-head 1D-CNN-GRU and Attention Mechanism for Human Activity Recognition,2021,"['One-dimensional convolutional neural network', 'Gated recurrent unit', 'Attention mechanism', 'Human activity recognition', 'Data augmentation', 'Inertial measurement unit']",국문 초록 정보 없음,다국어 초록 정보 없음
An Evaluation Method for Generalization Errors of CNN using Training Data,2021,"['합성곱 신경망', '일반화 오류', '반응 셋', '상대적 일반화 오류', 'convolutional neural network', 'generalization error', 'response set', 'relative generalization error']",국문 초록 정보 없음,다국어 초록 정보 없음
비디오 세그먼트 단위 부분 복사 검출을 위한 CNN Local Feature의 Aggregation 방법별 성능 비교,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
캠코딩 및 Black-Border 변형 동영상에서 YOLO CNN 모델을 이용한 원본 영상 영역 검출 방법,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
근복사 비디오 검출을 위한 프레임 CNN 특징벡터 융합 방법,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
다수의 CCTV 영상 분석을 위한 확장성 있는 CNN 기반 실시간 분석 시스템 설계,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
Waste Classification by Fine-Tuning Pre-trained CNN and GAN,2021,"['deep learning', 'image classification', 'convolutional neural networks', 'transfer learning', 'waste classification', 'recycling']",국문 초록 정보 없음,"Waste accumulation is becoming a significant challenge in most urban areas and if it continues unchecked, is poised to have severe repercussions on our environment and health. The massive industrialisation in our cities has been followed by a commensurate waste creation that has become a bottleneck for even waste management systems. While recycling is a viable solution for waste management, it can be daunting to classify waste material for recycling accurately. In this study, transfer learning models were proposed to automatically classify wastes based on six materials (cardboard, glass, metal, paper, plastic, and trash). The tested pre-trained models were ResNet50, VGG16, InceptionV3, and Xception. Data augmentation was done using a Generative Adversarial Network (GAN) with various image generation percentages. It was found that models based on Xception and VGG16 were more robust. In contrast, models based on ResNet50 and InceptionV3 were sensitive to the added machine-generated images as the accuracy degrades significantly compared to training with no artificial data."
Measuring similarity between images using CNN trained with image caption on academic papers,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
변동 재고 추적 방식을 이용한 CNN 기반의 스마트 냉장고 상품 인식,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
Beam forming 기술에서 사용하기 위한 10T-SRAM을 활용한 CNN 알고리즘 프로세스 인 메모리,2021,[],국문 초록 정보 없음,"When transferring data using processor-in-memory, the stabiliy of memory cells is directly related to the extent of data corruption. This is directly related to the stability of data transmission in order to locate and transmit the equipment being received by beamforming technology. In order to improve this, this paper proposes 10T-SRAM which is more stable than conventional 6T-SRAM."
색공간 필터링 및 딥러닝 기반의 CNN 모델을 이용한 화염 감지에 관한 연구,2021,[],국문 초록 정보 없음,"Technology development and social interest in fire prevention and safety are increasing, but currently installed fire detectors are steadily raising malfunction problems such as non-fire information through conventional sensors. This paper pre-processed an image using HSV color model and selective search, which is a candidate region proposal algorithm, and determined whether a flame occurred through a deep learning-based inference model to compensate for this problem. As a result, unnecessary background areas could be filtered in the input image, and the false detection rate could be reduced by effectively inferring the area where the flame exists."
FMCW 거리-도플러 이미지 중첩을 통한 CNN 기반 드론 탐지 및 식별,2021,[],FMCW 레이더의 거리-도플러 이미지의 드론별 미세 도플러 특징이 거리가 멀어질수록 희미해지는 문제를 해결하기 위해서 거리-도플러 이미지 중첩 방법을 제안하였다. 중첩 이미지를 이용하여 Alexnet 전이학습 기반 분류기를 이용하여 3 종의 드론에 대한 식별 시험을 시행한 결과 상당한 식별 성능 향상을 관찰할 수 있었다.,다국어 초록 정보 없음
배관 내부 결함 판별을 위한 초음파 신호와 CNN 적용 연구,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
다른 객체의 일부가 포함된 이미지에서 음식물 이물질 탐지를 위한 CNN 모델 개발,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
A Study on the Present Perfect used for Topic Communication in CNN and Yonhap News Reports,2021,"['news', 'present perfect', 'marked type', 'topic emphasis', 'topic flow']",국문 초록 정보 없음,"The purpose of this research is to figure out the features of the present perfect tense used in news reports especially from a perspective of topic flow. Based on two data sets, we analyzed topic types that the present perfect carried and reached following results. First, the present perfect was used for four topic types such as ‘topic introduction’ in the head, ‘topic shift’ and ‘topic elaboration’ in the middle, and ‘topic termination’ in the end texts. Second, the present perfect was found to convey more general information than specific information. The present perfect conveying general information includes the types used for ‘topic introduction’ delivering hot news in the lead, ‘topic shift’ providing other new information derived from the lead, and ‘topic termination’ expressing the final summary in the end. The present perfect carrying specific information includes ‘topic elaboration’. Third, the present perfect was also used for ‘topic emphasis’ as the present perfect, a more marked type than simple tenses, entered various locations amongst multiple past and present simples to highlight the gist of news topics in a variety of contexts."
6 륜 서비스 로봇 차량의 코너링 성능 향상을 위한 CNN 기반 인간 주행패턴 복제 알고리즘 설계,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
비원형 섬유형상을 갖는 단방향 복합재료의 기계적 거동예측을 위한 CNN 및 DNN 모델링 및 검증,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
Analysis and Prediction of Surface Condition of Artificial Skin Based on CNN and ConvLSTM,2021,"['artificial skin', 'image prediction', 'Convolutional Neural Network', 'ConvLSTM', 'deep learning', 'image analysis']",국문 초록 정보 없음,"Recently, with greater focus on ethical issues related to animal testing, interest in artificial skin platforms has increased in both cosmetic and medical industries. Artificial skin comprises dermal and epidermal layers. In particular, proper differentiation and proliferation of keratinocytes in the epidermal layer has a considerable influence on the role of the skin as a barrier. However, during 3D culture, real-time monitoring and evaluation of the tissue being cultured are difficult. In this study, Convolutional Neural Network and Convolutional Long Short-Term Memory were utilized for prediction of the artificial skin image. To evaluate the designed models, the similarity between the predicted artificial skin image was compared with the real image. We verified the possibility and practicability of artificial skin image analysis and prediction using neural network models. In the future, this approach could be applied to image prediction under certain conditions, such as inflammatory or skin diseases."
Synthetic Deep Neural Network Design for Lidar-inertial Odometry Based on CNN and LSTM,2021,"['Deep learning', 'Lidar-inertial odometry', 'loss function', 'pose estimation', 'synthetic neural network.']",국문 초록 정보 없음,"This paper proposes an integrated navigation algorithm based on the deep learning method using lidar and inertial measurements. The proposed method develops a new synthetic structure of neural networks for implementing the Lidar-inertial odometry to generate a 6 degree of freedom pose estimation. The proposed network consists of component neural networks that reflect each sensor’s characteristics, then an integrating network for combining estimates from heterogeneous sensors at the terminal stage. To secure an efficient estimation performance, a compound loss function design is exploited. The performance of the proposed deep learning-based LIO algorithm was verified through artificially generated data sets based on a high fidelity dynamics simulator. Instead of using the well-known reference data set of ground vehicles, the employed data set reflects the full 3D dynamic characteristics of the drone as well as low-cost sensor characteristics considering onboard implementation. Through the flight simulator data set, the estimation performance of the proposed synthetic network was demonstrated."
Inspecting Method for Defective Casting Products with Convolutional Neural Network (CNN),2021,['Convolution neural network · Defect inspection · Casting product · Deep learning'],국문 초록 정보 없음,"It is essential to conduct the quality control for gauranteeing sound products after finishing conventional manufacturing processes. Vision-based inpection system has been extensively applied to various industries linked with concept of the smart factory sin c e it does not only enhance the inspecting accuracy, but also decrease the cost for the human inspection, substantially. This paper mainly concerns the development of the inspecting system for the casting products with supported by the convolutional neural network, which makes it possible to detect various types of defects such as blow hole, chipping, crack, and wash automatically. To obtain high accuracy in inspecting system, it does not only require sub-partitioning of the original images, but also apply multiple labeling according to the order of the sub-images and the existence of the defects. Performance of the proposed inspecting algorithm has been validated with the 400 casting products, in which it exhibits substantially high accuracy more than 98%, experimentally."
Connection stiffness reduction analysis in steel bridge via deep CNN and modal experimental data,2021,"['structural monitoring', 'machine learning', 'steel truss bridge', 'vibration', 'numerical simulation', 'damage detection and localization', 'convolutional neural networks']",국문 초록 정보 없음,"This study devises a novel approach, namely quadruple 1D convolutional neural network, for detecting connection stiffness reduction in steel truss bridge structure using experimental and numerical modal data. The method is developed based on expertise in two domains: firstly, in Structural Health Monitoring, the mode shapes and its high-order derivatives, including second, third, and fourth derivatives, are accurate indicators in assessing damages. Secondly, in the Machine Learning literature, the deep convolutional neural networks are able to extract relevant features from input data, then perform classification tasks with high accuracy and reduced time complexity. The efficacy and effectiveness of the present method are supported through an extensive case study with the railway Nam O bridge. It delivers highly accurate results in assessing damage localization and damage severity for single as well as multiple damage scenarios. In addition, the robustness of this method is tested with the presence of white noise reflecting unavoidable uncertainties in signal processing and modeling in reality. The proposed approach is able to provide stable results with data corrupted by noise up to 10%."
다른 객체의 일부가 포함된 이미지에서 음식물 이물질 탐지를 위한 CNN 모델 개발,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
Ball Grid Array Solder Void Inspection Using Mask R-CNN,2021,"['Computer vision system', 'Digital image processing', 'BGA', 'Automatic X-Ray inspection', 'Solder joints void', 'Object segmentation', 'Deep learning']",국문 초록 정보 없음,"The ball grid array is one of the packaging methods that used in high density printed circuit board. Solder void defects caused by voids in the solder ball during the BGA process do not directly affect the reliability of the product, but it may accelerate the aging of the device on the PCB layer or interface surface depending on its size or location. Void inspection is important because it is related in yields with products. The most important process in the optical inspection of solder void is the segmentation process of solder and void. However, there are several segmentation algorithms for the vision inspection, it is impossible to inspect all of images ideally. When X-Ray images with poor contrast and high level of noise become difficult to perform image processing for vision inspection in terms of software programming. This paper suggests the solution to deal with the suggested problem by means of using Mask R-CNN instead of digital image processing algorithm. Mask R-CNN model can be trained with images pre-processed to increase contrast or alleviate noises. With this process, it provides more efficient system about complex object segmentation than conventional system."
Inception-CNN 기반 링크 통과 속도 예측 모델링,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
이미지 분할 모델을 이용한 Mask R-CNN 모델 정확도 향상 기법,2021,"['도로노면', '이미지 분할', '이미지 병합', '이미지 분석', '정확도 향상', 'Pavement Surface', 'Image Cropping', 'Image Merge', 'Image Analysis', 'Accuracy Enhancement']",국문 초록 정보 없음,"This paper proposes a method to improve the accuracy of artificial intelligence analysis of computer images of road surfaces. In the past, to analyze the road surface image, the size was reduced and then processed. In this process, as a result of road surface analysis, there was a problem that the quality of the image was degraded and the micro-crack on the road surface disappeared. In order to solve the above problem, in this paper, image segmentation and image cropping-merging models were combined in the preprocessing stage of the artificial intelligence model to eliminate the loss of resolution, and the micro-crack pattern was created through data scale conversion and adjustment of the number of training data according to the importance of crack patterns. Effectively detected. Finally, as a result of comparing with the previous image scale reduction method, it was confirmed that the accuracy was improved when analyzed through the proposed method."
Road Type Identification Ahead of the Tire Using D-CNN and Reflected Ultrasonic Signals,2021,"['Ultrasonic sensor', 'Road type identification', 'Friction coefficient', 'Short-time Fourier transform', 'Machinelearning', 'Deep convolutional neural network']",국문 초록 정보 없음,"Every land moving object accelerates or decelerates based on the frictional coefficient of the road surface. It has been known that this coefficient on the road is determined by the type of road surface. In this work, we propose a simplistic, machine-learning based solution to estimate the road type using the reflected ultrasonic signals paired with ultrasonic transmitter and receiver. Since the reflected signal contains the material information of the surface due to the difference in the surface roughness and acoustic impedance, different characteristics can be observed for each frequency of the reflected signal. To exploit such characteristics, the signals are transformed into the frequency domain using short-time Fourier transform. In addition, a deep convolutional neural network is applied as the road identifier due to its well-known representational power. In order to verify the aforementioned ideas, the ample database consisting of eight types of road surfaces are obtained with the ultrasonic sensors. And then, the database is used to train the model, as well as to evaluate the accuracy of the trained model. It can be seen that the proposed method makes it easier and more accurate to identify the type of road surface than the conventional methods."
Moving Object Detection with Single Moving Camera and IMU Sensor using Mask R-CNN Instance Image Segmentation,2021,['Moving camera · Motion estimation · Moving object detection · Deep learning'],국문 초록 정보 없음,"This paper describes a new method for the moving object detection using the IMU sensor and instance image segmentation. In the proposed method, the feature points are extracted by the detector, and the initial fundamental matrix is calculated from the IMU data. Next, the epipolar line is used to classify the extracted feature points. From the background feature point matching, fundamental matrix is calculated iteratively to minimize the error of classification. After the feature point classification, image segmentation is used to enhance the quality of the classification result. The proposed method is implemented and tested with real-world driving videos, and compared with the previous works."
"시계열 데이터에 대한 새로운 특징 추출 알고리즘 제시 및 군집화 성능 분석 : RP-CNN Autoencoder과 Wavelet, Autoencoder 비교",2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
Generating Synthetic Dataset for Scale-invariant Instance Segmentation of Food Materials based Upon Mask R -CNN,2021,"['scale-invariant', 'instance segmentation', 'synthetic dataset', 'food materials']",국문 초록 정보 없음,"This work proposes a scale-invariant instance segmentation method for images acquired from a real-time camera. It is challenging to detect and segment an exact shape by removing background (named as an instance) of a deformable semi-solid object such as food materials. In this work, we consider the segmentation with the cases of various sizes of an object and multiple objects overlapped with each. To do this, we address an augmented dataset generation method, which extends dataset from small number of base objects, a fundamental dataset. Our method is based upon data augmentation, which is well known that it is an effective way to improve the segmentation performance. Our method addresses the generation of dataset with various scales using small number of original dataset. It is relatively simple in method but provides better performance. We also proposed how to choose a target object(food material) with its centroid for grasping. Through diverse experiments using real-time images, we demonstrate that the proposed algorithm segments scale-invariant object masks and is successfully implemented for a robotic hand to grasp a food material. It is also compared with the state-of-the-art segmentation algorithm. As a result, the proposed method shows 74%, 85%, and 78% in accuracy, recall, and precision while the original dataset shows 67%, 79%, and 70%, respectively."
실내 환경에서 Chirp Emission과 Echo Signal을 이용한 심층신경망 기반 객체 감지 기법,2021,"['Audio-Visual', 'Chirp', 'echolocator', 'Deep convolutional neural network (DCNN)']",국문 초록 정보 없음,"Humans mainly recognize surrounding objects using visual and auditory information among the five senses (sight, hearing, smell, touch, taste). Major research related to the latest object recognition mainly focuses on analysis using image sensor information. In this paper, after emitting various chirp audio signals into the observation space, collecting echoes through a 2-channel receiving sensor, converting them into spectral images, an object recognition experiment in 3D space was conducted using an image learning algorithm based on deep learning. Through this experiment, the experiment was conducted in a situation where there is noise and echo generated in a general indoor environment, not in the ideal condition of an anechoic room, and the object recognition through echo was able to estimate the position of the object with 83% accuracy. In addition, it was possible to obtain visual information through sound through learning of 3D sound by mapping the inference result to the observation space and the 3D sound spatial signal and outputting it as sound. This means that the use of various echo information along with image information is required for object recognition research, and it is thought that this technology can be used for augmented reality through 3D sound."
합성곱 신경망 기반 물체 인식과 탑승 감지 센서를 이용한 개인형 이동수단 주행 안전 보조 시스템 개발,2021,[],국문 초록 정보 없음,A recent spread of personal mobility devices such as electric kickboards has brought about a rapid increase in accident cases. Such vehicles are susceptible to falling accidents due to their low dynamic stability and lack of outer protection chassis. This paper presents the development of an automatic emergency braking system and a safe starting system as driving assistance devices for electric kickboards. The braking system employed artificial intelligence to detect nearby threaening objects. The starting system was developed to disable powder to the motor until when the driver's boarding is confirmed. This study is meaningful in that it proposes the convergence technology of advanced driver assistance systems specialized for personal mobility devices.
농작물 질병분류를 위한 전이학습에 사용되는 기초 합성곱신경망 모델간 성능 비교,2021,"['Crop Disease', 'Transfer Learning', 'Convolutional Neural Network', 'Performance Evaluation']",국문 초록 정보 없음,"Recently, transfer learning techniques with a base convolutional neural network (CNN) model have widely gained acceptance in early detection and classification of crop diseases to increase agricultural productivity with reducing disease spread. The transfer learning techniques based classifiers generally achieve over 90% of classification accuracy for crop diseases using dataset of crop leaf images (e.g., PlantVillage dataset), but they have ability to classify only the pre-trained diseases. This paper provides with an evaluation scheme on selecting an effective base CNN model for crop disease transfer learning with regard to the accuracy of trained target crops as well as of untrained target crops. First, we present transfer learning models called CDC (crop disease classification) architecture including widely used base (pre-trained) CNN models. We evaluate each performance of seven base CNN models for four untrained crops. The results of performance evaluation show that the DenseNet201 is one of the best base CNN models."
저해상도 영상 자료를 사용하는 얼굴 표정 인식을 위한 소규모 심층 합성곱 신경망 모델 설계,2021,"['Convolutional Neural Networks', 'Facial Expression Recognition', 'Design of CNN architecture', 'Low Resolution Image', '합성곱 신경망', '얼굴 표정 인식', '합성곱 신경망 구조 설계', '저해상도 영상']",인공 지능은 놀라운 혜택을 제공하는 우리 삶의 중요한 부분이 되고 있다. 이와 관련하여 얼굴 표정 인식은 최근 수십 년 동안 컴퓨터 비전 연구자들 사이에서 뜨거운 주제 중 하나였다. 저해상도 이미지의 작은 데이터 세트를 분류하려면 새로운 소규모 심층 합성곱 신경망 모델을 개발해야 한다. 이를 위해 소규모 데이터 세트에 적합한 방법을 제안한다. 이 모델은 기존 심층 합성곱 신경망 모델에 비해 총 학습 가능 가중치 측면에서 메모리의 일부만 사용하지만 FER2013 및 FERPlus 데이터 세트에서 매우 유사한 결과를 보여준다.,"Artificial intelligence is becoming an important part of our lives providing incredible benefits. In this respect, facial expression recognition has been one of the hot topics among computer vision researchers in recent decades. Classifying small dataset of low resolution images requires the development of a new small scale deep CNN model. To do this, we propose a method suitable for small datasets. Compared to the traditional deep CNN models, this model uses only a fraction of the memory in terms of total learnable weights, but it shows very similar results for the FER2013 and FERPlus datasets."
합성곱신경망을 이용한 초분광영상기반 토양수분 예측,2021,"['Soil moisture', 'Plant growth', 'Hyperspectral image', 'Spectral band', 'CNN', '토양수분', '식물생육', '초분광영상', '분광밴드', '합성곱신경망']","식물의 생육은 수분에 의해서 크게 좌우되기 때문에 토양이 재배하는 식물에 최적의 수분을 가지도록 조절하는 것은 중요하다. 최근 초분광영상을 통하여 식물의 생육정보를 자동으로 분석하는 연구가 진행되고 있으며 토양의 수분함량을 측정하는 것도 포함한다. 그러나 초분광의 경우 많은 분광밴드에서 나타나는 방대한데이터로 인하여 분석과정이 복잡하기 때문에 사용이 어렵다. 본 논문에서는 초분광영상의 복잡도를 합성곱신경망 (Convolution Neural Network, CNN)을 통하여 해결하는 방법을 제안한다. 제안한 방법은 대상 초분광의 전체 대역을 심층학습방법을 사용하여 자동 분석하기 때문에 각 영상에 대해 인식에 필요한 특정 대역을 찾는 노력을 할 필요가 없다. 제안 시스템의 유효성을 보이기 위해서 토양에서 얻은 초분광영상을 이용한수분함량분석 실험을 수행하고 결과를 보인다.",다국어 초록 정보 없음
합성곱 신경망을 이용한 실시간 상추 생육 센싱 연구,2021,"['합성곱 신경망', '스테레오 카메라', 'RGB', 'CNN', '상추', '실시간 센싱', '생육 지표']","원예 작물의 생육 지표로 사용되는 생체중, 건물중, 높이, 엽면적, 직경은 증산 및 광합성과 밀접한 관계가 있고, 이러한 생육 지표는 작물 생산성을 정량화하여 최적의 환경, 양분, 관수 제어 전략을 수립하는데 활용될 수 있다. 따라서 정확한 생육 지표 측정은 매우 중요하지만, 생육 지표를 측정하기 위한 전통적인 방법은 파괴적이고 인적 자원을 많이 필요로 하여 시간과 비용 소모가 클 뿐만 아니라, 시료의 채취 방법이나 시료 상태에 따라 신뢰성이 떨어질 수 있다. 생육 지표 측정에는 정확성 뿐만 아니라 작물 성장 단계별 양액의 변량 공급을 위해 실시간으로 작물의 생육 정도를 측정하는 기술 또한 필요하다. 최근 딥러닝 기술의 발전으로 3차원 영상 데이터를 이용한 합성곱 신경망과 같은 기술이 도입되고 있어 생육 센싱을 비롯한 분야에서 농업 적용성이 높아지고 있다. 본 연구에서는 RGB 채널과 깊이 정보를 이용하여 4개 품종 상추의 생체중, 건물중, 높이, 엽면적, 직경을 예측할 수 있는 합성곱 신경망 기반 모델을 개발하고, 예측 성능을 구명하였다. 사용된 재료는 2021년 6월 바게닝긴대학교 주최 온라인 인공지능 경진대회에서 제공한 상추 데이터이며, 해당 데이터는 인텔 Realsense D435 카메라를 이용하여 수집된 상추의 RGB와 깊이 정보이다. 선행 연구에서 개발한 자동 3D 영상 데이터 수집 시스템 및 모니터링 시스템을 개선하여 합성곱 신경망 모델 적용이 가능하도록 하였으며, 측정 항목별 합성곱 신경망 예측 모델의 측정 성능을 분석한 결과 예측 모델은 결정계수 0.9 이상의 정확도를 나타냈으며 모니터링 시스템에서 이미지 하나당 평균 150 ms의 처리 속도를 나타내어 실시간 생육 지표 예측 가능성을 보였다.",다국어 초록 정보 없음
인공 신경망 가속기 온칩 메모리 크기에 따른 주메모리 접근 횟수 추정에 대한 연구,2021,"['CNN', 'Simulator', 'Main Memory Access', 'Hardware Accelerator', 'Global Buffer', 'Scratchpad']","이미지 인식 및 패턴 감지를 위해 널리 사용되는 알고리즘 중 하나는 convolution neural network(CNN)이다. CNN에서 대부분의 연산량을 차지하는 convolution 연산을 효율적으로 처리하기 위해 외부 하드웨어 가속기를 사용하여 CNN 어플리케이션의 성능을 향상 시킬 수 있다. 이러한 하드웨어 가속기를 사용함에 있어서 CNN은 막대한 연산량을 처리하기 위해 오프칩 DRAM에서 가속기 내부의 메모리로 데이터를 갖고 와야 한다. 즉 오프칩 DRAM과 가속기 내부의 온칩 메모리 혹은 글로벌 버퍼 사이의 데이터 통신이 CNN 어플리케이션의 성능에 큰 영향을 끼친다. 본 논문에서는 CNN 가속기 내의 온칩 메모리 혹은 글로벌 버퍼의 크기에 따른 주메모리 혹은 DRAM으로의 접근 횟수를 추산할 수 있는 시뮬레이터를 개발하였다. CNN 아키텍처 중 하나인 AlexNet에서, CNN 가속기 내부의 글로벌 버퍼의 크기를 증가시키면서 시뮬레이션 했을 때, 글로벌 버퍼 크기가 100kB 이상인 경우가 100kB 미만인 경우보다 가속기 내부와 오프칩 DRAM 간의 접근 횟수가 0.8배 낮은 것을 확인 했다.","One widely used algorithm for image recognition and pattern detection is the convolution neural network (CNN). To efficiently handle convolution operations, which account for the majority of computations in the CNN, we use hardware accelerators to improve the performance of CNN applications. In using these hardware accelerators, the CNN fetches data from the off-chip DRAM, as the massive computational volume of data makes it difficult to derive performance improvements only from memory inside the hardware accelerator. In other words, data communication between off-chip DRAM and memory inside the accelerator has a significant impact on the performance of CNN applications. In this paper, a simulator for the CNN is developed to analyze the main memory or DRAM access with respect to the size of the on-chip memory or global buffer inside the CNN accelerator. For AlexNet, one of the CNN architectures, when simulated with increasing the size of the global buffer, we found that the global buffer of size larger than 100kB has 0.8x as low a DRAM access count as the global buffer of size smaller than 100kB."
차량 내·외부 데이터 및 딥러닝 기반 차량 위기 감지 시스템 설계,2021,"['Autonomous vehicles', 'Convolutional Neural Networks', 'You Only Look Once', 'Crisis Detection', 'Pedestrian recognition']","현재 자율주행차량 시장은 3레벨 자율주행차량을 상용화하고 있으나, 안정성의 문제로 완전 자율주행 중에도 사고가 발생할 가능성이 있다. 실제로 자율주행차량은 81건의 사고를 기록하고 있다. 3레벨과 다르게 4레벨 이후의 자율주행차량은 긴급상황을 스스로 판단하고 대처해야 하기 때문이다. 따라서 본 논문에서는 CNN을 통하여 차량 외부의 정보를 수집하여 저장하고, 저장된 정보와 차량 센서 데이터를 이용하여 차량이 처한 위기 상황을 0~1 사이의 수치로 출력하는 차량 내.외부 데이터 및 딥러닝 기반 차량 위기 감지 시스템을 제안한다. 차량 위기 감지 시스템은 CNN기반 신경망 모델을 사용하여 주변 차량과 보행자 데이터를 수집하는 차량 외부 상황 수집 모듈과 차량 외부 상황 수집 모듈의 출력과 차량 내부 센서 데이터를 이용하여 차량이 처한 위기 상황을 수치화하는 차량 위기 상황 판단 모듈로 구성된다. 실험 결과, VESCM의 평균 연산 시간은 55ms 였고, R-CNN은 74ms, CNN은 101ms였다. 특히, R-CNN은 보행자 수가 적을 때 VESCM과 비슷한 연산 시간을 보이지만, 보행자 수가 많아 질수록 VESCM보다 많은 연산 시간을 소요했다. 평균적으로 VESCM는 R-CNN보다 25.68%, CNN보다 45.54% 더 빠른 연산 시간을 가졌고, 세 모델의 정확도는 모두 80% 이하로 감소하지 않으며 높은 정확도를 보였다.","Currently, autonomous vehicle markets are commercializing a third-level autonomous vehicle, but there is a possibility that an accident may occur even during fully autonomous driving due to stability issues. In fact, autonomous vehicles have recorded 81 accidents. This is because, unlike level 3, autonomous vehicles after level 4 have to judge and respond to emergency situations by themselves. Therefore, this paper proposes a vehicle crisis detection system(VCDS) that collects and stores information outside the vehicle through CNN, and uses the stored information and vehicle sensor data to output the crisis situation of the vehicle as a number between 0 and 1. The VCDS consists of two modules. The vehicle external situation collection module collects surrounding vehicle and pedestrian data using a CNN-based neural network model. The vehicle crisis situation determination module detects a crisis situation in the vehicle by using the output of the vehicle external situation collection module and the vehicle internal sensor data. As a result of the experiment, the average operation time of VESCM was 55ms, R-CNN was 74ms, and CNN was 101ms. In particular, R-CNN shows similar computation time to VESCM when the number of pedestrians is small, but it takes more computation time than VESCM as the number of pedestrians increases. On average, VESCM had 25.68% faster computation time than R-CNN and 45.54% faster than CNN, and the accuracy of all three models did not decrease below 80% and showed high accuracy."
Convolutional Neural Network 기반 EBG 구조 설계를 통한 고속 PCB 노이즈 저감,2021,"['Simultaneous Switching Noise', 'Electromagnetic Band Gap', 'Machine Learning', 'Convolutional Neural Network']","기술이 빠르게 발전하여 디지털 시스템의 동작 주파수는 수 GHz 대역까지 증가했다. 이로 인하여 Simultaneous Switching Noise 문제가 증가했고, 이를 줄이기 위해 Electromagnetic Band Gap(EBG) 구조가 많이 연구된다. EBG 구조 설계에서 중요한 과정 중 하나는 노이즈를 저감하는 Stopband 대역을 예측하는 것이다. 기존에 3차원 전자장 시뮬레이션 프로그램을 이용하는 방법과 Floquet 이론 기반의 수식을 이용하는 방법이 있으나, 한계점이 존재한다. 본 논문에서는 Convolutional Neural Network(CNN)을 이용하여 EBG 구조의 Stopband 대역을 예측하는 새로운 방법을 제안한다. 또한 기본 CNN 구조, GoogLeNet, ResNet, DenseNet과 같은 CNN Architecture 모델을 활용하여 어떤 CNN 구조가 Stopband 대역 예측에 높은 성능을 보이는지 분석한다. 900개의 EBG 구조 모델에 대해서 학습시킨 후 CNN 구조의 mean absolute error를 비교한 결과, DenseNet이 가장 우수한 성능을 보임을 확인하였다.","With rapid advances in technology, the operating frequencies of digital systems have increased to several GHz bands. This has led to an increase in simultaneous switching noise(SSN). To reduce SSN, electromagnetic bandgap(EBG) structures have been intensively studied. One of the critical steps in the design of an EBG structure is to predict the stopband that reduces SSN. Existing methods include using a 3D electromagnetic field simulation program or equations based on the Floquet theory. However, these have limitations. In this study, we verified a new method for predicting the stopband using a convolutional neural network(CNN). Specifically, a CNN architectural model was used to compare structures that perform well in predicting the stopband. It was also used to confirm that the DenseNet showed high performance."
다층퍼셉트론과 합성곱 신경망에 기반한 지진 지반응답해석,2021,"['지진 지반응답해석', '다층퍼셉트론(MLP)', '합성곱 신경망(CNN)', 'Seismic Ground Response', 'Multilayer Perceptron (MLP)', 'Convolution Neural Networks (CNN)']","지진으로 인한 구조물의 피해를 줄이기 위한, 내진성능을 고려한 방재계획 수립의 중요성이 부각되고 있다. 지진파는 기반암으로 부터 기반암 상부의 토사지반을 통해 전달된다. 전달되는 과정에서 특정 진동수(frequency)범위에서 증폭되기도 하며, 그 증폭 정도는 주로 지반 특성에 따라 좌우된다. 따라서 내진 설계의 신뢰성을 높이기 위해서는 지진 지반응답해석 과정이 필수적이다. 본 연구에서는 지반 하부 혹은 기반암의 지진파로부터 지표의 지진파를 예측하기 위한 모델을 다층퍼셉트론(MLP)과 합성곱 신경망(CNN) 인공신경망 모형을 바탕으로 제안하고, 제안한 모델의 적용성을 가속도 스펙트럼을 바탕으로 검증하였다. MLP와 CNN에 기반 하여 제안된 모델 모두 지표면의 지진파 가속도를 성공적으로 예측하였다. 또한, CNN에 기반한 모델은 MLP 모델과 비교하여 예측 지진파의 가속도 스펙트럼 평균오차가 약 10% 작게 산출되는 것을 확인하였다. 향후에는 해당 지역의 전단파 속도 등의 물성을 모델에 적용하여, 보다 보편적으로 활용할 수 있는 모델을 생성하고자 한다.","The importance of establishing a disaster prevention plan considering seismic performance is being highlighted to reduce damage to structures caused by earthquakes. Earthquake waves propagate from the bedrock to the ground surface through the soil. During the transmission process, they are amplified in a specific frequency range, and the degree of amplification depends mainly on the characteristics of the ground. Therefore, a seismic response analysis process is essential for enhancing the reliability of the seismic design. We propose a model for predicting seismic waves on the surface from seismic waves measured on the bedrock based on Multilayer Perceptron (MLP) and Convolutional Neural Networks (CNN) and validate the applicability of the proposed model with Spectral Acceleration (SA). Both the proposed models based on MLP and CNN successfully predicted the seismic response of the surface. The CNN-based model performed better than the MLP-based model, with a 10% smaller average error. We plan to implement the physical properties of the ground, such as shear wave velocity, to create a more versatile model in the future."
Visual SLAM을 위한 Transformer 기반 6DoF 자세 추정 기법,2021,"['Transformer', 'Self-attention', 'Hybrid network', 'Monocular camera', 'Visual odometry']",국문 초록 정보 없음,다국어 초록 정보 없음
뇌파기반 정신적 피로 판별을 위한 딥러닝 모델,2021,[],"개인의 정신적 피로는 인지능력 및 업무 수행능력을 감소시킬 뿐만 아니라 일상에서 발생하는 크고 작은 사고의 주요 요인이 된다. 본 논문에서는 EEG 기반의 정신적 피로 판별을 위한 CNN 모델을 제안하였다. 이를 위해 안정 상태와 작업 상태에서의 뇌파를 수집하여 제안한 CNN 모델에 적용한 후 모델 성능을 분석하였다. 실험에 참여한 피험자들은 모두 대학교에 재학 중인 오른손잡이 남학생들이며 평균 나이는 25.5세이다. 각 상태에서의 측정된 뇌파에 대해 스펙트럼분석을 수행하였으며, CNN 모델의 입력데이터로써 원시 EEG 신호, 절대파워, 상대파워를 사용하여 CNN모델의 성능을 비교 분석하였다. 그 결과, 알파대역 후두엽 위치의 상대파워가 가장 좋은 성능을 나타내었다. 모델정확도는 훈련데이터 85.6%, 검증데이터 78.5%, 시험데이터 95.7%이다. 제안한 모델은 정신적 피로 판별을 위한 자동화시스템 개발에 적용될 수 있다.","Individual mental fatigue not only reduces cognitive ability and work performance, but also becomes a major factor in large and small accidents occurring in daily life. In this paper, a CNN model for EEG-based mental fatigue discrimination was proposed. To this end, EEG in the resting state and task state were collected and applied to the proposed CNN model, and then the model performance was analyzed. All subjects who participated in the experiment were right-handed male students attending university, with and average age of 25.5 years. Spectral analysis was performed on the measured EEG in each state, and the performance of the CNN model was compared and analyzed using the raw EEG, absolute power, and relative power as input data of the CNN model. As a result, the relative power of the occipital lobe position in the alpha band showed the best performance. The model accuracy is 85.6% for training data, 78.5% for validation, and 95.7% for test data. The proposed model can be applied to the development of an automated system for mental fatigue detection."
가스터빈 연소기의 안전 운영을 위한 고속화염이미지의 기계학습기법을 활용한 연소불안정 진단,2021,"['Combustion Instability(연소불안정)', 'Confusion Matrix(오차 행렬)', 'Convolutional Neural Network(합성곱 신경망)', 'Dynamic Pressure(동압)', 'Flame Image(화염이미지)', 'Long Short Term Memory(장단기 기억)', 'Machine Learning(기계 학습)']","본 연구에서는 모델 가스터빈 연소기로부터 계측된 고속화염 이미지를 활용해 기계 학습을 수행하여 연소 불안정을 진단하였다. 기계학습에 사용된 이미지는 연소불안정이 안정영역에서 불안정 영역으로 천이되는 조건을 대상으로 초고속 카메라를 이용하여 8 kHz의 속도로 취득하였다. 연소불안정 여부를 판단하기 위하여 CNN과 CNN+LSTM의 두 가지 기계학습 모델을 개발･적용하였고, confusion matrix와 accuracy, recall, precision, F1-score 값을 활용하여 각 모델의 진단성능을 평가하였다. CNN 모델은 단일 이미지만으로 학습하기에 48.92~100%의 정확도의 일부 부정확한 분류를 수행하는 것을 확인하였고, 이에 반해 시계열 화염이미지 데이터를 활용한 CNN+LSTM 모델은 98.97~100%의 매우 정확한 분류를 수행하는 것을 확인하였다.","In this study, combustion instability has been diagnosed by performing machine learning using the flame images measured from a model gas turbine combustor. The images were acquired with an ultra-high-speed camera at the rate of 8 kHz in the transition condition of combustion instability from stable to unstable regimes. To judge the onset of combustion instability, two machine learning models of CNN and CNN+LSTM were developed and applied, and their diagnostic performances were evaluated using confusion matrix, accuracy, recall, precision and F1-score. It was confirmed that the CNN model performs partially inaccurate classification with an accuracy of 48.92~100% because it was trained and judges with only a single image, whereas the CNN+LSTM model, which uses time-series flame image data, performs very accurate classification with an accuracy of 98.97~100%."
Deep Learning-based Pes Planus Classification Model Using Transfer Learning,2021,"['Pes planus', 'Deep learning', 'Convolutional neural network(CNN)', 'Transfer learning', 'Data Augmentation', '편평발', '딥러닝', '합성곱 신경망', '전이학습', '데이터 증폭']","본 연구는 기존 편평발 측정을 위해 사용되던 다양한 방법의 한계를 보완할 수 있는 새로운 측정 방법으로 전이학습을 적용한 딥러닝 기반 편평발 분류 방법론을 제안한다. 편평발 88장, 정상발 88장으로 이루어진 총 176장의 이미지 데이터를 활용하여, 적은 데이터로도 우수한 예측 모델을 생성할 수 있는 데이터 증폭 기술과 사전학습 모델인 VGG16 구조를 활용하는 전이학습 기술을 적용하여 제안 모델의 학습을 진행하였다. 제안 모델의 우수성을 확인하기 위하여 기본 CNN 기반 모델과 제안 방법론의 예측 정확도를 비교하는 실험을 수행하였다. 기본 CNN 모델의 경우 훈련 정확도는 77.27%, 검증 정확도는 61.36%, 그리고 시험 정확도는 59.09%로 나타났으며, 제안모델의 경우 훈련 정확도는 94.32%, 검증 정확도는 86.36%, 그리고 시험 정확도는 84.09%로 나타나 기본 CNN 모델에 비해 제안 모델의 정확도가 큰 폭으로 향상된 것을 확인하였다.","This study proposes a deep learning-based flat foot classification methodology using transfer learning. We used a transfer learning with VGG16 pre-trained model and a data augmentation technique to generate a model with high predictive accuracy from a total of 176 image data consisting of 88 flat feet and 88 normal feet. To evaluate the performance of the proposed model, we performed an experiment comparing the prediction accuracy of the basic CNN-based model and the prediction model derived through the proposed methodology. In the case of the basic CNN model, the training accuracy was 77.27%, the validation accuracy was 61.36%, and the test accuracy was 59.09%. Meanwhile, in the case of our proposed model, the training accuracy was 94.32%, the validation accuracy was 86.36%, and the test accuracy was 84.09%, indicating that the accuracy of our model was significantly higher than that of the basic CNN model."
Deep Compression의 프루닝 문턱값 동적 조정,2021,"['CNN', '신경망 경량화', '가지치기', '문턱값 조정', 'LeNet', 'CNN', 'Neural network compression', 'Pruning', 'Threshold adjustment', 'LeNet']","최근 CNN(Convolutional Neural Network)이 다양한 컴퓨터 비전 분야에서 우수한 성능으로 널리 사용되고 있다. 그러나 CNN은 계산 집약적이고 많은 메모리가 요구되어 한정적인 하드웨어 자원을 가지는 모바일이나 IoT(Internet of Things) 기기에 적용하기 어렵다. 이런 한계를 해결하기 위해, 기존의 학습된 모델의 성능을 최대한 유지하며 네트워크의 크기를 줄이는 인공신경망 경량화 연구가 진행되고 있다. 본 논문은 신경망 압축 기술 중 하나인 프루닝(Pruning)의 문턱값을 동적으로 조정하는 CNN 압축 기법을 제안한다. 프루닝될 가중치를 결정하는 문턱값을 실험적, 경험적으로 정하는 기존의 기술과 달리 정확도의 저하를 방지하는 최적의 문턱값을 동적으로 찾을 수 있으며, 경량화된 신경망을 얻는 시간을 단축할 수 있다. 제안 기법의 성능 검증을 위해 MNIST 데이터 셋을 사용하여 LeNet을 훈련시켰으며, 정확도 손실 없이 약 1.3 ~ 3배의 시간을 단축하여 경량화된 LeNet을 얻을 수 있었다.","Recently, convolutional neural networks (CNNs) have been widely utilized due to their outstanding performance in various computer vision fields. However, due to their computational-intensive and high memory requirements, it is difficult to deploy CNNs on hardware platforms that have limited resources, such as mobile devices and IoT devices. To address these limitations, a neural network compression research is underway to reduce the size of neural networks while maintaining their performance. This paper proposes a CNN compression technique that dynamically adjusts the thresholds of pruning, one of the neural network compression techniques. Unlike the conventional pruning that experimentally or heuristically sets the thresholds that determine the weights to be pruned, the proposed technique can dynamically find the optimal thresholds that prevent accuracy degradation and output the light-weight neural network in less time. To validate the performance of the proposed technique, the LeNet was trained using the MNIST dataset and the light-weight LeNet could be automatically obtained 1.3 to 3 times faster without loss of accuracy."
Method for Estimating Intramuscular Fat Percentage of Hanwoo(Korean Traditional Cattle) Using Convolutional Neural Networks in Ultrasound Images,2021,"['Hanwoo', 'Ultrasound Images', 'CNN', '%IMF(Intramuscular Fat Percentage)', 'ROI']",국문 초록 정보 없음,"In order to preserve the seeds of excellent Hanwoo(Korean traditional cattle) and secure quality competitiveness in the infinite competition with foreign imported beef, production of high-quality Hanwoo beef is absolutely necessary. %IMF (Intramuscular Fat Percentage) is one of the most important factors in evaluating the value of high-quality meat, although standards vary according to food culture and industrial conditions by country. Therefore, it is required to develop a %IMF estimation algorithm suitable for Hanwoo. In this study, we proposed a method of estimating %IMF of Hanwoo using CNN in ultrasound images. First, the proposed method classified the chemically measured %IMF into 10 classes using k-means clustering method to apply CNN. Next, ROI images were obtained at regular intervals from each ultrasound image and used for CNN training and estimation. The proposed CNN model is composed of three stages of convolution layer and fully connected layer. As a result of the experiment, it was confirmed that the %IMF of Hanwoo was estimated with an accuracy of 98.2%. The correlation coefficient between the estimated %IMF and the real %IMF by the proposed method is 0.97, which is about 10% better than the 0.88 of the previous method."
합성곱 신경망을 이용한 수중 선체면 영상의 청소 상태 검사,2021,"['Classification(분류)', 'Cleaning Condition(청소 상태)', 'Convolutional Neural Network(합성곱 신경망)', 'Hull Surface(선체면)', 'Inspection Image(검사 영상)', 'Underwater Hull(수중 선체)']","본 연구에서는 합성곱 신경망(CNN: convolutional neural network)을 이용해 수중에서 촬영한 선체면 영상에서 선체면의 청소 상태를 검사하기 위한 방법을 제안한다. 원격 조종 수중 로봇에서 수집한 동영상을 이용해 학습 데이터를 생성하였으며, 이 데이터들을 청소가 된 상태와 청소가 안된 상태의 영상으로 분류하였다. 청소 상태 검사를 위한 CNN 모델을 합성곱 레이어(convolution layer), 최대풀링 레이어(max-pooling layer), 드롭아웃 레이어(dropout layer)로 구성된 네 개의 합성곱 블록(convolution block)과 세개의 완전 연결 레이어(fully-connected layer)로 구성하였다. 그리고, 미니배치 경사하강법(mini-batch gradient descent)과 Adam 최적화를 이용해 CNN 모델을 학습하였다. 그 결과, 테스트 셋에 대해 97.95%의 정확도와 97.94%의 F1-점수를 보여주었다.","We propose a method for inspecting the cleaning condition of hull surfaces from underwater hull surface images using a convolutional neural network (CNN). A training data set was generated using videos collected from a remotely operated underwater robot, and the data set was classified into cleaned images and uncleaned images. The CNN model for inspecting the cleaning condition was composed of four convolutional blocks and three fully connected layers, where each convolutional block consisted of a convolution layer, a max-pooling layer, and a dropout layer. The CNN model was trained using the mini-batch gradient descent method and an Adam optimizer. As a result, on the testing set, the accuracy was 97.95%, and the F1-score was 97.94%."
효과적인 비전 트랜스포머를 통한 화재 감지,2021,"['컨볼루션 뉴럴 네트워크', '화재 감지', '포그기아의 데이터 세트', '산불', '스마트시티', '비전 변압기', 'Convolution Neural Network', 'Fire Detection', 'Foggia’s Dataset', 'Forest Fire', 'Smart Cities', 'Vision Transformers']","오늘날 현대사회에서 스마트하고 안전한 도시는 연구 커뮤니티의 주요 관심사 중 하나이다. 도시들은 개방된 지역, 농경지, 숲으로 둘러싸여 있으며, 화재 발생은 인간의 삶을 위협하고 그들의 재산도 손상시킬 수 있다. 최근 비전 센서 기반 화재 감지 기술은 컴퓨터 비전 분야의 전문가들을 통해, 최신 문헌에서 다양한 컨볼루션 신경 네트워크 (CNN)을 대한 최고의 성능을 달성하고 있다. 그러나 이러한 기술은 변환 불변이고, 지역성에 민감하며, 이미지에 대한 전체적인 이해가 부족하다. 또한 CNN 기반 모델은 계산 비용을 줄이기 위해 차원 축소를 위한 풀링 레이어 전략을 사용했지만, 가장 활동적인 특징 검출기의 정확한 위치와 같은 많은 의미 있는 정보를 손실한다. 이러한 문 제를 극복하기 위해 본 연구에서는 비전 트랜스포머(ViT)기반 화재 감지 모델을 개발하였다. ViT는 입력 이미지를 이미지 패치로 분할한 다음 워드 임베딩과 유사한 시퀀스 구조로 트랜스포머에 제공한다. 우리는 벤치마크 화재 데 이터 세트에서 제안된 작업의 성능을 평가하고 최신(SOTA) CNN 방법과 비교할 때 좋은 결과를 달성한다.","In today's modern age, smart and safe cities are one of the major concerns of the research community. The cities are surrounded by open areas, agricultural land, and forests, where fire incidence can make human lives threatening, damaging their properties as well. Recently, vision sensors-based fire detection has attracted computer vision domain experts, where the leading performance is achieved by a variety of convolution neural networks(CNN) in the recent literature. However, these techniques are translation invariant, locality-sensitive, and lacking a global understanding of images. Furthermore, CNN-based models use the pooling layers strategy for dimensionality reduction to reduce the computational cost but it also loses a lot of meaningful information such as the precise location of the most active feature detector. To overcome these problems, in this work, we developed Vision Transformers(ViT) based model for fire detection. The ViT split the input image into image patches and then feed these patches to the transformer in a sequence structure similar to word embeddings. We evaluate the performance of the proposed work on the benchmark fire dataset and achieve good results when compared to state-of-the-art(SOTA) fire detection CNN models."
경안천 용존 산소 예측을 위한 입력 인자 선정 및 기계 학습 모델 비교,2021,"['인공신경망', '합성곱 신경망', '게이트 순환 유닛', '경안천', '랜덤 포레스트', 'Artificial Neural Network', 'Convolutional Neural Network', 'Gated Recurrent Unit', 'Gyeongan Stream', 'Random Forest']","목적:본 연구에서는 경안천의 용존 산소(dissolved oxygen, DO) 예측을 위해 기계 학습(machine learning) 모델의 최적 입력 인자를 선정하고 성능 평가 지표 결과를 비교하여 최적 모델을 찾고자 한다.방법:경안천 특정 지점의 수질 자료를 연구대상으로 삼아 1998년 1월 15일부터 2019년 12월 30일까지 자료를 수집하고, 전처리한 데이터를 7:3의 비율에 따라 train과 test 자료로 나누어 실험을 진행하였다. 기계 학습 중 랜덤 포레스트(random forest, RF), 인공신경망(artificial neural network, ANN), 합성곱 신경망(convolutional neural network, CNN), 게이트 순환 유닛(gated recurrent unit, GRU) 등을 이용하였다. RF와 ANN은 무작위 추출(random split)과 시계열 자료(time series)로 구분하여 실험하였으며, CNN과 GRU는 시계열 자료만 이용하여 실험을 진행하였다. 모델별 최적의 결과를 비교하기 위해 성능 평가 지표(결정 계수(square of the correlation coefficient, R2), 평균 제곱근 오차(root mean square error, RMSE), 평균 절대 오차(mean absolute error, MAE))를 사용하였다.결과 및 토의:RF 기여도 분석 결과와 참고문헌을 통해 최적 입력 인자로 수온, pH, 전기 전도도, PO4-P, NH4-N, 총 인, 부유물질, NO3-N 등으로 선정하였다. RF와 ANN 모두 무작위 추출보다 시계열 자료의 성능이 더 우수하였다. 시계열 자료를 이용하여 모델 성능을 비교해 보면, RF > CNN > GRU > ANN 순으로 나타났다.결론:본 연구에서 경안천의 DO 예측을 위한 기계 학습 모델의 최적 입력 인자로 8개(수온, pH, 전기 전도도, PO4-P, NH4-N, 총 인, 부유물질, NO3-N)를 선택하였다. DO 예측에 가장 우수한 모델은 시계열 자료를 사용한 RF 모델이었다. 따라서 경안천과 같은 하천의 DO를 예측하는 경우 최적 입력 인자 선정 후 시계열 자료를 바탕으로 RF 모델을 이용할 것을 제안한다.","Objectives:In this study, we select input factors for machine learning models to predict dissolved oxygen (DO) in Gyeongan Stream and compare results of performance evaluation indicators to find the optimal model.Methods:The water quality data from the specific points of Gyeongan Stream were collected between January 15, 1998 and December 30, 2019. The pretreatment data were divided into train and test data with the ratio of 7:3. We used random forest (RF), artificial neural network (ANN), convolutional neural network (CNN), and gated recurrent unit (GRU) among machine learning. RF and ANN were tested by both random split and time series data, while CNN and GRU conducted the experiment using only time series data. Performance evaluation indicators such as square of the correlation coefficient (R2), root mean square error (RMSE), and mean absolute error (MAE) were used to compare the optimal results for the models.Results and Discussion:Based on the RF variable importance results and references, water temperature, pH, electrical conductivity, PO4-P, NH4-N, total phosphorus, suspended solids, and NO3-N were used as input factors. Both RF and ANN performed better with time series data than random split. The model performance was good in order of RF > CNN > GRU > ANN.Conclusions:The eight input factors (water temperature, pH, electrical conductivity, PO4-P, NH4-N, total phosphorus, suspended solids, and NO3-N) were selected for machine learning models to predict DO in Gyeongan Stream. The best model for DO prediction was the RF model with time series data. Therefore, we suggest that the RF with the eight input factors could be used to predict the DO in streams."
Convolutional neural network-based damage detection method for building structures,2021,"['structural health monitoring', 'damage detection', 'convolutional neural network', 'dynamic response', 'modal participation ratio']",국문 초록 정보 없음,"This study presents a damage detection method based on modal responses for building structures using convolutional neural networks (CNNs). The modal responses used in the method are obtained from the dynamic responses, which are measured in a building structure under ambient excitations; these are then transformed to a modal participation ratio (MPR) value for a measuring point and mode. As modal responses vary after damages in the structures, the MPR for a specific location and mode also changes. Thus, in this study, MPR variations, which can be obtained by comparing the MPRs of damaged and healthy structures, are utilized for damage detection without the need for identification of modal parameters. Since MPRs are derived for the number of measuring points (<i>N</i>) in the structure as well as the same number of modes (<i>N</i>), the MPRs and MPR variations can be arranged as an <i>N</i> × <i>N</i> matrix. This low-dimensional MPR variations set is used as the input map of the presented CNN architecture and information about damage locations and severities of the target structure is set as the output of the CNN. The presented CNN is trained for establishing the relationship between MPR variations and damage information and utilized to estimate the damage. The presented damage detection method is applied to numerical examples for two multiple degrees of freedoms and a three-dimensional ASCE benchmark numerical model. Training datasets created from damage scenarios assuming changes in the stiffness are used to train the CNN and the performance of this CNN is verified. Finally, this study examines how variations in the operator size and number of layers in the CNN architecture affect the damage detection performance of CNNs."
차량 센서 데이터 조합을 통한 딥러닝 기반 차량 이상탐지,2021,"['Anomaly detection', 'CNN', 'LSTM', 'Vehicle', 'Deep learning']","4차산업혁명 시대에는 대량의 데이터를 학습하여 예측과 분류의 정확성을 향상시킬 수 있는 인공지능의 활용이 핵심적이다. 그러나, 기존 이상탐지를 위한 방법은 제한된 데이터를 다루는 전통적인 통계 방법에 의존하고 있어, 정확한 이상탐지가 어렵다. 그러므로, 본 연구는 인공지능 기반 이상탐지 방법을 제시하여 예측 정확도를 높이고, 새로운 데이터 패턴을 정의하는 것을 목적으로 한다. 특히, 자동차의 경우 공회전 기간의 센서 데이터가 이상 탐지에 활용될 수 있다는 관점에서 데이터를 수집하고 분석하였다. 이를 위해, 예측 모델에 입력되는 데이터의 적정 시간 길이를 결정하고, 공회전 기간 데이터와 전체 운행 데이터의 분석 결과를 비교하며, 다양한 센서 데이터 조합에 의한 최적 예측 방법을 도출하였다. 또한, 인공지능 방법으로 선택된 CNN의 예측 정확성을 검증하기 위해 LSTM 결과와 비교하였다. 분석 결과, 공회전 데이터를 이용하고, 공회전 기간보다 1.5배 많은 기간의 데이터를 이용하며 LSTM보다는 CNN을 활용하는 것이 더 좋은 예측결과를 보였다.","In the Industry 4.0 era, artificial intelligence has attracted considerable interest for learning mass data to improve the accuracy of forecasting and classification. On the other hand, the current method of detecting anomalies relies on traditional statistical methods for a limited amount of data, making it difficult to detect accurate anomalies. Therefore, this paper proposes an artificial intelligence-based anomaly detection methodology to improve the prediction accuracy and identify new data patterns. In particular, data were collected and analyzed from the point of view that sensor data collected at vehicle idle could be used to detect abnormalities. To this end, a sensor was designed to determine the appropriate time length of the data entered into the forecast model, compare the results of idling data with the overall driving data utilization, and make optimal predictions through a combination of various sensor data. In addition, the predictive accuracy of artificial intelligence techniques was presented by comparing Convolutional Neural Networks (CNN) and Long Short Term Memory (LSTM) as the predictive methodologies. According to the analysis, using idle data, using 1.5 times of the data for the idling periods, and using CNN over LSTM showed better prediction results."
Method for Estimating Intramuscular Fat Percentage of Hanwoo(Korean Traditional Cattle) Using Convolutional Neural Networks in Ultrasound Images,2021,"['Hanwoo', 'Ultrasound Images', 'CNN', '%IMF(Intramuscular Fat Percentage)', 'ROI']",국문 초록 정보 없음,"In order to preserve the seeds of excellent Hanwoo(Korean traditional cattle) and secure quality competitiveness in the infinite competition with foreign imported beef, production of high-quality Hanwoo beef is absolutely necessary. %IMF (Intramuscular Fat Percentage) is one of the most important factors in evaluating the value of high-quality meat, although standards vary according to food culture and industrial conditions by country. Therefore, it is required to develop a %IMF estimation algorithm suitable for Hanwoo. In this study, we proposed a method of estimating %IMF of Hanwoo using CNN in ultrasound images. First, the proposed method classified the chemically measured %IMF into 10 classes using k-means clustering method to apply CNN. Next, ROI images were obtained at regular intervals from each ultrasound image and used for CNN training and estimation. The proposed CNN model is composed of three stages of convolution layer and fully connected layer. As a result of the experiment, it was confirmed that the %IMF of Hanwoo was estimated with an accuracy of 98.2%. The correlation coefficient between the estimated %IMF and the real %IMF by the proposed method is 0.97, which is about 10% better than the 0.88 of the previous method."
유방암 선별진단을 위한 AI 개발을 위한 데이터 연구,2021,"['Breast cancer AI', 'Medical AI', 'AI', 'Medical dataset', 'Multi-modality', 'DICOM', 'CNN', 'FCN', 'U-Net']",유방암 선별 진단은 X선 유방조영술을 사용해 검사를 진행한다. X선 이미지를 읽는 것은 전문가에게도 어려운 작업이기에 유방암 검진 보조를 기반으로 기존의 유방암의 악성과 양성을 판별하는 인공지능은 상당한 연구가 진행되었다. 유방암의 악성과 약성을 판별하는 인공지능의 정확도를 높이고 멀티모달리티 기법을 적용하여 유방암 환자의 정보를 학습 시켜 환자의 추가적인 정보에 따라 유방암 위험 인자 분석을 통해 유방암 조직검사 이전의 선별 진료의 정확도를 향상한다. 의료 영상 장비를 사용하여 수집된 영상은 DICOM 형식으로 저장된다. 합성곱 신경망(CNN)을 이용한 학습으로 종양의 병변을 확인하도록 한다. 왼쪽 이미지와 오른쪽 이미지 중 왼쪽 이미지를 좌우 반전 시켜 데이터를 통합한 후 연구를 진행하였다. CNN을 보완한 FCN을 기반으로 구축된 모델인 U-Net을 활용하여 관심 영역을 찾아내고 학습하여 유방조영술 촬영본의 병변의 유무를 확인할 수 있다.,"Breast cancer screening is diagnosed using X-ray mammography. Since reading X-ray images is a difficult task even for experts, considerable research has been done on artificial intelligence that distinguishes between benign and malignant breast cancers based on breast cancer screening aids. Increase the accuracy of artificial intelligence to discriminate the malignancy and weakness of breast cancer, apply multimodality techniques to learn information from breast cancer patients, and improve the accuracy of screening treatment prior to breast cancer biopsy through breast cancer risk factor analysis according to the patient""s additional information make it Images acquired using medical imaging equipment are stored in DICOM format. Learning using a convolutional neural network (CNN) is used to identify tumor lesions. The study was conducted after integrating the data by inverting the left image among the left and right images. U-Net, a model built based on FCN supplemented with CNN, can be used to find and learn areas of interest to check the presence or absence of lesions in mammograms."
한 쌍의 앙상블 모델을 이용한 효율적인 골다공증 예측,2021,"['CT', 'Osteopenia', 'Osteoporosis', 'Dissimilarity loss function', 'Feature map', 'CNN', '컴퓨터 단층촬영', '골감소증', '골다공증', '비유사성 손실함수', '특징 정보']","본 논문에서는 컴퓨터 단층촬영(CT) 이미지를 이용한 합성곱 신경망(CNN)을 기반의 골감소증 및 골다공증 예측 모델을 제안한다. 기존의 CNN은 단일 CT 이미지에서 예측에 중요한 지역정보를 활용하지 못하다는 문제가 있다. 본 논문에서 이를 해결하고자 CT 이미지를 정규화하여 질감 정보가 다른 두 개의 이미지로 변환하고, 해당 이미지를 활용한 한 쌍의 신경망 네트워크를 제안한다. 동일한 구조를 가진 네트워크 각각의 신경망은 질감 정보가 다른 이미지를 입력으로 사용하고 비유사성 손실함수를 통해 다른 정보를 학습한다. 최종적으로 제안 모델은 중요한 지역정보를 포함한 단일 CT 이미지의 다양한 특징 정보를 학습하며, 이를 앙상블하여 골감소증 및 골다공증 예측 정확도를 높인다. 실험 결과를 통해 제안 모델의 정확도 77.11%를 확인할 수 있으며 Grad-CAM을 이용하여 모델이 바라보는 특징을 확인할 수 있다.","In this paper, we propose a prediction model for osteopenia and osteoporosis based on a convolutional neural network(CNN) using computed tomography(CT) images. In a single CT image, CNN had a limitation in utilizing important local features for diagnosis. So we propose a compound model which has two identical structures. As an input, two different texture images are used, which are converted from a single normalized CT image. The two networks train different information by using dissimilarity loss function. As a result, our model trains various features in a single CT image which includes important local features, then we ensemble them to improve the accuracy of predicting osteopenia and osteoporosis. In experiment results, our method shows an accuracy of 77.11% and the feature visualize of this model is confirmed by using Grad-CAM."
합성곱 신경망과 장단기 메모리를 이용한 리튬이온 배터리 SEI 층 전압 차의 특징 기반 State-of-Health 추정 연구,2021,[],"본 논문은 리튬이온 배터리의 State-of-Health(SOH)를 추정하기 위해 합성곱 신경망(Convolution Neural Networks, CNN)과 장단기메모리(Long Short-Term Memory, LSTM)를 사용하였다. 리튬이온 배터리 데이터셋은 Nasa Battery Data set 를 사용하였다. 입력 값에 사용되는 특징들은 사이클 변화에 따른 SEI 층의 전압 차로 짧은 사이클에 대해 학습할 수 있으며, 내부 요인(온도, CC 충전 량 등)에 대해 영향을 적게 받는다. 실험은 CNN, LSTM, CNN+LSTM 3 가지 경우를 고려하였다. CNN+LSTM 모델의 평균 손실 값과 표준편차는 약 5.46, 3.06(Root Mean Square Error)이며, CNN 과 LSTM 대비 약 80.77%, 6.78% 낮은 평균과 240.2%, 34.64% 낮은 표준편차 손실 값을 보이므로 다른 모델보다 성능이 높으며 안정적으로 예측하는 것을 볼 수 있다.",다국어 초록 정보 없음
Damage detection in structures using modal curvatures gapped smoothing method and deep learning,2021,"['damage detections', 'vibration-based', 'gapped smoothing method (GSM)', 'machine learning', 'deep learning', 'convolutional neural network', 'Finite Element Method (FEM)']",국문 초록 정보 없음,"This paper deals with damage detection using a Gapped Smoothing Method (GSM) combined with deep learning. Convolutional Neural Network (CNN) is a model of deep learning. CNN has an input layer, an output layer, and a number of hidden layers that consist of convolutional layers. The input layer is a tensor with shape (number of images) × (image width) × (image height) × (image depth). An activation function is applied each time to this tensor passing through a hidden layer and the last layer is the fully connected layer. After the fully connected layer, the output layer, which is the final layer, is predicted by CNN. In this paper, a complete machine learning system is introduced. The training data was taken from a Finite Element (FE) model. The input images are the contour plots of curvature gapped smooth damage index. A free-free beam is used as a case study. In the first step, the FE model of the beam was used to generate data. The collected data were then divided into two parts, i.e. 70% for training and 30% for validation. In the second step, the proposed CNN was trained using training data and then validated using available data. Furthermore, a vibration experiment on steel damaged beam in free-free support condition was carried out in the laboratory to test the method. A total number of 15 accelerometers were set up to measure the mode shapes and calculate the curvature gapped smooth of the damaged beam. Two scenarios were introduced with different severities of the damage. The results showed that the trained CNN was successful in detecting the location as well as the severity of the damage in the experimental damaged beam."
LSTM-Based Human Fall Detection using Thermal Array Sensor,2021,"['CNN', 'CNN-LSTM', 'Fall detection', 'LSTM', 'thermal array sensor']",국문 초록 정보 없음,"Accidental fall may lead to numerous serious and deadly injures. Existing fall detection systems mostly use cameras and are considered a privacy-intrusive approach. Thermal array sensors are considered a privacy-friendly device that does not raises discomforts for users. In this study, we simulate a fall detection system using a thermal array sensor with three different algorithms: CNN, LSTM, and CNN-LSTM. Our result shows that LSTM has the best accuracy among other algorithms by 99.96%."
Fault Diagnosis of Bearing Based on Convolutional Neural Network Using Multi-Domain Features,2021,"['CNN', 'DWT', 'Fault Diagnosis', 'Multi-domain', 'Time series Classification']",국문 초록 정보 없음,"Failures frequently occurred in manufacturing machines due to complex and changeable manufacturing environments, increasing the downtime and maintenance costs. This manuscript develops a novel deep learning-based method named Multi-Domain Convolutional Neural Network (MDCNN) to deal with this challenging task with vibration signals. The proposed MDCNN consists of time-domain, frequency-domain, and statistical-domain feature channels. The Time-domain channel is to model the hidden patterns of signals in the time domain. The frequency-domain channel uses Discrete Wavelet Transformation (DWT) to obtain the rich feature representations of signals in the frequency domain. The statistic-domain channel contains six statistical variables, which is to reflect the signals’ macro statistical-domain features, respectively. Firstly, in the proposed MDCNN, time-domain and frequency-domain channels are processed by CNN individually with various filters. Secondly, the CNN extracted features from time, and frequency domains are merged as time-frequency features. Lastly, time-frequency domain features are fused with six statistical variables as the comprehensive features for identifying the fault. Thereby, the proposed method could make full use of those three domain-features for fault diagnosis while keeping high distinguishability due to CNN's utilization. The authors designed massive experiments with 10-folder cross-validation technology to validate the proposed method's effectiveness on the CWRU bearing data set. The experimental results are calculated by ten-time averaged accuracy. They have confirmed that the proposed MDCNN could intelligently, accurately, and timely detect the fault under the complex manufacturing environments, whose accuracy is nearly 100%."
미세먼지 위험 단계 예측을 위한 1-D CRNN 모델 설계,2021,"['Fine dust', 'Deep learning', 'CNN', 'RNN', 'Data prediction', '미세먼지', '딥러닝', 'CNN', 'RNN', '데이터 예측']","최근 국내 미세먼지 발생의 증가에 따라 발생하는 인체에 유해한 영향을 줄이기 위하여, 미세먼지 수치를 예측하고 사전 조치를 취할 수 있도록 돕는 기술이 필요해지고 있다. 본 논문에서는 국내 미세먼지 위험 수준을 예측하기 위한 1D Convolutional to Recurrent Neural Network (1-D CRNN) 모델을 제안한다. 제안 된 모델은 딥러닝 신경망의 CNN과 RNN을 결합한 구조이며, 다른 종류의 데이터로 구성된 시계열 데이터 세트에서 데이터 예측을 수행 할 수 있다. 데이터 예측을 위해 국내·외 미세먼지, 풍향, 풍속 데이터를 사용한다. 제안된 모델은 약 76%(부분 최대 84%)의 정확도를 달성했으며, 일반 RNN 모델(53%)보다 정확한 예측 결과를 얻었을 수 있었다. 제안된 모델은 향후 여러 개의 시계열 데이터 세트를 고려해야 하는 데이터 예측 모델 학습 및 실험을 목표로 한다.","In order to reduce the harmful effects on the human body caused by the recent increase in the generation of fine dust in Korea, there is a need for technology to help predict the level of fine dust and take precautions. In this paper, we propose a 1D Convolutional-Recurrent Neural Network (1-D CRNN) model to predict the level of fine dust in Korea. The proposed model is a structure that combines the CNN and the RNN, and uses domestic and foreign fine dust, wind direction, and wind speed data for data prediction. The proposed model achieved an accuracy of about 76%(Partial up to 84%). The proposed model aims to data prediction model for time series data sets that need to consider various data in the future."
심층학습의 인스턴스 분할을 이용한 시설작물 레이블링,2021,"['심층학습', '시설작물', '레이블링', '인스턴스 분할', 'Deep learning', 'Facility Crops', 'Labeling', 'Instance Segmentation', 'Mask R-CNN']","본 논문에서는 심층학습 기반 시설작물 영상의 개체분할에 의한 레이블링을 제안한다. 여기서 개체의 레이블링을 위한 분할은 인스턴스 분할로 전이학습의 Mask R-CNN 모델을 이용한다. 개체분할을 위한 영상은 시설작물의 딸기영상이며, 딸기영상을 잎, 줄기, 꽃의 3가지 개체별로 분할 후 레이블링한다. 제안된 방법의 타당성과 성능을 확인하기 위하여 온실에서 획득된 135장의 RGB 딸기영상을 대상으로 실험한 결과, 3가지 각 개체들의 분할성능이 우수함을 확인하였다. 특히 잎과 같이 동일한 여러 개체가 중첩된 경우에도 개체의 분할성능이 우수함을 확인하였다.","In this paper, we propose labeling by object segmentation of deep learning-based facility crop images. Here, the segmentation for object labeling is instance segmentation and uses the Mask R-CNN model of transfer learning. In addition, the image for object segmentation is a strawberry image of a plant crop, and the strawberry image is labeled after dividing into three classes of leaves, stems, and flowers. In order to confirm the validity and performance of the proposed method, as a result of an experiment on 135 RGB strawberry images obtained in a greenhouse, it was confirmed that the segmentation performance of each of the three objects was excellent. In particular, it was confirmed that the segmentation performance of the individual was excellent even when several identical objects such as leaves were overlapped."
Improving Parallelism for Video Action Recognition Model Using One-dimensional Convolutional Neural Network,2021,"['비디오 분류', '비디오 행동 인식', '1차원 CNN', '딥러닝', 'video classification', 'video action recognition', '1D convolutional neural network', 'deep learning']",딥러닝 프레임워크는 컴퓨터 비전 많은 분야에서 괄목할 만한 성과를 보여주고 있다. 비디오 행동 인식 분야 역시 딥러닝 모델을 적용하기 위한 많은 연구들이 수행되었다. 한 선행연구는 2차원 CNN을 이용해 공간적 피쳐를 학습하고 이를 RNN에 입력으로 전달해 이용해 공간적 피쳐 사이의 시간적 상호 관계를 학습하는 모델 구조를 제안했다. 본 논문에서는 RNN 대신 1차원 CNN을 이용해 시간적 상호관계를 학습하도록 선행 연구의 모델 구조를 개선하는 연구를 수행한다. 이러한 구조 변경을 통해 RNN의 순차적 연산 과정을 제거해 향상된 GPU 활용도를 기대할 수 있다. 본 논문은 수정된 모델이 정확도를 비슷하게 유지하면서 연산 시간이 줄어드는 것을 보여주는 실험 결과를 제시함으로써 이러한 주장을 뒷받침한다.,"The deep learning framework has shown remarkable results on numerous computer vision tasks. Many studies have been performed for video action recognition tasks to apply deep learning models to the task. One of the previous works suggested the model architecture, where spatial features are learned from 2D Convolutional Neural Networks (CNNs) and then passed to Recurrent Neural Networks (RNNs) to learn about temporal dependency among them. In this paper, we study the improved model architecture where the temporal relationship of spatial features is processed with 1D CNN instead of RNN. From this modification, we can expect better utilization of GPU by removing sequential operations of RNN. We support the argument based on the experiment results that show that it leads to the reduction in computation time and maintains a similar classification accuracy."
볼트 체결 상태에 따른 동특성 변화를 이용한 인공지능 기반 구조물의 볼트 체결력 예측,2021,"['Bolt clamping force(볼트 체결력)', 'Frequency response function(주파수응답함수)', 'MS similarity function(MS 유사성함수)', 'MOR(모델차수축소법)', 'CNN(합성곱 신경망)']","볼트로 체결된 구조물에서 볼트 체결 상태에 따라 동특성이 변경되는 것을 활용하여 볼트의 체결상태에 따른 주파수응답함수를 생성하고 정상상태와의 유사성을 구하여 CNN 모델 훈련을 위한 빅데이터로 활용하고자 한다. 이때, 주파수응답해석에 많은 연산 시간이 요구되므로 수치 효율성 증대를 위하여 기존 시스템의 동특성은 정확히 유지하며 연산 시간은 단축하는 모델차수축소법을 이용한다. 이 방법으로 축소 시스템을 생성하고 대량의 주파수응답 데이터를 구축한다. 또한, 체결 상태에 따른 주파수응답 변화를 효과적으로 파악하기 위해 주파수응답의 크기 및 모양의 유사성을 나타내는 MS 유사성 함수를 이용한다. 최종적으로 주파수응답의 유사성에 대한 빅데이터를 활용하여 CNN을 훈련하고, 이 인공신경망을 통하여 임의의 볼트 상태에 대한 볼트 구조물의 체결력을 예측하고자 한다.","Structures clamped with bolts have different dynamic characteristics depending on the clamped state. Using this, we generate frequency response functions according to the bolt clamping state and use them as data for training the CNN models. However, the frequency response analysis performed to generate the frequency response function requires huge computation time. For an efficient way to overcome this, the model order reduction method is applied in order to reduce the computation time including the dynamic characteristics of the existing system. In this way, we generate a reduction system and construct a large amount of frequency response data. In addition, in order to effectively detect the change in frequency response according to the clamping state, the MS similarity function that indicates the similarity in magnitude and shape is used. Finally, using the data on frequency response similarity, we train CNNs and predict the clamping force of bolt structures."
Application of Deep Learning Techniques to Diagnose Mild Cognitive Impairment: Functional Near-Infrared Spectroscopy Study,2021,"['Mild cognitive impairment (MCI)', 'functional near-infrared spectroscopy (fNIRS)', 'brain-computer interface (BCI)', 'long short-term memory (LSTM)', 'convolutional neural network (CNN)']",국문 초록 정보 없음,"In this paper, we propose a novel deep learning algorithm (i.e., multi-scale convolutional neural network (CNN) accompanied by long short-term memory (LSTM) layers) for diagnosing patients with functional near-infrared spectroscopy (fNIRS). Mild cognitive impairment (MCI) is associated with aging and describes early symptoms of severe cognitive impairment known as Alzheimer""s disease (AD). Meanwhile, early detection of MCIs can prevent progression to AD. Many studies have been investigated on MCI diagnose over the past decade. In this work, we measure three mental tasks (i.e., N-back, Stroop, semantic verbal fluency tasks) for 38 MCI patients and 25 healthy people. The proposed multi-class CNN-LSTM network improves classification accuracy and reduces the classification time. By classifying the fNIRS data directly and minimizing the preprocessing process without finding the region of interest channels, the reduction of data processing time was achieved. The proposed algorithm was compared with a single LSTM algorithm to validate the performance and compare the accuracy, precision, recall, and F1 score with standard metrics. For the proposed multi-class CNN-LSTM, the maximum classification accuracy was 83.33% when performing N-back tasks, with an average accuracy of 77.77% for all tasks. For the LSTM only, the maximum classification accuracy is 73.33% when performing N-back tasks. The average classification accuracy for all tasks is 57.77%. The results, therefore, demonstrate that the proposed algorithm is superior to the LSTM, indicating the potential to be used for online classification."
An Improved Recommendation Algorithm Based on Two-layer Attention Mechanism,2021,"['Attention', 'Mechanism', 'Recommendation', 'Deep Learning', 'AMITI Algorithm', '주의', '메커니즘', '권장', '딥러닝', '아미티 알고리즘']","인터넷 기술의 발달로 기존의 추천 알고리즘은 사용자나 항목의 심층적인 특성을 학습할 수 없기 때문에 본 논문은 이 문제를 해결하기 위해 AMITI(주의 메커니즘 및 개선된 TF-IDF)에 기반한 추천 알고리즘을 제안했다. CNN(Convolutional Neural Network)에 2중 주의 메커니즘을 도입함으로써 CNN의 특징 추출 능력이 향상되고, 항목 특징에 다른 선호도 가중치가 할당되며, 사용자 선호도와 더 일치하는 권고사항이 달성되었다. 대상 사용자에게 항목을 추천할 때 점수 데이터와 항목 유형 데이터를 TF-IDF와 결합하여 권장 결과의 그룹화를 완료하였다. 본 논문에서 진행한 MovieLens-1M 데이터 세트에 대한 실험 결과는, AMITI 알고리즘이 권장 사항의 정확도를 향상시키고 프레젠테이션 방법의 순서와 선택성을 향상시킨다는 것을 보여준다.","With the development of Internet technology, because traditional recommendation algorithms cannot learn the in-depth characteristics of users or items, this paper proposed a recommendation algorithm based on the AMITI(attention mechanism and improved TF-IDF) to solve this problem. By introducing the two-layer attention mechanism into the CNN, the feature extraction ability of the CNN is improved, and different preference weights are assigned to item features, recommendations that are more in line with user preferences are achieved. When recommending items to target users, the scoring data and item type data are combined with TF-IDF to complete the grouping of the recommendation results. In this paper, the experimental results on the MovieLens-1M data set show that the AMITI algorithm improves the accuracy of recommendation to a certain extent and enhances the orderliness and selectivity of presentation methods."
파노라마방사선사진상에서 골다공증의 판독에서 인공지능의 민감영역 연구,2021,"['Panoramic radiograph', 'Neural network', 'Osteoporosis', 'Mandible']",국문 초록 정보 없음,"Artificial intelligence, has been applied in interpreting osteoporosis on dental panoramic radiograph with high accuracy. The purpose of this study was to investigate the sensitive area of convolutional neural network(CNN), one of artificial intelligence, in interpreting osteoporosis on dental panoramic radiograph. Dental panoramic radiographs taken from 1,170 female (49.19 ±21.91 average age, 21 minimum age, and 84 maximum age) were selected for this study. Two oral maxillofacial radiologists agreed upon interpreting osteoporosis by interpreting mandibular inferior cortical changes. The region of interest included upper and lower jaws for training and testing CNN in interpreting osteoporosis. A filter which was set to look for image characteristics moved through the entire panoramic radiography to identify sensitive areas that distinguish normal groups and osteoporosis patients. In interpreting osteoporosis on panoramic radiograph, CNN responded sensitively at the cancellous bone of the upper and lower jaws while oral maxillofacial radiologists interpreted mandibular inferior cortical change."
Convolution Neural Network을 이용한 탭홀 비전검사 시스템,2021,"['convolution neural network', 'image classification', 'tap hole', 'vision system', 'image processing']","탭홀의 내부에는 파손, 함몰, 이물질 존재 등의 다양한 불량이 존재할 수 있다. 카메라를 이용한 비전 시스템을 활용하여 검사를 하면 데이터베이스의 구축과 사용자의 숙련도에 따른 검사가 아닌 균일한 검사를 실시할 수 있다. 비전검사중 CNN을 사용하여 양품과 불량품을 분류하고, 불량품의 유형은 따로 분류한다. 학습데이터 7:3의 비율로 양품과 불량을 구성하여 진행한다. CNN의 구조는 2개의 Convolution layer와 2개의 Pool layer, 1개의 Fully Connected layer로 구성된다.","Various defects such as breakage, depression, and presence of foreign substances may exist inside the tap hole. If inspection is performed using a vision system using a camera, uniform inspection can be performed rather than based on the construction of a database and the user""s proficiency. During vision inspection, CNN is used to classify good and defective products, and the types of defective products are classified separately. The training data is carried out by composing good and bad products in a ratio of 7:3. The structure of CNN consists of two convolution layers, two pool layers, and one fully connected layer."
깊은 합성곱 신경망 모델에 따른 유방 초음파 영상 분류 성능 비교,2021,"['Breast Ultrasound', 'Breast Cancer', 'Tumor', 'Classification', 'VGG', 'ResNet', 'InceptionNet', 'DenseNet', 'EfficientNet', 'Convolutional Neural Network']",국문 초록 정보 없음,"Breast ultrasound has been widely utilized for classifying tumors into benignancy and malignancy. The limitations of traditional breast ultrasound are the handcrafted features obtained by well-trained sonographers and subjective decision according to different individual experiences. Recently, CNN-based deep learning techniques have exhibited better performance in medical images. However, most research for deep learning in medical ultrasound adopts CNN models developed for natural images due to the lack of common standard and dataset. In this paper, we compare six DCNN models which exhibit good performance for natural images - VGGNet, ResNet, InceptionNet, DenseNet, and EfficientNet. Our classification results demonstrate that CNN models of relatively lower performance on natural images show better performance on gray-scale ultrasound images and further study of CNN models are needed focusing on the features of medical images."
운전자의 주의분산 연구동향 및 딥러닝 기반 동작 분류 모델,2021,"['Driver’s Behavior', 'Driver’s Distraction', 'Behavior Recognition', 'ResNet-101', 'CAM', '운전자의 동작', '운전자의 주의 분산', '동작 인식']","본 논문에서는 운전자의 주의산만을 유발하는 운전자, 탑승자의 동작을 분석하고 핸드폰과 관련된 운전자의 행동 10가지를 인식하였다. 먼저 주의산만을 유발하는 동작을 환경 및 요인으로 분류하고 관련 최근 논문을 분석하였다. 분석된 논문을 기반으로 주의산만을 유발하는 주요 원인인 핸드폰과 관련된 10가지 운전자의 행동을 인식하였다. 약 10만 개의 이미지 데이터를 기반으로 실험을 진행하였다. SURF를 통해 특징을 추출하고 3가지 모델(CNN, ResNet-101, 개선된 ResNet-101)로 실험하였다. 개선된 ResNet-101 모델은 CNN보다 학습 오류와 검증 오류가 8.2배, 44.6배가량 줄어들었으며 평균적인 정밀도와 f1-score는 0.98로 높은 수준을 유지하였다. 또한 CAM(class activation maps)을 활용하여 딥러닝 모델이 운전자의 주의 분산 행동을 판단할 때, 핸드폰 객체와 위치를 결정적 원인으로 활용했는지 검토하였다.","In this paper, we analyzed driver""s and passenger""s motions that cause driver""s distraction, and recognized 10 driver""s behaviors related to mobile phones. First, distraction-inducing behaviors were classified into environments and factors, and related recent papers were analyzed. Based on the analyzed papers, 10 driver""s behaviors related to cell phones, which are the main causes of distraction, were recognized. The experiment was conducted based on about 100,000 image data. Features were extracted through SURF and tested with three models (CNN, ResNet-101, and improved ResNet-101). The improved ResNet-101 model reduced training and validation errors by 8.2 times and 44.6 times compared to CNN, and the average precision and f1-score were maintained at a high level of 0.98. In addition, using CAM (class activation maps), it was reviewed whether the deep learning model used the cell phone object and location as the decisive cause when judging the driver""s distraction behavior."
Privacy-preserving and Communication-efficient Convolutional Neural Network Prediction Framework in Mobile Cloud Computing,2021,"['Privacy Preservation', 'Convolutional Neural Networks', 'Homomorphic Encryption', 'Mobile Cloud Computing', 'Deep Learning']",국문 초록 정보 없음,"Deep Learning as a Service (DLaaS), utilizing the cloud-based deep neural network models to provide customer prediction services, has been widely deployed on mobile cloud computing (MCC). Such services raise privacy concerns since customers need to send private data to untrusted service providers. In this paper, we devote ourselves to building an efficient protocol to classify users’ images using the convolutional neural network (CNN) model trained and held by the server, while keeping both parties’ data secure. Most previous solutions commonly employ homomorphic encryption schemes based on Ring Learning with Errors (RLWE) hardness or two-party secure computation protocols to achieve it. However, they have limitations on large communication overheads and costs in MCC. To address this issue, we present LeHE4SCNN, a scalable privacy-preserving and communication-efficient framework for CNN-based DLaaS. Firstly, we design a novel low-expansion rate homomorphic encryption scheme with packing and unpacking methods (LeHE). It supports fast homomorphic operations such as vector-matrix multiplication and addition. Then we propose a secure prediction framework for CNN. It employs the LeHE scheme to compute linear layers while exploiting the data shuffling technique to perform non-linear operations. Finally, we implement and evaluate LeHE4SCNN with various CNN models on a real-world dataset. Experimental results demonstrate the effectiveness and superiority of the LeHE4SCNN framework in terms of response time, usage cost, and communication overhead compared to the state-of-the-art methods in the mobile cloud computing environment."
Neural network-based build time estimation for additive manufacturing: a performance comparison,2021,"['additive manufacturing', 'artificial neural network', '3D convolutional neural network', 'build time estimation', '3D printing']",국문 초록 정보 없음,"Additive manufacturing (AM) has brought positive opportunities with phenomenal changes to traditional manufacturing. Consistent efforts and novel studies into AM use have resolved critical issues in manufacturing and broadened technical boundaries. Build time estimation is one of the critical issues in AM that still needs attention. Accurate build time estimation is key for feasibility studies, preliminary design, and process/production planning. Recent studies have provided the possibility of neural network (NN)-based build time estimation. In particular, traditional artificial NN (ANN)- and convolutional NN (CNN)-based methods have been demonstrated. However, very little has been done on the performance comparison for build time estimation among the different types of NNs. This study is aimed at filling this gap by designing various NNs for build time estimation and comparing them. Two types of features are prepared as inputs for the NNs by processing three-dimensional (3D) models: (1) representative features (RFs) including dimensions, part volume, and support volume; and (2) the set of voxels generated from designating the cells occupied by the workpiece in a mesh grid. With the combination of NN types and input feature types, we design three NNs: (1) ANN with RFs; (2) ANN with voxels; and (3) CNN with voxels. To obtain large enough label data for reliable training, we consider simulation build time from commercial slicing applications rather than actual build time. The simulation build time is calculated based on a material extrusion process. To address various cases for input models, two design factors (scale and rotation) are considered by controlling the size and build orientation of 3D models. In computational experiments, we reveal that the CNN-based estimation is often more accurate than others. Furthermore, the design factors affect the performance of build time estimation. In particular, the CNN-based estimation is strongly influenced by changing the size of 3D models."
딥러닝 기반 부실기업 예측모형에 관한 연구,2021,"['기업 부실화', '딥러닝 기법', '머신러닝', '앙상블 모형', '한계기업 예측', 'Corporate Insolvency', 'Deep Learning', 'Machine Learning', 'Ensemble Model', 'Marginal Company Prediction']","부실기업 예측은 회계와 재무 분야에서 중요하게 다루어져 온 연구 주제이다. 특히, 급변하는 기업 환경과 최근 COVID-19 대유행으로 국내의 많은 기업이 기업 부실화로 재무적 어려움에 직면하고 있어 그 연구의 필요성이 더욱 강조되고 있다. 대표적인 관련 연구로는 기업부도 예측이 있지만, 부도기업은 사실상 사업활동을 중단한 기업으로 계속기업 간에 어떠한 기업이 부실 징후를 보이는지를 판단하는 기준으로 부적합하다는 한계점이 존재한다. 본 연구는 부실기업의 범주 중 하나인 한계기업을 그 예측대상으로 선정하였다. 한계기업은 3개년도 연속 이자보상비율이 1 미만인 기업으로, 사업활동을 영위하고 있으나 적정 수준의 이익을 지속적으로 확보하지 못하고 있는 부실기업을 의미한다. 본 연구에서는 한계기업 예측을 위한 방법으로 딥러닝 기법을 활용하였다. 딥러닝은 다양한 분야에서 그 우수성을 인정받아 최근 주목받고 있는 머신러닝 기법의 하나이지만 한계기업 예측을 위한 연구에서는 적용된 바가 없다. 본 연구는 여러 재무비율 변수를 독립변수로 하여 딥러닝 기법 중 RNN과 CNN를 적용하고, 선행연구에서 예측력이 뛰어나다고 보고된 머신러닝 앙상블 모형들과 그 성과를 비교하였다. 2017~2019년의 기업 데이터를 학습용 및 테스트용 데이터로 설정하여 분석한 결과, RNN-LSTM, RNN-GRU, CNN이 재현율(Recall)의 관점에서 우수한 성과를 보이는 것으로 나타났다. 그러므로 딥러닝 모형이 한계기업 예측에서도 널리 사용될 수 있는 분석방법이 될 것으로 기대된다.","Predicting insolvent companies is a research topic that has been important in accounting and finance. Especially, due to the rapidly changing business environments and the recent COVID-19 pandemic, many domestic companies are facing financial adversity. Thus, the necessity of research on corporate insolvency is being emphasized. As a related research, there is a prediction of corporate bankruptcy, however, a bankrupt company is the company whose business activities have been suspended, and there is a limitation in which it is inappropriate to determine which companies show signs of bankruptcy among continuing companies. Therefore, marginal company, one of the categories of insolvent companies, is selected as the prediction target. Marginal companies are the firms that are operating income interest compensation ratio are less than 1 for three consecutive years, and are engaged in business activities but have not consistently secured adequate profits. In this study, deep learning techniques are used to predict them. It is one of the machine learning techniques that has recently attracted attention because of its excellence in various fields. Nonetheless, has not been applied in research to predict marginal companies. This study applies RNN and CNN among deep learning techniques using several financial ratios as independent variables. Their performance are compared with machine learning ensemble models that have been reported to have excellent predictive power in previous studies. As a result of analysis on corporate data from 2017 to 2019 as training and test data, deep learning models such as RNN-LSTM, RNN-GRU, and CNN are better in forecasting of marginal companies than the ensemble models in terms of Recall score. Therefore, the deep learning models are expected to become widely used in the prediction of marginal companies in the future."
Effective Electricity Demand Prediction via Deep Learning,2021,"['LSTM', 'CNN', 'Electricity demand prediction', 'Deep-learning', 'Machine-learning', 'ARIMA', 'MLP']",국문 초록 정보 없음,"Prediction of electricity demand in homes and buildings can be used to optimize an energy management system by decreasing energy wastage. A time-series prediction system is still a challenging problem in machine learning and deep learning. Our main idea is to compare three methods. For this work, we analyzed an electricity demand prediction system using the current state-of-the-art deep-learning methods with a machine-learning method: error correction with multi-layer perceptron (eMLP) structure, autoregressive integrated moving average (ARIMA) structure, and a proposed structure named CNN-LSTM. For this, we measured and collected electricity demand data in Germany for home appliances. We report the prediction accuracy in terms of the mean square error (MSE) and mean absolute percentage error (MAPE). The experimental result indicates that CNN-LSTM outperforms eMLP and ARIMA in accuracy."
An Autonomous Driving Approach Based on Trajectory Learning Using Deep Neural Networks,2021,"['Autonomous driving', 'Trajectory learning', 'CNN_Raw-RNN', 'Pilot and copilot']",국문 초록 정보 없음,"Autonomous driving approaches today are mainly based on perception-planning-action modular pipelines and the End2End paradigm respectively. The End2End paradigm is a strategy that directly maps raw sensor data to vehicle control actions. This strategy is very promising and appealing because complex module design and cumbersome data labeling are avoided. Since this approach lacks a degree of interpretability, safety and practicability. we propose an autonomous driving approach based on trajectory learning using deep neural networks in this paper. In comparison to End2End algorithm, it is found that the trajectory learning algorithm performs better in autonomous driving. As for trajectory learning algorithm, the CNN_Raw-RNN network structure is established, which is verified to be more effective than the original CNN_LSTM network structure. Besides, we propose an autonomous driving architecture of a pilot and copilot combination. The pilot is responsible for trajectory prediction via imitation learning with labeled driving trajectories, while the copilot is a safety module that is employed to verify the effectiveness of the vehicle trajectory by the results of the semantic segmentation auxiliary task. The proposed autonomous driving architecture is verified with a real car on urban roads without manual intervention within 40 km."
딥러닝 기반의 전동킥보드 자동 주차 단속,2021,"['Parking Enforcement', 'Shared Kickboards', 'CNN-like', 'Deep Learning']",비교적 저렴한 가격으로 가까운 거리를 빠르게 이동할 수 있는 공유기반 전동킥보드의 이용률이 크게 향상되고 있다. 문제는 전동킥보드가 적절하지 않은 공간에 주차되어 안전사고를 유발하는 것이다. 본 논문에서는 딥러닝 기반 객체 인식 기술을 적용하여 방치된 전동킥보드의 잘못된 주차를 인식하는 체계를 제안한다. 본 논문에서는 실험 데이터의 특성을 고려하여 CNN과 유사한 모델을 별도로 생성하였으며 실험을 통하여 60%의 인식률을 얻었음을 보였다.,"The use of shared electric kickboards that can move quickly within a short distance at a relatively low price is increasing significantly. In this paper, we propose a system for recognizing incorrect parking of an abandoned shared kickboard by applying deep learning-based object recognition technology. In this paper, a model similar to CNN was created separately considering the characteristics of the experimental data, and it was shown that a recognition rate of 60% was obtained through the experiment."
ResNet과 Unet을 결합한 딥러닝 모델을 이용한 분광 신호에서 ROI 검출,2021,"['Peak Detection', 'Region of Interest', 'Deep Learning', 'CNN', 'Raman Spectroscopy']","본 연구에서는 딥러닝 기술(deep learning technology)을 이용하여 분광 신호의 ROI(region of interest)를 찾는 방법을 제안한다. 제안한 방법은 모의실험 데이터로 학습된 딥러닝 모델을 이용하여 분광 신호의 ROI를 검출하는 방법이다. 분광 신호의 피크는 물질의 물리 화학적인 정보를 포함하고 있으므로 정확한 피크 검출은 분석 시스템의 성능에 영향을 미치는 중요한 과정이다. 지금까지 가장 많이 사용되는 방법은 진폭을 기반으로 피크 검출을 진행하는 것이다. 하지만 이런 방법들은 전처리 과정을 포함하거나 분광 신호에 따라 파라미터를 육안 검사로 선택하여 추정하므로 복잡하고 주관적이다. 이러한 문제점 개선을 위해 딥러닝 모델을 통해 분광 신호의 ROI 검출을 수행하였다. 제안한 방법은 전처리 과정이 없고 파라미터를 설정하지 않아도 되는 장점을 갖는다. 또한 검출한 ROI에 따라 분광 신호에 후처리(post-processing)를 수행하여 피크를 얻을 수 있다. 디폴트 손실 함수에 3만개 테스트 데이터를 적용하여 얻은 손실값을 통해 성능 평가를 수행하였다. 제안된 ResNet과 Unet을 결합한 딥러닝 모델은 일반적인 컨볼루션 신경망(CNN: Convolutional Neural Network), ResNet, 그리고 Unet에 비해 각각 76.5%, 69.8%, 5.9%의 성능 향상을 보였으며, 실제 라만 분광 신호의 ROI 검출에도 효과적으로 적용될 수 있음을 확인하였다.","This study proposes a method to find the ROI (region of interest) of spectral signals using deep learning technology. The proposed method detects the ROI of spectral signals using a deep learning model trained with simulated data. Since the peak of the spectral signal contains physical and chemical information of the substance, accurate peak detection is an important process affecting the performance of the analyzed system. The widely used method for peak detection is the one based on the amplitude. However, this method is complex and subjective because it involves pre-processing or select and estimate parameters using visual inspection according to spectral signals. To overcome this problem, ROI detection of the spectral signal was performed through a deep learning model. The proposed method has the advantage of requiring no pre-processing and parameter setting. In addition, a peak may be obtained by performing post-processing of the spectral signal according to the detected ROI. Performance evaluation was performed through loss values obtained by applying 30,000 test data to the custom loss function. The proposed deep learning model combining ResNet and Unet showed performance improvements of 76.5%, 69.8%, and 5.9% compared to the general convolutional neural network (CNN), ResNet, and Unet, respectively. It was also confirmed that the proposed method could be effectively applied to measured spectral signals."
인공지지체 불량 검출을 위한 딥러닝 모델 성능 비교에 관한 연구,2021,"['Algorithm Evaluate', 'Classification Performance Compare', 'CNN', 'Defect Detection Model', 'Scaffold Defect']",국문 초록 정보 없음,"When we inspect scaffold defect using sight, inspecting performance is decrease and inspecting time is increase. We need for automatically scaffold defect detection method to increase detection accuracy and reduce detection times. In this paper. We produced scaffold defect classification models using densenet, alexnet, vggnet algorithms based on CNN. We photographed scaffold using multi dimension camera. We learned scaffold defect classification model using photographed scaffold images. We evaluated the scaffold defect classification accuracy of each models. As result of evaluation, the defect classification performance using densenet algorithm was at 99.1%. The defect classification performance using VGGnet algorithm was at 98.3%. The defect classification performance using Alexnet algorithm was at 96.8%. We were able to quantitatively compare defect classification performance of three type algorithms based on CNN."
관성센서와 합성곱 신경망을 이용하는 골프 스윙 분석에서의 특징 추출 방법,2021,"['관성센서(Inertial sensor)', '합성곱 신경망(CNN)', '골프(Golf)']",국문 초록 정보 없음,"Feature extraction method while analyzing human motion using inertial sensors and convolutional neural networks (CNNs) is a significant factor that greatly affects the subsequent analysis accuracy. In this study, we tried to find the most suitable method for feature extraction from the inertial sensor signal during golf swing analysis using an inertial sensor and a CNN. Five feature extraction methods were presented in consideration of the characteristics of the 6-axis inertial sensor. To compare the accuracy in golf swing segmentation, 9 male professional golfers and 11 high-skilled amateur golfers swung with a driver and a 7 iron to collect the golf swing data. As a result of comparing each of the proposed feature extraction methods when learning a CNN, the method that extracts features for each axis of the sensor signal shows the highest estimation accuracy. The result implies that the method can be used preferentially among various feature extraction methods for golf swing analysis."
"『길 위 1번지』, AI 제임스의 소설 : 「소설의 기술」과 인공신경망 알고리즘의 글쓰기",2021,"['Henry James', '“The Art of Fiction', '” 1 the Road', 'CNN', 'RNN', 'Creativity']",국문 초록 정보 없음,"This article explores the implications of 1 the Road (2018), a fiction produced by an artificial neural network, for the debate on machine creativity. Unlike most of the recent deeplearning writing programs, its creator Ross Goodwin traveled with this neural network machine from New York to New Orleans in a Cadillac equipped with a surveillance camera, a voice recognizer, and GPS. The AI thus had continuous feeds of fresh images and sounds, not unlike a novelist who hits the road searching for an experience. I argue that we can better understand this attempt of 1 the Road when discussed alongside Henry James’s realist notion of fiction in his essay “The Art of Fiction” (1884). Even though James is often considered an arch-humanist in his belief that fiction is an expression of the unique personality of a novelist, his idea of experience offers a way of understanding Goodwin’s machine as a creative writer. Its algorithmic operation―processing the new sense data via the CNN algorithm and producing the result as writing via the RNN algorithm―is strikingly similar to the workings of the novelist’s mind in James’s view. I do not argue that those sense data are unmediated, and this fact is reflected in the CNN’s algorithm that imitates the human mind. In fact, James asserts that sensory data are the result of mediated selection, which can only be seen through the final result, the writing itself. What I propose is that regardless of whether the machine has a so-called “consciousness,” its writing can affect the reader in similar ways as does a text written by a human being. As long as it works as a linguistic medium to relate the “experience,” which is the algorithmic process of selection and transcription, it is a creative writer."
Methods of Generating Time Series Image for detecting Anomalies in Time Series data,2021,"['Recurrence Plot', 'Gramian Angular Field', 'Markov Transition Field', 'LSTM', 'CNN']",국문 초록 정보 없음,"To detect anomalies in time series data, statistical techniques such as PCA and autoencoder are used, or anomalies are detected based on deep learning models such as RNN. It is difficult to expect good performance only with simple statistical techniques or RNN-based deep learning models because the environment and causes in which anomalies are recorded are not simple and various variables affect them. In this paper, we proposed a method of detecting anomalies using CNN-based deep learning model, a binary classification model of representative images, by imaging time series data. RP, GASF, GADF, and MAF algorithms were used as methods for imaging. All of time series image-based models showed equal or higher accuracy than conventional LSTM-based models, and among imaging-based CNN models, the method of imaging with MTF algorithm derived the highest accuracy."
DNN을 이용한 낮은 복잡도를 가지는 손 동작 인식에 관한 연구,2021,[],"손 동작을 인식하여 여러가지 사물의 기기를 올바르게 제어하기 위하여 다양한 인공지능 기술이 이용되고 있으며, 그 중에서도 CNN(Convolutional Neural Network) 기술은 성능이 우수하여 많이 이용되고 있다. 그러나 CNN 기법은 성능은 우수하지만, 높은 복잡도를 가지고 있는 단점이 있다. 따라서 본 논문에서는 손 동작 인식을 위하여 낮은 복잡도를 가지면서 CNN과 유사한 성능을 갖도록 전처리 과정을 거치는 DNN(Deep Neural Network)기법을 제안한다. 이를 위하여 입력으로 받은 영상으로부터 손 동작을 인식하기 위하여 Canny 알고리즘을 이용하여 엣지를 검출한 후에, DNN 기법을 이용하여 낮은 복잡도를 갖는 알고리즘을 연구하였다. 이러한 알고리즘은 손 동작을 통한 다양한 사물 인터넷 기기의 제어와 응용에 활용가능할 것으로 예상된다.",다국어 초록 정보 없음
혼합 가스 분류를 위한 전이학습 기반 방법론,2021,"['Mixture Gas Classification', 'Convolutional Neural Network', 'Transfer Learning']",국문 초록 정보 없음,"This paper proposes a new method for mixed gas classification based on the convolutional neural network (CNN) using transfer learning. The mixed gas classification is challenging because a gas sensor array of mixed gases is complex and high dimensional data. Moreover, it is limited to obtain enough training datasets due to high data collection costs. To overcome the challenges, the proposed method maps a gas sensor array into an analogous-image matrix, adopts the CNN for feature extraction from images, and uses transfer learning to speed up training and improve the performance of the CNN. The proposed method is validated using public mixture gas data from the UCI Machine Learning Repository and real data examples."
스마트폰 가속도계를 이용한 보행자 운동 인식 알고리즘,2021,"['Pedestrian Navigation', 'Smartphone', 'Motion Recognition', 'Decision Tree', 'Convolutional Neural Network']",국문 초록 정보 없음,"Pedestrian motion recognition algorithms using the accelerometer on a smartphone are implemented, and performance evaluation results are presented. The features for classifying the decision tree and design parameters of a CNN (Convolutional Neural Network) for recognizing pedestrian motion are listed. The accelerometer outputs of a smartphone that was used to monitor six adults who performed six motion types were collected. The decision tree thresholds were determined, and the CNN weights were learned from the collected data. With the derived thresholds and weights, the real-time pedestrian motion recognition algorithms were implemented on a smartphone, and their performance was evaluated. The performance evaluation results show that the CNN-based motion recognition algorithm has better accuracy than the decision tree-based motion recognition algorithm."
인공지능 기반 후두암 진단지원 모델 개발을 위한 후보모델 탐색 연구,2021,[],"본 연구는 후두내시경 이미지를 활용하여 인공지능 기술을 통한 후두암 진단 지원모델 개발을 위한 탐색 연구를 수행하였다. 두경부 분야 인공지능 연구 현황과 적용할 후보모델 알고리즘을 검토하였다. 샘플데이터를 기반으로 YOLO, Faster R-CNN, CNN+GradCAM 알고리즘 기반 모델을 활용한 파일럿 모델을 구축하고 성능을 평가하였다. VGG19를 활용한 CNN+GradCAM 알고리즘 모델이 준수한 성능과 임상적 유효성 평가 및 진단지원 모델적용시의 높은 활용적 이점을 나타내어, 이를 기반으로 향후 본 데이터셋 구축과 최적 학습을 통해 강건하고 우수한 성능의 모델 개발이 가능할 것이다.",다국어 초록 정보 없음
Faster RCNN과 픽셀 분류 신경망을 이용한 다상유동에서의 기포 검출에 대한 연구,2021,"['Bubble Detection', 'Artificial Neural Network', 'Multiphase Flow', '기포 검출', '인공 신경망', '다상유동']","다상유동에서 기포 크기 분포를 알기 위해 사용되고 있는 기존 이미지 처리 기법들은 실험 수행 조건에 영향을 받는다. 본 연구에서는 CNN을 기반으로 한 기포 검출 기법을 제안한다. 이미지에서 기포가 위치한 영역을 찾기 위해서 Faster RCNN을 사용하였고, 픽셀 분류 신경망을 이용해서 찾아진 영역에서 기포를 분할하였다. 신경망들을 훈련시키기 위해 필요한 이미지는 세 종류의 기포발생기를 이용한 실험으로부터 얻었으며, 배경 밝기, 유량들을 변경하며 실험하였다. 신경망의 backbone 구조에 따른 성능에 대한 비교를 진행하였다. 신경망의 깊이에 따른 구조 병렬화 영향에 대한 분석할 수 있었고 제안된 신경망은 실시간으로 이미지로부터 기포를 검출할 수 있었다.","Characterization of bubbles in gas-liquid multiphase flow is important to design and optimize industrial systems. To this end, multiple visual techniques, including image processing, have been developed to measure bubble size distributions. However, traditional image processing methods significantly influence experimental settings. Thus, an improved bubbled detection method based on convolutional neural networks (CNNs) is proposed herein. This method involves using a faster region-based CNN (Faster RCNN) to detect the bubble location and a pixel classification network to segment bubble shapes. Experiments were conducted using three types of bubble generators with various background intensities and volume flow rates. Furthermore, the backbone CNN architectures used in the Faster RCNN and the pixel classification network were compared. The model network is highly versatile, is capable of characterizing bubble information in real-time, and has the potential to replace the traditional image processing method."
딥 러닝을 이용한 단일 카메라 SLAM에서 스케일 드리프트 감소,2021,"['Monocular SLAM', 'Scale Drift', 'Deep Learning', 'Convolutional Neural Network']",국문 초록 정보 없음,"Monocular SLAM(Simultaneous Localization and Mapping) systems have such advantages as low cost and light weight compared to stereo or laser range finder based SLAM systems. However they also have relatively large errors when they measure the distances between a vehicle and some distinct objects, which can lead to scale ambiguity or scale drift. In this paper, we suggest a scale drift-aware monocular SLAM system using CNN(Convolutional Neural Network) which is one of the key technologies of Deep Learning. CNN nowadays has proved its performances especially in computer vision. We have trained the system with plenty of images of some predetermined objects using CNN. And then we can measure the absolute distances between a vehicle and already known objects and resolve the scale drift problems. The suggested system has been evaluated by several experiments."
딥러닝 성능 향상과 인지부하 평가를 위한 뇌파데이터의 웨이블릿 전처리 기법,2021,"['Wavelet', 'CNN', '뇌전도', 'EEG', '인지부하', '딥러닝']","학습이나 작업중 인지부하는 학습능력과 작업 효율성과 밀접한 관계를 가지고 있다. 인지부하를 측정하는 방법은 지필평가, 행동변화 평가, 생체신호에 의한 평가방법이 있으며 이중에서 생체신호에 의한 평가는 무의식적인 반응을 통해 객관적으로 평가할 수 있는 방법으로 알려져 있다. 특히 뇌파에 의한 평가는 중추신경계의 반응을 통해 알아내려는 시도로 전통적으로 다양한 생체신호처리를 통해 이루어지고 있다. 본 연구에서는 딥러닝을 통해 뇌파신호를 학습하고 정량적인 인지부하 평가 모델을 구축하기 위한 분석단계에서 시공간 분석이 가능한 웨이블릿 기반 특징추출을 적용하고 이를 통해 효율적인 CNN분류가 가능한 방법을 제안하였다. 본 연구의 결과를 통해 정량화된 뇌파분석을 위한 연구에 초석이 될 수 있을 것으로 기대한다.",다국어 초록 정보 없음
드론과 Mobile Mapping System을 활용한 인공지능 기반 도로 균열 검출,2021,"['artificial intelligence', 'CNN', 'drone', 'mobile mapping system', 'mobilenetv2', 'road crack', '인공지능', '드론', '모바일매핑시스템', '도로 균열']","최근 5년간 중앙정부의 전체 예산은 매년 4.9%의 비율로 증가하고 있으나, 도로부문의 유지관리 예산은 매년 줄고 있다. 또한 도로법의 개정 및 지속가능한 기반시설 관리 기본법의 신설에 따라 모든 지자체에서 유지관리와 성능개선을 위해 5년 단위의 기본계획을 수립해야 한다. 하지만 상대적으로 예산이 적은 지자체에서 도로관리를 위한 고가의 장비를 도입하기는 현실적으로 어려운 실정이다. 이에 본 연구는 인공지능을 활용하여 상대적으로 가격이 저렴한 Mobile Mapping System(MMS)와 드론을 활용한 도로균열 검출 방법을 제시하는 것을 연구의 목적으로 한다. MMS와 드론을 활용하여 얻은 해상도 높은 도로 노면 사진데이터를 취득하고 데이터의 특성에 따라 인공지능을 학습시키기 위하여 전처리를 수행하였다. 딥러닝 학습을 위해 도로 파손 유형에 따라 균열이 있는 곳과 없는 곳, 또는 도로가 아닌 곳으로 라벨링을 진행하였고 Basic CNN모델과 Mobilenetv2신경망을 수정하여 학습을 진행하였다. Mobilenetv2의 알고리즘의 분류정확도는 MMS데이터 95%, 드론데이터 78%를 얻었다. 이는 MMS와 드론을 활용하여 정도 높은 균열 분류가 가능하다는 결론을 도출할 수 있었다. 향후 본 연구에서 개발된 알고리즘을 기반으로 지자체와 시설물 관리 기관에서 도로균열을 체계적으로 관리될 것이다. 또한 사용자 중심의 소프트웨어를 활용하여 도로를 이용하는 시민들에게도 도움이 될 것으로 기대된다.","In recent years, the total budget of the central government has been increasing at a rate of 4.9% per year, but the maintenance budget of the road sector has been decreasing annually. In addition, with the revision of the Road Act and the establishment of the Framework Act on Sustainable Infrastructure Management, all local governments shall establish a five-year master plan to improve maintenance and performance. However, it is difficult for local governments with relatively small budgets to introduce expensive equipment for road management. In response, the purpose of this study is to present a road crack detection method using mobile mapping system (MMS) and drones that are relatively inexpensive with the use of artificial intelligence. High-precision road surface photographic data could be acquired using MMS and drones. Pre-processing was carried out to train the artificial intelligence depending on the characteristics of the data. Labeling was conducted according to the type of road cracks and was labeled based on where cracks were present, where none were present, or where roads were not. The training was done by modifying the basic convolution network model and the mobilenetv2 neural network. As a result of the training, the data classification accuracy using the mobilenetv2 algorithm was able to achieve 95% on MMS data and 78% on drone data. It can be hypothesized that a more high-performance crack classification accuracy might be achieved by utilizing MMS and drone equipment. In the future, road cracks will be systematically managed by local governments and facility management agencies based on algorithms developed in this study. It is also expected to benefit citizens who use user-centered software to use roads."
돌발 상황을 대비한 자율주행 시스템 구현,2021,"['자율주행', '돌발 장애물', 'CNN', '실시간 통신']","자율주행 기술이 고도화됨에 따라 사용자가 주행 상황을 실시간으로 모니터링하고 주행을 제어할 수 있는 자율주행 서비스가 필요하다고 생각했다. 또한, 돌발 장애물을 고려하며 정해진 경로로 주행하는 자율주행을 구현하고자 해당 시스템을 설계하게 되었다. 해당 시스템은 차량, 서버, 애플리케이션으로 구성되어있으며 구성요소 간의 실시간 통신을 통해 차량 주행 상황 및 사용자 제어 명령을 자유롭게 전달하고자 했다. 차량의 자율주행 알고리즘을 구현하기 위해 이미지 데이터 처리에 효과적인 CNN을 활용하여 장애물 회피 모델과 라인 트레이서 모델을 구현하여 해당 모델들을 하나의 솔루션으로 통합하였다. 해당 솔루션 구현을 통해 차량이 마주할 수 있는 돌발 상황에 대처하는 자율주행의 안전성을 높이고자 했으며 자율주행 환경에서 사용자 조작을 용이하게 하고자 하였다.",다국어 초록 정보 없음
증강현실을 위한 객체인식 기술 성능 비교,2021,"['YOLO', 'SSD', 'AR', '객체인식']",증강현실의 핵심기술은 객체인식기술이다. 최근 CNN등 다양한 인공지능 알고리즘의 개발로 인하여 영상s에서 특정 객체를 효과적으로 구분하는 것이 가능해졌다. 객체를 빠르고 정확하게 인식하는 기술이 확보되어야 더욱 현실감 있고 몰입감 있는 증강현실 콘텐츠의 구현이 가능해진다. 본 연구에서는 SSD(single shot multibox detector)를 이용한 객체인식 모델과 YOLO를 이용한 객체 인식 모델의 비교평가를 수행하였다.,"The core technology of augmented reality is object recognition technology. Recently, due to the development of various artificial intelligence algorithms such as CNN, it has become possible to effectively distinguish specific objects from images. It is possible to realize more realistic and immersive augmented reality contents only when technology for recognizing objects quickly and accurately is secured. In this study, an object recognition model using SSD (single shot multibox detector) and an object recognition model using YOLO were compared and evaluated."
Xception과 양방향 LSTM을 통한 뇌종양 진단에 관한 연구,2021,"['Deep Learning', 'Artificial Intelligence', 'Diagnosis', 'CNN', 'LSTM', 'Xception', 'Brain Tumor']","뇌종양은 전체 종양 중 세 번째로 많을 뿐만 아니라 우리나라에서도 환자 수가 늘어나는 추세이다. 하지만 영상기반 검사가 주로 이루어지는 뇌종양의 경우, 전문의가 판단하기 때문에 판독 결과에 오류가 생길 가능성이 있다. 이를 방지하고자 인공지능 기반의 진단 방법이 도입되고 있다. 본 연구의 목적은 뇌종양을 단순히 2가지(정상, 비정상)가 아닌 4가지(교종, 뇌수막종, 뇌수하체 종양, 정상)로 더 정교하게 진단하고, 다른 모델들과 정확도를 비교하는 것이다. 또한, 단순 분류가 아닌 이미지 분할을 통해 환자로 분류한 근거를 시각화한다. 이를 위해 본 논문에서는 Xception과 양방향 LSTM을 활용한 모델을 통해 MRI 사진을 4가지로 분류하고 정확도를 다른 딥러닝 알고리즘들과 비교, 분석한다. 또한, CAM(Class Activation Map)을 통해 이상 부위를 시각화한다. 분석 결과 본 연구에서 제안하는 모델이 정확도 86%를 보이며 가장 높은 정확도를 기록하였다. 특히, 단순히 Xception 모델을 사용하였을 때 보다 8%가 증가하였다. 따라서 본 연구는 두 가지 의의를 가진다. 첫번째로, 단순 Xception 모델보다 Xception 모델에 양방향 LSTM을 추가하였을 때, VGG16, MobileNet과 같은 다른 CNN기반의 사전 훈련된 딥러닝 모델들보다 성능이 높다는 결론을 도출했다는 점에서 의의가 있다. 두번째로, 기존 2단계로 예측하던 뇌종양 진단을 4단계로 분류함과 동시에 이상 부위를 시각화하여 더욱 정교한 뇌종양 진단 모델을 개발하였다는 점에 의의가 있다.","Brain tumors have the third-largest incidence among tumors, and the number of patients is increasing continuously in Korea. On the other hand, as the diagnosis of brain tumor is conducted mainly through a vision-based inspection by doctors, there is a possibility of errors in the stage of inspection. Artificial intelligence-based diagnostic methods are being introduced to prevent this problem. This study attempted to classify patients into more sophisticated stages (normal, glioma, pituitary, and meningioma) than previous research, which classified them into two stages (normal and patient). The accuracy of the proposed model was compared, and the anomalous part of the brain was visualized. To this end, MRI pictures were classified into four categories through Xception + Bi-directional LSTM and compared to the other pretrained models. Furthermore, the anomalous part of the brain was visualized through CAM (Class Activation Map). The proposed model achieved 86%, which is 8% higher than the simple Xception model. This research is significant in finding that the Xception + Bi-directional LSTM model showed higher accuracy than other pretrained models, such as simple Xception, VGG16, and MobileNet. Furthermore, this research is also worthwhile because the patients could be classified into four categories with high accuracy, and the anomaly parts could be visualized."
주기적 행동 검출을 위한 멀티스케일 U-Net,2021,"['Multi-scale U-Net', '3D CNN', 'Periodicity', 'Repetition']",국문 초록 정보 없음,다국어 초록 정보 없음
Xception과 양방향 LSTM을 통한 뇌종양 진단에 관한 연구,2021,"['Deep Learning', 'Artificial Intelligence', 'Xception', 'Diagnosis', 'CNN', 'LSTM', 'Brain Tumor']","뇌종양은 전체 종양 중 세 번째로 많을 뿐만 아니라 우리나라에서도 환자 수가 늘어나는 추세이다. 하지만 영상기반 검사가 주로 이루어지는 뇌종양의 경우, 전문의가 판단하기 때문에 판독 결과에 오류가 생길 가능성이 있다. 이를 방지하고자 인공지능 기반의 진단 방법이 도입되고 있다. 본 연구의 목적은 뇌종양을 단순히 2가지(정상, 비정상)가 아닌 4가지(교종, 뇌수막종, 뇌수하체 종양, 정상)로 더 정교하게 진단하고, 다른 모델들과 정확도를 비교하는 것이다. 또한, 단순 분류가 아닌 이미지 분할을 통해 환자로 분류한 근거를 시각화한다. 이를 위해 본 논문에서는 Xception과 양방향 LSTM을 활용한 모델을 통해 MRI 사진을 4가지로 분류하고 정확도를 다른 딥러닝 알고리즘들과 비교, 분석한다. 또한, CAM(Class Activation Map)을 통해 이상 부위를 시각화한다. 분석 결과 본 연구에서 제안하는 모델이 정확도 86%를 보이며 가장 높은 정확도를 기록하였다. 특히, 단순히 Xception 모델을 사용하였을 때 보다 8%가 증가하였다. 따라서 본 연구는 두 가지 의의를 가진다. 첫번째로, 단순 Xception 모델보다 Xception 모델에 양방향 LSTM을 추가하였을 때, VGG16, MobileNet과 같은 다른 CNN기반의 사전 훈련된 딥러닝 모델들보다 성능이 높다는 결론을 도출했다는 점에서 의의가 있다. 두번째로, 기존 2단계로 예측하던 뇌종양 진단을 4단계로 분류함과 동시에 이상 부위를 시각화하여 더욱 정교한 뇌종양 진단 모델을 개발하였다는 점에 의의가 있다.","Brain tumors have the third-largest incidence among tumors, and the number of patients is increasing continuously in Korea. On the other hand, as the diagnosis of brain tumor is conducted mainly through a vision-based inspection by doctors, there is a possibility of errors in the stage of inspection. Artificial intelligence-based diagnostic methods are being introduced to prevent this problem. This study attempted to classify patients into more sophisticated stages (normal, glioma, pituitary, and meningioma) than previous research, which classified them into two stages (normal and patient). The accuracy of the proposed model was compared, and the anomalous part of the brain was visualized. To this end, MRI pictures were classified into four categories through Xception + Bi-directional LSTM and compared to the other pretrained models. Furthermore, the anomalous part of the brain was visualized through CAM (Class Activation Map). The proposed model achieved 86%, which is 8% higher than the simple Xception model. This research is significant in finding that the Xception + Bi-directional LSTM model showed higher accuracy than other pretrained models, such as simple Xception, VGG16, and MobileNet. Furthermore, this research is also worthwhile because the patients could be classified into four categories with high accuracy, and the anomaly parts could be visualized."
광섬유 OTDR 데이터의 이상 상태 감지를 위한 오토인코더 구조 비교 연구,2021,[],"본 논문에서는 광섬유 OTDR 데이터의 이상 상태 감지를 위한 convolutional neural network (CNN) 기반 오토인코더 모델을 제안한다. 이를 위해 OTDR 의 수학적 모델을 통해 데이터를 획득하고 sinusoidal 노이즈 혼합하여 이상 상황을 모사하였다. 제안된 CNN-오토인코더 모델의 성능을 기존의 feedforward deep neural network (DNN)-오토인코더 구조와 비교한 결과, 기존의 86% 대비, 89%의 정확도로 이상 위치를 감지하였다.",다국어 초록 정보 없음
딥러닝 기반의 탑승자 HIC 예측 알고리즘 개발,2021,"['NCAP(자동차 안전도 평가)', 'Deep Learning(심층 학습)', 'Head Injury Criterion (머리상해지수)', 'CNN(합성곱 신경망)', 'Collision Safety(충돌 안전)']","본 논문에서는 자동차 충돌 시 얻어지는 도면 이미지 데이터를 기반으로 딥러닝 기법인 CNN을 활용하여 HIC 예측 기법을 제안한다. 자동차 안전성 평가를 위해 각 자동차 제조사들은 실차와 더미를 이용하여 NCAP 기준의 충돌 시험을 시행한다. 실차 충돌 시험 시, 많은 비용과 시간이 소요된다. 이에 본 논문에서는 실차 충돌 시험의 대체 방안으로서, 충돌 시의 도면 이미지 데이터를 기반으로 운전자의 머리 상해 지수를 예측하는 모델을 제안한다.",다국어 초록 정보 없음
MATE: Memory- and Retraining-Free Error Correction for Convolutional Neural Network Weights,2021,"['Convolutional neural network', 'Error correction codes', 'Main memory', 'Reliability', 'Weight data']",국문 초록 정보 없음,"Convolutional neural networks (CNNs) are one of the most frequently used artificial intelligence techniques. Among CNN-based applications, small and timing-sensitive applications have emerged, which must be reliable to prevent severe accidents. However, as the small and timing-sensitive systems do not have sufficient system resources, they do not possess proper error protection schemes. In this paper, we propose MATE, which is a low-cost CNN weight error correction technique. Based on the observation that all mantissa bits are not closely related to the accuracy, MATE replaces some mantissa bits in the weight with error correction codes. Therefore, MATE can provide high data protection without requiring additional memory space or modifying the memory architecture. The experimental results demonstrate that MATE retains nearly the same accuracy as the ideal error-free case on erroneous DRAM and has approximately 60% accuracy, even with extremely high bit error rates."
주파수응답 유사성을 이용한 합성곱 신경망 기반 볼트 체결력 예측,2021,"['Bolt clamp force(볼트 체결력)', 'Model order reduction(모델차수축소법)', 'Frequency response function(주파수응답함수)', 'MS similarity function(크기 및 모양 유사성 함수)', 'CNN(합성곱 신경망)', 'Regression analysis(회귀 분석)']",국문 초록 정보 없음,"Structures fastened with bolts have different dynamic characteristics depending on the fastening state of the bolts. Using these properties, this paper predicts bolt clamping force using frequency response function and MS similarity function. Clamping force prediction is performed through CNN-based regression analysis, and before experiments on actual structures, the results are analyzed using finite element analysis, which is easy to collect data, and it is intended to lay the foundation for future research. Since we do not know what size of training data will show high accuracy and efficiency, we collect data of various sizes and analyze the results of each. In addition, in order to shorten the time in the data collection process, the Krylov subspace-based model order reduction method is applied. After that, enough data is collected, and a neural network is created according to the data size to analyze performance such as error and loss. We intend to identify the most efficient data size and utilize it for future research and system development."
IMU 센서 기반 인간 행동 인식의 학습 방식 성능 분석,2021,[],"본 논문은 Human Activity Recognition(HAR)을 위한 IMU 센서 데이터 기반 데이터셋을 학습하는 방법에 대해 연구하였다. HAR 은 센서를 기반으로 인간의 행동을 분류하는 분야이다. 데이터셋은 UCI-HAR dataset 을 사용하였고, 학습을 수행하기 위해서 Support Vector Machine(SVM), Convolution Neural Network(CNN), Long Short Term Memory(LSTM)과 CNN-SVM, LSTM-SVM 을 사용하였고, 각 딥러닝 모델의 정확도와 F1 score 를 비교 분석하였다.",다국어 초록 정보 없음
인공지능 기반 유해조류 탐지 관제 시스템,2021,"['Drone', 'Machine Learning', 'Atonomous Driving', 'Control Systems', 'Harmful Birds', '드론', '머신러닝', '자율 주행', '관제 시스템', '유해 조류']","본 논문에서는 오리와 같은 유해조류에 의한 양식장의 피해를 방지하기 위해서 머신러닝 기반 해상용 드론 개발을 목적으로 한다. 기존 드론은 공중에서 새와 충돌하거나 바다에 떨어지는 경우 유실되는 문제점을 해결 하기 위해서 해상드론으로 개발하였다. 자율주행으로 작동하는 해상드론이 해상에 나타난 유해조류를 판단하기 위해 CNN기반 머신러닝 학습 알고리즘을 설계하였다. 유해조류의 위치 인식 및 추적을 위해 카메라에 라즈베리파이를 연결하여 관제 PC로 영상을 전송하도록 설계하였다. 모바일 기반 관제 센터에서 미리 GPS 좌표와 연동된 맵을 미리 제작한 후, 유해조류의 위치에 대한 GPS 위치값을 전달받아 설정된 위치로 해상용 드론이 출동하여 유해조류를 퇴치하는 자율주행 기반의 해상용 조류 퇴치 드론 시스템을 설계 및 구현하였다.","The purpose of this paper is to develop a machine learning-based marine drone to prevent the farming from harmful birds such as ducks. Existing drones have been developed as marine drones to solve the problem of being lost if they collide with birds in the air or are in the sea. We designed a CNN-based learning algorithm to judge harmful birds that appear on the sea by maritime drones operating by autonomous driving. It is designed to transmit video to the control PC by connecting the Raspberry Pi to the camera for location recognition and tracking of harmful birds. After creating a map linked with the location GPS coordinates in advance at the mobile-based control center, the GPS location value for the location of the harmful bird is received and provided, so that a marine drone is dispatched to combat the harmful bird. A bird fighting drone system was designed and implemented."
액티브 러닝을 활용한 반도체 웨이퍼 신규 불량 패턴 검출,2021,"['semiconductor manufacturing', 'defect identification', 'wafer bin map', 'active learning', 'sampling strategy', 'convolutional neural network']",국문 초록 정보 없음,"In the semiconductor manufacturing industry, a wafer bin map (WBM) contains defect patterns that provides important clues to identify the root causes of the defect. Traditionally, field engineers classify the pattern types by manually checking WBM. Recently, many studies have been conducted for automatic classification by using deep learning models. To accurately classify defect patterns with convolutional neural network (CNN)-based deep learning models, every WBM must have accurate pattern labels. However, in reality, it takes a lot of time and efforts for engineers to label all the data. In addition, existing CNN-based studies show limitations that cannot detect new defect patterns, frequently occurred in real situations. In this study, we propose a new wafer pattern detection method based on active learning. Active learning effectively samples the data so that accurate model performance can be secured with only a small number of labeled data. In addition, we propose a framework that can quickly detect new defect patterns that are not used in a training stage. The usefulness and applicability of the propose method was demonstrated by WM-811K, publicly available WBM data."
기계학습에 의한 Al-Si 주조 합금 미세조직 이미지 생성,2021,"['Machine learning', 'generative adversarial network', 'image generation', 'microstructure', 'aluminum alloys.']",국문 초록 정보 없음,"In this study, we constructed a deep convolutional generative adversarial network (DCGAN) to generate the microstructural images that imitate the real microstructures of binary Al-Si cast alloys. We prepared four combinations of alloys, Al-6wt%Si, Al-9wt%Si, Al-12wt%Si and Al-15wt%Si for machine learning. DCGAN is composed of a generator and a discriminator. The discriminator has a typical convolutional neural network (CNN), and the generator has an inverse shaped CNN. The fake images generated using DCGAN were similar to real microstructural images. However, they showed some strange morphology, including dendrites without directionality, and deformed Si crystals. Verification with Inception V3 revealed that the fake images generated using DCGAN were well classified into the target categories. Even the visually imperfect images in the initial training iterations showed high similarity to the target. It seems that the imperfect images had enough microstructural characteristics to satisfy the classification, even though human cannot recognize the images. Cross validation was carried out using real, fake and other test images.When the training dataset had the fake images only, the real and test images showed high similarities to the target categories. When the training dataset contained both the real and fake images, the similarity at the target categories were high enough to meet the right answers. We concluded that the DCGAN developed for microstructural images in this study is highly useful for data augmentation for rare microstructures."
2D CQT 심전도 영상을 이용한 운전자 식별 시스템,2021,"['driver identification', 'ECG', 'CQT', 'biometrics']","차량 내 · 외부의 보안이 강조되면서 생체신호를 이용한 운전자 식별 시스템 연구가 활발히 진행되는 중이다. 본 논문에서는 신체 내부에서 전기생리학적 신호로 발생하는 심전도의 1D 데이터를 2D CQT 영상으로 변환하여 운전자를 식별한다. 운전자 식별 시스템은 운전자로부터 취득된 심전도에서 1D 신호의 잡음 제거를 위한 전처리과정, 특징 추출을 위한 기준점 분할 과정, 2D CQT 영상 변환 과정, CNN에 의한 식별 과정으로 구성된다. 실험 결과, 휴식, 시내, 톨, 고속도로 주행 상태에서 평균 식별 정확도가 2D 스펙트로그램보다 0.9%, 2D 스칼로그램보다 13.3 %우수함을 확인하였다.","As security is emphasized inside and outside the vehicle, research on driver identification system using bio-signals is being studied. In this paper, it converts 1D data of an ECG generated as an electrophysiological signal inside the body into a 2D CQT image and identifies the driver. The driver identification system consists of a preprocessing process for noise removal of the 1D ECG signal acquired from the driver, a fiducial point segmentation process for feature extraction, a 2D CQT image conversion process, and an identification process by CNN. As a result of the experiment, it was confirmed that the average identification accuracy was 0.9% better than the 2D spectrogram and 13.3% better than the 2D scalogram in rest, downtown, toll, and high way driving state."
An Empirical Study on Food-Retail Demand Forecasting: A Comparative Analysis of Time Series Deep Learning Models,2021,[],국문 초록 정보 없음,"Accurate demand forecasting in the food-retail industry is a very important task since it can reduce the cost caused by either shortage or overflow of food materials. In this paper, we show a comparative analysis on food-retail demand forecasting using the following two time series deep learning models: long short-term memory (LSTM) and convolutional neural network (CNN)-LSTM models. Using a café point-of-sale (POS) dataset, it is demonstrated that the CNN-LSTM model has a marginal gain over the LSTM model in terms of prediction error."
청각장애인의 수어 교육을 위한 MediaPipe 활용 수어 학습 보조 시스템 개발,2021,"['수어', '학습 보조 플랫폼', '인공 지능 평가', '미디어 파이프', 'Sign Language', 'Learning Aids Platform', 'AI Evaluation', 'MediaPipe']","최근 선천적 청각장애 뿐만 아니라 후천적 요인으로 인해 청각장애를 가지게 되는 사람들도 증가하고 있지만, 수어를 익힐 수 있는 환경은 열악한 상황이다. 이에 본 연구에서는 수어를 배우는 수어 학습자를 위한 수어학습 보조도구로써 수어(지숫자/지문자) 평가 시스템을 제시하고자 한다. 이에 본 논문에서는 OpenCV 라이브러와 MediaPipe를 이용하여 손과 손가락을 추적하여 수어 동작을 인식하고 CNN기법을 이용하여 수어의 의미를 텍스트 형태의 데이터로 변환하여 학습자에게 제공하는 시스템을 연구한다. 이를 통해 수어를 배우는 학습자가 스스로 올바른 수형인지를 판단할 수 있도록 자기주도학습을 가능하게 하여 수어를 익히는데 도움이 되는 수어학습보조 시스템을 개발하고, 청각장애인들의 의사소통의 주언어인 수어학습을 지원하기 위한 방안으로 수어학습보조 시스템을 제안하는 데 목적이 있다.","Recently, not only congenital hearing impairment, but also the number of people with hearing impairment due to acquired factors is increasing. The environment in which sign language can be learned is poor. Therefore, this study intends to present a sign language (sign language number/sign language text) evaluation system as a sign language learning assistance tool for sign language learners. Therefore, in this paper, sign language is captured as an image using OpenCV and Convolutional Neural Network (CNN). In addition, we study a system that recognizes sign language behavior using MediaPipe, converts the meaning of sign language into text-type data, and provides it to users. Through this, self-directed learning is possible so that learners who learn sign language can judge whether they are correct dez. Therefore, we develop a sign language learning assistance system that helps us learn sign language. The purpose is to propose a sign language learning assistance system as a way to support sign language learning, the main language of communication for the hearing impaired."
객체 중심 증강기법을 이용한 임베딩 유사도 기반 군중 이상 탐지,2021,"['Anomaly detection', 'Deep learning', 'Embedding similarity', 'Object centric augmentation.']","본 논문에서는 객체 중심 증강 기법을 사용한 임베딩 유사성 기반 군중 이상 탐지 기법을 제안한다. 우선 모든 비디오 프레임의 영역별 픽셀값에 대해 평균을 구해 사람과 같은 객체가 나타나지 않는 배경 장면을 구성한다. 그 후 입력 이미지에서 이전에 구한 배경 장면의 픽셀 차이를 계산해서 객체만 포함된 이미지를 생성한다. 그런 다음 생성된 이미지에 대해 본 논문에서 제안하는 데이터 증강 기술을 적용하여 이미지의 가능한 모든 공간에 여러 객체가 존재할 수 있도록 이미지를 구성한다. 그런 다음 사전 훈련된 합성 곱 신경망(CNN)을 사용하여 CNN의 서로 다른 레이어로부터 임베딩 벡터를 추출한다. 그 후, 임베딩 벡터의 다변량 가우스 분포를 계산하여 정상 클래스에 대한 확률 파라미터인 평균과 분산값을 얻는다. 그 이후 정상 클래스를 나타내는 참조 벡터와 테스트 이미지에서부터 추출한 임베딩 벡터 사이의 거리를 계산하여 이상 영역이 감지된다. UCSD 데이터 셋을 사용하여 실험한 결과 우리가 제안한 방법이 다른 임베딩 유사성 기반 방법보다 이상 영역을 더 잘 감지할 수 있음을 보여준다. 실험 결과로부터 우리는 움직이는 객체가 있는 이미지가 포함된 데이터 셋에 대해서는 이미지 분포를 모델링 하는 데 있어서 객체 중심 증강 기법이 필수라는 것을 확인하였다.",다국어 초록 정보 없음
Optimization of Cyber-Attack Detection Using the Deep Learning Network,2021,"['cyber attack', 'combined deep learning', 'abnormal behaviors of cyber-attacks', 'detection attacks']",국문 초록 정보 없음,"Detecting cyber-attacks using machine learning or deep learning is being studied and applied widely in network intrusion detection systems. We noticed that the application of deep learning algorithms yielded many good results. However, because each deep learning model has different architecture and characteristics with certain advantages and disadvantages, so those deep learning models are only suitable for specific datasets or features. In this paper, in order to optimize the process of detecting cyber-attacks, we propose the idea of building a new deep learning network model based on the association and combination of individual deep learning models. In particular, based on the architecture of 2 deep learning models: Convolutional Neural Network (CNN) and Long Short Term Memory (LSTM), we combine them into a combined deep learning network for detecting cyber-attacks based on network traffic. The experimental results in Section IV.D have demonstrated that our proposal using the CNN-LSTM deep learning model for detecting cyber-attacks based on network traffic is completely correct because the results of this model are much better than some individual deep learning models on all measures."
Deep Learning Based Rumor Detection for Arabic Micro-Text,2021,"['Rumor Detection', 'Natural Language Processing', 'Convolutional Neural Network', 'Long Short-Term Memory']",국문 초록 정보 없음,"Nowadays microblogs have become the most popular platforms to obtain and spread information. Twitter is one of the most used platforms to share everyday life event. However, rumors and misinformation on Arabic social media platforms has become pervasive which can create inestimable harm to society. Therefore, it is imperative to tackle and study this issue to distinguish the verified information from the unverified ones. There is an increasing interest in rumor detection on microblogs recently, however, it is mostly applied on English language while the work on Arabic language is still ongoing research topic and need more efforts. In this paper, we propose a combined Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) to detect rumors on Twitter dataset. Various experiments were conducted to choose the best hyper-parameters tuning to achieve the best results. Moreover, different neural network models are used to evaluate performance and compare results. Experiments show that the CNN-LSTM model achieved the best accuracy 0.95 and an F1-score of 0.94 which outperform the state-of-the-art methods."
Comparison of the performance of several data-driven prediction models using small-sized thermal comfort datasets,2021,"['Thermal comfort', 'Thermal sensation', 'PMV', 'Machine learning', 'Transfer learning']",국문 초록 정보 없음,"HVAC has become an essential component of modern building systems, increasing thermal comfort and promoting high-quality human life. However, the uncontrolled use of such technologies often leads to excessive waste of energy and creates an undesirable thermal environment that negatively affects human health. Thus, research in data-driven thermal comfort prediction models have been fervidly conducted in a hope of developing accurate and efficient thermal comfort control systems. In continuation of such studies, many state-of-the-art prediction algorithms and methods have been proposed, but not many studies address the essential problem of collecting large-sized thermal comfort data sets for practical use.In this study, three high-performance data-driven prediction models, Random Forest, CNN_LSTM, and TL-CNN_LSTM, were used to test the applicability of using small thermal comfort datasets to control the thermal environment. As a result, the overall prediction performance of the selected models was observed to be more reliable than that of Fanger’s Predicted Mean Vote (PMV) model, but the highest results did not still exceed 45% in accuracy. Given the small size and subjective nature of the thermal comfort dataset, is still premature to apply such models to thermal comfort control operations. Given the subjective nature of the thermal comfort dataset, it is still premature to do the thermal comfort prediction modelling using a small dataset."
AI를 이용한 PEC 측정 데이터 내의 결함 검출,2021,[],"1. PEC(Pulse eddy current) 기법은 단열재하부식(CUI) 검출에 광범위하게 적용되는 전자기 비파괴 진단법이며, 여타 전자기 비파괴 측정 방식들보다 높은 투과성을 이용해 심도깊은 비접촉식 진단이 가능하나 전통적인 측정 방법보다 분석이 어려워 더욱 신뢰성 있는 측정을 위해 더욱 많은 연구가 필요하다. PEC 측정 데이터 분석의 난해함은 검사 시간 및 비용 증가의 원인이 되며, 검사자의 경험과 직관에 대한 의존성이 커 오류 발생 가능성을 높인다. 이 문제를 해결하기 위해서는 방대한 양의 데이터를 정량적으로 분석할 수 있는 인공지능 알고리즘의 도입이 필요하며, 인공지능 도입 가능성과 방안에 대한 연구가 필수적이다. 이 연구에서는 주식회사 AIPIT사가 개발한 PEC 측정 장비를 이용해 배관을 모사한 시편 검사 데이터 취득후 AI 알고리즘을 통해 분석하였다. 시료의 두께가 얇아질수록 일반적인 방법으로는 단차간의 구분이 어려웠으며, 이를 해결하기 위해 SVM과 CNN을 도입하였다.  2. AIPIT 사가 제작한 PEC 측정 장비를 이용하여 시계열의 펄스 와전류 신호를 취득하였으며, 취득한 신호 중 실제 데이터 분석에 이용한 부분은 진폭의 변화량, 최대진폭 및 최대진폭 도달 후 진폭이 펄스 와전류 인가전 시간으로 돌아오는데 걸린 시간이다. 시편에 PEC를 인가 후 장비의 수신 코일에는 먼저 도체 표면에서 유도된 전류가 수신되며, 그 다음 도체내 전도로 유도된 전류가 그 다음으로 감지되며, 이후로는 인가 지점에서 먼 곳에서 유도된 전류가 수신된다. 그러므로 수신된 시계열 전류 신호의 데이터의 중후반부에 도체내 발생한 결함, 도체의 두께에 정보가 있어 이를 분석해 결함 및 두께 정보를 추정할 수 있다. 보온재에 둘러싸인 배관의 내부 두께 측정이 가능한 것인지 확인해 보기 위해 다섯 개의 단차를 가진 탄소강 배관을 준비하였다. 0.5 mm 두께의 스테인레스 크래딩 안에 50 mm 두께의 플라스틱 보온재가 ASTM A106 Grade B 소재의 배관을 둘러 싸고 있다. 배관의 총 길이는 1500 mm이며, 300 mm의 동일간격으로 두께가 단계적으로 일정하게 줄어들도록 제작하였다. 배관 표면부를 동경 방향 매 45도마다 분할해 8 지점 및 길이 방향으로 5개의 계단 부 및 4개의 변곡 지점 총합 9 지점을 측정 지점으로 선정하였다. 총 측정지점은 72곳이며, 각 지점에서 10회씩 총 720개의 펄스 와전류 측정을 수행하였다. 데이터의 정규화 수행을 통해 측정간에 발생한 오차 및 노이즈의 영향을 완화하였다. 잘 알려진 CNN 처리 모델 중 VGG19 및 Inception을 이용하였으며, 모델 내 Convolution 부분은 실험 데이터에 맞게 1차원으로 수정되었다. 도입한 모델 중 높은 성능을 가진 모델 및 Sampling Length를 구별하기 위한 성능 지표로 Mean Absolute Error를 기존으로 삼아 측정을 수행하였다.  3. 펄스 와전류 측정을 통해 취득한 실험 데이터의 AI를 이용한 분석을 수행해 기존 방식의 숙련자의 경험에 의존하지 않으며 인간적 오류의 영향 여지가 적은 정량적 분석을 해내는 딥러닝 모델 개발의 가능성 및 한계를 확인하였으며, 이 모델의 배관 단차 추정 성능이 통계적 방법으로 분석이 어려운 구간에서도 두께를 추정할 수 있음을 확인하였다. 또한 각 모델의 성능 특성 및 최적 작동 환경을 분석을 통해 적합한 알고리즘과 작동 환경 및 이들의 경향성을 확인하였다. Sampling Length가 길어질수록 MAE는 낮아지는 경향을 보였고, 이는 펄스 와전류 진폭이 줄어드는 양상을 충분히 반영할 수 있는 길이의 데이터를 투입하여 성능을 더욱 높일 수 있음을 의미한다.",다국어 초록 정보 없음
Explanation segments 기반 설명 가능한 지식 완성 모델,2021,"['knowledge graph', 'explainable knowledge completion', 'embedding', 'attention mechanism', '지식 그래프', '설명 가능한 지식 완성', '임베딩', '어텐션 메커니즘']","최근 딥러닝을 활용하여 불완전한 지식 그래프를 대상으로 새로운 링크를 예측하는 연구가 많이 진행되고 있지만, 딥러닝을 활용한 링크 예측은 추론 결과에 대한 설명이 불가능하다는 한계점이 있다. 따라서 본 논문에서는 링크 예측 후, 추론 결과를 뒷받침하는 증거로서 설명 가능한 추론 경로를 제공하여 지식 완성의 효용성이 높은 모델을 제안한다. 이를 위해 우선 지식 그래프의 주어를 시작으로 목적어로 도달하는 또 다른 경로를 Path Ranking Algorithm 활용하여 생성하며, 이를 explanation segment라 정의하였다. 이 후 생성된 explanation segment를 CNN과 양방향 LSTM을 결합한 방식을 적용하여 임베딩 한다. 마지막으로 임베딩 된 explanation segment들과 추론할 후보 술어와의 의미적 유사성 계산을 기반으로 한 어텐션 메커니즘을 적용하여, 링크 예측 모델을 학습하였다. 모델 학습 후 링크 예측 설명에 적합한 explanation segment를 어텐션 점수에 기반으로 선정하여 제공한다. 제안하는 방법의 성능을 측정하기 위해 링크 예측 비교 실험 및 링크 예측 결과에 대한 설명으로 적합한 explanation segment의 비율을 측정하는 정확성 검증 실험을 진행하였다. 실험 데이터는 벤치마크 데이터인 NELL-995, FB15K-237, Countries를 대상으로 진행하였으며, 정확성 검증 실험에서 평균 89%. 44%, 97% 정확성을 보였고, 기존 연구와 비교했을 때, NELL-995는 평균 35%p, FB15K-237은 평균 21%p 높은 성능을 보였다.","Recently, a large number of studies that used deep learning have been conducted to predict new links in incomplete knowledge graphs. However, link prediction using deep learning has a major limitation as the inferred results cannot be explained. We propose a high-utility knowledge graph prediction model that yields explainable inference paths supporting the inference results. We define paths to the object from the knowledge graph using a path ranking algorithm and define them as the explanation segments. Then, the generated explanation segments are embedded using a Convolutional neural network (CNN) and a Bidirectional Long short-term memory (BiLSTM). The link prediction model is then trained by applying an attention mechanism, based on the calculation of the semantic similarity between the embedded explanation segments and inferred candidate predicates to be inferred. The explanation segment suitable for link prediction explanation is selected based on the measured attention scores. To evaluate the performance of the proposed method, a link prediction comparison experiment and an accuracy verification experiment are performed to measure the proportion of the explanation segments suitable to explain the link prediction results. We used the benchmark datasets NELL-995, FB15K-237, and countries for the experiment, and accuracy verification experiments showed the accuracies of 89%, 44%, and 97%, respectively. Compared with the existing method, the NELL-995, FB15K-237 data exhibited 35%p and 21%p higher performance on average."
머신러닝을 활용한 울릉분지 가스 하이드레이트 퇴적물의 광물 정량분석,2021,[],"광물 조성은 퇴적물의 기원, 저류층 특성, 가스하이드레이트(gas hydrate, GH) 부존과 관련이 있기 때문에 퇴적물의 광물 정량분석은 GH 저류 가능성을 평가하는 데 매우 중요하다. 지금까지 광물 정량분석은 X선 회절(X-ray diffraction, XRD) 분석을 통해 얻은 회절 패턴을 전문가가 분석하여 수행되어 왔다. 특히 GH 저류층은 매우 복잡한 광물 조성을 가지고 있고 비정질인 오팔-A도 포함하고 있기 때문에 정량 분석을 수행하는 데 많은 어려움이 있었다. 본 연구에서는 머신러닝을 이용하여 12개의 광물을 포함하고 있는 복잡한 조성의 울릉분지 GH 퇴적물의 광물 조성을 XRD 패턴으로부터 빠른 시간에 분석할 수 있는 모델을 개발하였다. 입사각에 대한 3100개의 XRD 피크 강도를 입력값으로 12개의 광물 조성비를 출력값으로 지도학습을 수행하였다. 울릉분지 퇴적물로부터 획득된 총 488개의 XRD 패턴과 광물 조성 값이 얻어졌고 8개의 시추공에 대해 데이터의 차원을 일치시키기 위해 전처리를 수행하였다. 488개의 데이터를 307개의 학습 데이터 132개의 검증 데이터 49개의 테스트 데이터로 나누어 학습을 수행하였으며 순환신경망(Recurrent Neural Network, RNN), 다중 계층 퍼셉트론(Multi-Layer Perceptron, MLP), 무작위숲(Random Forest, RF), 합성곱신경망 (Convolution Neural Network, CNN)의 네 개의 알고리즘을 활용되었다. 네 개의 알고리즘 중 RF 알고리즘이 전문가의 분석을 통해 얻은 값과의 각 광물 별 평균 차이가 2.56%로 가장 잘 예측하는 결과를 보여주었고 다른 알고리즘도 3% 미만의 차이를 나타내며 머신러닝을 활용한 광물조성 예측 가능성이 발견되었다. LSTM 알고리즘의 경우 입력값에 상관없이 비슷한 광물조성을 예측하는 결과를 보여주었고, CNN은 대부분의 광물에 대해 전문가가 분석한 값과 가장 큰 차이를 보였다. MLP의 경우 오팔-A나 석영과 같은 주요 광물에 대해서는 대체적으로 낮은 값을 예측하였고 미량의 광물에 대해서는 높은 값을 예측하였다. 본 연구를 통해 GH 퇴적물 시료에 대해 머신러닝을 활용하여 전문가의 분석 없이 XRD 실험을 통해 얻은 패턴으로부터 광물 조성을 빠르게 예측할 수 있는 가능성이 발견되었다.",다국어 초록 정보 없음
Development of a Deep Learning-based Electronic Nose System for Real-time Gas Identification,2021,"['Real-time gas identification', 'Deep learning', 'Electronic nose']",국문 초록 정보 없음,"The demand for gas sensors is increasing because of the growing interest in monitoring indoor/outdoor air pollutions. In particular, small-sized, low-cost, and highly sensitive semiconductor metal oxide (SMO) gas sensors are attracting attention as the next-generation gas sensors. However, there are limitations in the actual applications of SMO gas sensors due to their low selectivity. Although the method of implementing gas identification through multi-sensor-based electronic nose systems is in the limelight, the problems that it is difficult to implement gas identification in real-time, have yet to be resolved. In this study, the selectivity problem could be solved by fabricating a gas sensor array and applying the sensing data from the sensor array to the deep learning network. The fabricated gas sensor array used nanocolumnar films of metal oxides (SnO₂, In₂O₃, WO₃, and CuO) deposited through the glancing angle deposition (GLAD) as the sensing materials, and the convolutional neural network (CNN) was selected as the deep learning network for gas identification. Finally, a real-time gas identification for CO, NH₃, NO₂, Methane, and Acetone gas was achieved with an accuracy of 98% by applying preprocessed sensing data collected from the gas sensor arrays to the CNN."
오토인코더 기반의 잡음에 강인한 계층적 이미지 분류 시스템,2021,"['이미지 분류', '딥러닝', '머신러닝', '오토인코더', '잡음', 'Image classification', 'Deep learning', 'Machine learning', 'Autoencoder', 'Noise']",본 논문은 다수의 오토인코더 모델들을 이용한 잡음에 강인한 이미지 분류 시스템을 제안한다. 딥러닝 기술의 발달로 이미지 분류의 정확도는 점점 높아지고 있다. 하지만 입력 이미지가 잡음에 의해서 오염된 경우에는 이미지 분류 성능이 급격히 저하된다. 이미지에 첨가되는 잡음은 이미지의 생성 및 전송 과정에서 필연적으로 발생할 수밖에 없다. 따라서 실제 환경에서 이미지 분류기가 사용되기 위해서는 잡음에 대한 처리 및 대응이 반드시 필요하다. 한편 오토인코더는 입력값과 출력값이 유사하도록 학습되어지는 인공신경망 모델이다. 입력데이터가 학습데이터와 유사하다면 오토인코더의 출력데이터와 입력데이터 사이의 오차는 작을 것이다. 하지만 입력 데이터가 학습데이터와 유사성이 없다면 오토인코더의 출력데이터와 입력데이터 사이의 오차는 클 것이다. 제안하는 시스템은 오토인코더의 입력데이터와 출력데이터 사이의 관계를 이용한다. 제안하는 시스템의 이미지 분류 절차는 2단계로 구성된다. 1단계에서 분류 가능성이 가장 높은 클래스 2개를 선정하고 이들 클래스의 분류 가능성이 서로 유사하면 2단계에서 추가적인 분류 절차를 거친다. 제안하는 시스템의 성능 분석을 위해 가우시안 잡음으로 오염된 MNIST 데이터셋을 대상으로 분류 정확도를 실험하였다. 실험 결과 잡음 환경에서 제안하는 시스템이 CNN(Convolutional Neural Network) 기반의 분류 기법에 비해 높은 정확도를 나타냄을 확인하였다.,"This paper proposes a noise-tolerant image classification system using multiple autoencoders. The development of deep learning technology has dramatically improved the performance of image classifiers. However, if the images are contaminated by noise, the performance degrades rapidly. Noise added to the image is inevitably generated in the process of obtaining and transmitting the image. Therefore, in order to use the classifier in a real environment, we have to deal with the noise. On the other hand, the autoencoder is an artificial neural network model that is trained to have similar input and output values. If the input data is similar to the training data, the error between the input data and output data of the autoencoder will be small. However, if the input data is not similar to the training data, the error will be large. The proposed system uses the relationship between the input data and the output data of the autoencoder, and it has two phases to classify the images. In the first phase, the classes with the highest likelihood of classification are selected and subject to the procedure again in the second phase. For the performance analysis of the proposed system, classification accuracy was tested on a Gaussian noise-contaminated MNIST dataset. As a result of the experiment, it was confirmed that the proposed system in the noisy environment has higher accuracy than the CNN-based classification technique."
기계학습의 LSTM을 적용한 지상 기상변수 예측모델 개발,2021,"['Weather forecast', 'deep learning', 'RNN', 'LSTM']",국문 초록 정보 없음,"Numerical weather prediction (NWP) models play an essential role in predicting weather factors, but using them is challenging due to various factors. To overcome the difficulties of NWP models, deep learning models have been deployed in weather forecasting by several recent studies. This study adapts long short-term memory (LSTM), which demonstrates remarkable performance in time-series prediction. The combination of LSTM model input of meteorological features and activation functions have a significant impact on the performance therefore, the results from 5 combinations of input features and 4 activation functions are analyzed in 9 Automated Surface Observing System (ASOS) stations corresponding to cities/islands/mountains. The optimized LSTM model produces better performance within eight forecast hours than Local Data Assimilation and Prediction System (LDAPS) operated by Korean meteorological administration. Therefore, this study illustrates that this LSTM model can be usefully applied to very short-term weather forecasting, and further studies about CNN-LSTM model with 2-D spatial convolution neural network (CNN) coupled in LSTM are required for improvement."
Attention U-Net 신경망을 활용한 유체의 미래 상태 예측 기법,2021,"['딥러닝', '합성곱 신경망', '전산 유체 역학', '나비에-스토크스 방정식', '유체 시뮬레이션', 'Computational fluid dynamics', 'Navier Stokes equation', 'Deep learning', 'Convolutional Neural network', 'Fluid simulation.']","전산 유체 역학 시뮬레이션은 항공기, 건물, 자동차 등 유체와 관련된 다양한 디자인 분야에서 활용이 되어지고 있으나, 오랜 실행 시간과 많은 비용이 발생하는 나비에-스토크스 방정식의 사용으로 인해 개발에 많은 시간이 소요된다. 또한 위험 물질이 확산되는 환경과 같이 즉각적인 유체 흐름의 분석이 필요한 분야에서는활용이 어렵기 때문에 최대한 정확도를 보존하면서 빠르게 예측하는 기술이 매우 중요하게 여겨지고 있다.이를 위해 본 연구에서는 Attention U-Net 신경망을 기반으로 유체의 흐름을 예측하는 방법론을 제안하고테스트한다. 장애물을 인식하여 빠르게 7초 후 미래의 유체 흐름을 예측하는 방법으로 테스트를 진행하였고, 그 결과 기존 시뮬레이션 소프트웨어 및 CNN모델을 사용하였을 때 대비 정확도는 최대한 보존하면서 실행속도는 약 85배 빠른 결과를 얻을 수 있었다.","Computational Fluid Dynamics (CFD) simulation is used in various fluid-related fields such as aircrafts, buildings, or automobiles design and it consumes a lot of development time due to the use of Navier Stokes equation, which incur a long execution time with high cost. In addition, it is difficult to use it in such environments as the hazardous substance or epidemic diffusion where the fluid flow must be predicted immediately. In the situations, it is important and critical to predict as quickly as possible while preserving accuracy. Hence in this study, to address the issues, we suggest and test a method that uses Attention U-Net neural network to predict the future state of the fluid in a terrain with obstacles. As a result, compared to the existing simulation software or simple CNN method, the suggested approach shows the execution speed is 85 times faster while preserving the competitive accuracy."
Human Laughter Generation using Hybrid Generative Models,2021,"['Laughter Synthesis', 'Variational Autoencoder', 'Autoencoder', 'Objective and Subjective Evaluation']",국문 초록 정보 없음,"Laughter is one of the most important nonverbal sound that human generates. It is a means for expressing his emotions. The acoustic and contextual features of this specific sound are different from those of speech and many difficulties arise during their modeling process. During this work, we propose an audio laughter generation system based on unsupervised generative models: the autoencoder (AE) and its variants. This procedure is the association of three main sub-process, (1) the analysis which consist of extracting the log magnitude spectrogram from the laughter database, (2) the generative models training, (3) the synthesis stage which incorporate the involvement of an intermediate mechanism: the vocoder. To improve the synthesis quality, we suggest two hybrid models (LSTM-VAE, GRU-VAE and CNN-VAE) that combine the representation learning capacity of variational autoencoder (VAE) with the temporal modelling ability of a long short-term memory RNN (LSTM) and the CNN ability to learn invariant features. To figure out the performance of our proposed audio laughter generation process, objective evaluation (RMSE) and a perceptual audio quality test (listening test) were conducted. According to these evaluation metrics, we can show that the GRU-VAE outperforms the other VAE models."
Pixel Attention을 활용한 경량 Super-Resolution 모델,2021,[],국문 초록 정보 없음,"With the advancement of deep learning, CNN-based super-resolution (SR) models have made tremendous progress. However, these models have a disadvantage in that they are difficult to use in an actual environment because they require a significant computational cost. In order to compensate for this demerit, SR models focusing on light weighting have been recently developed. This paper analyzes lightweight SR models and proposes a method to add an appropriate attention module to them. As a result, a model with better qualitative results was implemented while maintaining the computational cost."
트랜스포머 기반 객체 검출,2021,[],DETR 등 트랜스포머 기반 객체 검출에서는 백본에서 출력된 특징맵을 트랜스포머의 인코더와 디코더를 통해 멀티헤드 어텐션(Multi Head 셀프 어텐션)을 수행하여 우수한 검출  성능을 얻고 있다. 본 논문에서는 멀티헤드 어텐션중 일부 연산을 CNN으로 대체하여 검출 성능의 향상을 시도한다. NEU 결함 데이터를 사용하여 ResNet에 대한 비교 실험을 수행한다.,다국어 초록 정보 없음
YOLOv5와 모션벡터를 활용한 트램-보행자 충돌 예측 방법 연구,2021,"['Tram', 'Dense Optical Flow', 'Estimation of Collision point', 'TTC', 'Time-To-Collision', 'YOLOv5', '트램', '충돌지점 추정', '충돌시간 추정']",국문 초록 정보 없음,"In recent years, autonomous driving technologies have become a high-value-added technology that attracts attention in the fields of science and industry. For smooth Self-driving, it is necessary to accurately detect an object and estimate its movement speed in real time. CNN-based deep learning algorithms and conventional dense optical flows have a large consumption time, making it difficult to detect objects and estimate its movement speed in real time. In this paper, using a single camera image, fast object detection was performed using the YOLOv5 algorithm, a deep learning algorithm, and fast estimation of the speed of the object was performed by using a local dense optical flow modified from the existing dense optical flow based on the detected object. Based on this algorithm, we present a system that can predict the collision time and probability, and through this system, we intend to contribute to prevent tram accidents."
감시 카메라를 이용한 딥러닝 기반의 화재 경보 시스템,2021,"['AUC', 'Convolution neural network', 'Cross validation', 'Deep learning', 'Fire detect', 'ROC curve', 'Surveillance camera']","센서 기반의 기존의 화재 검출기는 먼지나 습도에 의하여 오작동을 하여 유지 관리에 많은 비용이 들며, 경험적 파라미터에 크게 의존하기 때문에 조직적인 설계가 이루어질 수 없다. 또한, 프레임 차분을 통한 화재 검출 방식은 카메라의 통신 상태가 좋지 못한 곳에서는 그 성능이 떨어질 수밖에 없다. 이 논문에서는 CNN기반의 새로운 화재 감지 시스템을 보인다. 작은 화재까지도 검출하기 위하여 최소의 수용장 영역 (receptive filed)을 선택하였다. 또한, 매 프레임에서 화재를 검출하는 방식을 취하기 때문에 통신 환경 상태와 무관한 일정한 성능을 보인다. 정확한 검증을 위하여 교차 검증을 하여, 96.2%의 f1—score, 0.98의 최소 AUC를 얻었다.",다국어 초록 정보 없음
이미지 전처리와 앙상블 기법을 이용한 이미지 기반 악성코드 분류 시스템,2021,[],"정보통신 기술이 발전함에 따라 악의적인 공격을 통해 보안문제를 발생시키고 있다. 또한 새로운 악성코드가 유포되어 기존의 시그니처 비교방식은 새롭게 발생하는 악성코드를 빠르게 분석 할 수 없다. 새로운 악성코드를 빠르게 분석하고 방어기법을 제안하기 위해 악성코드의 패밀리를 분류할 필요가 있다. 본 논문에서는 악성코드의 바이너리 파일을 이용해 시각화하고 CNN모델을 통해 분류한다. 또한 정확도를 높이기 위해 LBP, HOG를 통해 악성코드 이미지에서 중요한 특성을 찾고 데이터 클래스 불균형에서 오는 문제를 앙상블 모델을 통해 해결하는 시스템을 제안한다.",다국어 초록 정보 없음
A Low Computational Cost Sensor-Based Human Activity Recognition using Hybrid-LSTM in Edge Computing Environment,2021,"['Human Activity Recognition', 'Thermal Array Sensor', 'Low-cost', 'Hybrid-LSTM', 'Edge Computing']",국문 초록 정보 없음,"In this paper, we proposed a hybrid-Long Short-Term Memory (LSTM) deep learning algorithm for thermal sensor-based Human Activity Recognition (HAR). Edge computing is characterized with Deep Learning (DL) computational capability as well as real-time response which is a requirement for non-intrusive HAR application. Applying DL on edge devices is more challenging due to the limited computational capability. Hence, a low-cost computational CNN-LSTM model is proposed in this work. Based on the simulation results, the proposed approach achieved a computational time of 0.5543 ms. which outperforms other algorithms."
딥러닝 기반 자세 및 손 제스처 인식 기술을 활용한 병원 수어 번역 프로그램 설계 및 구현,2021,[],"본 논문에서는 병원 진료시 수어 사용자들의 불편함을 줄여주기 위한 수화 통역기를 제안한다. ASL(American Sign Language)를 사용한 통, 번역기의 경우 관련 기술과 제품이 많다고 할 수 있지만 한국어 수어의 경우 많지 않다는 단점이 존재한다. 본 논문에서는 이러한 문제점을 보완하기 위해서 Mediapipe의 실시간 Hand Skeleton Tracking을 사용하여서 관절의 키 포인트를 추출한 뒤 잔차 구조를 사용한 CNN과 BI-DIRECTIONAL LSTM, Bahdanau Attention를 사용한 모델을 학습 시켜 수어를 예측하였다. 이의 효율성을 측정하기 위해 직접 촬영한 영상들로 예측을 해보았을 때 학습 데이터에서 약 99%, 테스트 데이터에서 98%의 높은 정확도를 기록하였다.",다국어 초록 정보 없음
유전알고리즘을 이용한 영상 분류 신경망 구조 탐색,2021,[],신경망 학습에 있어서 하이퍼파라미터를 설정하는 것과 신경망의 구조를 설계하는 것은 신경망의 성능에 있어서 매우 핵심적인 부분이다. 하지만 사람이 하이퍼파라미터와 신경망의 구조를 어떻게 정해주어야 신경망의 성능이 좋을지 알기도 어려울뿐더러 많은 시간이 요구된다. 현재 대부분의 신경망 구조는 전문가의 경험적 지식에 의존하여 직관적인 판단에 의해 설계된다. 이에 본 논문에서는 유전 알고리즘을 이용하여 Random CNN의 하이퍼파라미터와 신경망 구조를 자동으로 최적화하는 방법에 대해 소개한다.,다국어 초록 정보 없음
Darknet YOLO 버전 별 도심로 객체 검출 성능 비교,2021,"['DeepLearning(딥러닝)', 'Darknet', 'YOLOv3', 'Object Detection(객체검출)', 'Recognition(인식)']","자율주행 기술을 구성하는 세 단계의 파트인 인식, 판단, 제어 중 인식 파트는 라이다, 레이다, 초음파, 카메라 등의 센서가 차량의 전방향을 향해 정보를 수집하도록 골고루 장착되어 각 센서의 특성에 맞는 정보를 받아들인다. 카메라 센서는 영상정보를 받아 객체를 검출하는 역할을 한다. 카메라 센서를 통해 받아들인 영상 정보는 영상처리를 통해 필요한 정보를 획득하는 방법이 사용되어 왔으나 최근 딥러닝을 이용한 CNN기반 객체검출 알고리즘을 접목하여 성능을 향상시키는 연구가 증가하고 있다. 자율주행에서의 객체검출은 실시간성이 중요한 요소이다. 딥러닝 기반 객체 검출 알고리즘은 기본적으로 많은 계산량을 요구한다. 여러 객체 검출 알고리즘 가운데 Darknet은 One-stage Detection 모델 중의 하나로 획기적으로 연산 속도를 줄여 실시간에 근접한 검출 속도를 내는 것이 특징이다. 본 논문은 Darknet의 객체 검출모델 YOLO의 최근 버전 세 가지 모델 v3, v4, v5를 비교하는 실험을 진행하였다. 차이점과 구조, 그리고 같은 데이터셋에서 보이는 성능의 차이를 실험을 통해 비교해보았다. 실험에 사용된 데이터셋은 국내 화성, 대구 등의 도심로에서 직접 취득한 11,500장의 이미지로 이루어져 있다. 검출 대상의 클래스는 도심로 주행 시 공사구간에서 마주칠 수 있는 객체 및 신호등 신호를 포함한 10가지 객체로 선정하였다. 꼬깔콘, 차선 스틱, PE드럼 등이 포함되어 있다. 실험은 동일한 PC와 실차 상에 탑재하여 진행하였고 그 결과를 고찰하였다.",다국어 초록 정보 없음
그래프 딥러닝 모델 기반 RSE검지기 교통량 데이터 예측연구,2021,[],"효율적인 교통관리를 발전시키기 위해 지능형 교통체계(ITS)의 개발에 대한 관심이 높아짐에 따라 다양한 정보와 신뢰도 있는 교통정보가 요구되었다. 기존의 VDS 검지기 방식의 데이터는 초기구축 및 유지보수 비용이 높으며 수집가능한 정보의 한계가 있으므로 대체 가능한 교통정보 수집에 대한 연구가 필요하다. 본 연구에서는 RSE 검지기의 교통정보를 추출하여 딥러닝 모델을 적용한 뒤 VDS 교통량을 예측하는 연구를 진행하였다. 수집된 교통정보는 시간적인 특성과 공간적인 특성을 동시에 보유하므로 그래프 형식의 데이터로 변환한 뒤 ASTGCN 모델을 적용하였다. 이전에 연구한 FCNN과 CNN-LSTM 모델 예측값과 비교한 결과 시공간적 특성에 대해 학습해야할 뿐만 아니라 데이터 형식에 따라 예측값이 향상될 수 있음을 발견하였다. 이에, RSE 검지기 데이터로 VDS 검지기 데이터를 예측하여 적용함으로써 더욱 효율적인 교통정보 수집 및 제공이 이루어질 것으로 예상된다.",다국어 초록 정보 없음
얼굴 랜드마크 거리 특징을 이용한 표정 분류에 대한 연구,2021,"['facial recognition', 'emotion recognition', 'classification', 'coordinate distance correlation', 'feature selection']",표정 인식은 다양한 분야에서 지속적인 연구의 주제로서 자리 잡아 왔다. 본 논문에서는 얼굴 이미지 랜드마크 간의 거리를 계산하여 추출된 특징을 사용해 각 랜드마크들의 관계를 분석하고 5가지의 표정을 분류한다. 다수의 관측자들에 의해 수행된 라벨링 작업을 기반으로 데이터와 라벨 신뢰도를 높였다. 또한 원본 데이터에서 얼굴을 인식하고 랜드마크 좌표를 추출해 특징으로 사용하였으며 유전 알고리즘을 이용해 상대적으로 분류에 더 도움이 되는 특징을 선택하였다. 본 논문에서 제안한 방법을 이용하여 표정 인식 분류를 수행하였으며 제안된 방법을 이용하였을 때가 CNN을 이용하여 분류를 수행하였을 때 보다 성능이 향상됨을 볼 수 있었다.,"Facial expression recognition has long been established as a subject of continuous research in various fields. In this paper, the relationship between each landmark is analyzed using the features obtained by calculating the distance between the facial landmarks in the image, and five facial expressions are classified. We increased data and label reliability based on our labeling work with multiple observers. In addition, faces were recognized from the original data and landmark coordinates were extracted and used as features. A genetic algorithm was used to select features that are relatively more helpful for classification. We performed facial recognition classification and analysis with the method proposed in this paper, which shows the validity and effectiveness of the proposed method."
초고속영상의 의미론적 분할 및 객체 추적,2021,"['ultra-high-speed image', 'semantic segmentation', 'object tracking', '초고속영상', '의미적 분할', '객체추적']",국문 초록 정보 없음,"Ultra-high speed images are highly utilized as they can analyze the phenomena that are difficult to distinguish with the naked eye. In order to automatically recognize objects existing in the images, this paper proposes a method of semantically segmenting and tracking objects in ultra-high speed images. The proposed method consists of two phases: object segmentation and object tracking. In the object segmentation phase, the method segments an object region in the first ultra-high speed image using DeepLab v3+ which is a kind of CNN-based semantic segmentation models, extract the boundary pixels to track the object. The object tracking phase continuously extracts the object region in the second image and in subsequent images. The performance of the proposed method is verified by experiments. As a result of the experiment, the accuracy of object segmentation and object tracking show about 77% mIoU, about 83% mIoU, respectively."
실제 위치 데이터를 기반으로 실시간으로 근미래 위치를 예측하는 시스템,2021,[],"소비자의 과거 위치 데이터를 기반으로 다음 경로를 예측하는 것은 마케팅 부분에서 매우 중요한 부분이다. 그러나 전체 데이터를 이용해서 다음 위치를 제공하는 연구는 많았지만 이는 시간이 오래걸리기 때문에 서비스 제공에 이용하기에는 무리가 있다. 그래서 실시간으로 다음 경로를 예측 할 수 있는 서비스를 만들어 보았다. 데이터를 모으는 과정부터 데이터 베이스에 저장하고 활용해 시각화 하는 과정까지 총괄하는 서비스를 만들었다. 이 논문에서는 이동 데이터를 분석해 다음 위치를 예측하는 부분을 다룬다. 이동데이터를 전처리할때 학습의 편이를 위해 데이터의 형태를 [위도, 경도, 시간] 에서 [라벨값, 시간]으로 바꾸었다. 이 데이터를 CNN을 이용해 학습시킴으로서 실시간으로 예측값을 제공할 수 있다.",다국어 초록 정보 없음
Improved Convolutional Neural Network Based Cooperative Spectrum Sensing For Cognitive Radio,2021,"['Cognitive radio', 'Cooperative spectrum sensing', 'Primary user', 'Simulated annealing', 'Neural network']",국문 초록 정보 없음,"Cognitive radio systems are being implemented recently to tackle spectrum underutilization problems and aid efficient data traffic. Spectrum sensing is the crucial step in cognitive applications in which cognitive user detects the presence of primary user (PU) in a particular channel thereby switching to another channel for continuous transmission. In cognitive radio systems, the capacity to precisely identify the primary user’s signal is essential to secondary user so as to use idle licensed spectrum. Based on the inherent capability, a new spectrum sensing technique is proposed in this paper to identify all types of primary user signals in a cognitive radio condition. Hence, a spectrum sensing algorithm using improved convolutional neural network and long short-term memory (CNN-LSTM) is presented. The principle used in our approach is simulated annealing that discovers reasonable number of neurons for each layer of a completely associated deep neural network to tackle the streamlining issue. The probability of detection is considered as the determining parameter to find the efficiency of the proposed algorithm. Experiments are carried under different signal to noise ratio to indicate better performance of the proposed algorithm. The PU signal will have an associated modulation format and hence identifying the presence of a modulation format itself establishes the presence of PU signal."
얼굴 스푸핑 방지를 위한 다중 양식에 관한 연구,2021,[],국문 초록 정보 없음,"Face anti-spoofing (FAS) techniques play a significant role in the defense of facial recognition systems against spoofing attacks. Existing FAS methods achieve the great performance depending on annotated additional modalities. However, labeling these high-cost modalities need a lot of manpower, device resources and time. In this work, we proposed to use self-transforming modalities instead the annotated modalities. Three different modalities based on frequency domain and temporal domain are applied and analyzed. Intuitive visualization analysis shows the advantages of each modality. Comprehensive experiments in both the CNN-based and transformer-based architecture with various modalities combination demonstrate that self-transforming modalities improve the vanilla network a lot. The codes are available at https://github.com/chenmou0410/FAS-Challenge2021."
Multi-layered attentional peephole convolutional LSTM for abstractive text summarization,2021,"['abstractive text summarization', 'convolutional long short-term memory', 'deep neural network', 'long short-term memory', 'sequence to sequence modeling']",국문 초록 정보 없음,"Abstractive text summarization is a process of making a summary of a given text by paraphrasing the facts of the text while keeping the meaning intact. The manmade summary generation process is laborious and time-consuming. We present here a summary generation model that is based on multilayered attentional peephole convolutional long short-term memory (MAPCoL; LSTM) in order to extract abstractive summaries of large text in an automated manner. We added the concept of attention in a peephole convolutional LSTM to improve the overall quality of a summary by giving weights to important parts of the source text during training. We evaluated the performance with regard to semantic coherence of our MAPCoL model over a popular dataset named CNN/Daily Mail, and found that MAPCoL outperformed other traditional LSTM-based models. We found improvements in the performance of MAPCoL in different internal settings when compared to state-of-the-art models of abstractive text summarization."
유클리디안 안면 좌표 정보 기반 마스크 불량 착용자 검출 알고리즘,2021,[],국문 초록 정보 없음,"A novel mask-wearing state detection algorithm has been proposed to recognition of improper mask wearers in a real-time vision system. Currently, studies to determine whether to wear a mask has a problem that it cannot properly detect when a mask is worn over the nose or chin. In this study, we propose a technique for identifying the wrong mask wearer according to the distance information between the two coordinates by acquiring the coordinate information of the subject""s face and the mask in Euclidean space. To obtain object coordinate information, we use the YOLOv4 algorithm, a CNN-based object detection technology, and determine whether to wear a mask according to distance information defined as a reference in the 2D image coordinate system. As a result of applying the proposed algorithm, we proved through an experiment that it is possible to effectively detect the wearer of improper masks in a real-time environment."
Energy-Efficient DNN Processor on Embedded Systems for Spontaneous Human-Robot Interaction,2021,"['Deep learning', 'deep learning ASIC', 'deep neural network', 'mobile deep learning', 'reinforcement learning']",국문 초록 정보 없음,"Recently, deep neural networks (DNNs) are actively used for action control so that an autonomous system, such as the robot, can perform human-like behaviors and operations. Unlike recognition tasks, the real-time operation is essential in action control, and it is too slow to use remote learning on a server communicating through a network. New learning techniques, such as reinforcement learning (RL), are needed to determine and select the correct robot behavior locally. In this paper, we propose an energy-efficient DNN processor with a LUT-based processing engine and near-zero skipper. A CNN-based facial emotion recognition and an RNN-based emotional dialogue generation model is integrated for natural HRI system and tested with the proposed processor. It supports 1b to 16b variable weight bit precision with and 57.6% and 28.5% lower energy consumption than conventional MAC arithmetic units for 1b and 16b weight precision. Also, the near-zero skipper reduces 36% of MAC operation and consumes 28% lower energy consumption for facial emotion recognition tasks. Implemented in 65nm CMOS process, the proposed processor occupies 1784×1784 um2 areas and dissipates 0.28 mW and 34.4 mW at 1fps and 30fps facial emotion recognition tasks."
KI-HABS: Key Information Guided Hierarchical Abstractive Summarization,2021,"['neural network', 'deep learning', 'NLP', 'abstractive summarization', 'selective encoding']",국문 초록 정보 없음,"With the unprecedented growth of textual information on the Internet, an efficient automatic summarization system has become an urgent need. Recently, the neural network models based on the encoder-decoder with an attention mechanism have demonstrated powerful capabilities in the sentence summarization task. However, for paragraphs or longer document summarization, these models fail to mine the core information in the input text, which leads to information loss and repetitions. In this paper, we propose an abstractive document summarization method by applying guidance signals of key sentences to the encoder based on the hierarchical encoder-decoder architecture, denoted as KI-HABS. Specifically, we first train an extractor to extract key sentences in the input document by the hierarchical bidirectional GRU. Then, we encode the key sentences to the key information representation in the sentence level. Finally, we adopt key information representation guided selective encoding strategies to filter source information, which establishes a connection between the key sentences and the document. We use the CNN/Daily Mail and Gigaword datasets to evaluate our model. The experimental results demonstrate that our method generates more informative and concise summaries, achieving better performance than the competitive models."
Design of e-commerce business model through AI price prediction of agricultural products,2021,"['Agricultural product price', 'AI prediction', 'e-Commerce', 'Prediction model', 'AI algorithm', '농산물 가격', 'AI 예측', '전자거래', '예측 모델', '인공지능 알고리즘']",국문 초록 정보 없음,"For agricultural products, supply is irregular due to changes in meteorological conditions, and it has high price elasticity. For example, if the supply decreases by 10%, the price increases by 50%. Due to these fluctuations in the prices of agricultural products, the Korean government guarantees the safety of prices to producers through small merchants' auctions. However, when prices plummet due to overproduction, protection measures for producers are insufficient. Therefore, in this paper, we designed a business model that can be used in the electronic transaction system by predicting the price of agricultural products with an artificial intelligence algorithm. To this end, the trained model with the training pattern pairs and a predictive model was designed by applying ARIMA, SARIMA, RNN, and CNN. Finally, the agricultural product forecast price data was classified into short-term forecast and medium-term forecast and verified. As a result of verification, based on 2018 data, the actual price and predicted price showed an accuracy of 91.08%."
CAPS : CCTV 영상을 이용한 자율형 딥러닝 기반 아동학대 감지 시스템,2021,"['Child Abuse Protection System', 'Face Detection', 'Mosaic Generation', 'Deep Learning']",국문 초록 정보 없음,"Though the mandatory policy of installing CCTV in the childhood care facilities of public institutions such as kindergarten and daycare center, the criminal of child abuse cases is gradually increasing due to the lack of awareness of violent acts and the difficulty in understanding the reporting processes. This paper proposes a novel Child Abuse Protection System (CAPS) to solve the above social problem. The proposed CAPS is composed of three functional software modules to implement a deep-learning-based system that autonomously detects violent acts against children. First, the clip creator module divides long CCTV videos into several pieces of short video clips. Second, the violence detector module classifies the abuse behaviors from the generated clips. Finally, the face detector module automatically processes the witnessed suspect’s face being blurred out by mosaic. Experimental evaluation results show that the most suitable feature extractor for detecting the child abuse behaviors is the MobileNetV2+LSTM model among several candidates of the proposed CNN+LSTM violence detection module, which has the best at 92.51% accuracy. Furthermore, the recall rate can be increased up to 6% by exploiting the proposed data augmentation technique. Codes are available at https://github.com/learningsteady0J0/ CAPS-Child-Abuse-Protection-System."
Tumor Detection via Breast Histology Images,2021,"['object detection', 'breast histopathology images', 'cancer detection', 'tumor cells', 'deep learning']",국문 초록 정보 없음,"Biopsied tissue detection and classification within Breast Histopathology Images is a fundamental prerequisite to estimate the aggressiveness of breast cancer. The development and fully automated pipelines for tissue detection and classification enables the analysis of thousands of tissues within a whole slide histology image, which opens possibilities for analysis and prognosis of breast tumor. There are multiple annotated histology datasets available for evaluating the performance of machine learning models. The number of samples in these datasets is quite limited and usually the annotations provided are in the form of pair of points which points to the center of different types of cells. Most of the works in this field approach this problem by cropping a patch of the WSI usually 50x50 pixels (centered at given point), and then classify these patches with a simple classifier CNN. In this work we propose a method of converting the provided annotations (center points) into bounding box annotations. Then we use Faster-RCNN to detect and classify different types of cells in the WSI in a fully automated pipeline. We also propose data augmentation technique to increase the dataset size for Breast Histology images. Our proposed approach showed an average precision of 70.34% for classification and detection of tumor tissues."
Development of a Surface Roughness Evaluation Method from Light and Shade Composition using Deep Learning,2021,"['Surface roughness', 'Artificial intelligence', 'Deep learning', 'Evaluation method', 'Light and shade']",국문 초록 정보 없음,"Many companies agree on the need to introduce smart factories that promote low-cost, high-efficiency operation by applying IoT technologies to manufacturing plants. To assist in efficient manufacturing, this paper proposes a system for evaluating surface roughness through deep learning AI methods from the distribution of shade on the surface of an object. This is thought to greatly relieve the meticulous and tedious process of manual quality control for precision-machined surfaces and assist in the establishment of smart manufacturing industries. To demonstrate the usefulness of the developed technique, 305 samples of paper were categorized into three classes based on Ra threshold values, and images of paper were taken using a microscope camera. Luminance values, standard deviations, mean values, and image histograms were used to train custom-designed CNN+ LSTM composite neural networks. Completely new samples of non-training data were used for validation, which showed an accuracy of 85.185%. The proposed method can be economical, efficient, and fast compared to conventional surface roughness evaluation procedures. It can be easily integrated into an assembly line and automate quality assurance processes. This method could also prove useful in reducing labor costs and streamlining quality assurance processes due to its flexible adaptability."
Real-time Safety Monitoring Vision System for Linemen in Buckets Using Spatio-temporal Inference,2021,"['Gaussian mixture model', 'linemen safety monitoring', 'object detection', 'pose inference.']",국문 초록 정보 없음,"Linemen risk falls, electric shocks, burns, and other injuries during the daily job and these incidents canoften be fatal. In this paper, we present a novel vision-based real-time system for detection and tracking of variousnon-rigid safety wearables worn by linemen, in a highly cluttered environment. We set up four imaging sensors onthe repair truck’s bucket to robustly monitor the linemen from four different viewpoints. In the monitoring system,we firstly apply a novel fast background segmentation method to suppress false positives and reduce search space.Next, we represent each safety wearable with a Gaussian mixture model and track them with an LK-tracker. Inorder to track occluded or out-of-camera-view safety wearables, we propose a novel human pose inference method.The proposed method is an extension from the existing CNN-based human pose inference by utilizing light-weightcolor, shape, and space-based human pose inference mechanism. The proposed human pose inference method showsimproved performance in terms of precision, recall, and speed. Experimental results on a number of challengingsequences demonstrate the effectiveness of the proposed scheme, under complex background, prolonged occlusions,and varying color, shape, and lighting."
흐름이 있는 문서에 적합한 비지도학습 추상 요약 방법,2021,"['NLP', 'Summarization', 'GAN', 'BERT', 'Transformer']",국문 초록 정보 없음,"Recently, a breakthrough has been made in the NLP area by Transformer techniques based on encoder-decoder. However, this only can be used in mainstream languages where millions of dataset are well-equipped, such as English and Chinese, and there is a limitation that it cannot be used in non-mainstream languages where dataset are not established. In addition, there is a deflection problem that focuses on the beginning of the document in mechanical summarization. Therefore, these methods are not suitable for documents with flows such as fairy tales and novels. In this paper, we propose a hybrid summarization method that does not require a dataset and improves the deflection problem using GAN with two adaptive discriminators. We evaluate our model on the CNN/Daily Mail dataset to verify an objective validity. Also, we proved that the model has valid performance in Korean, one of the non-mainstream languages."
Aerial-Satellite Image Matching Framework for UAV Absolute Visual Localization using Contrastive Learning,2021,"['UAV', 'absolute visual localization', 'image matching', 'convolutional neural network']",국문 초록 정보 없음,"We present an Aerial-Satellite imagery matching framework for UAVs visual localization. The usage of Unmanned Aerial Vehicles (UAVs) has been continuously increasing in many applications, such as defense, agriculture, mapping, and observation. Localization plays an essential role in UAVs navigation system. The Global Positioning System (GPS) is mainly applied for localization; however, GPS interference may occur in a GPS-denied environment. One alternative that can be used is to use a pre-existing satellite image. By comparing aerial photographs with geo-tagged satellite images, global coordinates can be estimated in an intuitive way. However, due to various factors (such as weather, light conditions, and seasonal changes), it draws different visual representations between aerial and satellite imagery. To address this problem, we propose a image matching framework that exploits CNN-based Siamese Neural Network with contrastive learning method. The proposed framework firstly takes two input data; aerial image and satellite image of the area where UAV is estimated to be. By image retrieval and matching process, it predicts global coordinates of center of the aerial image. In this paper, we describe the structure of framework, data preparation, and the efficient representation learning strategy for downstream tasks. Additionally, we evaluate the performance of the proposed framework by measuring RMSE."
Determination of Abnormality of IGBT Images Using VGG16,2021,"['Ultrasound images', 'Convolutional neural network', 'Cycle-GAN', 'Data augmentation', 'VGG16', 'Batch normalization', 'Global average pooling']",국문 초록 정보 없음,"A power device is a semiconductor device for power control used for power conversion such as converting direct current to alternating current and alternating current to direct current. It is widely used such as refrigerators, air conditioners which is implemented electronic components that are closely related to our daily lives. Therefore, high reliability and safety are required, and power cycle tests are conducted for the purpose of evaluating them. In the conventional test, there is a problem that it is difficult to perform analysis because sparks are generated during the test and the device is severely damaged after the test. To solve this problem, a new technology has been developed that adds ultrasonic that enable internal observation during the test. However, there are remains a problem that the method for analyzing the ultrasonic image obtained in the new technology has not been established. Also, few abnormal images are obtained in the test. In this paper, we propose a method for detection of abnormal devices based on CNN. Especially, we implement a Cycle-GAN to extend the abnormal data and classify the known image based on improved VGG16. As an experimental result, classification accuracy of  = 97.06%,  = 93.58%,  −  = 95.17% were obtained."
Model Inversion Attack: Analysis under Gray-box Scenario on Deep Learning based Face Recognition System,2021,"['Model Inversion Attack', 'Deep Learning', 'Face Recognition System', 'Media Clone']",국문 초록 정보 없음,"In a wide range of ML applications, the training data contains privacy-sensitive information that should be kept secure. Training the ML systems by privacy-sensitive data makes the ML model inherent to the data. As the structure of the model has been fine-tuned by training data, the model can be abused for accessing the data by the estimation in a reverse process called model inversion attack (MIA). Although, MIA has been applied to shallow neural network models of recognizers in literature and its threat in privacy violation has been approved, in the case of a deep learning (DL) model, its efficiency was under question. It was due to the complexity of a DL model structure, big number of DL model parameters, the huge size of training data, big number of registered users to a DL model and thereof big number of class labels. This research work first analyses the possibility of MIA on a deep learning model of a recognition system, namely a face recognizer. Second, despite the conventional MIA under the white box scenario of having partial access to the users' non-sensitive information in addition to the model structure, the MIA is implemented on a deep face recognition system by just having the model structure and parameters but not any user information. In this aspect, it is under a semi-white box scenario or in other words a gray-box scenario. The experimental results in targeting five registered users of a CNN-based face recognition system approve the possibility of regeneration of users' face images even for a deep model by MIA under a gray box scenario. Although, for some images the evaluation recognition score is low and the generated images are not easily recognizable, but for some other images the score is high and facial features of the targeted identities are observable. The objective and subjective evaluations demonstrate that privacy cyber-attack by MIA on a deep recognition system not only is feasible but also is a serious threat with increasing alert state in the future as there is considerable potential for integration more advanced ML techniques to MIA."
SOH Monitoring and RUL Estimation of Lithium-Ion Batteries Using Physics-Infused Deep Learning,2021,"['Deep learning(딥러닝)', 'physics-infused neural network(물리기반 인공신경망)', 'lithium-ion battery(리튬이온 배터리)', 'remaining useful life(잔존수명)']",국문 초록 정보 없음,"Lithium-ion battery, a reliable source of energy for various electronic products, are replaced when it reaches its end-of-life (EOL) defined as 80% of the initial capacity. Even though it is rechargeable, it suffers from irreversible capacity loss during repeated charge-discharge cycles since the inactive part of battery keeps growing as time passes by. Therefore, it is required to understand the behavior of capacity fade trend or estimate the state of health (SOH) in the long term to forecast the remaining useful life (RUL) of a battery so that users can replace it in the right time [1]. The conventional ways to estimate SOH and RUL are threefold: physics-based approach, data-driven approach, and hybrid approach [2, 3]. Although most previous studies focus on the first two methods for their prominent and distinctive advantages, the hybrid approach has recently been shown to have the potential to replace them as it leverages the strengths of both sides. In this study, physics-infused neural network, a recursive deep neural network designed based on a typical LiFePO battery degradation model which reflects the solid electrolyte interphase (SEI) formation inside a battery cell, is investigated for the estimation of SOH and RUL simultaneously in real-time. The proposed method outperforms a number of purely data-driven models such as MLP, LSTM, and CNN-LSTM implying the general guidance effect of physics infusion for parameter optimization in training. Such effect has been investigated by varying the number of train data, and also by removing the physics-based part of the recurrent neural network cell."
"전산화 단층 촬영(Computed tomography, CT) 이미지에 대한 EfficientNet 기반 두개내출혈 진단 및 가시화 모델 개발",2021,"['Deep-learning', 'EfficientNet', 'Intracranial hemorrhage', 'Computed tomography images']",국문 초록 정보 없음,"Intracranial hemorrhage (ICH) refers to acute bleeding inside the intracranial vault. Not only does this devastating disease record a very high mortality rate, but it can also cause serious chronic impairment of sensory, motor, and cognitive functions. Therefore, a prompt and professional diagnosis of the disease is highly critical. Noninvasive brain imaging data are essential for clinicians to efficiently diagnose the locus of brain lesion, volume of bleeding, and subsequent cortical damage, and to take clinical interventions. In particular, computed tomography (CT) images are used most often for the diagnosis of ICH. In order to diagnose ICH through CT images, not only medical specialists with a sufficient number of diagnosis experiences are required, but even when this condition is met, there are many cases where bleeding cannot be successfully detected due to factors such as low signal ratio and artifacts of the image itself. In addition, discrepancies between interpretations or even misinterpretations might exist causing critical clinical consequences. To resolve these clinical problems, we developed a diagnostic model predicting intracranial bleeding and its subtypes (intraparenchymal, intraventricular, subarachnoid, subdural, and epidural) by applying deep learning algorithms to CT images. We also constructed a visualization tool highlighting important regions in a CT image for predicting ICH. Specifically, 1) 27,758 CT brain images from RSNA were pre-processed to minimize the computational load. 2) Three different CNN-based models (ResNet, EfficientNet-B2, and EfficientNet-B7) were trained based on a training image data set. 3) Diagnosis performance of each of the three models was evaluated based on an independent test image data set: As a result of the model comparison, EfficientNet-B7's performance (classification accuracy = 91%) was a way greater than the other models. 4) Finally, based on the result of EfficientNet-B7, we visualized the lesions of internal bleeding using the Grad-CAM. Our research suggests that artificial intelligence-based diagnostic systems can help diagnose and treat brain diseases resolving various problems in clinical situations."
도시 신진대사(Urban Metabolism)를 고려한 도시기후대(Urban Climate Zone) 분류방법 연구,2021,"['도시 신진대사', '국지기후대', 'AWS', 'AirKorea', '기후변화', '적응', '완화', 'Urban Metabolism', 'Local Climate Zone', 'Climate Change', 'Adaptation', 'Mitigation']","Ⅰ. Introduction1. Backgroundㅇ Over the past 60 years, Korea has achieved economic growth and urbanization.ㅇ Therefore, it is necessary to understand the interaction between cities and the climate/environment for implement the policies in the era of climate crisis.ㅇ Urban researches has mainly focused on urban structural analysis, but in order to capture the various characteristics of cities, it is necessary to analyze urban metabolism (UM) that represents human activities.2. Purposeㅇ To analize the Local Climate Zones (LCZs), a land-use classification model based on the urban structure.ㅇ To present the definition of UM, and to suggest the application strategy on policy planning.Ⅱ. LCZs Classification Method1. LCZs Classification Methodㅇ LCZs is standardized land use classification method that can classify the environment based on the landscapes around the urban observation sites.ㅇ LCZs classes consist of 10 built type classes (high-rise, mid-rise, low-rise, compact, open, sparsely, heavy, etc) and 7 land cover class (forest, grassland, bare-soil, low-plant, water, impervious, etc).ㅇ Urban climate researches are actively increasing, but they cannot be explained the spatial and temporal variability of the urban climate and environment well because they does not reflect the UM.2. LCZs Classification of AWS and AirKorea networkㅇ Classification LCZs of the automatic weather station (AWS; 618 sites) and the urban air quality monitoring network (AirKorea; 412 sites).ㅇ Analysis of the distribution characteristics of observation networks (AWS and AirKorea) located across the country, and suggestion of future directions for improving the observation network.ㅇ Cross-validation analysis of classification results using deep learning method based on satellite remote sensing data.Ⅲ. Application of Urban Metabolism1. Strategy of Building UM Databaseㅇ It is necessary to build a high-resolution UM database including population mobility, traffic accounts, energy consumption rates (ex, electricity and natural gas) for an application of UM to a policyㅇ It is necessary the discussion on the economic value of UM data, the establishment of data production, management, and utilization processes, and the publishment of ethical principles.2. Improvement Method for LCZs Considering UMㅇ As a result of analyzing the population density distribution (3,494 towns), it is suggested that the four categories of population density along with LCZs classification.3. Policy Use of UMㅇ The concept and data of UM should be utilized in climate change actions (i.e., mitigation and adaptation policies) to achieve the carbon-neutral 2050 vision.ㅇ UM data could be utilized in the implementation of environmental policies such as urban waste management and resource circulation, as well as the implementation of urban management policies for the building, transportation, and energy.Ⅳ. Conclusionㅇ It is expected the UM will be helpful in planning not only climate and environment policies but also spatial planning for architecture, transportation and energy.ㅇ LCZs should be continuously applied in the urban researches as a meta data, and continuous efforts should be made to reflect the characteristics of UM.ㅇ Data on floating population, real-time traffic volume, and energy consumption should be built and managed for the policy utilization of the UM, and efforts should be made to establish a data production, management, and utilization system and data ethics principles.",다국어 초록 정보 없음
영흥 풍력발전단지의 풍력발전량 예측을 위한 입력변수 선정 및 인공신경망과 1차원 합성곱 신경망 비교,2021,"['Artificial Neural Networks', 'Artificial Intelligence', 'Convolutional Neural Networks', 'Machine Learning', 'Wind Power', '인공신경망', '인공지능', '기계학습', '합성곱신경망', '풍력에너지']","목적 : 본 연구에선 비선형적 풍력발전량 예측 모델 개발을 목적으로 총 설치 용량 46 MW의 풍력발전단지가 설치된 영흥 풍력발전 단지의 자료를 이용하여 인공신경망(artificial neural network, ANN)과 1차원 합성곱신경망(1-dimension convolutional neural network, 1D-CNN)의 성능을 비교하고자 하였다.방법 : 자료는 46 MW 발전능력을 가진 영흥 풍력발전단지의 2018년 1월부터 12월의 1시간 단위 풍력발전량 자료와 기상청에서 얻은 기상자료를 이용하였다. 최적 입력변수를 선정을 위하여 문헌연구를 바탕으로 시행착오를 거쳐 인자를 선정하였다. 전처리 과정을 거친 17,306개의 자료의 80%를 학습(training), 20%를 테스트(test)으로 사용하였으며, 학습 자료의 20%를 검증(validation)자료로 구성하였다. 모델 내 활성화 함수로는 rectified linear unit를 사용하였으며, 시행착오법을 통해 하이퍼파라미터(hyperparameter)의 최적값을 도출하였다. 모든 모델은 Python의 Keras 라이브러리를 이용하여 설계하였으며, 성능지표인 결정계수(coefficient of determination, R²), 평균제곱근오차(root mean square error, RMSE), 평균절대오차(mean absolute error, MAE) 등은 Scikit-learn 라이브러리에서 이용하였다.결과 및 토의 : 최적 입력변수는 풍속, 풍향, 온도, 습도 등이었다. ANN의 최적점으로는 은닉층 8층, 은닉층별 노드수는 모두 100으로 나왔다. 최적 ANN 모델에서 성능지표는 R²=0.848, MAE=1.054, RMSE=1.616이었다. 1D-CNN 의 최적점으로는 합성곱층 4층, 층별 필터 수는 1층부터 64, 128, 64, 32개, 전결합층 1층에 노드 100개이다. 최적 1D-CNN 모델의 성능지표는 R²=0.875, MAE=0.982, RMSE=1.583였다. 1D-CNN이 ANN보다 R²는 높고, MAE와 RMSE는 낮았다. ANN, 1D-CNN의 결정계수가 모두 0.8 이상으로 예측 성능이 우수하나, 1D-CNN이 ANN보다 모든 성능지표에서 높았다.결론 : 최적화된 모델의 성능지표 비교 결과 1D-CNN이 ANN보다 높은 성능을 보여 영흥 풍력 발전소 발전량 예측에 적합할 것으로 보인다. 최적 입력변수는 풍속, 풍향, 온도, 습도였다.","Objectives : In this study, deep learning models of artificial neural network (ANN) and one-dimension convolutional neural networks (1D-CNN) were compared to predict nonlinear wind power generation at Yeongheung wind power plant.Methods : The study site was Yeongheung-do, which has a 46 MW wind power plant. Hourly wind power and meteorological data from January to December 2018 were collected. After pre-processing with standardscaler, the training data were 64%, the validation data were 16%, and the test data were 20%. The optimum input variables of the model were selected using literature, and trial and error method. Rectified linear unit was used as the activation function. Hyperparameters were adjusted by trial and error method to optimized models. To compare the optimized models, the coefficient of determination (R²), mean absolute error (MAE), and root mean square error (RMSE) were used as the performance efficiency. Both ANN, and 1D-CNN were imported from the Keras library, and all of the performance efficiency was imported from the Scikit-learn library.Results and Discussion : The optimized input variables in this study were wind speed, wind direction, temperature, and humidity. The optimized ANN performance was R²=0.848, MAE=1.054, and RMSE=1.616, and the hyperparameters were 8 hidden layers with 100 nodes in each layer. The optimized 1D-CNN (R²=0.875, MAE=0.982, and RMSE=1.583) had 4 convolutional layers and the number of filters were 64, 128, 64, and 32 in order from the first layer, and one hidden fully connected layer had 100 nodes. The 1D-CNN had higher R², and lower MAE and RMSE than the ANN. Therefore, the 1D-CNN was selected as the optimized model to predict wind generation of the Yeongheung wind power plant.Conclusions : The optimized 1D-CNN model in this study was more effective in predicting the Yeongheung wind power plant than the ANN. The optimal input variables were wind speed, wind direction, temperature, and humidity."
X-ray 이물검출기의 이물 검출 향상을 위한 딥러닝 방법,2021,"['X-ray inspection System', 'Image identification', 'Contamination recognition', 'Deep learning', 'Faster R-CNN']","식품은 기본적으로 영양성과 안전성을 반드시 갖추어야 한다. 최근에 식품의 안정성이 의심이 되는 안산의 한 유치원에서 식중독성 유증상자가 다수 발생하였다. 그래서 식품의 안전성은 더욱 요구되는 사항이다. 본 논문에서는 식품의 안전성을 확보하기 위한 이물검출기의 딥러닝모델을 통해 검출율을 향상시키는 방법을 제안한다. 제안방법으로는 CNN(convolution neural network), Faster R-CNN(region convolution neural network)의 네트워크를 통해 학습하고 정상과 이물제품의 영상을 테스트한다. 딥러닝 모델을 통해 테스트한 결과 기존 이물검출기의 알고리즘에 Faster R-CNN을 병행한 방법이 다른 방법보다 검출율이 좋은 성능을 보였다.","Food basically must have nutrition and safety. Recently, a number of symptoms of food poisoning occurred in a kindergarten in Ansan, where food safety was suspected. Therefore, the safety of food is more demanding. In this paper, we propose a method to improve the detector to secure food safety. The proposed method is to learn through the network of convolution neural network (CNN) and Faster region-CNN (Faster R-CNN) and test the images of normal and foreign products. As a result of testing through a deep learning model, the method that used Faster R-CNN in parallel with the existing foreign body detector algorithm showed better detection rate than other methods."
인공 위성 사진 내 선박 탐지 정확도 향상을 위한 Watershed 알고리즘 기반 RoI 축소 기법,2021,"['Coastline Extraction', 'Satellite Image', 'R-CNN', 'Watershed Algorithm', '해안선 추출', '인공위성 사진', 'R-CNN', 'Watershed 알고리즘']",국문 초록 정보 없음,"Research has been ongoing to detect ships from offshore photographs for a variety of reasons, including maritime security, identifying international trends, and social scientific research. Due to the development of artificial intelligence, R-CNN models for object detection in photographs and images have emerged, and the performance of object detection has risen dramatically. Ship detection in offshore photographs using the R-CNN model has also begun to apply to satellite photography. However, satellite images project large areas, so various objects such as vehicles, landforms, and buildings are sometimes recognized as ships. In this paper, we propose a novel methodology to improve the performance of ship detection in satellite photographs using R-CNN series models. We separate land and sea via marker-based watershed algorithm and perform morphology operations to specify RoI one more time, then detect vessels using R-CNN family models on specific RoI to reduce typology. Using this method, we could reduce the misdetection rate by 80% compared to using only the Fast R-CNN."
치과용 파노라마방사선사진에서 AlexNet의 골다공증 판정,2021,"['Osteoporosis', 'Panoramic Radiograph', 'Mandible', 'Neural network']",국문 초록 정보 없음,"This study was performed as a part of serial experiments of applying convolutional neural network(CNN) in determining osteoporosis on panoramic radiograph. The purpose of this study was to investigate how sensitively CNN determine osteoporosis on cropped panoramic radiograph. Panoramic radiographs from 1268 female patients(mean age 45.2 ± 21.1 yrs) were selected for this study. For the osteoporosis group, 633(mean age 72.2 ± 8.5 yrs) were selected, while for the normal group 635(mean age 28.3 ± 7.0 yrs). AlexNet was utilized as CNN in this study. A multiple-column CNN was designed with two rectangular regions of interest on the mandible inferior area. An occluding method was used to analyze the sensitive area in determining osteoporosis on AlexNet. Testing of AlexNet showed accuracy of 99% in determining osteoporosis on panoramic radiographs. AlexNet was sensitive at the area of cortical and cancellous bone of the mandible inferior area including adjacent soft tissue."
주철 미세조직 분석을 위한 합성곱 신경망에서의 중간층 시각화,2021,"['machine learning', 'convolutional neural network', 'image recognition', 'microstructure', 'cast iron']",국문 초록 정보 없음,"We attempted to classify the microstructural images of spheroidal graphite cast iron and grey cast iron using a convolutional neural network (CNN) model. The CNN comprised four combinations of convolution and pooling layers followed by two fully-connected layers. Numerous microscopic images of each cast iron were prepared to train and verify the CNN model. After training the network, the accuracy of the model was validated using an additional set of microstructural images which were not included in the training data. The CNN model exhibited an accuracy of approximately 98% for classification of the cast irons. Typically, CNN does not provide bases for image classification to human users. We tried to visualize the images between the network layers, to find out how the CNN identified the microstructures of the cast irons. The microstructural images shrank as they passed the convolutional and pooling layers. During the processes, it seems that the CNN detected morphological characteristics including the edges and contrast of the graphite phases. The mid-layer images still retained their characteristic microstructural features, although the image sizes were shrunk. The final images just before connecting the fully-connected layers seemed to have minimalized the information about the microstructural features to classify the two kinds of cast irons. Matrix phases such as ferrite and pearlite did not show prominent effects on the classification accuracy."
Few-Shot Learning을 사용한 호스트 기반 침입 탐지 모델,2021,"['Machine Learning', 'LID-DS', 'Few-Shot Learning', 'Siamese Network', 'HIDS', '기계학습', '퓨샷 러닝', '샴 네트워크', '호스트 기반 침입 탐지 시스템']",국문 초록 정보 없음,"As the current cyber attacks become more intelligent, the existing Intrusion Detection System is difficult for detecting intelligent attacks that deviate from the existing stored patterns. In an attempt to solve this, a model of a deep learning-based intrusion detection system that analyzes the pattern of intelligent attacks through data learning has emerged. Intrusion detection systems are divided into host-based and network-based depending on the installation location. Unlike network-based intrusion detection systems, host-based intrusion detection systems have the disadvantage of having to observe the inside and outside of the system as a whole. However, it has the advantage of being able to detect intrusions that cannot be detected by a network-based intrusion detection system. Therefore, in this study, we conducted a study on a host-based intrusion detection system. In order to evaluate and improve the performance of the host-based intrusion detection system model, we used the host-based Leipzig Intrusion Detection-Data Set (LID-DS) published in 2018. In the performance evaluation of the model using that data set, in order to confirm the similarity of each data and reconstructed to identify whether it is normal data or abnormal data, 1D vector data is converted to 3D image data. Also, the deep learning model has the drawback of having to re-learn every time a new cyber attack method is seen. In other words, it is not efficient because it takes a long time to learn a large amount of data. To solve this problem, this paper proposes the Siamese Convolutional Neural Network (Siamese-CNN) to use the Few-Shot Learning method that shows excellent performance by learning the little amount of data. Siamese-CNN determines whether the attacks are of the same type by the similarity score of each sample of cyber attacks converted into images. The accuracy was calculated using Few-Shot Learning technique, and the performance of Vanilla Convolutional Neural Network (Vanilla-CNN) and Siamese-CNN was compared to confirm the performance of Siamese-CNN. As a result of measuring Accuracy, Precision, Recall and F1-Score index, it was confirmed that the recall of the Siamese-CNN model proposed in this study was increased by about 6% from the Vanilla-CNN model."
인공지능을 이용한 UAV 영상 건물 경계선 추출 가능성 연구,2021,"['지적', '공간정보', '인공지능', 'Mask R-CNN', '건물경계', 'Cadastral', 'Geospatial Information', 'Artificial Intelligence', 'Mask R-CNN', 'Building Boundary']","UAV는 저비용･고효율로 측량 및 지적 등 공간정보 분야에서 이미 많은 적용과 활용이 이루어지고 있다. 인공지능 기술 역시 기술의 발전에 따른 빠른 연산속도와 수행능력으로 다양한 분야에서 활용하고 있다. R-CNN은 영상분류 분야의 대표적인 인공지능 모델이다. 본 연구에서는 인공지능을 적용하여 UAV 영상의 건물 경계선 추출 가능성을 분석･제시하고자 하였다. 이를 위해 UAV의 영상의 건물 경계선을 분류하고, 이를 Mask R-CNN에 적용하여 산출한 결과 값과 UAV의 원시 영상과 비교 하였다. 비교결과, 건물 경계선은 전반적으로 추출이 가능하나 정확도는 지역별로 편차가 있는 것으로 나타났다. 정확도가 낮은 건물의 경우는 대상 건물과 주변 영역이 명확히 인식되지 못하는 데에서 발생한 것으로 분석되었다. 향후 하드웨어의 발전과 많은 학습데이터가 축적 된다면 공간정보를 비롯한 지적 분야에서도 적용이 가능할 것으로 판단된다.","UAV are already being applied and utilized in geospatial information fields such as surveying and cadastral due to their low cost and high efficiency. Artificial intelligence technology is also being used in various fields due to its fast computational speed and performance capability according to the development of technology. R-CNN is a representative artificial intelligence model in the field of image classification. In this study, we tried to analyze and present the possibility of extracting the boundary line of the UAV image by applying artificial intelligence. For this purpose, the building boundary of the UAV image was classified, and the calculated result value was applied to the Mask R-CNN and compared with the original image of the UAV. As a result of the comparison, it was found that the boundary line of the building can be extracted as a whole, but the accuracy varies by region. In the case of a building with low accuracy, it was analyzed that it occurred because the target building and the surrounding area were not clearly recognized. If hardware advances and a lot of learning data is accumulated in the future, it is considered that it can be applied to cadastral fields including spatial information."
합성곱 신경망을 사용한 하천 수질예측 정확도 평가,2021,"['Convolutional neural network', 'Prediction accuracy', 'River water quality', 'Deep learning architecture', 'Univariate data', 'Multivariate data']",국문 초록 정보 없음,"The present study assessed the applicability of convolutional neural network (CNN), which showed superior performance for classification, segmentation, and natural language processing, to river water quality prediction. Monthly data was compiled from upstream and downstream water quality monitoring stations in the Hwang River over the period of January 2007 through December 2020, from which training and test sets were constructed in the ratio of 70:30. The performance of CNN consisting of single and multiple layers were evaluated separately using univariate data with single dependent variable (i.e., either chemical oxygen demand (COD) or chlorophyll-a (Chl-a) as well as multivariate data with dependent and 9 independent variables. The results showed that the prediction accuracy of the proposed CNN algorithm tested with univariate data was noticeably higher for COD than for Chl-a (in terms of target variable) as well as for multiple layers than for single layer (with respect to model architecture). In addition, the CNN algorithm evaluated with multivariate data achieved had better prediction performance than that of univariate data although its performance varied widely among data sets, and to a less extent, among stations and target variables. No measurable difference was also found in prediction performance of the CNN algorithm (for two target dependent variables) according to the number of (important) independent variables. All these results demonstrate that while the proposed CNN algorithm can be adopted to predict (monthly) water quality variables, its careful architecture design is yet required to achieve substantial performance improvement."
Respiratory-correlated 4D digital tomosynthesis with deep convolutional neural networks for image-guided radiation therapy,2021,['4D digital tomosynthesis · Convolutional neural network · Quantitative accuracy · Spatial resolution · Image noise'],국문 초록 정보 없음,"4D digital tomosynthesis (DTS) techniques for image-guided radiation therapy (IGRT) are able to reduce radiation dose, scan and reconstruction time compared to 4D cone-beam computed tomography (CBCT). In spite of these benefits, the 4D DTS techniques cause the degradation of image quality due to an intrinsic imaging strategy and consequently reduce treatment accuracy. In this study, a deep learning-based convolutional neural network (CNN) framework was proposed for 4D DTS imaging. The proposed CNN framework consisted of the data restoration network based on a U-Net and the denoising network combined with a 2D wavelet transform, and the network training was implemented with clinical images. The quality of the 4D DTS images obtained from the proposed model was evaluated in terms of quantitative accuracy, spatial resolution and noise property. The results showed that the proposed CNN framework improved the quantitative accuracy of 4D DTS images by 3–19%, and the spatial resolution and noise for the proposed CNN framework were reduced by 2.24–7.33% and 8.92–40.07%, respectively, in comparison to other imaging models. These results represented that the degradation of the 4D DTS image quality can be recovered using the proposed CNN framework, and the proposed model is suitable for maintaining spatial resolution as well as suppressing noise and artifacts. In conclusion, the proposed CNN framework can be potentially used to improve the quality of 4D DTS images for the IGRT."
한글 폰트 인식을 위한 데이터 수집 및 분류 기법 적용,2021,"['Font Recognition', 'CNN', 'Deep Learning', 'LeNet', 'ResNet']","딥러닝의 여러 모델 중 이미지 인식과 관련된 CNN(Convolutional Neural Network)을 기반으로 한 심층학습이 다양한 분야에서 진행되고 있다. 최근 COVID-19 상황으로 인한 비대면 방식의 수업 및 업무가 활성화되면서 디지털 문서 사용량이 많아지는 추세이다. 이에 따라 폰트에 대한 관심도와 종류도 증가하면서 분류 체계의 필요성도 늘어나고 있다. 본 논문에서는 한글 폰트 인식을 위한 데이터를 분석하고, 대표적인 CNN 모델들을 적용하여 폰트 인식성능을 테스트한다. 그리고 인식성능 향상 및 확대 데이터 구축을 위한 방법론을 제안한다.","Among the various models of deep learning, deep learning based on CNN(Convolutional Neural Network) related to image recognition is in progress in various fields. Recently, as non-face-to-face classes and work have been activated due to the COVID-19 situation, the use of digital documents is increasing. Accordingly, as the interest and types of fonts increase, the need for a classification system is also increasing. In this paper, we analyze the data for Korean font recognition and test the font recognition performance by applying representative CNN models. And we propose a methodology for improving recognition performance and constructing expanded data."
클라우드 플랫폼을 이용한 딥러닝 기반 장애인 주차구역 관리 시스템 구현,2021,"['Cloud platform', 'YOLO', 'CNN', 'Raspberry pi', 'Android phone', 'Deep learning']","본 연구는 딥러닝과 클라우드 플랫폼을 이용하여 장애인 복지 증진을 위한 장애인 주차 공간을 관리하는 시스템을 제안하였다. 딥러닝은 주차 영역의 자동차 영상에서 번호판 검출을 위하여 YOLO (you only look once)를 사용하였으며, 추출된 숫자 및 문자 영상에서 번호판 문자 인식을 위하여 CNN (convolutional neural network)을 사용하였다. 본 시스템은 실시간 관리가 가능하고, 동영상만으로 관리할 수 있도록 간소화하였다. 또한 기존 OCR (optical character recognition)보다 한글 문자 인식률을 높임으로서 안정성 및 정확성이 있으며, CCTV (closed circuit television)만 설치하면 주차관리가 가능하도록 함으로서 관리 영역의 확장성의 특장점을 가진다. 본 시스템은 기징 중요한 요소인 정확한 번호판 인식률을 높이는 연구와 다소 성능이 낮은 라즈베리 파이 환경에서 YOLO와 CNN 알고리즘 등을 실행하기 위한 처리속도 문재에 대한 지속적 연구가 필요하다.","This study proposed a system that manages parking spaces for the disabled, this will lead to the promotion of welfare for those who are disabled by using deep learning and cloud platforms. Deep learning used you only look once (YOLO) for license plate detection concerning car images in parking areas, and convolutional neural network (CNN) was used for license plate character recognition from extracted numbers and text images. This system can be managed in real time, and it has been simplified so that it can be managed only with video. In addition, it is recognized and accurate by increasing the recognition rate of Korean characters compared to the existing optical character recognition (OCR), and it has the advantage of scalability in the management area by enabling parking management but only if closed circuit television (CCTV) is installed. This system requires a study to increase the accurate license plate recognition rate. This is an important factor, and a continuous study on the processing speed problem to execute YOLO and CNN algorithms in a somewhat low performance raspberry environment."
Deep Face Verification Based Convolutional Neural Network,2021,"['Deep learning', 'Face recognition', 'Lifting scheme', 'CNN']",국문 초록 정보 없음,"The Convolutional Neural Network (CNN) has recently made potential improvements in face verification applications. In fact, different models based on the CNN have attained commendable progress in the classification rate using a massive amount of data in an uncontrolled environment. However, the enormous computation costs and the considerable use of storage causes a noticeable problem during training. To address these challenges, we focus on relevant data trained within the CNN model by integrating a lifting method for a better tradeoff between the data size and the computational efficiency. Our approach is characterized by the advantage that it does not need any additional space to store the features. Indeed, it makes the model much faster during the training and classification steps. The experimental results on Labeled Faces in the Wild and YouTube Faces datasets confirm that the proposed CNN framework improves performance in terms of precision. Obviously, our model deliberately designs to achieve significant speedup and reduce computational complexity in deep CNNs without any accuracy loss. Compared to the existing architectures, the proposed model achieves competitive results in face recognition tasks"
이산화 전처리 방식 및 컨볼루션 신경망을 활용한 네트워크 침입 탐지에 대한 연구,2021,"['NSL-KDD', '네트워크 이상 탐지', 'CNN', '연속형 변수 이산형화', 'Network Intrusion Detection', 'Discretization of Continuous']","새롭게 발생되는 사이버 공격으로 인해 개인, 민간 및 기업의 피해가 증가함에 따라, 이에 기반이 되는 네트워크 보안 문제는 컴퓨터 시스템의 주요 문제로 부각되었다. 이에 기존에 사용되는 네트워크 침입 탐지 시스템(Network Intrusion Detection System: NIDS)에서 발생되는 한계점을 개선하고자 기계 학습과 딥러닝을 활용한 연구 이뤄지고 있다. 이에 본 연구에서는 CNN(Convolution Neural Network) 알고리즘을 이용한 NIDS 모델 연구를 진행한다. 이미지 분류 기반의 CNN 알고리즘 학습을 위해 기존 사용되는 전처리 단계에서 연속성 변수 이산화(Discretization of Continuous) 알고리즘을 추가하여 예측 변수에 대해 선형 관계로 표현하여 해석에 용이한 데이터로 변환 후, 정사각형 행렬(Square Matrix) 구조에 매칭된 픽셀(Pixel) 이미지 구조를 모델에 학습한다. 모델의 성능 평가를 위해 네트워크 패킷 데이터인 NSL-KDD를 사용하였으며, 정확도(Accuracy), 정밀도(Precision), 재현율(Recall) 및 조화평균(F1-score)을 성능 지표로 사용하였다. 실험 결과 제안된 모델에서 85%의 정확도로 가장 높은 성능을 보였으며, 학습 표본이 적은 R2L 클래스의 조화평균이 71% 성능으로 다른 모델에 비해서 매우 좋은 성능을 보였다.","As damages to individuals, private sectors, and businesses increase due to newly occurring cyber attacks, the underlying network security problem has emerged as a major problem in computer systems. Therefore, NIDS using machine learning and deep learning is being studied to improve the limitations that occur in the existing Network Intrusion Detection System. In this study, a deep learning-based NIDS model study is conducted using the Convolution Neural Network (CNN) algorithm. For the image classification-based CNN algorithm learning, a discrete algorithm for continuity variables was added in the preprocessing stage used previously, and the predicted variables were expressed in a linear relationship and converted into easy-to-interpret data. Finally, the network packet processed through the above process is mapped to a square matrix structure and converted into a pixel image. For the performance evaluation of the proposed model, NSL-KDD, a representative network packet data, was used, and accuracy, precision, recall, and f1-score were used as performance indicators. As a result of the experiment, the proposed model showed the highest performance with an accuracy of 85%, and the harmonic mean (F1-Score) of the R2L class with a small number of training samples was 71%, showing very good performance compared to other models."
영상장비와 딥러닝을 이용한 고속도로 터널 균열 탐지 시스템 개발,2021,"['Tunnel crack detection', 'Deep learning', 'Cascade mask R-CNN', 'Negative sample training', '터널 균열 탐지', '딥러닝', 'Cascade Mask R-CNN', '비균열 학습']","빠르게 증가하는 노후 터널을 효율적으로 관리하기 위하여 최근 영상장비를 이용한 점검 방법론들이 많이 제안되고 있다. 하지만 기존의 방법론들은 대부분 국한된 영역에서 검증을 수행하였을 뿐 아니라, 다른 물체들이 존재하지 않는 깨끗한 콘크리트 표면에서 검증되어 실제 현장에 대한 적용성을 검증하기 어려웠다. 따라서 본 논문에서는 이러한 한계를 극복하기 위하여 비균열 물체 학습에 기반한 6단계 터널 균열 탐지 딥러닝 모델 개발 프레임워크를 제안한다. 제안된 프레임워크는 터널에서 취득된 이미지 내 균열 탐색, 픽셀 단위 균열 라벨링, 딥러닝 모델 학습, 비균열 물체 수집, 비균열 물체 재학습, 최종 학습 데이터 구축의 총 6단계로 이루어진다. 제안된 프레임워크를 이용하여 개발된 균열 탐지 딥러닝 모델 개발을 수행하였으며, 일반 균열 1561장, 비균열 206장으로 개별 물체 세분화(Instance Segmentation) 모델인 Cascade Mask R-CNN을 학습시켰다. 학습된 모델의 현장 적용성을 검토하기 위하여 전선, 전등 등을 포함하는 약 200m 길이의 실제 터널에서 균열 탐지를 수행하였다. 실험 결과 학습된 모델은 99% 정밀도와 92%의 재현율을 나타내며 뛰어난 현장 적용성을 나타내었다.","In order to efficiently inspect rapidly increasing old tunnels in many well-developed countries, many inspection methodologies have been proposed using imaging equipment and image processing. However, most of the existing methodologies evaluated their performance on a clean concrete surface with a limited area where other objects do not exist. Therefore, this paper proposes a 6-step framework for tunnel crack detection deep learning model development. The proposed method is mainly based on negative sample (non-crack object) training and Cascade Mask R-CNN. The proposed framework consists of six steps: searching for cracks in images captured from real tunnels, labeling cracks in pixel level, training a deep learning model, collecting non-crack objects, retraining the deep learning model with the collected non-crack objects, and constructing final training dataset. To implement the proposed framework, Cascade Mask R-CNN, an instance segmentation model, was trained with 1561 general crack images and 206 non-crack images. In order to examine the applicability of the trained model to the real-world tunnel crack detection, field testing is conducted on tunnel spans with a length of about 200m where electric wires and lights are prevalent. In the experimental result, the trained model showed 99% precision and 92% recall, which shows the excellent field applicability of the proposed framework."
비디오 감시에서 심층 컨볼루션 신경망을 사용한 폭력 활동 감지,2021,"['딥러닝', '감시 카메라', '비정상적인 활동', '컨볼루션 뉴럴 네트워크', 'Deep learning', 'surveillance cameras', 'abnormal activity', 'convolutional neural network']","최근에는 전세계적으로 범죄 예방을 위한 감시 시스템이 설치되어 방대한 양의 비디오 데이터를 생성하는 개인 및 공공장소를 모두 모니터링하고 있다. 이 설정에서 전문가가 진행 중인 활동을 지속적으로 관찰하고 모니터링해야 한 다. 이 지루한 작업을 처리하기 위해 실시간으로 실행 가능한 폭력 활동 감지(VAD) 기술이 큰 과제이다. 따라서 본 논문에서는 실시간 VAD을 위한 3단계 딥러닝 지원 프레임워크를 제안한다. 첫번째 단계에서는 프레임 차이 알고리즘을 통해 비디오 데이터에서 가장 중요한 모션 프레임을 획득하기 위한 사전 처리 단계를 적용한다. 이러한 프 레임은 경량 컨볼루션 신경 네트워크(CNN)가 가장 차별적인 특징을 추출하는 두 번째 단계로 제공된다. 마지막으 로 CNN 모델은 활동을 폭력적인 장면과 비폭력적인 장면으로 분류한다. 폭력적인 행위가 발생할 경우, 가장 가까 운 보안 부서와 경찰서에 신고하여 신속한 조치를 취하도록 한다. 제안된 방법은 공개적으로 사용 가능한 데이터 세 트에서 96%의 정확도를 달성하고 최신 방법보다 성능이 우수하다.","Recently, surveillance systems are globally installed for crime prevention by monitoring both private and public places which generate a massive amount of video data. This setup requires human experts to observe and monitor the ongoing activities continuously. To handle this tedious task, an automatic technique workable in real-time for violent activity detection (VAD) is a big challenge. Thus, this paper proposes a three-phase deep learning assisted framework for real-time VAD. In the first phase, a preprocessing step is applied to obtain the salient motion frames from the video data through frame differencing algorithm. These frames are fed into the second phase where a lightweight convolutional neural network (CNN) extracts the most discriminative features. Finally, a CNN model classifies the activity into violent and non-violent scene. In case of violent activity, the activity is reported to notify the nearest security departments and police stations for the prompt action. The proposed method achieves 96% accuracy on the publicly available dataset and outperforms over state-of-the-art methods."
Deep Convolutional Neural Network Architectures for Tonal Frequency Identification in a Lofargram,2021,"['Convolutional neural networks', 'lofar analysis', 'sonar analysis', 'underwater recognition.']",국문 초록 정보 없음,"Advances in convolutional neural networks (CNNs) have driven the development of computer vision. Recent CNN architectures, such as those with skip residual connections (ResNets) or densely connected architectures (DenseNets), have facilitated backpropagation and improved the performance of feature extraction and classification. Detecting objects in underwater environments by analyzing sound navigation and ranging (sonar) signals is considered an important process that should be automated. Several previous approaches have addressed this challenge; however, there has been no in-depth study of CNN architectures that effectively analyze sonar grams. In this paper, we have presented the identification of tonal frequencies in lofargrams using recent CNN architectures. Our study includes 175 CNN models that are derived from five different CNN architectures and 35 different input patch sizes. The study results showed that the accuracy of the best model was as high as 96.2% for precision and 99.5% for recall, with an inference time of 0.184 s."
VGG-16 딥러닝 알고리즘을 활용한 우식치아와 건전치아 분류,2021,"['CNN', 'Convolutional neural network', 'Deep learning', 'Dental caries classification', 'VGG-16']",국문 초록 정보 없음,"Objectives: Diagnosis of dental caries is based on the dentist’s observation and subjective judgment; therefore, a reliable and objective approach for diagnosing caries is required. Intraoral camera images combined with deep learning technology can be a useful tool to diagnose caries. This study aimed to evaluate the accuracy of the VGG-16 convolutional neural network (CNN) model in detecting dental caries in intraoral camera images.Methods: Images were obtained from the Internet and websites using keywords linked to teeth and dental caries. The 670 images that were obtained were categorized by an investigator as either sound (404 sound teeth) or dental caries (266 dental caries), and used in this study. The training and test datasets were divided in the ratio of 7:3 and a four-fold cross validation was performed. The Tensorflow-based Python package Keras was used to train and validate the CNN model. Accuracy, Kappa value, sensitivity, specificity, positive predictive value, negative predictive value, ROC (receiver operating characteristic) curve and AUC (area under curve) values were calculated for the test datasets.Results: The accuracy of the VGG-16 deep learning model for the four datasets, through random sampling, was between 0.77 and 0.81, with 0.81 being the highest. The Kappa value was 0.51- 0.60, indicating moderate agreement. The resulting positive predictive values were 0.77-0.82 and negative predictive values were 0.80-0.85. Sensitivity, specificity, and AUC values were 0.66-0.74, 0.81-0.88, and 0.88-0.91, respectively.Conclusions: The VGG-16 CNN model showed good discriminatory performance in detecting dental caries in intraoral camera images. The deep learning model can be beneficial in monitoring dental caries in the population."
Deep learning-based functional assessment of piezoelectric-based smart interface under various degradations,2021,"['CNN', 'debonding', 'deep learning', 'degradation', 'diagnosis', 'electromechanical', 'impedance characteristics', 'impedance method', 'piezoelectric sensor', 'sensor fault', 'shear lag', 'smart interface']",국문 초록 정보 없음,"The piezoelectric-based smart interface technique has shown promising prospects for electro-mechanical impedance (EMI)-based damage detection with various successful applications. During the process of EMI monitoring and damage identification, the operational functionality of the smart interface device is a major concern. In this study, common functional degradations that occurred in the smart interface are diagnosed using a deep learning-based method. Firstly, the effect of functional degradations on the EMI responses is analytically discussed. Secondly, a critical structural joint is selected as the test structure from which EM measurement using the smart interface is conducted. Thirdly, a numerical model corresponding to the experimental model is established and updated to reproduce the measured EMI responses. By using the updated numerical model, the EMI responses of the smart interface under the common functional degradations, such as the shear lag effect, the adhesive debonding, the sensor breakage, and the interface detaching, are simulated; then, the functional degradation-induced EMI changes are characterized. Finally, a convolutional neural network (CNN)-based functional assessment method is newly proposed for the smart interface. The CNN can automatically extract and directly learn optimal features from the raw EMI signals without preprocessing. The CNN is trained and tested using the datasets obtained from the updated numerical model. The obtained results show that the proposed method was successful to classify four types of common defects in the smart interface, even under the effect of noises."
딥러닝을 이용한 벼 도복 면적 추정,2021,"['area estimation', 'cnn', 'deep learning', 'lodging', 'machine learning', 'rice']",국문 초록 정보 없음,"Rice lodging is an annual occurrence caused by typhoons accompanied by strong winds and strong rainfall, resulting in damage relating to pre-harvest sprouting during the ripening period. Thus, rapid estimations of the area of lodged rice are necessary to enable timely responses to damage. To this end, we obtained images related to rice lodging using a drone in Gimje, Buan, and Gunsan, which were converted to 128 × 128 pixels images. A convolutional neural network (CNN) model, a deep learning model based on these images, was used to predict rice lodging, which was classified into two types (lodging and non-lodging), and the images were divided in a 8:2 ratio into a training set and a validation set. The CNN model was layered and trained using three optimizers (Adam, Rmsprop, and SGD). The area of rice lodging was evaluated for the three fields using the obtained data, with the exception of the training set and validation set. The images were combined to give composites images of the entire fields using Metashape, and these images were divided into 128 × 128 pixels. Lodging in the divided images was predicted using the trained CNN model, and the extent of lodging was calculated by multiplying the ratio of the total number of field images by the number of lodging images by the area of the entire field. The results for the training and validation sets showed that accuracy increased with a progression in learning and eventually reached a level greater than 0.919. The results obtained for each of the three fields showed high accuracy with respect to all optimizers, among which, Adam showed the highest accuracy (normalized root mean square error: 2.73%). On the basis of the findings of this study, it is anticipated that the area of lodged rice can be rapidly predicted using deep learning."
인공지능 기반 위 병변 검출 알고리즘 개발,2021,"['Gastric Endoscopy', 'CNN', 'R-CNN Model', '위 내시경', '합성곱 신경망', '영역기반 합성곱 신경망 모델']","위암은 1999년 이후 우리나라에서 가장 많이 발생하는 암으로 1위를 차지하고 있다. 위암은 내시경 검사를 통해 일차적으로 판단되고 조직검사를 통해 정확히 진단되기 전까지는 특징적인 증상이 없으며, 실제로 위 내시경 검사를 받은 환자는 받지 않은 환자에 비해 생존율이 2.24배 높다는 연구 결과가 발표된 바 있다. 이러한 문제를 해결하기 위하여 본 논문은 위암 환자의 위 내시경 시행 시 임상의에게 실시간으로 보조적인 정보를 제공해 주고자 제안되었다. 본 논문에서는 Faster R-CNN을 위 병변 검출에 적합한 모델로 개선하여 보다 빠르고 정확한 검출 결과를 임상의에게 제공하는 방법을 제안한다. 기존 알고리즘과의 비교 평가 결과 평균 91%의 정확도를 도출하여 제안 방법이 보다 효과적임을 증명하였으며, 영상 처리 속도 또한 0.1sec/frame을 도출하여 실시간 처리에 적합함을 증명하였다. 향후 연구로 다양한 환경에서의 내시경 영상 수집을 통한 학습 데이터의 개선을 통해 정확도를 개선하고자 한다.","Gastric cancer is the most common cancer and has been the number one incidence since 1999 in Korea. Gastric cancer is primarily judged through endoscopy and has no characteristic symptoms until accurately diagnosed through biopsy then In fact, a study found that patients who underwent gastroscopy had a 2.24 times higher survival rate than those who did not. to solve these problems, This paper was proposed to provide real-time ancillary information to clinicians when performing gastroscopy for gastric cancer patients. In this paper, we propose a method to provide faster and more accurate detection results to clinicians by improving Faster R-CNN as a model suitable for gastric lesion detection. As a result of comparative evaluation with existing algorithms, an average accuracy of 91% was derived, proving that the proposed method is more effective. and, The image processing speed was also proven to be suitable for real-time processing by deriving 0.1sec/frame. As a future study, we intend to improve the accuracy by improving the learning data through the collection of endoscopic images in various environments."
Reconstruction of Terrestrial Water Storage of GRACE/GFO Using Convolutional Neural Network and Climate Data,2021,"['GRACE', 'GRACE FO', 'CNN', 'TWS']",국문 초록 정보 없음,"Gravity Recovery and Climate Experiment (GRACE) gravimeter satellites observed the Earth gravity field with unprecedented accuracy since 2002. After the termination of GRACE mission, GRACE Follow-on (GFO) satellites successively observe global gravity field, but there is missing period between GRACE and GFO about one year. Many previous studies estimated terrestrial water storage (TWS) changes using hydrological models, vertical displacements from global navigation satellite system observations, altimetry, and satellite laser ranging for a continuity of GRACE and GFO data. Recently, in order to predict TWS changes, various machine learning methods are developed such as artificial neural network and multi-linear regression. Previous studies used hydrological and climate data simultaneously as input data of the learning process. Further, they excluded linear trends in input data and GRACE/GFO data because the trend components obtained from GRACE/GFO data were assumed to be the same for other periods. However, hydrological models include high uncertainties, and observational period of GRACE/GFO is not long enough to estimate reliable TWS trends. In this study, we used convolutional neural networks (CNN) method incorporating only climate data set (temperature, evaporation, and precipitation) to predict TWS variations in the missing period of GRACE/GFO. We also make CNN model learn the linear trend of GRACE/GFO data. In most river basins considered in this study, our CNN model successfully predicts seasonal and long-term variations of TWS change."
공연예술에서 광고포스터의 이미지 특성을 활용한 딥러닝 기반 관객예측,2021,"['공연예술', '흥행 예측', 'CNN', 'VGG-16', 'Inception-v3', 'ResNet50', 'Performing Arts', 'Box Office Prediction']","공연예술 기관에서의 공연에 대한 흥행 예측은 공연예술 산업 및 기관에서 매우 흥미롭고도 중요한 문제이다. 이를 위해 출연진, 공연장소, 가격 등 정형화된 데이터를 활용한 전통적인 예측방법론, 데이터마이닝 방법론이 제시되어 왔다. 그런데 관객들은 공연안내 포스터에 의하여 관람 의도가 소구되는 경향이 있음에도 불구하고, 포스터 이미지 분석을 통한 흥행 예측은 거의 시도되지 않았다. 그러나 최근 이미지를 통해 판별하는 CNN 계열의 딥러닝 방법이 개발되면서 포스터 분석의 가능성이 열렸다. 이에 본 연구의 목적은 공연 관련 포스터 이미지를 통해 흥행을 예측할 수 있는 딥러닝 방법을 제안하는 것이다. 이를 위해 KOPIS 공연예술 통합전산망에 공개된 포스터 이미지를 학습데이터로 하여 Pure CNN, VGG-16, Inception-v3, ResNet50 등 딥러닝 알고리즘을 통해 예측을 수행하였다. 또한 공연 관련 정형데이터를 활용한 전통적 회귀분석 방법론과의 앙상블을 시도하였다. 그 결과 흥행 예측 정확도 85%를 상회하는 높은 판별 성과를 보였다. 본 연구는 공연예술 분야에서 이미지 정보를 활용하여 흥행을 예측하는 첫 시도이며 본 연구에서 제안한 방법은 연극 외에 영화, 기관 홍보, 기업 제품 광고 등 포스터 기반의 광고를 하는 영역으로도 적용이 가능할 것이다.","The prediction of box office performance in performing arts institutions is an important issue in the performing arts industry and institutions. For this, traditional prediction methodology and data mining methodology using standardized data such as cast members, performance venues, and ticket prices have been proposed. However, although it is evident that audiences tend to seek out their intentions by the performance guide poster, few attempts were made to predict box office performance by analyzing poster images. Hence, the purpose of this study is to propose a deep learning application method that can predict box office success through performance-related poster images. Prediction was performed using deep learning algorithms such as Pure CNN, VGG-16, Inception-v3, and ResNet50 using poster images published on the KOPIS as learning data set. In addition, an ensemble with traditional regression analysis methodology was also attempted. As a result, it showed high discrimination performance exceeding 85% of box office prediction accuracy. This study is the first attempt to predict box office success using image data in the performing arts field, and the method proposed in this study can be applied to the areas of poster-based advertisements such as institutional promotions and corporate product advertisements."
호흡음 증상 분류를 위한 앙상블 기반 기계학습 모델,2021,[],국문 초록 정보 없음,"This paper optimizes CNN models by preprocessing respiratory sound data into three types of images, and proposes a CNN Ensemble model using optimized CNN models. The three types of images are MFCC, Scalogram, and waveform. The reason for using these three types of images is that they have different characteristics of those images depending on the symptom. The proposed CNNEnsemble model is a model that utilizes three proposed CNN models and combines them into an ensemble model. The proposed models are evaluated against a challenge dataset known as ICBHI 2017 in order to classify respiratory sound symptom. For the validity of the proposed CNNEnsemble model, the accuracy of symptom classification from the proposed model is compared with the accuracies of other researches."
MI 센서기반의 금속탐지용 뉴럴네트워크 성능비교에 관한연구,2021,"['합성곱신경망', '딥러닝', '전자기유도', '자기임피던스센서', '순환신경망', 'CNN', 'Deep Learning', 'Electromagnetic Induction', 'MI sensor', 'RNN']",국문 초록 정보 없음,"This paper is a study on the efficiency of the filtering method of signal processing and the metal detection method using deep learning for data obtained from multiple MI sensors. The MI sensor is a principle that detects changes in magnetic field and is a passive sensor that detects metal objects. However, when detecting a metal object, the amount of change in the magnetic field caused by the metal is small, so there is a limit to the detectable distance. In order to effectively detect and analyze this, a method using deep learning was applied. In addition, the performance of the deep learning model was compared and analyzed using the filtering method of signal processing. In this paper, the detection performance of CNN and RNN networks was compared and analyzed from the data extracted from the self-impedance sensor. The RNN model showed higher performance than the CNN model. However, in the shallow stage, the CNN model showed higher performance than the RNN model."
Classification of Vocalization Recordings of Laying Hens and Cattle Using Convolutional Neural Network Models,2021,"['Mel-frequency cepstrum', 'Convolutional neural network (CNN)', 'Vocalization classification', 'Cattle', 'Laying hens']",국문 초록 정보 없음,"Purpose Vocalizations of livestock convey information about the health and behavior of the animals, and vocal analysis could be a useful method to monitor livestock. We propose a deep learning classification of vocal recordings of laying hens and cattle with the aim of automatically classifying laying hen and cattle sounds in South Korea using a deep learning model.Methods Audio and video recordings of laying hens and cattle were acquired. We classified laying hens’ sounds into eight classes and cattle sounds into nine classes. Classified audio files were used for the development of convolutional neural network (CNN) models. Two types of CNN structures, one based on 2D ConVnet and the other based on a 1D model with long short-term memory, were developed and tested for modeling to classify the vocalizations of laying hens and cattle.Results The classification model based on 2D ConVnet performed better with a satisfactory classification accuracy of 75.78% for laying hens and 91.02% for cattle.Conclusion Based on the results for the developed CNN models, it is expected that real-time voice monitoring could be applicable for providing animal physiological information to growers."
Machine Learning-based 3D Printer Fault Detection on Edge Device,2021,"['3D printer', 'convolutional neural network (CNN)', 'fault detection']",국문 초록 정보 없음,"The 3D printer is a new manufacturing technique that becoming popular in the fields of industry. However, the rapid development of 3D printing technology needs fault detection in the printing process. In this paper, a fault detection based on stacked convolutional neural network (CNN) for 3D printer is proposed. Moreover, a dataset of 3D printer for fault diagnosis is also provided. The result presented in this paper shows that, a stacked-CNN is better than the single CNN and the other methods for fault detection."
ConvLSTM을 이용한 도로 구간 속도 예측 기법,2021,"['speed prediction', 'deep neural network', 'CNN', 'LSTM']",국문 초록 정보 없음,"Predicting the speed of a road link, which means a specific segment of a road, is an important technology for location-based services like best route on the road. Recently, machine learning-based speed prediction methods including deep neural networks have been proposed. In particular, a speed prediction method using a convolution neural network (CNN) and a recurrent neural network (RNN) has been proposed. CNN can predict the speed by considering the spatial characteristics of the road, and RNN can predict the speed by considering the temporal characteristics of the speed change according to time of the road. In this paper, we propose a speed prediction method based on Convolutional LSTM (ConvLSTM) combining RNN and CNN that considers the properties of the neighboring links of the road link and the properties of the temporal road link together. In addition, the previously proposed LSTM-based speed prediction method is partially modified and implemented, and the performance of both is compared through experiments. Finally we shows the superiority of the proposed method compared to the existing proposed method."
내시경 수술영상에서 수술도구 인식을 위한 물체인식 딥러닝 모델의 성능 비교,2021,[],"본 연구에서는 내시경 수술 영상에서 총 6종의 수술도구를 인식하기 위하여 YOLO 계열의 모델과 R-CNN 계열의 모델 간 성능 차이를 비교 분석하기 위한 연구를 수행하였다. 두 계열에는 방법의 차이가 존재하므로 주어진 영상과 문제마다 적합한 모델이 무엇인지 분석해보고자 한다. 본 연구에 적용된 방법은 YOLOv3와 Faster R-CNN이며, 그 결과 YOLOv3는 속도가 빠르지만 정확도가 조금 떨어지는 경향을 보였고, Faster R-CNN의 경우 YOLOv3대비 속도가 2.6배 느리지만 3.59%의 정확도가 더 높은 것을 확인하였다. 의료영상의 특성상 속도보다는 정확도가 더 중요하므로 Faster R-CNN을 적용하는 것이 바람직한 것으로 판단된다.",다국어 초록 정보 없음
Automatic modulation classification of noise‐like radar intrapulse signals using cascade classifier,2021,"['complex envelope', 'convolutional neural network', 'modulation classification', 'radar emitter identification']",국문 초록 정보 없음,"Automatic modulation classification is essential in radar emitter identification. We propose a cascade classifier by combining a support vector machine (SVM) and convolutional neural network (CNN), considering that noise might be taken as radar signals. First, the SVM distinguishes noise signals by the main ridge slice feature of signals. Second, the complex envelope features of the predicted radar signals are extracted and placed into a designed CNN, where a modulation classification task is performed. Simulation results show that the SVM‐CNN can effectively distinguish radar signals from noise. The overall probability of successful recognition (PSR) of modulation is 98.52% at 20 dB and 82.27% at −2 dB with low computation costs. Furthermore, we found that the accuracy of intermediate frequency estimation significantly affects the PSR. This study shows the possibility of training a classifier using complex envelope features. What the proposed CNN has learned can be interpreted as an equivalent matched filter consisting of a series of small filters that can provide different responses determined by envelope features."
합성곱 오토인코더를 이용한 체인 전동 장치의 고장 결함 감지 및 진단,2021,"['Fault Detection(고장 검출)', 'Fault Diagnosis(고장 진단)', 'Deep Learning(딥러닝)', 'Convolutional Auto-encoder(합성곱 오토인코더)', 'Unsupervised Learning(비지도학습)', 'Convolutional Neural Network(합성곱 신경망)']",국문 초록 정보 없음,"This paper presents a method to detect the mechanical faults of a chain drive power transmission system (CDPTS) using a convolutional auto-encoder (CAE). In previous research, it was known that the methods to detect faults of the CDPTS based on an artificial neural network (ANN) and convolutional neural network (CNN) were useful. In this paper, an advanced application of CNN, the CAE function of CNN is employed to detect faults. This method uses the characteristics of reconstruction of CAE. Difference of input images of the CNN and reconstructed images extracted by CAE were used as the guideline of fault detection. In the fault condition of the system, the difference was larger than the predetermined threshold of error. The encoder of CAE can be fine-tuned to classify the fault types of CDPTS. Finally, this method was well applied to diagnose the fault types of the test CDPTS installed in the laboratory."
자율주행 차량 영상 기반 객체 인식 인공지능 기술 현황,2021,"['객체 인식', '자율주행 차량', '영상 기반 인공지능', '단일 단계 검출', '두 단계 검출', 'Object detection', 'Autonomous vehicle', 'Image-based AI', 'Single-step detection', 'Two-step detection.']","객체 인식이란 하나의 특정 이미지를 입력했을 때, 주어진 이미지를 분석하여 특정한 객체(object)의 위치(location)와 종류(class)를 파악하는 것이다. 최근 객체 인식 기술이 적극적으로 접목되는 분야 중 하나는 자율주행 차량이라 할 수 있고, 본 논문에서는 자율주행 차량에서 영상 기반의 객체 인식 인공지능 기술에 대해 기술한다. 영상 기반 객체 검출 알고리즘은 최근 두 가지 방법(단일 단계 검출 방법 및 두 단계 검출 방법)으로 좁혀지고 있는데, 이를 중심으로 분석 정리하고자 한다. 두 가지 검출 방법의 장단점을 분석 제시하고, 단일 단계 검출 방법에 속하는 YOLO/SSD 알고리즘과 두 단계 검출 방법에 속하는 R-CNN/Faster R-CNN 알고리즘에 대해 분석 기술한다. 이를 통해 자율주행에 필요한 각 객체 인식 응용에 적합한 알고리즘이 선별적으로 선택되어 연구개발 되어질 수 있기를 기대한다.","Object recognition is to identify the location and class of a specific object by analyzing the given image when a specific image is input. One of the fields in which object recognition technology is actively applied in recent years is autonomous vehicles, and this paper describes the trend of image-based object recognition artificial intelligence technology in autonomous vehicles. The image-based object detection algorithm has recently been narrowed down to two methods (a single-step detection method and a two-step detection method), and we will analyze and organize them around this. The advantages and disadvantages of the two detection methods are analyzed and presented, and the YOLO/SSD algorithm belonging to the single-step detection method and the R-CNN/Faster R-CNN algorithm belonging to the two-step detection method are analyzed and described. This will allow the algorithms suitable for each object recognition application required for autonomous driving to be selectively selected and R&D."
음성기반 인간-인공지능 인터랙션에서 표정 정보를 활용한 사용자 감성 디코딩 기법의 적용 및 한계,2021,"['Deep learning', 'Human AI Interaction', 'Voice User Interfaces', 'Facial Expression Recognition']","Objective: 본 연구에서는 음성 기반 인간-인공지능 인터랙션(Human-AI Interaction, 이하 HAII) 환경에서 표정 정보를 활용하여 사용자의 감성을 디코딩하는 기존 방법론을 적용하고 그 결과를 분석하여 한계점을 도출하고 향후 연구 방향에 대하여 제안하고자 한다. Background: 사용자와 디바이스의 인터랙션에 대한 만족도를 평가할 수 있는 유용한 지표 중 하나는 사용자의 감성 만족도라고 할 수 있다. 하지만 HAII에서의 사용자 감성 평가에 대한 연구는 여전히 부족한 상황이며, 특히 음성 기반 인터랙션에서 사용자가 느끼는 감성을 평가하기 위한 체계나 도구들이 명확하게 제시된 바 없다. 최근, 다양한 모달리티(표정, 뇌파, 음성 등)를 이용한 사용자 감성 평가에 대한 연구가 많이 이루어지고 있지만 음성 기반 인터랙션에서의 사용자 개인에 적용 가능한 적응형 감성 평가 연구는 부족한 실정이다. 본 연구에서는 가장 기본적인 모달리티인 표정 데이터를 이용해서 VUI(Voice User Interface)기반 HAII에서 사용자 감성 평가 연구를 진행하고자 한다. Method: 실험을 위하여 사용자와 인공지능 스피커 간의 질의 응답 시나리오를 수행하는 HAII 실험을 진행하였다. 실험 과정에서 사용자는 서로 다른 설계변수를 바탕으로 대답을 제공하는 AI 에이전트와 상호작용을 수행하고 해당 인터랙션에 대한 감성 만족도를 평가한다. 본 연구에서는 이러한 HAII 과정에서 촬영한 사용자 얼굴 이미지 세트를 대상으로, VGGFace2를 이용해서 획득한 CNN feature와 FaceReader 8.0을 이용해서 획득한 얼굴 landmark 데이터를 이용하여 feature visualization 및 clustering을 진행하고 기존 표정 인식 데이터 세트인 CK+, Oulu-CASIA와의 비교 분석을 수행하였다. 추가적으로, 한국인/서양인만으로 구성된 데이터셋을 바탕으로 CNN 모델을 학습한 후 각 데이터셋에 대한 감정 분류를 진행하여 race bias에 의한 효과를 살펴보고자 하였다. Results: 실험 결과, HAII 과정에서 수집된 표정 데이터의 VA 점수는 대부분 지루함, 슬픔, 중립을 의미하는 영역대에 집중되었다. 기존의 CK+, Oulu-CASIA 데이터셋의 경우 각 감성 별 과장된 표정에 의하여 CNN feature가 표정에 따라 군집화 되는 모습을 보였으나, HAII 데이터셋의 경우 사용자의 감성 만족도에는 차이가 있더라도 표정에서는 명확히 드러나지 않아, CNN feature 또한 군집화 되지 않는 모습을 보였다. 또한, 서양인 기반 분류 모델은 한국인의 표정을 대부분 중립/슬픔으로 분류하는 것을 확인했으며, 한국인 기반 분류 모델은 특정 감성을 제외하고 서양인의 표정을 제대로 분류하지 못하는 결과를 확인할 수 있었다. Conclusion: 본 연구에서는 다양한 HAII 중 AI 비서, 스피커와 같은 VUI와의 상호작용에서 사용자가 느낄 수 있는 감성을 평가하기 위한 표정 기반 방법론의 적용과 한계점에 대하여 논하였다. 실험 결과를 통하여 음성 기반 HAII에서 사용자 표정을 이용한 감성 만족도 예측의 결과와 시사점들을 도출하였다. 향후 보다 자연스러운 HAII를 위해 음성, 표정, 뇌파 등을 함께 사용하는 멀티모달 인터랙션 기반의 감성 만족도 평가 프레임워크로 확장할 예정이며, 일반 VUI 디바이스의 컴퓨팅 파워를 고려해 경량 딥러닝 기반 감성평가 프로토콜 개발을 진행할 계획이다. Application: 본 연구 내용을 기반으로 자연스러운 음성기반 인터랙션 상황에서 표정 기반 감성 분석을 통한 사용자 맞춤형 서비스 제공이 가능하다. 표정 데이터 뿐만 아니라 음성, 뇌파와 결합해서 더욱 강인한 인터랙션 피드백을 제공할 수 있으며, 사용자 만족도에 큰 이바지를 할 것으로 기대한다.",다국어 초록 정보 없음
A comparative study of fine-tuning deep learning models for apple and pear disease recognition,2021,"['CNN', 'Deep learning', 'Disease classification', 'Fire blight', 'Fine-tuning']",국문 초록 정보 없음,"As there is no cure for fire blight, which mainly affects pears and apples, effective and rapid detection is very important. Existing fire blight diagnostic studies usually used biotechnology, such as immunodiagnostic kits. With the development of deep learning-based image recognition technology, an image-based fire blight diagnosis method has been proposed. For the diagnosis of diseases that have similar symptoms, including fire blight, this study developed a disease recognition model using the deep convolutional neural network (CNN). Fine-tuning was performed on VGG16, VGG19, ResNet50, DenseNet121, Inception-ResNet v2, NASNet and EfficientNet models, which were pre-trained through ImageNet dataset. The experiment used 14,304 images of six diseases collected from pear and apple as the dataset. As a result of the experiment, all seven fine-tuned models achieved an accuracy of more than 90%, among which the ResNet50 model achieved the highest accuracy at 98.83%. It is anticipated that the proposed model can be valuably used at actual farmhouses to diagnose and prevent fire blight through appropriate services in the future."
퓨 샷 러닝 모델을 이용한 영상 분류,2021,"['CNN', '이미지 특징', '컨볼루션 레이어', '분류 정확도']",본 논문에서는 모델 구조 최적화를 사용하여 기본 컨볼루션 신경망(CNN) 모델을 확장하고 컨볼루션 레이어를 추가하여 더 많은 이미지 특징을 추출하여 분류 정확도를 향상시킨다. 우리는 모델의 성능을 향상시키기 위해 특정 조치를 통합한다.,"In this paper, we extend the basic convolutional neural network (CNN) model using model structure optimization and extract more image features by adding a convolutional layer to improve classification accuracy. We incorporate certain measures to improve the performance of our model."
A Study on the Two-Dimensional Graph Data and Its Effectiveness in Human Behavior Classification Deep Learning,2021,"['CNN', 'image', 'deep learning', 'human behavior recognition', 'machine learning']",국문 초록 정보 없음,"Recently, a lot of research has been conducted using machine learning technology in various fields. It also develops models by applying various learning techniques. We propose a method to develop a CNN model using a two-dimensional graph image, focusing on learning using CNN to process time series information faster than LSTM. Process the data to create a two-dimensional graph and use it for training AI models. It collects data on 4 specific motions with a 6-axis sensor (Arduino nano 33 ble) and creates a two-dimensional graph. The result of testing the model trained in this study is 99.6% accuracy. This was able to achieve higher accuracy than other studies that did not image the data. The difference from the time series data training model using other CNNs is that you can analyze all items in the graph from one kernel. Conventional methods make it difficult to convolution all items into one kernel. Additionally, through experiments with various parameters, inferences between parameters and results and optimal settings are suggested."
모바일용 한글 필기 인식 시스템 개발,2021,"['CNN', 'recognition', 'Korean-handwritten character', 'preprocessing']","한글 필기 인식은 오래된 연구 주제 중 하나이다. 인공지능 기술의 발전으로 인하여 인식의 정확도가 높아졌지만, 중국어나 아랍어보다 인식률이 낮은 것이 사실이다. 정확도를 높이기 위해서는 CNN 모델의 계층을 깊게 하고 채널의 수를 늘리면 되지만, 인자의 개수가 증가하여 복잡도가 커진다. 이에 본 논문에서는 한글 필기의 특징을 고려하여 전처리 알고리즘을 제안한다. 한글의 모음은 대개 직선으로 필기되며 또한 한글은 모음의 위치에 따라 6가지 하나에 해당한다. 이에 기반하여 학습 모델의 복잡도는 낮추면서도 정확도는 높은 모바일 온라인 한글 필기 인식 시스템을 개발하였다.","The recognition of Korean-handwritten characters has been one of traditional research issues. As AI-related technologies was developed, the accuracy also increased. However, recognition accuracy is lower than that of Chinese or Arabic. To improve the accuracy, deepen the layer of the CNN model and increase the number of channels, which the number of parameters increases and the complexity increases. In this paper, we proposed preprocessing algorithm based on the special feature of Korean-handwritten. Korean vowels are usually written in straight lines and Hangul falls into one of six cases depending on the location of vowels. Based on the facts, we developed a mobile online Korean handwritten character recognition system with lower complexity and higher accuracy."
A Fast Real-time Facial Expression Classifier Deep Learning-based for Human-robot Interaction,2021,"['Efficient CNN', 'Facial expression', 'Human-robot Interaction', 'Real-time']",국문 초록 정보 없음,"Human-robot interaction drives the need for vision technology to recognize user expressions. Convolutional Neural Networks (CNN) has been introduced as a robust facial feature extractor and can overcome classification task. However, it is not supported by efficient computation for real-time applications. The work proposes an efficient CNN architecture to recognize human facial expressions that consist of five stages containing a combination of lightweight convolution operations. It introduces the efficient contextual extractor with a partial transfer module to suppress computational compression. This technique is applied to the mid and high-level features by separating the channel-based input features into two parts. Then it applies sequential convolution to only one part and combines it with the previous separated part. A shuffle channel group is used to exchange the information extracted. The structure of the entire network generates less than a million parameters. The CK+ and KDEF datasets are used as training and test sets to evaluate the performance of the proposed architecture. As a result, the proposed classifier obtains an accuracy that is competitive with other methods. In addition, the efficiency of the classifier has strongly suitable for implementation to edge devices by achieving 43 FPS on a Jetson Nano."
딥러닝 합성곱에서 데이터 재사용에 최적화된 GPGPU 설계,2021,"['Data Reuse', 'CNN', 'GPGPU', 'Row stationary', 'SIMT', 'Warp', 'Register bank']","본 논문은 합성곱 신경망에 데이터 재사용 방법을 효과적으로 적용하여 연산 횟수와 메모리 접근 횟수를 줄일 수 있는 GPGPU구조를 제안한다. 합성곱은 kernel과 입력 데이터를 이용한 2차원 연산으로 kernel이 slide하는 방법으로 연산이 이루어 진다. 이때, 합성곱 연산이 완료될 때 까지 kernel을 캐시메모리로 부터 전달 받는 것이 아니고 내부 레지스터를 이용하는 재사용 방법을 제안한다. SIMT방법으로 명령어가 실행되는 GPGPU의 원리 이용하여 데이터 재사용의 효과를 높이기 위해 합성곱에 직렬 연산 방식을 적용하였다. 본 논문에서는 레지스터기반 데이터 재사용을 위하여 kernel을 4x4로 고정하고 이를 효과적으로 지원하기 위한 warp 크기와 레지스터 뱅크를 갖는 GPGPU를 설계하였다. 설계된 GPGPU의 합성곱 신경망에 대한 성능을 검증하기 위해 FPGA로 구현한 뒤 LeNet을 실행시키고 TensorFlow를 이용한 비교 방법으로 AlexNet에 대한 성능을 측정하였다. 측정결과 AlexNet기준 1회 학습 속도는 0.468초이며 추론 속도는 0.135초이다.","This paper proposes a GPGPU structure that can reduce the number of operations and memory access by effectively applying a data reuse method to a convolutional neural network(CNN). Convolution is a two-dimensional operation using kernel and input data, and the operation is performed by sliding the kernel. In this case, a reuse method using an internal register is proposed instead of loading kernel from a cache memory until the convolution operation is completed. The serial operation method was applied to the convolution to increase the effect of data reuse by using the principle of GPGPU in which instructions are executed by the SIMT method. In this paper, for register-based data reuse, the kernel was fixed at 4x4 and GPGPU was designed considering the warp size and register bank to effectively support it. To verify the performance of the designed GPGPU on the CNN, we implemented it as an FPGA and then ran LeNet and measured the performance on AlexNet by comparison using TensorFlow. As a result of the measurement, 1-iteration learning speed based on AlexNet is 0.468sec and the inference speed is 0.135sec."
Implementation of Speech Recognition and Flight Controller Based on Deep Learning for Control to Primary Control Surface of Aircraft,2021,"['Speech Recognition', 'CNN', 'MFCC', 'Flight Controller', 'TensorFlow', '음성 인식', '합성곱 신경망', '비행 제어장치', '텐서플로우']","본 논문에서는 음성 명령을 인식하여 비행기의 1차 조종면을 제어할 수 있는 장치를 제안한다. 음성 명령어는 19개의 명령어로 구성되며 총 2,500개의 데이터셋을 근간으로 학습 모델을 구성한다. 학습 모델은 TensorFlow 기반의 Keras 모델의 Sequential 라이브러리를 이용하여 CNN 모델로 구성되며, 학습에 사용되는 음성 파일은 MFCC 알고리즘을 이용하여 특징을 추출한다. 특징을 인식하기 위한 2단계의 Convolution layer 와 분류를 위한 Fully Connected layer는 2개의 dense 층으로 구성하였다. 검증 데이터셋의 정확도는 98.4%이며 테스트 데이터셋의 성능평가에서는 97.6%의 정확도를 보였다. 또한, 라즈베리 파이 기반의 제어장치를 설계 및 구현하여 동작이 정상적으로 이루어짐을 확인하였다. 향후, 음성인식 자동 비행 및 항공정비 분야의 가상 훈련환경으로 활용될 수 있을 것이다.","In this paper, we propose a device that can control the primary control surface of an aircraft by recognizing speech commands. The speech command consists of 19 commands, and a learning model is constructed based on a total of 2,500 datasets. The training model is composed of a CNN model using the Sequential library of the TensorFlow-based Keras model, and the speech file used for training uses the MFCC algorithm to extract features. The learning model consists of two convolution layers for feature recognition and Fully Connected Layer for classification consists of two dense layers. The accuracy of the validation dataset was 98.4%, and the performance evaluation of the test dataset showed an accuracy of 97.6%. In addition, it was confirmed that the operation was performed normally by designing and implementing a Raspberry Pi-based control device. In the future, it can be used as a virtual training environment in the field of voice recognition automatic flight and aviation maintenance."
Real-Time Bhutanese Sign Language Digits Recognition System Using Convolutional Neural Network,2021,"['Sign language', 'CNN', 'BSL dataset', 'Augmentation', 'Computer vision']",국문 초록 정보 없음,"The communication gap between the deaf and public is the concern for both parents and the government of Bhutan. The deaf school urges people to learn Bhutanese Sign Language (BSL) but learning Sign Language (SL) is difficult. This paper presents the BSL digits recognition system using the Convolutional Neural Network (CNN) and a first-ever BSL dataset which has 20,000 sign images of 10 static digits collected from different volunteers. Different SL models were evaluated and compared with the proposed CNN model. The proposed system has achieved 97.62% training accuracy. The system was also evaluated with precision, recall, and F1-score."
Classification of Hand Gestures Based on Multi-channel EMG by Scale Average Wavelet Transform and Convolutional Neural Network,2021,"['Accuracy', 'classification', 'CNN', 'hand gestures', 'scale average wavelet transform (SAWT)', 'sEMG.']",국문 초록 정보 없음,"Predicting and accurately classifying intentions for human hand gestures can be used not only for active prosthetic hands, rehabilitation robots, and entertainment robots but also for artificial intelligence robots in general. In this paper, first of all, source data of three hand gestures of grasping and three hand gestures of sign language are acquired by using the armband combined with eight sEMG (surface Electromyography) sensors. To classify these hand gestures, basically simple CNN (convolutional neural network) models with raw data, short-time Fourier transform (STFT), wavelet transform (WT), and scale average wavelet transform (SAWT) are applied, and their performances are compared. Finally, it is shown that by using a CNN with SAWT images, the accuracy can be improved up to 94.6% for selected hand gestures with higher accuracy and lower computational burden than conventional multi-channel STFT or WT."
New Detection Cheating Method of Online-Exams during COVID-19 Pandemic,2021,"['E-exam', 'CNN', 'Proctoring', 'Cheating', 'Covid-19']",국문 초록 정보 없음,"A novel approach for the detection of cheating during e-Exams is presented here using convolutional neural networks (CNN) based systems. This system will help the proctors to identify any kind of uncertain event at the time of online exams, for which most of the government's across the globe are recommending due to the Covid-19 pandemic. Most of the institutions and students across the globe are badly affected by their academic programs and it is a challenging task for universities to conduct examinations using the traditional methods. Therefore, the students are attending most of their classes using different types of third party applications that are available online. However, to conduct online exams the universities cannot rely on these service providers for a long time. Therefore, in this work, a complete setup of the software tools is provided for the students, which can be used by students at their respective laptops/personal computers with strict guidelines from the university. The proposed approach helps most of the universities in Saudi Arabia to maintain their database of different events/activities of students at the time of E-Exams. This method proved to be more accurate and CNN based detection proved to be more sensitive with an accuracy of 97% to detect any kind of uncertain activity of the students at the time of e-Exam."
조선 네스팅 문제의 부재 페어링을 위한 딥러닝 기반 부재 분류 방법,2021,"['Convolutional neural network(CNN)', 'Deep learning', 'Nesting', 'No-fit polygon(NFP)', 'Pairing', 'Part Classification']",국문 초록 정보 없음,"With the rapid development of artificial intelligence technology, deep learning-based classification techniques have had enough reliability to be applied to industrial sites. However, while the study of the object classification on data acquired with 3D scanners or cameras has made remarkable progress, research activity based on geometric data sets is still in its infancy. In particular, in order to improve the classification performance of ship parts based on deep learning in the nesting problem to increase productivity in shipbuilding, the study of the construction of part datasets and data pre-processing is necessary. In this paper, we introduce a method to apply the artificial neural network technology of deep learning to the nesting algorithm for shipbuilding. Labeled with histogram-based shape contexts for constructing a dataset for classifying ship parts using Convolutional Neural Networks (CNNs). In addition, we introduce the preprocessing method of the geometric information of the ship parts for learning and the no-fit polygon (NFP) method for classified parts to pair up. To train the classification model for the 23,201 ship parts, a data set of 842 classes was constructed through the shape matching algorithm. The trained CNN model was able to classify those parts with an accuracy of 85.13%."
작은 데이터 세트에 대한 새로운 이미지 분류 방법,2021,"['image classification method', 'CNN', 'small data set', 'overfitting']",본 논문에서는 소규모 데이터 세트의 이미지 분류 작업에서 모델 과적합 및 비수렴을 해결하고 분류 정확도를 향상시키는 데 주로 사용되는 CNN(Convolutional Neural Network) 기반의 새로운 이미지 분류 방법을 제안한다.,"In this paper, we propose a new image classification method based on Convolutional Neural Network (CNN), which is mainly used to solve model overfitting and non-convergence and to improve classification accuracy in image classification tasks on small datasets."
사람의 움직임 감지를 측정한 학습 능률 확인 시스템,2021,"['딥러닝', '학습 능률', 'DeepLearning', 'CNN', 'OpenPose', 'Learning efficiency']",국문 초록 정보 없음,"In this paper, we implement a learning efficiency verification system to inspire learning motivation and help improve concentration by detecting the situation of the user studying. To this aim, data on learning attitude and concentration are measured by extracting the movement of the user’s face or body through a real-time camera. The Jetson board was used to implement the real-time embedded system, and a convolutional neural network (CNN) was implemented for image recognition. After detecting the feature part of the object using a CNN, motion detection is performed. The captured image is shown in a GUI written in PYQT5, and data is collected by sending push messages when each of the actions is obstructed. In addition, each function can be executed on the main screen made with the GUI, and functions such as a statistical graph that calculates the collected data, To do list, and white noise are performed. Through learning efficiency checking system, various functions including data collection and analysis of targets were provided to users."
딥러닝을 이용한 유방조영술의 종양 분할,2021,"['유방조영술', '딥러닝', '의미론적 분할', 'CNN', 'Mammography', 'Deep Learning', 'Semantic Segmentation']","유방 종양은 유방암의 증상 중 하나이며 유방암은 여성에게서 흔히 발병하는 질병이다. 유방 종양은 초기 검사인 유방조영술에서 발견되므로 초기 진단이 매우 중요하다. 하지만 유방 종양을 탐지하는 것은 전문가에게도 어려운 일이다. 최근 딥러닝을 사용하여 유방조영술영상에서 병변을 찾으려는 노력이 이루어지고 있으며 본 논문에서는 딥러닝을 사용하여 유방조영술 영상에서 유방 종양을 분할하고자 한다. CBIS-DDSM(Curated Breast Image Subset of Digital Database for Screening Mammography) 데이터를 수집하고 데이터에 전처리를 시행한다. 의미론적 분할 모델인 FCN(Fully Convolutional Network), U-Net과 CNN(Convolutional Neural Network) 백본망인 VGGNet(Visual Geometry Group Net), EfficientNet 모델의 조합으로 4개의 모델을 구성하여 학습 기법을 사용하여 학습한다. 평가 데이터를 통해 유방 종양이 예측된 마스크와 유방 종양을 나타내는 실제 마스크를 사용하여 얼마나 유사하게 분할하였는지 시각화하고 구성한 모델의 성능을 비교한다. U-Net-EfficientNet 모델이 85.91%로 가장 높은 성능을 보여주었고, U-Net-VGG-Net 모델이 63.56%로 가장 낮은 성능을 보여주었다.","Breast tumor is one of the symptoms of breast cancer. And breast cancer is a common disease in women. Initial diagnosis is very important because breast tumors are found by mammography, which is an initial examination. However, detecting breast tumor is difficult even for experts. Efforts have recently been made to use deep learning to look for lesions in mammographic images. Many papers used deep learning to isolate breast tumors from mammographic images. We collect CBISDDSM(Curated Breast Image Subset of Digital Database for Screening Mammography) data and preprocess the data. Semantic segmentation model, which is FCN(Fully Convolutional Network) and U-Net, is combined with CNN(Convolutional Neural Network) backbone, which is VGGNet(Visual Geometry Group Net) and EfficientNet, to construct four models. The four models are trained using learning methods. The evaluation data are used to visualize the similarity between the segmented result using a predicted mask and the actual mask showing breast tumors. The performances of the constructed models are compared. The U-Net-EfficientNet model showed the highest performance at 85.91%, and the U-Net-VGGNet showed the lowest performance at 63.56%."
딥러닝을 활용한 이미지 기반 교량 구성요소 자동분류 네트워크 개발,2021,"['BIM', 'Deep learning', 'CNN', 'Bridge component classification', '딥러닝', '교량 구성요소 분류']","우리나라의 교량은 대부분이 건설된 지 20년 이상이 지나 현재 노후화로 인하여 많은 문제점이 제기되고 있으며, 교량의 안전점검은 대부분 전문 인력의 주관적인 평가로 이루어지고 있다. 최근 교량 안전점검의 데이터의 체계적인 관리를 위해 BIM 등을 활용한 데이터 기반의 유지관리기술들이 개발되고 있지만, BIM과 구조물의 유지관리 데이터를 연동을 위해서 영상정보를 직접 라벨링하는 수작업을 필요로한다. 따라서 본 논문에서는 이미지 기반의 자동 교량 구성요소 분류 네트워크를 개발하고자 한다. 본 연구에서 제안한 방법은 두 개의 CNN 네트워크로 구성되었다. 첫 번째 네트워크에서 특정 교량 이미지에 대하여 교량의 형식을 자동으로 분류한 뒤, 두 번째 네트워크에서 교량의 형식별로 구성요소를 분류함으로써 정확도와 효율성을 향상시키고자 한다. 본 연구에서 개발한 시스템을 검증한 결과, 847개의 교량 이미지에 대해서 98.1 %의 정확도로 교량의 구성요소를 자동으로 분류 할 수 있었다. 본 연구에서 개발한 교량의 구성요소 자동분류 기술은 향후 교량의 유지관리에 기여를 할 수 있을 것으로 기대된다.","Most bridges in Korea are over 20 years old, and many problems linked to their deterioration are being reported. The current practice for bridge inspection mainly depends on expert evaluation, which can be subjective. Recent studies have introduced data-driven methods using building information modeling, which can be more efficient and objective, but these methods require manual procedures that consume time and money. To overcome this, this study developed an image-based automatic bridge component classification network to reduce the time and cost required for converting the visual information of bridges to a digital model. The proposed method comprises two convolutional neural networks. The first network estimates the type of the bridge based on the superstructure, and the second network classifies the bridge components. In avalidation test, the proposed system automatically classified the components of 461 bridge images with 96.6 % of accuracy. The proposed approach is expected to contribute toward current bridge maintenance practice."
디스플레이 패널의 결함 검출을 위한 이미지 추출 방법,2021,"['defect detection', 'panel positioning', 'luminance', 'CNN', 'learning data']","본 눈문에서는 결함 검출을 위해 딥러닝 학습데이터로 사용되는 패널이미지를 추출하는 방법에 대하여 설명한다. 패널의 이미지는 카메라와 Frame Graber를 이용하여 추출하며, 패널 포지셔닝, 휘도 설정과 같은 다양한 작업을 통하여 패널 이미지를 추출한다. 본 논문에서는 추출된 이미지 데이터들이 머신러닝 모델의 학습데이터로 사용될 수 있는지를 확인하기 위해 CNN 모델을 구성하고 결함 검출을 수행하였다.","In this paper, a method of extracting a panel image used as deep learning learning data for defect detection is described. The image of the panel is extracted using the camera and Frame Grabber, and the panel image is extracted through various tasks such as panel positioning and luminance setting. In this paper, in order to confirm whether the extracted image data can be used as training data for the machine learning model, a CNN model was constructed and defect detection was performed."
변환학습을 이용한 장면 분류,2021,"['multiclass image scene classification method', 'ResNet', 'ImageNet', 'CNN model']",본 논문에서는 변환 학습을 기반으로 한 다중 클래스 이미지 장면 분류 방법을 제안한다. 이미지 분류를 위해 대형 이미지 데이터 세트 ImageNet에 대해 사전 학습한 ResNet (ResNet) 모델을 사용하는 방법이다. CNN 모델의 이미지 분류 방법에 비해 분류 정확도 및 효율성을 크게 향상시킬 수 있다.,"In this paper, we proposed a multiclass image scene classification method based on transform learning. The method using the Residual Network (ResNet) model which pre-trained on the large image dataset ImageNet for image classification. Compared with the image classification method of the CNN model, it can greatly improve the classification accuracy and efficiency"
합성곱 신경망을 이용한 Local Maximum Scalogram 기반 부정맥 분류에 관한 연구,2021,"['Arrhythmia', 'LMS', 'learning model', 'SVM', 'CNN', 'standard deviation']",국문 초록 정보 없음,"The purpose of this study is to investigate whether it can be used for arrhythmia detection as a wavelet transform and another feature extraction method using the probability distribution of LMS(Local Maximum Scalogram). The SVM(Support Vector Machine) model uses two kernels: Polynomial and Radial Basis Function(RBF). Three types of data are used: standard deviation of the row (n), standard deviation of the column(n/2), and standard deviation of the row and column (3n/2) of the basic LMS matrix according to the sample (n = 90,180, 270, 360, 450), The training data of the CNN model uses two LMS matrices when fixed to and. The trained model is divided 5 times, and K-fold cross-validation is performed and evaluated using ROC, AUC, and confusion matrix. Finally, the filtered ECG data is compared with the confusion matrix result graph to consider the types of arrhythmia that are difficult to classify. CNN is evaluated to show good overall performance when is. The results of the SVM model show the possibility that the standard deviation values of the LMS’s rows and columns can be used as a feature of arrhythmic bit detection. Since it is simple but very efficient, it is expected to be used in various ways as a single feature extraction method."
샤인머스캣과 청포도 자동 분류 딥러닝 시스템 개발,2021,"['분류', '딥러닝', '인공지능', '스마트 팜', '샤인머스캣', '청포도', 'CNN', 'Classification', 'Deep Learning', 'Artificial Intelligence', 'Smart Farm', 'Shine-muscat', 'Green-grape']",국문 초록 정보 없음,"In this paper, in order to develop an artificial intelligence system for automatic classification of shine muscats and green grapes with similar characteristics, an image dataset of the two fruits and a feature-based numerical dataset were constructed. Two CNN models were applied to the constructed image dataset and the accuracy of automatic classification was calculated using verification data. As a result, the VGGNET model showed 25% accuracy, and the CNN deep learning model proposed to minimize overfitting showed 84% accuracy. In addition, when the linear regression deep learning model was applied to feature-based numerical datasets, the accuracy of automatic classification was 94%. It is expected that the dataset construction method and deep learning method proposed in this paper can be applied to the implementation of artificial intelligence-based smart farm systems by automatically classifying fruits or agricultural products of different varieties."
딥러닝 기술을 이용한 반려동물 검색시스템,2021,"['Companion Animal', 'Deep learning', 'Convolution Neural Network(CNN)', 'k-Nearest Neighbor(k-NN)']","최근 반려동물은 평생을 함께하는 가족 같은 존재로 사람들과 함께 생활하고 있다 소중히 여기던 반려동물이 실종되었을 때 사람들은 반려동물이 사라졌다는 것에 대해 심리적으로 불안해지게 된다 사람들은 실종된 반려동물을 찾기 위해 동물 보호센터 홈페이지 애플리케이션, SNS 등 관련 사이트에 접근하게 된다 그러나 사이트에 등록된 데이터가 많으므로 그중에서 자신의 반려동물을 찾는 것은 많은 시간과 노력이 소요된다 그런 문제를 해결하기 위해 본 논문에서는 딥러닝 기술을 사용한 반려동물 검색시스템을 제안한다 딥러닝 기술은 입력 데이터의 특징을 추출할 CNN 모델과 특징이 추출된 데이터를 통해 유사한 사진을 검색할 k-NN 알고리즘을 사용한다 실종된 반려동물 사진을 시스템에 등록하면 딥러닝 기술을 적용하여 수많은 데이터 중 유사도가 가장 높은 데이터를 반환하여 사용자가 잃어버린 반려동물을 신속하게 검색할 수 있도록 한다.","Recently, companion animals live with people as family members who spend their whole lives together. When precious companion animals disappear, people become psychologically anxious about their pets disappearing. People will access related sites such as the Animal Protection Center""s website, applications and social media to find the missing companion animals. But, it takes a lot of time and effort to find your companion animals because there is a lot of data registered on the site. To solve such a problem, this paper proposes a companion animal search system using deep learning. Deep learning uses CNN models to extract features from input data and k-NN algorithms to retrieve similar photos from the data from which features are extracted. When a picture of a missing companion animal is registered in the system, deep learning is applied that returns the most similar data among many data, allowing users to quickly find lost companion animals."
립모션 센서 기반 증강현실 인지재활 훈련시스템을 위한 합성곱신경망 손동작 인식,2021,"['Euler angle spectrograph', 'Convolutional neural network (CNN)', 'Hand gesture recognition', 'Augmented reality (AR)', 'Cognitive rehabilitation system', 'Leap motion controller (LMC)']",국문 초록 정보 없음,"In this paper, we evaluated prediction accuracy of Euler angle spectrograph classification method using a convolutional neural networks (CNN) for hand gesture recognition in augmented reality (AR) cognitive rehabilitation system based on Leap Motion Controller (LMC). Hand gesture recognition methods using a conventional support vector machine (SVM) show 91.3% accuracy in multiple motions. In this paper, five hand gestures (""Promise"", ""Bunny"", ""Close"", ""Victory"", and ""Thumb"") are selected and measured 100 times for testing the utility of spectral classification techniques. Validation results for the five hand gestures were able to be correctly predicted 100% of the time, indicating superior recognition accuracy than those of conventional SVM methods. The hand motion recognition using CNN meant to be applied more useful to AR cognitive rehabilitation training systems based on LMC than sign language recognition using SVM."
Lightweight image classifier for CIFAR-10,2021,"['Computer vision', 'Convolutional neural networks', 'Image classification', 'Lightweight CNN']",국문 초록 정보 없음,"Image classification is one of the fundamental applications of computer vision. It enables a system to identify an object in an image. Recently, image classification applications have broadened their scope from computer applications to edge devices. The convolutional neural network (CNN) is the main class of deep learning neural networks that are widely used in computer tasks, and it delivers high accuracy. However, CNN algorithms use a large number of parameters and incur high computational costs, which hinder their implementation in edge hardware devices. To address this issue, this paper proposes a lightweight image classifier that provides good accuracy while using fewer parameters. The proposed image classifier diverts the input into three paths and utilizes different scales of receptive fields to extract more feature maps while using fewer parameters at the time of training. This results in the development of a model of small size. This model is tested on the CIFAR-10 dataset and achieves an accuracy of 90% using .26M parameters. This is better than the state-of-the-art models, and it can be implemented on edge devices."
인공지능 기반 영어 발음 인식에 관한 연구,2021,"['인공지능', '동적 시간 워핑', '합성곱 신경망', '영어 발음', '영어 교육', 'AI', 'DTW', 'CNN', 'English Pronunciation', 'English Language Training']","최근 4차 산업혁명은 주요 선진국을 중심으로 세계의 국가들의 관심을 갖는 분야가 되고 있다. 4차 산업혁명 기술의 핵심기술인 인공지능기술은 다양한 분야에 융합하는 형태로 발전하고 있으며, 에듀테크 분야에도 많은 영향을 미치고 있으며 교육을 혁신적으로 변화하기 위해 많은 관심과 노력을 하고 있다. 본 논문은 DTW 음성인식 알고리즘을 이용하여 실험환경을 구축하고 다양한 원어민 데이터와 비원어민 데이터를 딥러닝 학습하고, CNN 알고리즘과의 비교를 통해 영어 발음의 유사도를 측정하여 비원어민이 원어민과 유사한 발음으로 교정할 수 있도록 연구한다.","Recently, the fourth industrial revolution has become an area of interest to many countries, mainly in major advanced countries. Artificial intelligence technology, the core technology of the fourth industrial revolution, is developing in a form of convergence in various fields and has a lot of influence on the edutech field to change education innovatively. This paper builds an experimental environment using the DTW speech recognition algorithm and deep learning on various native and non-native data. Furthermore, through comparisons with CNN algorithms, we study non-native speakers to correct them with similar pronunciation to native speakers by measuring the similarity of English pronunciation."
모바일 플랫폼 교육 콘텐츠 지원을 위한 손 글씨 기반 텍스트 인터페이스 설계,2021,"['텍스트 인터페이스', '딥 러닝', '모바일', '영어 교육 콘텐츠', 'text interface', 'EMNIST', 'CNN', 'deep learning', 'mobile', 'English education contents']","본 연구는 모바일 플랫폼 환경에서 언어 기반의 교육 콘텐츠 지원을 위한 텍스트 인터페이스를 제안한다. 이는 손 글씨를 통해 단어를 작성하는 입력 구조로 딥 러닝을 활용한다. 모바일 플랫폼 콘텐츠의 버튼, 메뉴 등을 활용한 GUI (Graphical User Interface)와 화면 터치, 클릭, 드래그 등의 입력 방식을 기반으로 손 글씨를 사용자로부터 직접 입력하여 처리할 수 있는 텍스트 인터페이스를 설계한다. 이는 EMNIST (Extended Modified National Institute of Standards and Technology database) 데이터 셋과 훈련된 CNN (Convolutional Neural Network)을 사용하여 알파벳 텍스트를 분류하고 조합하여 단어를 완성한다. 최종적으로 영어 단어 교육 콘텐츠를 직접 제작하여 제안하는 인터페이스의 학습 지원 효과를 분석하고 만족도를 비교하기 위한 실험을 진행한다. 동일한 교육 환경에서 기존의 키 패드 방식의 인터페이스와 제안하는 손 글씨 기반 텍스트 인터페이스를 서로 체험한 사용자들이 제시하는 영어 단어를 학습하는 능력을 비교하고, 인터페이스를 조작하여 단어를 작성하는 과정에서의 전체적인 만족도를 분석, 확인하도록 한다.","This study proposes a text interface for support of language-based educational contents in a mobile platform environment. The proposed interface utilizes deep learning as an input structure to write words through handwriting. Based on GUI (Graphical User Interface) using buttons and menus of mobile platform contents and input methods such as screen touch, click, and drag, we design a text interface that can directly input and process handwriting from the user. It uses the EMNIST (Extended Modified National Institute of Standards and Technology database) dataset and a trained CNN (Convolutional Neural Network) to classify and combine alphabetic texts to complete words. Finally, we conduct experiments to analyze the learning support effect of the interface proposed by directly producing English word education contents and to compare satisfaction. We compared the ability to learn English words presented by users who have experienced the existing keypad-type interface and the proposed handwriting-based text interface in the same educational environment, and we analyzed the overall satisfaction in the process of writing words by manipulating the interface."
스태킹 앙상블을 이용한 병렬 네트워크 이상호흡음 분류 모델,2021,"['Respiratory Sound Classification', 'Wheezes', 'Crackles', 'Convolutional Neural Network(CNN)', 'Stacking Ensemble', '호흡음 분류', '천명음', '수포음', '병렬 합성곱 신경망', '스태킹 앙상블']","최근 코로나(Covid-19)의 영향으로 스마트 헬스케어 관련 산업과 비대면 방식의 원격 진단을 통한 질환 분류 예측 연구의 필요성이 증가하고 있다. 일반적으로 호흡기 질환의 진단은 비용이 많이 들고 숙련된 의료 전문가를 필요로 하여 현실적으로 조기 진단 및 모니터링에 한계가 있다. 따라서, 간단하고 편리한 청진기로부터 수집된 호흡음을 딥러닝 기반 모델을 활용하여 높은 정확도로 분류하고 조기 진단이 필요하다. 본 연구에서는 청진을 통해 수집된 폐음 데이터를 이용하여 이상 호흡음 분류모델을 제안한다. 데이터 전처리로는 대역통과필터(BandPassFilter)방법론을 적용하고 로그 멜 스펙트로그램(Log-Mel Spectrogram)과 Mel Frequency Cepstral Coefficient(MFCC)을 이용하여 폐음의 특징적인 정보를 추출하였다. 추출된 폐음의 특징에 대해서 효과적으로 분류할 수 있는 병렬 합성곱 신경망 네트워크(Parallel CNN network)모델을 제안하고 다양한 머신러닝 분류기(Classifiers)와 결합한 스태킹 앙상블(Stacking Ensemble) 방법론을 이용하여 이상 호흡음을 높은 정확도로 분류하였다. 본 논문에서 제안한 방법은 96.9%의 정확도로 이상 호흡음을 분류하였으며, 기본모델의 결과 대비 정확도가 약 6.1% 향상되었다.","As the COVID-19 pandemic rapidly changes healthcare around the globe, the need for smart healthcare that allows for remote diagnosis is increasing. The current classification of respiratory diseases cost high and requires a face-to-face visit with a skilled medical professional, thus the pandemic significantly hinders monitoring and early diagnosis. Therefore, the ability to accurately classify and diagnose respiratory sound using deep learning-based AI　models is essential to modern medicine as a remote alternative to the current stethoscope. In this study, we propose a deep learning-based respiratory sound classification model using data collected from medical experts. The sound data were preprocessed with BandPassFilter, and the relevant respiratory audio features were extracted with Log-Mel Spectrogram and Mel Frequency Cepstral Coefficient (MFCC). Subsequently, a Parallel CNN network model was trained on these two inputs using stacking ensemble techniques combined with various machine learning classifiers to efficiently classify and detect abnormal respiratory sounds with high accuracy. The model proposed in this paper classified abnormal respiratory sounds with an accuracy of 96.9%, which is approximately 6.1% higher than the classification accuracy of baseline model."
Learning mode switching 기반 DCGAN을 사용한 시계열 웨어러블 센서 데이터에 대한 새로운 data augmentation 방법,2021,"['시계열 데이터(Time series data)', 'DCGAN', '심층 합성곱 신경망(Deep CNN)', '데이터 확장(Data augmentation)']",국문 초록 정보 없음,"This paper describes a new image augmentation method based on a DCGAN considering mode switching in terms of transient learning accuracy threshold on the problem of human gesture recognition through imaging of wearable sensor time-series data and a deep CNN structure. Because the discriminator in GANs learns faster than the generator, it is known that mode collapse occurs, in which only image modes biased to a specific image type are augmented among various image forms. In this study, to solve the mode collapse caused by the learning difficulty mismatch between networks, we add a learning mode switching layer between the generator and discriminator and receive feedback from both networks’ transient learning accuracies to switch the learning mode if predefined thresholds are exceeded. We confirm that the proposed approach balanced the learning rate between the generator and discriminator networks, resolved the mode collapse problem, and increased the test accuracy of a deep CNN trained with an augmented image set by approximately 20.35% compared to a conventional DCGAN. In addition, it showed better accuracy on a performance comparison with other improved DCGAN methods."
3축 가속도 센서 스트림에 대한 유한차분 및 합성곱 신경망 기반의 뇌전증 발작 감지 기법,2021,"['딥러닝', '합성곱 신경망', '다변량 분석', '유한차분법', 'IoT', '스트림 데이터', 'Deep Learning', 'CNN', 'Multivariate Analysis', 'Finite Difference Method', 'IoT', 'Stream Data']","뇌전증은 발작을 동반하는 만성 뇌질환이다. 뇌전증 발작 감지에는 일반적으로 뇌파를 활용한다. 뇌전증 발작은 불규칙한 시점에 발생하며, 지속적일 경우 뇌손상 또는 사망에 이를 수 있는 응급 상황이다. 따라서 신속한 대처를 위한 일상생활 중 뇌전증 발작의 실시간 감지가 중요하다. 그러나 센서 민감도와 같은 기술적 한계로 인하여, 현재까지는 전문 장비를 갖춘 병원에서조차 정확한 뇌파의 측정이 어렵다. 또한, 실시간으로 뇌파를 측정할 수 있는 웨어러블 기기로의 상용화는 더욱 어려운 상황이다. 따라서 3축 가속도 센서 스트림 기반 동작 인식은 일상생활 중 실시간 뇌전증 발작 감지를 위한 현실적인 대안이다. 본 논문에서는 스마트폰, 스마트워치 등에 내장된 3축 가속도 센서 데이터에 대한 유한차분 및 합성곱 신경망 기반의 뇌전증 발작 감지 기법을 제안한다. 제안하는 기법은 뇌전증 발작의 의학적 특성에 근거하여, 유한차분을 통해 각 축 값의 변화율을 구하고, 합성곱 신경망 기반의 다변량 분석을 수행하여 각 축 값 변화율 간의 관계를 통합적으로 고려한다. 제안하는 기법은 걷기, 뛰기와 같은 대표 동작 외에도 양치질, 톱질 등 뇌전증 발작과 유사한 짧은 주기의 반복 동작을 포함한 17가지 일상 상황들로부터 99% 이상의 확률로 뇌전증 발작을 감지할 수 있음을 실험을 통해 확인하였다.","Epilepsy is a chronic brain disease causing repetitive seizures. Epileptic seizures occur irregularly and are emergency situations that can lead to brain damage or even death if happen continuously. Therefore, real-time detection of epileptic seizures is important for rapid treatment. However, due to some technical limitations like sensitivity of sensors, it is difficult to accurately measure EEG even in hospitals. Also, it is even more difficult to commercialize wearable devices. Therefore, human activity recognition on 3-axis accelerometer streams is a realistic alternative for real-time detection of epileptic seizures. In this paper, we propose a epileptic seizure detection method based on finite difference and CNN for 3-axis accelerometer streams measured from smart devices. The proposed method considers the medical characteristics of epileptic seizures to calculate the finite difference of each axis, and carries out multivariate analysis based on CNN to integratively consider the relationship between rate of changes of each. Our experiments show that our method can detect the epileptic seizures with a probability of more than 99% from 17 types of daily activities including repetitive activities in short cycles being thought to be similar to epileptic seizures such as brushing teeth and sawing besides typical movements like walking or running."
API Call 정보 기반의 안드로이드 악성코드 분류를 위한 특성 집합 추출,2021,"['API-Call', 'Feature Selection', 'Dimensionality Reduction', 'Malware Classification', 'CNN', '특성 선택', '차원 축소', '악성코드 분류']","악성코드를 포함한 모든 응용프로그램은 실행 시 API(Application Programming Interface)를 호출한다. 최근에는 이러한 특성을 활용하여 API Call 정보를 기반으로 악성코드를 탐지하고 분류하는 접근방법이 많은 관심을 받고 있다. 그러나 API Call 정보를 포함하는 데이터세트는 그 양이 방대하여 많은 계산 비용과 처리시간이 필요하다. 또한, 악성코드 분류에 큰 영향을 미치지 않는 정보들이 학습모델의 분류 정확도에 영향을 미칠 수도 있다. 이에 본 논문에서는 다양한 특성 선택(feature selection) 방법을 적용하여 API Call 정보에 대한 차원을 축소시킨 후, 핵심 특성 집합을 추출하는 방안을 제시한다. 실험은 최근 발표된 안드로이드 악성코드 데이터세트인 CICAndMal2020을 이용하였다. 다양한 특성 선택 방법으로 핵심 특성 집합을 추출한 후 CNN(Convolutional Neural Network)을 이용하여 안드로이드 악성코드 분류를 시도하고 결과를 분석하였다. 그 결과 특성 선택 알고리즘에 따라 선택되는 특성 집합이나 가중치 우선순위가 달라짐을 확인하였다. 그리고 이진분류의 경우 특성 집합을 전체 크기의 15% 크기로 줄이더라도 97% 수준의 정확도로 악성코드를 분류하였다. 다중분류의 경우에는 최대 8% 이하의 크기로 특성 집합을 줄이면서도 평균 83%의 정확도를 달성하였다.","All application programs, including malware, call the Application Programming Interface (API) upon execution. Recently, using those characteristics, attempts to detect and classify malware based on API Call information have been actively studied. However, datasets containing API Call information require a large amount of computational cost and processing time. In addition, information that does not significantly affect the classification of malware may affect the classification accuracy of the learning model. Therefore, in this paper, we propose a method of extracting a essential feature set after reducing the dimensionality of API Call information by applying various feature selection methods. We used CICAndMal2020, a recently announced Android malware dataset, for the experiment. After extracting the essential feature set through various feature selection methods, Android malware classification was conducted using CNN (Convolutional Neural Network) and the results were analyzed. The results showed that the selected feature set or weight priority varies according to the feature selection methods. And, in the case of binary classification, malware was classified with 97% accuracy even if the feature set was reduced to 15% of the total size. In the case of multiclass classification, an average accuracy of 83% was achieved while reducing the feature set to 8% of the total size."
Facial Recognition Using an Ensemble Model of Dimension Reduction Techniques and Convolutional Neural Networks,2021,"['Dimensionality Reduction', 'Face Recognition', 'Ensemble Model', 'PCA', 'LLE', 'CNN']","기술 트렌드가 증가함에 따라, 엄청난 양의 데이터가 생성되고 있습니다. 많은 양의 데이터가 소비되는 기술분야 중 하나는 컴퓨터 비전이다. 인간은 기계와 비교할 때 시각에 영향을 미치는 표정, 조명 또는 시야각과 같은 외부 조건에서도 얼굴이나 사물을 쉽게 감지하고 인식할 수 있다. 그 이유는 그것과 관련된 높은 차원의 데이터 때문이다. 데이터 차원성은 모든 관측치에서 측정되는 변수의 총 수를 말합니다. 이번 사업은 안면인식시스템에 적합한 다양한 차원감소 기법을 비교하고 조도가 다양한 안면이미지로 구성된 다양한 데이터세트로 테스트해 모델의 정확도 향상에 도움이 되는 기법의 앙상블 모델을 제안하고 성능을 측정하는 것이 목적이다.렉스 배경과 표현. 제안된 앙상블 모델은 주성분 분석(PCA)과 로컬 선형 임베딩(LLE)이라는 두가지 차원 감소 기술의 혼합에서 벡터를 추출하고, 이를 밀도 높은 컨볼루션 신경망(CNN)을 통해 전달하여 야생 면(LFW) 데이터 세트의 얼굴을 예측한다. 이 모형은 0.95의 검정 정확도와 0.94의 검정 F1 점수로 수행됩니다. 제안된 시스템은 시스템이 얼굴을 예측할 수 있는 제안된 앙상블 모델과 통합된 웹캠에서 라이브 비디오 스트림을 캡처하는 플라스크를 사용하여 개발된 웹 앱을 포함한다.","With increasing trends in technology, there is a huge volume of data that is being created. One field in technology in which high amount of data is consumed, is computer vision. Human beings are able to detect and recognize faces or objects with ease even with external conditions such as expressions, illuminations or viewing angle affecting the sight when compared to the machines. This is because of high dimensions of data associated with it. Data dimensionality is refered to as total number of variables being measured in every observation. This project aims to compare different applicable dimensionality reduction techniques suitable for facial recognition system and propose an ensemble model of such techniques that will help improving the accuracy of the model and gauge the performance by testing it with different datasets consisting of facial images with varying illuminations, complex backgrounds, and expressions. The proposed ensemble model extracts feature vectors from a hybrid of two dimensional reduction techniques - Principal Component Analysis (PCA) and Locally Linear Embedding (LLE), and pass them through dense Convolutional Neural Network (CNN) to predict faces on the Labelled Faces in the Wild (LFW) dataset. The model performs with a testing accuracy of 0.95 and a testing F1 score of 0.94. The proposed system involves a webapp developed using Flask that captures a live video stream from a webcam which is integrated with the proposed ensemble model that allows the system to predict the face."
Deep convolutional neural network: a novel approach for the detection of Aspergillus fungi via stereomicroscopy,2021,"['Aspergillus detection', 'conidiophore and colony morphology', 'stereomicroscopy/dissecting microscopy', 'convolutional neural network (CNN)', 'Xception']",국문 초록 정보 없음,"Fungi of the genus Aspergillus are ubiquitously distributed in nature, and some cause invasive aspergillosis (IA) infections in immunosuppressed individuals and contamination in agricultural products. Because microscopic observation and molecular detection of Aspergillus species represent the most operator-dependent and time-intensive activities, automated and cost-effective approaches are needed. To address this challenge, a deep convolutional neural network (CNN) was used to investigate the ability to classify various Aspergillus species. Using a dissecting microscopy (DM)/stereomicroscopy platform, colonies on plates were scanned with a 35× objective, generating images of sufficient resolution for classification. A total of 8,995 original colony images from seven Aspergillus species cultured in enrichment medium were gathered and autocut to generate 17,142 image crops as training and test datasets containing the typical representative morphology of conidiophores or colonies of each strain.Encouragingly, the Xception model exhibited a classification accuracy of 99.8% on the training image set. After training, our CNN model achieved a classification accuracy of 99.7% on the test image set. Based on the Xception performance during training and testing, this classification algorithm was further applied to recognize and validate a new set of raw images of these strains, showing a detection accuracy of 98.2%. Thus, our study demonstrated a novel concept for an artificial-intelligence-based and cost-effective detection methodology for Aspergillus organisms, which also has the potential to improve the public’s understanding of the fungal kingdom."
통합 이미지 처리 기술을 이용한 콘크리트 교량 균열 탐지 및 매핑,2021,"['concrete crack', 'deep learning', 'orthomosaic', 'drone', 'cascade mask R-CNN']",국문 초록 정보 없음,"In many developed countries, such as South Korea, efficiently maintaining the aging infrastructures is an important issue. Currently, inspectors visually inspect the infrastructure for maintenance needs, but this method is inefficient due to its high costs, long logistic times, and hazards to the inspectors. Thus, in this paper, a novel crack inspection approach for concrete bridges is proposed using integrated image processing techniques. The proposed approach consists of four steps: (1) training a deep learning model to automatically detect cracks on concrete bridges, (2) acquiring in-situ images using a drone, (3) generating orthomosaic images based on 3D modeling, and (4) detecting cracks on the orthmosaic image using the trained deep learning model. Cascade Mask R-CNN, a state-of-the-art instance segmentation deep learning model, was trained with 3235 crack images that included 2415 hard negative images. We selected the Tancheon overpass, located in Seoul, South Korea, as a testbed for the proposed approach, and we captured images of pier 34-37 and slab 34-36 using a commercial drone. Agisoft Metashape was utilized as a 3D model generation program to generate an orthomosaic of the captured images. We applied the proposed approach to four orthomosaic images that displayed the front, back, left, and right sides of pier 37. Using pixel-level precision referencing visual inspection of the captured images, we evaluated the trained Cascade Mask R-CNN's crack detection performance. At the coping of the front side of pier 37, the model obtained its best precision: 94.34%. It achieved an average precision of 72.93% for the orthomosaics of the four sides of the pier. The test results show that this proposed approach for crack detection can be a suitable alternative to the conventional visual inspection method."
합성곱신경망을 사용한 이미지 기반의 안드로이드 악성소프트웨어 패밀리 분류,2021,"['안드로이드 악성소프트웨어', '패밀리 분류', '회색조 이미지', '합성곱 신경망', '데이터 섹션', 'android malware', 'family classification', 'grayscale image', 'CNN', 'data section']","안드로이드 악성소프트웨어가 지속적으로 증가함에 따라, 기계학습을 사용한 안드로이드 악성소프트웨어 탐지 및 분류 기법이 많이 연구되고 있다. 악성소프트웨어 패밀리(malware family) 분류는, 악성소프트웨어 샘플들을 연관성 있는 그룹으로 분류하는 기법으로 컴퓨터 포렌식 분석, 위협 평가, 위협완화 계획에 중요한 역할을 한다. 본 논문에서는 실행파일 중의 일부를 회색조 이미지(grayscale image)로 변환한 후 변환된 영상들을 대상으로 딥러닝 기법을 적용하여 안드로이드 악성소프트웨어 패밀리를 분류하는 방법을 제안한다. 대표적인 안드로이드 악성소프트웨어 데이터 셋(dataset)인 Drebin에서 제공되는 악성소프트웨어 대표 패밀리들을 대상으로 합성곱신경망(Convolutional Neural Network, CNN) 모델을 적용하여 악성소프트웨어를 분류한다. 본 실험의 연구 결과를 기존 연구 결과와 비교하여, 데이터 경량화와 적절한 데이터 크기의 선정, 정확도에 있어 본 연구가 악성소프트웨어 분류에 더 효과적임을 보인다.","As Android malware continues to increase, Android malware detection and classification techniques using machine learning are being studied intensively. Malware family classification is a technique for classifying malware samples into related malware families and plays an important role in computer forensic analysis, threat assessment, and threat mitigation planning. In this paper, we propose a method to classify Android malware families by converting only part of an executable file into a gray scale image and applying deep learning to the converted images. The malware samples are classified from the representative families of the dataset from the Drebin project by applying the Convolutional Neural Network (CNN) model. The experimental results show that the proposed method is more effective in classifying malware families in terms of processing overhead and classification accuracy."
봇 넷 트래픽 식별을 위한 스택구조 딥러닝 접근 방식,2021,"['Botnet', 'Botnet Detection System', 'Deep Learning', 'Convolutional Neural Network', 'CTU-13 Dataset', '넷', '봇 넷 검출 시스템', '딥러닝', 'CTU-13 데이터 셋']","봇 넷의 악의적인 행위는 인터넷 서비스 제공자뿐만 아니라 기업, 정부, 그리고 심지어 가정의 일반 사용자에 이르기까지 엄청난 경제적 손실을 끼치고 있다. 본 논문에서는 CTU-13 봇 넷 트래픽 데이터 셋을 사용하여 딥러닝 모델 Convolutional Neural Network(CNN)을 적용한 봇 넷 트래픽 검출에 대한 가능성을 확인하고자한다. 특히 알려진 봇 넷과 알려지지 않은 봇 넷 트래픽에 대해 C&C 서버를 검출하기 위한 봇과 C&C 서버 사이 트래픽, 봇을 검출하기 위한 C&C 통신 이외에 봇이 발생하는 트래픽, 그리고 정상 트래픽을 분류하는 멀티클래스 분류(multi-class classification)를 시도하였다. 성능검증을 위한 지표는 정확도, 정밀도, 재현율, 그리고 F1 점수를 제시하였다. 한편 확장성과 운영을 고려하여 봇 넷 타입 별로 모듈을 적재할 수 있는 스택구조의 봇 넷 검출 시스템을 제안함으로써 실제 네트워크의 적용 가능성을 제시하였다.","Malicious activities of Botnets are responsible for huge financial losses to Internet Service Providers, companies, governments and even home users. In this paper, we try to confirm the possibility of detecting botnet traffic by applying the deep learning model Convolutional Neural Network (CNN) using the CTU-13 botnet traffic dataset. In particular, we classify three classes, such as the C&C traffic between bots and C&C servers to detect C&C servers, traffic generated by bots other than C&C communication to detect bots, and normal traffic. Performance metrics were presented by accuracy, precision, recall, and F1 score on classifying both known and unknown botnet traffic. Moreover, we propose a stackable botnet detection system that can load modules for each botnet type considering scalability and operability on the real field."
맞대기 V형 그루브의 GMA 초층용접에서 합성곱 신경망을 이용한 이면비드 발생 예측 모델 개발,2021,"['Gas metal arc welding (GMAW)', 'V-Groove', 'Back-bead', 'Root pass', 'Full penetration', 'Deep learning', 'Convolutional neural network (CNN)', 'Laser vision']",국문 초록 정보 없음,"Gas metal arc (GMA) welding is widely used in the machinery industry. The quality of a welded joint is affected by the penetration of root pass welding in the V-groove joint. Automation using GMA welding is continuously required, and root pass welding automation is required to automate the entire welding process. In particular, the development of a prediction model that can ensure full penetration back-bead is required for the automation of root pass welding. In this study, a convolutional neural network (CNN) model was applied to predict the occurrence of back-bead in V-groove butt joint GMA root pass welding. The bead profile was measured using a laser vision sensor system and it was used as the input data for the prediction model, and the bead occurrence was used as the output data for the model. A total of 12,873 bead profiles were extracted and pre-processed through cutting, resizing, and thresholding. The CNN model consists of nine layers, and performs three convolution and two pooling operations. The accuracy of the prediction model was 99.5%, and through this study, it was demonstrated that the quality of root-pass welding can be controlled by using convolutional neural network and it can contribute to automation."
드론 촬영 정사영상을 이용한 합성곱 신경망 딥러닝 알고리즘 기반 콘크리트 균열 자동평가 시스템,2021,"['딥러닝', '합성곱 신경망', '정사영상', '드론', '콘크리트 균열', '균열 탐지', '균열 평가', 'Deep Learning', 'CNN', 'Orthomosaic', 'Ortho Facade', 'UAV', 'Drone', 'Concrete Crack', 'Crack Detection']",국문 초록 정보 없음,"Cracks in concrete structure can lead to major structure failure if not noticed correctly at the right time. Various methods have been studied to detect concrete cracks due to the disadvantage of existing visual inspection. As the fourth industrial revolution has also affected the construction industry, concrete crack detection technologies using fields such as drones and AI are also developing. Vision recognition-based systems still have limitations such as identifying the location of cracks. This study proposes an efficient method of automatically detecting concrete cracks by using Convolutional Neural Network(CNN) with the Orthomosaic image, modeled with the help of UAV. The CNN model was developed and trained from combination of open source and original images."
작은 물체 검출을 위한 딥러닝 네트워크 구조,2021,"['Object Detection(객체 검출)', 'Deep Learning(딥러닝)', 'Autonomous Driving(자율 주행)', 'Multi-object detection(다중 객체 검출)', 'CNN(Convolutional Neural Network)']",국문 초록 정보 없음,"Object detection algorithms are tasks that simultaneously perform classification localization of objects present within an image when the input image is maintained. These object detection algorithms have recently resulted in significant performance gains with the appearance of CNN(Convolution Neural Network). Following this tremendous development, it has recently begun to be used in the field of autonomous driving, and studies of object detection algorithms using CNN and deep learning networks are actively underway. Among these deep learning algorithms, this paper uses deep learning networks that do not use predefined bounding boxes using single-step object detection algorithms. In this paper, we describe the deep learning network structure used in object detection algorithms, analyze the shortcomings of these object detection algorithms, which are vulnerable to small object detection, and propose a new deep learning network structure to identify them."
뇌파를 활용한 IoT기반 스마트홈 시스템 구현,2021,"['스마트홈', '사물인터넷', '뇌-컴퓨터 인터페이스', '뇌파', '딥러닝', '합성곱신경망', 'Smart Home', 'Internet of Things (IoT)', 'Brain-Computer Interface (BCI)', 'Electroencephalography (EEG)', 'Deep learning', 'Convolutional Neural Network (CNN)']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝을 이용한 풍력 발전량 예측,2021,"['풍력발전', '예측', '머신 러닝', '다중 퍼셉트론', '재귀 신경망', '중기 단기 기억', '인공지능', '전력량', 'Wind power', 'prediction', 'LSTM(:Long short term memory)', 'CNN(:Cellular neural network)', 'Artificial intelligence']","본 연구는 풍력발전의 합리적인 운영 계획과 에너지 저장창치의 용량산정을 위한 풍력 발전량을 예측한다. 예측을 위해 물리적 접근법과 통계적 접근법을 결합하여 풍력 발전량의 예측 방법을 제시하고 풍력 발전의 요인을 분석하여 변수를 선정한다. 선정된 변수들의 과거 데이터를 수집하여 딥러닝을 이용해 풍력 발전량을 예측한다. 사용된 모델은 Bidirectional LSTM(:Long short term memory)과 CNN(:Convolution neural network) 알고리즘을 결합한 하이브리드 모델을 구성하였으며, 예측 성능 비교를 위해 MLP 알고리즘으로 이루어진 모델과 오차를 비교하여, 예측 성능을 평가하고 그 결과를 제시한다.","This study predicts the amount of wind power generation for rational operation plan of wind power generation and capacity calculation of ESS. For forecasting, we present a method of predicting wind power generation by combining a physical approach and a statistical approach. The factors of wind power generation are analyzed and variables are selected. By collecting historical data of the selected variables, the amount of wind power generation is predicted using deep learning. The model used is a hybrid model that combines a bidirectional long short term memory (LSTM) and a convolution neural network (CNN) algorithm. To compare the prediction performance, this model is compared with the model and the error which consist of the MLP(:Multi Layer Perceptron) algorithm, The results is presented to evaluate the prediction performance."
HNS 해양배출 영상학적 현상 연구,2021,"['hazardous and noxious substances (HNS)', 'optical image', 'global background suppression (GBS)', 'adaptive target enhancement (ATE)', 'deep learning', 'faster regions with convolutional neuron networks features (R-CNN)']","본 논문은 바다 혹은 강에 부유하는 위험 유해 물질 (HNS)의 탐지에 대한 논문들을 리뷰한다. 실시간 유출 사고 모니터링을 위해 HNS 유출의 자동 분류가 시급한 과제로 떠오르고 있다. 주요한 어려운 문제 중 하나는 가시 스펙트럼에서 벤젠, 자일렌, 팜유와 같은 투명한 HNS를 감지하는 것이다. 감지가 불가능한 투명 HNS를 인식하기 위해 최근 연구에서는 자외선(UV) 영상, 블루 채널 영상, RGB 영상 등 다양한 광학 영상을 활용하려고 시도하고 있다. 이러한 연구들은 대상의 반사율을 사용하는 레이더 이미지 대신 광학 이미지로 감지할 수 있는 석유와 탄화수소 화학 물질의 광학 특성 및 화학적 특성을 이용하려고 한다. 보다 정확한 HNS 탐지를 위해 GBS(Global Background Suppression) 및 ATE(Adaptive Target Enhancement)와 같은 배경 복잡성 감소 알고리즘을 제안하여 태양 빛 반사, 물결, 선박이나 구름의 그림자와 같은 불필요한 물체를 제거한다. 또한, 결과 이미지 내에서 HNS로 추정되는 대상을 추출하기 위해 여러 딥 러닝 기반 식별 방법이 제안되었다. 특히, faster R-CNN(regions with convolutional neuron network) 아키텍처 기반 HNS 탐지 알고리즘은 시간 복잡도 및 HNS 감지 정확도 측면에서 기존 이미지 분할 방법보다 성능이 우수한 것으로 입증되었다.","This paper presents a comprehensive literature review on the detection of hazardous and noxious substances (HNS) floating on sea or river surface. For real-time spill accident monitoring, an autonomous detection of HNS spills has been emerging as an urgent challenge. One of the main difficulty is to detect transparent HNS, such as benzene, xylene, and palm oil, in the visible spectrum. To recognize undetectable and transparent HNS, recent studies have attempted to utilize various optical images including ultraviolet (UV) images, blue channel images, and RGB images. Unlike the conventional imaging radar using the target’s reflectivity, recent researches try to exploit the optical characteristics and chemical properties of oil and hydrocarbon chemicals, which can be detected by optical images. For more accurate HNS detection, background complexity reduction algorithms, such as global background suppression (GBS) and adaptive target enhancement (ATE), have been proposed to reject redundant objects, including sun reflection, the flow of water, and the shadow of ships or clouds. Subsequently, several deep learning-based identification methods have been proposed to accurately detect HNS from background-complexity-reduced images. Specifically, faster regions with convolutional neuron networks (R-CNN) architecture-based HNS detection algorithms have been confirmed to outperform the conventional image segmentation methods in terms of time-complexity and HNS detection accuracy."
Wood Classification of Japanese Fagaceae using Partial Sample Area and Convolutional Neural Networks,2021,"['wood', 'microscopic image', 'sample selection', 'classification', 'convolutional neural network']",국문 초록 정보 없음,"Wood identification is regularly performed by observing the wood anatomy, such as colour, texture, fibre direction, and other characteristics. The manual process, however, could be time consuming, especially when identification work is required at high quantity. Considering this condition, a convolutional neural networks (CNN)-based program is applied to improve the image classification results. The research focuses on the algorithm accuracy and efficiency in dealing with the dataset limitations. For this, it is proposed to do the sample selection process or only take a small portion of the existing image. Still, it can be expected to represent the overall picture to maintain and improve the generalisation capabilities of the CNN method in the classification stages. The experiments yielded an incredible F1 score average up to 93.4% for medium sample area sizes (200 × 200 pixels) on each CNN architecture (VGG16, ResNet50, MobileNet, DenseNet121, and Xception based). Whereas DenseNet121-based architecture was found to be the best architecture in maintaining the generalisation of its model for each sample area size (100, 200, and 300 pixels). The experimental results showed that the proposed algorithm can be an accurate and reliable solution."
심장 소리 분류를 위한 Inverted Residuals 기반 경량화 모델,2021,"['Heart Sound Classification', 'Inverted Residuals', 'Lightweight Model Architecture', 'PASCAL Classifying Heart Sounds Challenge']",국문 초록 정보 없음,"For the treatment and prevention of heart diseases, which is the leading cause of high mortality rate globally, the need for healthcare devices equipped with artificial intelligence(AI) model that can monitor in real-time and analyze heart conditions is increasing. Therefore, in this study, we propose a light CNN that can be applied to healthcare devices, using the PASCAL data. The proposed model used MFCC feature extraction method suitable for heart sound range, The light CNN was designed with the inverted residuals used in MobileNetV2. The experiments showed that the proposed model with fewer 82.5% of the learnable parameters, achieved similar performance in accuracy within the range of 1 to 2% compared to the previous studies. It was confirmed that the proposed light CNN can be feasibly incorporated on mobile devices by means of comparative experiments in a reasonable amount of computation."
신용 데이터의 이미지 변환을 활용한 합성곱 신경망과 설명 가능한 인공지능(XAI)을 이용한 개인신용평가,2021,"['Convolutional Neural Networks', 'eXplainable Artificial Inteligence', 'Deep learning', 'Imaged data', 'Personal credit rating']",국문 초록 정보 없음,"PurposeThe purpose of this study is to enhance the accuracy score of personal credit scoring using the convolutional neural networks and secure the transparency of the deep learning model using eXplainalbe Artifical Inteligence(XAI) technique.Design/methodology/approachThis study built a classification model by using the convolutional neural networks(CNN) and applied a methodology that is transformation of numerical data to imaged data to apply CNN on personal credit data. Then layer-wise relevance propagation(LRP) was applied to model we constructed to find what variables are more influenced to the output value.FindingsAccording to the empirical analysis result, this study confirmed that accuracy score by model using CNN is highest among other models using logistic regression, neural networks, and support vector machines. In addition, With the LRP that is one of the technique of XAI, variables that have a great influence on calculating the output value for each observation could be found."
Food Detection by Fine-Tuning Pre-trained Convolutional Neural Network Using Noisy Labels,2021,"['deep learning', 'food image detection', 'symmetric label noise', 'convolutional neural networks', 'transfer learning']",국문 초록 정보 없음,"Deep learning is an advanced technology for large-scale data analysis, with numerous promising cases like image processing, object detection and significantly more. It becomes customarily to use transfer learning and fine-tune a pre-trained CNN model for most image recognition tasks. Having people taking photos and tag themselves provides a valuable resource of in-data. However, these tags and labels might be noisy as people who annotate these images might not be experts. This paper aims to explore the impact of noisy labels on fine-tuning pre-trained CNN models. Such effect is measured on a food recognition task using Food101 as a benchmark. Four pre-trained CNN models are included in this study: InceptionV3, VGG19, MobileNetV2 and DenseNet121. Symmetric label noise will be added with different ratios. In all cases, models based on DenseNet121 outperformed the other models. When noisy labels were introduced to the data, the performance of all models degraded almost linearly with the amount of added noise."
딥네트워크 기반 음성 감정인식 기술 동향,2021,"['Affective computing', 'deep learning', 'convolutional neural networks', 'machine learning', 'speech recognition']",국문 초록 정보 없음,"In the latest eras, there has been a significant amount of development and research is done on the usage of Deep Learning (DL) for speech emotion recognition (SER) based on Convolutional Neural Network (CNN). These techniques are usually focused on utilizing CNN for an application associated with emotion recognition. Moreover, numerous mechanisms are deliberated that is based on deep learning, meanwhile, it’s important in the SER-based human-computer interaction (HCI) applications. Associating with other methods, the methods created by DL are presenting quite motivating results in many fields including automatic speech recognition. Hence, it appeals to a lot of studies and investigations. In this article, a review with evaluations is illustrated on the improvements that happened in the SER domain though likewise arguing the existing studies that are existence SER based on DL and CNN methods."
와이어-아크 적층제조 공정의 비드 결함 감지를 위한 기계학습 모델,2021,"['Convolutional neural network', 'Feature extraction', 'Machine learning', 'Multi-layer perceptron', 'Voltage signature data', 'Weld beads', 'Wire-arc additive manufacturing']",국문 초록 정보 없음,"In the wire-arc additive manufacturing (WAAM) process, which creates metal layers with weld beads, it is important to detect weld bead defects and resolve them properly and timely. In this paper, we propose a machine learning approach for automatically detecting weld bead defects based on voltage signature data captured during the WAAM process. We adopt multi-layer perceptron (MLP) and convolutional neural network (CNN) as machine learning models, and consider three types of beads: normal bead, abnormal bead with balling effects, and abnormal bead with cuts. After capturing voltage signatures while building weld beads, we separated each voltage signature into 17 to 19 segments, from each of which a set of features are extracted. We then constructed training and test data with feature datasets. We built total 75 voltage signatures: 45 for normal beads, 15 for abnormal beads with balling effects, and 15 for abnormal beads with cuts. After training the MLP and CNN models using TensorFlow, we tested and compared their performance. We found that the two types of models works well even though the amount of data used is small, but the CNN models are more appropriate for real-time detection of weld bead defects."
딥러닝 전이학습의 가능성 검토: 부동산 분야를 사례로,2021,"['딥러닝', '전이학습', '신경망 모형', '부동산', '은닉층', 'Deep Learning', 'Transfer Learning', 'Neural Network', 'Real Estate', 'Hidden Layer']",국문 초록 정보 없음,"It is generally not a good idea to train a deep learning algorithm from scratch because it demands significantly large amount of data. Transfer learning technique is exploited in this study to overcome a sparse data problem in real estate industry. A dense neural network (DNN) is a universal algorithm to process structured data, and was utilized to estimate property price. In this case, the transfer learning did not show acceptable performance. In addition, a convolutional neural network (CNN), an algorithm specialized for unstructured data such as imagery data, was employed to classify a building usage based on the front-view of photographs collected. It was found that the transfer learning of CNN worked relatively well in image classification tasks. For structured data, the poor performance of the DNN could be attributed to the inefficiency of hidden layers and insufficient number of hidden layers used. In contrast, this study attributed excellent performance of the CNN to the efficiency of convolutional layers, and sufficient number of hidden layers used (50 layers)."
이미지 데이터에 대한 비선형 분류 방법의 비교,2021,"['지지벡터기계', '지지행렬기계', '커널', '합성곱 신경망', 'Convolutional neural network', 'kernel', 'support matrix machine', 'support vector machine']","이미지 분류는 기계학습에서 가장 활발하게 연구되고 있는 주제 중 하나이다. 이미지 데이터는 일반적으로 2차원 혹은 3차원 행렬 구조를 가지고 있으며, 지지벡터기계 등 전통적인 분류 기법을 적용하기 위해 벡터화를 시행하게 된다. 하지만 벡터화는 이미지 데이터가 제공하는 구조적 정보를 무시할 수 있다. 구조적 정보를 이용하는 합성곱 신경망은 이러한 단점을 보완하기 위해 도입되었으나, 합성곱 신경망을 포함하는 신경망은 일반적으로 많은 데이터를 요구한다. 반면 지지벡터기계는 적은 수의 표본에서도 상대적으로 안정적인 분류 성능을 보일 뿐만 아니라 지지행렬기계 및 커널 지지행렬기계로 확장됨으로써 이미지 데이터의 구조적 정보도 반영할 수 있게 되었다. 본 논문에서는 표본의 개수가 상대적으로 적은 이미지 데이터에 대하여 비선형 분류 방법인 지지벡터기계, 커널 지지행렬기계, 그리고 합성곱 신경망의 예측 성능을 비교하고 선형 분류 방법이지만 이미지 데이터의 구조적 정보를 반영하는 지지행렬기계도 함께 비교한다.","Image classification is one of the most actively studied topics in machine learning. Image data generally has a two-dimensional or three-dimensional matrix structure, and vectorization is performed to apply traditional classification techniques such as support vector machine (SVM). However, vectorization may ignore the structural information provided by image data. Convolutional neural network (CNN) using structural information has been introduced as a remedy to the drawback, but neural networks including CNN generally require a lot of data. On the other hand, SVM shows stable classification performances even with a small number of samples, and extensions of SVM reflecting structural information such as support matrix machine (SMM) and kernel support matrix machine (KSMM) have been recently proposed. In this paper, we compare the predictive performances of SVM, SMM, KSMM, and CNN on image data with relatively small number of samples."
Multi Label Deep Learning classification approach for False Data Injection Attacks in Smart Grid,2021,"['Deep learning', 'False Data Injection Attack', 'Internet of Things', 'Machine learning', 'Multi-label Classification', 'Power System', 'Smart grid']",국문 초록 정보 없음,"The smart grid replaces the traditional power structure with information inventiveness that contributes to a new physical structure. In such a field, malicious information injection can potentially lead to extreme results. Incorrect, FDI attacks will never be identified by typical residual techniques for false data identification. Most of the work on the detection of FDI attacks is based on the linearized power system model DC and does not detect attacks from the AC model. Also, the overwhelming majority of current FDIA recognition approaches focus on FDIA, whilst significant injection location data cannot be achieved. Building on the continuous developments in deep learning, we propose a Deep Learning based Locational Detection technique to continuously recognize the specific areas of FDIA. In the development area solver gap happiness is a False Data Detector (FDD) that incorporates a Convolutional Neural Network (CNN). The FDD is established enough to catch the fake information. As a multi-label classifier, the following CNN is utilized to evaluate the irregularity and cooccurrence dependency of power flow calculations due to the possible attacks. There are no earlier statistical assumptions in the architecture proposed, as they are ""model-free."" It is also ""cost-accommodating"" since it does not alter the current FDD framework and it is only several microseconds on a household computer during the identification procedure. We have shown that ANN-MLP, SVM-RBF, and CNN can conduct locational detection under different noise and attack circumstances through broad experience in IEEE 14, 30, 57, and 118 bus systems. Moreover, the multi-name classification method used successfully improves the precision of the present identification."
디지털 시추코어 이미지로부터 정밀 암상 분류를 위한 컨볼루션 오토인코더의 활용,2021,[],"시추 코어 이미지 자료는 지하 내부 퇴적 구조, 지층 경계 및 암상을 보다 상세하게 파악 할 수 있는 방법이다. 시추코어로부터 암상 구분을 위해서는 로깅이 이루어져야 하나 많은 시간이 걸릴 뿐 아니라 작업자의 주관적인 판단으로 결정된다. 따라서 본 연구에서는 객관적이면서 자동으로 보다 정밀한 종류의 암상을 분류할 수 있는 방법을 제안하였으며, 이를 위해 기계학습의 일종인 Convolutional Autoencoder (CAE)가 적용되었다. CAE는 입력과 출력 데이터 모두 같은 이미지를 사용하는 비지도 학습(unsupervised learning)이며, 이미지의 노이즈 제거와 차원 축소에 많이 사용된다. 특히, 기존의 Stacked Autoencoder와 달리 Convolution 연산을 통해 이미지의 특징을 적절하게 보존하여 이미지 분석 시에는 큰 장점이 있다. 본 연구에서는 CAE의 암상 특징 추출 및 분류에의 적용성을 평가하기 위해서 호주 Northern Carnarvon 분지의 Satyr-5 시추공에서 획득한 실제 코어 이미지를 활용하였다. 확보된 시추코어는 sand, shale, shaly sand, fracture가 포함된 sand로 구성되어있다. 따라서 CAE를 이용하여 4가지 암상의 특성을 학습하였다. 이때, 이용된 시추코어 자료는 총 90 m로 CAE 네트워크를 학습하기 충분하지 않아 기존 자료에 대한 자료증폭(data augmentation)을 실시하였으며, 이를 통해 16,000개(10 cm 로깅한 자료의 18배)의 자료를 확보 및 학습에 이용하였다. CAE의 특징 추출 성능을 이미지의 기본 특성값(예, RGB 채널, 로컬 엔트로피 평균 값 등)을 이용한 모델 및 CNN 기반 특징 추출 모델과 비교 검증하였다. CNN 기반 모델을 이용한 결과의 정확도는 87%, 이미지 기본 특성값에 기반한 모델 결과의 정확도는 81%로 나타났다. 반면, CAE를 이용한 모델 결과는 90%의 예측 정확도를 보여주었다. 추가적으로 CAE 기반 특징 추출 모델의 입력자료로 Canny Edge Detection 적용 결과를 추가 적용하였으며, 이의 결과는 88%의 예측 성능을 보여주었다. 결과를 종합하였을 때, CAE 기반의 네트워크가 입력되는 이미지에 대한 추가적인 전처리 과정 없이, 암상의 분류 특징을 가장 정밀하게 추출하는 것으로 판단된다. 또한, 본 연구에서 적용된 방법은 이미지 자료에 주로 활용되는 CNN 기법을 적용하는 것보다 전산 연산량이 낮아 시간 및 비용 효율적인 측면에서도 활용성이 높을 것으로 기대된다.",다국어 초록 정보 없음
基于语料库的美国媒体报道台湾问题的批判性话语分析,2021,"['CDA', 'Corpus Linguistics', 'American media', 'Taiwan issues', 'SGF', 'Ideological meanings']",국문 초록 정보 없음,"This research is a corpus-based critical discourse analysis of the U.S. news reporting on the Taiwan issues, with the objects as follows: 1) to explore the prospect of the application of Corpus Linguistics into CDA; 2) to analyze the underlying ideological meanings of the Taiwan issues in different American media; 3) to demonstrate the dialectical relationship between discourse and ideology as proved by this issue. From a critical perspective, this paper analyzes online news discourse in terms of Taiwan issues in three U.S. news websites. All the works the author offered in this paper are concerning on two questions: 1) What ideological meanings can be identified in the application of linguistic strategies? 2) Is there a stereotyped discourse model featuring the political news reports regarding the Taiwan issues in the American news websites? If there is, what are the common characteristics? If there is not, what characteristics displayed respectively? In this paper, the author follows the guideline of building three mini-corpora with the data extracted from three U.S. online news texts on the Taiwan issues during a certain period of time. It should be noted that the chosen texts need to be ensured as clean texts. Considering the integrity, reputation, the public influence of the news agency, and the depth and breadth of their coverage of the issue, the author chooses the time span as 2020 to March, 2021. And the three official websites are:  http://edition.cnn.com/ -- CNN;  http://www.nytimes.com/  -- NYT; http://www.washingtonpost.com/ -- WPC. With regard of the news reporting foci and density, the author extracts the texts in terms of politics on Taiwan issues rather than selecting all the news texts. As it raises the problem that the raw corpora are not suitable for analysis, the corpus tool Gotagger will be applied to tag the data. The tagged data will be put separately for various investigating objects. And the Oxford WordSmith Tool V4 will be applied to generate the keyword list and extract the concordance lines for analysis. From the foregoing investigation, it is clearly that CL can help the CDA in many aspects. Of course, there are many points of its role left for further analysis. It opens a door for linguistic researchers to apply CL into CDA. Firstly, the key wordlists and the concordance lines of specific search words give a good starting point for thematic analysis. It can be seen that a complete lexical and semantic network is summarized by this means. Secondly, taking the corpus-based approach with the help of functional grammar can form a better semantic analytical model – word driven pattern – to consider chunks and sentences as the analytical units, and then the paragraphs or even the whole text as reference contexts. Once taken this method, it is much easier to carry on the quantitative and qualitative, macro- and micro-level analysis simultaneously. Among different U.S. news websites, there is not a consistent discourse model on the Taiwan issues. Indeed, the three American news agencies have their own characteristics: CNN enjoys the most heterogeneous lexical choices for conveying the ideological meanings; and it likes to express the interpersonal meanings. While NYT and WPC tend to be more homogeneous in lexical choices, and their reporting tones are more neutral as well. In addition, more speaking rights are given to various distinguishing communities and groups for constructing interpersonal meanings. All in all, with the help of different linguistic devices, CDA gains a site for power struggle among different governments, parties, and communities concerns. Thus the dialectical relationship between language and ideology can be preserved."
고장 진단을 이용한 원심 혈액 펌프 내부 혈전 진단,2021,"['Centrifugal blood pump(원심성 혈액 펌프)', 'Fault diagnosis(고장 진단)', 'Thrombus(혈전)', 'Condition indicator(상태지표)', 'Kurtosis(첨도)', 'Convolutional neural network(합성곱 신경망)']","원심 혈액 펌프 내부에서 발생하는 혈전은 의료진의 육안 검사에 의존하며, 이에 대응이 어렵다. 이런 문제를 해결하기 위해 펌프에서 발생하는 진동을 이용하여 혈전을 진단하는 연구들이 있다. 본 연구에서는 결함진단에서 사용하는 다양한 상태지표를 적용 및 합성곱 신경망을 적용하여 정확도를 향상시킬 수 있는지 분석한다. 방법: 혈전 모델과 모의 시스템을 사용하여 체외 테스트를 수행했다. 3 차원 프린터와 실리콘을 사용하여 다양한 모양과 크기의 혈전 모델을 제작했다. 제작한 모델을 펌프헤드에 넣고, 기계를 작동시켰으며, 이 때 발생하는 진동을 가속도 센서로 측정했다. 측정한 데이터에 첨도를 매개변수로 서포트 벡터 머신을 수행했다. 그리고 단시간 퓨리에 변환을 적용하여 신호를 이미지로 변환하고 합성곱 신경망을 수행했다. 성능평가를 위해 이전 논문에서 제안한 세번째 고조파를 매개 변수로 서포트 벡터 머신을 실시했고, 결과를 비교했다. 결과: 첨도를 이용한 서포트 벡터 머신/합성곱 신경망/세번째 고조파를 이용한 서포트 벡터 머신 (기존 연구에서 제안) 정확도: 95.0/98.8/ 83.3. 결론: 원심 혈액 펌프 내부 혈전 진단에 결함 진단을 적용하여 정확도를 향상했다. 이를 통해 혈액 펌프의 고장을 조기에 식별하여 환자의 생존 능력을 향상시킬 수 있다.","The thrombus that occur inside the centrifugal blood pump relies on a visual examination by a medical staff, and it is difficult to respond. To solve the problem, there are studies that diagnose the thrombus using vibration generated by the pump. In this study, we analyze whether the accuracy can be improved by applying various state indicators used in fault diagnosis and applying a convolutional neural network (CNN). Methods: An in-vitro test was conducted using thrombus models and a mock system. Thrombus models of various shapes and sizes were produced using a three-dimensional (3D) printer and silicones. The model was placed in the pump head, the machine was operated, and the vibration generated was measured with an acceleration sensor. The support vector machine (SVM) was performed using kurtosis as a parameter. In addition, the signal was transformed into red-green-blue (RGB) images by applying Short Time Fourier Transform (STFT) and the CNN was performed. For performance evaluation, SVM was performed using the 3<sup>rd</sup> harmonic proposed in the previous paper as a parameter, and the results were compared. Results: accuracy of the SVM using kurtosis / CNN / SVM using 3<sup>rd</sup> harmonics (suggested in previous work): 95.0 / 98.8 / 83.3. Conclusion: Accuracy was improved as a result of applying fault diagnosis to diagnosing thrombus inside a centrifugal blood pump. This allows early identification of failures in the blood pump to improve patient viability."
Implementation of Low-cost Autonomous Car for Lane Recognition and Keeping based on Deep Neural Network model,2021,"['Deep Neural Network', 'Low cost', 'Autonomous car', 'Lane detection', 'Lane Keeping']",국문 초록 정보 없음,"CNN (Convolutional Neural Network), a type of deep learning algorithm, is a type of artificial neural network used to analyze visual images. In deep learning, it is classified as a deep neural network and is most commonly used for visual image analysis. Accordingly, an AI autonomous driving model was constructed through real-time image processing, and a crosswalk image of a road was used as an obstacle. In this paper, we proposed a low-cost model that can actually implement autonomous driving based on the CNN model. The most well-known deep neural network technique for autonomous driving is investigated and an end-to-end model is applied. In particular, it was shown that training and self-driving on a simulated road is possible through a practical approach to realizing lane detection and keeping"
뇌 MRI 분할을 위한 잔류 컨볼루션 기반의 압착 U-SegNet 아키텍처,2021,"['CNN', '뇌 조직', '분할', 'CNN', 'Brain tissues', 'Segmentation']","본 논문에서는 U-SegNet 을 화재 모듈 및 잔류 컨볼루션과 통합하여 자기 공명 영상(MRI)으로 뇌 조직을 분할하여 U-SegNet 모델을 개선한다. 제안된 인코더-디코더 방법에서, 잔류 연결뿐만 아니라 화재 모듈의 압착 및 확장 컨볼루션 레이어는 뇌 MRI 분할을 위한 더 가볍고 더 효율적인 아키텍처로 이어진다. 잔류 단위는 심층 아키텍처의 원활한 훈련에 도움이 되며, 잔류 컨볼루션 계층에서 얻은 특징은 분할 네트워크에서 더 나은 특징 표현을 보장한다. 또한 더 적은 수의 네트워크 매개 변수로 설계를 보다 효율적으로 만들고 뇌MRI 에 더 나은 분할 정확도를 제공한다. 제안된 아키텍처는 뇌 조직 분할을 위해 공개적으로 이용 가능한 OASIS 데이터 세트에서 평가된다. 제안된 방법의 실험 결과는 주사위 유사도 계수(DSC) 점수가 0.96 이고 자카드 지수(JI)가 0.92 인 뇌 MRI 분할에 대한 기존 방법보다 우수한 성능을 보여준다.","In this paper, we propose an improved U-SegNet model by integrating U-SegNet with fire modules and residual convolutions to segment brain tissues in a magnetic resonance image (MRI). In the proposed encoder-decoder method, the residual connections, as well as squeeze, and expand convolutional layers from the fire module, lead to lighter and more efficient architecture for brain MRI segmentation. The residual unit helps in the smooth training of the deep architecture, and features obtained from residual convolutional layers ensure better feature representation in the segmentation network. It also makes the design more efficient architecture with a fewer number of network parameters and provides better segmentation accuracy for brain MRI. The proposed architecture is evaluated on a publicly available OASIS dataset for brain tissue segmentation. The experimental results of the proposed method exhibit superior performances to conventionalmethods on brain MRI segmentation with a dice similarity coefficient (DSC) score of 0.96 and Jaccard index (JI) of 0.92."
자율주행용 임베디드 플랫폼 탑재를 위한 YOLOv4 기반 객체탐지 경량화 모델 개발,2021,"['Compressed CNN(경량화 CNN 모델)', 'Compressed object detection(경량화 객체탐지)', 'Autonomous driving(자율주행)', 'Embedded GPU(임베디드 GPU)', 'YOLOv4']",국문 초록 정보 없음,다국어 초록 정보 없음
식물의 질병 예측 및 감지를 통한 솔루션 제공 시스템,2021,"['딥러닝', 'CNN', '환경 감지', '영상 처리', 'Raspberry Pi']","국내 농업은 4차 산업혁명 기술 적용으로 더욱 발전하고 있다. 4차 산업혁명 기술은 농업환경의 식물 생장 데이터를 실시간 수집하고, 효율적인 데이터의 가공을 통해 작업자에게 효과적인 정보 제공이 가능하게 한다. 정밀하고 효과적인 알고리즘과 새로운 기술을 도입함으로써 기존의 인력 의존적인 문제점을 효율적으로 개선하고 보완하여 현재 농업환경을 발전시키는 것에 의미가 있다. 따라서 본 연구에서는 농업환경에서 설치된 카메라와 환경 센서를 통해 식물의 질병 발생률을 예측하고, 발생한 식물의 질병을 감지하며 적절한 솔루션을 제공하는 시스템을 개발하는 것이 목적이다. 개발 사양은 CPU: Intel i9-10900k 5.0ghz, RAM: 64gb이며, 개발환경은 Python 3.9, Android 9.0을 사용하였다. 환경 센서는 Arduino, Raspberry Pi를 사용하였으며 전원은 외부에서 공급하였다. 카메라는 Raspberry Pi High Quality Camera를 이용하였다. 딥러닝을 이용한 식물의 질병 예측 및 감지 알고리즘은 CNN 모델의 결과와 환경 감지 모델의 결과를 결합하고, 가중치를 통해 식물의 질병을 예측 및 감지하였다. 학습에 필요한 식물의 질병 데이터는 AI Hub에 위치한 식물 시설 작물 질병 진단 이미지를 이용하였고, 환경 감지 모델의 기반 데이터는 NCPMS를 참조하였다. 환경 데이터 수집은 설치된 Raspberry Pi가 Sensor를 통해 수집하였으며, 실시간으로 HTTP 통신 방식을 이용하여 시스템 서버에 전송하여 데이터를 분석하였다. 작업자 제공 인터페이스는 스마트 단말기를 이용한 안드로이드 애플리케이션을 사용하였고, 작업자의 신원을 확인하는 단계를 거쳐 설치되어 있는 농가의 질병 발생확률, 발생한 질병을 시각적으로 확인할 수 있도록 하였다. 또한 농가에 질병이 발생했을 때 발생 질병에 맞는 솔루션을 제공 받을 수 있도록 하였다. 해당 시스템 구축 결과는 테스트 이미지와 환경데이터를 이용한 예측 및 감지 시에는 평균적으로 0.9에 해당하는 정확도를 보여주었으나 실제 환경에서의 테스트 결과 평균적으로 0.6에 미치는 정확도를 보여주었다. 따라서 시스템의 정확도를 개선하기 위해서는 실시간으로 수집되는 이미지 데이터와 학습용 데이터의 오차를 줄이는 방안이 필요하다.",다국어 초록 정보 없음
Deep convolutional neural networks based ECG beats classifi cation to diagnose cardiovascular conditions,2021,"['ECG', 'CNN', 'VGG16', 'ECG beats classifi cation', 'SHAP value', 'ECG frequencies']",국문 초록 정보 없음,"Medical practitioners need to understand the critical features of ECG beats to diagnose and identify cardiovascular conditionsaccurately. This would be greatly facilitated by identifying the signifi cant features of frequency components in temporalECG wave-forms using computational methods. In this study, we have proposed a novel ECG beat classifi er based ona customized VGG16-based Convolution Neural Network (CNN) that uses the time-frequency representation of temporalECG, and a method to identify the contribution of interpretable ECG frequencies when classifying based on the SHapleyAdditive exPlanations (SHAP) values. We applied our model to the MIT-BIH arrhythmia dataset to classify the ECG beatsand to characterise of the beats frequencies. This model was evaluated with two advanced time-frequency analysis methods.Our results indicated that for 2-4 classes our proposed model achieves a classifi cation accuracy of 100% and for 5 classes itachieves a classifi cation accuracy of 99.90%. We have also tested the proposed model using premature ventricular contractionbeats from the American Heart Association (AHA) database and normal beats from Lobachevsky University Electrocardiographydatabase (LUDB) and obtained a classifi cation accuracy of 99.91% for the 5-classes case. In addition, SHAP valueincreased the interpretability of the ECG frequency features. Thus, this model could be applicable to the automation of thecardiovascular diagnosis system and could be used by clinicians."
딥러닝 기반 분류 모델의 성능 분석을 통한 건설 재해사례 텍스트 데이터의 효율적 관리방향 제안,2021,"['Construction Safety', 'CNN', 'Deep Learning', 'Classification Model', 'Disaster Data', '건설 안전', 'CNN', '딥러닝', '분류 모델', '재해 데이터']",국문 초록 정보 없음,"This study proposes an efficient management direction for Korean construction accident cases through a deep learning-based text data classification model. A deep learning model was developed, which categorizes five categories of construction accidents: fall, electric shock, flying object, collapse, and narrowness, which are representative accident types of KOSHA. After initial model tests, the classification accuracy of fall disasters was relatively high, while other types were classified as fall disasters. Through these results, it was analyzed that 1) specific accident-causing behavior, 2) similar sentence structure, and 3) complex accidents corresponding to multiple types affect the results. Two accuracy improvement experiments were then conducted: 1) reclassification, 2) elimination. As a result, the classification performance improved with 185.7% when eliminating complex accidents. Through this, the multicollinearity of complex accidents, including the contents of multiple accident types, was resolved. In conclusion, this study suggests the necessity to independently manage complex accidents while preparing a system to describe the situation of future accidents in detail."
Edge AI 기반 실시간 제스처를 이용한 로봇 팔 제어,2021,"['Edge AI', 'CNN', 'Robot arm', 'Image classification', 'Hand gesture']",국문 초록 정보 없음,"Recently, the importance of technology that interacts between human and robot has been increasing. Related this technology, the research that control the robot using hand gesture has been actively proceeding. This paper introduces robot arm control system using real-time hand gesture based on edge AI(Artificial Intelligence). There are five type of hand gesture, and CNN(Convolutional Neural Network) model is trained the hand gesture data in PC(Personal Computer) environment. After that, we distribute trained classifier to edge AI board, the trained classifier received the real-time video capture by a webcam as input and then outputting the one classified gesture data. Finally, the robot arm is controlled by transmitting the output data through the message communication of robot operation system(ROS) between the edge AI board and the UR3 robot."
Improvement of Vocal Detection Accuracy Using Convolutional Neural Networks,2021,"['Vocal Detection', 'CNN', 'Ensemble Learning']",국문 초록 정보 없음,"Vocal detection is one of the fundamental steps in musical information retrieval. Typically, the detection process consists of feature extraction and classification steps. Recently, neural networks are shown to outperform traditional classifiers. In this paper, we report our study on how to improve detection accuracy further by carefully choosing the parameters of the deep network model. Through experiments, we conclude that a feature-classifier model is still better than an end-to-end model. The recommended model uses a spectrogram as the input plane and the classifier is an 18-layer convolutional neural network (CNN). With this arrangement, when compared with existing literature, the proposed model improves the accuracy from 91.8% to 94.1% in Jamendo dataset. As the dataset has an accuracy of more than 90%, the improvement of 2.3% is difficult and valuable. If even higher accuracy is required, the ensemble learning may be used. The recommend setting is a majority vote with seven proposed models. Doing so, the accuracy increases by about 1.1% in Jamendo dataset."
다중 RGB Depth 카메라 및 합성곱 신경망을 이용한 6축 매니퓰레이터의 파지 알고리즘에 관한 연구,2021,"['visual servoing', 'CNN', 'manipulator', 'pick-and-place', 'image processing']",국문 초록 정보 없음,"In this paper, we propose a gripping algorithm for a 6-axis manipulator using two RGB depth cameras and a convolutional neural network (CNN). The proposed algorithm infers and locates an object through an RGB depth camera located in the working space, and then grasps the object through an RGB depth camera mounted on the manipulators end-effector. Then, by calculating the rotation angle and direction of the object, a gripping position is searched and a pick-and-place operation is performed. As a result of the experiments, the proposed algorithm showed that the gripping and pick-and-place motion were normally performed according to the shape of the object when a previously learned rectangular box and cylindrical object were detected."
손동작을 이용한 실시간 로봇 팔 제어 임베디드 시스템,2021,"['embedded board', 'CNN', 'image processing', 'hand gesture', 'ROS', 'robotic arm']",국문 초록 정보 없음,"Recently, HRI(Human-Robot Interaction) technology which has become increasingly important in the field of robotic has used hand gestures as communication means for robot control. Various studies are being researched to classify hand gestures using images and biological signals. In this paper, we propose a system that controls the robotic arm in real-time by classifying hand gestures using images in an embedded board environment. The proposed system consists of pre-processing the image data captured by the webcam, classifying it using CNN(Convolutional Neural Network) model, and controlling the robotic arm using ROS(Robot Operating System) in an embedded board environment. The performance of the system is evaluated based on experiments measuring the classification accuracy of the trained model, real-time robot control accuracy and the delay. Through these experiments, the high accuracy and fast processing speed of the proposed system are confirmed."
Korean Sentiment Analysis Using Natural Network: Based on IKEA Review Data,2021,"['NLP', 'Word2Vec', 'CNN', 'RNN', 'LSTM', 'GRU', 'BiLSTM', 'BiGRU']",국문 초록 정보 없음,"In this paper, we find a suitable methodology for Korean Sentiment Analysis through a comparative experiment in which methods of embedding and natural network models are learned at the highest accuracy and fastest speed. The embedding method compares word embeddeding and Word2Vec. The model compares and experiments representative neural network models CNN, RNN, LSTM, GRU, Bi-LSTM and Bi-GRU with IKEA review data. Experiments show that Word2Vec and BiGRU had the highest accuracy and second fastest speed with 94.23% accuracy and 42.30 seconds speed. Word2Vec and GRU were found to have the third highest accuracy and fastest speed with 92.53% accuracy and 26.75 seconds speed."
딥러닝과 의미론적 영상분할을 이용한 자동차 번호판의 숫자 및 문자영역 검출,2021,"['딥러닝', '합성곱 신경망(CNN)', '의미론적 분할', '자동차 번호판', '영상분할 및 인식', 'Deep Learning', 'Convolution Neural Network(CNN)', 'Semantic Segmentation', 'License Plate', 'Image Segmentation and Recognition']","자동차 번호판 인식은 지능형 교통시스템에서 핵심적인 역할을 담당한다. 따라서 효율적으로 자동차 번호판의 숫자 및 문자영역을 검출하는 것은 매우 중요한 과정이다. 본 연구에서는 딥러닝과 의미론적 영상분할 알고리즘을 적용 하여 효과적으로 자동차 번호판의 번호영역을 검출하는 방법을 제안한다. 제안된 방법은 화소 투영과 같은 전처리과정 없이 번호판 영상에서 바로 숫자 및 문자영역을 검출하는 알고리즘이다. 번호판 영상은 도로 위에 설치된 고정 카메라로 부터 획득한 영상으로 날씨 및 조명변화 등을 모두 포함한 다양한 실제 상황에서 촬영된 것을 사용하였다. 입력 영상은 색상변화를 줄이기 위해 정규화하고 실험에 사용된 딥러닝 신경망 모델은 Vgg16, Vgg19, ResNet18 및 ResNet50이 다. 제안방법의 성능을 검토하기 위해 번호판 영상 500장으로 실험하였다. 학습을 위해 300장을 할당하였으며 테스트용 으로 200장을 사용하였다. 컴퓨터모의 실험결과 ResNet50을 사용할 때 가장 우수하였으며 95.77% 정확도를 얻었다.","License plate recognition plays a key role in intelligent transportation systems. Therefore, it is a very important process to efficiently detect the number and character areas. In this paper, we propose a method to effectively detect license plate number area by applying deep learning and semantic image segmentation algorithm. The proposed method is an algorithm that detects number and text areas directly from the license plate without preprocessing such as pixel projection. The license plate image was acquired from a fixed camera installed on the road, and was used in various real situations taking into account both weather and lighting changes. The input images was normalized to reduce the color change, and the deep learning neural networks used in the experiment were Vgg16, Vgg19, ResNet18, and ResNet50. To examine the performance of the proposed method, we experimented with 500 license plate images. 300 sheets were used for learning and 200 sheets were used for testing. As a result of computer simulation, it was the best when using ResNet50, and 95.77% accuracy was obtained."
실시간 채팅 환경에서 문장 분석을 이용한 대상자 및 비속어 검출,2021,"['Target Recognition', 'Swear Detection', 'CNN', 'Telegram', 'Plug-in']",국문 초록 정보 없음,"By the increase of internet usage, communicating online became an everyday thing. Thereby various people have experienced profanity by anonymous users. Nowadays lots of studies tried to solve this problem using artificial intelligence, but most of the solutions were for non-real time situations. In this paper, we propose a Telegram plugin that detects swear words using word2vec, and an algorithm to find the target of the sentence. We vectorized the input sentence to find connections with other similar words, then inputted the value to the pre-trained CNN (Convolutional Neural Network) model to detect any swears. For target recognition we proposed a sequential algorithm based on KoNLPY."
Automated Fall Detection on Smart Factory based on Deep Learning Approach,2021,"['Convolutional Neural Network (CNN)', 'Fall-detection']",국문 초록 정보 없음,"The emergence of the smart environment and the Internet of Things paradigms with the increasing number of cameras in daily life, forms an optimal context for vision-based systems. This paper proposes a model to detect human falling by using deep learning algorithm for vision-based system. To improve fall-detection accuracy, a deep learning technique such as Convolutional Neural Network (CNN) combined with data augmentation and dropout layer to avoid over-fitting is proposed. It compared with existing convolutional-based architecture such as AlexNet, SqueezeNet, GoogleNet, and ResNet-18. The per-formance of the proposed algorithm is verified by using UR Fall Detection data set. The simulation result showed that the proposed algorithm achieves an accuracy 96.88% with validation loss 0.0638."
전기화재 원인분석을 위한 용융흔 외형 판별 딥러닝 알고리즘 설계,2021,"['전기 화재', '단락흔', '열흔', 'CNN', 'Resnet 알고리즘', 'Electric fire', 'Arc beads', 'Molten mark', 'CNN', 'Resnet']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝을 활용한 온실 내 딸기 성장단계의 인식과 탐지,2021,"['object detection', 'mask r-cnn', 'detectron2', 'hybrid deep learning', 'strawberry']",국문 초록 정보 없음,"The annual production of strawberries in Korea is around 1.5 trillion won, the largest among horticultural crops in Korea. Along with the growth of the domestic strawberry market, man y efforts have been made to improve productivity by automatically controlling the environment of strawberry greenhouses. One of the main tasks for an automated environment control in the greenhouse is the precise perception of the strawberry growth stage. This is because various controllable environmental factors inside the greenhouse can be optimally controlled depending on the growth stage of strawberry. An object detection and identification based on deep neural network using RGB images has shown a potential to provide an accurate perception of the growth stage with relatively lower cost. In this study, RGB images and hybrid deep learning net works were used to automatically recognize strawberry growth stage by detecting and identifying the flower and blooming of strawberries, guttation, and leaf-area. Mask R-CNN algorithm was implemented with a neural network based on a plant growth model which was used to estimate the leaf-area and the size of flowering. PyTorch-based Detectron2 was used as a deep neural network framework. Preliminary results with the network training of 500 strawberry images have shown a reasonable performance in detection and identification as well as a process time. Better performance could be achieved with a large number of training dataset and the net work optimization which needs to carry on in the future."
케일의 생중량 및 Glucosinolates 증대를 위한 Generative Rewarding Network (GRN) 기반의 대기 환경 제어 알고리즘,2021,"['스마트팜', '환경제어', 'GAN', 'CNN']","스마트팜에서 재배된 채소는 인공적으로 통제된 환경에서 생산량 증대를 궁극적인 목표로 한다. 이를 위해서는 다양한 생장 영향 요소 모델의 구성이 중요하다. AI와 딥러닝의 기술 발달로 인해 기존의 단순화된 경험식 기반의 생육 모델에서 데이터 기반의 블랙박스 모델 개발이 가능하다. AI를 통한 의사결정을 식물 재배환경을 통제하는 데 사용하기 위해서 강화학습과 같은 비지도 방법의 가능성이 제안되었지만, 가상의 환경을 구축해야 하는 어려움이 있으므로 지도학습을 통해 일부 모델을 선택적으로 구성해 줄 필요가 있다. 본 연구에서는 생성적 적대 신경망과 강화학습의 reward 시스템을 기반으로 식물공장 내 대기 환경을 최적화하기 위한 알고리즘 개발을 제안하고자 한다. 구체적인 목적으로, 딥러닝 기반의 지도학습인 CNN 구조를 통해 대기 환경 (온도, 습도, CO2) 조건에 따른 케일 생육과 glucosinolates 함량 변화를 예측하는 모델을 개발을 목표로 하였다. 이를 위해, 총 18개의 독립된 환경조건이 구성 가능한 공간에서 두 작기 케일 재배를 통해 학습 데이터 세트를 확보하였다. 확보된 데이터를 통해 개발된 예측모델을 본 연구에서 제안하는 GRN 구조의 인공지능 기술을 적용하여 최적의 환경조건을 찾는 시뮬레이션을 수행하였다. 생중량 예측 모델의 결과는 결정계수(R2) 0.95를 확인하였으며, glucosinolates 성분 예측모델에서는 결정계수(R2) 0.80의 결과를 얻었다. GRN 모델에서 생성된 최적화된 환경에서 케일 재배를 시뮬레이션 결과 약 9.59%의 평균 생육량 증대된 결과를 얻었다. 추후 케일 실증 실험을 통해 GRN을 통한 대기환경 제어 방법을 확인하고자 한다.",다국어 초록 정보 없음
Sentiment Orientation Using Deep Learning Sequential and Bidirectional Models,2021,"['Deep Learning', 'LSTM', 'CNN', 'Machine Learning', 'Supervised and Un-Supervised Learning']",국문 초록 정보 없음,"Sentiment Analysis has become very important field of research because posting of reviews is becoming a trend. Supervised, unsupervised and semi supervised machine learning methods done lot of work to mine this data. Feature engineering is complex and technical part of machine learning. Deep learning is a new trend, where this laborious work can be done automatically. Many researchers have done many works on Deep learning Convolutional Neural Network (CNN) and Long Shor Term Memory (LSTM) Neural Network. These requires high processing speed and memory. Here author suggested two models simple & bidirectional deep leaning, which can work on text data with normal processing speed. At end both models are compared and found bidirectional model is best, because simple model achieve 50% accuracy and bidirectional deep learning model achieve 99% accuracy on trained data while 78% accuracy on test data. But this is based on 10-epochs and 40-batch size. This accuracy can also be increased by making different attempts on epochs and batch size."
딥러닝 알고리즘 기반의 초미세먼지(PM2.5) 예측 성능 비교 분석,2021,"['딥런닝', '초미세먼지(PM2.5)', 'CNN', 'LSTM', 'GAN', '시계열데이터', 'Deep Learning', 'Fine particulate Matter(PM2.5)', 'Convolutional Neural Network', 'Long Short-Term Memory', 'Generative Adversarial Networks', 'Time Series Data']",국문 초록 정보 없음,다국어 초록 정보 없음
Building Energy Time Series Data Mining for Behavior Analytics and Forecasting Energy consumption,2021,"['ehavioral Analytics', 'Big Data Mining', 'Clustering Analysis', 'CNN', 'Energy Consumption', 'Energy Prediction', 'LSTM']",국문 초록 정보 없음,"The significant aim of this research has always been to evaluate the mechanism for efficient and inherently aware usage of vitality in-home devices, thus improving the information of smart metering systems with regard to the usage of selected homes and the time of use. Advances in information processing are commonly used to quantify gigantic building activity data steps to boost the activity efficiency of the building energy systems. Here, some smart data mining models are offered to measure, and predict the time series for energy in order to expose different ephemeral principles for using energy. Such considerations illustrate the use of machines in relation to time, such as day hour, time of day, week, month and year relationships within a family unit, which are key components in gathering and separating the effect of consumers behaviors in the use of energy and their pattern of energy prediction. It is necessary to determine the multiple relations through the usage of different appliances from simultaneous information flows. In comparison, specific relations among interval-based instances where multiple appliances use continue for certain duration are difficult to determine. In order to resolve these difficulties, an unsupervised energy time-series data clustering and a frequent pattern mining study as well as a deep learning technique for estimating energy use were presented. A broad test using true data sets that are rich in smart meter data were conducted. The exact results of the appliance designs that were recognized by the proposed model were filled out by Deep Convolutional Neural Networks (CNN) and Recurrent Neural Networks (LSTM and GRU) at each stage, with consolidated accuracy of 94.79%, 97.99%, 99.61%, for 25%, 50%, and 75%, respectively."
드론 탐지 및 분류를 위한 레이다 영상 기계학습 활용,2021,"['레이다', 'ISAR', '마이크로 도플러', '기계학습', 'CNN', 'Radar', 'ISAR', 'Micro-doppler', 'Machine learning', 'CNN']","최근 드론은 가격 하락, 소형화와 함께 높은 기술 발전에 힘입어 드론 보급이 민군에 걸쳐 증가하면서 보안안전사고, 치안‧안보 위협 등의 문제를 유발할 가능성도 커지고 있다. 드론으로 인해 발생하는 사건 및 사고를 예방하기 위해서는 드론의 출현에 대응할 수 있는 탐지 기술이 우선적으로 선행되어야 한다. 드론은 크기가 작고 전파 반사도가 낮은 재질로 구성되어 있어 음향, 적외선, 레이다의 운용만으로는 탐지가 어렵다. 최근 영상 식별 성능을 강화하기 위해 레이다 신호에 인공지능을 접목한 연구사례가 증가하는 추세이다. 본 논문에서는 레이다 영상을 이용한 드론 탐지 기술을 소개하며, 드론의 모의실험 데이터와 실제 실험 데이터를 기반으로 인공지능 기술에 적용하여 드론의 분류 정확도를 효과적으로 입증하였다.","Recent advance in low cost and light-weight drones has extended their application areas in both military and private sectors. Accordingly surveillance program against unfriendly drones has become an important issue. Drone detection and classification technique has long been emphasized in order to prevent attacks or accidents by commercial drones in urban areas. Most commercial drones have small sizes and low reflection and hence typical sensors that use acoustic, infrared, or radar signals exhibit limited performances. Recently, artificial intelligence algorithm has been actively exploited to enhance radar image identification performance. In this paper, we adopt machined learning algorithm for high resolution radar imaging in drone detection and classification applications. For this purpose, simulation is carried out against commercial drone models and compared with experimental data obtained through high resolution radar field test."
알루미늄 합금의 아크용접부 비전 스캔을 이용한 용접 부품의 기계적 특성 예측,2021,"['Aluminum Alloy', 'GMAW (Gas Metal Arc Welding)', 'CNN (Convolutional Neural Network)', 'SDAS (Secondary Dendrite Arm Spacing)', 'Welding Quality Prediction', 'Laser Vision', 'Artificial Intelligence']","자동차 부품에서의 알루미늄 합금은 용융용접을 통해 차체 및 샤시 부품에 적용되고 있다. 이러한 용융 용접부는 차체 및 샤시의 강성과 내구성에 큰 영향을 미치고 있어, 높은 수준의 품질이 요구된다. 품질검사는 육안으로 크랙이나 기공을 확인하기도 하지만, 용접부 인장강도, 용입량, 목두께, 토우각 등을 통해 수행된다. 하지만 이러한 품질검사는 용접부를 절단하여 단면을 확인하여야 하므로, 전수검사가 어렵고 검사를 위한 추가 시간이 소요된다. 따라서 이러한 문제를 해결하기 위해 수많은 비파괴 검사 및 예측에 대한 연구가 진행되고 있으며, 본 연구에서는 현장에서도 적용이 가능한 레이저 비전을 통해 용접부 외관을 측정하고 인공신경망 학습을 통해 품질을 예측할 수 있는 방법에 대한 연구를 수행하였다. 본 연구에서 알루미늄 5083과 6061 합금을 사용하였으며, 용접은 GMAW(gas metal arc welding), 와이어는 5336을 사용하였다. 용접속도, 와이어 송급속도, 전류, 전압 등의 변화에 따른 용접 특성을 분석하였으며, 레이저 비전 센서를 활용한 용접부 외관 비드 스캔, 인장강도 시험, 용접부 단면 분석을 수행하였다. 레이저 비전 센서를 통해 확보한 용접부 외관 형상 이미지 DATA와 인장강도 결과를 이용하여 아크용접부 강도를 예측하는 CNN(convolutional neural network) 모델을 개발하였다.",다국어 초록 정보 없음
문화재 관리를 위한 지능형 플랫폼 방안 연구,2021,"['문화재', 'IoT', '빅데이터', '심층신경망(DNN)', '합성곱신경망(CNN)', 'Cultural Property', 'IoT', 'Big Data', 'Deep Neural Network', 'Convolution Neural Network']",국문 초록 정보 없음,"Recently, with the rapid development of IoT technology, the issue of Intelligent Platforms for managing Cultural Properties is increasing. In order to develop an Intelligent Platform for Cultural Property management, Sensors can be installed to collect and analyze internal and external state data of Cultural Properties, and predict with Big Data analysis using Artificial Intelligence algorithms. This Study proposes an external and internal intelligent integrated platform research method based on IoT technology for maintenance and safety management of Cultural Properties. In the proposed Intelligent Platform, a Deep Neural Network (DNN) learning algorithm was proposed to analyze and predict the tilt Sensor data and the Meteorological Agency data considering changes in the external environment as external data of Cultural Properties. In addition, we propose a Convolutional Neural Network (CNN) learning algorithm to analyze and predict image data for detecting pests as internal data of Cultural Properties."
Automated Gastrointestinal Tract Classification Via Deep Learning and The Ensemble Method,2021,"['Gastrointestinal tract', 'Colorectal cancer', 'Deep learning', 'CNN', 'Transfer learning', 'Ensemble']",국문 초록 정보 없음,"Colorectal cancer is a leading cause of death among the cancer family with a record of almost a million moralities in 2020 alone. While the treatment of colorectal cancer is very difficult, early diagnosis can help immensely with treatment, eliminating the risks, and recovery. In most cases early diagnosis is possible by catching any of the precursors of the disease, many of which appear on the Gastrointestinal tract. The use of machine learning to automate the process of gastrointestinal tract examination could accelerate the process of diagnosis, and increase its efficiency. This study suggests the use of the stacking ensemble method with multiple pre-trained CNN models for an accurate classification of GI tract using the publicly available dataset Kvasir. The pre-trained models used in this study were ResNet50, MobileNetV2, and Xception, all of which were ensembled and trained on a subset of the data and tested on another to eliminate bias, and evaluates the model’s capacity for generalization. Overall, the model demonstrated impressive performance at 99.2% accuracy, 0.9977 AUC, and 99.29% F1-score, especially compared to the individual constituent models and other models discussed in the review section of the study."
A New Image Classification Method,2021,"['Image Classification Method', 'Training', 'Prime Number Learning', 'CNN']",국문 초록 정보 없음,"In this paper, we propose a new image classification method based on several trainings, which is mainly used to solve model overfitting and non-convergence in image classification tasks of small data sets and to improve classification accuracy. This method, based on prime number learning, uses model structure optimization to extend the underlying convolutional neural network (CNN) model and adds a convolutional layer to extract more image features to improve classification accuracy."
Spectrogram Based Detection Algorithm for Back-Bead in Gas Metal Arc Welding Process using Convolution Neural Network,2021,"['Gas metal arc welding', 'Convolution neural network (CNN)', 'Short time fourier transform (STFT)', 'Time-frequency domain analysis', 'Back-bead generation prediction']",국문 초록 정보 없음,"An automated welding system is essential to ensure a stable and good welding quality and improve productivity in the gas metal arc welding (GMAW) process. Therefore, various studies have been conducted on the establishment of smart factories and the demand for good weldability in the fields of production and manufacturing. In shipbuilding welding and pipe welding, the uniformly generated back-bead is an important criterion for judging the mechanical properties and weldability of the welded structure, and is also an important factor that enables the realization of an automated welding system. Therefore, in this study, the welding current signal measured in real-time in the GMAW process was pre-processed by a short time Fourier transform (STFT) to obtain a time-frequency domain feature image (spectrogram). Based on this, a back-bead generation detection algorithm was developed. To accelerate the training speed of the proposed convolution neural network (CNN) model, we used non-saturating neurons and a highly efficient GPU implementation of the convolution operation. As a result of applying the proposed detection model to actual welding process, the detection accuracies with and without the back-bead regions were 95.8% and 94.2%, respectively, which confirmed the excellent classification performance for back-bead generation."
Model for the Identification and Classification of Partially Damaged and Vandalized Traffic Signs,2021,"['Convolutional Neural Networks', 'Detection', 'Classification', 'Damaged traffic signs', 'Vandalized traffic signs']",국문 초록 정보 없음,"The development of Convolutional Neural Networks (CNN) has expanded with the accelerated progress of IT, as well as with the needs of the autonomous vehicle (AV) implementation. The specifics and requirements of AV towards the infrastructure primarily relate to the condition and quality of traffic signs. For the independent participation of these vehicles in traffic, an impeccable traffic sign condition is required, which is often not the case in practice. Damaged, faded, obscured, or vandalized traffic signs can usually be seen in the road network, which can impede the movement of AV in traffic. In the existing literature, little or very little attention is focused on the problem of identifying and classifying damaged and especially vandalized traffic signs. In this paper, the mentioned problem is addressed, and the CNN model is proposed. This model has been tested on a specially designed novel and challenging database containing 6,000 real-time images of traffic signs in the road network of the Republic of Serbia. This model is invariant to different lighting and weather (nighttime and fog) conditions. In this case study, the model reached an overall accuracy of 99.17%, whereby all vandalized and damaged traffic signs are accurately identified and classified."
번역 생성기와 문장 판별기 기반의 문장 데이터 증강 방법,2021,"['Data augmentation', 'deep learning', 'LSTM', 'CNN', 'self-attention']","본 논문에서는 번역 생성기 (translation generator)와 문장 판별기 (sentence discriminator) 기반의 문장 데이터 증강 방법을 제안한다. 번역 생성기는 다른 언어로의 반복 번역을 통해 원본 문장과 비슷한 의미를 가진 변형문장을 생성하여 데이터의 수를 늘린다. 하지만 이러한 방식으로 생성된 문장의 일부는 학습에 방해가 된다. 이에 문장 판별기는 학습에 방해되는 문장을 판별하기 위하여 Convolutional Neural Network (CNN)와 Bidirectional Long Short-Term Memory (Bi-LSTM)를 병렬로 병합한 딥러닝 모델로 원본문장을 학습하고 변형문장 중에서 학습에 방해되는 문장을 판별하고 제거하여 데이터 증강 문장을 출력한다. 본 논문의 데이터 증강 방법으로 데이터를 증강한 후 5가지의 딥러닝 모델로 테스트를 진행한 결과, 데이터의 크기에 따라 최대 9.28%의 성능 향상을 보였다.",다국어 초록 정보 없음
End-to-end Automatic Sleep Staging Algorithm using Convolution Neural Network and Bidirectional LSTM,2021,"['Sleep stages', 'Automatic classification', 'EEG', '1D-CNN', 'bi-LSTM']",국문 초록 정보 없음,"In order to measure sleep quality, sleep experts manually classify sleep stages through polysomnography (PSG) signals. However, it is time-consuming and labor-intensive work. Thus, automatic sleep stage classification methods are needed. In this study, we propose an end-to-end automatic sleep staging algorithm using a one-dimensional convolutional neural network (1DCNN) based on an inception network and bidirectional long short-term memory (bi-LSTM). First, a feature map was extracted from input data using the 1D-CNN architecture without preprocessing. Secondly, bi-LSTM learned a stage transition rule using the feature maps. In addition, we used the sleep-EDF public dataset to evaluate our model, and only one channel of EEG signal was used to save computational cost. The accuracy and macro-averaged F1 score of the classification performance were 85.05% and 79.05%, respectively. These results demonstrate state-of-the-art performance compared to previous studies using the same dataset, yielding an effective method for an automatic sleep staging algorithm."
Lost gamma source detection algorithm based on convolutional neural network,2021,"['Conventional neural network', 'Lost gamma source', 'GEANT4', 'Energy deposition']",국문 초록 정보 없음,"Based on the convolutional neural network (CNN), a novel technique is investigated for lost gamma source detection in a room. The CNN is trained with the result of a GEANT4 simulation containing a gamma source inside a meshed room. The dataset for the training process is the deposited energy in the meshes of different n-step paths. The neural network is optimized with parameters such as the number of input data and path length. Based on the proposed method, the place of the gamma source can be recognized with reasonable accuracy without human intervention. The results show that only by 5 measurements of the energy deposited in a 5-step path, (5 sequential points 50 cm apart within 1600 meshes), the gamma source location can be estimated with 94% accuracy. Also, the method is tested for the room geometry containing the interior walls. The results show 90% accuracy with the energy deposition measurement in the meshes of a 5-step path."
Non-linear data association method for cow tracking,2021,"['multi-objects tracking', 'ensemble Kalman filter', 'CNN', 'cow']",국문 초록 정보 없음,"Multi-objects tracking (MOT) is an important basic research area in computer vision in recent years. In particular, pedestrian tracking and vehicle tracking are very popular applications in MOT. In this paper, we perform MOT on cows, In this MOT task we address the following challenges: deformation and frequent occlusion. To solve deformation, we proposed a deep CNN model with SPP-Net as backbone to extract a feature vector of every cow. To solve occlusion, we use the ensemble Kalman filter that suitable for non-linear motion model to predict the attributes of bounding boxes directly. Our experiments reveal that nonlinear motion model and fixed deep features are more suitable on cows dataset with video sequences."
저복잡도를 위한 합성곱 신경망 기반의 적응형 4D-8PSK-TCM,2021,"['satellite communications', '4D-8PSK-TCM', 'T-algorithm', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
ECG Identification with One Dimensional Convolutional Neural Network,2021,"['ECG identification', 'biometrics', 'subject identification', 'machine learning', 'cnn']",국문 초록 정보 없음,"This study investigates the potential of electrocardiogram (ECG) signal for biometric recognition (subject identification). ECG is unique for each subject (person) depends on the anatomic features of the heart and body. A total of 1,676 datasets from 48 subjects were modeled using a machine learning technique (convolutional neural network-CNN). We managed to achieve the identification accuracy of 88% as well as the F1-score. This finding show that ECG analysis is potential for subject identification application."
Describing Environmental Information in Videos Using Machine Learning,2021,"['Machine Vision', 'Visual Recognition', 'Video Captioning', '3D CNN', 'RNN']",국문 초록 정보 없음,"The previous researches of video captioning task have focused on human actions or objects in videos, however, environmental information such as place, time, weather among others is also important information to understand videos. Therefore, in this paper, we create a new dataset which adds environmental information labels to MSVD dataset and train the machine learning model to analyze environmental information from videos. We apply R(2+1)D which is a 3D CNN model to extract video features and S2VT which is a RNN model to encode the video features and to decode the environmental information. The reason why we define the problem as a sequence to sequence problem, not multilabel classification, is that the input is a video, which is a sequence of frames, and the output is also related with each other. For example, if the place label is outside, then next label would be weather. We analyze the experimental results based on BLEU, METEOR, ROUGE-L, and CIDEr and it shows the competitive results compared to the state-of-the-art video captioning model."
실제 GPS L1 C/A 신호에 대한 기계학습 기반 재밍 신호 식별 기법,2021,"['GPS', 'Jamming', 'Machine Learning', 'SVN', 'CNN', 'Classification']",국문 초록 정보 없음,"In this paper, we propose a CNN (Convolution Neural Network)-based jamming signal classification scheme, which is a representative machine learning model that can effectively classify real GPS L1 C/A (Coarse/Acquisition) signal and five jamming signals generated in real time with our own experimental equipment. As a result of the experiment, the highest average classification accuracy of the conventional scheme is 95.29%, while the proposed scheme is 98.23%, showing a 2.94%P higher classification accuracy than the conventional scheme. In addition, the conventional scheme has a maximum difference of 9.66%P in classification performance for each jamming signal, whereas the proposed method is a more robust jamming classification scheme with a maximum of 3.03%P."
고해상도 정사영상을 이용한 딥러닝 기반의 산림수종 분류에 관한 연구,2021,"['딥러닝', '컨볼루션 신경망', '드론', '정사영상', '수종분류', 'Deep learning', 'CNN', 'Drone', 'Orthophoto', 'Species classification']",국문 초록 정보 없음,"In this study, we evaluated the accuracy of deep learning-based tree species classification model trained by using high-resolution images. We selected five species classed, i.e., pine, birch, larch, korean pine, mongolian oak for classification. We created 5,000 datasets using high-resolution orthophoto and forest type map. CNN deep learning model is used to tree species classification. We divided training data, verification data, and test data by a 5:3:2 ratio of the datasets and used it for the learning and evaluation of the model. The overall accuracy of the model was 89%. The accuracy of each species were pine 95%, birch 89%, larch 80%, korean pine 86% and mongolian oak 98%."
컬러 이미지 분석을 통한 블랙 아이스 검출 방법 연구,2021,"['Black ice', 'Artificial intelligence(AI)', 'Deep learning', 'Convolutional Neural Networks(CNN)', 'image classification']","현재 개발중인 그리고 운행중인 대부분의 자동차에는 다양한 IoT 센서들이 탑재되어 있지만, 자동차 사고를 일으키는 요인 중 몇몇 요인들은 상대적으로 탐지하기 힘들다. 이러한 요소 중 대표적인 위험 요인 중 하나가 블랙 아이스이다. 블랙 아이스는 블랙 아이스가 깔린 부분을 지나가는 모든 차량에 영향을 줄 수 있어 대형 사고를 유발할 가능성이 가장 높은 요인 중 하나이다. 따라서 대형 사고를 막기 위해 블랙 아이스 검출 기법은 꼭 필요하다. 이를 위해 몇몇 연구가 과거 진행되었으나 몇몇 부분에서 현실적이지 않는 요소들이 반영된 경우가 있어, 이를 보충하기 위한 연구가 필요하다. 본 논문에서는 CNN 기법으로 컬러 이미지를 분석하여 블랙 아이스를 탐지하고자 하였으며, 일정 수준의 블랙 아이스 탐지에 성공하였다. 다만 기존 연구 와 차이가 있어 그 이유를 분석하였다.",다국어 초록 정보 없음
제조 설비 이상탐지를 위한 지도학습 및 비지도학습 모델 설계에 관한 연구,2021,"['센서 데이터', '고장 예측 및 이상탐지', 'XGBoost', 'LightGBM', 'CNN', 'MD', 'AE', 'LSTM-AE', 'Sensor data', 'Fault and Anomaly Detection']",국문 초록 정보 없음,"In the era of the 4th industrial revolution, smart factories have received great attention, where production and manufacturing technology and ICT converge. With the development of IoT technology and big data, automation of production systems has become possible. In the advanced manufacturing industry, production systems are subject to unscheduled performance degradation and downtime, and there is a demand to reduce safety risks by detecting and reparing potential errors as soon as possible. This study designs a model based on supervised and unsupervised learning for detecting anomalies.The accuracy of XGBoost, LightGBM, and CNN models was compared as a supervised learning analysis method. Through the evaluation index based on the confusion matrix, it was confirmed that LightGBM is most predictive (97%). In addition, as an unsupervised learning analysis method, MD, AE, and LSTM-AE models were constructed. Comparing three unsupervised learning analysis methods, the LSTM-AE model detected 75% of anomalies and showed the best performance. This study aims to contribute to the advancement of the smart factory by combining supervised and unsupervised learning techniques to accurately diagnose equipment failures and predict when abnormal situations occur, thereby laying the foundation for preemptive responses to abnormal situations. do."
Deep Learning 방식 기반의 X-ray Fluorescence (XRF) 물질분석 시스템을 활용한 황동의 물질판별 및 정량화 연구,2021,"['상온반도체 XRF imaging', 'Deep-Learning', 'Convolutional Neural Network (CNN)', '상온반도체 XRF imaging', 'Deep-Learning', 'Convolutional Neural Network (CNN)']",국문 초록 정보 없음,다국어 초록 정보 없음
OFDM 신호에 대한 스펙트럼 센싱 기술,2021,"['OFDM', 'Cyclostationary', 'Spectral Correlation Function', 'FFT Accumulation Method', 'CNN']","본 논문은 기계학습에 기반을 둔 OFDM 신호를 탐지하는 알고리즘을 개발한 결과다. 스펙트럼 탐지 기술은 주파수 자원을 효율적으로 이용할 수 있는 인지 무선통신의 핵심 기술이다. 최근 무선통신시스템에서 송수신되는 신호는 OFDM을 기반으로 하고 있다. OFDM 신호는 채널 보정을 위해 파일럿 신호를 포함하고 있는데, 스펙트럼 상관 함수(SCF)를 사용하여 이를 검출할 수 있다. 이 과정에서 효율적인 SCF 연산을 위해 FAM 알고리즘이 사용되었다. 이렇게 구한 SCF를 입력 데이터로 하는 CNN 신경망 방식의 기계학습 알고리즘을 통해 OFDM 신호의 유무를 판단한다. 기계학습을 위한 학습 데이터는 −20 dB～0 dB의 SNR을 갖는 OFDM 신호의 SCF 값이 사용되었다. 학습 후 최적화한 신경망의 성능을 평가한 결과, SNR이 −12 dB인 수신 신호에 대해 오경보 확률 0.08 조건에서 0.9 확률로 신호를 탐지하였다.","This paper presents a machine learning (ML) algorithm to detect orthogonal frequency-division multiplexing (OFDM) signals. Spectrum sensing is a key technology in cognitive radio communication, which enhances spectral efficiency. Recently, signals  transmitted and received by wireless communication systems have been based on OFDM. These signals contain a pilot signal for channel calibration, which can be detected using a spectral correlation function (SCF). In this process, the FAM algorithm is applied for efficient SCF operation herein. The existence of OFDM signals is determined through a convolutional neural network-based ML algorithm using the SCF as input data. The learning data for ML use the SCF values for OFDM signals with signal-to-noise ratios (SNRs) of -20 to 0 dB. Consequently, on evaluation of the post-learning optimized neural network performance, signals were detected with a probability of 0.9 at the condition of 0.08 false alarm probability for reception signals with SNRs of -12 dB."
음성신호를 이용한 딥러닝 기반 우울증 진단 연구 동향 분석,2021,"['Depression diagnosis', 'Artificial intelligence', 'Speech signal', 'Deep learning', 'CNN']",국문 초록 정보 없음,"Depression is a common mental illness in modern society, and research on technologies that depression diagnosis using artificial intelligence has actively proceeded recently. In this paper, of the many artificial intelligence technologies, we analyze research trends on techniques for diagnosing depression based on deep learning models using speech signals. Specifically, deep learning models are presented such as CNN(Convolutional Neural Networks) and LSTM(Long-Short Term Memory), and methods for applying speech signals to deep learning models. Also, databases are described such as DAIC-WOZ(Distress Analysis Interview Corpus) database and AVEC2013(Audio-Visual Emotion recognition Challenge) depression database used for speech signal-based depression diagnosis."
A deep learning-based vision enhancement method for UAV assisted visual inspection of concrete cracks,2021,"['RRA-GAN', 'SR GAN', 'crack detection', 'Mask R-CNN', 'deep learning', 'SHM']",국문 초록 정보 없음,"Implementing unmanned aerial vehicles (UAVs) on concrete surface-crack inspection leads to a promising visual crack detection approach. One of the challenges for automated field visual cracking inspection is image degradation caused by the rain or fog and motion blur during data acquisition. The present study combines two deep neural networks to address the image degradation problem. By using the Variance of Laplacian algorithm for quantifying image clarity, the proposed deep neural networks can remarkably enhance the sharpness of the degraded images. After vision enhancement process, Mask Region Convolutional Neutral Network (Mask R-CNN) was developed to perform automated crack identification and segmentation. Results show a 8~13% enhancement in prediction accuracy compared to the degraded images, indicating that the proposed deep learning-based vision enhancement method can effectivey identify and segment concrete surface cracks from photos captured by UAVs."
스마트 공장의 품질예측을 위한 딥러닝 모델 적용 연구 - 플라스틱 사출공정을 중심으로,2021,"['Smart Factory', 'Plastic Injection Molding', 'Quality Prediction', 'Deep Leaning', 'DAE', 'LSTM', 'CNN']","스마트공장의 고도화된 기술들을 통해 산업 현장에서 생성되는 무수히 많은 데이터를 기반으로 공정 내에 발생하는 문제의 원인을 분석하고 탐색하는 것이 실시간으로 가능하며, 이러한 데이터를 바탕으로 효율적인 의사결정을 할 수 있게 된다. 본 연구에서는 플라스틱 사출성형 공정 내 센서들에서 생성되는 총 36개의 제조조건 데이터 학습을 통해 제품의 품질을 예측하는 것을 목표로 한다. 품질 예측을 위한 딥러닝 모델은 잡음 제거 오토인코더, 장 · 단기 기억신경망, 합성곱 신경망을 적용하였다. 학습 데이터 셋은 KAMP(Korea AI Manufacturing Platform)를 통해 수집하였고 모두 양품과 불량품에 대한 레이블링이 되어있다. 각 모델별 파라미터를 달리하여 성능을 평가하였으며, 각 모델을 비교 · 분석하여 좋은 성능을 내는 모델과 파라미터 셋을 혼동행렬 및 f1-score를 활용하여 성능을 평가하였다. 본 연구에서 제안한 딥러닝 모델에 기반을 둔 사출공장 품질예측 시스템은 사출기계로부터 실시간 취합되는 센서 데이터 셋을 이용하여 공정조건 변화에 따른 품질을 예측하게 함으로써 품질 신뢰도를 향상하고 공정 품질검사 투입인력을 절감할 수 있을 것으로 기대한다.","When it comes to smart factories technology, the analysis, and exploration of the causes of problems in the processes can be made in real-time, based on the myriad data gathered from manufacturing facilities, and efficient decisions can be made based on these data. We conducted a study to predict the quality of products through the analysis of sensor data from the plastic injection molding process. We utilized a denoising autoencoder (DAE), long-shot memory network (LSTM), and a convolutional neural network (CNN) to formulate deep learning models for quality prediction. The training data set was collected through KAMP (Korea AI Manufacturing Platform) and the information regarding defects was labeled. Performance was evaluated by different parameters for each model and compared using two measures such as the confusion matrix and f1-score. A quality prediction system based on deep learning models for an injection molding factory makes it possible to accurately predict the quality according to a change in process conditions by utilizing the sensor data set gathered from the machines. We can therefore expect an improvement in quality and reliability and a reduction of the input manpower for process quality inspection."
주파수 도메인 특성과 인공지능 신경망을 이용한 백내장 분류,2021,[],국문 초록 정보 없음,"A disease in which the eyes become cloudy and a person cannot see clearly is called a cataract. To diagnose the cataract, a diagnosis by a specialist is required, but the criteria for diagnosing cataracts may be different for each doctor, so diagnosis results may also be different. Accordingly, there is a need to diagnose cataracts according to consistent criteria. In this paper, we conducted a study to diagnose cataracts using a computer. The fundus picture of the normal eye looks clear, but that of cataractal eye is a little cloudy. This means that there is a difference in frequency components for each of images. So we used these features to transform the fundus photo into the frequency domain pictures and used it as input data. Next, neural networks(NN) of various layers and parameters were defined, some networks called CNN included a convolutional layer. The classification neural networks and convolutional neural  networks were trained during a long time of learning. As a result of this study, the highest average accuracy of the artificial intelligence NN was 93.34%."
HSV 컬러 모델 및 코너 검출 알고리즘을 이용한 딥러닝 기반의 화염 감지에 관한 연구,2021,"['Artificial intelligence', 'Deep learning', 'HSV color model', 'Corner detection algorithm', 'CNN']","최근 딥러닝 기법을 이용한 이미지 분류 모델이나 객체 감지 모델이 많이 연구되고 있지만 적절한 전처리 방법을설계하지 않을 경우 성능 평가 결과 낮은 정확도를 얻을 수 있다. 따라서 본 연구에서 제안하는 효과적인 화염검출전처리 방법으로는 HSV 컬러 모델과 Harris 코너 검출 알고리즘을 적용한 이미지 전처리 방법이다. HSV 컬러 모델을 통해 화염이 존재하는 색상영역을 필터링하고, 필터링된 결과물에 대해 Harris 코너 검출 방법을 적용할 경우 화염 이미지의 거친 질감 특성 때문에 화염 주변에 집중적으로 코너가 검출되게 된다. 이러한 특성을 통해 코너가 다수발생한 영역을 관심영역으로 검출하여 딥러닝 기반의 합성곱신경망(Convolutional neural network, CNN) 모델을 통해최종적으로 화염 여부를 분류하도록 하였다. 그 결과 본 연구에서 제안한 모델의 화염 검출 결과 정확도는 97.5%정밀도는 97%로 나타났다.","Recently, many image classification or object detection models that use deep learning techniques have been studied;however, in an actual performance evaluation, flame detection using these models may achieve low accuracy. Therefore,the flame detection method proposed in this study is image pre-processing with HSV color model conversion and the Harriscorner detection algorithm. The application of the Harris corner detection method, which filters the output from the HSVcolor model, allows the corners to be detected around the flame owing to the rough texture characteristics of the flameimage. These characteristics allow for the detection of a region of interest where multiple corners occur, and finally classifythe flame status using deep learning-based convolutional neural network models. The flame detection of the proposed modelin this study showed an accuracy of 97.5% and a precision of 97%."
단조 공정의 균일 변형률 분포를 위한 예비성형체 설계 방법,2021,"['단조공정(Forging process)', '예비성형체(Forging process)', '합성곱신경망(Convolution neural network)']",국문 초록 정보 없음,"Preform design is important for full filling of the die and uniform deformation in forging processes. In this study, a preform design methodology for uniform strain distribution is introduced. The proposed method is based on a convolution neural network (CNN) algorithm. By convolution operation with weight arrays, the model extracts geometrical features of the forging product, forging simulation result, and strain distribution, and connects those features with the corresponding preform. For the different forging products, the saved weight arrays can extract the characteristic features, so that proper preform shape can be easily acquired without any iterations. The proposed design method is utilized for the H-shaped forgings and validated through numerical experiments for rail wheel forging and disk forging. The proposed method has shown to be reliable in preform design procedures, granting uniform deformation with full filling in forging processes."
Swin Transformer를 이용한 항공사진에서 다중클래스 차량 검출,2021,"['artificial intelligence', 'computer vision', 'object detection', 'instance segmentation']","도시 상태를 탐지하기 위해서는 운송 수단 수, 교통 흐름등이 필수적으로 파악되어야 할 요소이다. 본 논문에서는 기존의 Mask R-CNN을 이용하여 다양한 차량의 형태를 학습하고, 드론으로 촬영한 도시 항공 영상에서 특정 유형의 차량 들을 검출하는 시스템을 오늘날 NLP 분야에서 널리 쓰이게 된 Transformer 모델을 컴퓨터 비전 문제에 도입하여 기존의 컨볼루션 신경망보다 높은 성능을 보여준 Swin Transformer 모델을 이용하여 기존의 연구에서 보여주었던 검출 시스템 능력을 향상시켰다.","In order to detect urban conditions, the number of means of transportation and traffic flow are essential factors to be identified. This paper improved the detection system capabilities shown in previous studies using the SwinTransformer model, which showed higher performance than existing convolutional neural networks, by learning various vehicle types using existing Mask R-CNN and introducing today’s widely used transformer model to detect certain types of vehicles in urban aerial images."
깊이 정보를 이용한 학습된 객체의 관심 영역의 방향 추출,2021,"['depth', 'mask-rcnn', 'object detection', '3d camera']","본 논문에서는 3D카메라의 깊이 정보를 이용해 사전에 학습된 객체에 대한 정밀한 정보를 추출하는 방법을 제안한다. 먼저, Mask R-CNN을 이용해 객체와 위치를 인식하고, 해당 영역의 깊이 정보를 획득한다. 획득한 깊이 정보를 이용하여 차원 평면에 방향을 표시하였다. 실험을 통해 값을 분석한 결과, 유효한 방향을 측정할 수 있었다.","In this paper, we proposed a method of extracting the precise information about an object learned in advance by using the depth of a 3D camera. First, an object and a location are recognized using a Mask R-CNN, and depth information of a corresponding area is obtained. The direction was indicated on the 2D plane using the obtained depth information. As a result of analyzing the values through experiments, effective directions could be measured."
V형 맞대기 이음의 GMA 초층 용접에서 용접 파형을 통한 완전용입 예측 합성곱 신경망 모델 개발,2021,"['Gas metal arc welding (GMAW)', 'V-Groove', 'Back-bead', 'Root pass', 'Full penetration', 'Deep learning', 'Convolutional neural network (CNN)', 'Fourier transform', 'Spectrogram']","가스 메탈 아크 용접 (gas metal arc welding, GMAW)은 산업기계 분야에서 요구하는 용접 품질을 확보하는데 용이한 생산 기술이기 때문에 널리 사용되고 있다. 소재가 두꺼운 경우 일반적으로 V형 이음부에서 다층 용접을 수행한다. 다층 용접 중에서 초층 용접은 용입 여부로 용접 접합부의 품질이 좌우된다. 현재 초층 용접은 용접 중 발생하는 외란에 대응하기 위하여 숙련된 작업자에 의존하지만, 용접의 특수성으로 인하여 숙련된 작업자를 확보하기 힘든 실정이기 때문에 고품질의 초층 용접을 진행하기 위해서는 GMAW 자동화가 지속적으로 요구되고 있다. 특히 초층 용접 자동화를 위해서는 완전 용입의 이면 비드를 확보할 수 있는 예측모델의 개발이 필요하다. 본 연구에서는 V형 맞대기 이음 GMA 초층 용접에서 완전 용입을 예측하기 위한 합성곱 신경망 (convolutional neural network, CNN) 모델을 개발했다. 모델의 입력 데이터는 용접 공정 중 생성된 전력을 주파수 영역으로 푸리에 변환 (fourier transform)하여 얻은 스펙트로그램(spectrogram)으로 생성하였다. 출력 데이터는 초층의 완전 용입을 예측하기 위하여 이면 비드 발생 유무로 두 가지 클래스를 사용하였다. 이러한 입출력 데이터를 이용하여 GMAW 공정에서 V형 맞대기 이음 초층 완전용입을 예측할 수 있는 모델을 개발하였다.",다국어 초록 정보 없음
딥러닝 기술을 이용한 캐비테이션 자동인식에 대한 연구,2021,"['Tip Vortex Cavitation(TVC', '날개 끝 보텍스 캐비테이션)', 'Cavitation Inception Speed(CIS', '캐비테이션 초생속력)', 'Convolution Neural Network(CNN', '합성곱 신경망)', 'Deep learning(딥러닝)', 'Image recognition(영상인식)']",국문 초록 정보 없음,"The main source of underwater radiated noise of ships is cavitation generated by propeller blades. After the Cavitation Inception Speed (CIS), noise level at all frequencies increases severely. In determining the CIS, it is based on the results observed with the naked eye during the model test, however accuracy and consistency of CIS values are becoming practical issues. This study was carried out with the aim of developing a technology that can automatically recognize cavitation images using deep learning technique based on a Convolutional Neural Network (CNN). Model tests on a three-dimensional hydrofoil were conducted at a cavitation tunnel, and tip vortex cavitation was strictly observed using a high-speed camera to obtain analysis data. The results show that this technique can be used to quantitatively evaluate not only the CIS, but also the amount and rate of cavitation from recorded images."
얼굴인식 기술을 적용한 실종자 식별 시스템 설계 및 구현,2021,"['Face recognition', 'Image Processing', 'Key point extraction', 'Missing Person', 'Similarity', 'Mobile', '얼굴인식', '영상처리', '특징점 검출', '실종자', '유사도', '모바일']","본 논문에서는 비전 기술과 딥러닝 기반의 얼굴인식을 통해 실종자를 식별하는 방법을 제안하였다. 모바일 디바이스에서 전송된 원본 이미지에 대해 얼굴인식에 적합하도록 이미지를 전처리한 후, 얼굴인식의 정확도 향상을 위한 이미지 데이터 증식과 CNN 기반 얼굴학습 및 검증을 통해 실종자를 인식하였다. 본 논문의 구현 결과를 이용하여 가상의 실종자 이미지를 식별한 결과, 원본 데이터와 블러 처리한 데이터를 함께 학습한 모델의 성능이 가장 우수하게 나왔다. 또한 사전학습된 가중치를 사용한 학습 모델은 사용하지 않은 모델보다 높은 성능을 보였지만, 편향과 분산이 높게 나오는 한계를 확인할 수 있었다.","In this paper proposes a method of finding missing persons based on face-recognition technology and deep learning. In this paper, a real-time face-recognition technology was developed, which performs face verification and improves the accuracy of face identification through data fortification for face recognition and convolutional neural network(CNN)-based image learning after the pre-processing of images transmitted from a mobile device. In identifying a missing person’s image using the system implemented in this paper, the model that learned both original and blur-processed data performed the best. Further, a model using the pre-learned Noisy Student outperformed the one not using the same, but it has had a limitation of producing high levels of deflection and dispersion."
Real-Time Multi-Person Action Recognition with a Neural Compute Stick,2021,"['action recognition', '3D convolutional neural network', 'neural compute stick', 'human-robot interaction']",국문 초록 정보 없음,"Deep learning has successfully boosted a performance of action recognition and inspired model developments for it. Specifically, 3D convolutional neural network (CNN) which best fits the purpose of vision-based action recognition has been applied to the task in various forms. In this paper, comprehensive research process for practical multi-person action recognition is presented. We perform various experiments using 3D CNN considering both performance and time efficiency. Distinguished from previous studies, we consider a performance on an embedded platform which consists of an embedded computer, ZED2 camera and a neural compute stick. The neural compute stick has its own memory and can be utilized asynchronously. This is a pioneer work proposing a multi-person action recognition framework using a neural compute stick. Step-by-step experiments verify a validity of the model configuration and the proposed framework."
시계열데이터 예측을 통한 주가예측 정확도 향상,2021,[],"본 논문은 기존의 주가 예측 모델을 개선하여 더 나은 예측 값을 갖도록 설계하였다. Long short term memory(LSTM), Gated recurrent unit (GRU) 외 Convolution neuron network (CNN)를 추가하여 시계열 데이터의 feature을 Recurrent neural network (RNN)에서 사용할 수 있게 구성하였다. 2007년부터 2021년 6월까지 총 3216개의 주가정보 데이터셋을 크롤링하여 사용하였으며 2513개의 train set 604개의 test set을 사용하여 훈련 하였다. 성능 평가에서는 Convolution neuron network (CNN) 을 사용해 개선한 모델이 0.0003287의 Round mean squared error (RMSE) 가 가장 낮은 값으로 2개의 기존 모델보다 나아진 성능을 보여준다.",다국어 초록 정보 없음
Self-Attention을 적용한 문장 임베딩으로부터 이미지 생성 연구,2021,"['자연어 처리', '이미지 생성', '적대적 신경망', 'Natural Language Processing', 'Image generation', 'Generative Adversarial Network']","사람이 어떤 문장을 보고 그 문장에 대해 이해하는 것은 문장 안에서 주요한 단어를 이미지로 연상시켜 그 문장에 대해 이해한다. 이러한 연상과정을 컴퓨터가 할 수 있도록 하는 것을 text-to-image라고 한다. 기존 딥 러닝 기반 text-to-image 모델은 Convolutional Neural Network(CNN)-Long Short Term Memory(LSTM), bi-directional LSTM을 사용하여 텍스트의 특징을 추출하고, GAN에 입력으로 하여 이미지를 생성한다. 기존 text-to-image 모델은 텍스트 특징 추출에서 기본적인 임베딩을 사용하였으며, 여러 모듈을 사용하여 이미지를 생성하므로 학습 시간이 오래 걸린다. 따라서 본 연구에서는 자연어 처리 분야에서 성능 향상을 보인 어텐션 메커니즘(Attention Mechanism)을 문장 임베딩에 사용하여 특징을 추출하고, 추출된 특징을 GAN에 입력하여 이미지를 생성하는 방법을 제안한다. 실험 결과 기존 연구에서 사용되는 모델보다 inception score가 높았으며 육안으로 판단하였을 때 입력된 문장에서 특징을 잘 표현하는 이미지를 생성하였다. 또한, 긴 문장이 입력되었을 때에도 문장을 잘 표현하는 이미지를 생성하였다.","When a person sees a sentence and understands the sentence, the person understands the sentence by reminiscent of the main word in the sentence as an image. Text-to-image is what allows computers to do this associative process. The previous deep learning-based text-to-image model extracts text features using Convolutional Neural Network (CNN)-Long Short Term Memory (LSTM) and bi-directional LSTM, and generates an image by inputting it to the GAN. The previous text-to-image model uses basic embedding in text feature extraction, and it takes a long time to train because images are generated using several modules. Therefore, in this research, we propose a method of extracting features by using the attention mechanism, which has improved performance in the natural language processing field, for sentence embedding, and generating an image by inputting the extracted features into the GAN. As a result of the experiment, the inception score was higher than that of the model used in the previous study, and when judged with the naked eye, an image that expresses the features well in the input sentence was created. In addition, even when a long sentence is input, an image that expresses the sentence well was created."
Novel Image Classification Method Based on Few-Shot Learning in Monkey Species,2021,"['Deep learning', 'Feature extraction', 'Few-shot learning', 'Image classification']",국문 초록 정보 없음,"This paper proposes a novel image classification method based on few-shot learning, which is mainly used to solve model overfitting and non-convergence in image classification tasks of small datasets and improve the accuracy of classification. This method uses model structure optimization to extend the basic convolutional neural network (CNN) model and extracts more image features by adding convolutional layers, thereby improving the classification accuracy. We incorporated certain measures to improve the performance of the model. First, we used general methods such as setting a lower learning rate and shuffling to promote the rapid convergence of the model. Second, we used the data expansion technology to preprocess small datasets to increase the number of training data sets and suppress over-fitting. We applied the model to 10 monkey species and achieved outstanding performances. Experiments indicated that our proposed method achieved an accuracy of 87.92%, which is 26.1% higher than that of the traditional CNN method and 1.1% higher than that of the deep convolutional neural network ResNet50."
Application of Statistical and Machine Learning Techniques for Habitat Potential Mapping of Siberian Roe Deer in South Korea,2021,"['Convolutional neural network algorithm', 'Frequency ratio method', 'Habitat potential map', 'Long short-term memory algorithm', 'Machine learning algorithms', 'Siberian roe deer']",국문 초록 정보 없음,"The study has been carried out with an objective to prepare Siberian roe deer habitat potential maps in South Korea based on three geographic information system-based models including frequency ratio (FR) as a bivariate statistical approach as well as convolutional neural network (CNN) and long short-term memory (LSTM) as machine learning algorithms. According to field observations, 741 locations were reported as roe deer's habitat preferences. The dataset were divided with a proportion of 70:30 for constructing models and validation purposes. Through FR model, a total of 10 influential factors were opted for the modelling process, namely altitude, valley depth, slope height, topographic position index (TPI), topographic wetness index (TWI), normalized difference water index, drainage density, road density, radar intensity, and morphological feature. The results of variable importance analysis determined that TPI, TWI, altitude and valley depth have higher impact on predicting. Furthermore, the area under the receiver operating characteristic (ROC) curve was applied to assess the prediction accuracies of three models. The results showed that all the models almost have similar performances, but LSTM model had relatively higher prediction ability in comparison to FR and CNN models with the accuracy of 76% and 73% during the training and validation process. The obtained map of LSTM model was categorized into five classes of potentiality including very low, low, moderate, high and very high with proportions of 19.70%, 19.81%, 19.31%, 19.86%, and 21.31%, respectively. The resultant potential maps may be valuable to monitor and preserve the Siberian roe deer habitats."
딥러닝을 이용한 스마트폰 녹음 여부 검출 포렌식,2021,"['Sound recording device forensics', 'Mel-spectrogram', 'Convolutional neural network', 'Smartphone']","사운드 녹음 장치 분류는 사운드 포렌식 기술 중에 하나로서 최근에는 딥러닝을 이용한 연구들이 진행되고 있다. 개별 녹음 장치 식별도 중요하고, 녹음 장치 종류의 구분도 유의미하다. 본 논문에서는 사운드에 대하여 스마트폰을 활용하여 녹음하였는지, 기타 장치들을 사용하여 녹음하였는지 검출하기 위한 포렌식 기술을 제안한다. Mel-spectrogram과 CNN 모델을 사용하는 딥러닝 기반의 알고리즘을 설계하였고, 실험을 통하여 제안한 알고리즘이 99.09%의 높은 정확도를 갖고 있음을 보였다.","The classification of sound recording devices is one of the sound forensic technologies, and recent studies using deep learning are being conducted. It is important to identify individual recording devices, and the classification of recording device types is also significant. In this paper, we propose a forensic technique to detect whether sound was recorded using a smartphone or other devices. A deep learning-based algorithm using Mel-spectrogram and CNN model is designed. Through experiments, it was shown that the proposed algorithm has a high accuracy of 99.09%."
Detection of OCT image Parameters Based on Deep Learning algorithm,2021,[],국문 초록 정보 없음,"In this article, we present a computerized detection of optical coherence tomography (OCT) image parameters using a deep learning method. To detect the parameters, Bruch’s membrane opening (BMO) and laminar cribrosa (LC) in OCT image, proposed system work with a convolutional neural network (CNN) algorithm. Herein, we designed detection method using YOLOv3 algorithm where darknet53 CNN used as a backbone network. We used OCT medical images for testing the detection performance. The excremental result for detection performance show that, 99.92% and 99.18% average detection precision of parameters BMO and LC, respectively on the testing image."
인공지능 기반 치주염 진단지원 모델 개발을 위한 후보모델 탐색 연구,2021,[],"본 연구에서는 치과 엑스레이 파노라마 이미지를 기반으로 인공지능 기술을 활용한 치주염 진단 지원 모델 개발을 위한 탐색 연구를 수행하였다. 치과 분야 인공지능 연구 현황과 적용할 후보 모델 알고리즘을 검토하였다. 샘플데이터를 기반으로 YOLO, Efficient Det, Faster-R CNN 알고리즘을 활용한 파일럿 연구를 수행하였다. 연구결과 적은 규모의 학습데이터임에도 불구하고 Faster R-CNN 기반알고리즘의 성능이 우수하였으며, 타 알고리즘과의 비교를 통해 RoI 예측이 치아의 치주염 수준별 객체 탐지에 있어 주요한 영향을 미침을 알 수 있었다. 이를 통해 향후 전체 데이터 셋을 대상으로 학습한 정교한 모델 구측 가능성을 확인하였다.",다국어 초록 정보 없음
GNSS 음영 지역에서의 정밀 위치추정을 위한 데이터셋,2021,"['Autonomous Driving(자율주행)', 'Dataset(데이터셋)', 'Object Detection(객체 인식)', 'Semantic Segmentation(시맨틱 분할)', 'Deep Learning(딥러닝)', 'GNSS(위성 항법 시스템)']","최근 도심, 지하차도 및 터널 등 Global Navigation Satellite System (GNSS) 수신 상태가 취약한 지역에서 자율주행에 필수적인 위치추정 기술의 수요가 증가함에 따라 단안 카메라 기반 위치 추정 연구가 활발하게 진행하고 있다. 2D 이미지 기반 객체 인식 분야에서 Convolutional Neural Networks(CNN)을 활용한 딥러닝 네트워크인 YOLOv3, EfficientDet, Fater R-CNN 등 객체의 클래스 및 바운딩 박스 정보를 추출해내는 연구가 활발히 진행되고 있으며, 시맨틱 분할 방법인 DeepLab, ENet, FCN 등을 활용하여 픽셀 별 클래스 분류를 수행하는 연구 또한 활발히 진행중이다. 이러한 딥러닝 기반 인공지능 구현에서 가장 중요한 것은 컴퓨터를 충분히 학습시킬 수 있는 다양한 학습 데이터이다. 하지만 국내 자율주행 시스템 개발을 위한 오픈소스 데이터는 해외의 데이터셋과 비교하여 매우 부족한 편이며 특히 GNSS정보는 수신이 어려운 지역에 대한 자료는 턱없이 부족한 상황이다. 따라서 본 논문에서는 GNSS 음영 지역에서의 정밀 위치추정을 위한 데이터셋을 구축하고자 한다. 본 데이터셋을 주행 시나리오에서 검출 가능한 다양한 랜드마크 중 위치추정 알고리즘에 활용될 수 있는 랜드마크를 선정하고, GNSS 정보의 신뢰성을 잃은 도심부, 터널 및 지하차도에서 영상 및 다양한 센서 데이터를 수집한다. 취득한 원천 데이터는 정제 및 크라우드소싱 기반 가공(labeling) 작업을 거쳐 양질의 인공지능 학습용 데이터로 변환된다.  마지막으로, 딥러닝 기술을 이용한 랜드마크 인식 알고리즘을 통해 학습 데이터의 유효성을 검증한다. 바운딩 박스 형태의 랜드마크에 대해서는 객체 인식 알고리즘을 적용하여 Average Precision (AP) 등의 지표를 통해 데이터셋의 유효성을 검증한다. 폴리곤 형태의 랜드마크에 대해서는 시맨틱 분할 방법을 적용하고 Intersection over Union (IoU)등의 지표를 통해 데이터셋의 유효성을 검증한다. 위 데이터셋을 활용한 이미지 랜드마크 인식 AI는 정밀 위치추정 알고리즘에 필요한 객체 인식 정보를 제공할 수 있다.",다국어 초록 정보 없음
합성곱 신경망을 사용한 미분된 활동전위 형상에 따른 약물의 부정맥 위험도 분류,2021,"['종합 체외 부정맥 분석(Comprehensive in vitro proarrhythmia assay', 'CiPA)', '약물 안정성 평가(Assessment of drug safety)', '부정맥 유발 위험성(Proarrhythmic risk)', '합성곱 신경망(Convolutional neural network)', '활동전위형상(action potential shapes)']",국문 초록 정보 없음,"CiPA projects for assessing proarrhythmic drugs suggested a logistic regression model using qNet as the Torsade de Pointes risk assessment biomarker, obtained from In-silico simulation. However, In-silico simulation requires high-performance computation resources and a lot of times. Thus, this study proposed a deep CNN model using differential action potential (AP) shapes to classify three proarrhythmic risk levels: high, intermediate, and low. We performed an In-silico simulation and got AP shapes with drug effects using IC50 and Hill coefficients of 28 drugs released by CiPA groups. Then, we trained the deep CNN model with the differential AP shapes of 12 drugs and tested it with those of 16 drugs. Our model had a better performance for classifying the proarrhythmic risk of drugs than the traditional logistic regression model using qNet. The classification accuracy was 98% for high-risk level drugs, 94% for intermediate-risk level drugs, and 89% for low-risk level drugs."
비전 트랜스포머를 활용한 이미지 분류 시스템 설계,2021,"['Image Classification', 'Vision Transformer', 'CIFAR-10', 'Convolutional Neural Network']","트랜스포머(Transformer)는 자연어 처리 분야에서 괄목할 만한 성과를 내어 왔다. 이러한 트랜스포머의 기능을 트랜스포머를 이미지 분류와 같은 다른 분야에 적용하는 연구가 최근 진행되고 있다. 본 연구에서는 이미지 데이터를 학습하여 해당 이미지를 분류하는 비전 트랜스포머 모델을 설계하고 구현하였다. 비전 트랜스포머(Vision Transformer ; ViT) 모델은 합성곱 신경망(Convolutional Neural Network ; CNN)을 사용하는 대신 어텐션 메커니즘 (Attention Mechanism)을 이미지 분류에 적용하여 계산비용을 크게 줄였다. 비전 트랜스포머의 설계를 검증하기 위해, CIFAR-10 데이터와 CIFAR-100 데이터를 벤치마크 데이터로 사용하였다. 실험 결과, 설계된 비전 트랜스포머를 향후 이미지 분류에 활용할 만한 가능성을 발견할 수 있었다.","We have seen remarkable achievements of Transformer in natural language processing fields. Recently, there have been research conducted for applying Transformer for other fields like image classification. In this paper, we design and implement vision transformer model that trains image data for classification. Vision Transformer (ViT) model significantly reduces the computational cost of training image classifiers by applying attention mechanism instead of using a convolutional neural network (CNN). To evaluate our design of Vision Transformer, we use CIFAR-10 and CIFAR-100 as benchmark datasets. From the experiment results, we discover the possibility of utilizing our Vision Transformer design for image classification tasks in the future."
Wavelet 기반의 영상 디테일 향상 잡음 제거 네트워크,2021,"['Image Denoising', 'Convolutional Neural Network', 'Wavelet Transform', 'Detail Enhancement']",국문 초록 정보 없음,"Although the performance of cameras is gradually improving now, there are noise in the acquired digital images from the camera, which acts as an obstacle to obtaining high-resolution images. Traditionally, a filtering method has been used for denoising, and a convolutional neural network (CNN), one of the deep learning techniques, has been showing better performance than traditional methods in the field of image denoising, but the details in images could be lost during the learning process. In this paper, we present a CNN for image denoising, which improves image details by learning the details of the image based on wavelet transform. The proposed network uses two subnetworks for detail enhancement and noise extraction. The experiment was conducted through Gaussian noise and real-world noise, we confirmed that our proposed method was able to solve the detail loss problem more effectively than conventional algorithms, and we verified that both objective quality evaluation and subjective quality comparison showed excellent results."
머신러닝 기반 음성분석을 통한 체질량지수 분류 예측 - 한국 성인을 중심으로,2021,"['Machine learning', 'Voice', 'Body Mass Index', 'Convolutional neural network']",국문 초록 정보 없음,"Objectives The purpose of this study was to check whether the classification of the individual's Body Mass Index (BMI) could be predicted by analyzing the voice data constructed at the Korean medicine data center (KDC) using machine learning. Methods In this study, we proposed a convolutional neural network (CNN)-based BMI classification model. The subjects of this study were Korean adults who had completed voice recording and BMI measurement in 2006-2015 among the data established at the Korean Medicine Data Center. Among them, 2,825 data were used for training to build the model, and 566 data were used to assess the performance of the model. As an input feature of CNN, Mel-frequency cepstral coefficient (MFCC) extracted from vowel utterances was used. A model was constructed to predict a total of four groups according to gender and BMI criteria: overweight male, normal male, overweight female, and normal female. Results & Conclusions Performance evaluation was conducted using F1-score and Accuracy. As a result of the prediction for four groups, The average accuracy was 0.6016, and the average F1-score was 0.5922. Although it showed good performance in gender discrimination, it is judged that performance improvement through follow-up studies is necessary for distinguishing BMI within gender. As research on deep learning is active, performance improvement is expected through future research."
A Three-Dimensional Deep Convolutional Neural Network for Automatic Segmentation and Diameter Measurement of Type B Aortic Dissection,2021,"['Aortic dissection', 'Tomography', 'X-ray computed', 'Deep learning']",국문 초록 정보 없음,"Objective: To provide an automatic method for segmentation and diameter measurement of type B aortic dissection (TBAD).Materials and Methods: Aortic computed tomography angiographic images from 139 patients with TBAD were consecutively collected. We implemented a deep learning method based on a three-dimensional (3D) deep convolutional neural (CNN) network, which realizes automatic segmentation and measurement of the entire aorta (EA), true lumen (TL), and false lumen (FL). The accuracy, stability, and measurement time were compared between deep learning and manual methods. The intra- and inter-observer reproducibility of the manual method was also evaluated.Results: The mean dice coefficient scores were 0.958, 0.961, and 0.932 for EA, TL, and FL, respectively. There was a linear relationship between the reference standard and measurement by the manual and deep learning method (r = 0.964 and 0.991, respectively). The average measurement error of the deep learning method was less than that of the manual method (EA, 1.64% vs. 4.13%; TL, 2.46% vs. 11.67%; FL, 2.50% vs. 8.02%). Bland-Altman plots revealed that the deviations of the diameters between the deep learning method and the reference standard were -0.042 mm (-3.412 to 3.330 mm), -0.376 mm (-3.328 to 2.577 mm), and 0.026 mm (-3.040 to 3.092 mm) for EA, TL, and FL, respectively. For the manual method, the corresponding deviations were -0.166 mm (-1.419 to 1.086 mm), -0.050 mm (-0.970 to 1.070 mm), and -0.085 mm (-1.010 to 0.084 mm). Intra- and inter-observer differences were found in measurements with the manual method, but not with the deep learning method. The measurement time with the deep learning method was markedly shorter than with the manual method (21.7 ± 1.1 vs. 82.5 ± 16.1 minutes, p < 0.001).Conclusion: The performance of efficient segmentation and diameter measurement of TBADs based on the 3D deep CNN was both accurate and stable. This method is promising for evaluating aortic morphology automatically and alleviating the workload of radiologists in the near future."
CAM 기반의 계층적 및 수평적 분류 모델을 결합한 운전자 부주의 검출 및 특징 영역 지역화,2021,"['Distracted Driver Detection', 'Convolutional Neural Networks', 'Class Activation Maps', 'Attention Area Localization', '운전자 부주의 검출', '합성곱신경망', 'CAM', 'Class Activation Map', '주의영역 지역화']",국문 초록 정보 없음,"Driver negligence accounts for the largest proportion of the causes of traffic accidents, and research to detect them is continuously being conducted. This paper proposes a method to accurately detect a distracted driver and localize the most characteristic parts of the driver. The proposed method hierarchically constructs a CNN basic model that classifies 10 classes based on CAM in order to detect driver distration and 4 subclass models for detailed classification of classes having a confusing or common feature area in this model. The classification result output from each model can be considered as a new feature indicating the degree of matching with the CNN feature maps, and the accuracy of classification is improved by horizontally combining and learning them. In addition, by combining the heat map results reflecting the classification results of the basic and detailed classification models, the characteristic areas of attention in the image are found. The proposed method obtained an accuracy of 95.14% in an experiment using the State Farm data set, which is 2.94% higher than the 92.2%, which is the highest accuracy among the results using this data set. Also, it was confirmed by the experiment that more meaningful and accurate attention areas were found than the results of the attention area found when only the basic model was used."
전이학습기반 앙상블 딥러닝을 이용한 COVID-19 환자 영상 분류,2021,"['딥러닝', '스태킹 앙상블', '전이학습', 'X-ray/CT 영상', 'COVID-19', 'deep learning', 'stacking ensemble', 'transfer learning', 'X-ray/CT image']","COVID-19 팬데믹으로 인한 피해는 공중 보건적 측면 뿐 만 아니라 정치, 경제, 사회, 문화 전반에 심각한 영향을 미치고 있다. 현재까지 COVID-19 표준 진단검사인 RT-PCR 검사는 검체의 종류, 검체 채취 방법 및 보관에 따라 검사 결과가 달라질 수 있고 코로나바이러스 (SARS-CoV-2) 감염 후 검사 시점에도 영향을 받는다. 본 논문은 전이학습 (transfer learning) 기반 앙상블 딥러닝을 사용하여 COVID-19 환자 X-ray/CT 영상을 분류하고자 한다. 여기서 사용된 전이학습은 CNN (convolutional neural network) 기반인 AlexNet, ResNet, Inception V3, DenseNet 모형이다. 본 연구에서 제안한 스태킹 앙상블 (stacking ensemble) 모형은 세 단계에 걸쳐 이루어진다. 첫 번째 단계에서는 기본모형 (base model)로서 여러 전이학습 모형을 이용하여 예측된 결과들을 얻고, 두 번째 단계에서는 concatenate layer를 통해 이들 결과들을 결합한 다음, 세 번째 단계에서는 메타모형(meta model), 여기서는 DNN (deep neural network) 모형을 적용하여 최종 분류한다. 본 논문에서 제안된 앙상블 모형의 성능평가를 위해 3가지 실제 COVID-19 환자의 X-ray/CT 영상데이터셋을 고려하였으며 여러 가지 성능평가 지표를 가지고 기존의 전이학습 모형과 앙상블 모형과 비교 분석하였다. 성능실험결과, 전반적으로 제안된 앙상블 모형이 기존의 전이학습 모형과 앙상블 모형보다 우수함을 보였다.","The damage caused by the COVID-19 pandemic has a serious impact not only on public health but also on politics, economy, society, and culture as a whole. To date, the RT-PCR test, a COVID-19 standard diagnostic test, may vary depending on the type of sample, sample collection method, and storage, and is also affected by the time of the test after infection with COVID-19. This paper attempts to classify COVID-19 patients with X-ray/CT images using transfer learning-based ensemble deep learning. The transfer learning used here is the AlexNet, ResNet, Inception V3, and DenseNet models based on the convolutional neural network (CNN). The stacking ensemble model proposed in this study takes place over three stages. In the first step, predicted results are obtained using several transfer learning models, in the second step, they are combined through a concatenate layer, and in the third step, a deep neural network (DNN) model is applied and finally classified. For the performance evaluation of the ensemble model proposed in this paper, three actual COVID-19 X-ray/CT image datasets were considered, and various performance evaluation indicators were compared and analyzed with the transfer learning model and the existing ensemble model. As a result of the performance experiment, the overall proposed ensemble model was superior to the transfer learning model and the existing ensemble model."
특허문서 자동분류를 위한 딥러닝 개별 모델 분류기와 앙상블 분류기의 성능비교,2021,"['Patent classification', 'Ensemble', 'Deep learning']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝 기반의 객체 검출 알고리즘을 활용한 야생동물 객체인식 기초 연구 -국립공원 생태통로 무인센서카메라 영상을 중심으로-,2021,[],"국립공원공단은 무인센서카메라(Camera-trap)를 통하여 야생동물 데이터가 수집되면 직원이 육안 판독하는 방식의 야생동물 현황 모니터링 체계를 운용하고 있다. 국립공원 내 생물종 감지 카메라는 2020년 기준 322대가 설치되어 있으며 이 중국립공원 생태통로 모니터링 무인센서카메라는 73대가 설치·운용 중에 있다. 그러나 현행 야생동물 모니터링 조사방법은 직원 육안판독으로 장시간이 소요되며, 조사품질의 일관성 유지가 어려운 한계가 존재한다.최근 딥러닝 기술은 컴퓨터 비전(Computer Vision) 분야에서 탁월한 성능으로 부각되고 있으며 딥러닝 알고리즘 중 합성곱 신경망(Convolutional Neural Network;CNN)은 객체 분류 및 탐지 기능에서 정확성 및 신속성을 인정받고 있다(이소영 등, 2019). 이러한 단순 반복적인 현행 조사방법을 개선하기 위하여 이미지나 동영상을 입력하면 데이터 패턴을 인식하여 자동으로 분류결과를 산출하는 딥러닝 기술을 활용한 연구가 필요하다.야생동물 모니터링 체계 개선을 위한 딥러닝 활용 선행연구로 국립공원공단 소백산국립공원북부사무소에서는 2018년 딥러닝을 통한 야생동물 자동식별 시험을 진행하여 딥러닝 활용 가능성을 확인하고 제39차 아시아 원격탐사학술대회 혁신상을 수상하는 등 공단 자체 연구 수행능력을 검증하였다. 본 연구는 이전 시험결과를 바탕으로 야생동물 모니터링 업무 지원을 위한 자동화된 소프트웨어를 개발하여 야생동물 모니터링 조사시간을 단축하고 인적오류 최소화 및 정확도 향상에 기여하는데 그 목적이 있다.본 연구에서는 야생동물 객체인식을 위하여 딥러닝 기반의 합성곱 신경망 객체 검출 알고리즘 사례 분석을 실시하였으며 2-stage 객체 검출방식인 R-CNN 기반의 MegaDetector 모델과 1-stage 객체 검출방식인 YOLOv5s 2가지 알고리즘을 선정하였다. MegaDetector 모델은 동물, 사람, 차량을 감지하도록 대규모 데이터셋이 학습되어 있으며 1-stage 객체 검출방식보다 정확도가 높으나 속도가 느리며, YOLOv5s는 backbone의 크기가 가장 작지만 2-stage 객체 검출방식보다 빠른 성능을 보이나 작은 물체에 대해 낮은 정확도를 보이는 특징이 있다.연구지역은 국립공원 생태통로 운영·관리 현황 및 무인센서 카메라 설치현황을 토대로 소백산국립공원 죽령생태통로와 설악산국립공원 한계령생태통로 2개소를 선정하였다. 선정된 연구지역에 설치된 무인센서카메라로 쵤영 후 판독을 완료한 야생동물 모니터링 자료를 수집하였으며 야생동물 22종에 대한 총 32,213장의 학습데이터를 구축하였다. 이 중 종별 국립공원 생태통로 이용횟수와 학습데이터 구축 비율을 고려하여 딥러닝학습 대상종으로 고라니, 멧돼지, 노루, 오소리 총 4종을 선정하고 딥러닝 알고리즘 학습을 각각 수행하였으며 동영상 70개의 시험용 데이터셋을 통해 그 결과를 도출하였다.연구결과, MegaDetector 모델은 멧돼지 95.8%, 고라니 74%의 정확도를 보였으며 YOLOv5s는 고라니 80%, 멧돼지 70%의 정확도를 보였다. 노루의 경우 고라니와 외형적 구분이 모호하여 2개 알고리즘 모두에서 정확도가 매우 낮게 나타나, 향후 특징이 명확히 드러나는 영상에 대한 학습데이터 구축 및 추가 학습을 통해 정확도를 높일 계획이다.",다국어 초록 정보 없음
A Study on Security Event Detection in ESM Using Big Data and Deep Learning,2021,"['Intrusion Detection Systems', 'Enterprise Security Management', 'Convolutional Neural Network Intrusion Prevention System']",국문 초록 정보 없음,"As cyber attacks become more intelligent, there is difficulty in detecting advanced attacks in various fields such as industry, defense, and medical care. IPS (Intrusion Prevention System), etc., but the need for centralized integrated management of each security system is increasing. In this paper, we collect big data for intrusion detection and build an intrusion detection platform using deep learning and CNN (Convolutional Neural Networks). In this paper, we design an intelligent big data platform that collects data by observing and analyzing user visit logs and linking with big data. We want to collect big data for intrusion detection and build an intrusion detection platform based on CNN model. In this study, we evaluated the performance of the Intrusion Detection System (IDS) using the KDD99 dataset developed by DARPA in 1998, and the actual attack categories were tested with KDD99's DoS, U2R, and R2L using four probing methods."
무인항공기의 자동 착륙을 위한 LSM 및 CPA를 활용한 영상 기반 장애물 상태 추정 및 충돌 예측,2021,"['Autonomous Precision Landing', 'Collision Prediction', 'Closest Point of Approach', 'Least-Squares Method', 'State Estimation']","무인항공기의 영상 기반 자동 정밀 착륙 기술은 착륙 지점에 대한 정밀한 위치 추정 기술과 착륙 유도 기술이 요구된다. 또한, 안전한 착륙을 위하여 지상 장애물에 대한 착륙 지점의 안전성을 판단하고, 안전성이 확보된 경우에만 착륙을 유도하도록 설계되어야 한다. 본 논문은 자동 정밀 착륙을 수행하기 위하여 영상 기반의 항법과 착륙 지점의 안전성을 판단하기 위한 알고리즘을 제안한다. 영상 기반 항법을 수행하기 위해 CNN 기법을 활용하여 착륙 패드를 탐지하고, 탐지 정보를 활용하여 통합 항법 해를 도출한다. 또한, 위치 추정 성능을 향상시키기 위한 칼만필터를 설계 및 적용한다. 착륙 지점의 안전성을 판단하기 위하여 동일한 방식으로 장애물 탐지 및 위치 추정을 수행하고, LSM을 활용하여 장애물의 속도를 추정한다. 추정한 장애물의 상태를 활용하여 계산한 CPA를 기반으로 장애물과의 충돌 여부를 판단한다. 최종적으로 본 논문에서 제안된 알고리즘을 비행 실험을 통해 검증한다.","Vision-based autonomous precision landing technology for UAVs requires precise position estimation and landing guidance technology. Also, for safe landing, it must be designed to determine the safety of the landing point against ground obstacles and to guide the landing only when the safety is ensured. In this paper, we proposes vision-based navigation, and algorithms for determining the safety of landing point to perform autonomous precision landings. To perform vision-based navigation, CNN technology is used to detect landing pad and the detection information is used to derive an integrated navigation solution. In addition, design and apply Kalman filters to improve position estimation performance. In order to determine the safety of the landing point, we perform the obstacle detection and position estimation in the same manner, and estimate the speed of the obstacle using LSM. The collision or not with the obstacle is determined based on the CPA calculated by using the estimated state of the obstacle. Finally, we perform flight test to verify the proposed algorithm."
화상 강의 집중도 관리 시스템 : Eyes On You,2021,"['COVID-19', 'non-face-to-face', 'video lecture', 'concentration', 'eye tracking', 'sentiment analysis']","화상 강의는 대면 강의에 비해 참여자들의 집중도가 낮아지는 단점이 있다. 강의자가 효과적으로 정보를 전달하기 위해서는 우선 참여자의 집중을 필요로 하고 강의자는 이를 확인하며 강의를 진행할 필요가 있는데, 비대면 상황에서는 참여자를 일일이 관리하기 어렵기 때문이다. 이러한 문제점을 해결하기 위해 본 논문에서는 화상강의 참여자의 집중도를 산정하고 이를 강의자에게 보여주는 집중도 관리 시스템 ‘Eyes On You""를 제안한다. 이 시스템에서는 Eye Tracking, OpenCV, CNN 등의 기술을 사용해 더욱 신뢰도 있는 결과를 도출한다. 이를 바탕으로 강의자와 참여자 모두에게 질 높은 강의를 제공하며, 다양한 방면으로 활용될 수 있다.","Video lectures have a disadvantage of reducing the concentration of participants compared to face-to-face lectures. In order for a lecturer to deliver information effectively, he/she first needs to concentrate on participants, and the lecturer needs to check it and conduct the lecture, because it is difficult to manage each participant in non-face-to-face situations. To address this problem, in this paper, we propose a concentration level management system ""Eyes On You"", which calculates the concentration of participants in video lectures and shows them to instructors. In this system, techniques such as Eye Tracking, OpenCV, and CNN are used to produce more reliable results. Based on this, it provides high-quality lectures to both lecturers and participants, and can be used in various ways."
Efficient Deep Learning Model for Data-Limited Modulation Recognition,2021,[],국문 초록 정보 없음,"Deep learning (DL) has been successfully applied for modulation recognition tasks. Most of the existing applications pay little attention to the volume of data used. In reality, real historic data for modulation recognition could be limited. Thus it is better to train recognition models on small amounts of data. This is however a huge challenge, since the performance of DL models depend on sufficient data. In this paper, we introduce an efficient system model based on CNN and different data augmentation methods, for the purpose of modulation recognition. Our system employs random rotation, flip, zoom, random shift and resize methods for data augmentation. The CNN model employs small filter sizes, pooling layers, and dropout layers to improve the network. We apply a small dataset consisting of 40 constellation images per modulation type, to the system. We further analyze the performance based on three data augmentation intervals. From our experiments, the model achieved an accuracy of 32% without data augmentation and 76.07%, 35.71% and 96.42% on the three data-augmentation intervals."
음향 장면 분류를 위한 경량화 모형 연구,2021,"['acoustic scene classification', 'light-weight model', 'deep learning', 'convolutional neural network', '음향 장면 분류', '경량화 모델', '딥러닝', '합성곱 신경망']","음향 장면 분류는 오디오 파일이 녹음된 환경이 어디인지 분류하는 문제이다. 이는 음향 장면 분류와 관련한 대회인 DCASE 대회에서 꾸준하게 연구되었던 분야이다. 실제 응용 분야에 음향 장면 분류 문제를 적용할 때, 모델의 복잡도를 고려하여야 한다. 특히 경량 기기에 적용하기 위해서는 경량 딥러닝 모델이 필요하다. 우리는 경량 기술이 적용된 여러 모델을 비교하였다. 먼저 log mel-spectrogram, deltas, delta-deltas 피쳐를 사용한 합성곱 신경망(CNN) 기반의 기본 모델을 제안하였다. 그리고 원래의 합성곱 층을 depthwise separable convolution block, linear bottleneck inverted residual block과 같은 효율적인 합성곱 블록으로 대체하고, 각 모델에 대하여 Quantization를 적용하여 경량 모델을 제안하였다. 경량화 기술을 고려한 모델은 기본 모델에 대비하여 성능이 비슷하거나 조금 낮은 성능을 보였지만, 모델 사이즈는 503KB에서 42.76KB로 작아진 것을 확인하였다.","Acoustic scene classification (ASC) categorizes an audio file based on the environment in which it has been recorded. This has long been studied in the detection and classification of acoustic scenes and events (DCASE). In this study, we considered the problem that ASC faces in real-world applications that the model used should have low-complexity. We compared several models that apply light-weight techniques. First, a base CNN model was proposed using log mel-spectrogram, deltas, and delta-deltas features. Second, depthwise separable convolution, linear bottleneck inverted residual block was applied to the convolutional layer, and Quantization was applied to the models to develop a low-complexity model. The model considering low-complexity was similar or slightly inferior to the performance of the base model, but the model size was significantly reduced from 503 KB to 42.76 KB."
분리형 에어컨의 고장 진단을 위한 다양한 머신러닝 기법의 성능 비교에 관한 연구,2021,"['Separate type air conditioner (분리형 에어컨)', 'Machine learning (기계 학습)', 'Steady state detector (정상상태 검출기)', 'Fault diagnosis (고장 진단)']",국문 초록 정보 없음,다국어 초록 정보 없음
MobileNetV2 기술을 이용한 색소 세포성 모반과 악성 흑색종 Dermatoscopic 영상의 이진 분류,2021,[],"색소 세포성 모반과 악성 흑색종은 형태가 유사하지만 유해성의 측면에서 악성 흑색종은 암으로써 무해한 색소 세포성 모반에 비해 위험한 질환이다. 이에 기반하여 기존 연구에서 색소 세포성 모반과 악성 흑색종을 구분하기 위한 연구가 있었지만, 데이터를 취득하는 과정에서 많은 cost 가 필요하였다. 본 연구에서는 이를 개선하기 위해 두 병변의 dermatoscopic 영상을 분류 학습의 데이터로 사용하여 연구를 진행하였다. 학습을 위한 데이터는 오픈소스 dermatoscopic 데이터셋인 HAM10000 을 사용하였으며 모델은 CNN 에서 개선된 MobileNetV2 를 사용하였다. 실험 결과, MobileNetV2 를 사용한 학습은 3-layer CNN 에 비해 15 분의 1 가량 적은 파라미터를 가졌으며, 검증 성능과 테스트 성능에서 93%에 근사하는 성능을 보였다. 본 연구는 이전 연구에 비해 cost 측면에서 큰 개선을 이루었으며, 상용화 가능한 분류 기법을 발견했다는 점을 시사한다.",다국어 초록 정보 없음
Codeless Deep Learning of COVID-19 Chest X-Ray Image Dataset with KNIME Analytics Platform,2021,"['COVID-19', 'Mass Chest X-Ray', 'Diagnosis', 'Computer Assisted', 'Deep Learning', 'KNIME']",국문 초록 정보 없음,"Objectives: This paper proposes a method for computer-assisted diagnosis of coronavirus disease 2019 (COVID-19) throughchest X-ray imaging using a deep learning model without writing a single line of code using the Konstanz Information Miner(KNIME) analytics platform. Methods: We obtained 155 samples of posteroanterior chest X-ray images from COVID-19open dataset repositories to develop a classification model using a simple convolutional neural network (CNN). All of theimages contained diagnostic information for COVID-19 and other diseases. The model would classify whether a patient wasinfected with COVID-19 or not. Eighty percent of the images were used for model training, and the rest were used for testing.The graphic user interface-based programming in the KNIME enabled class label annotation, data preprocessing, CNNmodel training and testing, performance evaluation, and so on. Results: 1,000 epochs training were performed to test thesimple CNN model. The lower and upper bounds of positive predictive value (precision), sensitivity (recall), specificity, andf-measure are 92.3% and 94.4%. Both bounds of the model’s accuracies were equal to 93.5% and 96.6% of the area under thereceiver operating characteristic curve for the test set. Conclusions: In this study, a researcher who does not have basic knowledgeof python programming successfully performed deep learning analysis of chest x-ray image dataset using the KNIME independently.The KNIME will reduce the time spent and lower the threshold for deep learning research applied to healthcare."
인공지능 모델을 이용한 공작기계의 스핀들 고장 진단,2021,"['Fault Diagnosis(고장 진단)', 'Artificial Intelligence(인공지능)', 'Spindle(스핀들)']","정보통신기술(ICT)의 발전은 전통적인 제조 분야의 혁신을 가속화시키고 있고, 스마트팩토리로 불리우는 최첨단 공장에서는 각종 센서를 통해 실시간으로 데이터를 수집하고 있다. 이러한 수집된 데이터에 인공지능 기술을 적용하여 기계 고장 상황에 빠르게 대처하는 연구가 최근 들어 많은 관심을 받고 있다. 본 연구에서는 공작기계 스핀들의 고장 진단을 목적으로 인공지능 기술의 적용 가능성을 확인하기 위해 테스트벤치를 구축한 후 볼트를 이용하여 인위적으로 스핀들의 편심을 변화시킨 고장 데이터를 수집하였고, 분류(classification) 문제에 주로 사용되는 인공지능 모델 3종(CNN, LSTM, auto-encoder)을 학습하여 스핀들의 7가지 상태를 분류하는 정확도를 비교 분석하였다. 또한, 공작기계 도메인에 인공지능 기술을 효과적으로 적용하기 위해 필요한 데이터 수집 및 처리방법과 모델 개발 방법을 제안한다.","The development of information and communication technology (ICT) is accelerating innovation in the traditional manufacturing sector. The smart factory which is a state-of-the-art factory collects data in real time through various sensors. Recently, researches on applying the artificial intelligence technology to these collected data to detect machine failures has gained a lot of attention. In this study, we built a test bench to check the possibility of applying the artificial intelligence technology for the fault diagnosis of the spindle of machine tools. We collected failure data by changing the off-center of the spindle using bolts. Further, we used artificial intelligence models (CNN, LSTM, and auto-encoder) to analyze the accuracy of seven types of fault classifications. In addition, the method of data collection, data process, and model development is proposed to effectively apply the artificial intelligence technology to machine tool domains."
Development of a Hybrid Deep-Learning Model for the Human Activity Recognition based on the Wristband Accelerometer Signals,2021,"['Activities of Daily Living', 'Human Activity Recognition', 'Smartwatch', 'Accelerometer', 'Machine Learning', 'Activity Classification', 'Feature Extraction', 'Feature Reduction']",국문 초록 정보 없음,"This study aims to develop a human activity recognition (HAR) system as a Deep-Learning (DL) classification model, distinguishing various human activities. We solely rely on the signals from a wristband accelerometer worn by a person for the user's convenience. 3-axis sequential acceleration signal data are gathered within a predefined time-window-slice, and they are used as input to the classification system. We are particularly interested in developing a Deep-Learning model that can outperform conventional machine learning classification performance. A total of 13 activities based on the laboratory experiments' data are used for the initial performance comparison. We have improved classification performance using the Convolutional Neural Network (CNN) combined with an auto-encoder feature reduction and parameter tuning. With various publically available HAR datasets, we could also achieve significant improvement in HAR classification. Our CNN model is also compared against Recurrent-Neural-Network(RNN) with Long Short-Term Memory(LSTM) to demonstrate its superiority. Noticeably, our model could distinguish both general activities and near-identical activities such as sitting down on the chair and floor, with almost perfect classification accuracy."
Application of qNet Variability Through the Convolution Neural Network for Assessment of Drug Proarrhythmicity,2021,"['CiPA', 'Machine Learning', 'Convolutional Neural Network']",국문 초록 정보 없음,"As part of the Comprehensive in vitro Proarrhythmia Assay initiative, methodologies for predicting the incidence of Torsade de Pointes (TdP) by drugs were recently developed, leading to the importance of assessment using In-silico simulations. We performed the In-silico simulation using the ventricular cell model suggested by Sara Dutta using IC50 and hill coefficient as the input that we got from the In-vitro experiment of drug-response of ion channels. From the In-silico simulation, we obtained the qNet variability according to pace. To increase drug toxicity evaluation performance, we proposed deep CNN model utilized the qNet variability as an input and classify into high-risk, intermediate-risk, and low-risk. We trained the model with 12 drugs and tested it with the remaining 16 drugs. In the high-risk , the proposed CNN model had an AUC of 0.90, 0.75 in the intermediate-risk, and 0.82 in the low-risk."
Use of Deep Learning Image Classification Models and Vehicle Mounted Cameras for Automatic Pavement Pothole Detection,2021,"['Pavement Distress Detection', 'Urgent Maintenance', 'Deep Learning Image Classification', 'Vehicle Mounted Camera']",국문 초록 정보 없음,"PURPOSES : This study uses deep learning image classification models and vehicle-mounted cameras to detect types of pavement distress — such as potholes, spalling, punch-outs, and patching damage — which require urgent maintenance. METHODS : For the automatic detection of pavement distress, the optimal mount location on a vehicle for a regular action camera was first determined. Using the orthogonal projection of obliquely captured surface images, morphological operations, and multi-blob image processing, candidate distressed pavement images were extracted from road surface images of a 16,036 km in-lane distance. Next, the distressed pavement images classified by experts were trained and tested for evaluation by three deep learning convolutional neural network (CNN) models: GoogLeNet, AlexNet, and VGGNet. The CNN models were image classification tools used to identify and extract the combined features of the target images via deep layers. Here, a data augmentation technique was applied to produce big distress data for training. Third, the dimensions of the detected distressed pavement patches were computed to estimate the quantity of repair materials needed. RESULTS : It was found that installing cameras 1.8 m above the ground on the exterior rear of the vehicle could provide clear pavement surface images with a resolution of 1 cm per pixel. The sensitivity analysis results of the trained GoogLeNet, AlexNet, and VGGNet models were 93 %, 86 %, and 72 %, respectively, compared to 62.7 % for the dimensional computation. Following readjustment of the image categories in the GoogLeNet model, distress detection sensitivity increased to 94.6 %. CONCLUSIONS : These findings support urgent maintenance by sending the detected distressed pavement images with the dimensions of the distressed patches and GPS coordinates to local maintenance offices in real-time."
Blockchain Assisted Unauthorized Target Localization for C4I Communication Network Using Convolution Neural Network,2021,"['Blockchain', 'convolution neural network', 'C4I', 'target localization']",국문 초록 정보 없음,"Data security, data integrity and access control are the major challenge of the C4I (command, control, communications, computer and intelligence) system. Motivated by this issue, the paper has introduced a block-chain assisted intelligent framework to authenticate and localize the unauthorized object in the surveillance area. The proposed scheme has used blockchain to deny the third party access, data falsification and intruder attacks and informs to the central control server (CCS). Concurrently, CCS received the radio frequency signal transmitted by the antenna array element to estimate the direction of arrival (DoA) to localize the unauthorized object. Hence, we design a signal model for the received signal which is processed through the convolution neural network (CNN). We also propose a CNN model, where number of layers and filters are adjusted to integrate large number of dataset and extracted features pools to output layer. According to the simulation results, the proposed algorithm outperforms to estimate DoA with their respective sources and generate spatial pseudo-spectrum with high signalto- noise ratio."
뉴로모픽 구조 기반 FPGA 임베디드 보드에서 이미지 분류 성능 향상을 위한 특징 표현 방법 연구,2021,"['뉴로모픽 아키텍처', '이산 코사인 변환', '이미지 재조정', '임베디드 뉴로모픽 보드', 'Neuromorphic architecture', 'Discrete Cosine Transform', 'Image Reduction', 'Embedded Neuromorphic Boards']",국문 초록 정보 없음,"Neuromorphic architecture is drawing attention as a next-generation computing that supports artificial intelligence technology with low energy. However, FPGA embedded boards based on Neuromorphic architecturehave limited resources due to size and power. In this paper, we compared and evaluated the image reduction method using the interpolation method that rescales the size without considering the feature points and the DCT (Discrete Cosine Transform) method that preserves the feature points as much as possible based on energy. The scaled images were compared and analyzed for accuracy through CNN (Convolutional Neural Networks) in a PC environment and in the Nengo framework of an FPGA embedded board.. As a result of the experiment, DCT based classification showed about 1.9% higher performance than that of interpolation representation in both CNN and FPGA nengo environments. Based on the experimental results, when the DCT method is used in a limited resource environment such as an embedded board, a lot of resources are allocated to the expression of neurons used for classification, and the recognition rate is expected to increase."
Assessment of Drug Proarrhythmicity using APD 90 variability,2021,"['CiPA', 'Cardiac Simulation', 'Machine Learning']",국문 초록 정보 없음,"Proarrhythmia occurs when a new arrhythmia or an exacerbation of an existing arrhythmia arises during treatment with a drug at a concentration that is generally not to be toxic. Early prediction of the risk of drugs that will induce proarrhythmia potentially prevents long-term complications and sudden cardiac death. Methodologies to classify the risk level of drugs have been developed based on Comprehensive in vitro Proarrhythmia Assay (CiPA) guidelines. In this study, we use experimental data of 28 drugs to develop an assessment system of drug proarrythmicity using 1-D Convolutional Neural Network (1-D CNN) based on Action Potential Duration (APD 90) variability. The dataset is divided into two groups: 12 drugs as training set and 16 drugs as testing dataset. Ten-fold cross-validation is used to evaluate the performance of the proposed 1-D CNN in classifying drugs that will induce Proarrhythmia into low, intermediate, and high-risk levels. After testing the test datasets 10000 times, the median AUC scores obtained for high, intermediate, and low-risk levels are 0.83, 0.83, and 0.95 respectively. Based on the performance results, the proposed model shows promising results to evaluate drug toxicity."
Major concerns regarding food services based on news media reports during the COVID-19 outbreak using the topic modeling approach,2021,"['COVID-19', 'food services', 'news media', 'text analytics', 'topic modeling']",국문 초록 정보 없음,"BACKGROUND/OBJECTIVES: Coronavirus disease 2019 (COVID-19) cases were first reported in December 2019, in China, and an increasing number of cases have since been detected all over the world. The purpose of this study was to collect significant news media reports on food services during the COVID-19 crisis and identify public communication and significant concerns regarding COVID-19 for suggesting future directions for the food industry and services.SUBJECTS/METHODS: News articles pertaining to food services were extracted from the home pages of major news media websites such as BBC, CNN, and Fox News between March 2020 and February 2021. The retrieved data was sorted and analyzed using Python software.RESULTS: The results of text analytics were presented in the format of the topic label and category for individual topics. The food and health category presented the effects of the COVID-19 pandemic on food and health, such as an increase in delivery services. The policy category was indicative of a change in government policy. The lifestyle change category addressed topics such as an increase in social media usage.CONCLUSIONS: This study is the first to analyze major news media (i.e., BBC, CNN, and Fox News) data related to food services in the context of the COVID-19 pandemic. Text analytics research on the food services domain revealed different categories such as food and health, policy, and lifestyle change. Therefore, this study contributes to the body of knowledge on food services research, through the use of text analytics to elicit findings from media sources."
딥러닝 기반 Local Climate Zone 분류체계를 이용한 지표면온도와 도시열섬 분석: 수원시와 대구광역시를 대상으로,2021,"['Local Climate Zone', 'Deep Learning', 'Convolutional Neural Network', 'Urban Heat Island', 'Urban Climate']",국문 초록 정보 없음,"Urbanization increases the amount of impervious surface and artificial heat emission, resulting in urban heat island (UHI) effect. Local climate zones (LCZ) are a classification scheme for urban areas considering urban land cover characteristics and the geometry and structure of buildings, which can be used for analyzing urban heat island effect in detail. This study aimed to examine the UHI effect by urban structure in Suwon and Daegu using the LCZ scheme. First, the LCZ maps were generated using Landsat 8 images and convolutional neural network (CNN) deep learning over the two cities. Then, Surface UHI (SUHI), which indicates the land surface temperature (LST) difference between urban and rural areas, was analyzed by LCZ class. The results showed that the overall accuracies of the CNN models for LCZ classification were relatively high 87.9% and 81.7% for Suwon and Daegu, respectively. In general, Daegu had higher LST for all LCZ classes than Suwon. For both cities, LST tended to increase with increasing building density with relatively low building height. For both cities, the intensity of SUHI was very high in summer regardless of LCZ classes and was also relatively high except for a few classes in spring and fall. In winter the SUHI intensity was low, resulting in negative values for many LCZ classes. This implies that UHI is very strong in summer, and some urban areas often are colder than rural areas in winter. The research findings demonstrated the applicability of the LCZ data for SUHI analysis and can provide a basis for establishing timely strategies to respond urban on-going climate change over urban areas."
수목 동정을 위한 수피 분류 데이터셋 구축과 합성곱 신경망 기반 53개 수종의 동정 모델 개발,2021,"['tree species identification', 'bark', 'convolutional neural network']",국문 초록 정보 없음,"Many studies have been conducted on developing automatic plant identification algorithms using machine learning to various plant features, such as leaves and flowers. Unlike other plant characteristics, barks show only little change regardless of the season and are maintained for a long period. Nevertheless, barks show a complex shape with a large variation depending on the environment, and there are insufficient materials that can be utilized to train algorithms. Here, in addition to the previously published bark image dataset, BarkNet v.1.0, images of barks were collected, and a dataset consisting of 53 tree species that can be easily observed in Korea was presented. A convolutional neural network (CNN) was trained and tested on the dataset, and the factors that interfere with the model's performance were identified. For CNN architecture, VGG-16 and 19 were utilized. As a result, VGG-16 achieved 90.41% and VGG-19 achieved 92.62% accuracy. When tested on new tree images that do not exist in the original dataset but belong to the same genus or family, it was confirmed that more than 80% of cases were successfully identified as the same genus or family. Meanwhile, it was found that the model tended to misclassify when there were distracting features in the image, including leaves, mosses, and knots. In these cases, we propose that random cropping and classification by majority votes are valid for improving possible errors in training and inferences."
A low-cost compensated approximate multiplier for Bfloat16 data processing on convolutional neural network inference,2021,"['Approximate computing', 'bfloat16 format', 'convolutional neural network', 'logarithmic multiplier', ""Mitchell's algorithm""]",국문 초록 정보 없음,"This paper presents a low-cost two-stage approximate multiplier for bfloat16 (brain floating-point) data processing. For cost-efficient approximate multiplication, the first stage implements Mitchell's algorithm that performs the approximate multiplication using only two adders. The second stage adopts the exact multiplication to compensate for the error from the first stage by multiplying error terms and adding its truncated result to the final output. In our design, the low-cost multiplications in both stages can reduce hardware costs significantly and provide low relative errors by compensating for the error from the first stage. We apply our approximate multiplier to the convolutional neural network (CNN) inferences, which shows small accuracy drops with well-known pre-trained models for the ImageNet database. Therefore, our design allows low-cost CNN inference systems with high test accuracy."
네트워크 침입 탐지를 위해 CICIDS2017 데이터셋으로 학습한 Stacked Sparse Autoencoder-DeepCNN 모델,2021,"['Stacked Sparse Autoenocder (SSAE)', 'DeepCNN', 'Edge Computing', 'Intrusion Detection', 'CICIDS2017']","엣지 컴퓨팅을 사용하는 서비스 공급업체는 높은 수준의 서비스를 제공한다. 이에 따라 다양하고 중요한 정보들이 단말 장치에 저장되면서 탐지하기 더욱 어려운 최신 사이버 공격의 핵심 목표가 됐다. 보안을 위해 침입 탐지시스템과 같은 보안 시스템이 자주 활용되지만, 기존의 침입 탐지 시스템은 탐지 정확도가 낮은 문제점이 존재한다. 따라서 본 논문에서는 엣지 컴퓨팅에서 단말 장치의 더욱 정확한 침입 탐지를 위한 기계 학습 모델을 제안한다. 제안하는 모델은 희소성 제약을 사용하여 입력 데이터의 중요한 특징 벡터들을 추출하는 stacked sparse autoencoder (SSAE)와 convolutional neural network (CNN)를 결합한 하이브리드 모델이다. 최적의 모델을 찾기위해 SSAE의 희소성 계수를 조절하면서 모델의 성능을 비교 및 분석했다. 그 결과 희소성 계수가 일 때 96.9%로 가장 높은 정확도를 보여주었다. 따라서 모델이 중요한 특징들만 학습할 경우 더 높은 성능을 얻을 수 있었다.","Service providers using edge computing provide a high level of service. As a result, devices store important information in inner storage and have become a target of the latest cyberattacks, which are more difficult to detect. Although experts use a security system such as intrusion detection systems, the existing intrusion systems have low detection accuracy. Therefore, in this paper, we proposed a machine learning model for more accurate intrusion detections of devices in edge computing. The proposed model is a hybrid model that combines a stacked sparse autoencoder (SSAE) and a convolutional neural network (CNN) to extract important feature vectors from the input data using sparsity constraints. To find the optimal model, we compared and analyzed the performance as adjusting the sparsity coefficient of SSAE. As a result, the model showed the highest accuracy as a 96.9% using the sparsity constraints. Therefore, the model showed the highest performance when model trains only important features."
성인 학습자의 학습 추이 분석을 위한 인공지능 기반 알고리즘 모델 개발 및 평가,2021,"['성인학습자', '자기조절학습', '인공지능 모델', '추이 분석', '텐서플로우', 'Adult learners', 'artificial intelligence model', 'learning trend analysis', 'Tensorflow']","A사이버교육시스템 성인학습자의 자기조절학습 관련 학습 추이를 분석하여 교육 성과를 높이기 위해 인공지 능을 활용한 알고리즘 모델을 다양하게 설계하고, 그것을 실제 데이터에 적용함으로써 성능을 평가하였다. 이를 위해 A사이버교육시스템에서 115명의 성인학습자의 로그 데이터를 분석하였다. A사이버교육시스템 성인학습자 들은 대부분 권장 학습 시간 이상을 학습하였으나, 학기 말에는 권장 학습 시간 대비 실제 학습 시간이 현저하 게 감소하였다. VOD 참여율이나 형성평가 참여율, 학습 활동 참여율에서도 학습 후반부에 접어들수록 학습 참 여율이 떨어졌다. 따라서 교육 성과를 높이려면 학습 시간이 후반에도 지속될 수 있도록 지원해야 한다 판단하 여 후반부에 학습 시간이 떨어지는 학습자를 찾아내기 위해 Tensorflow를 활용한 인공지능 모델을 개발하여 수 강 시작 날짜별 학습 시간을 예측하였다. 그 결과, CNN 모델을 활용하여 단일 출력 또는 다중 출력을 예측할 경우 다른 모델에 비해 평균 절대 오차가 가장 낮게 나타났다.","To improve educational performance by analyzing the learning trends of adult learners of Open High Schools, various algorithm models using artificial intelligence were designed and performance was evaluated by applying them to real data. We analyzed Log data of 115 adult learners in the cyber education system of Open High Schools. Most adult learners of Open High Schools learned more than recommended learning time, but at the end of the semester, the actual learning time was significantly reduced compared to the recommended learning time. In the second half of learning, the participation rate of VODs, formation assessments, and learning activities also decreased. Therefore, in order to improve educational performance, learning time should be supported to continue in the second half. In the latter half, we developed an artificial intelligence algorithm models using Tensorflow to predict learning time by data they started taking the course. As a result, when using CNN(Convolutional Neural Network) model to predict single or multiple outputs, the mean-absolute-error is lowest compared to other models."
A Deep Learning Model for Extracting Consumer Sentiments using Recurrent Neural Network Techniques,2021,"['Deep Learning', 'QoS', 'Word Embedding', 'Emotion Analysis', 'Text Analysis']",국문 초록 정보 없음,"The rapid rise of the Internet and social media has resulted in a large number of text-based reviews being placed on sites such as social media. In the age of social media, utilizing machine learning technologies to analyze the emotional context of comments aids in the understanding of QoS for any product or service. The classification and analysis of user reviews aids in the improvement of QoS. (Quality of Services). Machine Learning algorithms have evolved into a powerful tool for analyzing user sentiment. Unlike traditional categorization models, which are based on a set of rules. In sentiment categorization, Bidirectional Long Short-Term Memory (BiLSTM) has shown significant results, and Convolution Neural Network (CNN) has shown promising results. Using convolutions and pooling layers, CNN can successfully extract local information. BiLSTM uses dual LSTM orientations to increase the amount of background knowledge available to deep learning models. The suggested hybrid model combines the benefits of these two deep learning-based algorithms. The data source for analysis and classification was user reviews of Indian Railway Services on Twitter. The suggested hybrid model uses the Keras Embedding technique as an input source. The suggested model takes in data and generates lower-dimensional characteristics that result in a categorization result. The suggested hybrid model's performance was compared using Keras and Word2Vec, and the proposed model showed a significant improvement in response with an accuracy of 95.19 percent."
Deep Learning-based Classification of Respiratory Sounds and Its Clinical Value,2021,"['Auscultation', 'Respiratory Sound', 'Deep learning']",국문 초록 정보 없음,"IntroductionAuscultation of respiratory sound is a non-invasive and relatively simple diagnostic method that can be performed anytime, but the information provided is quite useful. Breath sound information markedly improves the accuracy of diagnosis and monitoring of disease status. Despite these advantages, auscultation has a major limitation, subjectivity. Since the interpretation of respiratory sounds requires significant expertise and clinical experience, doctors in training sometimes misidentify respiratory sounds. To overcome such a drawback, we developed an automated classification system of respiratory sounds.Method2840 respiratory sounds were recorded by a digital stethoscope in a real clinical setting. Three pulmonologists classified them and 1918 sounds including normal sounds, crackles, wheezes, rhonchi were selected. We applied deep learning convolutional neural network (CNN) to identify the classified database. We developed the predictive model for respiratory sound classifcation combining pretrained image feature extractor of series, respiratory sound, and CNN classifer. To evaluate the accuracy of human auscultation ability and compare it with our predictive model, 70 participants were asked to listen to classified sounds and identify them.ResultDeep learning-based classification model detected abnormal sounds with an accuracy of 86.5% and the AUC of 0.93. It further classifed abnormal lung sounds into crackles, wheezes, or rhonchi with an overall accuracy of 85.7% and a mean AUC of 0.92. Meanwhile, the accuracy of human auscultation was different depending on the group; 60.3% for medical students, 53.4% for interns, 68.8% for residents, and 80.1% for fellows.ConclusionThis respiratory sound classification model using deep learning is expected to complement the limitation of inaccurate auscultation of clinicians and help the rapid diagnosis and appropriate treatment of respiratory diseases. In addition, this model will be useful to meet the current medical demands such as non-face-to-face care due to COVID-19 and telemedicine in hard-to-reach area."
암반공학분야에 적용된 인공지능 알고리즘 분석,2021,"['Rock engineering', 'Artificial intelligence', 'Machine learning', 'Artificial neural networks', 'Algorithm', '암반공학', '인공지능', '기계학습', '인공신경망', '터널']","4차 산업혁명 시대의 도래에 따라 암반공학분야에서도 인공지능을 활용한 연구가 점차 증가하고 있다. 본 논문에서는 인공지능에 대한 이해와 그 활용도를 더욱 증진시키기 위하여, 암반공학기술의 주된 적용대상인 터널, 발파, 광산과 관련된 최근의 국내외 연구 중 인공지능이 활용된 논문들에서 그 알고리즘의 종류와 적용방법을 분석하였다. 터널에서는 암반분류, TBM굴진율 및 막장전방 지질 예측, 발파에서는 암반의 파쇄도 및 비산거리, 광산에서는 폐광의 침하가능성 예측을 위해 주로 활용되고 있으며, 기계학습의 다양한 알고리즘 중 인공신경망이 압도적으로 많이 활용되고 있는 것으로 나타났다. 연구결과의 정확도와 신뢰성 제고를 위해 사용하고자 하는 인공지능 알고리즘에 대한 정확하고 상세한 이해가 필수적이며, 현재는 접근이나 분석이 난해한 암반공학 분야의 다양한 문제해결을 위해 기계학습뿐 아니라 CNN 또는 RNN과 같은 딥러닝을 활용한 연구 아이디어들이 점차 증가될 것으로 기대된다.","As the era of Industry 4.0 arrives, the researches using artificial intelligence in the field of rock engineering as well have increased. For a better understanding and availability of AI, this paper analyzed the types of algorithms and how to apply them to the research papers where AI is applied among domestic and international studies related to tunnels, blasting and mines that are major objects in which rock engineering techniques are applied. The analysis results show that the main specific fields in which AI is applied are rock mass classification and prediction of TBM advance rate as well as geological condition ahead of TBM in a tunnel field, prediction of fragmentation and flyrock in a blasting field, and the evaluation of subsidence risk in abandoned mines. Of various AI algorithms, an artificial neural network is overwhelmingly applied among investigated fields. To enhance the credibility and accuracy of a study result, an accurate and thorough understanding on AI algorithms that a researcher wants to use is essential, and it is expected that to solve various problems in the rock engineering fields which have difficulty in approaching or analyzing at present, research ideas using not only machine learning but also deep learning such as CNN or RNN will increase."
Detecting Natural Disasters with Unmanned Aerial Vehicles,2021,"['Unmanned Aerial Vehicles', 'Deep Learning', 'Convolutional Neural Network', 'Natural Disasters']",국문 초록 정보 없음,"Unmanned aerial vehicles (UAVs) or drones are versatile innovations that can capture pictures and videos and even collect air or soil samples. Natural disaster drones are especially critical, which help with understanding the damage after a disaster, locating people who need help, distributing resources and preparing for the next event. Computer vision, deep learning (DL), and drones can augment the existing sensors, thereby increasing the accuracy of natural disasters detector, and most importantly, allow people to take precautions, stay safe, and reduce the number of deaths and injuries that happens due to these disasters. Therefore, in this paper we propose a novel lightweight convolutional neural network (CNN) based framework to detect natural disasters including cyclone, flood, earthquake, and wildfire. The proposed CNN model is obtained by fine-tuning the MobileNetV2 that can be deployed on drones. Furthermore, the model is trained and evaluated using a publicly available natural disasters dataset by obtaining 83.4% accuracy. Similarly, the framework has ability to broad cast the notification in alarming situations, which makes our proposed framework a best fit for natural disasters detection in realworld surveillance settings."
샴 네트워크 기반 객체 추적을 위한 표적 이미지 교환 모델,2021,"['Object tracking', 'Deep learning', 'Siamese network', 'Convolutional neural network', '객체 추적', '딥 러닝', '샴 네트워크', '컨볼루션 뉴럴 네트워크']",본 논문에서는 샴 네트워크 기반의 객체 추적 알고리즘의 성능 향상을 위한 표적 이미지 교환 모델을 제안한다. 샴 네트워크 기반의 객체 추적 알고리즘은 시퀀스의 첫 프레임에서 지정된 표적 이미지만을 사용하여 탐색 이미지 내에서 가장 유사한 부분을 찾아 객체를 추적한다. 첫 프레임의 객체와 유사도를 비교하기 때문에 추적에 한 번 실패하게 되면 오류가 축적되어 추적 객체가 아닌 부분에서 표류하게 되는 현상이 발생한다. 따라서 CNN(Convolutional Neural Network)기반의 모델을 설계하여 추적이 잘 진행되고 있는지 확인하고 샴 네트워크 기반의 객체 추적 알고리즘에서 출력되는 점수를 이용하여 표적 이미지 교환 시기를 정의하였다. 제안 모델은 VOT-2018 데이터 셋을 이용하여 성능을 평가하였고 최종적으로 정확도 0.611 견고도 22.816을 달성하였다.,"In this paper, we propose a target image exchange model to improve performance of the object tracking algorithm based on a Siamese network. The object tracking algorithm based on the Siamese network tracks the object by finding the most similar part in the search image using only the target image specified in the first frame of the sequence. Since only the object of the first frame and the search image compare similarity, if tracking fails once, errors accumulate and drift in a part other than the tracked object occurs. Therefore, by designing a CNN(Convolutional Neural Network) based model, we check whether the tracking is progressing well, and the target image exchange timing is defined by using the score output from the Siamese network-based object tracking algorithm. The proposed model is evaluated the performance using the VOT-2018 dataset, and finally achieved an accuracy of 0.611 and a robustness of 22.816."
전이 학습을 이용한 선박 기관실 기기의 분류에 관한 연구,2021,"['Patrol robot', 'Ship engine room equipment', 'Convolution neural network', 'Classification', 'Transfer learning', '순찰 로봇', '선박 기관실 기기', '합성곱 신경망', '분류', '전이 학습']","선박 기관실은 기술의 발전으로 인해 자동화 시스템이 향상되었지만, 해상에서는 바람, 파도, 진동, 기기 노후화 등의 다양한 변수가 많아 자동화 시스템에서 계측되지 않는 풀림, 절단, 누유, 누수 등이 발생하므로 기관사는 주기적으로 순찰을 한다. 순찰 시에는 1명의 기관사만 순찰하는 경우도 있으며, 이는 고온고압 및 회전기기가 운전 중인 기관실에서 많은 위험요소를 가지고 있다. 기관사가 순찰 시에는 오감을 활용하며, 특히 시각에 의존한다. 본 논문에서는 로봇이 기관실을 순찰하며 기기의 특이사항을 검출하고 알려주는 기관실 순찰 로봇을 구현하기 위한 선행연구로서 선박 기관실 기기의 이미지를 합성곱 신경망을 이용하여 분류하였다. 선박 기관실의 이미지 데이터 셋을 구성한 후 사전 훈련된 합성곱 신경망 모델로 학습하였다. 학습한 모델의 분류 성능은 높은 재현율을 보였으며, 클래스 활성화 맵으로 이미지를 시각화 하였다. 데이터의 양이 제한적이어서 일반화할 수는 없지만, 각 선박의 데이터를 전이학습으로 학습시키면 적은 시간과 비용으로 각 선박의 특성에 맞는 모델을 구축할 수 있을 것으로 사료된다.","Ship engine rooms have improved automation systems owing to the advancement of technology. However, there are many variables at sea, such as wind, waves, vibration, and equipment aging, which cause loosening, cutting, and leakage, which are not measured by automated systems. There are cases in which only one engineer is available for patrolling. This entails many risk factors in the engine room, where rotating equipment is operating at high temperature and high pressure. When the engineer patrols, he uses his five senses, with particular high dependence on vision. We hereby present a preliminary study to implement an engine-room patrol robot that detects and informs the machine room while a robot patrols the engine room. Images of ship engine-room equipment were classified using a convolutional neural network (CNN). After constructing the image dataset of the ship engine room, the network was trained with a pre-trained CNN model. Classification performance of the trained model showed high reproducibility. Images were visualized with a class activation map. Although it cannot be generalized because the amount of data was limited, it is thought that if the data of each ship were learned through transfer learning, a model suitable for the characteristics of each ship could be constructed with little time and cost expenditure."
딥러닝을 이용한 군 내외 거수자 행동 인식: 키포인트 2D 스케일링을 중심으로,2021,"['defense and security technology', 'surveillance camera', 'suspicious person', 'behavior recognition', 'OpenPose', '국방보안기술', '감시카메라', '거수자', '행동 인식', '오픈포즈']","본 연구는 딥러닝을 통해 군 내외에서 거수자의 행동을 인식하여 국방 보안 체계를 강화하는 데 목적을 두고 있다. 감시 카메라는 범죄자, 수상한 행동을 하는 사람을 찾아내는데 도움이 된다. 하지만 관리자가 카메라에서 전송되는 많은 영상을 모두 모니터링해야 한다는 점에서 비효율적이다. 큰 비용이 발생하며, 인적 오류에 취약하다. 따라서 본 연구에서는 감시카메라 영상만으로 주의 있게 봐야 할 행동을 하는 사람을 찾아내는 방법을 제안한다. 이를 위해 거수자 영상 데이터를 수집하였다. 또한, 입력 영상에서 사람마다 다른 신장, 동작을 일반화하는 알고리즘을 적용한 후 CNN, 양방향 LSTM, DNN을 결합한 모델을 통해 학습하였다. 실험 결과, 거수자의 행동 인식의 정확도를 향상시켰다. 따라서 기존 감시 카메라에 딥러닝을 접목한다면 거수자를 효율적으로 찾아낼 수 있을 것으로 기대한다.","The purpose of this study is to reinforce the defense and security system by recognizing the behaviors of suspicious person both inside and outside the military using deep learning. Surveillance cameras help detect criminals and people who are acting unusual. However, it is inefficient in that the administrator must monitor all the images transmitted from the camera. It incurs a large cost and is vulnerable to human error. Therefore, in this study, we propose a method to find a person who should be watched carefully only with surveillance camera images. For this purpose, the video data of doubtful behaviors were collected. In addition, after applying a algorithm that generalizes different heights and motions for each person in the input images, we trained through a model combining CNN, bidirectional LSTM, and DNN. As a result, the accuracy of the behavior recognition of suspicious behaviors was improved. Therefore, if deep learning is applied to existing surveillance cameras, it is expected that it will be possible to find the dubious person efficiently."
Development of Small Target Detection for Maritime Accident Monitoring Using 3D Game-Based Deep Learning,2021,"['해양사고(Maritime accidents)', '소형 물체 감지(Small object detection)', '딥러닝(Deep learning)', '데이터 복제(Data augmentation)', '게임 기반 학습(Game-based Learning)']",국문 초록 정보 없음,"It is important to recognize the drowning person as soon as possible in maritime accidents. In real maritime accidents, it is difficult to identify the drowning person because of their small size compared to the marine environment. To solve this problem, this paper presents a methodology to detect small target using commercial games with 3D graphical engines. Proposed methodology combines as following four steps: (1) divide high-resolution original image into several small patches, (2) image processing using CLAHE and Canny edge detection, (3) detecting small targets using convolutional neural networks (4) restore patches into original image. To detect small target in the high-resolution original image, small patches and image processing techniques are considered to raise the signal-to-noise ratio of the small target. The small patches are uses as test data of convolutional neural networks (CNN), the softmax values of each patch are displayed on the reconstructed image. To enhance the accuracy of CNN, virtual image data acquired from the commercial game using the 3D graphical engine are used as training data. In order to verify the performance of the proposed methodology, a case study of real maritime accident situation was conducted. The performance of the proposed methodology outperforms original deep convolutional neural networks."
음악 소리가 딥 러닝의 음향 분류 성능에 미치는 영향,2021,"['Sound classification', 'Deep learning', 'Music genre', 'UrbanSound8K', 'GTZAN']",국문 초록 정보 없음,"Sound classification is a computer technology that involves learning to classify sounds and to predict the category of that sound. Recently, the machine learning based approach is being actively conducted for improving recognition accuracy. In this approach, a deep neural network is trained using a sound dataset, and then the actual sound is applied to identify the sound category. In the identification stage, the recognition accuracy of the machine learning is degraded due to the ambient noise. In other words, unlike the experimental environment, various sounds are input into the microphone along with the target sound. Since these ambient sounds are not trained, they could lower the classification performance. However, there are only a few research results on the relation between the noise and the recognition performance despite of the practical importance. In this paper, we study the performance degradation of sound classification in the space where the music is playing with considering the music genre and the volume level. For this, we use CNN, UrbanSound8K dataset consisting of 10 kinds of environmental sounds, and GTZAN data set containing 10 kinds of music genres. First, CNN is trained to recognize the sounds of UrbanSound8K, and then five songs for each genre were selected from GTZAN and mixed to the UrbanSound8K so that the signal-to-noise ratio are -20dB, 0dB, 5dB, 10dB, and 20dB. Then we test the accuracy with the mixed sound input and compare with the noise-free target sound. As a result, there is 2.8% to 22% difference in the recognition accuracy by music genre and sound level. The result show that the SNR should be 20dB or more in order for music not to have a significant effect on the recognition accuracy."
심층학습 기반 불완전한 영상의 특징점 매칭과 기초행렬 추정,2021,"['Stereo Camera', 'Feature Detection', 'Feature Matching', 'Convolutional Neural Network', 'Fundamental Matrix']","스테레오 비전 시스템에서 특징점 검출과 특징점 매칭은 정확한 깊이추정을 위해 반드시 필요한 작업이다. 그러나 입력 영상으로부터 충분한 특징점을 획득하지 못한다면 특징점 매칭의 결과의 정확도는 낮아질 가능성이 높다. 본 논문에서는 일부 정보가 누락된 영상을 입력으로 받은 후 컨볼루션 신경망을 활용하여 특징점 검출 및 매칭을 수행한다. 스테레오 카메라 시스템을 이용하여 일부 정보가 누락된 한 쌍의 영상을 활용하여 컨볼루션 신경망 기반으로 특징점 검출의 정확도를 높여 이것으로부터 계산된 특징점 매칭의 결과와 기초행렬의 결과를 정보누락 없이 수행된 실험 결과와 비교해 본다. 본 연구에서 제안하는 방법을 검증하기 위하여 스테레오 카메라로부터 획득한 영상을 활용하고, 영상에서 임의의 영역을 삭제하여 정보가 누락된 영상을 생성한다. 심층학습을 수행하기 위하여 특징점 추출 단계에서 컨볼루션 신경망 모델을 이용하고 RANSAC(RANdom SAmple Consensus) 알고리즘을 이용하여 매칭을 수행한다.","The detection and matching of feature points are mandatory procedures for accurate depth estimation in stereo vision. The accuracy of correspondence matching is low unless sufficient numbers of detected feature points are acquired. This paper deals with incomplete images that lose a considerable number of pixels, and the detection and matching of feature points are performed using a convolutional neural network (CNN). Once feature detection and matching are carried out using the CNN, a comparison is made between the results of the fundamental matrix for both the cases of complete and incomplete images. As part of this work, to evaluate our method, some regions of an image are deleted so that an incomplete image can be generated. Once feature extraction is performed, an RANSAC algorithm is employed for feature correspondence."
Environment Recognition from A Spherical Camera Image Based on DeepLab v3+,2021,"['Autonomous Wheelchair', 'Semantic Segmentation', 'Spherical Camera', 'Panoramic Image', 'DeepLab v3+', 'Convolutional Neural Network', 'MobileNet v2', 'Squeeze-and-Excitation block', 'Deformable Convolutional Networks']",국문 초록 정보 없음,"The number of users of electric wheelchairs has been increasing in recent years because it is easy to operate the electric wheelchair and do not require physical strength. However, the traffic accidents are also increasing because of the large number of wheelchairs. The development of autonomous electric wheelchairs is expected to reduce the risk of accidents and improve the convenience of electric wheelchairs. Environmental recognition is essential for the development of autonomous electric wheelchairs. In this paper, we propose a method for recognizing roads, sidewalks, buildings, electric wheelchair drivers, poles, electric wheelchairs, vegetation, curbs, sky, pedestrians, lanes, cars, steps, and bicycles. For recognizing those objects, we use a panoramic image acquired from a spherical camera. As the machine techniques, we use DeepLab v3+, a semantic segmentation algorithm based on Convolutional Neural Network (CNN). In the proposed method, a new CNN model is constructed by adding deformable convolution, SE-block, and MobileNet v2 to DeepLab v3+ into the original DeepLab v3+. In the experiment, IoU 38.8% and Dice of 46.7% were obtained."
A Local-Cloud Edge based Keyword Spotting using Deep Learning,2021,"['Cloud computing', 'deep learning', 'edge device', 'keyword spotting']",국문 초록 정보 없음,"Objective: This study aims to develop a reliable and efficient keyword spotting (KWS) system suitable for a user interface on an edge device application. In addition, this study also aims to implement KWS on both local (to perform low-level tasks and in condition without internet access) and cloud (to perform high-level tasks). Background: KWS plays a significant role in realizing speech-based user interaction with an edge device. Existing KWS system issues include 1) low accuracy, caused by unrecognized noise signals during training and inference process, 2) high computational complexity, caused by the use of deep learning models with complex architecture, 3) internet connection dependency, caused by running main processes into cloud server, and 4) system responsiveness, can be affected by high latency in data transfer over the internet which is affected by external factors. Method: First, to increase the accuracy, crowd-sourcing techniques is used to obtain training sets which includes variety of audio sample with different accents and voice quality. The quality of the training data is improved using signal augmentation and curation methods. Second, to reduce the computational complexity, the trained model is optimized using a quantization method. In case of increasing accuracy, signal augmentation adds background noise to the training dataset and assists the KWS model to recognize the keyword in a variety of environments. Data curation is used is to process augmented signals which include: collecting, organizing, labeling, cleaning, enhancing, and preserving data for the KWS training process. In addition to signal augmentation and curation, a Mel Frequency Cepstral Coefficient (MFCC) is used to extract the features in an audio signal. The extracted features are then restructured to an image and a convolutional neural network (CNN) is used to learn the features and classify the MFCCs in each sample dataset. To further improve the accuracy, the training parameters are adjusted to achieve a validation accuracy of at least 85%. Also, regularization techniques and dropout layers are added to avoid overfitting. In KWS system deployment, the trained model is optimized to reduce memory, computing, and power consumption. Hence, model weights and activations parameters are quantized using 8-bit integers without incurring a significant loss in accuracy. The implementation utilizes the local-cloud server processing, where a local database residing in the edge server works alongside with the cloud server to execute more complex algorithm and processes. Results: The training result shows that our KWS model achieves an average accuracy and loss of 95.9% and 0.18, respectively. The raining result also reveals that the trained KWS model is ready for model testing on the edge. Furthermore, the optimization result shows the inference time, peak random access memory usage, and flash usage are reduced by 21.1%, 32.3%, and 58.5%, respectively. Conclusion: The result of model training and testing shows that the proposed KWS system has high accuracy and resource efficiency. The system also exhibits internet independence as local database is implemented locally. Application: The inference process uses two platforms: edge device and cloud server. The edge device, Arduino BLE sense microcontroller, is used to spot the keywords using optimized CNN that will produce a unique keyword identifier and is sent over to the cloud server. The identifier is used to match the keyword for its corresponding response. The cloud server sends the response of the spotted keyword to the edge device."
Feature Pyramid Network-based Long-Distance Drone Detection Method,2021,"['CNN', '딥러닝', '드론', 'FPN', '객체 탐지', 'deep learning', 'drone', 'object detection']",국문 초록 정보 없음,다국어 초록 정보 없음
Design and Implementation of Fire Detection System Using New Model Mixing,2021,"['CNN', 'YoloV5', 'DeepSort', 'Deep Appearance Deseriptor']",국문 초록 정보 없음,"In this paper, we intend to use a new mixed model of YoloV5 and DeepSort. For fire detection, we want to increase the accuracy by automatically extracting the characteristics of the flame in the image from the training data and using it. In addition, the high false alarm rate, which is a problem of fire detection, is to be solved by using this new mixed model. To confirm the results of this paper, we tested indoors and outdoors, respectively. Looking at the indoor test results, the accuracy of YoloV5 was 75% at 253Frame and 77% at 527Frame, and the YoloV5+DeepSort model showed the same accuracy at 75% at 253 frames and 77% at 527 frames. However, it was confirmed that the smoke and fire detection errors that appeared in YoloV5 disappeared. In addition, as a result of outdoor testing, the YoloV5 model had an accuracy of 75% in detecting fire, but an error in detecting a human face as smoke appeared. However, as a result of applying the YoloV5+DeepSort model, it appeared the same as YoloV5 with an accuracy of 75%, but it was confirmed that the false positive phenomenon disappeared."
변형 DAPPM을 활용한 실시간 Semantic Segmentation 성능 향상 연구,2021,"['CNN', 'Deep learning', 'Semantic segmentation', 'DAPPM']","본 논문에서는 실시간 Semantic segmentation에서 주로 사용되는 Two-pathway backbone을 활용하여 뚜렷한 성과를 내는 BISNet 알고리즘의 핵심인 Aggregation layer의 성능 향상을 위하여 변형 DAPPM(Deep Aggregation Pyramid Pooling Module)으로 변경을 제안한다. 기존의 Aggregation layer는 단순히 2가지 Branch의 특징 표현을 병합하도록 설계되었다면 변형 DAPPM은 다양한 크기의 풀링 커널과 서로 다른 깊이를 통합하여 다중 스케일 특성 과정을 진행한다. 이것은 입력 이미지 해상도의 1/64에 불과하므로 추론 속도에 거의 영향을 미치지 않으면서 특징을 추출할 수 있다. 그 결과 기존 BISNet 대비 처리속도는 동일하나, mIOU는 Aggregation layer 대비 2% 향상된 결과를 얻었다.","In this paper, we propose a transformation to modified DAPPM (Deep Aggregation Pyramid Pooling Module) to improve the performance of the aggregation layer, the core of the BISNet algorithm, which is using the two-pathway backbone that is mainly used in real-time Semantic segmentation. While the existing Aggregation layer was designed to simply merge the feature expressions of two branches, modified DAPPM performs a multi-scale feature process by integrating pooling kernels of various sizes and different depths. Since this is only 1/64 of the resolution of the input image, features can be extracted with little impact on the inference speed. As a result, the processing speed is the same compared to the existing BISNet, but the mIOU obtained a 2% improvement compared to the Aggregation layer."
강한 조명하에서 정확한 돼지 탐지를 위한 모델 앙상블,2021,[],"CNN 기반 객체 탐지기의 발전으로 돈사에서 돼지 모니터링이 가능하지만, 실제 농가에서 적용하기 위해서는 영상에서 돈사의 조명에 직접 노출된 돼지들이 노출 과다 현상에 의해 탐지되지 않는 문제가 여전히 남아있다. 이러한 문제점은 싱글 모델로서는 정확도 개선의 한계가 있어, 복수개의 모델을 이용한 모델 앙상블 기법을 제안한다. 특히 본 연구에서 제안하는 영상 처리 기법을 사용하여 생성된 상호 보안적인 데이터를 통해 학습된 두 개의 TinyYOLOv4 모델을 결합하면, 돼지 객체 탐지의 정확도가 하나의 TinyYOLOv4 모델에 비하여 획기적으로 개선되었음을 확인하였다.",다국어 초록 정보 없음
A Restoration Method of Single Image Super Resolution Using Improved Residual Learning with Squeeze and Excitation Blocks,2021,"['CNN', 'Super-resolution', 'SRGAN', 'Residual learning', 'Squeeze and excitation']",국문 초록 정보 없음,"Techniques for single-image super-resolution have been developed through deep learning. In this paper, we propose a method using advanced residual learning and squeeze and excitation (SE) blocks for such resolution. Improving the residual learning increases the similarity between pixels by adding one skip to the existing residual, and it is possible to improve the performance while slightly increasing the number of calculations by applying the SE block of SENet. The performance evaluation was tested as part of the super-resolution generative adversarial network (SRGAN) and using three proposed modules, and the effect of the residual and the SE blocks on the super-resolution and the change in performance was confirmed. Although the results vary slightly from image, SE and residual blocks have been found to help improve the performance and are best used with blocks."
삼중 경로 mDAPPM을 활용한 실시간 의미론적 분할 성능 향상 연구,2021,"['CNN', 'Deep learning', 'Semantic segmentation', 'DAPPM']",국문 초록 정보 없음,"In this paper, we propose real-time Semantic segmentation performance improvements when changing the aggregation layer, the core of the recently popular Two-pathway backbone and the BiSeNet v2 algorithm, to Modified Deep Aggregation Pyramid Pooling Module (mDAPPM). Existing aggregation layers are designed to simply merge feature representations from two branches, but in this paper, we use Three-pathway mDAPPM to integrate different depths with different sizes of pooling kernels to proceed with multi-scale feature point extraction. As a result, the real-time speed is 88fps identical to that of existing BiSeNet v2, and mIOUs obtain up to 3% improvement based on max_iter= 30,000 over BiSeNet v2."
지식증류 기법을 사용한 SRGAN 경량화 연구,2021,"['CNN', 'Network Lightening', 'Knowledge Distillation', 'Super-Resolution', 'SRGAN']",국문 초록 정보 없음,다국어 초록 정보 없음
키오스크 UI/UX 개인화를 위한 사용자 나이 추정,2021,"['Kiosk', 'CNN', 'UI/UX']",국문 초록 정보 없음,다국어 초록 정보 없음
화학사고 후 수계내 독성물질 농도 분포 예측 딥러닝 모델 개발,2021,"['딥러닝 CNN', '화학사고 모델링', '수질오염사고', '관거-수계 통합모델', 'EFDC']",국문 초록 정보 없음,다국어 초록 정보 없음
MLP 모델을 위한 Mixup 알고리즘 기반의 Data Augmentation에 관한 연구,2021,[],본 논문에서는 CNN 모델에서 학습에 사용할 이미지 데이터를 늘리기 위해 사용되는 Mixup 알고리즘을 MLP 모델에 사용하는 데이터셋에 적용하여 data augmentation 효과를 얻을 수 있는 지에 대한 테스트를 수행했다. 테스트 결과 MLP 모델에 사용할 데이터셋에도 Mixup 알고리즘으로 data augmentation 효과를 기대할 수 있음을 보여준다.,다국어 초록 정보 없음
Performance Comparison of Vision based Deep Learning Techniques for Fall Detection,2021,"['fall detection', 'CNN', 'deep learning', 'action recognition', 'human action']",국문 초록 정보 없음,다국어 초록 정보 없음
Encoding Dictionary Feature for Deep Learning-based Named Entity Recognition,2021,"['BiLSTM Dictionary', 'CNN Dictionary', 'Self-attention Dictionary', 'GFID Dataset', 'Biomedical NER']",국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망의 추론 정확도 향상을 위한 하드웨어 구조 연구,2021,"['AI accelerator', 'CNN', 'batch normalization', 'verilog-HDL', 'ASIC']",국문 초록 정보 없음,"In this paper, we propose a hardware architecture with built-in batch normalization to improve inference accuracy of convolutional neural networks. Batch normalization improves inference accuracy by normalizing the data distribution by the convolutional neural network layer. However, operations such as average and variance are required, and if there is a restriction on hardware resource usage, the operation accuracy decreases. Therefore, this paper proposes a hardware architecture in which batch normalization operations can be omitted by applying an 8-bit quantization technique when inferencing to improve computational accuracy and utilize internal control signals. The proposed hardware architecture was modeled using Verilog-HDL. Then the intermediate and final output values of the hardware operation were compared and evaluated with the output results of the software-based verification model and synthesized using the Samsung 28-nm process."
임베디드용 저해상도 적외선 영상 딥컨볼루션신경망,2021,"['Deep Learning', 'CNN', 'VGG', 'Low Resolution', 'Infrared', 'Synthesize Image', '딥러닝', '컨볼루션 신경망', '저해상도', '적외선', '합성영상']","본 논문은 저해상도 적외선영상을 사양이 낮은 임베디드 시스템에서 추론 가능하도록 강화된 VGG 스타일과 Global Average Pooling 조합으로 정확도를 증가시키면서 연산량을 최소화하는 딥러닝 컨볼루션 신경망을 이용한 저해상도 적외선 표적 분류 방법을 제안한다. 제안한 알고리즘은 OKTAL-SE로 생성한 합성영상 클래스 9개 3,723,328개를 분류하였다. 최초 임베디드 추론 가능하도록 파라메터 수가 최소화된 최대풀링 레이어 기준 입력단 8개와 출력단 8개 조합에 비해 강화된 VGG 스타일을 적용한 입력단 4개와 출력단 16개 필터수 조합을 이용하여 연산량은 약 34% 감소시켰으며, 정확도는 약 2.4% 증가시켜 최종 정확도 96.1%을 획득하였다. 추가로 C 코드로 포팅하여 수행시간을 확인하였으며, 줄어든 연산량 만큼 수행 시간이 약 32% 줄어든 것을 확인할 수 있었다.","In this paper, we propose reinforced VGG style network structure for low performance embedded system to classify low resolution infrared image. The combination of reinforced VGG style network structure and global average pooling makes lower computational complexity and higher accuracy. The proposed method classify the synthesize image which have 9 class 3,723,328ea images made from OKTAL-SE tool. The reinforced VGG style network structure composed of 4 filters on input and 16 filters on output from max pooling layer shows about 34% lower computational complexity and about 2.4% higher accuracy then the first parameter minimized network structure made for embedded system composed of 8 filters on input and 8 filters on output from max pooling layer. Finally we get 96.1% accuracy model. Additionally we confirmed the about 31% lower inference lead time in ported C code."
인공지능(AI) 분석과 PR 연구 방향 탐색,2021,"['인공지능', 'ANN', 'CNN', 'RNN', 'PR연구']",국문 초록 정보 없음,다국어 초록 정보 없음
An Optimized e-Lecture Video Search and Indexing framework,2021,"['Classification', 'Clustering', 'CNN', 'Indexing', 'Machine Learning', 'Text Detector', 'Video retrieval']",국문 초록 정보 없음,"The demand for e-learning through video lectures is rapidly increasing due to its diverse advantages over the traditional learning methods. This led to massive volumes of web-based lecture videos. Indexing and retrieval of a lecture video or a lecture video topic has thus proved to be an exceptionally challenging problem. Many techniques listed by literature were either visual or audio based, but not both. Since the effects of both the visual and audio components are equally important for the content-based indexing and retrieval, the current work is focused on both these components. A framework for automatic topic-based indexing and search depending on the innate content of the lecture videos is presented. The text from the slides is extracted using the proposed Merged Bounding Box (MBB) text detector. The audio component text extraction is done using Google Speech Recognition (GSR) technology. This hybrid approach generates the indexing keywords from the merged transcripts of both the video and audio component extractors. The search within the indexed documents is optimized based on the Naïve Bayes (NB) Classification and K-Means Clustering models. This optimized search retrieves results by searching only the relevant document cluster in the predefined categories and not the whole lecture video corpus. The work is carried out on the dataset generated by assigning categories to the lecture video transcripts gathered from e-learning portals. The performance of search is assessed based on the accuracy and time taken. Further the improved accuracy of the proposed indexing technique is compared with the accepted chain indexing technique."
딥러닝을 이용한 해양침적쓰레기 분류에 관한 연구,2021,"['해양침적쓰레기', 'VGG19', '소나이미지', '딥러닝', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
전자 기타 연주자를 위한 딥러닝 기반 이펙터 분류 시스템,2021,"['Deep learning', 'Sound classification', 'CNN', 'Instruments', 'Electric guitar']","Objective: 본 연구는 음원 데이터 분류를 위한 딥러닝 모델을 활용해 초급 및 중급 전자 기타 연주자들에게 도움이 될 수 있는 전자 기타 이펙터 자동 분류 시스템을 제안한다. Background: 이펙터는 전자 기타에 연결해 음의 파형에 변화를 주어 소리를 변조시키는 장치이다. 시중에는 다양한 종류의 이펙터가 존재하고 같은 종류의 이펙터라 하더라도 변조의 정도가 다르다는 점 때문에 대부분의 초/중급 연주자에게는 많은 비용과 시간을 들여 이펙터를 구매하고 기능과 조합을 학습해야 한다는 어려움이 존재한다. Method: 이펙터를 Filter, Time, Drive, Modulation 총 4가지 계열로 분류한 뒤, Filter계열은 wah. Time계열은 reverb, delay. Drive계열은 overdrive, distortion, fuzz. Modulation계열은 chorus, phaser, flanger, tremolo로 총 11개의 이펙터를 선정했다. 학습 및 실험에 사용하기 위한 음원 데이터는 Sonar사의 Cakewalk DAW와 TH3 전자 기타 VSTi를 활용해 수집했다. 데이터 세트는 0옥타브 도부터 3옥타브 도까지 22개의 단일음을 4초씩 연주한 44K 단음 데이터와 약 8분 45초 길이의 Canon Rock 연주음 데이터를 4초씩 분할한 44K 복합음 데이터로 구성되어 있다. 데이터 전처리를 수행한 후, 2640개의 각 계열별 단일음 샘플과 15720개의 복합음 샘플, 총 18360개의 샘플을 계열별 이펙터 분류 모델 훈련에 사용하였다. 음원에 적용된 각 계열별 이펙터를 분류하기 위하여 음원 데이터 분석을 위한 딥러닝 모델인 PANNs 신경망을 사용하였다. 각각의 이펙터 계열 분류를 위하여 4개의 개별 모델을 병렬적으로 학습하였다. 각 계열별로 이펙터가 사용되지 않은 상태의 음원까지 포함하여 10epoch 동안 학습을 진행했고 10-fold Cross Validation 결과, 모두 99%이상의 정확도를 기록했다. 각 모델의 일반화 성능을 평가하기 위해 추가적으로 1분 3초 길이의 신규 음원을 4초씩 분할한 1800개의 연주음 데이터 세트를 구성해 최종적인 모델 평가를 진행했다. Result: 모델 평가 결과, 학습 과정에 포함되지 않았던 신규 음원에 대하여 Filter계열은 97%, Time계열은 80%, Drive계열은 82%, Modulation계열은 82%의 정확도로 이펙터의 종류를 분류해냈다. 이진 분류인 Filter계열은 높은 정확도를 기록했고, Time계열은 delay이펙터, Drive계열은 fuzz이펙터, Modulation계열은 chorus이펙터에 약세를 보였다. 해당 이펙터에 대한 추가 학습을 진행하면 정확도를 더 높일 수 있을 것으로 기대된다. Conclusion: 본 연구에서 제안한 전자 기타 이펙터 분류 시스템을 통해 사용 빈도가 잦은 이펙터들을 80% 이상의 정확도로 분류해낼 수 있었으며, 분류가 어려운 이펙터의 종류를 파악하여 추가 학습 방안을 도출할 수 있었다. Application: 본 연구에서 제시된 시스템을 활용한다면 초급 및 중급자들의 연주 환경 구성에 도움이 될 것으로 판단되며, 향후 여러 전자 기타 연주 음원을 실제 환경에서 수집해 모델을 학습시킨다면 더욱 정확하고 광범위하게 사용할 수 있을 것으로 기대된다.",다국어 초록 정보 없음
합성곱 신경망을 이용한 프로펠러 캐비테이션 침식 위험도 연구,2021,"['Convolutional Neural Network(CNN', '합성곱 신경망)', 'Deep learning(딥러닝)', 'Propeller(프로펠러)', 'Cavitation(캐비테이션)', 'Erosion(침식)']",국문 초록 정보 없음,"Cavitation erosion is one of the major factors causing damage by lowering the structural strength of the marine propeller and the risk of it has been qualitatively evaluated by each institution with their own criteria based on the experiences. In this study, in order to quantitatively evaluate the risk of cavitation erosion on the propeller, we implement a deep learning algorithm based on a convolutional neural network. We train and verify it using the model tests results, including cavitation characteristics of various ship types. Here, we adopt the validated well-known networks such as VGG, GoogLeNet, and ResNet, and the results are compared with the expert’s qualitative prediction results to confirm the feasibility of the prediction algorithm using a convolutional neural network."
자율주행을 위한 동적 객체 인식 방법에 관한 연구,2021,"['Deep Learning', 'Faster R-CNN', 'Machine Learning', 'Support Vector Machine', 'Object Detection', 'Unmanned Vehicle', 'YOLO']",국문 초록 정보 없음,"Dynamic object recognition is an important task for autonomous vehicles. Since dynamic objects exhibit a higher collision risk than static objects, our own trajectories should be planned to match the future state of moving elements in the scene. Time information such as optical flow can be used to recognize movement. Existing optical flow calculations are based only on camera sensors and are prone to misunderstanding in low light conditions. In this regard, to improve recognition performance in low-light environments, we applied a normalization filter and a correction function for Gamma Value to the input images. The low light quality improvement algorithm can be applied to confirm the more accurate detection of Object's Bounding Box for the vehicle. It was confirmed that there is an important in object recognition through image prepocessing and deep learning using YOLO."
A Neural Network Based Computational Model for Post-transcriptional Modification Site Identification,2021,"['Convolution Neural Network (CNN)', 'Artificial Intelligent Systems', 'Computational Biology', 'Bioinformatics', 'Post-transcriptional Modification']",국문 초록 정보 없음,"In a variety of cellular and developmental processes, RNA alterations are important. Understanding the distributions of RNA modifications in genome sequences will lead to the discovery of their functions. In the last five years, computational methods for identifying RNA changes have been presented because experimental methods are time consuming and complex. However, both experimental and existing computational approaches have difficulties when it comes to concurrently recognizing changes on various nucleotides. Recently a machine learning based model for simultaneously identifying multiple kinds of RNA modifications was proposed however the neural networks for such problem are not explored yet. To solve this problem, we built a new predictor in this paper that can identify m6A, m5C, and m1A for alterations in Homo sapiens, Mus musculus, and Saccharomyces cerevisiae at the same time. The proposed model uses k-mer encoding scheme to encode the input sequence. The encoded sequence is used by convolution neural network which automatically learns the features and performs classification between modified and unmodified sequences. The 10-fold cross-validation results have exhibited improved results in comparison to the existing state-of-the-art results in literature."
딥러닝 기반의 효율적인 객체 인식을 위한 데이터 셋 구성,2021,"['Data set', 'faster R-CNN', 'deep learning', 'brightness', 'composite image']",국문 초록 정보 없음,다국어 초록 정보 없음
수환경 내 미량오염물질 정량화를 위한 딥러닝 기법 연구,2021,"['미량오염물질', '딥러닝', '고분해능질량분석', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
Thermal Sensor-Based Activity Detection in Smart Spaces using GentleBoost Optimized Classifier,2021,"['Fall Detection', 'Ensemble Learning', 'CNN', 'Smart spaces']",국문 초록 정보 없음,"On the smart factory shop floor, the safety of persons can be enhanced with an effective human activity detection system. This system should have the ability to monitor issues like fall detection which is a common work-related accident. In this work, we have used a public dataset that is based on a thermal array (ambient) sensor for the detection and classification of falls on the smart factory shop floor. The performance of the proposed optimized ensemble learning in MATLAB R2019b shows an accuracy of 100%, and a loss value of 0.00015642 using the minimum classification error plot."
Feasibility Evaluation of Brain Tumor Magnetic Resonance Imaging Classification Using Convolutional Neural Network Model,2021,"['MRI', 'Brain tumor', 'CNN', 'VGG16', 'Artificial intelligence', '자기공명영상', '뇌종양', '합성곱신경망', '인공지능']",국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망 인식률 개선을 위한 이미지 전처리에 대한 연구,2021,"['convolutional neural network', 'feature map', 'input shape', 'pre-processing', 'background padding']",국문 초록 정보 없음,"A convolutional neural network(CNN) produces an optimal feature map for that image by optimizing the weights of the kernel through the learning process. Therefore, it can be expected that the optimal learning rate will be achieved when utilizing datasets optimized for input shape of neural network models. However, using public datasets or collecting images directly by researchers may not be suitable for the input shape. In this paper, several steps of image pre-processing methods were tested to increase the recognition rate of convolutional neural networks. As a result of comparing the recognition rate before and after pre-processing for the datasets, the result after pre-processing improved the accuracy by 5.73%. Through this, it was found that the pre-processing method for the learning image had an important effect on improving recognition rates."
전이학습 기반의 해충 영상 분류 성능 비교,2021,"['Pest Classification', 'Deep Learning', 'CNN', 'Transfer Learning']","수많은 종류의 해충은 종류에 따라 물리적인 피해, 작물 수확의 피해 그리고 생태계 보전 가치를 해치는 피해를 준다. 하지만 해충은 작고 비슷하게 생겨 전문가가 아닌 사람이 육안으로 해충의 종류를 알고 분류하기란 쉽지 않다. 따라서 본 논문은 해충 영상을 분류를 위해 6개의 딥러닝 모델 ResNet50, VGG16, SqueezeNet, FPN(Feature Pyramid Network), Attention Gated Network, PVT(Pyramid Vision Transformer)의 분류 성능에 대한 비교 분석을 하려 한다 이를 통해 해충 영상 분류에 가장 우수한 모델을 찾아 해충의 종류에 따른 적합한 방제 시스템을 구축하고자 한다.","Numerous types of pests cause physical damage, damage to crop harvest, and damage that harms ecosystem conservation value depending on the type. However, since the pests are small and similar, it is not easy for non-experts to recognize and classify the types of pests with the naked eye. Therefore, this paper want to perform a comparative analysis on the classification performance of six deep learning models ResNet50, VGG16, SqueezeNet, FPN(Feature Pyramid Network), Attention Gated Network, and PVT(Pyramid Vision Transformer) to classify pest images. Through this, we want to find the best model for pest image classification and build an appropriate control system according to the pest type."
CoS: 딥러닝을 위한 시그모이드로 구성한 강조된 부드러운 비단조성 활성 함수,2021,"['activation function', 'deep learning', 'CNN', 'neural network', 'object detection']",국문 초록 정보 없음,"Activation functions are important components that affect the performance of neural networks. Activation functions such as Step, Sigmoid, Tanh, and ReLU have problems such that the important differentiation is not possible or the gradient is vanishing. Activation function Swish solved the problem with Characteristic of a smooth non-monotonic curves and boundary value of negative. Based on these characteristics, in this paper, we propose a Consisting of Sigmoid(CoS) function adding a smooth emphasized non-monotonic curves part and reducing negative results on negative inputs and improving the flow of information within the neural network. Through the proposed method, it was certain that accuracy is improved by 0.46%~0.77% and 0.38%~0.54% over the existing ReLU and Swish."
암세포 영상분류를 위한 심층학습 모델 연구,2021,"['Cancer Cell', 'Classification', 'CNN', 'Deep Learning']","특정 질병 진단을 위한 병리 검사는 필수적이며, 최근 이러한 분야의 시간적, 인적 자원의 필요성을 줄이기 위해 인공 지능을 활용한 암세포의 자동분류가 가능한 시스템 구축에 관련된 연구가 활발하게 진행되고 있다. 하지만, 이전 연구에서는 제한적인 심층학습 알고리즘에 기인한 비교적 낮은 정확도로 데이터 처리에 한계가 존재하였다. 본 연구에서는 심층 학습의 일종인 Convolution Neral Network를 통해 4종류의 암세포를 4 Class Classification을 시행하는 방법을 제안한다. EfficientNet, ResNet, Inception을 사용하였으며 여러 하이퍼 파라미터 튜닝을 통해 얻은 모델을 앙상블 하여 최종적으로 97.26의 정확도를 얻을 수 있었다.","Additional pathological tests using imaging equipment are essential before diagnosing cancer cells. Recently, in order to reduce the need for time and human resources in these fields, research related to the establishment of a system capable of automatic classification of cancer cells using artificial intelligence is being actively conducted. However, in both previous studies, there were relatively limited deep learning algorithms and cell types, and limitations existed with low accuracy at the same time. In this study, a method of performing 4class Classification on four types of cancer cells through the Convolution Neral Network, a type of in-depth learning. EfficientNet, ResNet, and Inception were used, and finally Resnet was used to obtain an accuracy of 96.11 on average for k-fold."
헬스케어 디바이스를 고려한 심음 분류 모델과 경량화 연구,2021,"['Heart Sound Classification', 'CNN', 'Light Weight', 'Health Care Device']",국문 초록 정보 없음,다국어 초록 정보 없음
Integrated Deep Learning Framework for Accelerated Optical Coherence Tomography Angiography,2021,"['Convolutional neural network (CNN)', 'deep learning (DL)', 'generative adversarial network (GAN)', 'high-speed imaging', 'optical coherence tomography angiography (OCTA)', 'two-stage network']",국문 초록 정보 없음,"Optical coherence tomography angiography (OCTA) has become a premium imaging tool in clinics to obtain structural and functional information of microvasculatures. One primary technical drawback for OCTA is its imaging speed. The current protocols require high sampling density and multiple acquisitions of cross-sectional B-scans to form one image frame, resulting in low acquisition speed. Recently, deep learning (DL)-based methods have gained attention in accelerating the OCTA acquisition process. They achieve faster acquisition using two independent reconstructing approaches: high-quality angiograms from a few repeated B-scans and high-resolution angiograms from undersampled data. While these approaches have shown promising results, they provide limited solutions that only partially account for the OCTA scanning mechanism. Herein, we propose an integrated DL method to tackle both factors in tandem and further enhance the reconstruction performance in speed and quality. We designed two-stage convolutional neural networks (CNNs) to reconstruct fully-sampled, high-quality (8 repeated B-scans) angiograms from their corresponding undersampled, low-quality (2 repeated B-scans) counterparts by successively enhancing the pixel resolution and the image quality. Using an in-vivo mouse brain vasculature dataset, we evaluate our proposed models through quantitative and qualitative assessments and demonstrate that our method can achieve superior reconstruction performance compared to conventional interpolation-based methods."
심층 학습을 통한 암세포 광학영상 식별기법,2021,"['Cancer Cell', 'Classification', 'CNN', 'Deep Learning']","임상에서 암 관련 질병의 확진을 위해 영상장비를 이용한 기초 진단 이후 추가적인 방법으로 생체검사 등을 이용한 병리적 검사가 필수적이다. 이러한 생체검사를 진행하기 위해서는 전문지식을 가진 종양학자, 임상병리사 등의 도움과 최소한의 소요시간은 확진을 위해 반드시 필요하다. 최근 들어, 인공지능을 활용한 암세포의 자동분류가 가능한 시스템 구축에 관련된 연구가 활발하게 진행되고 있다. 하지만, 이전 연구들은 한정된 알고리즘을 기반으로 하여 세포의 종류와 정확도에 한계를 보인다. 본 연구에서 심층 학습의 일종인 합성곱 신경망을 통해 총 4가지의 암세포를 식별하는 방법을 제안한다. 세포 배양을 통해 얻은 광학영상을 OpenCV를 사용하여 세포의 위치 식별 및 이미지 분할과 같은 전처리 수행 후, EfficientNet을 통해 학습하였다. 모델은 EfficientNet을 기준으로 다양한 hyper parameter를 사용하고, InceptionV3을 학습하여 성능을 비교분석 하였다. 그 결과 96.8%의 높은 정확도로 세포를 분류하는 결과를 보였으며, 이러한 분석방법은 암의 확진에 도움이 될 것으로 기대한다.","For the diagnosis of cancer-related diseases in clinical practice, pathological examination using biopsy is essential after basic diagnosis using imaging equipment. In order to proceed with such a biopsy, the assistance of an oncologist, clinical pathologist, etc. with specialized knowledge and the minimum required time are essential for confirmation. In recent years, research related to the establishment of a system capable of automatic classification of cancer cells using artificial intelligence is being actively conducted. However, previous studies show limitations in the type and accuracy of cells based on a limited algorithm. In this study, we propose a method to identify a total of 4 cancer cells through a convolutional neural network, a kind of deep learning. The optical images obtained through cell culture were learned through EfficientNet after performing pre-processing such as identification of the location of cells and image segmentation using OpenCV. The model used various hyper parameters based on EfficientNet, and trained InceptionV3 to compare and analyze the performance. As a result, cells were classified with a high accuracy of 96.8%, and this analysis method is expected to be helpful in confirming cancer."
Shoulder joint monitoring during upper limb rehabilitation exercises based on convolutional neural networks using a wrist-worn inertial sensor,2021,"['Inertial Sensor(관성 센서)', 'CNN(합성곱 신경망)', 'Rehabilitation(재활)']",국문 초록 정보 없음,"Stroke patients need continuous home rehabilitation for recovery and recurrence prevention. Recently, a home rehabilitation system based on an inertial sensor had been developed and its clinical effectiveness was evaluated. However, the existing studies still have limitations in monitoring the detailed status of patients such as kinematic and kinetic information. Therefore, in this study, we propose a convolutional neural networks-based method to estimate the range of motion, maximum force, and maximum torque of the shoulder joint from a wrist-worn inertial sensor during upper limb rehabilitation exercises. To verify the method, seven male participants without disability performed five upper limb rehabilitation exercises. An optical motion capture system was used to collect and calculate the reference data. As a result, the proposing method estimated each shoulder joint metric with an average error of 3.2±1.5°, 6.00±4.76 %, and 8.17±6.53 %, respectively. The proposing method enables monitoring the detailed kinematic and kinetic status of the users from an inertial sensor during the rehabilitation exercises and may help them to continue the home rehabilitation for better recoveries."
합성곱 신경망기반 딥러닝의 용접연구 적용 Part I: 모델과 활용사례,2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
온라인 한글 필기 글자 구분을 위한 전처리 모듈 개발,2021,"['hand-written', 'recognition', 'CNN', 'preprocessing module']",국문 초록 정보 없음,다국어 초록 정보 없음
Object Pose Estimation via Viewpoint Matching of 3D Models,2021,"['SLAM', 'Object detection', '3D CAD', 'Deep learning', 'CNN', 'Semantic Map']",국문 초록 정보 없음,"Object recognition in a static or dynamic environment provides important information in semantic SLAM. In this paper, we provide a system that can detect objects that are not registered in advance and build a data set that can automatically learn pose information from a recognition network using a CAD model. In general, object recognition and SLAM algorithms operate independently but complementary. When recognizing an object only with an image, it is difficult to grasp the exact posture or properties required by the SLAM algorithm. However, in order to build a 3d object recognition network, preparations such as modeling and labeling are required in advance, so it is difficult to apply to SLAM. In this paper, the CAD model can be applied to the SLAM algorithm by making artificial images rendered from various directions, reducing the effort of additional model or labeling work."
A Study on Fruit Quality Identification Using YOLO V2 Algorithm,2021,"['YOLOV2', 'Region Of Interest', 'Bound Box', 'R-CNN', 'Artificial Intelligence']",국문 초록 정보 없음,"Currently, one of the fields leading the 4th industrial revolution is the image recognition field of artificial intelligence, which is showing good results in many fields. In this paper, using is a YOLO V2 model, which is one of the image recognition models, we intend to classify and select into three types according to the characteristics of fruits. To this end, it was designed to proceed the number of iterations of learning 9000 counts based on 640 mandarin image data of 3 classes. For model evaluation, normal, rotten, and unripe mandarin oranges were used based on images. We as a result of the experiment, the accuracy of the learning model was different depending on the number of learning. Normal mandarin oranges showed the highest at 60.5% in 9000 repetition learning, and unripe mandarin oranges also showed the highest at 61.8% in 9000 repetition learning. Lastly, rotten tangerines showed the highest accuracy at 86.0% in 7000 iterations. It will be very helpful if the results of this study are used for fruit farms in rural areas where labor is scarce."
AR 네비게이션을 위한 딥러닝 기반의 VPS(Visual Positioning System),2021,[],국문 초록 정보 없음,다국어 초록 정보 없음
정형 및 비정형 데이터를 이용한 농산물 구매량 예측: 파프리카를 중심으로,2021,"['정형 데이터', '비정형 데이터', 'LSTM', 'CNN', 'SVR', 'Random Forest', 'XGBoost', 'SHAP', 'structured data', 'Unstructured data']",국문 초록 정보 없음,"Consumers’ food consumption behavior is likely to be affected not only by structured data such as consumer panel data but also by unstructured data such as mass media and social media. In this study, a deep learning-based consumption prediction model is generated and verified for the fusion data set linking structured data and unstructured data related to food consumption. The results of the study showed that model accuracy was improved when combining structured data and unstructured data. In addition, unstructured data were found to improve model predictability. As a result of using the SHAP technique to identify the importance of variables, it was found that variables r elated to b log and video data were on the top list and had a positive correlation with the amount of paprika purchased. In addition, according to the experimental results, it was confirmed that the machine learning model showed higher accuracy than the deep learning model and could be an efficient alternative to the existing time series analysis modeling."
기립상태 판별을 위한 족압 및 족부 움직임 측정 방법,2021,"['FSR', 'posture analysis', 'wearable sensors', 'CNN']",국문 초록 정보 없음,"Most human-mimicking robots are designed to have rigid frames that transmit the actuation force and are aimed at mobility, such as walking or running. There have been many attempts to implement the human foot structure, consisting of dozens of joints and flexible muscles, as a mechanical system. The feet are used not only for functional purposes such as mobility, but also for artistic expressions such as dancing. To implement a variety of postures with a robotic system, robust hardware and control methods are required. In particular, the motion of maintaining balance by standing only at the tip of the toe, such as the pointe technique of ballet, requires a wide angular range of the ankle and toe joints. In this paper, we propose a sock-type measurement system to analyze the state of standing on tiptoe. Foot pressure was measured by FSR (Force Sensitive Resistor) sensors, and foot movement was analyzed through image processing. The state when standing normally and when standing on tiptoe was determined by applying an artificial neural network model."
MPFANet: Semantic Segmentation Using Multiple Path Feature Aggregation,2021,"['MPFA', 'Semantic segmentation', 'Feature aggregation', 'CNN', 'Inverted residual block', 'Local context']",국문 초록 정보 없음,"Image segmentation is the process of simplifying the analysis of the meaning or the front to say the process of dividing the image into a set of multiple pixels. The multiple path feature aggregation (MPFA) method proposed in this paper aims to extract various information of an object, and uses conventional pyramid pooling or the extraction of various sized features. This information can be combined with different regional features to obtain the overall feature information. We split four paths to extract numerous local features, and the results showed that the mean intersection over union (mIOU) is 81.6% for the validation data from the PASCAL VOC 2012 dataset, and a better performance than the existing DeepLab model was demonstrated."
EfficientNet Architecture-Based Systems and Algorithms for Predicting Emotions in Humans,2021,"['Emotion Recognition', 'Bio-signal', 'AI', 'EfficientNet', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
기계학습을 이용한 공동 유동 가사화 연구,2021,"['Tip Vortex', 'Cavitation', 'Convolution Neural Network(CNN)', 'Machine Learning']",국문 초록 정보 없음,다국어 초록 정보 없음
음향신호를 이용한 기어박스모듈의 지능형 불량 검출 기법,2021,"['Anomaly Detection(이상감지)', 'Deep Learning(딥러닝)', 'CNN(콘볼루션신경망)', 'Auto Encode(오토인코더)']",국문 초록 정보 없음,다국어 초록 정보 없음
드론비행영상을 활용한 도로 혼잡도 분석,2021,"['Deep Learning', 'Traffic Analysis', 'Drone', 'CNN', 'Image Processing']",국문 초록 정보 없음,"Analysis of traffic consegstion is an important role in traffic management and distribution. Drone flight image is searching on the wide view of road information at once. This paper aims to analyze how congested the roads are detecting vehicles on the road using drone flight images taken in the city. Based on the YOLO architecture, the congestion analysis process is conducted with 83.3% accuracy for vehicle detection and 87.5% accuracy for lane detection. The information obtains through this is expected to analyze the traffic volume and navigation performance of roads. Furthermore, as it is a study that analyzes actual road condition, it is a helpful for traffic management and traffic signal systems."
An IoT based Cloud EEG Signal Analytic Framework for Thought to Text Mapping,2021,"['AWS lambda', 'Brain-computer interface', 'Cloud computing', 'CNN', 'EEG signal', 'IoT', 'Imagined speech to text']",국문 초록 정보 없음,"Paralyzed people have difficulty communicating with the world for their daily basic needs, and their caretakers have difficulty understanding their needs. The development and implementation of a handheld device-based brain-computer interface system with machine learning will solve the above problem. On the other hand, a simple handheld device cannot satisfy the computation of hunger ML algorithms and will have more latency. This paper overcomes the limitations of the above by processing the data in the cloud. The handheld device reads and preprocesses the electroencephalogram (EEG) data and forwards it to the IoT-based Cloud server. The cloud server applies the machine-learning algorithm and classifies it in the text, representing the word thought by the user. This text information result is sent back to the handheld device and intimates the caretaker to know the patient""s needs. The evaluation result of the proposed system for ten words to deal with the basic needs highlights the feasibility of implementing it in practice."
통계적 기법과 머신러닝을 이용한 진동데이터 기반의 이상 진단,2021,"['Anomaly detection', 'Mahalanobis', 'Vibration', 'Machin learning', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
Google Colab을 이용한 객체 검출 알고리즘 비교,2021,"['Deep running', 'Object detection', 'Google colab', 'YOLOv5', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
인접 픽셀 정보를 이용한 Shift-Convolution 기반의 3D LiDAR 깊이 완성,2021,"['Heterogeneous sensor calibration(이종 센서 캘리브레이션)', 'CNN(콘볼루션 뉴런 네트워크)', 'Depth completion(깊이 완성)', 'Autonomous driving(자율주행)', 'LiDAR(라이다)']",국문 초록 정보 없음,다국어 초록 정보 없음
Identification of Indian butterflies using Deep Convolutional Neural Network,2021,"['Indian butterfly identification', 'ButterflyNet', 'Butterfly', 'classification CNN', 'Computer vision']",국문 초록 정보 없음,"The conventional butterfly identification method is based on their different morphological characters namely wing-venation, color, shape, patterns and through the dissection studies and molecular techniques which are tedious, expensive and highly time-consuming. To overcome the above aforesaid challenges, a new butterfly identification system using butterfly images has been designed to instantly identify the butterfly with high ac curacy. In this study, we construct a new butterfly dataset with 34,024 butterfly images belonging to 315 species from India. We propose and prove the effectiveness of new data augmentation techniques on our dataset. To identify butterflies using photographic images, we built eleven new Deep Convolutional Neural Network (DCNN) butterfly classifier models using eleven pre-trained architectures namely ResNet-18, ResNet-34, ResNet-50, ResNet-121, ResNet-152, Alex-Net, DenseNet-121, DenseNet-161, VGG-16, VGG-19 and SqueezeNet-v1.1. The different model’s classification results were compared and the proposed technique achieved a maximum top-1 accuracy(94.44%), top-3 accuracy(98.46%) and top-5 accuracy(99.09%) using ResNet-152 model, followed by DenseNet-161 model achieved the top-1 accuracy(94.31%), top-3 accuracy (98.07%) and top-5 accuracy (98.66%). The results suggest that models can be assertively used to identify butterflies in India."
삼중항 손실 기반의 잔여 네트워크를 이용한 손가락 정맥 인식,2021,"['Finger-vein Identification', 'Deep learning', 'Triplet loss', 'CNN', 'Biometrics']","본 논문은 높은 정확도의 손가락 정맥 인식을 위해 삼중항 손실 기반의 심층 신경망을 설계하여 손가락 정맥 인식 알고리즘을 개발하는 것을 목적으로 한다. 심층 신경망을 이용한 분류기는 높은 정확도를 보장하기 위해 많은 학습 데이터가 필요하다. 그러나 손가락 정맥 인식에서는 학습 데이터가 적으면서 판별해야 할 클래스가 많기 때문에 기존 심층 신경망을 이용한 분류기는 적합하지 않다. 이러한 문제를 해결하기 위해, 서로 유사성을 가진 손가락 정맥 이미지를 차별적으로 학습하는 네트워크 구조를 설계하고, 높은 정확도의 인식률을 이끌어 내기 위한 목적 함수를 제안한다. 본 논문에서는 손가락 정맥 패턴의 특성에 최적화시키기 위해, 멀티 클래스 크로스 엔트로피와 삼중항 손실이 결합된 네트워크를 구축하여 인식률을 효과적으로 개선한다. 실험 결과 MMCBNU, FV_USM 그리고 SDUMLA 데이터 셋에서 각각 99.40%, 99.48%, 95.91% 정확도로 우수한 성능을 나타낸다.","The purpose of this paper is to develop a finger-vein identification algorithm by designing a deep neural network based on triplet loss for high accuracy. classifiers using deep neural networks require a lot of learning data to ensure high accuracy. However, in finger-vein identification, the classifier using the existing deep neural network is not suitable. Because the learning data is small and there are many classes to be identified. To solve this problem, we propose a network structure and loss function that extracts and identifies more differentiated features from finger-vein images for high accuracy. To learn the network by optimizing the characteristics of the finger-vein pattern, we construct a network that combines multi-class cross-entropy loss and triplet loss to effectively improve the identification accuracy. Experimental results show performance with 99.40%, 99.48%, 95.91% accuracy in the MMCBNU, FV_USM, and SDUMLA dataset."
MMS의 영상데이터에서 딥러닝을 이용한 수직 교통시설물의 검출,2021,"['정밀도로지도', '안전표지', '신호등', 'Mask R-CNN', '3차원 점군데이터']",국문 초록 정보 없음,다국어 초록 정보 없음
불균형데이터의 비용민감학습을 통한 국방분야 이미지 분류 성능 향상에 관한 연구,2021,"['Imbalanced Data', 'Cost-sensitive Learning', 'CNN', '불균형데이터', '비용민감학습', '컨볼루션 신경망']",국문 초록 정보 없음,"With the development of deep learning technology, researchers and technicians keep attempting to apply deep learning in various industrial and academic fields, including the defense. Most of these attempts assume that the data are balanced. In reality, since lots of the data are imbalanced, the classifier is not properly built and the model’s performance can be low. Therefore, this study proposes cost-sensitive learning as a solution to the imbalance data problem of image classification in the defense field. In the proposed model, cost-sensitive learning is a method of giving a high weight on the cost function of a minority class. The results of cost-sensitive based model shows the test F1-score is higher when cost-sensitive learning is applied than general learning's through 160 experiments using submarine/non-submarine dataset and warship/non-warship dataset. Furthermore, statistical tests are conducted and the results are shown significantly."
소형화 연산장치를 위한 최적 합성곱 계층 결합 모델의 밭 작물 인식,2021,"['Detection', 'Embedded', 'Neural network', 'CPU inference']",국문 초록 정보 없음,"Object detection in artificial neural networks using CNN has made great progress. However, as the performance of the network advances and advances, the complexity of the structure increases and the training time becomes longer. Furthermore, the increasing usage of GPU, which is the core of computation, makes it difficult to operate on multiple mobile and miniaturized devices. We construct using only optimized number of convolutional layers. We study configurability on local devices by testing them on CPUs. As a result of testing the constructed model on the CPU with the aim of testing it on a device for detecting field crops, the mAP of the model detecting crops and weeds achieved approximately 0.61 and the FPS achieved approximately 4."
잎사귀 질병 검출을 위한 어텐션 YOLO 모델,2021,"['Attention YOLO Model', 'Object Detection', 'Image Segmentation', 'CNN', 'Smart Farm']","기존 객체 검출에서 사용되고 있는 YOLO 모델은 특칭 추출과 분류를 한 번에 진행하여 빠르고 간단한 것이 특징이다. 실시간 객체 검출에서 사용할 수 있을 정도의 성능을 보이지만, 정확도 측면에서는 조금 아쉬운 것이 사실이다. 이러한 YOLO 모델을 잎사귀 질병 검출에서 활용할 때, 어텐션 기법을 활용해 잎사귀 질병의 특징을 적용한 모델과 기존 객체 검출 모델들의 성능을 비교하고자 한다.","The YOLO model is characterized by a simple feature extraction and classification at once. Although it shows performance enough to be used in real-time object detection, It is true that it is a bit disappointing in terms of accuracy. When using this YOLO model for leaf disease detection, we intend to create and apply a feature map for the region of interest to improve accuracy. Also, we want to compare the performance of the applied model and the existing object detection models."
인공지능 기반 교량 파손 유형별 분류 검출 방안 연구,2021,"['정기점검', '분류 알고리즘', '드론', 'Mask R-CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
결함검출 적용을 위한 YOLO 딥러닝 알고리즘 비교,2021,"['YOLO', 'Deep learning', 'Object detection', 'Defect detection', 'CNN']",국문 초록 정보 없음,"Recently, metal 3D printing technology has developed and has been widely applied in fields such as mechanical parts and construction sites. However, the problem of output defects must be resolved. These defects appear as pores and microcracks in the output, which can be confirmed through microscopic analysis of the output. In addition, if the understanding of pores or cracks is unclear or many images need to be checked in a short time, an error might occur. Therefore, this study aims to develop a precision object detection algorithm using deep learning. The purpose is to automatically detect defects using deep learning-based You Only Look Once (YOLO). Through comparison using YOLO v3 and v5 algorithms, the accuracy and speed were compared to analyze which YOLO model was efficient in the defect detection process."
다중 도메인 학습을 이용한 화면 촬영 영상 내 모아레 무늬 제거 기법,2021,"['Moire artifacts removal', 'demoireing', 'convolutional neural network (CNN)', 'multiple domain learning']",국문 초록 정보 없음,"We propose a moire artifacts removal algorithm for screen-shot images using multiple domain learning. First, we estimate clean preliminary images by exploiting complementary information of the moire artifacts in pixel value and frequency domains. Next, we estimate a clean edge map of the input moire image by developing a clean edge predictor. Then, we refine the pixel and frequency domain outputs to further improve the quality of the results using the estimated edge map as the guide information. Finally, the proposed algorithm obtains the final result by merging the two refined results. Experimental results on a public dataset demonstrate that the proposed algorithm outperforms conventional algorithms in quantitative and qualitative comparison."
딥러닝 기반 OpenPose를 이용한 한국 수화 동작 인식에 관한 연구,2021,"['딥러닝', '한국 수화', '수화인식', 'Deep Learning', 'CNN', 'OpenPose', 'Korea Sign Language', 'Sign Language Recognition']",국문 초록 정보 없음,"Most of the studies on the existing sign language use expensive equipment or do not consider non-manual signals. In order to improve this problem, we intend to acquire an image using an RGB camera and recognize sign language by including non-manual signals, which take a considerable weight in sign language, beyond recognizing only the existing hand shape. By using the OpenPose library, hand gestures, body gestures, and facial expressions were represented in the data as key points and were included as the non-manual signals. In addition, we propose a method of learning data using a deep learning neural network model and recognizing sign language motion through the trained model. In this paper, the goal is to increase the recognition rate for each sign language motion without the help of a specific sensor or wearable device because it learns data including non-manual elements and recognizes sign language motions."
합성곱 신경망을 이용한 컨포멀 코팅 PCB에 발생한 문제성 기포 검출 알고리즘,2021,"['Problematic Bubble', 'Bubble Detection', 'Conformal Coating', 'CNN', 'ResNet']",국문 초록 정보 없음,"Conformal coating is a technology that protects PCB(Printed Circuit Board) and minimizes PCB failures. Since the defects in the coating are linked to failure of the PCB, the coating surface is examined for air bubbles to satisfy the successful conditions of the conformal coating. In this paper, we propose an algorithm for detecting problematic bubbles in high-risk groups by applying image signal processing. The algorithm consists of finding candidates for problematic bubbles and verifying candidates. Bubbles do not appear in visible light images, but can be visually distinguished from UV(Ultra Violet) light sources. In particular the center of the problematic bubble is dark in brightness and the border is high in brightness. In the paper, these brightness characteristics are called valley and mountain features, and the areas where both characteristics appear at the same time are candidates for problematic bubbles. However, it is necessary to verify candidates because there may be candidates who are not bubbles. In the candidate verification phase, we used convolutional neural network models, and ResNet performed best compared to other models. The algorithms presented in this paper showed the performance of precision 0.805, recall 0.763, and f1-score 0.767, and these results show sufficient potential for bubble test automation."
VVC 인코더에서 합성 곱 신경망의 어텐션 맵을 이용한 휘도 매핑 함수 생성 방법,2021,"['VVC', 'Encoder', 'Luma mapping with Chroma Scaling', 'CNN']",국문 초록 정보 없음,"In this paper, we propose a method for generating luma signal mapping function to improve the coding efficiency of luma signal mapping methods in LMCS. In this paper, we propose a method to reflect the cognitive and perceptual features by multiplying the attention map of convolutional neural networks on local spatial variance used to reflect local features in the existing LMCS. To evaluate the performance of the proposed method, BD-rate is compared with VTM-12.0 using classes A1, A2, B, C and D of MPEG standard test sequences under AI (All Intra) conditions. As a result of experiments, the proposed method in this paper shows improvement in performance the average of -0.07% for luma components in terms of BD-rate performance compared to VTM-12.0 and encoding/decoding time is almost the same."
딥러닝을 이용한 유도탄 공력 예측 모델 설계,2021,"['MPI(메시지 전달 인터페이스)', 'MLP(다층 퍼셉트론)', 'CNN (합성곱 신경망)', 'Signed Distance Function(거리 부호 함수)', 'Missile Aerodynamic Loads(유도탄 공력 하중)']",국문 초록 정보 없음,다국어 초록 정보 없음
SpNet-Mouse: Tissue based prediction of m6A sites in mouse genome using neural network,2021,"['N6-methyladenosine', 'SpinalNet', 'One-hot-encoding', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
Interpolation based Single-path Sub-pixel Convolution for Super-Resolution Multi-Scale Networks,2021,"['Super-resolution', 'multi-scalable network', 'multi-scale single-path Super-resolution']",국문 초록 정보 없음,"Deep leaning convolutional neural networks (CNN) have successfully been applied to image super-resolution (SR). Despite their great performances, SR techniques tend to focus on a certain upscale factor when training a particular model. Algorithms for single model multi-scale networks can easily be constructed if images are upscaled prior to input, but sub-pixel convolution upsampling works differently for each scale factor. Recent SR methods employ multi-scale and multi-path learning as a solution. However, this causes unshared parameters and unbalanced parameter distribution across various scale factors. We present a multi-scale single-path upsample module as a solution by exploiting the advantages of sub-pixel convolution and interpolation algorithms. The proposed model employs sub-pixel convolution for the highest scale factor among the learning upscale factors, and then utilize 1-dimension interpolation, compressing the learned features on the channel axis to match the desired output image size. Experiments are performed for the single-path upsample module, and compared to the multi-path upsample module. Based on the experimental results, the proposed algorithm reduces the upsample module's parameters by 24% and presents slightly to better performance compared to the previous algorithm."
Research on the Detection of Image Tampering,2021,"['Image', 'Tampering', 'Forensics', 'Deep learning', 'CNN', '이미지', '변조', '포렌식', '딥러닝']","정보의 주요 전달체로서 디지털 이미지는 점점 더 중요해지고 있다. 그러나 이미지 획득 장비의 대중화와 이미지 편집 소프트웨어의 급속한 발전으로 인해, 최근 몇 년간 디지털 이미지 위조사건이 잇따라 발생해 이미지의 신뢰도를 떨어뜨릴 뿐만 아니라 사회와 개인에게도 큰 악영향을 미치고 있다. 이미지 복사-붙여넣기 변조(image copy-paste tampering)는 가장 일반적인 유형의 이미지 변조 중 하나이며, 조작이 쉽고 효과적이기 때문에 디지털 이미지 의미 정보 변경에 자주 사용된다. 본 논문에서는 이미지 복사 및 붙여넣기의 변조 탐지 방법을 연구하여 이미지 콘텐츠의 진정성과 무결성을 보호하는 방법이 제안되었다. 딥러닝의 우수한 학습과 분석능력을 감안해 영상처리작업이 남긴 흔적을 활용해 영상 속 원본 영역과 변조된 영역을 구분하는 딥러닝 기반 변조 검출법 2가지가 제안되었다. 또한 실험을 통해 이론적 근거의 합리성, 변조 탐지, 위치 및 분류의 정확성을 검증하였다.","As the main carrier of information, digital image is becoming more and more important. However, with the popularity of image acquisition equipment and the rapid development of image editing software, in recent years, digital image counterfeiting incidents have emerged one after another, which not only reduces the credibility of images, but also brings great negative impacts to society and individuals. Image copy-paste tampering is one of the most common types of image tampering, which is easy to operate and effective, and is often used to change the semantic information of digital images. In this paper, a method to protect the authenticity and integrity of image content by studying the tamper detection method of image copy and paste was proposed. In view of the excellent learning and analysis ability of deep learning, two tamper detection methods based on deep learning were proposed, which use the traces left by image processing operations to distinguish the tampered area from the original area in the image. A series of experimental results verified the rationality of the theoretical basis, the accuracy of tampering detection, location and classification."
Mesoscale spatial-temporal prediction of monthly streamflow in poorly gauged basins: A case study,2021,"['Climate Change', 'Convolutional Neural Network (CNN)', 'Recurrent Neural Network (RNN)', 'Streamflow Prediction', 'Transfer Learning']",국문 초록 정보 없음,다국어 초록 정보 없음
Neural Network Tomography for Noisy Quantum States,2021,[],국문 초록 정보 없음,"We present convolutional neural network (CNN) as a solution for simultaneous quantum state tomography and noise mitigation of high-dimensional qudits. Other approaches including maximum likelihood estimation and particle filtering have a propensity of converging to incorrect quantum states due to state preparation errors and decoherence. We provide details of the model architecture, and report the mean squared error and fidelity of our estimates. In this manner, we demonstrate the usefulness of CNNs for real quantum devices that are noisy."
An Invention of Portable Device to Self-Evaluate Welding Quality using Short-Range Laser Scanning,2021,"['Welding Quality', 'Laser Scanning', 'Camera Sensor', 'CNN']",국문 초록 정보 없음,"Welding is important for the manufacturing industry, including shipbuilding and railway, and construction industry, particularly in pipeline, bridge, and building such as airport. 100% inspection is performed visually after welding, which takes a lot of man-hours and presents the difficult task of securing highly skilled and experienced inspection staff. Human errors such as overlooking minute defects are also a serious challenge. Therefore, in recent years, in order to solve problems such as increase in productivity, improvement in quality, and shortage of manpower, research on the establishment of an automated welding quality inspection system using vision has been actively conducted. However, there is still no development of a portable inspection device that determine whether welding quality is defective or not in comparison of the welding quality standard. In this paper, a portable device using a near-field laser scanning was developed to self-evaluate the welding quality of various welding bead types including girth, fillet, and flat. The numerical profile of the welding bead obtained from a short-range line laser sensor is analyzed in real time to determine the compliance with the welding quality standard. The developed device was miniaturized so that the welding quality inspector can easily carry it, and also various welding quality standards such as ASME and AWS used in Korea were built into the device. As the datasets scanned by laser scanner and camera sensor are automatically analyzed in real time in conjunction with the standard, it is possible to check immediately whether the welding bead is defective or not."
포말대에서의 파랑특성을 관측하기 위한 STIV의 적용성 평가,2021,"['Swash zone', 'STIV', 'Artificial intelligence', 'CNN', 'Surface velocity', 'Rip current']",국문 초록 정보 없음,"The swash zone is an area that causes a change in the shape of a beach by generating sediment transport under the influence of intermittent waves, where wave run-up and run-down are infinitely repeated in the final stage of the shoaling process. However, the ability to predict the sediment transport is extremely poor despite the swash zone being an extremely important area in terms of offshore disaster prevention. In particular, many researchers are conducting studies on the development of various types of observation equipment and analysis techniques because the turbulent flow of active fluid dominates the sediment transport and is an extremely important parameter for the analysis of the transport mechanism. However, in flow velocity measurement, it is difficult to measure a quantitative representative flow velocity over time because the swash zone has a shallow water depth and an active turbulent flow. Expensive equipment and short-time measurement are also limitations. Therefore, the purpose of this study was to evaluate the applicability of nonintrusive space-time image velocimetry(STIV) to analyze the flow characteristics of fluid in the swash zone, such as the movement velocity and period of intermittent waves in the shoaling process. The prediction accuracy was improved by removing various noises included in the images with the introduction of artificial intelligence for immediate and accurate calculation of the representative flow velocity using images that can be obtained easily. Consequently, it was discovered that the spatial representative flow velocity occurring in the swash zone, change in the wave period according to the shoaling effect, rip current and surface velocity can be measured."
비디오 기반 딥러닝 융합 알고리즘에 의한 화재 감지 시스템에 관한 연구,2021,"['화재 감지', '연기 감지', '딥러닝', '객체 인식', 'CNN', 'Fire detection', 'smoke detection', 'deep learning', 'object detection', 'tracking', 'CNNs']",국문 초록 정보 없음,다국어 초록 정보 없음
메타러닝과 3D 이미지를 활용한 도심지내 밀리미터파 경로 손실 모델링,2021,"['Millimeter Wave', 'Path Loss Modeling', 'Meta-Learning', '5G', 'Convolutional Neural Network']",국문 초록 정보 없음,다국어 초록 정보 없음
수술 도구의 세분화와 행동 인식 기능이 탑재된 AI 서비스 개발,2021,"['Deep learning', 'Convolutional neural network (CNN)', 'Surgical tool', 'Segmentation', 'Recognition', 'AI service']",국문 초록 정보 없음,"In this paper, we propose an artificial intelligence (AI) service that plays a supportive role in robot assisted-surgery using deep learning algorithm that have recently been spotlighted in several fields. The proposed AI service is equipped with the ability to segment surgical tools and the ability to recognize the behavior of surgical tools. In addition, such AI service is opened using public web page to make them easier for surgeons to use. Models mounted on AI service are segmentation deep learning model and action recognition deep learning model. The segmentation deep learning model showed a final mIoU performance of 0.867 for seven surgical tools, and the action recognition deep learning model shows an accuracy of 86.96% for the opening and closing actions of all surgical tools."
A new framework for Person Re-identification: Integrated level feature pattern (ILEP),2021,"['Person reidentification', 'LBP', 'HOG', 'Deep features', 'PCA', 'CNN', 'm-XceptionNet']",국문 초록 정보 없음,"The system for re-identifying persons is used to find and verify the persons crossing through different spots using various cameras. Much research has been done to re-identify the person by utilising features with deep-learned or hand-crafted information. Deep learning techniques segregate and analyse the features of their layers in various forms, and the output is complex feature vectors. This paper proposes a distinctive framework called Integrated Level Feature Pattern (ILFP) framework, which integrates local and global features. A new deep learning architecture named modified XceptionNet (m-XceptionNet) is also proposed in this work, which extracts the global features effectively with lesser complexity. The proposed framework gives better performance in Rank1 metric for Market1501 (96.15%), CUHK03 (82.29%) and the newly created NEC01 (96.66%) datasets than the existing works. The mean Average Precision (mAP) calculated using the proposed framework gives 92%, 85% and 98%, respectively, for the same datasets."
AI기술을 활용한 가스터빈 연소불안정 이상진단 및 예측,2021,"['Gas Turbine(가스터빈)', 'Deep Learning(심층 학습)', 'CNN(합성곱 신경망)', 'Anomaly Detection and Prediction System(이상 진단 예측 시스템)']",국문 초록 정보 없음,다국어 초록 정보 없음
ConvLSTM2D 기법을 이용한 부분방전 유형 자동분류 성능개선,2021,"['partial discharge', 'prediction model', 'UHF sensor', 'deep learning', 'CNN algorithms', 'LSTM']",국문 초록 정보 없음,"Conv2D techniques can be used to automatically classify the type of partial discharge by learning with two-dimensional data with the phase and amplitude of the partial discharge signal, but fail to take into account the characteristics of the time series, resulting in the failure to accurately classify the type of partial discharge. In the paper, we propose an automatic classification technique of the type of partial discharge using the ConvLSTM2D technique with LSTM, which reflects time series characteristics on the Conv2D technique. The ConvLSTM2D technique proposed in this work is a method of learning with three-dimensional data with the phase, amplitude and time of the partial discharge signal. Experiments using Corona discharge and void discharge data, a representative type of partial discharge, confirm that ConvLSTM2D techniques improve the accuracy of classifying the types of Corona discharge and void discharge than conventional Conv2D techniques. The results of this paper are expected to be utilized in the field of failure prediction of switchboards through accurate automatic classification of the types of corona discharge and void discharge, which are representative types of partial discharge occurring in switchboards."
Machine Learning을 이용한 가상 에너지 생산 및 공급 시설의 실시간 고장 예측 진단 모델 설계,2021,"['Predictive Analytics', 'Prognostics and Health Management(PHM)', 'Convolutional Neural Network(CNN)', 'Long Short Term Memory(LSTM)', 'Artificial Neural Network(ANN)']",국문 초록 정보 없음,다국어 초록 정보 없음
A Deep Learning Based Approach for Strawberry Yield Prediction via Semantic Graphics,2021,"['semantic graphics', 'yield forecasting', 'crop management', 'segmentation', 'deep learning', 'encoder-decoder cnn']",국문 초록 정보 없음,"In Korea, strawberry producers lack efficient and precise yield forecasts, which would allow them to deploy optimal manpower, equipment, and other resources for harvesting, shipping, and marketing. Reliable estimation of the quantity of strawberry fruit with respect to their ripeness level is critical for forecasting the upcoming strawberry production. Typically, the quantity and ripeness of fruits are estimated manually, which is labor-intensive and time-consuming. In this case, automated yield prediction based on robotic agriculture is a realistic option. We provide in this study an automated strawberry fruit recognition and counting system for accurate and reliable yield prediction. This paper proposes a unique neural network training approach for strawberry fruit counting and ripeness detection that combines semantic graphics for data annotation with a fully convolutional neural network (FCN). Semantic graphics, the suggested data annotation approach, is straightforward to apply, and the desired targets can be quickly tagged with little effort. Moreover, the proposed FCN is an enhanced encoder-decoder network designed specifically for efficient learning of semantic graphics. Quantitative analysis of proposed algorithm showed 4.47% increase in detection accuracy over prior techniques while running at higher frames per second."
Apple Detection Algorithm based on an Improved SSD,2021,"['RFB', 'Attention Model', 'SSD', 'Apple detection', 'Objection detection', 'CNN']",국문 초록 정보 없음,"Under natural conditions, Apple detection has the problems of occlusion and small object detection difficulties. This paper proposes an improved model based on SSD. The SSD backbone network VGG16 is replaced with the ResNet50 network model, and the receptive field structure RFB structure is introduced. The RFB model amplifies the feature information of small objects and improves the detection accuracy of small objects. Combined with the attention mechanism (SE) to filter out the information that needs to be retained, the semantic information of the detection objectis enhanced. An improved SSD algorithm is trained on the VOC2007 data set. Compared with SSD, the improved algorithm has increased the accuracy of occlusion and small object detection by 3.4% and 3.9%. The algorithm has improved the false detection rate and missed detection rate. The improved algorithm proposed in this paper has higher efficiency."
딥 러닝 기반 OFDM 신호 자동 변조 분류,2021,"['automatic modulation classification (AMC)', 'orthogonal frequency division multiplexing (OFDM)', 'convolutional neural network (CNN)']","최신 협력 및 비협력 통신 환경에서 가장 중요한 기술 중 하나는 블라인드 자동 변조 분류 (automatic modulation classification, AMC)로 최근 머신 러닝을 AMC에 접목한 연구들이 많이 진행되고 있다. 특히 AMC는 단일 반송파 전송 방식 보다 직교 주파수 분할 다중 방식(orthogonal frequency division multiplexing, OFDM) 에서 더 도전적인 과제이다. 본 논문에서는 딥 러닝 알고리즘 중 합성곱 신경망(convolutional neural network) 을 기반으로 OFDM  신호의 변조 방식을 식별하는 방법을 제안하고 컴퓨터 모의실험을 통해 분류 성능을 분석하여 유효성을 검증한다.","In contemporary cooperative and non-cooperative communication contexts, blind automatic modulation classification (AMC) has become one of the most important techniques. Recently, many studies on AMC using machine learning have been conducted in many places in the literature. In particular, AMC in orthogonal frequency division multiplexing (OFDM) system becomes a more challenging task than that in a single carrier system. In this paper, we propose an improved AMC based on convolutional neural network to classify modulation type of OFDM signal and validate the proposed AMC through computer simulations."
Wavelet 기반의 영상 디테일 향상 잡음 제거 네트워크,2021,[],"최근 딥 러닝 기법의 하나인 합성곱 신경망(Convolutional Neural Network, CNN)은 영상 잡음(Noise) 제거 분야에서 전통적인 기법보다 좋은 성능을 나타내고 있지만 학습하는 과정에서 영상 내 디테일한 부분이 손실될 수 있다. 본 논문에서는 웨이블릿 변환(Wavelet Transform)을 기반으로 영상 내 디테일 정보도 같이 학습하여 영상 디테일을 향상하는 잡음 제거 합성곱 신경망 네트워크를 제안한다. 제안하는 네트워크는 디테일 향상 서브 네트워크(Detail Enhancement Subnetwork)와 영상 잡음 추출 서브 네트워크(Noise Extraction Subnetwork)를 이용하게 된다. 실험을 통해 제안하는 방법은 기존 알고리듬보다 디테일 손실 문제를 효과적으로 해결할 수 있었고 객관적 품질 평가인 PSNR(Peak Signal-to-Noise Ratio)와 주관적 품질 비교에서 모두 우수한 결과가 나온 것을 확인하였다.",다국어 초록 정보 없음
PCB 검사를 위한 YOLO 네트워크 기반의 PCB 부품 분류 알고리즘,2021,"['PCB Inspection', 'Defect Detection', 'AOI', 'Classification', 'Deep Learning', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
Is it possible to forecast KOSPI direction using deep learning methods?,2021,"['deep learning', 'machine learning', 'time-series data', '1D-CNN', 'LSTM']",국문 초록 정보 없음,"Deep learning methods have been developed, used in various fields, and they have shown outstanding performances in many cases. Many studies predicted a daily stock return, a classic example of time-series data, using deep learning methods. We also tried to apply deep learning methods to Korea's stock market data. We used Korea's stock market index (KOSPI) and several individual stocks to forecast daily returns and directions. We compared several deep learning models with other machine learning methods, including random forest and XGBoost. In regression, long short term memory (LSTM) and gated recurrent unit (GRU) models are better than other prediction models. For the classification applications, there is no clear winner. However, even the best deep learning models cannot predict significantly better than the simple base model. We believe that it is challenging to predict daily stock return data even if we use the latest deep learning methods."
딥러닝에 의한 항공사진 구름 분류 및 탐지 비교 실험,2021,"['Deep Learning', 'Classification', 'Detection', 'GoogLeNet', 'VGG16', 'Faster R-CNN', 'YOLOv3', '딥러닝', '분류', '탐지']",국문 초록 정보 없음,다국어 초록 정보 없음
GprMax Based Synthetic B-scans detection using Artificial Intelligence,2021,"['Ground Penetrating Radar (GPR)', 'Underground utilities', 'Convolutional Neural Network (CNN)', 'GprMax simulation', 'Synthetic B-scans']",국문 초록 정보 없음,다국어 초록 정보 없음
Accelerating a Deep Learning Application by Parallelization and Pipelining on Heterogeneous Processors,2021,"['딥 러닝', '이기종 프로세서', '파이프라이닝', '병렬화', 'deep learning', 'heterogeneous processors', 'pipelining', 'parallelization']","임베디드 시스템에서 딥 러닝 응용에 대한 필요가 증가함에 따라, 응용을 가속하는 데에 있어서 CPU가 아닌 처리 요소(processing element)를 임베디드 기기에 포함되고 있다. NVIDIA Jetson AGX Xavier는 대표적인 예제로 8-core CPU 뿐만 아니라 GPU와 2개의 딥러닝 가속기를 함께 갖고 있어서 자원이 제한된 환경에서 딥 러닝 응용의 성능을 끌어올리는 데에 활용된다. 임베디드 기기가 이기종처리 요소를 제공한다고 하여도, 이런 다양한 요소들을 함께 활용하여 성능을 올리는 것은 상당한 노력을 필요로 한다. 본 논문에서는 기존의 존재하는 여러 기법들과 우리가 제안하는 네트워크 파이프라이닝 기법을 함께 조합하여 이기종 처리요소를 가진 Xavier에서 딥 러닝 응용의 처리량을 최대화 하는 기법을 제안한다. 여러 개의 이미지 분류 예제와 사물 인식 예제를 통해 하나의 GPU를 사용하는 기존의 방법 대비 최대 355%까지 성능이 향상되는 것을 확인하였다.","Since the need of deep learning applications in embedded systems is increasing, non-CPU processing elements are equipped on an embedded device to accelerate those applications. NVIDIA Jetson AGX Xavier (Xavier) is a representative example which not only has an octa-core CPU, but also has one powerful GPU and two deep learning accelerators to enhance the performance of deep learning inference on resource-constrained environments. Although an embedded device provides heterogeneous processing elements, utilizing diverse computation units is burdensome to increase performance. In this paper, we proposed a technique that combines multiple existing methods and our proposed network pipelining method to maximize the throughput of deep learning applications. Our network pipelining method is made for utilizing heterogeneous processing elements on the Xavier. Results of experiments with image classification and object detection examples revealed up to 355% improvement compared to baseline Frames Per Second (FPS) with a single GPU."
SDCN: Synchronized Depthwise Separable Convolutional Neural Network for Single Image Super-Resolution,2021,"['Image supper-resolution', 'Deep convolutional neural network', 'Depthwise Separable convolution', 'Dense skip connection']",국문 초록 정보 없음,"Recently, image super-resolution techniques used in convolutional neural networks (CNN) have led to remarkable performance in the research area of digital image processing applications and computer vision tasks. Convolutional layers stacked on top of each other can design a more complex network architecture, but they also use more memory in terms of the number of parameters and introduce the vanishing gradient problem during training. Furthermore, earlier approaches of single image super-resolution used interpolation technique as a pre-processing stage to upscale the low-resolution image into HR image. The design of these approaches is simple, but not effective and insert the newer unwanted pixels (noises) in the reconstructed HR image. In this paper, authors are propose a novel single image super-resolution architecture based on synchronized depthwise separable convolution with Dense Skip Connection Block (DSCB). In addition, unlike existing SR methods that only rely on single path, but our proposed method used the synchronizes path for generating the SISR image. Extensive quantitative and qualitative experiments show that our method (SDCN) achieves promising improvements than other state-of-the-art methods."
딥러닝 기반 실시간 얼굴 모자이크 기법을 활용한 초상권 보호 시스템,2021,"['Machine learning', 'Deep learning', 'Face mosaic', 'Portrait rights', 'Yolov3', 'Facenet', 'R-CNN']",국문 초록 정보 없음,"Recently, the number of cases uploading videos taken by individuals on the Internet has increased. Uploading a video that includes not only yourself but also people around you can cause infringement of portrait rights and privacy issues. In general, The portrait rights of others are protected by manually blurring faces of people moving over time using a video editing program. However, this is a very cumbersome task and the existing automatic mosaic system also has limitations because it does not detect all identifiable faces properly in videos and it misses tracked faces frequently. Therefore, to prevent the problem of infringement of portrait rights, this paper proposes a portrait rights protection system using deep learning. The system uses YOLOv3, Face-Net, and SORT algorithm to protect the portrait rights by blurring faces of other people except the users registered in the system. Compared to the existing automatic mosaic system, It can detect all identifiable faces and blur faces more accurately. It can operate in real-time by skipping a certain frame and performing face verification. It is also possible to flexibly respond to various changes of the face reflected on the camera by applying the SORT object tracking algorithm. The proposed system can improve convenience for users by automating the task of manually blurring faces of people and it shows superior performance compared to the existing automatic mosaic system."
Artificial Intelligence-based Recognition of Chinese Characters and Translation of Classical Chinese: Focusing on the Current State of Korea,2021,"['Chinese Characters', 'Classical Chinese', 'AI(Artificial Intelligence)', 'OCR', 'CNN(Convolutional Neural Network)', 'Machine Translation', 'corpus']",국문 초록 정보 없음,다국어 초록 정보 없음
다중 데이터 합성 알고리즘 및 합성곱 신경망을 사용한 신원확인 기법 연구,2021,"['identification', 'face recognition', 'watermarking', 'data synthesis', 'artificial intelligence', 'CNN']",국문 초록 정보 없음,"This paper proposes an identification method using multiple biometric data synthesis algorithms and convolutional neural networks. In general, multi-biological data-based identity verification methods use multimodal deep learning. However, computation increases when two or more networks are used, making applying to the embedded system difficult. In this paper, a voice for authentication composed of facial images and several syllables was synthesized into one data, and identification was performed by applying it to one convolutional neural network. As for the actual environmental data for learning, a total of 800 multi-biological synthesized images were used by combining 8 facial images per person and 20 voices for authentication for 5 experimental personnel. As a result of the experiment, it was confirmed that the proposed identification method operates normally with an inference accuracy of about 93%."
도시림의 경관 회복 기능 평가를 위한 딥러닝 적용 가능성 모색: 문헌 및 방법론 리뷰를 중심으로,2021,"['합성곱 계층', '이미지 분류 및 분할', '지도학습', 'Convolutional Neural Network', 'CNN', 'Image classification and segmentation', 'Supervised learning']",국문 초록 정보 없음,"This study examines the feasibility of developing a model for evaluating urban landscapes based on deep learning as a preliminary study. The principal methodology of the study is literature analysis; to explore the possibility of applying the deep learning algorithm to landscape evaluation, we intensively reviewed researches regarding ‘urban forest landscape research’, ‘landscape evaluation scale’, and ‘feasibility of deep learning in landscape studies’. The results derived from this study are composed mainly of two contents. First, it is ‘Necessity to select images considering landscape composition and standardize evaluation indicators and scales’. The data to be evaluated for measuring the recovery effect of urban forests were found to be insufficient to be applied as a model. However, since the landscape elements and composition to be evaluated in existing studies were simply set, it will contribute to reducing the complexity of the model. When developing the model in the future, influence variables that have been proven several times in previous studies can be used as main input data. The evaluation results of existing studies that will be applied as input data to future evaluation models are composed of various scales and need to be adjusted to a level that can be compared to each other through standardization, moreover high resolution for the development and use of landscape evaluation algorithms in various fields. Second, ‘Proving of the possibility and feasibility of evaluating existing algorithms’. It is judged that the validity of the landscape evaluation model based on deep learning is high, and rather than a method of newly developing the evaluation algorithm itself, the basic data is constructed to improve the model's reliability by utilizing and partially correcting the already established landscape evaluating algorithm. This study is meaningful because it suggests directions and limitations for the future urban forest landscape evaluation model development."
동적 환경에서 SLAM 위치 추정의 성능 향상을 위한 객체 Movement 인식 방법,2021,"['SLAM(동시적 위치추정 및 지도 작성)', 'Deep learning(딥러닝)', 'Mask R-CNN(마스크 RCNN)', 'Optical flow(광류)', 'Object tracking(객체 추적)', 'Dynamic objects(동적객체)']",국문 초록 정보 없음,다국어 초록 정보 없음
Development of a Method for Detecting Abnormal Signals by Analyzing the Sound of an Emergency Diesel Generator Using the Artificial Intelligence (AI),2021,"['Artificial intelligence (AI)', 'Emergency diesel generator (EDG)', 'Convolutional neural network (CNN)', 'Spectrogram', 'AutoEncoder', 'Threshold']",국문 초록 정보 없음,다국어 초록 정보 없음
심층 신경망 기법을 이용한 유도탄 공력 하중 예측 모델 개발,2021,"['Deep Neural Network(심층 신경망)', 'MLP(다층 퍼셉트론)', 'CNN (합성곱 신경망)', 'Signed Distance Function(거리 부호 함수)', 'Missile Aerodynamic Loads(유도탄 공력 하중)']",국문 초록 정보 없음,다국어 초록 정보 없음
비디오 인코더를 통한 딥러닝 모델의 정수 가중치 압축,2021,"['Deep Learning Model Parameter Quantization', 'Weight compression', 'Lightweight model']",국문 초록 정보 없음,"Recently, various lightweight methods for using Convolutional Neural Network(CNN) models in mobile devices have emerged. Weight quantization, which lowers bit precision of weights, is a lightweight method that enables a model to be used through integer calculation in a mobile environment where GPU acceleration is unable. Weight quantization has already been used in various models as a lightweight method to reduce computational complexity and model size with a small loss of accuracy. Considering the size of memory and computing speed as well as the storage size of the device and the limited network environment, this paper proposes a method of compressing integer weights after quantization using a video codec as a method. To verify the performance of the proposed method, experiments were conducted on VGG16, Resnet50, and Resnet18 models trained with ImageNet and Places365 datasets. As a result, loss of accuracy less than 2% and high compression efficiency were achieved in various models. In addition, as a result of comparison with similar compression methods, it was verified that the compression efficiency was more than doubled."
이종 구조 기반 모바일 시스템에서의 신경망 계층 분배를 통한 추론 성능 최적화 연구,2021,[],"시각적인 정보를 학습하여 객체 탐지와 같은 응용 기술에 주로 사용되는 합성곱 신경망(CNN)의 추론(Inference) 등 복잡한 연산을, 스마트폰처럼 성능과 자원이 한정된 모바일 디바이스에서 효율적으로 실행하려고 하는 연구가 많이 이루어지고 있다. 신경망을 구성하는 각각의 컨볼루션 레이어는 신경망 모델에 따라 다양한 복잡도 및 특성을 가지고 있다. 최근의 모바일 디바이스는 고성능을 요구하는 어플리케이션의 증가로 인해 CPU 외에 GPU를 비롯한 다양한 가속기가 추가적으로 탑재되고 있으므로, CPU와 GPU의 하드웨어적 특성을 고려하여 타겟 신경망의 각 레이어를 좀 더 효율적인 하드웨어에서 연산하도록 분배하면 추가적으로 사용되는 메모리 없이 추론 연산 시간을 단축시킬 수 있다. 본 논문에서는 이러한 이종(Heterogeneous) 컴퓨팅 시스템에서 CPU와 GPU의 성능을 바탕으로 레이어를 세분화해 실행함으로써 더 효율적으로 추론이 가능함을 보인다.",다국어 초록 정보 없음
기계학습을 이용한 PIV 속도장 분석해상도 향상 방법,2021,"['PIV(입자영상유속계)', 'Cross-correlation(상호상관법)', 'Optical flow(광학흐름)', 'CNN (컨볼루션신경망)', 'FlowNet(플로우넷)', 'Coarse-to-fine', 'Synthetic particle image(합성입자이미지)']",국문 초록 정보 없음,다국어 초록 정보 없음
아동의 ADHD 진단 보조를 위한 기계 학습 기반의 뇌전도 분류,2021,"['Attention Deficit Hyperactivity Disorder (ADHD)', 'EEG', 'Gamma band', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
머신러닝 기법을 활용한 일사량 예보 모델 개발,2021,"['재생에너지(Renewable energy)', '시계열(Time series)', '합성곱 신경망(Convolutional neural network', 'CNN)', '순환 신경망(Recurrent Neural Network', 'RNN)']",국문 초록 정보 없음,다국어 초록 정보 없음
다중 차선 도로 차선 변경을 위한 컨볼루션 신경망 기반 충돌 감지 시스템,2021,"['Collision Detection(충돌 감지)', 'Deep Learning(딥 러닝)', 'Convolution Neural Network(CNN)', 'Autonomous Driving(자율주행)', 'LiDAR(라이다)', 'Radar(레이더)']",국문 초록 정보 없음,"This paper proposes a collision detection system to simultaneously predict crash situations by ego and target vehicles change lanes. There is little literature on the case research, but it is essential to predict this kind of collision for the active safety system. This paper presents a Convolution Neural Network-based collision detection system consisting of four classes to predict collision risk on the multi-lanes road. The network is formed on stacked Occupancy Grid Maps(OGMs) input data composed of point cloud data of the LiDAR and Radar sensors with in-vehicle sensor data Spatio-temporal information. The experimental results show that the collision detection system based on the proposed OGMs input data outperforms the results of other forms of OGMs, e.g., single-shot OGM and/or non-in-vehicle OGM, with an overall accuracy of 86.1% and a fall-out of about 6.1% about the collision situation from a confusion matrix."
지진 이벤트 분류를 위한 정규화 기법 분석,2021,[],국문 초록 정보 없음,"This paper presents an effective structure by applying various normalization to Convolutional Neural Networks (CNN) for seismic event classification. Normalization techniques can not only improve the learning speed of neural networks, but also show robustness to noise. In this paper, we analyze the effect of input data normalization and hidden layer normalization on the deep learning model for seismic event classification. In addition an effective model is derived through various experiments according to the structure of the applied hidden layer. As a result of various experiments, the model that applied input data normalization and weight normalization to the first hidden layer showed the most stable performance improvement."
Transposed Convolutional Layer 기반 Stacked Hourglass Network를 이용한 얼굴 특징점 검출에 관한 연구,2021,"['Facial Landmark Detection', 'Face Alignment', 'Stacked Hourglass Network', 'Transposed Convolutional Layer', 'Computer Vision', 'CNN', 'Heatmap Based Detection', 'Bodypart detection']",국문 초록 정보 없음,다국어 초록 정보 없음
유사 이미지 분류를 위한 딥 러닝 성능 향상 기법 연구,2021,"['분류', '딥 러닝', '유사 이미지', '컨볼루셔널 뉴럴 네트워크', '혼동률', 'Classification', 'Deep Learning', 'Similar Image', 'CNN', 'Confusion Rate']","딥 러닝을 활용한 컴퓨터 비전 연구는 여전히 대규모의 학습 데이터와 컴퓨팅 파워가 필수적이며, 최적의 네트워크 구조를 도출하기 위해 많은 시행착오가 수반된다. 본 연구에서는 네트워크 최적화나 데이터를 보강하는 것과 무관하게 데이터 자체의 특성만을 고려한 CR(Confusion Rate)기반의 유사 이미지 분류 성능 향상 기법을 제안한다. 제안 방법은 유사한 이미지 데이터를 정확히 분류하기 위해 CR을 산출하고 이를 손실 함수의 가중치에 반영함으로서 딥 러닝 모델의 성능을 향상시키는 기법을 제안한다. 제안 방법은 네트워크 최적화 결과와 독립적으로 이미지 분류 성능의 향상을 가져올 수 있으며, 클래스 간의 유사성을 고려해 유사도가 높은 이미지 식별에 적합하다. 제안 방법의 평가결과 HanDB에서는 0.22%, Animal-10N에서는 3.38%의 성능향상을 보였다. 제안한 방법은 다양한 Noisy Labeled 데이터를 활용한 인공지능 연구에 기반이 될 것을 기대한다.","Deep learning in computer vision has made accelerated improvement over a short period but large-scale learning data and computing power are still essential that required time-consuming trial and error tasks are involved to derive an optimal network model. In this study, we propose a similar image classification performance improvement method based on CR (Confusion Rate) that considers only the characteristics of the data itself regardless of network optimization or data reinforcement. The proposed method is a technique that improves the performance of the deep learning model by calculating the CRs for images in a dataset with similar characteristics and reflecting it in the weight of the Loss Function. Also, the CR-based recognition method is advantageous for image identification with high similarity because it enables image recognition in consideration of similarity between classes. As a result of applying the proposed method to the Resnet18 model, it showed a performance improvement of 0.22% in HanDB and 3.38% in Animal-10N. The proposed method is expected to be the basis for artificial intelligence research using noisy labeled data accompanying large-scale learning data."
WiSECam: A CSI-Based Deep Learning Motion Detection for Wireless Cameras,2021,"['Channel State Information (CSI)', 'Wi-Fi monitoring mode', 'deep learning', 'Convolutional Neural Network (CNN)', 'Long Short-Term Memory (LSTM)']",국문 초록 정보 없음,다국어 초록 정보 없음
자율주행 트랙터 경로 추종을 위한 영상 기반 경계검출기술 개발,2021,"['자율주행', '농업기계', '경계 검출', '합성곱 신경망', '조향제어', 'autonomous traveling', 'agricultural machinery', 'boundary detection', 'CNN', 'steering control']",국문 초록 정보 없음,다국어 초록 정보 없음
선삭공정에서 딥러닝 영상처리 기법을 이용한 작업자 위험 감소 방안 연구,2021,"['Deep Learning(딥러닝)', 'Vision System(영상처리 시스템)', 'Negligent Accident(안전사고)', 'Convolutional Neural Network(CNN)(컨볼루션신경망)', 'You Only Look Once(YOLO)(욜로)']",국문 초록 정보 없음,"The deep learning image processing technique was used to prevent accidents in lathe work caused by worker negligence. During lathe operation, when the chuck is rotated, it is very dangerous if the operator""s hand is near the chuck. However, if the chuck is stopped during operation, it is not dangerous for the operator’s hand to be in close proximity to the chuck for workpiece measurement, chip removal or tool change. We used YOLO (You Only Look Once), a deep learning image processing program for object detection and classification. Lathe work images such as hand, chuck rotation and chuck stop are used for learning, object detection and classification. As a result of the experiment, object detection and class classification were performed with a success probability of over 80% at a confidence score 0.5. Thus, we conclude that the artificial intelligence deep learning image processing technique can be effective in preventing incidents resulting from worker negligence in future manufacturing systems."
딥 뉴럴 네트워크에 의한 디지털 홀로그램의 워터마킹 및 홀로그램 데이터 특성을 고려한 학습,2021,"['Digital hologram', 'digital watermark', 'deep neural network (DNN)', 'training data set', 'convolution neural network (CNN)']","디지털 홀로그램(digital hologram, DH)은 2차원 데이터에 3차원의 정보를 포함하는 초고부가가치의 영상 콘텐츠이다. 따라서 이 콘텐츠의 유통을 위해서는 그 지적재산권이 반드시 보호되어야 한다. 본 논문에서는 이를 위해서 최초로 딥 뉴럴 네트워크를 이용한 DH의 워터마킹 방법을 제안한다. 이 방법은 워터마크(watermark, WM)가 의 비가시성, 공격에 대한 강인성, WM 추출 시 호스트 정보를 사용하지 않는 blind 워터마킹 방법이다. 제안하는 네트워크는 호스트와 워터마크 각각의 전처리, WM 삽입, WM 추출의 네 부-네트워크로 구성된다. 이 네트워크는 고주파 성분이 강한 DH의 특성을 감안하여 호스트 데이터를 축소하지 않고 WM 데이터를 확장하여 호스트 데이터와 정합함으로써 WM를 삽입한다. 또한 이 네트워크의 학습에 있어서 DH의 데이터 분포특성에 따른 성능의 차이를 확인하고, 모든 종류의 DH에서 최고의 성능을 갖는 학습 데이터 세트를 선정하는 방법을 제시한다. 제안한 방법을 다양한 종류와 강도의 공격에 대해 실험을 수행하여 그 성능을 보인다. 또한 이 방법이 호스트 DH의 해상도와 WM 데이터에 독립적으로 동작하여 높은 실용성을 갖는다는 것을 보인다.",다국어 초록 정보 없음
건설현장에서 발생하는 폐기물 인식 모델 개발,2021,"['건설폐기물', '인공지능', '이미지 분류', '건설현장', '합성곱신경망', 'construction and demolition waste', 'artificial intelligence', 'image classification', 'construction site', 'CNN']",국문 초록 정보 없음,"It is considered that the construction industry is one of the pivotal players in the national economy in terms of Gross Domestic Production (GDP) and employment. Behind the positive role of this industrial sector to the national economy, the construction industry generates approximately 50 % of the total waste generation from all the industrial sectors. There are several measures to mitigate the adverse impacts of the construction waste such as reduce, reuse and recycle. Recycling would be one of the effective strategies for waste minimisation, which would be able to reduce the demand upon new resources as well as enhance reusing the construction materials on sites. The automated construction waste classification system would make it possible not only to reduce the amount of labour input but also mitigate the possibility of errors during the manual classification process. In this study, we proposed an automated waste segmentation and classification system for recycling the construction and demolition waste in the real construction site context. Since the practical application to the real-world construction sites was one of the significant factors to develop the system, a YOLACT (You Only Look At CoefficienTs) algorithm was chosen to conduct the study. In this study, it is expected that the proposed system would make it possible to enhance the productivity as well as the cost efficiency by reducing the manpower for the construction and demolition waste management at the construction site."
임베디드 시스템에서 효율적인 차량 번호판 인식 시스템,2021,"['차량 번호판 인식', '딥러닝', '임베디드 시스템', '객체 검출', '합성곱 신경망', 'License Plate Recognition', 'Deep learning', 'Object detection', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
객체 검출을 위한 트랜스포머와 공간 피라미드 풀링 기반의 YOLO 네트워크,2021,[],"일반적으로 딥러닝 기반의 객체 검출(Object Detection)기법은 합성곱 신경망(Convolutional Neural Network, CNN)을 통해 입력된 영상의 특징(Feature)을 추출하여 이를 통해 객체 검출을 수행한다. 최근 자연어 처리 분야에서 획기적인 성능을 보인 트랜스포머(Transformer)가 영상 분류, 객체 검출과 같은 컴퓨터 비전 작업을 수행하는데 있어 경쟁력이 있음이 드러나고 있다. 본 논문에서는 YOLOv4-CSP의 CSP 블록을 개선한 one-stage 방식의 객체 검출 네트워크를 제안한다. 개선된 CSP 블록은 트랜스포머(Transformer)의 멀티 헤드 어텐션(Multi-Head Attention)과 CSP 형태의 공간 피라미드 풀링(Spatial Pyramid Pooling, SPP) 연산을 기반으로 네트워크의 Backbone과 Neck에서의 feature 학습을 돕는다. 본 실험은 MSCOCO test-dev2017 데이터 셋으로 평가하였으며 제안하는 네트워크는 YOLOv4-CSP의 경량화 모델인 YOLOv4s-mish에 대하여 평균 정밀도(Average Precision, AP)기준 2.7% 향상된 검출 정확도를 보인다.",다국어 초록 정보 없음
심층학습을 이용한 영상정보 기반 호흡신호 분류,2021,"['Respiration', 'Respiratory states', 'UWB radar', 'Visual information', 'Deep neural network']","본 논문에서는 영상정보에 기반한 호흡상태 분류 방법을 제안한다. 호흡신호는 초광대역 레이더 센서를 이용하여 획득하고 호흡신호의 값으로 이루어진 1차원 그래프 대신 그래프의 영상 정보가 담긴 2차원 정보 기반으로 호흡상태를 분류한다. 호흡상태의 분류는 심층신경망 모델을 사용하고, 심층신경망 모델은 호흡신호 그래프가 포함된 2차원 영상의 특징들을 학습하여 영상기반의 호흡상태 분류의 결과를 제공한다. 기존의 레이더 센서 기반 호흡신호의 상태 분류는 1차원 벡터의 구성요소 값 및 그 값들의 변화량을 이용하여 회귀, 심층학습 방법을 적용하였다. 그러나 1차원 그래프 기반의 호흡상태 분류는 다양한 형태의 정상호흡 상태에 대한 분류 성능에서 한계를 보였다. 본 논문에서는 호흡 신호로부터 얻은 그래프의 이미지 자체를 2차원 입력 신호로 사용하여 심층 신경망 모델을 적용하여 분류를 수행하였다. 본 논문에서 제안하는 영상정보 기반의 호흡상태 분류는 기존의 1차원 벡터 기반 호흡상태 분류 대비 호흡상태 분류의 정확도를 약 10% 향상 시켰다. 또한 기존의 두 가지 호흡상태 (정상 및 비정상) 분류에서 확장하여 세 가지 호흡상태 (정상1, 정상2, 비정상) 분류를 수행하였다.","This paper proposes an approach to the classification of respiratory states of humans based on visual information. An ultra-wide-band radar sensor acquired respiration signals, and the respiratory states were classified based on two-dimensional (2D) images instead of one-dimensional (1D) vectors. The 1D vector-based classification of respiratory states has limitations in cases of various types of normal respiration. The deep neural network model was employed for the classification, and the model learned the 2D images of respiration signals. Conventional classification methods use the value of the quantified respiration values or a variation of them based on regression or deep learning techniques. This paper used 2D images of the respiration signals, and the accuracy of the classification showed a 10% improvement compared to the method based on a 1D vector representation of the respiration signals. In the classification experiment, the respiration states were categorized into three classes, normal-1, normal-2, and abnormal respiration."
Implementation of AIoT Edge Cluster System via Distributed Deep Learning Pipeline,2021,"['Distributed Data pipeline', 'Deep Learning', 'IoT', 'Edge Computing', 'Kubernetes', 'Docker']",국문 초록 정보 없음,"Recently, IoT systems are cloud-based, so that continuous and large amounts of data collected from sensor nodes are processed in the data server through the cloud. However, in the centralized configuration of large-scale cloud computing, computational processing must be performed at a physical location where data collection and processing take place, and the need for edge computers to reduce the network load of the cloud system is gradually expanding. In this paper, a cluster system consisting of 6 inexpensive Raspberry Pi boards was constructed to perform fast data processing. And we propose ""Kubernetes cluster system(KCS)"" for processing large data collection and analysis by model distribution and data pipeline method. To compare the performance of this study, an ensemble model of deep learning was built, and the accuracy, processing performance, and processing time through the proposed KCS system and model distribution were compared and analyzed. As a result, the ensemble model was excellent in accuracy, but the KCS implemented as a data pipeline proved to be superior in processing speed.."
Former Unmanned Surface Vehicle Detection Based on Improved Convolutional Neural Network,2021,"['Object detection', 'Accuracy', 'Tracking system', 'Monocular camera']",국문 초록 정보 없음,"This paper proposes an approach to the real-time implementation of a convolutional neural network (CNN)-based object detector for a former Unmanned Surface Vehicle (USV). The original network VGG-16 of the Single Shot MultiBox Detector (SSD) is first replaced with ResNet-18, as the basic feature extraction network. The classifying network is then redesigned by reducing half of the convolutional kernel numbers, where kernel sizes of 1×1 and 3×3 are mainly used. Simultaneously, a monocular camera installed on the tracking system, is used to calculate the distance and azimuth of the former USV. The experimental results show that the proposed method has advantages of higher accuracy and lower computational complexity, compared with other existing approaches. Therefore, the proposed approach can be efficiently used on real-time tracking systems."
객체 검출과 한글 손글씨 인식 알고리즘을 이용한 차량 번호판 문자 추출 알고리즘,2021,"['Vehicle License Plate Recognition(VLPR)', 'Optical Character Recognition(OCR)', 'Object Detection', 'Faster R-CNN', 'Handwritten Hangul Recognition(HHR)']",국문 초록 정보 없음,"Recently, with the development of IT technology, unmanned systems are being introduced in many industrial fields, and one of the most important factors for introducing unmanned systems in the automobile field is vehicle licence plate recognition(VLPR). The existing VLPR algorithms are configured to use image processing for a specific type of license plate to divide individual areas of a character within the plate to recognize each character. However, as the number of Korean vehicle license plates increases, the law is amended, there are old-fashioned license plates, new license plates, and different types of plates are used for each type of vehicle. Therefore, it is necessary to update the VLPR system every time, which incurs costs. In this paper, we use an object detection algorithm to detect character regardless of the format of the vehicle license plate, and apply a handwritten Hangul recognition(HHR) algorithm to enhance the recognition accuracy of a single Hangul character, which is called a Hangul unit. Since Hangul unit is recognized by combining initial consonant, medial vowel and final consonant, so it is possible to use other Hangul units in addition to the 40 Hangul units used for the Korean vehicle license plate."
RGB 영상 기반 콩 병해충 분류 딥러닝 모델 개발,2021,"['딥러닝', '분류 모델', '병해충', '영상처리']","최근 한국의 농업은 인공지능 기술을 접목하여 농촌의 문제를 해결하는 연구가 활발히 진행되고 있다. 합성곱신경망(Convolutional Neural Network, CNN)을 기반으로 하는 딥러닝 기술은 특히 영상처리 기술과 결부되어 쉽게 취득 가능한 영상 데이터로부터 주어진 문제의 해결책을 얻을 수 있어 최근 주목받고 있는 기술이다. 병해충 진단은 병징을 관찰하여 병종을 파악할 수 있으므로 딥러닝을 통해 진단이 가능할 것으로 판단된다. 이에 본 연구에서는 RGB 센서로부터 콩 병해충 이미지 데이터를 얻은 뒤 이를 토대로 딥러닝 기반의 영상 분류 모델을 학습시켜 콩 병해충의 진단을 수행하였다. 평가 지표로는 분류 정확도를 사용하였으며 5개의 분류 모델을 학습시켜 최대 분류 정확도를 비교하였다. 이를 위해 배치 사이즈, 학습률 등의 하이퍼파라미터를 조건을 달리해 가며 최적의 학습 조건을 탐색하였다.",다국어 초록 정보 없음
문맥적응적 신경망 기반 화면내 예측의 트리 구조 반영 학습기법 분석,2021,[],"최근, 딥러닝 및 인공신경망 기술의 발전으로 비디오 부호화 분야에서도 인공지능을 이용한 요소 기술에 대한 연구가 활발이 진행되고 있다. 본 논문에서는 주변 참조샘플로부터 문맥정보를 이용하여 현재블록을 예측하는 CNN 기반의 화면내 예측 모델을 구현하고, 비디오 부호화의 블록 분할 구조를 반영한 학습 기법에 따른 부호화 성능을 분석한다. 실험결과 HM(HEVC Test Model)에 구현한 문맥적응적 신경망 기반 예측 모델에서 트리 분할 구조를 반영한 학습이 HM16.19 대비 0.35% BD-rate 부호화 성능 향상을 보였다.",다국어 초록 정보 없음
Collision Avoidance Based on Occupied Grids for Unmanned Aerial Vehicle,2021,"['Occupied grids', 'collision avoidance', 'UAV']",국문 초록 정보 없음,"This work presents a technique of collision avoidance for Unmanned Aerial Vehicle (UAV) using occupied grids algorithm. The proposed algorithm is utilizing bounding box based convolutional neural network (CNN). Image frame from UAV camera is divided into grids. Occupied grids by bounding box defines the distance and position of static also dynamic object around UAV in real-time. A flight trajectory, velocity and direction of UAV are presented as performance matrix. Experimental results show that proposed algorithm successfully directs UAV to avoid collision with object by decreasing its velocity and changing direction."
딥 러닝 기반 설명 가능한 인공지능과 무인기의 다중 이미지 센서를 활용한 무 시들음병 탐지 프레임워크,2021,"['무 시들음병', '딥 러닝', '설명가능한 인공지능', '무인비행체', 'RGB', '근적외선', 'Fusarium wilt', 'Deep learning', 'XAI', 'UAV', 'RGB', 'NIR']","전 세계적으로 사랑받고 있는 채소인 무는 뿌리채소 중 하나로 다양한 요리에 주재료로 사용되고 있어 많은 양이 생 산되고 소비된다. 무는 또한 한국의 음식 문화에서도 중요한 역할을 하는데, 대표적인 한국의 음식 중 하나인 김치 에도 무가 사용된다. 하지만 최근 급격한 기후 변화로 인해 무가 시들음병에 쉽게 노출될 수 있는 환경이 만들어져 무의 품질과 수확량이 크게 저하되는 문제가 생기고 있다. 무 시들음병 문제를 해결하기 위한 기존의 식물 대상의 질병 식별 방식은 수집한 컬러 이미지에서 수동으로 특징을 추출했기 때문에 많은 시간과 비용을 소모했다. 하지만 최근 근적외선 센서의 개발로 인해 식물의 질병 식별을 시간적, 금전적으로 보다 효율적으로 판별할 수 있도록 발전 하였다. 본 논문에서는 다중 이미지 센서를 기반으로 무인 비행체인 드론을 사용하여 무 시들음병을 식별할 수 있는 컬러 및 근적외선 이미지에 대한 딥 러닝 프레임워크를 제안하고 비교한다. 또한 사용자가 딥 러닝 모델의 결과를 시각적으로 이해할 수 있도록 설명가능한 인공지능(XAI) 접근 방식을 사용한다. 다양한 실험에서 얻은 결과로 제안 하는 프레임워크는 정확도, 계산 복잡성 측면에서 기존 탐지 시스템에 비해 더 나은 성능을 보인다는 것을 보여주었 고, 근적외선 데이터셋은 식생 지수 계산을 통해 무 시들음병을 식별하는데 효과가 있음을 보여주었다.","Radish, loved worldwide, is one of the root vegetables and is used as a main ingredient in various dishes, so it has a lot of production and consumption. Radish is also used in kimchi, one of the most popular Korean foods. Due to rapid climate change in recent years, it can be easily exposed to the radish fusarium wilt disease, which greatly reduces the quality and yield of radishes. Traditional plant disease identification methods used to solve the Fusarium Wilt problem are time-consuming and costly because they rely on manually extracting features from collected RGB images. Recent developments in near-infrared sensors have made it possible to determine plant health more efficiently, both in time and money. In this paper, we propose and compare Deep Learning Framework for RGB and NIR(Near-infrared) images that can identify radish fusarium wilt disease using Drone, Unmanned Aerial Vehicle based on multiple image sensors. It also uses an XAI(eXplainable Artificial Intelligence) approach that allows users to visually understand the results of the Deep Learning model. As a result of the various experiments, the proposed Framework showed better performance compared to existing detection systems in terms of accuracy and computational complexity, while NIR Dataset showed that it was effective in identifying the radish fusarium wilt disease through the Vegetation index calculation."
이질적 이미지의 딥러닝 분석을 위한 적대적 학습기반 이미지 보정 방법론,2021,"['Adversarial Learning', 'Color Constancy', 'Heterogeneous Images', 'Illumination Estimation', 'Image Correction', '적대적 학습', '색 항상성', '이질적 이미지', '조명 추정', '이미지 보정']",국문 초록 정보 없음,"The advent of the big data era has enabled the rapid development of deep learning that learns rules by itself from data. In particular, the performance of CNN algorithms has reached the level of self-adjusting the source data itself. However, the existing image processing method only deals with the image data itself, and does not sufficiently consider the heterogeneous environment in which the image is generated. Images generated in a heterogeneous environment may have the same information, but their features may be expressed differently depending on the photographing environment. This means that not only the different environmental information of each image but also the same information are represented by different features, which may degrade the performance of the image analysis model. Therefore, in this paper, we propose a method to improve the performance of the image color constancy model based on Adversarial Learning that uses image data generated in a heterogeneous environment simultaneously. Specifically, the proposed methodology operates with the interaction of the ‘Domain Discriminator’ that predicts the environment in which the image was taken and the ‘Illumination Estimator’ that predicts the lighting value. As a result of conducting an experiment on 7,022 images taken in heterogeneous environments to evaluate the performance of the proposed methodology, the proposed methodology showed superior performance in terms of Angular Error compared to the existing methods."
콘포머 기반 한국어 음성인식,2021,[],국문 초록 정보 없음,"We propose a speech recognition system based on conformer. Conformer is known to be convolution-augmented transformer, which combines transfer model for capturing global information with Convolution Neural Network (CNN) for exploiting local feature effectively. The baseline system is developed to be a transfer-based speech recognition using Long Short-Term Memory (LSTM)-based language model. The proposed system is a system which uses conformer instead of transformer with transformer-based language model. When Electronics and Telecommunications Research Institute (ETRI) speech corpus in AI-Hub is used for our evaluation, the proposed system yields 5.7 % of Character Error Rate (CER) while the baseline system results in 11.8 % of CER. Even though speech corpus is extended into other domain of AI-hub such as NHNdiguest speech corpus, the proposed system makes a robust performance for two domains. Throughout those experiments, we can prove a validation of the proposed system."
Pig Identification Using Deep Convolutional Neural Network Based on Different Age Range,2021,"['Convolutional neural network', 'Deep learning', 'Image classification', 'Individual identification']",국문 초록 정보 없음,"Purpose In this study, the main objectives are to show the performance of deep convolutional neural network in identifying individual pig and investigate the accuracy level of CNN using four datasets made with pig’s face in different growing period.Methods Firstly, the datasets were captured in an experimental pig barn at a different time. Secondly, the datasets were filtered similar images using the structural similarity index measure (SSIM) for data preparation. Finally, face image classification is performed by employing a deep convolutional neural network (DCNN) namely ZFNet model.Results The results have shown that individual pig identification is outperformed while using the same age dataset in training and testing stage with an accuracy rate above 97%.Conclusions The model performed better in a combined dataset which is a combination of all individual data. For future recommendation, it would be beneficial to perform the effectiveness on a large scale of pigs, and a network model should be considered unsupervised learning in case of ageing classification."
재구성 가능한 다중목표 격자환경을 위한 이미지 유사 상태정보를 활용한 심층 강화학습,2021,"['Deep reinforcement learning', 'Image-like state', 'Grid environment', 'Multiple targets']",국문 초록 정보 없음,"This paper proposes deep reinforcement learning using image-like state information for a grid environment has multiple targets which can be reconfigured for each episode. The proposed CNN based network approximates a state-action value function, and it is confirmed that the learned results shows a negligible level of errors compared with the true solution given by dynamic programming."
연료전지 순차 실험 데이터를 이용하여 플러딩과 드라잉 예측,2021,"['Fuel Cell(연료전지)', 'Flooding and Drying-out(연료전지 플러딩', '드라잉 현상)', 'Long Short-Term Memory(LSTM', '장단기메모리)', 'Convolutional Neural Network(CNN', '합성곱신경망)', 'Sequential Data(순차데이터)']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝과 감성 분석에 따른 보이스피싱 여부 판별,2021,[],"본 논문에서는 점차 진화되어가는 보이스피싱 수법에 대하여 딥러닝 기반 네트워크인 DNN(Deep Neural Network)를 통한 보이스피싱 여부 판별할 뿐만 아니라, CNN, Bi-LSTM을 활용한 다양한 관점에서의 감성 분석을 통하여 보이스피싱 조직원의 감성 상태를 파악하여 판별된 결과에 신뢰도를 높여주는 모델을 제안하였다.",다국어 초록 정보 없음
다중 손실 함수를 활용한 문장 유사도 성능 향상 기법,2021,"['Natural Language Processing (NLP)', 'BERT', 'Sentence Embedding', 'Semantic  Textual Similarity Task']","본 논문에서는 추가적인 데이터의 수집 없이 STS(Semantic Textual Similarity) task에서 multiple loss와 label smoothing 기법을 활용하여 성능을 향상시키는 방법을 제안한다. 기존의 모델들은 3-way softmax loss또는 cosine-similarity with MSE loss를 활용하여 STS task에 대한 손실 함숫값으로 계산하기 때문에, 사전 훈련된 언어 모델의 Word Contextual Embedding Vector가 좋지 않은 방향으로 변할 수 있는 문제점이 있다. 따라서 softmax loss에 label Smoothing 기법을 활용하여 유사한 문장끼리 클러스터링이 되도록 학습을 하였으며, 사전 언어 모델 중의 하나인 GPT(Generative Pre-training)에서 사전 훈련을 할 때 이용했던 loss 계산 방식에서 아이디어를 얻어 새로운 loss를 제안하는 모델에 결합하여 활용하였다. 이 2가지 접근 방식은 fine-tuning시에 활용하여 성능을 향상시킨다. 사전 훈련에는 Multi-genre Natural Language Inference, Stanford Natural Language Inference 데이터를 이용하였으며, 모델을 평가하기 위한 데이터로는 Semantic Textual Similarity benchmark를 이용하였다. 평균적으로 1.24% 정도의 성능 향상을 보였으며, Spearman’s rank에서는 최대 4.67%, Pearson correlation coefficient에서는 최대 5.64%의 성능 향상을 보였다.",다국어 초록 정보 없음
Split CSPDenseNet for Vision-Based UAV Classification in Heavily Deployed Surveillance Systems,2021,"['Classification', 'Data Augmentation', 'Intelligent Surveillance System', 'UAV']",국문 초록 정보 없음,"This paper proposes a system that detects UAVs by acquiring RGB images via sensor then apply them to a convolutional neural network (CNN) that behave as an object classifier. Proposing Split Cross Stage Partial DenseNet (SCSPDensenet) that is built from a modified CSPDenseNet. By splitting the feature map in two parts. Then, make each part flow in different side of the parallel network. The proposed network shows simulation results of an increment in the precision and showed higher AP<sub>5</sub>0 and AP<sub>7</sub>5 at higher frame rate on the UAV dataset With lower computational complexity."
합성곱 신경망 기반 유튜브 동영상 섬네일 스타일 분석,2021,"['동영상 섬네일', '이미지 스타일', '유튜브']","본 논문은 10 개 장르에 대하여 한국, 미국의 인기 유튜브 영상 4,863 개의 섬네일 이미지를 분석하여, 대표 섬네일 스타일을 도출하고 장르별 국가별 주 사용 스타일을 이해하였다. 사전훈련 된 CNN(Convolutional Neural Network) 모델을 사용하여 섬네일 이미지의 시각적 특성을 추출하였고, 계층적 클러스터링을 통해 원본 영상과 편집 효과 사용에 따른 5 개의 대표 스타일 유형을 도출해냈다. 또한, 한국과 미국 국가, 그리고 장르에 따라 주로 사용하는 섬네일 스타일이 무엇인지 통계적 분석을 수행하여 유의미한 관계가 있음을 밝혀냈다. 이러한 본 연구의 결과는 국가 별 장르 별로 영상의 섬네일을 디자인 할 때 어떤 요소들을 고려해야 할지를 보여준다.",다국어 초록 정보 없음
SORT와 DeepSORT의 혼합을 이용한 실시간 다중객체 추적,2021,"['multi-object tracking', 'real-time system', 'real-time tracking']",국문 초록 정보 없음,"Deep Simple Online and Real-time Tracking(DeepSORT) is a multi-object tracking technology that improves the accuracy of SORT, and has the characteristic of using a feature map of Convolution Neural Network(CNN) when determining the relationship between objects between consecutive frames in SORT. This feature has the advantage of dramatically improving the accuracy, but has a disadvantage in that the frame per second(FPS) is lowered due to the large amount of additional computing operations required. Therefore, for real-time systems such as autonomous vehicles, SORT has been considered more suitable than deep SORT. In this paper, we propose a method of mixing SORT technology with DeepSORT to remove the shortcomings of the existing DeepSORT. As a result of the experiment targeting MOT-16, a widely used data set used for multi-object tracking performance, it was confirmed that the proposed method dramatically increased the FPS with little loss in accuracy."
Convolutional Neural Network-based Foreign Object Debris (FOD) Detection System,2021,"['AlexNet', 'convolutional neural network', 'foreign object debris', 'object detection']",국문 초록 정보 없음,"Foreign Object Debris (FOD) are objects that are in a runway and taxiway in an airport that may cause damage in an aircraft. To address this gap, this paper proposes a detection system based on an improved AlexNet, a Convolutional Neural Network (CNN) that detects FOD that are present in runways or taxiways using an FOD image dataset consists of more than 3,000 images by Xu, et al. The proposed network is an improvised AlexNet that gave an accuracy of 92.59% in detecting FOD within a concrete background."
물체 움직임 및 시공간 특징지도를 이용한 비디오 물체 검출,2021,"['Deep learning (딥러닝)', 'Video object detection (비디오 물체 검출)', 'Object’s motion (물체 움직임)', 'Spatiotemporal feature map (시공간 특징지도)', 'Box offset calibration (박스 움직임 조정)']",국문 초록 정보 없음,"In this paper, we propose video object detection framework using object’s motion and spatio-temporal feature representation. This video object detection method, referred to as TM-VOD, aggregates visual feature maps extracted by convolutional neural network (CNN) backbone applying the gated attention scheme and spatial feature alignment. This spatiotemporal feature aggregation is performed in two stages. In the first stage, we fuse the visual feature maps via gated attention model in pixel-level. This enhanced aggregated feature map is exploited to produce more accurate region proposals than previous work. In the second stage, the aligned object features, extracted by temporal box offset calibration, are aggregated by weighting them according to the cosine similarity measure. We also represent the object’s motion in pixel-level and instance-level. In pixel-level, we extract the motion feature maps based on incremental changes between the adjacent visual feature maps to perform temporal box offset calibration. Next, we obtain instance-level motion feature map via GRU scheme and the feature map which represent the sequential changes of the box coordinates. Finally, we use all these features to produce detection results in current frame. The experiments conducted on the ImageNet VID dataset show that the proposed VOD-MT outperforms existing VOD methods."
군체 이미지를 이용한 기계학습 기반 휴대용 박테리아 종 분류 시스템,2021,[],"대기에 존재하는 바이오 에어로졸은 피부질환, 알레르기 질환, 기관지 천식, 아토피 등 질병을 일으키며, 과거 급성호흡기증후군(SARS), 신종인플루엔자의 대유행이 바이오 에어로졸의 공기 전파에 의한 감염으로 밝혀진 이후 공기 중 바이오 에어로졸 저감 및 모니터링의 중요성이 크게 부각되었다.본 연구에서는 바이오 에어로졸의 한 종류인 박테리아의 모니터링 방안으로, CNN (Convolutional Neural Network) 기반 기계학습 모델을 이용하여 Agar plate에 배양된 박테리아 군체의 이미지를 통해 종을 분류하는 휴대용 박테리아 종 분류 시스템을 제시한다. 본 연구에서는 총 7종(Escherichia coli, Bacillus subtills, Bacillus cereus, Staphylococcus aureus, Staphylococcus epidermidis, Brevibacterium casei, Microbacterium arborescens)의 박테리아들을 Agar plate에 24시간 배양 후, 휴대폰이 장착 가능한 자체제작 휴대용 종 분류 시스템을 이용해 박테리아 이미지 데이터를 얻어 기계학습의 학습 데이터로 사용한다. 내부를 암실로 만들고 특정 조명을 사용하여 모든 이미지 데이터들은 같은 조건에서 촬영된다. 시스템의 정확도 검증을 위해 챔버 실험을 진행한다. 대기 환경모사와 위해 대기 중 박테리아 농도와 같게 하여 챔버내에 박테리아 7종을 부유시켜 MAS-100<SUP>®</SUP>으로 박테리아를 Agar plate에 포집 및 배양시킨 후, 이를 휴대용 종 분류 시스템에 넣는다. 이후, 이전에 학습된 기계학습 모델을 실행시켜, 화면에 보이는 박테리아군체에 라벨링이 되게 한다. 챔버 테스트 후, 말디토프 질량분석기(MALDI-TOF MS)를 이용하여, 종 분류 정확성을 검증한 결과, 90% 이상의 예측 정확도를 확인할 수 있었다.",다국어 초록 정보 없음
객체 탐지를 통한 실내 공간의 위험도 산출 기법,2021,[],지진이나 화재와 같은 재난 발생 시 실내에 설치된 물건으로 인하여 피해가 더욱 커지는 경향이 있다. 이에 본 논문에서는 실내 시설물로 인한 피해를 최소화하기 위해 객체 탐지 모델 사용하여 실내에 존재하는 위험물들을 식별하고 해당 장소의 위험등급을 계산할 수 있는 기법을 제안한다. 빠르고 정확한 객체 탐지를 위하여 Mask R-CNN을 이용하여 실내에 위치한 위험물을 식별 모델을 설계하였으며 재난의 종류에 따라 위험도를 다르게 계산할 수 있도록 위험도 계산 공식을 정의하였다. 이를 통해 자연재난 발생 시 실내물건의 위험성으로 인한 피해를 줄일 수 있을 것으로 기대한다.,다국어 초록 정보 없음
비디오 모니터링 응용에서 움직인 돼지 탐지,2021,[],"비디오 모니터링은 자율주행차뿐만 아니라 농장 내 병든 동물 탐지 등과 같은 스마트팜 분야에서도 사람을 대신하여 24시간 연속 모니터링할 수 있는 중요한 응용 분야이다. 본 논문에서는 비디오 모니터링의 계산양을 줄이면서도 혼잡한 돈방에서 빠르게 움직이는 돼지들을 정확히 탐지하기 위해 CNN 기반 객체 탐지기의 정확도를 고려한 방법을 제안한다. 즉, 연속되는 비디오 영상에서 key frame을 먼저 추출한 후, 비디오의 특성인 움직임 정보가 포함된 영상에서 GMM을 이용하여 움직인 돼지와 움직이지 않은 돼지의 위치를 구분하고, 최종적으로 YOLOv4를 적용하여 움직인 돼지와 움직이지 않은 돼지를 탐지한다. 돈사에서 촬영된 비디오 데이터로 실험한 결과, 제안 방법은 효과적으로 움직인 돼지를 탐지할 수 있음을 확인하였다.",다국어 초록 정보 없음
채널 상태 정보를 이용한 이상 행동 분류에 대한 모델링 연구,2021,[],"Channel state information(CSI)은 매우 민감하기 때문에 주변 환경에 의해서 영향을 많이 받는다. 그렇기 때문에 CSI를 이용한 행동 인식을 실생활에 적용하기에는 어려움이 있을 것이다. 현재 노이즈를 제거하기 위한 다양한 필터링 기법들이 존재하지만, 이를 통해서 완벽하게 노이즈를 제거하기에는 한계가 있을 것으로 생각된다. 본 연구에서는 Autoencoder와 CNN 을 이용한 모델을 제안한다. 이를 통해서 노이즈가 많은 실생활에 CSI 를 이용한 행동 인식 기법을 활용할 수 있을 것으로 기대된다.",다국어 초록 정보 없음
음성감정 신호로부터 전이학습기반 딥러닝을 이용한 감정인식,2021,[],"최근 인공지능 기술의 발전으로 개인화 서비스가 증가함으로써 감정인식 기술이 중요하게 다뤄지고 있다. 감정인식 기술의 분야중 음성 감정인식은 사람의 목소리를 분석하여 감정 상태를 파악하는 기술이다. 본 논문에서는 한국어 음성데이터를 이용하여 특징 추출 방법에 따른 CNN 기반 전이 학습모델 중 하나인 ResNet18의 감정인식 성능을 비교한다. 데이터는 직접 구축한 한국어 음성 감정 데이터를 사용했고 감정 상태는 행복, 무감정, 화남, 슬픔 총 4가지로 분류된다. 특징추출 방법은 ERB 스펙트로그램과 로그 멜-스펙트로그램을 사용했고, 데이터를 4가지 경우로 나누어 성능을 비교한다. 이 중 모든 데이터를 사용했을 때, ERB 스펙트로그램을 사용한 경우 성능이 89.91%이고 로그 멜 스펙트로그램을 사용한 경우는 96.05%로 후자가 음성 감정인식에 더 적합하다는 것을 증명한다.",다국어 초록 정보 없음
음성인식과 화자검증을 통해 편리성과 보안성이 향상된 EMG 기반 능동의수 연구,2021,[],국문 초록 정보 없음,"In this study, speaker verification and speech recognition technology are combined with an electronic prosthesis that performs basic movements based on EMG, and a new operation method is used to increase convenience and security. The speaker""s speech was trained using speech recognition and CNN on 4 hand gestures obtained from 10 subjects, resulting in an average of 97% accuracy for real-time speech data."
근전도 신호를 이용한 CRNN 기반의 강인한 손 제스처 인식,2021,[],"사람의 생체 신호인 근전도(Electromyography, EMG) 신호를 이용한 손 제스처 인식에 대한 연구가 활발하게 이루어지고 있다. 손 제스처 분류를 위한 다양한 머신 러닝(Machine Learning) 방법이 연구되고 높은 분류율을 보이지만, 실시간으로 민감하지 않은 손 제스처 분류기를 만들기에는 어려움이 있다. CRNN(Convolutional Recurrent Neural Network) 모델은 CNN(Convolutional Neural Network)의 특징 추출 기능과 RNN(Recurrent Neural Network)의 시계열 데이터에 대한 분류 기능을 결합한 고성능 분류 모델이다. 본 논문에서는 근전도 신호를 이용한 CRNN 기반의 강인한 손 제스처 인식 모델을 제안한다. 제안하는 CRNN 분류기 모델은 정의한 5가지 손 제스처를 실시간으로 분류하는 데에 있어 높은 성능과 강인함을 보인다.",다국어 초록 정보 없음
"Rendang lokan: history, symbol of cultural identity, and food adaptation of Minangkabau tribe in West Sumatra, Indonesia",2021,"['Rendang lokan (oyster)', 'History of rendang', 'Cultural identity', 'The adaptation of food of Minangkabau tribe']",국문 초록 정보 없음,"Rendang is a kind of food that has become one of cultural heritages of Minangkabau tribe. It is not only a local food that has been crowned the best food in the world by CNN, but it also serves as the cultural identity. Most of people think that rendang is only made from beef of buffalo meat. In fact, rendang has many varieties that relate to the types of the area and the local natural resources where it is cooked. West Sumatra consists of mountainous and coastal areas. One of the popular rendang varieties in coastal areas is Rendang Lokan—it is not made from beef but oyster (lokan). Rendang Lokan is a kind of food for people who live in this area. They use resources of the sea for their foods. Rendang, for Minangkabau tribe, is not only considered as a traditional food but also as a symbol of cultural identity from a certain area. This article is aimed at discussing the history of using Oyster as the main ingredient for rendang as one of the rendang varieties coming from the coastal areas in West Sumatra. The results show that rendang lokan is a representation of the characteristics of Minangkabau people who have the ability to adapt themselves to the local environmental conditions in maintaining their cultural identity. Rendang lokan was initially created as the adjustment of the Minangkabau people who live in the coastal areas to the local natural resources and their economic conditions."
MobileNetV2 기반의 개선된 Lightweight 모델을 이용한 열화도로 영상에서의 블랙 아이스 인식,2021,[],국문 초록 정보 없음,"To accurately identify black ice and warn the drivers of information in advance so they can control speed and take preventive measures. In this paper, we propose a lightweight black ice detection network based on infrared road images. A black ice recognition network model based on CNN transfer learning has been developed. Additionally, to further improve the accuracy of black ice recognition, an enhanced lightweight network based on MobileNetV2 has been developed. To reduce the amount of calculation, linear bottlenecks and inverse residuals was used, and four bottleneck groups were used. At the same time, to improve the recognition rate of the model, each bottleneck group was connected to a 3×3 convolutional layer to enhance regional feature extraction and increase the number of feature maps. Finally, a black ice recognition experiment was performed on the constructed infrared road black ice dataset. The network model proposed in this paper had an accurate recognition rate of 99.07% for black ice."
Improvement of signal and noise performance using single image super-resolution based on deep learning in single photon-emission computed tomography imaging system,2021,"['Nuclear medicine imaging', 'Single photon emission computed tomography', 'Super-resolution', 'Deep learning', 'Deep convolutional neural network', 'Quantitative evaluation of image quality']",국문 초록 정보 없음,"Because single-photon emission computed tomography (SPECT) is one of the widely used nuclear medicine imaging systems, it is extremely important to acquire high-quality images for diagnosis. In this study, we designed a super-resolution (SR) technique using dense block-based deep convolutional neural network (CNN) and evaluated the algorithm on real SPECT phantom images. To acquire the phantom images, a real SPECT system using a<sup>99m</sup>Tc source and two physical phantoms was used. To confirm the image quality, the noise properties and visual quality metric evaluation parameters were calculated. The results demonstrate that our proposed method delivers a more valid SR improvement by using dense block-based deep CNNs as compared to conventional reconstruction techniques. In particular, when the proposed method was used, the quantitative performance was improved from 1.2 to 5.0 times compared to the result of using the conventional iterative reconstruction. Here, we confirmed the effects on the image quality of the resulting SR image, and our proposed technique was shown to be effective for nuclear medicine imaging."
감정의 긍정적인 변화를 위한 음성 및 표정을 통한 감정인식,2021,"['Gender recognition', 'Emotion recognition', 'Recipe recommendation', 'Music recommendation', 'Light color control']",국문 초록 정보 없음,"This paper presents a method that recognizes voice and facial expressions to improve personal emotion. The method recognizes gender and the four emotions from the voice and facial expression. For emotions are recognized: happiness, sadness, anger, and neutral. The method uses CNN and RNN model. The predicted values from the two emotion recognition models are integrated to determine the emotion corresponding to the highest mode value. Finally, the method recommends food recipes, controls light colors, and plays music that improves the user’s emotion."
RGB영상 기반 시설오이 검출을 위한 딥러닝 개체분할 모델의 적용,2021,"['오이', '스마트팜', '개체분할', '딥러닝']","최근 계측, 인공지능, IOT 등의 기술이 고도화하고 있는 가운데 로봇 기반 수확 및 모니터링을 위한 스마트 팜 작물 영상 기반 인식 기술의 필요성이 증대하고 있다. 특히 농촌의 노동력 부족 문제를 해결할 수 있을 것으로 기대되는 수확 로봇 개발을 위해서는 합성곱신경망(Convolutional Neural Network, CNN) 기반의 딥러닝 분류, 검출, 분할 모델 등을 이용한 작물 인식 기술이 필수적이다. 오이는 일반적인 작물과 달리 긴 형태의 과실을 가지기 있기 때문에 사각형 기반으로 작물을 인식하는 객체 검출 모델보다 픽셀(pixel) 기반으로 작물의 구체적 형태를 인식하는 개체분할(Instance Segmentation) 모델을 적용하는 것이 로봇의 수확 성능을 높일 수 있을 것으로 기대된다. 따라서 본 연구에서는 가장 성능이 뛰어난 개체분할 모델 중 하나로 평가 받는 Mask RCNN(Mask Regional Convolutional Neural Network) 모델을 이용해 RGB 영상 기반 스마트팜 내부 오이 과실에 대한 개체분할 기술 개발 연구를 진행하였으며, 여러 합성곱신경망을 적용해 각 모델들의 정확도와 속도 결과를 비교하였다.",다국어 초록 정보 없음
시계열 데이터 분석을 위한 컨볼루션 신경망 기반의 Empirical Mode Decomposition,2021,[],국문 초록 정보 없음,"EMD (Empirical Mode Decomposition) was proposed as a method for analyzing nonlinear and nonstationary data. In this study, an attempt was made to implement EMD with deep learning. The model used was a simple CNN (Convolutional Neural Network), and after prediction, it was shown that the prediction result and the true signal showed a similar tendency especially in the low-order IMF (Intrinsic Mode Function)."
자기 지도 학습훈련 기반의 Noise2Void 네트워크를 이용한 PET 영상의 잡음 제거 평가 : 팬텀 실험,2021,"['합성 곱 신경망', '자기 지도 학습훈련', '영상 잡음 제거', 'Noise2Void', '양전자방출단층촬영', 'Convolutional neural network', 'Self-supervised learning training', 'Image denoising', 'Noise2Void', 'PET']",국문 초록 정보 없음,"Positron emission tomography (PET) images is affected by acquisition time, short acquisition times results in low gamma counts leading to degradation of image quality by statistical noise. Noise2Void(N2V) is self supervised denoising model that is convolutional neural network (CNN) based deep learning. The purpose of this study is to evaluate denoising performance of N2V for PET image with a short acquisition time. The phantom was scanned as a list mode for 10 min using Biograph mCT40 of PET/CT (Siemens Healthcare, Erlangen, Germany). We compared PET images using NEMA image-quality phantom for standard acquisition time (10 min), short acquisition time (2min) and simulated PET image (S2 min). To evaluate performance of N2V, the peak signal to noise ratio (PSNR), normalized root mean square error (NRMSE), structural similarity index (SSIM) and radio-activity recovery coefficient (RC) were used. The PSNR, NRMSE and SSIM for 2 min and S2 min PET images compared to 10min PET image were 30.983, 33.936, 9.954, 7.609 and 0.916, 0.934 respectively. The RC for spheres with S2 min PET image also met European Association of Nuclear Medicine Research Ltd. (EARL) FDG PET accreditation program. We confirmed generated S2 min PET image from N2V deep learning showed improvement results compared to 2 min PET image and The PET images on visual analysis were also comparable between 10 min and S2 min PET images. In conclusion, noisy PET image by means of short acquisition time using N2V denoising network model can be improved image quality without underestimation of radioactivity."
연구단보: 얼굴 표정을 이용한 비접촉식 거짓말 탐지 시스템 개발 및 유의시점 분석,2021,"['Forensic investigation', 'Deep-learning', 'Deception detection', 'Face landmark', 'Convolutional neural network', 'Long short term memory']","본 연구는 기존의 접촉식 거짓말 탐지의 단점을 해결하기 위하여 비접촉식 거짓말 탐지 기법을 개발하고자 얼굴 표정 변화를 촬영하고 분석하였다. 거짓말 탐지를 위한 영상 데이터 얻고자 모의범죄 실험을 진행하였으며, 긴장정점검사(POT)을 이용하여 데이터를 수집하였다. 거짓말을 할 때의 표정 분석을 위해 합성곱 신경망(CNN) 계열의 stacked hourglass 네트워크 4층을 쌓은 모델을 이용하여 얼굴에서 특징점을 추출하였다. 영상에서 프레임 단위로 추출한 66개의 특징점을 시간 순으로 배치하여 장단기메모리(LSTM) 모델을 이용하여 거짓말 영상과 진실 영상을 분류하는 모델을 개발하였으며, 모델 학습을 진행하고 이를토대로 평가 데이터를 통한 분류 정확도는 85.19%이었다. 학습이 완료된 모델의 결과를 분석하기 위하여LSTM 활성도 분석을 진행하였다. 개발한 방법을 이용하여 사람의 얼굴에서의 표정 변화를 이용한 거짓말탐지의 가능성을 확인할 수 있었으며, 비접촉식 거짓말 탐지에 중요한 시점을 도출하여 추후 비접촉식 거짓말 탐지의 가능성을 확인할 수 있었다",다국어 초록 정보 없음
GAN으로 합성한 음성의 충실도 향상,2021,"['Generative Adversarial Networks', 'Frechet Inception Distance', 'Fidelity Improvement', 'Synthesized Voice', '생성적 적대 신경망', '프레쳇 인셉션 거리', '충실도 개선', '합성된 음성']",국문 초록 정보 없음,"Although Generative Adversarial Networks (GANs) have gained great popularity in computer vision and related fields, generating audio signals independently has yet to be presented. Unlike images, an audio signal is a sampled signal consisting of discrete samples, so it is not easy to learn the signals using CNN architectures, which is widely used in image generation tasks. In order to overcome this difficulty, GAN researchers proposed a strategy of applying time-frequency representations of audio to existing image-generating GANs. Following this strategy, we propose an improved method for increasing the fidelity of synthesized audio signals generated by using GANs. Our method is demonstrated on a public speech dataset, and evaluated by Frechet Inception Distance (FID). When employing our method, the FID showed 10.504, but 11.973 as for the existing state of the art method (lower FID indicates better fidelity)."
지능형 CCTV 응용을 위한 객체 인식 기반 배경 차분 방법,2021,"['Background subtraction', 'Deep learning', 'Context-awareness']",국문 초록 정보 없음,"In this paper, we present a context-aware method for background maintenance. Traditionally, it is often difficult to model a background scene when backgound patterns are dramatically changing over time. In order to handle dynamic background objects, we utilize a standard Convolutional Neural Network (CNN)-based 2D object detector to identify the background patterns. The key observation is that detected regions do not belong to a true background. Hence, we consider a new confidence map to update the static background model and exclude pre-learnt background objects for conventional background subtraction methods. To this end, we clearly split the process into training/testing stages, and assume interest objects appear in the testing stage. For a practical application, we obtain two CCTV image sequences for intelligent transport systems, in which the CCTV system aims to automatically detecting the unseen objects in the challenging traffic congestion. Compared to the existing method such as the Mixture of Gaussian (MoG) model, the robustness of the proposed method to dynamic backgrounds is qualitatively shown using the real-world examples."
결측치 영향에 강인한 특성을 갖는 이미지화 기법 기반의 시계열 예측 모델,2021,[],"실시간 감염병 전파 예측 문제나 금융현상과 같은 응용 서비스에 시계열 예측 모델들이 적용됨으로써 예측 정확도가 향상되어 활용도가 높아지고 있으며, 최근 ARIMA, DNN, LSTM과 같은 예측 기법을 이용해 데이터를 처리하기 위한 최적 모델연구가 활발해지고 있다. LSTM은 이 중에서도 시계열 예측에 매우 적합하다는 평을 많이 받고 있는 모델이다. 그러나, 연속성이라는 특성을 가진 시계열 데이터에서 결측치가 발생하면 모델 학습에 치명적인 문제가 발생할 수 있다. 본 논문에서는 이러한 문제를 최소화하기 위해 CNN 기반 시계열 예측 모델과 시계열 데이터 이미지화 방법을 제안한다. 제안하는 이미지화 방법은 짧은 시계열 구간의 데이터 셋을 사용하여 결측치에 대한 영향을 감소시키고 관련 데이터를 사용해 정확도를 보강한다. 성능 평가를 위해 LSTM기반 모델과의 비교 실험을 진행하며, 해당 문제를 해결하면서 학습 정확도 뿐만아니라 학습시간 측면에서도 제안 학습 모델이 더 우수함을 보였다.",다국어 초록 정보 없음
A deep reinforcement learning algorithm based on modified Twin delay DDPG method for robotic applications,2021,"['Deep Reinforcement Learning', 'Policy Gradient', 'Actor-Critic', 'Deep Q-Learning', 'Robot Vision']",국문 초록 정보 없음,"This paper proposes a deep reinforcement learning algorithm for autonomous robotics, in which we modify twin delay deep deterministic policy gradient (TD3) to adapt for autonomous robots with higher degree freedom in movement. To provide a robot with free movement in the 2D space without collisions against some obstacles, such as wall, a robot is equipped with three cameras. The images captured by camera are used to train Convolutional Neural Networks (CNN) to understand environment with collisions or not-collisions. We added two additional parameters, observation ‘O’, which are images obtained from cameras, and degrees of turns ‘deg’ into the original TD3’s parameters composed of four values: [state ‘s’, reward ‘r’, action ‘a’ and nextstate ‘s’’]. To determine a next action with higher reward from the observation, two additional Neural Networks are constructed, being the first one determines an action from observation and the second one determines degree of turn from the observation and the action. The simulation results under three environments constructed by CoppeliaSim show a good performance of the proposed algorithm, reaching the target with higher rewards, even though the environments are unknown by robots."
체압 분포 영상 초고해상도 보정을 이용한 욕창 예방을 위한 환자 자세 추정,2021,"['Pressure ulcer', 'super-resolution', 'generative adversarial network', 'posture detection']",국문 초록 정보 없음,"In this study, to improve the prediction of pressure ulcer spots, we have developed super-resolution (SR) techniques to reconstruct a high-resolution (HR) pressure image from a low-resolution (LR) body pressure image to overcome the limitations of sensor resolution. We implemented a super-resolution generative adversarial network (SRGAN) to reconstruct pressure images and a convolution neural network (CNN) to predict posture. To evaluate the similarity between the original pressure image and the 4× rescaled LR body pressure image restored using SR technology, we used image quality assessment (IQA) technology, peak signal-to-noise ratio (PSNR), and structural similarity (SSIM). The reconstructed pressure images were classified into four patient postures (supine, right side, left side, and others) with 98.37% accuracy showing the feasibility of practical implementation."
딥 러닝기반 실시간 영상처리를 통한 크랙 탐지 및 개인형 이동수단 주행 보조 시스템 개발,2021,[],"장애인 및 거동이 불편한 고령자를 위한 전동 휠체어, 짧은 이동거리를 편리하게 이동할 수 있는 전동 킥보드 등 전동 모빌리티의 사용이 지속적으로 증가하는 추세이다. 이와 같은 개인형 이동수단의 확산으로 인해 관련 사고 또한 증가하고 있는데, 특히 고르지 못한 노면으로 인한 사고가 빈번하게 발생한다. 본 논문은 노면 크랙으로 인한 사고 및 주행 중 탑승자에게 가해지는 충격을 감소하여 개인형 이동수단의 안전한 주행을 보조하기 위한 딥러닝 기반의 주행 보조시스템을 제안한다. 제안하는 시스템은 실시간으로 촬영한 노면 사진을 입력 받고, 영상처리 및 CNN 기반의 딥러닝 기술을 활용하여 노면에 존재하는 크랙을 탐지한다. 크랙이 탐지된 경우, 크랙과 전동 모빌리티 기체와의 거리를 계산하고 이를 기반으로 기체의 이동 속도를 제어하여 탑승자에게 가해지는 충격 및 이로 인한 사고를 효과적으로 줄일 수 있다. 제한된 연산 자원을 가진 사물인터넷 기기에서 실시간 주행 보조를 가능케 하기 위해 경량화 된 딥러닝 모델을 사용했으며, 이미지 분할 및 선택적 크랙 탐지 기법을 제안하여 연산 복잡도를 효과적으로 감소시켰다. 실 환경에서 수행한 검증 결과를 통해 제안하는 시스템이 실시간으로 크랙을 탐지하고 주행 속도를 자동으로 제어하여 효과적으로 충격 량을 감소시키는 것을 확인했다.",다국어 초록 정보 없음
다양한 이미지 증대 기법에 따른 토마토 병충해 분류 성능 개선 연구,2021,"['Convolutional Neural Network', 'Image Augmentation', 'Image Selection', 'Tomato Disease']",국문 초록 정보 없음,"Crop diseases are damaging agricultural food worldwide. Early detection of crop diseases is important to prevent damage to crops. However, it is difficult to distinguish crop diseases unless not expert. Therefore, in this paper, a crop diseases classification system that can recognize diseases even before expert judgment is proposed. The characteristics of diseases were learned and classified using Convolutional Neural Network(CNN). In addition, images are augmented to increase classification performance. To augment the image, a basic augmentation policy consisting of Random Crop and Random Horizontal Flip and Google""s AutoAugment are used. Then, the augmented image was selected as an base augmentation model by setting a threshold and then trained. We compared the performance of the original, augmentation model, and image selection model. As a result, the image selection model set to the threshold value of 0.7 in AutoAugment achieved the performance of F1 Score 0.958"
"Enhancing Early Breast Cancer Detection Using Transfer Learning, Deep Feature Extraction and SVM Classification",2021,"['Exercise intensity', 'Decision Tree', 'Heart Rate Reserve', 'Personalized Exercise Prescription']",국문 초록 정보 없음,"In recent years, breast cancer has emerged as one of the most common types of cancer among women globally. Late diagnosis often results in a higher mortality rate, underlining the crucial need for effective early detection systems, especially those leveraging personal imaging data. In this regard, this study focuses on the integration of transfer learning and deep feature extraction techniques to adapt pretrained CNN models to breast cancer detection. Specifically, AlexNet and VGG16 are employed for feature extraction, with further tuning conducted on AlexNet. The derived features are then classified using Support Vector Machines (SVM). A comprehensive evaluation is carried out using a publicly available breast cancer dataset based on surgical and cellular pathology. Accuracy scores serve as performance metrics. The findings underscore the superior performance of the transfer learning approach compared to the combination of deep feature extraction and SVM classification."
AI 스피커를 활용한 어텐션 메커니즘 기반 멀티모달 우울증 감지 시스템,2021,[],"전세계적으로 우울증은 정신 건강 질환으로써 문제가 되고 있으며, 이를 해결하기 위해 일상생활에서의 우울증 탐지에 대한 연구가 진행되고 있다. 따라서 본 논문에서는 일상생활에 밀접하게 연관되어 있는 AI 스피커를 사용한 어텐션 메커니즘(Attention Mechanism) 기반 멀티모달 우울증 감지 시스템을 제안한다. 제안된 방법은 AI 스피커로부터 수집할 수 있는 음성 및 텍스트 데이터를 수집하고 CNN(Convolutional Neural Network)과 BiLSTM(Bidirectional Long Short-Term Memory Network)를 통해 각 데이터에서의 학습을 진행한다. 학습과정에서 Self-Attention 을 적용하여 특징 벡터에 추가적인 가중치를 부여하는 어텐션 메커니즘을 사용한다. 최종적으로 음성 및 텍스트 데이터에서 어텐션 가중치가 추가된 특징들을 합하여 SoftMax 를 통해 우울증 점수를 예측한다.",다국어 초록 정보 없음
마이크로프로세서 기반의 얼굴 마스크 감지,2021,"['TinyML', 'Maixduino', 'Micropython', 'MobileNet', 'Mask detection']",국문 초록 정보 없음,"This paper proposes an embedded system that detects mask and face recognition based on a microprocessor instead of Nvidia Jetson Board what is popular development kit. We use a class of efficient models called Mobilenets for mobile and embedded vision applications. MobileNets are based on a streamlined architechture that uses depth- wise separable convolutions to build light weight deep neural networks. The device used a Maix development board with CNN hardware acceleration function, and the training model used MobileNet_V2 based SSD(Single Shot Multibox Detector) optimized for mobile devices. To make training model, 7553 face data from Kaggle are used. As a result of test dataset, the AUC (Area Under The Curve) value is as high as 0.98."
무인수거차량 작업자 안전을 위한 인식 시스템 연구,2021,"['Worker detection', 'Deep learning', 'Sensor fusion', 'Point cloud mapping']","본 연구에서는 무인 수거 차량의 작업자 안전을 위한 인식 시스템 구축 방법에 대해 제안하고자 한다. 시스템은 자율주행 차량의 물체 인식에서 사용되고 있는 카메라와 라이다 켈리브레이션 기법을 사용하여 센서를 융합하는 방법을 사용하였고, 화각이 넓은 카메라(화각 180o)와 좁은 라이다(수평 60°, 수직 4°) 사이에 발생하는 라이다의 사각지대에 대해서는 Convolutional Neural Network (CNN)을 적용한 보상 방법을 사용하였다. 보정판을 측정하여 획득한 2 차원, 3 차원 데이터의 캘리브레이션을 통해 두 센서 사이의 기하 보정, 회전행렬과 이동행렬을 구하여 라이다에서 측정된 3 차원 데이터를 2 차원 데이터로 변환한 후 물체 인식 알고리즘을 통해 획득한 작업자의 객체 박스와 라이다의 거리 데이터를 다시 학습함으로 사각 지대에서 거리 데이터를 유추하였다. 제안하고자 하는 방법에서 카메라 설치 위치는 사선으로 영상을 취득할 수 있는 높은 위치에 설치함으로 사각지대에서의 영상만으로 작업자 위치를 인식하는데 효과적인 영상을 획득할 수 있으며, 본 영구에서 제안한 방법을 통해 라이다 사각 지대에서의 작업자 인식 결과에서 거리가 정보 측정됨을 확인하였다.",다국어 초록 정보 없음
측면 영상을 이용한 영상 기반 케이블 변위 측정,2021,"['Computer Vision', '객체 추적', 'Multi-View Geometry', 'Cable Displacement']",사장교에서 케이블은 굉장히 중요한 구조요소 중 하나이다. 케이블의 건전성을 파악하고 대응하기 위해서는 발생한 진동의 측정을 필요로 한다. 케이블의 동적 진동을 측정하기 위해서 다양한 연구들이 수행되고 있다. 최근에는 Computer Vision 기술을 이용하여 구조물의 변위를 측정하는 연구들이 진행되고 있다. 하지만 기존의 영상 기반 변위 측정을 케이블에 적용하기에는 몇 가지 문제점이 발생한다. 본 연구에서는 Computer Vision 기술을 기반으로 CNN(Convolutional Neural Network)을 활용하여 사장교 케이블의 거동을 장기간 측정하는데 발생하는 문제점들을 해결하고자 한다.,다국어 초록 정보 없음
Optimizing TensorFlow Performance by Reconstructing the Convolution Routine,2021,"['TensorFlow', 'Profiling', 'Optimization', 'Batch']",국문 초록 정보 없음,"Using deep learning, we can currently build computational models composed of multiple processing layers to learn representations of data. Convolutional neural networks (CNNs) have been widely adopted to achieve significant performance in image recognition and classification. TensorFlow, an open-source deep learning framework from Google, uses profiling to select one convolution algorithm, from among several available, as the core of a CNN to deliver the best performance in terms of execution time and memory usage. However, the overhead from profiling is considerably significant, because TensorFlow executes and profiles all the available algorithms for the best selection whenever an application is launched. We observe that memory usage overshoots during profiling, which limits data parallelism, and thus, fails to deliver maximum performance. In this paper, we present a novel profiling method to reduce overhead by storing the profile result from the first run and reusing it from the second run on. Using Inception-V3, we achieved up to 1.12 times and 1.11 times higher throughput, compared to the vanilla TensorFlow and TensorFlow with XLA JIT compilation, respectively, without losing accuracy."
온사이트 지진조기경보를 위한 딥러닝 기반 실시간 오탐지 제거,2021,"['Earthquake early warning', 'Onsite warning', 'False-pick', 'False alarm', 'Deep learning', 'Convolutional neural network']",국문 초록 정보 없음,"This paper presents a real-time, false-pick filter based on deep learning to reduce false alarms of an onsite Earthquake Early Warning (EEW) system. Most onsite EEW systems use P-wave to predict S-wave. Therefore, it is essential to properly distinguish P-waves from noises or other seismic phases to avoid false alarms. To reduce false-picks causing false alarms, this study made the EEWNet Part 1 'False-Pick Filter' model based on Convolutional Neural Network (CNN). Specifically, it modified the Pick_FP (Lomax et al.) to generate input data such as the amplitude, velocity, and displacement of three components from 2 seconds ahead and 2 seconds after the P-wave arrival following one-second time steps. This model extracts log-mel power spectrum features from this input data, then classifies P-waves and others using these features. The dataset consisted of 3,189,583 samples: 81,394 samples from event data (727 events in the Korean Peninsula, 103 teleseismic events, and 1,734 events in Taiwan) and 3,108,189 samples from continuous data (recorded by seismic stations in South Korea for 27 months from 2018 to 2020). This model was trained with 1,826,357 samples through balancing, then tested on continuous data samples of the year 2019, filtering more than 99% of strong false-picks that could trigger false alarms. This model was developed as a module for USGS Earthworm and is written in C language to operate with minimal computing resources."
Convolutional Neural Network 기반 IRS 시스템 통신 기법,2021,[],"최근 밀리미터파와 같은 고주파수 대역 통신과 함께 intelligent reflecting surface (IRS)가 큰 주목을 받고 있다. IRS는 고주파수 대역 문제가 되었던 통신 거리와 전송 속도를 개선을 위해 사용되었으며, 저비용 수동소자로 이루어졌기 때문에 저렴한 가격과 기존의 릴레이 방식보다 높은 에너지 효율을 갖는 장점이 있다. IRS는 작은 안테나 요소들로 이루어져 있기 때문에 최적의 송수신기 설계는 상호 결합 매트릭스에 따라 결정된다. 이 논문에서는 convolutional neural network (CNN)기반 IRS 위상 제어 기법을 제안하고자한다.",다국어 초록 정보 없음
다중 작업 학습 기반의 밀링 공정에서의 절삭력 및 공구 마모 예측,2021,"['Multitask learning', 'Deep learning', 'Predictive models', 'Convolution neural network', 'Milling process']","최근 제조업에서 가공 상태 모니터링 및 결함 진단 등 다양한 측면에서 물리학 기반 모델을 보완하기 위해 딥러닝을 접목하고 있지만 단일 작업에 대한 예측만 수행할 수 있어 다양한 데이터 수집을 위해서는 실험 비용이 증가하고 반복 작업을 해야 하는 한계점이 존재한다. 이러한 문제를 해결하기 위해 본 연구에서는 가공 상태를 파악할 수 있는 요소인 절삭력과 공구마모 상태를 예측하는 합성곱 신경망(Convolution Neural Network, CNN)기반 다중 작업학습 방법(Multi-Task Learning, MTL)을 제안하고자 한다. 각각 다른 특성이 하나의 신경망을 통해 다양한 작업을 동시에 수행하고 작업 간 상호적으로 영향을 미치면서 학습하는 방식인 다중 작업 학습(MTL)기법은 각 작업의 정보를 공유하며 과적합을 억제할 수 있어 예측 정확도 향상 및 분석 시간 단축이 가능하기에 실질적으로 제조 현장에서 사용 가능한 모델을 구축할 수 있다. 제안된 방법론 검증을 위해 Doosan NX5500II 장비에서 SM45C 소재의 가공 데이터를 모니터링 시스템을 통해 수집하여 사용하였으며, 다중 작업 학습 기법의 적용 유무에 따른 예측 성능 향상 정도 및 분석 시간을 비교하였다. 그 결과 다중 작업 학습 모델이 단일 작업에 대한 독립적인 합성곱 신경망 모델 보다 성능이 우수하며 모든 경우의 분석 시간이 단축되는 것을 확인하였다.",다국어 초록 정보 없음
기상 데이터와 기상 위성 영상을 이용한 다중 딥러닝 모델 기반 일사량 예측,2021,"['Satellites Image', 'Weather Data', 'Multi Deep Learning Model', 'Radiation Prediction', 'Artificial Intelligence']","딥러닝은 데이터의 품질과 모델에 따라 예측 성능에 차이를 보인다. 본 연구는 발전량 예측에 가장 영향을 주는 일사량 예측을 위한 최적의 딥러닝 모델을 구축하기 위해 다양한 입력 데이터와 다중 딥러닝 모델을 사용하였다. 입력 데이터는 기상청의 기상 데이터와 천리안 기상영상을 기상청 지역의 영상을 분할하여 사용하였다, 본 연구는 기본적인 딥러닝 모델인 DNN, LSTM, CNN 모델에 대해 중간층의 깊이와 노드를 변경하여 일사량을 예측하여, 비교 평가하였다, 또한, 각 모델에서 가장 좋은 오차율을 가진 모델을 연결한 다증 딥러닝 모델을 구축하여 일사량을 예측하였다. 실험 결과로서 다중 딥러닝 모델인 모델 A의 RMSE는 0.0637이며, 모델 B의 RMSE는 0.07062이며, 모델 C의 RMSE는 0.06052로서 단일 모델보다 모델 A 그리고 모델 C의 오차율이 좋았다. 본 연구는 실험을 통해 두 개 이상의 모델을 연결한 모델이 향상된 예측률과 안정된 학습 결과를 보였다.","Deep learning shows differences in prediction performance depending on data quality and model. This study uses various input data and multiple deep learning models to build an optimal deep learning model for predicting solar radiation, which has the most influence on power generation prediction. did. As the input data, the weather data of the Korea Meteorological Administration and the clairvoyant meteorological image were used by segmenting the image of the Korea Meteorological Agency. , comparative evaluation, and predicting solar radiation by constructing multiple deep learning models connecting the models with the best error rate in each model. As an experimental result, the RMSE of model A, which is a multiple deep learning model, was 0.0637, the RMSE of model B was 0.07062, and the RMSE of model C was 0.06052, so the error rate of model A and model C was better than that of a single model. In this study, the model that connected two or more models through experiments showed improved prediction rates and stable learning results."
호가창(Limit Order Book)과 뉴스 헤드라인을 이용한 딥러닝 기반 주가 변동 예측,2021,[],"본 논문은 어떤 기업의 주식 주문 정보를 담고 있는 호가창(limit order book)과 해당 기업과 관련된 뉴스 헤드라인을 사용하여 해당 기업의 주가 등락을 예측하는 딥러닝 기반 모델을 제안한다. 제안 모델은 호가창의 중기 변화와 단기 변화를 모두 고려하는 한편, 동기간 발생한 뉴스 헤드라인까지 예측에 고려함으로써 주가 등락 예측 정확도를 높인다. 제안 모델은 호가창의 변화의 특징을 CNN(convolutional neural network)으로 추출하고 뉴스 헤드라인을 Word2vec으로 생성된 단어 임베딩 벡터를 사용하여 나타낸 뒤, 이들 정보를 결합하여 특정 기업 주식의 다음 날 등락여부를 예측한다. NASDAQ 실데이터를 사용한 실험을 통해 제안 모델로 5개 종목(Amazon, Apple, Facebook, Google, Tesla)의 일일 주가 등락을 예측한 결과, 제안 모델은 기존 방법에 비해 정확도를 최대 17.14%, 평균 10.7% 향상시켰다.",다국어 초록 정보 없음
Intrusion Detection for Network Based Cloud Computing By Custom RC-NN and Optimization,2021,"['Intrusion detection', 'Neural networks', 'Deep learning', 'Cloud computing', 'Network security']",국문 초록 정보 없음,"Intrusion detection acts as a vital function in providing information security, and additionally the key technology is to precisely classify diverse attacks. Intrusion detection system (IDS) is identified as an important security issue within the cloud network environment. In this paper, IDS is given based on an innovative optimized custom RC-NN (Recurrent Convolutional Neural Network) which is proposed for intrusion detection along with the Ant Lion optimization algorithm. By this method, CNN (Convolutional Neural Network) is made hybrid with LSTM (Long Short Term Memory). Thus, all the attacks identified with the network layer of cloud are classified efficiently. The experimental results shown below describe the presentation of the IDS classification model with high accuracy, thus improving the detection rate or error rate. The optimized custom RC-NN-IDS model thus achieved an improved classification accuracy of 94% and also a decreased error rate of 0.0012. Additionally true positive rate, true negative rate and precision are considered as performance metrics. The proposed approach is evaluated using the DARPA IDS evaluation Data Sets and CSE-CIC-IDS2018 dataset and is compared with some existing approaches."
RGBD 센서와 딥러닝을 응용한 과실의 비대 예측 및 적정 수확기 판단기술 개발,2021,"['RGBD 센서', '딥러닝', '과실 비대', '객체 검출', '검출 상자']","4차 산업 혁명에 따른 기술의 발전이 농업 분야에도 물결이 조용하고 빠르게 번지고 있다. 이러한 스마트팜에 적용되는 여러 가지 기술 중 특정 작물 및 과실에 대한 영상 기반 객체 인식 및 검출 기술은 과실의 생육 측정을 위한 모니터링의 자동화 및 로봇 기반 수확을 위하여 필수적이다. 특히 최근에는 합성곱신경망(Convolutional Neural Network, CNN) 기반의 딥러닝 모델을 활용하여 영상의 객체 검출 분야에서 높은 성능을 보이며, 스마트팜에 요구되는 영상인식 기술에서 다양하게 적용되고 있다. 본 연구에서는 사과(홍로)를 대상 과실로 지정하였으며, RGB-D 센서를 통해 현지 농가에서 획득한 사과의 RGB 영상과 Depth 영상을 이용하였다. 영상 내 과실의 검출에 이용되는 합성곱신경망 기반의 네트워크인 EfficientDet D2를 주로 적용하여 영상 내 사과의 개수와 위치, 특히 검출 상자의 위치를 정확하게 찾는 것을 우선시하였다. 또한, 과실의 생육 경과를 확인하기 위해서 검출된 사과의 픽셀 좌표와 깊이 센서를 통해 얻은 3차원 깊이 정보를 병합하여 과실의 비대를 예측하고 실제 과실의 크기와 비교 측정하여 검증하는 과정을 진행하였다.",다국어 초록 정보 없음
드론을 활용한 고속도로 고교각 교량의 영상점검 방안,2021,"['교량점검', '유지관리', '드론', '영상분석', '인공지능', 'Bridge Inspection', 'UAV', 'Artificial Intelligence']","도로교통연구원 구조물연구실에서는 4차산업혁명의 주요기술인 드론, IoT, AI 기술을 활용하여 고교각 외관조사를 위하여 영상기반의 스마트 교량점검 시스템 구축 방법에 대한 연구를 수행하였다. 본 논문에서는 공용 중인 학의대교 교각과 서해대교 사장교 구간에서 드론의 포인트 클라우드 기법과 VR기법을 활용하여 주탑, 고교각, 케이블 정착구, 슬래브 바닥판, 주탑 및 크로스빔 등의 외관조사결과를 소개하고자 한다. 영상점검기술을 활용하여 외관조사망도를 효율적으로 작성하였으며, 교량 표면의 손상유형 분류를 위하여 개선된 CNN(Convolutional Neural Network) 딥러닝 분석기법을 활용하였다.",다국어 초록 정보 없음
인공지능 기반 플랜트 도면 내 심볼 객체 자동화 검출,2021,[],국문 초록 정보 없음,"P&ID((Piping and Instrument Diagram) is a key drawing in the engineering industry because it contains information about the units and instrumentation of the plant. Until now, simple repetitive tasks like listing symbols in P&ID drawings have been done manually, consuming lots of time and manpower. Currently, a deep learning model based on CNN(Convolutional Neural Network) is studied for drawing object detection, but the detection time is about 30 minutes and the accuracy is about 90%, indicating performance that is not sufficient to be implemented in the real word. In this study, the detection of symbols in a drawing is performed using 1-stage object detection algorithms that process both region proposal and detection. Specifically, build the training data using the image labeling tool, and show the results of recognizing the symbol in the drawing which are trained in the deep learning model."
딥 러닝을 이용한 목재 옹이 이미지 분할,2021,[],"시각 검사에 의존하는 목재 품질 평가는 작업자의 주관에 의한 판단에 의존할 뿐만 아니라 반복 작업이 유발하는 피로 누적으로 인해 일관적인 평가를 담보하기 어렵다. 또한 시각 검사는 단속적으로 수행되기에 전반적인 공정의 속도를 저해하는 요인이다. 본 연구에서는 통상적 시각 검사를 보조 혹은 대체하기 위한 수단으로서 딥 러닝 모델을 이용한 목재 표면 옹이의 자동화 분할 모델을 개발하였다. 물체 검출 모델인 Mask R-CNN을 이용하여 침엽수 7종(Pinus densiflora, Pinus koraiensis, Pinus radiata, Larix kaempferi, Cryptomeria japonica, Chamaecyparis obtusa, Pseudotsuga menziesii )의 판재 표면 이미지들로부터 4종의 옹이(썩은 옹이, 죽은 옹이, 산 옹이, 긴 옹이)를 탐지 및 분할하였다. 이미지 데이터세트는 938장의 표면 이미지로 구성되어 있으며 이미지의 픽셀 해상도는 0.187 mm/pixel이었다. 모델의 옹이 탐지 및 분류 성능은 intersection over union (IOU)를 고려한 평균 정밀도(mean average precision, mAP)로 평가하였다. 구축된 탐지 모델은 IOU 50% 수준에서 mAP 80.4%를 달성하였다. 수동 시각 검사로부터 70-80% 이상의 정확도를 보장할 수 없다는 연구 결과들을 고려할 때 본 연구에서 개발된 탐지 모델은 통상적인 시각 검사를 보조할 수 있는 수준이라고 판단된다. 게다가 개발된 모델이 제공하는 옹이 영역 분할 정보로부터 옹이 크기를 산출할 수 있으며, 이는 등급 분류에 적용할 수 있다.",다국어 초록 정보 없음
드론을 활용한 고속도로 고교각 교량의 영상점검 방안,2021,"['교량점검', '유지관리', '드론', '영상분석', '인공지능', 'Bridge Inspection', 'UAV', 'Artificial Intelligence']","도로교통연구원 구조물연구실에서는 4차산업혁명의 주요기술인 드론, IoT, AI 기술을 활용하여 고교각 외관조사를 위하여 영상기반의 스마트 교량점검 시스템 구축 방법에 대한 연구를 수행하였다. 본 논문에서는 공용 중인 학의대교 교각과 서해대교 사장교 구간에서 드론의 포인트 클라우드 기법과 VR기법을 활용하여 주탑, 고교각, 케이블 정착구, 슬래브 바닥판, 주탑 및 크로스빔 등의 외관조사결과를 소개하고자 한다. 영상점검기술을 활용하여 외관조사망도를 효율적으로 작성하였으며, 교량 표면의 손상유형 분류를 위하여 개선된 CNN(Convolutional Neural Network) 딥러닝 분석기법을 활용하였다.",다국어 초록 정보 없음
Distracted Driver Recognizer with Simple and Efficient Convolutional Neural Network for Real-time System,2021,"['Convolutional Neural Network', 'Distracted driver recognizer', 'Driver Surveillance system', 'Image classification']",국문 초록 정보 없음,"The traffic accident is a big problem in the world and it is happening every day. One of the main causes is distracted driving. Those are the actions of the driver when they are not focusing on driving on the road such as using the cellphone, drinking, makeup, talking to others, etc. For driver warning purpose, this paper proposes a distracted driver recognizer with a simple and efficient Convolutional Neural Network (CNN). The evaluation results on the State Farm Distracted Driver Detection dataset with ten activities achieved an accuracy of 99.51% and on video with the latency allowed for deployment in the real-time system based on a low-computation device."
패스트 독립성분분석 기반의 화력발전기 이상 전조 증상 탐지,2021,"['독립 성분 분석', '화력발전소', '예지보전']","화력발전기는 이상 및 고장이 발생할 경우 잠재적인 위험성이 높은 설비이므로, 고장을 사전에 방지하는 이상 전조증상 탐지 기술이 중요하다. 이상 전조 증상 탐지 기술은 시스템의 열화 상태에 따라 고장발생 이전의 특징을 확인하고 선행보전활동을 수행함으로써, 사후보전비용을 최소화할 수 있다.본 발표에서는 통계적인 알고리즘 중 하나인 패스트 독립성분분석을 활용하여 화력발전기의 중요 변수를 산출하고 임계값을 지속적으로 이탈하는 구간을 이상 전조 구간으로 탐지한다. 또한, 탐지한 전조 구간을 활용하여 화력발전소의 잔여 수명을 조각별 열화 모델(Piecewise Degradation Model)과 컨볼루션 신경망(CNN)으로 추정하여 구체적인 사전예지보전을 수립하였다.실제 화력발전기 데이터를 적용한 결과, 제안한 방법론이 이상 전조 증상을 탐지하여 사전 정비를 통한 설비의 가용성을 높일 수 있을 뿐만 아니라, 발견하지 못한 고장에 대하여 탐색을 수행할 수 있음을 확인하였다.",다국어 초록 정보 없음
드론을 활용한 고속도로 고교각 교량의 영상점검 방안,2021,"['교량점검', '유지관리', '드론', '영상분석', '인공지능', 'Bridge Inspection', 'UAV', 'Artificial Intelligence']","도로교통연구원 구조물연구실에서는 4차산업혁명의 주요기술인 드론, IoT, AI 기술을 활용하여 고교각 외관조사를 위하여 영상기반의 스마트 교량점검 시스템 구축 방법에 대한 연구를 수행하였다. 본 논문에서는 공용 중인 학의대교 교각과 서해대교 사장교 구간에서 드론의 포인트 클라우드 기법과 VR기법을 활용하여 주탑, 고교각, 케이블 정착구, 슬래브 바닥판, 주탑 및 크로스빔 등의 외관조사결과를 소개하고자 한다. 영상점검기술을 활용하여 외관조사망도를 효율적으로 작성하였으며, 교량 표면의 손상유형 분류를 위하여 개선된 CNN(Convolutional Neural Network) 딥러닝 분석기법을 활용하였다.",다국어 초록 정보 없음
이미지 증대 기법을 이용한 토마토 병충해 분류,2021,"['Convolutional Neural Network', 'Generative Adversarial Network', 'Image Augmentation', 'Tomato Disease']",국문 초록 정보 없음,"The tomato is one of important crops in the world market with high commercial value. The early detection of disease is crucial for an successful crop yield. Many studies have recently been conducted to identify plant disease. In this paper, tomato disease classification using leaf images is proposed. Using the convolutional neural network(CNN), the features of disease are extracted and learned to classify. Data augmentation methods, Google’s AutoAugment algorithm and GAN(Generative Adversarial Networks), are used to increase tomato disease data. The classification model classifies nine classes of tomato disease. We compared the original model with the data augmentation models and explored that the classification that produced good performance. As a result, the SVHN policy of AutoAugment model achieved F1 Score 0.945."
funcGNN과 Siamese Network의 코드 유사성 분석 성능비교,2021,"['Code Similarity', 'funcGNN', 'Siamese Network', 'Control Flow Graph', 'Adjacency Matrices']",국문 초록 정보 없음,"As artificial intelligence technologies, including deep learning, develop, these technologies are being introduced to code similarity analysis. In the traditional analysis method of calculating the graph edit distance (GED) after converting the source code into a control flow graph (CFG), there are studies that calculate the GED through a trained graph neural network (GNN) with the converted CFG, Methods for analyzing code similarity through CNN by imaging CFG are also being studied. In this paper, to determine which approach will be effective and efficient in researching code similarity analysis methods using artificial intelligence in the future, code similarity is measured through funcGNN, which measures code similarity using GNN, and Siamese Network, which is an image similarity analysis model. The accuracy was compared and analyzed. As a result of the analysis, the error rate (0.0458) of the Siamese network was bigger than that of the funcGNN (0.0362)."
변전소를 위한 인공지능기법을 이용한 고장복구 지원 시스템,2021,[],"변전소의 고장 파급은 사회적 손실을 수반하므로 변전소 고장시 신속한 복구가 필요하다. 최근 컴퓨터 플랫폼이 개선되고, 기술이 고도화 되면서 전력설비의 지능화 필요성이 제기되고 있다. 본 논문에서는 인공지능기법(AI)을 이용한 변전소의 고장복구 지원 시스템을 제안한다. 변전소의 구성요소인 CB, Relay 동작 상태 정보를 이진데이터 형식으로 변환하여, 심층 신경망에서 학습할 수 있는 형태로 데이터 패턴을 구성하였다. 심층 신경망(CNN)을 이용하여 고장 유형을 판별하였다. 규칙 기반 전문가 시스템을 사용하여 고장복구 절차를 출력하고, 유형이 판별되지 않은 부분에 대해서 유전자알고리즘(GA)를 통해 최적화된 고장복구 경로를 도출한다. 각 구성요소별 임의 고장을 발생시키는 시뮬레이션을 통해 제안된 시스템의 성능을 검증하고자 한다.",다국어 초록 정보 없음
드론을 활용한 고속도로 고교각 교량의 영상점검 방안,2021,"['교량점검', '유지관리', '드론', '영상분석', '인공지능', 'Bridge Inspection', 'UAV', 'Artificial Intelligence']","도로교통연구원 구조물연구실에서는 4차산업혁명의 주요기술인 드론, IoT, AI 기술을 활용하여 고교각 외관조사를 위하여 영상기반의 스마트 교량점검 시스템 구축 방법에 대한 연구를 수행하였다. 본 논문에서는 공용 중인 학의대교 교각과 서해대교 사장교 구간에서 드론의 포인트 클라우드 기법과 VR기법을 활용하여 주탑, 고교각, 케이블 정착구, 슬래브 바닥판, 주탑 및 크로스빔 등의 외관조사결과를 소개하고자 한다. 영상점검기술을 활용하여 외관조사망도를 효율적으로 작성하였으며, 교량 표면의 손상유형 분류를 위하여 개선된 CNN(Convolutional Neural Network) 딥러닝 분석기법을 활용하였다.",다국어 초록 정보 없음
Edge Computing Based Surveillance Framework for Real Time Activity Recognition,2021,"['Edge computing', 'Convolutional Neural Network', 'Suspicious activity']",국문 초록 정보 없음,"Closed Circuit Television (CCTV) based Surveillance has become the fundamental part of the security Systems. In most cases, surveillance feeds are only used as evidence. The emergence of Edge Computing gives hope for enabling real time surveillance systems that focuses on prevention of crimes. The proposed architecture consists of a Convolutional Neural Network (CNN) enabled in an edge device, with reduced computational complexity, which classifies various actions like Pulling, pushing and other hand movements and locates the identified activities in the image frame using bounding boxes. The proposed architecture gives an alert whenever a suspicious activity is detected. The system was found efficient when validated against the Dataset taken from the SRM IST Campus."
드론을 활용한 고속도로 고교각 교량의 영상점검 방안,2021,"['교량점검', '유지관리', '드론', '영상분석', '인공지능', 'Bridge Inspection', 'UAV', 'Artificial Intelligence']","도로교통연구원 구조물연구실에서는 4차산업혁명의 주요기술인 드론, IoT, AI 기술을 활용하여 고교각 외관조사를 위하여 영상기반의 스마트 교량점검 시스템 구축 방법에 대한 연구를 수행하였다. 본 논문에서는 공용 중인 학의대교 교각과 서해대교 사장교 구간에서 드론의 포인트 클라우드 기법과 VR기법을 활용하여 주탑, 고교각, 케이블 정착구, 슬래브 바닥판, 주탑 및 크로스빔 등의 외관조사결과를 소개하고자 한다. 영상점검기술을 활용하여 외관조사망도를 효율적으로 작성하였으며, 교량 표면의 손상유형 분류를 위하여 개선된 CNN(Convolutional Neural Network) 딥러닝 분석기법을 활용하였다.",다국어 초록 정보 없음
A Detection Algorithm Design based on Image Segmentation Strategy for Vehicle Damage Recognition,2021,[],국문 초록 정보 없음,"In this paper, a detection algorithm design based on image segmentation strategy for vehicle damage recognition was proposed by constructing a vehicle segmentation dataset to analyze damage recognition for each body part of a vehicle. The proposed algorithm is processed based on the Mask RCNN (mask region of convolutional network) model and includes convolutional neural network (CNN), region proposal network (RPN) and region of interest (RoI). The proposed algorithm is expected to be able to act on behalf of humans in the field of self-driving vehicle damage estimation and auto insurance claim process after sufficient testing and reliability process."
Boosting Image Caption Generation with Parts of Speech,2021,"['이미지 캡션 생성', '인코더-디코더 구조', '품사', '컴퓨터 비전', 'image caption generation', 'encoder-decoder architecture', 'parts of speech', 'computer vision']",국문 초록 정보 없음,"With the integration of smart devices and reliance on AI into our daily lives, the ability to generate image caption is becoming increasingly important in various fields such as guidance for visually-impaired individuals, human-computer interaction and so on. In this paper, we propose a novel approach based on parts of speech (POS), such as nouns and verbs extracted from image to enhance the image caption generation. The proposed model exploits multiple CNN encoders, which were specifically trained to identify features related to POS, and feed them into an LSTM decoder to generate image captions. We conducted experiments involving both Flickr30k and MS-COCO datasets using several text metrics and additional human surveys to validate the practical effectiveness of the proposed model."
합성곱 신경망의 Channel Attention 모듈 및 제한적인 각도 다양성 조건에서의 SAR 표적영상 식별로의 적용,2021,[],국문 초록 정보 없음,"In the field of automatic target recognition(ATR) with synthetic aperture radar(SAR) imagery, it is usually impractical to obtain SAR target images covering a full range of aspect views. When the database consists of SAR target images with limited angular diversity, it can lead to performance degradation of the SAR-ATR system. To address this problem, this paper proposes a deep learning-based method where channel attention modules(CAMs) are inserted to a convolutional neural network(CNN). Motivated by the idea of the squeeze-and-excitation(SE) network, the CAM is considered to help improve recognition performance by selectively emphasizing discriminative features and suppressing ones with less information. After testing various CAM types included in the ResNet18-type base network, the SE CAM and its modified forms are applied to SAR target recognition using MSTAR dataset with different reduction ratios in order to validate recognition performance improvement under the limited angular diversity condition."
코로나19 재난문자 데이터를 활용한 의도 분류 모델 설계,2021,[],"코로나19가 2020년 전 세계적인 범유행 감염병이 됨에 따라 2020년에 한 해에 발송된 재난문자의 수는 54,734건으로 2019년에 비해 약 60배 증가하였다. 이에 발생한 문제를 해결하고자 코로나19 재난문자의 의도에 따라 기준을 정하고 자동으로 분류하여, 수신자가 필요한 내용만 수신하게 하는 목적으로 본 연구를 수행하였다. 코로나19 재난문자를 총 5개의 기준으로 분류하였고, 자동으로 분류하는 방법으로는 딥러닝 모델 중 KoBERT와 1D-CNN을, Clustering 알고리즘을 사용하는 BERTopic, K-Means Clustering과 단순 키워드 분류까지 5가지의 분류 모델을 선택하여 성능을 측정하였다. 이후 성능 향상을 위해 코로나19 재난문자의 분류 기준을 1, 2차 분류로 나눠 2단계로 분류하는 모델을 제안하였으며, 타 분류 모델들보다 높은 96.7%의 정확도를 달성하였다.",다국어 초록 정보 없음
A Practical Approach to Indoor Path Loss Modeling Based on Deep Learning,2021,"['Deep learning', 'Indoor path loss modeling', 'Convolutional neural networks']",국문 초록 정보 없음,"Deep learning has become one of the most powerful prediction approaches, and it can be used to solve classification and regression problems. We present a novel deep learning-based indoor Wi-Fi path loss modeling approach. Specifically, we propose a local area multi-line scanning algorithm that generates input images based on measurement locations and a floor plan. As the input images contain information regarding the propagation environment between the fixed access points (APs) and measurement locations, a convolutional neural network (CNN) model can be trained to learn the features of the indoor environment and approximate the underlying functions of the Wi-Fi signal propagation. The proposed deep learning-based indoor path loss model can achieve superior performance over 3D ray-tracing methods. The average root mean square error (RMSE) between the predicted and measured received signal strength values in the two scenarios is 4.63 dB."
시각장애인을 위한 시각 도움 서비스를 제공하는 인공지능 시스템 개발,2021,[],국문 초록 정보 없음,"order to provide helpful service for the visually impaired, this study was carried out to make a new smart glasses that transmit information monitoring walking environment in real-time object recognition. In terms of object recognition, YOLOv4 was used as the artificial intelligence model. The objects, that should be identified during walking of the visually impaired, were selected, and the learning data was populated from them and re-learning of YOLOv4 was performed.As a result, the accuracy was average of 68% for all objects, but for essential objects (Person, Bus, Car, Traffic_light, Bicycle, Motorcycle) was measured to be 84%. In the future, it is necessary to secure the learning data in more various ways and conduct CNN learning with various parameters using darkflow rather than YOLOv4 to perform comparisons in the various ways."
시간 합성곱 신경망을 이용한 베어링 성능 저하 예측 방법 개발,2021,"['구름 베어링(Rolling bearing)', '성능 저하 예측(Performance degradation prediction)', '시계열 예측(Timeseries prediction)', '시간 합성곱 신경망(Temporal convolutional networks)', '팽창 합성곱(Dilated convolution)', '인과적 합성곱(Causal convolution) 나사 베어링 데이터셋(Bearing dataset of NASA)']",국문 초록 정보 없음,"Performance degradation of a rolling bearing is a major factor for machine failure, which makes its prediction and diagnosis an important topic in engineering. Various studies have been carried out to predict this performance degradation, where recent developments in deep-learning led many researchers to tackle this problem using recurrent neural network (RNN) architectures such as long-short-term-memory (LSTM). However, RNN architectures consists of intrinsic problems such as the ‘requirement of substantial memory resource’ or ‘gradient vanishing’. Hence, this study proposes using a temporal convolutional network (TCN) for the bearing performance-degradation prediction. TCN is a convolutional neural network (CNN) that can predict time-series data using dilated causal convolutions. It has recently gained popularity in time-series prediction due to its capability to overcome issues caused by RNN architectures. A bearing dataset provided by NASA has been used to verify the performance of TCN, and the results were compared to other conventional deep-learning techniques."
Hybrid Deep Neural Network for Malicious DNS Infiltration Detection System,2021,"['DNS', 'DNS Security', 'DoH', 'LSTM', 'Machine Learning']",국문 초록 정보 없음,"The domain name system (DNS) is arguably the most important infrastructure of the Internet. Due to its prominant role in communication, DNS has come under heavy security attacks which are most times catastrophic. Encapsulating DNS inside of HyperText Transfer Protocol Secured (HTTPS) as DNS over HTTPS (DoH) does not completely prevent intruders from exploiting access into the network. In this paper we aim at mitigating such security concerns in DNS by proposing a hybrid network model that comprises of a convolutional neural network (CNN) and long short-term memory (LSTM) in classifying network traffic as either malicious, benign or non-DoH, thereby giving the system administrator the ability of eliminating all malicious traffics. Simulation results shows that the propose scheme could better detect between malicious, benign and non- DoH classes with an accuracy of 99%. Index Terms—DNS, DNS Security, DoH, LSTM, Machine Learning"
TensorFlow Lite for Microcontroller를 위한 Bfloat16 Simulation 환경 구현,2021,[],국문 초록 정보 없음,"This paper represents the inference efficiency of the brain floating-point (bfloat16) for DNNs (Deep Neural Networks) applications in TensorFlow Lite for Microcontroller (TFLM), which is a machine learning (ML) inference framework for running deep-learning models on embedded systems. Bfloat16 has a narrow mantissa from the single-precision floating-point (float32) format; thus, reducing the hardware complexity and maintaining the accuracy of the DNN computation. This paper explains the advantage of bfloat16 in DNNs application and represents the bfloat16 simulation system by adding bfloat16 custom instructions to the simulator and defining them in GCC. Our results show that in 96.4% cases, the output difference of the CNN model calculated by using the bfloat16 computation is less than 1% when comparing the float32 one."
이동체에서 2D 선레이저를 이용한 보도블럭 프로파일링 및 균열 검출 기법,2021,"['2D laser profiling', 'Crack detection', 'Pavement blocks monitoring', 'Pavement blocks profile']",국문 초록 정보 없음,"In this paper, we propose an on-line mechanism that simultaneously detects cracks and profiling pavement blocks to detect the displacement of ground surface adjacent to the excavation in the urban area. The proposed method utilizes a 2D laser to profile the information about pavement blocks including the depth and distance among them. In particular, it is designed to enable the detection of cracks and portholes at runtime. For the experiment, real data was collected through Gocator, and trainng was carried out using Faster R-CNN. The performance evaluation shows that our detection precision and recall are more than 90% and the pavement blocks are profiled at the same time. Our proposed mechanism can be used for monitoring management to quantitatively detect the level of excavation risk before a large-scale ground collapse occurs."
자동화된 용종 분할을 위한 트랜스포머 기반의 네트워크,2021,"['Transformer', 'Image Segmentation', 'Polyp Segmentation']",국문 초록 정보 없음,"In recent years, UNet architecture has shown to be a standard network for medical image segmentation. However, it suffers from some severe limitations. It loses localization ability for low-level details followed by the inability of long-range dependencies. Motivated by this, we explore transformer-based architectures that exploit global context by modeling long-range spatial dependencies, which are essential for accurate polyp segmentation. In this paper, we propose an attention-based transformer encoded UNet model. This hybrid model inherits both characteristics of CNN block as well as attention block. We perform various experiments in existing architectures like UNet, ResUNet, ResUNet-Mod and our proposed method. The proposed method achieved a 0.645 mIOU score took an unassailable lead over prior methods."
인공지능(AI) 기반 치매 조기진단 방법론에 관한 연구,2021,"['인공지능', '딥러닝', '치매', '치매 조기진단', '아밀로이드 플라크', 'AI', 'Deep learning', 'Dementia', 'Early diagnosis of dementia', 'Amyloid-plaques']",국문 초록 정보 없음,"The number of dementia patients in Korea is estimated to be over 800,000, and the severity of dementia is becoming a social problem. However, no treatment or drug has yet been developed to cure dementia worldwide. The number of dementia patients is expected to increase further due to the rapid aging of the population. Currently, early detection of dementia and delaying the course of dementia symptoms is the best alternative. This study presented a methodology for early diagnosis of dementia by measuring and analyzing amyloid plaques. This vital protein can most clearly and early diagnose dementia in the retina through AI-based image analysis. We performed binary classification and multi-classification learning based on CNN on retina data. We also developed a deep learning algorithm that can diagnose dementia early based on pre-processed retinal data. Accuracy and recall of the deep learning model were verified, and as a result of the verification, and derived results that satisfy both recall and accuracy. In the future, we plan to continue the study based on clinical data of actual dementia patients, and the results of this study are expected to solve the dementia problem."
AI 개발을 위한 노 코드 플랫폼의 개발 방향,2021,[],"4차 산업혁명이 시작된 이래로 다양한 산업 분야에서 AI가 활용되고 있고, 그 중에서도 컴퓨터 비전 분야에서 딥러닝 기술이 각광받고 있다. 하지만 딥러닝 기술은 높은 전문 지식이 요구되어 관련 지식이 없는 일반인들은 활용하기 어렵다. 본 논문에서는 AI 관련 배경지식이 없는 사용자들도 UI를 통해 쉽게 이미지 분류 모델을 학습시킬 수 있는 노 코드 플랫폼에 관하여 기술하고, django 프레임워크를 이용해 웹 개발과 딥러닝 모델 학습을 통합 개발을 위한 아키텍처와 방향성을 제시하고자 한다. 사용자가 웹서버에 업로드한 이미지들을 웹 인터페이스를 통해 라벨링 하여 학습 데이터를 생성한 후, 이 데이터를 사용하여 모델을 학습시킨다. CNN 모델에 데이터를 학습시키는 과정과 생성된 모델 기반으로 이미지 예측하는 모듈을 통해 전문지식이 없는 사용자가 딥러닝 기술에 대해 쉽게 이해하고 이용하는 것을 기대할 수 있다.",다국어 초록 정보 없음
Delineation of ischemic lesion from brain MRI using attention gated fully convolutional network,2021,"['Deep neural network', 'FCN', 'Attention', 'Ischemic lesion segmentation', 'MRI']",국문 초록 정보 없음,"Precise delineation of the ischemic lesion from unimodal Magnetic Resonance Imaging (MRI) is a challenging task due tothe subtle intensity difference between the lesion and normal tissues. Hence, multispectral MRI modalities are used for characterizingthe properties of brain tissues. Traditional lesion detection methods rely on extracting significant hand-engineeredfeatures to differentiate normal and abnormal brain tissues. But the identification of those discriminating features is quitecomplex, as the degree of differentiation varies according to each modality. This can be addressed well by ConvolutionalNeural Networks (CNN) which supports automatic feature extraction. It is capable of learning the global features from imageseffectively for image classification. But it loses the context of local information among the pixels that need to be retained forsegmentation. Also, it must provide more emphasis on the features of the lesion region for precise reconstruction. The majorcontribution of this work is the integration of attention mechanism with a Fully Convolutional Network (FCN) to segmentischemic lesion. This attention model is applied to learn and concentrate only on salient features of the lesion region bysuppressing the details of other regions. Hence the proposed FCN with attention mechanism was able to segment ischemiclesion of varying size and shape. To study the effectiveness of attention mechanism, various experiments were carried outon ISLES 2015 dataset and a mean dice coefficient of 0.7535 was obtained. Experimental results indicate that there is animprovement of 5% compared to the existing works."
컨볼루션 신경망 모델을 이용한 분류에서 입력 영상의 종류가 정확도에 미치는 영향,2021,"['X-ray', 'Convolutional neural network', 'Classification', 'Deep learning']",국문 초록 정보 없음,"The purpose of this study is to classify TIFF images, PNG images, and JPEG images using deep learning, and to compare the accuracy by verifying the classification performance. The TIFF, PNG, and JPEG images converted from chest X-ray DICOM images were applied to five deep neural network models performed in image recognition and classification to compare classification performance. The data consisted of a total of 4,000 X-ray images, which were converted from DICOM images into 16-bit TIFF images and 8-bit PNG and JPEG images. The learning models are CNN models - VGG16, ResNet50, InceptionV3, DenseNet121, and EfficientNetB0. The accuracy of the five convolutional neural network models of TIFF images is 99.86%, 99.86%, 99.99%, 100%, and 99.89%. The accuracy of PNG images is 99.88%, 100%, 99.97%, 99.87%, and 100%. The accuracy of JPEG images is 100%, 100%, 99.96%, 99.89%, and 100%. Validation of classification performance using test data showed 100% in accuracy, precision, recall and F1 score. Our classification results show that when DICOM images are converted to TIFF, PNG, and JPEG images and learned through preprocessing, the learning works well in all formats. In medical imaging research using deep learning, the classification performance is not affected by converting DICOM images into any format."
교통사고 분석 및 예측을 위한 AI모델 개발,2021,[],"본 연구는 1) 운수회사 위험운전 분석과 2) 도심 내 교통사고 예측을 목표로 한다. 먼저, 운수회사 위험운전 분석에는 데이터 큐브 모델링을 활용한 다차원 분석을 활용하며, 운수회사에 등록단 차량의 위험행동 정보, 법규위반정보, 업체규모 등의 정보를 활용하여 데이터 큐브를 구성하고, 분석을 수행한다. 도심 내 교통사고 예측부 에서는 상업용차량 및 프로브차량의 DTG 정보 및 도로기하구조정보를 활용하여 교통사고 예측, 심각도 추정, 원인 분석의 일련의 과정을 수핸한다. 먼저, DTG로부터 획득한 위험운전 정보 및 교통사고 이력정보를 활용하여, 격자단위의 예측 모델을 구성한다. 도심 교통사고의 예측을 위해 합성곱 신경망(Convolutional Neural Network, CNN) 모델을 활용하였으며, 일차적으로 교통사고의 유무를 예측한 후 이를 기반으로 계층적 깊은 신경망 (Hierarchical Deep Neural Network, DNN)을 활용하여 교통사고의 위험심각도를 예측하였다. 마지막으로, 교통사고 요인 파악을 위하여 해당 cell의 도로기하구조등의 정보를 활용한 의사결정트리를 바탕으로 정성적인 원인 분석을 수행하였다.",다국어 초록 정보 없음
Android Malware Detection System using Deep Learning and Code Item,2021,"['Android malware detection', 'Code item', 'Convolutional neural network', 'Grayscale image', 'Static analysis']",국문 초록 정보 없음,"This paper proposes an Android malware detection method that reduces the overhead of 2-dimensional image generation from Android packages (APK) to build deep learning models that effectively discern whether an application is malware. Other image-based malware detection methods typically use the whole Android application executable file (DEX file) or a large section that often contains redundant information. However, our technique generates grayscale images using minimal representative data from the code item section. Two-dimensional images are utilized by a state-of-the-art feature extractor and spatial pattern recognition technique with a convolutional neural networks (CNN) architecture for image classification. Positive results were obtained for the execution time and memory usage compared to other methods. The code item section binaries contain relevant information about an Android application."
현대자동차 자율주행 챌린지: 실차 자율주행을 위한 CarMaker 시뮬레이터 기반 자율주행시스템 연구,2021,"['자율주행시스템(Autonomous Driving System)', '물체인식(Object Detection)', '행동판단(Behavior Decision)', '경로계획(Path Planning)', '차량제어(Vehicle Dontrol)', '위치인식(Localization)']","현대자동차 자율주행 경진대회 준비를 위한 CarMaker 시뮬레이션 기반 자율주행 시스템을 연구하였다. 대회는 실차 기반의 자율주행 환경과 유사하게 구축된 CarMaker 시뮬레이션 환경에서 참가팀이 개발한 소프트웨어 알고리즘을 이용하여 각종 미션을 통과한 후 결승점에 도착하는 것을 목표로 한다. 자율주행시스템 구축을 위해 CarMaker 시뮬레이션에 실제 환경과 유사한 LiDAR, Camera, GPS 및 IMU 센서를 설계된 위치에 장착하고 시스템 구성을 위한 데이터를 수신한다. 제안된 자율주행시스템은 위치인식, 장애물인식, 경로계획, 차량제어, 장애물위치예측, 행동판단 파트로 나누어 구성된다. 위치인식은 LiDAR를 활용한 SLAM(Simultaneous Localization and Mapping) 기법을 활용하였다. 장애물인식은 LiDAR를 활용하여 룰 베이스 기반의 알고리즘과, CNN(Convolutional Neural Network) 기반의 SegLiDAR 알고리즘을 응용하여 활용하였다. 경로계획은 정밀지도 기반의 다익스트라 알고리즘을 통해 전역 경로를 설계하고, 전역 경로 내에서 장애물이 고려된 실시간 경로 생성을 위해 Hybrid A*와 인공전위 장을 활용하여 지역 경로를 설계하였다. 종 방향 제어는 PID 제어기를 활용하였고, 횡 방향 제어기는 Pure Pursuit를 활용하여 시스템을 구성하였다. 장애물위치예측은 장애물인식의 결과 데이터인 장애물의 방향과 속도 데이터를 활용하여 미래 위치를 예측하였다. 행동 판단은 외부 이벤트에 의한 감속, 가속, 정차 및 정차 후 재출발에 관한 종방향 감가속 판단과 전역 경로와 지역 경로에 대해 최선의 경로를 추종하는 경로 선택 판단으로 이루어진다. 제안된 자율주행시스템을 활용하여 현대자동차 자율주행 경진대회의 시뮬레이션 예선 대회에 통과하여 본선에 진출하는 성과를 거두었고, 실차 기반 대회를 위해 추가적인 연구를 진행하고 있다.",다국어 초록 정보 없음
딥러닝을 이용한 육불화텅스텐(WF6) 제조 공정의 지능형 영상 감지 시스템 구현,2021,"['object detection', 'you only look once (YOLO)', 'tungsten hexafluoride (WF6)', 'reduction', 'defect detection.']",국문 초록 정보 없음,"Through the process of chemical vapor deposition, Tungsten Hexafluoride (WF6) is widely used by the semiconductor industry to form tungsten films. Tungsten Hexafluoride (WF6) is produced through manufacturing processes such as pulverization, wet smelting, calcination and reduction of tungsten ores. The manufacturing process of Tungsten Hexafluoride (WF6) is required thorough quality control to improve productivity. In this paper, a real-time detection system for oxidation defects that occur in the manufacturing process of Tungsten Hexafluoride (WF6) is proposed. The proposed system is implemented by applying YOLOv5 based on Convolutional Neural Network (CNN); it is expected to enable more stable management than existing management, which relies on skilled workers. The implementation method of the proposed system and the results of performance comparison are presented to prove the feasibility of the method for improving the efficiency of the WF6 manufacturing process in this paper. The proposed system applying YOLOv5s, which is the most suitable material in the actual production environment, demonstrates high accuracy (mAP@0.5 99.4 %) and real-time detection speed (FPS 46)."
딥러닝 기반 집-나무-사람 검사 분석 모델의 개발,2021,[],"심리학에서 사람의 심리 상태를 알아보기 위해 사용되는 검사 방법 중, 집-나무-사람 검사(HTP Test)는 피실험자가 그린 집, 나무, 사람을 포함하는 그림을 사용하여 피실험자의 심리를 분석하는 투영 검사법이다. 본 논문에서는 딥러닝 모델을 이용해 HTP Test 에 사용되는 그림을 분석하는 시스템을 제안하며, 성능 평가를 통해 심리학에서의 딥러닝 모델 적용 가능성을 확인한다. 또한 그림 데이터 분석에 적합한 사전 훈련 모델을 개발하기 위해, ImageNet 과 스케치 데이터셋으로 사전 훈련하여 성능을 비교한다. 본 논문에서 제안하는 시스템은 크게 감정 분석을 위한 이미지 객체 추출부, 추출된 객체로 피실험자의 감정을 분류하는 감정 분류부로 구성되어 있다. 객체 추출과 이미지 분류 모두 CNN(Convolution Neural Network) 기반의 딥러닝 모델을 사용하며, 이미지 분류 모델은 서로 다른 데이터셋으로 모델을 사전 훈련한 후, 훈련 데이터셋으로 전이 학습하여 모델의 성능을 비교한다. 그림 심리 분석을 위한 HTP test 스케치 데이터셋은, HTP Test 와 동일하게 피실험자가 3 개 클래스의 집, 나무, 사람의 그림을 그려 자체 수집하였다.",다국어 초록 정보 없음
Gated Recurrent Unit-based UWB System Localization,2021,[],국문 초록 정보 없음,"In this paper, we propose a novel three-dimensional (3D) localization method that utilizes the ultra-wideband (UWB) technology and gated recurrent unit (GRU)-based deep learning model. The GRU-based model is developed to estimate the 3D location of a device that transmits UWB signal to many different receiver antennas inside an indoor environment. The position of the device is directly estimated from an input matrix generated from the received signals recorded in all the receivers. The simulation results show that the proposed method outperforms the previous time-of-arrival (ToA) method and the convolutional neural network (CNN)-based methods."
CAE 알고리즘을 이용한 레이더 강우 보정 평가,2021,[],국문 초록 정보 없음,"As the frequency of localized heavy rainfall has increased during recent years, the importance of high-resolution radar data has also increased. This study aims to correct the bias of Dual Polarization radar that still has a spatial and temporal bias. In many studies, various statistical techniques have been attempted to correct the bias of radar rainfall. In this study, the bias correction of the S-band Dual Polarization radar used in flood forecasting of ME was implemented by a Convolutional Autoencoder (CAE) algorithm, which is a type of Convolutional Neural Network (CNN). The CAE model was trained based on radar data sets that have a 10-min temporal resolution for the July 2017 flood event in Cheongju. The results showed that the newly developed CAE model provided improved simulation results in time and space by reducing the bias of raw radar rainfall. Therefore, the CAE model, which learns the spatial relationship between each adjacent grid, can be used for real-time updates of grid-based climate data generated by radar and satellites."
Machine learning based Human Activity Recognition with mobile 3-axis magnetometers,2021,[],국문 초록 정보 없음,"Recently, human activity recognition (HAR) plays an important role in well-being life and context-aware IoT systems. HAR can be carried out in real-time by using sensory data collected from embedded sensor networks in mobile smart phones. Recent HAR investigations have shown that is solely based on 3-axis accelerometers, which is the most energy-efficient approach. In this presentation, I propose a simple approach for HAR process with built-in 3-axis magnetometers in a smart phone. Based on deep learning with convolutional neural network(CNN), I found 98% accuracy for 4 -classes (standing, sitting, jogging, and walking)."
EMG Classification 기반의 로봇의수 제어와 착용형 햅틱 디바이스 기반의 자기수용감각 피드백의 폐루프 통합시스템,2021,"['EMG classification', 'proprioceptive feedback', 'sensory feedback device', 'haptic feedback', 'wearable feedback device']",국문 초록 정보 없음,"Many currently robotic prosthetic hands are controlled based on electromyography (EMG) signals, and amputees use their visual feedback to recognize robotic prosthetic hand movements. However, controlling robotic prosthetic hand without vision makes high cognitive loads and is inaccurate. To solve the limitations, we propose a wearable haptic device for proprioceptive feedback with high DOF and introduce a rule-based feedback method. Also, through various experiments, the recognition accuracy of the wearable haptic device for proprioceptive feedback was evaluated on 10 types of grips. And, to recognize the user's intentions, a CNN model for EMG classification was learned with 6 channel EMG signals. Finally, a closed-loop integrated system is constructed using the proposed wearable haptic device, the robotic prosthetic hand, and the EMG classification. We also evaluate the overall performance of the proposed integrated system through experiments on users."
딥블록: 웹 기반 딥러닝 교육용 플랫폼,2021,"['Artificial Intelligence', 'Block Coding', 'Cloud Service', 'Deep Learning', 'Education Platform']",국문 초록 정보 없음,"Recently, researches and projects of companies based on artificial intelligence have been actively carried out. Various services and systems are being grafted with artificial intelligence technology. They become more intelligent. Accordingly, interest in deep learning, one of the techniques of artificial intelligence, and people who want to learn it have increased. In order to learn deep learning, deep learning theory with a lot of knowledge such as computer programming and mathematics is required. That is a high barrier to entry to beginners. Therefore, in this study, we designed and implemented a web-based deep learning platform called DeepBlock, which enables beginners to implement basic models of deep learning such as DNN and CNN without considering programming and mathematics. The proposed DeepBlock can be used for the education of students or beginners interested in deep learning."
오이 수확로봇의 꼭지 인식을 위한 U-Net 기반의 차폐 영역 복원 기술 개발,2021,"['오이', '스마트팜', '딥러닝', '영상복원']","최근 인공지능 및 계측, 제어 기술의 발달과 함께 스마트팜에서의 수확로봇 개발 연구가 활발히 진행되고 있다. 수확로봇의 작업 정확도와 효율성 확보를 위해서는 빠르고 정확한 과실 인식 기술이 필수적이고, 과실이 잎에 가려진 경우에도 수확을 위한 절단 부위를 잘 인식할 수 있어야 한다. 특히 오이의 경우, 과실이 잎에 가려진 경우가 많아 기존의 오이 과실 인식 기술만으로는 절단 부위 인식에 한계가 있다. 따라서 오이 영상으로부터 꼭지 주위의 차폐 영역을 복원하는 기술을 통한 꼭지 위치 파악이 필요하다. 이를 위해 본 연구에서는 영상 분할 (segmentation)에 주로 이용되는 합성곱신경망 (CNN)의 일종인 U-Net과 U-Net++ 아키텍처를 활용하여 RGB 오이 이미지에서 꼭지 주위의 차폐 영역 복원 기술을 개발하였고, 모델의 인코더로 다양한 특징추출기 (feature extractor)를 활용한 후 복원 정확도를 비교, 평가 하였다.",다국어 초록 정보 없음
인터뷰 형식의 오디오 데이터를 이용한 전이 학습모델 기반 우울증 진단,2021,"['AI technology', 'Depression diagnosis', 'Transfer Learning', 'Interview-type audio data', 'two-dimensional images']",국문 초록 정보 없음,"Depression can lead to serious mental and physical illness, so early detection is important. Currently, a system to help early detection of depression using AI technology is being developed in various ways. In particular, research on diagnosing depression through voices that can be easily encountered in daily life is being actively conducted. In this paper, we compare and analyze the depression diagnosis performance of transfer learning models using interview-type audio data. Data use the DAIC-WOZ Depression Database, which contains audio files in interview-type. As the transfer learning model, it uses VGGish and YAMNet built based on Convolutional Neural Network(CNN) among deep learning models that are widely being used for audio classification. The characteristics of speech data are extracted to black-and-white and color two-dimensional images using the Bark spectrogram, Mel spectrogram, and Log Mel-spectrogram methods. The performance of the depression diagnosis model is higher in YAMNet than in VGGish. In case that black-and-white images are input, YAMNet’s performance was the highest with 94.48% when mel spectrogram features were used.On the other hand, in case that color images are input, YAMNet’s performance was the highest at 97.34% when bark spectrogram features were used proving that it is most suitable for diagnosing depression."
공사현장 자재관리 자동화를 위한 영상기반 인공지능 모델개발,2021,"['인공지능', '컴퓨터 비전', '이미지 처리', '객체 분할', '건설시공', 'artificial intelligence', 'computer vision', 'image processing', 'instance segmentation', 'construction work']",국문 초록 정보 없음,"Conventionally, in material management at a construction site, the type, size, and quantity of materials are identified by the eyes of the worker. Labor-intensive material management by manpower is slow, requires a lot of manpower, is prone to errors, and has limitations in that computerization of information on the identified types and quantities is additionally required. Therefore, a method that can quickly and accurately determine the type, size, and quantity of materials with a minimum number of workers is required to reduce labor costs at the construction site and improve work efficiency. In this study, we developed an automated convolution neural network(CNN) and computer vision technology-based rebar size and quantity estimation system that can quickly and accurately determine the type, size, and quantity of materials through images."
Quality control of seismic data based on convolutional neural network,2021,"['파워스펙트럼밀도', '품질관리', '심층학습', '합성곱 신경망', 'power spectral density', 'quality control', 'deep learning', 'convolutional neural network']",국문 초록 정보 없음,"Installing more seismic stations may result in improving the capability of earthquake monitoring and shortening the time to report the occurrence of earthquakes or deliver public earthquake warnings. However, accordingly, it becomes difficult to assess the condition of seismic instrument. The goal of this study is to develop an automated method for assessing the quality of seismic data, which is based on power spectral densities (PSD) of one-hour waveform data. We collected 10,309 PSDs of broadband seismometers and 4,452 PSDs of accelerometers recorded from 2016, 2017 and 2019, and used them as the input of the convolutional neural network (CNN), a class of deep learning. Two deep CNNs for broadband seismometer and accelerometer were trained to automatically determine the condition of seismic data: normal and abnormal conditions. We find that the condition of seismic data determined by the CNNs have an accuracy of 99.9% and they can successfully determine the condition from PSDs of 15-minute waveforms. The outstanding performance of the trained models indicates that this can be a very effective tool for assessing the condition of seismic instrument."
Deep Learning 기술을 이용한 DDI 반도체 불량 검출 성능 분석,2021,"['Deep learning', 'Bump defect', 'DDI defect', 'Machine vision system', 'Vision defect']","최근 Deep Learning 을 비롯한 인공지능 기술의 활용이 다양한 분야에서 활발해지고 있으며 Machine Vision System을 이용한 불량 검사에서도 불량 검출을 위한 수요가 증가하고 있다. 본 논문에서는 DDI (Display Driver IC) 반도체 공정에서 Deep Learning 을 이용하여 자동 분류 및 불량 검출을 위한 Algorithm을 개발하였다. Machine Vision Algorithm 처리 시 발생하는 Over Kill 에 대하여 Deep Learning Algorithm 을 적용함으로써 검사 변수에 의해 발생한 Over Kill Rate 를 줄이는 것이 목적이다. DDI 상의 범프 결함을 자동 검출하기 위하여 Machine Vision System 을 이용하여 범프 결함을 종류별로 분류하였으며, 분류된 데이터를 학습 데이터로 적용하여 데이터를 별도로 분류하지 않도록 작업을 최소화하였다. 검출 성능 향상을 위해 영상 검출에 높은 성능을 보이는 CNN (Convolutional Neural Network) Algorithm 을 적용하였으며, 그 중 가변적인 Resolution 변화에 적합한 Keras Algorithm 을 기본으로 사용하였다. SGD, ADAM Optimizer를 가장 효과적인 방법으로 사용하기 위해 서로를 복합적으로 적용함으로써 Machine Vision System 만을 사용하였을 경우와 비교하여 Over Kill 에 대한 검출 능력이 약 95% 향상됨을 확인하였다. 약 4,000 장의 데이터를 학습하였으며, 1,000 개의 시험 데이터를 이용하여 검증하였다.",다국어 초록 정보 없음
딥러닝 기반 손 그림 심리분석 알고리즘 연구,2021,"['그림 심리 검사', '객체 분류', '딥러닝', '객체 검출', '계층적 구조', 'Art Therapy', 'Classification', 'Deep learning', 'Object detection', 'Hierarchical structure']",국문 초록 정보 없음,"From simple scribbles of children to paintings by world-class artists, human psychology is melted into drawings. They express the concept, experience, desire, and attitude to the environment they have acquired, and can identify the persons tendency and personalities. This can be used as a medium for psychotherapy, called art therapy. We devise an efficient scheme to analyze the hand drawings based on a hierarchical structure, which allows us to produce certain results. First, we extract some separated parts which is consisted of whole objects by object detection. With the extracted parts, we perform the classification task based on 2D CNN to define key attribute. For the given image, the analyzed report is constructed based on the key attributes. The proposed algorithm is applied to tree test and cat test among many drawing psychological tests, and achieves an analysis accuracy of about 93% and 96%, respectively."
Grad-CAM(Gradient-Class Activation Map)을 이용한 웨이퍼 빈 맵 복합 불량 패턴 분해,2021,"['Explainable Intelligence Artificial', 'Gradient-Class Activation Map', 'Convolutional Neural Network', 'Wafer bin map', 'Mixed defect pattern']","반도체 제조 공정에서 하나의 반도체 칩은 매우 정교하고 복잡한 공정 과정을 통해 완성된다. 만들어진 칩은 제품의 성능을 보장하기 위해 EDS(Electrical Die Sorting)테스트를 수행하고, 칩의 정상과 불량 여부를 판단하여 표시하는데 이것이 웨이퍼 빈 맵(WBM, Wafer Bin Map)이다. 웨이퍼 빈 맵에 표시된 불량 패턴은 반도체 제조 공정, 설계상 불량의 원인에 대한 중요한 단서가 되므로 패턴의 정확한 감지와 지속적인 추적이 요구된다. 때문에 불량 패턴 감지 및 분류를 위해 기계학습을 이용한 여러 방법이 제안되었고, 최근에는 컴퓨팅 성능의 발달로 합성곱 신경망(CNN, Convolutional Neural Network)과 같은 복잡한 구조의 딥러닝 알고리즘을 통해 불량 패턴을 감지하고자 하는 노력이 지속되고 있다. 하지만 위와 같은 블랙박스(Black box) 형태의 알고리즘의 경우 불량의 발생 여부나 종류만 알 수 있고 불량의 크기나 위치 등 불량에 대한 추가 정보에 대해서는 제공하지 못한다. 특히, 불량 패턴이 한 웨이퍼에 복합적으로 발생하는 불량 패턴의 경우, 혼재되어 있는 불량 패턴을 파악하는 것은 더욱 어렵다. 본 논문에서는 현장 작업자에게 복합 불량 패턴의 크기, 위치와 같은 공간적 정보를 제공하기 위하여 단순 불량 패턴 이미지를 학습시킨 합성곱 신경망 분류기를 기반으로 설명 가능한 인공지능(XAI, Explainable Intelligence Artificial) 모델인 Grad-CAM(Gradient-Class Activation Map)을 이용하여 복합 불량 패턴의 위치와 영역 정보를 추출하고 이를 기반으로 복합 불량 패턴 분해 프로세스를 제안한다.",다국어 초록 정보 없음
성인 학습자의 학습 추이 분석을 위한 인공지능 기반 알고리즘 모델 개발 및 평가,2021,[],국문 초록 정보 없음,"To improve educational performance by analyzing the learning trends of adult learners of Open High Schools, various algorithm models using artificial intelligence were designed and performance was evaluated by applying them to real data. We analyzed Log data of 115 adult learners in the cyber education system of Open High Schools. Most adult learners of Open High Schools learned more than recommended learning time, but at the end of the semester, the actual learning time was significantly reduced compared to the recommended learning time. In the second half of learning, the participation rate of VODs, formation assessments, and learning activities also decreased. Therefore, in order to improve educational performance, learning time should be supported to continue in the second half. In the latter half, we developed an artificial intelligence algorithm models using Tensorflow to predict learning time by data they started taking the course. As a result, when using CNN(Convolutional Neural Network) model to predict single or multiple outputs, the mean-absolute-error is lowest compared to other models."
표준 OBD 주행데이터를 이용한 내연기관 차량의 연료 사용량 예측,2021,"['Machine Learning(머신러닝)', 'Big Data(빅데이터)', 'OBD-Ⅱ(온보드진단기)', 'Fuel Consumption(연료소비율)', 'CO₂(이산화탄소', '온실가스)', 'GPS(위성항법시스템)']","2016 년 3월 구글의 AI 바둑프로그램인 알파고가 한국의 이세돌 9단에게 승리한 이후 다양한 분야에서 인공지능 및 머신러닝에 대한 관심이 높아지고 있다. 자동차 분야 또한 인공지능 및 머신러닝을 적용하기 위해 많은 연구들이 진행되고 있다. 특히 인공지능 및 머신러닝 적용을 위해서는 방대한 양의 데이터 세트(Dataset)가 필요하다. 현대자동차와 같은 기업의 경우 자사의 특화된 프로그램(예: 블루링크)의 커넥티드 기능을 이용해 운전자의 운행패턴 및 속도, RPM등 중요 엔진데이터를 빅데이터화 하고 있지만 일반 연구자들은 자동차의 데이터에 접근하기도 쉽지 않다. 다만 차량의 엔진관련 정보에 접근 할 수 있는 방법이 하나 있는데 1970년 미국환경보호국(EPA)이 차량의 법적인 규정을 감시하기 위해 미국자동차공업협회(SAE)에서 제정한 표준OBD를 모든 차에 탑재하도록 한 것이다. 한국도 2005년 이후 국내에서 판매되는 모든 승용차에 OBD-Ⅱ 시스템의 장착을 의무화하고 있다. 본 연구에서는 표준 OBD-Ⅱ 데이터 중 차량의 속도, 엔진의 회전 속도(RPM), Fuel level, 전압, 연료/공기비, 스로틀 포지션, 매니폴드 압력을 매일 측정 하였고, 그날의 날씨, 교통량을 입력하여 빅데이터를 제작하였다. 이 빅데이터에 머신러닝을 적용하여 대표적인 온실가스인 CO<sub>2</sub> 와 연관 있는 연료소비율 예측 연구를 진행 하였다. 10hz 측정이 가능한 XGPS 160모델을 사용하여 시험 도로의 위도, 경도, 고도를 측정 하였고, OBD-Ⅱ스캐너는 ELM327을 사용하였다. 향후 연구에서는 딥러닝(CNN, RNN, Decision Tree, SVM)을 적용하여 더욱 높은 정확도를 가지고 다양한 친환경자동차의 연비 예측 모형을 모델링하고자 한다.",다국어 초록 정보 없음
Diabetic Retinopathy Diagnosis Based on Deep Learning and Independent Subspace Analysis,2021,"['당뇨성 망막변증 진단', '딥러닝', '독립 부분 공간 분석', '전이 학습', '자기 지도 학습', 'Diabetic Retinopathy Diagnosis', 'Deep Learning', 'Independent Subspace Analysis', 'Transfer Learning', 'Self-supervised Learning']","당뇨성 망막변증 진단 시스템을 개발하기 위해서 안저 영상과 인공지능 기법을 사용하는 것은 산업계에서 유망한 분야중의 하나이다. 당뇨성 망막변증의 검출은 영상의 색깔, 해상도, 밝기의 큰 변동과 클래스간의 불균형 분포를 갖는 데이터, 영상내의 병변이 아주 작아서 힘든 작업이다. 이 논문의 목적은 당뇨성 망막변증의 검출을 위한 더 좋은 방법을 찾는 것이다. 합성곱 신경회로망에 기반한 딥러닝과 독립 부분 공간 알고리즘을 표현을 학습하고 안저 데이터로부터 특징들을 추출하기 위해서 구현하였다. 이렇게 추출된 특징들은 당뇨성 망막변증을 검출하기 위해 분류기에 입력된다. 감독학습을 사용하여 당뇨성 망막변증을 검출하는데 최상의 결과를 얻었다.","Using fundus images and artificial intelligence(AI) technology to develop a Diabetic Retinopathy(DR) diagnostic system has been one of the hot research topics in the industry. DR detection is a challenging task due to tiny lesions in the images, inter-class imbalanced data distribution, and a huge variation in the brightness, resolution, and color of images. The aim of this paper is to explore better ways for DR detection. Convolutional neural network(CNN) based deep learning and independent subspace analysis(ISA) algorithm are implemented to learn representation and extract features from fundus data. Then these extracted features go through a classification to detect DR. We achieved the best result of DR detection performed using supervised learning."
Predicting wind-induced structural response with LSTM in transmission tower-line system,2021,"['dynamic response', 'nonlinear structure', 'LSTM', 'RNN', 'wind engineering']",국문 초록 정보 없음,"Wind-induced dynamic response of the nonlinear structure is critical for the structural safety and reliability. The traditional approaches for this response including observation or simulation focus on the structural health monitoring, the experiment, or finite element model development. However, all these approaches require high cost or computational investment. This paper proposes to predict the wind-induced dynamic response of the nonlinear structure with a novel deep learning approach, LSTM, and applies this in a structural lifeline system, the transmission tower-line system. By constructing the optimized LSTM architectures, the proposed method applies to both the linear structure, the single transmission tower and the nonlinear structure, the transmission tower-line system, with promising results for the dynamic and extreme response prediction. It can conclude that the layers and the hidden units have a strong impact on the LSTM prediction performance, and with proper training data set, the computational time can significantly decrease. A comparison surrogate model developed by CNN is also utilized to demonstrate the robustness of the LSTM-based surrogate model with limited data scale."
GNSS-based auroral oval boundary movements prediction using machine learning,2021,"['frame prediction architecture', 'computer vision', 'machine learning', 'operations research']",국문 초록 정보 없음,"The ionosphere is the part of the Earth's atmosphere with a high concentration of free electrons and ions. The ionosphere is characterised by its variability and inhomogeneity. One of the characteristic inhomogeneities is the so-called auroral oval, which determines the range of auroral radiance. Detection of the auroral oval is an important task for forecasting auroral storms, as they affect long-range communication systems, navigation, satellite-to-ground communications, making communications complicated or impossible. Therefore, an auroral oval detection and prediction needs to be performed in order to be informed about the area of their possible influence at certain time intervals. On the basis of the available image dataset from SIMuRG, which is based on GNSS data, it is proposed to use the LSTM model and CNN architecture. The paper reviews existing implementations and proposes a method for predicting auroral oval movements in the images, using the Convolutional LSTM architecture, which combines time series processing and computer vision. The work results in a machine learning model that can make the predictions based on even small sets of data."
Defect Detection of Laser Drilling Micro Holes Using Photodiode Sensor and Autoencoders,2021,"['Laser micro-drilling', 'Defect detection', 'anomaly detection', 'Micro-drilling defect', 'Autoencoder']",국문 초록 정보 없음,"Laser micro drilling is a manufacturing method commonly used to drill holes of microscopic diameters into metals. The size and quantity of holes drilled pose a challenge in accurate, thorough, and time-efficient quality control. We observed an abnormal amount of visible light scattered when the laser failed to drill through the material and created a defective hole. Using this observation, we hypothesized there would be a difference in the pattern of light around the work area during successful and defective drilling. In this paper we propose the usage of a photodiode sensor and autoencoders for in-situ progress monitoring and defect detection of laser micro drilling. We generated simulation data of the expected power over time prior to the data collection and trained CNN and LSTM autoencoders as a proof of concept. The photodiode sensor was installed at an angle to the 1064 nm Nd:YAG Laser to collect scattered, reflected and emitted light. Data collected showed high similarity to the general pattern of simulated data."
A Lightweight Deep Learning Model for Early Fire Detection using UAV Imagery,2021,"['Fire detection', 'Deep learning', 'Unmanned aerial vehicle']",국문 초록 정보 없음,"Fire is an extremely catastrophic disaster that leads to the destruction of forests, human assets, reduced soil fertility, land resources, and the cause of global warming. In the current decade, fire detection and its management are the major concern of several researchers to prevent social, ecological, and economic damages. To overcome such kind of losses, early fire detection, and the automatic response is very significant. Moreover, achieving high accuracy with reducing inference time and model size is also challenging for the Unmanned Aerial Vehicle (UAVs). Therefore, in this work, we enabled the VGG16 architecture for UAV in terms of reducing its learning parameters from 138 million to 11.4 million for early fire detection. The proposed system is inexpensive in terms of computation and size. The performance of our proposed work is evaluated over the custom dataset. We performed comprehensive experiments using various deep learning architectures such as VGG16, ResNet50, and the proposed CNN model. The experimental results based on the proposed model achieved an accuracy of 98% on 50 epochs."
Ergonomics Risk Assessment with a Hybrid Neural Network Architecture,2021,"['imbalanced class', 'musculoskeletal disorders', 'risk assessment', 'ergonomics', 'RULA']",국문 초록 정보 없음,"Work-related Musculoskeletal Disorders (WMSDs) are a common concern in the manufacturing industry. It is the main cause of absenteeism, lost working days, and temporary or permanent disability. Safe workplace design and monitoring worker health is essential to avoid the potential threats that have negative impacts on safety and production quality. Ergonomics assessment, such as Rapid Upper Limb Assessment (RULA), can help industries to prevent and evaluate the risk of WMSDs. RULA can be a guide in risk assessment based on the body posture of workers. In this study, we predict the risk level of workers"" posture during the assembly process. As we know, the assembly process usually has process has work steps and each of which has multiple activities. Due to many activities in the assembly process which have different levels of difficulty, we have an issue of imbalanced class distribution that degrades classification accuracy significantly. To the best of our knowledge, no previous work has addressed class imbalances in ergonomics risk assessment. We proposed a hybrid neural network architecture that combines Convolutional Neural Network (CNN) and Bidirectional Long Short-Term Memory (Bi-LSTM) to predict ergonomic risk levels. This study combines oversampling method and focal loss to handle the imbalanced class problem. We evaluate the proposed hybrid neural networks with an assembly process dataset collected from body and finger tracking sensors. Our proposed network achieved 93.48% F1 score, and it outperforms other previous methods."
BM3D and Deep Image Prior based Denoising for the Defense against Adversarial Attacks on Malware Detection Networks,2021,"['Malware detection', 'Deep Learning', 'Adversarial Examples', 'Denoising', 'BM3D', 'Deep Image Prior']",국문 초록 정보 없음,"Recently, Machine Learning-based visualization approaches have been proposed to combat the problem of malware detection. Unfortunately, these techniques are exposed to Adversarial examples. Adversarial examples are noises which can deceive the deep learning based malware detection network such that the malware becomes unrecognizable. To address the shortcomings of these approaches, we present Block-matching and 3D filtering (BM3D) algorithm and deep image prior based denoising technique to defend against adversarial examples on visualization-based malware detection systems. The BM3D based denoising method eliminates most of the adversarial noise. After that the deep image prior based denoising removes the remaining subtle noise. Experimental results on the MS BIG malware dataset and benign samples show that the proposed denoising based defense recovers the performance of the adversarial attacked CNN model for malware detection to some extent."
BM3D and Deep Image Prior based Denoising for the Defense against Adversarial Attacks on Malware Detection Networks,2021,"['Malware detection', 'Deep Learning', 'Adversarial Examples', 'Denoising', 'BM3D', 'Deep Image Prior']",국문 초록 정보 없음,"Recently, Machine Learning-based visualization approaches have been proposed to combat the problem of malware detection. Unfortunately, these techniques are exposed to Adversarial examples. Adversarial examples are noises which can deceive the deep learning based malware detection network such that the malware becomes unrecognizable. To address the shortcomings of these approaches, we present Blockmatching and 3D filtering (BM3D) algorithm and deep image prior based denoising technique to defend against adversarial examples on visualization-based malware detection systems. The BM3D based denoising method eliminates most of the adversarial noise. After that the deep image prior based denoising removes the remaining subtle noise. Experimental results on the MS BIG malware dataset and benign samples show that the proposed denoising based defense recovers the performance of the adversarial attacked CNN model for malware detection to some extent."
Handwriting Thai Digit Recognition Using Convolution Neural Networks,2021,"['Handwriting Thai Digit Recognition', 'Convolution Neural Network', 'Thai Digits Dataset']","필기체 인식 연구는 주로 딥러닝 기술에 초점이 맞춰져 있으며, 최근 몇 년 동안 많은 발전을 이루었다. 특히, 필기체 태국어 숫자 인식은 태국 공식 문서와 영수증과 같은 숫자 정보를 포함한 많은 분야에서 중요한 연구 분야지만, 동시에 도전적인 분야이기도 하다. 대규모 태국어 숫자 데이터 집합의부재를 해결하기 위해, 본 연구는 자체적인 데이터 집합을 구축하고 이를 다양한 컨볼루션 신경망으로 학습시켰다. 정확도 메트릭을 이용하여 평가한 결과, 배치 정규화 기반 VGG 13이 98.29%의 가장 높은 성능을 보였다.","Handwriting recognition research is mainly focused on deep learning techniques and has achieved a great performance in the last few years. Especially, handwritten Thai digit recognition has been an important research area including generic digital numerical information, such as Thai official government documents and receipts. However, it becomes also a challenging task for a long time. For resolving the unavailability of a large Thai digit dataset, this paper constructs our dataset and learns them with some variants of the CNN model; Decision tree, K-nearest neighbors, Alexnet, LaNet-5, and VGG (11,13,16,19). The experimental results using the accuracy metric show the maximum accuracy of 98.29% when using VGG 13 with batch normalization."
교통사고 심각 정도 예측을 위한 TATI 모델 제안,2021,"['TATI', 'Color Representation', 'Severity Prediction', 'Traffic Accident', '컬러 표현', '심각 정도 예측', '교통사고']",국문 초록 정보 없음,"The TATI model is a Traffic Accident Text to RGB Image model, which is a methodology proposed in this paper for predicting the severity of traffic accidents. Traffic fatalities are decreasing every year, but they are among the low in the OECD members. Many studies have been conducted to reduce the death rate of traffic accidents, and among them, studies have been steadily conducted to reduce the incidence and mortality rate by predicting the severity of traffic accidents. In this regard, research has recently been active to predict the severity of traffic accidents by utilizing statistical models and deep learning models. In this paper, traffic accident dataset is converted to color images to predict the severity of traffic accidents, and this is done via CNN models. For performance comparison, we experiment that train the same data and compare the prediction results with the proposed model and other models. Through 10 experiments, we compare the accuracy and error range of four deep learning models. Experimental results show that the accuracy of the proposed model was the highest at 0.85, and the second lowest error range at 0.03 was shown to confirm the superiority of the performance."
빅데이터를 활용한 인공지능 주식 예측 분석,2021,[],국문 초록 정보 없음,"With the advent of the low interest rate era, many investors are flocking to the stock market. In the past stock market, people invested in stocks labor-intensively through company analysis and their own investment techniques. However, in recent years, stock investment using artificial intelligence and data has been widely used. The success rate of stock prediction through artificial intelligence is currently not high, so various artificial intelligence models are trying to increase the stock prediction rate. In this study, we will look at various artificial intelligence models and examine the pros and cons and prediction rates between each model. This study investigated as stock prediction programs using artificial intelligence artificial neural network (ANN), deep learning or hierarchical learning (DNN), k-nearest neighbor algorithm(k-NN), convolutional neural network (CNN), recurrent neural network (RNN), and LSTMs."
Courses Recommendation Algorithm Based On Performance Prediction In E-Learning,2021,"['Algorithm', 'deep learning', 'recommendation system', 'collaborative approach', 'e-learning']",국문 초록 정보 없음,"The effectiveness of recommendation systems depends on the performance of the algorithms with which these systems are designed. The quality of the algorithms themselves depends on the quality of the strategies with which they were designed. These strategies differ from author to author. Thus, designing a good recommendation system means implementing the good strategies. It's in this context that several research works have been proposed on various strategies applied to algorithms to meet the needs of recommendations. Researchers are trying indefinitely to address this objective of seeking the qualities of recommendation algorithms. In this paper, we propose a new algorithm for recommending learning items. Learner performance predictions and collaborative recommendation methods are used as strategies for this algorithm. The proposed performance prediction model is based on convolutional neural networks (CNN). The results of the performance predictions are used by the proposed recommendation algorithm. The results of the predictions obtained show the efficiency of Deep Learning compared to the k-nearest neighbor (k-NN) algorithm. The proposed recommendation algorithm improves the recommendations of the learners' learning items. This algorithm also has the particularity of dissuading learning items in the learner's profile that are deemed inadequate for his or her training."
컨볼루션 신경망 기반 표정인식 스마트 미러,2021,"['Smart Mirror', 'Convolution neural network', 'Edge Computer', 'Facial expression recognition']","본 논문은 여러 인공지능 기술 중 이미지 분류를 통한 사람의 얼굴 표정을 인식하는 프로그램을 통해 사람의 표정을 인식하여 거울에 나타내는 스마트미러 기술을 소개한다. 여러 사람의 5가지 표정이미지를 통하여 인공지능으로 학습하였고, 사람이 거울을 볼 때 거울이 그 표정을 인식하여 인식한 결과를 거울에 나타내는 방식이다. 여러 사람의 얼굴을 표정별로 구분되어있는 dataset을 kaggle에서 제공하는 fer2013을 이용하여 사용하였고, 이미지 데이터 분류를 위해 네트워크 구조는 컨볼루션 신경망 구조를 이용하여 학습하였다. 최종적으로 학습된 모델을 임베디드 보드인 라즈베리파이4를 통해서 얼굴을 인식하여 거울을 통해 디스플레이에 나타내는 구조이다.","This paper introduces a smart mirror technology that recognizes a person’s facial expressions through image classification among several artificial intelligence technologies and presents them in a mirror. 5 types of facial expression images are trained through artificial intelligence. When someone looks at the smart mirror, the mirror recognizes my expression and shows the recognized result in the mirror. The dataset fer2013 provided by kaggle used the faces of several people to be separated by facial expressions. For image classification, the network structure is trained using convolution neural network (CNN). The face is recognized and presented on the screen in the smart mirror with the embedded board such as Raspberry Pi4."
6mA Modification Identification in Rosaceae Genome using SpinalNet Architecture,2021,"['Bioinformatics', 'Biotechnology', 'Neural Networks', 'SpinalNet', 'N6-methyladenine']",국문 초록 정보 없음,"DNA methylation is a crucial epigenetic change that affects a wide range of biological processes, including brain development and function. Accurate classification of N6-methyladenine (6mA) in different genomes is essential to identify the biological processes. While there are a variety of experimental methodologies for classifying 6mA-sites, in silico prediction has emerged as a promising method for reducing the cost and time required by experimental methods. In recent times, various research exercises have been conducted propose effective computational models for the identification of 6mA modifications but still significant space available for the improvement in performance. Using two separate datasets, F.vesca and R.chinensis, this research presents an efficient approach for detecting DNA N6-methyladenine alteration in rosacear species. The architecture combines the traditional CNN with a unique design known as SpinalNet. In comparison to current methodologies, the proposed design proved to be more efficient."
GBNet: Gradient Boosting Network for Monocular Depth Estimation,2021,"['Monocular Depth Estimation', 'Self-Supervised Learning', 'Semi-Supervised Learning']",국문 초록 정보 없음,"Recently, neural networks have shown promising results in estimating depth from a single image. A large amount of per-pixel ground truth depth data is required to train the neural network in supervised learning. However, the dense depth data of ground truth is challenging to collect in realistic dynamic environments. To solve this problem, many researchers propose self- and semi-supervised learning as a credible alternative. This paper proposes a novel self- and semi-supervised monocular depth estimation method, inspired by the gradient boosting method. The existing gradient boosting method provides training to several sequential, additive, and gradual models for minimizing the error. Similarly, we design our proposed network to refine the predicted depth map sequentially and gradually generate a high-quality depth map via multi-stack CNN structures. Our method shows the state-of-the-art results for monocular depth estimation on a DDAD (Dense Depth for Autonomous Driving) dataset."
합성곱 신경망에서 다운 샘플링 메소드 별 모델 성능 비교,2021,"['Convolutional Neural Network', 'Max pooling', 'Average poooling', 'Stride', 'Downsampling']","합성곱 신경망(Convolutional Neural Network)에서 사용되는 대표적인 다운샘플링 (Downsampling) 방법으로는 최대 풀링 (Max pooling), 평균 풀링 (Average pooling)과 같은 방법과 합성곱 신경망의 Stride 값 변화 등이 있다. 그러나, 서로 다른 다운샘플링 방법들이 존재함에도 불구하고, 가장 효과적인 다운샘플링 방법에 대한 체계적인 연구가 많지 않았다. 본 논문에서는 최대 풀링, 평균 풀링, Stride 값 변화 등 총 3가지를 비교하여 각각의 방법으로 모델을 학습하고 평가하였다. 평가를 위해 손실(Loss), 정확도(Accuracy), F1-Score 등의 성능지표를 통해 다운 샘플링 방법들을 비교하였다. 비교에 사용된 모델들은 기본적으로 Cifar-10 데이터셋을 학습한 합성곱 신경망 모델들로, 실험 결과 Max pooling 방식, Stride 변화 방식 2, Average pooling, Stride 변화 방식 1의 순서로 정확도 등 전체적인 성능지표가 높게 나았다. 본 연구의 다 운샘플링에 대한 분석 결과는 정확한 모델 학습을 위한 향후 연구 방향에 기여할 것으로 기대한다.","Popular downsampling methods in Convolutional Neural Network (CNN) include Max pooling, Average pooling, and changing the value of Stride on the filter. Although there are various downsampling methods available, few systematic research have been conducted for selecting effective downsampling. In this paper, we evaluate the performance of models trained with different downsampling methods. More specifically, we train Convolutional Neural Network models with popular downsampling method including Max pooling, Average pooling, and Striding with different values. After that, we compare each model with performance indicators such as Loss, Accuracy, and F1-Score. The models used in the experiment were basically Convolutional Neural Networks trained with the Cifar-10 dataset. As a result of the experiment, overall performance indicators such as accuracy were high in the order of Max pooling, method 2 for changing the value of Stride on the filter, Average pooling, and method 1 for changing the value of Stride on the filter. We expect our analysis of downsampling methods will contribute future research directions for accurate model learning."
Wafer Map Failure Pattern Classification using Geometrical Transformation Invariant Convolutional Neural Network,2021,"['Deep learning (심층학습)', 'semiconductor defect (반도체 결함)', 'wafer map pattern classification (웨이퍼 지도 결함패턴 분류)', 'rotation invariance (회전불변성)']",국문 초록 정보 없음,"The wafer bin map (WBM) pattern classification is vital for semiconductor wafer defect diagnosis as it can provide both key information of a single wafer state and the root cause of manufacturing malfunction if occur [1]. Unfortunately, labeled semiconductor data is scarce and this hinders diagnosis using data-driven approach. To solve the data shortage problem, most studies utilize data augmentation method [2]. However, the traditional data augmentation scheme is limited in cases where the original data size is too small [3]. In this study, we aim to acquire improved performance by learning features that reflect the invariance of WBM pattern to rotation and flip transformation even if the data size for training is limited. Polar mapping and kernel flip are taken care of in the convolution layer of a convolutional neural network (CNN). To evaluate the effectiveness of our model, the WM-811k public dataset and its manipulated data with rotation and flip are tested. To simulate the lack of data, we sampled several datasets which ranges from 300 to 1000 in size. As a result, not only the performance of the original data was improved but the performance of the metadata test set was also significantly improved for most cases."
DCGAN을 이용한 잡육에서의 바늘 검출,2021,"['X-Ray image', 'Deep convolutional generative adversarial network', 'DCGAN', 'Needle detection', 'Foreign object']",국문 초록 정보 없음,"Usually, during slaughter, the meat is divided into large chunks by part after deboning. The meat chunks are inspected for the presence of needles with an X-ray scanner. Although needles in the meat chunks are easily detectable, they can also be found in trimmings and meat offals, where meat skins, fat chunks, and pieces of meat from different parts get agglomerated. Detection of needles in trimmings and meat offals becomes challenging because of many needle-like patterns that are detected by the X-ray scanner. This problem can be solved by learning the trimmings or meat offals using deep learning. However, it is not easy to collect a large number of learning patterns in trimmings or meat offals. In this study, we demonstrate the use of deep convolutional generative adversarial network (DCGAN) to create fake images of trimmings or meat offals and train them using a convolution neural network (CNN)."
A Study on Pagoda Image Search Using Artificial Intelligence (AI) Technology for Restoration of Cultural Properties,2021,"['Enter key words or phrases in alphabetical order', 'separated by commas']",국문 초록 정보 없음,"The current cultural assets are being restored depending on the opinions of experts (craftsmen). We intend to introduce digitalized artificial intelligence techniques, excluding the personal opinions of experts on reconstruction of such cultural properties. The first step toward restoring digitized cultural properties is separation. The restoration of cultural properties should be reorganized based on recorded documents, period historical backgrounds and regional characteristics. The cultural properties in the form of photographs or images should be collected by separating the background. In addition, when restoring cultural properties most of them depend a lot on the tendency of the restoring person workers. As a result, it often occurs when there is a problem in the accuracy and reliability of restoration of cultural properties. In this study, we propose a search method for learning stored digital cultural assets using AI technology. Pagoda was selected for restoration of Cultural Properties. Pagoda data collection was collected through the Internet and various historical records. The pagoda data was classified by period and region, and grouped into similar buildings. The collected data was learned by applying the well-known CNN algorithm for artificial intelligence learning. The pagoda search used Yolo Marker to mark the tower shape. The tower was used a total of about 100-10,000 pagoda data. In conclusion, it was confirmed that the probability of searching for a tower differs according to the number of pagoda pictures and the number of learning iterations. Finally, it was confirmed that the number of 500 towers and the epochs in training of 8000 times were good. If the test result exceeds 8,000 times, it becomes overfitting. All so, I found a phenomenon that the recognition rate drops when the enemy repeatedly learns more than 8,000 times. As a result of this study, it is believed that it will be helpful in data gathering to increase the accuracy of tower restoration."
Age-invariant Face Recognition by Coupled Residual Learning Networks,2021,"['연령무관 얼굴인식', '심층학습', '연령모달리티', '컨볼루션신경망', 'age-invariant face recognition', 'deep learning', 'age modality', 'convolutional neural network']","현장에서 사용되는 응용 프로그램에서 연령에 무관한 얼굴 인식에 대한 연구가 그의 큰 잠재력으로 인하여 급증하고 있는 추세이다. 연령에 무관한 얼굴을 인식하는 연구의 어려움은 얼굴 모양이 시간이 지남에 따라 노화현상 등으로 인하여 스스로 변한다는 것이다. 따라서 나이 차이가 큰 경우에 얼굴을 인식하기가 쉽지 않다. 본 논문에서는 연령 무관 얼굴 인식을 위한 잔차 학습 모듈 기반의 새로운 결합 네트워크 아키텍처를 제안하였다. VGGFace2를 학습한 Inception-ResnetV1를 백본 네크워크로 사용하였으며, 하나의 연령모드에 보상을 추가하여, 잔차학습 모듈은 연령에 따른 모드 불일치(ARMD)를 감소시켜 다른 모드에 유사하도록 표현할 수 있다. ARMD 손실은 서로 다른 모드 간의 코사인거리를 최소화하여 모드 별 불일치를 완화시키도록 하였다. 실험결과는 교차연령 얼굴데이터인 CACD_VS, FGNET, GFR 및 LFW 데이터에서 제안 알고리즘이 다른 알고리즘에 비하여 우수한 성능을 나타내는 것을 보여주었다.","Age-Invariant Face Recognition (AIFR) has been drawing an increasing research interest, due to its potential in real-world applications. The crucial challenge of AIFR arises from the fact that the facial appearance is subject to significant intra-class variations caused by the aging process over time, hence, matching faces with big age gaps is challenging. In this paper, we propose a new coupled network architecture based on the residual learning module for age-invariant face recognition. We implemented the Inception-ResnetV1 (pre-trained on VGGFace2) as the backbone Convolutional Neural Network (CNN). By adding compensation to one of the modalities, the residual learning module reduces Age-Related Modality Discrepancy (ARMD) of which representation can be close to the other modality. The ARMD loss alleviates modal discrepancy by minimizing the cosine distance between different modalities. Experimental results on the cross-age datasets including CACD_VS, FGNET, and General Face Recognition (GFR) dataset indicate that the proposed method can obtain superior performance."
A Development of Nurse Scheduling Model Based on Q-Learning Algorithm,2021,"['Nurse Schedule', 'Nurse Scheduling Problem', 'Reinforcement Learning', 'Q-Learning', 'Fairness Indicator Score']",국문 초록 정보 없음,"In this paper, We focused the issue of creating a socially problematic nurse schedule. The nurse schedule should be prepared in consideration of three shifts, appropriate placement of experienced workers, the fairness of work assignment, and legal work standards. Because of the complex structure of the nurse schedule, which must reflect various requirements, in most hospitals, the nurse in charge writes it by hand with a lot of time and effort. This study attempted to automatically create an optimized nurse schedule based on legal labor standards and fairness. We developed an I/O Q-Learning algorithm-based model based on Python and Web Application for automatic nurse schedule. The model was trained to converge to 100 by creating an Fairness Indicator Score(FIS) that considers Labor Standards Act, Work equity, Work preference. Manual nurse schedules and this model are compared with FIS. This model showed a higher work equity index of 13.31 points, work preference index of 1.52 points, and FIS of 16.38 points. This study was able to automatically generate nurse schedule based on reinforcement Learning. In addition, as a result of creating the nurse schedule of E hospital using this model, it was possible to reduce the time required from 88 hours to 3 hours. If additional supplementation of FIS and reinforcement Learning techniques such as DQN, CNN, Monte Carlo Simulation and AlphaZero additionally utilize a more an optimized model can be developed."
컨볼루션 신경망에 기반한 비디오 월 컨트롤러의 블랙 스크린 감지,2021,"['Convolutional Neural Network', 'DCGAN', 'Deep Learning', 'Image Classification', 'Video Wall Controller']","최근에 비디오 월 컨트롤러 시장이 빠르게 성장하면서 지금까지는 크게 이슈화 되지 않았던 문제들이 표면화 되고 있는데, 비디오 월 컨트롤러에서 블랙 스크린이 발생하는 현상도 그 중 하나일 것이다. 블랙 스크린은 비디오 월 컨트롤러의 멀티 스크린에 정상적인 영상이 아닌 블랙 스크린이 표출되는 현상이다. 블랙 스크린의 발생을 인지하고 해결하기 위해서는 인간의 개입이 불가피 하지만 운영자가 24시간 멀티 스크린을 모니터링 하는 것은 사실상 불가능하다. 따라서 본 논문에서는 비디오 월 컨트롤러에서 블랙 스크린이 발생하는 것을 자동으로 감지하는 모델을 제안한다. 블랙 스크린 감지 모델은 이미지 분류에 널리 활용되고 있는 컨볼루션 신경망으로 블랙 스크린의 발생 여부를 감지한다.","As the video wall controller market is growing rapidly, issues that have not been addressed so far are raised. One of them is a phenomenon in which a black screen is displayed on a multi-screen. Black screen is displayed due to an error in the video being displayed in the video wall controller. Human intervention is inevitable to recognize and solve the black screen. However, it is impossible for the operator to monitor the multi-screen 24 hours a day. In this paper, we propose a model that detects the black screen being displayed on the video wall controller. We propose a CNN based architecture to detect a black screen."
Watermelon quality measurement based on sound deep learning,2021,"['Watermelon quality', 'Deep learning', 'Sound classification', 'Smartphone application']",국문 초록 정보 없음,"Objective: The aim of this study is to find out whether it is possible to classify the sugar content of watermelons through sound classification based on deep learning techniques. Background: In general, when people pick a watermelon with good sugar content at the supermarket, they not only take a close look at them with their eyes, but also tend to tap and listen to them. As a result of the interview in this study, experienced fruit merchants can classify the watermelons with good sugar content just by tapping them and listening to the sound. Method: In order to develop and verify a deep learning model for classifying sugar content based on the tapping sound of watermelons, about 4,000 sound data were collected from about 700 watermelons at Cheongnyangni fruit market and Yangpyeong Cheongwoon distribution center classifying watermelons with a non-destructive measuring device. The sound data of the watermelon was measured at a distance of 1 to 2 ㎝ using the iPhone (11 Pro) after tapping the center of the watermelon with the palm of the hand. Noise was not separately controlled when collecting the sound data. The classes of the watermelon were divided into four categories: low quality or hollow, 10brix, 11brix, and 12brix. Results: We have applied MLP (Multi-Layer Perceptron) and CNN (Convolutional Neural Network) deep learning models to classify this collected sound data, showing accuracies of 96.66% and 95.28%, respectively. Finally, we verified the model using data that was not used for learning and confirmed that it was classified correctly. Conclusion: It has been shown that watermelon sugar content can be classified with high precision based on sound deep learning, just like a human taps a watermelon to hear the sound and filter out a good watermelon. Application: Based on the developed deep learning model, we are developing a smartphone app that evaluates quality by tapping watermelons."
컴퓨팅 부하 예측 DNN 모델 기반 디지털 트윈 소프트웨어 개발 프레임워크,2021,"['Artificial intelligence cloud', 'data-driven model', 'load estimation', 'digital twin', 'autonomous things']",국문 초록 정보 없음,"Artificial intelligence clouds help to efficiently develop the autonomous things integrating artificial intelligence technologies and control technologies by sharing the learned models and providing the execution environments. The existing autonomous things development technologies only take into account for the accuracy of artificial intelligence models at the cost of the increment of the complexity of the models including the raise up of the number of the hidden layers and the kernels, and they consequently require a large amount of computation. Since resource-constrained computing environments, could not provide sufficient computing resources for the complex models, they make the autonomous things violate time criticality. In this paper, we propose a digital twin software development framework that selects artificial intelligence models optimized for the computing environments. The proposed framework uses a load estimation DNN model to select the optimal model for the specific computing environments by predicting the load of the artificial intelligence models with digital twin data so that the proposed framework develops the control software. The proposed load estimation DNN model shows up to 20% of error rate compared to the formula-based load estimation scheme by means of the representative CNN models based experiments."
흉부 X-선 영상에서 심장비대증 분류를 위한 합성곱 신경망 모델 제안,2021,"['합성곱 신경망', '딥러닝', '흉부 X-선', '분류', 'Convolutional Neural Network', 'Deep learning', 'Chest X-ray', 'Classification']","본 논문에서는 흉부 X선 영상에서 정상 심장과 비정상 심장(심장비대)을 분류할 수 있는 합성곱 신경망 모델을 제안하고자 한다. 학습 및 테스트 데이터로는 경북대학교병원에 내원하여 정상과 심장비대를 진단받은 환자들의 흉부 X-선 이미지를 획득하여 사용하였다. 제안된 합성곱 신경망 모델을 이용하였을 때의 정상 심장 및 비정상 심장(심장비대) 분류 정확도는 99.88%였다. 정상 심장 영상을 테스트 데이터로 사용하였을 때의 정확도, 정밀도, 재현율 및 F1 Score는 95%, 100%, 90%, 96%였다. 비정상 심장(심장비대) 영상을 테스트 데이터로 사용하였을 때의 정확도, 정밀도, 재현율 및 F1 Score는 95%, 92%, 100% 및 96%였다. 이러한 학습 및 테스트 분류 결과로 제안된 합성곱 신경망 모델은 흉부 X-선 영상의 특징 추출 및 분류에서 매우 우수한 성능을 보여주고 있다고 판단된다. 본 논문에서 제안하는 합성곱 신경망 모델은 흉부 X-선 영상의 질환 분류에 있어 유용한 결과를 보여줄 것으로 판단되며, 다른 의료 영상에서도 동일한 결과를 나타내는지 알아보기 위하여 추가적인 연구가 이루어져야 할 것이다.","The purpose of this study is to propose a convolutional neural network model that can classify normal and abnormal(cardiomegaly) in chest X-ray images. The training data and test data used in this paper were used by acquiring chest X-ray images of patients diagnosed with normal and abnormal(cardiomegaly). Using the proposed deep learning model, we classified normal and abnormal(cardiomegaly) images and verified the classification performance. When using the proposed model, the classification accuracy of normal and abnormal(cardiomegaly) was 99.88%. Validation of classification performance using normal images as test data showed 95%, 100%, 90%, and 96% in accuracy, precision, recall, and F1 score. Validation of classification performance using abnormal(cardiomegaly) images as test data showed 95%, 92%, 100%, and 96% in accuracy, precision, recall, and F1 score. Our classification results show that the proposed convolutional neural network model shows very good performance in feature extraction and classification of chest X-ray images. The convolutional neural network model proposed in this paper is expected to show useful results for disease classification of chest X-ray images, and further study of CNN models are needed focusing on the features of medical images."
Fusing RGB and depth with Self-attention for Unseen Object Segmentation,2021,"['Unseen Object Instance Segmentation', 'Self-attention', 'Synthetic Dataset', 'RGB-D Fusion']",국문 초록 정보 없음,"We present a Synthetic RGB-D Fusion Mask R-CNN (SF Mask R-CNN) for unseen object instance segmentation. Our key idea is to fuse RGB and depth with a learnable spatial attention estimator, named Self-Attention-based Confidence map Estimator (SACE), in four scales upon a category-agnostic instance segmentation model. We pre-trained this SF Mask R-CNN on a large synthetic dataset and evaluated it on a public dataset, WISDOM, after fine-tuning on only a small number of real-world datasets. Our experiments showed the state-of-the-art performance of SACE in unseen object segmentation. Also, we compared the feature maps varying the input modality and fusion method and showed that SACE could be helpful to learn distinctive object-related features. The codes, dataset, and models are available at https://github.com/gist-ailab/SF-Mask-RCNN"
Road Damage Detection and Classification based on Multi-level Feature Pyramids,2021,"['Multi-level Feature Pyramids', 'Road Damage Detection', 'VGG16', 'Multi-scale', 'Multi-level']",국문 초록 정보 없음,"Road damage detection is important for road maintenance. With the development of deep learning, more and more road damage detection methods have been proposed, such as Fast R-CNN, Faster R-CNN, Mask R-CNN and RetinaNet. However, because shallow and deep layers cannot be extracted at the same time, the existing methods do not perform well in detecting objects with fewer samples. In addition, these methods cannot obtain a highly accurate detecting bounding box. This paper presents a Multi-level Feature Pyramids method based on M2det. Because the feature layer has multi-scale and multi-level architecture, the feature layer containing more information and obvious features can be extracted. Moreover, an attention mechanism is used to improve the accuracy of local boundary boxes in the dataset. Experimental results show that the proposed method is better than the current state-of-the-art methods."
Application of object detection deep learning algorithms for automated detection of infiltration of mononuclear cell in SD rat liver,2021,"['Deep learning', 'Object detection', 'Infiltration mononuclear cell', 'Non-clinical study']",국문 초록 정보 없음,"The development of deep learning has shown outstanding performance in image analysis, and it has been accelerating the attempt to apply the technique to detect the pathological lesion automatically from the whole slide image (WSI) in the non-clinical study, as well as clinical study. We applied three deep learning-based algorithms including Mask R-CNN, DeepLab, and YOLO to detect mononuclear cell infiltration in SD rat liver which is one of the toxicological evidence in a non-clinical study. The lesion classified into two subtypes, lymphocytes and histiocytes infiltration, according to distinct features, therefore, trained separately. Total 4,191 tile images including the lesion were obtained from 44 WSIs for the analysis. The pathological lesions were labeled by VGG annotator 2.0.1.0, and the procedure that related to AI method, including train, validation, and test, was conducted by Tensor flow 2.1.0 powered by NVIDA 2080 Ti GPU. The dataset was divided with the ratio 7: 2: 1 using train_test_split function of scikit-learn. After the dataset division, the training dataset was augmented by 8 times using image augmentation techniques (reverse, rotation, and controlling brightness). The accuracy of prediction is determined by mean average precision (mAP), which can be inferred from the intersection of union (IoU) that measures the ratio of overlap area between the union of predictions and ground truth. After the training, the detection test accuracy rates were followed up by in order Mask R-CNN (96.74%), of DeepLab (92.07%), and last YOLO (70.16%). YOLO, the algorithm which detects the object using a bounding box, showed lower accuracy than the other two algorithms which detect the object by pixel segmentation. And Mask R-CNN, which showed the highest accuracy, might be an appropriate algorithm for the precise detection of infiltration mononuclear cell. In conclusion, we suggest pixel segmentation technique might be appropriate for more accurate detection of the lesions in WSIs."
머신러닝을 이용한 압출 제품의 표면 결함 모니터링시스템,2021,"['Machine learning', 'Object detection', 'Defect detection', 'Monitoring system']","4 차 산업혁명 및 스마트 팩토리 시장의 공장자동화에 대한 다양한 기술들이 연구되고 산업현장에 적용되고 있다. 머신러닝 종류 중 하나인 R-CNN (Region Based Convolution Neural Networks) 기반의 알고리즘이 적용된 사례로 Faster R-CNN 을 이용한 탄화수소 누출 감지, 유해물질 검출 등이 있다. 본 연구에서 다루고자 하는 대상은 압출 공정을 통하여 생산되는 Teflon Tube 이다. Teflon Tube 가 생산될 때, 다양한 이유로 압출 공정의 전형적인 외관 결함(그을음, 이물질, 스크래치 등)이 Teflon Tube 의 표면에 발생한다. 이러한 결함은 육안으로 확인하여 검사하고 있다. 이 검사 방법은 작업자 간의 검사 편차로 Teflon Tube 에 발생한 결함을 효과적으로 검출하지 못하는 한계가 있다. 따라서 본 연구에서는 객체 검출 알고리즘을 이용하여 Teflon Tube 의 품질 모니터링 시스템을 개발하고자 한다. Teflon Tube 종류 중 하나인 PFA (PerFluoroAlkoxy) Tube 에 인위적인 결함(그을음, 이물질)을 발생시켜 USB Camera를 통해 촬영한 이미지를 머신러닝 데이터 세트로 사용하였다. LabelImg Tool 로 수집한 결함 데이터를 라벨링하였고, 객체 검출 알고리즘으로는 YOLOv5 (You Only Look Once Version 5)로 PFA Tube 의 결함을 학습시켰다. 학습된 YOLOv5 모델을 이용하여 결함에 대한 객체 검출과 약 0.9 이상의 Precision 및 Recall 값을 확인하였다. 더 나아가 Kfold Cross Validation 과 mAP (Mean Average Precision)등의 평가지표를 활용하여 학습된 모델의 정확도 평가를 진행할 예정이다. 또한, 본 연구의 품질 모니터링 시스템을 실제 현장에 적용하기 위해 산업 현장에서 결함 검출에 영향을 미칠 수 있는 노이즈(빛, 그림자 등)를 최소화할 수 있는 하드웨어를 개발 중에 있다.",다국어 초록 정보 없음
아동 그림 심리분석을 위한 인공지능 기반 객체 탐지 알고리즘 응용,2021,"['인공지능', '딥러닝', '객체 탐지', '영상처리', '아동 그림분석', 'Artificial Intelligence', 'Deep Learning', 'Object detection', 'Image Processing', 'Child drawing analysis']",아동 그림은 내면의 감정을 표현할 수 있는 수단으로 아동 심리 진단에 널리 이용되고 있다. 본 논문에서는 아동 그림 분석에 적용할 수 있는 아동 그림 기반의 객체 탐지 알고리즘을 제안한다. 먼저 사진에서의 그림 영역을 추출하였고 데이터 라벨링 과정을 수행하였다. 이후 라벨링된 데이터 셋를 사용하여 Faster R-CNN 기반 객체 탐지모델을 학습하고 평가하였다. 탐지된 객체 결과를 기반으로 그림 면적 및 위치 또는 색상 정보를 계산하여 그림에 대한 기초정보를 쉽고 빠르게 분석할 수 있도록 설계하였다. 이를 통해 아동 그림을 이용한 심리분석에 있어 인공지능 기반 객체 탐지 알고리즘의 활용성을 보였다.,"Children""s drawings are widely used in the diagnosis of children""s psychology as a means of expressing inner feelings. This paper proposes a children""s drawings-based object detection algorithm applicable to children""s psychology analysis. First, the sketch area from the picture was extracted and the data labeling process was also performed. Then, we trained and evaluated a Faster R-CNN based object detection model using the labeled datasets. Based on the detection results, information about the drawing""s area, position, or color histogram is calculated to analyze primitive information about the drawings quickly and easily. The results of this paper show that Artificial Intelligence-based object detection algorithms were helpful in terms of psychological analysis using children""s drawings."
자세 추정을 위한 모션 캡처 데이터 복원,2021,"['pose estimation', 'motion capture', 'c3d data', 'data restoration', 'human pose data']","자세 추정을 위한 모션 캡처 데이터 파일에는 주변 환경과 움직임의 정도에 따라 부정확한 데이터가 존재할 수 있으므로, 이를 보정하는 작업이 필요하다. 기존에는 직접 후처리 과정을 통해 부정확한 데이터를 복원하였으나, 최근에는 자동화된 방법으로 LSTM, R-CNN 등 다양한 종류의 신경망을 사용한다. 하지만 신경망 기반의 데이터 복원 방법들은 컴퓨터 자원을 많이 요구하므로, 본 논문에서는 신경망 기반의 방법보다 자원 사용량은 낮추면서 데이터 복원율은 유지하는 방법을 제안한다. 제안하는 방법은 자세 측정 데이터(c3d)를 활용하여 부정확한 자세 데이터를 자동으로 복원한다. 실험 결과, 데이터의 부정확한 정도에 따라 89%에서부터 99% 정도의 데이터 복원율을 보였다.","Motion capture data files for pose estimation may have inaccurate data depending on the surrounding environment and the degree of movement, so it is necessary to correct it. In the past, inaccurate data was restored with post-processing by people, but recently various kind of neural networks such as LSTM and R-CNN are used as automated method. However, since neural network-based data restoration methods require a lot of computing resource, this paper proposes a method that reduces computing resource and maintains data restoration rate compared to neural network-based method. The proposed method automatically restores inaccurate motion capture data by using posture measurement data (c3d). As a result of the experiment, data restoration rates ranged from 89% to 99% depending on the degree of inaccuracy of the data."
심층학습 기반 부유쓰레기 성상 분석,2021,"['Object detection', 'Deep-learning', 'Classification', 'Marine Debris', 'Floating debris']","전 세계적으로 매년 발생하는 800만 톤 이상의 해양쓰레기 중 약 70%는 육상 기인 쓰레기로 조사된 바 있으며, 쓰레기의 대부분은 직접 수거에 의한 모니터링 기법으로 분석되고 있어 부유 쓰레기의 발생원 판별 및 수거 비용 산정이 어려운 실정이다. (J. Jambeck, 2015)   본 연구에서는 부유 쓰레기의 효율적인 모니터링과 데이터베이스 구축을 위해 성상 정보를 실시간으로 취득 및 분석하는 모니터링 기술을 개발하였다. 객체 감지 기법(Object Detection)을 활용하여 부유쓰레기의 성상을 분석하고, 학습 모델의 성능을 비교 검토하기 위해 Faster R-CNN, SSD 알고리즘을 이용하여 mAP(mean Average Precision) 수치로 모델의 성능을 비교하였다. 학습을 위한 데이터셋은 6가지 종류의 쓰레기(플라스틱, 비닐, 스티로폼, 초목류, 종이, 병)로 분류하였으며 가상의 부유쓰레기 차단시설을 구축하여 이미지 데이터로부터 94,237개의 객체 데이터를 확보하였다. 데이터는 증강 기술을 활용하여 471,185개로 증강하였으며, 객체 수량에 따른 모델의 성능 차이를 검토하기 위해 155,407개, 471,185개의 데이터셋으로 나누어 학습 및 검증하고, 모델의 성능을 비교하였다.  향후 모델 성능과 학습 데이터의 연관성을 고려하여 학습 계획을 재수립하고, 개선된 모델을 개발 기술에 적용할 예정이다. 본 기술을 통해 구축된 데이터셋은 해양쓰레기 통합 관리 시스템과 연계하여 효율적인 해양쓰레기 수거 전략, 비용 절감 및 정책을 수립하고, 수거 폐기물 관리체계 개선에 기여할 수 있을 것으로 판단된다.","It is widely cited that about 70% of marine debris which occurs by more than 8 million tons annually originates from land, however, this figure does not inform properly the total amount of debris entering the marine environment. The debris is generally classified by monitoring the collected debris at shore, thus, it is difficult to figure out where floating marine debris is from and to estimate total cost for collection. (J. Jambeck, 2015)  Newly proposed monitoring technique which acquire and analyze the object’s characteristics in real-time, in this study, was developed to establish efficient and enhanced floating marine debris monitoring system. An object detection technique, containing Faster R-CNN and SSD algorithm, is used to analyze the properties of the floating debris. These two algorithms are verified by mAP (mean Average Precision). The dataset for deep learning was classified into 6 categories (Plastic, CAN, PET, Vinyl, Bottle), and 94,237 object data was obtained from image data in the virtual floating debris barrier facility model. The data was augmented to 471,185 data by augmentation technology. In addition, the data is divided into datasets of 144,407 and 471,185 objects for verification of the model according to the number of objects.  The dataset model will be improved with updated data learning strategy, considering a relation between model performance and training data, in further study. The established dataset with the new monitoring technique will be applied into AMEIS(Advanced Marine Environment Improvement System), which allows debris management system to be enhanced with efficient debris collection strategy and policy and cost reduction."
Unified Deep Learning Model for El Niño/Southern Oscillation Forecasts by Incorporating Seasonality in Climate Data,2021,"['Deep learning', 'ENSO forecast', 'Seasonality of the ENSO']",국문 초록 정보 없음,"Although deep learning has achieved a milestone in forecasting the El Niño-Southern Oscillation (ENSO), the current models are insufficient to simulate diverse characteristics of the ENSO, which depends on the calendar season. Consequently, a model was generated for specific seasons which indicates these models did not consider physical constraints between different target seasons and forecast lead times, thereby leading to arbitrary fluctuations in the predicted time series. To overcome this problem and account for ENSO seasonality, we developed an all-season convolutional neural network (A_CNN) model. The correlation skill of the ENSO index was particularly improved for forecasts of the boreal spring, which is the most challenging season to predict. Moreover, activation map values indicated a clear time evolution with increasing forecast lead time. The study findings reveal the comprehensive role of various climate precursors of ENSO events that act differently over time, thus indicating the potential of the A_CNN model as a diagnostic tool."
재난문자 분류를 위한 딥러닝 모델,2021,"['Disaster Alerts', 'Text Classification', 'Deep Learning', 'Word Embedding', 'BERT', '재난문자', '텍스트 분류', '딥러닝', '단어 임베딩']","재난문자는 재난 발생 시 국가에서 해당 지역에 있는 시민들에게 보내는 문자 메시지다. 재난문자의 발송 건수는 점점 증가하여, 불필요한 재난문자가 많이 수신됨에 따라 재난문자를 차단하는 사람들이 증가하고 있다. 이와 같은 문제를 해결하기 위하여, 본 연구에서는 재난문자를 재난 유형별로 자동으로 분류하고 수신자에 따라 필요한 재난의 재난문자만 수신하게 하는 딥러닝 모델을 제안한다. 제안 모델은 재난문자를 KoBERT를 통해 임베딩하고, LSTM을 통해 재난 유형별로 분류한다. [명사], [명사 + 형용사 + 동사], [모든 품사]의 3가지 품사 조합과 제안 모델, 키워드 분류, Word2Vec + 1D-CNN 및 KoBERT + FFNN의 4종류 분류 모델을 활용하여 재난문자를 분류한 결과, 제안 모델이 0.988954의 정확도로 가장 높은 성능을 달성하였다.","Disaster alerts are text messages sent by government to people in the area in the event of a disaster. Since the number of disaster alerts has increased, the number of people who block disaster alerts is increasing as many unnecessary disaster alerts are being received. To solve this problem, this study proposes a deep learning model that automatically classifies disaster alerts by disaster type, and allows only necessary disaster alerts to be received according to the recipient. The proposed model embeds disaster alerts via KoBERT and classifies them by disaster type with LSTM. As a result of classifying disaster alerts using 3 combinations of parts of speech: [Noun], [Noun + Adjective + Verb] and [All parts], and 4 classification models: Proposed model, Keyword classification, Word2Vec + 1D-CNN and KoBERT + FFNN, the proposed model achieved the highest performance with 0.988954 accuracy."
딥러닝 기반 전동킥보드 헬멧 착용여부 감지 기법의 제안 및 성능 평가,2021,"['Deep learning', 'Object detection', 'Personal mobility driving safety', 'Helmet detection']","Objective: 전동킥보드에 거치된 스마트폰의 전면 카메라를 활용하여 사용자의 헬멧 착용 여부를 감지할 수 있는 시스템을 제안하고, 다양한 객체 인식 알고리즘들을 활용해 도출한 성능을 비교 분석하고자 한다. Background: 최근 전동킥보드 사용량이 급증함에 따라 안전사고도 증가하고 있다. 이에 정부는 헬멧 착용을 의무화하도록 도로교통법을 개정했으나, 헬멧 착용자는 16%에 불과한 상황이며 단속과 처벌 또한 어려운 상황이다. CCTV를 통한 단속을 진행한다고 하더라도 즉각적으로 제재하는 데 어려움이 있기 때문에 헬멧 미착용 시 사용자에게 즉각적인 규제를 적용할 수 있고 헬멧 착용률도 향상시킬 수 있는 새로운 방법이 필요한 상황이다. Method: 킥보드의 넥 중앙부에 얼굴을 올려다보는 각도로 스마트폰을 설치하고 주행 장면을 촬영하여 2,400장의 이미지를 수집하였다. 총 6명의 사용자를 대상으로 주간에 평평한 지형에서 촬영을 진행하였으며, 사용자별로 헬멧 착용 이미지, 헬멧 미착용 이미지를 각각 200장씩 수집하였다. 객체 인식을 위한 딥러닝 모델인 Faster-R-CNN, YOLOv3, DETR, Deformable DETR을 이용하여 30/100epoch 동안 학습을 진행하여 헬멧 착용 여부 판별 결과를 도출하였다. 딥러닝 학습 시, 학습 데이터는 1,680장, 검증 데이터는 240장, 테스트 데이터는 480장을 이용하였다. Results: 30 epoch 동안 학습을 진행한 경우 Faster-R-CNN, YOLOv3-320, YOLOv3-416, YOLOv3-608, DETR, Deformable DETR의 mAP는 각각 0.9, 0.693, 0.631, 0.38, 0.853, 0.879로 나타났다. 한편, 100 epoch 동안 학습한 경우, mAP는 각각 0.899, 0.785, 0.819, 0.783, 0.882, 0.905로 변화하였다. Epoch을 증가시켰을 때 YOLOv3가 다른 모델에 비해 더욱 큰 차이를 보였으며, 416 416 입력 기반모델의 성능이 가장 높은 것으로 평가되었다. 한편, 사용자의 정면에서 촬영된 헬멧 공개 데이터 730장으로 학습을 진행하고 본 연구에서 수집한 데이터를 대상으로 테스트를 진행한 경우 0.065~0.241의 현저히 낮은 ㎃P 수치를 확인할 수 있었다. Conclusion: 본 연구에서 제안한 환경에서 다양한 딥러닝 기반 객체 인식 모델들이 0.78 이상의 ㎃P를 보이며 주행 중 사용자 헬멧 착용 여부 감지 가능성을 확인할 수 있었다. 반면, 사용자 정면에서 촬영된 공개 헬멧 데이터만을 이용하여 학습한 모델의 경우 헬멧 착용 여부 판별에 한계가 있음을 알 수 있었다. Application: 본 연구 결과를 토대로 사용자의 편의성과 안전성을 고려하여 킥보드 내부에 소형 카메라를 탑재하고 헬멧 착용 여부를 인식할 수 있는 방향으로 확장 연구를 수행할 계획이며, 이는 헬멧 착용률 향상을 위한 인프라로 활용될 수 있을 것으로 기대된다.",다국어 초록 정보 없음
과채류 수확 로봇 개발을 위한 깊이 추정 기법의 온실 환경으로의 적용,2021,"['깊이 영상', '딥러닝', '시설 온실']","과채류 수확 로봇을 온실에 적용하기 위해서는 대상이 되는 작물에 대한 객체 인식이 필요하다. 현재 Faster R-CNN, Yolo, SSD 등 딥러닝 기반 객체 검출 모델들이 농업에 적용되는 사례가 많으며, 위 기술들은 장면에 포함된 모든 객체를 검출한다. 그러나 온실 내 배지 사이의 레일을 따라 작동하는 로봇 특성상, 작업 중인 구역의 객체만 인식하는 것이 유리하다. 때문에, 최근 RGB-D 카메라나 스테레오 카메라 등을 이용해 영상의 깊이를 함께 활용하는 연구가 시도되고 있지만, 별도의 깊이 카메라 장착이 필요하고 외부광으로 인한 깊이 영상 노이즈 발생 등의 문제가 있다. 본 논문은 온실에서 별도의 깊이 센서 없이 2D 영상에서 깊이를 추정하는 방식을 제안한다. 깊이 추정(Depth estimation)은 싱글 카메라로 촬영한 RGB 영상을 입력했을 때 깊이 맵이 출력되도록 하는 기법이다. 본 논문에서는 의미론적 분할(Semantic Segmantation) 기법의 하나인 UNet을 응용하는 방식으로 접근한다. 토마토 배지 재배 온실에서 촬영한 데이터를 기반으로 UNet을 학습했으며, Intel RealSense D435 카메라를 이용해 RGB 영상과 깊이 영상을 동시에 수집했다. 카메라를 모바일 로봇에 탑재해 레일을 따라 선형으로 촬영했으며, 생육 생장을 마친 토마토가 촬영 대상이기 때문에 지면으로부터 1m, 배지로부터 0.6m 떨어진 곳에 카메라를 설치했다. 촬영된 실제 깊이 맵은 16bit의 값을 가지지만, UNet 학습 시 입력과 정답 영상 모두 8bit 영상 형식을 요구하기 때문에 8bit로 압축해서 적용했다. 위와 같은 이유로 정답 영상에 손실된 정보가 많아 학습 결과 깊이 맵이 제대로 형성되지 않은 것을 확인했다. 향후 UNet의 학습 시 정답 영상을 손실 없이 압축하거나 16bit 배열 형식으로 학습할 수 있도록 해 한계점을 해결하고 수확 로봇 개발 시 2D 카메라만 사용하여 비용 및 연산량 절감을 이루고자 한다.",다국어 초록 정보 없음
가상 데이터를 이용한 딥러닝 기반 운전자 행위 검출 시스템,2021,[],"최근 딥러닝 기반의 운전자 행위 검출이 활발히 연구되고 있다. 기존 연구에서는 스켈레톤 조인트 매핑 또는 R-CNN(Region of Convolutional Neural Network) 계열의 2-단계 객체 검출 등을 사용한다. 이러한 방식은 다른 운전자 모니터링 시스템과 연계 하기에는 연산량이 많다. 또한, 운전자 행위 검출에서 행위 검출에 실패하는 주요 원인은 사람의 행위를 분류할 때 차량외부 객체에 영향을 받아 분류에 실패하는 문제점을 갖는다. 이러한 문제점을 해결하기 위하여 본 논문에서는 가상 데이터 생성 알고리즘 및 딥러닝 기반 운전자 행위 검출 시스템을 제안한다. 연산량을 줄이기 위하여 운전자 행위 검출 시스템은 1-단계 얼굴 검출기와 경량화된 분류기를 사용하였다. 다양한 배경을 적용한 가상 데이터를 이용하여 실제 데이터와 함께 학습데이터를 구성한다. 제안하는 시스템은 실제 차량 환경에서 실험을 통한 운전자 행위 예측 결과, 90%의 성능을 보였다.",다국어 초록 정보 없음
Fashion Category Detection and Classification with Detectron2 and Fashionpedia,2021,"['fashion', 'deep learning', 'classification', 'Detectron2']",국문 초록 정보 없음,"Fashion occupies a large part of the industry and has been a part of our lives. One of the ways to analyze trends in fashion is to detect and classify categories in fashion images. In this paper, we present fashion category detection through the utilization of Detectron2's Mask R-CNN, which is easy to learn with custom datasets and has a high model construction and learning speed. Learning is also done based on Fashionpedia, a large-scale fashion segmentation and attribute localization dataset built with fashion ontology. As a result, the average precision (AP) of the bounding box was 52.45 and that of segmentation was 48.77, showing reasonably high performances. We propose a possibility of using fashion category detection and classification work in the field of fashion design."
Development of a deep learning-based algorithm to analyze Fruit traits analysis through Image Analysis Algorithms Development Based on Deep Learning,2021,"['fruit image analysis', 'Mask-RCNN', 'deep-learning']",국문 초록 정보 없음,"We developed a deep learning-based algorithm with plant fruit images to predict the quantitative traits, fruit size, and weight. Highbush blueberry was selected as a model plant because of its commercial importance. Mask R-CNN was adopted for a deep learning guidance model to predict fruits' width, length, and weight. The deep learning algorithm had a high performance on object detection and image segmentation with more than 90% accuracy and detection rate."
청각 장애인을 위한 수어 영상-자연어 번역 서비스 및 모바일 어플리케이션 구현,2021,[],"Covid-19 로 인한 마스크 착용이 청각장애인들의 소통을 더 어렵게 하는 바, 제 3 자의 도움 없이 쌍방향 소통을 가능하게 하는 서비스의 필요성이 커지고 있다. 이에 본 논문은 소통의 어려움을 겪는 청각장애인과 비청각장애인을 위한 쌍방향 소통 서비스에 대한 연구와 개발 과정, 기대 효과를 담는다. 서비스는 GRU-CNN 하이브리드 아키텍처를 사용하여 데이터셋을 영상 공간 정보와 시간 정보를 포함한 프레임으로 분할하는 영상 분류 기법과 같은 딥 러닝 알고리즘을 통해 수어 영상을 분류한다. 해당 연구는 “눈속말” 모바일 어플리케이션으로 제작 중이며 음성을 인식하여 수어영상과 텍스트로 번역결과를 제공하는 청각장애인 버전과 카메라를 통해 들어온 수어 영상을 텍스트로 변환하여 음성과 함께 제공하는 비청각장애인 버전 두 가지로 나누어 구현한다. 청각장애인과 비장애인의 쌍방향 소통을 위한 서비스는 청각장애인이 사회로 나아가기 위한 가장 기본적인 관문으로서의 역할을 할 것이며 사회 참여를 돕고 소통이라는 장벽을 넘어서는 발돋움이 될 것이라 예측된다.",다국어 초록 정보 없음
산불 연기 데이터셋 구축 및 심층 신경망 기반 검출 기술 비교 분석,2021,[],"최근 화재 재해를 예방하기 위해 CCTV 를 이용한 화재 감지 기술의 필요성이 증대되고 있다. 화재를 감지하기 위해, 열 연기 및 불꽃에 대한 여러 센서기반 감지 장치가 사용되고 있으나, 제한적인 감지 범위 및 주변 환경의 요소에 따라 사용이 제한되는 단점이 있다. 이 문제들을 해결하기 위해 영상기반 화재 연기 감지 기술이 개발되고 있다. 본 논문에서는 영상기반 산불 연기 검출의 효율적 연구를 위해 객체검출 방법 중 잘 알려진 YOLO-v3, Faster R-CNN, Retina-Net, Corner-Net, Center-Net 에 대해 성능 비교를 진행하였다.",다국어 초록 정보 없음
Automatic Detection of Injection and Press Mold Parts on 2D Drawing Using Deep Neural Network,2021,"['deep neural network', '2D Drawing', 'image patch', 'mold parts', 'industrial product design']",국문 초록 정보 없음,"This paper proposes a deep learning–based method to automatically detect the injection mold parts (i.e., hook or boss) and press mold parts (i.e., DPS or Embo) in 3D CAD models of commercial TV. We first converted the 3D CAD models into 2D drawings and cropped them into a smaller image patch for the training efficiency of a deep neural network. Then, we found the position and type of mold parts using Cascade R-CNN and estimated the orientation of the detected mold parts using ResNet-50. Finally, we converted the 2D position of the mold parts to the 3D position of the original image. We obtained detection accuracy of injection mold parts with an average precision (AP) of 84.1% and an average recall (AR) of 91.2% and detection accuracy of press mold parts with an AP of 72.0% and an AR of 87.0%, as well as an orientation accuracy of injection and press mold parts with 94.4% and 92.0%, respectively, which can facilitate faster industrial product design."
비전 트랜스포머를 이용한 휴대 수하물 보안검색 위험화물 검출 연구,2021,[],"본 연구에서는 최근 각광받고 있는 비전 트랜스포머 백본 기반 객체 검출 알고리즘을 항공 및 지하철 등 휴대 수하물 보안검색에 적용하기 위해 x-선 투과 영상 내 위험화물 검출 모델을 구성하여 학습 및 검증한 결과를 보고하고자 한다. 최근 MS COCO 객체 검출 벤치마크 결과 가장 뛰어난 검출 성능이 발표된 바 있는 Swin 트랜스포머(Transformer) 백본과 Cascade R-CNN 검출기를 휴대 수하물 보안검색 x-선 촬영 영상 내 위험화물 검출에 적용하였으며, 휴대 수하물 보안검색 x-선 촬영 영상으로 구성된 공개 데이터셋인 SIXray-10에 대해 지도학습을 진행한 결과, 기존 합성곱 신경망 백본을 이용한 검출결과와 비교하여 개선된 63.8 ㎃P의 정확도를 얻을 수 있었다.",다국어 초록 정보 없음
초해상화 기법을 적용한 검출 네트워크의 성능 향상,2021,[],최근 딥러닝 네트워크 기반의 객체 검출의 성능을 높이기 위해 높은 해상도의 입력 이미지를 사용하는 경향이 있다. 이 방법은 더욱 많은 연산량을 필요로 하기 때문에 시도가 제한적일 뿐만 아니라 원본 이미지의 해상도에 많은 영향을 받는다. 본 논문에서는 초해상화 기법을 통해 효율적으로 객체 검출의 성능을 향상시키는 기법을 제안한다. Pascal VOC2012 데이터에 대해서 제안된 기법과 Mask R-CNN 기법의 성능을 비교한다.,다국어 초록 정보 없음
Aural-visual two-stream 기반의 아기 울음소리 식별,2021,[],국문 초록 정보 없음,"Infants communicate their feelings and needs to the outside world through non-verbal methods such as crying and displaying diverse facial expressions. However, inexperienced parents tend to decode these non-verbal messages incorrectly and take inappropriate actions, which might affect the bonding they build with their babies and the cognitive development of the newborns. In this paper, we propose an aural-visual two-stream based infant cry recognition system to help parents comprehend the feelings and needs of crying babies. The proposed system first extracts the features from the pre-processed audio and video data by using the VGGish model and 3D-CNN model respectively, fuses the extracted features using a fully connected layer, and finally applies a SoftMax function to classify the fused features and recognize the corresponding type of cry. The experimental results show that the proposed system classification exceeds 0.92 in F1-score, which is 0.08 and 0.10 higher than the single-stream aural model and single-stream visual model."
ConvLSTM 모델 기반의 짧은 지연시간을 갖는 베어링 결함 진단,2021,[],국문 초록 정보 없음,This study presents a novel approach based on convolutional long short-term Memory (ConvLSTM) model to reduce the latency involved in bearing fault diagnosis. Time-series sensor data are segmented into short vectors that are fed sequentially into the model to find spatio-temporal features efficiently. The ConvLSTM model is devised to a many-to-many structure by which the failure can be diagnosed as soon as several consecutive prediction results correspond to the failure condition. The experiments based on the proposed approach show that the latency reduction is as high as 99.3% compared to the 2D-CNN approach.
형광 영상 및 인공지능을 활용한 매개모기 자동분류 기술 개발,2021,"['매개모기', '인공지능', '딥러닝', '영상분석', '합성곱 알고리즘', '형광']",세계적으로 인간에게 감염병 및 바이러스를 가장 많이 매개하는 곤충은 모기이다. 매개 모기에 의한 감염병은 대부분 백신과 치료제가 개발되어있지 않기 때문에 확산 및 피해를 예방하는 것이 매우 중요하다. 매개 모기 발생 추세를 모니터링하여 효과적인 방제를 실시하는 것이 질병 관리에 중요한 방법이다. 현재 감염병 매개모기 발생 모니터링에 대한 방식으로 모기 포집장치가 쓰이고 있지만 단순 개체수 계수로 활용되고 있고 모기 종류별 개체수 확인은 불가능한 실정이다. 본 연구에서는 포집된 모기의 종류 구분을 위해 형광 영상을 활용하였다. 모기에서 발생하는 형광 특성을 측정하기 위해 자외선광원과 고파장투과필터가 장착된 카메라를 활용하였다. 포집 모기에 대한 영상 데이터셋을 구축하고 다양한 인공지능 딥러닝 모델을 적용하여 분류 성능을 확인하고자 하였다. 딥러닝 학습에 사용된 딥러닝 API는 Detectron2이며 Faster R-CNN(Region-Convolutional Neural Network) 딥러닝 알고리즘을 사용하여 모기 종류를 자동으로 분석할 수 있는 자동 탐지 모델을 개발하였다.,다국어 초록 정보 없음
Machine learnings for CVD graphene analysis: From measurement to simulation of SEM images,2021,"['System modeling', 'CVD graphene growth', 'Machine learning', 'SEM prediction']",국문 초록 정보 없음,"In this study, we introduce an approach that applies machine learning (ML) in various procedures topredict graphene growth pattern in chemical vapor deposition (CVD) system. Atfirst, CVD experimentswere conducted to synthesize graphene using CH4 as a precursor on a Cu substrate at high temperatures,to get experimental data for training those models. Then, the size, coverage, domain density, and aspectratio of graphene, which vary depending on the synthesis conditions, were measured and analyzedautomatically by developing a region proposal convolutional neural network (R-CNN). Subsequently, anartificial neural network (ANN) and a support vector machine (SVM) were used to develop surrogatemodels to deduce the correlation between CVD process variables and the measured specifications.Characteristic graphene grains with hexagonal morphology were created using a generative adversarialnetwork (GAN) to imitate the CVD growth. Then, they were modified to have the same size and aspectratio as the predicted values and placed to meet the predicted coverage and domain density. Finally, thepre-generated images were modified using Pix2pix to obtain the same outlook as the experimental SEMimages. As a result, it was possible to simulate graphene synthesis under various CVD condition. Throughnumerous simulations in advance, we were able to identify the experiment condition to synthesizegraphene with the desired morphologies of large grain size and low domain density. Developing aplatform to predict a CVD system for the controlled synthesis of graphene allow us to synthesize thegraphene with high efficiency, saving tremendous amounts of time and expenses."
목재 표면 검사를 위한 기계 학습 적용,2021,[],"최근 딥러닝을 비롯한 기계 학습의 눈부신 발전에 힘입어 많은 연구 분야는 기계 학습을 새로운 연구 방법론으로서 채택하고 있다. 목재 과학에서도 수종 식별, 정량적 해부학, 표면 품질 검사 등 방대한 데이터를 다루거나 노동 집약적인 분야에 기계 학습을 적용하기 위한 연구가 수행되고 있다. 목재의 표면 품질을 평가하기 위한 시각 검사는 숙련된 검사자의 주관적 판단에 의존하고 있으며 반복 작업으로 인한 신체적 피로 및 권태감은 판단 정확도를 감소시키는 요인이 된다. 표면 검사의 정확도 향상 및 연속 공정 도입을 위해 컴퓨터 비전과 기계 학습이 적용되었다. 초기에는 화상에서 수동으로 특징을 추출하는 특징 공학적 기법들이 적용되었다. Semantic segmentation에 기반하여 표면 이미지에서 결함 영역을 추출하고 유형을 분류하는 이 작업은 다수의 연구로부터 좋은 결과가 보고되었으나 사용자의 수동 작업이 여전히 큰 비중을 차지하였다. 최근에는 주로 딥러닝이 표면 검사에 적용되고 있다. Region-based Convolutional Neural Networks(R-CNN) 및 You Only Look Once(YOLO) 시리즈에 기반한 객체 탐지 모델이 표면 검사에 적용되었으며 기존의 특징 공학적 모델을 능가하는 성능이 보고되었다. 컴퓨터 하드웨어의 발전은 더욱더 깊은 backbone 네트워크 사용의 부담을 줄임으로써 성능 향상에 기여하고 있으며 instance segmentation은 표면 결함의 개체별 정확한 분획을 구현한다. 이제는 기계 학습이 목재 과학에서 생소한 분야가 아니다. 인공지능 기반 연구 환경 조성 및 이니셔티브 확장을 위해서는 대형 데이터베이스 구축, 이용 및 인력 양성을 위한 목재 과학 및 산업의 적극적 대응이 필요하다.",다국어 초록 정보 없음
딥러닝 기반 객체 탐지와 후처리를 이용한 선박 탐지의 정확도 향상,2021,"['위성사진', '영상 대비 강화', '심층신경망', '선박 탐지']","위성 영상을 이용한 자동 선박 검출은 세계 최대 규모의 해상에서 이루어지는 어업, 국방, 운송 등 다양한 산업에 적용되는 원격 탐사 기술이다. 본 논문에서 우리는 고해상도 인공위성 영상을 활용한 심층신경망 기반 선박 검출에서 미검출 객체를 줄인 다량의 1차 후보군을 추출하고 해상과 육지영역으로 분할된 이미지를 활용하여 육지 내 오 탐지된 후보를 제외하는 알고리즘을 제안한다. 인공위성 영상을 활용한 심층신경망 기반 객체 검출 알고리즘은 구름이나 큰 파도에 의한 영향, 육지의 지형 및 큰 건축물의 영향, 선박 간 조밀도, 인근 해역에 정착된 선박 등 상황에서 신뢰하기 힘든 탐지 결과를 나타낸다. 우리는 해상 영역이 아닌 육지 영역 내의 지형 및 큰 건축물, 도로 등 선박으로 오 탐지된 객체를 강건하게 제외한다. 제안된 접근 방법은 인공위성 영상 대비 향상 처리, 객체 탐지 알고리즘의 분류기 점수의 통과 기준을 완화, 육지영역 내의 오 탐지 선박 제외 알고리즘으로 구분된다. 영상 대비 강화 기법을 적용하여 높은 해상도를 가진 인공위성 영상을 확보하여 작은 표적 및 복합 재료로 만들어진 선박까지 탐지할 수 있는 능력을 함양한다. 그리고 회전 경계 상자를 이용한 Faster RCNN 기반 객체 탐지기인 Rbox-CNN 모델을 이용하여 미검출 객체를 줄인 다량의 1차 검출 선박 후보군을 추출한다. 마지막으로, 심층신경망 기반 Deeplabv3분할 알고리즘을 활용해 해상과 육지영역 분할 이미지를 확보하고 해상 영역의 선박만을 탐지하기 위한 선별 기준을 수립하여 1차 후보군으로 추출된 검출 선박 중 육지 내의 오 탐지된 선박을 제외한다. 그 결과 육지 내의 건물, 도로, 지형이 선박으로 오 탐지된 객체를 제외하여 해상에 위치한 선박을 최종적으로 검출한다. 더욱이 제안된 방법의 실험 결과는 기존의 선박 검출 알고리즘 성능보다 전체적인 선박 탐지율은 높고 오탐율은 현저히 감소하여 상당히 향상된 탐지 성능을 보였다.",다국어 초록 정보 없음
Keypoint-based Deep Learning Approach for Building Footprint Extraction Using Aerial Images,2021,"['Building footprint extraction', 'Keypoint detection', 'Instance segmentation', 'Deep learning']",국문 초록 정보 없음,"Building footprint extraction is an active topic in the domain of remote sensing, since buildings are a fundamental unit of urban areas. Deep convolutional neural networks successfully perform footprint extraction from optical satellite images. However, semantic segmentation produces coarse results in the output, such as blurred and rounded boundaries, which are caused by the use of convolutional layers with large receptive fields and pooling layers. The objective of this study is to generate visually enhanced building objects by directly extracting the vertices of individual buildings by combining instance segmentation and keypoint detection. The target keypoints in building extraction are defined as points of interest based on the local image gradient direction, that is, the vertices of a building polygon. The proposed framework follows a two-stage, top-down approach that is divided into object detection and keypoint estimation. Keypoints between instances are distinguished by merging the rough segmentation masks and the local features of regions of interest. A building polygon is created by grouping the predicted keypoints through a simple geometric method. Our model achieved an F1-score of 0.650 with an mIoU of 62.6 for building footprint extraction using the OpenCitesAI dataset. The results demonstrated that the proposed framework using keypoint estimation exhibited better segmentation performance when compared with Mask R-CNN in terms of both qualitative and quantitative results."
자율주행을 위한 의미론적 전역 포인트 클라우드 맵 데이터셋 구축,2021,"['LiDAR(라이다)', 'Point Cloud Map(포인트 클라우드 맵)', 'Semantic Segmentation(의미론적 분할)', 'Dataset(데이터셋)', 'Deep Learning(딥러닝)']","최근 자율주행의 핵심은 인지 파트는 다양한 센서를 기반으로 개발되고 있다. 그 중 LiDAR는 정밀한 위치 정보를 제공하고 외부 환경조건에 영향을 적게 받는다는 장점이 있어 이를 이용한 연구가 활발히 이루어지고 있다. 또한 딥러닝의 발전에 따라 뉴럴 네트워크를 이용한 객체 분류, 인식 및 의미론적 분할 등 다양한 task가 수행되고 있다. 포인트 클라우드 의미론적 분할은 가장 높은 수준의 분류로, 모든 포인트에 클래스를 부여하여 풍부한 정보를 제공한다. 지도 학습을 이용한 의미론적 분할은 포인트 별 분류 정답이 표기된 데이터셋이 필수적이다. 하지만 의미론적 분할된 포인트 클라우드 데이터셋은 매우 부족하며 한국의 도로 상태를 반영한 분류 체계를 갖는 데이터셋은 거의 없다. 따라서 ‘자율주행을 위한 의미론적 전역 포인트 클라우드 맵 데이터셋’을 구축하고자 한다. 본 데이터셋의 구축과정은 Fig.1과 같이 진행된다. 첫번째 단계인 logging 과정에서는 데이터 취득 지역을 선정하고, MMS(Mobile Mapping System)를 이용하여 포인트 클라우드 맵을 취득한다. 두번째 단계인 클래스 설계에서는 한국의 도심 환경 특성을 고려하여 연석, 신호등, 터널 내 객체 등을 포함한 분류 체계를 설계한다. 세번째 단계인 semi-auto labeling에서는 어노테이션 소요 비용을 최소화하기 위해 사전학습 된 모델을 사용해 얻은 분류 결과를 수정하는 과정을 거친다. 마지막 단계인 검수 과정에서는 다른 객체로 오분류된 포인트가 있는지 필터링을 통해 확인 후 수정한다. 데이터셋 구축 이후에는 데이터셋의 유효성 검증이 필수적이다. 이를 위해 여러 포인트 클라우드 의미론적 분할 모델을 사용한다. 이때 모델의 특성에 치우치지 않는 결과를 얻기 위해 다양한 프레임워크를 갖는 모델을 선정한다. 3D-CNN 기반, Point-wise MLP 기반, GCN 기반의 모델을 다양하게 선정하고, 각 모델을 구축한 데이터셋으로 학습하여 성능을 도출함으로써 데이터셋의 유효성을 검증한다.",다국어 초록 정보 없음
Question Similarity Measurement of Chinese Crop Diseases and Insect Pests Based on Mixed Information Extraction,2021,"['Text semantic similarity', 'Short text-similarity', 'Agricultural natural language processing', 'Chinese word segmentation']",국문 초록 정보 없음,"The Question Similarity Measurement of Chinese Crop Diseases and Insect Pests (QSM-CCD&IP) aims to judge the user’s tendency to ask questions regarding input problems. The measurement is the basis of the Agricultural Knowledge Question and Answering (Q & A) system, information retrieval, and other tasks. However, the corpus and measurement methods available in this field have some deficiencies. In addition, error propagation may occur when the word boundary features and local context information are ignored when the general method embeds sentences. Hence, these factors make the task challenging. To solve the above problems and tackle the Question Similarity Measurement task in this work, a corpus on Chinese crop diseases and insect pests (CCDIP), which contains 13 categories, was established. Then, taking the CCDIP as the research object, this study proposes a Chinese agricultural text similarity matching model, namely, the AgrCQS. This model is based on mixed information extraction. Specifically, the hybrid embedding layer can enrich character information and improve the recognition ability of the model on the word boundary. The multi-scale local information can be extracted by multi-core convolutional neural network based on multi-weight (MM-CNN). The self-attention mechanism can enhance the fusion ability of the model on global information. In this research, the performance of the AgrCQS on the CCDIP is verified, and three benchmark datasets, namely, AFQMC, LCQMC, and BQ, are used. The accuracy rates are 93.92%, 74.42%, 86.35%, and 83.05%, respectively, which are higher than that of baseline systems without using any external knowledge. Additionally, the proposed method module can be extracted separately and applied to other models, thus providing reference for related research."
