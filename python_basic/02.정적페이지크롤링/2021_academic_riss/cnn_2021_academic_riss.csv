title,date,keywords,abstract,multilingual_abstract
Cross-Domain Text Sentiment Classification Method Based on the CNN-BiLSTM-TE Model,2021,"['Bidirectional Long Short-Term Memory', 'Convolutional Neural Network', 'Deep Learning', 'Sentiment Analysis', 'Topic Extraction']",,"To address the problems of low precision rate, insufficient feature extraction, and poor contextual ability in existing text sentiment analysis methods, a mixed model account of a CNN-BiLSTM-TE (convolutional neural network, bidirectional long short-term memory, and topic extraction) model was proposed. First, Chinese text data was converted into vectors through the method of transfer learning by Word2Vec. Second, local features were extracted by the CNN model. Then, contextual information was extracted by the BiLSTM neural network and the emotional tendency was obtained using softmax. Finally, topics were extracted by the term frequency-inverse document frequency and K-means. Compared with the CNN, BiLSTM, and gate recurrent unit (GRU) models, the CNN-BiLSTM-TE model’s F1-score was higher than other models by 0.0147, 0.006, and 0.0052, respectively. Then compared with CNN-LSTM, LSTM-CNN, and BiLSTM-CNN models, the F1-score was higher by 0.0071, 0.0038, and 0.0049, respectively. Experimental results showed that the CNN-BiLSTM-TE model can effectively improve various indicators in application. Lastly, performed scalability verification through a takeaway dataset, which has great value in practical applications."
WiFi 신호를 활용한 CNN 기반 사람 행동 인식 시스템 설계 및 구현,2021,"['Accelerator', 'CNN', 'FPGA', 'Human Activity Recognition', 'WiFi signal']","기존의 사람 행동 인식 시스템은 웨어러블 센서, 카메라와 같은 장치를 통해 행동을 탐지하였다. 그러나, 이와 같은 방법들은 추가적인 장치와 비용이 요구되고, 특히 카메라 장치의 경우 사생활 침해 문제가 발생한다. 이미 설치되어 있는 WiFi 신호를 사용한다면 해당 문제를 해결할 수 있다는 장점이 있다. 본 논문에서는 WiFi 신호의 채널 상태 정보를 활용한 CNN 기반 사람 행동 인식 시스템을 제안하고, 가속 하드웨어 구조 설계 및 구현 결과를 제시한다. 해당 시스템은 실내 공간에서 학습 중 나타날 수 있는 네 가지 행동에 대해 정의하였고, 그에 대한 WiFi의 채널 상태 정보를 CNN으로 분류하여 평균 정확도는 91.86%를 보였다. 또한, 가속화를 위해 CNN 분류기에서 연산량이 가장 많은 완전 연결 계층에 대한 가속 하드웨어 구조 설계 결과를 제시하였다. FPGA 디바이스 상에서 성능 평가 결과, 기존 software 기반 시스템 대비 4.28배 빠른 연산 시간을 보임을 확인하였다.","Existing human activity recognition systems detect activities through devices such as wearable sensors and cameras. However, these methods require additional devices and costs, especially for cameras, which cause privacy issue. Using WiFi signals that are already installed can solve this problem. In this paper, we propose a CNN-based human activity recognition system using channel state information of WiFi signals, and present results of designing and implementing accelerated hardware structures. The system defined four possible behaviors during studying in indoor environments, and classified the channel state information of WiFi using convolutional neural network (CNN), showing and average accuracy of 91.86%. In addition, for acceleration, we present the results of an accelerated hardware structure design for fully connected layer with the highest computation volume on CNN classifiers. As a result of performance evaluation on FPGA device, it showed 4.28 times faster calculation time than software-based system."
Sentienl-1 SAR 영상을 활용한 유류 분포특성과 CNN 구조에 따른 유류오염 탐지모델 성능 평가,2021,"['Sentinel-1 SAR', 'Oil Spill Detection', 'CNN', 'U-net', 'Oil spill distribution characteristics']",,"Detecting oil spill area using statistical characteristics of SAR images has limitations in that classification algorithm is complicated and is greatly affected by outliers. To overcome these limitations, studies using neural networks to classify oil spills are recently investigated. However, the studies to evaluate whether the performance of model shows a consistent detection performance for various oil spill cases were insufficient. Therefore, in this study, two CNNs (Convolutional Neural Networks) with basic structures (Simple CNN and U-net) were used to discover whether there is a difference in detection performance according to the structure of CNN and distribution characteristics of oil spill. As a result, through the method proposed in this study, the Simple CNN with contracting path only detected oil spill with an F1 score of 86.24% and U-net, which has both contracting and expansive path showed an F1 score of 91.44%. Both models successfully detected oil spills, but detection performance of the U-net was higher than Simple CNN. Additionally, in order to compare the accuracy of models according to various oil spill cases, the cases were classified into four different categories according to the spatial distribution characteristics of the oil spill (presence of land near the oil spill area) and the clarity of border between oil and seawater. The Simple CNN had F1 score values of 85.71%, 87.43%, 86.50%, and 85.86% for each category, showing the maximum difference of 1.71%. In the case of U-net, the values for each category were 89.77%, 92.27%, 92.59%, and 92.66%, with the maximum difference of 2.90%. Such results indicate that neither model showed significant differences in detection performance by the characteristics of oil spill distribution. However, the difference in detection tendency was caused by the difference in the model structure and the oil spill distribution characteristics. In all four oil spill categories, the Simple CNN showed a tendency to overestimate the oil spill area and the U-net showed a tendency to underestimate it. These tendencies were emphasized when the border between oil and seawater was unclear."
고성능 CNN 기반 정밀 요검사 판별 기법,2021,"['CNN', 'Urinalysis', 'Image Discrimination']","요검사는 물리적 성상 검사, 화학적 검사, 현미경 검사 세 가지가 있다. 이 중에서 화학적 요검사는 일반인이 쉽게 접근하는 방법으로 요검사지의 화학반응을 눈으로 표준비색표와 비교하거나 휴대용 요검사기를 별도로 구매하여 검사를 진행한다. 현재는 스마트폰의 보급이 대중화되어 스마트폰을 활용한 요검사 서비스 연구가 높아지고 있다. 요검사 스크리닝 애플리케이션은 스마트폰을 활용한 요검사 서비스 중 하나이다. 그러나 요검사 스크리닝 애플리케이션으로 촬영한 요검사 패드 RGB 값은 조명영향으로 인해 큰 편차가 발생한다. 요검사 패드 RGB 값의 편차는 요검사 판별의 정확도를 떨어뜨린다. 따라서 본 논문에서는 스마트폰 기반 요검사 스크리닝 애플리케이션으로 촬영한 요검사지를 검사 항목별 요검사 패드로 분류한 후 CNN을 통해 요검사 패드 이미지 판별의 정확도를 높인다. 요검사지는 다양한 배경에서 촬영하여 CNN 이미지를 생성하였으며 ResNet-50 CNN 모델을 사용하여 요검사 판별을 분석하였다.",
산업용 로봇 원격제어를 위한 CNN기반 손 제스처 인식 방법,2021,"['Industrial robot', 'ROS', 'EMG', 'Teleoperation', 'CNN']",,"This paper introduces a teleoperation control system of an industrial robot based on hand gestures using the convolutional neural network (CNN). The proposed system employs the gesture data obtained from an EMG sensor and considers a CNN-based deep learning method. Using the proposed CNN model, we develop a real-time teleoperation control system for the industrial robot. Finally, it is confirmed that the proposed system is reliable in real system since it can be applied to the teleoperation control of a real industrial robot."
CNN 기반 딥러닝을 이용한 인공지지체의 외형 변형 불량 검출 모델에 관한 연구,2021,"['3D Printing Scaffold', 'CNN', 'Deep Learning', 'Defect Detection Model', 'Scaffold Warpage']",,"Warpage defect detecting of scaffold is very important in biosensor production. Because warpaged scaffold cause problem in cell culture. Currently, there is no detection equipment to warpaged scaffold. In this paper, we produced detection model for shape warpage detection using deep learning based CNN. We confirmed the shape of the scaffold that is widely used in cell culture. We produced scaffold specimens, which are widely used in biosensor fabrications. Then, the scaffold specimens were photographed to collect image data necessary for model manufacturing. We produced the detecting model of scaffold warpage defect using Densenet among CNN models. We evaluated the accuracy of the defect detection model with mAP, which evaluates the detection accuracy of deep learning. As a result of model evaluating, it was confirmed that the defect detection accuracy of the scaffold was more than 95%."
도로교통 이머징 리스크 탐지를 위한 AutoML과 CNN 기반 소프트 보팅 앙상블 분류 모델,2021,[],겨울철 도로 결빙으로 인한 사고는 대부분 큰 사고로 이어진다. 이는 운전자가 도로의 결빙을 사전에 자각하기 어렵기 때문이다. 본 연구에서는 AutoML과 CNN의 앙상블 모델을 이용하여 도로교통 이머징 리스크를 정확하게 탐지하는 방법을 연구한다. 비정형 데이터인 이미지를 이용한 CNN 이미지 특징 추출 기반 도로교통 이머징 리스크 분류 모델과 정형 데이터인 기상 데이터를 이용한 AutoML 기반 도로교통 이머징 리스크 분류 모델을 각각 학습시킨다. 그 후 모델들에서 도출된 확률값을 입력하여 CNN 기반 분류 모델을 보완하도록 앙상블 모델을 설계한다. 이를 통해 도로교통 이머징 리스크 분류 성능을 향상하고 더 정확하고 빠르게 운전자에게 경고하여 안전한 주행이 가능하도록 한다.,
CNN을 활용한 Tor 네트워크 트래픽 분류,2021,"['Tor', 'CNN', 'Binary Classification', 'Multiclass classification']","Onion Router라고 알려진 Tor는 강한 익명성을 보장하기 때문에 각종 범죄행위뿐만 아니라 신속한 포트 검색 및 인증정보의 외부 유출 등 해킹 시도에도 활발하게 이용되고 있다. 따라서 범죄 시도를 조기에 차단하고 해킹으로부터 조직의 정보시스템을 안전하게 보호하기 위해서는 Tor 트래픽의 빠르고 정확한 탐지가 상당히 중요하다. 이에 본 논문에서는 CNN(Convolutional Neural Network)을 기반으로 Tor 트래픽을 탐지하고 트래픽의 유형을 분류하는 분류모델을 제안한다. 제안하는 분류모델의 성능 검증에는 UNB Tor 2016 데이터세트가 사용되었다. 실험을 진행한 결과, 제안하는 접근방법은 Tor 및 Non-Tor 트패픽을 탐지하는 이진분류에서는 99.98%, Tor 트래픽의 유형을 구분하는 다중분류에서는 97.27%의 정확도를 보여주었다.",
하천 홍수 예측을 위한 CNN 기반의 수위 예측 모델 구현,2021,[],"수해는 홍수나 해일을 유발하여 막대한 인명과 재산의 피해를 초래할 수 있다. 이에 대해 홍수 예측을 통한 빠른 대피 결정으로 피해를 줄일 수 있으며, 해당 분야에서는 시계열 데이터를 활용하여 홍수를 예측하려는 연구들도 많이 진행되고 있다. 본 논문에서는 CNN 기반의 시계열 예측 모델을 제안한다. 하천의 수위와 강수량을 사용하여 CNN 기반의 수위 예측 모델을 구현하였고, 시계열 예측에 많이 사용되는 LSTM, GRU 모델과 비교하여 성능을 확인하였다. 또한 입력 데이터의 크기에 따른 성능 차이를 확인하여 보완해야 할 점을 찾을 수 있었고, LSTM과 GRU보다 더 좋은 성능을 낼 수 있다는 것을 확인하였다. 이를 통해 홍수 예측을 위한 초기 연구로서 활용할 수 있을 것으로 사료된다.",
유도전동기의 고정자 고장 진단을 위한 CNN의 활성화 함수 선정,2021,"['ReLu', '활성화 함수', '행렬화 이미지', '컨볼루션 인공 신경망', '3상 유도 전동기', '고장 진단', 'ReLu', 'Matrix image', 'CNN', '3-phase induction motor', 'Fault Diagnosis']","본 논문에서는 유도전동기 고정자 고장 진단에 있어서 활성화 함수가 미치는 영향을 분석하여 효율적인 CNN 활용 방법을 제안하였다. 일반적으로 유도전동기 고정자 고장 진단의 주된 목적은 미세한 턴 단락을 빠르게 진단함으로 고장을 미리 방지함에 있다. 이에 활성화 함수 활용에 있어서 전반적인 고정자 고장에는 ReLu가 우수성을 보임을 알 수 있었으나, 미세한 턴 단락인 2턴 단락에 있어서는 Sigmoid 함수가 ReLu 함수보다 진단의 정확도에 있어서 23.23% 유용함을 실험을 통해 확인할 수 있었다.","In this paper, we propose an efficient CNN application method by analyzing the effect of activation function on the failure diagnosis of the inductive motor stator. Generally, the main purpose of the inductive motor stator failure diagnosis is to prevent the failure by rapidly diagnosing the minute turn short. In the application of activation function, experiments show that the Sigmoid function is 23.23% more useful in accuracy of diagnosis than the ReLu function, although it is shown that ReLu has superiority in overall fixer failure in utilizing the activation function."
CNN의 SoftMax 연산을 위한 연속 근사 방식의 로그 연산 회로,2021,"['Accelerator', 'CNN', 'Logarithm', 'SoftMax']",,"In a CNN for image classification, a SoftMax layer is usually placed at the end. The exponentinal and logarithmic operations in the SoftMax layer are not adequate to be implemented in an accelerator circuit. The operations are usually implemented with look-up tables, and the exponential operation can be implemented in an iterative method. This paper proposes a successive approximation method to calculate a logarithm to remove a very large look-up table. By substituing the large table with two very small tables, the circuit can be reduced much. The experimental results show that the 85% area reduction can be reached with a small error degradation."
CNN기반의 청각장애인을 위한 수화번역 프로그램,2021,"['수화', '청각장애', 'AlexNet', 'U-Net', '의사소통', 'Sign Language', 'Deaf', 'AlexNet', 'U-Net', 'Communication']","사회가 점점 발전하면서 의사소통 방법이 다양한 형태로 발전하고 있다. 그러나 발전한 의사소통은 비장애인을 위한 방법이며, 청각장애인에게는 아무런 영향을 미치지 않는다. 따라서 본 논문에서는 청각장애인의 의사소통을 돕기 위한 CNN 기반의 수화번역 프로그램을 설계 및 구현한다. 수화번역 프로그램은 웹캠을 통해 입력된 수화 영상 데이터를 기반으로 의미에 맞게 번역한다. 수화번역 프로그램은 직접 제작한 24,000개의 한글 자모음 데이터를 사용하였으며, 효과적인 분류모델의 학습을 위해 U-Net을 통한 Segmentation을 진행한다. 전처리가 적용된 데이터는 19,200개의 Training Data와 4,800개의 Test Data를 통하여 AlexNet을 기반으로 학습을 진행한다. 구현한 수화번역 프로그램은 ‘ㅋ’이 97%의 정확도와 99%의 F1-Score로 모든 수화데이터 중에서 가장 우수한 성능을 나타내었으며, 모음 데이터에서는 ‘ㅣ’가 94%의 정확도와 95.5%의 F1-Score로 모음 데이터 중에서 가장 높은 성능을 보였다.","Society is developing more and more, and communication methods are developing in many ways. However, developed communication is a way for the non-disabled and has no effect on the deaf. Therefore, in this paper, a CNN-based sign language translation program is designed and implemented to help deaf people communicate. Sign language translation programs translate sign language images entered through WebCam according to meaning based on data. The sign language translation program uses 24,000 pieces of Korean vowel data produced directly and conducts U-Net segmentation to train effective classification models. In the implemented sign language translation program, ’ㅋ‘ showed the best performance among all sign language data with 97% accuracy and 99% F1-Score, while ’ㅣ‘ showed the highest performance among vowel data with 94% accuracy and 95.5% F1-Score."
시계열 데이터를 기반으로 한 CNN의 성능 향상 방법에 대한 비교 연구,2021,"['Artificial intelligence', 'Convolutional neural network', 'Deep learning', 'Image classification', 'Human activity recognition', 'Time series data']","인간 행동 인식 기술은 전통적으로 서포트 벡터 머신과 같은 기계 학습 기술 분야이다. 그리고 딥 러닝의 발전과 함께 순환 신경망을 사용하여 이와 같은 작업이 수행되고 있다. 최근에는 시계열 데이터를 이미지로 변환한 후 CNN (Convolutional Neural Networks)에 적용할 수 있음이 확인되었다. 저자는 시계열 기반 CNN 신경망에서 정밀도 향상을 위해 에지 향상, 선 너비 제어 및 색상 코드 최적화와 같은 몇 가지 방법을 제안했다. 엣지 강화 방법은 사물을 인식한다는 것은 사물의 형태를 본다는 직관에서 나온 아이디어이다. 또한 시계열 데이터의 데이터를 이미지로 변환 할 때, 빠른 정착 시간과 높은 정확도를 포함하여 최상의 성능을 얻을 수 있는 최적의 선폭이 존재할 수 있고, 이것이 선폭 제어 방법을 고안하게 되었다. 색상 코드 최적화는 보색으로부터 동기가 부여되었는데, 색상 코드 최적화는 색상 공간에서 색상 거리를 최대화하여 얻을 수 있다. 보색은 이미지를 더 선명하고 모양으로 만들어 신경망의 성능을 향상시킨다. 이 논문에서는 위의 세 가지 방법을 자세히 비교하고 평가한다. 실험 결과로부터 시계열 데이터의 이미지 분류 작업에서 선폭 제어가 가장 효과적인 기법이며 색상 코드 최적화도 효과적인 방법이었다. 이 논문에서 선폭 제어는 원시 정보가 시계열 데이터인 선이기 때문에 효과가 떨어졌다. 그러나 원시 데이터에 이미지와 같은 공간 정보가 있는 경우 f1-score를 향상시키는 데 에지 강화 기법이 훨씬 더 효과적일 것이다.",
안면 연령 예측을 위한 CNN기반의 히트 맵을 이용한 랜드마크 선정,2021,[],,"The purpose of this study is to improve the performance of the artificial neural network system for facial image analysis through the image landmark selection technique. For landmark selection, a CNN-based multi-layer ResNet model for classification of facial image age is required. From the configured ResNet model, a heat map that detects the change of the output node according to the change of the input node is extracted. By combining a plurality of extracted heat maps, facial landmarks related to age classification prediction are created. The importance of each pixel location can be analyzed through facial landmarks. In addition, by removing the pixels with low weights, a significant amount of input data can be reduced."
The Method for Generating Recommended Candidates through Prediction of Multi-Criteria Ratings Using CNN-BiLSTM,2021,"['Bidirectional Long Short-Term Memory', 'BiLSTM', 'Convolutional Neural Network', 'CNN', 'Multi-Criteria Recommendation System', 'Recommendation System']",,"To improve the accuracy of the recommendation system, multi-criteria recommendation systems have been widely researched. However, it is highly complicated to extract the preferred features of users and items from the data. To this end, subjective indicators, which indicate a user’s priorities for personalized recommendations, should be derived. In this study, we propose a method for generating recommendation candidates by predicting multi-criteria ratings from reviews and using them to derive user priorities. Using a deep learning model based on convolutional neural network (CNN) and bidirectional long short-term memory (BiLSTM), multi-criteria prediction ratings were derived from reviews. These ratings were then aggregated to form a linear regression model to predict the overall rating. This model not only predicts the overall rating but also uses the training weights from the layers of the model as the user’s priority. Based on this, a new score matrix for recommendation is derived by calculating the similarity between the user and the item according to the criteria, and an item suitable for the user is proposed. The experiment was conducted by collecting the actual “TripAdvisor” dataset. For performance evaluation, the proposed method was compared with a general recommendation system based on singular value decomposition. The results of the experiments demonstrate the high performance of the proposed method."
1D CNN과 기계 학습을 사용한 낙상 검출,2021,"['Machine Learning', 'Deep Learning', 'Fall Detection', '1D Convolutional Neural Network', '기계 학습', '심층 학습', '낙상 검출', '1차원 합성곱 신경망']",,"In this paper, fall detection using individual wearable devices for older people is considered. To design a low-cost wearable device for reliable fall detection, we present a comprehensive analysis of two representative models. One is a machine learning model composed of a decision tree, random forest, and Support Vector Machine(SVM). The other is a deep learning model relying on a one-dimensional(1D) Convolutional Neural Network(CNN). By considering data segmentation, preprocessing, and feature extraction methods applied to the input data, we also evaluate the considered models’ validity. Simulation results verify the efficacy of the deep learning model showing improved overall performance."
사과 품종 분류를 위한 CNN기반 모델링 및 분류 기법 연구,2021,"['스마트팜', '딥러닝', 'ResNet', '신경망', 'Smart Farm', 'Deep Learning', 'ResNet', 'Convolution Neural Network']","농장주들이 과일을 분류하는 데까지의 시간소모를 줄이고 향후 과일의 등급 판정 기준을 정량화하기 위하여 우리나라의 대표적인 과일이며 다양한 품종을 가지고 있는 사과를 대상으로 신경망 기반 분류 자동화 시스템을 제안한다. 컨베이어 벨트를 통해 지나가는 객체를 카메라모듈로 촬영하여 이를 통신 및 연산을 수행하는 라즈베리파이 기반 시스템을 설계, 구현한다. 깊은 네트워크와 나머지(residual)를 학습하는 ResNet 기반 알고리즘이 구동되는 딥러닝 서버와는 SSH통신을 통해 이미지와 학습된 모델을 주고받는다. 향후 품종뿐만 아니라 등급까지 분류 자동화한다면 다양한 품종의 과일을 대상으로 한 출하 자동화 시스템으로의 적용이 가능하다.","This paper propose a neural network-based classification automation system for apples, which are representative fruits of Korea and have a variety of varieties, in order to reduce the consumption of time for farmers to classify fruits and to quantify the criteria for grading the fruits. Raspberry Pi-based system that communicates and performs calculations by photographing objects passing through a conveyor belt with a camera module is designed and implemented. Then it receive the trained model using ResNet-based algorithm that runs on the deep-learning server. In the future, if classifying not only varieties but also grades is automated, it can be applied as a shipping automation system targeting various varieties of fruit."
CNN 잡음감쇠기에서 필터 수의 최적화,2021,"['잡음 감쇠', '심층 학습', '합성곱 신경망', '오차 역전파', '평균 제곱 오차', '평균 절대값 오차', 'Noise Attenuation', 'Deep Learning', 'CNN', 'Error Back Propagation', 'MSE', 'MAE']","본 논문은 잡음감쇠기에서 CNN(Convolutional Neural Network) 계층의 필터 수가 성능에 미치는 영향을 연구하였다 이 시스템은 적응필터 대신 신경망 예측필터를 이용하며 심층학습방법으로 잡음을 감쇠한다. 64-뉴런, 16-커널 CNN 필터와 오차 역전파 알고리즘을 이용하여 잡음이 포함된 음성신호로부터 음성을 추정한다. 본 연구에서 필터 수에 대한 잡음감쇠기의 성능을 검증하기 위하여 Keras 라이브러리를 사용한 프로그램을 작성하고 시뮬레이션을 실시하였다. 시뮬레이션 결과, 본 시스템은 필터 수가 16일 때 MSE(Mean Squared Error) 및 MAE(Mean Absolute Error) 값이 가장 작은 것으로 나타났으며 필터가 4개 일 때 성능이 가장 낮은 것을 볼 수 있다. 그리고 필터가 8개 이상이 되면 필터 수에 따라 MSE 및 MAE 값이 크게 차이나지 않는 것을 보여주었다. 이러한 결과로부터 음성신호의 주요 특징을 표현하기 위해서는 약 8개 이상의 필터를 사용해야 한다는 것을 알 수 있다.","This paper studies the effect of the number of filters in the CNN (Convolutional Neural Network) layer on the performance of a noise attenuator. Speech is estimated from a noised speech signal using a 64-neuron, 16-kernel CNN filter and an error back-propagation algorithm. In this study, in order to verify the performance of the noise attenuator with respect to the number of filters, a program using Keras library was written and simulation was performed. As a result of simulation, it can be seen that this system has the smallest MSE (Mean Squared Error) and MAE (Mean Absolute Error) values when the number of filters is 16, and the performance is the lowest when there are 4 filters. And when there are more than 8 filters, it was shown that the MSE and MAE values do not differ significantly depending on the number of filters. From these results, it can be seen that about 8 or more filters must be used to express the characteristics of the speech signal."
뇌파의 중첩 분할에 기반한 CNN 앙상블 모델을 이용한 뇌전증 발작 검출,2021,"['Epileptic Seizure', 'EEG', 'CNN', 'Ensemble Model', '뇌전증 발작', '뇌파', '합성곱 신경망', '앙상블 모델']",,"As the diagnosis using encephalography(EEG) has been expanded, various studies have been actively performed for classifying EEG automatically. This paper proposes a CNN model that can effectively classify EEG signals acquired from healthy persons and patients with epilepsy. We segment the EEG signals into sub-signals with smaller dimension to augment the EEG data that is necessary to train the CNN model. Then the sub-signals are segmented again with overlap and they are used for training the CNN model. We also propose ensemble strategy in order to improve the classification accuracy. Experimental result using public Bonn dataset shows that the CNN can detect the epileptic seizure with the accuracy above 99.0%. It also shows that the ensemble method improves the accuracy of 3-class and 5-class EEG classification."
CNN 추론 연산 가속기를 위한 곱셈기 최적화 설계,2021,['AI'],,"Recently, FPGA-based AI processors are being studied actively. Deep convolutional neural networks (CNN) are basic computational structures performed by AI processors and require a very large amount of multiplication. Considering that the multiplication coefficients used in CNN inference operation are all constants and that an FPGA is easy to design a multiplier tailored to a specific coefficient, this paper proposes a methodology to optimize the multiplier. The method utilizes 2's complement and distributive law to minimize the number of bits with a value of 1 in a multiplication coefficient, and thereby reduces the number of required stacked adders. As a result of applying this method to the actual example of implementing CNN in FPGA, the logic usage is reduced by up to 30.2% and the propagation delay is also reduced by up to 22%. Even when implemented with an ASIC chip, the hardware area is reduced by up to 35% and the delay is reduced by up to 19.2%."
Pointwise CNN for 3D Object Classification on Point Cloud,2021,"['Point Clouds', 'Pointwise CNN', '3D Object Classification']",,"Three-dimensional (3D) object classification tasks using point clouds are widely used in 3D modeling, face recognition, and robotic missions. However, processing raw point clouds directly is problematic for a traditional convolutional network due to the irregular data format of point clouds. This paper proposes a pointwise convolution neural network (CNN) structure that can process point cloud data directly without preprocessing. First, a 2D convolutional layer is introduced to percept coordinate information of each point. Then, multiple 2D convolutional layers and a global max pooling layer are applied to extract global features. Finally, based on the extracted features, fully connected layers predict the class labels of objects. We evaluated the proposed pointwise CNN structure on the ModelNet10 dataset. The proposed structure obtained higher accuracy compared to the existing methods. Experiments using the ModelNet10 dataset also prove that the difference in the point number of point clouds does not significantly influence on the proposed pointwise CNN structure."
MAC과 Pooling Layer을 최적화시킨 소형 CNN 가속기 칩,2021,['SoC'],,"This paper proposes a CNN accelerator which is optimized Pooling layer operation incorporated in Multiplication And Accumulation(MAC) to reduce the memory size. For optimizing memory and data path circuit, the quantized 8bit integer weights are used instead of 32bit floating-point weights for pre-training of MNIST data set. To reduce chip area, the proposed CNN model is reduced by a convolutional layer, a 4*4 Max Pooling, and two fully connected layers. And all the operations use specific MAC with approximation adders and multipliers. 94% of internal memory size reduction is achieved by simultaneously performing the convolution and the pooling operation in the proposed architecture. The proposed accelerator chip is designed by using TSMC65nmGP CMOS process. That has about half size of our previous paper, 0.8*0.9 = 0.72mm<sup>2</sup>. The presented CNN accelerator chip achieves 94% accuracy and 77us inference time per an MNIST image."
얼굴 열화상 기반 감정인식을 위한 CNN 학습전략,2021,"['얼굴 감정인식', '열화상', 'CNN 학습전략', '분할 정복법', 'Facial emotion recognition', 'Thermal image', 'CNN training strategy', 'Divide and Conquer']","감정인식은 응용 분야의 다양성으로 많은 연구가 이루어지고 있는 기술이며, RGB 영상은 물론 열화상을이용한 감정인식의 필요성도 높아지고 있다. 열화상의 경우는 RGB 영상과 비교해 조명 문제에 거의 영향을받지 않는 장점이 있으나 낮은 해상도로 성능 높은 인식 기술을 필요로 한다. 본 논문에서는 얼굴 열화상 기반 감정인식의 성능을 높이기 위한 Divide and Conquer 기반의 CNN 학습전략을 제안하였다. 제안된 방법은먼저 분류가 어려운 유사 감정 클래스를 confusion matrix 분석을 통해 동일 클래스 군으로 분류하도록 학습시키고, 다음으로 동일 클래스 군으로 분류된 감정 군을 실제 감정으로 다시 인식하도록 문제를 나누어서 해결하는 방법을 사용하였다. 실험을 통하여, 제안된 학습전략이 제시된 모든 감정을 하나의 CNN 모델에서 인식하는 경우보다 모든 실험에서 높은 인식성능을 보이는 것을 확인하였다.",
Two-stage Deep Learning Model with LSTM-based Autoencoder and CNN for Crop Classification Using Multi-temporal Remote Sensing Images,2021,"['Autoencoder', 'Convolutional neural network', 'Crop classification', 'Long short-term memory', 'Multi-temporal images']",,"This study proposes a two-stage hybrid classification model for crop classification using multi-temporal remote sensing images; the model combines feature embedding by using an autoencoder (AE) with a convolutional neural network (CNN) classifier to fully utilize features including informative temporal and spatial signatures. Long short-term memory (LSTM)-based AE (LAE) is fine-tuned using class label information to extract latent features that contain less noise and useful temporal signatures. The CNN classifier is then applied to effectively account for the spatial characteristics of the extracted latent features. A crop classification experiment with multi-temporal unmanned aerial vehicle images is conducted to illustrate the potential application of the proposed hybrid model. The classification performance of the proposed model is compared with various combinations of conventional deep learning models (CNN, LSTM, and convolutional LSTM) and different inputs (original multi-temporal images and features from stacked AE). From the crop classification experiment, the best classification accuracy was achieved by the proposed model that utilized the latent features by fine-tuned LAE as input for the CNN classifier. The latent features that contain useful temporal signatures and are less noisy could increase the class separability between crops with similar spectral signatures, thereby leading to superior classification accuracy. The experimental results demonstrate the importance of effective feature extraction and the potential of the proposed classification model for crop classification using multi-temporal remote sensing images."
CNN 모델을 이용한 프로그램 코드 변경 예측,2021,[],,"A software system is required to change during its life cycle due to various requirements such as adding functionalities, fixing bugs, and adjusting to new computing environments. Such program code modification should be considered as carefully as a new system development becase unexpected software errors could be introduced. In addition, when reusing open source programs, we can expect higher quality software if code changes of the open source program are predicted in advance. This paper proposes a Convolutional Neural Network (CNN)-based deep learning model to predict source code changes. In this paper, the prediction of code changes is considered as a kind of a binary classification problem in deep learning and labeled datasets are used for supervised learning. Java projects and code change logs are collected from GitHub for training and testing datasets. Software metrics are computed from the collected Java source code and they are used as input data for the proposed model to detect code changes. The performance of the proposed model has been measured by using evaluation metrics such as precision, recall, F1-score, and accuracy. The experimental results show the proposed CNN model has achieved 95% in terms of F1-Score and outperformed the multilayer percept-based DNN model whose F1-Score is 92%."
Efficient Visual Place Recognition by Adaptive CNN Landmark Matching,2021,"['visual place recognition', 'CNN', 'adaptive', 'landmark', 'matching']",,"Visual place recognition (VPR) is a fundamental yet challenging task of mobile robot navigation and localization. The existing VPR methods are usually based on some pairwise similarity of image descriptors, so they are sensitive to visual appearance change and also computationally expensive. This paper proposes a simple yet effective four-step method that achieves adaptive convolutional neural network (CNN) landmark matching for VPR. First, based on the features extracted from existing CNN models, the regions with higher significance scores are selected as landmarks. Then, according to the coordinate positions of potential landmarks, landmark matching is improved by removing mismatched landmark pairs. Finally, considering the significance scores obtained in the first step, robust image retrieval is performed based on adaptive landmark matching, and it gives more weight to the landmark matching pairs with higher significance scores. To verify the efficiency and robustness of the proposed method, evaluations are conducted on standard benchmark datasets. The experimental results indicate that the proposed method reduces the feature representation space of place images by more than 75% with negligible loss in recognition precision. Also, it achieves a fast matching speed in similarity calculation, satisfying the real-time requirement."
CNN 알고리즘을 이용한 인공지지체의 3D프린터 출력 시 실시간 출력 불량 탐지 시스템에 관한 연구,2021,"['3D Printing Scaffold', 'Defect Shape Comparison', 'Densenet Algorithm', 'Real-Time Detection', 'Scaffold Defect Detection']",,"Scaffold is used to produce bio sensor. Scaffold is required high dimensional accuracy. 3D printer is used to manufacture scaffold. 3D printer can't detect defect during printing. Defect detection is very important in scaffold printing. Real-time defect detection is very necessary on industry. In this paper, we proposed the method for real-time scaffold defect detection. Real-time defect detection model is produced using CNN(Convolution Neural Network) algorithm. Performance of the proposed model has been verified through evaluation. Real-time defect detection system are manufactured on hardware. Experiments were conducted to detect scaffold defects in real-time. As result of verification, the defect detection system detected scaffold defect well in real-time."
CNN 기반의 준지도학습을 활용한 GPR 이미지 분류,2021,"['GPR', '이미지 분류', 'CNN', '준지도학습', '이미지 클러스터링', 'Image classification', 'Semi-supervised learning', 'Image clustering']",,"GPR data is used for underground exploration. The data gathered are interpreted by experts based on experience as the underground facilities often reflect GPR. In addition, GPR data are different in the noise and characteristics of the data depending on the equipment, environment, etc. This often results in insufficient data with accurate labels. Generally, a large amount of training data have to be obtained to apply CNN models that exhibit high performance in image classification problems. However, due to the characteristics of GPR data, it makes difficult to obtain sufficient data. Finally, this makes neural networks unable to learn based on general supervised learning methods.This paper proposes an image classification method considering data characteristics to ensure that the accuracy of each label is similar. The proposed method is based on semi-supervised learning, and the image is classified using clustering techniques after extracting the feature values of the image from the neural network. This method can be utilized not only when the amount of the labeled data is insufficient, but also when labels that depend on the data are not highly reliable."
CNN 기법의 이미지 학습을 통한 팔굽혀펴기 자세 정확도 측정,2021,"['Image processing', 'Convolution Neural Network', 'Posture Measurement', 'Push-up', 'Machine Learning']",,"Push-ups are one of the body exercises that can be easily measured anytime, anywhere. As one of the most widely used techniques as a test tool for evaluating physical strength, they are broadly used in various fields, especially in fields that require physical ability to estimate, such as military, police, and firefighters. However, social distancing is currently being implemented, and the issue of fairness has been steadily raised due to subtle differences between measurement. Accordingly, in this paper, the correct posture for each individual was photographed and learned by a high-performance computer, and the result was derived by comparing it with the case of performing the incorrect posture of the individual. If method is introduced into the physical fitness evaluation through the proposed method, the individual takes the correct posture and learns the photographed photo, and measures the posture with several images taken during a given time. Through this, it is possible to measure more objectively because it measures with the merit that can be measured even in the present situation and with one's correct posture."
CNN 모델의 최적 양자화를 위한 웹 서비스 플랫폼,2021,"['Convolutional Neural Network', 'Deep Learning Accelerator', 'Quantization', 'Web Service']",,"Low-end IoT devices do not have enough computation and memory resources for DNN learning and inference. Integer quantization of real-type neural network models can reduce model size, hardware computational burden, and power consumption. This paper describes the design and implementation of a web-based quantization platform for CNN deep learning accelerator chips. In the web service platform, we implemented visualization of the model through a convenient UI, analysis of each step of inference, and detailed editing of the model. Additionally, a data augmentation function and a management function of files that store models and inference intermediate results are provided. The implemented functions were verified using three YOLO models."
고성능 CNN 기반 지정맥 인증 시스템 구현,2021,"['AI', 'Biometric authentication', 'Finger vein recognizer']",,"Biometric technology using finger veins is receiving a lot of attention due to its high security, convenience and accuracy. And the recent development of deep learning technology has improved the processing speed and accuracy for authentication. However, the training data is a subset of real data not in a certain order or method and the results are not constant. so the amount of data and the complexity of the artificial neural network must be considered. In this paper, the deep learning model of Inception-Resnet-v2 was used to improve the high accuracy of the finger vein recognizer and the performance of the authentication system, We compared and analyzed the performance of the deep learning model of DenseNet-201. The simulations used data from MMCBNU_6000 of Jeonbuk National University and finger vein images taken directly. There is no preprocessing for the image in the finger vein authentication system, and the results are checked through EER."
콘볼루션 신경망(CNN)과 다양한 이미지 증강기법을 이용한 혀 영역 분할,2021,"['Tongue segmentation', 'Tongue diagnosis', 'Image augmentation', 'Transfer learning', 'Convolutional neural network']",,"In Korean medicine, tongue diagnosis is one of the important diagnostic methods for diagnosing abnormalities in the body. Representative features that are used in the tongue diagnosis include color, shape, texture, cracks, and tooth marks. When diagnosing a patient through these features, the diagnosis criteria may be different for each oriental medical doctor, and even the same person may have different diagnosis results depending on time and work environment. In order to overcome this problem, recent studies to automate and standardize tongue diagnosis using machine learning are continuing and the basic process of such a machine learning-based tongue diagnosis system is tongue segmentation. In this paper, image data is augmented based on the main tongue features, and backbones of various famous deep learning architecture models are used for automatic tongue segmentation. The experimental results show that the proposed augmentation technique improves the accuracy of tongue segmentation, and that automatic tongue segmentation can be performed with a high accuracy of 99.12%."
간병 로봇을 위한 합성곱 신경망 (CNN) 기반 의약품 인식기 설계,2021,"['Convolutional Neural Network', 'Medicine classification', 'EfficientNet', 'Nursing robot', 'Autonomous mobile robot', 'Collaborative robot']",,"Our final goal is to implement nursing robots that can recognize patient's faces and their medicine on prescription. They can help patients to take medicine on time and prevent its abuse for recovering their health soon. As the first step, we proposed a medicine classifier with a low computational network that is able to run on embedded PCs without GPU in order to be applied to universal nursing robots. We confirm that our proposed model called MedicineNet achieves an 99.99% accuracy performance for classifying 15 kinds of medicines and background images. Moreover, we realize that the calculation time of our MedicineNet is about 8 times faster than EfficientNet-B0 which is well known as ImageNet classification with the high performance and the best computational efficiency."
잡음과 스펙트럼 이동에 강인한 CNN 기반 라만 분광 알고리즘,2021,"['Raman Spectroscopy', 'Convolutional Neural Network', 'Machine Learning', 'Spectral Shift Robustness', 'Noise Robustness', '라만 분광기', '합성곱 신경망', '기계학습', '스펙트럼 이동 강인성', '잡음 강인성']",,"Raman spectroscopy is an equipment that is widely used for classifying chemicals in chemical defense operations. However, the classification performance of Raman spectrum may deteriorate due to dark current noise, background noise, spectral shift by vibration of equipment, spectral shift by pressure change, etc. In this paper, we compare the classification accuracy of various machine learning algorithms including k-nearest neighbor, decision tree, linear discriminant analysis, linear support vector machine, nonlinear support vector machine, and convolutional neural network under noisy and spectral shifted conditions. Experimental results show that convolutional neural network maintains a high classification accuracy of over 95 % despite noise and spectral shift. This implies that convolutional neural network can be an ideal classification algorithm in a real combat situation where there is a lot of noise and spectral shift."
CNN Based Face Tracking and Re-identification for Privacy Protection in Video Contents,2021,[],,"Recently there is sharply increasing interest in watching and creating video contents such as YouTube. However, creating such video contents without privacy protection technique can expose other people in the background in public, which is consequently violating their privacy rights. This paper seeks to remedy these problems and proposes a technique that identifies faces and protecting portrait rights by blurring the face. The key contribution of this paper lies on our deep-learning technique with low detection error and high computation that allow to protect portrait rights in real-time videos. To reduce errors, an efficient tracking algorithm was used in this system with face detection and face recognition algorithm. This paper compares the performance of the proposed system with and without the tracking algorithm. We believe this system can be used wherever the video is used."
Lightweight CNN based Meter Digit Recognition,2021,"['Automatic meter reading', 'Lightweight Deep Neural Network', 'Image processing', 'Convolutional neural network']",,"Image processing is one of the major techniques that are used for computer vision. Nowadays, researchers are using machine learning and deep learning for the aforementioned task. In recent years, digit recognition tasks, i.e., automatic meter recognition approach using electric or water meters, have been studied several times. However, two major issues arise when we talk about previous studies: first, the use of the deep learning technique, which includes a large number of parameters that increase the computational cost and consume more power; and second, recent studies are limited to the detection of digits and not storing or providing detected digits to a database or mobile applications. This paper proposes a system that can detect the digital number of meter readings using a lightweight deep neural network (DNN) for low power consumption and send those digits to an Android mobile application in real-time to store them and make life easy. The proposed lightweight DNN is computationally inexpensive and exhibits accuracy similar to those of conventional DNNs."
Residual Learning Based CNN for Gesture Recognition in Robot Interaction,2021,"['Convolutional Neural Network', 'Feature Redundancy', 'Full Connection Layer', 'Gesture Recognition', 'Human-Computer Interaction', 'Residual Learning']",,"The complexity of deep learning models affects the real-time performance of gesture recognition, thereby limiting the application of gesture recognition algorithms in actual scenarios. Hence, a residual learning neural network based on a deep convolutional neural network is proposed. First, small convolution kernels are used to extract the local details of gesture images. Subsequently, a shallow residual structure is built to share weights, thereby avoiding gradient disappearance or gradient explosion as the network layer deepens; consequently, the difficulty of model optimisation is simplified. Additional convolutional neural networks are used to accelerate the refinement of deep abstract features based on the spatial importance of the gesture feature distribution. Finally, a fully connected cascade softmax classifier is used to complete the gesture recognition. Compared with the dense connection multiplexing feature information network, the proposed algorithm is optimised in feature multiplexing to avoid performance fluctuations caused by feature redundancy. Experimental results from the ISOGD gesture dataset and Gesture dataset prove that the proposed algorithm affords a fast convergence speed and high accuracy."
Stylized Image Generation based on Music-image Synesthesia Emotional Style Transfer using CNN Network,2021,"['Affective Computing', 'Image Style Transfer', 'Deep Convolutional Neural Networks']",,"Emotional style of multimedia art works are abstract content information. This study aims to explore emotional style transfer method and find the possible way of matching music with appropriate images in respect to emotional style. DCNNs (Deep Convolutional Neural Networks) can capture style and provide emotional style transfer iterative solution for affective image generation. Here, we learn the image emotion features via DCNNs and map the affective style on the other images. We set image emotion feature as the style target in this style transfer problem, and held experiments to handle affective image generation of eight emotion categories, including dignified, dreaming, sad, vigorous, soothing, exciting, joyous, and graceful. A user study was conducted to test the synesthesia emotional image style transfer result with ground truth user perception triggered by the music-image pairs’ stimuli. The transferred affective image result for music-image emotional synesthesia perception was proved effective according to user study result."
컴퓨터 텍스트 분석 툴(Tool)을 활용한 글로벌 뉴스 미디어의 싱가포르 북미정상회담 뉴스 프레임 분석 : BBC와 CNN을 중심으로,2021,"['싱가포르 북미정상회담', 'BBC', 'CNN', '비핵화', '뉴스프레임', 'Trump-Kim Singapore Summit', 'BBC', 'CNN', 'Denuclearization', 'News frame']","본 연구는 BBC와 CNN이 2018년 싱가포르 북미정상회담을 어떤 뉴스 프레임으로 보도했는지 비교 분석했다. 코퍼스 언어학을 기반으로 하는 키 워드분석방식인 워드스미스 툴(Tool)을 활용해, BBC와 CNN의 정상회담 에 관한 뉴스데이터에서 핵심 워드를 추출했다. 추출한 키워드를 중심으로 글로벌 뉴스 미디어가 가장 강조한 핵심키워드를 밝혀내 그 의제를 어떻게 보도했는지 귀납적 프레임 분석을 실시했다. 분석결과 데이터에서 두 언론 사가 공통으로 강조한 핵심어는 ‘비핵화’였다, BBC는 중국(China), 일본 (Japan) 핵심어를 사용하여 중국 전문가와 일본 정부를 주요정보원으로 인 용해 지정학적이고 거시적인 시각으로 정상회담에 관한 뉴스를 구성한 것으 로 나타났고, CNN은 언론사 자체의 의견, 공화당 의원의 인용을 정보원으 로 사용해 한미연합훈련중지, 주한 미군 철수와 같은 당시 트럼프 미국 대통 령의 발언을 비판하는 내용을 중심으로 비핵화 문제를 정치적으로 해석하려 는 경향을 보였다.","This study comparatively analyzed the ways in which BBC and CNN framed the 2018 North Korea-United States Singapore Summit. Using a corpus- based text analysis software Wordsmith, keywords in news data were extracted to identify the primary agendas that BBC and CNN highlighted. Drawing on these keywords, this article conducted an inductive frame analysis. The findings show that the main agenda that both BBC and CNN news made salient was the ‘denuclearization’ issue. The BBC cited Chinese experts and the Japanese government as main news sources using keywords such as ‘China’ and ‘Japan’ and reported the Trump-Kim meeting from the geopolitical and macro perspectives. CNN, however, included the media institution’s own views and the quotations of Republican senators as major news sources and underscored issues such as the suspension of the ROK-UK joint military drills and the withdrawal of US troops in Korea in news stories. Additionally, a keyword analysis shows that CNN tended to report the Trump-Kim meeting in a political way and constructed news by rebuking Trump’s remarks. Given the impact of international news coverage of conflict issues in the Korean Peninsula, this study shows the necessity of revisiting the role of global news media."
CNN 기반 악성코드 탐지에서 이미지 형식이 탐지성능과 자원 사용에 미치는 영향 분석,2021,"['CNN', 'Image', 'Malware', 'Detection', 'Classification', 'Resource Usage']","CNN 기반의 악성코드 탐지모델을 활용하기 위해 다양한 이미지 형식을 사용할 수 있다. 하지만 대부분의 기존 연구들은 최종적인 악성코드 탐지 및 분류 성능을 주로 강조하고 있으며, CNN에 입력되는 이미지의 형식이 모델의 성능과 자원 사용 량에 미칠 수 있는 영향은 거의 고려하지 않는다. 이에 본 논문에서는 CNN을 기반으로 안드로이드 악성코드를 탐지하는 모 델을 구축함에 있어 입력되는 이미지 형식이 탐지성능과 학습에 소요되는 자원의 사용량에 어떠한 영향을 미치는지를 분석하 였다. CICAndMal2017 데이터세트를 사용하여 BMP, JPG, PNG 및 TIFF 4가지 형식의 이미지로 변환하고, 자체적으로 구축 한 CNN 모델에 학습시킨 후 악성코드 탐지성능과 자원 사용량을 측정하였다. 그 결과 이미지 형식에 따른 이진분류 및 다중 분류 성능과 GPU 및 RAM 사용량은 큰 차이를 보이지 않았다. 그러나 생성된 이미지의 파일 크기는 이미지 형식에 따라 최 대 6배까지 차이가 났으며, 학습에 소요되는 시간에서도 유의미한 차이가 발생함을 확인하였다.","Various image formats are being used when attempting to construct a malware detection model based on CNN. However, most previous studies emphasize only the detection or classification performance, and do not take into account the possible impact of image format on detection performance and resource usage. Therefore, in this paper, we analyze how the input image formats affect detection performance and resources usage when detecting android malware based on CNN. The dataset used in the experiment is the CICAndMal2017 Dataset. Subdataset extracted from the CICAndMal2017 Dataset were converted into images in four formats: BMP, JPG, PNG, and TIFF. We then trained our CNN model and measured malware detection performance and resource usage. As a result, there was no sifnificant difference between detection performance and the GPU/RAM usage, even if the image format changed. However, we found that the file size of the generated images varied by up to six times depending on the image format, and that significant differences occurred in the training time."
CNN-based Fast Split Mode Decision Algorithm for Versatile Video Coding (VVC) Inter Prediction,2021,"['Versatile Video Coding (VVC)', 'Inter Prediction', 'Fast algorithm', 'Convolutional Neural Network (CNN)', 'Deep learning']",,"Versatile Video Coding (VVC) is the latest video coding standard developed by Joint Video Exploration Team (JVET). In VVC, the quadtree plus multi-type tree (QT+MTT) structure of coding unit (CU) partition is adopted, and its computational complexity is considerably high due to the brute-force search for recursive rate-distortion (RD) optimization. In this paper, we aim to reduce the time complexity of inter-picture prediction mode since the inter prediction accounts for a large portion of the total encoding time. The problem can be defined as classifying the split mode of each CU. To classify the split mode effectively, a novel convolutional neural network (CNN) called multi-level tree (MLT-CNN) architecture is introduced. For boosting classification performance, we utilize additional information including inter-picture information while training the CNN. The overall algorithm including the MLT-CNN inference process is implemented on VVC Test Model (VTM) 11.0. The CUs of size 128×128 can be the inputs of the CNN. The sequences are encoded at the random access (RA) configuration with five QP values {22, 27, 32, 37, 42}. The experimental results show that the proposed algorithm can reduce the computational complexity by 11.53% on average, and 26.14% for the maximum with an average 1.01% of the increase in Bjøntegaard delta bit rate (BDBR). Especially, the proposed method shows higher performance on the sequences of the A and B classes, reducing 9.81%~26.14% of encoding time with 0.95%~3.28% of the BDBR increase."
부분방전 데이터 처리 방법에 따른 CNN 기반 패턴 분류기의 비교 연구,2021,"['Data Processing', 'Partial Discharge', 'CNN', 'Projection', 'Pattern Recognition']",,"This study is focused on solution to the problem that may occur due to noise signals when using the image obtained through the conventional partial discharge preprocessing methods as inputs to the CNN-based partial discharge pattern classifier. To solve such problem, a new data preprocessing method is proposed by considering a projection technique. In the data information obtained through the conventional partial discharge preprocessing methods, data information of useless noise signal leads to the problem of performance degradation when constructing highly qualified pattern classifier based on the data information of partial discharge signal. The proposed preprocessing method called as ‘Projection’ in this study is designed to solve this problem and improve a classification performance of CNN-based partial discharge pattern classifier. First of all, through GIS simulation, one-dimensional partial discharge data is obtained as five cases such as corona discharge, floating discharge, insulator discharge, free particle discharge, and steady state (noise) in an environment with a noise signal by using a UHF sensor. After that, by applying the two conventional partial discharge preprocessing methods such as PRPS(Phase Resolved Pulse Sequence), PRPD(Phase Resolved Partial Discharge) and the proposed partial discharge preprocessing method, one-dimensional partial discharge data is transformed into 3 data types such as image set of PRPS, image set of PRPD, and image set of Projection. Finally each image set is used as inputs to the designed CNN-based partial discharge pattern classifier. Through the comparative analysis of the feature maps of each layer in CNN as well as the performance accuracy of partial discharge pattern classification for each image set, the superiority of the proposed preprocessing method is demonstrated."
CNN-based Android Malware Detection Using Reduced Feature Set,2021,"['CNN', 'Android', 'Malware', 'Feature selection', 'Binary classification', 'Multiclass classification', '안드로이드', '악성코드', '특성추출', '이진분류', '다중분류']","딥러닝 기반 악성코드 탐지 및 분류모델의 성능은 특성집합을 어떻게 구성하느냐에 따라 크게 좌우된다. 본 논문에서는 CNN 기반의 안드로이드 악성코드 탐지 시 탐지성능을 극대화할 수 있는 최적의 특성집합(feature set)을 선정하는 방법을 제안한다. 특성집합에 포함될 특성은 기계학습 및 딥러닝에서 특성추출을 위해 널리 사용되는 Chi-Square test 알고리즘을 사용하여 선정하였다. CICANDMAL2017 데이터세트를 대상으로 선정된 36개의 특성을 이용하여 CNN 모델을 학습시킨 후 악성코드 탐지성능을 측정한 결과 이진분류에서는 99.99%, 다중분류에서는 98.55%의 Accuracy를 달성하였다.","The performance of deep learning-based malware detection and classification models depends largely on how to construct a feature set to be applied to training. In this paper, we propose an approach to select the optimal feature set to maximize detection performance for CNN-based Android malware detection. The features to be included in the feature set were selected through the Chi-Square test algorithm, which is widely used for feature selection in machine learning and deep learning. To validate the proposed approach, the CNN model was trained using 36 characteristics selected for the CICANDMAL2017 dataset and then the malware detection performance was measured. As a result, 99.99% of Accuracy was achieved in binary classification and 98.55% in multiclass classification."
이미지 감성분류를 위한 CNN과 K-means RGB Cluster 이-단계 학습 방안,2021,"['이미지 감성분류', '색감', '이-단계 학습', 'Sentiment Analysis of Image', 'Sense of Color', 'CNN', 'Two-stage learning']",,"The biggest reason for using a deep learning model in image classification is that it is possible to consider the relationship between each region by extracting each regions features from the overall information of the image. However, the CNN model may not be suitable for emotional image data without the images regional features. To solve the difficulty of classifying emotion images, many researchers each year propose a CNN-based architecture suitable for emotion images. Studies on the relationship between color and human emotion were also conducted, and results were derived that different emotions are induced according to color. In studies using deep learning, there have been studies that apply color information to image subtraction classification. The case where the images color information is additionally used than the case where the classification model is trained with only the image improves the accuracy of classifying image emotions.  This study proposes two ways to increase the accuracy by incorporating the result value after the model classifies an images emotion. Both methods improve accuracy by modifying the result value based on statistics using the color of the picture. When performing the test by finding the two-color combinations most distributed for all training data, the two-color combinations most distributed for each test data image were found. The result values were corrected according to the color combination distribution. This method weights the result value obtained after the model classifies an images emotion by creating an expression based on the log function and the exponential function.  Emotion6, classified into six emotions, and Artphoto classified into eight categories were used for the image data. Densenet169, Mnasnet, Resnet101, Resnet152, and Vgg19 architectures were used for the CNN model, and the performance evaluation was compared before and after applying the two-stage learning to the CNN model.  Inspired by color psychology, which deals with the relationship between colors and emotions, when creating a model that classifies an images sentiment, we studied how to improve accuracy by modifying the result values based on color. Sixteen colors were used: red, orange, yellow, green, blue, indigo, purple, turquoise, pink, magenta, brown, gray, silver, gold, white, and black. It has meaning. Using Scikit-learns Clustering, the seven colors that are primarily distributed in the image are checked. Then, the RGB coordinate values of the colors from the image are compared with the RGB coordinate values of the 16 colors presented in the above data. That is, it was converted to the closest color. Suppose three or more color combinations are selected. In that case, too many color combinations occur, resulting in a problem in which the distribution is scattered, so a situation fewer influences the result value. Therefore, to solve this problem, two-color combinations were found and weighted to the model. Before training, the most distributed color combinations were found for all training data images. The distribution of color combinations for each class was stored in a Python dictionary format to be used during testing. During the test, the two-color combinations that are most distributed for each test data image are found. After that, we checked how the color combinations were distributed in the training data and corrected the result. We devised several equations to weight the result value from the model based on the extracted color as described above.  The data set was randomly divided by 80:20, and the model was verified using 20% of the data as a test set. After splitting the remaining 80% of the data into five divisions to perform 5-fold cross-validation, the model was trained five times using different verification datasets. Finally, the performance was checked using the test dataset that was previously separated. Adam was used as the activation function, and the learning rate"
Implementation and Performance Evaluation of Farm Waste Image Classification System using CNN-based Transfer Learning Models,2021,"['Artificial intelligence', 'Transfer-learning', 'CNN', 'Image classification', 'Farm waste collection']","영농 폐기물의 증가로 인해, 빠르고 효율적으로 수거할 수 있는 스마트 영농 폐기물 모니터링 시스템 개발이 필요하다. 본 논문에서는 영농 폐기물 분류 시스템을 제안하고 실제 지역 농촌에서 직접 수집한 영상을 이용하여 CNN 기반의 전이학습 모델들을 구현하고 비교하였다. 영농 폐기물 영상 분류에 적합한 모델과 학습 조건을 찾기 위해, 3가지의 학습 자료군 구성 조건 (2종 분류, 6종 분류, 6종 하위분류를 가진 2종 분류)을 달리하여 미세 조정된 6개의 사전 훈련 CNN 모델들의 검증 정확도를 비교하였다. 그 결과, ResNet-50 모델의 성능이 모든 학습 조건에서 평균 90.9%의 정확도로 가장 높았고, 폐기물 영상을 6종 분류했을 때보다 2종 분류로 했을 때의 검증 정확도가 10% 더 높았다. 특히, 학습 자료군 구성 방법 중 6종 하위분류를 가진 2종 분류했을 때의 검증 정확도는 2종 분류했을 때와 유사했다. 이를 통해 영농 폐기물은 한 종류만 모여 있지 않을뿐더러 다양한 폐기물들이 한데 섞여 있어서 영농 폐기물의 특정한 세부 종류로 분류하는 것보다 폐기물인지 아닌지를 이진 분류하는 것이 더 효과적임을 확인하였다. 나아가, 제안된 시스템의 동작을 확인하기 위해, 영농 환경 모니터링 서버와 영농 폐기물 영상 분류 서버 사이에 TCP / IP 기반의 통신 환경을 구축하고, 모의실험을 통해 구현한 영농 폐기물 영상 분류 시스템이 스마트 영농 폐기물 모니터링 시스템으로 사용될 가능성을 확인하였다. 본 연구의 결과는 정형화되지 않거나 여러 병변이 혼합된 의료 영상을 분류하는 경우에도 활용될 수 있을 것이다.","Due to the increase of farm waste in many countries, there’s a need to develop a smart farm waste monitoring system that can collect it promptly and efficiently. In this paper, we proposed, compared the performance of a convolutional neural network (CNN) -based transfer learning models and implement a farm waste image classification system, which is crucial component for the monitoring system. To find an appropriate model and labelling methods for farm waste image classification, we compared each validation accuracy of six different pre-trained CNN methods with three types of labelling scheme, using the waste images taken directly from the farming area. As a result, the ResNet-50 model performed best with an accuracy of 90.9% on average. Also, when classified into 2 categories, the accuracy was about 10% higher than that of the 6 categories. Furthermore, when the image was classified into 2 main categories with 6 sub-categories, the validation accuracy was similar to that of the 2 categories. Through these results, it seemed to be more effective to classify with binary labels such as ‘trash’ and ‘non-trash’, rather than with multiple labels of specific categories because farm waste is generated not only by single type of waste but also by various types of mixed waste. And a TCP / IP based communication environment between farm environment monitoring server and farm waste image classification server has been implemented. Experimental results using the system implemented for a smart farm waste monitoring showed that the proposed system can be used for a smart farm waste collection system. Also, the result of this study could be applied to classify medical images of unstructured and/or mixed lesion."
심전도 신호 분류를 위한 1D CNN 모델 구성 요소의 최적화,2021,"['Deep learning', 'Electrocardiogram', 'CNN', 'ResNet', 'Arrhythmia Detection', '딥러닝', '심전도', '부정맥 검출']","본 논문에서는 딥러닝 모델을 이용하여 모바일 기기의 심전도 신호 측정 데이터를 분류한다. 비정상 심장박동을 높은 정확도로 분류하기 위해 딥러닝 모델의 구성 요소 세 가지를 선정하고 요소의 조건 변화에 따른 분류 정확도를 비교한다. 심전도 신호 데이터의 특징을 스스로 추출할 수 있는 CNN 모델을 적용하고 모델을 구성하는 모델의 깊이, 최적화 방법, 활성화 함수의 조건을 변경하여 총 48개의 조합의 성능을 비교한다. 가장 높은 정확도를 보이는 조건의 조합을 도출한 결과 컨볼루션 레이어 19개, 최적화 방법 SGD, 활성화 함수 Mish를 적용하였을 때 정확도 97.88%로 모든 조합 중 가장 높은 분류 정확도를 얻었다. 이 실험에서 CNN을 활용한 1-채널 심전도 신호의 특징 추출과 비정상 박동 검출의 적합성을 확인하였다.","In this paper, we classify ECG signal data for mobile devices using deep learning models. To classify abnormal heartbeats with high accuracy, three factors of the deep learning model are selected, and the classification accuracy is compared according to the changes in the conditions of the factors. We apply a CNN model that can self-extract features of ECG data and compare the performance of a total of 48 combinations by combining conditions of the depth of model, optimization method, and activation functions that compose the model. Deriving the combination of conditions with the highest accuracy, we obtained the highest classification accuracy of 97.88% when we applied 19 convolutional layers, an optimization method SGD, and an activation function Mish. In this experiment, we confirmed the suitability of feature extraction and abnormal beat detection of 1-channel ECG signals using CNN."
CNN기반 상품분류 딥러닝모델을 위한 학습데이터 영향 실증 분석,2021,"['상품분류', 'CNN 모델', '딥러닝', '학습데이터', '사전처리', 'Product Classification', 'CNN Model', 'Deep Learning', 'Training Data', 'Preprocessing']","전자상거래에서 상품 정보에 따른 신속하고 정확한 자동 상품 분류는 중요하다. 최근의 딥러닝 기술 발전은 자동 상품 분류에도 적용이 시도되고 있다. 성능이 우수한 딥러닝 모델 개발에 있어, 학습 데이터의 품질과 모델에 적합한 데이터 전처리는 중요하다. 본 연구에서는, 텍스트 상품 데이터를 기반으로 카테고리를 자동 유추할 때, 데이터의 전처리 정도에 따른 영향력과 학습 데이터 선택 범위 영향력을 CNN모델을 사례 모델로 이용하여 비교 분석한다. 실험 분석에 사용한 데이터는 실제 데이터를 사용하여 연구 결과의 실증을 담보하였다. 본 연구가 도출한 실증 분석 및 결과는 딥러닝 상품 분류 모델 개발 시 성능 향상을 위한 레퍼런스로서 의의가 있다.","In e-commerce, rapid and accurate automatic product classification according to product information is important. Recent developments in deep learning technology have been actively applied to automatic product classification. In order to develop a deep learning model with good performance, the quality of training data and data preprocessing suitable for the model are crucial. In this study, when categories are inferred based on text product data using a deep learning model, both effects of the data preprocessing and of the selection of training data are extensively compared and analyzed. We employ our CNN model as an example of deep learning model. In the experimental analysis, we use a real e-commerce data to ensure the verification of the study results. The empirical analysis and results shown in this study may be meaningful as a reference study for improving performance when developing a deep learning product classification model."
CNN을 이용한 Cyclic Moment 기반 자동 변조 인식,2021,"['Automatic recognition modulation', 'Cyclic moment', 'Convolution neural network']",,
Review on the Recent Welding Research with Application of CNN-Based Deep Learning Part I: Models and Applications,2021,"['Deep learning', 'Convolution Neural Network', 'Image', 'Welding', 'Model', 'Application']",,"During machine learning algorithms, deep learning refers to a neural network containing multiple hidden layers. Welding research based upon deep learning has been increasing due to advances in algorithms and computer hardwares. Among the deep learning algorithms, the convolutional neural network (CNN) has recently received the spotlight for performing classification or regression based on image input. CNNs enables end-to-end learning without feature extraction and in-situ estimation of the process outputs. In this paper, 18 recent papers were reviewed to investigate how to apply CNN models to welding. The papers was classified into 5 groups: four for supervised learning models and one for unsupervised learning models. The classification of supervised learning groups was based on the application of transfer learning and data augmentation. For each paper, the structure and performance of its CNN model were described, and also its application in welding was explained."
무선 네트워크 침입탐지를 위해 개선된 CNN 분석,2021,"['Wireless network', 'Intrusion detection', 'Convolution neural network', 'Detection accuracy', 'True positive rate', 'False positive rate']","최근 5G기술과 함께 공중 및 사설 WiFi 서비스 영역이 크게 확대되면서 사용자 트래픽의 종류와 크기도 폭발적으로 증가하고 있다. 이와 함께 무선 네트워크의 보안 취약성을 이용한 인가되지 않은 악의적인 사용자의 침입/공격 트래픽도 크게 증가하고 있다. 침입/공격특성 또한 다양화되고 있어 기존 무선 네트워크 침입 탐지 시스템은 오탐률이 높고 탐지 효율성이 낮으며 침입 및 공격 트래픽에 대한 일반화 능력이 약하다. 본 논문에서는 과대적합 문제를 피하면서 일반화 능력을 개선하기 위한 방안으로 CNN의 커널 크기를 축소하고 콘볼루션 계층을 이중화하여 병렬 연산을 하는 구조를 제안한다. 테스트 데이터 세트로NSL-KDD CUP 데이터 세트를 사용하여, 실험 및 분석 결과 제안한 CNN은 침입/공격을 탐지하기 위한 샘플 테스트 수행에서 정확도와 참양성률(true positive rate)은 96.38%, 96.75%이며 이것은 기존 DBN과 RNN보다 2%이상 향상된 결과이다. 또한 위양성율(false positive rate)은 0.88%와 0.91% 보다 낮은 0.64%을 보여주었다.","Recently, along with 5G technology public and private WiFi service areas have been greatly expanded. Also, the types and sizes of user traffic are increasing explosively. At the same time, the frequency of intrusion/attack by unauthorized malicious users using security vulnerabilities of wireless networks is also increasing significantly. Intrusion/attack characteristics are also diversifying, so the existing wireless network intrusion detection system has a high false positive rate, low detection efficiency, and weak generalization ability for intrusion and attack traffic. In this paper, as a method to improve generalization ability while avoiding the overfitting problem, we propose a structure that reduces the size of the CNN kernel and duplicates the convolutional layer for parallel operation. The NSL-KDD CUP data set was used as the test data set. As a result of experiments and analysis, the proposed CNN show 96.38% and 96.75% accuracy and true positive rates in performing sample tests to detect intrusion/attack.This showed an improvement of more than 2% compared to the existing DBN and RNN. Also, the false positive rate was 0.64%, lower than 0.88% and 0.91%."
CNN-LSTM 기반 위치 측위를 이용한 영상 내 비승인자 추적 시스템,2021,"['CNN-LSTM', 'Location Positioning', 'Fingerprinting', 'Object Recognition', 'Object Tracking', '위치 측위', '핑거프린팅', '객체 인식', '객체 추적']","본 논문에서는 영상 데이터, 비콘 데이터의 결합을 통해 집단시설에서 출입이 허용된 승인자와 비승인자를 구분하는 시스템을 제안한다. IP 카메라를 통해 수집된 영상 데이터는 YOLOv4를 사용하여 사람 객체를 추출하고, 애플리케이션을 통해 비콘의 신호 데이터(UUID, RSSI)를 수집하여 핑거프린팅 기반의 라디오 맵을 구성한다. 비콘은 신호의 불안전성을 보완해 위치 파악의 정확도를 향상하기 위하여 CNN-LSTM 기반의 학습을 진행한 후 사용자 위치 데이터를 추출한다. 이후 도출된 위치 데이터와 사람 객체가 추출된 영상 데이터를 매핑해 실시간으로 비승인자를 추적한다. 본 논문의 결과로 93.47%의 정확도를 보였으며, 향후 코로나19로 사용이 증가한 QR코드 등의 출입 인증 절차와 융합해 인증 절차를 거치지 않은 사람을 추적하는 확장성까지 기대할 수 있다.","In this paper, we propose a system that uses image data and beacon data to classify authorized and unauthorized perosn who are allowed to enter a group facility. The image data collected through the IP camera uses YOLOv4 to extract a person object, and collects beacon signal data (UUID, RSSI) through an application to compose a fingerprinting-based radio map. Beacon extracts user location data after CNN-LSTM-based learning in order to improve location accuracy by supplementing signal instability. As a result of this paper, it showed an accuracy of 93.47%. In the future, it can be expected to fusion with the access authentication process such as QR code that has been used due to the COVID-19, track people who haven""t through the authentication process."
YOLO와 CNN을 이용한 강인한 차량 번호판 인식 시스템 구현,2021,"['you only look once', 'license plate', 'object detection', 'optical character recognition', 'convolution neural network']",,"In recent years, with the development of intelligent transportation systems, research on license plate recognition is drawing attention. Domestic license plate recognition is frequently misrecognized due to image quality and Korean language problems. This study implemented a real-time license plate recognition system robust against environmental changes using YOLO and CNN. YOLO was used to extract only a specific license plate area, and CNN was used to recognize license plates. License plate recognition extracted numbers and letters from the actual license plate drawing. Then, it was transformed and multiplied to be robust to the environment, and learned with CNN. In addition, three algorithms were used for recognizing Korean characters with many misrecognitions, such as detection of separated consonants and vowel regions using erosion and average regions, and extraction of syllable regions when there is no Korean syllable. Finally, the proposed license plate recognition system and the existing OCR algorithm were compared. As a result of the experiment, the easy OCR has an accuracy of 62.5%, the algorithm using only erosion is 82.5%, and the proposed algorithm has an accuracy of 97.5%."
Mammogram 특징 추출을 위한 maskSLIC 기반 CNN 분류 모델,2021,"['Deep learning', 'CNN', 'SLIC', 'Superpixel', 'Medical imaging']",,
전이학습 기반의 CNN을 이용한 컨포멀 코팅 PCB에 발생한 기포 검출 방법,2021,"['Transfer Learning', 'CNN', 'Bubble Detection', 'Conformal Coating', 'VGGNet']",,"Air bubbles which may be generated during the PCB coating process can be a major cause of malfunction. so it is necessary to detect the bubbles in advance. In previous studies, candidates for bubbles were extracted using the brightness characteristics of bubbles, and the candidates were verified using CNN(Convolutional Neural Networks). In this paper, we propose a bubble detection method using a transfer learning-based CNN model. The VGGNet is adopted and sigmoid is used as a classification layer, and the last convolutional layer and classification layer are trained together when transfer learning is applied. The performance of the proposed method is F1-score 0.9044, which shows an improvement of about 0.17 compared to the previous study."
Implementation of CNN-based Masking Algorithm for Post Processing of Aerial Image,2021,"['Aerial Image', 'Mask R-CNN', 'CNN', 'Digital Twin', 'Smart City']",,"Eunsoo CHOI;Zhixuan QUAN;Sangwoo JUNGPurpose: To solve urban problems, empirical research is being actively conducted to implement a smart city based on various ICT technologies, and digital twin technology is needed to effectively implement a smart city. A digital twin is essential for the realization of a smart city. A digital twin is a virtual environment that intuitively visualizes multidimensional data in the real world based on 3D. Digital twin is implemented on the premise of the convergence of GIS and BIM, and in particular, a lot of time is invested in data pre-processing and labeling in the data construction process. In digital twin, data quality is prioritized for consistency with reality, but there is a limit to data inspection with the naked eye. Therefore, in order to improve the required time and quality of digital twin construction, it was attempted to detect a building using Mask R-CNN, a deep learning-based masking algorithm for aerial images. If the results of this study are advanced and used to build digital twin data, it is thought that a high-quality smart city can be realized."
전이학습 기반 CNN을 통한 풀림 방지 코팅 볼트 이진 분류에 관한 연구,2021,"['Bolts With Anti-loosening Coating', 'Convolutional Neural Networks', 'Transfer Learning', 'Fine-tuning', 'Fully Connected Layer']","풀림 방지 코팅 볼트는 주로 자동차 안전 관련 부품을 결합하는 데 사용되므로 안전성 유지를 위해 코팅 결함을 사전에 감지해야 한다. 이를 위해 이전 연구 [CNN 및 모델 시각화 기법을 사용한 코팅 볼트 불량 판별]에서는 합성곱신경망을 사용했다. 이때 합성곱 신경망은 데이터 수가 많을수록 이미지 패턴 및 특성 분석 정확도가 증가하지만 그에 따라 학습시간이 증가한다. 또한 확보 가능한 코팅 볼트 샘플이 한정적이다. 본 연구에서는 이전 연구에 전이학습을 추가적으로 적용해 데이터 개수가 적은 경우에도 코팅 결함에 대해 정확한 분류를 하고자 한다. 전이학습을 적용할 때 학습데이터 수와 사전 학습 데이터 ImageNet 간의 유사성을 고려해 분류층만 학습했다. 데이터 학습에는 전역 평균 풀링, 선형 서포트 벡터 머신 및 완전 연결 계층과 같은 분류층을 적용했으며, 고려한 모델 중 완전 연결 계층 방법의 분류층이 가장 높은 95% 정확도를 가진다. 추가적으로 마지막 합성곱층과 분류층을 미세 조정하면 정확도는 97%까지 향상된다. 전이학습 및 미세 조정을 이용하면 선별 정확도를 향상시킴은 물론 이전보다 학습 소요시간을 절반으로 줄일 수 있음을 보였다.","Because bolts with anti-loosening coatings are used mainly for joining safety-related components in automobiles, accurate automatic screening of these coatings is essential to detect defects efficiently. The performance of the convolutional neural network (CNN) used in a previous study [Identification of bolt coating defects using CNN and Grad-CAM] increased with increasing number of data for the analysis of image patterns and characteristics. On the other hand, obtaining the necessary amount of data for coated bolts is difficult, making training time-consuming. In this paper, resorting to the same VGG16 model as in a previous study, transfer learning was applied to decrease the training time and achieve the same or better accuracy with fewer data. The classifier was trained, considering the number of training data for this study and its similarity with ImageNet data. In conjunction with the fully connected layer, the highest accuracy was achieved (95%). To enhance the performance further, the last convolution layer and the classifier were fine-tuned, which resulted in a 2% increase in accuracy (97%). This shows that the learning time can be reduced by transfer learning and fine-tuning while maintaining a high screening accuracy."
인공지능 기법(CNN)을 이용한 음성과 음악구분,2021,"['Speech-Music Discrimination', 'Fingerprint', 'Deep Learning', 'CNN', 'Mel-Spectrum', 'Transfer Learning']","음성, 음악 구분 방법은 전통적으로 퓨리에 분석치의 특성치를 직접 이용하는 방법이 사용되어 왔다. 하지만 딥러닝을 이용하면 end-to-end 방식으로 특성치를 별도로 부여하는 과정을 거치지 않고 구분이 가능하다. 본고에 사용된 자료는 국내 음악방송(FM 89.8MHz)에서 추출된 약 389만개의 음성, 음악 파일이다. 송출된 소리를 5초 단위로 구분하여 음성 2,401,040개 파일, 음악 1,489,168 총 3,890,208개의 파일을 구성했다. 5초 단위로 소리를 끊는 것은 일반적으로 음악 핑거프린팅이 5초 단위 소리를 사용하여 구분하기 때문이다. 이러한 자료에 대해 딥러닝 분석 기법인 CNN분석을 적용하되 기존의 이미지 학습을 이용한 전이학습(transfer learning)을 적용했다. 실험결과 모형의 복잡성을 높이지 않고도 기존 학습 모형을 응용해 약 89.6% 전후 정확도가 나왔다. 또한 혼동 행렬을 이용하면 음성을 음악으로 판단하는 오류는 12.3%, 음악을 음성으로 판단하는 오류는 12.2%를 보였다.","Traditionally, a method of directly using the characteristic value of the Fourier analysis has been used to distinguish voice and music. However, if deep learning is used, it is possible to distinguish voice and music with an end-to-end method without the need for the process of characteristic featuring. The data used in this paper are about 3.89 million voice and music files extracted from a domestic music broadcasting (FM 89.8MHz). The transmitted sound is divided into 5-second units. Breaking down sound into 5-second increments is applied because music fingerprinting generally uses 5-second increments to distinguish sounds. The CNN analysis, a deep learning analysis technique, was applied to these data, and transfer learning was performed using existing image learning models. An accuracy of about 89.6% was obtained in the existing learning model without increasing the complexity of the deep learning model. In addition, while using the confusion matrix, the error of judging voice as music was 12.3%, and the error in judging music as voice was 12.2%."
"전기화재 원인분석을 위한 실험실 데이터를 활용한 1차, 2차 단락흔 및 열흔 판별용 CNN 알고리즘 설계",2021,"['Electrical fire', 'Arc beads', 'Molten mark', 'Convolution neural network']",,"In this paper, a new CNN algorithm is proposed to determine the direct cause of electric fires. We create 10,000-15,000 three types of data that can occur at a fire scene in our laboratory, and then train and verify it through the proposed CNN algorithm. As a result of the experiment and analysis, the classification accuracy of the primary and secondary arc beads was 86.2%, the accuracy of arc beads and molten marks was 93.6%. And also, the classification accuracy of the primary and secondary arc beads and molten marks was 92.4%. The results of this study are meaningful in that fire forensics can provide accurate identification results in a shorter time through artificial intelligence algorithms compared to the existing methods of identification through visual classification and physicochemical material analysis methods. In particular, the classification between primary and secondary arc beads is known to be a very difficult problem. However, the results of this study provided more than 86% classification ability."
CNN기반의 온라인 수어통역 상담 시스템에 관한 연구,2021,"['OpenCV', '합성곱 신경망', '수어', '청각장애인', '영상처리', 'OpenCV(Open Source Computer Vision)', 'CNN(Convolutional Neural  Networks)', 'Sign Language', 'Hearing-Impaired Person', 'Image Processing']",,
CNN 기반 리뷰 유용성 점수 예측을 통한 개인화 추천 서비스 성능 향상에 관한 연구,2021,"['개인화 추천 서비스', '리뷰 유용성', '협업 필터링', '딥러닝', 'Personalized Recommendation Service', 'Review Helpfulness', 'CF', 'Deep Learning', 'CNN']",,"Recently, various types of products have been launched with the rapid growth of the e-commerce market. As a result, many users face information overload problems, which is time-consuming in the purchasing decision-making process. Therefore, the importance of a personalized recommendation service that can provide customized products and services to users is emerging. For example, global companies such as Netflix, Amazon, and Google have introduced personalized recommendation services to support users purchasing decisions. Accordingly, the users information search cost can reduce which can positively affect the companys sales increase. The existing personalized recommendation service research applied Collaborative Filtering (CF) technique predicts user preference mainly use quantified information. However, the recommendation performance may have decreased if only use quantitative information. To improve the problems of such existing studies, many studies using reviews to enhance recommendation performance. However, reviews contain factors that hinder purchasing decisions, such as advertising content, false comments, meaningless or irrelevant content. When providing recommendation service uses a review that includes these factors can lead to decrease recommendation performance. Therefore, we proposed a novel recommendation methodology through CNN-based review usefulness score prediction to improve these problems. The results show that the proposed methodology has better prediction performance than the recommendation method considering all existing preference ratings. In addition, the results suggest that can enhance the performance of traditional CF when the information on review usefulness reflects in the personalized recommendation service."
CNN Auto-Encoder Network Using Dilated Inception for Image Steganography,2021,"['Information security', 'Image steganography', 'Dilated convolution', 'CNN', 'Autoencoder']",,"Numerous studies have used convolutional neural networks (CNNs) in the field of information concealment as well as steganalysis, achieving promising results in terms of capacity and invisibility. In this study, we propose a CNN-based steganographic model to hide a color image within another color image. The proposed model consists of two sub-networks: the hiding network is used by the sender to conceal the secret image; and the reveal network is used by the recipient to extract the secret image from the stego image. The architecture of the concealment sub-network is inspired by the U-Net auto-encoder and benefits from the advantages of the dilated convolution. The reveal sub-network is inspired by the auto-encoder architecture. To ensure the integrity of the hidden secret image, the model is trained end to end: rather than training separately, the two sub-networks are trained simultaneously a pair of networks. The loss function is elaborated in such a way that it favors the quality of the stego image over the secret image as the stego image is the one that comes under steganalysis attacks. To validate the proposed model, we carried out several tests on a range of challenging publicly available image datasets such as ImageNet, Labeled Faces in the Wild (LFW), and PASCAL-VOC12. Our results show that the proposed method can dissimulate an image into another one with the same size, reaching an embedding capacity of 24 bit per pixel without generating visual or structural artefacts on the host image. In addition, the proposed model is generic, that is, it does not depend on the image’s size or the database source."
CNN 기반 주행 중인 차량 간 상대속도 추정 알고리즘,2021,"['mobile robot', 'deep learning', 'object detection', 'convolutional neural network', 'self-driving vehicle']",,"In this paper, we proposed an estimation algorithm of the relative velocity between two driving vehicles based on CNN(Convolutional Neural Network), as the perception of the surrounding environment around an autonomous car, such as distance and speed of other vehicles, is important. The proposed algorithm estimated the velocity of a target vehicle by using a stereo camera without any other sensors. A stereo camera is a sensor that acquires simultaneously RGB images and depth maps, and it is widely used for autonomous vehicles to obtain various information. The developed CNN-based semantic segmentation model with high speed and accuracy was used to recognize the target vehicle, detecting the shape of the target object and omitting background information around it. Due to this effect, the distance between the autonomous vehicle and target vehicle is more accurately estimated. The relative speed between each vehicle was estimated using the distance and time difference between frames. The performance of the proposed algorithm was compared with conventional methods and it was confirmed that the speed of the target vehicle was more accurately estimated using only the stereo camera."
CNN 영상 회귀 기반의 산란계수 추정을 통한 연무제거,2021,"['image dehazing', 'CNN', 'LiDAR', 'dark channel prior', 'scattering coefficient', 'image regression']",,"The estimation of the scattering coefficient in depth image-based dehazing is of paramount importance. Since scattering coefficients are used to estimate the transmission image for dehazing, the optimal scattering coefficients for effective dehazing must be obtained depending on the level of haze and fog generation. In this study, we performed a CNN-based image regression to obtain the optimal scattering coefficients for each image with fog and haze. A three-channel image was used as the input data, and the learning was performed with approximately 2,000 labeled synthetic haze and fog datasets. Subsequently, the transmission image was estimated using the scattering coefficient obtained for the input image through the learned model, and the depth image was obtained through the LiDAR point cloud projection for performing the dehazing. This paper presents a qualitative and quantitative comparison of the results obtained using the proposed dehazing technique with those obtained using the existing dehazing algorithms."
CNN Auto-Encoder Network Using Dilated Inception for Image Steganography,2021,"['Information security', 'Image steganography', 'Dilated convolution', 'CNN', 'Auto-encoder']",,"Numerous studies have used convolutional neural networks (CNNs) in the field of information concealment as well as steganalysis, achieving promising results in terms of capacity and invisibility. In this study, we propose a CNN-based steganographic model to hide a color image within another color image. The proposed model consists of two sub-networks: the hiding network is used by the sender to conceal the secret image; and the reveal network is used by the recipient to extract the secret image from the stego image. The architecture of the concealment sub-network is inspired by the U-Net auto-encoder and benefits from the advantages of the dilated convolution. The reveal sub-network is inspired by the auto-encoder architecture. To ensure the integrity of the hidden secret image, the model is trained end to end: rather than training separately, the two sub-networks are trained simultaneously a pair of networks. The loss function is elaborated in such a way that it favors the quality of the stego image over the secret image as the stego image is the one that comes under steganalysis attacks. To validate the proposed model, we carried out several tests on a range of challenging publicly available image datasets such as ImageNet, Labeled Faces in the Wild (LFW), and PASCAL-VOC12. Our results show that the proposed method can dissimulate an image into another one with the same size, reaching an embedding capacity of 24 bit per pixel without generating visual or structural artefacts on the host image. In addition, the proposed model is generic, that is, it does not depend on the image’s size or the database source."
CNN을 활용한 카오스 신호 분류 검증,2021,"['Convolutional Neural Network(합성곱 신경망)', 'Lyapunov Exponent(리아푸노브 지수)', 'Recurrence Plot(리커런스 플롯)', 'Chaos(카오스)']",,"The aim of the study was to classify the chaotic time-series data with the nonlinear problem using the convolutional neural network (CNN), and to determine and verify the chaotic characteristics from a deterministic system. The classical nonlinear differential equation established by the Rossler model was used, and the chaotic characteristics were determined by the Lyapunov exponent. The chaotic properties was visualized using an unthresholded recurrence plot through the proposed procedure. A simple CNN model was developed to learn the extracted image using the proposed feature-visualization technique. As a result, the chaotic characteristics were classified with an accuracy of 99 % or more."
YOLO 를 이용한 CNN 기반의 물체 인식과 파지 중심점 위치오차 최소화 알고리즘 연구 및 파지 성능 평가,2021,"['Machine Vision', 'Visual Servoing', 'Object Detection', 'Convolutional Neural Network', 'Transformation Matrix']",,"In the last few years, the use of robot manipulators has attracted increasing attention in various industries. Accordingly. Researchers have proposed unique ideas for co-robot control using vision sensors. In this study, you only look once (YOLO) based on convolutional neural network (CNN), and grasping center point position error minimization algorithms were proposed to reduce object misrecognition and increase the performance for grasping an object. In addition, a gripping algorithm was designed for six degree of freedom (DOF) robot manipulators. In addition, machine vision algorithms, including a Grayscale, Gaussian filter, Canny edge, and Contouring, were implemented to detect objects features, such as centroids and orientation. Furthermore, the coordinate system of the vision sensor was converted into a coordinate system of the robot manipulator using a transformation matrix to accurately move the end effector of the robot arm to the center point of the object. The logic implemented in this study not only detected the trained object on the workstation, but also minimized the positional error of the transformation matrix. Additionally, experiments were performed on the 6-DOF robot manipulators. The results revealed that the end effector of the 6-DOF manipulators successfully moved to the center of the detected object, and each of the eight objects was normally gripped."
CNN을 이용한 세포영상 자동분류 알고리즘에 관한 연구,2021,"['Automatic classification', 'HeLa cell', 'CCD-986SK', 'OpenCV', 'Convolutional Neural Network', 'Deep learning']",,"Recently, artificial intelligence can be used in various fields, especially for medical purposes. For example, it can help diagnose lung diseases and cancer accurately and quickly, thereby reducing the time and cost of medical treatment. In this study, image data were acquired using cultured cervical cancer cells and skin fibroblast cells. The acquired images were pre-processed using OpenCV and enabled the creation of input data optimized for training. In addition, an optimal deep learning algorithm was designed to classify cells by type using transfer learning methods. As a result, the CNN-based learning and automatic classification method proposed in this experiment showed a high accuracy of over 98% and is expected to be used for accurate diagnosis and treatment of diseases in the future."
CNN을 활용한 새싹삼의 품질 예측 모델 개발,2021,"['합성곱신경망', '새싹삼', '품질예측', '이미지 인식', 'convolutional neural network (CNN)', 'Ginseng Sprouts', 'Quality Prediction', 'Image Recognition']",,
Improved CNN-based Path Planning So an Autonomous UAV Can Climb Stairs By using a LiDAR Sensor,2021,"['UAVs', 'CNN', 'Path planning', 'Stair climbing', 'LiDAR sensor']",,"Unmanned aerial vehicles (UAVs) have tremendous potential in civil and public areas. These are especially beneficial in applications where human lives are threatened. Autonomous navigation in unknown environments is a challenging issue for UAVs where decision-based navigation is required. In this paper, a deep learning (DL) approach is presented that aids autonomous navigation for UAVs in completely unknown, GPS-denied indoor environments. The UAV is equipped with a monocular camera and a light detection and ranging (LiDAR) sensor to determine each next maneuver and distance calculation, respectively. For deeper feature extraction, a version of You Only Look Once (YOLOv3-tiny) is improved by adding a convolution layer with different filter sizes. The process is observed as an exercise where the DL model classifies the targeted image as stairs or not stairs. We created our dataset considering the indoor scenario for specific implementation. Comprehensive experimental results are compared with YOLOv3-tiny, indicating better performance in terms of accuracy, recall, F1-score, precision, and maneuvering movements."
영상 처리와 CNN을 이용한 애완동물 영상 세부 분류 비교,2021,"['fine grained classification', 'object recognition', 'image processing', 'Convolutional Neural Network']",,"The study of the fine grained classification of images continues to develop, but the study of object recognition for animals with polymorphic properties is proceeding slowly. Using only pet images corresponding to dogs and cats, this paper aims to compare methods using image processing and methods using deep learning among methods of classifying species of animals, which are fine grained classifications. In this paper, Grab-cut algorithm is used for object segmentation by method using image processing, and method using Fisher Vector for image encoding is proposed. Other methods used deep learning, which has achieved good results in various fields through machine learning, and among them, Convolutional Neural Network (CNN), which showed outstanding performance in image recognition, and Tensorflow, an open-source-based deep learning framework provided by Google. For each method proposed, 37 kinds of pet images, a total of 7,390 pages, were tested to verify and compare their effects."
A Fusion of CNN-based Frame Vector for Segment-level Video Partial Copy Detection,2021,"['비디오', '비디오 복사 검출', '비디오 부분 복사', '특징 융합', 'CNN', '딥러닝', 'video analysis', 'copy detection', 'partial-copy detection', 'feature fusion', 'deep learning']",,
Five-Class Classification of Cervical Pap Smear Images: A Study of CNN-Error-Correcting SVM Models,2021,"['Cervix Uteri', 'Diagnosis', 'Nerve Net', 'Papanicolaou Test', 'Support Vector Network']",,"Objectives: Different complex strategies of fusing handcrafted descriptors and features from convolutional neural network(CNN) models have been studied, mainly for two-class Papanicolaou (Pap) smear image classification. This paper explores asimplified system using combined binary coding for a five-class version of this problem. Methods: This system extracted featuresfrom transfer learning of AlexNet, VGG19, and ResNet50 networks before reducing this problem into multiple binarysub-problems using error-correcting coding. The learners were trained using the support vector machine (SVM) method. The outputs of these classifiers were combined and compared to the true class codes for the final prediction. Results: Despitethe superior performance of VGG19-SVM, with mean ± standard deviation accuracy and sensitivity of 80.68% ± 2.00% and80.86% ± 0.45%, respectively, this model required a long training time. There were also false-negative cases using both theVGGNet-SVM and ResNet-SVM models. AlexNet-SVM was more efficient in terms of running speed and prediction consistency. Our findings also showed good diagnostic ability, with an area under the curve of approximately 0.95. Further investigationalso showed good agreement between our research outcomes and that of the state-of-the-art methods, with specificityranging from 93% to 100%. Conclusions: We believe that the AlexNet-SVM model can be conveniently applied for clinicaluse. Further research could include the implementation of an optimization algorithm for hyperparameter tuning, as well asan appropriate selection of experimental design to improve the efficiency of Pap smear image classification."
Review on the Recent Welding Research with Application of CNN-Based Deep Learning Part II: Model Evaluation and Visualizations,2021,"['Deep learning', 'Convolution Neural Network', 'Image', 'Welding', 'Evaluation', 'Visualization']",,"With the development of deep learning technology, research on classification and regression models on welding phenomena using convolution neural networks (CNNs) are gradually increasing. Part 1 of this study introduced the characteristics of deep learning models using CNNs and their application to welding studies. In this paper, we reviewed recent welding research papers to analyze how to evaluate CNN models and visualize the modeling output, and details of evaluation index, comparison models, and visiualization methods were explained."
CNN-RNN 기반의 DNN을 활용한 DP 선박의 전력부하 예측,2021,"['심층 신경망(Deep Neural Network)', 'DP 선박(Dynamic Positioning Ship)', '전력부하 예측(Electric Power Load Forecasting)']",,
LSTM 및 CNN-LSTM 신경망을 활용한 도시부 간선도로 속도 예측,2021,"['교통속도 예측', '교통류 분석', '유고 영향권', '인공신경망', '연속류 도로', 'Traffic prediction', 'Traffic analysis', 'Traffic incident impact area', 'Artificial neural network', 'Uninterrupted flow']",,
Partial discharge detection of insulated conductors based on CNN-LSTM of attention mechanisms,2021,"['Partial discharge', 'Convolutional neural network', 'Long short-term memory', 'Attention mechanism', 'Fast Fourier transform']",,"Under the condition of a strong electric field, partial discharge often occurs when insulated wire is damaged. The recognition of partial discharge is an effective method for the fast and accurate detection of high voltage insulated wire faults. This paper proposes a PD recognition algorithm based on a convolutional neural network and long short-term memory (LSTM). In addition, attention mechanisms are introduced to give separate weights to LSTM hidden states through a mapping, weighting, and learning parameter matrix. This is done to reduce the loss of historical information and to strengthen the influence of important information. The complex relationship between the voltage signal change and the grid operation state response has been established. The proposed method is verified by the ENET data set published by VSB University. The recognition accuracy is 95.16% for no-PD and 94.44% for PD. Results from the proposed algorithm show that this method has a higher detection accuracy."
심층 CNN 기반 구조를 이용한 토마토 작물 병해충 분류 모델,2021,"['Convolutional Neural Networks', 'Deep Learning', 'Transfer Learning', 'Fine Tuning', 'Plant Diseases Classification']","토마토 작물은 병해충의 영향을 많이 받기 때문에 이를 예방하지 않으면 농업 경제에 막대한 손실을 초래할 수 있다. 따라서 토마토의 다양한 병해충의 진단을 빠르고 정확하게 진단하는 시스템이 요구된다. 본 논문에서는 ImageNet 데이터 셋 상에서 다양하게 사전 학습된 딥러닝 기반 CNN 모델을 적용하여 토마토의 9가지 병해충 및 정상인 경우의 클래스를 분류하는 시스템을 제안한다. PlantVillage 데이터 셋으로부터 발췌한 토마토 잎의 이미지 셋을 3가지 딥러닝 기반 CNN 구조를 갖는 ResNet, Xception, DenseNet의 입력으로 사용한다. 기본 CNN 모델 위에 톱-레벨 분류기를 추가하여 제안 모델을 구성하였으며, 훈련 데이터 셋에 대해 5-fold 교차검증 기법을 적용하여 학습시켰다. 3가지 제안 모델의 학습은 모두 기본 CNN 모델의 계층을 동결하여 학습시키는 전이 학습과 동결을 해제한 후 학습률을 매우 작은 수로 설정하여 학습시키는 미세 조정 학습 두 단계로 진행하였다. 모델 최적화 알고리즘으로는 SGD, RMSprop, Adam을 적용하였다. 실험 결과는 RMSprop 알고리즘이 적용된 DenseNet CNN 모델이 98.63%의 정확도로 가장 우수한 결과를 보였다.","Tomato crops are highly affected by tomato diseases, and if not prevented, a disease can cause severe losses for the agricultural economy. Therefore, there is a need for a system that quickly and accurately diagnoses various tomato diseases. In this paper, we propose a system that classifies nine diseases as well as healthy tomato plants by applying various pretrained deep learning-based CNN models trained on an ImageNet dataset. The tomato leaf image dataset obtained from PlantVillage is provided as input to ResNet, Xception, and DenseNet, which have deep learning-based CNN architectures. The proposed models were constructed by adding a top-level classifier to the basic CNN model, and they were trained by applying a 5-fold cross-validation strategy. All three of the proposed models were trained in two stages: transfer learning (which freezes the layers of the basic CNN model and then trains only the top-level classifiers), and fine-tuned learning (which sets the learning rate to a very small number and trains after unfreezing basic CNN layers). SGD, RMSprop, and Adam were applied as optimization algorithms. The experimental results show that the DenseNet CNN model to which the RMSprop algorithm was applied output the best results, with 98.63% accuracy."
"다양한 CNN 가속기에서 아키텍처에 따른 면적, 에너지, 성능 분석",2021,"['CNN 가속기', '아키텍처', '메모리 대역폭', '뉴럴 네트워크', 'CNN accelerators', 'architecture', 'memory bandwidth', 'neural networks']","Convolution Neural Network 가속기는 AI시대에 중요한 요소 중 하나로 떠오르게 되었다. CNN 가속기의 내부 구성을 몇 가지로 나눈다면 연산을 위한 Multiplier-Accumulator (MAC unit), 데이터 저장을 위한 SRAM, 데이터 이동을 위한 메모리 인터페이스 그리고 제어 로직으로 구분할 수 있다. 다양한 CNN 가속기들의 경우, 각기 다른 공정과 동작 주파수를 기준으로 제안되었으며, 또한 아키텍처 형태에 따라 내부 MAC unit의 수와 SRAM의 크기가 매우 큰 차이를 갖는 형태로 구성되어있다. 각 가속기들의 기본 사양으로 면적, 에너지, 성능을 비교하였을 때는 공정이나 동작 주파수 등 여러 조건들에 의해서 아키텍처에 따른 정량적인 비교가 용이하지 않게 된다. 따라서, 본 논문에서는 다양한 CNN 가속기에서 여러 조건들을 동일하게 재구성하였을 때, ResNet-50 추론 동작 시에 요구되는 면적, 에너지, 성능을 비교하여 아키텍처의 특징과 경향성을 분석하였다.","The Convolution Neural Network accelerator has emerged as an important element in the AI era. The primary components of a CNN accelerator include the Multiplier-Accumulator (MAC unit) for calculation, SRAM for data storage, memory interface for data movement, and control logic. Different CNN accelerators have been designed based on different assumptions regarding the process technologies and operating frequencies. In addition, the number of internal MAC units and the size of SRAM vary substantially between different types of architectures. These factors make it difficult to design a fair comparison of the area, energy, and performance of different CNN accelerators. In this paper, we attempt to compare the area, energy, and performance of different CNN accelerator architectures by constructing them all with the same fabrication process and operating frequency while making inferences using the ResNet-50 network."
저계수 행렬 근사 및 CP 분해 기법을 이용한 CNN 압축,2021,"['CNN', 'Neural Network Compression', 'Low-Rank Approximation', 'Canonical polyadic decomposition']",,"In recent years, Convolutional Neural Networks (CNNs) have achieved outstanding performance in the fields of computer vision such as image classification, object detection, visual quality enhancement, etc. However, as huge amount of computation and memory are required in CNN models, there is a limitation in the application of CNN to low-power environments such as mobile or IoT devices. Therefore, the need for neural network compression to reduce the model size while keeping the task performance as much as possible has been emerging. In this paper, we propose a method to compress CNN models by combining matrix decomposition methods of LR (Low-Rank) approximation and CP (Canonical Polyadic) decomposition. Unlike conventional methods that apply one matrix decomposition method to CNN models, we selectively apply two decomposition methods depending on the layer types of CNN to enhance the compression performance. To evaluate the performance of the proposed method, we use the models for image classification such as VGG-16, RestNet50 and MobileNetV2 models. The experimental results show that the proposed method gives improved classification performance at the same range of 1.5 to 12.1 times compression ratio than the existing method that applies only the LR approximation."
Effect of Input Data Video Interval and Input Data Image Similarity on Learning Accuracy in 3D-CNN,2021,"['3D-CNN', 'Gesture recognition', 'RNN', '2D-Cross correlation']",,"3D-CNN is one of the deep learning techniques for learning time series data. However, these three-dimensional learning can generate many parameters, requiring high performance or having a significant impact on learning speed. We will use these 3D-CNNs to learn hand gesture and find the parameters that showed the highest accuracy, and then analyze how the accuracy of 3D-CNN varies through input data changes without any structural changes in 3D-CNN. First, choose the interval of the input data. This adjusts the ratio of the stop interval to the gesture interval. Secondly, the corresponding interframe mean value is obtained by measuring and normalizing the similarity of images through interclass 2D cross correlation analysis. This experiment demonstrates that changes in input data affect learning accuracy without structural changes in 3D-CNN. In this paper, we proposed two methods for changing input data. Experimental results show that input data can affect the accuracy of the model."
패션 요소 검출을 위한 Mask R-CNN 딥러닝,2021,"['인공지능', '패션', 'R-CNN', 'Fast R-CNN', 'Faster R-CNN', 'Mask R-CNN', 'Artificial Intelligence', 'Fashion']",,"In this paper, in order to prepare a framework that can provide personalized artificial intelligence fashion coordination services, fashion elements were detected using the Mask R-CNN deep learning algorithm targeting the fashion image data set provided in the iMaterialist Fashion Attribute Dataset. As a result of performing deep learning to detect fashion elements with a total of 8 epochs, the loss of training data was found to be Lcls 0.53, Lbox 0.38, and Lmask 0.35. And the loss of Validation data was Lcls 0.54, Lbox 0.33, Lmask 0.36. Effective personal artificial intelligence fashion when fine-tuning using the deep learning method implemented in this paper after adding various conditions such as color, season, material, trend, and brand name based on the fashion image data set owned by an individual It is expected that it will be a coordination service."
지루성 두피염 진단을 위한 Faster R-CNN과 Atrous 컨볼루션 기반의 두피 각질 검출 기법,2021,"['지루성 두피염', '두피 관리', 'Atrous 컨볼루션', '객체 검출', 'seborrheic scalpitis', 'hair care', 'faster R-CNN', 'atrous convolution', 'object detection']","지루성 두피염은 과도한 스트레스나 화학제품의 남용, 불균형한 영양 섭취 등 다양한 요인으로 인해 발생하는 질병이다. 두피염의 대표적인 증상은 두피의 각질과 통증이며, 증상이 심해지면 탈모가 발생할 수 있다. 이에 각질 검출을 통해 두피염을 초기에 진단할 수 있는 스마트폰 기반의 애플리케이션이 다수 개발되었다. 하지만, 대부분은 수치로 된 분석 결과만을 제공할 뿐, 그 수치에 관한 근거를 확인하기 어렵다. 따라서, 본 논문에서는 지루성 두피염 진단을 위한 근거를 시각적으로 보여주기 위해 두피 영상에서 각질의 유무와 위치를 추출하는 기법을 제안한다. 이를 위해, 각질 검출에 Faster R-CNN (Faster Regions with Convolutional Neural Network) 모델을 사용하였으며, 모델의 성능을 더욱 향상하기 위해 Atrous 컨볼루션 연산을 적용하였다. 기존 컨볼루션과 Atrous 컨볼루션을 적용한 Faster R-CNN의 비교를 통해 우리가 제안하는 기법이 효과적으로 두피 각질을 검출할 수 있음을 보인다.","Seborrheic scalpitis can be caused by various factors, such as excessive stress, abuse of chemicals, and unbalanced nutrition. Typical symptoms of this disease entity are keratin and pain over the scalp, and when the symptoms become severe, hair loss may occur. Although various smartphone applications have been developed for early detection of scalpitis, it is difficult to ascertain the rationale for the results because they only provide numerical analysis. Therefore, in this paper, we propose a method for detection of keratin from scalp images to visualize the basis for diagnosing seborrheic scalpitis. In particular, we use the Faster Regions with Convolutional Neural Network (Faster R-CNN) model for keratin detection and apply atrous convolution to further improve the detection performance. By comparing our proposed method to the original Faster R-CNN method, we show that our method can effectively diagnose the symptoms of seborrheic scalpitis."
CNN 보조 손실을 이용한 차원 기반 감성 분석,2021,"['온라인 리뷰 분석', '차원 기반 감성 분석', 'Online review analysis', 'ABSA', 'TASD', 'CNN', 'BERT']",,"Aspect Based Sentiment Analysis (ABSA), which analyzes sentiment based on aspects that appear in the text, is drawing attention because it can be used in various business industries. ABSA is a study that analyzes sentiment by aspects for multiple aspects that a text has. It is being studied in various forms depending on the purpose, such as analyzing all targets or just aspects and sentiments. Here, the aspect refers to the property of a target, and the target refers to the text that causes the sentiment. For example, for restaurant reviews, you could set the aspect into food taste, food price, quality of service, mood of the restaurant, etc. Also, if there is a review that says, The pasta was delicious, but the salad was not, the words steak and salad, which are directly mentioned in the sentence, become the “target.”  So far, in ABSA, most studies have analyzed sentiment only based on aspects or targets. However, even with the same aspects or targets, sentiment analysis may be inaccurate. Instances would be when aspects or sentiment are divided or when sentiment exists without a target. For example, sentences like, Pizza and the salad were good, but the steak was disappointing. Although the aspect of this sentence is limited to “food,” conflicting sentiments coexist. In addition, in the case of sentences such as Shrimp was delicious, but the price was extravagant, although the target here is “shrimp,” there are opposite sentiments coexisting that are dependent on the aspect. Finally, in sentences like The food arrived too late and is cold now. there is no target (NULL), but it transmits a negative sentiment toward the aspect service. Like this, failure to consider both aspects and targets – when sentiment or aspect is divided or when sentiment exists without a target – creates a dual dependency problem.  To address this problem, this research analyzes sentiment by considering both aspects and targets (Target-Aspect-Sentiment Detection, hereby TASD). This study detected the limitations of existing research in the field of TASD: local contexts are not fully captured, and the number of epochs and batch size dramatically lowers the F1-score. The current model excels in spotting overall context and relations between each word. However, it struggles with phrases in the local context and is relatively slow when learning. Therefore, this study tries to improve the models performance.  To achieve the objective of this research, we additionally used auxiliary loss in aspect-sentiment classification by constructing CNN(Convolutional Neural Network) layers parallel to existing models. If existing models have analyzed aspect-sentiment through BERT encoding, Pooler, and Linear layers, this research added CNN layer-adaptive average pooling to existing models, and learning was progressed by adding additional loss values for aspect-sentiment to existing loss. In other words, when learning, the auxiliary loss, computed through CNN layers, allowed the local context to be captured more fitted. After learning, the model is designed to do aspect-sentiment analysis through the existing method.  To evaluate the performance of this model, two datasets, SemEval-2015 task 12 and SemEval-2016 task 5, were used and the f1-score increased compared to the existing models. When the batch was 8 and epoch was 5, the difference was largest between the F1-score of existing models and this study with 29 and 45, respectively. Even when batch and epoch were adjusted, the F1-scores were higher than the existing models. It can be said that even when the batch and epoch numbers were small, they can be learned effectively compared to the existing models. Therefore, it can be useful in situations where resources are limited.  Through this study, aspect-based sentiments can be more accurately analyzed. Through various uses in business, such as development or establishing marketing strategies, both consumers and sellers will be able to"
리튬이온 배터리 열분포 이미지를 활용한 CNN 기반 SOC 추정 연구,2021,"['Lithium-ion battery', 'Convolutional neural network', 'State-of-charge', 'Heat distribution image']",,
Korean Finger Number Gesture Recognition Based on CNN Using Surface Electromyography Signals,2021,['Convolutionary Neural Network  · Korean fi nger number gesture  · Surface electromyography signal'],,"This study proposes a recognition strategy for Korean fi nger number gestures based on convolutional neural network (CNN) using surface electromyography (sEMG) signals. A few studies have reported Chinese fi nger number gesture recognition using sEMG signals. However, fi nger number gestures vary across diff erent regions, prompting the need to investigate fi nger number gesture recognition specifi c to Koreans. To this end, six Korean fi nger number gestures ranging from zero to fi ve were selected and recognized by CNN using sEMG signals acquired from four pairs of electrodes on forearm muscles. In this study, we investigated the feasibility of CNN in fi nger number gesture recognition using sEMG time series data. The experimental results show that CNN achieved a 100% recognition rate over six Korean fi nger number gestures using sEMG time-series data. A comparative analysis of diff erent studies indicates that the proposed approach may be at least comparable to the existing studies selected in this work. It is therefore a more convenient and promising platform for recognition of fi nger number gestures."
CNN(Convolutional Neural Network) 모델을 이용한 야구 경기 영상의 동작 분류 및 검색시스템,2021,"['Deep Learning', 'Convolutional Neural Network', 'Scene classification and retrieval', '딥 러닝', 'CNN 신경망', '영상 분류 및 검색']","본 연구에서는 CNN(Convolution Neural Network) 모델을 이용하여 야구 경기 영상에서 투구나 스윙과 같은 특정 영상이 출현하는 장면을 자동으로 분류하여 효과적으로 검색하는 방법을 제안한다. 또한, 특정 동작의 분류 결과와 경기 기록을 연계한 영상 장면 검색시스템을 제안한다. 제안 시스템의 효율성을 검정하기 위하여 2018년부터 2019년까지 진행된 한국프로야구 경기 영상을 대상으로 특정 장면별로 분류하는 실험을 진행하였다. 야구 경기 영상에서 투구 장면을 분류하는 실험에서는 경기별로 약 90%의 정확도를 보였다. 그리고 경기 영상 내에 포함된 스코어보드를 추출하여 경기 기록과 연계하는 영상 장면 검색 실험에서는 경기별로 약 80% 정도의 정확도를 보였다. 본 연구 결과는 한국프로야구 경기에서 과거 경기 영상을 체계적으로 분석하여 경기력 향상을 위한 전략 수립을 위하여 효과적으로 사용할 수 있으리라 기대한다.","In this paper, we propose a method to effectively search by automatically classifying scenes in which specific images such as pitching or swing appear in baseball game images using a CNN(Convolution Neural Network) model. In addition, we propose a video scene search system that links the classification results of specific motions and game records. In order to test the efficiency of the proposed system, an experiment was conducted to classify the Korean professional baseball game videos from 2018 to 2019 by specific scenes. In an experiment to classify pitching scenes in baseball game images, the accuracy was about 90% for each game. And in the video scene search experiment linking the game record by extracting the scoreboard included in the game video, the accuracy was about 80% for each game. It is expected that the results of this study can be used effectively to establish strategies for improving performance by systematically analyzing past game images in Korean professional baseball games."
CNN 강우여부 분류기를 적용한 ANN 기반 X-Band 레이다 유의파고 보정,2021,"['X-band 레이다', '유의파고', '머신러닝', '인공신경망', '합성곱신경망', 'X-band marine radar', 'significant wave heights', 'machine learning', 'artificial neural network(ANN)', 'convolutional neural network(CNN)']",항해용 X-band 레이다를 이용한 파랑관측은 해수면에 후방산란 된 전자기파 이미지를 분석하여 이루어진다. 1분당 42개의 해수면 시계열 이미지로부터 3차원 FFT를 계산하고 변조전달함수(Modulation Transfer Function)를 구하여 파랑정보를 추출한다. 따라서 레이다 파고계로 계측한 유의파고의 정확도는 X-band 레이다 영상의 상태에 따라 결정된다. 2020년 여름 태풍 마이삭과 하이선 내습 시 강릉 안인 해안에 설치된 X-band 레이다 파고계로 관측한 유의파고의 오차가 크게 발생하였다. 이는 태풍 내습 시 급격히 유의파고가 증가하는 한편 강한 강우가 동반되어 X-band 레이다 영상의 품질이 저하되었기 때문이다. 최대 오차 발생 이전까지 많은 강우가 있었음이 확인된다. 본 연구에서는 convolution neural network(CNN)을 이용하여 레이다 이미지로부터 강우 여부를 분류하고 강우여부에 따라 강우시 인공신경망 모델을 적용하여 태풍 시 유의파고 관측 정확도를 향상시켰다. 폭우를 동반한 태풍 시 레이다 자료 특성에 기반하여 인공신경망 유의파고 산출 알고리즘을 개선하고 이를 통해 X-band 레이다 파고계의 정확도를 향상시키는 방법을 제시하였다.,"Wave observations using a marine X-band radar are conducted by analyzing the backscattered radar signal from sea surfaces. Wave parameters are extracted using Modulation Transfer Function obtained from 3D wave number and frequency spectra which are calculated by 3D FFT of time series of sea surface images (42 images per minute). The accuracy of estimation of the significant wave height is, therefore, critically dependent on the quality of radar images. Wave observations during Typhoon Maysak and Haishen in the summer of 2020 show large errors in the estimation of the significant wave heights. It is because of the deteriorated radar images due to raindrops falling on the sea surface. This paper presents the algorithm developed to increase the accuracy of wave heights estimation from radar images by adopting convolution neural network(CNN) which automatically classify radar images into rain and non-rain cases. Then, an algorithm for deriving the Hs is proposed by creating different ANN models and selectively applying them according to the rain or non-rain cases. The developed algorithm applied to heavy rain cases during typhoons and showed critically improved results."
Speech Emotion Recognition Using 2D-CNN with Mel-Frequency Cepstrum Coefficients,2021,"['Convolutional neural network', 'Deep learning', 'Mel-frequency cepstrum coefficients', 'Speech emotion recognition']",,"With the advent of context-aware computing, many attempts were made to understand emotions. Among these various attempts, Speech Emotion Recognition (SER) is a method of recognizing the speaker's emotions through speech information. The SER is successful in selecting distinctive 'features' and 'classifying' them in an appropriate way. In this paper, the performances of SER using neural network models (e.g., fully connected network (FCN), convolutional neural network (CNN)) with Mel-Frequency Cepstral Coefficients (MFCC) are examined in terms of the accuracy and distribution of emotion recognition. For Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS) dataset, by tuning model parameters, a two-dimensional Convolutional Neural Network (2D-CNN) model with MFCC showed the best performance with an average accuracy of 88.54% for 5 emotions, anger, happiness, calm, fear, and sadness, of men and women. In addition, by examining the distribution of emotion recognition accuracies for neural network models, the 2D-CNN with MFCC can expect an overall accuracy of 75% or more."
Pattern Classification for Small-Sized Defects Using Multi-Head CNN in Semiconductor Manufacturing,2021,['Automatic defect classification (ADC) · Convolutional neural network (CNN) · Modified median filtering · Rotated defects (RoD) transform'],,"To improve the quality of semiconductor manufacturing, defects need to be detected and their root causes controlled. Because the root causes can vary depending on defect patterns, classifying the patterns accurately is important. Several recent studies have investigated automatic defect classification using a convolutional neural network (CNN) with wafer map images. CNNs are excellent tools for classifying images of different shapes and sizes. However, the detection of small-sized defects that have small clusters and linear patterns is difficult. Therefore, this study focuses on patterns that are difficult to detect. We propose three steps for pattern classification. First, modified median filtering is used to preserve the original shapes of patterns. Second, a rotated defects (RoD) transform is performed by applying the rotational properties of wafer maps. The RoD transform augments the defect proportion and improves the detection of small-sized defects. Third, a multi-head CNN is used to extract and combine the features from the original and transformed maps. The combined features are then used to classify the defect patterns. Overall classification performance of defects can be improved by accurately classifying small clusters and linear patterns. The proposed model was evaluated using WM-811K wafer maps, and small-sized defects were accurately classified. Such an accurate defect classification model will enable effective root cause analysis and quality improvement in semiconductor manufacturing."
Activity Object Detection Based on Improved Faster R-CNN,2021,"['Human activity object', 'Faster R-CNN', 'Dense-Net', 'Soft-NMS']",,
Automatic Fracture Detection in CT Scan Images of Rocks Using Modified Faster R-CNN Deep-Learning Algorithm with Rotated Bounding Box,2021,"['Fracture detection', 'Computed tomography', 'Deep learning', 'Faster R-CNN', 'Rotated bounding box', '균열 탐지', '컴퓨터 단층촬영', '딥러닝 알고리즘', '회전 경계박스']","본 논문에서는 암석시료의 CT 촬영 이미지상의 균열을 자동으로 탐지하는 새로운 인공지능 딥러닝 기법을 제안한다. 본 제안 기법은 2단계 딥러닝 객체인식 알고르즘인 Faster R-CNN을 기반으로 회전 가능한 경계박스(bounding box) 개념을 도입하여 알고리즘을 개조하였다. 회전 경계박스의 도입은 관심 균열 영역 밖의 배경의 불균질성 및 균열의 크기와 형태에 영향을 받는 딥러닝 객체인식기법 상의 고유한 어려움을 극복하기 위한 핵심 역할을 한다. 본 회전형 경계박스의 사용은 일반적으로 사용되는 영상 수평 축과 평행한 경계박스 사용의 경우와 비교하여 긴 형태의 균열 형상 특성에 매우 잘 부합된다. 즉, 좋지 않은 영향을 끼치는 경계박스 내 균열 이외 배경영역의 비율을 최소화 시킬 수 있다. 이외에도, 회전 경계 박스의 추가적인 이점은 인식된 균열의 방향에 따라 회전하여 추론되는 경계박스를 통해 균열의 방향과 길이에 대한 정보를 직접적으로 얻을 수 있다. 본 제안기법의 적용성을 검증하기 위하여, 이미지상에서 매우 불균질한 화강암 시료에 인공적으로 균열을 발생시킨 다수의 암석시료 영상을 딥러닝 학습에 사용하고 추론 성능 실험을 진행하였다. 그 외에도, 동일 조건에서 사암과 셰일 암석 시료에도 적용하여 검증하였다. 결론적으로, 제안된 기법을 통해 균열 객체 인식의 평균 추론정확도(mAP)값이 0.89 정도 수준의 우수한 추론 성능을 보였으며, 기존 기법에 비해 추론된 경계박스 내 균열과 배경 영역의 비율 측면에 서 배경의 비율이 획기적으로 최소화되는 유리한 추론 검증 결과를 보였다.","In this study, we propose a new approach for automatic fracture detection in CT scan images of rock specimens. This approach is built on top of two-stage object detection deep learning algorithm called Faster R-CNN with a major modification of using rotated bounding box. The use of rotated bounding box plays a key role in the future work to overcome several inherent difficulties of fracture segmentation relating to the heterogeneity of uninterested background (i.e., minerals) and the variation in size and shape of fracture. Comparing to the commonly used bounding box (i.e., axis-align bounding box), rotated bounding box shows a greater adaptability to fit with the elongated shape of fracture, such that minimizing the ratio of background within the bounding box. Besides, an additional benefit of rotated bounding box is that it can provide relative information on the orientation and length of fracture without the further segmentation and measurement step. To validate the applicability of the proposed approach, we train and test our approach with a number of CT image sets of fractured granite specimens with highly heterogeneous background and other rocks such as sandstone and shale. The result demonstrates that our approach can lead to the encouraging results on fracture detection with the mean average precision (mAP) up to 0.89 and also outperform the conventional approach in terms of background-to-object ratio within the bounding box."
CNN 기반 근전도의 2D 스펙트로그램 이미지를 이용한 사용자 인식,2021,"['EMG', 'user recognition', 'spectrogram', 'CNN']",,"Recently, user recognition using biometric information has become a social issue due to forgery, alteration, and accidents, and research on user recognition using biometric signals is actively underway. Biometric signals are electrical signals that occur inside the body and generate individual-specific signals according to behavioral characteristics. Bio-signals typically include musculature, electrocardiogram, and cerebral conduction. Among the biometric signals the EMG signal is applied in the field of user recognition using features measured in different signal patterns according to an individual’s unique strength. In this paper, transform pre-processed one-dimensional EMG signals into two-dimensional EMG spectrogram images, extract features using CNN, and finally recognize the user to analyze the performance of the user recognition system. As a result of the experiment, user awareness of 40 people was analyzed to be 95.4%(±1.7%) when using 12 channels and the window length R of STFT was 256."
CNN 기반 특징맵 사용에 따른 특징점 가시화와 에러율,2021,"['CNN', 'Robustness', 'Deep learning', 'Image processing', 'Sparse Connection']",,"In this paper, we presented the experimental basis for the theoretical background and robustness of the Convolutional Neural Network for object recognition based on artificial intelligence. An experimental result was performed to visualize the weighting filters and feature maps for each layer to determine what characteristics CNN is automatically generating. experimental results were presented on the trend of learning error and identification error rate by checking the relevance of the weight filter and feature map for learning error and identification error. The weighting filter and characteristic map are presented as experimental results. The automatically generated characteristic quantities presented the results of error rates for moving and rotating robustness to geometric changes."
CNN based classifi cation of motor imaginary using variational mode decomposed EEG-spectrum image,2021,['.'],,"A novel approach of preprocessing EEG signals by generating spectrum image for eff ective Convolutional Neural Network(CNN) based classifi cation for Motor Imaginary (MI) recognition is proposed. The approach involves extracting the VariationalMode Decomposition (VMD) modes of EEG signals, from which the Short Time Fourier Transform (STFT) of allthe modes are arranged to form EEG spectrum images. The EEG spectrum images generated are provided as input image toCNN. The two generic CNN architectures for MI classifi cation (EEGNet and DeepConvNet) and the architectures for patternrecognition (AlexNet and LeNet) are used in this study. Among the four architectures, EEGNet provides average accuracies of91.37%, 94.41%, 85.67% and 90.21% for the four datasets used to validate the proposed approach. Consistently better resultsin comparison with results in recent literature demonstrate that the EEG spectrum image generation using VMD-STFT is apromising method for the time frequency analysis of EEG signals."
Human Face Recognition Based on improved CNN Model with Multi-layers,2021,"['Face Recognition', 'CNN Model', 'ORL Database', 'AR Face Database', 'Residual Network']",,
직접 볼륨 렌더링을 위한 CNN 기반 TF 색상 매핑,2021,"['직접 볼륨 렌더링', 'TF 색상화', 'Direct Volume Rendering', 'CNN', 'TF colorization']",직접 볼륨 렌더링은 볼륨 표면의 연산 없이 2차원 공간에 투영하여 렌더링 한다. 직접 볼륨 렌더링에서 전이함수(TF)는 볼륨에 색상과 투명도와 같은 광원 특성을 할당하는데 활용된다. 하지만 초보자가 TF를 조작하여 볼륨데이터를 파악하고 색상을 할당하기까지 오랜 시간이 필요합니다. 본 논문에서는 직관적인 볼륨 렌더링을 위해 인터넷에서 수집한 이미지를 사용하여 TF에 볼륨의 색상을 매핑하는 접근 방식을 제안한다. 또한 우리는 K-means 클러스터링을 활용한 색상 추출 방법을 토의한다.,"Direct Volume Rendering(DVR) renders by projecting data into a two-dimensional space without calculating the volume surfaces. In DVR, the transfer function(TF) assigns light properties such as color and transparency to the volume. However, it takes a long time for beginners to manipulate TF to understand volume data and assign colors. This paper proposes an approach to colorize the volume using sample images for intuitive volume rendering. We also discuss color extraction methods using K-means clustering."
Filter Combination Learning for CNN Model Compression,2021,"['Deep learning', 'Model compression', 'Filter combination']",,"In this paper, we propose a new method for generating convolution filters of a convolutional neural network (CNN) model as linear combinations of only a few basis filters that are provided as input features. In our approach, best coefficients of the linear combinations are searched (trained) with the given input basis filters (IBFs) to reconstruct the convolution filter parameters. Since all the convolution filters can be generated by the linear combinations of the IBFs, the size of a CNN model can be compressed if the number of coefficients for the linear combinations is less than that of filter parameters. Our primary goal is to investigate the possibility of expressing filters with a small set of IBFs by linear combinations. The second goal is to compress a model so that it can be beneficial when the model is distributed and stored (particularly downloaded to mobile devices through Wi-Fi)."
ConvXGB: A new deep learning model for classification problems based on CNN and XGBoost,2021,"['Convolutional neural network (CNN)', 'Classification algorithms', 'Deep learning', 'Extreme gradient boosting', 'XGBoost', 'Machine learning', 'Pattern recognition']",,"We describe a new deep learning model - Convolutional eXtreme Gradient Boosting (ConvXGB) for classification problems based on convolutional neural nets and Chen et al.'s XGBoost. As well as image data, ConvXGB also supports the general classification problems, with a data preprocessing module. ConvXGB consists of several stacked convolutional layers to learn the features of the input and is able to learn features automatically, followed by XGBoost in the last layer for predicting the class labels. The ConvXGB model is simplified by reducing the number of parameters under appropriate conditions, since it is not necessary re-adjust the weight values in a back propagation cycle. Experiments on several data sets from UCL Repository, including images and general data sets, showed that our model handled the classification problems, for all the tested data sets, slightly better than CNN and XGBoost alone and was sometimes significantly better."
리튬이온 배터리 노화상태 추정을 위한 건전성 지표 추출 및 CNN 적용,2021,"['Health indicator', 'Lithium-ion battery', 'Convolutional neural network', 'Urban dynamometer driving schedule', 'State-of-health estimation']",,"Due to the output characteristics of lithium-ion batteries used in electric vehicles (EVs) vary according to battery aging, accurate prediction of the state-of-health (SOH) reflecting the aging state is important. However, it is difficult to consider factors affecting battery characteristics, such as frequent charging and discharging, operating temperature, and state of charge, so there is a limitation in predicting battery SOH. Even in a model that considers the aging state of the battery under these various conditions, there is also a problem in that the complexity of the calculation process and parameters becomes serious. Therefore, in this paper, in order to research on the estimation of the aging state during operation of the INR18650-25R battery, a health indicator (HI) that can reflect the internal state of the battery according to aging is extracted. This research produce a learning image through the extracted HI and build a model study that enables algorithm learning through the image. The experimental profile used for model training and validation was an Urban Dynamometer Driving Schedule (UDDS), and a Convolutional Neural Network (CNN) with strength in image learning was applied for the estimation algorithm."
CNN 을 이용한 동전 분류,2021,"['CNN', 'machine learning', 'coin', 'coin classification', 'currency']",,
CNN 기반 깊이 추정을 이용한 실시간 장애물 회피,2021,"['path planning', 'deep learning', 'monocular depth estimation', 'collision avoidance']",,"The purpose of autonomous navigation is to reach the destination without collision. Traditionally, mobile robots have used LIDAR, sonar sensors, or stereo cameras to avoid obstacles. However, UAVs suffer from the selection of sensors due to payload capacity. To resolve this issue, we design the method using the only a monocular camera for obstacle avoidance on a quadrotor. In order to obtain the depth images, we use a CNN (Convolutional Neural Network). To improve the depth estimation performance, we develop a data augmentation algorithm of the magnified images especially ranging from 0.5~1 meters. By using the estimated depth image, the desired direction of the quadrotor is set. To validate our proposed algorithm, we conduct experiments with real drones in indoor environments. An analysis of the experiments shows that the proposed method can be utilized for navigation in cluttered environments."
CNN 기반 장르 소분류 모델을 활용한 실시간 음악 장르 분류 모델 연구,2021,"['Music Genre Classification', 'CNN', 'Machine Learning', 'Ensemble model']",,"In this paper, we propose an N-genre music classification model and ensemble models that can more accurately classify 10 music genres based on the proposed N-genre model. The GTZAN data set is used as the music data set, and different MFCC-based color maps are compared to identify the one that produces the best classification accuracy. Two methods of model learning are used: (i) using a 30 s long music image and (ii) using a 5 s long music image, wherein the latter utilizes the voting method. The classification accuracy of these two methods is compared. Among the various types of MFCC-based color maps, the gist-rainbow method with better classification accuracy is chosen, and the 3-genre classification model is actually selected among several N-genre classification models. Furthermore, ensemble models overlapped for four genres is proposed and their classification accuracies are compared. Ensemble Model II, using the voting method, obtains an accuracy of 92.0% for the GTZAN data set. The classification accuracy of the proposed ensemble model II is compared with the those of the other reported models."
CNN(Convolutional Neural Network) 알고리즘을 활용한 음성신호 중 비음성 구간 탐지 모델 연구,2021,"['음성인식', '딥러닝', '합성곱신경망', '인공지능', 'NLP', 'Speech Recognition', 'Deep-Learning', 'CNN', 'Artificial-Intelligence', 'NLP']",,
Gradient Flow Analysis and Performance Comparison of CNN Models,2021,"['CNN', '그래디언트 소실', '그래디언트 플로우', '성능 비교', '오류율', 'gradient vanishing problem', 'gradient flow', 'performance comparison', 'error rate']",,
계층적 CNN 기반 스테가노그래피 알고리즘의 6진 분류,2021,"['Steganography', 'Steganalysis', 'Hierarchical CNN', 'Senary Classification']",,
일반화 능력이 향상된 CNN 기반 위조 영상 식별,2021,"['Fake Image Identification', 'Generative Adversarial Networks', 'Image Forensics', 'CNN', 'Generalization']",,
Loss Compensation Faster R-CNN을 이용한 문서 이미지 내 표 검출 정확도 향상,2021,"['Table Detection', 'Deep Learning', 'Faster R-CNN', 'Loss Compensation Training']",,
복부 CT 영상에서 밝기값 정규화 및 Faster R-CNN을 이용한 자동 췌장 검출,2021,"['Object Detection', 'Faster R-CNN', 'Inception V2', 'Abdominal CT Images', 'Pancreas']",,
CNN 기반 딥러닝을 이용한 패션 아이템 분류 및 결합,2021,"['인공지능', '딥러닝', '머신러닝', '합성곱 신경망', '생성적 적대 신경망', '패션', 'Artificial Intelligence', 'Deep Learning', 'Machine Learning', 'Convolutional Neural Network', 'Generative Adversarial Network', 'Fashion']",,"In this paper, in order to implement an artificial intelligence system that can appropriately match fashion items according to the situation, a deep learning model based on convolutional neural network was designed after labeling with 10 fashion items based on fashion-MNIST. Based on the designed deep learning model, 45,000 fashion images were used as a training dataset, and 15,000 fashion images were used as a verification dataset, and deep learning was performed with a total of 15 epochs. As a result of the deep learning execution, the training data learning accuracy 96% and the verification data learning accuracy 94% were output in the accuracy evaluation of fashion item classification. In this paper, we constructed a dataset that can provide 7 types of fashion matching based on the implemented artificial intelligence fashion item classification system. The established dataset is expected to become the basis of an artificial intelligence fashion matching service that can satisfy various fashion needs of individuals in the future."
Lightweight Convolutional Neural Network (CNN) based COVID-19 Detection using X-ray Images,2021,"['Coronavirus', 'Computer Tomography', 'Convolutional Neural Network', 'X-ray']",,"In 2019, a novel coronavirus (COVID-19) outbreak started in China and spread all over the world. The countries went into lockdown and closed their borders to minimize the spread of the virus. Shortage of testing kits and trained clinicians, motivate researchers and computer scientists to look for ways to automatically diagnose the COVID-19 patient using X-ray and ease the burden on the healthcare system. In recent years, multiple frameworks are presented but most of them are trained on a very small dataset which makes clinicians adamant to use it. In this paper, we have presented a lightweight deep learning base automatic COVID-19 detection system. We trained our model on more than 22,000 dataset X-ray samples. The proposed model achieved an overall accuracy of 96.88% with a sensitivity of 91.55%."
높은 정밀도를 위한 CNN 기반의 개선된 모션 인식기,2021,"['Artificial intelligence', 'Convolution neural network', 'Deep learning', 'Motion recognition', 'Human activity recognition (HAR)', 'Sensors', 'Time series data']",,"Motion recognition (MR) is to understand and analyze the movements of things. This technique can categorize the movements into several activities and enables us understand the movements. Among the MR, human activity recognition (HAR) is to recognize what a person is doing. HAR has various applications such as rehabilitation engineering, health care, human machine interactive, security based on vision. HAR can be achieved with the help of sensor data or camera based vision information. The vision information results from monocular/binocular cameras, whereas the sensor data in general are from wearable sensors or sensors embedded in smartphones. The measured data are analyzed to carry out HAR. The data analysis methods include machine learning and neural networks. In the neural network based data analysis, the introduced time series data are converted into images, and the images are used for training of neural networks. In this paper, a new accuracy enhanced method is proposed in convolution neural network based HAR. If two images have their unique features, person may recognize the difference between the two images. Motivated from this intuition, this paper suggests a new method to add the unique feature, resulting in more precise accuracy. In this paper, firstly an optimal image conversion method is found via base line tests and secondly a reasonable neural network without overfitting is designed by trimming hyper parameters. From the experimental results, it is verified that the proposed method is valid and effective."
An Evaluation Method for Generalization Errors of CNN using Training Data,2021,"['합성곱 신경망', '일반화 오류', '반응 셋', '상대적 일반화 오류', 'convolutional neural network', 'generalization error', 'response set', 'relative generalization error']",,
Inspecting Method for Defective Casting Products with Convolutional Neural Network (CNN),2021,['Convolution neural network · Defect inspection · Casting product · Deep learning'],,"It is essential to conduct the quality control for gauranteeing sound products after finishing conventional manufacturing processes. Vision-based inpection system has been extensively applied to various industries linked with concept of the smart factory sin c e it does not only enhance the inspecting accuracy, but also decrease the cost for the human inspection, substantially. This paper mainly concerns the development of the inspecting system for the casting products with supported by the convolutional neural network, which makes it possible to detect various types of defects such as blow hole, chipping, crack, and wash automatically. To obtain high accuracy in inspecting system, it does not only require sub-partitioning of the original images, but also apply multiple labeling according to the order of the sub-images and the existence of the defects. Performance of the proposed inspecting algorithm has been validated with the 400 casting products, in which it exhibits substantially high accuracy more than 98%, experimentally."
Connection stiffness reduction analysis in steel bridge via deep CNN and modal experimental data,2021,"['structural monitoring', 'machine learning', 'steel truss bridge', 'vibration', 'numerical simulation', 'damage detection and localization', 'convolutional neural networks']",,"This study devises a novel approach, namely quadruple 1D convolutional neural network, for detecting connection stiffness reduction in steel truss bridge structure using experimental and numerical modal data. The method is developed based on expertise in two domains: firstly, in Structural Health Monitoring, the mode shapes and its high-order derivatives, including second, third, and fourth derivatives, are accurate indicators in assessing damages. Secondly, in the Machine Learning literature, the deep convolutional neural networks are able to extract relevant features from input data, then perform classification tasks with high accuracy and reduced time complexity. The efficacy and effectiveness of the present method are supported through an extensive case study with the railway Nam O bridge. It delivers highly accurate results in assessing damage localization and damage severity for single as well as multiple damage scenarios. In addition, the robustness of this method is tested with the presence of white noise reflecting unavoidable uncertainties in signal processing and modeling in reality. The proposed approach is able to provide stable results with data corrupted by noise up to 10%."
Synthetic Deep Neural Network Design for Lidar-inertial Odometry Based on CNN and LSTM,2021,"['Deep learning', 'Lidar-inertial odometry', 'loss function', 'pose estimation', 'synthetic neural network.']",,"This paper proposes an integrated navigation algorithm based on the deep learning method using lidar and inertial measurements. The proposed method develops a new synthetic structure of neural networks for implementing the Lidar-inertial odometry to generate a 6 degree of freedom pose estimation. The proposed network consists of component neural networks that reflect each sensor’s characteristics, then an integrating network for combining estimates from heterogeneous sensors at the terminal stage. To secure an efficient estimation performance, a compound loss function design is exploited. The performance of the proposed deep learning-based LIO algorithm was verified through artificially generated data sets based on a high fidelity dynamics simulator. Instead of using the well-known reference data set of ground vehicles, the employed data set reflects the full 3D dynamic characteristics of the drone as well as low-cost sensor characteristics considering onboard implementation. Through the flight simulator data set, the estimation performance of the proposed synthetic network was demonstrated."
Analysis and Prediction of Surface Condition of Artificial Skin Based on CNN and ConvLSTM,2021,"['artificial skin', 'image prediction', 'Convolutional Neural Network', 'ConvLSTM', 'deep learning', 'image analysis']",,"Recently, with greater focus on ethical issues related to animal testing, interest in artificial skin platforms has increased in both cosmetic and medical industries. Artificial skin comprises dermal and epidermal layers. In particular, proper differentiation and proliferation of keratinocytes in the epidermal layer has a considerable influence on the role of the skin as a barrier. However, during 3D culture, real-time monitoring and evaluation of the tissue being cultured are difficult. In this study, Convolutional Neural Network and Convolutional Long Short-Term Memory were utilized for prediction of the artificial skin image. To evaluate the designed models, the similarity between the predicted artificial skin image was compared with the real image. We verified the possibility and practicability of artificial skin image analysis and prediction using neural network models. In the future, this approach could be applied to image prediction under certain conditions, such as inflammatory or skin diseases."
A Study on the Present Perfect used for Topic Communication in CNN and Yonhap News Reports,2021,"['news', 'present perfect', 'marked type', 'topic emphasis', 'topic flow']",,"The purpose of this research is to figure out the features of the present perfect tense used in news reports especially from a perspective of topic flow. Based on two data sets, we analyzed topic types that the present perfect carried and reached following results. First, the present perfect was used for four topic types such as ‘topic introduction’ in the head, ‘topic shift’ and ‘topic elaboration’ in the middle, and ‘topic termination’ in the end texts. Second, the present perfect was found to convey more general information than specific information. The present perfect conveying general information includes the types used for ‘topic introduction’ delivering hot news in the lead, ‘topic shift’ providing other new information derived from the lead, and ‘topic termination’ expressing the final summary in the end. The present perfect carrying specific information includes ‘topic elaboration’. Third, the present perfect was also used for ‘topic emphasis’ as the present perfect, a more marked type than simple tenses, entered various locations amongst multiple past and present simples to highlight the gist of news topics in a variety of contexts."
Ball Grid Array Solder Void Inspection Using Mask R-CNN,2021,"['Computer vision system', 'Digital image processing', 'BGA', 'Automatic X-Ray inspection', 'Solder joints void', 'Object segmentation', 'Deep learning']",,"The ball grid array is one of the packaging methods that used in high density printed circuit board. Solder void defects caused by voids in the solder ball during the BGA process do not directly affect the reliability of the product, but it may accelerate the aging of the device on the PCB layer or interface surface depending on its size or location. Void inspection is important because it is related in yields with products. The most important process in the optical inspection of solder void is the segmentation process of solder and void. However, there are several segmentation algorithms for the vision inspection, it is impossible to inspect all of images ideally. When X-Ray images with poor contrast and high level of noise become difficult to perform image processing for vision inspection in terms of software programming. This paper suggests the solution to deal with the suggested problem by means of using Mask R-CNN instead of digital image processing algorithm. Mask R-CNN model can be trained with images pre-processed to increase contrast or alleviate noises. With this process, it provides more efficient system about complex object segmentation than conventional system."
이미지 분할 모델을 이용한 Mask R-CNN 모델 정확도 향상 기법,2021,"['도로노면', '이미지 분할', '이미지 병합', '이미지 분석', '정확도 향상', 'Pavement Surface', 'Image Cropping', 'Image Merge', 'Image Analysis', 'Accuracy Enhancement']",,"This paper proposes a method to improve the accuracy of artificial intelligence analysis of computer images of road surfaces. In the past, to analyze the road surface image, the size was reduced and then processed. In this process, as a result of road surface analysis, there was a problem that the quality of the image was degraded and the micro-crack on the road surface disappeared. In order to solve the above problem, in this paper, image segmentation and image cropping-merging models were combined in the preprocessing stage of the artificial intelligence model to eliminate the loss of resolution, and the micro-crack pattern was created through data scale conversion and adjustment of the number of training data according to the importance of crack patterns. Effectively detected. Finally, as a result of comparing with the previous image scale reduction method, it was confirmed that the accuracy was improved when analyzed through the proposed method."
Road Type Identification Ahead of the Tire Using D-CNN and Reflected Ultrasonic Signals,2021,"['Ultrasonic sensor', 'Road type identification', 'Friction coefficient', 'Short-time Fourier transform', 'Machinelearning', 'Deep convolutional neural network']",,"Every land moving object accelerates or decelerates based on the frictional coefficient of the road surface. It has been known that this coefficient on the road is determined by the type of road surface. In this work, we propose a simplistic, machine-learning based solution to estimate the road type using the reflected ultrasonic signals paired with ultrasonic transmitter and receiver. Since the reflected signal contains the material information of the surface due to the difference in the surface roughness and acoustic impedance, different characteristics can be observed for each frequency of the reflected signal. To exploit such characteristics, the signals are transformed into the frequency domain using short-time Fourier transform. In addition, a deep convolutional neural network is applied as the road identifier due to its well-known representational power. In order to verify the aforementioned ideas, the ample database consisting of eight types of road surfaces are obtained with the ultrasonic sensors. And then, the database is used to train the model, as well as to evaluate the accuracy of the trained model. It can be seen that the proposed method makes it easier and more accurate to identify the type of road surface than the conventional methods."
Moving Object Detection with Single Moving Camera and IMU Sensor using Mask R-CNN Instance Image Segmentation,2021,['Moving camera · Motion estimation · Moving object detection · Deep learning'],,"This paper describes a new method for the moving object detection using the IMU sensor and instance image segmentation. In the proposed method, the feature points are extracted by the detector, and the initial fundamental matrix is calculated from the IMU data. Next, the epipolar line is used to classify the extracted feature points. From the background feature point matching, fundamental matrix is calculated iteratively to minimize the error of classification. After the feature point classification, image segmentation is used to enhance the quality of the classification result. The proposed method is implemented and tested with real-world driving videos, and compared with the previous works."
Generating Synthetic Dataset for Scale-invariant Instance Segmentation of Food Materials based Upon Mask R -CNN,2021,"['scale-invariant', 'instance segmentation', 'synthetic dataset', 'food materials']",,"This work proposes a scale-invariant instance segmentation method for images acquired from a real-time camera. It is challenging to detect and segment an exact shape by removing background (named as an instance) of a deformable semi-solid object such as food materials. In this work, we consider the segmentation with the cases of various sizes of an object and multiple objects overlapped with each. To do this, we address an augmented dataset generation method, which extends dataset from small number of base objects, a fundamental dataset. Our method is based upon data augmentation, which is well known that it is an effective way to improve the segmentation performance. Our method addresses the generation of dataset with various scales using small number of original dataset. It is relatively simple in method but provides better performance. We also proposed how to choose a target object(food material) with its centroid for grasping. Through diverse experiments using real-time images, we demonstrate that the proposed algorithm segments scale-invariant object masks and is successfully implemented for a robotic hand to grasp a food material. It is also compared with the state-of-the-art segmentation algorithm. As a result, the proposed method shows 74%, 85%, and 78% in accuracy, recall, and precision while the original dataset shows 67%, 79%, and 70%, respectively."
실내 환경에서 Chirp Emission과 Echo Signal을 이용한 심층신경망 기반 객체 감지 기법,2021,"['Audio-Visual', 'Chirp', 'echolocator', 'Deep convolutional neural network (DCNN)']",,"Humans mainly recognize surrounding objects using visual and auditory information among the five senses (sight, hearing, smell, touch, taste). Major research related to the latest object recognition mainly focuses on analysis using image sensor information. In this paper, after emitting various chirp audio signals into the observation space, collecting echoes through a 2-channel receiving sensor, converting them into spectral images, an object recognition experiment in 3D space was conducted using an image learning algorithm based on deep learning. Through this experiment, the experiment was conducted in a situation where there is noise and echo generated in a general indoor environment, not in the ideal condition of an anechoic room, and the object recognition through echo was able to estimate the position of the object with 83% accuracy. In addition, it was possible to obtain visual information through sound through learning of 3D sound by mapping the inference result to the observation space and the 3D sound spatial signal and outputting it as sound. This means that the use of various echo information along with image information is required for object recognition research, and it is thought that this technology can be used for augmented reality through 3D sound."
합성곱 신경망 기반 물체 인식과 탑승 감지 센서를 이용한 개인형 이동수단 주행 안전 보조 시스템 개발,2021,[],,A recent spread of personal mobility devices such as electric kickboards has brought about a rapid increase in accident cases. Such vehicles are susceptible to falling accidents due to their low dynamic stability and lack of outer protection chassis. This paper presents the development of an automatic emergency braking system and a safe starting system as driving assistance devices for electric kickboards. The braking system employed artificial intelligence to detect nearby threaening objects. The starting system was developed to disable powder to the motor until when the driver's boarding is confirmed. This study is meaningful in that it proposes the convergence technology of advanced driver assistance systems specialized for personal mobility devices.
농작물 질병분류를 위한 전이학습에 사용되는 기초 합성곱신경망 모델간 성능 비교,2021,"['Crop Disease', 'Transfer Learning', 'Convolutional Neural Network', 'Performance Evaluation']",,"Recently, transfer learning techniques with a base convolutional neural network (CNN) model have widely gained acceptance in early detection and classification of crop diseases to increase agricultural productivity with reducing disease spread. The transfer learning techniques based classifiers generally achieve over 90% of classification accuracy for crop diseases using dataset of crop leaf images (e.g., PlantVillage dataset), but they have ability to classify only the pre-trained diseases. This paper provides with an evaluation scheme on selecting an effective base CNN model for crop disease transfer learning with regard to the accuracy of trained target crops as well as of untrained target crops. First, we present transfer learning models called CDC (crop disease classification) architecture including widely used base (pre-trained) CNN models. We evaluate each performance of seven base CNN models for four untrained crops. The results of performance evaluation show that the DenseNet201 is one of the best base CNN models."
저해상도 영상 자료를 사용하는 얼굴 표정 인식을 위한 소규모 심층 합성곱 신경망 모델 설계,2021,"['Convolutional Neural Networks', 'Facial Expression Recognition', 'Design of CNN architecture', 'Low Resolution Image', '합성곱 신경망', '얼굴 표정 인식', '합성곱 신경망 구조 설계', '저해상도 영상']",인공 지능은 놀라운 혜택을 제공하는 우리 삶의 중요한 부분이 되고 있다. 이와 관련하여 얼굴 표정 인식은 최근 수십 년 동안 컴퓨터 비전 연구자들 사이에서 뜨거운 주제 중 하나였다. 저해상도 이미지의 작은 데이터 세트를 분류하려면 새로운 소규모 심층 합성곱 신경망 모델을 개발해야 한다. 이를 위해 소규모 데이터 세트에 적합한 방법을 제안한다. 이 모델은 기존 심층 합성곱 신경망 모델에 비해 총 학습 가능 가중치 측면에서 메모리의 일부만 사용하지만 FER2013 및 FERPlus 데이터 세트에서 매우 유사한 결과를 보여준다.,"Artificial intelligence is becoming an important part of our lives providing incredible benefits. In this respect, facial expression recognition has been one of the hot topics among computer vision researchers in recent decades. Classifying small dataset of low resolution images requires the development of a new small scale deep CNN model. To do this, we propose a method suitable for small datasets. Compared to the traditional deep CNN models, this model uses only a fraction of the memory in terms of total learnable weights, but it shows very similar results for the FER2013 and FERPlus datasets."
합성곱신경망을 이용한 초분광영상기반 토양수분 예측,2021,"['Soil moisture', 'Plant growth', 'Hyperspectral image', 'Spectral band', 'CNN', '토양수분', '식물생육', '초분광영상', '분광밴드', '합성곱신경망']","식물의 생육은 수분에 의해서 크게 좌우되기 때문에 토양이 재배하는 식물에 최적의 수분을 가지도록 조절하는 것은 중요하다. 최근 초분광영상을 통하여 식물의 생육정보를 자동으로 분석하는 연구가 진행되고 있으며 토양의 수분함량을 측정하는 것도 포함한다. 그러나 초분광의 경우 많은 분광밴드에서 나타나는 방대한데이터로 인하여 분석과정이 복잡하기 때문에 사용이 어렵다. 본 논문에서는 초분광영상의 복잡도를 합성곱신경망 (Convolution Neural Network, CNN)을 통하여 해결하는 방법을 제안한다. 제안한 방법은 대상 초분광의 전체 대역을 심층학습방법을 사용하여 자동 분석하기 때문에 각 영상에 대해 인식에 필요한 특정 대역을 찾는 노력을 할 필요가 없다. 제안 시스템의 유효성을 보이기 위해서 토양에서 얻은 초분광영상을 이용한수분함량분석 실험을 수행하고 결과를 보인다.",
인공 신경망 가속기 온칩 메모리 크기에 따른 주메모리 접근 횟수 추정에 대한 연구,2021,"['CNN', 'Simulator', 'Main Memory Access', 'Hardware Accelerator', 'Global Buffer', 'Scratchpad']","이미지 인식 및 패턴 감지를 위해 널리 사용되는 알고리즘 중 하나는 convolution neural network(CNN)이다. CNN에서 대부분의 연산량을 차지하는 convolution 연산을 효율적으로 처리하기 위해 외부 하드웨어 가속기를 사용하여 CNN 어플리케이션의 성능을 향상 시킬 수 있다. 이러한 하드웨어 가속기를 사용함에 있어서 CNN은 막대한 연산량을 처리하기 위해 오프칩 DRAM에서 가속기 내부의 메모리로 데이터를 갖고 와야 한다. 즉 오프칩 DRAM과 가속기 내부의 온칩 메모리 혹은 글로벌 버퍼 사이의 데이터 통신이 CNN 어플리케이션의 성능에 큰 영향을 끼친다. 본 논문에서는 CNN 가속기 내의 온칩 메모리 혹은 글로벌 버퍼의 크기에 따른 주메모리 혹은 DRAM으로의 접근 횟수를 추산할 수 있는 시뮬레이터를 개발하였다. CNN 아키텍처 중 하나인 AlexNet에서, CNN 가속기 내부의 글로벌 버퍼의 크기를 증가시키면서 시뮬레이션 했을 때, 글로벌 버퍼 크기가 100kB 이상인 경우가 100kB 미만인 경우보다 가속기 내부와 오프칩 DRAM 간의 접근 횟수가 0.8배 낮은 것을 확인 했다.","One widely used algorithm for image recognition and pattern detection is the convolution neural network (CNN). To efficiently handle convolution operations, which account for the majority of computations in the CNN, we use hardware accelerators to improve the performance of CNN applications. In using these hardware accelerators, the CNN fetches data from the off-chip DRAM, as the massive computational volume of data makes it difficult to derive performance improvements only from memory inside the hardware accelerator. In other words, data communication between off-chip DRAM and memory inside the accelerator has a significant impact on the performance of CNN applications. In this paper, a simulator for the CNN is developed to analyze the main memory or DRAM access with respect to the size of the on-chip memory or global buffer inside the CNN accelerator. For AlexNet, one of the CNN architectures, when simulated with increasing the size of the global buffer, we found that the global buffer of size larger than 100kB has 0.8x as low a DRAM access count as the global buffer of size smaller than 100kB."
차량 내·외부 데이터 및 딥러닝 기반 차량 위기 감지 시스템 설계,2021,"['Autonomous vehicles', 'Convolutional Neural Networks', 'You Only Look Once', 'Crisis Detection', 'Pedestrian recognition']","현재 자율주행차량 시장은 3레벨 자율주행차량을 상용화하고 있으나, 안정성의 문제로 완전 자율주행 중에도 사고가 발생할 가능성이 있다. 실제로 자율주행차량은 81건의 사고를 기록하고 있다. 3레벨과 다르게 4레벨 이후의 자율주행차량은 긴급상황을 스스로 판단하고 대처해야 하기 때문이다. 따라서 본 논문에서는 CNN을 통하여 차량 외부의 정보를 수집하여 저장하고, 저장된 정보와 차량 센서 데이터를 이용하여 차량이 처한 위기 상황을 0~1 사이의 수치로 출력하는 차량 내.외부 데이터 및 딥러닝 기반 차량 위기 감지 시스템을 제안한다. 차량 위기 감지 시스템은 CNN기반 신경망 모델을 사용하여 주변 차량과 보행자 데이터를 수집하는 차량 외부 상황 수집 모듈과 차량 외부 상황 수집 모듈의 출력과 차량 내부 센서 데이터를 이용하여 차량이 처한 위기 상황을 수치화하는 차량 위기 상황 판단 모듈로 구성된다. 실험 결과, VESCM의 평균 연산 시간은 55ms 였고, R-CNN은 74ms, CNN은 101ms였다. 특히, R-CNN은 보행자 수가 적을 때 VESCM과 비슷한 연산 시간을 보이지만, 보행자 수가 많아 질수록 VESCM보다 많은 연산 시간을 소요했다. 평균적으로 VESCM는 R-CNN보다 25.68%, CNN보다 45.54% 더 빠른 연산 시간을 가졌고, 세 모델의 정확도는 모두 80% 이하로 감소하지 않으며 높은 정확도를 보였다.","Currently, autonomous vehicle markets are commercializing a third-level autonomous vehicle, but there is a possibility that an accident may occur even during fully autonomous driving due to stability issues. In fact, autonomous vehicles have recorded 81 accidents. This is because, unlike level 3, autonomous vehicles after level 4 have to judge and respond to emergency situations by themselves. Therefore, this paper proposes a vehicle crisis detection system(VCDS) that collects and stores information outside the vehicle through CNN, and uses the stored information and vehicle sensor data to output the crisis situation of the vehicle as a number between 0 and 1. The VCDS consists of two modules. The vehicle external situation collection module collects surrounding vehicle and pedestrian data using a CNN-based neural network model. The vehicle crisis situation determination module detects a crisis situation in the vehicle by using the output of the vehicle external situation collection module and the vehicle internal sensor data. As a result of the experiment, the average operation time of VESCM was 55ms, R-CNN was 74ms, and CNN was 101ms. In particular, R-CNN shows similar computation time to VESCM when the number of pedestrians is small, but it takes more computation time than VESCM as the number of pedestrians increases. On average, VESCM had 25.68% faster computation time than R-CNN and 45.54% faster than CNN, and the accuracy of all three models did not decrease below 80% and showed high accuracy."
다층퍼셉트론과 합성곱 신경망에 기반한 지진 지반응답해석,2021,"['지진 지반응답해석', '다층퍼셉트론(MLP)', '합성곱 신경망(CNN)', 'Seismic Ground Response', 'Multilayer Perceptron (MLP)', 'Convolution Neural Networks (CNN)']","지진으로 인한 구조물의 피해를 줄이기 위한, 내진성능을 고려한 방재계획 수립의 중요성이 부각되고 있다. 지진파는 기반암으로 부터 기반암 상부의 토사지반을 통해 전달된다. 전달되는 과정에서 특정 진동수(frequency)범위에서 증폭되기도 하며, 그 증폭 정도는 주로 지반 특성에 따라 좌우된다. 따라서 내진 설계의 신뢰성을 높이기 위해서는 지진 지반응답해석 과정이 필수적이다. 본 연구에서는 지반 하부 혹은 기반암의 지진파로부터 지표의 지진파를 예측하기 위한 모델을 다층퍼셉트론(MLP)과 합성곱 신경망(CNN) 인공신경망 모형을 바탕으로 제안하고, 제안한 모델의 적용성을 가속도 스펙트럼을 바탕으로 검증하였다. MLP와 CNN에 기반 하여 제안된 모델 모두 지표면의 지진파 가속도를 성공적으로 예측하였다. 또한, CNN에 기반한 모델은 MLP 모델과 비교하여 예측 지진파의 가속도 스펙트럼 평균오차가 약 10% 작게 산출되는 것을 확인하였다. 향후에는 해당 지역의 전단파 속도 등의 물성을 모델에 적용하여, 보다 보편적으로 활용할 수 있는 모델을 생성하고자 한다.","The importance of establishing a disaster prevention plan considering seismic performance is being highlighted to reduce damage to structures caused by earthquakes. Earthquake waves propagate from the bedrock to the ground surface through the soil. During the transmission process, they are amplified in a specific frequency range, and the degree of amplification depends mainly on the characteristics of the ground. Therefore, a seismic response analysis process is essential for enhancing the reliability of the seismic design. We propose a model for predicting seismic waves on the surface from seismic waves measured on the bedrock based on Multilayer Perceptron (MLP) and Convolutional Neural Networks (CNN) and validate the applicability of the proposed model with Spectral Acceleration (SA). Both the proposed models based on MLP and CNN successfully predicted the seismic response of the surface. The CNN-based model performed better than the MLP-based model, with a 10% smaller average error. We plan to implement the physical properties of the ground, such as shear wave velocity, to create a more versatile model in the future."
Convolutional Neural Network 기반 EBG 구조 설계를 통한 고속 PCB 노이즈 저감,2021,"['Simultaneous Switching Noise', 'Electromagnetic Band Gap', 'Machine Learning', 'Convolutional Neural Network']","기술이 빠르게 발전하여 디지털 시스템의 동작 주파수는 수 GHz 대역까지 증가했다. 이로 인하여 Simultaneous Switching Noise 문제가 증가했고, 이를 줄이기 위해 Electromagnetic Band Gap(EBG) 구조가 많이 연구된다. EBG 구조 설계에서 중요한 과정 중 하나는 노이즈를 저감하는 Stopband 대역을 예측하는 것이다. 기존에 3차원 전자장 시뮬레이션 프로그램을 이용하는 방법과 Floquet 이론 기반의 수식을 이용하는 방법이 있으나, 한계점이 존재한다. 본 논문에서는 Convolutional Neural Network(CNN)을 이용하여 EBG 구조의 Stopband 대역을 예측하는 새로운 방법을 제안한다. 또한 기본 CNN 구조, GoogLeNet, ResNet, DenseNet과 같은 CNN Architecture 모델을 활용하여 어떤 CNN 구조가 Stopband 대역 예측에 높은 성능을 보이는지 분석한다. 900개의 EBG 구조 모델에 대해서 학습시킨 후 CNN 구조의 mean absolute error를 비교한 결과, DenseNet이 가장 우수한 성능을 보임을 확인하였다.","With rapid advances in technology, the operating frequencies of digital systems have increased to several GHz bands. This has led to an increase in simultaneous switching noise(SSN). To reduce SSN, electromagnetic bandgap(EBG) structures have been intensively studied. One of the critical steps in the design of an EBG structure is to predict the stopband that reduces SSN. Existing methods include using a 3D electromagnetic field simulation program or equations based on the Floquet theory. However, these have limitations. In this study, we verified a new method for predicting the stopband using a convolutional neural network(CNN). Specifically, a CNN architectural model was used to compare structures that perform well in predicting the stopband. It was also used to confirm that the DenseNet showed high performance."
Visual SLAM을 위한 Transformer 기반 6DoF 자세 추정 기법,2021,"['Transformer', 'Self-attention', 'Hybrid network', 'Monocular camera', 'Visual odometry']",,
뇌파기반 정신적 피로 판별을 위한 딥러닝 모델,2021,[],"개인의 정신적 피로는 인지능력 및 업무 수행능력을 감소시킬 뿐만 아니라 일상에서 발생하는 크고 작은 사고의 주요 요인이 된다. 본 논문에서는 EEG 기반의 정신적 피로 판별을 위한 CNN 모델을 제안하였다. 이를 위해 안정 상태와 작업 상태에서의 뇌파를 수집하여 제안한 CNN 모델에 적용한 후 모델 성능을 분석하였다. 실험에 참여한 피험자들은 모두 대학교에 재학 중인 오른손잡이 남학생들이며 평균 나이는 25.5세이다. 각 상태에서의 측정된 뇌파에 대해 스펙트럼분석을 수행하였으며, CNN 모델의 입력데이터로써 원시 EEG 신호, 절대파워, 상대파워를 사용하여 CNN모델의 성능을 비교 분석하였다. 그 결과, 알파대역 후두엽 위치의 상대파워가 가장 좋은 성능을 나타내었다. 모델정확도는 훈련데이터 85.6%, 검증데이터 78.5%, 시험데이터 95.7%이다. 제안한 모델은 정신적 피로 판별을 위한 자동화시스템 개발에 적용될 수 있다.","Individual mental fatigue not only reduces cognitive ability and work performance, but also becomes a major factor in large and small accidents occurring in daily life. In this paper, a CNN model for EEG-based mental fatigue discrimination was proposed. To this end, EEG in the resting state and task state were collected and applied to the proposed CNN model, and then the model performance was analyzed. All subjects who participated in the experiment were right-handed male students attending university, with and average age of 25.5 years. Spectral analysis was performed on the measured EEG in each state, and the performance of the CNN model was compared and analyzed using the raw EEG, absolute power, and relative power as input data of the CNN model. As a result, the relative power of the occipital lobe position in the alpha band showed the best performance. The model accuracy is 85.6% for training data, 78.5% for validation, and 95.7% for test data. The proposed model can be applied to the development of an automated system for mental fatigue detection."
가스터빈 연소기의 안전 운영을 위한 고속화염이미지의 기계학습기법을 활용한 연소불안정 진단,2021,"['Combustion Instability(연소불안정)', 'Confusion Matrix(오차 행렬)', 'Convolutional Neural Network(합성곱 신경망)', 'Dynamic Pressure(동압)', 'Flame Image(화염이미지)', 'Long Short Term Memory(장단기 기억)', 'Machine Learning(기계 학습)']","본 연구에서는 모델 가스터빈 연소기로부터 계측된 고속화염 이미지를 활용해 기계 학습을 수행하여 연소 불안정을 진단하였다. 기계학습에 사용된 이미지는 연소불안정이 안정영역에서 불안정 영역으로 천이되는 조건을 대상으로 초고속 카메라를 이용하여 8 kHz의 속도로 취득하였다. 연소불안정 여부를 판단하기 위하여 CNN과 CNN+LSTM의 두 가지 기계학습 모델을 개발･적용하였고, confusion matrix와 accuracy, recall, precision, F1-score 값을 활용하여 각 모델의 진단성능을 평가하였다. CNN 모델은 단일 이미지만으로 학습하기에 48.92~100%의 정확도의 일부 부정확한 분류를 수행하는 것을 확인하였고, 이에 반해 시계열 화염이미지 데이터를 활용한 CNN+LSTM 모델은 98.97~100%의 매우 정확한 분류를 수행하는 것을 확인하였다.","In this study, combustion instability has been diagnosed by performing machine learning using the flame images measured from a model gas turbine combustor. The images were acquired with an ultra-high-speed camera at the rate of 8 kHz in the transition condition of combustion instability from stable to unstable regimes. To judge the onset of combustion instability, two machine learning models of CNN and CNN+LSTM were developed and applied, and their diagnostic performances were evaluated using confusion matrix, accuracy, recall, precision and F1-score. It was confirmed that the CNN model performs partially inaccurate classification with an accuracy of 48.92~100% because it was trained and judges with only a single image, whereas the CNN+LSTM model, which uses time-series flame image data, performs very accurate classification with an accuracy of 98.97~100%."
Deep Learning-based Pes Planus Classification Model Using Transfer Learning,2021,"['Pes planus', 'Deep learning', 'Convolutional neural network(CNN)', 'Transfer learning', 'Data Augmentation', '편평발', '딥러닝', '합성곱 신경망', '전이학습', '데이터 증폭']","본 연구는 기존 편평발 측정을 위해 사용되던 다양한 방법의 한계를 보완할 수 있는 새로운 측정 방법으로 전이학습을 적용한 딥러닝 기반 편평발 분류 방법론을 제안한다. 편평발 88장, 정상발 88장으로 이루어진 총 176장의 이미지 데이터를 활용하여, 적은 데이터로도 우수한 예측 모델을 생성할 수 있는 데이터 증폭 기술과 사전학습 모델인 VGG16 구조를 활용하는 전이학습 기술을 적용하여 제안 모델의 학습을 진행하였다. 제안 모델의 우수성을 확인하기 위하여 기본 CNN 기반 모델과 제안 방법론의 예측 정확도를 비교하는 실험을 수행하였다. 기본 CNN 모델의 경우 훈련 정확도는 77.27%, 검증 정확도는 61.36%, 그리고 시험 정확도는 59.09%로 나타났으며, 제안모델의 경우 훈련 정확도는 94.32%, 검증 정확도는 86.36%, 그리고 시험 정확도는 84.09%로 나타나 기본 CNN 모델에 비해 제안 모델의 정확도가 큰 폭으로 향상된 것을 확인하였다.","This study proposes a deep learning-based flat foot classification methodology using transfer learning. We used a transfer learning with VGG16 pre-trained model and a data augmentation technique to generate a model with high predictive accuracy from a total of 176 image data consisting of 88 flat feet and 88 normal feet. To evaluate the performance of the proposed model, we performed an experiment comparing the prediction accuracy of the basic CNN-based model and the prediction model derived through the proposed methodology. In the case of the basic CNN model, the training accuracy was 77.27%, the validation accuracy was 61.36%, and the test accuracy was 59.09%. Meanwhile, in the case of our proposed model, the training accuracy was 94.32%, the validation accuracy was 86.36%, and the test accuracy was 84.09%, indicating that the accuracy of our model was significantly higher than that of the basic CNN model."
Deep Compression의 프루닝 문턱값 동적 조정,2021,"['CNN', '신경망 경량화', '가지치기', '문턱값 조정', 'LeNet', 'CNN', 'Neural network compression', 'Pruning', 'Threshold adjustment', 'LeNet']","최근 CNN(Convolutional Neural Network)이 다양한 컴퓨터 비전 분야에서 우수한 성능으로 널리 사용되고 있다. 그러나 CNN은 계산 집약적이고 많은 메모리가 요구되어 한정적인 하드웨어 자원을 가지는 모바일이나 IoT(Internet of Things) 기기에 적용하기 어렵다. 이런 한계를 해결하기 위해, 기존의 학습된 모델의 성능을 최대한 유지하며 네트워크의 크기를 줄이는 인공신경망 경량화 연구가 진행되고 있다. 본 논문은 신경망 압축 기술 중 하나인 프루닝(Pruning)의 문턱값을 동적으로 조정하는 CNN 압축 기법을 제안한다. 프루닝될 가중치를 결정하는 문턱값을 실험적, 경험적으로 정하는 기존의 기술과 달리 정확도의 저하를 방지하는 최적의 문턱값을 동적으로 찾을 수 있으며, 경량화된 신경망을 얻는 시간을 단축할 수 있다. 제안 기법의 성능 검증을 위해 MNIST 데이터 셋을 사용하여 LeNet을 훈련시켰으며, 정확도 손실 없이 약 1.3 ~ 3배의 시간을 단축하여 경량화된 LeNet을 얻을 수 있었다.","Recently, convolutional neural networks (CNNs) have been widely utilized due to their outstanding performance in various computer vision fields. However, due to their computational-intensive and high memory requirements, it is difficult to deploy CNNs on hardware platforms that have limited resources, such as mobile devices and IoT devices. To address these limitations, a neural network compression research is underway to reduce the size of neural networks while maintaining their performance. This paper proposes a CNN compression technique that dynamically adjusts the thresholds of pruning, one of the neural network compression techniques. Unlike the conventional pruning that experimentally or heuristically sets the thresholds that determine the weights to be pruned, the proposed technique can dynamically find the optimal thresholds that prevent accuracy degradation and output the light-weight neural network in less time. To validate the performance of the proposed technique, the LeNet was trained using the MNIST dataset and the light-weight LeNet could be automatically obtained 1.3 to 3 times faster without loss of accuracy."
합성곱 신경망을 이용한 수중 선체면 영상의 청소 상태 검사,2021,"['Classification(분류)', 'Cleaning Condition(청소 상태)', 'Convolutional Neural Network(합성곱 신경망)', 'Hull Surface(선체면)', 'Inspection Image(검사 영상)', 'Underwater Hull(수중 선체)']","본 연구에서는 합성곱 신경망(CNN: convolutional neural network)을 이용해 수중에서 촬영한 선체면 영상에서 선체면의 청소 상태를 검사하기 위한 방법을 제안한다. 원격 조종 수중 로봇에서 수집한 동영상을 이용해 학습 데이터를 생성하였으며, 이 데이터들을 청소가 된 상태와 청소가 안된 상태의 영상으로 분류하였다. 청소 상태 검사를 위한 CNN 모델을 합성곱 레이어(convolution layer), 최대풀링 레이어(max-pooling layer), 드롭아웃 레이어(dropout layer)로 구성된 네 개의 합성곱 블록(convolution block)과 세개의 완전 연결 레이어(fully-connected layer)로 구성하였다. 그리고, 미니배치 경사하강법(mini-batch gradient descent)과 Adam 최적화를 이용해 CNN 모델을 학습하였다. 그 결과, 테스트 셋에 대해 97.95%의 정확도와 97.94%의 F1-점수를 보여주었다.","We propose a method for inspecting the cleaning condition of hull surfaces from underwater hull surface images using a convolutional neural network (CNN). A training data set was generated using videos collected from a remotely operated underwater robot, and the data set was classified into cleaned images and uncleaned images. The CNN model for inspecting the cleaning condition was composed of four convolutional blocks and three fully connected layers, where each convolutional block consisted of a convolution layer, a max-pooling layer, and a dropout layer. The CNN model was trained using the mini-batch gradient descent method and an Adam optimizer. As a result, on the testing set, the accuracy was 97.95%, and the F1-score was 97.94%."
Method for Estimating Intramuscular Fat Percentage of Hanwoo(Korean Traditional Cattle) Using Convolutional Neural Networks in Ultrasound Images,2021,"['Hanwoo', 'Ultrasound Images', 'CNN', '%IMF(Intramuscular Fat Percentage)', 'ROI']",,"In order to preserve the seeds of excellent Hanwoo(Korean traditional cattle) and secure quality competitiveness in the infinite competition with foreign imported beef, production of high-quality Hanwoo beef is absolutely necessary. %IMF (Intramuscular Fat Percentage) is one of the most important factors in evaluating the value of high-quality meat, although standards vary according to food culture and industrial conditions by country. Therefore, it is required to develop a %IMF estimation algorithm suitable for Hanwoo. In this study, we proposed a method of estimating %IMF of Hanwoo using CNN in ultrasound images. First, the proposed method classified the chemically measured %IMF into 10 classes using k-means clustering method to apply CNN. Next, ROI images were obtained at regular intervals from each ultrasound image and used for CNN training and estimation. The proposed CNN model is composed of three stages of convolution layer and fully connected layer. As a result of the experiment, it was confirmed that the %IMF of Hanwoo was estimated with an accuracy of 98.2%. The correlation coefficient between the estimated %IMF and the real %IMF by the proposed method is 0.97, which is about 10% better than the 0.88 of the previous method."
효과적인 비전 트랜스포머를 통한 화재 감지,2021,"['컨볼루션 뉴럴 네트워크', '화재 감지', '포그기아의 데이터 세트', '산불', '스마트시티', '비전 변압기', 'Convolution Neural Network', 'Fire Detection', 'Foggia’s Dataset', 'Forest Fire', 'Smart Cities', 'Vision Transformers']","오늘날 현대사회에서 스마트하고 안전한 도시는 연구 커뮤니티의 주요 관심사 중 하나이다. 도시들은 개방된 지역, 농경지, 숲으로 둘러싸여 있으며, 화재 발생은 인간의 삶을 위협하고 그들의 재산도 손상시킬 수 있다. 최근 비전 센서 기반 화재 감지 기술은 컴퓨터 비전 분야의 전문가들을 통해, 최신 문헌에서 다양한 컨볼루션 신경 네트워크 (CNN)을 대한 최고의 성능을 달성하고 있다. 그러나 이러한 기술은 변환 불변이고, 지역성에 민감하며, 이미지에 대한 전체적인 이해가 부족하다. 또한 CNN 기반 모델은 계산 비용을 줄이기 위해 차원 축소를 위한 풀링 레이어 전략을 사용했지만, 가장 활동적인 특징 검출기의 정확한 위치와 같은 많은 의미 있는 정보를 손실한다. 이러한 문 제를 극복하기 위해 본 연구에서는 비전 트랜스포머(ViT)기반 화재 감지 모델을 개발하였다. ViT는 입력 이미지를 이미지 패치로 분할한 다음 워드 임베딩과 유사한 시퀀스 구조로 트랜스포머에 제공한다. 우리는 벤치마크 화재 데 이터 세트에서 제안된 작업의 성능을 평가하고 최신(SOTA) CNN 방법과 비교할 때 좋은 결과를 달성한다.","In today's modern age, smart and safe cities are one of the major concerns of the research community. The cities are surrounded by open areas, agricultural land, and forests, where fire incidence can make human lives threatening, damaging their properties as well. Recently, vision sensors-based fire detection has attracted computer vision domain experts, where the leading performance is achieved by a variety of convolution neural networks(CNN) in the recent literature. However, these techniques are translation invariant, locality-sensitive, and lacking a global understanding of images. Furthermore, CNN-based models use the pooling layers strategy for dimensionality reduction to reduce the computational cost but it also loses a lot of meaningful information such as the precise location of the most active feature detector. To overcome these problems, in this work, we developed Vision Transformers(ViT) based model for fire detection. The ViT split the input image into image patches and then feed these patches to the transformer in a sequence structure similar to word embeddings. We evaluate the performance of the proposed work on the benchmark fire dataset and achieve good results when compared to state-of-the-art(SOTA) fire detection CNN models."
경안천 용존 산소 예측을 위한 입력 인자 선정 및 기계 학습 모델 비교,2021,"['인공신경망', '합성곱 신경망', '게이트 순환 유닛', '경안천', '랜덤 포레스트', 'Artificial Neural Network', 'Convolutional Neural Network', 'Gated Recurrent Unit', 'Gyeongan Stream', 'Random Forest']","목적:본 연구에서는 경안천의 용존 산소(dissolved oxygen, DO) 예측을 위해 기계 학습(machine learning) 모델의 최적 입력 인자를 선정하고 성능 평가 지표 결과를 비교하여 최적 모델을 찾고자 한다.방법:경안천 특정 지점의 수질 자료를 연구대상으로 삼아 1998년 1월 15일부터 2019년 12월 30일까지 자료를 수집하고, 전처리한 데이터를 7:3의 비율에 따라 train과 test 자료로 나누어 실험을 진행하였다. 기계 학습 중 랜덤 포레스트(random forest, RF), 인공신경망(artificial neural network, ANN), 합성곱 신경망(convolutional neural network, CNN), 게이트 순환 유닛(gated recurrent unit, GRU) 등을 이용하였다. RF와 ANN은 무작위 추출(random split)과 시계열 자료(time series)로 구분하여 실험하였으며, CNN과 GRU는 시계열 자료만 이용하여 실험을 진행하였다. 모델별 최적의 결과를 비교하기 위해 성능 평가 지표(결정 계수(square of the correlation coefficient, R2), 평균 제곱근 오차(root mean square error, RMSE), 평균 절대 오차(mean absolute error, MAE))를 사용하였다.결과 및 토의:RF 기여도 분석 결과와 참고문헌을 통해 최적 입력 인자로 수온, pH, 전기 전도도, PO4-P, NH4-N, 총 인, 부유물질, NO3-N 등으로 선정하였다. RF와 ANN 모두 무작위 추출보다 시계열 자료의 성능이 더 우수하였다. 시계열 자료를 이용하여 모델 성능을 비교해 보면, RF > CNN > GRU > ANN 순으로 나타났다.결론:본 연구에서 경안천의 DO 예측을 위한 기계 학습 모델의 최적 입력 인자로 8개(수온, pH, 전기 전도도, PO4-P, NH4-N, 총 인, 부유물질, NO3-N)를 선택하였다. DO 예측에 가장 우수한 모델은 시계열 자료를 사용한 RF 모델이었다. 따라서 경안천과 같은 하천의 DO를 예측하는 경우 최적 입력 인자 선정 후 시계열 자료를 바탕으로 RF 모델을 이용할 것을 제안한다.","Objectives:In this study, we select input factors for machine learning models to predict dissolved oxygen (DO) in Gyeongan Stream and compare results of performance evaluation indicators to find the optimal model.Methods:The water quality data from the specific points of Gyeongan Stream were collected between January 15, 1998 and December 30, 2019. The pretreatment data were divided into train and test data with the ratio of 7:3. We used random forest (RF), artificial neural network (ANN), convolutional neural network (CNN), and gated recurrent unit (GRU) among machine learning. RF and ANN were tested by both random split and time series data, while CNN and GRU conducted the experiment using only time series data. Performance evaluation indicators such as square of the correlation coefficient (R2), root mean square error (RMSE), and mean absolute error (MAE) were used to compare the optimal results for the models.Results and Discussion:Based on the RF variable importance results and references, water temperature, pH, electrical conductivity, PO4-P, NH4-N, total phosphorus, suspended solids, and NO3-N were used as input factors. Both RF and ANN performed better with time series data than random split. The model performance was good in order of RF > CNN > GRU > ANN.Conclusions:The eight input factors (water temperature, pH, electrical conductivity, PO4-P, NH4-N, total phosphorus, suspended solids, and NO3-N) were selected for machine learning models to predict DO in Gyeongan Stream. The best model for DO prediction was the RF model with time series data. Therefore, we suggest that the RF with the eight input factors could be used to predict the DO in streams."
차량 센서 데이터 조합을 통한 딥러닝 기반 차량 이상탐지,2021,"['Anomaly detection', 'CNN', 'LSTM', 'Vehicle', 'Deep learning']","4차산업혁명 시대에는 대량의 데이터를 학습하여 예측과 분류의 정확성을 향상시킬 수 있는 인공지능의 활용이 핵심적이다. 그러나, 기존 이상탐지를 위한 방법은 제한된 데이터를 다루는 전통적인 통계 방법에 의존하고 있어, 정확한 이상탐지가 어렵다. 그러므로, 본 연구는 인공지능 기반 이상탐지 방법을 제시하여 예측 정확도를 높이고, 새로운 데이터 패턴을 정의하는 것을 목적으로 한다. 특히, 자동차의 경우 공회전 기간의 센서 데이터가 이상 탐지에 활용될 수 있다는 관점에서 데이터를 수집하고 분석하였다. 이를 위해, 예측 모델에 입력되는 데이터의 적정 시간 길이를 결정하고, 공회전 기간 데이터와 전체 운행 데이터의 분석 결과를 비교하며, 다양한 센서 데이터 조합에 의한 최적 예측 방법을 도출하였다. 또한, 인공지능 방법으로 선택된 CNN의 예측 정확성을 검증하기 위해 LSTM 결과와 비교하였다. 분석 결과, 공회전 데이터를 이용하고, 공회전 기간보다 1.5배 많은 기간의 데이터를 이용하며 LSTM보다는 CNN을 활용하는 것이 더 좋은 예측결과를 보였다.","In the Industry 4.0 era, artificial intelligence has attracted considerable interest for learning mass data to improve the accuracy of forecasting and classification. On the other hand, the current method of detecting anomalies relies on traditional statistical methods for a limited amount of data, making it difficult to detect accurate anomalies. Therefore, this paper proposes an artificial intelligence-based anomaly detection methodology to improve the prediction accuracy and identify new data patterns. In particular, data were collected and analyzed from the point of view that sensor data collected at vehicle idle could be used to detect abnormalities. To this end, a sensor was designed to determine the appropriate time length of the data entered into the forecast model, compare the results of idling data with the overall driving data utilization, and make optimal predictions through a combination of various sensor data. In addition, the predictive accuracy of artificial intelligence techniques was presented by comparing Convolutional Neural Networks (CNN) and Long Short Term Memory (LSTM) as the predictive methodologies. According to the analysis, using idle data, using 1.5 times of the data for the idling periods, and using CNN over LSTM showed better prediction results."
Method for Estimating Intramuscular Fat Percentage of Hanwoo(Korean Traditional Cattle) Using Convolutional Neural Networks in Ultrasound Images,2021,"['Hanwoo', 'Ultrasound Images', 'CNN', '%IMF(Intramuscular Fat Percentage)', 'ROI']",,"In order to preserve the seeds of excellent Hanwoo(Korean traditional cattle) and secure quality competitiveness in the infinite competition with foreign imported beef, production of high-quality Hanwoo beef is absolutely necessary. %IMF (Intramuscular Fat Percentage) is one of the most important factors in evaluating the value of high-quality meat, although standards vary according to food culture and industrial conditions by country. Therefore, it is required to develop a %IMF estimation algorithm suitable for Hanwoo. In this study, we proposed a method of estimating %IMF of Hanwoo using CNN in ultrasound images. First, the proposed method classified the chemically measured %IMF into 10 classes using k-means clustering method to apply CNN. Next, ROI images were obtained at regular intervals from each ultrasound image and used for CNN training and estimation. The proposed CNN model is composed of three stages of convolution layer and fully connected layer. As a result of the experiment, it was confirmed that the %IMF of Hanwoo was estimated with an accuracy of 98.2%. The correlation coefficient between the estimated %IMF and the real %IMF by the proposed method is 0.97, which is about 10% better than the 0.88 of the previous method."
한 쌍의 앙상블 모델을 이용한 효율적인 골다공증 예측,2021,"['CT', 'Osteopenia', 'Osteoporosis', 'Dissimilarity loss function', 'Feature map', 'CNN', '컴퓨터 단층촬영', '골감소증', '골다공증', '비유사성 손실함수', '특징 정보']","본 논문에서는 컴퓨터 단층촬영(CT) 이미지를 이용한 합성곱 신경망(CNN)을 기반의 골감소증 및 골다공증 예측 모델을 제안한다. 기존의 CNN은 단일 CT 이미지에서 예측에 중요한 지역정보를 활용하지 못하다는 문제가 있다. 본 논문에서 이를 해결하고자 CT 이미지를 정규화하여 질감 정보가 다른 두 개의 이미지로 변환하고, 해당 이미지를 활용한 한 쌍의 신경망 네트워크를 제안한다. 동일한 구조를 가진 네트워크 각각의 신경망은 질감 정보가 다른 이미지를 입력으로 사용하고 비유사성 손실함수를 통해 다른 정보를 학습한다. 최종적으로 제안 모델은 중요한 지역정보를 포함한 단일 CT 이미지의 다양한 특징 정보를 학습하며, 이를 앙상블하여 골감소증 및 골다공증 예측 정확도를 높인다. 실험 결과를 통해 제안 모델의 정확도 77.11%를 확인할 수 있으며 Grad-CAM을 이용하여 모델이 바라보는 특징을 확인할 수 있다.","In this paper, we propose a prediction model for osteopenia and osteoporosis based on a convolutional neural network(CNN) using computed tomography(CT) images. In a single CT image, CNN had a limitation in utilizing important local features for diagnosis. So we propose a compound model which has two identical structures. As an input, two different texture images are used, which are converted from a single normalized CT image. The two networks train different information by using dissimilarity loss function. As a result, our model trains various features in a single CT image which includes important local features, then we ensemble them to improve the accuracy of predicting osteopenia and osteoporosis. In experiment results, our method shows an accuracy of 77.11% and the feature visualize of this model is confirmed by using Grad-CAM."
Damage detection in structures using modal curvatures gapped smoothing method and deep learning,2021,"['damage detections', 'vibration-based', 'gapped smoothing method (GSM)', 'machine learning', 'deep learning', 'convolutional neural network', 'Finite Element Method (FEM)']",,"This paper deals with damage detection using a Gapped Smoothing Method (GSM) combined with deep learning. Convolutional Neural Network (CNN) is a model of deep learning. CNN has an input layer, an output layer, and a number of hidden layers that consist of convolutional layers. The input layer is a tensor with shape (number of images) × (image width) × (image height) × (image depth). An activation function is applied each time to this tensor passing through a hidden layer and the last layer is the fully connected layer. After the fully connected layer, the output layer, which is the final layer, is predicted by CNN. In this paper, a complete machine learning system is introduced. The training data was taken from a Finite Element (FE) model. The input images are the contour plots of curvature gapped smooth damage index. A free-free beam is used as a case study. In the first step, the FE model of the beam was used to generate data. The collected data were then divided into two parts, i.e. 70% for training and 30% for validation. In the second step, the proposed CNN was trained using training data and then validated using available data. Furthermore, a vibration experiment on steel damaged beam in free-free support condition was carried out in the laboratory to test the method. A total number of 15 accelerometers were set up to measure the mode shapes and calculate the curvature gapped smooth of the damaged beam. Two scenarios were introduced with different severities of the damage. The results showed that the trained CNN was successful in detecting the location as well as the severity of the damage in the experimental damaged beam."
Fault Diagnosis of Bearing Based on Convolutional Neural Network Using Multi-Domain Features,2021,"['CNN', 'DWT', 'Fault Diagnosis', 'Multi-domain', 'Time series Classification']",,"Failures frequently occurred in manufacturing machines due to complex and changeable manufacturing environments, increasing the downtime and maintenance costs. This manuscript develops a novel deep learning-based method named Multi-Domain Convolutional Neural Network (MDCNN) to deal with this challenging task with vibration signals. The proposed MDCNN consists of time-domain, frequency-domain, and statistical-domain feature channels. The Time-domain channel is to model the hidden patterns of signals in the time domain. The frequency-domain channel uses Discrete Wavelet Transformation (DWT) to obtain the rich feature representations of signals in the frequency domain. The statistic-domain channel contains six statistical variables, which is to reflect the signals’ macro statistical-domain features, respectively. Firstly, in the proposed MDCNN, time-domain and frequency-domain channels are processed by CNN individually with various filters. Secondly, the CNN extracted features from time, and frequency domains are merged as time-frequency features. Lastly, time-frequency domain features are fused with six statistical variables as the comprehensive features for identifying the fault. Thereby, the proposed method could make full use of those three domain-features for fault diagnosis while keeping high distinguishability due to CNN's utilization. The authors designed massive experiments with 10-folder cross-validation technology to validate the proposed method's effectiveness on the CWRU bearing data set. The experimental results are calculated by ten-time averaged accuracy. They have confirmed that the proposed MDCNN could intelligently, accurately, and timely detect the fault under the complex manufacturing environments, whose accuracy is nearly 100%."
미세먼지 위험 단계 예측을 위한 1-D CRNN 모델 설계,2021,"['Fine dust', 'Deep learning', 'CNN', 'RNN', 'Data prediction', '미세먼지', '딥러닝', 'CNN', 'RNN', '데이터 예측']","최근 국내 미세먼지 발생의 증가에 따라 발생하는 인체에 유해한 영향을 줄이기 위하여, 미세먼지 수치를 예측하고 사전 조치를 취할 수 있도록 돕는 기술이 필요해지고 있다. 본 논문에서는 국내 미세먼지 위험 수준을 예측하기 위한 1D Convolutional to Recurrent Neural Network (1-D CRNN) 모델을 제안한다. 제안 된 모델은 딥러닝 신경망의 CNN과 RNN을 결합한 구조이며, 다른 종류의 데이터로 구성된 시계열 데이터 세트에서 데이터 예측을 수행 할 수 있다. 데이터 예측을 위해 국내·외 미세먼지, 풍향, 풍속 데이터를 사용한다. 제안된 모델은 약 76%(부분 최대 84%)의 정확도를 달성했으며, 일반 RNN 모델(53%)보다 정확한 예측 결과를 얻었을 수 있었다. 제안된 모델은 향후 여러 개의 시계열 데이터 세트를 고려해야 하는 데이터 예측 모델 학습 및 실험을 목표로 한다.","In order to reduce the harmful effects on the human body caused by the recent increase in the generation of fine dust in Korea, there is a need for technology to help predict the level of fine dust and take precautions. In this paper, we propose a 1D Convolutional-Recurrent Neural Network (1-D CRNN) model to predict the level of fine dust in Korea. The proposed model is a structure that combines the CNN and the RNN, and uses domestic and foreign fine dust, wind direction, and wind speed data for data prediction. The proposed model achieved an accuracy of about 76%(Partial up to 84%). The proposed model aims to data prediction model for time series data sets that need to consider various data in the future."
심층학습의 인스턴스 분할을 이용한 시설작물 레이블링,2021,"['심층학습', '시설작물', '레이블링', '인스턴스 분할', 'Deep learning', 'Facility Crops', 'Labeling', 'Instance Segmentation', 'Mask R-CNN']","본 논문에서는 심층학습 기반 시설작물 영상의 개체분할에 의한 레이블링을 제안한다. 여기서 개체의 레이블링을 위한 분할은 인스턴스 분할로 전이학습의 Mask R-CNN 모델을 이용한다. 개체분할을 위한 영상은 시설작물의 딸기영상이며, 딸기영상을 잎, 줄기, 꽃의 3가지 개체별로 분할 후 레이블링한다. 제안된 방법의 타당성과 성능을 확인하기 위하여 온실에서 획득된 135장의 RGB 딸기영상을 대상으로 실험한 결과, 3가지 각 개체들의 분할성능이 우수함을 확인하였다. 특히 잎과 같이 동일한 여러 개체가 중첩된 경우에도 개체의 분할성능이 우수함을 확인하였다.","In this paper, we propose labeling by object segmentation of deep learning-based facility crop images. Here, the segmentation for object labeling is instance segmentation and uses the Mask R-CNN model of transfer learning. In addition, the image for object segmentation is a strawberry image of a plant crop, and the strawberry image is labeled after dividing into three classes of leaves, stems, and flowers. In order to confirm the validity and performance of the proposed method, as a result of an experiment on 135 RGB strawberry images obtained in a greenhouse, it was confirmed that the segmentation performance of each of the three objects was excellent. In particular, it was confirmed that the segmentation performance of the individual was excellent even when several identical objects such as leaves were overlapped."
Improving Parallelism for Video Action Recognition Model Using One-dimensional Convolutional Neural Network,2021,"['비디오 분류', '비디오 행동 인식', '1차원 CNN', '딥러닝', 'video classification', 'video action recognition', '1D convolutional neural network', 'deep learning']",딥러닝 프레임워크는 컴퓨터 비전 많은 분야에서 괄목할 만한 성과를 보여주고 있다. 비디오 행동 인식 분야 역시 딥러닝 모델을 적용하기 위한 많은 연구들이 수행되었다. 한 선행연구는 2차원 CNN을 이용해 공간적 피쳐를 학습하고 이를 RNN에 입력으로 전달해 이용해 공간적 피쳐 사이의 시간적 상호 관계를 학습하는 모델 구조를 제안했다. 본 논문에서는 RNN 대신 1차원 CNN을 이용해 시간적 상호관계를 학습하도록 선행 연구의 모델 구조를 개선하는 연구를 수행한다. 이러한 구조 변경을 통해 RNN의 순차적 연산 과정을 제거해 향상된 GPU 활용도를 기대할 수 있다. 본 논문은 수정된 모델이 정확도를 비슷하게 유지하면서 연산 시간이 줄어드는 것을 보여주는 실험 결과를 제시함으로써 이러한 주장을 뒷받침한다.,"The deep learning framework has shown remarkable results on numerous computer vision tasks. Many studies have been performed for video action recognition tasks to apply deep learning models to the task. One of the previous works suggested the model architecture, where spatial features are learned from 2D Convolutional Neural Networks (CNNs) and then passed to Recurrent Neural Networks (RNNs) to learn about temporal dependency among them. In this paper, we study the improved model architecture where the temporal relationship of spatial features is processed with 1D CNN instead of RNN. From this modification, we can expect better utilization of GPU by removing sequential operations of RNN. We support the argument based on the experiment results that show that it leads to the reduction in computation time and maintains a similar classification accuracy."
파노라마방사선사진상에서 골다공증의 판독에서 인공지능의 민감영역 연구,2021,"['Panoramic radiograph', 'Neural network', 'Osteoporosis', 'Mandible']",,"Artificial intelligence, has been applied in interpreting osteoporosis on dental panoramic radiograph with high accuracy. The purpose of this study was to investigate the sensitive area of convolutional neural network(CNN), one of artificial intelligence, in interpreting osteoporosis on dental panoramic radiograph. Dental panoramic radiographs taken from 1,170 female (49.19 ±21.91 average age, 21 minimum age, and 84 maximum age) were selected for this study. Two oral maxillofacial radiologists agreed upon interpreting osteoporosis by interpreting mandibular inferior cortical changes. The region of interest included upper and lower jaws for training and testing CNN in interpreting osteoporosis. A filter which was set to look for image characteristics moved through the entire panoramic radiography to identify sensitive areas that distinguish normal groups and osteoporosis patients. In interpreting osteoporosis on panoramic radiograph, CNN responded sensitively at the cancellous bone of the upper and lower jaws while oral maxillofacial radiologists interpreted mandibular inferior cortical change."
An Improved Recommendation Algorithm Based on Two-layer Attention Mechanism,2021,"['Attention', 'Mechanism', 'Recommendation', 'Deep Learning', 'AMITI Algorithm', '주의', '메커니즘', '권장', '딥러닝', '아미티 알고리즘']","인터넷 기술의 발달로 기존의 추천 알고리즘은 사용자나 항목의 심층적인 특성을 학습할 수 없기 때문에 본 논문은 이 문제를 해결하기 위해 AMITI(주의 메커니즘 및 개선된 TF-IDF)에 기반한 추천 알고리즘을 제안했다. CNN(Convolutional Neural Network)에 2중 주의 메커니즘을 도입함으로써 CNN의 특징 추출 능력이 향상되고, 항목 특징에 다른 선호도 가중치가 할당되며, 사용자 선호도와 더 일치하는 권고사항이 달성되었다. 대상 사용자에게 항목을 추천할 때 점수 데이터와 항목 유형 데이터를 TF-IDF와 결합하여 권장 결과의 그룹화를 완료하였다. 본 논문에서 진행한 MovieLens-1M 데이터 세트에 대한 실험 결과는, AMITI 알고리즘이 권장 사항의 정확도를 향상시키고 프레젠테이션 방법의 순서와 선택성을 향상시킨다는 것을 보여준다.","With the development of Internet technology, because traditional recommendation algorithms cannot learn the in-depth characteristics of users or items, this paper proposed a recommendation algorithm based on the AMITI(attention mechanism and improved TF-IDF) to solve this problem. By introducing the two-layer attention mechanism into the CNN, the feature extraction ability of the CNN is improved, and different preference weights are assigned to item features, recommendations that are more in line with user preferences are achieved. When recommending items to target users, the scoring data and item type data are combined with TF-IDF to complete the grouping of the recommendation results. In this paper, the experimental results on the MovieLens-1M data set show that the AMITI algorithm improves the accuracy of recommendation to a certain extent and enhances the orderliness and selectivity of presentation methods."
깊은 합성곱 신경망 모델에 따른 유방 초음파 영상 분류 성능 비교,2021,"['Breast Ultrasound', 'Breast Cancer', 'Tumor', 'Classification', 'VGG', 'ResNet', 'InceptionNet', 'DenseNet', 'EfficientNet', 'Convolutional Neural Network']",,"Breast ultrasound has been widely utilized for classifying tumors into benignancy and malignancy. The limitations of traditional breast ultrasound are the handcrafted features obtained by well-trained sonographers and subjective decision according to different individual experiences. Recently, CNN-based deep learning techniques have exhibited better performance in medical images. However, most research for deep learning in medical ultrasound adopts CNN models developed for natural images due to the lack of common standard and dataset. In this paper, we compare six DCNN models which exhibit good performance for natural images - VGGNet, ResNet, InceptionNet, DenseNet, and EfficientNet. Our classification results demonstrate that CNN models of relatively lower performance on natural images show better performance on gray-scale ultrasound images and further study of CNN models are needed focusing on the features of medical images."
Privacy-preserving and Communication-efficient Convolutional Neural Network Prediction Framework in Mobile Cloud Computing,2021,"['Privacy Preservation', 'Convolutional Neural Networks', 'Homomorphic Encryption', 'Mobile Cloud Computing', 'Deep Learning']",,"Deep Learning as a Service (DLaaS), utilizing the cloud-based deep neural network models to provide customer prediction services, has been widely deployed on mobile cloud computing (MCC). Such services raise privacy concerns since customers need to send private data to untrusted service providers. In this paper, we devote ourselves to building an efficient protocol to classify users’ images using the convolutional neural network (CNN) model trained and held by the server, while keeping both parties’ data secure. Most previous solutions commonly employ homomorphic encryption schemes based on Ring Learning with Errors (RLWE) hardness or two-party secure computation protocols to achieve it. However, they have limitations on large communication overheads and costs in MCC. To address this issue, we present LeHE4SCNN, a scalable privacy-preserving and communication-efficient framework for CNN-based DLaaS. Firstly, we design a novel low-expansion rate homomorphic encryption scheme with packing and unpacking methods (LeHE). It supports fast homomorphic operations such as vector-matrix multiplication and addition. Then we propose a secure prediction framework for CNN. It employs the LeHE scheme to compute linear layers while exploiting the data shuffling technique to perform non-linear operations. Finally, we implement and evaluate LeHE4SCNN with various CNN models on a real-world dataset. Experimental results demonstrate the effectiveness and superiority of the LeHE4SCNN framework in terms of response time, usage cost, and communication overhead compared to the state-of-the-art methods in the mobile cloud computing environment."
운전자의 주의분산 연구동향 및 딥러닝 기반 동작 분류 모델,2021,"['Driver’s Behavior', 'Driver’s Distraction', 'Behavior Recognition', 'ResNet-101', 'CAM', '운전자의 동작', '운전자의 주의 분산', '동작 인식']","본 논문에서는 운전자의 주의산만을 유발하는 운전자, 탑승자의 동작을 분석하고 핸드폰과 관련된 운전자의 행동 10가지를 인식하였다. 먼저 주의산만을 유발하는 동작을 환경 및 요인으로 분류하고 관련 최근 논문을 분석하였다. 분석된 논문을 기반으로 주의산만을 유발하는 주요 원인인 핸드폰과 관련된 10가지 운전자의 행동을 인식하였다. 약 10만 개의 이미지 데이터를 기반으로 실험을 진행하였다. SURF를 통해 특징을 추출하고 3가지 모델(CNN, ResNet-101, 개선된 ResNet-101)로 실험하였다. 개선된 ResNet-101 모델은 CNN보다 학습 오류와 검증 오류가 8.2배, 44.6배가량 줄어들었으며 평균적인 정밀도와 f1-score는 0.98로 높은 수준을 유지하였다. 또한 CAM(class activation maps)을 활용하여 딥러닝 모델이 운전자의 주의 분산 행동을 판단할 때, 핸드폰 객체와 위치를 결정적 원인으로 활용했는지 검토하였다.","In this paper, we analyzed driver""s and passenger""s motions that cause driver""s distraction, and recognized 10 driver""s behaviors related to mobile phones. First, distraction-inducing behaviors were classified into environments and factors, and related recent papers were analyzed. Based on the analyzed papers, 10 driver""s behaviors related to cell phones, which are the main causes of distraction, were recognized. The experiment was conducted based on about 100,000 image data. Features were extracted through SURF and tested with three models (CNN, ResNet-101, and improved ResNet-101). The improved ResNet-101 model reduced training and validation errors by 8.2 times and 44.6 times compared to CNN, and the average precision and f1-score were maintained at a high level of 0.98. In addition, using CAM (class activation maps), it was reviewed whether the deep learning model used the cell phone object and location as the decisive cause when judging the driver""s distraction behavior."
Neural network-based build time estimation for additive manufacturing: a performance comparison,2021,"['additive manufacturing', 'artificial neural network', '3D convolutional neural network', 'build time estimation', '3D printing']",,"Additive manufacturing (AM) has brought positive opportunities with phenomenal changes to traditional manufacturing. Consistent efforts and novel studies into AM use have resolved critical issues in manufacturing and broadened technical boundaries. Build time estimation is one of the critical issues in AM that still needs attention. Accurate build time estimation is key for feasibility studies, preliminary design, and process/production planning. Recent studies have provided the possibility of neural network (NN)-based build time estimation. In particular, traditional artificial NN (ANN)- and convolutional NN (CNN)-based methods have been demonstrated. However, very little has been done on the performance comparison for build time estimation among the different types of NNs. This study is aimed at filling this gap by designing various NNs for build time estimation and comparing them. Two types of features are prepared as inputs for the NNs by processing three-dimensional (3D) models: (1) representative features (RFs) including dimensions, part volume, and support volume; and (2) the set of voxels generated from designating the cells occupied by the workpiece in a mesh grid. With the combination of NN types and input feature types, we design three NNs: (1) ANN with RFs; (2) ANN with voxels; and (3) CNN with voxels. To obtain large enough label data for reliable training, we consider simulation build time from commercial slicing applications rather than actual build time. The simulation build time is calculated based on a material extrusion process. To address various cases for input models, two design factors (scale and rotation) are considered by controlling the size and build orientation of 3D models. In computational experiments, we reveal that the CNN-based estimation is often more accurate than others. Furthermore, the design factors affect the performance of build time estimation. In particular, the CNN-based estimation is strongly influenced by changing the size of 3D models."
딥러닝 기반 부실기업 예측모형에 관한 연구,2021,"['기업 부실화', '딥러닝 기법', '머신러닝', '앙상블 모형', '한계기업 예측', 'Corporate Insolvency', 'Deep Learning', 'Machine Learning', 'Ensemble Model', 'Marginal Company Prediction']","부실기업 예측은 회계와 재무 분야에서 중요하게 다루어져 온 연구 주제이다. 특히, 급변하는 기업 환경과 최근 COVID-19 대유행으로 국내의 많은 기업이 기업 부실화로 재무적 어려움에 직면하고 있어 그 연구의 필요성이 더욱 강조되고 있다. 대표적인 관련 연구로는 기업부도 예측이 있지만, 부도기업은 사실상 사업활동을 중단한 기업으로 계속기업 간에 어떠한 기업이 부실 징후를 보이는지를 판단하는 기준으로 부적합하다는 한계점이 존재한다. 본 연구는 부실기업의 범주 중 하나인 한계기업을 그 예측대상으로 선정하였다. 한계기업은 3개년도 연속 이자보상비율이 1 미만인 기업으로, 사업활동을 영위하고 있으나 적정 수준의 이익을 지속적으로 확보하지 못하고 있는 부실기업을 의미한다. 본 연구에서는 한계기업 예측을 위한 방법으로 딥러닝 기법을 활용하였다. 딥러닝은 다양한 분야에서 그 우수성을 인정받아 최근 주목받고 있는 머신러닝 기법의 하나이지만 한계기업 예측을 위한 연구에서는 적용된 바가 없다. 본 연구는 여러 재무비율 변수를 독립변수로 하여 딥러닝 기법 중 RNN과 CNN를 적용하고, 선행연구에서 예측력이 뛰어나다고 보고된 머신러닝 앙상블 모형들과 그 성과를 비교하였다. 2017~2019년의 기업 데이터를 학습용 및 테스트용 데이터로 설정하여 분석한 결과, RNN-LSTM, RNN-GRU, CNN이 재현율(Recall)의 관점에서 우수한 성과를 보이는 것으로 나타났다. 그러므로 딥러닝 모형이 한계기업 예측에서도 널리 사용될 수 있는 분석방법이 될 것으로 기대된다.","Predicting insolvent companies is a research topic that has been important in accounting and finance. Especially, due to the rapidly changing business environments and the recent COVID-19 pandemic, many domestic companies are facing financial adversity. Thus, the necessity of research on corporate insolvency is being emphasized. As a related research, there is a prediction of corporate bankruptcy, however, a bankrupt company is the company whose business activities have been suspended, and there is a limitation in which it is inappropriate to determine which companies show signs of bankruptcy among continuing companies. Therefore, marginal company, one of the categories of insolvent companies, is selected as the prediction target. Marginal companies are the firms that are operating income interest compensation ratio are less than 1 for three consecutive years, and are engaged in business activities but have not consistently secured adequate profits. In this study, deep learning techniques are used to predict them. It is one of the machine learning techniques that has recently attracted attention because of its excellence in various fields. Nonetheless, has not been applied in research to predict marginal companies. This study applies RNN and CNN among deep learning techniques using several financial ratios as independent variables. Their performance are compared with machine learning ensemble models that have been reported to have excellent predictive power in previous studies. As a result of analysis on corporate data from 2017 to 2019 as training and test data, deep learning models such as RNN-LSTM, RNN-GRU, and CNN are better in forecasting of marginal companies than the ensemble models in terms of Recall score. Therefore, the deep learning models are expected to become widely used in the prediction of marginal companies in the future."
Effective Electricity Demand Prediction via Deep Learning,2021,"['LSTM', 'CNN', 'Electricity demand prediction', 'Deep-learning', 'Machine-learning', 'ARIMA', 'MLP']",,"Prediction of electricity demand in homes and buildings can be used to optimize an energy management system by decreasing energy wastage. A time-series prediction system is still a challenging problem in machine learning and deep learning. Our main idea is to compare three methods. For this work, we analyzed an electricity demand prediction system using the current state-of-the-art deep-learning methods with a machine-learning method: error correction with multi-layer perceptron (eMLP) structure, autoregressive integrated moving average (ARIMA) structure, and a proposed structure named CNN-LSTM. For this, we measured and collected electricity demand data in Germany for home appliances. We report the prediction accuracy in terms of the mean square error (MSE) and mean absolute percentage error (MAPE). The experimental result indicates that CNN-LSTM outperforms eMLP and ARIMA in accuracy."
An Autonomous Driving Approach Based on Trajectory Learning Using Deep Neural Networks,2021,"['Autonomous driving', 'Trajectory learning', 'CNN_Raw-RNN', 'Pilot and copilot']",,"Autonomous driving approaches today are mainly based on perception-planning-action modular pipelines and the End2End paradigm respectively. The End2End paradigm is a strategy that directly maps raw sensor data to vehicle control actions. This strategy is very promising and appealing because complex module design and cumbersome data labeling are avoided. Since this approach lacks a degree of interpretability, safety and practicability. we propose an autonomous driving approach based on trajectory learning using deep neural networks in this paper. In comparison to End2End algorithm, it is found that the trajectory learning algorithm performs better in autonomous driving. As for trajectory learning algorithm, the CNN_Raw-RNN network structure is established, which is verified to be more effective than the original CNN_LSTM network structure. Besides, we propose an autonomous driving architecture of a pilot and copilot combination. The pilot is responsible for trajectory prediction via imitation learning with labeled driving trajectories, while the copilot is a safety module that is employed to verify the effectiveness of the vehicle trajectory by the results of the semantic segmentation auxiliary task. The proposed autonomous driving architecture is verified with a real car on urban roads without manual intervention within 40 km."
ResNet과 Unet을 결합한 딥러닝 모델을 이용한 분광 신호에서 ROI 검출,2021,"['Peak Detection', 'Region of Interest', 'Deep Learning', 'CNN', 'Raman Spectroscopy']","본 연구에서는 딥러닝 기술(deep learning technology)을 이용하여 분광 신호의 ROI(region of interest)를 찾는 방법을 제안한다. 제안한 방법은 모의실험 데이터로 학습된 딥러닝 모델을 이용하여 분광 신호의 ROI를 검출하는 방법이다. 분광 신호의 피크는 물질의 물리 화학적인 정보를 포함하고 있으므로 정확한 피크 검출은 분석 시스템의 성능에 영향을 미치는 중요한 과정이다. 지금까지 가장 많이 사용되는 방법은 진폭을 기반으로 피크 검출을 진행하는 것이다. 하지만 이런 방법들은 전처리 과정을 포함하거나 분광 신호에 따라 파라미터를 육안 검사로 선택하여 추정하므로 복잡하고 주관적이다. 이러한 문제점 개선을 위해 딥러닝 모델을 통해 분광 신호의 ROI 검출을 수행하였다. 제안한 방법은 전처리 과정이 없고 파라미터를 설정하지 않아도 되는 장점을 갖는다. 또한 검출한 ROI에 따라 분광 신호에 후처리(post-processing)를 수행하여 피크를 얻을 수 있다. 디폴트 손실 함수에 3만개 테스트 데이터를 적용하여 얻은 손실값을 통해 성능 평가를 수행하였다. 제안된 ResNet과 Unet을 결합한 딥러닝 모델은 일반적인 컨볼루션 신경망(CNN: Convolutional Neural Network), ResNet, 그리고 Unet에 비해 각각 76.5%, 69.8%, 5.9%의 성능 향상을 보였으며, 실제 라만 분광 신호의 ROI 검출에도 효과적으로 적용될 수 있음을 확인하였다.","This study proposes a method to find the ROI (region of interest) of spectral signals using deep learning technology. The proposed method detects the ROI of spectral signals using a deep learning model trained with simulated data. Since the peak of the spectral signal contains physical and chemical information of the substance, accurate peak detection is an important process affecting the performance of the analyzed system. The widely used method for peak detection is the one based on the amplitude. However, this method is complex and subjective because it involves pre-processing or select and estimate parameters using visual inspection according to spectral signals. To overcome this problem, ROI detection of the spectral signal was performed through a deep learning model. The proposed method has the advantage of requiring no pre-processing and parameter setting. In addition, a peak may be obtained by performing post-processing of the spectral signal according to the detected ROI. Performance evaluation was performed through loss values obtained by applying 30,000 test data to the custom loss function. The proposed deep learning model combining ResNet and Unet showed performance improvements of 76.5%, 69.8%, and 5.9% compared to the general convolutional neural network (CNN), ResNet, and Unet, respectively. It was also confirmed that the proposed method could be effectively applied to measured spectral signals."
인공지지체 불량 검출을 위한 딥러닝 모델 성능 비교에 관한 연구,2021,"['Algorithm Evaluate', 'Classification Performance Compare', 'CNN', 'Defect Detection Model', 'Scaffold Defect']",,"When we inspect scaffold defect using sight, inspecting performance is decrease and inspecting time is increase. We need for automatically scaffold defect detection method to increase detection accuracy and reduce detection times. In this paper. We produced scaffold defect classification models using densenet, alexnet, vggnet algorithms based on CNN. We photographed scaffold using multi dimension camera. We learned scaffold defect classification model using photographed scaffold images. We evaluated the scaffold defect classification accuracy of each models. As result of evaluation, the defect classification performance using densenet algorithm was at 99.1%. The defect classification performance using VGGnet algorithm was at 98.3%. The defect classification performance using Alexnet algorithm was at 96.8%. We were able to quantitatively compare defect classification performance of three type algorithms based on CNN."
"『길 위 1번지』, AI 제임스의 소설 : 「소설의 기술」과 인공신경망 알고리즘의 글쓰기",2021,"['Henry James', '“The Art of Fiction', '” 1 the Road', 'CNN', 'RNN', 'Creativity']",,"This article explores the implications of 1 the Road (2018), a fiction produced by an artificial neural network, for the debate on machine creativity. Unlike most of the recent deeplearning writing programs, its creator Ross Goodwin traveled with this neural network machine from New York to New Orleans in a Cadillac equipped with a surveillance camera, a voice recognizer, and GPS. The AI thus had continuous feeds of fresh images and sounds, not unlike a novelist who hits the road searching for an experience. I argue that we can better understand this attempt of 1 the Road when discussed alongside Henry James’s realist notion of fiction in his essay “The Art of Fiction” (1884). Even though James is often considered an arch-humanist in his belief that fiction is an expression of the unique personality of a novelist, his idea of experience offers a way of understanding Goodwin’s machine as a creative writer. Its algorithmic operation―processing the new sense data via the CNN algorithm and producing the result as writing via the RNN algorithm―is strikingly similar to the workings of the novelist’s mind in James’s view. I do not argue that those sense data are unmediated, and this fact is reflected in the CNN’s algorithm that imitates the human mind. In fact, James asserts that sensory data are the result of mediated selection, which can only be seen through the final result, the writing itself. What I propose is that regardless of whether the machine has a so-called “consciousness,” its writing can affect the reader in similar ways as does a text written by a human being. As long as it works as a linguistic medium to relate the “experience,” which is the algorithmic process of selection and transcription, it is a creative writer."
스마트폰 가속도계를 이용한 보행자 운동 인식 알고리즘,2021,"['Pedestrian Navigation', 'Smartphone', 'Motion Recognition', 'Decision Tree', 'Convolutional Neural Network']",,"Pedestrian motion recognition algorithms using the accelerometer on a smartphone are implemented, and performance evaluation results are presented. The features for classifying the decision tree and design parameters of a CNN (Convolutional Neural Network) for recognizing pedestrian motion are listed. The accelerometer outputs of a smartphone that was used to monitor six adults who performed six motion types were collected. The decision tree thresholds were determined, and the CNN weights were learned from the collected data. With the derived thresholds and weights, the real-time pedestrian motion recognition algorithms were implemented on a smartphone, and their performance was evaluated. The performance evaluation results show that the CNN-based motion recognition algorithm has better accuracy than the decision tree-based motion recognition algorithm."
딥 러닝을 이용한 단일 카메라 SLAM에서 스케일 드리프트 감소,2021,"['Monocular SLAM', 'Scale Drift', 'Deep Learning', 'Convolutional Neural Network']",,"Monocular SLAM(Simultaneous Localization and Mapping) systems have such advantages as low cost and light weight compared to stereo or laser range finder based SLAM systems. However they also have relatively large errors when they measure the distances between a vehicle and some distinct objects, which can lead to scale ambiguity or scale drift. In this paper, we suggest a scale drift-aware monocular SLAM system using CNN(Convolutional Neural Network) which is one of the key technologies of Deep Learning. CNN nowadays has proved its performances especially in computer vision. We have trained the system with plenty of images of some predetermined objects using CNN. And then we can measure the absolute distances between a vehicle and already known objects and resolve the scale drift problems. The suggested system has been evaluated by several experiments."
Faster RCNN과 픽셀 분류 신경망을 이용한 다상유동에서의 기포 검출에 대한 연구,2021,"['Bubble Detection', 'Artificial Neural Network', 'Multiphase Flow', '기포 검출', '인공 신경망', '다상유동']","다상유동에서 기포 크기 분포를 알기 위해 사용되고 있는 기존 이미지 처리 기법들은 실험 수행 조건에 영향을 받는다. 본 연구에서는 CNN을 기반으로 한 기포 검출 기법을 제안한다. 이미지에서 기포가 위치한 영역을 찾기 위해서 Faster RCNN을 사용하였고, 픽셀 분류 신경망을 이용해서 찾아진 영역에서 기포를 분할하였다. 신경망들을 훈련시키기 위해 필요한 이미지는 세 종류의 기포발생기를 이용한 실험으로부터 얻었으며, 배경 밝기, 유량들을 변경하며 실험하였다. 신경망의 backbone 구조에 따른 성능에 대한 비교를 진행하였다. 신경망의 깊이에 따른 구조 병렬화 영향에 대한 분석할 수 있었고 제안된 신경망은 실시간으로 이미지로부터 기포를 검출할 수 있었다.","Characterization of bubbles in gas-liquid multiphase flow is important to design and optimize industrial systems. To this end, multiple visual techniques, including image processing, have been developed to measure bubble size distributions. However, traditional image processing methods significantly influence experimental settings. Thus, an improved bubbled detection method based on convolutional neural networks (CNNs) is proposed herein. This method involves using a faster region-based CNN (Faster RCNN) to detect the bubble location and a pixel classification network to segment bubble shapes. Experiments were conducted using three types of bubble generators with various background intensities and volume flow rates. Furthermore, the backbone CNN architectures used in the Faster RCNN and the pixel classification network were compared. The model network is highly versatile, is capable of characterizing bubble information in real-time, and has the potential to replace the traditional image processing method."
드론과 Mobile Mapping System을 활용한 인공지능 기반 도로 균열 검출,2021,"['artificial intelligence', 'CNN', 'drone', 'mobile mapping system', 'mobilenetv2', 'road crack', '인공지능', '드론', '모바일매핑시스템', '도로 균열']","최근 5년간 중앙정부의 전체 예산은 매년 4.9%의 비율로 증가하고 있으나, 도로부문의 유지관리 예산은 매년 줄고 있다. 또한 도로법의 개정 및 지속가능한 기반시설 관리 기본법의 신설에 따라 모든 지자체에서 유지관리와 성능개선을 위해 5년 단위의 기본계획을 수립해야 한다. 하지만 상대적으로 예산이 적은 지자체에서 도로관리를 위한 고가의 장비를 도입하기는 현실적으로 어려운 실정이다. 이에 본 연구는 인공지능을 활용하여 상대적으로 가격이 저렴한 Mobile Mapping System(MMS)와 드론을 활용한 도로균열 검출 방법을 제시하는 것을 연구의 목적으로 한다. MMS와 드론을 활용하여 얻은 해상도 높은 도로 노면 사진데이터를 취득하고 데이터의 특성에 따라 인공지능을 학습시키기 위하여 전처리를 수행하였다. 딥러닝 학습을 위해 도로 파손 유형에 따라 균열이 있는 곳과 없는 곳, 또는 도로가 아닌 곳으로 라벨링을 진행하였고 Basic CNN모델과 Mobilenetv2신경망을 수정하여 학습을 진행하였다. Mobilenetv2의 알고리즘의 분류정확도는 MMS데이터 95%, 드론데이터 78%를 얻었다. 이는 MMS와 드론을 활용하여 정도 높은 균열 분류가 가능하다는 결론을 도출할 수 있었다. 향후 본 연구에서 개발된 알고리즘을 기반으로 지자체와 시설물 관리 기관에서 도로균열을 체계적으로 관리될 것이다. 또한 사용자 중심의 소프트웨어를 활용하여 도로를 이용하는 시민들에게도 도움이 될 것으로 기대된다.","In recent years, the total budget of the central government has been increasing at a rate of 4.9% per year, but the maintenance budget of the road sector has been decreasing annually. In addition, with the revision of the Road Act and the establishment of the Framework Act on Sustainable Infrastructure Management, all local governments shall establish a five-year master plan to improve maintenance and performance. However, it is difficult for local governments with relatively small budgets to introduce expensive equipment for road management. In response, the purpose of this study is to present a road crack detection method using mobile mapping system (MMS) and drones that are relatively inexpensive with the use of artificial intelligence. High-precision road surface photographic data could be acquired using MMS and drones. Pre-processing was carried out to train the artificial intelligence depending on the characteristics of the data. Labeling was conducted according to the type of road cracks and was labeled based on where cracks were present, where none were present, or where roads were not. The training was done by modifying the basic convolution network model and the mobilenetv2 neural network. As a result of the training, the data classification accuracy using the mobilenetv2 algorithm was able to achieve 95% on MMS data and 78% on drone data. It can be hypothesized that a more high-performance crack classification accuracy might be achieved by utilizing MMS and drone equipment. In the future, road cracks will be systematically managed by local governments and facility management agencies based on algorithms developed in this study. It is also expected to benefit citizens who use user-centered software to use roads."
Xception과 양방향 LSTM을 통한 뇌종양 진단에 관한 연구,2021,"['Deep Learning', 'Artificial Intelligence', 'Diagnosis', 'CNN', 'LSTM', 'Xception', 'Brain Tumor']","뇌종양은 전체 종양 중 세 번째로 많을 뿐만 아니라 우리나라에서도 환자 수가 늘어나는 추세이다. 하지만 영상기반 검사가 주로 이루어지는 뇌종양의 경우, 전문의가 판단하기 때문에 판독 결과에 오류가 생길 가능성이 있다. 이를 방지하고자 인공지능 기반의 진단 방법이 도입되고 있다. 본 연구의 목적은 뇌종양을 단순히 2가지(정상, 비정상)가 아닌 4가지(교종, 뇌수막종, 뇌수하체 종양, 정상)로 더 정교하게 진단하고, 다른 모델들과 정확도를 비교하는 것이다. 또한, 단순 분류가 아닌 이미지 분할을 통해 환자로 분류한 근거를 시각화한다. 이를 위해 본 논문에서는 Xception과 양방향 LSTM을 활용한 모델을 통해 MRI 사진을 4가지로 분류하고 정확도를 다른 딥러닝 알고리즘들과 비교, 분석한다. 또한, CAM(Class Activation Map)을 통해 이상 부위를 시각화한다. 분석 결과 본 연구에서 제안하는 모델이 정확도 86%를 보이며 가장 높은 정확도를 기록하였다. 특히, 단순히 Xception 모델을 사용하였을 때 보다 8%가 증가하였다. 따라서 본 연구는 두 가지 의의를 가진다. 첫번째로, 단순 Xception 모델보다 Xception 모델에 양방향 LSTM을 추가하였을 때, VGG16, MobileNet과 같은 다른 CNN기반의 사전 훈련된 딥러닝 모델들보다 성능이 높다는 결론을 도출했다는 점에서 의의가 있다. 두번째로, 기존 2단계로 예측하던 뇌종양 진단을 4단계로 분류함과 동시에 이상 부위를 시각화하여 더욱 정교한 뇌종양 진단 모델을 개발하였다는 점에 의의가 있다.","Brain tumors have the third-largest incidence among tumors, and the number of patients is increasing continuously in Korea. On the other hand, as the diagnosis of brain tumor is conducted mainly through a vision-based inspection by doctors, there is a possibility of errors in the stage of inspection. Artificial intelligence-based diagnostic methods are being introduced to prevent this problem. This study attempted to classify patients into more sophisticated stages (normal, glioma, pituitary, and meningioma) than previous research, which classified them into two stages (normal and patient). The accuracy of the proposed model was compared, and the anomalous part of the brain was visualized. To this end, MRI pictures were classified into four categories through Xception + Bi-directional LSTM and compared to the other pretrained models. Furthermore, the anomalous part of the brain was visualized through CAM (Class Activation Map). The proposed model achieved 86%, which is 8% higher than the simple Xception model. This research is significant in finding that the Xception + Bi-directional LSTM model showed higher accuracy than other pretrained models, such as simple Xception, VGG16, and MobileNet. Furthermore, this research is also worthwhile because the patients could be classified into four categories with high accuracy, and the anomaly parts could be visualized."
주기적 행동 검출을 위한 멀티스케일 U-Net,2021,"['Multi-scale U-Net', '3D CNN', 'Periodicity', 'Repetition']",,
Xception과 양방향 LSTM을 통한 뇌종양 진단에 관한 연구,2021,"['Deep Learning', 'Artificial Intelligence', 'Diagnosis', 'CNN', 'LSTM', 'Xception', 'Brain Tumor']","뇌종양은 전체 종양 중 세 번째로 많을 뿐만 아니라 우리나라에서도 환자 수가 늘어나는 추세이다. 하지만 영상기반 검사가 주로 이루어지는 뇌종양의 경우, 전문의가 판단하기 때문에 판독 결과에 오류가 생길 가능성이 있다. 이를 방지하고자 인공지능 기반의 진단 방법이 도입되고 있다. 본 연구의 목적은 뇌종양을 단순히 2가지(정상, 비정상)가 아닌 4가지(교종, 뇌수막종, 뇌수하체 종양, 정상)로 더 정교하게 진단하고, 다른 모델들과 정확도를 비교하는 것이다. 또한, 단순 분류가 아닌 이미지 분할을 통해 환자로 분류한 근거를 시각화한다. 이를 위해 본 논문에서는 Xception과 양방향 LSTM을 활용한 모델을 통해 MRI 사진을 4가지로 분류하고 정확도를 다른 딥러닝 알고리즘들과 비교, 분석한다. 또한, CAM(Class Activation Map)을 통해 이상 부위를 시각화한다. 분석 결과 본 연구에서 제안하는 모델이 정확도 86%를 보이며 가장 높은 정확도를 기록하였다. 특히, 단순히 Xception 모델을 사용하였을 때 보다 8%가 증가하였다. 따라서 본 연구는 두 가지 의의를 가진다. 첫번째로, 단순 Xception 모델보다 Xception 모델에 양방향 LSTM을 추가하였을 때, VGG16, MobileNet과 같은 다른 CNN기반의 사전 훈련된 딥러닝 모델들보다 성능이 높다는 결론을 도출했다는 점에서 의의가 있다. 두번째로, 기존 2단계로 예측하던 뇌종양 진단을 4단계로 분류함과 동시에 이상 부위를 시각화하여 더욱 정교한 뇌종양 진단 모델을 개발하였다는 점에 의의가 있다.","Brain tumors have the third-largest incidence among tumors, and the number of patients is increasing continuously in Korea. On the other hand, as the diagnosis of brain tumor is conducted mainly through a vision-based inspection by doctors, there is a possibility of errors in the stage of inspection. Artificial intelligence-based diagnostic methods are being introduced to prevent this problem. This study attempted to classify patients into more sophisticated stages (normal, glioma, pituitary, and meningioma) than previous research, which classified them into two stages (normal and patient). The accuracy of the proposed model was compared, and the anomalous part of the brain was visualized. To this end, MRI pictures were classified into four categories through Xception + Bi-directional LSTM and compared to the other pretrained models. Furthermore, the anomalous part of the brain was visualized through CAM (Class Activation Map). The proposed model achieved 86%, which is 8% higher than the simple Xception model. This research is significant in finding that the Xception + Bi-directional LSTM model showed higher accuracy than other pretrained models, such as simple Xception, VGG16, and MobileNet. Furthermore, this research is also worthwhile because the patients could be classified into four categories with high accuracy, and the anomaly parts could be visualized."
MATE: Memory- and Retraining-Free Error Correction for Convolutional Neural Network Weights,2021,"['Convolutional neural network', 'Error correction codes', 'Main memory', 'Reliability', 'Weight data']",,"Convolutional neural networks (CNNs) are one of the most frequently used artificial intelligence techniques. Among CNN-based applications, small and timing-sensitive applications have emerged, which must be reliable to prevent severe accidents. However, as the small and timing-sensitive systems do not have sufficient system resources, they do not possess proper error protection schemes. In this paper, we propose MATE, which is a low-cost CNN weight error correction technique. Based on the observation that all mantissa bits are not closely related to the accuracy, MATE replaces some mantissa bits in the weight with error correction codes. Therefore, MATE can provide high data protection without requiring additional memory space or modifying the memory architecture. The experimental results demonstrate that MATE retains nearly the same accuracy as the ideal error-free case on erroneous DRAM and has approximately 60% accuracy, even with extremely high bit error rates."
인공지능 기반 유해조류 탐지 관제 시스템,2021,"['Drone', 'Machine Learning', 'Atonomous Driving', 'Control Systems', 'Harmful Birds', '드론', '머신러닝', '자율 주행', '관제 시스템', '유해 조류']","본 논문에서는 오리와 같은 유해조류에 의한 양식장의 피해를 방지하기 위해서 머신러닝 기반 해상용 드론 개발을 목적으로 한다. 기존 드론은 공중에서 새와 충돌하거나 바다에 떨어지는 경우 유실되는 문제점을 해결 하기 위해서 해상드론으로 개발하였다. 자율주행으로 작동하는 해상드론이 해상에 나타난 유해조류를 판단하기 위해 CNN기반 머신러닝 학습 알고리즘을 설계하였다. 유해조류의 위치 인식 및 추적을 위해 카메라에 라즈베리파이를 연결하여 관제 PC로 영상을 전송하도록 설계하였다. 모바일 기반 관제 센터에서 미리 GPS 좌표와 연동된 맵을 미리 제작한 후, 유해조류의 위치에 대한 GPS 위치값을 전달받아 설정된 위치로 해상용 드론이 출동하여 유해조류를 퇴치하는 자율주행 기반의 해상용 조류 퇴치 드론 시스템을 설계 및 구현하였다.","The purpose of this paper is to develop a machine learning-based marine drone to prevent the farming from harmful birds such as ducks. Existing drones have been developed as marine drones to solve the problem of being lost if they collide with birds in the air or are in the sea. We designed a CNN-based learning algorithm to judge harmful birds that appear on the sea by maritime drones operating by autonomous driving. It is designed to transmit video to the control PC by connecting the Raspberry Pi to the camera for location recognition and tracking of harmful birds. After creating a map linked with the location GPS coordinates in advance at the mobile-based control center, the GPS location value for the location of the harmful bird is received and provided, so that a marine drone is dispatched to combat the harmful bird. A bird fighting drone system was designed and implemented."
기계학습에 의한 Al-Si 주조 합금 미세조직 이미지 생성,2021,"['Machine learning', 'generative adversarial network', 'image generation', 'microstructure', 'aluminum alloys.']",,"In this study, we constructed a deep convolutional generative adversarial network (DCGAN) to generate the microstructural images that imitate the real microstructures of binary Al-Si cast alloys. We prepared four combinations of alloys, Al-6wt%Si, Al-9wt%Si, Al-12wt%Si and Al-15wt%Si for machine learning. DCGAN is composed of a generator and a discriminator. The discriminator has a typical convolutional neural network (CNN), and the generator has an inverse shaped CNN. The fake images generated using DCGAN were similar to real microstructural images. However, they showed some strange morphology, including dendrites without directionality, and deformed Si crystals. Verification with Inception V3 revealed that the fake images generated using DCGAN were well classified into the target categories. Even the visually imperfect images in the initial training iterations showed high similarity to the target. It seems that the imperfect images had enough microstructural characteristics to satisfy the classification, even though human cannot recognize the images. Cross validation was carried out using real, fake and other test images.When the training dataset had the fake images only, the real and test images showed high similarities to the target categories. When the training dataset contained both the real and fake images, the similarity at the target categories were high enough to meet the right answers. We concluded that the DCGAN developed for microstructural images in this study is highly useful for data augmentation for rare microstructures."
청각장애인의 수어 교육을 위한 MediaPipe 활용 수어 학습 보조 시스템 개발,2021,"['수어', '학습 보조 플랫폼', '인공 지능 평가', '미디어 파이프', 'Sign Language', 'Learning Aids Platform', 'AI Evaluation', 'MediaPipe']","최근 선천적 청각장애 뿐만 아니라 후천적 요인으로 인해 청각장애를 가지게 되는 사람들도 증가하고 있지만, 수어를 익힐 수 있는 환경은 열악한 상황이다. 이에 본 연구에서는 수어를 배우는 수어 학습자를 위한 수어학습 보조도구로써 수어(지숫자/지문자) 평가 시스템을 제시하고자 한다. 이에 본 논문에서는 OpenCV 라이브러와 MediaPipe를 이용하여 손과 손가락을 추적하여 수어 동작을 인식하고 CNN기법을 이용하여 수어의 의미를 텍스트 형태의 데이터로 변환하여 학습자에게 제공하는 시스템을 연구한다. 이를 통해 수어를 배우는 학습자가 스스로 올바른 수형인지를 판단할 수 있도록 자기주도학습을 가능하게 하여 수어를 익히는데 도움이 되는 수어학습보조 시스템을 개발하고, 청각장애인들의 의사소통의 주언어인 수어학습을 지원하기 위한 방안으로 수어학습보조 시스템을 제안하는 데 목적이 있다.","Recently, not only congenital hearing impairment, but also the number of people with hearing impairment due to acquired factors is increasing. The environment in which sign language can be learned is poor. Therefore, this study intends to present a sign language (sign language number/sign language text) evaluation system as a sign language learning assistance tool for sign language learners. Therefore, in this paper, sign language is captured as an image using OpenCV and Convolutional Neural Network (CNN). In addition, we study a system that recognizes sign language behavior using MediaPipe, converts the meaning of sign language into text-type data, and provides it to users. Through this, self-directed learning is possible so that learners who learn sign language can judge whether they are correct dez. Therefore, we develop a sign language learning assistance system that helps us learn sign language. The purpose is to propose a sign language learning assistance system as a way to support sign language learning, the main language of communication for the hearing impaired."
Explanation segments 기반 설명 가능한 지식 완성 모델,2021,"['knowledge graph', 'explainable knowledge completion', 'embedding', 'attention mechanism', '지식 그래프', '설명 가능한 지식 완성', '임베딩', '어텐션 메커니즘']","최근 딥러닝을 활용하여 불완전한 지식 그래프를 대상으로 새로운 링크를 예측하는 연구가 많이 진행되고 있지만, 딥러닝을 활용한 링크 예측은 추론 결과에 대한 설명이 불가능하다는 한계점이 있다. 따라서 본 논문에서는 링크 예측 후, 추론 결과를 뒷받침하는 증거로서 설명 가능한 추론 경로를 제공하여 지식 완성의 효용성이 높은 모델을 제안한다. 이를 위해 우선 지식 그래프의 주어를 시작으로 목적어로 도달하는 또 다른 경로를 Path Ranking Algorithm 활용하여 생성하며, 이를 explanation segment라 정의하였다. 이 후 생성된 explanation segment를 CNN과 양방향 LSTM을 결합한 방식을 적용하여 임베딩 한다. 마지막으로 임베딩 된 explanation segment들과 추론할 후보 술어와의 의미적 유사성 계산을 기반으로 한 어텐션 메커니즘을 적용하여, 링크 예측 모델을 학습하였다. 모델 학습 후 링크 예측 설명에 적합한 explanation segment를 어텐션 점수에 기반으로 선정하여 제공한다. 제안하는 방법의 성능을 측정하기 위해 링크 예측 비교 실험 및 링크 예측 결과에 대한 설명으로 적합한 explanation segment의 비율을 측정하는 정확성 검증 실험을 진행하였다. 실험 데이터는 벤치마크 데이터인 NELL-995, FB15K-237, Countries를 대상으로 진행하였으며, 정확성 검증 실험에서 평균 89%. 44%, 97% 정확성을 보였고, 기존 연구와 비교했을 때, NELL-995는 평균 35%p, FB15K-237은 평균 21%p 높은 성능을 보였다.","Recently, a large number of studies that used deep learning have been conducted to predict new links in incomplete knowledge graphs. However, link prediction using deep learning has a major limitation as the inferred results cannot be explained. We propose a high-utility knowledge graph prediction model that yields explainable inference paths supporting the inference results. We define paths to the object from the knowledge graph using a path ranking algorithm and define them as the explanation segments. Then, the generated explanation segments are embedded using a Convolutional neural network (CNN) and a Bidirectional Long short-term memory (BiLSTM). The link prediction model is then trained by applying an attention mechanism, based on the calculation of the semantic similarity between the embedded explanation segments and inferred candidate predicates to be inferred. The explanation segment suitable for link prediction explanation is selected based on the measured attention scores. To evaluate the performance of the proposed method, a link prediction comparison experiment and an accuracy verification experiment are performed to measure the proportion of the explanation segments suitable to explain the link prediction results. We used the benchmark datasets NELL-995, FB15K-237, and countries for the experiment, and accuracy verification experiments showed the accuracies of 89%, 44%, and 97%, respectively. Compared with the existing method, the NELL-995, FB15K-237 data exhibited 35%p and 21%p higher performance on average."
Attention U-Net 신경망을 활용한 유체의 미래 상태 예측 기법,2021,"['딥러닝', '합성곱 신경망', '전산 유체 역학', '나비에-스토크스 방정식', '유체 시뮬레이션', 'Computational fluid dynamics', 'Navier Stokes equation', 'Deep learning', 'Convolutional Neural network', 'Fluid simulation.']","전산 유체 역학 시뮬레이션은 항공기, 건물, 자동차 등 유체와 관련된 다양한 디자인 분야에서 활용이 되어지고 있으나, 오랜 실행 시간과 많은 비용이 발생하는 나비에-스토크스 방정식의 사용으로 인해 개발에 많은 시간이 소요된다. 또한 위험 물질이 확산되는 환경과 같이 즉각적인 유체 흐름의 분석이 필요한 분야에서는활용이 어렵기 때문에 최대한 정확도를 보존하면서 빠르게 예측하는 기술이 매우 중요하게 여겨지고 있다.이를 위해 본 연구에서는 Attention U-Net 신경망을 기반으로 유체의 흐름을 예측하는 방법론을 제안하고테스트한다. 장애물을 인식하여 빠르게 7초 후 미래의 유체 흐름을 예측하는 방법으로 테스트를 진행하였고, 그 결과 기존 시뮬레이션 소프트웨어 및 CNN모델을 사용하였을 때 대비 정확도는 최대한 보존하면서 실행속도는 약 85배 빠른 결과를 얻을 수 있었다.","Computational Fluid Dynamics (CFD) simulation is used in various fluid-related fields such as aircrafts, buildings, or automobiles design and it consumes a lot of development time due to the use of Navier Stokes equation, which incur a long execution time with high cost. In addition, it is difficult to use it in such environments as the hazardous substance or epidemic diffusion where the fluid flow must be predicted immediately. In the situations, it is important and critical to predict as quickly as possible while preserving accuracy. Hence in this study, to address the issues, we suggest and test a method that uses Attention U-Net neural network to predict the future state of the fluid in a terrain with obstacles. As a result, compared to the existing simulation software or simple CNN method, the suggested approach shows the execution speed is 85 times faster while preserving the competitive accuracy."
오토인코더 기반의 잡음에 강인한 계층적 이미지 분류 시스템,2021,"['이미지 분류', '딥러닝', '머신러닝', '오토인코더', '잡음', 'Image classification', 'Deep learning', 'Machine learning', 'Autoencoder', 'Noise']",본 논문은 다수의 오토인코더 모델들을 이용한 잡음에 강인한 이미지 분류 시스템을 제안한다. 딥러닝 기술의 발달로 이미지 분류의 정확도는 점점 높아지고 있다. 하지만 입력 이미지가 잡음에 의해서 오염된 경우에는 이미지 분류 성능이 급격히 저하된다. 이미지에 첨가되는 잡음은 이미지의 생성 및 전송 과정에서 필연적으로 발생할 수밖에 없다. 따라서 실제 환경에서 이미지 분류기가 사용되기 위해서는 잡음에 대한 처리 및 대응이 반드시 필요하다. 한편 오토인코더는 입력값과 출력값이 유사하도록 학습되어지는 인공신경망 모델이다. 입력데이터가 학습데이터와 유사하다면 오토인코더의 출력데이터와 입력데이터 사이의 오차는 작을 것이다. 하지만 입력 데이터가 학습데이터와 유사성이 없다면 오토인코더의 출력데이터와 입력데이터 사이의 오차는 클 것이다. 제안하는 시스템은 오토인코더의 입력데이터와 출력데이터 사이의 관계를 이용한다. 제안하는 시스템의 이미지 분류 절차는 2단계로 구성된다. 1단계에서 분류 가능성이 가장 높은 클래스 2개를 선정하고 이들 클래스의 분류 가능성이 서로 유사하면 2단계에서 추가적인 분류 절차를 거친다. 제안하는 시스템의 성능 분석을 위해 가우시안 잡음으로 오염된 MNIST 데이터셋을 대상으로 분류 정확도를 실험하였다. 실험 결과 잡음 환경에서 제안하는 시스템이 CNN(Convolutional Neural Network) 기반의 분류 기법에 비해 높은 정확도를 나타냄을 확인하였다.,"This paper proposes a noise-tolerant image classification system using multiple autoencoders. The development of deep learning technology has dramatically improved the performance of image classifiers. However, if the images are contaminated by noise, the performance degrades rapidly. Noise added to the image is inevitably generated in the process of obtaining and transmitting the image. Therefore, in order to use the classifier in a real environment, we have to deal with the noise. On the other hand, the autoencoder is an artificial neural network model that is trained to have similar input and output values. If the input data is similar to the training data, the error between the input data and output data of the autoencoder will be small. However, if the input data is not similar to the training data, the error will be large. The proposed system uses the relationship between the input data and the output data of the autoencoder, and it has two phases to classify the images. In the first phase, the classes with the highest likelihood of classification are selected and subject to the procedure again in the second phase. For the performance analysis of the proposed system, classification accuracy was tested on a Gaussian noise-contaminated MNIST dataset. As a result of the experiment, it was confirmed that the proposed system in the noisy environment has higher accuracy than the CNN-based classification technique."
기계학습의 LSTM을 적용한 지상 기상변수 예측모델 개발,2021,"['Weather forecast', 'deep learning', 'RNN', 'LSTM']",,"Numerical weather prediction (NWP) models play an essential role in predicting weather factors, but using them is challenging due to various factors. To overcome the difficulties of NWP models, deep learning models have been deployed in weather forecasting by several recent studies. This study adapts long short-term memory (LSTM), which demonstrates remarkable performance in time-series prediction. The combination of LSTM model input of meteorological features and activation functions have a significant impact on the performance therefore, the results from 5 combinations of input features and 4 activation functions are analyzed in 9 Automated Surface Observing System (ASOS) stations corresponding to cities/islands/mountains. The optimized LSTM model produces better performance within eight forecast hours than Local Data Assimilation and Prediction System (LDAPS) operated by Korean meteorological administration. Therefore, this study illustrates that this LSTM model can be usefully applied to very short-term weather forecasting, and further studies about CNN-LSTM model with 2-D spatial convolution neural network (CNN) coupled in LSTM are required for improvement."
Human Laughter Generation using Hybrid Generative Models,2021,"['Laughter Synthesis', 'Variational Autoencoder', 'Autoencoder', 'Objective and Subjective Evaluation']",,"Laughter is one of the most important nonverbal sound that human generates. It is a means for expressing his emotions. The acoustic and contextual features of this specific sound are different from those of speech and many difficulties arise during their modeling process. During this work, we propose an audio laughter generation system based on unsupervised generative models: the autoencoder (AE) and its variants. This procedure is the association of three main sub-process, (1) the analysis which consist of extracting the log magnitude spectrogram from the laughter database, (2) the generative models training, (3) the synthesis stage which incorporate the involvement of an intermediate mechanism: the vocoder. To improve the synthesis quality, we suggest two hybrid models (LSTM-VAE, GRU-VAE and CNN-VAE) that combine the representation learning capacity of variational autoencoder (VAE) with the temporal modelling ability of a long short-term memory RNN (LSTM) and the CNN ability to learn invariant features. To figure out the performance of our proposed audio laughter generation process, objective evaluation (RMSE) and a perceptual audio quality test (listening test) were conducted. According to these evaluation metrics, we can show that the GRU-VAE outperforms the other VAE models."
YOLOv5와 모션벡터를 활용한 트램-보행자 충돌 예측 방법 연구,2021,"['Tram', 'Dense Optical Flow', 'Estimation of Collision point', 'TTC', 'Time-To-Collision', 'YOLOv5', '트램', '충돌지점 추정', '충돌시간 추정']",,"In recent years, autonomous driving technologies have become a high-value-added technology that attracts attention in the fields of science and industry. For smooth Self-driving, it is necessary to accurately detect an object and estimate its movement speed in real time. CNN-based deep learning algorithms and conventional dense optical flows have a large consumption time, making it difficult to detect objects and estimate its movement speed in real time. In this paper, using a single camera image, fast object detection was performed using the YOLOv5 algorithm, a deep learning algorithm, and fast estimation of the speed of the object was performed by using a local dense optical flow modified from the existing dense optical flow based on the detected object. Based on this algorithm, we present a system that can predict the collision time and probability, and through this system, we intend to contribute to prevent tram accidents."
감시 카메라를 이용한 딥러닝 기반의 화재 경보 시스템,2021,"['AUC', 'Convolution neural network', 'Cross validation', 'Deep learning', 'Fire detect', 'ROC curve', 'Surveillance camera']","센서 기반의 기존의 화재 검출기는 먼지나 습도에 의하여 오작동을 하여 유지 관리에 많은 비용이 들며, 경험적 파라미터에 크게 의존하기 때문에 조직적인 설계가 이루어질 수 없다. 또한, 프레임 차분을 통한 화재 검출 방식은 카메라의 통신 상태가 좋지 못한 곳에서는 그 성능이 떨어질 수밖에 없다. 이 논문에서는 CNN기반의 새로운 화재 감지 시스템을 보인다. 작은 화재까지도 검출하기 위하여 최소의 수용장 영역 (receptive filed)을 선택하였다. 또한, 매 프레임에서 화재를 검출하는 방식을 취하기 때문에 통신 환경 상태와 무관한 일정한 성능을 보인다. 정확한 검증을 위하여 교차 검증을 하여, 96.2%의 f1—score, 0.98의 최소 AUC를 얻었다.",
Multi-layered attentional peephole convolutional LSTM for abstractive text summarization,2021,"['abstractive text summarization', 'convolutional long short-term memory', 'deep neural network', 'long short-term memory', 'sequence to sequence modeling']",,"Abstractive text summarization is a process of making a summary of a given text by paraphrasing the facts of the text while keeping the meaning intact. The manmade summary generation process is laborious and time-consuming. We present here a summary generation model that is based on multilayered attentional peephole convolutional long short-term memory (MAPCoL; LSTM) in order to extract abstractive summaries of large text in an automated manner. We added the concept of attention in a peephole convolutional LSTM to improve the overall quality of a summary by giving weights to important parts of the source text during training. We evaluated the performance with regard to semantic coherence of our MAPCoL model over a popular dataset named CNN/Daily Mail, and found that MAPCoL outperformed other traditional LSTM-based models. We found improvements in the performance of MAPCoL in different internal settings when compared to state-of-the-art models of abstractive text summarization."
Improved Convolutional Neural Network Based Cooperative Spectrum Sensing For Cognitive Radio,2021,"['Cognitive radio', 'Cooperative spectrum sensing', 'Primary user', 'Simulated annealing', 'Neural network']",,"Cognitive radio systems are being implemented recently to tackle spectrum underutilization problems and aid efficient data traffic. Spectrum sensing is the crucial step in cognitive applications in which cognitive user detects the presence of primary user (PU) in a particular channel thereby switching to another channel for continuous transmission. In cognitive radio systems, the capacity to precisely identify the primary user’s signal is essential to secondary user so as to use idle licensed spectrum. Based on the inherent capability, a new spectrum sensing technique is proposed in this paper to identify all types of primary user signals in a cognitive radio condition. Hence, a spectrum sensing algorithm using improved convolutional neural network and long short-term memory (CNN-LSTM) is presented. The principle used in our approach is simulated annealing that discovers reasonable number of neurons for each layer of a completely associated deep neural network to tackle the streamlining issue. The probability of detection is considered as the determining parameter to find the efficiency of the proposed algorithm. Experiments are carried under different signal to noise ratio to indicate better performance of the proposed algorithm. The PU signal will have an associated modulation format and hence identifying the presence of a modulation format itself establishes the presence of PU signal."
흐름이 있는 문서에 적합한 비지도학습 추상 요약 방법,2021,"['NLP', 'Summarization', 'GAN', 'BERT', 'Transformer']",,"Recently, a breakthrough has been made in the NLP area by Transformer techniques based on encoder-decoder. However, this only can be used in mainstream languages where millions of dataset are well-equipped, such as English and Chinese, and there is a limitation that it cannot be used in non-mainstream languages where dataset are not established. In addition, there is a deflection problem that focuses on the beginning of the document in mechanical summarization. Therefore, these methods are not suitable for documents with flows such as fairy tales and novels. In this paper, we propose a hybrid summarization method that does not require a dataset and improves the deflection problem using GAN with two adaptive discriminators. We evaluate our model on the CNN/Daily Mail dataset to verify an objective validity. Also, we proved that the model has valid performance in Korean, one of the non-mainstream languages."
Design of e-commerce business model through AI price prediction of agricultural products,2021,"['Agricultural product price', 'AI prediction', 'e-Commerce', 'Prediction model', 'AI algorithm', '농산물 가격', 'AI 예측', '전자거래', '예측 모델', '인공지능 알고리즘']",,"For agricultural products, supply is irregular due to changes in meteorological conditions, and it has high price elasticity. For example, if the supply decreases by 10%, the price increases by 50%. Due to these fluctuations in the prices of agricultural products, the Korean government guarantees the safety of prices to producers through small merchants' auctions. However, when prices plummet due to overproduction, protection measures for producers are insufficient. Therefore, in this paper, we designed a business model that can be used in the electronic transaction system by predicting the price of agricultural products with an artificial intelligence algorithm. To this end, the trained model with the training pattern pairs and a predictive model was designed by applying ARIMA, SARIMA, RNN, and CNN. Finally, the agricultural product forecast price data was classified into short-term forecast and medium-term forecast and verified. As a result of verification, based on 2018 data, the actual price and predicted price showed an accuracy of 91.08%."
KI-HABS: Key Information Guided Hierarchical Abstractive Summarization,2021,"['neural network', 'deep learning', 'NLP', 'abstractive summarization', 'selective encoding']",,"With the unprecedented growth of textual information on the Internet, an efficient automatic summarization system has become an urgent need. Recently, the neural network models based on the encoder-decoder with an attention mechanism have demonstrated powerful capabilities in the sentence summarization task. However, for paragraphs or longer document summarization, these models fail to mine the core information in the input text, which leads to information loss and repetitions. In this paper, we propose an abstractive document summarization method by applying guidance signals of key sentences to the encoder based on the hierarchical encoder-decoder architecture, denoted as KI-HABS. Specifically, we first train an extractor to extract key sentences in the input document by the hierarchical bidirectional GRU. Then, we encode the key sentences to the key information representation in the sentence level. Finally, we adopt key information representation guided selective encoding strategies to filter source information, which establishes a connection between the key sentences and the document. We use the CNN/Daily Mail and Gigaword datasets to evaluate our model. The experimental results demonstrate that our method generates more informative and concise summaries, achieving better performance than the competitive models."
CAPS : CCTV 영상을 이용한 자율형 딥러닝 기반 아동학대 감지 시스템,2021,"['Child Abuse Protection System', 'Face Detection', 'Mosaic Generation', 'Deep Learning']",,"Though the mandatory policy of installing CCTV in the childhood care facilities of public institutions such as kindergarten and daycare center, the criminal of child abuse cases is gradually increasing due to the lack of awareness of violent acts and the difficulty in understanding the reporting processes. This paper proposes a novel Child Abuse Protection System (CAPS) to solve the above social problem. The proposed CAPS is composed of three functional software modules to implement a deep-learning-based system that autonomously detects violent acts against children. First, the clip creator module divides long CCTV videos into several pieces of short video clips. Second, the violence detector module classifies the abuse behaviors from the generated clips. Finally, the face detector module automatically processes the witnessed suspect’s face being blurred out by mosaic. Experimental evaluation results show that the most suitable feature extractor for detecting the child abuse behaviors is the MobileNetV2+LSTM model among several candidates of the proposed CNN+LSTM violence detection module, which has the best at 92.51% accuracy. Furthermore, the recall rate can be increased up to 6% by exploiting the proposed data augmentation technique. Codes are available at https://github.com/learningsteady0J0/ CAPS-Child-Abuse-Protection-System."
Real-time Safety Monitoring Vision System for Linemen in Buckets Using Spatio-temporal Inference,2021,"['Gaussian mixture model', 'linemen safety monitoring', 'object detection', 'pose inference.']",,"Linemen risk falls, electric shocks, burns, and other injuries during the daily job and these incidents canoften be fatal. In this paper, we present a novel vision-based real-time system for detection and tracking of variousnon-rigid safety wearables worn by linemen, in a highly cluttered environment. We set up four imaging sensors onthe repair truck’s bucket to robustly monitor the linemen from four different viewpoints. In the monitoring system,we firstly apply a novel fast background segmentation method to suppress false positives and reduce search space.Next, we represent each safety wearable with a Gaussian mixture model and track them with an LK-tracker. Inorder to track occluded or out-of-camera-view safety wearables, we propose a novel human pose inference method.The proposed method is an extension from the existing CNN-based human pose inference by utilizing light-weightcolor, shape, and space-based human pose inference mechanism. The proposed human pose inference method showsimproved performance in terms of precision, recall, and speed. Experimental results on a number of challengingsequences demonstrate the effectiveness of the proposed scheme, under complex background, prolonged occlusions,and varying color, shape, and lighting."
Model Inversion Attack: Analysis under Gray-box Scenario on Deep Learning based Face Recognition System,2021,"['Model Inversion Attack', 'Deep Learning', 'Face Recognition System', 'Media Clone']",,"In a wide range of ML applications, the training data contains privacy-sensitive information that should be kept secure. Training the ML systems by privacy-sensitive data makes the ML model inherent to the data. As the structure of the model has been fine-tuned by training data, the model can be abused for accessing the data by the estimation in a reverse process called model inversion attack (MIA). Although, MIA has been applied to shallow neural network models of recognizers in literature and its threat in privacy violation has been approved, in the case of a deep learning (DL) model, its efficiency was under question. It was due to the complexity of a DL model structure, big number of DL model parameters, the huge size of training data, big number of registered users to a DL model and thereof big number of class labels. This research work first analyses the possibility of MIA on a deep learning model of a recognition system, namely a face recognizer. Second, despite the conventional MIA under the white box scenario of having partial access to the users' non-sensitive information in addition to the model structure, the MIA is implemented on a deep face recognition system by just having the model structure and parameters but not any user information. In this aspect, it is under a semi-white box scenario or in other words a gray-box scenario. The experimental results in targeting five registered users of a CNN-based face recognition system approve the possibility of regeneration of users' face images even for a deep model by MIA under a gray box scenario. Although, for some images the evaluation recognition score is low and the generated images are not easily recognizable, but for some other images the score is high and facial features of the targeted identities are observable. The objective and subjective evaluations demonstrate that privacy cyber-attack by MIA on a deep recognition system not only is feasible but also is a serious threat with increasing alert state in the future as there is considerable potential for integration more advanced ML techniques to MIA."
"전산화 단층 촬영(Computed tomography, CT) 이미지에 대한 EfficientNet 기반 두개내출혈 진단 및 가시화 모델 개발",2021,"['Deep-learning', 'EfficientNet', 'Intracranial hemorrhage', 'Computed tomography images']",,"Intracranial hemorrhage (ICH) refers to acute bleeding inside the intracranial vault. Not only does this devastating disease record a very high mortality rate, but it can also cause serious chronic impairment of sensory, motor, and cognitive functions. Therefore, a prompt and professional diagnosis of the disease is highly critical. Noninvasive brain imaging data are essential for clinicians to efficiently diagnose the locus of brain lesion, volume of bleeding, and subsequent cortical damage, and to take clinical interventions. In particular, computed tomography (CT) images are used most often for the diagnosis of ICH. In order to diagnose ICH through CT images, not only medical specialists with a sufficient number of diagnosis experiences are required, but even when this condition is met, there are many cases where bleeding cannot be successfully detected due to factors such as low signal ratio and artifacts of the image itself. In addition, discrepancies between interpretations or even misinterpretations might exist causing critical clinical consequences. To resolve these clinical problems, we developed a diagnostic model predicting intracranial bleeding and its subtypes (intraparenchymal, intraventricular, subarachnoid, subdural, and epidural) by applying deep learning algorithms to CT images. We also constructed a visualization tool highlighting important regions in a CT image for predicting ICH. Specifically, 1) 27,758 CT brain images from RSNA were pre-processed to minimize the computational load. 2) Three different CNN-based models (ResNet, EfficientNet-B2, and EfficientNet-B7) were trained based on a training image data set. 3) Diagnosis performance of each of the three models was evaluated based on an independent test image data set: As a result of the model comparison, EfficientNet-B7's performance (classification accuracy = 91%) was a way greater than the other models. 4) Finally, based on the result of EfficientNet-B7, we visualized the lesions of internal bleeding using the Grad-CAM. Our research suggests that artificial intelligence-based diagnostic systems can help diagnose and treat brain diseases resolving various problems in clinical situations."
영흥 풍력발전단지의 풍력발전량 예측을 위한 입력변수 선정 및 인공신경망과 1차원 합성곱 신경망 비교,2021,"['Artificial Neural Networks', 'Artificial Intelligence', 'Convolutional Neural Networks', 'Machine Learning', 'Wind Power', '인공신경망', '인공지능', '기계학습', '합성곱신경망', '풍력에너지']","목적 : 본 연구에선 비선형적 풍력발전량 예측 모델 개발을 목적으로 총 설치 용량 46 MW의 풍력발전단지가 설치된 영흥 풍력발전 단지의 자료를 이용하여 인공신경망(artificial neural network, ANN)과 1차원 합성곱신경망(1-dimension convolutional neural network, 1D-CNN)의 성능을 비교하고자 하였다.방법 : 자료는 46 MW 발전능력을 가진 영흥 풍력발전단지의 2018년 1월부터 12월의 1시간 단위 풍력발전량 자료와 기상청에서 얻은 기상자료를 이용하였다. 최적 입력변수를 선정을 위하여 문헌연구를 바탕으로 시행착오를 거쳐 인자를 선정하였다. 전처리 과정을 거친 17,306개의 자료의 80%를 학습(training), 20%를 테스트(test)으로 사용하였으며, 학습 자료의 20%를 검증(validation)자료로 구성하였다. 모델 내 활성화 함수로는 rectified linear unit를 사용하였으며, 시행착오법을 통해 하이퍼파라미터(hyperparameter)의 최적값을 도출하였다. 모든 모델은 Python의 Keras 라이브러리를 이용하여 설계하였으며, 성능지표인 결정계수(coefficient of determination, R²), 평균제곱근오차(root mean square error, RMSE), 평균절대오차(mean absolute error, MAE) 등은 Scikit-learn 라이브러리에서 이용하였다.결과 및 토의 : 최적 입력변수는 풍속, 풍향, 온도, 습도 등이었다. ANN의 최적점으로는 은닉층 8층, 은닉층별 노드수는 모두 100으로 나왔다. 최적 ANN 모델에서 성능지표는 R²=0.848, MAE=1.054, RMSE=1.616이었다. 1D-CNN 의 최적점으로는 합성곱층 4층, 층별 필터 수는 1층부터 64, 128, 64, 32개, 전결합층 1층에 노드 100개이다. 최적 1D-CNN 모델의 성능지표는 R²=0.875, MAE=0.982, RMSE=1.583였다. 1D-CNN이 ANN보다 R²는 높고, MAE와 RMSE는 낮았다. ANN, 1D-CNN의 결정계수가 모두 0.8 이상으로 예측 성능이 우수하나, 1D-CNN이 ANN보다 모든 성능지표에서 높았다.결론 : 최적화된 모델의 성능지표 비교 결과 1D-CNN이 ANN보다 높은 성능을 보여 영흥 풍력 발전소 발전량 예측에 적합할 것으로 보인다. 최적 입력변수는 풍속, 풍향, 온도, 습도였다.","Objectives : In this study, deep learning models of artificial neural network (ANN) and one-dimension convolutional neural networks (1D-CNN) were compared to predict nonlinear wind power generation at Yeongheung wind power plant.Methods : The study site was Yeongheung-do, which has a 46 MW wind power plant. Hourly wind power and meteorological data from January to December 2018 were collected. After pre-processing with standardscaler, the training data were 64%, the validation data were 16%, and the test data were 20%. The optimum input variables of the model were selected using literature, and trial and error method. Rectified linear unit was used as the activation function. Hyperparameters were adjusted by trial and error method to optimized models. To compare the optimized models, the coefficient of determination (R²), mean absolute error (MAE), and root mean square error (RMSE) were used as the performance efficiency. Both ANN, and 1D-CNN were imported from the Keras library, and all of the performance efficiency was imported from the Scikit-learn library.Results and Discussion : The optimized input variables in this study were wind speed, wind direction, temperature, and humidity. The optimized ANN performance was R²=0.848, MAE=1.054, and RMSE=1.616, and the hyperparameters were 8 hidden layers with 100 nodes in each layer. The optimized 1D-CNN (R²=0.875, MAE=0.982, and RMSE=1.583) had 4 convolutional layers and the number of filters were 64, 128, 64, and 32 in order from the first layer, and one hidden fully connected layer had 100 nodes. The 1D-CNN had higher R², and lower MAE and RMSE than the ANN. Therefore, the 1D-CNN was selected as the optimized model to predict wind generation of the Yeongheung wind power plant.Conclusions : The optimized 1D-CNN model in this study was more effective in predicting the Yeongheung wind power plant than the ANN. The optimal input variables were wind speed, wind direction, temperature, and humidity."
인공 위성 사진 내 선박 탐지 정확도 향상을 위한 Watershed 알고리즘 기반 RoI 축소 기법,2021,"['Coastline Extraction', 'Satellite Image', 'R-CNN', 'Watershed Algorithm', '해안선 추출', '인공위성 사진', 'R-CNN', 'Watershed 알고리즘']",,"Research has been ongoing to detect ships from offshore photographs for a variety of reasons, including maritime security, identifying international trends, and social scientific research. Due to the development of artificial intelligence, R-CNN models for object detection in photographs and images have emerged, and the performance of object detection has risen dramatically. Ship detection in offshore photographs using the R-CNN model has also begun to apply to satellite photography. However, satellite images project large areas, so various objects such as vehicles, landforms, and buildings are sometimes recognized as ships. In this paper, we propose a novel methodology to improve the performance of ship detection in satellite photographs using R-CNN series models. We separate land and sea via marker-based watershed algorithm and perform morphology operations to specify RoI one more time, then detect vessels using R-CNN family models on specific RoI to reduce typology. Using this method, we could reduce the misdetection rate by 80% compared to using only the Fast R-CNN."
치과용 파노라마방사선사진에서 AlexNet의 골다공증 판정,2021,"['Osteoporosis', 'Panoramic Radiograph', 'Mandible', 'Neural network']",,"This study was performed as a part of serial experiments of applying convolutional neural network(CNN) in determining osteoporosis on panoramic radiograph. The purpose of this study was to investigate how sensitively CNN determine osteoporosis on cropped panoramic radiograph. Panoramic radiographs from 1268 female patients(mean age 45.2 ± 21.1 yrs) were selected for this study. For the osteoporosis group, 633(mean age 72.2 ± 8.5 yrs) were selected, while for the normal group 635(mean age 28.3 ± 7.0 yrs). AlexNet was utilized as CNN in this study. A multiple-column CNN was designed with two rectangular regions of interest on the mandible inferior area. An occluding method was used to analyze the sensitive area in determining osteoporosis on AlexNet. Testing of AlexNet showed accuracy of 99% in determining osteoporosis on panoramic radiographs. AlexNet was sensitive at the area of cortical and cancellous bone of the mandible inferior area including adjacent soft tissue."
Few-Shot Learning을 사용한 호스트 기반 침입 탐지 모델,2021,"['Machine Learning', 'LID-DS', 'Few-Shot Learning', 'Siamese Network', 'HIDS', '기계학습', '퓨샷 러닝', '샴 네트워크', '호스트 기반 침입 탐지 시스템']",,"As the current cyber attacks become more intelligent, the existing Intrusion Detection System is difficult for detecting intelligent attacks that deviate from the existing stored patterns. In an attempt to solve this, a model of a deep learning-based intrusion detection system that analyzes the pattern of intelligent attacks through data learning has emerged. Intrusion detection systems are divided into host-based and network-based depending on the installation location. Unlike network-based intrusion detection systems, host-based intrusion detection systems have the disadvantage of having to observe the inside and outside of the system as a whole. However, it has the advantage of being able to detect intrusions that cannot be detected by a network-based intrusion detection system. Therefore, in this study, we conducted a study on a host-based intrusion detection system. In order to evaluate and improve the performance of the host-based intrusion detection system model, we used the host-based Leipzig Intrusion Detection-Data Set (LID-DS) published in 2018. In the performance evaluation of the model using that data set, in order to confirm the similarity of each data and reconstructed to identify whether it is normal data or abnormal data, 1D vector data is converted to 3D image data. Also, the deep learning model has the drawback of having to re-learn every time a new cyber attack method is seen. In other words, it is not efficient because it takes a long time to learn a large amount of data. To solve this problem, this paper proposes the Siamese Convolutional Neural Network (Siamese-CNN) to use the Few-Shot Learning method that shows excellent performance by learning the little amount of data. Siamese-CNN determines whether the attacks are of the same type by the similarity score of each sample of cyber attacks converted into images. The accuracy was calculated using Few-Shot Learning technique, and the performance of Vanilla Convolutional Neural Network (Vanilla-CNN) and Siamese-CNN was compared to confirm the performance of Siamese-CNN. As a result of measuring Accuracy, Precision, Recall and F1-Score index, it was confirmed that the recall of the Siamese-CNN model proposed in this study was increased by about 6% from the Vanilla-CNN model."
인공지능을 이용한 UAV 영상 건물 경계선 추출 가능성 연구,2021,"['지적', '공간정보', '인공지능', 'Mask R-CNN', '건물경계', 'Cadastral', 'Geospatial Information', 'Artificial Intelligence', 'Mask R-CNN', 'Building Boundary']","UAV는 저비용･고효율로 측량 및 지적 등 공간정보 분야에서 이미 많은 적용과 활용이 이루어지고 있다. 인공지능 기술 역시 기술의 발전에 따른 빠른 연산속도와 수행능력으로 다양한 분야에서 활용하고 있다. R-CNN은 영상분류 분야의 대표적인 인공지능 모델이다. 본 연구에서는 인공지능을 적용하여 UAV 영상의 건물 경계선 추출 가능성을 분석･제시하고자 하였다. 이를 위해 UAV의 영상의 건물 경계선을 분류하고, 이를 Mask R-CNN에 적용하여 산출한 결과 값과 UAV의 원시 영상과 비교 하였다. 비교결과, 건물 경계선은 전반적으로 추출이 가능하나 정확도는 지역별로 편차가 있는 것으로 나타났다. 정확도가 낮은 건물의 경우는 대상 건물과 주변 영역이 명확히 인식되지 못하는 데에서 발생한 것으로 분석되었다. 향후 하드웨어의 발전과 많은 학습데이터가 축적 된다면 공간정보를 비롯한 지적 분야에서도 적용이 가능할 것으로 판단된다.","UAV are already being applied and utilized in geospatial information fields such as surveying and cadastral due to their low cost and high efficiency. Artificial intelligence technology is also being used in various fields due to its fast computational speed and performance capability according to the development of technology. R-CNN is a representative artificial intelligence model in the field of image classification. In this study, we tried to analyze and present the possibility of extracting the boundary line of the UAV image by applying artificial intelligence. For this purpose, the building boundary of the UAV image was classified, and the calculated result value was applied to the Mask R-CNN and compared with the original image of the UAV. As a result of the comparison, it was found that the boundary line of the building can be extracted as a whole, but the accuracy varies by region. In the case of a building with low accuracy, it was analyzed that it occurred because the target building and the surrounding area were not clearly recognized. If hardware advances and a lot of learning data is accumulated in the future, it is considered that it can be applied to cadastral fields including spatial information."
합성곱 신경망을 사용한 하천 수질예측 정확도 평가,2021,"['Convolutional neural network', 'Prediction accuracy', 'River water quality', 'Deep learning architecture', 'Univariate data', 'Multivariate data']",,"The present study assessed the applicability of convolutional neural network (CNN), which showed superior performance for classification, segmentation, and natural language processing, to river water quality prediction. Monthly data was compiled from upstream and downstream water quality monitoring stations in the Hwang River over the period of January 2007 through December 2020, from which training and test sets were constructed in the ratio of 70:30. The performance of CNN consisting of single and multiple layers were evaluated separately using univariate data with single dependent variable (i.e., either chemical oxygen demand (COD) or chlorophyll-a (Chl-a) as well as multivariate data with dependent and 9 independent variables. The results showed that the prediction accuracy of the proposed CNN algorithm tested with univariate data was noticeably higher for COD than for Chl-a (in terms of target variable) as well as for multiple layers than for single layer (with respect to model architecture). In addition, the CNN algorithm evaluated with multivariate data achieved had better prediction performance than that of univariate data although its performance varied widely among data sets, and to a less extent, among stations and target variables. No measurable difference was also found in prediction performance of the CNN algorithm (for two target dependent variables) according to the number of (important) independent variables. All these results demonstrate that while the proposed CNN algorithm can be adopted to predict (monthly) water quality variables, its careful architecture design is yet required to achieve substantial performance improvement."
Respiratory-correlated 4D digital tomosynthesis with deep convolutional neural networks for image-guided radiation therapy,2021,['4D digital tomosynthesis · Convolutional neural network · Quantitative accuracy · Spatial resolution · Image noise'],,"4D digital tomosynthesis (DTS) techniques for image-guided radiation therapy (IGRT) are able to reduce radiation dose, scan and reconstruction time compared to 4D cone-beam computed tomography (CBCT). In spite of these benefits, the 4D DTS techniques cause the degradation of image quality due to an intrinsic imaging strategy and consequently reduce treatment accuracy. In this study, a deep learning-based convolutional neural network (CNN) framework was proposed for 4D DTS imaging. The proposed CNN framework consisted of the data restoration network based on a U-Net and the denoising network combined with a 2D wavelet transform, and the network training was implemented with clinical images. The quality of the 4D DTS images obtained from the proposed model was evaluated in terms of quantitative accuracy, spatial resolution and noise property. The results showed that the proposed CNN framework improved the quantitative accuracy of 4D DTS images by 3–19%, and the spatial resolution and noise for the proposed CNN framework were reduced by 2.24–7.33% and 8.92–40.07%, respectively, in comparison to other imaging models. These results represented that the degradation of the 4D DTS image quality can be recovered using the proposed CNN framework, and the proposed model is suitable for maintaining spatial resolution as well as suppressing noise and artifacts. In conclusion, the proposed CNN framework can be potentially used to improve the quality of 4D DTS images for the IGRT."
클라우드 플랫폼을 이용한 딥러닝 기반 장애인 주차구역 관리 시스템 구현,2021,"['Cloud platform', 'YOLO', 'CNN', 'Raspberry pi', 'Android phone', 'Deep learning']","본 연구는 딥러닝과 클라우드 플랫폼을 이용하여 장애인 복지 증진을 위한 장애인 주차 공간을 관리하는 시스템을 제안하였다. 딥러닝은 주차 영역의 자동차 영상에서 번호판 검출을 위하여 YOLO (you only look once)를 사용하였으며, 추출된 숫자 및 문자 영상에서 번호판 문자 인식을 위하여 CNN (convolutional neural network)을 사용하였다. 본 시스템은 실시간 관리가 가능하고, 동영상만으로 관리할 수 있도록 간소화하였다. 또한 기존 OCR (optical character recognition)보다 한글 문자 인식률을 높임으로서 안정성 및 정확성이 있으며, CCTV (closed circuit television)만 설치하면 주차관리가 가능하도록 함으로서 관리 영역의 확장성의 특장점을 가진다. 본 시스템은 기징 중요한 요소인 정확한 번호판 인식률을 높이는 연구와 다소 성능이 낮은 라즈베리 파이 환경에서 YOLO와 CNN 알고리즘 등을 실행하기 위한 처리속도 문재에 대한 지속적 연구가 필요하다.","This study proposed a system that manages parking spaces for the disabled, this will lead to the promotion of welfare for those who are disabled by using deep learning and cloud platforms. Deep learning used you only look once (YOLO) for license plate detection concerning car images in parking areas, and convolutional neural network (CNN) was used for license plate character recognition from extracted numbers and text images. This system can be managed in real time, and it has been simplified so that it can be managed only with video. In addition, it is recognized and accurate by increasing the recognition rate of Korean characters compared to the existing optical character recognition (OCR), and it has the advantage of scalability in the management area by enabling parking management but only if closed circuit television (CCTV) is installed. This system requires a study to increase the accurate license plate recognition rate. This is an important factor, and a continuous study on the processing speed problem to execute YOLO and CNN algorithms in a somewhat low performance raspberry environment."
이산화 전처리 방식 및 컨볼루션 신경망을 활용한 네트워크 침입 탐지에 대한 연구,2021,"['NSL-KDD', '네트워크 이상 탐지', 'CNN', '연속형 변수 이산형화', 'Network Intrusion Detection', 'Discretization of Continuous']","새롭게 발생되는 사이버 공격으로 인해 개인, 민간 및 기업의 피해가 증가함에 따라, 이에 기반이 되는 네트워크 보안 문제는 컴퓨터 시스템의 주요 문제로 부각되었다. 이에 기존에 사용되는 네트워크 침입 탐지 시스템(Network Intrusion Detection System: NIDS)에서 발생되는 한계점을 개선하고자 기계 학습과 딥러닝을 활용한 연구 이뤄지고 있다. 이에 본 연구에서는 CNN(Convolution Neural Network) 알고리즘을 이용한 NIDS 모델 연구를 진행한다. 이미지 분류 기반의 CNN 알고리즘 학습을 위해 기존 사용되는 전처리 단계에서 연속성 변수 이산화(Discretization of Continuous) 알고리즘을 추가하여 예측 변수에 대해 선형 관계로 표현하여 해석에 용이한 데이터로 변환 후, 정사각형 행렬(Square Matrix) 구조에 매칭된 픽셀(Pixel) 이미지 구조를 모델에 학습한다. 모델의 성능 평가를 위해 네트워크 패킷 데이터인 NSL-KDD를 사용하였으며, 정확도(Accuracy), 정밀도(Precision), 재현율(Recall) 및 조화평균(F1-score)을 성능 지표로 사용하였다. 실험 결과 제안된 모델에서 85%의 정확도로 가장 높은 성능을 보였으며, 학습 표본이 적은 R2L 클래스의 조화평균이 71% 성능으로 다른 모델에 비해서 매우 좋은 성능을 보였다.","As damages to individuals, private sectors, and businesses increase due to newly occurring cyber attacks, the underlying network security problem has emerged as a major problem in computer systems. Therefore, NIDS using machine learning and deep learning is being studied to improve the limitations that occur in the existing Network Intrusion Detection System. In this study, a deep learning-based NIDS model study is conducted using the Convolution Neural Network (CNN) algorithm. For the image classification-based CNN algorithm learning, a discrete algorithm for continuity variables was added in the preprocessing stage used previously, and the predicted variables were expressed in a linear relationship and converted into easy-to-interpret data. Finally, the network packet processed through the above process is mapped to a square matrix structure and converted into a pixel image. For the performance evaluation of the proposed model, NSL-KDD, a representative network packet data, was used, and accuracy, precision, recall, and f1-score were used as performance indicators. As a result of the experiment, the proposed model showed the highest performance with an accuracy of 85%, and the harmonic mean (F1-Score) of the R2L class with a small number of training samples was 71%, showing very good performance compared to other models."
영상장비와 딥러닝을 이용한 고속도로 터널 균열 탐지 시스템 개발,2021,"['Tunnel crack detection', 'Deep learning', 'Cascade mask R-CNN', 'Negative sample training', '터널 균열 탐지', '딥러닝', 'Cascade Mask R-CNN', '비균열 학습']","빠르게 증가하는 노후 터널을 효율적으로 관리하기 위하여 최근 영상장비를 이용한 점검 방법론들이 많이 제안되고 있다. 하지만 기존의 방법론들은 대부분 국한된 영역에서 검증을 수행하였을 뿐 아니라, 다른 물체들이 존재하지 않는 깨끗한 콘크리트 표면에서 검증되어 실제 현장에 대한 적용성을 검증하기 어려웠다. 따라서 본 논문에서는 이러한 한계를 극복하기 위하여 비균열 물체 학습에 기반한 6단계 터널 균열 탐지 딥러닝 모델 개발 프레임워크를 제안한다. 제안된 프레임워크는 터널에서 취득된 이미지 내 균열 탐색, 픽셀 단위 균열 라벨링, 딥러닝 모델 학습, 비균열 물체 수집, 비균열 물체 재학습, 최종 학습 데이터 구축의 총 6단계로 이루어진다. 제안된 프레임워크를 이용하여 개발된 균열 탐지 딥러닝 모델 개발을 수행하였으며, 일반 균열 1561장, 비균열 206장으로 개별 물체 세분화(Instance Segmentation) 모델인 Cascade Mask R-CNN을 학습시켰다. 학습된 모델의 현장 적용성을 검토하기 위하여 전선, 전등 등을 포함하는 약 200m 길이의 실제 터널에서 균열 탐지를 수행하였다. 실험 결과 학습된 모델은 99% 정밀도와 92%의 재현율을 나타내며 뛰어난 현장 적용성을 나타내었다.","In order to efficiently inspect rapidly increasing old tunnels in many well-developed countries, many inspection methodologies have been proposed using imaging equipment and image processing. However, most of the existing methodologies evaluated their performance on a clean concrete surface with a limited area where other objects do not exist. Therefore, this paper proposes a 6-step framework for tunnel crack detection deep learning model development. The proposed method is mainly based on negative sample (non-crack object) training and Cascade Mask R-CNN. The proposed framework consists of six steps: searching for cracks in images captured from real tunnels, labeling cracks in pixel level, training a deep learning model, collecting non-crack objects, retraining the deep learning model with the collected non-crack objects, and constructing final training dataset. To implement the proposed framework, Cascade Mask R-CNN, an instance segmentation model, was trained with 1561 general crack images and 206 non-crack images. In order to examine the applicability of the trained model to the real-world tunnel crack detection, field testing is conducted on tunnel spans with a length of about 200m where electric wires and lights are prevalent. In the experimental result, the trained model showed 99% precision and 92% recall, which shows the excellent field applicability of the proposed framework."
비디오 감시에서 심층 컨볼루션 신경망을 사용한 폭력 활동 감지,2021,"['딥러닝', '감시 카메라', '비정상적인 활동', '컨볼루션 뉴럴 네트워크', 'Deep learning', 'surveillance cameras', 'abnormal activity', 'convolutional neural network']","최근에는 전세계적으로 범죄 예방을 위한 감시 시스템이 설치되어 방대한 양의 비디오 데이터를 생성하는 개인 및 공공장소를 모두 모니터링하고 있다. 이 설정에서 전문가가 진행 중인 활동을 지속적으로 관찰하고 모니터링해야 한 다. 이 지루한 작업을 처리하기 위해 실시간으로 실행 가능한 폭력 활동 감지(VAD) 기술이 큰 과제이다. 따라서 본 논문에서는 실시간 VAD을 위한 3단계 딥러닝 지원 프레임워크를 제안한다. 첫번째 단계에서는 프레임 차이 알고리즘을 통해 비디오 데이터에서 가장 중요한 모션 프레임을 획득하기 위한 사전 처리 단계를 적용한다. 이러한 프 레임은 경량 컨볼루션 신경 네트워크(CNN)가 가장 차별적인 특징을 추출하는 두 번째 단계로 제공된다. 마지막으 로 CNN 모델은 활동을 폭력적인 장면과 비폭력적인 장면으로 분류한다. 폭력적인 행위가 발생할 경우, 가장 가까 운 보안 부서와 경찰서에 신고하여 신속한 조치를 취하도록 한다. 제안된 방법은 공개적으로 사용 가능한 데이터 세 트에서 96%의 정확도를 달성하고 최신 방법보다 성능이 우수하다.","Recently, surveillance systems are globally installed for crime prevention by monitoring both private and public places which generate a massive amount of video data. This setup requires human experts to observe and monitor the ongoing activities continuously. To handle this tedious task, an automatic technique workable in real-time for violent activity detection (VAD) is a big challenge. Thus, this paper proposes a three-phase deep learning assisted framework for real-time VAD. In the first phase, a preprocessing step is applied to obtain the salient motion frames from the video data through frame differencing algorithm. These frames are fed into the second phase where a lightweight convolutional neural network (CNN) extracts the most discriminative features. Finally, a CNN model classifies the activity into violent and non-violent scene. In case of violent activity, the activity is reported to notify the nearest security departments and police stations for the prompt action. The proposed method achieves 96% accuracy on the publicly available dataset and outperforms over state-of-the-art methods."
Deep Convolutional Neural Network Architectures for Tonal Frequency Identification in a Lofargram,2021,"['Convolutional neural networks', 'lofar analysis', 'sonar analysis', 'underwater recognition.']",,"Advances in convolutional neural networks (CNNs) have driven the development of computer vision. Recent CNN architectures, such as those with skip residual connections (ResNets) or densely connected architectures (DenseNets), have facilitated backpropagation and improved the performance of feature extraction and classification. Detecting objects in underwater environments by analyzing sound navigation and ranging (sonar) signals is considered an important process that should be automated. Several previous approaches have addressed this challenge; however, there has been no in-depth study of CNN architectures that effectively analyze sonar grams. In this paper, we have presented the identification of tonal frequencies in lofargrams using recent CNN architectures. Our study includes 175 CNN models that are derived from five different CNN architectures and 35 different input patch sizes. The study results showed that the accuracy of the best model was as high as 96.2% for precision and 99.5% for recall, with an inference time of 0.184 s."
VGG-16 딥러닝 알고리즘을 활용한 우식치아와 건전치아 분류,2021,"['CNN', 'Convolutional neural network', 'Deep learning', 'Dental caries classification', 'VGG-16']",,"Objectives: Diagnosis of dental caries is based on the dentist’s observation and subjective judgment; therefore, a reliable and objective approach for diagnosing caries is required. Intraoral camera images combined with deep learning technology can be a useful tool to diagnose caries. This study aimed to evaluate the accuracy of the VGG-16 convolutional neural network (CNN) model in detecting dental caries in intraoral camera images.Methods: Images were obtained from the Internet and websites using keywords linked to teeth and dental caries. The 670 images that were obtained were categorized by an investigator as either sound (404 sound teeth) or dental caries (266 dental caries), and used in this study. The training and test datasets were divided in the ratio of 7:3 and a four-fold cross validation was performed. The Tensorflow-based Python package Keras was used to train and validate the CNN model. Accuracy, Kappa value, sensitivity, specificity, positive predictive value, negative predictive value, ROC (receiver operating characteristic) curve and AUC (area under curve) values were calculated for the test datasets.Results: The accuracy of the VGG-16 deep learning model for the four datasets, through random sampling, was between 0.77 and 0.81, with 0.81 being the highest. The Kappa value was 0.51- 0.60, indicating moderate agreement. The resulting positive predictive values were 0.77-0.82 and negative predictive values were 0.80-0.85. Sensitivity, specificity, and AUC values were 0.66-0.74, 0.81-0.88, and 0.88-0.91, respectively.Conclusions: The VGG-16 CNN model showed good discriminatory performance in detecting dental caries in intraoral camera images. The deep learning model can be beneficial in monitoring dental caries in the population."
인공지능 기반 위 병변 검출 알고리즘 개발,2021,"['Gastric Endoscopy', 'CNN', 'R-CNN Model', '위 내시경', '합성곱 신경망', '영역기반 합성곱 신경망 모델']","위암은 1999년 이후 우리나라에서 가장 많이 발생하는 암으로 1위를 차지하고 있다. 위암은 내시경 검사를 통해 일차적으로 판단되고 조직검사를 통해 정확히 진단되기 전까지는 특징적인 증상이 없으며, 실제로 위 내시경 검사를 받은 환자는 받지 않은 환자에 비해 생존율이 2.24배 높다는 연구 결과가 발표된 바 있다. 이러한 문제를 해결하기 위하여 본 논문은 위암 환자의 위 내시경 시행 시 임상의에게 실시간으로 보조적인 정보를 제공해 주고자 제안되었다. 본 논문에서는 Faster R-CNN을 위 병변 검출에 적합한 모델로 개선하여 보다 빠르고 정확한 검출 결과를 임상의에게 제공하는 방법을 제안한다. 기존 알고리즘과의 비교 평가 결과 평균 91%의 정확도를 도출하여 제안 방법이 보다 효과적임을 증명하였으며, 영상 처리 속도 또한 0.1sec/frame을 도출하여 실시간 처리에 적합함을 증명하였다. 향후 연구로 다양한 환경에서의 내시경 영상 수집을 통한 학습 데이터의 개선을 통해 정확도를 개선하고자 한다.","Gastric cancer is the most common cancer and has been the number one incidence since 1999 in Korea. Gastric cancer is primarily judged through endoscopy and has no characteristic symptoms until accurately diagnosed through biopsy then In fact, a study found that patients who underwent gastroscopy had a 2.24 times higher survival rate than those who did not. to solve these problems, This paper was proposed to provide real-time ancillary information to clinicians when performing gastroscopy for gastric cancer patients. In this paper, we propose a method to provide faster and more accurate detection results to clinicians by improving Faster R-CNN as a model suitable for gastric lesion detection. As a result of comparative evaluation with existing algorithms, an average accuracy of 91% was derived, proving that the proposed method is more effective. and, The image processing speed was also proven to be suitable for real-time processing by deriving 0.1sec/frame. As a future study, we intend to improve the accuracy by improving the learning data through the collection of endoscopic images in various environments."
딥러닝을 이용한 벼 도복 면적 추정,2021,"['area estimation', 'cnn', 'deep learning', 'lodging', 'machine learning', 'rice']",,"Rice lodging is an annual occurrence caused by typhoons accompanied by strong winds and strong rainfall, resulting in damage relating to pre-harvest sprouting during the ripening period. Thus, rapid estimations of the area of lodged rice are necessary to enable timely responses to damage. To this end, we obtained images related to rice lodging using a drone in Gimje, Buan, and Gunsan, which were converted to 128 × 128 pixels images. A convolutional neural network (CNN) model, a deep learning model based on these images, was used to predict rice lodging, which was classified into two types (lodging and non-lodging), and the images were divided in a 8:2 ratio into a training set and a validation set. The CNN model was layered and trained using three optimizers (Adam, Rmsprop, and SGD). The area of rice lodging was evaluated for the three fields using the obtained data, with the exception of the training set and validation set. The images were combined to give composites images of the entire fields using Metashape, and these images were divided into 128 × 128 pixels. Lodging in the divided images was predicted using the trained CNN model, and the extent of lodging was calculated by multiplying the ratio of the total number of field images by the number of lodging images by the area of the entire field. The results for the training and validation sets showed that accuracy increased with a progression in learning and eventually reached a level greater than 0.919. The results obtained for each of the three fields showed high accuracy with respect to all optimizers, among which, Adam showed the highest accuracy (normalized root mean square error: 2.73%). On the basis of the findings of this study, it is anticipated that the area of lodged rice can be rapidly predicted using deep learning."
공연예술에서 광고포스터의 이미지 특성을 활용한 딥러닝 기반 관객예측,2021,"['공연예술', '흥행 예측', 'CNN', 'VGG-16', 'Inception-v3', 'ResNet50', 'Performing Arts', 'Box Office Prediction']","공연예술 기관에서의 공연에 대한 흥행 예측은 공연예술 산업 및 기관에서 매우 흥미롭고도 중요한 문제이다. 이를 위해 출연진, 공연장소, 가격 등 정형화된 데이터를 활용한 전통적인 예측방법론, 데이터마이닝 방법론이 제시되어 왔다. 그런데 관객들은 공연안내 포스터에 의하여 관람 의도가 소구되는 경향이 있음에도 불구하고, 포스터 이미지 분석을 통한 흥행 예측은 거의 시도되지 않았다. 그러나 최근 이미지를 통해 판별하는 CNN 계열의 딥러닝 방법이 개발되면서 포스터 분석의 가능성이 열렸다. 이에 본 연구의 목적은 공연 관련 포스터 이미지를 통해 흥행을 예측할 수 있는 딥러닝 방법을 제안하는 것이다. 이를 위해 KOPIS 공연예술 통합전산망에 공개된 포스터 이미지를 학습데이터로 하여 Pure CNN, VGG-16, Inception-v3, ResNet50 등 딥러닝 알고리즘을 통해 예측을 수행하였다. 또한 공연 관련 정형데이터를 활용한 전통적 회귀분석 방법론과의 앙상블을 시도하였다. 그 결과 흥행 예측 정확도 85%를 상회하는 높은 판별 성과를 보였다. 본 연구는 공연예술 분야에서 이미지 정보를 활용하여 흥행을 예측하는 첫 시도이며 본 연구에서 제안한 방법은 연극 외에 영화, 기관 홍보, 기업 제품 광고 등 포스터 기반의 광고를 하는 영역으로도 적용이 가능할 것이다.","The prediction of box office performance in performing arts institutions is an important issue in the performing arts industry and institutions. For this, traditional prediction methodology and data mining methodology using standardized data such as cast members, performance venues, and ticket prices have been proposed. However, although it is evident that audiences tend to seek out their intentions by the performance guide poster, few attempts were made to predict box office performance by analyzing poster images. Hence, the purpose of this study is to propose a deep learning application method that can predict box office success through performance-related poster images. Prediction was performed using deep learning algorithms such as Pure CNN, VGG-16, Inception-v3, and ResNet50 using poster images published on the KOPIS as learning data set. In addition, an ensemble with traditional regression analysis methodology was also attempted. As a result, it showed high discrimination performance exceeding 85% of box office prediction accuracy. This study is the first attempt to predict box office success using image data in the performing arts field, and the method proposed in this study can be applied to the areas of poster-based advertisements such as institutional promotions and corporate product advertisements."
Reconstruction of Terrestrial Water Storage of GRACE/GFO Using Convolutional Neural Network and Climate Data,2021,"['GRACE', 'GRACE FO', 'CNN', 'TWS']",,"Gravity Recovery and Climate Experiment (GRACE) gravimeter satellites observed the Earth gravity field with unprecedented accuracy since 2002. After the termination of GRACE mission, GRACE Follow-on (GFO) satellites successively observe global gravity field, but there is missing period between GRACE and GFO about one year. Many previous studies estimated terrestrial water storage (TWS) changes using hydrological models, vertical displacements from global navigation satellite system observations, altimetry, and satellite laser ranging for a continuity of GRACE and GFO data. Recently, in order to predict TWS changes, various machine learning methods are developed such as artificial neural network and multi-linear regression. Previous studies used hydrological and climate data simultaneously as input data of the learning process. Further, they excluded linear trends in input data and GRACE/GFO data because the trend components obtained from GRACE/GFO data were assumed to be the same for other periods. However, hydrological models include high uncertainties, and observational period of GRACE/GFO is not long enough to estimate reliable TWS trends. In this study, we used convolutional neural networks (CNN) method incorporating only climate data set (temperature, evaporation, and precipitation) to predict TWS variations in the missing period of GRACE/GFO. We also make CNN model learn the linear trend of GRACE/GFO data. In most river basins considered in this study, our CNN model successfully predicts seasonal and long-term variations of TWS change."
Classification of Vocalization Recordings of Laying Hens and Cattle Using Convolutional Neural Network Models,2021,"['Mel-frequency cepstrum', 'Convolutional neural network (CNN)', 'Vocalization classification', 'Cattle', 'Laying hens']",,"Purpose Vocalizations of livestock convey information about the health and behavior of the animals, and vocal analysis could be a useful method to monitor livestock. We propose a deep learning classification of vocal recordings of laying hens and cattle with the aim of automatically classifying laying hen and cattle sounds in South Korea using a deep learning model.Methods Audio and video recordings of laying hens and cattle were acquired. We classified laying hens’ sounds into eight classes and cattle sounds into nine classes. Classified audio files were used for the development of convolutional neural network (CNN) models. Two types of CNN structures, one based on 2D ConVnet and the other based on a 1D model with long short-term memory, were developed and tested for modeling to classify the vocalizations of laying hens and cattle.Results The classification model based on 2D ConVnet performed better with a satisfactory classification accuracy of 75.78% for laying hens and 91.02% for cattle.Conclusion Based on the results for the developed CNN models, it is expected that real-time voice monitoring could be applicable for providing animal physiological information to growers."
ConvLSTM을 이용한 도로 구간 속도 예측 기법,2021,"['speed prediction', 'deep neural network', 'CNN', 'LSTM']",,"Predicting the speed of a road link, which means a specific segment of a road, is an important technology for location-based services like best route on the road. Recently, machine learning-based speed prediction methods including deep neural networks have been proposed. In particular, a speed prediction method using a convolution neural network (CNN) and a recurrent neural network (RNN) has been proposed. CNN can predict the speed by considering the spatial characteristics of the road, and RNN can predict the speed by considering the temporal characteristics of the speed change according to time of the road. In this paper, we propose a speed prediction method based on Convolutional LSTM (ConvLSTM) combining RNN and CNN that considers the properties of the neighboring links of the road link and the properties of the temporal road link together. In addition, the previously proposed LSTM-based speed prediction method is partially modified and implemented, and the performance of both is compared through experiments. Finally we shows the superiority of the proposed method compared to the existing proposed method."
MI 센서기반의 금속탐지용 뉴럴네트워크 성능비교에 관한연구,2021,"['합성곱신경망', '딥러닝', '전자기유도', '자기임피던스센서', '순환신경망', 'CNN', 'Deep Learning', 'Electromagnetic Induction', 'MI sensor', 'RNN']",,"This paper is a study on the efficiency of the filtering method of signal processing and the metal detection method using deep learning for data obtained from multiple MI sensors. The MI sensor is a principle that detects changes in magnetic field and is a passive sensor that detects metal objects. However, when detecting a metal object, the amount of change in the magnetic field caused by the metal is small, so there is a limit to the detectable distance. In order to effectively detect and analyze this, a method using deep learning was applied. In addition, the performance of the deep learning model was compared and analyzed using the filtering method of signal processing. In this paper, the detection performance of CNN and RNN networks was compared and analyzed from the data extracted from the self-impedance sensor. The RNN model showed higher performance than the CNN model. However, in the shallow stage, the CNN model showed higher performance than the RNN model."
Automatic modulation classification of noise‐like radar intrapulse signals using cascade classifier,2021,"['complex envelope', 'convolutional neural network', 'modulation classification', 'radar emitter identification']",,"Automatic modulation classification is essential in radar emitter identification. We propose a cascade classifier by combining a support vector machine (SVM) and convolutional neural network (CNN), considering that noise might be taken as radar signals. First, the SVM distinguishes noise signals by the main ridge slice feature of signals. Second, the complex envelope features of the predicted radar signals are extracted and placed into a designed CNN, where a modulation classification task is performed. Simulation results show that the SVM‐CNN can effectively distinguish radar signals from noise. The overall probability of successful recognition (PSR) of modulation is 98.52% at 20 dB and 82.27% at −2 dB with low computation costs. Furthermore, we found that the accuracy of intermediate frequency estimation significantly affects the PSR. This study shows the possibility of training a classifier using complex envelope features. What the proposed CNN has learned can be interpreted as an equivalent matched filter consisting of a series of small filters that can provide different responses determined by envelope features."
합성곱 오토인코더를 이용한 체인 전동 장치의 고장 결함 감지 및 진단,2021,"['Fault Detection(고장 검출)', 'Fault Diagnosis(고장 진단)', 'Deep Learning(딥러닝)', 'Convolutional Auto-encoder(합성곱 오토인코더)', 'Unsupervised Learning(비지도학습)', 'Convolutional Neural Network(합성곱 신경망)']",,"This paper presents a method to detect the mechanical faults of a chain drive power transmission system (CDPTS) using a convolutional auto-encoder (CAE). In previous research, it was known that the methods to detect faults of the CDPTS based on an artificial neural network (ANN) and convolutional neural network (CNN) were useful. In this paper, an advanced application of CNN, the CAE function of CNN is employed to detect faults. This method uses the characteristics of reconstruction of CAE. Difference of input images of the CNN and reconstructed images extracted by CAE were used as the guideline of fault detection. In the fault condition of the system, the difference was larger than the predetermined threshold of error. The encoder of CAE can be fine-tuned to classify the fault types of CDPTS. Finally, this method was well applied to diagnose the fault types of the test CDPTS installed in the laboratory."
자율주행 차량 영상 기반 객체 인식 인공지능 기술 현황,2021,"['객체 인식', '자율주행 차량', '영상 기반 인공지능', '단일 단계 검출', '두 단계 검출', 'Object detection', 'Autonomous vehicle', 'Image-based AI', 'Single-step detection', 'Two-step detection.']","객체 인식이란 하나의 특정 이미지를 입력했을 때, 주어진 이미지를 분석하여 특정한 객체(object)의 위치(location)와 종류(class)를 파악하는 것이다. 최근 객체 인식 기술이 적극적으로 접목되는 분야 중 하나는 자율주행 차량이라 할 수 있고, 본 논문에서는 자율주행 차량에서 영상 기반의 객체 인식 인공지능 기술에 대해 기술한다. 영상 기반 객체 검출 알고리즘은 최근 두 가지 방법(단일 단계 검출 방법 및 두 단계 검출 방법)으로 좁혀지고 있는데, 이를 중심으로 분석 정리하고자 한다. 두 가지 검출 방법의 장단점을 분석 제시하고, 단일 단계 검출 방법에 속하는 YOLO/SSD 알고리즘과 두 단계 검출 방법에 속하는 R-CNN/Faster R-CNN 알고리즘에 대해 분석 기술한다. 이를 통해 자율주행에 필요한 각 객체 인식 응용에 적합한 알고리즘이 선별적으로 선택되어 연구개발 되어질 수 있기를 기대한다.","Object recognition is to identify the location and class of a specific object by analyzing the given image when a specific image is input. One of the fields in which object recognition technology is actively applied in recent years is autonomous vehicles, and this paper describes the trend of image-based object recognition artificial intelligence technology in autonomous vehicles. The image-based object detection algorithm has recently been narrowed down to two methods (a single-step detection method and a two-step detection method), and we will analyze and organize them around this. The advantages and disadvantages of the two detection methods are analyzed and presented, and the YOLO/SSD algorithm belonging to the single-step detection method and the R-CNN/Faster R-CNN algorithm belonging to the two-step detection method are analyzed and described. This will allow the algorithms suitable for each object recognition application required for autonomous driving to be selectively selected and R&D."
A Study on the Two-Dimensional Graph Data and Its Effectiveness in Human Behavior Classification Deep Learning,2021,"['CNN', 'image', 'deep learning', 'human behavior recognition', 'machine learning']",,"Recently, a lot of research has been conducted using machine learning technology in various fields. It also develops models by applying various learning techniques. We propose a method to develop a CNN model using a two-dimensional graph image, focusing on learning using CNN to process time series information faster than LSTM. Process the data to create a two-dimensional graph and use it for training AI models. It collects data on 4 specific motions with a 6-axis sensor (Arduino nano 33 ble) and creates a two-dimensional graph. The result of testing the model trained in this study is 99.6% accuracy. This was able to achieve higher accuracy than other studies that did not image the data. The difference from the time series data training model using other CNNs is that you can analyze all items in the graph from one kernel. Conventional methods make it difficult to convolution all items into one kernel. Additionally, through experiments with various parameters, inferences between parameters and results and optimal settings are suggested."
Classification of Hand Gestures Based on Multi-channel EMG by Scale Average Wavelet Transform and Convolutional Neural Network,2021,"['Accuracy', 'classification', 'CNN', 'hand gestures', 'scale average wavelet transform (SAWT)', 'sEMG.']",,"Predicting and accurately classifying intentions for human hand gestures can be used not only for active prosthetic hands, rehabilitation robots, and entertainment robots but also for artificial intelligence robots in general. In this paper, first of all, source data of three hand gestures of grasping and three hand gestures of sign language are acquired by using the armband combined with eight sEMG (surface Electromyography) sensors. To classify these hand gestures, basically simple CNN (convolutional neural network) models with raw data, short-time Fourier transform (STFT), wavelet transform (WT), and scale average wavelet transform (SAWT) are applied, and their performances are compared. Finally, it is shown that by using a CNN with SAWT images, the accuracy can be improved up to 94.6% for selected hand gestures with higher accuracy and lower computational burden than conventional multi-channel STFT or WT."
Real-Time Bhutanese Sign Language Digits Recognition System Using Convolutional Neural Network,2021,"['Sign language', 'CNN', 'BSL dataset', 'Augmentation', 'Computer vision']",,"The communication gap between the deaf and public is the concern for both parents and the government of Bhutan. The deaf school urges people to learn Bhutanese Sign Language (BSL) but learning Sign Language (SL) is difficult. This paper presents the BSL digits recognition system using the Convolutional Neural Network (CNN) and a first-ever BSL dataset which has 20,000 sign images of 10 static digits collected from different volunteers. Different SL models were evaluated and compared with the proposed CNN model. The proposed system has achieved 97.62% training accuracy. The system was also evaluated with precision, recall, and F1-score."
딥러닝 합성곱에서 데이터 재사용에 최적화된 GPGPU 설계,2021,"['Data Reuse', 'CNN', 'GPGPU', 'Row stationary', 'SIMT', 'Warp', 'Register bank']","본 논문은 합성곱 신경망에 데이터 재사용 방법을 효과적으로 적용하여 연산 횟수와 메모리 접근 횟수를 줄일 수 있는 GPGPU구조를 제안한다. 합성곱은 kernel과 입력 데이터를 이용한 2차원 연산으로 kernel이 slide하는 방법으로 연산이 이루어 진다. 이때, 합성곱 연산이 완료될 때 까지 kernel을 캐시메모리로 부터 전달 받는 것이 아니고 내부 레지스터를 이용하는 재사용 방법을 제안한다. SIMT방법으로 명령어가 실행되는 GPGPU의 원리 이용하여 데이터 재사용의 효과를 높이기 위해 합성곱에 직렬 연산 방식을 적용하였다. 본 논문에서는 레지스터기반 데이터 재사용을 위하여 kernel을 4x4로 고정하고 이를 효과적으로 지원하기 위한 warp 크기와 레지스터 뱅크를 갖는 GPGPU를 설계하였다. 설계된 GPGPU의 합성곱 신경망에 대한 성능을 검증하기 위해 FPGA로 구현한 뒤 LeNet을 실행시키고 TensorFlow를 이용한 비교 방법으로 AlexNet에 대한 성능을 측정하였다. 측정결과 AlexNet기준 1회 학습 속도는 0.468초이며 추론 속도는 0.135초이다.","This paper proposes a GPGPU structure that can reduce the number of operations and memory access by effectively applying a data reuse method to a convolutional neural network(CNN). Convolution is a two-dimensional operation using kernel and input data, and the operation is performed by sliding the kernel. In this case, a reuse method using an internal register is proposed instead of loading kernel from a cache memory until the convolution operation is completed. The serial operation method was applied to the convolution to increase the effect of data reuse by using the principle of GPGPU in which instructions are executed by the SIMT method. In this paper, for register-based data reuse, the kernel was fixed at 4x4 and GPGPU was designed considering the warp size and register bank to effectively support it. To verify the performance of the designed GPGPU on the CNN, we implemented it as an FPGA and then ran LeNet and measured the performance on AlexNet by comparison using TensorFlow. As a result of the measurement, 1-iteration learning speed based on AlexNet is 0.468sec and the inference speed is 0.135sec."
Implementation of Speech Recognition and Flight Controller Based on Deep Learning for Control to Primary Control Surface of Aircraft,2021,"['Speech Recognition', 'CNN', 'MFCC', 'Flight Controller', 'TensorFlow', '음성 인식', '합성곱 신경망', '비행 제어장치', '텐서플로우']","본 논문에서는 음성 명령을 인식하여 비행기의 1차 조종면을 제어할 수 있는 장치를 제안한다. 음성 명령어는 19개의 명령어로 구성되며 총 2,500개의 데이터셋을 근간으로 학습 모델을 구성한다. 학습 모델은 TensorFlow 기반의 Keras 모델의 Sequential 라이브러리를 이용하여 CNN 모델로 구성되며, 학습에 사용되는 음성 파일은 MFCC 알고리즘을 이용하여 특징을 추출한다. 특징을 인식하기 위한 2단계의 Convolution layer 와 분류를 위한 Fully Connected layer는 2개의 dense 층으로 구성하였다. 검증 데이터셋의 정확도는 98.4%이며 테스트 데이터셋의 성능평가에서는 97.6%의 정확도를 보였다. 또한, 라즈베리 파이 기반의 제어장치를 설계 및 구현하여 동작이 정상적으로 이루어짐을 확인하였다. 향후, 음성인식 자동 비행 및 항공정비 분야의 가상 훈련환경으로 활용될 수 있을 것이다.","In this paper, we propose a device that can control the primary control surface of an aircraft by recognizing speech commands. The speech command consists of 19 commands, and a learning model is constructed based on a total of 2,500 datasets. The training model is composed of a CNN model using the Sequential library of the TensorFlow-based Keras model, and the speech file used for training uses the MFCC algorithm to extract features. The learning model consists of two convolution layers for feature recognition and Fully Connected Layer for classification consists of two dense layers. The accuracy of the validation dataset was 98.4%, and the performance evaluation of the test dataset showed an accuracy of 97.6%. In addition, it was confirmed that the operation was performed normally by designing and implementing a Raspberry Pi-based control device. In the future, it can be used as a virtual training environment in the field of voice recognition automatic flight and aviation maintenance."
조선 네스팅 문제의 부재 페어링을 위한 딥러닝 기반 부재 분류 방법,2021,"['Convolutional neural network(CNN)', 'Deep learning', 'Nesting', 'No-fit polygon(NFP)', 'Pairing', 'Part Classification']",,"With the rapid development of artificial intelligence technology, deep learning-based classification techniques have had enough reliability to be applied to industrial sites. However, while the study of the object classification on data acquired with 3D scanners or cameras has made remarkable progress, research activity based on geometric data sets is still in its infancy. In particular, in order to improve the classification performance of ship parts based on deep learning in the nesting problem to increase productivity in shipbuilding, the study of the construction of part datasets and data pre-processing is necessary. In this paper, we introduce a method to apply the artificial neural network technology of deep learning to the nesting algorithm for shipbuilding. Labeled with histogram-based shape contexts for constructing a dataset for classifying ship parts using Convolutional Neural Networks (CNNs). In addition, we introduce the preprocessing method of the geometric information of the ship parts for learning and the no-fit polygon (NFP) method for classified parts to pair up. To train the classification model for the 23,201 ship parts, a data set of 842 classes was constructed through the shape matching algorithm. The trained CNN model was able to classify those parts with an accuracy of 85.13%."
딥러닝을 이용한 유방조영술의 종양 분할,2021,"['유방조영술', '딥러닝', '의미론적 분할', 'CNN', 'Mammography', 'Deep Learning', 'Semantic Segmentation']","유방 종양은 유방암의 증상 중 하나이며 유방암은 여성에게서 흔히 발병하는 질병이다. 유방 종양은 초기 검사인 유방조영술에서 발견되므로 초기 진단이 매우 중요하다. 하지만 유방 종양을 탐지하는 것은 전문가에게도 어려운 일이다. 최근 딥러닝을 사용하여 유방조영술영상에서 병변을 찾으려는 노력이 이루어지고 있으며 본 논문에서는 딥러닝을 사용하여 유방조영술 영상에서 유방 종양을 분할하고자 한다. CBIS-DDSM(Curated Breast Image Subset of Digital Database for Screening Mammography) 데이터를 수집하고 데이터에 전처리를 시행한다. 의미론적 분할 모델인 FCN(Fully Convolutional Network), U-Net과 CNN(Convolutional Neural Network) 백본망인 VGGNet(Visual Geometry Group Net), EfficientNet 모델의 조합으로 4개의 모델을 구성하여 학습 기법을 사용하여 학습한다. 평가 데이터를 통해 유방 종양이 예측된 마스크와 유방 종양을 나타내는 실제 마스크를 사용하여 얼마나 유사하게 분할하였는지 시각화하고 구성한 모델의 성능을 비교한다. U-Net-EfficientNet 모델이 85.91%로 가장 높은 성능을 보여주었고, U-Net-VGG-Net 모델이 63.56%로 가장 낮은 성능을 보여주었다.","Breast tumor is one of the symptoms of breast cancer. And breast cancer is a common disease in women. Initial diagnosis is very important because breast tumors are found by mammography, which is an initial examination. However, detecting breast tumor is difficult even for experts. Efforts have recently been made to use deep learning to look for lesions in mammographic images. Many papers used deep learning to isolate breast tumors from mammographic images. We collect CBISDDSM(Curated Breast Image Subset of Digital Database for Screening Mammography) data and preprocess the data. Semantic segmentation model, which is FCN(Fully Convolutional Network) and U-Net, is combined with CNN(Convolutional Neural Network) backbone, which is VGGNet(Visual Geometry Group Net) and EfficientNet, to construct four models. The four models are trained using learning methods. The evaluation data are used to visualize the similarity between the segmented result using a predicted mask and the actual mask showing breast tumors. The performances of the constructed models are compared. The U-Net-EfficientNet model showed the highest performance at 85.91%, and the U-Net-VGGNet showed the lowest performance at 63.56%."
딥러닝을 활용한 이미지 기반 교량 구성요소 자동분류 네트워크 개발,2021,"['BIM', 'Deep learning', 'CNN', 'Bridge component classification', '딥러닝', '교량 구성요소 분류']","우리나라의 교량은 대부분이 건설된 지 20년 이상이 지나 현재 노후화로 인하여 많은 문제점이 제기되고 있으며, 교량의 안전점검은 대부분 전문 인력의 주관적인 평가로 이루어지고 있다. 최근 교량 안전점검의 데이터의 체계적인 관리를 위해 BIM 등을 활용한 데이터 기반의 유지관리기술들이 개발되고 있지만, BIM과 구조물의 유지관리 데이터를 연동을 위해서 영상정보를 직접 라벨링하는 수작업을 필요로한다. 따라서 본 논문에서는 이미지 기반의 자동 교량 구성요소 분류 네트워크를 개발하고자 한다. 본 연구에서 제안한 방법은 두 개의 CNN 네트워크로 구성되었다. 첫 번째 네트워크에서 특정 교량 이미지에 대하여 교량의 형식을 자동으로 분류한 뒤, 두 번째 네트워크에서 교량의 형식별로 구성요소를 분류함으로써 정확도와 효율성을 향상시키고자 한다. 본 연구에서 개발한 시스템을 검증한 결과, 847개의 교량 이미지에 대해서 98.1 %의 정확도로 교량의 구성요소를 자동으로 분류 할 수 있었다. 본 연구에서 개발한 교량의 구성요소 자동분류 기술은 향후 교량의 유지관리에 기여를 할 수 있을 것으로 기대된다.","Most bridges in Korea are over 20 years old, and many problems linked to their deterioration are being reported. The current practice for bridge inspection mainly depends on expert evaluation, which can be subjective. Recent studies have introduced data-driven methods using building information modeling, which can be more efficient and objective, but these methods require manual procedures that consume time and money. To overcome this, this study developed an image-based automatic bridge component classification network to reduce the time and cost required for converting the visual information of bridges to a digital model. The proposed method comprises two convolutional neural networks. The first network estimates the type of the bridge based on the superstructure, and the second network classifies the bridge components. In avalidation test, the proposed system automatically classified the components of 461 bridge images with 96.6 % of accuracy. The proposed approach is expected to contribute toward current bridge maintenance practice."
샤인머스캣과 청포도 자동 분류 딥러닝 시스템 개발,2021,"['분류', '딥러닝', '인공지능', '스마트 팜', '샤인머스캣', '청포도', 'CNN', 'Classification', 'Deep Learning', 'Artificial Intelligence', 'Smart Farm', 'Shine-muscat', 'Green-grape']",,"In this paper, in order to develop an artificial intelligence system for automatic classification of shine muscats and green grapes with similar characteristics, an image dataset of the two fruits and a feature-based numerical dataset were constructed. Two CNN models were applied to the constructed image dataset and the accuracy of automatic classification was calculated using verification data. As a result, the VGGNET model showed 25% accuracy, and the CNN deep learning model proposed to minimize overfitting showed 84% accuracy. In addition, when the linear regression deep learning model was applied to feature-based numerical datasets, the accuracy of automatic classification was 94%. It is expected that the dataset construction method and deep learning method proposed in this paper can be applied to the implementation of artificial intelligence-based smart farm systems by automatically classifying fruits or agricultural products of different varieties."
합성곱 신경망을 이용한 Local Maximum Scalogram 기반 부정맥 분류에 관한 연구,2021,"['Arrhythmia', 'LMS', 'learning model', 'SVM', 'CNN', 'standard deviation']",,"The purpose of this study is to investigate whether it can be used for arrhythmia detection as a wavelet transform and another feature extraction method using the probability distribution of LMS(Local Maximum Scalogram). The SVM(Support Vector Machine) model uses two kernels: Polynomial and Radial Basis Function(RBF). Three types of data are used: standard deviation of the row (n), standard deviation of the column(n/2), and standard deviation of the row and column (3n/2) of the basic LMS matrix according to the sample (n = 90,180, 270, 360, 450), The training data of the CNN model uses two LMS matrices when fixed to and. The trained model is divided 5 times, and K-fold cross-validation is performed and evaluated using ROC, AUC, and confusion matrix. Finally, the filtered ECG data is compared with the confusion matrix result graph to consider the types of arrhythmia that are difficult to classify. CNN is evaluated to show good overall performance when is. The results of the SVM model show the possibility that the standard deviation values of the LMS’s rows and columns can be used as a feature of arrhythmic bit detection. Since it is simple but very efficient, it is expected to be used in various ways as a single feature extraction method."
립모션 센서 기반 증강현실 인지재활 훈련시스템을 위한 합성곱신경망 손동작 인식,2021,"['Euler angle spectrograph', 'Convolutional neural network (CNN)', 'Hand gesture recognition', 'Augmented reality (AR)', 'Cognitive rehabilitation system', 'Leap motion controller (LMC)']",,"In this paper, we evaluated prediction accuracy of Euler angle spectrograph classification method using a convolutional neural networks (CNN) for hand gesture recognition in augmented reality (AR) cognitive rehabilitation system based on Leap Motion Controller (LMC). Hand gesture recognition methods using a conventional support vector machine (SVM) show 91.3% accuracy in multiple motions. In this paper, five hand gestures (""Promise"", ""Bunny"", ""Close"", ""Victory"", and ""Thumb"") are selected and measured 100 times for testing the utility of spectral classification techniques. Validation results for the five hand gestures were able to be correctly predicted 100% of the time, indicating superior recognition accuracy than those of conventional SVM methods. The hand motion recognition using CNN meant to be applied more useful to AR cognitive rehabilitation training systems based on LMC than sign language recognition using SVM."
3축 가속도 센서 스트림에 대한 유한차분 및 합성곱 신경망 기반의 뇌전증 발작 감지 기법,2021,"['딥러닝', '합성곱 신경망', '다변량 분석', '유한차분법', 'IoT', '스트림 데이터', 'Deep Learning', 'CNN', 'Multivariate Analysis', 'Finite Difference Method', 'IoT', 'Stream Data']","뇌전증은 발작을 동반하는 만성 뇌질환이다. 뇌전증 발작 감지에는 일반적으로 뇌파를 활용한다. 뇌전증 발작은 불규칙한 시점에 발생하며, 지속적일 경우 뇌손상 또는 사망에 이를 수 있는 응급 상황이다. 따라서 신속한 대처를 위한 일상생활 중 뇌전증 발작의 실시간 감지가 중요하다. 그러나 센서 민감도와 같은 기술적 한계로 인하여, 현재까지는 전문 장비를 갖춘 병원에서조차 정확한 뇌파의 측정이 어렵다. 또한, 실시간으로 뇌파를 측정할 수 있는 웨어러블 기기로의 상용화는 더욱 어려운 상황이다. 따라서 3축 가속도 센서 스트림 기반 동작 인식은 일상생활 중 실시간 뇌전증 발작 감지를 위한 현실적인 대안이다. 본 논문에서는 스마트폰, 스마트워치 등에 내장된 3축 가속도 센서 데이터에 대한 유한차분 및 합성곱 신경망 기반의 뇌전증 발작 감지 기법을 제안한다. 제안하는 기법은 뇌전증 발작의 의학적 특성에 근거하여, 유한차분을 통해 각 축 값의 변화율을 구하고, 합성곱 신경망 기반의 다변량 분석을 수행하여 각 축 값 변화율 간의 관계를 통합적으로 고려한다. 제안하는 기법은 걷기, 뛰기와 같은 대표 동작 외에도 양치질, 톱질 등 뇌전증 발작과 유사한 짧은 주기의 반복 동작을 포함한 17가지 일상 상황들로부터 99% 이상의 확률로 뇌전증 발작을 감지할 수 있음을 실험을 통해 확인하였다.","Epilepsy is a chronic brain disease causing repetitive seizures. Epileptic seizures occur irregularly and are emergency situations that can lead to brain damage or even death if happen continuously. Therefore, real-time detection of epileptic seizures is important for rapid treatment. However, due to some technical limitations like sensitivity of sensors, it is difficult to accurately measure EEG even in hospitals. Also, it is even more difficult to commercialize wearable devices. Therefore, human activity recognition on 3-axis accelerometer streams is a realistic alternative for real-time detection of epileptic seizures. In this paper, we propose a epileptic seizure detection method based on finite difference and CNN for 3-axis accelerometer streams measured from smart devices. The proposed method considers the medical characteristics of epileptic seizures to calculate the finite difference of each axis, and carries out multivariate analysis based on CNN to integratively consider the relationship between rate of changes of each. Our experiments show that our method can detect the epileptic seizures with a probability of more than 99% from 17 types of daily activities including repetitive activities in short cycles being thought to be similar to epileptic seizures such as brushing teeth and sawing besides typical movements like walking or running."
API Call 정보 기반의 안드로이드 악성코드 분류를 위한 특성 집합 추출,2021,"['API-Call', 'Feature Selection', 'Dimensionality Reduction', 'Malware Classification', 'CNN', '특성 선택', '차원 축소', '악성코드 분류']","악성코드를 포함한 모든 응용프로그램은 실행 시 API(Application Programming Interface)를 호출한다. 최근에는 이러한 특성을 활용하여 API Call 정보를 기반으로 악성코드를 탐지하고 분류하는 접근방법이 많은 관심을 받고 있다. 그러나 API Call 정보를 포함하는 데이터세트는 그 양이 방대하여 많은 계산 비용과 처리시간이 필요하다. 또한, 악성코드 분류에 큰 영향을 미치지 않는 정보들이 학습모델의 분류 정확도에 영향을 미칠 수도 있다. 이에 본 논문에서는 다양한 특성 선택(feature selection) 방법을 적용하여 API Call 정보에 대한 차원을 축소시킨 후, 핵심 특성 집합을 추출하는 방안을 제시한다. 실험은 최근 발표된 안드로이드 악성코드 데이터세트인 CICAndMal2020을 이용하였다. 다양한 특성 선택 방법으로 핵심 특성 집합을 추출한 후 CNN(Convolutional Neural Network)을 이용하여 안드로이드 악성코드 분류를 시도하고 결과를 분석하였다. 그 결과 특성 선택 알고리즘에 따라 선택되는 특성 집합이나 가중치 우선순위가 달라짐을 확인하였다. 그리고 이진분류의 경우 특성 집합을 전체 크기의 15% 크기로 줄이더라도 97% 수준의 정확도로 악성코드를 분류하였다. 다중분류의 경우에는 최대 8% 이하의 크기로 특성 집합을 줄이면서도 평균 83%의 정확도를 달성하였다.","All application programs, including malware, call the Application Programming Interface (API) upon execution. Recently, using those characteristics, attempts to detect and classify malware based on API Call information have been actively studied. However, datasets containing API Call information require a large amount of computational cost and processing time. In addition, information that does not significantly affect the classification of malware may affect the classification accuracy of the learning model. Therefore, in this paper, we propose a method of extracting a essential feature set after reducing the dimensionality of API Call information by applying various feature selection methods. We used CICAndMal2020, a recently announced Android malware dataset, for the experiment. After extracting the essential feature set through various feature selection methods, Android malware classification was conducted using CNN (Convolutional Neural Network) and the results were analyzed. The results showed that the selected feature set or weight priority varies according to the feature selection methods. And, in the case of binary classification, malware was classified with 97% accuracy even if the feature set was reduced to 15% of the total size. In the case of multiclass classification, an average accuracy of 83% was achieved while reducing the feature set to 8% of the total size."
스태킹 앙상블을 이용한 병렬 네트워크 이상호흡음 분류 모델,2021,"['Respiratory Sound Classification', 'Wheezes', 'Crackles', 'Convolutional Neural Network(CNN)', 'Stacking Ensemble', '호흡음 분류', '천명음', '수포음', '병렬 합성곱 신경망', '스태킹 앙상블']","최근 코로나(Covid-19)의 영향으로 스마트 헬스케어 관련 산업과 비대면 방식의 원격 진단을 통한 질환 분류 예측 연구의 필요성이 증가하고 있다. 일반적으로 호흡기 질환의 진단은 비용이 많이 들고 숙련된 의료 전문가를 필요로 하여 현실적으로 조기 진단 및 모니터링에 한계가 있다. 따라서, 간단하고 편리한 청진기로부터 수집된 호흡음을 딥러닝 기반 모델을 활용하여 높은 정확도로 분류하고 조기 진단이 필요하다. 본 연구에서는 청진을 통해 수집된 폐음 데이터를 이용하여 이상 호흡음 분류모델을 제안한다. 데이터 전처리로는 대역통과필터(BandPassFilter)방법론을 적용하고 로그 멜 스펙트로그램(Log-Mel Spectrogram)과 Mel Frequency Cepstral Coefficient(MFCC)을 이용하여 폐음의 특징적인 정보를 추출하였다. 추출된 폐음의 특징에 대해서 효과적으로 분류할 수 있는 병렬 합성곱 신경망 네트워크(Parallel CNN network)모델을 제안하고 다양한 머신러닝 분류기(Classifiers)와 결합한 스태킹 앙상블(Stacking Ensemble) 방법론을 이용하여 이상 호흡음을 높은 정확도로 분류하였다. 본 논문에서 제안한 방법은 96.9%의 정확도로 이상 호흡음을 분류하였으며, 기본모델의 결과 대비 정확도가 약 6.1% 향상되었다.","As the COVID-19 pandemic rapidly changes healthcare around the globe, the need for smart healthcare that allows for remote diagnosis is increasing. The current classification of respiratory diseases cost high and requires a face-to-face visit with a skilled medical professional, thus the pandemic significantly hinders monitoring and early diagnosis. Therefore, the ability to accurately classify and diagnose respiratory sound using deep learning-based AI　models is essential to modern medicine as a remote alternative to the current stethoscope. In this study, we propose a deep learning-based respiratory sound classification model using data collected from medical experts. The sound data were preprocessed with BandPassFilter, and the relevant respiratory audio features were extracted with Log-Mel Spectrogram and Mel Frequency Cepstral Coefficient (MFCC). Subsequently, a Parallel CNN network model was trained on these two inputs using stacking ensemble techniques combined with various machine learning classifiers to efficiently classify and detect abnormal respiratory sounds with high accuracy. The model proposed in this paper classified abnormal respiratory sounds with an accuracy of 96.9%, which is approximately 6.1% higher than the classification accuracy of baseline model."
모바일 플랫폼 교육 콘텐츠 지원을 위한 손 글씨 기반 텍스트 인터페이스 설계,2021,"['텍스트 인터페이스', '딥 러닝', '모바일', '영어 교육 콘텐츠', 'text interface', 'EMNIST', 'CNN', 'deep learning', 'mobile', 'English education contents']","본 연구는 모바일 플랫폼 환경에서 언어 기반의 교육 콘텐츠 지원을 위한 텍스트 인터페이스를 제안한다. 이는 손 글씨를 통해 단어를 작성하는 입력 구조로 딥 러닝을 활용한다. 모바일 플랫폼 콘텐츠의 버튼, 메뉴 등을 활용한 GUI (Graphical User Interface)와 화면 터치, 클릭, 드래그 등의 입력 방식을 기반으로 손 글씨를 사용자로부터 직접 입력하여 처리할 수 있는 텍스트 인터페이스를 설계한다. 이는 EMNIST (Extended Modified National Institute of Standards and Technology database) 데이터 셋과 훈련된 CNN (Convolutional Neural Network)을 사용하여 알파벳 텍스트를 분류하고 조합하여 단어를 완성한다. 최종적으로 영어 단어 교육 콘텐츠를 직접 제작하여 제안하는 인터페이스의 학습 지원 효과를 분석하고 만족도를 비교하기 위한 실험을 진행한다. 동일한 교육 환경에서 기존의 키 패드 방식의 인터페이스와 제안하는 손 글씨 기반 텍스트 인터페이스를 서로 체험한 사용자들이 제시하는 영어 단어를 학습하는 능력을 비교하고, 인터페이스를 조작하여 단어를 작성하는 과정에서의 전체적인 만족도를 분석, 확인하도록 한다.","This study proposes a text interface for support of language-based educational contents in a mobile platform environment. The proposed interface utilizes deep learning as an input structure to write words through handwriting. Based on GUI (Graphical User Interface) using buttons and menus of mobile platform contents and input methods such as screen touch, click, and drag, we design a text interface that can directly input and process handwriting from the user. It uses the EMNIST (Extended Modified National Institute of Standards and Technology database) dataset and a trained CNN (Convolutional Neural Network) to classify and combine alphabetic texts to complete words. Finally, we conduct experiments to analyze the learning support effect of the interface proposed by directly producing English word education contents and to compare satisfaction. We compared the ability to learn English words presented by users who have experienced the existing keypad-type interface and the proposed handwriting-based text interface in the same educational environment, and we analyzed the overall satisfaction in the process of writing words by manipulating the interface."
통합 이미지 처리 기술을 이용한 콘크리트 교량 균열 탐지 및 매핑,2021,"['concrete crack', 'deep learning', 'orthomosaic', 'drone', 'cascade mask R-CNN']",,"In many developed countries, such as South Korea, efficiently maintaining the aging infrastructures is an important issue. Currently, inspectors visually inspect the infrastructure for maintenance needs, but this method is inefficient due to its high costs, long logistic times, and hazards to the inspectors. Thus, in this paper, a novel crack inspection approach for concrete bridges is proposed using integrated image processing techniques. The proposed approach consists of four steps: (1) training a deep learning model to automatically detect cracks on concrete bridges, (2) acquiring in-situ images using a drone, (3) generating orthomosaic images based on 3D modeling, and (4) detecting cracks on the orthmosaic image using the trained deep learning model. Cascade Mask R-CNN, a state-of-the-art instance segmentation deep learning model, was trained with 3235 crack images that included 2415 hard negative images. We selected the Tancheon overpass, located in Seoul, South Korea, as a testbed for the proposed approach, and we captured images of pier 34-37 and slab 34-36 using a commercial drone. Agisoft Metashape was utilized as a 3D model generation program to generate an orthomosaic of the captured images. We applied the proposed approach to four orthomosaic images that displayed the front, back, left, and right sides of pier 37. Using pixel-level precision referencing visual inspection of the captured images, we evaluated the trained Cascade Mask R-CNN's crack detection performance. At the coping of the front side of pier 37, the model obtained its best precision: 94.34%. It achieved an average precision of 72.93% for the orthomosaics of the four sides of the pier. The test results show that this proposed approach for crack detection can be a suitable alternative to the conventional visual inspection method."
Facial Recognition Using an Ensemble Model of Dimension Reduction Techniques and Convolutional Neural Networks,2021,"['Dimensionality Reduction', 'Face Recognition', 'Ensemble Model', 'PCA', 'LLE', 'CNN']","기술 트렌드가 증가함에 따라, 엄청난 양의 데이터가 생성되고 있습니다. 많은 양의 데이터가 소비되는 기술분야 중 하나는 컴퓨터 비전이다. 인간은 기계와 비교할 때 시각에 영향을 미치는 표정, 조명 또는 시야각과 같은 외부 조건에서도 얼굴이나 사물을 쉽게 감지하고 인식할 수 있다. 그 이유는 그것과 관련된 높은 차원의 데이터 때문이다. 데이터 차원성은 모든 관측치에서 측정되는 변수의 총 수를 말합니다. 이번 사업은 안면인식시스템에 적합한 다양한 차원감소 기법을 비교하고 조도가 다양한 안면이미지로 구성된 다양한 데이터세트로 테스트해 모델의 정확도 향상에 도움이 되는 기법의 앙상블 모델을 제안하고 성능을 측정하는 것이 목적이다.렉스 배경과 표현. 제안된 앙상블 모델은 주성분 분석(PCA)과 로컬 선형 임베딩(LLE)이라는 두가지 차원 감소 기술의 혼합에서 벡터를 추출하고, 이를 밀도 높은 컨볼루션 신경망(CNN)을 통해 전달하여 야생 면(LFW) 데이터 세트의 얼굴을 예측한다. 이 모형은 0.95의 검정 정확도와 0.94의 검정 F1 점수로 수행됩니다. 제안된 시스템은 시스템이 얼굴을 예측할 수 있는 제안된 앙상블 모델과 통합된 웹캠에서 라이브 비디오 스트림을 캡처하는 플라스크를 사용하여 개발된 웹 앱을 포함한다.","With increasing trends in technology, there is a huge volume of data that is being created. One field in technology in which high amount of data is consumed, is computer vision. Human beings are able to detect and recognize faces or objects with ease even with external conditions such as expressions, illuminations or viewing angle affecting the sight when compared to the machines. This is because of high dimensions of data associated with it. Data dimensionality is refered to as total number of variables being measured in every observation. This project aims to compare different applicable dimensionality reduction techniques suitable for facial recognition system and propose an ensemble model of such techniques that will help improving the accuracy of the model and gauge the performance by testing it with different datasets consisting of facial images with varying illuminations, complex backgrounds, and expressions. The proposed ensemble model extracts feature vectors from a hybrid of two dimensional reduction techniques - Principal Component Analysis (PCA) and Locally Linear Embedding (LLE), and pass them through dense Convolutional Neural Network (CNN) to predict faces on the Labelled Faces in the Wild (LFW) dataset. The model performs with a testing accuracy of 0.95 and a testing F1 score of 0.94. The proposed system involves a webapp developed using Flask that captures a live video stream from a webcam which is integrated with the proposed ensemble model that allows the system to predict the face."
인공지능 기반 영어 발음 인식에 관한 연구,2021,"['인공지능', '동적 시간 워핑', '합성곱 신경망', '영어 발음', '영어 교육', 'AI', 'DTW', 'CNN', 'English Pronunciation', 'English Language Training']","최근 4차 산업혁명은 주요 선진국을 중심으로 세계의 국가들의 관심을 갖는 분야가 되고 있다. 4차 산업혁명 기술의 핵심기술인 인공지능기술은 다양한 분야에 융합하는 형태로 발전하고 있으며, 에듀테크 분야에도 많은 영향을 미치고 있으며 교육을 혁신적으로 변화하기 위해 많은 관심과 노력을 하고 있다. 본 논문은 DTW 음성인식 알고리즘을 이용하여 실험환경을 구축하고 다양한 원어민 데이터와 비원어민 데이터를 딥러닝 학습하고, CNN 알고리즘과의 비교를 통해 영어 발음의 유사도를 측정하여 비원어민이 원어민과 유사한 발음으로 교정할 수 있도록 연구한다.","Recently, the fourth industrial revolution has become an area of interest to many countries, mainly in major advanced countries. Artificial intelligence technology, the core technology of the fourth industrial revolution, is developing in a form of convergence in various fields and has a lot of influence on the edutech field to change education innovatively. This paper builds an experimental environment using the DTW speech recognition algorithm and deep learning on various native and non-native data. Furthermore, through comparisons with CNN algorithms, we study non-native speakers to correct them with similar pronunciation to native speakers by measuring the similarity of English pronunciation."
Lightweight image classifier for CIFAR-10,2021,"['Computer vision', 'Convolutional neural networks', 'Image classification', 'Lightweight CNN']",,"Image classification is one of the fundamental applications of computer vision. It enables a system to identify an object in an image. Recently, image classification applications have broadened their scope from computer applications to edge devices. The convolutional neural network (CNN) is the main class of deep learning neural networks that are widely used in computer tasks, and it delivers high accuracy. However, CNN algorithms use a large number of parameters and incur high computational costs, which hinder their implementation in edge hardware devices. To address this issue, this paper proposes a lightweight image classifier that provides good accuracy while using fewer parameters. The proposed image classifier diverts the input into three paths and utilizes different scales of receptive fields to extract more feature maps while using fewer parameters at the time of training. This results in the development of a model of small size. This model is tested on the CIFAR-10 dataset and achieves an accuracy of 90% using .26M parameters. This is better than the state-of-the-art models, and it can be implemented on edge devices."
Deep convolutional neural network: a novel approach for the detection of Aspergillus fungi via stereomicroscopy,2021,"['Aspergillus detection', 'conidiophore and colony morphology', 'stereomicroscopy/dissecting microscopy', 'convolutional neural network (CNN)', 'Xception']",,"Fungi of the genus Aspergillus are ubiquitously distributed in nature, and some cause invasive aspergillosis (IA) infections in immunosuppressed individuals and contamination in agricultural products. Because microscopic observation and molecular detection of Aspergillus species represent the most operator-dependent and time-intensive activities, automated and cost-effective approaches are needed. To address this challenge, a deep convolutional neural network (CNN) was used to investigate the ability to classify various Aspergillus species. Using a dissecting microscopy (DM)/stereomicroscopy platform, colonies on plates were scanned with a 35× objective, generating images of sufficient resolution for classification. A total of 8,995 original colony images from seven Aspergillus species cultured in enrichment medium were gathered and autocut to generate 17,142 image crops as training and test datasets containing the typical representative morphology of conidiophores or colonies of each strain.Encouragingly, the Xception model exhibited a classification accuracy of 99.8% on the training image set. After training, our CNN model achieved a classification accuracy of 99.7% on the test image set. Based on the Xception performance during training and testing, this classification algorithm was further applied to recognize and validate a new set of raw images of these strains, showing a detection accuracy of 98.2%. Thus, our study demonstrated a novel concept for an artificial-intelligence-based and cost-effective detection methodology for Aspergillus organisms, which also has the potential to improve the public’s understanding of the fungal kingdom."
맞대기 V형 그루브의 GMA 초층용접에서 합성곱 신경망을 이용한 이면비드 발생 예측 모델 개발,2021,"['Gas metal arc welding (GMAW)', 'V-Groove', 'Back-bead', 'Root pass', 'Full penetration', 'Deep learning', 'Convolutional neural network (CNN)', 'Laser vision']",,"Gas metal arc (GMA) welding is widely used in the machinery industry. The quality of a welded joint is affected by the penetration of root pass welding in the V-groove joint. Automation using GMA welding is continuously required, and root pass welding automation is required to automate the entire welding process. In particular, the development of a prediction model that can ensure full penetration back-bead is required for the automation of root pass welding. In this study, a convolutional neural network (CNN) model was applied to predict the occurrence of back-bead in V-groove butt joint GMA root pass welding. The bead profile was measured using a laser vision sensor system and it was used as the input data for the prediction model, and the bead occurrence was used as the output data for the model. A total of 12,873 bead profiles were extracted and pre-processed through cutting, resizing, and thresholding. The CNN model consists of nine layers, and performs three convolution and two pooling operations. The accuracy of the prediction model was 99.5%, and through this study, it was demonstrated that the quality of root-pass welding can be controlled by using convolutional neural network and it can contribute to automation."
합성곱신경망을 사용한 이미지 기반의 안드로이드 악성소프트웨어 패밀리 분류,2021,"['안드로이드 악성소프트웨어', '패밀리 분류', '회색조 이미지', '합성곱 신경망', '데이터 섹션', 'android malware', 'family classification', 'grayscale image', 'CNN', 'data section']","안드로이드 악성소프트웨어가 지속적으로 증가함에 따라, 기계학습을 사용한 안드로이드 악성소프트웨어 탐지 및 분류 기법이 많이 연구되고 있다. 악성소프트웨어 패밀리(malware family) 분류는, 악성소프트웨어 샘플들을 연관성 있는 그룹으로 분류하는 기법으로 컴퓨터 포렌식 분석, 위협 평가, 위협완화 계획에 중요한 역할을 한다. 본 논문에서는 실행파일 중의 일부를 회색조 이미지(grayscale image)로 변환한 후 변환된 영상들을 대상으로 딥러닝 기법을 적용하여 안드로이드 악성소프트웨어 패밀리를 분류하는 방법을 제안한다. 대표적인 안드로이드 악성소프트웨어 데이터 셋(dataset)인 Drebin에서 제공되는 악성소프트웨어 대표 패밀리들을 대상으로 합성곱신경망(Convolutional Neural Network, CNN) 모델을 적용하여 악성소프트웨어를 분류한다. 본 실험의 연구 결과를 기존 연구 결과와 비교하여, 데이터 경량화와 적절한 데이터 크기의 선정, 정확도에 있어 본 연구가 악성소프트웨어 분류에 더 효과적임을 보인다.","As Android malware continues to increase, Android malware detection and classification techniques using machine learning are being studied intensively. Malware family classification is a technique for classifying malware samples into related malware families and plays an important role in computer forensic analysis, threat assessment, and threat mitigation planning. In this paper, we propose a method to classify Android malware families by converting only part of an executable file into a gray scale image and applying deep learning to the converted images. The malware samples are classified from the representative families of the dataset from the Drebin project by applying the Convolutional Neural Network (CNN) model. The experimental results show that the proposed method is more effective in classifying malware families in terms of processing overhead and classification accuracy."
봇 넷 트래픽 식별을 위한 스택구조 딥러닝 접근 방식,2021,"['Botnet', 'Botnet Detection System', 'Deep Learning', 'Convolutional Neural Network', 'CTU-13 Dataset', '넷', '봇 넷 검출 시스템', '딥러닝', 'CTU-13 데이터 셋']","봇 넷의 악의적인 행위는 인터넷 서비스 제공자뿐만 아니라 기업, 정부, 그리고 심지어 가정의 일반 사용자에 이르기까지 엄청난 경제적 손실을 끼치고 있다. 본 논문에서는 CTU-13 봇 넷 트래픽 데이터 셋을 사용하여 딥러닝 모델 Convolutional Neural Network(CNN)을 적용한 봇 넷 트래픽 검출에 대한 가능성을 확인하고자한다. 특히 알려진 봇 넷과 알려지지 않은 봇 넷 트래픽에 대해 C&C 서버를 검출하기 위한 봇과 C&C 서버 사이 트래픽, 봇을 검출하기 위한 C&C 통신 이외에 봇이 발생하는 트래픽, 그리고 정상 트래픽을 분류하는 멀티클래스 분류(multi-class classification)를 시도하였다. 성능검증을 위한 지표는 정확도, 정밀도, 재현율, 그리고 F1 점수를 제시하였다. 한편 확장성과 운영을 고려하여 봇 넷 타입 별로 모듈을 적재할 수 있는 스택구조의 봇 넷 검출 시스템을 제안함으로써 실제 네트워크의 적용 가능성을 제시하였다.","Malicious activities of Botnets are responsible for huge financial losses to Internet Service Providers, companies, governments and even home users. In this paper, we try to confirm the possibility of detecting botnet traffic by applying the deep learning model Convolutional Neural Network (CNN) using the CTU-13 botnet traffic dataset. In particular, we classify three classes, such as the C&C traffic between bots and C&C servers to detect C&C servers, traffic generated by bots other than C&C communication to detect bots, and normal traffic. Performance metrics were presented by accuracy, precision, recall, and F1 score on classifying both known and unknown botnet traffic. Moreover, we propose a stackable botnet detection system that can load modules for each botnet type considering scalability and operability on the real field."
딥러닝을 이용한 풍력 발전량 예측,2021,"['풍력발전', '예측', '머신 러닝', '다중 퍼셉트론', '재귀 신경망', '중기 단기 기억', '인공지능', '전력량', 'Wind power', 'prediction', 'LSTM(:Long short term memory)', 'CNN(:Cellular neural network)', 'Artificial intelligence']","본 연구는 풍력발전의 합리적인 운영 계획과 에너지 저장창치의 용량산정을 위한 풍력 발전량을 예측한다. 예측을 위해 물리적 접근법과 통계적 접근법을 결합하여 풍력 발전량의 예측 방법을 제시하고 풍력 발전의 요인을 분석하여 변수를 선정한다. 선정된 변수들의 과거 데이터를 수집하여 딥러닝을 이용해 풍력 발전량을 예측한다. 사용된 모델은 Bidirectional LSTM(:Long short term memory)과 CNN(:Convolution neural network) 알고리즘을 결합한 하이브리드 모델을 구성하였으며, 예측 성능 비교를 위해 MLP 알고리즘으로 이루어진 모델과 오차를 비교하여, 예측 성능을 평가하고 그 결과를 제시한다.","This study predicts the amount of wind power generation for rational operation plan of wind power generation and capacity calculation of ESS. For forecasting, we present a method of predicting wind power generation by combining a physical approach and a statistical approach. The factors of wind power generation are analyzed and variables are selected. By collecting historical data of the selected variables, the amount of wind power generation is predicted using deep learning. The model used is a hybrid model that combines a bidirectional long short term memory (LSTM) and a convolution neural network (CNN) algorithm. To compare the prediction performance, this model is compared with the model and the error which consist of the MLP(:Multi Layer Perceptron) algorithm, The results is presented to evaluate the prediction performance."
뇌파를 활용한 IoT기반 스마트홈 시스템 구현,2021,"['스마트홈', '사물인터넷', '뇌-컴퓨터 인터페이스', '뇌파', '딥러닝', '합성곱신경망', 'Smart Home', 'Internet of Things (IoT)', 'Brain-Computer Interface (BCI)', 'Electroencephalography (EEG)', 'Deep learning', 'Convolutional Neural Network (CNN)']",,
Wood Classification of Japanese Fagaceae using Partial Sample Area and Convolutional Neural Networks,2021,"['wood', 'microscopic image', 'sample selection', 'classification', 'convolutional neural network']",,"Wood identification is regularly performed by observing the wood anatomy, such as colour, texture, fibre direction, and other characteristics. The manual process, however, could be time consuming, especially when identification work is required at high quantity. Considering this condition, a convolutional neural networks (CNN)-based program is applied to improve the image classification results. The research focuses on the algorithm accuracy and efficiency in dealing with the dataset limitations. For this, it is proposed to do the sample selection process or only take a small portion of the existing image. Still, it can be expected to represent the overall picture to maintain and improve the generalisation capabilities of the CNN method in the classification stages. The experiments yielded an incredible F1 score average up to 93.4% for medium sample area sizes (200 × 200 pixels) on each CNN architecture (VGG16, ResNet50, MobileNet, DenseNet121, and Xception based). Whereas DenseNet121-based architecture was found to be the best architecture in maintaining the generalisation of its model for each sample area size (100, 200, and 300 pixels). The experimental results showed that the proposed algorithm can be an accurate and reliable solution."
신용 데이터의 이미지 변환을 활용한 합성곱 신경망과 설명 가능한 인공지능(XAI)을 이용한 개인신용평가,2021,"['Convolutional Neural Networks', 'eXplainable Artificial Inteligence', 'Deep learning', 'Imaged data', 'Personal credit rating']",,"PurposeThe purpose of this study is to enhance the accuracy score of personal credit scoring using the convolutional neural networks and secure the transparency of the deep learning model using eXplainalbe Artifical Inteligence(XAI) technique.Design/methodology/approachThis study built a classification model by using the convolutional neural networks(CNN) and applied a methodology that is transformation of numerical data to imaged data to apply CNN on personal credit data. Then layer-wise relevance propagation(LRP) was applied to model we constructed to find what variables are more influenced to the output value.FindingsAccording to the empirical analysis result, this study confirmed that accuracy score by model using CNN is highest among other models using logistic regression, neural networks, and support vector machines. In addition, With the LRP that is one of the technique of XAI, variables that have a great influence on calculating the output value for each observation could be found."
와이어-아크 적층제조 공정의 비드 결함 감지를 위한 기계학습 모델,2021,"['Convolutional neural network', 'Feature extraction', 'Machine learning', 'Multi-layer perceptron', 'Voltage signature data', 'Weld beads', 'Wire-arc additive manufacturing']",,"In the wire-arc additive manufacturing (WAAM) process, which creates metal layers with weld beads, it is important to detect weld bead defects and resolve them properly and timely. In this paper, we propose a machine learning approach for automatically detecting weld bead defects based on voltage signature data captured during the WAAM process. We adopt multi-layer perceptron (MLP) and convolutional neural network (CNN) as machine learning models, and consider three types of beads: normal bead, abnormal bead with balling effects, and abnormal bead with cuts. After capturing voltage signatures while building weld beads, we separated each voltage signature into 17 to 19 segments, from each of which a set of features are extracted. We then constructed training and test data with feature datasets. We built total 75 voltage signatures: 45 for normal beads, 15 for abnormal beads with balling effects, and 15 for abnormal beads with cuts. After training the MLP and CNN models using TensorFlow, we tested and compared their performance. We found that the two types of models works well even though the amount of data used is small, but the CNN models are more appropriate for real-time detection of weld bead defects."
Multi Label Deep Learning classification approach for False Data Injection Attacks in Smart Grid,2021,"['Deep learning', 'False Data Injection Attack', 'Internet of Things', 'Machine learning', 'Multi-label Classification', 'Power System', 'Smart grid']",,"The smart grid replaces the traditional power structure with information inventiveness that contributes to a new physical structure. In such a field, malicious information injection can potentially lead to extreme results. Incorrect, FDI attacks will never be identified by typical residual techniques for false data identification. Most of the work on the detection of FDI attacks is based on the linearized power system model DC and does not detect attacks from the AC model. Also, the overwhelming majority of current FDIA recognition approaches focus on FDIA, whilst significant injection location data cannot be achieved. Building on the continuous developments in deep learning, we propose a Deep Learning based Locational Detection technique to continuously recognize the specific areas of FDIA. In the development area solver gap happiness is a False Data Detector (FDD) that incorporates a Convolutional Neural Network (CNN). The FDD is established enough to catch the fake information. As a multi-label classifier, the following CNN is utilized to evaluate the irregularity and cooccurrence dependency of power flow calculations due to the possible attacks. There are no earlier statistical assumptions in the architecture proposed, as they are ""model-free."" It is also ""cost-accommodating"" since it does not alter the current FDD framework and it is only several microseconds on a household computer during the identification procedure. We have shown that ANN-MLP, SVM-RBF, and CNN can conduct locational detection under different noise and attack circumstances through broad experience in IEEE 14, 30, 57, and 118 bus systems. Moreover, the multi-name classification method used successfully improves the precision of the present identification."
이미지 데이터에 대한 비선형 분류 방법의 비교,2021,"['지지벡터기계', '지지행렬기계', '커널', '합성곱 신경망', 'Convolutional neural network', 'kernel', 'support matrix machine', 'support vector machine']","이미지 분류는 기계학습에서 가장 활발하게 연구되고 있는 주제 중 하나이다. 이미지 데이터는 일반적으로 2차원 혹은 3차원 행렬 구조를 가지고 있으며, 지지벡터기계 등 전통적인 분류 기법을 적용하기 위해 벡터화를 시행하게 된다. 하지만 벡터화는 이미지 데이터가 제공하는 구조적 정보를 무시할 수 있다. 구조적 정보를 이용하는 합성곱 신경망은 이러한 단점을 보완하기 위해 도입되었으나, 합성곱 신경망을 포함하는 신경망은 일반적으로 많은 데이터를 요구한다. 반면 지지벡터기계는 적은 수의 표본에서도 상대적으로 안정적인 분류 성능을 보일 뿐만 아니라 지지행렬기계 및 커널 지지행렬기계로 확장됨으로써 이미지 데이터의 구조적 정보도 반영할 수 있게 되었다. 본 논문에서는 표본의 개수가 상대적으로 적은 이미지 데이터에 대하여 비선형 분류 방법인 지지벡터기계, 커널 지지행렬기계, 그리고 합성곱 신경망의 예측 성능을 비교하고 선형 분류 방법이지만 이미지 데이터의 구조적 정보를 반영하는 지지행렬기계도 함께 비교한다.","Image classification is one of the most actively studied topics in machine learning. Image data generally has a two-dimensional or three-dimensional matrix structure, and vectorization is performed to apply traditional classification techniques such as support vector machine (SVM). However, vectorization may ignore the structural information provided by image data. Convolutional neural network (CNN) using structural information has been introduced as a remedy to the drawback, but neural networks including CNN generally require a lot of data. On the other hand, SVM shows stable classification performances even with a small number of samples, and extensions of SVM reflecting structural information such as support matrix machine (SMM) and kernel support matrix machine (KSMM) have been recently proposed. In this paper, we compare the predictive performances of SVM, SMM, KSMM, and CNN on image data with relatively small number of samples."
Implementation of Low-cost Autonomous Car for Lane Recognition and Keeping based on Deep Neural Network model,2021,"['Deep Neural Network', 'Low cost', 'Autonomous car', 'Lane detection', 'Lane Keeping']",,"CNN (Convolutional Neural Network), a type of deep learning algorithm, is a type of artificial neural network used to analyze visual images. In deep learning, it is classified as a deep neural network and is most commonly used for visual image analysis. Accordingly, an AI autonomous driving model was constructed through real-time image processing, and a crosswalk image of a road was used as an obstacle. In this paper, we proposed a low-cost model that can actually implement autonomous driving based on the CNN model. The most well-known deep neural network technique for autonomous driving is investigated and an end-to-end model is applied. In particular, it was shown that training and self-driving on a simulated road is possible through a practical approach to realizing lane detection and keeping"
자율주행용 임베디드 플랫폼 탑재를 위한 YOLOv4 기반 객체탐지 경량화 모델 개발,2021,"['Compressed CNN(경량화 CNN 모델)', 'Compressed object detection(경량화 객체탐지)', 'Autonomous driving(자율주행)', 'Embedded GPU(임베디드 GPU)', 'YOLOv4']",,
Deep convolutional neural networks based ECG beats classifi cation to diagnose cardiovascular conditions,2021,"['ECG', 'CNN', 'VGG16', 'ECG beats classifi cation', 'SHAP value', 'ECG frequencies']",,"Medical practitioners need to understand the critical features of ECG beats to diagnose and identify cardiovascular conditionsaccurately. This would be greatly facilitated by identifying the signifi cant features of frequency components in temporalECG wave-forms using computational methods. In this study, we have proposed a novel ECG beat classifi er based ona customized VGG16-based Convolution Neural Network (CNN) that uses the time-frequency representation of temporalECG, and a method to identify the contribution of interpretable ECG frequencies when classifying based on the SHapleyAdditive exPlanations (SHAP) values. We applied our model to the MIT-BIH arrhythmia dataset to classify the ECG beatsand to characterise of the beats frequencies. This model was evaluated with two advanced time-frequency analysis methods.Our results indicated that for 2-4 classes our proposed model achieves a classifi cation accuracy of 100% and for 5 classes itachieves a classifi cation accuracy of 99.90%. We have also tested the proposed model using premature ventricular contractionbeats from the American Heart Association (AHA) database and normal beats from Lobachevsky University Electrocardiographydatabase (LUDB) and obtained a classifi cation accuracy of 99.91% for the 5-classes case. In addition, SHAP valueincreased the interpretability of the ECG frequency features. Thus, this model could be applicable to the automation of thecardiovascular diagnosis system and could be used by clinicians."
Improvement of Vocal Detection Accuracy Using Convolutional Neural Networks,2021,"['Vocal Detection', 'CNN', 'Ensemble Learning']",,"Vocal detection is one of the fundamental steps in musical information retrieval. Typically, the detection process consists of feature extraction and classification steps. Recently, neural networks are shown to outperform traditional classifiers. In this paper, we report our study on how to improve detection accuracy further by carefully choosing the parameters of the deep network model. Through experiments, we conclude that a feature-classifier model is still better than an end-to-end model. The recommended model uses a spectrogram as the input plane and the classifier is an 18-layer convolutional neural network (CNN). With this arrangement, when compared with existing literature, the proposed model improves the accuracy from 91.8% to 94.1% in Jamendo dataset. As the dataset has an accuracy of more than 90%, the improvement of 2.3% is difficult and valuable. If even higher accuracy is required, the ensemble learning may be used. The recommend setting is a majority vote with seven proposed models. Doing so, the accuracy increases by about 1.1% in Jamendo dataset."
손동작을 이용한 실시간 로봇 팔 제어 임베디드 시스템,2021,"['embedded board', 'CNN', 'image processing', 'hand gesture', 'ROS', 'robotic arm']",,"Recently, HRI(Human-Robot Interaction) technology which has become increasingly important in the field of robotic has used hand gestures as communication means for robot control. Various studies are being researched to classify hand gestures using images and biological signals. In this paper, we propose a system that controls the robotic arm in real-time by classifying hand gestures using images in an embedded board environment. The proposed system consists of pre-processing the image data captured by the webcam, classifying it using CNN(Convolutional Neural Network) model, and controlling the robotic arm using ROS(Robot Operating System) in an embedded board environment. The performance of the system is evaluated based on experiments measuring the classification accuracy of the trained model, real-time robot control accuracy and the delay. Through these experiments, the high accuracy and fast processing speed of the proposed system are confirmed."
다중 RGB Depth 카메라 및 합성곱 신경망을 이용한 6축 매니퓰레이터의 파지 알고리즘에 관한 연구,2021,"['visual servoing', 'CNN', 'manipulator', 'pick-and-place', 'image processing']",,"In this paper, we propose a gripping algorithm for a 6-axis manipulator using two RGB depth cameras and a convolutional neural network (CNN). The proposed algorithm infers and locates an object through an RGB depth camera located in the working space, and then grasps the object through an RGB depth camera mounted on the manipulators end-effector. Then, by calculating the rotation angle and direction of the object, a gripping position is searched and a pick-and-place operation is performed. As a result of the experiments, the proposed algorithm showed that the gripping and pick-and-place motion were normally performed according to the shape of the object when a previously learned rectangular box and cylindrical object were detected."
Korean Sentiment Analysis Using Natural Network: Based on IKEA Review Data,2021,"['NLP', 'Word2Vec', 'CNN', 'RNN', 'LSTM', 'GRU', 'BiLSTM', 'BiGRU']",,"In this paper, we find a suitable methodology for Korean Sentiment Analysis through a comparative experiment in which methods of embedding and natural network models are learned at the highest accuracy and fastest speed. The embedding method compares word embeddeding and Word2Vec. The model compares and experiments representative neural network models CNN, RNN, LSTM, GRU, Bi-LSTM and Bi-GRU with IKEA review data. Experiments show that Word2Vec and BiGRU had the highest accuracy and second fastest speed with 94.23% accuracy and 42.30 seconds speed. Word2Vec and GRU were found to have the third highest accuracy and fastest speed with 92.53% accuracy and 26.75 seconds speed."
딥러닝 기반 분류 모델의 성능 분석을 통한 건설 재해사례 텍스트 데이터의 효율적 관리방향 제안,2021,"['Construction Safety', 'CNN', 'Deep Learning', 'Classification Model', 'Disaster Data', '건설 안전', 'CNN', '딥러닝', '분류 모델', '재해 데이터']",,"This study proposes an efficient management direction for Korean construction accident cases through a deep learning-based text data classification model. A deep learning model was developed, which categorizes five categories of construction accidents: fall, electric shock, flying object, collapse, and narrowness, which are representative accident types of KOSHA. After initial model tests, the classification accuracy of fall disasters was relatively high, while other types were classified as fall disasters. Through these results, it was analyzed that 1) specific accident-causing behavior, 2) similar sentence structure, and 3) complex accidents corresponding to multiple types affect the results. Two accuracy improvement experiments were then conducted: 1) reclassification, 2) elimination. As a result, the classification performance improved with 185.7% when eliminating complex accidents. Through this, the multicollinearity of complex accidents, including the contents of multiple accident types, was resolved. In conclusion, this study suggests the necessity to independently manage complex accidents while preparing a system to describe the situation of future accidents in detail."
전기화재 원인분석을 위한 용융흔 외형 판별 딥러닝 알고리즘 설계,2021,"['전기 화재', '단락흔', '열흔', 'CNN', 'Resnet 알고리즘', 'Electric fire', 'Arc beads', 'Molten mark', 'CNN', 'Resnet']",,
딥러닝 알고리즘 기반의 초미세먼지(PM2.5) 예측 성능 비교 분석,2021,"['딥런닝', '초미세먼지(PM2.5)', 'CNN', 'LSTM', 'GAN', '시계열데이터', 'Deep Learning', 'Fine particulate Matter(PM2.5)', 'Convolutional Neural Network', 'Long Short-Term Memory', 'Generative Adversarial Networks', 'Time Series Data']",,
딥러닝과 의미론적 영상분할을 이용한 자동차 번호판의 숫자 및 문자영역 검출,2021,"['딥러닝', '합성곱 신경망(CNN)', '의미론적 분할', '자동차 번호판', '영상분할 및 인식', 'Deep Learning', 'Convolution Neural Network(CNN)', 'Semantic Segmentation', 'License Plate', 'Image Segmentation and Recognition']","자동차 번호판 인식은 지능형 교통시스템에서 핵심적인 역할을 담당한다. 따라서 효율적으로 자동차 번호판의 숫자 및 문자영역을 검출하는 것은 매우 중요한 과정이다. 본 연구에서는 딥러닝과 의미론적 영상분할 알고리즘을 적용 하여 효과적으로 자동차 번호판의 번호영역을 검출하는 방법을 제안한다. 제안된 방법은 화소 투영과 같은 전처리과정 없이 번호판 영상에서 바로 숫자 및 문자영역을 검출하는 알고리즘이다. 번호판 영상은 도로 위에 설치된 고정 카메라로 부터 획득한 영상으로 날씨 및 조명변화 등을 모두 포함한 다양한 실제 상황에서 촬영된 것을 사용하였다. 입력 영상은 색상변화를 줄이기 위해 정규화하고 실험에 사용된 딥러닝 신경망 모델은 Vgg16, Vgg19, ResNet18 및 ResNet50이 다. 제안방법의 성능을 검토하기 위해 번호판 영상 500장으로 실험하였다. 학습을 위해 300장을 할당하였으며 테스트용 으로 200장을 사용하였다. 컴퓨터모의 실험결과 ResNet50을 사용할 때 가장 우수하였으며 95.77% 정확도를 얻었다.","License plate recognition plays a key role in intelligent transportation systems. Therefore, it is a very important process to efficiently detect the number and character areas. In this paper, we propose a method to effectively detect license plate number area by applying deep learning and semantic image segmentation algorithm. The proposed method is an algorithm that detects number and text areas directly from the license plate without preprocessing such as pixel projection. The license plate image was acquired from a fixed camera installed on the road, and was used in various real situations taking into account both weather and lighting changes. The input images was normalized to reduce the color change, and the deep learning neural networks used in the experiment were Vgg16, Vgg19, ResNet18, and ResNet50. To examine the performance of the proposed method, we experimented with 500 license plate images. 300 sheets were used for learning and 200 sheets were used for testing. As a result of computer simulation, it was the best when using ResNet50, and 95.77% accuracy was obtained."
실시간 채팅 환경에서 문장 분석을 이용한 대상자 및 비속어 검출,2021,"['Target Recognition', 'Swear Detection', 'CNN', 'Telegram', 'Plug-in']",,"By the increase of internet usage, communicating online became an everyday thing. Thereby various people have experienced profanity by anonymous users. Nowadays lots of studies tried to solve this problem using artificial intelligence, but most of the solutions were for non-real time situations. In this paper, we propose a Telegram plugin that detects swear words using word2vec, and an algorithm to find the target of the sentence. We vectorized the input sentence to find connections with other similar words, then inputted the value to the pre-trained CNN (Convolutional Neural Network) model to detect any swears. For target recognition we proposed a sequential algorithm based on KoNLPY."
문화재 관리를 위한 지능형 플랫폼 방안 연구,2021,"['문화재', 'IoT', '빅데이터', '심층신경망(DNN)', '합성곱신경망(CNN)', 'Cultural Property', 'IoT', 'Big Data', 'Deep Neural Network', 'Convolution Neural Network']",,"Recently, with the rapid development of IoT technology, the issue of Intelligent Platforms for managing Cultural Properties is increasing. In order to develop an Intelligent Platform for Cultural Property management, Sensors can be installed to collect and analyze internal and external state data of Cultural Properties, and predict with Big Data analysis using Artificial Intelligence algorithms. This Study proposes an external and internal intelligent integrated platform research method based on IoT technology for maintenance and safety management of Cultural Properties. In the proposed Intelligent Platform, a Deep Neural Network (DNN) learning algorithm was proposed to analyze and predict the tilt Sensor data and the Meteorological Agency data considering changes in the external environment as external data of Cultural Properties. In addition, we propose a Convolutional Neural Network (CNN) learning algorithm to analyze and predict image data for detecting pests as internal data of Cultural Properties."
Model for the Identification and Classification of Partially Damaged and Vandalized Traffic Signs,2021,"['Convolutional Neural Networks', 'Detection', 'Classification', 'Damaged traffic signs', 'Vandalized traffic signs']",,"The development of Convolutional Neural Networks (CNN) has expanded with the accelerated progress of IT, as well as with the needs of the autonomous vehicle (AV) implementation. The specifics and requirements of AV towards the infrastructure primarily relate to the condition and quality of traffic signs. For the independent participation of these vehicles in traffic, an impeccable traffic sign condition is required, which is often not the case in practice. Damaged, faded, obscured, or vandalized traffic signs can usually be seen in the road network, which can impede the movement of AV in traffic. In the existing literature, little or very little attention is focused on the problem of identifying and classifying damaged and especially vandalized traffic signs. In this paper, the mentioned problem is addressed, and the CNN model is proposed. This model has been tested on a specially designed novel and challenging database containing 6,000 real-time images of traffic signs in the road network of the Republic of Serbia. This model is invariant to different lighting and weather (nighttime and fog) conditions. In this case study, the model reached an overall accuracy of 99.17%, whereby all vandalized and damaged traffic signs are accurately identified and classified."
실제 GPS L1 C/A 신호에 대한 기계학습 기반 재밍 신호 식별 기법,2021,"['GPS', 'Jamming', 'Machine Learning', 'SVN', 'CNN', 'Classification']",,"In this paper, we propose a CNN (Convolution Neural Network)-based jamming signal classification scheme, which is a representative machine learning model that can effectively classify real GPS L1 C/A (Coarse/Acquisition) signal and five jamming signals generated in real time with our own experimental equipment. As a result of the experiment, the highest average classification accuracy of the conventional scheme is 95.29%, while the proposed scheme is 98.23%, showing a 2.94%P higher classification accuracy than the conventional scheme. In addition, the conventional scheme has a maximum difference of 9.66%P in classification performance for each jamming signal, whereas the proposed method is a more robust jamming classification scheme with a maximum of 3.03%P."
Building Energy Time Series Data Mining for Behavior Analytics and Forecasting Energy consumption,2021,"['ehavioral Analytics', 'Big Data Mining', 'Clustering Analysis', 'CNN', 'Energy Consumption', 'Energy Prediction', 'LSTM']",,"The significant aim of this research has always been to evaluate the mechanism for efficient and inherently aware usage of vitality in-home devices, thus improving the information of smart metering systems with regard to the usage of selected homes and the time of use. Advances in information processing are commonly used to quantify gigantic building activity data steps to boost the activity efficiency of the building energy systems. Here, some smart data mining models are offered to measure, and predict the time series for energy in order to expose different ephemeral principles for using energy. Such considerations illustrate the use of machines in relation to time, such as day hour, time of day, week, month and year relationships within a family unit, which are key components in gathering and separating the effect of consumers behaviors in the use of energy and their pattern of energy prediction. It is necessary to determine the multiple relations through the usage of different appliances from simultaneous information flows. In comparison, specific relations among interval-based instances where multiple appliances use continue for certain duration are difficult to determine. In order to resolve these difficulties, an unsupervised energy time-series data clustering and a frequent pattern mining study as well as a deep learning technique for estimating energy use were presented. A broad test using true data sets that are rich in smart meter data were conducted. The exact results of the appliance designs that were recognized by the proposed model were filled out by Deep Convolutional Neural Networks (CNN) and Recurrent Neural Networks (LSTM and GRU) at each stage, with consolidated accuracy of 94.79%, 97.99%, 99.61%, for 25%, 50%, and 75%, respectively."
End-to-end Automatic Sleep Staging Algorithm using Convolution Neural Network and Bidirectional LSTM,2021,"['Sleep stages', 'Automatic classification', 'EEG', '1D-CNN', 'bi-LSTM']",,"In order to measure sleep quality, sleep experts manually classify sleep stages through polysomnography (PSG) signals. However, it is time-consuming and labor-intensive work. Thus, automatic sleep stage classification methods are needed. In this study, we propose an end-to-end automatic sleep staging algorithm using a one-dimensional convolutional neural network (1DCNN) based on an inception network and bidirectional long short-term memory (bi-LSTM). First, a feature map was extracted from input data using the 1D-CNN architecture without preprocessing. Secondly, bi-LSTM learned a stage transition rule using the feature maps. In addition, we used the sleep-EDF public dataset to evaluate our model, and only one channel of EEG signal was used to save computational cost. The accuracy and macro-averaged F1 score of the classification performance were 85.05% and 79.05%, respectively. These results demonstrate state-of-the-art performance compared to previous studies using the same dataset, yielding an effective method for an automatic sleep staging algorithm."
Spectrogram Based Detection Algorithm for Back-Bead in Gas Metal Arc Welding Process using Convolution Neural Network,2021,"['Gas metal arc welding', 'Convolution neural network (CNN)', 'Short time fourier transform (STFT)', 'Time-frequency domain analysis', 'Back-bead generation prediction']",,"An automated welding system is essential to ensure a stable and good welding quality and improve productivity in the gas metal arc welding (GMAW) process. Therefore, various studies have been conducted on the establishment of smart factories and the demand for good weldability in the fields of production and manufacturing. In shipbuilding welding and pipe welding, the uniformly generated back-bead is an important criterion for judging the mechanical properties and weldability of the welded structure, and is also an important factor that enables the realization of an automated welding system. Therefore, in this study, the welding current signal measured in real-time in the GMAW process was pre-processed by a short time Fourier transform (STFT) to obtain a time-frequency domain feature image (spectrogram). Based on this, a back-bead generation detection algorithm was developed. To accelerate the training speed of the proposed convolution neural network (CNN) model, we used non-saturating neurons and a highly efficient GPU implementation of the convolution operation. As a result of applying the proposed detection model to actual welding process, the detection accuracies with and without the back-bead regions were 95.8% and 94.2%, respectively, which confirmed the excellent classification performance for back-bead generation."
드론 탐지 및 분류를 위한 레이다 영상 기계학습 활용,2021,"['레이다', 'ISAR', '마이크로 도플러', '기계학습', 'CNN', 'Radar', 'ISAR', 'Micro-doppler', 'Machine learning', 'CNN']","최근 드론은 가격 하락, 소형화와 함께 높은 기술 발전에 힘입어 드론 보급이 민군에 걸쳐 증가하면서 보안안전사고, 치안‧안보 위협 등의 문제를 유발할 가능성도 커지고 있다. 드론으로 인해 발생하는 사건 및 사고를 예방하기 위해서는 드론의 출현에 대응할 수 있는 탐지 기술이 우선적으로 선행되어야 한다. 드론은 크기가 작고 전파 반사도가 낮은 재질로 구성되어 있어 음향, 적외선, 레이다의 운용만으로는 탐지가 어렵다. 최근 영상 식별 성능을 강화하기 위해 레이다 신호에 인공지능을 접목한 연구사례가 증가하는 추세이다. 본 논문에서는 레이다 영상을 이용한 드론 탐지 기술을 소개하며, 드론의 모의실험 데이터와 실제 실험 데이터를 기반으로 인공지능 기술에 적용하여 드론의 분류 정확도를 효과적으로 입증하였다.","Recent advance in low cost and light-weight drones has extended their application areas in both military and private sectors. Accordingly surveillance program against unfriendly drones has become an important issue. Drone detection and classification technique has long been emphasized in order to prevent attacks or accidents by commercial drones in urban areas. Most commercial drones have small sizes and low reflection and hence typical sensors that use acoustic, infrared, or radar signals exhibit limited performances. Recently, artificial intelligence algorithm has been actively exploited to enhance radar image identification performance. In this paper, we adopt machined learning algorithm for high resolution radar imaging in drone detection and classification applications. For this purpose, simulation is carried out against commercial drone models and compared with experimental data obtained through high resolution radar field test."
Lost gamma source detection algorithm based on convolutional neural network,2021,"['Conventional neural network', 'Lost gamma source', 'GEANT4', 'Energy deposition']",,"Based on the convolutional neural network (CNN), a novel technique is investigated for lost gamma source detection in a room. The CNN is trained with the result of a GEANT4 simulation containing a gamma source inside a meshed room. The dataset for the training process is the deposited energy in the meshes of different n-step paths. The neural network is optimized with parameters such as the number of input data and path length. Based on the proposed method, the place of the gamma source can be recognized with reasonable accuracy without human intervention. The results show that only by 5 measurements of the energy deposited in a 5-step path, (5 sequential points 50 cm apart within 1600 meshes), the gamma source location can be estimated with 94% accuracy. Also, the method is tested for the room geometry containing the interior walls. The results show 90% accuracy with the energy deposition measurement in the meshes of a 5-step path."
저복잡도를 위한 합성곱 신경망 기반의 적응형 4D-8PSK-TCM,2021,"['satellite communications', '4D-8PSK-TCM', 'T-algorithm', 'CNN']",,
HSV 컬러 모델 및 코너 검출 알고리즘을 이용한 딥러닝 기반의 화염 감지에 관한 연구,2021,"['Artificial intelligence', 'Deep learning', 'HSV color model', 'Corner detection algorithm', 'CNN']","최근 딥러닝 기법을 이용한 이미지 분류 모델이나 객체 감지 모델이 많이 연구되고 있지만 적절한 전처리 방법을설계하지 않을 경우 성능 평가 결과 낮은 정확도를 얻을 수 있다. 따라서 본 연구에서 제안하는 효과적인 화염검출전처리 방법으로는 HSV 컬러 모델과 Harris 코너 검출 알고리즘을 적용한 이미지 전처리 방법이다. HSV 컬러 모델을 통해 화염이 존재하는 색상영역을 필터링하고, 필터링된 결과물에 대해 Harris 코너 검출 방법을 적용할 경우 화염 이미지의 거친 질감 특성 때문에 화염 주변에 집중적으로 코너가 검출되게 된다. 이러한 특성을 통해 코너가 다수발생한 영역을 관심영역으로 검출하여 딥러닝 기반의 합성곱신경망(Convolutional neural network, CNN) 모델을 통해최종적으로 화염 여부를 분류하도록 하였다. 그 결과 본 연구에서 제안한 모델의 화염 검출 결과 정확도는 97.5%정밀도는 97%로 나타났다.","Recently, many image classification or object detection models that use deep learning techniques have been studied;however, in an actual performance evaluation, flame detection using these models may achieve low accuracy. Therefore,the flame detection method proposed in this study is image pre-processing with HSV color model conversion and the Harriscorner detection algorithm. The application of the Harris corner detection method, which filters the output from the HSVcolor model, allows the corners to be detected around the flame owing to the rough texture characteristics of the flameimage. These characteristics allow for the detection of a region of interest where multiple corners occur, and finally classifythe flame status using deep learning-based convolutional neural network models. The flame detection of the proposed modelin this study showed an accuracy of 97.5% and a precision of 97%."
고해상도 정사영상을 이용한 딥러닝 기반의 산림수종 분류에 관한 연구,2021,"['딥러닝', '컨볼루션 신경망', '드론', '정사영상', '수종분류', 'Deep learning', 'CNN', 'Drone', 'Orthophoto', 'Species classification']",,"In this study, we evaluated the accuracy of deep learning-based tree species classification model trained by using high-resolution images. We selected five species classed, i.e., pine, birch, larch, korean pine, mongolian oak for classification. We created 5,000 datasets using high-resolution orthophoto and forest type map. CNN deep learning model is used to tree species classification. We divided training data, verification data, and test data by a 5:3:2 ratio of the datasets and used it for the learning and evaluation of the model. The overall accuracy of the model was 89%. The accuracy of each species were pine 95%, birch 89%, larch 80%, korean pine 86% and mongolian oak 98%."
스마트 공장의 품질예측을 위한 딥러닝 모델 적용 연구 - 플라스틱 사출공정을 중심으로,2021,"['Smart Factory', 'Plastic Injection Molding', 'Quality Prediction', 'Deep Leaning', 'DAE', 'LSTM', 'CNN']","스마트공장의 고도화된 기술들을 통해 산업 현장에서 생성되는 무수히 많은 데이터를 기반으로 공정 내에 발생하는 문제의 원인을 분석하고 탐색하는 것이 실시간으로 가능하며, 이러한 데이터를 바탕으로 효율적인 의사결정을 할 수 있게 된다. 본 연구에서는 플라스틱 사출성형 공정 내 센서들에서 생성되는 총 36개의 제조조건 데이터 학습을 통해 제품의 품질을 예측하는 것을 목표로 한다. 품질 예측을 위한 딥러닝 모델은 잡음 제거 오토인코더, 장 · 단기 기억신경망, 합성곱 신경망을 적용하였다. 학습 데이터 셋은 KAMP(Korea AI Manufacturing Platform)를 통해 수집하였고 모두 양품과 불량품에 대한 레이블링이 되어있다. 각 모델별 파라미터를 달리하여 성능을 평가하였으며, 각 모델을 비교 · 분석하여 좋은 성능을 내는 모델과 파라미터 셋을 혼동행렬 및 f1-score를 활용하여 성능을 평가하였다. 본 연구에서 제안한 딥러닝 모델에 기반을 둔 사출공장 품질예측 시스템은 사출기계로부터 실시간 취합되는 센서 데이터 셋을 이용하여 공정조건 변화에 따른 품질을 예측하게 함으로써 품질 신뢰도를 향상하고 공정 품질검사 투입인력을 절감할 수 있을 것으로 기대한다.","When it comes to smart factories technology, the analysis, and exploration of the causes of problems in the processes can be made in real-time, based on the myriad data gathered from manufacturing facilities, and efficient decisions can be made based on these data. We conducted a study to predict the quality of products through the analysis of sensor data from the plastic injection molding process. We utilized a denoising autoencoder (DAE), long-shot memory network (LSTM), and a convolutional neural network (CNN) to formulate deep learning models for quality prediction. The training data set was collected through KAMP (Korea AI Manufacturing Platform) and the information regarding defects was labeled. Performance was evaluated by different parameters for each model and compared using two measures such as the confusion matrix and f1-score. A quality prediction system based on deep learning models for an injection molding factory makes it possible to accurately predict the quality according to a change in process conditions by utilizing the sensor data set gathered from the machines. We can therefore expect an improvement in quality and reliability and a reduction of the input manpower for process quality inspection."
컬러 이미지 분석을 통한 블랙 아이스 검출 방법 연구,2021,"['Black ice', 'Artificial intelligence(AI)', 'Deep learning', 'Convolutional Neural Networks(CNN)', 'image classification']","현재 개발중인 그리고 운행중인 대부분의 자동차에는 다양한 IoT 센서들이 탑재되어 있지만, 자동차 사고를 일으키는 요인 중 몇몇 요인들은 상대적으로 탐지하기 힘들다. 이러한 요소 중 대표적인 위험 요인 중 하나가 블랙 아이스이다. 블랙 아이스는 블랙 아이스가 깔린 부분을 지나가는 모든 차량에 영향을 줄 수 있어 대형 사고를 유발할 가능성이 가장 높은 요인 중 하나이다. 따라서 대형 사고를 막기 위해 블랙 아이스 검출 기법은 꼭 필요하다. 이를 위해 몇몇 연구가 과거 진행되었으나 몇몇 부분에서 현실적이지 않는 요소들이 반영된 경우가 있어, 이를 보충하기 위한 연구가 필요하다. 본 논문에서는 CNN 기법으로 컬러 이미지를 분석하여 블랙 아이스를 탐지하고자 하였으며, 일정 수준의 블랙 아이스 탐지에 성공하였다. 다만 기존 연구 와 차이가 있어 그 이유를 분석하였다.",
OFDM 신호에 대한 스펙트럼 센싱 기술,2021,"['OFDM', 'Cyclostationary', 'Spectral Correlation Function', 'FFT Accumulation Method', 'CNN']","본 논문은 기계학습에 기반을 둔 OFDM 신호를 탐지하는 알고리즘을 개발한 결과다. 스펙트럼 탐지 기술은 주파수 자원을 효율적으로 이용할 수 있는 인지 무선통신의 핵심 기술이다. 최근 무선통신시스템에서 송수신되는 신호는 OFDM을 기반으로 하고 있다. OFDM 신호는 채널 보정을 위해 파일럿 신호를 포함하고 있는데, 스펙트럼 상관 함수(SCF)를 사용하여 이를 검출할 수 있다. 이 과정에서 효율적인 SCF 연산을 위해 FAM 알고리즘이 사용되었다. 이렇게 구한 SCF를 입력 데이터로 하는 CNN 신경망 방식의 기계학습 알고리즘을 통해 OFDM 신호의 유무를 판단한다. 기계학습을 위한 학습 데이터는 −20 dB～0 dB의 SNR을 갖는 OFDM 신호의 SCF 값이 사용되었다. 학습 후 최적화한 신경망의 성능을 평가한 결과, SNR이 −12 dB인 수신 신호에 대해 오경보 확률 0.08 조건에서 0.9 확률로 신호를 탐지하였다.","This paper presents a machine learning (ML) algorithm to detect orthogonal frequency-division multiplexing (OFDM) signals. Spectrum sensing is a key technology in cognitive radio communication, which enhances spectral efficiency. Recently, signals  transmitted and received by wireless communication systems have been based on OFDM. These signals contain a pilot signal for channel calibration, which can be detected using a spectral correlation function (SCF). In this process, the FAM algorithm is applied for efficient SCF operation herein. The existence of OFDM signals is determined through a convolutional neural network-based ML algorithm using the SCF as input data. The learning data for ML use the SCF values for OFDM signals with signal-to-noise ratios (SNRs) of -20 to 0 dB. Consequently, on evaluation of the post-learning optimized neural network performance, signals were detected with a probability of 0.9 at the condition of 0.08 false alarm probability for reception signals with SNRs of -12 dB."
제조 설비 이상탐지를 위한 지도학습 및 비지도학습 모델 설계에 관한 연구,2021,"['센서 데이터', '고장 예측 및 이상탐지', 'XGBoost', 'LightGBM', 'CNN', 'MD', 'AE', 'LSTM-AE', 'Sensor data', 'Fault and Anomaly Detection']",,"In the era of the 4th industrial revolution, smart factories have received great attention, where production and manufacturing technology and ICT converge. With the development of IoT technology and big data, automation of production systems has become possible. In the advanced manufacturing industry, production systems are subject to unscheduled performance degradation and downtime, and there is a demand to reduce safety risks by detecting and reparing potential errors as soon as possible. This study designs a model based on supervised and unsupervised learning for detecting anomalies.The accuracy of XGBoost, LightGBM, and CNN models was compared as a supervised learning analysis method. Through the evaluation index based on the confusion matrix, it was confirmed that LightGBM is most predictive (97%). In addition, as an unsupervised learning analysis method, MD, AE, and LSTM-AE models were constructed. Comparing three unsupervised learning analysis methods, the LSTM-AE model detected 75% of anomalies and showed the best performance. This study aims to contribute to the advancement of the smart factory by combining supervised and unsupervised learning techniques to accurately diagnose equipment failures and predict when abnormal situations occur, thereby laying the foundation for preemptive responses to abnormal situations. do."
딥러닝 기술을 이용한 캐비테이션 자동인식에 대한 연구,2021,"['Tip Vortex Cavitation(TVC', '날개 끝 보텍스 캐비테이션)', 'Cavitation Inception Speed(CIS', '캐비테이션 초생속력)', 'Convolution Neural Network(CNN', '합성곱 신경망)', 'Deep learning(딥러닝)', 'Image recognition(영상인식)']",,"The main source of underwater radiated noise of ships is cavitation generated by propeller blades. After the Cavitation Inception Speed (CIS), noise level at all frequencies increases severely. In determining the CIS, it is based on the results observed with the naked eye during the model test, however accuracy and consistency of CIS values are becoming practical issues. This study was carried out with the aim of developing a technology that can automatically recognize cavitation images using deep learning technique based on a Convolutional Neural Network (CNN). Model tests on a three-dimensional hydrofoil were conducted at a cavitation tunnel, and tip vortex cavitation was strictly observed using a high-speed camera to obtain analysis data. The results show that this technique can be used to quantitatively evaluate not only the CIS, but also the amount and rate of cavitation from recorded images."
얼굴인식 기술을 적용한 실종자 식별 시스템 설계 및 구현,2021,"['Face recognition', 'Image Processing', 'Key point extraction', 'Missing Person', 'Similarity', 'Mobile', '얼굴인식', '영상처리', '특징점 검출', '실종자', '유사도', '모바일']","본 논문에서는 비전 기술과 딥러닝 기반의 얼굴인식을 통해 실종자를 식별하는 방법을 제안하였다. 모바일 디바이스에서 전송된 원본 이미지에 대해 얼굴인식에 적합하도록 이미지를 전처리한 후, 얼굴인식의 정확도 향상을 위한 이미지 데이터 증식과 CNN 기반 얼굴학습 및 검증을 통해 실종자를 인식하였다. 본 논문의 구현 결과를 이용하여 가상의 실종자 이미지를 식별한 결과, 원본 데이터와 블러 처리한 데이터를 함께 학습한 모델의 성능이 가장 우수하게 나왔다. 또한 사전학습된 가중치를 사용한 학습 모델은 사용하지 않은 모델보다 높은 성능을 보였지만, 편향과 분산이 높게 나오는 한계를 확인할 수 있었다.","In this paper proposes a method of finding missing persons based on face-recognition technology and deep learning. In this paper, a real-time face-recognition technology was developed, which performs face verification and improves the accuracy of face identification through data fortification for face recognition and convolutional neural network(CNN)-based image learning after the pre-processing of images transmitted from a mobile device. In identifying a missing person’s image using the system implemented in this paper, the model that learned both original and blur-processed data performed the best. Further, a model using the pre-learned Noisy Student outperformed the one not using the same, but it has had a limitation of producing high levels of deflection and dispersion."
A Three-Dimensional Deep Convolutional Neural Network for Automatic Segmentation and Diameter Measurement of Type B Aortic Dissection,2021,"['Aortic dissection', 'Tomography', 'X-ray computed', 'Deep learning']",,"Objective: To provide an automatic method for segmentation and diameter measurement of type B aortic dissection (TBAD).Materials and Methods: Aortic computed tomography angiographic images from 139 patients with TBAD were consecutively collected. We implemented a deep learning method based on a three-dimensional (3D) deep convolutional neural (CNN) network, which realizes automatic segmentation and measurement of the entire aorta (EA), true lumen (TL), and false lumen (FL). The accuracy, stability, and measurement time were compared between deep learning and manual methods. The intra- and inter-observer reproducibility of the manual method was also evaluated.Results: The mean dice coefficient scores were 0.958, 0.961, and 0.932 for EA, TL, and FL, respectively. There was a linear relationship between the reference standard and measurement by the manual and deep learning method (r = 0.964 and 0.991, respectively). The average measurement error of the deep learning method was less than that of the manual method (EA, 1.64% vs. 4.13%; TL, 2.46% vs. 11.67%; FL, 2.50% vs. 8.02%). Bland-Altman plots revealed that the deviations of the diameters between the deep learning method and the reference standard were -0.042 mm (-3.412 to 3.330 mm), -0.376 mm (-3.328 to 2.577 mm), and 0.026 mm (-3.040 to 3.092 mm) for EA, TL, and FL, respectively. For the manual method, the corresponding deviations were -0.166 mm (-1.419 to 1.086 mm), -0.050 mm (-0.970 to 1.070 mm), and -0.085 mm (-1.010 to 0.084 mm). Intra- and inter-observer differences were found in measurements with the manual method, but not with the deep learning method. The measurement time with the deep learning method was markedly shorter than with the manual method (21.7 ± 1.1 vs. 82.5 ± 16.1 minutes, p < 0.001).Conclusion: The performance of efficient segmentation and diameter measurement of TBADs based on the 3D deep CNN was both accurate and stable. This method is promising for evaluating aortic morphology automatically and alleviating the workload of radiologists in the near future."
CAM 기반의 계층적 및 수평적 분류 모델을 결합한 운전자 부주의 검출 및 특징 영역 지역화,2021,"['Distracted Driver Detection', 'Convolutional Neural Networks', 'Class Activation Maps', 'Attention Area Localization', '운전자 부주의 검출', '합성곱신경망', 'CAM', 'Class Activation Map', '주의영역 지역화']",,"Driver negligence accounts for the largest proportion of the causes of traffic accidents, and research to detect them is continuously being conducted. This paper proposes a method to accurately detect a distracted driver and localize the most characteristic parts of the driver. The proposed method hierarchically constructs a CNN basic model that classifies 10 classes based on CAM in order to detect driver distration and 4 subclass models for detailed classification of classes having a confusing or common feature area in this model. The classification result output from each model can be considered as a new feature indicating the degree of matching with the CNN feature maps, and the accuracy of classification is improved by horizontally combining and learning them. In addition, by combining the heat map results reflecting the classification results of the basic and detailed classification models, the characteristic areas of attention in the image are found. The proposed method obtained an accuracy of 95.14% in an experiment using the State Farm data set, which is 2.94% higher than the 92.2%, which is the highest accuracy among the results using this data set. Also, it was confirmed by the experiment that more meaningful and accurate attention areas were found than the results of the attention area found when only the basic model was used."
Self-Attention을 적용한 문장 임베딩으로부터 이미지 생성 연구,2021,"['자연어 처리', '이미지 생성', '적대적 신경망', 'Natural Language Processing', 'Image generation', 'Generative Adversarial Network']","사람이 어떤 문장을 보고 그 문장에 대해 이해하는 것은 문장 안에서 주요한 단어를 이미지로 연상시켜 그 문장에 대해 이해한다. 이러한 연상과정을 컴퓨터가 할 수 있도록 하는 것을 text-to-image라고 한다. 기존 딥 러닝 기반 text-to-image 모델은 Convolutional Neural Network(CNN)-Long Short Term Memory(LSTM), bi-directional LSTM을 사용하여 텍스트의 특징을 추출하고, GAN에 입력으로 하여 이미지를 생성한다. 기존 text-to-image 모델은 텍스트 특징 추출에서 기본적인 임베딩을 사용하였으며, 여러 모듈을 사용하여 이미지를 생성하므로 학습 시간이 오래 걸린다. 따라서 본 연구에서는 자연어 처리 분야에서 성능 향상을 보인 어텐션 메커니즘(Attention Mechanism)을 문장 임베딩에 사용하여 특징을 추출하고, 추출된 특징을 GAN에 입력하여 이미지를 생성하는 방법을 제안한다. 실험 결과 기존 연구에서 사용되는 모델보다 inception score가 높았으며 육안으로 판단하였을 때 입력된 문장에서 특징을 잘 표현하는 이미지를 생성하였다. 또한, 긴 문장이 입력되었을 때에도 문장을 잘 표현하는 이미지를 생성하였다.","When a person sees a sentence and understands the sentence, the person understands the sentence by reminiscent of the main word in the sentence as an image. Text-to-image is what allows computers to do this associative process. The previous deep learning-based text-to-image model extracts text features using Convolutional Neural Network (CNN)-Long Short Term Memory (LSTM) and bi-directional LSTM, and generates an image by inputting it to the GAN. The previous text-to-image model uses basic embedding in text feature extraction, and it takes a long time to train because images are generated using several modules. Therefore, in this research, we propose a method of extracting features by using the attention mechanism, which has improved performance in the natural language processing field, for sentence embedding, and generating an image by inputting the extracted features into the GAN. As a result of the experiment, the inception score was higher than that of the model used in the previous study, and when judged with the naked eye, an image that expresses the features well in the input sentence was created. In addition, even when a long sentence is input, an image that expresses the sentence well was created."
Wavelet 기반의 영상 디테일 향상 잡음 제거 네트워크,2021,"['Image Denoising', 'Convolutional Neural Network', 'Wavelet Transform', 'Detail Enhancement']",,"Although the performance of cameras is gradually improving now, there are noise in the acquired digital images from the camera, which acts as an obstacle to obtaining high-resolution images. Traditionally, a filtering method has been used for denoising, and a convolutional neural network (CNN), one of the deep learning techniques, has been showing better performance than traditional methods in the field of image denoising, but the details in images could be lost during the learning process. In this paper, we present a CNN for image denoising, which improves image details by learning the details of the image based on wavelet transform. The proposed network uses two subnetworks for detail enhancement and noise extraction. The experiment was conducted through Gaussian noise and real-world noise, we confirmed that our proposed method was able to solve the detail loss problem more effectively than conventional algorithms, and we verified that both objective quality evaluation and subjective quality comparison showed excellent results."
Application of Statistical and Machine Learning Techniques for Habitat Potential Mapping of Siberian Roe Deer in South Korea,2021,"['Convolutional neural network algorithm', 'Frequency ratio method', 'Habitat potential map', 'Long short-term memory algorithm', 'Machine learning algorithms', 'Siberian roe deer']",,"The study has been carried out with an objective to prepare Siberian roe deer habitat potential maps in South Korea based on three geographic information system-based models including frequency ratio (FR) as a bivariate statistical approach as well as convolutional neural network (CNN) and long short-term memory (LSTM) as machine learning algorithms. According to field observations, 741 locations were reported as roe deer's habitat preferences. The dataset were divided with a proportion of 70:30 for constructing models and validation purposes. Through FR model, a total of 10 influential factors were opted for the modelling process, namely altitude, valley depth, slope height, topographic position index (TPI), topographic wetness index (TWI), normalized difference water index, drainage density, road density, radar intensity, and morphological feature. The results of variable importance analysis determined that TPI, TWI, altitude and valley depth have higher impact on predicting. Furthermore, the area under the receiver operating characteristic (ROC) curve was applied to assess the prediction accuracies of three models. The results showed that all the models almost have similar performances, but LSTM model had relatively higher prediction ability in comparison to FR and CNN models with the accuracy of 76% and 73% during the training and validation process. The obtained map of LSTM model was categorized into five classes of potentiality including very low, low, moderate, high and very high with proportions of 19.70%, 19.81%, 19.31%, 19.86%, and 21.31%, respectively. The resultant potential maps may be valuable to monitor and preserve the Siberian roe deer habitats."
Novel Image Classification Method Based on Few-Shot Learning in Monkey Species,2021,"['Deep learning', 'Feature extraction', 'Few-shot learning', 'Image classification']",,"This paper proposes a novel image classification method based on few-shot learning, which is mainly used to solve model overfitting and non-convergence in image classification tasks of small datasets and improve the accuracy of classification. This method uses model structure optimization to extend the basic convolutional neural network (CNN) model and extracts more image features by adding convolutional layers, thereby improving the classification accuracy. We incorporated certain measures to improve the performance of the model. First, we used general methods such as setting a lower learning rate and shuffling to promote the rapid convergence of the model. Second, we used the data expansion technology to preprocess small datasets to increase the number of training data sets and suppress over-fitting. We applied the model to 10 monkey species and achieved outstanding performances. Experiments indicated that our proposed method achieved an accuracy of 87.92%, which is 26.1% higher than that of the traditional CNN method and 1.1% higher than that of the deep convolutional neural network ResNet50."
인공지능 모델을 이용한 공작기계의 스핀들 고장 진단,2021,"['Fault Diagnosis(고장 진단)', 'Artificial Intelligence(인공지능)', 'Spindle(스핀들)']","정보통신기술(ICT)의 발전은 전통적인 제조 분야의 혁신을 가속화시키고 있고, 스마트팩토리로 불리우는 최첨단 공장에서는 각종 센서를 통해 실시간으로 데이터를 수집하고 있다. 이러한 수집된 데이터에 인공지능 기술을 적용하여 기계 고장 상황에 빠르게 대처하는 연구가 최근 들어 많은 관심을 받고 있다. 본 연구에서는 공작기계 스핀들의 고장 진단을 목적으로 인공지능 기술의 적용 가능성을 확인하기 위해 테스트벤치를 구축한 후 볼트를 이용하여 인위적으로 스핀들의 편심을 변화시킨 고장 데이터를 수집하였고, 분류(classification) 문제에 주로 사용되는 인공지능 모델 3종(CNN, LSTM, auto-encoder)을 학습하여 스핀들의 7가지 상태를 분류하는 정확도를 비교 분석하였다. 또한, 공작기계 도메인에 인공지능 기술을 효과적으로 적용하기 위해 필요한 데이터 수집 및 처리방법과 모델 개발 방법을 제안한다.","The development of information and communication technology (ICT) is accelerating innovation in the traditional manufacturing sector. The smart factory which is a state-of-the-art factory collects data in real time through various sensors. Recently, researches on applying the artificial intelligence technology to these collected data to detect machine failures has gained a lot of attention. In this study, we built a test bench to check the possibility of applying the artificial intelligence technology for the fault diagnosis of the spindle of machine tools. We collected failure data by changing the off-center of the spindle using bolts. Further, we used artificial intelligence models (CNN, LSTM, and auto-encoder) to analyze the accuracy of seven types of fault classifications. In addition, the method of data collection, data process, and model development is proposed to effectively apply the artificial intelligence technology to machine tool domains."
Codeless Deep Learning of COVID-19 Chest X-Ray Image Dataset with KNIME Analytics Platform,2021,"['COVID-19', 'Mass Chest X-Ray', 'Diagnosis', 'Computer Assisted', 'Deep Learning', 'KNIME']",,"Objectives: This paper proposes a method for computer-assisted diagnosis of coronavirus disease 2019 (COVID-19) throughchest X-ray imaging using a deep learning model without writing a single line of code using the Konstanz Information Miner(KNIME) analytics platform. Methods: We obtained 155 samples of posteroanterior chest X-ray images from COVID-19open dataset repositories to develop a classification model using a simple convolutional neural network (CNN). All of theimages contained diagnostic information for COVID-19 and other diseases. The model would classify whether a patient wasinfected with COVID-19 or not. Eighty percent of the images were used for model training, and the rest were used for testing.The graphic user interface-based programming in the KNIME enabled class label annotation, data preprocessing, CNNmodel training and testing, performance evaluation, and so on. Results: 1,000 epochs training were performed to test thesimple CNN model. The lower and upper bounds of positive predictive value (precision), sensitivity (recall), specificity, andf-measure are 92.3% and 94.4%. Both bounds of the model’s accuracies were equal to 93.5% and 96.6% of the area under thereceiver operating characteristic curve for the test set. Conclusions: In this study, a researcher who does not have basic knowledgeof python programming successfully performed deep learning analysis of chest x-ray image dataset using the KNIME independently.The KNIME will reduce the time spent and lower the threshold for deep learning research applied to healthcare."
전이학습기반 앙상블 딥러닝을 이용한 COVID-19 환자 영상 분류,2021,"['딥러닝', '스태킹 앙상블', '전이학습', 'X-ray/CT 영상', 'COVID-19', 'deep learning', 'stacking ensemble', 'transfer learning', 'X-ray/CT image']","COVID-19 팬데믹으로 인한 피해는 공중 보건적 측면 뿐 만 아니라 정치, 경제, 사회, 문화 전반에 심각한 영향을 미치고 있다. 현재까지 COVID-19 표준 진단검사인 RT-PCR 검사는 검체의 종류, 검체 채취 방법 및 보관에 따라 검사 결과가 달라질 수 있고 코로나바이러스 (SARS-CoV-2) 감염 후 검사 시점에도 영향을 받는다. 본 논문은 전이학습 (transfer learning) 기반 앙상블 딥러닝을 사용하여 COVID-19 환자 X-ray/CT 영상을 분류하고자 한다. 여기서 사용된 전이학습은 CNN (convolutional neural network) 기반인 AlexNet, ResNet, Inception V3, DenseNet 모형이다. 본 연구에서 제안한 스태킹 앙상블 (stacking ensemble) 모형은 세 단계에 걸쳐 이루어진다. 첫 번째 단계에서는 기본모형 (base model)로서 여러 전이학습 모형을 이용하여 예측된 결과들을 얻고, 두 번째 단계에서는 concatenate layer를 통해 이들 결과들을 결합한 다음, 세 번째 단계에서는 메타모형(meta model), 여기서는 DNN (deep neural network) 모형을 적용하여 최종 분류한다. 본 논문에서 제안된 앙상블 모형의 성능평가를 위해 3가지 실제 COVID-19 환자의 X-ray/CT 영상데이터셋을 고려하였으며 여러 가지 성능평가 지표를 가지고 기존의 전이학습 모형과 앙상블 모형과 비교 분석하였다. 성능실험결과, 전반적으로 제안된 앙상블 모형이 기존의 전이학습 모형과 앙상블 모형보다 우수함을 보였다.","The damage caused by the COVID-19 pandemic has a serious impact not only on public health but also on politics, economy, society, and culture as a whole. To date, the RT-PCR test, a COVID-19 standard diagnostic test, may vary depending on the type of sample, sample collection method, and storage, and is also affected by the time of the test after infection with COVID-19. This paper attempts to classify COVID-19 patients with X-ray/CT images using transfer learning-based ensemble deep learning. The transfer learning used here is the AlexNet, ResNet, Inception V3, and DenseNet models based on the convolutional neural network (CNN). The stacking ensemble model proposed in this study takes place over three stages. In the first step, predicted results are obtained using several transfer learning models, in the second step, they are combined through a concatenate layer, and in the third step, a deep neural network (DNN) model is applied and finally classified. For the performance evaluation of the ensemble model proposed in this paper, three actual COVID-19 X-ray/CT image datasets were considered, and various performance evaluation indicators were compared and analyzed with the transfer learning model and the existing ensemble model. As a result of the performance experiment, the overall proposed ensemble model was superior to the transfer learning model and the existing ensemble model."
무인항공기의 자동 착륙을 위한 LSM 및 CPA를 활용한 영상 기반 장애물 상태 추정 및 충돌 예측,2021,"['Autonomous Precision Landing', 'Collision Prediction', 'Closest Point of Approach', 'Least-Squares Method', 'State Estimation']","무인항공기의 영상 기반 자동 정밀 착륙 기술은 착륙 지점에 대한 정밀한 위치 추정 기술과 착륙 유도 기술이 요구된다. 또한, 안전한 착륙을 위하여 지상 장애물에 대한 착륙 지점의 안전성을 판단하고, 안전성이 확보된 경우에만 착륙을 유도하도록 설계되어야 한다. 본 논문은 자동 정밀 착륙을 수행하기 위하여 영상 기반의 항법과 착륙 지점의 안전성을 판단하기 위한 알고리즘을 제안한다. 영상 기반 항법을 수행하기 위해 CNN 기법을 활용하여 착륙 패드를 탐지하고, 탐지 정보를 활용하여 통합 항법 해를 도출한다. 또한, 위치 추정 성능을 향상시키기 위한 칼만필터를 설계 및 적용한다. 착륙 지점의 안전성을 판단하기 위하여 동일한 방식으로 장애물 탐지 및 위치 추정을 수행하고, LSM을 활용하여 장애물의 속도를 추정한다. 추정한 장애물의 상태를 활용하여 계산한 CPA를 기반으로 장애물과의 충돌 여부를 판단한다. 최종적으로 본 논문에서 제안된 알고리즘을 비행 실험을 통해 검증한다.","Vision-based autonomous precision landing technology for UAVs requires precise position estimation and landing guidance technology. Also, for safe landing, it must be designed to determine the safety of the landing point against ground obstacles and to guide the landing only when the safety is ensured. In this paper, we proposes vision-based navigation, and algorithms for determining the safety of landing point to perform autonomous precision landings. To perform vision-based navigation, CNN technology is used to detect landing pad and the detection information is used to derive an integrated navigation solution. In addition, design and apply Kalman filters to improve position estimation performance. In order to determine the safety of the landing point, we perform the obstacle detection and position estimation in the same manner, and estimate the speed of the obstacle using LSM. The collision or not with the obstacle is determined based on the CPA calculated by using the estimated state of the obstacle. Finally, we perform flight test to verify the proposed algorithm."
A Study on Security Event Detection in ESM Using Big Data and Deep Learning,2021,"['Intrusion Detection Systems', 'Enterprise Security Management', 'Convolutional Neural Network Intrusion Prevention System']",,"As cyber attacks become more intelligent, there is difficulty in detecting advanced attacks in various fields such as industry, defense, and medical care. IPS (Intrusion Prevention System), etc., but the need for centralized integrated management of each security system is increasing. In this paper, we collect big data for intrusion detection and build an intrusion detection platform using deep learning and CNN (Convolutional Neural Networks). In this paper, we design an intelligent big data platform that collects data by observing and analyzing user visit logs and linking with big data. We want to collect big data for intrusion detection and build an intrusion detection platform based on CNN model. In this study, we evaluated the performance of the Intrusion Detection System (IDS) using the KDD99 dataset developed by DARPA in 1998, and the actual attack categories were tested with KDD99's DoS, U2R, and R2L using four probing methods."
특허문서 자동분류를 위한 딥러닝 개별 모델 분류기와 앙상블 분류기의 성능비교,2021,"['Patent classification', 'Ensemble', 'Deep learning']",,
음향 장면 분류를 위한 경량화 모형 연구,2021,"['acoustic scene classification', 'light-weight model', 'deep learning', 'convolutional neural network', '음향 장면 분류', '경량화 모델', '딥러닝', '합성곱 신경망']","음향 장면 분류는 오디오 파일이 녹음된 환경이 어디인지 분류하는 문제이다. 이는 음향 장면 분류와 관련한 대회인 DCASE 대회에서 꾸준하게 연구되었던 분야이다. 실제 응용 분야에 음향 장면 분류 문제를 적용할 때, 모델의 복잡도를 고려하여야 한다. 특히 경량 기기에 적용하기 위해서는 경량 딥러닝 모델이 필요하다. 우리는 경량 기술이 적용된 여러 모델을 비교하였다. 먼저 log mel-spectrogram, deltas, delta-deltas 피쳐를 사용한 합성곱 신경망(CNN) 기반의 기본 모델을 제안하였다. 그리고 원래의 합성곱 층을 depthwise separable convolution block, linear bottleneck inverted residual block과 같은 효율적인 합성곱 블록으로 대체하고, 각 모델에 대하여 Quantization를 적용하여 경량 모델을 제안하였다. 경량화 기술을 고려한 모델은 기본 모델에 대비하여 성능이 비슷하거나 조금 낮은 성능을 보였지만, 모델 사이즈는 503KB에서 42.76KB로 작아진 것을 확인하였다.","Acoustic scene classification (ASC) categorizes an audio file based on the environment in which it has been recorded. This has long been studied in the detection and classification of acoustic scenes and events (DCASE). In this study, we considered the problem that ASC faces in real-world applications that the model used should have low-complexity. We compared several models that apply light-weight techniques. First, a base CNN model was proposed using log mel-spectrogram, deltas, and delta-deltas features. Second, depthwise separable convolution, linear bottleneck inverted residual block was applied to the convolutional layer, and Quantization was applied to the models to develop a low-complexity model. The model considering low-complexity was similar or slightly inferior to the performance of the base model, but the model size was significantly reduced from 503 KB to 42.76 KB."
Major concerns regarding food services based on news media reports during the COVID-19 outbreak using the topic modeling approach,2021,"['COVID-19', 'food services', 'news media', 'text analytics', 'topic modeling']",,"BACKGROUND/OBJECTIVES: Coronavirus disease 2019 (COVID-19) cases were first reported in December 2019, in China, and an increasing number of cases have since been detected all over the world. The purpose of this study was to collect significant news media reports on food services during the COVID-19 crisis and identify public communication and significant concerns regarding COVID-19 for suggesting future directions for the food industry and services.SUBJECTS/METHODS: News articles pertaining to food services were extracted from the home pages of major news media websites such as BBC, CNN, and Fox News between March 2020 and February 2021. The retrieved data was sorted and analyzed using Python software.RESULTS: The results of text analytics were presented in the format of the topic label and category for individual topics. The food and health category presented the effects of the COVID-19 pandemic on food and health, such as an increase in delivery services. The policy category was indicative of a change in government policy. The lifestyle change category addressed topics such as an increase in social media usage.CONCLUSIONS: This study is the first to analyze major news media (i.e., BBC, CNN, and Fox News) data related to food services in the context of the COVID-19 pandemic. Text analytics research on the food services domain revealed different categories such as food and health, policy, and lifestyle change. Therefore, this study contributes to the body of knowledge on food services research, through the use of text analytics to elicit findings from media sources."
A low-cost compensated approximate multiplier for Bfloat16 data processing on convolutional neural network inference,2021,"['Approximate computing', 'bfloat16 format', 'convolutional neural network', 'logarithmic multiplier', ""Mitchell's algorithm""]",,"This paper presents a low-cost two-stage approximate multiplier for bfloat16 (brain floating-point) data processing. For cost-efficient approximate multiplication, the first stage implements Mitchell's algorithm that performs the approximate multiplication using only two adders. The second stage adopts the exact multiplication to compensate for the error from the first stage by multiplying error terms and adding its truncated result to the final output. In our design, the low-cost multiplications in both stages can reduce hardware costs significantly and provide low relative errors by compensating for the error from the first stage. We apply our approximate multiplier to the convolutional neural network (CNN) inferences, which shows small accuracy drops with well-known pre-trained models for the ImageNet database. Therefore, our design allows low-cost CNN inference systems with high test accuracy."
Development of a Hybrid Deep-Learning Model for the Human Activity Recognition based on the Wristband Accelerometer Signals,2021,"['Activities of Daily Living', 'Human Activity Recognition', 'Smartwatch', 'Accelerometer', 'Machine Learning', 'Activity Classification', 'Feature Extraction', 'Feature Reduction']",,"This study aims to develop a human activity recognition (HAR) system as a Deep-Learning (DL) classification model, distinguishing various human activities. We solely rely on the signals from a wristband accelerometer worn by a person for the user's convenience. 3-axis sequential acceleration signal data are gathered within a predefined time-window-slice, and they are used as input to the classification system. We are particularly interested in developing a Deep-Learning model that can outperform conventional machine learning classification performance. A total of 13 activities based on the laboratory experiments' data are used for the initial performance comparison. We have improved classification performance using the Convolutional Neural Network (CNN) combined with an auto-encoder feature reduction and parameter tuning. With various publically available HAR datasets, we could also achieve significant improvement in HAR classification. Our CNN model is also compared against Recurrent-Neural-Network(RNN) with Long Short-Term Memory(LSTM) to demonstrate its superiority. Noticeably, our model could distinguish both general activities and near-identical activities such as sitting down on the chair and floor, with almost perfect classification accuracy."
Use of Deep Learning Image Classification Models and Vehicle Mounted Cameras for Automatic Pavement Pothole Detection,2021,"['Pavement Distress Detection', 'Urgent Maintenance', 'Deep Learning Image Classification', 'Vehicle Mounted Camera']",,"PURPOSES : This study uses deep learning image classification models and vehicle-mounted cameras to detect types of pavement distress — such as potholes, spalling, punch-outs, and patching damage — which require urgent maintenance. METHODS : For the automatic detection of pavement distress, the optimal mount location on a vehicle for a regular action camera was first determined. Using the orthogonal projection of obliquely captured surface images, morphological operations, and multi-blob image processing, candidate distressed pavement images were extracted from road surface images of a 16,036 km in-lane distance. Next, the distressed pavement images classified by experts were trained and tested for evaluation by three deep learning convolutional neural network (CNN) models: GoogLeNet, AlexNet, and VGGNet. The CNN models were image classification tools used to identify and extract the combined features of the target images via deep layers. Here, a data augmentation technique was applied to produce big distress data for training. Third, the dimensions of the detected distressed pavement patches were computed to estimate the quantity of repair materials needed. RESULTS : It was found that installing cameras 1.8 m above the ground on the exterior rear of the vehicle could provide clear pavement surface images with a resolution of 1 cm per pixel. The sensitivity analysis results of the trained GoogLeNet, AlexNet, and VGGNet models were 93 %, 86 %, and 72 %, respectively, compared to 62.7 % for the dimensional computation. Following readjustment of the image categories in the GoogLeNet model, distress detection sensitivity increased to 94.6 %. CONCLUSIONS : These findings support urgent maintenance by sending the detected distressed pavement images with the dimensions of the distressed patches and GPS coordinates to local maintenance offices in real-time."
뉴로모픽 구조 기반 FPGA 임베디드 보드에서 이미지 분류 성능 향상을 위한 특징 표현 방법 연구,2021,"['뉴로모픽 아키텍처', '이산 코사인 변환', '이미지 재조정', '임베디드 뉴로모픽 보드', 'Neuromorphic architecture', 'Discrete Cosine Transform', 'Image Reduction', 'Embedded Neuromorphic Boards']",,"Neuromorphic architecture is drawing attention as a next-generation computing that supports artificial intelligence technology with low energy. However, FPGA embedded boards based on Neuromorphic architecturehave limited resources due to size and power. In this paper, we compared and evaluated the image reduction method using the interpolation method that rescales the size without considering the feature points and the DCT (Discrete Cosine Transform) method that preserves the feature points as much as possible based on energy. The scaled images were compared and analyzed for accuracy through CNN (Convolutional Neural Networks) in a PC environment and in the Nengo framework of an FPGA embedded board.. As a result of the experiment, DCT based classification showed about 1.9% higher performance than that of interpolation representation in both CNN and FPGA nengo environments. Based on the experimental results, when the DCT method is used in a limited resource environment such as an embedded board, a lot of resources are allocated to the expression of neurons used for classification, and the recognition rate is expected to increase."
성인 학습자의 학습 추이 분석을 위한 인공지능 기반 알고리즘 모델 개발 및 평가,2021,"['성인학습자', '자기조절학습', '인공지능 모델', '추이 분석', '텐서플로우', 'Adult learners', 'artificial intelligence model', 'learning trend analysis', 'Tensorflow']","A사이버교육시스템 성인학습자의 자기조절학습 관련 학습 추이를 분석하여 교육 성과를 높이기 위해 인공지 능을 활용한 알고리즘 모델을 다양하게 설계하고, 그것을 실제 데이터에 적용함으로써 성능을 평가하였다. 이를 위해 A사이버교육시스템에서 115명의 성인학습자의 로그 데이터를 분석하였다. A사이버교육시스템 성인학습자 들은 대부분 권장 학습 시간 이상을 학습하였으나, 학기 말에는 권장 학습 시간 대비 실제 학습 시간이 현저하 게 감소하였다. VOD 참여율이나 형성평가 참여율, 학습 활동 참여율에서도 학습 후반부에 접어들수록 학습 참 여율이 떨어졌다. 따라서 교육 성과를 높이려면 학습 시간이 후반에도 지속될 수 있도록 지원해야 한다 판단하 여 후반부에 학습 시간이 떨어지는 학습자를 찾아내기 위해 Tensorflow를 활용한 인공지능 모델을 개발하여 수 강 시작 날짜별 학습 시간을 예측하였다. 그 결과, CNN 모델을 활용하여 단일 출력 또는 다중 출력을 예측할 경우 다른 모델에 비해 평균 절대 오차가 가장 낮게 나타났다.","To improve educational performance by analyzing the learning trends of adult learners of Open High Schools, various algorithm models using artificial intelligence were designed and performance was evaluated by applying them to real data. We analyzed Log data of 115 adult learners in the cyber education system of Open High Schools. Most adult learners of Open High Schools learned more than recommended learning time, but at the end of the semester, the actual learning time was significantly reduced compared to the recommended learning time. In the second half of learning, the participation rate of VODs, formation assessments, and learning activities also decreased. Therefore, in order to improve educational performance, learning time should be supported to continue in the second half. In the latter half, we developed an artificial intelligence algorithm models using Tensorflow to predict learning time by data they started taking the course. As a result, when using CNN(Convolutional Neural Network) model to predict single or multiple outputs, the mean-absolute-error is lowest compared to other models."
수목 동정을 위한 수피 분류 데이터셋 구축과 합성곱 신경망 기반 53개 수종의 동정 모델 개발,2021,"['tree species identification', 'bark', 'convolutional neural network']",,"Many studies have been conducted on developing automatic plant identification algorithms using machine learning to various plant features, such as leaves and flowers. Unlike other plant characteristics, barks show only little change regardless of the season and are maintained for a long period. Nevertheless, barks show a complex shape with a large variation depending on the environment, and there are insufficient materials that can be utilized to train algorithms. Here, in addition to the previously published bark image dataset, BarkNet v.1.0, images of barks were collected, and a dataset consisting of 53 tree species that can be easily observed in Korea was presented. A convolutional neural network (CNN) was trained and tested on the dataset, and the factors that interfere with the model's performance were identified. For CNN architecture, VGG-16 and 19 were utilized. As a result, VGG-16 achieved 90.41% and VGG-19 achieved 92.62% accuracy. When tested on new tree images that do not exist in the original dataset but belong to the same genus or family, it was confirmed that more than 80% of cases were successfully identified as the same genus or family. Meanwhile, it was found that the model tended to misclassify when there were distracting features in the image, including leaves, mosses, and knots. In these cases, we propose that random cropping and classification by majority votes are valid for improving possible errors in training and inferences."
네트워크 침입 탐지를 위해 CICIDS2017 데이터셋으로 학습한 Stacked Sparse Autoencoder-DeepCNN 모델,2021,"['Stacked Sparse Autoenocder (SSAE)', 'DeepCNN', 'Edge Computing', 'Intrusion Detection', 'CICIDS2017']","엣지 컴퓨팅을 사용하는 서비스 공급업체는 높은 수준의 서비스를 제공한다. 이에 따라 다양하고 중요한 정보들이 단말 장치에 저장되면서 탐지하기 더욱 어려운 최신 사이버 공격의 핵심 목표가 됐다. 보안을 위해 침입 탐지시스템과 같은 보안 시스템이 자주 활용되지만, 기존의 침입 탐지 시스템은 탐지 정확도가 낮은 문제점이 존재한다. 따라서 본 논문에서는 엣지 컴퓨팅에서 단말 장치의 더욱 정확한 침입 탐지를 위한 기계 학습 모델을 제안한다. 제안하는 모델은 희소성 제약을 사용하여 입력 데이터의 중요한 특징 벡터들을 추출하는 stacked sparse autoencoder (SSAE)와 convolutional neural network (CNN)를 결합한 하이브리드 모델이다. 최적의 모델을 찾기위해 SSAE의 희소성 계수를 조절하면서 모델의 성능을 비교 및 분석했다. 그 결과 희소성 계수가 일 때 96.9%로 가장 높은 정확도를 보여주었다. 따라서 모델이 중요한 특징들만 학습할 경우 더 높은 성능을 얻을 수 있었다.","Service providers using edge computing provide a high level of service. As a result, devices store important information in inner storage and have become a target of the latest cyberattacks, which are more difficult to detect. Although experts use a security system such as intrusion detection systems, the existing intrusion systems have low detection accuracy. Therefore, in this paper, we proposed a machine learning model for more accurate intrusion detections of devices in edge computing. The proposed model is a hybrid model that combines a stacked sparse autoencoder (SSAE) and a convolutional neural network (CNN) to extract important feature vectors from the input data using sparsity constraints. To find the optimal model, we compared and analyzed the performance as adjusting the sparsity coefficient of SSAE. As a result, the model showed the highest accuracy as a 96.9% using the sparsity constraints. Therefore, the model showed the highest performance when model trains only important features."
샴 네트워크 기반 객체 추적을 위한 표적 이미지 교환 모델,2021,"['Object tracking', 'Deep learning', 'Siamese network', 'Convolutional neural network', '객체 추적', '딥 러닝', '샴 네트워크', '컨볼루션 뉴럴 네트워크']",본 논문에서는 샴 네트워크 기반의 객체 추적 알고리즘의 성능 향상을 위한 표적 이미지 교환 모델을 제안한다. 샴 네트워크 기반의 객체 추적 알고리즘은 시퀀스의 첫 프레임에서 지정된 표적 이미지만을 사용하여 탐색 이미지 내에서 가장 유사한 부분을 찾아 객체를 추적한다. 첫 프레임의 객체와 유사도를 비교하기 때문에 추적에 한 번 실패하게 되면 오류가 축적되어 추적 객체가 아닌 부분에서 표류하게 되는 현상이 발생한다. 따라서 CNN(Convolutional Neural Network)기반의 모델을 설계하여 추적이 잘 진행되고 있는지 확인하고 샴 네트워크 기반의 객체 추적 알고리즘에서 출력되는 점수를 이용하여 표적 이미지 교환 시기를 정의하였다. 제안 모델은 VOT-2018 데이터 셋을 이용하여 성능을 평가하였고 최종적으로 정확도 0.611 견고도 22.816을 달성하였다.,"In this paper, we propose a target image exchange model to improve performance of the object tracking algorithm based on a Siamese network. The object tracking algorithm based on the Siamese network tracks the object by finding the most similar part in the search image using only the target image specified in the first frame of the sequence. Since only the object of the first frame and the search image compare similarity, if tracking fails once, errors accumulate and drift in a part other than the tracked object occurs. Therefore, by designing a CNN(Convolutional Neural Network) based model, we check whether the tracking is progressing well, and the target image exchange timing is defined by using the score output from the Siamese network-based object tracking algorithm. The proposed model is evaluated the performance using the VOT-2018 dataset, and finally achieved an accuracy of 0.611 and a robustness of 22.816."
딥러닝 기반 Local Climate Zone 분류체계를 이용한 지표면온도와 도시열섬 분석: 수원시와 대구광역시를 대상으로,2021,"['Local Climate Zone', 'Deep Learning', 'Convolutional Neural Network', 'Urban Heat Island', 'Urban Climate']",,"Urbanization increases the amount of impervious surface and artificial heat emission, resulting in urban heat island (UHI) effect. Local climate zones (LCZ) are a classification scheme for urban areas considering urban land cover characteristics and the geometry and structure of buildings, which can be used for analyzing urban heat island effect in detail. This study aimed to examine the UHI effect by urban structure in Suwon and Daegu using the LCZ scheme. First, the LCZ maps were generated using Landsat 8 images and convolutional neural network (CNN) deep learning over the two cities. Then, Surface UHI (SUHI), which indicates the land surface temperature (LST) difference between urban and rural areas, was analyzed by LCZ class. The results showed that the overall accuracies of the CNN models for LCZ classification were relatively high 87.9% and 81.7% for Suwon and Daegu, respectively. In general, Daegu had higher LST for all LCZ classes than Suwon. For both cities, LST tended to increase with increasing building density with relatively low building height. For both cities, the intensity of SUHI was very high in summer regardless of LCZ classes and was also relatively high except for a few classes in spring and fall. In winter the SUHI intensity was low, resulting in negative values for many LCZ classes. This implies that UHI is very strong in summer, and some urban areas often are colder than rural areas in winter. The research findings demonstrated the applicability of the LCZ data for SUHI analysis and can provide a basis for establishing timely strategies to respond urban on-going climate change over urban areas."
암반공학분야에 적용된 인공지능 알고리즘 분석,2021,"['Rock engineering', 'Artificial intelligence', 'Machine learning', 'Artificial neural networks', 'Algorithm', '암반공학', '인공지능', '기계학습', '인공신경망', '터널']","4차 산업혁명 시대의 도래에 따라 암반공학분야에서도 인공지능을 활용한 연구가 점차 증가하고 있다. 본 논문에서는 인공지능에 대한 이해와 그 활용도를 더욱 증진시키기 위하여, 암반공학기술의 주된 적용대상인 터널, 발파, 광산과 관련된 최근의 국내외 연구 중 인공지능이 활용된 논문들에서 그 알고리즘의 종류와 적용방법을 분석하였다. 터널에서는 암반분류, TBM굴진율 및 막장전방 지질 예측, 발파에서는 암반의 파쇄도 및 비산거리, 광산에서는 폐광의 침하가능성 예측을 위해 주로 활용되고 있으며, 기계학습의 다양한 알고리즘 중 인공신경망이 압도적으로 많이 활용되고 있는 것으로 나타났다. 연구결과의 정확도와 신뢰성 제고를 위해 사용하고자 하는 인공지능 알고리즘에 대한 정확하고 상세한 이해가 필수적이며, 현재는 접근이나 분석이 난해한 암반공학 분야의 다양한 문제해결을 위해 기계학습뿐 아니라 CNN 또는 RNN과 같은 딥러닝을 활용한 연구 아이디어들이 점차 증가될 것으로 기대된다.","As the era of Industry 4.0 arrives, the researches using artificial intelligence in the field of rock engineering as well have increased. For a better understanding and availability of AI, this paper analyzed the types of algorithms and how to apply them to the research papers where AI is applied among domestic and international studies related to tunnels, blasting and mines that are major objects in which rock engineering techniques are applied. The analysis results show that the main specific fields in which AI is applied are rock mass classification and prediction of TBM advance rate as well as geological condition ahead of TBM in a tunnel field, prediction of fragmentation and flyrock in a blasting field, and the evaluation of subsidence risk in abandoned mines. Of various AI algorithms, an artificial neural network is overwhelmingly applied among investigated fields. To enhance the credibility and accuracy of a study result, an accurate and thorough understanding on AI algorithms that a researcher wants to use is essential, and it is expected that to solve various problems in the rock engineering fields which have difficulty in approaching or analyzing at present, research ideas using not only machine learning but also deep learning such as CNN or RNN will increase."
전이 학습을 이용한 선박 기관실 기기의 분류에 관한 연구,2021,"['Patrol robot', 'Ship engine room equipment', 'Convolution neural network', 'Classification', 'Transfer learning', '순찰 로봇', '선박 기관실 기기', '합성곱 신경망', '분류', '전이 학습']","선박 기관실은 기술의 발전으로 인해 자동화 시스템이 향상되었지만, 해상에서는 바람, 파도, 진동, 기기 노후화 등의 다양한 변수가 많아 자동화 시스템에서 계측되지 않는 풀림, 절단, 누유, 누수 등이 발생하므로 기관사는 주기적으로 순찰을 한다. 순찰 시에는 1명의 기관사만 순찰하는 경우도 있으며, 이는 고온고압 및 회전기기가 운전 중인 기관실에서 많은 위험요소를 가지고 있다. 기관사가 순찰 시에는 오감을 활용하며, 특히 시각에 의존한다. 본 논문에서는 로봇이 기관실을 순찰하며 기기의 특이사항을 검출하고 알려주는 기관실 순찰 로봇을 구현하기 위한 선행연구로서 선박 기관실 기기의 이미지를 합성곱 신경망을 이용하여 분류하였다. 선박 기관실의 이미지 데이터 셋을 구성한 후 사전 훈련된 합성곱 신경망 모델로 학습하였다. 학습한 모델의 분류 성능은 높은 재현율을 보였으며, 클래스 활성화 맵으로 이미지를 시각화 하였다. 데이터의 양이 제한적이어서 일반화할 수는 없지만, 각 선박의 데이터를 전이학습으로 학습시키면 적은 시간과 비용으로 각 선박의 특성에 맞는 모델을 구축할 수 있을 것으로 사료된다.","Ship engine rooms have improved automation systems owing to the advancement of technology. However, there are many variables at sea, such as wind, waves, vibration, and equipment aging, which cause loosening, cutting, and leakage, which are not measured by automated systems. There are cases in which only one engineer is available for patrolling. This entails many risk factors in the engine room, where rotating equipment is operating at high temperature and high pressure. When the engineer patrols, he uses his five senses, with particular high dependence on vision. We hereby present a preliminary study to implement an engine-room patrol robot that detects and informs the machine room while a robot patrols the engine room. Images of ship engine-room equipment were classified using a convolutional neural network (CNN). After constructing the image dataset of the ship engine room, the network was trained with a pre-trained CNN model. Classification performance of the trained model showed high reproducibility. Images were visualized with a class activation map. Although it cannot be generalized because the amount of data was limited, it is thought that if the data of each ship were learned through transfer learning, a model suitable for the characteristics of each ship could be constructed with little time and cost expenditure."
음악 소리가 딥 러닝의 음향 분류 성능에 미치는 영향,2021,"['Sound classification', 'Deep learning', 'Music genre', 'UrbanSound8K', 'GTZAN']",,"Sound classification is a computer technology that involves learning to classify sounds and to predict the category of that sound. Recently, the machine learning based approach is being actively conducted for improving recognition accuracy. In this approach, a deep neural network is trained using a sound dataset, and then the actual sound is applied to identify the sound category. In the identification stage, the recognition accuracy of the machine learning is degraded due to the ambient noise. In other words, unlike the experimental environment, various sounds are input into the microphone along with the target sound. Since these ambient sounds are not trained, they could lower the classification performance. However, there are only a few research results on the relation between the noise and the recognition performance despite of the practical importance. In this paper, we study the performance degradation of sound classification in the space where the music is playing with considering the music genre and the volume level. For this, we use CNN, UrbanSound8K dataset consisting of 10 kinds of environmental sounds, and GTZAN data set containing 10 kinds of music genres. First, CNN is trained to recognize the sounds of UrbanSound8K, and then five songs for each genre were selected from GTZAN and mixed to the UrbanSound8K so that the signal-to-noise ratio are -20dB, 0dB, 5dB, 10dB, and 20dB. Then we test the accuracy with the mixed sound input and compare with the noise-free target sound. As a result, there is 2.8% to 22% difference in the recognition accuracy by music genre and sound level. The result show that the SNR should be 20dB or more in order for music not to have a significant effect on the recognition accuracy."
심층학습 기반 불완전한 영상의 특징점 매칭과 기초행렬 추정,2021,"['Stereo Camera', 'Feature Detection', 'Feature Matching', 'Convolutional Neural Network', 'Fundamental Matrix']","스테레오 비전 시스템에서 특징점 검출과 특징점 매칭은 정확한 깊이추정을 위해 반드시 필요한 작업이다. 그러나 입력 영상으로부터 충분한 특징점을 획득하지 못한다면 특징점 매칭의 결과의 정확도는 낮아질 가능성이 높다. 본 논문에서는 일부 정보가 누락된 영상을 입력으로 받은 후 컨볼루션 신경망을 활용하여 특징점 검출 및 매칭을 수행한다. 스테레오 카메라 시스템을 이용하여 일부 정보가 누락된 한 쌍의 영상을 활용하여 컨볼루션 신경망 기반으로 특징점 검출의 정확도를 높여 이것으로부터 계산된 특징점 매칭의 결과와 기초행렬의 결과를 정보누락 없이 수행된 실험 결과와 비교해 본다. 본 연구에서 제안하는 방법을 검증하기 위하여 스테레오 카메라로부터 획득한 영상을 활용하고, 영상에서 임의의 영역을 삭제하여 정보가 누락된 영상을 생성한다. 심층학습을 수행하기 위하여 특징점 추출 단계에서 컨볼루션 신경망 모델을 이용하고 RANSAC(RANdom SAmple Consensus) 알고리즘을 이용하여 매칭을 수행한다.","The detection and matching of feature points are mandatory procedures for accurate depth estimation in stereo vision. The accuracy of correspondence matching is low unless sufficient numbers of detected feature points are acquired. This paper deals with incomplete images that lose a considerable number of pixels, and the detection and matching of feature points are performed using a convolutional neural network (CNN). Once feature detection and matching are carried out using the CNN, a comparison is made between the results of the fundamental matrix for both the cases of complete and incomplete images. As part of this work, to evaluate our method, some regions of an image are deleted so that an incomplete image can be generated. Once feature extraction is performed, an RANSAC algorithm is employed for feature correspondence."
딥러닝을 이용한 군 내외 거수자 행동 인식: 키포인트 2D 스케일링을 중심으로,2021,"['defense and security technology', 'surveillance camera', 'suspicious person', 'behavior recognition', 'OpenPose', '국방보안기술', '감시카메라', '거수자', '행동 인식', '오픈포즈']","본 연구는 딥러닝을 통해 군 내외에서 거수자의 행동을 인식하여 국방 보안 체계를 강화하는 데 목적을 두고 있다. 감시 카메라는 범죄자, 수상한 행동을 하는 사람을 찾아내는데 도움이 된다. 하지만 관리자가 카메라에서 전송되는 많은 영상을 모두 모니터링해야 한다는 점에서 비효율적이다. 큰 비용이 발생하며, 인적 오류에 취약하다. 따라서 본 연구에서는 감시카메라 영상만으로 주의 있게 봐야 할 행동을 하는 사람을 찾아내는 방법을 제안한다. 이를 위해 거수자 영상 데이터를 수집하였다. 또한, 입력 영상에서 사람마다 다른 신장, 동작을 일반화하는 알고리즘을 적용한 후 CNN, 양방향 LSTM, DNN을 결합한 모델을 통해 학습하였다. 실험 결과, 거수자의 행동 인식의 정확도를 향상시켰다. 따라서 기존 감시 카메라에 딥러닝을 접목한다면 거수자를 효율적으로 찾아낼 수 있을 것으로 기대한다.","The purpose of this study is to reinforce the defense and security system by recognizing the behaviors of suspicious person both inside and outside the military using deep learning. Surveillance cameras help detect criminals and people who are acting unusual. However, it is inefficient in that the administrator must monitor all the images transmitted from the camera. It incurs a large cost and is vulnerable to human error. Therefore, in this study, we propose a method to find a person who should be watched carefully only with surveillance camera images. For this purpose, the video data of doubtful behaviors were collected. In addition, after applying a algorithm that generalizes different heights and motions for each person in the input images, we trained through a model combining CNN, bidirectional LSTM, and DNN. As a result, the accuracy of the behavior recognition of suspicious behaviors was improved. Therefore, if deep learning is applied to existing surveillance cameras, it is expected that it will be possible to find the dubious person efficiently."
Feature Pyramid Network-based Long-Distance Drone Detection Method,2021,"['CNN', '딥러닝', '드론', 'FPN', '객체 탐지', 'deep learning', 'drone', 'object detection']",,
삼중 경로 mDAPPM을 활용한 실시간 의미론적 분할 성능 향상 연구,2021,"['CNN', 'Deep learning', 'Semantic segmentation', 'DAPPM']",,"In this paper, we propose real-time Semantic segmentation performance improvements when changing the aggregation layer, the core of the recently popular Two-pathway backbone and the BiSeNet v2 algorithm, to Modified Deep Aggregation Pyramid Pooling Module (mDAPPM). Existing aggregation layers are designed to simply merge feature representations from two branches, but in this paper, we use Three-pathway mDAPPM to integrate different depths with different sizes of pooling kernels to proceed with multi-scale feature point extraction. As a result, the real-time speed is 88fps identical to that of existing BiSeNet v2, and mIOUs obtain up to 3% improvement based on max_iter= 30,000 over BiSeNet v2."
지식증류 기법을 사용한 SRGAN 경량화 연구,2021,"['CNN', 'Network Lightening', 'Knowledge Distillation', 'Super-Resolution', 'SRGAN']",,
Design and Implementation of Fire Detection System Using New Model Mixing,2021,"['CNN', 'YoloV5', 'DeepSort', 'Deep Appearance Deseriptor']",,"In this paper, we intend to use a new mixed model of YoloV5 and DeepSort. For fire detection, we want to increase the accuracy by automatically extracting the characteristics of the flame in the image from the training data and using it. In addition, the high false alarm rate, which is a problem of fire detection, is to be solved by using this new mixed model. To confirm the results of this paper, we tested indoors and outdoors, respectively. Looking at the indoor test results, the accuracy of YoloV5 was 75% at 253Frame and 77% at 527Frame, and the YoloV5+DeepSort model showed the same accuracy at 75% at 253 frames and 77% at 527 frames. However, it was confirmed that the smoke and fire detection errors that appeared in YoloV5 disappeared. In addition, as a result of outdoor testing, the YoloV5 model had an accuracy of 75% in detecting fire, but an error in detecting a human face as smoke appeared. However, as a result of applying the YoloV5+DeepSort model, it appeared the same as YoloV5 with an accuracy of 75%, but it was confirmed that the false positive phenomenon disappeared."
A Restoration Method of Single Image Super Resolution Using Improved Residual Learning with Squeeze and Excitation Blocks,2021,"['CNN', 'Super-resolution', 'SRGAN', 'Residual learning', 'Squeeze and excitation']",,"Techniques for single-image super-resolution have been developed through deep learning. In this paper, we propose a method using advanced residual learning and squeeze and excitation (SE) blocks for such resolution. Improving the residual learning increases the similarity between pixels by adding one skip to the existing residual, and it is possible to improve the performance while slightly increasing the number of calculations by applying the SE block of SENet. The performance evaluation was tested as part of the super-resolution generative adversarial network (SRGAN) and using three proposed modules, and the effect of the residual and the SE blocks on the super-resolution and the change in performance was confirmed. Although the results vary slightly from image, SE and residual blocks have been found to help improve the performance and are best used with blocks."
임베디드용 저해상도 적외선 영상 딥컨볼루션신경망,2021,"['Deep Learning', 'CNN', 'VGG', 'Low Resolution', 'Infrared', 'Synthesize Image', '딥러닝', '컨볼루션 신경망', '저해상도', '적외선', '합성영상']","본 논문은 저해상도 적외선영상을 사양이 낮은 임베디드 시스템에서 추론 가능하도록 강화된 VGG 스타일과 Global Average Pooling 조합으로 정확도를 증가시키면서 연산량을 최소화하는 딥러닝 컨볼루션 신경망을 이용한 저해상도 적외선 표적 분류 방법을 제안한다. 제안한 알고리즘은 OKTAL-SE로 생성한 합성영상 클래스 9개 3,723,328개를 분류하였다. 최초 임베디드 추론 가능하도록 파라메터 수가 최소화된 최대풀링 레이어 기준 입력단 8개와 출력단 8개 조합에 비해 강화된 VGG 스타일을 적용한 입력단 4개와 출력단 16개 필터수 조합을 이용하여 연산량은 약 34% 감소시켰으며, 정확도는 약 2.4% 증가시켜 최종 정확도 96.1%을 획득하였다. 추가로 C 코드로 포팅하여 수행시간을 확인하였으며, 줄어든 연산량 만큼 수행 시간이 약 32% 줄어든 것을 확인할 수 있었다.","In this paper, we propose reinforced VGG style network structure for low performance embedded system to classify low resolution infrared image. The combination of reinforced VGG style network structure and global average pooling makes lower computational complexity and higher accuracy. The proposed method classify the synthesize image which have 9 class 3,723,328ea images made from OKTAL-SE tool. The reinforced VGG style network structure composed of 4 filters on input and 16 filters on output from max pooling layer shows about 34% lower computational complexity and about 2.4% higher accuracy then the first parameter minimized network structure made for embedded system composed of 8 filters on input and 8 filters on output from max pooling layer. Finally we get 96.1% accuracy model. Additionally we confirmed the about 31% lower inference lead time in ported C code."
합성곱 신경망의 추론 정확도 향상을 위한 하드웨어 구조 연구,2021,"['AI accelerator', 'CNN', 'batch normalization', 'verilog-HDL', 'ASIC']",,"In this paper, we propose a hardware architecture with built-in batch normalization to improve inference accuracy of convolutional neural networks. Batch normalization improves inference accuracy by normalizing the data distribution by the convolutional neural network layer. However, operations such as average and variance are required, and if there is a restriction on hardware resource usage, the operation accuracy decreases. Therefore, this paper proposes a hardware architecture in which batch normalization operations can be omitted by applying an 8-bit quantization technique when inferencing to improve computational accuracy and utilize internal control signals. The proposed hardware architecture was modeled using Verilog-HDL. Then the intermediate and final output values of the hardware operation were compared and evaluated with the output results of the software-based verification model and synthesized using the Samsung 28-nm process."
Encoding Dictionary Feature for Deep Learning-based Named Entity Recognition,2021,"['BiLSTM Dictionary', 'CNN Dictionary', 'Self-attention Dictionary', 'GFID Dataset', 'Biomedical NER']",,
합성곱 신경망을 이용한 프로펠러 캐비테이션 침식 위험도 연구,2021,"['Convolutional Neural Network(CNN', '합성곱 신경망)', 'Deep learning(딥러닝)', 'Propeller(프로펠러)', 'Cavitation(캐비테이션)', 'Erosion(침식)']",,"Cavitation erosion is one of the major factors causing damage by lowering the structural strength of the marine propeller and the risk of it has been qualitatively evaluated by each institution with their own criteria based on the experiences. In this study, in order to quantitatively evaluate the risk of cavitation erosion on the propeller, we implement a deep learning algorithm based on a convolutional neural network. We train and verify it using the model tests results, including cavitation characteristics of various ship types. Here, we adopt the validated well-known networks such as VGG, GoogLeNet, and ResNet, and the results are compared with the expert’s qualitative prediction results to confirm the feasibility of the prediction algorithm using a convolutional neural network."
합성곱 신경망 인식률 개선을 위한 이미지 전처리에 대한 연구,2021,"['convolutional neural network', 'feature map', 'input shape', 'pre-processing', 'background padding']",,"A convolutional neural network(CNN) produces an optimal feature map for that image by optimizing the weights of the kernel through the learning process. Therefore, it can be expected that the optimal learning rate will be achieved when utilizing datasets optimized for input shape of neural network models. However, using public datasets or collecting images directly by researchers may not be suitable for the input shape. In this paper, several steps of image pre-processing methods were tested to increase the recognition rate of convolutional neural networks. As a result of comparing the recognition rate before and after pre-processing for the datasets, the result after pre-processing improved the accuracy by 5.73%. Through this, it was found that the pre-processing method for the learning image had an important effect on improving recognition rates."
자율주행을 위한 동적 객체 인식 방법에 관한 연구,2021,"['Deep Learning', 'Faster R-CNN', 'Machine Learning', 'Support Vector Machine', 'Object Detection', 'Unmanned Vehicle', 'YOLO']",,"Dynamic object recognition is an important task for autonomous vehicles. Since dynamic objects exhibit a higher collision risk than static objects, our own trajectories should be planned to match the future state of moving elements in the scene. Time information such as optical flow can be used to recognize movement. Existing optical flow calculations are based only on camera sensors and are prone to misunderstanding in low light conditions. In this regard, to improve recognition performance in low-light environments, we applied a normalization filter and a correction function for Gamma Value to the input images. The low light quality improvement algorithm can be applied to confirm the more accurate detection of Object's Bounding Box for the vehicle. It was confirmed that there is an important in object recognition through image prepocessing and deep learning using YOLO."
CoS: 딥러닝을 위한 시그모이드로 구성한 강조된 부드러운 비단조성 활성 함수,2021,"['activation function', 'deep learning', 'CNN', 'neural network', 'object detection']",,"Activation functions are important components that affect the performance of neural networks. Activation functions such as Step, Sigmoid, Tanh, and ReLU have problems such that the important differentiation is not possible or the gradient is vanishing. Activation function Swish solved the problem with Characteristic of a smooth non-monotonic curves and boundary value of negative. Based on these characteristics, in this paper, we propose a Consisting of Sigmoid(CoS) function adding a smooth emphasized non-monotonic curves part and reducing negative results on negative inputs and improving the flow of information within the neural network. Through the proposed method, it was certain that accuracy is improved by 0.46%~0.77% and 0.38%~0.54% over the existing ReLU and Swish."
합성곱 신경망기반 딥러닝의 용접연구 적용 Part I: 모델과 활용사례,2021,[],,
Feasibility Evaluation of Brain Tumor Magnetic Resonance Imaging Classification Using Convolutional Neural Network Model,2021,"['MRI', 'Brain tumor', 'CNN', 'VGG16', 'Artificial intelligence', '자기공명영상', '뇌종양', '합성곱신경망', '인공지능']",,
다중 도메인 학습을 이용한 화면 촬영 영상 내 모아레 무늬 제거 기법,2021,"['Moire artifacts removal', 'demoireing', 'convolutional neural network (CNN)', 'multiple domain learning']",,"We propose a moire artifacts removal algorithm for screen-shot images using multiple domain learning. First, we estimate clean preliminary images by exploiting complementary information of the moire artifacts in pixel value and frequency domains. Next, we estimate a clean edge map of the input moire image by developing a clean edge predictor. Then, we refine the pixel and frequency domain outputs to further improve the quality of the results using the estimated edge map as the guide information. Finally, the proposed algorithm obtains the final result by merging the two refined results. Experimental results on a public dataset demonstrate that the proposed algorithm outperforms conventional algorithms in quantitative and qualitative comparison."
수술 도구의 세분화와 행동 인식 기능이 탑재된 AI 서비스 개발,2021,"['Deep learning', 'Convolutional neural network (CNN)', 'Surgical tool', 'Segmentation', 'Recognition', 'AI service']",,"In this paper, we propose an artificial intelligence (AI) service that plays a supportive role in robot assisted-surgery using deep learning algorithm that have recently been spotlighted in several fields. The proposed AI service is equipped with the ability to segment surgical tools and the ability to recognize the behavior of surgical tools. In addition, such AI service is opened using public web page to make them easier for surgeons to use. Models mounted on AI service are segmentation deep learning model and action recognition deep learning model. The segmentation deep learning model showed a final mIoU performance of 0.867 for seven surgical tools, and the action recognition deep learning model shows an accuracy of 86.96% for the opening and closing actions of all surgical tools."
비디오 기반 딥러닝 융합 알고리즘에 의한 화재 감지 시스템에 관한 연구,2021,"['화재 감지', '연기 감지', '딥러닝', '객체 인식', 'CNN', 'Fire detection', 'smoke detection', 'deep learning', 'object detection', 'tracking', 'CNNs']",,
포말대에서의 파랑특성을 관측하기 위한 STIV의 적용성 평가,2021,"['Swash zone', 'STIV', 'Artificial intelligence', 'CNN', 'Surface velocity', 'Rip current']",,"The swash zone is an area that causes a change in the shape of a beach by generating sediment transport under the influence of intermittent waves, where wave run-up and run-down are infinitely repeated in the final stage of the shoaling process. However, the ability to predict the sediment transport is extremely poor despite the swash zone being an extremely important area in terms of offshore disaster prevention. In particular, many researchers are conducting studies on the development of various types of observation equipment and analysis techniques because the turbulent flow of active fluid dominates the sediment transport and is an extremely important parameter for the analysis of the transport mechanism. However, in flow velocity measurement, it is difficult to measure a quantitative representative flow velocity over time because the swash zone has a shallow water depth and an active turbulent flow. Expensive equipment and short-time measurement are also limitations. Therefore, the purpose of this study was to evaluate the applicability of nonintrusive space-time image velocimetry(STIV) to analyze the flow characteristics of fluid in the swash zone, such as the movement velocity and period of intermittent waves in the shoaling process. The prediction accuracy was improved by removing various noises included in the images with the introduction of artificial intelligence for immediate and accurate calculation of the representative flow velocity using images that can be obtained easily. Consequently, it was discovered that the spatial representative flow velocity occurring in the swash zone, change in the wave period according to the shoaling effect, rip current and surface velocity can be measured."
메타러닝과 3D 이미지를 활용한 도심지내 밀리미터파 경로 손실 모델링,2021,"['Millimeter Wave', 'Path Loss Modeling', 'Meta-Learning', '5G', 'Convolutional Neural Network']",,
정형 및 비정형 데이터를 이용한 농산물 구매량 예측: 파프리카를 중심으로,2021,"['정형 데이터', '비정형 데이터', 'LSTM', 'CNN', 'SVR', 'Random Forest', 'XGBoost', 'SHAP', 'structured data', 'Unstructured data']",,"Consumers’ food consumption behavior is likely to be affected not only by structured data such as consumer panel data but also by unstructured data such as mass media and social media. In this study, a deep learning-based consumption prediction model is generated and verified for the fusion data set linking structured data and unstructured data related to food consumption. The results of the study showed that model accuracy was improved when combining structured data and unstructured data. In addition, unstructured data were found to improve model predictability. As a result of using the SHAP technique to identify the importance of variables, it was found that variables r elated to b log and video data were on the top list and had a positive correlation with the amount of paprika purchased. In addition, according to the experimental results, it was confirmed that the machine learning model showed higher accuracy than the deep learning model and could be an efficient alternative to the existing time series analysis modeling."
인접 픽셀 정보를 이용한 Shift-Convolution 기반의 3D LiDAR 깊이 완성,2021,"['Heterogeneous sensor calibration(이종 센서 캘리브레이션)', 'CNN(콘볼루션 뉴런 네트워크)', 'Depth completion(깊이 완성)', 'Autonomous driving(자율주행)', 'LiDAR(라이다)']",,
삼중항 손실 기반의 잔여 네트워크를 이용한 손가락 정맥 인식,2021,"['Finger-vein Identification', 'Deep learning', 'Triplet loss', 'CNN', 'Biometrics']","본 논문은 높은 정확도의 손가락 정맥 인식을 위해 삼중항 손실 기반의 심층 신경망을 설계하여 손가락 정맥 인식 알고리즘을 개발하는 것을 목적으로 한다. 심층 신경망을 이용한 분류기는 높은 정확도를 보장하기 위해 많은 학습 데이터가 필요하다. 그러나 손가락 정맥 인식에서는 학습 데이터가 적으면서 판별해야 할 클래스가 많기 때문에 기존 심층 신경망을 이용한 분류기는 적합하지 않다. 이러한 문제를 해결하기 위해, 서로 유사성을 가진 손가락 정맥 이미지를 차별적으로 학습하는 네트워크 구조를 설계하고, 높은 정확도의 인식률을 이끌어 내기 위한 목적 함수를 제안한다. 본 논문에서는 손가락 정맥 패턴의 특성에 최적화시키기 위해, 멀티 클래스 크로스 엔트로피와 삼중항 손실이 결합된 네트워크를 구축하여 인식률을 효과적으로 개선한다. 실험 결과 MMCBNU, FV_USM 그리고 SDUMLA 데이터 셋에서 각각 99.40%, 99.48%, 95.91% 정확도로 우수한 성능을 나타낸다.","The purpose of this paper is to develop a finger-vein identification algorithm by designing a deep neural network based on triplet loss for high accuracy. classifiers using deep neural networks require a lot of learning data to ensure high accuracy. However, in finger-vein identification, the classifier using the existing deep neural network is not suitable. Because the learning data is small and there are many classes to be identified. To solve this problem, we propose a network structure and loss function that extracts and identifies more differentiated features from finger-vein images for high accuracy. To learn the network by optimizing the characteristics of the finger-vein pattern, we construct a network that combines multi-class cross-entropy loss and triplet loss to effectively improve the identification accuracy. Experimental results show performance with 99.40%, 99.48%, 95.91% accuracy in the MMCBNU, FV_USM, and SDUMLA dataset."
딥러닝 기반 OpenPose를 이용한 한국 수화 동작 인식에 관한 연구,2021,"['딥러닝', '한국 수화', '수화인식', 'Deep Learning', 'CNN', 'OpenPose', 'Korea Sign Language', 'Sign Language Recognition']",,"Most of the studies on the existing sign language use expensive equipment or do not consider non-manual signals. In order to improve this problem, we intend to acquire an image using an RGB camera and recognize sign language by including non-manual signals, which take a considerable weight in sign language, beyond recognizing only the existing hand shape. By using the OpenPose library, hand gestures, body gestures, and facial expressions were represented in the data as key points and were included as the non-manual signals. In addition, we propose a method of learning data using a deep learning neural network model and recognizing sign language motion through the trained model. In this paper, the goal is to increase the recognition rate for each sign language motion without the help of a specific sensor or wearable device because it learns data including non-manual elements and recognizes sign language motions."
MPFANet: Semantic Segmentation Using Multiple Path Feature Aggregation,2021,"['MPFA', 'Semantic segmentation', 'Feature aggregation', 'CNN', 'Inverted residual block', 'Local context']",,"Image segmentation is the process of simplifying the analysis of the meaning or the front to say the process of dividing the image into a set of multiple pixels. The multiple path feature aggregation (MPFA) method proposed in this paper aims to extract various information of an object, and uses conventional pyramid pooling or the extraction of various sized features. This information can be combined with different regional features to obtain the overall feature information. We split four paths to extract numerous local features, and the results showed that the mean intersection over union (mIOU) is 81.6% for the validation data from the PASCAL VOC 2012 dataset, and a better performance than the existing DeepLab model was demonstrated."
VVC 인코더에서 합성 곱 신경망의 어텐션 맵을 이용한 휘도 매핑 함수 생성 방법,2021,"['VVC', 'Encoder', 'Luma mapping with Chroma Scaling', 'CNN']",,"In this paper, we propose a method for generating luma signal mapping function to improve the coding efficiency of luma signal mapping methods in LMCS. In this paper, we propose a method to reflect the cognitive and perceptual features by multiplying the attention map of convolutional neural networks on local spatial variance used to reflect local features in the existing LMCS. To evaluate the performance of the proposed method, BD-rate is compared with VTM-12.0 using classes A1, A2, B, C and D of MPEG standard test sequences under AI (All Intra) conditions. As a result of experiments, the proposed method in this paper shows improvement in performance the average of -0.07% for luma components in terms of BD-rate performance compared to VTM-12.0 and encoding/decoding time is almost the same."
합성곱 신경망을 이용한 컨포멀 코팅 PCB에 발생한 문제성 기포 검출 알고리즘,2021,"['Problematic Bubble', 'Bubble Detection', 'Conformal Coating', 'CNN', 'ResNet']",,"Conformal coating is a technology that protects PCB(Printed Circuit Board) and minimizes PCB failures. Since the defects in the coating are linked to failure of the PCB, the coating surface is examined for air bubbles to satisfy the successful conditions of the conformal coating. In this paper, we propose an algorithm for detecting problematic bubbles in high-risk groups by applying image signal processing. The algorithm consists of finding candidates for problematic bubbles and verifying candidates. Bubbles do not appear in visible light images, but can be visually distinguished from UV(Ultra Violet) light sources. In particular the center of the problematic bubble is dark in brightness and the border is high in brightness. In the paper, these brightness characteristics are called valley and mountain features, and the areas where both characteristics appear at the same time are candidates for problematic bubbles. However, it is necessary to verify candidates because there may be candidates who are not bubbles. In the candidate verification phase, we used convolutional neural network models, and ResNet performed best compared to other models. The algorithms presented in this paper showed the performance of precision 0.805, recall 0.763, and f1-score 0.767, and these results show sufficient potential for bubble test automation."
Identification of Indian butterflies using Deep Convolutional Neural Network,2021,"['Indian butterfly identification', 'ButterflyNet', 'Butterfly', 'classification CNN', 'Computer vision']",,"The conventional butterfly identification method is based on their different morphological characters namely wing-venation, color, shape, patterns and through the dissection studies and molecular techniques which are tedious, expensive and highly time-consuming. To overcome the above aforesaid challenges, a new butterfly identification system using butterfly images has been designed to instantly identify the butterfly with high ac curacy. In this study, we construct a new butterfly dataset with 34,024 butterfly images belonging to 315 species from India. We propose and prove the effectiveness of new data augmentation techniques on our dataset. To identify butterflies using photographic images, we built eleven new Deep Convolutional Neural Network (DCNN) butterfly classifier models using eleven pre-trained architectures namely ResNet-18, ResNet-34, ResNet-50, ResNet-121, ResNet-152, Alex-Net, DenseNet-121, DenseNet-161, VGG-16, VGG-19 and SqueezeNet-v1.1. The different model’s classification results were compared and the proposed technique achieved a maximum top-1 accuracy(94.44%), top-3 accuracy(98.46%) and top-5 accuracy(99.09%) using ResNet-152 model, followed by DenseNet-161 model achieved the top-1 accuracy(94.31%), top-3 accuracy (98.07%) and top-5 accuracy (98.66%). The results suggest that models can be assertively used to identify butterflies in India."
A new framework for Person Re-identification: Integrated level feature pattern (ILEP),2021,"['Person reidentification', 'LBP', 'HOG', 'Deep features', 'PCA', 'CNN', 'm-XceptionNet']",,"The system for re-identifying persons is used to find and verify the persons crossing through different spots using various cameras. Much research has been done to re-identify the person by utilising features with deep-learned or hand-crafted information. Deep learning techniques segregate and analyse the features of their layers in various forms, and the output is complex feature vectors. This paper proposes a distinctive framework called Integrated Level Feature Pattern (ILFP) framework, which integrates local and global features. A new deep learning architecture named modified XceptionNet (m-XceptionNet) is also proposed in this work, which extracts the global features effectively with lesser complexity. The proposed framework gives better performance in Rank1 metric for Market1501 (96.15%), CUHK03 (82.29%) and the newly created NEC01 (96.66%) datasets than the existing works. The mean Average Precision (mAP) calculated using the proposed framework gives 92%, 85% and 98%, respectively, for the same datasets."
결함검출 적용을 위한 YOLO 딥러닝 알고리즘 비교,2021,"['YOLO', 'Deep learning', 'Object detection', 'Defect detection', 'CNN']",,"Recently, metal 3D printing technology has developed and has been widely applied in fields such as mechanical parts and construction sites. However, the problem of output defects must be resolved. These defects appear as pores and microcracks in the output, which can be confirmed through microscopic analysis of the output. In addition, if the understanding of pores or cracks is unclear or many images need to be checked in a short time, an error might occur. Therefore, this study aims to develop a precision object detection algorithm using deep learning. The purpose is to automatically detect defects using deep learning-based You Only Look Once (YOLO). Through comparison using YOLO v3 and v5 algorithms, the accuracy and speed were compared to analyze which YOLO model was efficient in the defect detection process."
불균형데이터의 비용민감학습을 통한 국방분야 이미지 분류 성능 향상에 관한 연구,2021,"['Imbalanced Data', 'Cost-sensitive Learning', 'CNN', '불균형데이터', '비용민감학습', '컨볼루션 신경망']",,"With the development of deep learning technology, researchers and technicians keep attempting to apply deep learning in various industrial and academic fields, including the defense. Most of these attempts assume that the data are balanced. In reality, since lots of the data are imbalanced, the classifier is not properly built and the model’s performance can be low. Therefore, this study proposes cost-sensitive learning as a solution to the imbalance data problem of image classification in the defense field. In the proposed model, cost-sensitive learning is a method of giving a high weight on the cost function of a minority class. The results of cost-sensitive based model shows the test F1-score is higher when cost-sensitive learning is applied than general learning's through 160 experiments using submarine/non-submarine dataset and warship/non-warship dataset. Furthermore, statistical tests are conducted and the results are shown significantly."
Research on the Detection of Image Tampering,2021,"['Image', 'Tampering', 'Forensics', 'Deep learning', 'CNN', '이미지', '변조', '포렌식', '딥러닝']","정보의 주요 전달체로서 디지털 이미지는 점점 더 중요해지고 있다. 그러나 이미지 획득 장비의 대중화와 이미지 편집 소프트웨어의 급속한 발전으로 인해, 최근 몇 년간 디지털 이미지 위조사건이 잇따라 발생해 이미지의 신뢰도를 떨어뜨릴 뿐만 아니라 사회와 개인에게도 큰 악영향을 미치고 있다. 이미지 복사-붙여넣기 변조(image copy-paste tampering)는 가장 일반적인 유형의 이미지 변조 중 하나이며, 조작이 쉽고 효과적이기 때문에 디지털 이미지 의미 정보 변경에 자주 사용된다. 본 논문에서는 이미지 복사 및 붙여넣기의 변조 탐지 방법을 연구하여 이미지 콘텐츠의 진정성과 무결성을 보호하는 방법이 제안되었다. 딥러닝의 우수한 학습과 분석능력을 감안해 영상처리작업이 남긴 흔적을 활용해 영상 속 원본 영역과 변조된 영역을 구분하는 딥러닝 기반 변조 검출법 2가지가 제안되었다. 또한 실험을 통해 이론적 근거의 합리성, 변조 탐지, 위치 및 분류의 정확성을 검증하였다.","As the main carrier of information, digital image is becoming more and more important. However, with the popularity of image acquisition equipment and the rapid development of image editing software, in recent years, digital image counterfeiting incidents have emerged one after another, which not only reduces the credibility of images, but also brings great negative impacts to society and individuals. Image copy-paste tampering is one of the most common types of image tampering, which is easy to operate and effective, and is often used to change the semantic information of digital images. In this paper, a method to protect the authenticity and integrity of image content by studying the tamper detection method of image copy and paste was proposed. In view of the excellent learning and analysis ability of deep learning, two tamper detection methods based on deep learning were proposed, which use the traces left by image processing operations to distinguish the tampered area from the original area in the image. A series of experimental results verified the rationality of the theoretical basis, the accuracy of tampering detection, location and classification."
A Study on Fruit Quality Identification Using YOLO V2 Algorithm,2021,"['YOLOV2', 'Region Of Interest', 'Bound Box', 'R-CNN', 'Artificial Intelligence']",,"Currently, one of the fields leading the 4th industrial revolution is the image recognition field of artificial intelligence, which is showing good results in many fields. In this paper, using is a YOLO V2 model, which is one of the image recognition models, we intend to classify and select into three types according to the characteristics of fruits. To this end, it was designed to proceed the number of iterations of learning 9000 counts based on 640 mandarin image data of 3 classes. For model evaluation, normal, rotten, and unripe mandarin oranges were used based on images. We as a result of the experiment, the accuracy of the learning model was different depending on the number of learning. Normal mandarin oranges showed the highest at 60.5% in 9000 repetition learning, and unripe mandarin oranges also showed the highest at 61.8% in 9000 repetition learning. Lastly, rotten tangerines showed the highest accuracy at 86.0% in 7000 iterations. It will be very helpful if the results of this study are used for fruit farms in rural areas where labor is scarce."
An IoT based Cloud EEG Signal Analytic Framework for Thought to Text Mapping,2021,"['AWS lambda', 'Brain-computer interface', 'Cloud computing', 'CNN', 'EEG signal', 'IoT', 'Imagined speech to text']",,"Paralyzed people have difficulty communicating with the world for their daily basic needs, and their caretakers have difficulty understanding their needs. The development and implementation of a handheld device-based brain-computer interface system with machine learning will solve the above problem. On the other hand, a simple handheld device cannot satisfy the computation of hunger ML algorithms and will have more latency. This paper overcomes the limitations of the above by processing the data in the cloud. The handheld device reads and preprocesses the electroencephalogram (EEG) data and forwards it to the IoT-based Cloud server. The cloud server applies the machine-learning algorithm and classifies it in the text, representing the word thought by the user. This text information result is sent back to the handheld device and intimates the caretaker to know the patient""s needs. The evaluation result of the proposed system for ten words to deal with the basic needs highlights the feasibility of implementing it in practice."
Interpolation based Single-path Sub-pixel Convolution for Super-Resolution Multi-Scale Networks,2021,"['Super-resolution', 'multi-scalable network', 'multi-scale single-path Super-resolution']",,"Deep leaning convolutional neural networks (CNN) have successfully been applied to image super-resolution (SR). Despite their great performances, SR techniques tend to focus on a certain upscale factor when training a particular model. Algorithms for single model multi-scale networks can easily be constructed if images are upscaled prior to input, but sub-pixel convolution upsampling works differently for each scale factor. Recent SR methods employ multi-scale and multi-path learning as a solution. However, this causes unshared parameters and unbalanced parameter distribution across various scale factors. We present a multi-scale single-path upsample module as a solution by exploiting the advantages of sub-pixel convolution and interpolation algorithms. The proposed model employs sub-pixel convolution for the highest scale factor among the learning upscale factors, and then utilize 1-dimension interpolation, compressing the learned features on the channel axis to match the desired output image size. Experiments are performed for the single-path upsample module, and compared to the multi-path upsample module. Based on the experimental results, the proposed algorithm reduces the upsample module's parameters by 24% and presents slightly to better performance compared to the previous algorithm."
도시림의 경관 회복 기능 평가를 위한 딥러닝 적용 가능성 모색: 문헌 및 방법론 리뷰를 중심으로,2021,"['합성곱 계층', '이미지 분류 및 분할', '지도학습', 'Convolutional Neural Network', 'CNN', 'Image classification and segmentation', 'Supervised learning']",,"This study examines the feasibility of developing a model for evaluating urban landscapes based on deep learning as a preliminary study. The principal methodology of the study is literature analysis; to explore the possibility of applying the deep learning algorithm to landscape evaluation, we intensively reviewed researches regarding ‘urban forest landscape research’, ‘landscape evaluation scale’, and ‘feasibility of deep learning in landscape studies’. The results derived from this study are composed mainly of two contents. First, it is ‘Necessity to select images considering landscape composition and standardize evaluation indicators and scales’. The data to be evaluated for measuring the recovery effect of urban forests were found to be insufficient to be applied as a model. However, since the landscape elements and composition to be evaluated in existing studies were simply set, it will contribute to reducing the complexity of the model. When developing the model in the future, influence variables that have been proven several times in previous studies can be used as main input data. The evaluation results of existing studies that will be applied as input data to future evaluation models are composed of various scales and need to be adjusted to a level that can be compared to each other through standardization, moreover high resolution for the development and use of landscape evaluation algorithms in various fields. Second, ‘Proving of the possibility and feasibility of evaluating existing algorithms’. It is judged that the validity of the landscape evaluation model based on deep learning is high, and rather than a method of newly developing the evaluation algorithm itself, the basic data is constructed to improve the model's reliability by utilizing and partially correcting the already established landscape evaluating algorithm. This study is meaningful because it suggests directions and limitations for the future urban forest landscape evaluation model development."
다중 데이터 합성 알고리즘 및 합성곱 신경망을 사용한 신원확인 기법 연구,2021,"['identification', 'face recognition', 'watermarking', 'data synthesis', 'artificial intelligence', 'CNN']",,"This paper proposes an identification method using multiple biometric data synthesis algorithms and convolutional neural networks. In general, multi-biological data-based identity verification methods use multimodal deep learning. However, computation increases when two or more networks are used, making applying to the embedded system difficult. In this paper, a voice for authentication composed of facial images and several syllables was synthesized into one data, and identification was performed by applying it to one convolutional neural network. As for the actual environmental data for learning, a total of 800 multi-biological synthesized images were used by combining 8 facial images per person and 20 voices for authentication for 5 experimental personnel. As a result of the experiment, it was confirmed that the proposed identification method operates normally with an inference accuracy of about 93%."
PCB 검사를 위한 YOLO 네트워크 기반의 PCB 부품 분류 알고리즘,2021,"['PCB Inspection', 'Defect Detection', 'AOI', 'Classification', 'Deep Learning', 'CNN']",,
Accelerating a Deep Learning Application by Parallelization and Pipelining on Heterogeneous Processors,2021,"['딥 러닝', '이기종 프로세서', '파이프라이닝', '병렬화', 'deep learning', 'heterogeneous processors', 'pipelining', 'parallelization']","임베디드 시스템에서 딥 러닝 응용에 대한 필요가 증가함에 따라, 응용을 가속하는 데에 있어서 CPU가 아닌 처리 요소(processing element)를 임베디드 기기에 포함되고 있다. NVIDIA Jetson AGX Xavier는 대표적인 예제로 8-core CPU 뿐만 아니라 GPU와 2개의 딥러닝 가속기를 함께 갖고 있어서 자원이 제한된 환경에서 딥 러닝 응용의 성능을 끌어올리는 데에 활용된다. 임베디드 기기가 이기종처리 요소를 제공한다고 하여도, 이런 다양한 요소들을 함께 활용하여 성능을 올리는 것은 상당한 노력을 필요로 한다. 본 논문에서는 기존의 존재하는 여러 기법들과 우리가 제안하는 네트워크 파이프라이닝 기법을 함께 조합하여 이기종 처리요소를 가진 Xavier에서 딥 러닝 응용의 처리량을 최대화 하는 기법을 제안한다. 여러 개의 이미지 분류 예제와 사물 인식 예제를 통해 하나의 GPU를 사용하는 기존의 방법 대비 최대 355%까지 성능이 향상되는 것을 확인하였다.","Since the need of deep learning applications in embedded systems is increasing, non-CPU processing elements are equipped on an embedded device to accelerate those applications. NVIDIA Jetson AGX Xavier (Xavier) is a representative example which not only has an octa-core CPU, but also has one powerful GPU and two deep learning accelerators to enhance the performance of deep learning inference on resource-constrained environments. Although an embedded device provides heterogeneous processing elements, utilizing diverse computation units is burdensome to increase performance. In this paper, we proposed a technique that combines multiple existing methods and our proposed network pipelining method to maximize the throughput of deep learning applications. Our network pipelining method is made for utilizing heterogeneous processing elements on the Xavier. Results of experiments with image classification and object detection examples revealed up to 355% improvement compared to baseline Frames Per Second (FPS) with a single GPU."
딥러닝 기반 실시간 얼굴 모자이크 기법을 활용한 초상권 보호 시스템,2021,"['Machine learning', 'Deep learning', 'Face mosaic', 'Portrait rights', 'Yolov3', 'Facenet', 'R-CNN']",,"Recently, the number of cases uploading videos taken by individuals on the Internet has increased. Uploading a video that includes not only yourself but also people around you can cause infringement of portrait rights and privacy issues. In general, The portrait rights of others are protected by manually blurring faces of people moving over time using a video editing program. However, this is a very cumbersome task and the existing automatic mosaic system also has limitations because it does not detect all identifiable faces properly in videos and it misses tracked faces frequently. Therefore, to prevent the problem of infringement of portrait rights, this paper proposes a portrait rights protection system using deep learning. The system uses YOLOv3, Face-Net, and SORT algorithm to protect the portrait rights by blurring faces of other people except the users registered in the system. Compared to the existing automatic mosaic system, It can detect all identifiable faces and blur faces more accurately. It can operate in real-time by skipping a certain frame and performing face verification. It is also possible to flexibly respond to various changes of the face reflected on the camera by applying the SORT object tracking algorithm. The proposed system can improve convenience for users by automating the task of manually blurring faces of people and it shows superior performance compared to the existing automatic mosaic system."
딥러닝에 의한 항공사진 구름 분류 및 탐지 비교 실험,2021,"['Deep Learning', 'Classification', 'Detection', 'GoogLeNet', 'VGG16', 'Faster R-CNN', 'YOLOv3', '딥러닝', '분류', '탐지']",,
Apple Detection Algorithm based on an Improved SSD,2021,"['RFB', 'Attention Model', 'SSD', 'Apple detection', 'Objection detection', 'CNN']",,"Under natural conditions, Apple detection has the problems of occlusion and small object detection difficulties. This paper proposes an improved model based on SSD. The SSD backbone network VGG16 is replaced with the ResNet50 network model, and the receptive field structure RFB structure is introduced. The RFB model amplifies the feature information of small objects and improves the detection accuracy of small objects. Combined with the attention mechanism (SE) to filter out the information that needs to be retained, the semantic information of the detection objectis enhanced. An improved SSD algorithm is trained on the VOC2007 data set. Compared with SSD, the improved algorithm has increased the accuracy of occlusion and small object detection by 3.4% and 3.9%. The algorithm has improved the false detection rate and missed detection rate. The improved algorithm proposed in this paper has higher efficiency."
Is it possible to forecast KOSPI direction using deep learning methods?,2021,"['deep learning', 'machine learning', 'time-series data', '1D-CNN', 'LSTM']",,"Deep learning methods have been developed, used in various fields, and they have shown outstanding performances in many cases. Many studies predicted a daily stock return, a classic example of time-series data, using deep learning methods. We also tried to apply deep learning methods to Korea's stock market data. We used Korea's stock market index (KOSPI) and several individual stocks to forecast daily returns and directions. We compared several deep learning models with other machine learning methods, including random forest and XGBoost. In regression, long short term memory (LSTM) and gated recurrent unit (GRU) models are better than other prediction models. For the classification applications, there is no clear winner. However, even the best deep learning models cannot predict significantly better than the simple base model. We believe that it is challenging to predict daily stock return data even if we use the latest deep learning methods."
ConvLSTM2D 기법을 이용한 부분방전 유형 자동분류 성능개선,2021,"['partial discharge', 'prediction model', 'UHF sensor', 'deep learning', 'CNN algorithms', 'LSTM']",,"Conv2D techniques can be used to automatically classify the type of partial discharge by learning with two-dimensional data with the phase and amplitude of the partial discharge signal, but fail to take into account the characteristics of the time series, resulting in the failure to accurately classify the type of partial discharge. In the paper, we propose an automatic classification technique of the type of partial discharge using the ConvLSTM2D technique with LSTM, which reflects time series characteristics on the Conv2D technique. The ConvLSTM2D technique proposed in this work is a method of learning with three-dimensional data with the phase, amplitude and time of the partial discharge signal. Experiments using Corona discharge and void discharge data, a representative type of partial discharge, confirm that ConvLSTM2D techniques improve the accuracy of classifying the types of Corona discharge and void discharge than conventional Conv2D techniques. The results of this paper are expected to be utilized in the field of failure prediction of switchboards through accurate automatic classification of the types of corona discharge and void discharge, which are representative types of partial discharge occurring in switchboards."
비디오 인코더를 통한 딥러닝 모델의 정수 가중치 압축,2021,"['Deep Learning Model Parameter Quantization', 'Weight compression', 'Lightweight model']",,"Recently, various lightweight methods for using Convolutional Neural Network(CNN) models in mobile devices have emerged. Weight quantization, which lowers bit precision of weights, is a lightweight method that enables a model to be used through integer calculation in a mobile environment where GPU acceleration is unable. Weight quantization has already been used in various models as a lightweight method to reduce computational complexity and model size with a small loss of accuracy. Considering the size of memory and computing speed as well as the storage size of the device and the limited network environment, this paper proposes a method of compressing integer weights after quantization using a video codec as a method. To verify the performance of the proposed method, experiments were conducted on VGG16, Resnet50, and Resnet18 models trained with ImageNet and Places365 datasets. As a result, loss of accuracy less than 2% and high compression efficiency were achieved in various models. In addition, as a result of comparison with similar compression methods, it was verified that the compression efficiency was more than doubled."
아동의 ADHD 진단 보조를 위한 기계 학습 기반의 뇌전도 분류,2021,"['Attention Deficit Hyperactivity Disorder (ADHD)', 'EEG', 'Gamma band', 'CNN']",,
심층학습을 이용한 영상정보 기반 호흡신호 분류,2021,"['Respiration', 'Respiratory states', 'UWB radar', 'Visual information', 'Deep neural network']","본 논문에서는 영상정보에 기반한 호흡상태 분류 방법을 제안한다. 호흡신호는 초광대역 레이더 센서를 이용하여 획득하고 호흡신호의 값으로 이루어진 1차원 그래프 대신 그래프의 영상 정보가 담긴 2차원 정보 기반으로 호흡상태를 분류한다. 호흡상태의 분류는 심층신경망 모델을 사용하고, 심층신경망 모델은 호흡신호 그래프가 포함된 2차원 영상의 특징들을 학습하여 영상기반의 호흡상태 분류의 결과를 제공한다. 기존의 레이더 센서 기반 호흡신호의 상태 분류는 1차원 벡터의 구성요소 값 및 그 값들의 변화량을 이용하여 회귀, 심층학습 방법을 적용하였다. 그러나 1차원 그래프 기반의 호흡상태 분류는 다양한 형태의 정상호흡 상태에 대한 분류 성능에서 한계를 보였다. 본 논문에서는 호흡 신호로부터 얻은 그래프의 이미지 자체를 2차원 입력 신호로 사용하여 심층 신경망 모델을 적용하여 분류를 수행하였다. 본 논문에서 제안하는 영상정보 기반의 호흡상태 분류는 기존의 1차원 벡터 기반 호흡상태 분류 대비 호흡상태 분류의 정확도를 약 10% 향상 시켰다. 또한 기존의 두 가지 호흡상태 (정상 및 비정상) 분류에서 확장하여 세 가지 호흡상태 (정상1, 정상2, 비정상) 분류를 수행하였다.","This paper proposes an approach to the classification of respiratory states of humans based on visual information. An ultra-wide-band radar sensor acquired respiration signals, and the respiratory states were classified based on two-dimensional (2D) images instead of one-dimensional (1D) vectors. The 1D vector-based classification of respiratory states has limitations in cases of various types of normal respiration. The deep neural network model was employed for the classification, and the model learned the 2D images of respiration signals. Conventional classification methods use the value of the quantified respiration values or a variation of them based on regression or deep learning techniques. This paper used 2D images of the respiration signals, and the accuracy of the classification showed a 10% improvement compared to the method based on a 1D vector representation of the respiration signals. In the classification experiment, the respiration states were categorized into three classes, normal-1, normal-2, and abnormal respiration."
WiSECam: A CSI-Based Deep Learning Motion Detection for Wireless Cameras,2021,"['Channel State Information (CSI)', 'Wi-Fi monitoring mode', 'deep learning', 'Convolutional Neural Network (CNN)', 'Long Short-Term Memory (LSTM)']",,
자율주행 트랙터 경로 추종을 위한 영상 기반 경계검출기술 개발,2021,"['자율주행', '농업기계', '경계 검출', '합성곱 신경망', '조향제어', 'autonomous traveling', 'agricultural machinery', 'boundary detection', 'CNN', 'steering control']",,
딥 뉴럴 네트워크에 의한 디지털 홀로그램의 워터마킹 및 홀로그램 데이터 특성을 고려한 학습,2021,"['Digital hologram', 'digital watermark', 'deep neural network (DNN)', 'training data set', 'convolution neural network (CNN)']","디지털 홀로그램(digital hologram, DH)은 2차원 데이터에 3차원의 정보를 포함하는 초고부가가치의 영상 콘텐츠이다. 따라서 이 콘텐츠의 유통을 위해서는 그 지적재산권이 반드시 보호되어야 한다. 본 논문에서는 이를 위해서 최초로 딥 뉴럴 네트워크를 이용한 DH의 워터마킹 방법을 제안한다. 이 방법은 워터마크(watermark, WM)가 의 비가시성, 공격에 대한 강인성, WM 추출 시 호스트 정보를 사용하지 않는 blind 워터마킹 방법이다. 제안하는 네트워크는 호스트와 워터마크 각각의 전처리, WM 삽입, WM 추출의 네 부-네트워크로 구성된다. 이 네트워크는 고주파 성분이 강한 DH의 특성을 감안하여 호스트 데이터를 축소하지 않고 WM 데이터를 확장하여 호스트 데이터와 정합함으로써 WM를 삽입한다. 또한 이 네트워크의 학습에 있어서 DH의 데이터 분포특성에 따른 성능의 차이를 확인하고, 모든 종류의 DH에서 최고의 성능을 갖는 학습 데이터 세트를 선정하는 방법을 제시한다. 제안한 방법을 다양한 종류와 강도의 공격에 대해 실험을 수행하여 그 성능을 보인다. 또한 이 방법이 호스트 DH의 해상도와 WM 데이터에 독립적으로 동작하여 높은 실용성을 갖는다는 것을 보인다.",
임베디드 시스템에서 효율적인 차량 번호판 인식 시스템,2021,"['차량 번호판 인식', '딥러닝', '임베디드 시스템', '객체 검출', '합성곱 신경망', 'License Plate Recognition', 'Deep learning', 'Object detection', 'CNN']",,
유사 이미지 분류를 위한 딥 러닝 성능 향상 기법 연구,2021,"['분류', '딥 러닝', '유사 이미지', '컨볼루셔널 뉴럴 네트워크', '혼동률', 'Classification', 'Deep Learning', 'Similar Image', 'CNN', 'Confusion Rate']","딥 러닝을 활용한 컴퓨터 비전 연구는 여전히 대규모의 학습 데이터와 컴퓨팅 파워가 필수적이며, 최적의 네트워크 구조를 도출하기 위해 많은 시행착오가 수반된다. 본 연구에서는 네트워크 최적화나 데이터를 보강하는 것과 무관하게 데이터 자체의 특성만을 고려한 CR(Confusion Rate)기반의 유사 이미지 분류 성능 향상 기법을 제안한다. 제안 방법은 유사한 이미지 데이터를 정확히 분류하기 위해 CR을 산출하고 이를 손실 함수의 가중치에 반영함으로서 딥 러닝 모델의 성능을 향상시키는 기법을 제안한다. 제안 방법은 네트워크 최적화 결과와 독립적으로 이미지 분류 성능의 향상을 가져올 수 있으며, 클래스 간의 유사성을 고려해 유사도가 높은 이미지 식별에 적합하다. 제안 방법의 평가결과 HanDB에서는 0.22%, Animal-10N에서는 3.38%의 성능향상을 보였다. 제안한 방법은 다양한 Noisy Labeled 데이터를 활용한 인공지능 연구에 기반이 될 것을 기대한다.","Deep learning in computer vision has made accelerated improvement over a short period but large-scale learning data and computing power are still essential that required time-consuming trial and error tasks are involved to derive an optimal network model. In this study, we propose a similar image classification performance improvement method based on CR (Confusion Rate) that considers only the characteristics of the data itself regardless of network optimization or data reinforcement. The proposed method is a technique that improves the performance of the deep learning model by calculating the CRs for images in a dataset with similar characteristics and reflecting it in the weight of the Loss Function. Also, the CR-based recognition method is advantageous for image identification with high similarity because it enables image recognition in consideration of similarity between classes. As a result of applying the proposed method to the Resnet18 model, it showed a performance improvement of 0.22% in HanDB and 3.38% in Animal-10N. The proposed method is expected to be the basis for artificial intelligence research using noisy labeled data accompanying large-scale learning data."
지진 이벤트 분류를 위한 정규화 기법 분석,2021,[],,"This paper presents an effective structure by applying various normalization to Convolutional Neural Networks (CNN) for seismic event classification. Normalization techniques can not only improve the learning speed of neural networks, but also show robustness to noise. In this paper, we analyze the effect of input data normalization and hidden layer normalization on the deep learning model for seismic event classification. In addition an effective model is derived through various experiments according to the structure of the applied hidden layer. As a result of various experiments, the model that applied input data normalization and weight normalization to the first hidden layer showed the most stable performance improvement."
Former Unmanned Surface Vehicle Detection Based on Improved Convolutional Neural Network,2021,"['Object detection', 'Accuracy', 'Tracking system', 'Monocular camera']",,"This paper proposes an approach to the real-time implementation of a convolutional neural network (CNN)-based object detector for a former Unmanned Surface Vehicle (USV). The original network VGG-16 of the Single Shot MultiBox Detector (SSD) is first replaced with ResNet-18, as the basic feature extraction network. The classifying network is then redesigned by reducing half of the convolutional kernel numbers, where kernel sizes of 1×1 and 3×3 are mainly used. Simultaneously, a monocular camera installed on the tracking system, is used to calculate the distance and azimuth of the former USV. The experimental results show that the proposed method has advantages of higher accuracy and lower computational complexity, compared with other existing approaches. Therefore, the proposed approach can be efficiently used on real-time tracking systems."
Transposed Convolutional Layer 기반 Stacked Hourglass Network를 이용한 얼굴 특징점 검출에 관한 연구,2021,"['Facial Landmark Detection', 'Face Alignment', 'Stacked Hourglass Network', 'Transposed Convolutional Layer', 'Computer Vision', 'CNN', 'Heatmap Based Detection', 'Bodypart detection']",,
선삭공정에서 딥러닝 영상처리 기법을 이용한 작업자 위험 감소 방안 연구,2021,"['Deep Learning(딥러닝)', 'Vision System(영상처리 시스템)', 'Negligent Accident(안전사고)', 'Convolutional Neural Network(CNN)(컨볼루션신경망)', 'You Only Look Once(YOLO)(욜로)']",,"The deep learning image processing technique was used to prevent accidents in lathe work caused by worker negligence. During lathe operation, when the chuck is rotated, it is very dangerous if the operator""s hand is near the chuck. However, if the chuck is stopped during operation, it is not dangerous for the operator’s hand to be in close proximity to the chuck for workpiece measurement, chip removal or tool change. We used YOLO (You Only Look Once), a deep learning image processing program for object detection and classification. Lathe work images such as hand, chuck rotation and chuck stop are used for learning, object detection and classification. As a result of the experiment, object detection and class classification were performed with a success probability of over 80% at a confidence score 0.5. Thus, we conclude that the artificial intelligence deep learning image processing technique can be effective in preventing incidents resulting from worker negligence in future manufacturing systems."
객체 검출과 한글 손글씨 인식 알고리즘을 이용한 차량 번호판 문자 추출 알고리즘,2021,"['Vehicle License Plate Recognition(VLPR)', 'Optical Character Recognition(OCR)', 'Object Detection', 'Faster R-CNN', 'Handwritten Hangul Recognition(HHR)']",,"Recently, with the development of IT technology, unmanned systems are being introduced in many industrial fields, and one of the most important factors for introducing unmanned systems in the automobile field is vehicle licence plate recognition(VLPR). The existing VLPR algorithms are configured to use image processing for a specific type of license plate to divide individual areas of a character within the plate to recognize each character. However, as the number of Korean vehicle license plates increases, the law is amended, there are old-fashioned license plates, new license plates, and different types of plates are used for each type of vehicle. Therefore, it is necessary to update the VLPR system every time, which incurs costs. In this paper, we use an object detection algorithm to detect character regardless of the format of the vehicle license plate, and apply a handwritten Hangul recognition(HHR) algorithm to enhance the recognition accuracy of a single Hangul character, which is called a Hangul unit. Since Hangul unit is recognized by combining initial consonant, medial vowel and final consonant, so it is possible to use other Hangul units in addition to the 40 Hangul units used for the Korean vehicle license plate."
Implementation of AIoT Edge Cluster System via Distributed Deep Learning Pipeline,2021,"['Distributed Data pipeline', 'Deep Learning', 'IoT', 'Edge Computing', 'Kubernetes', 'Docker']",,"Recently, IoT systems are cloud-based, so that continuous and large amounts of data collected from sensor nodes are processed in the data server through the cloud. However, in the centralized configuration of large-scale cloud computing, computational processing must be performed at a physical location where data collection and processing take place, and the need for edge computers to reduce the network load of the cloud system is gradually expanding. In this paper, a cluster system consisting of 6 inexpensive Raspberry Pi boards was constructed to perform fast data processing. And we propose ""Kubernetes cluster system(KCS)"" for processing large data collection and analysis by model distribution and data pipeline method. To compare the performance of this study, an ensemble model of deep learning was built, and the accuracy, processing performance, and processing time through the proposed KCS system and model distribution were compared and analyzed. As a result, the ensemble model was excellent in accuracy, but the KCS implemented as a data pipeline proved to be superior in processing speed.."
이질적 이미지의 딥러닝 분석을 위한 적대적 학습기반 이미지 보정 방법론,2021,"['Adversarial Learning', 'Color Constancy', 'Heterogeneous Images', 'Illumination Estimation', 'Image Correction', '적대적 학습', '색 항상성', '이질적 이미지', '조명 추정', '이미지 보정']",,"The advent of the big data era has enabled the rapid development of deep learning that learns rules by itself from data. In particular, the performance of CNN algorithms has reached the level of self-adjusting the source data itself. However, the existing image processing method only deals with the image data itself, and does not sufficiently consider the heterogeneous environment in which the image is generated. Images generated in a heterogeneous environment may have the same information, but their features may be expressed differently depending on the photographing environment. This means that not only the different environmental information of each image but also the same information are represented by different features, which may degrade the performance of the image analysis model. Therefore, in this paper, we propose a method to improve the performance of the image color constancy model based on Adversarial Learning that uses image data generated in a heterogeneous environment simultaneously. Specifically, the proposed methodology operates with the interaction of the ‘Domain Discriminator’ that predicts the environment in which the image was taken and the ‘Illumination Estimator’ that predicts the lighting value. As a result of conducting an experiment on 7,022 images taken in heterogeneous environments to evaluate the performance of the proposed methodology, the proposed methodology showed superior performance in terms of Angular Error compared to the existing methods."
SORT와 DeepSORT의 혼합을 이용한 실시간 다중객체 추적,2021,"['multi-object tracking', 'real-time system', 'real-time tracking']",,"Deep Simple Online and Real-time Tracking(DeepSORT) is a multi-object tracking technology that improves the accuracy of SORT, and has the characteristic of using a feature map of Convolution Neural Network(CNN) when determining the relationship between objects between consecutive frames in SORT. This feature has the advantage of dramatically improving the accuracy, but has a disadvantage in that the frame per second(FPS) is lowered due to the large amount of additional computing operations required. Therefore, for real-time systems such as autonomous vehicles, SORT has been considered more suitable than deep SORT. In this paper, we propose a method of mixing SORT technology with DeepSORT to remove the shortcomings of the existing DeepSORT. As a result of the experiment targeting MOT-16, a widely used data set used for multi-object tracking performance, it was confirmed that the proposed method dramatically increased the FPS with little loss in accuracy."
딥 러닝 기반 설명 가능한 인공지능과 무인기의 다중 이미지 센서를 활용한 무 시들음병 탐지 프레임워크,2021,"['무 시들음병', '딥 러닝', '설명가능한 인공지능', '무인비행체', 'RGB', '근적외선', 'Fusarium wilt', 'Deep learning', 'XAI', 'UAV', 'RGB', 'NIR']","전 세계적으로 사랑받고 있는 채소인 무는 뿌리채소 중 하나로 다양한 요리에 주재료로 사용되고 있어 많은 양이 생 산되고 소비된다. 무는 또한 한국의 음식 문화에서도 중요한 역할을 하는데, 대표적인 한국의 음식 중 하나인 김치 에도 무가 사용된다. 하지만 최근 급격한 기후 변화로 인해 무가 시들음병에 쉽게 노출될 수 있는 환경이 만들어져 무의 품질과 수확량이 크게 저하되는 문제가 생기고 있다. 무 시들음병 문제를 해결하기 위한 기존의 식물 대상의 질병 식별 방식은 수집한 컬러 이미지에서 수동으로 특징을 추출했기 때문에 많은 시간과 비용을 소모했다. 하지만 최근 근적외선 센서의 개발로 인해 식물의 질병 식별을 시간적, 금전적으로 보다 효율적으로 판별할 수 있도록 발전 하였다. 본 논문에서는 다중 이미지 센서를 기반으로 무인 비행체인 드론을 사용하여 무 시들음병을 식별할 수 있는 컬러 및 근적외선 이미지에 대한 딥 러닝 프레임워크를 제안하고 비교한다. 또한 사용자가 딥 러닝 모델의 결과를 시각적으로 이해할 수 있도록 설명가능한 인공지능(XAI) 접근 방식을 사용한다. 다양한 실험에서 얻은 결과로 제안 하는 프레임워크는 정확도, 계산 복잡성 측면에서 기존 탐지 시스템에 비해 더 나은 성능을 보인다는 것을 보여주었 고, 근적외선 데이터셋은 식생 지수 계산을 통해 무 시들음병을 식별하는데 효과가 있음을 보여주었다.","Radish, loved worldwide, is one of the root vegetables and is used as a main ingredient in various dishes, so it has a lot of production and consumption. Radish is also used in kimchi, one of the most popular Korean foods. Due to rapid climate change in recent years, it can be easily exposed to the radish fusarium wilt disease, which greatly reduces the quality and yield of radishes. Traditional plant disease identification methods used to solve the Fusarium Wilt problem are time-consuming and costly because they rely on manually extracting features from collected RGB images. Recent developments in near-infrared sensors have made it possible to determine plant health more efficiently, both in time and money. In this paper, we propose and compare Deep Learning Framework for RGB and NIR(Near-infrared) images that can identify radish fusarium wilt disease using Drone, Unmanned Aerial Vehicle based on multiple image sensors. It also uses an XAI(eXplainable Artificial Intelligence) approach that allows users to visually understand the results of the Deep Learning model. As a result of the various experiments, the proposed Framework showed better performance compared to existing detection systems in terms of accuracy and computational complexity, while NIR Dataset showed that it was effective in identifying the radish fusarium wilt disease through the Vegetation index calculation."
콘포머 기반 한국어 음성인식,2021,[],,"We propose a speech recognition system based on conformer. Conformer is known to be convolution-augmented transformer, which combines transfer model for capturing global information with Convolution Neural Network (CNN) for exploiting local feature effectively. The baseline system is developed to be a transfer-based speech recognition using Long Short-Term Memory (LSTM)-based language model. The proposed system is a system which uses conformer instead of transformer with transformer-based language model. When Electronics and Telecommunications Research Institute (ETRI) speech corpus in AI-Hub is used for our evaluation, the proposed system yields 5.7 % of Character Error Rate (CER) while the baseline system results in 11.8 % of CER. Even though speech corpus is extended into other domain of AI-hub such as NHNdiguest speech corpus, the proposed system makes a robust performance for two domains. Throughout those experiments, we can prove a validation of the proposed system."
Pig Identification Using Deep Convolutional Neural Network Based on Different Age Range,2021,"['Convolutional neural network', 'Deep learning', 'Image classification', 'Individual identification']",,"Purpose In this study, the main objectives are to show the performance of deep convolutional neural network in identifying individual pig and investigate the accuracy level of CNN using four datasets made with pig’s face in different growing period.Methods Firstly, the datasets were captured in an experimental pig barn at a different time. Secondly, the datasets were filtered similar images using the structural similarity index measure (SSIM) for data preparation. Finally, face image classification is performed by employing a deep convolutional neural network (DCNN) namely ZFNet model.Results The results have shown that individual pig identification is outperformed while using the same age dataset in training and testing stage with an accuracy rate above 97%.Conclusions The model performed better in a combined dataset which is a combination of all individual data. For future recommendation, it would be beneficial to perform the effectiveness on a large scale of pigs, and a network model should be considered unsupervised learning in case of ageing classification."
연구단보: 얼굴 표정을 이용한 비접촉식 거짓말 탐지 시스템 개발 및 유의시점 분석,2021,"['Forensic investigation', 'Deep-learning', 'Deception detection', 'Face landmark', 'Convolutional neural network', 'Long short term memory']","본 연구는 기존의 접촉식 거짓말 탐지의 단점을 해결하기 위하여 비접촉식 거짓말 탐지 기법을 개발하고자 얼굴 표정 변화를 촬영하고 분석하였다. 거짓말 탐지를 위한 영상 데이터 얻고자 모의범죄 실험을 진행하였으며, 긴장정점검사(POT)을 이용하여 데이터를 수집하였다. 거짓말을 할 때의 표정 분석을 위해 합성곱 신경망(CNN) 계열의 stacked hourglass 네트워크 4층을 쌓은 모델을 이용하여 얼굴에서 특징점을 추출하였다. 영상에서 프레임 단위로 추출한 66개의 특징점을 시간 순으로 배치하여 장단기메모리(LSTM) 모델을 이용하여 거짓말 영상과 진실 영상을 분류하는 모델을 개발하였으며, 모델 학습을 진행하고 이를토대로 평가 데이터를 통한 분류 정확도는 85.19%이었다. 학습이 완료된 모델의 결과를 분석하기 위하여LSTM 활성도 분석을 진행하였다. 개발한 방법을 이용하여 사람의 얼굴에서의 표정 변화를 이용한 거짓말탐지의 가능성을 확인할 수 있었으며, 비접촉식 거짓말 탐지에 중요한 시점을 도출하여 추후 비접촉식 거짓말 탐지의 가능성을 확인할 수 있었다",
GAN으로 합성한 음성의 충실도 향상,2021,"['Generative Adversarial Networks', 'Frechet Inception Distance', 'Fidelity Improvement', 'Synthesized Voice', '생성적 적대 신경망', '프레쳇 인셉션 거리', '충실도 개선', '합성된 음성']",,"Although Generative Adversarial Networks (GANs) have gained great popularity in computer vision and related fields, generating audio signals independently has yet to be presented. Unlike images, an audio signal is a sampled signal consisting of discrete samples, so it is not easy to learn the signals using CNN architectures, which is widely used in image generation tasks. In order to overcome this difficulty, GAN researchers proposed a strategy of applying time-frequency representations of audio to existing image-generating GANs. Following this strategy, we propose an improved method for increasing the fidelity of synthesized audio signals generated by using GANs. Our method is demonstrated on a public speech dataset, and evaluated by Frechet Inception Distance (FID). When employing our method, the FID showed 10.504, but 11.973 as for the existing state of the art method (lower FID indicates better fidelity)."
MobileNetV2 기반의 개선된 Lightweight 모델을 이용한 열화도로 영상에서의 블랙 아이스 인식,2021,[],,"To accurately identify black ice and warn the drivers of information in advance so they can control speed and take preventive measures. In this paper, we propose a lightweight black ice detection network based on infrared road images. A black ice recognition network model based on CNN transfer learning has been developed. Additionally, to further improve the accuracy of black ice recognition, an enhanced lightweight network based on MobileNetV2 has been developed. To reduce the amount of calculation, linear bottlenecks and inverse residuals was used, and four bottleneck groups were used. At the same time, to improve the recognition rate of the model, each bottleneck group was connected to a 3×3 convolutional layer to enhance regional feature extraction and increase the number of feature maps. Finally, a black ice recognition experiment was performed on the constructed infrared road black ice dataset. The network model proposed in this paper had an accurate recognition rate of 99.07% for black ice."
Improvement of signal and noise performance using single image super-resolution based on deep learning in single photon-emission computed tomography imaging system,2021,"['Nuclear medicine imaging', 'Single photon emission computed tomography', 'Super-resolution', 'Deep learning', 'Deep convolutional neural network', 'Quantitative evaluation of image quality']",,"Because single-photon emission computed tomography (SPECT) is one of the widely used nuclear medicine imaging systems, it is extremely important to acquire high-quality images for diagnosis. In this study, we designed a super-resolution (SR) technique using dense block-based deep convolutional neural network (CNN) and evaluated the algorithm on real SPECT phantom images. To acquire the phantom images, a real SPECT system using a<sup>99m</sup>Tc source and two physical phantoms was used. To confirm the image quality, the noise properties and visual quality metric evaluation parameters were calculated. The results demonstrate that our proposed method delivers a more valid SR improvement by using dense block-based deep CNNs as compared to conventional reconstruction techniques. In particular, when the proposed method was used, the quantitative performance was improved from 1.2 to 5.0 times compared to the result of using the conventional iterative reconstruction. Here, we confirmed the effects on the image quality of the resulting SR image, and our proposed technique was shown to be effective for nuclear medicine imaging."
자기 지도 학습훈련 기반의 Noise2Void 네트워크를 이용한 PET 영상의 잡음 제거 평가 : 팬텀 실험,2021,"['합성 곱 신경망', '자기 지도 학습훈련', '영상 잡음 제거', 'Noise2Void', '양전자방출단층촬영', 'Convolutional neural network', 'Self-supervised learning training', 'Image denoising', 'Noise2Void', 'PET']",,"Positron emission tomography (PET) images is affected by acquisition time, short acquisition times results in low gamma counts leading to degradation of image quality by statistical noise. Noise2Void(N2V) is self supervised denoising model that is convolutional neural network (CNN) based deep learning. The purpose of this study is to evaluate denoising performance of N2V for PET image with a short acquisition time. The phantom was scanned as a list mode for 10 min using Biograph mCT40 of PET/CT (Siemens Healthcare, Erlangen, Germany). We compared PET images using NEMA image-quality phantom for standard acquisition time (10 min), short acquisition time (2min) and simulated PET image (S2 min). To evaluate performance of N2V, the peak signal to noise ratio (PSNR), normalized root mean square error (NRMSE), structural similarity index (SSIM) and radio-activity recovery coefficient (RC) were used. The PSNR, NRMSE and SSIM for 2 min and S2 min PET images compared to 10min PET image were 30.983, 33.936, 9.954, 7.609 and 0.916, 0.934 respectively. The RC for spheres with S2 min PET image also met European Association of Nuclear Medicine Research Ltd. (EARL) FDG PET accreditation program. We confirmed generated S2 min PET image from N2V deep learning showed improvement results compared to 2 min PET image and The PET images on visual analysis were also comparable between 10 min and S2 min PET images. In conclusion, noisy PET image by means of short acquisition time using N2V denoising network model can be improved image quality without underestimation of radioactivity."
합성곱 신경망의 Channel Attention 모듈 및 제한적인 각도 다양성 조건에서의 SAR 표적영상 식별로의 적용,2021,[],,"In the field of automatic target recognition(ATR) with synthetic aperture radar(SAR) imagery, it is usually impractical to obtain SAR target images covering a full range of aspect views. When the database consists of SAR target images with limited angular diversity, it can lead to performance degradation of the SAR-ATR system. To address this problem, this paper proposes a deep learning-based method where channel attention modules(CAMs) are inserted to a convolutional neural network(CNN). Motivated by the idea of the squeeze-and-excitation(SE) network, the CAM is considered to help improve recognition performance by selectively emphasizing discriminative features and suppressing ones with less information. After testing various CAM types included in the ResNet18-type base network, the SE CAM and its modified forms are applied to SAR target recognition using MSTAR dataset with different reduction ratios in order to validate recognition performance improvement under the limited angular diversity condition."
다양한 이미지 증대 기법에 따른 토마토 병충해 분류 성능 개선 연구,2021,"['Convolutional Neural Network', 'Image Augmentation', 'Image Selection', 'Tomato Disease']",,"Crop diseases are damaging agricultural food worldwide. Early detection of crop diseases is important to prevent damage to crops. However, it is difficult to distinguish crop diseases unless not expert. Therefore, in this paper, a crop diseases classification system that can recognize diseases even before expert judgment is proposed. The characteristics of diseases were learned and classified using Convolutional Neural Network(CNN). In addition, images are augmented to increase classification performance. To augment the image, a basic augmentation policy consisting of Random Crop and Random Horizontal Flip and Google""s AutoAugment are used. Then, the augmented image was selected as an base augmentation model by setting a threshold and then trained. We compared the performance of the original, augmentation model, and image selection model. As a result, the image selection model set to the threshold value of 0.7 in AutoAugment achieved the performance of F1 Score 0.958"
Boosting Image Caption Generation with Parts of Speech,2021,"['이미지 캡션 생성', '인코더-디코더 구조', '품사', '컴퓨터 비전', 'image caption generation', 'encoder-decoder architecture', 'parts of speech', 'computer vision']",,"With the integration of smart devices and reliance on AI into our daily lives, the ability to generate image caption is becoming increasingly important in various fields such as guidance for visually-impaired individuals, human-computer interaction and so on. In this paper, we propose a novel approach based on parts of speech (POS), such as nouns and verbs extracted from image to enhance the image caption generation. The proposed model exploits multiple CNN encoders, which were specifically trained to identify features related to POS, and feed them into an LSTM decoder to generate image captions. We conducted experiments involving both Flickr30k and MS-COCO datasets using several text metrics and additional human surveys to validate the practical effectiveness of the proposed model."
체압 분포 영상 초고해상도 보정을 이용한 욕창 예방을 위한 환자 자세 추정,2021,"['Pressure ulcer', 'super-resolution', 'generative adversarial network', 'posture detection']",,"In this study, to improve the prediction of pressure ulcer spots, we have developed super-resolution (SR) techniques to reconstruct a high-resolution (HR) pressure image from a low-resolution (LR) body pressure image to overcome the limitations of sensor resolution. We implemented a super-resolution generative adversarial network (SRGAN) to reconstruct pressure images and a convolution neural network (CNN) to predict posture. To evaluate the similarity between the original pressure image and the 4× rescaled LR body pressure image restored using SR technology, we used image quality assessment (IQA) technology, peak signal-to-noise ratio (PSNR), and structural similarity (SSIM). The reconstructed pressure images were classified into four patient postures (supine, right side, left side, and others) with 98.37% accuracy showing the feasibility of practical implementation."
이미지 증대 기법을 이용한 토마토 병충해 분류,2021,"['Convolutional Neural Network', 'Generative Adversarial Network', 'Image Augmentation', 'Tomato Disease']",,"The tomato is one of important crops in the world market with high commercial value. The early detection of disease is crucial for an successful crop yield. Many studies have recently been conducted to identify plant disease. In this paper, tomato disease classification using leaf images is proposed. Using the convolutional neural network(CNN), the features of disease are extracted and learned to classify. Data augmentation methods, Google’s AutoAugment algorithm and GAN(Generative Adversarial Networks), are used to increase tomato disease data. The classification model classifies nine classes of tomato disease. We compared the original model with the data augmentation models and explored that the classification that produced good performance. As a result, the SVHN policy of AutoAugment model achieved F1 Score 0.945."
funcGNN과 Siamese Network의 코드 유사성 분석 성능비교,2021,"['Code Similarity', 'funcGNN', 'Siamese Network', 'Control Flow Graph', 'Adjacency Matrices']",,"As artificial intelligence technologies, including deep learning, develop, these technologies are being introduced to code similarity analysis. In the traditional analysis method of calculating the graph edit distance (GED) after converting the source code into a control flow graph (CFG), there are studies that calculate the GED through a trained graph neural network (GNN) with the converted CFG, Methods for analyzing code similarity through CNN by imaging CFG are also being studied. In this paper, to determine which approach will be effective and efficient in researching code similarity analysis methods using artificial intelligence in the future, code similarity is measured through funcGNN, which measures code similarity using GNN, and Siamese Network, which is an image similarity analysis model. The accuracy was compared and analyzed. As a result of the analysis, the error rate (0.0458) of the Siamese network was bigger than that of the funcGNN (0.0362)."
Intrusion Detection for Network Based Cloud Computing By Custom RC-NN and Optimization,2021,"['Intrusion detection', 'Neural networks', 'Deep learning', 'Cloud computing', 'Network security']",,"Intrusion detection acts as a vital function in providing information security, and additionally the key technology is to precisely classify diverse attacks. Intrusion detection system (IDS) is identified as an important security issue within the cloud network environment. In this paper, IDS is given based on an innovative optimized custom RC-NN (Recurrent Convolutional Neural Network) which is proposed for intrusion detection along with the Ant Lion optimization algorithm. By this method, CNN (Convolutional Neural Network) is made hybrid with LSTM (Long Short Term Memory). Thus, all the attacks identified with the network layer of cloud are classified efficiently. The experimental results shown below describe the presentation of the IDS classification model with high accuracy, thus improving the detection rate or error rate. The optimized custom RC-NN-IDS model thus achieved an improved classification accuracy of 94% and also a decreased error rate of 0.0012. Additionally true positive rate, true negative rate and precision are considered as performance metrics. The proposed approach is evaluated using the DARPA IDS evaluation Data Sets and CSE-CIC-IDS2018 dataset and is compared with some existing approaches."
마이크로프로세서 기반의 얼굴 마스크 감지,2021,"['TinyML', 'Maixduino', 'Micropython', 'MobileNet', 'Mask detection']",,"This paper proposes an embedded system that detects mask and face recognition based on a microprocessor instead of Nvidia Jetson Board what is popular development kit. We use a class of efficient models called Mobilenets for mobile and embedded vision applications. MobileNets are based on a streamlined architechture that uses depth- wise separable convolutions to build light weight deep neural networks. The device used a Maix development board with CNN hardware acceleration function, and the training model used MobileNet_V2 based SSD(Single Shot Multibox Detector) optimized for mobile devices. To make training model, 7553 face data from Kaggle are used. As a result of test dataset, the AUC (Area Under The Curve) value is as high as 0.98."
Optimizing TensorFlow Performance by Reconstructing the Convolution Routine,2021,"['TensorFlow', 'Profiling', 'Optimization', 'Batch']",,"Using deep learning, we can currently build computational models composed of multiple processing layers to learn representations of data. Convolutional neural networks (CNNs) have been widely adopted to achieve significant performance in image recognition and classification. TensorFlow, an open-source deep learning framework from Google, uses profiling to select one convolution algorithm, from among several available, as the core of a CNN to deliver the best performance in terms of execution time and memory usage. However, the overhead from profiling is considerably significant, because TensorFlow executes and profiles all the available algorithms for the best selection whenever an application is launched. We observe that memory usage overshoots during profiling, which limits data parallelism, and thus, fails to deliver maximum performance. In this paper, we present a novel profiling method to reduce overhead by storing the profile result from the first run and reusing it from the second run on. Using Inception-V3, we achieved up to 1.12 times and 1.11 times higher throughput, compared to the vanilla TensorFlow and TensorFlow with XLA JIT compilation, respectively, without losing accuracy."
온사이트 지진조기경보를 위한 딥러닝 기반 실시간 오탐지 제거,2021,"['Earthquake early warning', 'Onsite warning', 'False-pick', 'False alarm', 'Deep learning', 'Convolutional neural network']",,"This paper presents a real-time, false-pick filter based on deep learning to reduce false alarms of an onsite Earthquake Early Warning (EEW) system. Most onsite EEW systems use P-wave to predict S-wave. Therefore, it is essential to properly distinguish P-waves from noises or other seismic phases to avoid false alarms. To reduce false-picks causing false alarms, this study made the EEWNet Part 1 'False-Pick Filter' model based on Convolutional Neural Network (CNN). Specifically, it modified the Pick_FP (Lomax et al.) to generate input data such as the amplitude, velocity, and displacement of three components from 2 seconds ahead and 2 seconds after the P-wave arrival following one-second time steps. This model extracts log-mel power spectrum features from this input data, then classifies P-waves and others using these features. The dataset consisted of 3,189,583 samples: 81,394 samples from event data (727 events in the Korean Peninsula, 103 teleseismic events, and 1,734 events in Taiwan) and 3,108,189 samples from continuous data (recorded by seismic stations in South Korea for 27 months from 2018 to 2020). This model was trained with 1,826,357 samples through balancing, then tested on continuous data samples of the year 2019, filtering more than 99% of strong false-picks that could trigger false alarms. This model was developed as a module for USGS Earthworm and is written in C language to operate with minimal computing resources."
Edge Computing Based Surveillance Framework for Real Time Activity Recognition,2021,"['Edge computing', 'Convolutional Neural Network', 'Suspicious activity']",,"Closed Circuit Television (CCTV) based Surveillance has become the fundamental part of the security Systems. In most cases, surveillance feeds are only used as evidence. The emergence of Edge Computing gives hope for enabling real time surveillance systems that focuses on prevention of crimes. The proposed architecture consists of a Convolutional Neural Network (CNN) enabled in an edge device, with reduced computational complexity, which classifies various actions like Pulling, pushing and other hand movements and locates the identified activities in the image frame using bounding boxes. The proposed architecture gives an alert whenever a suspicious activity is detected. The system was found efficient when validated against the Dataset taken from the SRM IST Campus."
기상 데이터와 기상 위성 영상을 이용한 다중 딥러닝 모델 기반 일사량 예측,2021,"['Satellites Image', 'Weather Data', 'Multi Deep Learning Model', 'Radiation Prediction', 'Artificial Intelligence']","딥러닝은 데이터의 품질과 모델에 따라 예측 성능에 차이를 보인다. 본 연구는 발전량 예측에 가장 영향을 주는 일사량 예측을 위한 최적의 딥러닝 모델을 구축하기 위해 다양한 입력 데이터와 다중 딥러닝 모델을 사용하였다. 입력 데이터는 기상청의 기상 데이터와 천리안 기상영상을 기상청 지역의 영상을 분할하여 사용하였다, 본 연구는 기본적인 딥러닝 모델인 DNN, LSTM, CNN 모델에 대해 중간층의 깊이와 노드를 변경하여 일사량을 예측하여, 비교 평가하였다, 또한, 각 모델에서 가장 좋은 오차율을 가진 모델을 연결한 다증 딥러닝 모델을 구축하여 일사량을 예측하였다. 실험 결과로서 다중 딥러닝 모델인 모델 A의 RMSE는 0.0637이며, 모델 B의 RMSE는 0.07062이며, 모델 C의 RMSE는 0.06052로서 단일 모델보다 모델 A 그리고 모델 C의 오차율이 좋았다. 본 연구는 실험을 통해 두 개 이상의 모델을 연결한 모델이 향상된 예측률과 안정된 학습 결과를 보였다.","Deep learning shows differences in prediction performance depending on data quality and model. This study uses various input data and multiple deep learning models to build an optimal deep learning model for predicting solar radiation, which has the most influence on power generation prediction. did. As the input data, the weather data of the Korea Meteorological Administration and the clairvoyant meteorological image were used by segmenting the image of the Korea Meteorological Agency. , comparative evaluation, and predicting solar radiation by constructing multiple deep learning models connecting the models with the best error rate in each model. As an experimental result, the RMSE of model A, which is a multiple deep learning model, was 0.0637, the RMSE of model B was 0.07062, and the RMSE of model C was 0.06052, so the error rate of model A and model C was better than that of a single model. In this study, the model that connected two or more models through experiments showed improved prediction rates and stable learning results."
Quality control of seismic data based on convolutional neural network,2021,"['파워스펙트럼밀도', '품질관리', '심층학습', '합성곱 신경망', 'power spectral density', 'quality control', 'deep learning', 'convolutional neural network']",,"Installing more seismic stations may result in improving the capability of earthquake monitoring and shortening the time to report the occurrence of earthquakes or deliver public earthquake warnings. However, accordingly, it becomes difficult to assess the condition of seismic instrument. The goal of this study is to develop an automated method for assessing the quality of seismic data, which is based on power spectral densities (PSD) of one-hour waveform data. We collected 10,309 PSDs of broadband seismometers and 4,452 PSDs of accelerometers recorded from 2016, 2017 and 2019, and used them as the input of the convolutional neural network (CNN), a class of deep learning. Two deep CNNs for broadband seismometer and accelerometer were trained to automatically determine the condition of seismic data: normal and abnormal conditions. We find that the condition of seismic data determined by the CNNs have an accuracy of 99.9% and they can successfully determine the condition from PSDs of 15-minute waveforms. The outstanding performance of the trained models indicates that this can be a very effective tool for assessing the condition of seismic instrument."
인터뷰 형식의 오디오 데이터를 이용한 전이 학습모델 기반 우울증 진단,2021,"['AI technology', 'Depression diagnosis', 'Transfer Learning', 'Interview-type audio data', 'two-dimensional images']",,"Depression can lead to serious mental and physical illness, so early detection is important. Currently, a system to help early detection of depression using AI technology is being developed in various ways. In particular, research on diagnosing depression through voices that can be easily encountered in daily life is being actively conducted. In this paper, we compare and analyze the depression diagnosis performance of transfer learning models using interview-type audio data. Data use the DAIC-WOZ Depression Database, which contains audio files in interview-type. As the transfer learning model, it uses VGGish and YAMNet built based on Convolutional Neural Network(CNN) among deep learning models that are widely being used for audio classification. The characteristics of speech data are extracted to black-and-white and color two-dimensional images using the Bark spectrogram, Mel spectrogram, and Log Mel-spectrogram methods. The performance of the depression diagnosis model is higher in YAMNet than in VGGish. In case that black-and-white images are input, YAMNet’s performance was the highest with 94.48% when mel spectrogram features were used.On the other hand, in case that color images are input, YAMNet’s performance was the highest at 97.34% when bark spectrogram features were used proving that it is most suitable for diagnosing depression."
딥러닝을 이용한 육불화텅스텐(WF6) 제조 공정의 지능형 영상 감지 시스템 구현,2021,"['object detection', 'you only look once (YOLO)', 'tungsten hexafluoride (WF6)', 'reduction', 'defect detection.']",,"Through the process of chemical vapor deposition, Tungsten Hexafluoride (WF6) is widely used by the semiconductor industry to form tungsten films. Tungsten Hexafluoride (WF6) is produced through manufacturing processes such as pulverization, wet smelting, calcination and reduction of tungsten ores. The manufacturing process of Tungsten Hexafluoride (WF6) is required thorough quality control to improve productivity. In this paper, a real-time detection system for oxidation defects that occur in the manufacturing process of Tungsten Hexafluoride (WF6) is proposed. The proposed system is implemented by applying YOLOv5 based on Convolutional Neural Network (CNN); it is expected to enable more stable management than existing management, which relies on skilled workers. The implementation method of the proposed system and the results of performance comparison are presented to prove the feasibility of the method for improving the efficiency of the WF6 manufacturing process in this paper. The proposed system applying YOLOv5s, which is the most suitable material in the actual production environment, demonstrates high accuracy (mAP@0.5 99.4 %) and real-time detection speed (FPS 46)."
Delineation of ischemic lesion from brain MRI using attention gated fully convolutional network,2021,"['Deep neural network', 'FCN', 'Attention', 'Ischemic lesion segmentation', 'MRI']",,"Precise delineation of the ischemic lesion from unimodal Magnetic Resonance Imaging (MRI) is a challenging task due tothe subtle intensity difference between the lesion and normal tissues. Hence, multispectral MRI modalities are used for characterizingthe properties of brain tissues. Traditional lesion detection methods rely on extracting significant hand-engineeredfeatures to differentiate normal and abnormal brain tissues. But the identification of those discriminating features is quitecomplex, as the degree of differentiation varies according to each modality. This can be addressed well by ConvolutionalNeural Networks (CNN) which supports automatic feature extraction. It is capable of learning the global features from imageseffectively for image classification. But it loses the context of local information among the pixels that need to be retained forsegmentation. Also, it must provide more emphasis on the features of the lesion region for precise reconstruction. The majorcontribution of this work is the integration of attention mechanism with a Fully Convolutional Network (FCN) to segmentischemic lesion. This attention model is applied to learn and concentrate only on salient features of the lesion region bysuppressing the details of other regions. Hence the proposed FCN with attention mechanism was able to segment ischemiclesion of varying size and shape. To study the effectiveness of attention mechanism, various experiments were carried outon ISLES 2015 dataset and a mean dice coefficient of 0.7535 was obtained. Experimental results indicate that there is animprovement of 5% compared to the existing works."
딥블록: 웹 기반 딥러닝 교육용 플랫폼,2021,"['Artificial Intelligence', 'Block Coding', 'Cloud Service', 'Deep Learning', 'Education Platform']",,"Recently, researches and projects of companies based on artificial intelligence have been actively carried out. Various services and systems are being grafted with artificial intelligence technology. They become more intelligent. Accordingly, interest in deep learning, one of the techniques of artificial intelligence, and people who want to learn it have increased. In order to learn deep learning, deep learning theory with a lot of knowledge such as computer programming and mathematics is required. That is a high barrier to entry to beginners. Therefore, in this study, we designed and implemented a web-based deep learning platform called DeepBlock, which enables beginners to implement basic models of deep learning such as DNN and CNN without considering programming and mathematics. The proposed DeepBlock can be used for the education of students or beginners interested in deep learning."
CAE 알고리즘을 이용한 레이더 강우 보정 평가,2021,[],,"As the frequency of localized heavy rainfall has increased during recent years, the importance of high-resolution radar data has also increased. This study aims to correct the bias of Dual Polarization radar that still has a spatial and temporal bias. In many studies, various statistical techniques have been attempted to correct the bias of radar rainfall. In this study, the bias correction of the S-band Dual Polarization radar used in flood forecasting of ME was implemented by a Convolutional Autoencoder (CAE) algorithm, which is a type of Convolutional Neural Network (CNN). The CAE model was trained based on radar data sets that have a 10-min temporal resolution for the July 2017 flood event in Cheongju. The results showed that the newly developed CAE model provided improved simulation results in time and space by reducing the bias of raw radar rainfall. Therefore, the CAE model, which learns the spatial relationship between each adjacent grid, can be used for real-time updates of grid-based climate data generated by radar and satellites."
딥러닝 기반 손 그림 심리분석 알고리즘 연구,2021,"['그림 심리 검사', '객체 분류', '딥러닝', '객체 검출', '계층적 구조', 'Art Therapy', 'Classification', 'Deep learning', 'Object detection', 'Hierarchical structure']",,"From simple scribbles of children to paintings by world-class artists, human psychology is melted into drawings. They express the concept, experience, desire, and attitude to the environment they have acquired, and can identify the persons tendency and personalities. This can be used as a medium for psychotherapy, called art therapy. We devise an efficient scheme to analyze the hand drawings based on a hierarchical structure, which allows us to produce certain results. First, we extract some separated parts which is consisted of whole objects by object detection. With the extracted parts, we perform the classification task based on 2D CNN to define key attribute. For the given image, the analyzed report is constructed based on the key attributes. The proposed algorithm is applied to tree test and cat test among many drawing psychological tests, and achieves an analysis accuracy of about 93% and 96%, respectively."
컨볼루션 신경망 모델을 이용한 분류에서 입력 영상의 종류가 정확도에 미치는 영향,2021,"['X-ray', 'Convolutional neural network', 'Classification', 'Deep learning']",,"The purpose of this study is to classify TIFF images, PNG images, and JPEG images using deep learning, and to compare the accuracy by verifying the classification performance. The TIFF, PNG, and JPEG images converted from chest X-ray DICOM images were applied to five deep neural network models performed in image recognition and classification to compare classification performance. The data consisted of a total of 4,000 X-ray images, which were converted from DICOM images into 16-bit TIFF images and 8-bit PNG and JPEG images. The learning models are CNN models - VGG16, ResNet50, InceptionV3, DenseNet121, and EfficientNetB0. The accuracy of the five convolutional neural network models of TIFF images is 99.86%, 99.86%, 99.99%, 100%, and 99.89%. The accuracy of PNG images is 99.88%, 100%, 99.97%, 99.87%, and 100%. The accuracy of JPEG images is 100%, 100%, 99.96%, 99.89%, and 100%. Validation of classification performance using test data showed 100% in accuracy, precision, recall and F1 score. Our classification results show that when DICOM images are converted to TIFF, PNG, and JPEG images and learned through preprocessing, the learning works well in all formats. In medical imaging research using deep learning, the classification performance is not affected by converting DICOM images into any format."
Android Malware Detection System using Deep Learning and Code Item,2021,"['Android malware detection', 'Code item', 'Convolutional neural network', 'Grayscale image', 'Static analysis']",,"This paper proposes an Android malware detection method that reduces the overhead of 2-dimensional image generation from Android packages (APK) to build deep learning models that effectively discern whether an application is malware. Other image-based malware detection methods typically use the whole Android application executable file (DEX file) or a large section that often contains redundant information. However, our technique generates grayscale images using minimal representative data from the code item section. Two-dimensional images are utilized by a state-of-the-art feature extractor and spatial pattern recognition technique with a convolutional neural networks (CNN) architecture for image classification. Positive results were obtained for the execution time and memory usage compared to other methods. The code item section binaries contain relevant information about an Android application."
인공지능(AI) 기반 치매 조기진단 방법론에 관한 연구,2021,"['인공지능', '딥러닝', '치매', '치매 조기진단', '아밀로이드 플라크', 'AI', 'Deep learning', 'Dementia', 'Early diagnosis of dementia', 'Amyloid-plaques']",,"The number of dementia patients in Korea is estimated to be over 800,000, and the severity of dementia is becoming a social problem. However, no treatment or drug has yet been developed to cure dementia worldwide. The number of dementia patients is expected to increase further due to the rapid aging of the population. Currently, early detection of dementia and delaying the course of dementia symptoms is the best alternative. This study presented a methodology for early diagnosis of dementia by measuring and analyzing amyloid plaques. This vital protein can most clearly and early diagnose dementia in the retina through AI-based image analysis. We performed binary classification and multi-classification learning based on CNN on retina data. We also developed a deep learning algorithm that can diagnose dementia early based on pre-processed retinal data. Accuracy and recall of the deep learning model were verified, and as a result of the verification, and derived results that satisfy both recall and accuracy. In the future, we plan to continue the study based on clinical data of actual dementia patients, and the results of this study are expected to solve the dementia problem."
이동체에서 2D 선레이저를 이용한 보도블럭 프로파일링 및 균열 검출 기법,2021,"['2D laser profiling', 'Crack detection', 'Pavement blocks monitoring', 'Pavement blocks profile']",,"In this paper, we propose an on-line mechanism that simultaneously detects cracks and profiling pavement blocks to detect the displacement of ground surface adjacent to the excavation in the urban area. The proposed method utilizes a 2D laser to profile the information about pavement blocks including the depth and distance among them. In particular, it is designed to enable the detection of cracks and portholes at runtime. For the experiment, real data was collected through Gocator, and trainng was carried out using Faster R-CNN. The performance evaluation shows that our detection precision and recall are more than 90% and the pavement blocks are profiled at the same time. Our proposed mechanism can be used for monitoring management to quantitatively detect the level of excavation risk before a large-scale ground collapse occurs."
교통사고 심각 정도 예측을 위한 TATI 모델 제안,2021,"['TATI', 'Color Representation', 'Severity Prediction', 'Traffic Accident', '컬러 표현', '심각 정도 예측', '교통사고']",,"The TATI model is a Traffic Accident Text to RGB Image model, which is a methodology proposed in this paper for predicting the severity of traffic accidents. Traffic fatalities are decreasing every year, but they are among the low in the OECD members. Many studies have been conducted to reduce the death rate of traffic accidents, and among them, studies have been steadily conducted to reduce the incidence and mortality rate by predicting the severity of traffic accidents. In this regard, research has recently been active to predict the severity of traffic accidents by utilizing statistical models and deep learning models. In this paper, traffic accident dataset is converted to color images to predict the severity of traffic accidents, and this is done via CNN models. For performance comparison, we experiment that train the same data and compare the prediction results with the proposed model and other models. Through 10 experiments, we compare the accuracy and error range of four deep learning models. Experimental results show that the accuracy of the proposed model was the highest at 0.85, and the second lowest error range at 0.03 was shown to confirm the superiority of the performance."
Diabetic Retinopathy Diagnosis Based on Deep Learning and Independent Subspace Analysis,2021,"['당뇨성 망막변증 진단', '딥러닝', '독립 부분 공간 분석', '전이 학습', '자기 지도 학습', 'Diabetic Retinopathy Diagnosis', 'Deep Learning', 'Independent Subspace Analysis', 'Transfer Learning', 'Self-supervised Learning']","당뇨성 망막변증 진단 시스템을 개발하기 위해서 안저 영상과 인공지능 기법을 사용하는 것은 산업계에서 유망한 분야중의 하나이다. 당뇨성 망막변증의 검출은 영상의 색깔, 해상도, 밝기의 큰 변동과 클래스간의 불균형 분포를 갖는 데이터, 영상내의 병변이 아주 작아서 힘든 작업이다. 이 논문의 목적은 당뇨성 망막변증의 검출을 위한 더 좋은 방법을 찾는 것이다. 합성곱 신경회로망에 기반한 딥러닝과 독립 부분 공간 알고리즘을 표현을 학습하고 안저 데이터로부터 특징들을 추출하기 위해서 구현하였다. 이렇게 추출된 특징들은 당뇨성 망막변증을 검출하기 위해 분류기에 입력된다. 감독학습을 사용하여 당뇨성 망막변증을 검출하는데 최상의 결과를 얻었다.","Using fundus images and artificial intelligence(AI) technology to develop a Diabetic Retinopathy(DR) diagnostic system has been one of the hot research topics in the industry. DR detection is a challenging task due to tiny lesions in the images, inter-class imbalanced data distribution, and a huge variation in the brightness, resolution, and color of images. The aim of this paper is to explore better ways for DR detection. Convolutional neural network(CNN) based deep learning and independent subspace analysis(ISA) algorithm are implemented to learn representation and extract features from fundus data. Then these extracted features go through a classification to detect DR. We achieved the best result of DR detection performed using supervised learning."
BM3D and Deep Image Prior based Denoising for the Defense against Adversarial Attacks on Malware Detection Networks,2021,"['Malware detection', 'Deep Learning', 'Adversarial Examples', 'Denoising', 'BM3D', 'Deep Image Prior']",,"Recently, Machine Learning-based visualization approaches have been proposed to combat the problem of malware detection. Unfortunately, these techniques are exposed to Adversarial examples. Adversarial examples are noises which can deceive the deep learning based malware detection network such that the malware becomes unrecognizable. To address the shortcomings of these approaches, we present Blockmatching and 3D filtering (BM3D) algorithm and deep image prior based denoising technique to defend against adversarial examples on visualization-based malware detection systems. The BM3D based denoising method eliminates most of the adversarial noise. After that the deep image prior based denoising removes the remaining subtle noise. Experimental results on the MS BIG malware dataset and benign samples show that the proposed denoising based defense recovers the performance of the adversarial attacked CNN model for malware detection to some extent."
성인 학습자의 학습 추이 분석을 위한 인공지능 기반 알고리즘 모델 개발 및 평가,2021,[],,"To improve educational performance by analyzing the learning trends of adult learners of Open High Schools, various algorithm models using artificial intelligence were designed and performance was evaluated by applying them to real data. We analyzed Log data of 115 adult learners in the cyber education system of Open High Schools. Most adult learners of Open High Schools learned more than recommended learning time, but at the end of the semester, the actual learning time was significantly reduced compared to the recommended learning time. In the second half of learning, the participation rate of VODs, formation assessments, and learning activities also decreased. Therefore, in order to improve educational performance, learning time should be supported to continue in the second half. In the latter half, we developed an artificial intelligence algorithm models using Tensorflow to predict learning time by data they started taking the course. As a result, when using CNN(Convolutional Neural Network) model to predict single or multiple outputs, the mean-absolute-error is lowest compared to other models."
빅데이터를 활용한 인공지능 주식 예측 분석,2021,[],,"With the advent of the low interest rate era, many investors are flocking to the stock market. In the past stock market, people invested in stocks labor-intensively through company analysis and their own investment techniques. However, in recent years, stock investment using artificial intelligence and data has been widely used. The success rate of stock prediction through artificial intelligence is currently not high, so various artificial intelligence models are trying to increase the stock prediction rate. In this study, we will look at various artificial intelligence models and examine the pros and cons and prediction rates between each model. This study investigated as stock prediction programs using artificial intelligence artificial neural network (ANN), deep learning or hierarchical learning (DNN), k-nearest neighbor algorithm(k-NN), convolutional neural network (CNN), recurrent neural network (RNN), and LSTMs."
A Study on Pagoda Image Search Using Artificial Intelligence (AI) Technology for Restoration of Cultural Properties,2021,"['Enter key words or phrases in alphabetical order', 'separated by commas']",,"The current cultural assets are being restored depending on the opinions of experts (craftsmen). We intend to introduce digitalized artificial intelligence techniques, excluding the personal opinions of experts on reconstruction of such cultural properties. The first step toward restoring digitized cultural properties is separation. The restoration of cultural properties should be reorganized based on recorded documents, period historical backgrounds and regional characteristics. The cultural properties in the form of photographs or images should be collected by separating the background. In addition, when restoring cultural properties most of them depend a lot on the tendency of the restoring person workers. As a result, it often occurs when there is a problem in the accuracy and reliability of restoration of cultural properties. In this study, we propose a search method for learning stored digital cultural assets using AI technology. Pagoda was selected for restoration of Cultural Properties. Pagoda data collection was collected through the Internet and various historical records. The pagoda data was classified by period and region, and grouped into similar buildings. The collected data was learned by applying the well-known CNN algorithm for artificial intelligence learning. The pagoda search used Yolo Marker to mark the tower shape. The tower was used a total of about 100-10,000 pagoda data. In conclusion, it was confirmed that the probability of searching for a tower differs according to the number of pagoda pictures and the number of learning iterations. Finally, it was confirmed that the number of 500 towers and the epochs in training of 8000 times were good. If the test result exceeds 8,000 times, it becomes overfitting. All so, I found a phenomenon that the recognition rate drops when the enemy repeatedly learns more than 8,000 times. As a result of this study, it is believed that it will be helpful in data gathering to increase the accuracy of tower restoration."
BM3D and Deep Image Prior based Denoising for the Defense against Adversarial Attacks on Malware Detection Networks,2021,"['Malware detection', 'Deep Learning', 'Adversarial Examples', 'Denoising', 'BM3D', 'Deep Image Prior']",,"Recently, Machine Learning-based visualization approaches have been proposed to combat the problem of malware detection. Unfortunately, these techniques are exposed to Adversarial examples. Adversarial examples are noises which can deceive the deep learning based malware detection network such that the malware becomes unrecognizable. To address the shortcomings of these approaches, we present Block-matching and 3D filtering (BM3D) algorithm and deep image prior based denoising technique to defend against adversarial examples on visualization-based malware detection systems. The BM3D based denoising method eliminates most of the adversarial noise. After that the deep image prior based denoising removes the remaining subtle noise. Experimental results on the MS BIG malware dataset and benign samples show that the proposed denoising based defense recovers the performance of the adversarial attacked CNN model for malware detection to some extent."
DCGAN을 이용한 잡육에서의 바늘 검출,2021,"['X-Ray image', 'Deep convolutional generative adversarial network', 'DCGAN', 'Needle detection', 'Foreign object']",,"Usually, during slaughter, the meat is divided into large chunks by part after deboning. The meat chunks are inspected for the presence of needles with an X-ray scanner. Although needles in the meat chunks are easily detectable, they can also be found in trimmings and meat offals, where meat skins, fat chunks, and pieces of meat from different parts get agglomerated. Detection of needles in trimmings and meat offals becomes challenging because of many needle-like patterns that are detected by the X-ray scanner. This problem can be solved by learning the trimmings or meat offals using deep learning. However, it is not easy to collect a large number of learning patterns in trimmings or meat offals. In this study, we demonstrate the use of deep convolutional generative adversarial network (DCGAN) to create fake images of trimmings or meat offals and train them using a convolution neural network (CNN)."
A Development of Nurse Scheduling Model Based on Q-Learning Algorithm,2021,"['Nurse Schedule', 'Nurse Scheduling Problem', 'Reinforcement Learning', 'Q-Learning', 'Fairness Indicator Score']",,"In this paper, We focused the issue of creating a socially problematic nurse schedule. The nurse schedule should be prepared in consideration of three shifts, appropriate placement of experienced workers, the fairness of work assignment, and legal work standards. Because of the complex structure of the nurse schedule, which must reflect various requirements, in most hospitals, the nurse in charge writes it by hand with a lot of time and effort. This study attempted to automatically create an optimized nurse schedule based on legal labor standards and fairness. We developed an I/O Q-Learning algorithm-based model based on Python and Web Application for automatic nurse schedule. The model was trained to converge to 100 by creating an Fairness Indicator Score(FIS) that considers Labor Standards Act, Work equity, Work preference. Manual nurse schedules and this model are compared with FIS. This model showed a higher work equity index of 13.31 points, work preference index of 1.52 points, and FIS of 16.38 points. This study was able to automatically generate nurse schedule based on reinforcement Learning. In addition, as a result of creating the nurse schedule of E hospital using this model, it was possible to reduce the time required from 88 hours to 3 hours. If additional supplementation of FIS and reinforcement Learning techniques such as DQN, CNN, Monte Carlo Simulation and AlphaZero additionally utilize a more an optimized model can be developed."
컴퓨팅 부하 예측 DNN 모델 기반 디지털 트윈 소프트웨어 개발 프레임워크,2021,"['Artificial intelligence cloud', 'data-driven model', 'load estimation', 'digital twin', 'autonomous things']",,"Artificial intelligence clouds help to efficiently develop the autonomous things integrating artificial intelligence technologies and control technologies by sharing the learned models and providing the execution environments. The existing autonomous things development technologies only take into account for the accuracy of artificial intelligence models at the cost of the increment of the complexity of the models including the raise up of the number of the hidden layers and the kernels, and they consequently require a large amount of computation. Since resource-constrained computing environments, could not provide sufficient computing resources for the complex models, they make the autonomous things violate time criticality. In this paper, we propose a digital twin software development framework that selects artificial intelligence models optimized for the computing environments. The proposed framework uses a load estimation DNN model to select the optimal model for the specific computing environments by predicting the load of the artificial intelligence models with digital twin data so that the proposed framework develops the control software. The proposed load estimation DNN model shows up to 20% of error rate compared to the formula-based load estimation scheme by means of the representative CNN models based experiments."
Age-invariant Face Recognition by Coupled Residual Learning Networks,2021,"['연령무관 얼굴인식', '심층학습', '연령모달리티', '컨볼루션신경망', 'age-invariant face recognition', 'deep learning', 'age modality', 'convolutional neural network']","현장에서 사용되는 응용 프로그램에서 연령에 무관한 얼굴 인식에 대한 연구가 그의 큰 잠재력으로 인하여 급증하고 있는 추세이다. 연령에 무관한 얼굴을 인식하는 연구의 어려움은 얼굴 모양이 시간이 지남에 따라 노화현상 등으로 인하여 스스로 변한다는 것이다. 따라서 나이 차이가 큰 경우에 얼굴을 인식하기가 쉽지 않다. 본 논문에서는 연령 무관 얼굴 인식을 위한 잔차 학습 모듈 기반의 새로운 결합 네트워크 아키텍처를 제안하였다. VGGFace2를 학습한 Inception-ResnetV1를 백본 네크워크로 사용하였으며, 하나의 연령모드에 보상을 추가하여, 잔차학습 모듈은 연령에 따른 모드 불일치(ARMD)를 감소시켜 다른 모드에 유사하도록 표현할 수 있다. ARMD 손실은 서로 다른 모드 간의 코사인거리를 최소화하여 모드 별 불일치를 완화시키도록 하였다. 실험결과는 교차연령 얼굴데이터인 CACD_VS, FGNET, GFR 및 LFW 데이터에서 제안 알고리즘이 다른 알고리즘에 비하여 우수한 성능을 나타내는 것을 보여주었다.","Age-Invariant Face Recognition (AIFR) has been drawing an increasing research interest, due to its potential in real-world applications. The crucial challenge of AIFR arises from the fact that the facial appearance is subject to significant intra-class variations caused by the aging process over time, hence, matching faces with big age gaps is challenging. In this paper, we propose a new coupled network architecture based on the residual learning module for age-invariant face recognition. We implemented the Inception-ResnetV1 (pre-trained on VGGFace2) as the backbone Convolutional Neural Network (CNN). By adding compensation to one of the modalities, the residual learning module reduces Age-Related Modality Discrepancy (ARMD) of which representation can be close to the other modality. The ARMD loss alleviates modal discrepancy by minimizing the cosine distance between different modalities. Experimental results on the cross-age datasets including CACD_VS, FGNET, and General Face Recognition (GFR) dataset indicate that the proposed method can obtain superior performance."
흉부 X-선 영상에서 심장비대증 분류를 위한 합성곱 신경망 모델 제안,2021,"['합성곱 신경망', '딥러닝', '흉부 X-선', '분류', 'Convolutional Neural Network', 'Deep learning', 'Chest X-ray', 'Classification']","본 논문에서는 흉부 X선 영상에서 정상 심장과 비정상 심장(심장비대)을 분류할 수 있는 합성곱 신경망 모델을 제안하고자 한다. 학습 및 테스트 데이터로는 경북대학교병원에 내원하여 정상과 심장비대를 진단받은 환자들의 흉부 X-선 이미지를 획득하여 사용하였다. 제안된 합성곱 신경망 모델을 이용하였을 때의 정상 심장 및 비정상 심장(심장비대) 분류 정확도는 99.88%였다. 정상 심장 영상을 테스트 데이터로 사용하였을 때의 정확도, 정밀도, 재현율 및 F1 Score는 95%, 100%, 90%, 96%였다. 비정상 심장(심장비대) 영상을 테스트 데이터로 사용하였을 때의 정확도, 정밀도, 재현율 및 F1 Score는 95%, 92%, 100% 및 96%였다. 이러한 학습 및 테스트 분류 결과로 제안된 합성곱 신경망 모델은 흉부 X-선 영상의 특징 추출 및 분류에서 매우 우수한 성능을 보여주고 있다고 판단된다. 본 논문에서 제안하는 합성곱 신경망 모델은 흉부 X-선 영상의 질환 분류에 있어 유용한 결과를 보여줄 것으로 판단되며, 다른 의료 영상에서도 동일한 결과를 나타내는지 알아보기 위하여 추가적인 연구가 이루어져야 할 것이다.","The purpose of this study is to propose a convolutional neural network model that can classify normal and abnormal(cardiomegaly) in chest X-ray images. The training data and test data used in this paper were used by acquiring chest X-ray images of patients diagnosed with normal and abnormal(cardiomegaly). Using the proposed deep learning model, we classified normal and abnormal(cardiomegaly) images and verified the classification performance. When using the proposed model, the classification accuracy of normal and abnormal(cardiomegaly) was 99.88%. Validation of classification performance using normal images as test data showed 95%, 100%, 90%, and 96% in accuracy, precision, recall, and F1 score. Validation of classification performance using abnormal(cardiomegaly) images as test data showed 95%, 92%, 100%, and 96% in accuracy, precision, recall, and F1 score. Our classification results show that the proposed convolutional neural network model shows very good performance in feature extraction and classification of chest X-ray images. The convolutional neural network model proposed in this paper is expected to show useful results for disease classification of chest X-ray images, and further study of CNN models are needed focusing on the features of medical images."
Road Damage Detection and Classification based on Multi-level Feature Pyramids,2021,"['Multi-level Feature Pyramids', 'Road Damage Detection', 'VGG16', 'Multi-scale', 'Multi-level']",,"Road damage detection is important for road maintenance. With the development of deep learning, more and more road damage detection methods have been proposed, such as Fast R-CNN, Faster R-CNN, Mask R-CNN and RetinaNet. However, because shallow and deep layers cannot be extracted at the same time, the existing methods do not perform well in detecting objects with fewer samples. In addition, these methods cannot obtain a highly accurate detecting bounding box. This paper presents a Multi-level Feature Pyramids method based on M2det. Because the feature layer has multi-scale and multi-level architecture, the feature layer containing more information and obvious features can be extracted. Moreover, an attention mechanism is used to improve the accuracy of local boundary boxes in the dataset. Experimental results show that the proposed method is better than the current state-of-the-art methods."
아동 그림 심리분석을 위한 인공지능 기반 객체 탐지 알고리즘 응용,2021,"['인공지능', '딥러닝', '객체 탐지', '영상처리', '아동 그림분석', 'Artificial Intelligence', 'Deep Learning', 'Object detection', 'Image Processing', 'Child drawing analysis']",아동 그림은 내면의 감정을 표현할 수 있는 수단으로 아동 심리 진단에 널리 이용되고 있다. 본 논문에서는 아동 그림 분석에 적용할 수 있는 아동 그림 기반의 객체 탐지 알고리즘을 제안한다. 먼저 사진에서의 그림 영역을 추출하였고 데이터 라벨링 과정을 수행하였다. 이후 라벨링된 데이터 셋를 사용하여 Faster R-CNN 기반 객체 탐지모델을 학습하고 평가하였다. 탐지된 객체 결과를 기반으로 그림 면적 및 위치 또는 색상 정보를 계산하여 그림에 대한 기초정보를 쉽고 빠르게 분석할 수 있도록 설계하였다. 이를 통해 아동 그림을 이용한 심리분석에 있어 인공지능 기반 객체 탐지 알고리즘의 활용성을 보였다.,"Children""s drawings are widely used in the diagnosis of children""s psychology as a means of expressing inner feelings. This paper proposes a children""s drawings-based object detection algorithm applicable to children""s psychology analysis. First, the sketch area from the picture was extracted and the data labeling process was also performed. Then, we trained and evaluated a Faster R-CNN based object detection model using the labeled datasets. Based on the detection results, information about the drawing""s area, position, or color histogram is calculated to analyze primitive information about the drawings quickly and easily. The results of this paper show that Artificial Intelligence-based object detection algorithms were helpful in terms of psychological analysis using children""s drawings."
재난문자 분류를 위한 딥러닝 모델,2021,"['Disaster Alerts', 'Text Classification', 'Deep Learning', 'Word Embedding', 'BERT', '재난문자', '텍스트 분류', '딥러닝', '단어 임베딩']","재난문자는 재난 발생 시 국가에서 해당 지역에 있는 시민들에게 보내는 문자 메시지다. 재난문자의 발송 건수는 점점 증가하여, 불필요한 재난문자가 많이 수신됨에 따라 재난문자를 차단하는 사람들이 증가하고 있다. 이와 같은 문제를 해결하기 위하여, 본 연구에서는 재난문자를 재난 유형별로 자동으로 분류하고 수신자에 따라 필요한 재난의 재난문자만 수신하게 하는 딥러닝 모델을 제안한다. 제안 모델은 재난문자를 KoBERT를 통해 임베딩하고, LSTM을 통해 재난 유형별로 분류한다. [명사], [명사 + 형용사 + 동사], [모든 품사]의 3가지 품사 조합과 제안 모델, 키워드 분류, Word2Vec + 1D-CNN 및 KoBERT + FFNN의 4종류 분류 모델을 활용하여 재난문자를 분류한 결과, 제안 모델이 0.988954의 정확도로 가장 높은 성능을 달성하였다.","Disaster alerts are text messages sent by government to people in the area in the event of a disaster. Since the number of disaster alerts has increased, the number of people who block disaster alerts is increasing as many unnecessary disaster alerts are being received. To solve this problem, this study proposes a deep learning model that automatically classifies disaster alerts by disaster type, and allows only necessary disaster alerts to be received according to the recipient. The proposed model embeds disaster alerts via KoBERT and classifies them by disaster type with LSTM. As a result of classifying disaster alerts using 3 combinations of parts of speech: [Noun], [Noun + Adjective + Verb] and [All parts], and 4 classification models: Proposed model, Keyword classification, Word2Vec + 1D-CNN and KoBERT + FFNN, the proposed model achieved the highest performance with 0.988954 accuracy."
Machine learnings for CVD graphene analysis: From measurement to simulation of SEM images,2021,"['System modeling', 'CVD graphene growth', 'Machine learning', 'SEM prediction']",,"In this study, we introduce an approach that applies machine learning (ML) in various procedures topredict graphene growth pattern in chemical vapor deposition (CVD) system. Atfirst, CVD experimentswere conducted to synthesize graphene using CH4 as a precursor on a Cu substrate at high temperatures,to get experimental data for training those models. Then, the size, coverage, domain density, and aspectratio of graphene, which vary depending on the synthesis conditions, were measured and analyzedautomatically by developing a region proposal convolutional neural network (R-CNN). Subsequently, anartificial neural network (ANN) and a support vector machine (SVM) were used to develop surrogatemodels to deduce the correlation between CVD process variables and the measured specifications.Characteristic graphene grains with hexagonal morphology were created using a generative adversarialnetwork (GAN) to imitate the CVD growth. Then, they were modified to have the same size and aspectratio as the predicted values and placed to meet the predicted coverage and domain density. Finally, thepre-generated images were modified using Pix2pix to obtain the same outlook as the experimental SEMimages. As a result, it was possible to simulate graphene synthesis under various CVD condition. Throughnumerous simulations in advance, we were able to identify the experiment condition to synthesizegraphene with the desired morphologies of large grain size and low domain density. Developing aplatform to predict a CVD system for the controlled synthesis of graphene allow us to synthesize thegraphene with high efficiency, saving tremendous amounts of time and expenses."
Keypoint-based Deep Learning Approach for Building Footprint Extraction Using Aerial Images,2021,"['Building footprint extraction', 'Keypoint detection', 'Instance segmentation', 'Deep learning']",,"Building footprint extraction is an active topic in the domain of remote sensing, since buildings are a fundamental unit of urban areas. Deep convolutional neural networks successfully perform footprint extraction from optical satellite images. However, semantic segmentation produces coarse results in the output, such as blurred and rounded boundaries, which are caused by the use of convolutional layers with large receptive fields and pooling layers. The objective of this study is to generate visually enhanced building objects by directly extracting the vertices of individual buildings by combining instance segmentation and keypoint detection. The target keypoints in building extraction are defined as points of interest based on the local image gradient direction, that is, the vertices of a building polygon. The proposed framework follows a two-stage, top-down approach that is divided into object detection and keypoint estimation. Keypoints between instances are distinguished by merging the rough segmentation masks and the local features of regions of interest. A building polygon is created by grouping the predicted keypoints through a simple geometric method. Our model achieved an F1-score of 0.650 with an mIoU of 62.6 for building footprint extraction using the OpenCitesAI dataset. The results demonstrated that the proposed framework using keypoint estimation exhibited better segmentation performance when compared with Mask R-CNN in terms of both qualitative and quantitative results."
Question Similarity Measurement of Chinese Crop Diseases and Insect Pests Based on Mixed Information Extraction,2021,"['Text semantic similarity', 'Short text-similarity', 'Agricultural natural language processing', 'Chinese word segmentation']",,"The Question Similarity Measurement of Chinese Crop Diseases and Insect Pests (QSM-CCD&IP) aims to judge the user’s tendency to ask questions regarding input problems. The measurement is the basis of the Agricultural Knowledge Question and Answering (Q & A) system, information retrieval, and other tasks. However, the corpus and measurement methods available in this field have some deficiencies. In addition, error propagation may occur when the word boundary features and local context information are ignored when the general method embeds sentences. Hence, these factors make the task challenging. To solve the above problems and tackle the Question Similarity Measurement task in this work, a corpus on Chinese crop diseases and insect pests (CCDIP), which contains 13 categories, was established. Then, taking the CCDIP as the research object, this study proposes a Chinese agricultural text similarity matching model, namely, the AgrCQS. This model is based on mixed information extraction. Specifically, the hybrid embedding layer can enrich character information and improve the recognition ability of the model on the word boundary. The multi-scale local information can be extracted by multi-core convolutional neural network based on multi-weight (MM-CNN). The self-attention mechanism can enhance the fusion ability of the model on global information. In this research, the performance of the AgrCQS on the CCDIP is verified, and three benchmark datasets, namely, AFQMC, LCQMC, and BQ, are used. The accuracy rates are 93.92%, 74.42%, 86.35%, and 83.05%, respectively, which are higher than that of baseline systems without using any external knowledge. Additionally, the proposed method module can be extracted separately and applied to other models, thus providing reference for related research."
