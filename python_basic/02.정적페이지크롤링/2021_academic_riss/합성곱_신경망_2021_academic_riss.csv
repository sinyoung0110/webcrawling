title,date,keywords,abstract,multilingual_abstract
합성곱신경망을 이용한 타이타닉호의 재난 데이터 분석,2021,"['타이타닉 재난데이터', '합성곱신경망', 'LeNet-5', 'Keras', 'Titanic Disaster Data', 'Convolutional Neural Networks', 'LeNet-5', 'Keras']","본 연구에서는 합성곱신경망을 이용해서 타이타닉 재난데이터를 분석하였다. 그 동안 타이타닉 재난 데이터에 대한 k-최근접이웃 알고리즘, Naive Bayes 알고리즘, 의사결정트리 알고리즘 , SVM 알고리즘, 로지스틱 회귀 알고리즘 등 인공지능기법을 이용한 많은 분석이 이루어져왔다. 또한 인공신경망을 이용한 분석도 이루어져왔지만 합성곱신경망을 이용해서 이 타이타닉 재난데이터에 대한 분석은 없었다. 이 타이타닉 재난데이터 분석을 위하여 Keras를 이용하여 합성곱신경망중 LeNet-5를 사용해 모델링하여 훈련을 진행하였다. 이 성능결과를 Kaggle 웹사이트에 올려진 다중신경망을 이용한 분석결과와 비교하였다. LeNet-5를 이용한 경우 모델훈련에서 요구되는 훈련파라미터 개수의 비교에서 Kaggle 웹사이트에 올려진 다중신경망보다 월등히 적었다. 또한 훈련된 모델을 이용한 테스트 결과에서도 정확도는 0.856, 정밀도는 0.924를 나타냈다. 이 성능측정치는 Kaggle에 올려진 다중신경망의 정확도 0.842, 정밀도 0.873보다 우수한 것이다.","Titanic disaster data is analyzed using the convolutional neural networks in this paper. Although many researchers have analyzed this data using the aritificial intelligence techniques such as k-nearest neighbors algorithm, Naive Bayes algorithm, decision tree algorithm, SVM algorithm and logistic regression algorithm. Although the artificial neural networks are also used in another researches, the convolutional neural networks model has not been used in the analysis for this titanic disaster data. LeNet-5 among the various convolutional neural networks model is used with Keras for the train in this analysis. The performance result is compared with the result of analysis using the mutlilayer neural networks uploaded in Kaggle web site. In the comparison of the number of parameters to be trained, LeNet-5 shows efficient than multilayer neural networks. In the results of test after trained process, LeNet-5 shows 0.856 in accuracy and 0.923 in precision. These performance measures are better than those of multilayer neural networks whose accuracy was 0.841 and the precision was 0.872."
합성곱신경망을 이용한 KDD Cup 1999 데이터분석,2021,"['KDD Cup 1999 Data', 'Convolutional Neural Networks', 'LeNet-5', 'Keras', 'KDD Cup 1999 데이터', '합성곱신경망', 'LeNet-5', 'Keras']","KDD Cup 1999 데이터는 네트워크침입탐지 연구에 많이 이용된 데이터셋이다. 본 연구에서는 합성곱신경망을 이용해서 이 데이터를 분석하였다. 그 동안 이 데이터에 대한 TASVM, 의사결정트리 알고리즘, 랜덤포레스트알고리즘 등의 인공지능기법을 이용한 많은 분석이 이루어졌다. 그리고 다층신경망을 통한 분석도 이루어져왔지만 합성곱신경망을 이용한 접근은 거의 없었다. 합성곱신경망중 LeNet-5를 이용하여 Keras를 사용해서 분석을 하였다. 첫 번째 방법에서는 KDD Cup 1999의 10%훈련셋을 훈련셋과 테스트셋으로 나누어 분석하였다. 그리고 두 번째 방법에서는 10%훈련셋으로는 훈련하고 테스트는 테스트셋을 사용하여 분석하였다. 그리고 이 두 가지 방법의 결과를 캐글 웹사이트에 올려진 다층신경망과 비교하였다. KDD Cup 1999 데이터에는 침입유형을 크게 4가지로 분류하는데 각 유형별로 성능척도를 계산하였다. 그 결과 2가지 방법 모두에서 LeNet-5가 캐글에 올려진 다층신경망보다 우수한 성능을 나타냈다.","KDD Cup 1999 data has been used for the network intrusion detection studies. This data is analyzed using the convolutional neural networks in this paper. Many researchers have analyzed this data using the aritificial intelligence techniques such as TAVSM, decision tree algorithm and random forest algorithm etc. Although multilayer neural networks also have been used in these analysis, convolutional neural networks models have not been used. LeNet-5 among the various convolutional neural networks models is used with Keras for this analysis. At the first method, the 10% training set of the KDD Cup 1999 dividing into training set and testing set is used. At the second method, the 10% training set is used for train and testing set is used for test. The results are compared with the result of analysis using the mutlilayer neural networks uploaded in Kaggle web site. Because attacks are classified into 4 types in KDD Cup 1999 data, the performance measures are calculated by each attack types. LeNet-5 shows the better perfomance than the multilayer neural networks uploaded to Kaggle web site at both methods in all performance measures."
합성곱신경망을 이용한 초분광영상기반 토양수분 예측,2021,"['Soil moisture', 'Plant growth', 'Hyperspectral image', 'Spectral band', 'CNN', '토양수분', '식물생육', '초분광영상', '분광밴드', '합성곱신경망']","식물의 생육은 수분에 의해서 크게 좌우되기 때문에 토양이 재배하는 식물에 최적의 수분을 가지도록 조절하는 것은 중요하다. 최근 초분광영상을 통하여 식물의 생육정보를 자동으로 분석하는 연구가 진행되고 있으며 토양의 수분함량을 측정하는 것도 포함한다. 그러나 초분광의 경우 많은 분광밴드에서 나타나는 방대한데이터로 인하여 분석과정이 복잡하기 때문에 사용이 어렵다. 본 논문에서는 초분광영상의 복잡도를 합성곱신경망 (Convolution Neural Network, CNN)을 통하여 해결하는 방법을 제안한다. 제안한 방법은 대상 초분광의 전체 대역을 심층학습방법을 사용하여 자동 분석하기 때문에 각 영상에 대해 인식에 필요한 특정 대역을 찾는 노력을 할 필요가 없다. 제안 시스템의 유효성을 보이기 위해서 토양에서 얻은 초분광영상을 이용한수분함량분석 실험을 수행하고 결과를 보인다.",
합성곱신경망을 사용한 이미지 기반의 안드로이드 악성소프트웨어 패밀리 분류,2021,"['안드로이드 악성소프트웨어', '패밀리 분류', '회색조 이미지', '합성곱 신경망', '데이터 섹션', 'android malware', 'family classification', 'grayscale image', 'CNN', 'data section']","안드로이드 악성소프트웨어가 지속적으로 증가함에 따라, 기계학습을 사용한 안드로이드 악성소프트웨어 탐지 및 분류 기법이 많이 연구되고 있다. 악성소프트웨어 패밀리(malware family) 분류는, 악성소프트웨어 샘플들을 연관성 있는 그룹으로 분류하는 기법으로 컴퓨터 포렌식 분석, 위협 평가, 위협완화 계획에 중요한 역할을 한다. 본 논문에서는 실행파일 중의 일부를 회색조 이미지(grayscale image)로 변환한 후 변환된 영상들을 대상으로 딥러닝 기법을 적용하여 안드로이드 악성소프트웨어 패밀리를 분류하는 방법을 제안한다. 대표적인 안드로이드 악성소프트웨어 데이터 셋(dataset)인 Drebin에서 제공되는 악성소프트웨어 대표 패밀리들을 대상으로 합성곱신경망(Convolutional Neural Network, CNN) 모델을 적용하여 악성소프트웨어를 분류한다. 본 실험의 연구 결과를 기존 연구 결과와 비교하여, 데이터 경량화와 적절한 데이터 크기의 선정, 정확도에 있어 본 연구가 악성소프트웨어 분류에 더 효과적임을 보인다.","As Android malware continues to increase, Android malware detection and classification techniques using machine learning are being studied intensively. Malware family classification is a technique for classifying malware samples into related malware families and plays an important role in computer forensic analysis, threat assessment, and threat mitigation planning. In this paper, we propose a method to classify Android malware families by converting only part of an executable file into a gray scale image and applying deep learning to the converted images. The malware samples are classified from the representative families of the dataset from the Drebin project by applying the Convolutional Neural Network (CNN) model. The experimental results show that the proposed method is more effective in classifying malware families in terms of processing overhead and classification accuracy."
농작물 질병분류를 위한 전이학습에 사용되는 기초 합성곱신경망 모델간 성능 비교,2021,"['Crop Disease', 'Transfer Learning', 'Convolutional Neural Network', 'Performance Evaluation']",,"Recently, transfer learning techniques with a base convolutional neural network (CNN) model have widely gained acceptance in early detection and classification of crop diseases to increase agricultural productivity with reducing disease spread. The transfer learning techniques based classifiers generally achieve over 90% of classification accuracy for crop diseases using dataset of crop leaf images (e.g., PlantVillage dataset), but they have ability to classify only the pre-trained diseases. This paper provides with an evaluation scheme on selecting an effective base CNN model for crop disease transfer learning with regard to the accuracy of trained target crops as well as of untrained target crops. First, we present transfer learning models called CDC (crop disease classification) architecture including widely used base (pre-trained) CNN models. We evaluate each performance of seven base CNN models for four untrained crops. The results of performance evaluation show that the DenseNet201 is one of the best base CNN models."
립모션 센서 기반 증강현실 인지재활 훈련시스템을 위한 합성곱신경망 손동작 인식,2021,"['Euler angle spectrograph', 'Convolutional neural network (CNN)', 'Hand gesture recognition', 'Augmented reality (AR)', 'Cognitive rehabilitation system', 'Leap motion controller (LMC)']",,"In this paper, we evaluated prediction accuracy of Euler angle spectrograph classification method using a convolutional neural networks (CNN) for hand gesture recognition in augmented reality (AR) cognitive rehabilitation system based on Leap Motion Controller (LMC). Hand gesture recognition methods using a conventional support vector machine (SVM) show 91.3% accuracy in multiple motions. In this paper, five hand gestures (""Promise"", ""Bunny"", ""Close"", ""Victory"", and ""Thumb"") are selected and measured 100 times for testing the utility of spectral classification techniques. Validation results for the five hand gestures were able to be correctly predicted 100% of the time, indicating superior recognition accuracy than those of conventional SVM methods. The hand motion recognition using CNN meant to be applied more useful to AR cognitive rehabilitation training systems based on LMC than sign language recognition using SVM."
심방세동 진단을 위한 시계열성을 보전한 2차원 심전도 데이터 기반의 합성곱 신경망 모델,2021,"['2D 시계열', '심전도', '심방세동', '진단', '합성곱 신경망', '2D time series', 'electrocardiogram', 'atrial fibrillation', 'diagnosing', 'convolutional nueral network']","본 논문은 심장의 이상징후 중 심방세동 진단을 위하여 시계열성을 보전한 2D 심전도 데이터 기반의 합성곱 신경망 모델을 제안한다. 제안 모델은 시계열성을 보전한 2D 구조의 심전도 데이터를 사용하여 1D 합성곱 신경망 모델이나 기존의 2D 합성곱 신경망 모델에 비하여 심방세동 진단 성능을 높인다. 제안 방법의 유효성을 검증하기 위하여 Physionet 2017에 공개된 심전도 데이터를 활용하여 비교실험을 수행하였다. 1D 합성곱 신경망을 사용한 모델, 기존의 2D 합성곱 신경망 모델들과 제안 방법을 동일 환경에서 비교한 결과, 제안 방법이 다른 방법들에 비하여 더 적은 수의 학습 파라미터를 사용하면서도 더 높은 F1 점수와 정밀도(precision)를 보임을 확인하였다.","This paper proposes a convolutional neural network model based on 2D electrocardiogram data that preserves time series for diagnosing of atrial fibrillation among cardiac abnormalities. The proposed model uses ECG data of a 2D structure that preserves time series to improve atrial fibrillation diagnosing performance compared to the 1D convolutional neural network model and the existing 2D convolutional neural network model. To confirm the superiority of the proposed method, a comparative experiment was conducted using the ECG data published in Physionet 2017. A comparing of a 1D convolutional neural network model, two existing 2D convolutional neural network models and ours in the same experimental environments, the proposed method shows a higher F1 score and precision with fewer learning parameters."
흉부 X-선 영상에서 심장비대증 분류를 위한 합성곱 신경망 모델 제안,2021,"['합성곱 신경망', '딥러닝', '흉부 X-선', '분류', 'Convolutional Neural Network', 'Deep learning', 'Chest X-ray', 'Classification']","본 논문에서는 흉부 X선 영상에서 정상 심장과 비정상 심장(심장비대)을 분류할 수 있는 합성곱 신경망 모델을 제안하고자 한다. 학습 및 테스트 데이터로는 경북대학교병원에 내원하여 정상과 심장비대를 진단받은 환자들의 흉부 X-선 이미지를 획득하여 사용하였다. 제안된 합성곱 신경망 모델을 이용하였을 때의 정상 심장 및 비정상 심장(심장비대) 분류 정확도는 99.88%였다. 정상 심장 영상을 테스트 데이터로 사용하였을 때의 정확도, 정밀도, 재현율 및 F1 Score는 95%, 100%, 90%, 96%였다. 비정상 심장(심장비대) 영상을 테스트 데이터로 사용하였을 때의 정확도, 정밀도, 재현율 및 F1 Score는 95%, 92%, 100% 및 96%였다. 이러한 학습 및 테스트 분류 결과로 제안된 합성곱 신경망 모델은 흉부 X-선 영상의 특징 추출 및 분류에서 매우 우수한 성능을 보여주고 있다고 판단된다. 본 논문에서 제안하는 합성곱 신경망 모델은 흉부 X-선 영상의 질환 분류에 있어 유용한 결과를 보여줄 것으로 판단되며, 다른 의료 영상에서도 동일한 결과를 나타내는지 알아보기 위하여 추가적인 연구가 이루어져야 할 것이다.","The purpose of this study is to propose a convolutional neural network model that can classify normal and abnormal(cardiomegaly) in chest X-ray images. The training data and test data used in this paper were used by acquiring chest X-ray images of patients diagnosed with normal and abnormal(cardiomegaly). Using the proposed deep learning model, we classified normal and abnormal(cardiomegaly) images and verified the classification performance. When using the proposed model, the classification accuracy of normal and abnormal(cardiomegaly) was 99.88%. Validation of classification performance using normal images as test data showed 95%, 100%, 90%, and 96% in accuracy, precision, recall, and F1 score. Validation of classification performance using abnormal(cardiomegaly) images as test data showed 95%, 92%, 100%, and 96% in accuracy, precision, recall, and F1 score. Our classification results show that the proposed convolutional neural network model shows very good performance in feature extraction and classification of chest X-ray images. The convolutional neural network model proposed in this paper is expected to show useful results for disease classification of chest X-ray images, and further study of CNN models are needed focusing on the features of medical images."
Deep Metric Learning을 활용한 합성곱 신경망 기반의 피부질환 분류 기술,2021,"['합성곱 신경망', 'deep metric 손실', '클래스 불균형', '피부질환', 'convolutional neural network', 'deep metric loss', 'class imbalance', 'skin disease']","피부는 외부 오염으로부터 일차적으로 몸을 보호하는 역할을 한다. 피부병이 발생하게 되면 피부의 보호 기능이 저하되므로 신속한 진단과 처치가 필요하다. 최근 인공지능의 발달로 인해 여러 분야에 기술적용을 위한 연구가 이루어지고 있으며, 피부과에서도 인공지능을 활용해 오진율을 줄여 신속한 치료를 받을 수 있는 환경을 만들기 위한 연구가 진행되고 있다. 종래 연구들의 주된 흐름은 발생 빈도가 낮은 피부질환의 진단이었지만, 본 논문에서는 사람들에게 흔히 발생할 수 있고, 개인이 명확히 판별하기 힘든 티눈과 사마귀를 합성곱 신경망을 통해 분류하는 방법을 제안한다. 사용한 데이터셋은 3개의 클래스로 이루어져 있으며, 총 2,515장의 이미지를 가지고 있다, 학습 데이터 부족과 클래스 불균형 문제가 존재한다. 모델의 학습에는 deep metric 손실 함수와 교차 손실 함수를 이용해 각각 성능을 분석하였으며, 정밀도, 재현율, F1 점수, 정확도의 측면에서 비교한 결과 deep metric 손실 함수에서 더 우수한 성능을 보였다.","The skin is the body s first line of defense against external infection. When a skin disease strikes, the skin s protective role is compromised, necessitating quick diagnosis and treatment. Recently, as artificial intelligence has advanced, research for technical applications has been done in a variety of sectors, including dermatology, to reduce the rate of misdiagnosis and obtain quick treatment using artificial intelligence. Although previous studies have diagnosed skin diseases with low incidence, this paper proposes a method to classify common illnesses such as warts and corns using a convolutional neural network. The data set used consists of 3 classes and 2,515 images, but there is a problem of lack of training data and class imbalance. We analyzed the performance using a deep metric loss function and a cross-entropy loss function to train the model. When comparing that in terms of accuracy, recall, F1 score, and accuracy, the former performed better."
합성곱 신경망을 이용한 수중 선체면 영상의 청소 상태 검사,2021,"['Classification(분류)', 'Cleaning Condition(청소 상태)', 'Convolutional Neural Network(합성곱 신경망)', 'Hull Surface(선체면)', 'Inspection Image(검사 영상)', 'Underwater Hull(수중 선체)']","본 연구에서는 합성곱 신경망(CNN: convolutional neural network)을 이용해 수중에서 촬영한 선체면 영상에서 선체면의 청소 상태를 검사하기 위한 방법을 제안한다. 원격 조종 수중 로봇에서 수집한 동영상을 이용해 학습 데이터를 생성하였으며, 이 데이터들을 청소가 된 상태와 청소가 안된 상태의 영상으로 분류하였다. 청소 상태 검사를 위한 CNN 모델을 합성곱 레이어(convolution layer), 최대풀링 레이어(max-pooling layer), 드롭아웃 레이어(dropout layer)로 구성된 네 개의 합성곱 블록(convolution block)과 세개의 완전 연결 레이어(fully-connected layer)로 구성하였다. 그리고, 미니배치 경사하강법(mini-batch gradient descent)과 Adam 최적화를 이용해 CNN 모델을 학습하였다. 그 결과, 테스트 셋에 대해 97.95%의 정확도와 97.94%의 F1-점수를 보여주었다.","We propose a method for inspecting the cleaning condition of hull surfaces from underwater hull surface images using a convolutional neural network (CNN). A training data set was generated using videos collected from a remotely operated underwater robot, and the data set was classified into cleaned images and uncleaned images. The CNN model for inspecting the cleaning condition was composed of four convolutional blocks and three fully connected layers, where each convolutional block consisted of a convolution layer, a max-pooling layer, and a dropout layer. The CNN model was trained using the mini-batch gradient descent method and an Adam optimizer. As a result, on the testing set, the accuracy was 97.95%, and the F1-score was 97.94%."
합성곱 신경망 모델을 이용한 진동 응답의 모드 기여도 추정,2021,"['Deep Learning(딥러닝)', 'Mode Participation Factor(모드 기여도 계수)', 'Convolutional Neural Network(합성곱 신경망)', 'Natural Mode(고유 모드)', 'Mode Superposition Method(모드 중첩법)']","본 연구에서는 모드 중첩법으로 표현된 구조물의 강제 진동 응답에서 각 고유 모드의 기여도를 합성곱 신경망 모델을 이용하여 추정하는 방법론을 제시하고, 외팔보에 적용하여 제시한 방법론의 유효성을 입증한다. 과도 응답이 사라진 후에 조화 가진력에 의한 구조물의 강제 진동 거동은 해당 구조물이 갖는 고유 모드들의 선형 조합으로 표현할 수 있다. 각 고유 모드의 기여도는 가진력의 주파수, 가진 위치와 크기의 분포 등에 따라 달라지기 때문에 기여도가 큰 몇 개의 고유 모드만 사용하여 강제 진동거동을 근사적으로 표현할 수 있다. 이런 기여도를 추정할 수 있는 딥러닝 모델을 제안하고, 알맞은 입력과 출력 데이터를 사용하여 딥러닝 모델을 학습시킨다. 학습이 완료된 딥러닝 모델은 높은 정확도를 갖는 것을 알 수 있었고, 이런 결과가 응용될 수 있는 분야를 살펴본다.","In this study, a method based on a convolutional neural network was proposed to estimate the participation factor of each vibration mode in forced vibration response, expressed by the mode superposition method, and the effectiveness of the method was validated by applying it to a cantilever beam. After the transient response decays out, the forced vibration behaviour of a structure due to a harmonic excitation force can be expressed as a linear combination of its vibration modes. Since the participation factor of each vibration mode varies depending on the frequency of the excitation force, its location, and distribution, only a few vibration modes with large participation factors can be used to approximate the forced vibration behaviour. To estimate this participation factor, a convolutional neural network model was trained using appropriate input and output data. The proposed and trained deep learning model showed high accuracy against test data. Furthermore, its areas of application were discussed."
3축 가속도 센서 스트림에 대한 유한차분 및 합성곱 신경망 기반의 뇌전증 발작 감지 기법,2021,"['딥러닝', '합성곱 신경망', '다변량 분석', '유한차분법', 'IoT', '스트림 데이터', 'Deep Learning', 'CNN', 'Multivariate Analysis', 'Finite Difference Method', 'IoT', 'Stream Data']","뇌전증은 발작을 동반하는 만성 뇌질환이다. 뇌전증 발작 감지에는 일반적으로 뇌파를 활용한다. 뇌전증 발작은 불규칙한 시점에 발생하며, 지속적일 경우 뇌손상 또는 사망에 이를 수 있는 응급 상황이다. 따라서 신속한 대처를 위한 일상생활 중 뇌전증 발작의 실시간 감지가 중요하다. 그러나 센서 민감도와 같은 기술적 한계로 인하여, 현재까지는 전문 장비를 갖춘 병원에서조차 정확한 뇌파의 측정이 어렵다. 또한, 실시간으로 뇌파를 측정할 수 있는 웨어러블 기기로의 상용화는 더욱 어려운 상황이다. 따라서 3축 가속도 센서 스트림 기반 동작 인식은 일상생활 중 실시간 뇌전증 발작 감지를 위한 현실적인 대안이다. 본 논문에서는 스마트폰, 스마트워치 등에 내장된 3축 가속도 센서 데이터에 대한 유한차분 및 합성곱 신경망 기반의 뇌전증 발작 감지 기법을 제안한다. 제안하는 기법은 뇌전증 발작의 의학적 특성에 근거하여, 유한차분을 통해 각 축 값의 변화율을 구하고, 합성곱 신경망 기반의 다변량 분석을 수행하여 각 축 값 변화율 간의 관계를 통합적으로 고려한다. 제안하는 기법은 걷기, 뛰기와 같은 대표 동작 외에도 양치질, 톱질 등 뇌전증 발작과 유사한 짧은 주기의 반복 동작을 포함한 17가지 일상 상황들로부터 99% 이상의 확률로 뇌전증 발작을 감지할 수 있음을 실험을 통해 확인하였다.","Epilepsy is a chronic brain disease causing repetitive seizures. Epileptic seizures occur irregularly and are emergency situations that can lead to brain damage or even death if happen continuously. Therefore, real-time detection of epileptic seizures is important for rapid treatment. However, due to some technical limitations like sensitivity of sensors, it is difficult to accurately measure EEG even in hospitals. Also, it is even more difficult to commercialize wearable devices. Therefore, human activity recognition on 3-axis accelerometer streams is a realistic alternative for real-time detection of epileptic seizures. In this paper, we propose a epileptic seizure detection method based on finite difference and CNN for 3-axis accelerometer streams measured from smart devices. The proposed method considers the medical characteristics of epileptic seizures to calculate the finite difference of each axis, and carries out multivariate analysis based on CNN to integratively consider the relationship between rate of changes of each. Our experiments show that our method can detect the epileptic seizures with a probability of more than 99% from 17 types of daily activities including repetitive activities in short cycles being thought to be similar to epileptic seizures such as brushing teeth and sawing besides typical movements like walking or running."
Word2Vec과 2채널 합성곱 신경망을 활용한 영화추천시스템의 정확도 개선,2021,"['Word2vec', 'Collaborative filtering', 'Recommender systems', 'Convolutional neural networks', 'Deep learning', 'Accuracy improvement']","상품 추천 시스템의 예측 정확도를 개선하는 것은 추천 시스템 분야의 주요 주제 중 하나이다. 최근 텍스트 분석에서 많이 활용되고 있는 Word2Vec을 이용한 예측 정확성 개선 연구가 제시되고 있다. 또한, 다양한 신경망을 이용한 예측 정확성 개선 연구가 제시되고 있다. 이 연구는 Word2Vec과 2채널 합성곱 신경망을 결합한 영화 추천 시스템의 예측 정확도를 향상할 수 있는 방안을 제안한다. Word2Vec을 이용하여 사용자 간 연관성을 다차원 벡터 공간으로 표현한다. 또한, 영화 간 연관성을 다차원 벡터 공간으로 표현한다. 추가로 사용자 평점 성향을 유추하기 위해 사용자별 평균 평점 정보를 사용하여 제2의 사용자별 다차원 벡터를 찾아낸다. 비슷하게 제2의 영화별 다차원 벡터를 찾아낸다. 사용자 벡터와 영화 벡터를 2채널로 구성하고 이를 2채널 합성곱 신경망을 통해 학습한다. 합성곱 신경망은 사용자 합성곱 모델과 영화 합성곱 모델로 각각 구성되고 완전연결 계층에서 연결된다. 제안한 모델의 예측 정확성 성능 평가를 위해 filmtrust 데이터를 가지고 실험하였다. 실험 결과 제안한 기법이 기존 선행연구에서 제안한 기법에 비해 예측 정확도를 개선함을 알 수 있었다.",
영흥 풍력발전단지의 풍력발전량 예측을 위한 입력변수 선정 및 인공신경망과 1차원 합성곱 신경망 비교,2021,"['Artificial Neural Networks', 'Artificial Intelligence', 'Convolutional Neural Networks', 'Machine Learning', 'Wind Power', '인공신경망', '인공지능', '기계학습', '합성곱신경망', '풍력에너지']","목적 : 본 연구에선 비선형적 풍력발전량 예측 모델 개발을 목적으로 총 설치 용량 46 MW의 풍력발전단지가 설치된 영흥 풍력발전 단지의 자료를 이용하여 인공신경망(artificial neural network, ANN)과 1차원 합성곱신경망(1-dimension convolutional neural network, 1D-CNN)의 성능을 비교하고자 하였다.방법 : 자료는 46 MW 발전능력을 가진 영흥 풍력발전단지의 2018년 1월부터 12월의 1시간 단위 풍력발전량 자료와 기상청에서 얻은 기상자료를 이용하였다. 최적 입력변수를 선정을 위하여 문헌연구를 바탕으로 시행착오를 거쳐 인자를 선정하였다. 전처리 과정을 거친 17,306개의 자료의 80%를 학습(training), 20%를 테스트(test)으로 사용하였으며, 학습 자료의 20%를 검증(validation)자료로 구성하였다. 모델 내 활성화 함수로는 rectified linear unit를 사용하였으며, 시행착오법을 통해 하이퍼파라미터(hyperparameter)의 최적값을 도출하였다. 모든 모델은 Python의 Keras 라이브러리를 이용하여 설계하였으며, 성능지표인 결정계수(coefficient of determination, R²), 평균제곱근오차(root mean square error, RMSE), 평균절대오차(mean absolute error, MAE) 등은 Scikit-learn 라이브러리에서 이용하였다.결과 및 토의 : 최적 입력변수는 풍속, 풍향, 온도, 습도 등이었다. ANN의 최적점으로는 은닉층 8층, 은닉층별 노드수는 모두 100으로 나왔다. 최적 ANN 모델에서 성능지표는 R²=0.848, MAE=1.054, RMSE=1.616이었다. 1D-CNN 의 최적점으로는 합성곱층 4층, 층별 필터 수는 1층부터 64, 128, 64, 32개, 전결합층 1층에 노드 100개이다. 최적 1D-CNN 모델의 성능지표는 R²=0.875, MAE=0.982, RMSE=1.583였다. 1D-CNN이 ANN보다 R²는 높고, MAE와 RMSE는 낮았다. ANN, 1D-CNN의 결정계수가 모두 0.8 이상으로 예측 성능이 우수하나, 1D-CNN이 ANN보다 모든 성능지표에서 높았다.결론 : 최적화된 모델의 성능지표 비교 결과 1D-CNN이 ANN보다 높은 성능을 보여 영흥 풍력 발전소 발전량 예측에 적합할 것으로 보인다. 최적 입력변수는 풍속, 풍향, 온도, 습도였다.","Objectives : In this study, deep learning models of artificial neural network (ANN) and one-dimension convolutional neural networks (1D-CNN) were compared to predict nonlinear wind power generation at Yeongheung wind power plant.Methods : The study site was Yeongheung-do, which has a 46 MW wind power plant. Hourly wind power and meteorological data from January to December 2018 were collected. After pre-processing with standardscaler, the training data were 64%, the validation data were 16%, and the test data were 20%. The optimum input variables of the model were selected using literature, and trial and error method. Rectified linear unit was used as the activation function. Hyperparameters were adjusted by trial and error method to optimized models. To compare the optimized models, the coefficient of determination (R²), mean absolute error (MAE), and root mean square error (RMSE) were used as the performance efficiency. Both ANN, and 1D-CNN were imported from the Keras library, and all of the performance efficiency was imported from the Scikit-learn library.Results and Discussion : The optimized input variables in this study were wind speed, wind direction, temperature, and humidity. The optimized ANN performance was R²=0.848, MAE=1.054, and RMSE=1.616, and the hyperparameters were 8 hidden layers with 100 nodes in each layer. The optimized 1D-CNN (R²=0.875, MAE=0.982, and RMSE=1.583) had 4 convolutional layers and the number of filters were 64, 128, 64, and 32 in order from the first layer, and one hidden fully connected layer had 100 nodes. The 1D-CNN had higher R², and lower MAE and RMSE than the ANN. Therefore, the 1D-CNN was selected as the optimized model to predict wind generation of the Yeongheung wind power plant.Conclusions : The optimized 1D-CNN model in this study was more effective in predicting the Yeongheung wind power plant than the ANN. The optimal input variables were wind speed, wind direction, temperature, and humidity."
저해상도 영상 자료를 사용하는 얼굴 표정 인식을 위한 소규모 심층 합성곱 신경망 모델 설계,2021,"['Convolutional Neural Networks', 'Facial Expression Recognition', 'Design of CNN architecture', 'Low Resolution Image', '합성곱 신경망', '얼굴 표정 인식', '합성곱 신경망 구조 설계', '저해상도 영상']",인공 지능은 놀라운 혜택을 제공하는 우리 삶의 중요한 부분이 되고 있다. 이와 관련하여 얼굴 표정 인식은 최근 수십 년 동안 컴퓨터 비전 연구자들 사이에서 뜨거운 주제 중 하나였다. 저해상도 이미지의 작은 데이터 세트를 분류하려면 새로운 소규모 심층 합성곱 신경망 모델을 개발해야 한다. 이를 위해 소규모 데이터 세트에 적합한 방법을 제안한다. 이 모델은 기존 심층 합성곱 신경망 모델에 비해 총 학습 가능 가중치 측면에서 메모리의 일부만 사용하지만 FER2013 및 FERPlus 데이터 세트에서 매우 유사한 결과를 보여준다.,"Artificial intelligence is becoming an important part of our lives providing incredible benefits. In this respect, facial expression recognition has been one of the hot topics among computer vision researchers in recent decades. Classifying small dataset of low resolution images requires the development of a new small scale deep CNN model. To do this, we propose a method suitable for small datasets. Compared to the traditional deep CNN models, this model uses only a fraction of the memory in terms of total learnable weights, but it shows very similar results for the FER2013 and FERPlus datasets."
합성곱 신경망을 이용한 야생 매개모기 종의 분류,2021,"['매개 모기', '곤충 분류', '합성곱 신경망', '딥러닝', 'vector mosquitoes', 'insects classification', 'convolutional neural networks', 'deep learning']","최근 감염병을 매개하는 모기의 발생 분포가 확대됨에 따라 이들 개체의 신속한 방제를 위해 이들 개체의 분포를 빠르게 파악하는 것이 요구되고 있다. 그러나 기존 시스템에 적용된 모기 식별 알고리즘은 야생 모기의 종별 분류가 불가능하다는 한계가 있다. 이러한 문제를 해결하기 위해, 이 연구에서는 야생에서 나타나는 모기의 종 분류가 가능한 합성곱 신경망 모델을 학습하고 평가한다. 학습에 필요한 데이터를 취득하기 위해 살아있는 모기의 이미지를 야생에서 효율적으로 취득할 수 있는 포집기 형태의 촬영장치를 제작하였고 이를 사용하여 주요 감염병 매개 모기인 흰줄숲모기, 빨간집모기, 얼룩날개모기속을 포함한 1만 장 이상의 이미지를 취득하여 데이터 세트를 구성하였다. 그 결과, 학습한 모델에서 검증 데이터 세트에 대하여 최대 96.87%, 야생 데이터 세트에 대하여 최대 67.89%의 분류 정확도를 확인하여 지향하는 포집기 시스템에서의 적용 가능성과 개선 방향을 확인하였다.","The distribution of infectious mosquitoes has been constantly expanding, thus identifying the species is required for rapid pest control. However, the current mosquito identification algorithm could not apply to wild mosquito species classification. To solve this problem, we propose a convolutional neural network model for classifying vector mosquito species in the wild. To acquire data for training and evaluation, we developed a trap-shaped imaging device to efficiently acquire live mosquito images in the wild and built datasets including more than 10,000 images of Aedes albopictus, Culex pipiens, and Anopheles Spp. As a result, our model achieved up to 96.87% of validation accuracy and 67.89% of wild mosquito classification accuracy, which shows great prospects for the future trap system and a way for further improvement."
합성곱 신경망을 이용한 프로펠러 캐비테이션 침식 위험도 연구,2021,"['Convolutional Neural Network(CNN', '합성곱 신경망)', 'Deep learning(딥러닝)', 'Propeller(프로펠러)', 'Cavitation(캐비테이션)', 'Erosion(침식)']",,"Cavitation erosion is one of the major factors causing damage by lowering the structural strength of the marine propeller and the risk of it has been qualitatively evaluated by each institution with their own criteria based on the experiences. In this study, in order to quantitatively evaluate the risk of cavitation erosion on the propeller, we implement a deep learning algorithm based on a convolutional neural network. We train and verify it using the model tests results, including cavitation characteristics of various ship types. Here, we adopt the validated well-known networks such as VGG, GoogLeNet, and ResNet, and the results are compared with the expert’s qualitative prediction results to confirm the feasibility of the prediction algorithm using a convolutional neural network."
다층퍼셉트론과 합성곱 신경망에 기반한 지진 지반응답해석,2021,"['지진 지반응답해석', '다층퍼셉트론(MLP)', '합성곱 신경망(CNN)', 'Seismic Ground Response', 'Multilayer Perceptron (MLP)', 'Convolution Neural Networks (CNN)']","지진으로 인한 구조물의 피해를 줄이기 위한, 내진성능을 고려한 방재계획 수립의 중요성이 부각되고 있다. 지진파는 기반암으로 부터 기반암 상부의 토사지반을 통해 전달된다. 전달되는 과정에서 특정 진동수(frequency)범위에서 증폭되기도 하며, 그 증폭 정도는 주로 지반 특성에 따라 좌우된다. 따라서 내진 설계의 신뢰성을 높이기 위해서는 지진 지반응답해석 과정이 필수적이다. 본 연구에서는 지반 하부 혹은 기반암의 지진파로부터 지표의 지진파를 예측하기 위한 모델을 다층퍼셉트론(MLP)과 합성곱 신경망(CNN) 인공신경망 모형을 바탕으로 제안하고, 제안한 모델의 적용성을 가속도 스펙트럼을 바탕으로 검증하였다. MLP와 CNN에 기반 하여 제안된 모델 모두 지표면의 지진파 가속도를 성공적으로 예측하였다. 또한, CNN에 기반한 모델은 MLP 모델과 비교하여 예측 지진파의 가속도 스펙트럼 평균오차가 약 10% 작게 산출되는 것을 확인하였다. 향후에는 해당 지역의 전단파 속도 등의 물성을 모델에 적용하여, 보다 보편적으로 활용할 수 있는 모델을 생성하고자 한다.","The importance of establishing a disaster prevention plan considering seismic performance is being highlighted to reduce damage to structures caused by earthquakes. Earthquake waves propagate from the bedrock to the ground surface through the soil. During the transmission process, they are amplified in a specific frequency range, and the degree of amplification depends mainly on the characteristics of the ground. Therefore, a seismic response analysis process is essential for enhancing the reliability of the seismic design. We propose a model for predicting seismic waves on the surface from seismic waves measured on the bedrock based on Multilayer Perceptron (MLP) and Convolutional Neural Networks (CNN) and validate the applicability of the proposed model with Spectral Acceleration (SA). Both the proposed models based on MLP and CNN successfully predicted the seismic response of the surface. The CNN-based model performed better than the MLP-based model, with a 10% smaller average error. We plan to implement the physical properties of the ground, such as shear wave velocity, to create a more versatile model in the future."
심층 합성곱 신경망을 사용한 인스타그램 위조품 판매 게시물 탐지,2021,"['위조품 탐지', '딥러닝', '심층 합성곱 신경망', '특징 추출', '인스타그램', 'Counterfeit detection', 'Deep learning', 'DCNN', 'Feature extraction', 'Instagram']",,"This study proposed a detection algorithm using a deep learning method to help detect counterfeit sales posts that hinder the SNS environment and further curb the widespread production of counterfeit. We analyzed 382,790 data collected from Instagram using a deep convolutional neural network (DCNN) and identified the characteristics of counterfeit sales posts. As a result of comparing detection performance using five pre-trained DCNN models, the best performance model was able to detect counterfeit sales posts with 92% performance only with images. In addition, the lightweight model also performed 90% which demonstrates the practical availability of counterfeit sales post detection algorithms in the mobile environment."
다항 곡선과 합성곱 신경망을 이용한 요추 전위 정량화 방법,2021,"['Vertebral displacement', 'Lumbar vertebrae diagnosis', 'Convolutional neural networks', 'Polynomial curve', '추체 전위', '요추 진단', '합성곱 신경망', '다항 곡선']","요추 통증의 주요 원인이 되는 전위는 X-ray 영상 분석을 통하여 진단될 수 있는데, 주로 사람의 수작업에 의해서 전위 정도가 정량화되어 왔다. 따라서 수작업에 의한 정량화 과정을 개선하기 위해서 본 연구에서는 요추의 전위 정도를 정량화할 수 있는 자동화 알고리즘을 제안한다. 추체의 꼭지점 자동 추출을 위해서는 합성곱 신경망 기반의 두 단계 네트워크를 활용하였고, 꼭지점 위치의 평균을 이용하여 추체 중심선 특징점을 계산하였다. 중심선 특징점에 3차 다항 곡선 적합을 수행하여 중심선 식을 얻었다. 각 추체 중심점에서 다항 곡선까지의 최소 거리값을 계산함으로써 전위 정량화를 수행하였다. 요추 X-ray 영상 1000장에 제안하는 방법을 적용하여 자동 전위 정량화가 성공적으로 수행됨을 확인하였다. 특징점에 대한 참값을 이용한 정량화와 비교하여, 정량화 오차는 약 2.47 픽셀로 나타났다. 본 연구에서 실험결과는 요추에 한정되어 있지만, 제안하는 방법을 전신 척추에도 적용이 가능할 것이다.","Lumbar vertebral displacement, which is the main cause of lumbar pain, can be diagnosed by X-ray image analysis, and the degree of displacement has been quantified mainly by human labeling. Therefore, in order to improve the manual quantification process, this study proposes an automated algorithm that can quantify the degree of lumbar vertebral displacement. For automatic extraction of vertebral corner points, a two-stage network based on convolutional neural networks was used, and vertebral midline feature points were calculated using the average positions of corner points. The vertebral midline equation was obtained by performing cubic polynomial curve fitting on the midline feature points. Vertebral displacement quantification was performed by calculating the minimum distance from each vertebral centroid to the polynomial curve. The automatic quantification was successfully performed by applying the proposed method to 1000 lumbar X-ray images. Compared with the quantification using the ground truth of the feature point, the quantification error was about 2.47 pixels. Although the experimental results in this study are limited to the lumbar spine, the proposed method can be applicable to the whole spine."
전이학습과 그래프 합성곱 신경망 기반의 다중 패션 스타일 인식,2021,"['다중 레이블 인식', '레이블 종속성', '전이학습', '그래프 합성곱 신경망', 'Multi-Label Recognition', 'Label Dependency', 'Transfer Learning', 'Graph Convolution Network']","최근 패션업계에서는 급속도로 발전하는 딥러닝 방법론을 활용하려는 시도가 늘고 있다. 이에 따라 다양한 패션 관련 문제들을 다루는 연구들이 제안되었고, 우수한 성능을 달성하였다. 하지만 패션 스타일 분류 문제의 경우, 기존 연구들은 한 옷차림이 여러 스타일을 동시에 포함할 수 있다는 패션 스타일의 특성을 반영하지 못하였다. 따라서 본 연구에서는 동시에 존재하는 레이블 간의 종속성을 모델링하고, 이를 반영하여 패션 스타일의 다중 분류 문제를 해결하고자 한다. 패션 스타일 사이의 종속성을 포착하고 탐색하기 위해 GCN(graph convolution network) 기반의 다중 레이블 인식 모델을 적용하였다. 또한 전이학습을 통해 모델의 학습 속도 및 성능을 향상시켰다. 제안하는 모델은 웹 크롤링을 통해 수집한 SNS 이미지 데이터를 이용하여 검증하였으며, 비교 모델 대비 우수한 성능을 기록하였다.","Recently, there are increasing attempts to utilize deep learning methodology in the fashion industry. Accordingly, research dealing with various fashion-related problems have been proposed, and superior performances have been achieved. However, the studies for fashion style classification have not reflected the characteristics of the fashion style that one outfit can include multiple styles simultaneously. Therefore, we aim to solve the multi-label classification problem by utilizing the dependencies between the styles. A multi-label recognition model based on a graph convolution network is applied to detect and explore fashion styles dependencies. Furthermore, we accelerate model training and improve the models performance through transfer learning. The proposed model was verified by a dataset collected from social network services and outperformed baselines."
합성곱 신경망의 추론 정확도 향상을 위한 하드웨어 구조 연구,2021,"['AI accelerator', 'CNN', 'batch normalization', 'verilog-HDL', 'ASIC']",,"In this paper, we propose a hardware architecture with built-in batch normalization to improve inference accuracy of convolutional neural networks. Batch normalization improves inference accuracy by normalizing the data distribution by the convolutional neural network layer. However, operations such as average and variance are required, and if there is a restriction on hardware resource usage, the operation accuracy decreases. Therefore, this paper proposes a hardware architecture in which batch normalization operations can be omitted by applying an 8-bit quantization technique when inferencing to improve computational accuracy and utilize internal control signals. The proposed hardware architecture was modeled using Verilog-HDL. Then the intermediate and final output values of the hardware operation were compared and evaluated with the output results of the software-based verification model and synthesized using the Samsung 28-nm process."
합성곱 신경망을 이용한 고선명 영상 획득,2021,"['multi-focus image fusion', 'activity level measurement', 'fusion rule', 'convolutional neural network']",,"Robust pupil detection is essential for binocular gaze estimation in the augmented reality. Since it is important to acquire a clear pupil image for accurate pupil detection, multi-focus image fusion has received a lot of attention. Multi-focus image fusion is a technique for extracting a focused region from the blurred images to obtain a image with high sharpness. In multi-focus image fusion, activity level measurement and fusion rule are important factors. Since the existing multi-focus image fusion not only considers activity level measurement and fusion rule separatively, but also becomes more and more complicated, a convolutional neural network as one of the deep learning techniques is proposed in this paper to obtain a multi-focus image fusion results with excellent performance through directly mapping between the blurred images and the focus map. Experimental results demonstrate the effectiveness of the proposed method."
합성곱 신경망의 Channel Attention 모듈 및 제한적인 각도 다양성 조건에서의 SAR 표적영상 식별로의 적용,2021,[],,"In the field of automatic target recognition(ATR) with synthetic aperture radar(SAR) imagery, it is usually impractical to obtain SAR target images covering a full range of aspect views. When the database consists of SAR target images with limited angular diversity, it can lead to performance degradation of the SAR-ATR system. To address this problem, this paper proposes a deep learning-based method where channel attention modules(CAMs) are inserted to a convolutional neural network(CNN). Motivated by the idea of the squeeze-and-excitation(SE) network, the CAM is considered to help improve recognition performance by selectively emphasizing discriminative features and suppressing ones with less information. After testing various CAM types included in the ResNet18-type base network, the SE CAM and its modified forms are applied to SAR target recognition using MSTAR dataset with different reduction ratios in order to validate recognition performance improvement under the limited angular diversity condition."
합성곱 신경망을 이용한 컨포멀 코팅 PCB에 발생한 문제성 기포 검출 알고리즘,2021,"['Problematic Bubble', 'Bubble Detection', 'Conformal Coating', 'CNN', 'ResNet']",,"Conformal coating is a technology that protects PCB(Printed Circuit Board) and minimizes PCB failures. Since the defects in the coating are linked to failure of the PCB, the coating surface is examined for air bubbles to satisfy the successful conditions of the conformal coating. In this paper, we propose an algorithm for detecting problematic bubbles in high-risk groups by applying image signal processing. The algorithm consists of finding candidates for problematic bubbles and verifying candidates. Bubbles do not appear in visible light images, but can be visually distinguished from UV(Ultra Violet) light sources. In particular the center of the problematic bubble is dark in brightness and the border is high in brightness. In the paper, these brightness characteristics are called valley and mountain features, and the areas where both characteristics appear at the same time are candidates for problematic bubbles. However, it is necessary to verify candidates because there may be candidates who are not bubbles. In the candidate verification phase, we used convolutional neural network models, and ResNet performed best compared to other models. The algorithms presented in this paper showed the performance of precision 0.805, recall 0.763, and f1-score 0.767, and these results show sufficient potential for bubble test automation."
합성곱 신경망기반 딥러닝의 용접연구 적용 Part I: 모델과 활용사례,2021,[],,
합성곱 신경망을 이용한 Local Maximum Scalogram 기반 부정맥 분류에 관한 연구,2021,"['Arrhythmia', 'LMS', 'learning model', 'SVM', 'CNN', 'standard deviation']",,"The purpose of this study is to investigate whether it can be used for arrhythmia detection as a wavelet transform and another feature extraction method using the probability distribution of LMS(Local Maximum Scalogram). The SVM(Support Vector Machine) model uses two kernels: Polynomial and Radial Basis Function(RBF). Three types of data are used: standard deviation of the row (n), standard deviation of the column(n/2), and standard deviation of the row and column (3n/2) of the basic LMS matrix according to the sample (n = 90,180, 270, 360, 450), The training data of the CNN model uses two LMS matrices when fixed to and. The trained model is divided 5 times, and K-fold cross-validation is performed and evaluated using ROC, AUC, and confusion matrix. Finally, the filtered ECG data is compared with the confusion matrix result graph to consider the types of arrhythmia that are difficult to classify. CNN is evaluated to show good overall performance when is. The results of the SVM model show the possibility that the standard deviation values of the LMS’s rows and columns can be used as a feature of arrhythmic bit detection. Since it is simple but very efficient, it is expected to be used in various ways as a single feature extraction method."
합성곱 신경망을 사용한 하천 수질예측 정확도 평가,2021,"['Convolutional neural network', 'Prediction accuracy', 'River water quality', 'Deep learning architecture', 'Univariate data', 'Multivariate data']",,"The present study assessed the applicability of convolutional neural network (CNN), which showed superior performance for classification, segmentation, and natural language processing, to river water quality prediction. Monthly data was compiled from upstream and downstream water quality monitoring stations in the Hwang River over the period of January 2007 through December 2020, from which training and test sets were constructed in the ratio of 70:30. The performance of CNN consisting of single and multiple layers were evaluated separately using univariate data with single dependent variable (i.e., either chemical oxygen demand (COD) or chlorophyll-a (Chl-a) as well as multivariate data with dependent and 9 independent variables. The results showed that the prediction accuracy of the proposed CNN algorithm tested with univariate data was noticeably higher for COD than for Chl-a (in terms of target variable) as well as for multiple layers than for single layer (with respect to model architecture). In addition, the CNN algorithm evaluated with multivariate data achieved had better prediction performance than that of univariate data although its performance varied widely among data sets, and to a less extent, among stations and target variables. No measurable difference was also found in prediction performance of the CNN algorithm (for two target dependent variables) according to the number of (important) independent variables. All these results demonstrate that while the proposed CNN algorithm can be adopted to predict (monthly) water quality variables, its careful architecture design is yet required to achieve substantial performance improvement."
합성곱 신경망 기반 물체 인식과 탑승 감지 센서를 이용한 개인형 이동수단 주행 안전 보조 시스템 개발,2021,[],,A recent spread of personal mobility devices such as electric kickboards has brought about a rapid increase in accident cases. Such vehicles are susceptible to falling accidents due to their low dynamic stability and lack of outer protection chassis. This paper presents the development of an automatic emergency braking system and a safe starting system as driving assistance devices for electric kickboards. The braking system employed artificial intelligence to detect nearby threaening objects. The starting system was developed to disable powder to the motor until when the driver's boarding is confirmed. This study is meaningful in that it proposes the convergence technology of advanced driver assistance systems specialized for personal mobility devices.
합성곱 신경망 인식률 개선을 위한 이미지 전처리에 대한 연구,2021,"['convolutional neural network', 'feature map', 'input shape', 'pre-processing', 'background padding']",,"A convolutional neural network(CNN) produces an optimal feature map for that image by optimizing the weights of the kernel through the learning process. Therefore, it can be expected that the optimal learning rate will be achieved when utilizing datasets optimized for input shape of neural network models. However, using public datasets or collecting images directly by researchers may not be suitable for the input shape. In this paper, several steps of image pre-processing methods were tested to increase the recognition rate of convolutional neural networks. As a result of comparing the recognition rate before and after pre-processing for the datasets, the result after pre-processing improved the accuracy by 5.73%. Through this, it was found that the pre-processing method for the learning image had an important effect on improving recognition rates."
합성곱 신경망기반 딥러닝의 용접연구 적용 Part II: 모델의 평가와 시각화,2021,[],,
3차원 합성곱 신경망 기반 향상된 스테레오 매칭 알고리즘,2021,"['Stereo matching', '3D Convolutional Neural Network', 'Parallax dimension', 'Computation cost', 'Network structure']",,"For stereo matching based on deep learning, the design of network structure is crucial to the calculation of matching cost, and the time-consuming problem of convolutional neural network in image processing also needs to be solved urgently. In this paper, a method of stereo matching using sparse loss volume in parallax dimension is proposed. A sparse 3D loss volume is constructed by using a wide step length translation of the right view feature map, which reduces the video memory and computing resources required by the 3D convolution module by several times. In order to improve the accuracy of the algorithm, the nonlinear up-sampling of the matching loss in the parallax dimension is carried out by using the method of multi-category output, and the training model is combined with two kinds of loss functions. Compared with the benchmark algorithm, the proposed algorithm not only improves the accuracy but also shortens the running time by about 30%."
깊은 합성곱 신경망 모델에 따른 유방 초음파 영상 분류 성능 비교,2021,"['Breast Ultrasound', 'Breast Cancer', 'Tumor', 'Classification', 'VGG', 'ResNet', 'InceptionNet', 'DenseNet', 'EfficientNet', 'Convolutional Neural Network']",,"Breast ultrasound has been widely utilized for classifying tumors into benignancy and malignancy. The limitations of traditional breast ultrasound are the handcrafted features obtained by well-trained sonographers and subjective decision according to different individual experiences. Recently, CNN-based deep learning techniques have exhibited better performance in medical images. However, most research for deep learning in medical ultrasound adopts CNN models developed for natural images due to the lack of common standard and dataset. In this paper, we compare six DCNN models which exhibit good performance for natural images - VGGNet, ResNet, InceptionNet, DenseNet, and EfficientNet. Our classification results demonstrate that CNN models of relatively lower performance on natural images show better performance on gray-scale ultrasound images and further study of CNN models are needed focusing on the features of medical images."
평균-교사 합성곱 순환 신경망 모델을 이용한 약지도 음향 이벤트 검출 시스템의 성능 분석,2021,['-'],,"This paper introduces and implements a Sound Event Detection (SED) system based on weakly-supervised learning where only part of the data is labeled, and analyzes the effect of parameters. The SED system estimates the classes and onset/offset times of events in the acoustic signal. In order to train the model, all information on the event class and onset/offset times must be provided. Unfortunately, the onset/offset times are hard to be labeled exactly. Therefore, in the weakly-supervised task, the SED model is trained by ""strongly labeled data"" including the event class and activations, ""weakly labeled data"" including the event class, and ""unlabeled data"" without any label. Recently, the SED systems using the mean-teacher model are widely used for the task with several parameters. These parameters should be chosen carefully because they may affect the performance. In this paper, performance analysis was performed on parameters, such as the feature, moving average parameter, weight of the consistency cost function, ramp-up length, and maximum learning rate, using the data of DCASE 2020 Task 4. Effects and the optimal values of the parameters were discussed."
스트립 바이너리에서 합성곱 신경망을 이용한 컴파일러 정보 추출 기법,2021,"['Convolution Neural Network', 'Strip binary', 'Compiler information extraction']",,"The strip binary is a binary from which debug symbol information has been deleted, and therefore it is difficult to analyze the binary through techniques such as reverse engineering. Traditional binary analysis tools rely on debug symbolic information to analyze binaries, making it difficult to detect or analyze malicious code with features of these strip binaries. In order to solve this problem, the need for a technology capable of effectively extracting the information of the strip binary has emerged. In this paper, focusing on the fact that the byte code of the binary file is generated very differently depending on compiler version, optimazer level, etc. For effective compiler version extraction, the entire byte code is read and imaged as the target of the stripped binaries and this is applied to the convolution neural network. Finally, we achieve an accuracy of 93.5%, and we provide an opportunity to analyze stripped binary more effectively than before."
VVC 인코더에서 합성 곱 신경망의 어텐션 맵을 이용한 휘도 매핑 함수 생성 방법,2021,"['VVC', 'Encoder', 'Luma mapping with Chroma Scaling', 'CNN']",,"In this paper, we propose a method for generating luma signal mapping function to improve the coding efficiency of luma signal mapping methods in LMCS. In this paper, we propose a method to reflect the cognitive and perceptual features by multiplying the attention map of convolutional neural networks on local spatial variance used to reflect local features in the existing LMCS. To evaluate the performance of the proposed method, BD-rate is compared with VTM-12.0 using classes A1, A2, B, C and D of MPEG standard test sequences under AI (All Intra) conditions. As a result of experiments, the proposed method in this paper shows improvement in performance the average of -0.07% for luma components in terms of BD-rate performance compared to VTM-12.0 and encoding/decoding time is almost the same."
저복잡도를 위한 합성곱 신경망 기반의 적응형 4D-8PSK-TCM,2021,"['satellite communications', '4D-8PSK-TCM', 'T-algorithm', 'CNN']",,
파노라마방사선사진에서 심층 합성곱 신경망의 하악 피질골 비박 판독 능력,2021,"['Mandible', 'Osteoporosis', 'Panoramic radiograph', 'Neural network']",,"Deep convolutional network is a deep learning approach to optimize image recognition. This study aimed to apply DCNN to the reading of mandibular cortical thinning in digital panoramic radiographs. Digital panoramic radiographs of 1,268 female dental patients (age 45.2 ± 21.1yrs) were used in the reading of the mandibular cortical bone by two maxillofacial radiologists. Among the subjects, 535 normal subject’s panoramic radiographs (age 28.6 ±7.4 yrs) and 533 those of osteoporosis pationts (age 72.1 ± 8.7 yrs) with mandibular cortical thinning were used for training DCNN. In the testing of mandibular cortical thinning, 100 panoramic radiographs of normal subjects (age 26.6 ± 4.5 yrs) and 100 mandibular cortical thinning (age 72.5 ± 7.2 yrs) were used. The sensitive area of DCNN to mandibular cortical thinning was investigated by occluding analysis. The readings of DCNN were compared by two maxillofacial radiologists.DCNN showed 97.5% accuracy, 96% sensitivity, and 99% specificity in reading mandibular cortical thinning. DCNN was sensitively responded on the cancellous and cortical bone of the mandibular inferior area. DCNN was effective in diagnosing mandibular cortical thinning."
다중 데이터 합성 알고리즘 및 합성곱 신경망을 사용한 신원확인 기법 연구,2021,"['identification', 'face recognition', 'watermarking', 'data synthesis', 'artificial intelligence', 'CNN']",,"This paper proposes an identification method using multiple biometric data synthesis algorithms and convolutional neural networks. In general, multi-biological data-based identity verification methods use multimodal deep learning. However, computation increases when two or more networks are used, making applying to the embedded system difficult. In this paper, a voice for authentication composed of facial images and several syllables was synthesized into one data, and identification was performed by applying it to one convolutional neural network. As for the actual environmental data for learning, a total of 800 multi-biological synthesized images were used by combining 8 facial images per person and 20 voices for authentication for 5 experimental personnel. As a result of the experiment, it was confirmed that the proposed identification method operates normally with an inference accuracy of about 93%."
간병 로봇을 위한 합성곱 신경망 (CNN) 기반 의약품 인식기 설계,2021,"['Convolutional Neural Network', 'Medicine classification', 'EfficientNet', 'Nursing robot', 'Autonomous mobile robot', 'Collaborative robot']",,"Our final goal is to implement nursing robots that can recognize patient's faces and their medicine on prescription. They can help patients to take medicine on time and prevent its abuse for recovering their health soon. As the first step, we proposed a medicine classifier with a low computational network that is able to run on embedded PCs without GPU in order to be applied to universal nursing robots. We confirm that our proposed model called MedicineNet achieves an 99.99% accuracy performance for classifying 15 kinds of medicines and background images. Moreover, we realize that the calculation time of our MedicineNet is about 8 times faster than EfficientNet-B0 which is well known as ImageNet classification with the high performance and the best computational efficiency."
주철 미세조직 분석을 위한 합성곱 신경망에서의 중간층 시각화,2021,"['machine learning', 'convolutional neural network', 'image recognition', 'microstructure', 'cast iron']",,"We attempted to classify the microstructural images of spheroidal graphite cast iron and grey cast iron using a convolutional neural network (CNN) model. The CNN comprised four combinations of convolution and pooling layers followed by two fully-connected layers. Numerous microscopic images of each cast iron were prepared to train and verify the CNN model. After training the network, the accuracy of the model was validated using an additional set of microstructural images which were not included in the training data. The CNN model exhibited an accuracy of approximately 98% for classification of the cast irons. Typically, CNN does not provide bases for image classification to human users. We tried to visualize the images between the network layers, to find out how the CNN identified the microstructures of the cast irons. The microstructural images shrank as they passed the convolutional and pooling layers. During the processes, it seems that the CNN detected morphological characteristics including the edges and contrast of the graphite phases. The mid-layer images still retained their characteristic microstructural features, although the image sizes were shrunk. The final images just before connecting the fully-connected layers seemed to have minimalized the information about the microstructural features to classify the two kinds of cast irons. Matrix phases such as ferrite and pearlite did not show prominent effects on the classification accuracy."
다중 RGB Depth 카메라 및 합성곱 신경망을 이용한 6축 매니퓰레이터의 파지 알고리즘에 관한 연구,2021,"['visual servoing', 'CNN', 'manipulator', 'pick-and-place', 'image processing']",,"In this paper, we propose a gripping algorithm for a 6-axis manipulator using two RGB depth cameras and a convolutional neural network (CNN). The proposed algorithm infers and locates an object through an RGB depth camera located in the working space, and then grasps the object through an RGB depth camera mounted on the manipulators end-effector. Then, by calculating the rotation angle and direction of the object, a gripping position is searched and a pick-and-place operation is performed. As a result of the experiments, the proposed algorithm showed that the gripping and pick-and-place motion were normally performed according to the shape of the object when a previously learned rectangular box and cylindrical object were detected."
신용 데이터의 이미지 변환을 활용한 합성곱 신경망과 설명 가능한 인공지능(XAI)을 이용한 개인신용평가,2021,"['Convolutional Neural Networks', 'eXplainable Artificial Inteligence', 'Deep learning', 'Imaged data', 'Personal credit rating']",,"PurposeThe purpose of this study is to enhance the accuracy score of personal credit scoring using the convolutional neural networks and secure the transparency of the deep learning model using eXplainalbe Artifical Inteligence(XAI) technique.Design/methodology/approachThis study built a classification model by using the convolutional neural networks(CNN) and applied a methodology that is transformation of numerical data to imaged data to apply CNN on personal credit data. Then layer-wise relevance propagation(LRP) was applied to model we constructed to find what variables are more influenced to the output value.FindingsAccording to the empirical analysis result, this study confirmed that accuracy score by model using CNN is highest among other models using logistic regression, neural networks, and support vector machines. In addition, With the LRP that is one of the technique of XAI, variables that have a great influence on calculating the output value for each observation could be found."
3D GPR 탐사 데이터와 심층 합성곱 신경망을 이용한 지하 관로 자동 탐색 시스템,2021,"['Underground Pipe', 'GPR', 'Deep Learning', '3D Image Segmentation', 'Automatic Detection System of Underground Pipe', '지하 관로', '지표 투과 레이더', '딥 러닝', '3D 이미지 분할', '지하 관로 자동 탐색 시스템']","본 논문에서는 관로를 자동으로 검출하는 지하 관로 자동 탐색 시스템을 제안한다. 시간에 따른 지반변화, 관로 시공 불일치 등 여러 가지 요인으로 실제 관로의 위치가 지하 관로 도면과 일치하지 않는다. 이로 인하여 굴착공사나 관로 노후화에 의한 여러 사고가 발생한다. 사고를 방지하기 위해 GPR(지표 투과 레이더, Ground Penetrating Radar) 탐사를 통해 지하시설물을 찾아내는 작업이 이루어지고 있지만, 분석을 담당할 수 있는 전문가의 수가 부족하다. GPR 데이터는 매우 방대하며 분석과정에도 오랜 시간이 걸리기 때문이다. 이에 본 논문에서는 3D GPR 데이터를 자동으로 분석하기 위해 딥 러닝기술인 3D 이미지 분할을 사용하고, 이에 적합한 데이터 생성 알고리즘을 제안한다. 또한 GPR 데이터 특성에 맞는 데이터 증강 기법, 데이터 전처리 모듈을 제안한다. 실험 결과를 통해 제안한 시스템은 F1 Score 40.4%의 성능을 보였으며 이를 통해 이미지 분할을 이용한 관로 분석의 가능성을 확인하였다.","In this paper, we propose Automatic detection system of underground pipe which automatically detects underground pipe to help experts. Actual location of underground pipe does not match with blueprint due to various factors such as ground changes over time, construction discrepancies, etc. So, various accidents occur during excavation or just by ageing. Locating underground utilities is done through GPR exploration to prevent these accidents but there are shortage of experts, because GPR data is enormous and takes long time to analyze. In this paper, To analyze 3D GPR data automatically, we use 3D image segmentation, one of deep learning technique, and propose proper data generation algorithm. We also propose data augmentation technique and pre-processing module that are adequate to GPR data. In experiment results, we found the possibility for pipe analysis using image segmentation through our system recorded the performance of F1 score 40.4%."
맞대기 V형 그루브의 GMA 초층용접에서 합성곱 신경망을 이용한 이면비드 발생 예측 모델 개발,2021,"['Gas metal arc welding (GMAW)', 'V-Groove', 'Back-bead', 'Root pass', 'Full penetration', 'Deep learning', 'Convolutional neural network (CNN)', 'Laser vision']",,"Gas metal arc (GMA) welding is widely used in the machinery industry. The quality of a welded joint is affected by the penetration of root pass welding in the V-groove joint. Automation using GMA welding is continuously required, and root pass welding automation is required to automate the entire welding process. In particular, the development of a prediction model that can ensure full penetration back-bead is required for the automation of root pass welding. In this study, a convolutional neural network (CNN) model was applied to predict the occurrence of back-bead in V-groove butt joint GMA root pass welding. The bead profile was measured using a laser vision sensor system and it was used as the input data for the prediction model, and the bead occurrence was used as the output data for the model. A total of 12,873 bead profiles were extracted and pre-processed through cutting, resizing, and thresholding. The CNN model consists of nine layers, and performs three convolution and two pooling operations. The accuracy of the prediction model was 99.5%, and through this study, it was demonstrated that the quality of root-pass welding can be controlled by using convolutional neural network and it can contribute to automation."
수목 동정을 위한 수피 분류 데이터셋 구축과 합성곱 신경망 기반 53개 수종의 동정 모델 개발,2021,"['tree species identification', 'bark', 'convolutional neural network']",,"Many studies have been conducted on developing automatic plant identification algorithms using machine learning to various plant features, such as leaves and flowers. Unlike other plant characteristics, barks show only little change regardless of the season and are maintained for a long period. Nevertheless, barks show a complex shape with a large variation depending on the environment, and there are insufficient materials that can be utilized to train algorithms. Here, in addition to the previously published bark image dataset, BarkNet v.1.0, images of barks were collected, and a dataset consisting of 53 tree species that can be easily observed in Korea was presented. A convolutional neural network (CNN) was trained and tested on the dataset, and the factors that interfere with the model's performance were identified. For CNN architecture, VGG-16 and 19 were utilized. As a result, VGG-16 achieved 90.41% and VGG-19 achieved 92.62% accuracy. When tested on new tree images that do not exist in the original dataset but belong to the same genus or family, it was confirmed that more than 80% of cases were successfully identified as the same genus or family. Meanwhile, it was found that the model tended to misclassify when there were distracting features in the image, including leaves, mosses, and knots. In these cases, we propose that random cropping and classification by majority votes are valid for improving possible errors in training and inferences."
설치류 후각 뇌의 혈역학적 반응을 이용한 합성곱 신경망 기반 냄새 분류,2021,"['near-infrared spectroscopy', 'convolutional neural networks', 'hemodynamic responses', 'olfactory bulb']",,"Although various odor detection and identification devices are being developed, such as air pollution, sewage pollution, fire, and explosive detection, there are still many difficulties in reproducing the mammalian sense of smell. Research is being actively conducted based on the fact that neural response signals in the olfactory brain of mammals appear differently depending on the odorant. In particular, near-infrared spectroscopy is a non-invasive technique that can stably record the neural response of the olfactory brain according to odors. Therefore, this study proposes a method for classifying odorants from data recorded neural responses of rat olfactory bulbs through near-infrared spectroscopy. Convolutional Neural Networks, one of the deep learning-based image classification technologies, was used as a classifier to classify three odor including air, isoamyl acetate, 2-heptanone. The classification result showed an average performance of 0.79 based on the F1-score."
ResNet-합성곱 오토인코더 기반 신경망을 이용한 스펙트럼 데이터 압축,2021,"['Data Compression', 'PCA', 'Autoencoder', 'ResNet', 'Raman Spectrum']","본 논문에서는 스펙트럼 저장 시 데이터용량을 줄이기 위해 합성곱 오토인코더(convolutional autoencoder) 구조에 ResNet(Residual Neural Network) 알고리즘을 적용한 스펙트럼 데이터 압축 신경망을 제안한다. 최근 분광법(spectroscopy)의 적용 분야가 넓어짐에 따라 스펙트럼 데이터베이스가 대용량화되어 효율적인 전송이 어렵고 많은 저장 공간을 필요로 한다. 이러한 대용량의 데이터베이스를 효율적으로 관리하기 위해 데이터 압축을 수행한다. 기존 데이터 압축에 주로 사용되는 PCA(Principal Component Analysis)는 주성분의 개수에 따라 압축률이 결정된다. 주성분 개수가 적을수록 압축률은 높아지지만 정보 손실이 보다 쉽게 발생하기 복원 시 원본 데이터와의 크게 오차가 발생한다. 이러한 한계점을 극복하기 위해 본 논문에서는 제안한 신경망인 CAER(Convolutional AutoEncoder+ResNet)을 통하여 데이터 압축을 수행하였다. 신경망 학습은 실제 스펙트럼 데이터를 묘사하여 생성한 모의실험 데이터를 통해 수행하였다. CAER 신경망의 성능 검증을 위해 라만 스펙트럼을 PCA와 신경망을 통하여 75%, 87.5%, 93.75%의 압축률로 압축과 복원을 수행한 후 각각의 결과를 비교 분석하였다. 원본과 복원 데이터의 오차 비교를 하였을 때 CAER 신경망은 PCA보다 평균 94.2%의 낮은 오차를 보인다. 이 결과를 통해 CAER 신경망이 스펙트럼 데이터 압축에 효과적으로 적용될 수 있음을 확인하였다.","In this paper, we propose a spectrum compression neural network that applied the ResNet (Residual Neural Network) algorithm to the convolutional autoencoder structure to reduce data capacity requirement in storing the spectrum. Recently, as the field of application of spectroscopy widens, the spectrum database is becoming larger, making efficient transmission difficult and requiring large amount of storage. Therefore, data compression is performed to manage large amounts of data efficiently. In PCA (Principal Component Analysis), which is mainly used for data compression, the compression ratio is determined by the number of principal components. As the number of principal components decreases, the compression rate increases, but at the same time, it is easier for information loss to occur. Hence, errors occur between reconstruction and the raw spectrum. To overcome these limitations, we perform compression through the proposed CAER (Convolutional AutoEncoder+ResNet) network. The training of the network was performed through simulated data describing the real spectrum. To verify the performance of the CAER network, the Raman spectrum was compressed and reconstructed at compression rates of 75%, 87.5%, and 93.75% through the PCA and CAER networks. Comparing the errors between raw and reconstructed data, the CAER network shows an average error of 94.2% lower than that of the PCA. The results obtained confirm that the CAER network can be effectively applied to spectrum compression."
3차원 합성곱 양방향 게이트 순환 신경망을 이용한 음악 템포 자극에 따른 다채널 뇌파 분류 방식,2021,"['ElectroEncephaloGraphy (EEG)', 'Tempo stimuli', '3D convolutional bidirectional gated recurrent neural network', 'Gated recurrent unit', '뇌파', '템포 자극', '3차원 합성곱 양방향 게이트 순환 신경망', '게이트 순환 유닛']",본 논문에서는 다양한 음악 템포 자극에 따라 변화하는 다채널 ElectroEncephaloGraphy(EEG)의 특징을추출하고 분류하는 방식을 제안한다. 제안하는 방식에서 3차원 합성곱 양방향 게이트 순환 신경망은 전처리 과정 통해변환된 3차원 EEG 입력 표현으로부터 시공간 및 긴 시간 종속적 특징을 추출한다. 실험 결과는 제안된 템포 자극 분류방식이 기존의 방식보다 우수하며 음악 기반 뇌-컴퓨터 인터페이스를 구축할 수 있는 가능성을 보여준다.,"In this paper, we propose a method to extract and classify features of multi-channel Electro- Encephalo Graphy (EEG) that change according to various musical tempo stimuli. In the proposed method, a 3D convolutional bidirectional gated recurrent neural network extracts spatio-temporal and long time-dependent features from the 3D EEG input representation transformed through the preprocessing. The experimental results show that the proposed tempo stimuli classification method is superior to the existing method and the possibility of constructing a music-based brain-computer interface."
딥러닝 합성곱에서 데이터 재사용에 최적화된 GPGPU 설계,2021,"['Data Reuse', 'CNN', 'GPGPU', 'Row stationary', 'SIMT', 'Warp', 'Register bank']","본 논문은 합성곱 신경망에 데이터 재사용 방법을 효과적으로 적용하여 연산 횟수와 메모리 접근 횟수를 줄일 수 있는 GPGPU구조를 제안한다. 합성곱은 kernel과 입력 데이터를 이용한 2차원 연산으로 kernel이 slide하는 방법으로 연산이 이루어 진다. 이때, 합성곱 연산이 완료될 때 까지 kernel을 캐시메모리로 부터 전달 받는 것이 아니고 내부 레지스터를 이용하는 재사용 방법을 제안한다. SIMT방법으로 명령어가 실행되는 GPGPU의 원리 이용하여 데이터 재사용의 효과를 높이기 위해 합성곱에 직렬 연산 방식을 적용하였다. 본 논문에서는 레지스터기반 데이터 재사용을 위하여 kernel을 4x4로 고정하고 이를 효과적으로 지원하기 위한 warp 크기와 레지스터 뱅크를 갖는 GPGPU를 설계하였다. 설계된 GPGPU의 합성곱 신경망에 대한 성능을 검증하기 위해 FPGA로 구현한 뒤 LeNet을 실행시키고 TensorFlow를 이용한 비교 방법으로 AlexNet에 대한 성능을 측정하였다. 측정결과 AlexNet기준 1회 학습 속도는 0.468초이며 추론 속도는 0.135초이다.","This paper proposes a GPGPU structure that can reduce the number of operations and memory access by effectively applying a data reuse method to a convolutional neural network(CNN). Convolution is a two-dimensional operation using kernel and input data, and the operation is performed by sliding the kernel. In this case, a reuse method using an internal register is proposed instead of loading kernel from a cache memory until the convolution operation is completed. The serial operation method was applied to the convolution to increase the effect of data reuse by using the principle of GPGPU in which instructions are executed by the SIMT method. In this paper, for register-based data reuse, the kernel was fixed at 4x4 and GPGPU was designed considering the warp size and register bank to effectively support it. To verify the performance of the designed GPGPU on the CNN, we implemented it as an FPGA and then ran LeNet and measured the performance on AlexNet by comparison using TensorFlow. As a result of the measurement, 1-iteration learning speed based on AlexNet is 0.468sec and the inference speed is 0.135sec."
합성곱 오토인코더를 이용한 체인 전동 장치의 고장 결함 감지 및 진단,2021,"['Fault Detection(고장 검출)', 'Fault Diagnosis(고장 진단)', 'Deep Learning(딥러닝)', 'Convolutional Auto-encoder(합성곱 오토인코더)', 'Unsupervised Learning(비지도학습)', 'Convolutional Neural Network(합성곱 신경망)']",,"This paper presents a method to detect the mechanical faults of a chain drive power transmission system (CDPTS) using a convolutional auto-encoder (CAE). In previous research, it was known that the methods to detect faults of the CDPTS based on an artificial neural network (ANN) and convolutional neural network (CNN) were useful. In this paper, an advanced application of CNN, the CAE function of CNN is employed to detect faults. This method uses the characteristics of reconstruction of CAE. Difference of input images of the CNN and reconstructed images extracted by CAE were used as the guideline of fault detection. In the fault condition of the system, the difference was larger than the predetermined threshold of error. The encoder of CAE can be fine-tuned to classify the fault types of CDPTS. Finally, this method was well applied to diagnose the fault types of the test CDPTS installed in the laboratory."
합성 데이터를 통한 부분 가려짐에 강인한 군용 차량 검출,2021,"['부분 가림', '객체 검출', '가려짐 합성', '군용 차량 검출', '심층 합성곱 신경망', 'partially occluded', 'object detection', 'synthetically occluded', 'military vehicle detection', 'deep convolutional neural networks']","최근 심층 신경망 기반 객체 검출 기술의 발전에도 불구하고 부분적으로 가려진 객체를 검출하는 것은 여전히 어려운 문제이다. 객체의 외관 및 형태에 대한 제한적인 정보로 인해 가려짐이 있는 객체에 대한 정확한 바운딩 박스를 찾거나 클래스를 구별하는 것이 어렵기 때문이다. 본 논문에서는 가려짐을 갖는 데이터를 합성하여 생성하고, 이를 이용한 모델 학습을 통해 부분 가려짐이 있는 객체의 검출 성능을 향상시키는 방법을 제안한다. 다양한 가려짐 상황을 고려하기 위해 다양한 가려짐 레벨 및 종류에 따라 합성 데이터를 생성한다. 제안하는 방법의 성능을 평가하기 위해 실제 군용 차량에 대한 데이터셋을 수집하였고, 이에 대한 합성 데이터를 생성하여 모델 학습에 활용하였다. 다양한 실험을 통해 합성 데이터를 이용하여 학습한 모델이 부분 가려짐을 갖는 객체 검출 성능을 향상시킴을 보였다.","Although advances in object detection are based on deep neural networks, detecting partially occluded objects remains a difficult task. Localizing or classifying objects under partial occlusion is difficult due to limited information about the appearances and shapes of the objects. This paper generates synthetically occluded data and presents a method to improve object detection under partial occlusion by synthetic data. We generated synthetic data with various levels and types of occlusion to consider various occlusion situations. To evaluate our method, we collect a military vehicle dataset and exploit the synthetically occluded data generated by our method for model learning. We show that our model trained with synthetic data improves object detection under partial occlusion through various experiments."
Attention U-Net 신경망을 활용한 유체의 미래 상태 예측 기법,2021,"['딥러닝', '합성곱 신경망', '전산 유체 역학', '나비에-스토크스 방정식', '유체 시뮬레이션', 'Computational fluid dynamics', 'Navier Stokes equation', 'Deep learning', 'Convolutional Neural network', 'Fluid simulation.']","전산 유체 역학 시뮬레이션은 항공기, 건물, 자동차 등 유체와 관련된 다양한 디자인 분야에서 활용이 되어지고 있으나, 오랜 실행 시간과 많은 비용이 발생하는 나비에-스토크스 방정식의 사용으로 인해 개발에 많은 시간이 소요된다. 또한 위험 물질이 확산되는 환경과 같이 즉각적인 유체 흐름의 분석이 필요한 분야에서는활용이 어렵기 때문에 최대한 정확도를 보존하면서 빠르게 예측하는 기술이 매우 중요하게 여겨지고 있다.이를 위해 본 연구에서는 Attention U-Net 신경망을 기반으로 유체의 흐름을 예측하는 방법론을 제안하고테스트한다. 장애물을 인식하여 빠르게 7초 후 미래의 유체 흐름을 예측하는 방법으로 테스트를 진행하였고, 그 결과 기존 시뮬레이션 소프트웨어 및 CNN모델을 사용하였을 때 대비 정확도는 최대한 보존하면서 실행속도는 약 85배 빠른 결과를 얻을 수 있었다.","Computational Fluid Dynamics (CFD) simulation is used in various fluid-related fields such as aircrafts, buildings, or automobiles design and it consumes a lot of development time due to the use of Navier Stokes equation, which incur a long execution time with high cost. In addition, it is difficult to use it in such environments as the hazardous substance or epidemic diffusion where the fluid flow must be predicted immediately. In the situations, it is important and critical to predict as quickly as possible while preserving accuracy. Hence in this study, to address the issues, we suggest and test a method that uses Attention U-Net neural network to predict the future state of the fluid in a terrain with obstacles. As a result, compared to the existing simulation software or simple CNN method, the suggested approach shows the execution speed is 85 times faster while preserving the competitive accuracy."
딥러닝 기반 탄성파 단층 해석을 위한 합성 학습 자료 생성,2021,"['딥 러닝', '학습 자료', '단층 해석', '합성곱 신경망', '합성 탄성파 자료', 'deep learning', 'training data', 'fault interpretation', 'convolutional neural network', 'synthetic seismic data']",,"Fault detection in seismic data is well suited to the application of machine learning algorithms. Accordingly, various machine learning techniques are being developed. In recent studies, machine learning models, which utilize synthetic data, are the particular focus when training with deep learning. The use of synthetic training data has many advantages; Securing massive data for training becomes easy and generating exact fault labels is possible with the help of synthetic training data. To interpret real data with the model trained by synthetic data, the synthetic data used for training should be geologically realistic. In this study, we introduce a method to generate realistic synthetic seismic data. Initially, reflectivity models are generated to include realistic fault structures, and then, a one-way wave equation is applied to efficiently generate seismic stack sections. Next, a migration algorithm is used to remove diffraction artifacts and random noise is added to mimic actual field data. A convolutional neural network model based on the U-Net structure is used to verify the generated synthetic data set. From the results of the experiment, we confirm that realistic synthetic data effectively creates a deep learning model that can be applied to field data."
CNN(Convolutional Neural Network) 알고리즘을 활용한 음성신호 중 비음성 구간 탐지 모델 연구,2021,"['음성인식', '딥러닝', '합성곱신경망', '인공지능', 'NLP', 'Speech Recognition', 'Deep-Learning', 'CNN', 'Artificial-Intelligence', 'NLP']",,
악성코드의 특성 이미지화를 통한 딥러닝 기반의 탐지 모델,2021,"['악성코드', '지능화', '악성코드 변종', '딥러닝', '탐지 모델', 'Malware', 'Intelligence', 'Malware Variants', 'Deeplearning', 'Detection Model']",,
SKU-Net: Improved U-Net using Selective Kernel Convolution for Retinal Vessel Segmentation,2021,"['Deep Learning', 'Retinal Vessel Segmentation', 'Convolutional Neural Network', 'Selective Kernel Convolution', 'U-Net', '딥러닝', '망막 혈관 분할', '합성곱 신경망', '선택적 커널 합성곱']","본 논문에서는 안저영상의 다중 스케일 정보를 다루기 위한 딥러닝 기반의 망막 혈관 분할 모델을 제안한다. 제안 모델은 이미지 분할 딥러닝 모델인 U-Net과 선택적 커널 합성곱을 통합한 합성곱 신경망으로 안저영상에서 눈과 관련된 질병을 진단하는데 중요한 정보가 되는 망막 혈관의 다양한 모양과 크기를 갖는 특징 정보를 추출하고 분할한다. 제안 모델은 일반적인 합성곱과 선택적 커널 합성곱으로 구성된다. 일반적인 합성곱 층은 같은 크기 커널 크기를 통해 정보를 추출하는 반면, 선택적 커널 합성곱은 다양한 커널 크기를 갖는 브랜치들에서 정보를 추출하고 이를 분할 주의집중을 통해 적응적으로 조정하여 결합한다. 제안 모델의 성능 평가를 위해 안저영상 데이터인 DRIVE와 CHASE DB1 데이터셋을 사용하였으며 제안 모델은 두 데이터셋에 대하여 F1 점수 기준 82.91%, 81.71%의 성능을 보여 망막 혈관 분할에 효과적임을 확인하였다.","In this paper, we propose a deep learning-based retinal vessel segmentation model for handling multi-scale information of fundus images. we integrate the selective kernel convolution into U-Net-based convolutional neural network. The proposed model extracts and segment features information with various shapes and sizes of retinal blood vessels, which is important information for diagnosing eye-related diseases from fundus images. The proposed model consists of standard convolutions and selective kernel convolutions. While the standard convolutional layer extracts information through the same size kernel size, The selective kernel convolution extracts information from branches with various kernel sizes and combines them by adaptively adjusting them through split-attention. To evaluate the performance of the proposed model, we used the DRIVE and CHASE DB1 datasets and the proposed model showed F1 score of 82.91% and 81.71% on both datasets respectively, confirming that the proposed model is effective in segmenting retinal blood vessels."
이미지 데이터에 대한 비선형 분류 방법의 비교,2021,"['지지벡터기계', '지지행렬기계', '커널', '합성곱 신경망', 'Convolutional neural network', 'kernel', 'support matrix machine', 'support vector machine']","이미지 분류는 기계학습에서 가장 활발하게 연구되고 있는 주제 중 하나이다. 이미지 데이터는 일반적으로 2차원 혹은 3차원 행렬 구조를 가지고 있으며, 지지벡터기계 등 전통적인 분류 기법을 적용하기 위해 벡터화를 시행하게 된다. 하지만 벡터화는 이미지 데이터가 제공하는 구조적 정보를 무시할 수 있다. 구조적 정보를 이용하는 합성곱 신경망은 이러한 단점을 보완하기 위해 도입되었으나, 합성곱 신경망을 포함하는 신경망은 일반적으로 많은 데이터를 요구한다. 반면 지지벡터기계는 적은 수의 표본에서도 상대적으로 안정적인 분류 성능을 보일 뿐만 아니라 지지행렬기계 및 커널 지지행렬기계로 확장됨으로써 이미지 데이터의 구조적 정보도 반영할 수 있게 되었다. 본 논문에서는 표본의 개수가 상대적으로 적은 이미지 데이터에 대하여 비선형 분류 방법인 지지벡터기계, 커널 지지행렬기계, 그리고 합성곱 신경망의 예측 성능을 비교하고 선형 분류 방법이지만 이미지 데이터의 구조적 정보를 반영하는 지지행렬기계도 함께 비교한다.","Image classification is one of the most actively studied topics in machine learning. Image data generally has a two-dimensional or three-dimensional matrix structure, and vectorization is performed to apply traditional classification techniques such as support vector machine (SVM). However, vectorization may ignore the structural information provided by image data. Convolutional neural network (CNN) using structural information has been introduced as a remedy to the drawback, but neural networks including CNN generally require a lot of data. On the other hand, SVM shows stable classification performances even with a small number of samples, and extensions of SVM reflecting structural information such as support matrix machine (SMM) and kernel support matrix machine (KSMM) have been recently proposed. In this paper, we compare the predictive performances of SVM, SMM, KSMM, and CNN on image data with relatively small number of samples."
경안천 용존 산소 예측을 위한 입력 인자 선정 및 기계 학습 모델 비교,2021,"['인공신경망', '합성곱 신경망', '게이트 순환 유닛', '경안천', '랜덤 포레스트', 'Artificial Neural Network', 'Convolutional Neural Network', 'Gated Recurrent Unit', 'Gyeongan Stream', 'Random Forest']","목적:본 연구에서는 경안천의 용존 산소(dissolved oxygen, DO) 예측을 위해 기계 학습(machine learning) 모델의 최적 입력 인자를 선정하고 성능 평가 지표 결과를 비교하여 최적 모델을 찾고자 한다.방법:경안천 특정 지점의 수질 자료를 연구대상으로 삼아 1998년 1월 15일부터 2019년 12월 30일까지 자료를 수집하고, 전처리한 데이터를 7:3의 비율에 따라 train과 test 자료로 나누어 실험을 진행하였다. 기계 학습 중 랜덤 포레스트(random forest, RF), 인공신경망(artificial neural network, ANN), 합성곱 신경망(convolutional neural network, CNN), 게이트 순환 유닛(gated recurrent unit, GRU) 등을 이용하였다. RF와 ANN은 무작위 추출(random split)과 시계열 자료(time series)로 구분하여 실험하였으며, CNN과 GRU는 시계열 자료만 이용하여 실험을 진행하였다. 모델별 최적의 결과를 비교하기 위해 성능 평가 지표(결정 계수(square of the correlation coefficient, R2), 평균 제곱근 오차(root mean square error, RMSE), 평균 절대 오차(mean absolute error, MAE))를 사용하였다.결과 및 토의:RF 기여도 분석 결과와 참고문헌을 통해 최적 입력 인자로 수온, pH, 전기 전도도, PO4-P, NH4-N, 총 인, 부유물질, NO3-N 등으로 선정하였다. RF와 ANN 모두 무작위 추출보다 시계열 자료의 성능이 더 우수하였다. 시계열 자료를 이용하여 모델 성능을 비교해 보면, RF > CNN > GRU > ANN 순으로 나타났다.결론:본 연구에서 경안천의 DO 예측을 위한 기계 학습 모델의 최적 입력 인자로 8개(수온, pH, 전기 전도도, PO4-P, NH4-N, 총 인, 부유물질, NO3-N)를 선택하였다. DO 예측에 가장 우수한 모델은 시계열 자료를 사용한 RF 모델이었다. 따라서 경안천과 같은 하천의 DO를 예측하는 경우 최적 입력 인자 선정 후 시계열 자료를 바탕으로 RF 모델을 이용할 것을 제안한다.","Objectives:In this study, we select input factors for machine learning models to predict dissolved oxygen (DO) in Gyeongan Stream and compare results of performance evaluation indicators to find the optimal model.Methods:The water quality data from the specific points of Gyeongan Stream were collected between January 15, 1998 and December 30, 2019. The pretreatment data were divided into train and test data with the ratio of 7:3. We used random forest (RF), artificial neural network (ANN), convolutional neural network (CNN), and gated recurrent unit (GRU) among machine learning. RF and ANN were tested by both random split and time series data, while CNN and GRU conducted the experiment using only time series data. Performance evaluation indicators such as square of the correlation coefficient (R2), root mean square error (RMSE), and mean absolute error (MAE) were used to compare the optimal results for the models.Results and Discussion:Based on the RF variable importance results and references, water temperature, pH, electrical conductivity, PO4-P, NH4-N, total phosphorus, suspended solids, and NO3-N were used as input factors. Both RF and ANN performed better with time series data than random split. The model performance was good in order of RF > CNN > GRU > ANN.Conclusions:The eight input factors (water temperature, pH, electrical conductivity, PO4-P, NH4-N, total phosphorus, suspended solids, and NO3-N) were selected for machine learning models to predict DO in Gyeongan Stream. The best model for DO prediction was the RF model with time series data. Therefore, we suggest that the RF with the eight input factors could be used to predict the DO in streams."
시간 연속성을 고려한 딥러닝 기반 레이더 강우예측,2021,"['레이더', '강우예측', '합성곱 신경망', '장단기메모리', '딥러닝', 'Radar', 'Rainfall prediction', 'Convolutional neural network', 'Long short-term memory', 'Deep learning']","본 연구에서는 시계열 순서의 의미가 희석될 수 있는 기존의 U-net 기반 딥러닝 강우예측 모델의 성능을 개선하고자 하였다. 이를 위해서 데이터의 연속성을 고려한 ConvLSTM2D U-Net 신경망 구조를 갖는 모델을 적용하고, RainNet 모델 및 외삽 기반의 이류모델을 이용하여 예측정확도 개선 정도를 평가하였다. 또한 신경망 기반 모델 학습과정에서의 불확실성을 개선하기 위해 단일 모델뿐만 아니라 10개의 앙상블 모델로 학습을 수행하였다. 학습된 신경망 강우예측모델은 현재를 기준으로 과거 30분 전까지의 연속된 4개의 자료를 이용하여 10분 선행 예측자료를 생성하는데 최적화되었다. 최적화된 딥러닝 강우예측모델을 이용하여 강우예측을 수행한 결과, ConvLSTM2D U-Net을 사용하였을 때 예측 오차의 크기가 가장 작고, 강우 이동 위치를 상대적으로 정확히 구현하였다. 특히, 앙상블 ConvLSTM2D U-Net이 타 예측모델에 비해 높은 CSI와 낮은 MAE를 보이며, 상대적으로 정확하게 강우를 예측하였으며, 좁은 오차범위로 안정적인 예측성능을 보여주었다. 다만, 특정 지점만을 대상으로 한 예측성능은 전체 강우 영역에 대한 예측성능에 비해 낮게 나타나, 상세한 영역의 강우예측에 대한 딥러닝 강우예측모델의 한계도 확인하였다. 본 연구를 통해 시간의 변화를 고려하기 위한 ConvLSTM2D U-Net 신경망 구조가 예측정확도를 높일 수 있었으나, 여전히 강한 강우영역이나 상세한 강우예측에는 공간평활로 인한 합성곱 신경망 모델의 한계가 있음을 확인하였다.","In this study, we tried to improve the performance of the existing U-net-based deep learning rainfall prediction model, which can weaken the meaning of time series order. For this, ConvLSTM2D U-Net structure model considering temporal consistency of data was applied, and we evaluated accuracy of the ConvLSTM2D U-Net model using a RainNet model and an extrapolation-based advection model. In addition, we tried to improve the uncertainty in the model training process by performing learning not only with a single model but also with 10 ensemble models. The trained neural network rainfall prediction model was optimized to generate 10-minute advance prediction data using four consecutive data of the past 30 minutes from the present. The results of deep learning rainfall prediction models are difficult to identify schematically distinct differences, but with ConvLSTM2D U-Net, the magnitude of the prediction error is the smallest and the location of rainfall is relatively accurate. In particular, the ensemble ConvLSTM2D U-Net showed high CSI, low MAE, and a narrow error range, and predicted rainfall more accurately and stable prediction performance than other models. However, the prediction performance for a specific point was very low compared to the prediction performance for the entire area, and the deep learning rainfall prediction model also had limitations. Through this study, it was confirmed that the ConvLSTM2D U-Net neural network structure to account for the change of time could increase the prediction accuracy, but there is still a limitation of the convolution deep neural network model due to spatial smoothing in the strong rainfall region or detailed rainfall prediction."
CNN 강우여부 분류기를 적용한 ANN 기반 X-Band 레이다 유의파고 보정,2021,"['X-band 레이다', '유의파고', '머신러닝', '인공신경망', '합성곱신경망', 'X-band marine radar', 'significant wave heights', 'machine learning', 'artificial neural network(ANN)', 'convolutional neural network(CNN)']",항해용 X-band 레이다를 이용한 파랑관측은 해수면에 후방산란 된 전자기파 이미지를 분석하여 이루어진다. 1분당 42개의 해수면 시계열 이미지로부터 3차원 FFT를 계산하고 변조전달함수(Modulation Transfer Function)를 구하여 파랑정보를 추출한다. 따라서 레이다 파고계로 계측한 유의파고의 정확도는 X-band 레이다 영상의 상태에 따라 결정된다. 2020년 여름 태풍 마이삭과 하이선 내습 시 강릉 안인 해안에 설치된 X-band 레이다 파고계로 관측한 유의파고의 오차가 크게 발생하였다. 이는 태풍 내습 시 급격히 유의파고가 증가하는 한편 강한 강우가 동반되어 X-band 레이다 영상의 품질이 저하되었기 때문이다. 최대 오차 발생 이전까지 많은 강우가 있었음이 확인된다. 본 연구에서는 convolution neural network(CNN)을 이용하여 레이다 이미지로부터 강우 여부를 분류하고 강우여부에 따라 강우시 인공신경망 모델을 적용하여 태풍 시 유의파고 관측 정확도를 향상시켰다. 폭우를 동반한 태풍 시 레이다 자료 특성에 기반하여 인공신경망 유의파고 산출 알고리즘을 개선하고 이를 통해 X-band 레이다 파고계의 정확도를 향상시키는 방법을 제시하였다.,"Wave observations using a marine X-band radar are conducted by analyzing the backscattered radar signal from sea surfaces. Wave parameters are extracted using Modulation Transfer Function obtained from 3D wave number and frequency spectra which are calculated by 3D FFT of time series of sea surface images (42 images per minute). The accuracy of estimation of the significant wave height is, therefore, critically dependent on the quality of radar images. Wave observations during Typhoon Maysak and Haishen in the summer of 2020 show large errors in the estimation of the significant wave heights. It is because of the deteriorated radar images due to raindrops falling on the sea surface. This paper presents the algorithm developed to increase the accuracy of wave heights estimation from radar images by adopting convolution neural network(CNN) which automatically classify radar images into rain and non-rain cases. Then, an algorithm for deriving the Hs is proposed by creating different ANN models and selectively applying them according to the rain or non-rain cases. The developed algorithm applied to heavy rain cases during typhoons and showed critically improved results."
인접성 벡터를 이용한 트리플 지식 그래프의 임베딩 모델 개선,2021,"['지식 그래프', '노드 임베딩', '트리플 그래프', '합성곱 신경망', '그래프 특징 추출', '머신러닝', 'Knowledge Graph', 'Node Embedding', 'Triple Graph', 'Convolutional Network', 'Graph Feature Extraction', 'Machine Learning']","그래프 표현 학습을 위한 노드 임베딩 기법은 그래프 마이닝에서 양질의 결과를 얻는 데 중요한 역할을 한다. 지금까지 대표적인 노드 임베딩 기법은 동종 그래프를 대상으로 연구 되었기에, 간선 별로 고유한 의미를 갖는 지식 그래프를 학습하는 데 어려움이 있었다. 이러한 문제를 해결하고자, 기존 Triple2Vec 기법은 지식 그래프의 노드 쌍과 간선을 하나의 노드로 갖는 트리플 그래프를 학습하여 임베딩 모델을 구축한다. 하지만 Triple2Vec 임베딩 모델은 트리플 노드 간 관련성을 단순한 척도로 산정하기 때문에 성능을 높이는데 한계를 가진다. 이에 본 논문은 Triple2Vec 임베딩 모델을 개선하기 위한 그래프 합성곱 신경망 기반의 특징 추출 기법을 제안한다. 제안 기법은 트리플 그래프의 인접성 벡터(Neighborliness Vector)를 추출하여 트리플 그래프에 대해 노드 별로 이웃한 노드 간 관계성을 학습한다. 본 논문은 DBLP, DBpedia, IMDB 데이터셋을 활용한 카테고리 분류 실험을 통해, 제안 기법을 적용한 임베딩 모델이 기존 Triple2Vec 모델보다 우수함을 입증한다.","The node embedding technique for learning graph representation plays an important role in obtaining good quality results in graph mining. Until now, representative node embedding techniques have been studied for homogeneous graphs, and thus it is difficult to learn knowledge graphs with unique meanings for each edge. To resolve this problem, the conventional Triple2Vec technique builds an embedding model by learning a triple graph having a node pair and an edge of the knowledge graph as one node. However, the Triple2 Vec embedding model has limitations in improving performance because it calculates the relationship between triple nodes as a simple measure. Therefore, this paper proposes a feature extraction technique based on a graph convolutional neural network to improve the Triple2Vec embedding model. The proposed method extracts the neighborliness vector of the triple graph and learns the relationship between neighboring nodes for each node in the triple graph. We proves that the embedding model applying the proposed method is superior to the existing Triple2Vec model through category classification experiments using DBLP, DBpedia, and IMDB datasets."
인공지능 기반 위 병변 검출 알고리즘 개발,2021,"['Gastric Endoscopy', 'CNN', 'R-CNN Model', '위 내시경', '합성곱 신경망', '영역기반 합성곱 신경망 모델']","위암은 1999년 이후 우리나라에서 가장 많이 발생하는 암으로 1위를 차지하고 있다. 위암은 내시경 검사를 통해 일차적으로 판단되고 조직검사를 통해 정확히 진단되기 전까지는 특징적인 증상이 없으며, 실제로 위 내시경 검사를 받은 환자는 받지 않은 환자에 비해 생존율이 2.24배 높다는 연구 결과가 발표된 바 있다. 이러한 문제를 해결하기 위하여 본 논문은 위암 환자의 위 내시경 시행 시 임상의에게 실시간으로 보조적인 정보를 제공해 주고자 제안되었다. 본 논문에서는 Faster R-CNN을 위 병변 검출에 적합한 모델로 개선하여 보다 빠르고 정확한 검출 결과를 임상의에게 제공하는 방법을 제안한다. 기존 알고리즘과의 비교 평가 결과 평균 91%의 정확도를 도출하여 제안 방법이 보다 효과적임을 증명하였으며, 영상 처리 속도 또한 0.1sec/frame을 도출하여 실시간 처리에 적합함을 증명하였다. 향후 연구로 다양한 환경에서의 내시경 영상 수집을 통한 학습 데이터의 개선을 통해 정확도를 개선하고자 한다.","Gastric cancer is the most common cancer and has been the number one incidence since 1999 in Korea. Gastric cancer is primarily judged through endoscopy and has no characteristic symptoms until accurately diagnosed through biopsy then In fact, a study found that patients who underwent gastroscopy had a 2.24 times higher survival rate than those who did not. to solve these problems, This paper was proposed to provide real-time ancillary information to clinicians when performing gastroscopy for gastric cancer patients. In this paper, we propose a method to provide faster and more accurate detection results to clinicians by improving Faster R-CNN as a model suitable for gastric lesion detection. As a result of comparative evaluation with existing algorithms, an average accuracy of 91% was derived, proving that the proposed method is more effective. and, The image processing speed was also proven to be suitable for real-time processing by deriving 0.1sec/frame. As a future study, we intend to improve the accuracy by improving the learning data through the collection of endoscopic images in various environments."
Deep learning based Person Re-identification with RGB-D sensors,2021,"['person re-identification', 'surveillance system', 'deep learning', 'human action recognition', 'multi class identification', '사람 재인식', '감시 시스템', '딥러닝', '합성곱신경망', '사람 행동 인식', '다중 분류 인식']","본 연구에서는 3차원 RGB-D Xtion2 카메라를 이용하여 보행자의 골격좌표를 추출한 결과를 바탕으로 동적인 특성(속도, 가속도)을 함께 고려하여 딥러닝 모델을 통해 사람을 인식하는 방법을 제안한다. 본 논문의 핵심목표는 RGB-D 카메라로 손쉽게 좌표를 추출하고 새롭게 생성한 동적인 특성을 기반으로 자체 고안한 1차원 합성곱 신경망 분류기 모델(1D-ConvNet)을 통해 자동으로 보행 패턴을 파악하는 것이다. 1D-ConvNet의 인식 정확도와 동적인 특성이 정확도에 미치는 영향을 알아보기 위한 실험을 수행하였다. 정확도는 F1 Score를 기준으로 측정하였고, 동적인 특성을 고려한 분류기 모델(JCSpeed)과 고려하지 않은 분류기 모델(JC)의 정확도 비교를 통해 영향력을 측정하였다. 그 결과 동적인 특성을 고려한 경우의 분류기 모델이 그렇지 않은 경우보다 F1 Score가 약 8% 높게 나타났다.","In this paper, we propose a deep learning-based person re-identification method using a three-dimensional RGB-Depth Xtion2 camera considering joint coordinates and dynamic features(velocity, acceleration). The main idea of the proposed identification methodology is to easily extract gait data such as joint coordinates, dynamic features with an RGB-D camera and automatically identify gait patterns through a self-designed one-dimensional convolutional neural network classifier(1D-ConvNet). The accuracy was measured based on the F1 Score, and the influence was measured by comparing the accuracy with the classifier model (JC) that did not consider dynamic characteristics. As a result, our proposed classifier model in the case of considering the dynamic characteristics(JCSpeed) showed about 8% higher F1-Score than JC."
Artificial Neural Network Method Based on Convolution to Efficiently Extract the DoF Embodied in Images,2021,"['Artificial neural network', 'Convolutional neural network', 'Depth of field', 'Image processing', 'Region of interest', 'Object detection', '인공 신경망', '합성곱 신경망', '피사계 심도', '이미지 프로세싱', '관심영역', '객체 검출']","본 논문에서는 카메라의 포커싱과 아웃포커싱에 의해 이미지에서 뿌옇게 표현되는 피사계 심도(Depth of field, DoF) 영역을 효율적인 합성곱 신경망을 통해 찾는 방법을 제안한다. 우리의 접근방식은 RGB채널기반의 상호-상관 필터를 이용하여 DoF영역을 이미지로부터 효율적으로 분류하고, 합성곱 신경망 네트워크에 학습하기 위한 데이터를 구축하며, 이렇게 얻어진 데이터를 이용하여 이미지-DoF가중치 맵 데이터 쌍을 설정한다. 학습할 때 사용되는 데이터는 이미지와 상호-상관필터 기반으로 추출된 DoF 가중치 맵을 이용하며, 네트워크 학습 단계에서 수렴률을 높이기 위해 스무딩을 과정을 한번 더 적용한 결과를 사용한다. 테스트 결과로 얻은 DoF 가중치 이미지는 입력 이미지에서 DoF영역을 안정적으로 찾아내며, 제안하는 방법은 DoF영역을 사용자의 ROI(Region of interest)로 활용하여 NPR렌더링, 객체 검출 등 다양한 곳에 활용이 가능하다.","In this paper, we propose a method to find the DoF(Depth of field) that is blurred in an image by focusing and out-focusing the camera through a efficient convolutional neural network. Our approach uses the RGB channel-based cross-correlation filter to efficiently classify the DoF region from the image and build data for learning in the convolutional neural network. A data pair of the training data is established between the image and the DoF weighted map. Data used for learning uses DoF weight maps extracted by cross-correlation filters, and uses the result of applying the smoothing process to increase the convergence rate in the network learning stage. The DoF weighted image obtained as the test result stably finds the DoF region in the input image. As a result, the proposed method can be used in various places such as NPR(Non-photorealistic rendering) rendering and object detection by using the DoF area as the user""s ROI(Region of interest)."
음향 장면 분류를 위한 경량화 모형 연구,2021,"['acoustic scene classification', 'light-weight model', 'deep learning', 'convolutional neural network', '음향 장면 분류', '경량화 모델', '딥러닝', '합성곱 신경망']","음향 장면 분류는 오디오 파일이 녹음된 환경이 어디인지 분류하는 문제이다. 이는 음향 장면 분류와 관련한 대회인 DCASE 대회에서 꾸준하게 연구되었던 분야이다. 실제 응용 분야에 음향 장면 분류 문제를 적용할 때, 모델의 복잡도를 고려하여야 한다. 특히 경량 기기에 적용하기 위해서는 경량 딥러닝 모델이 필요하다. 우리는 경량 기술이 적용된 여러 모델을 비교하였다. 먼저 log mel-spectrogram, deltas, delta-deltas 피쳐를 사용한 합성곱 신경망(CNN) 기반의 기본 모델을 제안하였다. 그리고 원래의 합성곱 층을 depthwise separable convolution block, linear bottleneck inverted residual block과 같은 효율적인 합성곱 블록으로 대체하고, 각 모델에 대하여 Quantization를 적용하여 경량 모델을 제안하였다. 경량화 기술을 고려한 모델은 기본 모델에 대비하여 성능이 비슷하거나 조금 낮은 성능을 보였지만, 모델 사이즈는 503KB에서 42.76KB로 작아진 것을 확인하였다.","Acoustic scene classification (ASC) categorizes an audio file based on the environment in which it has been recorded. This has long been studied in the detection and classification of acoustic scenes and events (DCASE). In this study, we considered the problem that ASC faces in real-world applications that the model used should have low-complexity. We compared several models that apply light-weight techniques. First, a base CNN model was proposed using log mel-spectrogram, deltas, and delta-deltas features. Second, depthwise separable convolution, linear bottleneck inverted residual block was applied to the convolutional layer, and Quantization was applied to the models to develop a low-complexity model. The model considering low-complexity was similar or slightly inferior to the performance of the base model, but the model size was significantly reduced from 503 KB to 42.76 KB."
전이 학습을 이용한 선박 기관실 기기의 분류에 관한 연구,2021,"['Patrol robot', 'Ship engine room equipment', 'Convolution neural network', 'Classification', 'Transfer learning', '순찰 로봇', '선박 기관실 기기', '합성곱 신경망', '분류', '전이 학습']","선박 기관실은 기술의 발전으로 인해 자동화 시스템이 향상되었지만, 해상에서는 바람, 파도, 진동, 기기 노후화 등의 다양한 변수가 많아 자동화 시스템에서 계측되지 않는 풀림, 절단, 누유, 누수 등이 발생하므로 기관사는 주기적으로 순찰을 한다. 순찰 시에는 1명의 기관사만 순찰하는 경우도 있으며, 이는 고온고압 및 회전기기가 운전 중인 기관실에서 많은 위험요소를 가지고 있다. 기관사가 순찰 시에는 오감을 활용하며, 특히 시각에 의존한다. 본 논문에서는 로봇이 기관실을 순찰하며 기기의 특이사항을 검출하고 알려주는 기관실 순찰 로봇을 구현하기 위한 선행연구로서 선박 기관실 기기의 이미지를 합성곱 신경망을 이용하여 분류하였다. 선박 기관실의 이미지 데이터 셋을 구성한 후 사전 훈련된 합성곱 신경망 모델로 학습하였다. 학습한 모델의 분류 성능은 높은 재현율을 보였으며, 클래스 활성화 맵으로 이미지를 시각화 하였다. 데이터의 양이 제한적이어서 일반화할 수는 없지만, 각 선박의 데이터를 전이학습으로 학습시키면 적은 시간과 비용으로 각 선박의 특성에 맞는 모델을 구축할 수 있을 것으로 사료된다.","Ship engine rooms have improved automation systems owing to the advancement of technology. However, there are many variables at sea, such as wind, waves, vibration, and equipment aging, which cause loosening, cutting, and leakage, which are not measured by automated systems. There are cases in which only one engineer is available for patrolling. This entails many risk factors in the engine room, where rotating equipment is operating at high temperature and high pressure. When the engineer patrols, he uses his five senses, with particular high dependence on vision. We hereby present a preliminary study to implement an engine-room patrol robot that detects and informs the machine room while a robot patrols the engine room. Images of ship engine-room equipment were classified using a convolutional neural network (CNN). After constructing the image dataset of the ship engine room, the network was trained with a pre-trained CNN model. Classification performance of the trained model showed high reproducibility. Images were visualized with a class activation map. Although it cannot be generalized because the amount of data was limited, it is thought that if the data of each ship were learned through transfer learning, a model suitable for the characteristics of each ship could be constructed with little time and cost expenditure."
스태킹 앙상블을 이용한 병렬 네트워크 이상호흡음 분류 모델,2021,"['Respiratory Sound Classification', 'Wheezes', 'Crackles', 'Convolutional Neural Network(CNN)', 'Stacking Ensemble', '호흡음 분류', '천명음', '수포음', '병렬 합성곱 신경망', '스태킹 앙상블']","최근 코로나(Covid-19)의 영향으로 스마트 헬스케어 관련 산업과 비대면 방식의 원격 진단을 통한 질환 분류 예측 연구의 필요성이 증가하고 있다. 일반적으로 호흡기 질환의 진단은 비용이 많이 들고 숙련된 의료 전문가를 필요로 하여 현실적으로 조기 진단 및 모니터링에 한계가 있다. 따라서, 간단하고 편리한 청진기로부터 수집된 호흡음을 딥러닝 기반 모델을 활용하여 높은 정확도로 분류하고 조기 진단이 필요하다. 본 연구에서는 청진을 통해 수집된 폐음 데이터를 이용하여 이상 호흡음 분류모델을 제안한다. 데이터 전처리로는 대역통과필터(BandPassFilter)방법론을 적용하고 로그 멜 스펙트로그램(Log-Mel Spectrogram)과 Mel Frequency Cepstral Coefficient(MFCC)을 이용하여 폐음의 특징적인 정보를 추출하였다. 추출된 폐음의 특징에 대해서 효과적으로 분류할 수 있는 병렬 합성곱 신경망 네트워크(Parallel CNN network)모델을 제안하고 다양한 머신러닝 분류기(Classifiers)와 결합한 스태킹 앙상블(Stacking Ensemble) 방법론을 이용하여 이상 호흡음을 높은 정확도로 분류하였다. 본 논문에서 제안한 방법은 96.9%의 정확도로 이상 호흡음을 분류하였으며, 기본모델의 결과 대비 정확도가 약 6.1% 향상되었다.","As the COVID-19 pandemic rapidly changes healthcare around the globe, the need for smart healthcare that allows for remote diagnosis is increasing. The current classification of respiratory diseases cost high and requires a face-to-face visit with a skilled medical professional, thus the pandemic significantly hinders monitoring and early diagnosis. Therefore, the ability to accurately classify and diagnose respiratory sound using deep learning-based AI　models is essential to modern medicine as a remote alternative to the current stethoscope. In this study, we propose a deep learning-based respiratory sound classification model using data collected from medical experts. The sound data were preprocessed with BandPassFilter, and the relevant respiratory audio features were extracted with Log-Mel Spectrogram and Mel Frequency Cepstral Coefficient (MFCC). Subsequently, a Parallel CNN network model was trained on these two inputs using stacking ensemble techniques combined with various machine learning classifiers to efficiently classify and detect abnormal respiratory sounds with high accuracy. The model proposed in this paper classified abnormal respiratory sounds with an accuracy of 96.9%, which is approximately 6.1% higher than the classification accuracy of baseline model."
전이학습 기반 CNN을 통한 풀림 방지 코팅 볼트 이진 분류에 관한 연구,2021,"['Bolts With Anti-loosening Coating', 'Convolutional Neural Networks', 'Transfer Learning', 'Fine-tuning', 'Fully Connected Layer']","풀림 방지 코팅 볼트는 주로 자동차 안전 관련 부품을 결합하는 데 사용되므로 안전성 유지를 위해 코팅 결함을 사전에 감지해야 한다. 이를 위해 이전 연구 [CNN 및 모델 시각화 기법을 사용한 코팅 볼트 불량 판별]에서는 합성곱신경망을 사용했다. 이때 합성곱 신경망은 데이터 수가 많을수록 이미지 패턴 및 특성 분석 정확도가 증가하지만 그에 따라 학습시간이 증가한다. 또한 확보 가능한 코팅 볼트 샘플이 한정적이다. 본 연구에서는 이전 연구에 전이학습을 추가적으로 적용해 데이터 개수가 적은 경우에도 코팅 결함에 대해 정확한 분류를 하고자 한다. 전이학습을 적용할 때 학습데이터 수와 사전 학습 데이터 ImageNet 간의 유사성을 고려해 분류층만 학습했다. 데이터 학습에는 전역 평균 풀링, 선형 서포트 벡터 머신 및 완전 연결 계층과 같은 분류층을 적용했으며, 고려한 모델 중 완전 연결 계층 방법의 분류층이 가장 높은 95% 정확도를 가진다. 추가적으로 마지막 합성곱층과 분류층을 미세 조정하면 정확도는 97%까지 향상된다. 전이학습 및 미세 조정을 이용하면 선별 정확도를 향상시킴은 물론 이전보다 학습 소요시간을 절반으로 줄일 수 있음을 보였다.","Because bolts with anti-loosening coatings are used mainly for joining safety-related components in automobiles, accurate automatic screening of these coatings is essential to detect defects efficiently. The performance of the convolutional neural network (CNN) used in a previous study [Identification of bolt coating defects using CNN and Grad-CAM] increased with increasing number of data for the analysis of image patterns and characteristics. On the other hand, obtaining the necessary amount of data for coated bolts is difficult, making training time-consuming. In this paper, resorting to the same VGG16 model as in a previous study, transfer learning was applied to decrease the training time and achieve the same or better accuracy with fewer data. The classifier was trained, considering the number of training data for this study and its similarity with ImageNet data. In conjunction with the fully connected layer, the highest accuracy was achieved (95%). To enhance the performance further, the last convolution layer and the classifier were fine-tuned, which resulted in a 2% increase in accuracy (97%). This shows that the learning time can be reduced by transfer learning and fine-tuning while maintaining a high screening accuracy."
MI 센서기반의 금속탐지용 뉴럴네트워크 성능비교에 관한연구,2021,"['합성곱신경망', '딥러닝', '전자기유도', '자기임피던스센서', '순환신경망', 'CNN', 'Deep Learning', 'Electromagnetic Induction', 'MI sensor', 'RNN']",,"This paper is a study on the efficiency of the filtering method of signal processing and the metal detection method using deep learning for data obtained from multiple MI sensors. The MI sensor is a principle that detects changes in magnetic field and is a passive sensor that detects metal objects. However, when detecting a metal object, the amount of change in the magnetic field caused by the metal is small, so there is a limit to the detectable distance. In order to effectively detect and analyze this, a method using deep learning was applied. In addition, the performance of the deep learning model was compared and analyzed using the filtering method of signal processing. In this paper, the detection performance of CNN and RNN networks was compared and analyzed from the data extracted from the self-impedance sensor. The RNN model showed higher performance than the CNN model. However, in the shallow stage, the CNN model showed higher performance than the RNN model."
ResNet을 이용한 도로 네트워크 교통 데이터 예측,2021,"['합성곱 신경망', '잔차 학습', '전이 학습', '교통 속도 예측', 'Convolutional Neural Network', 'Residual Learning', 'ResNet', 'Transfer Learning', 'Traffic Speed Prediction']",,
An Evaluation Method for Generalization Errors of CNN using Training Data,2021,"['합성곱 신경망', '일반화 오류', '반응 셋', '상대적 일반화 오류', 'convolutional neural network', 'generalization error', 'response set', 'relative generalization error']",,
CNN을 활용한 새싹삼의 품질 예측 모델 개발,2021,"['합성곱신경망', '새싹삼', '품질예측', '이미지 인식', 'convolutional neural network (CNN)', 'Ginseng Sprouts', 'Quality Prediction', 'Image Recognition']",,
CNN기반의 온라인 수어통역 상담 시스템에 관한 연구,2021,"['OpenCV', '합성곱 신경망', '수어', '청각장애인', '영상처리', 'OpenCV(Open Source Computer Vision)', 'CNN(Convolutional Neural  Networks)', 'Sign Language', 'Hearing-Impaired Person', 'Image Processing']",,
딥러닝과 의미론적 영상분할을 이용한 자동차 번호판의 숫자 및 문자영역 검출,2021,"['딥러닝', '합성곱 신경망(CNN)', '의미론적 분할', '자동차 번호판', '영상분할 및 인식', 'Deep Learning', 'Convolution Neural Network(CNN)', 'Semantic Segmentation', 'License Plate', 'Image Segmentation and Recognition']","자동차 번호판 인식은 지능형 교통시스템에서 핵심적인 역할을 담당한다. 따라서 효율적으로 자동차 번호판의 숫자 및 문자영역을 검출하는 것은 매우 중요한 과정이다. 본 연구에서는 딥러닝과 의미론적 영상분할 알고리즘을 적용 하여 효과적으로 자동차 번호판의 번호영역을 검출하는 방법을 제안한다. 제안된 방법은 화소 투영과 같은 전처리과정 없이 번호판 영상에서 바로 숫자 및 문자영역을 검출하는 알고리즘이다. 번호판 영상은 도로 위에 설치된 고정 카메라로 부터 획득한 영상으로 날씨 및 조명변화 등을 모두 포함한 다양한 실제 상황에서 촬영된 것을 사용하였다. 입력 영상은 색상변화를 줄이기 위해 정규화하고 실험에 사용된 딥러닝 신경망 모델은 Vgg16, Vgg19, ResNet18 및 ResNet50이 다. 제안방법의 성능을 검토하기 위해 번호판 영상 500장으로 실험하였다. 학습을 위해 300장을 할당하였으며 테스트용 으로 200장을 사용하였다. 컴퓨터모의 실험결과 ResNet50을 사용할 때 가장 우수하였으며 95.77% 정확도를 얻었다.","License plate recognition plays a key role in intelligent transportation systems. Therefore, it is a very important process to efficiently detect the number and character areas. In this paper, we propose a method to effectively detect license plate number area by applying deep learning and semantic image segmentation algorithm. The proposed method is an algorithm that detects number and text areas directly from the license plate without preprocessing such as pixel projection. The license plate image was acquired from a fixed camera installed on the road, and was used in various real situations taking into account both weather and lighting changes. The input images was normalized to reduce the color change, and the deep learning neural networks used in the experiment were Vgg16, Vgg19, ResNet18, and ResNet50. To examine the performance of the proposed method, we experimented with 500 license plate images. 300 sheets were used for learning and 200 sheets were used for testing. As a result of computer simulation, it was the best when using ResNet50, and 95.77% accuracy was obtained."
변형 Residual Convolutional Neural Network 모델을 이용한 고효율 심전도 데이터 분석 기법,2021,"['MIT-BIH arrhythmia 데이터베이스', 'ResNet', 'ResNeXt', 'Adabound', '주입기법']",,
CNN 잡음감쇠기에서 필터 수의 최적화,2021,"['잡음 감쇠', '심층 학습', '합성곱 신경망', '오차 역전파', '평균 제곱 오차', '평균 절대값 오차', 'Noise Attenuation', 'Deep Learning', 'CNN', 'Error Back Propagation', 'MSE', 'MAE']","본 논문은 잡음감쇠기에서 CNN(Convolutional Neural Network) 계층의 필터 수가 성능에 미치는 영향을 연구하였다 이 시스템은 적응필터 대신 신경망 예측필터를 이용하며 심층학습방법으로 잡음을 감쇠한다. 64-뉴런, 16-커널 CNN 필터와 오차 역전파 알고리즘을 이용하여 잡음이 포함된 음성신호로부터 음성을 추정한다. 본 연구에서 필터 수에 대한 잡음감쇠기의 성능을 검증하기 위하여 Keras 라이브러리를 사용한 프로그램을 작성하고 시뮬레이션을 실시하였다. 시뮬레이션 결과, 본 시스템은 필터 수가 16일 때 MSE(Mean Squared Error) 및 MAE(Mean Absolute Error) 값이 가장 작은 것으로 나타났으며 필터가 4개 일 때 성능이 가장 낮은 것을 볼 수 있다. 그리고 필터가 8개 이상이 되면 필터 수에 따라 MSE 및 MAE 값이 크게 차이나지 않는 것을 보여주었다. 이러한 결과로부터 음성신호의 주요 특징을 표현하기 위해서는 약 8개 이상의 필터를 사용해야 한다는 것을 알 수 있다.","This paper studies the effect of the number of filters in the CNN (Convolutional Neural Network) layer on the performance of a noise attenuator. Speech is estimated from a noised speech signal using a 64-neuron, 16-kernel CNN filter and an error back-propagation algorithm. In this study, in order to verify the performance of the noise attenuator with respect to the number of filters, a program using Keras library was written and simulation was performed. As a result of simulation, it can be seen that this system has the smallest MSE (Mean Squared Error) and MAE (Mean Absolute Error) values when the number of filters is 16, and the performance is the lowest when there are 4 filters. And when there are more than 8 filters, it was shown that the MSE and MAE values do not differ significantly depending on the number of filters. From these results, it can be seen that about 8 or more filters must be used to express the characteristics of the speech signal."
CNN 기반 딥러닝을 이용한 패션 아이템 분류 및 결합,2021,"['인공지능', '딥러닝', '머신러닝', '합성곱 신경망', '생성적 적대 신경망', '패션', 'Artificial Intelligence', 'Deep Learning', 'Machine Learning', 'Convolutional Neural Network', 'Generative Adversarial Network', 'Fashion']",,"In this paper, in order to implement an artificial intelligence system that can appropriately match fashion items according to the situation, a deep learning model based on convolutional neural network was designed after labeling with 10 fashion items based on fashion-MNIST. Based on the designed deep learning model, 45,000 fashion images were used as a training dataset, and 15,000 fashion images were used as a verification dataset, and deep learning was performed with a total of 15 epochs. As a result of the deep learning execution, the training data learning accuracy 96% and the verification data learning accuracy 94% were output in the accuracy evaluation of fashion item classification. In this paper, we constructed a dataset that can provide 7 types of fashion matching based on the implemented artificial intelligence fashion item classification system. The established dataset is expected to become the basis of an artificial intelligence fashion matching service that can satisfy various fashion needs of individuals in the future."
Quality control of seismic data based on convolutional neural network,2021,"['파워스펙트럼밀도', '품질관리', '심층학습', '합성곱 신경망', 'power spectral density', 'quality control', 'deep learning', 'convolutional neural network']",,"Installing more seismic stations may result in improving the capability of earthquake monitoring and shortening the time to report the occurrence of earthquakes or deliver public earthquake warnings. However, accordingly, it becomes difficult to assess the condition of seismic instrument. The goal of this study is to develop an automated method for assessing the quality of seismic data, which is based on power spectral densities (PSD) of one-hour waveform data. We collected 10,309 PSDs of broadband seismometers and 4,452 PSDs of accelerometers recorded from 2016, 2017 and 2019, and used them as the input of the convolutional neural network (CNN), a class of deep learning. Two deep CNNs for broadband seismometer and accelerometer were trained to automatically determine the condition of seismic data: normal and abnormal conditions. We find that the condition of seismic data determined by the CNNs have an accuracy of 99.9% and they can successfully determine the condition from PSDs of 15-minute waveforms. The outstanding performance of the trained models indicates that this can be a very effective tool for assessing the condition of seismic instrument."
문화재 관리를 위한 지능형 플랫폼 방안 연구,2021,"['문화재', 'IoT', '빅데이터', '심층신경망(DNN)', '합성곱신경망(CNN)', 'Cultural Property', 'IoT', 'Big Data', 'Deep Neural Network', 'Convolution Neural Network']",,"Recently, with the rapid development of IoT technology, the issue of Intelligent Platforms for managing Cultural Properties is increasing. In order to develop an Intelligent Platform for Cultural Property management, Sensors can be installed to collect and analyze internal and external state data of Cultural Properties, and predict with Big Data analysis using Artificial Intelligence algorithms. This Study proposes an external and internal intelligent integrated platform research method based on IoT technology for maintenance and safety management of Cultural Properties. In the proposed Intelligent Platform, a Deep Neural Network (DNN) learning algorithm was proposed to analyze and predict the tilt Sensor data and the Meteorological Agency data considering changes in the external environment as external data of Cultural Properties. In addition, we propose a Convolutional Neural Network (CNN) learning algorithm to analyze and predict image data for detecting pests as internal data of Cultural Properties."
YOLO V3 기반의 시각장애인을 위한 유도 블록 인식 알고리즘,2021,"['YOLO', '영상인식', '머신러닝', '합성곱 신경망', '평균 정밀도', 'Object detection', 'Machine learning', 'Convolutional neurual network', 'Mean average precision']","현재 우리나라에 설치된 유도 블록 중에서 일부는 설치 후에 관리가 미흡한 편이며 파손된 경우 보수도 잘 이루어지지 않아 시각장애인들의 보행에 부정적인 영향을 미치는 경우가 많다. 시각장애인들에게 유도 블록의 위치와 의미를 전달하는 시스템에 관한 연구가 필요한 상황이며 이를 위해서 휴대하기 편하고 스마트폰에서도 계산이 가능한 알고리즘이 요구된다. 이에 본 논문은 실시간 물체 검출이 가능하고, 준수한 FPS(frame per second)를 유지할 수 있는 YOLO를 기반으로 한 시각장애인을 위한 유도 블록 인식 알고리즘을 제안한다. 그리고 영상인식 영역의 성능을 여러 가지 수치로 비교하여 최선의 알고리즘을 선택했고 해당 알고리즘은 mAP와 YOLO-Loss, AP, Precision 등의 수치를 이용하여 성능을 평가하였다. 제안한 알고리즘은 연산량을 줄여주고 그에 따른 정확도의 하락을 방지하는 방법도 제시했다.","Currently, some of the induction blocks in the case of in Korea are poorly managed when some of the induction blocks are installed, and there is a visual impairment because neither case nor maintenance is well done. There is a need for research on a system that delivers the location and meaning of guidance blocks to visually impaired people, and an algorithm that is easy to perform and that can be calculated on a smartphone is required. Therefore, this paper proposes an induction block recognition algorithm for the visually impaired based on YOLO, which enables real-time detection and uses compliant FPS (frame per second). Then, the best algorithm was selected by comparing the performance of the image recognition area with various numbers, and the performance was evaluated using mAP, YOLO-Loss, AP, and Precision. The proposed algorithm flows the computational load and also suggests a method to prevent its degradation."
자율주행 트랙터 경로 추종을 위한 영상 기반 경계검출기술 개발,2021,"['자율주행', '농업기계', '경계 검출', '합성곱 신경망', '조향제어', 'autonomous traveling', 'agricultural machinery', 'boundary detection', 'CNN', 'steering control']",,
인공지능 기반 영어 발음 인식에 관한 연구,2021,"['인공지능', '동적 시간 워핑', '합성곱 신경망', '영어 발음', '영어 교육', 'AI', 'DTW', 'CNN', 'English Pronunciation', 'English Language Training']","최근 4차 산업혁명은 주요 선진국을 중심으로 세계의 국가들의 관심을 갖는 분야가 되고 있다. 4차 산업혁명 기술의 핵심기술인 인공지능기술은 다양한 분야에 융합하는 형태로 발전하고 있으며, 에듀테크 분야에도 많은 영향을 미치고 있으며 교육을 혁신적으로 변화하기 위해 많은 관심과 노력을 하고 있다. 본 논문은 DTW 음성인식 알고리즘을 이용하여 실험환경을 구축하고 다양한 원어민 데이터와 비원어민 데이터를 딥러닝 학습하고, CNN 알고리즘과의 비교를 통해 영어 발음의 유사도를 측정하여 비원어민이 원어민과 유사한 발음으로 교정할 수 있도록 연구한다.","Recently, the fourth industrial revolution has become an area of interest to many countries, mainly in major advanced countries. Artificial intelligence technology, the core technology of the fourth industrial revolution, is developing in a form of convergence in various fields and has a lot of influence on the edutech field to change education innovatively. This paper builds an experimental environment using the DTW speech recognition algorithm and deep learning on various native and non-native data. Furthermore, through comparisons with CNN algorithms, we study non-native speakers to correct them with similar pronunciation to native speakers by measuring the similarity of English pronunciation."
소음 신호를 이용한 딥러닝 이용 파워 드라이빙 시스템의 건전성 감시,2021,"['Convolutional Neural Network(합성곱 신경망)', 'Continuous Wavelet Transform(연속 웨이블렛 변환)', 'Power Driving System(동력 구동 시스템)']",,"The power driving system (PDS) comprises parts such as the chain, sprocket, gear, bearing, and rotating shaft. The purpose of this study is to develop a condition-monitoring device that diagnoses component defects early by using a convolutional neural network to prevent complete damage due to component defects. For this study, eight types of defects are artificially manufactured in various parts and assembled to build a PDS. A convolutional neural network is developed to classify and diagnose the eight types of defects. A feature for faults is successfully extracted, and fault classification is achieved with 90 % accuracy."
CNN을 활용한 카오스 신호 분류 검증,2021,"['Convolutional Neural Network(합성곱 신경망)', 'Lyapunov Exponent(리아푸노브 지수)', 'Recurrence Plot(리커런스 플롯)', 'Chaos(카오스)']",,"The aim of the study was to classify the chaotic time-series data with the nonlinear problem using the convolutional neural network (CNN), and to determine and verify the chaotic characteristics from a deterministic system. The classical nonlinear differential equation established by the Rossler model was used, and the chaotic characteristics were determined by the Lyapunov exponent. The chaotic properties was visualized using an unthresholded recurrence plot through the proposed procedure. A simple CNN model was developed to learn the extracted image using the proposed feature-visualization technique. As a result, the chaotic characteristics were classified with an accuracy of 99 % or more."
뇌파를 활용한 IoT기반 스마트홈 시스템 구현,2021,"['스마트홈', '사물인터넷', '뇌-컴퓨터 인터페이스', '뇌파', '딥러닝', '합성곱신경망', 'Smart Home', 'Internet of Things (IoT)', 'Brain-Computer Interface (BCI)', 'Electroencephalography (EEG)', 'Deep learning', 'Convolutional Neural Network (CNN)']",,
한 쌍의 앙상블 모델을 이용한 효율적인 골다공증 예측,2021,"['CT', 'Osteopenia', 'Osteoporosis', 'Dissimilarity loss function', 'Feature map', 'CNN', '컴퓨터 단층촬영', '골감소증', '골다공증', '비유사성 손실함수', '특징 정보']","본 논문에서는 컴퓨터 단층촬영(CT) 이미지를 이용한 합성곱 신경망(CNN)을 기반의 골감소증 및 골다공증 예측 모델을 제안한다. 기존의 CNN은 단일 CT 이미지에서 예측에 중요한 지역정보를 활용하지 못하다는 문제가 있다. 본 논문에서 이를 해결하고자 CT 이미지를 정규화하여 질감 정보가 다른 두 개의 이미지로 변환하고, 해당 이미지를 활용한 한 쌍의 신경망 네트워크를 제안한다. 동일한 구조를 가진 네트워크 각각의 신경망은 질감 정보가 다른 이미지를 입력으로 사용하고 비유사성 손실함수를 통해 다른 정보를 학습한다. 최종적으로 제안 모델은 중요한 지역정보를 포함한 단일 CT 이미지의 다양한 특징 정보를 학습하며, 이를 앙상블하여 골감소증 및 골다공증 예측 정확도를 높인다. 실험 결과를 통해 제안 모델의 정확도 77.11%를 확인할 수 있으며 Grad-CAM을 이용하여 모델이 바라보는 특징을 확인할 수 있다.","In this paper, we propose a prediction model for osteopenia and osteoporosis based on a convolutional neural network(CNN) using computed tomography(CT) images. In a single CT image, CNN had a limitation in utilizing important local features for diagnosis. So we propose a compound model which has two identical structures. As an input, two different texture images are used, which are converted from a single normalized CT image. The two networks train different information by using dissimilarity loss function. As a result, our model trains various features in a single CT image which includes important local features, then we ensemble them to improve the accuracy of predicting osteopenia and osteoporosis. In experiment results, our method shows an accuracy of 77.11% and the feature visualize of this model is confirmed by using Grad-CAM."
YOLO v3를 이용한 높은 정확도의 차량 계수 방법,2021,"['Vehicle detection(차량 검출)', 'Deep learning(딥러닝)', 'Convolutional neural network(합성곱신경망)', 'Traffic surveillance data(교통감시데이터)', 'YOLO(You Only Look Once', '욜로)']",,
임베디드 시스템에서 효율적인 차량 번호판 인식 시스템,2021,"['차량 번호판 인식', '딥러닝', '임베디드 시스템', '객체 검출', '합성곱 신경망', 'License Plate Recognition', 'Deep learning', 'Object detection', 'CNN']",,
뇌파의 중첩 분할에 기반한 CNN 앙상블 모델을 이용한 뇌전증 발작 검출,2021,"['Epileptic Seizure', 'EEG', 'CNN', 'Ensemble Model', '뇌전증 발작', '뇌파', '합성곱 신경망', '앙상블 모델']",,"As the diagnosis using encephalography(EEG) has been expanded, various studies have been actively performed for classifying EEG automatically. This paper proposes a CNN model that can effectively classify EEG signals acquired from healthy persons and patients with epilepsy. We segment the EEG signals into sub-signals with smaller dimension to augment the EEG data that is necessary to train the CNN model. Then the sub-signals are segmented again with overlap and they are used for training the CNN model. We also propose ensemble strategy in order to improve the classification accuracy. Experimental result using public Bonn dataset shows that the CNN can detect the epileptic seizure with the accuracy above 99.0%. It also shows that the ensemble method improves the accuracy of 3-class and 5-class EEG classification."
Feasibility Evaluation of Brain Tumor Magnetic Resonance Imaging Classification Using Convolutional Neural Network Model,2021,"['MRI', 'Brain tumor', 'CNN', 'VGG16', 'Artificial intelligence', '자기공명영상', '뇌종양', '합성곱신경망', '인공지능']",,
머신러닝 기반 모바일 스마트폰 자기센서를 이용한 인간행동인식,2021,"['machine learning', 'convolution neural-network', 'human activity recognition', 'magnetometer', '머신러닝', '합성곱 신경망', '인간행동인식', '자기센서']",,"As the performance of sensors embedded in mobile smart phones has improved, many studies using data collected from sensors are being conducted. In this study, using the data obtained from the 3-axis magnetic sensor mounted on the smartphone, a study on the recognition of four human activities was performed using machine learning. From the total data of the 3-axis magnetic sensor, the data was bundled into frames for 2 seconds, divided into several frames, and then supervised learning was carried out using it as an input to the convolutional neural network. The operation of the magnetic sensor depending on the direction was confirmed, and the human activity recognition for standing, sitting, walking, and jogging was verified."
Visual SLAM을 위한 Transformer 기반 6DoF 자세 추정 기법,2021,"['Transformer', 'Self-attention', 'Hybrid network', 'Monocular camera', 'Visual odometry']",,
가스터빈 연소기의 안전 운영을 위한 고속화염이미지의 기계학습기법을 활용한 연소불안정 진단,2021,"['Combustion Instability(연소불안정)', 'Confusion Matrix(오차 행렬)', 'Convolutional Neural Network(합성곱 신경망)', 'Dynamic Pressure(동압)', 'Flame Image(화염이미지)', 'Long Short Term Memory(장단기 기억)', 'Machine Learning(기계 학습)']","본 연구에서는 모델 가스터빈 연소기로부터 계측된 고속화염 이미지를 활용해 기계 학습을 수행하여 연소 불안정을 진단하였다. 기계학습에 사용된 이미지는 연소불안정이 안정영역에서 불안정 영역으로 천이되는 조건을 대상으로 초고속 카메라를 이용하여 8 kHz의 속도로 취득하였다. 연소불안정 여부를 판단하기 위하여 CNN과 CNN+LSTM의 두 가지 기계학습 모델을 개발･적용하였고, confusion matrix와 accuracy, recall, precision, F1-score 값을 활용하여 각 모델의 진단성능을 평가하였다. CNN 모델은 단일 이미지만으로 학습하기에 48.92~100%의 정확도의 일부 부정확한 분류를 수행하는 것을 확인하였고, 이에 반해 시계열 화염이미지 데이터를 활용한 CNN+LSTM 모델은 98.97~100%의 매우 정확한 분류를 수행하는 것을 확인하였다.","In this study, combustion instability has been diagnosed by performing machine learning using the flame images measured from a model gas turbine combustor. The images were acquired with an ultra-high-speed camera at the rate of 8 kHz in the transition condition of combustion instability from stable to unstable regimes. To judge the onset of combustion instability, two machine learning models of CNN and CNN+LSTM were developed and applied, and their diagnostic performances were evaluated using confusion matrix, accuracy, recall, precision and F1-score. It was confirmed that the CNN model performs partially inaccurate classification with an accuracy of 48.92~100% because it was trained and judges with only a single image, whereas the CNN+LSTM model, which uses time-series flame image data, performs very accurate classification with an accuracy of 98.97~100%."
Implementation of Speech Recognition and Flight Controller Based on Deep Learning for Control to Primary Control Surface of Aircraft,2021,"['Speech Recognition', 'CNN', 'MFCC', 'Flight Controller', 'TensorFlow', '음성 인식', '합성곱 신경망', '비행 제어장치', '텐서플로우']","본 논문에서는 음성 명령을 인식하여 비행기의 1차 조종면을 제어할 수 있는 장치를 제안한다. 음성 명령어는 19개의 명령어로 구성되며 총 2,500개의 데이터셋을 근간으로 학습 모델을 구성한다. 학습 모델은 TensorFlow 기반의 Keras 모델의 Sequential 라이브러리를 이용하여 CNN 모델로 구성되며, 학습에 사용되는 음성 파일은 MFCC 알고리즘을 이용하여 특징을 추출한다. 특징을 인식하기 위한 2단계의 Convolution layer 와 분류를 위한 Fully Connected layer는 2개의 dense 층으로 구성하였다. 검증 데이터셋의 정확도는 98.4%이며 테스트 데이터셋의 성능평가에서는 97.6%의 정확도를 보였다. 또한, 라즈베리 파이 기반의 제어장치를 설계 및 구현하여 동작이 정상적으로 이루어짐을 확인하였다. 향후, 음성인식 자동 비행 및 항공정비 분야의 가상 훈련환경으로 활용될 수 있을 것이다.","In this paper, we propose a device that can control the primary control surface of an aircraft by recognizing speech commands. The speech command consists of 19 commands, and a learning model is constructed based on a total of 2,500 datasets. The training model is composed of a CNN model using the Sequential library of the TensorFlow-based Keras model, and the speech file used for training uses the MFCC algorithm to extract features. The learning model consists of two convolution layers for feature recognition and Fully Connected Layer for classification consists of two dense layers. The accuracy of the validation dataset was 98.4%, and the performance evaluation of the test dataset showed an accuracy of 97.6%. In addition, it was confirmed that the operation was performed normally by designing and implementing a Raspberry Pi-based control device. In the future, it can be used as a virtual training environment in the field of voice recognition automatic flight and aviation maintenance."
딥러닝 기술을 이용한 캐비테이션 자동인식에 대한 연구,2021,"['Tip Vortex Cavitation(TVC', '날개 끝 보텍스 캐비테이션)', 'Cavitation Inception Speed(CIS', '캐비테이션 초생속력)', 'Convolution Neural Network(CNN', '합성곱 신경망)', 'Deep learning(딥러닝)', 'Image recognition(영상인식)']",,"The main source of underwater radiated noise of ships is cavitation generated by propeller blades. After the Cavitation Inception Speed (CIS), noise level at all frequencies increases severely. In determining the CIS, it is based on the results observed with the naked eye during the model test, however accuracy and consistency of CIS values are becoming practical issues. This study was carried out with the aim of developing a technology that can automatically recognize cavitation images using deep learning technique based on a Convolutional Neural Network (CNN). Model tests on a three-dimensional hydrofoil were conducted at a cavitation tunnel, and tip vortex cavitation was strictly observed using a high-speed camera to obtain analysis data. The results show that this technique can be used to quantitatively evaluate not only the CIS, but also the amount and rate of cavitation from recorded images."
잡음과 스펙트럼 이동에 강인한 CNN 기반 라만 분광 알고리즘,2021,"['Raman Spectroscopy', 'Convolutional Neural Network', 'Machine Learning', 'Spectral Shift Robustness', 'Noise Robustness', '라만 분광기', '합성곱 신경망', '기계학습', '스펙트럼 이동 강인성', '잡음 강인성']",,"Raman spectroscopy is an equipment that is widely used for classifying chemicals in chemical defense operations. However, the classification performance of Raman spectrum may deteriorate due to dark current noise, background noise, spectral shift by vibration of equipment, spectral shift by pressure change, etc. In this paper, we compare the classification accuracy of various machine learning algorithms including k-nearest neighbor, decision tree, linear discriminant analysis, linear support vector machine, nonlinear support vector machine, and convolutional neural network under noisy and spectral shifted conditions. Experimental results show that convolutional neural network maintains a high classification accuracy of over 95 % despite noise and spectral shift. This implies that convolutional neural network can be an ideal classification algorithm in a real combat situation where there is a lot of noise and spectral shift."
강화 학습을 이용한 덕트 청소 로봇 자율 주행 알고리듬 개발,2021,"['Air Duct(공조 덕트)', 'Autonomous Driving(자율 주행)', 'Cleaning Robot(청소 로봇)', 'Convolutional Neural Networks(합성곱 신경망)', 'Reinforcement Learning(강화 학습)', 'Support Vector Machine(서포트 벡터 머신)']",실내 공기 정화를 위해 건물에 설치된 덕트는 장기간 사용 시 내부에 먼지가 축적되며 이는 실내공기 오염 및 화재의 위험으로 정기적인 먼지 제거가 필수적이다. 기존 덕트 청소 방법은 시간 및 비용적 비효율과 청소 상태가 좋지 않아 기존 연구에서 머신 러닝을 활용해 먼지 정량적 판단 알고리듬을 제안했으나 실제 청소 로봇에 적용하기 위해서는 청소 로봇의 자율 주행이 필수적이다. 따라서 본 연구에서는 청소 로봇의 자율 주행을 위해 강화 학습을 적용하고 이를 통해 덕트 청소 로봇 알고리듬을 개발한다. 3D 가상환경에서 다양한 덕트 형상별 주행을 강화 학습하여 청소 로봇이 벽과 충돌하지 않고 최적의 경로를 탐색 가능하게 했다. 덕트 청소 로봇은 주행 시 기존 연구의 먼지 정량화 알고리듬을 토대로 먼지량을 판단한다. 본 연구에서 제시한 알고리듬을 주행 로봇에 탑재하여 검증했다. 이를 통해 강화 학습을 적용한 자율 주행과 먼지 정량화 알고리듬이 효과적으로 적용 및 주행 가능함을 확인했다.,"Dust accumulation in indoor air purification built-in ducts is inevitable. To reduce air pollution and the risk of fire, frequent dust removal is essential. However, conventional duct cleaning methods are time-and cost-extensive and cleaning results are not satisfactory. To resolve this issue, we previously suggested a quantitative dust determination algorithm using machine learning. However, as autonomous driving is equally essential, in this study, reinforcement learning is applied to autonomous driving of the cleaning robot, based on which a cleaning robot algorithm is developed. In a 3D virtual environment, reinforced (driving) training was conducted for various duct shapes. Through this process, collision with the duct wall can be avoided and the optimum route can be obtained. The dust amount is determined during drive by the duct cleaning robot which uses a previously developed dust quantification algorithm. The algorithm presented in this study is validated by installing it on the robot. It can be confirmed that reinforcement learning-based self-driving together with the previously suggested dust quantification algorithm is effective and is applicable to autonomous driving."
1D CNN과 기계 학습을 사용한 낙상 검출,2021,"['Machine Learning', 'Deep Learning', 'Fall Detection', '1D Convolutional Neural Network', '기계 학습', '심층 학습', '낙상 검출', '1차원 합성곱 신경망']",,"In this paper, fall detection using individual wearable devices for older people is considered. To design a low-cost wearable device for reliable fall detection, we present a comprehensive analysis of two representative models. One is a machine learning model composed of a decision tree, random forest, and Support Vector Machine(SVM). The other is a deep learning model relying on a one-dimensional(1D) Convolutional Neural Network(CNN). By considering data segmentation, preprocessing, and feature extraction methods applied to the input data, we also evaluate the considered models’ validity. Simulation results verify the efficacy of the deep learning model showing improved overall performance."
CAM 기반의 계층적 및 수평적 분류 모델을 결합한 운전자 부주의 검출 및 특징 영역 지역화,2021,"['Distracted Driver Detection', 'Convolutional Neural Networks', 'Class Activation Maps', 'Attention Area Localization', '운전자 부주의 검출', '합성곱신경망', 'CAM', 'Class Activation Map', '주의영역 지역화']",,"Driver negligence accounts for the largest proportion of the causes of traffic accidents, and research to detect them is continuously being conducted. This paper proposes a method to accurately detect a distracted driver and localize the most characteristic parts of the driver. The proposed method hierarchically constructs a CNN basic model that classifies 10 classes based on CAM in order to detect driver distration and 4 subclass models for detailed classification of classes having a confusing or common feature area in this model. The classification result output from each model can be considered as a new feature indicating the degree of matching with the CNN feature maps, and the accuracy of classification is improved by horizontally combining and learning them. In addition, by combining the heat map results reflecting the classification results of the basic and detailed classification models, the characteristic areas of attention in the image are found. The proposed method obtained an accuracy of 95.14% in an experiment using the State Farm data set, which is 2.94% higher than the 92.2%, which is the highest accuracy among the results using this data set. Also, it was confirmed by the experiment that more meaningful and accurate attention areas were found than the results of the attention area found when only the basic model was used."
딥러닝을 이용한 음향 고유 모드와 고유 주파수 예측,2021,"['Deep Learning(딥러닝)', 'Acoustic Natural Mode(음향 고유 모드)', 'Acoustic Natural Frequency(음향 고유 주파수)', 'Convolutional Neural Network(합성곱 신경망)', 'Partition(격벽)', 'Vehicle Compartment (차실)']","본 연구에서는 형상 정보만 주어지면 해당 구조물의 음향 고유 모드와 고유 주파수를 예측할 수 있는 딥러닝 기반 음향 해석 방법을 개발하고, 차실의 음향 특성 파악에 적용하여 제시한 방법의 유효성을 입증한다. 닫힌 공간의 음향 특성은 내부에 존재하는 격벽들의 형상, 크기와 위치 등에 따라 달라진다. 음향 이론이나 음향 해석 프로그램에 대한 지식이 없더라도 후보군에 있는 형상들의 음향 특성을 알 수 있다면, 자동차와 같은 기계 구조물의 재설계 시간을 설계자가 극단적으로 단축시킬 수 있다. 이를 위해, 2차원 음향 공동 모델에 대해 이 작업을 수행할 수 있는 딥러닝 모델을 제안한다. 알맞은 입력과 출력 데이터로 딥러닝 모델을 학습시켜서 가능성을 파악한 후에, 2차원 차실 모델에 적용하여 제안한 방법의 유효성을 입증한다.","In this study, a deep learning-based acoustic analysis method is proposed to predict the acoustic natural modes and natural frequencies of a structure given only its shape information. The effectiveness of the proposed method is proved by applying it to identification of the acoustic characteristics of a vehicle. The acoustic characteristics of a closed space vary depending on the shape, size, and location of the partitions existing therein. Although a designer may possess no knowledge of acoustic theory or acoustic analysis programs, the redesigning time of a mechanical structure, such as a vehicle, can be dramatically shortened if the acoustic characteristics of the candidate shape can be identified. A deep learning model is developed to perform this task on a two-dimensional acoustic cavity. It is trained with appropriate input and output data to verify the feasibility, and subsequently applied to the two-dimensional vehicle model to demonstrate its validity."
Multiple Binarization Quadtree Framework for Optimizing Deep Learning-Based Smoke Synthesis Method,2021,"['Quadtree', 'Binarization', 'Downscaling', 'Convolutional neural network', 'Super-resolution', 'Fluid simulations', '쿼드트리', '이진화', '다운스케일링', '합성곱 신경망', '초해상도', '유체 시뮬레이션']","본 논문에서는 초해상도(Super-Resolution, SR)을 계산하는데 필요한 물리 기반 시뮬레이션 데이터를 효율적으로 분류하고 분할하여 빠르게 SR연산을 가능하게 하는 쿼드트리 기반 최적화 기법을 제안한다. 제안하는 방법은 입력 데이터로 사용하는 연기 시뮬레이션 데이터를 다운스케일링(Downscaling)하여 쿼드트리 연산 소요 시간을 대폭 감소시킨다. 이 과정에서 연기의 밀도를 이진화함으로써, 다운스케일링 과정에서 밀도가 수치 손실되는 문제를 완화하며 쿼드트리를 구축한다. 학습에 사용된 데이터는 COCO 2017 데이터 셋이며, 인공신경망은 VGG19 기반 네트워크를 사용한다. 컨볼루션 계층을 거칠 때 데이터의 손실을 막기 위해 잔차(Residual) 보완 방식과 유사하게 이전 계층의 출력 값을 더해주며 학습을 진행한다. 실험결과가 연기의 경우 제안된 방법은 이전 접근법에 비해 약 15~18배 정도의 속도향상을 얻었다.","In this paper, we propose a quadtree-based optimization technique that enables fast Super-resolution(SR) computation by efficiently classifying and dividing physics-based simulation data required to calculate SR. The proposed method reduces the time required for quadtree computation by downscaling the smoke simulation data used as input data. By binarizing the density of the smoke in this process, a quadtree is constructed while mitigating the problem of numerical loss of density in the downscaling process. The data used for training is the COCO 2017 Dataset, and the artificial neural network uses a VGG19-based network. In order to prevent data loss when passing through the convolutional layer, similar to the residual method, the output value of the previous layer is added and learned. In the case of smoke, the proposed method achieved a speed improvement of about 15 to 18 times compared to the previous approach."
잡음 환경에 효과적인 마스크 기반 음성 향상을 위한 손실함수 조합에 관한 연구,2021,"['Speech enhancement', 'Mask', 'Noisy environments', 'Loss function', 'Deep neural network', '음성 향상', '마스크', '잡음 환경', '손실함수', '심층 신경망']","본 논문에서는 잡음 환경에서 효과적인 음성 인식을 위해 마스크 기반의 음성 향상 기법을 개선한다. 마스크기반의 음성 향상 기법에서는 심층 신경망을 기반으로 추정한 마스크를 잡음 오염 음성에 곱하여 향상된 음성을 얻는다. 마스크 추정 모델로 VoiceFilter(VF) 모델을 사용하고 추정된 마스크로 얻은 음성으로부터 잔여 잡음을 보다 확실히 제거하기 위해 Spectrogram Inpainting(SI)기법을 적용한다. 본 논문에서는 음성 향상 결과를 보다 개선하기 위해마스크 추정을 위한 모델 학습 과정에 사용되는 조합된 손실함수를 제안한다. 음성 구간에 남아 있는 잡음을 보다 효과적으로 제거하기 위해 잡음 오염 음성에 마스크를 적용한 Triplet 손실함수의 Positive 부분을 컴포넌트 손실함수와조합하여 사용한다. 실험 평가를 위한 잡음 음성 데이터는 TIMIT 데이터베이스와 NOISEX92, 배경음악 잡음을 다양한 Signal to Noise Ratio(SNR) 조건으로 합성하여 만들어 사용한다. 음성 향상의 성능 평가는 Source to Distortion Ratio(SDR), Perceptual Evaluation of Speech Quality(PESQ), Short-Time Objective Intelligibility(STOI)를 이용한다. 실험을 통해 평균 제곱 오차로만 훈련된 기존 시스템과 비교하여, VF 모델은 평균 제곱 오차로 훈련하고 SI 모델은 조합된 손실함수를 사용하였을 때 SDR은 평균 0.5dB, PESQ는 평균 0.06, STOI는 평균 0.002만큼 성능이 향상된것을 확인했다.","In this paper, the mask-based speech enhancement is improved for effective speech recognition in noise environments. In the mask-based speech enhancement, enhanced spectrum is obtained by multiplying the noisy speech spectrum by the mask. The VoiceFilter (VF) model is used as the mask estimation, and the Spectrogram Inpainting (SI) technique is used to remove residual noise of enhanced spectrum. In this paper, we propose a combined loss to further improve speech enhancement. In order to effectively remove the residual noise in the speech, the positive part of the Triplet loss is used with the component loss. For the experiment TIMIT database is re-constructed using NOISEX92 noise and background music samples with various Signal to Noise Ratio (SNR) conditions. Source to Distortion Ratio (SDR), Perceptual Evaluation of Speech Quality (PESQ), and Short-Time Objective Intelligibility (STOI) are used as the metrics of performance evaluation. When the VF was trained with the mean squared error and the SI model was trained with the combined loss, SDR, PESQ, and STOI were improved by 0.5, 0.06, and 0.002 respectively compared to the system trained only with the mean squared error."
Deep Learning-based Pes Planus Classification Model Using Transfer Learning,2021,"['Pes planus', 'Deep learning', 'Convolutional neural network(CNN)', 'Transfer learning', 'Data Augmentation', '편평발', '딥러닝', '합성곱 신경망', '전이학습', '데이터 증폭']","본 연구는 기존 편평발 측정을 위해 사용되던 다양한 방법의 한계를 보완할 수 있는 새로운 측정 방법으로 전이학습을 적용한 딥러닝 기반 편평발 분류 방법론을 제안한다. 편평발 88장, 정상발 88장으로 이루어진 총 176장의 이미지 데이터를 활용하여, 적은 데이터로도 우수한 예측 모델을 생성할 수 있는 데이터 증폭 기술과 사전학습 모델인 VGG16 구조를 활용하는 전이학습 기술을 적용하여 제안 모델의 학습을 진행하였다. 제안 모델의 우수성을 확인하기 위하여 기본 CNN 기반 모델과 제안 방법론의 예측 정확도를 비교하는 실험을 수행하였다. 기본 CNN 모델의 경우 훈련 정확도는 77.27%, 검증 정확도는 61.36%, 그리고 시험 정확도는 59.09%로 나타났으며, 제안모델의 경우 훈련 정확도는 94.32%, 검증 정확도는 86.36%, 그리고 시험 정확도는 84.09%로 나타나 기본 CNN 모델에 비해 제안 모델의 정확도가 큰 폭으로 향상된 것을 확인하였다.","This study proposes a deep learning-based flat foot classification methodology using transfer learning. We used a transfer learning with VGG16 pre-trained model and a data augmentation technique to generate a model with high predictive accuracy from a total of 176 image data consisting of 88 flat feet and 88 normal feet. To evaluate the performance of the proposed model, we performed an experiment comparing the prediction accuracy of the basic CNN-based model and the prediction model derived through the proposed methodology. In the case of the basic CNN model, the training accuracy was 77.27%, the validation accuracy was 61.36%, and the test accuracy was 59.09%. Meanwhile, in the case of our proposed model, the training accuracy was 94.32%, the validation accuracy was 86.36%, and the test accuracy was 84.09%, indicating that the accuracy of our model was significantly higher than that of the basic CNN model."
잡음 학생 모델 기반의 자가 학습을 활용한 음향 사건 검지,2021,[],"본 논문에서는 잡음 학생 모델 기반의 자가 학습을 활용한 음향 사건 검지 기법을 제안한다. 제안된 음향 사건 검지 모델은 두 단계로 구성된다. 첫 번째 단계에서는 잔차 합성곱 순환 신경망(Residual Convolutional Recurrent Neural Network, RCRNN)을 훈련하여 레이블이 지정되지 않은 비표기 데이터셋의 레이블 예측에 활용한다. 두 번째 단계에서는 세 가지 잡음 종류를 적용한 잡음 학생 모델을 자가학습 기법으로 반복하여 학습한다. 여기서 잡음 학생 모델은 SpecAugment, Mixup, 시간-주파수 이동을 활용한 특징 잡음, 드롭아웃을 활용한 모델 잡음, 그리고 semi-supervised loss function을 적용한 레이블 잡음을 활용하여 학습된다. 제안된 음향 사건 검지 모델의 성능은 Detection and Classification of Acoustic Scenes and Events(DCASE) 2020 Challenge Task 4의 validation set으로 평가하였다. DCASE 2020 챌린지 데이터셋의 baseline 및 최상위 랭크된 모델과 이벤트 단위 F1 점수 성능을 비교한 결과, 제안된 음향 사건 검지 모델이 단일 모델과 앙상블 모델에서 최상위 모델 대비 F1 점수를 각각 4.6 %와 3.4 % 향상시켰다.",
딥러닝 기반 특징 앙상블을 사용한 MRI 영상의 뇌종양 분류,2021,"['Artificial intelligence', 'Machine learning', 'Deep learning', 'Brain tumor classification', 'Transfer learning', 'Ensemble learning', '인공지능', '기계학습', '딥러닝', '뇌 종양 분류', '전이 학습', '앙상블 학습']",뇌 MRI 영상의 자동 분류는 뇌종양의 조기 진단을 하는 데 있어 중요한 역할을 한다. 본 연구에서 우리는 심층 특징 앙상블을 사용한 MRI 영상에서의 딥 러닝 기반 뇌종양 분류 모델을 제안한다. 우선 사전 학습된 3개의 합성 곱 신경망을 사용하여 입력 MRI 영상에 대한 심층 특징들을 추출한다. 그 이후 추출된 심층 특징들은 완전 연결 계층들로 구성된 분류 모듈의 입력 값으로 들어간다. 분류 모듈에서는 우선 3개의 서로 다른 심층 특징들 각각에 대해 먼저 완전 연결 계층을 거쳐 특징 차원을 줄인다. 그 이후 3개의 차원이 준 특징들을 결합하여 하나의 특징 벡터를 생성한 뒤 다시 완전 연결 계층의 입력값으로 들어가서 최종적인 분류 결과를 예측한다. 우리가 제안한 모델을 평가하기 위해 웹상에 공개된 뇌 MRI 데이터 셋을 사용하였다. 실험 결과 우리가 제안한 모델이 다른 기계학습 기반 모델보다 더 좋은 성능을 나타냄을 확인하였다.,"Automatic classification of brain MRI images play an important role in early diagnosis of brain tumors. In this work, we present a deep learning-based brain tumor classification model in MRI images using ensemble of deep features. In our proposed framework, three different deep features from brain MR image are extracted using three different pre-trained models. After that, the extracted deep features are fed to the classification module. In the classification module, the three different deep features are first fed into the fully-connected layers individually to reduce the dimension of the features. After that, the output features from the fully-connected layers are concatenated and fed into the fully-connected layer to predict the final output. To evaluate our proposed model, we use openly accessible brain MRI dataset from web. Experimental results show that our proposed model outperforms other machine learning-based models."
연구단보: 얼굴 표정을 이용한 비접촉식 거짓말 탐지 시스템 개발 및 유의시점 분석,2021,"['Forensic investigation', 'Deep-learning', 'Deception detection', 'Face landmark', 'Convolutional neural network', 'Long short term memory']","본 연구는 기존의 접촉식 거짓말 탐지의 단점을 해결하기 위하여 비접촉식 거짓말 탐지 기법을 개발하고자 얼굴 표정 변화를 촬영하고 분석하였다. 거짓말 탐지를 위한 영상 데이터 얻고자 모의범죄 실험을 진행하였으며, 긴장정점검사(POT)을 이용하여 데이터를 수집하였다. 거짓말을 할 때의 표정 분석을 위해 합성곱 신경망(CNN) 계열의 stacked hourglass 네트워크 4층을 쌓은 모델을 이용하여 얼굴에서 특징점을 추출하였다. 영상에서 프레임 단위로 추출한 66개의 특징점을 시간 순으로 배치하여 장단기메모리(LSTM) 모델을 이용하여 거짓말 영상과 진실 영상을 분류하는 모델을 개발하였으며, 모델 학습을 진행하고 이를토대로 평가 데이터를 통한 분류 정확도는 85.19%이었다. 학습이 완료된 모델의 결과를 분석하기 위하여LSTM 활성도 분석을 진행하였다. 개발한 방법을 이용하여 사람의 얼굴에서의 표정 변화를 이용한 거짓말탐지의 가능성을 확인할 수 있었으며, 비접촉식 거짓말 탐지에 중요한 시점을 도출하여 추후 비접촉식 거짓말 탐지의 가능성을 확인할 수 있었다",
주기적 행동 검출을 위한 멀티스케일 U-Net,2021,"['Multi-scale U-Net', '3D CNN', 'Periodicity', 'Repetition']",,
스마트 공장의 품질예측을 위한 딥러닝 모델 적용 연구 - 플라스틱 사출공정을 중심으로,2021,"['Smart Factory', 'Plastic Injection Molding', 'Quality Prediction', 'Deep Leaning', 'DAE', 'LSTM', 'CNN']","스마트공장의 고도화된 기술들을 통해 산업 현장에서 생성되는 무수히 많은 데이터를 기반으로 공정 내에 발생하는 문제의 원인을 분석하고 탐색하는 것이 실시간으로 가능하며, 이러한 데이터를 바탕으로 효율적인 의사결정을 할 수 있게 된다. 본 연구에서는 플라스틱 사출성형 공정 내 센서들에서 생성되는 총 36개의 제조조건 데이터 학습을 통해 제품의 품질을 예측하는 것을 목표로 한다. 품질 예측을 위한 딥러닝 모델은 잡음 제거 오토인코더, 장 · 단기 기억신경망, 합성곱 신경망을 적용하였다. 학습 데이터 셋은 KAMP(Korea AI Manufacturing Platform)를 통해 수집하였고 모두 양품과 불량품에 대한 레이블링이 되어있다. 각 모델별 파라미터를 달리하여 성능을 평가하였으며, 각 모델을 비교 · 분석하여 좋은 성능을 내는 모델과 파라미터 셋을 혼동행렬 및 f1-score를 활용하여 성능을 평가하였다. 본 연구에서 제안한 딥러닝 모델에 기반을 둔 사출공장 품질예측 시스템은 사출기계로부터 실시간 취합되는 센서 데이터 셋을 이용하여 공정조건 변화에 따른 품질을 예측하게 함으로써 품질 신뢰도를 향상하고 공정 품질검사 투입인력을 절감할 수 있을 것으로 기대한다.","When it comes to smart factories technology, the analysis, and exploration of the causes of problems in the processes can be made in real-time, based on the myriad data gathered from manufacturing facilities, and efficient decisions can be made based on these data. We conducted a study to predict the quality of products through the analysis of sensor data from the plastic injection molding process. We utilized a denoising autoencoder (DAE), long-shot memory network (LSTM), and a convolutional neural network (CNN) to formulate deep learning models for quality prediction. The training data set was collected through KAMP (Korea AI Manufacturing Platform) and the information regarding defects was labeled. Performance was evaluated by different parameters for each model and compared using two measures such as the confusion matrix and f1-score. A quality prediction system based on deep learning models for an injection molding factory makes it possible to accurately predict the quality according to a change in process conditions by utilizing the sensor data set gathered from the machines. We can therefore expect an improvement in quality and reliability and a reduction of the input manpower for process quality inspection."
리튬이온 배터리 열분포 이미지를 활용한 CNN 기반 SOC 추정 연구,2021,"['Lithium-ion battery', 'Convolutional neural network', 'State-of-charge', 'Heat distribution image']",,
음성학적 과학수사 용도의 달팽이관 모사 스펙트럼을 이용하는 딥러닝에 기반한 대화자 식별 알고리즘,2021,"['Deep learning', 'Speaker identification', 'Forensic science', 'Phonetics', 'Biomimetics']","제한된 증거를 바탕으로 하는 과학수사 분야에서는 최소한의 데이터로부터 최선의 결과를 얻을 수있는 알고리즘의 개발이 필요하다. 본 연구에서는 평균 0.556초의 짧은 음성을 이용하는 화자인식 딥러닝알고리즘을 개발하였다. 개발에 사용된 달팽이관 모사 스펙트럼은 음성 신호의 기존 파형을 최대한 유지하면서 인간이 청각 신호를 받아드리는 전처리 과정을 모사하여 딥러닝 네트워크가 분류에 집중하여 학습할수 있도록 하였다. 그 결과, 2차원 합성곱 신경망에 71명의 화자 중 1명의 음성을 무작위로 제시하였을 때교차검증 평균 정확도 96.2%로 1명의 화자를 식별하였다. 본 연구에서 수집한 데이터베이스는 거짓말탐지자극검사를 활용하여 추후 거짓말 탐지 연구에도 활용할 수 있을 뿐 아니라, 개발한 알고리즘은 전과자 데이터베이스를 활용하여 용의자를 특정하는 데에 활용할 수 있을 것으로 기대된다.",
밝기정보와 색상정보에 의해 분할된 병변을 이용한 심층학습 기반 피부질환 판별시스템 개발,2021,"['피부질환 판별', '흑색종', '병변분할', '밝기정보', '색상정보', '심층학습', 'Skin disease discrimination', 'Melanoma', 'Lesion segmentation', 'Brightness information', 'Color information', 'Deep learning']","본 논문에서는 RGB 색상의 피부질환 영상으로부터 밝기와 색상 정보로 병변을 분할한 후 심층학습으로 질환을 판별하는 시스템을 개발한다. 여기서 밝기정보의 이용은 병변분할에서 색상정보만을 이용할 때 밝기 변화로 영상의 고유색상이 쉽게 변하는 제약을 해결하기 위함이다. 심층학습으로 병변을 분류하는 것은 복잡하고 비선형적인 속성을 가진 피부질환을 좀 더 정확하게 판별하기 위함이다. 영상의 밝기정보를 획득하기 위해 256단계의 픽셀 값을 가지는 Gray 모델을 이용하며, 색상정보는 영상 획득 시 밝기변화에 둔감한 HSV 모델에서 색조(Hue)와 채도(Saturation)를 동시에 이용한다. 질환판별을 위한 심층학습 모델로 합성곱신경망을 이용한다. 제안된 기법의 성능을 확인하기 위하여 94개(비흑색종 : 39, 흑색종 : 55개) 임의크기의 흑색종 DermQuest 영상을 대상으로 실험한 결과, 제안방법은 정밀도, 재현율, F1-score, 그리고 정확도의 지표에서 우수한 성능이 있음을 알 수 있다. 또한 원 영상을 이용하는 방법에 비해 우수한 판별성능도 있음을 확인하였다.","In this paper, we develop a system for discriminating diseases through deep learning after segmenting lesions by brightness and color information from skin disease images in RGB colors. The use of brightness information is to solve the limitation that the intrinsic color of the image easily changes according to the change in brightness when only color information is used in lesion segmentation. Classifying lesions by deep learning is to more accurately discriminate the skin diseases with complex and nonlinear properties. In order to obtain the brightness information of an image, gray model having 256 levels of pixel values is used. For the color information, hue and saturation are simultaneously used in an HSV model that is insensitive to changes in brightness during image acquisition. In addition, a convolutional neural network is used as a deep learning model for disease discrimination. In order to confirm the performance of the proposed technique, as a result of experimenting with 94 (non-melanoma: 39, melanoma: 55) melanoma DermQuest images of arbitrary size, the proposed method has excellent performance in the indicators of precision, recall, F1-score, and accuracy. It is also confirmed that there is superior discrimination performance compared to the method of using the original image."
HSV 컬러 모델 및 코너 검출 알고리즘을 이용한 딥러닝 기반의 화염 감지에 관한 연구,2021,"['Artificial intelligence', 'Deep learning', 'HSV color model', 'Corner detection algorithm', 'CNN']","최근 딥러닝 기법을 이용한 이미지 분류 모델이나 객체 감지 모델이 많이 연구되고 있지만 적절한 전처리 방법을설계하지 않을 경우 성능 평가 결과 낮은 정확도를 얻을 수 있다. 따라서 본 연구에서 제안하는 효과적인 화염검출전처리 방법으로는 HSV 컬러 모델과 Harris 코너 검출 알고리즘을 적용한 이미지 전처리 방법이다. HSV 컬러 모델을 통해 화염이 존재하는 색상영역을 필터링하고, 필터링된 결과물에 대해 Harris 코너 검출 방법을 적용할 경우 화염 이미지의 거친 질감 특성 때문에 화염 주변에 집중적으로 코너가 검출되게 된다. 이러한 특성을 통해 코너가 다수발생한 영역을 관심영역으로 검출하여 딥러닝 기반의 합성곱신경망(Convolutional neural network, CNN) 모델을 통해최종적으로 화염 여부를 분류하도록 하였다. 그 결과 본 연구에서 제안한 모델의 화염 검출 결과 정확도는 97.5%정밀도는 97%로 나타났다.","Recently, many image classification or object detection models that use deep learning techniques have been studied;however, in an actual performance evaluation, flame detection using these models may achieve low accuracy. Therefore,the flame detection method proposed in this study is image pre-processing with HSV color model conversion and the Harriscorner detection algorithm. The application of the Harris corner detection method, which filters the output from the HSVcolor model, allows the corners to be detected around the flame owing to the rough texture characteristics of the flameimage. These characteristics allow for the detection of a region of interest where multiple corners occur, and finally classifythe flame status using deep learning-based convolutional neural network models. The flame detection of the proposed modelin this study showed an accuracy of 97.5% and a precision of 97%."
자기 지도 학습훈련 기반의 Noise2Void 네트워크를 이용한 PET 영상의 잡음 제거 평가 : 팬텀 실험,2021,"['합성 곱 신경망', '자기 지도 학습훈련', '영상 잡음 제거', 'Noise2Void', '양전자방출단층촬영', 'Convolutional neural network', 'Self-supervised learning training', 'Image denoising', 'Noise2Void', 'PET']",,"Positron emission tomography (PET) images is affected by acquisition time, short acquisition times results in low gamma counts leading to degradation of image quality by statistical noise. Noise2Void(N2V) is self supervised denoising model that is convolutional neural network (CNN) based deep learning. The purpose of this study is to evaluate denoising performance of N2V for PET image with a short acquisition time. The phantom was scanned as a list mode for 10 min using Biograph mCT40 of PET/CT (Siemens Healthcare, Erlangen, Germany). We compared PET images using NEMA image-quality phantom for standard acquisition time (10 min), short acquisition time (2min) and simulated PET image (S2 min). To evaluate performance of N2V, the peak signal to noise ratio (PSNR), normalized root mean square error (NRMSE), structural similarity index (SSIM) and radio-activity recovery coefficient (RC) were used. The PSNR, NRMSE and SSIM for 2 min and S2 min PET images compared to 10min PET image were 30.983, 33.936, 9.954, 7.609 and 0.916, 0.934 respectively. The RC for spheres with S2 min PET image also met European Association of Nuclear Medicine Research Ltd. (EARL) FDG PET accreditation program. We confirmed generated S2 min PET image from N2V deep learning showed improvement results compared to 2 min PET image and The PET images on visual analysis were also comparable between 10 min and S2 min PET images. In conclusion, noisy PET image by means of short acquisition time using N2V denoising network model can be improved image quality without underestimation of radioactivity."
