title,date,keywords,abstract,multilingual_abstract
공간 적응적 조건부 적대적 생성신경망을 활용한 단일 영상 내 반사 영역 제거기법,2021,"['조건부 적대적 생성신경망', '영상데이터 간 전환', '반사 영역 제거', '공간 적응적 비 정규화', 'Conditional generative adversarial network', 'Image-to-image translation', 'Reflection removal', 'Spatially adaptive de-normalization']",,
적대적 생성 신경망과 딥러닝을 이용한 교량 상판의 균열 감지,2021,"['딥러닝', '이미지 생성 모델', '균열 감지', '교량 점검', '콘크리트 교량', 'Deep learning', 'Image generative model', 'Crack detection', 'Bridge deck monitoring', 'Concrete bridge']",,
적대적 생성 신경망을 사용한 유기 행동 검출,2021,"['Abandonment Behavior Detection', 'Ganerative Advesarial Networks', 'Anomaly Detection']",,"Abandoned luggage items in public areas will be a potential threat caused by bombs or biological warfare. We present a method for real-time automatic detection of abandoned luggage in video captured by surveillance cameras. Most works for abandoned objects detection use a preliminary step to detect foreground regions or objects, and use various techniques including deep learning to distinguish between abandoned luggage items and other objects. These object detection-based methods require direct learning of characteristics of different types of objects. However, it is difficult to detect a new type of unlearned object, and there is insufficient detection of the instantaneous situation in which an object is abandoned. In order to solve these problems, we propose reconstruction-based anomaly detection to identify unusual patterns that do not conform to expected behavior such as abandoning objects. The approach is comprised of two stages - first, static object detection based on YOLOv4 and second, abandoned luggage recognition based on anomaly detection using Ganerative Advesarial Networks (GAN). We demonstrate the proposed GAN-based anomaly detection for abandonment behavior by performing experiments on Abnormal Event CCTV Video Dataset."
생성적 적대 신경망을 활용한 영상 생성 기술의 초현실주의적 기제 - 도시 풍경을 생성하는 작업 뷰포터(Viewporter)의 창작 배경을 기반으로,2021,"['초현실주의', '영상 생성 기술', '인공지능', '매체 미학', '미디어 아트', 'Surrealism', 'image generation', 'artificial intelligence', 'media aesthetics', 'media arts']","사진과 영상 매체는 인간 내면의 환영을 생생하게 묘사할 수 있다는 점에서 초현실주의적인 작업의 표현에 적극적으로 활용 되었다. 사진과 영상 기술들에 덧붙여서 최근 획기적인 횡보를 보여준 인공지능 기술, 특별히 생성적 적대 신경망(GAN) 또 한 초현실주의적 작업의 도구로써 무한한 가능성을 제공한다는 관점에서 본 연구를 진행하게 되었다. 초현실주의적 영상의 특성에 관한 문헌 연구, GAN의 기술의 분석, 나아가 이를 적용한 작업 창작을 통한 복합적인 방식으로 본 연구를 진행한다. 특별히 프리드리히 키틀러(Fredrich Kittler)의 매체 분석 방식과 유사하게 인공지능 기술의 작동 방식을 조명한다. 영상 생성 기술의 작동 방식인 데이터 학습, 알고리즘을 활용한 통계, 그리고 모델을 적용하는 세 단계에서 가지는 특성을 파편성, 가변 성, 결합성으로 정리하며 이를 초현실주의적인 표현 요소로써 발견하였다. 이러한 특성을 적용하여 도시 개발에 관한 환상과 허상이라는 주제로 본인의 인터렉티브 미디어아트 <뷰포터(Viewporter)>를 제작하였다. <뷰포터>는 GAN을 활용하여 가상 의 도시 풍경을 생성해내고 이 영상을 전망대의 망원경과 유사한 장치를 통해 관객에게 보여준다. 이 작업을 통해 사회 집단 이 가진 무의식적 욕망을 묘사하는 한편, 이를 관객이 내면화하고 향유할 수 있도록 하였다. <뷰포터> 작업을 통해 인공지능 기술이 생성한 영상이 보는 이의 무의식적인 욕망을 촉발하는 촉매제로써 작용할 수 있다는 점에서 인공지능 기술을 활용한 초현실주의적 예술이 향후 나아가야 할 방향성을 발견할 수 있었다.","Photography and film have been actively used in relation to surrealistic artworks to depict human internal desires. The author of this study uncovered the creative potential of image generation techniques, specifically a generative adversarial network (GAN), for creating surrealistic artworks in addition to the traditional imaging techniques used in photography and film, such as cameras, projection, and film editing. This study utilizes a mixed research method involving a literature review of surrealistic film and media art, an analysis on GAN techniques, and media art project development. Based on Freidrich Kittler’s analysis method for media studies, this research examines the operational methods of GAN for image generation. The study summarizes the three steps of GAN techniques (data learning, algorithmic statistics, and model application processes) as showing fragmentary, fluidity and combinatory aspects, which relates well with surrealistic expressions. Based on the findings here, the author created an interactive media art project, termed <Viewporter>, and compared a surrealistic AI technique with social phenomena pertaining to city development. <Viewporter> depicts a landscape of a non-existent city and shows this view through a device that resembles a telescope. Developing this project, the author aimed to visualize the subconscious desires of a group, which the viewer can internalize through the artwork. This study shows the future direction of surrealistic artworks using AI for image generation, which is to evoke and drive the viewer’s subconscious desires."
섬유 드레이프 이미지를 활용한 드레이프 생성 모델 구현에 관한 연구,2021,"['드레이프', '조건부 적대적 생성 신경망', '3D 시뮬레이션', 'Drape', 'Conditional Generative Adversarial Network', '3D Simulation']","드레이프는 의상의 외형을 결정하는 요인 중 하나로 섬유·패션 산업에서 매우 중요한 요소 중 하나이다. 코로나 바이러스의 영향으로 비대면 거래가 활성화되고 있는 시점에서, 드레이프값을 요구하는 업체들이 많아지고 있다. 하지만 중소기업이나 영세기업의 경우, 드레이프를 측정하는 것에 대한 시간과 비용적 부담을 느껴, 드레이프를 측정하는 데에 어려움을 겪고 있다. 따라서 본 연구는 디지털 물성을 측정하여 생성된 3D 시뮬레이션 이미지를 통해 조건부 적대적 생성 신경망을 이용하여 입력된 소재의 물성값에 대한 드레이프 이미지 생성을 목표로 하였다. 기존 보유한 736개의 디지털 물성값을 통해, 드레이프 이미지를 생성하였으며, 이를 모델 학습에 이용하였다. 이후 생성 모델을 통해 나온 이미지 샘플에 대하여 드레이프 값을 계산하였다. 실제 드레이프 실험 값과 생성 드레이프 값 비교결과, 첨두수의 오차는 0.75개였으며, 드레이프값의 평균 오차는 7.875의 오차를 보임을 확인할 수 있었다.","Drape is one of the factors that determine the shape of clothes and is one of the very important factors in the textile and fashion industry. At a time when non-face-to-face transactions are being activated due to the impact of the coronavirus, more and more companies are asking for drape value. However, in the case of small and medium-sized enterprises (SMEs), it is difficult to measure the drape, because they feel the burden of time and money for measuring the drape. Therefore, this study aimed to generate a drape image for the material property value input using a conditional adversarial neural network through 3D simulation images generated by measuring digital properties. A drape image was created through the existing 736 digital property values, and this was used for model training. Then, the drape value was calculated for the image samples obtained through the generative model. As a result of comparing the actual drape experimental value and the generated drape value, it was confirmed that the error of the peak number was 0.75, and the average error of the drape value was 7.875"
Self-Attention을 적용한 문장 임베딩으로부터 이미지 생성 연구,2021,"['자연어 처리', '이미지 생성', '적대적 신경망', 'Natural Language Processing', 'Image generation', 'Generative Adversarial Network']","사람이 어떤 문장을 보고 그 문장에 대해 이해하는 것은 문장 안에서 주요한 단어를 이미지로 연상시켜 그 문장에 대해 이해한다. 이러한 연상과정을 컴퓨터가 할 수 있도록 하는 것을 text-to-image라고 한다. 기존 딥 러닝 기반 text-to-image 모델은 Convolutional Neural Network(CNN)-Long Short Term Memory(LSTM), bi-directional LSTM을 사용하여 텍스트의 특징을 추출하고, GAN에 입력으로 하여 이미지를 생성한다. 기존 text-to-image 모델은 텍스트 특징 추출에서 기본적인 임베딩을 사용하였으며, 여러 모듈을 사용하여 이미지를 생성하므로 학습 시간이 오래 걸린다. 따라서 본 연구에서는 자연어 처리 분야에서 성능 향상을 보인 어텐션 메커니즘(Attention Mechanism)을 문장 임베딩에 사용하여 특징을 추출하고, 추출된 특징을 GAN에 입력하여 이미지를 생성하는 방법을 제안한다. 실험 결과 기존 연구에서 사용되는 모델보다 inception score가 높았으며 육안으로 판단하였을 때 입력된 문장에서 특징을 잘 표현하는 이미지를 생성하였다. 또한, 긴 문장이 입력되었을 때에도 문장을 잘 표현하는 이미지를 생성하였다.","When a person sees a sentence and understands the sentence, the person understands the sentence by reminiscent of the main word in the sentence as an image. Text-to-image is what allows computers to do this associative process. The previous deep learning-based text-to-image model extracts text features using Convolutional Neural Network (CNN)-Long Short Term Memory (LSTM) and bi-directional LSTM, and generates an image by inputting it to the GAN. The previous text-to-image model uses basic embedding in text feature extraction, and it takes a long time to train because images are generated using several modules. Therefore, in this research, we propose a method of extracting features by using the attention mechanism, which has improved performance in the natural language processing field, for sentence embedding, and generating an image by inputting the extracted features into the GAN. As a result of the experiment, the inception score was higher than that of the model used in the previous study, and when judged with the naked eye, an image that expresses the features well in the input sentence was created. In addition, even when a long sentence is input, an image that expresses the sentence well was created."
Research on WGAN models with Renyi Differential Privacy,2021,"['적대적 생성 신경망', '데이터 프라이버시', '차분 프라이버시', 'Renyi 차분 프라이버시', 'Generative Adversarial Network', 'Data privacy', 'Differential privacy', 'Renyi Differential privacy']",,
Facial Emotion Recognition Data Augmentation using Generative Adversarial Network,2021,"['적대적 생성 신경망', '데이터 증강', '얼굴 감정 인식', '이미지 간 변환', 'generative adversarial network', 'data augmentation', 'facial emotion recognition', 'image-to-image translation']",,
