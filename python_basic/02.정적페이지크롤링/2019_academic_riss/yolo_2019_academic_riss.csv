title,date,keywords,abstract,multilingual_abstract
YOLO 모델 기반 농업 환경 내 사람 인식 시스템의 예비 타당성 평가,2019,"['자율주행 트랙터', '인공지능', 'YOLO', '사람 인식']","자율 주행 트랙터는 무인화된 미래 농업의 필수 요소로써, 농작업 성능뿐만 아니라 사고 방지를 위한 다양한 기술이 요구된다. 특히, 농경지에 사람이 들어왔을 때, 자율주행 트랙터에 의한 인명 사고 방지할 수 있는 기술은 필수로 요구되는 기술이다. 한편, YOLO는 이미지 내에서 다수의 물체를 인식하는 대표적인 인공지능 모델로써, 자율주행 자동차 분야등에서 사람 인식 및 주변 환경 인식을 위해 사용되고 있다. 이에 본 연구에서는 자율주행 트랙터의 인명 사고 방지를 위한 기술로써 YOLO 모델의 활용 가능성에 대한 예비 타당성 평가를 실시하였다. 본 평가의 방법은 기존 다중 객체 인식 YOLO 모델과 사람 객체만을 인식하기 위해 수정한 YOLO 모델의 성능 비교 실험을 실시하였다. 기존 다중 객체 인식 YOLO 모델을 사용하여 농업 환경 내 사람 이미지를 인식한 결과 동물로 오인식 하는 경우가 빈번히 발생하였다. 반면, 수정된 YOLO 모델의 경우 동물로 오인식 되었던 사람에 대해서 개선된 효과를 볼 수 있었다. 하지만, 농업 환경에서의 사람 객체는 작물에 의해 신체의 일부가 가려지거나 그 자세가 다양하여 사람으로 인식하지 못하는 문제가 있었다. 이러한 문제는 추후 농업 환경에 존재하는 사람 객체 데이터 학습을 통해 개선 가능할 것으로 보인다.",다국어 초록 정보 없음
RGB 영상 및 LiDAR 포인트 클라우드 합성을 통한 YOLO 기반 실시간 객체 탐지,2019,"['RGB image', 'YOLO', 'LiDAR point cloud', 'real-time', 'object detection']","차량 스스로의 판단만으로 도로의 주행을 목표로 하는 자율주행의 구현을 위해 다양한 객체 탐지 알고리즘을 통한 실시간 주행환경 감지 연구가 활발히 진행되고 있다. 이를 위해 일반적으로 RGB 카메라를 통한 객체 탐지가 이루어지고 있지만, 주행환경 감지 성능 향상을 위해 또 다른 감지 센서와의 융합을 통한 상호보완이 이루어지고 있는 추세이다. 따라서, 본 논문에서는 객체 탐지 성능 고도화 및 실시간 감지를 위해 RGB 영상 데이터와 LiDAR 포인트 클라우드의 합성을 통한 YOLO 기반의 객체 탐지 시스템을 제안한다. 제안된 시스템의 성능평가를 위해 KITTI Benchmark Suite을 활용하였으며, 그 결과 RGB 카메라를 단독으로 활용하였을 때 보다 훨씬 우수한 객체 탐지율을 보여주었으며 이로써 낮은 미검출율을 가능하게 할 수 있음을 확인하였다.","In order to realize autonomous driving, detection studies on real-time driving environment through various object detection algorithms are actively being carried out. For this purpose, object detection is generally performed by RGB cameras. However, in order to improve the sensing performance of the driving environment, it is being complemented by fusion with other sensors. Therefore, in this paper, we propose a YOLO-based object detection system by combining RGB image data and LiDAR point cloud for object detection enhancement and real-time detection. The KITTI Benchmark Suite was used to evaluate the performance of the proposed system. As a result, the object detection rate was much better than that of the RGB camera alone, which enabled a low detection rate."
YOLO를 이용한 이미지 Blur 처리,2019,[],국문 초록 정보 없음,"In the case of blur processing, it is common to use a tool such as Photoshop to perform processing manually. However, it can be considered very efficient if the blur is processed at one time in the object detection process. Based on this point, we can use the object detection model to blur the objects during the process. The object detection is performed by using the YOLO [3] model. If such blur processing is used, it may be additionally applied to streaming data of video or image."
Two-Stream YOLO를 이용한 실시간 고양이 행동 인식,2019,[],"고양이를 기르는 가구의 증가와 함께 건강한 애묘 방법을 찾는 애묘인 또한 증가하고 있다. 본 논문에서는 고양이의 건강 상태를 모니터링하기 위해 반드시 선행되어야만 하는 고양이의 행동 정보를 딥러닝 방법론을 기반으로 인식하고자 한다. 인식을 위해 먼저, 카메라 센서를 이용하여 고양이 영상 데이터를 수집한 후, 수집된 영상에서 RGB 프레임과 optical flow 프레임 정보를 각각 수집한다. 각각의 프레임은 RGB Network 와 Flow Network 에 입력되고, 두 네트워크 결과 정보에 대하여 concatenation 을 수행한다. 연계된 특징 정보는 행동 인식 알고리즘인 Two-Stream YOLO 에 입력이 되어 고양이의 행동을 인식한다. 고양이의 행동 인식은 일곱 개의 클래스로 나누어 진행하였다. 행동 인식 실험 수행 결과 mAP와 f1-score 모두에서 0.9이상의 높은 성능을 보였으며, 실시간으로 수행이 가능함을 확인하였다.",다국어 초록 정보 없음
YOLO 기반의 시각 장애인 보행 보조 애플리케이션,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
YOLO를 활용한 자전거 도로 유지보수 지원 시스템,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
YOLO기반의 ADAS 오작동 대응방안 연구,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
NVIDIA Jetson TX1 기반의 사람 표정 판별을 위한 YOLO 모델 FPS 향상 방법,2019,"['Deep Learning', 'Embedded system. Facial expression recognition', 'TensorRT', 'YOLO']","본 이 논문에서는 NVIDIA Jetson TX1에서 YOLO v2 모델의 정확도를 유지하면서 FPS를 개선하는 방법을 제안한다. 일반적으로, 딥러닝 모델에서는 연산량을 줄여 처리 속도를 높이기 위해 파라미터들을 실수형에서 정수형으로 변환하여 정수 연산을 통해 속도를 높이거나 네트워크의 깊이를 감소시키는 방법을 사용한다. 그러나 이 방법들은 인식 정확도가 떨어질 수 있다. 이 논문에서는 YOLO v2 모델을 이용해 표정인식기를 개발하고 정확도 유지 시키기 위해 정수 연산이나 네트워크 깊이 감소를 사용하는 대신, 다음 세 가지 방법을 통해 연산량 및 메모리 소모를 줄인다. 첫 번째, 3x3 필터를 1x1 필터로 교체하여 각 Layer 당 매개 변수 수를 9 분의 1로 줄인다. 두 번째, TensorRT의 추론 가속 기능 중 CBR (Convolution-Add Bias-Relu)을 통해 연산량을 줄이고, 마지막으로 TensorRT를 사용하여 반복되는 동일한 연산구조를 가진 레이어를 통합하여 메모리 소비를 줄인다. 시뮬레이션 결과, 기존 YOLO v2 모델에 비해 정확도는 1 % 감소했지만 FPS는 기존 3.9 FPS에서 11 FPS로 282%의 속도 향상을 보였다.","In this paper, we propose a novel method to improve FPS while maintaining the accuracy of YOLO v2 model in NVIDIA Jetson TX1. In general, in order to reduce the amount of computation, a conversion to an integer operation or  reducing the depth of a network have been used. However, the accuracy of recognition can be deteriorated. So, we use methods to reduce computation and memory consumption through adjustment of the filter size and integrated computation of the network The first method is to replace the 3x3 filter with a 1x1 filter, which reduces the number of parameters to one-ninth. The second method is to reduce the amount of computation through CBR (Convolution-Add Bias-Relu) among the inference acceleration functions of TensorRT, and the last method is to reduce memory consumption by integrating repeated layers using TensorRT. For the simulation results, although the accuracy is decreased by 1% compared to the existing YOLO v2 model, the FPS has been improved from the existing 3.9 FPS to 11 FPS."
Improving Performance of YOLO Network Using Multi-layer Overlapped Windows for Detecting Correct Position of Small Dense Objects,2019,"['Multi-layer Overlapped Window', 'YOLO network', 'Small Dense Objects', 'Crossing Area', 'Small Vehicle Tracking']",국문 초록 정보 없음,"This paper proposes a new method using multi-layer overlapped windows to improve the performance of YOLO network which is vulnerable to detect small dense objects. In particular, the proposed method uses the YOLO Network based on the multi-layer overlapped windows to track small dense vehicles that approach from long distances. The method improves the detection performance for location and size of small vehicles. It allows crossing area of two multi-layer overlapped windows to track moving vehicles from a long distance to a short distance. And the YOLO network is optimized so that GPU computation time due to multi-layer overlapped windows should be reduced. The superiority of the proposed algorithm has been proved through various experiments using captured images from road surveillance cameras."
YOLO 딥러닝 기법을 이용한 드론카메라 영상 내 건물 외벽 균열 검출 시스템,2019,"['드론(Drone)', '균열(Crack)', '영상인식(Image Recognition)', '딥러닝(Deep Learning)']",국문 초록 정보 없음,다국어 초록 정보 없음
A Multi-level Threshold Method for a Solving Multi-Detection Problem in YOLO V3,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
YOLO를 활용한 실시간 교통표지 검출,2019,"['Object detection(객체 검출)', 'Real-time (실시간성)', 'Mobile robot (모바일 로봇)', 'Autonomous driving (자율주행)']",국문 초록 정보 없음,"In this work, we adopt an object detection algorithm to a TurtleBot3 which is small-sized, low-cost but well-known as a ROS (robot operating system) standard platform. This aims at the real-time detection of traffic signs in the AutoRace track where the TurtleBot3 attempts to complete missions during self-driving. As an effort for the real-time guarantee, a YOLO (you only look once) is selected as an unified object detection algorithm. In order to run this deep neural network-based algorithm in real-time, a Nvidia Jetson TX2 is employed as a single board computer in the TurtleBot3. While training the network in the YOLO, we suffer from much lower recall levels in distinguishing between left-turn and right-turn signs than others. It turns out that this stems from horizontal flipping, one of the built-in means to augment data in the YOLO. By disabling horizontal flipping, we finally obtain a recall level of over 90% across 12 classes of the traffic signs at a speed of 10fps. The achieved performance is good enough for the TurtleBot3 to follow missions in real-time."
YOLO-v3을 활용한 건설 장비 주변 위험 상황 인지 알고리즘 개발,2019,"['Deep Learning', 'Image Processing', 'Construction Safety', 'Sensor', 'Construction Equipment']","최근 정부는 건설 산업의 재해율과 사고 사망률이 전체 산업 중 높은 비율을 차지한다는 점을 개선하기 위하여 새로운 대책을 강구하고 있다. 특히 4차 산업혁명의 시대적 흐름에 맞춰 ICT 기술과 융합된 건설 기술 개발에 집중적으로 투자하고 있다. 이런 상황에 대응하고자 본 논문에서는 건설 기계를 사용하는 작업에서 작업자의 안전성 향상을 위한 방법으로, 건설 기계 운전자와 주변 작업자 간의 작업 상황 정보를 공유하고 인지할 수 있는 개념을 제시하였다. 그리고 해당 개념의 일부를 실현하고자 카메라를 이용한 인공 지능 기반 영상처리 기술을 활용하여 토공 작업에 접목시켰다. 그 중에서도 다짐 장비를 이용한 실험을 통해 YOLO-v3 기반의 영상 처리 알고리즘으로 토공 작업 중에 주변 작업자 상황을 인지하고 위험 상황 여부를 판단할 수 있는 알고리즘을 구현하였다. 그 결과 본 알고리즘은 동영상에서 초당 15.06프레임을 처리하며 90.48%의 정확도로 건설 기계 주변 위험 상황을 인지할 수 있다. 향후 이 같은 기술을 활용하여 건설 현장의 안전사고 예방에 기여하고자 한다.","Recently, the government is taking new approaches to change the fact that the accident rate and accident death rate of the construction industry account for a high percentage of the whole industry. Especially, it is investing heavily in the development of construction technology that is fused with ICT technology in line with the current trend of the 4th Industrial Revolution. In order to cope with this situation, this paper proposed a concept to recognize and share the work situation information between the construction machine driver and the surrounding worker to enhance the safety in the place where construction machines are operated. In order to realize the part of the concept, we applied image processing technology using camera based on artificial intelligence to earth-moving work. Especially, we implemented an algorithm that can recognize the surrounding worker’s circumstance and identify the risk situation through the experiment using the compaction equipment. and image processing algorithm based on YOLO-v3. This algorithm processes 15.06 frames per second in video and can recognize danger situation around construction machine with accuracy of 90.48%. We will contribute to the prevention of safety accidents at the construction site by utilizing this technology in the future."
Teat detection algorithm: YOLO vs. Haar-cascade,2019,"['Automatic milking systems', 'Haar-cascade', 'Teat detection', 'YOLO']",국문 초록 정보 없음,"In this study we have developed and experimented with two methods of teat detection based on machine learning approach in image recognition and object detection. Automatic milking systems rely strongly on the vision system for successful milking operation initiation which is the attachment of the teat cups correctly. Teat detection method currently employed in the industry is based on laser assisted edge detection mechanism, making the current systems less advanced than the existing methods in the field of image processing and robotic vision. By experimenting on a basic object detection method based on Haar-like features, viz. Haar cascade classification method and a latest state-of-the-art method based on convolutional neural nets, viz. YOLO-object detection method, we have compared the results of detection on a fake teat model casted from silicon, especially for indoor environments. This study is in extension to the successful real time detection in a cow farm using Haar-cascade based algorithm."
YOLO를 이용한 기관실에서의 화재 검출,2019,"['화재검출', '합성곱 신경망', '욜로', '기관실', 'Fire Detection', 'Convolution Neural Network', 'YOLO', 'Engine Room']",국문 초록 정보 없음,다국어 초록 정보 없음
YOLO와 라즈베리파이를 이용한 반려동물 이동식 CCTV 설계,2019,"['Pets', 'YOLO', 'Object Detection', 'Tracking', 'Monitoring']",국문 초록 정보 없음,다국어 초록 정보 없음
해상환경에서의 YOLO-V3 기법 기반 영상센서를 이용한 이동물체 인식 연구,2019,"['YOLO-V3', 'Object detection', 'Unmanned vessel', 'Marine environment']",국문 초록 정보 없음,다국어 초록 정보 없음
YOLO을 이용한 실시간 폭력 감지 시스템,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
Deep Learning 기반의 YOLO를 활용한 실시간 안전장비 착용 감지,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
A multiplier-less quantization for a high performance YOLO-v2 implementation on FPGA,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
Real Time Object Detection Based on YOLO with Feature Filter Bank,2019,"['convolutional neural network', 'real-time object detection', 'YOLO', 'feature filter bank']",국문 초록 정보 없음,"Real-time object detection is one of the most important and challenging tasks in current object detection and classification fields. Lots of research work have contributed to improving the ability of detection and classification accuracy in the last decades. Also, recent research on computer vision is prevailing to improve the accuracy of video surveillance, robotic vision, self-driving cars, and many applications. YOLO (You Only Look Once) is one of the fastest CNN (Convolutional Neural Network) and, it is one of state of the art techniques fo performing real-time object detection tasks. However, there are still some localization problems. In this paper, we propose a network with feature filter bank to improve the performance of YOLO network. Experiments have shown that the object detection performance of the proposed network is improved."
Recurrent YOLO and LSTM-based IR single pedestrian tracking,2019,"['ROLO', 'TIR-VOT', 'Recurrent YOLO', 'LSTM', 'tracking-by-detection']",국문 초록 정보 없음,다국어 초록 정보 없음
Drowsiness Preventing System using YOLO,2019,"['Drowsiness Driving', 'Deep Learning', 'Water Gun', 'YOLO']",국문 초록 정보 없음,다국어 초록 정보 없음
YOLO V3 알고리즘과 LIDAR 센서를 이용한 영상 분석 및 물체인식 기술,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
Yolo 를 이용한 교통량 측정 및 차종 인식 정확도 향상,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
인조 번호판 데이터를 활용한 YOLO v3 기반 번호판 인식 시스템 구현,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
헤드라이트 이미지 분석을 통한 YOLO 기반 차종 인식 기법,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
Training Analysis of YOLO Model for Living Room Object Recognition,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
Feature Squeezing 이 YOLO v3 모델 성능에 미치는 영향에 대한 연구,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
개인 정보 보호를 위한 YOLO 기반 신용 카드 이미지 검출 기법,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
임베디드 플랫폼 기반 자율주행을 위한 다양한 YOLO 알고리즘 성능 분석,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
드론영상을 이용한 물체탐지알고리즘 기반 도로균열탐지,2019,"['딥러닝', '도로균열', '드론', 'Tiny-YOLO-V2', 'Faster-RCNN', 'Deep Learning', 'Road Crack', 'Drone', 'Tiny-YOLO-V2', 'Faster-RCNN']","본 연구에서는 대전광역시 주요 간선도로인 유성대로를 대상으로 드론을 통해 취득한 노면영상데이터를 기반으로 물체탐지알고리즘(Object Detection algorithm) 가운데 Tiny-YOLO-V2와Faster-RCNN을 활용하여 아스팔트 도로노면의 균열을 인식, 균열유형을 구분하고 실험 결과차이를 비교하였다. 분석결과, Faster-RCNN의 mAP는 71%이고 Tiny-YOLO-V2의 mAP는 33%로 측정되었으며, 이는 1stage Detection인 YOLO계열 알고리즘보다 2Stage Detection인 Faster-RCNN 계열의 알고리즘이 도로노면의 균열을 확인하고 분리하는데 더 좋은 성능을 보인다는 것을 확인하였다. 향후, 드론과 인공지능형 균열검지시스템을 이용한 도로자산관리체계(Infrastructure Asset Management) 구축방안 마련을 통해 효율적이고 경제적인 도로 유지관리 의사결정 지원시스템 구축 및 운영 환경을 조성할 수 있을 것이라 판단된다.","This paper proposes a new methodology to recognize cracks on asphalt road surfaces using the image data obtained with drones. The target section was Yuseong-daero, the main highway of Daejeon. Furthermore, two object detection algorithms, such as Tiny-YOLO-V2 and Faster-RCNN, were used to recognize cracks on road surfaces, classify the crack types, and compare the experimental results. As a result, mean average precision of Faster-RCNN and Tiny-YOLO-V2 was 71% and 33%, respectively.The Faster-RCNN algorithm, 2Stage Detection, showed better performance in identifying and separating road surface cracks than the Yolo algorithm, 1Stage Detection. In the future, it will be possible to prepare a plan for building an infrastructure asset-management system using drones and AI crack detection systems. An efficient and economical road-maintenance decision-support system will be established and an operating environment will be produced."
딥러닝 기반의 보행자 탐지 및 경보 시스템 연구,2019,"['Pedestrian traffic accident prevention', 'CNN', 'YOLO', 'ITS', 'UTIS', '보행자 교통사고 방지', 'CNN', 'YOLO', '지능형 교통시스템 체계', 'UTIS']","보행자 교통사고의 경우 사고 발생 시 사망사고로 연결되는 위험성이 있다. 국내 지능형교통시스템(ITS)은 질 좋은 교통 인프라를 구축하고 있음에도 불구하고, 거의 교통정보 수집에만 이용되고 있어, 위험상황 발생 시 지능적인 위험 요소 분류가 이루어지지 않고 있다. 본 연구에서 제안하는 시스템의 주요 구성 요소인 CNN 기반의 보행자 탐지 분류 모델의 경우 제한적인 환경에서 설치 운영되는 것을 가정하여 임베디드 시스템 기반으로 구현되었다. 기존YOLO의 인공신경망 모델을 개선하여 My-Tiny-Model3라는 새로운 모델을 생성하였고, 20,000 번의 반복 학습 기준으로 평균 정확도 86.29%와 21.1 fps의 실시간 탐지 속도 결과를 보였다.그리고, 이러한 탐지 시스템을 기반으로 하여 ITS 체계와 연계 가능한 시스템 구현 및 프로토콜 연동 시나리오를 구성하였다. 본 연구를 통해 기존 ITS 체계와 연동하는 보행자 사고 방지시스템을 구현한다면, 새로운 인프라 구축비용을 절감하고 보행자 교통사고 발생률을 줄이는데 도움이 될 것이다. 또한, 기존의 시스템 감시인력 소요에 따른 비용 또한 줄일 수 있을 것으로 기대된다.","In the case of a pedestrian traffic accident, it has a large-scale danger directly connected by a fatal accident at the time of the accident. The domestic ITS is not used for intelligent risk classification because it is used only for collecting traffic information despite of the construction of good quality traffic infrastructure. The CNN based pedestrian detection classification model, which is a major component of the proposed system, is implemented on an embedded system assuming that it is installed and operated in a restricted environment. A new model was created by improving YOLO's artificial neural network, and the real-time detection speed result of average accuracy 86.29% and 21.1 fps was shown with 20,000 iterative learning. And we constructed a protocol interworking scenario and implementation of a system that can connect with the ITS. If a pedestrian accident prevention system connected with ITS will be implemented through this study, it will help to reduce the cost of constructing a new infrastructure and reduce the incidence of traffic accidents for pedestrians, and we can also reduce the cost for system monitoring."
혼족을 위한 도자식기 디자인에 관한 연구,2019,['1인가구(Single Households) 식생활 라이프스타일(Eating Lifestyle) 도자식기(Ceramic Tableware)'],"본 논문은 1인가구라 불리는 뉴라이프스타일의 욜로족의 또 다른 이름 혼족을 위한 혼족에 의한 커뮤니티가 시작되어 그 가치와 크기가 커지고 있는 시점에 혼족을 위한 도자식기 디자인에 관련하여 상품화에 접근할 수 있는 가능성을 다양한 디자인의 시점으로 결론을도출하고자 함이 연구의 목적이었다. 연구의 방법으로식생활 라이프스타일의 고찰의 전개 내용으로 혼족의정의, 식생활 라이프스타일의 변화에 대한 이론적 배경을 바탕으로 혼밥을 하고 있는 20.30대 30명을 대상으로 도자식기 디자인의 다양한 시점의 설문조사를 실시하고 분석하였다. 문헌조사 결과 1인가구가 증가하며식생활 라이프 사회적 변화의 크기가 커지고 있으며, 혼족의 또 다른 이름 YOLO족으로 인하여 생긴 새로운현상은 나홀로 족을 위한 식생활 라이프의 문화가 다양한 시점으로 변화하고 있음을 인지할 수 있었다. 설문의 분석결과 홈카페라는 트렌드화된 1인가구 혼족은간략한 식기를 사용하나 디자인이 가격보다 중요한 소비의 가치라는 점과 주식을 위한 식기 외에 개인적 기호의 상차림을 위한 새로운 장식효과가 큰 기능적인 도자 공예도 요구한다는 점을 알 수 있었다. 본 논문의 연구 결과 내용이 혼족을 위한 새로운 식기제작을 하고자하는 도자식기 상품 디자이너에게 혼밥족의 도자식기소비의 새로운 트렌드를 선도해 갈 수 있는 제안이 되기를 기대한다.","In this paper, it is suggested that a new community of YOLO a new lifestyle YOLO which is called “one-soul,” has been started and its value and size are getting bigger. The purpose of this study was to investigate the dietary life style as a research method and to analyze the relationship between dietary life style and the definition of tongue, The results of the literature survey showed that the number of households increased and the social change of the dietary life became bigger.Another name of the hometown was the result of YOLO group A new phenomenon is the culture of life for the Naho family Was able to recognize that changing one point As a result of the questionnaire analysis, it is found that the home café is one of the trends of the traditional culinary style. However, the design is more important than the price, and the decorative effect for decorating the culinary table It is expected that it will be a proposal to lead a new trend of consumption of porcelain tableware of Hon-Bob in commodity designer of ceramic tableware who want to make new tableware for contents of the study result of this paper"
A method based on Multi-Convolution layers Joint and Generative Adversarial Networks for Vehicle Detection,2019,"['Vehicle detection', 'non-maximum suppression', 'generative adversarial networks', 'joint feature map', 'mask occlusion']",국문 초록 정보 없음,"In order to achieve rapid and accurate detection of vehicle objects in complex traffic conditions, we propose a novel vehicle detection method. Firstly, more contextual and small-object vehicle information can be obtained by our Joint Feature Network (JFN). Secondly, our Evolved Region Proposal Network (EPRN) generates initial anchor boxes by adding an improved version of the region proposal network in this network, and at the same time filters out a large number of false vehicle boxes by soft-Non Maximum Suppression (NMS). Then, our Mask Network (MaskN) generates an example that includes the vehicle occlusion, the generator and discriminator can learn from each other in order to further improve the vehicle object detection capability. Finally, these candidate vehicle detection boxes are optimized to obtain the final vehicle detection boxes by the Fine-Tuning Network(FTN). Through the evaluation experiment on the DETRAC benchmark dataset, we find that in terms of mAP, our method exceeds Faster-RCNN by 11.15%, YOLO by 11.88%, and EB by 1.64%. Besides, our algorithm also has achieved top2 comaring with MS-CNN, YOLO-v3, RefineNet, RetinaNet, Faster-rcnn, DSSD and YOLO-v2 of vehicle category in KITTI dataset."
딥러닝 SW 기술을 이용한 임베디드형 융합 CCTV 카메라,2019,"['LPR 카메라', 'CCTV', '융합', 'Edge Base', '임베디드', '영상 분석 모듈', '딥러닝 SW 기술', 'LPR Camera', 'CCTV', 'convergence', 'Edge base', 'Embedded', 'Image Analysis Module', 'Deep Learning SW Technology']","차량 번호판 인식 카메라는 차량 번호판 내 문자와 숫자의 인식을 위하여 대상 차량의 이미지 취득을 목적으로 하는 전용 카메라를 말하며 대부분 단독 사용보다는 서버와 영상 분석 모듈과 결합된 시스템의 일부로 적용된다. 그러나 차량 번호판 인식을 위한 시스템 구축을 위해서는 취득 영상 관리 및 분석 지원을 위한 서버와 문자, 숫자의 추출 및 인식을 위한 영상 분석 모듈을 함께 구성하여야 하므로 구축을 위한 설비가 필요하고 초기 비용이 많이 든다는 문제점이 있다. 이에 본 연구에서는 카메라의 기능을 차량 번호판 인식에만 한정하지 않고 방범 기능을 함께 수행할 수 있도록 확장하고 카메라 단독으로도 두가지 기능 수행이 가능한 Edge Base의 임베디드형 융합 카메라를 개발한다. 임베디드형 융합 카메라는 선명한 영상 취득 및 빠른 데이터 전송을 위해 고해상도 4K IP 카메라를 탑재하고 오픈소스 신경망 알고리즘 기반의 다중 객체 인식을 위한 딥러닝 SW인 YOLO를 적용하여 차량 번호판 영역을 추출한 후 차량 번호판 내의 문자와 숫자를 검출하고 검출 정확도와 인식 정확도를 검증하여 CCTV 방범 기능과 차량 번호 인식 기능이 가능한지를 확인 하였다.","License plate recognition camera is dedicated device designed for acquiring images of the target vehicle for recognizing letters and numbers in a license plate.Mostly, it is used as a part of the system combined with server and image analysis module rather than as a single use. However, building a system for vehicle license plate recognition is costly because it is required to construct a facility with a server providing the management and analysis of the captured images and an image analysis module providing the extraction of numbers and characters and recognition of the vehicle’s plate. In this study, we would like to develop an embedded type convergent camera (Edge Base) which can expand the function of the camera to not only the license plate recognition but also the security CCTV function together and to perform two functions within the camera. This embedded type convergence camera equipped with a high resolution 4K IP camera for clear image acquisition and fast data transmission extracted license plate area by applying YOLO, a deep learning software for multi object recognition based on open source neural network algorithm and detected number and characters of the plate and verified the detection accuracy and recognition accuracy and confirmed that this camera can perform CCTV security function and vehicle number plate recognition function successfully."
택배화물 자동 하역장비를 위한 딥러닝 기반의 화물 인식 알 고리즘,2019,"['Unloading system', 'deep learning algorithm', 'YOLO v2', 'Masked -CRNN', '자동하역장치', '딥러닝 알고리즘', 'YOLO v2', 'Masked R-CNN']",본 논문에서는 택배화물 자동하역장치에 적합한 개선된 딥러닝 알고리즘을 제안한다. 제안된 알고리즘은 실시간객체검출에 우수한 성능을 보이는 YOLO v2모델을 기반으로 픽셀단위 택배화물의 위치까지 검출할 수 있도록 Masked R-CNN을 융합한 구조를 가진다. 제안된 알고리즘은 YOLO v2를 이용하여 객체의 영역과 분류를 수행하면서 객체 영역을Masked R-CNN의 객체분할(Instance segmentation)과정을 거쳐 택배화물의 픽셀단위 위치까지 계산할 수 있도록 하였다.제안된 알고리즘의 성능을 평가하기 위하여 실제 택배화물 차량의 적재공간과 동일한 영역에서 택배화물들을 이용하여실험하였으며 실험결과 만족할만한 성능을 보임을 확인하였다,"In this paper, an improved deep learning algorithm for automatic unloading systems is proposed. The proposed algorithm is based on the YOLO v2 model, which shows excellent performance in real-time object detection, and has a fused structure with Masked R-CNN to detect pixel position of parcel. The proposed algorithm performs object segmentation and classification using YOLO v2, and calculates the object region to the pixel position of the parcel by mask segmentation process of Instanced R-CNN.In order to evaluate the performance of the proposed algorithm, we experimented in the same area as the loading space of the actual parcel cargo vehicle and showed the excellent performance in the expiemr ental results."
딥 러닝 및 칼만 필터를 이용한 객체 추적 방법,2019,"['YOLO', 'Kalman filter', 'Object tracking', 'CNN', 'Deep learning']","딥 러닝의 대표 알고리즘에는 영상 인식에 주로 사용되는 CNN(Convolutional Neural Networks), 음성인식 및 자연어 처리에 주로 사용되는 RNN(Recurrent Neural Networks) 등이 있다. 이 중 CNN은 데이터로부터 자동으로 특징을 학습하는 알고리즘으로 특징 맵을 생성하는 필터까지 학습할 수 있어 영상 인식 분야에서 우수한 성능을 보이면서 주류를 이루게 되었다. 이후, 객체 탐지 분야에서는 CNN의 성능을 향상하고자 R-CNN 등 다양한 알고리즘이 등장하였으며, 최근에는 검출 속도 향상을 위해 YOLO(You Only Look Once), SSD(Single Shot Multi-box Detector) 등의 알고리즘이 제안되고 있다. 하지만 이러한 딥러닝 기반 탐지 네트워크는 정지 영상에서 탐지의 성공 여부를 결정하기 때문에 동영상에서의 안정적인 객체 추적 및 탐지를 위해서는 별도의 추적 기능이 필요하다. 따라서 본 논문에서는 동영상에서의 객체 추적 및 탐지 성능 향상을 위해 딥 러닝 기반 탐지 네트워크에 칼만 필터를 결합한 방법을 제안한다. 탐지 네트워크는 실시간 처리가 가능한 YOLO v2를 이용하였으며, 실험 결과 제안한 방법은 기존 YOLO v2 네트워크에 비교하여 7.7%의 IoU 성능 향상 결과를 보였고 FHD 영상에서 20 fps의 처리 속도를 보였다.",다국어 초록 정보 없음
Vehicle Manufacturer Recognition using Deep Learning and Perspective Transformation,2019,"['Vehicle Logo', 'Object detection', 'YOLO', 'Faster R-CNN', 'VMR.']",국문 초록 정보 없음,"In real world object detection is an active research topic for understanding different objects from images. There are different models presented in past and had significant results. In this paper we are presenting vehicle logo detection using previous object detection models such as You only look once (YOLO) and Faster Region-based CNN (F-RCNN). Both the front and rear view of the vehicles were used for training and testing the proposed method. Along with deep learning an image pre-processing algorithm called perspective transformation is proposed for all the test images. Using perspective transformation, the top view images were transformed into front view images. This algorithm has higher detection rate as compared to raw images. Furthermore, YOLO model has better result as compare to F-RCNN model."
딥 러닝 기반의 영상처리 기법을 이용한 겹침 돼지 분리,2019,"['Pig Monitoring', 'Occluding Pigs', 'Segmentation', 'Deep Learning', 'YOLO']",국문 초록 정보 없음,"The crowded environment of a domestic pig farm is highly vulnerable to the spread of infectious diseases such as foot-and-mouth disease, and studies have been conducted to automatically analyze behavior of pigs in a crowded pig farm through a video surveillance system using a camera. Although it is required to correctly separate occluding pigs for tracking each individual pigs, extracting the boundaries of the occluding pigs fast and accurately is a challenging issue due to the complicated occlusion patterns such as X shape and T shape. In this study, we propose a fast and accurate method to separate occluding pigs not only by exploiting the characteristics (i.e., one of the fast deep learning-based object detectors) of You Only Look Once, YOLO, but also by overcoming the limitation (i.e., the bounding box-based object detector) of YOLO with the test-time data augmentation of rotation. Experimental results with two-pigs occlusion patterns show that the proposed method can provide better accuracy and processing speed than one of the state-of-the-art widely used deep learning-based segmentation techniques such as Mask R-CNN (i.e., the performance improvement over Mask R-CNN was about 11 times, in terms of the accuracy/processing speed performance metrics)."
돼지의 빠른 자세 결정과 머리 제거를 위한영상처리 및 딥러닝 기법,2019,"['Real-Time Pig Monitoring', 'Posture Determining', 'Head Removal', 'Image Processing', 'Deep Learning', 'YOLO', '실시간 돼지 모니터링', '자세 결정', '머리 제거', '영상처리', '딥러닝', 'YOLO']",국문 초록 정보 없음,"The weight of pig is one of the main factors in determining the health and growth state of pigs, their shipment, the breeding environment, and the ration of feed, and thus measuring the pig’s weight is an important issue in productivity perspective. In order to estimate the pig’s weight by using the number of pig’s pixels from images, acquired from a Top-view camera, the posture determining and the head removal from images are necessary to measure the accurate number of pixels. In this research, we propose the fast and accurate method to determine the pig’s posture by using a fast image processing technique, find the head location by using a fast deep learning technique, and remove pig’s head by using light weighted image processing technique. First, we determine the pig’s posture by comparing the length from the center of the pig‘s body to the outline of the pig in the binary image. Then, we train the location of pig’s head, body, and hip in images using YOLO(one of the fast deep learning based object detector), and then we obtain the location of pig’s head and remove an outside area of head by using head location. Finally, we find the boundary of head and body by using Convex-hull, and we remove pig’s head. In the Experiment result, we confirmed that the pig’s posture was determined with an accuracy of 0.98 and a processing speed of 250.00fps, and the pig’s head was removed with an accuracy of 0.96 and a processing speed of 48.97fps."
스트리밍 서버를 이용한 AWS 기반의 딥러닝 플랫폼 구현과 성능 비교 실험,2019,"['AWS', 'Cloud Computing Service', 'Deep Learning', 'Streaming server', 'YOLO']","본 논문에서는 로컬 PC의 성능이 주는 영향이 적은 딥러닝 동작 구조를 구현하였다. 일반적으로, 딥러닝 모델은 많은 연산량을 가지고 있어 처리하는 PC의 성능에 영향을 많이 받는다. 본 논문에서는 이와 같은 제약 사항을 줄이기 위하여 AWS와 스트리밍 서버를 이용하여 딥러닝 동작을 구현하였다. 첫 번째, AWS에서 딥러닝 연산을 하여 로컬 PC의 성능이 떨어지더라도 딥러닝 동작이 정상적으로 작동할 수 있도록 하였다. 하지만 AWS를 통해 연산 시 입력에 대해 출력의 실시간성이 떨어진다. 두 번째, 스트리밍 서버를 이용하여 딥러닝 모델의 실시간성을 증가시킨다. 스트리밍 서버를 사용하지 않았을 경우 한 이미지씩 처리하거나 이미지를 쌓아서 동영상으로 만들어 처리하여야 하기 때문에 실시간 성이 떨어진다. 성능 비교 실험을 위한 딥러닝 모델로는 YOLO v3모델을 사용하였고, AWS의 인스턴스들 및 고성능 GPU인 GTX1080을 탑재한 로컬 PC의 성능을 비교하였다. 시뮬레이션 결과 AWS의 인스턴스인 p3 인스턴스를 사용하였을 때 한 이미지 당 테스트 시간이 0.023444초로써 고성능 GPU인 GTX1080을 탑재한 로컬 PC의 한 이미지 당 테스트 시간인 0.027099초와 유사하다는 결과를 얻었다.","In this paper, we implemented a deep learning operation structure with less influence of local PC performance. In general, the deep learning model has a large amount of computation and is heavily influenced by the performance of the processing PC. In this paper, we implemented deep learning operation using AWS and streaming server to reduce this limitation. First, deep learning operations were performed on AWS so that deep learning operation would work even if the performance of the local PC decreased. However, with AWS, the output is less real-time relative to the input when computed. Second, we use streaming server to increase the real-time of deep learning model. If the streaming server is not used, the real-time performance is poor because the images must be processed one by one or by stacking the images. We used the YOLO v3 model as a deep learning model for performance comparison experiments, and compared the performance of local PCs with instances of AWS and GTX1080, a high-performance GPU. The simulation results show that the test time per image is 0.023444 seconds when using the p3 instance of AWS, which is similar to the test time per image of 0.027099 seconds on a local PC with the high-performance GPU GTX1080."
합성곱 신경망을 이용한 선박 기관실에서의 화재 검출에 관한 연구,2019,"['Fire Detection', 'Image-based', 'Ship Engine Room', 'Convolution Neural Network', 'YOLO', '화재검출', '영상기반', '선박 기관실', '합성곱 신경망', '욜로']","화재의 초기 검출은 인명과 재화의 손실을 최소화하기 위한 중요한 요소이다. 불꽃과 연기를 신속하면서 동시에 검출해야 하며 이를 위해 영상 기반의 화재 검출에 관한 연구가 다양하게 진행되고 있다. 기존의 화재 검출은 불꽃과 연기의 특징을 추출하기 위해 여러 알고리즘을 거쳐서 화재의 검출 유무를 판단하므로 연산량이 많이 소모되었으나, 딥러닝 알고리즘인 합성곱 신경망을 이용하면 별도의 과정이 생략되므로 신속하게 검출할 수 있다. 본 논문에서는 선박 기관실에서 화재 영상을 녹화한 데이터로 실험을 수행하였다. 불꽃과 연기의 특징을 외각 상자로 추출한 후 합성곱 신경망 중 하나인 욜로(YOLO)를 이용하여 학습하고 결과를 테스트하였다. 실험 결과를 검출률, 오검출률, 정확도로 평가하였으며 불꽃은 0.994, 0.011, 0.998, 연기는 0.978, 0.021, 0.978을 나타내었고, 연산시간은 0.009s를 소모됨을 확인하였다.","Early detection of fire is an important measure for minimizing the loss of life and property damage. However, fire and smoke need to be simultaneously detected. In this context, numerous studies have been conducted on image-based fire detection. Conventional fire detection methods are compute-intensive and comprise several algorithms for extracting the flame and smoke characteristics. Hence, deep learning algorithms and convolution neural networks can be alternatively employed for fire detection. In this study, recorded image data of fire in a ship engine room were analyzed. The flame and smoke characteristics were extracted from the outer box, and the YOLO (You Only Look Once) convolutional neural network algorithm was subsequently employed for learning and testing. Experimental results were evaluated with respect to three attributes, namely detection rate, error rate, and accuracy. The respective values of detection rate, error rate, and accuracy are found to be 0.994, 0.011, and 0.998 for the flame, 0.978, 0.021, and 0.978 for the smoke, and the calculation time is found to be 0.009 s."
Stereoscopic Imaging System 및 딥러닝을 활용한 충돌 회피 알고리즘 개발,2019,"['Autonomous(자율주행)', 'Vehicle(자동차)', 'Object detection(물체 탐지)', 'Stereo-camera(스테레오 카메라)', 'Stereo-image(스테레오이미지)', 'Deep learning(딥러닝)', 'YOLO(You Only Look Once)']",국문 초록 정보 없음,"Due to the development of technology, research on autonomous vehicle driving is being actively conducted. Many people want to take autonomous driving, but the technology is unreliable and high in cost and limited use. In order to increase the reliability of autonomous driving using autonomous driving sub-devices using low-cost cameras that do not use expensive Radar or LiDAR, new technologies will be discussed. With the development of deep learning technology, an image recognition algorithm called YOLO has been developed, which shows the improvement of image recognition speed and high accuracy which is a problem of the existing image recognition. In addition, it is possible to develop an algorithm to obtain accurate position, velocity and acceleration by recognizing the object measured by YOLO using stereo image matching technology. Both technologies will enable the development of low cost autonomous driving sub-equipment using cameras."
RCNN을 활용한 복숭아 불량 검출 모델,2019,"['Payment', 'YOLO', 'AI', 'Smart farm', 'Peach defect detection']",국문 초록 정보 없음,다국어 초록 정보 없음
충동구매와 골프용품: 골프참여자의 충동구매성향 정도에 따른 과시적 소비성향 및 체면민감성의 차이,2019,"['골프참여자', '충동구매', '과시적소비성향', '체면민감성', 'Golf Participant', 'Impulse Buying Tendency', 'Conspicuous Consumption', 'Social Face Sensitivity']","[목적] 최근 욜로(Yolo), 워라밸, 탕진잼 등의 단어가 유행하며 후회없는 삶을 추구하는 사람들이 늘어나고 있다. 이는 곧 후회 없는 구매를 지향하는 사회적 분위기로 이어지며, 국내 마케팅 업계에서는 `충동구매'라는 단어에 집중하고 있다. 이에 본 연구에서는 골프참여자들의 충동구매성향 정도를 분류하고, 과시적소비성향과 체면민감성의 차이를 비교 분석하고자 한다. [방법] 편의표본추출법을 사용하여 311부의 설문지를 수집한 후 SPSS 24.0 프로그램을 통해 타당도와 신뢰도 분석을 검증하였고, 비교분석을 위하여 다변량분석(MANOVA)을 실시하였다. [결과] 골프참여자 중 고충동구매그룹이 저충동구매그룹에 비해 과시적 소비성향 중 고가격지향과 체면민감성 중 창피의식성에 높게 나타났다. [결론] 본 연구결과를 토대로 골프참여자 중 충동구매가 높은 집단은 자신의 높은 체면을 선호하며, 그로 인해 가격이 비싼 제품의 골프용품들을 선호하는 것으로 나타났다. 따라서 골프용품점에서는 매출률을 높이기 위해 소비자에게 고가격제품이 비싼 이유를 설명하고, 그에 대한 특수성을 인지시켜야 할 것으로 판단된다.","[Purpose] Recently, as the words like Yolo and Work-Life Balance have been prevalent. The domestic marketing industry focuses on the words, impulse buying. Thus, this study would classify the degree of impulse buying tendency of golf participants and conduct a comparative analysis of the difference between propensity for conspicuous consumption and decency sensitivity. [Method] 311 copies of questionnaires were collected, using the convenient sampling method, and validity and reliability analysis was verified through SPSS 24. For comparative analysis, MANOVA was conducted. [Result] High price orientation of propensity for conspicuous consumption and shame consciousness of decency sensitivity were high in the group of those with high impulse buying level as compared to the group of those with low impulse buying level, of the golf participants. [Conclusion] It turned out that of the golf participants, the group of those with high impulse buying level preferred their high decency, and accordingly, they preferred expensive golf items. Thus, it is judged that golf shops should explain to consumers why expensive goods are expensive to increase sales rate and make them understand their distinctiveness."
CycleGAN을 이용한 야간 상황 물체 검출 알고리즘,2019,"['CycleGAN', 'Data Sampling', 'Image-to-Image Translation']",국문 초록 정보 없음,"Recently, image-based object detection has made great progress with the introduction of Convolutional Neural Network (CNN). Many trials such as Region-based CNN, Fast R-CNN, and Faster R-CNN, have been proposed for achieving better performance in object detection. YOLO has showed the best performance under consideration of both accuracy and computational complexity. However, these data- driven detection methods including YOLO have the fundamental problem is that they can not guarantee the good performance without a large number of training database. In this paper, we propose a data sampling method using CycleGAN to solve this problem, which can convert styles while retaining the characteristics of a given input image. We will generate the insufficient data samples for training more robust object detection without efforts of collecting more database. We make extensive experimental results using the day-time and night-time road images and we validate the proposed method can improve the object detection accuracy of the night-time without training night-time object databases, because we converts the day-time training images into the synthesized night-time images and we train the detection model with the real day-time images and the synthesized night-time images."
비주얼 서보잉을 위한 딥러닝 기반 물체 인식 및 자세 추정,2019,"['Object Detection', 'Object Recognition', 'Deep Learning', 'Line Detection', 'Hough Transform', 'Perspective-Transform', 'Pose Estimation']",국문 초록 정보 없음,"Recently, smart factories have attracted much attention as a result of the 4th Industrial Revolution. Existing factory automation technologies are generally designed for simple repetition without using vision sensors. Even small object assemblies are still dependent on manual work. To satisfy the needs for replacing the existing system with new technology such as bin picking and visual servoing, precision and real-time application should be core. Therefore in our work we focused on the core elements by using deep learning algorithm to detect and classify the target object for real-time and analyzing the object features. We chose YOLO CNN which is capable of real-time working and combining the two tasks as mentioned above though there are lots of good deep learning algorithms such as Mask R-CNN and Fast R-CNN. Then through the line and inside features extracted from target object, we can obtain final outline and estimate object posture."
모노 카메라 영상과 딥 러닝을 이용한 차량 검출 및 거리 등급 분류에 관한 연구,2019,"['딥러닝', '객체검출', '거리추정', '단안카메라', 'Deep learning', 'Object Detection', 'Distance Estimation', 'Mono Camera']","본 연구에서는 차량에 부착된 모노 카메라와 딥 러닝을 이용하여 객체 검출 및 검출된 객체에 대한 거리정보를 바탕으로 하는 위험도 분류 시스템을 제안한다. 다양한 상황에서 기존 컴퓨터 비전 기법들보다 변화에 강인하며 검출 능력이 뛰어난 딥 러닝을 이용하여 주행 영상을 통해 주행환경 상에 있는 객체들을 검출한다. 이때 객체 검출기로는 합성 곱 신경망 네트워크를 기반으로 만들어진 YOLO v2(You Only Look Once v2)알고리즘을 이용하며, 해당 알고리즘은 사전에 ImageNet 1000 Class 데이터로 학습 된 Pre-trained model에 KITTI 데이터 셋 및 웹 포털 사이트에서 크롤링을 통해 획득한 12K개의 이미지를 이용하여 전이학습 하였다. 그리고 DB 구축 Tool을 이용하여 KITTI 데이터 셋에서 취득한 이미지와 캘리브레이션된 LiDAR 센서 데이터를 통해 검출된 객체와의 거리 정보를 취득하였다. 객체 검출기의 결과로는 Bounding Box의 이미지 내 좌표인 x,y와 Bounding Box의 이미지 내 크기인 width, height 정보가 나온다. 객체와의 거리정보를 특정 구간 단위로 분류하여 Class화 하였고, 해당 Class(거리 등급)와 객체 검출 정보인 Bounding box 정보들을 Multi-layer Perceptron을 이용하여 분류한다.","In this study, we propose a risk classification system based on distance information of object detected and objects detection using mono camera based on deep learning. It detects the objects in the driving environment through driving images by using deep learning which is robust against change and has superior detection ability than existing computer vision techniques in various situations. In this case, we use YOLO v2 (You Only Look Once v2) algorithm, which is based on a convolution neural network as an object detector. The algorithm uses a KITTI data set and a web portal The site was trained using 12K images acquired through crawling. Using the DB construction tool, we obtained the distance information between the image obtained from the KITTI dataset and the detected object through the calibrated LiDAR sensor data. The result of the object detector is x, y coordinates in the image of the bounding box, and width and height information in the image of the bounding box. Classification is made by classifying the distance information with objects in a specific section, and classification of the class (distance class) and object detection information, Bounding box information, using Multi-layer Perceptron."
알약 자동 인식을 위한 딥러닝 모델간 비교 및 검증,2019,"['Pill Classification', 'Object Detection', 'Deep Learning', 'Artificial Intelligent', 'Hospital']",국문 초록 정보 없음,"When a prescription change occurs in the hospital depending on a patient’s improvement status, pharmacists directly classify manually returned pills which are not taken by a patient. There are hundreds of kinds of pills to classify. Because it is manual, mistakes can occur and which can lead to medical accidents. In this study, we have compared YOLO, Faster R-CNN and RetinaNet to classify and detect pills. The data consisted of 10 classes and used 100 images per class. To evaluate the performance of each model, we used cross-validation. As a result, the YOLO Model had sensitivity of 91.05%, FPs/image of 0.0507. The Faster R-CNN’s sensitivity was 99.6% and FPs/image was 0.0089. The RetinaNet showed sensitivity of 98.31% and FPs/image of 0.0119. Faster RCNN showed the best performance among these three models tested. Thus, the most appropriate model for classifying pills among the three models is the Faster R-CNN with the most accurate detection and classification results and a low FP/image."
전·후처리를 이용한 딥러닝 기반의 주차여부인식,2019,"['Parking Occupation Detection', 'Multiple Thresholds Filtering', 'Voting', 'Pre-Processing', 'Deep Learning', '주차여부인식', '다중 임계치', '보우팅', '전처리', '딥러닝']","최근 주차공간의 효율적 관리를 위해서 주차유도 시스템이 점점 보급화 되고 있다. 단순히 주차할 곳을 찾기 위한 안내용으로 사용되기도 하지만, 차량 운전자가 본인의 차량이 주차된 곳을 찾기 위해서 영상처리 기술을 이용하여, 주차된 차량 찾기 서비스까지 연동되기도 한다. 따라서, 다양한 영상처리 및 패턴 인식 기술을 이용하여 주차여부인식 및 차량 번호 인식에 대한 연구가 지속되고 있다. 본 논문에서는 인식률을 높이면서, 빠르게 주차면의 주차여부인식을 할 수 있는 알고리즘을 제안한다. 주차면의 주차여부를 분석하기 위해서 전처리 부분으로 다중 임계치 병렬적용을 하였고, 보우팅 방법을 통해 객체 인식률을 높였으며, 딥러닝 기술(YOLO)을 이용한 카메라내 객체를 추출을 통하여 사람과 같은 다른 객체 추출에 의해서 발생할 수 있는 주차여부의 오류율을 줄일 수 있었다. 또한 인식률을 저하 시킬 수 있는 요인(빛, 장소)등에서도 제안한 알고리즘을 통한 높은 인식률을 얻을 수 있었다.","Recently, parking guidance systems have been increasingly popular for efficient management of parking spaces. It is often used as an insider's guide to find a place to park, but it can also be linked to a parked vehicle search service using a camera-like image processing technology to find where the driver has parked his vehicle. Therefore, researches on parking occupation recognition and licence plate recognition using various image processing and pattern recognition technologies are continuing. In this paper, we propose an algorithm that recognizes parking occupation detection quickly in addition to increase the recognition rate. In order to analyze whether the parking slot is occupied, multiple thresholds are applied in parallel as a pre-processing part. Object recognition rate is increased through the voting method. Extraction of objects in the camera use deep learning(YOLO). It was possible to reduce the error rate of possible parking. Also, we can obtain high recognition rate through the proposed algorithm even in the factors that may decrease the recognition rate (light, circulation)."
FILM: finding the location of microaneurysms on the retina,2019,['YOLO · Microaneurysm detection · Diabetes retinopathy · Object detection'],국문 초록 정보 없음,"Diabetes retinopathy (DR) is one of the leading cause of blindness among people suff ering from diabetes. It is a lesionbased disease which starts off as small red spots on the retina. These small red lesions are known as microaneurysms (MA).These microaneurysms gradually increase in size as the DR progresses, which eventually leads to blindness. Thus, DR canbe prevented at a very early stage by eliminating the retinal microaneurysms. However, elimination of MA is a two step process.The fi rst step requires detecting the presence of MA on the retina. The second step involves pinpointing the location ofMA on the retina. Even though, these two steps are interdependent, there is no model available that can perform both stepssimultaneously. Most of the models perform the fi rst step successfully, while the second step is performed by opthamologistsmanually. Hence we have proposed an object detection model that integrates the two steps by detecting (fi rst step) andpinpointing (second step) the MA on the retina simultaneously. This would help the opthamologists in directly fi nding theexact location of MA on the retina, thereby simplifying the process and eliminating any manual intervention."
드론을 활용한 공사구간 교통류 특성분석,2019,"['드론', 'VISSIM', 'YOLO V2', '공사구간', '교통류']",국문 초록 정보 없음,다국어 초록 정보 없음
인공지능을 적용한 PCB 납땜 비전검사 불량 검출 정확도 고도화,2019,"['Object detection(객체탐색)', 'YOLO(욜로)', 'Artificial Intelligence(인공지능)']",국문 초록 정보 없음,다국어 초록 정보 없음
전기차 충전기앞 불법 주차 경고 영상인식 시스템,2019,"['영상인식(Image Recognition)', 'YOLO', '불법주차(Illegal parking)', '전기차(Electric vehicle)']",국문 초록 정보 없음,다국어 초록 정보 없음
360˚ 스트리밍 영상에서의 객체 인식 연구,2019,"['360˚ 스트리밍 영상(360˚ Streaming Video)', 'YOLO', '객체인식(Object Recognition)']",국문 초록 정보 없음,다국어 초록 정보 없음
드론과 딥러닝을 활용한 도로균열탐지 및 유형분류에 관한 연구,2019,"['도로 균열', '인공지능', '드론', 'Tiny-Yolo-V2']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝을 이용한 야간 감시 열화상 카메라 개발에 관한 연구,2019,"['Thermal camera', 'Infrared', 'Deep learning', 'CNN', 'YOLO']",국문 초록 정보 없음,다국어 초록 정보 없음
실시간 인식 기반의 제품의 표시 정보 추출을 위한 모바일 어플리케이션 설계 및 구현,2019,"['실시간 인식', '제품 표시 정보 추출', 'YOLO', 'Tesseract', 'Real-time recognition', 'Extracting product’s information']","소비자는 제품을 소비할 때 여러 외적 요소를 보지만 가장 중요한 것은 제품의 기능과 성분이다. 특히, 화학품은 오남용을 방지하고자 구성 성분을 정확히 파악하는 것이 중요하며, 체계적인 관리 방법이 필요하다. 하지만 소비자들이 화학 성분을 체계적으로 관리하는 방법이 부족하며, 이를 수동으로 관리하기에는 많은 노력이 따른다. 따라서, 본 논문에서는 소비자들이 화학 성분을 체계적으로 관리하는데 활용될 수 있는 실시간 인식 기반의 제품의 표시 정보 추출 기법을 제안하고, 해당 기법의 모바일 어플리케이션 프로토타입을 설계 및 개발한다. 개발된 프로토타입은 추후 복수 개의 화학 제품들을 체계적으로 관리할 수 있도록 발전 가능하다.","Consumers see many external factors when they buy a product, but the most important thing is the function and composition of the product. In particular, it is important to accurately identify the components of chemicals in order to prevent misuse, and a systematic management method is required. However, there is a lack of a systematic way for consumers to manage chemical components, and much effort is required to manage them manually. Therefore, in this paper, we propose a method of extracting product’s information of real-time recognition based products that can be used to systematically manage chemical components, and design and develop a mobile application prototype of the method. The prototype can be developed to systematically manage multiple chemical products in the future."
영상인식 기술을 이용한 불법 주차 방지 시스템 개발,2019,"['인식(recognition)', '실시간 객체 감지(YOLO)', '라즈베리파이(Raspberry Pi)']",국문 초록 정보 없음,다국어 초록 정보 없음
Investigation of Deep Unified Pipeline Models for Multi-Object Detection in Real-time UAV Applications,2019,"['real-time object recognition', 'unified pipeline model', 'deep learning', 'yolo', 'ssd', 'UAV']",국문 초록 정보 없음,다국어 초록 정보 없음
Millennial Generation,2019,"['Millennials', 'Generation X', 'Generation Y', 'Generation Z', 'Gen Z-ers', 'Work-life balance', 'YOLO trend']",국문 초록 정보 없음,다국어 초록 정보 없음
효과적으로 기부를 받기 위한 인간형 로봇의 외형 디자인 및 행동에 관한 연구,2019,"['Humanoid', 'Service Robot', 'Robot Design', 'Donation', 'Charity Fundraising', 'HRI']",국문 초록 정보 없음,"Robot ALICE@ERICA is a service robot developed to receive donations and to provide information services. ALICE@ERICA stands for Artificial Learning Intelligence robot for Culture and Entertainment at ERICA. In order to achieve the specific purpose of receiving donations, proper appearance design, appropriate movement and good communication skills are required in terms of HRI. In this paper, we introduce three strategies for developing robots to receive donations effectively. The first is to design a robot that makes people feel intimacy, the second is to approach only one of several people as a donor, and finally the donor communicates with video contents and voice recognition. A survey was conducted on the person who showed the reaction after the robot donated money in public places. Based on the survey results, it is proved that the method presented in this study effectively contributed to fund raising. If robots can perform actions that require high level of HRI, such as donation, robots can contribute more to human society. We hope that this study contributes to the improvement of human happiness."
An IoT-Based Object Detection and Alerting System for Livestock Disease Prevention,2019,"['Faster R-CNN', 'YOLOv3', 'Object Detection', 'Livestock Disease Prevention', 'Internet of Things']",국문 초록 정보 없음,"In this paper, we implement object detection system for animal disease prevention through Faster Region-based Convolutional Neural Network (R-CNN) model and You Only Look Once (YOLO) v3 model. For object detection systems, we derive visual targets (pigs, human, trucks) and create open dataset through image collection and labeling. The open dataset is used to design the Faster R-CNN model for livestock disease detection of the object detection engine and the YOLOv3 model for farm environment detection of the object detection engine is designed using the pre-learned parameters. For the experiment, we use a webcam to capture the image of the visual target and detect the object using the designed model. The detected result is encoded for sharing. Then, the detection result is transmitted to the Internet of Things (IoT) server through the IoT client conforming to oneM2M standard. As a result, the Faster R-CNN model for animal disease detection was about 43.58%, and the YOLOv3 model for farm environment detection was about 55.17% and about 62.16%, respectively. The encoded data collected in the IoT server is decoded and sent to the registered users through the social network service (SNS) agent to implement the object detection system for the prevention of livestock diseases."
Multi-Modal 영역제안 및 CNN-SVM 기반야간 원거리 원적외선 보행자 검출,2019,"['remote pedestrian detection', 'far infrared', 'multi-scale contrast filter', 'local projection', 'CNN']",국문 초록 정보 없음,"This paper presents a novel remote infrared pedestrian detection method for night use by means of local projection-CNN.Conventional sliding window methods (HOG/ACF) or region proposal-based deep learning approaches (faster R-CNN, SSD, YOLO)either fail to detect small objects or generate many false positives. Multi-modal region proposal schemes (multi-scale contrast filters withlocal projection+ACF) are used to improve remote pedestrian detection. AlexNet-based CNN feature extraction and SVM classificationcan reduce false positives further. This paper’s experimental evaluations indicate that the proposed method can improve remote IRpedestrian detection by 16%."
진공흡착방식 기반의 벽면 이동로봇을 위한 자동 균열검출 프로세스에 관한 연구,2019,[],"본 논문은 진공을 이용한 흡착방식과 바퀴형 이동방식을 사용하는 벽면 이동로봇의 구성과 로봇 내부에서의 균열검출 및 처리 프로세스에 관한 연구이다. 임베디드 시스템에서 기계학습을 이용한 균열검출을 구현하기 위해 YOLO v3를 수정하여 구동하였으며, 검출된 균열의 영상을 저장하고 위치 정보를 추정하였다. 또한, 균열 정보를 수집하기 위해 고정 IP를 갖는 서버를 구축하고 각 기기 간의 효율적인 통신 네트워크를 구성하였다. 본 기술은 균열검출 작업뿐만 아니라 보수작업에도 활용될 수 있어, 대형 구조물과 건축물 등의 안전진단뿐만 아니라 안전성 향상에 이바지할 수 있을 것으로 예상한다.",다국어 초록 정보 없음
딥러닝을 통한 차등간격의 조향각 노드 결정에 의한 자율주행,2019,"['CNN (convolution neural network)', 'non-uniform steering angle intervals', 'autonomous driving', 'deep learning']",국문 초록 정보 없음,"In this work, an autonomous driving model using only one camera was implemented by combining a CNN (ConvolutionalNeural networks) and a YOLO (You Only Look Once) framework. Hyper-parameters in the structure were adjusted to improve drivingperformance. Autonomous driving in a corridor was performed by applying the improved model. An appropriate dropout and deeplearning structure associated with non-uniform steering angle intervals as output is proposed. The proposed algorithm was implemented,and through experiments resulted in successful obstacle avoidance and stable driving."
벽면 이동로봇의 자동 균열검출에 적합한 기계학습 알고리즘에 관한 연구,2019,"['Wall-Climbing Robot', 'Crack Detection Algorithms', 'Machine Learning', 'Localization', '벽면 이동로봇', '균열검출 알고리즘', '기계학습', '위치추정']","본 논문은 진공을 이용한 흡착방식과 바퀴형 이동방식을 사용하는 벽면 이동로봇의 구성과 이러한 임베디드 환경에 적합하고 기계학습에 기반한 벽면 균열 자동 검출 알고리즘의 성능 비교에 관한 연구이다. 임베디드 시스템 환경에서 객체 학습을 위해 YOLO 등 최근에 시도된 학습 방법들을 적용하여 성능을 비교, 검토하였으며 기존의 에지 검출 알고리즘들과도 성능을 비교하였다. 결국, 본 연구에서는 균열검출을 잘하며 임베디드 환경에도 적합한 최적의 기계학습방법을 선택하고 기존 방법과 성능을 비교하여 우수성을 제시하였다. 또한, 검출된 균열의 영상을 저장하고 위치 정보를 추정하여 균열에 대한 정보를 관리자 기기로 전송하는 지능적인 문제해결 기능을 구축하였다.",다국어 초록 정보 없음
CNN 물체 인식 알고리즘을 이용한 협동 로봇 시스템 내 작업자 위치 추정 및 예측,2019,"['로봇 안전(Robot Safety)', '머신 비전(Machine Vision)', '협동 로봇 시스템(Collaborative Robot System)', '물체 인식(Object Detection)', '작업자 위치 추정(Human Position Monitoring)']",국문 초록 정보 없음,"More and more people and collaborative robots are sharing their workspaces. Safety issues are increasing as collaborative robots and people share workspaces. In this paper, we propose a technique that uses two fixed RGB cameras to calculating human position for safety. YOLO algorithm using Convolution Neural Network detects people through RGB cameras. The image coordinates of the detection area obtained from the algorithm can be used to calculate the human position of real world through coordinate transformation. Finally, I proposed a way to predict a person’s position even if the camera doesn’t recognize some or all of the camera."
Viewpoint Classification for the Bus-Waiting Blinds in Congested Traffic Environment,2019,"['Viewpoints classification', 'Car distribution', 'Blind people', 'Congested traffic enverionment']",국문 초록 정보 없음,"To provide an effective notification service for the blinds awaiting the bus, it is crucial to have a viewpoint classification technique in which a viewpoint is defined with tilt and panning of camera. This paper proposes a viewpoint classification method using the car distribution information in the congested traffic environment. The proposed method takes four steps for classification. First, the YOLO algorithm is used to detect the car positions in the images. Second, the car positions are normalized for feature computation. Third, nineteen simple features are extracted and finally, the viewpoint classification is conducted.The proposed method uses the information gain measure to select relevant ones from the extracted features, and uses the Random Forest algorithm as a classifier. In the experiments, the proposed method has been tested for various roadside scenarios of congested traffic in day and night. The accuracies for car detection and viewpoint classification were 79:90% and 86:00%, respectively, which are improved compared to the prior work."
Sub-Frame Analysis-based Object Detection for Real-Time Video Surveillance,2019,"['object detection', 'object tracking', 'convolutional neural network', 'real time video surveillance', 'sub-frame analysis.']",국문 초록 정보 없음,"We introduce a vision-based object detection method for real-time video surveillance system in low-end edge computing environments. Recently, the accuracy of object detection has been improved due to the performance of approaches based on deep learning algorithm such as Region Convolutional Neural Network(R-CNN) which has two stage for inferencing. On the other hand, one stage detection algorithms such as single-shot detection (SSD) and you only look once (YOLO) have been developed at the expense of some accuracy and can be used for real-time systems. However, high-performance hardware such as General-Purpose computing on Graphics Processing Unit(GPGPU) is required to still achieve excellent object detection performance and speed. To address hardware requirement that is burdensome to low-end edge computing environments, We propose subframe analysis method for the object detection. In specific, We divide a whole image frame into smaller ones then inference them on Convolutional Neural Network (CNN) based image detection network, which is much faster than conventional network designed for full frame image. We reduced its computational requirement significantly without losing throughput and object detection accuracy with the proposed method."
딥러닝을 이용한 객체 검출 알고리즘,2019,[],국문 초록 정보 없음,"Object detection is applied in various field. Autonomous driving, surveillance, OCR(optical character recognition) and aerial image etc. We will look at the algorithms that are using to object detect. These algorithms are divided into two methods. The one is R-CNN algorithms [2], [5], [6] which based on region proposal. The other is YOLO [7] and SSD [8] which are one stage object detector based on regression/classification."
호텔기업 밀레니얼 세대 공유 리더십이 팀 효능감과 조직웰빙에 미치는 영향: 팀 효능감 매개효과,2019,"['밀레니얼 세대', '공유 리더십', '팀 효능감', '조직웰빙', 'Millennials', 'Shared Leadership', 'Team Efficacy', 'Organizational Well-being']",국문 초록 정보 없음,"Team efficacy and organizational well-being of the Millennium Generation’s shared leadership, has emerged as a key force in the overall political, economic, social and cultural sector, as well as the largest new consumption humans in the global consumption market. Especially, hotel companies are rapidly changing into the growing number of Millennials and consumption patterns that place the greatest importance on their values and happiness, such as shared accommodation, shared economy, work and life Balance, cost-effectiveness, YOLO, etc. In this way, we analyze the influence of hotel companies on shared leadership as leadership that creates high performance in the environment where the complexity of the organization is increased and customer’s expectation about service quality and speed increases. The results of this study show that shared leadership has positive effects on team efficacy and organizational well-being of the Millennial generation through dynamic leadership sharing and interaction. In addition, for happiness with the Millennial generation, we identified the importance of well-being balance in organizational well-being and individual dimension and examined the effects of shared leadership indirectly on organizational well-being through team efficacy and discussed implications based on the results respectively."
Lightweight Traffic Sign Recognition Algorithm based on Cascaded CNN,2019,"['Traffic Sign Recognition', 'Lightweight', 'Cascaded CNN']",국문 초록 정보 없음,"Autonomous vehicle technology is evolving with deep learning. Traffic sign recognition informs the driver of necessary information when the driver does not recognize the traffic sign while driving or when the traffic sign information is missing from the GPS database. In this paper, we collected Traffic signs in South Korea and we proposed a light-weight traffic sign recognition (TSR) algorithm based on cascaded CNN. This algorithm is hardware-friendly and reduces the computational complexity and the number of computations compared to the previously announced YOLO v2-tiny. Our Korean traffic sign dataset was used to learn the network and verify the algorithm. Through this process, we have studied the future improvement plan to make algorithm that can be used for actual road driving."
자율주행 제어를 위한 향상된 주변환경 인식 알고리즘,2019,[],국문 초록 정보 없음,"This paper describes the improved environment recognition algorithms using some type of sensors like LiDAR and cameras. Additionally, integrated control algorithm for an autonomous vehicle is included. The integrated algorithm was based on C++ environment and supported the stability of the whole driving control algorithms. As to the improved vision algorithms, lane tracing and traffic sign recognition were mainly operated with three cameras. There are two algorithms developed for lane tracing, Improved Lane Tracing (ILT) and Histogram Extension (HIX). Two independent algorithms were combined into one algorithm - Enhanced Lane Tracing with Histogram Extension (ELIX). As for the enhanced traffic sign recognition algorithm, integrated Mutual Validation Procedure (MVP) by using three algorithms - Cascade, Reinforced DSIFT SVM and YOLO was developed. Comparing to the results for those, it is convincing that the precision of traffic sign recognition is substantially increased. With the LiDAR sensor, static and dynamic obstacle detection and obstacle avoidance algorithms were focused. Therefore, improved environment recognition algorithms, which are higher accuracy and faster processing speed than ones of the previous algorithms, were proposed. Moreover, by optimizing with integrated control algorithm, the memory issue of irregular system shutdown was prevented. Therefore, the maneuvering stability of the autonomous vehicle in severe environment were enhanced."
딥러닝 및 영상처리 기술을 활용한 콘크리트 균열 검출 방법,2019,"['콘크리트 균열', '균열 검출', '딥러닝', '영상처리', '합성곱신경망', 'Concrete Crack', 'Crack Detection', 'Deep Learning', 'Image Processing', 'CNN']","현행 균열조사 업무는 육안조사로 이루어지고 있어 점검자의 주관이 개입되어 점검 결과에 차이가 발생하거나, 측정오차가 발생할 여지가 있다. 이에 본 연구는 콘크리트 균열 조사의 객관성과 효율성을 높이기 위하여 딥러닝 네트워크 중 실시간 분석이 가능한 YOLO v.2를 활용하여 균열을 인지하고, 영상처리 기술을 활용하여 균열의 특성정보를 추출하는 프로세스를 제시하였다. 실험 결과, 실시간 분석이 가능한 검출속도와 정확도를 확보할 수 있었다. 본 연구의 결과는 시설물 하자진단 자동화 시스템 개발의 기초자료로 활용될수 있을 것이다.","Most of the current crack investigation work consists of visual inspection using simple measuring equipment such as crack scale. Thesemethods involve the subjection of the inspector, which may lead to differences in the inspection results prepared by the inspector, and maylead to a large number of measurement errors. So, this study proposes an image-based crack detection method to enhance objectivity andefficiency of concrete crack investigation. In this study, YOLOv2 was used to determine the presence of cracks in the image information toensure the speed and accuracy of detection for real-time analysis. In addition, we extracted shapes of cracks and calculated quantitatively,such as width and length using various image processing techniques. The results of this study will be used as a basis for the development ofimage-based facility defect diagnosis automation system."
항공서비스에서 Z세대의 서비스 회복에 대한 실증연구: 불평 행동 조절 효과를 중심으로,2019,"['Z세대 항공소비행동', '고객충성도', '인지된 서비스 품질', '불평 행동 성향', '서비스 회복에 대한 기대감', '서비스 회복에 대한 만족도', 'airline consumer behavior of Generation Z', 'customer loyalty', 'perceived service quality', 'complaint behavior tendency', 'service recovery expectation', 'service recovery satisfaction']",국문 초록 정보 없음,"The purpose of this study is to identify factors affecting service recovery expectations and service recovery satisfaction in the airline service industry. Also, this research is intended to investigate how the relationship varies according to individuals complaint behavior tendency. This study has several differentiation points. Firstly, the study focuses on the customer-side variables, which are customer loyalty and perceived service quality, among the leading variables influencing service recovery expectations based on the previous studies. Specifically, the degree of customer loyalty was assessed by the presence of a specific airline membership, and the degree of perceived service quality was judged by other service benefits according to the in-flight classes(business class versus economy class). The result of the pretest confirmed that the manipulations were statistically significant. Secondly, the study concentrates on airline consumers of Generation Z in order to find out their airline consumption behavior and perception. Generation Z refers to the next generation of the Millennium generation, and generally consists of people who are born from the mid-1990s to the early 2010s. As reflected in words such as YOLO or Work-Life Balance, which represents lifestyles of Generation Z, many people now travel and enjoy their leisure time to find happiness right away. In this context, the study is needed to look specifically at the airline consumption behaviors of Generation Z, and seek how airlines can respond effectively by identifying the needs of their growing consumers.  In this study, the scenario-based experiment was conducted on the Generation Z by manipulating the customer-side variables. Hypotheses were verified by the two-way ANOVA using a total of 445 responses. In detail, two - way ANOVA was conducted by the 4×2 factorial design measuring customer-side variables (divided by four different types according to customer loyalty and perceived service quality) and complaint behaviors tendency (divided by active complainers versus passive complainers).  The results showed that customer loyalty and perceived service quality did not show a statistically significant difference in service recovery expectation and service recovery satisfaction. On the other hand, the interaction effects were shown with complaint behavior tendency: Active Complainers showed higher degree of service recovery expectation and service recovery satisfaction than passive complainers even though they both had identical service failure and service recovery processes.  The implications of this study are as follows: First, customers who show complaints after service failure occurs can act as an opportunity for airlines. Second, airline service operators should seek ways to motivate customers to actively engage in complaining behaviors. Among them, it would be desirable for airlines to appropriately utilize service guarantees that provide benefits to customers who show complaint behaviors. By doing so, airline service operators are able to find out opinions of dissatisfied customers and increase their satisfaction by meeting their expectations."
Deep Learning–based Number Detection and Recognition for Gas Meter Reading,2019,"['Gas meter?reading system', 'Computer vision', 'Image processing', 'Convolutional neural network']",국문 초록 정보 없음,"The meter reading.system field has been researched from conventional methods centered on image processing technology to techniques based on learning methods such as machine learning or deep learning. The biggest problem for meter reading systems based on computer vision is difficulty in recognizing the various kinds of meters. In fact, there are more than five major manufacturers for the meters installed in Korea. There are different meter reading areas, ID regions, and number formats by version. Because of these problems, most of the meter reading is still done hands-on. In this paper, we present an automatic meter.reading system that can work simply and efficiently, compared to existing meter reading systems that need a skilled worker. Our meter reading system consists of three parts: i) detection of meter-reading and ID regions using You Only Look Once (YOLO), ii) digit segmentation for recognition, and iii) convolutional neural network (CNN)-based digit recognition. It is possible to robustly detect and recognize various meter types by using the method presented here. Therefore, it can provide an environment where gas meter checkers can work efficiently without inconvenient procedures."
저채널 3차원 라이다를 이용한 폴라뷰 기반의 객체인식 알고리즘,2019,"['autonomous vehicle', 'object detection', 'polar-view', '3D low-channel lidar']",국문 초록 정보 없음,"In order for an autonomous vehicle to move, object detection is required to recognize the surrounding environment. The sensors used for object detection mainly use a camera and lidar. However, it is difficult to detect the camera because of its influence on the surrounding environment. Therefore, object detection using lidar is required. For lidar-based object detection, we mainly use a high-channel lidar with a high resolution. However, high-channel lidar is expensive and is difficult to commercialize. To solve this problem, object detection studies using low-channel lidar are underway. In this paper, we present an algorithm to find an object (vehicle or pedestrian) using three 3D low-channel lidar systems. First, we converted the data from the lidar to the polar view. Then, we input the converted polar view into YOLO v3 to predict the class and the region of interest (ROI) of the object. We used K-means to separate the background and the object from the image in the predicted ROI to find the object except for the background. Only the object area found last was converted back into 3D space to find the location of the object."
무인항공기 영상에서의 조류 및 차량 검출을 위한 딥러닝 기반 검출 모델 개발,2019,"['딥러닝', '야생조류', '무인항공기', '항공영상', '조류인플루 엔자']","야생동물에 대한 주기적인 모니터링은 생태계의 보전과 관리, 이상 징후의 포착에 필수적이다. 특히 한국의 경우 주기적으로 발생하고 있는 조류 인플루엔자의 예찰을 위해 야생조류에 대한 효과적 예찰 시스템이 요구되는 상황이다. 야생동물에 대한 항공영상 기반의 조사는 1920년대부터 수행되었으며 다른 조사방법들 대비 지상으로 접근하기 어려운 지점에 대한 접근이 가능한 점, 넓은 범위의 영역에 대한 조사가 가능한 점 등의 장점이 있다. 하지만 유인항공기를 이용하는 기존 연구의 경우 비용 소모가 크고, 숙련된 비행사가 필요하였으며, 비행사고로 인한 위험성 또한 존재했다. 이러한 단점을 극복하기 위하여 최근 야생동물에 대한 항공 조사에 소형 무인항공기를 적용하는 연구들이 활발히 진행되고 있다. 기존의 야생 조류에 대한 항공 조사의 경우 주로 사람이 직접 영상에서 새를 검출하거나, 고전적인 영상처리 방식이 사용되었다. 하지만 이러한 고전적 영상처리 및 머신러닝 방법들은 해당 방법들이 적용된 특정 환경에서 적용되었으며, 다양한 환경에서 일관성 있게 적용되기 힘들다. 최근 영상데이터에 대한 분류, 검출 등의 분석 작업에서는 CNN(Convolutional Neural Networks) 기반의 알고리즘들이 주목받고 있으나, 현재까지 야생조류의 검출에 이를 적용하려는 사례는 많지 않다. 따라서 본 연구에서는 야생조류의 서식지를 비롯한 조류독감 방역대의 항공 조사를 위한 딥러닝 기반 야생 조류와 차량에 대한 검출 모델을 개발하고자 하였다. 모델의 학습을 위해 실제 야생조류, 모형조류, 차량에 대한 영상을 다양한 환경에서 수집하여 데이터세트를 구성하였으며, Faster R-CNN, R-FCN, Retinanet, SSD, YOLO 등의 딥러닝 검출 구조와 Resnet, Inception, Mobilenet 등의 특징 추출 네트워크를 조합하여 검출 모델을 구성하고 성능을 비교 평가하였다.",다국어 초록 정보 없음
밀레니얼세대의 노후준비에 대한 주관적 인식 연구,2019,"['retirement preparation', 'millennial generation', 'Q methodology', '노후준비', '밀레니얼세대', 'Q방법론']","노후준비가 사회적인 화두가 되면서 중⋅장년층의 노후준비 뿐 아니라 밀레니얼세대의 노후준비에 대한 관심또한 증가하고 있다. 본 연구의 목적은 Q방법론을 적용하여 밀레니얼세대의 노후준비에 대한 다양한 주관적 인식 유형을 확인하고 각 유형별 특성을 분석하는데 있다. 분석 결과, 각기 다른 특성을 가진 5개의 유형이 나타났다. 제 1유형은 ‘통합적 준비 지향형’으로 노후준비는 통합적으로 이루어져야 하는 것이라고 인식하는 유형이다. 제 2유형은 ‘YOLO 라이프 지향형’으로 노후준비에 있어 현재를 잘 살다보면 자연스럽게 노후도 잘 살 수있을 것이라고 인식하는 유형이다. 3유형은 ‘주도적 준비 중시형’으로 노후준비에 있어 주체는 자신이 되어야하며, 정부는 보충적 또는 잔여적 역할을 해주어야 한다고 인식하는 유형이다. 4유형은 ‘경제적 준비 우선형’으로 노후준비에 있어 경제적인 준비 즉, 자금마련을 우선적으로 인식하는 유형이다. 제 5유형은 ‘현재 삶 중시형’으로 노후준비에 있어 실천 불가능한 것으로 인식하여 현재의 삶에 집중해야 한다고 인식하는 유형이다.","As the retirement preparation become a social topic, there is also an increasing interest in the elderly’s preparation for retirement as well as for the retirement of the millennial generation. The purpose of this study is to identify various types of subjective perception about retirement preparation of millennial generation by applying the Q methodology and to explain the characteristics of each type. As a result of analyzing the recognition type of the millennial generation for the retirement preparation, five types with different characteristics appeared. Type1 is ‘Extensive integrated preparation’, Type2 is ‘YOLO life practice’, Type3 is ‘Preparation for each role’, Type 4 is ‘Unconditional financing funds’, Type 5 is ‘just impossible’."
