title,date,keywords,abstract,multilingual_abstract
CNN-LSTM 조합모델을 이용한 영화리뷰 감성분석,2019,"['CNN', 'LSTM', 'Deep Learning', 'Integrated Model', 'Movie Review', 'Sentiment Analysis', 'CNN', 'LSTM', '딥러닝', '조합모델', '영화리뷰', '감성분석']","인터넷 기술과 소셜 미디어의 빠른 성장으로 인하여, 구조화되지 않은 문서 표현도 다양한 응용 프로그램에사용할 수 있게 마이닝 기술이 발전되었다. 그 중 감성분석은 제품이나 서비스에 내재된 사용자의 감성을 탐지할 수 있는 분석방법이기 때문에 지난 몇 년 동안 많은 관심을 받아왔다. 감성분석에서는 주로 텍스트 데이터를이용하여 사람들의 감성을 사전 정의된 긍정 및 부정의 범주를 할당하여 분석하며, 이때 사전 정의된 레이블을이용하기 때문에 다양한 방향으로 연구가 진행되고 있다. 초기의 감성분석 연구에서는 쇼핑몰 상품의 리뷰 중심으로 진행되었지만, 최근에는 블로그, 뉴스기사, 날씨 예보, 영화 리뷰, SNS, 주식시장의 동향 등 다양한 분야에 적용되고 있다. 많은 선행연구들이 진행되어 왔으나 대부분 전통적인 단일 기계학습기법에 의존한 감성분류를 시도하였기에 분류 정확도 면에서 한계점이 있었다. 본 연구에서는 전통적인 기계학습기법 대신 대용량 데이터의 처리에 우수한 성능을 보이는 딥러닝 기법과 딥러닝 중 CNN과 LSTM의 조합모델을 이용하여 감성분석의 분류 정확도를 개선하고자 한다. 본 연구에서는 대표적인 영화 리뷰 데이터셋인 IMDB의 리뷰 데이터 셋을이용하여, 감성분석의 극성분석을 긍정 및 부정으로 범주를 분류하고, 딥러닝과 제안하는 조합모델을 활용하여극성분석의 예측 정확도를 개선하는 것을 목적으로 한다. 이 과정에서 여러 매개 변수가 존재하기 때문에 그수치와 정밀도의 관계에 대해 고찰하여 최적의 조합을 찾아 정확도 등 감성분석의 성능 개선을 시도한다. 연구결과, 딥러닝 기반의 분류 모형이 좋은 분류성과를 보였으며, 특히 본 연구에서 제안하는 CNN-LSTM 조합모델의 성과가 가장 우수한 것으로 나타났다.","Rapid growth of internet technology and social media is progressing. Data mining technology has evolved to enable unstructured document representations in a variety of applications. Sentiment analysis is an important technology that can distinguish poor or high-quality content through text data of products, and it has proliferated during text mining. Sentiment analysis mainly analyzes people's opinions in text data by assigning predefined data categories as positive and negative. This has been studied in various directions in terms of accuracy from simple rule-based to dictionary-based approaches using predefined labels. In fact, sentiment analysis is one of the most active researches in natural language processing and is widely studied in text mining. When real online reviews aren't available for others, it's not only easy to openly collect information, but it also affects your business. In marketing, real-world information from customers is gathered on websites, not surveys. Depending on whether the website's posts are positive or negative, the customer response is reflected in the sales and tries to identify the information. However, many reviews on a website are not always good, and difficult to identify. The earlier studies in this research area used the reviews data of the Amazon.com shopping mal, but the research data used in the recent studies uses the data for stock market trends, blogs, news articles, weather forecasts, IMDB, and facebook etc. However, the lack of accuracy is recognized because sentiment calculations are changed according to the subject, paragraph, sentiment lexicon direction, and sentence strength. This study aims to classify the polarity analysis of sentiment analysis into positive and negative categories and increase the prediction accuracy of the polarity analysis using the pretrained IMDB review data set. First, the text classification algorithm related to sentiment analysis adopts the popular machine learning algorithms such as NB (naive bayes), SVM (support vector machines), XGboost, RF (random forests), and Gradient Boost as comparative models.Second, deep learning has demonstrated discriminative features that can extract complex features of data. Representative algorithms are CNN (convolution neural networks), RNN (recurrent neural networks), LSTM (long-short term memory). CNN can be used similarly to BoW when processing a sentence in vector format, but does not consider sequential data attributes. RNN can handle well in order because it takes into account the time information of the data, but there is a long-term dependency on memory. To solve the problem of long-term dependence, LSTM is used. For the comparison, CNN and LSTM were chosen as simple deep learning models. In addition to classical machine learning algorithms, CNN, LSTM, and the integrated models were analyzed. Although there are many parameters for the algorithms, we examined the relationship between numerical value and precision to find the optimal combination. And, we tried to figure out how the models work well for sentiment analysis and how these models work. This study proposes integrated CNN and LSTM algorithms to extract the positive and negative features of text analysis. The reasons for mixing these two algorithms are as follows. CNN can extract features for the classification automatically by applying convolution layer and massively parallel processing. LSTM is not capable of highly parallel processing. Like faucets, the LSTM has input, output, and forget gates that can be moved and controlled at a desired time. These gates have the advantage of placing memory blocks on hidden nodes. The memory block of the LSTM may not store all the data, but it can solve the CNN's long-term dependency problem. Furthermore, when LSTM is used in CNN's pooling layer, it has an end-to-end structure, so that spatial and temporal features can be designed simultaneously. In combination with CNN-LSTM, 90.33% accuracy was measured. Thi..."
CNN 기반 초분광 영상 분류를 위한 PCA 차원축소의 영향 분석,2019,"['Principal Component Analysis', 'Convolutional Neural Network', 'Dimensionality Reduction', 'Hyperspectral Image Classification']","대표적인 딥러닝(deep learning) 기법 중 하나인 Convolutional Neural Network(CNN)은 고수준의 공간- 분광 특징을 추출할 수 있어 초분광 영상 분류(Hyperspectral Image Classification)에 적용하는 연구가 활발히 진행되고 있다. 그러나 초분광 영상은 높은 분광 차원이 학습 과정의 시간과 복잡도를 증가시킨다는 문제가 있어 이를 해결하기 위해 기존 딥러닝 기반 초분광 영상 분류 연구들에서는 차원축소의 목적으로 Principal Component Analysis (PCA)를 적용한 바 있다. PCA는 데이터를 독립적인 주성분의 축으로 변환시킬 수 있어 분광 차원을 효율적으로 압축할 수 있으나, 분광 정보의 손실을 초래할 수 있다. PCA의 사용 유무가 CNN 학습의정확도와 시간에 영향을 미치는 것은 분명하지만 이를 분석한 연구가 부족하다. 본 연구의 목적은 PCA를 통한분광 차원축소가 CNN에 미치는 영향을 정량적으로 분석하여 효율적인 초분광 영상 분류를 위한 적절한 PCA 의 적용 방법을 제안하는 데에 있다. 이를 위해 PCA를 적용하여 초분광 영상을 축소시켰으며, 축소된 차원의크기를 바꿔가며 CNN 모델에 적용하였다. 또한, 모델 내의 컨볼루션(convolution) 연산 방식에 따른 PCA의 민감도를 분석하기 위해 2D-CNN과 3D-CNN을 적용하여 비교 분석하였다. 실험결과는 분류정확도, 학습시간, 분산 비율, 학습 과정을 통해 분석되었다. 축소된 차원의 크기가 분산 비율이 99.7~8%인 주성분 개수일 때 가장 효율적이었으며, 3차원 커널 경우 2D-CNN과는 다르게 원 영상의 분류정확도가 PCA-CNN보다 더 높았으며, 이를 통해 PCA의 차원축소 효과가 3차원 커널에서 상대적으로 적은 것을 알 수 있었다.","CNN (Convolutional Neural Network) is one representative deep learning algorithm, which can extract high-level spatial and spectral features, and has been applied for hyperspectral image classification. However, one significant drawback behind the application of CNNs in hyperspectral images is the high dimensionality of the data, which increases the training time and processing complexity. To address this problem, several CNN based hyperspectral image classification studies have exploited PCA (Principal Component Analysis) for dimensionality reduction. One limitation to this is that the spectral information of the original image can be lost through PCA. Although it is clear that the use of PCA affects the accuracy and the CNN training time, the impact of PCA for CNN based hyperspectral image classification has been understudied. The purpose of this study is to analyze the quantitative effect of PCA in CNN for hyperspectral image classification. The hyperspectral images were first transformed through PCA and applied into the CNN model by varying the size of the reduced dimensionality. In addition, 2D-CNN and 3D-CNN frameworks were applied to analyze the sensitivity of the PCA with respect to the convolution kernel in the model. Experimental results were evaluated based on classification accuracy, learning time, variance ratio, and training process. The size of the reduced dimensionality was the most efficient when the explained variance ratio recorded 99.7%~99.8%. Since the 3D kernel had higher classification accuracy in the original-CNN than the PCA-CNN in comparison to the 2D-CNN, the results revealed that the dimensionality reduction was relatively less effective in 3D kernel."
관절질환 관리를 위한 Mask R-CNN을 이용한 모션 모니터링,2019,"['CNN', '휴먼모션', '헬스케어', '딥러닝', 'Mask R-CNN', '개인건강기록', 'CNN', 'Human Motion', 'Healthcare', 'Deep Learning', 'Mask R-CNN', 'Personal Health Record']","현대사회는 생활과 개성이 중요시 되면서 개인화된 생활습관 및 패턴이 생기고 있으며, 잘못된 생활습관으로 인해 관절질환자가 증가하고 있다. 또한 1인 가구가 점점 증가하면서 응급상황이 발생할 경우 알맞은 시간에 응급처치를 받지 못하는 경우가 생긴다. 건강과 질병관리에 필요한 개인의 상태에 따른 정확한 분석을 통해 스스로 관리할 수 있는 정보와 응급상황에 맞는 케어가 필요하다. 딥러닝 중에서 CNN은 데이터의 분류 및 예측에 효율적으로 사용된다. CNN은 데이터 특징에 따라 정확도 및 처리 속도에 차이를 보인다. 따라서 실시간 헬스케어를 위해 처리속도 향상과 정확도 개선이 필요하다. 본 논문에서는 관절질환 관리를 위한 Mask R-CNN을 이용한 모션 모니터링을 제안한다. 제안하는 방법은 Mask R-CNN을 이용하여 CNN의 정확도와 처리 속도를 개선하는 방법이다. 사용자의 모션을 신경망에 학습시킨 후 사용자의 모션이 학습된 데이터와 차이가 있을 경우 사용자에게 관리법을 피드백 해주고 보호자에게 응급상황을 알릴 수 있으며 상황에 맞는 적절한 조치를 취할 수 있다.","In modern society, lifestyle and individuality are important, and personalized lifestyle and patterns are emerging. The number of people with articulation diseases is increasing due to wrong living habits. In addition, as the number of households increases, there is a case where emergency care is not received at the appropriate time. We need information that can be managed by ourselves through accurate analysis according to the individual's condition for health and disease management, and care appropriate to the emergency situation. It is effectively used for classification and prediction of data using CNN in deep learning. CNN differs in accuracy and processing time according to the data features. Therefore, it is necessary to improve processing speed and accuracy for real-time healthcare. In this paper, we propose motion monitoring using Mask R-CNN for articulation disease management. The proposed method uses Mask R-CNN which is superior in accuracy and processing time than CNN. After the user's motion is learned in the neural network, if the user's motion is different from the learned data, the control method can be fed back to the user, the emergency situation can be informed to the guardian, and appropriate methods can be taken according to the situation."
"뉴스 텍스트에 나타난 아랍어의 통합성지수 연구 - 아랍뉴스 ‘al-Riyadh’, ‘al-Ahram’과 KBS, CNN의 아랍어 번역뉴스 비교를 중심으로 –",2019,"['Index of Synthesis', 'Media Arabic Language', 'Levelling Out in Translation', '통합성 지수', '미디어 아랍어', '번역어의 특징']","본 고에서는 현대 표준 아랍어의 특징이 형태적으로 잘 유지되고 있는지를 알아보기 위하여, 사우디 아라비아의 ‘알리야드’지와 이집트의 ‘알아흐람’지가 포함된 아랍권 뉴스 텍스트의 통합성 지수와 국내의 KBS의 아랍어 뉴스와 미국 CNN 아랍어의 통합성 지수를 비교해 보았다. 아랍권 뉴스의 평균 통합성 지수는 4.34, 국내의 KBS 아랍어 뉴스의 통합성 지수는 4.07, 미국 CNN 아랍어뉴스의 통합성 지수는 4.27임을 확인하였다. 통합성 지수 전체로 보아서는 미국 CNN 아랍어뉴스의 통합성 지수가 국내의 KBS의 아랍어 뉴스보다 아랍권 뉴스의 현대 표준 아랍어에 더 가까운 것으로 나타났다.한편 타갈로그어, 베트남어, 페르시아어, 터키어와 같은 언어와 아랍어의 통합성 지수를 측정했던 페인(Payne 1990, 178)은 그의 연구에서 아랍어의 통합성 지수를 3.14로 규정했는데, 그는 통합성 지수에 사용된 언어자료를 구체적으로 밝히지 않았다. 그런데 이 수치는 본 연구에서 측정한 사우디 아라비아의 대표적 인터넷 신문인 ‘일 리야드’지의 통합성 지수 3.14와 일치한다는 흥미로운 사실을 확인할 수 있었다. 본 연구의 수치는 품사를 제외한 수치이므로 페인이 측정한 텍스트의 유형은 현대 표준 아랍어 중 뉴스 텍스트일 가능성이 매우 높고, 단어당 형태소를 측정하는 통합성 지수 수식에서 품사를 제외했을 가능성도 있다.아랍권 뉴스나 미국의 CNN 아랍어 뉴스에 비해 국내의 KBS뉴스에서 품사수의 분포가 1,000여개 더 적게 나왔다. 총 형태소 수에서도 동일한 경향이 나타나 국내의 KBS뉴스의 총 형태소 수가 아랍권 뉴스나 미국의 CNN 아랍어 뉴스에 비해 더 적게 나왔다.아랍권 뉴스 평균과 국내의 KBS 아랍어 뉴스에서 동사 사용이 각 428개, 453개로 유사한 분포를 보였으나, 미국의 CNN 아랍어 뉴스에서는 동사 사용이 200 여개 더 많은 674개로 상이한 양상을 나타냈다. 게다가 명사류의 사용분포를 보면, 국내의 KBS 아랍어 뉴스와 미국의 CNN 아랍어 뉴스에서는 각 3,826개, 3,776개인 반면 아랍권 뉴스 평균이 4,091개로, 아랍권 뉴스에서 명사류의 사용분포가 더 많았다. 이것은 문 구조에서, 아랍권 뉴스와 국내의 KBS 아랍어 뉴스의 경우 명사문을 더 선호한다는 것을 나타낸다. 반면 미국의 CNN 아랍어 뉴스에서는 명사문보다 동사문을 더 선호한다는 것을 보여준다. 선행 국내의 연구 중 코란과 현대 표준 아랍어를 비교한 연구가 있는데(이인섭 2019, 11-12), 본 연구와 동일한 코퍼스 크기인 코란 5,000 어절을 기준으로, 코란에서는 1,311개의 동사가 사용되었다. 코란과 비교하자면, 아랍권 뉴스와 국내의 KBS 아랍어 뉴스 텍스트와 달리 미국의 CNN 아랍어 뉴스 텍스트의 문 구조가 동사문을 선호하는 코란의 문구조 경향에 더 가깝다는 것을 알 수 있다.그렇다면 미국의 CNN 아랍어 뉴스 텍스트에서 동사문이 선호되는 현상은 실제로 코란의 아랍어에 근접하게 번역되었기 때문인지 생각해 볼 필요가 있다. CNN 아랍어 뉴스에 쓰인 내용을 보면 아랍의 시리아 공습과 리비아 혹은 아랍과 이스라엘 간의 관계에 관한 내용 등도 있었지만 미국 뉴스 사이트인 만큼 미국 국내의 사정내용도 상당 부분 언급되고 있다. 여기서 영어로 기사 작성된 미국 국내의 뉴스가 아랍어로 번역되었다는 점을 고려해 보아야 할 것이다. 기사가 영어에서 아랍어로 번역되는 과정을 감안하면, 출발어인 영어의 언어관습이 아랍어 번역문에도 영향  ...","The study aims to compare the index of synthesis of Arabic language between non-translated news texts and translated news texts. It is analyzed through an index of synthesis of media Arabic language, which means internet Arabic news; including, ‘al-Riyadh’ of Saudi Arabia, and ‘al-Ahram’ of Egypt, in contrast to ‘KBS Arabic news of South Korea’ and ‘CNN Arabic news of the United States’. The average of the index of synthesis of internet news in Saudi Arabia and Egypt stood at 4.34, the index of synthesis of Arabic language of internet news of South Korea stood at 4.07, and the index of synthesis of CNN Arabic news stood at 4.27. In addition, translated news texts in Arabic were affected by language customs of the source texts: it is neither target-language nor source-language dependent, and that is what we call “levelling out”."
홈보안 시스템을 위한 CNN 기반 2D와 2.5D 얼굴 인식,2019,"['Face Recognition', 'Convolutional Neural Networks', 'Smart Home Security System', 'Face Accurac', '얼굴 인식', '컨벌루션 신경망', '스마트 홈보안 시스템', '얼굴 정확도']","4차 산업혁명의 기술이 우리도 모르는 사이 우리의 삶 속으로 스며들고 있다. CNN이 이미지 인식 분야에서 탁월한 능력을 보여준 이후 많은 IoT 기반 홈보안 시스템은 침입자로부터 가족과 가정을 보호하며 얼굴을 인식하기 위한 좋은 생체인식 방법으로 CNN을 사용하고 있다. 본 논문에서는 2D와 2.5D 이미지에 대하여 여러 종류의 입력 이미지 크기와 필터를 가지고 있는 CNN의 구조를 연구한다. 실험 결과는 50*50 크기를 가진 2.5D 입력 이미지, 2 컨벌류션과 맥스풀링 레이어, 3*3 필터를 가진 CNN 구조가 0.966의 인식률을 보여 주었고, 1개의 입력 이미지에 대하여 가장 긴 CPU 소비시간은 0.057S로 나타났다. 홈보안 시스템은 좋은 얼굴 인식률과 짧은 연산 시간을 요구 하므로 본 논문에서 제안한 구조의 CNN은 홈보안 시스템에서 얼굴인식을 기반으로 하는 액추에이터 제어 등에 적합한 방법이 될 것이다.","Technologies of the 4th industrial revolution have been unknowingly seeping into our lives. Many IoT based home security systems are using the convolutional neural network(CNN) as good biometrics to recognize a face and protect home and family from intruders since CNN has demonstrated its excellent ability in image recognition. In this paper, three layouts of CNN for 2D and 2.5D image of small dataset with various input image size and filter size are explored. The simulation results show that the layout of CNN with 50*50 input size of 2.5D image, 2 convolution and max pooling layer, and 3*3 filter size for small dataset of 2.5D image is optimal for a home security system with recognition accuracy of 0.966. In addition, the longest CPU time consumption for one input image is 0.057S. The proposed layout of CNN for a face recognition is suitable to control the actuators in the home security system because a home security system requires good face recognition and short recognition time."
"CNN의 컨볼루션 레이어, 커널과 정확도의 연관관계 분석",2019,"['Deep Learning', 'Convolution Neural Network', 'Kernel', 'Layer', 'Accuracy', 'Learning Time', '딥러닝', 'CNN', '커널', '레이어', '정확도', '학습 시간']","본 논문에서는 CNN의 컨볼루션 레이어 개수 및 커널의 크기와 개수가 CNN에 어떠한 영향을 끼치는지 실험을 통해 알아보기 위해 진행하였다. 또한 분석을 위해 일반적인 CNN도 실험하여 실험에 사용된 CNN과 비교하 였다. 분석에 사용될 신경망들은 CNN을 기반으로 하며 각각의 실험모델들은 레이어 개수, 커널의 크기 및 개수를 일정한 값으로 고정해 실험을 진행하였다. 모든 실험에는 2계층의 완전연결계층을 고정으로 사용하였다. 다른 변수들은 모두 동일한 값을 주어 실험하였다. 분석결과 레이어의 수가 작을 경우 커널의 크기 및 개수와 상관없이 데이터의 분산 값이 작아 견고한 정확도를 보여주었다. 레이어의 수가 커질수록 정확도도 증가됐으나 일정 수치 이상부턴 오히려 정확도가 내려갔으며 분산 값도 커져 정확도 편차가 크게 나타났다. 커널의 개수는 다른 변수보다 학습속도에 큰 영향을 끼쳤다.","In this paper, we experimented to find out how the number of convolution layers, the size, and the number of kernels affect the CNN. In addition, the general CNN was also tested for analysis and compared with the CNN used in the experiment. The neural networks used for the analysis are based on CNN, and each experimental model is experimented with the number of layers, the size, and the number of kernels at a constant value. All experiments were conducted using two layers of fully connected layers as a fixed. All other variables were tested with the same value. As the result of the analysis, when the number of layers is small, the data variance value is small regardless of the size and number of kernels, showing a solid accuracy. As the number of layers increases, the accuracy increases, but from above a certain number, the accuracy decreases, and the variance value also increases, resulting in a large accuracy deviation. The number of kernels had a greater effect on learning speed than other variables."
계층적 CNN 구조를 이용한 스테가노그래피 식별,2019,"['Steganalysis', 'CNN', 'Multi-level classification', 'Hierarchical structure', 'Secret data recovery', '스테그아날리시스', 'CNN', '다층 분류', '계층적 구조', '비밀 데이터 복원']","스테그아날리시스(steganalysis)는 스테가노그래피(steganography)에 의해 숨겨진 데이터를 감지하고 복구하기 위한 기법이다. 스테그아날리시스 방법은 데이터 삽입 시 발생하는 시각적, 통계적 변화를 분석하여 숨겨진 데이터를 찾는다. 숨겨진 데이터를 복원하기 위해서는 어떤 스테가노그래피 방법에 의해 데이터가 숨겨졌는지를 알아야 한다. 그러므로 본 논문은 다층 분류를 통해 입력 영상에 적용된 스테가노그래피 방법을 식별하는 계층적 CNN 구조를 제안한다. 이를 위해 4개의 기본 CNN을 각각 입력 영상에 스테가노그래피 방법이 적용되었는지 여부나 서로 다른 두 스테가노그래피 방법 중에 어떤 방법이 적용되었는지를 이진 판별하도록 학습시켰으며, 학습된 CNN을 계층적으로 연결하였다. 실험 결과를 통해 제안된 계층적 CNN 구조는 4개의 서로 다른 스테가노그래피 방법인 LSB(Least Significant Bit Substitution), PVD(Pixel Value Difference), WOW(Wavelet Obtained Weights), UNIWARD(Universal Wavelet Relative Distortion)을 79%의 정확도로 식별할 수 있음을 확인하였다.","Steganalysis is a technique that aims to detect and recover data hidden by steganography. Steganalytic methods detect hidden data by analyzing visual and statistical distortions caused during data embedding. However, for recovering the hidden data, they need to know which steganographic methods the hidden data has been embedded by. Therefore, we propose a hierarchical convolutional neural network (CNN) structure that identifies a steganographic method applied to an input image through multi-level classification. We trained four base CNNs (each is a binary classifier that determines whether or not a steganographic method has been applied to an input image or which of two different steganographic methods has been applied to an input image) and connected them hierarchically. Experimental results demonstrate that the proposed hierarchical CNN structure can identify four different steganographic methods (LSB, PVD, WOW, and UNIWARD) with an accuracy of 79%."
가속 회로에 적합한 CNN의 Conv-XP 가지치기,2019,[],"CNN은 컴퓨터 영상 인식 부분에서 높은 성능을 보여주고 있으나 많은 연산양을 요구하는 단점으로 인해 전력이나 연산 능력에 제한이 있는 임베디드 환경에서는 사용하기 어렵다. 이러한 단점을 극복하기 위해 CNN을 위한 가속회로나 가지치기 기법에 대한 연구가 많이 이루어지고 있다. 기존의 가지치기 기법은 가속 회로의 구조를 고려하지 않아서, 가지치기된 CNN을 위한 가속 회로는 비효율적인 구조를 가지게 된다. 이 논문에서는 가속 회로의 구조를 고려한 새로운 가지치기 기법인 Conv-XP 가지치기를 제안한다. Conv-XP 가지치기에서는 'X'와 '+' 모양의 두 가지 패턴으로만 가지치기함으로써, 이 기법으로 가지치기된 CNN을 위한 가속 회로의 구조를 단순하게 설계할 수 있도록 하였다. 실험 결과에 따르면, Conv-XP와 같이 가지치기 패턴을 제한하여도 CNN의 성능이 악화되지 않으며, 가속 회로의 면적은 12.8%을 감소시킬 수 있다.",다국어 초록 정보 없음
구조적인 차이를 가지는 CNN 기반의 스테그아날리시스 방법의 실험적 비교,2019,"['Image steganography', 'CNN-based steganalysis', 'preprocessing filter', 'CNN structure', 'experimental comparison']","영상 스테그아날리시스는 입력 영상을 스테가노그래피 알고리즘이 적용된 스테고 영상과 스테가노그래피 알고리즘이 적용되지 않은 커버 영상으로 분류하는 알고리즘이다. 기존에는 주로 수제 특징 기반의 스테그아날리시스를 연구하였다. 하지만 CNN 기반의 물체 인식이 큰 성과를 이루면서 최근 CNN 기반의 스테그아날리시스가 활발히 연구되고 있다. CNN 기반의 스테그아날리시스는 물체 인식과는 달리 커버 영상과 스테고 영상의 미세한 차이를 식별하기 위해서 전처리 필터를 필요로 한다. 그러므로, CNN 기반의 스테그아날리시스 연구들은 효과적인 전처리 필터와 네트워크 구조를 개발하는 데 초점을 두고 있다. 본 논문에서는 동일한 실험 조건에서 기존 연구들을 비교하고, 그 결과를 기반으로 전처리 필터와 네트워크 구조적인 차이에 의한 성능 변화를 분석한다.",다국어 초록 정보 없음
대비 결합 CNN을 이용한 인공위성 사진 내 선박 탐지 정확도 향상 연구,2019,"['인공위성 영상', '딥러닝', 'CNN', '영상처리', '이미지 대비 융합', '최적화', 'satellite image', 'deep learning', 'CNN', 'image processing', 'image contrast fusion', 'optimization']","인공위성은 지상관측이나 통신, 해양, 방송 등의 임무를 가지며 인공위성 사진을 이용한 선박 탐지는 해상 보안 및 교통 통제 등 쓰임새가 다양하다. 인공위성 사진의 특성은 지구 전역을 촬영하기 때문에 저장되는 데이터양이 많고 각 사진은 초고해상도로 크기가 매우 커 컴퓨터를 이용한 자동 선박 탐지가 필요하다. 기존 연구에서는 여러 딥러닝 모델을 이용하여 선박 탐지 연구를 진행하였지만, 인공위성 사진 특성으로 인한 처리속도가 문제되어 상대적으로 빠른 CNN 모델을 이용하여 연구가 진행되고 있다. 그러나 선박이 있는 선착장과 등대, 파도 등 여러 가지 요인으로 인해서 대부분 정확도와 성능을 높이는데 어려움을 가지고 있다. 따라서 이 논문에서는 이미지 명암 대비 향상을 기존 CNN(Convolution Neural Network)에 접목해 정확도와 성능을 높인 모델을 제안한다. 또한, 학습 단계에서 선박 분류에 필요한 데이터의 양을 늘리기 위해 overlap과 rotation 기능을 이용하고 실제 인공위성 사진에서 탐지 속도를 줄이기 위해 탐지 최적화(window sliding)를 고려하여 자동화 탐지 기술을 구현한다. 식별된 선박 데이터는 다시 학습데이터로 사용하여 정확도를 높이고 실제 산업에서 사용할 수 있도록 구현한다.","The satellite has various missions such as ground/marine observation, communication, broadcasting, etc. Satellite photographs provide information for the maintenance of marine security and traffic control for ship detection. Since satellite photos are taken all over the earth, the memory storage is not sufficient to hold such data with each data being of a high resolution and requiring automatic ship detection using the computer. The existing literature on ship detection employed several deep learning models. However, the problem of processing speed due to the characteristics of satellite photographs leads to the necessity of using a CNN(Convolution Neural Network) model that has a comparably high processing speed. On the contrary, it is difficult to improve the accuracy and performance mostly due to factors such as marina, lighthouses and waves. Therefore, in this paper, we propose a model that improves the accuracy and performance by combining image contrast enhancement with the existing CNN. In addition, we have employed the overlap and rotation functions to increase the amount of data required for ship classification in the learning stage and implement automation detection technology considering window sliding to reduce detection speed in real satellite photographs. Also, the identified ship data has been used as learning data to improve accuracy for the model that can be used in the real industry."
CNN의 깊은 특징과 전이학습을 사용한 보행자 분류,2019,"['Pedestrian Classification', 'Transfer Learning', 'Deep Features', 'CNN', 'INRIA Person Data Set', '보행자 분류', '전이학습', '깊은 특징', 'CNN', 'INRIA Person데이터 세트']","자율주행 시스템에서, 카메라에 포착된 영상을 통하여 보행자를 분류하는 기능은 보행자 안전을 위하여 매우 중요하다. 기존에는HOG(Histogram of Oriented Gradients)나 SIFT(Scale-Invariant Feature Transform) 등으로 보행자의 특징을 추출한 후 SVM(Support Vector Machine)으로 분류하는 기술을 사용했었으나, 보행자 특징을 위와 같이 수동(handcrafted)으로 추출하는 것은 많은 한계점을 가지고있다. 따라서 본 논문에서는 CNN(Convolutional Neural Network)의 깊은 특징(deep features)과 전이학습(transfer learning)을 사용하여보행자를 안정적이고 효과적으로 분류하는 방법을 제시한다. 본 논문은 2가지 대표적인 전이학습 기법인 고정특징추출(fixed feature extractor) 기법과 미세조정(fine-tuning) 기법을 모두 사용하여 실험하였고, 특히 미세조정 기법에서는 3가지 다른 크기로 레이어를 전이구간과 비전이구간으로 구분한 후, 비전이구간에 속한 레이어들에 대해서만 가중치를 조정하는 설정(M-Fine: Modified Fine-tuning) 을 새롭게 추가하였다. 5가지 CNN모델(VGGNet, DenseNet, Inception V3, Xception, MobileNet)과 INRIA Person데이터 세트로 실험한결과, HOG나 SIFT 같은 수동적인 특징보다 CNN의 깊은 특징이 더 좋은 성능을 보여주었고, Xception의 정확도(임계치 = 0.5)가 99.61% 로 가장 높았다. Xception과 유사한 성능을 내면서도 80% 적은 파라메터를 학습한 MobileNet이 효율성 측면에서는 가장 뛰어났다.그리고 3가지 전이학습 기법중 미세조정 기법의 성능이 가장 우수하였고, M-Fine 기법의 성능은 미세조정 기법과 대등하거나 조금낮았지만 고정특징추출 기법보다는 높았다.",다국어 초록 정보 없음
CNN-based Skip-Gram Method for Improving Classification Accuracy of Chinese Text,2019,"['Natural language processing (NLP)', 'deep learning', 'text classification', 'convolutional neural networks', 'skip-gram method']",국문 초록 정보 없음,"Text classification is one of the fundamental techniques in natural language processing. Numerous studies are based on text classification, such as news subject classification, question answering system classification, and movie review classification. Traditional text classification methods are used to extract features and then classify them. However, traditional methods are too complex to operate, and their accuracy is not sufficiently high. Recently, convolutional neural network (CNN) based one-hot method has been proposed in text classification to solve this problem. In this paper, we propose an improved method using CNN based skip-gram method for Chinese text classification and it conducts in Sogou news corpus. Experimental results indicate that CNN with the skip-gram model performs more efficiently than CNN-based one-hot method."
작물 분류에서 시공간 특징을 고려하기 위한 2D CNN과 양방향 LSTM의 결합,2019,"['Crop classification', 'Convolutional neural network', 'Long short-term memory', 'Spatiotemporal features']","이 논문에서는 작물 분류를 목적으로 작물의 시공간 특징을 고려할 수 있는 딥러닝 모델 2D convolution with bidirectional long short-term memory(2DCBLSTM)을 제안하였다. 제안 모델은 우선 작물의 공간 특징을 추출하기 위해 2차원의 합성곱 연산자를 적용하고, 추출된 공간 특징을 시간 특징을 고려할 수 있는 양방향 LSTM 모델의 입력 자료로 이용한다. 제안 모델의 분류 성능을 평가하기 위해 안반덕에서 수집된 다중시기 무인기 영상을 이용한 밭작물 구분 사례 연구를 수행하였다. 비교를 목적으로 기존 딥러닝 모델인 2차원의 공간 특징을이용하는 2D convolutional neural network(CNN), 시간 특징을 이용하는 LSTM과 3차원의 시공간 특징을 이용하는 3D CNN을 적용하였다. 하이퍼 파라미터의 영향 분석을 통해, 시공간 특징을 이용함으로써 작물의 오분류 양상을 현저히 줄일 수 있었으며, 제안 모델이 공간 특징이나 시간 특징만을 고려하는 기존 딥러닝 모델에비해 가장 우수한 분류 정확도를 나타냈다. 따라서 이 연구에서 제안된 모델은 작물의 시공간 특징을 고려할수 있기 때문에 작물 분류에 효과적으로 적용될 수 있을 것으로 기대된다.","In this paper, a hybrid deep learning model, called 2D convolution with bidirectional long short-term memory (2DCBLSTM), is presented that can effectively combine both spatial and temporal features for crop classification. In the proposed model, 2D convolution operators are first applied to extract spatial features of crops and the extracted spatial features are then used as inputs for a bidirectional LSTM model that can effectively process temporal features. To evaluate the classification performance of the proposed model, a case study of crop classification was carried out using multi-temporal unmanned aerial vehicle images acquired in Anbandegi, Korea. For comparison purposes, we applied conventional deep learning models including two-dimensional convolutional neural network (CNN) using spatial features, LSTM using temporal features, and three-dimensional CNN using spatio-temporal features. Through the impact analysis of hyper-parameters on the classification performance, the use of both spatial and temporal features greatly reduced misclassification patterns of crops and the proposed hybrid model showed the best classification accuracy, compared to the conventional deep learning models that considered either spatial features or temporal features. Therefore, it is expected that the proposed model can be effectively applied to crop classification owing to its ability to consider spatio-temporal features of crops."
어종 분류를 위한 CNN의 적용,2019,[],국문 초록 정보 없음,"In this study, before system development for the elimination of foreign fish species, we propose an algorithm to classify fish species by training fish images with CNN. The raw data for CNN learning were directly captured images for each species, Dataset 1 increases the number of images to improve the classification of fish species and Dataset 2 realizes images close to natural environment are constructed and used as training and test data. The classification performance of four CNNs are over 99.97% for dataset 1 and 99.5% for dataset 2, in particular, we confirm that the learned CNN using Data Set 2 has satisfactory performance for fish images similar to the natural environment. And among four CNNs, AlexNet achieves satisfactory performance, and this has also the shortest execution time and training time, we confirm that it is the most suitable structure to develop the system for the elimination of foreign fish species."
가상화 플랫폼을 통한 CNN기반 모니터링 애플리케이션의 안정적인 응답 속도 보장 방안 연구,2019,"['Virtualized Platform', 'Cloud Computing', 'OpenStack', 'Docker', 'IaaS', 'CNN', 'Monitoring', '가상화 플랫폼', '클라우드 컴퓨팅', 'OpenStack', 'Docker', 'IaaS', 'CNN', '모니터링']","최근 가상화 기술이 적용된 가상화 플랫폼(Virtualized Platform)을 도입하게 되면서 단일 하드웨어 리소스의 파티셔닝을 통한 리소스 활용률 상승과 마이그레이션을 통한 확장성의 이점을 통해 서비스의 안정적인 응답 속도를 기대할 수 있게 되었다. 기존 단일 하드웨어 서버기반 모니터링 애플리케이션 서비스에서는 필요 이상의 리소스를 사용하거나 사용자의 요청에 비해 리소스가 부족하여 응답 속도가 저하되는 문제가 발생하였다. 본 논문에서는 이를 해결하기 위해 오픈 소스 가상화 플랫폼인 OpenBaton, OpenStack과 Docker를 통해 이미지에 대해 화재 및 연기 예측이 가능한 ResNet50 기반의 CNN 모델이 적용된 모니터링 애플리케이션을 구현하였다. 이를 통해 본 논문에서는 기존 단일 하드웨어 서버와 제안된 시스템의 응답 속도 비교를 통해 안정적인 응답 속도 보장 방안에 대해 연구하였다.","With the recent introduction of a virtualized platform with virtualization technology, the benefits of increased resource utilization through partitioning of a single hardware resource and scalability through migration provide a reliable response rate for services. Traditional single hardware server-based monitoring application services have had problems with using more resources than needed or lack of resources compared to the user's request, resulting in slower response times. To address this, this paper implemented a monitoring application with a CNN model based on ResNet50 that enables fire and smoke prediction for images through open source virtualization platforms, OpenBaton, OpenStack and Docker. In this paper, we studied how to ensure a stable response rate through comparing the response speed of the existing single hardware server with the proposed system."
Multi-Modal 영역제안 및 CNN-SVM 기반야간 원거리 원적외선 보행자 검출,2019,"['remote pedestrian detection', 'far infrared', 'multi-scale contrast filter', 'local projection', 'CNN']",국문 초록 정보 없음,"This paper presents a novel remote infrared pedestrian detection method for night use by means of local projection-CNN.Conventional sliding window methods (HOG/ACF) or region proposal-based deep learning approaches (faster R-CNN, SSD, YOLO)either fail to detect small objects or generate many false positives. Multi-modal region proposal schemes (multi-scale contrast filters withlocal projection+ACF) are used to improve remote pedestrian detection. AlexNet-based CNN feature extraction and SVM classificationcan reduce false positives further. This paper’s experimental evaluations indicate that the proposed method can improve remote IRpedestrian detection by 16%."
GPR 히트맵 이미지 데이터 기반 CNN을 이용한 철근 두께 예측에 관한 연구,2019,"['GPR', 'B-scan', '히트맵', '합성곱 신경망', '철근', '두께', 'Ground Penetrating Radar', 'B-scan', 'heatmap', 'Convolution Neural Network', 'Rebar Thickness']","본 논문에서는 시설물 내부 철근 두께를 예측하기 위해 GPR 데이터를 활용한 철근 두께 예측 기법에 관한 연구를 실시하였다. 국내의 규격 미달 철근의 사용 및 배근 시공과 같은 부실시공 사례에서 볼 수 있듯이, 구조물 정밀진단을 위해서 철근 두께에 대한 정보는 정밀 안전진단을 위해서 꼭 필요함을 알 수 있다. 이를 위해 본 연구에서는 시편을 제작하여 철근 직경을 단계적으로 증가시켜 GPR의 B-scan 데이터를 취득하였다. GPR 의 B-scan 데이터는 가시성이 떨어지기 때문에 이를 migration을 통해 히트맵 이미지 데이터로 변화시켜 데이터의 직관성을 높이고자 하였다. 본 연구는 보편적으로 이용되는 B-scan 데이터와 히트맵 데이터의 합성곱 신경망(CNN) 적용 시 결과를 비교하기 위해 B-scan 및 히트맵 데이터에서 각각 철근에 대한 영역을 추출하여 학습 및 검증 데이터를 구축하였으며, 구축된 데이터에 CNN을 적용하였다. 그 결과, 히트맵 데이터의 경우 B-scan 데이터와 비교하였을 때 더 좋은 결괏값을 얻을 수 있었다. 이를 통해 GPR 히트맵 데이터를 이용하였을 경우 B-scan 데이터를 이용하였을 때보다 더 높은 정확도로 철근 두께를 예측할 수 있음을 확인하였으며, 시설물 내부 철근 두께 예측의 가능성을 검증하였다.","In this paper, a study was conducted on the method of using GPR data to predict rebar thickness inside a facility. As shown in the cases of poor construction, such as the use of rebars below the domestic standard and the construction of reinforcement, information on rebar thickness can be found to be essential for precision safety diagnosis of structures. For this purpose, the B-scan data of GPR was obtained by gradually increasing the diameter of rebars by making specimen. Because the B-scan data of GPR is less visible, the data was converted into the heatmap image data through migration to increase the intuition of the data. In order to compare the results of application of commonly used B-scan data and heatmap data to CNN, this study extracted areas for rebars from B-scan and heatmap data respectively to build training and validation data, and applied CNN to the deployed data. As a result, better results were obtained for the heatmap data when compared with the B-scan data. This confirms that if GPR heatmap data are used, rebar thickness can be predicted with higher accuracy than when B-scan data is used, and the possibility of predicting rebar thickness inside a facility is verified."
MALICIOUS URL RECOGNITION AND DETECTION USING ATTENTION-BASED CNN-LSTM,2019,"['Malicious URL', 'Recognition and Detection', 'Attention-Based CNN-LSTM', 'Deep Learning']",국문 초록 정보 없음,"A malicious Uniform Resource Locator (URL) recognition and detection method based on the combination of Attention mechanism with Convolutional Neural Network and Long Short-Term Memory Network (Attention-Based CNN-LSTM), is proposed. Firstly, the WHOIS check method is used to extract and filter features, including the URL texture information, the URL string statistical information of attributes and the WHOIS information, and the features are subsequently encoded and pre-processed followed by inputting them to the constructed Convolutional Neural Network (CNN) convolution layer to extract local features. Secondly, in accordance with the weights from the Attention mechanism, the generated local features are input into the Long-Short Term Memory (LSTM) model, and subsequently pooled to calculate the global features of the URLs. Finally, the URLs are detected and classified by the SoftMax function using global features. The results demonstrate that compared with the existing methods, the Attention-based CNN-LSTM mechanism has higher accuracy for malicious URL detection."
CNN에서 훈련 및 시험 영상 수에 따른 정확도 분석,2019,"['CNN(Convolution Neural Networks)', '정확도(accuracy)', 'RGB채널(RGB channel)']","본 논문은 CNN (Convolution Neural Networks)의 첫 번째 컨볼루션층(convolution layer)을 RGB-csb(RGB channel separation block)로 대체하여 입력 영상의 RGB 값을 특징 맵에 적용시켜 정확성을 제고시킬 수 있는 선행연구 결과에 추가적으로, 훈련 및 시험 영상 수에 따른 분석을 통하여 정확도 향상 방법을 제안한다. 제안한 방법은 영상의 개수가 작을수록 각 학습 간의 정확도 편차가 크게 나타나는 불안정성은 있지만 기존 CNN모델에 비하여 정확도 차이가 증가함을 알 수 있다.",다국어 초록 정보 없음
CNN과 Bidirectional LSTM을 활용한 부산시 민원 자동 분류 연구,2019,"['automatic text classification', 'civil complaint', 'CNN', 'bidirectional LSTM', 'bi－LSTM', '민원', '자동분류', '딥러닝', '순환신경망', '양방향 LSTM', 'CNN']","온라인과 정보통신기술의 발달로 정부정책에 대한 시민의 참여 욕구는 높아지고 있다. 이에 따라 시민들은 민원을 인터넷과 모바일을 활용하여 전자 민원 게시판을 통해 접수하는 건수가 증가하고 있다. 폭발적으로 늘어나는 민원의 양에 비해 아직 수작업으로 분류 하여 오류가 발생하거나 신속한 대응이 이루어지지 않아 민원인들의 불만이 늘어나고 있다. 본 연구에서는 딥러닝 기법을 통해 담당 부서 분류를 자동화하기 위해 2017년도의 부산시 민원 데이터를 수집하고, 담당 부서를 확인 할 수 있는 부서명, 전화번호, 담당자명을 기준으로 레이블을 부여하였다. 그리고 딥러닝 중 대표적인 분류방법인 CNN과 최근 여러 분야에서 두각을 내고 있는 Bidirectional LSTM을 기반으로 상위 12개 범주에 대하여 지도학습을 실시하였다. 지도학습 결과 각각 73%, 77%의 정확도를 보여 안정적인 성능을 보여주었다. 본 연구의 민원 분류에 대한 지도학습 사례는 향후 다른 주제 및 지방자치단체 민원에 대한 텍스트 데이터의 분류에 이용될 수 있어 실무적인 공헌도와 함께 후속연구를 유발할 수 있다는 학문적 기여도가 있다.",다국어 초록 정보 없음
CNN을 이용한 자율주행 트랙터 조향각 및 속도 조작 기술 기초 연구,2019,"['자율주행', '인공지능', 'CNN', '조향각', '속도', '시뮬레이션']","농촌인구의 감소, 급속한 고령화로 1인당 경작 규모가 증가 됨에 따라 농기계산업 및 학계는 부족한 일손을 효과적으로 대체하며, 농작업 효율성 증대가 가능한 자율농작업 트랙터 연구에 노력을 기울이고 있다. 그중 경로를 정밀 추종하기 위한 정교한 조향각 및 속도 명령 생성 연구는 자율주행 기술의 고도화를 위해 필수적이지만, 농민의 경험과 직관까지 모델식으로 표현하기에는 한계가 존재한다. 따라서 본 논문에서는 일반적으로 자율주행 시스템에서 도출되는 GPS 정보를 활용해 농민의 경험·직관을 수치화하는 방법을 제시하고, 누적된 데이터를 통해 운전습관을 모방할 수 있는 Convolutional Neural Networks (CNN) 기반의 조향각 및 속도 명령 생성 알고리즘을 개발하고자 하였다. 농민의 직관과 경험을 정량화하기 위해 GPS가 장착된 지점부터 선견 지점(3m)까지 1cm 간격으로 측면변위와 방향각 변위를 조사하여 1×301×2 배열을 생성하여 입력으로 사용하고, 그때의 조향각과 속도를 label 값으로 사용하였다. 기준경로는 이전에 개발된 경로생성 알고리즘을 활용하였다. 알고리즘은 Python 환경에서 Keras library를 활용하여 1개의 normalization layer, 3개의 convolutional layer, 1개의 dropout layer, 그리고 2개의 fully connected layer로 총 4종류의 layer로 구성 된 network로 구성하였다. 실제 농민의 운전 데이터를 학습하기 전에 제시한 알고리즘의 효요성을 판단하기 위해, 충남 논산시 상월면에 위치한 97 x 35.7 ㎡의 직사각형 논에서 수행된 C형 선회 기반의 자율주행 균평 작업 시 직접 취득된 48957개의 sample을 활용하였다. 검증을 위해 이전에 개발된 시뮬레이터를 활용하여 C, X, R형 기반의 선회와 직진 경로를 추종하고 모델식 기반의 추종 알고리즘의 결과와 비교하였다. 실험결과, 모든 작업이 수행된 구간에서 측면과 방향각 평균 제곱근편차(RMSE)는 각각 3.3 cm와 0.7deg로 측정되어 모델식 기반의 추종 결과 (3.1cm와 0.6deg 이하)과 유사하였으며, 학습한 C형 기반의 선회뿐 아니라 다른 선회유형도 추종 가능함을 보여 개발된 CNN기반의 조향각 및 속도 명령 생성 알고리즘의 현장적용 가능성을 검증하였다.",다국어 초록 정보 없음
홈 IoT 환경에서의 CNN-DNN 기반 음향인지 알고리즘,2019,"['Deep learning', 'sound event detection', 'log mel filter bank', '딥러닝', '음향인지', 'log mel filter bank']",국문 초록 정보 없음,"In this study, we proposed a CNN-DNN based sound event detection in home IoT environments. To reduce the impact of input volume variation, we applied peak normalization, and extracted acoustic feature named Log mel filter bank. Log-mel filter bank is very popular acoustic feature based on mel filter which is powerful for speech recognition and sound event detection. Then, we used CNN-DNN model for classification. CNN outputs of sequential 32 frames were used as DNN input for considering time-series characteristic of the sound. Data were collected in real apartment environment. We used 13 sounds as target such as doorbell, babycry, vacuum, and so on. We evaluated our method using computer simulation, as a result, the accuracy of the proposed sound event detection algorithm was 90.76%."
Applications of Hyperspectral Imaging and Convolutional Neural Networks (CNN) for Agricultural Products and Food Quality,2019,"['Hyperspectral imaging techniques', 'convolutional neural networks', 'chemometrics', 'food safety']",국문 초록 정보 없음,"Hyperspectral imaging techniques have been used for decades to measure the quality and safety of food. Chemometrics methods such as principal components analysis (PCA), and partial least-squares (PLS) have mainly been employed for hyperspectral imaging analysis. However, the methods do not consider the relationship between the neighboring pixel information constituting an image. The objective of this study is to identify the applicability of the convolutional neural networks (CNN) method to hyperspectral images for the assessment of food quality. We compared the accuracy of the proposed CNN-based method with that of the chemometrics method. The results revealed that the 3-D CNN-based method provided competitive results for the assessment of food quality."
CNN 기반 전이학습을 이용한 음성 감정 인식,2019,"['Speech Emotion Recognition', 'Transfer Learning', 'Deep Learning', 'Convolutional Neural Networks', '음성 감정 인식', '전이학습', '딥러닝', '합성곱 신경망']","로봇은 사람의 편의를 위해 존재하므로 사람과 로봇의 상호작용은 중요하다. 로봇이 사람의 감정을 파악하는 것은 여러상호작용 중 하나이다. 최근 사람의 음성으로 감정을 인식하는 음성 감정 인식(speech emotion recognition; SER)분야는딥러닝 (deep learning)의 접목으로 그 성능이 향상되고 있다. 하지만, 데이터의 부족으로 깊은 신경망을 사용하거나추가적인 학습 기법을 적용하지 않고서는 높은 정확도를 기대하기 힘들다. 본 논문에서는 데이터가 부족할 때 사용하는 학습기법 중의 하나인 전이학습 (transfer learning)을 SER에 적용한 효과를 확인한다. 딥러닝을 적용하기 위해 합성곱 신경망(convolutional neural networks; CNN) 구조를 사용한다. 전이학습에 음성 감정 데이터가 아닌 일반 소리 데이터를 사용하여데이터 개수에 대한 한계를 없앤다. 전이학습 중 특징 추출기 (feature extractor)로써 사용한 경우와 미세조정 (fine tuning)을한 경우로 나누어 결과를 확인한다. 그 결과, 미세조정한 경우 수렴 시간이 약 20% 줄었고, 특징 추출기로써 사용한 경우 약20%에서 70% 줄었다. 정확도는 특징 추출기로써 사용한 경우 오히려 정확도가 감소하는 경우가 발생하였고 증가한 경우 약3% 증가했다. 미세조정을 한 경우 정확도가 평균적으로 약 7% 향상되었다","Interaction between human and robot is important because robots exist for the convenience of people. Robot grasping human emotions is one of many interactions. The field of SER (speech emotion recognition) has been improved by combining deep learning. The lack of data makes it difficult to expect high accuracy without using deep neural networks or applying additional learning techniques. In this paper, we confirm the effect of applying the transfer learning, which is one of the learning methods used when there is insufficient data, to SER. For deep learning, CNN (convolutional neural networks) architecture is used. By using general sound data instead of speech emotion data for the transfer learning, the limit on the number of data is eliminated. The results are verified by dividing transfer learning into two case, using as a feature extractor and fine-tuning. As a result, convergence time was reduced by about 20% when fine-tuning, and about 20% to 70% when used as a feature extractor. Accuracy of the feature extractor is rather reduced when it is used as a feature extractor and increased by about 3% when it is increased. On the average, the accuracy was improved by about 7% when fine-tuning."
CNN 기반 잡음 제거 : CNN에서 layer 수의 따른 커널 복원,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
입력영상 변환에 의한 CNN 기반의 SMT 부품 결함 분류 방법,2019,"['surface mount technology', 'machine learning', 'deep learning', 'histogram stretching']",국문 초록 정보 없음,"Surface Mount Technology (SMT) is a manufacturing process in which components are mounted on the surface of a printed circuit board (PCB). The automatic optical inspection system (AOI) has mainly used the learning-based method for the defect classification of the SMT process, and recently the CNN-based classification method has appeared. However, existing techniques do not consider the area margin of the part, so the classification accuracy decreases. In addition, the classification performance of the CNN classifier is degraded due to the uneven color distribution according to the position of the components. In this paper, we propose a system that can extract the component region and improve the color distribution by the input image transformation. We extract the correct component area through vertical and horizontal projection, and the color improvement enhance the brightness value distribution of the component image through local histogram stretching. By experimental result, we prove the performance of the proposed classification method."
영상에서 다중 객체 추적을 위한 CNN 기반의 다중 객체 검출에 관한 연구,2019,"['Object Detection', 'Object Tracking', 'Convolutional Neural Network(CNN)', 'Machine Learning']",국문 초록 정보 없음,"Recently, video monitoring system technology has been rapidly developed to monitor and respond quickly to various situations. In particular, computer vision and related research are being actively carried out to track objects in the video. This paper proposes an efficient multiple objects detection method based on convolutional neural network (CNN) for multiple objects tracking. The results of the experiment show that multiple objects can be detected and tracked in the video in the proposed method, and that our method is also good performance in complex environments."
지역 군집화를 위한 CNN-GRU 기반 다변량 시계열 데이터의 특성 추출,2019,[],"시계열 데이터에 대한 군집화 관련 연구는 주로 통계 분석을 통해 이뤄지기 때문에 데이터가 갖는 특성을 완전히 반영하는 데 한계를 갖는다. 본 논문에서는 다변량 데이터에서의 군집화를 위하여 변수별로 시간에 따른 변화와 특징을 추출하기 위한 CNN-GRU(Convolutional Neural Network – Gated Recurrent Unit) 기반의 신경망 모델을 제안한다. CNN을 활용하여 변수별로 갖는 특성을 파악하고자 하였으며, GRU을 통해 전체 시간에 따른 소비 추세를 도출하고자 하였다. 지역별로 업종에 따라 사용된 2년 치의 실제 카드 데이터를 활용하였으며, 유사한 소비 추세를 보이는 지역을 군집화하는데 이를 적용하였다. 결과적으로, 다변량 시계열 데이터를 통해 전체적인 흐름을 반영하여 패턴화했다는 점에서 의의를 갖는다.",다국어 초록 정보 없음
Self-Attention을 활용한 Siamese CNN-Bidirectional LSTM 기반 문장 유사도 예측,2019,"['자연어 처리', '유사도 측정', '샴 네트워크', '합성곱 신경망', '순환 신경망', '어텐션', 'natural language processing', 'similarity measure', 'siamese network', 'convolution neural network', 'recurrent neural network', 'attention']",본 논문에서는 입력된 두 문장의 유사도를 측정하는 딥러닝 모델을 제안한다. 기존의 문장의유사도 측정 모델에는 단어 혹은 형태소 단위로 문장을 분해하여 임베딩 하는 방식을 활용한다. 하지만 이는 사전의 크기를 증가시켜 모델의 복잡도를 높이는 문제점이 있다. 본 논문에서는 문장을 음소 단위로 분해하여 모델 복잡도를 줄이고 해당 음소를 묶어주는 다양한 필터 사이즈의 1D Convolution Neural Network와 Long Short Term Memory(LSTM)을 결합한 Siamese CNN-Bidirectional LSTM 모델을 제안한다. 본 모델을 평가하기 위해 네이버 지식인 데이터를 활용하여 기존의 문서 유사 측정에서 좋은 성능을 보이는 모델 Manhattan LSTM(MaLSTM)과 비교하였다.,"A deep learning model for semantic similarity between sentences was presented. In general, most of the models for measuring similarity word use level or morpheme level embedding.However, the attempt to apply either word use or morpheme level embedding results in higher complexity of the model due to the large size of the dictionary. To solve this problem, a Siamese CNN-Bidirectional LSTM model that utilizes phonemes instead of words or morphemes and combines long short term memory (LSTM) with 1D convolution neural networks with various window lengths that bind phonemes is proposed. For evaluation, we compared our model with Manhattan LSTM (MaLSTM) which shows good performance in measuring similarity between similar questions in the Naver Q&A dataset (similar to Kaggle Quora Question Pair)."
CNN-based Visual/Auditory Feature Fusion Method with Frame Selection for Classifying Video Events,2019,"['Multimedia', 'Computer Vision Systems', 'Aritifical Intelligence', 'Video Classification']",국문 초록 정보 없음,"In recent years, personal videos have been shared online due to the popular uses of portable devices, such as smartphones and action cameras. A recent report[1] predicted that 80% of the Internet traffic will be video content by the year 2021. Several studies have been conducted on the detection of main video events to manage a large scale of videos. These studies show fairly good performance in certain genres. However, the methods used in previous studies have difficulty in detecting events of personal video. This is because the characteristics and genres of personal videos vary widely. In a research, we found that adding a dataset with the right perspective in the study improved performance. It has also been shown that performance improves depending on how you extract keyframes from the video. we selected frame segments that can represent video considering the characteristics of this personal video. In each frame segment, object, location, food and audio features were extracted, and representative vectors were generated through a CNN-based recurrent model and a fusion module. The proposed method showed mAP 78.4% performance through experiments using LSVC[2] data."
인간-컴퓨터 상호작용을 위한 CNN 기반 객체 검출,2019,[],비전 기반 제스처 인식은 비 침입적이고 저렴한 비용으로 자연스러운 인간-컴퓨터 상호 작용을 제공한다. 로봇의 사용이 증가함에 따라 인간-로봇 상호 작용은 점점 더 중요해질 것이다. 최근 효율적인 딥러닝 기술이 연구되고 있다. 본 연구는 인간 컴퓨터 상호 작용을 위해 CNN을 기반으로 한 얼굴 및 손 동작의 인식을 위해 객체 검출 기법의 적용 결과를 제시한다.,다국어 초록 정보 없음
CNN에서의 DropOut과 DropConnect에 대한 성능 비교,2019,[],"CNN 은 합성곱 연산을 사용하는 인공신경망의 한 종류이다. 이러한 인공 신경망에서는 훈련 데이터에 대한 과도한 학습으로 인해 시험 데이터에 제대로 반응하지 못하는 오버피팅이 발생할 우려가 있다. 이를 해결하기 위해 DropOut 과 DropConnect 를 사용할 수 있다. 본 논문에서는 DropOut 과 DropConnect 를 통한 학습 정도를 실험을 통해서 비교해보고, 인공 신경망에서 이 방법의 효과를 살펴본다.",다국어 초록 정보 없음
캡슐내시경의 위치추적을 위한 CNN 기반 위장관 랜드마크 분류기 설계,2019,[],"최근의 영상 처리 분야는 딥러닝 기법들의 성능이 입증됨에 따라 다양한 분야에서 이와 같은 기법들을 활용해 영상에 대한 분류, 분석, 검출 등을 수행하려는 시도가 활발하다. 그중에서도 의료 진단 보조 역할을 할 수 있는 의료 영상 분석 소프트웨어에 대한 기대가 증가하고 있는데, 본 연구에서는 캡슐내시경 영상에 주목하였다. 캡슐내시경은 주로 소장 촬영을 목표로 하며 식도부터 대장까지 약 8~10시간 동안 촬영된다. 이로 인해 CT, MR, X-ray와 같은 다른 의료 영상과 다르게 하나의 데이터 셋이 10~15만 장의 이미지를 갖는다. 일반적으로 캡슐내시경 영상을 판독하는 순서는 위장관 교차점(Z-Line, 유문판, 회맹판)을 기준으로 위장관 랜드마크(식도, 위, 소장, 대장)를 구분한 뒤, 각 랜드마크 별로 병변 정보를 찾아내는 방식이다. 그러나 워낙 방대한 영상 데이터를 가지기 때문에 의사 혹은 의료 전문가가 영상을 판독하는데 많은 시간과 노력이 소모되고 있다. 본 논문의 목적은 캡슐내시경 영상의 판독에서 모든 환자에 대해 공통으로 수행되고, 판독하는 데 많은 시간을 차지하는 위장관 랜드마크를 찾는 것에 있다. 이를 위해, 위장관 랜드마크를 식별할 수 있는 CNN 학습 모델을 설계하였으며, 더욱 효과적인 학습을 위해 전처리 과정으로 학습에 방해가 되는 학습 노이즈 영상들을 제거하고 위장관 랜드마크 별 특징 분석을 진행하였다. 총 8명의 환자 데이터를 가지고 학습된 모델에 대해 평가 및 검증을 진행하였는데, 무작위로 환자 데이터를 샘플링하여 학습한 모델을 평가한 결과, 평균 정확도가 95% 가 확인되었으며 개별 환자별로 교차 검증 방식을 진행한 결과 평균 정확도 67% 가 확인되었다.",다국어 초록 정보 없음
CNN을 활용한 수화 번역 시스템,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
PPG 센서를 이용한 CNN 기반의 음주 상태 추정 기술,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 시험용 달 궤도선 자세제어 성능 정보 이상 검출 자동화,2019,"['Korea Pathfinder Lunar Orbiter(시험용 달 궤도선)', 'Attitude Control Software(자세제어 소프트웨어)', 'Performance Verification(성능검증)', 'Machine Learning(기계학습)']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 사용한 패션 코디네이션의 설계,2019,"['Fashion coordination', 'Fashion recommendation', 'Convolutional neural networks']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 Quad Tree 기반 2D Smoke Super-resolution,2019,"['쿼드 트리', '슈퍼 레졸루션', '가속화', '연기 시뮬레이션', 'Quad Tree', 'Super-resolution', 'Acceleration', 'Smoke Simulation']","물리 기반 유체 시뮬레이션은 고해상도 연산을 위해 많은 시간이 필요하다. 이 문제를 해결하기 위해 저해상도 유체 시뮬레이션의 한계를 딤 러닝으로 보완하는 연구들이 있으며, 그중에서는 저해상도의 시뮬레이션 데이터 를 고해상도로 변환해주는 Super-resolution 분야가 있다. 하지만 기존 기법들은 전체 데이터 공간에서 밀도 데이터가 없는 부분까지 연산하므로 전체 시뮬레이션 속도 면에서 효율성이 떨어지며, 입력 해상도가 큰 경우 에는 GPU 메모리가 부족해 연산할 수 없는 경우가 발생할 수 있다. 본 연구에서는 공간 분할 법 중 하나인 쿼 드 트리를 활용하여 시뮬레이션 공간을 분할 및 분류하여 Super-resolution 하는 기법을 제안한다. 본 기법은 필요 공간만 Super-resolution 하므로 전체 시뮬레이션 가속화가 가능하고, 입력 데이터를 분할 연산하므로 GPU 메모리 문제를 해결할 수 있게 된다.","Physically-based fluid simulation takes a lot of time for high resolution. To solve this problem, there are studies that make up the limitation of low resolution fluid simulation by using deep running. Among them, Super-re solution, which converts low-resolution simulation data to high resolution is under way. However, traditional techniques require to the entire space where there are no density data, so there are problems that are inefficient in terms of the full simulation speed and that cannot be computed with the lack of GPU memory as input resolution increases. In this paper, we propose a new method that divides and classifies 2D smoke simulation data into the space using the quad tree, one of the spatial partitioning methods, and performs Super-resolution only required space. This technique accelerates the simulation speed by computing only necessary space. It also processes the divided input data, which can solve GPU memory problems."
다양한 음성 특징값을 이용한 CNN 기반의 감정 인식 모델,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 레이다 신호 자동 분류,2019,"['Radar Signal Classification', 'Jamming Technique', 'Machine Learning', 'Convolution Neural Network', '-']",국문 초록 정보 없음,"In this paper, we propose a classification method for radar signals depending on the type of threat by applying machine learning to parameter data of radar signals . Currently, the army uses a library of mapping relations between the parameters and the types of threat to recognize threat signals. This approach has certain limitations when classifying signals and recognizing new types of threat or types of threat that do not exist in the current libraries. In this paper, we propose an automatic radar signal classification method depending on the type of threat that uses only parameter data without a library. A convolutional neural network is used as the classifier and machine learning is applied to train the classifier. The proposed method does not use a library, and hence, can classify threat signals that are new or do not exist in the current library."
CNN과 영상처리기술을 사용한 과수모니터링 시스템,2019,"['agricultural production', 'feature extraction', 'Image Processing Technology', 'Convolutional neutral network']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반 물체 파지를 위한 위치 탐색,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN과 LSTM 네트워크를 활용한 한국어 QA봇,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
3차원 가상도시 모델에서 높이맵을 이용한 CNN 기반의 그림자 탐지방법,2019,"['그림자 탐지', '딥러닝', 'Shadow detection', 'Deep-learning']","최근 교육, 제조, 건설 등 다양한 응용 분야에서 사실적인 가상환경을 표현하기 위하여 실세계 영상데이터를 활용하는 사례가 증가하고 있다. 특히, 스마트 시티 등 디지털 트윈에 대한 관심이 높아지면서, 항공 영상 등 실제 촬영한 영상을 이용하여 현실감 있는 3D 도시 모델을 구축하고 있다. 그러나, 촬영된 항공 영상에는 태양에 의한 그림자가 포함되어 있으며, 그림자가 포함된 3D 도시 모델은 사용자에게 정보를 왜곡시켜 표현하는 문제를 안고 있다. 그림자를 제거하기 위하여 그동안 많은 연구가 진행되었지만, 아직 까지 해결하기 어려운 도전적인 문제로 인식되고 있다. 본 논문에서는 VWorld에서 제공하는 3차원 공간정보를 이용하여 건물의 높이맵을 포함한 가상환경 데이터 셋을 구축하고, 높이맵과 딥러닝을 이용한 새로운 그림자 탐지 방법을 제안한다. 실험 결과에 의하면, 높이맵을 사용했을 때 기존 방법보다 그림자 탐지 에러율이 감소한 것을 확인할 수 있다.","Recently, the use of real-world image data has been increasing to express realistic virtual environments in various application fields such as education, manufacturing, and construction. In particular, with increasing interest in digital twins like smart cities, realistic 3D urban models are being built using real-world images, such as aerial images. However, the captured aerial image includes shadows from the sun, and the 3D city model including the shadows has a problem of distorting and expressing information to the user. Many studies have been conducted to remove the shadow, but it is recognized as a challenging problem that is still difficult to solve. In this paper, we construct a virtual environment dataset including the height map of buildings using 3D spatial information provided by VWorld, and We propose a new shadow detection method using height map and deep learning. According to the experimental results, We can observed that the shadow detection error rate is reduced when using the height map."
효율적인 CNN을 이용한 눈 개폐 검출에 관한 연구,2019,[],"눈의 개폐 검출은 졸음 운전 감지, 온라인 강의에서 수강자 모니터링, 인간 컴퓨터 상호작용(HCI) 등에 적용될 수 있다. 최근에는 모바일 장치에 적용 가능한 효율적인 기법들이 연구되고 있으며 객체 검출 기법과 결합하여 좋은 결과를 보여주고 있다. 본 논문에서는 임베디드 환경에서 적용할 수 있는 가볍고 빠른 딥러닝 방법을 살펴보고, 눈 개폐 검출에 적용하는 방법에 대해 검토한다.",다국어 초록 정보 없음
심층 CNN을 활용한 영상 분위기 분류 및 이를 활용한 동영상 자동 생성,2019,"['Convergence', 'Machine Learning', 'Multi-class Classification', 'Mood Classification', 'Convolutional Neural Network', 'Multilayer Perceptron', '융합', '기계학습', '다중 클래스 분류', '감정 분류', '합성곱 신경망', '다층 퍼셉트론']","본 연구에서는 영상의 분위기를 심층 합성곱 신경망을 통해 8 가지로 분류하고, 이에 맞는 배경 음악을 적용하여 동영상을 자동적으로 생성하였다. 수집된 이미지 데이터를 바탕으로 다층퍼셉트론을 사용하여 분류 모델을 학습한다. 이를 활용하여 다중 클래스 분류를 통해 동영상 생성에 사용할 이미지의 분위기를 예측하며, 미리 분류된 음악을 매칭시켜 동영상을 생성한다. 10겹 교차 검증의 결과, 72.4%의 정확도를 얻을 수 있었고, 실제 영상에 대한 실험에서 64%의 오차 행렬 정확도를 얻을 수 있었다. 오답의 경우, 주변의 비슷한 분위기로 분류하여 동영상에서 나오는 음악과 크게 위화감이 없음을 확인하였다.","In this paper, the mood of images was classified into eight categories through a deep convolutional neural network and video was automatically generated using proper background music. Based on the collected image data, the classification model is learned using a multilayer perceptron (MLP). Using the MLP, a video is generated by using multi-class classification to predict image mood to be used for video generation, and by matching pre-classified music. As a result of 10-fold cross-validation and result of experiments on actual images, each 72.4% of accuracy and 64% of confusion matrix accuracy was achieved. In the case of misclassification, by classifying video into a similar mood, it was confirmed that the music from the video had no great mismatch with images."
워드 임베딩과 CNN을 사용하여 영화 리뷰에 대한 감성 분석,2019,"['Social Network Service', 'Sensitivity Prediction', 'Morpheme Analysis', 'Embedding', 'Learning']",국문 초록 정보 없음,"Reaction of people is importantly considered about specific case as a social network service grows. In the previous research on analysis of social network service, they predicted tendency of interesting topic by giving scores to sentences written by user. Based on previous study we proceeded research of sentiment analysis for social network service’s sentences, which predict the result as positive or negative for movie reviews. In this study, we used movie review to get high accuracy. We classify the movie review into positive or negative based on the score for learning. Also, we performed embedding and morpheme analysis on movie review. We could predict learning result as positive or negative with a number 0 and 1 by applying the model based on learning result to social network service. Experimental result show accuracy of about 80% in predicting sentence as positive or negative."
이미지 유사도 측정을 위한 CNN 기반 이미지 임베딩 모델 비교 분석,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
얼굴인식을 위한 다중입력 CNN의 기본 구현,2019,[],국문 초록 정보 없음,"Face recognition is an extensively researched area of computer vision. Visible, infrared, thermal, and 3D modalities have been used against various challenges of face recognition such as illumination, pose, expression, partial information, and disguise. In this paper we present a multi-modal approach to face recognition using convolutional neural networks. We use visible and thermal face images as two separate inputs to a multi-input deep learning network for face recognition. The experiments are performed on IRIS visible and thermal face database and high face verification rates are achieved."
비트평면 영상을 이용한 이진 CNN 연산 알고리즘,2019,"['Bit-plane', 'Binary CNN', 'Computing Power', 'Embedded System', 'Binary kernel', 'XOR']","본 논문에서는 이진영상과 이진커널을 사용하여 컨볼루션, 풀링, ReLU 연산을 수행하는 이진 CNN 연산 알고리즘을 제안한다. 256 그레이스케일 영상을 8개의 비트평면으로 분해하고, -1과 1로 구성되는 이진커널을 사용하는 방법이다. 이진영상과 이진커널의 컨볼루션 연산은 가산과 감산으로 수행한다. 논리적으로는 XNOR 연산과 비교기로 구성되는 이진연산 알고리즘이다. ReLU와 풀링 연산은 각각 XNOR와 OR 논리연산으로 수행한다. 본 논문에서 제안한 알고리즘의 유용성을 증명하기 위한 실험을 통해, CNN 연산을 이진 논리연산으로 변환하여 수행할 수 있음을 확인한다. 이진 CNN 알고리즘은 컴퓨팅 파워가 약한 시스템에서도 딥러닝을 구현할 수 있는 알고리즘으로 스마트 폰, 지능형 CCTV, IoT 시스템, 자율주행 자동차 등의 임베디드 시스템에서 다양하게 적용될 수 있는 시스템이다.","In this paper, we propose an algorithm to perform convolution, pooling, and ReLU operations in CNN using binary image and binary kernel. It decomposes 256 gray-scale images into 8 bit planes and uses a binary kernel consisting of -1 and 1. The convolution operation of binary image and binary kernel is performed by addition and subtraction. Logically, it is a binary operation algorithm using the XNOR and comparator. ReLU and pooling operations are performed by using XNOR and OR logic operations, respectively. Through the experiments to verify the usefulness of the proposed algorithm, We confirm that the CNN operation can be performed by converting it to binary logic operation. It is an algorithm that can implement deep running even in a system with weak computing power. It can be applied to a variety of embedded systems such as smart phones,  intelligent CCTV, IoT system, and autonomous car."
CNN 알고리즘을 이용한 체커스위치 불량 검출 시스템 개발,2019,"['Error Detection(불량 검출)', 'Machine Learning(머신러닝)', 'CNN', 'Checker Switch(체커스위치)']",국문 초록 정보 없음,"Various automation studies have been conducted to detect defective products based on product images. In the case of machine vision-based studies, size and color error are detected through a preprocessing process. A situation may arise in which the main features are removed during the preprocessing process, thereby decreasing the accuracy. In addition, complex systems are required to detect various kinds of defects. In this study, we designed and developed a system to detect errors by analyzing various conditions of defective products. We designed the deep learning algorithm to detect the defective features from the product images during the automation process using a convolution neural network (CNN) and verified the performance by applying the algorithm to the checker-switch failure detection system. It was confirmed that all seven error characteristics were detected accurately, and it is expected that it will show excellent performance when applied to automation systems for error detection."
블레이드의 표면 결함 검출을 위한 Faster R-CNN 딥러닝 모델 구축,2019,"['블레이드', '딥러닝', 'Faster R-CNN', '객체 인식', '표면 결함', '터빈엔진', 'Blade', 'Deep learning', 'Faster R-CNN', 'Object detection', 'Surface damage', 'Turbine engine']","컴퓨터 성능 향상으로 다양한 분야에서 딥러닝을 활용한 연구가 활발히 진행되고 있으며 최근에는 구조물 안전성 평가 연구에도 그 적용이 이루어지고 있다. 특히 터빈의 내부 블레이드는 분리가 쉽지 않고 어두운 주변 환경으로 인해 블레이드의 표면 결함 검출은 전문 인력의 경험에 의존하고 있으며, 점검시간도 상당히 소요되고 있는 실정이다. 따라서, 본 연구에서는 딥러닝 기술을 적용하여 터빈 구조의 부재 중 하나인 내부 블레이드에 발생하는 결함을 검출할 수 있는 효율적인 방법을 제시하였다. Faster R-CNN 인공신경망 기법을 활용하여 결함의 이미지 데이터를 학습하였고 부족한 이미지는 필터링과 Image Data Generator를 이용하여 데이터를 확장하였다. 그 결과 블레이드의 결함을 학습한 딥러닝 모델은 평균적으로 약 96.1%의 정확도와 재현율은 95.3%, 정밀도는 96%의 성능을 보였다. 재현율을 통해 제시된 딥러닝 모델이 결함을 탐지하지 못하는 경우는 4.7% 로 나타났다. 재현율의 성능은 여러 환경의 많은 결함 이미지 데이터를 수집하고 확장하여 딥러닝 학습에 적용함으로써 더욱 향상되리라 판단된다. 이러한 실제 블레이드의 결함 이미지 데이터 확보와 학습을 통해 향후 터빈엔진 정비에 적용 가능한 결함 검출 시스템으로 발전할 수 있을 것이다.","As computer performance improves, research using deep learning are being actively carried out in various fields. Recently, deep learning technology has been applying to the safety evaluation for structures. In particular, the internal blades of a turbine structure requires experienced experts and considerable time to detect surface damages because of the difficulty of separation of the blades from the structure and the dark environmental condition. This study proposes a Faster R-CNN deep learning model that can detect surface damages on the internal blades, which is one of the primary elements of the turbine structure. The deep learning model was trained using image data with dent and punch damages. The image data was also expanded using image filtering and image data generator techniques. As a result, the deep learning model showed 96.1% accuracy, 95.3% recall, and 96% precision. The value of the recall means that the proposed deep learning model could not detect the blade damages for 4.7%. The performance of the proposed damage detection system can be  further improved by collecting and extending damage images in various environments, and finally it can be applicable for turbine engine maintenance."
RED-CNN에 기반한 X-ray dose에 따른 CT 영상에서의 denoising 평가,2019,[],국문 초록 정보 없음,"Reducing the radiation dose to the patients has been an important issue in X-ray CT research. Although several iterative based techniques have been proposed, they are time-consuming, and sometime need to find a proper optimization parameter for the given tasks. Recently, convolutional neural network has shown a big success in denoising of natural images, and its application on low dose CT denoising using RED-CNN (Residual Encode-Decode Convolutional Neural Network) shows a promising result. In this work, we evaluate the performance of the RED-CNN in low dose CT denoising for different dose levels, and how its image quality changes after passing through the RED-CNN."
에너지인터넷에서 1D-CNN과 양방향 LSTM을이용한 에너지 수요예측,2019,"['CNN', 'LSTM', '1D-ConvBLSTM', 'Energy prediction', 'Internet of Energy']","에너지인터넷 기술의 발전과 다양한 전자기기의 보급으로 에너지소비량이 패턴이 다양해짐에 따라 수요예측에 대한 신뢰도가 감소하고 있어 발전량 최적화 및 전력공급 안정화에 문제를 야기하고 있다. 본 연구에서는 고신뢰성을 갖는 수요예측을위해 딥러닝 기법인 Convolution neural network(CNN)과 Bidirectional Long Short-Term Memory(BLSTM)을 융합한1Dimention-Convolution and Bidirectional LSTM(1D-ConvBLSTM)을 제안하고, 제안한 기법을 활용하여 시계열 에너지소비량대한 소비패턴을 효과적으로 추출한다. 실험 결과에서는 다양한 반복학습 횟수와 feature map에 대해서 수요를 예측하고 적은 반복학습 횟수로도 테스트 데이터의 그래프 개형을 예측하는 것을 검증한다.","As the development of internet of energy (IoE) technologies and spread of various electronic devices have diversifiedpatterns of energy consumption, the reliability of demand prediction has decreased, causing problems in optimization ofpower generation and stabilization of power supply. In this study, we propose a deep learning method, 1-Dimention-Convolution and Bidirectional Long Short-Term Memory (1D-ConvBLSTM), that combines a convolution neuralnetwork (CNN) and a Bidirectional Long Short-Term Memory(BLSTM) for highly reliable demand forecasting byeffectively extracting the energy consumption pattern. In experimental results, the demand is predicted with the proposeddeep learning method for various number of learning iterations and feature maps, and it is verified that the test data ispredicted with a small number of iterations."
CNN 기반 당뇨병성 망막병증 특징 추출 및 심각도 등급 분류,2019,"['Faster R-CNN', 'Random Forest', 'Classification', '비증식성 당뇨병성 망막병증', '의료 영상처리']","비증식성 당뇨성 망막 병증은 당뇨병 환자의 대표적인 합병증으로서 시력저하와 실명을 일으키는 주요한 원인 중 하나로 알려져 있다. 당뇨성 망막 병증을 자동으로 탐지하는 연구는 지속적으로 이루어지고 있으나, 여기에 추가적으로 심각도의 등급을 자동으로 분류하는 시스템에 대한 연구의 필요성 또한 대두되고 있다. 본 논문에서는 당뇨성 망막 병증의 병리적 특징인 미세혈관류, 망막 출혈과 경성 삼출물을 검출하기 위해 Faster R-CNN 기술을 적용하여 해당 병리 증상에 대해 자동으로 검출하는 시스템을 제안하였다. 검출된 특징에 대해 히스토그램 평활화 등의 전처리 과정을 수행하였고, 이 데이터를 이용해 랜덤포레스트 분류기를 학습하고 테스트함으로써 병리증상의 특징을 기반으로 한 심각도 등급을 자동 분류하는 시스템을 고안하였다. 이를 통해 검사자의 주관적 해석 개입을 방지하고 객관적 자료와 지표를 이용하여 구체적으로 판단할 수 있도록 하고 의료 영상 분석 분야 업무의 효율성을 높일 수 있도록 하였다. 본 논문에서 제안하는 방법을 이용해 테스트 안저 영상 103장에 대하여 등급 별 분류 실험을 한 결과 98%의 정확도를 보이는 분류 시스템을 구현할 수 있었고, 이는 향 후 다수의 의미 있는 데이터가 수집된다면 더 높은 완성도를 보일 수 있을 것으로 예상된다.","Non-proliferative diabetic retinopathy is a representative complication of diabetic patients and is known to be a major cause of impaired vision and blindness. There has been ongoing research on automatic detection of diabetic retinopathy; however, there is also a growing need for research on an automatic severity classification system. This study proposes an automatic detection system for pathological symptoms of diabetic retinopathy such as microaneurysm, retinal hemorrhage, and hard exudate by applying the Faster R-CNN technique. An automatic severity classification system based on the features of pathological symptoms of diabetic retinopathy was devised by training and testing a random forest classifier based on the data obtained through preprocessing, such as histogram smoothing of the detected features. The proposed system enables accurate judgment using objective data and indices while avoiding the subjective interpretation of testers and improving the efficiency of medical image analysis. An experiment of classifying 103 test fundus images with the proposed classification system showed 98% accuracy. The proposed automatic severity classification is expected to show a higher degree of accuracy if a greater amount of meaningful data can be collected in the future."
컬러 히스토그램과 CNN 모델을 이용한 객체 추적,2019,"['CNN', 'GOTURN', 'Mean-shift', 'SVM', 'Color histogram.']","본 논문에서는 컬러 히스토그램과 CNN 모델을 이용한 객체 추적 기법 알고리즘을 제안한다. CNN (convolutional neural network) 모델 기반 객체 추적 알고리즘인 GOTURN (generic object tracking using regression network)의 정확도를 높이기 위해 컬러 히스토그램 기반 mean-shift 추적 알고리즘을 합성하였다. 두 알고리즘을 SVM (support vector machine)을 통해 분류하여 추적 정확도가 더 높은 알고리즘을 선택하도록 설계하였다. Mean-shift 추적 알고리즘은 객체 추적에 실패할 때 경계 박스가 큰 범위로 움직이는 경향이 있어 경계 박스의 이동거리에 제한을 두어 정확도를 향상 시켰다. 또한 영상 평균 밝기, 히스토그램 유사도를 고려하여 두 알고리즘의 추적 시작 위치를 초기화하여 성능을 높였다. 결과적으로 기존 GOTURN 알고리즘보다 본 논문에서 제안한 알고리즘이 전체적으로 정확도가 1.6% 향상되었다.","In this paper, we propose an object tracking algorithm based on color histogram and convolutional neural network model. In order to increase the tracking accuracy, we synthesize generic object tracking using regression network algorithm which is one of the convolutional neural network model-based tracking algorithms and a mean-shift tracking algorithm which is a color histogram-based algorithm. Both algorithms are classified through support vector machine and designed to select an algorithm with higher tracking accuracy. The mean-shift tracking algorithm tends to move the bounding box to a large range when the object tracking fails, thus we improve the accuracy by limiting the movement distance of the bounding box. Also, we improve the performance by initializing the tracking start positions of the two algorithms based on the average brightness and the histogram similarity. As a result, the overall accuracy of the proposed algorithm is 1.6% better than the existing generic object tracking using regression network algorithm."
Faster R-CNN 기반의 관심영역 유사도를 이용한 후방접근차량 검출 연구,2019,"['Deep lerning', 'Faster r-cnn', 'Agricultural machine', 'Vehicle detection', 'Structure similarity']",본 논문에서는 농업 기계 시스템에서 사용하기 위한 딥러닝 알고리즘 기반의 프레임 내의 관심 영역 유사성을 이용한 새로운 후방 접근 차량 검출 알고리즘을 제안한다. 농업 기계 시스템은 후방에서 접근하는 차량만 검출해야 한다. 지나가는 자동차가 검출되면 혼란을 야기할 수 있다. 논문에서는 차량 검출을 위해 딥러닝에서 뛰어난 검출률을 나타내는 FasterR-CNN 모델을 사용하였다. 딥러닝은 뒤에서 접근하는 차량뿐만 아니라 지나가는 차량도 검출하므로 긍정오류 차량을 배제해야 한다. 본 논문에서 이를 해결하기 위해 검출된 프레임에서 관심 영역에 대한 유사성과 평균 에러를 피라미드 형태로 이용하여 접근하는 자동차만 검출하는 알고리즘을 제안하였다. 실험을 통하여 제안된 방법이 평균 98.8%의 높은 검출률을 나타내었다.,"In this paper, we propose a new algorithm to detect rear-approaching vehicle using the frame similarity of ROI(Regionof Interest) based on deep learning algorithm for use in agricultural machinery systems. Since the vehicle detectionsystem for agricultural machinery needs to detect only a vehicle approaching from the rear. we use Faster R-CNN modelthat shows excellent accuracy rate in deep learning for vehicle detection. And we proposed an algorithm that uses theframe similarity for ROI using constrained conditions. Experimental results show that the proposed method has adetection rate of 99.9% and reduced the false positive values."
Xilinx DPU를 사용한 CNN 추론 분석,2019,[],"지능형 IoT 애플리케이션들을 효과적으로 사용하기 위해서는 추론 엔진을 Edge device로 포팅하는 것이 필수적이다. 그러나 컴퓨팅 자원이 제한적인 Edge 환경에서 computational cost가 상당히 큰 CNN 추론을 실시간으로 하는 것은 쉽지 않다. 이에, CNN 추론의 하드웨어 가속화의 필요성이 제기되어 활발한 연구가 진행되고 있으며, Xilinx, Intel 등에서도 하드웨어 가속화를 도와주는 툴을 개발하여 지속적으로 업그레이드하고 있다. 본 연구에서는 CIFAR-10 데이터베이스의 테스트 이미지 10,000개를 Xilinx 사의 CNN 추론 엔진인 DPU를 사용하여 Zynq UltraScale+ 보드에서 추론해보고, DPU 아키텍처에 따른 결과를 비교·분석했다. 병렬처리 수준을 높게 한 DPU는 그렇지 않은 DPU보다 소비전력 및 자원 사용량이 3배 이상 높았지만, 1.65배 좋은 성능을 보여 Trade-off 관계를 확인할 수 있었다.",다국어 초록 정보 없음
두 개의 이종 CNN 융합을 이용한 차선 검출,2019,"['lane detection', 'deep learning', 'convolutional neural networks', 'transfer learning']",국문 초록 정보 없음,"Lane detection is essential in many applications including autonomous navigation and intelligent vehicles. Recently, theperformance of image recognition and detection has been remarkably improved by Convolutional Neural Networks (CNN). In thispaper, we present a method for lane detection by combining the results of two CNN architectures. The first CNN detects lanelocations on the image via a sliding window, while the second one detects the vanishing point and the lane angle. By combining theresults of these two structures, we present a method to improve lane detection results by comparing the lane detection result fromeach structure."
한자 이미지 분할 기법 및 Mask R-CNN 성능 평가,2019,"['Character extraction', 'Mask R-CNN', 'Image segmentation', 'Computer vision', 'AI']","인공지능 진보에 따라서 컴퓨터 비전을 포함한 다양한 분야에서 인공지능을 활용하고 있다. 특히주어진 이미지에서 객체와 배경을 분리하여 인식하는 기법들이 발달됨에 따라서 기존 객체 분할로사용되던 기술들이 가지고 있던 단점들을 극복할 수 있는 방안으로 활용이 가능하다. 기존의 기술의경우 한자와 같이 특별한 객체를 정확하게 검출하지 못하고, 영역분할 요류 및 영역 겹침 오류가나타난다. 본 논문은 한자 사전 작업에 앞서 고서 스캔 이미지에서 활자를 검출 및 추출에 기존알고리즘이 가지는 제약점을 살펴보며, 활자 검출에 있어서 mask R-CNN의 활용 가능성 및 성능에대한 평가하여 기존 알고리즘 대비 mask R-CNN의 활용성이 높음을 확인하였다.",다국어 초록 정보 없음
치매 진단을 위한 Faster R-CNN 활용 MRI 바이오마커 자동 검출 연동 분류 기술 개발,2019,"['Computer-Aided Diagnosis', ""Alzheimer's Disease"", 'Deep Convolution Neural Network', 'Faster R-CNN', 'Biomarker']",국문 초록 정보 없음,"In order to diagnose and prevent Alzheimer's Disease (AD), it is becoming increasingly important to develop a CAD(Computer-aided Diagnosis) system for AD diagnosis, which provides effective treatment for patients by analyzing 3D MRI images. It is essential to apply powerful deep learning algorithms in order to automatically classify stages of Alzheimer's Disease and to develop a Alzheimer's Disease support diagnosis system that has the function of detecting hippocampus and CSF(Cerebrospinal fluid) which are important biomarkers in diagnosis of Alzheimer's Disease. In this paper, for AD diagnosis, we classify a given MRI data into three categories of AD, mild cognitive impairment, and normal control according by applying 3D brain MRI image to the Faster R-CNN model and detect hippocampus and CSF in MRI image. To do this, we use the 2D MRI slice images extracted from the 3D MRI data of the Faster R-CNN, and perform the widely used majority voting algorithm on the resulting bounding box labels for classification. To verify the proposed method, we used the public ADNI data set, which is the standard brain MRI database. Experimental results show that the proposed method achieves impressive classification performance compared with other state-of-the-art methods."
Mask R-CNN을 이용한 항공 영상에서의 도로 균열 검출,2019,[],국문 초록 정보 없음,"Conventional crack detection methods have a problem of consuming a lot of labor, time and cost. To solve these problems, an automatic detection system is needed to detect cracks in images obtained by using vehicles or UAVs(unmanned aerial vehicles). In this paper, we have studied road crack detection with unmanned aerial photographs. Aerial images are generated through preprocessing and labeling to generate morphological information data sets of cracks. The generated data set was applied to the mask R-CNN model to obtain a new model in which various crack information was learned. Experimental results show that the cracks in the proposed aerial image were detected with an accuracy of 73.5% and some of them were predicted in a certain type of crack region."
임의 차원 데이터 대응 Dynamic RNN-CNN 멀웨어 분류기,2019,['F1'],국문 초록 정보 없음,"This study proposes a malware classification model that can handle arbitrary length input data using the Microsoft Malware Classification Challenge dataset. We are based on imaging existing data from malware. The proposed model generates a lot of images when malware data is large, and generates a small image of small data. The generated image is learned as time series data by Dynamic RNN. The output value of the RNN is classified into malware by using only the highest weighted output by applying the Attention technique, and learning the RNN output value by Residual CNN again. Experiments on the proposed model showed a Micro-average F1 score of 92% in the validation data set. Experimental results show that the performance of a model capable of learning and classifying arbitrary length data can be verified without special feature extraction and dimension reduction."
방사선 디텍터에서 CNN 기법을 사용한 픽셀 결함 보정,2019,[],국문 초록 정보 없음,"In the medical imaging, TFT(thin film transistor) panels are used to obtain high-quality X-ray images for flat panel radiography detectors. However, pixel defects occur in the TFT panels and degrade the image qualities. In order to produce high-quality images, pixel defects must be corrected. Techniques of bilinear interpolation and template matching are currently used. In this paper, we propose a pixel-defect correction algorithm based on a CNN (convolutional neural network) deep learning structure. The proposed algorithm was compared with the conventional template matching scheme, and showed better performance qualitatively and quantitatively."
Text-CNN 알고리즘 적용한 교육장터 플랫폼 기반 맞춤형 교육 컨텐츠 추천 메커니즘 개발,2019,[],"현재에는 다양한 교육 서비스, 자료, 기구가 개발되어 산재되어 있다. 그래서 학생에 맞는 맞춤형 교육으로 학생들의 적성, 진로에 관한 안목을 높이고, 교육의 질을 높이는 것이 중요하다. 기존의 교육플랫폼은 교육 프로그램 및 교구 자료들이 여러 곳에 분산되어 있어 자료 선택이 어렵다. 이를 해결하기 위하여 맞춤형 교육 서비스 자료, 기구 등을 선생님(사용자)들에게 추천하는 메커니즘을 제안한다. 본 새로운 플랫폼에서 CNN 알고리즘을 통해 학급, 학생들에게 맞는 추천 컨텐츠를 제공한다. 이 메커니즘을 통해 자료 선택에 도움을 주어 교육의 질을 높이고자 한다.",다국어 초록 정보 없음
MAV 환경에서의 CNN 기반 듀얼 채널 음향 향상 기법,2019,['2'],"최근 드론과 같은 멀티로터 UAV(Unmanned Aerial Vehicle, 무인항공기)의 산업 범위가 크게 확대됨에 따라, UAV를 활용한 데이터의 수집 및 처리, 분석에 대한 요구도 함께 증가하고 있다. 그러나 UAV를 이용해서 수집된 음향 데이터는 UAV의 모터 소음과 바람 소리 등으로 크게 손상되어, 음향 데이터의 처리 및 분석이 어렵다는 단점이 있다. 따라서 본 논문에서는 UAV에 연결된 마이크를 통해 수신된 음향 신호로부터 목표 음향 신호의 품질을 향상시킬 수 있는 방법에 대해 연구하였다. 본 논문에서는 기존의 단일 채널 음향 향상 기술 중 하나인 densely connected dilated convolutional network를 음향 신호의 채널 간 특성을 반영할 수 있도록 확장하였으며, 그 결과 SDR, PESQ, STOI과 같은 평가 지표에서 기존 연구 대비 좋은 성능을 보였다.",다국어 초록 정보 없음
CNN 기법을 활용한 터널 암판정 예측기술 개발,2019,"['Deep Learning', 'VGG16', 'Convolutional Neural Network', 'Face Mapping', 'RMR']",국문 초록 정보 없음,"Quick identification of the condition of tunnel face and optimized determination of support patterns during tunnel excavation in underground construction projects help engineers prevent tunnel collapse and safely excavate tunnels. This study investigates a CNN technique for quick determination of rock quality classification depending on the condition of tunnel face, and presents the procedure for rock quality classification using a deep learning technique and the improved method for accurate prediction. The VGG16 model developed by tens of thousands prestudied images was used for deep learning, and 1,43769 tunnel face images were used to classify the five types of rock quality condition. In this study, the prediction accuracy using this technique was up to 83.9%. It is expected that this technique can be used for an error-minimizing rock quality classification system not depending on experienced professionals in rock quality rating."
A Study on Fault Classification of Machining Center using Acceleration Data Based on 1D CNN Algorithm,2019,"['Machining Center(머시닝센터)', 'Machine Learning(머신러닝)', 'Fault Signal Classification(고장신호 분류)', 'CNN(합성곱 신경망)']",국문 초록 정보 없음,"The structure of the machinery industry due to the 4th industrial revolution is changing from precision and durability to intelligent and smart machinery through sensing and interconnection(IoT). There is a growing need for research on prognostics and health management(PHM) that can prevent abnormalities in processing machines and accurately predict and diagnose conditions. PHM is a technology that monitors the condition of a mechanical system, diagnoses signs of failure, and predicts the remaining life of the object. In this study, the vibration generated during machining is measured and a classification algorithm for normal and fault signals is developed. Arbitrary fault signal is collected by changing the conditions of un stable supply cutting oil and fixing jig. The signal processing is performed to apply the measured signal to the learning model. The sampling rate is changed for high speed operation and performed machine learning using raw signal without FFT. The fault classification algorithm for 1D convolution neural network composed of 2 convolution layers is developed."
Faster R-CNN과 DenseNet을 이용한 도형 상표 비엔나 분류 자동화 연구,2019,[],이미지 형식으로 등록되는 상표의 특성상 상표의 검색에는 어려움이 따른다. 특허청은 도형 상표의 검색을 용이하게 하기 위해 상표가 포함하고 있는 구성요소에 도형분류코드를 부여한다. 하지만 도형 상표에 포함된 이미지를 확인하고 분류코드를 부여하는 과정은 사람이 직접 수행해야 한다는 어려움이 따른다. 이에 본 논문에서는 딥러닝을 이용하여 자동으로 도형 상표 내 객체를 인식하고 분류코드를 부여하는 방안을 제안한다. DenseNet을 이용하여 중분류를 먼저 예측한 후 각 중분류에 해당하는 Faster R-CNN 모델을 이용하여 세분류 예측을 수행하였다. 성능평가를 통해 비엔나분류 중분류별 평균 74.49%의 예측 정확도를 확인하였다.,다국어 초록 정보 없음
Faster R-CNN기법을 이용한 비정상 침입탐지 모델 연구,2019,"['Intrusion Detection System', 'Convolutional Neural Network', 'Faster R-CNN', 'KDD CUP 1999']",국문 초록 정보 없음,다국어 초록 정보 없음
이종 CNN 알고리즘을 이용한 물체 인식과 로봇의 파지 제어,2019,"['deep learning', 'instance segmentation', 'fully convolutional network', 'object detection', 'ROS']",국문 초록 정보 없음,"The detection of robot manipulator’s object-grasping point is the most important step in precise handling of object. To grasp object needs some important parameters, which are object’s center coordinates (x, y, z) and width, yaw angle. In this paper, we predict not individual parameters but grasping area by using Segmentation Algorithm. Combining Mask R-CNN algorithm and Fully Convolutional Net algorithm and adding them to ROS, we construct ROS architecture. And, we apply them to control moving robot’s manipulator in grasping objects. So, we can reduce processing time for detecting object and improve applicability of this new method in robotic grasping control."
Mask R-CNN기법을 활용한 목재 표면 옹이 구획화,2019,[],"목재 품질의 객관적 평가 및 목재 생산의 고속화를 위해서는 컴퓨터 비전을 활용한 목재 표면 화상분석 자동화가 필요하다. 딥러닝(Deep Learning) 기술은 최근 컴퓨터 비전을 통한 화상 분석 및 패턴인식 분야에서 높은 정확도와 속도로 인해 그 활용도가 높아지고 있다. 따라서 본 연구에서는 딥러닝 기술 중 화상의 구획화에 높은 성능을 보이는 알려진 합성곱 신경망(Convolutional Neural Network)을 이용하여 목재 표면 옹이를 구획화하고, 그 종류를 분류하였다. 본 연구에서 사용한 목재 재면 사진은 낙엽 송, 잣나무, 소나무, 삼나무, 편백, 더글라스 퍼, 라디에타 파인에서 획득한 938개의 제재목 사진을 사용 하였다. 제재목 사진에서 추출한 옹이 이미지는 1,172개로, 4 가지 종류로 분류하였다. 옹이의 종류와 위치에 대한 데이터베이스를 통해 제재목 표면의 옹이를 구획화하여 표시하고, 그 종류를 분류하는 알고리즘 학습을 진행하였다. 학습에 사용한 Mask R-CNN(Regions with Convolutional Neural Network) 모델은 resnet101을 이용하여 Feature Pyramid Network를 토대로 옹이 위치 예측 학습과 옹이 종류 분류 학습을 동시에 진행하였다. 목재 표면의 옹이 구획화 학습을 진행한 결과, 옹이 종류별 이미지의 편차가 존재하며, 옹이의 크기가 다양함에 불구하고 높은 정확도로 목재 표면의 옹이 탐지가 가능하였다. 200번의 반복학습결과, 학습이 반복될수록 학습 이미지셋에 과적합하는 현상이 발생하여 목재 문양이 옹이로 탐지되는 경우가 발생하였다. 하지만 높은 정확도로 분류가 가능하였기 때문에 다양한 옹이 형태를 추가로 학습시킨다면 더 높은 정확도로 옹이 구획화가 가능할 것으로 기대된다.",다국어 초록 정보 없음
노인 홈 케어를위한 CNN 기반의 비정상 인간 활동 인식 시스템,2019,"['Smart homes', 'Convolutional Neural Networks', 'Abnormal behavior detection']",국문 초록 정보 없음,"Changes in a person's health affect one's lifestyle and work activities. According to the World Health Organization (WHO), abnormal activity is growing faster in people aged 60 or more than any other age group in almost every country. This trend steadily continues and expected to increase further in the near future. Abnormal activity put these people at high risk of expected incidents since most of these people live alone. Human abnormal activity analysis is a challenging, useful and interesting problem among the researchers and its particularly crucial task in life and health care areas. In this paper, we discuss the problem of abnormal activities of old people lives alone at home. We propose Convolutional Neural Network (CNN) based model to detect the abnormal behaviors of elderlies by utilizing six simulated action data from daily life actions."
모바일 어플리케이션을 위한 CNN 기반 성별 인식,2019,"['Machine Learning', 'Neural Network', 'Deep Learning']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN 아키텍처의 얼굴 표정 기반 감정 예측 성능 비교,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 을 활용한 서울 경복궁 모바일 관광 가이드 시스템 개발,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
R-CNN을 이용한 다중 차량 검출 연구,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 및 Word2Vec 기반 이미지 연관 해시태그 추진  모델,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반 열 분포 영상을 이용한 배터리 SOC 추정 연구,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
감정 인식을 위한 합성곱신경망(CNN) 최적화,2019,[],국문 초록 정보 없음,"In this paper, we propose a convolution neural network structure optimized for facial recognition.   We optimized the structure of the hidden layer to reduce the amount of learning computation, and as a result, the learning speed was improved. In addition, we improved the emotional recognition accuracy through learning parameters and data argumentation. As a result of the final learning experiment, the predicated rate was 84.9% and the learning speed was improved compared to VGG network [1]."
CNN 기반 감성 분류에서 단어 표상 기법의 효용성 평가,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
Mask R-CNN을 활용한 한국 문화유산(도자기와 토기) 자동 검출 연구,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
다양한 변수에 따른 CNN 성능 분석,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
에지 분류 CNN 을 이용한 U-Net 기반 에지 검출,2019,"['edge', 'convolutional neural networks', 'deep learning']",국문 초록 정보 없음,"Edge detection is the first necessary step in image processing for object segmentation, detection, and recognition. TheCanny algorithm is widely used filter-based approach, but it requires the correct adjustment of its parameters according to thevariations in images. In this paper, we propose a method that is consisted of two steps for the robust detection of edges in an image.The proposed algorithm adopts convolutional neural networks that can handle the diverse variations caused by illumination, pose,and scale change. First, we train a convolutional neural network to decide whether a given input edge image is good or not. We cangenerate as many training images as we want using this network. Finally, U-Net is used to generate an edge image using a gray imageas input. Experimental results show the robustness of the proposed algorithm for images acquired under outdoor and indoor environments."
복수의 엣지 디바이스에서의 CNN 모델 분산 처리를 위한 축소된 분류 모델 활용에 대한 분석,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
영상 노이즈 제거를 위한 CNN 구조의 손실 함수 개선 방안 연구,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
유전 알고리즘을 이용한 CNN 내 가중치의 최적화,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
Convolutional Neural Network (CNN) 모형을 기반으로 한 중국과 한반도의 NPP추정,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
빗줄기 제거를 위한 잔차 네트워크와 Fast R-CNN을 통한 폭우 환경에서의 객체 검출 성능 비교,2019,"['Rain Removal', 'Object Detection', 'Deep Learning']","최근 인공지능 기술을 기반으로 자율 주행 기술이 발달함에 따라 객체 검출 기법에 대한 연구가 활발히 진행되고 있다. 하지만 컴퓨터 비전 기반의 객체 검출 기법은 폭설, 폭우, 안개와 같은 악천 후 환경에 따라 상당한 영향을 받게 된다. 악천후 조건에서 수집된 영상에서 객체 검출 성능을 높이기 위해서는 빗줄기 패턴이 객체 검출에 필요한 특징 추출에 부정적인 영향을 미치는지를 조사할 필요가 있다. 기존의 연구는 객체 검출과 빗줄기 제거 과정이 서로 독립적으로 연구되고 있으므로 폭우 환경에서의 빗줄기 패턴과 객체 검출 성능과의 연관성을 제시하지 못하고 있다. 따라서 본 논문에서는 빗줄기 패턴이 객체 검출 성능에 미치는 영향을 조사하고자 한다. 이를 위해, 빗줄기 제거를 위한 잔차 네트워크와 객체 검출을 위한 Fast RCNN 네트워크를 각각 학습한 후, 빗줄기 제거 전후의 객체 검출 성능을 정량적으로 비교하고자 한다. 실험을 통해 빗줄기 영상에서 빗줄기를 제거한 후에 평균정밀도가 11.1만큼 향상된 것을 확인하였다.","Recently, as the autonomous driving technology is developed based on the artificial intelligence, the study on the object detection is being actively conducted. However, computer vision-based object detection methods are significantly affected by bad weather conditions such as heavy snow, heavy rain, and fog. To improve the performance of object detection for images collected under bad weather conditions, it is necessary to investigate whether the rain pattern has a negative effect on feature extraction required for object detection. Existing studies have not been able to suggest the correlation between rain patterns and object detection performance in heavy rain environment because object detection and rain removal are studied independently. Therefore, this paper investigates the effect of rain patterns on object detection performance. To achieve this, residual network for rain removal and Fast RCNN network for object detection are trained separately, and then object detection performance before and after rain removal is compared. Through experiments, it is confirmed that average precision was improved by 11.1 after removing the rain streaks from rain images."
이미지 센서를 위한 Bayer Pattern 기반 Face Detection CNN,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
Performance Comparison of the Optimizers in a Faster R-CNN Model for Object Detection of Metaphase Chromosomes,2019,[],국문 초록 정보 없음,"In this paper, we compares the performance of the gredient descent optimizers of the Faster Region-based Convolutional Neural Network (R-CNN) model for the chromosome object detection in digital images composed of human metaphase chromosomes. In faster R-CNN, the gradient descent optimizer is used to minimize the objective function of the region proposal network (RPN) module and the classification score and bounding box regression blocks. The gradient descent optimizer. Through performance comparisons among these four gradient descent optimizers in our experiments, we found that the Adamax optimizer could achieve the mean average precision (mAP) of about 52% when considering faster R-CNN with a base network, VGG16. In case of faster R-CNN with a base network, ResNet50, the Adadelta optimizer could achieve the mAP of about 58%."
인공위성 자료를 이용한 Faster R-CNN 기반 태풍 식별 및 강도․중심위치 산출,2019,"['Deep Learning', 'Object Detection', 'Convolutional Neural Network', 'Typhoon Intensity and Center Estimation']",국문 초록 정보 없음,"Locating the center and predicting the intensity of typhoons are critical issues to prevent damages caused bythem. In this paper, we propose two models based on Faster R-CNN for predicting the intensity and the centerlocation of typhoons via satellite images without pre-processing; one of the models utilizes an only single-channeland the other uses whole four channels. The biggest advantage of proposed models is that it can produce both thecenter coordinates and the class of the intensity regardless of the number of typhoons occurred, which never havebeen studies yet. Compared to the single-channel model, multi-channel model achieves higher typhoon detection ratethan single-channel model since it can extract various aspects of features from multiple channels through CNNbackbone network."
사영 변환하의 합성 이미지를 이용한Mask R-CNN 기반 QR 코드 검출,2019,"['QR code', '2D barcode', 'deep learning', 'convolutional neural networks', 'transfer learning']",국문 초록 정보 없음,"Various types of 2D barcodes including QR code, Data Matrix are widely used in diverse industries. Recently, QR code isadopted in mobile phone. They require QR code occupy some amount of area on the image to correctly operate. In other applicationof mobile robot navigation where QR code is used as landmarks, we need to detect QR code in various scale and lighting condition.Traditional approaches operate well under restricted conditions also they require the setting of many parameters. In this paper, wedeal with the detection of QR code in wild including various lighting condition and scale. We adopt the Mask R-CNN [11] for thedetection of QR code. It requires many training images to have good performance. We present a method that uses composite imageswhich is made under general perspective transform. QR code under reference poses and real images are composited by the presentedmethod. We present various experimental results under diverse configuration of hyperparameters. Sequential step of first trainingusing many composite images then finally training using real images show the best performance. Experimental results show thefeasibility of presented approach."
영상에서 패치기반 CNN 모형을 이용한 잡음제거,2019,"['딥러닝', '잡음영상', '잡음제거', 'convolutional neural network', 'Convolutional neural network (CNN)', 'deep learning', 'noise reduction', 'noisy image']","영상에서 잡음제거는 패턴인식, 영상압축, 에지검출, 영상분할과 같은 영상처리 분야의 전처리과정으로 도전할 만한 가치가 있다. 본 논문에서는 딥러닝의 convolutional neural network (CNN) 모형을 이용하여 잡음제거 하고자 한다. CNN 모형은 영상인식, 물체인식 얼굴인식과 같은 컴퓨터 비전 문제에서 좋은 성능을 보이고 있으나 잡음제거에 대해서는 그 중요성에 비추어 아직까지 연구가 덜 이루어졌다. 지금까지 영상에서 잡음제거는 특정한 분포 특성을 갖고 있다는 가정 하에서 설계된 고유한 필터를 사용하였다. 이 경우 가정을 만족하지 않는 필더를 사용하는 경우 성능이 현저히 떨어지는 경향이 있다. 본 논문에서는 잡음에 대한 사전정보 없이 사용가능한 방법으로 영상의 작은 블록인 패치 (patch) 상에서 CNN을 적용하고 중첩된 패치(overlapped patches)에서 해당 픽셀들의 가중평균을 구하여 잡음제거 영상을 얻는다. CNN에서 매개변수 최적화는 잡음데이터에 적응력이 좋은 Adam 알고리즘을 사용한다. 영상실험은 가우시안 잡음영상과 임펄스 잡음영상 모두를 고려하였고 실험결과, 패치기반 CNN 모형은 다른 방법보다 좋은 화질의 영상을 도출하였고 또한 MAE (mean absolute error)와 PSNR (peak signal-to-noise ratio) 면에서도 좋은 성능을 지님을 알 수 있었다.","Noise reduction problem in images still prevails as a challenge in the field of image processing such as pattern recognition, image compression, edge detection and image segmentation. Addressing this issue, this paper presents a novel deep learning approach based on a Convolutional Neural Network (CNN) . CNN has shown excellent performance in computer vision problems such as image recognition, object recognition, and face recognition, but little has been discussed in light of the importance of noise reduction in images. Until now, noise reduction in the images has been used with filters designed under the assumption that it has specific distribution characteristics. In this case, the use of filters that do not satisfy the assumption leads to significant performance degradation. In this paper, CNN is applied on patches of images in a way that is available without prior information about noise. The restored image is obtained by the weighted average of the corresponding pixels in overlapping patches. In CNN, parameter optimization is done by the Adam algorithm that is adaptable to noise data. We considered both Gaussian noise and impulse noise to test the performance of our CNN model. Experimental results on several images show that the patch-based CNN model yields significantly superior image quality and better MAE (mean absolute error) and PSNR (peak signal-to-noise ratio)."
실시간 야구 중계를 위한 CNN 기반 고속 야구 선수 위치 검출 시스템,2019,"['image detection algorithm', 'deep learning', 'CNN', 'baseball broadcasting', '이미지 위치 검출', '딥러닝', 'CNN', '야구 경기 중계']","본 논문에서는 야구 경기 영상에서 딥 러닝 기법들 중 영상 인식에 적합한 CNN을 사용하여 야구 선수의 위치를 검출하는 시스템을 제안한다. 객체의 위치 검출을 위한 기존의 영상 처리 기법들 중 다수는 영상 프레임 사이의 차영상이나 객체의 윤곽을 얻는 방법들을 사용해왔지만, 야구 중계와 같이 다양한 기후와 배경을 모두 고려하여 실용화하기에는 추가적인 검증 과정이 필요하다. 본 논문에서는 다양한 경우에 움직이는 객체의 위치를 빠르게 학습하고 검출하기 위해 이진 블록 영상을 적용하였고 학습 성능을 향상시키기 위해 학습 영상을 추가로 생성하는 데이터 증강 기법을 사용하였다. 선수 위치의 정확도 평가 척도는 목표 객체의 중심점과 지능망을 통해 검출된 확률 중심과의 거리를 평가 척도로 적용하였다.실험 결과는 제안한 방법의 평균 거리가 2.92픽셀로 Faster R-CNN의 평균 거리인 3.35보다 0.43픽셀이 낮아 선수의 위치 검출 정확도가 높으며, 수행 속도도 제안한 방법이 Faster R-CNN보다 69.93배 빠름을 보여준다.","The paper proposes a player location detection system in a baseball game broadcast.Location detection system uses CNN (convolutional neural network) suitable for image processing among diverse deep learning systems. To train the location of a player faster and accurately, we choose binary block labeling instead of the commonly used edge detection methods. Data augmentation method, which generates additional training images was applied to increase the degree of accuracy.The distance between the center position of the target and the output position by neural network was used to measure performance. Experimental results indicated that the average pixel distances between center of target position and one of output are 2.92 and 3.35 in the case of the proposed method and Faster R-CNN, respectively. In addition, the execution time of the proposed method was established to be 69.93 times faster than that of Faster R-CNN."
CNN 기반 기보학습 및 강화학습을 이용한 인공지능 게임 에이전트,2019,"['Reinforcement Learning', 'Othello game agent', 'Value function network', 'CNN', 'Records learning']","본 논문에서는 인공지능 오델로 게임 에이전트를 구현하기 위해 실제 프로기사들의 기보를 CNN으로 학습시키고 이를 상태의 형세 판단을 위한 근거로 삼아 최소최대탐색을 이용해 현 상태에서 최적의 수를 찾는 의사결정구조를 사용하고 이를 발전시키고자 강화학습 이론을 이용한 자가대국 학습방법을 제안하여 적용하였다. 본 논문에서 제안하는 구현 방법은 기보학습의 성능 평가 차원에서 가치평가를 위한 네트워크로서 기존의 ANN을 사용한 방법과 대국을 통한 방법으로 비교하였으며, 대국 결과 흑일 때 69.7%, 백일 때 72.1%의 승률을 나타내었다. 또한 본 논문에서 제안하는 강화학습 적용 결과 네크워크의 성능을 강화학습을 적용하지 않은 ANN 및 CNN 가치평가 네트워크 기반 에이전트와 비교한 결과 각각 100%, 78% 승률을 나타내어 성능이 개선됨을 확인할 수 있었다.","This paper proposes a CNN architecture as value function network of an artificial intelligence Othello game agent and its learning scheme using reinforcement learning algorithm. We propose an approach to construct the value function network by using CNN to learn the records of professional players’ real game and an approach to enhance the network parameter by learning from self-play using reinforcement learning algorithm. The performance of value function network CNN was compared with existing ANN by letting two agents using each network to play games each other. As a result, the winning rate of the CNN agent was 69.7% and 72.1% as black and white, respectively. In addition, as a result of applying the reinforcement learning, the performance of the agent was improved by showing 100% and 78% winning rate, respectively, compared with the network-based agent without the reinforcement learning."
Enhanced CNN-based Plant Growing-stage Classification using Additional Information Carried in an Additional Channel,2019,"['Plant phenotype', 'Convolutional neural network', 'Additional image channel', 'Plant growing stage']",국문 초록 정보 없음,"Studying the observable characteristics of mutants and the growing stages of the same genotype plant interacting with various environmental conditions is important in order to understand the performance of a particular trait in different growth environments. A plant""s growing stage affects the growth rate of leaves, the photosynthetic rate, water absorption capacity, and other characteristics. By automating the plant mutant classification process and the growing-stage classification process, botanists and agriculture scientists can perform large-scale experiments to cultivate plants with useful traits to combat extreme environmental conditions. This research aims to construct an enhanced optimum convolutional neural network (CNN) for image-based plant growing-stage classification, and a description of the algorithms to construct the optimum CNN for image-based plant mutant classification is included as well. This research was carried out using the Ara2013-Canon dataset annotated by the International Plant Phenotyping Network (IPPN) for classification processes. Optimum parameters found in this paper are for 1) the number of convolutional layers, 2) the number of neurons in a fully connected (FC) layer, and 3) the number of FC layers in a CNN for plant growing-stage classification. The possibility to enhance the successful classification rate is explored by introducing an additional channel that carries additional useful information, such as 1) mutant type, 2) number of leaves, 3) total size for all leaves, 4) mean leaf size, and 5) standard deviation of the leaf size in the form of square matrices. Experimental results show that under optimum conditions for growing-stage classification, a CNN classification system utilizing plant images and all additional useful information provides the best recognition rate at 81.97%."
A Text Sentiment Classification Method Based on LSTM-CNN,2019,"['Machine Learning', 'CNN', 'LSTM', 'Text Sentiment Classification Methods', 'Deep Learning', '텍스트 정서 분류 방법']","머신 러닝의 심층 개발로 딥 러닝 방법은 특히 CNN(Convolution Neural Network)에서 큰 진전을 이루었다. 전통적인 텍스트 정서 분류 방법과 비교할 때 딥 러닝 기반 CNN은 복잡한 다중 레이블 및 다중 분류 실험의 텍스트 분류 및 처리에서 크게 발전하였다. 그러나 텍스트 정서 분류를 위한 신경망에도 문제가 있다. 이 논문에서는 LSTM (Long-Short Term Memory network) 및 CNN 딥 러닝 방법에 기반 한 융합 모델을 제안하고, 다중 카테고리 뉴스 데이터 세트에 적용하여 좋은 결과를 얻었다. 실험에 따르면 딥 러닝을 기반으로 한 융합 모델이 텍스트 정서 분류의 예측성과 정확성을 크게 개선하였다. 본 논문에서 제안한 방법은 모델을 최적화하고 그 모델의 성능을 개선하는 중요한 방법이 될 것이다.","With the in-depth development of machine learning, the deep learning method has made great progress, especially with the Convolution Neural Network(CNN). Compared with traditional text sentiment classification methods, deep learning based CNNs have made great progress in text classification and processing of complex multi-label and multi-classification experiments. However, there are also problems with the neural network for text sentiment classification. In this paper, we propose a fusion model based on Long-Short Term Memory networks(LSTM) and CNN deep learning methods, and applied to multi-category news datasets, and achieved good results. Experiments show that the fusion model based on deep learning has greatly improved the precision and accuracy of text sentiment classification. This method will become an important way to optimize the model and improve the performance of the model."
딥러닝에 의한 객체인식 향상을 위한 학습 데이터의 효과적 구성: Mask R-CNN을 중심으로,2019,"['딥러닝', '합성곱 신경망', 'Mask R-CNN', '학습 데이터']",인공지능을 실현하기 위한 딥러닝(DL)은 최근 컴퓨팅 파워가 향상됨에 따라서 여러 분야에서 활용되고 있다. 합성곱 신경망(CNN: Convolutional Neural Network)은 영상 학습을 위한 대표적인 DL모델이다. CNN에서 발전된 영역기반 합성곱 신경망(R-CNN: Region- based Convolutional Neural Network)은 객체가 존재하는 영역을 탐지하고 객체를 인식하는 DL 모델이다. 본 연구에서는 R-CNN 중 가장 최근에 개발된 Mask R-CNN의 학습 데이터를 효과적으로 구성하여 건물의 인식 정확도를 높일 수 있는 방안을 제시하였다.,다국어 초록 정보 없음
시점 정보가 있는 정형 데이터의 2차원 변환을 통한 CNN 적용 가능성 검토 : 온라인 커머스 조회이력 기반 구매예측 모델 적용사례,2019,"['정형 데이터', '커머스 데이터', '합성곱신경망(CNN)', '구매 예측', '2차원 변환']","온라인 커머스 고객 데이터는 구매 및 조회 등 사건 발생 시점과 다량의 사건 발생 관련 변수가 함께 기 록되어 있는 정형 데이터이 다. 최근 발전된 2차원 CNN은 국소적 특성 추출 기능 및 메모리 효율성 향상에서 큰 이점이 있지만, 해당 데이터는 그러한 장점을 활용하기 어려웠다. 또한, 벡터 기반 예측 모델을 사용할 시 성김성(Sparsity)문 제로 인하여 시점에 따른 변화 정보까지 반영한 다 량의 변수를 사용하기 어렵다는 한계를 가지고 있 다. 이에 본 연구는 온라인 커머스 분야의 구매 또는 조 회 이력 데이터에 2차원 CNN 을 적용하기 위한 2차 원 변환 방법을 제시한다. 이 방식은 고객의 사건 관련 변수를 필요에 따라 합산하거나 합산하지 않고 2차원 행렬에 나열하며, 특성 정보와 같이 시점에 따라 변하지 않는 정보 또한 2차원 변환에 포함하여 각 고객별 특성을 나타낼 수 있는 방법이 다. 실제 온라인 쇼핑몰 데이터를 활용하여 제안 방법을 검증한 결과, 합성곱층이 제안된 2차원 변환 행렬에 서 예측을 위한 특성을 충분히 찾아낸다는 사실을 확인하였다. 또한 예측력 향상을 위해 사건 발생 순 서 정보를 제시하는 방법으로 제안 방법이 유용함을 확인하였다.",다국어 초록 정보 없음
CNN-based damage identification method of tied-arch bridge using  spatial-spectral information,2019,"['multiple damage identification for hangers', 'tied-arch bridge', 'convolutional neural network', 'deep learning', 'Fourier amplitude spectra', 'ambient wind vibration data']",국문 초록 정보 없음,"In the structural health monitoring field, damage detection has been commonly carried out based on the structural model and the engineering features related to the model. However, the extracted features are often subjected to various errors, which makes the pattern recognition for damage detection still challenging. In this study, an automated damage identification method is presented for hanger cables in a tied-arch bridge using a convolutional neural network (CNN). Raw measurement data for Fourier amplitude spectra (FAS) of acceleration responses are used without a complex data pre-processing for modal identification. A CNN is a kind of deep neural network that typically consists of convolution, pooling, and fully-connected layers. A numerical simulation study was performed for multiple damage detection in the hangers using ambient wind vibration data on the bridge deck. The results show that the current CNN using FAS data performs better under various damage states than the CNN using time-history data and the traditional neural network using FAS. Robustness of the present CNN has been proven under various observational noise levels and wind speeds."
Deep CNN-Based Blind Image Quality Predictor,2019,[],국문 초록 정보 없음,"<P>Image recognition based on convolutional neural networks (CNNs) has recently been shown to deliver the state-of-the-art performance in various areas of computer vision and image processing. Nevertheless, applying a deep CNN to no-reference image quality assessment (NR-IQA) remains a challenging task due to critical obstacles, i.e., the lack of a training database. In this paper, we propose a CNN-based NR-IQA framework that can effectively solve this problem. The proposed method—deep image quality assessor (DIQA)—separates the training of NR-IQA into two stages: 1) an objective distortion part and 2) a human visual system-related part. In the first stage, the CNN learns to predict the objective error map, and then the model learns to predict subjective score in the second stage. To complement the inaccuracy of the objective error map prediction on the homogeneous region, we also propose a reliability map. Two simple handcrafted features were additionally employed to further enhance the accuracy. In addition, we propose a way to visualize perceptual error maps to analyze what was learned by the deep CNN model. In the experiments, the DIQA yielded the state-of-the-art accuracy on the various databases.</P>"
Real-Time Implementation of Human Detection in Thermal Imagery Based on CNN,2019,"['background modeling', 'CNN', 'deep learning', 'human detection', 'thermal videos']",국문 초록 정보 없음,"In this paper, an effective human detection method in thermal imaging is proposed using background modeling and convolution neural network(CNN). For real-time implementation, the background modeling is done by modified running Gaussian average and the CNN-based human classification is performed for only detected foreground objects. To enhance human detection accuracy, morphological operators and ellipse testing are adopted to extract Region of Interest. Also, three CNN models with different input sizes and voting method are trained using our own dataset. For real-time system, the whole system is implemented in C++ and it process more than 30 fps with high accuracy."
Faster Deep-learning CNN based QoE Assessment Software Development with Keras and Tensorflow,2019,"['Deep learning', 'Convolutional Neural Network', 'Computer Networks', 'Video Steaming', '4K UHD', 'QoE']",현대의 고해상도 스트리밍 서비스는 사용자들로부터 높은 품질의 경험(QoE)을 필요로 한다. 높은 계산의 오버헤드를 위해 4K 스트리밍에서 비디오 품질에 대한 평가는 처리하기가 쉽지 않다. 본 논문에서는 기준 영상없이 영상 화질을 정확하게 예측하는 심층 학습 기반의 CNN(Convolutional Neural Network)을 논의한다. CNN은 이미지 패치를 입력으로 삼아 기존 방식에서 채용한 수공예 기능을 사용하지 않고 공간 영역에서 작업하고 제안된 모델은 MOS(Mean Opinion Score) 범주의 모든 이미지를 분류하는 데 활용된다. 이 접근 방식은 KoniQ-10k 데이터 세트에서 적절한 성과를 달성하고 적절한 이미지를 적절한 범주로 분류하는 데 탁월한 일반화 능력을 보여준다.,"Modern high resolution streaming services requires high Quality of Experience (QoE) from users. No Reference video quality assesment in 4K streaming is difficult to process for high computation overhead. In this work we describe a deep-learning based Convolutional Neural Network (CNN) to accurately predict image quality without a reference image. Taking image patches as input, the CNN works in the spatial domain without using hand-crafted features that are employed by most previous methods. proposed model is utilized to classify all images in a MOS (Mean Opinion Score) category. This approach achieves state of the art performance on the KonIQ-10k dataset and shows excellent generalization ability in classifying proper images into proper category."
드론의 자동 랜딩을 위한 CNN을 이용한 객체인식,2019,"['쿼드콥터', '무인항공기', '비전 센서', '객체 인식', '제어', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN과 후처리를 이용한 해상쓰레기와 해파리 무리 인식,2019,"['해파리 검출', '해상쓰레기', 'CLAHE', '군집인식', 'CNN', 'Jellyfish Detection', 'Marine Garbage', 'Cluster Recognition']","최근 해상쓰레기와 해파리 등으로 인하여 어민들과 바닷가 방문객이 큰 피해를 보고 있다. 본 연구에서는 영상에서 이러한 해상쓰레기와 해파리를 검출하는 방법을 제안한다. 우리나라 근해의 해수는 부유물이 많아서 색상이 탁하며, 수면에 햇빛이 반사되어 해수면 아래에 있는 해파리를 검출하기가 쉽지가 않아 CLAHE를 이용하여 영상을 개선한다. 해파리는 무리 지어서 이동하는 특징이 있다. 따라서 해파리를 개별적으로 인식하는 것이 보다 무리를 검출하는 것이 효율적이라고 판단하여, 개체가 다섯 마리 이상이면 무리라고 간주하고 군집인식방법을 수행한다. 군집인식에서는 필터를 이용하여 해파리 색상인 흰색 분포의 밀집 지점을 찾는다. 그 후 k-평균 클러스터링 알고리즘을 이용하여 바다와 해파리를 분류한다. 군집인식을 수행한 결과, 해파리 개체 하나하나를 인식하는 것보다 해파리 무리를 인식하는 것이 좋은 성능을 나타내는 것을 볼 수 있었다. 해상쓰레기는 CNN을 사용하여 좋은 결과를 얻었다.","Recently, fishermen and person who visits seashore are suffering greatly because of marine garbage and jellyfish. In this paper, we propose a method to detect marine garbage and jellyfish in images. It is difficult to detect jellyfish below the sea surface because seawater in Korea has a lot of suspended matter and its color is cloudy, and sunlight is reflected on the water surface. So the image is enhanced using the CLAHE. Jellyfish has a property of moving in groups. Therefore, it is more effective to detect jellyfish group than each jellyfish. Therefore, if the number of jellyfish is more than five, it is regarded as a group and a cluster recognition method is performed. A filter is used to find the dense point of the white distribution of the jellyfish color. Then, a method of classifying the image into the sea and jellyfish using k-means clustering algorithm is performed. As the result of cluster recognition, we could see that recognized jellyfish group was better than recognizing individual jellyfish. Marine garbage recognition achieved good results using CNN."
CNN을 활용한 회계 계정코드 분류,2019,"['Artificial Neural Network', 'Deep Learning', 'CNN', 'Classification', 'General Ledger Account Code']","최근에 이르러 ERP(Enterprise Resource Planning) 시스템의 사용이 일반화되면서 개인 비용전표 중심으로 경리부서 직원이 아닌 일반부서 직원들이 직접 자신의 경비를 입력하는 일이 증가했다. 본 연구는 기업의 일반 직원이 비용 전표를 작성할 때, 주어진 최소한의 정보로 회계계정코드를 자동 분류하는 모델을 개발하고자 한다. 비용 전표 중에서 개인이 가장 많이 사용하는 법인카드 데이터를 이용하여 계정 분류 모델을 구현할 것이며, 최근 유행하는 CNN 알고리즘으로 분류 모델을 만들고자 한다.","Recently, as the use of ERP (Enterprise Resource Planning) system becomes more popular, more and more employees, rather than employees of accounting department, enter their own expense vouchers by themselves. This study attempts to develop a model that automatically classifies general ledger account code using a least amount of information when company employees enter a expense voucher.  I will implement the classification model of a general ledger account code with the latest popular CNN algorithm using the most commonly used voucher, corporate credit card among the expense vouchers."
CNN을 이용한 궤적데이터에 대한 이동성 모드 분류 방법,2019,"['mobility modes', 'CNN', 'classification', 'trjajectory']",국문 초록 정보 없음,"Recognizing the mobility modes (bus, car, train, etc.) of the users moving trajectories in trajectory mining is very important for extracting more accurate information. In this paper, we propose a mobility mode classification method for users trajectories based on CNN (Convolution Neural Network). The proposed mobility mode classification method in this paper generates the users’ bus trajectories by using the actual bus trajectories. We use the approach of classifying the mobility modes of the collected user trajectories using the derived learning model through CNN using the collected user trajectories and the generated bus users’ trajectories. We perform the mobility mode classification experiment using the actual user trajectory data. As the result of the mobility mode classification experiment, the classification accuracy was 95.98%. In addition, it was confirmed that the proposed method is more suitable for the mobility mode classification for the users trajectories through a comparison experiment with the previously proposed mobility mode classification method."
GPR 영상에서 딥러닝 기반 CNN을 이용한 배관 위치 추정 연구,2019,"['sink holes', 'pipe', 'GPR', 'image recognition', 'underground detection', 'CNN', 'deep-learning', '지하공동', '배관', 'GPR영상', '지하 탐지', '영상 인식', '딥러닝', '컨볼루션 뉴럴 네트워크']",최근에 지하공동이나 배관의 위치 파악 등의 필요에 의해 금속을 포함하여 다양한 재질의 지하 물체를 탐지하는 일이 중요해지고있다. 이러한 이유로 지하 탐지 분야에서 GPR(Ground Penetrating Radar) 기술이 주목을 받고 있다. GPR은 지하에 묻혀 있는 물체의위치를 찾기 위하여 레이더파를 조사하고 물체로부터 반사되는 반사파를 영상으로 표현한다. 그런데 레이더 신호는 지하에서 여러가지 물체에서 반사되어 나오는 특징이 물체마다 유사한 경우가 많기 때문에 GPR 영상을 해석하는 것은 쉽지 않다. 따라서 본 논문에서는 이러한 문제를 해결하기 위해서 영상 인식 분야에서 최근에 많이 활용되고 있는 딥러닝 기반의 CNN(Convolutional Neural Network)모델을 이용하여 임계값에 따른 GPR 영상에서의 배관 위치를 추정하고 그 실험 결과 임계값이 7 혹은 8 일 때 가장 확실하게 배관의 위치를 찾음을 증명하였다,"In recently years, it has become important to detect underground objects of various marterials including metals, such as detecting the location of sink holes and pipe. For this reason, ground penetrating radar(GPR) technology is attracting attention in the field of underground detection. GPR irradiates the radar wave to find the position of the object buried underground and express the reflected wave from the object as image. However, it is not easy to interpret GPR images because the features reflected from various objects underground are similar to each other in GPR images. Therefore, in order to solve this problem, in this paper, to estimate the piping position in the GRP image according to the threshold value using the CNN (Convolutional Neural Network) model based on deep running, which is widely used in the field of image recognition, As a result of the experiment, it is proved that the pipe position is most reliably detected when the threshold value is 7 or 8."
CNN에 기초한 방사선 디텍터의 화소 결함 보정,2019,[],국문 초록 정보 없음,"In radiography imaging, flat-panel radiography detectors use TFT (thin film transistor) panels to acquire high-quality X-ray images. Pixel defects in TFT panels can lower the production yield of panels and ultimately increase production costs. Furthermore, pixel defects can degrade the image quality. Hence, there is a need to develop an appropriate correction algorithm. Current algorithms have difficulties in optimizing their performances especially for image edge parts. This paper proposes a pixel-defect correction algorithm based on a CNN (convolutional neural network) deep learning structure. This structure combines ANN(artificial neural network) and CNN to improve the pixel correction performance. The proposed algorithm shows better performances than those of the conventional TMC (template matching) algorithms."
CNN을 활용한 IoT 스트림 데이터 패턴 분류 기법,2019,"['IoT', '스트림 데이터', '딥러닝', '패턴 분류', 'IoT', 'stream data', 'deep learning', 'pattern analysis']","사물 인터넷(Internet of Things, IoT) 환경의 발달로 다양한 종류의 센서들로부터 대량의 데이터가 생성되고 있으며, 이를 수집, 관리 및 분석하기 위한 빅데이터 기술이 중요해지고 있다. 최근에는 실시간으로 생성되는 대용량의 IoT 데이터 분석에 딥러닝 기술을 활용하여 특정 데이터 패턴이나 경향성의 분석을 수행하기 위한 연구가 진행되고 있다. 본 논문에서는 헬스케어 등 IoT 기반 서비스에의 활용 가능성이 높은 스트림데이터 중 하나인 ECG(Electrocardiogram, 심전도) 데이터에 대하여, 딥러닝 모델을 설계 및 적용함으로써 효율적인 분석을 가능하도록 하였다. 먼저, ECG 스트림 데이터의 패턴 분류를 위하여 합성곱 신경망(Convolutional Neural Networks, CNN) 기반의 딥러닝 모델을 설계하고, 이를 최적화하기 위한 다양한 파라미터들을 각각 모델의 구조와 학습에 관련한 파라미터들로 분리하여 실험을 설계 및 진행하였다. 또한, 분류 작업의 추가적인 성능 향상을 위하여, ECG 스트림 데이터에 대한 전처리 기법을 고안하여 적용해 보았다. 이러한 다양한 조건을 기반으로 설계된 실험들은, 서로 다른 센서에서 서로 다른 목적으로 수집되어 서로다른 특성을 갖는 두 가지의 ECG 스트림 데이터 세트 에 대하여 각각 수행되었다. 그 결과, 레이어가 깊을수록, 배치 크기가 큰 학습 모델일수록 IoT 스트림 데이터의 패턴 분류에 용이한 모델 구조라는 결론을 얻을수 있었다.","These days due to the development of the Internet of Things environment, big data technology is becoming important for collecting and managing large amounts of data. Recent studies are being conducted to incorporate deep learning technology into Internet of Things(IoT) data analysis in order to classify the specific pattern and trends. In this paper, ECG(Electrocardiogram) data, which could be useful for IoT services, is the input steam data, and a deep learning model structure suitable for data characteristics is found, so that IoT data analysis is efficiently performed. In order to classify the IoT stream data pattern, the experiments were conducted to find the best suitable model structure using the convolutional neural networks. To optimize the CNN, various models and parameter values were used to design various experiments. Also to enhance the classification performance, a preprocessing step is added to the existing convolutional neural networks model. The model structure parameters and the model learning parameters are divided into two major conditions. The experiment environment is set up and applied to two time series data with different characteristics. It is concluded that the deeper the layer and the larger the batch size, the easier model structure for IoT data pattern classification."
Mask R-CNN을 이용한 물체인식 및 개체분할의 학습 데이터셋 자동 생성,2019,"['Object Detection', 'Instance Segmentation', 'Deep Learning', 'Dataset Generation']",국문 초록 정보 없음,"A robot usually adopts ANN (artificial neural network)-based object detection and instance segmentation algorithms to recognize objects but creating datasets for these algorithms requires high labeling costs because the dataset should be manually labeled. In order to lower the labeling cost, a new scheme is proposed that can automatically generate a training images and label them for specific objects. This scheme uses an instance segmentation algorithm trained to give the masks of unknown objects, so that they can be obtained in a simple environment. The RGB images of objects can be obtained by using these masks, and it is necessary to label the classes of objects through a human supervision. After obtaining object images, they are synthesized with various background images to create new images. Labeling the synthesized images is performed automatically using the masks and previously input object classes. In addition, human intervention is further reduced by using the robot arm to collect object images. The experiments show that the performance of instance segmentation trained through the proposed method is equivalent to that of the real dataset and that the time required to generate the dataset can be significantly reduced."
Lightweight Traffic Sign Recognition Algorithm based on Cascaded CNN,2019,"['Traffic Sign Recognition', 'Lightweight', 'Cascaded CNN']",국문 초록 정보 없음,"Autonomous vehicle technology is evolving with deep learning. Traffic sign recognition informs the driver of necessary information when the driver does not recognize the traffic sign while driving or when the traffic sign information is missing from the GPS database. In this paper, we collected Traffic signs in South Korea and we proposed a light-weight traffic sign recognition (TSR) algorithm based on cascaded CNN. This algorithm is hardware-friendly and reduces the computational complexity and the number of computations compared to the previously announced YOLO v2-tiny. Our Korean traffic sign dataset was used to learn the network and verify the algorithm. Through this process, we have studied the future improvement plan to make algorithm that can be used for actual road driving."
CNN을 이용한 얼굴 표정 인식,2019,"['Facial Expression Recognition', 'Emotion', 'CNN', 'Machine Learning', 'Neural Network']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN기법을 이용한 보일러설비의 미세조직 재질열화등급 분류,2019,"['보일러', 'PHM', 'CNN', '딥러닝', '미세조직', '재질열화']","국내 발전의 60% 이상을 차지하고 있는 화력발전은 국가 전력생산의 핵심이 되는 산업이다. 화력발전소는 크게 보일러, 터빈, 발전기로 이루어져 있는데 보일러에서 가열된 고온, 고압의 증기가 증기터빈으로 공급되어 만들어지는 회전력으로 발전이 이루어진다. 이때 증기를 생산하기 위해 보일러 튜브에 공급되는 물은 약 1100°C의 연소열과 접촉해 550~600°C 고온의 증기로 변환되는데, 이런 고온 고압의 환경에 놓여있는 보일러 압력부의 크고 작은 고장은 상당한 경제적 손실을 야기한다. 특히 국내 25년 이상 운영된 발전소의 설계수명인 30년을 고려했을 때 향후 신뢰성 평가에 의한 수명연장이 필요한 시점이다. 따라서 본 연구에서는 보일러 수명평가를 위해 존재하는 다양한 평가기법을 쉽게 사용할 수 있는 프레임워크를 개발하는 동시에 정밀점검 Data분석을 위한 DB를 구축하고, Deep Learning을 적용한 객관적 조직분석 방법론을 개발하여 궁극적으로 종합 분석을 통한 설비상태 예측 및 통합관리 시스템을 개발한다.",다국어 초록 정보 없음
CNN모델 기반의 저해상도 열화상 이미지를 통한 안면 3차원 모델링 데이터 생성 방법에 관한 연구,2019,"['Image processing', 'Row-resolution', 'Infrared Thermal camera', 'CNN-model', 'Temperature compensation']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 재난 예경보 시스템,2019,"['Disaster prevention system', 'Object detection', 'Deep-Learning', 'CNN', 'SVM']",국문 초록 정보 없음,"In this paper, we propose an intelligent CCTV technology which is applied to a recent attracted attention real-time object detection technology in a disaster alarm system. Natural disasters are rapidly increasing due to climate change (global warming). Various disaster alarm systems have been developed and operated to solve this problem. In this paper, we detect object through Neuron Network algorithm and test the difference from existing SVM classifier. Experimental results show that the proposed algorithm overcomes the limitations of existing object detection techniques and achieves higher detection performance by about 15%."
CNN을 활용한 착륙 패드 부분 인식 상황에서의 패드 중심점 추정 기법 연구,2019,"['드론(Drone)', '정밀 착륙(Precision Landing)', '합성곱 신경망(Convolutional Neural Network', 'CNN)', '부분 인식(Partial Recognition)']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN기법을 이용한 보일러설비의 미세조직 재질열화등급 분류,2019,"['Power plant bolier', 'Convolutional Neural Network', 'Image classification']",국문 초록 정보 없음,"The pressure parts of boiler facility is directly exposure to high temperature and pressure. Especially the water flowing in boiler tubes changes to high temperature(600°C) steam to operate turbines. And the tubes in a heat-affected- zone always contacts to 1100°C combustion heat, so that they lie in a poor environment. Domestic power plants, therefore, use various techniques to evaluate the high pressure parts of boiler facilities’ remaining life. For example, classifying material degradation grades is the technique of evaluating remaining life of materials by classifying degradation grades of microstructure. Due to the characteristics of the technique, however, the results from the technique can be different depending on inspectors. For this reason, classifying material degradation grades technique is used to inspectors who have efficient knowledges and experiences. This implies to needs for improving reliabilities in life assessment filed. Therefore, represented in the paper suggest a methodology using CNN to gain objectivity to results of evaluation."
CNN을 이용한 차량 수 카운팅 알고리즘,2019,"['CNN', 'Vehicle Counting', 'Classification']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN-LSTM-MDN 을 이용한 vehicle kinematic state variables 및 불확실성 추정,2019,"['불확실성(Uncertainty)', '혼합 밀도 네트워크(Mixture Density Network', 'MDN)', 'CNN-LSTM']",국문 초록 정보 없음,다국어 초록 정보 없음
심전도 신호의 시간-주파수 표현에 의한 CNN기반 개인식별의 성능비교,2019,"['ECG', 'CNN', 'MFCC', 'scalogram', 'spectrogram', 'personal identification']",국문 초록 정보 없음,다국어 초록 정보 없음
강건한 CNN기반 수중 물체 인식을 위한 이미지 합성과 자동화된 Annotation Tool,2019,"['Deep Learning', 'Data Annotation', 'Object Detection', '3D CAD Model']",국문 초록 정보 없음,"In this paper, we present auto-annotation tool and synthetic dataset using 3D CAD model for deep learning based object detection. To be used as training data for deep learning methods, class, segmentation, bounding-box, contour, and pose annotations of the object are needed. We propose an automated annotation tool and synthetic image generation. Our resulting synthetic dataset reflects occlusion between objects and applicable for both underwater and in-air environments. To verify our synthetic dataset, we use MASK R-CNN as a state-of-the-art method among object detection model using deep learning. For experiment, we make the experimental environment reflecting the actual underwater environment. We show that object detection model trained via our dataset show significantly accurate results and robustness for the underwater environment. Lastly, we verify that our synthetic dataset is suitable for deep learning model for the underwater environments."
3차원 GPR 블록 데이터와 3D CNN을 이용한 동공탐지,2019,[],국문 초록 정보 없음,"Ground penetrating radar (GPR) is a typical sensor system for underground objects detection area. The multichannel GPR devices can give more detail and informative three-dimensional (3D) data for classification underground objects. Spatial information of underground objects can be well characterized in the three-dimensional GPR block data which consists of several B-scan and C-scan data. In this article underground object classification method is proposed by using 3D GRP data. Deep learning technique is recently being adopted into this field due to its powerful image classification capacity. The 3D GRP block data is then used to train deep three-dimensional convolution neural network (3D CNN). The proposed method successfully classifies cavity, pipe, manhole and subsoils having small false positive errors. The suggested method is experimentally validated by area data collected on urban roads in Seoul, South Korea."
CNN합성곱 연산기의 효율성 향상을 위한 하드웨어 구조 연구,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN기반 Residual Dense Block을 활용한 단일 영상에서의 안개 제거 기법,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 비디오 카메라 모델 식별 시스템,2019,[],국문 초록 정보 없음,"In this paper, camera model identification technique for video, not image is proposed. We analyzed video frames using the trained model with images. we used the P frame because we want to limit a differences in the characteristics of frames. Then, we presented a video camera model identification system by applying a majority-based decision algorithm. In the experiment using 10 video camera models, we obtained maximum 99.09% identification rate for each camera model."
CNN을 이용한 누수 상황 검출,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 파이프 용접 최적화에 대한 연구,2019,"['Welding', 'Convolutional neural network', 'Welding Quality']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 주파수 도약 신호 기반 RF Fingerprinting 시스템,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN기반 HD-EMG 손동작 인지 기술에서 시간-창 길이 변화에 대한 인식정확도 비교 분석,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 고해상도 위성사진에서의 객체검출에 관한 연구,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 전방위 영상의 워터마크 추출,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN기반 열매 이미지를 통한 수확시기 및 수확량 예측 시스템,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 익형의 공력 성능 예측,2019,"['Deep Leaning(심층학습)', 'Convolution Neural Network(합성곱 신경망)', 'Airfoil(익형)', 'Aerospace Application(항공우주적용)']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN구조를 이용한 Starcraft II 미니게임 모방학습,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN기법을 활용한 지중송전 케이블 시스템 PD 패턴 인식,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 균열 검출 기반 포장도로 영역별 심각도 추정,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
3D CNN을 이용한 360도 입체영상에서의 사이버 멀미 예측,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
TF-IDF와 CNN을 사용한 법률문서 분류 시스템에 관한 연구,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
블록정보를 이용한 CNN기반 인 루프 필터,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
다중 넓이 커널 CNN을 이용한 구름 요소 베어링 고장 진단,2019,"['구름 요소 베어링(Rolling element bearing)', '전이 학습(Transfer learning)', '고장 진단(Fault diagnosis)', '합성곱신경망(Convolution neural networks)']",국문 초록 정보 없음,다국어 초록 정보 없음
기침소리 데이터 전처리에 따른 CNN기반 분류모델의 성능 평가,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
Micro Doppler radar Hand gesture recognition 시스템에서 CNN을 위한 후처리 기법,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
Handwritten Signature Verification Using CNN with Data Augmentation,2019,"['Neural Network', 'CNN', 'Handwritten Signature Verification', 'ConvNet', 'Data Augmentation']",국문 초록 정보 없음,"A signature is a mark or sign which is made by an individual on an instrument or document to signify knowledge, approval, acceptance or obligation. To authenticate writing or a notice of its source and to bind the individual signing which is written by the provisions contained in the document. Signature verification is more important for not only in commercial banks but also with every sector like falsification of documents in numerous financial, legal and other commercial aspects. A signature is an important factor in biometric technique in which it is used to detect forged or genuine signature. This paper concerns offline handwritten signature verification using convolutional neural network (CNN). Here we have used data augmentation with CNN model and also, we have made a comparative study with Multilayer Perceptron (MLP) and Single Layer Perceptron (SLP). The model is tested using 4480 images with 20 subjects where we have found the accuracy of CNN is 82.75% and CNN with data augmentation is 98.33%, SLP is 39.91% and MLP is 63.57%. Based on the comparative study CNN with data augmentation proves the best performance."
Analyses on the Performance of the CNN Reflecting the Cerebral Structure for Prediction of Cybersickness Occurrence,2019,"['Cybersickness', 'Dizziness', 'CNN', 'EEG', 'Artificial Neural Network']",국문 초록 정보 없음,"In this study, we compared and analyzed the performance of each Convolution Neural Network (CNN) by implementing the CNN that reflected the characteristics of the cerebral structure, in order to analyze the CNN that was used for the prediction of cybersickness, and provided the performance varying depending on characteristics of the brain. Dizziness has many causes, but the most severe symptoms are considered attributable to vestibular dysfunction associated with the brain. Brain waves serve as indicators showing the state of brain activities, and tend to exhibit differences depending on external stimulation and cerebral activities. Changes in brain waves being caused by external stimuli and cerebral activities have been proved by many studies and experiments, including the thesis of Martijn E. Wokke, Tony Ro, published in 2019. Based on such correlation, we analyzed brain wave data collected from dizziness-inducing environments and implemented the dizziness predictive artificial neural network reflecting characteristics of the cerebral structure. The results of this study are expected to provide a basis for achieving optimal performance of the CNN used in the prediction of dizziness, and for predicting and preventing the occurrence of dizziness under various virtual reality (VR) environments."
Comparing Convolutional Neural Network(CNN) models for machine learning-based drone and bird classification of anti-drone system,2019,"['Drone classification', 'Anti-drone', 'Convolutional Neural Network(CNN)', 'Drone defense system']",국문 초록 정보 없음,"As drones become more advanced and commercialized, crimes using drones are also on rise. For this reason, development of anti-drone systems is increasing. In this paper, CNN model is examined that is suitable for visible camera-based drone identification. The CNN models used for the validation are Alexnet, GoLeNet, Inception-v3 Vg16, Resnet-18, Resnet-50 and Squezezenet. These seven models have already been validated in the ImageNet Large Scale Visual Recognition Competition (ILSVRC). In ILSVRC, 1000 labels are classified, but in this study limits them to three drones, birds and backgrounds. Therefore, it is necessary to verify whether the three labels are the same as the ILSVRC result. In order to verify this, CNN models are learned and tested in the same environment. The experimental results show that the performance of Alexnet, Resnet and Squeeznet is relatively better then the others, unlike the performance of CNN known through ILSVRC. his result shows that a shallow network with a simple structure is more reasonable when the number of labels is small. Based on these results, the further work is to develop a neural network optimized for Drone identification."
향상된 Mask R-CNN을 적용한 뇌종양 검출,2019,"['Brain tumor detection', 'Deep Learning', 'Convolutional Neural Network(CNN)']",국문 초록 정보 없음,"A brain tumor is a mass, or lump in the brain which is caused when brain cells divide and grow in an uncontrolled way. Brain tumor surgery may be difficult, but it is also incredibly important. So Detection of tumor is important to make a diagnosis and treat of the disease. Recently, AI would be able to get higher accuracy than a medical image judged by a doctor. In this paper, a model with the best efficiency is proposed in brain tumor detection and Mask R-CNN training and test using enhanced Mask R-CNN by combining group normalization and U-Net. This paper uses brain tumor data from Medical Segmentation decathlon 2018.  The results of the proposed Mask R-CNN showed that the brain MRI image was bound boxed in areas containing brain tumors, carefully masking the brain tumor. When using group normalization and U-Net, the dice coefficient is 0.8196. When not using group normalization and U-Net, the dice coefficient is 0.7749, which confirms that the former model has a high average accuracy."
A Study on Motor Poor Maintenance Detection Based on DT-CNN,2019,"['Deep learning', 'CNN', 'Motor fault diagnosis', 'Motor installation fault']",국문 초록 정보 없음,"Signals of the motor failure, such as a bearing or gear fault, are proportional to its mechanical characteristics. These characteristics generate similar signal patterns for the same fault. However, signals in poor installation maintenance depend on how to install them. This means that a different signal pattern occurs in the same fault state. In this paper, DT-CNN (Decision Tree Convolutional Neural Network) algorithm is proposed to solve the above problems in applying deep learning to motor fault diagnosis. The supervised learning cannot verify outlier data. The proposed algorithm complements this disadvantage by using over fitted CNN in the selection process of the decision tree. In order to verify the performance of this algorithm, normal and gear fault data were collected. The data were collected by varying the motor installation state. Using these data, DT-CNN algorithm was implemented and it succeeded in detecting the maintenance failure signal almost similar to the normal state and the validity was confirmed."
Action recognition using optimized deep autoencoder and CNN for surveillance data streams of non-stationary environments,2019,"['Big data processing', 'Action recognition', 'Online data stream analysis', 'Optimized deep autoencoder', 'Convolutional neural network', 'Machine learning', 'Non-stationary environment']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>Action recognition is a challenging research area in which several convolutional neural networks (CNN) based action recognition methods are recently presented. However, such methods are inefficient for real-time online data stream processing with satisfied accuracy. Therefore, in this paper we propose an efficient and optimized CNN based system to process data streams in real-time, acquired from visual sensor of non-stationary surveillance environment. Firstly, frame level deep features are extracted using a pre-trained CNN model. Next, an optimized deep autoencoder (DAE) is introduced to learn temporal changes of the actions in the surveillance stream. Furthermore, a non-linear learning approach, quadratic SVM is trained for the classification of human actions. Finally, an iterative fine-tuning process is added in the testing phase that can update the parameters of trained model using the newly accumulated data of non-stationary environment. Experiments are conducted on benchmark datasets and results reveal the better performance of our system in terms of accuracy and running time compared to state-of-the-art methods. We believe that our proposed system is a suitable candidate for action recognition in surveillance data stream of non-stationary environments.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Action recognition in online data stream acquired from non-stationary surveillance. </LI> <LI>  Efficient CNN model is used for frame-level representation. </LI> <LI>  An optimized deep autoencoder is presented for learning sequences and squeezing high. dimensional features. </LI> <LI>  Investigated a non-linear learning approach for action recognition. </LI> <LI>  Iterative fine-tuning of the trained recognition model for newly accumulated data. </LI> </UL> </P>"
CNN Model Performance Analysis on MRI Images of an OASIS Dataset for Distinction Between Healthy and Alzheimer’s Patients,2019,"['Medical MRI', 'CNN', 'AlexNet', 'GoogLeNet', 'ResNet50', 'CAD']",국문 초록 정보 없음,"In this paper, we present the performance of a medical image classification model pretrained on natural images. In addition, another model is scratch trained from available medical magnetic resonance images in order to get a comparative analysis. We perform shallow tuning and fine-tuning of the pretrained model (AlexNet, GoogLeNet, and ResNet50) in a bunch of layers in order to find the impact of each section of layers in the classification result. We use 28 normal controls (NC) and 28 Alzheimer’s disease (AD) patients for classification, selecting 30 important slices from each patient. Once all the slices were collected, each model was trained, validated, and tested at a ratio of 6:2:2 on a random selection basis. The testing results are reported and analyzed so the final CNN model could be built with a minimal number of layers for optimal performance."
Faster R-CNN을 활용한 GPR 영상에서의 지하배관 위치추적 성능분석,2019,"['지하 배관', 'Faster R-CNN', '지표 투과 레이더', '딥러닝', 'VGGnet', '어그멘테이션', 'Buried pipelines', 'Faster R-CNN', 'GPR', 'Deep learning', 'VGGnet', 'Augmentation']",국문 초록 정보 없음,다국어 초록 정보 없음
Gesture-Based Emotion Recognition by 3D-CNN and LSTM with Keyframes Selection,2019,"['Gesture-based Emotion Recognition', '3D Convolutional Networks', 'Convolution LSTM.']",국문 초록 정보 없음,"In recent years, emotion recognition has been an interesting and challenging topic. Compared to facial expressions and speech modality, gesture-based emotion recognition has not received much attention with only a few efforts using traditional hand-crafted methods. These approaches require major computational costs and do not offer many opportunities for improvement as most of the science community is conducting their research based on the deep learning technique. In this paper, we propose an end-to-end deep learning approach for classifying emotions based on bodily gestures. In particular, the informative keyframes are first extracted from raw videos as input for the 3D-CNN deep network. The 3D-CNN exploits the short-term spatiotemporal information of gesture features from selected keyframes, and the convolutional LSTM networks learn the long-term feature from the features results of 3D-CNN. The experimental results on the FABO dataset exceed most of the traditional methods results and achieve state-of-the-art results for the deep learning-based technique for gesture-based emotion recognition."
가보웨이블릿 특징맵을 입력으로 한 CNN 기반 영상잡음제거기,2019,[],"최근 Convolutional Neural Network (CNN)에 영상이 아닌 비학습적 알고리즘으로부터 도출된 특징맵을 입력함으로써 영상처리 성능 및 계산자원 효율성 향상을 이룬 보고가 늘어나고 있다. 본 논문에서는 이러한 점을 바탕으로 가보웨이블릿 특징맵을 입력으로 하는 CNN 기반 영상잡음제거기를 제안하고 그 성능 및 특징을 고찰하였다. 즉 기존의 CNN 에서는 일반적인 영상을 입력하는 반면에 본 논문에서는 영상으로부터 추출한 웨이블릿 계수들을 입력하였고, 이를 통하여 기존의 방법에 비하여 성능을 유지하면서 계산량을 줄일 수 있는 가능성을 확인하였다.",다국어 초록 정보 없음
Atypical Character Recognition Based on Mask R-CNN for Hangul Signboard,2019,"['Atypical Character Recognition', 'Hangul Signboard', 'Mask R-CNN', 'Hangul signboard character']",국문 초록 정보 없음,"This study proposes a method of learning and recognizing the characteristics that are the classification criteria of Hangul using Mask R-CNN, one of the deep learning techniques, to recognize and classify atypical Hangul characters. The atypical characters on the Hangul signboard have a lot of deformed and colorful shapes beyond the general characters. Therefore, in order to recognize the Hangul signboard character, it is necessary to learn a separate atypical Hangul character rather than the existing formulaic one. We selected the Hangul character ‘닭’ as sample data and constructed 5,383 Hangul image data sets and used them for learning and verifying the deep learning model. The accuracy of the results of analyzing the performance of the learning model using the test set constructed to verify the reliability of the learning model was about 92.65% (the area detection rate). Therefore we confirmed that the proposed method is very useful for Hangul signboard character recognition, and we plan to extend it to various Hangul data."
EMG-based hand gesture classification by scale average wavelet transform and CNN,2019,"['sEMG', 'scale average wavelet transform(SAWT)', 'scalogram', 'CNN', 'hand gestures', 'classification', 'accuracy']",국문 초록 정보 없음,"Predicting and accurately classifying intentions for human hand gestures can be used not only for active prosthetic hands, rehabilitation robots and entertainment robots but also for artificial intelligence robots in general. In this paper, first of all, source data of three hand gestures of grasping and three hand gestures of sign language are acquired by using the armband combined with 8 sEMG (surface Electromyography) sensors. To classify these hand gestures, basic CNN (Convolutional Neural Network) and wavelet transform CNN are applied and compared as a deep learning algorithm. Finally, it is shown that by using wavelet transform and an average value of the transformed data according to scale change of mother function, the accuracy can be improved up to 94% for selected hand gestures."
영상처리와 CNN 결합을 통한 야간 도로상의 전방 차량 인식,2019,"['CNN-based object classification', 'disparity estimation', 'light-blobs', 'nighttime vehicle detection']",국문 초록 정보 없음,We propose a convolutional neural network (CNN)-based approach to detect vehicles in front of an ego-vehicle for road traffic scenes at night and compare it with our AdaBoost-based approaches. The new approach enhances the previous approaches [5] in terms of vehicle detection performance. We also produce negative learning data by exploiting a vehicle candidate-generation scheme that further improves classifier performance. The experimental results for real-world road images illustrate the effectiveness of the proposed algorithm.
CNN 기반 잡음 제거: layer 크기에 따른 커널 복원,2019,[],국문 초록 정보 없음,"CNN (Convolutional Neural Network) is one of the deep learning techniques for analyzing images and images. In this paper, we analyze the denoising performance of CNN with respect to the layer size for quarter dose XCAT images. The results shows that there are suitable layer size for denoising images. In addition, reconstructed images with error function MSE and VGG16 decrease high frequency level. Also using bif convolution layer can make lines along the boundary."
Fast R-CNN을 이용한 객체 인식 기반의 도로 노면 파손 탐지 기법,2019,"['도로 노면 파손', '심층 신경망', '유지보수', '영역 기반 합성곱', '객체 인식', 'Road surface damage', 'Deep neural network', 'Road maintenance', 'Region based convolutional neural networks', 'Object recognition']",국문 초록 정보 없음,다국어 초록 정보 없음
LSTM 신경망과 Du-CNN을 융합한 적외선 방사특성 예측 및 표적과 클러터 구분을 위한 CR-DuNN 알고리듬 연구,2019,"['Infrared image', 'Coast targets', 'Long short term memory', 'Convolutional neural network']",국문 초록 정보 없음,"In this paper, we analyze the infrared feature for the small coast targets according to the surrounding environment for autonomous flight device equipped with an infrared imaging sensor and we propose Cross Duality of Neural Network (CR-DuNN) method which can classify the target and clutter in coastal environment. In coastal environment, there are various property according to diverse change of air temperature, sea temperature, deferent seasons. And small coast target have various infrared feature according to diverse change of environment. In this various environment, it is very important thing that we analyze and classify targets from the clutters to improve target detection accuracy. Thus, we propose infrared feature learning algorithm through LSTM neural network and also propose CR-DuNN algorithm that integrate LSTM prediction network with Du-CNN classification network to classify targets from the clutters."
UAV 항공사진측량 기술과 Faster R-CNN알고리즘을 활용한 연안양식장 탐색에 관한 연구,2019,"['UAVs', 'aerial photogrammetry', 'Coastal areas', 'Ocean farms', 'Facility detection', 'Faster R-CNN']",국문 초록 정보 없음,"Recently, many researches using unmanned aerial vehicles(UAV) has been proposed for applications in coastal areas. However, there is still a need for consecutive researches on various types of UAVs, sensors and regions. Especially, it is necessary to study the practical use of the UAV photogrammetry in marine surveying. In Korea, aquaculture production accounts for 61.8% of total aquatic-product production in 2017 and is increasing year by year. Therefore, there is a growing need to systematically manage, support and monitor aquatic products. In particular, unlicensed and illegal fisheries are increasing in Jeollanam-do. In 2016, the number of unlicensed and illegal fisheries has increased to 180% comparing in 2012. The Jeollanam-do fisheries resources division is implementing special crackdown on illegal aquaculture farmers every year. However, due to the nature of the marine environment, surveillance and enforcement are limited by field surveys alone. In this study, we propose a methodology by using UAV photogrammetry and automatic image recognition technology to increase efficiency of monitoring aquaculture farms. For this purpose, UAV photogrammetry was performed on abalone and seaweed ocean farms in Wando, Jeollanam-do. Then, we developed a methodology for automatically detecting the farm facilities in the marine environment by applying the Faster-RCNN (Regional Convolution Neural Network) to the generated orthophotos. Through the study, it is identified that small UAVs can be effectively used for the surveillance and management of the ocean farms in coastal areas. Also, the automatic method for recognizing aquaculture object using Faster R-CNN technique can be developed."
Atypical Character Recognition Based on Mask R-CNN for Hangul Signboard,2019,"['Atypical Character Recognition', 'Hangul Signboard', 'Mask R-CNN', 'Hangul signboard character']",국문 초록 정보 없음,"This study proposes a method of learning and recognizing the characteristics that are the classification criteria of Hangul using Mask R-CNN, one of the deep learning techniques, to recognize and classify atypical Hangul characters. The atypical characters on the Hangul signboard have a lot of deformed and colorful shapes beyond the general characters. Therefore, in order to recognize the Hangul signboard character, it is necessary to learn a separate atypical Hangul character rather than the existing formulaic one. We selected the Hangul character '닭' as sample data and constructed 5,383 Hangul image data sets and used them for learning and verifying the deep learning model. The accuracy of the results of analyzing the performance of the learning model using the test set constructed to verify the reliability of the learning model was about 92.65% (the area detection rate). Therefore we confirmed that the proposed method is very useful for Hangul signboard character recognition, and we plan to extend it to various Hangul data."
Atypical Character Recognition Based on Mask R-CNN for Hangul Signboard,2019,"['Atypical Character Recognition', 'Hangul Signboard', 'Mask R-CNN', 'Hangul signboard character']",국문 초록 정보 없음,"This study proposes a method of learning and recognizing the characteristics that are the classification criteria of Hangul using Mask R-CNN, one of the deep learning techniques, to recognize and classify atypical Hangul characters. The atypical characters on the Hangul signboard have a lot of deformed and colorful shapes beyond the general characters. Therefore, in order to recognize the Hangul signboard character, it is necessary to learn a separate atypical Hangul character rather than the existing formulaic one. We selected the Hangul character ‘닭’ as sample data and constructed 5,383 Hangul image data sets and used them for learning and verifying the deep learning model. The accuracy of the results of analyzing the performance of the learning model using the test set constructed to verify the reliability of the learning model was about 92.65% (the area detection rate). Therefore we confirmed that the proposed method is very useful for Hangul signboard character recognition, and we plan to extend it to various Hangul data."
A Detection Method for Liver Cancer Region Based on Faster R-CNN,2019,"['Computer Aided Diagnosis', 'Convolutional Neural Network', 'Object Detection', 'Faster R-CNN']",국문 초록 정보 없음,"In recent years, liver cancer has become the fourth-largest number of deaths in the world. Surgery is a typical treatment for liver cancer. Therefore, advance information about the number and size of cancer is important for surgery. Multi-phase CT images are well known diagnostic method. By extracting the region of the liver and the region of cancer from the obtained CT image, the shape can be finally restored in 3D. In this paper, as a preliminary step to construct an image analysis method for efficiently extracting cancerous regions in multi-phase CT, we propose a method of obtaining a rectangular region as a rough cancerous region of interest. As a method, after preprocessing the input image, using Faster R-CNN, the region of interest including the cancer region is extracted as a rectangle. As a result of applying this method to 11 cases of arterial phase of multi-phase CT, the detection performance was different depending on the network model adopted for backbone part."
Point Cloud Segmentation of Crane Parts Using Dynamic Graph CNN for Crane Collision Avoidance,2019,"['Crane', '3D point cloud', 'Segmentation', 'DBSCAN', 'Dynamic graph', 'CNN']",국문 초록 정보 없음,"In this study, we have developed a point cloud segmentation algorithm for a collision avoidance system between cranes and other objects in construction yards. We used the Dynamic Graph CNN (DGCNN) algorithm to segment the point cloud of the entire yard into crane parts and backgrounds. The point cloud data were obtained from several LIDAR sensors attached to the crane. All points were grouped into specific core clusters using the DBSCAN algorithm. The core clusters were used to train the DGCNN after labeling with corresponding part names. This network classified the point cloud into crane types and their part names. Experimental results show that the crane part segmentation performance of the suggested algorithm is accurate enough to be used for collision avoidance system. It is possible to estimate the pose of a crane by comparing the segmented point clouds with those of the CAD model."
RED-CNN에 기반한 CT 영상 픽셀 크기에 따른 denoising 성능평가,2019,[],국문 초록 정보 없음,"In X-ray CT studies, reducing the noise in CT images is an increasingly important problem. Many studies suggested and focused on how to apply processes of deep learning, such as network types or loss functions. However, we thought there was an efficient way of preprocessing for better denoising performance of a deep learning method. In this study, we used fan beam geometry to generate noise in CT images, and changed the pixel size of the images. We expected that the smaller pixel size of the images brings out the better effect of denoising by RED-CNN. This study showed how CT images quality changed by pixel size of the images."
Determination of Anterior Cruciate Ligament Complete& Partial Rupture using Cascaded CNN,2019,"['CNN(Convolutional Neural Network)', '전방십자인대(Anterior Cruciate Ligament)']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN Classifier Based Energy Monitoring System for Production Tracking of Sewing Process Line,2019,"['Energy monitoring', 'sewing process', 'convolutional neural networks', 'production tracking', 'smart sensor', 'smart factory']",국문 초록 정보 없음,"The garment industry is one of the most labor-intensive manufacturing industries, with its sewing process relying almost entirely on manual labor. Its costs highly depend on the efficiency of this production line and thus is crucial to determine the production rate in real-time for line balancing. However, current production tracking methods are costly and make it difficult for many Small and Medium-sized Enterprises (SMEs) to implement them. As a result, their reliance on manual counting of finished products is both time consuming and prone to error, leading to high manufacturing costs and inef- ficiencies. In this paper, a production tracking system that uses the sewing machines’ energy consumption data to track and count the total number of sewing tasks completed through Convolutional Neural Network (CNN) classifiers is pro- posed. This system was tested on two target sewing tasks, with a resulting maximum classification accuracy of 98.6%; all sewing tasks were detected. In the developing countries, the garment sewing industry is a very important industry, but the use of a lot of capital is very limited, such as applying expensive high technology to solve the above problem. Applied with the appropriate technology, this system is expected to be of great help to the garment industry in developing countries."
코랩 환경 CNN 구조의 독성 식물 판별 시스템,2019,"['CNN', 'Deep Learning', 'Image', 'Toxic', 'Plants Classification']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN 을 이용한 전방위 비디오 합성 시점의 화질 개선 알고리즘,2019,[],"본 논문은 최근 MPEG-I 에서 논의되고 있는 전방위 6 자유도 영상의 가상시점 합성의 기존 공개 소프트웨어의 문제점 해결방안을 제안한다. 참조시점을 사용하여 합성된 가상시점의 영상을 대상으로 묶음 조정(bundle adjustment) 개념의 딥 러닝을 적용하여 영상 간 시공간적 품질 차이를 낮춘다. 실험에 따르면 중간시점 영상 합성 후 같은 시간적 특성을 같은 묶음을 MF-CNN (Multi-Frame Convolutional Neural Networks)에 적용함으로써 단순 VVS2.0 의 합성 결과 대비 평균 공간적으로 0.34dB, 시간적으로 0.81dB 의 성능 향상을 제공하였다.",다국어 초록 정보 없음
CNN 기반의 웹툰 유사도 분석 모델 연구,2019,"['유사도 분석', '웹툰', 'CNN', 'Inception ResNetV2']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN 을 이용한 공구 마모 상태 분류,2019,"['CNN', 'Tool', 'Wear']",국문 초록 정보 없음,다국어 초록 정보 없음
3D CNN 을 이용한 CAD 모델의 제조 단가 예측,2019,"['제조 원가 예측(Manufacturing cost prediction)', '캐드모델(CAD Model)', '3D CNN(3D Convolutional Neural Networks)']",국문 초록 정보 없음,다국어 초록 정보 없음
항공 영상에서의 Mask R-CNN을 이용한 도로 표면 균열 검출 연구,2019,"['crack', 'object detection', 'mask R-CNN', 'GeoAI', 'aerial image']",국문 초록 정보 없음,다국어 초록 정보 없음
Text Classification Using LSTM-CNN,2019,"['deep learning model fusion', 'LSTM-CNN', 'THUCNews', 'RNN']",국문 초록 정보 없음,다국어 초록 정보 없음
영상 노이즈 제거 CNN 구조 개선을 위한 VGG CNN 손실함수 적용에 대한 연구,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
Fast ROI Detection for Speed up in a CNN based Object Detection,2019,"['ROI detection', 'Noise', 'Image difference', 'Object detection.']",국문 초록 정보 없음,"Fast operation of a CNN based object detection is important in many application areas. It is an efficient approach to reduce the size of an input image. However, it is difficult to find an area that includes a target object with minimal computation. This paper proposes a ROI detection method that is fast and robust to noise. The proposed method is not affected by a flicker line noise that is a kind of aliasing between camera and LED light. Fast operation is achieved by using down-sampling efficiently. The accuracy of the proposed ROI detection method is 92.5% and the operation time for a frame with a resolution of 640 x 360 is 0.388msec."
Channel Attention과 그룹 컨볼루션을 이용한 효율적인 얼굴 감정인식 CNN,2019,"['facial expression recognition', 'efficient cnn', 'group convolution', 'depth-wise separable convolution', 'channel attention', '얼굴 감정인식', '컨볼루션 신경망', '그룹 컨볼루션', '깊이별 분리 컨볼루션', '채널 어텐션']","최근 얼굴 표정에서 감정을 인식하기 위한 문제에서 컨볼루션 신경망을 이용한 연구가 활발히 진행되고 있다. 본 논문에서는 사람의 얼굴 표정에서 나타나는 감정을 인식하기 위해 사용하는 딥 컨볼루션 신경망의 모델 복잡도(Complexity) 문제점을 해결한 효율적인 컨볼루션 신경망을 제안한다. 본 논문에서는 모델의 복잡도를 줄이기 위해 그룹 컨볼루션, 깊이별 분리 컨볼루션을 사용하여 파라미터 수와 연산량을 감소시키고 특징 연결을 위한 Skip Connection과 Channel Attention을 사용하여 특징의 재사용성과 채널 정보를 강화하였다. 제안하는 모델의 학습 파라미터 개수는 0.39 M(Million), 0.41 M으로 기존 모델에 비해 4배 이상 적은 수의 파라미터를 사용하여 FER2013, RAF-single 데이터셋에서 각각 70.32%, 85.23%의 정확도를 달성하였다.","ecently, studies using the convolutional neural network have been actively conducted to recognize emotions from facial expressions. In this paper, we propose an efficient convolutional neural network that solves the model complexity problem of the deep convolutional neural network used to recognize the emotions in facial expression. To reduce the complexity of the model, we used group convolution, depth-wise separable convolution to reduce the number of parameters, and the computational cost. We also enhanced the reuse of featuRecently, studies using the convolutional neural network have been actively conducted to recognize emotions from facial expressions. In this paper, we propose an efficient convolutional neural network that solves the model complexity problem of the deep convolutional neural network used to recognize the emotions in facial expression. To reduce the complexity of the model, we used group convolution, depth-wise separable convolution to reduce the number of parameters, and the computational cost. We also enhanced the reuse of features and channel information by using Skip Connection for feature connection and Channel Attention. Our method achieved 70.32% and 85.23% accuracy on FER2013, RAF-single datasets with four times fewer parameters (0.39 Million, 0.41 Million) than the existing model.res and channel information by using Skip Connection for feature connection and Channel Attention. Our method achieved 70.32% and 85.23% accuracy on FER2013, RAF-single datasets with four times fewer parameters (0.39 Million, 0.41 Million) than the existing model."
3D Depth Computation of Moving Objects Using a CNN with an Orthogonal Stereo Fisheye Camera System,2019,"['Fisheye camera', 'Depth computation', 'Orthogonal stereo matching', 'Viewpoint transformation', 'Wide angle']",국문 초록 정보 없음,"Stereo matching of images taken by wide-angle (WA) fisheye lens cameras pose difficulties because the degree of distortion increases along the outer edge of the image. In addition, in an orthogonal stereo camera system in which adjacent WA cameras are positioned at right angles to cover 360°, the relationship between correspondence and depth information varies from that of a general-purpose parallel stereo camera system, thus requiring special mathematical modeling. In order to solve the abovementioned problems, this paper proposes an algorithm to minimize the degree of distortion by viewpoint transformation, and calculates the three-dimensional distance information of a moving object through the mathematical modeling of a fisheye stereo camera system arranged at right angles. The proposed algorithm consists of five steps. First, using the calibrated camera parameters, the viewpoints are changed so that the stereo images perpendicular to each other are viewed in parallel in the same direction. Second, by using a convolutional neural network (CNN) model, features are extracted from the viewpoint-transformed images. Third, matching between adjacent images based on the extracted features is performed. Fourth, depth information of moving objects is calculated from matching points. Finally, the computed depth information is refined for improved accuracy. Simulation results show that the depth calculated by the proposed algorithm is fairly accurate, with an average error rate of about 4%."
Autonomous-Driving Vehicle Learning Environments using Unity Real-time Engine and End-to-End CNN Approach,2019,"['Autonomous Shuttle Vehicle', 'Artificial Intelligence', 'Virtual Environment', 'Behavior Learning']",국문 초록 정보 없음,"Collecting a rich but meaningful training data plays a key role in machine learning and deep learning researches for a self-driving vehicle. This paper introduces a detailed overview of existing open-source simulators which could be used for training self-driving vehicles. After reviewing the simulators, we propose a new effective approach to make a synthetic autonomous vehicle simulation platform suitable for learning and training artificial intelligence algorithms. Specially, we develop a synthetic simulator with various realistic situations and weather conditions which make the autonomous shuttle to learn more realistic situations and handle some unexpected events. The virtual environment is the mimics of the activity of a genuine shuttle vehicle on a physical world. Instead of doing the whole experiment of training in the real physical world, scenarios in 3D virtual worlds are made to calculate the parameters and training the model. From the simulator, the user can obtain data for the various situation and utilize it for the training purpose. Flexible options are available to choose sensors, monitor the output and implement any autonomous driving algorithm. Finally, we verify the effectiveness of the developed simulator by implementing an end-to-end CNN algorithm for training a self-driving shuttle."
CNN 과 LSTM 을 이용한 다중 차량 추적 알고리즘,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 물체 인식 알고리즘을 이용한 협동 로봇 시스템 내 작업자 위치 추정 및 예측,2019,"['로봇 안전(Robot Safety)', '머신 비전(Machine Vision)', '협동 로봇 시스템(Collaborative Robot System)', '물체 인식(Object Detection)', '작업자 위치 추정(Human Position Monitoring)']",국문 초록 정보 없음,"More and more people and collaborative robots are sharing their workspaces. Safety issues are increasing as collaborative robots and people share workspaces. In this paper, we propose a technique that uses two fixed RGB cameras to calculating human position for safety. YOLO algorithm using Convolution Neural Network detects people through RGB cameras. The image coordinates of the detection area obtained from the algorithm can be used to calculate the human position of real world through coordinate transformation. Finally, I proposed a way to predict a person’s position even if the camera doesn’t recognize some or all of the camera."
CNN 기반의 프레임 동기 신호 추정 기법,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반 열화상 카메라를 활용한 재실자의 열쾌적감 예측에 관한 연구,2019,"['열쾌적감', '열화상 카메라', '피부온도', '기계학습', '합성곱신경망', 'Thermal Comfort', 'Thermographic Camera', 'Skin Temperature', 'Machine learning', 'Convolutional Neural Network']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반 Jigsaw Puzzle 문제 해결 연구,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 을 사용한 건물 외벽 오염도 검출,2019,"['Convolutional neural network', 'Machine vision', 'Image processing', 'Facade cleaning']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN using the super-resolution pre-processor for the classifier to improve accuracy,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반 D-STLC 송신 안테나 선택 성능 실험,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 을 이용한 단일영상 고해상도 복원 및 수용영역 확장을 통한 성능 향상,2019,[],"합성곱 신경망의 성능이 증가하면서 다양한 영상 처리 문제를 해결하기 위해 합성곱 신경망을 적용한 시도들이 증가하고 있다. 고해상도 복원 문제도 그 중 하나였으며, 보다 높은 성능을 얻기 위해 주로 신경망의 깊이를 깊게 하는 시도들이 있었다. 본 논문에서는 고해상도 복원 작업을 위한 합성곱 신경망의 성능 향상을 위해 깊이를 증가시키는 접근법이 아닌 수용영역을 확장시키는 접근법을 시도하였다. 논문에서 제시한 모델은 신경망 내부에 두 개의 브랜치를 두어, 하나의 브랜치는 Dilated Convolution 을 이용해 수용영역을 확장하는데 사용되며, 다른 하나는 이 브랜치를 통해 나온 feature 를 가공하는데 사용된다. 기본 모델은 EDSR 을 사용하였으며, 최종적으로 4.79M 의 파라미터로 평균 32.46dB 의 PSNR 을 보여주었다. 하지만 모델의 구조가 복잡하여 깊이를 늘이는 접근법을 적용하기 어렵다는 한계점이 있다.",다국어 초록 정보 없음
CNN 기반의 배경 변화에 강인한 클릭 동작 인식,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 을 이용한 스포츠 경기 영상에서의 선수 검출과 팀 구분,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반의 CAN 시스템 상의 악의적 노드 감지,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반의 지능형 화재 감시 시스템,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 구조에 기반한 인공지능 드론의 자율 비행,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반의 이종 신경망 융합을 이용한 물체 인식 및 파지점 예측,2019,"['Deep Learning', 'Machine Learning', 'FCN', 'Object Detection', 'Grasping point Detection', 'ROS']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN 특징벡터 기반 비디오 근-복사 검출,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
Deep CNN 기반의 얼굴인식 시스템 개발,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
위성사진과 CNN 기반 전이 학습을 통한 인구 통계 예측,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
YOLOv3 CNN 연산량 간소화 위한 구현 알고리즘,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
A CNN data configuration method for Multivariate Time Series IoT Data,2019,"['AI', 'Big Data', 'Convolutional Neural Network', 'Deep Learning', 'IoT']",국문 초록 정보 없음,다국어 초록 정보 없음
Two-Context CNN Inference with TensorRT,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
Faster R-CNN을 이용한 고속도로 통행량 및 속도 추정 구현,2019,"['Deep learning', 'Object Detection', 'Vehicle Speed Estimation', 'Traffic Estimation', 'Traffic Situation Analysis']",국문 초록 정보 없음,다국어 초록 정보 없음
딥 CNN 에서의 Different Scale Information Fusion (DSIF) 의 영향에 대한 이해,2019,[],국문 초록 정보 없음,"Different scale of information is an important component in computer vision systems. Recently, there are considerable researches on utilizing multi-scale information to solve the scale-invariant problems, such as GoogLeNet and FPN. In this paper, we introduce the notion of different scale information fusion (DSIF) and show that it has a significant effect on the performance of object recognition systems. We analyze the DSIF in several architecture designs, and the effect of nonlinear activations, dropout, sub-sampling and skip connections on it. This leads to clear suggestions for ways of the DSIF to choose."
Fast R-CNN을 이용한 도로노면파손 객체 추출 알고리즘 개발,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
최적화된 CNN 모델을 이용한 시선추적,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
얼굴인식 CNN 모델을 활용한 눈썹 모양 추천 서비스,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
Mask R-CNN을 이용한 다중 뉴럴 스타일 전이 방법,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
Deep CNN 기반의 얼굴인식 시스템 개발,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
실제 제조공정에서 CNN 기반의 물건파지방법 인식,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
CW 재밍환경에서 CNN 기반 검파기의 GPS L1 C/A 신호 검파 성능분석,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
FFT 와 CNN 구조를 이용한 다중 센서의 고속 정보 처리 구조 설계,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
A novel CNN based security guaranteed image watermarking generation scenario for smart city applications,2019,"['Convolutional neural network', 'Image watermark', 'Generation scenario', 'Algorithm design', 'Smart cities']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>The rise of machine learning increases the current computing capabilities and paves the way to novel disruptive applications. In the current era of big data, the application of image retrieval technology for large-scale data is a popular research area. To ensure the robustness and security of digital image watermarking, we propose a novel algorithm using synergetic neural networks. The algorithm first processes a meaningful gray watermark image, then embeds it as a watermark signal into the block Discrete Cosine Transform (DCT) component. The companion algorithm for detection and extraction of the watermark uses a cooperative neural network, where the suspected watermark signal is used as the input while the output consists in the result of the recognition process. The simulation experiments show that the algorithm can complete certain image processing operations with improved performance, not only simultaneously completing watermark detection and extraction, but also efficiently determining the watermark attribution. Compared with other state-of-the-art models, the proposed model obtains an optimal Peak Signal-to-noise ratio (PSNR).</P>"
Jamming Signals Classification Using CNN for Anti-Jamming Performance of TH-NRDCSK System,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
이미지 복원을 위한 CNN 기반의 Mixture of Expert 네트워크,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
공동 손실함수가 적용된 CNN 기반의 시점 변화에 강인한 걸음걸이 식별,2019,"['Gait recognition', 'gait energy image', 'convolution neural network', 'discriminative-feature learning', 'center loss']",국문 초록 정보 없음,"Most current gait recognition approaches based on convolution neural networks (CNNs) do not learn the discriminative features of separable inter-class differences resulting from cross-view data. To improve this discriminative ability, this paper proposes a network that reduces intra-class variation using a center loss function for view-invariant gait recognition. The proposed method achieved 92% accuracy using OU-MVLP, the largest existing gait recognition dataset. Furthermore, a network trained using the OU-MVLP achieved 95% accuracy with the OU-LP . These results demonstrate that the proposed method offers a good generalization performance."
전처리 필터의 수가 CNN 기반 스테그아날리시스의 성능에 미치는 영향 분석,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
소고기 등급 판정을 위한 CNN(Convolution neural network) 적용 가능성 연구,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
Zero-Free 배열 유도 방식의 CNN 연산기 성능 개선,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
Compressed Representation of CNN for Image Compression in MPEG-NNR,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
Vision DSP를 위한 CNN Application의 최적화된 타일링 방법,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
MPEG-NNR 의 Local Binary 방법을 이용한 CNN 압축,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
Radix-X 가중치를 갖는 멤리스터 기반의 CNN 하드웨어 구현,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
Object location information extraction using CNN Heatmaps,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
시계열 데이터를 이미지로 encoding 하여 CNN 을 통한 태양 조도 예측,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
필터 분해 기법을 이용한 에너지 효율적 재구성형 CNN 가속기 설계,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
자동 영상인식 모델생성도구를 이용한 계층적 CNN 구조와 랜덤 레이블에 관한 연구,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
임베디드 보드에서의 인공신경망 압축을 이용한 CNN 모델의 가속 및 성능 검증,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
스마트 구조물 균열 감지를 위한 1차원 합성곱신경망(1D CNN) 딥러닝을 이용한 파괴 신호 특정 기법,2019,"['구조물 모니터링', '기계 학습', '1D Convolution', '진동 센서', 'Structure Health Monitoring', 'Machine Learning', '1D Convolution Network', 'Accelerometer']","초고층 빌딩, 대형 구조물 등의 건설이 일반화됨에 따라 점차 노후화 및 지진, 태풍 등의 자연재해에 의한 구조물의 손상 모니터링에 대한 필요도가 증가하고 있다. 특히, 하부구조인 구조물 기초에서의 손상은 구조물 전체의 건전도에 부정적인 영향을 미칠 수 있기 때문에, 이에 대한 감지는 매우 중요하다. 구조물 건전도 비파괴검사 방법으로는 대표적으로 음향, 진동 감지기법 등이 제안되었으며, 이에 음향, 진동 감지기에 의해 수집된 신호를 해석하여 균열의 발생 위치 및 균열의 크기, 내구도 등을 역으로 추정하는 방법에 관한 연구가 실험실 스케일에서 많이 수행되어왔다. 하지만 실제로 현장에서는 적용되는 경우가 극히 드문 데 그 이유는 평소 발생하는 노이즈 신호(정상 신호)와 손상파괴 신호(비정상 신호)를 구분하는 것이 어렵기 때문이다. 특히 노이즈 신호와 구조물 파괴 신호가 동시에 수집될 때 이를 구분하는 것은 더욱 어려워진다. 이에 본 연구에서는 노이즈 신호(정상 신호)와 손상파괴 신호(비정상 신호)를 수집하고, 무작위로 합성된 신호를 딥러닝 기법인 1D convolutional neural network model을 통해서 정상 신호와 비정상 신호를 구분하는 알고리즘을 개발하였다. 개발된 알고리즘을 사용하면 현장에서 실시간으로 수집된 신호를 구분할 수 있게 됨으로써 구조물 안전성 변화 예측을 통해 재산 및 인명 피해 위험성을 최소화할 수 있을 것으로 생각한다.","Structures can be damaged by natural disasters such as earthquakes and typhoons. In particular, any damage to the foundation of a structure can present critical problems. Therefore, a smart monitoring technique such as the acoustic emission method is required to detect internal cracks and other types of structural damage. Many laboratory studies on this method have been conducted to estimate the locations and sizes of cracks as well as the resulting changes in structural durability using collected acoustic signals. However, the method has rarely been applied in the field because identifying damage signals from acquired signals, which can contain ambient noise, is difficult. We developed a deep learning algorithm based on a one-dimensional convolutional neural network method that can identify damage or crack signals generated from concrete failure from randomly synthesized signals. Using the developed algorithm, we were able to distinguish damage signals from random ambient noise signals. This algorithm enables real-time monitoring of concrete structures, thus providing a smart monitoring strategy."
정비 자료 디지털 변환을 위한 영상 인식 알고리즘: CNN and FCN,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
고용 불안에 시달리는 서구 언론인_소규모 언론사 모집 공고에 CNN·로이터 출신 기자까지,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
Interference Management in Ultra-Dense Heterogeneous Networks Using Denoising CNN,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
특징 연결과 깊이별 분리 컨볼루션을 이용한 효율적인 얼굴 감정인식 CNN,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
Classification of stomach cancer gene expression data using CNN algorithm of deep learning,2019,"['gene expression data', 'deep learning', 'convolutional neural network', 'principal component analysis', 'heatmap']",국문 초록 정보 없음,다국어 초록 정보 없음
CCTV 동영상에서 보행자 검색을 위한 패션 어텐션 기반 보행자 CNN 특징 추출 방법,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
정비 자료 디지털 변환을 위한 영상 인식 알고리즘: CNN and FCN,2019,"['Deep Learning(심층학습)', 'Classification(분류)', 'Digitization(전산화)', 'Tabular data(표 데이터)']",국문 초록 정보 없음,다국어 초록 정보 없음
지식 그래프 완성을 위한 그래프 어텐션 기반의 다채널 CNN 모델,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
A Combined Model of Outline Feature Map and CNN for Detection of People at the Beach,2019,"['InsightCNN', '객체 인식', '특징 맵', '복잡한 영상', '외곽선', 'intelligent video surveillance system', 'object detection', 'complex image', 'outline']",국문 초록 정보 없음,다국어 초록 정보 없음
Evaluation of the Importance of High Level Features in CNN,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
R-CNN 기법을 활용한 딥러닝 기반 철도 콘크리트 도상 자동 균열 검측 시스템 개발,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
Faster R-CNN 을 이용한 Primitive Model 식별에 관한 연구,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
Conditional GAN과 Mask R-CNN 기반의 Image-to-Image Translation을 이용한 차량 이미지 생성,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
첨단운전자보조시스템(ADAS)을 위한 Fast R-CNN 기반 Auto Image Description 시스템,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
Context-aware pedestrian detection especially for small-sized instances with Deconvolution Integrated Faster RCNN (DIF R-CNN),2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
랜섬웨어 방어를 위한 합성곱 신경망 기반의 데이터 암호화 탐지 기법,2019,"['ransomware', 'deep learning', 'convolutional neural network', 'computer security', '랜섬웨어', '딥러닝', '합성곱 신경망', '컴퓨터 보안']","최근 랜섬웨어에 의한 피해가 심각해짐에 따라, 랜섬웨어 공격을 실시간으로 감지하고 방어하는 기술 개발의 중요성이 높아지고 있다. 기존 랜섬웨어 탐지 기법의 한계를 극복하기 위해, 저장장치 내부 수준의 데이터 보존 및 복구 기법이 제안되었으나, 무분별한 데이터 보존으로 인해 저장공간 부하를 크게 증가시킬 수 있다는 한계점이 존재한다. 본 논문에서는 보존할 데이터를 정확하게 선정하면서도 피해 데이터를 온전하게 보존하기 위한, 합성곱 신경망 기반의 데이터 암호화 여부 판단 기법을 제시한다. 실험 결과, 제안한 기법은 저장장치 내부 수준에서 상위 계층의 정보 없이 93.90%의 높은 정확도로 데이터의 암호화 여부를 판단하였다. 또한, 손실 함수와 결정 경곗값을 수정하여 0에 가까운 부정 오류율을 달성하였다.","With the rapid increase in the number of ransomwares recently, the development of real-time strategies for ransomware defense is imperative. To overcome the limitations of traditional ransomware defense techniques, a storage-level data recovery technique was suggested. However, as the technique inefficiently selects data to conserve, it has a negative impact on the lifetime and performance of storage. In this paper, we propose a CNN-based encrypted data detection technique to enhance the accuracy of selecting data to conserve while ensuring complete data recovery. Our experiments show that the proposed technique achieved 93.90% detection accuracy at the storage-level without any high-level information. Furthermore, by changing the loss function and controlling a detection threshold, we attained a false negative rate of nearly 0."
컨볼루션 신경망 기반 운동심상을 이용한 뇌의 연결성 분석 및 분류방법,2019,"['brain-computer interface', 'brain connectivity', 'convolutional neural network', 'machine learning', '뇌-컴퓨터 인터페이스', '뇌 연결성', '컨볼루션 신경망', '기계학습']","뇌-컴퓨터 인터페이스 (brain-computer interface; BCI)란 뇌에서 발생한 전기신호를 인공지능 알고리즘을 통해 사용자의의도를 예측하고, 그에 따라 로봇이나 컴퓨터를 제어해주는 기술로 세계 다양한 기관에서 미래 핵심 기술로 손꼽히는기술이다. BCI는 구현하는 방법 (Slow Cortical Potentials, Sensorimotor Rhythms, P300, Steady-State Visually Evoked Potential, Directional Tuning 등)에 따라 다양한 어플리케이션에 이용되고 있다. 하지만 BCI를 실생활에 사용하기 위해서는상황에 따라 시스템을 켜거나 꺼주거나 시스템의 모드 (typing, 로봇 제어, 전동 휠체어 제어 등)를 변경해주어야 한다. 본논문에서는 일반인 피험자 10명을 대상으로 EEG (Electroencephalography)를 측정 및 분석하여 피험자의 다양한 상태(resting, speech imagery, legs-motor imagery, hands-motor imagery)를 구분해내는 알고리즘을 개발하고 그 결과 88.25%의정확도로 상태를 구분할 수 있었다. 이는 BCI 모드 변경을 위한 핵심 알고리즘으로 BCI 기술의 실용화를 앞당길 것으로기대한다.","The brain-computer interface (BCI) is a technology that predicts user’s intention through artificial intelligent algorithm and control robot or computer accordingly and is recognized as a core technology for the future by various organizations around the world. BCI is used in various applications according to the implementation method (Slow Cortical Potentials, Sensorimotor Rhythms, P300, Steady State Visually Evoked Potential, Directional Tuning, etc). However, to use BCI in real life, it is necessary to turn on/off the system according to the situation or to change the system mode (typing, robot control, electric wheelchair control, etc). In this paper, we developed an algorithm to measure various states (resting, speech imagery, legs-motor imagery, hands-motor imagery) of subjects by measuring and analyzing EEG in 10 subjects and as a result, we were able to distinguish the state with an accuracy of 88.25%. We expected that BCI technology would be put into practical use as a critical algorithm for changing BCI mode."
자연어를 활용한 SQL문 생성을 위한 합성곱 신경망 기반 칼럼 예측 모델,2019,"['SQL', 'RDBMS', 'natural language processing', 'convolutional neural networks', 'SQL', '관계형 데이터베이스', '자연어 처리', '합성곱 신경망']","관계형 데이터베이스 시스템을 이용하여 대규모의 데이터를 검색하기 위해서는 테이블 스키마 및 SQL문을 이해해야 하는 필요성이 있다. 이를 해결하기 위해 자연어가 입력으로 주어질 때, 이에 대응하는 SQL문을 생성하는 연구가 최근 진행되고 있다. 기존 연구에서 가장 어려운 부분은 SQL문의 조건에 해당되는 칼럼을 효과적으로 예측하는 부분이며, 예측해야 하는 칼럼의 개수가 여러 개일 때 정확도가 크게 떨어지는 문제점이 있다. 본 논문에서는 칼럼 어텐션 메카니즘을 이용하여, 자연어 데이터의 숨겨진 표현을 효과적으로 추출하는 합성곱 신경망 모델을 제안한다. 본 연구의 제안 방법은 기존 방법 대비 약 6% 이상 정확도가 향상되는 것을 확인할 수 있었다.","To retrieve massive data using relational database management system (RDBMS), it is important to understanding of table schemas and SQL grammar. To address this issue, many studies have recently been carried out to generate an SQL query from a natural language question. However, the existing works suffer mostly from predicting columns at where clause and the accuracy is greatly reduced when there are multiple columns to be predicted. In this paper, we propose a convolutional neural network model with column attention mechanism that effectively extracts the latent representation of input question which helps column prediction of the model. The experiment shows that our model outperforms the accuracy of the existing model (SQLNet) by 6%."
컨볼루션 신경망 기반 초해상도 이미지 복원에 대한 분석 및 최적화,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
LeafNet: 합성곱 신경망을 이용한 식물체 분할,2019,"['Deep learning', 'Segmentation', 'Plant phenomics', 'Phenomics system', 'CNN', '딥 러닝', '분할', '식물 표현체', '피노믹스 시스템', '합성곱 신경망']","식물 표현체(plant phenomics) 연구는 우수한 형질의 식물 품종과 유전적 특성을 선별하기 위해 여러 식물체의 형태적 특징을 관측하고, 획득한 영상 빅데이터를 분석하는 기술이다. 기존의 방법은 검출 대상에 따라 직접 색상 임계값을 변경해야 하기 때문에 빅데이터를 다루는 정밀검정시스템에 적용하기 어렵다. 본 논문에서는 정밀검정시스템을 위한 식물체와 배경의 자동 분할이 가능한 합성곱 신경망(Convolution neural network: CNN) 구조를 제안한다. LeafNet은 9개의 컨벌루션 계층과 식물의 유무를 판단하기 위한 시그모이드(Sigmoid) 활성화 함수로 구성된다. LeafNet을 이용한 학습 결과, 식물 모종 영상에 대하여 정밀도 98.0%, 재현율 90.3%의 결과가 도출되어 정밀검정시스템의 적용 가능성을 확인하였다.",다국어 초록 정보 없음
Deep Convolutional Neural Network with Bottleneck Structure using Raw Seismic Waveform for Earthquake Classification,2019,"['Convolutional neural network', 'earthquake classification', 'bottleneck structure', 'raw seismic waveform', 'centering preprocessing']",국문 초록 정보 없음,"In this paper, we propose deep convolutional neural network(CNN) with bottleneck structure which improves the performance of earthquake classification. In order to address all possible forms of earthquakes including micro-earthquakes and artificial-earthquakes as well as large earthquakes, we need a representation and classifier that can effectively discriminate seismic waveforms in adverse conditions. In particular, to robustly classify seismic waveforms even in low snr, a deep CNN with 1x1 convolution bottleneck structure is proposed in raw seismic waveforms. The representative experimental results show that the proposed method is effective for noisy seismic waveforms and outperforms the previous state-of-the art methods on domestic earthquake database."
설계품질 자동검토 도구를 위한 시각지능 기반 BIM 객체 인식 구현,2019,"['3D object classification', 'Building element', 'Building information modeling', 'Convolutional neural network', 'Design rule-checking']",국문 초록 정보 없음,"This paper presents an approach and implementation of auto-classification of unclassified objects in BIM models using deep learning for design rule-checking systems. The validation of required data in BIM models is an important task while BIM applications have proved their benefits in various architecture domains. To handle the problem related to the data quality check, which tends to rely on a manual way, previous studies related to checking and validating BIM objects for ensuring data integrity of BIM instances have been proposed. As a part of the studies, this paper applies convolutional neural networks to the pre-checking of BIM models for the design rule-checking application. We have trained BIM object recognition model and developed a stand-alone application. A plug-in of the design rule-checking software has developed and demonstrated with practical rule-checking execution. It is confirmed to enable to successfully execute rule-checking by utilizing the result values of auto-classification. We expect this approach and implementation to help validation of BIM data and contribute to the practical use of not only rule-checking but also other BIM-based applications."
태양광 전력 기반의 컨벌루션 신경망 설계와 숫자 인식률 개선,2019,"['Solar Energy', 'Convolution Neural Network', 'Handwritten Numeral Images', 'Fully Connected Network', 'Feature Matching', 'Misrecognition']",국문 초록 정보 없음,"Applications of solar power are also increasingly common. In this paper, we explained the characteristics of our new discriminator based on solar energy and CNN for number recognition. Our CNN(Convolution Neural Network) is one in deep learning models with the function of human visual perception. The neural network model carries out the image feature matching process to recognize entered digital images. Our proposed CNN structure was designed with multiple hidden layers to retrieve the features of handwritten numeral images. The CNN structure performs 2D image convolution operation to extract noise, edge and stroke information from the numeral images. These feature information from the convolution layers is served as a new input stream of FCN(Fully Connected Network) for the classification of the features. The FCN performs a classification procedure based on the protypes already deployed for numeral image matching. We used MNIST(Modified National Institute of Standards and Technology) data set to achieve objective recognition measurement. The 60,000 samples of MNIST data set were applied for the learning process of our CNN recognizer, while we used the 10,000 samples for the performance measurement of our CNN recognizer. The measurement experiments were carried out after the repeating the training process of CNN only two times. The several misrecognition results were observed in our performance test, therefore we performed the additional training step to enhance the recognition rate of our CNN. Our additional method is the distortion of our input samples. we performed serveral distortion function such as a scaling, a rotation, and an elastic. In the final measurement of CNN recognizer, we observed that the recognition rate after the applying distortion process was improved by about 98.04%."
Generation of PET Attenuation Map for Whole-Body Time-of-Flight <sup>18</sup>F-FDG PET/MRI Using a Deep Neural Network Trained with Simultaneously Reconstructed Activity and Attenuation Maps,2019,"['PET/MRI', 'attenuation correction', 'deep learning', 'simultaneous reconstruction']",국문 초록 정보 없음,"<P>We propose a new deep learning–based approach to provide more accurate whole-body PET/MRI attenuation correction than is possible with the Dixon-based 4-segment method. We use activity and attenuation maps estimated using the maximum-likelihood reconstruction of activity and attenuation (MLAA) algorithm as inputs to a convolutional neural network (CNN) to learn a CT-derived attenuation map. <B>Methods:</B> The whole-body <SUP>18</SUP>F-FDG PET/CT scan data of 100 cancer patients (38 men and 62 women; age, 57.3 ± 14.1 y) were retrospectively used for training and testing the CNN. A modified U-net was trained to predict a CT-derived μ-map (μ-CT) from the MLAA-generated activity distribution (λ-MLAA) and μ-map (μ-MLAA). We used 1.3 million patches derived from 60 patients’ data for training the CNN, data of 20 others were used as a validation set to prevent overfitting, and the data of the other 20 were used as a test set for the CNN performance analysis. The attenuation maps generated using the proposed method (μ-CNN), μ-MLAA, and 4-segment method (μ-segment) were compared with the μ-CT, a ground truth. We also compared the voxelwise correlation between the activity images reconstructed using ordered-subset expectation maximization with the μ-maps, and the SUVs of primary and metastatic bone lesions obtained by drawing regions of interest on the activity images. <B>Results:</B> The CNN generates less noisy attenuation maps and achieves better bone identification than MLAA. The average Dice similarity coefficient for bone regions between μ-CNN and μ-CT was 0.77, which was significantly higher than that between μ-MLAA and μ-CT (0.36). Also, the CNN result showed the best pixel-by-pixel correlation with the CT-based results and remarkably reduced differences in activity maps in comparison to CT-based attenuation correction. <B>Conclusion:</B> The proposed deep neural network produced a more reliable attenuation map for 511-keV photons than the 4-segment method currently used in whole-body PET/MRI studies.</P>"
Classification of schizophrenia and normal controls using 3D convolutional neural network and outcome visualization,2019,"['Classification accuracy', 'Convolutional neural network', 'Support vector machine', 'Saliency map', 'Schizophrenia']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P><B>Background</B></P> <P>The recent deep learning-based studies on the classification of schizophrenia (SCZ) using MRI data rely on manual extraction of feature vector, which destroys the 3D structure of MRI data. In order to both identify SCZ and find relevant biomarkers, preserving the 3D structure in classification pipeline is critical.</P>   <P><B>Objectives</B></P> <P>The present study investigated whether the proposed 3D convolutional neural network (CNN) model produces higher accuracy compared to the support vector machine (SVM) and other 3D-CNN models in distinguishing individuals with SCZ spectrum disorders (SSDs) from healthy controls. We sought to construct saliency map using class saliency visualization (CSV) method.</P>   <P><B>Methods</B></P> <P>Task-based fMRI data were obtained from 103 patients with SSDs and 41 normal controls. To preserve spatial locality, we used 3D activation map as input for the 3D convolutional autoencoder (3D-CAE)-based CNN model. Data on 62 patients with SSDs were used for unsupervised pretraining with 3D-CAE. Data on the remaining 41 patients and 41 normal controls were processed for training and testing with CNN. The performance of our model was analyzed and compared with SVM and other 3D-CNN models. The learned CNN model was visualized using CSV method.</P>   <P><B>Results</B></P> <P>Using task-based fMRI data, our model achieved 84.15%∼84.43% classification accuracies, outperforming SVM and other 3D-CNN models. The inferior and middle temporal lobes were identified as key regions for classification.</P>   <P><B>Conclusions</B></P> <P>Our findings suggest that the proposed 3D-CAE-based CNN can classify patients with SSDs and controls with higher accuracy compared to other models. Visualization of salient regions provides important clinical information.</P>"
Facial Data Visualization for Improved Deep Learning Based Emotion Recognition,2019,"['facial expression recognition', 'convolutional neural network', 'facial landmark points', 'facial geometry visualization']",국문 초록 정보 없음,"A convolutional neural network (CNN) has been widely used in facial expression recognition (FER) because it can automatically learn discriminative appearance features from an expression image. To make full use of its discriminating capability, this paper suggests a simple but effective method for CNN based FER. Specifically, instead of an original expression image that contains facial appearance only, the expression image with facial geometry visualization is used as input to CNN. In this way, geometric and appearance features could be simultaneously learned, making CNN more discriminative for FER. A simple CNN extension is also presented in this paper, aiming to utilize geometric expression change derived from an expression image sequence. Experimental results on two public datasets (CK+ and MMI) show that CNN using facial geometry visualization clearly outperforms the conventional CNN using facial appearance only."
Convolutional Neural Network for Monocular Vision-based Multi-target Tracking,2019,"['CNN-based multi-target detection', 'indoor quadrotor tracking', 'monocular vision', 'multi-target tracking', 'three-dimensional indoor quadrotor simulator']",국문 초록 정보 없음,"This paper addresses multi-target tracking using a monocular vision sensor. To overcome the fundamental observability issue of the monocular vision, a convolutional neural network (CNN)-based method is proposed.The method combines a CNN-based multi-target detection into a model-based multi-target tracking framework. While previous CNN applications to image-based object recognition and tracking focused on prediction of region of interest (RoI), the proposed method allows for prediction of the three-dimensional position information of the moving objects of interest. This is achieved by appropriately construct a network tailored to the moving object tracking problems with potentially occluded objects. In addition, the cubature Kalman filter integrated with a data association scheme is adopted for effective tracking of nonlinear motion of the objects with the measurements information from the learned network. A virtual simulator that generates the trajectories of the target motions and a sequence of images of the scene has been developed and used to test and verify the proposed CNN scheme. Simulation case studies demonstrate that the proposed CNN improves the position accuracy in the depth direction substantially."
합성곱신경망 테스트 자료에 따른 파노라마 방사선 사진에서의 골다공증 판독의 차이,2019,"['CNN', 'Osteoporosis', 'DR panoramic radiographs', 'CR panoramic radiographs']",국문 초록 정보 없음,"This study was conducted as part of a series of studies to introduce the Convolutional Neural Network(CNN) into the diagnostic eld of osteoporosis. The purpose of this study was to compare the results when testing Digital Radiography(DR) and Computed adiography(CR) panoramic radiographs by CNN that were trained by DR panoramic radiographs. The digital panoramic radiographs f females who visited for the purpose of diagnosis and treatment at Chonnam National University Dental Hospital were taken. Two Oral and Maxillofacial Radiologists were selected for the study to compare the panoramic radiographs with normal and osteoporosis mages. Among them, 1068 panoramic radiographs of females{Mean [± standard deviation] age: 49.19 ± 21.91 years} obtained by DR method were used for training of CNN. 200 panoramic radiographs of females{Mean [± standard deviation] age: 63.95 ± 6.45 years} btained by DR method and 202 panoramic radiographs of females{Mean [± standard deviation] age: 62.00 ± 6.86 years} obtained by R method were used for testing of CNN. When the DR panoramic radiographs were tested, the Accuracy was 92.5%. When the CR anoramic radiographs were tested, the Accuracy was 76.2%. It can be seen that the CNN trained by DR panoramic radiographs is uitable to be tested with the same DR panoramic radiographs."
딥 뉴럴네트워크 기반의 소리 이벤트 검출,2019,"['딥 뉴럴 네트워크', '소리 이벤트 검출', '컨벌루셔널 리커런트 뉴럴 네트워크', 'Deep Neural Networks', 'Sound Event Detection', 'Convolutional Recurrent Neural Networks']","본 논문에서는 다양한 구조의 딥 뉴럴 네트워크를 소리 이벤트 검출을 위하여 적용하였으며 공통의 오디오 데이터베이스를 이용하여 그들 간의 성능을 비교 하였다. FNN, CNN, RNN 그리고 CRNN이 주어진 오디오데이터베이스 및 딥 뉴럴 네트워크의 구조에 최적화된 하이퍼파라미터 값을 이용하여 구현되었다. 구현된 방식 중에서 CRNN이 모든 테스트 환경에서 가장 좋은 성능을 보였으며 그 다음으로 CNN의 성능이 우수함을 알 수 있었다. RNN은 오디오 신호에서의 시간 상관관계를 잘 추적하는 장점에도 불구하고 CNN 과 CRNN에 비해서 저조한 성능을 보임을 확인 할 수 있었다.","In this paper, various architectures of deep neural networks were applied for sound event detection and their performances were compared using a common audio database. FNN, CNN, RNN and CRNN were implemented using hyper-parameters optimized for the database as well as the architecture of each neural network. Among the implemented deep neural networks, CRNN performed best at all testing conditions and CNN followed CRNN in performance. Although RNN has a merit in tracking the time-correlations in audio signals, it showed poor performance compared with CNN and CRNN."
Comparison between convolutional neural networks and random forest for local climate zone classification in mega urban areas using Landsat images,2019,"['Local climate zone', 'Convolutional neural networks', 'Random forest', 'Urban climate', 'Landsat']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>The Local Climate Zone (LCZ) scheme is a classification system providing a standardization framework to present the characteristics of urban forms and functions, especially for urban heat island (UHI) research. Landsat-based 100 m resolution LCZ maps have been classified by the World Urban Database and Portal Tool (WUDAPT) method using a random forest (RF) machine learning classifier. Some studies have proposed modified RF and convolutional neural network (CNN) approaches. This study aims to compare CNN with an RF classifier for LCZ mapping in great detail. We designed five schemes (three RF-based schemes (S1–S3) and two CNN-based ones (S4–S5)), which consist of various combinations of input features from bitemporal Landsat 8 data over four global mega cities: Rome, Hong Kong, Madrid, and Chicago. Among the five schemes, the CNN-based one with the incorporation of a larger neighborhood information showed the best classification performance. When compared to the WUDAPT workflow, the overall accuracies for entire land cover classes (OA) and for urban LCZ types (i.e., LCZ1-10; OA<SUB>urb</SUB>) increased by about 6–8% and 10–13%, respectively, for the four cities. The transferability of LCZ models for the four cities were evaluated, showing that CNN consistently resulted in higher accuracy (increased by about 7–18% and 18–29% for OA and OA<SUB>urb</SUB>, respectively) than RF. This study revealed that the CNN classifier classified particularly well for the specific LCZ classes in which buildings were mixed with trees or buildings or plants were sparsely distributed. The research findings can provide a basis for guidance of future LCZ classification using deep learning.</P>"
합성곱 신경망을 이용한 아스팔트 콘크리트 도로포장 표면균열 검출,2019,"['딥러닝', '합성곱 신경망', '아스팔트 도로포장', '아스팔트 도로포장 표면균열', 'Deep learning', 'Convolutional Neural Network', 'Asphalt Pavement', 'Surface Crack']","본 연구에서는 아스팔트 콘크리트 도로포장의 표면균열 검출을 위해 합성곱 신경망을 이용하였다. 합성곱 신경망의 학습에 사용되는 표면균열 이미지 데이터의 양에 따른 합성곱 신경망의 성능향상 정도를 평가하였다. 사용된 합성곱 신경망의 구조는 5개의 층으로 구성되어있으며, 3x3 크기의 convolution filter와 2x2 크기의 pooling kernel을 사용하였다. 합성곱 신경망의 학습을 위해서 도로노면 조사 장비를 통해 구축된 국내 도로포장 표면균열 이미지를 활용하였다. 표면균열 이미지 데이터를 학습한 합성곱 신경망 모델의 표면균열 검출 정확도, 정밀도, 재현율, 미검출율, 과검출율을 평가하였다. 가장 많은 양의 데이터를 학습한 합성곱 신경망 모델의 표면균열 검출 정확도, 정밀도, 재현율은 96.6% 이상, 미검출율, 과검출율은 3.4% 이하의 성능을 나타내었다.","A Convolution Neural Network(CNN) model was utilized to detect surface cracks in asphalt concrete pavements. The CNN used for this study consists of five layers with 3x3 convolution filter and 2x2 pooling kernel. Pavement surface crack images collected by automated road surveying equipment was used for the training and testing of the CNN. The performance of the CNN was evaluated using the accuracy, precision, recall, missing rate, and over rate of the surface crack detection. The CNN trained with the largest amount of data shows more than 96.6% of the accuracy, precision, and recall as well as less than 3.4% of the missing rate and the over rate."
Convolutional neural network for ultrasonic weldment flaw classification in noisy conditions,2019,"['Convolutional neural network (CNN)', 'Signal to noise ratio (SNR)', 'Ultrasonic testing', 'Weldment flaw classification']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>Ultrasonic flaw classification in weldment is an active area of research and many artificial intelligence approaches have been applied to automate this process. However, in the industrial applications, the ultrasonic flaw signals are not noise free and automatic intelligent defect classification algorithms show relatively low classification performance. In addition, most of the algorithms require some statistical or signal processing techniques to extract some features from signals in order to make classification easier. In this article, the convolutional neural network (CNN) is applied to noisy ultrasonic signatures to improve classification performance of weldment defects and applicability. The result shows that CNN is robust, does not require specific feature extraction methods and give considerable high defect classification accuracies even for noisy signals.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Investigation of CNN for classification of noisy ultrasonic flaw signals. </LI> <LI>  Time shifting of signals for data augmentation. </LI> <LI>  Performance comparison of fully connected deep neural network and CNN. </LI> </UL> </P>"
패션 이미지 카테고리 분류를 이용한 웹사이트,2019,"['Computer Vision', 'Artificial Intelligence', 'CNN', 'Image Classification', 'Web', 'Web Standard']","옷을 구매할 때 중요하게 여겨지는 요소 중 하나는 바로 다른 부위의 옷과의 조합이다. 여러 온라인 스토어에서는 판매자가 임의로 조합한 옷들을 보여주기도 한다. 그러나, 이는 사용자가 원하는 조합을 알아보기에는 한계가 있다. SNS 그리고 인공지능 기술을 융합하여 패션 조합에 대한 검색 문제를 해결하는 방안을 연구하였다.  웹 사이트를 기반으로 사람들이 자신의 패션 사진을 웹사이트상에 업로드하여 타인과 공유하며 조합을 선택하여 선택된 조건과 일치하는 사진들을 제공한다. 그리고 이를 바탕으로 통계적으로 어떤 옷이 많이 업로드되었고 어떤 조합이 인기가 있는지 확인할 수 있도록 한다. 인공지능 기술의 경우 인공신경망의 한 종류인 Convolutional Neural Network(이하 CNN)을 이용한다. CNN을 통한 이미지 카테고리 분류를 해당 웹사이트와 연동하여 사용한다. 이미지 속에서 사람을 인식한다. 그리고 성별, 상의의 종류 및 무늬와 하의의 종류 및 무늬를 분류한다. 이 정보들을 저장하여 조합 검색 기능 및 통계 기능에 활용한다.  이를 통해 기대하는 효과는 다음과 같다. 먼저, 웹사이트를 통해 사용자는 자신이 원하는 조합을 쉽게 확인할 수 있다. 두 번째는 바로 사람들이 선호하는 패션을 간단하게나마 통계적으로 확인할 수 있다는 점이다, 옷을 구매하거나 판매할 때 이를 바탕으로 정보를 활용할 수 있음을 기대한다.","One of the important factors in buying clothes is the combination of clothes from other parts. Many online stores even show a random combination of clothes. However, this is limited to identifying the combinations that users want. The search problem for fashion combinations was studied by merging SNS and artificial intelligence technology.  Based on the website, people upload their fashion photos to the website, share them with others, and choose a combination to provide pictures that match the chosen condition. And based on this, we can statistically see which clothes have been uploaded and which combinations are popular. In the case of artificial intelligence technology, it uses a type of artificial neural network called CNN. Image category classification via CNN is used in conjunction with the website concerned. recognize a person in an image They also classify gender, type of top and pattern and type and pattern of bottom. These information are stored and used for combinatorial search and statistical functions.  The effects expected from this are as follows: First, through the website, users can easily see the combination they want. The second is that people can simply check their preferred fashion statistically, albeit simply, and expect that information can be used based on it when purchasing or selling clothes."
딥 러닝 및 칼만 필터를 이용한 객체 추적 방법,2019,"['YOLO', 'Kalman filter', 'Object tracking', 'CNN', 'Deep learning']","딥 러닝의 대표 알고리즘에는 영상 인식에 주로 사용되는 CNN(Convolutional Neural Networks), 음성인식 및 자연어 처리에 주로 사용되는 RNN(Recurrent Neural Networks) 등이 있다. 이 중 CNN은 데이터로부터 자동으로 특징을 학습하는 알고리즘으로 특징 맵을 생성하는 필터까지 학습할 수 있어 영상 인식 분야에서 우수한 성능을 보이면서 주류를 이루게 되었다. 이후, 객체 탐지 분야에서는 CNN의 성능을 향상하고자 R-CNN 등 다양한 알고리즘이 등장하였으며, 최근에는 검출 속도 향상을 위해 YOLO(You Only Look Once), SSD(Single Shot Multi-box Detector) 등의 알고리즘이 제안되고 있다. 하지만 이러한 딥러닝 기반 탐지 네트워크는 정지 영상에서 탐지의 성공 여부를 결정하기 때문에 동영상에서의 안정적인 객체 추적 및 탐지를 위해서는 별도의 추적 기능이 필요하다. 따라서 본 논문에서는 동영상에서의 객체 추적 및 탐지 성능 향상을 위해 딥 러닝 기반 탐지 네트워크에 칼만 필터를 결합한 방법을 제안한다. 탐지 네트워크는 실시간 처리가 가능한 YOLO v2를 이용하였으며, 실험 결과 제안한 방법은 기존 YOLO v2 네트워크에 비교하여 7.7%의 IoU 성능 향상 결과를 보였고 FHD 영상에서 20 fps의 처리 속도를 보였다.",다국어 초록 정보 없음
Speckle-Noise-Invariant Convolutional Neural Network for SAR Target Recognition,2019,[],국문 초록 정보 없음,"<P>Speckle noise is inherent to synthetic aperture radar (SAR) images and degrades the target recognition performance. Deep learning based on convolutional neural networks (CNNs) has been widely applied for SAR target recognition, but the extracted features are still sensitive to speckle noise. In addition, speckle noise has been seldom considered in such CNN-based approaches. In this letter, we propose a speckle-noise-invariant CNN that employs regularization for minimizing feature variations caused by this noise. Before CNN training, we performed SAR image despeckling using the improved Lee sigma filter for feature extraction. Then, we generated SAR images for CNN training by adding speckle noise to the despeckled images. The proposed regularization improves both the feature robustness to speckle noise and SAR target recognition. Experiments on the moving and stationary target acquisition and recognition database demonstrate that the proposed CNN notably improves the classification accuracy compared with the conventional methods.</P>"
Refrigerant charge fault detection method of air source heat pump system using convolutional neural network for energy saving,2019,"['Heat pump system', 'Refrigerant charge fault detection', 'Convolutional neural network', 'Quantitative prediction', 'Classification', 'Regression']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>In heat pumps, refrigerant leakage is one of the frequent faults. Since the systems have the best performance at the optimal charge, it is essential to predict refrigerant charge amount. Hence, the refrigerant charge fault detection (RCFD) methods have been developed by researchers. Due to improvements in computing speed and big-data, data-driven techniques such as artificial neural networks (ANNs) have been highlighted recently. However, most existing ANN-based RCFD methods use low-performance shallow neural networks (SNNs) and require the features extracted by experts’ experiences. Also, they have some critical limitations. First, they cannot provide quantitative information on recharge amount due to a simple classification such as undercharge or overcharge. Second, many ANN-based RCFD methods can be used in one operation mode (cooling or heating mode). To improve the limitations, a novel RCFD strategy based on convolutional neural networks (CNNs) was suggested. Two prediction models using classification and regression can predict the quantitative refrigerant amount in both cooling and heating mode with a single model. The mean accuracy of the CNN-based classification model was 99.9% for the learned cases. Also, the CNN-based regression model showed the excellent prediction performance with root-mean-square (RMS) error of 3.1% including the untrained refrigerant charge amount data.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Two quantitative refrigerant charge fault detection (RCFD) methods using CNN for heat pumps. </LI> <LI>  The CNN-based RCFD classification model achieved the prediction accuracy of 99.9%. </LI> <LI>  In the CNN-based regression model, the prediction error was within 3.1% of the RMS error. </LI> <LI>  New methods can predict the refrigerant charge amount in both cooling and heating mode. </LI> </UL> </P>"
Convolutional Neural Network-Based Multi-Target Detection and Recognition Method for Unmanned Airborne Surveillance Systems,2019,"['Convolutional neural network (CNN)', 'Multi-target detection and recognition', 'Unmanned airborne surveillance', 'Bearing angle', 'Airborne surveillance neural network (ASNet)']",국문 초록 정보 없음,"This paper proposes the convolutional neural network (CNN)-based multiple targets detection and recognition method for unmanned airborne surveillance systems. The proposed method is capable of recognizing the target’s type, position and bearing angle. Recently, deep learning approaches using convolutional neural networks (CNNs) have significantly improved the object detection accuracy on benchmark datasets such as Pascal visual object classes (VOC) and common objects in context (COCO) data sets. Typical CNN-based object detection technologies are designed to recognize regions of interest (RoI) and object classes based on VOC or COCO data set criteria only. However, in many surveillance missions, the bearing angle of the object is also an important entity to infer in addition to the RoI and the vehicle-type. This paper proposes a CNN-based object recognition technique called airborne surveillance neural network (ASNet) that can recognize this additional bearing angle information. Indoor experiments demonstrate the validity of the proposed method."
PMU 빅데이터를 활용한 계통고장분류 모델 개발,2019,"['WAMS', 'PMU', 'Big-Data', 'CNN', 'Fault Classification']",국문 초록 정보 없음,"Recently, innovative techniques in artificial intelligence such as machine learning have emerged to efficiently process huge amounts of big data delivered from PMUs to WAMS. Through processing raw data and analyzing big data, It delivers highly useful and valuable system status information to system operators. The types of machine learning vary depending on the usage, but the CNN (Convolution Neural Network) model is mainly used for the post analysis and fault detection(classification) in the power system. In this paper, based on PMU big data, we study the power system fault classification model by using CNN Model. Using Convolution neural network model based on KERAS, the database for each fault type was built and supervised learning was conducted for the model. The constructed model was verified with test data and the validity of the model was verified by inputting the actual power system fault data for the trained model. As a result, developed model classified correctly for the actual fault."
랜섬웨어 방지를 위한 딥러닝 기반의 사용자 비정상 행위 탐지 성능 평가,2019,"['Abnomal behavior detection', 'Anomaly Detection', 'Ransomware', 'Deep Learning', 'Performance Comparison', 'CNN-LSTM', '비정상 행위 탐지', '이상 징후 탐지', '랜섬웨어', '딥러닝', '성능 비교', 'CNN-LSTM']",국문 초록 정보 없음,"With the development of IT technology, computer-related crimes are rapidly increasing, and in recent years, the damage to ransomware infections is increasing rapidly at home and abroad. Conventional security solutions are not sufficient to prevent ransomware infections, and to prevent threats such as malware and ransomware that are evolving, a combination of deep learning technologies is needed to detect abnormal behavior and abnormal symptoms. In this paper, a method is proposed to detect user abnormal behavior using CNN-LSTM model and various deep learning models. Among the proposed models, CNN-LSTM model detects user abnormal behavior with 99% accuracy."
CT Image Conversion among Different Reconstruction Kernels without a Sinogram by Using a Convolutional Neural Network,2019,"['Multidetector computed tomography', 'Image reconstruction', 'Machine learning', 'Emphysema', 'CNN']",국문 초록 정보 없음,"Objective: The aim of our study was to develop and validate a convolutional neural network (CNN) architecture to convert CT images reconstructed with one kernel to images with different reconstruction kernels without using a sinogram.Materials and Methods: This retrospective study was approved by the Institutional Review Board. Ten chest CT scans were performed and reconstructed with the B10f, B30f, B50f, and B70f kernels. The dataset was divided into six, two, and two examinations for training, validation, and testing, respectively. We constructed a CNN architecture consisting of six convolutional layers, each with a 3 x 3 kernel with 64 filter banks. Quantitative performance was evaluated using root mean square error (RMSE) values. To validate clinical use, image conversion was conducted on 30 additional chest CT scans reconstructed with the B30f and B50f kernels. The influence of image conversion on emphysema quantification was assessed with Bland–Altman plots.Results: Our scheme rapidly generated conversion results at the rate of 0.065 s/slice. Substantial reduction in RMSE was observed in the converted images in comparison with the original images with different kernels (mean reduction, 65.7%; range, 29.5–82.2%). The mean emphysema indices for B30f, B50f, converted B30f, and converted B50f were 5.4 ± 7.2%, 15.3 ± 7.2%, 5.9 ± 7.3%, and 16.8 ± 7.5%, respectively. The 95% limits of agreement between B30f and other kernels (B50f and converted B30f) ranged from -14.1% to -2.6% (mean, -8.3%) and -2.3% to 0.7% (mean, -0.8%), respectively.Conclusion: CNN-based CT kernel conversion shows adequate performance with high accuracy and speed, indicating its potential clinical use."
합성곱 신경망 기반의 딥러닝에 의한 수치표면모델의 객체분류,2019,"['합성곱 신경망', '딥러닝 모델', '학습 및 검증 데이터', '수치표면모델 분류', 'CNN', 'DL Model', 'Training and Validation Data', 'DSM Classification']","최근 딥러닝(DL)은 여러 분야에서 급속도로 활용되고 있으며, 특히 영상으로부터 객체를 인식하여 분류하고 인식하기 위한 컴퓨터비전 분야에서 활발하게 연구가 진행되고 있다. 영상분야에서는 주로 합성곱 신경망(CNN)을 이용한 딥러닝 모델의 성능 향상에 주력하고 있다. 대부분의 합성곱 신경망은 영상을 학습시켜 영상분류 및 객체인식에 활용하고 있지만, 본 논문에서는 독일 사진측량, 원격탐사 및 공간정보학회(DGPF)가 구축하고 국제 사진측량 및 원격탐사학회(ISPRS)가 제공하는 데이터 셋 중에서 수치표면모델(DSM)과 이 데이터로부터 생성한 경사 및 주향 정보를 효율성과 성능이 우수하다고 평가받는 합성곱 신경망기반의 SegNet 모델에 적용하여 객체를 분류하고 분석하였다. 딥러닝은 고사양의 컴퓨터 시스템과 다량의 학습 데이터와 라벨 데이터가 필요하고, 다수의 시행착오에 의한 풍부한 경험이 요구된다. 또한 본 논문에서는 한정된 수량의 데이터로부터 효율적인 학습을 위한 데이터 생성 방법을 제시하고 수치표면모델을 분류하였다. 분석 결과 수치표면모델 데이터와 이로부터 도출한 부가적인 데이터를 딥러닝 모델에 적용해도 객체를 타당한 정확도로 분류할 수 있음을 확인하였다.","Recently, DL (Deep Learning) has been rapidly applied in various fields. In particular, classification and object recognition from images are major tasks in computer vision. Most of the DL utilizing imagery is primarily based on the CNN (Convolutional Neural Network) and improving performance of the DL model is main issue. While most CNNs are involve with images for training data, this paper aims to classify and recognize objects using DSM (Digital Surface Model), and slope and aspect information derived from the DSM instead of images. The DSM data sets used in the experiment were established by DGPF (German Society for Photogrammetry, Remote Sensing and Geoinformatics) and provided by ISPRS (International Society for Photogrammetry and Remote Sensing). The CNN-based SegNet model, that is evaluated as having excellent efficiency and performance, was used to train the data sets. In addition, this paper proposed a scheme for training data generation efficiently from the limited number of data. The results demonstrated DSM and derived data could be feasible for semantic classification with desirable accuracy using DL."
Hedging Deep Features for Visual Tracking,2019,[],국문 초록 정보 없음,"<P>Convolutional Neural Networks (CNNs) have been applied to visual tracking with demonstrated success in recent years. Most CNN-based trackers utilize hierarchical features extracted from a certain layer to represent the target. However, features from a certain layer are not always effective for distinguishing the target object from the backgrounds especially in the presence of complicated interfering factors (e.g., heavy occlusion, background clutter, illumination variation, and shape deformation). In this work, we propose a CNN-based tracking algorithm which hedges deep features from different CNN layers to better distinguish target objects and background clutters. Correlation filters are applied to feature maps of each CNN layer to construct a weak tracker, and all weak trackers are hedged into a strong one. For robust visual tracking, we propose a hedge method to adaptively determine weights of weak classifiers by considering both the difference between the historical as well as instantaneous performance, and the difference among all weak trackers over time. In addition, we design a Siamese network to define the loss of each weak tracker for the proposed hedge method. Extensive experiments on large benchmark datasets demonstrate the effectiveness of the proposed algorithm against the state-of-the-art tracking methods.</P>"
Deep Learning Algorithm for Reducing CT Slice Thickness: Effect on Reproducibility of Radiomic Features in Lung Cancer,2019,"['Computed tomography', 'Radiomics', 'Slice thickness', 'Deep learning']",국문 초록 정보 없음,"Objective: To retrospectively assess the effect of CT slice thickness on the reproducibility of radiomic features (RFs) of lung cancer, and to investigate whether convolutional neural network (CNN)-based super-resolution (SR) algorithms can improve the reproducibility of RFs obtained from images with different slice thicknesses. Materials and Methods: CT images with 1-, 3-, and 5-mm slice thicknesses obtained from 100 pathologically proven lung cancers between July 2017 and December 2017 were evaluated. CNN-based SR algorithms using residual learning were developed to convert thick-slice images into 1-mm slices. Lung cancers were semi-automatically segmented and a total of 702 RFs (tumor intensity, texture, and wavelet features) were extracted from 1-, 3-, and 5-mm slices, as well as the 1-mm slices generated from the 3- and 5-mm images. The stabilities of the RFs were evaluated using concordance correlation coefficients (CCCs). Results: The mean CCCs for the comparisons of original 1 mm vs. 3 mm, 1 mm vs. 5 mm, and 3 mm vs. 5 mm images were 0.41, 0.27, and 0.65, respectively (p < 0.001 for all comparisons). Tumor intensity features showed the best reproducibility while wavelets showed the lowest reproducibility. The majority of RFs failed to achieve reproducibility (CCC ≥ 0.85; 3.6%, 1.0%, and 21.5%, respectively). After applying the CNN-based SR algorithms, the reproducibility significantly improved in all three pairings (mean CCCs: 0.58, 0.45, and 0.72; p < 0.001 for all comparisons). The reproducible RFs also increased (36.3%, 17.4%, and 36.9%, respectively). Conclusion: The reproducibility of RFs in lung cancer is significantly influenced by CT slice thickness, which can be improved by the CNN-based SR algorithms."
Code authorship identification using convolutional neural networks,2019,"['Code authorship identification', 'Program features privacy', 'Convolutional neural network', 'Deep learning identification', 'Software forensics and security']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>Although source code authorship identification creates a privacy threat for many open source contributors, it is an important topic for the forensics field and enables many successful forensic applications, including ghostwriting detection, copyright dispute settlements, and other code analysis applications. This work proposes a convolutional neural network (CNN) based code authorship identification system. Our proposed system exploits term frequency-inverse document frequency, word embedding modeling, and feature learning techniques for code representation. This representation is then fed into a CNN-based code authorship identification model to identify the code’s author. Evaluation results from using our approach on data from Google Code Jam demonstrate an identification accuracy of up to 99.4% with 150 candidate programmers, and 96.2% with 1,600 programmers. The evaluation of our approach also shows high accuracy for programmers identification over real-world code samples from 1987 public repositories on GitHub with 95% accuracy for 745 C programmers and 97% for the C++ programmers. These results indicate that the proposed approaches are not language-specific techniques and can identify programmers of different programming languages.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  We proposed three CNN-based code authorship identification systems. </LI> <LI>  We explained various source code representations and our feature learning technique. </LI> <LI>  We then fed the code representations into a CNN-based code authorship model. </LI> <LI>  Large-scale code authorship process of different programming languages is conducted. </LI> <LI>  Our technique identified a large number of programmers (1,600) with 99.5% accuracy. </LI> </UL> </P>"
Convolutional Neural Network with Expert Knowledge for Hyperspectral Remote Sensing Imagery Classification,2019,"['Hyperspectral imagery classification', 'convolutional neural network', 'principal component analysis', 'gray-level co-occurrence matrix', 'differential Mathematical morphology']",국문 초록 정보 없음,"The recent interest in artificial intelligence and machine learning has partly contributed to an interest in the use of such approaches for hyperspectral remote sensing (HRS) imagery classification, as evidenced by the increasing number of deep framework with deep convolutional neural networks (CNN) structures proposed in the literature. In these approaches, the assumption of obtaining high quality deep features by using CNN is not always easy and efficient because of the complex data distribution and the limited sample size. In this paper, conventional handcrafted learning-based multi features based on expert knowledge are introduced as the input of a special designed CNN to improve the pixel description and classification performance of HRS imagery. The introduction of these handcrafted features can reduce the complexity of the original HRS data and reduce the sample requirements by eliminating redundant information and improving the starting point of deep feature training. It also provides some concise and effective features that are not readily available from direct training with CNN. Evaluations using three public HRS datasets demonstrate the utility of our proposed method in HRS classification."
전역특징과 국소특징 기반 심층학습에 의한 질감영상의 분류,2019,"['Texture classification', 'Feature extraction', 'Dominant neighborhood structure(DNS)', 'Global neighborhood structure(GNS)', 'Deep learning', '질감분류', '특징추출', '지배적 이웃구조', '전역 이웃구조', '국소이진패턴', '심층학습']","본 논문에서는 전역특징과 국소특징을 조합한 심층학습에 기반을 둔 질감영상의 분류기법을 제안한다. 여기서 전역특징은비국소적이며 잡음에 강건한 Dominant neighborhood structure(DNS) 지도를 이용한 Global neighborhood structure(GNS) 지도로부터 추출되며, 국소특징은 국부적인 구조를 효과적으로 요약하는 비모수적 서술자인 Local binary pattern(LBP)에의해 추출된다. 추출된 전역특징과 국소특징을 선형적으로 조합하여 Convolutional neural network(CNN)으로 심층학습을수행함으로써 질감영상을 분류한다. 제안된 기법의 성능을 확인하기 위하여 9종의 임의의 크기를 가지는 질감영상을대상으로 실험한 결과, 특징을 이용하지 않는 CNN의 심층학습에 의한 기법보다 우수한 분류성능이 있음을 확인하였다. 또한전역특징과 국소특징을 조합한 제안방법이 어느 하나의 특징만을 이용한 기법보다도 상대적으로 우수한 분류성능도 있음을알 수 있다.","In this paper, we propose a texture classification method based on deep learning using both global features and local features. The global features are extracted from the global neighborhood structure(GNS) map by dominant neighborhood structure(DNS) maps which are non-local and robust to noise. And the local features are also extracted by local binary pattern(LBP) which is a non-parametric descriptor that effectively summarizes local structures of images. Texture images are classified by performing deep learning with convolutional neural network(CNN) by linearly combining extracted global features and local features. In order to verify the performance of the proposed technique, we experimented with texture images with arbitrary sizes of 9 types and found that it has better classification performance than deep learning with CNN which does not use features. Also, it can be seen that the proposed method has relatively better classification performance than the method using only one feature."
Facile synthesis of Br-doped g-C3N4 nanosheets via one-step exfoliation using ammonium bromide for photodegradation of oxytetracycline antibiotics,2019,['Photocatalyst g-C3N4 Nanosheets Antibiotics Exfoliation Ammonium salts'],국문 초록 정보 없음,"Graphitic carbon nitride (g-C3N4) was suggested since it enables the oxidation process under visible lightirradiation. To enhance the photocatalytic activity of g-C3N4 (BCN) it is essential to exfoliate bulk g-C3N4to the nanosheets form via a one-step exfoliation method, which was used to prepare g-C3N4 nanosheetswith Br (CNN-Br) or Cl (CNN-Cl) doping by using melamine and ammonium salts. Thefinal productionyield reached 52% and the specific volume of CNN-Br was eight times compared to BCN. The Cl and Brdoping of g-C3N4 was changed to increase the light absorbance in the visible-light region and to slightlydecrease the bandgap energy of the samples. Additionally, the photocurrent densities of the CNN sampleswere enhanced compared with that of BCN. We evaluated the photocatalytic performance of theresultant nanosheets for the photodegradation of oxytetracycline under visible-light irradiation. Theresults showed that the Br or Cl doping of g-C3N4 and the nanosheet structure had synergetic effects,namely enhancing the absorbance in the visible-light region, the efficiency of photoinduced chargecarriers, and the charge-separation capability. These improvements are useful for the photocatalyticdegradation of antibiotics."
A Recommendation Model based on Character-level Deep Convolution Neural Network,2019,[],"추천 시스템의 등급 예측 정확도를 높이기 위해서는, 사용자 항목 등급 데이터뿐만 아니라 주석, 태그 또는 설명과 같은 항목의 보조 정보도 고려해야만 한다. 기존 접근법에서는 단어 단위에서 bag-of-words 모델을 사용하여 보조 정보를 모델링한다. 그러나 이러한 모델은 보조 정보를 효과적으로 활용할 수 없으므로 보조 정보를 제한적으로 이해하게 된다. 한편, 컨볼루션 신경망(CNN)에서는 보조 정보로부터 특징 벡터를 효과적으로 포착하고 추출할 수 있다. 따라서 본 논문에서는 새로운 추천 모델을 위해 딥 CNN을 행렬 분해에 통합시킨 문자 수준의 딥 컨볼루션 신경망 기반 행렬 분해 (Char-DCNN-MF) 방법을 제안한다. Char-DCNN-MF에서는 보조 정보를 더 심층적으로 이해하고 추천 성능을 더욱 향상시킬 수 있다. 실험은 세 가지 다른 실제 데이터 세트에서 수행되었으며 그 결과는 Char-DCNN-MF가 다른 비교 모델보다 유의적으로 뛰어난 성능을 보여주었다.","In order to improve the accuracy of the rating prediction of the recommendation model, not only user-item rating data are used but also consider auxiliary information of item such as comments, tags, or descriptions. The traditional approaches use a word-level model of the bag-of-words for the auxiliary information. This model, however, cannot utilize the auxiliary information effectively, which leads to shallow understanding of auxiliary information. Convolution neural network (CNN) can capture and extract feature vector from auxiliary information effectively. Thus, this paper proposes character-level deep-Convolution Neural Network based matrix factorization (Char-DCNN-MF) that integrates deep CNN into matrix factorization for a novel recommendation model. Char-DCNN-MF can deeper understand auxiliary information and further enhance recommendation performance. Experiments are performed on three different real data sets, and the results show that Char-DCNN-MF performs significantly better than other comparative models."
딥러닝 기반의 열연 강판 제품의 표면 결함 판독,2019,"['결함인식', '결함진단', '딥러닝']","철강 제품의 표면 결함은 강판의 품질과 가격을 결정하는 중요한 요인 중 하나다. 때문에 많은 철강 업체는 표면결함을 사전에 판독하여 신속하게 대처하기 위하여 표면 결함 탐상장치와 육안 검사 등에 많은 비용과 시간을 소비하고 있다. 하지만 생산되는 강판 재질 특성에 따라 지속적으로 결함 패턴이 변경되거나 새로운 결함이 추가되는 실세계의 산업현장에서 탐상장치의 결함 판독 성능을 유지시키기 어렵다. 또한 육안 검사는 검사자간의 경험 차이로 인한 휴먼 에러가 발생하여 표면 결함을 정확하게 판독하기 어렵다.따라서 본 논문에서는 영상인식에 강인하고 갱신성이 뛰어난 CNN(Convolution Neural Networks)를 계층적으로 구성하여 보다 지능적이고 높은 정확도를 갖는 새로운 강판 표면 결함 판독 시스템을 제안한다. 제안된 시스템의 첫번째 계층의 CNN은 이진 분류기로 표면 결함을 탐지하고, 두 번째 계층의 CNN은 다중 클래스 분류기로 탐지된 표면 결함의 종류를 ‘선형흠’, ‘비늘형’, ‘스캡’ 등으로 세분화 판독하여 관리자에게 제공해줌으로써 신속하게 품질 이슈에 대응할 수 있도록 돕는다. 본 논문에서 제안하는 시스템의 성능 테스트에서 97.2%의 코일 결함 탐지 정확도와 94.1%의 코일 결함종류 판독 정확도를 보였다. 또한 갱신성이 강한 CNN 고유의 특성상 결함 발생 패턴이 변화하거나 새로운 결함이 추가되더라도 시스템의 점증적 갱신이 가능하며 시스템 성능 유지보수가 용이하다.",다국어 초록 정보 없음
딥러닝을 이용한 WTCI 설태량 평가를 위한 유효성 검증,2019,"['설진', 'WTCI', '설태량', '딥러닝', '콘볼루션 뉴럴 네트워크', 'Tongue Diagnosis', 'WTCI', 'the amount of Tongue Coating', 'Deep Learning', 'Convolutional Neural Network']","한방 설진에서 WTCI(Winkel Tongue Coating Index) 설태 평가는 환자의 설태량 측정을 위한 중요한 객관적인 지표 중의 하나이다. 그러나 이전의 WTCI 설태 평가는 혀영상으로부터 설태 부분을 추출하여 전체 혀 영역에서 추출된 설태 영역의 비율을 정량적으로 측정하는 방법이 대부분으로 혀영상의 촬영 조건이나 설태 인식 성능에 의해서 비객관적 측정의 문제점이 있었다. 따라서 본 논문에서는 빅데이터를 기반으로 하는 인공지능의 딥러닝 방법을 적용하여 설태량을 분류하여 평가하는 딥러닝 기반의 WTCI 평가 방법을 제안하고 검증한다. 설태 평가 방법에 있어서 딥러닝의 유효성 검증을 위해서는 CNN을 학습 모델로 사용하여 소태, 박태, 후태의 3가지 유형의 설태량을 분류한다. 설태 샘플 영상을 학습 및 검증 데이터로 구축하여 CNN 기반의 딥러닝 모델로 학습한 결과 96.7%의 설태량 분류 정확성을 보였다.","A WTCI is an important criteria for evaluating an mount of patient’s tongue coating in tongue diagnosis. However, Previous WTCI tongue coating evaluation methods is a most of quantitatively measuring ration of the extracted tongue coating region and tongue body region, which has a non-objective measurement problem occurring by exposure conditions of tongue image or the recognition performance of tongue coating. Therefore, a WTCI based on deep learning is proposed for classifying an amount of tonger coating in this paper. This is applying the AI deep learning method using big data. to WTCI for evaluating an amount of tonger coating. In order to verify the effectiveness performance of the deep learning in tongue coating evaluating method, we classify the 3 types class(no coating, some coating, intense coating) of an amount of tongue coating by using CNN model. As a results by testing a building the tongue coating sample images for learning and verification of CNN model, proposed method is showed 96.7% with respect to the accuracy of classifying an amount of tongue coating."
A Deep Approach for Classifying Artistic Media from Artworks,2019,"['CNN', 'VGGNet', 'classification', 'artistic media', 'artwork']",국문 초록 정보 없음,"We present a deep CNN-based approach for classifying artistic media from artwork images. We aim to classify most frequently used artistic media including oilpaint brush, watercolor brush, pencil and pastel, etc. For this purpose, we extend VGGNet, one of the most widely used CNN structure, by substituting its last layer with a fully convolutional layer, which reveals class activation map (CAM), the region of classification. We build two artwork image datasets: YMSet that collects more than 4K artwork images for four most frequently used artistic media from various internet websites and WikiSet that collects almost 9K artwork images for ten most frequently used media from WikiArt. We execute a human baseline experiment to compare the classification performance. Through our experiments, we conclude that our classifier is superior in classifying artistic media to human."
압축 영상 화질 개선을 위한 딥 러닝 연구에 대한 분석,2019,"['CNN', 'HEVC', 'Noise Reduction', 'Quality Enhancement']","최근 CNN (Convolutional Neural Network) 기반의 화질 개선 기술이 H.265/HEVC와 같은 블록 기반 영상 압축 표준을 사용하여 압축된 영상의 화질을 향상시키는 데 적극적으로 사용되어 왔다. 이 논문은 이러한 영상 압축 기술을 위한 화질 개선 연구의 추세를 요약하고 분석하는 것을 목표로 한다. 먼저, 화질 개선을 위한 CNN의 구성 요소를 살펴보고 이미지 도메인에서의 사전 연구를 요약한다. 다음으로 네트워크 구조, 데이터셋 및 학습 방법의 세 가지 측면에서 관련 연구들을 정리하고 성능 비교를 위한 구현 및 실험 결과를 제시하고자 한다.",다국어 초록 정보 없음
인명피해를 최소화할 수 있는 제동 방향전환 시스템,2019,"['Autonomous Vehicle', 'CNN', 'Random Forset', 'Deep-Learning', 'V2V']","본 논문에서는 주행 중인 차량이 전방 차량들의 승객 배치 상황을 파악하고 위험 상황에서 인명피해를 최소화할 수 있는 제동 방향을 결정하는 Braking Redirection System(BRS) to minimize casualties in consideration of the passenger""s boarding situation in dangerous situations을 제안한다. 제안하는 시스템은 두 가지 모듈로 구성된다. 첫째, Passenger Situation Extraction Module(PSEM)은 차량에 탑승하고 있는 승객 상황을 추출한다. 둘째, Front Passenger Extraction Situation Module(FPSEM)은 차량에 장착된 카메라와 CNN을 사용하여 차량 전방의 이미지를 분석하고, 분석한 결과를 다른 차량에 전달한다. BRS는 PSEM에서 추출한 승객 배치 상황과 FPSEM에서 추출한 전방 승객 배치 상황을 Random Forest로 연산하여 위험 상황에서 인명피해를 최소화하는 제동 방향을 결정한다. 제안된 시스템은 차량 내부에 체압센서를 사용해 기존에 제안된 시각화 센서를 사용한 승객 탐지 방법보다 승객의 배치 상황을 자세하게 분석하고 높은 정확도를 보장한다.","In this paper, the Braking Redirection System (BRS) to minimize the casualties in consideration of the passenger""s boarding situation in dangerous situations is proposed. The proposed system consists of two modules. First, the Passenger Situation Extraction Module (PSEM) extracts the passenger situation in the vehicle. Second, the Front Passenger Extraction Situation Module (FPSEM) analyzes the image in front of the vehicle using the camera and CNN installed in the vehicle, and delivers the analysis results to other vehicles. The BRS calculates the braking direction to minimize the casualties in the dangerous situation by calculating the passenger arrangement situation extracted from the PSEM and the front passenger arrangement situation extracted from the FPSEM as Random Forest. The proposed system uses a body pressure sensor inside the vehicle to analyze the passenger""s placement in detail and guarantee high accuracy than the passenger detection method using the previously proposed visualization sensor."
SSD 알고리즘 기반 MI-FL을 적용한 회전 불변의 다중 객체 검출 시스템 구현,2019,"['object detection', 'CNN', 'SSD', 'moment invariant']",국문 초록 정보 없음,"Recently, object detection technology based on CNN has been actively studied. Object detection technology is used as an important technology in autonomous vehicles, intelligent image analysis, and so on. In this paper, we propose a rotation change robust object detection system by applying MI-FL (Moment Invariant-Feature Layer) to SSD (Single Shot Multibox Detector) which is one of CNN-based object detectors. First, the features of the input image are extracted based on the VGG network. Then, a total of six feature layers are applied to generate bounding boxes by predicting the location and type of object. We then use the NMS algorithm to get the bounding box that is the most likely object. Once an object bounding box has been determined, the invariant moment feature of the corresponding region is extracted using MI-FL, and stored and learned in advance. In the detection process, it is possible to detect the rotated image more robust than the conventional method by using the previously stored moment invariant feature information. The performance improvement of about 4 ~ 5% was confirmed by comparing SSD with existing SSD and MI-FL."
딥러닝 개념을 위한 인공지능 교육 프로그램,2019,"['Artificial Intelligence', 'Machine Learning', 'Deep Learning', 'CNN', 'SW education', '인공지능', '기계학습', '딥러닝 교육', '컨볼루션네트워크', '소프트웨어교육']","본 연구의 목적은 초등학생을 대상으로 한 딥러닝 개념 학습을 위한 교육 프로그램을 개발하는 것이다. 먼저 문헌연구와 선행연구를 토대로 전문가 그룹 토의를 진행하여 프로그램 개발 방향을 위한 준거를 세웠다. 프로그램의 모델은 CT요소 중심 모델을 토대로 딥러닝 교수학습모델을 개발하였다. 개발한 프로그램의 주제는 인공지능의 이미지인식 CNN알고리즘으로 정하고, 9개 차시 교육프로그램을 개발하였다. 프로그램은 6학년을 대상으로 2주간에 걸쳐 적용을 하였다. 프로그램에 대한 학습 적합도 검사는 전문가들의 타당도와 학습자 만족도 설문 검사를 통해 분석하였다. 전문가 타당도 분석 결과 최소 CVR값이 .56이상을 넘어 타당하게 나왔다. 학습자 수준 적합도와 교사 지도 수준의 적합도 문항의 경우 .80이하로 나타났으며 .96이 넘은 학습 환경과 매체의 적합도 문항에서는 높게 나타났다. 낯선 소재로 인해 교사들이 어려워하기는 하지만 기존 SW 교육에서 실시했던 언플러그드 CS 활용의 접근법을 통해 수업의 적용이 가능함을 보여주고 있음을 알 수 있었다. 학생들의 만족도 분석 결과 학습자들의 참여는 적극적으로 하였음을 알 수 있었고, 인공지능 학습의 이해도와 유익성, 흥미도, 학습자료 등에 대해서 평균 4.0이상을 보여 긍정적인 평가를 하였다. 이에 본 프로그램은 초등학교 현장에서의 인공지능 교수학습자료의 토대를 제공할 수 있음을 알 수 있다.","The purpose of this study is to develop an educational program for learning deep learning concepts for elementary school students. First of all, based on literature and previous research, a group of experts was discussed to establish the criteria for the direction of program development. The model of education program was developed the deep-learning teaching method based on CT element-oriented teaching and learning model. The subject of the developed program is the artificial intelligence image recognition CNN algorithm, and we have developed 9 educational programs.  We applied the program over six weeks to sixth graders. he test of learning suitability for the education program was analyzed through the validity of the experts and the survey on the satisfaction of learners. Expert validity analysis showed that the minimum CVR value was more than .56. The fitness level of learner level and the level of teacher guidance were less than .80, and the fitness of learning environment and media above .96 was high. Although it is difficult for teachers due to the unfamiliar material of artificial intelligence, it can be seen that the class can be applied through the approach of using the unplugged CS that was implemented in the existing SW education. The students' satisfaction analysis showed that the learners actively participated in the class. Students gave a positive evaluation of the average of 4.0 or higher on the understanding, benefit, interest, and learning materials of artificial intelligence learning. Therefore, it can be seen that the educational program developed in this study can provide a foundation for artificial intelligence teaching and learning materials in elementary school."
다중 CCTV 사물인터넷 환경에서의 객체 추적 기법,2019,"['물리 보안', '인공지능', '씨앤앤알고리즘', '객체 검출', '씨씨티비', 'Physical security', 'artificial intelligence', 'CNN algorithm', 'object detection', 'CCTV']",본 연구는 최근 전국적으로 계속해서 사물인터넷 CCTV의 설치 대수가 증가함에 따라 CCTV의 활용범위를넓히고자 CCTV를 통하여 범죄 의심자 또는 이상 행동자를 추적하는 방법을 제안한다. 이상 행동 구분은 기존에 나와있던 연구들을 활용하여 범죄 의심자 또는 이상 행동자를 색출해내고 CNN을 활용하여 대상을 객체와 하여 추적을하고 주변 CCTV를 서로 네트워크로 연결하여 객체화된 대상의 이동 경로를 예측해 해당 경로 근방의 CCTV들에객체의 샘플 데이터를 공유하여 대상 판별 및 해당 대상을 추적하는 방식을 이용하였다. 해당 연구를 통하여 추적하기 힘든 범죄자의 위치를 추적하여 국가 치안에 기여하고 더욱 다양한 기술들이 CCTV에 접목될 수 있도록 지속적인연구가 필요하다.,"This study suggests a methodology to track crime suspects or anomalies through CCTV in order to expand the scope of CCTV use as the number of CCTV installations continues to increase nationwide in recent years. For the abnormal behavior classification, we use the existing studies to find out suspected criminals or abnormal actors, use CNN to track objects, and connect the surrounding CCTVs to each other to predict the movement path of objectified objects CCTVs in the vicinity of the path were used to share objects' sample data to track objects and to track objects. Through this research, we will keep track of criminals who can not be traced, contribute to the national security, and continue to study them so that more diverse technologies can be applied to CCTV."
Visual Speech Recognition of Korean Words Using Convolutional Neural Network,2019,"['Convolutional neural network', 'Human–robot interaction', 'Korean word recognition', 'Viola–Jones algorithm', 'Visual speech recognition']",국문 초록 정보 없음,"In recent studies, speech recognition performance is greatly improved by using HMM and CNN. HMM is studying statistical modeling of voice to construct an acoustic model and to reduce the error rate by predicting voice through image of mouth region using CNN. In this paper, we propose visual speech recognition (VSR) using lip images. To implement VSR, we repeatedly recorded three subjects speaking 53 words chosen from an emergency medical service vocabulary book. To extract images of consonants, vowels, and final consonants in the recorded video, audio signals were used. The Viola–Jones algorithm was used for lip tracking on the extracted images. The lip tracking images were grouped and then classified using CNNs. To classify the components of a syllable including consonants, vowels, and final consonants, the structure of the CNN used VGG-s and modified LeNet-5, which has more layers. All syllable components were classified, and then the word was found by the Euclidean distance. From this experiment, a classification rate of 72.327% using 318 total testing words was obtained when VGG-s was used. When LeNet-5 applied this classifier for words, however, the classification rate was 22.327%."
시간에 따라 변화하는 빗줄기 장면을 이용한 딥러닝 기반 비지도 학습 빗줄기 제거 기법,2019,"['Rain Streak Removal', 'Unsupervised Learning', 'Convolutional Neural Networks', 'Siamese Network']",국문 초록 정보 없음,"Single image rain removal is a typical inverse problem which decomposes the image into a background scene and a rain streak. Recent works have witnessed a substantial progress on the task due to the development of convolutional neural network (CNN). However, existing CNN-based approaches train the network with synthetically generated training examples. These data tend to make the network bias to the synthetic scenes. In this paper, we present an unsupervised framework for removing rain streaks from real-world rainy images. We focus on the natural phenomena that static rainy scenes capture a common background but different rain streak. From this observation, we train siamese network with the real rain image pairs, which outputs identical backgrounds from the pairs. To train our network, a real rainy dataset is constructed via web-crawling. We show that our unsupervised framework outperforms the recent CNN-based approaches, which are trained by supervised manner. Experimental results demonstrate that the effectiveness of our framework on both synthetic and real-world datasets, showing improved performance over previous approaches."
데이터 증강을 통한 딥러닝 기반 주가 패턴 예측 정확도 향상 방안,2019,"['Stock Price Pattern', 'Deep Learning', 'Convolutional Neural Network', 'Data Augmentation', 'Gaussian Noise', '주가 패턴', '딥러닝', '컨볼루셔널 뉴럴 네트워크', '데이터 증강', '가우시안 노이즈']","인공지능 기술이 발전하면서 이미지, 음성, 텍스트 등 다양한 분야에 적용되고 있으며, 데이터가 충분한 경우 기존 기법들에 비해 좋은 결과를 보인다. 주식시장은 경제, 정치와 같은 많은 변수에 의해 영향을 받기 때문에, 주식 가격의 움직임 예측은 어려운 과제로 알려져 있다. 다양한 기계학습 기법과 인공지능 기법을 이용하여 주가 패턴을 연구하여 주가의 등락을 예측하려는 시도가 있어왔다. 본 연구는 딥러닝 기법 중 컨볼루셔널 뉴럴 네트워크(CNN)를 기반으로 주가 패턴 예측률 향상을 위한 데이터 증강 방안을 제안한다. CNN은 컨볼루셔널 계층을 통해 이미지에서 특징을 추출하여 뉴럴 네트워크를 이용하여 이미지를 분류한다. 따라서, 본 연구는 주식 데이터를 캔들스틱 차트 이미지로 만들어 CNN을 통해 패턴을 예측하고 분류하고자 한다. 딥러닝은 다량의 데이터가 필요하기에, 주식 차트 이미지에 다양한 데이터 증강(Data Augmentation) 방안을 적용하여 분류 정확도를 향상 시키는 방법을 제안한다. 데이터 증강 방안으로는 차트를 랜덤하게 변경하는 방안과 차트에 가우시안 노이즈를 적용하여 추가 데이터를 생성하였으며, 추가 생성된 데이터를 활용하여 학습하고 테스트 집합에 대한 분류 정확도를 비교하였다. 랜덤하게 차트를 변경하여 데이터를 증강시킨 경우의 분류 정확도는 79.92%였고, 가우시안 노이즈를 적용하여 생성된 데이터를 가지고 학습한 경우의 분류 정확도는 80.98%이었다. 주가의 다음날 상승/하락으로 분류하는 경우에는 60분 단위 캔들 차트가 82.60%의 정확도를 기록하였다.",다국어 초록 정보 없음
OCEAN: Object-centric arranging network for self-supervised visual representations learning,2019,"['Self-supervised learning', 'Visual representations learning', 'Object proposals', 'Convolutional neural networks']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>Learning visual representations plays an important role in computer vision and machine learning applications. It facilitates a model to understand and perform high-level tasks intelligently. A common approach for learning visual representations is supervised one which requires a huge amount of human annotations to train the model. This paper presents a self-supervised approach which learns visual representations from input images without human annotations. We learn the correct arrangement of object proposals to represent an image using a convolutional neural network (CNN) without any manual annotations. We hypothesize that the network trained for solving this problem requires the embedding of semantic visual representations. Unlike existing approaches that use uniformly sampled patches, we relate object proposals that contain prominent objects and object parts. More specifically, we discover the representation that considers overlap, inclusion, and exclusion relationship of proposals as well as their relative position. This allows focusing on potential objects and parts rather than on clutter. We demonstrate that our model outperforms existing self-supervised learning methods and can be used as a generic feature extractor by applying it to object detection, classification, action recognition, image retrieval, and semantic matching tasks.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  A self-supervised learning which does not require human annotations for training CNN. </LI> <LI>  Learning the correct arrangement of object proposals to represent an image by CNN. </LI> <LI>  Demonstrating the advantage of our model by applying it to PASCAL VOC datasets. </LI> <LI>  Application to other vision tasks including image retrieval and semantic matching. </LI> </UL> </P>"
유도 전동기의 속도 및 부하 조건을 고려한 딥러닝 고장 진단 알고리즘 개발에 관한 연구,2019,"['Deep learning', 'Motor fault diagnosis', 'CNN', 'Data analysis', 'Induction motor', 'FFT', 'Frequency domain']",국문 초록 정보 없음,"The motor mechanical fault has been diagnosed under fixed driving conditions. The induction motor speed is affected not only by the input frequency but also by the load. In addition, the vibration generated by the induction motor is affected by the speed as well as the input frequency. For these reasons, a data preprocessing algorithm has been developed that shifts the measured data in the frequency domain based on motor speed. The algorithm also takes the input frequency as an input variable and removes the vibration component by the power source frequency. The data processed by the above procedure are classified through the deep learning algorithm based on CNN. As a result, a fault diagnosis system that can be applied to the industrial field has been developed by considering the motor driving conditions using the proposed algorithms."
몬테칼로 렌더링 노이즈 제거를 위한 듀얼 신경망 구조 설계,2019,"['Ray Tracing', 'Denoising', 'MonteCarlo rendering', 'Autoencoder', 'Neural Network', 'Graphics']","본 논문에서는 레이 트레이싱 그래픽에서 사용되는 몬테칼로 렌더링에 포함되는 잡음을 제거하기 위해 개선된 신경망구조 를 설계하였다. 몬테칼로 렌더링은 그래픽의 실감을 높이는데 가장 좋은 방법이지만 픽셀마다 수천 개 이상의 빛 효과를 계산해야 하기 때문에 렌더링 처리시간이 급격히 증가하여 실시간 처리에 큰 문제를 갖고 있다. 이 문제를 개선하기 위해 픽셀에서 사용되는 빛의 수를 줄이게 되는데 이때 렌더링 잡음이 발생하게 되고 이 잡음을 제거하기 위해 다양한 연구가 진행되어 왔다. 본 논문에서는 렌더링 잡음을 제거하는데 딥러닝을 사용하며 특히, 렌더링 이미지를 확산광과 집중광으로 분리하여 이중 신경망 구조를 설계하였다. 설계결과 단일구조 신경망에 비하여 듀얼구조 신경망은 PSNR기준으로 64개 테스트 이미지에 대하여 평균 0.58db가 개선되었으며 reference image에 비하여 99.22% 빛의 수를 줄여 실시간 레이 트레이싱 렌더링을 구현하였다.","In this paper, we designed a revised neural network to remove the Monte Carlo Rendering noise contained in the ray tracing graphics. The Monte Carlo Rendering is the best way to enhance the graphic""s realism, but because of the need to calculate more than thousands of light effects per pixel, rendering processing time has increased rapidly, causing a major problem with real-time processing. To improve this problem, the number of light used in pixels is reduced, where rendering noise occurs and various studies have been conducted to eliminate this noise. In this paper, a deep learning is used to remove rendering noise, especially by separating the rendering image into diffuse and specular light, so that the structure of the dual neural network is designed. As a result, the dual neural network improved by an average of 0.58 db for 64 test images based on PSNR, and 99.22% less light compared to reference image, enabling real-time race-tracing rendering"
Motion Sickness Prediction in Stereoscopic Videos using 3D Convolutional Neural Networks,2019,[],국문 초록 정보 없음,"<P>In this paper, we propose a three-dimensional (3D) convolutional neural network (CNN)-based method for predicting the degree of motion sickness induced by a 360° stereoscopic video. We consider the user's eye movement as a new feature, in addition to the motion velocity and depth features of a video used in previous work. For this purpose, we use saliency, optical flow, and disparity maps of an input video, which represent eye movement, velocity, and depth, respectively, as the input of the 3D CNN. To train our machine-learning model, we extend the dataset established in the previous work using two data augmentation techniques: frame shifting and pixel shifting. Consequently, our model can predict the degree of motion sickness more precisely than the previous method, and the results have a more similar correlation to the distribution of ground-truth sickness.</P>"
심층신경망 구조에 따른 구개인두부전증 환자 음성 인식 향상 연구,2019,[],국문 초록 정보 없음,"This paper proposes speech recognition systems employing Convolutional Neural Network (CNN) and Long Short Term Memory (LSTM) structures combined with Hidden Markov Moldel (HMM) to effectively recognize the speech of VeloPharyngeal Insufficiency (VPI) patients, and compares the recognition performance of the systems to the Gaussian Mixture Model (GMM-HMM) and fully-connected Deep Neural Network (DNNHMM) based speech recognition systems. In this paper, the initial model is trained using normal speakers' speech and simulated VPI speech is used for generating a prior model for speaker adaptation. For VPI speaker adaptation, selected layers are trained in the CNN-HMM based model, and dropout regulatory technique is applied in the LSTM-HMM based model, showing 3.68 % improvement in recognition accuracy. The experimental results demonstrate that the proposed LSTM-HMM-based speech recognition system is effective for VPI speech with small-sized speech data, compared to conventional GMM-HMM and fully-connected DNN-HMM system."
위험 외부 승객 감지 기반 트램 사고 경보 시스템,2019,"['accident warning system(사고 경보 시스템)', 'tram(트램)', 'passenger protection(승객보호)', 'CNN based object detector(CNN기반 물체 검출기)', '위험구역(warning zone)']",국문 초록 정보 없음,다국어 초록 정보 없음
Inception V3 모델을 활용한 관광사진 분류 및 정확도 평가,2019,[],"본 연구는 소셜 네트워크 서비스(Social Network Service, SNS)인 플리커(Flickr)에 공유된 지오태깅된 사진 데이터를 활용하여 관광지 이미지 특성을 분석하고자 한다. 2013년부터 2018년까지 우리나라를 방문한 관광객이 업로드한 약 16만장의 사진을 이용하였다. 사진에 대한 분석은 합성곱 신경망(Convolutional Neural Network, CNN) 중 하나인 Inception V3를 활용하였으며, 사진 분류 정확도를 평가하기 위해 전체 데이터의 약 23%에 달하는 사진 데이터에 대해 수동 라벨링을 하여 사진의 분류 정확도를 평가하였다. 관광 활동으로 생성된 사진 데이터들을 imagenet의 분류 카테고리로 분류할 경우의 한계점을 분석하고 향후 연구과제로 관광 목적에 맞는 이미지 카테고리 개발을 제안하였다.",다국어 초록 정보 없음
딥러닝 기반의 차량 후미등 신호 분류기 연구,2019,"['Taillight Signal Classification(후미등 신호 분류)', 'Sequence to Sequence Model(시퀀스 투 시퀀스 모델)', 'Recurrent Neural Network', 'RNN(순환신경망)', 'C3D Model(C3D 모델)', '3D CNN(3D 콘볼루션 뉴럴 네트워크)']",국문 초록 정보 없음,"Classification of taillight signal for forward vehicles is an important clue for self-driving plans. Accurate taillight recognition requires temporal context grasp over several frames. We build a new dataset that accurately reflects the situation where the taillight states change over time. Using the dataset, We train and evaluate two deep learning models that can learn temporal context. First model is the sequence to sequence network which uses RNN, and second model is the C3D network which uses 3D CNN."
사물인식을 위한 딥러닝 모델 선정 플랫폼,2019,"['딥러닝', '신경망', '사물인식', '플랫폼', 'Deep Learning', 'Neural Network', 'Object Recognition', 'Platform']","최근 컴퓨터 비전을 활용한 사물인식 기술이 센서 기반 사물인식 기술을 대체할 기술로 주목을 받고 있다. 센서 기반 사물인식 기술은 일반적으로 고가의 센서를 필요로 하기 때문에 기술이 상용화되기 어렵다는 문제가 있었다. 반면 컴퓨터 비전을 활용한 사물인식 기술은 고가의 센서 대신 비교적 저렴한 카메라를 사용할 수 있다. 동시에 CNN이 발전하면서 실시간 사물인식이 가능해진 이후 IoT, 자율주행자동차 등 타 분야에 활발하게 도입되고 있다. 그러나 사물 인식 모델을 상황에 알맞게 선택하고 학습시키기 위해서는 딥러닝에 대한 전문적인 지식을 요구하기 때문에 비전문가가 사물 인식 모델을 사용하기에는 어려움이 따른다. 따라서 본 논문에서는 딥러닝 기반 사물인식 모델들의 구조와 성능을 분석하고, 사용자가 원하는 조건의 최적의 딥러닝 기반 사물 인식 모델을 스스로 선정할 수 있는 플랫폼을 제안한다. 또한 통계에 기반한 사물 인식 모델 선정이 필요한 이유를 실험을 통해 증명한다.","Recently, object recognition technology using computer vision has attracted attention as a technology to replace sensor-based object recognition technology. Sensor-based object recognition technology has a problem that it is difficult to commercialize the technology because an expensive sensor is required. On the other hand, since object recognition technology using computer vision can replace sensors with inexpensive cameras. Moreover, Real-time object recognition becomes possible because of the development of CNN, it is actively introduced into other fields such as IoT and autonomous vehicles. However, using the object recognition model requires expert knowledge on deep learning to select and learn the model, it is difficult for non-experts to use it. Therefore, in this paper, we analyze the structure of deep - learning - based object recognition models, and propose a platform that can automatically select a deep - running object recognition model based on a user s desired condition. We also show the reason why we need to select the object recognition model based on the statistics through experiments on the models."
A method for rapidly evaluating reliability and predicting remaining useful life using two-dimensional convolutional neural network with signal conversion,2019,"['Rolling bearing', 'Remaining useful life', 'Convolution neural network', 'Signal conversion', 'Correlation entropy']",국문 초록 정보 없음,"Real-time monitoring and rapid evaluation of bearing operating conditions, especially for the reliability evaluation and remaining useful life (RUL) prediction, are major challenges in the rotating machinery field. A two-dimensional (2-D) deep convolution neural network (CNN) is proposed for rapidly evaluating reliability and predicting RUL, in which a signal conversion method is proposed for converting the one-dimensional signal into the 2-D image to satisfy the input requirements of the 2-D CNN. Different activation functions are employed to implement the conversion of the input data to the output data for each layer of the network, and dropout is only adopted in the hidden layer to change the network structure to prevent overfitting. The maximum correlation entropy with regular terms is employed as the loss function of the model to obtain better training performance compared with the mean square error (MSE). Then, the rolling bearing degradation vibration data is applied to the proposed model to verify the accuracy and rapidity. The results show that the proposed method has good accuracy and fast calculation ability in bearing reliability evaluation and RUL prediction, especially, its time consumption is shorter than that by other deep learning networks."
Real-time Multiple Pedestrians Tracking for Embedded Smart Visual Systems,2019,"['Pedestrian Tracking', 'Object Detection', 'Deep Learning', 'Object Association']",국문 초록 정보 없음,"Even though so much progresses have been achieved in Multiple Object Tracking (MOT), most of reported MOT methods are not still satisfactory for commercial embedded products like Pan-Tilt-Zoom (PTZ) camera. In this paper, we propose a real-time multiple pedestrians tracking method for embedded environments. First, we design a new light weight convolutional neural network(CNN)-based pedestrian detector, which is constructed to detect even small size pedestrians, as well. For further saving of processing time, the designed detector is applied for every other frame, and Kalman filter is employed to predict pedestrians' positions in frames where the designed CNN-based detector is not applied. The pose orientation information is incorporated to enhance object association for tracking pedestrians without further computational cost. Through experiments on Nvidia's embedded computing board, Jetson TX2, it is verified that the designed pedestrian detector detects even small size pedestrians fast and well, compared to many state-of-the-art detectors, and that the proposed tracking method can track pedestrians in real-time and show accuracy performance comparably to performances of many state-of-the-art tracking methods, which do not target for operation in embedded systems."
딥 컨볼루셔널 인코더-디코더 네트워크를 이용한 망막 OCT 영상의 층 분할,2019,"['Optical Coherence Tomography', 'Image Segmentation', 'Convolutional Neural Network', 'Deep Learning']",국문 초록 정보 없음,"In medical image analysis, segmentation is considered as a vital process since it partitions an image into coherent parts and extracts interesting objects from the image. In this paper, we consider automatic segmentations of OCT retinal images to find six layer boundaries using convolutional neural networks.Segmenting retinal images by layer boundaries is very important in diagnosing and predicting progress of eye diseases including diabetic retinopathy, glaucoma, and AMD (age-related macular degeneration).We applied well-known CNN architecture for general image segmentation, called Segnet, U-net, and CNN-S into this problem. We also proposed a shortest path-based algorithm for finding the layer boundaries from the outputs of Segnet and U-net. We analysed their performance on public OCT image data set. The experimental results show that the Segnet combined with the proposed shortest path-based boundary finding algorithm outperforms other two networks."
A Tracking-by-Detection System for Pedestrian Tracking Using Deep Learning Technique and Color Information,2019,"['Color Distribution', 'Convolutional Neural Network', 'Pedestrian Tracking', 'Tracking-by-Detection']",국문 초록 정보 없음,"Pedestrian tracking is a particular object tracking problem and an important component in various visionbasedapplications, such as autonomous cars and surveillance systems. Following several years of development,pedestrian tracking in videos remains challenging, owing to the diversity of object appearances and surroundingenvironments. In this research, we proposed a tracking-by-detection system for pedestrian tracking, whichincorporates a convolutional neural network (CNN) and color information. Pedestrians in video frames arelocalized using a CNN-based algorithm, and then detected pedestrians are assigned to their correspondingtracklets based on similarities between color distributions. The experimental results show that our system isable to overcome various difficulties to produce highly accurate tracking results."
Real-time Multiple Pedestrians Tracking for Embedded Smart Visual Systems,2019,"['Pedestrian Tracking', 'Object Detection', 'Deep Learning', 'Object Association']",국문 초록 정보 없음,"Even though so much progresses have been achieved in Multiple Object Tracking (MOT), most of reported MOT methods are not still satisfactory for commercial embedded products like Pan-Tilt–Zoom (PTZ) camera. In this paper, we propose a real-time multiple pedestrians tracking method for embedded environments. First, we design a new light weight convolutional neural network(CNN)-based pedestrian detector, which is constructed to detect even small size pedestrians, as well. For further saving of processing time, the designed detector is applied for every other frame, and Kalman filter is employed to predict pedestrians’ positions in frames where the designed CNN-based detector is not applied. The pose orientation information is incorporated to enhance object association for tracking pedestrians without further computational cost. Through experiments on Nvidia’s embedded computing board, Jetson TX2, it is verified that the designed pedestrian detector detects even small size pedestrians fast and well, compared to many state-of-the-art detectors, and that the proposed tracking method can track pedestrians in real-time and show accuracy performance comparably to performances of many state-of-the-art tracking methods, which do not target for operation in embedded systems."
A Tracking-by-Detection System for Pedestrian Tracking Using Deep Learning Technique and Color Information,2019,"['Color Distribution', 'Convolutional Neural Network', 'Pedestrian Tracking', 'Tracking-by-Detection']",국문 초록 정보 없음,"Pedestrian tracking is a particular object tracking problem and an important component in various vision-based applications, such as autonomous cars and surveillance systems. Following several years of development, pedestrian tracking in videos remains challenging, owing to the diversity of object appearances and surrounding environments. In this research, we proposed a tracking-by-detection system for pedestrian tracking, which incorporates a convolutional neural network (CNN) and color information. Pedestrians in video frames are localized using a CNN-based algorithm, and then detected pedestrians are assigned to their corresponding tracklets based on similarities between color distributions. The experimental results show that our system is able to overcome various difficulties to produce highly accurate tracking results."
천리안 위성 자료를 활용한 합성곱 순환 신경망 기반 태풍 최대풍속 산출,2019,"['Satellite', 'Typhoon', 'Intensity Estimation', 'Deep Learning', 'Convolutional Neural Network', 'Recurrent Neural Network']",국문 초록 정보 없음,"It is crucial to predict the intensity of typhoons since they cause massive casualties and damage in property. We propose a model for estimating the maximum wind speed of typhoons using Convolutional Recurrent Neural Network (CRNN). Compared to the current method in investigating typhoons which is fully subjected to the meteorologist’s analyzing skill and domain knowledge, the proposed model assists meteorologists to obtain the objective analysis of typhoons. In previous studies, they construct the model utilizing only CNN. However, our suggested model is built with CNN followed by LSTM to consider the fact that the typhoons occur sequentially. We train the model by using each single channel in COMS satellite data composed of IR1, IR2, WV, and SWIR. As a result, the CRNN model trained on WV shows the lowest RMSE error, which is 9.84knot."
사출품 외관 불량 검출을 위한 앙상블 모델 기반 이미지 분류,2019,"['Defect detection', 'Mold product', 'Convolutional neural network', 'Support vector machine']","사출품은 생산환경, 사출기 설정 온도 및 압력, 금형 내부의 온도 및 압력, 그리고 실린더 이물과 같은 요인으로 다양한 불량이 발생하고 있다. 불량의 유형은 미성형, 흑점, 플로마크, 플래시 등 육안으로 검출 가능한 불량과 제품 내부 버블 및 미성형 등과 같이 육안으로 검출할 수 없는 불량으로 분류할 수 있다. 사출품은 자동차 부품, 의료기기 및 생활용품 등 다양한 분야에서 사용되고 있고 사용되는 목적에 따라 높은 수준의 외관 및 기능 품질이 요구된다. 따라서 대부분의 사출공정에서는 불량 검출을 위해 전수검사를 실시하고 있으며 이에 따라 투입되는 자원의 양이 많아 손실이 큰 공정 중 하나이다. 본 연구에서는 비전 센서를 활용하여 제품의 외관이미지를 취득하고 무게 센서를 통해 제품의 무게 데이터를 취득한다. 이미지 데이터는 고도화된 CNN(Convolutional neural network) 중 하나인 ResNeXt(Aggregated Residual network)를 활용하여 외관 불량을 검출한다. 또한 CNN의 단점 중 하나인 고정된 커널 사이즈 및 형태를 보완하기 위해 Deformable ResNeXt 모델을 적용한다. 더 나아가 SVM(Support Vector Machine)을 활용하여 무게 데이터를 기반으로 결과를 도출한다. 마지막으로 불량검출 성능을 증진시키기 위해 적용된 모델의 결과를 조합하는 앙상블 모델을 제안하며 사례 연구를 통해 모델의 우수성을 검증한다.",다국어 초록 정보 없음
합성곱 신경망을 이용한 밭 토양의 물리적 특성 예측,2019,"['합성곱 신경망', '밭 토양', '물리적 특성', '표층 함수비', '건조밀도']","토양의 생산성은 토양의 종류 뿐만 아니라 배수, 통기성, 토양 구조, 유기물의 함량 등 여러 요인에 따라 달라질 수 있다. 이에 따라 작물 재배 시 토양의 특성 및 현재 토양의 상태에 따라 토양 관리 방법을 조율하여야 한다. 현재 농업용 토양 관리는 실내시험을 통한 토양 특성 평가, 현장 시험을 통한 토양 특성 평가, 설치형 센서를 이용한 토양 모니터링 등을 통해 이루어진다. 기존 방법은 관측하고자 하는 지점이 많아질수록 시간과 비용이 많이 소요되기 때문에 현장에서는 일부 지점의 데이터를 이용하여 토양 관리를 수행하는 실정이다. 최근에는 토양의 특성을 빠르게 파악하기 위해 기존의 실험적 방법이 아닌 표층이나 단면의 이미지를 분석하는 방법에 대한 연구가 진행되고 있다. SEM image나 CT-Scan 이미지를 이용하여 토양의 밀도, 투수성을 예측하는 방법이 제시되고 있으나 해당 방법을 현장에서 쉽게 적용하기에는 어려운 실정이다. 최근 다양한 연구가 진행되고 있는 Deep-learning 기법 중의 하나인 합성곱 신경망 (CNN, convolutional neural network)은 기존 분석 알고리즘들의 이미지 분류 및 분석 정확도가 낮은 한계점을 극복한 기술로 이를 이용한 토양 특성 예측 모델 구축 시 낮은 비용으로 신속하게 현장 토양 관리를 수행할 수 있을것으로 예측된다. 본 연구에서는 합성곱 신경망을 기반으로 하여 밭 토양의 이미지를 활용해 물리적 특성을 예측하는 모델을 개발하고자 한다. 국내 밭 토양을 대상으로 연구를 진행하였으며 토양의 이미지는 광조건을 균일하게 통제할 수 있도록 실내에서 촬영되었다. 토양 시료는 직경 150mm, 높이 50mm의 원형 몰드에 함수비, 건조밀도를 각각 달리하여 성형되었으며 각 조건별로 3회 반복촬영을 수행하여 토양별 60개의 원본 이미지를 획득하였다. CNN모델은 Tensorflow 1.14를 기반으로 구성되었으며 예측하고자 하는 인자에 따라 각 계층의 구성 및 초매개변수를 달리하여 모델의 정확도를 높일 수 있도록 하였다. 본 연구의 결과는 향후 밭 토양 관리에 활용되어 토양 함수비 및 건조밀도 추정의 정확도 및 모니터링 효율성을 높일 수 있을것으로 기대된다.",다국어 초록 정보 없음
시각장애인을 위한 딥러닝 기반 인물 위주 이미지 캡션 방법,2019,"['Blind', 'Face Recognition', 'Image Captioning', 'Image segmentation', 'DVS']","본 논문에서는 영상의 시각적인 정보를 딥러닝을 이용하여 시각장애인들에게 영상 내 등장인물과 배경을 인식하여 제공하는 시스템을 제안한다. 시각장애인들은 드라마, 영화, 광고 등 영상에서 장소, 행위, 등장인물 등 영상에 나타나는 시각적인 정보들을 제한적으로 시청하고 있어 시각적인 정보들을 화면해설방송을 사용하여 얻고 있다. 하지만 화면해설방송은 화면해설작가가 영상 정보를 수집하여 대본을 쓴 뒤 성우가 녹음을 진행하고, 화면해설 전문엔지니어가 영상 작업을 해야만 시청이 가능한 불편함을 갖는다. 이를 개선하고자 히스토그램을 이용하여 영상을 자동으로 분할하고, 등장인물들은 CNN을 이용하여 인물 별로 학습시킨 후 분류하며, 영상의 이미지를 MSCOCO 데이터 셋을 이용하여 학습시켜 이미지에 대한 행동, 배경들을 묘사한 정보를 이미지 캡션을 한다. 위의 결과를 통해 얻어진 이미지 캡션 결과에 대해서 20대 이상의 성인을 대상으로 영상내의 시각적인 정보와 비교하는 정성적 평가를 진행함으로서 시각장애인들에게 시각적인 영상 정보를 제공함을 확인할 수 있다.","In this paper, we propose a system for visually impaired people to recognize visual characters and background in visual images by using deep learning. For people with visual impaired, since there is a limitation to viewing visual information such as place, action, character, etc. that appear in the video such as drama, movie or advertisement, they can only get those visual information from the Descriptive Video Service(DVS). However, screen commentary broadcasts are inconvenienced when the screenwriter collects the video information and writes the script, and the voice actor carries out the recording and the professional engineer of the screen commentary performs the video work. To improve this, the image is automatically segmented using the histogram, the characters are learned and classified by the person using CNN, and the image of the image is learned using the MSCOCO data set to describe the behavior and background of the image Captures image information. The image caption obtained from the above results can be confirmed to provide visual image information to the visually impaired by carrying out a qualitative evaluation comparing with the visual information in the image of the adult over 20 persons."
딥러닝에 기반한 병원 실내이미지의 감성어휘 분류,2019,"['분류', '감성어휘', '병원', '실내이미지', '딥러닝', 'Classification', 'Emotional adjective', 'Hospital', 'Indoor image', 'Deep learning']",국문 초록 정보 없음,"This research suggests to classify Emotional adjective for the hospital indoor image. The aim of this study was twofold. First it is an attempt to overcome limitation of overfitting data with pre-process and Second it is an approach for prediction quantified the image data with Emotional adjective. The emotion is important because emotion interact between indoor and human. The hospital indoor image also have specialized emotional effect.Emotional adjective is necessary to verify throughout variety of source qualitative and quantitative research.recently it is getting more harder with I.R.B.(Institutional Review Board) than Emotional adjective data had made.This research is based on deep learning method for emotional adjective quantifiaction that can replace thousands of people’s cognition. In the proposed simulation, emotional colors are firstly processed in the frequency domain to indoor images which can be treated as an emotional image. For pre-processing Emotional colors are extracted from hospital image. and search the emotional adjetive to get indoor images to fed in CNN(Convolutional Neural Network). For the hospital indoor image clustered, emotional indoor image are fed in CNN. The output of the CNNs are fused using TF(TensorFlow) API. The input of the fusion is given to a support of Python language for image classification. The proposed system is evaluated using Tensor board - which is the proved data. This research has concluded that it is desirable to use TF for predicting the set of emotional adjective and it helps for emotion analysis efficiently. TF works for the emotional image classifying the hospital indoor images. The hospital image is classified using deep learning, and analysis of emotion as A is 80 percentage modern and B is 20 percent natural in a second for a thousand emotional colors. It is expected to use these results of research have for implications of emotional analysis that represent functions of the indoor images."
절단된 분포를 이용한 인공신경망에서의 초기값 설정방법,2019,"['initialization', 'saturation', 'Xavier initialization', 'truncated distribution', 'deep learning', '초기값', '포화', 'Xavier', '절단된 분포', '딥러닝']",딥러닝은 대용량의 데이터의 분류 및 예측하는 방법으로 각광받고 있다. 데이터의 양이 많아지면서 신경망의 구조는 더 깊어 지고 있다. 이때 초기값이 지나치게 클 경우 층이 깊어 질수록 활성화 함수의 기울기가 매우 작아지는 포화(Saturation)현상이 발생한다. 이러한 포화현상은 가중치의 학습능력을 저하시키는 현상을 발생시키기 때문에 초기값의 중요성이 커지고 있다.이런 포화현상 문제를 해결하기 위해 Glorot과 Bengio (2010)과 He 등 (2015) 층과 층 사이에 데이터가 다양하게 흘러야 효율적인 신경망학습이 가능하고 주장했다. 데이터가 다양하게 흐르기 위해서는 각 층의 출력에 대한 분산과 입력에 대한 분산이 동일해야 한다고 제안했다. Glorot과 Bengio (2010)과 He 등 (2015)는 각 층별 활성화 값의 분산이 같다고 가정해 초기값을 설정하였다. 본 논문에서는 절단된 코쉬 분포와 절단된 정규분포를 활용하여 초기값을 설정하는 방안을 제안한다. 출력에 대한 분산과 입력에 대한 분산의 값을 동일하게 맞춰주고 그 값이 절단된 확률분포의 분산과 같게 적용함으로써 큰 초기값이 나오는 걸 제한하고 0에 가까운 값이 나오도록 분포를 조정하였다. 제안된 방법은 MNIST 데이터와 CIFAR-10 데이터를 DNN과 CNN 모델에 각각 적용하여 실험함으로써 기존의 초기값 설정방법보다 모델의 성능을 좋게 한다는 것을 보였다,"Deep learning has gained popularity for the classification and prediction task. Neural network layers become deeper as more data becomes available. Saturation is the phenomenon that the gradient of an activation function gets closer to 0 and can happen when the value of weight is too big. Increased importance has been placed on the issue of saturation which limits the ability of weight to learn. To resolve this problem, Glorot and Bengio (Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, 249-256, 2010) claimed that efficient neural network training is possible when data flows variously between layers. They argued that variance over the output of each layer and variance over input of each layer are equal. They proposed a method of initialization that the variance of the output of each layer and the variance of the input should be the same. In this paper, we propose a new method of establishing initialization by adopting truncated normal distribution and truncated cauchy distribution. We decide where to truncate the distribution while adapting the initialization method by Glorot and Bengio (2010). Variances are made over output and input equal that are then accomplished by setting variances equal to the variance of truncated distribution. It manipulates the distribution so that the initial values of weights would not grow so large and with values that simultaneously get close to zero. To compare the performance of our proposed method with existing methods, we conducted experiments on MNIST and CIFAR-10 data using DNN and CNN. Our proposed method outperformed existing methods in terms of accuracy."
Triplet Loss를 이용한 Adversarial Attack 연구,2019,[],"최근 많은 영역에 딥러닝이 활용되고 있다. 특히 CNN과 같은 아키텍처는 얼굴인식과 같은 이미지 분류 분야에서 활용된다. 이러한 딥러닝 기술을 완전한 기술로서 활용할 수 있는지에 대한 연구가 이뤄져왔다. 관련 연구로 PGD(Projected Gradient Descent) 공격이 존재한다. 해당 공격을 이용하여 원본 이미지에 노이즈를 더해주게 되면, 수정된 이미지는 전혀 다른 클래스로 분류되게 된다. 본 연구에서 기존의 FGSM(Fast gradient sign method) 공격기법에 Triplet loss를 활용한 Adversarial 공격 모델을 제안 및 구현하였다. 제안된 공격 모델은 간단한 시나리오를 기반으로 검증하였고 해당 결과를 분석하였다.",다국어 초록 정보 없음
딥 러닝 기법을 이용한 오피니언 마이닝 분석과 성과에 관한 실증연구: 합성곱 신경망 모델과 머신러닝 모델간 성과비교를 중심으로,2019,"['Deep learning', 'Convolutional neural network', 'Sentiment analysis', 'Opinion mining', 'Machine learning classifiers', 'Financial supervisory policy', '딥 러닝', '합성곱 신경망', '감성분석', '오피니언 마이닝', '머신러닝 분류기']","본 연구는 딥 러닝 기법인 합성곱 신경망 (CNN: Convolutional Neural Network)을 이용하여 금융자료에 관한 사용자의 오피니언을 추정하는 오피니언 마이닝 (Opinion mining) 방법과 그 결과를 설명한다. 본 연구에서는 다음과 같이 합성곱 신경망의 효과성을 검증하였다. 첫째, 스터디1은 주식관련 온라인 리뷰 데이터를 분석하였다. 즉, 형태소 분석단계를 거쳐 속성벡터를 만들어 리뷰 문장의 감성점수를 산출하였다. 해당 문장의 감성점수에 따라 오피니언을 3-클라스, 5-클라스 문제로 구분하여 실증분석을 하였다. 둘째, 스터디2에서는 청와대 국민청원에 게시된 금융관련 국민청원 텍스트 문장을 분석하여 청원인원을 추정하였다. 청원게시판에 등재된 청원 인원을 분위 수에 따라 분류하여 2-클라스 문제 (50%이상, 50% 미만) 4-클라스 문제 (75%이상, 50%이상, 25%이상, 25%미만)로 분류하였다. 스터디1, 2의 실증분석결과 정확도, 정밀도, 재현율, F1 점수 등 모든 성과지표에서 벤치마킹용 분류기와 비교할 때 합성곱 신경망이 더 우수한 성과를 보였다. 따라서, 합성곱 신경망을 이용함으로써 금융감독 관련 정책 및 활동을 효과적으로 수행할 수 있음을 실증적으로 확인하였다.",다국어 초록 정보 없음
Pix2Pix 모델을 활용한 단일 영상의 깊이맵 추출,2019,"['Deep Learning', 'Pix2Pix', 'GAN', 'Monocular Depth Map', 'Depth Map Extraction']",국문 초록 정보 없음,"To extract the depth map from a single image, a number of CNN-based deep learning methods have been performed in recent research. In this study, the GAN structure of Pix2Pix is maintained. this model allows to converge well, because it has the structure of the generator and the discriminator. But the convolution in this model takes a long time to compute. So we change the convolution form in the generator to a depthwise convolution to improve the speed while preserving the result. Thus, the seven down-sizing convolutional hidden layers in the generator U-Net are changed to depthwise convolution. This type of convolution decreases the number of parameters, and also speeds up computation time. The proposed model shows similar depth map prediction results as in the case of the existing structure, and the computation time in case of a inference is decreased by 64%."
韓日両言語におけるアルファベット頭文字語のアクセント研究 − 釜山方言と鹿児島諸方言を中心に −,2019,"['アルファベット頭文字語', 'アルファベット関連語彙', '鹿児島諸方言', '釜山方言', 'Alphabetic Acronym', 'Alphabetic Compound', 'Kagoshima Dialect', 'Busan Dialect']",국문 초록 정보 없음,"The purpose of this study is to clarify the accent pattern of alphabetic acronyms like ‘ID and CNN’ and alphabetic compounds of Korean Busan dialect. This study would also like to clarify the difference between the accent pattern of alphabetic acronyms in both Kagoshima dialects of Japan and Busan dialect of Korean. Accents of the Busan dialect alphabetic acronyms are largely divided depending on whether the first element is a monosyllable or polysyllable. In the case of beginning with a monosyllable, the words are pronounced “HHL…” regardless of the accent of the following element. In the case of beginning with a polysyllable, the acronyms are pronounced “first syllable start low, go high from the second syllable to high until the accent of the final element (LH… or LH…HL)”. Unlike the foreign words accent rules and compound word accent rules, the accent of alphabetic acronyms follows its own accent rules.This point is different from the accent of the alphabetic acronyms of Kagoshima dialects of Japan, which is concerned with the accent of loanwords or compound words."
깊이영상을 이용한 나이와 성별인식을 통해 캐릭터 플로팅 홀로그램 구현,2019,"['Age Recognition', 'Gender Recognition', 'Floating Hologram']",국문 초록 정보 없음,"In this paper, we propose a character floating hologram system using the user’s gender and age. The proposed system recognizes the gender and age of the user through depth images and color images. The depth images are used to find and normalize facial position. Next, by using facial color images, the age and gender are estimated through an verified database-based model of CNN. Finally, the estimated age and gender are expressed to a character for the floating hologram. The proposed system can be used in a variety of areas, including marketing, advertising, and exhibition events using gender or age."
360 도 ERP 영상에서 행동 인식 모델 성능 향상을 위한 전처리 기법,2019,[],"본 논문에서 Equirectangular projection(ERP) 영상을 행동 인식 모델에 입력하기전 제안하는 전처리를 통하여 성능을 향상시키는 것을 보인다. ERP 영상의 특성상 행동 인식을 하는데 불필요한 영역이 일반적인 2D 카메라로 촬영한 영상보다 많다. 또한 행동 인식은 사람이 Object of Interest(OOI)이다. 따라서 객체 인식 모델로 인간 객체를 인식한 후 Region of Interest(ROI)를 추출하여 불필요한 영역을 없애고, 왜곡 또한 줄어든다. 본 논문에서 제안하는 기법으로 전처리 후 CNN-LSTM 모델로 성능을 테스트했다. 제안하는 방법으로 전처리를 한 데이터와 하지 않은 데이터로 행동 인식을 한 정확도로 비교하였으며 제안하는 기법으로 전처리 한 데이터로 행동 인식을 한 경우 데이터의 특성에 따라 다르지만, 최대 61%까지 성능향상을 보였다.",다국어 초록 정보 없음
합성곱 신경망을 이용한 보행자 머리상해치 예측기법 개발,2019,"['HIC(머리상해치)', 'NCAP(신차평가제도)', 'VRU Safety(보행자 안전)', 'Deep learning(심층 학습)', 'Pre-trained model(사전 학습 모델)']","보행자 관련 안전사고를 예방하고자 세계 각국에서는 NCAP제도를 활용하여 신차의 안전도를 평가하고있다. HIC는 교통약자(VRU)가 차량과 충돌하였을 때 받는 머리상해치를 의미한다. 기존 HIC예측을 위해선 후드상의 타격포인트에 대한 반복실험, 혹은 담당자의 경험적 판단 하에 성능인자를 추출하여 해석기법을 통해 예측하였다. 그러나 위와 같은 방법은 구조 변경마다 실험에 반복되는 공수소요가 발생하며, 경험적 판단에 의존함으로 객관성이 결여된다. 이에 본 연구에서는 인공지능 기법 중 딥 러닝의 CNN과 차량 설계도면, 그리고 충격 량 실험 값을 학습하여 딥 러닝을 이용한 HIC와 HIC 등급을 예측하며, Error rate, Top1-Acc등의 평가지표를 활용하여 성능을 검증한다.",다국어 초록 정보 없음
Change of malicious code API call pattern extraction using RNN and LSTM,2019,"['NN', 'Recurrent neural networks', 'API Call Patten', 'Malware', 'Malware API', 'Machine Learning', 'Deep Learning', 'LSTM']",국문 초록 정보 없음,"Existing malicious code and detection technologies analyze known malicious code with much time and effort, update it afterwards, detect malicious codes and prevent malicious codes from exploiting new and variant malicious codes. These malicious codes are rapidly changing into various variants to avoid detection of the vaccine. Among the dynamic analysis, methods used to more effectively detect and classify these strains of malware, malicious code family classifies a typical API call pattern by applying CNN. which it is used for natural language processing."
[컴퓨터지능 및 지능시스템] 심층 학습 및 IoT 기법을 이용한 유도 전동기의 실시간 고장 진단과 자기 보완 시스템,2019,"['IoT', 'Deep Learning', 'Self-Complement', 'Real-time', 'Diagnosis']",국문 초록 정보 없음,"Existing fault diagnosis using deep Learning, has experimented by collecting data from a controlled environment. However, it is not easy to diagnose motor faults in various environments, becuase input data are measured with various disturbances together. For this reason, in this paper, the verification and learning process are separated and used in each system so that motor data of various environments can be considered. In the verification process, a data preprocessing process is added to verify and collect necessary data. A CNN-based in-depth learning algorithm is implemented and data is stored in real time. Since the data is re-learned based on the collected data, a model considering both existing features and newly input data is created. Even the continuous disturbance is also used as learning data, it is easier to cope with disturbance than the conventional method. As a result, a system applicable to an industrial field is proposed considering various environments."
End-to-End Partial Discharge Detection in Power Cables via Time-Domain Convolutional Neural Networks,2019,['Partial discharges · Fault detection · Power cable · Deep neural networks · Convolutional neural networks'],국문 초록 정보 없음,"The analysis of partial discharge (PD) signals has been identifi ed as a standardized diagnostic tool in monitoring the condition of diff erent electrical apparatus nowadays. In this paper, we propose a novel data-driven approach to detect PD pulses in power cables using one-dimensional convolutional neural networks (CNNs), a successful deep neural network approach.Applying this deep learning method, an end-to-end framework has been proposed considering the propagations of PD signals and noises in power cables. The proposed method uses PD pulses as input, automatically extracts meaningful features for waveforms of PD pulses, and fi nally detects PD. Most of the existing methods, which use traditional classifi ers, such as support vector machines (SVMs) and multi-layer perceptron (MLP) have mainly focused on improving feature representation and extraction manually for this task. However, the proposed CNN-based detection algorithm captures important latent features for waveforms of PD pulses with the help of its automatic feature extraction capability from raw inputs. Our experimental results show that the proposed method is better than conventional SVMs and achieves 97.38% and 93.23% detection accuracies in end-to-end settings based on our theoretical model-generated and empirical real-world PD signals, respectively."
Four-Dimensional CBCT Reconstruction Based on a Residual Convolutional Neural Network for Improving Image Quality,2019,"['4D computed tomography', 'Residual convolution neural network', 'Streak artifacts']",국문 초록 정보 없음,"In radiation treatment, a cone-beam computed tomography (CBCT) scan is conducted for precise positioning of tumors, and the image quality is usually degraded by motion artifacts due to patient's respiration and movement during scanning. Four-dimensional (4D) CBCT reconstruction with phase binning is typically used to overcome these difficulties. Albeit motion artifacts might be reduced with 4D CBCT, the overall image quality is typically worsened by severe streak artifacts due to the sparse-angle projections available in the 3D reconstruction for each motion phase. This study presents a method for reducing streak artifacts effectively in conventional 4D CBCT reconstruction by using a state-of-the-art convolutional neural network (a residual U-Net was used). We performed a computational simulation and an experiment to investigate the image quality and evaluate the effectiveness of the proposed method. The proposed 4D CBCT reconstruction method reduced streak artifacts noticeably, and its effectiveness was validated by comparing its results to those of other reconstruction methods such as the filtered-backprojection, a compressed-sensing, and a simple CNN-based algorithm for the 4D CBCT datasets."
Document Summarization Model Based on General Context in RNN,2019,"['Document Summarization', 'General Context', 'Natural Language Processing', 'Sequence-to-Sequence Model']",국문 초록 정보 없음,"In recent years, automatic document summarization has been widely studied in the field of natural language processing thanks to the remarkable developments made using deep learning models. To decode a word, existing models for abstractive summarization usually represent the context of a document using the weighted hidden states of each input word when they decode it. Because the weights change at each decoding step, these weights reflect only the local context of a document. Therefore, it is difficult to generate a summary that reflects the overall context of a document. To solve this problem, we introduce the notion of a general context and propose a model for summarization based on it. The general context reflects overall context of the document that is independent of each decoding step. Experimental results using the CNN/Daily Mail dataset show that the proposed model outperforms existing models."
FCSS: Fully Convolutional Self-Similarity for Dense Semantic Correspondence,2019,[],국문 초록 정보 없음,"<P>We present a descriptor, called fully convolutional self-similarity (FCSS), for dense semantic correspondence. Unlike traditional dense correspondence approaches for estimating depth or optical flow, semantic correspondence estimation poses additional challenges due to intra-class appearance and shape variations among different instances within the same object or scene category. To robustly match points across semantically similar images, we formulate FCSS using local self-similarity (LSS), which is inherently insensitive to intra-class appearance variations. LSS is incorporated through a proposed convolutional self-similarity (CSS) layer, where the sampling patterns and the self-similarity measure are jointly learned in an end-to-end and multi-scale manner. Furthermore, to address shape variations among different object instances, we propose a convolutional affine transformer (CAT) layer that estimates explicit affine transformation fields at each pixel to transform the sampling patterns and corresponding receptive fields. As training data for semantic correspondence is rather limited, we propose to leverage object candidate priors provided in most existing datasets and also correspondence consistency between object pairs to enable weakly-supervised learning. Experiments demonstrate that FCSS significantly outperforms conventional handcrafted descriptors and CNN-based descriptors on various benchmarks.</P>"
단어 생성 이력을 이용한 요약문 생성의 어휘 반복 문제 해결,2019,"['text summarization', 'sequence-to-sequence model', 'word repetition', 'repeat loss', '문서 요약', '반복 제어', '시퀀스-투-시퀀스', '손실 함수']","시퀀스-투-시퀀스 기반의 요약 모델에서 자주 발생하는 문제 중 하나는 요약문의 생성과정에서 단어나 구, 문장이 불필요하게 반복적으로 생성되는 것이다. 이를 해결하기 위해 기존 연구들은 대부분 모델에 여러 모듈을 추가하는 방법을 제안했지만, 위 방법은 생성하지 말아야 하는 단어에 대한 학습이 부족하여 반복 생성 문제를 해결함에 있어 한계가 있다. 본 논문에서는 단어 생성 이력을 직접적으로 이용하여 반복 생성을 제어하는 Repeat Loss를 이용한 새로운 학습 방법을 제안한다. Repeat Loss를 디코더가 단어 생성 확률을 계산 했을 때 이전에 생성한 단어가 다시 생성될 확률로 정의함으로써 실제 생성한 단어가 반복 생성될 확률을 직접적으로 제어할 수 있다. 제안한 방법으로 요약 모델을 학습한 결과, 단어 반복이 줄어들어 양질의 요약을 생성하는 것을 실험적으로 확인할 수 있었다.","Neural attentional sequence-to-sequence models have achieved great success in abstractive summarization. However, the model is limited by several challenges including repetitive generation of words, phrase and sentences in the decoding step. Many studies have attempted to address the problem by modifying the model structure. Although the consideration of actual history of word generation is crucial to reduce word repetition, these methods, however, do not consider the decoding history of generated sequence. In this paper, we propose a new loss function, called ‘Repeat Loss’ to avoid repetitions. The Repeat Loss directly prevents the model from repetitive generation of words by giving a loss penalty to the generation probability of words already generated in the decoding history. Since the propose Repeat Loss does not need a special network structure, the loss function is applicable to any existing sequence-to-sequence models. In experiments, we applied the Repeat Loss to a number of sequence-to-sequence model based summarization systems and trained them on both Korean and CNN/Daily Mail summarization datasets. The results demonstrate that the proposed method reduced repetitions and produced high-quality summarization."
숫자 인식 서비스 기반 다층 퍼셉트론에 대한 입력 데이터 축소 알고리즘,2019,"['artificial neural networks', 'multi-layer perceptron', 'mobile pattern recognition', 'recognition']",국문 초록 정보 없음,"IT fusion and composite technologies generate a large amount of data, and deep learning technologies that can identify them on their own are currently receiving great attention in the industrial field. Deep learning, which artificially models biological brains, requires a high amount of computation. In this paper, we propose a numerical data reduction algorithm as a first step to reduce high computations, a fundamental problem of deep learning. After identifying the all features in the image, measure the number of features and arrange them into a fixed array of 16 sizes. This reduces the computation and learning time of the neural network. In order to evaluate the performance of the proposed numerical data Conversion algorithm, the processed data is compared with 3-layer-ANN and CNN-LeNet5 after learning through multilayer perceptron. Experimental results showed somewhat poor results with accuracy of 99.4% and error rate of 0.0264%. However, the time measurement showed more than three times faster operation than the conventional method."
Document Summarization Model Based on General Context in RNN,2019,"['Document Summarization', 'General Context', 'Natural Language Processing', 'Sequence-to-Sequence Model']",국문 초록 정보 없음,"In recent years, automatic document summarization has been widely studied in the field of natural language processing thanks to the remarkable developments made using deep learning models. To decode a word, existing models for abstractive summarization usually represent the context of a document using the weighted hidden states of each input word when they decode it. Because the weights change at each decoding step, these weights reflect only the local context of a document. Therefore, it is difficult to generate a summary that reflects the overall context of a document. To solve this problem, we introduce the notion of a general context and propose a model for summarization based on it. The general context reflects overall context of the document that is independent of each decoding step. Experimental results using the CNN/Daily Mail dataset show that the proposed model outperforms existing models."
Document Summarization Model Based on General Context in RNN,2019,"['Document Summarization', 'General Context', 'Natural Language Processing', 'Sequence-to-Sequence Model']",국문 초록 정보 없음,"In recent years, automatic document summarization has been widely studied in the field of natural languageprocessing thanks to the remarkable developments made using deep learning models. To decode a word,existing models for abstractive summarization usually represent the context of a document using the weightedhidden states of each input word when they decode it. Because the weights change at each decoding step, theseweights reflect only the local context of a document. Therefore, it is difficult to generate a summary that reflectsthe overall context of a document. To solve this problem, we introduce the notion of a general context andpropose a model for summarization based on it. The general context reflects overall context of the documentthat is independent of each decoding step. Experimental results using the CNN/Daily Mail dataset show thatthe proposed model outperforms existing models."
딥러닝 기반의 주행가능 영역 추출 모델에 관한 연구,2019,"['Drivable area segmentation', 'Segmentation', 'Deep Learning', 'DeepLab V3+', 'Mask R-CNN', 'BDD Dataset', '주행가능 영역 추출', '영상 분할', '딥러닝', 'DeepLab V3+', 'Mask R-CNN', 'BDD 데이터셋']","인공지능, 빅데이터, 자율주행 등 4차 산업혁명시대를 이끄는 핵심기술은 컴퓨팅 파워의 급속한 발전과 사물인터넷에 기반한 초연결 네트워크를 통해 구현되고 서비스된다. 본 논문에서는 자율주행을 위한 기본적인 기능으로 다양한 환경에서도 정확하게 주행가능한 영역을 인식하여 추출하는 인공지능 딥러닝 모델들을 구현하고, 그 결과를 비교, 분석한다. 주행가능한 영역을 추출하는 딥러닝모델은 영상 분할 분야에서 성능이 우수하고 자율주행 연구에서 많이 사용하는 Deep Lab V3+와 Mask R-CNN을 활용하였다. 다양한환경에서의 주행 정보를 위해 여러 가지 날씨 조건과 주·야간 환경에서의 주행 영상 및 이미지를 제공하는 BDD 데이터셋을 학습데이터로 사용하였다. 활용한 모델들의 실험 결과, DeepLab V3+는 48.97%의 IoU를 보였으며, Mask R-CNN은 68.33%의 IoU로 더 우수한성능을 보였다. 또한, 구현한 모델로 추출된 주행가능 영역을 이미지에 표시하여 육안으로 검사한 결과, Mask R-CNN은 83%, Deep Lab V3+는 69% 정확도로 Mask R-CNN이 Deep Lab V3+ 보다 주행가능한 영역을 추출하는 분야에서는 더 성능이 높은 것으로 확인하였다.","Core technologies that lead the Fourth Industrial Revolution era, such as artificial intelligence, big data, and autonomous driving, are implemented and serviced through the rapid development of computing power and hyper-connected networks based on the Internet of Things. In this paper, we implement two different models for drivable area segmentation in various environment, and propose a better model by comparing the results. The models for drivable area segmentation are using DeepLab V3+ and Mask R-CNN, which have great performances in the field of image segmentation and are used in many studies in autonomous driving technology. For driving information in various environment, we use BDD dataset which provides driving videos and images in various weather conditions and day&night time. The result of two different models shows that Mask R-CNN has higher performance with 68.33% IoU than DeepLab V3+ with 48.97% IoU. In addition, the result of visual inspection of drivable area segmentation on driving image, the accuracy of Mask R-CNN is 83% and DeepLab V3+ is 69%. It indicates Mask R-CNN is more efficient than DeepLab V3+ in drivable area segmentation."
Deep learning approaches for automatic detection of sleep apnea events from an electrocardiogram,2019,"['Sleep apnea', 'Deep learning', 'Convolutional neural network', 'Recurrent neural network', 'Long short-term memory', 'Gated-recurrent unit']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P><B>Background and Objective</B></P> <P>This study demonstrates deep learning approaches with an aim to find the optimal method to automatically detect sleep apnea (SA) events from an electrocardiogram (ECG) signal.</P>   <P><B>Methods</B></P> <P>Six deep learning approaches were designed and implemented for automatic detection of SA events including deep neural network (DNN), one-dimensional (1D) convolutional neural networks (CNN), two-dimensional (2D) CNN, recurrent neural networks (RNN), long short-term memory, and gated-recurrent unit (GRU). Designed deep learning models were analyzed and compared in the performances. The ECG signal was pre-processed, normalized, and segmented into 10 s intervals. Subsequently, the signal was converted into a 2D form for analysis in the 2D CNN model. A dataset collected from 86 patients with SA was used. The training set comprised data from 69 of the patients, while the test set contained data from the remaining 17 patients.</P>   <P><B>Results</B></P> <P>The accuracy of the best-performing model was 99.0%, and the 1D CNN and GRU models had 99.0% recall rates.</P>   <P><B>Conclusions</B></P> <P>The designed deep learning approaches performed better than those developed and tested in previous studies in terms of detecting SA events, and they could distinguish between apnea and hypopnea events using an ECG signal. The deep learning approaches such as 1D CNN and GRU can be helpful tools to automatically detect SA in sleep apnea screening and related studies.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Deep learning approaches were designed to automatically detect sleep apnea (SA) from an electrocardiogram signal. </LI> <LI>  Six deep learning approaches were designed and implemented including DNN, 1D CNN, 2D CNN, RNN, long short-term memory, and gated-recurrent unit models. </LI> <LI>  The 1D CNN and GRU models were the best-performing of the accuracy was 99.0% and recall was 99.0%. </LI> <LI>  The designed deep learning approaches performed better than those developed and tested in previous studies in terms of detecting SA events. </LI> </UL> </P>"
Scale-space approximated convolutional neural networks for retinal vessel segmentation,2019,"['Retinal vessel segmentation', 'Convolutional neural networks', 'Multi-scale representation', 'Scale-space approximation']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>Background and objective: Retinal fundus images are widely used to diagnose retinal diseases and can potentially be used for early diagnosis and prevention of chronic vascular diseases and diabetes. While various automatic retinal vessel segmentation methods using deep learning have been proposed, they are mostly based on common CNN structures developed for other tasks such as classification.</P>   <P><B>Methods</B></P> <P>We present a novel and simple multi-scale convolutional neural network (CNN) structure for retinal vessel segmentation. We first provide a theoretical analysis of existing multi-scale structures based on signal processing. In previous structures, multi-scale representations are achieved through downsampling by subsampling and decimation. By incorporating scale-space theory, we propose a simple yet effective multi-scale structure for CNNs using upsampling, which we term <I>scale-space approximated CNN (SSANet)</I>. Based on further analysis of the effects of the SSA structure within a CNN, we also incorporate residual blocks, resulting in a multi-scale CNN that outperforms current state-of-the-art methods.</P>   <P><B>Results</B></P> <P>Quantitative evaluations are presented as the area-under-curve (AUC) of the receiver operating characteristic (ROC) curve and the precision-recall curve, as well as accuracy, for four publicly available datasets, namely DRIVE, STARE, CHASE_DB1, and HRF. For the CHASE_DB1 set, the SSANet achieves state-of-the-art AUC value of 0.9916 for the ROC curve. An ablative analysis is presented to analyze the contribution of different components of the SSANet to the performance improvement.</P>   <P><B>Conclusions</B></P> <P>The proposed retinal SSANet achieves state-of-the-art or comparable accuracy across publicly available datasets, especially improving segmentation for thin vessels, vessel junctions, and central vessel reflexes.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Conventional CNN structures may cause aliasing in multi-scale feature extraction. </LI> <LI>  In the scale-space approximated CNN (SSANet) decimation is replaced with upsampling. </LI> <LI>  Upsampling after downsampling is essentially Gaussian blurring in scalespace theory. </LI> <LI>  Reduced receptive field is offset with residual blocks that also increase capacity. </LI> <LI>  Proposed SSANet shows state-of-the-art accuracy for retinal vessel segmentation. </LI> </UL> </P>   <P><B>Graphical abstract</B></P>   <P>[DISPLAY OMISSION]</P>"
A new fault diagnosis method based on convolutional neural network and compressive sensing,2019,"['Compressive sensing', 'Fault diagnosis', 'Convolutional neural network', 'Feature extraction', 'Gearbox', 'Bearing']",국문 초록 정보 없음,"Compressive sensing is an efficient machinery monitoring framework, which just needs to sample and store a small amount of observed signal. However, traditional reconstruction and fault detection methods cost great time and the accuracy is not satisfied. For this problem, a 1D convolutional neural network (CNN) is adopted here for fault diagnosis using the compressed signal. CNN replaces the reconstruction and fault detection processes and greatly improves the performance. Since the main information has been reserved in the compressed signal, the CNN is able to extract features from it automatically. The experiments on compressed gearbox signal demonstrated that CNN not only achieves better accuracy but also costs less time. The influencing factors of CNN have been discussed, and we compared the CNN with other classifiers. Moreover, the CNN model was also tested on bearing dataset from Case Western Reserve University. The proposed model achieves more than 90 % accuracy even for 50 % compressed signal."
딥러닝 알고리즘과 2D Lidar 센서를 이용한 이미지 분류,2019,"['Deep learning', 'deep learning neural network', 'convolutional neural network', 'object detection', 'image classification']","본 논문은 CNN (Convolutional Neural Network)와 2D Lidar 센서에서 획득한 위치 데이터를 이용하여 이미지를 분류하는 방법을 제시한다. Lidar 센서는 데이터 정확도, 형상 왜곡 및 광 변화에 대한 강인성 측면에서의 이점으로 인해 무인 장치에 널리 사용되어 왔다. CNN 알고리즘은 하나 이상의 컨볼루션 및 풀링 레이어로 구성되며 이미지 분류에 만족스러운 성능을 보여 왔다. 본 논문에서는 학습 방법에 따라 다른 유형의 CNN 아키텍처들인 Gradient Descent (GD) 및 Levenbergarquardt(LM)를 구현하였다. LM 방법에는 학습 파라메터를 업데이트하는 요소 중 하나인 Hessian 행렬 근사 빈도에 따라 두 가지 유형이 있다. LM 알고리즘의 시뮬레이션 결과는 GD 알고리즘보다 이미지 데이터의 분류 성능이 우수하였다. 또한 Hessian 행렬 근사가 더 빈번한 LM 알고리즘은 다른 유형의 LM 알고리즘보다 작은 오류를 보여주었다.","This paper presents an approach for classifying image made by acquired position data from a 2D Lidar sensor with a convolutional neural network (CNN). Lidar sensor has been widely used for unmanned devices owing to advantages in term of data accuracy, robustness against geometry distortion and light variations. A CNN algorithm consists of one or more convolutional and pooling layers and has shown a satisfactory performance for image classification. In this paper, different types of CNN architectures based on training methods, Gradient Descent(GD) and Levenbergarquardt(LM), are implemented. The LM method has two types based on the frequency of approximating Hessian matrix, one of the factors to update training parameters. Simulation results of the LM algorithms show better classification performance of the image data than that of the GD algorithm. In addition, the LM algorithm with more frequent Hessian matrix approximation shows a smaller error than the other type of LM algorithm."
Improving Model Performance for Urban Sound Classification With Model Ensembling,2019,"['Convolutional neuralnetworks', 'Raw waveforms', 'Environmental sound', 'Bootstrap aggregation']",국문 초록 정보 없음,"Recent work has demonstrated the end-to-end learning using a convolutional neural network (CNN) is sucessfully used in various kinds of deep learning tasks. Deep convolutional neural network (DCNNs) usually have high variance due to their high capacity and flexibility. Bootstrap aggregating (bagging) with CNN models has been widedly used in image classification for its effectiveness. CNN approach has been applied to audio signals, using 1- D convolutional layer that takes raw waveforms as input as well, but ensemble methods are not fully explored yet. In this paper, we improve the model performance for urban sound classification by adopting SENets, which is state-of-the-art CNN models usign bagging. Since SE blocks are sufficiently flexiblie to be used in CNN models, we apply SE blocks to advanced CNN architectures, residual networks (ResNet). The result show SENet and ensemble model with SENet and Resnet achieve significant improvements over previous state-of-the- art models in the Urban Sound 8k."
Automatic Prediction of Atrial Fibrillation Based on Convolutional Neural Network Using a Short-term Normal Electrocardiogram Signal,2019,"['Atrial Fibrillation', 'Electrocardiogram', 'Convolutional Neural Network', 'Deep Learning']",국문 초록 정보 없음,"Background: In this study, we propose a method for automatically predicting atrial fibrillation (AF) based on convolutional neural network (CNN) using a short-term normal electrocardiogram (ECG) signal.Methods: We designed a CNN model and optimized it by dropout and normalization. One- dimensional convolution, max-pooling, and fully-connected multiple perceptron were used to analyze the short-term normal ECG. The ECG signal was preprocessed and segmented to train and evaluate the proposed CNN model. The training and test sets consisted of the two AF and one normal dataset from the MIT-BIH database.Results: The proposed CNN model for the automatic prediction of AF achieved a high performance with a sensitivity of 98.6%, a specificity of 98.7%, and an accuracy of 98.7%.Conclusion: The results show the possibility of automatically predicting AF based on the CNN model using a short-term normal ECG signal. The proposed CNN model for the automatic prediction of AF can be a helpful tool for the early diagnosis of AF in healthcare fields."
UWB 시스템에서 합성곱 신경망을 이용한 거리 추정,2019,[],국문 초록 정보 없음,"The paper proposes a distance estimation technique for ultra-wideband (UWB) systems using convolutional neural network (CNN). To estimate the distance from the transmitter and the receiver in the proposed method, 1 dimensional vector consisted of the magnitudes of the received samples is reshaped into a 2 dimensional matrix, and by using this matrix, the distance is estimated through the CNN regressor. The received signal for CNN training is generated by the UWB channel model in the IEEE 802.15.4a, and the CNN model is trained. Next, the received signal for CNN test is generated by filed experiments in indoor environments, and the distance estimation performance is verified. The proposed technique is also compared with the existing threshold based method. According to the results, the proposed CNN based technique is superior to the conventional method and specifically, the proposed method shows 0.6 m root mean square error (RMSE) at distance 10 m while the conventional technique shows much worse 1.6 m RMSE."
Fully Automatic Segmentation of Acute Ischemic Lesions on Diffusion-Weighted Imaging Using Convolutional Neural Networks: Comparison with Conventional Algorithms,2019,"['Diffusion-weighted imaging', 'Cerebral ischemia', 'Segmentation', 'Convolutional neural networks']",국문 초록 정보 없음,"Objective: To develop algorithms using convolutional neural networks (CNNs) for automatic segmentation of acute ischemic lesions on diffusion-weighted imaging (DWI) and compare them with conventional algorithms, including a thresholding-based segmentation.Materials and Methods: Between September 2005 and August 2015, 429 patients presenting with acute cerebral ischemia (training:validation:test set = 246:89:94) were retrospectively enrolled in this study, which was performed under Institutional Review Board approval. Ground truth segmentations for acute ischemic lesions on DWI were manually drawn under the consensus of two expert radiologists. CNN algorithms were developed using two-dimensional U-Net with squeeze-and-excitation blocks (U-Net) and a DenseNet with squeeze-and-excitation blocks (DenseNet) with squeeze-and-excitation operations for automatic segmentation of acute ischemic lesions on DWI. The CNN algorithms were compared with conventional algorithms based on DWI and the apparent diffusion coefficient (ADC) signal intensity. The performances of the algorithms were assessed using the Dice index with 5-fold cross-validation. The Dice indices were analyzed according to infarct volumes (< 10 mL, ≥ 10 mL), number of infarcts (≤ 5, 6–10, ≥ 11), and b-value of 1000 (b1000) signal intensities (< 50, 50–100, > 100), time intervals to DWI, and DWI protocols.Results: The CNN algorithms were significantly superior to conventional algorithms (p < 0.001). Dice indices for the CNN algorithms were 0.85 for U-Net and DenseNet and 0.86 for an ensemble of U-Net and DenseNet, while the indices were 0.58 for ADC-b1000 and b1000-ADC and 0.52 for the commercial ADC algorithm. The Dice indices for small and large lesions, respectively, were 0.81 and 0.88 with U-Net, 0.80 and 0.88 with DenseNet, and 0.82 and 0.89 with the ensemble of U-Net and DenseNet. The CNN algorithms showed significant differences in Dice indices according to infarct volumes (p < 0.001).Conclusion: The CNN algorithm for automatic segmentation of acute ischemic lesions on DWI achieved Dice indices greater than or equal to 0.85 and showed superior performance to conventional algorithms."
Salt Delineation From Electromagnetic Data Using Convolutional Neural Networks,2019,[],국문 초록 정보 없음,"<P>With recent advances in machine learning, convolutional neural networks (CNNs) have been successfully applied in many fields, and several attempts have been made in the field of geophysics. In this letter, we investigated the mapping of subsurface electrical resistivity distributions from electromagnetic (EM) data with CNNs. To begin imaging electrical resistivity using CNNs, we carried out precise delineation of a subsurface salt structure, which is indispensable for identification of offshore hydrocarbon reservoirs, using towed streamer EM data. For training the CNN model, an electrical resistivity model, including a salt body, and corresponding EM data calculated through numerical modeling were used as the label and input, respectively. The optimal weights and biases of the CNN were obtained minimizing the mean-square error between the predicted resistivity distribution and the target label. The final CNN model was selected using a validation data set during training. After training, we applied the trained CNN to test data sets of noisy data and simulated-SEAM data, which were not provided to the network during training. The test results demonstrate that our trained CNN model is stable, reliable, and efficient, and indicate the possibility of successful application of our CNN model to field data. Our study has shown the promising potential of CNNs for identifying defined subsurface electrical resistivity structures that are difficult to find using conventional EM inversion.</P>"
Analyze weeds classification with visual explanation based on Convolutional Neural Networks,2019,"['Grad-CAM', 'CNN', 'visualization', 'Resnet']",국문 초록 정보 없음,"To understand how a Convolutional Neural Network (CNN) model captures the features of a pattern to determine which class it belongs to, in this paper, we use Gradient-weighted Class Activation Mapping (Grad-CAM) to visualize and analyze how well a CNN model behave on the CNU weeds dataset. We apply this technique to Resnet model and figure out which features this model captures to determine a specific class, what makes the model get a correct/wrong classification, and how those wrong label images can cause a negative effect to a CNN model during the training process. In the experiment, Grad-CAM highlights the important regions of weeds, depending on the patterns learned by Resnet, such as the lobe and limb on 미국가막사리, or the entire leaf surface on 단풍잎돼지풀. Besides, Grad-CAM points out a CNN model can localize the object even though it is trained only for the classification problem."
딥러닝을 활용한 흔들림 영상 안정화 알고리즘,2019,"['Stabilization', 'Feature map', 'CNN', 'LSTM']","본 논문에서는 딥러닝을 활용한 흔들림 영상 안정화 알고리즘을 제안하였다. 제안하는 알고리즘은 기존 몇 가지2D, 2.5D 및 3D 기반 안정화 기술과 다르게 딥러닝을 활용한다. 제안하는 알고리즘은 흔들리는 영상을 CNN 네트워크 구조와 LSTM 네트워크 구조를 통한 특징 추출 및 비교하여 이전 프레임과 현재 프레임 간의 특징점 위치 차이를 통해 특징점의이동 크기와 방향의 반대로 영상을 변환하는 알고리즘이다. 흔들림 안정화를 위한 알고리즘은 각 프레임의 특징 추출 및비교를 위해 Tensorflow를 활용하여 CNN 네트워크과 LSTM 구조를 구현하였으며, 영상 흔들림 안정화는 OpenCV open source를 활용해 구현하였다. 실험결과 영상의 흔들림이 상하좌우로 흔들리는 영상과, 급격한 카메라 이동이 없는 영상을실험에 사용하여, 제안한 알고리즘을 적용한 결과 사용한 상하좌우 흔들림 영상에서는 안정적인 흔들림 안정화 성능을 기대할 수 있었다.","In this paper, we proposed a shaking image stabilization algorithm using deep learning. The proposed algorithm utilizes deep learning, unlike some 2D, 2.5D and 3D based stabilization techniques. The proposed algorithm is an algorithm that extracts and compares features of shaky images through CNN network structure and LSTM network structure, and transforms images in reverse order of movement size and direction of feature points through the difference of feature point between previous frame and current frame. The algorithm for stabilizing the shake is implemented by using CNN network and LSTM structure using Tensorflow for feature extraction and comparison of each frame. Image stabilization is implemented by using OpenCV open source. Experimental results show that the proposed algorithm can be used to stabilize the camera shake stability in the up, down, left, and right shaking images."
Development and Application of a Deep Convolutional Neural Network Noise Reduction Algorithm for Diffusion-weighted Magnetic Resonance Imaging,2019,"['Deep convolutional neural network (Deep-CNN) noise reduction algorithm', 'Diffusion-weighted imaging(DWI)', 'Magnetic resonance imaging(MRI)', 'Image processing', 'quantitative evaluation of image performance']",국문 초록 정보 없음,"Diffusion-weighted imaging (DWI) is frequently used in the field of diagnostic medicine to detect various human diseases. In DWI, noise suppression is very important for achieving high detection accuracy of diseases. In this study, we develop a deep convolutional neural network (Deep-CNN) noise reduction algorithm and evaluate its effectiveness in DWI by performing both simulations and real experiments with a 1.5- and a 3.0-T MRI system. The results validate the proposed Deep-CNN algorithm for DWI. Compared with previously developed non-local means (NLM) algorithms, the proposed Deep-CNN algorithm achieves superior quantitative results. In conclusion, the quantitative results verify that the proposed Deep-CNN algorithm has higher noise reduction efficiency and image visibility than previously developed algorithms for DWI."
합성곱신경망의 학습 및 테스트자료에 따른 골다공증 판독에 미치는 영향,2019,"['Mandible', 'Osteoporosis', 'Panoramic radiograph', 'Computer']",국문 초록 정보 없음,"This study aimed to test a convolutional neural network (CNN) in two different settings of training and testing data. Panoramic radiographs were selected from 1170 female dental patients (mean age 49.19 ± 21.91 yr). The cortical bone of the mandible inferior border was evaluated for osteoporosis or normal condition on the panoramic radiographs. Among them, 586 patients (mean age 27.46 ± 6.73 yr) had normal condition, and osteoporosis was interpreted on 584 patients (mean age 71.00 ± 7.64 yr). Among them, one data set of 569 normal patients (mean age 26.61 ± 4.60 yr) and 502 osteoporosis patients (mean age 72.37 ± 7.10 yr) was used for training CNN, and the other data set of 17 normal patients (mean age 55.94 ± 4.0 yr) and 82 osteoporosis patients (mean age 62.60 ± 5.00 yr) for testing CNN in the first experiment, while the latter was used for training CNN and the former for testing CNN in the second experiment.The error rate was 15.15% in the first experiment and 5.14% in the second experiment. This study suggests that age-matched training data make more accurate testing results."
Data Preprocessing Method in Motor Fault Diagnosis Using Unsupervised Learning,2019,"['Deep Learning', 'Unsupervised learning', 'K-means', 'Motor Fault Diagnosis', 'Data pre-processing']",국문 초록 정보 없음,"Motor failure diagnosis using the existing deep learning is a lot of research using the CNN algorithm. Supervised learning is an algorithm in which a user specifies a correct answer of data and learns based on the correct answer. Therefore, CNN is very clear to classification of characteristics data. However, data that is not learned cannot be classified. The existing fault diagnosis using CNN failed to verify the data even if only the sensor measuring vibration in the same environment was changed. In this paper, a research was conducted using the K-means algorithm, which is unsupervised learning. In order to apply K-means to fault diagnosis, FFT data is divided by frequency. The center point is calculated by applying K-means algorithm for each frequency. The correct data set was determined based on the input data. Using the input data, the answer data set is calculated similarity and distance to the centroid of the cluster classified by each frequency, and the data with high probability are selected to classify the correct answer data set classified as Kmeans as normal or fault. By using the above method, even if the sensor is changed, it is possible to verify the data of similar trend. In order to verify the proposed algorithm, data were collected using different sensors and compared with the conventional CNN algorithm. The CNN failed to classify the data when the sensor was changed, but the proposed algorithm classified the data and showed high accuracy."
택배화물 자동 하역장비를 위한 딥러닝 기반의 화물 인식 알 고리즘,2019,"['Unloading system', 'deep learning algorithm', 'YOLO v2', 'Masked -CRNN', '자동하역장치', '딥러닝 알고리즘', 'YOLO v2', 'Masked R-CNN']",본 논문에서는 택배화물 자동하역장치에 적합한 개선된 딥러닝 알고리즘을 제안한다. 제안된 알고리즘은 실시간객체검출에 우수한 성능을 보이는 YOLO v2모델을 기반으로 픽셀단위 택배화물의 위치까지 검출할 수 있도록 Masked R-CNN을 융합한 구조를 가진다. 제안된 알고리즘은 YOLO v2를 이용하여 객체의 영역과 분류를 수행하면서 객체 영역을Masked R-CNN의 객체분할(Instance segmentation)과정을 거쳐 택배화물의 픽셀단위 위치까지 계산할 수 있도록 하였다.제안된 알고리즘의 성능을 평가하기 위하여 실제 택배화물 차량의 적재공간과 동일한 영역에서 택배화물들을 이용하여실험하였으며 실험결과 만족할만한 성능을 보임을 확인하였다,"In this paper, an improved deep learning algorithm for automatic unloading systems is proposed. The proposed algorithm is based on the YOLO v2 model, which shows excellent performance in real-time object detection, and has a fused structure with Masked R-CNN to detect pixel position of parcel. The proposed algorithm performs object segmentation and classification using YOLO v2, and calculates the object region to the pixel position of the parcel by mask segmentation process of Instanced R-CNN.In order to evaluate the performance of the proposed algorithm, we experimented in the same area as the loading space of the actual parcel cargo vehicle and showed the excellent performance in the expiemr ental results."
도시재생정책에 대한 감성분석: 감천문화마을 방문객 리뷰를 중심으로,2019,"['Big data analysis', 'Gamcheon culture village', 'policy evaluation', 'sentimental analysis', 'TF-IDF weighted model', 'urban regeneration policy', '감성분석', '감천문화마을', '도시재생정책', '빅데이터 분석', '정책평가', 'TF-IDF 가중치모델.']","본 연구는 감천문화마을을 방문한 국내관광객들의 댓글을 이용한 감성분석을 통해 정부가 추진하고 있는 도시재생 정책에 대한 평가의 지능화를 목적으로 한다. 이를 위해 구글 지역리뷰 41,496건의 댓글을 수집 후 형태소, 음절, 그리고 자소를 결합한 Multi-channel CNN 모델을 활용하여 분석하였다. Multi-channel CNN 모델의 정확도는 86.68%로 단일로 구성된 모델들보다 높은 정확도를 보였다. 감성분석의 결과 긍정과 부정 비율이 8:2로, 감천문화마을의 도시재생정책에 대해 긍정 감성이 높게 나타났다. 또한 각각의 긍정문장과 부정문장을 분류하고 TF-IDF가중치 모델을 활용하여 긍정과 부정의 감성을 발생시킨 주요 요인들을 도출하였다. 본 연구의 공헌도로 학술적으로는 감성분석을 적용한 정책평가를 제시하였다는 점에서 향후 후속 연구를 유발할 것으로 예상된다. 실무적으로는 정부정책의 새로운 평가 방법으로서 방문객들의 댓글을 분석하여 정부사업의 성공여부를 판별할 수 있는 기초자료로 활용할 수 있다.","This study conducted a sentiment analysis using comments from domestic tourists who visited the Gamcheon Culture Village to evaluate the government's urban regeneration project automatically and efficiently. For this purpose, 41,496 comments from the local review from Google Map were collected and analyzed using a Multi-Channel CNN model that combines morphemes, syllables, and phonemes. The accuracy of the Multi-Channel CNN model was 85.72 percent, which is higher than the accuracy seen in Single-Channel CNN model. In the sentiment analysis, the ratio between the positive and negative responses was eight to two, indicating overall positive opinion regarding the urban regeneration project that is taking place in the Gamcheon Culture Village. Furthermore, the main factors that generated the positive and negative sentiments were extracted by classifying each positive and negative sentence using the TF-IDF weighted model. This study has an academic contribution in that the suggestion of policy evaluation through the application of a sentiment analysis will induce future studies. Practically, this study suggested an analysis of the visitors' comments as a new method of evaluating government policies, which can be used as fundamental data that can determine the success of other government projects in the future."
"Visual Classification of Wood Knots Using k-Nearest Neighbor and Convolutional Neural Network(k-Nearest Neighbor와 Convolutional Neural Network에 의한 
제재목 표면 옹이 종류의 화상 분류)",2019,"['visual classification', 'knot classification', 'k-nearest neighbor', 'convolution neural network', 'deep learning', 'species identification', 'wood classification']",국문 초록 정보 없음,"Various wood defects occur during tree growing or wood processing. Thus, to use wood practically, it is necessary to objectively assess their quality based on the usage requirement by accurately classifying their defects. However, manual visual grading and species classification may result in differences due to subjective decisions; therefore, computer-vision-based image analysis is required for the objective evaluation of wood quality and the speeding up of wood production. In this study, the SIFT+k-NN and CNN models were used to implement a model that automatically classifies knots and analyze its accuracy. Toward this end, a total of 1,172 knot images in various shapes from five domestic conifers were used for learning and validation. For the SIFT+k-NN model, SIFT technology was used to extract properties from the knot images and k-NN was used for the classification, resulting in the classification with an accuracy of up to 60.53% when k-index was 17. The CNN model comprised 8 convolution layers and 3 hidden layers, and its maximum accuracy was 88.09% after 1205 epoch, which was higher than that of the SIFT+k-NN model. Moreover, if there is a large difference in the number of images by knot types, the SIFT+k-NN tended to show a learning biased toward the knot type with a higher number of images, whereas the CNN model did not show a drastic bias regardless of the difference in the number of images. Therefore, the CNN model showed better performance in knot classification. It is determined that the wood knot classification by the CNN model will show a sufficient accuracy in its practical applicability."
딥러닝 기반의 복합 열화 영상 분류 및 복원 기법,2019,"['Deep learning', 'Multi-Degradation', 'Degradation Classification', 'Restoration order', 'Restoration']","CNN (convolutional neural network) 기반의 단일 열화 영상 복원 방법은 우수한 성능을 나타내지만 한가지의 특정 열화를 해결하는 데 맞춤화 되어있다. 본 연구에서는 복합적으로 열화 된 영상 분류 및 복원을 위한 알고리즘을 제시한다. 복합 열화 영상 분류 문제를 해결하기 위해 CNN 기반의 알고리즘인 사전 학습된 Inception-v3 네트워크를 활용하고, 영상 열화 복원을 위해 기존의 CNN 기반의 복원 알고리즘을 사용하여 툴체인을 구성한다. 실험적으로 복합 열화 영상의 복원 순서를 추정하였으며, CNN 기반의 영상 화질 측정 알고리즘의 결과와 비교하였다. 제안하는 알고리즘은 추정된 복원 순서를 바탕으로 구현되어 실험 결과를 통해 복합 열화 문제를 효과적으로 해결할 수 있음을 보인다.",다국어 초록 정보 없음
An IoT-Based Object Detection and Alerting System for Livestock Disease Prevention,2019,"['Faster R-CNN', 'YOLOv3', 'Object Detection', 'Livestock Disease Prevention', 'Internet of Things']",국문 초록 정보 없음,"In this paper, we implement object detection system for animal disease prevention through Faster Region-based Convolutional Neural Network (R-CNN) model and You Only Look Once (YOLO) v3 model. For object detection systems, we derive visual targets (pigs, human, trucks) and create open dataset through image collection and labeling. The open dataset is used to design the Faster R-CNN model for livestock disease detection of the object detection engine and the YOLOv3 model for farm environment detection of the object detection engine is designed using the pre-learned parameters. For the experiment, we use a webcam to capture the image of the visual target and detect the object using the designed model. The detected result is encoded for sharing. Then, the detection result is transmitted to the Internet of Things (IoT) server through the IoT client conforming to oneM2M standard. As a result, the Faster R-CNN model for animal disease detection was about 43.58%, and the YOLOv3 model for farm environment detection was about 55.17% and about 62.16%, respectively. The encoded data collected in the IoT server is decoded and sent to the registered users through the social network service (SNS) agent to implement the object detection system for the prevention of livestock diseases."
딥러닝 기반의 보행자 탐지 및 경보 시스템 연구,2019,"['Pedestrian traffic accident prevention', 'CNN', 'YOLO', 'ITS', 'UTIS', '보행자 교통사고 방지', 'CNN', 'YOLO', '지능형 교통시스템 체계', 'UTIS']","보행자 교통사고의 경우 사고 발생 시 사망사고로 연결되는 위험성이 있다. 국내 지능형교통시스템(ITS)은 질 좋은 교통 인프라를 구축하고 있음에도 불구하고, 거의 교통정보 수집에만 이용되고 있어, 위험상황 발생 시 지능적인 위험 요소 분류가 이루어지지 않고 있다. 본 연구에서 제안하는 시스템의 주요 구성 요소인 CNN 기반의 보행자 탐지 분류 모델의 경우 제한적인 환경에서 설치 운영되는 것을 가정하여 임베디드 시스템 기반으로 구현되었다. 기존YOLO의 인공신경망 모델을 개선하여 My-Tiny-Model3라는 새로운 모델을 생성하였고, 20,000 번의 반복 학습 기준으로 평균 정확도 86.29%와 21.1 fps의 실시간 탐지 속도 결과를 보였다.그리고, 이러한 탐지 시스템을 기반으로 하여 ITS 체계와 연계 가능한 시스템 구현 및 프로토콜 연동 시나리오를 구성하였다. 본 연구를 통해 기존 ITS 체계와 연동하는 보행자 사고 방지시스템을 구현한다면, 새로운 인프라 구축비용을 절감하고 보행자 교통사고 발생률을 줄이는데 도움이 될 것이다. 또한, 기존의 시스템 감시인력 소요에 따른 비용 또한 줄일 수 있을 것으로 기대된다.","In the case of a pedestrian traffic accident, it has a large-scale danger directly connected by a fatal accident at the time of the accident. The domestic ITS is not used for intelligent risk classification because it is used only for collecting traffic information despite of the construction of good quality traffic infrastructure. The CNN based pedestrian detection classification model, which is a major component of the proposed system, is implemented on an embedded system assuming that it is installed and operated in a restricted environment. A new model was created by improving YOLO's artificial neural network, and the real-time detection speed result of average accuracy 86.29% and 21.1 fps was shown with 20,000 iterative learning. And we constructed a protocol interworking scenario and implementation of a system that can connect with the ITS. If a pedestrian accident prevention system connected with ITS will be implemented through this study, it will help to reduce the cost of constructing a new infrastructure and reduce the incidence of traffic accidents for pedestrians, and we can also reduce the cost for system monitoring."
인공지능 기반 MNIST 손글씨 인식에 대한 연구,2019,"['Handwriting', 'SLR', 'ANN', 'CNN', 'Deep learning', '손글씨', '소프트맥스 회귀분석', '인공신경망', '합성곱신경망', '딥러닝']",국문 초록 정보 없음,"In the development of electronic devices such as PDAs, smartphones, and tablets, research on handwriting recognition has emerged. In the meantime, there have been efforts to recognize various handwriting such as numbers, Japanese, and English. However, there is a point that it is difficult to recognize when the font shape is relatively irregular, such as handwriting of children. As a result, the need for research to improve handwriting recognition rate by applying deep learning techniques has recently been raised. Therefore, this study attempted to improve handwriting recognition rate based on various deep learning techniques. In the case of handwriting, it is difficult to prepare a variety of data sets, which limits the recognition rate. In this study, we tried to improve the accuracy of handwriting recognition by using CNN technique in order to find a way to overcome these limitations. The techniques used were SLR, ANN, and CNN, each measuring the accuracy of each method. As a result, CNN showed the highest performance of 95%."
얼굴 표정 인식을 위한 Densely Backward Attention 기반 컨볼루션 네트워크,2019,[],"Convolutional neural network(CNN)의 등장으로 얼굴 표현 인식 연구는 많은 발전을 이루었다. 그러나, 기존의 CNN 접근법은 미리 학습된 훈련모델에서 Multiple-level 의 의미적 맥락을 포함하지 않는 Attention-embedded 문제가 발생한다. 사람의 얼굴 감정은 다양한 근육의 움직임과 결합에 기초하여 관찰되며, CNN 에서 딥 레이어의 산출물로 나온 특징들의 결합은 많은 서브샘플링 단계를 통해서 class 구별와 같은 의미 정보의 손실이 일어나기 때문에 전이 학습을 통한 올바른 훈련 모델 생성이 어렵다는 단점이 있다. 따라서, 본 논문은 Backbone 네트워크의 Multi-level 특성에서 Channel-wise Attention 통합 및 의미 정보를 포함하여 높은 인식 성능을 달성하는 Densely Backwarnd Attention(DBA) CNN 방법을 제안한다. 제안하는 기법은 High-level 기능에서 채널 간 시멘틱 정보를 활용하여 세분화된 시멘틱 정보를 Low-level 버전에서 다시 재조정한다. 그런 다음, 중요한 얼굴 표정의 묘사를 분명하게 포함시키기 위해서 multi-level 데이터를 통합하는 단계를 추가로 실행한다. 실험을 통해, 제안된 접근방법이 정확도 79.37%를 달성 하여 제안 기술이 효율성이 있음을 증명하였다.",다국어 초록 정보 없음
ResNet 모델을 이용한 눈 주변 영역의 특징 추출 및 개인 인증,2019,"['Periocular Region', 'Authentication', 'CNN', 'MLP']",국문 초록 정보 없음,"Deep learning approach based on convolution neural network (CNN)  has extensively studied in the field of computer vision. However, periocular feature extraction using CNN was not well studied because it is practically impossible to collect large volume of biometric data. This study uses the ResNet model which was trained with the ImageNet dataset. To overcome the problem of insufficient training data, we focused on the training of multi-layer perception (MLP) having simple structure rather than training the CNN having complex structure. It first extracts features using the pretrained ResNet model and reduces the feature dimension by principle component analysis (PCA), then trains a MLP classifier. Experimental results with the public periocular dataset UBIPr show that the proposed method is effective in person authentication using periocular region. Especially it has the advantage which can be directly applied for other biometric traits."
영상처리와 딥러닝 기법을 사용한 채소의 등급별 자동 분류시스템 개발,2019,"['채소 자동분류 시스템', '기계학습 기법', 'CNN', 'VGGNet', '오이 실험영상.', 'vegetable automatic classification system', 'machine learning techniques', 'CNN', 'VGGNet', 'cucumber experiment image.']","농업에서 생산된 과수나 채소에 대한 질을 확인하고 향상시키는 작업은 영상처리에서 굉장히 중요한 부분이다. 실제 농가에서는 스마트팜(smart_farm)을 도입하여 생산량의 증가로 자연히 수익을 늘어나고 또 노동시간이 단축되며 여가시간이 늘어 농가의 삶의 질을 높일 수 있게 되었다. 본 논문에서는 영상처리 기법과 딥러닝 기술을 사용하여 채소의 등급을 자동 분류하기 위한 시스템을 소개한다. 이를 목적으로 농가에서 직접 재배한 오이를 동일한 배경에서 촬영하여 이미지 데이터와 데이터 증가(augmentation) 기법을 통해 데이터셋을 구성하고 3가지 등급으로 분류하기 위한 기계학습방법인 SVM과 딥러닝 방법인 CNN, VGGNet 등을 사용하였다. 또한 본 연구는 대규모 데이터에서 오이를 기계가 자동으로 중요한 패턴과 규칙을 학습하고 의사결정과 예측 등을 하기 위해 구조나 손실 및 활성화 함수들 그리고 학습비율과 같은 하이퍼 파라미터(hyper-parameter)등을 변경시켜 가며 더 좋은 분류 성능을 내는 알고리즘을 개발하였다. 또한 실험을 통해서 제안된 알고리즘이 농업현장에서 취득한 영상자료를 사용해서 오이를 등급별로 잘 구별하는 것을 확인 할 수 있었다. 앞으로 이를 발전시켜 더 좋은 데이터를 많이 확보하고 훈련을 시킨다면 자동분류 시스템의 개발에 더 좋은 성능이 기대되며, 다양한 방면에 활용이 가능 할 것이다.","Identifying and improving the quality of fruits and vegetables produced in agriculture is a very important part of image processing. The introduction of smart_farm in the farmhouse increased production and naturally increased profit of the farmer. In addition, their working hours have been shortened and leisure time has been increased, so that the quality of life of the farmers can be increased. In this paper, we introduce a system for automatically classifying vegetable grades using image processing and deep-learning techniques. For this purpose, We obtained image data of cucumber cultivated directly in a farmhouse on the same background and constructed a data set using data augmentation technique. In order to classify cucumber into three classes, we used SVM, which is a machine running method, and CNN and VGGNet, which are deep running methods. In this study, we also modified the hyper-parameters such as structure, loss and activation functions and learning rate in order to learn the important patterns and rules of the machine automatically from large data and to make decisions and predictions. Experimental results show that the proposed algorithm can distinguish the cucumber by grade using image data obtained from farming sites. If we improve the performance of the automatic classification system by securing much better data and training, then it can be applied to various aspects."
합성곱 신경망을 이용한 보청기 환경잡음 분류 알고리즘,2019,"['Hearing aids', 'Noise classification', 'convolutional neural networks', 'Spectrogram', 'Hearing aids satisfaction']","본 논문은 보청기의 환경잡음 분류를 위해 소리 신호를 이미지 신호로 변환하여 합성곱 신경망(CNN, convolutional neural networks)을 적용한 잡음 분류 알고리즘에 관한 것이다. 장시간 현장 녹음한 생활 잡음을 이미지 신호로 변환하기 위해 스펙트로그램을 확인하고, sharpening mask와 median filter를 적용하여 합성곱 신경망 기법의 분류 결과를 비교하였다. 1초/2.5초/5초 단위 시간의 스펙트로그램 이미지 분류 결과, 1초의 합성곱 신경망 분류율이 가장 높았으며, 단위 시간이 증가 할수록 분류율이 감소하였다. 합성곱 신경망의 입력 데이터에 제안된 필터를 적용하여 분류율 결과를 비교했을 때, 필터를 적용하지 않은 스펙트로그램 이미지를 분류율이 median filter를 적용했을 때보다 최대 약 2.8% 상승한 것을 확인하였다.","In this paper, we present the environment noise classification algorithm using CNN(convolutional neural networks) for hearing aids by converting a sound signal to an image signal. We made spectrogram images from sound signal which have recorded the environment noise around hearing aids, and results of classification using CNN were compared by applying Sharpening Mask and Median Filter. As a result of the spectrogram image classification rate in 1sec. was the highest, and the classification rate was decreased as the time increased to 5sec. When comparing the proposed classification rate results according to the CNN input data, the classification rate without the filter was up to about 2.8% higher than that with the median filter."
문장 레벨 그래프 회선 신경망을 통한 텍스트 분류,2019,"['natural language processing', 'neural networks', 'graph convolutional networks', 'textgraph', 'graph classification', 'text classification', '자연어 처리', '인공 신경망', '그래프 회선 신경망', '텍스트그래프', '그래프 분류', '텍스트 분류']","텍스트 분류는 자연어처리 분야의 전통적인 문제이다. 기존의 RNN 및 CNN 기반 텍스트 분류 모델들은 순차적인 단어 구조에 의존하기 때문에 인접하지 않지만 관련성이 높은 단어 간의 관계를 유추하기 어렵다는 문제점이 있다. 반면 GCN(Graph Convolutional Network)은 그래프의 형태로 데이터를 입력받기 때문에 문장의 순차적 구조에 대한 의존도를 줄일 수 있다. 본 논문에서는 문서의 비순차적인 관계를 그래프로 담아내어 더욱 효과적으로 파악하고 분류하는 인공신경망 모델을 제안한다. 문서를 그래프로 표현하기 위해 각 단어를 그래프의 노드로 변환하고, 단어 간의 관계를 계산해 엣지로 정의한다. 최근에 제시된 GCN 구조를 통해 단어 간의 관계가 반영된 단어 벡터를 계산한 뒤, 어텐션 기반 요약 함수를 통해 문단을 주어진 클래스로 분류하는 방법을 제시한다. 실험 결과, 새롭게 제시된 모델이 RNN 및 CNN 기반 텍스트 분류 모델보다 좋은 성능을 보였다.","Text classification is an important task in natural language processing, and most of the recent approaches employ neural networks to learn and classify the texts. RNN and CNN based models, which are widely used for solving the task, involve reading and processing the text in a sequential manner. This creates inefficiency in learning dependencies between far-apart words. On the contrary, Graph Convolutional Network (GCN) architecture is capable of processing more complex graph-structured data, thus having potential to recognize and learn from complex linguistic structures.In the present work, we transform text sequences into graphs by assigning each word in the text as a node and representing the relationship between words as edges. We then propose a method for solving text classification that uses recent GCN architectures to take the transformed text-graph as input, learn hidden representations, and output a single hidden representation for classification. In our experiments, our proposed model outperformed RNN and CNN based models with regards to various text classification tasks."
Structural vibration-based classification and prediction of delamination in smart composite laminates using deep learning neural network,2019,"['Smart materials', 'Delamination', 'Vibration', 'Non-destructive testing']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>This paper proposes a Convolutional Neural Network (CNN) based approach for the classification and prediction of various types of in-plane and through-the-thickness delamination in smart composite laminates using low-frequency structural vibration outputs. An electromechanically coupled mathematical model is developed for the healthy and delaminated smart composite laminates, and their structural vibration responses are obtained in the time domain. Short Time Fourier Transform (STFT) is employed to transform the transient responses into two-dimensional spectral frame representation. A convolutional neural network is incorporated to distinguish between the damaged and undamaged states, as well as various types of damage of the laminated composites, by automatically extracting discriminative features from the vibration-based spectrograms. The CNN showed a classification accuracy of 90.1% on one healthy and 12 delaminated cases. The study of the confusion matrix of CNN provided further insights into the physics of the problem. The predictive performance of a pre-trained CNN classifier was also evaluated on unseen cases of delamination, and physically consistent results were obtained.</P>"
Convolutional neural network based surface inspection system for non-patterned welding defects,2019,['Defect detection Automatic inspection Convolutional neural network Machine vision Image processing Deep learning'],국문 초록 정보 없음,"In this paper, we propose a convolutional neural network (CNN) based method that inspects non-patterned welding defects (craters, pores, foreign substances and fissures) on the surface of the engine transmission using a single RGB camera. The proposed method consists of two steps: first, extracting the welding area to be inspected from the captured image, and then determining whether the extracted area includes defects. In the first step, to extract the welding area from the captured image, a CNN based approach is proposed to detect a center of the engine transmission in the image. In the second stage, the extracted area is identified by another CNN as defective or non-defective. To train the second stage CNN stably, we propose a class-specific batch sampling method. With our sampling method, biased learning caused by data imbalance (number of collected defective images is much less than that of non-defective images) is effectively prevented. We evaluated our system with a large amount of samples (about 32,000 images) collected manually from the production line, and our system shows a remarkable performance in all experiments."
A Comparative Study on OCR using Super-Resolution for Small Fonts,2019,"['Korean OCR', 'Tesseract', 'Super-resolution', 'Text-recognition', 'and Deep-learning']",국문 초록 정보 없음,"Recently, there have been many issues related to text recognition using Tesseract. One of these issues is that the text recognition accuracy is significantly lower for smaller fonts. Tesseract extracts text by creating an outline with direction in the image. By searching the Tesseract database, template matching with characters with similar feature points is used to select the character with the lowest error. Because of the poor text extraction, the recognition accuracy is lowerd. In this paper, we compared text recognition accuracy after applying various super-resolution methods to smaller text images and experimented with how the recognition accuracy varies for various image size. In order to recognize small Korean text images, we have used super-resolution algorithms based on deep learning models such as SRCNN, ESRCNN, DSRCNN, and DCSCN. The dataset for training and testing consisted of Korean-based scanned images. The images was resized from 0.5 times to 0.8 times with 12pt font size. The experiment was performed on x0.5 resized images, and the experimental result showed that DCSCN super-resolution is the most efficient method to reduce precision error rate by 7.8%, and reduce the recall error rate by 8.4%. The experimental results have demonstrated that the accuracy of text recognition for smaller Korean fonts can be improved by adding super-resolution methods to the OCR preprocessing module."
Pest Control System using Deep Learning Image Classification Method,2019,"['Image Processing', 'Convolutional Neural Network', 'Background Subtraction', 'Classification']",국문 초록 정보 없음,"In this paper, we propose a layer structure of a pest image classifier model using CNN (Convolutional Neural Network) and background removal image processing algorithm for improving classification accuracy in order to build a smart monitoring system for pine wilt pest control. In this study, we have constructed and trained a CNN classifier model by collecting image data of pine wilt pest mediators, and experimented to verify the classification accuracy of the model and the effect of the proposed classification algorithm. Experimental results showed that the proposed method successfully detected and preprocessed the region of the object accurately for all the test images, resulting in showing classification accuracy of about 98.91%. This study shows that the layer structure of the proposed CNN classifier model classified the targeted pest image effectively in various environments. In the field test using the Smart Trap for capturing the pine wilt pest mediators, the proposed classification algorithm is effective in the real environment, showing a classification accuracy of 88.25%, which is improved by about 8.12% according to whether the image cropping preprocessing is performed. Ultimately, we will proceed with procedures to apply the techniques and verify the functionality to field tests on various sites."
Effect of Data Augmentation of F-18-Florbetaben Positron-Emission Tomography Images by Using Deep Learning Convolutional Neural Network Architecture for Amyloid Positive Patients,2019,"['Alzheimer’s disease (AD)', 'Mild cognitive impairment (MCI)', 'F-18-Florbetaben (F-18-FBB)', 'Amyloid PET', 'Convolutional neural network (CNN)', 'Artificial intelligence (AI)']",국문 초록 정보 없음,"Early diagnosis of dementia helps in finding suitable treatments that reduce or even prevent future cognitive dysfunction of patients. In this paper, we use a convolutional neural network to classify the brain positron-emission tomography (PET) image of Alzheimer’s disease (AD) and mild cognitive impairment (MCI) in a normal control (NC). The purpose of this study is to investigate the influence of the data increment method and the number of data for the best accuracy in the convolutional neural network (CNN) by using the AlexNet algorithm with amyloid PET images. All subjects had an intravenous injection of 300 MBq of F-18-Florbetaben (F-18-FBB, Piramal Imaging, Berlin), and PET acquisition was started 90 min after the radio-tracer injection. The image data were classified into NC, MCI and AD based on the findings of the neurologist. We performed data augmentation using a method such as flip, rotation, and GAN, in addition to pre-processing and data augmentation for AlexNet, in order to supplement a number of deficient data. Artificial intelligence (AI) learning was simulated using the Mini-batch Stochastic Gradient Descent (MSGD) algorithm, and the learning rate was 5e-5, and the epoch was 100. Using a CNN and the ‘AlexNet’ architecture, we successfully classified F-18-FBB PET images of AD from NC where the accuracy of the test data on trained data reached 98.14%. In this work, the CNN, which is a deep learning neural network architecture, was used in order to distinguish AD and MCI from the NC. Accuracy was 98.33%, NC recall was 99.16%, MCI recall was 95.83% and AD recall was 98.16% after learning the data by using rotation and LR flip to increase the number of data. The accuracy was increased by 4.96%, NC recall was increased by 10.68%, MCI recall was decreased by 0.23%, and AD recall was increased by 9.65% after learning the data by using DCGAN to increase the number of data to 4020. Accuracy and recall were improved when data were learned through data augmentation by rotation and by left and right reversal. However, the effect of learning data by increasing the data by using up-down reversal and data augmentation through DCGAN was almost insignificant."
CycleGAN을 이용한 야간 상황 물체 검출 알고리즘,2019,"['CycleGAN', 'Data Sampling', 'Image-to-Image Translation']",국문 초록 정보 없음,"Recently, image-based object detection has made great progress with the introduction of Convolutional Neural Network (CNN). Many trials such as Region-based CNN, Fast R-CNN, and Faster R-CNN, have been proposed for achieving better performance in object detection. YOLO has showed the best performance under consideration of both accuracy and computational complexity. However, these data- driven detection methods including YOLO have the fundamental problem is that they can not guarantee the good performance without a large number of training database. In this paper, we propose a data sampling method using CycleGAN to solve this problem, which can convert styles while retaining the characteristics of a given input image. We will generate the insufficient data samples for training more robust object detection without efforts of collecting more database. We make extensive experimental results using the day-time and night-time road images and we validate the proposed method can improve the object detection accuracy of the night-time without training night-time object databases, because we converts the day-time training images into the synthesized night-time images and we train the detection model with the real day-time images and the synthesized night-time images."
Exploiting hierarchical visual features for visual question answering,2019,"['Visual question answering', 'Multi-level features', 'Neural networks']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>Visual question answering (VQA) aims reasoning answers given a pair of textual question and image. Previous approaches for VQA use only the highest layer of a Convolutional Neural Network (CNN) for visual representation, which biases on object classification task. These object-categorization oriented features lose low-level semantics (attribute related questions), e.g., color, texture, and the number of instances. Consequently, conventional VQA methods are vulnerable to low-level semantic questions. On the other hand, low-level layer features retain the low-level semantics. Thus, we suggest that the low-level layer features are superior in low-level semantic questions, and justify it through our experiments. Furthermore, we propose a novel VQA model named Hierarchical Feature Network (HFnet), which exploits intermediate CNN layers to derive various semantics for VQA. In the answer reasoning stage, each hierarchical feature is combined with the attention map and multimodal pooled to consider both high and low level semantic questions. Our proposed model outperforms the existing methods. The qualitative experiments also demonstrate that our proposed HFnet is superior in reasoning attention regions.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  We show that low-level semantic information can be derived from low-level CNN layers to improve VQA performance. </LI> <LI>  HFnet, a novel VQA that exploits both low and high-level features from a CNN for encoding visual semantics, is proposed. </LI> <LI>  The proposed method improves VQA accuracy using only the image-question paired dataset. </LI> </UL> </P>"
Research on Concrete Cracks Recognition based on Dual Convolutional Neural Network,2019,"['concrete bridges', 'bridge inspection', 'recognition of cracks', 'double convolutional neural network model', 'structure of merging layer-by-layer']",국문 초록 정보 없음,"Cracks are the most common and important diseases of concrete bridges. A dual convolutional neural network (DCN) model which is composed of one convolutional neural network (CNN) model and one fully convolutional network (FCN) model is proposed to recognize the cracks in image. Firstly, the CNN model is used to identify the crack area. The interfering factors such as spot, shadow, water stain, and graffiti in the non-crack area will be excluded by CNN model. Then, the CNN results will be segmented by the FCN model with the structure of merging layer-by-layer to extract crack features such as length and width. The DCN model is trained to recognize the actual concrete bridge cracks in this paper. The recognition results show that the DCN model has a good balance between high accuracy and low noise in the process of crack recognition compared with the current image recognition method. The reliability and accuracy of recognition are both greatly improved. The DCN model is helpful for automatic identification of cracks in concrete bridges."
심층 신경회로망들을 사용한 기흉 진단,2019,"['Convolutional Neural Networks', 'U-Net', 'EfficientNet', 'ResNetM', 'ask-RCNN', 'Xecption']","기흉은 가슴에 공기가 차는 것으로, 일반적으로 흉부 엑스레이를 사용하여 진단한다. 데이터 전처리를 하였고, 전처리방법으로는 결측값 제거 및 마스킹을 하였다. 최근에 와서 심층신경망의 성능이 개선됨에 따라서 활발히 사용되고 있고, 특히 영상인식에 적용되어 기존의 방법에 비하여 향상된 성능을 보이고 있다.기흉을 진단하는데 U-Net, Mask R-CNN, Resnet, EfficientNet, Xception을 사용하였으며, 이 심층 신경 회로망들의 성능을 비교하였다. U-Net은 Sementic Segmentation을사용하였고, Mask R-CNN은 Instance Segmentation을 사용하였다. Sementic Segmentation은 분할의 기본 단위를 클래스로하여, 동일한 클래스에 속하는 사물은 예측마스크 상에 동일한 색깔로 표시한다. Instance Segmentation은 분할의 기본단위를 사물로 하여, 동일한 클래스에 속하더 라도 다른 사물에 해당하면 예측 마스크 상에 다른 색깔로 표시한다. 실험 결과EfficientNet의 성능이 가장 좋았다. 이는 의사의 기흉 진단을 보조하기에 충분한 성능으로 의사를 도와 기흉을 진단하는데효율적으로 이용 될 수 있다.","A Pneumothorax is an abnormal collection of air in the space between lung and chest wall and is diagnosed using chest X-ray. Preprocessings, such as the eliminaton of missing value and masking, were performed. Performances of U-Net, Mask R-CNN, Resnet, EfficientNet and Xception for diagnosing pneumothorax are compared. U-Net uses semantic segmentation and Mask R-CNN uses instance segmentation. Semantic segmentation uses a class as the unit of segmentation. Therefore, objects in the same class are denoted using the same color on the prediction mask. On the other hand, instance segmentation uses object as the unit of segmentation. Therefore, objects in the same class are denoted using the different color on the prediction mask, if they belong to the different objects. EfficientNet got the best result. It can be efficiently used because it performs well enough to assist for physicians to diagnose pneumothorax using the chest X-ray"
멀티 뷰 기법 리뷰: 이해와 응용,2019,"['멀티 뷰 학습', '딥 러닝', '기계학습', '데이터 통합', 'multi-view learning', 'multi-modal learning', 'deep learning', 'machine learning', 'data integration']","멀티 뷰 기법은 데이터를 다양한 관점에서 보려는 접근 방법이며 데이터의 다양한 정보를 통합하여 사용하려는 시도이다. 최근 많은 연구가 진행되고 있는 멀티 뷰 기법에서는 단일 뷰 만을 이용하여 모형을 학습시켰을 때 보다 좋은 성과를 보인 경우가 많았다. 멀티 뷰 기법에서 딥 러닝 기법의 도입으로 이미지, 텍스트, 음성, 영상 등 다양한 분야에서 좋은 성과를 보였다. 본 연구에서는 멀티 뷰 기법이 인간 행동 인식, 의학, 정보 검색, 표정 인식 분야에서 직면한 여러 가지 문제들을 어떻게 해결하고 있는지 소개하였다. 또한 전통적인 멀티 뷰 기법들을 데이터 차원, 분류기 차원, 표현 간의 통합으로 분류하여 멀티 뷰 기법의 데이터 통합 원리를 리뷰 하였다. 마지막으로 딥 러닝 기법 중 가장 범용적으로 사용되고 있는 CNN, RNN, RBM, Autoencoder, GAN 등이 멀티 뷰 기법에 어떻게 응용되고 있는지를 살펴보았다. 이때 CNN, RNN 기반 학습 모형을 지도학습 기법으로, RBM, Autoencoder, GAN 기반 학습 모형을 비지도 학습 기법으로 분류하여 이 방법들이 대한 이해를 돕고자 하였다.","Multi-view learning considers data from various viewpoints as well as attempts to integrate various information from data. Multi-view learning has been studied recently and has showed superior performance to a model learned from only a single view. With the introduction of deep learning techniques to a multi-view learning approach, it has showed good results in various fields such as image, text, voice, and video. In this study, we introduce how multi-view learning methods solve various problems faced in human behavior recognition, medical areas, information retrieval and facial expression recognition. In addition, we review data integration principles of multi-view learning methods by classifying traditional multi-view learning methods into data integration, classifiers integration, and representation integration. Finally, we examine how CNN, RNN, RBM, Autoencoder, and GAN, which are commonly used among various deep learning methods, are applied to multi-view learning algorithms. We categorize CNN and RNN-based learning methods as supervised learning, and RBM, Autoencoder, and GAN-based learning methods as unsupervised learning."
환경 빅데이터 분석 및 서비스 개발 Ⅲ,2019,"['빅데이터', '기계학습', '신경망모형', '텍스트마이닝', 'Big Data', 'Machine Learning', 'Neural Network Model', 'Text Mining']","Ⅰ. 연구의 배경 및 목적□ 환경연구에 빅데이터 분석 방법론을 접목하여 환경정책 개발 가능성을 모색□ 빅데이터 분석 방법론의 정확성 및 재생성을 활용하여 정책수요 파악 및 정책 시의성 평가, 정책 유효성 평가를 주기적으로 시행하는 ‘(가칭)환경정책 모니터링 시스템’ 구축ㅇ 정책 수요 파악: 환경오염도 예측, 환경 수요자 생성 텍스트 및 환경 관련 SNS 감성분석, 환경이슈 기반 데이터 분석- 환경오염도 예측: 정책 개입이 필요한 환경정책 분야 사전 파악- 환경 수요자 생성 텍스트 분석: 수요자의 관심이 집중되는 환경 분야 파악- 환경 관련 SNS 감성분석: 국민의 불안을 야기하는 환경이슈 파악- 환경이슈 기반 데이터 분석: 국민적 관심 대상 이슈를 선정하고 이슈별 데이터 분석을 연계하여 분석 결과가 환경에 부정적인 이슈를 파악ㅇ 정책 시의성 평가: 환경 공급자 생성 텍스트를 분석하여 해당 시점의 환경수요와 조응 여부 평가ㅇ 정책 유효성 평가: 환경오염 개선 여부, 환경 SNS 감성 개선 여부, 환경이슈 개선여부 진단- 환경오염 개선: 정책 시행 이전 예측치와 이후 실측치 비교- 환경 SNS 감성 개선: 정책 시행 이전과 이후 SNS 감성 비교- 환경이슈 개선 여부: 환경에 부정적인 분석 결과에 대한 개선 여부 점검□ ‘(가칭)환경정책 모니터링 시스템’을 구성하는 ‘딥러닝 기반 환경오염 종합예측 알고리즘’, ‘실시간 환경 텍스트 분석 알고리즘’, ‘질문 중심 데이터베이스’ 구축작업을 시작ㅇ 딥러닝 기반 환경오염 종합예측 알고리즘: 6개 대기오염물질 오염도를 예측하는 대기오염 예측모형과 클로로필-a 오염도를 예측하는 수질오염 예측모형으로 구성ㅇ 실시간 환경 텍스트 분석 알고리즘: 환경정책수요자 생성 텍스트 및 환경정책 공급자 생성 텍스트 주제-키워드를 추출하는 ‘환경 텍스트 정보 추출’ 알고리즘과 기후변화 SNS 감성을 분류하는 ‘기후변화 감성분석기’로 구성ㅇ 질문 중심 데이터베이스: 환경 관련 주요 이슈 네트워크와 각 이슈 관련 데이터 분석으로 구성□ ‘(가칭)환경정책 모니터링 시스템’으로 포괄하기 어려운 2건의 개별 연구 수행ㅇ 딥러닝 기반 풍력발전량 예측: 기상데이터를 이용하여 풍력발전량 예측ㅇ 딥러닝 이용 국내 노인인구 COPD 사망 추정: 건강보험 코호트 데이터를 이용하여 미세먼지 오염도가 만성 폐쇄성 폐질환 환자 사망위험에 미치는 영향 추정Ⅱ. ‘(가칭)환경정책 모니터링 시스템’ 구현1. 딥러닝 기반 환경오염 통합예측□ 대기오염 오염도 예측 알고리즘: CNN 알고리즘을 이용하여 6개 대기오염물질(PM<sub>10</sub>, PM<sub>2.5</sub>, O<sub>3</sub>, CO, SO<sub>2</sub>, NO<sub>2</sub>) 오염도 예측ㅇ 전국을 10㎞ × 10㎞로 분할, 각 권역의 시간별 오염도를 1~24시간 전 예측ㅇ 일산화탄소(CO) 오염도 예측치, 미세먼지(PM<sub>10</sub>) 오염도 예측치, 초미세먼지(PM<sub>2.5</sub>) 오염도 예측치의 평균제곱근오차를 표본표준편차의 14.8~44.0%로 축소ㅇ 미세먼지 오염도가 ‘나쁨’이상으로 분류되는 상황은 정확도 90.4%, 초미세먼지 오염도가 ‘나쁨’이상으로 분류되는 상황은 정확도 92.2%로 예측□ 녹조 예측 알고리즘: CNN 알고리즘을 이용하여 4대강 유역 29개 측성소의 클로로필-a 오염도를 1일 전 예측ㅇ 예측치의 평균제곱근오차를 표본표준편차의 30.3%로 축소2. 실시간 환경 텍스트 분석 알고리즘□ 환경 텍스트 정보 추출 알고리즘: 환경정책수요자 생성 텍스트 및 환경정책 공급자 생성 텍스트를 주기적으로 수집하고 주제 및 키워드 분석을 수행ㅇ 환경정책수요자 생성 텍스트로는 네이버 뉴스, 환경정책 공급자 생성 텍스트로는 환경부 보도자료 및 환경부 e-News를 사용ㅇ 키워드 빈도 수 파악, 키워드 네트워크 추출, 문서요약, 키워드 그룹 추출 및 키워드 그룹 구성비 추출ㅇ 수집 및 정보 추출을 1일 2회 반복하여 결과를 축적□ 기후변화 감성분류기: 기후변화 SNS 전처리를 자동화하고 4개 감성분류 알고리즘의 앙상블(ensemble) 모형을 개발하여 감성분류 정확도를 제고ㅇ 4개 알고리즘: 형태소 단위 감성분류 알고리즘 2개, 음절 단위 감성분류 알고리즘, 자모 단위 감성분류 알고리즘- 형태소 단위: 형태소 분류기 MECAB, TWITTER 2가지 사용ㅇ SNS 텍스트의 감성을 79.9% 정확도로 ‘긍정’ 및 ‘부정’으로 분류 가능하고 평균정확도(Average Precision)는 0.846 달성3. 질문 중심 데이터베이스□ ‘중요한 이슈를 파악하고, 이슈와 관련된 데이터 분석을 제공’하는 질문기반 데이터 활용을 환경 분야에 적용ㅇ ‘존재하는 데이터로 분석할 수 있는 이슈를 분석’하는 기존 데이터 연구 방식이 정책이슈의 동태적 변화에 대응하기 어려운 약점을 보완ㅇ 국회회의록 및 신문기사로부터 환경정책 부문 주요 이슈 도출- 18·19대 국회 환경노동위원회 법안심사소위원회 회의록, 20대 국회 환경노동위원회 환경소위 회의록, 2008~2018년 13개 신문사 환경 관련 기사 17만 6,663개 사용- 미세먼지 관련 이슈가 압도적인 비중을 차지ㅇ 선정된 이슈 18개를 3개 층위 네트워크로 구성하고, 각 이슈별 관련 데이터 분석 연계ㅇ 데이터 수집 및 분석 과정 자동화: 실시간 분석 결과 확인 및 신규 데이터를 반영하여 분석 결과를 갱신하는 기능 부여Ⅲ. 개별 연구□ ‘딥러닝 기반 풍력발전량 예측’: 한국남부발전 제주 한경 1호기, 2호기 풍력발전량을 고산 기상관측소의 기상데이터를 이용하여 예측하는 RNN, LSTM 알고리즘 개발ㅇ 풍속, 풍향, 기온, 강수량, 습도, 기압 자료를 이용하여 1시간 및 1일 이후 발전량 예측ㅇ 단순회귀분석 대비 1일 이후 발전량 예측치 평균제곱근오차 11.6%, 12시간 이후 발전량 예측치 평균제곱근 오차 43.9%, 6시간 이후 발전량 예측치 평균제곱근 오차 56.9% 축소□ ‘딥러닝 이용 국내 노인인구 COPD 사망위험 추정’: 1개월 미만의 단기 미세먼지 노출이 65세 이상 만성폐쇄성폐질환 환자의 사망위험에 미치는 영향 추정ㅇ cox proportional hazard 모형을 이용한 생존분석(Survival analysis) 이용ㅇ 서울시 거주 65세 이상 만성폐쇄성폐질환 환자의 2006~2015년 건강보험 자료와 시군구 단위 환자 거주지의 기상 및 대기오염 오염도 자료를 결합ㅇ 미세먼지 노출 정도: 사망 1개월 전에 일평균 미세먼지 오염도가 ‘나쁨’ 이상인 일수가 1~14일임을 나타내는 더미변수ㅇ 노출일수가 0인 경우에 비해서 PM<sub>10</sub>은 노출일수 6일 이상, PM<sub>2.5</sub>는 노출일수 9일 이상일 경우 사망위험의 hazard ratio가 2이상으로 증가Ⅳ. 결론 및 정책 제언□ ‘(가칭)환경정책 모니터링 시스템’ 운용 가능성 확인: 2019년 개발 알고리즘을 사용하면 미세먼지 관련 정책수요 진단, 정책 시의성 평가, 정책 유효성 평가 가능ㅇ 딥러닝 기반 환경오염 통합예측 알고리즘: 1일 후 미세먼지 오염도 ‘나쁨’ 이상 예측 지역을 10㎞ × 10㎞ 단위로 파악ㅇ ‘환경 텍스트 정보 추출’ 알고리즘: 수요자 생성문서(네이버 뉴스)의 미세먼지 관련 키워드 출연 시점과 동일 시점의 공급자 생성문서(환경부 보도자료, 환경부 e-News) 키워드를 비교하여 정책의 시의성 진단ㅇ 딥러닝 기반 환경오염 통합예측 알고리즘: 정책 개입 이전 미세먼지 오염도 예측치와 정책 개입 이후 실측치를 비교- 다양한 시차를 두고 지역별로 파악 가능ㅇ ‘질문 중심 데이터베이스’: 정책 개입 이전과 이후의 각 이슈 관련 데이터 분석 결과를 비교하여 정책 개입의 성과를 18개 이슈에 대하여 진단 가능□ 스마트 그리드 구축에 딥러닝 모형 적용 가능: 발전량이 불안정한 풍력발전량의 변화를 예측하여 발전량 부족이 예측될 경우 가동 시간이 짧은 대체 발전원 연계□ 미세먼지 위험 관리 시 고령 만성폐쇄성폐질환 환자 사망위험 고려 필요ㅇ 65세 이상 만성폐쇄성폐질환 환자는 일평균 농도가 ‘나쁨’ 이상이 되는 기간이 1주일 이상 지속되는 경우에는 심각한 위험에 노출되므로 적극적 개입 필요","Ⅰ. Background and Aims of Research□ We tried to apply the Big Data analysis methodology to environmental policy research.□ Applying Machine Learning to build up an ‘Environmental Policy Monitoring System’ dedicated to periodically searching environmental policy needs and assessing timeliness and effectiveness of environmental policyㅇ Search for needs: Pollution prediction, policy consumer text analysis, environment-related social media sentiment analysis, issue-based data analysis- Pollution prediction: Early detection of policy areas in need of policy intervention- Policy consumer text analysis: Detect policy areas which draw consumers’ attention- Social media sentiment analysis: Detect environmental issues related to negative sentiment- Issue-based data analysis: Link preselected environmental issues with simple data analysis, and identify issues with non-environmentally friendly data analysis outcomesㅇ Timeliness assessment: Analyze text produced by policy provider to check if keywords/topics match the policy needs at handㅇ Effectiveness assessment: Check pollution improvement, social media sentiment improvement, and environmental issue improvement- Pollution improvement: Compare pollution estimates before and after policy intervention- Social media sentiment: Compare social media sentiment before and after policy intervention- Environmental issue improvement: Check issues with non-environmentally friendly data analysis outcomes before policy intervention□ Begin to construct three compartments of an ‘Environmental Policy Monitoring System’: ‘Deep Learning-Based Pollution Prediction algorithm’, ‘Environmental Text Analysis algorithm’, and ‘Issue-Based Database’ㅇ Deep Learning-Based Pollution algorithm: An air pollution prediction algorithm which estimates the pollution of 6 air pollutants and a water pollution prediction algorithm which estimates chlorophyll-a pollutionㅇ Environmental Text Analysis algorithm: A text mining algorithm for text produced by policy consumer and policy provider, and a sentiment analysis algorithm for climate change related to social mediaㅇ Issue-Based Database: An environmental issue network and data analysis for each issue in the network□ Perform research that cannot be integrated into the ‘Environment Policy Monitoring System’: Two casesㅇ Deep Learning-Based Wind Power Generation Prediction: Estimate wind power generation using climate dataㅇ Deep Learning-Based Death Risk Estimation of Korean Senior COPD Patients: Estimate the effect of PM pollution on the death risk of COPD patients using NHI (National Health Insurance) dataⅡ. Environmental Policy Monitoring System1. Deep Learning-Based Pollution Prediction algorithm□ Air pollution Prediction algorithm: A CNN algorithm which estimates the air pollution of 6 pollutants (PM10, PM2.5, O3, CO, SO2, NO2)ㅇ Estimate the air pollution of a 10km x 10km grid on the South Korean Peninsula 1~24 hours in advanceㅇ Reduce RMSE of CO pollution predictions, PM10 pollution predictions, PM2.5 pollution predictions to 14.8-44.0% of sample standard deviationㅇ Predict ‘high concentrations’ of PM10 with 90.4% accuracy, and predict ‘high concentrations’ of PM2.5 with 92.2% accuracy□ Chlorophyll-a Pollution Prediction algorithm: A CNN algorithm which estimates 29 water pollution measuring stations on 4 major rivers a day in advanceㅇ Reduce RMSE of chlorophyll-a pollution prediction to 30.3% of sample standard deviation2. Environmental Text Analysis algorithm□ Environmental Text Mining algorithm: Periodically collect text produced by policy consumer and policy provider, and perform topic derivation and keyword analysisㅇ We used Naver environmental news to collect text produced by policy consumer and press releases from the Ministry of Environment for text produced by policy providerㅇ Perform Keyword frequency count, keyword network extraction, auto text summarization, keyword group extraction, keyword group composition calculationㅇ Accumulate data and update results twice a day□ Climate Change related social media sentiment analysis algorithm: Automatize pre-processing and construct an ensemble algorithm of four sentiment analysis algorithmsㅇ Four sub algorithms: 2 token-based algorithms, 1 syllable-based algorithm, 1 character-based algorithm- Different tokenizers were used for each token-based algorithm: MECAB, TWITTERㅇ Perform Keyword frequency count, keyword network extraction, auto text summarization, keyword group extraction, keyword group composition calculation3. Issue-Based Database□ Applying the principle of ‘identify the issue first and then provide data analysis related to the issue’ to Environmental Policy Analysisㅇ Compensate for the rigidness of the current method of ‘identify data, and then analyze the issues related to that data’ㅇ Identifying issues: Select 18 issues from text mining results in the national assembly minutes and newspaper articles- 18·19th Assembly Environment and Labor Committee Bill Subcommittee Minutes, 20th Assembly Environment and Labor Committee Environment Subcommittee Minutes, 176,633 newspaper articles related to environmental issues from 2008 to 2018- The issue of fine particles dominated all text sourcesㅇ Organize 18 issues into a three-level hierarchy network and link issuespecific data analysis to each issueㅇ Automatize data collection and data analysis : Real-time new data collection and updatesⅢ. Separate Research□ Deep Learning-Based Wind Power Generation Prediction: Predict wind power generation of Korea Southern Power Co. Jeju Hankyung 1 plant, Hankyung 2 with the climate data from the Gosan Weather Station using RNN, LSTMㅇ Used wind speed, wind direction, temperature, rainfall, humidity, air pressureㅇ Compared to Linear Regression, RNN, LSTM algorithm reduced RMSE of 1-day-ahead prediction by 11.6%, 12-hour-ahead prediction by 43.9%, 6-hour-ahead prediction by 56.9%□ ‘Deep Learning-Based Death Risk Estimation of Korean Senior COPD Patients’: Estimate the effect of short-term exposure within 1 month on the death risk of COPD patients aged 65 and olderㅇ Perform survival analysis using the cox proportional hazard modelㅇ Combine national health insurance medical data of COPD patients aged 65 and older in Seoul from 2006-2015 with air pollution and climate dataㅇ Exposure variables: Dummy variables indicating the number of days of ‘high concentrations of PM a month before deathㅇ Compared to 0 day exposure, patients exposed to ‘high concentrations’ of PM10 for 6 days or more had the hazard risk two times higher.ㅇ Compared to 0 day exposure, patients exposed to ‘high concentrations’ of PM2.5 for 9 days or more had the hazard risk two times higher.Ⅳ. Conclusion and Suggestions□ Confirm that the ‘Environmental Policy Monitoring System’ can be used in practice: Algorithms developed up to 2019 can be used for fine particle policy monitoringㅇ Deep Learning-Based Pollution Prediction algorithm: Detect possible areas of ‘high concentrations’ of PM in a 10km x 10km area a day in advanceㅇ Environment text mining algorithm: Check whether keywords from press releases of the Ministry of Environment were related to fine particles when the keywords from Naver news were mostly related to fine particlesㅇ Deep Learning-Based Pollution Prediction algorithm: Compare PM pollution predictions before policy implementation with the actual level of pollution after policy implementation- Making comparisons by regions can be staggeredㅇ Issue-Based Database: Compare Data analysis results for 18 issues before and after policy implementation□ RNN, LSTM model can be used to construct a smart grid: Predict wind power generation and make alternative generators ready for predicted power shortages□ Fine particle policy should take into account the health risks of senior COPD patients: Being exposed to the ‘high’ concentrations of PM for more than a week could be critical for COPD patients aged 65 and older. Active policy involvement is needed."
특징점 가중치를 이용한 MNIST 필기체 숫자 학습속도 및 정확도 향상 방법,2019,"['CNN', 'Deep Learning', 'Convolution', 'Feature Map', 'Cropping']","본 논문에서는 CNN(Convolution Neural Network)에 Convolution 필터 적용 이후 발생하는 특징 맵들이 필터에 따라 얼마나 많은 중복적 영향을 받는지를 분석하고, 중복적 영향을 많이 받지 않는 특징 점에 영향력과 반비례한 가중치를 주었을 때 필터 수와 가중치 값에 따라 MNIST 필기체 숫자 인식을 위한 학습속도 및 정확도가 어떻게 변하는지에 대해 연구하였다. 그 결과 처리속도는 평균 389초 정도 향상되었으며, 숫자 인식률은 기존 97%에서 98%로 1% 향상됨을 증명하였다.","In this paper, we analyzed how much redundancy of the feature maps that occur after the application of the Convolution Filter to CNN (Convolution Neural Network) are affected by the filter, and studied how the learning speed and accuracy for recognition of the number of filters and their weighting changes depending on the number of filters and their weight values when the characteristic points that are not heavily affected by the overlap are weighted. As a result, the processing speed was improved by an average of 839 seconds and the numerical recognition rate was improved by 1% from 97% to 98%."
Best Practices on Educational Service Platform with AI Approach,2019,"['CNN Algorithm', 'Education', 'Recommendation', 'User Focused.']",국문 초록 정보 없음,"The current education is becoming more extensive with the application of various teaching methods. This is a problem that is so distributed that it is difficult for users to find the data and it takes a long time to find the information they need. Currently, various educational services, materials, and instruments are developed and scattered. Therefore, it is important to raise students' awareness of aptitude and career path with customized education tailored to students. Conventional education platforms have very difficult to choose the right materials for students because of the spread of educational programs and institution materials. To solve this, we propose a customized recommendation approach to recommend customized educational service materials and institution for students to teachers, which helps teachers conveniently choose materials suitable for their respective environments. On this new platform, the CNN algorithm provides recommended content for classes and students. For real service on the educational service platform, we implement this system for Jeil edus business . Through this mechanism, we expect to improve the quality of education by helping to select the right service."
몰포러지 신경망 기반 딥러닝 시스템,2019,"['CNN', 'Deep Learning', 'Embedded System', 'MNN', 'Morphology', 'VLSI']","본 논문에서는 몰포러지 연산을 기본으로 하는 몰포러지 신경망(MNN: Morphological Neural Network) 기반 딥러닝 시스템을 제안하였다. 딥러닝에 사용되는 레이어는 몰포러지 레이어, 풀링 레이어, ReLU 레이어, Fully connected 레이어 등이다. 몰포러지 레이어에서 사용되는 연산은 에로전, 다이레이션, 에지검출 등이다. 본 논문에서 새롭게 제안한 MNN은 기존의 CNN(Convolutional Neural Network)을 이용한 딥러닝 시스템과는 달리 히든 레이어의 수와 각 레이어에 적용되는 커널 수가 제한적이다. 레이어 단위 처리시간이 감소하고, VLSI 칩 설계가 용이하다는 장점이 있으므로 모바일 임베디드 시스템에  딥러닝을 다양하게 적용할 수 있다. MNN에서는 제한된 수의 커널로 에지와 형상검출 등의 연산을 수행하기 때문이다. 데이터베이스 영상을 대상으로 행한 실험을 통해 MNN의 성능 및 딥러닝 시스템으로의 활용 가능성을 확인하였다.","In this paper, we propose a deep learning system based on morphological neural network(MNN). The deep learning layers are  morphological operation layer, pooling layer, ReLU layer, and the fully connected layer. The operations used in morphological layer are erosion, dilation, and edge detection, etc. Unlike CNN, the number of hidden layers and kernels applied to each layer is limited in MNN. Because of the reduction of processing time and utility of VLSI chip design, it is possible to apply MNN to various mobile  embedded systems. MNN performs the edge and shape detection operations with a limited number of kernels. Through experiments using database images, it is confirmed that MNN can be used as a deep learning system and its performance."
"안전도, 뇌파도, 근전도 분석을 통한 수면 단계 분류",2019,"['Sleep Stage Classification', 'CNN Algorithm', 'DNN Algorithm', 'EEG', 'EOG', 'EMG', 'Polysomnography']",국문 초록 정보 없음,"Insufficient sleep time and bad sleep quality causes many illnesses and it’s research became more and more important. The most common method for measuring sleep quality is the polysomnography(PSG). The PSG is a test used to diagnose sleep disorders. The most common PSG data is obtained from the examiner, which attaches several sensors on a body and takes sleep overnight. However, most of the sleep stage classification in PSG are low accuracy of the classification. In this paper, we have studied algorithm for sleep level classification based on machine learning which can replace PSG. EEG, EOG, and EMG channel signals are studied and tested by using CNN algorithm. In order to compensate the performance, a mixed model using both CNN and DNN models is designed and tested for performance."
센서 및 카메라 비전을 활용한 OPC UA 기반 협동로봇 가드 시스템의 설계 및 구현,2019,"['Collaborative Robot Guard System', 'CNN', 'OPC UA']","제조 패러다임 변화에 따라 다양한 협동로봇이 신규시장을 창출하고 있다. 협동로봇은 기존 산업용 로봇 대비쉬운 운용, 생산성 향상, 단순 작업을 하는 인력을 대체하는 목적으로 모든 산업에서 협동로봇의 수요가 증가하고 있다.그러나 산업현장에서 협동로봇으로 인한 작업 중 사고가 빈번하게 발생하고 있으며, 작업자의 안전을 위협하고 있다.인간 중심의 환경에서 로봇을 통한 산업현장이 구성되려면 작업자의 안전을 보장해야 하며 출동 가능성을 업애고 신뢰할수 있는 통신을 하는 협동로봇 가드 시스템의 개발의 필요성이 있다. 센서 및 컴퓨터 비전을 통해 협동로봇의 작업 반경내에서 발생하는 사고를 이중으로 방지하고 안전사고 위험을 감소시켜야 한다. 다양한 산업용 장비와 통신을 위한 국제프로토콜인 OPC UA를 기반으로 시스템을 구축하고 초음파 센서와 CNN(Convolution Neural Network)적용한 영상분석을 통한 협동로봇 가드 시스템을 제안한다. 제안 된 시스템은 작업자의 불안전한 상황에서 로봇 제어의 가능성을평가한다.","The robot is the creation of new markets and various cooperation according to the manufacturing paradigm shift. Cooperative management easy for existing industrial robots, robots work on productivity, manpower to replace the robot in every industry cooperation for the purpose of and demand increases.to exist But the industrial robot at the scene of the cooperation working due to accidents are frequent, threatening the safety of the operator. Of industrial site is configured with a robot in an environment ensuring the safety of the operator to and confidence to communicate that can do the possibility of action.Robot guard system of the need for development cooperation. The robot's cooperation through the sensors and computer vision task within a radius of the double to prevent accidents and accidents should reduce the risk. International protocol for a variety of industrial production equipment and communications opc ua system based on ultrasonic sensors and cnn to (Convolution Neural Network) for video analytics.We suggest the cooperation with the robot guard system. Robots in a proposed system is unsafe situation of workers evaluating the possibility of control."
A Comparative Study of Alzheimer’s Disease Classification using Multiple Transfer Learning Models,2019,"['Alzheimer’s disease', 'CNN', 'MR images', 'Transfer learning.']",국문 초록 정보 없음,"Over the past decade, researchers were able to solve complex medical problems as well as acquire deeper understanding of entire issue due to the availability of machine learning techniques, particularly predictive algorithms and automatic recognition of patterns in medical imaging. In this study, a technique called transfer learning has been utilized to classify Magnetic Resonance (MR) images by a pre-trained Convolutional Neural Network (CNN). Rather than training an entire model from scratch, transfer learning approach uses the CNN model by fine-tuning them, to classify MR images into Alzheimer’s disease (AD), mild cognitive impairment (MCI) and normal control (NC). The performance of this method has been evaluated over Alzheimer’s Disease Neuroimaging (ADNI) dataset by changing the learning rate of the model. Moreover, in this study, in order to demonstrate the transfer learning approach we utilize different pre-trained deep learning models such as GoogLeNet, VGG-16, AlexNet and ResNet-18, and compare their efficiency to classify AD. The overall classification accuracy resulted by GoogLeNet for training and testing was 99.84% and 98.25% respectively, which was exceptionally more than other models training and testing accuracies."
Deep convolutional neural network for the diagnosis of thyroid nodules on ultrasound,2019,"['convolutional neural network (CNN)', 'deep learning', 'thyroid cancer', 'thyroid nodule', 'ultrasound']",국문 초록 정보 없음,"<P><B>Abstract</B></P><P><B>Background</B></P><P>We designed a deep convolutional neural network (CNN) to diagnose thyroid malignancy on ultrasound (US) and compared the diagnostic performance of CNN with that of experienced radiologists.</P><P><B>Methods</B></P><P>Between May 2012 and February 2015, 589 thyroid nodules in 519 patients were diagnosed as benign or malignant by surgical excision. Experienced radiologists retrospectively reviewed the US of the thyroid nodules in a test set. CNNs were trained and tested using retrospective data of 439 and 150 US images, respectively. Diagnostic performances were compared between the two groups.</P><P><B>Results</B></P><P>Of the 589 thyroid nodules, 396 were malignant and 193 were benign. The area under the curve (AUC) for diagnosing thyroid malignancy was 0.805‐0.860 for radiologists. The AUCs for diagnosing thyroid malignancy for the three CNNs were 0.845, 0.835, and 0.850. There was no significant difference in AUC between radiologists and CNNs.</P><P><B>Conclusions</B></P><P>CNNs showed comparable diagnostic performance compared to experienced radiologists in differentiating thyroid malignancy on US.</P>"
앙상블 학습 알고리즘을 이용한 컨벌루션 신경망의 분류 성능 분석에 관한 연구,2019,"['Deep Learning', 'Computer Vision', 'CNN', 'Ensemble Learning Algorithm']",국문 초록 정보 없음,"In this paper, we compare and analyze the classification performance of deep learning algorithm Convolutional Neural Network(CNN) ac cording to ensemble generation and combining techniques. We used several CNN models(VGG16, VGG19, DenseNet121, DenseNet169, DenseNet201, ResNet18, ResNet34, ResNet50, ResNet101, ResNet152, GoogLeNet) to create 10 ensemble generation combinations and applied 6 combine techniques(average, weighted average, maximum, minimum, median, product) to the optimal combination. Experimental results, DenseNet169-VGG16-GoogLeNet combination in ensemble generation, and the product rule in ensemble combination showed the best performance. Based on this, it was concluded that ensemble in different models of high benchmarking scores is another way to get good results."
목적 지향 대화를 위한 효율적 질의 의도 분석에 관한 연구,2019,"['Intent-Analysing', 'Goal-oriented Dialogue', 'CNN(Convolutional Neural Network)', 'concept-sequence', 'speech-act']",국문 초록 정보 없음,"The purpose of this study is to understand the intention of the inquirer from the single text type question in Goal-oriented dialogue. Goal-Oriented Dialogue system means a dialogue system that satisfies the user’s specific needs via text or voice. The intention analysis process is a step of analysing the user’s intention of inquiry prior to the answer generation, and has a great influence on the performance of the entire Goal-Oriented Dialogue system. The proposed model was used for a daily chemical products domain and Korean text data related to the domain was used. The analysis is divided into a speech-act which means independent on a specific field concept-sequence and which means depend on a specific field. We propose a classification method using the word embedding model and the CNN as a method for analyzing speech-act and concept-sequence. The semantic information of the word is abstracted through the word embedding model, and concept-sequence and speech-act classification are performed through the CNN based on the semantic information of the abstract word."
Low-complexity 1D-convolutional Neural Network for Super Resolution,2019,"['Super-resolution', 'Deep-learning', 'Low-complexity', 'CNN']",국문 초록 정보 없음,"This paper proposes a method for accelerating deep learning based super-resolution technology. In order to alleviate the complexity of the deep learning based super-resolution technology, the proposed method extracts the horizontal and vertical high-frequency signals separately using one-dimensional filters. Then, the final super-resolution image is obtained by the proposed network from the horizontal and vertical high-frequency signals and the low-resolution input image. The proposed method requires a low computational complexity by using only onedimensional filters due to a smaller number of weights. The proposed method in the high-resolution image restoration experiment shows that the average visual quality in PSNR and SSIM is comparable to ones of VDSR. However, the average speed performance is accelerated by 86.57%."
MODIFIED CONVOLUTIONAL NEURAL NETWORK WITH TRANSFER LEARNING FOR SOLAR FLARE PREDICTION,2019,"['magnetic fields', 'Sun: activity', 'Sun: ares', 'techniques: image processing']",국문 초록 정보 없음,"We apply a modified Convolutional Neural Network (CNN) model in conjunction with transfer learning to predict whether an active region (AR) would produce a ≥C-class or ≥M-class are within the next 24 hours. We collect line-of-sight magnetogram samples of ARs provided by the SHARP from May 2010 to September 2018, which is a new data product from the HMI onboard the SDO. Based on these AR samples, we adopt the approach of shuffle-and-split cross-validation (CV) to build a database that includes 10 separate data sets. Each of the 10 data sets is segregated by NOAA AR number into a training and a testing data set. After training, validating, and testing our model, we compare the results with previous studies using predictive performance metrics, with a focus on the true skill statistic (TSS). The main results from this study are summarized as follows. First, to the best of our knowledge, this is the first time that the CNN model with transfer learning is used in solar physics to make binary class predictions for both ≥C-class and ≥M-class ares, without manually engineered features extracted from the observational data. Second, our model achieves relatively high scores of TSS = 0.6400.075 and TSS = 0.5260.052 for ≥M-class prediction and ≥C-class prediction, respectively, which is comparable to that of previous models. Third, our model also obtains quite good scores in five other metrics for both ≥C-class and ≥M-class are prediction. Our results demonstrate that our modified CNN model with transfer learning is an effective method for are forecasting with reasonable prediction performance."
딥러닝 모델 기반 단기 전력수요 예측,2019,"['Deep Learning', 'Short-Term Load Forecasting', 'CNN', 'LSTM']",국문 초록 정보 없음,"This paper presents a Short-Term Long-short term memory Convolutional neural network(STLC) Model that is combined with Convolutional Neural Network(CNN) and Long-Short Term Memory(LSTM). CNN model predicts load pattern using past load profile, LSTM model forecasts load variation depending on temperature and time index. STLC model’s output is hourly load data to combine two model’s outputs. The input parameters of STLC model are composed of time index, weighted weather data, past load data. Weights are calculated based on electricity consumption by main region in South Korea and reflects in the weather data. STLC model is trained with data from 2013 through 2017 and is verified with data from 2018. The STLC model forecasts 1-day hourly load data. Simulation results obtained show the comparison of actual and forecasted load data and also compare with other methods in MAPE(Mean Absolute Percentage Error) to prove accuracy of the proposed model."
Parkinson’s disease based on deep learning using MR images,2019,"['Parkinson’s Disease', 'Faster R-CNN', 'CNN', 'Deep Learning']",국문 초록 정보 없음,"Magnetic resonance imaging has become an indispensable aid in the Parkinson's disease. The traditional method of analysis is that the patient takes an MR image of the brain and then the doctor analyzes the MR image for diagnosis. However, due to the poor quality of MR images and the high noise, it is difficult for doctors to diagnose, and the professional requirements for doctors are relatively high when analyzing nuclear magnetic resonance images. This paper proposed a MR image classification algorithm based on deep learning. The algorithm is mainly divided into two phases. The first phase is to detect the diagnostic region of the MR image by the improved Faster RCNN network. The second phase is to classify the diagnostic areas detected in the previous phase through our custom CNN network. We tested the algorithm using MR images of Parkinson's disease. The experimental results show that the accuracy of MR image detection and classification can be greatly improved by algorithm improvement."
Deep Learning and Color Histogram based Fire and Smoke Detection Research,2019,"['Fire Detection', 'Deep Learning', 'Structure Similarity', 'Frame Difference. Color Histogram.']",국문 초록 정보 없음,"The fire should extinguish as soon as possible because it causes economic loss and loses precious life. In this study, we propose a new atypical fire and smoke detection algorithm using deep learning and color histogram of fire and smoke. First, input frame images obtain from the ONVIF surveillance camera mounted in factory search motion candidate frame by motion detection algorithm and mean square error (MSE). Second deep learning (Faster R-CNN) is used to extract the fire and smoke candidate area of motion frame. Third, we apply a novel algorithm to detect the fire and smoke using color histogram algorithm with local area motion, similarity, and MSE. In this study, we developed a novel fire and smoke detection algorithm applied the local motion and color histogram method. Experimental results show that the surveillance camera with the proposed algorithm showed good fire and smoke detection results with very few false positives."
지능형 관광 서비스를 위한 관광 사진 분류체계 개발,2019,"['플리커', 'SNS', '관광목적 사진 분류체계', '딥러닝', '합성곱신경망', '한국 관광', 'Flickr', 'Social Network Service', 'Photo Classification for Tourist purpose', 'Deep Learning', 'Convolutional Neural Network', 'Korea Tour']","최근 딥러닝 기술 가운데 이미지데이타 분석에 뛰어난 성능을 보이는 합성곱신경망 기술의 발전은 이미지 분석 영역에서다양한 가능성을 제시하고 있다. 관광객이 게시한 사진을 딥러닝 기술을 이용하여 분류하기 위해서는 관광사진에 대한 분류와목적에 맞는 딥러닝 모델의 훈련작업이 필수적으로 선행되어야 한다. 본 연구에서는 관광객이 플리커에 게시한 사진을 효율적으로분류하기 위해 관광목적으로 사진이 어떻게 분류되어야 하는지 관광목적 사진분류 체계를 개발하고자 하였다. 관광목적 사진분류 카테고리 개발을 위해 문헌분석, 웹사이트 분석, 관광객이 게시한 약 38,000장 사진의 검토과정을 거쳐 사진 분류 카테고리를개발하였으며, 약 8400장의 사진을 개발된 카테고리에 맞춰 분류해 봄으로써 개발된 카테고리의 검증과정을 거쳤다. 이 과정을거쳐 최종으로 제안된 카테고리는 13개 대분류, 64개 중분류, 164개의 세분류 체계를 갖으며, 본 연구 결과는 향후 관광목적사진을 딥러닝 모델을 이용하여 분류하고자 할 때 기초자료로 활용될 것으로 기대된다.","In recent years technology of Convolutional Neural Network (CNN) among the technologies of deep learning has evolved dramatically and has shown an outstanding performance in the analysis of image data. First of all, the training of deep learning model is prerequisite to classify the photos posted by the tourists on Web by applying CNN technology. In this study we aim to develop the photo classification system in view of travel purpose in order to classify the photos posted by tourists on Flickr. We developed the category for photo classification by reviewing around 38,000 photos posted by tourists as well as by analysing literatures and web sites, and then verified the category by classifying 8,400 photos one by one manually according to the category developed. The category we developed has 3 hierarchical levels such as 13 major classification, 64 medium classification and 164 minor classification. We expect that our study can applied in base material when one tries to classify the photos for travel purpose by using the CNN deep learning model."
Forest Classification Method Based on Convolutional Neural Networks and Sentinel-2 Satellite Imagery,2019,"['Forest classification', 'Contextual information', 'Satellite imagery', 'Sentinel-2', 'Convolutional Neural Network']",국문 초록 정보 없음,"The objective of this study is to develop a classification method based on convolutional neural network (CNN) and Sentinel-2 satellite imagery including the spectral feature, spectral index and spatial feature together as an input to answer forest monitoring problem. This research also used contextual information on Indonesia National Standard Agency’s document for Land cover classification as a baseline for feature extraction to get the appropriate classifier feature. The test set was located in Semarang, Central Java, Indonesia. The research workflow consists of defining forest class based on Indonesia National Standard Agency for Land cover classification, extracting optical image features based on contextual information of the forest class definition, extracting image features from the Sentinel-2 satellite image, and classifying image object features using CNN classifier. Image segmentation produced 1,211 segments/objects by using eCognition software. Subsequently, these objects were used as a dataset. Overall accuracy was used to evaluate the performance of the classification result. The result showed the classification method results in this study yielded high overall accuracy (97.66%) when using CNN with the image features like NDVI, Brightness, GLCM homogeneity and Rectangular fit. Small improvement of overall accuracy was also achieved when it was compared to GBT with an overall accuracy of 95.50%."
딥러닝을 이용한 자동화된 콘크리트 균열 탐지 기술,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝을 이용한 판류형 간판의 인식,2019,"['Signboard Detection', 'Flat Type', 'Faster Region-Based Convolutional Neural Network', 'Watershed', 'K-Means Clustering', 'Boundary Area', '간판 인식', '판류형', 'Faster R-CNN', '워터쉐드', 'K-평균 군집화', '경계 영역']","간판은 유형마다 간판의 규격이 정해져 있으나 실제 설치된 간판은 형태와 크기가 일정하지 않다. 또한, 간판은 간판 내부의 색상에 대한 규정이 정해져 있지 않기 때문에 다양한 색상을 갖고 있다. 간판을 인식하기 위한 방법은 도로표지판과 차량번호판을 인식하는 유사한 방법으로 생각할 수 있으나 간판의 특성으로 인해 도로표지판과 차량번호판과 유사한 방법으로 간판을 인식할 수 없는 한계점이 있다. 이에 본 연구에서는 딥러닝 기반의 Faster R-CNN 알고리즘을 이용하여 불법 및 노후 간판의 주요 대상이 되는 판류형 간판을 인식하고 간판의 영역을 자동으로 추출하는 방법론을 제안하였다. 스마트폰 카메라를 이용하여 촬영한 간판 영상을 통해 판류형 간판을 인식하는 과정은 2가지의 순서로 나뉜다. 먼저, 다양한 유형의 간판 영상에서 판류형 간판을 인식하기 위해 딥러닝을 이용하여 간판의 유형을 인식하였으며 그 결과는 약 71%의 정확도로 나타났다. 다음으로 판류형 간판의 경계영역을 인식하기 위해 간판 영역 인식 알고리즘을 적용하였을 때 85%의 정확도로 판류형 간판의 경계영역을 인식하였다.","The specifications of signboards are set for each type of signboards, but the shape and size of the signboard actually installed are not uniform. In addition, because the colors of the signboard are not defined, so various colors are applied to the signboard. Methods for recognizing signboards can be thought of as similar methods of recognizing road signs and license plates, but due to the nature of the signboards, there are limitations in that the signboards can not be recognized in a way similar to road signs and license plates. In this study, we proposed a methodology for recognizing plate-type signboards, which are the main targets of illegal and old signboards, and automatically extracting areas of signboards, using the deep learning-based Faster R-CNN algorithm. The process of recognizing flat type signboards through signboard images captured by using smartphone cameras is divided into two sequences. First, the type of signboard was recognized using deep learning to recognize flat type signboards in various types of signboard images, and the result showed an accuracy of about 71%. Next, when the boundary recognition algorithm for the signboards was applied to recognize the boundary area of the flat type signboard, the boundary of flat type signboard was recognized with an accuracy of 85%."
콘볼루션 신경회로망을 이용한 능동펄스 식별 알고리즘,2019,[],국문 초록 정보 없음,"In this paper, we propose an algorithm to classify the received active pulse when the active sonar system is operated as a non-cooperative mode. The proposed algorithm uses CNN (Convolutional Neural Networks) which shows good performance in various fields. As an input of CNN, time frequency analysis data which performs STFT (Short Time Fourier Transform) of the received signal is used. The CNN used in this paper consists of two convolution and pulling layers. We designed a database based neural network and a pulse feature based neural network according to the output layer design. To verify the performance of the algorithm, the data of 3110 CW (Continuous Wave) pulses and LFM (Linear Frequency Modulated) pulses received from the actual ocean were processed to construct training data and test data. As a result of simulation, the database based neural network showed 99.9 % accuracy and the feature based neural network showed about 96 % accuracy when allowing 2 pixel error."
Multi-channel과 Densely Connected Convolution Networks을 이용한 한국어 감성분석,2019,"['한국어 감성분석', 'Korean Sentiment Analysis', 'Multi-channel DenseNet', 'Text Classification', 'DenseNet']","본 논문은 한국어 문장의 감성 분류를 위해 문장의 형태소, 음절, 자소를 입력으로 하는 합성곱층과 DenseNet 을 적용한 Text Multi-channel DenseNet 모델을 제안한다. 맞춤법 오류, 음소나 음절의 축약과 탈락, 은어나 비속어의 남용, 의태어 사용 등 문법적 규칙에 어긋나는 다양한 표현으로 인해 단어 기반 CNN 으로 추출 할 수 없는 특징들을 음절이나 자소에서 추출 할 수 있다. 한국어 감성분석에 형태소 기반 CNN 이 많이 쓰이고 있으나, 본 논문에서 제안한 Text Multi-channel DenseNet 모델은 형태소, 음절, 자소를 동시에 고려하고, DenseNet 에 정보를 밀집 전달하여 문장의 감성 분류의 정확도를 개선하였다. 네이버 영화 리뷰 데이터를 대상으로 실험한 결과 제안 모델은 85.96%의 정확도를 보여 Multi-channel CNN 에 비해 1.45% 더 정확하게 문장의 감성을 분류하였다.",다국어 초록 정보 없음
Introduction to convolutional neural network using Keras; an understanding from a statistician,2019,"['deep neural network', 'convolutional neural network', 'image classification', 'machine learning', 'MNIST', 'CIFAR10', 'Keras']",국문 초록 정보 없음,"Deep Learning is one of the machine learning methods to find features from a huge data using non-linear transformation. It is now commonly used for supervised learning in many fields. In particular, Convolutional Neural Network (CNN) is the best technique for the image classification since 2012. For users who consider deep learning models for real-world applications, Keras is a popular API for neural networks written in Python and also can be used in R. We try examine the parameter estimation procedures of Deep Neural Network and structures of CNN models from basics to advanced techniques. We also try to figure out some crucial steps in CNN that can improve image classification performance in the CIFAR10 dataset using Keras. We found that several stacks of convolutional layers and batch normalization could improve prediction performance. We also compared image classification performances with other machine learning methods, including K-Nearest Neighbors (K-NN), Random Forest, and XGBoost, in both MNIST and CIFAR10 dataset."
Improvement of fully automated airway segmentation on volumetric computed tomographic images using a 2.5 dimensional convolutional neural net,2019,"['Airway', 'Artificial intelligence', 'Convolutional neural net', 'Deep learning', 'Machine learning', 'Segmentation']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>We propose a novel airway segmentation method in volumetric chest computed tomography (CT) and evaluate its performance on multiple datasets. The segmentation is performed voxel-by-voxel by a 2.5D convolutional neural net (2.5D CNN) trained in a supervised manner. To enhance the accuracy of the segmented airway tree, we simultaneously took three adjacent slices in each of the orthogonal directions including axial, sagittal, and coronal and fine-tuned the parameters that influence the tree length and the number of leakage. The gold standard of airway segmentation was generated by a semi-automated method using AVIEW™. The 2.5D CNN was trained and evaluated on a subset of inspiratory thoracic CT scans taken from the Korean obstructive lung disease study, which includes normal subjects and chronic obstructive pulmonary disease patients. The reliability and further practicality of our proposed method was demonstrated in multiple datasets. In eight test datasets collected by the same imaging protocol, the percentage detected tree length, false positive rate, and Dice similarity coefficient of our method were 92.16%, 7.74%, and 0.8997 ± 0.0892, respectively. In 20 test datasets of the EXACT’09 challenge, the percentage detected tree length was 60.1% and the false positive rate was 4.56%. Our fully automated (end-to-end) segmentation method could be applied in radiologic practice.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  A novel airway segmentation method using 2.5D CNN is proposed. </LI> <LI>  The 2.5D patches capture the 3D appearance of the airway efficiently. </LI> <LI>  Iterative optimization by probability-based patching improves the performance. </LI> <LI>  Validation on multiple dataset shows the reliability and practicality of our method. </LI> <LI>  Our end-to-end segmentation method is feasible in radiologic practice. </LI> </UL> </P>   <P><B>Graphical abstract</B></P>   <P>[DISPLAY OMISSION]</P>"
컨볼루션 신경망 기반 유해 네트워크 트래픽 탐지 기법평가,2019,"['Convolutional Neural Network', 'Traffic Classification', 'Image Transform', 'Configuration']","최근 유해 네트워크 트래픽을 탐지하기 위해 머신러닝 기법을 활용하는 다양한 방법론들이 주목을 받고 있다. 이 논문에서는 컨볼루션 신경망 (Convolutioanl Neural Network)을 기반으로 유해 네트워크 트래픽을 분류하는 기법을 소개하고 그 성능을 평가한다. 이미지 처리에 강한 컨볼루션 신경망의 활용을 위해, 네트워크 트래픽의 주요 정보를 규격화된 이미지로 변환하는 방법을 제안하고, 변환된 이미지를 입력으로 컨볼루션 신경망을 학습시켜 유해 네트워크 트래픽의 분류를 수행하도록 한다. 실제 네트워크 트래픽 관련 데이터셋을 활용하여 이미지 변환 및 컨볼루션 신경망 기반 네트워크 트래픽 분류 기법의 성능을 검증하였다. 특히, 다양한 컨볼루션 신경망 기반 네트워크 모델 구성에 따른 트래픽 분류 기법의 성능을 평가하였다.","Recently, various machine learning based traffic classification methods are focused on detecting malicious network traffic. In this paper, convolutional neural network based malicious network traffic classification method is introduced and its performance is evaluated. In order to utilize the convolutional neural network which is excellent in analyzing images, a image transform method from important information of network traffic to a standardized image is proposed, and the transformed images are used as learning input of a CNN network traffic classifier. By using the real network traffic dataset, the proposed image transform method and CNN based network traffic classification method are evaluated. Especially, under various configurations of CNN, the performance of the proposed method is evaluated."
< 전시-P-05 > k-Nearest Neighbor와 합성곱신경망에 의한 국산 침엽수재 표면의 옹이 종류 분류,2019,[],"목재를 용도에 맞게 효율적으로 이용하기 위해서는 강도와 심미적 기능에 영향을 주는 옹이의 종류를 정확하게 분류할 필요가 있다. 통상적으로 널리 이용되고 있는 육안등급구분은 주변 환경에 쉽게 영향을 받을 수 있기 때문에 목재 품질의 객관적 평가 및 목재 생산의 고속화를 위해서는 컴퓨터 비전을 활용한 화상분석 자동화가 필요하다. 본 연구에서는 SIFT(Scale-Invariant Feature Transform) +k-NN(k-Nearest Neighbor)모델과 CNN(Convolutional Neural Network)모델을 통해 옹이의 종류를 분류하고 그 정확도를 평가하였다. 실험에 사용한 수종은 다섯 가지 국산 침엽수종으로 낙엽송, 소나무, 잣나무, 삼나무, 편백이었다. 제재목 표면에서 4가지 형태(sound, encased, decayed, spike)의 옹이 이미지 1,172개를 획득하여 각 모델에서의 학습 및 검증에 사용하였다. SIFT+k-NN 모델의 경우, SIFT 기술을 이용하여 옹이 이미지에서 특성을 추출한 뒤, k-NN을 이용하여 분류를 실시하였으며, 최대 60.53%의 정확도로 분류가 가능하였다. CNN 모델의 경우, 8층의 convolution layer와 3층의 hidden layer로 구성되어있는 모델을 사용하였으며 최대 88.09%로 옹이 분류가 가능하였다. 또한 CNN 모델은 옹이 종류별 이미지의 개수 차이가 큰 경우에도 특성 추출의 편향이 심하지 않아 옹이 분류에 있어 더 높은 정확도를 보였다.",다국어 초록 정보 없음
소프트맥스를 이용한 딥러닝 음악장르 자동구분 투표 시스템,2019,[],국문 초록 정보 없음,"Research that implements the classification process through Deep Learning algorithm, one of the outstanding human abilities, includes a unimodal model, a multi-modal model, and a multi-modal method using music videos. In this study, the results were better by suggesting a system to analyze each song's spectrum into short samples and vote for the results. Among Deep Learning algorithms, CNN showed superior performance in the category of music genre compared to RNN, and improved performance when CNN and RNN were applied together. The system of voting for each CNN result by Deep Learning a short sample of music showed better results than the previous model and the model with Softmax layer added to the model performed best. The need for the explosive growth of digital media and the automatic classification of music genres in numerous streaming services is increasing. Future research will need to reduce the proportion of undifferentiated songs and develop algorithms for the last category classification of undivided songs."
알약 자동 인식을 위한 딥러닝 모델간 비교 및 검증,2019,"['Pill Classification', 'Object Detection', 'Deep Learning', 'Artificial Intelligent', 'Hospital']",국문 초록 정보 없음,"When a prescription change occurs in the hospital depending on a patient’s improvement status, pharmacists directly classify manually returned pills which are not taken by a patient. There are hundreds of kinds of pills to classify. Because it is manual, mistakes can occur and which can lead to medical accidents. In this study, we have compared YOLO, Faster R-CNN and RetinaNet to classify and detect pills. The data consisted of 10 classes and used 100 images per class. To evaluate the performance of each model, we used cross-validation. As a result, the YOLO Model had sensitivity of 91.05%, FPs/image of 0.0507. The Faster R-CNN’s sensitivity was 99.6% and FPs/image was 0.0089. The RetinaNet showed sensitivity of 98.31% and FPs/image of 0.0119. Faster RCNN showed the best performance among these three models tested. Thus, the most appropriate model for classifying pills among the three models is the Faster R-CNN with the most accurate detection and classification results and a low FP/image."
Enhancer prediction with histone modification marks using a hybrid neural network model,2019,"['Enhancer', 'Convolutional neural network', 'Recurrent neural network', 'Histone modification mark']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>Enhancer is a DNA sequence of a genome that controls transcription of downstream target genes. Enhancers are known to be associated with certain epigenetic signatures. Machine learning tools, such as CSI-ANN, ChromHMM, and RFECS, were developed for predicting enhancers using various epigenetic features. However, predictions by different tools vary widely and quite a significant portion of enhancer predictions does not agree. Thus, computational methods for enhancer prediction should be further developed. In this paper, a hybrid neural network called Enhancer-CRNN, a convolutional neural network (CNN) followed by a recurrent neural network (RNN), was developed and they were used to predict enhancer regions with histone modification marks as input. The CNN in our model is to reflect local characteristics and the RNN is to learn sequential dependencies among the histone marks. Hybridization of both neural networks outperformed existing prediction tools in experiments with GM12878, H1hesc, HeLaS3, and HepG2 cell lines. On average, 13–17 percent of the enhancers predicted by our method were cell type-specific. With the trained model, optimized virtual input histone marks was generated to provide a deeper insight into how histone modification marks can represent enhancer regions in which histone marks indicate active or repressed enhancers. In summary, our model produced accurate annotation of enhancers with detailed information on how histone profiles contribute to the presence of putative enhancers.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  A hybrid model to predict enhancers is suggested by combining CNN and RNN. </LI> <LI>  This model uses only histone modification data as an input. </LI> <LI>  Our approach achieved improved recall compared to previous methods. </LI> <LI>  Optimized input histone data is suggested for ideal identification of an enhancer. </LI> </UL> </P>"
비주얼 서보잉을 위한 딥러닝 기반 물체 인식 및 자세 추정,2019,"['Object Detection', 'Object Recognition', 'Deep Learning', 'Line Detection', 'Hough Transform', 'Perspective-Transform', 'Pose Estimation']",국문 초록 정보 없음,"Recently, smart factories have attracted much attention as a result of the 4th Industrial Revolution. Existing factory automation technologies are generally designed for simple repetition without using vision sensors. Even small object assemblies are still dependent on manual work. To satisfy the needs for replacing the existing system with new technology such as bin picking and visual servoing, precision and real-time application should be core. Therefore in our work we focused on the core elements by using deep learning algorithm to detect and classify the target object for real-time and analyzing the object features. We chose YOLO CNN which is capable of real-time working and combining the two tasks as mentioned above though there are lots of good deep learning algorithms such as Mask R-CNN and Fast R-CNN. Then through the line and inside features extracted from target object, we can obtain final outline and estimate object posture."
An application of convolutional neural networks with salient features for relation classification,2019,"['Convolutional neural networks', 'Biomedical data analysis', 'Relation classification', 'Hyperparameter optimization', 'Deep learning']",국문 초록 정보 없음,"<P><B>Background</B></P><P>Due to the advent of deep learning, the increasing number of studies in the biomedical domain has attracted much interest in feature extraction and classification tasks. In this research, we seek the best combination of feature set and hyperparameter setting of deep learning algorithms for relation classification. To this end, we incorporate an entity and relation extraction tool, PKDE4J to extract biomedical features (i.e., biomedical entities, relations) for the relation classification. We compared the chosen Convolutional Neural Networks (CNN) based classification model with the most widely used learning algorithms.</P><P><B>Results</B></P><P>Our CNN based classification model outperforms the most widely used supervised algorithms. We achieved a significant performance on binary classification with a weighted macro-average F1-score: 94.79% using pre-extracted relevant feature combinations. For multi-class classification, the weighted macro-average F1-score is estimated around 86.95%.</P><P><B>Conclusions</B></P><P>Our results suggest that our proposed CNN based model using the not only single feature as the raw text of the sentences of biomedical literature, but also coupling with multiple and highlighted features extracted from the biomedical sentences could improve the classification performance significantly. We offer hyperparameter tuning and optimization approaches for our proposed model to obtain optimal hyperparameters of the models with the best performance.</P>"
딥러닝을 활용한 상실치아 수 예측의 가능성: 파일럿 스터디,2019,"['Deep learning', 'Linear regression', 'Missing teeth', 'Real-time PCR', 'Periodontitis']",국문 초록 정보 없음,"Objectives: The primary objective of this study was to determine if the number of missing teeth could be predicted by oral disease pathogens, and the secondary objective was to assess whether deep learning is a better way of predicting the number of missing teeth than multivariable linear regression (MLR).Methods: Data were collected through review of patient’s initial medical records. A total of 960 participants were cross-sectionally surveyed. MLR analysis was performed to assess the relationship between the number of missing teeth and the results of real-time PCR assay (done for quantification of 11 oral disease pathogens). A convolutional neural network (CNN) was used as the deep learning model and compared with MLR models. Each model was performed five times to generate an average accuracy rate and mean square error (MSE). The accuracy of predicting the number of missing teeth was evaluated and compared between the CNN and MLR methods.Results: Model 1 had the demographic information necessary for the prediction of periodontal diseases in addition to the red and the orange complex bacteria that are highly predominant in oral diseases. The accuracy of the convolutional neural network in this model was 65.0%. However, applying Model 4, which added yellow complex bacteria to the total bacterial load, increased the expected extractions of dental caries to 70.2%.On the other hand, the accuracy of the MLR was about 50.0% in all models. The mean square error of the CNN was considerably smaller than that of the MLR, resulting in better predictability.Conclusions: Oral disease pathogens can be used as a predictor of missing teeth and deep learning can be a more accurate analysis method to predict the number of missing teeth as compared to MLR."
Detection of construction workers under varying poses and changing background in image sequences via very deep residual networks,2019,"['Construction worker detection', 'Deep learning', 'Two-stage approach', 'Very deep residual networks']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>Analyzing the location and behavior of construction workers using construction site images has been recognized as a means of providing useful information for safety management and productivity analysis. Although effective utilization of analyzed image data requires accurate and timely detection of workers in complex, continuously changing working environments, the previous methods that detect construction workers still require improvement because of the poor detection performance. This study proposes the use of very deep residual networks to accurately and rapidly detect construction workers under varying poses and against changing backgrounds in image sequences. The architecture of construction worker detection in this study is based on convolutional neural networks (CNNs). The proposed method is divided into two stages: extracting feature maps via very deep residual networks (ResNet-152) and bounding box regression and labeling from the original image via Faster regions with CNN features (R-CNN). The experiments were conducted at actual construction sites by acquiring 1.3-megapixel and 3.1-megapixel images from a movable digital camera to verify the proposed method for images from fixed and moving cameras. Faster R-CNN with ResNet-152 had accuracy, precision, and recall rates of 94.3%, 96.03%, and 98.13% for 3241 images, respectively. The proposed method processed 0.2 s per frame (i.e., 5 frames per second) on average. The results show that it is possible to accurately and rapidly detect multiple workers in construction site images by employing very deep residual networks without relying on limited assumptions about workers' postures, appearance, and background.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  This study integrated a very deep residual network-152 for detecting construction workers. </LI> <LI>  3241 construction site images used for validation in varying poses and changing backgrounds </LI> <LI>  Accuracy, precision, and recall were 94.3%, 96.03%, and 98.13%, respectively, at 5 fps. </LI> <LI>  Possible to accurately detect workers without assumptions about posture or the background </LI> <LI>  Improved in terms of reliability performance compared with the most recent studies for this purpose </LI> </UL> </P>"
스마트폰 다종 데이터를 활용한 딥러닝 기반의 사용자 동행 상태 인식,2019,"['사용자 행동 인식', '그룹 상호작용', '스마트폰 물리 센서', '컨볼루션 신경망', '장단기 기억 순환 신경망', 'human activity recognition', 'group interaction', 'smartphone multimodal sensors', 'convolutional neural network', 'long short-term memory recurrent network']","스마트폰이 널리 보급되고 현대인들의 생활 속에 깊이 자리 잡으면서, 스마트폰에서 수집된 다종 데이터를바탕으로 사용자 개인의 행동을 인식하고자 하는 연구가 활발히 진행되고 있다. 그러나 타인과의 상호작용 행동 인식에 대한 연구는 아직까지 상대적으로 미진하였다. 기존 상호작용 행동 인식 연구에서는 오디오, 블루투스, 와이파이 등의 데이터를 사용하였으나, 이들은 사용자 사생활 침해 가능성이 높으며 단시간 내에 충분한 양의 데이터를 수집하기 어렵다는 한계가 있다. 반면 가속도, 자기장, 자이로스코프 등의 물리 센서의 경우 사생활 침해 가능성이 낮으며 단시간 내에 충분한 양의 데이터를 수집할 수 있다. 본 연구에서는 이러한 점에 주목하여, 스마트폰 상의 다종 물리 센서 데이터만을 활용, 딥러닝 모델에 기반을 둔 사용자의 동행 상태 인식 방법론을 제안한다. 사용자의 동행 여부 및 대화 여부를 분류하는 동행 상태 분류 모델은 컨볼루션 신경망과 장단기기억 순환 신경망이 혼합된 구조를 지닌다. 먼저 스마트폰의 다종 물리 센서에서 수집한 데이터에 존재하는 타임 스태프의 차이를 상쇄하고, 정규화를 수행하여 시간에 따른 시퀀스 데이터 형태로 변환함으로써 동행 상태분류 모델의 입력 데이터를 생성한다. 이는 컨볼루션 신경망에 입력되며, 데이터의 시간적 국부 의존성이 반영된 요인 지도를 출력한다. 장단기 기억 순환 신경망은 요인 지도를 입력받아 시간에 따른 순차적 연관 관계를학습하며, 동행 상태 분류를 위한 요인을 추출하고 소프트맥스 분류기에서 이에 기반한 최종적인 분류를 수행한다. 자체 제작한 스마트폰 애플리케이션을 배포하여 실험 데이터를 수집하였으며, 이를 활용하여 제안한 방법론을 평가하였다. 최적의 파라미터를 설정하여 동행 상태 분류 모델을 학습하고 평가한 결과, 동행 여부와 대화 여부를 각각 98.74%, 98.83%의 높은 정확도로 분류하였다.","As smartphones are getting widely used, human activity recognition (HAR) tasks for recognizing personal activities of smartphone users with multimodal data have been actively studied recently. The research area is expanding from the recognition of the simple body movement of an individual user to the recognition of low-level behavior and high-level behavior. However, HAR tasks for recognizing interaction behavior with other people, such as whether the user is accompanying or communicating with someone else, have gotten less attention so far. And previous research for recognizing interaction behavior has usually depended on audio, Bluetooth, and Wi-Fi sensors, which are vulnerable to privacy issues and require much time to collect enough data. Whereas physical sensors including accelerometer, magnetic field and gyroscope sensors are less vulnerable to privacy issues and can collect a large amount of data within a short time. In this paper, a method for detecting accompanying status based on deep learning model by only using multimodal physical sensor data, such as an accelerometer, magnetic field and gyroscope, was proposed. The accompanying status was defined as a redefinition of a part of the user interaction behavior, including whether the user is accompanying with an acquaintance at a close distance and the user is actively communicating with the acquaintance. A framework based on convolutional neural networks (CNN) and long short-term memory (LSTM) recurrent networks for classifying accompanying and conversation was proposed.First, a data preprocessing method which consists of time synchronization of multimodal data fromdifferent physical sensors, data normalization and sequence data generation was introduced. We applied the nearest interpolation to synchronize the time of collected data from different sensors. Normalization was performed for each x, y, z axis value of the sensor data, and the sequence data was generated according to the sliding window method. Then, the sequence data became the input for CNN, where feature maps representing local dependencies of the original sequence are extracted. The CNN consisted of 3 convolutional layers and did not have a pooling layer to maintain the temporal information of the sequence data. Next, LSTM recurrent networks received the feature maps, learned long-term dependencies from them and extracted features. The LSTM recurrent networks consisted of two layers, each with 128 cells. Finally, the extracted features were used for classification by softmax classifier. The loss function of the model was cross entropy function and the weights of the model were randomly initialized on a normal distribution with an average of 0 and a standard deviation of 0.1. The model was trained using adaptive moment estimation (ADAM) optimization algorithm and the mini batch size was set to 128. We applied dropout to input values of the LSTM recurrent networks to prevent overfitting. The initial learning rate was set to 0.001, and it decreased exponentially by 0.99 at the end of each epoch training.An Android smartphone application was developed and released to collect data. We collected smartphone data for a total of 18 subjects. Using the data, the model classified accompanying and conversation by 98.74% and 98.83% accuracy each. Both the F1 score and accuracy of the model were higher than the F1 score and accuracy of the majority vote classifier, support vector machine, and deep recurrent neural network. In the future research, we will focus on more rigorous multimodal sensor data synchronization methods that minimize the time stamp differences. In addition, we will further study transfer learning method that enables transfer of trained models tailored to the training data to the evaluation data that follows a different distribution. It is expected that a model capable of exhibiting robust recognition performance against changes in data that is not considered in the model learning stage wil..."
딥러닝을 통한 차등간격의 조향각 노드 결정에 의한 자율주행,2019,"['CNN (convolution neural network)', 'non-uniform steering angle intervals', 'autonomous driving', 'deep learning']",국문 초록 정보 없음,"In this work, an autonomous driving model using only one camera was implemented by combining a CNN (ConvolutionalNeural networks) and a YOLO (You Only Look Once) framework. Hyper-parameters in the structure were adjusted to improve drivingperformance. Autonomous driving in a corridor was performed by applying the improved model. An appropriate dropout and deeplearning structure associated with non-uniform steering angle intervals as output is proposed. The proposed algorithm was implemented,and through experiments resulted in successful obstacle avoidance and stable driving."
Best Practices on Educational Service Platform with AI Approach,2019,"['CNN Algorithm', 'Education', 'Recommendation', 'User Focused.']",국문 초록 정보 없음,"The current education is becoming more extensive with the application of various teaching methods. This is a problem that is so distributed that it is difficult for users to find the data and it takes a long time to find the information they need. Currently, various educational services, materials, and instruments are developed and scattered. Therefore, it is important to raise students' awareness of aptitude and career path with customized education tailored to students. Conventional education platforms have very difficult to choose the right materials for students because of the spread of educational programs and institution materials.To solve this, we propose a customized recommendation approach to recommend customized educational service materials and institution for students to teachers, which helps teachers conveniently choose materials suitable for their respective environments. On this new platform, the CNN algorithm provides recommended content for classes and students. For real service on the educational service platform, we implement this system for Jeil edus business . Through this mechanism, we expect to improve the quality of education by helping to select the right service."
Best Practices on Educational Service Platform with AI Approach,2019,"['CNN Algorithm', 'Education', 'Recommendation', 'User Focused']",국문 초록 정보 없음,"The current education is becoming more extensive with the application of various teaching methods. This is a problem that is so distributed that it is difficult for users to find the data and it takes a long time to find the information they need. Currently, various educational services, materials, and instruments are developed and scattered. Therefore, it is important to raise students' awareness of aptitude and career path with customized education tailored to students. Conventional education platforms have very difficult to choose the right materials for students because of the spread of educational programs and institution materials. To solve this, we propose a customized recommendation approach to recommend customized educational service materials and institution for students to teachers, which helps teachers conveniently choose materials suitable for their respective environments. On this new platform, the CNN algorithm provides recommended content for classes and students. For real service on the educational service platform, we implement this system for Jeil edus business. Through this mechanism, we expect to improve the quality of education by helping to select the right service."
기상위성을 이용한 태양광발전 일사량 예측,2019,"['Python', 'CNN(Convolutional Neural Network)', 'Deep Learning Technique', 'Solar power generation']",국문 초록 정보 없음,"Recently, due to the depletion of fossil fuel resources and the regulation of CO2 emissions, attention and demand for solar power generation are increasing. The solar power generation has begun to be applied to small-scale power generation, and recently, large- scale power plants have been built and sold to utility companies or power demand has been supplied to cities. In addition, facilities for microgrid for energy self-reliance through renewable energy such as solar power, wind power, and tidal power are being constructed and studied in places where electricity supply is difficult, such as island or inland countryside. The solar power generation is advantageous in that it has no pollution, is easy to maintain, and has a long life. However, the power generation depends on the weather, the installation site is limited, and the initial investment cost and the power generation cost are high. Particularly, since it depends on the weather condition, the generation amount is very intermittent and it is difficult to adjust the power generation amount, and it is difficult to establish a power generation plan in advance. Therefore, high accuracy solar power generation forecasting is essential to reduce the uncertainty of solar power generation and to improve the economical efficiency of solar power generation. Existing solar power generation forecasting has been conducted to predict power generation using Extreme Learning Machine (ELM), Support Vector Regression (SVR), and neural network. However, in this paper, we forecast the solar power generation using the meteorological satellite data from 2011 to 2017 and forecasting method using the CNN (Convolutional Neural Network) which is one of the deep running algorithms. And the feasibility of the proposed method was verified using the meteorological satellite data in 2018. For the forecasting program, we programmed using Python, which is specialized for deep running."
인공지능 기반의 울음소리를 이용한 영아 상태 인식,2019,"['infant', 'spectrogram', 'CNN', 'sound classification', 'emotion recognition']",국문 초록 정보 없음,"Babies in infancy communicate most by crying. Since it is a critical period in the brain development stage, a lot of effort is needed to understand the desire of the baby correctly. In this study, we introduce the analysis of research on babys crying and patterns, and how to classify them using artificial intelligence. The sound source consists of the baby’s crying sample from the existing research, and the pattern is stored and classified. It is transformed into spectrogram image data, visualized, analyzed and preprocessed, and used as learning data for CNN model. This study presents how to implement a system that classify baby’s crying with comparatively higher accuracy than existing research that uses patterns from the average of frequency measurements. If much more input data is verified by experts in the near future, it can be commercialized easily and immediately."
딥 러닝과 데이터 결합에 의한 싱크홀 트래킹,2019,"['sinkhole tracking', 'CNN transfer learning', 'data association', 'Hungarian Algorithm', 'Otsu algorithm']",국문 초록 정보 없음,"Accurate tracking of the sinkholes that are appearing frequently now is an important method of protecting human and property damage. Although many sinkhole detection systems have been proposed, it is still far from completely solved especially in-depth area. Furthermore, detection of sinkhole algorithms experienced the problem of unstable result that makes the system difficult to fire a warning in real-time. In this paper, we proposed a method of sinkhole tracking by deep learning and data association, that takes advantage of the recent development of CNN transfer learning. Our system consists of three main parts which are binary segmentation, sinkhole classification, and sinkhole tracking. The experiment results show that the sinkhole can be tracked in real-time on the dataset. These achievements have proven that the proposed system is able to apply to the practical application."
Prediction of partially observed human activity based on pre-trained deep representation,2019,"['Pre-trained CNN', 'Human activity prediction', 'Human interaction', 'Sub-volume co-occurrence matrix']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>Prediction of complex human activities from a partially observed video is valuable in many practical applications but is a challenging problem. When a video is partially observed, maximizing the representational power of the given video is more important than modeling the temporal dynamics of the activity. In this paper, we propose a novel human activity descriptor for prediction, which can maximize the discriminative power of a system in a compact and efficient way using pre-trained deep networks. Specifically, the proposed descriptor can capture the potentially important pairwise relationships between objects without prior knowledge or preset attributes. The relationship information is automatically reflected during the descriptor construction procedure based on object’s participation ratios, local and global motion activations. Pre-trained Convolutional Neural Networks are utilized without additional model training procedure. From a practical point of view, the proposed method is more cost-effective when implementing a smart surveillance system. In the experiments, we evaluate the proposed methods in two cases: (1) prediction accuracy with different observation ratios, and (2) the effect of pre-trained network and layer selection. Experimental results from five public datasets verified the efficacy of the proposed method by outperforming competing methods with stable high-performance regardless of network selection.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  We propose a novel ongoing human activity descriptor for video class prediction. </LI> <LI>  The proposed method automatically captures the potentially important relationships. </LI> <LI>  We utilize pre-trained CNN without additional network training for cost-efficiency. </LI> </UL> </P>"
결합 신경망을 이용한 여권 MRZ 정보 인식,2019,"['Passport Recognition', 'MRZ Information', 'CNN', 'Identity Information Recognition']",국문 초록 정보 없음,"In case of reading passport using a smart phone in contrast with a dedicated passport reading system, MRZ(Machine Readable Zone) character recognition can be hard when the character strokes were broken, touched or blurred according to the lighting condition, and the position and size of MRZ character lines were varied due to the camera distance and angle. In this paper, the effective recognition algorithm of the passport MRZ information using a combined neural network recognizer of CNN(Convolutional Neural Network) and ANN( Artificial Neural Network), is proposed under the various sized and skewed passport images. The MRZ line detection using connected component analysis algorithm and the skew correction using perspective transform algorithm are also designed in order to achieve effective character segmentation results. Each of the MRZ field recognition results is verified by using five check digits for deciding whether retrying the recognition process of passport MRZ information or not. After we implement the proposed recognition algorithm of passport MRZ information, the excellent recognition performance of the passport MRZ information was obtained in the experimental results for PC off-line mode and smart phone on-line mode."
효과적인 역 톤 매핑을 위한 필터링 기법,2019,"['Inverse Tone-mapping', 'HDR', 'CNN', 'Deep Learning', 'Guided Image Filter']",본 논문에서는 가이디드 영상 필터 (guided image filter: GIF)를 이용하여 컨볼루션 신경망 (convolutional neural network; CNN)을 이용한 역 톤 매핑 (inverse tone-mapping) 기법의 결과를 향상시킬 수 있는 필터링 기법을 제안한다. 저동적범위 (low dynamic range; LDR) 영상을 고동적범위 (high dynamic range; HDR) 디스플레이에서 표현할 수 있도록 변환하는 역 톤 매핑 기법은 지속적으로 제안되어왔다. 최근 들어 컨볼루션 신경망을 이용하여 단일 LDR 영상을 HDR 영상으로 변환하는 알고리듬이 많이 연구되었다. 그 중엔 제한된 동적범위 (dynamic range)로 인해 화소가 포화되어 기존 화소 정보가 손실되는데 이를 학습된 컨볼루션 신경망을 이용해서 복원하는 알고리듬이 존재한다. 해당 알고리듬은 비포화 영역의 잡음까지는 억제하지 못하며 포화 영역의 디테일까지는 복원하지 못한다. 제안한 알고리듬은 입력 영상에 가중된 가이디드 영상 필터 (weighted guided image filter; WGIF)를 사용해서 비포화 영역의 잡음을 억제하고 포화 영역의 디테일을 복원시킨 다음 컨볼루션 신경망에 인가하여 최종 결과 영상의 품질을 개선하였다. 제안하는 알고리듬은 HDR 정량적 화질평가 지표를 측정하였을 때 기존의 알고리듬에 비해 높은 화질평가 지수를 나타내었다.,다국어 초록 정보 없음
엔터프라이즈 환경의 딥 러닝을 활용한 이미지 예측 시스템 아키텍처,2019,"['Deep Learning', 'Softmax', 'ReLU', 'CNN', 'Inception', 'Architecture', '딥 러닝', 'Softmax', 'ReLU', 'CNN', '인셉션', '아키텍처']","본 논문에서는 엔터프라이즈 환경에서의 딥 러닝에 대한 이미지 예측 시스템 아키텍처를 제안한다. 엔터프라이즈 환경에 대해 인공지능 플랫폼으로 변환을 쉽게 하고, 인공지능 플랫폼이 파이선에 집중되어서 자바 중심의 엔터프라이즈 개발이 어려운 단점을 개선하기 위해 자바 중심의 아키텍처에서도 충분한 딥 러닝 서비스의 개발과 수정이 가능하도록 한다. 또한, 제안된 환경을 토대로 이미지 예측 실험을 통해 기존에 학습된 딥 러닝 아키텍처 환경에서의 정확도가 높은 예측 시스템을 제안한다. 실험을 통해 딥 러닝이 수행되기 위해 제공된 이미지 예에서 95.23%의 정확도를 보이며, 제안된 모델은 유사한 다른 모델에 비교해 96.54%의 정확도를 보인다. 제시된 아키텍처를 활용하여 활발한 엔터프라이즈급 환경의 딥 러닝 서비스가 개발 및 제공될 것으로 보이며, 기존 엔터프라이즈 환경이 딥 러닝 아키텍처가 탑재된 환경으로 전환이 활발히 이루어질 것이다.","This paper proposes an image prediction system architecture for deep running in enterprise environment. Easily transform into an artificial intelligence platform for an enterprise environment, and allow sufficient deep-running services to be developed and modified even in Java-centric architectures to improve the shortcomings of Java-centric enterprise development because artificial intelligence platforms are concentrated in the pipeline. In addition, based on the proposed environment, we propose a more accurate prediction system in the deep running architecture environment that has been previously learned through image forecasting experiments. Experiments show 95.23% accuracy in the image example provided for deep running to be performed, and the proposed model shows 96.54% accuracy compared to other similar models."
AI기반 의류정보를 이용한 비인가 접근감지,2019,"['인공지능(Artificial Information)', 'CNN(CNN)', '의류정보(Clothing Information)', '학습데이터(Training data)']",국문 초록 정보 없음,다국어 초록 정보 없음
Optimization Calculations and Machine Learning Aimed at Reduction of Wind Forces Acting on Tall Buildings and Mitigation of Wind Environment,2019,"['Optimization calculation', 'CFD', 'CNN', 'Wind force', 'Wind environment']",국문 초록 정보 없음,"We performed calculations combining optimization technologies and Computational Fluid Dynamics (CFD) aimed at reducing wind forces and mitigating wind environments (local strong winds) around buildings. However, the Reynolds Averaged Navier-stokes Simulation (RANS), which seems somewhat inaccurate, needs to be used to create a realistic CFD optimization tool. Therefore, in this study we explored the possibilities of optimizing calculations using RANS. We were able to demonstrate that building configurations advantageous to wind forces could be predicted even with RANS. We also demonstrated that building layouts was more effective than building configurations in mitigating local strong winds around tall buildings. Additionally, we used the Convolutional Neural Network (CNN) as an airflow prediction method alternative to CFD in order to increase the speed of optimization calculations, and validated its prediction accuracy."
Vehicle Manufacturer Recognition using Deep Learning and Perspective Transformation,2019,"['Vehicle Logo', 'Object detection', 'YOLO', 'Faster R-CNN', 'VMR.']",국문 초록 정보 없음,"In real world object detection is an active research topic for understanding different objects from images. There are different models presented in past and had significant results. In this paper we are presenting vehicle logo detection using previous object detection models such as You only look once (YOLO) and Faster Region-based CNN (F-RCNN). Both the front and rear view of the vehicles were used for training and testing the proposed method. Along with deep learning an image pre-processing algorithm called perspective transformation is proposed for all the test images. Using perspective transformation, the top view images were transformed into front view images. This algorithm has higher detection rate as compared to raw images. Furthermore, YOLO model has better result as compare to F-RCNN model."
An Efficient Comparing and Updating Method of Rights Management Information for Integrated Public Domain Image Search Engine,2019,"['Public Domain Image', 'RMI', 'dHash', 'Average Hash', 'CNN', 'Weighted Scoring Model']",국문 초록 정보 없음,"In this paper, we propose a Rights Management Information(RMI) expression systems for individual sites are integrated and the performance evaluation is performed to find out an efficient comparing and updating method of RMI through various image feature point search techniques. In addition, we proposed a weighted scoring model for both public domain sites and posts in order to use the most latest RMI based on reliable data. To solve problem that most public domain sites are exposed to copyright infringement by providing inconsistent RMI(Rights Management Information) expression system and non-up-to-date RMI information. The weighted scoring model proposed in this paper makes it possible to use the latest RMI for duplicated images that have been verified through the performance evaluation experiments of SIFT and CNN techniques and to improve the accuracy when applied to search engines. In addition, there is an advantage in providing users with accurate original public domain images and their RMI from the search engine even when some modified public domain images are searched by users."
A New CSR-DCF Tracking Algorithm based on Faster RCNN Detection Model and CSRT Tracker for Drone Data,2019,"['Object Tracking', 'CSR-DCF', 'Object Detection', 'CNN', 'Faster R-CNN', 'OpenCV', 'DNN Module', 'CSRT', 'Drone', 'Deep Learning']",국문 초록 정보 없음,"Nowadays object tracking process becoming one of the most challenging task in Computer Vision filed. A CSR-DCF (channel spatial reliability-discriminative correlation filter) tracking algorithm have been proposed on recent tracking benchmark that could achieve stat-of-the-art performance where channel spatial reliability concepts to DCF tracking and provide a novel learning algorithm for its efficient and seamless integration in the filter update and the tracking process with only two simple standard features, HoGs and Color names. However, there are some cases where this method cannot track properly, like overlapping, occlusions, motion blur, changing appearance, environmental variations and so on. To overcome that kind of complications a new modified version of CSR-DCF algorithm has been proposed by integrating deep learning based object detection and CSRT  tracker which implemented in OpenCV library. As an object detection model, according to the comparable result of object detection methods and by reason of high efficiency and celerity of Faster RCNN (Region-based Convolutional Neural Network) has been used, and combined with CSRT tracker, which demonstrated outstanding real-time detection and tracking performance. The results indicate that the trained object detection model integration with tracking algorithm gives better outcomes rather than using tracking algorithm or filter itself."
Medical Image Analysis Using Artificial Intelligence,2019,"['Artificial Intelligence (AI)', 'Medical images', 'Deep-learning', 'Machine-learning', 'Convolutional Neural Network (CNN)', 'Big data']",국문 초록 정보 없음,"Purpose: Automated analytical systems have begun to emerge as a database system that enables the scanning of medical images to be performed on computers and the construction of big data.Deep-learning artificial intelligence (AI) architectures have been developed and applied to medical images, making high-precision diagnosis possible.Materials and Methods: For diagnosis, the medical images need to be labeled and standardized.After pre-processing the data and entering them into the deep-learning architecture, the final diagnosis results can be obtained quickly and accurately. To solve the problem of overfitting because of an insufficient amount of labeled data, data augmentation is performed through rotation, using left and right flips to artificially increase the amount of data. Because various deeplearning architectures have been developed and publicized over the past few years, the results of the diagnosis can be obtained by entering a medical image.Results: Classification and regression are performed by a supervised machine-learning method and clustering and generation are performed by an unsupervised machine-learning method. When the convolutional neural network (CNN) method is applied to the deep-learning layer, feature extraction can be used to classify diseases very efficiently and thus to diagnose various diseases.Conclusions: AI, using a deep-learning architecture, has expertise in medical image analysis of the nerves, retina, lungs, digital pathology, breast, heart, abdomen, and musculo-skeletal system."
MLP 기반의 GAN을 사용한 흑백 사진 채색 기법,2019,[],"본 논문에서 grayscale 이미지를 그럴듯한 컬러 이미지로의 전환을 다루고자 한다. 기존의 CNN Network 를 통해 실제 Image 를 만들어내려는 기법들은 모든 Pixel 의 Error 를 Loss 로 사용한다. 각 픽셀별로 가장 완벽한 답을 찾으려고 하기보다는, 전체 픽셀의 관점에서의 Loss 를 줄이려고 하기 때문에, 픽셀 값이 정확한 값대신 안전한 값으로 넘어간다는 단점이 있다. 이 문제를 해결하기 위해 본 논문에서 GAN 기반의 Image-to-Image Translation 기법에 NIN(Network in Network) 적용해 이 문제를 해결할 수 있음을 보인다. 전통 CNN 기법보다 더 Photo-realistic 한 이미지를 생성할 수 있게 된다.",다국어 초록 정보 없음
임베디드 GPU에서의 딥러닝 기반 실시간 보행자 탐지 기법,2019,"['Pedestrian detection', 'convolutional neural network', 'embedded system']","본 논문은 임베디드 GPU에서 실시간 동작하는 딥 컨볼루션 뉴럴 네트워크(CNN) 기반의 보행자 탐지 기법을 제안한다. 제안하는 기법에서는 먼저 영상 내 보행자 크기에 대한 통계적 분석을 통해서 최적의 컨볼루션 층의 개수를 결정한다. 또한, 본 논문에서는 다중 스케일 CNN 학습 기법을 적용하여 영상 내의 보행자 크기 변화에 강인한 탐지 기법을 개발한다. 컴퓨터 모의실험을 통해 제안하는 알고리즘이 임베디드 GPU에서 실시간 동작하면서도 기존의 기법과 비교하여 평균적으로 높은 정확도를 보임을 확인한다.",다국어 초록 정보 없음
심층신경망을 이용한 소스 코드 원작자 식별,2019,"['컴퓨터 법의학', '예측 기반 벡터', 'TF-IDF', '심층 학습', 'CNN', 'Computer Forensic', 'Frequency Based Embedding', 'TF-IDF', 'Deep Learning', 'CNN']","현재 프로그래밍 소스들이 온라인에서 공개되어 있기 때문에 무분별한 표절이나 저작권에 대한 문제가 일어나고 있다. 그 중 반복된 저자가 작성한 소스코드는 프로그래밍 특성상 고유의 지문이 있을 수 있다. 본 논문은 구글 코드 잼 프로그램 소스를 심층신경망을 이용한 학습을 통해 각각의 저자를 분별하는 것이다. 이 때 원작자의 소스를 예측 기반 벡터나, 주파수 기반 접근법인 TF-IDF등의 전처리기를 사용하여 입력 값들을 벡터화해주고, 심층신경망을 이용한 학습을 통해 각 프로그램 소스 원작자를 식별하고자 한다. 전처리기를 이용하여 언어에 독립적인 학습시스템을 구성하고, 기존의 다른 학습 방법들과 비교하였다. 그 중 TF-IDF와 심층신경망을 사용한 모델은 다른 전처리기나 다른 학습방식을 사용한 것보다 좋은 성능을 보임을 확인하였다.",다국어 초록 정보 없음
기침 소리를 이용한 백일해 진단 모델 개발,2019,"['Pertussis', 'Automatic diagnosis', 'Cough sound', 'Mel-Frequency Cepstral Coefficient', 'Convolutional Neural Network']",국문 초록 정보 없음,"The purpose of this study is to develop a convolutional neural networks (CNN) based model that can diagnose pertussis using cough sound. Pertussis is a highly contagious respiratory disease, and 75% of the infected patients are infants less than 9 years old. In particular, if a child suffers from pertussis, it can die from complications and newborns within 4 weeks of birth have a 4% mortality rate due to pertussis. Early diagnosis is important to prevent the contagion and death from pertussis. Currently the method of diagnosing pertussis is performed by clinical symptoms and laboratory tests. However, this method is costly and difficult to diagnose it early. This study suggests a learning model for early diagnosis of pertussis. The cough sound data are transformed to image using MFCC and the hidden features are learned using the CNN model. The accuracy of the model has been improved through data augmentation and model optimization. The suggested model has high diagnostic performance: accuracy of 93%, sensitivity of 91%, and specificity of 80%. The proposed model with high classification accuracy and usability can be applied to medical applications to detect pertussis and it can be useful for early screening of children""s pertussis."
Occlusion Robust Object Detection and Tracking on a Real-time Drone,2019,"['Object Detection', 'Object Tracking', 'Drone Tracking', 'Mask R-CNN']",국문 초록 정보 없음,This paper presents a vision-based tracking algorithm for real-time drone. This method consists of cnn based object detection and object tracking using the result of detector. The detector outputs a class label and a binary mask of the object. The tracker uses this binary mask to extract object features from the background. We use this information to estimate the accurate target location and tracking the target to each frame considering the similarity between target and each detected object feature vector. We validate this method using real-time drone.
Dhash 기반 고속 악성코드 변종 탐지기법,2019,"['악성코드 탐지', '정적 분석', '변종 악성코드', 'Dhash (Difference hash)', 'CNN (Convolutional Neural Network)', 'malware detection', 'static analysis', 'mutant malware', 'Dhash (Difference hash)', 'CNN (Convolutional Neural Network)']","악성코드 생성 도구와 난독화 기법의 대중화로 악성코드는 지능화되고 있지만 기존의 악성코드 탐지 기법은 악성코드에 대해 완벽하지 못한 탐지를 보여주고 있다. 이에 새롭게 등장하는 악성코드 중 다수가 기존에 발생했던 악성코드의 변종이라는 것과 변종 악성코드는 원본 악성코드와 비슷한 바이너리 데이터를 갖는 특징을 고려해 파일의 바이너리 데이터를 통해 이미지를 분류하는 Dhash 기반 악성코드 탐지 기법을 제시하며, Dhash 알고리즘의 전수비교로 인한 느린 분석 시간을 개선한 10-gram 알고리즘을 제시한다. 변종 악성코드 탐지에서 우수한 ssdeep 기법과의 비교를 통해 ssdeep이 탐지하지 못하는 영역에 대해 Dhash 알고리즘이 탐지했음을 보이며, 기존의 Dhash 알고리즘과 본 논문에서 제안하는 알고리즘의 탐지 속도 성능 비교 실험을 통해 제안하는 알고리즘의 우수성을 증명한다. 향후 다른 LSH기반 탐지 기법과 연계한 변종 악성코드 분석 기술 개발을 지속 진행할 예정이다.","Malicious codes are becoming more intelligent due to the popularization of malware generation tools and obfuscation techniques, but existing malware detection techniques suffer from incomplete detection of malicious codes. Considering the facts that many newly emerging malicious codes are variants of existing malicious codes, and that they have binary data similar to those of the original malicious codes, a Dhash-based malware detection technique is presented here that classifies images based on the binary data in a file, along with a 10-gram algorithm that improves the long time taken by the analysis due to the full comparison of the Dhash algorithm. A comparison with the superior ssdep technique in variant malware detection shows that the Dhash algorithm can detect areas that ssdep does not detect, and the superiority of the proposed algorithm through the existing Dhash algorithm and the detection speed comparison experiment of the algorithms proposed in this paper. Future work will continue to develop variety of malware analysis technologies that are linked to other LSH-based detection techniques."
순환신경망 모형을 활용한 시계열 비교예측,2019,"['ARIMA model', 'neural network', 'RNN', 'LSTM.', 'ARIMA 모형', '신경망모형', '순환신경망', 'LSTM.']","최근 알파고 이후 딥러닝 연구에 대한 활발한 연구가 진행되고 있다. 딥러닝에는 이미지 분석에 적합한 CNN(convolution neural network), 순차적 자료에 적합한 RNN(recurrent neural network) 모델 등 많은 모델이 존재하는데 그 중 시계열데이터 분석에 적합한 딥러닝 모델을 전형적 시계열데이터인 항공사 데이터(1949년 1월부터 1960년 12월까지 매월 총 국제 항공사 승객 수)에 Box-Jenkins의 ARIMA 모형과 함께 적합시켜 비교 할 것이다. 본 연구에서는 R 프로그램을 이용하여 LSTM(long short-term memory) 순환신경망 모델을 구축하고, ARIMA 모형, Faraway(1998)가 제시한 단순 신경망(neural network) 모형 그리고 Jordan & Elman의 순환신경망 모형과의 적합도를 비교하였다. 모형 비교결과 Elman 모형의 오차제곱합이 0.0128, Jordan 모형의 오차제곱 합이 0.0138, LSTM 모형의 오차제곱합이 0.0165, 신경망 모형은 오차제곱합 0.0212로 ARIMA 모형의 0.0194 에 비해 조금 뒤떨어지는 것으로 나타났다. 결국 Elman 순환신경망 모형이 가장 우수하게 나타났으며 LSTM 모형도 기존 ARIMA 모형과 Faraway의 단순신경망모형 보다 우수한 적합도를 나타났다.","Typical algorithms for deep learning include DNN (deep neural network), CNN (convolution neural network), and RNN (recurrent neural network) algorithms. Among them, RNN is excellent at dealing with sequential data. Sequential data such as time series data can be handled without losing gradient by LSTM (long short-term memory) RNN. In this study, the LSTM, a modified algorithm of RNN, is applied to international airline passenger data (from January 1, 1994 to December 1960). We find the optimal model and compare it with the ARIMA model, the initial network model presented by Faraway (1998), and the model of Jordan & Elman, the simple RNN model. To compare the models, we train the data as learning data sets from January 1949 to December 1950, and designate the remaining one year of data as test sets. and compare the performance of the model with the sum of square errors of the test sets. The model comparison shows that the Elman RNN model was the best, and that the LSTM model was not inferior to the ARIMA model."
Target-aware convolutional neural network for target-level sentiment analysis,2019,"['Sentiment anlaysis', 'Target-level sentiment analysis (TLSA)', 'Word distance', 'Deep learning', 'Convolutional neural network (CNN)']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>Target-level sentiment analysis (TLSA) is a classification task to extract sentiments from targets in text. In this paper, we propose <U>t</U>arget-dependent <U>c</U>onvolutional <U>n</U>eural <U>n</U>etwork (<ce:sans-serif>TCNN</ce:sans-serif>) tailored to the task of TLSA. The <ce:sans-serif>TCNN</ce:sans-serif> leverages the distance information between the target word and its neighboring words to learn the importance of each word to the target. Experimental results show that the <ce:sans-serif>TCNN</ce:sans-serif> achieves state-of-the-art performance on both single- and multi-target datasets. Qualitative evaluations were conducted to demonstrate the limitations of previous TLSA methods and also to verify that distance information is crucial for TLSA. Furthermore, by exploiting a convolutional neural network (CNN), the <ce:sans-serif>TCNN</ce:sans-serif> trains six times faster per epoch than other baselines based on recurrent neural networks.</P>"
차량용 인포테인먼트 시스템의 딥 러닝 기반 UI 테스팅 자동화 기술,2019,"['소프트웨어 테스팅 자동화', 'UI 테스팅 자동화', '차량용 인포테인먼트 시스템', '인공지능 응용', '객체검출', 'R-CNN', 'software testing automation', 'UI testing automation', 'in-vehicle infotainment system', 'artificial intelligence application', 'object detection', 'R-CNN']","최근 텔레메틱스(Telematics), 커넥티드 카(Connected Car), 자율 주행 자동차 기술의 발전으로 인해 차량용 인포테인먼트 시스템(In-Vehicle Infotainment, IVI)에 포함되는 기능이 다양화되고 역할과 중요도가 크게 높아지고 있다. 이에 따라 IVI와 사용자 간의 상호작용을 담당하는 사용자 인터페이스(User Interface, UI)의 복잡성이 증가되고 있으며, 높은 품질의 UI 개발을 위한 UI 테스팅 기술의 필요성 또한 증대되었다. 본 논문에서는 IVI의 화면으로부터 객체를 인식하는 딥 러닝 모델을 이용한 UI 테스팅 자동화 기술을 제안하고, IVI 자동화 테스팅 도구 VISTA에 적용시킨 사례에 대해 기술한다.","Lately, the functions included in the in-vehicle infotainment system (IVI) have diversified and their roles and importance greatly increased due to the development of telematics, connected cars, and autonomous vehicle technology. the complexity of the user interface (UI) responsible for the interaction between IVI and the user, and the need for a UI testing technique for a UI. In this paper, we propose a UI testing technology using a deep learning model that recognizes objects from the IVI screen, and describe a case where it is applied to IVI automation testing tool VISTA."
Bird sounds classification by combining PNCC and robust Mel-log filter bank features,2019,[],국문 초록 정보 없음,"In this paper, combining features is proposed as a way to enhance the classification accuracy of sounds under noisy environments using the CNN (Convolutional Neural Network) structure. A robust log Mel-filter bank using Wiener filter and PNCCs (Power Normalized Cepstral Coefficients) are extracted to form a 2-dimensional feature that is used as input to the CNN structure. An ebird database is used to classify 43 types of bird species in their natural environment. To evaluate the performance of the combined features under noisy environments, the database is augmented with 3 types of noise under 4 different SNRs (Signal to Noise Ratios) (20 dB, 10 dB, 5 dB, 0 dB). The combined feature is compared to the log Mel-filter bank with and without incorporating the Wiener filter and the PNCCs. The combined feature is shown to outperform the other mentioned features under clean environments with a 1.34 % increase in overall average accuracy. Additionally, the accuracy under noisy environments at the 4 SNR levels is increased by 1.06 % and 0.65 % for shop and schoolyard noise backgrounds, respectively."
작물 분류를 위한 다중 규모 공간특징의 가중 결합 기반 합성곱 신경망 모델,2019,"['Crop classification', 'Convolutional neural network', 'Spatial feature', 'Image patch']","이 논문에서는 작물 분류를 목적으로 합성곱 신경망 구조에 다중 규모의 입력 영상으로부터 추출가능한 다양한 공간특징을 가중 결합하는 모델을 제안하였다. 제안 모델은 합성곱 계층에서 서로 다른 크기의 입력패치를 이용하여 공간특징을 추출한 후, squeeze-and-excitation block을 통해 추출한 공간특징의 중요도에 따라가중치를 부여한다. 제안 모델의 장점은 분류에 유용한 특징들을 추출하고 특징의 상대적 중요도를 분류에 이용하는데 있다. 제안 모델의 분류 성능을 평가하기 위해 미국 일리노이 주에서 수집한 다중시기 Landsat-8 OLI 영상을 이용한 작물 분류 사례연구를 수행하였다. 유용한 패치 크기 결정을 위해 먼저 단일 패치 모델에서 패치 크기가 작물 분류에 미치는 영향을 분석하였다. 그 후에 단일 패치 모델과 특징의 중요도를 고려하지 않는다중 패치 모델과 분류 성능을 비교하였다. 비교 실험 결과, 제안 모델은 연구지역에서 재배하는 작물의 공간특징을 고려함으로써 오분류 양상을 완화시켜 비교 모델들에 비해 가장 우수한 분류 정확도를 나타냈다. 분류에 유용한 공간특징의 상대적 중요도를 고려하는 제안 모델은 작물뿐만 아니라 서로 다른 공간특성을 보이는객체 분류에도 유용하게 적용될 수 있을 것으로 기대된다.","This paper proposes an advanced crop classification model that combines a procedure for weighted combination of spatial features extracted from multi-scale input images with a conventional convolutional neural network (CNN) structure. The proposed model first extracts spatial features from patches with different sizes in convolution layers, and then assigns different weights to the extracted spatial features by considering feature-specific importance using squeeze-and-excitation block sets. The novelty of the model lies in its ability to extract spatial features useful for classification and account for their relative importance. A case study of crop classification with multi-temporal Landsat-8 OLI images in Illinois, USA was carried out to evaluate the classification performance of the proposed model. The impact of patch sizes on crop classification was first assessed in a single-patch model to find useful patch sizes. The classification performance of the proposed model was then compared with those of conventional two CNN models including the single-patch model and a multi-patch model without considering feature-specific weights. From the results of comparison experiments, the proposed model could alleviate misclassification patterns by considering the spatial characteristics of different crops in the study area, achieving the best classification accuracy compared to the other models. Based on the case study results, the proposed model, which can account for the relative importance of spatial features, would be effectively applied to classification of objects with different spatial characteristics, as well as crops."
Tissue Level Based Deep Learning Framework for Early Detection of Dysplasia in Oral Squamous Epithelium,2019,"['oral cancer', 'oral epithelial tissue', 'oral dysplasia', 'deep learning']",국문 초록 정보 없음,"Deep learning is emerging as one of the best tool in processing data related to medical imaging. In our research work, we have proposed a deep learning based framework CNN (Convolutional Neural Network) for the classification of dysplastic tissue images. The CNN has classified the given images into 4 different classes namely normal tissue, mild dysplastic tissue, moderate dysplastic tissue and severe dysplastic tissue. The dataset under taken for the study consists of 672 tissue images of epithelial squamous layer of oral cavity captured out of the biopsy samples of 52 patients. After applying the data pre-processing and augmentation on the given dataset, 2688 images were created. Further, these 2688 images were classified into 4 categories with the help of expert Oral Pathologist. The classified data was supplied to the convolutional neural network for training and testing of the proposed framework. It has been observed that training data shows 91.65% accuracy whereas the testing data achieves 89.3% accuracy. The results produced by our proposed framework are also tested and validated by comparing the manual results produced by the medical experts working in this area."
디컨볼루션 픽셀층 기반의 도로 이미지의 의미론적 분할,2019,[],국문 초록 정보 없음,"Semantic segmentation has remained as a challenging problem in the field of computer vision. Given the immense power of Convolution Neural Network (CNN) models, many complex problems have been solved in computer vision. Semantic segmentation is the challenge of classifying several pixels of an image into one category. With the help of convolution neural networks, we have witnessed prolific results over the time. We propose a convolutional neural network model which uses Fully CNN with deconvolutional pixel layers. The goal is to create a hierarchy of features while the fully convolutional model does the primary learning and later deconvolutional model visually segments the target image. The proposed approach creates a direct link among the several adjacent pixels in the resulting feature maps. It also preserves the spatial features such as corners and edges in images and hence adding more accuracy to the resulting outputs. We test our algorithm on Karlsruhe Institute of Technology and Toyota Technologies Institute (KITTI) street view data set. Our method achieves an mIoU accuracy of 92.04 %."
Sub-Frame Analysis-based Object Detection for Real-Time Video Surveillance,2019,"['object detection', 'object tracking', 'convolutional neural network', 'real time video surveillance', 'sub-frame analysis.']",국문 초록 정보 없음,"We introduce a vision-based object detection method for real-time video surveillance system in low-end edge computing environments. Recently, the accuracy of object detection has been improved due to the performance of approaches based on deep learning algorithm such as Region Convolutional Neural Network(R-CNN) which has two stage for inferencing. On the other hand, one stage detection algorithms such as single-shot detection (SSD) and you only look once (YOLO) have been developed at the expense of some accuracy and can be used for real-time systems. However, high-performance hardware such as General-Purpose computing on Graphics Processing Unit(GPGPU) is required to still achieve excellent object detection performance and speed. To address hardware requirement that is burdensome to low-end edge computing environments, We propose subframe analysis method for the object detection. In specific, We divide a whole image frame into smaller ones then inference them on Convolutional Neural Network (CNN) based image detection network, which is much faster than conventional network designed for full frame image. We reduced its computational requirement significantly without losing throughput and object detection accuracy with the proposed method."
RGB-D Dense Visual Odometry through Pixel Level Segmentation in Dynamic Environments,2019,"['Visual Odometry', 'Dynamic Environment', 'A Dynamic Object Tracking']",국문 초록 정보 없음,Estimating a camera pose in dynamic environments is one of the challenging problems in Visual Odometry. We propose an RGB-D Dense Visual Odometry (Dense-VO) system which uses preprocessed images that passed the Convolutional Neural Network (CNN). The algorithm adopts the CNN that tracks the designated dynamic object. The tracked dynamic object is excluded when the Dense-VO estimates the camera motion by minimizing photometric error between consecutive images. The system was tested in two datasets which includes a dynamic object. The proposed approach containing the preprocessing procedure estimates the camera trajectory with less drift in a dynamic environment.
두 개의 컨볼루션 신경망을 이용한 PCB 상의 SMD 분류 시스템,2019,"['deep learning', 'printed circuit board', 'surface mount technology', 'automated optical inspection']",국문 초록 정보 없음,It is important to classify SMD(Surface Mount Device) type for programing of AOI. A new SMD classification system is proposed using series of two CNNs to improve accuracy. A series of device region detection CNN and classification CNN are proposed where the first network is device region detect network and second network is device classification network. The device region detect network is designed lighter than the previously used region detect network. Experimental results showed that better accuracy is obtained when classification is performed after region detection.
외래잡초 분류 : 합성곱 신경망 기반 계층적 구조,2019,"['exotic weeds', 'weed classification', 'hierarchical architecture', 'convolutional neural networks']",국문 초록 정보 없음,"Weeds are a major object which is very harmful to crops. To remove the weeds effectively, we have to classify them accurately and use herbicides. As computing technology has developed, image-based machine learning methods have been studied in this field, specially convolutional neural network(CNN) based models have shown good performance in public image dataset. However, CNN with numerous training parameters and high computational amount. Thus, it works under high hardware condition of expensive GPUs in real application. To solve these problems, in this paper, a hierarchical architecture based deep-learning model is proposed. The experimental results show that the proposed model successfully classify 21 species of the exotic weeds. That is, the model achieve 97.2612% accuracy with a small number of parameters. Our proposed model with a few parameters is expected to be applicable to actual application of network based classification services."
Feature Map Swap: Multispectral Data Fusion Method for Pedestrian Detection,2019,"['Multispectral Pedestrian detection', 'Multispectral data fusion', 'Fusion network']",국문 초록 정보 없음,"This paper proposes a novel multispectral data fusion method for pedestrian detection. For all-day vision, a fusion of CCD and Infrared (IR) sensors are inevitable, and fusion of heterogeneous data based on a Convolutional neural network (CNN) is only based on the feature map concatenation of parallel CNN architecture. However, concatenation that is simply applied has a problem in that it can not fully utilize multispectral data in a deep network architecture. Therefore, this paper proposes a method called Feature Map Swap (FMS) of swapping feature maps in addition to concatenation. The proposed method can use multispectral data more efficiently by facilitating learning, by swapping the different domain weights of feature maps besides to concatenation. Also, the proposed method does not require any modifications, such as adding or removing layers to an already configured network architecture. Experimental results show that the performance of the KAIST multispectral pedestrian dataset is improved by about 7-10 % based on log-average miss rate compared to simple concatenation."
Automated classification of gastric neoplasms in endoscopic images using a convolutional neural network,2019,[],국문 초록 정보 없음,"<B>Abstract</B><P> Background Visual inspection, lesion detection, and differentiation between malignant and benign features are key aspects of an endoscopist’s role. The use of machine learning for the recognition and differentiation of images has been increasingly adopted in clinical practice. This study aimed to establish convolutional neural network (CNN) models to automatically classify gastric neoplasms based on endoscopic images.</P><P> Methods Endoscopic white-light images of pathologically confirmed gastric lesions were collected and classified into five categories: advanced gastric cancer, early gastric cancer, high grade dysplasia, low grade dysplasia, and non-neoplasm. Three pretrained CNN models were fine-tuned using a training dataset. The classifying performance of the models was evaluated using a test dataset and a prospective validation dataset.</P><P> Results A total of 5017 images were collected from 1269 patients, among which 812 images from 212 patients were used as the test dataset. An additional 200 images from 200 patients were collected and used for prospective validation. For the five-category classification, the weighted average accuracy of the Inception-Resnet-v2 model reached 84.6 %. The mean area under the curve (AUC) of the model for differentiating gastric cancer and neoplasm was 0.877 and 0.927, respectively. In prospective validation, the Inception-Resnet-v2 model showed lower performance compared with the endoscopist with the best performance (five-category accuracy 76.4 % vs. 87.6 %; cancer 76.0 % vs. 97.5 %; neoplasm 73.5 % vs. 96.5 %; P < 0.001). However, there was no statistical difference between the Inception-Resnet-v2 model and the endoscopist with the worst performance in the differentiation of gastric cancer (accuracy 76.0 % vs. 82.0 %) and neoplasm (AUC 0.776 vs. 0.865).</P><P> Conclusion The evaluated deep-learning models have the potential for clinical application in classifying gastric cancer or neoplasm on endoscopic white-light images.</P>"
CFAR와 합성곱 신경망을 이용한 기두부와 단 분리 시 조각 구분,2019,"['micro motion', 'micro-Doppler spectrogram', 'CA-CFAR', 'convolutional neural networks', 'warhead', 'debris']",국문 초록 정보 없음,"Warhead and debris show the different micro-Doppler frequency shape in the spectrogram because of the different micro motion. So we can classify them using the micro-Doppler features. In this paper, we classified warhead and debris in the separation phase using CNN(Convolutional Neural Networks). For the input image of CNN, we used micro-Doppler spectrogram. In addition, to improve classification performance of warhead and debris, we applied the preprocessing using CA-CFAR to the micro-Doppler spectrogram. As a result, when the preprocessing of micro-Doppler spectrogram was used, classification performance is improved in all signal-to-noise ratio(SNR)."
센서 융합 시스템을 이용한 심층 컨벌루션 신경망 기반 6자유도 위치 재인식,2019,"['Relocalization', 'Sensor Fusion', 'Convolutional Neural Network', 'pose regression']",국문 초록 정보 없음,"This paper presents a 6-DOF relocalization using a 3D laser scanner and a monocular camera. A relocalization problem in robotics is to estimate pose of sensor when a robot revisits the area. A deep convolutional neural network (CNN) is designed to regress 6-DOF sensor pose and trained using both RGB image and 3D point cloud information in end-to-end manner. We generate the new input that consists of RGB and range information. After training step, the relocalization system results in the pose of the sensor corresponding to each input when a new input is received. However, most of cases, mobile robot navigation system has successive sensor measurements. In order to improve the localization performance, the output of CNN is used for measurements of the particle filter that smooth the trajectory. We evaluate our relocalization method on real world datasets using a mobile robot platform."
영상 구성 파라미터 추출을 위한 융합 분석 알고리듬 연구,2019,"['Internet One-person Broadcasting Creators(인터넷 1인 방송 크리에이터)', 'Optical Flow(옵티컬 플로우)', 'Image Histogram(이미지 히스토그램)', 'Convolutional Neural Network(컨벌루셔널 뉴럴 네트워크)', 'Convergence Content(융합콘텐츠)']","본 연구는 영상콘텐츠 제작과정에서 배경음악 선정의 자동화를 위하여 영상의 특성을 분류, 분석할 수 있는 프로그램을 구성하였다. 연구 결과 및 내용은 다음과 같다. 영상의 특성은 ‘주제 범주’, ‘감정’, ‘픽셀 움직임 속도’, ‘색상’, ‘등장인물’ 로 선정하며, ‘주제 범주’와 ‘감정’은 Microsoft사의 Azure Video Indexer를, ‘픽셀 움직임 속도’는 Optical flow, ‘색상’은 Image Histogram, ‘등장인물’은 CNN (Convolutional Neural Network)을 활용하여 데이터를 추출하였다. 이러한 본 연구의 결과는 최근 주목을 받고있는 ‘인터넷 1인 방송 크리에이터’들의 콘텐츠 제작과정에서 배경음악 매칭을 위한 영상 특성 분석이 이루어졌다는 점에서 의의가 있다.","This study was conducted to organize a program to classify and analyze the characteristics of images for the automation of background music selection in the video content production process. The results and contents of the study are as follows: video characteristics are selected as subject category, emotion, pixel motion speed, color, and character material. Subject categories and feelings were extracted using Microsoft""s Azure Video Indexer, Pixel Movement Speed was an Optional flow, Color was an Image Histogram for Image, and character materials was CNN(Convolutional Neural Network). The results of this study are significant in that video analysis was conducted to match background music in the recent content production process of ""Internet One-person Broadcasting Creators""."
Music Onset Detection Using Convolutional Neural Network,2019,"['Onset detection', 'MIR', 'ASR', 'raw waveform']",국문 초록 정보 없음,Onset detection is a primary task in audio processing for any higher-level audio processing such as music information retrieval or automatic speech recognition. Onset detection using data driven approach is hard due to labeled data scarcity. In this work we use some in build dataset for training our convolutional neural network (CNN) work and make some test data for Nepalese traditional music. The CNN with raw waveform of input audio signal performs well in this study for onset detection. This network performs well in diversified audio type where 50 millisecond windows are set in each audio file to identify the presence or absence of onset.
다중 주파수 대역 convolutional neural network 기반 지진 신호 검출 기법,2019,[],국문 초록 정보 없음,"In this paper, a deep learning-based detection and classification using multi-band frequency signals is presented for detecting earthquakes prevalent in Korea. Based on an analysis of the previous earthquakes in Korea, it is observed that multi-band signals are appropriate for classifying earthquake signals. Therefore, in this paper, we propose a deep CNN (Convolutional Neural Network) using multi-band signals as training data. The proposed algorithm extracts the multi-band signals (Low/Medium/High frequency) by applying band pass filters to mel-spectrum of earthquake signals. Then, we construct three CNN architecture pipelines for extracting features and classifying the earthquake signals by a late fusion of the three CNNs. We validate effectiveness of the proposed method by performing various experiments for classifying the domestic earthquake signals detected in 2018."
공개 딥러닝 라이브러리에 대한 보안 취약성 검증,2019,"['Adversarial attack', 'MNIST', 'deep learning', 'security', 'autoencoder', 'convolution neural network']","최근 다양한 분야에서 활용중인 딥러닝은 적대적 공격 가능성의 발견으로 위험성이 제기되고 있다. 본 논문에서는딥러닝의 이미지 분류 모델에서 악의적 공격자가 생성한 적대적 샘플에 의해 분류 정확도가 낮아짐을 실험적으로 검증하였다. 대표적인 이미지 샘플인 MNIST데이터 셋을 사용하였으며, 텐서플로우와 파이토치라이브러리를 사용하여만든 오토인코더 분류 모델과 CNN(Convolution neural network)분류 모델에 적대적 샘플을 주입하여 탐지정확도를 측정한다. 적대적 샘플은 MNIST테스트 데이터 셋을 JSMA(Jacobian-based Saliency MapAttack)방법으로 생성한 방법과 FGSM(Fast Gradient Sign Method)방식으로 변형하여 생성하였으며, 분류모델에 주입하여 측정하였을 때 최소 21.82%에서 최대 39.08%만큼 탐지 정확도가 낮아짐을 검증하였다.","Deep Learning, which is being used in various fields recently, is being threatened with Adversarial Attack. In this paper,we experimentally verify that the classification accuracy is lowered by adversarial samples generated by malicious attackersin image classification models. We used MNIST dataset and measured the detection accuracy by injecting adversarialsamples into the Autoencoder classification model and the CNN (Convolution neural network) classification model, which arecreated using the Tensorflow library and the Pytorch library. Adversarial samples were generated by transforming MNISTtest dataset with JSMA(Jacobian-based Saliency Map Attack) and FGSM(Fast Gradient Sign Method). When injected into theclassification model, detection accuracy decreased by at least 21.82% up to 39.08%."
Identifying Tonal Frequencies in a Lofargram with Convolutional Neural Networks,2019,"['Underwater recognition', 'convolutional neural networks', 'lofar analysis']",국문 초록 정보 없음,"SONAR signal detection is widely used to detect and recognize objects in ocean environment, such as fishes, sea mines, ships or submarines. Because the analysis process of sonargram is time-consuming and difficult even to the expert sonar technician, many previous approaches attempted to automate the process. Recently, convolutional neural networks (CNN) are used in many computer vision problems as feature extractor and predictor, and the performance overwhelms existing approaches. In this paper, we use convolutional neural network models to identify tonal frequencies in a lofargram. We divide a lofargram into several small patches, and a CNN model predicts the probability that the patch is from a tonal frequency. Our model shows 92.5% of precision and 99.8% of recall, and 0.150 seconds of processing time for an inference batch at a specific time frame."
Image-to-Image Learning to Predict Traffic Speeds by Considering Area-Wide Spatio-Temporal Dependencies,2019,[],국문 초록 정보 없음,"<P>Spatio-temporal dependencies are the key to predicting the traffic parameters of an urban arterial network. However, their inclusion in forecasting traffic states has been hampered due to both the absence of a robust model and the computational burden. Recently, an innovative way to tackle the problem was developed by adopting a convolutional neural network (CNN) to deal with map images representing traffic states. Unlike previous studies that utilized map images only for input, the present study adopted images for both the input and the output of a CNN model to predict traffic speeds. The results show that the performance of the proposed model based on image-to-image learning is superior to that of the existing models.</P>"
Vehicle Detection in Aerial Images Based on Hyper Feature Map in Deep Convolutional Network,2019,"['Car detection', 'deep convolutional network', 'hyper feature map', 'small object detection', 'feature fusion']",국문 초록 정보 없음,"Vehicle detection based on aerial images is an interesting and challenging research topic. Most of the traditional vehicle detection methods are based on the sliding window search algorithm, but these methods are not sufficient for the extraction of object features, and accompanied with heavy computational costs. Recent studies have shown that convolutional neural network algorithm has made a significant progress in computer vision, especially Faster R-CNN. However, this algorithm mainly detects objects in natural scenes, it is not suitable for detecting small object in aerial view. In this paper, an accurate and effective vehicle detection algorithm based on Faster R-CNN is proposed. Our method fuse a hyperactive feature map network with Eltwise model and Concat model, which is more conducive to the extraction of small object features. Moreover, setting suitable anchor boxes based on the size of the object is used in our model, which also effectively improves the performance of the detection. We evaluate the detection performance of our method on the Munich dataset and our collected dataset, with improvements in accuracy and effectivity compared with other methods. Our model achieves 82.2% in recall rate and 90.2% accuracy rate on Munich dataset, which has increased by 2.5 and 1.3 percentage points respectively over the state-of-the-art methods."
Selection of CDMA and OFDM using machine learning in underwater wireless networks,2019,['Underwater communicationMachine learningCDMAOFDM'],국문 초록 정보 없음,"Underwater acoustic (UWA) channels have long propagation delays and irregular Doppler shifts, which make the design of communication scheme difficult. Even though two transceivers are fixed, UWA channels dramatically vary by time since speed velocity profile in UWA channel is changed by day and night. This paper proposes a selection method between CDMA and OFDM modulations using a convolutional neural network (CNN) for estimating channel parameters and Random Forest (RF) for modulation selection based on the CNN results. Computer simulations demonstrate that the parameter estimation of the proposed method is better than that of the conventional least square (LS) estimation, and RF selection method exhibits better detection results than the conventional DNN."
합성곱신경망을 이용한 제주도 강수패턴 분석 연구,2019,"['Precipitation', 'Convolution NN (Neural Network)', 'Texture', 'weather satellite', 'Jeju', '강수패턴', '합성곱신경망', '텍스처', '기상위성', '제주지역']",국문 초록 정보 없음,"Since Jeju is the absolute weight of agriculture and tourism, the analysis of precipitation is more important than other regions. Currently, some numerical models are used for analysis of precipitation of Jeju Island using observation data from meteorological satellites. However, since precipitation changes are more diverse than other regions, it is difficult to obtain satisfactory results using the existing numerical models. In this paper, we propose a Jeju precipitation pattern analysis method using the texture analysis method based on Convolution Neural Network (CNN). The proposed method converts the water vapor image and the temperature information of the area of ​​Jeju Island from the weather satellite into texture images. Then converted images are fed into the CNN to analyse the precipitation patterns of Jeju Island. We implement the proposed method and show the effectiveness of the proposed method through experiments."
Development of Predictive Models in Patients with Epiphora Using Lacrimal Scintigraphy and Machine Learning,2019,['Epiphora . Dacryocystography . Lacrimal scintigraphy . Machine learning . Deep learning . Convolutional neural network'],국문 초록 정보 없음,"Purpose We developed predictive models using different programming languages and different computing platforms for machine learning (ML) and deep learning (DL) that classify clinical diagnoses in patients with epiphora.We evaluated the diagnostic performance of these models.Methods Between January 2016 and September 2017, 250 patients with epiphora who underwent dacryocystography (DCG) and lacrimal scintigraphy (LS) were included in the study.We developed five different predictive models usingMLtools, Pythonbased TensorFlow, R, and Microsoft Azure Machine Learning Studio (MAMLS). A total of 27 clinical characteristics and parameters including variables related to epiphora (VE) and variables related to dacryocystography (VDCG) were used as input data. Apart from this, we developed two predictive convolutional neural network (CNN) models for diagnosing LS images. We conducted this study using supervised learning.Results Among 500 eyes of 250 patients, 59 eyes had anatomical obstruction, 338 eyes had functional obstruction, and the remaining 103 eyes were normal. For the data set that excluded VE and VDCG, the test accuracies in Python-based TensorFlow, R, multiclass logistic regression in MAMLS, multiclass neural network in MAMLS, and nuclear medicine physician were 81.70%, 80.60%, 81.70%, 73.10%, and 80.60%, respectively. The test accuracies of CNN models in three-class classification diagnosis and binary classification diagnosis were 72.00% and 77.42%, respectively.Conclusions ML-based predictive models using different programming languages and different computing platforms were useful for classifying clinical diagnoses in patients with epiphora and were similar to a clinician’s diagnostic ability."
Sentinel-1 A/B 위성 SAR 자료와 딥러닝 모델을 이용한 여름철 북극해 해빙 분류 연구,2019,"['Sentinel-1 A/B', 'sea ice', 'thermal noise', 'Deep Learning', 'classification']","북극항로의 개척 가능성과 정확한 기후 예측 모델의 필요성에 의해 북극해 고해상도 해빙 지도의 중요성이 증가하고 있다. 그러나 기존의 북극 해빙 지도는 제작에 사용된 위성 영상 취득 센서의 특성에 따른 데이터의 취득과 공간해상도 등에서 그 활용도가 제한된다. 본 연구에서는 Sentinel-1 A/B SAR 위성자료로부터 고해상도 해빙 지도를 생성하기 위한 딥러닝 기반의 해빙 분류 알고리즘을 연구하였다. 북극해 Ice Chart를 기반으로 전문가 판독에 의해 Open Water, First Year Ice, Multi Year Ice의 세 클래스로 구성된 훈련자료를 구축하였으며, Convolutional Neural Network 기반의 두 가지 딥러닝 모델(Simple CNN, Resnet50)과 입사각 및 thermal noise가 보정된 HV 밴드를 포함하는 다섯 가지 입력 밴드 조합을 이용하여 총 10가지 케이스의 해빙 분류를 실시하였다. 이 케이스들에 대하여 Ground Truth Point를 사용하여 정확도를 비교하고, 가장 높은 정확도가 나온케이스에 대해 confusion matrix 및 Cohen의 kappa 분석을 실시하였다. 또한 전통적으로 분류를 위해 많이 활용되어 온 Maximum Likelihood Classifier 기법을 이용한 분류결과에 대해서도 같은 비교를 하였다. 그 결과Convolution 층 2개, Max Pooling 층 2개를 가진 구조의 Convolutional Neural Network에 [HV, 입사각] 밴드를 넣은 딥러닝 알고리즘의 분류 결과가 96.66%의 가장 높은 분류 정확도를 보였으며, Cohen의 kappa 계수는 0.9499 로 나타나 딥러닝에 의한 해빙 분류는 비교적 높은 분류 결과를 보였다. 또한 모든 딥러닝 케이스는 Maximum Likelihood Classifier 기법에 비해 높은 분류 정확도를 보였다.","The importance of high-resolution sea ice maps of the Arctic Ocean is increasing due to the possibility of pioneering North Pole Routes and the necessity of precise climate prediction models. In this study, sea ice classification algorithms for two deep learning models were examined using Sentinel- 1 A/B SAR data to generate high-resolution sea ice classification maps. Based on current ice charts, three classes (Open Water, First Year Ice, Multi Year Ice) of training data sets were generated by Arctic sea ice and remote sensing experts. Ten sea ice classification algorithms were generated by combing two deep learning models (i.e. Simple CNN and Resnet50) and five cases of input bands including incident angles and thermal noise corrected HV bands. For the ten algorithms, analyses were performed by comparing classification results with ground truth points. A confusion matrix and Cohen’s kappa coefficient were produced for the case that showed best result. Furthermore, the classification result with the Maximum Likelihood Classifier that has been traditionally employed to classify sea ice. In conclusion, the Convolutional Neural Network case, which has two convolution layers and two max pooling layers, with HV and incident angle input bands shows classification accuracy of 96.66%, and Cohen’s kappa coefficient of 0.9499. All deep learning cases shows better classification accuracy than the classification result of the Maximum Likelihood Classifier."
An Application of Artificial Intelligence to Diagnostic Imaging of Spine Disease: Estimating Spinal Alignment From Moiré Images,2019,"['Adolescent idiopathic scoliosis', 'Moiré', 'Artificial intelligence', 'Estimation', 'Cobb angle', 'Vertebral rotation']",국문 초록 정보 없음,"The use of artificial intelligence (AI) as a tool supporting the diagnosis and treatment of spinal diseases is eagerly anticipated. In the field of diagnostic imaging, the possible application of AI includes diagnostic support for diseases requiring highly specialized expertise, such as trauma in children, scoliosis, symptomatic diseases, and spinal cord tumors. Moiré topography, which describes the 3-dimensional surface of the trunk with band patterns, has been used to screen students for scoliosis, but the interpretation of the band patterns can be ambiguous. Thus, we created a scoliosis screening system that estimates spinal alignment, the Cobb angle, and vertebral rotation from moiré images. In our system, a convolutional neural network (CNN) estimates the positions of 12 thoracic and 5 lumbar vertebrae, 17 spinous processes, and the vertebral rotation angle of each vertebra. We used this information to estimate the Cobb angle. The mean absolute error (MAE) of the estimated vertebral positions was 3.6 pixels (~5.4 mm) per person. T1 and L5 had smaller MAEs than the other levels. The MAE per person between the Cobb angle measured by doctors and the estimated Cobb angle was 3.42°. The MAE was 4.38° in normal spines, 3.13° in spines with a slight deformity, and 2.74° in spines with a mild to severe deformity. The MAE of the angle of vertebral rotation was 2.9°±1.4°, and was smaller when the deformity was milder. The proposed method of estimating the Cobb angle and AVR from moiré images using a CNN is expected to enhance the accuracy of scoliosis screening."
전이 학습과 진동 신호를 이용한 설비 고장 진단 및 분석,2019,"['Fault diagnosis', 'Transfer learning', 'Prognostics and health management', 'Deep learning', 'Convolutional neural networks']",국문 초록 정보 없음,"With the automation of production lines in the manufacturing industry, the importance of real-time fault diagnosis of facility is increasing. In this paper, we propose a fault diagnosis algorithm of LM (Linear Motion)-guide based on deep learning using vibration signals. Generally, in order to guarantee the performance of the deep learning, it is necessary to have a sufficient amount of data, but in a manufacturing industry, it is often difficult to obtain enough data due to physical and time constraints. To solve this problem, we propose a convolutional neural networks (CNN) model based on transfer learning. In addition, the spectrogram image is input to the CNN to reflect the frequency characteristic of the vibration signals with time. The performance of fault diagnosis according to various load condition and transfer learning method was compared and evaluated by experiments. The results showed that the proposed algorithm exhibited an excellent performance."
R-FCN과 Transfer Learning 기법을 이용한 영상기반 건설 안전모 자동 탐지,2019,"['Construction safety', 'Object detection', 'Deep learning', 'Neural network', '건설안전', '물체 탐지', '딥러닝', '인공신경망']","대한민국에서 건설업은 타 업종들과 비교하여 안전사고의 위험성이 가장 높게 나타난다. 따라서 건설업 내 안전성 향상을 도모하기 위해 여러 연구가 예전부터 진행이 되어 왔고, 본 연구에선 건설현장 영상 데이터를 기반으로 물체 탐지 및 분류 알고리즘을 이용해서 효과적인 안전모 자동탐지 시스템을 구축하여 건설현장 노동자들의 안전성 향상에 기여하고자 한다. 본 연구에서 사용된 알고리즘은 Convolutional Neural Network (CNN) 기반의 물체 탐지 및 분류 알고리즘인 Region-based Fully Convolutional Networks (R-FCN)이고 이를 Transfer Learning 기법을 사용하여 딥러닝을 실시하였다. ImageNet에서 수집한 1089장의 사람과 안전모가 포함된 영상으로 학습을 시행하였고 그 결과, 사람과 안전모의 mean Average Precision (mAP)은 각각 0.86, 0.83로 측정되었다.","In Korea, the construction industry has been known to have the highest risk of safety accidents compared to other industries. Therefore, in order to improve safety in the construction industry, several researches have been carried out from the past. This study aims at improving safety of labors in construction site by constructing an effective automatic safety helmet detection system using object detection algorithm based on image data of construction field. Deep learning was conducted using Region-based Fully Convolutional Network (R-FCN) which is one of the object detection algorithms based on Convolutional Neural Network (CNN) with Transfer Learning technique. Learning was conducted with 1089 images including human and safety helmet collected from ImageNet and the mean Average Precision (mAP) of the human and the safety helmet was measured as 0.86 and 0.83, respectively."
인공 신경망과 웨이블릿 변환을 이용한 주가 지수 예측,2019,"['웨이블릿 변환', '주가 지수 예측', '인공 신경망', '시계열 분석', 'wavelet transform', 'forecasting stock market price', 'artificial neural network', 'time series analysis']","기계학습 기술과 인공신경망 기술의 발전과 함께 주식시장의 흐름을 예측하려는 연구가 다양하게 시도되어 왔다. 특히 영상, 음성 처리를 위한 인공신경망 기술들이 주식시장 예측에 도입되어 예측의 정확도를 향상시키고 있다. 본 논문에서는 KOSPI의 지수변화와 방향성을 예측하기 위해 추출한 기술적 지표를 웨이블릿 변환을 이용하여 고주파수부분과 저주파수부분으로 나누어 인공신경망에서 각각 독립적으로 학습하고 예측한 다음, 고주파수부분과 저주파수부분을 합하여 지수와 방향성을 최종 예측하였다. 인공신경망으로 합성곱신경망, Dual Path Network 그리고 LSTM을 사용하여 인공신경망 간의 성능비교와 웨이블릿 변환의 효용성을 분석하였다. 지수예측에서는 합성곱신경망이 MAPE 0.51%, 등락예측에서는 LSTM이 정확도 81.7%로 최적의 결과를 보였고, 웨이블릿 변환으로 향상된 성능은 지수 예측의 경우 평균 38%, 등락 예측의 경우 평균 25%를 얻어 웨이블릿 변환의 효용성을 확인하였다.","With advancements in technologies on machine learning and artificial neural network, various researches have attempted to predict the changes in the price of the stock market. The prediction accuracy has improved with adoption of new artificial neural network technologies that have been developed for image and voice signal processing. In the present work, the technical indices from KOSPI were decomposed for the prediction of index and movement direction of KOSPI into high-frequency part and low-frequency part using wavelet transform, then used to predict KOSPI independently by using artificial neural networks. For the final prediction, the prediction result of each frequency part was added. CNN, DPN, and LSTM were employed as artificial neural network; the performance of each model was compared and the efficiency of the wavelet transform of input variables was analyzed. CNN with 0.51% of MAPE for the index prediction and LSTM with 81.7% of accuracy for movement prediction showed the best performance among the three models. The efficiency of wavelet transform was confirmed with averaged 38% of the improved performance for the index prediction and averaged 25% of the improved performance for the movement prediction."
무인항공기 영상에서의 조류 및 차량 검출을 위한 딥러닝 기반 검출 모델 개발,2019,"['딥러닝', '야생조류', '무인항공기', '항공영상', '조류인플루 엔자']","야생동물에 대한 주기적인 모니터링은 생태계의 보전과 관리, 이상 징후의 포착에 필수적이다. 특히 한국의 경우 주기적으로 발생하고 있는 조류 인플루엔자의 예찰을 위해 야생조류에 대한 효과적 예찰 시스템이 요구되는 상황이다. 야생동물에 대한 항공영상 기반의 조사는 1920년대부터 수행되었으며 다른 조사방법들 대비 지상으로 접근하기 어려운 지점에 대한 접근이 가능한 점, 넓은 범위의 영역에 대한 조사가 가능한 점 등의 장점이 있다. 하지만 유인항공기를 이용하는 기존 연구의 경우 비용 소모가 크고, 숙련된 비행사가 필요하였으며, 비행사고로 인한 위험성 또한 존재했다. 이러한 단점을 극복하기 위하여 최근 야생동물에 대한 항공 조사에 소형 무인항공기를 적용하는 연구들이 활발히 진행되고 있다. 기존의 야생 조류에 대한 항공 조사의 경우 주로 사람이 직접 영상에서 새를 검출하거나, 고전적인 영상처리 방식이 사용되었다. 하지만 이러한 고전적 영상처리 및 머신러닝 방법들은 해당 방법들이 적용된 특정 환경에서 적용되었으며, 다양한 환경에서 일관성 있게 적용되기 힘들다. 최근 영상데이터에 대한 분류, 검출 등의 분석 작업에서는 CNN(Convolutional Neural Networks) 기반의 알고리즘들이 주목받고 있으나, 현재까지 야생조류의 검출에 이를 적용하려는 사례는 많지 않다. 따라서 본 연구에서는 야생조류의 서식지를 비롯한 조류독감 방역대의 항공 조사를 위한 딥러닝 기반 야생 조류와 차량에 대한 검출 모델을 개발하고자 하였다. 모델의 학습을 위해 실제 야생조류, 모형조류, 차량에 대한 영상을 다양한 환경에서 수집하여 데이터세트를 구성하였으며, Faster R-CNN, R-FCN, Retinanet, SSD, YOLO 등의 딥러닝 검출 구조와 Resnet, Inception, Mobilenet 등의 특징 추출 네트워크를 조합하여 검출 모델을 구성하고 성능을 비교 평가하였다.",다국어 초록 정보 없음
Text Detection with Deep Neural Network System Based on Overlapped Labels and a Hierarchical Segmentation of Feature Maps,2019,"['Deep neural netwrok', 'detection framework', 'text detection', 'text localization']",국문 초록 정보 없음,"This paper proposes a three-level framework to detect texts in a single image. First, a salient feature map of text is extracted using a Fully Convolutional Network (FCN) that achieves good performance in semantic segmentation. Label combination using both boxes of word and characters level is proposed to improve the detection of uneven boundaries of text regions. Second, in the feature map of FCN, the text region has a higher probability value than the background region, and the coordinates in the character area are very close to each other. We segment the text area and the background area by using the characteristics of text feature map with Hierarchical Cluster Analysis (HCA). Finally, we applied a Convolutional Neural Networks (CNN) to classify the candidate text area into text and non-text. In this paper,we used CNN which can classify 4 classes in total by separating the background area and three text classes (one character, two characters, three characters or more). The text detection framework proposed in this paper have shown good performance with ICDAR2015, and high performance especially in Recall criterion, ﬁnding more texts than other algorithms."
라이다 센서 데이터를 이용한 구형 특징 표현 기반의 도시 구조물 3차원 점 군 분류에 관한 연구,2019,"['a라이다 센서', '거리 데이터', '물체 인식', '도시 구조물', '키티 데이터', '구형 특징 표현', '합성곱 신경망', 'LiDAR Sensor', 'Depth Data', 'Object Recognition', 'Urban Structure', 'KITTI Data', 'Spherical Signature Descriptor', 'Convolutional Neural Network']","물체 인식은 영상 등의 이미지 정보와 깊이 정보 등의 센서 데이터를 이용하여 물체의 종류와 크기, 방향, 위치 등의 고차원적인 공간 정보를 실시간으로 알아내는 기술로 자율주행의 기본 기술이 된다. 본 논문에서는 거리 데이터 기반의 물체인식을 목표로 하고 있으며, 3차원 점을 구성하고 있는 모든 점에 의미를 부여 할 수 있는 구형 특징 표현을 이용한 학습 데이터 생성을 제안하였다. 구형 특징 표현을 이용하여 생성된 학습 데이터는 주변 점들의 분포와 밀집도를 이용하여 한 점의 특징을 정의 함으로서 모든 점들에 대하여 생성이 가능하기 때문에 인공지능을 위한 학습데이터 준비에 매우 용이하게 사용될 수 있다. 본 논문에서는 KITTI 데이터와 직접 수집한 라이다 센서 데이터를 구형 특징 표현에 적용하여 학습 데이터를 생성하고 생성된 학습 데이터를 인공지능 학습의 한 종류인 CNN(Convolutional Neural Network)에 입력하여 도시 구조물에 대한 3차원 점 군을 분류하고자 하였다.","Object recognition is a technology that detects real-time high-dimensional spatial information such as type, size, direction, and position of an object using sensor data such as image information and depth information of photographs. In this study, we aim at achieving object recognition based on distance data and propose the generation of learning data using the spherical signature descriptor capable of giving meaning to all points composing a 3D point group. The learning data generated by using the spherical signature descriptor can easily be used for generating learning data for artificial intelligence because it is possible to define the characteristics of a point using the distribution and density of the surrounding points and to generate from all the points. In this study, we generated learning data by applying collected KITTI and LiDAR sensor data directly to the spherical signature descriptor and classifying the urban structures through artificial intelligence learning using a CNN (convolutional neural network)."
An Intrusion Detection Model based on a Convolutional Neural Network,2019,"['Intrusion detection', 'Deep learning', 'Convolutional neural network', 'Recurrent neural network.']",국문 초록 정보 없음,"Machine-learning techniques have been actively employed to information security in recent years. Traditional rule-based security solutions are vulnerable to advanced attacks due to unpredictable behaviors and unknown vulnerabilities. By employing ML techniques, we are able to develop intrusion detection systems (IDS) based on anomaly detection instead of misuse detection. Moreover, threshold issues in anomaly detection can also be resolved through machine-learning. There are very few datasets for network intrusion detection compared to datasets for malicious code. KDD CUP 99 (KDD) is the most widely used dataset for the evaluation of IDS. Numerous studies on ML-based IDS have been using KDD or the upgraded versions of KDD. In this work, we develop an IDS model using CSE-CIC-IDS 2018, a dataset containing the most up-to-date common network attacks. We employ deep-learning techniques and develop a convolutional neural network (CNN) model for CSE-CIC-IDS 2018. We then evaluate its performance comparing with a recurrent neural network (RNN) model. Our experimental results show that the performance of our CNN model is higher than that of the RNN model when applied to CSE-CIC-IDS 2018 dataset. Furthermore, we suggest a way of improving the performance of our model."
Word2Vec과 2계층 양방향 장단기 기억 네트워크를 이용한 특허 문서의 자동 IPC 분류,2019,"['텍스트 마이닝', '문서 분류', '순환 신경망', 'text mining', 'document classification', 'recurrent neural network']","자연어 처리를 이용한 문서 분류 분야에서도 전통적인 방법에서 벗어나 단어 임베딩을 활용한 합성곱 신경망과 순환 신경망 등 심층 신경망을 이용한 다양한 연구가 진행되고 있다. 본 논문에서는 Word2Vec과 두 개의 계층으로 구성된 양방향 장단기 기억 네트워크를 이용한 특허 문서의 IPC(International Patents Classification) 자동 분류 모델을 제안한다. IPC는 세계지식재산권기구에서 제정한 국제적으로 통일된 특허 분류 기준이며, 각 국가의 공인된 기관에서 수작업으로 분류하고 있다. IPC 자동 분류를 위하여 입력 시퀀스에 Word2Vec을 이용한 단어 임베딩가중치를 사용한다. 그리고 가중치가 부여된 시퀀스를 두 개의 계층을 갖는 깊은 구조의 양방향 장단기 기억 네트워크 신경망에 입력하여 IPC를 분류한다. 실험 결과 특허 문서의 분류 정확도가 합성곱 신경망 보다는 약 7% 향상되었으며, 순환 신경망을 단일로 이용하는 것 보다는 약 5% 향상된 것을 확인할 수 있었다. 또한 전통적인 방법인 나이브 베이시안, 로지스틱 분류 및 서포트 벡터 머신보다는 5~12% 이상 우수한 성능을 나타내었다.","There are various studies using Deep Neural Network such as CNN(Convolutional Neural Network) and RNN(Recurrent Neural Network) that utilize word embedding in document classification using natural language processing out of traditional methods. In this paper, we propose the IPC(International Patents Classification) automatic classification model of patent documents using two layers BLSTM(Bidirectional Long Short Term memory) network. The IPC is an internationally uniform standard for patent classification established by the World Intellectual Property Organization and is categorized by hand in authorized agencies in each country. For the IPC automatic classification, we use word embedding weight with Word2Vec in the input sequences. And they are classified by entering a weighted sequences into a deep neural network with two layers BLSTM. The experimental results showed that the accuracy of classification is improved by about 7% than that of CNN, and about 5% than that of single layer LSTM that is a field of RNN. Also it showed more than 5~12% higher performance than traditional methods such as Naive Bayes, Logistic and Support Vector Machine classification."
딥러닝을 이용한 번호판 검출과 인식 알고리즘,2019,"['License Plate', 'SVM', 'Machine Learning', 'Deep Learning', 'Intelligent Transportation System']",최근 지능형 교통관제 시스템에 관한 다양한 연구가 진행되고 있는 가운데 번호판 검출과 인식 알고리즘은 가장 중요한요소 중에 하나로 대두되고 있다. 번호판은 차량의 고유 식별값을 가지고 있기 때문이다. 기존의 차량 통행 관제 시스템은정차를 기반으로 하고 있으며 차량의 입출입 인식 방법으로 루프 코일을 사용하고 있다. 이러한 방법은 교통 정체를 유발하고 유지보수 비용이 상승하는 단점을 가지고 있다. 본 논문에서는 이러한 문제점을 해결하기 위해서 차량의 입출입 인식 방법으로 카메라 영상을 사용한다. 차량 통행 관제 시스템의 특성상 카메라가 고정되어 있다. 이에 차량이 접근하면 카메라의배경화면이 달라진다. 이 특징을 이용하여 배경화면의 차분영상을 구하면 차량의 입출입을 인식할 수 있다. 입출입 인식 후한국 번호판의 형태학적 특성을 이용하여 후보 이미지를 추정한다. 그리고 선형 SVM(Support Vector Machine)을 이용해서최종 번호판을 검출한다. 검출한 번호판의 글자와 숫자 인식 방법으로는 CNN(Convolutional Neural Network) 알고리즘을사용한다. 제안한 알고리즘은 기존의 시스템과 달리 검출 위치를 기준으로 글자와 숫자를 인식하기 때문에 번호판의 규격이변해도 인식할 수 있다. 실험한 결과 기존의 번호판 인식 알고리즘들 보다 제안한 알고리즘이 더 높은 인식률을 가진다.,"One of the most important research topics on intelligent transportation systems in recent years is detecting andrecognizing a license plate. The license plate has a unique identification data on vehicle information. The existing vehicletraffic control system is based on a stop and uses a loop coil as a method of vehicle entrance/exit recognition. Themethod has the disadvantage of causing traffic jams and rising maintenance costs. We propose to exploit differentialimage of camera background instead of loop coil as an entrance/exit recognition method of vehicles. After entrance/exitrecognition, we detect the candidate images of license plate using the morphological characteristics. The license plate canfinally be detected using SVM(Support Vector Machine). Letter and numbers of the detected license plate are recognizedusing CNN(Convolutional Neural Network). The experimental results show that the proposed algorithm has a higherrecognition rate than the existing license plate recognition algorithm."
CTC를 적용한 CRNN 기반 한국어 음소인식 모델 연구,2019,"['Phoneme Recognition', 'CTC Algorithm', 'Convolutional Neural Network', 'Recurrent Neural Network', '음소 인식', 'CTC 알고리즘', '합성곱 신경망', '순환 신경망']",국문 초록 정보 없음,"For Korean phoneme recognition, Hidden Markov-Gaussian Mixture model(HMM-GMM) or hybrid models which combine artificial neural network with HMM have been mainly used. However, current approach has limitations in that such models require force-aligned corpus training data that is manually annotated by experts. Recently, researchers used neural network based phoneme recognition model which combines recurrent neural network(RNN)-based structure with connectionist temporal classification(CTC) algorithm to overcome the problem of obtaining manually annotated training data. Yet, in terms of implementation, these RNN-based models have another difficulty in that the amount of data gets larger as the structure gets more sophisticated. This problem of large data size is particularly problematic in the Korean language, which lacks refined corpora. In this study, we introduce CTC algorithm that does not require force-alignment to create a Korean phoneme recognition model. Specifically, the phoneme recognition model is based on convolutional neural network(CNN) which requires relatively small amount of data and can be trained faster when compared to RNN based models. We present the results from two different experiments and a resulting best performing phoneme recognition model which distinguishes 49 Korean phonemes. The best performing phoneme recognition model combines CNN with 3hop Bidirectional LSTM with the final Phoneme Error Rate(PER) at 3.26. The PER is a considerable improvement compared to existing Korean phoneme recognition models that report PER ranging from 10 to 12."
자율주행 자동차 환경에서의 3D-LiDAR 와 딥러닝을 이용한 클러스터링 후보군 기반 실시간 객체 검출,2019,"['autonomous vehicle', '3d-LiDAR', 'clustering', 'deep learning', 'object detection']",국문 초록 정보 없음,"Recently, IT companies such as Google, NVIDIA, and NAVER have been also developing autonomous vehicle platform technologies. In particular, sensors for object detection in surrounding environments have been improved in recognition rates by applying multi-sensor systems using camera, LiDAR, and radar. With the increasing importance of recognition technology, 3D information-based recognition technologies have been actively advanced as a commercial product of 3D-LiDAR. In this paper, a candidate group of point-clouds from 3D-LiDAR is extracted using Euclidean clustering in order to reduce the processing time delay in RPN (Region Proposal Network), which is one of the basic schemes for existing object detection. Then, it proposes types of input slicing, based on the extracted candidates. In addition, the accuracy and the processing time using four CNN networks (Basic CNN, ResNet, VGG16, and MobileNet) are compared over not only the private data (CVLab dataset) obtained in actual road environment but also the publicly open KITTI dataset."
딥러닝 신경망을 이용한 신용카드 부도위험 예측의 효용성 분석,2019,"['딥러닝', '인공신경망', '신용카드', '부도위험', '머신러닝', 'Deep Learning', 'Artificial Neural Network', 'Credit Card', 'Default Risk', 'Machine Learning']","본 연구는 국내․외 금융시장에서 아직 활성화되지 못한 딥러닝 신경망(deep learning neural network) 알고리즘을 이용해 신용카드 부도위험 예측의 정확도 향상 가능성에 대해서 점검한다. 이를 위해 기존 머신러닝 알고리즘(Logistic, SVM, Random Forest, Lasso 등)을 딥러닝 신경망 분석의 성능 점검을 위한 비교 지표로 활용한다. 우선, 딥러닝 신경망은 두 개의 은닉층(hidden layers)과 다섯 개의 뉴런(neuron)으로 구축하고, 활성함수(activation function)와 초기값(initial value) 설정방법에 따른 예측정확도를 도출한다. 그 결과 딥러닝 신경망 분석이 기존 머신러닝 알고리즘 보다 최소 0.6%p에서 최대 6.6%p 성능이 향상된 것으로 나타났다. 이 중 가장 높은 예측 정확도를 보인 활성함수와 초기값 설정방식은 ReLU(rectified linear units)와 Xavier(2010)이고 이를 기준으로 은닉층과 뉴런의 수를 각각 최대 10개와 25개까지 늘려 분석한 결과에서도 유사한 결과가 나타났다. 다만, 기존 연구에서와 같이 은닉층과 뉴런의 수의 증가에 따른 뚜렷한 성능의 향상은 나타나지 않았다. 또한, 이미지 식별 분야에서 높은 성능을 보였던 Dropout과 CNN(convolution neural network) 모델도 예측 정확도에서 큰 차이를 보이지 않았다. 이는 여기에서 사용된 신용카드 데이터가 다수 픽셀(pixel)로 이루어진 이미지 데이터와 비교해 양적․질적 한계가 있기 때문으로 판단된다. 한편, 본 연구에서 사용된 개인의 신용카드 부도 데이터는 횡단면 자료이기 때문에 시계열 데이터에서 높은 성능을 나타내는 RNN(recurrent neural network) 및 LSTM(Long- Short Term Memory) 등의 딥러닝 신경망 알고리즘을 사용하지는 않았다. 따라서 추후 시계열 자료가 포함된 빅데이터를 통해 이들 딥러닝 신경망 방법론을 적용한다면, 현재의 다양한 금융시장의 식별문제(신용등급, 연체율, 금리산정)에 있어 보다 향상된 결과를 도출할 수 있을 것으로 기대된다.","This study aims to discuss the usefulness of the deep learning neural network and the possibility of the deep learning neural network analysis in judging credit information by using credit card default data. Deep learning neural network analysis in the financial sector excluding the current stock price prediction model is under limited research. It is mainly used for upgrading models of the credit rating (Kvamme et al., 2016, 2018; Tran, 2016; Luo, 2017) and the delinquency rate (Sirignano et al., 2018).In the credit card market, it is focused on credit card issuance and fraud detection model (Ramanathan, 2014, Niimi, 2015). As mentioned earlier, there has not been much analysis of deep learning neural network using financial market data. This is because the study of deep learning neural networks is actively carried out mainly in the field of computer science such as image, speech recognition, natural language processing. Additionally, Researchers in the financial sector have difficulty learning deep learning algorithms and setting up a computer runtime environment. It is also difficult to apply the algorithm to financial data due to lower dimension than the image. Nowadays, financial companies have been interested in machine learning and are increasing their recruitment, but it is still in the stage of verifying the possibility of deep learning neural network.Therefore, This study examines the possibility of improving the accuracy of credit card default risk prediction by using a deep learning neural network algorithm. To do this, we use existing machine learning algorithms (Logistic, SVM, Random Forest, Lasso, etc.) as a comparison index for performance check of deep learning neural network analysis. Firstly, the deep learning neural network is constructed with two hidden layers and five neurons, and derives the prediction accuracy according to the activation function and the initial value setting method. There are Sigmoid, ReLU, tanh and Maxout as active functions, and random value, Xavier, RBM, He’s as initialization methods. Based on this, we compare the accuracy of existing machine learning algorithms. As a result, the deep learning neural network analysis showed performance improvement between 0.6% and 6.6%p compared to the existing machine learning algorithms (Logistic, SVM, Random Forest, Lasso, etc.). Among these results, the active function and the initial value setting method with the highest prediction accuracy are ReLU (rectified linear units) and Xavier initialization. However, there is no significant improvement in performance with increasing number of hidden layers and neurons up to 10 and 25, respectively. Also, the dropout and CNN (convolution neural network) models, which showed high performance in the field of image identification, showed no significant difference in prediction accuracy.Nevertheless, it could be interpreted that the increase of hidden layers can improve the accuracy of estimation because the highest accuracy (0.8161) and the AUC (0.7726) are observed for 10 hidden nodes and 15 neurons.However, we can’t say that accuracy increases linearly by the number of hidden layers and neurons. These limitation could be due to the quantitative and qualitative limitations of the credit card data used here. We did not use recurrent neural network (RNN) and long-short term memory (LSTM) models since the personal default data for credit card used in this study is cross-sectional data. These method are for Time-Series data. Therefore, it is expected that it will be able to obtain better results in identification problems (credit rating, delinquency rate, interest rate calculation) of present various financial markets if these deep learning neural network methodologies are applied through big data including time series data.This study can be turned into a question of how deep learning analysis can lower the default risk and delinquency rate by using financial data from a practical point of ..."
A Multi-Stage Convolution Machine with Scaling and Dilation for Human Pose Estimation,2019,"['CNN', 'Human pose estimation', 'Multi-stage', 'Pyramid stacking', 'Dilation', 'Gating']",국문 초록 정보 없음,"Vision-based Human Pose Estimation has been considered as one of challenging research subjects due to problems including confounding background clutter, diversity of human appearances and illumination changes in scenes. To tackle these problems, we propose to use a new multi-stage convolution machine for estimating human pose. To provide better heatmap prediction of body joints, the proposed machine repeatedly produces multiple predictions according to stages with receptive field large enough for learning the long-range spatial relationship. And stages are composed of various modules according to their strategic purposes. Pyramid stacking module and dilation module are used to handle problem of human pose at multiple scales. Their multi-scale information from different receptive fields are fused with concatenation, which can catch more contextual information from different features. And spatial and channel information of a given input are converted to gating factors by squeezing the feature maps to a single numeric value based on its importance in order to give each of the network channels different weights. Compared with other ConvNet-based architectures, we demonstrated that our proposed architecture achieved higher accuracy on experiments using standard benchmarks of LSP and MPII pose datasets."
Convolutional Neural Network-Based Channel Matrix Recovery for MIMO Communication,2019,"['CNN', 'Deep learning', 'Channel Matrix Recovery', 'Dropout', 'MIMO Communication']",국문 초록 정보 없음,다국어 초록 정보 없음
Text Classification and Application of Fusion of Deep Learning,2019,"['LSTM', 'CNN', 'deep learning', 'multi-category', 'accuracy']",국문 초록 정보 없음,다국어 초록 정보 없음
인공지능을 적용한 협업 이동로봇의 하드웨어 제작 및 ROS 구성,2019,"['ROS', 'CNN', 'Cooperative Robot', 'SLAM &amp', 'Navigation', 'Sharing Computing Power']",국문 초록 정보 없음,다국어 초록 정보 없음
사람 재인식을 위한 개선된 PersonNet,2019,"['PersonNet', 'CNN', 'Inception Layer', 'Cross neighborhood difference', 'Person re-Identification']","이 논문에서는 사람 재식별 모델인 PersonNet의 성능을 개선하는 방법을 제안하고 실험한다. 특징점 추출을 위해 인셉션 레이어를 접목하여, 기존 32개의 특징점을 154개로 증가시켜 강화하였다. 또한, PersonNet에서 사용하는 CND 방식을 수정하여 비대칭성을 완화하였고, 보행자 이미지의 특징점을 3부분으로 나누어 가중치를 적용한 방법을 적용하여 특징을 더 뚜렷하게 파악하도록 하였다. 성능 평가를 위해 CUHK01, CUHK03 그리고 Market-1501 3가지의 데이터베이스를 사용하였고 실험결과 27～31% 성능이 개선되었다.","This paper propose and experiment advanced PersonNet, a human identification model, with advanced performance. We apply the inception layer to extract feature points, and increase the existing 32 feature points to 154. Also, we modify the CND method used by PersonNet to mitigate asymmetry, and apply weights to the feature map of pedestrian images in three parts, thereby making the features more distinct. Three databases were used for performance evaluation：CUHK01, CUHK03 and Market-1501. The experiment results showed 27-31% improvement in performance."
Adult Access Detection System based on Clothing Information,2019,"['Artificial Information', 'CNN', 'Clothing Information', 'Training data']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝 기반의 이미지 분류를 이용한 패션 이미지 검색 웹사이트,2019,"['Computer vision', 'CNN', 'Deep learning', 'Image classification', 'Web']","기존에 존재하는 패션 웹 사이트 에서는 상의, 하의 등의 품목에서는 한 가지 종류의 옷에 대한 검색결과만 보여주기 때문에사용자가 원하는 옷에 대한 조합을 찾을 수 없다. 또 패션 시장이 성장함에 따라 소비자들은 다양한 패션 정보를 찾을 수 플랫폼을 요구하고 있다. 이러한 문제를 해결하고자 하여 딥러닝을 통한 이미지분류를 웹 사이트와 연동하고 SNS 기능을 접목하는 아이디어를 고안해냈다. 웹 사이트에 사용자가 본인의 이미지을 업로드하여 딥러닝 서버를 통해서 이미지의 특징을 파악하고 분류하여 저장한다. 사용자들은 저장된 정보를 가지고 여러 조합을 통해 원하는 이미지들을 검색할 수 있다. 또 SNS 기능을 통해사용자간의 커뮤니케이션이 활발하게 이루어질 수 있다. 이를 통해서 기존에 존재하는 패션 관련 사이트의 문제를 해결하는 방안을 마련하였다.","Existing fashion web sites show only the search results for one type of clothes in items such as tops and bottoms. As the fashionmarket grows, consumers are demanding a platform to find a variety of fashion information. To solve this problem, we devised theidea of linking image classification through deep learning with a website and integrating SNS functions. User uploads their ownimage to the web site and uses the deep learning server to identify, classify and store the image’s characteristics. Users can use thestored information to search for the images in various combinations. In addition, communication between users can be activelyperformed through the SNS function. Through this, the plan to solve the problem of existing fashion-related sites was prepared."
Convolution Neural Network를 이용한 도로인식 모델,2019,"['Deep Learning', 'CNN', 'Road Recognition', 'Image Processing']",국문 초록 정보 없음,다국어 초록 정보 없음
가시광-근적외선 혼합 영상에서의 얼굴인식에 관한 연구,2019,"['Face Recognition', 'CNN (Convolutional Neural Networks)', 'Deep Learning']",국문 초록 정보 없음,다국어 초록 정보 없음
안저영상의 영역분할에 사용된 합성곱 신경망 방식의 혈관 조영 영상의 적용,2019,"['U-Net', 'CNN', 'Deep learning', 'retinal image', 'semantic segmentation']",국문 초록 정보 없음,다국어 초록 정보 없음
SHVC 부호화 성능 개선을 위한 딥러닝 기반 계층간 참조 픽처 생성 방법,2019,"['Scalable HEVC', 'CNN', 'Deep learning', 'Super resolution', 'Inter-layer prediction']","본 논문에서는 SHVC 부호화 성능 개선을 위하여 딥러닝 기반 계층간 예측을 위한 참조 픽처 생성 방법을 제안한다. 새로운 참조 픽처를 생성하기 위하여 DCT-IF기반 업샘플링 된 픽처를 VDSR 네트워크를 이용한 필터링을 진행하는 구조와 SHVC 계층간 참조 픽처를 생성하기 위한 트레이닝 방법에 대해 설명한다. 제안하는 방법은 SHM 12.0 기반으로 구현되어 있다. 성능 평가를 위하여 사전 학습을 이용하여 계층간 예측 픽처를 생성하는 방법과 비교를 진행하였다. 그 결과 상위 계층의 부호화 성능은 사전 학습을 이용한 방법 대비 최대 13.14%의 비트 감소, SHM 대비 최대 15.39%의 비트 감소율을 보였고, 평균 6.46%의 비트 감소율을 보였다.",다국어 초록 정보 없음
도로 영역 검출을 위한 카메라 라이다 융합 방법,2019,"['Sensor fusion', 'CNN', 'Segmentation', 'lidar', 'camera']",국문 초록 정보 없음,다국어 초록 정보 없음
심층학습 활성함수에 따른 표정 인식 성능 분석,2019,"['Activation function', 'CNN', 'Deep-Learning', 'Facial expression recognition']",국문 초록 정보 없음,다국어 초록 정보 없음
FCN을 이용한 UAV object detection and tracking 알고리즘 연구,2019,"['Fully convolutional neural network', 'CNN', 'OpenCV', 'Loss function', 'UAV']",국문 초록 정보 없음,다국어 초록 정보 없음
거래 기반 블록체인 네트워크 이중지불 탐지에 대한 연구,2019,"['Blockchain', 'Convolution Neural Network (CNN)', 'Double-Spending Attack', 'Network', 'Bitcoin Gold']",국문 초록 정보 없음,"Blockchain is a technological concept that forms the basis for cryptocurrency used in cryptocurrency systems such as bitcoin and etherium. However, because there is no central institution and it consists of transactions among participants in the network, a series of double-spending attacks occurred by rogue miners, securing 51% of the computing power of a particular blockchain network and resulting in a massive outflow of funds. The purpose of this paper is to propose the method to detect blockchain network double-spending attacks in earlier stage by distinguishing the differences between ordinary transactions and double spending attacks."
Image to Text Conversion Technique for Anti-Plagiarism System,2019,"['Convolutional Neural Network (CNN)', 'Image Processing', 'Optical Character Recognition (OCR)', 'Plagiarism']",국문 초록 정보 없음,"Background/Objectives: The IMAGE TO TEXT CONVERSION TECHNIQUE FOR ANTI-PLAGIARISM SYSTEM is a design project on how the Optical Character Recognition will be utilized in order to extract text from images that can be used to increase the accuracy rate of an anti-plagiarism checker. It also highlights the integration of Convolutional Neural Network and its effect in the result of the conversion. Methods/Statistical analysis: Optical Character Recognition is a technology that recognizes text within an image. It is commonly used to recognize text in scanned documents, but it serves many other purposes as well. While Convolutional Neural network is a category of neural networks that have been proven very effective in performing image recognition and classification. The main objective of the study is to design a software that will convert images of text into plain editable text. The study aims to use a specific algorithm to extract useful information from the images. Findings: It will integrate the two algorithm, convolutional neural network and optical character recognition technology in order to develop a software. The input of the software is a document in .docx format and will generate an output in the same format. Improvements/Applications: This software will be an aid to the existing anti-plagiarism checkers to generate a more thorough and better plagiarism"
딥런닝 기반의 프레임 유사성을 이용한화재 오탐 검출 개선 연구,2019,"['deep learning', 'faster r-cnn', 'fire detection', 'smoke detection', 'ssim']","화염 및 연기 감지 알고리즘 연구는 다양한 모양, 빠른 확산 및 색상으로 인해 컴퓨터 비전에서 어려운 과제이다. 일반적인센서 기반 화재 감지 시스템의 성능은 환경 요인 (실내 및 화재발생 위치)에 따라 크게 제한된다. 이러한 문제를 해결하기위해 딥러닝 방법을 적용하였으며, 이것은 물체의 형상을 특징으로 추출하므로 비슷한 형상이 프레임내에 존재하면 오탐으로검출 될 수 있다. 본 연구는 화재 오탐 검출 개선을 위해 딥런닝 사용 전과 후에 프레임 유사성을 이용하여 오탐을 줄이는새로운 알고리즘을 제안한다. 실험결과 제안된 방법을 적용하여 화재 검출 성능은 유지를 하면서 오탐 부분이 최소 30% 까지 감소하는 결과를 얻을 수 있었다. 제안된 방법의 오탐 검출 성능이 뛰어나다는 것을 확인하였다.","Fire flame and smoke detection algorithm studies are challenging task in computer vision due to the variety of shapes,rapid spread and colors. The performance of a typical sensor based fire detection system is largely limited byenvironmental factors (indoor and fire locations). To solve this problem, a deep learning method is applied. Because itextracts the feature of the object using several methods, so that if a similar shape exists in the frame, it can be detectedas false postive. This study proposes a new algorithm to reduce false positives by using frame similarity before usingdeep learning to decrease the false detection rate. Experimental results show that the fire detection performance ismaintained and the false positives are reduced by applying the proposed method. It is confirmed that the proposed methodhas excellent false detection performance"
Modeling the Dynamics of Quadrotor Using Convolutional Neural Network,2019,"['System identification', 'quadrotor', 'dynamics', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
단일 영상 비균일 블러 제거를 위한 다중 학습 구조,2019,"['Dynamic Motion Deblurring', 'CNN', 'Motion Estimation', 'Multi-task Architecture']",국문 초록 정보 없음,"We present a novel deep learning architecture for obtaining a latent image from a single blurry image, which contains dynamic motion blurs through object/camera movements. The proposed architecture consists of two sub-modules: blur image restoration and optical flow estimation. The tasks are highly related in that object/camera movements make cause blurry artifacts, whereas they are estimated through optical flow. The ablation study demonstrates that training multi-task architecture simultaneously improves both tasks compared to handling them separately. Objective and subjective evaluations show that our method outperforms the state-of-the-arts deep learning based techniques."
딥러닝의 모델 학습 과정 개선을 위한 배치 정규화에 대한 연구,2019,"['Batch Normalization', 'Model Parameter', 'CNN', 'EMNIST', 'Fashion MNIST']",국문 초록 정보 없음,다국어 초록 정보 없음
캡차 이미지 인식을 통한 개선된 캡차 이미지 생성 알고리즘,2019,"['Captcha', 'Convolutional Neural Network(CNN)', 'OpenCV', 'Pixel shift']",국문 초록 정보 없음,다국어 초록 정보 없음
Deep Learning Method for Animal Image Classification,2019,"['Deep Learning Method', 'CNN', 'Training Model', 'NumPy Files']",국문 초록 정보 없음,다국어 초록 정보 없음
Spectrogram Approach for Gait Classification using Deep Convolutional Neural Networks,2019,"['Gait classification', 'Deep CNN', 'Robotic intelligence']",국문 초록 정보 없음,다국어 초록 정보 없음
Interworking technology of neural network and data among deep learning frameworks,2019,"['AI', 'AlexNet', 'Caffe', 'CNN', 'deep learning', 'interworking', 'neural network', 'NNEF', 'parser', 'Tensorflow']",국문 초록 정보 없음,"Based on the growing demand for neural network technologies, various neural network inference engines are being developed. However, each inference engine has its own neural network storage format. There is a growing demand for standardization to solve this problem. This study presents interworking techniques for ensuring the compatibility of neural networks and data among the various deep learning frameworks. The proposed technique standardizes the graphic expression grammar and learning data storage format using the Neural Network Exchange Format (NNEF) of Khronos. The proposed converter includes a lexical, syntax, and parser. This NNEF parser converts neural network information into a parsing tree and quantizes data. To validate the proposed system, we verified that MNIST is immediately executed by importing AlexNet's neural network and learned data. Therefore, this study contributes an efficient design technique for a converter that can execute a neural network and learned data in various frameworks regardless of the storage format of each framework."
도심 자율주행 제어시스템을 위한 컨볼루션 신경망 기반 도로 차선모델 추정,2019,"['Deep Learning (딥 러닝)', 'Convolutional Neural Networks (CNN', '컨볼루션 신경망)', 'Lane Keeping System (차로 유지 시스템)', 'Autonomous Driving (자율 주행)', 'Road Lane Model (도로 차선 모델)']",국문 초록 정보 없음,"The lane keeping system (LKS) simulates the shape of the road as a cubic polynomial through a camera sensor. The control input, steering wheel angle, is calculated to follow the reference based on the vehicle motion model using the road coefficients. LKS can maintain the lane safe only when the lane information is valid and cannot guarantee the stability of the control system when there is no lane information at all or the sensor fail for a long period of time. In this paper, we propose a parallel deep convolutional neural network (P-DCNN) that generates the road lane model for urban driving environments. The data for training and validation is collected by our in-vehicle logging systems and experiment was performed through the computational simulation."
Performance Improvements of Deep Residual Convolutional Network with Hyperparameter Optimizations,2019,"['Image recognition', 'Convolutional Neural Network (CNN)', 'Deep Residual Learning', 'Hyperparameters', 'Stochastic Gradient Descent']",국문 초록 정보 없음,다국어 초록 정보 없음
Classification of EEG for Dementia Patients with Convolutional Neural Network,2019,"['Electroencephalography(EEG)', 'Dementia', 'Convolutional Neural Network(CNN)', 'Mechine Learning']",국문 초록 정보 없음,다국어 초록 정보 없음
자율주행을 위한 주변차량 cut-in 의도 판단 알고리즘 개발,2019,"['자율주행', 'cut-in', '의도 판단', 'CNN', 'LSTM', 'PreScan', 'Vissim']",국문 초록 정보 없음,다국어 초록 정보 없음
Implementation of Melody Playback Method through Image Classification and Stroke Analysis,2019,"['Music', 'Image classification', 'Stroke analysis', 'Audioization', 'CNN', 'Google Quick Draw']",국문 초록 정보 없음,"In this study, we devised a application that generates and reproduces music by analyzing images received from a user. It was aimed not only to capture the technical meaning of auditioning images, but also to express emotions and intentions in user's images. In the proposed application, a user draws a picture of a desired object. The application uses artificial intelligence to determine which object an image is. After that, the emotions that can be connected with each objects. The application determines the key that matches the mood through the emotion associated with the object. After setting a key suitable for the emotion, the user's stroke order is analyzed, and the melody is composed based on the extracted user’s stroke data. In the future, research on arts such as painting and music will be continued as well as implementing auditory expression of images. Based on this, we will present the direction to embody the artistic and intention in the image into music. It will also be a meaningful attempt as a direction of combination between engineering fields such as artificial intelligence for recognizing pictures and art fields such as picture analysis, and music production."
Implementation of Melody Playback Method through Image Classification and Stroke Analysis,2019,"['Music', 'Image classification', 'Stroke analysis', 'Audioization', 'CNN', 'Google Quick Draw']",국문 초록 정보 없음,"In this study, we devised a application that generates and reproduces music by analyzing images received from a user. It was aimed not only to capture the technical meaning of auditioning images, but also to express emotions and intentions in user s images. In the proposed application, a user draws a picture of a desired object. The application uses artificial intelligence to determine which object an image is. After that, the emotions that can be connected with each objects. The application determines the key that matches the mood through the emotion associated with the object. After setting a key suitable for the emotion, the user s stroke order is analyzed, and the melody is composed based on the extracted user’s stroke data. In the future, research on arts such as painting and music will be continued as well as implementing auditory expression of images. Based on this, we will present the direction to embody the artistic and intention in the image into music. It will also be a meaningful attempt as a direction of combination between engineering fields such as artificial intelligence for recognizing pictures and art fields such as picture analysis, and music production."
Splicing Prediction Using Deep Learning,2019,"['Alternative splicing (AS)', 'convolution neural network (CNN)', 'cassette exons', 'feature representations']",국문 초록 정보 없음,다국어 초록 정보 없음
의류 생산 작업량 측정을 위한 합성곱 신경망 알고리즘의 데이터 증강 연구,2019,"['Data augmentation', 'Convolutional neural network', 'CNN', 'Counting', 'Clothes']",국문 초록 정보 없음,다국어 초록 정보 없음
Underground Cavity Detection Based on 3D Convolutional Neural Network,2019,"['3D GPR', 'deep learning', '3D CNN', 'underground object classification', 'voxel', 'cavity detection']",국문 초록 정보 없음,다국어 초록 정보 없음
인공지능 기반의 행동인식을 통한 개인 운동 트레이너 구현의 방향성 제시,2019,"['Healthcare', 'Fitness', 'Artificial Intelligence', 'Deep Running', 'CNN', 'RNN', '헬스케어', '피트니스', '인공지능', '딥러닝', '합성곱 신경망', '순환 신경망']","최근 딥러닝을 비롯한 인공지능 기술의 활용이 다양한 분야에서 활발해지고 있으며, 특히 딥러닝 기술 기반의 객체 인식 및 검출에 뛰어난 성능을 보이는 여러 알고리즘들이 발표되고 있다. 이에 본 논문에서는 사용자의 편의성이 효과적으로 반영된 모바일 헬스케어 애플리케이션 구현에 대한 적절한 방향성을 제시하고자 한다. 기존의 피트니스 애플리케이션들에 대한 이용 만족도 연구 및 모바일 헬스케어 애플리케이션에 대한 현황을 파악하여, 이로부터 피트니스 애플리케이션 시장에서의 생존과 우위를 확보하는 동시에, 최근 주목 받고 있는 인공지능 기술의 효과적인 적용에 의한 성능 개선을 통해 기존 이용자 유지 및 확대를 도모하고자 한다.","Recently, the use of artificial intelligence technology including deep learning has become active in various fields. In particular, several algorithms showing superior performance in object recognition and detection based on deep learning technology have been presented. In this paper, we propose the proper direction for the implementation of mobile healthcare application that user's convenience is effectively reflected. By effectively analyzing the current state of use satisfaction research for the existing fitness applications and the current status of mobile healthcare applications, we attempt to secure survival and superiority in the fitness application market, and, at the same time, to maintain and expand the existing user base."
딥 러닝 기반의 SIFT 이미지 특징 추출,2019,"['SIFT Feature extraction', 'Deep learning', 'VGG', 'CNN(Convolutional Neural Network)', 'Repeatability']","본 논문에서는 일정 크기로 자른 영상의 가운데 픽셀이 SIFT 특징점인지를 판별함으로써 SIFT 특징점을 추출하는 딥 뉴럴 네트워크(Deep Neural Network)를 제안한다. 이 네트워크의 데이터 세트는 DIV2K 데이터 세트를 33×33 크기로 잘라서 구성하고, 흑백 영상으로 판별하는 SIFT와는 달리 RGB 영상을 사용한다. 그라운드 트루스(ground truth)는 옥타브(scale, octave)를 0, 시그마(sigma)는 1.6, 간격(intervals)은 3으로 설정하여 추출한 RobHess SIFT 특징들로 구성한다. VGG-16을 기반으로 컨볼루션 층을 13개에서 23개와 33개로 점점 깊은 네트워크를 구성하고, 영상의 스케일을 증가시키는 방법을 바꿔가며 실험을 수행한다. 출력 층의 활성화 함수로 시그모이드(sigmoid) 함수를 사용한 결과와 소프트맥스(softmax) 함수를 사용한 결과를 비교하여 분석한다. 실험결과 제안한 네트워크가 99% 이상의 추출 정확도를 가질 뿐 아니라 왜곡된 영상에 대해서도 높은 추출 반복성을 가진다는 것을 보인다.",다국어 초록 정보 없음
인공지능 기반의 수면무호흡 환자 추정에 관한 연구,2019,"['Sleep apnea estimation', 'Artificial Intelligence', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
IoT 및 딥 러닝 기반 스마트 팜 환경 최적화 및 수확량 예측 플랫폼,2019,"['Agricultural', 'Analysis System', 'Artificial Intelligence System', 'CNN', 'Smart Farm']","본 논문은 농장의 바이오 센서 데이터를 수집해서 농장에서 재배중인 농작물의 질병을 진단하고, 그 해 수확량을 예측하는 IoT 및 딥 러닝 기반 스마트 팜 환경 최적화 및 수확량 예측 플랫폼을 제안한다. 이 플랫폼은 현재 날씨, 토양 미생물 등 수집 가능한 모든 정보를 수집하여 작물이 잘 성장할 수 있도록 농장 환경을 최적화하고, 농장에서 재배 중인 작물의 잎을 이용하여 작물의 질병을 진단하고, 그리고, 농장의 모든 정보를 사용하여 올해 수확량을 예측한다. 실험 결과 AEOM(Agricultural Environment Optimization Module)의 평균 정확도는 RF(Random Forest)보다 약 15%, GBD(Gradient Boosting Tree)보다 약 8% 높고, 데이터가 증가해도 RF나 GBD에 비해 정확도가 덜 감소한다. 선형 회귀에 따르면 정확도의 기울기는 ReLU의 경우 –3.641E-4, Sigmoid의 경우 –4.0710E-4, 계단함수의 경우 –7.4534E-4이다. 따라서 ReLU 사용시 정확도 기울기가 가장 낮으므로 테스트 데이터의 양이 증가함에 따라 ReLU는 다른 두 가지 활성화 기능보다 더 정확하다. 본 논문에서 제안한 EOYPP는 농장 전체를 관리하는 플랫폼으로 실제 농장에 도입된다면 국내 스마트 팜의 발전에 크게 이바지할 것이다.","This paper proposes “A Smart Farm Environment Optimization and Yield Prediction Platform based on IoT and Deep Learning” which gathers bio-sensor data from farms, diagnoses the diseases of growing crops, and predicts the year's harvest. The platform collects all the information currently available such as weather and soil microbes, optimizes the farm environment so that the crops can grow well, diagnoses the crop’s diseases by using the leaves of the crops being grown on the farm, and predicts this year's harvest by using all the information on the farm. The result shows that the average accuracy of the AEOM is about 15% higher than that of the RF and about 8% higher than the GBD. Although data increases, the accuracy is reduced less than that of the RF or GBD. The linear regression shows that the slope of accuracy is –3.641E-4 for the ReLU, –4.0710E-4 for the Sigmoid, and –7.4534E-4 for the step function. Therefore, as the amount of test data increases, the ReLU is more accurate than the other two activation functions. This paper is a platform for managing the entire farm and, if introduced to actual farms, will greatly contribute to the development of smart farms in Korea."
카메라를 이용한 Deep Convolutional Neural Network 기반 자율주행차량의 다중주기 횡방향 모션 제어,2019,"['Autonomous Driving', 'Deep convolutional neural network(Deep CNN)', 'Lateral motion control']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝을 이용한 야간 감시 열화상 카메라 개발에 관한 연구,2019,"['Thermal camera', 'Infrared', 'Deep learning', 'CNN', 'YOLO']",국문 초록 정보 없음,다국어 초록 정보 없음
사운드 소스 기반 머신러닝을 이용한 차량용 진단 시스템 설계,2019,"['Machine Learning(머신러닝)', 'Diagnostic(진단)', 'CNN(Convolutional Neural Network)']",국문 초록 정보 없음,다국어 초록 정보 없음
전층각막이식 수술의 수술자 편의를 위한 각막 홀더 및 시각적 보조기술의 개발,2019,"['Corneal transplant', 'Corneal Holder', 'Deep Learning', 'CNN', 'Cornea detection']",국문 초록 정보 없음,다국어 초록 정보 없음
DCT 신호처리 및 딥러닝 알고리즘 적용을 통한 채터 진단,2019,"['Milling machining', 'Machine tools', 'Vibration signal', 'CNN', 'Chatter diagnosis', 'DCT']",국문 초록 정보 없음,다국어 초록 정보 없음
Edge AI 기술을 이용한 영상 기반 재실감지 시스템의 개발,2019,"['human occupancy detection', 'object detection', 'Edge AI', 'CNN', 'inference accelerator', 'GPU', 'TPU']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝(CRNN)기법을 활용한 GPS궤적기반 교통이동수단 추정,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
Style Transfer Deep Learning Framework for Nighttime Robust Vehicle Detection in On-Road Mobile Platforms,2019,"['style transfer', 'Convolutional Neural Network (CNN)', '자율주행차량', '차량인식', 'self-driving car', 'vehicle detection']",국문 초록 정보 없음,다국어 초록 정보 없음
Deep Learning Based Tree Recognition rate improving Method for Elementary and Middle School Learning,2019,"['Machine Learning', 'Deep Learning', 'Convolutional Neural Network', 'CNN', 'Inception V3', 'Smart Device Education', '머신러닝', '딥러닝', '컨볼루션 신경망', '인셉션V3', '스마트기기교육']","본 연구의 목적은 수업 시 스마트기기에 적용할 수 있는 나무 이미지를 인식하고 분류하여 정확도를 측정할 수 있는 효율적인 모델을 제안하는 것이다. 2015개정 교육과정으로 개정되면서 초등학교 4학년 과학교과서의 학습 목표에서 스마트 기기 사용한 식물 인식이 새롭게 추가 되었다. 특히 나무 인식의 경우 다른 사물 인식과 달리 수형, 수피, 잎, 꽃, 열매의 부위별 특징이 있으며, 계절에 따라 모양 및 색깔의 변화를 거치므로 인식률에 차이가 존재한다. 그러므로 본 연구를 통해 컨볼루션 신경망 기반의 사전 학습된 인셉션V3모델을 이용하여 재학습 전 후의 나무 부위별 인식률을 비교한다. 또한 각 나무의 유형별 이미지 정확도를 결합시키는 방식을 통해 효율적인 나무 분류 방안을 제시하며 교육현장에서 사용하는 스마트기기에 적용 할 수 있을 것이라 기대한다.","The goal of this study is to propose an efficient model for recognizing and classifying tree images to measure the accuracy that can be applied to smart devices during class. From the 2009 revised textbook to the 2015 revised textbook, the learning objective to the fourth-grade science textbook of elementary schools was added to the plant recognition utilizing smart devices. In this study, we compared the recognition rates of trees before and after retraining using a pre-trained inception V3 model, which is the support of the Google Inception V3. In terms of tree recognition, it can distinguish several features, including shapes, bark, leaves, flowers, and fruits that may lead to the recognition rate. Furthermore, if all the leaves of trees may fall during winter, it may challenge to identify the type of tree, as only the bark of the tree will remain some leaves. Therefore, the effective tree classification model is presented through the combination of the images by tree type and the method of combining the model for the accuracy of each tree type. I hope that this model will apply to smart devices used in educational settings."
적응형 채널 어텐션 모듈을 활용한 복합 열화 복원 네트워크,2019,"['Image restoration', 'Deep learning', 'Channel attention', 'CNN', '영상복원', '딥러닝', '채널 어텐션', '합성곱신경망']",자율 주행 자동차나 소방 로봇과 같은 시스템에서 영상을 얻을 때 다양한 요인들로 인해 잡음，블러와 같은 열화가 발생한 다. 이런 열화된 영상에 직접 영상 분류와 같은 기술을 적용하기 어려워 열화 제거가 불가피하나 이러한 시스템들은 영상의 열화를 인식할 수 없어서 열화된 영상을 복원하는데 어려움이 있다. 본 논문에서는 영상에 적용된 열화를 인지하지 못하는 상황에서 여러 방법들로 열화된 영상으로부터 자연스럽고 선명한 영상을 복원하는 방법을 제안한다. 우리가 제안한 방법은 딥러닝 모델에 채널 어텐션 모듈과스깁 커넥션을사용하여 영상에 적용된 열화에 따라복원에 필요한 채널에 높은 가중치를 적용해 복합 열화 영상의 복원을 진행한다. 이 방법은 다른복합 열화복원 방법 에 비해 학습이 간단하고 기존의 다른 방법들에 비 해 높은 복합 열화 복원 성능을 낸다.,"The image obtained from systems such as autonomous driving cars or fire-fighting robots often suffer from several degradation such as noise, motion blur, and compression artifact due to multiple factor. It is difficult to apply image recognition to these degraded images, then the image restoration is essential. However, these systems cannot recognize what kind of degradation and thus there are difficulty restoring the images. In this paper, we propose the deep neural network, which restore natural images from images degraded in several ways such as noise, blur and JPEG compression in situations where the distortion applied to images is not recognized. We adopt the channel attention modules and skip connections in the proposed method, which makes the network focus on valuable information to image restoration. The proposed method is simpler to train than other methods, and experimental results show that the proposed method outperforms existing state-of-the-art methods."
Video Representation via Fusion of Static and Motion Features Applied to Human Activity Recognition,2019,"['Activity recognition', 'static features', 'motion features', 'trajectories', 'CNN', 'LSTM']",국문 초록 정보 없음,"In human activity recognition system both static and motion information play crucial role for efficient and competitive results. Most of the existing methods are insufficient to extract video features and unable to investigate the level of contribution of both (Static and Motion) components. Our work highlights this problem and proposes Static-Motion fused features descriptor (SMFD), which intelligently leverages both static and motion features in the form of descriptor. First, static features are learned by two-stream 3D convolutional neural network. Second, trajectories are extracted by tracking key points and only those trajectories have been selected which are located in central region of the original video frame in order to to reduce irrelevant background trajectories as well computational complexity. Then, shape and motion descriptors are obtained along with key points by using SIFT flow. Next, cholesky transformation is introduced to fuse static and motion feature vectors to guarantee the equal contribution of all descriptors. Finally, Long Short-Term Memory (LSTM) network is utilized to discover long-term temporal dependencies and final prediction. To confirm the effectiveness of the proposed approach, extensive experiments have been conducted on three well-known datasets i.e. UCF101, HMDB51 and YouTube. Findings shows that the resulting recognition system is on par with state-of-the-art methods."
Implementation of Melody Playback Method through Image Classification and Stroke Analysis,2019,"['Music', 'Image classification', 'Stroke analysis', 'Audioization', 'CNN', 'Google Quick Draw']","본 연구에서는 사용자로부터 입력받은 이미지를 분석하여 그에 맞는 음악을 생성, 재생하는 방법을 고안 하였다. 단순히 이미지를 청각화 하는 기술적인 의미 뿐 아니라 사용자의 이미지에 담긴 정서와 의도 또한 담아내는 것을 목표로 하였다. 사용자는 본 연구에서 제안된 어플리케이션에 원하는 물체를 그린다. 인공지능을 통해 이미지가 어떤 물체인지 판별 후, 그 물체와 이어질 수 있는 감정을 대응해 해당 멜로디의 감정과 분위기를 맞출 수 있도록 하였다. 정서에 알맞는 음정(key)를 설정한 뒤, 사용자가 이미지를 그릴 때 입력한 획순을 분석해 이를 기준으로 음계를 추출하여 선율을 생성하였다. 향후 이미지의 청각적 표현을 구현하는 것뿐만 아니라 그림에 대한 예술적인 이해와 의미 있는 음악을 만들어내기 위한 화성법 등의 작곡이론을 연구하여 이미지에 담긴 예술성과 의도를 음악에 담아낼 수 있는 한 가지 방향을 제시할 것이다. 또한 그림을 인식하고 판별하기 위한 인공지능 기술과 그림 분석, 음악 생성 등의 예술 분야를 결합해 공학과 예술의 융합이라는 방향으로서 의미 있는 시도가 될 것이다.","In this study, we devised a application that generates and reproduces music by analyzing images received from a user. It was aimed not only to capture the technical meaning of auditioning images, but also to express emotions and intentions in user s images. In the proposed application, a user draws a picture of a desired object. The application uses artificial intelligence to determine which object an image is. After that, the emotions that can be connected with each objects. The application determines the key that matches the mood through the emotion associated with the object. After setting a key suitable for the emotion, the user s stroke order is analyzed, and the melody is composed based on the extracted user’s stroke data. In the future, research on arts such as painting and music will be continued as well as implementing auditory expression of images. Based on this, we will present the direction to embody the artistic and intention in the image into music. It will also be a meaningful attempt as a direction of combination between engineering fields such as artificial intelligence for recognizing pictures and art fields such as picture analysis, and music production."
딥 러닝을 이용한 안면 여드름 분류 모델,2019,"['Deep Learning', 'Classification', 'Correlation Analysis', 'ACNE', 'CNN', '딥 러닝', '분류', '상관분석', '여드름', '컨볼루션 뉴럴 네트워크']","의학계에 다양하게 인공지능을 적용하는데 있어 한계는 우선적으로 해석자의 병증 이미지를 해석하는데 주관적 견해와 광범위한 해석자, 육체적 피로감 등이다. 그리고 병증마다 주석 달린 데이터 셋을 수집하는데 기간이 오래 걸린다는 것과 개발된 딥러닝 학습 알고리즘의 성능 저하가 없으면서도 충분한 훈련 데이터를 얻을지에 대한 의문이 있다는 것이다.이에 본 논문에서는 여드름 데이터 셋을 기준으로 기본 이미지를 수집할 때 선정 기준과 수집 절차에 대해 연구하고, Sequential 구조로 딥 러닝 기법을 적용하여 적은 손실률(5.46%)과 높은 정확도(96.26%)로 데이터를 분류하는 모델을 제안한다. Keras에서 기본 제공하는 모델과 비교실험을 통해 제안 모델의 성능을 비교 검증한다. 향후 본 논문에서 제안하는 여드름 분류 모델에 유사 현상들 적용하여 의학 및 피부 관리 분야에도 적용 가능할 것으로 예상된다.","The limitations of applying a variety of artificial intelligence to the medical community are, first, subjective views, extensive interpreters and physical fatigue in interpreting the image of an interpreter's illness. And there are questions about how long it takes to collect annotated data sets for each illness and whether to get sufficient training data without compromising the performance of the developed deep learning algorithm.In this paper, when collecting basic images based on acne data sets, the selection criteria and collection procedures are described, and a model is proposed to classify data into small loss rates (5.46%) and high accuracy (96.26%) in the sequential structure. The performance of the proposed model is compared and verified through a comparative experiment with the model provided by Keras. Similar phenomena are expected to be applied to the field of medical and skin care by applying them to the acne classification model proposed in this paper in the future."
U-Net 앙상블을 이용한 LeafNet의 성능향상,2019,"['합성곱 신경망', '이미지 분할', 'U-Net', '식물', '앙상블', 'CNN', 'Image Segmentation', 'Plant', 'Ensemble']",국문 초록 정보 없음,다국어 초록 정보 없음
동공 검출 기법의 최신 연구 동향,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
2.5D human pose estimation for shadow puppet animation,2019,"['Human pose estimation', 'shadow puppet', 'mapping network', '2.5 pose data', 'CNN']",국문 초록 정보 없음,"Digital shadow puppet has traditionally relied on expensive motion capture equipments and complex design. In this paper, a low-cost driven technique is presented, that captures human pose estimation data with simple camera from real scenarios, and use them to drive virtual Chinese shadow play in a 2.5D scene. We propose a special method for extracting human pose data for driving virtual Chinese shadow play, which is called 2.5D human pose estimation. Firstly, we use the 3D human pose estimation method to obtain the initial data. In the process of the following transformation, we treat the depth feature as an implicit feature, and map body joints to the range of constraints. We call the obtain pose data as 2.5D pose data. However, the 2.5D pose data can not better control the shadow puppet directly, due to the difference in motion pattern and composition structure between real pose and shadow puppet. To this end, the 2.5D pose data transformation is carried out in the implicit pose mapping space based on self-network and the final 2.5D pose expression data is produced for animating shadow puppets. Experimental results have demonstrated the effectiveness of our new method."
A Study of System Design of Automatic Vehicle Passengers Number Count for High Occupancy Vehicle Lanes,2019,"['HOV (High Occupancy Vehicle Lanes)', 'Deep Learning', 'Computer Vision', 'SIFT', 'HOG', 'CNN']",국문 초록 정보 없음,"In this paper, it includes a system design study that automatically checks the number of passengers of driving vehicles at HOV (High Occupancy Vehicle Lanes).  The system of this paper has constructed the trigger, camera, and counter. First, the trigger detects a target among a car driving at HOV. Next, The Camera will take a photo of the target. Last, the counter will count the passenger""s number at the photo. If the result is criteria over, the counter will notify a person in charge.  In order to count the number of inside passengers of the car driving at HOV, this paper includes a technology combination of deep running and computer vision."
Introduction of optimization algorithm and artificial intelligence application for performance evaluation of construction materials,2019,"['Micromechanics', 'Genetic algorithm (GA)', 'Particle swarm optimization (PSO)', 'Convolutional neural networks (CNN)']",국문 초록 정보 없음,다국어 초록 정보 없음
Finding robust domain from attacks: A learning framework for blind watermarking,2019,"['Digital watermarking', 'Color image watermarking', 'Blind watermarking', 'Convolutional neural network (CNN)']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>In recent years, some researchers have been interested in whether robustness and blindness can be simultaneously secured in a watermarking based on machine learning. However, achieving robustness against various attacks at once is still difficult for watermarking techniques. To address the problem, in this paper, we propose a learning framework for robust and blind watermarking based on reinforcement learning. We repeat three stages: watermark embedding, attack simulation, and weight updating. Specifically, we present image watermarking networks called WMNet using convolutional neural networks (CNNs). Two methods to embed a watermark are proposed and these two methods are based on backpropagation and autoencoder, respectively. We can optimize the robustness while carefully considering the invisibility of the watermarking system. The experimental results show that the trained WMNet captures more robust features than the current watermarking schemes, which use the frequency domain. The trade-off between the robustness and the invisibility of each technique was measured. Also, we adopt a visual masking with which we can achieve the appropriate balance between robustness and invisibility of the watermark. Our reinforcement-learning-based technique has better robustness than the existing techniques for both attacks seen in learning and unseen attacks. Due to the generalization ability of WMNet, moreover, it shows high robustness against multiple attacks and various levels of attacks which are not considered in training stage.</P>"
카메라의 성능 향상을 위한 시각적 방해 요소 개선 기법 조사,2019,[],"최적의 사진을 얻기 위해 시각적 방해요소들을 개선할 수 있는 기술들을 조사했다. CNN 모델을 활용한 HDR 이미지 재구성, 방해물과 원하는 피사체와의 깊이 차이에서 생기는 시차를 이용한 이미지 처리를 사용해서 시각적 방해요소를 개선하는 알고리즘을 기술했다.",다국어 초록 정보 없음
Radon Transform for Forgery Image Detection,2019,"['forgery image', 'imageforensics', 'feature vector', 'deep learning', 'convolutional neural network(CNN)']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝을 활용한 스마트 철강 코일 밴드 재질 감별 시스템 개발,2019,"['Coil band strap classification', 'Deep Learning', 'Convolutional Neural Network (CNN)', 'VGG19']",국문 초록 정보 없음,다국어 초록 정보 없음
Recurrence Plot 알고리즘을 이용한 버스트 신호 검출 성능 분석,2019,"['Burst signal', 'Energy detection', 'Recurrence plot (RP) algorithm', 'CNN', 'Deep learning']",국문 초록 정보 없음,다국어 초록 정보 없음
3D Res-Inception Network Transfer Learning for Multiple Label Crowd Behavior Recognition,2019,"['Densely crowed group', '3D Convolutional Neural Network (3D CNN)', '3D Res- Inception', 'Transfer Learning']",국문 초록 정보 없음,"The problem towards crowd behavior recognition in a serious clustered scene is extremely challenged on account of variable scales with non-uniformity. This paper aims to propose a crowed behavior classification framework based on a transferring hybrid network blending 3D res-net with inception-v3. First, the 3D res-inception network is presented so as to learn the augmented visual feature of UCF 101. Then the target dataset is applied to fine-tune the network parameters in an attempt to classify the behavior of densely crowded scenes. Finally, a transferred entropy function is used to calculate the probability of multiple labels in accordance with these features. Experimental results show that the proposed method could greatly improve the accuracy of crowd behavior recognition and enhance the accuracy of multiple label classification."
도시 구조물 분류를 위한 거리데이터 기반의 3층 구형 특징 이미지 생성,2019,"['라이다센서(LiDAR sensor)', '물체식별(Object identification)', '의미지도 작성(Semantic mapping)', '컨볼루셔널 뉴럴 네트워크(Convolutional Neural Network)']",국문 초록 정보 없음,"We propose to generate a three-layered spherical signature image for CNN(Convolutional Neural Network) classification. The proposed method consists of spherical layering, evidence accumulation, and RGB channeling. Threelayered spheres are generated to classify the origin point of its spheres. The surrounding points are projected onto three layers and updated the occupancy probability by Bayer’s rule. Three patterned layers are stacked for RGB channeling to generate representative images of one point. The novelty of our method is that we can give meaning to every individual point in a 3D Point cloud using only LiDAR data. Experimental results and evaluations in urban environments demonstrate the validity of the proposed methods."
한국어 음성 명령어 인식을 위한 자동데이터 구축,2019,"['Korean Speech Command', 'Speech Recognition', 'Automatic Data Construction', 'ResNet', 'CNN', '한국어 명령어 인식', '음성인식', '자동 데이터 구축', '레스넷', '합성곱신경망']","최근 화두가 되고 있는 AI분야에서 가장 큰 문제점은 학습데이터의 부족 문제를 꼽을 수 있다. 수동 데이터 구축에는 많은 시간과 노력이 소요되기에 개인이 손쉽게 필요 데이터를 구축하기는 매우 어렵다. 반면, 수동 데이터 구축에 비해 자동으로 구축하는 것은 높은 품질을 유지하는 것이 관건이다. 본 논문에서는 한국어 음성 명령어 인식기 개발에 필요한 데이터를 웹에서 자동으로 추출하고, 학습데이터로 사용할 수 있는 데이터를 자동으로 선별하는 방법을 소개한다. 특히, 자동 구축된 한국어 음성 데이터를 대상으로 우수한 성능을 보이는 ResNet기반의 수정 모델을 기반으로, 건강 및 일상생활도메인의 명령어 셋을 대상으로 적용가능성을 보이기 위한 실험을 진행하였다. 자동으로 구축된 데이터만을 사용한 일련의 실험에서 건강도메인은 ResNet15에서 89.5%, 일상생활도메인에서는 ResNet8에서 82%의 정확도를 보임으로써, 자동 수집 데이터의 활용 가능성을 검증하였다.","The biggest problem in the AI field, which has become a hot topic in recent years, is how to deal with the lack of training data. Since manual data construction takes a lot of time and efforts, it is non-trivial for an individual to easily build the necessary data. On the other hand, automatic data construction needs to handle data quality issue. In this paper, we introduce a method to automatically extract the data required to develop Korean speech command recognizer from the web and to automatically select the data that can be used for training data. In particular, we propose a modified ResNet model that shows modest performance for the automatically constructed Korean speech command data. We conducted an experiment to show the applicability of the command set of the health and daily life domain. In a series of experiments using only automatically constructed data, the accuracy of the health domain was 89.5% in ResNet15 and 82% in ResNet8 in the daily lives domain, respectively."
딥러닝 및 영상처리 기술을 활용한 콘크리트 균열 검출 방법,2019,"['콘크리트 균열', '균열 검출', '딥러닝', '영상처리', '합성곱신경망', 'Concrete Crack', 'Crack Detection', 'Deep Learning', 'Image Processing', 'CNN']","현행 균열조사 업무는 육안조사로 이루어지고 있어 점검자의 주관이 개입되어 점검 결과에 차이가 발생하거나, 측정오차가 발생할 여지가 있다. 이에 본 연구는 콘크리트 균열 조사의 객관성과 효율성을 높이기 위하여 딥러닝 네트워크 중 실시간 분석이 가능한 YOLO v.2를 활용하여 균열을 인지하고, 영상처리 기술을 활용하여 균열의 특성정보를 추출하는 프로세스를 제시하였다. 실험 결과, 실시간 분석이 가능한 검출속도와 정확도를 확보할 수 있었다. 본 연구의 결과는 시설물 하자진단 자동화 시스템 개발의 기초자료로 활용될수 있을 것이다.","Most of the current crack investigation work consists of visual inspection using simple measuring equipment such as crack scale. Thesemethods involve the subjection of the inspector, which may lead to differences in the inspection results prepared by the inspector, and maylead to a large number of measurement errors. So, this study proposes an image-based crack detection method to enhance objectivity andefficiency of concrete crack investigation. In this study, YOLOv2 was used to determine the presence of cracks in the image information toensure the speed and accuracy of detection for real-time analysis. In addition, we extracted shapes of cracks and calculated quantitatively,such as width and length using various image processing techniques. The results of this study will be used as a basis for the development ofimage-based facility defect diagnosis automation system."
Skeleton Joints 기반 행동 분류 모델 설계,2019,[],"키넥트는 RGBD 카메라로 인체의 뼈대와 관절을 3D 공간에서 스켈레톤 데이터수집을 가능하게 해주었다. 스켈레톤 데이터를 활용한 행동 분류는 RNN, CNN 등 다양한 인공 신경망으로 접근하고 있다. 본 연구는 키넥트를 이용해서 Skeleton Joints를 수집하고, DNN 기반 스켈레톤 모델링 학습으로 행동을 분류한다. Skeleton Joints Processing 과정은 키넥트의 Depth Map 기반의 Skeleton Tracker로 25가지 Skeleton Joints 좌표를 얻고, 학습을 위한 전처리 과정으로 각 좌표를 상대좌표로 변경하고 데이터 수를 제한하며, Joint가 트래킹 되지 않은 부분에 대한 예외 처리를 수행한다. 스켈레톤 모델링 학습 과정에선 3계층의 DNN 신경망을 구축하고, softmax_cross_entropy 함수로 Skeleton Joints를 집는 모션, 내려놓는 모션, 팔짱 낀 모션, 얼굴을 가까이 가져가는 모션 해서 4가지 행동으로 분류한다.",다국어 초록 정보 없음
딥러닝을 활용한 다발성 골절 분류,2019,"['딥러닝', '컨볼루션 신경망', '골절', '다중 레이블', 'Deep Learning', 'Convolutional Neural Network', 'Fracture', 'Multi-Label']","정형외과 의사는 컴퓨터 단층 촬영(CT)을 활용해 골절 환자의 골절 범주를 식별하고 치료 방법을 결정한다. 골절이 발생하게 되면 다발성 골절인 경우가 많고 골절 범주가 많기 때문에, 의사가 골절을 정확히 분류하기 위해서는 높은 전문성과 많은 노력이 필요하다. 이 논문에서는 골절 범주 식별을 다중 부류 분류 문제로 정의하고, 골절의 범주를 식별하기 위해 딥러닝을 사용하는 방법을 제안한다. 제안하는 딥러닝 모델은 GoogleNet과 유사한 형태로 골절의 특징을 추출하고, 다층퍼셉트론으로 각 골절 범주의 점수를 계산해 분류를 한다. 그리고 출력 노드의 점수가 특정 임계값 내에 있는 최대 4개의 골절 부류를 선택한다. 하반신 골절 CT 데이터에 대한 제안 방법의 정밀도는 73.3%, 재현율은 86.9%였다.","The orthopedists use computed tomography(CT) to identify fracture categories of fractured patients and determine their treatment. Fractures often result in multiple fractures which have various categories. Here it is required for orthopedists to have a high level of expertise and stressful examination. This paper casts the fracture category identifier task as a multi-label classification problem, and proposes a deep learning based method to it. The proposed deep learning model extracts the features of fractures with GoogleNet-like front-end and determines the fracture categories from the categorieswise score computed with back-end fully connected layer. The proposed method showed 73.3% precision and 86.9%recall for a CT dataset for lower body fracture in the experiments."
An Improved PeleeNet Algorithm with Feature Pyramid Networks for Image Detection,2019,[],국문 초록 정보 없음,"Faced with the increasing demand for image recognition on mobile devices, how to run convolutional neural network (CNN) models on mobile devices with limited computing power and limited storage resources encourages people to study efficient model design. In recent years, many effective architectures have been proposed, such as mobilenet_v1, mobilenet_v2 and PeleeNet. However, in the process of feature selection, all these models neglect some information of shallow features, which reduces the capture of shallow feature location and semantics. In this study, we propose an effective framework based on Feature Pyramid Networks to improve the recognition accuracy of deep and shallow images while guaranteeing the recognition speed of PeleeNet structured images. Compared with PeleeNet, the accuracy of structure recognition on CIFA-10 data set increased by 4.0%."
자율주행을 위한 공간적 경향성이 고려된 End-to-End Neural Network 설계,2019,"['Artificial Intelligence (인공 지능)', 'End-to-End Neural Network (엔드투엔드 신경망)', 'Convolutional Neural Network (CNN', '컨볼류션 신경망)', 'Spatial Dependency (공간적 경향성)', 'Autonomous Driving (자율주행)']",국문 초록 정보 없음,"Recently, autonomous driving and advanced driver assistance system (ADAS) have been actively researched in the automotive field. It is very important to consider the improvement of perception ability about a forward driving scene. However, the sensors capability maintains high quality when the driving condition is only ideal. There are so many road conditions and an environment in real driving situations. In this paper, we propose a steering wheel angle prediction model using a deep convolutional end-to-end neural network for various driving environments and road shapes. The image data for training and validation is UDACITY Challenge dataset and the experiment was performed through computational simulation."
신호등이 설치된 교차로 구역에서의 자율주행 시스템 구현,2019,"['Autonomous driving(자율주행)', 'Traffic light recognition(신호등인식)', 'A intersection driving(교차로 주행)', 'Coordinates map(좌표지도)', 'CNN(Convolutional Neural Network', '콘볼루션 신경망)']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝 기반 비속어 필터링 채팅 프로그램 설계 및 구현,2019,[],"최근에 게임이나 채팅 프로그램 내에서의 비속어 필터링은 금칙어 기반으로 운영되고 있다. 하지만 금칙어 기반의 프로그램은 여러 한계점을 보이며, 따라서, 본 논문에서는 ‘Text-CNN’을 활용한 딥러닝 기법에 기반하여 비속어 필터링 프로그램을 제안한다. 데이터의 자질을 ‘자모’ 단위로 전처리하여 학습시키고 어느 부분이 비속어인지 검출하여 마스킹 처리하는 ‘LIME 알고리즘’을 사용하여 우리의 프로그램을 이용하는 사용자들에게 바른 언어습관을 지향하며 더 나아가 올바른 인터넷 문화를 조성할 수 있도록 필터링 채팅 프로그램을 제안한다.",다국어 초록 정보 없음
모터 전류 신호를 이용한 출입문 부품의 고장진단,2019,"['Condition Based Maintenance(상태 기반 정비)', 'Railway door(철도 출입문)', 'Cam follower bearing(캠팔로워베어링)', 'Roller(롤러)', 'Motor current(모터 전류)', 'K-Nearest Neighbor(KNN)', 'Convolution Neural Network(CNN)']",국문 초록 정보 없음,다국어 초록 정보 없음
Ensemble convolutional neural networks for automatic fusion recognition of multi‐platform radar emitters,2019,"['deep learning', 'emitter recognition', 'ensemble learning', 'robustness', 'time‐frequency analysis']",국문 초록 정보 없음,"Presently, the extraction of hand‐crafted features is still the dominant method in radar emitter recognition. To solve the complicated problems of selection and updation of empirical features, we present a novel automatic feature extraction structure based on deep learning. In particular, a convolutional neural network (CNN) is adopted to extract high‐level abstract representations from the time‐frequency images of emitter signals. Thus, the redundant process of designing discriminative features can be avoided. Furthermore, to address the performance degradation of a single platform, we propose the construction of an ensemble learning‐based architecture for multi‐platform fusion recognition. Experimental results indicate that the proposed algorithms are feasible and effective, and they outperform other typical feature extraction and fusion recognition methods in terms of accuracy. Moreover, the proposed structure could be extended to other prevalent ensemble learning alternatives."
음소 단위 임베딩 모형을 이용한 감성 분석,2019,[],형태소 분석을 통하여 한국어 문장을 형태소 단위의 임베딩 및 학습 관련 연구가 되었으나 최근 비정형적인 텍스트 데이터의 증가에 따라 음소 단위의 임베딩을 통한 신경망 학습에 대한 요구가 높아지고 있다. 본 논문은 비정형적인 텍스트 감성 분석 성능 향상을 위해 음소 단위의 토큰을 생성하고 이를 CNN 모형을 기반으로 다차원 임베딩을 수행하고 감성분석을 위하여 양방향 순환신경망 모델을 사용하여 유튜브의 비정형 텍스트를 학습시켰다. 그 결과 텍스트의 긍정 부정 판별에 있어 90%의 정확도를 보였다.,다국어 초록 정보 없음
Image Denoising Methods based on DAECNN for Medication Prescriptions,2019,"['ROI', 'DAECNN', 'SSIM', 'PSNR', 'MSE', 'ROI', 'DAECNN', 'SSIM', 'PSNR', 'MSE']","본 연구는 환자의 알레르기 예방시스템을 구축하기 위해 스마트폰을 이용하여 저장된 처방전의 이미지잡음제거 를 위한 ROI 추출 방법에 중점을 두었다. 현재 ROI 추출은 제한된 실험 환경에서 좋은 성능을 보여 주었지만 실제 환경에서의 성능은 잡음으로 인해 좋지 않았다. 따라서 본 연구에서는 정확도 높은 ROI 추출을 위해 스마트폰 영상에 서 발생하는 잡음제거 방법을 제안한다. SMF, DIN, DAE, DAECNN(Denoising Autoencoder with Convolution Neural Network) and median filter with DAECNN(MF+DAECNN) 방법을 실험하였고 그 결과 DAECNN 및 MF + DAECNN 방법이 스마트폰에서 이미지의 잡음제거가 효과적임을 보여주었다. 성능 향상을 검증하기 위해 SSIM, PSNR 및 MSE 방법을 사용하였고 이 시스템은 OpenCV, C ++ 및 Python로 구현 및 실험되었고 실제 이미지에서 성능 테스트를 거쳐 자연잡음(natural noise)을 제거하는데 본 논문에서 제안한 DAECNN과 MF+DAECNN이 각 69%로 기존의 DAE 방법 55% 보다 상대적으로 높은 결과를 도출하였다.","We aimed to build a patient-based allergy prevention system using the smartphone and focused on the region of interest (ROI) extraction method for Optical Character Recognition (OCR) in the general environment. However, the current ROI extraction method has shown good performance in the experimental environment, but the performance in the real environment was not good due to the noisy background. Therefore, in this paper, we propose the compared methods of reducing noisy background to solve the ROI extraction problem. There five methods used as a SMF, DIN, Denoising Autoencoder(DAE), DAE with Convolution Neural Network(DAECNN) and median filter(MF) with DAECNN (MF+DAECNN). We have shown that our proposed DAECNN and MF+DAECNN methods are 69%, respectively, which is relatively higher than the conventional DAE method 55%. The verification of performance improvement uses MSE, PSNR and SSIM. The system has implemented OpenCV, C++and Python, including its performance, is tested on real images."
얼굴표정을 통한 감정 분류 및 음악재생 프로그램,2019,"['감성(emotion)', '얼굴표정인식(facial expression recognition)', '뮤직플레이어(music player)']","본 논문에서는 감성과 힐링, 머신러닝이라는 주제를 바탕으로 딥러닝을 통한 사용자의 얼굴표정을 인식하고 그 얼굴표정을 기반으로 음악을 재생해주는 얼굴표정 기반의 음악재생 프로그램을 제안한다. 얼굴표정 기반 음악재생 프로그램은 딥러닝 기반의 음악 프로그램으로써, 이미지 인식 분야에서 뛰어난 성능을 보여주고 있는 CNN 모델을 기반으로 얼굴의 표정을 인식할 수 있도록 데이터 학습을 진행하였고, 학습된 모델을 이용하여 웹캠으로부터 사용자의 얼굴표정을 인식하는 것을 통해 사용자의 감정을 추측해낸다. 그 후, 해당 감정에 맞게 감정을 더 증폭시켜줄 수 있도록, 감정과 매칭되는 노래를 재생해주고, 이를 통해, 사용자의 감정이 힐링 및 완화될 수 있도록 도움을 준다.",다국어 초록 정보 없음
Data Empowered Insights for Sustainability of Korean MNEs,2019,"['Korean Multinational Enterprises', 'Data mining', 'News media', 'Social media', 'Sustainability.']",국문 초록 정보 없음,"This study aims to utilize big data contents of news and social media for developing a corporate strategy of multinational enterprises and their global decision-making through the data mining technique, especially text mining. In this paper, the data of 2 news media (BBC and CNN) and 2 social media (Facebook and Twitter) were collected for the three global leading Korean companies (Samsung, Hyundai Motor Company, and LG) from April, 2018 to April, 2019. The findings of this paper have shown that traditional news media and also modern social media have become devastating tools to extract global trends or phenomena for businesses. Moreover, this presents that a company can adopt a two-track strategy through two different types of media by deriving the key issues or trends from news media channels and also grasping consumers’ sentiments, preference or issues of interest such as battery or design from social media. In addition, analyzing the texts of those media and understanding the association rules greatly contribute to the comparison between two different types of media channels to see the difference. Lastly, this provides meaningful and valuable data empowered insights to find a future direction comprehensively and develop a global strategy for sustainability of business."
안개영상의 의미론적 분할 및 안개제거를 위한 심층 멀티태스크 네트워크,2019,"['Semantic Segmentation', 'Dehazing', 'Deep Learning', 'Multi-task Learning']",국문 초록 정보 없음,"Image semantic segmentation and dehazing are key tasks in the computer vision. In recent years, researches in both tasks have achieved substantial improvements in performance with the development of Convolutional Neural Network (CNN). However, most of the previous works for semantic segmentation assume the images are captured in clear weather and show degraded performance under hazy images with low contrast and faded color. Meanwhile, dehazing aims to recover clear image given observed hazy image, which is an ill-posed problem and can be alleviated with additional information about the image. In this work, we propose a deep multi-task network for simultaneous semantic segmentation and dehazing. The proposed network takes single haze image as input and predicts dense semantic segmentation map and clear image. The visual information getting refined during the dehazing process can help the recognition task of semantic segmentation. On the other hand, semantic features obtained during the semantic segmentation process can provide cues for color priors for objects, which can help dehazing process. Experimental results demonstrate the effectiveness of the proposed multi-task approach, showing improved performance compared to the separate networks."
고밀도 비디오 캡션 생성을 위한 의미 특징 학습,2019,"['고밀도 비디오 캡션 생성', '의미 특징 학습', '주의 집중', 'dense video captioning', 'semantic feature learning', 'attention']","본 논문에서는 고밀도 비디오 캡션 생성을 위한 새로운 심층 신경망 모델을 제안한다. 고밀도 비디오 캡션 생성은 하나의 입력 비디오로부터 다수의 이벤트 구간들을 찾아내고, 이들 각각에 관한 자연어 설명 문장을 생성하는 작업이다. 기존의 모델들에서는 합성곱 신경망을 통해 입력 비디오의 시각 특징 만을 추출하여 사용한 것과는 달리, 본 논문에서 제안하는 모델에서는 행위, 물체, 배경, 사람 등 중요한 이벤트 구성 요소들을 효과적으로 표현할 수 있는 고수준의 의미 특징들을 추가적으로 활용하였다. 또한 제안 모델에서는 순환 신경망인 LSTM을 이용하여 비디오 안에 포함된 이벤트 시간 영역들을 탐지하였다. 또, 제안 모델에서는 중요도에 따라 선택적으로 입력 특징들에 집중할 수 있도록, 캡션 생성 과정에 주의집중 메커니즘을 적용하였다. 고밀도 비디오 캡션 생성을 위한 대용량 벤치마크 데이터 집합인 ActivityNet Captions 데이터 집합을 이용한 다양한 실험을 통해, 본 논문에서 제안한 모델의 높은 성능과 우수성을 확인할 수 있었다.","In this paper, we propose a new deep neural network model for dense video captioning.Dense video captioning is an emerging task that aims at both localizing and describing all events in a video. Unlike many existing models, which use only visual features extracted from the given video through a sort of convolutional neural network(CNN), our proposed model makes additional use of high-level semantic features that describe important event components such as actions, people, objects, and backgrounds. The proposed model localizes temporal regions of events by using LSTM, a recurrent neural network(RNN). Furthermore, our model adopts an attention mechanism for caption generation to selectively focus on input features depending on their importance. By conducting experiments using a large-scale benchmark dataset for dense video captioning, AcitivityNet Captions, we demonstrate high performance and superiority of our model."
초중고 교육을 위한 딥러닝 기반 암석 분류기 개발,2019,"['딥 러닝', '텐서플로우', '이미지 인식', '암석 이미지', '교육', 'deep learning', 'tensorflow', 'image recognition', 'rock image', 'education']",국문 초록 정보 없음,"These days, as Interest in Image recognition with deep learning is increasing, there has been a lot of research in image recognition using deep learning. In this study, we propose a system for classifying rocks through rock images of 18 types of rock(6 types of igneous, 6 types of metamorphic, 6 types of sedimentary rock) which are addressed in the high school curriculum, using CNN model based on Tensorflow, deep learning open source framework. As a result, we developed a classifier to distinguish rocks by learning the images of rocks and confirmed the classification performance of rock classifier. Finally, through the mobile application implemented, students can use the application as a learning tool in classroom or on-site experience."
A Novel Integrated Convolutional Neural Network via Deep Transfer Learning in Colorectal Images,2019,"['Colon Disease Classification', 'Convolutional Neural Networks', 'Transfer Learning']",국문 초록 정보 없음,"In this paper, we explore the use of current deep learning methods, convolutional neural networks (CNNs) in the field of computer-aided diagnosis systems to classify several endoscopic colon diseases. Transfer learning by fine-tuning deep convolutional neural networks (CNNs) is applied due to the limited amount of data. For this, state-of-the-art CNN architectures, such as VGG16, VGG19, InceptionV3, ResNet50, Inception-ResNet-V2, DenseNet169 were used for training and validating the dataset. However, these existing architectures cannot extract more dense endoscopic image features and have problem on similar-looking images of different category. Therefore, we propose a novel integrated convolutional neural network to develop a more accurate and highly efficient method for endoscopic image classification, which uses the features of earlier layers in the classification process and increases the receptive field of view at the end layers in the network. We compare and evaluate our performance using performance metrics Accuracy (ACC), Recall, Precision and F1-score. In our experimental results, the proposed method outperforms the existing architectures, obtaining an accuracy of about 92.4% on the test dataset."
Neural Network Learning-based Traffic Jam Prediction Technique,2019,[],국문 초록 정보 없음,"The accurate city-wide traffic congestion prediction can plays a vital role in management of the Transportation Network, it can assists both traffic administrators to take measures for maintaining smooth traffic flow and commuters to plan the optimal route in advance. Few algorithm has been proposed for congestion prediction based on Image data, but cannot perform well for large road network. This paper proposed an efficient congestion prediction algorithm based on convolutional neural network (CNN), long short-term memory (LSTM) and de -convolutional neural network (deCNN). The effectiveness of the proposed model is evaluated on Traffic Image data capture from Seoul Transportation Operation and Information Service (TOPIS), an online web service."
인공지능 기반의 토지피복분류 모델의 적용을 통한 농촌 용수구역 단위 토지이용 변화 분석,2019,"['토지이용변화', '인공지능', '용수구역']","농촌 용수구역은 많은 용수공급이 필요한 논 벼작물에 맞추어 설계, 운영 되어오고 있으나 최근 쌀소비량의 감소 및 정부정책 등의 영향으로 논의 밭으로의 전용이 이루어 짐에 따라 적절한 용수공급을 위한 논의 밭전환 양상 분석이 필요하다. 본 연구에서는 저수지 용수구역에 대해 인공지능 기반의 토지피복분류모델을 적용하고 토지이용 변화를 분석하고자 하였다. 수혜면적 200ha 이상의 211개 저수지 용수구역을 선정하고 2010년, 2016년도 2개년간의 정사영상을 이용하여, 인공지능 중 Convolutional Neural Network(CNN)기반의 토지피복 분류 모델을 적용하여 토지이용을 분류하였다. 논과 밭의 면적변화 양상을 용수구역의 위치적 특성을 분석을 진행하였다. 본 연구를 통해 지역에 따른 논의 밭전환 특성을 반영한 용수공급 운영의 결정에 기초자료로써 활용될 수 있을 것이다.",다국어 초록 정보 없음
A wavelet packet spectral subtraction and convolutional neural network based method for diagnosis of system health,2019,"['Diagnosis', 'Convolutional neural network', 'Wavelet packet decomposition', 'Vibration signal', 'Spectral subtraction', 'Prognosis health management']",국문 초록 정보 없음,"Health monitoring systems play a key role inside smart factories. To enhance the real-time capability and reliability of health monitoring systems, we propose a fully automatic method for machine diagnosis. Firstly, acquired vibration signals are converted into high-resolution images by wavelet packet spectral subtraction. Next, a trained convolutional neural network (CNN) automatically extracts important features and determines the current health of the machine. The performance of the proposed method is demonstrated by employing a diagnosis problem of a bearing system. The result shows an outstanding classification accuracy of 99.64 % even with a small amount of training data (5 % of the data)."
Real Time Object Detection Based on YOLO with Feature Filter Bank,2019,"['convolutional neural network', 'real-time object detection', 'YOLO', 'feature filter bank']",국문 초록 정보 없음,"Real-time object detection is one of the most important and challenging tasks in current object detection and classification fields. Lots of research work have contributed to improving the ability of detection and classification accuracy in the last decades. Also, recent research on computer vision is prevailing to improve the accuracy of video surveillance, robotic vision, self-driving cars, and many applications. YOLO (You Only Look Once) is one of the fastest CNN (Convolutional Neural Network) and, it is one of state of the art techniques fo performing real-time object detection tasks. However, there are still some localization problems. In this paper, we propose a network with feature filter bank to improve the performance of YOLO network. Experiments have shown that the object detection performance of the proposed network is improved."
Deep Learning-based Bird Sound Recognition System with Data Pre-processing,2019,[],국문 초록 정보 없음,"Over the past decade, scarecrows have begun moving from stand-alone scarecrows to scarecrows using Internet of Things (IOT) technology. This study focuses on building a “smart” scarecrow that recognizes and detects birds by bird sounds. We propose a bird sound recognition model based on data pre-processing and Convolutional Neural Network (CNN). The hypothesis has been established that noise elimination through data pre-processing is more effective than not using data pre-processing to recognize bird sounds. The results showed that the overall performance of the bird and non-bird sound classification through the pre-processing system was 79.8%, which was no different from that of a system without data preprocessing. However, the proposed model has a 4.81% improvement in non-bird sound classification performance compared to models without data preprocessing."
딥러닝 기반 실시간 손 제스처 인식,2019,"['Leap Motion', 'Deep Learning', 'VR', 'Gesture Recognition']",국문 초록 정보 없음,"In this paper, we propose a real-time hand gesture recognition algorithm to eliminate the inconvenience of using hand controllers in VR applications. The user's 3D hand coordinate information is detected by leap motion sensor and then the coordinates are generated into two dimensional image. We classify hand gestures in real-time by learning the imaged 3D hand coordinate information through SSD(Single Shot multibox Detector) model which is one of CNN(Convolutional Neural Networks) models. We propose to use all 3 channels rather than only one channel. A sliding window technique is also proposed to recognize the gesture in real time when the user actually makes a gesture. An experiment was conducted to measure the recognition rate and learning performance of the proposed model. Our proposed model showed 99.88% recognition accuracy and showed higher usability than the existing algorithm."
실내 복도환경에서의 컨벌루션 신경망을 이용한 드론의 자율주행 연구,2019,[],국문 초록 정보 없음,"Autonomous driving of drone indoor must move along a narrow path and overcome other factors such as lighting, topographic characteristics, obstacles. In addition, it is difficult to operate the drone in the hallway because of insufficient texture and the lack of its diversity comparing with the complicated environment. In this paper, we study an autonomous drone navigation using Convolution Neural Network(CNN) in indoor environment. The proposed method receives an image from the front camera of the drone and then steers the drone by predicting the next path based on the image. As a result of a total of 38 autonomous drone navigation tests, it was confirmed that a drone was successfully navigating in the indoor environment by the proposed method without hitting the walls or doors in the hallway."
합성곱 신경망 기반의 PPG 신호 동잡음 구간 검출,2019,"['광맥파계', '생체신호', '동잡음', '인공 신경망', '합성곱 신경망', 'Photoplethysmographic', 'Bio-signal', 'Motion artifact', 'Artificial neural network', 'Convolutional neural network']",국문 초록 정보 없음,"Among the various bio-signals, Photoplethysmographic (PPG) is widely used in areas such as u-health and human factor evaluation due to its low cost of measurement and freedom of user’s motion. Despite its advantages, PPG signal tends to be corrupted by the movement of user. In this study, we proposes the method for detecting the motion artifact in PPG signals using CNN (Convolutional Neural Network). Continuous PPG signals were divided into multiple pulse signals, converted to image, and then each pulse signal is used for training. We have used 3,000 normal signals and 3000 corrupted signals from PhysioNet database for training. With the proposed method, the signals corrupted by motion artifact were successfully detected with 92% accuracy."
딥러닝 기반 BIM(Building Information Modeling) 벽체 하위 유형 자동 분류 통한 정합성 검증에 관한 연구,2019,"['BIM', 'IFC', '하위 유형 분류', '건축 벽체', '딥러닝', 'BIM', 'IFC', 'Subtype Classification', 'Architectural Walls', 'Deep Learning']",국문 초록 정보 없음,"With Building Information Modeling(BIM) becoming the de facto standard for data sharing in the AEC industry, additional needs have increased to ensure the data integrity of BIM models themselves. Although the Industry Foundation Classes provide an open and neutral data format, its generalized schema leaves it open to data loss and misclassifications This research applied deep learning to automatically classify BIM elements and thus check the integrity of BIM-to-IFC mappings. Multi-view CNN(MVCC) and PointNet, which are two deep learning models customized to learn and classify in 3 dimensional non-euclidean spaces, were used. The analysis was restricted to classifying subtypes of architectural walls. MVCNN resulted in the highest performance, with ACC and F1 score of 0.95 and 0.94.MVCNN unitizes images from multiple perspectives of an element, and was thus able to learn the nuanced differences of wall subtypes.PointNet, on the other hand, lost many of the detailed features as it uses a sample of the point clouds and perceived only the 'skeleton' of the given walls."
GAN-based shadow removal using context information,2019,"['Shadow Removal', 'Generative Adversarial Network', 'Deep-Learning']",국문 초록 정보 없음,"When dealing with outdoor images in a variety of computer vision applications, the presence of shadow degrades performance. In order to understand the information occluded by shadow, it is essential to remove the shadow. To solve this problem, in many studies, involves a two-step process of shadow detection and removal. However, the field of shadow detection based on CNN has greatly improved, but the field of shadow removal has been difficult because it needs to be restored after removing the shadow. In this paper, it is assumed that shadow is detected, and shadow-less image is generated by using original image and shadow mask. In previous methods, based on CGAN, the image created by the generator was learned from only the aspect of the image patch in the adversarial learning through the discriminator. In the contrast, we propose a novel method using a discriminator that judges both the whole image and the local patch at the same time. We not only use the residual generator to produce high quality images, but we also use joint loss, which combines reconstruction loss and GAN loss for training stability. To evaluate our approach, we used an ISTD datasets consisting of a single image. The images generated by our approach show sharp and restored detailed information compared to previous methods."
Automatic Segmentation Method of Phalange Regions Based on Residual U-Net and MSGVF Snakes,2019,"['Rheumatoid Arthritis', 'Osteoporosis', 'Computer Aided Diagnosis', 'Convolutional Neural Network', 'Microscopy Via Multiscale Gradient Vector Flow Snakes']",국문 초록 정보 없음,"Bone diseases include rheumatoid arthritis and osteoporosis. Although visual screening using computed radiography (CR) images is an effective method for diagnosing osteoporosis, there are some similar diseases that exhibit low bone mass status. To this end, we aim to develop a computer-aided diagnostic (CAD) system to support the automatic diagnosis of osteoporosis from CR images. In this paper, we use convolutional neural network (CNN) and multiscale gradient vector flow snakes (MSGVF Snakes) algorithms to segment each finger bone regions from the CR image. The proposed method is applied to 15 cases, 92.95 [%] of the true positive rates, 2.21 [%] of the false positive rates, 7.05 [%] of the false negative rates are obtained respectively."
텍스트마이닝과 딥러닝 기술을 활용한 외국인 관광객의 국내 지역별 이미지 비교,2019,[],"본 연구에서는 소셜 네트워크 서비스(Social Network Service, SNS)인 플리커(Flickr)에 게시된 지오태깅된 사진 데이터와 텍스트 데이터를 활용하여 우리나라 방문객이 갖는 지역별 이미지를 비교하였다. 플리커 데이터 수집은 2013년부터 2018년까지 약 6년간 데이터를 수집하였으며, 6년간 수집된 데이터 29만여건 가운데 관광객이 업로드한 것으로 추정되는 약 17만장의 사진을 분석대상으로 하였다. 플리커의 태그와 텍스트에 대한 분석은 텍스트마이닝 기법 중 단어간 빈도분석 및 연관관계분석을 적용하였으며, 사진에 대한 분석은 합성곱 신경망(Convolutional Neural Network, CNN) 중 하나인 Inception V3 모델을 활용하였다. 지역에 대한 이미지 분석은 서울, 부산, 제주 지역을 대상으로 하였으며, 텍스트 분석 결과와 사진 이미지 분석결과를 비교하여 지역 이미지의 차이를 분석하였다.",다국어 초록 정보 없음
ADD-Net : Attention Based 3D Dense Network for Action Recognition,2019,"['Deep Learning', 'Action Recognition', 'Convolution Neural Network', 'Attention Mechanism']",국문 초록 정보 없음,"Recent years with the development of artificial intelligence and the success of the deep model, they have been deployed in all fields of computer vision. Action recognition, as an important branch of human perception and computer vision system research, has attracted more and more attention. Action recognition is a challenging task due to the special complexity of human movement, the same movement may exist between multiple individuals. The human action exists as a continuous image frame in the video, so action recognition requires more computational power than processing static images. And the simple use of the CNN network cannot achieve the desired results. Recently, the attention model has achieved good results in computer vision and natural language processing. In particular, for video action classification, after adding the attention model, it is more effective to focus on motion features and improve performance. It intuitively explains which part the model attends to when making a particular decision, which is very helpful in real applications. In this paper, we proposed a 3D dense convolutional network based on attention mechanism(ADD-Net), recognition of human motion behavior in the video."
< 구두-B-01 > Data mining in annual growth pattern of Cryptomeria Japonica using wavelet convolutional neural network,2019,[],국문 초록 정보 없음,"Tree-ring analysis is an important field of science, including dendrochronology, dendroclimatology and modeling the tree growth environmental response system. In most cases the analyses have been conducted using one parameter from one tree-ring, e.g. ring-width, density, ratio of radioisotope, and so on. The information within a ring, however, has been less studied and many more things to be explored such as seasonal response in the shorter time scales. From another point of view, many species of softwood are often used into tree-ring analyses but our previous work revealed that simple CNN models did not work well in identification of softwood images where the morphology is rather regular or periodic. Therefore, substantial improvement in either feature extraction or the design of neural network was needed. In this study, therefore, we applied wavelet transform into deep-learning technique in order to extract information of tree growth environmental response in sub-seasonal time scales from softwood images."
잡음 환경에서 선로 전환기 이상 상황 탐지,2019,[],"센서 및 정보 통신 기술의 발전은 산업 현장에서 취득한 정보를 기반으로 다양한 연구를 수행할 수 있는 토대가 되었다. 본 연구에서는 철도의 진로 방향을 전환하는 선로 전환기 주변에 설치한 소리 센서에서 수집한 소리를 기반으로 선로 전환기의 이상 상황을 탐지하고자 한다. 이와 같은 소리 데이터 기반의 이상 상황 탐지 시스템을 실제 산업 현장에서 성공적으로 운용되기 위해서는 소리 취득 시 발생하는 다양한 잡음 환경에서도 이상 상황을 식별할 수 있는 강인함이 보장되어야 한다. 본 논문에서는 소리 음질을 향상시키기 위하여 SEGAN(Speech Enhancement Generative Adversarial Network)을 활용하며, CNN(Convolutional Neural Network)을 기반으로 선로 전환기의 이상 상황을 식별하는 시스템을 제안한다. 수집된 소리 데이터를 기반으로 제안한 시스템을 실험적으로 검증한 바 잡음에 강인한 성능을 확인하였다.",다국어 초록 정보 없음
합성곱신경망 기반의 StyleGAN 이미지 탐지모델,2019,"['Deep Learning', 'Generative Adversarial Network', 'Convolutional Neural Network', 'Fake Image Detection', 'Face Detection']",국문 초록 정보 없음,"As artificial intelligence technology is actively used in image processing, it is possible to generate high-quality fake images based on deep learning. Fake images generated using GAN(Generative Adversarial Network), one of unsupervised learning algorithms, have reached levels that are hard to discriminate from the naked eye. Detecting these fake images is required as they can be abused for crimes such as illegal content production, identity fraud  and defamation. In this paper, we develop a deep-learning model based on CNN(Convolutional Neural Network) for the detection of StyleGAN fake images. StyleGAN is one of GAN algorithms and has an excellent performance in generating face images. We experiment with 48 number of experimental scenarios developed by combining parameters of the proposed model. We train and test each scenario with 300,000 number of real and fake face images in order to present a model parameter that improves performance in the detection of fake faces."
심층 신경망의 손실함수 표면 평탄도가 클래스 증가 학습에 적용된 정규화 기법의 성능에 미치는 영향,2019,[],국문 초록 정보 없음,"Incremental class learning is one of continual learning scenarios where classes of original training data are split and sequentially provided. The main problem to solve here is known as catastrophic forgetting, which is caused by drastic parameter shift due to the difference of data distributions. In this paper, we investigate the relation between the flatness of DNN loss surface and the performance of regularization technique applied to incremental class learning. We make use of Entropy SGD to find flatter local minima and recent method for visualizing loss landscape as contour plot. Experiments are done on SplitMNIST dataset and basic MLP and CNN structure are used. We show that flatter minima lead to better accuracy value after learning more classes and visualize them for intuitive comprehension."
RNN을 이용한 태양광 에너지 생산 예측,2019,"['Machine learning', 'Vanilla RNN', 'LSTM', 'Solar']",국문 초록 정보 없음,"Coal and Natural gas are two biggest contributors to a generation of energy throughout the world. Most of these resources create environmental pollution while making energy affecting the natural habitat. Many approaches have been proposed as alternatives to these sources. One of the leading alternatives is Solar Energy which is usually harnessed using solar farms. In artificial intelligence, the most researched area in recent times is machine learning. With machine learning, many tasks which were previously thought to be only humanly doable are done by machine. Neural networks have two major subtypes i.e. Convolutional neural networks (CNN) which are used primarily for classification and Recurrent neural networks which are utilized for time-series predictions. In this paper, we predict energy generated by solar fields and optimal angles for solar panels in these farms for the upcoming seven days using environmental and historical data. We experiment with multiple configurations of RNN using Vanilla and LSTM (Long Short-Term Memory) RNN. We are able to achieve RSME of 0.20739 using LSTMs."
Finding the optimal path for V2V multi-hop connectivity with Q-learning and Convolutional Neural Networks,2019,[],국문 초록 정보 없음,"Vehicle-to-vehicle (V2V) technology generally adopts Dedicated Short-Range Communications (DSRC) to transmit based safety messages (BSMs) e.g., geographical location, braking information, speed, the status of the turn signal, and direction of travel. Specific propagation and wireless communications channel models have been proposed from industry and academic researchers. However, the range of DSRC is limited to a few hundred meters, and it is necessary to employ a multi-hop communication to extend the range of communication, reaching many target vehicles as possible. In this article, we explore the problem of multi-hop connectivity in V2V networks and propose a methodology that consists of two different deep learning (DL) routines. First, two convolutional neural networks (CNN) are created and tuned to segment terrestrial imagery into different environments. The multi-environments are anticipated to have different propagation models. The second part uses a reinforcement learning (RL) algorithm to find the optimal multi-hop path with the lowest propagation loss, based on the results of the environment segmentation. The optimal multi-hop link is simulated and compared with current single propagation models, showing that our proposal can extend the coverage of multi-hop wireless links by transmitting the link via the optimum path."
Classification of Circulating Tumor Cells in Fluorescence Microscopy Images Based on SqueezeNet,2019,"['Circulating Tumor Cells', 'Fluorescence Microscopy Images', 'SqueezeNet', 'BFED Algorithm']",국문 초록 정보 없음,"Circulating Tumor Cells (CTC) is expected as a useful biomarker test that can evaluate cancer metastasis. CTC exists in the blood of cancer patients and is considered to be an incentive of cancer metastasis. Pathologists analyze the blood to find these metastasis cancers from three colors of fluorescence microscopy images, but the manual analysis is time-consuming. In this paper, we develop an automatic CTC classification method in fluorescence microscopy images to reduce the burden of pathologists. In the proposed method, we detect cell regions by the bacterial foraging-based edge detection (BFED) algorithm and classify CTC by SqueezeNet, which is the kind of convolutional neural network (CNN). We apply the proposed method to 5040 microscopy images (6 samples) and evaluate the effectiveness. The experimental results demonstrate that the proposed method has a true positive rate is 89.86% and a false positive rate is 3.27%."
스타일 분석을 통한 커플 매칭 플랫폼,2019,[],"본연구는 커플들의 이미지 빅 데이터를 분석하여 각각 얼굴과 패션에 따라 유사한 유형 끼리 클러스터링 하여 새로운 사람 이미지가 주어졌을 때 해당 사람이 어느 유형에 속하는지 찾아내고 해당 유형의 사람들은 어떤 유형의 이성과 잘 맞는지 찾아 추천해주는 플랫폼이다. 빅 데이터를 수집하기 위하여 SNS상에서 커플들의 이미지를 크롤링하여 저장한다. 수집된 커플들의 이미지를 AI 머신 러닝으로 나이, 성별을 분석하여 미리 설정한 나이대의 이성 커플들의 이미지 만을 추려내서 각각 남, 여의 이미지를 분리하여 저장한다. 해당 이미지들로 비슷한 얼굴, 패션 유형의 사람들을 같은 클러스터로 모으고 CNN 으로 학습 시켜서 새로운 이미지가 들어올 경우 효율적으로 해당 이미지가 어느 클러스터에 속하는지 찾아낼 수 있도록 한다. 특정 이미지가 속하는 클러스터를 찾아내면 해당 클러스터에 속하는 사람들의 연인들이 어느 클러스터에 가장 많이 포함되어 있는지 찾아서 해당 클러스터 유형의 이성을 추천해준다. 웹과 어플리케이션으로 이루어진 플랫폼 서비스이며, 커플 매칭 기능 뿐만 아니라 매칭된 회원 간 연락 기능, 실제 커플의 이미지로 두 사람의 매칭도 확인 등의 부가적 기능 또한 인공지능 서비스로 제공된다.",다국어 초록 정보 없음
딥 러닝 기반의 이미지학습을 통한 저항 용접품질 검증,2019,"['Resistance welding(저항 용접)', 'Quality verification(품질 검증)', 'Deep learning(딥 러닝)', 'Tensorflow(텐서플로우)']",국문 초록 정보 없음,"Welding is one of the most popular joining methods and most welding quality estimation methods are executed using joined material. This paper propose welding quality estimation methods using dynamic current, voltage and resistance which are obtained during welding in real time. There are many kinds of welding method. Among them, we focused on the projection welding and gathered dynamic characteristics from two different types of projection welding. For image learning, graphs are drawn using obtained current, voltage and resistance, and the graphs are converted to images. The images are labeled with two sub-categories - normal and defect. For deep learning of images obtained from welding, Convolutional Neural Network (CNN) is applied, and Tensorflow was used as a framework for deep learning. With two resistance welding test datasets, we conclude that the Convolutional Neural Network helps in predicting the welding quality."
심층 신경망 기반의 생활폐기물 자동 분류,2019,[],"도시화 과정에서 도시의 생활폐기물 문제가 빠르게 증가되고 있고, 효과적이지 못한 생활폐기물 관리는 도시의 오염을 악화시키고 물리적인 환경오염과 경제적인 부분에서 극심한 문제들을 야기시킬 수 있다. 게다가 부피가 커서 관리하기 힘든 대형 생활폐기물들이 증가하여 도시 발전에도 방해가 된다. 생활폐기물을 처리하는데 있어 대형 생활폐기물 품목에 대해서는 요금을 청구하여 처리한다. 다양한 유형의 대형 생활폐기물을 수동으로 분류하는 것은 시간과 비용이 많이 든다. 그 결과 대형 생활폐기물을 자동으로 분류하는 시스템을 도입하는 것이 중요하다. 본 논문에서는 대형 생활폐기물 분류를 위한 시스템을 제안하며, 이 논문의 4 가지로 분류된다. 1) 높은 정확도와 강 분류(roust classification) 수행에 적합한 Convolution Neural Network(CNN) 모델 중 VGG-19, Inception-V3, ResNet50 의 정확도와 속도를 비교한다. 제안된 20 개의 클래스의 대형 생활폐기물의 데이터 셋(data set)에 대해 가장 높은 분류의 정확도는 86.19%이다. 2) 불균형 데이터 문제를 처리하기 Class Weight VGG-19(CW-VGG-19)와 Extreme Gradient Boosting VGG-19 두 가지 방법을 사용하였다. 3) 20 개의 클래스를 포함하는 데이터 셋을 수동으로 수집 및 검증하였으며 각 클래스의 컬러 이미지 수는 500 개 이상이다. 4) 딥 러닝(Deep Learning) 기반 모바일 애플리케이션을 개발하였다.",다국어 초록 정보 없음
기계학습을 이용한 주파수 분석을 통한 퍼팅 판별 알고리즘,2019,"['골프 퍼팅 (Golf putting)', '모션 추출 (Motion detection)', '기계 학습 (Machine Learning)', '주파수 분석 (Frequency Anaylsis)']",국문 초록 정보 없음,"Auto-scoring related wearable devices for golf have emerged to meet consumer demands. Wrist-worn devices capable of automatic scoring using inertial sensors are providing user convenience. Impact of putting is, however, relatively small , and it is difficult to extract the putting signal due to influence of the hand grip. In this study, we designed a puttingdiscrimination algorithm for auto-scoring using inertial sensors. The putting-determination consists of selecting a putting phase from arbitrary motion, and extracting a putting signal in the phase. The putting phase was determined by using Convolution Neural Network (CNN). It was determined based on manual labeling by inputting the acceleration and angular velocity data. Putting-signal extraction exploits the phenomenon that vibration caused by natural frequency occurs even for a small impact. And the putting signal is extracted by designing a bandpass filter which passes only the natural frequency in the putting phase. The natural frequency of the putting is analyzed by assuming the putter as a beam, The parameters are estimated to identify the grip boundary conditions. The impact is derived through the frequency analysis, and experimentally verified. The method presented can be employed to increase accuracy of the wrist-type automatic scoring devices for other sports."
An overview of deep learning in the field of dentistry,2019,"['Artificial Intelligence', 'Deep Learning', 'Dentistry', 'Radiology']",국문 초록 정보 없음,"Purpose: Artificial intelligence (AI), represented by deep learning, can be used for real-life problems and is applied across all sectors of society including medical and dental field. The purpose of this study is to review articles about deep learning that were applied to the field of oral and maxillofacial radiology. Materials and Methods: A systematic review was performed using Pubmed, Scopus, and IEEE explore databases to identify articles using deep learning in English literature. The variables from 25 articles included network architecture, number of training data, evaluation result, pros and cons, study object and imaging modality. Results: Convolutional Neural network (CNN) was used as a main network component. The number of published paper and training datasets tended to increase, dealing with various field of dentistry. Conclusion: Dental public datasets need to be constructed and data standardization is necessary for clinical application of deep learning in dental field."
An overview of deep learning in the field of dentistry,2019,"['Artificial Intelligence', 'Deep Learning', 'Dentistry', 'Radiology']",국문 초록 정보 없음,"Purpose: Artificial intelligence (AI), represented by deep learning, can be used for real-life problems and is applied across all sectors of society including medical and dental field. The purpose of this study is to review articles about deep learning that were applied to the field of oral and maxillofacial radiology.Materials and Methods: A systematic review was performed using Pubmed, Scopus, and IEEE explore databases to identify articles using deep learning in English literature. The variables from 25 articles included network architecture, number of training data, evaluation result, pros and cons, study object and imaging modality.Results: Convolutional Neural network (CNN) was used as a main network component. The number of published paper and training datasets tended to increase, dealing with various field of dentistry.Conclusion: Dental public datasets need to be constructed and data standardization is necessary for clinical application of deep learning in dental field."
수도 레이블을 활용한 준지도 학습 기반의 도로노면 파손 탐지,2019,"['Road surface damage', 'Semantic segmentation', 'Convolutional neural network', 'Semi-supervised learning', '도로노면 파손', '의미론적 분할', '합성곱 신경망', '준지도 학습']","의미론적 분할 형태로 합성곱 신경망을 구성하여 도로노면의 파손을 탐지하는 연구가 진행되고 있다. 이러한 합성곱 신경망 형태의 모델을 생성하기 위해서는 입력 이미지와 이에 상응한 레이블된 이미지 데이터셋으로 수집해야 하고, 이러한 과정에서는 굉장히 많은 시간과 비용이 발생하게 된다. 본 논문에서는 이러한 작업을 완화하기 위하여 수도 레이블링을 활용한준지도 학습 기반의 도로노면 파손 탐지 기술을 제안하고자 한다. 레이블된 데이터셋과 레이블되지 않은 데이터셋을 적절하게 혼합하여 도로노면 파손을 탐지하는 모델을 업데이트하고, 이를 레이블된 데이터셋만을 활용한 기존 모델과 성능을 비교한다. 주관적인 성능결과, 민감도부분에서는 조금 저하된 성능을 보였지만, 정밀도 부분에서는 대폭 성능 향상이 있었으며, 최종적으로 F1-score 또한 높은 수치로 평가되었다.","By using convolutional neural networks (CNNs) based on semantic segmentation, road surface damage detection has being studied. In order to generate the CNN model, it is essential to collect the input and the corresponding labeled images. Unfortunately, such collecting pairs of the dataset requires a great deal of time and costs. In this paper, we proposed a road surface damage detection technique based on semi-supervised learning using pseudo labels to mitigate such problem. The model is updated by properly mixing labeled and unlabeled datasets, and compares the performance against existing model using only labeled dataset. As a subjective result, it was confirmed that the recall was slightly degraded, but the precision was considerably improved. In addition, the F1-score was also evaluated as a high value."
딥러닝을 이용한 전문분야 문서 분류 시스템 개발,2019,[],"본 논문에서는 고도장비의 운용 및 정비를 위한 교육훈련 시스템 개발을 위해 자연어 처리와 딥러닝 기술을 이용하여 항공정비와 관련된 전문분야의 문서 분류가 가능한 방법을 제안하고자 한다. 문서 분류 모델의 개발을 위해 항공정비 교범을 텍스트 파일로 변환하여 총 4917개의 문서를 생성하였으며, 정비사 개인별 정비능력 관리(IMQC)를 기준으로 12개의 범주로 구분하였다. 수집된 문서는 전문분야의 문서인 점을 고려하여 전문용어 사전을 추가하였으며, KoNLPy를 이용하여 전처리를 수행하였다. 전문분야의 문서는 범주에 상관없이 문서 내용의 유사도가 매우 높은 특징을 가지고 있어, 특정 범주내에서 중요한 정도를 잘 표현 할 수 있는 TF-ICF를 이용하여 특징 추출을 하였다. 이후 합성곱 신경망(CNN)을 이용하여 특징 맵을 생성한 후 완전 결합 계층을 통하여 분류하였으며, 테스트 문서 983건을 분류한 결과 평균 73.6%의 분류성능을 보여주었다.",다국어 초록 정보 없음
재실자 착의량 산출을 위한 선행 연구 및 기술 분석,2019,"['Indoor Environment', 'Thermal Quality', 'Predictive Mean Vote', 'Clothing Insulation', '실내환경', '온열환경', '예상평균온열감', '착의량']",국문 초록 정보 없음,"Purpose: The aim of this study is to verify the feasibility and applicability of a neural network-based model for estimating clothing insulation of building occupants. This is a preliminary study before developing an estimation model for the clothing insulation. Method: The existing researches on the method of estimating the clothing insulation were investigated and the neural network techniques that can be applied to the model were analyzed.Clothing image datasets were collected and convolutional neural networks (CNNs) that is effective for training images were investigated. Various advanced CNN structures were analyzed to confirm their applicability in developing models. Lastly, an application process for the neural network-based model for estimating clothing insulation and the real-time PMV control was proposed as a flowchart. Result: As a result, the possibility of the neural network-based model for estimating occupants clothing insulation was confirmed, and the basis for providing a comfort indoor thermal environment was established."
딥러닝기반 다중 표적 인식을 활용한 모바일 로봇 경로 계획,2019,"['표적인식', '경로계획', '장애물 회피', '딥러닝', '모바일 로봇', 'Taget Detection', 'Path Planning', 'Avoidance Obstacle', 'Deep-Learning', 'Mobile Robot']","복합적인 고차원의 임무를 수행하기 위하여 미래무인화 전투 체게는 인공지능 기술을 필요로 한다. 특히 합성곱 신경망은 영상뿐만 아니라 자연어 처리까지 광범위한 범위에서 탁월한 성능을 보이고 있어 무인화 전투체계의 표적정보인식, 피아식별, 전장정보인식 등 각종 센서 융합에 매우 적합하다. 본 연구에서는 합성곱 신경망의 영상인식 기술을 활용하여 다수 대상체의 상태정보를 인식함으로써 변화되는 환경에서의 무인로봇 경로 계획 개선 방안을 제시하였고 시뮬레이션을 통하여 추정된 로봇의 위치, 장애물, 목표물 정보로부터 로봇의 경로 계획의 유효성을 검증 하였다.","Unmmanned systems are one of the essential areas of future military weapons systems that must carry out dangerous and cmplex missions. Especially, deep learning should recognize many landmarks through the image and project them onto the map to improve the problem of position estimation, because it shows excellent performance of recognizing and classifying the characteristics of image data among other artificial intelligence techniques. In this study, the path planning of the unmanned reconnaissance aircraft and the unmanned ground vehicle, which are currently being used in the ROK military, is linked with the CNN based multi target recognition algorithm without GPS. Throuth experiments, we verified the effectiveness of the path planning of the mobile robot with respect to the position of the robot, obstacle, and target point estimated by the target detection algorithm."
수중 소나 영상 학습 데이터의 왜곡 및 회전 Augmentation을 통한 딥러닝 기반의 마커 검출 성능에 관한 연구,2019,"['Deep Learning', 'Data Augmentation', 'Object Detection', 'Underwater Sonar Image']",국문 초록 정보 없음,"In the ground environment, mobile robot research uses sensors such as GPS and optical cameras to localize surrounding landmarks and to estimate the position of the robot. However, an underwater environment restricts the use of sensors such as optical cameras and GPS. Also, unlike the ground environment, it is difficult to make a continuous observation of landmarks for location estimation. So, in underwater research, artificial markers are installed to generate a strong and lasting landmark. When artificial markers are acquired with an underwater sonar sensor, different types of noise are caused in the underwater sonar image. This noise is one of the factors that reduces object detection performance. This paper aims to improve object detection performance through distortion and rotation augmentation of training data. Object detection is detected using a Faster R-CNN."
Detection of Lung Nodules from Temporal Subtraction Image Using Deep Learning,2019,"['Computer Aided Diagnosis', 'Temporal Subtraction Technique', 'Deep Learning', 'SENets']",국문 초록 정보 없음,"In recent years, the number of death due to lung cancer is increasing year by year worldwide. Early detection and early treatment of lung cancer are important. Especially, early detection of the abnormalities on thoracic MDCT images detection of small nodules is required in visual screening. Although a CT apparatus is used for the examination, the burden on the image interpretation doctor is large due to the high performance of the CT, so the diagnostic accuracy may be reduced. In this paper, we propose an image analysis method to detect abnormal shadows from chest CT images automatically. The initial lesion candidate areas are extracted by using temporal subtraction technique that emphasizes temporal change by subtracting from a current image to previous one which is obtained same subject. The image of the area is given as input and classification is performed by CNN (Convolutional Neural Network). In the discrimination experiment based on our proposed method, 90.26 [%] of true positive rates and 13.58 [%] of false positive rates are obtained from the 49 clinical cases."
A Study on User Recognition Using 2D ECG Image Based on Ensemble Networks for Intelligent Vehicles,2019,[],국문 초록 정보 없음,"<P>IoT enabled smart car era is expected to begin in the near future as convergence between car and IT accelerates. Current smart cars can provide various information and services needed by the occupants via wearable devices or Vehicle to Everything (V2X) communication environment. In order to provide such services, a system to analyze wearable device information on the smart car platform needs to be designed. In this paper a real time user recognition method using 2D ECG (Electrocardiogram) images, a biometric signal that can be obtained from wearable devices, will be studied. ECG (Electrocardiogram) signal can be classified by fiducial point method using feature points detection or nonfiducial point method due to time change. In the proposed algorithm, a CNN based ensemble network was designed to improve performance by overcoming problems like overfitting which occur in a single network. Test results show that 2D ECG image based user recognition accuracy improved by 1%~1.7% for the fiducial point method and by 0.9%~2% for the nonfiducial point method. By showing 13% higher performance compared to the single network in which recognition rate reduction occurs because similar characteristics are shown between classes, capability for use in a smart vehicle platform based user recognition system that requires reliability was demonstrated by the proposed method.</P>"
Deep Learning–based Number Detection and Recognition for Gas Meter Reading,2019,"['Gas meter?reading system', 'Computer vision', 'Image processing', 'Convolutional neural network']",국문 초록 정보 없음,"The meter reading.system field has been researched from conventional methods centered on image processing technology to techniques based on learning methods such as machine learning or deep learning. The biggest problem for meter reading systems based on computer vision is difficulty in recognizing the various kinds of meters. In fact, there are more than five major manufacturers for the meters installed in Korea. There are different meter reading areas, ID regions, and number formats by version. Because of these problems, most of the meter reading is still done hands-on. In this paper, we present an automatic meter.reading system that can work simply and efficiently, compared to existing meter reading systems that need a skilled worker. Our meter reading system consists of three parts: i) detection of meter-reading and ID regions using You Only Look Once (YOLO), ii) digit segmentation for recognition, and iii) convolutional neural network (CNN)-based digit recognition. It is possible to robustly detect and recognize various meter types by using the method presented here. Therefore, it can provide an environment where gas meter checkers can work efficiently without inconvenient procedures."
딥러닝 기반의 대퇴골 영역 분할을 위한 훈련 데이터 증강 연구,2019,"['데이터 증강', '딥러닝', '의료영상', '영역 분할', 'Data augmentation', 'Deep learning', 'Medical image', 'Image segmentation']","본 연구에서는 CT 영상의 대퇴골 부위를 해부학적으로 의미 있게 변형하여 CT 영상의 대퇴골 영역을 분할하기 위한 컨벌루션 신경망(CNN)의 훈련 데이터를 증강하는 방법을 제안한다. 먼저 CT 영상으로부터 삼차원 삼각형 대퇴골 메쉬를 얻는다. 그 후 메쉬의 국소부위에 대한 기하학적 특성을 계산하고, 군집화하여 메쉬를 의미 있는 부분들로 분할한다. 마지막으로, 분할한 부분들을 적절한 알고리즘으로 변형한 뒤, 이를 바탕으로 CT 영상을 와핑하여 새로운 CT영상을 생성하였다. 본 연구의 데이터 증강 방법을 이용하여 학습시킨 딥러닝 모델은 기하학적 변환이나 색상 변환 같이 일반적으로 사용되는 데이터 증강법과 비교하여 더 나은 영상분할 성능을 보인다.","In this study, we modified CT images of femoral head in consideration of anatomically meaningful structure, proposing the method to augment the training data of convolution Neural network for segmentation of femur mesh model. First, the femur mesh model is obtained from the CT image. Then divide the mesh model into meaningful parts by using cluster analysis on geometric characteristic of mesh surface. Finally, transform the segments by using an appropriate mesh deformation algorithm, then create new CT images by warping CT images accordingly. Deep learning models using the data enhancement methods of this study show better image division performance compared to data augmentation methods which have been commonly used, such as geometric conversion or color conversion."
해외 정보분석기법의 활용 및 효용성에 관한 연구,2019,"['intelligence analysis', 'uncertainty of international order', 'intelligence capacity', 'structured analysis', 'decision making', 'cognitive bias. blind spot', '구조화 분석', 'SWOT 분석', '분석의 오류', '인지적 오류', '인지적 편향성', '대북군사행동']","미중 패권경쟁의 심화와 남북관계 급변, 북미 관계개선의 교착, 한일갈등의 심화 등 동북아 안보지형이 어느 때 보다 불확실하고 불안정하다. 이렇게 불확실한 안보 상황에서 뛰어난 정보역량으로 국가적 위기를 대비하고 극복해나가는 것은 매우 중요하다. 본 연구는 미국 CIA, DIA 등을 비롯한 구미 정보기관들이 국내외 위기상황에 효과적으로 대처하기 위해 다양한 정보분석기법을 개발하고 있는 시점에서 우리의 분석역량 제고에 기여할 수 있는 정보분석기법들을 살펴보았다. 특히, 우리보다 많은 경험과 정보 노하우를 축적한 구미 정보기관들의 선진분석기법들을 살펴보고 이들을 가상상황인 미국의 대북군사행동에 적용해서 분석기법의 효용성을 살펴보았다. 구조화 브레인스토밍을 시작으로 레드햇 분석과 사분면분할분석, PEST 분석과 SWOT 분석기법들을 가상사례에 적용하였을 때 그 분석과정에서의 효용가치를 살펴보았다. 구조화분석기법은 정보실패를 초래하는 정보분석관들의 인지적 편향성을 극복하는데 기여할 수 있는 것으로 알려졌다. 즉 구조화 분석기법(structured analytic techniques)은 분석관이 입수한 불완전하고 모호하며 때로는 기만적인 첩보들을 단계적으로 처리할 수 있는 절차적 분석방법으로서 내적 사고의 절차를 시스템적이고 투명한 방법으로 드러나게 함으로써 다른 사람들과 분석과정을 공유하고, 공동작업을 통해 서로 비판적으로 검토 할 수 있게 해준다. 물론 이런 방식만이 항상 올바른 결론을 얻을 수 있는 공식과 같은 것으로 존재할 수는 없지만 분석기법을 구조적으로 조직화하는 것은 분석과정에서 오류의 정도와 빈도를 줄이는데 기여할 수 있다. 그러나, 가상사례인 미국의 대북군사행동을 분석하는데 이 분석기법들을 적용한 결과 그 자체로 여러 가지 도움을 주는 것은 사실이지만 그렇다고 해서 엄청나게 획기적인 성과를 기대해서는 안될 것 같다. 구조화분석기법은 하나의 테크닉이지 본질이나 실질(Substance)은 아니다. 특정주제에 대해 고도의 전문성이 없이는 심층적인 분석에 한계가 있다. 새로운 아이디어의 발굴 또는 예기치 않은 변수의 분석에 기여하는 바가 있지만 전문분석관이 쌓은 오랜 경험과 경륜에서 오는 직관적인 통찰력 역시 무시할 수 없다. 구조화 분석기법이 미래예측을 하는 수정구슬이라기 보다는 수정구슬을 잘 들여다 볼 수 있게 도움을 주는 유용한 보조도구라고 생각하고 사용할 필요가 있다.","As such uncertain situations in East Asia are rapidly unfolded, it has become significant to improve intelligence analysis and inform decision makers about the incoming crises. When multiple U.S. intelligence bodies like CIA put lots of efforts to develop good analytic techniques in order to cope with future crisis, we also need to develop new alternative analyses, which can make a great contribution to enhance our analytical skills. This study makes an attempt to investigate the utility of some analytic techniques like structured analyses developed by retired CIA intelligence analysts. This study explores into the utilization of structured analytical techniques by applying them to a simulated case of American invasion to North Korea, which almost became to be a plausible scenario by CNN two years ago. As a result of applying to a simulated case such various analytic techniques like Structured Brainstorming, Red Hat analysis, Quadrant Crunching, this study came up with a conclusion that we should be working harder to strengthen our analytic capacity. However, it is also important to guard against too much expectations to these alternative analyses since they seem to be more techniques rather than substance. These analytical methods help intelligence analysts identify the blind spot of their analyses and enlighten them on the problems of their cognitive biases. However, as they are no more panacea, we need to use these methods more as an auxiliary instrument than as a crystall ball of fortunetelling."
Recognition of Surrounding Environment for Electric Wheelchair Based on WideSeg,2019,"['Autonomous Wheelchair', 'Sidewalk', 'Crosswalk', 'Traffic Light', 'Semantic Segmentation', 'Convolutional Neural Network', 'WideSeg']",국문 초록 정보 없음,"At present, the aging population is growing in Japan. Along with that, the expectation for the utilization of welfare equipment is increasing. Electric wheelchair, a convenient transportation tool, is popularized rapidly. On the other hand, accidents have occurred, and the dangers for driving are pointed out. Therefore, it needs to improve accident factors, reduce accidents and improve the convenience of electric wheelchair by automation. Environmental recognition is necessary for the development of autonomous electric wheelchair. Environmental recognition includes self-position estimation, recognition of sidewalks, crosswalks and traffic lights, moving object prediction, etc. In order to solve these various problems, this paper examines the segmentation of sidewalks, crosswalks and traffic lights. We develop the WideSeg that is one of semantic segmentation algorithms applying convolutional neural networks (CNN)."
Automatic spine segmentation from CT images using Convolutional Neural Network via redundant generation of class labels,2019,['Automatic image segmentation Computed tomography images Convolutional neural network Spine segmentation'],국문 초록 정보 없음,"There has been a signiﬁcant increase from 2010 to 2016 in the number of people suffering from spine problems. The automatic image segmentation of the spine obtained from a computed tomography (CT) image is important for diagnosing spine conditions and for performing surgery with computer-assisted surgery systems. The spine has a complex anatomy that consists of 33 vertebrae, 23 intervertebral disks, the spinal cord, and connecting ribs. As a result, the spinal surgeon is faced with the challenge of needing a robust algorithm to segment and create a model of the spine. In this study, we developed a fully auto-matic segmentation method to segment the spine from CT images, and we compared our segmentation results with reference segmentations obtained by well-known methods. We use a hybrid method. This method combines the convolutional neural network (CNN) and fully convolutional network (FCN), and utilizes class redundancy as a soft constraint to greatly improve the segmentation results. The proposed method was found to signiﬁcantly enhance the accuracy of the segmentation results and the system pro-cessing time. Our comparison was based on 12 measurements: the Dice coefﬁcient (94%), Jaccard index (93%), volumetric similarity (96%), sensitivity (97%), speciﬁcity (99%), precision (over segmentation 8.3 and under segmentation 2.6), accuracy (99%), Matthews correlation coefﬁcient (0.93), mean surface dis-tance (0.16 mm), Hausdorff distance (7.4 mm), and global consistency error (0.02). We experimented with CT images from 32 patients, and the experimental results demonstrated the efﬁciency of the pro-posed method."
Super-Resolution Model for High-Precision In Vivo Proton Range Verification Using a Stereo Gamma Camera: A Feasibility Study,2019,"['Monte-Carlo simulation', 'Proton range verification', 'Super-resolution', 'Deep-learning', 'Gamma cameras']",국문 초록 정보 없음,"The feasibility of a deep-learning-based super-resolution (SR) model to improve the fiducial marker-tracking accuracy of a stereo portable gamma camera (SPGC) system over the range of an in vivo proton beam was verified in a Monte-Carlo (MC) simulation using the Geometry and Tracking 4 (Geant4) package. The SPGC system is capable of measuring the three-dimensional (3D) position of excited gold markers by detecting proton-induced X-ray emissions (PIXEs) generated by the interactions between the gold marker and a proton beam. The SPGC system was modeled using Geant4 according to manufacturer’s specifications. The original image (Io) acquired by using the SPGC system, which was comprised of 32 × 32 arrays over an area of 104 × 104 mm2, was subjected to resolution enhancement to produce an SR-enhanced image (ISR) (128 × 128 arrays) through a fully trained SR model based on a convolutional neural network (CNN). In virtual experiments, two portable gamma cameras were positioned perpendicular to each other. Next, a pair of Io’s were acquired by detecting the radiations from the exited gold marker positioned in a water phantom. Then, the fully trained SR model improved the quality of the Io’s by converting those to ISR’s. The 3D position of the radiation source was calculated by using Anger logic and 3D vector calculations. Virtual experiments for in vivo proton range verification using the SPGC system were performed by irradiating to a gold marker in a water phantom with a proton beam. A gold marker was placed at five different positions along the Bragg curve of a 100.0-MeV proton beam, which had a range of 74.5 mm in water. The proton beam was irradiated to deliver 20.0 Gy to the gold marker when it was positioned at the center of the Bragg peak; then, the PIXEs were measured by using the SPGC system. When a gold marker was at a different position, it was irradiated with the same dose for a quantitative comparison. Then 3D position of the gold marker was calculated for the original image (Io) and for the high-resolution image (ISR) to compare the detection accuracy. The averaged root-mean-square errors of the five positions between the reference and calculation for Io and ISR were 9.127 mm and 3.991 mm, respectively. In conclusion, the feasibility of using a deep-learning SR model for improving the image resolution of Io and therefore, the tracking accuracy of the SPGC system was validated in MC simulations. The SR model can be applicable to diverse areas of research using gamma camera."
딥러닝기반 다중 표적 인식을 활용한 모바일 로봇 경로 계획,2019,"['표적인식', '경로계획', '장애물 회피', '딥러닝', '모바일 로봇', 'Taget Detection', 'Path Planning', 'Avoidance Obstacle', 'Deep-Learning', 'Mobile Robot']","복합적인 고차원의 임무를 수행하기 위하여 미래무인화 전투 체게는 인공지능 기술을 필요로 한다. 특히 합성곱 신경망은 영상뿐만 아니라 자연어 처리까지 광범위한 범위에서 탁월한 성능을 보이고 있어 무인화 전투체계의 표적정보인식, 피아식별, 전장정보인식 등 각종 센서 융합에 매우 적합하다. 본 연구에서는 합성곱 신경망의 영상인식 기술을 활용하여 다수 대상체의 상태정보를 인식함으로써 변화되는 환경에서의 무인로봇 경로 계획 개선 방안을 제시하였고 시뮬레이션을 통하여 추정된 로봇의 위치, 장애물, 목표물 정보로부터 로봇의 경로 계획의 유효성을 검증 하였다.","Unmmanned systems are one of the essential areas of future military weapons systems that must carry out dangerous and cmplex missions. Especially, deep learning should recognize many landmarks through the image and project them onto the map to improve the problem of position estimation, because it shows excellent performance of recognizing and classifying the characteristics of image data among other artificial intelligence techniques. In this study, the path planning of the unmanned reconnaissance aircraft and the unmanned ground vehicle, which are currently being used in the ROK military, is linked with the CNN based multi target recognition algorithm without GPS. Throuth experiments, we verified the effectiveness of the path planning of the mobile robot with respect to the position of the robot, obstacle, and target point estimated by the target detection algorithm."
No-Reference Image Quality Assessment Using Independent Component Analysis and Convolutional Neural Network,2019,['Convolutional neural network Independent component analysis No-reference image quality assessment Patch selection'],국문 초록 정보 없음,"As digital images have become a significantly primary medium in a broad area, there is a growing interest in the development of automatic objective image quality assessment (IQA) methods. In this paper, a novel no-reference IQA (NRIQA) algorithm is proposed based on independent component analysis and convolutional neural network. The proposed NRIQA algorithm consists of the following three steps: selection of some representative patches, extraction of the features of the selected image patches, and prediction of the image quality by exploiting the features. Initially, an image is divided into non-overlapping patches and then some patches are selected with the suitable property for assessing the overall image quality. In this paper, we refer to the selected patches as image quality patches. The largest infinity norm of the gradient of each image quality patch is employed as a basis when the image quality patches being selected. Second, we employ independent component analysis (ICA) to extract the features of image quality patches. At the last moment, a convolutional neural network (CNN) is applied to the independent component coefficients of image quality patches to predict the corresponding differential mean opinion score (DMOS). We compared the performance of the proposed NQIRM with other IQMs in terms of PCC, SROCC, and RMSE on the database LIVE2, CSIQ and TID2008/2013. The PCC, SROCC and RMSE values achieve respectively to 0.996, 0.999 and 6.011 on the database TID2013. The performance comparison results show the proposed NRIQM is superior to commonly used IQMs."
Acoustic spectral imaging and transfer learning for reliable bearing fault diagnosis under variable speed conditions,2019,"['Acoustic emission signal', 'Spectrum imaging', 'Feature extraction and classification', 'Fault diagnosis', 'Convolution neural network', 'Transfer learning']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>Incipient fault diagnosis of a bearing requires robust feature representation for an accurate condition-based monitoring system. Existing fault diagnosis schemes are mostly confined to manual features and traditional machine learning approaches such as artificial neural networks (ANN) and support vector machines (SVM). These handcrafted features require substantial human expertise and domain knowledge. In addition, these feature characteristics vary with the bearing’s rotational speed. Thus, such methods do not yield the best results under variable speed conditions. To address this issue, this paper presents a reliable fault diagnosis scheme based on acoustic spectral imaging (ASI) of acoustic emission (AE) signals as a precise health state. These health states are further utilized with transfer learning, which is a machine learning technique, which shares knowledge with convolutional neural networks (CNN) for accurate diagnosis under variable operating conditions. In ASI, the amplitudes of the spectral components of the windowed time-domain acoustic emission signal are transformed into spectrum imaging. ASI provides a visual representation of acoustic emission spectral features in images. This ensures enhanced spectral images for transfer learning (TL) testing and training, and thus provides a robust classifier technique with high diagnostic accuracy.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Feature characteristics vary with the bearing’s rotational speed. </LI> <LI>  This paper proposes a reliable fault diagnosis scheme based on acoustic spectral imaging (ASI) of acoustic emission signals. </LI> <LI>  ASI provides a visual representation of acoustic emission spectral features in images. </LI> <LI>  The proposed approach provides a robust classifier technique with high diagnostic accuracy. </LI> </UL> </P>   <P><B>Graphical abstract</B></P>   <P>[DISPLAY OMISSION]</P>"
Convolutional Neural Network based Acoustic Classification Model for Behavioral Parameters of a Cow and Laying Hens,2019,"['Deep-learning', 'MFCC', 'Vocal Recognition', 'Augmentation']",국문 초록 정보 없음,"Vocal information for animals is an effective method of communicating between the groups or individuals and has the advantage of effectively reaching a long range. The voice provides information on the age, gender, sequence and breeding status of the vocalizing animal. For instance, laying hens communicate with each other through frequent auditory information throughout the day. In the case of a cow, when they feel hungry or thirsty, when a cow is in an estrus orin or in a certain stresssituations, a cow phonate a voice with specific pattern. Although many studies have been conducted to extract the feature values of these acoustic sounds and classify each of the sounds, the classification accuracies have not been high yet. Recently, since deep learning based classification models have been applied showing the capabilities of high accuracy and reliability in various fields such as XX, there is high potential of using the deep learning method for effectively classifying animal vocals that contain their behavioral meanings. The purpose of this study is to develop a Convolutional Neural Network (CNN) based classification model to effectively recognize sounds that contain eight behavioral meanings of each of laying hen and cow. In addition, our ultimate goal is to develop an online monitoring system that acquires the livestock sound and sends the vocal information to the cloud server in real time, and classifies the animals voice to determine their status in real time. In order to visualize the acoustic data, we preprocessed the voice data through Mel-Frequency Cepstral Coefficient (MFCC) which is a representation of the short-term power spectrum of a sound, based on a linear cosine transform of a log power spectrum on a nonlinear mel scale of frequency. Audio-augmentation method was used to increase the number of training samples by means of shifting, noise adding, and stretching of sounds. As for individual cow vocalization, the training accuracy was 99.99% and the test accuracy was 91.23%, and the training accuracy of laying hens vocal classification was 99.23% and the test accuracy was 82.12%. Since the vocal parameters changes by the circumstance around animals, they can be used for a more precise and efficient environment prediction for livestock management."
적외선 영상처리 및 딥러닝을 이용한 콘크리트 시설 내외부 결함 검출 연구,2019,"['콘크리트', '결함', '적외선', '영상처리', '딥러닝']","사회기반시설인 댐, 교량, 도로 등의 시설물은 국가 경제 발전 및 삶에 미치는 영향이 크고, 특히 농업분야에 있어 중요성이 매우 크다. 앞서 언급한 시설들은 약 25년이 경과 한 후 노후화가 시작되는 것으로 밝혀져 있으며, 노후화된 시설물들은 국민 안전 및 경제에 위험을 주고, 노후화된 기간에 비례하여 유지관리 비용이 증가한다. 선행 연구에 따르면 2020년 기준으로 미국은 3840조 원의 비용이 필요할 것으로 전망된다. 교량이나 도로의 경우 콘크리트로 이루어져 있으며 노후화로 인한 시설 내부, 외부 결함 및 파괴로 일반 경제 분야뿐만 아니라 농업에 미칠 잠재적 문제를 방지할 필요가 있다. 이를 해결하고자 노후화나 결함을 사고 이전에 파악하기 위한 연구들이 지속되어 왔다. 초기에는 영상센서를 이용한 표면 검사나 센서를 부착하는 방식이 대부분이었기 때문에 측정자에 따른 편차가 컸고, 이후에는 초음파, 방사선 진단 등의 비파괴적인 연구가 이루어지고 있는 상태이다.외부 결함의 경우 과거의 표면 영상 인식 기술을 사용할 경우 결함뿐만 아니라 콘크리트가 결합된 정상적인 틈이나 그림자 등을 구분하기 어려운 환경에 놓일 수 있어 실제 현장에서 일관성을 가지기 힘들다. 이를 극복하고자 여러 종류의 콘크리트가 가진 결함 및 비결함 데이터를 획득하고, 최근 영상 분류 작업에 연구되는 인공신경망 기반의 CNN(Convolutional Neural Networks) 알고리즘을 적용하여 결함 유무를 분류하였으며, 결함으로 분류된 영상데이터들에 대해 Otsu, Niblack, Sauvola 등의 이진화 작업을 통해 영상 중 결함의 정확한 위치를 찾아내고 성능을 평가하였다.내부 결함의 경우 비파괴 검사 중 적외선 열영상 기법의 결함부위별 온도 이질성을 볼 수 있는 특징에서 착안하여 임의로 다양한 결함이 추가된 콘크리트를 설계 및 제작하고, 자연상태의 햇빛을 받거나 그늘진 환경에 배치하는 Passive Thermography를 적용하였다. 이러한 적외선 열영상에 PCT, DFT, Autoencoder 등의 영상처리를 하여 결함의 존재 및 위치 등의 데이터들을 해석하는 연구를 진행하였다.",다국어 초록 정보 없음
Origin of the Higher Difficulty in the Recognition of Vowels Compared to Handwritten Digits in Deep Neural Networks,2019,"['Vowel recognition', 'Deep neural network', 'Mel-frequency cepstral coe cients', 'Formant analysis']",국문 초록 정보 없음,"We investigate the origin of the signicantly dierent error rates between handwritten digit machine recognition and vowel sound machine recognition. While the error rate for ve Korean vowel sounds, [A], [U], [I], [o], and [E], is about 10 percent, that of handwritten digit recognition is less than 1 percent for convolutional neural networks (CNNs) with raw data. We rst dilute the information of the sound by subtracting its temporal ne structure, with the assumption that sorting out extraneous sound information will improve the accuracy of vowel recognition. Simulation results show no improvement though, indicating that the recognition rate dierence does not arise from unnecessary sound information. Rather, conserving subtle information with no information reduction can be helpful to improve recognition rates; however, even the model with the highest accuracy does not reach the accuracy for handwritten digit recognition we desired. Finally, we nd that the main diculty of Korean vowel sound recognition comes from the similarity of [o] and [E]; without [E], recognition of the remaining vowels is up to 99 percent. The similarity can be seen through their formant structure. Humans overcome the similarity to adeptly dierentiate the two, and human vowel recognition remains far superior to the best performing CNNs. This indicates room to develop deep neural networks beyond the CNN still exists."
향상된 음향 신호 기반의 음향 이벤트 분류,2019,"['Noise Robustness', 'Sound Signal Generation', 'End-to-End Architecture', 'Deep Learning', '잡음 견고성', '음향 신호 생성', 'End-to-End 구조', '딥러닝']",국문 초록 정보 없음,"The explosion of data due to the improvement of sensor technology and computing performance has become the basis for analyzing the situation in the industrial fields, and various attempts to detect events based on such data are increasing recently. In particular, sound signals collected from sensors are used as important information to classify events in various application fields as an advantage of efficiently collecting field information at a relatively low cost. However, the performance of sound-event classification in the field cannot be guaranteed if noise can not be removed. That is, in order to implement a system that can be practically applied, robust performance should be guaranteed even in various noise conditions. In this study, we propose a system that can classify the sound event after generating the enhanced sound signal based on the deep learning algorithm. Especially, to remove noise from the sound signal itself, the enhanced sound data against the noise is generated using SEGAN applied to the GAN with a VAE technique. Then, an end-to-end based sound-event classification system is designed to classify the sound events using the enhanced sound signal as input data of CNN structure without a data conversion process. The performance of the proposed method was verified experimentally using sound data obtained from the industrial field, and the f1 score of 99.29% (railway industry) and 97.80% (livestock industry) was confirmed."
정형 데이터와 비정형 데이터를 동시에 고려하는 기계학습 기반의 직업훈련 중도탈락 예측 모형,2019,"['Vocational Training', 'Dropout', 'Machine Learning', 'Convolutional Neural Network', 'Word2vec', '직업훈련 교육', '중도탈락', '기계학습', '합성곱 신경망', 'Word2vec']","직업훈련 교육 현장에서 느끼는 가장 큰 어려움 중 하나는 중도탈락 문제이다. 훈련과정마다 많은 수의 학생들이 중도탈락을 하게 되어 국가 예산 낭비 및 청년 취업률 개선에 장애 요인이 되고 있다. 본 연구에서는 중도탈락의 원인을 주로 분석한 기존 연구들과 달리, 각종 수강생 정보를 활용하여 사전에 중도탈락을 예측할 수 있는 기계학습 기반 모형을 제안하고자 한다. 특히 본 연구의 제안모형은 수강생 관련 정형 데이터 뿐 아니라 비정형 데이터인 강사의 상담일지 정보까지 동시에 고려하여 모형의 예측정확도를 제고하고자 하였다. 이 때 비정형 데이터에 대한 분석은 최근 주목받고 있는 텍스트 분석 기술인 Word2vec과 합성곱 신경망을 이용해 수행하였다. 국내 한 직업훈련기관의 실제 데이터에 제안모형을 적용해 본 결과, 정형 데이터만을 사용하여 중도탈락을 예측할 때보다 비정형 데이터를 함께 고려했을 때 예측의 정확도가 최대 20%까지 향상됨을 확인할 수 있었다. 아울러, Support Vector Machine을 기반으로 정형 데이터와 비정형 데이터를 결합해 분석했을 때, 검증용 데이터셋 기준으로 90% 후반대의 높은 예측 정확도를 나타냄을 확인하였다.","One of the biggest difficulties in the vocational training field is the dropout problem. A large number of students drop out during the training process, which hampers the waste of the state budget and the improvement of the youth employment rate. Previous studies have mainly analyzed the cause of dropouts. The purpose of this study is to propose a machine learning based model that predicts dropout in advance by using various information of learners. In particular, this study aimed to improve the accuracy of the prediction model by taking into consideration not only structured data but also unstructured data. Analysis of unstructured data was performed using Word2vec and Convolutional Neural Network(CNN), which are the most popular text analysis technologies. We could find that application of the proposed model to the actual data of a domestic vocational training institute improved the prediction accuracy by up to 20%. In addition, the support vector machine-based prediction model using both structured and unstructured data showed high prediction accuracy of the latter half of 90%."
네트워크 공격 탐지 성능향상을 위한 딥러닝을 이용한 트래픽 데이터 생성 연구,2019,"['Network security', 'Intrusion detection', 'Network traffic data', 'Deep learning', 'GAN', '네트워크 보안', '침입탐지', '네트워크 트래픽 데이터', '딥러닝', 'GAN']","네트워크 공격을 탐지하기 위하여 기계학습을 이용한 다양한 연구가 최근 급격히 증가하고 있다. 이러한 기계학습 방법은 많은 데이터에 의존적이며 연구를 위해 다양한 실험 데이터가 공개되어 사용되고 있다. 하지만 실험 데이터 및 실제 환경에서 수집되는 데이터는 class간의 수량이 불균형하다는 문제점을 가지고 있다. 본 연구에서는 기계 학습을 이용한 침입탐지시스템의 한계점 중 학습데이터의 class간 불균형으로 인한 분류 성능 저하를 해결하기 위한 방법을 제안한다. 이를 위해 네트워크 트래픽 데이터를 처리하고 seqGAN를 이용하여 부족한 데이터를 생성하였다. 제안된 방법은 NSL-KDD, UNSW-NB15 데이터 셋을 대상으로 Text-CNN을 이용하여 분류하는 테스트를 실행한 결과 정밀도가 향상되는 것을 확인할 수 있었다.","Recently, various approaches to detect network attacks using machine learning have been studied and are being applied to detect new attacks and to increase precision. However, the machine learning method is dependent on feature extraction and takes a long time and complexity. It also has limitation of performace due to learning data imbalance. In this study, we propose a method to solve the degradation of classification performance due to imbalance of learning data among the limit points of detection system. To do this, we generate data using Generative Adversarial Networks (GANs) and propose a classification method using Convolutional Neural Networks (CNNs). Through this approach, we can confirm that the accuracy is improved when applied to the NSL-KDD and UNSW-NB15 datasets."
UNPU: An Energy-Efficient Deep Neural Network Accelerator With Fully Variable Weight Bit Precision,2019,[],국문 초록 정보 없음,"<P>An energy-efficient deep neural network (DNN) accelerator, unified neural processing unit (UNPU), is proposed for mobile deep learning applications. The UNPU can support both convolutional layers (CLs) and recurrent or fully connected layers (FCLs) to support versatile workload combinations to accelerate various mobile deep learning applications. In addition, the UNPU is the first DNN accelerator ASIC that can support fully variable weight bit precision from 1 to 16 bit. It enables the UNPU to operate on the accuracy-energy optimal point. Moreover, the lookup table (LUT)-based bit-serial processing element (LBPE) in the UNPU achieves the energy consumption reduction compared to the conventional fixed-point multiply-and-accumulate (MAC) array by 23.1%, 27.2%, 41%, and 53.6% for the 16-, 8-, 4-, and 1-bit weight precision, respectively. Besides the energy efficiency improvement, the unified DNN core architecture of the UNPU improves the peak performance for CL by 1.15 <TEX>$\times$</TEX> compared to the previous work. It makes the UNPU operate on the lower voltage and frequency for the given DNN to increase energy efficiency. The UNPU is implemented in 65-nm CMOS technology and occupies the <TEX>$4 \times 4$</TEX> mm<SUP>2</SUP> die area. The UNPU can operates from 0.63- to 1.1-V supply voltage with maximum frequency of 200 MHz. The UNPU has peak performance of 345.6 GOPS for 16-bit weight precision and 7372 GOPS for 1-bit weight precision. The wide operating range of UNPU makes the UNPU achieve the power efficiency of 3.08 TOPS/W for 16-bit weight precision and 50.6 TOPS/W for 1-bit weight precision. The functionality of the UNPU is successfully demonstrated on the verification system using ImageNet deep CNN (VGG-16).</P>"
객체 인식에서의 속도 향상을 위한 모델 앙상블,2019,"['Object detection', 'Ensemble method', 'Convolutional neural network']",국문 초록 정보 없음,다국어 초록 정보 없음
자율운항선박의 국제해상충돌예방규칙 준수를 위한 합성곱 신경망 기반의 선박 분류에 관한 연구,2019,"['자율운항선박', '선박 분류', '국제해상충돌예방규칙', '합성곱 신경망', 'Autonomous Ships', 'Vessel Classification', 'COLREGs', 'Convolutional Neural Networks']","최근 자율운항선박에 대한 관심이 증가하고 있으며, 바다를 항해하는 자율운항선박은 유인선과 같이 국제해상충돌방지규칙을 준수해야한다. 따라서 본 논문에서는 자율운항선박이 국제해상충돌예방규칙을 준수하기 위해서 필요한 선박 범주 및 합성곱 신경망 기반의 선박 분류 기술을 제안하였다. 먼저 국제해상충돌예방규칙을 분석하여 자율운항선박이 구별해야 되는 14개의 선박 범주를 정의하였다. 또한 본 논문에서 정의된 선박 범주에 맞도록 인터넷 영상검색 및 기존 데이터 셋 정제를 통하여 40,300장 규모의 선박 범주 분류 데이터 셋을 구축하였다. 마지막으로 최신 합성곱 신경망 모델을 구축된 선박 범주 분류 데이터 셋에 적용하여 선박 범주 분류 성능을 분석하였다. 실험결과 전이학습을 통하여 학습된 Inception-ResNet v2 모델은 14개 선박 범주를 91%의 높은 정확도로 분류함을 확인하였다.","The interest in autonomous ships for marine industries has increased significantly over the past few years and autonomous ships also must follow maritime laws in the same way as regular ships operated by crews. Therefore, in this paper, we propose the vessel taxonomy for COLREGs compliance of autonomous ships and evaluate the performance of the vessel classification method using CNNs. First, we define the vessel taxonomy for complying with maritime laws by analyzing the COLREGs. And then, we build our dataset separated manually by the vessel taxonomy. For the dataset, 40,300 images are collected by image search on websites and refining the publicly available dataset. Finally, the state-of-the-art CNN model is applied to evaluate the recognition rate of our dataset. The experimental results show that the Inception-ResNet v2 model which is trained by transfer learning effectively classifies the ships with a high accuracy of 91%."
Prediction Model of User Physical Activity using Data Characteristics-based Long Short-term Memory Recurrent Neural Networks,2019,"['Data Mining', 'Neural Networks', 'LSTM', 'Prediction', 'Mobile Healthcare']",국문 초록 정보 없음,"Recently, mobile healthcare services have attracted significant attention because of the emerging development and supply of diverse wearable devices. Smartwatches and health bands are the most common type of mobile-based wearable devices and their market size is increasing considerably. However, simple value comparisons based on accumulated data have revealed certain problems, such as the standardized nature of health management and the lack of personalized health management service models. The convergence of information technology (IT) and biotechnology (BT) has shifted the medical paradigm from continuous health management and disease prevention to the development of a system that can be used to provide ground-based medical services regardless of the user’s location. Moreover, the IT-BT convergence has necessitated the development of lifestyle improvement models and services that utilize big data analysis and machine learning to provide mobile healthcare-based personal health management and disease prevention information. Users’ health data, which are specific as they change over time, are collected by different means according to the users’ lifestyle and surrounding circumstances. In this paper, we propose a prediction model of user physical activity that uses data characteristics-based long short-term memory (DC-LSTM) recurrent neural networks (RNNs). To provide personalized services, the characteristics and surrounding circumstances of data collectable from mobile host devices were considered in the selection of variables for the model. The data characteristics considered were ease of collection, which represents whether or not variables are collectable, and frequency of occurrence, which represents whether or not changes made to input values constitute significant variables in terms of activity. The variables selected for providing personalized services were activity, weather, temperature, mean daily temperature, humidity, UV, fine dust, asthma and lung disease probability index, skin disease probability index, cadence, travel distance, mean heart rate, and sleep hours. The selected variables were classified according to the data characteristics. To predict activity, an LSTM RNN was built that uses the classified variables as input data and learns the dynamic characteristics of time series data. LSTM RNNs resolve the vanishing gradient problem that occurs in existing RNNs. They are classified into three different types according to data characteristics and constructed through connections among the LSTMs. The constructed neural network learns training data and predicts user activity. To evaluate the proposed model, the root mean square error (RMSE) was used in the performance evaluation of the user physical activity prediction method for which an autoregressive integrated moving average (ARIMA) model, a convolutional neural network (CNN), and an RNN were used. The results show that the proposed DC-LSTM RNN method yields an excellent mean RMSE value of 0.616. The proposed method is used for predicting significant activity considering the surrounding circumstances and user status utilizing the existing standardized activity prediction services. It can also be used to predict user physical activity and provide personalized healthcare based on the data collectable from mobile host devices."
문장 분류를 위한 정보 이득 및 유사도에 따른 단어 제거와 선택적 단어 임베딩 방안,2019,"['문장 분류', '특징 선택', '정보 이득', '단어 유사도', '단어 임베딩', 'Sentence Classification', 'Feature Selection', 'Information Gain', 'Word Similarity', 'Word Embedding']","텍스트 데이터가 특정 범주에 속하는지 판별하는 문장 분류에서, 문장의 특징을 어떻게 표현하고 어떤 특징을 선택할 것인가는 분류기의 성능에 많은 영향을 미친다. 특징 선택의 목적은 차원을 축소하여도 데이터를 잘설명할 수 있는 방안을 찾아내는 것이다. 다양한 방법이 제시되어 왔으며 Fisher Score나 정보 이득(Information Gain) 알고리즘 등을 통해 특징을 선택 하거나 문맥의 의미와 통사론적 정보를 가지는 Word2Vec 모델로 학습된 단어들을 벡터로 표현하여 차원을 축소하는 방안이 활발하게 연구되었다. 사전에 정의된 단어의 긍정 및 부정 점수에 따라 단어의 임베딩을 수정하는 방법 또한 시도하였다.본 연구는 문장 분류 문제에 대해 선택적 단어 제거를 수행하고 임베딩을 적용하여 문장 분류 정확도를 향상시키는 방안을 제안한다. 텍스트 데이터에서 정보 이득 값이 낮은 단어들을 제거하고 단어 임베딩을 적용하는방식과, 정보이득 값이 낮은 단어와 코사인 유사도가 높은 주변 단어를 추가로 선택하여 텍스트 데이터에서 제거하고 단어 임베딩을 재구성하는 방식이다.본 연구에서 제안하는 방안을 수행함에 있어 데이터는 Amazon.com의 ‘Kindle’ 제품에 대한 고객리뷰, IMDB 의 영화리뷰, Yelp의 사용자 리뷰를 사용하였다. Amazon.com의 리뷰 데이터는 유용한 득표수가 5개 이상을 만족하고, 전체 득표 중 유용한 득표의 비율이 70% 이상인 리뷰에 대해 유용한 리뷰라고 판단하였다. Yelp의 경우는 유용한 득표수가 5개 이상인 리뷰 약 75만개 중 10만개를 무작위 추출하였다. 학습에 사용한 딥러닝 모델은 CNN, Attention-Based Bidirectional LSTM을 사용하였고, 단어 임베딩은 Word2Vec과 GloVe를 사용하였다.단어 제거를 수행하지 않고 Word2Vec 및 GloVe 임베딩을 적용한 경우와 본 연구에서 제안하는 선택적으로 단어 제거를 수행하고 Word2Vec 임베딩을 적용한 경우를 비교하여 통계적 유의성을 검정하였다.","Dimensionality reduction is one of the methods to handle big data in text mining. For dimensionality reduction, we should consider the density of data, which has a significant influence on the performance of sentence classification. It requires lots of computations for data of higher dimensions. Eventually, it can cause lots of computational cost and overfitting in the model. Thus, the dimension reduction process is necessary to improve the performance of the model. Diverse methods have been proposed from only lessening the noise of data like misspelling or informal text to including semantic and syntactic information.On top of it, the expression and selection of the text features have impacts on the performance of the classifier for sentence classification, which is one of the fields of Natural Language Processing. The common goal of dimension reduction is to find latent space that is representative of raw data from observation space. Existing methods utilize various algorithms for dimensionality reduction, such as feature extraction and feature selection. In addition to these algorithms, word embeddings, learning low-dimensional vector space representations of words, that can capture semantic and syntactic information from data are also utilized. For improving performance, recent studies have suggested methods that the word dictionary is modified according to the positive and negative score of pre-defined words.The basic idea of this study is that similar words have similar vector representations. Once the feature selection algorithm selects the words that are not important, we thought the words that are similar to the selected words also have no impacts on sentence classification. This study proposes two ways to achieve more accurate classification that conduct selective word elimination under specific regulations and construct word embedding based on Word2Vec embedding. To select words having low importance from the text, we use information gain algorithm to measure the importance and cosine similarity to search for similar words. First, we eliminate words that have comparatively low information gain values from the raw text and form word embedding. Second, we select words additionally that are similar to the words that have a low level of information gain values and make word embedding. In the end, these filtered text and word embedding apply to the deep learning models; Convolutional Neural Network and Attention-Based Bidirectional LSTM.This study uses customer reviews on Kindle in Amazon.com, IMDB, and Yelp as datasets, and classify each data using the deep learning models. The reviews got more than five helpful votes, and the ratio of helpful votes was over 70% classified as helpful reviews. Also, Yelp only shows the number of helpful votes. We extracted 100,000 reviews which got more than five helpful votes using a random sampling method among 750,000 reviews. The minimal preprocessing was executed to each dataset, such as removing numbers and special characters from text data. To evaluate the proposed methods, we compared the performances of Word2Vec and GloVe word embeddings, which used all the words.We showed that one of the proposed methods is better than the embeddings with all the words. By removing unimportant words, we can get better performance. However, if we removed too many words, it showed that the performance was lowered. For future research, it is required to consider diverse ways of preprocessing and the in-depth analysis for the co-occurrence of words to measure similarity values among words. Also, we only applied the proposed method with Word2Vec. Other embedding methods such as GloVe, fastText, ELMo can be applied with the proposed methods, and it is possible to identify the possible combinations between word embedding methods and elimination methods."
영상기반 콘크리트 균열 탐지 딥러닝 모델의 유형별 성능 비교,2019,"['crack detection', 'deep learning', 'image classification', 'object detection', 'semantic segmentation', 'instance segmentation']",국문 초록 정보 없음,"In this study, various types of deep learning models that have been proposed recently are classified according to data input / output types and analyzed to find the deep learning model suitable for constructing a crack detection model. First the deep learning models are classified into image classification model, object segmentation model, object detection model, and instance segmentation model. ResNet-101, DeepLab V2, Faster R-CNN, and Mask R-CNN were selected as representative deep learning model of each type. For the comparison, ResNet-101 was implemented for all the types of deep learning model as a backbone network which serves as a main feature extractor. The four types of deep learning models were trained with 500 crack images taken from real concrete structures and collected from the Internet. The four types of deep learning models showed high accuracy above 94% during the training.Comparative evaluation was conducted using 40 images taken from real concrete structures. The performance of each type of deep learning model was measured using precision and recall. In the experimental result, Mask R-CNN, an instance segmentation deep learning model showed the highest precision and recall on crack detection.Qualitative analysis also shows that Mask R-CNN could detect crack shapes most similarly to the real crack shapes."
빠른 영역-합성곱 신경망을 이용한 다중 스케일 보행자 검출 방법,2019,[],"최근에 딥러닝 기술을 적용한 보행자 검출 연구가 활발히 진행되고 있다. 연구자들은 딥러닝 네트워크를 이용하여 보행자 오검출율을 낮추는 방법에 대해 지속적으로 연구하여 성능을 꾸준히 상승시켰다. 그러나 대부분의 연구는 다중 스케일 보행자가 분포되는 저해상도 영상에서 보행자를 제대로 검출하지 못하는 어려움이 존재한다. 따라서 본 연구에서는 기존의 Faster R-CNN 구조를 기반으로 하여 새로운 다중 특징 융합 레이어와 다중 스케일 앵커 박스를 적용하여 보행자 오검출율을 줄이는 MS-FRCNN(Multi-scaleF aster R-CNN) 구조를 제안한다. 제안된 방식의 성능 검증을 위해 Caltech 데이터세트를 이용하여 실험한 결과, 제안된 MS-FRCNN 방식이 기존의 다른 보행자 검출 방식보다 다중 스케일 보행자 검출에서 medium 조건하에 5%, all 조건하에 3.9% 나아짐을 알 수 있었다.",다국어 초록 정보 없음
RGB-D 카메라와 시맨틱 분할 기법을 이용한작업자의 안전 모니터링,2019,"['deep learning', 'semantic segmentation', 'safety monitoring', 'autonomous mobile robots']",국문 초록 정보 없음,"This paper suggests a deep learning-based algorithm for monitoring workers’ safety in a smart factory environment. With thegrowth of smart factories in industry, the need for an AMR (autonomous mobile robot) that self-drives in a production line is increasing.Although most AMRs are designed to actively prevent a collision, there should be another monitoring solution to double-check workers’safety because not all machines are reliable. We use an RGB-D camera which provides both depth information and RGB color informationand a semantic segmentation method to monitor workers’ safety. The semantic segmentation algorithm is called Mask R-CNN and is usedto detect workers and moveable equipment including AMRs. Since Mask R-CNN can specify an object’s boundary in RGB images, we areable to determine an object’s position in 3D coordinates by using the camera’s depth information. We can monitor the workers’ safety bychecking whether they are close to hazardous equipment. We experimented with an AMR and manufacturing equipment to verify oursuggested algorithm."
Extracting Vehicle Trajectories Using Unmanned Aerial Vehicles in Congested Traffic Conditions,2019,[],국문 초록 정보 없음,"<P>Obtaining the trajectories of all vehicles in congested traffic is essential for analyzing traffic dynamics. To conduct an effective analysis using trajectory data, a framework is needed to efficiently and accurately extract the data. Unfortunately, obtaining accurate trajectories in congested traffic is challenging due to false detections and tracking errors caused by factors in the road environment, such as adjacent vehicles, shadows, road signs, and road facilities. Unmanned aerial vehicles (UAVs), with incorporating machine learning and image processing, can mitigate these difficulties by their ability to hover above the traffic. However, research is lacking regarding the extraction and evaluation of vehicle trajectories in congested traffic. In this study, we propose and compare two learning-based frameworks for detecting vehicles: the aggregated channel feature (ACF), which is based on human-made features, and the faster region-based convolutional neural network (Faster R-CNN), which is based on data-driven features. We extend the detection results to extract vehicle trajectories in congested traffic conditions from UAV images. To remove the errors associated with tracking vehicles, we also develop a postprocessing method based on motion constraints. Then, we conduct detailed performance analyses to confirm the feasibility of the proposed framework on a congested expressway in Korea. The results show that Faster R-CNN outperforms the ACF in images with large objects and in those with small objects if sufficient data are provided. This framework extracts the vehicle trajectories with high precision, making them available for analyzing traffic dynamics based on the training of just a small number of positive samples. The results of this study provide a practical guideline for building a framework to extract vehicles trajectories based on given conditions.</P>"
딥 러닝 기반의 영상처리 기법을 이용한 겹침 돼지 분리,2019,"['Pig Monitoring', 'Occluding Pigs', 'Segmentation', 'Deep Learning', 'YOLO']",국문 초록 정보 없음,"The crowded environment of a domestic pig farm is highly vulnerable to the spread of infectious diseases such as foot-and-mouth disease, and studies have been conducted to automatically analyze behavior of pigs in a crowded pig farm through a video surveillance system using a camera. Although it is required to correctly separate occluding pigs for tracking each individual pigs, extracting the boundaries of the occluding pigs fast and accurately is a challenging issue due to the complicated occlusion patterns such as X shape and T shape. In this study, we propose a fast and accurate method to separate occluding pigs not only by exploiting the characteristics (i.e., one of the fast deep learning-based object detectors) of You Only Look Once, YOLO, but also by overcoming the limitation (i.e., the bounding box-based object detector) of YOLO with the test-time data augmentation of rotation. Experimental results with two-pigs occlusion patterns show that the proposed method can provide better accuracy and processing speed than one of the state-of-the-art widely used deep learning-based segmentation techniques such as Mask R-CNN (i.e., the performance improvement over Mask R-CNN was about 11 times, in terms of the accuracy/processing speed performance metrics)."
Bridge Inspection and condition assessment using Unmanned Aerial Vehicles (UAVs): Major challenges and solutions from a practical perspective,2019,"['bridge inspection', 'unmanned aerial vehicle (UAV)', 'imaging device', 'condition assessment', 'deep learning algorithm']",국문 초록 정보 없음,"Bridge collapses may deliver a huge impact on our society in a very negative way. Out of many reasons why bridges collapse, poor maintenance is becoming a main contributing factor to many recent collapses. Furthermore, the aging of bridges is able to make the situation much worse. In order to prevent this unwanted event, it is indispensable to conduct continuous bridge monitoring and timely maintenance. Visual inspection is the most widely used method, but it is heavily dependent on the experience of the inspectors. It is also time-consuming, labor-intensive, costly, disruptive, and even unsafe for the inspectors. In order to address its limitations, in recent years increasing interests have been paid to the use of unmanned aerial vehicles (UAVs), which is expected to make the inspection process safer, faster and more cost-effective. In addition, it can cover the area where it is too hard to reach by inspectors. However, this strategy is still in a primitive stage because there are many things to be addressed for real implementation. In this paper, a typical procedure of bridge inspection using UAVs consisting of three phases (i.e., pre-inspection, inspection, and post-inspection phases) and the detailed tasks by phase are described. Also, three major challenges, which are related to a UAV’s flight, image data acquisition, and damage identification, respectively, are identified from a practical perspective (e.g., localization of a UAV under the bridge, high-quality image capture, etc.) and their possible solutions are discussed by examining recently developed or currently developing techniques such as the graph-based localization algorithm, and the image quality assessment and enhancement strategy. In particular, deep learning based algorithms such as R-CNN and Mask R-CNN for classifying, localizing and quantifying several damage types (e.g., cracks, corrosion, spalling, efflorescence, etc.) in an automatic manner are discussed. This strategy is based on a huge amount of image data obtained from unmanned inspection equipment consisting of the UAV and imaging devices (vision and IR cameras)."
딥러닝을 이용한 객체 검출 알고리즘,2019,[],국문 초록 정보 없음,"Object detection is applied in various field. Autonomous driving, surveillance, OCR(optical character recognition) and aerial image etc. We will look at the algorithms that are using to object detect. These algorithms are divided into two methods. The one is R-CNN algorithms [2], [5], [6] which based on region proposal. The other is YOLO [7] and SSD [8] which are one stage object detector based on regression/classification."
Deep Learning and Color Histogram based Fire and Smoke Detection Research,2019,"['Fire Detection', 'Deep Learning', 'Structure Similarity', 'Frame Difference', 'Color Histogram']",국문 초록 정보 없음,"The fire should extinguish as soon as possible because it causes economic loss and loses precious life. In this study, we propose a new atypical fire and smoke detection algorithm using deep learning and color histogram of fire and smoke. First, input frame images obtain from the ONVIF surveillance camera mounted in factory search motion candidate frame by motion detection algorithm and mean square error (MSE). Second deep learning (Faster R-CNN) is used to extract the fire and smoke candidate area of motion frame. Third, we apply a novel algorithm to detect the fire and smoke using color histogram algorithm with local area motion, similarity, and MSE. In this study, we developed a novel fire and smoke detection algorithm applied the local motion and color histogram method. Experimental results show that the surveillance camera with the proposed algorithm showed good fire and smoke detection results with very few false positives."
Deep Learning and Color Histogram based Fire and Smoke Detection Research,2019,"['Fire Detection', 'Deep Learning', 'Structure Similarity', 'Frame Difference. Color Histogram.']",국문 초록 정보 없음,"The fire should extinguish as soon as possible because it causes economic loss and loses precious life. In this study, we propose a new atypical fire and smoke detection algorithm using deep learning and color histogram of fire and smoke. First, input frame images obtain from the ONVIF surveillance camera mounted in factory search motion candidate frame by motion detection algorithm and mean square error (MSE).Second deep learning (Faster R-CNN) is used to extract the fire and smoke candidate area of motion frame.Third, we apply a novel algorithm to detect the fire and smoke using color histogram algorithm with local area motion, similarity, and MSE. In this study, we developed a novel fire and smoke detection algorithm applied the local motion and color histogram method. Experimental results show that the surveillance camera with the proposed algorithm showed good fire and smoke detection results with very few false positives."
A method based on Multi-Convolution layers Joint and Generative Adversarial Networks for Vehicle Detection,2019,"['Vehicle detection', 'non-maximum suppression', 'generative adversarial networks', 'joint feature map', 'mask occlusion']",국문 초록 정보 없음,"In order to achieve rapid and accurate detection of vehicle objects in complex traffic conditions, we propose a novel vehicle detection method. Firstly, more contextual and small-object vehicle information can be obtained by our Joint Feature Network (JFN). Secondly, our Evolved Region Proposal Network (EPRN) generates initial anchor boxes by adding an improved version of the region proposal network in this network, and at the same time filters out a large number of false vehicle boxes by soft-Non Maximum Suppression (NMS). Then, our Mask Network (MaskN) generates an example that includes the vehicle occlusion, the generator and discriminator can learn from each other in order to further improve the vehicle object detection capability. Finally, these candidate vehicle detection boxes are optimized to obtain the final vehicle detection boxes by the Fine-Tuning Network(FTN). Through the evaluation experiment on the DETRAC benchmark dataset, we find that in terms of mAP, our method exceeds Faster-RCNN by 11.15%, YOLO by 11.88%, and EB by 1.64%. Besides, our algorithm also has achieved top2 comaring with MS-CNN, YOLO-v3, RefineNet, RetinaNet, Faster-rcnn, DSSD and YOLO-v2 of vehicle category in KITTI dataset."
건설현장 근로자의 안전모 착용 여부 검출을 위한 컴퓨터 비전 기반 딥러닝 알고리즘의 적용,2019,"['construction safety', 'safety helmet', 'deep learning', 'computer vision']",국문 초록 정보 없음,"Since construction sites are exposed to outdoor environments, working conditions are significantly dangerous. Thus, wearing of the personal protective equipments such as safety helmet is very important for worker safety. However, construction workers are often wearing-off the helmet as inconvenient and uncomportable. As a result, a small mistake may lead to serious accident. For this, checking of wearing safety helmet is important task to safety managers in field.However, due to the limited time and manpower, the checking can not be executed for every individual worker spread over a large construction site. Therefore, if an automatic checking system is provided, field safety management should be performed more effectively and efficiently. In this study, applicability of deep learning based computer vision technology is investigated for automatic checking of wearing safety helmet in construction sites. Faster R-CNN deep learning algorithm for object detection and classification is employed to develop the automatic checking model. Digital camera images captured in real construction site are used to validate the proposed model.Based on the results, it is concluded that the proposed model may effectively be used for automatic checking of wearing safety helmet in construction site."
Two person Interaction Recognition Based on Effective Hybrid Learning,2019,"['Action Recognition', 'Convolutional Neural Network', 'Deep Architecture', 'Transfer Learning']",국문 초록 정보 없음,"Action recognition is an essential task in computer vision due to the variety of prospective applications, such as security surveillance, machine learning, and human-computer interaction. The availability of more video data than ever before and the lofty performance of deep convolutional neural networks also make it essential for action recognition in video. Unfortunately, limited crafted video features and the scarcity of benchmark datasets make it challenging to address the multi-person action recognition task in video data. In this work, we propose a deep convolutional neural network-based Effective Hybrid Learning (EHL) framework for two-person interaction classification in video data. Our approach exploits a pre-trained network model (the VGG16 from the University of Oxford Visual Geometry Group) and extends the Faster R-CNN (region-based convolutional neural network a state-of-the-art detector for image classification). We broaden a semi-supervised learning method combined with an active learning method to improve overall performance. Numerous types of two-person interactions exist in the real world, which makes this a challenging task. In our experiment, we consider a limited number of actions, such as hugging, fighting, linking arms, talking, and kidnapping in two environment such simple and complex. We show that our trained model with an active semi-supervised learning architecture gradually improves the performance. In a simple environment using an Intelligent Technology Laboratory (ITLab) dataset from Inha University, performance increased to 95.6% accuracy, and in a complex environment, performance reached 81% accuracy. Our method reduces data-labeling time, compared to supervised learning methods, for the ITLab dataset. We also conduct extensive experiment on Human Action Recognition benchmarks such as UT-Interaction dataset, HMDB51 dataset and obtain better performance than state-of-the-art approaches."
분광 분석법을 활용한 국내산 포도 품종 통합 당도 검량식 개발 연구,2019,"['분광 분석법', '당도측정', '포도', 'PLSR', '머신러닝']","한국의 신선농산물 수출액은 최근 3년간 꾸준히 증가하고 있으며 2018년에는 12억 8천만 달러로 전년대비 1억 8200만 달러가 늘어나 역대 최고의 증가액 실적을 기록하였다. 이러한 호재의 배경에는 한류와 함께 퍼져나간 한국산 과일의 인기가 한몫했다고 알려져 있는데, 그중 두드러지는 약진을 보여준 것이 바로 ‘포도’이다. 한국산 포도는 ‘샤인 머스캣’이라 불리는 신품종을 앞세워 특히 중국과 베트남 등의 동남아 지역에서 최근 폭발적인 인기를 얻고 있으며, 특유의 향기와 높은 당도로 최근 국내에서도 그 인기가 날로 상승하고 있다. 그 결과, 오랜 시간 동안 국내 포도 재배의 약 80% 이상을 차지하던 주력 품종인 캠벨과 거봉을 빠른 속도로 대체해 가고 있으며, 이에 따라 국내 포도 재배 트랜드도 급격하게 변화하고 있다. 하지만, 실제 농가를 방문해본 결과 샤인 머스캣을 지원하는 당도 선별기의 보급은 상당히 더딘 편이었으며, 몇 농가에서만 간이 측정기로 당도를 측정해 출하하고 있는 것이 실정이었다. 또한, 주력 품종이 변화하고 있는 과도기인 만큼 아직 샤인 머스캣뿐만 아니라 기존의 캠벨이나 거봉을 함께 재배하는 농가들도 다수 존재하였는데, 이런 경우 정확한 당도 정보를 얻기 위해서는 품종별로 상이한 당도 측정기를 사용해야 한다는 불편함도 있었다. 따라서, 본 연구에서는 캠벨과 거봉 그리고 샤인 머스캣에 대해 한 번에 적용할 수 있는 품종 통합 당도 측정 모델을 개발하고자 하였다. 모델에 사용한 알고리즘으로는 오늘날 농산물산지유통센터 선별기에 주로 보급된 PLSR(Partial Least Squares Regression)과 여기에 추가로 파장 선택법을 적용해 효율을 증가시킨 VIP(Variable Importance in Projection)-PLSR, Beta-Bootstrap-PLSR 등의 통계적인 방식이 있다. 또한, 최근 분광분석 연구들에서 종종 기존의 통계적인 기법보다 개선된 결과를 보여주고 있는 SVR(Support Vector Regression), ANN(Artificial Neural Network), 1D-CNN(1 Dimensional Convolution Neural Network) 등과 같은 머신러닝 기반의 알고리즘들도 접목하여 최적의 통합 당도 검량식 모델을 선정하는 것을 목표로 하였다.",다국어 초록 정보 없음
