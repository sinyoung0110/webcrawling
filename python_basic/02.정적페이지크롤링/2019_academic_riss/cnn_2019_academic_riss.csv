title,date,keywords,abstract,multilingual_abstract
CNN 기반 초분광 영상 분류를 위한 PCA 차원축소의 영향 분석,2019,"['Principal Component Analysis', 'Convolutional Neural Network', 'Dimensionality Reduction', 'Hyperspectral Image Classification']","대표적인 딥러닝(deep learning) 기법 중 하나인 Convolutional Neural Network(CNN)은 고수준의 공간- 분광 특징을 추출할 수 있어 초분광 영상 분류(Hyperspectral Image Classification)에 적용하는 연구가 활발히 진행되고 있다. 그러나 초분광 영상은 높은 분광 차원이 학습 과정의 시간과 복잡도를 증가시킨다는 문제가 있어 이를 해결하기 위해 기존 딥러닝 기반 초분광 영상 분류 연구들에서는 차원축소의 목적으로 Principal Component Analysis (PCA)를 적용한 바 있다. PCA는 데이터를 독립적인 주성분의 축으로 변환시킬 수 있어 분광 차원을 효율적으로 압축할 수 있으나, 분광 정보의 손실을 초래할 수 있다. PCA의 사용 유무가 CNN 학습의정확도와 시간에 영향을 미치는 것은 분명하지만 이를 분석한 연구가 부족하다. 본 연구의 목적은 PCA를 통한분광 차원축소가 CNN에 미치는 영향을 정량적으로 분석하여 효율적인 초분광 영상 분류를 위한 적절한 PCA 의 적용 방법을 제안하는 데에 있다. 이를 위해 PCA를 적용하여 초분광 영상을 축소시켰으며, 축소된 차원의크기를 바꿔가며 CNN 모델에 적용하였다. 또한, 모델 내의 컨볼루션(convolution) 연산 방식에 따른 PCA의 민감도를 분석하기 위해 2D-CNN과 3D-CNN을 적용하여 비교 분석하였다. 실험결과는 분류정확도, 학습시간, 분산 비율, 학습 과정을 통해 분석되었다. 축소된 차원의 크기가 분산 비율이 99.7~8%인 주성분 개수일 때 가장 효율적이었으며, 3차원 커널 경우 2D-CNN과는 다르게 원 영상의 분류정확도가 PCA-CNN보다 더 높았으며, 이를 통해 PCA의 차원축소 효과가 3차원 커널에서 상대적으로 적은 것을 알 수 있었다.","CNN (Convolutional Neural Network) is one representative deep learning algorithm, which can extract high-level spatial and spectral features, and has been applied for hyperspectral image classification. However, one significant drawback behind the application of CNNs in hyperspectral images is the high dimensionality of the data, which increases the training time and processing complexity. To address this problem, several CNN based hyperspectral image classification studies have exploited PCA (Principal Component Analysis) for dimensionality reduction. One limitation to this is that the spectral information of the original image can be lost through PCA. Although it is clear that the use of PCA affects the accuracy and the CNN training time, the impact of PCA for CNN based hyperspectral image classification has been understudied. The purpose of this study is to analyze the quantitative effect of PCA in CNN for hyperspectral image classification. The hyperspectral images were first transformed through PCA and applied into the CNN model by varying the size of the reduced dimensionality. In addition, 2D-CNN and 3D-CNN frameworks were applied to analyze the sensitivity of the PCA with respect to the convolution kernel in the model. Experimental results were evaluated based on classification accuracy, learning time, variance ratio, and training process. The size of the reduced dimensionality was the most efficient when the explained variance ratio recorded 99.7%~99.8%. Since the 3D kernel had higher classification accuracy in the original-CNN than the PCA-CNN in comparison to the 2D-CNN, the results revealed that the dimensionality reduction was relatively less effective in 3D kernel."
CNN-LSTM 조합모델을 이용한 영화리뷰 감성분석,2019,"['CNN', 'LSTM', 'Deep Learning', 'Integrated Model', 'Movie Review', 'Sentiment Analysis', 'CNN', 'LSTM', '딥러닝', '조합모델', '영화리뷰', '감성분석']","인터넷 기술과 소셜 미디어의 빠른 성장으로 인하여, 구조화되지 않은 문서 표현도 다양한 응용 프로그램에사용할 수 있게 마이닝 기술이 발전되었다. 그 중 감성분석은 제품이나 서비스에 내재된 사용자의 감성을 탐지할 수 있는 분석방법이기 때문에 지난 몇 년 동안 많은 관심을 받아왔다. 감성분석에서는 주로 텍스트 데이터를이용하여 사람들의 감성을 사전 정의된 긍정 및 부정의 범주를 할당하여 분석하며, 이때 사전 정의된 레이블을이용하기 때문에 다양한 방향으로 연구가 진행되고 있다. 초기의 감성분석 연구에서는 쇼핑몰 상품의 리뷰 중심으로 진행되었지만, 최근에는 블로그, 뉴스기사, 날씨 예보, 영화 리뷰, SNS, 주식시장의 동향 등 다양한 분야에 적용되고 있다. 많은 선행연구들이 진행되어 왔으나 대부분 전통적인 단일 기계학습기법에 의존한 감성분류를 시도하였기에 분류 정확도 면에서 한계점이 있었다. 본 연구에서는 전통적인 기계학습기법 대신 대용량 데이터의 처리에 우수한 성능을 보이는 딥러닝 기법과 딥러닝 중 CNN과 LSTM의 조합모델을 이용하여 감성분석의 분류 정확도를 개선하고자 한다. 본 연구에서는 대표적인 영화 리뷰 데이터셋인 IMDB의 리뷰 데이터 셋을이용하여, 감성분석의 극성분석을 긍정 및 부정으로 범주를 분류하고, 딥러닝과 제안하는 조합모델을 활용하여극성분석의 예측 정확도를 개선하는 것을 목적으로 한다. 이 과정에서 여러 매개 변수가 존재하기 때문에 그수치와 정밀도의 관계에 대해 고찰하여 최적의 조합을 찾아 정확도 등 감성분석의 성능 개선을 시도한다. 연구결과, 딥러닝 기반의 분류 모형이 좋은 분류성과를 보였으며, 특히 본 연구에서 제안하는 CNN-LSTM 조합모델의 성과가 가장 우수한 것으로 나타났다.","Rapid growth of internet technology and social media is progressing. Data mining technology has evolved to enable unstructured document representations in a variety of applications. Sentiment analysis is an important technology that can distinguish poor or high-quality content through text data of products, and it has proliferated during text mining. Sentiment analysis mainly analyzes people's opinions in text data by assigning predefined data categories as positive and negative. This has been studied in various directions in terms of accuracy from simple rule-based to dictionary-based approaches using predefined labels. In fact, sentiment analysis is one of the most active researches in natural language processing and is widely studied in text mining. When real online reviews aren't available for others, it's not only easy to openly collect information, but it also affects your business. In marketing, real-world information from customers is gathered on websites, not surveys. Depending on whether the website's posts are positive or negative, the customer response is reflected in the sales and tries to identify the information. However, many reviews on a website are not always good, and difficult to identify. The earlier studies in this research area used the reviews data of the Amazon.com shopping mal, but the research data used in the recent studies uses the data for stock market trends, blogs, news articles, weather forecasts, IMDB, and facebook etc. However, the lack of accuracy is recognized because sentiment calculations are changed according to the subject, paragraph, sentiment lexicon direction, and sentence strength. This study aims to classify the polarity analysis of sentiment analysis into positive and negative categories and increase the prediction accuracy of the polarity analysis using the pretrained IMDB review data set. First, the text classification algorithm related to sentiment analysis adopts the popular machine learning algorithms such as NB (naive bayes), SVM (support vector machines), XGboost, RF (random forests), and Gradient Boost as comparative models.Second, deep learning has demonstrated discriminative features that can extract complex features of data. Representative algorithms are CNN (convolution neural networks), RNN (recurrent neural networks), LSTM (long-short term memory). CNN can be used similarly to BoW when processing a sentence in vector format, but does not consider sequential data attributes. RNN can handle well in order because it takes into account the time information of the data, but there is a long-term dependency on memory. To solve the problem of long-term dependence, LSTM is used. For the comparison, CNN and LSTM were chosen as simple deep learning models. In addition to classical machine learning algorithms, CNN, LSTM, and the integrated models were analyzed. Although there are many parameters for the algorithms, we examined the relationship between numerical value and precision to find the optimal combination. And, we tried to figure out how the models work well for sentiment analysis and how these models work. This study proposes integrated CNN and LSTM algorithms to extract the positive and negative features of text analysis. The reasons for mixing these two algorithms are as follows. CNN can extract features for the classification automatically by applying convolution layer and massively parallel processing. LSTM is not capable of highly parallel processing. Like faucets, the LSTM has input, output, and forget gates that can be moved and controlled at a desired time. These gates have the advantage of placing memory blocks on hidden nodes. The memory block of the LSTM may not store all the data, but it can solve the CNN's long-term dependency problem. Furthermore, when LSTM is used in CNN's pooling layer, it has an end-to-end structure, so that spatial and temporal features can be designed simultaneously. In combination with CNN-LSTM, 90.33% accuracy was measured. Thi..."
관절질환 관리를 위한 Mask R-CNN을 이용한 모션 모니터링,2019,"['CNN', '휴먼모션', '헬스케어', '딥러닝', 'Mask R-CNN', '개인건강기록', 'CNN', 'Human Motion', 'Healthcare', 'Deep Learning', 'Mask R-CNN', 'Personal Health Record']","현대사회는 생활과 개성이 중요시 되면서 개인화된 생활습관 및 패턴이 생기고 있으며, 잘못된 생활습관으로 인해 관절질환자가 증가하고 있다. 또한 1인 가구가 점점 증가하면서 응급상황이 발생할 경우 알맞은 시간에 응급처치를 받지 못하는 경우가 생긴다. 건강과 질병관리에 필요한 개인의 상태에 따른 정확한 분석을 통해 스스로 관리할 수 있는 정보와 응급상황에 맞는 케어가 필요하다. 딥러닝 중에서 CNN은 데이터의 분류 및 예측에 효율적으로 사용된다. CNN은 데이터 특징에 따라 정확도 및 처리 속도에 차이를 보인다. 따라서 실시간 헬스케어를 위해 처리속도 향상과 정확도 개선이 필요하다. 본 논문에서는 관절질환 관리를 위한 Mask R-CNN을 이용한 모션 모니터링을 제안한다. 제안하는 방법은 Mask R-CNN을 이용하여 CNN의 정확도와 처리 속도를 개선하는 방법이다. 사용자의 모션을 신경망에 학습시킨 후 사용자의 모션이 학습된 데이터와 차이가 있을 경우 사용자에게 관리법을 피드백 해주고 보호자에게 응급상황을 알릴 수 있으며 상황에 맞는 적절한 조치를 취할 수 있다.","In modern society, lifestyle and individuality are important, and personalized lifestyle and patterns are emerging. The number of people with articulation diseases is increasing due to wrong living habits. In addition, as the number of households increases, there is a case where emergency care is not received at the appropriate time. We need information that can be managed by ourselves through accurate analysis according to the individual's condition for health and disease management, and care appropriate to the emergency situation. It is effectively used for classification and prediction of data using CNN in deep learning. CNN differs in accuracy and processing time according to the data features. Therefore, it is necessary to improve processing speed and accuracy for real-time healthcare. In this paper, we propose motion monitoring using Mask R-CNN for articulation disease management. The proposed method uses Mask R-CNN which is superior in accuracy and processing time than CNN. After the user's motion is learned in the neural network, if the user's motion is different from the learned data, the control method can be fed back to the user, the emergency situation can be informed to the guardian, and appropriate methods can be taken according to the situation."
"뉴스 텍스트에 나타난 아랍어의 통합성지수 연구 - 아랍뉴스 ‘al-Riyadh’, ‘al-Ahram’과 KBS, CNN의 아랍어 번역뉴스 비교를 중심으로 –",2019,"['Index of Synthesis', 'Media Arabic Language', 'Levelling Out in Translation', '통합성 지수', '미디어 아랍어', '번역어의 특징']","본 고에서는 현대 표준 아랍어의 특징이 형태적으로 잘 유지되고 있는지를 알아보기 위하여, 사우디 아라비아의 ‘알리야드’지와 이집트의 ‘알아흐람’지가 포함된 아랍권 뉴스 텍스트의 통합성 지수와 국내의 KBS의 아랍어 뉴스와 미국 CNN 아랍어의 통합성 지수를 비교해 보았다. 아랍권 뉴스의 평균 통합성 지수는 4.34, 국내의 KBS 아랍어 뉴스의 통합성 지수는 4.07, 미국 CNN 아랍어뉴스의 통합성 지수는 4.27임을 확인하였다. 통합성 지수 전체로 보아서는 미국 CNN 아랍어뉴스의 통합성 지수가 국내의 KBS의 아랍어 뉴스보다 아랍권 뉴스의 현대 표준 아랍어에 더 가까운 것으로 나타났다.한편 타갈로그어, 베트남어, 페르시아어, 터키어와 같은 언어와 아랍어의 통합성 지수를 측정했던 페인(Payne 1990, 178)은 그의 연구에서 아랍어의 통합성 지수를 3.14로 규정했는데, 그는 통합성 지수에 사용된 언어자료를 구체적으로 밝히지 않았다. 그런데 이 수치는 본 연구에서 측정한 사우디 아라비아의 대표적 인터넷 신문인 ‘일 리야드’지의 통합성 지수 3.14와 일치한다는 흥미로운 사실을 확인할 수 있었다. 본 연구의 수치는 품사를 제외한 수치이므로 페인이 측정한 텍스트의 유형은 현대 표준 아랍어 중 뉴스 텍스트일 가능성이 매우 높고, 단어당 형태소를 측정하는 통합성 지수 수식에서 품사를 제외했을 가능성도 있다.아랍권 뉴스나 미국의 CNN 아랍어 뉴스에 비해 국내의 KBS뉴스에서 품사수의 분포가 1,000여개 더 적게 나왔다. 총 형태소 수에서도 동일한 경향이 나타나 국내의 KBS뉴스의 총 형태소 수가 아랍권 뉴스나 미국의 CNN 아랍어 뉴스에 비해 더 적게 나왔다.아랍권 뉴스 평균과 국내의 KBS 아랍어 뉴스에서 동사 사용이 각 428개, 453개로 유사한 분포를 보였으나, 미국의 CNN 아랍어 뉴스에서는 동사 사용이 200 여개 더 많은 674개로 상이한 양상을 나타냈다. 게다가 명사류의 사용분포를 보면, 국내의 KBS 아랍어 뉴스와 미국의 CNN 아랍어 뉴스에서는 각 3,826개, 3,776개인 반면 아랍권 뉴스 평균이 4,091개로, 아랍권 뉴스에서 명사류의 사용분포가 더 많았다. 이것은 문 구조에서, 아랍권 뉴스와 국내의 KBS 아랍어 뉴스의 경우 명사문을 더 선호한다는 것을 나타낸다. 반면 미국의 CNN 아랍어 뉴스에서는 명사문보다 동사문을 더 선호한다는 것을 보여준다. 선행 국내의 연구 중 코란과 현대 표준 아랍어를 비교한 연구가 있는데(이인섭 2019, 11-12), 본 연구와 동일한 코퍼스 크기인 코란 5,000 어절을 기준으로, 코란에서는 1,311개의 동사가 사용되었다. 코란과 비교하자면, 아랍권 뉴스와 국내의 KBS 아랍어 뉴스 텍스트와 달리 미국의 CNN 아랍어 뉴스 텍스트의 문 구조가 동사문을 선호하는 코란의 문구조 경향에 더 가깝다는 것을 알 수 있다.그렇다면 미국의 CNN 아랍어 뉴스 텍스트에서 동사문이 선호되는 현상은 실제로 코란의 아랍어에 근접하게 번역되었기 때문인지 생각해 볼 필요가 있다. CNN 아랍어 뉴스에 쓰인 내용을 보면 아랍의 시리아 공습과 리비아 혹은 아랍과 이스라엘 간의 관계에 관한 내용 등도 있었지만 미국 뉴스 사이트인 만큼 미국 국내의 사정내용도 상당 부분 언급되고 있다. 여기서 영어로 기사 작성된 미국 국내의 뉴스가 아랍어로 번역되었다는 점을 고려해 보아야 할 것이다. 기사가 영어에서 아랍어로 번역되는 과정을 감안하면, 출발어인 영어의 언어관습이 아랍어 번역문에도 영향  ...","The study aims to compare the index of synthesis of Arabic language between non-translated news texts and translated news texts. It is analyzed through an index of synthesis of media Arabic language, which means internet Arabic news; including, ‘al-Riyadh’ of Saudi Arabia, and ‘al-Ahram’ of Egypt, in contrast to ‘KBS Arabic news of South Korea’ and ‘CNN Arabic news of the United States’. The average of the index of synthesis of internet news in Saudi Arabia and Egypt stood at 4.34, the index of synthesis of Arabic language of internet news of South Korea stood at 4.07, and the index of synthesis of CNN Arabic news stood at 4.27. In addition, translated news texts in Arabic were affected by language customs of the source texts: it is neither target-language nor source-language dependent, and that is what we call “levelling out”."
"CNN의 컨볼루션 레이어, 커널과 정확도의 연관관계 분석",2019,"['Deep Learning', 'Convolution Neural Network', 'Kernel', 'Layer', 'Accuracy', 'Learning Time', '딥러닝', 'CNN', '커널', '레이어', '정확도', '학습 시간']","본 논문에서는 CNN의 컨볼루션 레이어 개수 및 커널의 크기와 개수가 CNN에 어떠한 영향을 끼치는지 실험을 통해 알아보기 위해 진행하였다. 또한 분석을 위해 일반적인 CNN도 실험하여 실험에 사용된 CNN과 비교하 였다. 분석에 사용될 신경망들은 CNN을 기반으로 하며 각각의 실험모델들은 레이어 개수, 커널의 크기 및 개수를 일정한 값으로 고정해 실험을 진행하였다. 모든 실험에는 2계층의 완전연결계층을 고정으로 사용하였다. 다른 변수들은 모두 동일한 값을 주어 실험하였다. 분석결과 레이어의 수가 작을 경우 커널의 크기 및 개수와 상관없이 데이터의 분산 값이 작아 견고한 정확도를 보여주었다. 레이어의 수가 커질수록 정확도도 증가됐으나 일정 수치 이상부턴 오히려 정확도가 내려갔으며 분산 값도 커져 정확도 편차가 크게 나타났다. 커널의 개수는 다른 변수보다 학습속도에 큰 영향을 끼쳤다.","In this paper, we experimented to find out how the number of convolution layers, the size, and the number of kernels affect the CNN. In addition, the general CNN was also tested for analysis and compared with the CNN used in the experiment. The neural networks used for the analysis are based on CNN, and each experimental model is experimented with the number of layers, the size, and the number of kernels at a constant value. All experiments were conducted using two layers of fully connected layers as a fixed. All other variables were tested with the same value. As the result of the analysis, when the number of layers is small, the data variance value is small regardless of the size and number of kernels, showing a solid accuracy. As the number of layers increases, the accuracy increases, but from above a certain number, the accuracy decreases, and the variance value also increases, resulting in a large accuracy deviation. The number of kernels had a greater effect on learning speed than other variables."
홈보안 시스템을 위한 CNN 기반 2D와 2.5D 얼굴 인식,2019,"['Face Recognition', 'Convolutional Neural Networks', 'Smart Home Security System', 'Face Accurac', '얼굴 인식', '컨벌루션 신경망', '스마트 홈보안 시스템', '얼굴 정확도']","4차 산업혁명의 기술이 우리도 모르는 사이 우리의 삶 속으로 스며들고 있다. CNN이 이미지 인식 분야에서 탁월한 능력을 보여준 이후 많은 IoT 기반 홈보안 시스템은 침입자로부터 가족과 가정을 보호하며 얼굴을 인식하기 위한 좋은 생체인식 방법으로 CNN을 사용하고 있다. 본 논문에서는 2D와 2.5D 이미지에 대하여 여러 종류의 입력 이미지 크기와 필터를 가지고 있는 CNN의 구조를 연구한다. 실험 결과는 50*50 크기를 가진 2.5D 입력 이미지, 2 컨벌류션과 맥스풀링 레이어, 3*3 필터를 가진 CNN 구조가 0.966의 인식률을 보여 주었고, 1개의 입력 이미지에 대하여 가장 긴 CPU 소비시간은 0.057S로 나타났다. 홈보안 시스템은 좋은 얼굴 인식률과 짧은 연산 시간을 요구 하므로 본 논문에서 제안한 구조의 CNN은 홈보안 시스템에서 얼굴인식을 기반으로 하는 액추에이터 제어 등에 적합한 방법이 될 것이다.","Technologies of the 4th industrial revolution have been unknowingly seeping into our lives. Many IoT based home security systems are using the convolutional neural network(CNN) as good biometrics to recognize a face and protect home and family from intruders since CNN has demonstrated its excellent ability in image recognition. In this paper, three layouts of CNN for 2D and 2.5D image of small dataset with various input image size and filter size are explored. The simulation results show that the layout of CNN with 50*50 input size of 2.5D image, 2 convolution and max pooling layer, and 3*3 filter size for small dataset of 2.5D image is optimal for a home security system with recognition accuracy of 0.966. In addition, the longest CPU time consumption for one input image is 0.057S. The proposed layout of CNN for a face recognition is suitable to control the actuators in the home security system because a home security system requires good face recognition and short recognition time."
계층적 CNN 구조를 이용한 스테가노그래피 식별,2019,"['Steganalysis', 'CNN', 'Multi-level classification', 'Hierarchical structure', 'Secret data recovery', '스테그아날리시스', 'CNN', '다층 분류', '계층적 구조', '비밀 데이터 복원']","스테그아날리시스(steganalysis)는 스테가노그래피(steganography)에 의해 숨겨진 데이터를 감지하고 복구하기 위한 기법이다. 스테그아날리시스 방법은 데이터 삽입 시 발생하는 시각적, 통계적 변화를 분석하여 숨겨진 데이터를 찾는다. 숨겨진 데이터를 복원하기 위해서는 어떤 스테가노그래피 방법에 의해 데이터가 숨겨졌는지를 알아야 한다. 그러므로 본 논문은 다층 분류를 통해 입력 영상에 적용된 스테가노그래피 방법을 식별하는 계층적 CNN 구조를 제안한다. 이를 위해 4개의 기본 CNN을 각각 입력 영상에 스테가노그래피 방법이 적용되었는지 여부나 서로 다른 두 스테가노그래피 방법 중에 어떤 방법이 적용되었는지를 이진 판별하도록 학습시켰으며, 학습된 CNN을 계층적으로 연결하였다. 실험 결과를 통해 제안된 계층적 CNN 구조는 4개의 서로 다른 스테가노그래피 방법인 LSB(Least Significant Bit Substitution), PVD(Pixel Value Difference), WOW(Wavelet Obtained Weights), UNIWARD(Universal Wavelet Relative Distortion)을 79%의 정확도로 식별할 수 있음을 확인하였다.","Steganalysis is a technique that aims to detect and recover data hidden by steganography. Steganalytic methods detect hidden data by analyzing visual and statistical distortions caused during data embedding. However, for recovering the hidden data, they need to know which steganographic methods the hidden data has been embedded by. Therefore, we propose a hierarchical convolutional neural network (CNN) structure that identifies a steganographic method applied to an input image through multi-level classification. We trained four base CNNs (each is a binary classifier that determines whether or not a steganographic method has been applied to an input image or which of two different steganographic methods has been applied to an input image) and connected them hierarchically. Experimental results demonstrate that the proposed hierarchical CNN structure can identify four different steganographic methods (LSB, PVD, WOW, and UNIWARD) with an accuracy of 79%."
가속 회로에 적합한 CNN의 Conv-XP 가지치기,2019,[],"CNN은 컴퓨터 영상 인식 부분에서 높은 성능을 보여주고 있으나 많은 연산양을 요구하는 단점으로 인해 전력이나 연산 능력에 제한이 있는 임베디드 환경에서는 사용하기 어렵다. 이러한 단점을 극복하기 위해 CNN을 위한 가속회로나 가지치기 기법에 대한 연구가 많이 이루어지고 있다. 기존의 가지치기 기법은 가속 회로의 구조를 고려하지 않아서, 가지치기된 CNN을 위한 가속 회로는 비효율적인 구조를 가지게 된다. 이 논문에서는 가속 회로의 구조를 고려한 새로운 가지치기 기법인 Conv-XP 가지치기를 제안한다. Conv-XP 가지치기에서는 'X'와 '+' 모양의 두 가지 패턴으로만 가지치기함으로써, 이 기법으로 가지치기된 CNN을 위한 가속 회로의 구조를 단순하게 설계할 수 있도록 하였다. 실험 결과에 따르면, Conv-XP와 같이 가지치기 패턴을 제한하여도 CNN의 성능이 악화되지 않으며, 가속 회로의 면적은 12.8%을 감소시킬 수 있다.",
구조적인 차이를 가지는 CNN 기반의 스테그아날리시스 방법의 실험적 비교,2019,"['Image steganography', 'CNN-based steganalysis', 'preprocessing filter', 'CNN structure', 'experimental comparison']","영상 스테그아날리시스는 입력 영상을 스테가노그래피 알고리즘이 적용된 스테고 영상과 스테가노그래피 알고리즘이 적용되지 않은 커버 영상으로 분류하는 알고리즘이다. 기존에는 주로 수제 특징 기반의 스테그아날리시스를 연구하였다. 하지만 CNN 기반의 물체 인식이 큰 성과를 이루면서 최근 CNN 기반의 스테그아날리시스가 활발히 연구되고 있다. CNN 기반의 스테그아날리시스는 물체 인식과는 달리 커버 영상과 스테고 영상의 미세한 차이를 식별하기 위해서 전처리 필터를 필요로 한다. 그러므로, CNN 기반의 스테그아날리시스 연구들은 효과적인 전처리 필터와 네트워크 구조를 개발하는 데 초점을 두고 있다. 본 논문에서는 동일한 실험 조건에서 기존 연구들을 비교하고, 그 결과를 기반으로 전처리 필터와 네트워크 구조적인 차이에 의한 성능 변화를 분석한다.",
대비 결합 CNN을 이용한 인공위성 사진 내 선박 탐지 정확도 향상 연구,2019,"['인공위성 영상', '딥러닝', 'CNN', '영상처리', '이미지 대비 융합', '최적화', 'satellite image', 'deep learning', 'CNN', 'image processing', 'image contrast fusion', 'optimization']","인공위성은 지상관측이나 통신, 해양, 방송 등의 임무를 가지며 인공위성 사진을 이용한 선박 탐지는 해상 보안 및 교통 통제 등 쓰임새가 다양하다. 인공위성 사진의 특성은 지구 전역을 촬영하기 때문에 저장되는 데이터양이 많고 각 사진은 초고해상도로 크기가 매우 커 컴퓨터를 이용한 자동 선박 탐지가 필요하다. 기존 연구에서는 여러 딥러닝 모델을 이용하여 선박 탐지 연구를 진행하였지만, 인공위성 사진 특성으로 인한 처리속도가 문제되어 상대적으로 빠른 CNN 모델을 이용하여 연구가 진행되고 있다. 그러나 선박이 있는 선착장과 등대, 파도 등 여러 가지 요인으로 인해서 대부분 정확도와 성능을 높이는데 어려움을 가지고 있다. 따라서 이 논문에서는 이미지 명암 대비 향상을 기존 CNN(Convolution Neural Network)에 접목해 정확도와 성능을 높인 모델을 제안한다. 또한, 학습 단계에서 선박 분류에 필요한 데이터의 양을 늘리기 위해 overlap과 rotation 기능을 이용하고 실제 인공위성 사진에서 탐지 속도를 줄이기 위해 탐지 최적화(window sliding)를 고려하여 자동화 탐지 기술을 구현한다. 식별된 선박 데이터는 다시 학습데이터로 사용하여 정확도를 높이고 실제 산업에서 사용할 수 있도록 구현한다.","The satellite has various missions such as ground/marine observation, communication, broadcasting, etc. Satellite photographs provide information for the maintenance of marine security and traffic control for ship detection. Since satellite photos are taken all over the earth, the memory storage is not sufficient to hold such data with each data being of a high resolution and requiring automatic ship detection using the computer. The existing literature on ship detection employed several deep learning models. However, the problem of processing speed due to the characteristics of satellite photographs leads to the necessity of using a CNN(Convolution Neural Network) model that has a comparably high processing speed. On the contrary, it is difficult to improve the accuracy and performance mostly due to factors such as marina, lighthouses and waves. Therefore, in this paper, we propose a model that improves the accuracy and performance by combining image contrast enhancement with the existing CNN. In addition, we have employed the overlap and rotation functions to increase the amount of data required for ship classification in the learning stage and implement automation detection technology considering window sliding to reduce detection speed in real satellite photographs. Also, the identified ship data has been used as learning data to improve accuracy for the model that can be used in the real industry."
CNN의 깊은 특징과 전이학습을 사용한 보행자 분류,2019,"['Pedestrian Classification', 'Transfer Learning', 'Deep Features', 'CNN', 'INRIA Person Data Set', '보행자 분류', '전이학습', '깊은 특징', 'CNN', 'INRIA Person데이터 세트']","자율주행 시스템에서, 카메라에 포착된 영상을 통하여 보행자를 분류하는 기능은 보행자 안전을 위하여 매우 중요하다. 기존에는HOG(Histogram of Oriented Gradients)나 SIFT(Scale-Invariant Feature Transform) 등으로 보행자의 특징을 추출한 후 SVM(Support Vector Machine)으로 분류하는 기술을 사용했었으나, 보행자 특징을 위와 같이 수동(handcrafted)으로 추출하는 것은 많은 한계점을 가지고있다. 따라서 본 논문에서는 CNN(Convolutional Neural Network)의 깊은 특징(deep features)과 전이학습(transfer learning)을 사용하여보행자를 안정적이고 효과적으로 분류하는 방법을 제시한다. 본 논문은 2가지 대표적인 전이학습 기법인 고정특징추출(fixed feature extractor) 기법과 미세조정(fine-tuning) 기법을 모두 사용하여 실험하였고, 특히 미세조정 기법에서는 3가지 다른 크기로 레이어를 전이구간과 비전이구간으로 구분한 후, 비전이구간에 속한 레이어들에 대해서만 가중치를 조정하는 설정(M-Fine: Modified Fine-tuning) 을 새롭게 추가하였다. 5가지 CNN모델(VGGNet, DenseNet, Inception V3, Xception, MobileNet)과 INRIA Person데이터 세트로 실험한결과, HOG나 SIFT 같은 수동적인 특징보다 CNN의 깊은 특징이 더 좋은 성능을 보여주었고, Xception의 정확도(임계치 = 0.5)가 99.61% 로 가장 높았다. Xception과 유사한 성능을 내면서도 80% 적은 파라메터를 학습한 MobileNet이 효율성 측면에서는 가장 뛰어났다.그리고 3가지 전이학습 기법중 미세조정 기법의 성능이 가장 우수하였고, M-Fine 기법의 성능은 미세조정 기법과 대등하거나 조금낮았지만 고정특징추출 기법보다는 높았다.",
CNN-based Skip-Gram Method for Improving Classification Accuracy of Chinese Text,2019,"['Natural language processing (NLP)', 'deep learning', 'text classification', 'convolutional neural networks', 'skip-gram method']",,"Text classification is one of the fundamental techniques in natural language processing. Numerous studies are based on text classification, such as news subject classification, question answering system classification, and movie review classification. Traditional text classification methods are used to extract features and then classify them. However, traditional methods are too complex to operate, and their accuracy is not sufficiently high. Recently, convolutional neural network (CNN) based one-hot method has been proposed in text classification to solve this problem. In this paper, we propose an improved method using CNN based skip-gram method for Chinese text classification and it conducts in Sogou news corpus. Experimental results indicate that CNN with the skip-gram model performs more efficiently than CNN-based one-hot method."
작물 분류에서 시공간 특징을 고려하기 위한 2D CNN과 양방향 LSTM의 결합,2019,"['Crop classification', 'Convolutional neural network', 'Long short-term memory', 'Spatiotemporal features']","이 논문에서는 작물 분류를 목적으로 작물의 시공간 특징을 고려할 수 있는 딥러닝 모델 2D convolution with bidirectional long short-term memory(2DCBLSTM)을 제안하였다. 제안 모델은 우선 작물의 공간 특징을 추출하기 위해 2차원의 합성곱 연산자를 적용하고, 추출된 공간 특징을 시간 특징을 고려할 수 있는 양방향 LSTM 모델의 입력 자료로 이용한다. 제안 모델의 분류 성능을 평가하기 위해 안반덕에서 수집된 다중시기 무인기 영상을 이용한 밭작물 구분 사례 연구를 수행하였다. 비교를 목적으로 기존 딥러닝 모델인 2차원의 공간 특징을이용하는 2D convolutional neural network(CNN), 시간 특징을 이용하는 LSTM과 3차원의 시공간 특징을 이용하는 3D CNN을 적용하였다. 하이퍼 파라미터의 영향 분석을 통해, 시공간 특징을 이용함으로써 작물의 오분류 양상을 현저히 줄일 수 있었으며, 제안 모델이 공간 특징이나 시간 특징만을 고려하는 기존 딥러닝 모델에비해 가장 우수한 분류 정확도를 나타냈다. 따라서 이 연구에서 제안된 모델은 작물의 시공간 특징을 고려할수 있기 때문에 작물 분류에 효과적으로 적용될 수 있을 것으로 기대된다.","In this paper, a hybrid deep learning model, called 2D convolution with bidirectional long short-term memory (2DCBLSTM), is presented that can effectively combine both spatial and temporal features for crop classification. In the proposed model, 2D convolution operators are first applied to extract spatial features of crops and the extracted spatial features are then used as inputs for a bidirectional LSTM model that can effectively process temporal features. To evaluate the classification performance of the proposed model, a case study of crop classification was carried out using multi-temporal unmanned aerial vehicle images acquired in Anbandegi, Korea. For comparison purposes, we applied conventional deep learning models including two-dimensional convolutional neural network (CNN) using spatial features, LSTM using temporal features, and three-dimensional CNN using spatio-temporal features. Through the impact analysis of hyper-parameters on the classification performance, the use of both spatial and temporal features greatly reduced misclassification patterns of crops and the proposed hybrid model showed the best classification accuracy, compared to the conventional deep learning models that considered either spatial features or temporal features. Therefore, it is expected that the proposed model can be effectively applied to crop classification owing to its ability to consider spatio-temporal features of crops."
어종 분류를 위한 CNN의 적용,2019,[],,"In this study, before system development for the elimination of foreign fish species, we propose an algorithm to classify fish species by training fish images with CNN. The raw data for CNN learning were directly captured images for each species, Dataset 1 increases the number of images to improve the classification of fish species and Dataset 2 realizes images close to natural environment are constructed and used as training and test data. The classification performance of four CNNs are over 99.97% for dataset 1 and 99.5% for dataset 2, in particular, we confirm that the learned CNN using Data Set 2 has satisfactory performance for fish images similar to the natural environment. And among four CNNs, AlexNet achieves satisfactory performance, and this has also the shortest execution time and training time, we confirm that it is the most suitable structure to develop the system for the elimination of foreign fish species."
Multi-Modal 영역제안 및 CNN-SVM 기반야간 원거리 원적외선 보행자 검출,2019,"['remote pedestrian detection', 'far infrared', 'multi-scale contrast filter', 'local projection', 'CNN']",,"This paper presents a novel remote infrared pedestrian detection method for night use by means of local projection-CNN.Conventional sliding window methods (HOG/ACF) or region proposal-based deep learning approaches (faster R-CNN, SSD, YOLO)either fail to detect small objects or generate many false positives. Multi-modal region proposal schemes (multi-scale contrast filters withlocal projection+ACF) are used to improve remote pedestrian detection. AlexNet-based CNN feature extraction and SVM classificationcan reduce false positives further. This paper’s experimental evaluations indicate that the proposed method can improve remote IRpedestrian detection by 16%."
가상화 플랫폼을 통한 CNN기반 모니터링 애플리케이션의 안정적인 응답 속도 보장 방안 연구,2019,"['Virtualized Platform', 'Cloud Computing', 'OpenStack', 'Docker', 'IaaS', 'CNN', 'Monitoring', '가상화 플랫폼', '클라우드 컴퓨팅', 'OpenStack', 'Docker', 'IaaS', 'CNN', '모니터링']","최근 가상화 기술이 적용된 가상화 플랫폼(Virtualized Platform)을 도입하게 되면서 단일 하드웨어 리소스의 파티셔닝을 통한 리소스 활용률 상승과 마이그레이션을 통한 확장성의 이점을 통해 서비스의 안정적인 응답 속도를 기대할 수 있게 되었다. 기존 단일 하드웨어 서버기반 모니터링 애플리케이션 서비스에서는 필요 이상의 리소스를 사용하거나 사용자의 요청에 비해 리소스가 부족하여 응답 속도가 저하되는 문제가 발생하였다. 본 논문에서는 이를 해결하기 위해 오픈 소스 가상화 플랫폼인 OpenBaton, OpenStack과 Docker를 통해 이미지에 대해 화재 및 연기 예측이 가능한 ResNet50 기반의 CNN 모델이 적용된 모니터링 애플리케이션을 구현하였다. 이를 통해 본 논문에서는 기존 단일 하드웨어 서버와 제안된 시스템의 응답 속도 비교를 통해 안정적인 응답 속도 보장 방안에 대해 연구하였다.","With the recent introduction of a virtualized platform with virtualization technology, the benefits of increased resource utilization through partitioning of a single hardware resource and scalability through migration provide a reliable response rate for services. Traditional single hardware server-based monitoring application services have had problems with using more resources than needed or lack of resources compared to the user's request, resulting in slower response times. To address this, this paper implemented a monitoring application with a CNN model based on ResNet50 that enables fire and smoke prediction for images through open source virtualization platforms, OpenBaton, OpenStack and Docker. In this paper, we studied how to ensure a stable response rate through comparing the response speed of the existing single hardware server with the proposed system."
GPR 히트맵 이미지 데이터 기반 CNN을 이용한 철근 두께 예측에 관한 연구,2019,"['GPR', 'B-scan', '히트맵', '합성곱 신경망', '철근', '두께', 'Ground Penetrating Radar', 'B-scan', 'heatmap', 'Convolution Neural Network', 'Rebar Thickness']","본 논문에서는 시설물 내부 철근 두께를 예측하기 위해 GPR 데이터를 활용한 철근 두께 예측 기법에 관한 연구를 실시하였다. 국내의 규격 미달 철근의 사용 및 배근 시공과 같은 부실시공 사례에서 볼 수 있듯이, 구조물 정밀진단을 위해서 철근 두께에 대한 정보는 정밀 안전진단을 위해서 꼭 필요함을 알 수 있다. 이를 위해 본 연구에서는 시편을 제작하여 철근 직경을 단계적으로 증가시켜 GPR의 B-scan 데이터를 취득하였다. GPR 의 B-scan 데이터는 가시성이 떨어지기 때문에 이를 migration을 통해 히트맵 이미지 데이터로 변화시켜 데이터의 직관성을 높이고자 하였다. 본 연구는 보편적으로 이용되는 B-scan 데이터와 히트맵 데이터의 합성곱 신경망(CNN) 적용 시 결과를 비교하기 위해 B-scan 및 히트맵 데이터에서 각각 철근에 대한 영역을 추출하여 학습 및 검증 데이터를 구축하였으며, 구축된 데이터에 CNN을 적용하였다. 그 결과, 히트맵 데이터의 경우 B-scan 데이터와 비교하였을 때 더 좋은 결괏값을 얻을 수 있었다. 이를 통해 GPR 히트맵 데이터를 이용하였을 경우 B-scan 데이터를 이용하였을 때보다 더 높은 정확도로 철근 두께를 예측할 수 있음을 확인하였으며, 시설물 내부 철근 두께 예측의 가능성을 검증하였다.","In this paper, a study was conducted on the method of using GPR data to predict rebar thickness inside a facility. As shown in the cases of poor construction, such as the use of rebars below the domestic standard and the construction of reinforcement, information on rebar thickness can be found to be essential for precision safety diagnosis of structures. For this purpose, the B-scan data of GPR was obtained by gradually increasing the diameter of rebars by making specimen. Because the B-scan data of GPR is less visible, the data was converted into the heatmap image data through migration to increase the intuition of the data. In order to compare the results of application of commonly used B-scan data and heatmap data to CNN, this study extracted areas for rebars from B-scan and heatmap data respectively to build training and validation data, and applied CNN to the deployed data. As a result, better results were obtained for the heatmap data when compared with the B-scan data. This confirms that if GPR heatmap data are used, rebar thickness can be predicted with higher accuracy than when B-scan data is used, and the possibility of predicting rebar thickness inside a facility is verified."
MALICIOUS URL RECOGNITION AND DETECTION USING ATTENTION-BASED CNN-LSTM,2019,"['Malicious URL', 'Recognition and Detection', 'Attention-Based CNN-LSTM', 'Deep Learning']",,"A malicious Uniform Resource Locator (URL) recognition and detection method based on the combination of Attention mechanism with Convolutional Neural Network and Long Short-Term Memory Network (Attention-Based CNN-LSTM), is proposed. Firstly, the WHOIS check method is used to extract and filter features, including the URL texture information, the URL string statistical information of attributes and the WHOIS information, and the features are subsequently encoded and pre-processed followed by inputting them to the constructed Convolutional Neural Network (CNN) convolution layer to extract local features. Secondly, in accordance with the weights from the Attention mechanism, the generated local features are input into the Long-Short Term Memory (LSTM) model, and subsequently pooled to calculate the global features of the URLs. Finally, the URLs are detected and classified by the SoftMax function using global features. The results demonstrate that compared with the existing methods, the Attention-based CNN-LSTM mechanism has higher accuracy for malicious URL detection."
CNN과 Bidirectional LSTM을 활용한 부산시 민원 자동 분류 연구,2019,"['automatic text classification', 'civil complaint', 'CNN', 'bidirectional LSTM', 'bi－LSTM', '민원', '자동분류', '딥러닝', '순환신경망', '양방향 LSTM', 'CNN']","온라인과 정보통신기술의 발달로 정부정책에 대한 시민의 참여 욕구는 높아지고 있다. 이에 따라 시민들은 민원을 인터넷과 모바일을 활용하여 전자 민원 게시판을 통해 접수하는 건수가 증가하고 있다. 폭발적으로 늘어나는 민원의 양에 비해 아직 수작업으로 분류 하여 오류가 발생하거나 신속한 대응이 이루어지지 않아 민원인들의 불만이 늘어나고 있다. 본 연구에서는 딥러닝 기법을 통해 담당 부서 분류를 자동화하기 위해 2017년도의 부산시 민원 데이터를 수집하고, 담당 부서를 확인 할 수 있는 부서명, 전화번호, 담당자명을 기준으로 레이블을 부여하였다. 그리고 딥러닝 중 대표적인 분류방법인 CNN과 최근 여러 분야에서 두각을 내고 있는 Bidirectional LSTM을 기반으로 상위 12개 범주에 대하여 지도학습을 실시하였다. 지도학습 결과 각각 73%, 77%의 정확도를 보여 안정적인 성능을 보여주었다. 본 연구의 민원 분류에 대한 지도학습 사례는 향후 다른 주제 및 지방자치단체 민원에 대한 텍스트 데이터의 분류에 이용될 수 있어 실무적인 공헌도와 함께 후속연구를 유발할 수 있다는 학문적 기여도가 있다.",
홈 IoT 환경에서의 CNN-DNN 기반 음향인지 알고리즘,2019,"['Deep learning', 'sound event detection', 'log mel filter bank', '딥러닝', '음향인지', 'log mel filter bank']",,"In this study, we proposed a CNN-DNN based sound event detection in home IoT environments. To reduce the impact of input volume variation, we applied peak normalization, and extracted acoustic feature named Log mel filter bank. Log-mel filter bank is very popular acoustic feature based on mel filter which is powerful for speech recognition and sound event detection. Then, we used CNN-DNN model for classification. CNN outputs of sequential 32 frames were used as DNN input for considering time-series characteristic of the sound. Data were collected in real apartment environment. We used 13 sounds as target such as doorbell, babycry, vacuum, and so on. We evaluated our method using computer simulation, as a result, the accuracy of the proposed sound event detection algorithm was 90.76%."
CNN 기반 전이학습을 이용한 음성 감정 인식,2019,"['Speech Emotion Recognition', 'Transfer Learning', 'Deep Learning', 'Convolutional Neural Networks', '음성 감정 인식', '전이학습', '딥러닝', '합성곱 신경망']","로봇은 사람의 편의를 위해 존재하므로 사람과 로봇의 상호작용은 중요하다. 로봇이 사람의 감정을 파악하는 것은 여러상호작용 중 하나이다. 최근 사람의 음성으로 감정을 인식하는 음성 감정 인식(speech emotion recognition; SER)분야는딥러닝 (deep learning)의 접목으로 그 성능이 향상되고 있다. 하지만, 데이터의 부족으로 깊은 신경망을 사용하거나추가적인 학습 기법을 적용하지 않고서는 높은 정확도를 기대하기 힘들다. 본 논문에서는 데이터가 부족할 때 사용하는 학습기법 중의 하나인 전이학습 (transfer learning)을 SER에 적용한 효과를 확인한다. 딥러닝을 적용하기 위해 합성곱 신경망(convolutional neural networks; CNN) 구조를 사용한다. 전이학습에 음성 감정 데이터가 아닌 일반 소리 데이터를 사용하여데이터 개수에 대한 한계를 없앤다. 전이학습 중 특징 추출기 (feature extractor)로써 사용한 경우와 미세조정 (fine tuning)을한 경우로 나누어 결과를 확인한다. 그 결과, 미세조정한 경우 수렴 시간이 약 20% 줄었고, 특징 추출기로써 사용한 경우 약20%에서 70% 줄었다. 정확도는 특징 추출기로써 사용한 경우 오히려 정확도가 감소하는 경우가 발생하였고 증가한 경우 약3% 증가했다. 미세조정을 한 경우 정확도가 평균적으로 약 7% 향상되었다","Interaction between human and robot is important because robots exist for the convenience of people. Robot grasping human emotions is one of many interactions. The field of SER (speech emotion recognition) has been improved by combining deep learning. The lack of data makes it difficult to expect high accuracy without using deep neural networks or applying additional learning techniques. In this paper, we confirm the effect of applying the transfer learning, which is one of the learning methods used when there is insufficient data, to SER. For deep learning, CNN (convolutional neural networks) architecture is used. By using general sound data instead of speech emotion data for the transfer learning, the limit on the number of data is eliminated. The results are verified by dividing transfer learning into two case, using as a feature extractor and fine-tuning. As a result, convergence time was reduced by about 20% when fine-tuning, and about 20% to 70% when used as a feature extractor. Accuracy of the feature extractor is rather reduced when it is used as a feature extractor and increased by about 3% when it is increased. On the average, the accuracy was improved by about 7% when fine-tuning."
Self-Attention을 활용한 Siamese CNN-Bidirectional LSTM 기반 문장 유사도 예측,2019,"['자연어 처리', '유사도 측정', '샴 네트워크', '합성곱 신경망', '순환 신경망', '어텐션', 'natural language processing', 'similarity measure', 'siamese network', 'convolution neural network', 'recurrent neural network', 'attention']",본 논문에서는 입력된 두 문장의 유사도를 측정하는 딥러닝 모델을 제안한다. 기존의 문장의유사도 측정 모델에는 단어 혹은 형태소 단위로 문장을 분해하여 임베딩 하는 방식을 활용한다. 하지만 이는 사전의 크기를 증가시켜 모델의 복잡도를 높이는 문제점이 있다. 본 논문에서는 문장을 음소 단위로 분해하여 모델 복잡도를 줄이고 해당 음소를 묶어주는 다양한 필터 사이즈의 1D Convolution Neural Network와 Long Short Term Memory(LSTM)을 결합한 Siamese CNN-Bidirectional LSTM 모델을 제안한다. 본 모델을 평가하기 위해 네이버 지식인 데이터를 활용하여 기존의 문서 유사 측정에서 좋은 성능을 보이는 모델 Manhattan LSTM(MaLSTM)과 비교하였다.,"A deep learning model for semantic similarity between sentences was presented. In general, most of the models for measuring similarity word use level or morpheme level embedding.However, the attempt to apply either word use or morpheme level embedding results in higher complexity of the model due to the large size of the dictionary. To solve this problem, a Siamese CNN-Bidirectional LSTM model that utilizes phonemes instead of words or morphemes and combines long short term memory (LSTM) with 1D convolution neural networks with various window lengths that bind phonemes is proposed. For evaluation, we compared our model with Manhattan LSTM (MaLSTM) which shows good performance in measuring similarity between similar questions in the Naver Q&A dataset (similar to Kaggle Quora Question Pair)."
입력영상 변환에 의한 CNN 기반의 SMT 부품 결함 분류 방법,2019,"['surface mount technology', 'machine learning', 'deep learning', 'histogram stretching']",,"Surface Mount Technology (SMT) is a manufacturing process in which components are mounted on the surface of a printed circuit board (PCB). The automatic optical inspection system (AOI) has mainly used the learning-based method for the defect classification of the SMT process, and recently the CNN-based classification method has appeared. However, existing techniques do not consider the area margin of the part, so the classification accuracy decreases. In addition, the classification performance of the CNN classifier is degraded due to the uneven color distribution according to the position of the components. In this paper, we propose a system that can extract the component region and improve the color distribution by the input image transformation. We extract the correct component area through vertical and horizontal projection, and the color improvement enhance the brightness value distribution of the component image through local histogram stretching. By experimental result, we prove the performance of the proposed classification method."
영상에서 다중 객체 추적을 위한 CNN 기반의 다중 객체 검출에 관한 연구,2019,"['Object Detection', 'Object Tracking', 'Convolutional Neural Network(CNN)', 'Machine Learning']",,"Recently, video monitoring system technology has been rapidly developed to monitor and respond quickly to various situations. In particular, computer vision and related research are being actively carried out to track objects in the video. This paper proposes an efficient multiple objects detection method based on convolutional neural network (CNN) for multiple objects tracking. The results of the experiment show that multiple objects can be detected and tracked in the video in the proposed method, and that our method is also good performance in complex environments."
CNN-based Visual/Auditory Feature Fusion Method with Frame Selection for Classifying Video Events,2019,"['Multimedia', 'Computer Vision Systems', 'Aritifical Intelligence', 'Video Classification']",,"In recent years, personal videos have been shared online due to the popular uses of portable devices, such as smartphones and action cameras. A recent report[1] predicted that 80% of the Internet traffic will be video content by the year 2021. Several studies have been conducted on the detection of main video events to manage a large scale of videos. These studies show fairly good performance in certain genres. However, the methods used in previous studies have difficulty in detecting events of personal video. This is because the characteristics and genres of personal videos vary widely. In a research, we found that adding a dataset with the right perspective in the study improved performance. It has also been shown that performance improves depending on how you extract keyframes from the video. we selected frame segments that can represent video considering the characteristics of this personal video. In each frame segment, object, location, food and audio features were extracted, and representative vectors were generated through a CNN-based recurrent model and a fusion module. The proposed method showed mAP 78.4% performance through experiments using LSVC[2] data."
CNN을 이용한 Quad Tree 기반 2D Smoke Super-resolution,2019,"['쿼드 트리', '슈퍼 레졸루션', '가속화', '연기 시뮬레이션', 'Quad Tree', 'Super-resolution', 'Acceleration', 'Smoke Simulation']","물리 기반 유체 시뮬레이션은 고해상도 연산을 위해 많은 시간이 필요하다. 이 문제를 해결하기 위해 저해상도 유체 시뮬레이션의 한계를 딤 러닝으로 보완하는 연구들이 있으며, 그중에서는 저해상도의 시뮬레이션 데이터 를 고해상도로 변환해주는 Super-resolution 분야가 있다. 하지만 기존 기법들은 전체 데이터 공간에서 밀도 데이터가 없는 부분까지 연산하므로 전체 시뮬레이션 속도 면에서 효율성이 떨어지며, 입력 해상도가 큰 경우 에는 GPU 메모리가 부족해 연산할 수 없는 경우가 발생할 수 있다. 본 연구에서는 공간 분할 법 중 하나인 쿼 드 트리를 활용하여 시뮬레이션 공간을 분할 및 분류하여 Super-resolution 하는 기법을 제안한다. 본 기법은 필요 공간만 Super-resolution 하므로 전체 시뮬레이션 가속화가 가능하고, 입력 데이터를 분할 연산하므로 GPU 메모리 문제를 해결할 수 있게 된다.","Physically-based fluid simulation takes a lot of time for high resolution. To solve this problem, there are studies that make up the limitation of low resolution fluid simulation by using deep running. Among them, Super-re solution, which converts low-resolution simulation data to high resolution is under way. However, traditional techniques require to the entire space where there are no density data, so there are problems that are inefficient in terms of the full simulation speed and that cannot be computed with the lack of GPU memory as input resolution increases. In this paper, we propose a new method that divides and classifies 2D smoke simulation data into the space using the quad tree, one of the spatial partitioning methods, and performs Super-resolution only required space. This technique accelerates the simulation speed by computing only necessary space. It also processes the divided input data, which can solve GPU memory problems."
CNN을 이용한 레이다 신호 자동 분류,2019,"['Radar Signal Classification', 'Jamming Technique', 'Machine Learning', 'Convolution Neural Network', '-']",,"In this paper, we propose a classification method for radar signals depending on the type of threat by applying machine learning to parameter data of radar signals . Currently, the army uses a library of mapping relations between the parameters and the types of threat to recognize threat signals. This approach has certain limitations when classifying signals and recognizing new types of threat or types of threat that do not exist in the current libraries. In this paper, we propose an automatic radar signal classification method depending on the type of threat that uses only parameter data without a library. A convolutional neural network is used as the classifier and machine learning is applied to train the classifier. The proposed method does not use a library, and hence, can classify threat signals that are new or do not exist in the current library."
3차원 가상도시 모델에서 높이맵을 이용한 CNN 기반의 그림자 탐지방법,2019,"['그림자 탐지', '딥러닝', 'Shadow detection', 'Deep-learning']","최근 교육, 제조, 건설 등 다양한 응용 분야에서 사실적인 가상환경을 표현하기 위하여 실세계 영상데이터를 활용하는 사례가 증가하고 있다. 특히, 스마트 시티 등 디지털 트윈에 대한 관심이 높아지면서, 항공 영상 등 실제 촬영한 영상을 이용하여 현실감 있는 3D 도시 모델을 구축하고 있다. 그러나, 촬영된 항공 영상에는 태양에 의한 그림자가 포함되어 있으며, 그림자가 포함된 3D 도시 모델은 사용자에게 정보를 왜곡시켜 표현하는 문제를 안고 있다. 그림자를 제거하기 위하여 그동안 많은 연구가 진행되었지만, 아직 까지 해결하기 어려운 도전적인 문제로 인식되고 있다. 본 논문에서는 VWorld에서 제공하는 3차원 공간정보를 이용하여 건물의 높이맵을 포함한 가상환경 데이터 셋을 구축하고, 높이맵과 딥러닝을 이용한 새로운 그림자 탐지 방법을 제안한다. 실험 결과에 의하면, 높이맵을 사용했을 때 기존 방법보다 그림자 탐지 에러율이 감소한 것을 확인할 수 있다.","Recently, the use of real-world image data has been increasing to express realistic virtual environments in various application fields such as education, manufacturing, and construction. In particular, with increasing interest in digital twins like smart cities, realistic 3D urban models are being built using real-world images, such as aerial images. However, the captured aerial image includes shadows from the sun, and the 3D city model including the shadows has a problem of distorting and expressing information to the user. Many studies have been conducted to remove the shadow, but it is recognized as a challenging problem that is still difficult to solve. In this paper, we construct a virtual environment dataset including the height map of buildings using 3D spatial information provided by VWorld, and We propose a new shadow detection method using height map and deep learning. According to the experimental results, We can observed that the shadow detection error rate is reduced when using the height map."
심층 CNN을 활용한 영상 분위기 분류 및 이를 활용한 동영상 자동 생성,2019,"['Convergence', 'Machine Learning', 'Multi-class Classification', 'Mood Classification', 'Convolutional Neural Network', 'Multilayer Perceptron', '융합', '기계학습', '다중 클래스 분류', '감정 분류', '합성곱 신경망', '다층 퍼셉트론']","본 연구에서는 영상의 분위기를 심층 합성곱 신경망을 통해 8 가지로 분류하고, 이에 맞는 배경 음악을 적용하여 동영상을 자동적으로 생성하였다. 수집된 이미지 데이터를 바탕으로 다층퍼셉트론을 사용하여 분류 모델을 학습한다. 이를 활용하여 다중 클래스 분류를 통해 동영상 생성에 사용할 이미지의 분위기를 예측하며, 미리 분류된 음악을 매칭시켜 동영상을 생성한다. 10겹 교차 검증의 결과, 72.4%의 정확도를 얻을 수 있었고, 실제 영상에 대한 실험에서 64%의 오차 행렬 정확도를 얻을 수 있었다. 오답의 경우, 주변의 비슷한 분위기로 분류하여 동영상에서 나오는 음악과 크게 위화감이 없음을 확인하였다.","In this paper, the mood of images was classified into eight categories through a deep convolutional neural network and video was automatically generated using proper background music. Based on the collected image data, the classification model is learned using a multilayer perceptron (MLP). Using the MLP, a video is generated by using multi-class classification to predict image mood to be used for video generation, and by matching pre-classified music. As a result of 10-fold cross-validation and result of experiments on actual images, each 72.4% of accuracy and 64% of confusion matrix accuracy was achieved. In the case of misclassification, by classifying video into a similar mood, it was confirmed that the music from the video had no great mismatch with images."
워드 임베딩과 CNN을 사용하여 영화 리뷰에 대한 감성 분석,2019,"['Social Network Service', 'Sensitivity Prediction', 'Morpheme Analysis', 'Embedding', 'Learning']",,"Reaction of people is importantly considered about specific case as a social network service grows. In the previous research on analysis of social network service, they predicted tendency of interesting topic by giving scores to sentences written by user. Based on previous study we proceeded research of sentiment analysis for social network service’s sentences, which predict the result as positive or negative for movie reviews. In this study, we used movie review to get high accuracy. We classify the movie review into positive or negative based on the score for learning. Also, we performed embedding and morpheme analysis on movie review. We could predict learning result as positive or negative with a number 0 and 1 by applying the model based on learning result to social network service. Experimental result show accuracy of about 80% in predicting sentence as positive or negative."
비트평면 영상을 이용한 이진 CNN 연산 알고리즘,2019,"['Bit-plane', 'Binary CNN', 'Computing Power', 'Embedded System', 'Binary kernel', 'XOR']","본 논문에서는 이진영상과 이진커널을 사용하여 컨볼루션, 풀링, ReLU 연산을 수행하는 이진 CNN 연산 알고리즘을 제안한다. 256 그레이스케일 영상을 8개의 비트평면으로 분해하고, -1과 1로 구성되는 이진커널을 사용하는 방법이다. 이진영상과 이진커널의 컨볼루션 연산은 가산과 감산으로 수행한다. 논리적으로는 XNOR 연산과 비교기로 구성되는 이진연산 알고리즘이다. ReLU와 풀링 연산은 각각 XNOR와 OR 논리연산으로 수행한다. 본 논문에서 제안한 알고리즘의 유용성을 증명하기 위한 실험을 통해, CNN 연산을 이진 논리연산으로 변환하여 수행할 수 있음을 확인한다. 이진 CNN 알고리즘은 컴퓨팅 파워가 약한 시스템에서도 딥러닝을 구현할 수 있는 알고리즘으로 스마트 폰, 지능형 CCTV, IoT 시스템, 자율주행 자동차 등의 임베디드 시스템에서 다양하게 적용될 수 있는 시스템이다.","In this paper, we propose an algorithm to perform convolution, pooling, and ReLU operations in CNN using binary image and binary kernel. It decomposes 256 gray-scale images into 8 bit planes and uses a binary kernel consisting of -1 and 1. The convolution operation of binary image and binary kernel is performed by addition and subtraction. Logically, it is a binary operation algorithm using the XNOR and comparator. ReLU and pooling operations are performed by using XNOR and OR logic operations, respectively. Through the experiments to verify the usefulness of the proposed algorithm, We confirm that the CNN operation can be performed by converting it to binary logic operation. It is an algorithm that can implement deep running even in a system with weak computing power. It can be applied to a variety of embedded systems such as smart phones,  intelligent CCTV, IoT system, and autonomous car."
CNN 알고리즘을 이용한 체커스위치 불량 검출 시스템 개발,2019,"['Error Detection(불량 검출)', 'Machine Learning(머신러닝)', 'CNN', 'Checker Switch(체커스위치)']",,"Various automation studies have been conducted to detect defective products based on product images. In the case of machine vision-based studies, size and color error are detected through a preprocessing process. A situation may arise in which the main features are removed during the preprocessing process, thereby decreasing the accuracy. In addition, complex systems are required to detect various kinds of defects. In this study, we designed and developed a system to detect errors by analyzing various conditions of defective products. We designed the deep learning algorithm to detect the defective features from the product images during the automation process using a convolution neural network (CNN) and verified the performance by applying the algorithm to the checker-switch failure detection system. It was confirmed that all seven error characteristics were detected accurately, and it is expected that it will show excellent performance when applied to automation systems for error detection."
블레이드의 표면 결함 검출을 위한 Faster R-CNN 딥러닝 모델 구축,2019,"['블레이드', '딥러닝', 'Faster R-CNN', '객체 인식', '표면 결함', '터빈엔진', 'Blade', 'Deep learning', 'Faster R-CNN', 'Object detection', 'Surface damage', 'Turbine engine']","컴퓨터 성능 향상으로 다양한 분야에서 딥러닝을 활용한 연구가 활발히 진행되고 있으며 최근에는 구조물 안전성 평가 연구에도 그 적용이 이루어지고 있다. 특히 터빈의 내부 블레이드는 분리가 쉽지 않고 어두운 주변 환경으로 인해 블레이드의 표면 결함 검출은 전문 인력의 경험에 의존하고 있으며, 점검시간도 상당히 소요되고 있는 실정이다. 따라서, 본 연구에서는 딥러닝 기술을 적용하여 터빈 구조의 부재 중 하나인 내부 블레이드에 발생하는 결함을 검출할 수 있는 효율적인 방법을 제시하였다. Faster R-CNN 인공신경망 기법을 활용하여 결함의 이미지 데이터를 학습하였고 부족한 이미지는 필터링과 Image Data Generator를 이용하여 데이터를 확장하였다. 그 결과 블레이드의 결함을 학습한 딥러닝 모델은 평균적으로 약 96.1%의 정확도와 재현율은 95.3%, 정밀도는 96%의 성능을 보였다. 재현율을 통해 제시된 딥러닝 모델이 결함을 탐지하지 못하는 경우는 4.7% 로 나타났다. 재현율의 성능은 여러 환경의 많은 결함 이미지 데이터를 수집하고 확장하여 딥러닝 학습에 적용함으로써 더욱 향상되리라 판단된다. 이러한 실제 블레이드의 결함 이미지 데이터 확보와 학습을 통해 향후 터빈엔진 정비에 적용 가능한 결함 검출 시스템으로 발전할 수 있을 것이다.","As computer performance improves, research using deep learning are being actively carried out in various fields. Recently, deep learning technology has been applying to the safety evaluation for structures. In particular, the internal blades of a turbine structure requires experienced experts and considerable time to detect surface damages because of the difficulty of separation of the blades from the structure and the dark environmental condition. This study proposes a Faster R-CNN deep learning model that can detect surface damages on the internal blades, which is one of the primary elements of the turbine structure. The deep learning model was trained using image data with dent and punch damages. The image data was also expanded using image filtering and image data generator techniques. As a result, the deep learning model showed 96.1% accuracy, 95.3% recall, and 96% precision. The value of the recall means that the proposed deep learning model could not detect the blade damages for 4.7%. The performance of the proposed damage detection system can be  further improved by collecting and extending damage images in various environments, and finally it can be applicable for turbine engine maintenance."
에너지인터넷에서 1D-CNN과 양방향 LSTM을이용한 에너지 수요예측,2019,"['CNN', 'LSTM', '1D-ConvBLSTM', 'Energy prediction', 'Internet of Energy']","에너지인터넷 기술의 발전과 다양한 전자기기의 보급으로 에너지소비량이 패턴이 다양해짐에 따라 수요예측에 대한 신뢰도가 감소하고 있어 발전량 최적화 및 전력공급 안정화에 문제를 야기하고 있다. 본 연구에서는 고신뢰성을 갖는 수요예측을위해 딥러닝 기법인 Convolution neural network(CNN)과 Bidirectional Long Short-Term Memory(BLSTM)을 융합한1Dimention-Convolution and Bidirectional LSTM(1D-ConvBLSTM)을 제안하고, 제안한 기법을 활용하여 시계열 에너지소비량대한 소비패턴을 효과적으로 추출한다. 실험 결과에서는 다양한 반복학습 횟수와 feature map에 대해서 수요를 예측하고 적은 반복학습 횟수로도 테스트 데이터의 그래프 개형을 예측하는 것을 검증한다.","As the development of internet of energy (IoE) technologies and spread of various electronic devices have diversifiedpatterns of energy consumption, the reliability of demand prediction has decreased, causing problems in optimization ofpower generation and stabilization of power supply. In this study, we propose a deep learning method, 1-Dimention-Convolution and Bidirectional Long Short-Term Memory (1D-ConvBLSTM), that combines a convolution neuralnetwork (CNN) and a Bidirectional Long Short-Term Memory(BLSTM) for highly reliable demand forecasting byeffectively extracting the energy consumption pattern. In experimental results, the demand is predicted with the proposeddeep learning method for various number of learning iterations and feature maps, and it is verified that the test data ispredicted with a small number of iterations."
CNN 기반 당뇨병성 망막병증 특징 추출 및 심각도 등급 분류,2019,"['Faster R-CNN', 'Random Forest', 'Classification', '비증식성 당뇨병성 망막병증', '의료 영상처리']","비증식성 당뇨성 망막 병증은 당뇨병 환자의 대표적인 합병증으로서 시력저하와 실명을 일으키는 주요한 원인 중 하나로 알려져 있다. 당뇨성 망막 병증을 자동으로 탐지하는 연구는 지속적으로 이루어지고 있으나, 여기에 추가적으로 심각도의 등급을 자동으로 분류하는 시스템에 대한 연구의 필요성 또한 대두되고 있다. 본 논문에서는 당뇨성 망막 병증의 병리적 특징인 미세혈관류, 망막 출혈과 경성 삼출물을 검출하기 위해 Faster R-CNN 기술을 적용하여 해당 병리 증상에 대해 자동으로 검출하는 시스템을 제안하였다. 검출된 특징에 대해 히스토그램 평활화 등의 전처리 과정을 수행하였고, 이 데이터를 이용해 랜덤포레스트 분류기를 학습하고 테스트함으로써 병리증상의 특징을 기반으로 한 심각도 등급을 자동 분류하는 시스템을 고안하였다. 이를 통해 검사자의 주관적 해석 개입을 방지하고 객관적 자료와 지표를 이용하여 구체적으로 판단할 수 있도록 하고 의료 영상 분석 분야 업무의 효율성을 높일 수 있도록 하였다. 본 논문에서 제안하는 방법을 이용해 테스트 안저 영상 103장에 대하여 등급 별 분류 실험을 한 결과 98%의 정확도를 보이는 분류 시스템을 구현할 수 있었고, 이는 향 후 다수의 의미 있는 데이터가 수집된다면 더 높은 완성도를 보일 수 있을 것으로 예상된다.","Non-proliferative diabetic retinopathy is a representative complication of diabetic patients and is known to be a major cause of impaired vision and blindness. There has been ongoing research on automatic detection of diabetic retinopathy; however, there is also a growing need for research on an automatic severity classification system. This study proposes an automatic detection system for pathological symptoms of diabetic retinopathy such as microaneurysm, retinal hemorrhage, and hard exudate by applying the Faster R-CNN technique. An automatic severity classification system based on the features of pathological symptoms of diabetic retinopathy was devised by training and testing a random forest classifier based on the data obtained through preprocessing, such as histogram smoothing of the detected features. The proposed system enables accurate judgment using objective data and indices while avoiding the subjective interpretation of testers and improving the efficiency of medical image analysis. An experiment of classifying 103 test fundus images with the proposed classification system showed 98% accuracy. The proposed automatic severity classification is expected to show a higher degree of accuracy if a greater amount of meaningful data can be collected in the future."
컬러 히스토그램과 CNN 모델을 이용한 객체 추적,2019,"['CNN', 'GOTURN', 'Mean-shift', 'SVM', 'Color histogram.']","본 논문에서는 컬러 히스토그램과 CNN 모델을 이용한 객체 추적 기법 알고리즘을 제안한다. CNN (convolutional neural network) 모델 기반 객체 추적 알고리즘인 GOTURN (generic object tracking using regression network)의 정확도를 높이기 위해 컬러 히스토그램 기반 mean-shift 추적 알고리즘을 합성하였다. 두 알고리즘을 SVM (support vector machine)을 통해 분류하여 추적 정확도가 더 높은 알고리즘을 선택하도록 설계하였다. Mean-shift 추적 알고리즘은 객체 추적에 실패할 때 경계 박스가 큰 범위로 움직이는 경향이 있어 경계 박스의 이동거리에 제한을 두어 정확도를 향상 시켰다. 또한 영상 평균 밝기, 히스토그램 유사도를 고려하여 두 알고리즘의 추적 시작 위치를 초기화하여 성능을 높였다. 결과적으로 기존 GOTURN 알고리즘보다 본 논문에서 제안한 알고리즘이 전체적으로 정확도가 1.6% 향상되었다.","In this paper, we propose an object tracking algorithm based on color histogram and convolutional neural network model. In order to increase the tracking accuracy, we synthesize generic object tracking using regression network algorithm which is one of the convolutional neural network model-based tracking algorithms and a mean-shift tracking algorithm which is a color histogram-based algorithm. Both algorithms are classified through support vector machine and designed to select an algorithm with higher tracking accuracy. The mean-shift tracking algorithm tends to move the bounding box to a large range when the object tracking fails, thus we improve the accuracy by limiting the movement distance of the bounding box. Also, we improve the performance by initializing the tracking start positions of the two algorithms based on the average brightness and the histogram similarity. As a result, the overall accuracy of the proposed algorithm is 1.6% better than the existing generic object tracking using regression network algorithm."
Faster R-CNN 기반의 관심영역 유사도를 이용한 후방접근차량 검출 연구,2019,"['Deep lerning', 'Faster r-cnn', 'Agricultural machine', 'Vehicle detection', 'Structure similarity']",본 논문에서는 농업 기계 시스템에서 사용하기 위한 딥러닝 알고리즘 기반의 프레임 내의 관심 영역 유사성을 이용한 새로운 후방 접근 차량 검출 알고리즘을 제안한다. 농업 기계 시스템은 후방에서 접근하는 차량만 검출해야 한다. 지나가는 자동차가 검출되면 혼란을 야기할 수 있다. 논문에서는 차량 검출을 위해 딥러닝에서 뛰어난 검출률을 나타내는 FasterR-CNN 모델을 사용하였다. 딥러닝은 뒤에서 접근하는 차량뿐만 아니라 지나가는 차량도 검출하므로 긍정오류 차량을 배제해야 한다. 본 논문에서 이를 해결하기 위해 검출된 프레임에서 관심 영역에 대한 유사성과 평균 에러를 피라미드 형태로 이용하여 접근하는 자동차만 검출하는 알고리즘을 제안하였다. 실험을 통하여 제안된 방법이 평균 98.8%의 높은 검출률을 나타내었다.,"In this paper, we propose a new algorithm to detect rear-approaching vehicle using the frame similarity of ROI(Regionof Interest) based on deep learning algorithm for use in agricultural machinery systems. Since the vehicle detectionsystem for agricultural machinery needs to detect only a vehicle approaching from the rear. we use Faster R-CNN modelthat shows excellent accuracy rate in deep learning for vehicle detection. And we proposed an algorithm that uses theframe similarity for ROI using constrained conditions. Experimental results show that the proposed method has adetection rate of 99.9% and reduced the false positive values."
치매 진단을 위한 Faster R-CNN 활용 MRI 바이오마커 자동 검출 연동 분류 기술 개발,2019,"['Computer-Aided Diagnosis', ""Alzheimer's Disease"", 'Deep Convolution Neural Network', 'Faster R-CNN', 'Biomarker']",,"In order to diagnose and prevent Alzheimer's Disease (AD), it is becoming increasingly important to develop a CAD(Computer-aided Diagnosis) system for AD diagnosis, which provides effective treatment for patients by analyzing 3D MRI images. It is essential to apply powerful deep learning algorithms in order to automatically classify stages of Alzheimer's Disease and to develop a Alzheimer's Disease support diagnosis system that has the function of detecting hippocampus and CSF(Cerebrospinal fluid) which are important biomarkers in diagnosis of Alzheimer's Disease. In this paper, for AD diagnosis, we classify a given MRI data into three categories of AD, mild cognitive impairment, and normal control according by applying 3D brain MRI image to the Faster R-CNN model and detect hippocampus and CSF in MRI image. To do this, we use the 2D MRI slice images extracted from the 3D MRI data of the Faster R-CNN, and perform the widely used majority voting algorithm on the resulting bounding box labels for classification. To verify the proposed method, we used the public ADNI data set, which is the standard brain MRI database. Experimental results show that the proposed method achieves impressive classification performance compared with other state-of-the-art methods."
두 개의 이종 CNN 융합을 이용한 차선 검출,2019,"['lane detection', 'deep learning', 'convolutional neural networks', 'transfer learning']",,"Lane detection is essential in many applications including autonomous navigation and intelligent vehicles. Recently, theperformance of image recognition and detection has been remarkably improved by Convolutional Neural Networks (CNN). In thispaper, we present a method for lane detection by combining the results of two CNN architectures. The first CNN detects lanelocations on the image via a sliding window, while the second one detects the vanishing point and the lane angle. By combining theresults of these two structures, we present a method to improve lane detection results by comparing the lane detection result fromeach structure."
한자 이미지 분할 기법 및 Mask R-CNN 성능 평가,2019,"['Character extraction', 'Mask R-CNN', 'Image segmentation', 'Computer vision', 'AI']","인공지능 진보에 따라서 컴퓨터 비전을 포함한 다양한 분야에서 인공지능을 활용하고 있다. 특히주어진 이미지에서 객체와 배경을 분리하여 인식하는 기법들이 발달됨에 따라서 기존 객체 분할로사용되던 기술들이 가지고 있던 단점들을 극복할 수 있는 방안으로 활용이 가능하다. 기존의 기술의경우 한자와 같이 특별한 객체를 정확하게 검출하지 못하고, 영역분할 요류 및 영역 겹침 오류가나타난다. 본 논문은 한자 사전 작업에 앞서 고서 스캔 이미지에서 활자를 검출 및 추출에 기존알고리즘이 가지는 제약점을 살펴보며, 활자 검출에 있어서 mask R-CNN의 활용 가능성 및 성능에대한 평가하여 기존 알고리즘 대비 mask R-CNN의 활용성이 높음을 확인하였다.",
임의 차원 데이터 대응 Dynamic RNN-CNN 멀웨어 분류기,2019,['F1'],,"This study proposes a malware classification model that can handle arbitrary length input data using the Microsoft Malware Classification Challenge dataset. We are based on imaging existing data from malware. The proposed model generates a lot of images when malware data is large, and generates a small image of small data. The generated image is learned as time series data by Dynamic RNN. The output value of the RNN is classified into malware by using only the highest weighted output by applying the Attention technique, and learning the RNN output value by Residual CNN again. Experiments on the proposed model showed a Micro-average F1 score of 92% in the validation data set. Experimental results show that the performance of a model capable of learning and classifying arbitrary length data can be verified without special feature extraction and dimension reduction."
Mask R-CNN을 이용한 항공 영상에서의 도로 균열 검출,2019,[],,"Conventional crack detection methods have a problem of consuming a lot of labor, time and cost. To solve these problems, an automatic detection system is needed to detect cracks in images obtained by using vehicles or UAVs(unmanned aerial vehicles). In this paper, we have studied road crack detection with unmanned aerial photographs. Aerial images are generated through preprocessing and labeling to generate morphological information data sets of cracks. The generated data set was applied to the mask R-CNN model to obtain a new model in which various crack information was learned. Experimental results show that the cracks in the proposed aerial image were detected with an accuracy of 73.5% and some of them were predicted in a certain type of crack region."
MAV 환경에서의 CNN 기반 듀얼 채널 음향 향상 기법,2019,['2'],"최근 드론과 같은 멀티로터 UAV(Unmanned Aerial Vehicle, 무인항공기)의 산업 범위가 크게 확대됨에 따라, UAV를 활용한 데이터의 수집 및 처리, 분석에 대한 요구도 함께 증가하고 있다. 그러나 UAV를 이용해서 수집된 음향 데이터는 UAV의 모터 소음과 바람 소리 등으로 크게 손상되어, 음향 데이터의 처리 및 분석이 어렵다는 단점이 있다. 따라서 본 논문에서는 UAV에 연결된 마이크를 통해 수신된 음향 신호로부터 목표 음향 신호의 품질을 향상시킬 수 있는 방법에 대해 연구하였다. 본 논문에서는 기존의 단일 채널 음향 향상 기술 중 하나인 densely connected dilated convolutional network를 음향 신호의 채널 간 특성을 반영할 수 있도록 확장하였으며, 그 결과 SDR, PESQ, STOI과 같은 평가 지표에서 기존 연구 대비 좋은 성능을 보였다.",
CNN 기법을 활용한 터널 암판정 예측기술 개발,2019,"['Deep Learning', 'VGG16', 'Convolutional Neural Network', 'Face Mapping', 'RMR']",,"Quick identification of the condition of tunnel face and optimized determination of support patterns during tunnel excavation in underground construction projects help engineers prevent tunnel collapse and safely excavate tunnels. This study investigates a CNN technique for quick determination of rock quality classification depending on the condition of tunnel face, and presents the procedure for rock quality classification using a deep learning technique and the improved method for accurate prediction. The VGG16 model developed by tens of thousands prestudied images was used for deep learning, and 1,43769 tunnel face images were used to classify the five types of rock quality condition. In this study, the prediction accuracy using this technique was up to 83.9%. It is expected that this technique can be used for an error-minimizing rock quality classification system not depending on experienced professionals in rock quality rating."
A Study on Fault Classification of Machining Center using Acceleration Data Based on 1D CNN Algorithm,2019,"['Machining Center(머시닝센터)', 'Machine Learning(머신러닝)', 'Fault Signal Classification(고장신호 분류)', 'CNN(합성곱 신경망)']",,"The structure of the machinery industry due to the 4th industrial revolution is changing from precision and durability to intelligent and smart machinery through sensing and interconnection(IoT). There is a growing need for research on prognostics and health management(PHM) that can prevent abnormalities in processing machines and accurately predict and diagnose conditions. PHM is a technology that monitors the condition of a mechanical system, diagnoses signs of failure, and predicts the remaining life of the object. In this study, the vibration generated during machining is measured and a classification algorithm for normal and fault signals is developed. Arbitrary fault signal is collected by changing the conditions of un stable supply cutting oil and fixing jig. The signal processing is performed to apply the measured signal to the learning model. The sampling rate is changed for high speed operation and performed machine learning using raw signal without FFT. The fault classification algorithm for 1D convolution neural network composed of 2 convolution layers is developed."
이종 CNN 알고리즘을 이용한 물체 인식과 로봇의 파지 제어,2019,"['deep learning', 'instance segmentation', 'fully convolutional network', 'object detection', 'ROS']",,"The detection of robot manipulator’s object-grasping point is the most important step in precise handling of object. To grasp object needs some important parameters, which are object’s center coordinates (x, y, z) and width, yaw angle. In this paper, we predict not individual parameters but grasping area by using Segmentation Algorithm. Combining Mask R-CNN algorithm and Fully Convolutional Net algorithm and adding them to ROS, we construct ROS architecture. And, we apply them to control moving robot’s manipulator in grasping objects. So, we can reduce processing time for detecting object and improve applicability of this new method in robotic grasping control."
에지 분류 CNN 을 이용한 U-Net 기반 에지 검출,2019,"['edge', 'convolutional neural networks', 'deep learning']",,"Edge detection is the first necessary step in image processing for object segmentation, detection, and recognition. TheCanny algorithm is widely used filter-based approach, but it requires the correct adjustment of its parameters according to thevariations in images. In this paper, we propose a method that is consisted of two steps for the robust detection of edges in an image.The proposed algorithm adopts convolutional neural networks that can handle the diverse variations caused by illumination, pose,and scale change. First, we train a convolutional neural network to decide whether a given input edge image is good or not. We cangenerate as many training images as we want using this network. Finally, U-Net is used to generate an edge image using a gray imageas input. Experimental results show the robustness of the proposed algorithm for images acquired under outdoor and indoor environments."
Performance Comparison of the Optimizers in a Faster R-CNN Model for Object Detection of Metaphase Chromosomes,2019,[],,"In this paper, we compares the performance of the gredient descent optimizers of the Faster Region-based Convolutional Neural Network (R-CNN) model for the chromosome object detection in digital images composed of human metaphase chromosomes. In faster R-CNN, the gradient descent optimizer is used to minimize the objective function of the region proposal network (RPN) module and the classification score and bounding box regression blocks. The gradient descent optimizer. Through performance comparisons among these four gradient descent optimizers in our experiments, we found that the Adamax optimizer could achieve the mean average precision (mAP) of about 52% when considering faster R-CNN with a base network, VGG16. In case of faster R-CNN with a base network, ResNet50, the Adadelta optimizer could achieve the mAP of about 58%."
인공위성 자료를 이용한 Faster R-CNN 기반 태풍 식별 및 강도․중심위치 산출,2019,"['Deep Learning', 'Object Detection', 'Convolutional Neural Network', 'Typhoon Intensity and Center Estimation']",,"Locating the center and predicting the intensity of typhoons are critical issues to prevent damages caused bythem. In this paper, we propose two models based on Faster R-CNN for predicting the intensity and the centerlocation of typhoons via satellite images without pre-processing; one of the models utilizes an only single-channeland the other uses whole four channels. The biggest advantage of proposed models is that it can produce both thecenter coordinates and the class of the intensity regardless of the number of typhoons occurred, which never havebeen studies yet. Compared to the single-channel model, multi-channel model achieves higher typhoon detection ratethan single-channel model since it can extract various aspects of features from multiple channels through CNNbackbone network."
사영 변환하의 합성 이미지를 이용한Mask R-CNN 기반 QR 코드 검출,2019,"['QR code', '2D barcode', 'deep learning', 'convolutional neural networks', 'transfer learning']",,"Various types of 2D barcodes including QR code, Data Matrix are widely used in diverse industries. Recently, QR code isadopted in mobile phone. They require QR code occupy some amount of area on the image to correctly operate. In other applicationof mobile robot navigation where QR code is used as landmarks, we need to detect QR code in various scale and lighting condition.Traditional approaches operate well under restricted conditions also they require the setting of many parameters. In this paper, wedeal with the detection of QR code in wild including various lighting condition and scale. We adopt the Mask R-CNN [11] for thedetection of QR code. It requires many training images to have good performance. We present a method that uses composite imageswhich is made under general perspective transform. QR code under reference poses and real images are composited by the presentedmethod. We present various experimental results under diverse configuration of hyperparameters. Sequential step of first trainingusing many composite images then finally training using real images show the best performance. Experimental results show thefeasibility of presented approach."
영상에서 패치기반 CNN 모형을 이용한 잡음제거,2019,"['딥러닝', '잡음영상', '잡음제거', 'convolutional neural network', 'Convolutional neural network (CNN)', 'deep learning', 'noise reduction', 'noisy image']","영상에서 잡음제거는 패턴인식, 영상압축, 에지검출, 영상분할과 같은 영상처리 분야의 전처리과정으로 도전할 만한 가치가 있다. 본 논문에서는 딥러닝의 convolutional neural network (CNN) 모형을 이용하여 잡음제거 하고자 한다. CNN 모형은 영상인식, 물체인식 얼굴인식과 같은 컴퓨터 비전 문제에서 좋은 성능을 보이고 있으나 잡음제거에 대해서는 그 중요성에 비추어 아직까지 연구가 덜 이루어졌다. 지금까지 영상에서 잡음제거는 특정한 분포 특성을 갖고 있다는 가정 하에서 설계된 고유한 필터를 사용하였다. 이 경우 가정을 만족하지 않는 필더를 사용하는 경우 성능이 현저히 떨어지는 경향이 있다. 본 논문에서는 잡음에 대한 사전정보 없이 사용가능한 방법으로 영상의 작은 블록인 패치 (patch) 상에서 CNN을 적용하고 중첩된 패치(overlapped patches)에서 해당 픽셀들의 가중평균을 구하여 잡음제거 영상을 얻는다. CNN에서 매개변수 최적화는 잡음데이터에 적응력이 좋은 Adam 알고리즘을 사용한다. 영상실험은 가우시안 잡음영상과 임펄스 잡음영상 모두를 고려하였고 실험결과, 패치기반 CNN 모형은 다른 방법보다 좋은 화질의 영상을 도출하였고 또한 MAE (mean absolute error)와 PSNR (peak signal-to-noise ratio) 면에서도 좋은 성능을 지님을 알 수 있었다.","Noise reduction problem in images still prevails as a challenge in the field of image processing such as pattern recognition, image compression, edge detection and image segmentation. Addressing this issue, this paper presents a novel deep learning approach based on a Convolutional Neural Network (CNN) . CNN has shown excellent performance in computer vision problems such as image recognition, object recognition, and face recognition, but little has been discussed in light of the importance of noise reduction in images. Until now, noise reduction in the images has been used with filters designed under the assumption that it has specific distribution characteristics. In this case, the use of filters that do not satisfy the assumption leads to significant performance degradation. In this paper, CNN is applied on patches of images in a way that is available without prior information about noise. The restored image is obtained by the weighted average of the corresponding pixels in overlapping patches. In CNN, parameter optimization is done by the Adam algorithm that is adaptable to noise data. We considered both Gaussian noise and impulse noise to test the performance of our CNN model. Experimental results on several images show that the patch-based CNN model yields significantly superior image quality and better MAE (mean absolute error) and PSNR (peak signal-to-noise ratio)."
실시간 야구 중계를 위한 CNN 기반 고속 야구 선수 위치 검출 시스템,2019,"['image detection algorithm', 'deep learning', 'CNN', 'baseball broadcasting', '이미지 위치 검출', '딥러닝', 'CNN', '야구 경기 중계']","본 논문에서는 야구 경기 영상에서 딥 러닝 기법들 중 영상 인식에 적합한 CNN을 사용하여 야구 선수의 위치를 검출하는 시스템을 제안한다. 객체의 위치 검출을 위한 기존의 영상 처리 기법들 중 다수는 영상 프레임 사이의 차영상이나 객체의 윤곽을 얻는 방법들을 사용해왔지만, 야구 중계와 같이 다양한 기후와 배경을 모두 고려하여 실용화하기에는 추가적인 검증 과정이 필요하다. 본 논문에서는 다양한 경우에 움직이는 객체의 위치를 빠르게 학습하고 검출하기 위해 이진 블록 영상을 적용하였고 학습 성능을 향상시키기 위해 학습 영상을 추가로 생성하는 데이터 증강 기법을 사용하였다. 선수 위치의 정확도 평가 척도는 목표 객체의 중심점과 지능망을 통해 검출된 확률 중심과의 거리를 평가 척도로 적용하였다.실험 결과는 제안한 방법의 평균 거리가 2.92픽셀로 Faster R-CNN의 평균 거리인 3.35보다 0.43픽셀이 낮아 선수의 위치 검출 정확도가 높으며, 수행 속도도 제안한 방법이 Faster R-CNN보다 69.93배 빠름을 보여준다.","The paper proposes a player location detection system in a baseball game broadcast.Location detection system uses CNN (convolutional neural network) suitable for image processing among diverse deep learning systems. To train the location of a player faster and accurately, we choose binary block labeling instead of the commonly used edge detection methods. Data augmentation method, which generates additional training images was applied to increase the degree of accuracy.The distance between the center position of the target and the output position by neural network was used to measure performance. Experimental results indicated that the average pixel distances between center of target position and one of output are 2.92 and 3.35 in the case of the proposed method and Faster R-CNN, respectively. In addition, the execution time of the proposed method was established to be 69.93 times faster than that of Faster R-CNN."
CNN 기반 기보학습 및 강화학습을 이용한 인공지능 게임 에이전트,2019,"['Reinforcement Learning', 'Othello game agent', 'Value function network', 'CNN', 'Records learning']","본 논문에서는 인공지능 오델로 게임 에이전트를 구현하기 위해 실제 프로기사들의 기보를 CNN으로 학습시키고 이를 상태의 형세 판단을 위한 근거로 삼아 최소최대탐색을 이용해 현 상태에서 최적의 수를 찾는 의사결정구조를 사용하고 이를 발전시키고자 강화학습 이론을 이용한 자가대국 학습방법을 제안하여 적용하였다. 본 논문에서 제안하는 구현 방법은 기보학습의 성능 평가 차원에서 가치평가를 위한 네트워크로서 기존의 ANN을 사용한 방법과 대국을 통한 방법으로 비교하였으며, 대국 결과 흑일 때 69.7%, 백일 때 72.1%의 승률을 나타내었다. 또한 본 논문에서 제안하는 강화학습 적용 결과 네크워크의 성능을 강화학습을 적용하지 않은 ANN 및 CNN 가치평가 네트워크 기반 에이전트와 비교한 결과 각각 100%, 78% 승률을 나타내어 성능이 개선됨을 확인할 수 있었다.","This paper proposes a CNN architecture as value function network of an artificial intelligence Othello game agent and its learning scheme using reinforcement learning algorithm. We propose an approach to construct the value function network by using CNN to learn the records of professional players’ real game and an approach to enhance the network parameter by learning from self-play using reinforcement learning algorithm. The performance of value function network CNN was compared with existing ANN by letting two agents using each network to play games each other. As a result, the winning rate of the CNN agent was 69.7% and 72.1% as black and white, respectively. In addition, as a result of applying the reinforcement learning, the performance of the agent was improved by showing 100% and 78% winning rate, respectively, compared with the network-based agent without the reinforcement learning."
Enhanced CNN-based Plant Growing-stage Classification using Additional Information Carried in an Additional Channel,2019,"['Plant phenotype', 'Convolutional neural network', 'Additional image channel', 'Plant growing stage']",,"Studying the observable characteristics of mutants and the growing stages of the same genotype plant interacting with various environmental conditions is important in order to understand the performance of a particular trait in different growth environments. A plant""s growing stage affects the growth rate of leaves, the photosynthetic rate, water absorption capacity, and other characteristics. By automating the plant mutant classification process and the growing-stage classification process, botanists and agriculture scientists can perform large-scale experiments to cultivate plants with useful traits to combat extreme environmental conditions. This research aims to construct an enhanced optimum convolutional neural network (CNN) for image-based plant growing-stage classification, and a description of the algorithms to construct the optimum CNN for image-based plant mutant classification is included as well. This research was carried out using the Ara2013-Canon dataset annotated by the International Plant Phenotyping Network (IPPN) for classification processes. Optimum parameters found in this paper are for 1) the number of convolutional layers, 2) the number of neurons in a fully connected (FC) layer, and 3) the number of FC layers in a CNN for plant growing-stage classification. The possibility to enhance the successful classification rate is explored by introducing an additional channel that carries additional useful information, such as 1) mutant type, 2) number of leaves, 3) total size for all leaves, 4) mean leaf size, and 5) standard deviation of the leaf size in the form of square matrices. Experimental results show that under optimum conditions for growing-stage classification, a CNN classification system utilizing plant images and all additional useful information provides the best recognition rate at 81.97%."
A Text Sentiment Classification Method Based on LSTM-CNN,2019,"['Machine Learning', 'CNN', 'LSTM', 'Text Sentiment Classification Methods', 'Deep Learning', '텍스트 정서 분류 방법']","머신 러닝의 심층 개발로 딥 러닝 방법은 특히 CNN(Convolution Neural Network)에서 큰 진전을 이루었다. 전통적인 텍스트 정서 분류 방법과 비교할 때 딥 러닝 기반 CNN은 복잡한 다중 레이블 및 다중 분류 실험의 텍스트 분류 및 처리에서 크게 발전하였다. 그러나 텍스트 정서 분류를 위한 신경망에도 문제가 있다. 이 논문에서는 LSTM (Long-Short Term Memory network) 및 CNN 딥 러닝 방법에 기반 한 융합 모델을 제안하고, 다중 카테고리 뉴스 데이터 세트에 적용하여 좋은 결과를 얻었다. 실험에 따르면 딥 러닝을 기반으로 한 융합 모델이 텍스트 정서 분류의 예측성과 정확성을 크게 개선하였다. 본 논문에서 제안한 방법은 모델을 최적화하고 그 모델의 성능을 개선하는 중요한 방법이 될 것이다.","With the in-depth development of machine learning, the deep learning method has made great progress, especially with the Convolution Neural Network(CNN). Compared with traditional text sentiment classification methods, deep learning based CNNs have made great progress in text classification and processing of complex multi-label and multi-classification experiments. However, there are also problems with the neural network for text sentiment classification. In this paper, we propose a fusion model based on Long-Short Term Memory networks(LSTM) and CNN deep learning methods, and applied to multi-category news datasets, and achieved good results. Experiments show that the fusion model based on deep learning has greatly improved the precision and accuracy of text sentiment classification. This method will become an important way to optimize the model and improve the performance of the model."
CNN-based damage identification method of tied-arch bridge using  spatial-spectral information,2019,"['multiple damage identification for hangers', 'tied-arch bridge', 'convolutional neural network', 'deep learning', 'Fourier amplitude spectra', 'ambient wind vibration data']",,"In the structural health monitoring field, damage detection has been commonly carried out based on the structural model and the engineering features related to the model. However, the extracted features are often subjected to various errors, which makes the pattern recognition for damage detection still challenging. In this study, an automated damage identification method is presented for hanger cables in a tied-arch bridge using a convolutional neural network (CNN). Raw measurement data for Fourier amplitude spectra (FAS) of acceleration responses are used without a complex data pre-processing for modal identification. A CNN is a kind of deep neural network that typically consists of convolution, pooling, and fully-connected layers. A numerical simulation study was performed for multiple damage detection in the hangers using ambient wind vibration data on the bridge deck. The results show that the current CNN using FAS data performs better under various damage states than the CNN using time-history data and the traditional neural network using FAS. Robustness of the present CNN has been proven under various observational noise levels and wind speeds."
Real-Time Implementation of Human Detection in Thermal Imagery Based on CNN,2019,"['background modeling', 'CNN', 'deep learning', 'human detection', 'thermal videos']",,"In this paper, an effective human detection method in thermal imaging is proposed using background modeling and convolution neural network(CNN). For real-time implementation, the background modeling is done by modified running Gaussian average and the CNN-based human classification is performed for only detected foreground objects. To enhance human detection accuracy, morphological operators and ellipse testing are adopted to extract Region of Interest. Also, three CNN models with different input sizes and voting method are trained using our own dataset. For real-time system, the whole system is implemented in C++ and it process more than 30 fps with high accuracy."
드론의 자동 랜딩을 위한 CNN을 이용한 객체인식,2019,"['쿼드콥터', '무인항공기', '비전 센서', '객체 인식', '제어', 'CNN']",,
CNN을 이용한 궤적데이터에 대한 이동성 모드 분류 방법,2019,"['mobility modes', 'CNN', 'classification', 'trjajectory']",,"Recognizing the mobility modes (bus, car, train, etc.) of the users moving trajectories in trajectory mining is very important for extracting more accurate information. In this paper, we propose a mobility mode classification method for users trajectories based on CNN (Convolution Neural Network). The proposed mobility mode classification method in this paper generates the users’ bus trajectories by using the actual bus trajectories. We use the approach of classifying the mobility modes of the collected user trajectories using the derived learning model through CNN using the collected user trajectories and the generated bus users’ trajectories. We perform the mobility mode classification experiment using the actual user trajectory data. As the result of the mobility mode classification experiment, the classification accuracy was 95.98%. In addition, it was confirmed that the proposed method is more suitable for the mobility mode classification for the users trajectories through a comparison experiment with the previously proposed mobility mode classification method."
CNN과 후처리를 이용한 해상쓰레기와 해파리 무리 인식,2019,"['해파리 검출', '해상쓰레기', 'CLAHE', '군집인식', 'CNN', 'Jellyfish Detection', 'Marine Garbage', 'Cluster Recognition']","최근 해상쓰레기와 해파리 등으로 인하여 어민들과 바닷가 방문객이 큰 피해를 보고 있다. 본 연구에서는 영상에서 이러한 해상쓰레기와 해파리를 검출하는 방법을 제안한다. 우리나라 근해의 해수는 부유물이 많아서 색상이 탁하며, 수면에 햇빛이 반사되어 해수면 아래에 있는 해파리를 검출하기가 쉽지가 않아 CLAHE를 이용하여 영상을 개선한다. 해파리는 무리 지어서 이동하는 특징이 있다. 따라서 해파리를 개별적으로 인식하는 것이 보다 무리를 검출하는 것이 효율적이라고 판단하여, 개체가 다섯 마리 이상이면 무리라고 간주하고 군집인식방법을 수행한다. 군집인식에서는 필터를 이용하여 해파리 색상인 흰색 분포의 밀집 지점을 찾는다. 그 후 k-평균 클러스터링 알고리즘을 이용하여 바다와 해파리를 분류한다. 군집인식을 수행한 결과, 해파리 개체 하나하나를 인식하는 것보다 해파리 무리를 인식하는 것이 좋은 성능을 나타내는 것을 볼 수 있었다. 해상쓰레기는 CNN을 사용하여 좋은 결과를 얻었다.","Recently, fishermen and person who visits seashore are suffering greatly because of marine garbage and jellyfish. In this paper, we propose a method to detect marine garbage and jellyfish in images. It is difficult to detect jellyfish below the sea surface because seawater in Korea has a lot of suspended matter and its color is cloudy, and sunlight is reflected on the water surface. So the image is enhanced using the CLAHE. Jellyfish has a property of moving in groups. Therefore, it is more effective to detect jellyfish group than each jellyfish. Therefore, if the number of jellyfish is more than five, it is regarded as a group and a cluster recognition method is performed. A filter is used to find the dense point of the white distribution of the jellyfish color. Then, a method of classifying the image into the sea and jellyfish using k-means clustering algorithm is performed. As the result of cluster recognition, we could see that recognized jellyfish group was better than recognizing individual jellyfish. Marine garbage recognition achieved good results using CNN."
GPR 영상에서 딥러닝 기반 CNN을 이용한 배관 위치 추정 연구,2019,"['sink holes', 'pipe', 'GPR', 'image recognition', 'underground detection', 'CNN', 'deep-learning', '지하공동', '배관', 'GPR영상', '지하 탐지', '영상 인식', '딥러닝', '컨볼루션 뉴럴 네트워크']",최근에 지하공동이나 배관의 위치 파악 등의 필요에 의해 금속을 포함하여 다양한 재질의 지하 물체를 탐지하는 일이 중요해지고있다. 이러한 이유로 지하 탐지 분야에서 GPR(Ground Penetrating Radar) 기술이 주목을 받고 있다. GPR은 지하에 묻혀 있는 물체의위치를 찾기 위하여 레이더파를 조사하고 물체로부터 반사되는 반사파를 영상으로 표현한다. 그런데 레이더 신호는 지하에서 여러가지 물체에서 반사되어 나오는 특징이 물체마다 유사한 경우가 많기 때문에 GPR 영상을 해석하는 것은 쉽지 않다. 따라서 본 논문에서는 이러한 문제를 해결하기 위해서 영상 인식 분야에서 최근에 많이 활용되고 있는 딥러닝 기반의 CNN(Convolutional Neural Network)모델을 이용하여 임계값에 따른 GPR 영상에서의 배관 위치를 추정하고 그 실험 결과 임계값이 7 혹은 8 일 때 가장 확실하게 배관의 위치를 찾음을 증명하였다,"In recently years, it has become important to detect underground objects of various marterials including metals, such as detecting the location of sink holes and pipe. For this reason, ground penetrating radar(GPR) technology is attracting attention in the field of underground detection. GPR irradiates the radar wave to find the position of the object buried underground and express the reflected wave from the object as image. However, it is not easy to interpret GPR images because the features reflected from various objects underground are similar to each other in GPR images. Therefore, in order to solve this problem, in this paper, to estimate the piping position in the GRP image according to the threshold value using the CNN (Convolutional Neural Network) model based on deep running, which is widely used in the field of image recognition, As a result of the experiment, it is proved that the pipe position is most reliably detected when the threshold value is 7 or 8."
CNN을 활용한 IoT 스트림 데이터 패턴 분류 기법,2019,"['IoT', '스트림 데이터', '딥러닝', '패턴 분류', 'IoT', 'stream data', 'deep learning', 'pattern analysis']","사물 인터넷(Internet of Things, IoT) 환경의 발달로 다양한 종류의 센서들로부터 대량의 데이터가 생성되고 있으며, 이를 수집, 관리 및 분석하기 위한 빅데이터 기술이 중요해지고 있다. 최근에는 실시간으로 생성되는 대용량의 IoT 데이터 분석에 딥러닝 기술을 활용하여 특정 데이터 패턴이나 경향성의 분석을 수행하기 위한 연구가 진행되고 있다. 본 논문에서는 헬스케어 등 IoT 기반 서비스에의 활용 가능성이 높은 스트림데이터 중 하나인 ECG(Electrocardiogram, 심전도) 데이터에 대하여, 딥러닝 모델을 설계 및 적용함으로써 효율적인 분석을 가능하도록 하였다. 먼저, ECG 스트림 데이터의 패턴 분류를 위하여 합성곱 신경망(Convolutional Neural Networks, CNN) 기반의 딥러닝 모델을 설계하고, 이를 최적화하기 위한 다양한 파라미터들을 각각 모델의 구조와 학습에 관련한 파라미터들로 분리하여 실험을 설계 및 진행하였다. 또한, 분류 작업의 추가적인 성능 향상을 위하여, ECG 스트림 데이터에 대한 전처리 기법을 고안하여 적용해 보았다. 이러한 다양한 조건을 기반으로 설계된 실험들은, 서로 다른 센서에서 서로 다른 목적으로 수집되어 서로다른 특성을 갖는 두 가지의 ECG 스트림 데이터 세트 에 대하여 각각 수행되었다. 그 결과, 레이어가 깊을수록, 배치 크기가 큰 학습 모델일수록 IoT 스트림 데이터의 패턴 분류에 용이한 모델 구조라는 결론을 얻을수 있었다.","These days due to the development of the Internet of Things environment, big data technology is becoming important for collecting and managing large amounts of data. Recent studies are being conducted to incorporate deep learning technology into Internet of Things(IoT) data analysis in order to classify the specific pattern and trends. In this paper, ECG(Electrocardiogram) data, which could be useful for IoT services, is the input steam data, and a deep learning model structure suitable for data characteristics is found, so that IoT data analysis is efficiently performed. In order to classify the IoT stream data pattern, the experiments were conducted to find the best suitable model structure using the convolutional neural networks. To optimize the CNN, various models and parameter values were used to design various experiments. Also to enhance the classification performance, a preprocessing step is added to the existing convolutional neural networks model. The model structure parameters and the model learning parameters are divided into two major conditions. The experiment environment is set up and applied to two time series data with different characteristics. It is concluded that the deeper the layer and the larger the batch size, the easier model structure for IoT data pattern classification."
Mask R-CNN을 이용한 물체인식 및 개체분할의 학습 데이터셋 자동 생성,2019,"['Object Detection', 'Instance Segmentation', 'Deep Learning', 'Dataset Generation']",,"A robot usually adopts ANN (artificial neural network)-based object detection and instance segmentation algorithms to recognize objects but creating datasets for these algorithms requires high labeling costs because the dataset should be manually labeled. In order to lower the labeling cost, a new scheme is proposed that can automatically generate a training images and label them for specific objects. This scheme uses an instance segmentation algorithm trained to give the masks of unknown objects, so that they can be obtained in a simple environment. The RGB images of objects can be obtained by using these masks, and it is necessary to label the classes of objects through a human supervision. After obtaining object images, they are synthesized with various background images to create new images. Labeling the synthesized images is performed automatically using the masks and previously input object classes. In addition, human intervention is further reduced by using the robot arm to collect object images. The experiments show that the performance of instance segmentation trained through the proposed method is equivalent to that of the real dataset and that the time required to generate the dataset can be significantly reduced."
CNN을 이용한 재난 예경보 시스템,2019,"['Disaster prevention system', 'Object detection', 'Deep-Learning', 'CNN', 'SVM']",,"In this paper, we propose an intelligent CCTV technology which is applied to a recent attracted attention real-time object detection technology in a disaster alarm system. Natural disasters are rapidly increasing due to climate change (global warming). Various disaster alarm systems have been developed and operated to solve this problem. In this paper, we detect object through Neuron Network algorithm and test the difference from existing SVM classifier. Experimental results show that the proposed algorithm overcomes the limitations of existing object detection techniques and achieves higher detection performance by about 15%."
강건한 CNN기반 수중 물체 인식을 위한 이미지 합성과 자동화된 Annotation Tool,2019,"['Deep Learning', 'Data Annotation', 'Object Detection', '3D CAD Model']",,"In this paper, we present auto-annotation tool and synthetic dataset using 3D CAD model for deep learning based object detection. To be used as training data for deep learning methods, class, segmentation, bounding-box, contour, and pose annotations of the object are needed. We propose an automated annotation tool and synthetic image generation. Our resulting synthetic dataset reflects occlusion between objects and applicable for both underwater and in-air environments. To verify our synthetic dataset, we use MASK R-CNN as a state-of-the-art method among object detection model using deep learning. For experiment, we make the experimental environment reflecting the actual underwater environment. We show that object detection model trained via our dataset show significantly accurate results and robustness for the underwater environment. Lastly, we verify that our synthetic dataset is suitable for deep learning model for the underwater environments."
Analyses on the Performance of the CNN Reflecting the Cerebral Structure for Prediction of Cybersickness Occurrence,2019,"['Cybersickness', 'Dizziness', 'CNN', 'EEG', 'Artificial Neural Network']",,"In this study, we compared and analyzed the performance of each Convolution Neural Network (CNN) by implementing the CNN that reflected the characteristics of the cerebral structure, in order to analyze the CNN that was used for the prediction of cybersickness, and provided the performance varying depending on characteristics of the brain. Dizziness has many causes, but the most severe symptoms are considered attributable to vestibular dysfunction associated with the brain. Brain waves serve as indicators showing the state of brain activities, and tend to exhibit differences depending on external stimulation and cerebral activities. Changes in brain waves being caused by external stimuli and cerebral activities have been proved by many studies and experiments, including the thesis of Martijn E. Wokke, Tony Ro, published in 2019. Based on such correlation, we analyzed brain wave data collected from dizziness-inducing environments and implemented the dizziness predictive artificial neural network reflecting characteristics of the cerebral structure. The results of this study are expected to provide a basis for achieving optimal performance of the CNN used in the prediction of dizziness, and for predicting and preventing the occurrence of dizziness under various virtual reality (VR) environments."
CNN Model Performance Analysis on MRI Images of an OASIS Dataset for Distinction Between Healthy and Alzheimer’s Patients,2019,"['Medical MRI', 'CNN', 'AlexNet', 'GoogLeNet', 'ResNet50', 'CAD']",,"In this paper, we present the performance of a medical image classification model pretrained on natural images. In addition, another model is scratch trained from available medical magnetic resonance images in order to get a comparative analysis. We perform shallow tuning and fine-tuning of the pretrained model (AlexNet, GoogLeNet, and ResNet50) in a bunch of layers in order to find the impact of each section of layers in the classification result. We use 28 normal controls (NC) and 28 Alzheimer’s disease (AD) patients for classification, selecting 30 important slices from each patient. Once all the slices were collected, each model was trained, validated, and tested at a ratio of 6:2:2 on a random selection basis. The testing results are reported and analyzed so the final CNN model could be built with a minimal number of layers for optimal performance."
Faster R-CNN을 활용한 GPR 영상에서의 지하배관 위치추적 성능분석,2019,"['지하 배관', 'Faster R-CNN', '지표 투과 레이더', '딥러닝', 'VGGnet', '어그멘테이션', 'Buried pipelines', 'Faster R-CNN', 'GPR', 'Deep learning', 'VGGnet', 'Augmentation']",,
Gesture-Based Emotion Recognition by 3D-CNN and LSTM with Keyframes Selection,2019,"['Gesture-based Emotion Recognition', '3D Convolutional Networks', 'Convolution LSTM.']",,"In recent years, emotion recognition has been an interesting and challenging topic. Compared to facial expressions and speech modality, gesture-based emotion recognition has not received much attention with only a few efforts using traditional hand-crafted methods. These approaches require major computational costs and do not offer many opportunities for improvement as most of the science community is conducting their research based on the deep learning technique. In this paper, we propose an end-to-end deep learning approach for classifying emotions based on bodily gestures. In particular, the informative keyframes are first extracted from raw videos as input for the 3D-CNN deep network. The 3D-CNN exploits the short-term spatiotemporal information of gesture features from selected keyframes, and the convolutional LSTM networks learn the long-term feature from the features results of 3D-CNN. The experimental results on the FABO dataset exceed most of the traditional methods results and achieve state-of-the-art results for the deep learning-based technique for gesture-based emotion recognition."
Atypical Character Recognition Based on Mask R-CNN for Hangul Signboard,2019,"['Atypical Character Recognition', 'Hangul Signboard', 'Mask R-CNN', 'Hangul signboard character']",,"This study proposes a method of learning and recognizing the characteristics that are the classification criteria of Hangul using Mask R-CNN, one of the deep learning techniques, to recognize and classify atypical Hangul characters. The atypical characters on the Hangul signboard have a lot of deformed and colorful shapes beyond the general characters. Therefore, in order to recognize the Hangul signboard character, it is necessary to learn a separate atypical Hangul character rather than the existing formulaic one. We selected the Hangul character ‘닭’ as sample data and constructed 5,383 Hangul image data sets and used them for learning and verifying the deep learning model. The accuracy of the results of analyzing the performance of the learning model using the test set constructed to verify the reliability of the learning model was about 92.65% (the area detection rate). Therefore we confirmed that the proposed method is very useful for Hangul signboard character recognition, and we plan to extend it to various Hangul data."
영상처리와 CNN 결합을 통한 야간 도로상의 전방 차량 인식,2019,"['CNN-based object classification', 'disparity estimation', 'light-blobs', 'nighttime vehicle detection']",,We propose a convolutional neural network (CNN)-based approach to detect vehicles in front of an ego-vehicle for road traffic scenes at night and compare it with our AdaBoost-based approaches. The new approach enhances the previous approaches [5] in terms of vehicle detection performance. We also produce negative learning data by exploiting a vehicle candidate-generation scheme that further improves classifier performance. The experimental results for real-world road images illustrate the effectiveness of the proposed algorithm.
Fast R-CNN을 이용한 객체 인식 기반의 도로 노면 파손 탐지 기법,2019,"['도로 노면 파손', '심층 신경망', '유지보수', '영역 기반 합성곱', '객체 인식', 'Road surface damage', 'Deep neural network', 'Road maintenance', 'Region based convolutional neural networks', 'Object recognition']",,
LSTM 신경망과 Du-CNN을 융합한 적외선 방사특성 예측 및 표적과 클러터 구분을 위한 CR-DuNN 알고리듬 연구,2019,"['Infrared image', 'Coast targets', 'Long short term memory', 'Convolutional neural network']",,"In this paper, we analyze the infrared feature for the small coast targets according to the surrounding environment for autonomous flight device equipped with an infrared imaging sensor and we propose Cross Duality of Neural Network (CR-DuNN) method which can classify the target and clutter in coastal environment. In coastal environment, there are various property according to diverse change of air temperature, sea temperature, deferent seasons. And small coast target have various infrared feature according to diverse change of environment. In this various environment, it is very important thing that we analyze and classify targets from the clutters to improve target detection accuracy. Thus, we propose infrared feature learning algorithm through LSTM neural network and also propose CR-DuNN algorithm that integrate LSTM prediction network with Du-CNN classification network to classify targets from the clutters."
UAV 항공사진측량 기술과 Faster R-CNN알고리즘을 활용한 연안양식장 탐색에 관한 연구,2019,"['UAVs', 'aerial photogrammetry', 'Coastal areas', 'Ocean farms', 'Facility detection', 'Faster R-CNN']",,"Recently, many researches using unmanned aerial vehicles(UAV) has been proposed for applications in coastal areas. However, there is still a need for consecutive researches on various types of UAVs, sensors and regions. Especially, it is necessary to study the practical use of the UAV photogrammetry in marine surveying. In Korea, aquaculture production accounts for 61.8% of total aquatic-product production in 2017 and is increasing year by year. Therefore, there is a growing need to systematically manage, support and monitor aquatic products. In particular, unlicensed and illegal fisheries are increasing in Jeollanam-do. In 2016, the number of unlicensed and illegal fisheries has increased to 180% comparing in 2012. The Jeollanam-do fisheries resources division is implementing special crackdown on illegal aquaculture farmers every year. However, due to the nature of the marine environment, surveillance and enforcement are limited by field surveys alone. In this study, we propose a methodology by using UAV photogrammetry and automatic image recognition technology to increase efficiency of monitoring aquaculture farms. For this purpose, UAV photogrammetry was performed on abalone and seaweed ocean farms in Wando, Jeollanam-do. Then, we developed a methodology for automatically detecting the farm facilities in the marine environment by applying the Faster-RCNN (Regional Convolution Neural Network) to the generated orthophotos. Through the study, it is identified that small UAVs can be effectively used for the surveillance and management of the ocean farms in coastal areas. Also, the automatic method for recognizing aquaculture object using Faster R-CNN technique can be developed."
Atypical Character Recognition Based on Mask R-CNN for Hangul Signboard,2019,"['Atypical Character Recognition', 'Hangul Signboard', 'Mask R-CNN', 'Hangul signboard character']",,"This study proposes a method of learning and recognizing the characteristics that are the classification criteria of Hangul using Mask R-CNN, one of the deep learning techniques, to recognize and classify atypical Hangul characters. The atypical characters on the Hangul signboard have a lot of deformed and colorful shapes beyond the general characters. Therefore, in order to recognize the Hangul signboard character, it is necessary to learn a separate atypical Hangul character rather than the existing formulaic one. We selected the Hangul character ‘닭’ as sample data and constructed 5,383 Hangul image data sets and used them for learning and verifying the deep learning model. The accuracy of the results of analyzing the performance of the learning model using the test set constructed to verify the reliability of the learning model was about 92.65% (the area detection rate). Therefore we confirmed that the proposed method is very useful for Hangul signboard character recognition, and we plan to extend it to various Hangul data."
Atypical Character Recognition Based on Mask R-CNN for Hangul Signboard,2019,"['Atypical Character Recognition', 'Hangul Signboard', 'Mask R-CNN', 'Hangul signboard character']",,"This study proposes a method of learning and recognizing the characteristics that are the classification criteria of Hangul using Mask R-CNN, one of the deep learning techniques, to recognize and classify atypical Hangul characters. The atypical characters on the Hangul signboard have a lot of deformed and colorful shapes beyond the general characters. Therefore, in order to recognize the Hangul signboard character, it is necessary to learn a separate atypical Hangul character rather than the existing formulaic one. We selected the Hangul character '닭' as sample data and constructed 5,383 Hangul image data sets and used them for learning and verifying the deep learning model. The accuracy of the results of analyzing the performance of the learning model using the test set constructed to verify the reliability of the learning model was about 92.65% (the area detection rate). Therefore we confirmed that the proposed method is very useful for Hangul signboard character recognition, and we plan to extend it to various Hangul data."
CNN Classifier Based Energy Monitoring System for Production Tracking of Sewing Process Line,2019,"['Energy monitoring', 'sewing process', 'convolutional neural networks', 'production tracking', 'smart sensor', 'smart factory']",,"The garment industry is one of the most labor-intensive manufacturing industries, with its sewing process relying almost entirely on manual labor. Its costs highly depend on the efficiency of this production line and thus is crucial to determine the production rate in real-time for line balancing. However, current production tracking methods are costly and make it difficult for many Small and Medium-sized Enterprises (SMEs) to implement them. As a result, their reliance on manual counting of finished products is both time consuming and prone to error, leading to high manufacturing costs and inef- ficiencies. In this paper, a production tracking system that uses the sewing machines’ energy consumption data to track and count the total number of sewing tasks completed through Convolutional Neural Network (CNN) classifiers is pro- posed. This system was tested on two target sewing tasks, with a resulting maximum classification accuracy of 98.6%; all sewing tasks were detected. In the developing countries, the garment sewing industry is a very important industry, but the use of a lot of capital is very limited, such as applying expensive high technology to solve the above problem. Applied with the appropriate technology, this system is expected to be of great help to the garment industry in developing countries."
Channel Attention과 그룹 컨볼루션을 이용한 효율적인 얼굴 감정인식 CNN,2019,"['facial expression recognition', 'efficient cnn', 'group convolution', 'depth-wise separable convolution', 'channel attention', '얼굴 감정인식', '컨볼루션 신경망', '그룹 컨볼루션', '깊이별 분리 컨볼루션', '채널 어텐션']","최근 얼굴 표정에서 감정을 인식하기 위한 문제에서 컨볼루션 신경망을 이용한 연구가 활발히 진행되고 있다. 본 논문에서는 사람의 얼굴 표정에서 나타나는 감정을 인식하기 위해 사용하는 딥 컨볼루션 신경망의 모델 복잡도(Complexity) 문제점을 해결한 효율적인 컨볼루션 신경망을 제안한다. 본 논문에서는 모델의 복잡도를 줄이기 위해 그룹 컨볼루션, 깊이별 분리 컨볼루션을 사용하여 파라미터 수와 연산량을 감소시키고 특징 연결을 위한 Skip Connection과 Channel Attention을 사용하여 특징의 재사용성과 채널 정보를 강화하였다. 제안하는 모델의 학습 파라미터 개수는 0.39 M(Million), 0.41 M으로 기존 모델에 비해 4배 이상 적은 수의 파라미터를 사용하여 FER2013, RAF-single 데이터셋에서 각각 70.32%, 85.23%의 정확도를 달성하였다.","ecently, studies using the convolutional neural network have been actively conducted to recognize emotions from facial expressions. In this paper, we propose an efficient convolutional neural network that solves the model complexity problem of the deep convolutional neural network used to recognize the emotions in facial expression. To reduce the complexity of the model, we used group convolution, depth-wise separable convolution to reduce the number of parameters, and the computational cost. We also enhanced the reuse of featuRecently, studies using the convolutional neural network have been actively conducted to recognize emotions from facial expressions. In this paper, we propose an efficient convolutional neural network that solves the model complexity problem of the deep convolutional neural network used to recognize the emotions in facial expression. To reduce the complexity of the model, we used group convolution, depth-wise separable convolution to reduce the number of parameters, and the computational cost. We also enhanced the reuse of features and channel information by using Skip Connection for feature connection and Channel Attention. Our method achieved 70.32% and 85.23% accuracy on FER2013, RAF-single datasets with four times fewer parameters (0.39 Million, 0.41 Million) than the existing model.res and channel information by using Skip Connection for feature connection and Channel Attention. Our method achieved 70.32% and 85.23% accuracy on FER2013, RAF-single datasets with four times fewer parameters (0.39 Million, 0.41 Million) than the existing model."
Fast ROI Detection for Speed up in a CNN based Object Detection,2019,"['ROI detection', 'Noise', 'Image difference', 'Object detection.']",,"Fast operation of a CNN based object detection is important in many application areas. It is an efficient approach to reduce the size of an input image. However, it is difficult to find an area that includes a target object with minimal computation. This paper proposes a ROI detection method that is fast and robust to noise. The proposed method is not affected by a flicker line noise that is a kind of aliasing between camera and LED light. Fast operation is achieved by using down-sampling efficiently. The accuracy of the proposed ROI detection method is 92.5% and the operation time for a frame with a resolution of 640 x 360 is 0.388msec."
3D Depth Computation of Moving Objects Using a CNN with an Orthogonal Stereo Fisheye Camera System,2019,"['Fisheye camera', 'Depth computation', 'Orthogonal stereo matching', 'Viewpoint transformation', 'Wide angle']",,"Stereo matching of images taken by wide-angle (WA) fisheye lens cameras pose difficulties because the degree of distortion increases along the outer edge of the image. In addition, in an orthogonal stereo camera system in which adjacent WA cameras are positioned at right angles to cover 360°, the relationship between correspondence and depth information varies from that of a general-purpose parallel stereo camera system, thus requiring special mathematical modeling. In order to solve the abovementioned problems, this paper proposes an algorithm to minimize the degree of distortion by viewpoint transformation, and calculates the three-dimensional distance information of a moving object through the mathematical modeling of a fisheye stereo camera system arranged at right angles. The proposed algorithm consists of five steps. First, using the calibrated camera parameters, the viewpoints are changed so that the stereo images perpendicular to each other are viewed in parallel in the same direction. Second, by using a convolutional neural network (CNN) model, features are extracted from the viewpoint-transformed images. Third, matching between adjacent images based on the extracted features is performed. Fourth, depth information of moving objects is calculated from matching points. Finally, the computed depth information is refined for improved accuracy. Simulation results show that the depth calculated by the proposed algorithm is fairly accurate, with an average error rate of about 4%."
Autonomous-Driving Vehicle Learning Environments using Unity Real-time Engine and End-to-End CNN Approach,2019,"['Autonomous Shuttle Vehicle', 'Artificial Intelligence', 'Virtual Environment', 'Behavior Learning']",,"Collecting a rich but meaningful training data plays a key role in machine learning and deep learning researches for a self-driving vehicle. This paper introduces a detailed overview of existing open-source simulators which could be used for training self-driving vehicles. After reviewing the simulators, we propose a new effective approach to make a synthetic autonomous vehicle simulation platform suitable for learning and training artificial intelligence algorithms. Specially, we develop a synthetic simulator with various realistic situations and weather conditions which make the autonomous shuttle to learn more realistic situations and handle some unexpected events. The virtual environment is the mimics of the activity of a genuine shuttle vehicle on a physical world. Instead of doing the whole experiment of training in the real physical world, scenarios in 3D virtual worlds are made to calculate the parameters and training the model. From the simulator, the user can obtain data for the various situation and utilize it for the training purpose. Flexible options are available to choose sensors, monitor the output and implement any autonomous driving algorithm. Finally, we verify the effectiveness of the developed simulator by implementing an end-to-end CNN algorithm for training a self-driving shuttle."
Faster R-CNN을 이용한 고속도로 통행량 및 속도 추정 구현,2019,"['Deep learning', 'Object Detection', 'Vehicle Speed Estimation', 'Traffic Estimation', 'Traffic Situation Analysis']",,
공동 손실함수가 적용된 CNN 기반의 시점 변화에 강인한 걸음걸이 식별,2019,"['Gait recognition', 'gait energy image', 'convolution neural network', 'discriminative-feature learning', 'center loss']",,"Most current gait recognition approaches based on convolution neural networks (CNNs) do not learn the discriminative features of separable inter-class differences resulting from cross-view data. To improve this discriminative ability, this paper proposes a network that reduces intra-class variation using a center loss function for view-invariant gait recognition. The proposed method achieved 92% accuracy using OU-MVLP, the largest existing gait recognition dataset. Furthermore, a network trained using the OU-MVLP achieved 95% accuracy with the OU-LP . These results demonstrate that the proposed method offers a good generalization performance."
스마트 구조물 균열 감지를 위한 1차원 합성곱신경망(1D CNN) 딥러닝을 이용한 파괴 신호 특정 기법,2019,"['구조물 모니터링', '기계 학습', '1D Convolution', '진동 센서', 'Structure Health Monitoring', 'Machine Learning', '1D Convolution Network', 'Accelerometer']","초고층 빌딩, 대형 구조물 등의 건설이 일반화됨에 따라 점차 노후화 및 지진, 태풍 등의 자연재해에 의한 구조물의 손상 모니터링에 대한 필요도가 증가하고 있다. 특히, 하부구조인 구조물 기초에서의 손상은 구조물 전체의 건전도에 부정적인 영향을 미칠 수 있기 때문에, 이에 대한 감지는 매우 중요하다. 구조물 건전도 비파괴검사 방법으로는 대표적으로 음향, 진동 감지기법 등이 제안되었으며, 이에 음향, 진동 감지기에 의해 수집된 신호를 해석하여 균열의 발생 위치 및 균열의 크기, 내구도 등을 역으로 추정하는 방법에 관한 연구가 실험실 스케일에서 많이 수행되어왔다. 하지만 실제로 현장에서는 적용되는 경우가 극히 드문 데 그 이유는 평소 발생하는 노이즈 신호(정상 신호)와 손상파괴 신호(비정상 신호)를 구분하는 것이 어렵기 때문이다. 특히 노이즈 신호와 구조물 파괴 신호가 동시에 수집될 때 이를 구분하는 것은 더욱 어려워진다. 이에 본 연구에서는 노이즈 신호(정상 신호)와 손상파괴 신호(비정상 신호)를 수집하고, 무작위로 합성된 신호를 딥러닝 기법인 1D convolutional neural network model을 통해서 정상 신호와 비정상 신호를 구분하는 알고리즘을 개발하였다. 개발된 알고리즘을 사용하면 현장에서 실시간으로 수집된 신호를 구분할 수 있게 됨으로써 구조물 안전성 변화 예측을 통해 재산 및 인명 피해 위험성을 최소화할 수 있을 것으로 생각한다.","Structures can be damaged by natural disasters such as earthquakes and typhoons. In particular, any damage to the foundation of a structure can present critical problems. Therefore, a smart monitoring technique such as the acoustic emission method is required to detect internal cracks and other types of structural damage. Many laboratory studies on this method have been conducted to estimate the locations and sizes of cracks as well as the resulting changes in structural durability using collected acoustic signals. However, the method has rarely been applied in the field because identifying damage signals from acquired signals, which can contain ambient noise, is difficult. We developed a deep learning algorithm based on a one-dimensional convolutional neural network method that can identify damage or crack signals generated from concrete failure from randomly synthesized signals. Using the developed algorithm, we were able to distinguish damage signals from random ambient noise signals. This algorithm enables real-time monitoring of concrete structures, thus providing a smart monitoring strategy."
A Combined Model of Outline Feature Map and CNN for Detection of People at the Beach,2019,"['InsightCNN', '객체 인식', '특징 맵', '복잡한 영상', '외곽선', 'intelligent video surveillance system', 'object detection', 'complex image', 'outline']",,
Classification of stomach cancer gene expression data using CNN algorithm of deep learning,2019,"['gene expression data', 'deep learning', 'convolutional neural network', 'principal component analysis', 'heatmap']",,
랜섬웨어 방어를 위한 합성곱 신경망 기반의 데이터 암호화 탐지 기법,2019,"['ransomware', 'deep learning', 'convolutional neural network', 'computer security', '랜섬웨어', '딥러닝', '합성곱 신경망', '컴퓨터 보안']","최근 랜섬웨어에 의한 피해가 심각해짐에 따라, 랜섬웨어 공격을 실시간으로 감지하고 방어하는 기술 개발의 중요성이 높아지고 있다. 기존 랜섬웨어 탐지 기법의 한계를 극복하기 위해, 저장장치 내부 수준의 데이터 보존 및 복구 기법이 제안되었으나, 무분별한 데이터 보존으로 인해 저장공간 부하를 크게 증가시킬 수 있다는 한계점이 존재한다. 본 논문에서는 보존할 데이터를 정확하게 선정하면서도 피해 데이터를 온전하게 보존하기 위한, 합성곱 신경망 기반의 데이터 암호화 여부 판단 기법을 제시한다. 실험 결과, 제안한 기법은 저장장치 내부 수준에서 상위 계층의 정보 없이 93.90%의 높은 정확도로 데이터의 암호화 여부를 판단하였다. 또한, 손실 함수와 결정 경곗값을 수정하여 0에 가까운 부정 오류율을 달성하였다.","With the rapid increase in the number of ransomwares recently, the development of real-time strategies for ransomware defense is imperative. To overcome the limitations of traditional ransomware defense techniques, a storage-level data recovery technique was suggested. However, as the technique inefficiently selects data to conserve, it has a negative impact on the lifetime and performance of storage. In this paper, we propose a CNN-based encrypted data detection technique to enhance the accuracy of selecting data to conserve while ensuring complete data recovery. Our experiments show that the proposed technique achieved 93.90% detection accuracy at the storage-level without any high-level information. Furthermore, by changing the loss function and controlling a detection threshold, we attained a false negative rate of nearly 0."
컨볼루션 신경망 기반 운동심상을 이용한 뇌의 연결성 분석 및 분류방법,2019,"['brain-computer interface', 'brain connectivity', 'convolutional neural network', 'machine learning', '뇌-컴퓨터 인터페이스', '뇌 연결성', '컨볼루션 신경망', '기계학습']","뇌-컴퓨터 인터페이스 (brain-computer interface; BCI)란 뇌에서 발생한 전기신호를 인공지능 알고리즘을 통해 사용자의의도를 예측하고, 그에 따라 로봇이나 컴퓨터를 제어해주는 기술로 세계 다양한 기관에서 미래 핵심 기술로 손꼽히는기술이다. BCI는 구현하는 방법 (Slow Cortical Potentials, Sensorimotor Rhythms, P300, Steady-State Visually Evoked Potential, Directional Tuning 등)에 따라 다양한 어플리케이션에 이용되고 있다. 하지만 BCI를 실생활에 사용하기 위해서는상황에 따라 시스템을 켜거나 꺼주거나 시스템의 모드 (typing, 로봇 제어, 전동 휠체어 제어 등)를 변경해주어야 한다. 본논문에서는 일반인 피험자 10명을 대상으로 EEG (Electroencephalography)를 측정 및 분석하여 피험자의 다양한 상태(resting, speech imagery, legs-motor imagery, hands-motor imagery)를 구분해내는 알고리즘을 개발하고 그 결과 88.25%의정확도로 상태를 구분할 수 있었다. 이는 BCI 모드 변경을 위한 핵심 알고리즘으로 BCI 기술의 실용화를 앞당길 것으로기대한다.","The brain-computer interface (BCI) is a technology that predicts user’s intention through artificial intelligent algorithm and control robot or computer accordingly and is recognized as a core technology for the future by various organizations around the world. BCI is used in various applications according to the implementation method (Slow Cortical Potentials, Sensorimotor Rhythms, P300, Steady State Visually Evoked Potential, Directional Tuning, etc). However, to use BCI in real life, it is necessary to turn on/off the system according to the situation or to change the system mode (typing, robot control, electric wheelchair control, etc). In this paper, we developed an algorithm to measure various states (resting, speech imagery, legs-motor imagery, hands-motor imagery) of subjects by measuring and analyzing EEG in 10 subjects and as a result, we were able to distinguish the state with an accuracy of 88.25%. We expected that BCI technology would be put into practical use as a critical algorithm for changing BCI mode."
자연어를 활용한 SQL문 생성을 위한 합성곱 신경망 기반 칼럼 예측 모델,2019,"['SQL', 'RDBMS', 'natural language processing', 'convolutional neural networks', 'SQL', '관계형 데이터베이스', '자연어 처리', '합성곱 신경망']","관계형 데이터베이스 시스템을 이용하여 대규모의 데이터를 검색하기 위해서는 테이블 스키마 및 SQL문을 이해해야 하는 필요성이 있다. 이를 해결하기 위해 자연어가 입력으로 주어질 때, 이에 대응하는 SQL문을 생성하는 연구가 최근 진행되고 있다. 기존 연구에서 가장 어려운 부분은 SQL문의 조건에 해당되는 칼럼을 효과적으로 예측하는 부분이며, 예측해야 하는 칼럼의 개수가 여러 개일 때 정확도가 크게 떨어지는 문제점이 있다. 본 논문에서는 칼럼 어텐션 메카니즘을 이용하여, 자연어 데이터의 숨겨진 표현을 효과적으로 추출하는 합성곱 신경망 모델을 제안한다. 본 연구의 제안 방법은 기존 방법 대비 약 6% 이상 정확도가 향상되는 것을 확인할 수 있었다.","To retrieve massive data using relational database management system (RDBMS), it is important to understanding of table schemas and SQL grammar. To address this issue, many studies have recently been carried out to generate an SQL query from a natural language question. However, the existing works suffer mostly from predicting columns at where clause and the accuracy is greatly reduced when there are multiple columns to be predicted. In this paper, we propose a convolutional neural network model with column attention mechanism that effectively extracts the latent representation of input question which helps column prediction of the model. The experiment shows that our model outperforms the accuracy of the existing model (SQLNet) by 6%."
LeafNet: 합성곱 신경망을 이용한 식물체 분할,2019,"['Deep learning', 'Segmentation', 'Plant phenomics', 'Phenomics system', 'CNN', '딥 러닝', '분할', '식물 표현체', '피노믹스 시스템', '합성곱 신경망']","식물 표현체(plant phenomics) 연구는 우수한 형질의 식물 품종과 유전적 특성을 선별하기 위해 여러 식물체의 형태적 특징을 관측하고, 획득한 영상 빅데이터를 분석하는 기술이다. 기존의 방법은 검출 대상에 따라 직접 색상 임계값을 변경해야 하기 때문에 빅데이터를 다루는 정밀검정시스템에 적용하기 어렵다. 본 논문에서는 정밀검정시스템을 위한 식물체와 배경의 자동 분할이 가능한 합성곱 신경망(Convolution neural network: CNN) 구조를 제안한다. LeafNet은 9개의 컨벌루션 계층과 식물의 유무를 판단하기 위한 시그모이드(Sigmoid) 활성화 함수로 구성된다. LeafNet을 이용한 학습 결과, 식물 모종 영상에 대하여 정밀도 98.0%, 재현율 90.3%의 결과가 도출되어 정밀검정시스템의 적용 가능성을 확인하였다.",
Deep Convolutional Neural Network with Bottleneck Structure using Raw Seismic Waveform for Earthquake Classification,2019,"['Convolutional neural network', 'earthquake classification', 'bottleneck structure', 'raw seismic waveform', 'centering preprocessing']",,"In this paper, we propose deep convolutional neural network(CNN) with bottleneck structure which improves the performance of earthquake classification. In order to address all possible forms of earthquakes including micro-earthquakes and artificial-earthquakes as well as large earthquakes, we need a representation and classifier that can effectively discriminate seismic waveforms in adverse conditions. In particular, to robustly classify seismic waveforms even in low snr, a deep CNN with 1x1 convolution bottleneck structure is proposed in raw seismic waveforms. The representative experimental results show that the proposed method is effective for noisy seismic waveforms and outperforms the previous state-of-the art methods on domestic earthquake database."
설계품질 자동검토 도구를 위한 시각지능 기반 BIM 객체 인식 구현,2019,"['3D object classification', 'Building element', 'Building information modeling', 'Convolutional neural network', 'Design rule-checking']",,"This paper presents an approach and implementation of auto-classification of unclassified objects in BIM models using deep learning for design rule-checking systems. The validation of required data in BIM models is an important task while BIM applications have proved their benefits in various architecture domains. To handle the problem related to the data quality check, which tends to rely on a manual way, previous studies related to checking and validating BIM objects for ensuring data integrity of BIM instances have been proposed. As a part of the studies, this paper applies convolutional neural networks to the pre-checking of BIM models for the design rule-checking application. We have trained BIM object recognition model and developed a stand-alone application. A plug-in of the design rule-checking software has developed and demonstrated with practical rule-checking execution. It is confirmed to enable to successfully execute rule-checking by utilizing the result values of auto-classification. We expect this approach and implementation to help validation of BIM data and contribute to the practical use of not only rule-checking but also other BIM-based applications."
태양광 전력 기반의 컨벌루션 신경망 설계와 숫자 인식률 개선,2019,"['Solar Energy', 'Convolution Neural Network', 'Handwritten Numeral Images', 'Fully Connected Network', 'Feature Matching', 'Misrecognition']",,"Applications of solar power are also increasingly common. In this paper, we explained the characteristics of our new discriminator based on solar energy and CNN for number recognition. Our CNN(Convolution Neural Network) is one in deep learning models with the function of human visual perception. The neural network model carries out the image feature matching process to recognize entered digital images. Our proposed CNN structure was designed with multiple hidden layers to retrieve the features of handwritten numeral images. The CNN structure performs 2D image convolution operation to extract noise, edge and stroke information from the numeral images. These feature information from the convolution layers is served as a new input stream of FCN(Fully Connected Network) for the classification of the features. The FCN performs a classification procedure based on the protypes already deployed for numeral image matching. We used MNIST(Modified National Institute of Standards and Technology) data set to achieve objective recognition measurement. The 60,000 samples of MNIST data set were applied for the learning process of our CNN recognizer, while we used the 10,000 samples for the performance measurement of our CNN recognizer. The measurement experiments were carried out after the repeating the training process of CNN only two times. The several misrecognition results were observed in our performance test, therefore we performed the additional training step to enhance the recognition rate of our CNN. Our additional method is the distortion of our input samples. we performed serveral distortion function such as a scaling, a rotation, and an elastic. In the final measurement of CNN recognizer, we observed that the recognition rate after the applying distortion process was improved by about 98.04%."
Facial Data Visualization for Improved Deep Learning Based Emotion Recognition,2019,"['facial expression recognition', 'convolutional neural network', 'facial landmark points', 'facial geometry visualization']",,"A convolutional neural network (CNN) has been widely used in facial expression recognition (FER) because it can automatically learn discriminative appearance features from an expression image. To make full use of its discriminating capability, this paper suggests a simple but effective method for CNN based FER. Specifically, instead of an original expression image that contains facial appearance only, the expression image with facial geometry visualization is used as input to CNN. In this way, geometric and appearance features could be simultaneously learned, making CNN more discriminative for FER. A simple CNN extension is also presented in this paper, aiming to utilize geometric expression change derived from an expression image sequence. Experimental results on two public datasets (CK+ and MMI) show that CNN using facial geometry visualization clearly outperforms the conventional CNN using facial appearance only."
합성곱신경망 테스트 자료에 따른 파노라마 방사선 사진에서의 골다공증 판독의 차이,2019,"['CNN', 'Osteoporosis', 'DR panoramic radiographs', 'CR panoramic radiographs']",,"This study was conducted as part of a series of studies to introduce the Convolutional Neural Network(CNN) into the diagnostic eld of osteoporosis. The purpose of this study was to compare the results when testing Digital Radiography(DR) and Computed adiography(CR) panoramic radiographs by CNN that were trained by DR panoramic radiographs. The digital panoramic radiographs f females who visited for the purpose of diagnosis and treatment at Chonnam National University Dental Hospital were taken. Two Oral and Maxillofacial Radiologists were selected for the study to compare the panoramic radiographs with normal and osteoporosis mages. Among them, 1068 panoramic radiographs of females{Mean [± standard deviation] age: 49.19 ± 21.91 years} obtained by DR method were used for training of CNN. 200 panoramic radiographs of females{Mean [± standard deviation] age: 63.95 ± 6.45 years} btained by DR method and 202 panoramic radiographs of females{Mean [± standard deviation] age: 62.00 ± 6.86 years} obtained by R method were used for testing of CNN. When the DR panoramic radiographs were tested, the Accuracy was 92.5%. When the CR anoramic radiographs were tested, the Accuracy was 76.2%. It can be seen that the CNN trained by DR panoramic radiographs is uitable to be tested with the same DR panoramic radiographs."
Convolutional Neural Network for Monocular Vision-based Multi-target Tracking,2019,"['CNN-based multi-target detection', 'indoor quadrotor tracking', 'monocular vision', 'multi-target tracking', 'three-dimensional indoor quadrotor simulator']",,"This paper addresses multi-target tracking using a monocular vision sensor. To overcome the fundamental observability issue of the monocular vision, a convolutional neural network (CNN)-based method is proposed.The method combines a CNN-based multi-target detection into a model-based multi-target tracking framework. While previous CNN applications to image-based object recognition and tracking focused on prediction of region of interest (RoI), the proposed method allows for prediction of the three-dimensional position information of the moving objects of interest. This is achieved by appropriately construct a network tailored to the moving object tracking problems with potentially occluded objects. In addition, the cubature Kalman filter integrated with a data association scheme is adopted for effective tracking of nonlinear motion of the objects with the measurements information from the learned network. A virtual simulator that generates the trajectories of the target motions and a sequence of images of the scene has been developed and used to test and verify the proposed CNN scheme. Simulation case studies demonstrate that the proposed CNN improves the position accuracy in the depth direction substantially."
딥 뉴럴네트워크 기반의 소리 이벤트 검출,2019,"['딥 뉴럴 네트워크', '소리 이벤트 검출', '컨벌루셔널 리커런트 뉴럴 네트워크', 'Deep Neural Networks', 'Sound Event Detection', 'Convolutional Recurrent Neural Networks']","본 논문에서는 다양한 구조의 딥 뉴럴 네트워크를 소리 이벤트 검출을 위하여 적용하였으며 공통의 오디오 데이터베이스를 이용하여 그들 간의 성능을 비교 하였다. FNN, CNN, RNN 그리고 CRNN이 주어진 오디오데이터베이스 및 딥 뉴럴 네트워크의 구조에 최적화된 하이퍼파라미터 값을 이용하여 구현되었다. 구현된 방식 중에서 CRNN이 모든 테스트 환경에서 가장 좋은 성능을 보였으며 그 다음으로 CNN의 성능이 우수함을 알 수 있었다. RNN은 오디오 신호에서의 시간 상관관계를 잘 추적하는 장점에도 불구하고 CNN 과 CRNN에 비해서 저조한 성능을 보임을 확인 할 수 있었다.","In this paper, various architectures of deep neural networks were applied for sound event detection and their performances were compared using a common audio database. FNN, CNN, RNN and CRNN were implemented using hyper-parameters optimized for the database as well as the architecture of each neural network. Among the implemented deep neural networks, CRNN performed best at all testing conditions and CNN followed CRNN in performance. Although RNN has a merit in tracking the time-correlations in audio signals, it showed poor performance compared with CNN and CRNN."
합성곱 신경망을 이용한 아스팔트 콘크리트 도로포장 표면균열 검출,2019,"['딥러닝', '합성곱 신경망', '아스팔트 도로포장', '아스팔트 도로포장 표면균열', 'Deep learning', 'Convolutional Neural Network', 'Asphalt Pavement', 'Surface Crack']","본 연구에서는 아스팔트 콘크리트 도로포장의 표면균열 검출을 위해 합성곱 신경망을 이용하였다. 합성곱 신경망의 학습에 사용되는 표면균열 이미지 데이터의 양에 따른 합성곱 신경망의 성능향상 정도를 평가하였다. 사용된 합성곱 신경망의 구조는 5개의 층으로 구성되어있으며, 3x3 크기의 convolution filter와 2x2 크기의 pooling kernel을 사용하였다. 합성곱 신경망의 학습을 위해서 도로노면 조사 장비를 통해 구축된 국내 도로포장 표면균열 이미지를 활용하였다. 표면균열 이미지 데이터를 학습한 합성곱 신경망 모델의 표면균열 검출 정확도, 정밀도, 재현율, 미검출율, 과검출율을 평가하였다. 가장 많은 양의 데이터를 학습한 합성곱 신경망 모델의 표면균열 검출 정확도, 정밀도, 재현율은 96.6% 이상, 미검출율, 과검출율은 3.4% 이하의 성능을 나타내었다.","A Convolution Neural Network(CNN) model was utilized to detect surface cracks in asphalt concrete pavements. The CNN used for this study consists of five layers with 3x3 convolution filter and 2x2 pooling kernel. Pavement surface crack images collected by automated road surveying equipment was used for the training and testing of the CNN. The performance of the CNN was evaluated using the accuracy, precision, recall, missing rate, and over rate of the surface crack detection. The CNN trained with the largest amount of data shows more than 96.6% of the accuracy, precision, and recall as well as less than 3.4% of the missing rate and the over rate."
딥 러닝 및 칼만 필터를 이용한 객체 추적 방법,2019,"['YOLO', 'Kalman filter', 'Object tracking', 'CNN', 'Deep learning']","딥 러닝의 대표 알고리즘에는 영상 인식에 주로 사용되는 CNN(Convolutional Neural Networks), 음성인식 및 자연어 처리에 주로 사용되는 RNN(Recurrent Neural Networks) 등이 있다. 이 중 CNN은 데이터로부터 자동으로 특징을 학습하는 알고리즘으로 특징 맵을 생성하는 필터까지 학습할 수 있어 영상 인식 분야에서 우수한 성능을 보이면서 주류를 이루게 되었다. 이후, 객체 탐지 분야에서는 CNN의 성능을 향상하고자 R-CNN 등 다양한 알고리즘이 등장하였으며, 최근에는 검출 속도 향상을 위해 YOLO(You Only Look Once), SSD(Single Shot Multi-box Detector) 등의 알고리즘이 제안되고 있다. 하지만 이러한 딥러닝 기반 탐지 네트워크는 정지 영상에서 탐지의 성공 여부를 결정하기 때문에 동영상에서의 안정적인 객체 추적 및 탐지를 위해서는 별도의 추적 기능이 필요하다. 따라서 본 논문에서는 동영상에서의 객체 추적 및 탐지 성능 향상을 위해 딥 러닝 기반 탐지 네트워크에 칼만 필터를 결합한 방법을 제안한다. 탐지 네트워크는 실시간 처리가 가능한 YOLO v2를 이용하였으며, 실험 결과 제안한 방법은 기존 YOLO v2 네트워크에 비교하여 7.7%의 IoU 성능 향상 결과를 보였고 FHD 영상에서 20 fps의 처리 속도를 보였다.",
PMU 빅데이터를 활용한 계통고장분류 모델 개발,2019,"['WAMS', 'PMU', 'Big-Data', 'CNN', 'Fault Classification']",,"Recently, innovative techniques in artificial intelligence such as machine learning have emerged to efficiently process huge amounts of big data delivered from PMUs to WAMS. Through processing raw data and analyzing big data, It delivers highly useful and valuable system status information to system operators. The types of machine learning vary depending on the usage, but the CNN (Convolution Neural Network) model is mainly used for the post analysis and fault detection(classification) in the power system. In this paper, based on PMU big data, we study the power system fault classification model by using CNN Model. Using Convolution neural network model based on KERAS, the database for each fault type was built and supervised learning was conducted for the model. The constructed model was verified with test data and the validity of the model was verified by inputting the actual power system fault data for the trained model. As a result, developed model classified correctly for the actual fault."
Convolutional Neural Network-Based Multi-Target Detection and Recognition Method for Unmanned Airborne Surveillance Systems,2019,"['Convolutional neural network (CNN)', 'Multi-target detection and recognition', 'Unmanned airborne surveillance', 'Bearing angle', 'Airborne surveillance neural network (ASNet)']",,"This paper proposes the convolutional neural network (CNN)-based multiple targets detection and recognition method for unmanned airborne surveillance systems. The proposed method is capable of recognizing the target’s type, position and bearing angle. Recently, deep learning approaches using convolutional neural networks (CNNs) have significantly improved the object detection accuracy on benchmark datasets such as Pascal visual object classes (VOC) and common objects in context (COCO) data sets. Typical CNN-based object detection technologies are designed to recognize regions of interest (RoI) and object classes based on VOC or COCO data set criteria only. However, in many surveillance missions, the bearing angle of the object is also an important entity to infer in addition to the RoI and the vehicle-type. This paper proposes a CNN-based object recognition technique called airborne surveillance neural network (ASNet) that can recognize this additional bearing angle information. Indoor experiments demonstrate the validity of the proposed method."
CT Image Conversion among Different Reconstruction Kernels without a Sinogram by Using a Convolutional Neural Network,2019,"['Multidetector computed tomography', 'Image reconstruction', 'Machine learning', 'Emphysema', 'CNN']",,"Objective: The aim of our study was to develop and validate a convolutional neural network (CNN) architecture to convert CT images reconstructed with one kernel to images with different reconstruction kernels without using a sinogram.Materials and Methods: This retrospective study was approved by the Institutional Review Board. Ten chest CT scans were performed and reconstructed with the B10f, B30f, B50f, and B70f kernels. The dataset was divided into six, two, and two examinations for training, validation, and testing, respectively. We constructed a CNN architecture consisting of six convolutional layers, each with a 3 x 3 kernel with 64 filter banks. Quantitative performance was evaluated using root mean square error (RMSE) values. To validate clinical use, image conversion was conducted on 30 additional chest CT scans reconstructed with the B30f and B50f kernels. The influence of image conversion on emphysema quantification was assessed with Bland–Altman plots.Results: Our scheme rapidly generated conversion results at the rate of 0.065 s/slice. Substantial reduction in RMSE was observed in the converted images in comparison with the original images with different kernels (mean reduction, 65.7%; range, 29.5–82.2%). The mean emphysema indices for B30f, B50f, converted B30f, and converted B50f were 5.4 ± 7.2%, 15.3 ± 7.2%, 5.9 ± 7.3%, and 16.8 ± 7.5%, respectively. The 95% limits of agreement between B30f and other kernels (B50f and converted B30f) ranged from -14.1% to -2.6% (mean, -8.3%) and -2.3% to 0.7% (mean, -0.8%), respectively.Conclusion: CNN-based CT kernel conversion shows adequate performance with high accuracy and speed, indicating its potential clinical use."
합성곱 신경망 기반의 딥러닝에 의한 수치표면모델의 객체분류,2019,"['합성곱 신경망', '딥러닝 모델', '학습 및 검증 데이터', '수치표면모델 분류', 'CNN', 'DL Model', 'Training and Validation Data', 'DSM Classification']","최근 딥러닝(DL)은 여러 분야에서 급속도로 활용되고 있으며, 특히 영상으로부터 객체를 인식하여 분류하고 인식하기 위한 컴퓨터비전 분야에서 활발하게 연구가 진행되고 있다. 영상분야에서는 주로 합성곱 신경망(CNN)을 이용한 딥러닝 모델의 성능 향상에 주력하고 있다. 대부분의 합성곱 신경망은 영상을 학습시켜 영상분류 및 객체인식에 활용하고 있지만, 본 논문에서는 독일 사진측량, 원격탐사 및 공간정보학회(DGPF)가 구축하고 국제 사진측량 및 원격탐사학회(ISPRS)가 제공하는 데이터 셋 중에서 수치표면모델(DSM)과 이 데이터로부터 생성한 경사 및 주향 정보를 효율성과 성능이 우수하다고 평가받는 합성곱 신경망기반의 SegNet 모델에 적용하여 객체를 분류하고 분석하였다. 딥러닝은 고사양의 컴퓨터 시스템과 다량의 학습 데이터와 라벨 데이터가 필요하고, 다수의 시행착오에 의한 풍부한 경험이 요구된다. 또한 본 논문에서는 한정된 수량의 데이터로부터 효율적인 학습을 위한 데이터 생성 방법을 제시하고 수치표면모델을 분류하였다. 분석 결과 수치표면모델 데이터와 이로부터 도출한 부가적인 데이터를 딥러닝 모델에 적용해도 객체를 타당한 정확도로 분류할 수 있음을 확인하였다.","Recently, DL (Deep Learning) has been rapidly applied in various fields. In particular, classification and object recognition from images are major tasks in computer vision. Most of the DL utilizing imagery is primarily based on the CNN (Convolutional Neural Network) and improving performance of the DL model is main issue. While most CNNs are involve with images for training data, this paper aims to classify and recognize objects using DSM (Digital Surface Model), and slope and aspect information derived from the DSM instead of images. The DSM data sets used in the experiment were established by DGPF (German Society for Photogrammetry, Remote Sensing and Geoinformatics) and provided by ISPRS (International Society for Photogrammetry and Remote Sensing). The CNN-based SegNet model, that is evaluated as having excellent efficiency and performance, was used to train the data sets. In addition, this paper proposed a scheme for training data generation efficiently from the limited number of data. The results demonstrated DSM and derived data could be feasible for semantic classification with desirable accuracy using DL."
랜섬웨어 방지를 위한 딥러닝 기반의 사용자 비정상 행위 탐지 성능 평가,2019,"['Abnomal behavior detection', 'Anomaly Detection', 'Ransomware', 'Deep Learning', 'Performance Comparison', 'CNN-LSTM', '비정상 행위 탐지', '이상 징후 탐지', '랜섬웨어', '딥러닝', '성능 비교', 'CNN-LSTM']",,"With the development of IT technology, computer-related crimes are rapidly increasing, and in recent years, the damage to ransomware infections is increasing rapidly at home and abroad. Conventional security solutions are not sufficient to prevent ransomware infections, and to prevent threats such as malware and ransomware that are evolving, a combination of deep learning technologies is needed to detect abnormal behavior and abnormal symptoms. In this paper, a method is proposed to detect user abnormal behavior using CNN-LSTM model and various deep learning models. Among the proposed models, CNN-LSTM model detects user abnormal behavior with 99% accuracy."
Deep Learning Algorithm for Reducing CT Slice Thickness: Effect on Reproducibility of Radiomic Features in Lung Cancer,2019,"['Computed tomography', 'Radiomics', 'Slice thickness', 'Deep learning']",,"Objective: To retrospectively assess the effect of CT slice thickness on the reproducibility of radiomic features (RFs) of lung cancer, and to investigate whether convolutional neural network (CNN)-based super-resolution (SR) algorithms can improve the reproducibility of RFs obtained from images with different slice thicknesses. Materials and Methods: CT images with 1-, 3-, and 5-mm slice thicknesses obtained from 100 pathologically proven lung cancers between July 2017 and December 2017 were evaluated. CNN-based SR algorithms using residual learning were developed to convert thick-slice images into 1-mm slices. Lung cancers were semi-automatically segmented and a total of 702 RFs (tumor intensity, texture, and wavelet features) were extracted from 1-, 3-, and 5-mm slices, as well as the 1-mm slices generated from the 3- and 5-mm images. The stabilities of the RFs were evaluated using concordance correlation coefficients (CCCs). Results: The mean CCCs for the comparisons of original 1 mm vs. 3 mm, 1 mm vs. 5 mm, and 3 mm vs. 5 mm images were 0.41, 0.27, and 0.65, respectively (p < 0.001 for all comparisons). Tumor intensity features showed the best reproducibility while wavelets showed the lowest reproducibility. The majority of RFs failed to achieve reproducibility (CCC ≥ 0.85; 3.6%, 1.0%, and 21.5%, respectively). After applying the CNN-based SR algorithms, the reproducibility significantly improved in all three pairings (mean CCCs: 0.58, 0.45, and 0.72; p < 0.001 for all comparisons). The reproducible RFs also increased (36.3%, 17.4%, and 36.9%, respectively). Conclusion: The reproducibility of RFs in lung cancer is significantly influenced by CT slice thickness, which can be improved by the CNN-based SR algorithms."
전역특징과 국소특징 기반 심층학습에 의한 질감영상의 분류,2019,"['Texture classification', 'Feature extraction', 'Dominant neighborhood structure(DNS)', 'Global neighborhood structure(GNS)', 'Deep learning', '질감분류', '특징추출', '지배적 이웃구조', '전역 이웃구조', '국소이진패턴', '심층학습']","본 논문에서는 전역특징과 국소특징을 조합한 심층학습에 기반을 둔 질감영상의 분류기법을 제안한다. 여기서 전역특징은비국소적이며 잡음에 강건한 Dominant neighborhood structure(DNS) 지도를 이용한 Global neighborhood structure(GNS) 지도로부터 추출되며, 국소특징은 국부적인 구조를 효과적으로 요약하는 비모수적 서술자인 Local binary pattern(LBP)에의해 추출된다. 추출된 전역특징과 국소특징을 선형적으로 조합하여 Convolutional neural network(CNN)으로 심층학습을수행함으로써 질감영상을 분류한다. 제안된 기법의 성능을 확인하기 위하여 9종의 임의의 크기를 가지는 질감영상을대상으로 실험한 결과, 특징을 이용하지 않는 CNN의 심층학습에 의한 기법보다 우수한 분류성능이 있음을 확인하였다. 또한전역특징과 국소특징을 조합한 제안방법이 어느 하나의 특징만을 이용한 기법보다도 상대적으로 우수한 분류성능도 있음을알 수 있다.","In this paper, we propose a texture classification method based on deep learning using both global features and local features. The global features are extracted from the global neighborhood structure(GNS) map by dominant neighborhood structure(DNS) maps which are non-local and robust to noise. And the local features are also extracted by local binary pattern(LBP) which is a non-parametric descriptor that effectively summarizes local structures of images. Texture images are classified by performing deep learning with convolutional neural network(CNN) by linearly combining extracted global features and local features. In order to verify the performance of the proposed technique, we experimented with texture images with arbitrary sizes of 9 types and found that it has better classification performance than deep learning with CNN which does not use features. Also, it can be seen that the proposed method has relatively better classification performance than the method using only one feature."
Facile synthesis of Br-doped g-C3N4 nanosheets via one-step exfoliation using ammonium bromide for photodegradation of oxytetracycline antibiotics,2019,['Photocatalyst g-C3N4 Nanosheets Antibiotics Exfoliation Ammonium salts'],,"Graphitic carbon nitride (g-C3N4) was suggested since it enables the oxidation process under visible lightirradiation. To enhance the photocatalytic activity of g-C3N4 (BCN) it is essential to exfoliate bulk g-C3N4to the nanosheets form via a one-step exfoliation method, which was used to prepare g-C3N4 nanosheetswith Br (CNN-Br) or Cl (CNN-Cl) doping by using melamine and ammonium salts. Thefinal productionyield reached 52% and the specific volume of CNN-Br was eight times compared to BCN. The Cl and Brdoping of g-C3N4 was changed to increase the light absorbance in the visible-light region and to slightlydecrease the bandgap energy of the samples. Additionally, the photocurrent densities of the CNN sampleswere enhanced compared with that of BCN. We evaluated the photocatalytic performance of theresultant nanosheets for the photodegradation of oxytetracycline under visible-light irradiation. Theresults showed that the Br or Cl doping of g-C3N4 and the nanosheet structure had synergetic effects,namely enhancing the absorbance in the visible-light region, the efficiency of photoinduced chargecarriers, and the charge-separation capability. These improvements are useful for the photocatalyticdegradation of antibiotics."
Convolutional Neural Network with Expert Knowledge for Hyperspectral Remote Sensing Imagery Classification,2019,"['Hyperspectral imagery classification', 'convolutional neural network', 'principal component analysis', 'gray-level co-occurrence matrix', 'differential Mathematical morphology']",,"The recent interest in artificial intelligence and machine learning has partly contributed to an interest in the use of such approaches for hyperspectral remote sensing (HRS) imagery classification, as evidenced by the increasing number of deep framework with deep convolutional neural networks (CNN) structures proposed in the literature. In these approaches, the assumption of obtaining high quality deep features by using CNN is not always easy and efficient because of the complex data distribution and the limited sample size. In this paper, conventional handcrafted learning-based multi features based on expert knowledge are introduced as the input of a special designed CNN to improve the pixel description and classification performance of HRS imagery. The introduction of these handcrafted features can reduce the complexity of the original HRS data and reduce the sample requirements by eliminating redundant information and improving the starting point of deep feature training. It also provides some concise and effective features that are not readily available from direct training with CNN. Evaluations using three public HRS datasets demonstrate the utility of our proposed method in HRS classification."
A Recommendation Model based on Character-level Deep Convolution Neural Network,2019,[],"추천 시스템의 등급 예측 정확도를 높이기 위해서는, 사용자 항목 등급 데이터뿐만 아니라 주석, 태그 또는 설명과 같은 항목의 보조 정보도 고려해야만 한다. 기존 접근법에서는 단어 단위에서 bag-of-words 모델을 사용하여 보조 정보를 모델링한다. 그러나 이러한 모델은 보조 정보를 효과적으로 활용할 수 없으므로 보조 정보를 제한적으로 이해하게 된다. 한편, 컨볼루션 신경망(CNN)에서는 보조 정보로부터 특징 벡터를 효과적으로 포착하고 추출할 수 있다. 따라서 본 논문에서는 새로운 추천 모델을 위해 딥 CNN을 행렬 분해에 통합시킨 문자 수준의 딥 컨볼루션 신경망 기반 행렬 분해 (Char-DCNN-MF) 방법을 제안한다. Char-DCNN-MF에서는 보조 정보를 더 심층적으로 이해하고 추천 성능을 더욱 향상시킬 수 있다. 실험은 세 가지 다른 실제 데이터 세트에서 수행되었으며 그 결과는 Char-DCNN-MF가 다른 비교 모델보다 유의적으로 뛰어난 성능을 보여주었다.","In order to improve the accuracy of the rating prediction of the recommendation model, not only user-item rating data are used but also consider auxiliary information of item such as comments, tags, or descriptions. The traditional approaches use a word-level model of the bag-of-words for the auxiliary information. This model, however, cannot utilize the auxiliary information effectively, which leads to shallow understanding of auxiliary information. Convolution neural network (CNN) can capture and extract feature vector from auxiliary information effectively. Thus, this paper proposes character-level deep-Convolution Neural Network based matrix factorization (Char-DCNN-MF) that integrates deep CNN into matrix factorization for a novel recommendation model. Char-DCNN-MF can deeper understand auxiliary information and further enhance recommendation performance. Experiments are performed on three different real data sets, and the results show that Char-DCNN-MF performs significantly better than other comparative models."
딥러닝을 이용한 WTCI 설태량 평가를 위한 유효성 검증,2019,"['설진', 'WTCI', '설태량', '딥러닝', '콘볼루션 뉴럴 네트워크', 'Tongue Diagnosis', 'WTCI', 'the amount of Tongue Coating', 'Deep Learning', 'Convolutional Neural Network']","한방 설진에서 WTCI(Winkel Tongue Coating Index) 설태 평가는 환자의 설태량 측정을 위한 중요한 객관적인 지표 중의 하나이다. 그러나 이전의 WTCI 설태 평가는 혀영상으로부터 설태 부분을 추출하여 전체 혀 영역에서 추출된 설태 영역의 비율을 정량적으로 측정하는 방법이 대부분으로 혀영상의 촬영 조건이나 설태 인식 성능에 의해서 비객관적 측정의 문제점이 있었다. 따라서 본 논문에서는 빅데이터를 기반으로 하는 인공지능의 딥러닝 방법을 적용하여 설태량을 분류하여 평가하는 딥러닝 기반의 WTCI 평가 방법을 제안하고 검증한다. 설태 평가 방법에 있어서 딥러닝의 유효성 검증을 위해서는 CNN을 학습 모델로 사용하여 소태, 박태, 후태의 3가지 유형의 설태량을 분류한다. 설태 샘플 영상을 학습 및 검증 데이터로 구축하여 CNN 기반의 딥러닝 모델로 학습한 결과 96.7%의 설태량 분류 정확성을 보였다.","A WTCI is an important criteria for evaluating an mount of patient’s tongue coating in tongue diagnosis. However, Previous WTCI tongue coating evaluation methods is a most of quantitatively measuring ration of the extracted tongue coating region and tongue body region, which has a non-objective measurement problem occurring by exposure conditions of tongue image or the recognition performance of tongue coating. Therefore, a WTCI based on deep learning is proposed for classifying an amount of tonger coating in this paper. This is applying the AI deep learning method using big data. to WTCI for evaluating an amount of tonger coating. In order to verify the effectiveness performance of the deep learning in tongue coating evaluating method, we classify the 3 types class(no coating, some coating, intense coating) of an amount of tongue coating by using CNN model. As a results by testing a building the tongue coating sample images for learning and verification of CNN model, proposed method is showed 96.7% with respect to the accuracy of classifying an amount of tongue coating."
압축 영상 화질 개선을 위한 딥 러닝 연구에 대한 분석,2019,"['CNN', 'HEVC', 'Noise Reduction', 'Quality Enhancement']","최근 CNN (Convolutional Neural Network) 기반의 화질 개선 기술이 H.265/HEVC와 같은 블록 기반 영상 압축 표준을 사용하여 압축된 영상의 화질을 향상시키는 데 적극적으로 사용되어 왔다. 이 논문은 이러한 영상 압축 기술을 위한 화질 개선 연구의 추세를 요약하고 분석하는 것을 목표로 한다. 먼저, 화질 개선을 위한 CNN의 구성 요소를 살펴보고 이미지 도메인에서의 사전 연구를 요약한다. 다음으로 네트워크 구조, 데이터셋 및 학습 방법의 세 가지 측면에서 관련 연구들을 정리하고 성능 비교를 위한 구현 및 실험 결과를 제시하고자 한다.",
A Deep Approach for Classifying Artistic Media from Artworks,2019,"['CNN', 'VGGNet', 'classification', 'artistic media', 'artwork']",,"We present a deep CNN-based approach for classifying artistic media from artwork images. We aim to classify most frequently used artistic media including oilpaint brush, watercolor brush, pencil and pastel, etc. For this purpose, we extend VGGNet, one of the most widely used CNN structure, by substituting its last layer with a fully convolutional layer, which reveals class activation map (CAM), the region of classification. We build two artwork image datasets: YMSet that collects more than 4K artwork images for four most frequently used artistic media from various internet websites and WikiSet that collects almost 9K artwork images for ten most frequently used media from WikiArt. We execute a human baseline experiment to compare the classification performance. Through our experiments, we conclude that our classifier is superior in classifying artistic media to human."
SSD 알고리즘 기반 MI-FL을 적용한 회전 불변의 다중 객체 검출 시스템 구현,2019,"['object detection', 'CNN', 'SSD', 'moment invariant']",,"Recently, object detection technology based on CNN has been actively studied. Object detection technology is used as an important technology in autonomous vehicles, intelligent image analysis, and so on. In this paper, we propose a rotation change robust object detection system by applying MI-FL (Moment Invariant-Feature Layer) to SSD (Single Shot Multibox Detector) which is one of CNN-based object detectors. First, the features of the input image are extracted based on the VGG network. Then, a total of six feature layers are applied to generate bounding boxes by predicting the location and type of object. We then use the NMS algorithm to get the bounding box that is the most likely object. Once an object bounding box has been determined, the invariant moment feature of the corresponding region is extracted using MI-FL, and stored and learned in advance. In the detection process, it is possible to detect the rotated image more robust than the conventional method by using the previously stored moment invariant feature information. The performance improvement of about 4 ~ 5% was confirmed by comparing SSD with existing SSD and MI-FL."
딥러닝 개념을 위한 인공지능 교육 프로그램,2019,"['Artificial Intelligence', 'Machine Learning', 'Deep Learning', 'CNN', 'SW education', '인공지능', '기계학습', '딥러닝 교육', '컨볼루션네트워크', '소프트웨어교육']","본 연구의 목적은 초등학생을 대상으로 한 딥러닝 개념 학습을 위한 교육 프로그램을 개발하는 것이다. 먼저 문헌연구와 선행연구를 토대로 전문가 그룹 토의를 진행하여 프로그램 개발 방향을 위한 준거를 세웠다. 프로그램의 모델은 CT요소 중심 모델을 토대로 딥러닝 교수학습모델을 개발하였다. 개발한 프로그램의 주제는 인공지능의 이미지인식 CNN알고리즘으로 정하고, 9개 차시 교육프로그램을 개발하였다. 프로그램은 6학년을 대상으로 2주간에 걸쳐 적용을 하였다. 프로그램에 대한 학습 적합도 검사는 전문가들의 타당도와 학습자 만족도 설문 검사를 통해 분석하였다. 전문가 타당도 분석 결과 최소 CVR값이 .56이상을 넘어 타당하게 나왔다. 학습자 수준 적합도와 교사 지도 수준의 적합도 문항의 경우 .80이하로 나타났으며 .96이 넘은 학습 환경과 매체의 적합도 문항에서는 높게 나타났다. 낯선 소재로 인해 교사들이 어려워하기는 하지만 기존 SW 교육에서 실시했던 언플러그드 CS 활용의 접근법을 통해 수업의 적용이 가능함을 보여주고 있음을 알 수 있었다. 학생들의 만족도 분석 결과 학습자들의 참여는 적극적으로 하였음을 알 수 있었고, 인공지능 학습의 이해도와 유익성, 흥미도, 학습자료 등에 대해서 평균 4.0이상을 보여 긍정적인 평가를 하였다. 이에 본 프로그램은 초등학교 현장에서의 인공지능 교수학습자료의 토대를 제공할 수 있음을 알 수 있다.","The purpose of this study is to develop an educational program for learning deep learning concepts for elementary school students. First of all, based on literature and previous research, a group of experts was discussed to establish the criteria for the direction of program development. The model of education program was developed the deep-learning teaching method based on CT element-oriented teaching and learning model. The subject of the developed program is the artificial intelligence image recognition CNN algorithm, and we have developed 9 educational programs.  We applied the program over six weeks to sixth graders. he test of learning suitability for the education program was analyzed through the validity of the experts and the survey on the satisfaction of learners. Expert validity analysis showed that the minimum CVR value was more than .56. The fitness level of learner level and the level of teacher guidance were less than .80, and the fitness of learning environment and media above .96 was high. Although it is difficult for teachers due to the unfamiliar material of artificial intelligence, it can be seen that the class can be applied through the approach of using the unplugged CS that was implemented in the existing SW education. The students' satisfaction analysis showed that the learners actively participated in the class. Students gave a positive evaluation of the average of 4.0 or higher on the understanding, benefit, interest, and learning materials of artificial intelligence learning. Therefore, it can be seen that the educational program developed in this study can provide a foundation for artificial intelligence teaching and learning materials in elementary school."
다중 CCTV 사물인터넷 환경에서의 객체 추적 기법,2019,"['물리 보안', '인공지능', '씨앤앤알고리즘', '객체 검출', '씨씨티비', 'Physical security', 'artificial intelligence', 'CNN algorithm', 'object detection', 'CCTV']",본 연구는 최근 전국적으로 계속해서 사물인터넷 CCTV의 설치 대수가 증가함에 따라 CCTV의 활용범위를넓히고자 CCTV를 통하여 범죄 의심자 또는 이상 행동자를 추적하는 방법을 제안한다. 이상 행동 구분은 기존에 나와있던 연구들을 활용하여 범죄 의심자 또는 이상 행동자를 색출해내고 CNN을 활용하여 대상을 객체와 하여 추적을하고 주변 CCTV를 서로 네트워크로 연결하여 객체화된 대상의 이동 경로를 예측해 해당 경로 근방의 CCTV들에객체의 샘플 데이터를 공유하여 대상 판별 및 해당 대상을 추적하는 방식을 이용하였다. 해당 연구를 통하여 추적하기 힘든 범죄자의 위치를 추적하여 국가 치안에 기여하고 더욱 다양한 기술들이 CCTV에 접목될 수 있도록 지속적인연구가 필요하다.,"This study suggests a methodology to track crime suspects or anomalies through CCTV in order to expand the scope of CCTV use as the number of CCTV installations continues to increase nationwide in recent years. For the abnormal behavior classification, we use the existing studies to find out suspected criminals or abnormal actors, use CNN to track objects, and connect the surrounding CCTVs to each other to predict the movement path of objectified objects CCTVs in the vicinity of the path were used to share objects' sample data to track objects and to track objects. Through this research, we will keep track of criminals who can not be traced, contribute to the national security, and continue to study them so that more diverse technologies can be applied to CCTV."
Visual Speech Recognition of Korean Words Using Convolutional Neural Network,2019,"['Convolutional neural network', 'Human–robot interaction', 'Korean word recognition', 'Viola–Jones algorithm', 'Visual speech recognition']",,"In recent studies, speech recognition performance is greatly improved by using HMM and CNN. HMM is studying statistical modeling of voice to construct an acoustic model and to reduce the error rate by predicting voice through image of mouth region using CNN. In this paper, we propose visual speech recognition (VSR) using lip images. To implement VSR, we repeatedly recorded three subjects speaking 53 words chosen from an emergency medical service vocabulary book. To extract images of consonants, vowels, and final consonants in the recorded video, audio signals were used. The Viola–Jones algorithm was used for lip tracking on the extracted images. The lip tracking images were grouped and then classified using CNNs. To classify the components of a syllable including consonants, vowels, and final consonants, the structure of the CNN used VGG-s and modified LeNet-5, which has more layers. All syllable components were classified, and then the word was found by the Euclidean distance. From this experiment, a classification rate of 72.327% using 318 total testing words was obtained when VGG-s was used. When LeNet-5 applied this classifier for words, however, the classification rate was 22.327%."
시간에 따라 변화하는 빗줄기 장면을 이용한 딥러닝 기반 비지도 학습 빗줄기 제거 기법,2019,"['Rain Streak Removal', 'Unsupervised Learning', 'Convolutional Neural Networks', 'Siamese Network']",,"Single image rain removal is a typical inverse problem which decomposes the image into a background scene and a rain streak. Recent works have witnessed a substantial progress on the task due to the development of convolutional neural network (CNN). However, existing CNN-based approaches train the network with synthetically generated training examples. These data tend to make the network bias to the synthetic scenes. In this paper, we present an unsupervised framework for removing rain streaks from real-world rainy images. We focus on the natural phenomena that static rainy scenes capture a common background but different rain streak. From this observation, we train siamese network with the real rain image pairs, which outputs identical backgrounds from the pairs. To train our network, a real rainy dataset is constructed via web-crawling. We show that our unsupervised framework outperforms the recent CNN-based approaches, which are trained by supervised manner. Experimental results demonstrate that the effectiveness of our framework on both synthetic and real-world datasets, showing improved performance over previous approaches."
데이터 증강을 통한 딥러닝 기반 주가 패턴 예측 정확도 향상 방안,2019,"['Stock Price Pattern', 'Deep Learning', 'Convolutional Neural Network', 'Data Augmentation', 'Gaussian Noise', '주가 패턴', '딥러닝', '컨볼루셔널 뉴럴 네트워크', '데이터 증강', '가우시안 노이즈']","인공지능 기술이 발전하면서 이미지, 음성, 텍스트 등 다양한 분야에 적용되고 있으며, 데이터가 충분한 경우 기존 기법들에 비해 좋은 결과를 보인다. 주식시장은 경제, 정치와 같은 많은 변수에 의해 영향을 받기 때문에, 주식 가격의 움직임 예측은 어려운 과제로 알려져 있다. 다양한 기계학습 기법과 인공지능 기법을 이용하여 주가 패턴을 연구하여 주가의 등락을 예측하려는 시도가 있어왔다. 본 연구는 딥러닝 기법 중 컨볼루셔널 뉴럴 네트워크(CNN)를 기반으로 주가 패턴 예측률 향상을 위한 데이터 증강 방안을 제안한다. CNN은 컨볼루셔널 계층을 통해 이미지에서 특징을 추출하여 뉴럴 네트워크를 이용하여 이미지를 분류한다. 따라서, 본 연구는 주식 데이터를 캔들스틱 차트 이미지로 만들어 CNN을 통해 패턴을 예측하고 분류하고자 한다. 딥러닝은 다량의 데이터가 필요하기에, 주식 차트 이미지에 다양한 데이터 증강(Data Augmentation) 방안을 적용하여 분류 정확도를 향상 시키는 방법을 제안한다. 데이터 증강 방안으로는 차트를 랜덤하게 변경하는 방안과 차트에 가우시안 노이즈를 적용하여 추가 데이터를 생성하였으며, 추가 생성된 데이터를 활용하여 학습하고 테스트 집합에 대한 분류 정확도를 비교하였다. 랜덤하게 차트를 변경하여 데이터를 증강시킨 경우의 분류 정확도는 79.92%였고, 가우시안 노이즈를 적용하여 생성된 데이터를 가지고 학습한 경우의 분류 정확도는 80.98%이었다. 주가의 다음날 상승/하락으로 분류하는 경우에는 60분 단위 캔들 차트가 82.60%의 정확도를 기록하였다.",
유도 전동기의 속도 및 부하 조건을 고려한 딥러닝 고장 진단 알고리즘 개발에 관한 연구,2019,"['Deep learning', 'Motor fault diagnosis', 'CNN', 'Data analysis', 'Induction motor', 'FFT', 'Frequency domain']",,"The motor mechanical fault has been diagnosed under fixed driving conditions. The induction motor speed is affected not only by the input frequency but also by the load. In addition, the vibration generated by the induction motor is affected by the speed as well as the input frequency. For these reasons, a data preprocessing algorithm has been developed that shifts the measured data in the frequency domain based on motor speed. The algorithm also takes the input frequency as an input variable and removes the vibration component by the power source frequency. The data processed by the above procedure are classified through the deep learning algorithm based on CNN. As a result, a fault diagnosis system that can be applied to the industrial field has been developed by considering the motor driving conditions using the proposed algorithms."
심층신경망 구조에 따른 구개인두부전증 환자 음성 인식 향상 연구,2019,[],,"This paper proposes speech recognition systems employing Convolutional Neural Network (CNN) and Long Short Term Memory (LSTM) structures combined with Hidden Markov Moldel (HMM) to effectively recognize the speech of VeloPharyngeal Insufficiency (VPI) patients, and compares the recognition performance of the systems to the Gaussian Mixture Model (GMM-HMM) and fully-connected Deep Neural Network (DNNHMM) based speech recognition systems. In this paper, the initial model is trained using normal speakers' speech and simulated VPI speech is used for generating a prior model for speaker adaptation. For VPI speaker adaptation, selected layers are trained in the CNN-HMM based model, and dropout regulatory technique is applied in the LSTM-HMM based model, showing 3.68 % improvement in recognition accuracy. The experimental results demonstrate that the proposed LSTM-HMM-based speech recognition system is effective for VPI speech with small-sized speech data, compared to conventional GMM-HMM and fully-connected DNN-HMM system."
몬테칼로 렌더링 노이즈 제거를 위한 듀얼 신경망 구조 설계,2019,"['Ray Tracing', 'Denoising', 'MonteCarlo rendering', 'Autoencoder', 'Neural Network', 'Graphics']","본 논문에서는 레이 트레이싱 그래픽에서 사용되는 몬테칼로 렌더링에 포함되는 잡음을 제거하기 위해 개선된 신경망구조 를 설계하였다. 몬테칼로 렌더링은 그래픽의 실감을 높이는데 가장 좋은 방법이지만 픽셀마다 수천 개 이상의 빛 효과를 계산해야 하기 때문에 렌더링 처리시간이 급격히 증가하여 실시간 처리에 큰 문제를 갖고 있다. 이 문제를 개선하기 위해 픽셀에서 사용되는 빛의 수를 줄이게 되는데 이때 렌더링 잡음이 발생하게 되고 이 잡음을 제거하기 위해 다양한 연구가 진행되어 왔다. 본 논문에서는 렌더링 잡음을 제거하는데 딥러닝을 사용하며 특히, 렌더링 이미지를 확산광과 집중광으로 분리하여 이중 신경망 구조를 설계하였다. 설계결과 단일구조 신경망에 비하여 듀얼구조 신경망은 PSNR기준으로 64개 테스트 이미지에 대하여 평균 0.58db가 개선되었으며 reference image에 비하여 99.22% 빛의 수를 줄여 실시간 레이 트레이싱 렌더링을 구현하였다.","In this paper, we designed a revised neural network to remove the Monte Carlo Rendering noise contained in the ray tracing graphics. The Monte Carlo Rendering is the best way to enhance the graphic""s realism, but because of the need to calculate more than thousands of light effects per pixel, rendering processing time has increased rapidly, causing a major problem with real-time processing. To improve this problem, the number of light used in pixels is reduced, where rendering noise occurs and various studies have been conducted to eliminate this noise. In this paper, a deep learning is used to remove rendering noise, especially by separating the rendering image into diffuse and specular light, so that the structure of the dual neural network is designed. As a result, the dual neural network improved by an average of 0.58 db for 64 test images based on PSNR, and 99.22% less light compared to reference image, enabling real-time race-tracing rendering"
A method for rapidly evaluating reliability and predicting remaining useful life using two-dimensional convolutional neural network with signal conversion,2019,"['Rolling bearing', 'Remaining useful life', 'Convolution neural network', 'Signal conversion', 'Correlation entropy']",,"Real-time monitoring and rapid evaluation of bearing operating conditions, especially for the reliability evaluation and remaining useful life (RUL) prediction, are major challenges in the rotating machinery field. A two-dimensional (2-D) deep convolution neural network (CNN) is proposed for rapidly evaluating reliability and predicting RUL, in which a signal conversion method is proposed for converting the one-dimensional signal into the 2-D image to satisfy the input requirements of the 2-D CNN. Different activation functions are employed to implement the conversion of the input data to the output data for each layer of the network, and dropout is only adopted in the hidden layer to change the network structure to prevent overfitting. The maximum correlation entropy with regular terms is employed as the loss function of the model to obtain better training performance compared with the mean square error (MSE). Then, the rolling bearing degradation vibration data is applied to the proposed model to verify the accuracy and rapidity. The results show that the proposed method has good accuracy and fast calculation ability in bearing reliability evaluation and RUL prediction, especially, its time consumption is shorter than that by other deep learning networks."
사물인식을 위한 딥러닝 모델 선정 플랫폼,2019,"['딥러닝', '신경망', '사물인식', '플랫폼', 'Deep Learning', 'Neural Network', 'Object Recognition', 'Platform']","최근 컴퓨터 비전을 활용한 사물인식 기술이 센서 기반 사물인식 기술을 대체할 기술로 주목을 받고 있다. 센서 기반 사물인식 기술은 일반적으로 고가의 센서를 필요로 하기 때문에 기술이 상용화되기 어렵다는 문제가 있었다. 반면 컴퓨터 비전을 활용한 사물인식 기술은 고가의 센서 대신 비교적 저렴한 카메라를 사용할 수 있다. 동시에 CNN이 발전하면서 실시간 사물인식이 가능해진 이후 IoT, 자율주행자동차 등 타 분야에 활발하게 도입되고 있다. 그러나 사물 인식 모델을 상황에 알맞게 선택하고 학습시키기 위해서는 딥러닝에 대한 전문적인 지식을 요구하기 때문에 비전문가가 사물 인식 모델을 사용하기에는 어려움이 따른다. 따라서 본 논문에서는 딥러닝 기반 사물인식 모델들의 구조와 성능을 분석하고, 사용자가 원하는 조건의 최적의 딥러닝 기반 사물 인식 모델을 스스로 선정할 수 있는 플랫폼을 제안한다. 또한 통계에 기반한 사물 인식 모델 선정이 필요한 이유를 실험을 통해 증명한다.","Recently, object recognition technology using computer vision has attracted attention as a technology to replace sensor-based object recognition technology. Sensor-based object recognition technology has a problem that it is difficult to commercialize the technology because an expensive sensor is required. On the other hand, since object recognition technology using computer vision can replace sensors with inexpensive cameras. Moreover, Real-time object recognition becomes possible because of the development of CNN, it is actively introduced into other fields such as IoT and autonomous vehicles. However, using the object recognition model requires expert knowledge on deep learning to select and learn the model, it is difficult for non-experts to use it. Therefore, in this paper, we analyze the structure of deep - learning - based object recognition models, and propose a platform that can automatically select a deep - running object recognition model based on a user s desired condition. We also show the reason why we need to select the object recognition model based on the statistics through experiments on the models."
A Tracking-by-Detection System for Pedestrian Tracking Using Deep Learning Technique and Color Information,2019,"['Color Distribution', 'Convolutional Neural Network', 'Pedestrian Tracking', 'Tracking-by-Detection']",,"Pedestrian tracking is a particular object tracking problem and an important component in various visionbasedapplications, such as autonomous cars and surveillance systems. Following several years of development,pedestrian tracking in videos remains challenging, owing to the diversity of object appearances and surroundingenvironments. In this research, we proposed a tracking-by-detection system for pedestrian tracking, whichincorporates a convolutional neural network (CNN) and color information. Pedestrians in video frames arelocalized using a CNN-based algorithm, and then detected pedestrians are assigned to their correspondingtracklets based on similarities between color distributions. The experimental results show that our system isable to overcome various difficulties to produce highly accurate tracking results."
Real-time Multiple Pedestrians Tracking for Embedded Smart Visual Systems,2019,"['Pedestrian Tracking', 'Object Detection', 'Deep Learning', 'Object Association']",,"Even though so much progresses have been achieved in Multiple Object Tracking (MOT), most of reported MOT methods are not still satisfactory for commercial embedded products like Pan-Tilt–Zoom (PTZ) camera. In this paper, we propose a real-time multiple pedestrians tracking method for embedded environments. First, we design a new light weight convolutional neural network(CNN)-based pedestrian detector, which is constructed to detect even small size pedestrians, as well. For further saving of processing time, the designed detector is applied for every other frame, and Kalman filter is employed to predict pedestrians’ positions in frames where the designed CNN-based detector is not applied. The pose orientation information is incorporated to enhance object association for tracking pedestrians without further computational cost. Through experiments on Nvidia’s embedded computing board, Jetson TX2, it is verified that the designed pedestrian detector detects even small size pedestrians fast and well, compared to many state-of-the-art detectors, and that the proposed tracking method can track pedestrians in real-time and show accuracy performance comparably to performances of many state-of-the-art tracking methods, which do not target for operation in embedded systems."
A Tracking-by-Detection System for Pedestrian Tracking Using Deep Learning Technique and Color Information,2019,"['Color Distribution', 'Convolutional Neural Network', 'Pedestrian Tracking', 'Tracking-by-Detection']",,"Pedestrian tracking is a particular object tracking problem and an important component in various vision-based applications, such as autonomous cars and surveillance systems. Following several years of development, pedestrian tracking in videos remains challenging, owing to the diversity of object appearances and surrounding environments. In this research, we proposed a tracking-by-detection system for pedestrian tracking, which incorporates a convolutional neural network (CNN) and color information. Pedestrians in video frames are localized using a CNN-based algorithm, and then detected pedestrians are assigned to their corresponding tracklets based on similarities between color distributions. The experimental results show that our system is able to overcome various difficulties to produce highly accurate tracking results."
Real-time Multiple Pedestrians Tracking for Embedded Smart Visual Systems,2019,"['Pedestrian Tracking', 'Object Detection', 'Deep Learning', 'Object Association']",,"Even though so much progresses have been achieved in Multiple Object Tracking (MOT), most of reported MOT methods are not still satisfactory for commercial embedded products like Pan-Tilt-Zoom (PTZ) camera. In this paper, we propose a real-time multiple pedestrians tracking method for embedded environments. First, we design a new light weight convolutional neural network(CNN)-based pedestrian detector, which is constructed to detect even small size pedestrians, as well. For further saving of processing time, the designed detector is applied for every other frame, and Kalman filter is employed to predict pedestrians' positions in frames where the designed CNN-based detector is not applied. The pose orientation information is incorporated to enhance object association for tracking pedestrians without further computational cost. Through experiments on Nvidia's embedded computing board, Jetson TX2, it is verified that the designed pedestrian detector detects even small size pedestrians fast and well, compared to many state-of-the-art detectors, and that the proposed tracking method can track pedestrians in real-time and show accuracy performance comparably to performances of many state-of-the-art tracking methods, which do not target for operation in embedded systems."
딥 컨볼루셔널 인코더-디코더 네트워크를 이용한 망막 OCT 영상의 층 분할,2019,"['Optical Coherence Tomography', 'Image Segmentation', 'Convolutional Neural Network', 'Deep Learning']",,"In medical image analysis, segmentation is considered as a vital process since it partitions an image into coherent parts and extracts interesting objects from the image. In this paper, we consider automatic segmentations of OCT retinal images to find six layer boundaries using convolutional neural networks.Segmenting retinal images by layer boundaries is very important in diagnosing and predicting progress of eye diseases including diabetic retinopathy, glaucoma, and AMD (age-related macular degeneration).We applied well-known CNN architecture for general image segmentation, called Segnet, U-net, and CNN-S into this problem. We also proposed a shortest path-based algorithm for finding the layer boundaries from the outputs of Segnet and U-net. We analysed their performance on public OCT image data set. The experimental results show that the Segnet combined with the proposed shortest path-based boundary finding algorithm outperforms other two networks."
시각장애인을 위한 딥러닝 기반 인물 위주 이미지 캡션 방법,2019,"['Blind', 'Face Recognition', 'Image Captioning', 'Image segmentation', 'DVS']","본 논문에서는 영상의 시각적인 정보를 딥러닝을 이용하여 시각장애인들에게 영상 내 등장인물과 배경을 인식하여 제공하는 시스템을 제안한다. 시각장애인들은 드라마, 영화, 광고 등 영상에서 장소, 행위, 등장인물 등 영상에 나타나는 시각적인 정보들을 제한적으로 시청하고 있어 시각적인 정보들을 화면해설방송을 사용하여 얻고 있다. 하지만 화면해설방송은 화면해설작가가 영상 정보를 수집하여 대본을 쓴 뒤 성우가 녹음을 진행하고, 화면해설 전문엔지니어가 영상 작업을 해야만 시청이 가능한 불편함을 갖는다. 이를 개선하고자 히스토그램을 이용하여 영상을 자동으로 분할하고, 등장인물들은 CNN을 이용하여 인물 별로 학습시킨 후 분류하며, 영상의 이미지를 MSCOCO 데이터 셋을 이용하여 학습시켜 이미지에 대한 행동, 배경들을 묘사한 정보를 이미지 캡션을 한다. 위의 결과를 통해 얻어진 이미지 캡션 결과에 대해서 20대 이상의 성인을 대상으로 영상내의 시각적인 정보와 비교하는 정성적 평가를 진행함으로서 시각장애인들에게 시각적인 영상 정보를 제공함을 확인할 수 있다.","In this paper, we propose a system for visually impaired people to recognize visual characters and background in visual images by using deep learning. For people with visual impaired, since there is a limitation to viewing visual information such as place, action, character, etc. that appear in the video such as drama, movie or advertisement, they can only get those visual information from the Descriptive Video Service(DVS). However, screen commentary broadcasts are inconvenienced when the screenwriter collects the video information and writes the script, and the voice actor carries out the recording and the professional engineer of the screen commentary performs the video work. To improve this, the image is automatically segmented using the histogram, the characters are learned and classified by the person using CNN, and the image of the image is learned using the MSCOCO data set to describe the behavior and background of the image Captures image information. The image caption obtained from the above results can be confirmed to provide visual image information to the visually impaired by carrying out a qualitative evaluation comparing with the visual information in the image of the adult over 20 persons."
딥러닝에 기반한 병원 실내이미지의 감성어휘 분류,2019,"['분류', '감성어휘', '병원', '실내이미지', '딥러닝', 'Classification', 'Emotional adjective', 'Hospital', 'Indoor image', 'Deep learning']",,"This research suggests to classify Emotional adjective for the hospital indoor image. The aim of this study was twofold. First it is an attempt to overcome limitation of overfitting data with pre-process and Second it is an approach for prediction quantified the image data with Emotional adjective. The emotion is important because emotion interact between indoor and human. The hospital indoor image also have specialized emotional effect.Emotional adjective is necessary to verify throughout variety of source qualitative and quantitative research.recently it is getting more harder with I.R.B.(Institutional Review Board) than Emotional adjective data had made.This research is based on deep learning method for emotional adjective quantifiaction that can replace thousands of people’s cognition. In the proposed simulation, emotional colors are firstly processed in the frequency domain to indoor images which can be treated as an emotional image. For pre-processing Emotional colors are extracted from hospital image. and search the emotional adjetive to get indoor images to fed in CNN(Convolutional Neural Network). For the hospital indoor image clustered, emotional indoor image are fed in CNN. The output of the CNNs are fused using TF(TensorFlow) API. The input of the fusion is given to a support of Python language for image classification. The proposed system is evaluated using Tensor board - which is the proved data. This research has concluded that it is desirable to use TF for predicting the set of emotional adjective and it helps for emotion analysis efficiently. TF works for the emotional image classifying the hospital indoor images. The hospital image is classified using deep learning, and analysis of emotion as A is 80 percentage modern and B is 20 percent natural in a second for a thousand emotional colors. It is expected to use these results of research have for implications of emotional analysis that represent functions of the indoor images."
절단된 분포를 이용한 인공신경망에서의 초기값 설정방법,2019,"['initialization', 'saturation', 'Xavier initialization', 'truncated distribution', 'deep learning', '초기값', '포화', 'Xavier', '절단된 분포', '딥러닝']",딥러닝은 대용량의 데이터의 분류 및 예측하는 방법으로 각광받고 있다. 데이터의 양이 많아지면서 신경망의 구조는 더 깊어 지고 있다. 이때 초기값이 지나치게 클 경우 층이 깊어 질수록 활성화 함수의 기울기가 매우 작아지는 포화(Saturation)현상이 발생한다. 이러한 포화현상은 가중치의 학습능력을 저하시키는 현상을 발생시키기 때문에 초기값의 중요성이 커지고 있다.이런 포화현상 문제를 해결하기 위해 Glorot과 Bengio (2010)과 He 등 (2015) 층과 층 사이에 데이터가 다양하게 흘러야 효율적인 신경망학습이 가능하고 주장했다. 데이터가 다양하게 흐르기 위해서는 각 층의 출력에 대한 분산과 입력에 대한 분산이 동일해야 한다고 제안했다. Glorot과 Bengio (2010)과 He 등 (2015)는 각 층별 활성화 값의 분산이 같다고 가정해 초기값을 설정하였다. 본 논문에서는 절단된 코쉬 분포와 절단된 정규분포를 활용하여 초기값을 설정하는 방안을 제안한다. 출력에 대한 분산과 입력에 대한 분산의 값을 동일하게 맞춰주고 그 값이 절단된 확률분포의 분산과 같게 적용함으로써 큰 초기값이 나오는 걸 제한하고 0에 가까운 값이 나오도록 분포를 조정하였다. 제안된 방법은 MNIST 데이터와 CIFAR-10 데이터를 DNN과 CNN 모델에 각각 적용하여 실험함으로써 기존의 초기값 설정방법보다 모델의 성능을 좋게 한다는 것을 보였다,"Deep learning has gained popularity for the classification and prediction task. Neural network layers become deeper as more data becomes available. Saturation is the phenomenon that the gradient of an activation function gets closer to 0 and can happen when the value of weight is too big. Increased importance has been placed on the issue of saturation which limits the ability of weight to learn. To resolve this problem, Glorot and Bengio (Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, 249-256, 2010) claimed that efficient neural network training is possible when data flows variously between layers. They argued that variance over the output of each layer and variance over input of each layer are equal. They proposed a method of initialization that the variance of the output of each layer and the variance of the input should be the same. In this paper, we propose a new method of establishing initialization by adopting truncated normal distribution and truncated cauchy distribution. We decide where to truncate the distribution while adapting the initialization method by Glorot and Bengio (2010). Variances are made over output and input equal that are then accomplished by setting variances equal to the variance of truncated distribution. It manipulates the distribution so that the initial values of weights would not grow so large and with values that simultaneously get close to zero. To compare the performance of our proposed method with existing methods, we conducted experiments on MNIST and CIFAR-10 data using DNN and CNN. Our proposed method outperformed existing methods in terms of accuracy."
딥 러닝 기법을 이용한 오피니언 마이닝 분석과 성과에 관한 실증연구: 합성곱 신경망 모델과 머신러닝 모델간 성과비교를 중심으로,2019,"['Deep learning', 'Convolutional neural network', 'Sentiment analysis', 'Opinion mining', 'Machine learning classifiers', 'Financial supervisory policy', '딥 러닝', '합성곱 신경망', '감성분석', '오피니언 마이닝', '머신러닝 분류기']","본 연구는 딥 러닝 기법인 합성곱 신경망 (CNN: Convolutional Neural Network)을 이용하여 금융자료에 관한 사용자의 오피니언을 추정하는 오피니언 마이닝 (Opinion mining) 방법과 그 결과를 설명한다. 본 연구에서는 다음과 같이 합성곱 신경망의 효과성을 검증하였다. 첫째, 스터디1은 주식관련 온라인 리뷰 데이터를 분석하였다. 즉, 형태소 분석단계를 거쳐 속성벡터를 만들어 리뷰 문장의 감성점수를 산출하였다. 해당 문장의 감성점수에 따라 오피니언을 3-클라스, 5-클라스 문제로 구분하여 실증분석을 하였다. 둘째, 스터디2에서는 청와대 국민청원에 게시된 금융관련 국민청원 텍스트 문장을 분석하여 청원인원을 추정하였다. 청원게시판에 등재된 청원 인원을 분위 수에 따라 분류하여 2-클라스 문제 (50%이상, 50% 미만) 4-클라스 문제 (75%이상, 50%이상, 25%이상, 25%미만)로 분류하였다. 스터디1, 2의 실증분석결과 정확도, 정밀도, 재현율, F1 점수 등 모든 성과지표에서 벤치마킹용 분류기와 비교할 때 합성곱 신경망이 더 우수한 성과를 보였다. 따라서, 합성곱 신경망을 이용함으로써 금융감독 관련 정책 및 활동을 효과적으로 수행할 수 있음을 실증적으로 확인하였다.",
Pix2Pix 모델을 활용한 단일 영상의 깊이맵 추출,2019,"['Deep Learning', 'Pix2Pix', 'GAN', 'Monocular Depth Map', 'Depth Map Extraction']",,"To extract the depth map from a single image, a number of CNN-based deep learning methods have been performed in recent research. In this study, the GAN structure of Pix2Pix is maintained. this model allows to converge well, because it has the structure of the generator and the discriminator. But the convolution in this model takes a long time to compute. So we change the convolution form in the generator to a depthwise convolution to improve the speed while preserving the result. Thus, the seven down-sizing convolutional hidden layers in the generator U-Net are changed to depthwise convolution. This type of convolution decreases the number of parameters, and also speeds up computation time. The proposed model shows similar depth map prediction results as in the case of the existing structure, and the computation time in case of a inference is decreased by 64%."
韓日両言語におけるアルファベット頭文字語のアクセント研究 − 釜山方言と鹿児島諸方言を中心に −,2019,"['アルファベット頭文字語', 'アルファベット関連語彙', '鹿児島諸方言', '釜山方言', 'Alphabetic Acronym', 'Alphabetic Compound', 'Kagoshima Dialect', 'Busan Dialect']",,"The purpose of this study is to clarify the accent pattern of alphabetic acronyms like ‘ID and CNN’ and alphabetic compounds of Korean Busan dialect. This study would also like to clarify the difference between the accent pattern of alphabetic acronyms in both Kagoshima dialects of Japan and Busan dialect of Korean. Accents of the Busan dialect alphabetic acronyms are largely divided depending on whether the first element is a monosyllable or polysyllable. In the case of beginning with a monosyllable, the words are pronounced “HHL…” regardless of the accent of the following element. In the case of beginning with a polysyllable, the acronyms are pronounced “first syllable start low, go high from the second syllable to high until the accent of the final element (LH… or LH…HL)”. Unlike the foreign words accent rules and compound word accent rules, the accent of alphabetic acronyms follows its own accent rules.This point is different from the accent of the alphabetic acronyms of Kagoshima dialects of Japan, which is concerned with the accent of loanwords or compound words."
깊이영상을 이용한 나이와 성별인식을 통해 캐릭터 플로팅 홀로그램 구현,2019,"['Age Recognition', 'Gender Recognition', 'Floating Hologram']",,"In this paper, we propose a character floating hologram system using the user’s gender and age. The proposed system recognizes the gender and age of the user through depth images and color images. The depth images are used to find and normalize facial position. Next, by using facial color images, the age and gender are estimated through an verified database-based model of CNN. Finally, the estimated age and gender are expressed to a character for the floating hologram. The proposed system can be used in a variety of areas, including marketing, advertising, and exhibition events using gender or age."
[컴퓨터지능 및 지능시스템] 심층 학습 및 IoT 기법을 이용한 유도 전동기의 실시간 고장 진단과 자기 보완 시스템,2019,"['IoT', 'Deep Learning', 'Self-Complement', 'Real-time', 'Diagnosis']",,"Existing fault diagnosis using deep Learning, has experimented by collecting data from a controlled environment. However, it is not easy to diagnose motor faults in various environments, becuase input data are measured with various disturbances together. For this reason, in this paper, the verification and learning process are separated and used in each system so that motor data of various environments can be considered. In the verification process, a data preprocessing process is added to verify and collect necessary data. A CNN-based in-depth learning algorithm is implemented and data is stored in real time. Since the data is re-learned based on the collected data, a model considering both existing features and newly input data is created. Even the continuous disturbance is also used as learning data, it is easier to cope with disturbance than the conventional method. As a result, a system applicable to an industrial field is proposed considering various environments."
Document Summarization Model Based on General Context in RNN,2019,"['Document Summarization', 'General Context', 'Natural Language Processing', 'Sequence-to-Sequence Model']",,"In recent years, automatic document summarization has been widely studied in the field of natural language processing thanks to the remarkable developments made using deep learning models. To decode a word, existing models for abstractive summarization usually represent the context of a document using the weighted hidden states of each input word when they decode it. Because the weights change at each decoding step, these weights reflect only the local context of a document. Therefore, it is difficult to generate a summary that reflects the overall context of a document. To solve this problem, we introduce the notion of a general context and propose a model for summarization based on it. The general context reflects overall context of the document that is independent of each decoding step. Experimental results using the CNN/Daily Mail dataset show that the proposed model outperforms existing models."
End-to-End Partial Discharge Detection in Power Cables via Time-Domain Convolutional Neural Networks,2019,['Partial discharges · Fault detection · Power cable · Deep neural networks · Convolutional neural networks'],,"The analysis of partial discharge (PD) signals has been identifi ed as a standardized diagnostic tool in monitoring the condition of diff erent electrical apparatus nowadays. In this paper, we propose a novel data-driven approach to detect PD pulses in power cables using one-dimensional convolutional neural networks (CNNs), a successful deep neural network approach.Applying this deep learning method, an end-to-end framework has been proposed considering the propagations of PD signals and noises in power cables. The proposed method uses PD pulses as input, automatically extracts meaningful features for waveforms of PD pulses, and fi nally detects PD. Most of the existing methods, which use traditional classifi ers, such as support vector machines (SVMs) and multi-layer perceptron (MLP) have mainly focused on improving feature representation and extraction manually for this task. However, the proposed CNN-based detection algorithm captures important latent features for waveforms of PD pulses with the help of its automatic feature extraction capability from raw inputs. Our experimental results show that the proposed method is better than conventional SVMs and achieves 97.38% and 93.23% detection accuracies in end-to-end settings based on our theoretical model-generated and empirical real-world PD signals, respectively."
Document Summarization Model Based on General Context in RNN,2019,"['Document Summarization', 'General Context', 'Natural Language Processing', 'Sequence-to-Sequence Model']",,"In recent years, automatic document summarization has been widely studied in the field of natural languageprocessing thanks to the remarkable developments made using deep learning models. To decode a word,existing models for abstractive summarization usually represent the context of a document using the weightedhidden states of each input word when they decode it. Because the weights change at each decoding step, theseweights reflect only the local context of a document. Therefore, it is difficult to generate a summary that reflectsthe overall context of a document. To solve this problem, we introduce the notion of a general context andpropose a model for summarization based on it. The general context reflects overall context of the documentthat is independent of each decoding step. Experimental results using the CNN/Daily Mail dataset show thatthe proposed model outperforms existing models."
숫자 인식 서비스 기반 다층 퍼셉트론에 대한 입력 데이터 축소 알고리즘,2019,"['artificial neural networks', 'multi-layer perceptron', 'mobile pattern recognition', 'recognition']",,"IT fusion and composite technologies generate a large amount of data, and deep learning technologies that can identify them on their own are currently receiving great attention in the industrial field. Deep learning, which artificially models biological brains, requires a high amount of computation. In this paper, we propose a numerical data reduction algorithm as a first step to reduce high computations, a fundamental problem of deep learning. After identifying the all features in the image, measure the number of features and arrange them into a fixed array of 16 sizes. This reduces the computation and learning time of the neural network. In order to evaluate the performance of the proposed numerical data Conversion algorithm, the processed data is compared with 3-layer-ANN and CNN-LeNet5 after learning through multilayer perceptron. Experimental results showed somewhat poor results with accuracy of 99.4% and error rate of 0.0264%. However, the time measurement showed more than three times faster operation than the conventional method."
단어 생성 이력을 이용한 요약문 생성의 어휘 반복 문제 해결,2019,"['text summarization', 'sequence-to-sequence model', 'word repetition', 'repeat loss', '문서 요약', '반복 제어', '시퀀스-투-시퀀스', '손실 함수']","시퀀스-투-시퀀스 기반의 요약 모델에서 자주 발생하는 문제 중 하나는 요약문의 생성과정에서 단어나 구, 문장이 불필요하게 반복적으로 생성되는 것이다. 이를 해결하기 위해 기존 연구들은 대부분 모델에 여러 모듈을 추가하는 방법을 제안했지만, 위 방법은 생성하지 말아야 하는 단어에 대한 학습이 부족하여 반복 생성 문제를 해결함에 있어 한계가 있다. 본 논문에서는 단어 생성 이력을 직접적으로 이용하여 반복 생성을 제어하는 Repeat Loss를 이용한 새로운 학습 방법을 제안한다. Repeat Loss를 디코더가 단어 생성 확률을 계산 했을 때 이전에 생성한 단어가 다시 생성될 확률로 정의함으로써 실제 생성한 단어가 반복 생성될 확률을 직접적으로 제어할 수 있다. 제안한 방법으로 요약 모델을 학습한 결과, 단어 반복이 줄어들어 양질의 요약을 생성하는 것을 실험적으로 확인할 수 있었다.","Neural attentional sequence-to-sequence models have achieved great success in abstractive summarization. However, the model is limited by several challenges including repetitive generation of words, phrase and sentences in the decoding step. Many studies have attempted to address the problem by modifying the model structure. Although the consideration of actual history of word generation is crucial to reduce word repetition, these methods, however, do not consider the decoding history of generated sequence. In this paper, we propose a new loss function, called ‘Repeat Loss’ to avoid repetitions. The Repeat Loss directly prevents the model from repetitive generation of words by giving a loss penalty to the generation probability of words already generated in the decoding history. Since the propose Repeat Loss does not need a special network structure, the loss function is applicable to any existing sequence-to-sequence models. In experiments, we applied the Repeat Loss to a number of sequence-to-sequence model based summarization systems and trained them on both Korean and CNN/Daily Mail summarization datasets. The results demonstrate that the proposed method reduced repetitions and produced high-quality summarization."
Four-Dimensional CBCT Reconstruction Based on a Residual Convolutional Neural Network for Improving Image Quality,2019,"['4D computed tomography', 'Residual convolution neural network', 'Streak artifacts']",,"In radiation treatment, a cone-beam computed tomography (CBCT) scan is conducted for precise positioning of tumors, and the image quality is usually degraded by motion artifacts due to patient's respiration and movement during scanning. Four-dimensional (4D) CBCT reconstruction with phase binning is typically used to overcome these difficulties. Albeit motion artifacts might be reduced with 4D CBCT, the overall image quality is typically worsened by severe streak artifacts due to the sparse-angle projections available in the 3D reconstruction for each motion phase. This study presents a method for reducing streak artifacts effectively in conventional 4D CBCT reconstruction by using a state-of-the-art convolutional neural network (a residual U-Net was used). We performed a computational simulation and an experiment to investigate the image quality and evaluate the effectiveness of the proposed method. The proposed 4D CBCT reconstruction method reduced streak artifacts noticeably, and its effectiveness was validated by comparing its results to those of other reconstruction methods such as the filtered-backprojection, a compressed-sensing, and a simple CNN-based algorithm for the 4D CBCT datasets."
Document Summarization Model Based on General Context in RNN,2019,"['Document Summarization', 'General Context', 'Natural Language Processing', 'Sequence-to-Sequence Model']",,"In recent years, automatic document summarization has been widely studied in the field of natural language processing thanks to the remarkable developments made using deep learning models. To decode a word, existing models for abstractive summarization usually represent the context of a document using the weighted hidden states of each input word when they decode it. Because the weights change at each decoding step, these weights reflect only the local context of a document. Therefore, it is difficult to generate a summary that reflects the overall context of a document. To solve this problem, we introduce the notion of a general context and propose a model for summarization based on it. The general context reflects overall context of the document that is independent of each decoding step. Experimental results using the CNN/Daily Mail dataset show that the proposed model outperforms existing models."
딥러닝 기반의 주행가능 영역 추출 모델에 관한 연구,2019,"['Drivable area segmentation', 'Segmentation', 'Deep Learning', 'DeepLab V3+', 'Mask R-CNN', 'BDD Dataset', '주행가능 영역 추출', '영상 분할', '딥러닝', 'DeepLab V3+', 'Mask R-CNN', 'BDD 데이터셋']","인공지능, 빅데이터, 자율주행 등 4차 산업혁명시대를 이끄는 핵심기술은 컴퓨팅 파워의 급속한 발전과 사물인터넷에 기반한 초연결 네트워크를 통해 구현되고 서비스된다. 본 논문에서는 자율주행을 위한 기본적인 기능으로 다양한 환경에서도 정확하게 주행가능한 영역을 인식하여 추출하는 인공지능 딥러닝 모델들을 구현하고, 그 결과를 비교, 분석한다. 주행가능한 영역을 추출하는 딥러닝모델은 영상 분할 분야에서 성능이 우수하고 자율주행 연구에서 많이 사용하는 Deep Lab V3+와 Mask R-CNN을 활용하였다. 다양한환경에서의 주행 정보를 위해 여러 가지 날씨 조건과 주·야간 환경에서의 주행 영상 및 이미지를 제공하는 BDD 데이터셋을 학습데이터로 사용하였다. 활용한 모델들의 실험 결과, DeepLab V3+는 48.97%의 IoU를 보였으며, Mask R-CNN은 68.33%의 IoU로 더 우수한성능을 보였다. 또한, 구현한 모델로 추출된 주행가능 영역을 이미지에 표시하여 육안으로 검사한 결과, Mask R-CNN은 83%, Deep Lab V3+는 69% 정확도로 Mask R-CNN이 Deep Lab V3+ 보다 주행가능한 영역을 추출하는 분야에서는 더 성능이 높은 것으로 확인하였다.","Core technologies that lead the Fourth Industrial Revolution era, such as artificial intelligence, big data, and autonomous driving, are implemented and serviced through the rapid development of computing power and hyper-connected networks based on the Internet of Things. In this paper, we implement two different models for drivable area segmentation in various environment, and propose a better model by comparing the results. The models for drivable area segmentation are using DeepLab V3+ and Mask R-CNN, which have great performances in the field of image segmentation and are used in many studies in autonomous driving technology. For driving information in various environment, we use BDD dataset which provides driving videos and images in various weather conditions and day&night time. The result of two different models shows that Mask R-CNN has higher performance with 68.33% IoU than DeepLab V3+ with 48.97% IoU. In addition, the result of visual inspection of drivable area segmentation on driving image, the accuracy of Mask R-CNN is 83% and DeepLab V3+ is 69%. It indicates Mask R-CNN is more efficient than DeepLab V3+ in drivable area segmentation."
A new fault diagnosis method based on convolutional neural network and compressive sensing,2019,"['Compressive sensing', 'Fault diagnosis', 'Convolutional neural network', 'Feature extraction', 'Gearbox', 'Bearing']",,"Compressive sensing is an efficient machinery monitoring framework, which just needs to sample and store a small amount of observed signal. However, traditional reconstruction and fault detection methods cost great time and the accuracy is not satisfied. For this problem, a 1D convolutional neural network (CNN) is adopted here for fault diagnosis using the compressed signal. CNN replaces the reconstruction and fault detection processes and greatly improves the performance. Since the main information has been reserved in the compressed signal, the CNN is able to extract features from it automatically. The experiments on compressed gearbox signal demonstrated that CNN not only achieves better accuracy but also costs less time. The influencing factors of CNN have been discussed, and we compared the CNN with other classifiers. Moreover, the CNN model was also tested on bearing dataset from Case Western Reserve University. The proposed model achieves more than 90 % accuracy even for 50 % compressed signal."
딥러닝 알고리즘과 2D Lidar 센서를 이용한 이미지 분류,2019,"['Deep learning', 'deep learning neural network', 'convolutional neural network', 'object detection', 'image classification']","본 논문은 CNN (Convolutional Neural Network)와 2D Lidar 센서에서 획득한 위치 데이터를 이용하여 이미지를 분류하는 방법을 제시한다. Lidar 센서는 데이터 정확도, 형상 왜곡 및 광 변화에 대한 강인성 측면에서의 이점으로 인해 무인 장치에 널리 사용되어 왔다. CNN 알고리즘은 하나 이상의 컨볼루션 및 풀링 레이어로 구성되며 이미지 분류에 만족스러운 성능을 보여 왔다. 본 논문에서는 학습 방법에 따라 다른 유형의 CNN 아키텍처들인 Gradient Descent (GD) 및 Levenbergarquardt(LM)를 구현하였다. LM 방법에는 학습 파라메터를 업데이트하는 요소 중 하나인 Hessian 행렬 근사 빈도에 따라 두 가지 유형이 있다. LM 알고리즘의 시뮬레이션 결과는 GD 알고리즘보다 이미지 데이터의 분류 성능이 우수하였다. 또한 Hessian 행렬 근사가 더 빈번한 LM 알고리즘은 다른 유형의 LM 알고리즘보다 작은 오류를 보여주었다.","This paper presents an approach for classifying image made by acquired position data from a 2D Lidar sensor with a convolutional neural network (CNN). Lidar sensor has been widely used for unmanned devices owing to advantages in term of data accuracy, robustness against geometry distortion and light variations. A CNN algorithm consists of one or more convolutional and pooling layers and has shown a satisfactory performance for image classification. In this paper, different types of CNN architectures based on training methods, Gradient Descent(GD) and Levenbergarquardt(LM), are implemented. The LM method has two types based on the frequency of approximating Hessian matrix, one of the factors to update training parameters. Simulation results of the LM algorithms show better classification performance of the image data than that of the GD algorithm. In addition, the LM algorithm with more frequent Hessian matrix approximation shows a smaller error than the other type of LM algorithm."
Automatic Prediction of Atrial Fibrillation Based on Convolutional Neural Network Using a Short-term Normal Electrocardiogram Signal,2019,"['Atrial Fibrillation', 'Electrocardiogram', 'Convolutional Neural Network', 'Deep Learning']",,"Background: In this study, we propose a method for automatically predicting atrial fibrillation (AF) based on convolutional neural network (CNN) using a short-term normal electrocardiogram (ECG) signal.Methods: We designed a CNN model and optimized it by dropout and normalization. One- dimensional convolution, max-pooling, and fully-connected multiple perceptron were used to analyze the short-term normal ECG. The ECG signal was preprocessed and segmented to train and evaluate the proposed CNN model. The training and test sets consisted of the two AF and one normal dataset from the MIT-BIH database.Results: The proposed CNN model for the automatic prediction of AF achieved a high performance with a sensitivity of 98.6%, a specificity of 98.7%, and an accuracy of 98.7%.Conclusion: The results show the possibility of automatically predicting AF based on the CNN model using a short-term normal ECG signal. The proposed CNN model for the automatic prediction of AF can be a helpful tool for the early diagnosis of AF in healthcare fields."
UWB 시스템에서 합성곱 신경망을 이용한 거리 추정,2019,[],,"The paper proposes a distance estimation technique for ultra-wideband (UWB) systems using convolutional neural network (CNN). To estimate the distance from the transmitter and the receiver in the proposed method, 1 dimensional vector consisted of the magnitudes of the received samples is reshaped into a 2 dimensional matrix, and by using this matrix, the distance is estimated through the CNN regressor. The received signal for CNN training is generated by the UWB channel model in the IEEE 802.15.4a, and the CNN model is trained. Next, the received signal for CNN test is generated by filed experiments in indoor environments, and the distance estimation performance is verified. The proposed technique is also compared with the existing threshold based method. According to the results, the proposed CNN based technique is superior to the conventional method and specifically, the proposed method shows 0.6 m root mean square error (RMSE) at distance 10 m while the conventional technique shows much worse 1.6 m RMSE."
Fully Automatic Segmentation of Acute Ischemic Lesions on Diffusion-Weighted Imaging Using Convolutional Neural Networks: Comparison with Conventional Algorithms,2019,"['Diffusion-weighted imaging', 'Cerebral ischemia', 'Segmentation', 'Convolutional neural networks']",,"Objective: To develop algorithms using convolutional neural networks (CNNs) for automatic segmentation of acute ischemic lesions on diffusion-weighted imaging (DWI) and compare them with conventional algorithms, including a thresholding-based segmentation.Materials and Methods: Between September 2005 and August 2015, 429 patients presenting with acute cerebral ischemia (training:validation:test set = 246:89:94) were retrospectively enrolled in this study, which was performed under Institutional Review Board approval. Ground truth segmentations for acute ischemic lesions on DWI were manually drawn under the consensus of two expert radiologists. CNN algorithms were developed using two-dimensional U-Net with squeeze-and-excitation blocks (U-Net) and a DenseNet with squeeze-and-excitation blocks (DenseNet) with squeeze-and-excitation operations for automatic segmentation of acute ischemic lesions on DWI. The CNN algorithms were compared with conventional algorithms based on DWI and the apparent diffusion coefficient (ADC) signal intensity. The performances of the algorithms were assessed using the Dice index with 5-fold cross-validation. The Dice indices were analyzed according to infarct volumes (< 10 mL, ≥ 10 mL), number of infarcts (≤ 5, 6–10, ≥ 11), and b-value of 1000 (b1000) signal intensities (< 50, 50–100, > 100), time intervals to DWI, and DWI protocols.Results: The CNN algorithms were significantly superior to conventional algorithms (p < 0.001). Dice indices for the CNN algorithms were 0.85 for U-Net and DenseNet and 0.86 for an ensemble of U-Net and DenseNet, while the indices were 0.58 for ADC-b1000 and b1000-ADC and 0.52 for the commercial ADC algorithm. The Dice indices for small and large lesions, respectively, were 0.81 and 0.88 with U-Net, 0.80 and 0.88 with DenseNet, and 0.82 and 0.89 with the ensemble of U-Net and DenseNet. The CNN algorithms showed significant differences in Dice indices according to infarct volumes (p < 0.001).Conclusion: The CNN algorithm for automatic segmentation of acute ischemic lesions on DWI achieved Dice indices greater than or equal to 0.85 and showed superior performance to conventional algorithms."
Analyze weeds classification with visual explanation based on Convolutional Neural Networks,2019,"['Grad-CAM', 'CNN', 'visualization', 'Resnet']",,"To understand how a Convolutional Neural Network (CNN) model captures the features of a pattern to determine which class it belongs to, in this paper, we use Gradient-weighted Class Activation Mapping (Grad-CAM) to visualize and analyze how well a CNN model behave on the CNU weeds dataset. We apply this technique to Resnet model and figure out which features this model captures to determine a specific class, what makes the model get a correct/wrong classification, and how those wrong label images can cause a negative effect to a CNN model during the training process. In the experiment, Grad-CAM highlights the important regions of weeds, depending on the patterns learned by Resnet, such as the lobe and limb on 미국가막사리, or the entire leaf surface on 단풍잎돼지풀. Besides, Grad-CAM points out a CNN model can localize the object even though it is trained only for the classification problem."
딥러닝을 활용한 흔들림 영상 안정화 알고리즘,2019,"['Stabilization', 'Feature map', 'CNN', 'LSTM']","본 논문에서는 딥러닝을 활용한 흔들림 영상 안정화 알고리즘을 제안하였다. 제안하는 알고리즘은 기존 몇 가지2D, 2.5D 및 3D 기반 안정화 기술과 다르게 딥러닝을 활용한다. 제안하는 알고리즘은 흔들리는 영상을 CNN 네트워크 구조와 LSTM 네트워크 구조를 통한 특징 추출 및 비교하여 이전 프레임과 현재 프레임 간의 특징점 위치 차이를 통해 특징점의이동 크기와 방향의 반대로 영상을 변환하는 알고리즘이다. 흔들림 안정화를 위한 알고리즘은 각 프레임의 특징 추출 및비교를 위해 Tensorflow를 활용하여 CNN 네트워크과 LSTM 구조를 구현하였으며, 영상 흔들림 안정화는 OpenCV open source를 활용해 구현하였다. 실험결과 영상의 흔들림이 상하좌우로 흔들리는 영상과, 급격한 카메라 이동이 없는 영상을실험에 사용하여, 제안한 알고리즘을 적용한 결과 사용한 상하좌우 흔들림 영상에서는 안정적인 흔들림 안정화 성능을 기대할 수 있었다.","In this paper, we proposed a shaking image stabilization algorithm using deep learning. The proposed algorithm utilizes deep learning, unlike some 2D, 2.5D and 3D based stabilization techniques. The proposed algorithm is an algorithm that extracts and compares features of shaky images through CNN network structure and LSTM network structure, and transforms images in reverse order of movement size and direction of feature points through the difference of feature point between previous frame and current frame. The algorithm for stabilizing the shake is implemented by using CNN network and LSTM structure using Tensorflow for feature extraction and comparison of each frame. Image stabilization is implemented by using OpenCV open source. Experimental results show that the proposed algorithm can be used to stabilize the camera shake stability in the up, down, left, and right shaking images."
Development and Application of a Deep Convolutional Neural Network Noise Reduction Algorithm for Diffusion-weighted Magnetic Resonance Imaging,2019,"['Deep convolutional neural network (Deep-CNN) noise reduction algorithm', 'Diffusion-weighted imaging(DWI)', 'Magnetic resonance imaging(MRI)', 'Image processing', 'quantitative evaluation of image performance']",,"Diffusion-weighted imaging (DWI) is frequently used in the field of diagnostic medicine to detect various human diseases. In DWI, noise suppression is very important for achieving high detection accuracy of diseases. In this study, we develop a deep convolutional neural network (Deep-CNN) noise reduction algorithm and evaluate its effectiveness in DWI by performing both simulations and real experiments with a 1.5- and a 3.0-T MRI system. The results validate the proposed Deep-CNN algorithm for DWI. Compared with previously developed non-local means (NLM) algorithms, the proposed Deep-CNN algorithm achieves superior quantitative results. In conclusion, the quantitative results verify that the proposed Deep-CNN algorithm has higher noise reduction efficiency and image visibility than previously developed algorithms for DWI."
합성곱신경망의 학습 및 테스트자료에 따른 골다공증 판독에 미치는 영향,2019,"['Mandible', 'Osteoporosis', 'Panoramic radiograph', 'Computer']",,"This study aimed to test a convolutional neural network (CNN) in two different settings of training and testing data. Panoramic radiographs were selected from 1170 female dental patients (mean age 49.19 ± 21.91 yr). The cortical bone of the mandible inferior border was evaluated for osteoporosis or normal condition on the panoramic radiographs. Among them, 586 patients (mean age 27.46 ± 6.73 yr) had normal condition, and osteoporosis was interpreted on 584 patients (mean age 71.00 ± 7.64 yr). Among them, one data set of 569 normal patients (mean age 26.61 ± 4.60 yr) and 502 osteoporosis patients (mean age 72.37 ± 7.10 yr) was used for training CNN, and the other data set of 17 normal patients (mean age 55.94 ± 4.0 yr) and 82 osteoporosis patients (mean age 62.60 ± 5.00 yr) for testing CNN in the first experiment, while the latter was used for training CNN and the former for testing CNN in the second experiment.The error rate was 15.15% in the first experiment and 5.14% in the second experiment. This study suggests that age-matched training data make more accurate testing results."
택배화물 자동 하역장비를 위한 딥러닝 기반의 화물 인식 알 고리즘,2019,"['Unloading system', 'deep learning algorithm', 'YOLO v2', 'Masked -CRNN', '자동하역장치', '딥러닝 알고리즘', 'YOLO v2', 'Masked R-CNN']",본 논문에서는 택배화물 자동하역장치에 적합한 개선된 딥러닝 알고리즘을 제안한다. 제안된 알고리즘은 실시간객체검출에 우수한 성능을 보이는 YOLO v2모델을 기반으로 픽셀단위 택배화물의 위치까지 검출할 수 있도록 Masked R-CNN을 융합한 구조를 가진다. 제안된 알고리즘은 YOLO v2를 이용하여 객체의 영역과 분류를 수행하면서 객체 영역을Masked R-CNN의 객체분할(Instance segmentation)과정을 거쳐 택배화물의 픽셀단위 위치까지 계산할 수 있도록 하였다.제안된 알고리즘의 성능을 평가하기 위하여 실제 택배화물 차량의 적재공간과 동일한 영역에서 택배화물들을 이용하여실험하였으며 실험결과 만족할만한 성능을 보임을 확인하였다,"In this paper, an improved deep learning algorithm for automatic unloading systems is proposed. The proposed algorithm is based on the YOLO v2 model, which shows excellent performance in real-time object detection, and has a fused structure with Masked R-CNN to detect pixel position of parcel. The proposed algorithm performs object segmentation and classification using YOLO v2, and calculates the object region to the pixel position of the parcel by mask segmentation process of Instanced R-CNN.In order to evaluate the performance of the proposed algorithm, we experimented in the same area as the loading space of the actual parcel cargo vehicle and showed the excellent performance in the expiemr ental results."
도시재생정책에 대한 감성분석: 감천문화마을 방문객 리뷰를 중심으로,2019,"['Big data analysis', 'Gamcheon culture village', 'policy evaluation', 'sentimental analysis', 'TF-IDF weighted model', 'urban regeneration policy', '감성분석', '감천문화마을', '도시재생정책', '빅데이터 분석', '정책평가', 'TF-IDF 가중치모델.']","본 연구는 감천문화마을을 방문한 국내관광객들의 댓글을 이용한 감성분석을 통해 정부가 추진하고 있는 도시재생 정책에 대한 평가의 지능화를 목적으로 한다. 이를 위해 구글 지역리뷰 41,496건의 댓글을 수집 후 형태소, 음절, 그리고 자소를 결합한 Multi-channel CNN 모델을 활용하여 분석하였다. Multi-channel CNN 모델의 정확도는 86.68%로 단일로 구성된 모델들보다 높은 정확도를 보였다. 감성분석의 결과 긍정과 부정 비율이 8:2로, 감천문화마을의 도시재생정책에 대해 긍정 감성이 높게 나타났다. 또한 각각의 긍정문장과 부정문장을 분류하고 TF-IDF가중치 모델을 활용하여 긍정과 부정의 감성을 발생시킨 주요 요인들을 도출하였다. 본 연구의 공헌도로 학술적으로는 감성분석을 적용한 정책평가를 제시하였다는 점에서 향후 후속 연구를 유발할 것으로 예상된다. 실무적으로는 정부정책의 새로운 평가 방법으로서 방문객들의 댓글을 분석하여 정부사업의 성공여부를 판별할 수 있는 기초자료로 활용할 수 있다.","This study conducted a sentiment analysis using comments from domestic tourists who visited the Gamcheon Culture Village to evaluate the government's urban regeneration project automatically and efficiently. For this purpose, 41,496 comments from the local review from Google Map were collected and analyzed using a Multi-Channel CNN model that combines morphemes, syllables, and phonemes. The accuracy of the Multi-Channel CNN model was 85.72 percent, which is higher than the accuracy seen in Single-Channel CNN model. In the sentiment analysis, the ratio between the positive and negative responses was eight to two, indicating overall positive opinion regarding the urban regeneration project that is taking place in the Gamcheon Culture Village. Furthermore, the main factors that generated the positive and negative sentiments were extracted by classifying each positive and negative sentence using the TF-IDF weighted model. This study has an academic contribution in that the suggestion of policy evaluation through the application of a sentiment analysis will induce future studies. Practically, this study suggested an analysis of the visitors' comments as a new method of evaluating government policies, which can be used as fundamental data that can determine the success of other government projects in the future."
"Visual Classification of Wood Knots Using k-Nearest Neighbor and Convolutional Neural Network(k-Nearest Neighbor와 Convolutional Neural Network에 의한 
제재목 표면 옹이 종류의 화상 분류)",2019,"['visual classification', 'knot classification', 'k-nearest neighbor', 'convolution neural network', 'deep learning', 'species identification', 'wood classification']",,"Various wood defects occur during tree growing or wood processing. Thus, to use wood practically, it is necessary to objectively assess their quality based on the usage requirement by accurately classifying their defects. However, manual visual grading and species classification may result in differences due to subjective decisions; therefore, computer-vision-based image analysis is required for the objective evaluation of wood quality and the speeding up of wood production. In this study, the SIFT+k-NN and CNN models were used to implement a model that automatically classifies knots and analyze its accuracy. Toward this end, a total of 1,172 knot images in various shapes from five domestic conifers were used for learning and validation. For the SIFT+k-NN model, SIFT technology was used to extract properties from the knot images and k-NN was used for the classification, resulting in the classification with an accuracy of up to 60.53% when k-index was 17. The CNN model comprised 8 convolution layers and 3 hidden layers, and its maximum accuracy was 88.09% after 1205 epoch, which was higher than that of the SIFT+k-NN model. Moreover, if there is a large difference in the number of images by knot types, the SIFT+k-NN tended to show a learning biased toward the knot type with a higher number of images, whereas the CNN model did not show a drastic bias regardless of the difference in the number of images. Therefore, the CNN model showed better performance in knot classification. It is determined that the wood knot classification by the CNN model will show a sufficient accuracy in its practical applicability."
딥러닝 기반의 복합 열화 영상 분류 및 복원 기법,2019,"['Deep learning', 'Multi-Degradation', 'Degradation Classification', 'Restoration order', 'Restoration']","CNN (convolutional neural network) 기반의 단일 열화 영상 복원 방법은 우수한 성능을 나타내지만 한가지의 특정 열화를 해결하는 데 맞춤화 되어있다. 본 연구에서는 복합적으로 열화 된 영상 분류 및 복원을 위한 알고리즘을 제시한다. 복합 열화 영상 분류 문제를 해결하기 위해 CNN 기반의 알고리즘인 사전 학습된 Inception-v3 네트워크를 활용하고, 영상 열화 복원을 위해 기존의 CNN 기반의 복원 알고리즘을 사용하여 툴체인을 구성한다. 실험적으로 복합 열화 영상의 복원 순서를 추정하였으며, CNN 기반의 영상 화질 측정 알고리즘의 결과와 비교하였다. 제안하는 알고리즘은 추정된 복원 순서를 바탕으로 구현되어 실험 결과를 통해 복합 열화 문제를 효과적으로 해결할 수 있음을 보인다.",
딥러닝 기반의 보행자 탐지 및 경보 시스템 연구,2019,"['Pedestrian traffic accident prevention', 'CNN', 'YOLO', 'ITS', 'UTIS', '보행자 교통사고 방지', 'CNN', 'YOLO', '지능형 교통시스템 체계', 'UTIS']","보행자 교통사고의 경우 사고 발생 시 사망사고로 연결되는 위험성이 있다. 국내 지능형교통시스템(ITS)은 질 좋은 교통 인프라를 구축하고 있음에도 불구하고, 거의 교통정보 수집에만 이용되고 있어, 위험상황 발생 시 지능적인 위험 요소 분류가 이루어지지 않고 있다. 본 연구에서 제안하는 시스템의 주요 구성 요소인 CNN 기반의 보행자 탐지 분류 모델의 경우 제한적인 환경에서 설치 운영되는 것을 가정하여 임베디드 시스템 기반으로 구현되었다. 기존YOLO의 인공신경망 모델을 개선하여 My-Tiny-Model3라는 새로운 모델을 생성하였고, 20,000 번의 반복 학습 기준으로 평균 정확도 86.29%와 21.1 fps의 실시간 탐지 속도 결과를 보였다.그리고, 이러한 탐지 시스템을 기반으로 하여 ITS 체계와 연계 가능한 시스템 구현 및 프로토콜 연동 시나리오를 구성하였다. 본 연구를 통해 기존 ITS 체계와 연동하는 보행자 사고 방지시스템을 구현한다면, 새로운 인프라 구축비용을 절감하고 보행자 교통사고 발생률을 줄이는데 도움이 될 것이다. 또한, 기존의 시스템 감시인력 소요에 따른 비용 또한 줄일 수 있을 것으로 기대된다.","In the case of a pedestrian traffic accident, it has a large-scale danger directly connected by a fatal accident at the time of the accident. The domestic ITS is not used for intelligent risk classification because it is used only for collecting traffic information despite of the construction of good quality traffic infrastructure. The CNN based pedestrian detection classification model, which is a major component of the proposed system, is implemented on an embedded system assuming that it is installed and operated in a restricted environment. A new model was created by improving YOLO's artificial neural network, and the real-time detection speed result of average accuracy 86.29% and 21.1 fps was shown with 20,000 iterative learning. And we constructed a protocol interworking scenario and implementation of a system that can connect with the ITS. If a pedestrian accident prevention system connected with ITS will be implemented through this study, it will help to reduce the cost of constructing a new infrastructure and reduce the incidence of traffic accidents for pedestrians, and we can also reduce the cost for system monitoring."
인공지능 기반 MNIST 손글씨 인식에 대한 연구,2019,"['Handwriting', 'SLR', 'ANN', 'CNN', 'Deep learning', '손글씨', '소프트맥스 회귀분석', '인공신경망', '합성곱신경망', '딥러닝']",,"In the development of electronic devices such as PDAs, smartphones, and tablets, research on handwriting recognition has emerged. In the meantime, there have been efforts to recognize various handwriting such as numbers, Japanese, and English. However, there is a point that it is difficult to recognize when the font shape is relatively irregular, such as handwriting of children. As a result, the need for research to improve handwriting recognition rate by applying deep learning techniques has recently been raised. Therefore, this study attempted to improve handwriting recognition rate based on various deep learning techniques. In the case of handwriting, it is difficult to prepare a variety of data sets, which limits the recognition rate. In this study, we tried to improve the accuracy of handwriting recognition by using CNN technique in order to find a way to overcome these limitations. The techniques used were SLR, ANN, and CNN, each measuring the accuracy of each method. As a result, CNN showed the highest performance of 95%."
ResNet 모델을 이용한 눈 주변 영역의 특징 추출 및 개인 인증,2019,"['Periocular Region', 'Authentication', 'CNN', 'MLP']",,"Deep learning approach based on convolution neural network (CNN)  has extensively studied in the field of computer vision. However, periocular feature extraction using CNN was not well studied because it is practically impossible to collect large volume of biometric data. This study uses the ResNet model which was trained with the ImageNet dataset. To overcome the problem of insufficient training data, we focused on the training of multi-layer perception (MLP) having simple structure rather than training the CNN having complex structure. It first extracts features using the pretrained ResNet model and reduces the feature dimension by principle component analysis (PCA), then trains a MLP classifier. Experimental results with the public periocular dataset UBIPr show that the proposed method is effective in person authentication using periocular region. Especially it has the advantage which can be directly applied for other biometric traits."
영상처리와 딥러닝 기법을 사용한 채소의 등급별 자동 분류시스템 개발,2019,"['채소 자동분류 시스템', '기계학습 기법', 'CNN', 'VGGNet', '오이 실험영상.', 'vegetable automatic classification system', 'machine learning techniques', 'CNN', 'VGGNet', 'cucumber experiment image.']","농업에서 생산된 과수나 채소에 대한 질을 확인하고 향상시키는 작업은 영상처리에서 굉장히 중요한 부분이다. 실제 농가에서는 스마트팜(smart_farm)을 도입하여 생산량의 증가로 자연히 수익을 늘어나고 또 노동시간이 단축되며 여가시간이 늘어 농가의 삶의 질을 높일 수 있게 되었다. 본 논문에서는 영상처리 기법과 딥러닝 기술을 사용하여 채소의 등급을 자동 분류하기 위한 시스템을 소개한다. 이를 목적으로 농가에서 직접 재배한 오이를 동일한 배경에서 촬영하여 이미지 데이터와 데이터 증가(augmentation) 기법을 통해 데이터셋을 구성하고 3가지 등급으로 분류하기 위한 기계학습방법인 SVM과 딥러닝 방법인 CNN, VGGNet 등을 사용하였다. 또한 본 연구는 대규모 데이터에서 오이를 기계가 자동으로 중요한 패턴과 규칙을 학습하고 의사결정과 예측 등을 하기 위해 구조나 손실 및 활성화 함수들 그리고 학습비율과 같은 하이퍼 파라미터(hyper-parameter)등을 변경시켜 가며 더 좋은 분류 성능을 내는 알고리즘을 개발하였다. 또한 실험을 통해서 제안된 알고리즘이 농업현장에서 취득한 영상자료를 사용해서 오이를 등급별로 잘 구별하는 것을 확인 할 수 있었다. 앞으로 이를 발전시켜 더 좋은 데이터를 많이 확보하고 훈련을 시킨다면 자동분류 시스템의 개발에 더 좋은 성능이 기대되며, 다양한 방면에 활용이 가능 할 것이다.","Identifying and improving the quality of fruits and vegetables produced in agriculture is a very important part of image processing. The introduction of smart_farm in the farmhouse increased production and naturally increased profit of the farmer. In addition, their working hours have been shortened and leisure time has been increased, so that the quality of life of the farmers can be increased. In this paper, we introduce a system for automatically classifying vegetable grades using image processing and deep-learning techniques. For this purpose, We obtained image data of cucumber cultivated directly in a farmhouse on the same background and constructed a data set using data augmentation technique. In order to classify cucumber into three classes, we used SVM, which is a machine running method, and CNN and VGGNet, which are deep running methods. In this study, we also modified the hyper-parameters such as structure, loss and activation functions and learning rate in order to learn the important patterns and rules of the machine automatically from large data and to make decisions and predictions. Experimental results show that the proposed algorithm can distinguish the cucumber by grade using image data obtained from farming sites. If we improve the performance of the automatic classification system by securing much better data and training, then it can be applied to various aspects."
Convolutional neural network based surface inspection system for non-patterned welding defects,2019,['Defect detection Automatic inspection Convolutional neural network Machine vision Image processing Deep learning'],,"In this paper, we propose a convolutional neural network (CNN) based method that inspects non-patterned welding defects (craters, pores, foreign substances and fissures) on the surface of the engine transmission using a single RGB camera. The proposed method consists of two steps: first, extracting the welding area to be inspected from the captured image, and then determining whether the extracted area includes defects. In the first step, to extract the welding area from the captured image, a CNN based approach is proposed to detect a center of the engine transmission in the image. In the second stage, the extracted area is identified by another CNN as defective or non-defective. To train the second stage CNN stably, we propose a class-specific batch sampling method. With our sampling method, biased learning caused by data imbalance (number of collected defective images is much less than that of non-defective images) is effectively prevented. We evaluated our system with a large amount of samples (about 32,000 images) collected manually from the production line, and our system shows a remarkable performance in all experiments."
문장 레벨 그래프 회선 신경망을 통한 텍스트 분류,2019,"['natural language processing', 'neural networks', 'graph convolutional networks', 'textgraph', 'graph classification', 'text classification', '자연어 처리', '인공 신경망', '그래프 회선 신경망', '텍스트그래프', '그래프 분류', '텍스트 분류']","텍스트 분류는 자연어처리 분야의 전통적인 문제이다. 기존의 RNN 및 CNN 기반 텍스트 분류 모델들은 순차적인 단어 구조에 의존하기 때문에 인접하지 않지만 관련성이 높은 단어 간의 관계를 유추하기 어렵다는 문제점이 있다. 반면 GCN(Graph Convolutional Network)은 그래프의 형태로 데이터를 입력받기 때문에 문장의 순차적 구조에 대한 의존도를 줄일 수 있다. 본 논문에서는 문서의 비순차적인 관계를 그래프로 담아내어 더욱 효과적으로 파악하고 분류하는 인공신경망 모델을 제안한다. 문서를 그래프로 표현하기 위해 각 단어를 그래프의 노드로 변환하고, 단어 간의 관계를 계산해 엣지로 정의한다. 최근에 제시된 GCN 구조를 통해 단어 간의 관계가 반영된 단어 벡터를 계산한 뒤, 어텐션 기반 요약 함수를 통해 문단을 주어진 클래스로 분류하는 방법을 제시한다. 실험 결과, 새롭게 제시된 모델이 RNN 및 CNN 기반 텍스트 분류 모델보다 좋은 성능을 보였다.","Text classification is an important task in natural language processing, and most of the recent approaches employ neural networks to learn and classify the texts. RNN and CNN based models, which are widely used for solving the task, involve reading and processing the text in a sequential manner. This creates inefficiency in learning dependencies between far-apart words. On the contrary, Graph Convolutional Network (GCN) architecture is capable of processing more complex graph-structured data, thus having potential to recognize and learn from complex linguistic structures.In the present work, we transform text sequences into graphs by assigning each word in the text as a node and representing the relationship between words as edges. We then propose a method for solving text classification that uses recent GCN architectures to take the transformed text-graph as input, learn hidden representations, and output a single hidden representation for classification. In our experiments, our proposed model outperformed RNN and CNN based models with regards to various text classification tasks."
합성곱 신경망을 이용한 보청기 환경잡음 분류 알고리즘,2019,"['Hearing aids', 'Noise classification', 'convolutional neural networks', 'Spectrogram', 'Hearing aids satisfaction']","본 논문은 보청기의 환경잡음 분류를 위해 소리 신호를 이미지 신호로 변환하여 합성곱 신경망(CNN, convolutional neural networks)을 적용한 잡음 분류 알고리즘에 관한 것이다. 장시간 현장 녹음한 생활 잡음을 이미지 신호로 변환하기 위해 스펙트로그램을 확인하고, sharpening mask와 median filter를 적용하여 합성곱 신경망 기법의 분류 결과를 비교하였다. 1초/2.5초/5초 단위 시간의 스펙트로그램 이미지 분류 결과, 1초의 합성곱 신경망 분류율이 가장 높았으며, 단위 시간이 증가 할수록 분류율이 감소하였다. 합성곱 신경망의 입력 데이터에 제안된 필터를 적용하여 분류율 결과를 비교했을 때, 필터를 적용하지 않은 스펙트로그램 이미지를 분류율이 median filter를 적용했을 때보다 최대 약 2.8% 상승한 것을 확인하였다.","In this paper, we present the environment noise classification algorithm using CNN(convolutional neural networks) for hearing aids by converting a sound signal to an image signal. We made spectrogram images from sound signal which have recorded the environment noise around hearing aids, and results of classification using CNN were compared by applying Sharpening Mask and Median Filter. As a result of the spectrogram image classification rate in 1sec. was the highest, and the classification rate was decreased as the time increased to 5sec. When comparing the proposed classification rate results according to the CNN input data, the classification rate without the filter was up to about 2.8% higher than that with the median filter."
Effect of Data Augmentation of F-18-Florbetaben Positron-Emission Tomography Images by Using Deep Learning Convolutional Neural Network Architecture for Amyloid Positive Patients,2019,"['Alzheimer’s disease (AD)', 'Mild cognitive impairment (MCI)', 'F-18-Florbetaben (F-18-FBB)', 'Amyloid PET', 'Convolutional neural network (CNN)', 'Artificial intelligence (AI)']",,"Early diagnosis of dementia helps in finding suitable treatments that reduce or even prevent future cognitive dysfunction of patients. In this paper, we use a convolutional neural network to classify the brain positron-emission tomography (PET) image of Alzheimer’s disease (AD) and mild cognitive impairment (MCI) in a normal control (NC). The purpose of this study is to investigate the influence of the data increment method and the number of data for the best accuracy in the convolutional neural network (CNN) by using the AlexNet algorithm with amyloid PET images. All subjects had an intravenous injection of 300 MBq of F-18-Florbetaben (F-18-FBB, Piramal Imaging, Berlin), and PET acquisition was started 90 min after the radio-tracer injection. The image data were classified into NC, MCI and AD based on the findings of the neurologist. We performed data augmentation using a method such as flip, rotation, and GAN, in addition to pre-processing and data augmentation for AlexNet, in order to supplement a number of deficient data. Artificial intelligence (AI) learning was simulated using the Mini-batch Stochastic Gradient Descent (MSGD) algorithm, and the learning rate was 5e-5, and the epoch was 100. Using a CNN and the ‘AlexNet’ architecture, we successfully classified F-18-FBB PET images of AD from NC where the accuracy of the test data on trained data reached 98.14%. In this work, the CNN, which is a deep learning neural network architecture, was used in order to distinguish AD and MCI from the NC. Accuracy was 98.33%, NC recall was 99.16%, MCI recall was 95.83% and AD recall was 98.16% after learning the data by using rotation and LR flip to increase the number of data. The accuracy was increased by 4.96%, NC recall was increased by 10.68%, MCI recall was decreased by 0.23%, and AD recall was increased by 9.65% after learning the data by using DCGAN to increase the number of data to 4020. Accuracy and recall were improved when data were learned through data augmentation by rotation and by left and right reversal. However, the effect of learning data by increasing the data by using up-down reversal and data augmentation through DCGAN was almost insignificant."
Pest Control System using Deep Learning Image Classification Method,2019,"['Image Processing', 'Convolutional Neural Network', 'Background Subtraction', 'Classification']",,"In this paper, we propose a layer structure of a pest image classifier model using CNN (Convolutional Neural Network) and background removal image processing algorithm for improving classification accuracy in order to build a smart monitoring system for pine wilt pest control. In this study, we have constructed and trained a CNN classifier model by collecting image data of pine wilt pest mediators, and experimented to verify the classification accuracy of the model and the effect of the proposed classification algorithm. Experimental results showed that the proposed method successfully detected and preprocessed the region of the object accurately for all the test images, resulting in showing classification accuracy of about 98.91%. This study shows that the layer structure of the proposed CNN classifier model classified the targeted pest image effectively in various environments. In the field test using the Smart Trap for capturing the pine wilt pest mediators, the proposed classification algorithm is effective in the real environment, showing a classification accuracy of 88.25%, which is improved by about 8.12% according to whether the image cropping preprocessing is performed. Ultimately, we will proceed with procedures to apply the techniques and verify the functionality to field tests on various sites."
CycleGAN을 이용한 야간 상황 물체 검출 알고리즘,2019,"['CycleGAN', 'Data Sampling', 'Image-to-Image Translation']",,"Recently, image-based object detection has made great progress with the introduction of Convolutional Neural Network (CNN). Many trials such as Region-based CNN, Fast R-CNN, and Faster R-CNN, have been proposed for achieving better performance in object detection. YOLO has showed the best performance under consideration of both accuracy and computational complexity. However, these data- driven detection methods including YOLO have the fundamental problem is that they can not guarantee the good performance without a large number of training database. In this paper, we propose a data sampling method using CycleGAN to solve this problem, which can convert styles while retaining the characteristics of a given input image. We will generate the insufficient data samples for training more robust object detection without efforts of collecting more database. We make extensive experimental results using the day-time and night-time road images and we validate the proposed method can improve the object detection accuracy of the night-time without training night-time object databases, because we converts the day-time training images into the synthesized night-time images and we train the detection model with the real day-time images and the synthesized night-time images."
A Comparative Study on OCR using Super-Resolution for Small Fonts,2019,"['Korean OCR', 'Tesseract', 'Super-resolution', 'Text-recognition', 'and Deep-learning']",,"Recently, there have been many issues related to text recognition using Tesseract. One of these issues is that the text recognition accuracy is significantly lower for smaller fonts. Tesseract extracts text by creating an outline with direction in the image. By searching the Tesseract database, template matching with characters with similar feature points is used to select the character with the lowest error. Because of the poor text extraction, the recognition accuracy is lowerd. In this paper, we compared text recognition accuracy after applying various super-resolution methods to smaller text images and experimented with how the recognition accuracy varies for various image size. In order to recognize small Korean text images, we have used super-resolution algorithms based on deep learning models such as SRCNN, ESRCNN, DSRCNN, and DCSCN. The dataset for training and testing consisted of Korean-based scanned images. The images was resized from 0.5 times to 0.8 times with 12pt font size. The experiment was performed on x0.5 resized images, and the experimental result showed that DCSCN super-resolution is the most efficient method to reduce precision error rate by 7.8%, and reduce the recall error rate by 8.4%. The experimental results have demonstrated that the accuracy of text recognition for smaller Korean fonts can be improved by adding super-resolution methods to the OCR preprocessing module."
Research on Concrete Cracks Recognition based on Dual Convolutional Neural Network,2019,"['concrete bridges', 'bridge inspection', 'recognition of cracks', 'double convolutional neural network model', 'structure of merging layer-by-layer']",,"Cracks are the most common and important diseases of concrete bridges. A dual convolutional neural network (DCN) model which is composed of one convolutional neural network (CNN) model and one fully convolutional network (FCN) model is proposed to recognize the cracks in image. Firstly, the CNN model is used to identify the crack area. The interfering factors such as spot, shadow, water stain, and graffiti in the non-crack area will be excluded by CNN model. Then, the CNN results will be segmented by the FCN model with the structure of merging layer-by-layer to extract crack features such as length and width. The DCN model is trained to recognize the actual concrete bridge cracks in this paper. The recognition results show that the DCN model has a good balance between high accuracy and low noise in the process of crack recognition compared with the current image recognition method. The reliability and accuracy of recognition are both greatly improved. The DCN model is helpful for automatic identification of cracks in concrete bridges."
심층 신경회로망들을 사용한 기흉 진단,2019,"['Convolutional Neural Networks', 'U-Net', 'EfficientNet', 'ResNetM', 'ask-RCNN', 'Xecption']","기흉은 가슴에 공기가 차는 것으로, 일반적으로 흉부 엑스레이를 사용하여 진단한다. 데이터 전처리를 하였고, 전처리방법으로는 결측값 제거 및 마스킹을 하였다. 최근에 와서 심층신경망의 성능이 개선됨에 따라서 활발히 사용되고 있고, 특히 영상인식에 적용되어 기존의 방법에 비하여 향상된 성능을 보이고 있다.기흉을 진단하는데 U-Net, Mask R-CNN, Resnet, EfficientNet, Xception을 사용하였으며, 이 심층 신경 회로망들의 성능을 비교하였다. U-Net은 Sementic Segmentation을사용하였고, Mask R-CNN은 Instance Segmentation을 사용하였다. Sementic Segmentation은 분할의 기본 단위를 클래스로하여, 동일한 클래스에 속하는 사물은 예측마스크 상에 동일한 색깔로 표시한다. Instance Segmentation은 분할의 기본단위를 사물로 하여, 동일한 클래스에 속하더 라도 다른 사물에 해당하면 예측 마스크 상에 다른 색깔로 표시한다. 실험 결과EfficientNet의 성능이 가장 좋았다. 이는 의사의 기흉 진단을 보조하기에 충분한 성능으로 의사를 도와 기흉을 진단하는데효율적으로 이용 될 수 있다.","A Pneumothorax is an abnormal collection of air in the space between lung and chest wall and is diagnosed using chest X-ray. Preprocessings, such as the eliminaton of missing value and masking, were performed. Performances of U-Net, Mask R-CNN, Resnet, EfficientNet and Xception for diagnosing pneumothorax are compared. U-Net uses semantic segmentation and Mask R-CNN uses instance segmentation. Semantic segmentation uses a class as the unit of segmentation. Therefore, objects in the same class are denoted using the same color on the prediction mask. On the other hand, instance segmentation uses object as the unit of segmentation. Therefore, objects in the same class are denoted using the different color on the prediction mask, if they belong to the different objects. EfficientNet got the best result. It can be efficiently used because it performs well enough to assist for physicians to diagnose pneumothorax using the chest X-ray"
멀티 뷰 기법 리뷰: 이해와 응용,2019,"['멀티 뷰 학습', '딥 러닝', '기계학습', '데이터 통합', 'multi-view learning', 'multi-modal learning', 'deep learning', 'machine learning', 'data integration']","멀티 뷰 기법은 데이터를 다양한 관점에서 보려는 접근 방법이며 데이터의 다양한 정보를 통합하여 사용하려는 시도이다. 최근 많은 연구가 진행되고 있는 멀티 뷰 기법에서는 단일 뷰 만을 이용하여 모형을 학습시켰을 때 보다 좋은 성과를 보인 경우가 많았다. 멀티 뷰 기법에서 딥 러닝 기법의 도입으로 이미지, 텍스트, 음성, 영상 등 다양한 분야에서 좋은 성과를 보였다. 본 연구에서는 멀티 뷰 기법이 인간 행동 인식, 의학, 정보 검색, 표정 인식 분야에서 직면한 여러 가지 문제들을 어떻게 해결하고 있는지 소개하였다. 또한 전통적인 멀티 뷰 기법들을 데이터 차원, 분류기 차원, 표현 간의 통합으로 분류하여 멀티 뷰 기법의 데이터 통합 원리를 리뷰 하였다. 마지막으로 딥 러닝 기법 중 가장 범용적으로 사용되고 있는 CNN, RNN, RBM, Autoencoder, GAN 등이 멀티 뷰 기법에 어떻게 응용되고 있는지를 살펴보았다. 이때 CNN, RNN 기반 학습 모형을 지도학습 기법으로, RBM, Autoencoder, GAN 기반 학습 모형을 비지도 학습 기법으로 분류하여 이 방법들이 대한 이해를 돕고자 하였다.","Multi-view learning considers data from various viewpoints as well as attempts to integrate various information from data. Multi-view learning has been studied recently and has showed superior performance to a model learned from only a single view. With the introduction of deep learning techniques to a multi-view learning approach, it has showed good results in various fields such as image, text, voice, and video. In this study, we introduce how multi-view learning methods solve various problems faced in human behavior recognition, medical areas, information retrieval and facial expression recognition. In addition, we review data integration principles of multi-view learning methods by classifying traditional multi-view learning methods into data integration, classifiers integration, and representation integration. Finally, we examine how CNN, RNN, RBM, Autoencoder, and GAN, which are commonly used among various deep learning methods, are applied to multi-view learning algorithms. We categorize CNN and RNN-based learning methods as supervised learning, and RBM, Autoencoder, and GAN-based learning methods as unsupervised learning."
몰포러지 신경망 기반 딥러닝 시스템,2019,"['CNN', 'Deep Learning', 'Embedded System', 'MNN', 'Morphology', 'VLSI']","본 논문에서는 몰포러지 연산을 기본으로 하는 몰포러지 신경망(MNN: Morphological Neural Network) 기반 딥러닝 시스템을 제안하였다. 딥러닝에 사용되는 레이어는 몰포러지 레이어, 풀링 레이어, ReLU 레이어, Fully connected 레이어 등이다. 몰포러지 레이어에서 사용되는 연산은 에로전, 다이레이션, 에지검출 등이다. 본 논문에서 새롭게 제안한 MNN은 기존의 CNN(Convolutional Neural Network)을 이용한 딥러닝 시스템과는 달리 히든 레이어의 수와 각 레이어에 적용되는 커널 수가 제한적이다. 레이어 단위 처리시간이 감소하고, VLSI 칩 설계가 용이하다는 장점이 있으므로 모바일 임베디드 시스템에  딥러닝을 다양하게 적용할 수 있다. MNN에서는 제한된 수의 커널로 에지와 형상검출 등의 연산을 수행하기 때문이다. 데이터베이스 영상을 대상으로 행한 실험을 통해 MNN의 성능 및 딥러닝 시스템으로의 활용 가능성을 확인하였다.","In this paper, we propose a deep learning system based on morphological neural network(MNN). The deep learning layers are  morphological operation layer, pooling layer, ReLU layer, and the fully connected layer. The operations used in morphological layer are erosion, dilation, and edge detection, etc. Unlike CNN, the number of hidden layers and kernels applied to each layer is limited in MNN. Because of the reduction of processing time and utility of VLSI chip design, it is possible to apply MNN to various mobile  embedded systems. MNN performs the edge and shape detection operations with a limited number of kernels. Through experiments using database images, it is confirmed that MNN can be used as a deep learning system and its performance."
Best Practices on Educational Service Platform with AI Approach,2019,"['CNN Algorithm', 'Education', 'Recommendation', 'User Focused.']",,"The current education is becoming more extensive with the application of various teaching methods. This is a problem that is so distributed that it is difficult for users to find the data and it takes a long time to find the information they need. Currently, various educational services, materials, and instruments are developed and scattered. Therefore, it is important to raise students' awareness of aptitude and career path with customized education tailored to students. Conventional education platforms have very difficult to choose the right materials for students because of the spread of educational programs and institution materials. To solve this, we propose a customized recommendation approach to recommend customized educational service materials and institution for students to teachers, which helps teachers conveniently choose materials suitable for their respective environments. On this new platform, the CNN algorithm provides recommended content for classes and students. For real service on the educational service platform, we implement this system for Jeil edus business . Through this mechanism, we expect to improve the quality of education by helping to select the right service."
A Comparative Study of Alzheimer’s Disease Classification using Multiple Transfer Learning Models,2019,"['Alzheimer’s disease', 'CNN', 'MR images', 'Transfer learning.']",,"Over the past decade, researchers were able to solve complex medical problems as well as acquire deeper understanding of entire issue due to the availability of machine learning techniques, particularly predictive algorithms and automatic recognition of patterns in medical imaging. In this study, a technique called transfer learning has been utilized to classify Magnetic Resonance (MR) images by a pre-trained Convolutional Neural Network (CNN). Rather than training an entire model from scratch, transfer learning approach uses the CNN model by fine-tuning them, to classify MR images into Alzheimer’s disease (AD), mild cognitive impairment (MCI) and normal control (NC). The performance of this method has been evaluated over Alzheimer’s Disease Neuroimaging (ADNI) dataset by changing the learning rate of the model. Moreover, in this study, in order to demonstrate the transfer learning approach we utilize different pre-trained deep learning models such as GoogLeNet, VGG-16, AlexNet and ResNet-18, and compare their efficiency to classify AD. The overall classification accuracy resulted by GoogLeNet for training and testing was 99.84% and 98.25% respectively, which was exceptionally more than other models training and testing accuracies."
센서 및 카메라 비전을 활용한 OPC UA 기반 협동로봇 가드 시스템의 설계 및 구현,2019,"['Collaborative Robot Guard System', 'CNN', 'OPC UA']","제조 패러다임 변화에 따라 다양한 협동로봇이 신규시장을 창출하고 있다. 협동로봇은 기존 산업용 로봇 대비쉬운 운용, 생산성 향상, 단순 작업을 하는 인력을 대체하는 목적으로 모든 산업에서 협동로봇의 수요가 증가하고 있다.그러나 산업현장에서 협동로봇으로 인한 작업 중 사고가 빈번하게 발생하고 있으며, 작업자의 안전을 위협하고 있다.인간 중심의 환경에서 로봇을 통한 산업현장이 구성되려면 작업자의 안전을 보장해야 하며 출동 가능성을 업애고 신뢰할수 있는 통신을 하는 협동로봇 가드 시스템의 개발의 필요성이 있다. 센서 및 컴퓨터 비전을 통해 협동로봇의 작업 반경내에서 발생하는 사고를 이중으로 방지하고 안전사고 위험을 감소시켜야 한다. 다양한 산업용 장비와 통신을 위한 국제프로토콜인 OPC UA를 기반으로 시스템을 구축하고 초음파 센서와 CNN(Convolution Neural Network)적용한 영상분석을 통한 협동로봇 가드 시스템을 제안한다. 제안 된 시스템은 작업자의 불안전한 상황에서 로봇 제어의 가능성을평가한다.","The robot is the creation of new markets and various cooperation according to the manufacturing paradigm shift. Cooperative management easy for existing industrial robots, robots work on productivity, manpower to replace the robot in every industry cooperation for the purpose of and demand increases.to exist But the industrial robot at the scene of the cooperation working due to accidents are frequent, threatening the safety of the operator. Of industrial site is configured with a robot in an environment ensuring the safety of the operator to and confidence to communicate that can do the possibility of action.Robot guard system of the need for development cooperation. The robot's cooperation through the sensors and computer vision task within a radius of the double to prevent accidents and accidents should reduce the risk. International protocol for a variety of industrial production equipment and communications opc ua system based on ultrasonic sensors and cnn to (Convolution Neural Network) for video analytics.We suggest the cooperation with the robot guard system. Robots in a proposed system is unsafe situation of workers evaluating the possibility of control."
"안전도, 뇌파도, 근전도 분석을 통한 수면 단계 분류",2019,"['Sleep Stage Classification', 'CNN Algorithm', 'DNN Algorithm', 'EEG', 'EOG', 'EMG', 'Polysomnography']",,"Insufficient sleep time and bad sleep quality causes many illnesses and it’s research became more and more important. The most common method for measuring sleep quality is the polysomnography(PSG). The PSG is a test used to diagnose sleep disorders. The most common PSG data is obtained from the examiner, which attaches several sensors on a body and takes sleep overnight. However, most of the sleep stage classification in PSG are low accuracy of the classification. In this paper, we have studied algorithm for sleep level classification based on machine learning which can replace PSG. EEG, EOG, and EMG channel signals are studied and tested by using CNN algorithm. In order to compensate the performance, a mixed model using both CNN and DNN models is designed and tested for performance."
앙상블 학습 알고리즘을 이용한 컨벌루션 신경망의 분류 성능 분석에 관한 연구,2019,"['Deep Learning', 'Computer Vision', 'CNN', 'Ensemble Learning Algorithm']",,"In this paper, we compare and analyze the classification performance of deep learning algorithm Convolutional Neural Network(CNN) ac cording to ensemble generation and combining techniques. We used several CNN models(VGG16, VGG19, DenseNet121, DenseNet169, DenseNet201, ResNet18, ResNet34, ResNet50, ResNet101, ResNet152, GoogLeNet) to create 10 ensemble generation combinations and applied 6 combine techniques(average, weighted average, maximum, minimum, median, product) to the optimal combination. Experimental results, DenseNet169-VGG16-GoogLeNet combination in ensemble generation, and the product rule in ensemble combination showed the best performance. Based on this, it was concluded that ensemble in different models of high benchmarking scores is another way to get good results."
MODIFIED CONVOLUTIONAL NEURAL NETWORK WITH TRANSFER LEARNING FOR SOLAR FLARE PREDICTION,2019,"['magnetic fields', 'Sun: activity', 'Sun: ares', 'techniques: image processing']",,"We apply a modified Convolutional Neural Network (CNN) model in conjunction with transfer learning to predict whether an active region (AR) would produce a ≥C-class or ≥M-class are within the next 24 hours. We collect line-of-sight magnetogram samples of ARs provided by the SHARP from May 2010 to September 2018, which is a new data product from the HMI onboard the SDO. Based on these AR samples, we adopt the approach of shuffle-and-split cross-validation (CV) to build a database that includes 10 separate data sets. Each of the 10 data sets is segregated by NOAA AR number into a training and a testing data set. After training, validating, and testing our model, we compare the results with previous studies using predictive performance metrics, with a focus on the true skill statistic (TSS). The main results from this study are summarized as follows. First, to the best of our knowledge, this is the first time that the CNN model with transfer learning is used in solar physics to make binary class predictions for both ≥C-class and ≥M-class ares, without manually engineered features extracted from the observational data. Second, our model achieves relatively high scores of TSS = 0.6400.075 and TSS = 0.5260.052 for ≥M-class prediction and ≥C-class prediction, respectively, which is comparable to that of previous models. Third, our model also obtains quite good scores in five other metrics for both ≥C-class and ≥M-class are prediction. Our results demonstrate that our modified CNN model with transfer learning is an effective method for are forecasting with reasonable prediction performance."
목적 지향 대화를 위한 효율적 질의 의도 분석에 관한 연구,2019,"['Intent-Analysing', 'Goal-oriented Dialogue', 'CNN(Convolutional Neural Network)', 'concept-sequence', 'speech-act']",,"The purpose of this study is to understand the intention of the inquirer from the single text type question in Goal-oriented dialogue. Goal-Oriented Dialogue system means a dialogue system that satisfies the user’s specific needs via text or voice. The intention analysis process is a step of analysing the user’s intention of inquiry prior to the answer generation, and has a great influence on the performance of the entire Goal-Oriented Dialogue system. The proposed model was used for a daily chemical products domain and Korean text data related to the domain was used. The analysis is divided into a speech-act which means independent on a specific field concept-sequence and which means depend on a specific field. We propose a classification method using the word embedding model and the CNN as a method for analyzing speech-act and concept-sequence. The semantic information of the word is abstracted through the word embedding model, and concept-sequence and speech-act classification are performed through the CNN based on the semantic information of the abstract word."
Parkinson’s disease based on deep learning using MR images,2019,"['Parkinson’s Disease', 'Faster R-CNN', 'CNN', 'Deep Learning']",,"Magnetic resonance imaging has become an indispensable aid in the Parkinson's disease. The traditional method of analysis is that the patient takes an MR image of the brain and then the doctor analyzes the MR image for diagnosis. However, due to the poor quality of MR images and the high noise, it is difficult for doctors to diagnose, and the professional requirements for doctors are relatively high when analyzing nuclear magnetic resonance images. This paper proposed a MR image classification algorithm based on deep learning. The algorithm is mainly divided into two phases. The first phase is to detect the diagnostic region of the MR image by the improved Faster RCNN network. The second phase is to classify the diagnostic areas detected in the previous phase through our custom CNN network. We tested the algorithm using MR images of Parkinson's disease. The experimental results show that the accuracy of MR image detection and classification can be greatly improved by algorithm improvement."
Low-complexity 1D-convolutional Neural Network for Super Resolution,2019,"['Super-resolution', 'Deep-learning', 'Low-complexity', 'CNN']",,"This paper proposes a method for accelerating deep learning based super-resolution technology. In order to alleviate the complexity of the deep learning based super-resolution technology, the proposed method extracts the horizontal and vertical high-frequency signals separately using one-dimensional filters. Then, the final super-resolution image is obtained by the proposed network from the horizontal and vertical high-frequency signals and the low-resolution input image. The proposed method requires a low computational complexity by using only onedimensional filters due to a smaller number of weights. The proposed method in the high-resolution image restoration experiment shows that the average visual quality in PSNR and SSIM is comparable to ones of VDSR. However, the average speed performance is accelerated by 86.57%."
딥러닝 모델 기반 단기 전력수요 예측,2019,"['Deep Learning', 'Short-Term Load Forecasting', 'CNN', 'LSTM']",,"This paper presents a Short-Term Long-short term memory Convolutional neural network(STLC) Model that is combined with Convolutional Neural Network(CNN) and Long-Short Term Memory(LSTM). CNN model predicts load pattern using past load profile, LSTM model forecasts load variation depending on temperature and time index. STLC model’s output is hourly load data to combine two model’s outputs. The input parameters of STLC model are composed of time index, weighted weather data, past load data. Weights are calculated based on electricity consumption by main region in South Korea and reflects in the weather data. STLC model is trained with data from 2013 through 2017 and is verified with data from 2018. The STLC model forecasts 1-day hourly load data. Simulation results obtained show the comparison of actual and forecasted load data and also compare with other methods in MAPE(Mean Absolute Percentage Error) to prove accuracy of the proposed model."
Deep Learning and Color Histogram based Fire and Smoke Detection Research,2019,"['Fire Detection', 'Deep Learning', 'Structure Similarity', 'Frame Difference. Color Histogram.']",,"The fire should extinguish as soon as possible because it causes economic loss and loses precious life. In this study, we propose a new atypical fire and smoke detection algorithm using deep learning and color histogram of fire and smoke. First, input frame images obtain from the ONVIF surveillance camera mounted in factory search motion candidate frame by motion detection algorithm and mean square error (MSE). Second deep learning (Faster R-CNN) is used to extract the fire and smoke candidate area of motion frame. Third, we apply a novel algorithm to detect the fire and smoke using color histogram algorithm with local area motion, similarity, and MSE. In this study, we developed a novel fire and smoke detection algorithm applied the local motion and color histogram method. Experimental results show that the surveillance camera with the proposed algorithm showed good fire and smoke detection results with very few false positives."
지능형 관광 서비스를 위한 관광 사진 분류체계 개발,2019,"['플리커', 'SNS', '관광목적 사진 분류체계', '딥러닝', '합성곱신경망', '한국 관광', 'Flickr', 'Social Network Service', 'Photo Classification for Tourist purpose', 'Deep Learning', 'Convolutional Neural Network', 'Korea Tour']","최근 딥러닝 기술 가운데 이미지데이타 분석에 뛰어난 성능을 보이는 합성곱신경망 기술의 발전은 이미지 분석 영역에서다양한 가능성을 제시하고 있다. 관광객이 게시한 사진을 딥러닝 기술을 이용하여 분류하기 위해서는 관광사진에 대한 분류와목적에 맞는 딥러닝 모델의 훈련작업이 필수적으로 선행되어야 한다. 본 연구에서는 관광객이 플리커에 게시한 사진을 효율적으로분류하기 위해 관광목적으로 사진이 어떻게 분류되어야 하는지 관광목적 사진분류 체계를 개발하고자 하였다. 관광목적 사진분류 카테고리 개발을 위해 문헌분석, 웹사이트 분석, 관광객이 게시한 약 38,000장 사진의 검토과정을 거쳐 사진 분류 카테고리를개발하였으며, 약 8400장의 사진을 개발된 카테고리에 맞춰 분류해 봄으로써 개발된 카테고리의 검증과정을 거쳤다. 이 과정을거쳐 최종으로 제안된 카테고리는 13개 대분류, 64개 중분류, 164개의 세분류 체계를 갖으며, 본 연구 결과는 향후 관광목적사진을 딥러닝 모델을 이용하여 분류하고자 할 때 기초자료로 활용될 것으로 기대된다.","In recent years technology of Convolutional Neural Network (CNN) among the technologies of deep learning has evolved dramatically and has shown an outstanding performance in the analysis of image data. First of all, the training of deep learning model is prerequisite to classify the photos posted by the tourists on Web by applying CNN technology. In this study we aim to develop the photo classification system in view of travel purpose in order to classify the photos posted by tourists on Flickr. We developed the category for photo classification by reviewing around 38,000 photos posted by tourists as well as by analysing literatures and web sites, and then verified the category by classifying 8,400 photos one by one manually according to the category developed. The category we developed has 3 hierarchical levels such as 13 major classification, 64 medium classification and 164 minor classification. We expect that our study can applied in base material when one tries to classify the photos for travel purpose by using the CNN deep learning model."
Forest Classification Method Based on Convolutional Neural Networks and Sentinel-2 Satellite Imagery,2019,"['Forest classification', 'Contextual information', 'Satellite imagery', 'Sentinel-2', 'Convolutional Neural Network']",,"The objective of this study is to develop a classification method based on convolutional neural network (CNN) and Sentinel-2 satellite imagery including the spectral feature, spectral index and spatial feature together as an input to answer forest monitoring problem. This research also used contextual information on Indonesia National Standard Agency’s document for Land cover classification as a baseline for feature extraction to get the appropriate classifier feature. The test set was located in Semarang, Central Java, Indonesia. The research workflow consists of defining forest class based on Indonesia National Standard Agency for Land cover classification, extracting optical image features based on contextual information of the forest class definition, extracting image features from the Sentinel-2 satellite image, and classifying image object features using CNN classifier. Image segmentation produced 1,211 segments/objects by using eCognition software. Subsequently, these objects were used as a dataset. Overall accuracy was used to evaluate the performance of the classification result. The result showed the classification method results in this study yielded high overall accuracy (97.66%) when using CNN with the image features like NDVI, Brightness, GLCM homogeneity and Rectangular fit. Small improvement of overall accuracy was also achieved when it was compared to GBT with an overall accuracy of 95.50%."
딥러닝을 이용한 판류형 간판의 인식,2019,"['Signboard Detection', 'Flat Type', 'Faster Region-Based Convolutional Neural Network', 'Watershed', 'K-Means Clustering', 'Boundary Area', '간판 인식', '판류형', 'Faster R-CNN', '워터쉐드', 'K-평균 군집화', '경계 영역']","간판은 유형마다 간판의 규격이 정해져 있으나 실제 설치된 간판은 형태와 크기가 일정하지 않다. 또한, 간판은 간판 내부의 색상에 대한 규정이 정해져 있지 않기 때문에 다양한 색상을 갖고 있다. 간판을 인식하기 위한 방법은 도로표지판과 차량번호판을 인식하는 유사한 방법으로 생각할 수 있으나 간판의 특성으로 인해 도로표지판과 차량번호판과 유사한 방법으로 간판을 인식할 수 없는 한계점이 있다. 이에 본 연구에서는 딥러닝 기반의 Faster R-CNN 알고리즘을 이용하여 불법 및 노후 간판의 주요 대상이 되는 판류형 간판을 인식하고 간판의 영역을 자동으로 추출하는 방법론을 제안하였다. 스마트폰 카메라를 이용하여 촬영한 간판 영상을 통해 판류형 간판을 인식하는 과정은 2가지의 순서로 나뉜다. 먼저, 다양한 유형의 간판 영상에서 판류형 간판을 인식하기 위해 딥러닝을 이용하여 간판의 유형을 인식하였으며 그 결과는 약 71%의 정확도로 나타났다. 다음으로 판류형 간판의 경계영역을 인식하기 위해 간판 영역 인식 알고리즘을 적용하였을 때 85%의 정확도로 판류형 간판의 경계영역을 인식하였다.","The specifications of signboards are set for each type of signboards, but the shape and size of the signboard actually installed are not uniform. In addition, because the colors of the signboard are not defined, so various colors are applied to the signboard. Methods for recognizing signboards can be thought of as similar methods of recognizing road signs and license plates, but due to the nature of the signboards, there are limitations in that the signboards can not be recognized in a way similar to road signs and license plates. In this study, we proposed a methodology for recognizing plate-type signboards, which are the main targets of illegal and old signboards, and automatically extracting areas of signboards, using the deep learning-based Faster R-CNN algorithm. The process of recognizing flat type signboards through signboard images captured by using smartphone cameras is divided into two sequences. First, the type of signboard was recognized using deep learning to recognize flat type signboards in various types of signboard images, and the result showed an accuracy of about 71%. Next, when the boundary recognition algorithm for the signboards was applied to recognize the boundary area of the flat type signboard, the boundary of flat type signboard was recognized with an accuracy of 85%."
콘볼루션 신경회로망을 이용한 능동펄스 식별 알고리즘,2019,[],,"In this paper, we propose an algorithm to classify the received active pulse when the active sonar system is operated as a non-cooperative mode. The proposed algorithm uses CNN (Convolutional Neural Networks) which shows good performance in various fields. As an input of CNN, time frequency analysis data which performs STFT (Short Time Fourier Transform) of the received signal is used. The CNN used in this paper consists of two convolution and pulling layers. We designed a database based neural network and a pulse feature based neural network according to the output layer design. To verify the performance of the algorithm, the data of 3110 CW (Continuous Wave) pulses and LFM (Linear Frequency Modulated) pulses received from the actual ocean were processed to construct training data and test data. As a result of simulation, the database based neural network showed 99.9 % accuracy and the feature based neural network showed about 96 % accuracy when allowing 2 pixel error."
Introduction to convolutional neural network using Keras; an understanding from a statistician,2019,"['deep neural network', 'convolutional neural network', 'image classification', 'machine learning', 'MNIST', 'CIFAR10', 'Keras']",,"Deep Learning is one of the machine learning methods to find features from a huge data using non-linear transformation. It is now commonly used for supervised learning in many fields. In particular, Convolutional Neural Network (CNN) is the best technique for the image classification since 2012. For users who consider deep learning models for real-world applications, Keras is a popular API for neural networks written in Python and also can be used in R. We try examine the parameter estimation procedures of Deep Neural Network and structures of CNN models from basics to advanced techniques. We also try to figure out some crucial steps in CNN that can improve image classification performance in the CIFAR10 dataset using Keras. We found that several stacks of convolutional layers and batch normalization could improve prediction performance. We also compared image classification performances with other machine learning methods, including K-Nearest Neighbors (K-NN), Random Forest, and XGBoost, in both MNIST and CIFAR10 dataset."
소프트맥스를 이용한 딥러닝 음악장르 자동구분 투표 시스템,2019,[],,"Research that implements the classification process through Deep Learning algorithm, one of the outstanding human abilities, includes a unimodal model, a multi-modal model, and a multi-modal method using music videos. In this study, the results were better by suggesting a system to analyze each song's spectrum into short samples and vote for the results. Among Deep Learning algorithms, CNN showed superior performance in the category of music genre compared to RNN, and improved performance when CNN and RNN were applied together. The system of voting for each CNN result by Deep Learning a short sample of music showed better results than the previous model and the model with Softmax layer added to the model performed best. The need for the explosive growth of digital media and the automatic classification of music genres in numerous streaming services is increasing. Future research will need to reduce the proportion of undifferentiated songs and develop algorithms for the last category classification of undivided songs."
컨볼루션 신경망 기반 유해 네트워크 트래픽 탐지 기법평가,2019,"['Convolutional Neural Network', 'Traffic Classification', 'Image Transform', 'Configuration']","최근 유해 네트워크 트래픽을 탐지하기 위해 머신러닝 기법을 활용하는 다양한 방법론들이 주목을 받고 있다. 이 논문에서는 컨볼루션 신경망 (Convolutioanl Neural Network)을 기반으로 유해 네트워크 트래픽을 분류하는 기법을 소개하고 그 성능을 평가한다. 이미지 처리에 강한 컨볼루션 신경망의 활용을 위해, 네트워크 트래픽의 주요 정보를 규격화된 이미지로 변환하는 방법을 제안하고, 변환된 이미지를 입력으로 컨볼루션 신경망을 학습시켜 유해 네트워크 트래픽의 분류를 수행하도록 한다. 실제 네트워크 트래픽 관련 데이터셋을 활용하여 이미지 변환 및 컨볼루션 신경망 기반 네트워크 트래픽 분류 기법의 성능을 검증하였다. 특히, 다양한 컨볼루션 신경망 기반 네트워크 모델 구성에 따른 트래픽 분류 기법의 성능을 평가하였다.","Recently, various machine learning based traffic classification methods are focused on detecting malicious network traffic. In this paper, convolutional neural network based malicious network traffic classification method is introduced and its performance is evaluated. In order to utilize the convolutional neural network which is excellent in analyzing images, a image transform method from important information of network traffic to a standardized image is proposed, and the transformed images are used as learning input of a CNN network traffic classifier. By using the real network traffic dataset, the proposed image transform method and CNN based network traffic classification method are evaluated. Especially, under various configurations of CNN, the performance of the proposed method is evaluated."
알약 자동 인식을 위한 딥러닝 모델간 비교 및 검증,2019,"['Pill Classification', 'Object Detection', 'Deep Learning', 'Artificial Intelligent', 'Hospital']",,"When a prescription change occurs in the hospital depending on a patient’s improvement status, pharmacists directly classify manually returned pills which are not taken by a patient. There are hundreds of kinds of pills to classify. Because it is manual, mistakes can occur and which can lead to medical accidents. In this study, we have compared YOLO, Faster R-CNN and RetinaNet to classify and detect pills. The data consisted of 10 classes and used 100 images per class. To evaluate the performance of each model, we used cross-validation. As a result, the YOLO Model had sensitivity of 91.05%, FPs/image of 0.0507. The Faster R-CNN’s sensitivity was 99.6% and FPs/image was 0.0089. The RetinaNet showed sensitivity of 98.31% and FPs/image of 0.0119. Faster RCNN showed the best performance among these three models tested. Thus, the most appropriate model for classifying pills among the three models is the Faster R-CNN with the most accurate detection and classification results and a low FP/image."
딥러닝을 활용한 상실치아 수 예측의 가능성: 파일럿 스터디,2019,"['Deep learning', 'Linear regression', 'Missing teeth', 'Real-time PCR', 'Periodontitis']",,"Objectives: The primary objective of this study was to determine if the number of missing teeth could be predicted by oral disease pathogens, and the secondary objective was to assess whether deep learning is a better way of predicting the number of missing teeth than multivariable linear regression (MLR).Methods: Data were collected through review of patient’s initial medical records. A total of 960 participants were cross-sectionally surveyed. MLR analysis was performed to assess the relationship between the number of missing teeth and the results of real-time PCR assay (done for quantification of 11 oral disease pathogens). A convolutional neural network (CNN) was used as the deep learning model and compared with MLR models. Each model was performed five times to generate an average accuracy rate and mean square error (MSE). The accuracy of predicting the number of missing teeth was evaluated and compared between the CNN and MLR methods.Results: Model 1 had the demographic information necessary for the prediction of periodontal diseases in addition to the red and the orange complex bacteria that are highly predominant in oral diseases. The accuracy of the convolutional neural network in this model was 65.0%. However, applying Model 4, which added yellow complex bacteria to the total bacterial load, increased the expected extractions of dental caries to 70.2%.On the other hand, the accuracy of the MLR was about 50.0% in all models. The mean square error of the CNN was considerably smaller than that of the MLR, resulting in better predictability.Conclusions: Oral disease pathogens can be used as a predictor of missing teeth and deep learning can be a more accurate analysis method to predict the number of missing teeth as compared to MLR."
비주얼 서보잉을 위한 딥러닝 기반 물체 인식 및 자세 추정,2019,"['Object Detection', 'Object Recognition', 'Deep Learning', 'Line Detection', 'Hough Transform', 'Perspective-Transform', 'Pose Estimation']",,"Recently, smart factories have attracted much attention as a result of the 4th Industrial Revolution. Existing factory automation technologies are generally designed for simple repetition without using vision sensors. Even small object assemblies are still dependent on manual work. To satisfy the needs for replacing the existing system with new technology such as bin picking and visual servoing, precision and real-time application should be core. Therefore in our work we focused on the core elements by using deep learning algorithm to detect and classify the target object for real-time and analyzing the object features. We chose YOLO CNN which is capable of real-time working and combining the two tasks as mentioned above though there are lots of good deep learning algorithms such as Mask R-CNN and Fast R-CNN. Then through the line and inside features extracted from target object, we can obtain final outline and estimate object posture."
스마트폰 다종 데이터를 활용한 딥러닝 기반의 사용자 동행 상태 인식,2019,"['사용자 행동 인식', '그룹 상호작용', '스마트폰 물리 센서', '컨볼루션 신경망', '장단기 기억 순환 신경망', 'human activity recognition', 'group interaction', 'smartphone multimodal sensors', 'convolutional neural network', 'long short-term memory recurrent network']","스마트폰이 널리 보급되고 현대인들의 생활 속에 깊이 자리 잡으면서, 스마트폰에서 수집된 다종 데이터를바탕으로 사용자 개인의 행동을 인식하고자 하는 연구가 활발히 진행되고 있다. 그러나 타인과의 상호작용 행동 인식에 대한 연구는 아직까지 상대적으로 미진하였다. 기존 상호작용 행동 인식 연구에서는 오디오, 블루투스, 와이파이 등의 데이터를 사용하였으나, 이들은 사용자 사생활 침해 가능성이 높으며 단시간 내에 충분한 양의 데이터를 수집하기 어렵다는 한계가 있다. 반면 가속도, 자기장, 자이로스코프 등의 물리 센서의 경우 사생활 침해 가능성이 낮으며 단시간 내에 충분한 양의 데이터를 수집할 수 있다. 본 연구에서는 이러한 점에 주목하여, 스마트폰 상의 다종 물리 센서 데이터만을 활용, 딥러닝 모델에 기반을 둔 사용자의 동행 상태 인식 방법론을 제안한다. 사용자의 동행 여부 및 대화 여부를 분류하는 동행 상태 분류 모델은 컨볼루션 신경망과 장단기기억 순환 신경망이 혼합된 구조를 지닌다. 먼저 스마트폰의 다종 물리 센서에서 수집한 데이터에 존재하는 타임 스태프의 차이를 상쇄하고, 정규화를 수행하여 시간에 따른 시퀀스 데이터 형태로 변환함으로써 동행 상태분류 모델의 입력 데이터를 생성한다. 이는 컨볼루션 신경망에 입력되며, 데이터의 시간적 국부 의존성이 반영된 요인 지도를 출력한다. 장단기 기억 순환 신경망은 요인 지도를 입력받아 시간에 따른 순차적 연관 관계를학습하며, 동행 상태 분류를 위한 요인을 추출하고 소프트맥스 분류기에서 이에 기반한 최종적인 분류를 수행한다. 자체 제작한 스마트폰 애플리케이션을 배포하여 실험 데이터를 수집하였으며, 이를 활용하여 제안한 방법론을 평가하였다. 최적의 파라미터를 설정하여 동행 상태 분류 모델을 학습하고 평가한 결과, 동행 여부와 대화 여부를 각각 98.74%, 98.83%의 높은 정확도로 분류하였다.","As smartphones are getting widely used, human activity recognition (HAR) tasks for recognizing personal activities of smartphone users with multimodal data have been actively studied recently. The research area is expanding from the recognition of the simple body movement of an individual user to the recognition of low-level behavior and high-level behavior. However, HAR tasks for recognizing interaction behavior with other people, such as whether the user is accompanying or communicating with someone else, have gotten less attention so far. And previous research for recognizing interaction behavior has usually depended on audio, Bluetooth, and Wi-Fi sensors, which are vulnerable to privacy issues and require much time to collect enough data. Whereas physical sensors including accelerometer, magnetic field and gyroscope sensors are less vulnerable to privacy issues and can collect a large amount of data within a short time. In this paper, a method for detecting accompanying status based on deep learning model by only using multimodal physical sensor data, such as an accelerometer, magnetic field and gyroscope, was proposed. The accompanying status was defined as a redefinition of a part of the user interaction behavior, including whether the user is accompanying with an acquaintance at a close distance and the user is actively communicating with the acquaintance. A framework based on convolutional neural networks (CNN) and long short-term memory (LSTM) recurrent networks for classifying accompanying and conversation was proposed.First, a data preprocessing method which consists of time synchronization of multimodal data fromdifferent physical sensors, data normalization and sequence data generation was introduced. We applied the nearest interpolation to synchronize the time of collected data from different sensors. Normalization was performed for each x, y, z axis value of the sensor data, and the sequence data was generated according to the sliding window method. Then, the sequence data became the input for CNN, where feature maps representing local dependencies of the original sequence are extracted. The CNN consisted of 3 convolutional layers and did not have a pooling layer to maintain the temporal information of the sequence data. Next, LSTM recurrent networks received the feature maps, learned long-term dependencies from them and extracted features. The LSTM recurrent networks consisted of two layers, each with 128 cells. Finally, the extracted features were used for classification by softmax classifier. The loss function of the model was cross entropy function and the weights of the model were randomly initialized on a normal distribution with an average of 0 and a standard deviation of 0.1. The model was trained using adaptive moment estimation (ADAM) optimization algorithm and the mini batch size was set to 128. We applied dropout to input values of the LSTM recurrent networks to prevent overfitting. The initial learning rate was set to 0.001, and it decreased exponentially by 0.99 at the end of each epoch training.An Android smartphone application was developed and released to collect data. We collected smartphone data for a total of 18 subjects. Using the data, the model classified accompanying and conversation by 98.74% and 98.83% accuracy each. Both the F1 score and accuracy of the model were higher than the F1 score and accuracy of the majority vote classifier, support vector machine, and deep recurrent neural network. In the future research, we will focus on more rigorous multimodal sensor data synchronization methods that minimize the time stamp differences. In addition, we will further study transfer learning method that enables transfer of trained models tailored to the training data to the evaluation data that follows a different distribution. It is expected that a model capable of exhibiting robust recognition performance against changes in data that is not considered in the model learning stage wil..."
딥러닝을 통한 차등간격의 조향각 노드 결정에 의한 자율주행,2019,"['CNN (convolution neural network)', 'non-uniform steering angle intervals', 'autonomous driving', 'deep learning']",,"In this work, an autonomous driving model using only one camera was implemented by combining a CNN (ConvolutionalNeural networks) and a YOLO (You Only Look Once) framework. Hyper-parameters in the structure were adjusted to improve drivingperformance. Autonomous driving in a corridor was performed by applying the improved model. An appropriate dropout and deeplearning structure associated with non-uniform steering angle intervals as output is proposed. The proposed algorithm was implemented,and through experiments resulted in successful obstacle avoidance and stable driving."
Best Practices on Educational Service Platform with AI Approach,2019,"['CNN Algorithm', 'Education', 'Recommendation', 'User Focused']",,"The current education is becoming more extensive with the application of various teaching methods. This is a problem that is so distributed that it is difficult for users to find the data and it takes a long time to find the information they need. Currently, various educational services, materials, and instruments are developed and scattered. Therefore, it is important to raise students' awareness of aptitude and career path with customized education tailored to students. Conventional education platforms have very difficult to choose the right materials for students because of the spread of educational programs and institution materials. To solve this, we propose a customized recommendation approach to recommend customized educational service materials and institution for students to teachers, which helps teachers conveniently choose materials suitable for their respective environments. On this new platform, the CNN algorithm provides recommended content for classes and students. For real service on the educational service platform, we implement this system for Jeil edus business. Through this mechanism, we expect to improve the quality of education by helping to select the right service."
Best Practices on Educational Service Platform with AI Approach,2019,"['CNN Algorithm', 'Education', 'Recommendation', 'User Focused.']",,"The current education is becoming more extensive with the application of various teaching methods. This is a problem that is so distributed that it is difficult for users to find the data and it takes a long time to find the information they need. Currently, various educational services, materials, and instruments are developed and scattered. Therefore, it is important to raise students' awareness of aptitude and career path with customized education tailored to students. Conventional education platforms have very difficult to choose the right materials for students because of the spread of educational programs and institution materials.To solve this, we propose a customized recommendation approach to recommend customized educational service materials and institution for students to teachers, which helps teachers conveniently choose materials suitable for their respective environments. On this new platform, the CNN algorithm provides recommended content for classes and students. For real service on the educational service platform, we implement this system for Jeil edus business . Through this mechanism, we expect to improve the quality of education by helping to select the right service."
기상위성을 이용한 태양광발전 일사량 예측,2019,"['Python', 'CNN(Convolutional Neural Network)', 'Deep Learning Technique', 'Solar power generation']",,"Recently, due to the depletion of fossil fuel resources and the regulation of CO2 emissions, attention and demand for solar power generation are increasing. The solar power generation has begun to be applied to small-scale power generation, and recently, large- scale power plants have been built and sold to utility companies or power demand has been supplied to cities. In addition, facilities for microgrid for energy self-reliance through renewable energy such as solar power, wind power, and tidal power are being constructed and studied in places where electricity supply is difficult, such as island or inland countryside. The solar power generation is advantageous in that it has no pollution, is easy to maintain, and has a long life. However, the power generation depends on the weather, the installation site is limited, and the initial investment cost and the power generation cost are high. Particularly, since it depends on the weather condition, the generation amount is very intermittent and it is difficult to adjust the power generation amount, and it is difficult to establish a power generation plan in advance. Therefore, high accuracy solar power generation forecasting is essential to reduce the uncertainty of solar power generation and to improve the economical efficiency of solar power generation. Existing solar power generation forecasting has been conducted to predict power generation using Extreme Learning Machine (ELM), Support Vector Regression (SVR), and neural network. However, in this paper, we forecast the solar power generation using the meteorological satellite data from 2011 to 2017 and forecasting method using the CNN (Convolutional Neural Network) which is one of the deep running algorithms. And the feasibility of the proposed method was verified using the meteorological satellite data in 2018. For the forecasting program, we programmed using Python, which is specialized for deep running."
딥 러닝과 데이터 결합에 의한 싱크홀 트래킹,2019,"['sinkhole tracking', 'CNN transfer learning', 'data association', 'Hungarian Algorithm', 'Otsu algorithm']",,"Accurate tracking of the sinkholes that are appearing frequently now is an important method of protecting human and property damage. Although many sinkhole detection systems have been proposed, it is still far from completely solved especially in-depth area. Furthermore, detection of sinkhole algorithms experienced the problem of unstable result that makes the system difficult to fire a warning in real-time. In this paper, we proposed a method of sinkhole tracking by deep learning and data association, that takes advantage of the recent development of CNN transfer learning. Our system consists of three main parts which are binary segmentation, sinkhole classification, and sinkhole tracking. The experiment results show that the sinkhole can be tracked in real-time on the dataset. These achievements have proven that the proposed system is able to apply to the practical application."
인공지능 기반의 울음소리를 이용한 영아 상태 인식,2019,"['infant', 'spectrogram', 'CNN', 'sound classification', 'emotion recognition']",,"Babies in infancy communicate most by crying. Since it is a critical period in the brain development stage, a lot of effort is needed to understand the desire of the baby correctly. In this study, we introduce the analysis of research on babys crying and patterns, and how to classify them using artificial intelligence. The sound source consists of the baby’s crying sample from the existing research, and the pattern is stored and classified. It is transformed into spectrogram image data, visualized, analyzed and preprocessed, and used as learning data for CNN model. This study presents how to implement a system that classify baby’s crying with comparatively higher accuracy than existing research that uses patterns from the average of frequency measurements. If much more input data is verified by experts in the near future, it can be commercialized easily and immediately."
엔터프라이즈 환경의 딥 러닝을 활용한 이미지 예측 시스템 아키텍처,2019,"['Deep Learning', 'Softmax', 'ReLU', 'CNN', 'Inception', 'Architecture', '딥 러닝', 'Softmax', 'ReLU', 'CNN', '인셉션', '아키텍처']","본 논문에서는 엔터프라이즈 환경에서의 딥 러닝에 대한 이미지 예측 시스템 아키텍처를 제안한다. 엔터프라이즈 환경에 대해 인공지능 플랫폼으로 변환을 쉽게 하고, 인공지능 플랫폼이 파이선에 집중되어서 자바 중심의 엔터프라이즈 개발이 어려운 단점을 개선하기 위해 자바 중심의 아키텍처에서도 충분한 딥 러닝 서비스의 개발과 수정이 가능하도록 한다. 또한, 제안된 환경을 토대로 이미지 예측 실험을 통해 기존에 학습된 딥 러닝 아키텍처 환경에서의 정확도가 높은 예측 시스템을 제안한다. 실험을 통해 딥 러닝이 수행되기 위해 제공된 이미지 예에서 95.23%의 정확도를 보이며, 제안된 모델은 유사한 다른 모델에 비교해 96.54%의 정확도를 보인다. 제시된 아키텍처를 활용하여 활발한 엔터프라이즈급 환경의 딥 러닝 서비스가 개발 및 제공될 것으로 보이며, 기존 엔터프라이즈 환경이 딥 러닝 아키텍처가 탑재된 환경으로 전환이 활발히 이루어질 것이다.","This paper proposes an image prediction system architecture for deep running in enterprise environment. Easily transform into an artificial intelligence platform for an enterprise environment, and allow sufficient deep-running services to be developed and modified even in Java-centric architectures to improve the shortcomings of Java-centric enterprise development because artificial intelligence platforms are concentrated in the pipeline. In addition, based on the proposed environment, we propose a more accurate prediction system in the deep running architecture environment that has been previously learned through image forecasting experiments. Experiments show 95.23% accuracy in the image example provided for deep running to be performed, and the proposed model shows 96.54% accuracy compared to other similar models."
효과적인 역 톤 매핑을 위한 필터링 기법,2019,"['Inverse Tone-mapping', 'HDR', 'CNN', 'Deep Learning', 'Guided Image Filter']",본 논문에서는 가이디드 영상 필터 (guided image filter: GIF)를 이용하여 컨볼루션 신경망 (convolutional neural network; CNN)을 이용한 역 톤 매핑 (inverse tone-mapping) 기법의 결과를 향상시킬 수 있는 필터링 기법을 제안한다. 저동적범위 (low dynamic range; LDR) 영상을 고동적범위 (high dynamic range; HDR) 디스플레이에서 표현할 수 있도록 변환하는 역 톤 매핑 기법은 지속적으로 제안되어왔다. 최근 들어 컨볼루션 신경망을 이용하여 단일 LDR 영상을 HDR 영상으로 변환하는 알고리듬이 많이 연구되었다. 그 중엔 제한된 동적범위 (dynamic range)로 인해 화소가 포화되어 기존 화소 정보가 손실되는데 이를 학습된 컨볼루션 신경망을 이용해서 복원하는 알고리듬이 존재한다. 해당 알고리듬은 비포화 영역의 잡음까지는 억제하지 못하며 포화 영역의 디테일까지는 복원하지 못한다. 제안한 알고리듬은 입력 영상에 가중된 가이디드 영상 필터 (weighted guided image filter; WGIF)를 사용해서 비포화 영역의 잡음을 억제하고 포화 영역의 디테일을 복원시킨 다음 컨볼루션 신경망에 인가하여 최종 결과 영상의 품질을 개선하였다. 제안하는 알고리듬은 HDR 정량적 화질평가 지표를 측정하였을 때 기존의 알고리듬에 비해 높은 화질평가 지수를 나타내었다.,
결합 신경망을 이용한 여권 MRZ 정보 인식,2019,"['Passport Recognition', 'MRZ Information', 'CNN', 'Identity Information Recognition']",,"In case of reading passport using a smart phone in contrast with a dedicated passport reading system, MRZ(Machine Readable Zone) character recognition can be hard when the character strokes were broken, touched or blurred according to the lighting condition, and the position and size of MRZ character lines were varied due to the camera distance and angle. In this paper, the effective recognition algorithm of the passport MRZ information using a combined neural network recognizer of CNN(Convolutional Neural Network) and ANN( Artificial Neural Network), is proposed under the various sized and skewed passport images. The MRZ line detection using connected component analysis algorithm and the skew correction using perspective transform algorithm are also designed in order to achieve effective character segmentation results. Each of the MRZ field recognition results is verified by using five check digits for deciding whether retrying the recognition process of passport MRZ information or not. After we implement the proposed recognition algorithm of passport MRZ information, the excellent recognition performance of the passport MRZ information was obtained in the experimental results for PC off-line mode and smart phone on-line mode."
An Efficient Comparing and Updating Method of Rights Management Information for Integrated Public Domain Image Search Engine,2019,"['Public Domain Image', 'RMI', 'dHash', 'Average Hash', 'CNN', 'Weighted Scoring Model']",,"In this paper, we propose a Rights Management Information(RMI) expression systems for individual sites are integrated and the performance evaluation is performed to find out an efficient comparing and updating method of RMI through various image feature point search techniques. In addition, we proposed a weighted scoring model for both public domain sites and posts in order to use the most latest RMI based on reliable data. To solve problem that most public domain sites are exposed to copyright infringement by providing inconsistent RMI(Rights Management Information) expression system and non-up-to-date RMI information. The weighted scoring model proposed in this paper makes it possible to use the latest RMI for duplicated images that have been verified through the performance evaluation experiments of SIFT and CNN techniques and to improve the accuracy when applied to search engines. In addition, there is an advantage in providing users with accurate original public domain images and their RMI from the search engine even when some modified public domain images are searched by users."
Vehicle Manufacturer Recognition using Deep Learning and Perspective Transformation,2019,"['Vehicle Logo', 'Object detection', 'YOLO', 'Faster R-CNN', 'VMR.']",,"In real world object detection is an active research topic for understanding different objects from images. There are different models presented in past and had significant results. In this paper we are presenting vehicle logo detection using previous object detection models such as You only look once (YOLO) and Faster Region-based CNN (F-RCNN). Both the front and rear view of the vehicles were used for training and testing the proposed method. Along with deep learning an image pre-processing algorithm called perspective transformation is proposed for all the test images. Using perspective transformation, the top view images were transformed into front view images. This algorithm has higher detection rate as compared to raw images. Furthermore, YOLO model has better result as compare to F-RCNN model."
A New CSR-DCF Tracking Algorithm based on Faster RCNN Detection Model and CSRT Tracker for Drone Data,2019,"['Object Tracking', 'CSR-DCF', 'Object Detection', 'CNN', 'Faster R-CNN', 'OpenCV', 'DNN Module', 'CSRT', 'Drone', 'Deep Learning']",,"Nowadays object tracking process becoming one of the most challenging task in Computer Vision filed. A CSR-DCF (channel spatial reliability-discriminative correlation filter) tracking algorithm have been proposed on recent tracking benchmark that could achieve stat-of-the-art performance where channel spatial reliability concepts to DCF tracking and provide a novel learning algorithm for its efficient and seamless integration in the filter update and the tracking process with only two simple standard features, HoGs and Color names. However, there are some cases where this method cannot track properly, like overlapping, occlusions, motion blur, changing appearance, environmental variations and so on. To overcome that kind of complications a new modified version of CSR-DCF algorithm has been proposed by integrating deep learning based object detection and CSRT  tracker which implemented in OpenCV library. As an object detection model, according to the comparable result of object detection methods and by reason of high efficiency and celerity of Faster RCNN (Region-based Convolutional Neural Network) has been used, and combined with CSRT tracker, which demonstrated outstanding real-time detection and tracking performance. The results indicate that the trained object detection model integration with tracking algorithm gives better outcomes rather than using tracking algorithm or filter itself."
임베디드 GPU에서의 딥러닝 기반 실시간 보행자 탐지 기법,2019,"['Pedestrian detection', 'convolutional neural network', 'embedded system']","본 논문은 임베디드 GPU에서 실시간 동작하는 딥 컨볼루션 뉴럴 네트워크(CNN) 기반의 보행자 탐지 기법을 제안한다. 제안하는 기법에서는 먼저 영상 내 보행자 크기에 대한 통계적 분석을 통해서 최적의 컨볼루션 층의 개수를 결정한다. 또한, 본 논문에서는 다중 스케일 CNN 학습 기법을 적용하여 영상 내의 보행자 크기 변화에 강인한 탐지 기법을 개발한다. 컴퓨터 모의실험을 통해 제안하는 알고리즘이 임베디드 GPU에서 실시간 동작하면서도 기존의 기법과 비교하여 평균적으로 높은 정확도를 보임을 확인한다.",
순환신경망 모형을 활용한 시계열 비교예측,2019,"['ARIMA model', 'neural network', 'RNN', 'LSTM.', 'ARIMA 모형', '신경망모형', '순환신경망', 'LSTM.']","최근 알파고 이후 딥러닝 연구에 대한 활발한 연구가 진행되고 있다. 딥러닝에는 이미지 분석에 적합한 CNN(convolution neural network), 순차적 자료에 적합한 RNN(recurrent neural network) 모델 등 많은 모델이 존재하는데 그 중 시계열데이터 분석에 적합한 딥러닝 모델을 전형적 시계열데이터인 항공사 데이터(1949년 1월부터 1960년 12월까지 매월 총 국제 항공사 승객 수)에 Box-Jenkins의 ARIMA 모형과 함께 적합시켜 비교 할 것이다. 본 연구에서는 R 프로그램을 이용하여 LSTM(long short-term memory) 순환신경망 모델을 구축하고, ARIMA 모형, Faraway(1998)가 제시한 단순 신경망(neural network) 모형 그리고 Jordan & Elman의 순환신경망 모형과의 적합도를 비교하였다. 모형 비교결과 Elman 모형의 오차제곱합이 0.0128, Jordan 모형의 오차제곱 합이 0.0138, LSTM 모형의 오차제곱합이 0.0165, 신경망 모형은 오차제곱합 0.0212로 ARIMA 모형의 0.0194 에 비해 조금 뒤떨어지는 것으로 나타났다. 결국 Elman 순환신경망 모형이 가장 우수하게 나타났으며 LSTM 모형도 기존 ARIMA 모형과 Faraway의 단순신경망모형 보다 우수한 적합도를 나타났다.","Typical algorithms for deep learning include DNN (deep neural network), CNN (convolution neural network), and RNN (recurrent neural network) algorithms. Among them, RNN is excellent at dealing with sequential data. Sequential data such as time series data can be handled without losing gradient by LSTM (long short-term memory) RNN. In this study, the LSTM, a modified algorithm of RNN, is applied to international airline passenger data (from January 1, 1994 to December 1960). We find the optimal model and compare it with the ARIMA model, the initial network model presented by Faraway (1998), and the model of Jordan & Elman, the simple RNN model. To compare the models, we train the data as learning data sets from January 1949 to December 1950, and designate the remaining one year of data as test sets. and compare the performance of the model with the sum of square errors of the test sets. The model comparison shows that the Elman RNN model was the best, and that the LSTM model was not inferior to the ARIMA model."
심층신경망을 이용한 소스 코드 원작자 식별,2019,"['컴퓨터 법의학', '예측 기반 벡터', 'TF-IDF', '심층 학습', 'CNN', 'Computer Forensic', 'Frequency Based Embedding', 'TF-IDF', 'Deep Learning', 'CNN']","현재 프로그래밍 소스들이 온라인에서 공개되어 있기 때문에 무분별한 표절이나 저작권에 대한 문제가 일어나고 있다. 그 중 반복된 저자가 작성한 소스코드는 프로그래밍 특성상 고유의 지문이 있을 수 있다. 본 논문은 구글 코드 잼 프로그램 소스를 심층신경망을 이용한 학습을 통해 각각의 저자를 분별하는 것이다. 이 때 원작자의 소스를 예측 기반 벡터나, 주파수 기반 접근법인 TF-IDF등의 전처리기를 사용하여 입력 값들을 벡터화해주고, 심층신경망을 이용한 학습을 통해 각 프로그램 소스 원작자를 식별하고자 한다. 전처리기를 이용하여 언어에 독립적인 학습시스템을 구성하고, 기존의 다른 학습 방법들과 비교하였다. 그 중 TF-IDF와 심층신경망을 사용한 모델은 다른 전처리기나 다른 학습방식을 사용한 것보다 좋은 성능을 보임을 확인하였다.",
Medical Image Analysis Using Artificial Intelligence,2019,"['Artificial Intelligence (AI)', 'Medical images', 'Deep-learning', 'Machine-learning', 'Convolutional Neural Network (CNN)', 'Big data']",,"Purpose: Automated analytical systems have begun to emerge as a database system that enables the scanning of medical images to be performed on computers and the construction of big data.Deep-learning artificial intelligence (AI) architectures have been developed and applied to medical images, making high-precision diagnosis possible.Materials and Methods: For diagnosis, the medical images need to be labeled and standardized.After pre-processing the data and entering them into the deep-learning architecture, the final diagnosis results can be obtained quickly and accurately. To solve the problem of overfitting because of an insufficient amount of labeled data, data augmentation is performed through rotation, using left and right flips to artificially increase the amount of data. Because various deeplearning architectures have been developed and publicized over the past few years, the results of the diagnosis can be obtained by entering a medical image.Results: Classification and regression are performed by a supervised machine-learning method and clustering and generation are performed by an unsupervised machine-learning method. When the convolutional neural network (CNN) method is applied to the deep-learning layer, feature extraction can be used to classify diseases very efficiently and thus to diagnose various diseases.Conclusions: AI, using a deep-learning architecture, has expertise in medical image analysis of the nerves, retina, lungs, digital pathology, breast, heart, abdomen, and musculo-skeletal system."
Dhash 기반 고속 악성코드 변종 탐지기법,2019,"['악성코드 탐지', '정적 분석', '변종 악성코드', 'Dhash (Difference hash)', 'CNN (Convolutional Neural Network)', 'malware detection', 'static analysis', 'mutant malware', 'Dhash (Difference hash)', 'CNN (Convolutional Neural Network)']","악성코드 생성 도구와 난독화 기법의 대중화로 악성코드는 지능화되고 있지만 기존의 악성코드 탐지 기법은 악성코드에 대해 완벽하지 못한 탐지를 보여주고 있다. 이에 새롭게 등장하는 악성코드 중 다수가 기존에 발생했던 악성코드의 변종이라는 것과 변종 악성코드는 원본 악성코드와 비슷한 바이너리 데이터를 갖는 특징을 고려해 파일의 바이너리 데이터를 통해 이미지를 분류하는 Dhash 기반 악성코드 탐지 기법을 제시하며, Dhash 알고리즘의 전수비교로 인한 느린 분석 시간을 개선한 10-gram 알고리즘을 제시한다. 변종 악성코드 탐지에서 우수한 ssdeep 기법과의 비교를 통해 ssdeep이 탐지하지 못하는 영역에 대해 Dhash 알고리즘이 탐지했음을 보이며, 기존의 Dhash 알고리즘과 본 논문에서 제안하는 알고리즘의 탐지 속도 성능 비교 실험을 통해 제안하는 알고리즘의 우수성을 증명한다. 향후 다른 LSH기반 탐지 기법과 연계한 변종 악성코드 분석 기술 개발을 지속 진행할 예정이다.","Malicious codes are becoming more intelligent due to the popularization of malware generation tools and obfuscation techniques, but existing malware detection techniques suffer from incomplete detection of malicious codes. Considering the facts that many newly emerging malicious codes are variants of existing malicious codes, and that they have binary data similar to those of the original malicious codes, a Dhash-based malware detection technique is presented here that classifies images based on the binary data in a file, along with a 10-gram algorithm that improves the long time taken by the analysis due to the full comparison of the Dhash algorithm. A comparison with the superior ssdep technique in variant malware detection shows that the Dhash algorithm can detect areas that ssdep does not detect, and the superiority of the proposed algorithm through the existing Dhash algorithm and the detection speed comparison experiment of the algorithms proposed in this paper. Future work will continue to develop variety of malware analysis technologies that are linked to other LSH-based detection techniques."
차량용 인포테인먼트 시스템의 딥 러닝 기반 UI 테스팅 자동화 기술,2019,"['소프트웨어 테스팅 자동화', 'UI 테스팅 자동화', '차량용 인포테인먼트 시스템', '인공지능 응용', '객체검출', 'R-CNN', 'software testing automation', 'UI testing automation', 'in-vehicle infotainment system', 'artificial intelligence application', 'object detection', 'R-CNN']","최근 텔레메틱스(Telematics), 커넥티드 카(Connected Car), 자율 주행 자동차 기술의 발전으로 인해 차량용 인포테인먼트 시스템(In-Vehicle Infotainment, IVI)에 포함되는 기능이 다양화되고 역할과 중요도가 크게 높아지고 있다. 이에 따라 IVI와 사용자 간의 상호작용을 담당하는 사용자 인터페이스(User Interface, UI)의 복잡성이 증가되고 있으며, 높은 품질의 UI 개발을 위한 UI 테스팅 기술의 필요성 또한 증대되었다. 본 논문에서는 IVI의 화면으로부터 객체를 인식하는 딥 러닝 모델을 이용한 UI 테스팅 자동화 기술을 제안하고, IVI 자동화 테스팅 도구 VISTA에 적용시킨 사례에 대해 기술한다.","Lately, the functions included in the in-vehicle infotainment system (IVI) have diversified and their roles and importance greatly increased due to the development of telematics, connected cars, and autonomous vehicle technology. the complexity of the user interface (UI) responsible for the interaction between IVI and the user, and the need for a UI testing technique for a UI. In this paper, we propose a UI testing technology using a deep learning model that recognizes objects from the IVI screen, and describe a case where it is applied to IVI automation testing tool VISTA."
Tissue Level Based Deep Learning Framework for Early Detection of Dysplasia in Oral Squamous Epithelium,2019,"['oral cancer', 'oral epithelial tissue', 'oral dysplasia', 'deep learning']",,"Deep learning is emerging as one of the best tool in processing data related to medical imaging. In our research work, we have proposed a deep learning based framework CNN (Convolutional Neural Network) for the classification of dysplastic tissue images. The CNN has classified the given images into 4 different classes namely normal tissue, mild dysplastic tissue, moderate dysplastic tissue and severe dysplastic tissue. The dataset under taken for the study consists of 672 tissue images of epithelial squamous layer of oral cavity captured out of the biopsy samples of 52 patients. After applying the data pre-processing and augmentation on the given dataset, 2688 images were created. Further, these 2688 images were classified into 4 categories with the help of expert Oral Pathologist. The classified data was supplied to the convolutional neural network for training and testing of the proposed framework. It has been observed that training data shows 91.65% accuracy whereas the testing data achieves 89.3% accuracy. The results produced by our proposed framework are also tested and validated by comparing the manual results produced by the medical experts working in this area."
Bird sounds classification by combining PNCC and robust Mel-log filter bank features,2019,[],,"In this paper, combining features is proposed as a way to enhance the classification accuracy of sounds under noisy environments using the CNN (Convolutional Neural Network) structure. A robust log Mel-filter bank using Wiener filter and PNCCs (Power Normalized Cepstral Coefficients) are extracted to form a 2-dimensional feature that is used as input to the CNN structure. An ebird database is used to classify 43 types of bird species in their natural environment. To evaluate the performance of the combined features under noisy environments, the database is augmented with 3 types of noise under 4 different SNRs (Signal to Noise Ratios) (20 dB, 10 dB, 5 dB, 0 dB). The combined feature is compared to the log Mel-filter bank with and without incorporating the Wiener filter and the PNCCs. The combined feature is shown to outperform the other mentioned features under clean environments with a 1.34 % increase in overall average accuracy. Additionally, the accuracy under noisy environments at the 4 SNR levels is increased by 1.06 % and 0.65 % for shop and schoolyard noise backgrounds, respectively."
작물 분류를 위한 다중 규모 공간특징의 가중 결합 기반 합성곱 신경망 모델,2019,"['Crop classification', 'Convolutional neural network', 'Spatial feature', 'Image patch']","이 논문에서는 작물 분류를 목적으로 합성곱 신경망 구조에 다중 규모의 입력 영상으로부터 추출가능한 다양한 공간특징을 가중 결합하는 모델을 제안하였다. 제안 모델은 합성곱 계층에서 서로 다른 크기의 입력패치를 이용하여 공간특징을 추출한 후, squeeze-and-excitation block을 통해 추출한 공간특징의 중요도에 따라가중치를 부여한다. 제안 모델의 장점은 분류에 유용한 특징들을 추출하고 특징의 상대적 중요도를 분류에 이용하는데 있다. 제안 모델의 분류 성능을 평가하기 위해 미국 일리노이 주에서 수집한 다중시기 Landsat-8 OLI 영상을 이용한 작물 분류 사례연구를 수행하였다. 유용한 패치 크기 결정을 위해 먼저 단일 패치 모델에서 패치 크기가 작물 분류에 미치는 영향을 분석하였다. 그 후에 단일 패치 모델과 특징의 중요도를 고려하지 않는다중 패치 모델과 분류 성능을 비교하였다. 비교 실험 결과, 제안 모델은 연구지역에서 재배하는 작물의 공간특징을 고려함으로써 오분류 양상을 완화시켜 비교 모델들에 비해 가장 우수한 분류 정확도를 나타냈다. 분류에 유용한 공간특징의 상대적 중요도를 고려하는 제안 모델은 작물뿐만 아니라 서로 다른 공간특성을 보이는객체 분류에도 유용하게 적용될 수 있을 것으로 기대된다.","This paper proposes an advanced crop classification model that combines a procedure for weighted combination of spatial features extracted from multi-scale input images with a conventional convolutional neural network (CNN) structure. The proposed model first extracts spatial features from patches with different sizes in convolution layers, and then assigns different weights to the extracted spatial features by considering feature-specific importance using squeeze-and-excitation block sets. The novelty of the model lies in its ability to extract spatial features useful for classification and account for their relative importance. A case study of crop classification with multi-temporal Landsat-8 OLI images in Illinois, USA was carried out to evaluate the classification performance of the proposed model. The impact of patch sizes on crop classification was first assessed in a single-patch model to find useful patch sizes. The classification performance of the proposed model was then compared with those of conventional two CNN models including the single-patch model and a multi-patch model without considering feature-specific weights. From the results of comparison experiments, the proposed model could alleviate misclassification patterns by considering the spatial characteristics of different crops in the study area, achieving the best classification accuracy compared to the other models. Based on the case study results, the proposed model, which can account for the relative importance of spatial features, would be effectively applied to classification of objects with different spatial characteristics, as well as crops."
센서 융합 시스템을 이용한 심층 컨벌루션 신경망 기반 6자유도 위치 재인식,2019,"['Relocalization', 'Sensor Fusion', 'Convolutional Neural Network', 'pose regression']",,"This paper presents a 6-DOF relocalization using a 3D laser scanner and a monocular camera. A relocalization problem in robotics is to estimate pose of sensor when a robot revisits the area. A deep convolutional neural network (CNN) is designed to regress 6-DOF sensor pose and trained using both RGB image and 3D point cloud information in end-to-end manner. We generate the new input that consists of RGB and range information. After training step, the relocalization system results in the pose of the sensor corresponding to each input when a new input is received. However, most of cases, mobile robot navigation system has successive sensor measurements. In order to improve the localization performance, the output of CNN is used for measurements of the particle filter that smooth the trajectory. We evaluate our relocalization method on real world datasets using a mobile robot platform."
두 개의 컨볼루션 신경망을 이용한 PCB 상의 SMD 분류 시스템,2019,"['deep learning', 'printed circuit board', 'surface mount technology', 'automated optical inspection']",,It is important to classify SMD(Surface Mount Device) type for programing of AOI. A new SMD classification system is proposed using series of two CNNs to improve accuracy. A series of device region detection CNN and classification CNN are proposed where the first network is device region detect network and second network is device classification network. The device region detect network is designed lighter than the previously used region detect network. Experimental results showed that better accuracy is obtained when classification is performed after region detection.
Sub-Frame Analysis-based Object Detection for Real-Time Video Surveillance,2019,"['object detection', 'object tracking', 'convolutional neural network', 'real time video surveillance', 'sub-frame analysis.']",,"We introduce a vision-based object detection method for real-time video surveillance system in low-end edge computing environments. Recently, the accuracy of object detection has been improved due to the performance of approaches based on deep learning algorithm such as Region Convolutional Neural Network(R-CNN) which has two stage for inferencing. On the other hand, one stage detection algorithms such as single-shot detection (SSD) and you only look once (YOLO) have been developed at the expense of some accuracy and can be used for real-time systems. However, high-performance hardware such as General-Purpose computing on Graphics Processing Unit(GPGPU) is required to still achieve excellent object detection performance and speed. To address hardware requirement that is burdensome to low-end edge computing environments, We propose subframe analysis method for the object detection. In specific, We divide a whole image frame into smaller ones then inference them on Convolutional Neural Network (CNN) based image detection network, which is much faster than conventional network designed for full frame image. We reduced its computational requirement significantly without losing throughput and object detection accuracy with the proposed method."
CFAR와 합성곱 신경망을 이용한 기두부와 단 분리 시 조각 구분,2019,"['micro motion', 'micro-Doppler spectrogram', 'CA-CFAR', 'convolutional neural networks', 'warhead', 'debris']",,"Warhead and debris show the different micro-Doppler frequency shape in the spectrogram because of the different micro motion. So we can classify them using the micro-Doppler features. In this paper, we classified warhead and debris in the separation phase using CNN(Convolutional Neural Networks). For the input image of CNN, we used micro-Doppler spectrogram. In addition, to improve classification performance of warhead and debris, we applied the preprocessing using CA-CFAR to the micro-Doppler spectrogram. As a result, when the preprocessing of micro-Doppler spectrogram was used, classification performance is improved in all signal-to-noise ratio(SNR)."
외래잡초 분류 : 합성곱 신경망 기반 계층적 구조,2019,"['exotic weeds', 'weed classification', 'hierarchical architecture', 'convolutional neural networks']",,"Weeds are a major object which is very harmful to crops. To remove the weeds effectively, we have to classify them accurately and use herbicides. As computing technology has developed, image-based machine learning methods have been studied in this field, specially convolutional neural network(CNN) based models have shown good performance in public image dataset. However, CNN with numerous training parameters and high computational amount. Thus, it works under high hardware condition of expensive GPUs in real application. To solve these problems, in this paper, a hierarchical architecture based deep-learning model is proposed. The experimental results show that the proposed model successfully classify 21 species of the exotic weeds. That is, the model achieve 97.2612% accuracy with a small number of parameters. Our proposed model with a few parameters is expected to be applicable to actual application of network based classification services."
Vehicle Detection in Aerial Images Based on Hyper Feature Map in Deep Convolutional Network,2019,"['Car detection', 'deep convolutional network', 'hyper feature map', 'small object detection', 'feature fusion']",,"Vehicle detection based on aerial images is an interesting and challenging research topic. Most of the traditional vehicle detection methods are based on the sliding window search algorithm, but these methods are not sufficient for the extraction of object features, and accompanied with heavy computational costs. Recent studies have shown that convolutional neural network algorithm has made a significant progress in computer vision, especially Faster R-CNN. However, this algorithm mainly detects objects in natural scenes, it is not suitable for detecting small object in aerial view. In this paper, an accurate and effective vehicle detection algorithm based on Faster R-CNN is proposed. Our method fuse a hyperactive feature map network with Eltwise model and Concat model, which is more conducive to the extraction of small object features. Moreover, setting suitable anchor boxes based on the size of the object is used in our model, which also effectively improves the performance of the detection. We evaluate the detection performance of our method on the Munich dataset and our collected dataset, with improvements in accuracy and effectivity compared with other methods. Our model achieves 82.2% in recall rate and 90.2% accuracy rate on Munich dataset, which has increased by 2.5 and 1.3 percentage points respectively over the state-of-the-art methods."
공개 딥러닝 라이브러리에 대한 보안 취약성 검증,2019,"['Adversarial attack', 'MNIST', 'deep learning', 'security', 'autoencoder', 'convolution neural network']","최근 다양한 분야에서 활용중인 딥러닝은 적대적 공격 가능성의 발견으로 위험성이 제기되고 있다. 본 논문에서는딥러닝의 이미지 분류 모델에서 악의적 공격자가 생성한 적대적 샘플에 의해 분류 정확도가 낮아짐을 실험적으로 검증하였다. 대표적인 이미지 샘플인 MNIST데이터 셋을 사용하였으며, 텐서플로우와 파이토치라이브러리를 사용하여만든 오토인코더 분류 모델과 CNN(Convolution neural network)분류 모델에 적대적 샘플을 주입하여 탐지정확도를 측정한다. 적대적 샘플은 MNIST테스트 데이터 셋을 JSMA(Jacobian-based Saliency MapAttack)방법으로 생성한 방법과 FGSM(Fast Gradient Sign Method)방식으로 변형하여 생성하였으며, 분류모델에 주입하여 측정하였을 때 최소 21.82%에서 최대 39.08%만큼 탐지 정확도가 낮아짐을 검증하였다.","Deep Learning, which is being used in various fields recently, is being threatened with Adversarial Attack. In this paper,we experimentally verify that the classification accuracy is lowered by adversarial samples generated by malicious attackersin image classification models. We used MNIST dataset and measured the detection accuracy by injecting adversarialsamples into the Autoencoder classification model and the CNN (Convolution neural network) classification model, which arecreated using the Tensorflow library and the Pytorch library. Adversarial samples were generated by transforming MNISTtest dataset with JSMA(Jacobian-based Saliency Map Attack) and FGSM(Fast Gradient Sign Method). When injected into theclassification model, detection accuracy decreased by at least 21.82% up to 39.08%."
영상 구성 파라미터 추출을 위한 융합 분석 알고리듬 연구,2019,"['Internet One-person Broadcasting Creators(인터넷 1인 방송 크리에이터)', 'Optical Flow(옵티컬 플로우)', 'Image Histogram(이미지 히스토그램)', 'Convolutional Neural Network(컨벌루셔널 뉴럴 네트워크)', 'Convergence Content(융합콘텐츠)']","본 연구는 영상콘텐츠 제작과정에서 배경음악 선정의 자동화를 위하여 영상의 특성을 분류, 분석할 수 있는 프로그램을 구성하였다. 연구 결과 및 내용은 다음과 같다. 영상의 특성은 ‘주제 범주’, ‘감정’, ‘픽셀 움직임 속도’, ‘색상’, ‘등장인물’ 로 선정하며, ‘주제 범주’와 ‘감정’은 Microsoft사의 Azure Video Indexer를, ‘픽셀 움직임 속도’는 Optical flow, ‘색상’은 Image Histogram, ‘등장인물’은 CNN (Convolutional Neural Network)을 활용하여 데이터를 추출하였다. 이러한 본 연구의 결과는 최근 주목을 받고있는 ‘인터넷 1인 방송 크리에이터’들의 콘텐츠 제작과정에서 배경음악 매칭을 위한 영상 특성 분석이 이루어졌다는 점에서 의의가 있다.","This study was conducted to organize a program to classify and analyze the characteristics of images for the automation of background music selection in the video content production process. The results and contents of the study are as follows: video characteristics are selected as subject category, emotion, pixel motion speed, color, and character material. Subject categories and feelings were extracted using Microsoft""s Azure Video Indexer, Pixel Movement Speed was an Optional flow, Color was an Image Histogram for Image, and character materials was CNN(Convolutional Neural Network). The results of this study are significant in that video analysis was conducted to match background music in the recent content production process of ""Internet One-person Broadcasting Creators""."
다중 주파수 대역 convolutional neural network 기반 지진 신호 검출 기법,2019,[],,"In this paper, a deep learning-based detection and classification using multi-band frequency signals is presented for detecting earthquakes prevalent in Korea. Based on an analysis of the previous earthquakes in Korea, it is observed that multi-band signals are appropriate for classifying earthquake signals. Therefore, in this paper, we propose a deep CNN (Convolutional Neural Network) using multi-band signals as training data. The proposed algorithm extracts the multi-band signals (Low/Medium/High frequency) by applying band pass filters to mel-spectrum of earthquake signals. Then, we construct three CNN architecture pipelines for extracting features and classifying the earthquake signals by a late fusion of the three CNNs. We validate effectiveness of the proposed method by performing various experiments for classifying the domestic earthquake signals detected in 2018."
Selection of CDMA and OFDM using machine learning in underwater wireless networks,2019,['Underwater communicationMachine learningCDMAOFDM'],,"Underwater acoustic (UWA) channels have long propagation delays and irregular Doppler shifts, which make the design of communication scheme difficult. Even though two transceivers are fixed, UWA channels dramatically vary by time since speed velocity profile in UWA channel is changed by day and night. This paper proposes a selection method between CDMA and OFDM modulations using a convolutional neural network (CNN) for estimating channel parameters and Random Forest (RF) for modulation selection based on the CNN results. Computer simulations demonstrate that the parameter estimation of the proposed method is better than that of the conventional least square (LS) estimation, and RF selection method exhibits better detection results than the conventional DNN."
Development of Predictive Models in Patients with Epiphora Using Lacrimal Scintigraphy and Machine Learning,2019,['Epiphora . Dacryocystography . Lacrimal scintigraphy . Machine learning . Deep learning . Convolutional neural network'],,"Purpose We developed predictive models using different programming languages and different computing platforms for machine learning (ML) and deep learning (DL) that classify clinical diagnoses in patients with epiphora.We evaluated the diagnostic performance of these models.Methods Between January 2016 and September 2017, 250 patients with epiphora who underwent dacryocystography (DCG) and lacrimal scintigraphy (LS) were included in the study.We developed five different predictive models usingMLtools, Pythonbased TensorFlow, R, and Microsoft Azure Machine Learning Studio (MAMLS). A total of 27 clinical characteristics and parameters including variables related to epiphora (VE) and variables related to dacryocystography (VDCG) were used as input data. Apart from this, we developed two predictive convolutional neural network (CNN) models for diagnosing LS images. We conducted this study using supervised learning.Results Among 500 eyes of 250 patients, 59 eyes had anatomical obstruction, 338 eyes had functional obstruction, and the remaining 103 eyes were normal. For the data set that excluded VE and VDCG, the test accuracies in Python-based TensorFlow, R, multiclass logistic regression in MAMLS, multiclass neural network in MAMLS, and nuclear medicine physician were 81.70%, 80.60%, 81.70%, 73.10%, and 80.60%, respectively. The test accuracies of CNN models in three-class classification diagnosis and binary classification diagnosis were 72.00% and 77.42%, respectively.Conclusions ML-based predictive models using different programming languages and different computing platforms were useful for classifying clinical diagnoses in patients with epiphora and were similar to a clinician’s diagnostic ability."
R-FCN과 Transfer Learning 기법을 이용한 영상기반 건설 안전모 자동 탐지,2019,"['Construction safety', 'Object detection', 'Deep learning', 'Neural network', '건설안전', '물체 탐지', '딥러닝', '인공신경망']","대한민국에서 건설업은 타 업종들과 비교하여 안전사고의 위험성이 가장 높게 나타난다. 따라서 건설업 내 안전성 향상을 도모하기 위해 여러 연구가 예전부터 진행이 되어 왔고, 본 연구에선 건설현장 영상 데이터를 기반으로 물체 탐지 및 분류 알고리즘을 이용해서 효과적인 안전모 자동탐지 시스템을 구축하여 건설현장 노동자들의 안전성 향상에 기여하고자 한다. 본 연구에서 사용된 알고리즘은 Convolutional Neural Network (CNN) 기반의 물체 탐지 및 분류 알고리즘인 Region-based Fully Convolutional Networks (R-FCN)이고 이를 Transfer Learning 기법을 사용하여 딥러닝을 실시하였다. ImageNet에서 수집한 1089장의 사람과 안전모가 포함된 영상으로 학습을 시행하였고 그 결과, 사람과 안전모의 mean Average Precision (mAP)은 각각 0.86, 0.83로 측정되었다.","In Korea, the construction industry has been known to have the highest risk of safety accidents compared to other industries. Therefore, in order to improve safety in the construction industry, several researches have been carried out from the past. This study aims at improving safety of labors in construction site by constructing an effective automatic safety helmet detection system using object detection algorithm based on image data of construction field. Deep learning was conducted using Region-based Fully Convolutional Network (R-FCN) which is one of the object detection algorithms based on Convolutional Neural Network (CNN) with Transfer Learning technique. Learning was conducted with 1089 images including human and safety helmet collected from ImageNet and the mean Average Precision (mAP) of the human and the safety helmet was measured as 0.86 and 0.83, respectively."
Sentinel-1 A/B 위성 SAR 자료와 딥러닝 모델을 이용한 여름철 북극해 해빙 분류 연구,2019,"['Sentinel-1 A/B', 'sea ice', 'thermal noise', 'Deep Learning', 'classification']","북극항로의 개척 가능성과 정확한 기후 예측 모델의 필요성에 의해 북극해 고해상도 해빙 지도의 중요성이 증가하고 있다. 그러나 기존의 북극 해빙 지도는 제작에 사용된 위성 영상 취득 센서의 특성에 따른 데이터의 취득과 공간해상도 등에서 그 활용도가 제한된다. 본 연구에서는 Sentinel-1 A/B SAR 위성자료로부터 고해상도 해빙 지도를 생성하기 위한 딥러닝 기반의 해빙 분류 알고리즘을 연구하였다. 북극해 Ice Chart를 기반으로 전문가 판독에 의해 Open Water, First Year Ice, Multi Year Ice의 세 클래스로 구성된 훈련자료를 구축하였으며, Convolutional Neural Network 기반의 두 가지 딥러닝 모델(Simple CNN, Resnet50)과 입사각 및 thermal noise가 보정된 HV 밴드를 포함하는 다섯 가지 입력 밴드 조합을 이용하여 총 10가지 케이스의 해빙 분류를 실시하였다. 이 케이스들에 대하여 Ground Truth Point를 사용하여 정확도를 비교하고, 가장 높은 정확도가 나온케이스에 대해 confusion matrix 및 Cohen의 kappa 분석을 실시하였다. 또한 전통적으로 분류를 위해 많이 활용되어 온 Maximum Likelihood Classifier 기법을 이용한 분류결과에 대해서도 같은 비교를 하였다. 그 결과Convolution 층 2개, Max Pooling 층 2개를 가진 구조의 Convolutional Neural Network에 [HV, 입사각] 밴드를 넣은 딥러닝 알고리즘의 분류 결과가 96.66%의 가장 높은 분류 정확도를 보였으며, Cohen의 kappa 계수는 0.9499 로 나타나 딥러닝에 의한 해빙 분류는 비교적 높은 분류 결과를 보였다. 또한 모든 딥러닝 케이스는 Maximum Likelihood Classifier 기법에 비해 높은 분류 정확도를 보였다.","The importance of high-resolution sea ice maps of the Arctic Ocean is increasing due to the possibility of pioneering North Pole Routes and the necessity of precise climate prediction models. In this study, sea ice classification algorithms for two deep learning models were examined using Sentinel- 1 A/B SAR data to generate high-resolution sea ice classification maps. Based on current ice charts, three classes (Open Water, First Year Ice, Multi Year Ice) of training data sets were generated by Arctic sea ice and remote sensing experts. Ten sea ice classification algorithms were generated by combing two deep learning models (i.e. Simple CNN and Resnet50) and five cases of input bands including incident angles and thermal noise corrected HV bands. For the ten algorithms, analyses were performed by comparing classification results with ground truth points. A confusion matrix and Cohen’s kappa coefficient were produced for the case that showed best result. Furthermore, the classification result with the Maximum Likelihood Classifier that has been traditionally employed to classify sea ice. In conclusion, the Convolutional Neural Network case, which has two convolution layers and two max pooling layers, with HV and incident angle input bands shows classification accuracy of 96.66%, and Cohen’s kappa coefficient of 0.9499. All deep learning cases shows better classification accuracy than the classification result of the Maximum Likelihood Classifier."
인공 신경망과 웨이블릿 변환을 이용한 주가 지수 예측,2019,"['웨이블릿 변환', '주가 지수 예측', '인공 신경망', '시계열 분석', 'wavelet transform', 'forecasting stock market price', 'artificial neural network', 'time series analysis']","기계학습 기술과 인공신경망 기술의 발전과 함께 주식시장의 흐름을 예측하려는 연구가 다양하게 시도되어 왔다. 특히 영상, 음성 처리를 위한 인공신경망 기술들이 주식시장 예측에 도입되어 예측의 정확도를 향상시키고 있다. 본 논문에서는 KOSPI의 지수변화와 방향성을 예측하기 위해 추출한 기술적 지표를 웨이블릿 변환을 이용하여 고주파수부분과 저주파수부분으로 나누어 인공신경망에서 각각 독립적으로 학습하고 예측한 다음, 고주파수부분과 저주파수부분을 합하여 지수와 방향성을 최종 예측하였다. 인공신경망으로 합성곱신경망, Dual Path Network 그리고 LSTM을 사용하여 인공신경망 간의 성능비교와 웨이블릿 변환의 효용성을 분석하였다. 지수예측에서는 합성곱신경망이 MAPE 0.51%, 등락예측에서는 LSTM이 정확도 81.7%로 최적의 결과를 보였고, 웨이블릿 변환으로 향상된 성능은 지수 예측의 경우 평균 38%, 등락 예측의 경우 평균 25%를 얻어 웨이블릿 변환의 효용성을 확인하였다.","With advancements in technologies on machine learning and artificial neural network, various researches have attempted to predict the changes in the price of the stock market. The prediction accuracy has improved with adoption of new artificial neural network technologies that have been developed for image and voice signal processing. In the present work, the technical indices from KOSPI were decomposed for the prediction of index and movement direction of KOSPI into high-frequency part and low-frequency part using wavelet transform, then used to predict KOSPI independently by using artificial neural networks. For the final prediction, the prediction result of each frequency part was added. CNN, DPN, and LSTM were employed as artificial neural network; the performance of each model was compared and the efficiency of the wavelet transform of input variables was analyzed. CNN with 0.51% of MAPE for the index prediction and LSTM with 81.7% of accuracy for movement prediction showed the best performance among the three models. The efficiency of wavelet transform was confirmed with averaged 38% of the improved performance for the index prediction and averaged 25% of the improved performance for the movement prediction."
An Application of Artificial Intelligence to Diagnostic Imaging of Spine Disease: Estimating Spinal Alignment From Moiré Images,2019,"['Adolescent idiopathic scoliosis', 'Moiré', 'Artificial intelligence', 'Estimation', 'Cobb angle', 'Vertebral rotation']",,"The use of artificial intelligence (AI) as a tool supporting the diagnosis and treatment of spinal diseases is eagerly anticipated. In the field of diagnostic imaging, the possible application of AI includes diagnostic support for diseases requiring highly specialized expertise, such as trauma in children, scoliosis, symptomatic diseases, and spinal cord tumors. Moiré topography, which describes the 3-dimensional surface of the trunk with band patterns, has been used to screen students for scoliosis, but the interpretation of the band patterns can be ambiguous. Thus, we created a scoliosis screening system that estimates spinal alignment, the Cobb angle, and vertebral rotation from moiré images. In our system, a convolutional neural network (CNN) estimates the positions of 12 thoracic and 5 lumbar vertebrae, 17 spinous processes, and the vertebral rotation angle of each vertebra. We used this information to estimate the Cobb angle. The mean absolute error (MAE) of the estimated vertebral positions was 3.6 pixels (~5.4 mm) per person. T1 and L5 had smaller MAEs than the other levels. The MAE per person between the Cobb angle measured by doctors and the estimated Cobb angle was 3.42°. The MAE was 4.38° in normal spines, 3.13° in spines with a slight deformity, and 2.74° in spines with a mild to severe deformity. The MAE of the angle of vertebral rotation was 2.9°±1.4°, and was smaller when the deformity was milder. The proposed method of estimating the Cobb angle and AVR from moiré images using a CNN is expected to enhance the accuracy of scoliosis screening."
합성곱신경망을 이용한 제주도 강수패턴 분석 연구,2019,"['Precipitation', 'Convolution NN (Neural Network)', 'Texture', 'weather satellite', 'Jeju', '강수패턴', '합성곱신경망', '텍스처', '기상위성', '제주지역']",,"Since Jeju is the absolute weight of agriculture and tourism, the analysis of precipitation is more important than other regions. Currently, some numerical models are used for analysis of precipitation of Jeju Island using observation data from meteorological satellites. However, since precipitation changes are more diverse than other regions, it is difficult to obtain satisfactory results using the existing numerical models. In this paper, we propose a Jeju precipitation pattern analysis method using the texture analysis method based on Convolution Neural Network (CNN). The proposed method converts the water vapor image and the temperature information of the area of ​​Jeju Island from the weather satellite into texture images. Then converted images are fed into the CNN to analyse the precipitation patterns of Jeju Island. We implement the proposed method and show the effectiveness of the proposed method through experiments."
전이 학습과 진동 신호를 이용한 설비 고장 진단 및 분석,2019,"['Fault diagnosis', 'Transfer learning', 'Prognostics and health management', 'Deep learning', 'Convolutional neural networks']",,"With the automation of production lines in the manufacturing industry, the importance of real-time fault diagnosis of facility is increasing. In this paper, we propose a fault diagnosis algorithm of LM (Linear Motion)-guide based on deep learning using vibration signals. Generally, in order to guarantee the performance of the deep learning, it is necessary to have a sufficient amount of data, but in a manufacturing industry, it is often difficult to obtain enough data due to physical and time constraints. To solve this problem, we propose a convolutional neural networks (CNN) model based on transfer learning. In addition, the spectrogram image is input to the CNN to reflect the frequency characteristic of the vibration signals with time. The performance of fault diagnosis according to various load condition and transfer learning method was compared and evaluated by experiments. The results showed that the proposed algorithm exhibited an excellent performance."
CTC를 적용한 CRNN 기반 한국어 음소인식 모델 연구,2019,"['Phoneme Recognition', 'CTC Algorithm', 'Convolutional Neural Network', 'Recurrent Neural Network', '음소 인식', 'CTC 알고리즘', '합성곱 신경망', '순환 신경망']",,"For Korean phoneme recognition, Hidden Markov-Gaussian Mixture model(HMM-GMM) or hybrid models which combine artificial neural network with HMM have been mainly used. However, current approach has limitations in that such models require force-aligned corpus training data that is manually annotated by experts. Recently, researchers used neural network based phoneme recognition model which combines recurrent neural network(RNN)-based structure with connectionist temporal classification(CTC) algorithm to overcome the problem of obtaining manually annotated training data. Yet, in terms of implementation, these RNN-based models have another difficulty in that the amount of data gets larger as the structure gets more sophisticated. This problem of large data size is particularly problematic in the Korean language, which lacks refined corpora. In this study, we introduce CTC algorithm that does not require force-alignment to create a Korean phoneme recognition model. Specifically, the phoneme recognition model is based on convolutional neural network(CNN) which requires relatively small amount of data and can be trained faster when compared to RNN based models. We present the results from two different experiments and a resulting best performing phoneme recognition model which distinguishes 49 Korean phonemes. The best performing phoneme recognition model combines CNN with 3hop Bidirectional LSTM with the final Phoneme Error Rate(PER) at 3.26. The PER is a considerable improvement compared to existing Korean phoneme recognition models that report PER ranging from 10 to 12."
Word2Vec과 2계층 양방향 장단기 기억 네트워크를 이용한 특허 문서의 자동 IPC 분류,2019,"['텍스트 마이닝', '문서 분류', '순환 신경망', 'text mining', 'document classification', 'recurrent neural network']","자연어 처리를 이용한 문서 분류 분야에서도 전통적인 방법에서 벗어나 단어 임베딩을 활용한 합성곱 신경망과 순환 신경망 등 심층 신경망을 이용한 다양한 연구가 진행되고 있다. 본 논문에서는 Word2Vec과 두 개의 계층으로 구성된 양방향 장단기 기억 네트워크를 이용한 특허 문서의 IPC(International Patents Classification) 자동 분류 모델을 제안한다. IPC는 세계지식재산권기구에서 제정한 국제적으로 통일된 특허 분류 기준이며, 각 국가의 공인된 기관에서 수작업으로 분류하고 있다. IPC 자동 분류를 위하여 입력 시퀀스에 Word2Vec을 이용한 단어 임베딩가중치를 사용한다. 그리고 가중치가 부여된 시퀀스를 두 개의 계층을 갖는 깊은 구조의 양방향 장단기 기억 네트워크 신경망에 입력하여 IPC를 분류한다. 실험 결과 특허 문서의 분류 정확도가 합성곱 신경망 보다는 약 7% 향상되었으며, 순환 신경망을 단일로 이용하는 것 보다는 약 5% 향상된 것을 확인할 수 있었다. 또한 전통적인 방법인 나이브 베이시안, 로지스틱 분류 및 서포트 벡터 머신보다는 5~12% 이상 우수한 성능을 나타내었다.","There are various studies using Deep Neural Network such as CNN(Convolutional Neural Network) and RNN(Recurrent Neural Network) that utilize word embedding in document classification using natural language processing out of traditional methods. In this paper, we propose the IPC(International Patents Classification) automatic classification model of patent documents using two layers BLSTM(Bidirectional Long Short Term memory) network. The IPC is an internationally uniform standard for patent classification established by the World Intellectual Property Organization and is categorized by hand in authorized agencies in each country. For the IPC automatic classification, we use word embedding weight with Word2Vec in the input sequences. And they are classified by entering a weighted sequences into a deep neural network with two layers BLSTM. The experimental results showed that the accuracy of classification is improved by about 7% than that of CNN, and about 5% than that of single layer LSTM that is a field of RNN. Also it showed more than 5~12% higher performance than traditional methods such as Naive Bayes, Logistic and Support Vector Machine classification."
Text Detection with Deep Neural Network System Based on Overlapped Labels and a Hierarchical Segmentation of Feature Maps,2019,"['Deep neural netwrok', 'detection framework', 'text detection', 'text localization']",,"This paper proposes a three-level framework to detect texts in a single image. First, a salient feature map of text is extracted using a Fully Convolutional Network (FCN) that achieves good performance in semantic segmentation. Label combination using both boxes of word and characters level is proposed to improve the detection of uneven boundaries of text regions. Second, in the feature map of FCN, the text region has a higher probability value than the background region, and the coordinates in the character area are very close to each other. We segment the text area and the background area by using the characteristics of text feature map with Hierarchical Cluster Analysis (HCA). Finally, we applied a Convolutional Neural Networks (CNN) to classify the candidate text area into text and non-text. In this paper,we used CNN which can classify 4 classes in total by separating the background area and three text classes (one character, two characters, three characters or more). The text detection framework proposed in this paper have shown good performance with ICDAR2015, and high performance especially in Recall criterion, ﬁnding more texts than other algorithms."
자율주행 자동차 환경에서의 3D-LiDAR 와 딥러닝을 이용한 클러스터링 후보군 기반 실시간 객체 검출,2019,"['autonomous vehicle', '3d-LiDAR', 'clustering', 'deep learning', 'object detection']",,"Recently, IT companies such as Google, NVIDIA, and NAVER have been also developing autonomous vehicle platform technologies. In particular, sensors for object detection in surrounding environments have been improved in recognition rates by applying multi-sensor systems using camera, LiDAR, and radar. With the increasing importance of recognition technology, 3D information-based recognition technologies have been actively advanced as a commercial product of 3D-LiDAR. In this paper, a candidate group of point-clouds from 3D-LiDAR is extracted using Euclidean clustering in order to reduce the processing time delay in RPN (Region Proposal Network), which is one of the basic schemes for existing object detection. Then, it proposes types of input slicing, based on the extracted candidates. In addition, the accuracy and the processing time using four CNN networks (Basic CNN, ResNet, VGG16, and MobileNet) are compared over not only the private data (CVLab dataset) obtained in actual road environment but also the publicly open KITTI dataset."
딥러닝을 이용한 번호판 검출과 인식 알고리즘,2019,"['License Plate', 'SVM', 'Machine Learning', 'Deep Learning', 'Intelligent Transportation System']",최근 지능형 교통관제 시스템에 관한 다양한 연구가 진행되고 있는 가운데 번호판 검출과 인식 알고리즘은 가장 중요한요소 중에 하나로 대두되고 있다. 번호판은 차량의 고유 식별값을 가지고 있기 때문이다. 기존의 차량 통행 관제 시스템은정차를 기반으로 하고 있으며 차량의 입출입 인식 방법으로 루프 코일을 사용하고 있다. 이러한 방법은 교통 정체를 유발하고 유지보수 비용이 상승하는 단점을 가지고 있다. 본 논문에서는 이러한 문제점을 해결하기 위해서 차량의 입출입 인식 방법으로 카메라 영상을 사용한다. 차량 통행 관제 시스템의 특성상 카메라가 고정되어 있다. 이에 차량이 접근하면 카메라의배경화면이 달라진다. 이 특징을 이용하여 배경화면의 차분영상을 구하면 차량의 입출입을 인식할 수 있다. 입출입 인식 후한국 번호판의 형태학적 특성을 이용하여 후보 이미지를 추정한다. 그리고 선형 SVM(Support Vector Machine)을 이용해서최종 번호판을 검출한다. 검출한 번호판의 글자와 숫자 인식 방법으로는 CNN(Convolutional Neural Network) 알고리즘을사용한다. 제안한 알고리즘은 기존의 시스템과 달리 검출 위치를 기준으로 글자와 숫자를 인식하기 때문에 번호판의 규격이변해도 인식할 수 있다. 실험한 결과 기존의 번호판 인식 알고리즘들 보다 제안한 알고리즘이 더 높은 인식률을 가진다.,"One of the most important research topics on intelligent transportation systems in recent years is detecting andrecognizing a license plate. The license plate has a unique identification data on vehicle information. The existing vehicletraffic control system is based on a stop and uses a loop coil as a method of vehicle entrance/exit recognition. Themethod has the disadvantage of causing traffic jams and rising maintenance costs. We propose to exploit differentialimage of camera background instead of loop coil as an entrance/exit recognition method of vehicles. After entrance/exitrecognition, we detect the candidate images of license plate using the morphological characteristics. The license plate canfinally be detected using SVM(Support Vector Machine). Letter and numbers of the detected license plate are recognizedusing CNN(Convolutional Neural Network). The experimental results show that the proposed algorithm has a higherrecognition rate than the existing license plate recognition algorithm."
라이다 센서 데이터를 이용한 구형 특징 표현 기반의 도시 구조물 3차원 점 군 분류에 관한 연구,2019,"['a라이다 센서', '거리 데이터', '물체 인식', '도시 구조물', '키티 데이터', '구형 특징 표현', '합성곱 신경망', 'LiDAR Sensor', 'Depth Data', 'Object Recognition', 'Urban Structure', 'KITTI Data', 'Spherical Signature Descriptor', 'Convolutional Neural Network']","물체 인식은 영상 등의 이미지 정보와 깊이 정보 등의 센서 데이터를 이용하여 물체의 종류와 크기, 방향, 위치 등의 고차원적인 공간 정보를 실시간으로 알아내는 기술로 자율주행의 기본 기술이 된다. 본 논문에서는 거리 데이터 기반의 물체인식을 목표로 하고 있으며, 3차원 점을 구성하고 있는 모든 점에 의미를 부여 할 수 있는 구형 특징 표현을 이용한 학습 데이터 생성을 제안하였다. 구형 특징 표현을 이용하여 생성된 학습 데이터는 주변 점들의 분포와 밀집도를 이용하여 한 점의 특징을 정의 함으로서 모든 점들에 대하여 생성이 가능하기 때문에 인공지능을 위한 학습데이터 준비에 매우 용이하게 사용될 수 있다. 본 논문에서는 KITTI 데이터와 직접 수집한 라이다 센서 데이터를 구형 특징 표현에 적용하여 학습 데이터를 생성하고 생성된 학습 데이터를 인공지능 학습의 한 종류인 CNN(Convolutional Neural Network)에 입력하여 도시 구조물에 대한 3차원 점 군을 분류하고자 하였다.","Object recognition is a technology that detects real-time high-dimensional spatial information such as type, size, direction, and position of an object using sensor data such as image information and depth information of photographs. In this study, we aim at achieving object recognition based on distance data and propose the generation of learning data using the spherical signature descriptor capable of giving meaning to all points composing a 3D point group. The learning data generated by using the spherical signature descriptor can easily be used for generating learning data for artificial intelligence because it is possible to define the characteristics of a point using the distribution and density of the surrounding points and to generate from all the points. In this study, we generated learning data by applying collected KITTI and LiDAR sensor data directly to the spherical signature descriptor and classifying the urban structures through artificial intelligence learning using a CNN (convolutional neural network)."
An Intrusion Detection Model based on a Convolutional Neural Network,2019,"['Intrusion detection', 'Deep learning', 'Convolutional neural network', 'Recurrent neural network.']",,"Machine-learning techniques have been actively employed to information security in recent years. Traditional rule-based security solutions are vulnerable to advanced attacks due to unpredictable behaviors and unknown vulnerabilities. By employing ML techniques, we are able to develop intrusion detection systems (IDS) based on anomaly detection instead of misuse detection. Moreover, threshold issues in anomaly detection can also be resolved through machine-learning. There are very few datasets for network intrusion detection compared to datasets for malicious code. KDD CUP 99 (KDD) is the most widely used dataset for the evaluation of IDS. Numerous studies on ML-based IDS have been using KDD or the upgraded versions of KDD. In this work, we develop an IDS model using CSE-CIC-IDS 2018, a dataset containing the most up-to-date common network attacks. We employ deep-learning techniques and develop a convolutional neural network (CNN) model for CSE-CIC-IDS 2018. We then evaluate its performance comparing with a recurrent neural network (RNN) model. Our experimental results show that the performance of our CNN model is higher than that of the RNN model when applied to CSE-CIC-IDS 2018 dataset. Furthermore, we suggest a way of improving the performance of our model."
딥러닝 신경망을 이용한 신용카드 부도위험 예측의 효용성 분석,2019,"['딥러닝', '인공신경망', '신용카드', '부도위험', '머신러닝', 'Deep Learning', 'Artificial Neural Network', 'Credit Card', 'Default Risk', 'Machine Learning']","본 연구는 국내․외 금융시장에서 아직 활성화되지 못한 딥러닝 신경망(deep learning neural network) 알고리즘을 이용해 신용카드 부도위험 예측의 정확도 향상 가능성에 대해서 점검한다. 이를 위해 기존 머신러닝 알고리즘(Logistic, SVM, Random Forest, Lasso 등)을 딥러닝 신경망 분석의 성능 점검을 위한 비교 지표로 활용한다. 우선, 딥러닝 신경망은 두 개의 은닉층(hidden layers)과 다섯 개의 뉴런(neuron)으로 구축하고, 활성함수(activation function)와 초기값(initial value) 설정방법에 따른 예측정확도를 도출한다. 그 결과 딥러닝 신경망 분석이 기존 머신러닝 알고리즘 보다 최소 0.6%p에서 최대 6.6%p 성능이 향상된 것으로 나타났다. 이 중 가장 높은 예측 정확도를 보인 활성함수와 초기값 설정방식은 ReLU(rectified linear units)와 Xavier(2010)이고 이를 기준으로 은닉층과 뉴런의 수를 각각 최대 10개와 25개까지 늘려 분석한 결과에서도 유사한 결과가 나타났다. 다만, 기존 연구에서와 같이 은닉층과 뉴런의 수의 증가에 따른 뚜렷한 성능의 향상은 나타나지 않았다. 또한, 이미지 식별 분야에서 높은 성능을 보였던 Dropout과 CNN(convolution neural network) 모델도 예측 정확도에서 큰 차이를 보이지 않았다. 이는 여기에서 사용된 신용카드 데이터가 다수 픽셀(pixel)로 이루어진 이미지 데이터와 비교해 양적․질적 한계가 있기 때문으로 판단된다. 한편, 본 연구에서 사용된 개인의 신용카드 부도 데이터는 횡단면 자료이기 때문에 시계열 데이터에서 높은 성능을 나타내는 RNN(recurrent neural network) 및 LSTM(Long- Short Term Memory) 등의 딥러닝 신경망 알고리즘을 사용하지는 않았다. 따라서 추후 시계열 자료가 포함된 빅데이터를 통해 이들 딥러닝 신경망 방법론을 적용한다면, 현재의 다양한 금융시장의 식별문제(신용등급, 연체율, 금리산정)에 있어 보다 향상된 결과를 도출할 수 있을 것으로 기대된다.","This study aims to discuss the usefulness of the deep learning neural network and the possibility of the deep learning neural network analysis in judging credit information by using credit card default data. Deep learning neural network analysis in the financial sector excluding the current stock price prediction model is under limited research. It is mainly used for upgrading models of the credit rating (Kvamme et al., 2016, 2018; Tran, 2016; Luo, 2017) and the delinquency rate (Sirignano et al., 2018).In the credit card market, it is focused on credit card issuance and fraud detection model (Ramanathan, 2014, Niimi, 2015). As mentioned earlier, there has not been much analysis of deep learning neural network using financial market data. This is because the study of deep learning neural networks is actively carried out mainly in the field of computer science such as image, speech recognition, natural language processing. Additionally, Researchers in the financial sector have difficulty learning deep learning algorithms and setting up a computer runtime environment. It is also difficult to apply the algorithm to financial data due to lower dimension than the image. Nowadays, financial companies have been interested in machine learning and are increasing their recruitment, but it is still in the stage of verifying the possibility of deep learning neural network.Therefore, This study examines the possibility of improving the accuracy of credit card default risk prediction by using a deep learning neural network algorithm. To do this, we use existing machine learning algorithms (Logistic, SVM, Random Forest, Lasso, etc.) as a comparison index for performance check of deep learning neural network analysis. Firstly, the deep learning neural network is constructed with two hidden layers and five neurons, and derives the prediction accuracy according to the activation function and the initial value setting method. There are Sigmoid, ReLU, tanh and Maxout as active functions, and random value, Xavier, RBM, He’s as initialization methods. Based on this, we compare the accuracy of existing machine learning algorithms. As a result, the deep learning neural network analysis showed performance improvement between 0.6% and 6.6%p compared to the existing machine learning algorithms (Logistic, SVM, Random Forest, Lasso, etc.). Among these results, the active function and the initial value setting method with the highest prediction accuracy are ReLU (rectified linear units) and Xavier initialization. However, there is no significant improvement in performance with increasing number of hidden layers and neurons up to 10 and 25, respectively. Also, the dropout and CNN (convolution neural network) models, which showed high performance in the field of image identification, showed no significant difference in prediction accuracy.Nevertheless, it could be interpreted that the increase of hidden layers can improve the accuracy of estimation because the highest accuracy (0.8161) and the AUC (0.7726) are observed for 10 hidden nodes and 15 neurons.However, we can’t say that accuracy increases linearly by the number of hidden layers and neurons. These limitation could be due to the quantitative and qualitative limitations of the credit card data used here. We did not use recurrent neural network (RNN) and long-short term memory (LSTM) models since the personal default data for credit card used in this study is cross-sectional data. These method are for Time-Series data. Therefore, it is expected that it will be able to obtain better results in identification problems (credit rating, delinquency rate, interest rate calculation) of present various financial markets if these deep learning neural network methodologies are applied through big data including time series data.This study can be turned into a question of how deep learning analysis can lower the default risk and delinquency rate by using financial data from a practical point of ..."
A Multi-Stage Convolution Machine with Scaling and Dilation for Human Pose Estimation,2019,"['CNN', 'Human pose estimation', 'Multi-stage', 'Pyramid stacking', 'Dilation', 'Gating']",,"Vision-based Human Pose Estimation has been considered as one of challenging research subjects due to problems including confounding background clutter, diversity of human appearances and illumination changes in scenes. To tackle these problems, we propose to use a new multi-stage convolution machine for estimating human pose. To provide better heatmap prediction of body joints, the proposed machine repeatedly produces multiple predictions according to stages with receptive field large enough for learning the long-range spatial relationship. And stages are composed of various modules according to their strategic purposes. Pyramid stacking module and dilation module are used to handle problem of human pose at multiple scales. Their multi-scale information from different receptive fields are fused with concatenation, which can catch more contextual information from different features. And spatial and channel information of a given input are converted to gating factors by squeezing the feature maps to a single numeric value based on its importance in order to give each of the network channels different weights. Compared with other ConvNet-based architectures, we demonstrated that our proposed architecture achieved higher accuracy on experiments using standard benchmarks of LSP and MPII pose datasets."
사람 재인식을 위한 개선된 PersonNet,2019,"['PersonNet', 'CNN', 'Inception Layer', 'Cross neighborhood difference', 'Person re-Identification']","이 논문에서는 사람 재식별 모델인 PersonNet의 성능을 개선하는 방법을 제안하고 실험한다. 특징점 추출을 위해 인셉션 레이어를 접목하여, 기존 32개의 특징점을 154개로 증가시켜 강화하였다. 또한, PersonNet에서 사용하는 CND 방식을 수정하여 비대칭성을 완화하였고, 보행자 이미지의 특징점을 3부분으로 나누어 가중치를 적용한 방법을 적용하여 특징을 더 뚜렷하게 파악하도록 하였다. 성능 평가를 위해 CUHK01, CUHK03 그리고 Market-1501 3가지의 데이터베이스를 사용하였고 실험결과 27～31% 성능이 개선되었다.","This paper propose and experiment advanced PersonNet, a human identification model, with advanced performance. We apply the inception layer to extract feature points, and increase the existing 32 feature points to 154. Also, we modify the CND method used by PersonNet to mitigate asymmetry, and apply weights to the feature map of pedestrian images in three parts, thereby making the features more distinct. Three databases were used for performance evaluation：CUHK01, CUHK03 and Market-1501. The experiment results showed 27-31% improvement in performance."
SHVC 부호화 성능 개선을 위한 딥러닝 기반 계층간 참조 픽처 생성 방법,2019,"['Scalable HEVC', 'CNN', 'Deep learning', 'Super resolution', 'Inter-layer prediction']","본 논문에서는 SHVC 부호화 성능 개선을 위하여 딥러닝 기반 계층간 예측을 위한 참조 픽처 생성 방법을 제안한다. 새로운 참조 픽처를 생성하기 위하여 DCT-IF기반 업샘플링 된 픽처를 VDSR 네트워크를 이용한 필터링을 진행하는 구조와 SHVC 계층간 참조 픽처를 생성하기 위한 트레이닝 방법에 대해 설명한다. 제안하는 방법은 SHM 12.0 기반으로 구현되어 있다. 성능 평가를 위하여 사전 학습을 이용하여 계층간 예측 픽처를 생성하는 방법과 비교를 진행하였다. 그 결과 상위 계층의 부호화 성능은 사전 학습을 이용한 방법 대비 최대 13.14%의 비트 감소, SHM 대비 최대 15.39%의 비트 감소율을 보였고, 평균 6.46%의 비트 감소율을 보였다.",
딥러닝 기반의 이미지 분류를 이용한 패션 이미지 검색 웹사이트,2019,"['Computer vision', 'CNN', 'Deep learning', 'Image classification', 'Web']","기존에 존재하는 패션 웹 사이트 에서는 상의, 하의 등의 품목에서는 한 가지 종류의 옷에 대한 검색결과만 보여주기 때문에사용자가 원하는 옷에 대한 조합을 찾을 수 없다. 또 패션 시장이 성장함에 따라 소비자들은 다양한 패션 정보를 찾을 수 플랫폼을 요구하고 있다. 이러한 문제를 해결하고자 하여 딥러닝을 통한 이미지분류를 웹 사이트와 연동하고 SNS 기능을 접목하는 아이디어를 고안해냈다. 웹 사이트에 사용자가 본인의 이미지을 업로드하여 딥러닝 서버를 통해서 이미지의 특징을 파악하고 분류하여 저장한다. 사용자들은 저장된 정보를 가지고 여러 조합을 통해 원하는 이미지들을 검색할 수 있다. 또 SNS 기능을 통해사용자간의 커뮤니케이션이 활발하게 이루어질 수 있다. 이를 통해서 기존에 존재하는 패션 관련 사이트의 문제를 해결하는 방안을 마련하였다.","Existing fashion web sites show only the search results for one type of clothes in items such as tops and bottoms. As the fashionmarket grows, consumers are demanding a platform to find a variety of fashion information. To solve this problem, we devised theidea of linking image classification through deep learning with a website and integrating SNS functions. User uploads their ownimage to the web site and uses the deep learning server to identify, classify and store the image’s characteristics. Users can use thestored information to search for the images in various combinations. In addition, communication between users can be activelyperformed through the SNS function. Through this, the plan to solve the problem of existing fashion-related sites was prepared."
가시광-근적외선 혼합 영상에서의 얼굴인식에 관한 연구,2019,"['Face Recognition', 'CNN (Convolutional Neural Networks)', 'Deep Learning']",,
Interworking technology of neural network and data among deep learning frameworks,2019,"['AI', 'AlexNet', 'Caffe', 'CNN', 'deep learning', 'interworking', 'neural network', 'NNEF', 'parser', 'Tensorflow']",,"Based on the growing demand for neural network technologies, various neural network inference engines are being developed. However, each inference engine has its own neural network storage format. There is a growing demand for standardization to solve this problem. This study presents interworking techniques for ensuring the compatibility of neural networks and data among the various deep learning frameworks. The proposed technique standardizes the graphic expression grammar and learning data storage format using the Neural Network Exchange Format (NNEF) of Khronos. The proposed converter includes a lexical, syntax, and parser. This NNEF parser converts neural network information into a parsing tree and quantizes data. To validate the proposed system, we verified that MNIST is immediately executed by importing AlexNet's neural network and learned data. Therefore, this study contributes an efficient design technique for a converter that can execute a neural network and learned data in various frameworks regardless of the storage format of each framework."
단일 영상 비균일 블러 제거를 위한 다중 학습 구조,2019,"['Dynamic Motion Deblurring', 'CNN', 'Motion Estimation', 'Multi-task Architecture']",,"We present a novel deep learning architecture for obtaining a latent image from a single blurry image, which contains dynamic motion blurs through object/camera movements. The proposed architecture consists of two sub-modules: blur image restoration and optical flow estimation. The tasks are highly related in that object/camera movements make cause blurry artifacts, whereas they are estimated through optical flow. The ablation study demonstrates that training multi-task architecture simultaneously improves both tasks compared to handling them separately. Objective and subjective evaluations show that our method outperforms the state-of-the-arts deep learning based techniques."
딥런닝 기반의 프레임 유사성을 이용한화재 오탐 검출 개선 연구,2019,"['deep learning', 'faster r-cnn', 'fire detection', 'smoke detection', 'ssim']","화염 및 연기 감지 알고리즘 연구는 다양한 모양, 빠른 확산 및 색상으로 인해 컴퓨터 비전에서 어려운 과제이다. 일반적인센서 기반 화재 감지 시스템의 성능은 환경 요인 (실내 및 화재발생 위치)에 따라 크게 제한된다. 이러한 문제를 해결하기위해 딥러닝 방법을 적용하였으며, 이것은 물체의 형상을 특징으로 추출하므로 비슷한 형상이 프레임내에 존재하면 오탐으로검출 될 수 있다. 본 연구는 화재 오탐 검출 개선을 위해 딥런닝 사용 전과 후에 프레임 유사성을 이용하여 오탐을 줄이는새로운 알고리즘을 제안한다. 실험결과 제안된 방법을 적용하여 화재 검출 성능은 유지를 하면서 오탐 부분이 최소 30% 까지 감소하는 결과를 얻을 수 있었다. 제안된 방법의 오탐 검출 성능이 뛰어나다는 것을 확인하였다.","Fire flame and smoke detection algorithm studies are challenging task in computer vision due to the variety of shapes,rapid spread and colors. The performance of a typical sensor based fire detection system is largely limited byenvironmental factors (indoor and fire locations). To solve this problem, a deep learning method is applied. Because itextracts the feature of the object using several methods, so that if a similar shape exists in the frame, it can be detectedas false postive. This study proposes a new algorithm to reduce false positives by using frame similarity before usingdeep learning to decrease the false detection rate. Experimental results show that the fire detection performance ismaintained and the false positives are reduced by applying the proposed method. It is confirmed that the proposed methodhas excellent false detection performance"
딥 러닝 기반의 SIFT 이미지 특징 추출,2019,"['SIFT Feature extraction', 'Deep learning', 'VGG', 'CNN(Convolutional Neural Network)', 'Repeatability']","본 논문에서는 일정 크기로 자른 영상의 가운데 픽셀이 SIFT 특징점인지를 판별함으로써 SIFT 특징점을 추출하는 딥 뉴럴 네트워크(Deep Neural Network)를 제안한다. 이 네트워크의 데이터 세트는 DIV2K 데이터 세트를 33×33 크기로 잘라서 구성하고, 흑백 영상으로 판별하는 SIFT와는 달리 RGB 영상을 사용한다. 그라운드 트루스(ground truth)는 옥타브(scale, octave)를 0, 시그마(sigma)는 1.6, 간격(intervals)은 3으로 설정하여 추출한 RobHess SIFT 특징들로 구성한다. VGG-16을 기반으로 컨볼루션 층을 13개에서 23개와 33개로 점점 깊은 네트워크를 구성하고, 영상의 스케일을 증가시키는 방법을 바꿔가며 실험을 수행한다. 출력 층의 활성화 함수로 시그모이드(sigmoid) 함수를 사용한 결과와 소프트맥스(softmax) 함수를 사용한 결과를 비교하여 분석한다. 실험결과 제안한 네트워크가 99% 이상의 추출 정확도를 가질 뿐 아니라 왜곡된 영상에 대해서도 높은 추출 반복성을 가진다는 것을 보인다.",
Implementation of Melody Playback Method through Image Classification and Stroke Analysis,2019,"['Music', 'Image classification', 'Stroke analysis', 'Audioization', 'CNN', 'Google Quick Draw']",,"In this study, we devised a application that generates and reproduces music by analyzing images received from a user. It was aimed not only to capture the technical meaning of auditioning images, but also to express emotions and intentions in user's images. In the proposed application, a user draws a picture of a desired object. The application uses artificial intelligence to determine which object an image is. After that, the emotions that can be connected with each objects. The application determines the key that matches the mood through the emotion associated with the object. After setting a key suitable for the emotion, the user's stroke order is analyzed, and the melody is composed based on the extracted user’s stroke data. In the future, research on arts such as painting and music will be continued as well as implementing auditory expression of images. Based on this, we will present the direction to embody the artistic and intention in the image into music. It will also be a meaningful attempt as a direction of combination between engineering fields such as artificial intelligence for recognizing pictures and art fields such as picture analysis, and music production."
Implementation of Melody Playback Method through Image Classification and Stroke Analysis,2019,"['Music', 'Image classification', 'Stroke analysis', 'Audioization', 'CNN', 'Google Quick Draw']",,"In this study, we devised a application that generates and reproduces music by analyzing images received from a user. It was aimed not only to capture the technical meaning of auditioning images, but also to express emotions and intentions in user s images. In the proposed application, a user draws a picture of a desired object. The application uses artificial intelligence to determine which object an image is. After that, the emotions that can be connected with each objects. The application determines the key that matches the mood through the emotion associated with the object. After setting a key suitable for the emotion, the user s stroke order is analyzed, and the melody is composed based on the extracted user’s stroke data. In the future, research on arts such as painting and music will be continued as well as implementing auditory expression of images. Based on this, we will present the direction to embody the artistic and intention in the image into music. It will also be a meaningful attempt as a direction of combination between engineering fields such as artificial intelligence for recognizing pictures and art fields such as picture analysis, and music production."
IoT 및 딥 러닝 기반 스마트 팜 환경 최적화 및 수확량 예측 플랫폼,2019,"['Agricultural', 'Analysis System', 'Artificial Intelligence System', 'CNN', 'Smart Farm']","본 논문은 농장의 바이오 센서 데이터를 수집해서 농장에서 재배중인 농작물의 질병을 진단하고, 그 해 수확량을 예측하는 IoT 및 딥 러닝 기반 스마트 팜 환경 최적화 및 수확량 예측 플랫폼을 제안한다. 이 플랫폼은 현재 날씨, 토양 미생물 등 수집 가능한 모든 정보를 수집하여 작물이 잘 성장할 수 있도록 농장 환경을 최적화하고, 농장에서 재배 중인 작물의 잎을 이용하여 작물의 질병을 진단하고, 그리고, 농장의 모든 정보를 사용하여 올해 수확량을 예측한다. 실험 결과 AEOM(Agricultural Environment Optimization Module)의 평균 정확도는 RF(Random Forest)보다 약 15%, GBD(Gradient Boosting Tree)보다 약 8% 높고, 데이터가 증가해도 RF나 GBD에 비해 정확도가 덜 감소한다. 선형 회귀에 따르면 정확도의 기울기는 ReLU의 경우 –3.641E-4, Sigmoid의 경우 –4.0710E-4, 계단함수의 경우 –7.4534E-4이다. 따라서 ReLU 사용시 정확도 기울기가 가장 낮으므로 테스트 데이터의 양이 증가함에 따라 ReLU는 다른 두 가지 활성화 기능보다 더 정확하다. 본 논문에서 제안한 EOYPP는 농장 전체를 관리하는 플랫폼으로 실제 농장에 도입된다면 국내 스마트 팜의 발전에 크게 이바지할 것이다.","This paper proposes “A Smart Farm Environment Optimization and Yield Prediction Platform based on IoT and Deep Learning” which gathers bio-sensor data from farms, diagnoses the diseases of growing crops, and predicts the year's harvest. The platform collects all the information currently available such as weather and soil microbes, optimizes the farm environment so that the crops can grow well, diagnoses the crop’s diseases by using the leaves of the crops being grown on the farm, and predicts this year's harvest by using all the information on the farm. The result shows that the average accuracy of the AEOM is about 15% higher than that of the RF and about 8% higher than the GBD. Although data increases, the accuracy is reduced less than that of the RF or GBD. The linear regression shows that the slope of accuracy is –3.641E-4 for the ReLU, –4.0710E-4 for the Sigmoid, and –7.4534E-4 for the step function. Therefore, as the amount of test data increases, the ReLU is more accurate than the other two activation functions. This paper is a platform for managing the entire farm and, if introduced to actual farms, will greatly contribute to the development of smart farms in Korea."
적응형 채널 어텐션 모듈을 활용한 복합 열화 복원 네트워크,2019,"['Image restoration', 'Deep learning', 'Channel attention', 'CNN', '영상복원', '딥러닝', '채널 어텐션', '합성곱신경망']",자율 주행 자동차나 소방 로봇과 같은 시스템에서 영상을 얻을 때 다양한 요인들로 인해 잡음，블러와 같은 열화가 발생한 다. 이런 열화된 영상에 직접 영상 분류와 같은 기술을 적용하기 어려워 열화 제거가 불가피하나 이러한 시스템들은 영상의 열화를 인식할 수 없어서 열화된 영상을 복원하는데 어려움이 있다. 본 논문에서는 영상에 적용된 열화를 인지하지 못하는 상황에서 여러 방법들로 열화된 영상으로부터 자연스럽고 선명한 영상을 복원하는 방법을 제안한다. 우리가 제안한 방법은 딥러닝 모델에 채널 어텐션 모듈과스깁 커넥션을사용하여 영상에 적용된 열화에 따라복원에 필요한 채널에 높은 가중치를 적용해 복합 열화 영상의 복원을 진행한다. 이 방법은 다른복합 열화복원 방법 에 비해 학습이 간단하고 기존의 다른 방법들에 비 해 높은 복합 열화 복원 성능을 낸다.,"The image obtained from systems such as autonomous driving cars or fire-fighting robots often suffer from several degradation such as noise, motion blur, and compression artifact due to multiple factor. It is difficult to apply image recognition to these degraded images, then the image restoration is essential. However, these systems cannot recognize what kind of degradation and thus there are difficulty restoring the images. In this paper, we propose the deep neural network, which restore natural images from images degraded in several ways such as noise, blur and JPEG compression in situations where the distortion applied to images is not recognized. We adopt the channel attention modules and skip connections in the proposed method, which makes the network focus on valuable information to image restoration. The proposed method is simpler to train than other methods, and experimental results show that the proposed method outperforms existing state-of-the-art methods."
Implementation of Melody Playback Method through Image Classification and Stroke Analysis,2019,"['Music', 'Image classification', 'Stroke analysis', 'Audioization', 'CNN', 'Google Quick Draw']","본 연구에서는 사용자로부터 입력받은 이미지를 분석하여 그에 맞는 음악을 생성, 재생하는 방법을 고안 하였다. 단순히 이미지를 청각화 하는 기술적인 의미 뿐 아니라 사용자의 이미지에 담긴 정서와 의도 또한 담아내는 것을 목표로 하였다. 사용자는 본 연구에서 제안된 어플리케이션에 원하는 물체를 그린다. 인공지능을 통해 이미지가 어떤 물체인지 판별 후, 그 물체와 이어질 수 있는 감정을 대응해 해당 멜로디의 감정과 분위기를 맞출 수 있도록 하였다. 정서에 알맞는 음정(key)를 설정한 뒤, 사용자가 이미지를 그릴 때 입력한 획순을 분석해 이를 기준으로 음계를 추출하여 선율을 생성하였다. 향후 이미지의 청각적 표현을 구현하는 것뿐만 아니라 그림에 대한 예술적인 이해와 의미 있는 음악을 만들어내기 위한 화성법 등의 작곡이론을 연구하여 이미지에 담긴 예술성과 의도를 음악에 담아낼 수 있는 한 가지 방향을 제시할 것이다. 또한 그림을 인식하고 판별하기 위한 인공지능 기술과 그림 분석, 음악 생성 등의 예술 분야를 결합해 공학과 예술의 융합이라는 방향으로서 의미 있는 시도가 될 것이다.","In this study, we devised a application that generates and reproduces music by analyzing images received from a user. It was aimed not only to capture the technical meaning of auditioning images, but also to express emotions and intentions in user s images. In the proposed application, a user draws a picture of a desired object. The application uses artificial intelligence to determine which object an image is. After that, the emotions that can be connected with each objects. The application determines the key that matches the mood through the emotion associated with the object. After setting a key suitable for the emotion, the user s stroke order is analyzed, and the melody is composed based on the extracted user’s stroke data. In the future, research on arts such as painting and music will be continued as well as implementing auditory expression of images. Based on this, we will present the direction to embody the artistic and intention in the image into music. It will also be a meaningful attempt as a direction of combination between engineering fields such as artificial intelligence for recognizing pictures and art fields such as picture analysis, and music production."
Video Representation via Fusion of Static and Motion Features Applied to Human Activity Recognition,2019,"['Activity recognition', 'static features', 'motion features', 'trajectories', 'CNN', 'LSTM']",,"In human activity recognition system both static and motion information play crucial role for efficient and competitive results. Most of the existing methods are insufficient to extract video features and unable to investigate the level of contribution of both (Static and Motion) components. Our work highlights this problem and proposes Static-Motion fused features descriptor (SMFD), which intelligently leverages both static and motion features in the form of descriptor. First, static features are learned by two-stream 3D convolutional neural network. Second, trajectories are extracted by tracking key points and only those trajectories have been selected which are located in central region of the original video frame in order to to reduce irrelevant background trajectories as well computational complexity. Then, shape and motion descriptors are obtained along with key points by using SIFT flow. Next, cholesky transformation is introduced to fuse static and motion feature vectors to guarantee the equal contribution of all descriptors. Finally, Long Short-Term Memory (LSTM) network is utilized to discover long-term temporal dependencies and final prediction. To confirm the effectiveness of the proposed approach, extensive experiments have been conducted on three well-known datasets i.e. UCF101, HMDB51 and YouTube. Findings shows that the resulting recognition system is on par with state-of-the-art methods."
Style Transfer Deep Learning Framework for Nighttime Robust Vehicle Detection in On-Road Mobile Platforms,2019,"['style transfer', 'Convolutional Neural Network (CNN)', '자율주행차량', '차량인식', 'self-driving car', 'vehicle detection']",,
딥러닝을 이용한 야간 감시 열화상 카메라 개발에 관한 연구,2019,"['Thermal camera', 'Infrared', 'Deep learning', 'CNN', 'YOLO']",,
인공지능 기반의 행동인식을 통한 개인 운동 트레이너 구현의 방향성 제시,2019,"['Healthcare', 'Fitness', 'Artificial Intelligence', 'Deep Running', 'CNN', 'RNN', '헬스케어', '피트니스', '인공지능', '딥러닝', '합성곱 신경망', '순환 신경망']","최근 딥러닝을 비롯한 인공지능 기술의 활용이 다양한 분야에서 활발해지고 있으며, 특히 딥러닝 기술 기반의 객체 인식 및 검출에 뛰어난 성능을 보이는 여러 알고리즘들이 발표되고 있다. 이에 본 논문에서는 사용자의 편의성이 효과적으로 반영된 모바일 헬스케어 애플리케이션 구현에 대한 적절한 방향성을 제시하고자 한다. 기존의 피트니스 애플리케이션들에 대한 이용 만족도 연구 및 모바일 헬스케어 애플리케이션에 대한 현황을 파악하여, 이로부터 피트니스 애플리케이션 시장에서의 생존과 우위를 확보하는 동시에, 최근 주목 받고 있는 인공지능 기술의 효과적인 적용에 의한 성능 개선을 통해 기존 이용자 유지 및 확대를 도모하고자 한다.","Recently, the use of artificial intelligence technology including deep learning has become active in various fields. In particular, several algorithms showing superior performance in object recognition and detection based on deep learning technology have been presented. In this paper, we propose the proper direction for the implementation of mobile healthcare application that user's convenience is effectively reflected. By effectively analyzing the current state of use satisfaction research for the existing fitness applications and the current status of mobile healthcare applications, we attempt to secure survival and superiority in the fitness application market, and, at the same time, to maintain and expand the existing user base."
Deep Learning Based Tree Recognition rate improving Method for Elementary and Middle School Learning,2019,"['Machine Learning', 'Deep Learning', 'Convolutional Neural Network', 'CNN', 'Inception V3', 'Smart Device Education', '머신러닝', '딥러닝', '컨볼루션 신경망', '인셉션V3', '스마트기기교육']","본 연구의 목적은 수업 시 스마트기기에 적용할 수 있는 나무 이미지를 인식하고 분류하여 정확도를 측정할 수 있는 효율적인 모델을 제안하는 것이다. 2015개정 교육과정으로 개정되면서 초등학교 4학년 과학교과서의 학습 목표에서 스마트 기기 사용한 식물 인식이 새롭게 추가 되었다. 특히 나무 인식의 경우 다른 사물 인식과 달리 수형, 수피, 잎, 꽃, 열매의 부위별 특징이 있으며, 계절에 따라 모양 및 색깔의 변화를 거치므로 인식률에 차이가 존재한다. 그러므로 본 연구를 통해 컨볼루션 신경망 기반의 사전 학습된 인셉션V3모델을 이용하여 재학습 전 후의 나무 부위별 인식률을 비교한다. 또한 각 나무의 유형별 이미지 정확도를 결합시키는 방식을 통해 효율적인 나무 분류 방안을 제시하며 교육현장에서 사용하는 스마트기기에 적용 할 수 있을 것이라 기대한다.","The goal of this study is to propose an efficient model for recognizing and classifying tree images to measure the accuracy that can be applied to smart devices during class. From the 2009 revised textbook to the 2015 revised textbook, the learning objective to the fourth-grade science textbook of elementary schools was added to the plant recognition utilizing smart devices. In this study, we compared the recognition rates of trees before and after retraining using a pre-trained inception V3 model, which is the support of the Google Inception V3. In terms of tree recognition, it can distinguish several features, including shapes, bark, leaves, flowers, and fruits that may lead to the recognition rate. Furthermore, if all the leaves of trees may fall during winter, it may challenge to identify the type of tree, as only the bark of the tree will remain some leaves. Therefore, the effective tree classification model is presented through the combination of the images by tree type and the method of combining the model for the accuracy of each tree type. I hope that this model will apply to smart devices used in educational settings."
딥 러닝을 이용한 안면 여드름 분류 모델,2019,"['Deep Learning', 'Classification', 'Correlation Analysis', 'ACNE', 'CNN', '딥 러닝', '분류', '상관분석', '여드름', '컨볼루션 뉴럴 네트워크']","의학계에 다양하게 인공지능을 적용하는데 있어 한계는 우선적으로 해석자의 병증 이미지를 해석하는데 주관적 견해와 광범위한 해석자, 육체적 피로감 등이다. 그리고 병증마다 주석 달린 데이터 셋을 수집하는데 기간이 오래 걸린다는 것과 개발된 딥러닝 학습 알고리즘의 성능 저하가 없으면서도 충분한 훈련 데이터를 얻을지에 대한 의문이 있다는 것이다.이에 본 논문에서는 여드름 데이터 셋을 기준으로 기본 이미지를 수집할 때 선정 기준과 수집 절차에 대해 연구하고, Sequential 구조로 딥 러닝 기법을 적용하여 적은 손실률(5.46%)과 높은 정확도(96.26%)로 데이터를 분류하는 모델을 제안한다. Keras에서 기본 제공하는 모델과 비교실험을 통해 제안 모델의 성능을 비교 검증한다. 향후 본 논문에서 제안하는 여드름 분류 모델에 유사 현상들 적용하여 의학 및 피부 관리 분야에도 적용 가능할 것으로 예상된다.","The limitations of applying a variety of artificial intelligence to the medical community are, first, subjective views, extensive interpreters and physical fatigue in interpreting the image of an interpreter's illness. And there are questions about how long it takes to collect annotated data sets for each illness and whether to get sufficient training data without compromising the performance of the developed deep learning algorithm.In this paper, when collecting basic images based on acne data sets, the selection criteria and collection procedures are described, and a model is proposed to classify data into small loss rates (5.46%) and high accuracy (96.26%) in the sequential structure. The performance of the proposed model is compared and verified through a comparative experiment with the model provided by Keras. Similar phenomena are expected to be applied to the field of medical and skin care by applying them to the acne classification model proposed in this paper in the future."
한국어 음성 명령어 인식을 위한 자동데이터 구축,2019,"['Korean Speech Command', 'Speech Recognition', 'Automatic Data Construction', 'ResNet', 'CNN', '한국어 명령어 인식', '음성인식', '자동 데이터 구축', '레스넷', '합성곱신경망']","최근 화두가 되고 있는 AI분야에서 가장 큰 문제점은 학습데이터의 부족 문제를 꼽을 수 있다. 수동 데이터 구축에는 많은 시간과 노력이 소요되기에 개인이 손쉽게 필요 데이터를 구축하기는 매우 어렵다. 반면, 수동 데이터 구축에 비해 자동으로 구축하는 것은 높은 품질을 유지하는 것이 관건이다. 본 논문에서는 한국어 음성 명령어 인식기 개발에 필요한 데이터를 웹에서 자동으로 추출하고, 학습데이터로 사용할 수 있는 데이터를 자동으로 선별하는 방법을 소개한다. 특히, 자동 구축된 한국어 음성 데이터를 대상으로 우수한 성능을 보이는 ResNet기반의 수정 모델을 기반으로, 건강 및 일상생활도메인의 명령어 셋을 대상으로 적용가능성을 보이기 위한 실험을 진행하였다. 자동으로 구축된 데이터만을 사용한 일련의 실험에서 건강도메인은 ResNet15에서 89.5%, 일상생활도메인에서는 ResNet8에서 82%의 정확도를 보임으로써, 자동 수집 데이터의 활용 가능성을 검증하였다.","The biggest problem in the AI field, which has become a hot topic in recent years, is how to deal with the lack of training data. Since manual data construction takes a lot of time and efforts, it is non-trivial for an individual to easily build the necessary data. On the other hand, automatic data construction needs to handle data quality issue. In this paper, we introduce a method to automatically extract the data required to develop Korean speech command recognizer from the web and to automatically select the data that can be used for training data. In particular, we propose a modified ResNet model that shows modest performance for the automatically constructed Korean speech command data. We conducted an experiment to show the applicability of the command set of the health and daily life domain. In a series of experiments using only automatically constructed data, the accuracy of the health domain was 89.5% in ResNet15 and 82% in ResNet8 in the daily lives domain, respectively."
3D Res-Inception Network Transfer Learning for Multiple Label Crowd Behavior Recognition,2019,"['Densely crowed group', '3D Convolutional Neural Network (3D CNN)', '3D Res- Inception', 'Transfer Learning']",,"The problem towards crowd behavior recognition in a serious clustered scene is extremely challenged on account of variable scales with non-uniformity. This paper aims to propose a crowed behavior classification framework based on a transferring hybrid network blending 3D res-net with inception-v3. First, the 3D res-inception network is presented so as to learn the augmented visual feature of UCF 101. Then the target dataset is applied to fine-tune the network parameters in an attempt to classify the behavior of densely crowded scenes. Finally, a transferred entropy function is used to calculate the probability of multiple labels in accordance with these features. Experimental results show that the proposed method could greatly improve the accuracy of crowd behavior recognition and enhance the accuracy of multiple label classification."
2.5D human pose estimation for shadow puppet animation,2019,"['Human pose estimation', 'shadow puppet', 'mapping network', '2.5 pose data', 'CNN']",,"Digital shadow puppet has traditionally relied on expensive motion capture equipments and complex design. In this paper, a low-cost driven technique is presented, that captures human pose estimation data with simple camera from real scenarios, and use them to drive virtual Chinese shadow play in a 2.5D scene. We propose a special method for extracting human pose data for driving virtual Chinese shadow play, which is called 2.5D human pose estimation. Firstly, we use the 3D human pose estimation method to obtain the initial data. In the process of the following transformation, we treat the depth feature as an implicit feature, and map body joints to the range of constraints. We call the obtain pose data as 2.5D pose data. However, the 2.5D pose data can not better control the shadow puppet directly, due to the difference in motion pattern and composition structure between real pose and shadow puppet. To this end, the 2.5D pose data transformation is carried out in the implicit pose mapping space based on self-network and the final 2.5D pose expression data is produced for animating shadow puppets. Experimental results have demonstrated the effectiveness of our new method."
Recurrence Plot 알고리즘을 이용한 버스트 신호 검출 성능 분석,2019,"['Burst signal', 'Energy detection', 'Recurrence plot (RP) algorithm', 'CNN', 'Deep learning']",,
딥러닝 및 영상처리 기술을 활용한 콘크리트 균열 검출 방법,2019,"['콘크리트 균열', '균열 검출', '딥러닝', '영상처리', '합성곱신경망', 'Concrete Crack', 'Crack Detection', 'Deep Learning', 'Image Processing', 'CNN']","현행 균열조사 업무는 육안조사로 이루어지고 있어 점검자의 주관이 개입되어 점검 결과에 차이가 발생하거나, 측정오차가 발생할 여지가 있다. 이에 본 연구는 콘크리트 균열 조사의 객관성과 효율성을 높이기 위하여 딥러닝 네트워크 중 실시간 분석이 가능한 YOLO v.2를 활용하여 균열을 인지하고, 영상처리 기술을 활용하여 균열의 특성정보를 추출하는 프로세스를 제시하였다. 실험 결과, 실시간 분석이 가능한 검출속도와 정확도를 확보할 수 있었다. 본 연구의 결과는 시설물 하자진단 자동화 시스템 개발의 기초자료로 활용될수 있을 것이다.","Most of the current crack investigation work consists of visual inspection using simple measuring equipment such as crack scale. Thesemethods involve the subjection of the inspector, which may lead to differences in the inspection results prepared by the inspector, and maylead to a large number of measurement errors. So, this study proposes an image-based crack detection method to enhance objectivity andefficiency of concrete crack investigation. In this study, YOLOv2 was used to determine the presence of cracks in the image information toensure the speed and accuracy of detection for real-time analysis. In addition, we extracted shapes of cracks and calculated quantitatively,such as width and length using various image processing techniques. The results of this study will be used as a basis for the development ofimage-based facility defect diagnosis automation system."
신호등이 설치된 교차로 구역에서의 자율주행 시스템 구현,2019,"['Autonomous driving(자율주행)', 'Traffic light recognition(신호등인식)', 'A intersection driving(교차로 주행)', 'Coordinates map(좌표지도)', 'CNN(Convolutional Neural Network', '콘볼루션 신경망)']",,
딥러닝을 활용한 다발성 골절 분류,2019,"['딥러닝', '컨볼루션 신경망', '골절', '다중 레이블', 'Deep Learning', 'Convolutional Neural Network', 'Fracture', 'Multi-Label']","정형외과 의사는 컴퓨터 단층 촬영(CT)을 활용해 골절 환자의 골절 범주를 식별하고 치료 방법을 결정한다. 골절이 발생하게 되면 다발성 골절인 경우가 많고 골절 범주가 많기 때문에, 의사가 골절을 정확히 분류하기 위해서는 높은 전문성과 많은 노력이 필요하다. 이 논문에서는 골절 범주 식별을 다중 부류 분류 문제로 정의하고, 골절의 범주를 식별하기 위해 딥러닝을 사용하는 방법을 제안한다. 제안하는 딥러닝 모델은 GoogleNet과 유사한 형태로 골절의 특징을 추출하고, 다층퍼셉트론으로 각 골절 범주의 점수를 계산해 분류를 한다. 그리고 출력 노드의 점수가 특정 임계값 내에 있는 최대 4개의 골절 부류를 선택한다. 하반신 골절 CT 데이터에 대한 제안 방법의 정밀도는 73.3%, 재현율은 86.9%였다.","The orthopedists use computed tomography(CT) to identify fracture categories of fractured patients and determine their treatment. Fractures often result in multiple fractures which have various categories. Here it is required for orthopedists to have a high level of expertise and stressful examination. This paper casts the fracture category identifier task as a multi-label classification problem, and proposes a deep learning based method to it. The proposed deep learning model extracts the features of fractures with GoogleNet-like front-end and determines the fracture categories from the categorieswise score computed with back-end fully connected layer. The proposed method showed 73.3% precision and 86.9%recall for a CT dataset for lower body fracture in the experiments."
안개영상의 의미론적 분할 및 안개제거를 위한 심층 멀티태스크 네트워크,2019,"['Semantic Segmentation', 'Dehazing', 'Deep Learning', 'Multi-task Learning']",,"Image semantic segmentation and dehazing are key tasks in the computer vision. In recent years, researches in both tasks have achieved substantial improvements in performance with the development of Convolutional Neural Network (CNN). However, most of the previous works for semantic segmentation assume the images are captured in clear weather and show degraded performance under hazy images with low contrast and faded color. Meanwhile, dehazing aims to recover clear image given observed hazy image, which is an ill-posed problem and can be alleviated with additional information about the image. In this work, we propose a deep multi-task network for simultaneous semantic segmentation and dehazing. The proposed network takes single haze image as input and predicts dense semantic segmentation map and clear image. The visual information getting refined during the dehazing process can help the recognition task of semantic segmentation. On the other hand, semantic features obtained during the semantic segmentation process can provide cues for color priors for objects, which can help dehazing process. Experimental results demonstrate the effectiveness of the proposed multi-task approach, showing improved performance compared to the separate networks."
Image Denoising Methods based on DAECNN for Medication Prescriptions,2019,"['ROI', 'DAECNN', 'SSIM', 'PSNR', 'MSE', 'ROI', 'DAECNN', 'SSIM', 'PSNR', 'MSE']","본 연구는 환자의 알레르기 예방시스템을 구축하기 위해 스마트폰을 이용하여 저장된 처방전의 이미지잡음제거 를 위한 ROI 추출 방법에 중점을 두었다. 현재 ROI 추출은 제한된 실험 환경에서 좋은 성능을 보여 주었지만 실제 환경에서의 성능은 잡음으로 인해 좋지 않았다. 따라서 본 연구에서는 정확도 높은 ROI 추출을 위해 스마트폰 영상에 서 발생하는 잡음제거 방법을 제안한다. SMF, DIN, DAE, DAECNN(Denoising Autoencoder with Convolution Neural Network) and median filter with DAECNN(MF+DAECNN) 방법을 실험하였고 그 결과 DAECNN 및 MF + DAECNN 방법이 스마트폰에서 이미지의 잡음제거가 효과적임을 보여주었다. 성능 향상을 검증하기 위해 SSIM, PSNR 및 MSE 방법을 사용하였고 이 시스템은 OpenCV, C ++ 및 Python로 구현 및 실험되었고 실제 이미지에서 성능 테스트를 거쳐 자연잡음(natural noise)을 제거하는데 본 논문에서 제안한 DAECNN과 MF+DAECNN이 각 69%로 기존의 DAE 방법 55% 보다 상대적으로 높은 결과를 도출하였다.","We aimed to build a patient-based allergy prevention system using the smartphone and focused on the region of interest (ROI) extraction method for Optical Character Recognition (OCR) in the general environment. However, the current ROI extraction method has shown good performance in the experimental environment, but the performance in the real environment was not good due to the noisy background. Therefore, in this paper, we propose the compared methods of reducing noisy background to solve the ROI extraction problem. There five methods used as a SMF, DIN, Denoising Autoencoder(DAE), DAE with Convolution Neural Network(DAECNN) and median filter(MF) with DAECNN (MF+DAECNN). We have shown that our proposed DAECNN and MF+DAECNN methods are 69%, respectively, which is relatively higher than the conventional DAE method 55%. The verification of performance improvement uses MSE, PSNR and SSIM. The system has implemented OpenCV, C++and Python, including its performance, is tested on real images."
Ensemble convolutional neural networks for automatic fusion recognition of multi‐platform radar emitters,2019,"['deep learning', 'emitter recognition', 'ensemble learning', 'robustness', 'time‐frequency analysis']",,"Presently, the extraction of hand‐crafted features is still the dominant method in radar emitter recognition. To solve the complicated problems of selection and updation of empirical features, we present a novel automatic feature extraction structure based on deep learning. In particular, a convolutional neural network (CNN) is adopted to extract high‐level abstract representations from the time‐frequency images of emitter signals. Thus, the redundant process of designing discriminative features can be avoided. Furthermore, to address the performance degradation of a single platform, we propose the construction of an ensemble learning‐based architecture for multi‐platform fusion recognition. Experimental results indicate that the proposed algorithms are feasible and effective, and they outperform other typical feature extraction and fusion recognition methods in terms of accuracy. Moreover, the proposed structure could be extended to other prevalent ensemble learning alternatives."
A Novel Integrated Convolutional Neural Network via Deep Transfer Learning in Colorectal Images,2019,"['Colon Disease Classification', 'Convolutional Neural Networks', 'Transfer Learning']",,"In this paper, we explore the use of current deep learning methods, convolutional neural networks (CNNs) in the field of computer-aided diagnosis systems to classify several endoscopic colon diseases. Transfer learning by fine-tuning deep convolutional neural networks (CNNs) is applied due to the limited amount of data. For this, state-of-the-art CNN architectures, such as VGG16, VGG19, InceptionV3, ResNet50, Inception-ResNet-V2, DenseNet169 were used for training and validating the dataset. However, these existing architectures cannot extract more dense endoscopic image features and have problem on similar-looking images of different category. Therefore, we propose a novel integrated convolutional neural network to develop a more accurate and highly efficient method for endoscopic image classification, which uses the features of earlier layers in the classification process and increases the receptive field of view at the end layers in the network. We compare and evaluate our performance using performance metrics Accuracy (ACC), Recall, Precision and F1-score. In our experimental results, the proposed method outperforms the existing architectures, obtaining an accuracy of about 92.4% on the test dataset."
합성곱 신경망 기반의 PPG 신호 동잡음 구간 검출,2019,"['광맥파계', '생체신호', '동잡음', '인공 신경망', '합성곱 신경망', 'Photoplethysmographic', 'Bio-signal', 'Motion artifact', 'Artificial neural network', 'Convolutional neural network']",,"Among the various bio-signals, Photoplethysmographic (PPG) is widely used in areas such as u-health and human factor evaluation due to its low cost of measurement and freedom of user’s motion. Despite its advantages, PPG signal tends to be corrupted by the movement of user. In this study, we proposes the method for detecting the motion artifact in PPG signals using CNN (Convolutional Neural Network). Continuous PPG signals were divided into multiple pulse signals, converted to image, and then each pulse signal is used for training. We have used 3,000 normal signals and 3000 corrupted signals from PhysioNet database for training. With the proposed method, the signals corrupted by motion artifact were successfully detected with 92% accuracy."
딥러닝 기반 BIM(Building Information Modeling) 벽체 하위 유형 자동 분류 통한 정합성 검증에 관한 연구,2019,"['BIM', 'IFC', '하위 유형 분류', '건축 벽체', '딥러닝', 'BIM', 'IFC', 'Subtype Classification', 'Architectural Walls', 'Deep Learning']",,"With Building Information Modeling(BIM) becoming the de facto standard for data sharing in the AEC industry, additional needs have increased to ensure the data integrity of BIM models themselves. Although the Industry Foundation Classes provide an open and neutral data format, its generalized schema leaves it open to data loss and misclassifications This research applied deep learning to automatically classify BIM elements and thus check the integrity of BIM-to-IFC mappings. Multi-view CNN(MVCC) and PointNet, which are two deep learning models customized to learn and classify in 3 dimensional non-euclidean spaces, were used. The analysis was restricted to classifying subtypes of architectural walls. MVCNN resulted in the highest performance, with ACC and F1 score of 0.95 and 0.94.MVCNN unitizes images from multiple perspectives of an element, and was thus able to learn the nuanced differences of wall subtypes.PointNet, on the other hand, lost many of the detailed features as it uses a sample of the point clouds and perceived only the 'skeleton' of the given walls."
초중고 교육을 위한 딥러닝 기반 암석 분류기 개발,2019,"['딥 러닝', '텐서플로우', '이미지 인식', '암석 이미지', '교육', 'deep learning', 'tensorflow', 'image recognition', 'rock image', 'education']",,"These days, as Interest in Image recognition with deep learning is increasing, there has been a lot of research in image recognition using deep learning. In this study, we propose a system for classifying rocks through rock images of 18 types of rock(6 types of igneous, 6 types of metamorphic, 6 types of sedimentary rock) which are addressed in the high school curriculum, using CNN model based on Tensorflow, deep learning open source framework. As a result, we developed a classifier to distinguish rocks by learning the images of rocks and confirmed the classification performance of rock classifier. Finally, through the mobile application implemented, students can use the application as a learning tool in classroom or on-site experience."
실내 복도환경에서의 컨벌루션 신경망을 이용한 드론의 자율주행 연구,2019,[],,"Autonomous driving of drone indoor must move along a narrow path and overcome other factors such as lighting, topographic characteristics, obstacles. In addition, it is difficult to operate the drone in the hallway because of insufficient texture and the lack of its diversity comparing with the complicated environment. In this paper, we study an autonomous drone navigation using Convolution Neural Network(CNN) in indoor environment. The proposed method receives an image from the front camera of the drone and then steers the drone by predicting the next path based on the image. As a result of a total of 38 autonomous drone navigation tests, it was confirmed that a drone was successfully navigating in the indoor environment by the proposed method without hitting the walls or doors in the hallway."
A wavelet packet spectral subtraction and convolutional neural network based method for diagnosis of system health,2019,"['Diagnosis', 'Convolutional neural network', 'Wavelet packet decomposition', 'Vibration signal', 'Spectral subtraction', 'Prognosis health management']",,"Health monitoring systems play a key role inside smart factories. To enhance the real-time capability and reliability of health monitoring systems, we propose a fully automatic method for machine diagnosis. Firstly, acquired vibration signals are converted into high-resolution images by wavelet packet spectral subtraction. Next, a trained convolutional neural network (CNN) automatically extracts important features and determines the current health of the machine. The performance of the proposed method is demonstrated by employing a diagnosis problem of a bearing system. The result shows an outstanding classification accuracy of 99.64 % even with a small amount of training data (5 % of the data)."
GAN-based shadow removal using context information,2019,"['Shadow Removal', 'Generative Adversarial Network', 'Deep-Learning']",,"When dealing with outdoor images in a variety of computer vision applications, the presence of shadow degrades performance. In order to understand the information occluded by shadow, it is essential to remove the shadow. To solve this problem, in many studies, involves a two-step process of shadow detection and removal. However, the field of shadow detection based on CNN has greatly improved, but the field of shadow removal has been difficult because it needs to be restored after removing the shadow. In this paper, it is assumed that shadow is detected, and shadow-less image is generated by using original image and shadow mask. In previous methods, based on CGAN, the image created by the generator was learned from only the aspect of the image patch in the adversarial learning through the discriminator. In the contrast, we propose a novel method using a discriminator that judges both the whole image and the local patch at the same time. We not only use the residual generator to produce high quality images, but we also use joint loss, which combines reconstruction loss and GAN loss for training stability. To evaluate our approach, we used an ISTD datasets consisting of a single image. The images generated by our approach show sharp and restored detailed information compared to previous methods."
딥러닝 기반 실시간 손 제스처 인식,2019,"['Leap Motion', 'Deep Learning', 'VR', 'Gesture Recognition']",,"In this paper, we propose a real-time hand gesture recognition algorithm to eliminate the inconvenience of using hand controllers in VR applications. The user's 3D hand coordinate information is detected by leap motion sensor and then the coordinates are generated into two dimensional image. We classify hand gestures in real-time by learning the imaged 3D hand coordinate information through SSD(Single Shot multibox Detector) model which is one of CNN(Convolutional Neural Networks) models. We propose to use all 3 channels rather than only one channel. A sliding window technique is also proposed to recognize the gesture in real time when the user actually makes a gesture. An experiment was conducted to measure the recognition rate and learning performance of the proposed model. Our proposed model showed 99.88% recognition accuracy and showed higher usability than the existing algorithm."
고밀도 비디오 캡션 생성을 위한 의미 특징 학습,2019,"['고밀도 비디오 캡션 생성', '의미 특징 학습', '주의 집중', 'dense video captioning', 'semantic feature learning', 'attention']","본 논문에서는 고밀도 비디오 캡션 생성을 위한 새로운 심층 신경망 모델을 제안한다. 고밀도 비디오 캡션 생성은 하나의 입력 비디오로부터 다수의 이벤트 구간들을 찾아내고, 이들 각각에 관한 자연어 설명 문장을 생성하는 작업이다. 기존의 모델들에서는 합성곱 신경망을 통해 입력 비디오의 시각 특징 만을 추출하여 사용한 것과는 달리, 본 논문에서 제안하는 모델에서는 행위, 물체, 배경, 사람 등 중요한 이벤트 구성 요소들을 효과적으로 표현할 수 있는 고수준의 의미 특징들을 추가적으로 활용하였다. 또한 제안 모델에서는 순환 신경망인 LSTM을 이용하여 비디오 안에 포함된 이벤트 시간 영역들을 탐지하였다. 또, 제안 모델에서는 중요도에 따라 선택적으로 입력 특징들에 집중할 수 있도록, 캡션 생성 과정에 주의집중 메커니즘을 적용하였다. 고밀도 비디오 캡션 생성을 위한 대용량 벤치마크 데이터 집합인 ActivityNet Captions 데이터 집합을 이용한 다양한 실험을 통해, 본 논문에서 제안한 모델의 높은 성능과 우수성을 확인할 수 있었다.","In this paper, we propose a new deep neural network model for dense video captioning.Dense video captioning is an emerging task that aims at both localizing and describing all events in a video. Unlike many existing models, which use only visual features extracted from the given video through a sort of convolutional neural network(CNN), our proposed model makes additional use of high-level semantic features that describe important event components such as actions, people, objects, and backgrounds. The proposed model localizes temporal regions of events by using LSTM, a recurrent neural network(RNN). Furthermore, our model adopts an attention mechanism for caption generation to selectively focus on input features depending on their importance. By conducting experiments using a large-scale benchmark dataset for dense video captioning, AcitivityNet Captions, we demonstrate high performance and superiority of our model."
Real Time Object Detection Based on YOLO with Feature Filter Bank,2019,"['convolutional neural network', 'real-time object detection', 'YOLO', 'feature filter bank']",,"Real-time object detection is one of the most important and challenging tasks in current object detection and classification fields. Lots of research work have contributed to improving the ability of detection and classification accuracy in the last decades. Also, recent research on computer vision is prevailing to improve the accuracy of video surveillance, robotic vision, self-driving cars, and many applications. YOLO (You Only Look Once) is one of the fastest CNN (Convolutional Neural Network) and, it is one of state of the art techniques fo performing real-time object detection tasks. However, there are still some localization problems. In this paper, we propose a network with feature filter bank to improve the performance of YOLO network. Experiments have shown that the object detection performance of the proposed network is improved."
합성곱신경망 기반의 StyleGAN 이미지 탐지모델,2019,"['Deep Learning', 'Generative Adversarial Network', 'Convolutional Neural Network', 'Fake Image Detection', 'Face Detection']",,"As artificial intelligence technology is actively used in image processing, it is possible to generate high-quality fake images based on deep learning. Fake images generated using GAN(Generative Adversarial Network), one of unsupervised learning algorithms, have reached levels that are hard to discriminate from the naked eye. Detecting these fake images is required as they can be abused for crimes such as illegal content production, identity fraud  and defamation. In this paper, we develop a deep-learning model based on CNN(Convolutional Neural Network) for the detection of StyleGAN fake images. StyleGAN is one of GAN algorithms and has an excellent performance in generating face images. We experiment with 48 number of experimental scenarios developed by combining parameters of the proposed model. We train and test each scenario with 300,000 number of real and fake face images in order to present a model parameter that improves performance in the detection of fake faces."
An overview of deep learning in the field of dentistry,2019,"['Artificial Intelligence', 'Deep Learning', 'Dentistry', 'Radiology']",,"Purpose: Artificial intelligence (AI), represented by deep learning, can be used for real-life problems and is applied across all sectors of society including medical and dental field. The purpose of this study is to review articles about deep learning that were applied to the field of oral and maxillofacial radiology. Materials and Methods: A systematic review was performed using Pubmed, Scopus, and IEEE explore databases to identify articles using deep learning in English literature. The variables from 25 articles included network architecture, number of training data, evaluation result, pros and cons, study object and imaging modality. Results: Convolutional Neural network (CNN) was used as a main network component. The number of published paper and training datasets tended to increase, dealing with various field of dentistry. Conclusion: Dental public datasets need to be constructed and data standardization is necessary for clinical application of deep learning in dental field."
An overview of deep learning in the field of dentistry,2019,"['Artificial Intelligence', 'Deep Learning', 'Dentistry', 'Radiology']",,"Purpose: Artificial intelligence (AI), represented by deep learning, can be used for real-life problems and is applied across all sectors of society including medical and dental field. The purpose of this study is to review articles about deep learning that were applied to the field of oral and maxillofacial radiology.Materials and Methods: A systematic review was performed using Pubmed, Scopus, and IEEE explore databases to identify articles using deep learning in English literature. The variables from 25 articles included network architecture, number of training data, evaluation result, pros and cons, study object and imaging modality.Results: Convolutional Neural network (CNN) was used as a main network component. The number of published paper and training datasets tended to increase, dealing with various field of dentistry.Conclusion: Dental public datasets need to be constructed and data standardization is necessary for clinical application of deep learning in dental field."
ADD-Net : Attention Based 3D Dense Network for Action Recognition,2019,"['Deep Learning', 'Action Recognition', 'Convolution Neural Network', 'Attention Mechanism']",,"Recent years with the development of artificial intelligence and the success of the deep model, they have been deployed in all fields of computer vision. Action recognition, as an important branch of human perception and computer vision system research, has attracted more and more attention. Action recognition is a challenging task due to the special complexity of human movement, the same movement may exist between multiple individuals. The human action exists as a continuous image frame in the video, so action recognition requires more computational power than processing static images. And the simple use of the CNN network cannot achieve the desired results. Recently, the attention model has achieved good results in computer vision and natural language processing. In particular, for video action classification, after adding the attention model, it is more effective to focus on motion features and improve performance. It intuitively explains which part the model attends to when making a particular decision, which is very helpful in real applications. In this paper, we proposed a 3D dense convolutional network based on attention mechanism(ADD-Net), recognition of human motion behavior in the video."
재실자 착의량 산출을 위한 선행 연구 및 기술 분석,2019,"['Indoor Environment', 'Thermal Quality', 'Predictive Mean Vote', 'Clothing Insulation', '실내환경', '온열환경', '예상평균온열감', '착의량']",,"Purpose: The aim of this study is to verify the feasibility and applicability of a neural network-based model for estimating clothing insulation of building occupants. This is a preliminary study before developing an estimation model for the clothing insulation. Method: The existing researches on the method of estimating the clothing insulation were investigated and the neural network techniques that can be applied to the model were analyzed.Clothing image datasets were collected and convolutional neural networks (CNNs) that is effective for training images were investigated. Various advanced CNN structures were analyzed to confirm their applicability in developing models. Lastly, an application process for the neural network-based model for estimating clothing insulation and the real-time PMV control was proposed as a flowchart. Result: As a result, the possibility of the neural network-based model for estimating occupants clothing insulation was confirmed, and the basis for providing a comfort indoor thermal environment was established."
딥 러닝 기반의 이미지학습을 통한 저항 용접품질 검증,2019,"['Resistance welding(저항 용접)', 'Quality verification(품질 검증)', 'Deep learning(딥 러닝)', 'Tensorflow(텐서플로우)']",,"Welding is one of the most popular joining methods and most welding quality estimation methods are executed using joined material. This paper propose welding quality estimation methods using dynamic current, voltage and resistance which are obtained during welding in real time. There are many kinds of welding method. Among them, we focused on the projection welding and gathered dynamic characteristics from two different types of projection welding. For image learning, graphs are drawn using obtained current, voltage and resistance, and the graphs are converted to images. The images are labeled with two sub-categories - normal and defect. For deep learning of images obtained from welding, Convolutional Neural Network (CNN) is applied, and Tensorflow was used as a framework for deep learning. With two resistance welding test datasets, we conclude that the Convolutional Neural Network helps in predicting the welding quality."
딥러닝기반 다중 표적 인식을 활용한 모바일 로봇 경로 계획,2019,"['표적인식', '경로계획', '장애물 회피', '딥러닝', '모바일 로봇', 'Taget Detection', 'Path Planning', 'Avoidance Obstacle', 'Deep-Learning', 'Mobile Robot']","복합적인 고차원의 임무를 수행하기 위하여 미래무인화 전투 체게는 인공지능 기술을 필요로 한다. 특히 합성곱 신경망은 영상뿐만 아니라 자연어 처리까지 광범위한 범위에서 탁월한 성능을 보이고 있어 무인화 전투체계의 표적정보인식, 피아식별, 전장정보인식 등 각종 센서 융합에 매우 적합하다. 본 연구에서는 합성곱 신경망의 영상인식 기술을 활용하여 다수 대상체의 상태정보를 인식함으로써 변화되는 환경에서의 무인로봇 경로 계획 개선 방안을 제시하였고 시뮬레이션을 통하여 추정된 로봇의 위치, 장애물, 목표물 정보로부터 로봇의 경로 계획의 유효성을 검증 하였다.","Unmmanned systems are one of the essential areas of future military weapons systems that must carry out dangerous and cmplex missions. Especially, deep learning should recognize many landmarks through the image and project them onto the map to improve the problem of position estimation, because it shows excellent performance of recognizing and classifying the characteristics of image data among other artificial intelligence techniques. In this study, the path planning of the unmanned reconnaissance aircraft and the unmanned ground vehicle, which are currently being used in the ROK military, is linked with the CNN based multi target recognition algorithm without GPS. Throuth experiments, we verified the effectiveness of the path planning of the mobile robot with respect to the position of the robot, obstacle, and target point estimated by the target detection algorithm."
수도 레이블을 활용한 준지도 학습 기반의 도로노면 파손 탐지,2019,"['Road surface damage', 'Semantic segmentation', 'Convolutional neural network', 'Semi-supervised learning', '도로노면 파손', '의미론적 분할', '합성곱 신경망', '준지도 학습']","의미론적 분할 형태로 합성곱 신경망을 구성하여 도로노면의 파손을 탐지하는 연구가 진행되고 있다. 이러한 합성곱 신경망 형태의 모델을 생성하기 위해서는 입력 이미지와 이에 상응한 레이블된 이미지 데이터셋으로 수집해야 하고, 이러한 과정에서는 굉장히 많은 시간과 비용이 발생하게 된다. 본 논문에서는 이러한 작업을 완화하기 위하여 수도 레이블링을 활용한준지도 학습 기반의 도로노면 파손 탐지 기술을 제안하고자 한다. 레이블된 데이터셋과 레이블되지 않은 데이터셋을 적절하게 혼합하여 도로노면 파손을 탐지하는 모델을 업데이트하고, 이를 레이블된 데이터셋만을 활용한 기존 모델과 성능을 비교한다. 주관적인 성능결과, 민감도부분에서는 조금 저하된 성능을 보였지만, 정밀도 부분에서는 대폭 성능 향상이 있었으며, 최종적으로 F1-score 또한 높은 수치로 평가되었다.","By using convolutional neural networks (CNNs) based on semantic segmentation, road surface damage detection has being studied. In order to generate the CNN model, it is essential to collect the input and the corresponding labeled images. Unfortunately, such collecting pairs of the dataset requires a great deal of time and costs. In this paper, we proposed a road surface damage detection technique based on semi-supervised learning using pseudo labels to mitigate such problem. The model is updated by properly mixing labeled and unlabeled datasets, and compares the performance against existing model using only labeled dataset. As a subjective result, it was confirmed that the recall was slightly degraded, but the precision was considerably improved. In addition, the F1-score was also evaluated as a high value."
Super-Resolution Model for High-Precision In Vivo Proton Range Verification Using a Stereo Gamma Camera: A Feasibility Study,2019,"['Monte-Carlo simulation', 'Proton range verification', 'Super-resolution', 'Deep-learning', 'Gamma cameras']",,"The feasibility of a deep-learning-based super-resolution (SR) model to improve the fiducial marker-tracking accuracy of a stereo portable gamma camera (SPGC) system over the range of an in vivo proton beam was verified in a Monte-Carlo (MC) simulation using the Geometry and Tracking 4 (Geant4) package. The SPGC system is capable of measuring the three-dimensional (3D) position of excited gold markers by detecting proton-induced X-ray emissions (PIXEs) generated by the interactions between the gold marker and a proton beam. The SPGC system was modeled using Geant4 according to manufacturer’s specifications. The original image (Io) acquired by using the SPGC system, which was comprised of 32 × 32 arrays over an area of 104 × 104 mm2, was subjected to resolution enhancement to produce an SR-enhanced image (ISR) (128 × 128 arrays) through a fully trained SR model based on a convolutional neural network (CNN). In virtual experiments, two portable gamma cameras were positioned perpendicular to each other. Next, a pair of Io’s were acquired by detecting the radiations from the exited gold marker positioned in a water phantom. Then, the fully trained SR model improved the quality of the Io’s by converting those to ISR’s. The 3D position of the radiation source was calculated by using Anger logic and 3D vector calculations. Virtual experiments for in vivo proton range verification using the SPGC system were performed by irradiating to a gold marker in a water phantom with a proton beam. A gold marker was placed at five different positions along the Bragg curve of a 100.0-MeV proton beam, which had a range of 74.5 mm in water. The proton beam was irradiated to deliver 20.0 Gy to the gold marker when it was positioned at the center of the Bragg peak; then, the PIXEs were measured by using the SPGC system. When a gold marker was at a different position, it was irradiated with the same dose for a quantitative comparison. Then 3D position of the gold marker was calculated for the original image (Io) and for the high-resolution image (ISR) to compare the detection accuracy. The averaged root-mean-square errors of the five positions between the reference and calculation for Io and ISR were 9.127 mm and 3.991 mm, respectively. In conclusion, the feasibility of using a deep-learning SR model for improving the image resolution of Io and therefore, the tracking accuracy of the SPGC system was validated in MC simulations. The SR model can be applicable to diverse areas of research using gamma camera."
딥러닝 기반의 대퇴골 영역 분할을 위한 훈련 데이터 증강 연구,2019,"['데이터 증강', '딥러닝', '의료영상', '영역 분할', 'Data augmentation', 'Deep learning', 'Medical image', 'Image segmentation']","본 연구에서는 CT 영상의 대퇴골 부위를 해부학적으로 의미 있게 변형하여 CT 영상의 대퇴골 영역을 분할하기 위한 컨벌루션 신경망(CNN)의 훈련 데이터를 증강하는 방법을 제안한다. 먼저 CT 영상으로부터 삼차원 삼각형 대퇴골 메쉬를 얻는다. 그 후 메쉬의 국소부위에 대한 기하학적 특성을 계산하고, 군집화하여 메쉬를 의미 있는 부분들로 분할한다. 마지막으로, 분할한 부분들을 적절한 알고리즘으로 변형한 뒤, 이를 바탕으로 CT 영상을 와핑하여 새로운 CT영상을 생성하였다. 본 연구의 데이터 증강 방법을 이용하여 학습시킨 딥러닝 모델은 기하학적 변환이나 색상 변환 같이 일반적으로 사용되는 데이터 증강법과 비교하여 더 나은 영상분할 성능을 보인다.","In this study, we modified CT images of femoral head in consideration of anatomically meaningful structure, proposing the method to augment the training data of convolution Neural network for segmentation of femur mesh model. First, the femur mesh model is obtained from the CT image. Then divide the mesh model into meaningful parts by using cluster analysis on geometric characteristic of mesh surface. Finally, transform the segments by using an appropriate mesh deformation algorithm, then create new CT images by warping CT images accordingly. Deep learning models using the data enhancement methods of this study show better image division performance compared to data augmentation methods which have been commonly used, such as geometric conversion or color conversion."
수중 소나 영상 학습 데이터의 왜곡 및 회전 Augmentation을 통한 딥러닝 기반의 마커 검출 성능에 관한 연구,2019,"['Deep Learning', 'Data Augmentation', 'Object Detection', 'Underwater Sonar Image']",,"In the ground environment, mobile robot research uses sensors such as GPS and optical cameras to localize surrounding landmarks and to estimate the position of the robot. However, an underwater environment restricts the use of sensors such as optical cameras and GPS. Also, unlike the ground environment, it is difficult to make a continuous observation of landmarks for location estimation. So, in underwater research, artificial markers are installed to generate a strong and lasting landmark. When artificial markers are acquired with an underwater sonar sensor, different types of noise are caused in the underwater sonar image. This noise is one of the factors that reduces object detection performance. This paper aims to improve object detection performance through distortion and rotation augmentation of training data. Object detection is detected using a Faster R-CNN."
딥러닝기반 다중 표적 인식을 활용한 모바일 로봇 경로 계획,2019,"['표적인식', '경로계획', '장애물 회피', '딥러닝', '모바일 로봇', 'Taget Detection', 'Path Planning', 'Avoidance Obstacle', 'Deep-Learning', 'Mobile Robot']","복합적인 고차원의 임무를 수행하기 위하여 미래무인화 전투 체게는 인공지능 기술을 필요로 한다. 특히 합성곱 신경망은 영상뿐만 아니라 자연어 처리까지 광범위한 범위에서 탁월한 성능을 보이고 있어 무인화 전투체계의 표적정보인식, 피아식별, 전장정보인식 등 각종 센서 융합에 매우 적합하다. 본 연구에서는 합성곱 신경망의 영상인식 기술을 활용하여 다수 대상체의 상태정보를 인식함으로써 변화되는 환경에서의 무인로봇 경로 계획 개선 방안을 제시하였고 시뮬레이션을 통하여 추정된 로봇의 위치, 장애물, 목표물 정보로부터 로봇의 경로 계획의 유효성을 검증 하였다.","Unmmanned systems are one of the essential areas of future military weapons systems that must carry out dangerous and cmplex missions. Especially, deep learning should recognize many landmarks through the image and project them onto the map to improve the problem of position estimation, because it shows excellent performance of recognizing and classifying the characteristics of image data among other artificial intelligence techniques. In this study, the path planning of the unmanned reconnaissance aircraft and the unmanned ground vehicle, which are currently being used in the ROK military, is linked with the CNN based multi target recognition algorithm without GPS. Throuth experiments, we verified the effectiveness of the path planning of the mobile robot with respect to the position of the robot, obstacle, and target point estimated by the target detection algorithm."
Deep Learning–based Number Detection and Recognition for Gas Meter Reading,2019,"['Gas meter?reading system', 'Computer vision', 'Image processing', 'Convolutional neural network']",,"The meter reading.system field has been researched from conventional methods centered on image processing technology to techniques based on learning methods such as machine learning or deep learning. The biggest problem for meter reading systems based on computer vision is difficulty in recognizing the various kinds of meters. In fact, there are more than five major manufacturers for the meters installed in Korea. There are different meter reading areas, ID regions, and number formats by version. Because of these problems, most of the meter reading is still done hands-on. In this paper, we present an automatic meter.reading system that can work simply and efficiently, compared to existing meter reading systems that need a skilled worker. Our meter reading system consists of three parts: i) detection of meter-reading and ID regions using You Only Look Once (YOLO), ii) digit segmentation for recognition, and iii) convolutional neural network (CNN)-based digit recognition. It is possible to robustly detect and recognize various meter types by using the method presented here. Therefore, it can provide an environment where gas meter checkers can work efficiently without inconvenient procedures."
No-Reference Image Quality Assessment Using Independent Component Analysis and Convolutional Neural Network,2019,['Convolutional neural network Independent component analysis No-reference image quality assessment Patch selection'],,"As digital images have become a significantly primary medium in a broad area, there is a growing interest in the development of automatic objective image quality assessment (IQA) methods. In this paper, a novel no-reference IQA (NRIQA) algorithm is proposed based on independent component analysis and convolutional neural network. The proposed NRIQA algorithm consists of the following three steps: selection of some representative patches, extraction of the features of the selected image patches, and prediction of the image quality by exploiting the features. Initially, an image is divided into non-overlapping patches and then some patches are selected with the suitable property for assessing the overall image quality. In this paper, we refer to the selected patches as image quality patches. The largest infinity norm of the gradient of each image quality patch is employed as a basis when the image quality patches being selected. Second, we employ independent component analysis (ICA) to extract the features of image quality patches. At the last moment, a convolutional neural network (CNN) is applied to the independent component coefficients of image quality patches to predict the corresponding differential mean opinion score (DMOS). We compared the performance of the proposed NQIRM with other IQMs in terms of PCC, SROCC, and RMSE on the database LIVE2, CSIQ and TID2008/2013. The PCC, SROCC and RMSE values achieve respectively to 0.996, 0.999 and 6.011 on the database TID2013. The performance comparison results show the proposed NRIQM is superior to commonly used IQMs."
Automatic spine segmentation from CT images using Convolutional Neural Network via redundant generation of class labels,2019,['Automatic image segmentation Computed tomography images Convolutional neural network Spine segmentation'],,"There has been a signiﬁcant increase from 2010 to 2016 in the number of people suffering from spine problems. The automatic image segmentation of the spine obtained from a computed tomography (CT) image is important for diagnosing spine conditions and for performing surgery with computer-assisted surgery systems. The spine has a complex anatomy that consists of 33 vertebrae, 23 intervertebral disks, the spinal cord, and connecting ribs. As a result, the spinal surgeon is faced with the challenge of needing a robust algorithm to segment and create a model of the spine. In this study, we developed a fully auto-matic segmentation method to segment the spine from CT images, and we compared our segmentation results with reference segmentations obtained by well-known methods. We use a hybrid method. This method combines the convolutional neural network (CNN) and fully convolutional network (FCN), and utilizes class redundancy as a soft constraint to greatly improve the segmentation results. The proposed method was found to signiﬁcantly enhance the accuracy of the segmentation results and the system pro-cessing time. Our comparison was based on 12 measurements: the Dice coefﬁcient (94%), Jaccard index (93%), volumetric similarity (96%), sensitivity (97%), speciﬁcity (99%), precision (over segmentation 8.3 and under segmentation 2.6), accuracy (99%), Matthews correlation coefﬁcient (0.93), mean surface dis-tance (0.16 mm), Hausdorff distance (7.4 mm), and global consistency error (0.02). We experimented with CT images from 32 patients, and the experimental results demonstrated the efﬁciency of the pro-posed method."
해외 정보분석기법의 활용 및 효용성에 관한 연구,2019,"['intelligence analysis', 'uncertainty of international order', 'intelligence capacity', 'structured analysis', 'decision making', 'cognitive bias. blind spot', '구조화 분석', 'SWOT 분석', '분석의 오류', '인지적 오류', '인지적 편향성', '대북군사행동']","미중 패권경쟁의 심화와 남북관계 급변, 북미 관계개선의 교착, 한일갈등의 심화 등 동북아 안보지형이 어느 때 보다 불확실하고 불안정하다. 이렇게 불확실한 안보 상황에서 뛰어난 정보역량으로 국가적 위기를 대비하고 극복해나가는 것은 매우 중요하다. 본 연구는 미국 CIA, DIA 등을 비롯한 구미 정보기관들이 국내외 위기상황에 효과적으로 대처하기 위해 다양한 정보분석기법을 개발하고 있는 시점에서 우리의 분석역량 제고에 기여할 수 있는 정보분석기법들을 살펴보았다. 특히, 우리보다 많은 경험과 정보 노하우를 축적한 구미 정보기관들의 선진분석기법들을 살펴보고 이들을 가상상황인 미국의 대북군사행동에 적용해서 분석기법의 효용성을 살펴보았다. 구조화 브레인스토밍을 시작으로 레드햇 분석과 사분면분할분석, PEST 분석과 SWOT 분석기법들을 가상사례에 적용하였을 때 그 분석과정에서의 효용가치를 살펴보았다. 구조화분석기법은 정보실패를 초래하는 정보분석관들의 인지적 편향성을 극복하는데 기여할 수 있는 것으로 알려졌다. 즉 구조화 분석기법(structured analytic techniques)은 분석관이 입수한 불완전하고 모호하며 때로는 기만적인 첩보들을 단계적으로 처리할 수 있는 절차적 분석방법으로서 내적 사고의 절차를 시스템적이고 투명한 방법으로 드러나게 함으로써 다른 사람들과 분석과정을 공유하고, 공동작업을 통해 서로 비판적으로 검토 할 수 있게 해준다. 물론 이런 방식만이 항상 올바른 결론을 얻을 수 있는 공식과 같은 것으로 존재할 수는 없지만 분석기법을 구조적으로 조직화하는 것은 분석과정에서 오류의 정도와 빈도를 줄이는데 기여할 수 있다. 그러나, 가상사례인 미국의 대북군사행동을 분석하는데 이 분석기법들을 적용한 결과 그 자체로 여러 가지 도움을 주는 것은 사실이지만 그렇다고 해서 엄청나게 획기적인 성과를 기대해서는 안될 것 같다. 구조화분석기법은 하나의 테크닉이지 본질이나 실질(Substance)은 아니다. 특정주제에 대해 고도의 전문성이 없이는 심층적인 분석에 한계가 있다. 새로운 아이디어의 발굴 또는 예기치 않은 변수의 분석에 기여하는 바가 있지만 전문분석관이 쌓은 오랜 경험과 경륜에서 오는 직관적인 통찰력 역시 무시할 수 없다. 구조화 분석기법이 미래예측을 하는 수정구슬이라기 보다는 수정구슬을 잘 들여다 볼 수 있게 도움을 주는 유용한 보조도구라고 생각하고 사용할 필요가 있다.","As such uncertain situations in East Asia are rapidly unfolded, it has become significant to improve intelligence analysis and inform decision makers about the incoming crises. When multiple U.S. intelligence bodies like CIA put lots of efforts to develop good analytic techniques in order to cope with future crisis, we also need to develop new alternative analyses, which can make a great contribution to enhance our analytical skills. This study makes an attempt to investigate the utility of some analytic techniques like structured analyses developed by retired CIA intelligence analysts. This study explores into the utilization of structured analytical techniques by applying them to a simulated case of American invasion to North Korea, which almost became to be a plausible scenario by CNN two years ago. As a result of applying to a simulated case such various analytic techniques like Structured Brainstorming, Red Hat analysis, Quadrant Crunching, this study came up with a conclusion that we should be working harder to strengthen our analytic capacity. However, it is also important to guard against too much expectations to these alternative analyses since they seem to be more techniques rather than substance. These analytical methods help intelligence analysts identify the blind spot of their analyses and enlighten them on the problems of their cognitive biases. However, as they are no more panacea, we need to use these methods more as an auxiliary instrument than as a crystall ball of fortunetelling."
자율운항선박의 국제해상충돌예방규칙 준수를 위한 합성곱 신경망 기반의 선박 분류에 관한 연구,2019,"['자율운항선박', '선박 분류', '국제해상충돌예방규칙', '합성곱 신경망', 'Autonomous Ships', 'Vessel Classification', 'COLREGs', 'Convolutional Neural Networks']","최근 자율운항선박에 대한 관심이 증가하고 있으며, 바다를 항해하는 자율운항선박은 유인선과 같이 국제해상충돌방지규칙을 준수해야한다. 따라서 본 논문에서는 자율운항선박이 국제해상충돌예방규칙을 준수하기 위해서 필요한 선박 범주 및 합성곱 신경망 기반의 선박 분류 기술을 제안하였다. 먼저 국제해상충돌예방규칙을 분석하여 자율운항선박이 구별해야 되는 14개의 선박 범주를 정의하였다. 또한 본 논문에서 정의된 선박 범주에 맞도록 인터넷 영상검색 및 기존 데이터 셋 정제를 통하여 40,300장 규모의 선박 범주 분류 데이터 셋을 구축하였다. 마지막으로 최신 합성곱 신경망 모델을 구축된 선박 범주 분류 데이터 셋에 적용하여 선박 범주 분류 성능을 분석하였다. 실험결과 전이학습을 통하여 학습된 Inception-ResNet v2 모델은 14개 선박 범주를 91%의 높은 정확도로 분류함을 확인하였다.","The interest in autonomous ships for marine industries has increased significantly over the past few years and autonomous ships also must follow maritime laws in the same way as regular ships operated by crews. Therefore, in this paper, we propose the vessel taxonomy for COLREGs compliance of autonomous ships and evaluate the performance of the vessel classification method using CNNs. First, we define the vessel taxonomy for complying with maritime laws by analyzing the COLREGs. And then, we build our dataset separated manually by the vessel taxonomy. For the dataset, 40,300 images are collected by image search on websites and refining the publicly available dataset. Finally, the state-of-the-art CNN model is applied to evaluate the recognition rate of our dataset. The experimental results show that the Inception-ResNet v2 model which is trained by transfer learning effectively classifies the ships with a high accuracy of 91%."
네트워크 공격 탐지 성능향상을 위한 딥러닝을 이용한 트래픽 데이터 생성 연구,2019,"['Network security', 'Intrusion detection', 'Network traffic data', 'Deep learning', 'GAN', '네트워크 보안', '침입탐지', '네트워크 트래픽 데이터', '딥러닝', 'GAN']","네트워크 공격을 탐지하기 위하여 기계학습을 이용한 다양한 연구가 최근 급격히 증가하고 있다. 이러한 기계학습 방법은 많은 데이터에 의존적이며 연구를 위해 다양한 실험 데이터가 공개되어 사용되고 있다. 하지만 실험 데이터 및 실제 환경에서 수집되는 데이터는 class간의 수량이 불균형하다는 문제점을 가지고 있다. 본 연구에서는 기계 학습을 이용한 침입탐지시스템의 한계점 중 학습데이터의 class간 불균형으로 인한 분류 성능 저하를 해결하기 위한 방법을 제안한다. 이를 위해 네트워크 트래픽 데이터를 처리하고 seqGAN를 이용하여 부족한 데이터를 생성하였다. 제안된 방법은 NSL-KDD, UNSW-NB15 데이터 셋을 대상으로 Text-CNN을 이용하여 분류하는 테스트를 실행한 결과 정밀도가 향상되는 것을 확인할 수 있었다.","Recently, various approaches to detect network attacks using machine learning have been studied and are being applied to detect new attacks and to increase precision. However, the machine learning method is dependent on feature extraction and takes a long time and complexity. It also has limitation of performace due to learning data imbalance. In this study, we propose a method to solve the degradation of classification performance due to imbalance of learning data among the limit points of detection system. To do this, we generate data using Generative Adversarial Networks (GANs) and propose a classification method using Convolutional Neural Networks (CNNs). Through this approach, we can confirm that the accuracy is improved when applied to the NSL-KDD and UNSW-NB15 datasets."
객체 인식에서의 속도 향상을 위한 모델 앙상블,2019,"['Object detection', 'Ensemble method', 'Convolutional neural network']",,
향상된 음향 신호 기반의 음향 이벤트 분류,2019,"['Noise Robustness', 'Sound Signal Generation', 'End-to-End Architecture', 'Deep Learning', '잡음 견고성', '음향 신호 생성', 'End-to-End 구조', '딥러닝']",,"The explosion of data due to the improvement of sensor technology and computing performance has become the basis for analyzing the situation in the industrial fields, and various attempts to detect events based on such data are increasing recently. In particular, sound signals collected from sensors are used as important information to classify events in various application fields as an advantage of efficiently collecting field information at a relatively low cost. However, the performance of sound-event classification in the field cannot be guaranteed if noise can not be removed. That is, in order to implement a system that can be practically applied, robust performance should be guaranteed even in various noise conditions. In this study, we propose a system that can classify the sound event after generating the enhanced sound signal based on the deep learning algorithm. Especially, to remove noise from the sound signal itself, the enhanced sound data against the noise is generated using SEGAN applied to the GAN with a VAE technique. Then, an end-to-end based sound-event classification system is designed to classify the sound events using the enhanced sound signal as input data of CNN structure without a data conversion process. The performance of the proposed method was verified experimentally using sound data obtained from the industrial field, and the f1 score of 99.29% (railway industry) and 97.80% (livestock industry) was confirmed."
정형 데이터와 비정형 데이터를 동시에 고려하는 기계학습 기반의 직업훈련 중도탈락 예측 모형,2019,"['Vocational Training', 'Dropout', 'Machine Learning', 'Convolutional Neural Network', 'Word2vec', '직업훈련 교육', '중도탈락', '기계학습', '합성곱 신경망', 'Word2vec']","직업훈련 교육 현장에서 느끼는 가장 큰 어려움 중 하나는 중도탈락 문제이다. 훈련과정마다 많은 수의 학생들이 중도탈락을 하게 되어 국가 예산 낭비 및 청년 취업률 개선에 장애 요인이 되고 있다. 본 연구에서는 중도탈락의 원인을 주로 분석한 기존 연구들과 달리, 각종 수강생 정보를 활용하여 사전에 중도탈락을 예측할 수 있는 기계학습 기반 모형을 제안하고자 한다. 특히 본 연구의 제안모형은 수강생 관련 정형 데이터 뿐 아니라 비정형 데이터인 강사의 상담일지 정보까지 동시에 고려하여 모형의 예측정확도를 제고하고자 하였다. 이 때 비정형 데이터에 대한 분석은 최근 주목받고 있는 텍스트 분석 기술인 Word2vec과 합성곱 신경망을 이용해 수행하였다. 국내 한 직업훈련기관의 실제 데이터에 제안모형을 적용해 본 결과, 정형 데이터만을 사용하여 중도탈락을 예측할 때보다 비정형 데이터를 함께 고려했을 때 예측의 정확도가 최대 20%까지 향상됨을 확인할 수 있었다. 아울러, Support Vector Machine을 기반으로 정형 데이터와 비정형 데이터를 결합해 분석했을 때, 검증용 데이터셋 기준으로 90% 후반대의 높은 예측 정확도를 나타냄을 확인하였다.","One of the biggest difficulties in the vocational training field is the dropout problem. A large number of students drop out during the training process, which hampers the waste of the state budget and the improvement of the youth employment rate. Previous studies have mainly analyzed the cause of dropouts. The purpose of this study is to propose a machine learning based model that predicts dropout in advance by using various information of learners. In particular, this study aimed to improve the accuracy of the prediction model by taking into consideration not only structured data but also unstructured data. Analysis of unstructured data was performed using Word2vec and Convolutional Neural Network(CNN), which are the most popular text analysis technologies. We could find that application of the proposed model to the actual data of a domestic vocational training institute improved the prediction accuracy by up to 20%. In addition, the support vector machine-based prediction model using both structured and unstructured data showed high prediction accuracy of the latter half of 90%."
Origin of the Higher Difficulty in the Recognition of Vowels Compared to Handwritten Digits in Deep Neural Networks,2019,"['Vowel recognition', 'Deep neural network', 'Mel-frequency cepstral coe cients', 'Formant analysis']",,"We investigate the origin of the signicantly dierent error rates between handwritten digit machine recognition and vowel sound machine recognition. While the error rate for ve Korean vowel sounds, [A], [U], [I], [o], and [E], is about 10 percent, that of handwritten digit recognition is less than 1 percent for convolutional neural networks (CNNs) with raw data. We rst dilute the information of the sound by subtracting its temporal ne structure, with the assumption that sorting out extraneous sound information will improve the accuracy of vowel recognition. Simulation results show no improvement though, indicating that the recognition rate dierence does not arise from unnecessary sound information. Rather, conserving subtle information with no information reduction can be helpful to improve recognition rates; however, even the model with the highest accuracy does not reach the accuracy for handwritten digit recognition we desired. Finally, we nd that the main diculty of Korean vowel sound recognition comes from the similarity of [o] and [E]; without [E], recognition of the remaining vowels is up to 99 percent. The similarity can be seen through their formant structure. Humans overcome the similarity to adeptly dierentiate the two, and human vowel recognition remains far superior to the best performing CNNs. This indicates room to develop deep neural networks beyond the CNN still exists."
Prediction Model of User Physical Activity using Data Characteristics-based Long Short-term Memory Recurrent Neural Networks,2019,"['Data Mining', 'Neural Networks', 'LSTM', 'Prediction', 'Mobile Healthcare']",,"Recently, mobile healthcare services have attracted significant attention because of the emerging development and supply of diverse wearable devices. Smartwatches and health bands are the most common type of mobile-based wearable devices and their market size is increasing considerably. However, simple value comparisons based on accumulated data have revealed certain problems, such as the standardized nature of health management and the lack of personalized health management service models. The convergence of information technology (IT) and biotechnology (BT) has shifted the medical paradigm from continuous health management and disease prevention to the development of a system that can be used to provide ground-based medical services regardless of the user’s location. Moreover, the IT-BT convergence has necessitated the development of lifestyle improvement models and services that utilize big data analysis and machine learning to provide mobile healthcare-based personal health management and disease prevention information. Users’ health data, which are specific as they change over time, are collected by different means according to the users’ lifestyle and surrounding circumstances. In this paper, we propose a prediction model of user physical activity that uses data characteristics-based long short-term memory (DC-LSTM) recurrent neural networks (RNNs). To provide personalized services, the characteristics and surrounding circumstances of data collectable from mobile host devices were considered in the selection of variables for the model. The data characteristics considered were ease of collection, which represents whether or not variables are collectable, and frequency of occurrence, which represents whether or not changes made to input values constitute significant variables in terms of activity. The variables selected for providing personalized services were activity, weather, temperature, mean daily temperature, humidity, UV, fine dust, asthma and lung disease probability index, skin disease probability index, cadence, travel distance, mean heart rate, and sleep hours. The selected variables were classified according to the data characteristics. To predict activity, an LSTM RNN was built that uses the classified variables as input data and learns the dynamic characteristics of time series data. LSTM RNNs resolve the vanishing gradient problem that occurs in existing RNNs. They are classified into three different types according to data characteristics and constructed through connections among the LSTMs. The constructed neural network learns training data and predicts user activity. To evaluate the proposed model, the root mean square error (RMSE) was used in the performance evaluation of the user physical activity prediction method for which an autoregressive integrated moving average (ARIMA) model, a convolutional neural network (CNN), and an RNN were used. The results show that the proposed DC-LSTM RNN method yields an excellent mean RMSE value of 0.616. The proposed method is used for predicting significant activity considering the surrounding circumstances and user status utilizing the existing standardized activity prediction services. It can also be used to predict user physical activity and provide personalized healthcare based on the data collectable from mobile host devices."
문장 분류를 위한 정보 이득 및 유사도에 따른 단어 제거와 선택적 단어 임베딩 방안,2019,"['문장 분류', '특징 선택', '정보 이득', '단어 유사도', '단어 임베딩', 'Sentence Classification', 'Feature Selection', 'Information Gain', 'Word Similarity', 'Word Embedding']","텍스트 데이터가 특정 범주에 속하는지 판별하는 문장 분류에서, 문장의 특징을 어떻게 표현하고 어떤 특징을 선택할 것인가는 분류기의 성능에 많은 영향을 미친다. 특징 선택의 목적은 차원을 축소하여도 데이터를 잘설명할 수 있는 방안을 찾아내는 것이다. 다양한 방법이 제시되어 왔으며 Fisher Score나 정보 이득(Information Gain) 알고리즘 등을 통해 특징을 선택 하거나 문맥의 의미와 통사론적 정보를 가지는 Word2Vec 모델로 학습된 단어들을 벡터로 표현하여 차원을 축소하는 방안이 활발하게 연구되었다. 사전에 정의된 단어의 긍정 및 부정 점수에 따라 단어의 임베딩을 수정하는 방법 또한 시도하였다.본 연구는 문장 분류 문제에 대해 선택적 단어 제거를 수행하고 임베딩을 적용하여 문장 분류 정확도를 향상시키는 방안을 제안한다. 텍스트 데이터에서 정보 이득 값이 낮은 단어들을 제거하고 단어 임베딩을 적용하는방식과, 정보이득 값이 낮은 단어와 코사인 유사도가 높은 주변 단어를 추가로 선택하여 텍스트 데이터에서 제거하고 단어 임베딩을 재구성하는 방식이다.본 연구에서 제안하는 방안을 수행함에 있어 데이터는 Amazon.com의 ‘Kindle’ 제품에 대한 고객리뷰, IMDB 의 영화리뷰, Yelp의 사용자 리뷰를 사용하였다. Amazon.com의 리뷰 데이터는 유용한 득표수가 5개 이상을 만족하고, 전체 득표 중 유용한 득표의 비율이 70% 이상인 리뷰에 대해 유용한 리뷰라고 판단하였다. Yelp의 경우는 유용한 득표수가 5개 이상인 리뷰 약 75만개 중 10만개를 무작위 추출하였다. 학습에 사용한 딥러닝 모델은 CNN, Attention-Based Bidirectional LSTM을 사용하였고, 단어 임베딩은 Word2Vec과 GloVe를 사용하였다.단어 제거를 수행하지 않고 Word2Vec 및 GloVe 임베딩을 적용한 경우와 본 연구에서 제안하는 선택적으로 단어 제거를 수행하고 Word2Vec 임베딩을 적용한 경우를 비교하여 통계적 유의성을 검정하였다.","Dimensionality reduction is one of the methods to handle big data in text mining. For dimensionality reduction, we should consider the density of data, which has a significant influence on the performance of sentence classification. It requires lots of computations for data of higher dimensions. Eventually, it can cause lots of computational cost and overfitting in the model. Thus, the dimension reduction process is necessary to improve the performance of the model. Diverse methods have been proposed from only lessening the noise of data like misspelling or informal text to including semantic and syntactic information.On top of it, the expression and selection of the text features have impacts on the performance of the classifier for sentence classification, which is one of the fields of Natural Language Processing. The common goal of dimension reduction is to find latent space that is representative of raw data from observation space. Existing methods utilize various algorithms for dimensionality reduction, such as feature extraction and feature selection. In addition to these algorithms, word embeddings, learning low-dimensional vector space representations of words, that can capture semantic and syntactic information from data are also utilized. For improving performance, recent studies have suggested methods that the word dictionary is modified according to the positive and negative score of pre-defined words.The basic idea of this study is that similar words have similar vector representations. Once the feature selection algorithm selects the words that are not important, we thought the words that are similar to the selected words also have no impacts on sentence classification. This study proposes two ways to achieve more accurate classification that conduct selective word elimination under specific regulations and construct word embedding based on Word2Vec embedding. To select words having low importance from the text, we use information gain algorithm to measure the importance and cosine similarity to search for similar words. First, we eliminate words that have comparatively low information gain values from the raw text and form word embedding. Second, we select words additionally that are similar to the words that have a low level of information gain values and make word embedding. In the end, these filtered text and word embedding apply to the deep learning models; Convolutional Neural Network and Attention-Based Bidirectional LSTM.This study uses customer reviews on Kindle in Amazon.com, IMDB, and Yelp as datasets, and classify each data using the deep learning models. The reviews got more than five helpful votes, and the ratio of helpful votes was over 70% classified as helpful reviews. Also, Yelp only shows the number of helpful votes. We extracted 100,000 reviews which got more than five helpful votes using a random sampling method among 750,000 reviews. The minimal preprocessing was executed to each dataset, such as removing numbers and special characters from text data. To evaluate the proposed methods, we compared the performances of Word2Vec and GloVe word embeddings, which used all the words.We showed that one of the proposed methods is better than the embeddings with all the words. By removing unimportant words, we can get better performance. However, if we removed too many words, it showed that the performance was lowered. For future research, it is required to consider diverse ways of preprocessing and the in-depth analysis for the co-occurrence of words to measure similarity values among words. Also, we only applied the proposed method with Word2Vec. Other embedding methods such as GloVe, fastText, ELMo can be applied with the proposed methods, and it is possible to identify the possible combinations between word embedding methods and elimination methods."
영상기반 콘크리트 균열 탐지 딥러닝 모델의 유형별 성능 비교,2019,"['crack detection', 'deep learning', 'image classification', 'object detection', 'semantic segmentation', 'instance segmentation']",,"In this study, various types of deep learning models that have been proposed recently are classified according to data input / output types and analyzed to find the deep learning model suitable for constructing a crack detection model. First the deep learning models are classified into image classification model, object segmentation model, object detection model, and instance segmentation model. ResNet-101, DeepLab V2, Faster R-CNN, and Mask R-CNN were selected as representative deep learning model of each type. For the comparison, ResNet-101 was implemented for all the types of deep learning model as a backbone network which serves as a main feature extractor. The four types of deep learning models were trained with 500 crack images taken from real concrete structures and collected from the Internet. The four types of deep learning models showed high accuracy above 94% during the training.Comparative evaluation was conducted using 40 images taken from real concrete structures. The performance of each type of deep learning model was measured using precision and recall. In the experimental result, Mask R-CNN, an instance segmentation deep learning model showed the highest precision and recall on crack detection.Qualitative analysis also shows that Mask R-CNN could detect crack shapes most similarly to the real crack shapes."
RGB-D 카메라와 시맨틱 분할 기법을 이용한작업자의 안전 모니터링,2019,"['deep learning', 'semantic segmentation', 'safety monitoring', 'autonomous mobile robots']",,"This paper suggests a deep learning-based algorithm for monitoring workers’ safety in a smart factory environment. With thegrowth of smart factories in industry, the need for an AMR (autonomous mobile robot) that self-drives in a production line is increasing.Although most AMRs are designed to actively prevent a collision, there should be another monitoring solution to double-check workers’safety because not all machines are reliable. We use an RGB-D camera which provides both depth information and RGB color informationand a semantic segmentation method to monitor workers’ safety. The semantic segmentation algorithm is called Mask R-CNN and is usedto detect workers and moveable equipment including AMRs. Since Mask R-CNN can specify an object’s boundary in RGB images, we areable to determine an object’s position in 3D coordinates by using the camera’s depth information. We can monitor the workers’ safety bychecking whether they are close to hazardous equipment. We experimented with an AMR and manufacturing equipment to verify oursuggested algorithm."
딥 러닝 기반의 영상처리 기법을 이용한 겹침 돼지 분리,2019,"['Pig Monitoring', 'Occluding Pigs', 'Segmentation', 'Deep Learning', 'YOLO']",,"The crowded environment of a domestic pig farm is highly vulnerable to the spread of infectious diseases such as foot-and-mouth disease, and studies have been conducted to automatically analyze behavior of pigs in a crowded pig farm through a video surveillance system using a camera. Although it is required to correctly separate occluding pigs for tracking each individual pigs, extracting the boundaries of the occluding pigs fast and accurately is a challenging issue due to the complicated occlusion patterns such as X shape and T shape. In this study, we propose a fast and accurate method to separate occluding pigs not only by exploiting the characteristics (i.e., one of the fast deep learning-based object detectors) of You Only Look Once, YOLO, but also by overcoming the limitation (i.e., the bounding box-based object detector) of YOLO with the test-time data augmentation of rotation. Experimental results with two-pigs occlusion patterns show that the proposed method can provide better accuracy and processing speed than one of the state-of-the-art widely used deep learning-based segmentation techniques such as Mask R-CNN (i.e., the performance improvement over Mask R-CNN was about 11 times, in terms of the accuracy/processing speed performance metrics)."
Bridge Inspection and condition assessment using Unmanned Aerial Vehicles (UAVs): Major challenges and solutions from a practical perspective,2019,"['bridge inspection', 'unmanned aerial vehicle (UAV)', 'imaging device', 'condition assessment', 'deep learning algorithm']",,"Bridge collapses may deliver a huge impact on our society in a very negative way. Out of many reasons why bridges collapse, poor maintenance is becoming a main contributing factor to many recent collapses. Furthermore, the aging of bridges is able to make the situation much worse. In order to prevent this unwanted event, it is indispensable to conduct continuous bridge monitoring and timely maintenance. Visual inspection is the most widely used method, but it is heavily dependent on the experience of the inspectors. It is also time-consuming, labor-intensive, costly, disruptive, and even unsafe for the inspectors. In order to address its limitations, in recent years increasing interests have been paid to the use of unmanned aerial vehicles (UAVs), which is expected to make the inspection process safer, faster and more cost-effective. In addition, it can cover the area where it is too hard to reach by inspectors. However, this strategy is still in a primitive stage because there are many things to be addressed for real implementation. In this paper, a typical procedure of bridge inspection using UAVs consisting of three phases (i.e., pre-inspection, inspection, and post-inspection phases) and the detailed tasks by phase are described. Also, three major challenges, which are related to a UAV’s flight, image data acquisition, and damage identification, respectively, are identified from a practical perspective (e.g., localization of a UAV under the bridge, high-quality image capture, etc.) and their possible solutions are discussed by examining recently developed or currently developing techniques such as the graph-based localization algorithm, and the image quality assessment and enhancement strategy. In particular, deep learning based algorithms such as R-CNN and Mask R-CNN for classifying, localizing and quantifying several damage types (e.g., cracks, corrosion, spalling, efflorescence, etc.) in an automatic manner are discussed. This strategy is based on a huge amount of image data obtained from unmanned inspection equipment consisting of the UAV and imaging devices (vision and IR cameras)."
Deep Learning and Color Histogram based Fire and Smoke Detection Research,2019,"['Fire Detection', 'Deep Learning', 'Structure Similarity', 'Frame Difference', 'Color Histogram']",,"The fire should extinguish as soon as possible because it causes economic loss and loses precious life. In this study, we propose a new atypical fire and smoke detection algorithm using deep learning and color histogram of fire and smoke. First, input frame images obtain from the ONVIF surveillance camera mounted in factory search motion candidate frame by motion detection algorithm and mean square error (MSE). Second deep learning (Faster R-CNN) is used to extract the fire and smoke candidate area of motion frame. Third, we apply a novel algorithm to detect the fire and smoke using color histogram algorithm with local area motion, similarity, and MSE. In this study, we developed a novel fire and smoke detection algorithm applied the local motion and color histogram method. Experimental results show that the surveillance camera with the proposed algorithm showed good fire and smoke detection results with very few false positives."
Deep Learning and Color Histogram based Fire and Smoke Detection Research,2019,"['Fire Detection', 'Deep Learning', 'Structure Similarity', 'Frame Difference. Color Histogram.']",,"The fire should extinguish as soon as possible because it causes economic loss and loses precious life. In this study, we propose a new atypical fire and smoke detection algorithm using deep learning and color histogram of fire and smoke. First, input frame images obtain from the ONVIF surveillance camera mounted in factory search motion candidate frame by motion detection algorithm and mean square error (MSE).Second deep learning (Faster R-CNN) is used to extract the fire and smoke candidate area of motion frame.Third, we apply a novel algorithm to detect the fire and smoke using color histogram algorithm with local area motion, similarity, and MSE. In this study, we developed a novel fire and smoke detection algorithm applied the local motion and color histogram method. Experimental results show that the surveillance camera with the proposed algorithm showed good fire and smoke detection results with very few false positives."
Two person Interaction Recognition Based on Effective Hybrid Learning,2019,"['Action Recognition', 'Convolutional Neural Network', 'Deep Architecture', 'Transfer Learning']",,"Action recognition is an essential task in computer vision due to the variety of prospective applications, such as security surveillance, machine learning, and human-computer interaction. The availability of more video data than ever before and the lofty performance of deep convolutional neural networks also make it essential for action recognition in video. Unfortunately, limited crafted video features and the scarcity of benchmark datasets make it challenging to address the multi-person action recognition task in video data. In this work, we propose a deep convolutional neural network-based Effective Hybrid Learning (EHL) framework for two-person interaction classification in video data. Our approach exploits a pre-trained network model (the VGG16 from the University of Oxford Visual Geometry Group) and extends the Faster R-CNN (region-based convolutional neural network a state-of-the-art detector for image classification). We broaden a semi-supervised learning method combined with an active learning method to improve overall performance. Numerous types of two-person interactions exist in the real world, which makes this a challenging task. In our experiment, we consider a limited number of actions, such as hugging, fighting, linking arms, talking, and kidnapping in two environment such simple and complex. We show that our trained model with an active semi-supervised learning architecture gradually improves the performance. In a simple environment using an Intelligent Technology Laboratory (ITLab) dataset from Inha University, performance increased to 95.6% accuracy, and in a complex environment, performance reached 81% accuracy. Our method reduces data-labeling time, compared to supervised learning methods, for the ITLab dataset. We also conduct extensive experiment on Human Action Recognition benchmarks such as UT-Interaction dataset, HMDB51 dataset and obtain better performance than state-of-the-art approaches."
건설현장 근로자의 안전모 착용 여부 검출을 위한 컴퓨터 비전 기반 딥러닝 알고리즘의 적용,2019,"['construction safety', 'safety helmet', 'deep learning', 'computer vision']",,"Since construction sites are exposed to outdoor environments, working conditions are significantly dangerous. Thus, wearing of the personal protective equipments such as safety helmet is very important for worker safety. However, construction workers are often wearing-off the helmet as inconvenient and uncomportable. As a result, a small mistake may lead to serious accident. For this, checking of wearing safety helmet is important task to safety managers in field.However, due to the limited time and manpower, the checking can not be executed for every individual worker spread over a large construction site. Therefore, if an automatic checking system is provided, field safety management should be performed more effectively and efficiently. In this study, applicability of deep learning based computer vision technology is investigated for automatic checking of wearing safety helmet in construction sites. Faster R-CNN deep learning algorithm for object detection and classification is employed to develop the automatic checking model. Digital camera images captured in real construction site are used to validate the proposed model.Based on the results, it is concluded that the proposed model may effectively be used for automatic checking of wearing safety helmet in construction site."
A method based on Multi-Convolution layers Joint and Generative Adversarial Networks for Vehicle Detection,2019,"['Vehicle detection', 'non-maximum suppression', 'generative adversarial networks', 'joint feature map', 'mask occlusion']",,"In order to achieve rapid and accurate detection of vehicle objects in complex traffic conditions, we propose a novel vehicle detection method. Firstly, more contextual and small-object vehicle information can be obtained by our Joint Feature Network (JFN). Secondly, our Evolved Region Proposal Network (EPRN) generates initial anchor boxes by adding an improved version of the region proposal network in this network, and at the same time filters out a large number of false vehicle boxes by soft-Non Maximum Suppression (NMS). Then, our Mask Network (MaskN) generates an example that includes the vehicle occlusion, the generator and discriminator can learn from each other in order to further improve the vehicle object detection capability. Finally, these candidate vehicle detection boxes are optimized to obtain the final vehicle detection boxes by the Fine-Tuning Network(FTN). Through the evaluation experiment on the DETRAC benchmark dataset, we find that in terms of mAP, our method exceeds Faster-RCNN by 11.15%, YOLO by 11.88%, and EB by 1.64%. Besides, our algorithm also has achieved top2 comaring with MS-CNN, YOLO-v3, RefineNet, RetinaNet, Faster-rcnn, DSSD and YOLO-v2 of vehicle category in KITTI dataset."
