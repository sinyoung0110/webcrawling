title,date,keywords,abstract,multilingual_abstract
ResNet 모델을 이용한 눈 주변 영역의 특징 추출 및 개인 인증,2019,"['Periocular Region', 'Authentication', 'CNN', 'MLP']",국문 초록 정보 없음,"Deep learning approach based on convolution neural network (CNN)  has extensively studied in the field of computer vision. However, periocular feature extraction using CNN was not well studied because it is practically impossible to collect large volume of biometric data. This study uses the ResNet model which was trained with the ImageNet dataset. To overcome the problem of insufficient training data, we focused on the training of multi-layer perception (MLP) having simple structure rather than training the CNN having complex structure. It first extracts features using the pretrained ResNet model and reduces the feature dimension by principle component analysis (PCA), then trains a MLP classifier. Experimental results with the public periocular dataset UBIPr show that the proposed method is effective in person authentication using periocular region. Especially it has the advantage which can be directly applied for other biometric traits."
Multi-parametric MRIs based assessment of Hepatocellular Carcinoma Differentiation with Multi-scale ResNet,2019,"['Multi-parametric MRI', 'data fusion', 'transfer learning', 'deep learning', 'hepatocellular carcinoma differentiation']",국문 초록 정보 없음,"To explore an effective non-invasion medical imaging diagnostics approach for hepatocellular carcinoma (HCC), we propose a method based on adopting the multiple technologies with the multi-parametric data fusion, transfer learning, and multi-scale deep feature extraction. Firstly, to make full use of complementary and enhancing the contribution of different modalities viz. multi-parametric MRI images in the lesion diagnosis, we propose a data-level fusion strategy. Secondly, based on the fusion data as the input, the multi-scale residual neural network with SPP (Spatial Pyramid Pooling) is utilized for the discriminative feature representation learning. Thirdly, to mitigate the impact of the lack of training samples, we do the pre-training of the proposed multi-scale residual neural network model on the natural image dataset and the fine-tuning with the chosen multi-parametric MRI images as complementary data. The comparative experiment results on the dataset from the clinical cases show that our proposed approach by employing the multiple strategies achieves the highest accuracy of 0.847±0.023 in the classification problem on the HCC differentiation. In the problem of discriminating the HCC lesion from the non-tumor area, we achieve a good performance with accuracy, sensitivity, specificity and AUC (area under the ROC curve) being 0.981±0.002, 0.981±0.002, 0.991±0.007 and 0.999±0.0008, respectively."
ResNet을 이용한 얼굴 인식 기반 출입관리시스템 개발,2019,"['Face Recognition', 'Access Control', 'Deep Learning', 'ResNet']",국문 초록 정보 없음,다국어 초록 정보 없음
ResNet을 구성하는 잔차 블록의 필터 개수에 따른 네트워크 성능 비교,2019,"['딥러닝', 'ResNet', 'Image classification', 'Residual learning', 'Shotcut connection']",국문 초록 정보 없음,다국어 초록 정보 없음
ResNet을 이용한 PCB 코팅의 기포 분류,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
ResNet 과 LSTM 을 이용한 전력 수요 예측,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
이미지의 눈제거를 위한 심층 Resnet,2019,[],국문 초록 정보 없음,"Atmospheric particle removal is a challenging task and attacks wide interests in computer vision filed. In this paper, we proposed a single image snow removal framework based on deep residual networks. According to the fact that there are various snow sizes in a snow image, the inception module which consists of different filter kernels was adopted to extract multiple resolution features of the input snow image. Except the traditional mean square error loss, the perceptual loss and total variation loss were employed to generate more clean images. Experimental results on synthetic and realistic snow images indicated that the proposed method achieves superior performance in respect of visual perception and objective evaluation."
한국어 음성 명령어 인식을 위한 자동데이터 구축,2019,"['Korean Speech Command', 'Speech Recognition', 'Automatic Data Construction', 'ResNet', 'CNN', '한국어 명령어 인식', '음성인식', '자동 데이터 구축', '레스넷', '합성곱신경망']","최근 화두가 되고 있는 AI분야에서 가장 큰 문제점은 학습데이터의 부족 문제를 꼽을 수 있다. 수동 데이터 구축에는 많은 시간과 노력이 소요되기에 개인이 손쉽게 필요 데이터를 구축하기는 매우 어렵다. 반면, 수동 데이터 구축에 비해 자동으로 구축하는 것은 높은 품질을 유지하는 것이 관건이다. 본 논문에서는 한국어 음성 명령어 인식기 개발에 필요한 데이터를 웹에서 자동으로 추출하고, 학습데이터로 사용할 수 있는 데이터를 자동으로 선별하는 방법을 소개한다. 특히, 자동 구축된 한국어 음성 데이터를 대상으로 우수한 성능을 보이는 ResNet기반의 수정 모델을 기반으로, 건강 및 일상생활도메인의 명령어 셋을 대상으로 적용가능성을 보이기 위한 실험을 진행하였다. 자동으로 구축된 데이터만을 사용한 일련의 실험에서 건강도메인은 ResNet15에서 89.5%, 일상생활도메인에서는 ResNet8에서 82%의 정확도를 보임으로써, 자동 수집 데이터의 활용 가능성을 검증하였다.","The biggest problem in the AI field, which has become a hot topic in recent years, is how to deal with the lack of training data. Since manual data construction takes a lot of time and efforts, it is non-trivial for an individual to easily build the necessary data. On the other hand, automatic data construction needs to handle data quality issue. In this paper, we introduce a method to automatically extract the data required to develop Korean speech command recognizer from the web and to automatically select the data that can be used for training data. In particular, we propose a modified ResNet model that shows modest performance for the automatically constructed Korean speech command data. We conducted an experiment to show the applicability of the command set of the health and daily life domain. In a series of experiments using only automatically constructed data, the accuracy of the health domain was 89.5% in ResNet15 and 82% in ResNet8 in the daily lives domain, respectively."
Layer‐wise hint‐based training for knowledge transfer in a teacher‐student framework,2019,"['knowledge transfer', 'layer‐wise hint training', 'residual networks', 'teacher‐student framework']",국문 초록 정보 없음,"We devise a layer‐wise hint training method to improve the existing hint‐based knowledge distillation (KD) training approach, which is employed for knowledge transfer in a teacher‐student framework using a residual network (ResNet). To achieve this objective, the proposed method first iteratively trains the student ResNet and incrementally employs hint‐based information extracted from the pretrained teacher ResNet containing several hint and guided layers. Next, typical softening factor‐based KD training is performed using the previously estimated hint‐based information. We compare the recognition accuracy of the proposed approach with that of KD training without hints, hint‐based KD training, and ResNet‐based layer‐wise pretraining using reliable datasets, including CIFAR‐10, CIFAR‐100, and MNIST. When using the selected multiple hint‐based information items and their layer‐wise transfer in the proposed method, the trained student ResNet more accurately reflects the pretrained teacher ResNet's rich information than the baseline training methods, for all the benchmark datasets we consider in this study."
앙상블 학습 알고리즘을 이용한 컨벌루션 신경망의 분류 성능 분석에 관한 연구,2019,"['Deep Learning', 'Computer Vision', 'CNN', 'Ensemble Learning Algorithm']",국문 초록 정보 없음,"In this paper, we compare and analyze the classification performance of deep learning algorithm Convolutional Neural Network(CNN) ac cording to ensemble generation and combining techniques. We used several CNN models(VGG16, VGG19, DenseNet121, DenseNet169, DenseNet201, ResNet18, ResNet34, ResNet50, ResNet101, ResNet152, GoogLeNet) to create 10 ensemble generation combinations and applied 6 combine techniques(average, weighted average, maximum, minimum, median, product) to the optimal combination. Experimental results, DenseNet169-VGG16-GoogLeNet combination in ensemble generation, and the product rule in ensemble combination showed the best performance. Based on this, it was concluded that ensemble in different models of high benchmarking scores is another way to get good results."
Regression with residual neural network for vanishing point detection,2019,"['Vanishing point detection', 'Deep learning', 'Naver Street View dataset', 'ResNet', 'Regression']",국문 초록 정보 없음,<P><B>Abstract</B></P>  <P>This paper aims to propose a regression method with a residual neural network (ResNet) for vanishing point detection. The purpose of this study is to estimate the position of the vanishing point accurately. Our newly collected Naver Maps' Street View dataset is used for training regression ResNet-34 and for comparison with previous methods. It is concluded that the trained regression ResNet outperforms previous methods in terms of both computation time and accuracy.</P>
Comparing Convolutional Neural Network(CNN) models for machine learning-based drone and bird classification of anti-drone system,2019,"['Drone classification', 'Anti-drone', 'Convolutional Neural Network(CNN)', 'Drone defense system']",국문 초록 정보 없음,"As drones become more advanced and commercialized, crimes using drones are also on rise. For this reason, development of anti-drone systems is increasing. In this paper, CNN model is examined that is suitable for visible camera-based drone identification. The CNN models used for the validation are Alexnet, GoLeNet, Inception-v3 Vg16, Resnet-18, Resnet-50 and Squezezenet. These seven models have already been validated in the ImageNet Large Scale Visual Recognition Competition (ILSVRC). In ILSVRC, 1000 labels are classified, but in this study limits them to three drones, birds and backgrounds. Therefore, it is necessary to verify whether the three labels are the same as the ILSVRC result. In order to verify this, CNN models are learned and tested in the same environment. The experimental results show that the performance of Alexnet, Resnet and Squeeznet is relatively better then the others, unlike the performance of CNN known through ILSVRC. his result shows that a shallow network with a simple structure is more reasonable when the number of labels is small. Based on these results, the further work is to develop a neural network optimized for Drone identification."
CNN Model Performance Analysis on MRI Images of an OASIS Dataset for Distinction Between Healthy and Alzheimer’s Patients,2019,"['Medical MRI', 'CNN', 'AlexNet', 'GoogLeNet', 'ResNet50', 'CAD']",국문 초록 정보 없음,"In this paper, we present the performance of a medical image classification model pretrained on natural images. In addition, another model is scratch trained from available medical magnetic resonance images in order to get a comparative analysis. We perform shallow tuning and fine-tuning of the pretrained model (AlexNet, GoogLeNet, and ResNet50) in a bunch of layers in order to find the impact of each section of layers in the classification result. We use 28 normal controls (NC) and 28 Alzheimer’s disease (AD) patients for classification, selecting 30 important slices from each patient. Once all the slices were collected, each model was trained, validated, and tested at a ratio of 6:2:2 on a random selection basis. The testing results are reported and analyzed so the final CNN model could be built with a minimal number of layers for optimal performance."
A Novel Integrated Convolutional Neural Network via Deep Transfer Learning in Colorectal Images,2019,"['Colon Disease Classification', 'Convolutional Neural Networks', 'Transfer Learning']",국문 초록 정보 없음,"In this paper, we explore the use of current deep learning methods, convolutional neural networks (CNNs) in the field of computer-aided diagnosis systems to classify several endoscopic colon diseases. Transfer learning by fine-tuning deep convolutional neural networks (CNNs) is applied due to the limited amount of data. For this, state-of-the-art CNN architectures, such as VGG16, VGG19, InceptionV3, ResNet50, Inception-ResNet-V2, DenseNet169 were used for training and validating the dataset. However, these existing architectures cannot extract more dense endoscopic image features and have problem on similar-looking images of different category. Therefore, we propose a novel integrated convolutional neural network to develop a more accurate and highly efficient method for endoscopic image classification, which uses the features of earlier layers in the classification process and increases the receptive field of view at the end layers in the network. We compare and evaluate our performance using performance metrics Accuracy (ACC), Recall, Precision and F1-score. In our experimental results, the proposed method outperforms the existing architectures, obtaining an accuracy of about 92.4% on the test dataset."
영상기반 콘크리트 균열 탐지 딥러닝 모델의 유형별 성능 비교,2019,"['crack detection', 'deep learning', 'image classification', 'object detection', 'semantic segmentation', 'instance segmentation']",국문 초록 정보 없음,"In this study, various types of deep learning models that have been proposed recently are classified according to data input / output types and analyzed to find the deep learning model suitable for constructing a crack detection model. First the deep learning models are classified into image classification model, object segmentation model, object detection model, and instance segmentation model. ResNet-101, DeepLab V2, Faster R-CNN, and Mask R-CNN were selected as representative deep learning model of each type. For the comparison, ResNet-101 was implemented for all the types of deep learning model as a backbone network which serves as a main feature extractor. The four types of deep learning models were trained with 500 crack images taken from real concrete structures and collected from the Internet. The four types of deep learning models showed high accuracy above 94% during the training.Comparative evaluation was conducted using 40 images taken from real concrete structures. The performance of each type of deep learning model was measured using precision and recall. In the experimental result, Mask R-CNN, an instance segmentation deep learning model showed the highest precision and recall on crack detection.Qualitative analysis also shows that Mask R-CNN could detect crack shapes most similarly to the real crack shapes."
말벌 영상인식을 위한 심층 합성곱 신경망의 성능 평가,2019,"['Vespa hornets', 'Deep convolutional neural network', 'Deep learning', 'Classification']",국문 초록 정보 없음,"One of the serious factors for honeybee decline is due to the various attacks from Vespa hornets, indigenous and invaded. Population monitoring as well as the alerting systems is requested against the Vespa. Automated image recognition is the primary step for the unmanned autonomous monitoring system development. This study compared the recent deep convolutional neural network (DCNN) algorithms such as AlexNet, VGG19, GoogLeNet, and ResNet50 for the best model selection for classification of 3 Vespa species, V. mandarinia, V. crabro and V. velutina. To evaluate classification performance, accuracy was utilized after transfer learning on each DCNN. As a result, the ResNet50 showed the best in terms of accuracy after sufficient training of 100 epochs. If performance and speed are considered simultaneously, AlexNet could be the alternative. The real-time monitoring system for objects requires both localization and classification. And Vespa occurrence or population change would need rapid recognition for the objects. Therefore speedy image recognition based on the DCNN, which combines localization and classification for objects in an image, should be considered in the future works."
가상화 플랫폼을 통한 CNN기반 모니터링 애플리케이션의 안정적인 응답 속도 보장 방안 연구,2019,"['Virtualized Platform', 'Cloud Computing', 'OpenStack', 'Docker', 'IaaS', 'CNN', 'Monitoring', '가상화 플랫폼', '클라우드 컴퓨팅', 'OpenStack', 'Docker', 'IaaS', 'CNN', '모니터링']","최근 가상화 기술이 적용된 가상화 플랫폼(Virtualized Platform)을 도입하게 되면서 단일 하드웨어 리소스의 파티셔닝을 통한 리소스 활용률 상승과 마이그레이션을 통한 확장성의 이점을 통해 서비스의 안정적인 응답 속도를 기대할 수 있게 되었다. 기존 단일 하드웨어 서버기반 모니터링 애플리케이션 서비스에서는 필요 이상의 리소스를 사용하거나 사용자의 요청에 비해 리소스가 부족하여 응답 속도가 저하되는 문제가 발생하였다. 본 논문에서는 이를 해결하기 위해 오픈 소스 가상화 플랫폼인 OpenBaton, OpenStack과 Docker를 통해 이미지에 대해 화재 및 연기 예측이 가능한 ResNet50 기반의 CNN 모델이 적용된 모니터링 애플리케이션을 구현하였다. 이를 통해 본 논문에서는 기존 단일 하드웨어 서버와 제안된 시스템의 응답 속도 비교를 통해 안정적인 응답 속도 보장 방안에 대해 연구하였다.","With the recent introduction of a virtualized platform with virtualization technology, the benefits of increased resource utilization through partitioning of a single hardware resource and scalability through migration provide a reliable response rate for services. Traditional single hardware server-based monitoring application services have had problems with using more resources than needed or lack of resources compared to the user's request, resulting in slower response times. To address this, this paper implemented a monitoring application with a CNN model based on ResNet50 that enables fire and smoke prediction for images through open source virtualization platforms, OpenBaton, OpenStack and Docker. In this paper, we studied how to ensure a stable response rate through comparing the response speed of the existing single hardware server with the proposed system."
위내시경 디지털 영상에서 정상과 위궤양 딥러닝 분류 모델,2019,"['위궤양', '내시경 영상', '딥러닝', '인공지능', 'Gastric Ulcer', 'Endoscopic Image', 'Deep Learning', 'Artificial Intelligent']","내시경 장비의 발전으로 위장 질환의 조기 발견 및 치료에 많은 향상이 있다. 따라서, 많은 내시경 이미지과 함께 내시경 이미지 분류에 대한 연구가 활발히 증가하고 있다. 본 논문에서는 위내시경에서 많이 발견되는 질환인 위궤양을 분류하고자 한다. 위궤양은 초기에 적절한 치료를 하지 않으면 합병증을 일으킬 수 있으므로, 초기에 병변을 진단하는 것이 가장 중요하다. 본 연구에서는 ResNet-50 딥러닝 모델을 이용하여 정상과 위궤양을 분류하고자 하였다. 총 1,525개의 이미지를 이용하여 모델을 생성하였고, 효율적인 학습을 위해 데이터 증강을 적용하였다. 제안된 모델의 분류 성능은 정확도 0.9016, ROC 곡선은 0.83으로 확인하였다.","Due to the development of endoscopic equipment, there has been much progress in the early detection and treatment of gastrointestinal diseases. Therefore, many endoscopic images have been provided, and studies on endoscopic image classification have been increased actively. In this paper, we aim to classify gastric ulcer, a disease frequently found in endoscopy.Gastric ulcers can lead to complications if not properly treated early on, so it is most important to diagnose the lesions early.Our study used the ResNet-50 in-depth learning model. A model was created using a total of 1,525 images, and data enhancement was applied for efficient learning. The classification performance of the proposed model is 0.9016 with accuracy and 0.83 with ROC curve."
Sentinel-1 A/B 위성 SAR 자료와 딥러닝 모델을 이용한 여름철 북극해 해빙 분류 연구,2019,"['Sentinel-1 A/B', 'sea ice', 'thermal noise', 'Deep Learning', 'classification']","북극항로의 개척 가능성과 정확한 기후 예측 모델의 필요성에 의해 북극해 고해상도 해빙 지도의 중요성이 증가하고 있다. 그러나 기존의 북극 해빙 지도는 제작에 사용된 위성 영상 취득 센서의 특성에 따른 데이터의 취득과 공간해상도 등에서 그 활용도가 제한된다. 본 연구에서는 Sentinel-1 A/B SAR 위성자료로부터 고해상도 해빙 지도를 생성하기 위한 딥러닝 기반의 해빙 분류 알고리즘을 연구하였다. 북극해 Ice Chart를 기반으로 전문가 판독에 의해 Open Water, First Year Ice, Multi Year Ice의 세 클래스로 구성된 훈련자료를 구축하였으며, Convolutional Neural Network 기반의 두 가지 딥러닝 모델(Simple CNN, Resnet50)과 입사각 및 thermal noise가 보정된 HV 밴드를 포함하는 다섯 가지 입력 밴드 조합을 이용하여 총 10가지 케이스의 해빙 분류를 실시하였다. 이 케이스들에 대하여 Ground Truth Point를 사용하여 정확도를 비교하고, 가장 높은 정확도가 나온케이스에 대해 confusion matrix 및 Cohen의 kappa 분석을 실시하였다. 또한 전통적으로 분류를 위해 많이 활용되어 온 Maximum Likelihood Classifier 기법을 이용한 분류결과에 대해서도 같은 비교를 하였다. 그 결과Convolution 층 2개, Max Pooling 층 2개를 가진 구조의 Convolutional Neural Network에 [HV, 입사각] 밴드를 넣은 딥러닝 알고리즘의 분류 결과가 96.66%의 가장 높은 분류 정확도를 보였으며, Cohen의 kappa 계수는 0.9499 로 나타나 딥러닝에 의한 해빙 분류는 비교적 높은 분류 결과를 보였다. 또한 모든 딥러닝 케이스는 Maximum Likelihood Classifier 기법에 비해 높은 분류 정확도를 보였다.","The importance of high-resolution sea ice maps of the Arctic Ocean is increasing due to the possibility of pioneering North Pole Routes and the necessity of precise climate prediction models. In this study, sea ice classification algorithms for two deep learning models were examined using Sentinel- 1 A/B SAR data to generate high-resolution sea ice classification maps. Based on current ice charts, three classes (Open Water, First Year Ice, Multi Year Ice) of training data sets were generated by Arctic sea ice and remote sensing experts. Ten sea ice classification algorithms were generated by combing two deep learning models (i.e. Simple CNN and Resnet50) and five cases of input bands including incident angles and thermal noise corrected HV bands. For the ten algorithms, analyses were performed by comparing classification results with ground truth points. A confusion matrix and Cohen’s kappa coefficient were produced for the case that showed best result. Furthermore, the classification result with the Maximum Likelihood Classifier that has been traditionally employed to classify sea ice. In conclusion, the Convolutional Neural Network case, which has two convolution layers and two max pooling layers, with HV and incident angle input bands shows classification accuracy of 96.66%, and Cohen’s kappa coefficient of 0.9499. All deep learning cases shows better classification accuracy than the classification result of the Maximum Likelihood Classifier."
Detection of construction workers under varying poses and changing background in image sequences via very deep residual networks,2019,"['Construction worker detection', 'Deep learning', 'Two-stage approach', 'Very deep residual networks']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>Analyzing the location and behavior of construction workers using construction site images has been recognized as a means of providing useful information for safety management and productivity analysis. Although effective utilization of analyzed image data requires accurate and timely detection of workers in complex, continuously changing working environments, the previous methods that detect construction workers still require improvement because of the poor detection performance. This study proposes the use of very deep residual networks to accurately and rapidly detect construction workers under varying poses and against changing backgrounds in image sequences. The architecture of construction worker detection in this study is based on convolutional neural networks (CNNs). The proposed method is divided into two stages: extracting feature maps via very deep residual networks (ResNet-152) and bounding box regression and labeling from the original image via Faster regions with CNN features (R-CNN). The experiments were conducted at actual construction sites by acquiring 1.3-megapixel and 3.1-megapixel images from a movable digital camera to verify the proposed method for images from fixed and moving cameras. Faster R-CNN with ResNet-152 had accuracy, precision, and recall rates of 94.3%, 96.03%, and 98.13% for 3241 images, respectively. The proposed method processed 0.2 s per frame (i.e., 5 frames per second) on average. The results show that it is possible to accurately and rapidly detect multiple workers in construction site images by employing very deep residual networks without relying on limited assumptions about workers' postures, appearance, and background.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  This study integrated a very deep residual network-152 for detecting construction workers. </LI> <LI>  3241 construction site images used for validation in varying poses and changing backgrounds </LI> <LI>  Accuracy, precision, and recall were 94.3%, 96.03%, and 98.13%, respectively, at 5 fps. </LI> <LI>  Possible to accurately detect workers without assumptions about posture or the background </LI> <LI>  Improved in terms of reliability performance compared with the most recent studies for this purpose </LI> </UL> </P>"
딥러닝 기반 포즈 변화에 강인한 귀 인식 연구,2019,"['Ear recognition', 'Convolutional neural networks', 'K-ear database', 'Ensemble']",국문 초록 정보 없음,다국어 초록 정보 없음
Decomposed “Spatial and Temporal” Convolution for Human Action Recognition in Videos,2019,[],국문 초록 정보 없음,"In this paper we study the effect of decomposed spatiotemporal convolutions for action recognition in videos. Our motivation emerges from the empirical observation that spatial convolution applied on solo frames of the video provide good performance in action recognition. In this research we empirically show the accuracy of factorized convolution on individual frames of video for action classification. We take 3D ResNet-18 as base line model for our experiment, factorize its 3D convolution to 2D (Spatial) and 1D (Temporal) convolution. We train the model from scratch using Kinetics video dataset. We then fine-tune the model on UCF-101 dataset and evaluate the performance. Our results show good accuracy similar to that of the state of the art algorithms on Kinetics and UCF- 101 datasets."
Improved Reinforcement Learning through Imitation Learning Pretraining Towards Image-based Autonomous Driving,2019,"['Autonomous driving', 'reinforcement learning', 'imitation learning']",국문 초록 정보 없음,"We present a training pipeline for the autonomous driving task given the current camera image and vehicle speed as the input to produce the throttle, brake, and steering control output. The simulator Airsim’s [1] convenient weather and lighting API provides a sufficient diversity during training which can be very helpful to increase the trained policy’s robustness. In order to not limit the possible policy’s performance, we use a continuous and deterministic control policy setting. We utilize ResNet-34 [2] as our actor and critic networks with some slight changes in the fully connected layers. Considering human’s mastery of this task and the high-complexity nature of this task, we first use imitation learning to mimic the given human policy and then leverage the trained policy and its weights to the reinforcement learning phase for which we use DDPG [3]. This combination shows a considerable performance boost comparing to both pure imitation learning and pure DDPG for the autonomous driving task."
TVM 딥러닝 컴파일러와 VTA 가속기의 성능 고찰,2019,[],국문 초록 정보 없음,"Deep learning techniques have been applied to various fields, such as image recognition, natural language processing, computer vision, and so on. Therefore, their accelerators are getting attention due to the execution efficiency in terms of speed and power, and the deep learning compilers help programmers to develop optimized code. In this paper, we review TVM, an open-source deep-learning compiler, and analyze its performance by using GoogLeNet. Also, we compare the performance of VTA, the neural network accelerator based on TVM, with CPU by using the quantized ResNet-18."
심층 신경망 기반의 생활폐기물 자동 분류,2019,[],"도시화 과정에서 도시의 생활폐기물 문제가 빠르게 증가되고 있고, 효과적이지 못한 생활폐기물 관리는 도시의 오염을 악화시키고 물리적인 환경오염과 경제적인 부분에서 극심한 문제들을 야기시킬 수 있다. 게다가 부피가 커서 관리하기 힘든 대형 생활폐기물들이 증가하여 도시 발전에도 방해가 된다. 생활폐기물을 처리하는데 있어 대형 생활폐기물 품목에 대해서는 요금을 청구하여 처리한다. 다양한 유형의 대형 생활폐기물을 수동으로 분류하는 것은 시간과 비용이 많이 든다. 그 결과 대형 생활폐기물을 자동으로 분류하는 시스템을 도입하는 것이 중요하다. 본 논문에서는 대형 생활폐기물 분류를 위한 시스템을 제안하며, 이 논문의 4 가지로 분류된다. 1) 높은 정확도와 강 분류(roust classification) 수행에 적합한 Convolution Neural Network(CNN) 모델 중 VGG-19, Inception-V3, ResNet50 의 정확도와 속도를 비교한다. 제안된 20 개의 클래스의 대형 생활폐기물의 데이터 셋(data set)에 대해 가장 높은 분류의 정확도는 86.19%이다. 2) 불균형 데이터 문제를 처리하기 Class Weight VGG-19(CW-VGG-19)와 Extreme Gradient Boosting VGG-19 두 가지 방법을 사용하였다. 3) 20 개의 클래스를 포함하는 데이터 셋을 수동으로 수집 및 검증하였으며 각 클래스의 컬러 이미지 수는 500 개 이상이다. 4) 딥 러닝(Deep Learning) 기반 모바일 애플리케이션을 개발하였다.",다국어 초록 정보 없음
Performance Comparison of the Optimizers in a Faster R-CNN Model for Object Detection of Metaphase Chromosomes,2019,[],국문 초록 정보 없음,"In this paper, we compares the performance of the gredient descent optimizers of the Faster Region-based Convolutional Neural Network (R-CNN) model for the chromosome object detection in digital images composed of human metaphase chromosomes. In faster R-CNN, the gradient descent optimizer is used to minimize the objective function of the region proposal network (RPN) module and the classification score and bounding box regression blocks. The gradient descent optimizer. Through performance comparisons among these four gradient descent optimizers in our experiments, we found that the Adamax optimizer could achieve the mean average precision (mAP) of about 52% when considering faster R-CNN with a base network, VGG16. In case of faster R-CNN with a base network, ResNet50, the Adadelta optimizer could achieve the mAP of about 58%."
Training Data Sets Construction from Large Data Set for PCB Character Recognition,2019,"['PCB inspection', 'Optical character recognition', 'Deep learning', 'Data reduction', 'Sampling.']",국문 초록 정보 없음,"Deep learning has become increasingly popular in both academic and industrial areas nowadays. Various domains including pattern recognition, Computer vision have witnessed the great power of deep neural networks. However, current studies on deep learning mainly focus on quality data sets with balanced class labels, while training on bad and imbalanced data set have been providing great challenges for classification tasks. We propose in this paper a method of data analysis-based data reduction techniques for selecting good and diversity data samples from a large dataset for a deep learning model. Furthermore, data sampling techniques could be applied to decrease the large size of raw data by retrieving its useful knowledge as representatives. Therefore, instead of dealing with large size of raw data, we can use some data reduction techniques to sample data without losing important information. We group PCB characters in classes and train deep learning on the ResNet56 v2 and SENet model in order to improve the classification performance of optical character recognition (OCR) character classifier."
Deep-Learning Seat Selection on a Tour Bus Based on Scenery and Sunlight Information,2019,"['Deep learning', 'Transfer learning', 'Google Street View', 'Tour']",국문 초록 정보 없음,"When traveling on a tour bus, the seat one chooses for viewing scenery is one of the main factors affecting one’s enjoyment of a trip. However, such scenery information is not available in advance. Therefore, it is necessary to predict the scenery for a tour bus route. In previous research, such predictions have been attempted through machine learning. However, the prediction result has only informed users about which direction is best, not about how good that direction is. Moreover, no information was given about sunlight, which can also affect the viewing of scenery. Therefore, in this paper, we propose the Beautiful Scenery & Cool Shade system that quantifies the information about scenery and sunlight in four directions using deep learning and the azimuth theory. More specifically, we used ResNet-152, DenseNet-161, and Inception v3 for the prediction, and we used Google Street View for the input data. After building the system, we tested its applications to two existing tour bus routes. The results showed that our system outperformed the previous system. The proposed system allows tourists to make satisfactory travel plans and allows tour companies to develop more valuable tour services, ultimately contributing to the development of the global tourism industry."
A Comparative Study of Alzheimer’s Disease Classification using Multiple Transfer Learning Models,2019,"['Alzheimer’s disease', 'CNN', 'MR images', 'Transfer learning.']",국문 초록 정보 없음,"Over the past decade, researchers were able to solve complex medical problems as well as acquire deeper understanding of entire issue due to the availability of machine learning techniques, particularly predictive algorithms and automatic recognition of patterns in medical imaging. In this study, a technique called transfer learning has been utilized to classify Magnetic Resonance (MR) images by a pre-trained Convolutional Neural Network (CNN). Rather than training an entire model from scratch, transfer learning approach uses the CNN model by fine-tuning them, to classify MR images into Alzheimer’s disease (AD), mild cognitive impairment (MCI) and normal control (NC). The performance of this method has been evaluated over Alzheimer’s Disease Neuroimaging (ADNI) dataset by changing the learning rate of the model. Moreover, in this study, in order to demonstrate the transfer learning approach we utilize different pre-trained deep learning models such as GoogLeNet, VGG-16, AlexNet and ResNet-18, and compare their efficiency to classify AD. The overall classification accuracy resulted by GoogLeNet for training and testing was 99.84% and 98.25% respectively, which was exceptionally more than other models training and testing accuracies."
Cody Recommendation System Using Deep Learning and User Preferences,2019,"['deep-learning', 'Fashion', 'Cody Recommendation', 'User Preferences']",국문 초록 정보 없음,"As AI technology is recently introduced into various fields, it is being applied to the fashion field. This paper proposes a system for recommending cody clothes suitable for a user's selected clothes. The proposed system consists of user app, cody recommendation module, and server interworking of each module and managing database data. Cody recommendation system classifies clothing images into 80 categories composed of feature combinations, selects multiple representative reference images for each category, and selects 3 full body cordy images for each representative reference image. Cody images of the representative reference image were determined by analyzing the user's preference using Google survey app. The proposed algorithm classifies categories the clothing image selected by the user into a category, recognizes the most similar image among the classification category reference images, and transmits the linked cody images to the user's app. The proposed system uses the ResNet-50 model to categorize the input image and measures similarity using ORB and HOG features to select a reference image in the category. We test the proposed algorithm in the Android app, and the result shows that the recommended system runs well."
Cody Recommendation System Using Deep Learning and User Preferences,2019,"['deep-learning', 'Fashion', 'Cody Recommendation', 'User Preferences']",국문 초록 정보 없음,"As AI technology is recently introduced into various fields, it is being applied to the fashion field. This paper proposes a system for recommending cody clothes suitable for a user's selected clothes. The proposed system consists of user app, cody recommendation module, and server interworking of each module and managing database data. Cody recommendation system classifies clothing images into 80 categories composed of feature combinations, selects multiple representative reference images for each category, and selects 3 full body cordy images for each representative reference image. Cody images of the representative reference image were determined by analyzing the user's preference using Google survey app. The proposed algorithm classifies categories the clothing image selected by the user into a category, recognizes the most similar image among the classification category reference images, and transmits the linked cody images to the user's app. The proposed system uses the ResNet-50 model to categorize the input image and measures similarity using ORB and HOG features to select a reference image in the category. We test the proposed algorithm in the Android app, and the result shows that the recommended system runs well."
Cody Recommendation System Using Deep Learning and User Preferences,2019,"['deep-learning', 'Fashion', 'Cody Recommendation', 'User Preferences']",국문 초록 정보 없음,"As AI technology is recently introduced into various fields, it is being applied to the fashion field. This paper proposes a system for recommending cody clothes suitable for a user's selected clothes. The proposed system consists of user app, cody recommendation module, and server interworking of each module and managing database data. Cody recommendation system classifies clothing images into 80 categories composed of feature combinations, selects multiple representative reference images for each category, and selects 3 full body cordy images for each representative reference image. Cody images of the representative reference image were determined by analyzing the user's preference using Google survey app. The proposed algorithm classifies categories the clothing image selected by the user into a category, recognizes the most similar image among the classification category reference images, and transmits the linked cody images to the user's app. The proposed system uses the ResNet-50 model to categorize the input image and measures similarity using ORB and HOG features to select a reference image in the category. We test the proposed algorithm in the Android app, and the result shows that the recommended system runs well."
Mask R-CNN기법을 활용한 목재 표면 옹이 구획화,2019,[],"목재 품질의 객관적 평가 및 목재 생산의 고속화를 위해서는 컴퓨터 비전을 활용한 목재 표면 화상분석 자동화가 필요하다. 딥러닝(Deep Learning) 기술은 최근 컴퓨터 비전을 통한 화상 분석 및 패턴인식 분야에서 높은 정확도와 속도로 인해 그 활용도가 높아지고 있다. 따라서 본 연구에서는 딥러닝 기술 중 화상의 구획화에 높은 성능을 보이는 알려진 합성곱 신경망(Convolutional Neural Network)을 이용하여 목재 표면 옹이를 구획화하고, 그 종류를 분류하였다. 본 연구에서 사용한 목재 재면 사진은 낙엽 송, 잣나무, 소나무, 삼나무, 편백, 더글라스 퍼, 라디에타 파인에서 획득한 938개의 제재목 사진을 사용 하였다. 제재목 사진에서 추출한 옹이 이미지는 1,172개로, 4 가지 종류로 분류하였다. 옹이의 종류와 위치에 대한 데이터베이스를 통해 제재목 표면의 옹이를 구획화하여 표시하고, 그 종류를 분류하는 알고리즘 학습을 진행하였다. 학습에 사용한 Mask R-CNN(Regions with Convolutional Neural Network) 모델은 resnet101을 이용하여 Feature Pyramid Network를 토대로 옹이 위치 예측 학습과 옹이 종류 분류 학습을 동시에 진행하였다. 목재 표면의 옹이 구획화 학습을 진행한 결과, 옹이 종류별 이미지의 편차가 존재하며, 옹이의 크기가 다양함에 불구하고 높은 정확도로 목재 표면의 옹이 탐지가 가능하였다. 200번의 반복학습결과, 학습이 반복될수록 학습 이미지셋에 과적합하는 현상이 발생하여 목재 문양이 옹이로 탐지되는 경우가 발생하였다. 하지만 높은 정확도로 분류가 가능하였기 때문에 다양한 옹이 형태를 추가로 학습시킨다면 더 높은 정확도로 옹이 구획화가 가능할 것으로 기대된다.",다국어 초록 정보 없음
Analyze weeds classification with visual explanation based on Convolutional Neural Networks,2019,"['Grad-CAM', 'CNN', 'visualization', 'Resnet']",국문 초록 정보 없음,"To understand how a Convolutional Neural Network (CNN) model captures the features of a pattern to determine which class it belongs to, in this paper, we use Gradient-weighted Class Activation Mapping (Grad-CAM) to visualize and analyze how well a CNN model behave on the CNU weeds dataset. We apply this technique to Resnet model and figure out which features this model captures to determine a specific class, what makes the model get a correct/wrong classification, and how those wrong label images can cause a negative effect to a CNN model during the training process. In the experiment, Grad-CAM highlights the important regions of weeds, depending on the patterns learned by Resnet, such as the lobe and limb on 미국가막사리, or the entire leaf surface on 단풍잎돼지풀. Besides, Grad-CAM points out a CNN model can localize the object even though it is trained only for the classification problem."
Spatio-Temporal Residual Networks for Slide Transition Detection in Lecture Videos,2019,"['Lecture video', 'slide transition', '3D ConvNet', 'ResNet']",국문 초록 정보 없음,"In this paper, we present an approach for detecting slide transitions in lecture videos by introducing the spatio-temporal residual networks. Given a lecture video which records the digital slides, the speaker, and the audience by multiple cameras, our goal is to find keyframes where slide content changes. Since temporal dependency among video frames is important for detecting slide changes, 3D Convolutional Networks has been regarded as an efficient approach to learn the spatio-temporal features in videos. However, 3D ConvNet will cost much training time and need lots of memory. Hence, we utilize ResNet to ease the training of network, which is easy to optimize. Consequently, we present a novel ConvNet architecture based on 3D ConvNet and ResNet for slide transition detection in lecture videos. Experimental results show that the proposed novel ConvNet architecture achieves the better accuracy than other slide progression detection approaches."
Automated classification of gastric neoplasms in endoscopic images using a convolutional neural network,2019,[],국문 초록 정보 없음,"<B>Abstract</B><P> Background Visual inspection, lesion detection, and differentiation between malignant and benign features are key aspects of an endoscopist’s role. The use of machine learning for the recognition and differentiation of images has been increasingly adopted in clinical practice. This study aimed to establish convolutional neural network (CNN) models to automatically classify gastric neoplasms based on endoscopic images.</P><P> Methods Endoscopic white-light images of pathologically confirmed gastric lesions were collected and classified into five categories: advanced gastric cancer, early gastric cancer, high grade dysplasia, low grade dysplasia, and non-neoplasm. Three pretrained CNN models were fine-tuned using a training dataset. The classifying performance of the models was evaluated using a test dataset and a prospective validation dataset.</P><P> Results A total of 5017 images were collected from 1269 patients, among which 812 images from 212 patients were used as the test dataset. An additional 200 images from 200 patients were collected and used for prospective validation. For the five-category classification, the weighted average accuracy of the Inception-Resnet-v2 model reached 84.6 %. The mean area under the curve (AUC) of the model for differentiating gastric cancer and neoplasm was 0.877 and 0.927, respectively. In prospective validation, the Inception-Resnet-v2 model showed lower performance compared with the endoscopist with the best performance (five-category accuracy 76.4 % vs. 87.6 %; cancer 76.0 % vs. 97.5 %; neoplasm 73.5 % vs. 96.5 %; P < 0.001). However, there was no statistical difference between the Inception-Resnet-v2 model and the endoscopist with the worst performance in the differentiation of gastric cancer (accuracy 76.0 % vs. 82.0 %) and neoplasm (AUC 0.776 vs. 0.865).</P><P> Conclusion The evaluated deep-learning models have the potential for clinical application in classifying gastric cancer or neoplasm on endoscopic white-light images.</P>"
Multipath-DenseNet: A Supervised ensemble architecture of densely connected convolutional networks,2019,"['Image classification', 'Neural network', 'Deep-learning']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>Deep networks with skip-connections such as ResNets have achieved great results in recent years. DenseNet exploits the ResNet skip-connections by connecting each layer in convolution neural network to all preceding layers and achieves state-of-the-art accuracy. It is well-known that deeper networks are more efficient and easier to train than shallow or wider networks. Despite the high performance of very deep networks, they are limited in terms of vanishing gradient, diminishing forward flow, and slower training time. In this paper, we propose to combine the benefits of the depth and width of networks. We train supervised independent shallow networks on the same input in a block fashion. We use a state-of-the-art DenseNet block to increase the number of paths for gradient flow. Our proposed architecture has several advantages over other deeper networks including DenseNet; our architecture which we call Multipath-DenseNet is deeper as well as wider, reduces training time, and uses a smaller number of parameters. We evaluate our proposed architecture on the following four object recognition datasets: CIFAR-10, CIFAR-100, SVHN, and ImageNet. The evaluation results show that Multipath-DenseNet achieves significant improvement in performance over DenseNet on the benchmark datasets.</P>"
심층 신경회로망들을 사용한 기흉 진단,2019,"['Convolutional Neural Networks', 'U-Net', 'EfficientNet', 'ResNetM', 'ask-RCNN', 'Xecption']","기흉은 가슴에 공기가 차는 것으로, 일반적으로 흉부 엑스레이를 사용하여 진단한다. 데이터 전처리를 하였고, 전처리방법으로는 결측값 제거 및 마스킹을 하였다. 최근에 와서 심층신경망의 성능이 개선됨에 따라서 활발히 사용되고 있고, 특히 영상인식에 적용되어 기존의 방법에 비하여 향상된 성능을 보이고 있다.기흉을 진단하는데 U-Net, Mask R-CNN, Resnet, EfficientNet, Xception을 사용하였으며, 이 심층 신경 회로망들의 성능을 비교하였다. U-Net은 Sementic Segmentation을사용하였고, Mask R-CNN은 Instance Segmentation을 사용하였다. Sementic Segmentation은 분할의 기본 단위를 클래스로하여, 동일한 클래스에 속하는 사물은 예측마스크 상에 동일한 색깔로 표시한다. Instance Segmentation은 분할의 기본단위를 사물로 하여, 동일한 클래스에 속하더 라도 다른 사물에 해당하면 예측 마스크 상에 다른 색깔로 표시한다. 실험 결과EfficientNet의 성능이 가장 좋았다. 이는 의사의 기흉 진단을 보조하기에 충분한 성능으로 의사를 도와 기흉을 진단하는데효율적으로 이용 될 수 있다.","A Pneumothorax is an abnormal collection of air in the space between lung and chest wall and is diagnosed using chest X-ray. Preprocessings, such as the eliminaton of missing value and masking, were performed. Performances of U-Net, Mask R-CNN, Resnet, EfficientNet and Xception for diagnosing pneumothorax are compared. U-Net uses semantic segmentation and Mask R-CNN uses instance segmentation. Semantic segmentation uses a class as the unit of segmentation. Therefore, objects in the same class are denoted using the same color on the prediction mask. On the other hand, instance segmentation uses object as the unit of segmentation. Therefore, objects in the same class are denoted using the different color on the prediction mask, if they belong to the different objects. EfficientNet got the best result. It can be efficiently used because it performs well enough to assist for physicians to diagnose pneumothorax using the chest X-ray"
C++ 기반 범용 오픈소스 딥러닝 프레임워크 WICWIU,2019,"['딥러닝', '신경망', '프레임워크', '오픈소스', 'WICWIU', 'deep learning', 'neural networks', 'framework', 'open source']","국내 대학으로는 최초로 공개한 오픈소스 딥러닝 프레임워크 WICWIU를 소개한다. WICWIU 는 다양한 연산자와 모듈, 그리고 일반적인 계산 그래프들을 표현할 수 있는 신경망 구조를 제공하여 Inception, ResNet, DenseNet 등 널리 사용되는 최신 딥러닝 모델들을 구성하기에 충분한 기능을 제공한다. 또한, GPU 기반 대규모 병렬 컴퓨팅을 지원해 빠른 학습이 가능하다. 모든 API가 C++로 제공되어 C++ 개발자들이 쉽게 적응할 수 있으며, C++환경에 기반하기 때문에 파이썬 기반의 프레임워크에 비해 메모리 및 성능 최적화에도 유리하다. 따라서, 프레임워크 자체를 자원이 제한된 환경에 맞도록 수정하기에도 용이하다. 일관성 높은 코드와 API로 구성되어 가독성과 확장성이 우수하며, 한국어 문서를 제공해 국내 개발자들이 쉽게 접근할 수 있다. WICWIU는 Apache 2.0 라이선스를 적용해 어떠한 연구 목적 및 상용 목적으로도 자유롭게 활용할 수 있다.","In this paper, we introduce WICWIU, the first open source deep learning framework among Korean universities. WICWIU provides a variety of operators and modules together with a network structure that can represent an arbitrary general computational graph. The WICWIU features are sufficient to compose widely used deep learning models such as Inception, ResNet, and DenseNet.WICWIU also supports GPU-based massive parallel computing which significantly accelerates the training of neural networks. It is also easily accessible for C++ developers because the whole API is provided in C++. WICWIU has an advantage over Python-based frameworks in memory and performance optimization based on the C++ environment. This eases the customizability of WICWIU for environments with limited resources. WICWIU is readable and extensible because it is composed of C++ codes coupled with consistent APIs. With Korean documentation, it is particularly suitable for Korean developers. WICWIU applies the Apache 2.0 license which is available for any research or commercial purposes for free."
합성곱 신경망(Convolutional Neural Network)을 활용한 지능형 유사상표 검색 모형 개발,2019,"['Deep Learning', 'Convolutional Neural Network', 'Trademark Retrieval System', 'Image retrieval Algorithm', '합성곱신경망', '딥 러닝', '상표 검색 시스템', '이미지 검색 알고리즘']","전 세계적으로 온라인 상거래 시장 규모가 성장함에 따라 국제 및 국내 기업의 상표권이 침해되는 사례가 빈번하게 발생하고 있다. 다양한 연구 및 보고서에 따르면, 해외 기업 또는 개인이 국내 기업의 상표권을 침해한 사례와, 국내 기업 간 발생하는 상표권 분쟁 사례가 증가하고 있는 것으로 나타나고 있으며, 특허청의 보고서에 따르면 기업의 규모가 작을수록 상표보호를 위한 사전 예방활동을 수행하지 않는다고 응답한 비율이 높은 것으로 나타났다. 이러한 문제는 선등록 상표에 대한 사전조사 또는 자사의 상표보호를위해 소요되는 인력과 비용이 원인인 것으로 판단된다.한편, 국내에서 선등록상표에 대한 사전조사를 위해 상용되는 서비스를 살펴보면 상표 이미지를 활용한검색 서비스를 제공하고 있지 않은 상황이다. 이로 인해 국내 대다수의 기업은 자사의 상표 보호 및 선등록 상표에 대한 사전조사 수행 시 방대한 양의 선등록된 상표를 수작업으로 조사해야하는 문제가 발생한다.따라서 본 연구에서는 기업의 상표권 보호 및 선등록 상표에 대한 사전조사 수행 시 투입되는 인력 및비용절감과, 국내외에서 발생하고 있는 상표권 침해 문제를 해결하기 위해 합성곱 신경망 기법을 활용한지능형 유사 상표 검색 모델을 개발하고자 한다. 지적 재산권 전문가가 선정한 테스트 데이터를 활용하여지능형 유사 상표 검색 모델의 정확도를 측정한 결과 ResNet V1 101의 성능이 가장 높게 나타났다. 해당결과를 통해 이미지 분류 알고리즘이 단순한 사물 인식 분야뿐만 아니라 이미지 검색 분야에서도 높은 성능을 나타낸다는 것을 실증적으로 입증했으며, 본 연구는 실제 상표 이미지 데이터를 활용했다는 측면에서실제 산업 환경에서 활용성이 높을 것으로 사료된다.","Recently, many companies improving their management performance by building a powerful brand value which is recognized for trademark rights. However, as growing up the size of online commerce market, the infringement of trademark rights is increasing. According to various studies and reports, cases of foreign and domestic companies infringing on their trademark rights are increased. As the manpower and the cost required for the protection of trademark are enormous, small and medium enterprises(SMEs) could not conduct preliminary investigations to protect their trademark rights.Besides, due to the trademark image search service does not exist, many domestic companies have a problem that investigating huge amounts of trademarks manually when conducting preliminary investigations to protect their rights of trademark.Therefore, we develop an intelligent similar trademark search model to reduce the manpower and cost for preliminary investigation. To measure the performance of the model which is developed in this study, test data selected by intellectual property experts was used, and the performance of ResNet V1 101 was the highest. The significance of this study is as follows. The experimental results empirically demonstrate that the image classification algorithm shows high performance not only object recognition but also image retrieval. Since the model that developed in this study was learned through actual trademark image data, it is expected that it can be applied in the real industrial environment."
Improving Model Performance for Urban Sound Classification With Model Ensembling,2019,"['Convolutional neuralnetworks', 'Raw waveforms', 'Environmental sound', 'Bootstrap aggregation']",국문 초록 정보 없음,"Recent work has demonstrated the end-to-end learning using a convolutional neural network (CNN) is sucessfully used in various kinds of deep learning tasks. Deep convolutional neural network (DCNNs) usually have high variance due to their high capacity and flexibility. Bootstrap aggregating (bagging) with CNN models has been widedly used in image classification for its effectiveness. CNN approach has been applied to audio signals, using 1- D convolutional layer that takes raw waveforms as input as well, but ensemble methods are not fully explored yet. In this paper, we improve the model performance for urban sound classification by adopting SENets, which is state-of-the-art CNN models usign bagging. Since SE blocks are sufficiently flexiblie to be used in CNN models, we apply SE blocks to advanced CNN architectures, residual networks (ResNet). The result show SENet and ensemble model with SENet and Resnet achieve significant improvements over previous state-of-the- art models in the Urban Sound 8k."
딥러닝(FCN) 기반 용접부 미세조직 분석에 대한 연구,2019,"['deep learning', 'fully convolutional network', 'ResNet', 'acicular ferrite', 'carbon steel', 'segmentation']",국문 초록 정보 없음,다국어 초록 정보 없음
Implementation Multi-Channel Video Analysis Based on Deep Learning Using GPU,2019,"['Multi-channel', 'Video surveillance', 'Object detection', 'Deep-learning', 'ResNet']",국문 초록 정보 없음,다국어 초록 정보 없음
Fast R-CNN을 이용한 객체 인식 기반의 도로 노면 파손 탐지 기법,2019,"['도로 노면 파손', '심층 신경망', '유지보수', '영역 기반 합성곱', '객체 인식', 'Road surface damage', 'Deep neural network', 'Road maintenance', 'Region based convolutional neural networks', 'Object recognition']",국문 초록 정보 없음,다국어 초록 정보 없음
심층신경망을 이용한 시간 영역 음향 이벤트 검출 알고리즘,2019,"['Sound Event Detection (SED)', 'Time-domain based DNN structure', 'ResGLU-SE', 'Data augmentation', 'pseudo-labeling']","본 논문에서는 심층신경망을 이용한 시간 영역 음향 이벤트 검출 알고리즘을 제시한다. 본 시스템에서는 주파수 영역으로 변환되지 않은 시간 영역의 음향 데이터를 심층신경망의 입력으로 사용한다. 전반적인 구조는 CRNN 구조를 사용하였으며, GLU, ResNet, Squeeze- and-excitation 블럭을 적용하였다. 그리고 여러 계층에서 추출된 특징을 함께 고려하는 구조를 제안하였다. 또한 본 연구에서는 강한 라벨이 있는 훈련 데이터를 확보하는 것이 현실적으로 어렵다는 전제 아래에서 약한 라벨이 있는 훈련 데이터 약간 그리고 다수의 라벨이 없는 훈련 데이터를 활용하여 훈련을 수행하였다. 적은 수의 훈련 데이터를 효과적으로 사용하기 위해 타임 스트레칭, 피치 변화, 동적 영역 압축, 블럭 혼합 등의 데이터 증강 방법을 적용하였다. 라벨이 없는 데이터에는 의사 라벨을 붙여 부족한 훈련 데이터를 보완하였다. 본 논문에서 제안한 신경망과 데이터 증강 방법을 사용하는 경우, 종래의 방식으로 CRNN 구조의 신경망을 훈련하여 사용하는 경우보다, 음향 이벤트 검출 성능이 약 6 % (f-score 기준)가 개선되었다.",다국어 초록 정보 없음
영상변형:얼굴 스케치와 사진간의 증명가능한 영상변형 네트워크,2019,[],국문 초록 정보 없음,"In this paper, we propose a verifiable image transformation networks to transform face sketch to photo and vice versa. Face sketch-photo is very popular in computer vision applications. It has been used in some specific official departments such as law enforcement and digital entertainment. There are several existing face sketch-photo synthesizing methods that use feed-forward convolution neural networks; however, it is hard to assure whether the results of the methods are well mapped by depending only on loss values or accuracy results alone. In our approach, we use two Resnet encoder-decoder networks as image transformation networks. One is for sketch-photo and another is for photo-sketch. They depend on each other to verify their output results during training. For example, using photo-sketch transformation networks to verify the photo result of sketch-photo by inputting the result to the photosketch transformation networks and find loss between the reversed transformed result with ground-truth sketch. Likely, we can verify the sketch result as well in a reverse way. Our networks contain two loss functions such as sketch-photo loss and photo-sketch loss for the basic transformation stages and the other two-loss functions such as sketch-photo verification loss and photo-sketch verification loss for the verification stages. Our experiment results on CUFS dataset achieve reasonable results compared with the state-of-the-art approaches."
신원 확인을 위한 멀티 태스크 네트워크,2019,"['Person reidentification', 'Verification loss', 'Identification loss']",국문 초록 정보 없음,"Because of the difference in network structure and loss function, Verification and identification models have their respective advantages and limitations for person reidentification (re-ID). In this work, we propose a multi-task network simultaneously computes the identification loss and verification loss for person reidentification. Given a pair of images as network input, the multi-task network simultaneously outputs the identities of the two images and whether the images belong to the same identity. In experiments, we analyze the major factors affect the accuracy of person reidentification. To address the occlusion problem and improve the generalization ability of re- ID models, we use the Random Erasing Augmentation (REA) method to preprocess the images. The method can be easily applied to different pre-trained networks, such as ResNet and VGG. The experimental results on the Market1501 datasets show significant and consistent improvements over the state-of-the-art methods."
The development of food image detection and recognition model of Korean food for mobile dietary management,2019,"['Food recognition', 'deep convolutional neural networks (DCNN)', 'mobile device', 'dietary assessment']",국문 초록 정보 없음,"BACKGROUND/OBJECTIVES: The aim of this study was to develop Korean food image detection and recognition model for use in mobile devices for accurate estimation of dietary intake.MATERIALS/METHODS: We collected food images by taking pictures or by searching web images and built an image dataset for use in training a complex recognition model for Korean food. Augmentation techniques were performed in order to increase the dataset size. The dataset for training contained more than 92,000 images categorized into 23 groups of Korean food.All images were down-sampled to a fixed resolution of 150 × 150 and then randomly divided into training and testing groups at a ratio of 3:1, resulting in 69,000 training images and 23,000 test images. We used a Deep Convolutional Neural Network (DCNN) for the complex recognition model and compared the results with those of other networks: AlexNet, GoogLeNet, Very Deep Convolutional Neural Network, VGG and ResNet, for large-scale image recognition.RESULTS: Our complex food recognition model, K-foodNet, had higher test accuracy (91.3%) and faster recognition time (0.4 ms) than those of the other networks.CONCLUSION: The results showed that K-foodNet achieved better performance in detecting and recognizing Korean food compared to other state-of-the-art models."
자율주행 자동차 환경에서의 3D-LiDAR 와 딥러닝을 이용한 클러스터링 후보군 기반 실시간 객체 검출,2019,"['autonomous vehicle', '3d-LiDAR', 'clustering', 'deep learning', 'object detection']",국문 초록 정보 없음,"Recently, IT companies such as Google, NVIDIA, and NAVER have been also developing autonomous vehicle platform technologies. In particular, sensors for object detection in surrounding environments have been improved in recognition rates by applying multi-sensor systems using camera, LiDAR, and radar. With the increasing importance of recognition technology, 3D information-based recognition technologies have been actively advanced as a commercial product of 3D-LiDAR. In this paper, a candidate group of point-clouds from 3D-LiDAR is extracted using Euclidean clustering in order to reduce the processing time delay in RPN (Region Proposal Network), which is one of the basic schemes for existing object detection. Then, it proposes types of input slicing, based on the extracted candidates. In addition, the accuracy and the processing time using four CNN networks (Basic CNN, ResNet, VGG16, and MobileNet) are compared over not only the private data (CVLab dataset) obtained in actual road environment but also the publicly open KITTI dataset."
The development of food image detection and recognition model of Korean food for mobile dietary management,2019,"['Food recognition', 'deep convolutional neural networks (DCNN)', 'mobile device', 'dietary assessment']",국문 초록 정보 없음,"BACKGROUND/OBJECTIVES: The aim of this study was to develop Korean food image detection and recognition model for use in mobile devices for accurate estimation of dietary intake. MATERIALS/METHODS: We collected food images by taking pictures or by searching web images and built an image dataset for use in training a complex recognition model for Korean food. Augmentation techniques were performed in order to increase the dataset size. The dataset for training contained more than 92,000 images categorized into 23 groups of Korean food. All images were down-sampled to a fixed resolution of $150{\times}150$ and then randomly divided into training and testing groups at a ratio of 3:1, resulting in 69,000 training images and 23,000 test images. We used a Deep Convolutional Neural Network (DCNN) for the complex recognition model and compared the results with those of other networks: AlexNet, GoogLeNet, Very Deep Convolutional Neural Network, VGG and ResNet, for large-scale image recognition. RESULTS: Our complex food recognition model, K-foodNet, had higher test accuracy (91.3%) and faster recognition time (0.4 ms) than those of the other networks. CONCLUSION: The results showed that K-foodNet achieved better performance in detecting and recognizing Korean food compared to other state-of-the-art models."
무인항공기 영상에서의 조류 및 차량 검출을 위한 딥러닝 기반 검출 모델 개발,2019,"['딥러닝', '야생조류', '무인항공기', '항공영상', '조류인플루 엔자']","야생동물에 대한 주기적인 모니터링은 생태계의 보전과 관리, 이상 징후의 포착에 필수적이다. 특히 한국의 경우 주기적으로 발생하고 있는 조류 인플루엔자의 예찰을 위해 야생조류에 대한 효과적 예찰 시스템이 요구되는 상황이다. 야생동물에 대한 항공영상 기반의 조사는 1920년대부터 수행되었으며 다른 조사방법들 대비 지상으로 접근하기 어려운 지점에 대한 접근이 가능한 점, 넓은 범위의 영역에 대한 조사가 가능한 점 등의 장점이 있다. 하지만 유인항공기를 이용하는 기존 연구의 경우 비용 소모가 크고, 숙련된 비행사가 필요하였으며, 비행사고로 인한 위험성 또한 존재했다. 이러한 단점을 극복하기 위하여 최근 야생동물에 대한 항공 조사에 소형 무인항공기를 적용하는 연구들이 활발히 진행되고 있다. 기존의 야생 조류에 대한 항공 조사의 경우 주로 사람이 직접 영상에서 새를 검출하거나, 고전적인 영상처리 방식이 사용되었다. 하지만 이러한 고전적 영상처리 및 머신러닝 방법들은 해당 방법들이 적용된 특정 환경에서 적용되었으며, 다양한 환경에서 일관성 있게 적용되기 힘들다. 최근 영상데이터에 대한 분류, 검출 등의 분석 작업에서는 CNN(Convolutional Neural Networks) 기반의 알고리즘들이 주목받고 있으나, 현재까지 야생조류의 검출에 이를 적용하려는 사례는 많지 않다. 따라서 본 연구에서는 야생조류의 서식지를 비롯한 조류독감 방역대의 항공 조사를 위한 딥러닝 기반 야생 조류와 차량에 대한 검출 모델을 개발하고자 하였다. 모델의 학습을 위해 실제 야생조류, 모형조류, 차량에 대한 영상을 다양한 환경에서 수집하여 데이터세트를 구성하였으며, Faster R-CNN, R-FCN, Retinanet, SSD, YOLO 등의 딥러닝 검출 구조와 Resnet, Inception, Mobilenet 등의 특징 추출 네트워크를 조합하여 검출 모델을 구성하고 성능을 비교 평가하였다.",다국어 초록 정보 없음
자율운항선박의 국제해상충돌예방규칙 준수를 위한 합성곱 신경망 기반의 선박 분류에 관한 연구,2019,"['자율운항선박', '선박 분류', '국제해상충돌예방규칙', '합성곱 신경망', 'Autonomous Ships', 'Vessel Classification', 'COLREGs', 'Convolutional Neural Networks']","최근 자율운항선박에 대한 관심이 증가하고 있으며, 바다를 항해하는 자율운항선박은 유인선과 같이 국제해상충돌방지규칙을 준수해야한다. 따라서 본 논문에서는 자율운항선박이 국제해상충돌예방규칙을 준수하기 위해서 필요한 선박 범주 및 합성곱 신경망 기반의 선박 분류 기술을 제안하였다. 먼저 국제해상충돌예방규칙을 분석하여 자율운항선박이 구별해야 되는 14개의 선박 범주를 정의하였다. 또한 본 논문에서 정의된 선박 범주에 맞도록 인터넷 영상검색 및 기존 데이터 셋 정제를 통하여 40,300장 규모의 선박 범주 분류 데이터 셋을 구축하였다. 마지막으로 최신 합성곱 신경망 모델을 구축된 선박 범주 분류 데이터 셋에 적용하여 선박 범주 분류 성능을 분석하였다. 실험결과 전이학습을 통하여 학습된 Inception-ResNet v2 모델은 14개 선박 범주를 91%의 높은 정확도로 분류함을 확인하였다.","The interest in autonomous ships for marine industries has increased significantly over the past few years and autonomous ships also must follow maritime laws in the same way as regular ships operated by crews. Therefore, in this paper, we propose the vessel taxonomy for COLREGs compliance of autonomous ships and evaluate the performance of the vessel classification method using CNNs. First, we define the vessel taxonomy for complying with maritime laws by analyzing the COLREGs. And then, we build our dataset separated manually by the vessel taxonomy. For the dataset, 40,300 images are collected by image search on websites and refining the publicly available dataset. Finally, the state-of-the-art CNN model is applied to evaluate the recognition rate of our dataset. The experimental results show that the Inception-ResNet v2 model which is trained by transfer learning effectively classifies the ships with a high accuracy of 91%."
