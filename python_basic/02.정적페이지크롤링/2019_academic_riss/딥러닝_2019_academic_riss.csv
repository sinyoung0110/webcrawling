title,date,keywords,abstract,multilingual_abstract
딥러닝 기술이 가지는 보안 문제점에 대한 분석,2019,"['인공지능', '기계학습', '딥러닝', '보안', '비즈니스모델', 'Convergence', 'AI', 'Machine Learning', 'Deep Learning', 'Security', 'Business Model']",본 논문에서는 딥러닝 기술이 인터넷과 연결된 다양한 비즈니스 분야에 새로운 형태의 비즈니스 업무에 활용할 수 있도록 보안에 관한 문제점을 분석하고자 한다. 우선 딥러닝이 비즈니스 영역에 보안 업무를 충분히 수행하기 위해서 는 많은 데이터를 가지고 반복적인 학습을 필요하게 된다. 본 논문에서 딥러닝이 안정적인 비즈니스 보안 업무를 완벽하 게 수행할 수 있는 학습적 능력을 얻기 위해서는 비정상 IP패킷에 대한 탐지 능력과 정상적인 소프트웨어와 악성코드를 탑재하여 감염 의도를 가지고 접근하는 공격을 탐지해낼 수 있는 인지 능력을 갖추고 있는지를 분석하였다. 이에 본 논문에서는 인공지능의 딥러닝 기술이 시스템에 접근하여 문제의 비즈니스 모델을 안정적으로 수행할 수 있게 하기 위해서는 시스템내의 비정상 데이터를 추출해 내고 시스템 데이터 침해를 구분해 낼 수 있는 수학적 역할의 문제점을 보완하기 위해 새로운 IP에 대한 세션 및 로그 분석을 수행할 수 있도록 보안 엔진이 탑재된 딥러닝 기술을 개발하여 비즈니스 모델에 적용시켜서 취약점을 제거하여 비즈니스 업무 능력을 향상시키도록 문제적 방안을 비교 분석하였다.,"In this paper, it will analyze security problems, so technology’s potential can apply to business security area. First, in order to deep learning do security tasks sufficiently in the business area, deep learning requires repetitive learning with large amounts of data. In this paper, to acquire learning ability to do stable business tasks, it must detect abnormal IP packets and attack such as normal software with malicious code. Therefore, this paper will analyze whether deep learning has the cognitive ability to detect various attack. In this paper, to deep learning to reach the system and reliably execute the business model which has problem, this paper will develop deep learning technology which is equipped with security engine to analyze new IP about Session and do log analysis and solve the problem of mathematical role which can extract abnormal data and distinguish infringement of system data. Then it will apply to business model to drop the vulnerability and improve the business performance."
딥러닝 모델 설계를 위한 모델 패턴 추출 및 시각화,2019,"['딥러닝 모델 설계', '딥러닝 모델 시각화', '딥러닝 모델 재사용', '빈발 패턴 마이닝', '부분 시퀀스 마이닝', 'Deep Learning Model Design', 'Deep Learning Model visualization', 'Deep Learning Model Reuse', 'Frequent Pattern Mining']","최근 공개되고 있는 딥러닝 모델의 계층구조는 복잡한 형태를 갖는 경향을 보인다. 이러한 딥러닝 모델의 계층구조는 한눈에 파악하기 힘들고 재사용하기 힘들다는 어려움이 있다. 따라서 이 논문에서는 딥러닝 모델의 재사용과 가시화를 위해 복잡한 구조의 딥러닝 모델로부터 반복되는 계층을 추출하고, 모듈화하는 방법을 제안한다. 제안한 방법은 딥러닝 모델을 그래프 구조로 표현하고, 패턴 추출 과정에서 부분 그래프 마이닝 기법과 부분 패턴 마이닝 기을 단계적으로 거쳐 반복되는 패턴을 추출한다. 추가적으로, GUI 기반 에디터를 구현하여 복잡한 딥러닝 모델의 구조를 추상화함으로써 모델의 계층구조를 단순하게 표현할 수 있을 뿐만 아니라 기존 딥러닝 모듈의 효율적인 재사용이 가능하도록 지원한다.","Recent deep learning models tend to have a complex architecture. But it is hard for developers to grasp such hierarchical structure of the deep learning models and it is also difficult to reuse existing deep learning models. To solve these problems, we propose a method of extracting and modularizing repeated layers from a deep learning model for model reuse and visualization. Each repeating pattern is extracted by subgraph mining and frequent pattern mining. We also propose the GUI based editor which not only displays more simplified structure by abstract of original structure but also provides deep learning model reuse."
불꽃 감지를 위한 임베디드 시스템에 적합한 딥러닝 구조,2019,"['embedded system', 'deep learning structure', 'resource occupancy rate', 'flame detection time', 'flame detection rate']","본 논문에서는 불꽃 감지를 위한 임베디드 시스템에 적합한 딥러닝 구조를 제안한다. 제안하는 딥러닝 구조의 불꽃 감지과정은 불꽃 색깔 모델을 사용한 불꽃 영역 검출, 불꽃 색깔 특화 딥러닝 구조를 사용한 불꽃 영상 분류, 검출된 불꽃 영역의 ×  셀 분리, 불꽃 모양 특화 딥러닝 구조를 사용한 불꽃 영상 분류 등의 4가지 과정으로 구성된다. 첫 번째로 입력 영상에서 불꽃의 색만을 추출한 다음 레이블링하여 불꽃 영역을 검출한다. 두 번째로 검출된 불꽃 영역을 불꽃 색깔에 특화 학습된 딥러닝 구조의 입력으로 넣고, 출력단의 불꽃 클래스 확률이 75% 이상에서만 불꽃 영상으로 분류한다. 세 번째로 앞 단에서 75% 미만 불꽃 영상으로 분류된 영상들의 검출된 불꽃 영역을  ×  단위로 분할한다. 네 번째로  × 단위로 분할된작은 셀들을 불꽃의 모양에 특화 학습된 딥러닝 구조의 입력으로 넣고, 각 셀의 불꽃 여부를 판단하여 50% 이상의 셀들이불꽃 영상으로 분류될 경우에 불꽃 영상으로 분류한다. 제안된 딥러닝 구조의 성능을 평가하기 위하여 ImageNet의 불꽃 데이터베이스를 사용하여 실험하였다. 실험 결과, 제안하는 딥러닝 구조는 기존의 딥러닝 구조보다 평균 29.86% 낮은 리소스점유율과 8초 빠른 불꽃 감지 시간을 나타내었다. 불꽃 검출률은 기존의 딥러닝 구조와 비교하여 평균 0.95% 낮은 결과를나타내었으나, 이는 임베디드 시스템에 적용하기 위해 딥러닝 구조를 가볍게 구성한데서 나온 결과이다. 따라서 본 논문에서제안하는 불꽃 감지를 위한 딥러닝 구조는 임베디드 시스템 적용에 적합함이 입증되었다.","In this paper, we propose a deep learning structure suitable for embedded system. The flame detection process of theproposed deep learning structure consists of four steps：flame area detection using flame color model, flame imageclassification using deep learning structure for flame color specialization,  × cell separation in detected flame area, flameimage classification using deep learning structure for flame shape specialization. First, only the color of the flame isextracted from the input image and then labeled to detect the flame area. Second, area of flame detected is the input ofa deep learning structure specialized in flame color and is classified as flame image only if the probability of flame classat the output is greater than 75%. Third, divide the detected flame region of the images classified as flame images lessthan 75% in the preceding section into  × units. Fourthly, small cells divided into  × units are inserted into theinput of a deep learning structure specialized to the shape of the flame and each cell is judged to be flame proof andclassified as flame images if more than 50% of cells are classified as flame images. To verify the effectiveness of theproposed deep learning structure, we experimented with a flame database of ImageNet. Experimental results show that theproposed deep learning structure has an average resource occupancy rate of 29.86% and an 8 second fast flame detectiontime. The flame detection rate averaged 0.95% lower compared to the existing deep learning structure, but this was theresult of light construction of the deep learning structure for application to embedded systems. Therefore, the deep learningstructure for flame detection proposed in this paper has been proved suitable for the application of embedded system."
딥러닝 신경망을 이용한 신용카드 부도위험 예측의 효용성 분석,2019,"['딥러닝', '인공신경망', '신용카드', '부도위험', '머신러닝', 'Deep Learning', 'Artificial Neural Network', 'Credit Card', 'Default Risk', 'Machine Learning']","본 연구는 국내․외 금융시장에서 아직 활성화되지 못한 딥러닝 신경망(deep learning neural network) 알고리즘을 이용해 신용카드 부도위험 예측의 정확도 향상 가능성에 대해서 점검한다. 이를 위해 기존 머신러닝 알고리즘(Logistic, SVM, Random Forest, Lasso 등)을 딥러닝 신경망 분석의 성능 점검을 위한 비교 지표로 활용한다. 우선, 딥러닝 신경망은 두 개의 은닉층(hidden layers)과 다섯 개의 뉴런(neuron)으로 구축하고, 활성함수(activation function)와 초기값(initial value) 설정방법에 따른 예측정확도를 도출한다. 그 결과 딥러닝 신경망 분석이 기존 머신러닝 알고리즘 보다 최소 0.6%p에서 최대 6.6%p 성능이 향상된 것으로 나타났다. 이 중 가장 높은 예측 정확도를 보인 활성함수와 초기값 설정방식은 ReLU(rectified linear units)와 Xavier(2010)이고 이를 기준으로 은닉층과 뉴런의 수를 각각 최대 10개와 25개까지 늘려 분석한 결과에서도 유사한 결과가 나타났다. 다만, 기존 연구에서와 같이 은닉층과 뉴런의 수의 증가에 따른 뚜렷한 성능의 향상은 나타나지 않았다. 또한, 이미지 식별 분야에서 높은 성능을 보였던 Dropout과 CNN(convolution neural network) 모델도 예측 정확도에서 큰 차이를 보이지 않았다. 이는 여기에서 사용된 신용카드 데이터가 다수 픽셀(pixel)로 이루어진 이미지 데이터와 비교해 양적․질적 한계가 있기 때문으로 판단된다. 한편, 본 연구에서 사용된 개인의 신용카드 부도 데이터는 횡단면 자료이기 때문에 시계열 데이터에서 높은 성능을 나타내는 RNN(recurrent neural network) 및 LSTM(Long- Short Term Memory) 등의 딥러닝 신경망 알고리즘을 사용하지는 않았다. 따라서 추후 시계열 자료가 포함된 빅데이터를 통해 이들 딥러닝 신경망 방법론을 적용한다면, 현재의 다양한 금융시장의 식별문제(신용등급, 연체율, 금리산정)에 있어 보다 향상된 결과를 도출할 수 있을 것으로 기대된다.","This study aims to discuss the usefulness of the deep learning neural network and the possibility of the deep learning neural network analysis in judging credit information by using credit card default data. Deep learning neural network analysis in the financial sector excluding the current stock price prediction model is under limited research. It is mainly used for upgrading models of the credit rating (Kvamme et al., 2016, 2018; Tran, 2016; Luo, 2017) and the delinquency rate (Sirignano et al., 2018).In the credit card market, it is focused on credit card issuance and fraud detection model (Ramanathan, 2014, Niimi, 2015). As mentioned earlier, there has not been much analysis of deep learning neural network using financial market data. This is because the study of deep learning neural networks is actively carried out mainly in the field of computer science such as image, speech recognition, natural language processing. Additionally, Researchers in the financial sector have difficulty learning deep learning algorithms and setting up a computer runtime environment. It is also difficult to apply the algorithm to financial data due to lower dimension than the image. Nowadays, financial companies have been interested in machine learning and are increasing their recruitment, but it is still in the stage of verifying the possibility of deep learning neural network.Therefore, This study examines the possibility of improving the accuracy of credit card default risk prediction by using a deep learning neural network algorithm. To do this, we use existing machine learning algorithms (Logistic, SVM, Random Forest, Lasso, etc.) as a comparison index for performance check of deep learning neural network analysis. Firstly, the deep learning neural network is constructed with two hidden layers and five neurons, and derives the prediction accuracy according to the activation function and the initial value setting method. There are Sigmoid, ReLU, tanh and Maxout as active functions, and random value, Xavier, RBM, He’s as initialization methods. Based on this, we compare the accuracy of existing machine learning algorithms. As a result, the deep learning neural network analysis showed performance improvement between 0.6% and 6.6%p compared to the existing machine learning algorithms (Logistic, SVM, Random Forest, Lasso, etc.). Among these results, the active function and the initial value setting method with the highest prediction accuracy are ReLU (rectified linear units) and Xavier initialization. However, there is no significant improvement in performance with increasing number of hidden layers and neurons up to 10 and 25, respectively. Also, the dropout and CNN (convolution neural network) models, which showed high performance in the field of image identification, showed no significant difference in prediction accuracy.Nevertheless, it could be interpreted that the increase of hidden layers can improve the accuracy of estimation because the highest accuracy (0.8161) and the AUC (0.7726) are observed for 10 hidden nodes and 15 neurons.However, we can’t say that accuracy increases linearly by the number of hidden layers and neurons. These limitation could be due to the quantitative and qualitative limitations of the credit card data used here. We did not use recurrent neural network (RNN) and long-short term memory (LSTM) models since the personal default data for credit card used in this study is cross-sectional data. These method are for Time-Series data. Therefore, it is expected that it will be able to obtain better results in identification problems (credit rating, delinquency rate, interest rate calculation) of present various financial markets if these deep learning neural network methodologies are applied through big data including time series data.This study can be turned into a question of how deep learning analysis can lower the default risk and delinquency rate by using financial data from a practical point of ..."
스트리밍 서버를 이용한 AWS 기반의 딥러닝 플랫폼 구현과 성능 비교 실험,2019,"['AWS', 'Cloud Computing Service', 'Deep Learning', 'Streaming server', 'YOLO']","본 논문에서는 로컬 PC의 성능이 주는 영향이 적은 딥러닝 동작 구조를 구현하였다. 일반적으로, 딥러닝 모델은 많은 연산량을 가지고 있어 처리하는 PC의 성능에 영향을 많이 받는다. 본 논문에서는 이와 같은 제약 사항을 줄이기 위하여 AWS와 스트리밍 서버를 이용하여 딥러닝 동작을 구현하였다. 첫 번째, AWS에서 딥러닝 연산을 하여 로컬 PC의 성능이 떨어지더라도 딥러닝 동작이 정상적으로 작동할 수 있도록 하였다. 하지만 AWS를 통해 연산 시 입력에 대해 출력의 실시간성이 떨어진다. 두 번째, 스트리밍 서버를 이용하여 딥러닝 모델의 실시간성을 증가시킨다. 스트리밍 서버를 사용하지 않았을 경우 한 이미지씩 처리하거나 이미지를 쌓아서 동영상으로 만들어 처리하여야 하기 때문에 실시간 성이 떨어진다. 성능 비교 실험을 위한 딥러닝 모델로는 YOLO v3모델을 사용하였고, AWS의 인스턴스들 및 고성능 GPU인 GTX1080을 탑재한 로컬 PC의 성능을 비교하였다. 시뮬레이션 결과 AWS의 인스턴스인 p3 인스턴스를 사용하였을 때 한 이미지 당 테스트 시간이 0.023444초로써 고성능 GPU인 GTX1080을 탑재한 로컬 PC의 한 이미지 당 테스트 시간인 0.027099초와 유사하다는 결과를 얻었다.","In this paper, we implemented a deep learning operation structure with less influence of local PC performance. In general, the deep learning model has a large amount of computation and is heavily influenced by the performance of the processing PC. In this paper, we implemented deep learning operation using AWS and streaming server to reduce this limitation. First, deep learning operations were performed on AWS so that deep learning operation would work even if the performance of the local PC decreased. However, with AWS, the output is less real-time relative to the input when computed. Second, we use streaming server to increase the real-time of deep learning model. If the streaming server is not used, the real-time performance is poor because the images must be processed one by one or by stacking the images. We used the YOLO v3 model as a deep learning model for performance comparison experiments, and compared the performance of local PCs with instances of AWS and GTX1080, a high-performance GPU. The simulation results show that the test time per image is 0.023444 seconds when using the p3 instance of AWS, which is similar to the test time per image of 0.027099 seconds on a local PC with the high-performance GPU GTX1080."
딥러닝을 이용한 화강암 X-ray CT 영상에서의 균열 검출에 관한 연구,2019,"['Granite', 'Deep learning', 'Crack detection', 'Image augmentation', '화강암', 'X-ray CT', '딥러닝', '균열추출', '영상 데이터 증대 기술']","본 연구에서는 화강암 시편에서 수압 파쇄법에 의해 생성된 미세균열의 3차원 형상을 X-ray CT 영상과 딥러닝을 이용하여 추출하였다. 실험으로 생성된 미세균열은 X-ray CT 영상 상에서 일반적인 영상처리 방법으로는 추출하기 매우 어렵고 육안으로만 관찰이 가능한 형태를 지닌다. 하지만 본 연구에서 제안한 합성곱 신경망(Convolutional neural network) 기반 인코더-디코더(Encoder-Decoder) 구조의 딥러닝 모델을 통해 미세균열을 정량적으로 추출할 수 있었다. 특히 픽셀 단위의 미세균열 추출을 위해 인코딩 과정에서 소실되는 정보를 디코딩 과정으로 직접 전달하는 디코더 모델을 제안하였다. 또한, 딥러닝 기반 신경망 학습에 필요한 데이터의 수를 증가시키기 위해 이미지의 분할(Division), 회전(Rotation), 그리고 반전(Flipping) 등으로 데이터를 생성하는 영상 증대 방법을 적용하였으며 이때 최적의 조합을 확인하였다. 최적의 영상 학습 데이터 증대 방법을 적용하였을 때 검증 데이터뿐만 아니라 테스트 데이터에서의 성능 향상을 확인하였다. 학습 데이터의 원본 개수가 딥러닝 기반 신경망의 균열 추출 성능에 미치는 영향을 확인하고 딥러닝 기술을 사용하여 성공적으로 미세균열을 추출하였다.","This study aims to extract a 3D image of micro-cracks generated by hydraulic fracturing tests, using the deep learning method and X-ray computed tomography images. The pixel-level cracks are difficult to be detected via conventional image processing methods, such as global thresholding, canny edge detection, and the region growing method. Thus, the convolutional neural network-based encoder-decoder network is adapted to extract and analyze the micro-crack quantitatively. The number of training data can be acquired by dividing, rotating, and flipping images and the optimum combination for the image augmentation method is verified. Application of the optimal image augmentation method shows enhanced performance for not only the validation dataset but also the test dataset. In addition, the influence of the original number of training data to the performance of the deep learning-based neural network is confirmed, and it leads to succeed the pixel-level crack detection."
딥러닝 알고리즘 기반기술의 스마트 정보 활성화 방안에 관한 연구,2019,"['4차 산업혁명', '딥러닝 알고리즘', '기반기술', '스마트 정보', '4th Industrial Revolution', 'Deep Learning Algorithm', 'Infrastructure', 'Smart Information']","4차 산업혁명은 컴퓨터의 인공지능을 높일 수 있는 딥러닝 알고리즘을 개발하여 사용하고 있으며, 심층신경망 구현을 위해 인간 두뇌의 연결성을 모방하여 데이터 세트를 분류하고 데이터 간의 상관관계를 찾게된다. 딥러닝 알고리즘 활용의 인공지능 기술은 스스로 자기가 학습할 수 있는 능력을 갖추는 기술이 핵심이며, 인공지능과 사물센서 기술이 융합된 마지막 산업혁명이다.그동안 단편적인 기술 적용으로 성장해왔던 제조업이 새로운 성장 패러다임으로 바뀌고 있으며, 최첨단기술들이 계속 발전되어 상품화 되고 있다. 그러므로 사용자가 원하는 조건의 딥러닝 알고리즘 기반의 사물인식 모델 및 하이퍼 파라미터를 통계에 기반하여 자동으로 선정할 수 있는 플랫폼 등이 개발되어야 한다.본 연구는 딥러닝 알고리즘의 기술적 방향의 제시보다는 실무적 관점에서 살펴본 후, 향후의 해석적 기초를제시하고자 한다.","The 4th Industrial Revolution has developed a deep learning algorithm that can enhance the artificial intelligence of computers and for the implementation of the neural network, we classify the data sets by mimicking the connectivity of the human brain and find the correlation between the data. The technology that has the ability to learn on its own is the core of artificial intelligence technology that utilizes the deep learning algorithm and it is the last industrial revolution that combines artificial intelligence and object sensor technology.Manufacturing which has grown from application of fragmentary technology is changing to a new growth paradigm and State-of-the-art technologies are being developed and commercialized. Therefore it is necessary to develop platform that can automatically select an object recognition model and hyper parameters on the deep learning algorithm of the user's desired condition based on statistics. The purpose of this study is to present the analytical foundation of the deep learning algorithm from the practical point of view rather than presenting the technical direction of the deep learning algorithm."
증강현실⋅딥러닝 기반 교육용 어플리케이션 개발 연구 -(중⋅고등학교) 문제지 답안 및 해설서비스 어플리케이션 개발중심으로-,2019,"['AR(증강현실)', 'Deep Learning (딥러닝)', 'Immersion(몰입감)', 'Learning Services Applications(학습서비스 어플리케이션) Object Detection (개체탐지)', 'Image Segmentation (이미지 분할)', 'Convergence Service (융합서비스)']","증강현실은 이미지나 배경에 3차원 가상이미지를겹쳐서 하나의 영상으로 보여주는 기술로 스마트폰보급 확대, 디바이스의 진화 등 ICT기술의 발전과 페이스북, 구글, MS, 애플 등 세계적인 IT기업의 투자를 배경으로 급성장 하고 있다. 이러한 새로운 성장동력으로 주목 받고 있는 증강현실 산업의 다양한 확장 영역 중 교육 분야 응용현황을 분석하면 현재 국내 영유아를 비롯한 초등학교 교육 분야에서의 증강현실 응용이 지배적이다. 이러한 현황에 비추어 본 결과 본 연구는 중고등학생들의 학습에 있어 다양한 매체를 통한 학습서비스의 필요성을 제시하며 증강현실기술을 기반 한 학습지 문제해설 어플리케이션을 개발하여 학습자에게 학습에 대한 상세한 도움을 실시간으로 주고자 하는데 그 연구목적이 있다. 연구를 진행하기 위해 우선적으로 기반기술인 증강현실 기술의특성과 문제인식 및 답안해설 추출을 위한 딥러닝 기술을 분석하고 딥러닝 관련기술 Object Detection 및Image Segmentation 의 이미지 처리기술에서의 여러장의 연속된 이미지를 실시간으로 처리하는 기술의체계를 분석하여 학습지에서의 문제인식 및 답안 해설 자동 추출 시스템을 구성하였다. 연구 방법으로 이론적 배경에 대한 분석을 위해 증강현실 기술과 딥러닝 기술에 관한 국내외 논문을 선행연구 하였으며 증강현실 교육용 어플리케이션 현황분석을 위해 구글, 네이버에 등록된 증강현실 기반 교육서비스를 분석하였다. 그 결과 현재 국내외 논문과 연구에서 증명된증강현실 기반 학습 환경에서의 학습자의 현존감, 학습 몰입감과 사용성이 높은 장점에 비해 영유아와 아동의 학습서비스에 치중되어 다양한 연령층의 학습서비스가 이루어지지 않음을 알 수 있었다. 모바일 기기와 디지털기술 기반 한 어플리케이션 사용량이 가장큰 연령층임에도(청소년) 불구하고 그들의 눈높이 맞는 학습서비스 콘텐츠의 부재, 모바일 기술에서의 증강현실 기반기술 탑재부재와 환경속도에 따른 기술적한계에 의해 교육활용 어플리케이션이 개발되어 활용되고 있지 않은 실정이다.학습서비스의 활용부재의 무엇보다 중요한 이유는중고등학생들의 실질적인 학습서비스에 대한 교육 킬러콘텐츠의 부재가 가장 크다고 보여진다.본 연구는 이러한 청소년층을 위한 실감 형 교육콘텐츠의 활용을 높이고 다양하고 직접적인 학습서비스를 개발하여 자기주도교육에 있어 도움을 주고자 증강현실 기반 학습설명서 어플리케이션을 개발하여 교육 분야에서의 증강현실 활성화뿐 아니라 딥러닝 기술과의 융합서비스를 개발하여 앞으로 다가올 교육서비스의 선두적인 방향과 그 해결방안을 제시하고자한다.","Augmented reality is a technology that overlaps three-dimensional virtual images with images or backgrounds and shows them in a single image, and is rapidly growing against the backdrop of the development of ICT technologies, including the expansion of the spread of smartphones and evolution of devices, as well as investments by global IT companies such as Facebook, Google, Microsoft and Apple. Analysis of the application status of the education sector among various areas of expansion of the augmented reality industry, which is drawing attention as a new growth engine, currently dominates augmented reality applications in elementary school education areas, including infants and children in Korea.In light of this situation, this research is aimed at providing real-time assistance to learners by developing a problem-solving application for learning paper based on augmented reality technology. In order to carry out the research, we analyzed the characteristics of the augmented reality technology and the deep learning technology for problem recognition and solution analysis, and analyzed the system of the technology to process multiple consecutive images in image processing technology of deep learning related technology Object Detection and Image Segmentation in real time, forming an automatic problem recognition and answer description extraction system in the study paper. In order to analyze the theoretical background with the research method, domestic and foreign papers on augmented reality technology and deep learning technology were researched in advance, and augmented reality-based education services registered with Google and Naver were analyzed for analysis of current status of augmented reality education applications. As a result, it was shown that the learning service of infants and children does not take place in various age groups as the learning service is concentrated on the learning service of the learner in an augmented reality-based learning environment as demonstrated in the present domestic and international papers and research. Despite the fact that mobile devices and digital technologybased applications are among the largest age groups (teenagers), educational applications are not being developed and utilized due to the lack of learning service content that suits their eye, the lack of components equipped with augmented reality-based technologies in mobile technology and the technological limits according to environmental speed.The most important reason for the lack of use of learning services is the lack of educational killer content on practical learning services for middle and high school students. In order to enhance the utilization of realistic educational contents for these young adults and help them in self-direct education by developing diverse learning services, this study aims to develop an augmented reality-based learning manual application and develop a convergence service with deep learning technology to present the leading direction of education services and their solutions."
딥러닝을 이용한 WTCI 설태량 평가를 위한 유효성 검증,2019,"['설진', 'WTCI', '설태량', '딥러닝', '콘볼루션 뉴럴 네트워크', 'Tongue Diagnosis', 'WTCI', 'the amount of Tongue Coating', 'Deep Learning', 'Convolutional Neural Network']","한방 설진에서 WTCI(Winkel Tongue Coating Index) 설태 평가는 환자의 설태량 측정을 위한 중요한 객관적인 지표 중의 하나이다. 그러나 이전의 WTCI 설태 평가는 혀영상으로부터 설태 부분을 추출하여 전체 혀 영역에서 추출된 설태 영역의 비율을 정량적으로 측정하는 방법이 대부분으로 혀영상의 촬영 조건이나 설태 인식 성능에 의해서 비객관적 측정의 문제점이 있었다. 따라서 본 논문에서는 빅데이터를 기반으로 하는 인공지능의 딥러닝 방법을 적용하여 설태량을 분류하여 평가하는 딥러닝 기반의 WTCI 평가 방법을 제안하고 검증한다. 설태 평가 방법에 있어서 딥러닝의 유효성 검증을 위해서는 CNN을 학습 모델로 사용하여 소태, 박태, 후태의 3가지 유형의 설태량을 분류한다. 설태 샘플 영상을 학습 및 검증 데이터로 구축하여 CNN 기반의 딥러닝 모델로 학습한 결과 96.7%의 설태량 분류 정확성을 보였다.","A WTCI is an important criteria for evaluating an mount of patient’s tongue coating in tongue diagnosis. However, Previous WTCI tongue coating evaluation methods is a most of quantitatively measuring ration of the extracted tongue coating region and tongue body region, which has a non-objective measurement problem occurring by exposure conditions of tongue image or the recognition performance of tongue coating. Therefore, a WTCI based on deep learning is proposed for classifying an amount of tonger coating in this paper. This is applying the AI deep learning method using big data. to WTCI for evaluating an amount of tonger coating. In order to verify the effectiveness performance of the deep learning in tongue coating evaluating method, we classify the 3 types class(no coating, some coating, intense coating) of an amount of tongue coating by using CNN model. As a results by testing a building the tongue coating sample images for learning and verification of CNN model, proposed method is showed 96.7% with respect to the accuracy of classifying an amount of tongue coating."
딥러닝 영상처리를 통한 비탈면의 지반 특성화 영역 자동 분류에 관한 연구,2019,"['Instance segmentation', 'Deep learning', 'Slope failure image', 'Ground characteristics of Slope', '딥러닝', '비탈면 붕괴영상', '비탈면 지반특성']","비탈면의 붕괴로 인해 재산피해뿐만 아니라 인명피해 또한 발생할 수 있으므로 안정성 평가를 통해 비탈면의 붕괴여부 예측 및 보강을 진행해야 한다. 본 논문은 비탈면 영상에서 암반 절리군, 암반 단층, 토양, 비탈면 누수영역 등 비탈면 붕괴와 관련하여 특성화 시킬 수 있는 지반 영역들을 정의하고 이를 딥러닝 기법을 통해 자동으로 분류해 낼 수 있는 방법에 대해 고찰하였다. 이에 따라 딥러닝 객체 영역분할(Instance segmentation) 네트워크를 활용하여 영상에 보여지는 다른 특성을 갖는 지반영역의 정확한 형상을 인식하고 자동 분할 할 수 있음을 보였으며, 향후 비탈면 안정성 평가를 위해 시행되는 비탈면 매핑 작업을 지원하고, 비탈면 보강 대책 등 의사결정에 필요한 비탈면의 지반특성 정보를 자동으로 산출할 수 있는 가능성을 보였다.","Because of the slope failure, not only property damage but also human damage can occur, slope stability analysis should be conducted to predict and reinforce of the slope. This paper, defines the ground areas that can be characterized in terms of slope failure such as Rockmass jointset, Rockmass fault, Soil, Leakage water and Crush zone in sloped images. As a result, it was shown that the deep learning instance segmentation network can be used to recognize and automatically segment the precise shape of the ground region with different characteristics shown in the image. It showed the possibility of supporting the slope mapping work and automatically calculating the ground characteristics information of slopes necessary for decision making such as slope reinforcement."
딥러닝의 변수 중요도를 이용한 인공지능 기술 분석,2019,"['딥러닝', '변수중요도', '기술분석', '선형회귀분석', '인공지능', '특허데이터', 'Deep learning', 'Variable importance', 'Technology analysis', 'Linear regression analysis', 'Artificial intelligence', 'Patent data']",인공지능 기술은 빠른 속도로 발전하고 있다. 특히 인공지능 개발을 이끌고 있는 많은 세부기술 간의 관계를 파악하는 것은 인공지능 기술을 이해하는데 중요하다. 본 연구에서는 이와 같은 인공지능의 기술 분석을 위하여 딥러닝을 적용한다. 최근 전통적인 통계학 및 머신러닝 기법에 비해 딥러닝의 예측 성능이 더 우수함을 보여주는 다양한 연구결과가 발표되고 있다. 하지만 최종 예측과 함께 예측에 사용된 입력변수들의 상대적인 중요도를 파악하는 것은 기존의 통계적 기법에 비해 딥러닝이 가지고 있는 어려움 중 하나이다. 예측모형에서 입력변수가 출력변수에 어떤 형태로 영향을 주는지 확인하려는 연구는 여러 분야에서 이루어지고 있다. 선형회귀분석은 입력변수의 중요도를 확인하기 위하여 표준화 회귀계수를 이용한다. 본 논문에서는 가중치 분석을 통하여 딥러닝의 입력변수 중요도를 계산하여 인공지능 기술에 영향을 미치는 세부기술에 대한 기술 분석을 수행한다. 제안 방법의 타당성을 보이기 위하여 인공지능 기술관련 특허문서를 수집하고 분석하여 인공지능 세부기술간 기술 연관성을 확인한다.,"Artificial intelligence (AI) technology has been developed at a fast pace. In particular, understanding the relationship between various sub technologies leading to AI development is very important to understand AI. In this study, we use deep learning to analyze AI technology. Many studies have been published showing the prediction performance of deep running is superior to the conventional statistical and machine learning methods. However, understanding the relative importance of input variables used in the prediction of output variable is one of the difficulties of deep learning compared to the existing statistical methods. There are many studies in various fields to find out how the input variable affects the output variable in forecasting. For example, linear regression analysis uses standardized coefficients to determine the variable importance. This paper performs technology analysis on the sub technologies that influence AI technology using the variable importance of deep learning. To show the validity of the proposed methodology, we collect and analyze patent documents related to AI technology."
딥러닝을 통한 이미지의 인식론 - 창발성의 비주얼 커뮤니케이션,2019,"['이미지 인식론', '딥러닝', '비주얼 커뮤니케이션', '미적 경험', '인식론적 창발성', 'Image Epistemology', 'Deep Learning', 'Visual Communication', 'Aesthetic  Experience', 'Epistemological Emergent Properties']","이 연구는 ‘인공지능과 빅데이터를 통한 이미지의 존재론과 창발성’이라는 본인의 선행 연구를 잇는다. 이전 연구에서는 ‘인공지능과 빅데이터를 통해 생산한 이미지’와 ‘예술 작품의 이미지’를 ‘이미지 생산 주 체’의 문제와 ‘생산된 이미지의 존재론’의 관점에서 비교, 연구했다. 전자가 현재까지는 예술이 아니지만, 예술이 될 가능성을, 양자가 공유하는 ‘예측 블가능성’을 키워드로 삼아, 이미지 존재론의 관점에서 제시 했다. ‘예측 불가능성’이 ‘인식론적 창발성’의 주요 특징이라는 점에서, 본 연구는 이미지 존재론에 관한 선행 연구를 인식론의 관점으로 확장하는 창발성의 비주얼 커뮤니케이션을 연구하기 위해 다음처럼 논문 을 구성한다. 구체적으로 2장에서는 ‘인식론의 이미지 인식’을 인식 주체인 인간과 대상인 이미지 사이에 상호 작용하는 입장으로 전개된 것으로 고찰한다. 3장에서는 ‘인지과학의 이미지 인식’을 ‘이미지 인지’ 의 차원에서 실행함으로써 인간 지능에 기능해 온 것으로 살펴본다. 4장에서는 ‘딥러닝의 이미지 인식’을 인공지능이 비지도학습이라는 자가 감독 학습을 실행함으로써 이미지의 외피적 판별에만 국한되는 것이 아닌 이미지가 내포한 의미론까지 파악하는 것으로 살펴본다. 마지막 6장에서는 ‘딥러닝을 통한 시각예 술의 이미지 인식’을 딥러닝을 실험하는 3인(팀)의 미술가들(하름 판 덴 도르펠, 레이체 아라, 포렌식 아 키텍처)이 발표한 실제의 작품을 분석하면서 살펴본다. 본 연구는 최근 인공지능이 생산하는 이미지에 대한 미적 경험과 의미 나아가 예술적 해석의 관계를 탐구하는데 기여할 것이다.","This study connects with my previous research, 'Image Ontology and Emergence Properties through AI and Big Data'. In that work, I compared an 'image produced through artificial intelligence and big data' with an 'image of visual artwork' from the viewpoint of 'subject of image production' and the 'ontology of the produced image'. Although the former is not considered art thus far, the possibility of it becoming art is presented from the viewpoint of image ontology using the keyword 'unpredictability', which exists on both sides. 'Unpredictability' is a key feature of 'epistemic emergence'. In this regard, this study proceeds as follows to study the visual communication of Emergent Properties that extend earlier work on image ontology to the perspective of epistemology. Specifically, in Chapter 2 we consider that the 'image recognition of epistemology' has developed into a position of interaction between humans as subjects of recognition and images as objects of recognition. In Chapter 3, we examine how the 'image recognition of cognitive science' has functioned in human intelligence through the concept of 'image cognition'. In Chapter 4, 'image recognition in early machine learning' is examined by considering images that are grasped by supervised learning. In Chapter 5, we examine 'image recognition of deep learning' as artificial intelligence learns self-supervised learning through unsupervised learning to understand the semantics implied by an image rather than being limited to external classifications of images. In the last chapter, chapter 6,""Realization of Visual Art through Deep Learning,"" an actual work of three artists (team members) who are experimenting with deep running (Ham vanden Dorpel, Rachel Ara, and Forensic Architecture), is analyzed. This study will contribute to explorations of the relationship between the aesthetic experience of artificial intelligence produced by artificial intelligence and meaning and artistic interpretation."
영상기반 딥러닝 및 이미지 프로세싱 기법을 이용한 볼트풀림 손상 검출,2019,"['bolt-loosening detection', 'vision', 'deep learning', 'RCNN', 'image processing', 'hough line transform', '볼트풀림 검출', '영상기반 딥러닝', 'RCNN', '이미지 프로세싱', 'Hough 변환', '호모그래피']","본 연구에서는 영상기반 딥러닝 및 이미지 프로세싱 기법을 이용한 볼트풀림 손상검출 기법을 제안하였다. 이를 위해 먼저, 딥러닝 및 이미지 프로세싱 기반 볼트풀림 검출 기법을 설계하였다. 영상기반 볼트풀림 검출 기법은 볼트 이미지 검출 과정 및 볼트풀림 각도 추정 과정으로 구성된다. 볼트 이미지의 검출을 위하여 RCNN기반 딥러닝 알고리즘을 이용하였다. 영상의 원근왜곡 교정을 위해 호모그래피 개념을 이용하였으며 볼트풀림 각도를 추정을 위하여 Hough 변환을 이용하였다. 다음으로 제안된 기법의 성능을 검증을 위하여 거더의 볼트 연결부 모형을 대상으로 볼트풀림 손상검출 실험을 수행하였다. 다양한 원근 왜곡 조건에 대하여 RCNN 기반 볼트 검출기와 Hough 변환 기반 볼트풀림 각도 추정기의 성능을 검토하였다.","In this paper, a vision-based deep learning algorithm and image processing method are proposed to detect bolt-loosening in steel connections. To achieve this objective, the following approaches are implemented. First, a bolt-loosening detection method that includes regional convolutional neural network(RCNN)-based deep learning algorithm and Hough line transform(HLT)-based image processing algorithm are designed. The RCNN-based deep learning algorithm is developed to identify and crop bolts in a connection image. The HLT-based image processing algorithm is designed to estimate the bolt angles from the cropped bolt images. Then, the proposed vision-based method is evaluated for verifying bolt-loosening detection in a lab-scale girder connection. The accuracy of the RCNN-based bolt detector and HLT-based bolt angle estimator are examined with respect to various perspective distortions."
블레이드의 표면 결함 검출을 위한 Faster R-CNN 딥러닝 모델 구축,2019,"['블레이드', '딥러닝', 'Faster R-CNN', '객체 인식', '표면 결함', '터빈엔진', 'Blade', 'Deep learning', 'Faster R-CNN', 'Object detection', 'Surface damage', 'Turbine engine']","컴퓨터 성능 향상으로 다양한 분야에서 딥러닝을 활용한 연구가 활발히 진행되고 있으며 최근에는 구조물 안전성 평가 연구에도 그 적용이 이루어지고 있다. 특히 터빈의 내부 블레이드는 분리가 쉽지 않고 어두운 주변 환경으로 인해 블레이드의 표면 결함 검출은 전문 인력의 경험에 의존하고 있으며, 점검시간도 상당히 소요되고 있는 실정이다. 따라서, 본 연구에서는 딥러닝 기술을 적용하여 터빈 구조의 부재 중 하나인 내부 블레이드에 발생하는 결함을 검출할 수 있는 효율적인 방법을 제시하였다. Faster R-CNN 인공신경망 기법을 활용하여 결함의 이미지 데이터를 학습하였고 부족한 이미지는 필터링과 Image Data Generator를 이용하여 데이터를 확장하였다. 그 결과 블레이드의 결함을 학습한 딥러닝 모델은 평균적으로 약 96.1%의 정확도와 재현율은 95.3%, 정밀도는 96%의 성능을 보였다. 재현율을 통해 제시된 딥러닝 모델이 결함을 탐지하지 못하는 경우는 4.7% 로 나타났다. 재현율의 성능은 여러 환경의 많은 결함 이미지 데이터를 수집하고 확장하여 딥러닝 학습에 적용함으로써 더욱 향상되리라 판단된다. 이러한 실제 블레이드의 결함 이미지 데이터 확보와 학습을 통해 향후 터빈엔진 정비에 적용 가능한 결함 검출 시스템으로 발전할 수 있을 것이다.","As computer performance improves, research using deep learning are being actively carried out in various fields. Recently, deep learning technology has been applying to the safety evaluation for structures. In particular, the internal blades of a turbine structure requires experienced experts and considerable time to detect surface damages because of the difficulty of separation of the blades from the structure and the dark environmental condition. This study proposes a Faster R-CNN deep learning model that can detect surface damages on the internal blades, which is one of the primary elements of the turbine structure. The deep learning model was trained using image data with dent and punch damages. The image data was also expanded using image filtering and image data generator techniques. As a result, the deep learning model showed 96.1% accuracy, 95.3% recall, and 96% precision. The value of the recall means that the proposed deep learning model could not detect the blade damages for 4.7%. The performance of the proposed damage detection system can be  further improved by collecting and extending damage images in various environments, and finally it can be applicable for turbine engine maintenance."
전이학습과 딥러닝 네트워크를 활용한 고해상도 위성영상의 변화탐지,2019,"['High-resolution Satellite Images', 'Change Detection', 'Deep Learning', 'Transfer Learning', 'Fully Convolutional Layer', 'Convolutional Long Short Term Memory Layer', '고해상도 위성영상', '변화탐지', '딥러닝', '전이학습', '완전 합성곱 레이어', '합성곱 장단기 메모리 레이어']","운용 가능한 위성의 수가 증가하고 기술이 진보함에 따라 영상정보의 성과물이 다양해지고 많은 양의 자료가 축적되고 있다. 본 연구에서는 기구축된 영상정보를 활용하여 부족한 훈련자료의 문제를 극복하고 딥러닝(deep learning) 기법의 장점을 활용하고자 전이학습과 변화탐지 네트워크를 활용한 고해상도 위성영상의 변화탐지를 수행하였다. 본 연구에서 활용한 딥러닝 네트워크는 공간 및 분광 정보를 추출하는 합성곱 레이어(convolutional layer)와 시계열 정보를 분석하는 합성곱 장단기 메모리 레이어(convolutional long short term memory layer)로 구성되었으며, 고해상도 다중분광 영상에 최적화된 정보를 추출하기 위하여 커널(kernel)의 차원에 따른 정확도를 비교하였다. 또한, 학습된 커널 정보를 활용하기 위하여 변화탐지 네트워크의 초기 합성곱 레이어를 고해상도 항공영상인 ISPRS (International Society for Photogrammetry and Remote Sensing) 데이터셋에서 추출된 40,000개의 패치로 학습된 값으로 초기화하였다. 다시기 KOMPSAT-3A (KOrean Multi-Purpose SATllite-3A) 영상에 대한 실험 결과, 전이학습과 딥러닝 네트워크를 활용할 경우 기복 변위 및 그림자 등으로 인한 변화에 덜 민감하게 반응하며 분류 항목이 달라진 지역의 변화를 보다 효과적으로 추출할 수 있었으며, 2차원 커널보다 3차원 커널을 사용할 때 변화탐지의 정확도가 높았다. 3차원 커널은 공간 및 분광정보를 모두 고려하여 특징 맵(feature map)을 추출하기 때문에 고해상도 영상의 분류뿐만 아니라 변화탐지에도 효과적인 것을 확인하였다. 본 연구에서는 고해상도 위성영상의 변화탐지를 위한 전이학습과 딥러닝 기법의 활용 가능성을 제시하였으며, 추후 훈련된 변화탐지 네트워크를 새롭게 취득된 영상에 적용하는 연구를 수행하여 제안기법의 활용범위를 확장할 예정이다.","As the number of available satellites increases and technology advances, image information outputs are becoming increasingly diverse and a large amount of data is accumulating. In this study, we propose a change detection method for high-resolution satellite images that uses transfer learning and a deep learning network to overcome the limit caused by insufficient training data via the use of pre-trained information. The deep learning network used in this study comprises convolutional layers to extract the spatial and spectral information and convolutional long-short term memory layers to analyze the time series information. To use the learned information, the two initial convolutional layers of the change detection network are designed to use learned values from 40,000 patches of the ISPRS (International Society for Photogrammertry and Remote Sensing) dataset as initial values. In addition, 2D (2-Dimensional) and 3D (3-dimensional) kernels were used to find the optimized structure for the high-resolution satellite images. The experimental results for the KOMPSAT-3A (KOrean Multi-Purpose SATllite-3A) satellite images show that this change detection method can effectively extract changed/unchanged pixels but is less sensitive to changes due to shadow and relief displacements. In addition, the change detection accuracy of two sites was improved by using 3D kernels. This is because a 3D kernel can consider not only the spatial information but also the spectral information. This study indicates that we can effectively detect changes in high-resolution satellite images using the constructed image information and deep learning network. In future work, a pre-trained change detection network will be applied to newly obtained images to extend the scope of the application."
합성곱 신경망 기반의 딥러닝에 의한 수치표면모델의 객체분류,2019,"['합성곱 신경망', '딥러닝 모델', '학습 및 검증 데이터', '수치표면모델 분류', 'CNN', 'DL Model', 'Training and Validation Data', 'DSM Classification']","최근 딥러닝(DL)은 여러 분야에서 급속도로 활용되고 있으며, 특히 영상으로부터 객체를 인식하여 분류하고 인식하기 위한 컴퓨터비전 분야에서 활발하게 연구가 진행되고 있다. 영상분야에서는 주로 합성곱 신경망(CNN)을 이용한 딥러닝 모델의 성능 향상에 주력하고 있다. 대부분의 합성곱 신경망은 영상을 학습시켜 영상분류 및 객체인식에 활용하고 있지만, 본 논문에서는 독일 사진측량, 원격탐사 및 공간정보학회(DGPF)가 구축하고 국제 사진측량 및 원격탐사학회(ISPRS)가 제공하는 데이터 셋 중에서 수치표면모델(DSM)과 이 데이터로부터 생성한 경사 및 주향 정보를 효율성과 성능이 우수하다고 평가받는 합성곱 신경망기반의 SegNet 모델에 적용하여 객체를 분류하고 분석하였다. 딥러닝은 고사양의 컴퓨터 시스템과 다량의 학습 데이터와 라벨 데이터가 필요하고, 다수의 시행착오에 의한 풍부한 경험이 요구된다. 또한 본 논문에서는 한정된 수량의 데이터로부터 효율적인 학습을 위한 데이터 생성 방법을 제시하고 수치표면모델을 분류하였다. 분석 결과 수치표면모델 데이터와 이로부터 도출한 부가적인 데이터를 딥러닝 모델에 적용해도 객체를 타당한 정확도로 분류할 수 있음을 확인하였다.","Recently, DL (Deep Learning) has been rapidly applied in various fields. In particular, classification and object recognition from images are major tasks in computer vision. Most of the DL utilizing imagery is primarily based on the CNN (Convolutional Neural Network) and improving performance of the DL model is main issue. While most CNNs are involve with images for training data, this paper aims to classify and recognize objects using DSM (Digital Surface Model), and slope and aspect information derived from the DSM instead of images. The DSM data sets used in the experiment were established by DGPF (German Society for Photogrammetry, Remote Sensing and Geoinformatics) and provided by ISPRS (International Society for Photogrammetry and Remote Sensing). The CNN-based SegNet model, that is evaluated as having excellent efficiency and performance, was used to train the data sets. In addition, this paper proposed a scheme for training data generation efficiently from the limited number of data. The results demonstrated DSM and derived data could be feasible for semantic classification with desirable accuracy using DL."
터널 내 돌발상황 오탐지 영상의 반복 학습을 통한 딥러닝 추론 성능의 자가 성장 효과,2019,"['오탐지 데이터', '레이블링 데이터', '딥러닝 기반 터널 CCTV 영상유고 시스템', '오탐지 데이터 포함 딥러닝 모델 학습', 'False Positive data', 'Labeling data', 'Deep learning-based CCTV incident detection system', 'Deep learning model training including False Positive data']","대부분 딥러닝 모델의 학습은 입력값과 입력값에 따른 출력값이 포함된 레이블링 데이터(labeling data)를 학습하는 지도 학습(supervised learning)으로 진행된다. 레이블링 데이터는 인간이 직접 제작하므로 데이터의 정확도가 높다는 장점이 있지만 비용과 시간의 문제로 인해 데이터의 확보에 많은 노력이 소요된다. 그리고 지도 학습의 목표는 정탐지 데이터(true positive data)의 인식 성능 향상에 초점이 맞추어져 있으며, 오탐지 데이터(false positive data)의 발생에 대한대처는 미흡한 실정이다. 본 논문은 터널 관제센터에 투입된 딥러닝 모델 기반 영상유고 시스템의 모니터링을 통해 정탐지와 레이블링 데이터의 학습으로 예측하기 힘든 오탐지의 발생을 확인하였다. 오탐지의 유형은 작업차량의 경광등, 터널 입구부에서 반사되는 햇빛, 차선과 차량의 일부에서 발생하는 길쭉한 검은 음영 등이 화재와 보행자로 오탐지되고 있었다. 이러한 문제를 해결하기 위해 현장에서 발생한 오탐지 데이터와 레이블링 데이터를 동시에 학습하여 딥러닝 모델을 개발하였으며, 그 결과 기존 레이블링 데이터만 학습한 모델과 비교하면 레이블링 데이터에 대한 재추론 성능이 향상됨을 알 수 있었다. 그리고 오탐지 데이터에 대한 재추론을 한 결과 오탐지 데이터를 많이 포함하여 학습한 모델일 경우보행자의 오탐지 개수가 훨씬 줄었으며, 오탐지 데이터의 학습을 통해 딥러닝 모델의 현장 적용성을 향상시킬 수 있었다.","Most of deep learning model training was proceeded by supervised learning, which is to train labeling data composed by inputs and corresponding outputs. Labeling data was directly generated manually, so labeling accuracy of data is relatively high.However, it requires heavy efforts in securing data because of cost and time.Additionally, the main goal of supervised learning is to improve detection performance for ‘True Positive’ data but not to reduce occurrence of ‘False Positive’ data. In this paper, the occurrence of unpredictable ‘False Positive’ appears by trained modes with labeling data and ‘True Positive’ data in monitoring of deep learning-based CCTV accident detection system, which is under operation at a tunnel monitoring center.Those types of ‘False Positive’ to ‘fire’ or ‘person’ objects were frequently taking place for lights of working vehicle, reflecting sunlight at tunnel entrance, long black feature which occurs to the part of lane or car, etc. To solve this problem, a deep learning model was developed by simultaneously training the ‘False Positive’ data generated in the field and the labeling data. As a result, in comparison with the model that was trained only by the existing labeling data, the re-inference performance with respect to the labeling data was improved. In addition, re-inference of the ‘False Positive’ data shows that the number of ‘False Positive’ for the persons were more reduced in case of training model including many ‘False Positive’ data. By training of the ‘False Positive’ data, the capability of field application of the deep learning model was improved automatically."
몰포러지 신경망 기반 딥러닝 시스템,2019,"['CNN', 'Deep Learning', 'Embedded System', 'MNN', 'Morphology', 'VLSI']","본 논문에서는 몰포러지 연산을 기본으로 하는 몰포러지 신경망(MNN: Morphological Neural Network) 기반 딥러닝 시스템을 제안하였다. 딥러닝에 사용되는 레이어는 몰포러지 레이어, 풀링 레이어, ReLU 레이어, Fully connected 레이어 등이다. 몰포러지 레이어에서 사용되는 연산은 에로전, 다이레이션, 에지검출 등이다. 본 논문에서 새롭게 제안한 MNN은 기존의 CNN(Convolutional Neural Network)을 이용한 딥러닝 시스템과는 달리 히든 레이어의 수와 각 레이어에 적용되는 커널 수가 제한적이다. 레이어 단위 처리시간이 감소하고, VLSI 칩 설계가 용이하다는 장점이 있으므로 모바일 임베디드 시스템에  딥러닝을 다양하게 적용할 수 있다. MNN에서는 제한된 수의 커널로 에지와 형상검출 등의 연산을 수행하기 때문이다. 데이터베이스 영상을 대상으로 행한 실험을 통해 MNN의 성능 및 딥러닝 시스템으로의 활용 가능성을 확인하였다.","In this paper, we propose a deep learning system based on morphological neural network(MNN). The deep learning layers are  morphological operation layer, pooling layer, ReLU layer, and the fully connected layer. The operations used in morphological layer are erosion, dilation, and edge detection, etc. Unlike CNN, the number of hidden layers and kernels applied to each layer is limited in MNN. Because of the reduction of processing time and utility of VLSI chip design, it is possible to apply MNN to various mobile  embedded systems. MNN performs the edge and shape detection operations with a limited number of kernels. Through experiments using database images, it is confirmed that MNN can be used as a deep learning system and its performance."
Sentinel-1 A/B 위성 SAR 자료와 딥러닝 모델을 이용한 여름철 북극해 해빙 분류 연구,2019,"['Sentinel-1 A/B', 'sea ice', 'thermal noise', 'Deep Learning', 'classification']","북극항로의 개척 가능성과 정확한 기후 예측 모델의 필요성에 의해 북극해 고해상도 해빙 지도의 중요성이 증가하고 있다. 그러나 기존의 북극 해빙 지도는 제작에 사용된 위성 영상 취득 센서의 특성에 따른 데이터의 취득과 공간해상도 등에서 그 활용도가 제한된다. 본 연구에서는 Sentinel-1 A/B SAR 위성자료로부터 고해상도 해빙 지도를 생성하기 위한 딥러닝 기반의 해빙 분류 알고리즘을 연구하였다. 북극해 Ice Chart를 기반으로 전문가 판독에 의해 Open Water, First Year Ice, Multi Year Ice의 세 클래스로 구성된 훈련자료를 구축하였으며, Convolutional Neural Network 기반의 두 가지 딥러닝 모델(Simple CNN, Resnet50)과 입사각 및 thermal noise가 보정된 HV 밴드를 포함하는 다섯 가지 입력 밴드 조합을 이용하여 총 10가지 케이스의 해빙 분류를 실시하였다. 이 케이스들에 대하여 Ground Truth Point를 사용하여 정확도를 비교하고, 가장 높은 정확도가 나온케이스에 대해 confusion matrix 및 Cohen의 kappa 분석을 실시하였다. 또한 전통적으로 분류를 위해 많이 활용되어 온 Maximum Likelihood Classifier 기법을 이용한 분류결과에 대해서도 같은 비교를 하였다. 그 결과Convolution 층 2개, Max Pooling 층 2개를 가진 구조의 Convolutional Neural Network에 [HV, 입사각] 밴드를 넣은 딥러닝 알고리즘의 분류 결과가 96.66%의 가장 높은 분류 정확도를 보였으며, Cohen의 kappa 계수는 0.9499 로 나타나 딥러닝에 의한 해빙 분류는 비교적 높은 분류 결과를 보였다. 또한 모든 딥러닝 케이스는 Maximum Likelihood Classifier 기법에 비해 높은 분류 정확도를 보였다.","The importance of high-resolution sea ice maps of the Arctic Ocean is increasing due to the possibility of pioneering North Pole Routes and the necessity of precise climate prediction models. In this study, sea ice classification algorithms for two deep learning models were examined using Sentinel- 1 A/B SAR data to generate high-resolution sea ice classification maps. Based on current ice charts, three classes (Open Water, First Year Ice, Multi Year Ice) of training data sets were generated by Arctic sea ice and remote sensing experts. Ten sea ice classification algorithms were generated by combing two deep learning models (i.e. Simple CNN and Resnet50) and five cases of input bands including incident angles and thermal noise corrected HV bands. For the ten algorithms, analyses were performed by comparing classification results with ground truth points. A confusion matrix and Cohen’s kappa coefficient were produced for the case that showed best result. Furthermore, the classification result with the Maximum Likelihood Classifier that has been traditionally employed to classify sea ice. In conclusion, the Convolutional Neural Network case, which has two convolution layers and two max pooling layers, with HV and incident angle input bands shows classification accuracy of 96.66%, and Cohen’s kappa coefficient of 0.9499. All deep learning cases shows better classification accuracy than the classification result of the Maximum Likelihood Classifier."
딥러닝 기반 항생제 내성균 감염 예측,2019,"['Antibiotic Resistance', 'Deep Learning', 'Neural Embedding Model', 'Matrix Factorization', 'Electronic Health Records', '항생제 내성', '딥러닝', '뉴럴 임베딩 모델', '행렬 분해', '전자의무기록']","세계보건기구(WHO)를 비롯해 세계 각국의 정부기관은 항생제 오남용에 따른 항생제 내성균 감염에 대해 심각하게 경고하며 이를 예방하기 위한 관리와 감시를 강화하고 있다. 하지만 감염을 확인하기 위한 감염균 배양에 수일의 시간이 소요되면서 격리와 접촉주의를 통한 감염 확산 방지 효과가 떨어져 선제적 조치를 위한 신속하고 정확한 예측 및 추정방법이 요구되고 있다. 본 연구는 Electronic Health Records에 포함된 질병 진단내역과 항생제 처방내역을 neural embedding model과 matrix factorization을 통해 embedding 하였고, 이를 활용한 딥러닝 기반 분류 예측 모형을 제안하였다. 항생제 내성균 감염의 주요 원인인 질병과 항생제 정보를 embedding 하여 환자의 기본정보와 병원이용 정보에 추가했을 때 딥러닝 예측 모형의 f1-score는 0.525에서 0.617로 상승하였고, 딥러닝 모형은 Super Learner와 같은 기존 기계학습 모형보다 더 나은 성능을 보여주었다. 항생제 내성균 감염환자의 특성을 분석한 결과, 감염환자는 동일한 질병을진단받은 비감염환자에 비교해 J01 계열 항생제 사용이 많았고 WHO 권고기준(DDD)을 크게 벗어나는 오남용 청구사례가 6.3배 이상 높게 나타났으며 항생제 오남용과 항생제 내성균 감염 간의 높은 연관성이 발견되었다.","The World Health Organization (WHO) and other government agencies aroundthe world have warned against antibiotic-resistant bacteria due to abuse of antibiotics and are strengthening their care and monitoring to prevent infection. However, it is highly necessary to develop an expeditious and accurate prediction and estimating method for preemptive measures. Because it takes several days to cultivate the infecting bacteria to identify the infection, quarantine and contact are not effective to prevent spread of infection. In this study, the disease diagnosis and antibiotic prescriptions included in Electronic Health Records were embedded through neural embedding model and matrix factorization, and deep learning based classification predictive model was proposed. The f1-score of the deep learning model increased from 0.525 to 0.617when embedding information on disease and antibiotics, whichare the main causes of antibiotic resistance, added to the patient’s basic information and hospital use information. And deep learning model outperformed the traditional machine hospital use information. And deep learning model outperformed the traditional machine learning models.As a result of analyzing the characteristics of antibiotic resistant patients, resistant patients were more likely to use antibiotics in J01 than nonresistant patients who were diagnosed with the same diseases and were prescribed 6.3 times more than DDD."
딥러닝 개념을 위한 인공지능 교육 프로그램,2019,"['Artificial Intelligence', 'Machine Learning', 'Deep Learning', 'CNN', 'SW education', '인공지능', '기계학습', '딥러닝 교육', '컨볼루션네트워크', '소프트웨어교육']","본 연구의 목적은 초등학생을 대상으로 한 딥러닝 개념 학습을 위한 교육 프로그램을 개발하는 것이다. 먼저 문헌연구와 선행연구를 토대로 전문가 그룹 토의를 진행하여 프로그램 개발 방향을 위한 준거를 세웠다. 프로그램의 모델은 CT요소 중심 모델을 토대로 딥러닝 교수학습모델을 개발하였다. 개발한 프로그램의 주제는 인공지능의 이미지인식 CNN알고리즘으로 정하고, 9개 차시 교육프로그램을 개발하였다. 프로그램은 6학년을 대상으로 2주간에 걸쳐 적용을 하였다. 프로그램에 대한 학습 적합도 검사는 전문가들의 타당도와 학습자 만족도 설문 검사를 통해 분석하였다. 전문가 타당도 분석 결과 최소 CVR값이 .56이상을 넘어 타당하게 나왔다. 학습자 수준 적합도와 교사 지도 수준의 적합도 문항의 경우 .80이하로 나타났으며 .96이 넘은 학습 환경과 매체의 적합도 문항에서는 높게 나타났다. 낯선 소재로 인해 교사들이 어려워하기는 하지만 기존 SW 교육에서 실시했던 언플러그드 CS 활용의 접근법을 통해 수업의 적용이 가능함을 보여주고 있음을 알 수 있었다. 학생들의 만족도 분석 결과 학습자들의 참여는 적극적으로 하였음을 알 수 있었고, 인공지능 학습의 이해도와 유익성, 흥미도, 학습자료 등에 대해서 평균 4.0이상을 보여 긍정적인 평가를 하였다. 이에 본 프로그램은 초등학교 현장에서의 인공지능 교수학습자료의 토대를 제공할 수 있음을 알 수 있다.","The purpose of this study is to develop an educational program for learning deep learning concepts for elementary school students. First of all, based on literature and previous research, a group of experts was discussed to establish the criteria for the direction of program development. The model of education program was developed the deep-learning teaching method based on CT element-oriented teaching and learning model. The subject of the developed program is the artificial intelligence image recognition CNN algorithm, and we have developed 9 educational programs.  We applied the program over six weeks to sixth graders. he test of learning suitability for the education program was analyzed through the validity of the experts and the survey on the satisfaction of learners. Expert validity analysis showed that the minimum CVR value was more than .56. The fitness level of learner level and the level of teacher guidance were less than .80, and the fitness of learning environment and media above .96 was high. Although it is difficult for teachers due to the unfamiliar material of artificial intelligence, it can be seen that the class can be applied through the approach of using the unplugged CS that was implemented in the existing SW education. The students' satisfaction analysis showed that the learners actively participated in the class. Students gave a positive evaluation of the average of 4.0 or higher on the understanding, benefit, interest, and learning materials of artificial intelligence learning. Therefore, it can be seen that the educational program developed in this study can provide a foundation for artificial intelligence teaching and learning materials in elementary school."
딥러닝을 이용한 다변량 시계열 데이터의 결측치 처리에 관한 연구 조사,2019,"['딥러닝', '데이터 마이닝', '다변량 시계열 데이터', '결측치', 'Deep Learning', 'Data Minning', 'Multivariate Time Series', 'Missing value']","다변량 시계열 데이터는 기상, 교통, 제조 등 다양한 산업에서 예측 및 이상 탐지 등의 여러 응용을 위해 활발히 활용된다. 하지만 여러 원인에 의해 발생하는 다변량 시계열 데이터 내의 결측치는 데이터의 품질과 활용도를 크게 떨어뜨린다. 따라서 다변량 시계열 데이터 내에서의 결측치를 처리하기 위한 다양한 연구가 시도되었다. 하지만 대부분의 기존 방법들은 다변량 시계열 데이터의 가장 중요한 두 가지 특징인 변수 간 상관관계와 시간상의 의존관계를 제대로 반영하지 못하였다. 본 논문에서는 위 두 가지 특징을 효과적으로 고려하여 결측치 처리 성능을 크게 향상한 딥러닝 기반의 최근 연구들을 소개한다. 제시된 모델들은 크게 확정적 모델과 생성 모델로 구분된다. 본 논문은 각 모델의 특징을 기반으로 작동방식과 장단점을 자세하게 설명한다. 그리고 딥러닝을 이용한 방법들의 한계점을 지목하며 향후 연구 방향에 대하여 토의한다.","Multivariate time series data has been widely used for various applications (e.g. prediction and outlier detection) across many industries such as meteorology, transportation, and manufacturing.However, missing values in multivariate time series data significantly reduce the usability of the data. There have been many efforts to overcome this problem, but most of the previous studies do not effectively consider the two most important characteristics of multivariate time series data: (1) the correlation between variables and (2) the temporal dependency. This paper introduces the recent deep learning-based approaches which show better performances on processing missing values by taking into account these two characteristics. According to the mechanism of the model, the introduced studies can be categorized into either a discriminative model or a generative model. This paper explains the basic mechanism of each model, as well as its strengths and weaknesses. The limitations of the models and possible future research directions are also discussed."
딥러닝으로 불경 읽기 - Word2Vec으로 CBETA 불경 데이터 읽기,2019,"['불경', '인공지능', '딥러닝', '인공지능인문학', '디지털인문학', '디지털 불교학', 'Buddhist scriptures', 'Artificial intelligence', 'deep learning', 'artificial intelligence', 'digital humanities', 'digital Buddhism']","본 연구는 CBETA(씨베타) 불경 데이터를 대상으로 딥러닝 방법인 Word2Vec(워드투벡)을 통해서 불경을 분석하고 시각화하는 방법을 탐색하고, 이를 토대로 인공지능이 불경을 읽는 방법의 장단점을 검토했다.  우선 인공지능에 대한 불교학 연구가 인공지능에 대한 비판의 측면에 집중되어 있는 현상을 제시하며, 인공지능을 활용한 불교학 연구를 제안하였다. 이를 위해서 Word2Vec을 통한 불경 분석의 이론적 배경과 분석 알고리즘을 서술하였다. 또한 불교학 연구자가 분석 결과를 탐색할 수 있는 방법을 제시하고, 이를 토대로 불교학 연구자가 분석 결과에 손쉽게 접근하여 사용할 수 있는 시각화 방안을 제시하였다.  마지막으로 인공지능 분석 방법의 장점으로 ‘넓게 보기’, ‘다르게 보기’, ‘디지털 학문 선순환’을 제시하였고, 단점으로 ‘형태적인 접근의 한계’, ‘설명 불가능한 인공지능’, ‘해석 불가능한 인공지능’의 문제를 서술하였다. 그리고 서술한 문제를 해결하는 방안으로 불교학의 지식과 사유를 디지털에 이식하기 위한 불교학 디지털 온톨로지를 제안하였다.","This study explored how to analyze and visualize the Buddhist scriptures using the deep learning method Word2Vec using CBETA data, and based on this, examined the advantages and disadvantages of how artificial intelligence read the Buddhist scriptures.  First of all, the Buddhist study on artificial intelligence presented a phenomenon focusing on the aspects of criticism on artificial intelligence, and proposed the study of Buddhism using artificial intelligence. To this end, the theoretical background and analysis algorithm of Buddhist scripture analysis through Word2Vec were described, the method by which Buddhist researchers could explore the analysis results was presented, and a visualization method was presented to enable Buddhist researchers to easily access and use the analysis results.  Finally, the strengths of artificial intelligence were ""broad view,"" ""different view,"" and ""digital academic development,"" while shortcoming was to describe the limitations of formative approach, unexplained artificial intelligence, and incomprehensible AI problems. And as a way to solve the problem described, I proposed a Buddhist study digital ontology to transplant Buddhist knowledge and manas to digital."
딥러닝 모형을 사용한 한국어 음성인식,2019,"['한국어 음성인식', '종단 간 딥러닝', '연결성 시계열 분류기', '주의 기제', '베이즈 딥러닝', 'Korean speech recognition', 'end to end deep learning', 'Connectionist temporal classification', 'Attention', 'Bayesian deep learning']","본 논문에서는 베이즈 신경망을 결합한 종단 간 딥러닝 모형을 한국어 음성인식에 적용하였다. 논문에서는 종단 간 학습 모형으로 연결성 시계열 분류기(connectionist temporal classification), 주의 기제, 그리고 주의 기제에 연결성 시계열 분류기를 결합한 모형을 사용하였으며. 각 모형은 순환신경망(recurrent neural network) 혹은 합성곱신경망(convolutional neural network)을 기반으로 하였다. 추가적으로 디코딩 과정에서 빔 탐색과 유한 상태 오토마타를 활용하여 자모음 순서를 조정한 최적의 문자열을 도출하였다. 또한 베이즈 신경망을 각 종단 간 모형에 적용하여 일반적인 점 추정치와 몬테카를로 추정치를 구하였으며 이를 기존 종단 간 모형의 결괏값과 비교하였다. 최종적으로 본 논문에 제안된 모형 중에 가장 성능이 우수한 모형을 선택하여 현재 상용되고 있는 Application Programming Interface (API)들과 성능을 비교하였다. 우리말샘 온라인 사전 훈련 데이터에 한하여 비교한 결과, 제안된 모형의 word error rate (WER)와 label error rate (LER)는 각각 26.4%와 4.58%로서 76%의 WER와 29.88%의 LER 값을 보인 Google API보다 월등히 개선된 성능을 보였다.","In this paper, we propose an end-to-end deep learning model combining Bayesian neural network with Korean speech recognition.In the past, Korean speech recognition was a complicated task due to the excessive parameters of many intermediate steps and needs for Korean expertise knowledge.Fortunately, Korean speech recognition becomes manageable with the aid of recent breakthroughs in ``End-to-end"" model.The end-to-end model decodes mel-frequency cepstral coefficients directly as text without any intermediate processes.Especially, Connectionist Temporal Classification loss and Attention based model are a kind of the end-to-end.In addition, we combine Bayesian neural network to implement the end-to-end model and obtain Monte Carlo estimates.Finally, we carry out our experiments on the ``WorimalSam"" online dictionary dataset. We obtain 4.58% Word Error Rate showing improved results compared to Google and Naver API."
딥러닝 기법을 이용한 차량 연료차단 주행의 감지법,2019,"['연료차단', '친환경운전', '딥러닝', '연비', 'GPS', 'Fuel-cut', 'Eco-drive', 'Deep-learning', 'Fuel economy', 'GPS']","차량의 변속기어가 체결된 주행 상태에서 가속페달을 방치하는 경우 연료차단 주행이 시작된다. 적극적인 연료차단 주행을 활용하면 차량 연비가 개선된다. 본 연구에서는 차량의 속도, 가속도, 도로구배를 입력데이터로 사용하여 연료차단 주행 여부를 예측할 수 있는 딥러닝 기법을 제안하였다. 약 12km 정도의 도로주행을 통해 측정한 9600개의 데이터에 은닉층 3~10개, 매개변수 10~20개의 딥러닝 연산법을 적용하여 연료차단 주행여부를 예측하였다. 연산 결과, 렐루함수를 활성화함수로 적용하고 은닉층 7개, 매개변수 10개인 경우 정확도 84.5% 수준으로 예측할 수 있었다. 입력데이터인 속도, 가속도, 도로구배의 변화율이 연료소모율 데이터의 변화율에 비해 큰 것이 오차의 원인으로 판단된다. 따라서 입력데이터 정규화 과정을 통해 정확도를 높일 수 있을 것으로 예상된다. 본 연구의 특징은 차량의 연료분사 인젝터나 OBD 데이터를 사용하지 않고 GPS 등에서 쉽게 측정할 수 있는 데이터에 딥러닝을 적용한 방식이다. 또한 연산량이 적어 본 연구에서 제안한 방식으로 친환경 경제운전에 적용하기 용이할 것으로 기대된다.","The Fuel-cut driving is started when the acceleration pedal released with transmission gear engaged. Fuel economy of the vehicle improves by active fuel-cut driving. A deep-learning technique is proposed to predict fuel-cut driving with vehicle speed, acceleration and road gradient data in the study. It’s 3~10 of hidden layers and 10~20 of variables and is applied to the 9600 data obtained in the test driving of a vehicle in the road of 12km. Its accuracy is about 84.5% with 10 variables, 7 hidden layers and Relu as activation function. Its error is regarded from the fact that the change rate of input data is higher than the rate of fuel consumption data. Therefore the accuracy can be better by the normalizing process of input data. It’s unnecessary to get the signal of vehicle injector or OBD, and a deep-learning technique applied to the data to be got easily, like GPS. It can contribute to eco-drive for the computing time small."
딥러닝을 활용한 자산분배 시스템,2019,"['Portfolio', 'Deep Learning', 'Autoencoder', 'ETF', '자산분배', '딥러닝', '오토인코더', 'ETF']",딥러닝 네트워크 기반의 알고리즘의 발전으로 인공지능은 전세계적으로 빠른 성장세를 보이고 있다. 그 중 금융은 인공지능이 가장 많이 활용될 분야로 예상되고 있으며 최근 많은 연구가 되고 있다. 기존의 딥러닝을 사용한 재무 전략은 단일 종목에 대한 주가 예측에만 치중되어 있어 변동성에 취약하다. 따라서 본 연구는 딥러닝을 이용하여 펀드 구성 종목을 산출하고 종목들을 분산 투자하여 ETF 상품을 구성하는 모델을 제안한다. 실험 결과로 제안하는 모델을 통해 코스피 100 지수를 대상으로 하는 성능을 분석하며 수익률 또는 안정성 측면에서 향상된 결과를 확인하였다.,
딥러닝 기반 의료 영상 인공지능 모델의 취약성: 적대적 공격,2019,"['Deep Learning', 'Artificial Intelligence', 'Medical Imaging']","딥러닝 학습모델 성능의 비약적인 발전으로 인해 영상의학을 중심으로 하여 기계학습 모델들이 실제 임상현장에서 의사를 보조하여 진단능을 높이고 작업의 효율성을 증대 시켜줄 것이라는 기대가 많다. 이러한 기대로 인해 많은 병원과 민간 기업 등에서 의학 영상을 이용한자동 진단 학습모델 개발 경쟁이 뜨겁다. 실제로 가까운 미래에 많은 딥러닝 기반의 자동 진단 프로그램들이 의료 환경에서 사용될 것이다. 그러나, 딥러닝 알고리듬이 내재적으로 가진불확실성(uncertainty)에 의한 적대적 공격(adversarial attack)의 가능성은 특히 의학문제에 딥러닝 알고리듬을 적용하는 데에 큰 걸림돌이 된다. 본 종설에서는 의학영상을 다루는딥러닝 모델들에 대해 어떠한 원리와 방식으로 적대적 공격이 이루어질 수 있으며, 이로 인하여 어떤 문제들이 발생할 수 있으며 적대적 공격을 차단할 수 있는 방법은 없는지 자세히살펴보고자 한다.","Due to rapid developments in the deep learning model, artificial intelligence (AI) models are expected to enhance clinical diagnostic ability and work efficiency by assisting physicians. Therefore, many hospitals and private companies are competing to develop AI-based automatic diagnostic systems using medical images. In the near future, many deep learning-based automatic diagnostic systems would be used clinically. However, the possibility of adversarial attacks exploiting certain vulnerabilities of the deep learning algorithm is a major obstacle to deploying deep learning-based systems in clinical practice. In this paper, we will examine in detail the kinds of principles and methods of adversarial attacks that can be made to deep learning models dealing with medical images, the problems that can arise, and the preventive measures that can be taken against them."
C++ 기반 범용 오픈소스 딥러닝 프레임워크 WICWIU,2019,"['딥러닝', '신경망', '프레임워크', '오픈소스', 'WICWIU', 'deep learning', 'neural networks', 'framework', 'open source']","국내 대학으로는 최초로 공개한 오픈소스 딥러닝 프레임워크 WICWIU를 소개한다. WICWIU 는 다양한 연산자와 모듈, 그리고 일반적인 계산 그래프들을 표현할 수 있는 신경망 구조를 제공하여 Inception, ResNet, DenseNet 등 널리 사용되는 최신 딥러닝 모델들을 구성하기에 충분한 기능을 제공한다. 또한, GPU 기반 대규모 병렬 컴퓨팅을 지원해 빠른 학습이 가능하다. 모든 API가 C++로 제공되어 C++ 개발자들이 쉽게 적응할 수 있으며, C++환경에 기반하기 때문에 파이썬 기반의 프레임워크에 비해 메모리 및 성능 최적화에도 유리하다. 따라서, 프레임워크 자체를 자원이 제한된 환경에 맞도록 수정하기에도 용이하다. 일관성 높은 코드와 API로 구성되어 가독성과 확장성이 우수하며, 한국어 문서를 제공해 국내 개발자들이 쉽게 접근할 수 있다. WICWIU는 Apache 2.0 라이선스를 적용해 어떠한 연구 목적 및 상용 목적으로도 자유롭게 활용할 수 있다.","In this paper, we introduce WICWIU, the first open source deep learning framework among Korean universities. WICWIU provides a variety of operators and modules together with a network structure that can represent an arbitrary general computational graph. The WICWIU features are sufficient to compose widely used deep learning models such as Inception, ResNet, and DenseNet.WICWIU also supports GPU-based massive parallel computing which significantly accelerates the training of neural networks. It is also easily accessible for C++ developers because the whole API is provided in C++. WICWIU has an advantage over Python-based frameworks in memory and performance optimization based on the C++ environment. This eases the customizability of WICWIU for environments with limited resources. WICWIU is readable and extensible because it is composed of C++ codes coupled with consistent APIs. With Korean documentation, it is particularly suitable for Korean developers. WICWIU applies the Apache 2.0 license which is available for any research or commercial purposes for free."
딥러닝 기반 포즈 변화에 강인한 귀 인식 연구,2019,"['Ear recognition', 'Convolutional neural networks', 'K-ear database', 'Ensemble']",,
딥러닝을 활용한 다발성 골절 분류,2019,"['딥러닝', '컨볼루션 신경망', '골절', '다중 레이블', 'Deep Learning', 'Convolutional Neural Network', 'Fracture', 'Multi-Label']","정형외과 의사는 컴퓨터 단층 촬영(CT)을 활용해 골절 환자의 골절 범주를 식별하고 치료 방법을 결정한다. 골절이 발생하게 되면 다발성 골절인 경우가 많고 골절 범주가 많기 때문에, 의사가 골절을 정확히 분류하기 위해서는 높은 전문성과 많은 노력이 필요하다. 이 논문에서는 골절 범주 식별을 다중 부류 분류 문제로 정의하고, 골절의 범주를 식별하기 위해 딥러닝을 사용하는 방법을 제안한다. 제안하는 딥러닝 모델은 GoogleNet과 유사한 형태로 골절의 특징을 추출하고, 다층퍼셉트론으로 각 골절 범주의 점수를 계산해 분류를 한다. 그리고 출력 노드의 점수가 특정 임계값 내에 있는 최대 4개의 골절 부류를 선택한다. 하반신 골절 CT 데이터에 대한 제안 방법의 정밀도는 73.3%, 재현율은 86.9%였다.","The orthopedists use computed tomography(CT) to identify fracture categories of fractured patients and determine their treatment. Fractures often result in multiple fractures which have various categories. Here it is required for orthopedists to have a high level of expertise and stressful examination. This paper casts the fracture category identifier task as a multi-label classification problem, and proposes a deep learning based method to it. The proposed deep learning model extracts the features of fractures with GoogleNet-like front-end and determines the fracture categories from the categorieswise score computed with back-end fully connected layer. The proposed method showed 73.3% precision and 86.9%recall for a CT dataset for lower body fracture in the experiments."
사물인식을 위한 딥러닝 모델 선정 플랫폼,2019,"['딥러닝', '신경망', '사물인식', '플랫폼', 'Deep Learning', 'Neural Network', 'Object Recognition', 'Platform']","최근 컴퓨터 비전을 활용한 사물인식 기술이 센서 기반 사물인식 기술을 대체할 기술로 주목을 받고 있다. 센서 기반 사물인식 기술은 일반적으로 고가의 센서를 필요로 하기 때문에 기술이 상용화되기 어렵다는 문제가 있었다. 반면 컴퓨터 비전을 활용한 사물인식 기술은 고가의 센서 대신 비교적 저렴한 카메라를 사용할 수 있다. 동시에 CNN이 발전하면서 실시간 사물인식이 가능해진 이후 IoT, 자율주행자동차 등 타 분야에 활발하게 도입되고 있다. 그러나 사물 인식 모델을 상황에 알맞게 선택하고 학습시키기 위해서는 딥러닝에 대한 전문적인 지식을 요구하기 때문에 비전문가가 사물 인식 모델을 사용하기에는 어려움이 따른다. 따라서 본 논문에서는 딥러닝 기반 사물인식 모델들의 구조와 성능을 분석하고, 사용자가 원하는 조건의 최적의 딥러닝 기반 사물 인식 모델을 스스로 선정할 수 있는 플랫폼을 제안한다. 또한 통계에 기반한 사물 인식 모델 선정이 필요한 이유를 실험을 통해 증명한다.","Recently, object recognition technology using computer vision has attracted attention as a technology to replace sensor-based object recognition technology. Sensor-based object recognition technology has a problem that it is difficult to commercialize the technology because an expensive sensor is required. On the other hand, since object recognition technology using computer vision can replace sensors with inexpensive cameras. Moreover, Real-time object recognition becomes possible because of the development of CNN, it is actively introduced into other fields such as IoT and autonomous vehicles. However, using the object recognition model requires expert knowledge on deep learning to select and learn the model, it is difficult for non-experts to use it. Therefore, in this paper, we analyze the structure of deep - learning - based object recognition models, and propose a platform that can automatically select a deep - running object recognition model based on a user s desired condition. We also show the reason why we need to select the object recognition model based on the statistics through experiments on the models."
딥러닝 알고리즘 개발과정을 통해 본 영상의학분야에서 딥러닝의 최신 경향,2019,"['Artificial Intelligence', 'Deep Learning', 'Algorithms']","최근 인공지능은 지각정보를 해석하는데 있어 상당한 진보를 이루었으며, 이를 통해 기계는매우 복잡한 데이터를 보다 잘 해석할 수 있게 되었다. 최근 몇 년간 딥러닝 기술로 대표되는인공지능의 의료 및 생물의학 연구분야로의 적용이 기하급수적으로 증가하고 있다. 이번 기고문에서는 의료영상분야의 딥러닝 알고리즘 개발 단계를 주제선정, 데이터 수집, 데이터 탐색 및 정제, 알고리즘 개발, 알고리즘 평가 그리고 임상적용의 단계로 나누어 설명하고, 각각의 단계에서 최신의 동향을 소개하고자 한다","Recently, considerable progress has been made in interpreting perceptual information through artificial intelligence, allowing better interpretation of highly complex data by machines. Furthermore, the applications of artificial intelligence, represented by deep learning technology, to the fields of medical and biomedical research are increasing exponentially. In this article, we will explain the stages of deep learning algorithm development in the field of medical imaging, namely topic selection, data collection, data exploration and refinement, algorithm development, algorithm evaluation, and clinical application; we will also discuss the latest trends for each stage."
데이터 증강을 통한 딥러닝 기반 주가 패턴 예측 정확도 향상 방안,2019,"['Stock Price Pattern', 'Deep Learning', 'Convolutional Neural Network', 'Data Augmentation', 'Gaussian Noise', '주가 패턴', '딥러닝', '컨볼루셔널 뉴럴 네트워크', '데이터 증강', '가우시안 노이즈']","인공지능 기술이 발전하면서 이미지, 음성, 텍스트 등 다양한 분야에 적용되고 있으며, 데이터가 충분한 경우 기존 기법들에 비해 좋은 결과를 보인다. 주식시장은 경제, 정치와 같은 많은 변수에 의해 영향을 받기 때문에, 주식 가격의 움직임 예측은 어려운 과제로 알려져 있다. 다양한 기계학습 기법과 인공지능 기법을 이용하여 주가 패턴을 연구하여 주가의 등락을 예측하려는 시도가 있어왔다. 본 연구는 딥러닝 기법 중 컨볼루셔널 뉴럴 네트워크(CNN)를 기반으로 주가 패턴 예측률 향상을 위한 데이터 증강 방안을 제안한다. CNN은 컨볼루셔널 계층을 통해 이미지에서 특징을 추출하여 뉴럴 네트워크를 이용하여 이미지를 분류한다. 따라서, 본 연구는 주식 데이터를 캔들스틱 차트 이미지로 만들어 CNN을 통해 패턴을 예측하고 분류하고자 한다. 딥러닝은 다량의 데이터가 필요하기에, 주식 차트 이미지에 다양한 데이터 증강(Data Augmentation) 방안을 적용하여 분류 정확도를 향상 시키는 방법을 제안한다. 데이터 증강 방안으로는 차트를 랜덤하게 변경하는 방안과 차트에 가우시안 노이즈를 적용하여 추가 데이터를 생성하였으며, 추가 생성된 데이터를 활용하여 학습하고 테스트 집합에 대한 분류 정확도를 비교하였다. 랜덤하게 차트를 변경하여 데이터를 증강시킨 경우의 분류 정확도는 79.92%였고, 가우시안 노이즈를 적용하여 생성된 데이터를 가지고 학습한 경우의 분류 정확도는 80.98%이었다. 주가의 다음날 상승/하락으로 분류하는 경우에는 60분 단위 캔들 차트가 82.60%의 정확도를 기록하였다.",
성별의 알고리즘 편향성 감소를 위한 오토인코더 기반 딥러닝 모델,2019,"['algorithmic bias', 'autoencoder', 'latent space', 'bias-variance dilemma', 'deep learning', '알고리즘 편향성', '오토인코더', '잠재공간', '편향-분산 딜레마', '딥러닝']",알고리즘 편향성은 알고리즘 설계과정에서 트레이닝 데이터에서의 편견이나 모델과 데이터의 특성 사이의 조합에 의해 모델에 반영되는 편향을 의미한다. 최근에는 이러한 편향성이 딥러닝 모델에서 나타날 뿐만 아니라 증폭된다는 연구가 진행되면서 편향성 제거에 관한 문제가 제기되고 있다. 본 논문에서는 성별에 의한 알고리즘 편향성을 편향-분산 딜레마의 관점에서 분석하며 편향성의 원인을 규명하였고 이를 해결하기 위해 심층 오토인코더 기반 잠재공간 일치모델을 제안한다. 우리는 딥러닝에서의 알고리즘 편향성은 모델 내부의 특징 추출부분에서 보호특징별 잠재 공간이 다르다는 것을 실험으로 보여주었다. 본 논문에서 제안하는 모델은 성별특징이 다른 데이터를 동일한 잠재공간으로 전사시킴으로써 추출된 특징의 차이를 줄여 저편향성을 달성하였다. 우리는 정량적 평가지표로 Equality of Odds와 Equality of Opportunity 를 사용하여 기존모델에 비해 편향성이 낮음을 입증하고 ROC 곡선으로 통해 성별사이의 예측결과의 편차가 줄어들었음을 확인하였다.,"Algorithmic bias is a discrimination that is reflected in the model by a bias in data or combination of characteristics of model and data in the algorithm. In recent years, it has been identified that the bias is not only present but also amplified in the deep learning model; thus, there exists a problem related to bias elimination. In this paper, we analyze the bias of the algorithm by gender in terms of bias-variance dilemma and identify the cause of bias. To solve this problem, we propose a deep auto-encoder based latent space matching model. Based on the experimental results, it is apparent that the algorithm bias in deep learning is caused by difference of the latent space for each protected feature in the feature extraction part of the model. A model proposed in this paper achieves the low bias by reducing the differences in extracted features by transferring data with different gender characteristics to the same latent space. We employed Equality of Odds and Equality of Opportunity as a quantitative measure and proved that proposed model is less biased than the previous model. The ROC curve shows a decrease in the deviation of the predicted values between the genders."
위성 영상과 관측 센서 데이터를 이용한 PM10농도 데이터의 시공간 해상도 향상 딥러닝 모델 설계,2019,"['PM10', 'Deep Learning', 'Satellite Image', 'Sensor Data', 'Spatiotemporal Resolution', 'PM10', '딥러닝', '위성 영상', '센서 데이터', '시공간 해상도']","PM10 농도는 시간 및 공간 의존성을 동시에 가지는 시공간 데이터이지만 현실적으로 연속적인 시공간 데이터를 획득하는 것은 쉬운 일이 아니다. 본 연구에서는 위성영상과 대기질 및 기상 관측 센서 데이터를 복합적인 딥러닝 모델에 적용하여 시공간 해상도를 향상시키는 모델을 설계하였다. 설계된 딥러닝 모델은 기상, 토지 이용 등 PM10 농도에 영향을 줄 수 있는 인자를 이용하여 학습하였으며, 대기질 및 기상 관측 데이터만을 이용하여 15분 단위의 30m×30m의 공간해상도를 PM10 영상을 생성하였다.","PM10 concentration is a spatiotemporal phenomenta and capturing data for such continuous phenomena is a difficult task. This study designed a model that enhances spatiotemporal resolution of PM10 concentration levels using satellite imagery, atmospheric and meteorological sensor data, and multiple deep learning models. The designed deep learning model was trained using input data whose factors may affect concentration of  PM10 such as meteorological conditions and land-use. Using this model,  PM10 images having 15 minute temporal resolution and 30m×30m spatial resolution were produced with only atmospheric and meteorological data."
딥러닝 SW 기술을 이용한 임베디드형 융합 CCTV 카메라,2019,"['LPR 카메라', 'CCTV', '융합', 'Edge Base', '임베디드', '영상 분석 모듈', '딥러닝 SW 기술', 'LPR Camera', 'CCTV', 'convergence', 'Edge base', 'Embedded', 'Image Analysis Module', 'Deep Learning SW Technology']","차량 번호판 인식 카메라는 차량 번호판 내 문자와 숫자의 인식을 위하여 대상 차량의 이미지 취득을 목적으로 하는 전용 카메라를 말하며 대부분 단독 사용보다는 서버와 영상 분석 모듈과 결합된 시스템의 일부로 적용된다. 그러나 차량 번호판 인식을 위한 시스템 구축을 위해서는 취득 영상 관리 및 분석 지원을 위한 서버와 문자, 숫자의 추출 및 인식을 위한 영상 분석 모듈을 함께 구성하여야 하므로 구축을 위한 설비가 필요하고 초기 비용이 많이 든다는 문제점이 있다. 이에 본 연구에서는 카메라의 기능을 차량 번호판 인식에만 한정하지 않고 방범 기능을 함께 수행할 수 있도록 확장하고 카메라 단독으로도 두가지 기능 수행이 가능한 Edge Base의 임베디드형 융합 카메라를 개발한다. 임베디드형 융합 카메라는 선명한 영상 취득 및 빠른 데이터 전송을 위해 고해상도 4K IP 카메라를 탑재하고 오픈소스 신경망 알고리즘 기반의 다중 객체 인식을 위한 딥러닝 SW인 YOLO를 적용하여 차량 번호판 영역을 추출한 후 차량 번호판 내의 문자와 숫자를 검출하고 검출 정확도와 인식 정확도를 검증하여 CCTV 방범 기능과 차량 번호 인식 기능이 가능한지를 확인 하였다.","License plate recognition camera is dedicated device designed for acquiring images of the target vehicle for recognizing letters and numbers in a license plate.Mostly, it is used as a part of the system combined with server and image analysis module rather than as a single use. However, building a system for vehicle license plate recognition is costly because it is required to construct a facility with a server providing the management and analysis of the captured images and an image analysis module providing the extraction of numbers and characters and recognition of the vehicle’s plate. In this study, we would like to develop an embedded type convergent camera (Edge Base) which can expand the function of the camera to not only the license plate recognition but also the security CCTV function together and to perform two functions within the camera. This embedded type convergence camera equipped with a high resolution 4K IP camera for clear image acquisition and fast data transmission extracted license plate area by applying YOLO, a deep learning software for multi object recognition based on open source neural network algorithm and detected number and characters of the plate and verified the detection accuracy and recognition accuracy and confirmed that this camera can perform CCTV security function and vehicle number plate recognition function successfully."
딥러닝 및 영상처리 기술을 활용한 콘크리트 균열 검출 방법,2019,"['콘크리트 균열', '균열 검출', '딥러닝', '영상처리', '합성곱신경망', 'Concrete Crack', 'Crack Detection', 'Deep Learning', 'Image Processing', 'CNN']","현행 균열조사 업무는 육안조사로 이루어지고 있어 점검자의 주관이 개입되어 점검 결과에 차이가 발생하거나, 측정오차가 발생할 여지가 있다. 이에 본 연구는 콘크리트 균열 조사의 객관성과 효율성을 높이기 위하여 딥러닝 네트워크 중 실시간 분석이 가능한 YOLO v.2를 활용하여 균열을 인지하고, 영상처리 기술을 활용하여 균열의 특성정보를 추출하는 프로세스를 제시하였다. 실험 결과, 실시간 분석이 가능한 검출속도와 정확도를 확보할 수 있었다. 본 연구의 결과는 시설물 하자진단 자동화 시스템 개발의 기초자료로 활용될수 있을 것이다.","Most of the current crack investigation work consists of visual inspection using simple measuring equipment such as crack scale. Thesemethods involve the subjection of the inspector, which may lead to differences in the inspection results prepared by the inspector, and maylead to a large number of measurement errors. So, this study proposes an image-based crack detection method to enhance objectivity andefficiency of concrete crack investigation. In this study, YOLOv2 was used to determine the presence of cracks in the image information toensure the speed and accuracy of detection for real-time analysis. In addition, we extracted shapes of cracks and calculated quantitatively,such as width and length using various image processing techniques. The results of this study will be used as a basis for the development ofimage-based facility defect diagnosis automation system."
딥러닝 기법을 이용한 P2P 소셜 대출 채무자 부도 예측모델에 관한 연구,2019,"['딥러닝', 'P2P 소셜대출', '대출 부도', '예측 모델', '이진 분류', 'Deep Learning', 'P2P Social Lending', 'Lending Default', 'Prediction Model', 'Binary Classification']",,"It is important for platform service providers and investors to find and invest in loan requests that do not cause delinquency or default. However, due to the characteristics of the loan requestor, it is true that the default rate is higher than those who are borrowed from the bank. Therefore, it is important to analyze the contents of the loan request to select the loans for which no delinquency or default will occur. In this paper, we developed a prediction model of P2P social loan debtor s default using deep learning method for lending club database. We used all parameters to increase the accuracy and extracted features using stacked auto encoder to increase learning speed. Using AI based balanced sub sampling the data class is uniformized and the default prediction is performed using the multi-layer perceptron. As a result of applying it to the lending club database, it was confirmed that both the accuracy and the precision outperforms other classifiers."
딥러닝 기법을 이용한 미숙아 망막병증 분류 시스템,2019,"['retinopathy of prematurity', 'deep learning', 'smartphone funduscopy']","미숙아망막병증(Retinopathy of Prematurity, ROP) 이란 37주 미만의 미숙아에게 발생하는 혈관증식성 질환으로 전 세계적으로 소아 실명의 중요한 원인이 되는 질환이다. 미숙아 망막병증 진단을 위한 미숙아의 안저 촬영에는 고가의 촬영 장비가 필요하지만, 현재 우리나라의 수가 체계와 의료 시스템 상 장비를 갖추고 있는 병원이 부족하다. 본 논문에서는 고가의 장비대신 스마트폰으로 촬영한 미숙아 안저 사진을 딥러닝 기법을 이용하여 미숙아 망막병증을 진단하는 분류기를 개발하였다. 스마트폰으로 촬영하였기 때문에 기존의 고가 장비에 비해 현저히 해상도가 떨어짐에도 불구하고 본 논문에서 개발한 분류기의 결과 99% 이상의 정확도를 보여, 본 연구를 통해 보다 손쉽게 스마트폰 촬영으로 미숙아 망막병증을 진단할 수 있을 것이다.","Retinophathy of Prematurity(ROP) is a vascular disease that occurs in premature babies less than 37 weeks old and is an important cause of childhood blindness worldwide. To capture the premature infant's fundus image for diagnosing ROP requires the expensive camera equipment, but the hospitals currently lacks equipment in the national medical system. In this paper, a classification system for diagnosing ROP was developed using deep learning technique via smartphone funduscopy instead of expensive equipment. Although the resolution of the smartphone photographs is significantly lower than that of existing high-end equipment, the results of the classification system developed in this paper show 99% accuracy, making it easier to diagnose ROP by taking a smartphone."
스마트 팩토리 환경에서의 딥러닝 기반 제품 데이터 시각화 및 지능형 모니터링 기술 연구,2019,"['딥러닝', '클라우드 컴퓨팅', '모바일 엣지 컴퓨팅', '플랫폼 가상화', 'IoT', '지능형 예측', 'Deep learning', 'Cloud Computing', 'MEC', 'Platform Virtualization', 'IoT', 'Intelligent Prediction']",오늘날의 스마트 공장에서 실시간 제품 데이터 모니터링 및 예측을 위한 클라우드 기반의 가상화 플랫폼은 산업 프로세스 자동화를 위해 매우 중요하다. MEC(Multi-Access Edge Computing) 기반의 서버와 같은 클라우드 플랫폼은 실시간 모니터링 환경에서 저지연과 고성능을 지원하기 때문이다. 공장 데이터 시각화 및 모니터링에 관한 많은 연구는 기존에도 많이 이루어졌으나 본 논문에서는 데이터 시각화 및 클러스터링을 위한 DNN(Deep Neural Network : 이하 DNN)을 제안했다. 본 논문을 통해 이전에는 없었던 스마트 팩토리 환경에서의 클러스터링 모듈과 데이터 시각화 및 DNN을 통한 최신 스마트 팩토리 데이터 모니터링 및 디스플레이 모듈에 대한 새로운 시스템을 제안하였다.,"Cloud based virtual platform for real-time product monitoring and prediction is crucial for automation of Industrial processes. The MEC based server and cloud platform gives a low latency and high performance in real-time environment monitoring. Although many research has been done in the data visualization, neural network and factory data monitoring, combining these methods to make a MEC based Smart factory data monitoring system has never been proposed. In this research article, we have proposed a data visualization and DNN (Deep Neural Network) with Clustering module. This proposed method for training the neural network achieves a 98% accuracy in the prediction and the cluster can give a 87% accuracy for 2 clusters. This accuracy is state of the art for factory production data classification. This state of art smart factory data monitoring and display module gives the smart factory system a MEC based and high accuracy based monitoring capability."
딥러닝 기반 BIM(Building Information Modeling) 벽체 하위 유형 자동 분류 통한 정합성 검증에 관한 연구,2019,"['BIM', 'IFC', '하위 유형 분류', '건축 벽체', '딥러닝', 'BIM', 'IFC', 'Subtype Classification', 'Architectural Walls', 'Deep Learning']",,"With Building Information Modeling(BIM) becoming the de facto standard for data sharing in the AEC industry, additional needs have increased to ensure the data integrity of BIM models themselves. Although the Industry Foundation Classes provide an open and neutral data format, its generalized schema leaves it open to data loss and misclassifications This research applied deep learning to automatically classify BIM elements and thus check the integrity of BIM-to-IFC mappings. Multi-view CNN(MVCC) and PointNet, which are two deep learning models customized to learn and classify in 3 dimensional non-euclidean spaces, were used. The analysis was restricted to classifying subtypes of architectural walls. MVCNN resulted in the highest performance, with ACC and F1 score of 0.95 and 0.94.MVCNN unitizes images from multiple perspectives of an element, and was thus able to learn the nuanced differences of wall subtypes.PointNet, on the other hand, lost many of the detailed features as it uses a sample of the point clouds and perceived only the 'skeleton' of the given walls."
머신러닝을 통한 건축 도시 데이터 분석의 기초적 연구 - 딥러닝을 이용한 유동인구 모델 구축 -,2019,"['Machine learning', 'Deep learning', 'ANN', 'Urban planning', '머신러닝', '딥러닝', 'ANN', '도시 계획', '건축 계획']",,"In this paper, we construct a prototype model for city data prediction by using time series data of floating population, and use machine learning to analyze urban data of complex structure. A correlation prediction model was constructed using three of the 10 data (total flow population, male flow population, and Monday flow population), and the result was compared with the actual data. The results of the accuracy were evaluated. The results of this study show that the predicted model of the floating population predicts the correlation between the predicted floating population and the current state of commerce. It is expected that it will help efficient and objective design in the planning stages of architecture, landscape, and urban areas such as tree environment design and layout of trails. Also, it is expected that the dynamic population prediction using multivariate time series data and collected location data will be able to perform integrated simulation with time series data of various fields."
딥러닝 기반 자연어 처리에서 도메인 지식의 역할,2019,"['domain knowledge', 'natural language processing', 'tagging', 'segmentation', 'deep learning', '도메인 지식', '자연어처리', '형태소분석', '분절', '딥러닝']",,"In Symbolic AI, the domain knowledge was considered indispensable. In rule-based NLP, likewise, the linguistic knowledge played an important role. As probabilistic NLP and machine learning techniques develop, the role of domain knowledge shrank. As deep learning appears, even the role of feature engineering and domain knowledge has become almost zero.In order to prove the importance of domain knowledge even in this deep learning age, I built a parts-of-speech tagger of Korean. This task in Korean is challenging, due to morphophonological alternations, deletions and contractions. I reformulated this task of segmentation as that of classification. For this purpose, I examined a large corpus, and found empirically 200 types of mapping between an input syllable and an output string. Based on these categories, I built and trained an LSTM-based neural network. With this model of segmentation, the parts-of-speech tagging model is easily trained by the familiar sequence tagging algorithm. By combining these two models and a few dictionaries, I got 98.0% of the F1 score."
딥러닝에 기반한 병원 실내이미지의 감성어휘 분류,2019,"['분류', '감성어휘', '병원', '실내이미지', '딥러닝', 'Classification', 'Emotional adjective', 'Hospital', 'Indoor image', 'Deep learning']",,"This research suggests to classify Emotional adjective for the hospital indoor image. The aim of this study was twofold. First it is an attempt to overcome limitation of overfitting data with pre-process and Second it is an approach for prediction quantified the image data with Emotional adjective. The emotion is important because emotion interact between indoor and human. The hospital indoor image also have specialized emotional effect.Emotional adjective is necessary to verify throughout variety of source qualitative and quantitative research.recently it is getting more harder with I.R.B.(Institutional Review Board) than Emotional adjective data had made.This research is based on deep learning method for emotional adjective quantifiaction that can replace thousands of people’s cognition. In the proposed simulation, emotional colors are firstly processed in the frequency domain to indoor images which can be treated as an emotional image. For pre-processing Emotional colors are extracted from hospital image. and search the emotional adjetive to get indoor images to fed in CNN(Convolutional Neural Network). For the hospital indoor image clustered, emotional indoor image are fed in CNN. The output of the CNNs are fused using TF(TensorFlow) API. The input of the fusion is given to a support of Python language for image classification. The proposed system is evaluated using Tensor board - which is the proved data. This research has concluded that it is desirable to use TF for predicting the set of emotional adjective and it helps for emotion analysis efficiently. TF works for the emotional image classifying the hospital indoor images. The hospital image is classified using deep learning, and analysis of emotion as A is 80 percentage modern and B is 20 percent natural in a second for a thousand emotional colors. It is expected to use these results of research have for implications of emotional analysis that represent functions of the indoor images."
딥러닝을 이용한 스윙 시퀀스 영상 기반 3차원 골프 스윙 분석,2019,"['golf swing analysis', 'sequence image regression', 'deep learning']","빠르게 움직이는 골프 스윙 동작을 인간의 눈으로 평가하고 분석하는 것은 평가하는 사람의 주관에 따라 크게 달라질 수 있다. 본 논문에서는 최근 영상 인식 분야에서 좋은 성능을 나타내고 있는 딥러닝 기술을 이용해 단일 카메라 기반 스윙 분석 시스템의 한계를 극복하고, 3차원의 정량적 정보 추출 및 분석 방법을 연구한다. 먼저, 합성곱 신경망을 이용해 시퀀스 영상의 특징을 추출하고, 스윙 구간을 분류한다. 스윙 구간 정보를 갖는 시퀀스 특징은 양방향 장단기 메모리 기반의 스윙 분석 모델의 입력으로 사용되며, 바디-스웨이, 헤드-업, X-factor 분석을 수행한다. 각 분석 모델을 통한 스윙의 정량적 상태 예측 결과, 상체의 움직임 예측 RMSE 4.23, 머리 움직임 예측 RMSE 5.18, X-factor 예측 결과 RMSE 3.86의 성능으로 나타났다. 이 결과로 2차원 정면의 시퀀스 영상을 기반으로 3차원의 정량적 골프 스윙 분석이 가능함을 확인하였다.","The evaluation and analysis of the fast moving golf swing motion by human eyes can vary greatly depending on the evaluator's perspective. In this paper, we study the method of three-dimensional quantitative information extraction by overcoming the limitation of single camera based golf swing analysis system using deep learning which is showing good performance in image recognition field recently. First, the features of the sequence images are extracted using convolutional neural network, and the swing section is classified. Sequence features with swing section information are used as inputs to the bidirectional long short-term memory based swing analysis model, and perform body-swing, head-up, and X-factor value prediction. Experimental results showed that the performance of the upper body motion prediction RMSE 4.23, the head motion prediction RMSE 5.18, and the X-factor prediction result RMSE 3.86. As a result, it is confirmed that 2D frontal sequence images based 3D quantitative golf swing analysis is possible."
초중고 교육을 위한 딥러닝 기반 암석 분류기 개발,2019,"['딥 러닝', '텐서플로우', '이미지 인식', '암석 이미지', '교육', 'deep learning', 'tensorflow', 'image recognition', 'rock image', 'education']",,"These days, as Interest in Image recognition with deep learning is increasing, there has been a lot of research in image recognition using deep learning. In this study, we propose a system for classifying rocks through rock images of 18 types of rock(6 types of igneous, 6 types of metamorphic, 6 types of sedimentary rock) which are addressed in the high school curriculum, using CNN model based on Tensorflow, deep learning open source framework. As a result, we developed a classifier to distinguish rocks by learning the images of rocks and confirmed the classification performance of rock classifier. Finally, through the mobile application implemented, students can use the application as a learning tool in classroom or on-site experience."
딥러닝을 이용한 이변량 장기종속시계열 예측,2019,"['딥러닝', '장기종속시계열', 'LSTM', 'FIVARMA', 'VARFIMA', 'deep learning', 'long range dependent', 'LSTM', 'FARIMA', 'FIVARMA', 'VARFIMA']","본 논문에서는 딥러닝을 이용한 이변량 장기종속시계열(long-range dependent time series) 예측을 고려하였다. 시계열 데이터 예측에 적합한 LSTM(long short-term memory) 네트워크를 이용하여 이변량 장기종속시계열을 예측하고 이를 이변량 FARIMA(fractional ARIMA) 모형인 FIVARMA 모형과 VARFIMA 모형과의 예측 성능을 실증 자료 분석을 통해 비교하였다. 실증 자료로는 기능적 자기공명 영상(fMRI) 및 일일 실현 변동성(daily realized volatility) 자료를 이용하였으며 표본외 예측(out-of sample forecasting) 오차 비교를 통해 예측 성능을 측정하였다. 그 결과, FIVARMA 모형과 VARFIMA 모형의 예측값에는 미묘한 차이가 존재하며, LSTM 네트워크의 경우 초매개변수 선택으로 복잡해 보이지만 계산적으로 더 안정되면서 예측 성능도 모수적 장기종속시계열과 뒤지지 않은 좋은 예측 성능을 보였다.","We consider bivariate long range dependent (LRD) time series forecasting using a deep learning method. A long short-term memory (LSTM) network well-suited to time series data is applied to forecast bivariate time series; in addition, we compare the forecasting performance with bivariate fractional autoregressive integrated moving average (FARIMA) models. Out-of-sample forecasting errors are compared with various performance measures for functional MRI (fMRI) data and daily realized volatility data. The results show a subtle difference in the predicted values of the FIVARMA model and VARFIMA model. LSTM is computationally demanding due to hyper-parameter selection, but is more stable and the forecasting performance is competitively good to that of parametric long range dependent time series models."
딥러닝 기반의 이미지 분류를 이용한 패션 이미지 검색 웹사이트,2019,"['Computer vision', 'CNN', 'Deep learning', 'Image classification', 'Web']","기존에 존재하는 패션 웹 사이트 에서는 상의, 하의 등의 품목에서는 한 가지 종류의 옷에 대한 검색결과만 보여주기 때문에사용자가 원하는 옷에 대한 조합을 찾을 수 없다. 또 패션 시장이 성장함에 따라 소비자들은 다양한 패션 정보를 찾을 수 플랫폼을 요구하고 있다. 이러한 문제를 해결하고자 하여 딥러닝을 통한 이미지분류를 웹 사이트와 연동하고 SNS 기능을 접목하는 아이디어를 고안해냈다. 웹 사이트에 사용자가 본인의 이미지을 업로드하여 딥러닝 서버를 통해서 이미지의 특징을 파악하고 분류하여 저장한다. 사용자들은 저장된 정보를 가지고 여러 조합을 통해 원하는 이미지들을 검색할 수 있다. 또 SNS 기능을 통해사용자간의 커뮤니케이션이 활발하게 이루어질 수 있다. 이를 통해서 기존에 존재하는 패션 관련 사이트의 문제를 해결하는 방안을 마련하였다.","Existing fashion web sites show only the search results for one type of clothes in items such as tops and bottoms. As the fashionmarket grows, consumers are demanding a platform to find a variety of fashion information. To solve this problem, we devised theidea of linking image classification through deep learning with a website and integrating SNS functions. User uploads their ownimage to the web site and uses the deep learning server to identify, classify and store the image’s characteristics. Users can use thestored information to search for the images in various combinations. In addition, communication between users can be activelyperformed through the SNS function. Through this, the plan to solve the problem of existing fashion-related sites was prepared."
Dynamic Stale Synchronous Parallel 기법을 활용한 분산 병렬 딥러닝 구조,2019,"['딥러닝', 'Stale Synchronous Parallel(SSP)', '학습 진전율(LPR)', '동적 threshold', '대규모 학습 모델', 'Deep learning', 'Learning progress ratio(LPR)', 'Dynamic threshold', 'Large-scale learning model']",,"Recent deep learning architectures has been adopted to effectively share the heavy workload over multiple nodes. Since each node is learning with a subset of data or models in such multiple node architectures, however, continuous synchronization between nodes is required to maintain consistency to manage global learning model parameters, and thus, learning time and accuracy are significantly affected by synchronization techniques. In this paper, we propose a DTSSP (dynamic threshold stale synchronous parallel) method which utilize local parameter cache and dynamic threshold based on real-time learning progress ratio (LPR), and evaluates the performance with those of other methods. The method significantly reduces synchronization overhead and network overhead resulting from large-scale parallel learning methods."
딥러닝을 이용한 차로이탈 경고 시스템,2019,"['Lane departure warning system', 'Advanced driver assistance system', 'Deep learning', '차선이탈 경고시스템', '첨단 운전자 지원 시스템', '딥러닝']",최근 인공지능 기술이 급격히 발전하면서 첨단 운전자 지원 시스템 분야에 딥러닝 기술을 접목하여 기존의 기술보다 뛰어난 성능을 보여주기 위한 여러 연구들이 진행 되고 있다. 이러한 동향 에 맞춰 본 논문 또한 첨단 운전자 지원 시스템의 핵심 요소 중 하나인 차로이탈 경고시스템에 딥러 닝 기술을 접목한 방법을 제안한다. 제안하는 방법과 기존의 차선검출 기반의 경고시스템과의 비교 실 험을 통해 그 성능을 평가 하였다. 고속도로 주행영상과 시내 주행영상을 이용한 두 가지의 서로 다른 환경에서 모두 제안하는 방법이 정확도 및 정밀도 부분에서 더 높은 수치를 보여주었다.,
딥러닝 기반의 구조물 화재 재난 시 최적 대피로 안내 시스템,2019,,"구조물에서 화재 발생 시 화재의 발생 위치를 정확하게 파악하지 못해 화재 진압이 용이하지 못하는 문제, 연기나 유독가스로 시야 확보가 어려운 상태에서 비상구 및 탈출로에 대한 정보를 방향지시기와 LED 유도등에 의존하여 위험에 빠지는 문제가 빈번히 발생하고 있다. 이에 본 논문에서는 딥러닝 기반(RNN) 구조물 재난 시 최적의 대피로를 안내할 수 있는 시스템 알고리즘을 제시한다. 설치되어 있는 감지 센서를 이용하고, 센서별 검출된 데이터를 서버로 실시간 전송되며, 감지 센서 주변의 온도, 열, 연기, 유독가스 등의 정보가 전달된다. 그리고 이를 분석하고, 설정된 임계치 범위 내에 있는 가장 안전한 이동 경로를 파한다. 이때 구조물 내에 있는 LED 유도등과 방향지시기에 실시간으로 정보를 전달하여 위험 요소를 피할 수 있는 서비스를 제공해 준다. 이는 구조물의 각 구역별 온도, 열, 연기, 유독가스의 정보를 파악할 수 있어, 구조물 재난 시 최적의 대피로를 안내받을 수 있을 것이라고 사료된다.",
딥러닝을 활용한 흔들림 영상 안정화 알고리즘,2019,"['Stabilization', 'Feature map', 'CNN', 'LSTM']","본 논문에서는 딥러닝을 활용한 흔들림 영상 안정화 알고리즘을 제안하였다. 제안하는 알고리즘은 기존 몇 가지2D, 2.5D 및 3D 기반 안정화 기술과 다르게 딥러닝을 활용한다. 제안하는 알고리즘은 흔들리는 영상을 CNN 네트워크 구조와 LSTM 네트워크 구조를 통한 특징 추출 및 비교하여 이전 프레임과 현재 프레임 간의 특징점 위치 차이를 통해 특징점의이동 크기와 방향의 반대로 영상을 변환하는 알고리즘이다. 흔들림 안정화를 위한 알고리즘은 각 프레임의 특징 추출 및비교를 위해 Tensorflow를 활용하여 CNN 네트워크과 LSTM 구조를 구현하였으며, 영상 흔들림 안정화는 OpenCV open source를 활용해 구현하였다. 실험결과 영상의 흔들림이 상하좌우로 흔들리는 영상과, 급격한 카메라 이동이 없는 영상을실험에 사용하여, 제안한 알고리즘을 적용한 결과 사용한 상하좌우 흔들림 영상에서는 안정적인 흔들림 안정화 성능을 기대할 수 있었다.","In this paper, we proposed a shaking image stabilization algorithm using deep learning. The proposed algorithm utilizes deep learning, unlike some 2D, 2.5D and 3D based stabilization techniques. The proposed algorithm is an algorithm that extracts and compares features of shaky images through CNN network structure and LSTM network structure, and transforms images in reverse order of movement size and direction of feature points through the difference of feature point between previous frame and current frame. The algorithm for stabilizing the shake is implemented by using CNN network and LSTM structure using Tensorflow for feature extraction and comparison of each frame. Image stabilization is implemented by using OpenCV open source. Experimental results show that the proposed algorithm can be used to stabilize the camera shake stability in the up, down, left, and right shaking images."
딥러닝 기반의 대퇴골 영역 분할을 위한 훈련 데이터 증강 연구,2019,"['데이터 증강', '딥러닝', '의료영상', '영역 분할', 'Data augmentation', 'Deep learning', 'Medical image', 'Image segmentation']","본 연구에서는 CT 영상의 대퇴골 부위를 해부학적으로 의미 있게 변형하여 CT 영상의 대퇴골 영역을 분할하기 위한 컨벌루션 신경망(CNN)의 훈련 데이터를 증강하는 방법을 제안한다. 먼저 CT 영상으로부터 삼차원 삼각형 대퇴골 메쉬를 얻는다. 그 후 메쉬의 국소부위에 대한 기하학적 특성을 계산하고, 군집화하여 메쉬를 의미 있는 부분들로 분할한다. 마지막으로, 분할한 부분들을 적절한 알고리즘으로 변형한 뒤, 이를 바탕으로 CT 영상을 와핑하여 새로운 CT영상을 생성하였다. 본 연구의 데이터 증강 방법을 이용하여 학습시킨 딥러닝 모델은 기하학적 변환이나 색상 변환 같이 일반적으로 사용되는 데이터 증강법과 비교하여 더 나은 영상분할 성능을 보인다.","In this study, we modified CT images of femoral head in consideration of anatomically meaningful structure, proposing the method to augment the training data of convolution Neural network for segmentation of femur mesh model. First, the femur mesh model is obtained from the CT image. Then divide the mesh model into meaningful parts by using cluster analysis on geometric characteristic of mesh surface. Finally, transform the segments by using an appropriate mesh deformation algorithm, then create new CT images by warping CT images accordingly. Deep learning models using the data enhancement methods of this study show better image division performance compared to data augmentation methods which have been commonly used, such as geometric conversion or color conversion."
딥러닝 기반의 주행가능 영역 추출 모델에 관한 연구,2019,"['Drivable area segmentation', 'Segmentation', 'Deep Learning', 'DeepLab V3+', 'Mask R-CNN', 'BDD Dataset', '주행가능 영역 추출', '영상 분할', '딥러닝', 'DeepLab V3+', 'Mask R-CNN', 'BDD 데이터셋']","인공지능, 빅데이터, 자율주행 등 4차 산업혁명시대를 이끄는 핵심기술은 컴퓨팅 파워의 급속한 발전과 사물인터넷에 기반한 초연결 네트워크를 통해 구현되고 서비스된다. 본 논문에서는 자율주행을 위한 기본적인 기능으로 다양한 환경에서도 정확하게 주행가능한 영역을 인식하여 추출하는 인공지능 딥러닝 모델들을 구현하고, 그 결과를 비교, 분석한다. 주행가능한 영역을 추출하는 딥러닝모델은 영상 분할 분야에서 성능이 우수하고 자율주행 연구에서 많이 사용하는 Deep Lab V3+와 Mask R-CNN을 활용하였다. 다양한환경에서의 주행 정보를 위해 여러 가지 날씨 조건과 주·야간 환경에서의 주행 영상 및 이미지를 제공하는 BDD 데이터셋을 학습데이터로 사용하였다. 활용한 모델들의 실험 결과, DeepLab V3+는 48.97%의 IoU를 보였으며, Mask R-CNN은 68.33%의 IoU로 더 우수한성능을 보였다. 또한, 구현한 모델로 추출된 주행가능 영역을 이미지에 표시하여 육안으로 검사한 결과, Mask R-CNN은 83%, Deep Lab V3+는 69% 정확도로 Mask R-CNN이 Deep Lab V3+ 보다 주행가능한 영역을 추출하는 분야에서는 더 성능이 높은 것으로 확인하였다.","Core technologies that lead the Fourth Industrial Revolution era, such as artificial intelligence, big data, and autonomous driving, are implemented and serviced through the rapid development of computing power and hyper-connected networks based on the Internet of Things. In this paper, we implement two different models for drivable area segmentation in various environment, and propose a better model by comparing the results. The models for drivable area segmentation are using DeepLab V3+ and Mask R-CNN, which have great performances in the field of image segmentation and are used in many studies in autonomous driving technology. For driving information in various environment, we use BDD dataset which provides driving videos and images in various weather conditions and day&night time. The result of two different models shows that Mask R-CNN has higher performance with 68.33% IoU than DeepLab V3+ with 48.97% IoU. In addition, the result of visual inspection of drivable area segmentation on driving image, the accuracy of Mask R-CNN is 83% and DeepLab V3+ is 69%. It indicates Mask R-CNN is more efficient than DeepLab V3+ in drivable area segmentation."
딥러닝을 이용한 판류형 간판의 인식,2019,"['Signboard Detection', 'Flat Type', 'Faster Region-Based Convolutional Neural Network', 'Watershed', 'K-Means Clustering', 'Boundary Area', '간판 인식', '판류형', 'Faster R-CNN', '워터쉐드', 'K-평균 군집화', '경계 영역']","간판은 유형마다 간판의 규격이 정해져 있으나 실제 설치된 간판은 형태와 크기가 일정하지 않다. 또한, 간판은 간판 내부의 색상에 대한 규정이 정해져 있지 않기 때문에 다양한 색상을 갖고 있다. 간판을 인식하기 위한 방법은 도로표지판과 차량번호판을 인식하는 유사한 방법으로 생각할 수 있으나 간판의 특성으로 인해 도로표지판과 차량번호판과 유사한 방법으로 간판을 인식할 수 없는 한계점이 있다. 이에 본 연구에서는 딥러닝 기반의 Faster R-CNN 알고리즘을 이용하여 불법 및 노후 간판의 주요 대상이 되는 판류형 간판을 인식하고 간판의 영역을 자동으로 추출하는 방법론을 제안하였다. 스마트폰 카메라를 이용하여 촬영한 간판 영상을 통해 판류형 간판을 인식하는 과정은 2가지의 순서로 나뉜다. 먼저, 다양한 유형의 간판 영상에서 판류형 간판을 인식하기 위해 딥러닝을 이용하여 간판의 유형을 인식하였으며 그 결과는 약 71%의 정확도로 나타났다. 다음으로 판류형 간판의 경계영역을 인식하기 위해 간판 영역 인식 알고리즘을 적용하였을 때 85%의 정확도로 판류형 간판의 경계영역을 인식하였다.","The specifications of signboards are set for each type of signboards, but the shape and size of the signboard actually installed are not uniform. In addition, because the colors of the signboard are not defined, so various colors are applied to the signboard. Methods for recognizing signboards can be thought of as similar methods of recognizing road signs and license plates, but due to the nature of the signboards, there are limitations in that the signboards can not be recognized in a way similar to road signs and license plates. In this study, we proposed a methodology for recognizing plate-type signboards, which are the main targets of illegal and old signboards, and automatically extracting areas of signboards, using the deep learning-based Faster R-CNN algorithm. The process of recognizing flat type signboards through signboard images captured by using smartphone cameras is divided into two sequences. First, the type of signboard was recognized using deep learning to recognize flat type signboards in various types of signboard images, and the result showed an accuracy of about 71%. Next, when the boundary recognition algorithm for the signboards was applied to recognize the boundary area of the flat type signboard, the boundary of flat type signboard was recognized with an accuracy of 85%."
딥러닝을 이용한 연안방재 시스템 구축에 관한 연구,2019,"['방재 시스템', '인공지능', '딥러닝', '빅데이터', 'Disaster prevention system', 'Artificial intelligence', 'Deep learning', 'Big data']",,"Numerous deaths and substantial property damage have occurred recently due to frequent disasters of the highest intensity according to the abnormal climate, which is caused by various problems, such as global warming, all over the world. Such large-scale disasters have become an international issue and have made people aware of the disasters so they can implement disaster-prevention measures. Extensive information on disaster prevention actively has been announced publicly to support the natural disaster reduction measures throughout the world. In Japan, diverse developmental studies on disaster prevention systems, which support hazard map development and flood control activity, have been conducted vigorously to estimate external forces according to design frequencies as well as expected maximum frequencies from a variety of areas, such as rivers, coasts, and ports based on broad disaster prevention data obtained from several huge disasters. However, the current reduction measures alone are not sufficiently effective due to the change of the paradigms of the current disasters. Therefore, in order to obtain the synergy effect of reduction measures, a study of the establishment of an integrated system is required to improve the various disaster prevention technologies and the current disaster prevention system. In order to develop a similar typhoon search system and establish a disaster prevention infrastructure, in this study, techniques will be developed that can be used to forecast typhoons before they strike by using artificial intelligence (AI) technology and offer primary disaster prevention information according to the direction of the typhoon. The main function of this model is to predict the most similar typhoon among the existing typhoons by utilizing the major typhoon information, such as course, central pressure, and speed, before the typhoon directly impacts South Korea. This model is equipped with a combination of AI and DNN forecasts of typhoons that change from moment to moment in order to efficiently forecast a current typhoon based on similar typhoons in the past. Thus, the result of a similar typhoon search showed that the quality of prediction was higher with the grid size of one degree rather than two degrees in latitude and longitude."
딥러닝 기반의 영상분할을 이용한 토지피복분류,2019,"['Land cover', 'Semantic segmentation', 'SegNet', 'Classification']","본 연구에서는 항공정사영상을 이용하여 SegNet 기반의 의미분할을 수행하고, 토지피복분류에서의그 성능을 평가하였다. 의미분할을 위한 분류 항목을 4가지(시가화건조지역, 농지, 산림, 수역)로 선정하였고, 항공정사영상과 세분류 토지피복도를 이용하여 총 2,000개의 데이터셋을 8:2 비율로 훈련(1,600개) 및 검증(400개)로 구분하여 구축하였다. 구축된 데이터셋은 훈련과 검증으로 나누어 학습하였고, 모델 학습 시 정확도에 영향을 미치는 하이퍼파라미터의 변화에 따른 검증 정확도를 평가하였다. SegNet 모델 검증 결과 반복횟수100,000회, batch size 5에서 가장 높은 성능을 보였다. 이상과 같이 훈련된 SegNet 모델을 이용하여 테스트 데이터셋 200개에 대한 의미분할을 수행한 결과, 항목별 정확도는 농지(87.89%), 산림(87.18%), 수역(83.66%), 시가화건조지역(82.67%), 전체 분류정확도는 85.48%로 나타났다. 이 결과는 기존의 항공영상을 활용한 토지피복분류연구보다 향상된 정확도를 나타냈으며, 딥러닝 기반 의미분할 기법의 적용 가능성이 충분하다고 판단된다. 향후 다양한 채널의 자료와 지수의 활용과 함께 분류 정확도 향상에 크게 기여할 수 있을 것으로 기대된다.","We evaluated the land cover classification performance of SegNet, which features semantic segmentation of aerial imagery. We selected four semantic classes, i.e., urban, farmland, forest, and water areas, and created 2,000 datasets using aerial images and land cover maps. The datasets were divided at a 8:2 ratio into training (1,600) and validation datasets (400); we evaluated validation accuracy after tuning the hyperparameters. SegNet performance was optimal at a batch size of five with 100,000 iterations. When 200 test datasets were subjected to semantic segmentation using the trained SegNet model, the accuracies were farmland 87.89, forest 87.18, water 83.66, and urban regions 85.48%; the overall accuracy was 85.48%. Thus, deep learning-based semantic segmentation can be used to classify land cover."
한국인 영어학습자의 영어 문장은 얼마나 원어민스러운가: 딥러닝 기반 분석,2019,"['딥러닝', '분류', '학습자 코퍼스', '오류 분석', 'deep learning', 'classification', 'learner corpus', 'error analysis']",,"Building upon the state-of-the-art deep learning techniques, the present study classifies the texts written by Korean EFL learners and English native speakers and thereby demonstrates how the two types of texts differ from each other. To this end, the current work makes use of the Yonsei English Learner Corpus (YELC) and Gacheon Learner Corpus (GLC) as the L2 data, and Corpus of Contemporary American English (COCA) as the L1 data. Utilizing the sentence classification methods, the current work implements a system to differentiate the two types of texts, the accuracy of which is about 94%. This indicates that the deep leaning-based system is capable of identifying the well-formedness and felicities of the texts written by Korean EFL learners. Nonetheless, the system-based judgments do not overlap with human judgments largely because the deep learning model exclusively focuses on sequence of words. The present study provides a further analysis to see how the two types of judgments differ with respect to grammatical errors (e.g., word order, voice, etc.) and felicity errors (e.g., semantic prosody, the position of adverbs, etc.)."
딥러닝을 이용한 한국의 물류경쟁력에 관한 연구,2019,"['물류성과지수', '국가경쟁력 지수', '딥러닝', '인공신경망', 'Logistics Performance Index', 'Global Competitiveness Index', 'Deep Learning', 'Artificial Neural Network']",,"Purpose: According to the World Logistics Performance Index (LPI) released by the World Bank, Korea ranks 21st in 2014, 24th in 2016 and 25th in 2018 among 160 countries. Therefore, the purpose of this study is to analyze the reason why the LPI index is lowered even though various logistics policies are being pursued.Composition/Logic: In order to identify the most important factors affecting LPI in terms of Global Competitive Index(GCI), we analyzed it by using deep learning algorithm. In fact, the deep learning technique has a limitation in accurately interpreting the relative importance of the input value to the output value. Thus, scenario analysis was applied to overcome these limitations.Findings: For improving LPI performance, it was found that the burden of government regulations, cooperation among multiple stakeholders, salary and productivity, efficiency of customs procedures, high-speed internet subscribers, corruption index, road connection, labor tax rate, willingness of delegation, tariff complexity, tariff rate were the most influential factors in Korea.Originality/Value: It is meaningful that we analyzed logistics competitiveness at national level by linking with economic indicators and analyzing such interlinkages using deep learning algorithm. Especially, in Korea, the importance of social factors such as corruption index and independence of the judiciary as well as economic factors were also found to be important factors for improvement of national logistics performance."
딥러닝을 이용한 시계열데이터 군집화,2019,"['Deep Learning', 'Deep Embedding Clustering', 'Time Series Data']",,"Purpose: This paper presents the clustering results of time series multiple sensor data using deep neural networks based unsupervised learning algorithm without target variables.Methods: Time series data collected from multiple sensors were clustered using two clustering algorithms based on deep learning: Deep Embedding Clustering (DEC) and Jointly Deep Embedding Clustering (JDEC). DEC and JDEC are designed based on the autoencoder and the convolutional neural network, which are representative neural network structures. They allow highdimensional data to be represented by low-dimensional data and clustered based on their corresponding low-dimensional values.Results: Two data sets, real time series data collected from manufacturing processes and simulated data, were used in the experiments. The simulated data’s performance was evaluated for accuracy, while the clustering performance of the real data was visually evaluated by mapping data and their clusters into a two-dimensional space. The experimental results show that the proposed methods were more accurate than K-means clustering.Conclusion: Real time series data collected from manufacturing processes and simulated data were analyzed and meaningful clustering results were obtained. The proposed methods enabled the unsupervised learning of time series multiple sensor data without target variables by a deep neural network and showed good clustering performance."
딥러닝 기반 이미지 자동 레이블링을 활용한 건축물 파사드 데이터세트 구축 기술 개발,2019,"['건설 데이터세트', '건설 데이터베이스', '딥러닝', '파사드', '자동 레이블링', 'Construction Dataset', 'Construction Database', 'Deep Learning', 'Facade', 'Automatic Image Labeling']",,"The construction industry has made great strides in the past decades by utilizing computer programs including CAD. However, compared to other manufacturing sectors, labor productivity is low due to the high proportion of workers"" knowledge-based task in addition to simple repetitive task. Therefore, the knowledge-based task efficiency of workers should be improved by recognizing the visual information of computers. A computer needs a lot of training data, such as the ImageNet project, to recognize visual information. This study, aim at proposing building facade datasets that is efficiently constructed by quickly collecting building facade data through portal site road view and automatically labeling using deep learning as part of construction of image dataset for visual recognition construction by the computer. As a method proposed in this study, we constructed a dataset for a part of Dongseong-ro, Daegu Metropolitan City and analyzed the utility and reliability of the dataset. Through this, it was confirmed that the computer could extract the significant facade information of the portal site road view by recognizing the visual information of the building facade image. Additionally, In contribution to verifying the feasibility of building construction image datasets. this study suggests the possibility of securing quantitative and qualitative facade design knowledge by extracting the facade design knowledge from any facade all over the world."
딥러닝 객체인식을 통한 경로보정 자율 주행 로봇의 구현,2019,"['Wheeled Mobile Robot', 'Path Finding', 'Deep Reinforcement Learning', 'Deep Learning', 'Autonomous Driving Robot', '바퀴식 주행로봇', '경로 찾기', '딥강화학습', '딥러닝', '자율주행로봇']",본 논문에서는 실내 환경에서 시각정보를 기반으로 출발지점에서 경유지를 거쳐 목표지점으로 최적의 경로를 찾아 자율 주행하는 바퀴달린 로봇을 구현한다. 로봇은 출발지점에서 경유지를 거쳐 목표지점으로의 최적의 경로를 딥강화학습으로 얻을 수 있다. 그러나 로봇이 구해진 경로로 자율 주행을 할 때 표면의 굴곡과 이물질 등의 외부적 요인으로 목적지까지 정확하게 주행하지 못하는 경우가 발생한다.이에 본 연구는 카메라만 장착한 로봇이 외부 요인으로 인해 최적의 경로를 이탈할 경우 이를 인지하도록 한다. 이 인지를 토대로 로봇이 스스로 경로를 보정하고 계획된 경유지와 최종 목적지점에 도달할 수 있게 하는 알고리즘을 제안한다.본 연구를 위해 파이캠을 탑재한 라즈베리파이와 아두이노로 제어하는 바퀴식 자율 주행 로봇이 제작되었다. 로봇은 실내환경에서 OSX 환경의 서버와 실시간 연동하면서 계획된 최적의 경로로 시험주행을 완료하였다.,"In this paper, we implement a wheeled mobile robot that accurately and autonomously finds the optimal route from the starting point to the destination point based on computer vision in a complex indoor environment. We get a number of waypoints from the starting point to get the best route to the target through deep reinforcement learning. However, in the case of autonomous driving, the majority of cases do not reach their destination accurately due to external factors such as surface curvature and foreign objects. Therefore, we propose an algorithm to deepen the waypoints and destinations included in the planned route and then correct the route through the waypoint recognition while driving to reach the planned destination.We built an autonomous wheeled mobile robot controlled by Arduino and equipped with Raspberry Pi and Pycamera and tested the planned route in the indoor environment using the proposed algorithm through real-time linkage with the server in the OSX environment."
딥러닝 기반 카메라 모델 판별,2019,"['딥러닝', '카메라 모델 판별', '컨볼루셔널 뉴럴 네트워크', '고주파 통과 필터', '명암도 동시발생 행렬', 'Deep Learning', 'Camera Model Identification', 'Convolutional Neural Network', 'High Pass Filter', 'Gray Level Co-Occurrence Matrix']",,"Camera model identification has been a subject of steady study in the field of digital forensics. Among the increasingly sophisticated crimes, crimes such as illegal filming are taking up a high number of crimes because they are hard to detect as cameras become smaller. Therefore, technology that can specify which camera a particular image was taken on could be used as evidence to prove a criminal's suspicion when a criminal denies his or her criminal behavior. This paper proposes a deep learning model to identify the camera model used to acquire the image. The proposed model consists of four convolution layers and two fully connection layers, and a high pass filter is used as a filter for data pre-processing. To verify the performance of the proposed model, Dresden Image Database was used and the dataset was generated by applying the sequential partition method. To show the performance of the proposed model, it is compared with existing studies using 3 layers model or model with GLCM. The proposed model achieves 98% accuracy which is similar to that of the latest technology."
공개 딥러닝 라이브러리에 대한 보안 취약성 검증,2019,"['Adversarial attack', 'MNIST', 'deep learning', 'security', 'autoencoder', 'convolution neural network']","최근 다양한 분야에서 활용중인 딥러닝은 적대적 공격 가능성의 발견으로 위험성이 제기되고 있다. 본 논문에서는딥러닝의 이미지 분류 모델에서 악의적 공격자가 생성한 적대적 샘플에 의해 분류 정확도가 낮아짐을 실험적으로 검증하였다. 대표적인 이미지 샘플인 MNIST데이터 셋을 사용하였으며, 텐서플로우와 파이토치라이브러리를 사용하여만든 오토인코더 분류 모델과 CNN(Convolution neural network)분류 모델에 적대적 샘플을 주입하여 탐지정확도를 측정한다. 적대적 샘플은 MNIST테스트 데이터 셋을 JSMA(Jacobian-based Saliency MapAttack)방법으로 생성한 방법과 FGSM(Fast Gradient Sign Method)방식으로 변형하여 생성하였으며, 분류모델에 주입하여 측정하였을 때 최소 21.82%에서 최대 39.08%만큼 탐지 정확도가 낮아짐을 검증하였다.","Deep Learning, which is being used in various fields recently, is being threatened with Adversarial Attack. In this paper,we experimentally verify that the classification accuracy is lowered by adversarial samples generated by malicious attackersin image classification models. We used MNIST dataset and measured the detection accuracy by injecting adversarialsamples into the Autoencoder classification model and the CNN (Convolution neural network) classification model, which arecreated using the Tensorflow library and the Pytorch library. Adversarial samples were generated by transforming MNISTtest dataset with JSMA(Jacobian-based Saliency Map Attack) and FGSM(Fast Gradient Sign Method). When injected into theclassification model, detection accuracy decreased by at least 21.82% up to 39.08%."
영상처리와 딥러닝 기법을 사용한 채소의 등급별 자동 분류시스템 개발,2019,"['채소 자동분류 시스템', '기계학습 기법', 'CNN', 'VGGNet', '오이 실험영상.', 'vegetable automatic classification system', 'machine learning techniques', 'CNN', 'VGGNet', 'cucumber experiment image.']","농업에서 생산된 과수나 채소에 대한 질을 확인하고 향상시키는 작업은 영상처리에서 굉장히 중요한 부분이다. 실제 농가에서는 스마트팜(smart_farm)을 도입하여 생산량의 증가로 자연히 수익을 늘어나고 또 노동시간이 단축되며 여가시간이 늘어 농가의 삶의 질을 높일 수 있게 되었다. 본 논문에서는 영상처리 기법과 딥러닝 기술을 사용하여 채소의 등급을 자동 분류하기 위한 시스템을 소개한다. 이를 목적으로 농가에서 직접 재배한 오이를 동일한 배경에서 촬영하여 이미지 데이터와 데이터 증가(augmentation) 기법을 통해 데이터셋을 구성하고 3가지 등급으로 분류하기 위한 기계학습방법인 SVM과 딥러닝 방법인 CNN, VGGNet 등을 사용하였다. 또한 본 연구는 대규모 데이터에서 오이를 기계가 자동으로 중요한 패턴과 규칙을 학습하고 의사결정과 예측 등을 하기 위해 구조나 손실 및 활성화 함수들 그리고 학습비율과 같은 하이퍼 파라미터(hyper-parameter)등을 변경시켜 가며 더 좋은 분류 성능을 내는 알고리즘을 개발하였다. 또한 실험을 통해서 제안된 알고리즘이 농업현장에서 취득한 영상자료를 사용해서 오이를 등급별로 잘 구별하는 것을 확인 할 수 있었다. 앞으로 이를 발전시켜 더 좋은 데이터를 많이 확보하고 훈련을 시킨다면 자동분류 시스템의 개발에 더 좋은 성능이 기대되며, 다양한 방면에 활용이 가능 할 것이다.","Identifying and improving the quality of fruits and vegetables produced in agriculture is a very important part of image processing. The introduction of smart_farm in the farmhouse increased production and naturally increased profit of the farmer. In addition, their working hours have been shortened and leisure time has been increased, so that the quality of life of the farmers can be increased. In this paper, we introduce a system for automatically classifying vegetable grades using image processing and deep-learning techniques. For this purpose, We obtained image data of cucumber cultivated directly in a farmhouse on the same background and constructed a data set using data augmentation technique. In order to classify cucumber into three classes, we used SVM, which is a machine running method, and CNN and VGGNet, which are deep running methods. In this study, we also modified the hyper-parameters such as structure, loss and activation functions and learning rate in order to learn the important patterns and rules of the machine automatically from large data and to make decisions and predictions. Experimental results show that the proposed algorithm can distinguish the cucumber by grade using image data obtained from farming sites. If we improve the performance of the automatic classification system by securing much better data and training, then it can be applied to various aspects."
사용자 인증을 위한 딥러닝 기반 얼굴인식 기술 동향,2019,"['얼굴인식', '사용자인증', '딥러닝', '인증', '다중 인증', 'Face Recognition', 'User Authentication', 'Deep Learning', 'Authentication', 'Multi-Factor Authentication']",,
단어 임베딩과 어텐션 기반의 딥러닝 모델을 활용한 장소정보 탐지 기법,2019,"['장소정보', '어텐션', '딥러닝', '단어 임베딩', '자연어처리', 'POI', 'Location Information', 'Attention', 'Deep Learning', 'Word Embedding', 'Natural Language Processing']","최근 소셜미디어 플랫폼의 활용이 증가함에 따라 장소정보를 포함하고 있는 수많은 텍스트 데이터가 발생하고 있다. 다수의 플랫폼이 장소정보를 입력하는 기능을 제공하고 있지만, 지오태깅 된 게시물의 수가 적어 장소정보가 제대로 활용되지 못하고 있다. 텍스트 내 장소정보를 활용하기 위해 기존에는 BIO(Beginning-Inside-Outside)태깅을 이용한 개체명인식을 통해 지명 등을 추출하는 연구들이 진행되었지만, BIO태깅에는 상당한 시간과 인력이 소모되며 보통명사는 태깅하지 않는다. 이에 본 연구는 장소정보 포함 여부에 따른 라벨링을 하고, 단어 임베딩과 어텐션 기반의 딥러닝 모델을 활용하여 장소정보를 포함했는지의 이진 분류기 학습을 통해 보통명사를 포함한 확장된 범위의 장소정보를 탐지하였다. 실험 데이터에 대한 장소정보 포함 여부 탐지 정확도는 약 88%이며, AUC 0.945의 성능을 보였고, 제안한 방법을 통해 문장 내 장소정보를 시각화 및 추출도 가능한 것을 확인하였다.","Recently, as the use of the social media platform increases, a lot of unstructured text data including location information is generated. Although such platforms provide the function of adding location information, the use of location information is limited due to a small number of geotagged posts. In order to make use of these location information in the text, named entity recognition using BIO(beginning-inside-outside)tagging was used to extract locational information. However, it takes considerable time and manpower labeling and ignores common nouns. In this study, we detect extended location information including common nouns by training binary classifier using word embedding and attention-based deep learning model. The proposed model showed about 88% accuracy and AUC of 0.945 in detecting location information, which can also be visualized or extracted."
GPR 영상에서 딥러닝 기반 CNN을 이용한 배관 위치 추정 연구,2019,"['sink holes', 'pipe', 'GPR', 'image recognition', 'underground detection', 'CNN', 'deep-learning', '지하공동', '배관', 'GPR영상', '지하 탐지', '영상 인식', '딥러닝', '컨볼루션 뉴럴 네트워크']",최근에 지하공동이나 배관의 위치 파악 등의 필요에 의해 금속을 포함하여 다양한 재질의 지하 물체를 탐지하는 일이 중요해지고있다. 이러한 이유로 지하 탐지 분야에서 GPR(Ground Penetrating Radar) 기술이 주목을 받고 있다. GPR은 지하에 묻혀 있는 물체의위치를 찾기 위하여 레이더파를 조사하고 물체로부터 반사되는 반사파를 영상으로 표현한다. 그런데 레이더 신호는 지하에서 여러가지 물체에서 반사되어 나오는 특징이 물체마다 유사한 경우가 많기 때문에 GPR 영상을 해석하는 것은 쉽지 않다. 따라서 본 논문에서는 이러한 문제를 해결하기 위해서 영상 인식 분야에서 최근에 많이 활용되고 있는 딥러닝 기반의 CNN(Convolutional Neural Network)모델을 이용하여 임계값에 따른 GPR 영상에서의 배관 위치를 추정하고 그 실험 결과 임계값이 7 혹은 8 일 때 가장 확실하게 배관의 위치를 찾음을 증명하였다,"In recently years, it has become important to detect underground objects of various marterials including metals, such as detecting the location of sink holes and pipe. For this reason, ground penetrating radar(GPR) technology is attracting attention in the field of underground detection. GPR irradiates the radar wave to find the position of the object buried underground and express the reflected wave from the object as image. However, it is not easy to interpret GPR images because the features reflected from various objects underground are similar to each other in GPR images. Therefore, in order to solve this problem, in this paper, to estimate the piping position in the GRP image according to the threshold value using the CNN (Convolutional Neural Network) model based on deep running, which is widely used in the field of image recognition, As a result of the experiment, it is proved that the pipe position is most reliably detected when the threshold value is 7 or 8."
시각장애인을 위한 딥러닝 기반 인물 위주 이미지 캡션 방법,2019,"['Blind', 'Face Recognition', 'Image Captioning', 'Image segmentation', 'DVS']","본 논문에서는 영상의 시각적인 정보를 딥러닝을 이용하여 시각장애인들에게 영상 내 등장인물과 배경을 인식하여 제공하는 시스템을 제안한다. 시각장애인들은 드라마, 영화, 광고 등 영상에서 장소, 행위, 등장인물 등 영상에 나타나는 시각적인 정보들을 제한적으로 시청하고 있어 시각적인 정보들을 화면해설방송을 사용하여 얻고 있다. 하지만 화면해설방송은 화면해설작가가 영상 정보를 수집하여 대본을 쓴 뒤 성우가 녹음을 진행하고, 화면해설 전문엔지니어가 영상 작업을 해야만 시청이 가능한 불편함을 갖는다. 이를 개선하고자 히스토그램을 이용하여 영상을 자동으로 분할하고, 등장인물들은 CNN을 이용하여 인물 별로 학습시킨 후 분류하며, 영상의 이미지를 MSCOCO 데이터 셋을 이용하여 학습시켜 이미지에 대한 행동, 배경들을 묘사한 정보를 이미지 캡션을 한다. 위의 결과를 통해 얻어진 이미지 캡션 결과에 대해서 20대 이상의 성인을 대상으로 영상내의 시각적인 정보와 비교하는 정성적 평가를 진행함으로서 시각장애인들에게 시각적인 영상 정보를 제공함을 확인할 수 있다.","In this paper, we propose a system for visually impaired people to recognize visual characters and background in visual images by using deep learning. For people with visual impaired, since there is a limitation to viewing visual information such as place, action, character, etc. that appear in the video such as drama, movie or advertisement, they can only get those visual information from the Descriptive Video Service(DVS). However, screen commentary broadcasts are inconvenienced when the screenwriter collects the video information and writes the script, and the voice actor carries out the recording and the professional engineer of the screen commentary performs the video work. To improve this, the image is automatically segmented using the histogram, the characters are learned and classified by the person using CNN, and the image of the image is learned using the MSCOCO data set to describe the behavior and background of the image Captures image information. The image caption obtained from the above results can be confirmed to provide visual image information to the visually impaired by carrying out a qualitative evaluation comparing with the visual information in the image of the adult over 20 persons."
불완전한 데이터를 위한 딥러닝 모델,2019,"['Deep learning model', 'Extended data expression', 'Incomplete data', 'Attribute value', 'EBP', '딥러닝 모델', '확장된 데이터 표현', '불완전한 데이터', '속성값', 'EBP']","제안 모델은 소실 데이터를 포함하는 불완전한 데이터에서 정보의 손실을 최소화할 수 있도록 개발되었다. 이를 위한 과정은 우선 데이터 확장기법을 이용하여 손실 정보를 보상하도록 학습 데이터를 변환한다. 이 변환 과정에서 데이터의 속성값은 원-핫 인코딩으로 이진 또는 확률값으로 채워진다. 다음 이 변환 데이터는 딥러닝 모델에 입력되는데, 이때 각 속성의 카디너리티에 따라 엔트리 수가 일정하지 않게 된다. 그리고 각 속성의 엔트리 값들을 각각의 입력 노드에 할당하고 학습을 진행한다. 이점이 기존 학습 모델과의 차이점으로, 임의의 속성값이 입력층에서 여러 개의 노드로 분산되는 특이한 구조를 가진다. 제안 모델의 학습 성능을 평가하기 위해, 소실 데이터를 대상으로 다양한 실험을 수행하여 성능 면에서 우수함을 보인다. 제안 모델은 유비쿼터스 환경에서 손실을 최소화하기 위한 알고리즘으로 유용하게 사용될 것으로 본다.","The proposed model is developed to minimize the loss of information in incomplete data including missing data. The first step is to transform the learning data to compensate for the loss information using the data extension technique. In this conversion process, the attribute values of the data are filled with binary or probability values in one-hot encoding. Next, this conversion data is input to the deep learning model, where the number of entries is not constant depending on the cardinality of each attribute. Then, the entry values of each attribute are assigned to the respective input nodes, and learning proceeds. This is different from existing learning models, and has an unusual structure in which arbitrary attribute values are distributedly input to multiple nodes in the input layer. In order to evaluate the learning performance of the proposed model, various experiments are performed on the missing data and it shows that it is superior in terms of performance. The proposed model will be useful as an algorithm to minimize the loss in the ubiquitous environment."
전·후처리를 이용한 딥러닝 기반의 주차여부인식,2019,"['Parking Occupation Detection', 'Multiple Thresholds Filtering', 'Voting', 'Pre-Processing', 'Deep Learning', '주차여부인식', '다중 임계치', '보우팅', '전처리', '딥러닝']","최근 주차공간의 효율적 관리를 위해서 주차유도 시스템이 점점 보급화 되고 있다. 단순히 주차할 곳을 찾기 위한 안내용으로 사용되기도 하지만, 차량 운전자가 본인의 차량이 주차된 곳을 찾기 위해서 영상처리 기술을 이용하여, 주차된 차량 찾기 서비스까지 연동되기도 한다. 따라서, 다양한 영상처리 및 패턴 인식 기술을 이용하여 주차여부인식 및 차량 번호 인식에 대한 연구가 지속되고 있다. 본 논문에서는 인식률을 높이면서, 빠르게 주차면의 주차여부인식을 할 수 있는 알고리즘을 제안한다. 주차면의 주차여부를 분석하기 위해서 전처리 부분으로 다중 임계치 병렬적용을 하였고, 보우팅 방법을 통해 객체 인식률을 높였으며, 딥러닝 기술(YOLO)을 이용한 카메라내 객체를 추출을 통하여 사람과 같은 다른 객체 추출에 의해서 발생할 수 있는 주차여부의 오류율을 줄일 수 있었다. 또한 인식률을 저하 시킬 수 있는 요인(빛, 장소)등에서도 제안한 알고리즘을 통한 높은 인식률을 얻을 수 있었다.","Recently, parking guidance systems have been increasingly popular for efficient management of parking spaces. It is often used as an insider's guide to find a place to park, but it can also be linked to a parked vehicle search service using a camera-like image processing technology to find where the driver has parked his vehicle. Therefore, researches on parking occupation recognition and licence plate recognition using various image processing and pattern recognition technologies are continuing. In this paper, we propose an algorithm that recognizes parking occupation detection quickly in addition to increase the recognition rate. In order to analyze whether the parking slot is occupied, multiple thresholds are applied in parallel as a pre-processing part. Object recognition rate is increased through the voting method. Extraction of objects in the camera use deep learning(YOLO). It was possible to reduce the error rate of possible parking. Also, we can obtain high recognition rate through the proposed algorithm even in the factors that may decrease the recognition rate (light, circulation)."
기후 및 계절정보를 이용한 딥러닝 기반의 장기간 태양광 발전량 예측 기법,2019,"['태양광 발전량 예측', 'Deep Learning', 'Machine Learning', '시계열 분석', '계절형 ARIMA Model', 'Photovoltaic Power Prediction', 'Deep Learning', 'Machine Learning', 'Time Series Analysis', 'Seasonal ARIMA Model']","최근 온실가스의 증가로 인한 기후변화 대응의 필요성과 전력수요의 증가로 인해 태양광 발전량(PV) 예측의 중요성은 급격히 증가하고 있다. 특히, 태양광 발전량을 예측하는 것은 합리적인 전력 가격결정과 시스템 안정성 및 전력 생산 균형과 같은 문제를 효과적으로 해결하기 위해 전력생산 계획을 합리적으로 계획하는데 도움이 될 수 있다. 그러나 일사량, 운량, 온도 등과 같은 기후정보 및 계절 변화로 인한 태양광 발전량이 무작위적으로 변화하기 때문에 정확한 태양광 발전량을 예측하는 것은 도전적인 일이다. 따라서 본 논문에서는 딥러닝 모델을 통해 기후 및 계절정보를 이용하여 학습함으로써 장기간 태양광 발전량 예측 성능을 향상시킬 수 있는 기법을 제안한다. 본 연구에서는 대표적인 시계열 방법 중 하나인 계절형 ARIMA 모델과 하나의 은닉층으로 구성되어 있는 ANN 기반의 모델, 하나 이상의 은닉층으로 구성되어 있는 DNN 기반의 모델과의 비교를 통해 본 연구에서 제시한 모델의 성능을 평가한다. 실 데이터를 통한 실험 결과, 딥러닝 기반의 태양광 발전량 예측 기법이 가장 우수한 성능을 보였으며, 이는 본 연구에서 목표로 한 태양광 발전량 예측 성능 향상에 긍정적인 영향을 나타내었음을 보여준다.","Recently, since responding to meteorological changes depending on increasing greenhouse gas and electricity demand, the importance prediction of photovoltaic power (PV) is rapidly increasing. In particular, the prediction of PV power generation may help to determine a reasonable price of electricity, and solve the problem addressed such as a system stability and electricity production balance. However, since the dynamic changes of meteorological values such as solar radiation, cloudiness, and temperature, and seasonal changes, the accurate long-term PV power prediction is significantly challenging. Therefore, in this paper, we propose PV power prediction model based on deep learning that can be improved the PV power prediction performance by learning to use meteorological and seasonal information. We evaluate the performances using the proposed model compared to seasonal ARIMA (S-ARIMA) model, which is one of the typical time series methods, and ANN model, which is one hidden layer. As the experiment results using real-world dataset, the proposed model shows the best performance. It means that the proposed model shows positive impact on improving the PV power forecast performance."
원-핫 인코딩을 이용한 딥러닝 단기 전력수요 예측모델,2019,"['Electric Load Forecasting', 'LSTM', 'One-Hot Encoding', 'RNN', 'Virtual Power Plant']","분산자원 집합 거래시장에 참여를 원하는 소비자나 사업자를 위한 가상발전소의 전력거래 플랫폼에서 사업참여자의 수요자원을 관리하고, 이에 적절한 전략을 제공하기 위해 익일 개별 참여자의 수요와 전체 계통의 전력수요를 예측하는 것이 대단히 중요하다. 이러한 전력거래 플랫폼에서 활용하는 것을 목표로 본 논문은 우선 익일의 24시간 전력계통 전력수요예측 모델을 개발하였다. 본 논문에서는 전력수요예측 데이터의 시계열 특성을 고려하여 딥러닝 기법 중 LSTM 알고리즘을 사용하였고, 전력수요량 등의 입출력 값에 원-핫 인코딩 기법을 적용하는 새로운 시도를 하였다. 성능평가에서 일반 DNN과 본 논문에서 구현된 LSTM 예측모델은 각각 평균 제곱근 오차 4.50, 1.89를 나타내어 LSTM 모델이 예측정확도가 높게 나타났다.","In order to manage the demand resources of project participants and to provide appropriate strategies in the virtualpower plant's power trading platform for consumers or operators who want to participate in the distributed resourcecollective trading market, it is very important to forecast the next day's demand of individual participants and the overallsystem's electricity demand. This paper developed a power demand forecasting model for the next day. For the model,we used LSTM algorithm of deep learning technique in consideration of time series characteristics of power demandforecasting data, and new scheme is applied by applying one-hot encoding method to input/output values such as powerdemand. In the performance evaluation for comparing the general DNN with our LSTM forecasting model, both modelshowed 4.50 and 1.89 of root mean square error, respectively, and our LSTM model showed high prediction accuracy."
영어 리뷰데이터를 이용한 딥러닝 기반 다국어 감성분석,2019,"['Deep Learning', 'Natural Language Processing(NLP)', 'Sentimental Analysis', 'Shopping Mall', 'Word2vec']","영어로 된 아마존과 같은 대형 글로벌 온라인 쇼핑몰은 전 세계를 대상으로 영어 또는 판매 해당국가 언어로서비스를 하고 있다. 온라인 쇼핑몰 이용자 중, 많은 고객은 상품 리뷰평가를 참조하여 상품을 구매하고 있다. 그래서고객들이 작성한 대량의 리뷰데이터를 이용하여 구매 상품에 대해 긍정과 부정을 판정하는 감성분석을 영어를 중심으로활발히 연구되고 분석 결과는 고객의 타켓 마케팅에 활용되고 있다. 하지만 이와 같은 영어 중심의 감성분석 시스템을전 세계의 다양한 언어에 그대로 적용하기는 어렵다. 따라서 본 연구에서는 영어로 된 50만개 이상의 아마존 푸드 상품리뷰데이터를 학습과 테스트 데이터로 분리하여 딥러닝 기술 기반의 감성분석 시스템을 구현하였다. 먼저 영어 테스트데이터의 3가지 모델에 대한 감성분석 평가 실험을 한 후에, 같은 데이터를 자동번역기로 7개국(한국어, 일본어, 중국어, 베트남어, 불어, 독어, 영어) 언어로 번역 후에 다시 영어로 번역하여 실험 결과를 얻었다. 감성분석 정확성은 영어(94.35%)에 비해 각 7개국 언어의 평균(91.59%)보다 정확도가 2.77% 정도 낮게 나왔으나 번역 성능 수준에서 실용가능성을 확인하였다.","Large global online shopping malls, such as Amazon, offer services in English or in the language of a country when their products are sold. Since many customers purchase products based on the product reviews, the shopping malls actively utilize the sentimental analysis technique in judging preference of each product using the large amount of review data that the customer has written. And the result of such analysis can be used for the marketing to look the potential shoppers. However, it is difficult to apply this English-based semantic analysis system to different languages used around the world. In this study, more than 500,000 data from Amazon fine food reviews was used for training a deep learning based system. First, sentiment analysis evaluation experiments were carried out with three models of English test data. Secondly, the same data was translated into seven languages (Korean, Japanese, Chinese, Vietnamese, French, German and English) and then the similar experiments were done. The result suggests that although the accuracy of the sentimental analysis was 2.77% lower than the average of the seven countries (91.59%) compared to the English (94.35%), it is believed that the results of the experiment can be used for practical applications."
납기와 작업준비비용을 고려한 병렬기계에서 딥러닝 기반의 일정계획 생성 모델,2019,"['Scheduling', 'Deep Neural Network', 'Due Date', 'Setup Cost', 'Machine Learning', '일정계획', '심층신경망', '납기', '작업준비용', '머신러닝']","4차 산업혁명이 진행되면서 제조업에서 사물인터넷(IoT), 머신러닝과 같은 지능정보기술을 적용하는 사례가 증가하고 있다. 반도체/LCD/타이어 제조공정에서는 납기일(due date)을 준수하면서 작업물 종류 변경(Job change)으로 인한 작업 준비 비용(Setup Cost)을 최소화 하는 일정계획을 수립하는 것이 효과적인 제품 생산을 위해 매우 중요하다. 따라서 본 연구에서는 병렬기계에서 딥러닝 기반의 납기 지연과 작업 준비 비용 최소화를 달성하는 일정계획 생성 모델을 제안한다. 제안한 모델은 과거의 많은 데이터를 이용하여 고려되어지는 주문에 대해 작업 준비와 납기 지연을 최소화하는 패턴을 학습한다. 따라서 세 가지 주문 리스트의 난이도에 따른 실험 결과, 본 연구에서 제안한 기법이 기존의 우선순위 규칙보다 성능이 우수하다는 것을 확인하였다.","As the 4th industrial revolution progressing, manufacturers are trying to apply intelligent information technologies such as IoT(internet of things) and machine learning. In the semiconductor/LCD/tire manufacturing process, schedule plan that minimizes setup change and due date violation is very important in order to ensure efficient production. Therefore,in this paper, we suggest the deep learning based scheduling generation model minimizes setup change and due date violation in parallel machines. The proposed model learns patternsof minimizing setup change and due date violation depending on considered order using the amount of historical data. Therefore, the experiment results using three dataset dependingon levels of the order list, the proposed model outperforms compared to priority rules."
V-그램: 명령어 기본 블록과 딥러닝 기반의 악성코드 탐지,2019,"['malware detection', 'static analysis', 'disassemble', 'n-gram', 'feature hashing', '악성코드 탐지', '정적 분석', '디스어셈블', 'n-그램', '피쳐 해싱']","악성코드가 급증하여 기계 학습 기반의 자동 탐지 연구가 중요해지고 있다. 악성코드 실행파일로부터 추출되는 opcode 시퀀스는 악성코드 탐지에 좋은 특징이기 때문에 바이트 기반의 n-그램 처리 기법을 거쳐 기계 학습의 입력 데이터로서 폭넓게 사용되고 있다. 본 논문에서는 처리 속도와 저장 공간 측면에서 기존 n-그램 방식을 크게 향상시키는 기본 블록 단위의 딥러닝 입력 데이터 가공 기법인 V-그램을 새롭게 제안한다. V-그램은 opcode 시퀀스로부터 의미 없는 입력 데이터의 불필요한 생성을 막을 수 있다. 본 논문에서는 64,000개 이상의 실제 정상 및 악성코드 파일을 수집하여 진행한 실험을 통해서, V- 그램이 처리 속도와 저장 공간, 그리고 탐지 정확도 측면에서 모두 기존의 n-그램 기법보다 우수하다는 것을 검증하였다.","With the rapid increase in number of malwares, automatic detection based on machine learning becomes more important. Since the opcode sequence extracted from a malicious executable file is useful feature for malware detection, it is widely used as input data for machine learning through byte-based n-gram processing techniques. This study proposed a V-gram, a new data preprocessing technique for deep learning, which improves existing n-gram methods in terms of processing speed and storage space. V-gram can prevent unnecessary generation of meaningless input data from opcode sequences. It was verified that the V-gram is superior to the conventional n-gram method in terms of processing speed, storage space, and detection accuracy, through experiments conducted by collecting more than 64,000 normal and malicious code files."
학술논문 PDF에 대한 딥러닝 기반의 메타데이터 추출 방법 연구,2019,"['PDF Metadata extraction', 'metadata extraction', 'information extraction', 'text mining', 'deep learning', 'PDF 메타데이터 추출', '메타데이터 추출', '정보추출', '텍스트마이닝', '딥러닝']","최근 학술문헌의 수가 빠르게 증가함에 따라, 최신 연구 동향 및 정보를 얻기 위한 학술데이터베이스 서비스의 필요성이 대두되었다. 학술데이터베이스 구축을 위한 메타데이터 추출 자동화 서비스가 연구되었으나, 대부분의 학술문헌 원문은 PDF로 구성되어 자동적인 정보 추출이 쉽지 않은 문제가 있다.이에 본 연구는 학술문헌 PDF에 대한 메타데이터 자동 추출 방법을 제안한다. 먼저 학술문헌 PDF를 XML 형식으로 변환한 이후, XML 마크업 토큰 내의 좌표, 크기, 넓이와 텍스트 자질을 추출하여 벡터 형태로 구성한다. 추출된 자질 정보를 연속적 레이블링에 특화된 딥러닝 모델인 Bidirectional GRU-CRF를 활용하여 분석하고 메타데이터를 추출한다. 본 연구에서는 국내 학술지 중 10종을 선정하여 메타데이터 추출을 위한 학습집합을 구축하고, 제안한 방법론을 활용하여 실험하였다. 9종의 메타데이터에 대한 추출 실험 결과, 88.27%의 정확도와 84.39%의 F1 성능을 얻었다.","Recently, with a rapid increase in the number of academic documents, there has arisen a need for an academic database service to obtain information about the latest research trends.Although automated metadata extraction service for academic database construction has been studied, most of the academic texts are composed of PDF, which makes it difficult to automatically extract information. In this paper, we propose an automatic metadata extraction method for PDF documents.First, after transforming the PDF into XML format, the coordinates, size, width, and text feature in the XML markup token are extracted and constructed as a vector form. Extracted feature information is analyzed using Bidirectional GRU-CRF, which is an deep learning model specialized for sequence labeling, and finally, metadata are extracted. In this study, 10 kinds of journals among various domestic journals were selected and a training set for metadata extraction was constructed and experimented using the proposed methodology. As a result of extraction experiment on 9 kinds of metadata, 88.27% accuracy and 84.39% F1 performance was obtained."
위내시경 디지털 영상에서 정상과 위궤양 딥러닝 분류 모델,2019,"['위궤양', '내시경 영상', '딥러닝', '인공지능', 'Gastric Ulcer', 'Endoscopic Image', 'Deep Learning', 'Artificial Intelligent']","내시경 장비의 발전으로 위장 질환의 조기 발견 및 치료에 많은 향상이 있다. 따라서, 많은 내시경 이미지과 함께 내시경 이미지 분류에 대한 연구가 활발히 증가하고 있다. 본 논문에서는 위내시경에서 많이 발견되는 질환인 위궤양을 분류하고자 한다. 위궤양은 초기에 적절한 치료를 하지 않으면 합병증을 일으킬 수 있으므로, 초기에 병변을 진단하는 것이 가장 중요하다. 본 연구에서는 ResNet-50 딥러닝 모델을 이용하여 정상과 위궤양을 분류하고자 하였다. 총 1,525개의 이미지를 이용하여 모델을 생성하였고, 효율적인 학습을 위해 데이터 증강을 적용하였다. 제안된 모델의 분류 성능은 정확도 0.9016, ROC 곡선은 0.83으로 확인하였다.","Due to the development of endoscopic equipment, there has been much progress in the early detection and treatment of gastrointestinal diseases. Therefore, many endoscopic images have been provided, and studies on endoscopic image classification have been increased actively. In this paper, we aim to classify gastric ulcer, a disease frequently found in endoscopy.Gastric ulcers can lead to complications if not properly treated early on, so it is most important to diagnose the lesions early.Our study used the ResNet-50 in-depth learning model. A model was created using a total of 1,525 images, and data enhancement was applied for efficient learning. The classification performance of the proposed model is 0.9016 with accuracy and 0.83 with ROC curve."
스마트폰 다종 데이터를 활용한 딥러닝 기반의 사용자 동행 상태 인식,2019,"['사용자 행동 인식', '그룹 상호작용', '스마트폰 물리 센서', '컨볼루션 신경망', '장단기 기억 순환 신경망', 'human activity recognition', 'group interaction', 'smartphone multimodal sensors', 'convolutional neural network', 'long short-term memory recurrent network']","스마트폰이 널리 보급되고 현대인들의 생활 속에 깊이 자리 잡으면서, 스마트폰에서 수집된 다종 데이터를바탕으로 사용자 개인의 행동을 인식하고자 하는 연구가 활발히 진행되고 있다. 그러나 타인과의 상호작용 행동 인식에 대한 연구는 아직까지 상대적으로 미진하였다. 기존 상호작용 행동 인식 연구에서는 오디오, 블루투스, 와이파이 등의 데이터를 사용하였으나, 이들은 사용자 사생활 침해 가능성이 높으며 단시간 내에 충분한 양의 데이터를 수집하기 어렵다는 한계가 있다. 반면 가속도, 자기장, 자이로스코프 등의 물리 센서의 경우 사생활 침해 가능성이 낮으며 단시간 내에 충분한 양의 데이터를 수집할 수 있다. 본 연구에서는 이러한 점에 주목하여, 스마트폰 상의 다종 물리 센서 데이터만을 활용, 딥러닝 모델에 기반을 둔 사용자의 동행 상태 인식 방법론을 제안한다. 사용자의 동행 여부 및 대화 여부를 분류하는 동행 상태 분류 모델은 컨볼루션 신경망과 장단기기억 순환 신경망이 혼합된 구조를 지닌다. 먼저 스마트폰의 다종 물리 센서에서 수집한 데이터에 존재하는 타임 스태프의 차이를 상쇄하고, 정규화를 수행하여 시간에 따른 시퀀스 데이터 형태로 변환함으로써 동행 상태분류 모델의 입력 데이터를 생성한다. 이는 컨볼루션 신경망에 입력되며, 데이터의 시간적 국부 의존성이 반영된 요인 지도를 출력한다. 장단기 기억 순환 신경망은 요인 지도를 입력받아 시간에 따른 순차적 연관 관계를학습하며, 동행 상태 분류를 위한 요인을 추출하고 소프트맥스 분류기에서 이에 기반한 최종적인 분류를 수행한다. 자체 제작한 스마트폰 애플리케이션을 배포하여 실험 데이터를 수집하였으며, 이를 활용하여 제안한 방법론을 평가하였다. 최적의 파라미터를 설정하여 동행 상태 분류 모델을 학습하고 평가한 결과, 동행 여부와 대화 여부를 각각 98.74%, 98.83%의 높은 정확도로 분류하였다.","As smartphones are getting widely used, human activity recognition (HAR) tasks for recognizing personal activities of smartphone users with multimodal data have been actively studied recently. The research area is expanding from the recognition of the simple body movement of an individual user to the recognition of low-level behavior and high-level behavior. However, HAR tasks for recognizing interaction behavior with other people, such as whether the user is accompanying or communicating with someone else, have gotten less attention so far. And previous research for recognizing interaction behavior has usually depended on audio, Bluetooth, and Wi-Fi sensors, which are vulnerable to privacy issues and require much time to collect enough data. Whereas physical sensors including accelerometer, magnetic field and gyroscope sensors are less vulnerable to privacy issues and can collect a large amount of data within a short time. In this paper, a method for detecting accompanying status based on deep learning model by only using multimodal physical sensor data, such as an accelerometer, magnetic field and gyroscope, was proposed. The accompanying status was defined as a redefinition of a part of the user interaction behavior, including whether the user is accompanying with an acquaintance at a close distance and the user is actively communicating with the acquaintance. A framework based on convolutional neural networks (CNN) and long short-term memory (LSTM) recurrent networks for classifying accompanying and conversation was proposed.First, a data preprocessing method which consists of time synchronization of multimodal data fromdifferent physical sensors, data normalization and sequence data generation was introduced. We applied the nearest interpolation to synchronize the time of collected data from different sensors. Normalization was performed for each x, y, z axis value of the sensor data, and the sequence data was generated according to the sliding window method. Then, the sequence data became the input for CNN, where feature maps representing local dependencies of the original sequence are extracted. The CNN consisted of 3 convolutional layers and did not have a pooling layer to maintain the temporal information of the sequence data. Next, LSTM recurrent networks received the feature maps, learned long-term dependencies from them and extracted features. The LSTM recurrent networks consisted of two layers, each with 128 cells. Finally, the extracted features were used for classification by softmax classifier. The loss function of the model was cross entropy function and the weights of the model were randomly initialized on a normal distribution with an average of 0 and a standard deviation of 0.1. The model was trained using adaptive moment estimation (ADAM) optimization algorithm and the mini batch size was set to 128. We applied dropout to input values of the LSTM recurrent networks to prevent overfitting. The initial learning rate was set to 0.001, and it decreased exponentially by 0.99 at the end of each epoch training.An Android smartphone application was developed and released to collect data. We collected smartphone data for a total of 18 subjects. Using the data, the model classified accompanying and conversation by 98.74% and 98.83% accuracy each. Both the F1 score and accuracy of the model were higher than the F1 score and accuracy of the majority vote classifier, support vector machine, and deep recurrent neural network. In the future research, we will focus on more rigorous multimodal sensor data synchronization methods that minimize the time stamp differences. In addition, we will further study transfer learning method that enables transfer of trained models tailored to the training data to the evaluation data that follows a different distribution. It is expected that a model capable of exhibiting robust recognition performance against changes in data that is not considered in the model learning stage wil..."
비주얼 서보잉을 위한 딥러닝 기반 물체 인식 및 자세 추정,2019,"['Object Detection', 'Object Recognition', 'Deep Learning', 'Line Detection', 'Hough Transform', 'Perspective-Transform', 'Pose Estimation']",,"Recently, smart factories have attracted much attention as a result of the 4th Industrial Revolution. Existing factory automation technologies are generally designed for simple repetition without using vision sensors. Even small object assemblies are still dependent on manual work. To satisfy the needs for replacing the existing system with new technology such as bin picking and visual servoing, precision and real-time application should be core. Therefore in our work we focused on the core elements by using deep learning algorithm to detect and classify the target object for real-time and analyzing the object features. We chose YOLO CNN which is capable of real-time working and combining the two tasks as mentioned above though there are lots of good deep learning algorithms such as Mask R-CNN and Fast R-CNN. Then through the line and inside features extracted from target object, we can obtain final outline and estimate object posture."
불균형 데이터 분류를 위한 딥러닝 기반 오버샘플링 기법,2019,"['불균형 데이터', 'CGAN', '딥러닝', '오버샘플링', 'Imbalanced Data', 'CGAN', 'Deep Learning', 'Over-Sampling']",,"Classification problem is to predict the class to which an input data belongs. One of the most popular methods to do this is training a machine learning algorithm using the given dataset. In this case, the dataset should have a well-balanced class distribution for the best performance. However, when the dataset has an imbalanced class distribution, its classification performance could be very poor. To overcome this problem, we propose an over-sampling scheme that balances the number of data by using Conditional Generative Adversarial Networks (CGAN). CGAN is a generative model developed from Generative Adversarial Networks (GAN), which can learn data characteristics and generate data that is similar to real data. Therefore, CGAN can generate data of a class which has a small number of data so that the problem induced by imbalanced class distribution can be mitigated, and classification performance can be improved. Experiments using actual collected data show that the over-sampling technique using CGAN is effective and that it is superior to existing over-sampling techniques."
외재적 변수를 이용한 딥러닝 예측 기반의 도시가스 인수량 예측,2019,"['city-gas', 'forecasting demand', 'LSTM', 'ARIMA', 'time-series', 'acceptance']","본 연구에서는 국내 도시가스 인수량에 대한 예측 모델을 개발하였다. 국내의 도시가스 회사는 KOGAS에 차년도 수요를 예측하여 보고해야 하므로 도시가스 인수량 예측은 도시가스 회사에 중요한 사안이다. 도시가스 사용량에 영향을 미치는 요인은 용도구분에 따라 다소 상이하나, 인수량 데이터는 용도별 구분이 어렵기 때문에 특정 용도에 관계없이 영향을 주는 요인으로 외기온도를 고려하여 모델개발을 실시하였다.실험 및 검증은 JB주식회사의2008년부터 2018년까지 총 11년 치 도시가스 인수량 데이터를 사용하였으며, 전통적인 시계열 분석 중 하나인ARIMA(Auto-Regressive Integrated Moving Average)와 딥러닝 기법인 LSTM(Long Short-Term Memory)을 이용하여 각각 예측 모델을 구축하고 두 방법의 단점을 최소화하기 위하여 다양한 앙상블(Ensemble) 기법을 사용하였다.본 연구에서 제안한 일별 예측의 오차율 절댓값 평균은 Ensemble LSTM 기준 0.48%, 월별 예측의 오차율 절댓값 평균은 2.46%, 1년 예측의 오차율 절댓값 평균은 5.24%임을 확인하였다","In this study, we have developed a forecasting model for city- gas acceptance.City-gas corporations have to report about city-gas sale volume next year to KOGAS. So it is a important thing to them. Factors influenced city-gas have differences corresponding to usage classification, however, in city-gas acceptence, it is hard to classificate. So we have considered tha outside temperature as factor that influence regardless of usage classification and the model development was carried out. ARIMA, one of the traditional time series analysis, and LSTM, a deep running technique, were used to construct forecasting models, and various Ensemble techniques were used to minimize the disadvantages of these two methods.Experiments and validation were conducted using data from JB Corp. from 2008 to 2018 for 11 years.The average of the error rate of the daily forecast was 0.48% for Ensemble LSTM, the average of the error rate of the monthly forecast was 2.46% for Ensemble LSTM, And the absolute value of the error rate is 5.24% for Ensemble LSTM."
음절 단위 임베딩과 딥러닝 기법을 이용한 복합명사 분해,2019,"['복합명사 분해', 'bigram', '음절 임베딩', 'LSTM', '선형체인 CRF', 'compound noun decomposition', 'bigram', 'syllable embedding', 'LSTM', 'Linear-Chain CRF']","기존의 복합명사 분해 알고리즘은 미등록어 단위명사들이 포함된 복합명사를 분해할 때 미등록어를 분리하기 어려운 문제가 발생한다. 이는 현실적으로 모든 고유명사, 신조어, 외래어 등의 모든 단위 명사를 사전에 등록하는 것은 불가능하다는 한계가 존재하기 때문이다. 이 문제를 해결하기 위하여 복합명사 분해 문제를 태그 열 부착(sequence labeling) 문제로 정의하고 음절 단위 임베딩과 딥러닝 기법을 이용하는 복합명사 분해 방법을 제안한다. 단위명사 사전을 구축하지 않고 미등록 단위명사를 인식하기 위하여 복합명사를 구성하는 각 음절들을 연속적인 벡터 공간에 표현하여 LSTM과 선형체인(linear-chain) CRF를 이용하는 방식으로 복합명사를 단위명사들로 분해한다.","The existing compound noun decomposition algorithm has a problem that it is difficult to separate unregistered nouns when decomposing compound nouns that contain unregistered unit nouns in the dictionary. This is because there is a limit to the fact that it is impossible to register all unit nouns into the dictionary such as proper nouns, coined words, and foreign words in advance. In this paper, in order to solve this problem, compound noun decomposition problem is defined as tag sequence labeling problem and compound noun decomposition method to use syllable unit embedding and deep learning technique is proposed. In order to recognize unregistered unit nouns without constructing unit noun dictionary, compound nouns are decomposed into unit nouns by using LSTM and linear-chain CRF expressing each syllable that constitutes a compound noun in the continuous vector space."
랜섬웨어 방지를 위한 딥러닝 기반의 사용자 비정상 행위 탐지 성능 평가,2019,"['Abnomal behavior detection', 'Anomaly Detection', 'Ransomware', 'Deep Learning', 'Performance Comparison', 'CNN-LSTM', '비정상 행위 탐지', '이상 징후 탐지', '랜섬웨어', '딥러닝', '성능 비교', 'CNN-LSTM']",,"With the development of IT technology, computer-related crimes are rapidly increasing, and in recent years, the damage to ransomware infections is increasing rapidly at home and abroad. Conventional security solutions are not sufficient to prevent ransomware infections, and to prevent threats such as malware and ransomware that are evolving, a combination of deep learning technologies is needed to detect abnormal behavior and abnormal symptoms. In this paper, a method is proposed to detect user abnormal behavior using CNN-LSTM model and various deep learning models. Among the proposed models, CNN-LSTM model detects user abnormal behavior with 99% accuracy."
택배화물 자동 하역장비를 위한 딥러닝 기반의 화물 인식 알 고리즘,2019,"['Unloading system', 'deep learning algorithm', 'YOLO v2', 'Masked -CRNN', '자동하역장치', '딥러닝 알고리즘', 'YOLO v2', 'Masked R-CNN']",본 논문에서는 택배화물 자동하역장치에 적합한 개선된 딥러닝 알고리즘을 제안한다. 제안된 알고리즘은 실시간객체검출에 우수한 성능을 보이는 YOLO v2모델을 기반으로 픽셀단위 택배화물의 위치까지 검출할 수 있도록 Masked R-CNN을 융합한 구조를 가진다. 제안된 알고리즘은 YOLO v2를 이용하여 객체의 영역과 분류를 수행하면서 객체 영역을Masked R-CNN의 객체분할(Instance segmentation)과정을 거쳐 택배화물의 픽셀단위 위치까지 계산할 수 있도록 하였다.제안된 알고리즘의 성능을 평가하기 위하여 실제 택배화물 차량의 적재공간과 동일한 영역에서 택배화물들을 이용하여실험하였으며 실험결과 만족할만한 성능을 보임을 확인하였다,"In this paper, an improved deep learning algorithm for automatic unloading systems is proposed. The proposed algorithm is based on the YOLO v2 model, which shows excellent performance in real-time object detection, and has a fused structure with Masked R-CNN to detect pixel position of parcel. The proposed algorithm performs object segmentation and classification using YOLO v2, and calculates the object region to the pixel position of the parcel by mask segmentation process of Instanced R-CNN.In order to evaluate the performance of the proposed algorithm, we experimented in the same area as the loading space of the actual parcel cargo vehicle and showed the excellent performance in the expiemr ental results."
공동주택 전력 소비 데이터 분석 및 딥러닝을 사용한 전력 소비 예측,2019,"['advanced metering infrastructure', 'deep neural network', 'load data', 'load forecasting', 'k-means clustering', 'meter reading']","에너지의 생산 효율성을 증가시키기 위해 최근 스마트그리드 기술 중 지능형 검침 시스템(AMI, advanced metering infrastructure)의 개발이 활발히 진행되고 있다. 전력 소비 데이터를 분석하고 소비 패턴을 예측하는 일은 AMI에서 핵심적인 부분이다. 본 논문에서는 수집된 전력 소비 데이터를 분석하고 발생할 수 있는 오류들을 정리하였으며 소비 패턴을 월별로 k-means 군집화 알고리즘을 사용하여 분석하였다. 또한 deep neural network를 이용하여 소비 패턴을 예측하였는데, 가구별 하루 전력 사용량 예측의 어려움을 극복하기 위하여 전력 사용량을 100개의 군집으로 분류하여 이 군집의 하루 평균으로 다음날 군집의 평균을 예측하였다. 실제 AMI에서의 전력 데이터를 사용하여 오류들을 분석하였으며 군집화 방법을 도입하여 성공적으로 전력 소비 예측이 가능하였다.","In order to increase energy efficiency, developments of the advanced metering infrastructure (AMI) in the smart grid technology have recently been actively conducted. An essential part of AMI is analyzing power consumption and forecasting consumption patterns. In this paper, we analyze the power consumption and summarized the data errors. Monthly power consumption patterns are also analyzed using the k-means clustering algorithm. Forecasting the consumption pattern by each household is difficult. Therefore, we first classify the data into 100 clusters and then predict the average of the next day as the daily average of the clusters based on the deep neural network. Using practically collected AMI data, we analyzed the data errors and could successfully conducted power forecasting based on a clustering technique."
SHVC 부호화 성능 개선을 위한 딥러닝 기반 계층간 참조 픽처 생성 방법,2019,"['Scalable HEVC', 'CNN', 'Deep learning', 'Super resolution', 'Inter-layer prediction']","본 논문에서는 SHVC 부호화 성능 개선을 위하여 딥러닝 기반 계층간 예측을 위한 참조 픽처 생성 방법을 제안한다. 새로운 참조 픽처를 생성하기 위하여 DCT-IF기반 업샘플링 된 픽처를 VDSR 네트워크를 이용한 필터링을 진행하는 구조와 SHVC 계층간 참조 픽처를 생성하기 위한 트레이닝 방법에 대해 설명한다. 제안하는 방법은 SHM 12.0 기반으로 구현되어 있다. 성능 평가를 위하여 사전 학습을 이용하여 계층간 예측 픽처를 생성하는 방법과 비교를 진행하였다. 그 결과 상위 계층의 부호화 성능은 사전 학습을 이용한 방법 대비 최대 13.14%의 비트 감소, SHM 대비 최대 15.39%의 비트 감소율을 보였고, 평균 6.46%의 비트 감소율을 보였다.",
전역 및 지역 특징 기반 딥러닝을 이용한 프린터 장치 판별 기술,2019,"['Global Feature', 'Local Feature', 'Deep Learning', 'Printer Identification', 'Convolutional Neural Network', '전역 특징', '지역 특징', '딥러닝', '프린터 장치 판별', '컨볼루셔널 뉴럴 네트워크']",,"With the advance of digital IT technology, the performance of the printing and scanning devices is improved and their price becomes cheaper. As a result, the public can easily access these devices for crimes such as forgery of official and private documents. Therefore, if we can identify which printing device is used to print the documents, it would help to narrow the investigation and identify suspects. In this paper, we propose a deep learning model for printer identification. A convolutional neural network model based on local features which is widely used for identification in recent is presented. Then, another model including a step to calculate global features and hence improving the convergence speed and accuracy is presented. Using 8 printer models, the performance of the presented models was compared with previous feature-based identification methods. Experimental results show that the presented model using local feature and global feature achieved 97.23% and 99.98% accuracy respectively, which is much better than other previous methods in accuracy."
백스터 로봇의 시각기반 로봇 팔 조작 딥러닝을 위한 강화학습 알고리즘 구현,2019,"['Robotics', 'Visuomotor Policy', 'Reinforcement Learning', 'Guided Policy Search', 'Baxter Research Robot']",,"Reinforcement learning has been applied to various problems in robotics. However, it was still hard to train complex robotic manipulation tasks since there is a few models which can be applicable to general tasks. Such general models require a lot of training episodes. In these reasons, deep neural networks which have shown to be good function approximators have not been actively used for robot manipulation task. Recently, some of these challenges are solved by a set of methods, such as Guided Policy Search, which guide or limit search directions while training of a deep neural network based policy model. These frameworks are already applied to a humanoid robot, PR2. However, in robotics, it is not trivial to adjust existing algorithms designed for one robot to another robot. In this paper, we present our implementation of Guided Policy Search to the robotic arms of the Baxter Research Robot. To meet the goals and needs of the project, we build on an existing implementation of Baxter Agent class for the Guided Policy Search algorithm code using the built-in Python interface. This work is expected to play an important role in popularizing robot manipulation reinforcement learning methods on cost-effective robot platforms."
유도 전동기의 속도 및 부하 조건을 고려한 딥러닝 고장 진단 알고리즘 개발에 관한 연구,2019,"['Deep learning', 'Motor fault diagnosis', 'CNN', 'Data analysis', 'Induction motor', 'FFT', 'Frequency domain']",,"The motor mechanical fault has been diagnosed under fixed driving conditions. The induction motor speed is affected not only by the input frequency but also by the load. In addition, the vibration generated by the induction motor is affected by the speed as well as the input frequency. For these reasons, a data preprocessing algorithm has been developed that shifts the measured data in the frequency domain based on motor speed. The algorithm also takes the input frequency as an input variable and removes the vibration component by the power source frequency. The data processed by the above procedure are classified through the deep learning algorithm based on CNN. As a result, a fault diagnosis system that can be applied to the industrial field has been developed by considering the motor driving conditions using the proposed algorithms."
네트워크 공격 탐지 성능향상을 위한 딥러닝을 이용한 트래픽 데이터 생성 연구,2019,"['Network security', 'Intrusion detection', 'Network traffic data', 'Deep learning', 'GAN', '네트워크 보안', '침입탐지', '네트워크 트래픽 데이터', '딥러닝', 'GAN']","네트워크 공격을 탐지하기 위하여 기계학습을 이용한 다양한 연구가 최근 급격히 증가하고 있다. 이러한 기계학습 방법은 많은 데이터에 의존적이며 연구를 위해 다양한 실험 데이터가 공개되어 사용되고 있다. 하지만 실험 데이터 및 실제 환경에서 수집되는 데이터는 class간의 수량이 불균형하다는 문제점을 가지고 있다. 본 연구에서는 기계 학습을 이용한 침입탐지시스템의 한계점 중 학습데이터의 class간 불균형으로 인한 분류 성능 저하를 해결하기 위한 방법을 제안한다. 이를 위해 네트워크 트래픽 데이터를 처리하고 seqGAN를 이용하여 부족한 데이터를 생성하였다. 제안된 방법은 NSL-KDD, UNSW-NB15 데이터 셋을 대상으로 Text-CNN을 이용하여 분류하는 테스트를 실행한 결과 정밀도가 향상되는 것을 확인할 수 있었다.","Recently, various approaches to detect network attacks using machine learning have been studied and are being applied to detect new attacks and to increase precision. However, the machine learning method is dependent on feature extraction and takes a long time and complexity. It also has limitation of performace due to learning data imbalance. In this study, we propose a method to solve the degradation of classification performance due to imbalance of learning data among the limit points of detection system. To do this, we generate data using Generative Adversarial Networks (GANs) and propose a classification method using Convolutional Neural Networks (CNNs). Through this approach, we can confirm that the accuracy is improved when applied to the NSL-KDD and UNSW-NB15 datasets."
스마트 구조물 균열 감지를 위한 1차원 합성곱신경망(1D CNN) 딥러닝을 이용한 파괴 신호 특정 기법,2019,"['구조물 모니터링', '기계 학습', '1D Convolution', '진동 센서', 'Structure Health Monitoring', 'Machine Learning', '1D Convolution Network', 'Accelerometer']","초고층 빌딩, 대형 구조물 등의 건설이 일반화됨에 따라 점차 노후화 및 지진, 태풍 등의 자연재해에 의한 구조물의 손상 모니터링에 대한 필요도가 증가하고 있다. 특히, 하부구조인 구조물 기초에서의 손상은 구조물 전체의 건전도에 부정적인 영향을 미칠 수 있기 때문에, 이에 대한 감지는 매우 중요하다. 구조물 건전도 비파괴검사 방법으로는 대표적으로 음향, 진동 감지기법 등이 제안되었으며, 이에 음향, 진동 감지기에 의해 수집된 신호를 해석하여 균열의 발생 위치 및 균열의 크기, 내구도 등을 역으로 추정하는 방법에 관한 연구가 실험실 스케일에서 많이 수행되어왔다. 하지만 실제로 현장에서는 적용되는 경우가 극히 드문 데 그 이유는 평소 발생하는 노이즈 신호(정상 신호)와 손상파괴 신호(비정상 신호)를 구분하는 것이 어렵기 때문이다. 특히 노이즈 신호와 구조물 파괴 신호가 동시에 수집될 때 이를 구분하는 것은 더욱 어려워진다. 이에 본 연구에서는 노이즈 신호(정상 신호)와 손상파괴 신호(비정상 신호)를 수집하고, 무작위로 합성된 신호를 딥러닝 기법인 1D convolutional neural network model을 통해서 정상 신호와 비정상 신호를 구분하는 알고리즘을 개발하였다. 개발된 알고리즘을 사용하면 현장에서 실시간으로 수집된 신호를 구분할 수 있게 됨으로써 구조물 안전성 변화 예측을 통해 재산 및 인명 피해 위험성을 최소화할 수 있을 것으로 생각한다.","Structures can be damaged by natural disasters such as earthquakes and typhoons. In particular, any damage to the foundation of a structure can present critical problems. Therefore, a smart monitoring technique such as the acoustic emission method is required to detect internal cracks and other types of structural damage. Many laboratory studies on this method have been conducted to estimate the locations and sizes of cracks as well as the resulting changes in structural durability using collected acoustic signals. However, the method has rarely been applied in the field because identifying damage signals from acquired signals, which can contain ambient noise, is difficult. We developed a deep learning algorithm based on a one-dimensional convolutional neural network method that can identify damage or crack signals generated from concrete failure from randomly synthesized signals. Using the developed algorithm, we were able to distinguish damage signals from random ambient noise signals. This algorithm enables real-time monitoring of concrete structures, thus providing a smart monitoring strategy."
생활도로 노상주차 식별을 위한 Google Street View API와 딥러닝 모형의 적용,2019,"['Street Parking', 'Deep Learning', 'Google Street View Image', 'Object Detection', 'Convolutional Neural Network', '노상주차', '딥러닝', '구글 가로 이미지', '객체 탐색', '합성곱신경망']","본 연구는 Google Street View API를 통해 취득한 가로 이미지를 활용하여 서울시 생활도로의 노상주차를 식별하는 모형을 학습 및 검증하였다. 다양한 반복학습 횟수에 따른 모형들의 정확도를 검증하여 최종모형으로 도출하였으며, 최종 모형은 모든 객체 유형에 대해 약 75.68%, 노상주차 차량에 대해 약 82.07%의 객체 탐색 정확도를 나타낸다. 연구의 주요 시사점은 주로 현장조사에 의존해 진행되어, 시간과 금전적 비용이 많이 필요하던 노상주차 데이터 수집의 한계점을 보완하였다는 점과, 딥러닝 모형을 공간분석 및 도시 계획 분야의 공간정보 수집에 적용하여 그 가능성을 제시했다는 점을 들 수 있다.",This study has trained and validated a deep learning model that identifies street parking on the streets of Seoul by utilizing the street view images obtained through the Google Street View API. We derived the final model which shows highest accuracy of object detection among models with variation of the number of training iterations. The final model shows 75.68% accuracy of object detection for all object types and 82.07% for street parking vehicles. The main implications of this study are as follows. This study introduces improved data collection method of street parking data in terms of time and monetary cost compared to the conventional field survey. Also this study applies the deep learning using street view image on the collection of spatial information for the urban planning and spatial analysis field.
위성 영상과 관측 센서 데이터를 이용한 PM<SUB>10</SUB>농도 데이터의 시공간 해상도 향상 딥러닝 모델 설계,2019,"['PM&lt', 'SUB&gt', '10&lt', '/SUB&gt', 'Deep Learning', 'Satellite Image', 'Sensor Data', 'Spatiotemporal Resolution', '딥러닝', '위성 영상', '센서 데이터', '시공간 해상도']",,
2D 슈팅 게임 학습 에이전트의 성능 향상을 위한 딥러닝 활성화 함수 비교 분석,2019,"['Game', 'Activation function', 'Re-enforcement Learning']","최근 강화 학습을 통해 게임을 학습하는 인공지능 에이전트를 만드는 연구가 활발히 진행되고 있다. 게임을 에이전트에게 학습 시킬 때 어떠한 딥러닝 활성화 함수를 사용하는지에 따라 그 학습 성능이 달라진다. 본 논문은 2D 슈팅 게임 환경에서 에이전트가 강화 학습을 통해 게임을 학습할 경우 어떤 활성화 함수가 최적의 결과를 얻는지를 비교 평가 한다. 이를위해 비교 평가에서 사용할 메트릭을 정의하고 각 활성화 함수에 따른 메트릭 값을 학습 시간에 따라 그래프로 나타내었다.그 결과 ELU (Exponential Linear Unit) 활성화 함수에 1.0으로 파라미터 값을 설정할 경우 게임의 보상 값이 다른 활성화함수보다 평균적으로 높은 것을 알 수 있었고, 가장 낮은 보상 값을 가졌던 활성화 함수와의 차이는 23.6%였다.","Recently, there has been active researches about building an artificial intelligence agent that can learn how to play a game by using re-enforcement learning. The performance of the learning can be diverse according to what kinds of deep learning activation functions they used when they train the agent. This paper compares the activation functions when we train our agent for learning how to play a 2D shooting game by using re-enforcement learning. We defined performance metrics to analyze the results and plotted them along a training time. As a result, we found ELU (Exponential Linear Unit) with a parameter 1.0 achieved best rewards than other activation functions. There was 23.6% gap between the best activation function and the worst activation function."
돼지의 빠른 자세 결정과 머리 제거를 위한영상처리 및 딥러닝 기법,2019,"['Real-Time Pig Monitoring', 'Posture Determining', 'Head Removal', 'Image Processing', 'Deep Learning', 'YOLO', '실시간 돼지 모니터링', '자세 결정', '머리 제거', '영상처리', '딥러닝', 'YOLO']",,"The weight of pig is one of the main factors in determining the health and growth state of pigs, their shipment, the breeding environment, and the ration of feed, and thus measuring the pig’s weight is an important issue in productivity perspective. In order to estimate the pig’s weight by using the number of pig’s pixels from images, acquired from a Top-view camera, the posture determining and the head removal from images are necessary to measure the accurate number of pixels. In this research, we propose the fast and accurate method to determine the pig’s posture by using a fast image processing technique, find the head location by using a fast deep learning technique, and remove pig’s head by using light weighted image processing technique. First, we determine the pig’s posture by comparing the length from the center of the pig‘s body to the outline of the pig in the binary image. Then, we train the location of pig’s head, body, and hip in images using YOLO(one of the fast deep learning based object detector), and then we obtain the location of pig’s head and remove an outside area of head by using head location. Finally, we find the boundary of head and body by using Convex-hull, and we remove pig’s head. In the Experiment result, we confirmed that the pig’s posture was determined with an accuracy of 0.98 and a processing speed of 250.00fps, and the pig’s head was removed with an accuracy of 0.96 and a processing speed of 48.97fps."
딥러닝 기반의 복합 열화 영상 분류 및 복원 기법,2019,"['Deep learning', 'Multi-Degradation', 'Degradation Classification', 'Restoration order', 'Restoration']","CNN (convolutional neural network) 기반의 단일 열화 영상 복원 방법은 우수한 성능을 나타내지만 한가지의 특정 열화를 해결하는 데 맞춤화 되어있다. 본 연구에서는 복합적으로 열화 된 영상 분류 및 복원을 위한 알고리즘을 제시한다. 복합 열화 영상 분류 문제를 해결하기 위해 CNN 기반의 알고리즘인 사전 학습된 Inception-v3 네트워크를 활용하고, 영상 열화 복원을 위해 기존의 CNN 기반의 복원 알고리즘을 사용하여 툴체인을 구성한다. 실험적으로 복합 열화 영상의 복원 순서를 추정하였으며, CNN 기반의 영상 화질 측정 알고리즘의 결과와 비교하였다. 제안하는 알고리즘은 추정된 복원 순서를 바탕으로 구현되어 실험 결과를 통해 복합 열화 문제를 효과적으로 해결할 수 있음을 보인다.",
딥러닝 기반 3차원 라이다의 반사율 세기 신호를 이용한 흑백 영상 생성 기법,2019,"['Artificial intelligence', 'Deep learning', 'Fully convolution network', 'Image generation', 'LiDAR sensor']",,"In this paper, we propose a method of generating a 2D gray image from LiDAR 3D reflection intensity. The proposed method uses the Fully Convolutional Network (FCN) to generate the gray image from 2D reflection intensity which is projected from LiDAR 3D intensity. Both encoder and decoder of FCN are configured with several convolution blocks in the symmetric fashion. Each convolution block consists of a convolution layer with 3×3 filter, batch normalization layer and activation function. The performance of the proposed method architecture is empirically evaluated by varying depths of convolution blocks. The well-known KITTI data set for various scenarios is used for training and performance evaluation. The simulation results show that the proposed method produces the improvements of 8.56 dB in peak signal-to-noise ratio and 0.33 in structural similarity index measure compared with conventional interpolation methods such as inverse distance weighted and nearest neighbor. The proposed method can be possibly used as an assistance tool in the night-time driving system for autonomous vehicles."
딥러닝 기반 교량 손상추정을 위한 Generative Adversarial Network를 이용한 가속도 데이터 생성 모델,2019,"['Generative Adversarial Network', '생성모델', '손상추정기법', '디지털 트윈', '유지관리', 'Generative Adversarial Network', 'Generative Model', 'Damage Detection', 'Digital Twin', 'Maintenance']",,"Maintenance of aging structures has attracted societal attention. Maintenance of the aging structure can be efficiently performed with a digital twin. In order to maintain the structure based on the digital twin, it is required to accurately detect the damage of the structure. Meanwhile, deep learning-based damage detection approaches have shown good performance for detecting damage of structures. However, in order to develop such deep learning-based damage detection approaches, it is necessary to use a large number of data before and after damage, but there is a problem that the amount of data before and after the damage is unbalanced in reality.In order to solve this problem, this study proposed a method based on Generative adversarial network, one of Generative Model, for generating acceleration data usually used for damage detection approaches. As results, it is confirmed that the acceleration data generated by the GAN has a very similar pattern to the acceleration generated by the simulation with structural analysis software. These results show that not only the pattern of the macroscopic data but also the frequency domain of the acceleration data can be reproduced. Therefore, these findings show that the GAN model can analyze complex acceleration data on its own, and it is thought that this data can help training of the deep learning-based damage detection approaches."
딥러닝을 통한 차등간격의 조향각 노드 결정에 의한 자율주행,2019,"['CNN (convolution neural network)', 'non-uniform steering angle intervals', 'autonomous driving', 'deep learning']",,"In this work, an autonomous driving model using only one camera was implemented by combining a CNN (ConvolutionalNeural networks) and a YOLO (You Only Look Once) framework. Hyper-parameters in the structure were adjusted to improve drivingperformance. Autonomous driving in a corridor was performed by applying the improved model. An appropriate dropout and deeplearning structure associated with non-uniform steering angle intervals as output is proposed. The proposed algorithm was implemented,and through experiments resulted in successful obstacle avoidance and stable driving."
딥러닝을 활용한 단안 카메라 기반 실시간 물체 검출 및 거리 추정,2019,"['Deep Learning', 'Object Detection', 'Distance Estimation', 'Monocular Camera']",,"This paper proposes a model and train method that can real-time detect objects and distances estimation based on a monocular camera by applying deep learning. It used YOLOv2 model which is applied to autonomous or robot due to the fast image processing speed. We have changed and learned the loss function so that the YOLOv2 model can detect objects and distances at the same time. The YOLOv2 loss function added a term for learning bounding box values x, y, w, h, and distance values z as 클래스ification losses. In addition, the learning was carried out by multiplying the distance term with parameters for the balance of learning. we trained the model location, recognition by camera and distance data measured by lidar so that we enable the model to estimate distance and objects from a monocular camera, even when the vehicle is going up or down hill. To evaluate the performance of object detection and distance estimation, MAP (Mean Average Precision) and Adjust R square were used and performance was compared with previous research papers. In addition, we compared the original YOLOv2 model FPS (Frame Per Second) for speed measurement with FPS of our model."
딥러닝 기술을 적용한 운전자 맞춤형 긴급자동제동시스템 파라메터 추출,2019,"['customized autonomous emergency braking', 'deep neural network', 'braking propensity']",,"The autonomous emergency braking system is one of advanced driving assist systems. It is an advanced safety functiondesigned to prevent collision with a forward vehicle or a pedestrian in the event of driver’s carelessness or a sudden accident ahead.Because the AEB stops the vehicle with a maximum deceleration command at the last possible time to brake so that collision avoidance ispossible, it can prevent a collision with a preceding vehicle. However, there are risks of a secondary collision with a trailing vehicle andinjury to a passenger due to sharp deceleration. In addition, sudden braking control can present a driving feeling gap to the driver. Theseproblems must be solved because they can amplify a user's rejection of automatic emergency braking (AEB) and negatively affect theacceptability of this technology. In this study, the driver's braking propensity is derived by means of deep learning and it is applied to acustomized AEB system to prevent secondary accidents caused by sudden braking and to improve user acceptance. In order to derive adriver's braking behavior, normal driving data and stationary target based braking test data are collected. Utilizing a deep neural network,the driver’s braking profile during ordinary driving and a sudden stop are extracted. The correlation between the two extracted driver’sbraking behaviors is analyzed. This provides the means to derive sudden braking behavior as a function of driving speed, leading tocustomized AEB parameters."
딥러닝과 전이학습을 이용한 콘크리트 균열 인식 및 시각화,2019,"['Deep Learning', 'transfer learning', 'concrete crack', 'visualization']",,"Although crack on concrete exists from its early formation, crack requires attention as it affects stiffness of structure and can lead demolition of structure as it grows. Detecting cracks on concrete is needed to take action prior to performance degradation of structure, and deep learning can be utilized for it. In this study, transfer learning, one of the deep learning techniques, was used to detect the crack, as the amount of crack’s image data was limited. Pre-trained Inception-v3 was applied as a base model for the transfer learning. Web scrapping was utilized to fetch images of concrete wall with or without crack from web. In the recognition of crack, image post-process including changing size or removing color were applied. In the visualization of crack, source images divided into 30px, 50px or 100px size were used as input data, and different numbers of input data per category were applied for each case. With the results of visualized crack image, false positive and false negative errors were examined. Highest accuracy for the recognizing crack was achieved when the source images were adjusted into 224px size under gray-scale. In visualization, the result using 50 data per category under 100px interval size showed the smallest error. With regard to the false positive error, the best result was obtained using 400 data per category, and regarding to the false negative error, the case using 50 data per category showed the best result."
딥러닝과 ICP 알고리즘을 이용한 링 모양의소형 빈피킹 물체의 실시간 3차원 자세 추정,2019,"['bin picking', 'pose estimation', 'deep learning', 'object detection']",,"Bin picking is an important task in smart manufacturing and intelligent robotics. For a robot to pick or grip an object with ahuman-like gripping action, it needs to know the accurate 3D pose of the object. In this paper, we propose a method for estimating the 3Dpose of a small ring-shaped object using infrared and depth images generated by a depth camera. The proposed method consists of twoalgorithm modules, the first to recognize an object in a 2D infrared image and the second to estimate the 3D pose by applying the ICP(iterative closest point) algorithm to 3D depth data. In the first module, we propose a method to generate a three-channel integrated imagewith features from the depth and infrared images. Next, we introduce a method for training an object detector based on deep-learning.Because the bin-picking test object in this paper is small and ring-shaped, it is difficult to detect and find 3D poses of individual objectswhen many such objects are piled up. We solved this problem with a depth-based filtering method. Using the filtered image, each objectregion is separated by the deep learning approach. In the second module, the ICP algorithm is employed to estimate the 3D pose of the ringobject. We match a 3D reference model of the object and the real object using the point-to-point ICP algorithm. Performance of theproposed method is evaluated by using two different types of depth camera in the experiments."
딥러닝 기반 영상 주행기록계와 단안 깊이 추정 및 기술을 위한 벤치마크,2019,"['Visual Odomtery', 'Monocualr Depth Estimation', 'Deep Learning']",,"This paper presents a new benchmark system for visual odometry (VO) and monocular depth estimation (MDE). As deep learning has become a key technology in computer vision, many researchers are trying to apply deep learning to VO and MDE. Just a couple of years ago, they were independently studied in a supervised way, but now they are coupled and trained together in an unsupervised way. However, before designing fancy models and losses, we have to customize datasets to use them for training and testing. After training, the model has to be compared with the existing models, which is also a huge burden. The benchmark provides input dataset ready-to-use for VO and MDE research in ‘tfrecords’ format and output dataset that includes model checkpoints and inference results of the existing models. It also provides various tools for data formatting, training, and evaluation. In the experiments, the exsiting models were evaluated to verify their performances presented in the corresponding papers and we found that the evaluation result is inferior to the presented performances."
딥러닝을 활용한 상실치아 수 예측의 가능성: 파일럿 스터디,2019,"['Deep learning', 'Linear regression', 'Missing teeth', 'Real-time PCR', 'Periodontitis']",,"Objectives: The primary objective of this study was to determine if the number of missing teeth could be predicted by oral disease pathogens, and the secondary objective was to assess whether deep learning is a better way of predicting the number of missing teeth than multivariable linear regression (MLR).Methods: Data were collected through review of patient’s initial medical records. A total of 960 participants were cross-sectionally surveyed. MLR analysis was performed to assess the relationship between the number of missing teeth and the results of real-time PCR assay (done for quantification of 11 oral disease pathogens). A convolutional neural network (CNN) was used as the deep learning model and compared with MLR models. Each model was performed five times to generate an average accuracy rate and mean square error (MSE). The accuracy of predicting the number of missing teeth was evaluated and compared between the CNN and MLR methods.Results: Model 1 had the demographic information necessary for the prediction of periodontal diseases in addition to the red and the orange complex bacteria that are highly predominant in oral diseases. The accuracy of the convolutional neural network in this model was 65.0%. However, applying Model 4, which added yellow complex bacteria to the total bacterial load, increased the expected extractions of dental caries to 70.2%.On the other hand, the accuracy of the MLR was about 50.0% in all models. The mean square error of the CNN was considerably smaller than that of the MLR, resulting in better predictability.Conclusions: Oral disease pathogens can be used as a predictor of missing teeth and deep learning can be a more accurate analysis method to predict the number of missing teeth as compared to MLR."
머신러닝 및 딥러닝 연구동향 분석: 토픽모델링을 중심으로,2019,"['Machine Learning', 'Deep Learning', 'Artificial Neural Network', 'Text Mining']",,"The purpose of this study is to examine the trends on machine learning and deep learning research in the published journals from the Web of Science Database. To achieve the study purpose, we used the abstracts of 20,664 articles published between 1990 and 2017, which include the word 'machine learning', 'deep learning', and 'artificial neural network' in their titles. Twenty major research topics were identified from topic modeling analysis and they were inclusive of classification accuracy, machine learning, optimization problem, time series model, temperature flow, engine variable, neuron layer, spectrum sample, image feature, strength property, extreme machine learning, control system, energy power, cancer patient, descriptor compound, fault diagnosis, soil map, concentration removal, protein gene, and job problem. The analysis of the time-series linear regression showed that all identified topics in machine learning research were 'hot' ones."
딥러닝 기반의 농산물 가격 예측 시스템에 대한 연구,2019,"['agricultural price prediction system', 'deep learning', 'reinforcement learning', 'KAMIS']",,"This paper proposes a reinforcement learning model using agricultural price information as a deep learning-based agricultural price prediction system. Based on the information provided by KAMIS of the Korea Agro-Fisheries & Food Trade Corporation, information on price changes was collected and applied to the proposed system for the facilities crops that are not suitable for applying climate information. The proposed system consists of the environment, agents, policy neural networks and policy learners, which apply the LSTM neural network to calculate the probability of increasing revenue for sales and supply and demand activities. The simulation of the target agricultural products using the proposed system showed similar prediction results to the change of agricultural prices and showed a significant improvement compared to the existing complex agricultural price prediction techniques."
딥러닝을 이용한 시스템식별에 관한 연구,2019,"['Deep learing', 'Deep belief network', 'PID control', 'Time delay', 'Pade’ Aproximaion', 'System identification', 'Controller tuning']",,"This paper deals with a study on a system identification using deep learning in the case of a controller tuning for the system where a time delay exists. Of studies on the controller tuning for the system identification, the controller tuning method suggested by Yunwana and Seborg(1982) has an advantage of taking a good control over either none or small time delays due to phase error by Pade' approximation, whereas it comes with a disadvantage of having a greater estimated of time delay over the presence of a large time delay and of being unable to be used in a system. Furthermore, the trial-and-error method suggested by Zigler-Nichols and commonly used in industrial fields shows a disadvantage which is time consuming for a controller tuning. The controller tuning using a process response curve suggested by Cohen-Coon has a benefit of cutting more time taken for a controller tuning than the method by Zigler-Nichols does. It also faces a limitation of being applicable only to the open loop system but not applicable to the close loop system. To make up for these disadvantages, the Suh-suggested method, as its benefit, is applicable even to the close loop system. On top of this, it proposed a controller's optimal tuning method by reducing phase error through setting up control factors in the Pade' approximation with respect to the phase error generated in converting time delay into Pade' approximation. This method, however, involves putting control factors in proportion to time-delay constant values, which is therefore - as a disadvantage - not analytical. This paper went through a theoretical analysis on phase error as an analytical method to solve an issue involving the large estimation of phase error by Pade' approximation and time delay with the use of deep learning. Presented based on the findings of this existing researcher Suh (1984) was a new optimal tuning method dedicated to reducing phase error to a optimal level by setting control factors using the deep belief network algorithm out of deep learning algorithms. Besides, a related simulation was performed to compare the trial-and-error method by Zielger-Nichols and the tuning method for a controller suggested by Yunwana-Seborg, and the validity of the methods suggested in this paper was verified, accordingly."
딥러닝을 이용한 야간 감시 열화상 카메라 개발에 관한 연구,2019,"['Thermal camera', 'Infrared', 'Deep learning', 'CNN', 'YOLO']",,
딥러닝을 이용한 셰익스피어 작품의 감정 분석,2019,"['sentiment analysis', 'deep learning', 'Shakespeare', 'tweeter data']",,"This study examined the sentiment movement of Shakespeare’s plays (four tragedies and five comedies) using a deep learning technique. Sentiment analyses have been used in several fields to extract aspects of opinions using sentiment dictionaries such as ANEW, AFFINE, and VADER, which involve an evaluation of a word list for sentiment analysis. Nowadays, however, as deep learning algorithms develop, it became possible to conduct a sentiment analysis by using deep learning algorithms. This study directly compared the output of a simple deep learning model (trained with tweeters) with the output of a sentiment dictionary, VADER, targeting Shakespeare’s plays. The results showed that the simple deep learning model led to a similar performance with VADER for Shakespeare’s tragedies and outperformed the sentiment dictionary especially for Shakespeare’s comedies."
딥러닝을 이용한 번호판 검출과 인식 알고리즘,2019,"['License Plate', 'SVM', 'Machine Learning', 'Deep Learning', 'Intelligent Transportation System']",최근 지능형 교통관제 시스템에 관한 다양한 연구가 진행되고 있는 가운데 번호판 검출과 인식 알고리즘은 가장 중요한요소 중에 하나로 대두되고 있다. 번호판은 차량의 고유 식별값을 가지고 있기 때문이다. 기존의 차량 통행 관제 시스템은정차를 기반으로 하고 있으며 차량의 입출입 인식 방법으로 루프 코일을 사용하고 있다. 이러한 방법은 교통 정체를 유발하고 유지보수 비용이 상승하는 단점을 가지고 있다. 본 논문에서는 이러한 문제점을 해결하기 위해서 차량의 입출입 인식 방법으로 카메라 영상을 사용한다. 차량 통행 관제 시스템의 특성상 카메라가 고정되어 있다. 이에 차량이 접근하면 카메라의배경화면이 달라진다. 이 특징을 이용하여 배경화면의 차분영상을 구하면 차량의 입출입을 인식할 수 있다. 입출입 인식 후한국 번호판의 형태학적 특성을 이용하여 후보 이미지를 추정한다. 그리고 선형 SVM(Support Vector Machine)을 이용해서최종 번호판을 검출한다. 검출한 번호판의 글자와 숫자 인식 방법으로는 CNN(Convolutional Neural Network) 알고리즘을사용한다. 제안한 알고리즘은 기존의 시스템과 달리 검출 위치를 기준으로 글자와 숫자를 인식하기 때문에 번호판의 규격이변해도 인식할 수 있다. 실험한 결과 기존의 번호판 인식 알고리즘들 보다 제안한 알고리즘이 더 높은 인식률을 가진다.,"One of the most important research topics on intelligent transportation systems in recent years is detecting andrecognizing a license plate. The license plate has a unique identification data on vehicle information. The existing vehicletraffic control system is based on a stop and uses a loop coil as a method of vehicle entrance/exit recognition. Themethod has the disadvantage of causing traffic jams and rising maintenance costs. We propose to exploit differentialimage of camera background instead of loop coil as an entrance/exit recognition method of vehicles. After entrance/exitrecognition, we detect the candidate images of license plate using the morphological characteristics. The license plate canfinally be detected using SVM(Support Vector Machine). Letter and numbers of the detected license plate are recognizedusing CNN(Convolutional Neural Network). The experimental results show that the proposed algorithm has a higherrecognition rate than the existing license plate recognition algorithm."
딥러닝 알고리즘과 2D Lidar 센서를 이용한 이미지 분류,2019,"['Deep learning', 'deep learning neural network', 'convolutional neural network', 'object detection', 'image classification']","본 논문은 CNN (Convolutional Neural Network)와 2D Lidar 센서에서 획득한 위치 데이터를 이용하여 이미지를 분류하는 방법을 제시한다. Lidar 센서는 데이터 정확도, 형상 왜곡 및 광 변화에 대한 강인성 측면에서의 이점으로 인해 무인 장치에 널리 사용되어 왔다. CNN 알고리즘은 하나 이상의 컨볼루션 및 풀링 레이어로 구성되며 이미지 분류에 만족스러운 성능을 보여 왔다. 본 논문에서는 학습 방법에 따라 다른 유형의 CNN 아키텍처들인 Gradient Descent (GD) 및 Levenbergarquardt(LM)를 구현하였다. LM 방법에는 학습 파라메터를 업데이트하는 요소 중 하나인 Hessian 행렬 근사 빈도에 따라 두 가지 유형이 있다. LM 알고리즘의 시뮬레이션 결과는 GD 알고리즘보다 이미지 데이터의 분류 성능이 우수하였다. 또한 Hessian 행렬 근사가 더 빈번한 LM 알고리즘은 다른 유형의 LM 알고리즘보다 작은 오류를 보여주었다.","This paper presents an approach for classifying image made by acquired position data from a 2D Lidar sensor with a convolutional neural network (CNN). Lidar sensor has been widely used for unmanned devices owing to advantages in term of data accuracy, robustness against geometry distortion and light variations. A CNN algorithm consists of one or more convolutional and pooling layers and has shown a satisfactory performance for image classification. In this paper, different types of CNN architectures based on training methods, Gradient Descent(GD) and Levenbergarquardt(LM), are implemented. The LM method has two types based on the frequency of approximating Hessian matrix, one of the factors to update training parameters. Simulation results of the LM algorithms show better classification performance of the image data than that of the GD algorithm. In addition, the LM algorithm with more frequent Hessian matrix approximation shows a smaller error than the other type of LM algorithm."
딥러닝 기반 실시간 손 제스처 인식,2019,"['Leap Motion', 'Deep Learning', 'VR', 'Gesture Recognition']",,"In this paper, we propose a real-time hand gesture recognition algorithm to eliminate the inconvenience of using hand controllers in VR applications. The user's 3D hand coordinate information is detected by leap motion sensor and then the coordinates are generated into two dimensional image. We classify hand gestures in real-time by learning the imaged 3D hand coordinate information through SSD(Single Shot multibox Detector) model which is one of CNN(Convolutional Neural Networks) models. We propose to use all 3 channels rather than only one channel. A sliding window technique is also proposed to recognize the gesture in real time when the user actually makes a gesture. An experiment was conducted to measure the recognition rate and learning performance of the proposed model. Our proposed model showed 99.88% recognition accuracy and showed higher usability than the existing algorithm."
딥러닝을 이용한 IOT 기기 인식 시스템,2019,"['See-Thru Communication', 'Deep Learning', 'Convolutional Neural Network', 'Transfer Learning']",,"As the number of IOT devices is growing rapidly, various ‘see-thru connection’ techniques have been reported for efficient communication with them. In this paper, we propose a deep learning based IOT device recognition system for interaction with these devices. The overall system consists of a TensorFlow based deep learning server and two Android apps for data collection and recognition purposes. As the basic neural network model, we adopted Google’s inception-v3, and modified the output stage to classify 20 types of IOT devices. After creating a data set consisting of 1000 images of 20 categories, we trained our deep learning network using a transfer learning technology. As a result of the experiment, we achieve 94.5% top-1 accuracy and 98.1% top-2 accuracy."
딥러닝 기법을 이용한 망막 혈관 분할,2019,"['retinal imaging', 'blood vessel', 'deep learning', 'segmentation']",,"Diabetic retinopathy is a complicated form of diabetes due to circulatory disorder in the peripheral blood vessels of the retina. We segment the microvessel for diagnosing diabetic retinophathy. The conventional methods using filter and features can segment the thick blood vessels, but it has relatively weak for segmenting fine blood vessels. In pre-processing step, noise reduction filter and histogram equalization are applied to suppress the noise and enhance the image contrast. Then, deep learning technique is used for pixel-by-pixel segmentation. The accuracy of conventional methods is between 90% to 94%, while the proposed method has improved as 95% accuracy. There is a problem of segmentation error around the optic disc and exudate due to the network depth. However the accuracy can be improved by modifying the network architecture in the future."
딥러닝 기반의 보행자 탐지 및 경보 시스템 연구,2019,"['Pedestrian traffic accident prevention', 'CNN', 'YOLO', 'ITS', 'UTIS', '보행자 교통사고 방지', 'CNN', 'YOLO', '지능형 교통시스템 체계', 'UTIS']","보행자 교통사고의 경우 사고 발생 시 사망사고로 연결되는 위험성이 있다. 국내 지능형교통시스템(ITS)은 질 좋은 교통 인프라를 구축하고 있음에도 불구하고, 거의 교통정보 수집에만 이용되고 있어, 위험상황 발생 시 지능적인 위험 요소 분류가 이루어지지 않고 있다. 본 연구에서 제안하는 시스템의 주요 구성 요소인 CNN 기반의 보행자 탐지 분류 모델의 경우 제한적인 환경에서 설치 운영되는 것을 가정하여 임베디드 시스템 기반으로 구현되었다. 기존YOLO의 인공신경망 모델을 개선하여 My-Tiny-Model3라는 새로운 모델을 생성하였고, 20,000 번의 반복 학습 기준으로 평균 정확도 86.29%와 21.1 fps의 실시간 탐지 속도 결과를 보였다.그리고, 이러한 탐지 시스템을 기반으로 하여 ITS 체계와 연계 가능한 시스템 구현 및 프로토콜 연동 시나리오를 구성하였다. 본 연구를 통해 기존 ITS 체계와 연동하는 보행자 사고 방지시스템을 구현한다면, 새로운 인프라 구축비용을 절감하고 보행자 교통사고 발생률을 줄이는데 도움이 될 것이다. 또한, 기존의 시스템 감시인력 소요에 따른 비용 또한 줄일 수 있을 것으로 기대된다.","In the case of a pedestrian traffic accident, it has a large-scale danger directly connected by a fatal accident at the time of the accident. The domestic ITS is not used for intelligent risk classification because it is used only for collecting traffic information despite of the construction of good quality traffic infrastructure. The CNN based pedestrian detection classification model, which is a major component of the proposed system, is implemented on an embedded system assuming that it is installed and operated in a restricted environment. A new model was created by improving YOLO's artificial neural network, and the real-time detection speed result of average accuracy 86.29% and 21.1 fps was shown with 20,000 iterative learning. And we constructed a protocol interworking scenario and implementation of a system that can connect with the ITS. If a pedestrian accident prevention system connected with ITS will be implemented through this study, it will help to reduce the cost of constructing a new infrastructure and reduce the incidence of traffic accidents for pedestrians, and we can also reduce the cost for system monitoring."
딥러닝 설명을 위한 슈퍼픽셀 제외·포함 다중스케일 접근법,2019,,,"As deep learning has become popular, researches which can help explaining the prediction results also become important. Superpixel based multi-scale combining technique, which provides the advantage of visual pleasing by maintaining the shape of the object, has been recently proposed. Based on the principle of prediction difference, this technique computes the saliency map from the difference between the predicted result excluding the superpixel and the original predicted result. In this paper, we propose a new technique of both excluding and including super pixels. Experimental results show 3.3% improvement in IoU evaluation."
딥러닝을 활용한 반도체 제조 물류 시스템 통행량 예측모델 설계,2019,"['Semiconductor', 'prediction model', 'AutoMod', 'deep learning']",,"Semiconductor logistics systems are facing difficulties in increasing production as production processes become more complicated due to the upgrading of fine processes. Therefore, the purpose of the research is to design predictive models that can predict traffic during the pre-planning stage, identify the risk zones that occur during the production process, and prevent them in advance. As a solution, we build FABs using automode simulation to collect data. Then, the traffic prediction model of the areas of interest is constructed using deep learning techniques (keras - multistory conceptron structure). The design of the predictive model gave an estimate of the traffic in the area of interest with an accuracy of about 87%. The expected effect can be used as an indicator for making decisions by proactively identifying congestion risk areas during the Fab Design or Factory Expansion Planning stage, as the maximum traffic per section is predicted."
딥러닝 모델 기반 단기 전력수요 예측,2019,"['Deep Learning', 'Short-Term Load Forecasting', 'CNN', 'LSTM']",,"This paper presents a Short-Term Long-short term memory Convolutional neural network(STLC) Model that is combined with Convolutional Neural Network(CNN) and Long-Short Term Memory(LSTM). CNN model predicts load pattern using past load profile, LSTM model forecasts load variation depending on temperature and time index. STLC model’s output is hourly load data to combine two model’s outputs. The input parameters of STLC model are composed of time index, weighted weather data, past load data. Weights are calculated based on electricity consumption by main region in South Korea and reflects in the weather data. STLC model is trained with data from 2013 through 2017 and is verified with data from 2018. The STLC model forecasts 1-day hourly load data. Simulation results obtained show the comparison of actual and forecasted load data and also compare with other methods in MAPE(Mean Absolute Percentage Error) to prove accuracy of the proposed model."
딥러닝 기술을 이용한 트러스 구조물의 손상 탐지,2019,"['Damage detection', 'Deep learning', 'Neural network', 'Truss structure']",,"There has been considerable recent interest in deep learning techniques for structural analysis and design. However, despite newer algorithms and more precise methods have been developed in the field of computer science, the recent effective deep learning techniques have not been applied to the damage detection topics. In this study, we have explored the structural damage detection method of truss structures using the state-of-the-art deep learning techniques. The deep neural networks are used to train knowledge of the patterns in the response of the undamaged and the damaged structures. A 31-bar planar truss are considered to show the capabilities of the deep learning techniques for identifying the single or multiple-structural damage. The frequency responses and the elasticity moduli of individual elements are used as input and output datasets, respectively. In all considered cases, the neural network can assess damage conditions with very good accuracy."
딥러닝을 활용한 에지 컴퓨팅 기반의 지능형 컨스트럭션 영상 관제 시스템,2019,"['edge computing', 'machine learning', 'deep learning', 'video management system', 'supervised learning']",,"With the development of artificial intelligence technology, artificial intelligence has begun to be applied in various fields. In particular, in each domain area of the industry, attempts are made to reduce costs or generate revenue by applying various artificial intelligence technologies in the existing service types. The intelligent construction video management system is an intelligent internet field live monitoring system that synchronizes noise, vibration, gas levels and on-site images at the site as quickly as possible and presents them online in the event of a civil complaint. Based on intelligent edge computing, this paper implements a system that automatically controls traffic transmitted from edge node to cloud efficiently in order to prevent overflow of field images stored in the cloud. Performance measurement results were checked with the implemented system and performance improvement was achieved with a traffic reduction rate of more than 10% compared to the previous one while maintaining the same quality of service. If the system is applied to small construction sites, it is expected to save some hundreds of thousands of won per month in communications costs."
딥러닝 기술 기반 HEVC로 압축된 영상의 이중 압축 검출 기술,2019,"['Video Forensic', 'Double Compression Detection', 'HEVC', 'Picture Partitioning', 'Deep Learning']",,"Detection of double compression is one of the most efficient ways of remarking the validity of videos. Many methods have been introduced to detect HEVC double compression with different coding parameters. However, HEVC double compression detection under the same coding environments is still a challenging task in video forensic. In this paper, we introduce a novel method based on the frame partitioning information in intra prediction mode for detecting double compression in with the same coding environments. We propose to extract statistical feature and Deep Convolution Neural Network (DCNN) feature from the difference of partitioning picture including Coding Unit (CU) and Transform Unit (TU) information. Finally, a softmax layer is integrated to perform the classification of the videos into single and double compression by combing the statistical and the DCNN features. Experimental results show the effectiveness of the statistical and the DCNN features with an average accuracy of 87.5% for WVGA and 84.1% for HD dataset."
딥러닝을 이용한 당뇨성황반부종 등급 분류의 정확도 개선을 위한 검증 데이터 증강 기법,2019,"['deep learning', 'Validation data augmentation', 'Diagnostic accuracy', 'Diabetic macular edema']",,"This paper proposed a method of validation data augmentation for improving the grading accuracy of diabetic macular edema (DME) using deep learning. The data augmentation technique is basically applied in order to secure diversity of data by transforming one image to several images through random translation, rotation, scaling and reflection in preparation of input data of the deep neural network (DNN). In this paper, we apply this technique in the validation process of the trained DNN, and improve the grading accuracy by combining the classification results of the augmented images. To verify the effectiveness, 1,200 retinal images of Messidor dataset was divided into training and validation data at the ratio 7:3. By applying random augmentation to 359 validation data, 1.61 ± 0.55% accuracy improvement was achieved in the case of six times augmentation (N=6). This simple method has shown that the accuracy can be improved in the N range from 2 to 6 with the correlation coefficient of 0.5667. Therefore, it is expected to help improve the diagnostic accuracy of DME with the grading information provided by the proposed DNN."
고속 딥러닝 알고리즘의 효과적인 구현,2019,"['Artificial intelligence', 'Deep learning', 'Digital signal processing', 'Image classification', 'Keras', 'Tensorflow']",,"AI (Artificial Intelligence) based on deep learning has been successful in many application areas. Supervised learning such as image classification and object detection has been mainly used for vision and ADAS (Advanced Driver Assistance Systems) / AD (Autonomous Driving). And reinforce learning has been generally utilized for robotics and energy optimization. Therefore, in order to improve the performance, many research papers have focused on optimizing neural networks. However, in practice, FPS (frame per second) is a hidden and critical factor because FPS is also included in the performance measurement. This note show that pre-processing and post-processing are major components affecting FPS. And It is verified that FPS cannot be improved by optimizing the neural network itself because the pre-processing and post-processing are out of the neural networks. In this note, fast pre-processing methods on the basis of DSP (digital signal processing) is suggested. For DSP implementation, binary arithmetic is presented and quantization error due to the conversion from floating point calculation to fixed point calculation is discussed. In addition, major design frameworks for deep learning algorithm implementation are compared and their merit and demerit are also summarized. In the note, implementation is categorized into three, i.e., input data generation with pre-processing, model design of neural network, and performance evaluation. With the selected framework, detailed implementation is also presented."
LSTM과 GRU 딥러닝 IoT 파워미터 기반의 단기 전력사용량 예측,2019,"['Power Meter', 'Internet of Things', 'Deep Learning', 'LSTM', 'GRU', 'Short-term Power Forecasting']","본 연구에서는 Long Short Term Memory (LSTM) 신경망과 Gated Recurrent Unit(GRU) 신경망을Internet of Things (IoT) 파워미터에 적용하여 단기 전력사용량 예측방법을 제안하고, 실제 가정의 전력사용량 데이터를 토대로 예측 성능을 분석한다. 성능평가 지표로써 Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE), Mean Percentage Error (MPE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE) 를 이용한다. 실험 결과는 GRU 기반의 모델이 LSTM 기반의 모델에 비해 MAPE 기준으로 4.52%, MPE 기준으로5.59%만큼의 성능개선을 보였다.","In this paper, we propose a short-term power forecasting method by applying Long Short Term Memory (LSTM) and Gated Recurrent Unit (GRU) neural network to Internet of Things (IoT) power meter.We analyze performance based on real power consumption data of households. Mean absolute error (MAE), mean absolute percentage error (MAPE), mean percentage error (MPE), mean squared error (MSE), and root mean squared error (RMSE) are used as performance evaluation indexes. The experimental results show that the GRU-based model improves the performance by 4.52% in the MAPE and 5.59% in the MPE compared to the LSTM-based model."
트랜잭션 기반 머신러닝에서 특성 추출 자동화를 위한 딥러닝 응용,2019,"['Machine Learning', 'Deep Learning', 'Feature Engineering', 'Automated Feature Extraction', 'Transaction Data']",,"Machine learning (ML) is a method of fitting given data to a mathematical model to derive insights or to predict. In the age of big data, where the amount of available data increases exponentially due to the development of information technology and smart devices, ML shows high prediction performance due to pattern detection without bias. The feature engineering that generates the features that can explain the problem to be solved in the ML process has a great influence on the performance and its importance is continuously emphasized. Despite this importance, however, it is still considered a difficult task as it requires a thorough understanding of the domain characteristics as well as an understanding of source data and the iterative procedure. Therefore, we propose methods to apply deep learning for solving the complexity and difficulty of feature extraction and improving the performance of ML model. Unlike other techniques, the most common reason for the superior performance of deep learning techniques in complex unstructured data processing is that it is possible to extract features from the source data itself. In order to apply these advantages to the business problems, we propose deep learning based methods that can automatically extract features from transaction data or directly predict and classify target variables. In particular, we applied techniques that show high performance in existing text processing based on the structural similarity between transaction data and text data. And we also verified the suitability of each method according to the characteristics of transaction data. Through our study, it is possible not only to search for the possibility of automated feature extraction but also to obtain a benchmark model that shows a certain level of performance before performing the feature extraction task by a human. In addition, it is expected that it will be able to provide guidelines for choosing a suitable deep learning model based on the business problem and the data characteristics."
소프트맥스를 이용한 딥러닝 음악장르 자동구분 투표 시스템,2019,,,"Research that implements the classification process through Deep Learning algorithm, one of the outstanding human abilities, includes a unimodal model, a multi-modal model, and a multi-modal method using music videos. In this study, the results were better by suggesting a system to analyze each song's spectrum into short samples and vote for the results. Among Deep Learning algorithms, CNN showed superior performance in the category of music genre compared to RNN, and improved performance when CNN and RNN were applied together. The system of voting for each CNN result by Deep Learning a short sample of music showed better results than the previous model and the model with Softmax layer added to the model performed best. The need for the explosive growth of digital media and the automatic classification of music genres in numerous streaming services is increasing. Future research will need to reduce the proportion of undifferentiated songs and develop algorithms for the last category classification of undivided songs."
컴퓨터 비전과 딥러닝을 통한 견종식별 연구,2019,"['Computer Vision', 'Deep Learning', 'Companion Animal']",,
임베디드 GPU에서의 딥러닝 기반 실시간 보행자 탐지 기법,2019,"['Pedestrian detection', 'convolutional neural network', 'embedded system']","본 논문은 임베디드 GPU에서 실시간 동작하는 딥 컨볼루션 뉴럴 네트워크(CNN) 기반의 보행자 탐지 기법을 제안한다. 제안하는 기법에서는 먼저 영상 내 보행자 크기에 대한 통계적 분석을 통해서 최적의 컨볼루션 층의 개수를 결정한다. 또한, 본 논문에서는 다중 스케일 CNN 학습 기법을 적용하여 영상 내의 보행자 크기 변화에 강인한 탐지 기법을 개발한다. 컴퓨터 모의실험을 통해 제안하는 알고리즘이 임베디드 GPU에서 실시간 동작하면서도 기존의 기법과 비교하여 평균적으로 높은 정확도를 보임을 확인한다.",
잡음제거 모델 훈련을 위한 딥러닝 기반 가상 데이터베이스 생성 기법,2019,"['Deep neural network', 'virtual noisy database', 'real environment', 'denoising', 'ideal ratio mask']",,
GAN과 DNN을 활용한 딥러닝 기반의 지능형 개인신용 평가모형,2019,"['FinTech', 'Deep Learning', 'Imbalance Data', 'GAN', 'DNN']",,"data using machine learning techniques such as decision trees, neural networks, deep learning, and GAN. We develop a personal credit rating model to resolve an issue from imbalanced data for machine learning by utilized the SMOTE and GAN. Personal credit rating is an important system for personal loans such as FinTech, and has been applied with many deep learning techniques. Therefore, the purpose of this study is to develop an intelligent personal credit rating model based on deep learning that can be effectively used in a small data set. Therefore, in this study, 5 samples of 10,000 data sets are sampled and the size of the data set is increased by utilizing the SMOTE and GAN, which is an over sampling technique. We applied classification techniques such as logit, decision tree, ANN, and DNN. Then, to solve the imbalanced data problems, we applied under sampling, SMOTE, and GAN, and compared which the performance of statistical techniques, machine learning, and deep learning. As a result, deep learning based on personal credit rating model of SMOTE + DNN showed the highest performance with 66.2%."
영상기반 콘크리트 균열 탐지 딥러닝 모델의 유형별 성능 비교,2019,"['crack detection', 'deep learning', 'image classification', 'object detection', 'semantic segmentation', 'instance segmentation']",,"In this study, various types of deep learning models that have been proposed recently are classified according to data input / output types and analyzed to find the deep learning model suitable for constructing a crack detection model. First the deep learning models are classified into image classification model, object segmentation model, object detection model, and instance segmentation model. ResNet-101, DeepLab V2, Faster R-CNN, and Mask R-CNN were selected as representative deep learning model of each type. For the comparison, ResNet-101 was implemented for all the types of deep learning model as a backbone network which serves as a main feature extractor. The four types of deep learning models were trained with 500 crack images taken from real concrete structures and collected from the Internet. The four types of deep learning models showed high accuracy above 94% during the training.Comparative evaluation was conducted using 40 images taken from real concrete structures. The performance of each type of deep learning model was measured using precision and recall. In the experimental result, Mask R-CNN, an instance segmentation deep learning model showed the highest precision and recall on crack detection.Qualitative analysis also shows that Mask R-CNN could detect crack shapes most similarly to the real crack shapes."
효과적인 인간-로봇 상호작용을 위한 딥러닝 기반 로봇 비전 자연어 설명문 생성 및 발화 기술,2019,"['Human-Robot Interaction', 'Video To Audio Description', 'Video Captioning', 'Speech Synthesis', 'Text To Speech']",,"For effective human-robot interaction, robots need to understand the current situation context well, but also the robots need to transfer its understanding to the human participant in efficient way. The most convenient way to deliver robot’s understanding to the human participant is that the robot expresses its understanding using voice and natural language. Recently, the artificial intelligence for video understanding and natural language process has been developed very rapidly especially based on deep learning. Thus, this paper proposes robot vision to audio description method using deep learning. The applied deep learning model is a pipeline of two deep learning models for generating natural language sentence from robot vision and generating voice from the generated natural language sentence. Also, we conduct the real robot experiment to show the effectiveness of our method in human-robot interaction."
알약 자동 인식을 위한 딥러닝 모델간 비교 및 검증,2019,"['Pill Classification', 'Object Detection', 'Deep Learning', 'Artificial Intelligent', 'Hospital']",,"When a prescription change occurs in the hospital depending on a patient’s improvement status, pharmacists directly classify manually returned pills which are not taken by a patient. There are hundreds of kinds of pills to classify. Because it is manual, mistakes can occur and which can lead to medical accidents. In this study, we have compared YOLO, Faster R-CNN and RetinaNet to classify and detect pills. The data consisted of 10 classes and used 100 images per class. To evaluate the performance of each model, we used cross-validation. As a result, the YOLO Model had sensitivity of 91.05%, FPs/image of 0.0507. The Faster R-CNN’s sensitivity was 99.6% and FPs/image was 0.0089. The RetinaNet showed sensitivity of 98.31% and FPs/image of 0.0119. Faster RCNN showed the best performance among these three models tested. Thus, the most appropriate model for classifying pills among the three models is the Faster R-CNN with the most accurate detection and classification results and a low FP/image."
현실 환경에서 증강현실과 딥러닝을 활용한 M&S 모델 증강가시화,2019,"['Modeling & Simulation (M&S)', 'Augmented reality', 'Deep learning', 'Visual augmentation']",,"This paper proposes a new method to effectively visualize modeling & simulation (M&S) results in a real environment using augmented reality (AR) and deep learning. The proposed approach makes it possible to dynamically generate an M&S analysis space of the real environment, to recognize real objects by using a deep learning technique, and to place the analyzed M&S results onto them. In order to construct an M&S space dynamically, we perform area learning on the real space using a smart device supporting RGB-D camera. In addition, real objects are recognized through deep learning-based object detection. Spatial mapping and user interaction are conducted to match the recognized real object with corresponding M&S model in the mobile AR environment. A proof-of-concept system was developed to show the advantage and feasibility of the proposed method. Therefore, the proposed approach can be used for seamlessly integrating M&S models into various real spaces and for reviewing M&S results more consistently and effectively."
SNS에서 텍스트-칼라영상의 교차양식 검색을 위한 데이터셋 구축과 딥러닝 모델,2019,"['Cross Modal Retrieval', 'Social Network Service(SNS)', 'Text-Image Dataset', 'Deep Learning', 'Computer Vision']",,
심실 조기 수축 비트 검출을 위한 딥러닝 기반의 최적 파라미터 검출,2019,['RR'],,"Legacy studies for classifying arrhythmia have been studied to improve the accuracy of classification, Neural Network, Fuzzy, etc. Deep learning is most frequently used for arrhythmia classification using error backpropagation algorithm by solving the limit of hidden layer number, which is a problem of neural network. In order to apply a deep learning model to an ECG signal, it is necessary to select an optimal model and parameters. In this paper, we propose optimal parameter extraction method based on a deep learning. For this purpose, R-wave is detected in the ECG signal from which noise has been removed, QRS and RR interval segment is modelled. And then, the weights were learned by supervised learning method through deep learning and the model was evaluated by the verification data. The detection and classification rate of R wave and PVC is evaluated through MIT-BIH arrhythmia database. The performance results indicate the average of 99.77% in R wave detection and 97.84% in PVC classification."
자율주행 자동차 환경에서의 3D-LiDAR 와 딥러닝을 이용한 클러스터링 후보군 기반 실시간 객체 검출,2019,"['autonomous vehicle', '3d-LiDAR', 'clustering', 'deep learning', 'object detection']",,"Recently, IT companies such as Google, NVIDIA, and NAVER have been also developing autonomous vehicle platform technologies. In particular, sensors for object detection in surrounding environments have been improved in recognition rates by applying multi-sensor systems using camera, LiDAR, and radar. With the increasing importance of recognition technology, 3D information-based recognition technologies have been actively advanced as a commercial product of 3D-LiDAR. In this paper, a candidate group of point-clouds from 3D-LiDAR is extracted using Euclidean clustering in order to reduce the processing time delay in RPN (Region Proposal Network), which is one of the basic schemes for existing object detection. Then, it proposes types of input slicing, based on the extracted candidates. In addition, the accuracy and the processing time using four CNN networks (Basic CNN, ResNet, VGG16, and MobileNet) are compared over not only the private data (CVLab dataset) obtained in actual road environment but also the publicly open KITTI dataset."
반도체 제조라인 내 물류자동화시스템의 처리능력 향상을 위한 딥러닝 기반 디스패칭 방법론,2019,"['Scheduling', 'Deep learning', 'Semiconductor manufacturing', 'Lot targeting']",,"We present a deep-learning-based prediction method for the machine allocation problem of production scheduling in semiconductor manufacturing fabrication (FAB). This method is devised to improve the throughput capacity of the automated material handling system (AMHS). A prediction method is applied to determine the machine to perform the next process after a lot completes a process. Selecting the proper machine for the next process can shorten the travel distance of the overhead hoist transfers (OHTs), and this will eventually lead to reduced utilization and increased throughput capacity of the AMHS. The results confirm that the accuracy of our deep-learning-based machine selecting method is quite high and that it outperforms the other machine learning methods."
시간에 따라 변화하는 빗줄기 장면을 이용한 딥러닝 기반 비지도 학습 빗줄기 제거 기법,2019,"['Rain Streak Removal', 'Unsupervised Learning', 'Convolutional Neural Networks', 'Siamese Network']",,"Single image rain removal is a typical inverse problem which decomposes the image into a background scene and a rain streak. Recent works have witnessed a substantial progress on the task due to the development of convolutional neural network (CNN). However, existing CNN-based approaches train the network with synthetically generated training examples. These data tend to make the network bias to the synthetic scenes. In this paper, we present an unsupervised framework for removing rain streaks from real-world rainy images. We focus on the natural phenomena that static rainy scenes capture a common background but different rain streak. From this observation, we train siamese network with the real rain image pairs, which outputs identical backgrounds from the pairs. To train our network, a real rainy dataset is constructed via web-crawling. We show that our unsupervised framework outperforms the recent CNN-based approaches, which are trained by supervised manner. Experimental results demonstrate that the effectiveness of our framework on both synthetic and real-world datasets, showing improved performance over previous approaches."
도로포장의 유지관리 계획 수립을 위한 딥러닝 기반 열화 예측 모델 개발,2019,"['Pavement Deterioration Prediction', 'Deep Learning', 'Recurrent Neural Network', 'Long Short-Term Memory', 'Deep Neural Network']",,"The maintenance cost for road pavement is gradually increasing due to the continuous increase in road extension as well as increase in the number of old routes that have passed the public period. As a result, there is a need for a method of minimizing costs through preventative grievance preventive maintenance requires the establishment of a strategic plan through accurate prediction of road pavement. Hence, In this study, the deep neural network(DNN) and the recurrent neural network(RNN) were used in order to develop the expressway pavement damage prediction model. A superior model among these two network models was then suggested by comparing and analyzing their performance. In order to solve the RNN’s vanishing gradient problem, the LSTM (Long short-term memory) circuits which are a more complicated form of the RNN structure were used. The learning result showed that the RMSE value of the RNN-LSTM model was 0.102 which was lower than the RMSE value of the DNN model, indicating that the performance of the RNN-LSTM model was superior. In addition, high accuracy of the RNN-LSTM model was verified through the comparison between the estimated average road pavement condition and the actually measured road pavement condition of the target section over time."
수신된 전파신호의 자동 변조 인식을 위한 딥러닝 방법론,2019,,,"The automatic modulation recognition of a radio signal is a major task of an intelligent receiver, with various civilian and military applications. In this paper, we propose a method to recognize the modulation of radio signals in wireless communication based on the deep neural network. We classify the modulation pattern of radio signal by using the LSTM model, which can catch the long-term pattern for the sequential data as the input data of the deep neural network. The amplitude and phase of the modulated signal, the in-phase carrier, and the quadrature-phase carrier are used as input data in the LSTM model. In order to verify the performance of the proposed learning method, we use a large dataset for training and test, including the ten types of modulation signal under various signal-to-noise ratios."
유사 영상 거칠기와 공간잡음 비용함수를 이용한 딥러닝 신경망 장면 기반 불균일보정,2019,"['Deep Neural Network', 'Image Roughness-like', 'SN', 'SBNUC', 'Improved IRLMS']",,"In this paper, a new Scene-based Nonuniformity Correction (SBNUC) method is proposed by applying Image Roughness-like and Spatial Noise cost functions on deep neural network structure. The classic approaches for nonuniformity correction require generally plenty of sequential image data sets to acquire accurate image correction offset coefficients. The proposed method, however, is able to estimate offset from only a couple of images powered by the characteristic of deep neural network scheme. The real world SWIR image set is applied　to verify the performance of proposed method and the result shows that image quality improvement of PSNR 70.3dB (maximum) is achieved. This is about 8.0dB more than the improved IRLMS algorithm which preliminarily requires precise image registration process on consecutive image frames."
건설현장 근로자의 안전모 착용 여부 검출을 위한 컴퓨터 비전 기반 딥러닝 알고리즘의 적용,2019,"['construction safety', 'safety helmet', 'deep learning', 'computer vision']",,"Since construction sites are exposed to outdoor environments, working conditions are significantly dangerous. Thus, wearing of the personal protective equipments such as safety helmet is very important for worker safety. However, construction workers are often wearing-off the helmet as inconvenient and uncomportable. As a result, a small mistake may lead to serious accident. For this, checking of wearing safety helmet is important task to safety managers in field.However, due to the limited time and manpower, the checking can not be executed for every individual worker spread over a large construction site. Therefore, if an automatic checking system is provided, field safety management should be performed more effectively and efficiently. In this study, applicability of deep learning based computer vision technology is investigated for automatic checking of wearing safety helmet in construction sites. Faster R-CNN deep learning algorithm for object detection and classification is employed to develop the automatic checking model. Digital camera images captured in real construction site are used to validate the proposed model.Based on the results, it is concluded that the proposed model may effectively be used for automatic checking of wearing safety helmet in construction site."
수중 소나 영상 학습 데이터의 왜곡 및 회전 Augmentation을 통한 딥러닝 기반의 마커 검출 성능에 관한 연구,2019,"['Deep Learning', 'Data Augmentation', 'Object Detection', 'Underwater Sonar Image']",,"In the ground environment, mobile robot research uses sensors such as GPS and optical cameras to localize surrounding landmarks and to estimate the position of the robot. However, an underwater environment restricts the use of sensors such as optical cameras and GPS. Also, unlike the ground environment, it is difficult to make a continuous observation of landmarks for location estimation. So, in underwater research, artificial markers are installed to generate a strong and lasting landmark. When artificial markers are acquired with an underwater sonar sensor, different types of noise are caused in the underwater sonar image. This noise is one of the factors that reduces object detection performance. This paper aims to improve object detection performance through distortion and rotation augmentation of training data. Object detection is detected using a Faster R-CNN."
엔터프라이즈 환경의 딥 러닝을 활용한 이미지 예측 시스템 아키텍처,2019,"['Deep Learning', 'Softmax', 'ReLU', 'CNN', 'Inception', 'Architecture', '딥 러닝', 'Softmax', 'ReLU', 'CNN', '인셉션', '아키텍처']","본 논문에서는 엔터프라이즈 환경에서의 딥 러닝에 대한 이미지 예측 시스템 아키텍처를 제안한다. 엔터프라이즈 환경에 대해 인공지능 플랫폼으로 변환을 쉽게 하고, 인공지능 플랫폼이 파이선에 집중되어서 자바 중심의 엔터프라이즈 개발이 어려운 단점을 개선하기 위해 자바 중심의 아키텍처에서도 충분한 딥 러닝 서비스의 개발과 수정이 가능하도록 한다. 또한, 제안된 환경을 토대로 이미지 예측 실험을 통해 기존에 학습된 딥 러닝 아키텍처 환경에서의 정확도가 높은 예측 시스템을 제안한다. 실험을 통해 딥 러닝이 수행되기 위해 제공된 이미지 예에서 95.23%의 정확도를 보이며, 제안된 모델은 유사한 다른 모델에 비교해 96.54%의 정확도를 보인다. 제시된 아키텍처를 활용하여 활발한 엔터프라이즈급 환경의 딥 러닝 서비스가 개발 및 제공될 것으로 보이며, 기존 엔터프라이즈 환경이 딥 러닝 아키텍처가 탑재된 환경으로 전환이 활발히 이루어질 것이다.","This paper proposes an image prediction system architecture for deep running in enterprise environment. Easily transform into an artificial intelligence platform for an enterprise environment, and allow sufficient deep-running services to be developed and modified even in Java-centric architectures to improve the shortcomings of Java-centric enterprise development because artificial intelligence platforms are concentrated in the pipeline. In addition, based on the proposed environment, we propose a more accurate prediction system in the deep running architecture environment that has been previously learned through image forecasting experiments. Experiments show 95.23% accuracy in the image example provided for deep running to be performed, and the proposed model shows 96.54% accuracy compared to other similar models."
ARM 기반 IoT 장치에서 효율적인 딥 러닝 수행을 위한 BLAS 및 신경망 라이브러리의 성능 및 에너지 비교,2019,"['IoT', 'deep learning', 'deep learning library', 'deep learning profiling', 'GPU-based acceleration', 'IoT', '딥 러닝', '딥 러닝 라이브러리', '딥 러닝 프로파일링', 'GPU 가속']","기존에 IoT 장치에서 딥 러닝을 수행하기 위해 주로 클라우드 컴퓨팅을 사용했다. 그러나 클라우드 컴퓨팅을 사용할 경우 연결을 보장할 수 없고, 통신을 위한 에너지 소모, 그리고 보안에 대한 취약성이 문제가 된다. 이와 같은 문제점을 해결하기 위해 최근 IoT 장치 내에서 딥 러닝을 수행하기 위한 시도가 진행되고 있다. 이 시도들은 주로 IoT 장치를 위한 연산량이 적은 딥 러닝 모델 또는 압축 기법 등을 제안하지만, 실제 IoT 장치에서 수행될 때의 영향에 대한 분석이 부족했다. IoT 장치마다 연산 장치의 구성과 지원되는 라이브러리가 다르기 때문에, 최적의 딥 러닝 수행을 위해 각 IoT 장치에서 다양한 수행 환경에 대한 분석이 필요하다. 본 논문에서는 다양한 하드웨어 구성을 가진 IoT 장치에서 수행 환경에 따른 성능 및 에너지를 측정하고 분석한다. 또한, 적절한 라이브러리를 사용하는 것만으로도 속도와 에너지 효율이 최대 9.43배, 26.78배까지 상승하는 것을 보여준다.","Cloud computing is generally used to perform deep learning on IoT devices. However, its application is associated with limitations such as connection instability, energy consumption for communication, and security vulnerabilities. To solve such problems, recent attempts at performing deep learning within IoT devices have occurred. These attempts mainly suggest either lightweight deep learning models or compression techniques concerning IoT devices, but they lack analysis of the effect when it is performed in actual IoT devices. Since each IoT device has different configuration of processing units and supported libraries, it is necessary to analyze various execution environments in each IoT device in order to perform optimized deep learning. In this study, performance and energy of IoT devices with various hardware configurations were measured and analyzed according to the application of the deep learning model, library, and compression technique. It was established that utilizing the appropriate libraries improve both speed and energy efficiency up to 13.3 times and 48.5 times, respectively."
딥 러닝 및 칼만 필터를 이용한 객체 추적 방법,2019,"['YOLO', 'Kalman filter', 'Object tracking', 'CNN', 'Deep learning']","딥 러닝의 대표 알고리즘에는 영상 인식에 주로 사용되는 CNN(Convolutional Neural Networks), 음성인식 및 자연어 처리에 주로 사용되는 RNN(Recurrent Neural Networks) 등이 있다. 이 중 CNN은 데이터로부터 자동으로 특징을 학습하는 알고리즘으로 특징 맵을 생성하는 필터까지 학습할 수 있어 영상 인식 분야에서 우수한 성능을 보이면서 주류를 이루게 되었다. 이후, 객체 탐지 분야에서는 CNN의 성능을 향상하고자 R-CNN 등 다양한 알고리즘이 등장하였으며, 최근에는 검출 속도 향상을 위해 YOLO(You Only Look Once), SSD(Single Shot Multi-box Detector) 등의 알고리즘이 제안되고 있다. 하지만 이러한 딥러닝 기반 탐지 네트워크는 정지 영상에서 탐지의 성공 여부를 결정하기 때문에 동영상에서의 안정적인 객체 추적 및 탐지를 위해서는 별도의 추적 기능이 필요하다. 따라서 본 논문에서는 동영상에서의 객체 추적 및 탐지 성능 향상을 위해 딥 러닝 기반 탐지 네트워크에 칼만 필터를 결합한 방법을 제안한다. 탐지 네트워크는 실시간 처리가 가능한 YOLO v2를 이용하였으며, 실험 결과 제안한 방법은 기존 YOLO v2 네트워크에 비교하여 7.7%의 IoU 성능 향상 결과를 보였고 FHD 영상에서 20 fps의 처리 속도를 보였다.",
모노 카메라 영상과 딥 러닝을 이용한 차량 검출 및 거리 등급 분류에 관한 연구,2019,"['딥러닝', '객체검출', '거리추정', '단안카메라', 'Deep learning', 'Object Detection', 'Distance Estimation', 'Mono Camera']","본 연구에서는 차량에 부착된 모노 카메라와 딥 러닝을 이용하여 객체 검출 및 검출된 객체에 대한 거리정보를 바탕으로 하는 위험도 분류 시스템을 제안한다. 다양한 상황에서 기존 컴퓨터 비전 기법들보다 변화에 강인하며 검출 능력이 뛰어난 딥 러닝을 이용하여 주행 영상을 통해 주행환경 상에 있는 객체들을 검출한다. 이때 객체 검출기로는 합성 곱 신경망 네트워크를 기반으로 만들어진 YOLO v2(You Only Look Once v2)알고리즘을 이용하며, 해당 알고리즘은 사전에 ImageNet 1000 Class 데이터로 학습 된 Pre-trained model에 KITTI 데이터 셋 및 웹 포털 사이트에서 크롤링을 통해 획득한 12K개의 이미지를 이용하여 전이학습 하였다. 그리고 DB 구축 Tool을 이용하여 KITTI 데이터 셋에서 취득한 이미지와 캘리브레이션된 LiDAR 센서 데이터를 통해 검출된 객체와의 거리 정보를 취득하였다. 객체 검출기의 결과로는 Bounding Box의 이미지 내 좌표인 x,y와 Bounding Box의 이미지 내 크기인 width, height 정보가 나온다. 객체와의 거리정보를 특정 구간 단위로 분류하여 Class화 하였고, 해당 Class(거리 등급)와 객체 검출 정보인 Bounding box 정보들을 Multi-layer Perceptron을 이용하여 분류한다.","In this study, we propose a risk classification system based on distance information of object detected and objects detection using mono camera based on deep learning. It detects the objects in the driving environment through driving images by using deep learning which is robust against change and has superior detection ability than existing computer vision techniques in various situations. In this case, we use YOLO v2 (You Only Look Once v2) algorithm, which is based on a convolution neural network as an object detector. The algorithm uses a KITTI data set and a web portal The site was trained using 12K images acquired through crawling. Using the DB construction tool, we obtained the distance information between the image obtained from the KITTI dataset and the detected object through the calibrated LiDAR sensor data. The result of the object detector is x, y coordinates in the image of the bounding box, and width and height information in the image of the bounding box. Classification is made by classifying the distance information with objects in a specific section, and classification of the class (distance class) and object detection information, Bounding box information, using Multi-layer Perceptron."
딥 러닝을 이용한 안면 여드름 분류 모델,2019,"['Deep Learning', 'Classification', 'Correlation Analysis', 'ACNE', 'CNN', '딥 러닝', '분류', '상관분석', '여드름', '컨볼루션 뉴럴 네트워크']","의학계에 다양하게 인공지능을 적용하는데 있어 한계는 우선적으로 해석자의 병증 이미지를 해석하는데 주관적 견해와 광범위한 해석자, 육체적 피로감 등이다. 그리고 병증마다 주석 달린 데이터 셋을 수집하는데 기간이 오래 걸린다는 것과 개발된 딥러닝 학습 알고리즘의 성능 저하가 없으면서도 충분한 훈련 데이터를 얻을지에 대한 의문이 있다는 것이다.이에 본 논문에서는 여드름 데이터 셋을 기준으로 기본 이미지를 수집할 때 선정 기준과 수집 절차에 대해 연구하고, Sequential 구조로 딥 러닝 기법을 적용하여 적은 손실률(5.46%)과 높은 정확도(96.26%)로 데이터를 분류하는 모델을 제안한다. Keras에서 기본 제공하는 모델과 비교실험을 통해 제안 모델의 성능을 비교 검증한다. 향후 본 논문에서 제안하는 여드름 분류 모델에 유사 현상들 적용하여 의학 및 피부 관리 분야에도 적용 가능할 것으로 예상된다.","The limitations of applying a variety of artificial intelligence to the medical community are, first, subjective views, extensive interpreters and physical fatigue in interpreting the image of an interpreter's illness. And there are questions about how long it takes to collect annotated data sets for each illness and whether to get sufficient training data without compromising the performance of the developed deep learning algorithm.In this paper, when collecting basic images based on acne data sets, the selection criteria and collection procedures are described, and a model is proposed to classify data into small loss rates (5.46%) and high accuracy (96.26%) in the sequential structure. The performance of the proposed model is compared and verified through a comparative experiment with the model provided by Keras. Similar phenomena are expected to be applied to the field of medical and skin care by applying them to the acne classification model proposed in this paper in the future."
딥 러닝을 이용한 주택가격 예측에 관한 연구,2019,"['주택매매가격', '비선형', '예측', '딥 러닝', '순환신경망(RNN)', 'Housing Price', 'Nonlinear', 'Prediction', 'Deep Learning', 'Recurrent Neural Network']",,"The purpose of this study is to estimate housing prices using deep running. The simple RNN, LSTM, and GRU models, which are evaluated to be suitable for time series forecasting, are based on the time series data of apartment real price index, interest rate, household loan, building permit area and consumer price index. As a result of the empirical analysis, it is confirmed that the prediction power of the GRU model is superior to that of the learning data by evaluating the performance of forecasting power on apartment real price index based on the RMSE value. On the other hand, in the verification data, it is confirmed that the prediction power of the RNN model is excellent. Also, if the performance of the deep running model is evaluated with accuracy, the accuracy of the RNN model and the GRU model is the highest. As a result of this study, the government needs to build and develop a system that can predict and diagnose the housing market by using the deep learning technique that combines artificial neural network and big data to advance the housing market."
딥 러닝을 활용한 인공지능의 예술표현 사례 연구,2019,"['Artificial Intelligence', 'Deep Learning', 'Art Expression', '인공지능', '딥 러닝', '예술표현']","본 논문은 최근 떠오르고 있는 인류 산업의 과제인 인공지능의 예술표현에 대해 연구하였다. 지금까지의 인공지능 예술표현 사례 분석을 통해 앞으로 과학기술의 예술적 수용에 있어 인공지능이 지니는 새로운 가능성과 한계점을 파악하여 인공지능을 활용한 예술이 발전할 수 있는 기반을 마련하는 데 그 목적이 있다. 이를 위해 딥 러닝의 개념과 인공지능 시대에서 예술의 전개 방향과 특징을 파악하고, 창의성과 행위의 주체성을 기준으로 인공지능의 예술표현 사례를 간접적 표현 측면과 직접적 표현 측면으로 나누어 Deep Dream, The Next Rembrandt, Aaron 등을 분석하였다. 사례 분석을 통해 인간의 신경활동을 본떠 만든 인공신경회로망을 기반으로 구축한 기계학습, 즉 인간의 두뇌가 수많은 데이터 속에서 패턴을 발견한 뒤 사물을 구분하는 정보처리 방식을 모방한 인공지능은 스스로 15세기부터 20세기에 이르기까지 다양한 이미지를 학습할 수 있으며, 축척된 방대한 데이터를 통해 원하는 형태의 그림을 자유롭게 그릴 수 있다는 사실을 알 수 있었다. 또한 인간과 비교할 수 없는 인공지능의 습득 속도에 따른 발달이 예술분야 전반에 미칠 영향으로 연구 필요성을 확인하였다.본 연구를 통해 과학기술을 활용하여 예술을 표현하는 것은 변화하는 시대 속에서 다르게 요구되는 상대적 속성인 예술의 의미를 구현하는 방식의 변화이자 표현양상임을 알 수 있었다. 따라서 본 연구를 기반으로 다각도에서 예술과 인공지능의 관계에 대해 생각한 인공지능의 예술표현 확장을 기대한다.","This study examined artistic expression by artificial intelligence(AI), which is one of the recently emerging topics in the human industries. By analyzing cases of artistic expression by AI up to the present, this study aims to ascertain the new possibilities and limitations presented by AI with regard to the artistic acceptance of science and technology. It also intends to provide the foundations for the future development of AI-based art. For this purpose, we first presented the concept of deep learning in addition to the direction and characteristics of how art is evolving in the age of AI. Based on this, we analyzed cases of AI-based artistic expression such as Deep Dream, The Next Rembrandt, and Aaron, making distinctions between the aspects of direct and indirect expression and based on the criteria of creativity and autonomy of action. This study’s case analysis revealed that machine learning systems built upon ANN, which mimics human neural activity, were able to imitate the information processing methods of the human brain—i.e., discovering patterns within the myriad data and identifying objects—such that they could learn diverse images from the 15th to the 20th century. We also found that they could use the vast accumulated data to freely draw pictures as they intended. Furthermore, we confirmed the need to study how the highly superior learning speed of AI, and the development thereof, would affect the arts in general. This study’s significance lies in that, by examining artistic expression through science and technology, it explores the changes in how the meaning of art—which is a relative attribute that changes with the times—is realized and expressed. Therefore, based on this research, we expect to expand the artistic expression of artificial intelligence that thought about the relation between art and artificial intelligence in various angles."
시각 장애인 가상현실 체험 환경을 위한 딥 러닝을 활용한 몰입형 보행 상호작용 설계,2019,"['몰입형 가상현실', '보행 상호작용', '딥러닝', '시각장애인', 'immersive virtual reality', 'walking interaction', 'deep learning', 'visually impaired people']","본 연구는 시각 장애인의 도보 적응올 위한 새로운 가상현실 체험 환경을 제안한다. 제안하는 가상현실 체험 환경의 핵심은 몰입형 보행 상호작용과 딥러닝 기반 점자 블록 인식으로 구성된다. 우선, 시각 장애인의 입장에서 현실적인 걷기 경험을 제공함을 목적으로 제자리 걸음을 감지하여 걷기를 판단하는 트래커 기반 걷기 처리과정과 시각 장애인의 보행 보조 도구를 가상현실에 적용한 컨트롤러 기반 VR 횐지광이를 설계한다. 또한, VR 횐지광이를 활용한 길 안내 과정에서 도로 위의 점자 블록 인지 및 반응 등 종합적인 의사결정을 수행하는 학습 모델을 제안한다. 이를 기반으로 가상현실 도보 체험 환경에 대한 실험을 위하여 실외 도시 환경으로 구성된 가상현실 어플리케이션을 제작하고, 참가자를 대상으로 설문 실험 및 성능 분석을 진행하였다. 결과적으로 제안한 가상현실 체험 환경이 시각 장애인의 입장에서 현존감 높은 도보 체험을 제공하고 있음을 확인하였다. 그리고 제안한 학습과 처 리과정이 인도와 차도, 인도 위의 점자 블록을 높은 정확도로 인지함을 확인하였다.","In this study, a novel virtual reality (VR) experience environment is proposed for enabling walking adaptation of visually impaired people. The core of proposed VR environment is based on immersive walking interactions and deep learning based braille blocks recognition. To provide a realistic walking experience from the perspective of visually impaired people, a tracker-based walking process is designed for determining the walking state by detecting marching in place, and a controller-based VR white cane is developed that serves as the walking assistance tool for visually impaired people. Additionally, a learning model is developed for conducting comprehensive decision-making by recognizing and responding to braille blocks situated on roads that are followed during the course of directions provided by the VR white cane. Based on the same, a VR application comprising an outdoor urban environment is designed for analyzing the VR walking environment experience. An experimental survey and performance analysis were also conducted for the participants. Obtained results corroborate that the proposed VR walking environment provides a presence of high-level walking experience from the perspective of visually impaired people. Furthermore, the results verify that the proposed learning algorithm and process can recognize braille blocks situated on sidewalks and roadways with high accuracy."
딥 러닝과 데이터 결합에 의한 싱크홀 트래킹,2019,"['sinkhole tracking', 'CNN transfer learning', 'data association', 'Hungarian Algorithm', 'Otsu algorithm']",,"Accurate tracking of the sinkholes that are appearing frequently now is an important method of protecting human and property damage. Although many sinkhole detection systems have been proposed, it is still far from completely solved especially in-depth area. Furthermore, detection of sinkhole algorithms experienced the problem of unstable result that makes the system difficult to fire a warning in real-time. In this paper, we proposed a method of sinkhole tracking by deep learning and data association, that takes advantage of the recent development of CNN transfer learning. Our system consists of three main parts which are binary segmentation, sinkhole classification, and sinkhole tracking. The experiment results show that the sinkhole can be tracked in real-time on the dataset. These achievements have proven that the proposed system is able to apply to the practical application."
딥 러닝을 이용한 비디오 카메라 모델 판별 시스템,2019,"['video camera model identification', 'forensic', 'deep learning', 'convolutional neural network']","현대 사회에서 영상 정보 통신 기술이 발전함에 따라서 영상 획득 및 대량 생산 기술도 급속히 발전하였지만 이를 이용한 범죄도 증가하여 범죄 예방을 위한 법의학 연구가 진행되고 있다. 영상 획득 장치에 대한 판별 기술은 많이 연구되었지만, 그 분야가 영상으로 한정되어 있다. 본 논문에서는 영상이 아닌 동영상에 대한 카메라 모델의 판별 기법을 제안한다. 기존의 영상을 학습한 모델을 사용하여 동영상의 프레임을 분석하였고, 동영상의 프레임 특성을 활용한 학습과 분석을 통하여 P 프레임을 활용한 모델의 우수성을 보였다. 이를 이용하여 다수결 기반 판별 알고리즘을 적용한 동영상에 대한 카메라 모델 판별 시스템을 제안하였다. 실험에서는 5개 비디오 카메라 모델을 이용하여 분석을 하였고, 각각의 프레임 판별에 대해 최대 96.18% 정확도를 얻었으며, 비디오 카메라 모델 판별 시스템은 각 카메라 모델에 대하여 100% 판별률을 달성하였다.","With the development of imaging information communication technology in modern society, imaging acquisition and mass production technology have developed rapidly. However, crime rates using these technology are increased and forensic studies are conducted to prevent it. Identification techniques for image acquisition devices are studied a lot, but the field is limited to images. In this paper, camera model identification technique for video, not image is proposed. We analyzed video frames using the trained model with images. Through training and analysis by considering the frame characteristics of video, we showed the superiority of the model using the P frame. Then, we presented a video camera model identification system by applying a majority-based decision algorithm. In the experiment using 5 video camera models, we obtained maximum 96.18% accuracy for each frame identification and the proposed video camera model identification system achieved 100% identification rate for each camera model."
딥 러닝 기법을 이용한 오피니언 마이닝 분석과 성과에 관한 실증연구: 합성곱 신경망 모델과 머신러닝 모델간 성과비교를 중심으로,2019,"['Deep learning', 'Convolutional neural network', 'Sentiment analysis', 'Opinion mining', 'Machine learning classifiers', 'Financial supervisory policy', '딥 러닝', '합성곱 신경망', '감성분석', '오피니언 마이닝', '머신러닝 분류기']","본 연구는 딥 러닝 기법인 합성곱 신경망 (CNN: Convolutional Neural Network)을 이용하여 금융자료에 관한 사용자의 오피니언을 추정하는 오피니언 마이닝 (Opinion mining) 방법과 그 결과를 설명한다. 본 연구에서는 다음과 같이 합성곱 신경망의 효과성을 검증하였다. 첫째, 스터디1은 주식관련 온라인 리뷰 데이터를 분석하였다. 즉, 형태소 분석단계를 거쳐 속성벡터를 만들어 리뷰 문장의 감성점수를 산출하였다. 해당 문장의 감성점수에 따라 오피니언을 3-클라스, 5-클라스 문제로 구분하여 실증분석을 하였다. 둘째, 스터디2에서는 청와대 국민청원에 게시된 금융관련 국민청원 텍스트 문장을 분석하여 청원인원을 추정하였다. 청원게시판에 등재된 청원 인원을 분위 수에 따라 분류하여 2-클라스 문제 (50%이상, 50% 미만) 4-클라스 문제 (75%이상, 50%이상, 25%이상, 25%미만)로 분류하였다. 스터디1, 2의 실증분석결과 정확도, 정밀도, 재현율, F1 점수 등 모든 성과지표에서 벤치마킹용 분류기와 비교할 때 합성곱 신경망이 더 우수한 성과를 보였다. 따라서, 합성곱 신경망을 이용함으로써 금융감독 관련 정책 및 활동을 효과적으로 수행할 수 있음을 실증적으로 확인하였다.",
딥 러닝 기법을 이용한 레이더 신호 분류 모델 연구,2019,"['Deep Learning(딥 러닝)', 'Convolutional Neural Network(컨볼루션 신경망)', 'Recurrent Neural Network(순환신경망)', 'Radar Signal Classification(레이더 신호 분류)', 'Electronic Warfare(전자전)']",,"Classification of radar signals in the field of electronic warfare is a problem of discriminating threat types by analyzing enemy threat radar signals such as aircraft, radar, and missile received through electronic warfare equipment. Recent radar systems have adopted a variety of modulation schemes that are different from those used in conventional systems, and are often difficult to analyze using existing algorithms. Also, it is necessary to design a robust algorithm for the signal received in the real environment due to the environmental influence and the measurement error due to the characteristics of the hardware. In this paper, we propose a radar signal classification method which are not affected by radar signal modulation methods and noise generation by using deep learning techniques."
딥 러닝 기반의 이미지학습을 통한 저항 용접품질 검증,2019,"['Resistance welding(저항 용접)', 'Quality verification(품질 검증)', 'Deep learning(딥 러닝)', 'Tensorflow(텐서플로우)']",,"Welding is one of the most popular joining methods and most welding quality estimation methods are executed using joined material. This paper propose welding quality estimation methods using dynamic current, voltage and resistance which are obtained during welding in real time. There are many kinds of welding method. Among them, we focused on the projection welding and gathered dynamic characteristics from two different types of projection welding. For image learning, graphs are drawn using obtained current, voltage and resistance, and the graphs are converted to images. The images are labeled with two sub-categories - normal and defect. For deep learning of images obtained from welding, Convolutional Neural Network (CNN) is applied, and Tensorflow was used as a framework for deep learning. With two resistance welding test datasets, we conclude that the Convolutional Neural Network helps in predicting the welding quality."
딥 러닝 기반 얼굴 메쉬 데이터 디노이징 시스템,2019,"['3D mesh data', 'denoising', 'deep learning', 'autoencoder', 'convolution']","3차원 프린터나 깊이 카메라 등을 이용하면 실세계의 3차원 메쉬 데이터를 손쉽게 생성할 수 있지만, 이렇게 생성된 데이터에는 필연적으로 불필요한 노이즈가 포함되어 있다. 따라서, 온전한 3차원 메쉬 데이터를 얻기 위해서는 메쉬 디노이징 작업이 필수적이다. 하지만 기존의 수학적인 디노이징 방법들은 전처리 작업이 필요하며 3차원 메쉬의 일부 중요한 특징들이 사라지는 문제점이 있다. 본 논문에서는 이러한 문제를 해결하기 위해 딥 러닝 기반의 3차원 메쉬 디노이징 기법을 소개한다. 구체적으로 본 논문에서는 인코더와 디코더로 구성된 컨볼루션 기반 오토인코더 모델을 제안한다. 메쉬 데이터에 적용하는 컨볼루션 연산은 메쉬 데이터를 구성하고 있는 각각의 정점과 그 주변의 정점들 간의 관계를 고려하여 디노이징을 수행하며, 컨볼루션이 완료되면 학습 속도 향상을 위해 샘플링 연산을 수행한다. 실험 결과, 본 논문에서 제안한 오토인코더 모델이 기존 방식보다 더 빠르고 더 높은 품질의 디노이징된 데이터를 생성함을 확인하였다.","Although one can easily generate real-world 3D mesh data using a 3D printer or a depth camera, the generated data inevitably includes unnecessary noise. Therefore, mesh denoising is essential to obtain intact 3D mesh data. However, conventional mathematical denoising methods require preprocessing and often eliminate some important features of the 3D mesh. To address this problem, this paper proposes a deep learning based 3D mesh denoising method. Specifically, we propose a convolution-based autoencoder model consisting of an encoder and a decoder. The convolution operation applied to the mesh data performs denoising considering the relationship between each vertex constituting the mesh data and the surrounding vertices. When the convolution is completed, a sampling operation is performed to improve the learning speed. Experimental results show that the proposed autoencoder model produces faster and higher quality denoised data than the conventional methods."
딥 러닝 기반 휴먼 모션 디노이징,2019,"['human motion', 'motion capture', 'motion denoising', 'attention', 'bidirectional recurrent neural network']","본 논문에서는 어텐션 기법을 적용한 양방향 순환신경망을 이용하여 새로운 휴먼 모션 디노이징 방법을 제안한다. 본 방법을 이용하면, 단일 3D 깊이 센서 카메라에서 캡처된 노이즈가 포함된 사람의 움직임이 잘 교정된 자연스러운 움직임으로 자동 조정된다. 양방향 순환신경망에 어텐션 기법을 도입하면, 입력으로 들어온 움직임을 인코딩할 때 여러 자세 중에 더 중요한 자세가 있는 프레임에 더 높은 어텐션 가중치를 부여함으로써, 다른 딥 러닝 네트워크와 비교해 더 나은 최적화 결과와 더 높은 정확도를 보인다. 실험을 통해 본 논문에서 제시한 방법이 다양한 스타일의 움직임과 노이즈를 효과적으로 처리함을 확인하였으며, 제시한 방법은 모션 캡처 후처리 단계의 애플리케이션으로 충분히 사용 가능할 것으로 기대된다.","In this paper, we propose a novel method of denoising human motion using a bidirectional recurrent neural network (BRNN) with an attention mechanism. The corrupted motion captured from a single 3D depth sensor camera is automatically fixed in the well-established smooth motion manifold. Incorporating an attention mechanism into BRNN achieves better optimization results and higher accuracy than other deep learning frameworks because a higher weight value is selectively given to a more important input pose at a specific frame for encoding the input motion. Experimental results show that our approach effectively handles various types of motion and noise, and we believe that our method can sufficiently be used in motion capture applications as a post-processing step after capturing human motion."
IoT 및 딥 러닝 기반 스마트 팜 환경 최적화 및 수확량 예측 플랫폼,2019,"['Agricultural', 'Analysis System', 'Artificial Intelligence System', 'CNN', 'Smart Farm']","본 논문은 농장의 바이오 센서 데이터를 수집해서 농장에서 재배중인 농작물의 질병을 진단하고, 그 해 수확량을 예측하는 IoT 및 딥 러닝 기반 스마트 팜 환경 최적화 및 수확량 예측 플랫폼을 제안한다. 이 플랫폼은 현재 날씨, 토양 미생물 등 수집 가능한 모든 정보를 수집하여 작물이 잘 성장할 수 있도록 농장 환경을 최적화하고, 농장에서 재배 중인 작물의 잎을 이용하여 작물의 질병을 진단하고, 그리고, 농장의 모든 정보를 사용하여 올해 수확량을 예측한다. 실험 결과 AEOM(Agricultural Environment Optimization Module)의 평균 정확도는 RF(Random Forest)보다 약 15%, GBD(Gradient Boosting Tree)보다 약 8% 높고, 데이터가 증가해도 RF나 GBD에 비해 정확도가 덜 감소한다. 선형 회귀에 따르면 정확도의 기울기는 ReLU의 경우 –3.641E-4, Sigmoid의 경우 –4.0710E-4, 계단함수의 경우 –7.4534E-4이다. 따라서 ReLU 사용시 정확도 기울기가 가장 낮으므로 테스트 데이터의 양이 증가함에 따라 ReLU는 다른 두 가지 활성화 기능보다 더 정확하다. 본 논문에서 제안한 EOYPP는 농장 전체를 관리하는 플랫폼으로 실제 농장에 도입된다면 국내 스마트 팜의 발전에 크게 이바지할 것이다.","This paper proposes “A Smart Farm Environment Optimization and Yield Prediction Platform based on IoT and Deep Learning” which gathers bio-sensor data from farms, diagnoses the diseases of growing crops, and predicts the year's harvest. The platform collects all the information currently available such as weather and soil microbes, optimizes the farm environment so that the crops can grow well, diagnoses the crop’s diseases by using the leaves of the crops being grown on the farm, and predicts this year's harvest by using all the information on the farm. The result shows that the average accuracy of the AEOM is about 15% higher than that of the RF and about 8% higher than the GBD. Although data increases, the accuracy is reduced less than that of the RF or GBD. The linear regression shows that the slope of accuracy is –3.641E-4 for the ReLU, –4.0710E-4 for the Sigmoid, and –7.4534E-4 for the step function. Therefore, as the amount of test data increases, the ReLU is more accurate than the other two activation functions. This paper is a platform for managing the entire farm and, if introduced to actual farms, will greatly contribute to the development of smart farms in Korea."
차량용 인포테인먼트 시스템의 딥 러닝 기반 UI 테스팅 자동화 기술,2019,"['소프트웨어 테스팅 자동화', 'UI 테스팅 자동화', '차량용 인포테인먼트 시스템', '인공지능 응용', '객체검출', 'R-CNN', 'software testing automation', 'UI testing automation', 'in-vehicle infotainment system', 'artificial intelligence application', 'object detection', 'R-CNN']","최근 텔레메틱스(Telematics), 커넥티드 카(Connected Car), 자율 주행 자동차 기술의 발전으로 인해 차량용 인포테인먼트 시스템(In-Vehicle Infotainment, IVI)에 포함되는 기능이 다양화되고 역할과 중요도가 크게 높아지고 있다. 이에 따라 IVI와 사용자 간의 상호작용을 담당하는 사용자 인터페이스(User Interface, UI)의 복잡성이 증가되고 있으며, 높은 품질의 UI 개발을 위한 UI 테스팅 기술의 필요성 또한 증대되었다. 본 논문에서는 IVI의 화면으로부터 객체를 인식하는 딥 러닝 모델을 이용한 UI 테스팅 자동화 기술을 제안하고, IVI 자동화 테스팅 도구 VISTA에 적용시킨 사례에 대해 기술한다.","Lately, the functions included in the in-vehicle infotainment system (IVI) have diversified and their roles and importance greatly increased due to the development of telematics, connected cars, and autonomous vehicle technology. the complexity of the user interface (UI) responsible for the interaction between IVI and the user, and the need for a UI testing technique for a UI. In this paper, we propose a UI testing technology using a deep learning model that recognizes objects from the IVI screen, and describe a case where it is applied to IVI automation testing tool VISTA."
산불 방재용 무선 센서 네트워크에서 딥 러닝 기반의 온도 센서 데이터 추정 및 산불 전파 예측,2019,"['Wireless Sensor Network', 'duty cycle', 'wildfire prediction', 'Deep Neural Network', 'Recurrent Neural Network']",,
딥 러닝 기반의 SIFT 이미지 특징 추출,2019,"['SIFT Feature extraction', 'Deep learning', 'VGG', 'CNN(Convolutional Neural Network)', 'Repeatability']","본 논문에서는 일정 크기로 자른 영상의 가운데 픽셀이 SIFT 특징점인지를 판별함으로써 SIFT 특징점을 추출하는 딥 뉴럴 네트워크(Deep Neural Network)를 제안한다. 이 네트워크의 데이터 세트는 DIV2K 데이터 세트를 33×33 크기로 잘라서 구성하고, 흑백 영상으로 판별하는 SIFT와는 달리 RGB 영상을 사용한다. 그라운드 트루스(ground truth)는 옥타브(scale, octave)를 0, 시그마(sigma)는 1.6, 간격(intervals)은 3으로 설정하여 추출한 RobHess SIFT 특징들로 구성한다. VGG-16을 기반으로 컨볼루션 층을 13개에서 23개와 33개로 점점 깊은 네트워크를 구성하고, 영상의 스케일을 증가시키는 방법을 바꿔가며 실험을 수행한다. 출력 층의 활성화 함수로 시그모이드(sigmoid) 함수를 사용한 결과와 소프트맥스(softmax) 함수를 사용한 결과를 비교하여 분석한다. 실험결과 제안한 네트워크가 99% 이상의 추출 정확도를 가질 뿐 아니라 왜곡된 영상에 대해서도 높은 추출 반복성을 가진다는 것을 보인다.",
딥 러닝 기반 대학 이수학점 및 활동에 의한 교원임용 후보자 경쟁 시험 합격여부 예측,2019,,,"The recent increase in preference for teacher jobs has led to a rise in preference for education colleges. Not all students can enter teachers, but they must pass the test called the competitive examination for teacher appointment candidates after graduation. However, due to the declining population, the and employment T.O.s are decreasing every year and the competition rate is rising steeply. Therefore, in order to concentrate on the recruitment exam upon entering the university, the university is becoming a huge academy for the exam, not a place to study and learn. We found a connection between students' overall school life and their use of study groups as well as their grades and whether they passed the competition test for teachers using deep running. The academic activities did not significantly affect the acceptance process, and the accuracy of the prediction of the acceptance rate was generally 70% accurate."
딥 러닝 기반의 영상처리 기법을 이용한 겹침 돼지 분리,2019,"['Pig Monitoring', 'Occluding Pigs', 'Segmentation', 'Deep Learning', 'YOLO']",,"The crowded environment of a domestic pig farm is highly vulnerable to the spread of infectious diseases such as foot-and-mouth disease, and studies have been conducted to automatically analyze behavior of pigs in a crowded pig farm through a video surveillance system using a camera. Although it is required to correctly separate occluding pigs for tracking each individual pigs, extracting the boundaries of the occluding pigs fast and accurately is a challenging issue due to the complicated occlusion patterns such as X shape and T shape. In this study, we propose a fast and accurate method to separate occluding pigs not only by exploiting the characteristics (i.e., one of the fast deep learning-based object detectors) of You Only Look Once, YOLO, but also by overcoming the limitation (i.e., the bounding box-based object detector) of YOLO with the test-time data augmentation of rotation. Experimental results with two-pigs occlusion patterns show that the proposed method can provide better accuracy and processing speed than one of the state-of-the-art widely used deep learning-based segmentation techniques such as Mask R-CNN (i.e., the performance improvement over Mask R-CNN was about 11 times, in terms of the accuracy/processing speed performance metrics)."
압축 영상 화질 개선을 위한 딥 러닝 연구에 대한 분석,2019,"['CNN', 'HEVC', 'Noise Reduction', 'Quality Enhancement']","최근 CNN (Convolutional Neural Network) 기반의 화질 개선 기술이 H.265/HEVC와 같은 블록 기반 영상 압축 표준을 사용하여 압축된 영상의 화질을 향상시키는 데 적극적으로 사용되어 왔다. 이 논문은 이러한 영상 압축 기술을 위한 화질 개선 연구의 추세를 요약하고 분석하는 것을 목표로 한다. 먼저, 화질 개선을 위한 CNN의 구성 요소를 살펴보고 이미지 도메인에서의 사전 연구를 요약한다. 다음으로 네트워크 구조, 데이터셋 및 학습 방법의 세 가지 측면에서 관련 연구들을 정리하고 성능 비교를 위한 구현 및 실험 결과를 제시하고자 한다.",
머신러닝에 관한 OSS 라이선스 연구,2019,"['Artificial Intelligence', 'Machine Learning', 'Deep Learning', 'Tensorflow', 'Open Source Software', 'License', 'Open Source License', 'Apache License', 'Copyright', '인공지능', '머신러닝', '딥러닝', '텐서플로', '오픈소스 소트웨어', '라이선스', '오픈소스 라이선스', '아파치 라이선스', '저작권']","인공지능에 관한 산업적 관심이 높아지고 시장이 확대되면서 국내에서 인공지능에 관한 컴퓨터프로그램(이하 “프로그램”이라 한다)의 활용이 점차 확대되고 있다. 인공 지능을 구현하기 위해 머신러닝 기술이 활용되는데, 이 분야의 주요한 머신러닝 관련 프로그램으로 TensorFlow를 비롯하여 scikit-learn, Machine Learning Library (MLlib), Weka 3 등이 있다. 그리고 이것들에는 오픈소스 라이선스인 Apache License v.2.0, MIT License 및 New BSD License(3-Clause BSD License)이 적용되었다. 특히, Apache License v.2.0에 관하여서는 국제적으로 높은 사용률을 보이면서도 국내에 참고문헌이 많지 않다. 그리고 프로그램의 법적 문제는 이것에 적용된 라이선스의 해석에 기초해 야 하므로, 적용된 라이선스들의 구체적인 해석이 필요하다. 그렇지만 관련 산업에서 오픈소스 소프트웨어에 대한 법적 문제의식은 상당히 낮은 상황이다. 따라서 오픈소 스 소프트웨어에 적용된 라이선스들에 대한 법적 해석론을 제시함에 의해 관련 산업 에서의 잠재적인 법적 문제들을 해결할 수 있을 것이다. 그래서 이 논문은 머신러닝 에 관한 오픈소스 소프트웨어에 적용된 오픈소스 라이선스들에 대해 간략히 살펴보 고, 라이선스에 사용된 중요한 용어들을 검토한 후에, 라이선스의 주요한 법적 문제들 을 검토하다. Apache License v.2.0, MIT License 및 New BSD License는 퍼미시브 라이선스이고, 이 중 Apache License v.2.0은 정의, 저작권, 특허, 상표 등을 포함하여 상당히 구체적으로 규 정되어 있다. 그리고 라이선시는 재배포 시에 라이선스를 함께 배포하고, 저작권 외에도 특허권, 상표권 등에 관하여 고려해야 한다. 그런데 이 라이선스는 오픈소스 이니셔티브 의 오픈소스의 정의에 부합하도록 정의되어 있으면서, 퍼미시브 라이선스로 오픈소스 소프트웨어의 이용자 측면에서 비교적 유연한 내용들을 포함한다. 예를 들어 TensorFlow 와 같이 이 라이선스가 적용된 프로그램의 변경물이나 2차적저작물의 일부 또는 전체에 추가적인 또는 별도의 라이선스 규정 및 조건을 부여할 수 있다. 다만, 카피레프트 조항 을 포함하는 라이선스와의 양립성의 문제는 카피레프트 라이선스로의 일방적인 통합을 의미한다. 결론적으로, Apache License v.2.0은 개발자나 사업자의 관점에서는 다양한 선택지를 갖도록 한다. 그렇지만 오픈소스 라이선스가 적용된 머신러닝 관련 프로그램들을 이용할 때 라 이선스와 관련한 사안들에 유의해야 할 필요가 있다. 우선, 조합저작물 또는 2차적저 작물에 대해 권리 및 귀속 고지의 의무를 반드시 준수해야 한다. 그리고 작은 분량의 프로그램도 저작권이 있을 수 있으므로 권리 및 귀속에 관한 고지를 소스 형태 내에 반드시 포함시키도록 한다. 또한 머신러닝 관련 프로그램들을 조합하거나 이 프로그 램을 다른 프로그램에 포함시키는 경우에 라이선스 간의 양립성 문제가 발생할 수 있 으므로, 라이선스의 양립성에 대해 유의해야 한다. 이에 더해 라이선시는 머신러닝에 관한 오픈소스 소프트웨어를 활용하여 발명을 하고 이것에 대해 특허를 취득한 경우 에, 특허 소송에 대한 보복조항이 있을 수 있고 없더라도 묵시적 실시허락이 인정될 수 있으므로, 특허 소송은 신중하게 접근할 필요가 있다.","As the industrial interest on artificial intelligence(AI) increases and the market related to AI expands, the application of computer programs on AI is gradually expanding in Korea. Machine learning technology is used to implement AI, and major machine learning programs in this field include scikit-learn, Machine Learning Library (MLlib), and Weka 3 in addition to TensorFlow, which are covered by the Apache License v.2.0, MIT License and New BSD License(3-Clause BSD License). In particular, Apache License v.2.0 has a high usage rate internationally, but there are not many references in the country. And the copyright issue of the program must be based on the interpretation of the license applied to it, so a specific interpretation of the applied licenses is necessary. However, legal awareness of open source software (OSS) in the related industry is very low. Therefore, we expect to be able to solve the potential legal problems in the related industry by presenting the legal interpretation related to the licenses applied to the OSS. So, this paper briefly reviews the open source licenses applied to OSS for machine learning, reviews the key terms used in the licenses, and then reviews the major legal issues of the licenses. The Apache License v.2.0, MIT License, and New BSD License are Permissive licenses, of which the Apache License v.2.0 was prescribed in considerable detail, including definitions, copyright, patent, and trademark. And Licensee shall distribute the Licenses at the time of redistribution and take into account patents, trademarks, etc. in addition to copyrights. However, this license is defined to conform to Open Source Initiative’s open source definition, and it also includes relatively flexible content in terms of users of the OSS as a permissive license. For example, Licensee of programs such as TensorFlow may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole under certain conditions. However, the issue of compatibility with licenses including copyleft terms implies a one way integration into copyleft licenses. In conclusion, the Apache license v.2.0 allows a wide variety of choices from the developer or business perspective. Nevertheless, you need to be aware of issues related to OSS licenses when using programs licensed by OSS licenses. First of all, you shall comply with the obligations of the rights and attribution notices for the combined or Derivative works. And a small amount of programs can be copyrighted, so you shall be sure to include notices of rights and attribution in the source form. In addition, compatibility between licenses may occur when combining machine learning-related programs or including them in other programs, so you shall be careful about licenses’ compatibility. In addition, if a licensee invents and patents using an open source software related to machine learning, patent litigation needs to be taken with caution, as there may be retaliation provision for patent litigation and implied licenses may be admitted."
인공지능(AI) 기술을 이용한 디지털 성범죄에 대한 검토 - 딥페이크(Deepfake) 포르노 규제를 중심으로 -,2019,"['Deepfake Porno', 'Act on Promotion of Information and Communication Network Utilization and Information protection', 'Act on Special Cases Concerning the Punishment', 'etc. of Sexual Crimes', 'Taking Photos by Using Cameras', 'etc.', 'Digital-sexual Crimes', 'Criminal Regulations', '딥페이크 포르노', '정보통신망법', '성폭력처벌법', '카메라등이용촬영죄', '디지털성폭력', '형사규제']","최근 유명 연예인 등에 의한 일련의 소위 디지털 성범죄가 발생함에 따라 다시금 카메라등이용촬영및 유포행위에 대한 문제의 심각성이 크게 대두되었다. 그러나 이러한 문제의 심각성에 대해서는 사건발생시 국회와 언론만 뜨겁게 반응했을 뿐, 아직 일반시민의 의식 저변을 변화시키는데 까지는 이르지못했음이 여실히 들어났다.이를 반증하는 것으로 최근 한국에서도 본격적으로 ‘가짜 연예인 음란 동영상’ 문제가 불거지고 있다. 이른바 ‘지인능욕’이라고 불리는 딥페이크(Deepfake) 포르노 문제가 바로 그러한데, 이는 인공지능(AI) 기술인 딥러닝을 활용하여 피해자의 음성과 얼굴을 위조하고 이를 통해 편집⋅영상합성된 포르노 영상물을 유포하는 것이다. 문제는 이러한 딥페이크 포르노가 기존의 보편화된 컴퓨터그래픽 기술에 인공지능(AI) 딥러닝기법으로 손쉽게 제작가능하다는 점과 이렇게 업로드되는 딥페이크 포르노영상을 완벽하게 필터링할 수 없다는 점, 더욱이 불법영상물이 급속도로 확산될 뿐만 아니라 완전히삭제되지 않아 피해자가 계속적으로 피해를 받아야 한다는 점에 있다.한편, 이에 대하여 현재 정보통신망법상 허위사실적시 사이버명예훼손죄나 사이버 음란물유포죄로형사처벌하고 있는데, 이는 실제 성행위 촬영이 이루지지 않다는 점에 근거하는 것이다. 이로 인해 불법촬영물 성폭력범죄에 비해 가해자 처벌 및 피해자 구제에 부족함이 나타나게 된다. 다만 이러한 딥페이크(Deepfake) 포르노 문제에 대하여 형사규제가 요구되더라도 그 적용에 있어서는 신중을 기해야한다는 점에서, 딥페이크 포르노 문제에 대하여 살펴보고, 또한 이러한 가해행위를 대법원 판례에 기초하여 성폭력처벌법 제14조의 카메라등이용촬영죄로 규율할 수 있는지 여부를 분석하고 더 나아가입법적 대안에 대해서도 검토한다.","While the rapid development of technology in recent years has brought many benefits to Korean society, it also has been implications for such matters as the privacy and the role of law. Especially In Korea, Violence on women’s bodies and sexuality in cyberspace has been a problem since the 2000s. This violence against women’s bodies and sexuality in cyberspace is not just a violation of the social legal interest using information, but also a direct violation of the individual’s body and character using digital technology, just like rape, a traditional sexual crime. Under the ‘ACT ON SPECIAL CASES CONCERNING THE PUNISHMENT, ETC. OF SEXUAL CRIMES’ Article 14 cannot catch various types of sexual crimes that are actually occurring by excluding the leakage of self-pictured sexual images and taking issue with the extent of physical exposure of images.This study aims to find criminal policy for punishment and regulations after conducting an study on the type of digital-sexual crimes, including the use of AI technology(deepfake). The problem recognition in this study is to explore whether the current methods and content of punishment and regulation are adequately responding to the type of cyber sexual crime that is currently occurring, what problems are there if not addressed, and what improvements are needed to address them. Therefore, it analyzed domestic and international legal systems related to digital-sexual crimes. Also, it was also consider issues raised in the process of actual punishment and regulation."
머신러닝을 이용한 관중 수요 예측에 관한 연구,2019,"['수요예측', '머신러닝', '딥러닝', '랜덤포레스트']","특정한 이벤트나 콘텐츠를 즐기기 위해 모인 사람들을 관중 또는 관객이라고 하고, 모임의 특성에 따라 다양한 성향을 나타낸다. 그러한 차이점은 있지만, 일반적으로 관중 수는 경영적인 측면과 직결되는 요소로써, 관람료부터 다른 시설의 이용료 등 다양한 수입을 통해 콘텐츠 판매를 위한 안정적인 재정 운영을 가능케 한다. 따라서 관중 수에 대한 예측은 마케팅과 예산 전략 수립에 주요한 요소로 활용될 수 있다. 본 연구에서는 관중 수에 대한 예측을 위한 여러 가지 기존 모델을 검토하고, 그 중에서 효율적인 머신러닝 모델을 제안하고자 한다. 또한 딥러닝과 랜덤포레스트 모델을 혼용하여 일별 관중 수 예측과 비정상적 관중 수 예측에 대한 연구를 진행하였다.","People who gathered to enjoy a specific event or content are called audiences or spectators, and show various propensity according to the characteristics of the crowd. Although there is such a difference, in general, the number of attendance is directly related to the business aspect, which enables stable financial operation for the sale of contents through various incomes, such as the admission fee and the use of other facilities. Therefore, prediction of audience can be used as a major factor in marketing and budgeting strategies. In this study, we review several existing models for predicting the number of attendance and propose an efficient machine learning model. In addition, we studied daily attendance prediction and abnormal attendance prediction using combine DNN(Deep Neural Network) and RF(Random Forest) model."
딥런닝 기반의 프레임 유사성을 이용한화재 오탐 검출 개선 연구,2019,"['deep learning', 'faster r-cnn', 'fire detection', 'smoke detection', 'ssim']","화염 및 연기 감지 알고리즘 연구는 다양한 모양, 빠른 확산 및 색상으로 인해 컴퓨터 비전에서 어려운 과제이다. 일반적인센서 기반 화재 감지 시스템의 성능은 환경 요인 (실내 및 화재발생 위치)에 따라 크게 제한된다. 이러한 문제를 해결하기위해 딥러닝 방법을 적용하였으며, 이것은 물체의 형상을 특징으로 추출하므로 비슷한 형상이 프레임내에 존재하면 오탐으로검출 될 수 있다. 본 연구는 화재 오탐 검출 개선을 위해 딥런닝 사용 전과 후에 프레임 유사성을 이용하여 오탐을 줄이는새로운 알고리즘을 제안한다. 실험결과 제안된 방법을 적용하여 화재 검출 성능은 유지를 하면서 오탐 부분이 최소 30% 까지 감소하는 결과를 얻을 수 있었다. 제안된 방법의 오탐 검출 성능이 뛰어나다는 것을 확인하였다.","Fire flame and smoke detection algorithm studies are challenging task in computer vision due to the variety of shapes,rapid spread and colors. The performance of a typical sensor based fire detection system is largely limited byenvironmental factors (indoor and fire locations). To solve this problem, a deep learning method is applied. Because itextracts the feature of the object using several methods, so that if a similar shape exists in the frame, it can be detectedas false postive. This study proposes a new algorithm to reduce false positives by using frame similarity before usingdeep learning to decrease the false detection rate. Experimental results show that the fire detection performance ismaintained and the false positives are reduced by applying the proposed method. It is confirmed that the proposed methodhas excellent false detection performance"
머신러닝을 활용한 사상체질 분류 모델 선정과 서비스 플로우 디자인,2019,"['머신러닝', '딥러닝', '한의학', '사상체질', '데이터베이스', 'MachineLearning', 'DeepLearning', 'Or7iental Medicine', 'Sasang-Type', 'Database']",,"Unlike in modern medicine, medical data have not been standardized yet and infrastructure for accumulating data is poor in oriental medicine. These problems become obstacles in artificial intelligence research and bilateral cooperation in domain of oriental medicine. To solve this problem, we compared the classification accuracy using several machine learning algorithms to select the highest accuracy model. Also we designed an application using the selected classification algorithm model to offer convenience service to doctor and patient. In addition, we designed the database to accumulate medical data, so accumulated data can be used to enhance the accuracy of classification algorithm model."
베이지안 추론과 정규화를 이용한 회귀 머신러닝,2019,"['Bayesian Statistics', 'Machine Learning', 'Deep Learning', 'Patent Keyword Data', 'Technology Analysis', '베이지안 추론 및 정규화', '신경망', '회귀분석', '머신러닝', '심층학습', '딥러닝']","최근 심층학습에 기반 한 신경망 모형이 기존의 머신러닝 알고리즘을 대체하고 있다. 특히 컴퓨터비전, 자연어처리 등이미지와 음성 인식 문제를 위한 분류 작업에서 매우 우수한 성능을 보여주고 있다. 하지만 신경망 모형의 구조에서 은닉층을심층적으로 디자인함으로써 기존의 신경망에 비하여 더 많은 계산시간이 필요하게 되는 어려움이 있다. 분류문제가아닌 회귀문제에 있어서도 같은 문제가 있다. 이와 같은 심층 신경망에 비하여 본 연구에서 제시하는 베이지안 신경망은하나의 은닉층만을 사용하고 베이지안 추론 및 정규화를 이용하여 신경망 모형의 예측력을 유지하면서 동시에 계산시간을단축시키는 결과를 얻기 위하여 노력한다. 즉, 신경망 모형의 가중치를 모수의 사전 및 사후 분포를 이용하여 갱신한다.모의실험 데이터를 이용하여 베이지안 신경망과 심층 신경망의 예측의 정확성과 계산시간을 비교하여 제안 방법의 타당성을보인다","Recently, the neural network models based on deep learning are replacing the existing machine learning algorithm. In particular, they show excellent performance in classification tasks for image and speech recognition problems such as computer vision and natural language processing. However, because of the large size of hidden layer, the deep neural network model has a difficulty that requires more computation time than the conventional neural networks. The same problem exists for regression problems that are not classification problems. Compared with such deep neural networks, the Bayesian neural network proposed in this study uses only one hidden layer and uses Bayesian inference and regularization to maintain the predictive power of the neural network model while reducing the computation time. That is, the weights of the neural network model are updated by using the prior and posterior distributions of parameters. By using the simulation data, we compare the accuracy and computation time of Bayesian neural networks and deep neural networks to show the validity of the proposed method"
Web access prediction based on parallel deep learning,2019,"['Apache Spark', 'Neural network', 'Parallel deep learning', 'Parameter tuning', 'Web access prediction', '아파치 스파크', '신경망', '병렬 딥러닝', '파라미터 튜닝', '웹 접근 예측']","웹에서 정보 접근에 대한 폭발적인 주문으로 웹 사용자의 다음 접근 페이지를 예측하는 필요성이 대두되었다. 웹 접근 예측을 위해 마코브(markov) 모델, 딥 신경망, 벡터 머신, 퍼지 추론 모델등 많은 모델이 제안되었다. 신경망 모델에 기반한 딥러닝 기법에서 대규모 웹 사용 데이터에 대한 학습 시간이 엄청 길어진다. 이 문제를 해결하기 위하여 딥 신경망 모델에서는 학습을 여러 컴퓨터에 동시에, 즉 병렬로 학습시킨다. 본 논문에서는 먼저 스파크 클러스터에서 다층 Perceptron 모델을 학습 시킬 때 중요한 데이터 분할, shuffling, 압축, locality와 관련된 기본 파라미터들이 얼마만큼 영향을 미치는지 살펴보았다. 그 다음 웹 접근 예측을 위해 다층 Perceptron 모델을 학습 시킬 때 성능을 높이기 위하여 이들 스파크 파라미터들을 튜닝 하였다. 실험을 통하여 논문에서 제안한 스파크 파라미터 튜닝을 통한 웹 접근 예측 모델이 파라미터 튜닝을 하지 않았을 경우와 비교하여 웹 접근 예측에 대한 정확성과 성능 향상의 효과를 보였다.","Due to the exponential growth of access information on the web, the need for predicting web users’ next access has increased. Various models such as markov models, deep neural networks, support vector machines, and fuzzy inference models were proposed to handle web access prediction. For deep learning based on neural network models, training time on large-scale web usage data is very huge. To address this problem, deep neural network models are trained on cluster of computers in parallel. In this paper, we investigated impact of several important spark parameters related to data partitions, shuffling, compression, and locality (basic spark parameters) for training Multi-Layer Perceptron model on Spark standalone cluster. Then based on the investigation, we tuned basic spark parameters for training Multi-Layer Perceptron model and used it for tuning Spark when training Multi-Layer Perceptron model for web access prediction. Through experiments, we showed the accuracy of web access prediction based on our proposed web access prediction model. In addition, we also showed performance improvement in training time based on our spark basic parameters tuning for training Multi-Layer Perceptron model over default spark parameters configuration."
Development of Handwriting Recognition Using Deep Learning in Unit3yD,2019,"['Character recognition', 'Deep learning', 'Unity3D', 'Handwriting Recognition', 'Convolutional Neural Network']","필기 인식은 사람이 작성한 문서나 종이에 쓴 글자, 사진에 보이는 글자 등을 인식하는 기술이다. 대표적인 기술로는 OCR과 온라인 필기인식 기술이 있으며 OCR은 정자로 또박또박 쓴 글씨 인식률은 높지만 그렇지 않는 경우에는 인식률이 낮다. 온라인 필기인식 기술은 필기 입력순서와 사람의 필체의 차이에 따라 인식률이 확연하게 달랐다. 본 논문에서는 이러한 단점을 보완하고자 딥러닝을 이용하여 필기체 인식 시스템을 제안하고자 한다. 본 논문에서는 신경망 알고리즘 중 Convolutional Neural Network와 EMNIST 데이터 세트를 사용하여 학습 데이터를 설계하였고 Unity3D 게임엔진을 이용하여 전체적인 시스템을 구성하였다. 또한 본 논문에 서는 CPU와 GPU 성능이 학습 결과에 영향을 미치는지 알아보기 위해 성능을 비교분석을 하였고, loss값과 accuracy 결과에 큰 차이는 없었지만 학습 속도에는 최대 30배 정도 속도 차이가 났다. 마지막으로 실험을 통해 시스템 인식결과를 분석하였고, 문자와 숫자가 유사한 O, q, l과 같은 알파벳이나, 실험자가 글자를 다른 알파벳과 유사하게 보이게 필기하면 인식률이 낮았다. 본 논문에서 제안하는 시스템은 게임엔진을 사용하여 인공지능 시스템을 개발했기 때문에 프로세스 절차가 간략해졌고 호환성도 좋아졌다.","Handwriting recognition is a technology that recognizes people s written documents, characters written on paper, and characters shown in pictures. Typical technologies include OCR and on-line handwriting recognition technology. OCR had a high recognition rate of writing that was clearly written, but if not, it had a low recognition rate. On-Line handwriting recognition technology clearly differed depending on the difference between handwriting input order and a person s handwriting. In this paper, in order to compensate for these shortcomings, we propose a handwriting recognition system using deep learning. In this paper, the learning data were designed using Convolutional Neural Network and EMNIST data set among neural network algorithms and the whole system was constructed using Unity3D game engine. In this paper, we also did a comparative analysis to see if CPU and GPU performance affect learning results, and although there was no big difference in loss value and acuracy value results, there was a maximum speed difference of 30 times at learning speed. Finally, the results of recognition were analyzed through experiments, and alphabets with similar shapes of characters and numbers, such as O, q, and l, had lower recognition rates. And if the experimenter wrote the characters to look similar to other alphabets, the recognition rate was low. The system proposed in this paper has developed an artificial intelligence system using game engine, so the process procedure has been simplified and the compatibility has improved."
Deep Learning based violent protest detection system,2019,"['Collecting evidence', 'drone', 'deep learning', 'detection', 'AWS']",,"In this paper, we propose a real-time drone-based violent protest detection system. Our proposed system uses drones to detect scenes of violent protest in real-time. The important problem is that the victims and violent actions have to be manually searched in videos when the evidence has been collected. Firstly, we focused to solve the limitations of existing collecting evidence devices by using drone to collect evidence live and upload in AWS(Amazon Web Service)[1]. Secondly, we built a Deep Learning based violence detection model from the videos using Yolov3 Feature Pyramid Network for human activity recognition, in order to detect three types of violent action. The built model classifies people with possession of gun, swinging pipe, and violent activity with the accuracy of 92, 91 and 80.5% respectively. This system is expected to significantly save time and human resource of the existing collecting evidence."
Generation of contrast enhanced computed tomography image using deep learning network,2019,"['Contrast enhanced computed tomography', 'deep learning', 'generative adversarial network']",,"In this paper, we propose a application of conditional generative adversarial network (cGAN) for generation of contrast enhanced computed tomography (CT) image. Two types of CT data which were the enhanced and non-enhanced were used and applied by the histogram equalization for adjusting image intensities. In order to validate the generation of contrast enhanced CT data, the structural similarity index measurement (SSIM) was performed. Prepared generated contrast CT data were analyzed the statistical analysis using paired sample t-test. In order to apply the optimized algorithm for the lymph node cancer, they were calculated by short to long axis ratio (S/L) method. In the case of the model trained with CT data and their histogram equalized SSIM were 0.905±0.048 and 0.908±0.047. The tumor S/L of generated contrast enhanced CT data were validated similar to the ground truth when they were compared to scanned contrast enhanced CT data. It is expected that advantages of Generated contrast enhanced CT data based on deep learning are a cost-effective and less radiation exposure as well as further anatomical information with non-enhanced CT data."
Detection of Moving Direction using PIR Sensors and Deep Learning Algorithm,2019,"['Passive infrared', 'movement direction detection', 'deep learning', 'machine learning', 'convolutional neural network']",,"In this paper, we propose a method to recognize the moving direction in the indoor environment by using the sensing system equipped with passive infrared (PIR) sensors and a deep learning algorithm. A PIR sensor generates a signal that can be distinguished according to the direction of movement of the user. A sensing system with four PIR sensors deployed by 45° increments is developed and installed in the ceiling of the room. The PIR sensor signals from 6 users with 10-time experiments for 8 directions were collected. We extracted the raw data sets and performed experiments varying the number of sensors fed into the deep learning algorithm. The proposed sensing system using deep learning algorithm can recognize the users’ moving direction by 99.2 %. In addition, with only one PIR senor, the recognition accuracy reaches 98.4%."
Pest Control System using Deep Learning Image Classification Method,2019,"['Image Processing', 'Convolutional Neural Network', 'Background Subtraction', 'Classification']",,"In this paper, we propose a layer structure of a pest image classifier model using CNN (Convolutional Neural Network) and background removal image processing algorithm for improving classification accuracy in order to build a smart monitoring system for pine wilt pest control. In this study, we have constructed and trained a CNN classifier model by collecting image data of pine wilt pest mediators, and experimented to verify the classification accuracy of the model and the effect of the proposed classification algorithm. Experimental results showed that the proposed method successfully detected and preprocessed the region of the object accurately for all the test images, resulting in showing classification accuracy of about 98.91%. This study shows that the layer structure of the proposed CNN classifier model classified the targeted pest image effectively in various environments. In the field test using the Smart Trap for capturing the pine wilt pest mediators, the proposed classification algorithm is effective in the real environment, showing a classification accuracy of 88.25%, which is improved by about 8.12% according to whether the image cropping preprocessing is performed. Ultimately, we will proceed with procedures to apply the techniques and verify the functionality to field tests on various sites."
소형 네트워크에서 배치 정규화의 스케일링 인자를 활용한 채널 프루닝,2019,"['Convolutional Neural Network', 'Pruning', 'Classification', 'Embedded Systems']",,
딥러닝기반 다중 표적 인식을 활용한 모바일 로봇 경로 계획,2019,"['표적인식', '경로계획', '장애물 회피', '딥러닝', '모바일 로봇', 'Taget Detection', 'Path Planning', 'Avoidance Obstacle', 'Deep-Learning', 'Mobile Robot']","복합적인 고차원의 임무를 수행하기 위하여 미래무인화 전투 체게는 인공지능 기술을 필요로 한다. 특히 합성곱 신경망은 영상뿐만 아니라 자연어 처리까지 광범위한 범위에서 탁월한 성능을 보이고 있어 무인화 전투체계의 표적정보인식, 피아식별, 전장정보인식 등 각종 센서 융합에 매우 적합하다. 본 연구에서는 합성곱 신경망의 영상인식 기술을 활용하여 다수 대상체의 상태정보를 인식함으로써 변화되는 환경에서의 무인로봇 경로 계획 개선 방안을 제시하였고 시뮬레이션을 통하여 추정된 로봇의 위치, 장애물, 목표물 정보로부터 로봇의 경로 계획의 유효성을 검증 하였다.","Unmmanned systems are one of the essential areas of future military weapons systems that must carry out dangerous and cmplex missions. Especially, deep learning should recognize many landmarks through the image and project them onto the map to improve the problem of position estimation, because it shows excellent performance of recognizing and classifying the characteristics of image data among other artificial intelligence techniques. In this study, the path planning of the unmanned reconnaissance aircraft and the unmanned ground vehicle, which are currently being used in the ROK military, is linked with the CNN based multi target recognition algorithm without GPS. Throuth experiments, we verified the effectiveness of the path planning of the mobile robot with respect to the position of the robot, obstacle, and target point estimated by the target detection algorithm."
Faster R-CNN을 이용한 고속도로 통행량 및 속도 추정 구현,2019,"['Deep learning', 'Object Detection', 'Vehicle Speed Estimation', 'Traffic Estimation', 'Traffic Situation Analysis']",,
“인공지능은 인문학이다”: 구성적 정보 철학적 관점에서,2019,"['인공지능', '인문학', '정보 철학', '구성주의', 'artificial intelligence', 'humanities', 'philosophy of information', 'constructivism']","인공지능은 기계가 인간 지능을 가지도록 모색하는 컴퓨터과학의 한 분야이다. 이를 위하여 인간의 지능을 계산적 모델로 이해하기 위한 연구 분야이기도 한다. 그러므로 인공지능은 인간을 이해하기 위한 오랜 학문인 문사철의 인문학과 밀접한 관계가 있다. 더구나 인지과학의 발달로 인하여 인간에 대한 이해는 새로운 국면에 들어섰다고 할 수 있다. 인지과학의 한 분야이기도 한 인공지능은 포괄적으로 인간에 대한 이해를 도모하는 또 다른 측면의 인문학이라고 할 수 있다.  필자는 현재의 인공지능이 아직은 인문학적 인간 이해와는 많은 거리를 가지고 있지만 좀 더 발전된 인공지능을 위해서 인공지능은 인문학에 대한 이해가 필수적이고, 인문학 또한 좀 더 정교한 인간 이해를 위해서는 인공지능에 대한 이해와 인공지능적 상상력이 필요하다고 생각한다. 본 연구는 구성주의에 기반한 정보 철학이 인공지능과 인문학을 포괄적으로 이해하기 위한 방편이 될 수 있다고 논의한다.","Artificial intelligence is a branch of computer science that seeks to make machines have human intelligence. To this end, it is also a field of research to understand human intelligence as a computational model. Therefore, artificial intelligence is closely related to the humanities of Moon Sa-chul(Literature-History-Philosophy), a long-standing study to understand humans. Moreover, with the development of cognitive science, understanding of human beings has entered a new phase. Artificial intelligence, which is also an area of cognitive science, is another aspect of humanities that comprehensively promotes understanding of human beings.  I think that although current artificial intelligence still has a lot of distance from human understanding, for more advanced artificial intelligence, an understanding of humanities is essential, and for more sophisticated human understanding of humanities also requires an understanding of artificial intelligence and an artificial intelligence imagination. This study discusses that information philosophy based on constructivism can be a way to comprehensively understand artificial intelligence and humanities."
영상품질별 학습기반 알고리즘 폐색영역 객체 검출 능력 분석,2019,"['Deep Learning', '3D Modeling', 'Texturing', 'Image Quality', 'Occlusion Area', '딥러닝', '3차원 모델링', '텍스처링', '영상품질', '폐색영역']","정보화 사회로 진입하면서 공간정보의 중요성은 급격하게 부각되고 있다. 특히 스마트시티, 디지털트윈과 같은 Real World Object의 3차원 공간정보 구축 및 모델링은 중요한 핵심기술로 자리매김하고 있다. 구축된 3차원 공간정보는 국토관리, 경관분석, 환경 및 복지 서비스 등 다양한 분야에서 활용된다. 영상기반의 3차원 모델링은 객체 벽면에 대한 텍스처링을 생성하여 객체의 가시성과 현실성을 높이고 있다. 하지만 이러한 텍스처링은 영상 취득 당시의 가로수, 인접 객체, 차량, 현수막 등의 물리적 적치물에 의해 필연적으로 폐색영역이 발생한다. 이러한 폐색영역은 구축된 3차원 모델링의 현실성과 정확성 저하의 주요원인이다. 폐색영역 해결을 위한 다양한 연구가 수행되고 있으며, 딥러닝을 이용한 폐색영역 검출 및 해결방안에 대한 연구가 수행되고 있다. 딥러닝 알고리즘 적용한 폐색영역 검출 및 해결을 위해서는 충분한 학습 데이터가 필요하며, 수집된 학습 데이터 품질은 딥러닝의 성능 및 결과에 직접적인 영향을 미친다. 따라서 본 연구에서는 이러한 학습 데이터의 품질에 따라 딥러닝의 성능 및 결과를 확인하기 위하여 다양한 영상품질을 이용하여 영상의 폐색영역 검출 능력을 분석하였다. 폐색을 유발하는 객체가 포함된 영상을 인위적이고 정량화된 영상품질별로 생성하여 구현된 딥러닝 알고리즘에 적용하였다. 연구결과, 밝기값 조절 영상품질은 밝은 영상일수록 0.56 검출비율로 낮게 나타났고 픽셀크기와 인위적 노이즈 조절 영상품질은 원본영상에서 중간단계의 비율로 조절된 영상부터 결과 검출비율이 급격히 낮아지는 것을 확인할 수 있었다. F-measure 성능평가 방법에서 노이즈 조절한 영상품질 변화가 0.53으로 가장 높게 나타났다. 연구결과로 획득된 영상품질별에 따른 폐색영역 검출 능력은 향후 딥러닝을 실제 적용을 위한 귀중한 기준으로 활용될 것이다. 영상 취득 단계에서 일정 수준의 영상 취득과 노이즈, 밝기값, 픽셀크기 등에 대한 기준을 마련함으로써 딥러닝을 실질적인 적용에 많은 기여가 예상된다.","The importance of spatial information is rapidly rising. In particular, 3D spatial information construction and modeling for Real World Objects, such as smart cities and digital twins, has become an important core technology. The constructed 3D spatial information is used in various fields such as land management, landscape analysis, environment and welfare service. Three-dimensional modeling with image has the hig visibility and reality of objects by generating texturing. However, some texturing might have occlusion area inevitably generated due to physical deposits such as roadside trees, adjacent objects, vehicles, banners, etc. at the time of acquiring image Such occlusion area is a major cause of the deterioration of reality and accuracy of the constructed 3D modeling. Various studies have been conducted to solve the occlusion area. Recently the researches of deep learning algorithm have been conducted for detecting and resolving the occlusion area. For deep learning algorithm, sufficient training data is required, and the collected training data quality directly affects the performance and the result of the deep learning. Therefore, this study analyzed the ability of detecting the occlusion area of ​​the image using various image quality to verify the performance and the result of deep learning according to the quality of the learning data. An image containing an object that causes occlusion is generated for each artificial and quantified image quality and applied to the implemented deep learning algorithm. The study found that the image quality for adjusting brightness was lower at 0.56 detection ratio for brighter images and that the image quality for pixel size and artificial noise control decreased rapidly from images adjusted from the main image to the middle level. In the F-measure performance evaluation method, the change in noise-controlled image resolution was the highest at 0.53 points. The ability to detect occlusion zones by image quality will be used as a valuable criterion for actual application of deep learning in the future. In the acquiring image, it is expected to contribute a lot to the practical application of deep learning by providing a certain level of image acquisition."
A Text Sentiment Classification Method Based on LSTM-CNN,2019,"['Machine Learning', 'CNN', 'LSTM', 'Text Sentiment Classification Methods', 'Deep Learning', '텍스트 정서 분류 방법']","머신 러닝의 심층 개발로 딥 러닝 방법은 특히 CNN(Convolution Neural Network)에서 큰 진전을 이루었다. 전통적인 텍스트 정서 분류 방법과 비교할 때 딥 러닝 기반 CNN은 복잡한 다중 레이블 및 다중 분류 실험의 텍스트 분류 및 처리에서 크게 발전하였다. 그러나 텍스트 정서 분류를 위한 신경망에도 문제가 있다. 이 논문에서는 LSTM (Long-Short Term Memory network) 및 CNN 딥 러닝 방법에 기반 한 융합 모델을 제안하고, 다중 카테고리 뉴스 데이터 세트에 적용하여 좋은 결과를 얻었다. 실험에 따르면 딥 러닝을 기반으로 한 융합 모델이 텍스트 정서 분류의 예측성과 정확성을 크게 개선하였다. 본 논문에서 제안한 방법은 모델을 최적화하고 그 모델의 성능을 개선하는 중요한 방법이 될 것이다.","With the in-depth development of machine learning, the deep learning method has made great progress, especially with the Convolution Neural Network(CNN). Compared with traditional text sentiment classification methods, deep learning based CNNs have made great progress in text classification and processing of complex multi-label and multi-classification experiments. However, there are also problems with the neural network for text sentiment classification. In this paper, we propose a fusion model based on Long-Short Term Memory networks(LSTM) and CNN deep learning methods, and applied to multi-category news datasets, and achieved good results. Experiments show that the fusion model based on deep learning has greatly improved the precision and accuracy of text sentiment classification. This method will become an important way to optimize the model and improve the performance of the model."
심층신경망 알고리즘을 이용한 가상환경에서의 멀미 측정,2019,"['가상현실', '사이버 멀미', '뇌파', '딥러닝', 'Virtual Reality (VR)', 'Cybersickness', 'EEG', 'Deep Learning']","사이버 멀미는 VR 체험 중 발생하는 증상으로, 주로 감각과 인지 시스템 사이의 불일치로 인해 발생하는 것으로 추정된다. 하지만 감각 및 인지 시스템을 객관적으로 측정할 수 있는 방법이 없기 때문에, 사이버 멀미를 측정하는 것은 어렵다. 이를 해결하기 위해 사이버 멀미를 측정하기 위해 다양한 방법론들이 연구되고 있다. 기존의 멀미를 측정하기 위한 방법은 설문 방식을 이용하거나, 머신 러닝을 이용하여 뇌파 데이터를 분석하는 방식으로 진행되어 왔다. 하지만 설문을 이용한 방식은 객관성이 떨어지며, 머신 러닝을 사용하는 방식은 아직 정확한 측정이 불가능하다. 본 논문에서는 뇌파 데이터를 Deep Neural Network (DNN) 딥러닝 알고리즘에 적용하여 객관적인 사이버 멀미 측정 방식을 제안한다. 또한 우리는 더 정확한 사이버 멀미 측정 결과를 위하여 딥러닝 네트워크 구조와 뇌파 데이터 전처리 기법을 제안한다. 우리의 접근 방법은 최대 98.88%의 정확도로 사이버 멀미를 측정한다. 또한 우리는 실험에서 사이버 멀미를 유발하는 영상의 특성을 분석한다. 일반적으로 사이버 멀미는 상하 움직임이 심한 화면, 화면의 지속적이고 빠른 전환, 공중에 떠있는 상황에서 발생한다.","Cybersickness is a symptom of dizziness that occurs while experiencing Virtual Reality (VR) technology and it is presumed to occur mainly by crosstalk between the sensory and cognitive systems. However, since the sensory and cognitive systems cannot be measured objectively, it is difficult to measure cybersickness. Therefore, methodologies for measuring cybersickness have been studied in various ways. Traditional studies have collected answers to questionnaires or analyzed EEG data using machine learning algorithms. However, the system relying on the questionnaires lacks objectivity, and it is difficult to obtain highly accurate measurements with the machine learning algorithms. In this work, we apply Deep Neural Network (DNN) deep learning algorithm for objective cybersickness measurement from EEG data. We also propose a data preprocessing for learning and network structures allowing us to achieve high performance when learning EEG data with the deep learning algorithms. Our approach provides cybersickness measurement with an accuracy up to 98.88%. Besides, we analyze video characteristics where cybersickness occurs by examining the video segments causing cybersickness in the experiments. We discover that cybersickness happens even in unusually persistent changes in the darkness such as the light in a room keeps switching on and off."
DANN : 이산 산술 신경망,2019,"['DANN', '이산 산술 신경망', '딥 러닝', '기계 학습', '부울 공간', 'DANN', 'Discrete Arithmetic Neural Networks', 'Deep Learning', 'Machine Learning', 'Boolean Space']","딥러닝은 기계학습의 일종으로, 입력값과 결과값 사이의 적당한 함수를 역전파 알고리즘을 통해 구한다. 그러나 딥러닝은 훈련값의 패턴에 대해 추론하기보단 훈련값을 외우려는 현상이 짙고, 이는 훈련값에서 벗어난 데이터에 대해선 추론능력이 크게 떨어지는 오버핏(overfit) 현상을 보인다. 이 문제를 해결하기 위해, 본 논문에서는 실수 공간의 입력값과 출력값을 부울 공간으로 한정시킴으로써 문제를 해결하려는 Discrete Arithmetic Neural Networks (DANN)라는 알고리즘을 제시한다. DANN은 입력값과 출력값이 부울 공간으로 한정될 수 있는 경우, 부울 대수만을 이용하여 딥러닝을 설계할 수 있음을 보인다. 다만 부울 대수만으로는 역전파 알고리즘을 구현할 수 없으므로, 실수(float)를 적절히 이용하여 부울 연산을 모방한다. 결과적으로 이것이 부울 공간을 사용했을 때 LSTM 등 기존의 딥러닝 알고리즘을 사용했을 경우보다 성능이 우수함을 보인다.","Deep learning is a kind of machine learning, and a proper function between the input value and the result value is obtained through the back propagation algorithm. However, deep running is a phenomenon that attempts to memorize the training value rather than deducing the pattern of the training value, which shows overfitting phenomenon that the reasoning ability is greatly reduced for the data that deviates from the training value. To solve this problem, we propose an DANN to solve the problem by limiting input and output values ​​of real space to Boolean space. DANN shows that if the input and output values ​​can be limited to boolean spaces, we can design a deep running using only Boolean algebra. However, since Boolean algebra alone can not implement a back propagation algorithm, it imitates a Boolean operation using the float appropriately. As a result, it shows better performance when using Boolean space than using existing deep running algorithms such as LSTM."
CNN을 활용한 IoT 스트림 데이터 패턴 분류 기법,2019,"['IoT', '스트림 데이터', '딥러닝', '패턴 분류', 'IoT', 'stream data', 'deep learning', 'pattern analysis']","사물 인터넷(Internet of Things, IoT) 환경의 발달로 다양한 종류의 센서들로부터 대량의 데이터가 생성되고 있으며, 이를 수집, 관리 및 분석하기 위한 빅데이터 기술이 중요해지고 있다. 최근에는 실시간으로 생성되는 대용량의 IoT 데이터 분석에 딥러닝 기술을 활용하여 특정 데이터 패턴이나 경향성의 분석을 수행하기 위한 연구가 진행되고 있다. 본 논문에서는 헬스케어 등 IoT 기반 서비스에의 활용 가능성이 높은 스트림데이터 중 하나인 ECG(Electrocardiogram, 심전도) 데이터에 대하여, 딥러닝 모델을 설계 및 적용함으로써 효율적인 분석을 가능하도록 하였다. 먼저, ECG 스트림 데이터의 패턴 분류를 위하여 합성곱 신경망(Convolutional Neural Networks, CNN) 기반의 딥러닝 모델을 설계하고, 이를 최적화하기 위한 다양한 파라미터들을 각각 모델의 구조와 학습에 관련한 파라미터들로 분리하여 실험을 설계 및 진행하였다. 또한, 분류 작업의 추가적인 성능 향상을 위하여, ECG 스트림 데이터에 대한 전처리 기법을 고안하여 적용해 보았다. 이러한 다양한 조건을 기반으로 설계된 실험들은, 서로 다른 센서에서 서로 다른 목적으로 수집되어 서로다른 특성을 갖는 두 가지의 ECG 스트림 데이터 세트 에 대하여 각각 수행되었다. 그 결과, 레이어가 깊을수록, 배치 크기가 큰 학습 모델일수록 IoT 스트림 데이터의 패턴 분류에 용이한 모델 구조라는 결론을 얻을수 있었다.","These days due to the development of the Internet of Things environment, big data technology is becoming important for collecting and managing large amounts of data. Recent studies are being conducted to incorporate deep learning technology into Internet of Things(IoT) data analysis in order to classify the specific pattern and trends. In this paper, ECG(Electrocardiogram) data, which could be useful for IoT services, is the input steam data, and a deep learning model structure suitable for data characteristics is found, so that IoT data analysis is efficiently performed. In order to classify the IoT stream data pattern, the experiments were conducted to find the best suitable model structure using the convolutional neural networks. To optimize the CNN, various models and parameter values were used to design various experiments. Also to enhance the classification performance, a preprocessing step is added to the existing convolutional neural networks model. The model structure parameters and the model learning parameters are divided into two major conditions. The experiment environment is set up and applied to two time series data with different characteristics. It is concluded that the deeper the layer and the larger the batch size, the easier model structure for IoT data pattern classification."
인공지능 기반 수요예측 기법의 리뷰,2019,"['빅데이터', '인공지능', '수요예측', '머신러닝', '딥 러닝', 'big data', 'artificial intelligence', 'demand forecasting', 'machine learning', 'deep learning']","최근 다양한 분야에서 ‘빅데이터’가 생성되었다. 많은 기업들은 인공지능(AI)을 기반으로 빅데이터 분석이 가능한 시스템을 구축하여 이익 창출을 시도하고 있다. 인공지능 기술을 접목함으로써 방대한 양의 데이터를 효율적으로 분석하고 효과적으로 활용하는 것은 점점 더 중요해지고 있다. 특히 재무, 조달, 생산 및 마케팅과 같은 다양한 분야에서 국가 및 기업 경영 관리에있어 최소의 오차와 최대의 정확도를 갖춘 수요예측은 절대적으로 중요한 요소이다. 이 때 각 분야의 수요패턴을 고려한 적절한 모델을 적용하는 것이 중요하다. 전통적으로 쓰이는 시계열모델이나 회귀모델로도 비대해진 실제 데이터의 복잡한 비선형적인 패턴을 분석할 수 있다.그러나 다양한 비선형 모델들 중에서 적절한 모델을 선택하는 것은 사전 지식 없이는 어려운 일이다. 최근에는 인공지능 기반의 기법들인 머신러닝이나 딥러닝 기법을 중심으로 이루어진 연구들이 이를 극복할 수 있음을 증명하고 있다. 뿐만 아니라 정형데이터와 이미지나 텍스트의 비정형 데이터 분석을 통한 수요예측도 높은 정확도를 갖춘 결과를 보이고 있다. 따라서 본 연구에서는 수요예측이 비교적 활발하게 일어나는 중요한 분야들을 나누어 설명하였다. 그리고 각 분야별로 갖는 특징적인 성격을 고려한 인공지능 기반의 수요예측 기법에 대해 머신러닝과 딥러닝 기법으로 나누어 소개하였다.","Big data has been generated in various fields. Many companies have now tried to make profits by building a system capable of analyzing big data based on artificial intelligence (AI) techniques. Integrating AI technology has made analyzing and utilizing vast amounts of data increasingly valuable. In particular, demand forecasting with maximum accuracy is critical to government and business management in various fields such as finance, procurement, production and marketing. In this case, it is important to apply an appropriate model that considers the demand pattern for each field. It is possible to analyze complex patterns of real data that can also be enlarged by a traditional time series model or regression model.However, choosing the right model among the various models is difficult without prior knowledge. Many studies based on AI techniques such as machine learning and deep learning have been proven to overcome these problems. In addition, demand forecasting through the analysis of stereotyped data and unstructured data of images or texts has also shown high accuracy. This paper introduces important areas where demand forecasts are relatively active as well as introduces machine learning and deep learning techniques that consider the characteristics of each field."
지능형 관광 서비스를 위한 관광 사진 분류체계 개발,2019,"['플리커', 'SNS', '관광목적 사진 분류체계', '딥러닝', '합성곱신경망', '한국 관광', 'Flickr', 'Social Network Service', 'Photo Classification for Tourist purpose', 'Deep Learning', 'Convolutional Neural Network', 'Korea Tour']","최근 딥러닝 기술 가운데 이미지데이타 분석에 뛰어난 성능을 보이는 합성곱신경망 기술의 발전은 이미지 분석 영역에서다양한 가능성을 제시하고 있다. 관광객이 게시한 사진을 딥러닝 기술을 이용하여 분류하기 위해서는 관광사진에 대한 분류와목적에 맞는 딥러닝 모델의 훈련작업이 필수적으로 선행되어야 한다. 본 연구에서는 관광객이 플리커에 게시한 사진을 효율적으로분류하기 위해 관광목적으로 사진이 어떻게 분류되어야 하는지 관광목적 사진분류 체계를 개발하고자 하였다. 관광목적 사진분류 카테고리 개발을 위해 문헌분석, 웹사이트 분석, 관광객이 게시한 약 38,000장 사진의 검토과정을 거쳐 사진 분류 카테고리를개발하였으며, 약 8400장의 사진을 개발된 카테고리에 맞춰 분류해 봄으로써 개발된 카테고리의 검증과정을 거쳤다. 이 과정을거쳐 최종으로 제안된 카테고리는 13개 대분류, 64개 중분류, 164개의 세분류 체계를 갖으며, 본 연구 결과는 향후 관광목적사진을 딥러닝 모델을 이용하여 분류하고자 할 때 기초자료로 활용될 것으로 기대된다.","In recent years technology of Convolutional Neural Network (CNN) among the technologies of deep learning has evolved dramatically and has shown an outstanding performance in the analysis of image data. First of all, the training of deep learning model is prerequisite to classify the photos posted by the tourists on Web by applying CNN technology. In this study we aim to develop the photo classification system in view of travel purpose in order to classify the photos posted by tourists on Flickr. We developed the category for photo classification by reviewing around 38,000 photos posted by tourists as well as by analysing literatures and web sites, and then verified the category by classifying 8,400 photos one by one manually according to the category developed. The category we developed has 3 hierarchical levels such as 13 major classification, 64 medium classification and 164 minor classification. We expect that our study can applied in base material when one tries to classify the photos for travel purpose by using the CNN deep learning model."
Inception V3를 이용한 뇌 실질 MRI 영상 분류의 정확도 평가,2019,"['Deep-learning', 'Inception V3', 'Keras', 'Brain MR image', '딥러닝', '인셉션 V3', '케라스', '파이썬', '뇌 실질 MRI 의료영상']","의료영상으로 생성된 데이터의 양은 전문적인 시각적 분석 한계를 점점 초과하여, 자동화된 의료영상 분석의 필요성이 증가되고 있는 실정이다. 이러한 이유 등으로 인하여 본 논문에서는 정상소견과 종양소견을 보이는 각각의 뇌 실질 MRI 의료영상을 이용하여 Inception V3 딥러닝 모델을 이용한 종양 유무에 따른 분류 및 정확도를 평가하였다. 연구 결과, 딥러닝 모델의 정확도 평가는 학습 데이터 세트의 경우 90%, 검증 데이터 세트의 경우 86%의 정확도를 나타내었다. 손실률 평가에서는 학습 데이터 세트의 경우 0.56, 검증 데이터 세트의 경우 1.28의 손실률을 나타내었다. 향 후 연구에서는 딥러닝 모델의 성능 향상 및 평가의 신뢰성 확보를 위하여 공개된 의료영상의 데이터를 충분히 확보하고, 라벨링 분류 작업을 통한 라벨링의 정확도를 개선하여 모델링을 구현해 볼 필요가 있다고 사료된다.","The amount of data generated from medical images is increasingly exceeding the limits of professional visual analysis, and the need for automated medical image analysis is increasing. For this reason, this study evaluated the classification and accuracy according to the presence or absence of tumor using Inception V3 deep learning model, using MRI medical images showing normal and tumor findings. As a result, the accuracy of the deep learning model was 90% for the training data set and 86% for the validation data set. The loss rate was 0.56 for the training data set and 1.28 for the validation data set. In future studies, it is necessary to secure the data of publicly available medical images to improve the performance of the deep learning model and to ensure the reliability of the evaluation, and to implement modeling by improving the accuracy of labeling through labeling classification."
CNN-LSTM 조합모델을 이용한 영화리뷰 감성분석,2019,"['CNN', 'LSTM', 'Deep Learning', 'Integrated Model', 'Movie Review', 'Sentiment Analysis', 'CNN', 'LSTM', '딥러닝', '조합모델', '영화리뷰', '감성분석']","인터넷 기술과 소셜 미디어의 빠른 성장으로 인하여, 구조화되지 않은 문서 표현도 다양한 응용 프로그램에사용할 수 있게 마이닝 기술이 발전되었다. 그 중 감성분석은 제품이나 서비스에 내재된 사용자의 감성을 탐지할 수 있는 분석방법이기 때문에 지난 몇 년 동안 많은 관심을 받아왔다. 감성분석에서는 주로 텍스트 데이터를이용하여 사람들의 감성을 사전 정의된 긍정 및 부정의 범주를 할당하여 분석하며, 이때 사전 정의된 레이블을이용하기 때문에 다양한 방향으로 연구가 진행되고 있다. 초기의 감성분석 연구에서는 쇼핑몰 상품의 리뷰 중심으로 진행되었지만, 최근에는 블로그, 뉴스기사, 날씨 예보, 영화 리뷰, SNS, 주식시장의 동향 등 다양한 분야에 적용되고 있다. 많은 선행연구들이 진행되어 왔으나 대부분 전통적인 단일 기계학습기법에 의존한 감성분류를 시도하였기에 분류 정확도 면에서 한계점이 있었다. 본 연구에서는 전통적인 기계학습기법 대신 대용량 데이터의 처리에 우수한 성능을 보이는 딥러닝 기법과 딥러닝 중 CNN과 LSTM의 조합모델을 이용하여 감성분석의 분류 정확도를 개선하고자 한다. 본 연구에서는 대표적인 영화 리뷰 데이터셋인 IMDB의 리뷰 데이터 셋을이용하여, 감성분석의 극성분석을 긍정 및 부정으로 범주를 분류하고, 딥러닝과 제안하는 조합모델을 활용하여극성분석의 예측 정확도를 개선하는 것을 목적으로 한다. 이 과정에서 여러 매개 변수가 존재하기 때문에 그수치와 정밀도의 관계에 대해 고찰하여 최적의 조합을 찾아 정확도 등 감성분석의 성능 개선을 시도한다. 연구결과, 딥러닝 기반의 분류 모형이 좋은 분류성과를 보였으며, 특히 본 연구에서 제안하는 CNN-LSTM 조합모델의 성과가 가장 우수한 것으로 나타났다.","Rapid growth of internet technology and social media is progressing. Data mining technology has evolved to enable unstructured document representations in a variety of applications. Sentiment analysis is an important technology that can distinguish poor or high-quality content through text data of products, and it has proliferated during text mining. Sentiment analysis mainly analyzes people's opinions in text data by assigning predefined data categories as positive and negative. This has been studied in various directions in terms of accuracy from simple rule-based to dictionary-based approaches using predefined labels. In fact, sentiment analysis is one of the most active researches in natural language processing and is widely studied in text mining. When real online reviews aren't available for others, it's not only easy to openly collect information, but it also affects your business. In marketing, real-world information from customers is gathered on websites, not surveys. Depending on whether the website's posts are positive or negative, the customer response is reflected in the sales and tries to identify the information. However, many reviews on a website are not always good, and difficult to identify. The earlier studies in this research area used the reviews data of the Amazon.com shopping mal, but the research data used in the recent studies uses the data for stock market trends, blogs, news articles, weather forecasts, IMDB, and facebook etc. However, the lack of accuracy is recognized because sentiment calculations are changed according to the subject, paragraph, sentiment lexicon direction, and sentence strength. This study aims to classify the polarity analysis of sentiment analysis into positive and negative categories and increase the prediction accuracy of the polarity analysis using the pretrained IMDB review data set. First, the text classification algorithm related to sentiment analysis adopts the popular machine learning algorithms such as NB (naive bayes), SVM (support vector machines), XGboost, RF (random forests), and Gradient Boost as comparative models.Second, deep learning has demonstrated discriminative features that can extract complex features of data. Representative algorithms are CNN (convolution neural networks), RNN (recurrent neural networks), LSTM (long-short term memory). CNN can be used similarly to BoW when processing a sentence in vector format, but does not consider sequential data attributes. RNN can handle well in order because it takes into account the time information of the data, but there is a long-term dependency on memory. To solve the problem of long-term dependence, LSTM is used. For the comparison, CNN and LSTM were chosen as simple deep learning models. In addition to classical machine learning algorithms, CNN, LSTM, and the integrated models were analyzed. Although there are many parameters for the algorithms, we examined the relationship between numerical value and precision to find the optimal combination. And, we tried to figure out how the models work well for sentiment analysis and how these models work. This study proposes integrated CNN and LSTM algorithms to extract the positive and negative features of text analysis. The reasons for mixing these two algorithms are as follows. CNN can extract features for the classification automatically by applying convolution layer and massively parallel processing. LSTM is not capable of highly parallel processing. Like faucets, the LSTM has input, output, and forget gates that can be moved and controlled at a desired time. These gates have the advantage of placing memory blocks on hidden nodes. The memory block of the LSTM may not store all the data, but it can solve the CNN's long-term dependency problem. Furthermore, when LSTM is used in CNN's pooling layer, it has an end-to-end structure, so that spatial and temporal features can be designed simultaneously. In combination with CNN-LSTM, 90.33% accuracy was measured. Thi..."
기술용어 분산표현을 활용한 특허문헌 분류에 관한 연구,2019,"['Patent Literature Classification', 'Distributed Representation', 'Word Embedding Vector', 'Deep Learning', '특허문헌 분류', '분산표현', '워드 임베딩 벡터', '딥러닝']","본 연구의 목적은 특허 문헌 분류에 가장 적합한 방법론을 발견하기 위하여 다양한 자질 추출 방법과 기계학습 및 딥러닝 모델을 살펴보고 실험을 통해 최적의 성능을 제공하는 방법론을 분석하는데 있다. 자질 추출 방법으로는 전통적인 BoW 방법과 분산표현 방식인 워드 임베딩 벡터를 비교 실험하고, 문헌 집합 구축 방식으로는 형태소 분석과 멀티그램을 이용하는 방식을 비교 검토하였다. 또한 전통적인 기계학습 모델과 딥러닝 모델을 이용하여 분류 성능을 검증하였다. 실험 결과, 분산표현 방법과 형태소 분석을 이용한 자질추출 방법을 기반으로 딥러닝 모델을 적용하였을 경우에 분류 성능이 가장 우수한 것으로 판명되었으며 섹션, 클래스, 서브클래스 분류 실험에서 전통적인 기계학습 방법에 비해 각각 5.71%, 18.84%, 21.53% 우수한 분류 성능을 보여주었다.","In this paper, we propose optimal methodologies for classifying patent literature by examining various feature extraction methods, machine learning and deep learning models, and provide optimal performance through experiments. We compared the traditional BoW method and a distributed representation method (word embedding vector) as a feature extraction, and compared the morphological analysis and multi gram as the method of constructing the document collection. In addition, classification performance was verified using traditional machine learning model and deep learning model. Experimental results show that the best performance is achieved when we apply the deep learning model with distributed representation and morphological analysis based feature extraction. In Section, Class and Subclass classification experiments, We improved the performance by 5.71%, 18.84% and 21.53%, respectively, compared with traditional classification methods."
스마트 그리드 시스템을 위한 전력선 통신 시스템의 종단 간 방식의 간섭 제거 기법,2019,"['Power Line Communication', 'Smart Grid System', 'Interference Cancellation', 'End-to-end', 'Impulsive Noise', 'Deep Learning', 'Channel Estimation']","본 논문은 스마트 그리드를 위한 전력선 통신 시스템에서 데이터 신뢰성을 향상시키는 딥러닝 기반의 종단 간 방식의 간섭 제거 알고리즘에 대해 연구하였다. 본 논문에서 제안한 기법은 딥러닝 기술을 적용하여 채널에서 발생하는 잡음을예측하여 제거하는 기술로서 수신단에서 딥러닝에 의해 학습된 잡음들을 활용하여 효과적으로 잡음을 제거함으로써 신호의품질을 향상시킬 수 있다. 딥러닝 기술의 잡음 예측 정확도를 향상시키기 위해 기존의 잡음 형태를 데이터베이스화하여 활용하였다. 채널 모델로서 Middleton Class A 간섭 모델을 사용하였고, 비트 오류율을 평가하여 성능을 검증하였다. 모의실험을통해 간섭 제거 기법이 적용된 시스템 모델과 이론적인 모델의 비트오류율을 비교하여 제안하는 시스템이 잡음을 효과적으로 제거하여 신호의 품질 성능을 향상시킬 수 있음을 확인하였다. 제안한 시스템 모델은 전력선 통신뿐만 아니라 일반적인통신 시스템에서도 신호의 품질을 향상시킬 수 있도록 다양하게 적용이 가능하다.","In this paper, we propose the interference cancellation scheme of end-to-end method algorithm for power line communication (PLC) systems in smart grid. The proposed scheme estimates the channel noise information of receiver by applying a deep learning model at the receiver. Then, the estimated channel noise is updated in database. In the modulator, the channel noise which reduces the power line communication performance is effectively removed through interference cancellation technique. As an impulsive noise model, Middleton Class A interference model was employed.The performance is evaluated in terms of bit error rate (BER). From the simulation results, it is confirmed that the proposed scheme has better BER performance compared to the theoretical model based on additive white Gaussian noise.As a result, the proposed interference cancellation with deep learning improves the signal quality of PLC systems by effectively removing the channel noise. The results of the paper can be applied to PLC for smart grid and general communication systems."
디노이징 필터와 LSTM을 활용한 KOSPI200 선물지수 예측,2019,"['디노이징 필터', '슬라이딩 윈도우', 'KOSPI200 선물지수', 'LSTM', 'Denoising filter', 'KOSPI200 future index', 'sliding window']","딥러닝 모형을 통해 금융시장을 예측하는 연구는 활발하지만 디노이징 필터를 적용하여 금융 데이터의 노이즈를 제거함으로써 예측 모형의 성능을 높이는 연구는 거의 이루어지지 않고 있다. 따라서, 본 연구의 목적은 디노이징 필터를 사용하여 데이터의 노이즈를 제거한 후 시계열 예측에 유용한 딥러닝 모형인 LSTM의 예측 성능을 높이는 것이다. KOSPI200 선물지수의 일봉과 30분봉 데이터를 이용해 실증분석을 하였다. 디노이징 필터를 적용한 예측 모형의 성능이 기존 LSTM보다 전체 기간 실험과 슬라이딩 윈도우 실험을 통해 우수함을 입증하였다. 또한, 제안한 디노이징 필터 중 사비츠키-골레이 필터가 이동평균 필터보다 예측 모형 성능 향상에 유용함을 확인하였다. 향후, 디노이징 필터가 다양한 딥러닝 모형의 예측 성능 향상에 사용될 수 있음을 기대한다.","There has been many studies which predict the financial market using the deep learning model. However, there has been few studies which apply the denoising filter that improves the performance of predictions removing the noise of financial data. Therefore, the purpose of this study is to apply denoising filter to remove noise from data and then to improve the prediction performance of long short term memory, a deep learning model which is useful for time series prediction. We conducted an empirical analysis using daily and 30 min KOSPI200 futures index data. It is proven that the performance of prediction model using denoising filter is superior to that of the previous long short term memory for the whole period and the sliding window experiment. Also, we confirmed that savitzky-golay filter is more useful for improving the prediction model performance than moving average filter. In the future, denosing filter may be used to improve the prediction performance of various deep learning models."
Atrous Convolution과 Grad-CAM을 통한 손 끝 탐지,2019,"['Deep Learning', 'Atrous Convolution', 'Grad-CAM', 'Object Detection', '딥러닝', 'Atrous Convolution', 'Grad-CAM', '객체 탐지']","딥러닝 기술의 발전으로 가상 현실이나 증강 현실 응용에서 사용하기 적절한 사용자 친화적 인터페이스에 관한 연구가 활발히 이뤄지고 있다. 본 논문은 사용자의 손을 이용한 인터페이스를 지원하기 위하여 손 끝 좌표를 추적하여 가상의 객체를 선택하거나, 공중에 글씨나 그림을 작성하는 행위가 가능하도록 딥러닝 기반 손 끝 객체 탐지 방법을 제안한다. 입력 영상에서 Grad-CAM으로 해당 손 끝 객체의 대략적인 부분을 잘라낸 후, 잘라낸 영상에 대하여 Atrous Convolution을 이용한 합성곱 신경망을 수행하여 손 끝의 위치를 찾는다. 본 방법은 객체의 주석 전처리 과정을 별도로 요구하지 않으면서 기존 객체 탐지 알고리즘 보다 간단하고 구현하기에 쉽다. 본 방법을 검증하기 위하여 Air-Writing 응용을 구현한 결과 평균 81%의 인식률과 76 ms 속도로 허공에서 지연 시간 없이 부드럽게 글씨 작성이 가능하여 실시간으로 활용 가능함을 알 수 있었다.","With the development of deep learning technology, research is being actively carried out on user-friendly interfaces that are suitable for use in virtual reality or augmented reality applications. To support the interface using the user's hands, this paper proposes a deep learning-based fingertip detection method to enable the tracking of fingertip  coordinates to select virtual objects, or to write or draw in the air. After cutting the approximate part of the corresponding fingertip object from the input image with the Grad-CAM, and perform the convolution neural network with Atrous Convolution for the cut image to detect fingertip location. This method is simpler and easier to implement than existing object detection algorithms without requiring a pre-processing for annotating objects. To verify this method we implemented an air writing application and showed that the recognition rate of 81% and the speed of 76 ms were able to write smoothly without delay in the air, making it possible to utilize the application in real time."
영상에서 패치기반 CNN 모형을 이용한 잡음제거,2019,"['딥러닝', '잡음영상', '잡음제거', 'convolutional neural network', 'Convolutional neural network (CNN)', 'deep learning', 'noise reduction', 'noisy image']","영상에서 잡음제거는 패턴인식, 영상압축, 에지검출, 영상분할과 같은 영상처리 분야의 전처리과정으로 도전할 만한 가치가 있다. 본 논문에서는 딥러닝의 convolutional neural network (CNN) 모형을 이용하여 잡음제거 하고자 한다. CNN 모형은 영상인식, 물체인식 얼굴인식과 같은 컴퓨터 비전 문제에서 좋은 성능을 보이고 있으나 잡음제거에 대해서는 그 중요성에 비추어 아직까지 연구가 덜 이루어졌다. 지금까지 영상에서 잡음제거는 특정한 분포 특성을 갖고 있다는 가정 하에서 설계된 고유한 필터를 사용하였다. 이 경우 가정을 만족하지 않는 필더를 사용하는 경우 성능이 현저히 떨어지는 경향이 있다. 본 논문에서는 잡음에 대한 사전정보 없이 사용가능한 방법으로 영상의 작은 블록인 패치 (patch) 상에서 CNN을 적용하고 중첩된 패치(overlapped patches)에서 해당 픽셀들의 가중평균을 구하여 잡음제거 영상을 얻는다. CNN에서 매개변수 최적화는 잡음데이터에 적응력이 좋은 Adam 알고리즘을 사용한다. 영상실험은 가우시안 잡음영상과 임펄스 잡음영상 모두를 고려하였고 실험결과, 패치기반 CNN 모형은 다른 방법보다 좋은 화질의 영상을 도출하였고 또한 MAE (mean absolute error)와 PSNR (peak signal-to-noise ratio) 면에서도 좋은 성능을 지님을 알 수 있었다.","Noise reduction problem in images still prevails as a challenge in the field of image processing such as pattern recognition, image compression, edge detection and image segmentation. Addressing this issue, this paper presents a novel deep learning approach based on a Convolutional Neural Network (CNN) . CNN has shown excellent performance in computer vision problems such as image recognition, object recognition, and face recognition, but little has been discussed in light of the importance of noise reduction in images. Until now, noise reduction in the images has been used with filters designed under the assumption that it has specific distribution characteristics. In this case, the use of filters that do not satisfy the assumption leads to significant performance degradation. In this paper, CNN is applied on patches of images in a way that is available without prior information about noise. The restored image is obtained by the weighted average of the corresponding pixels in overlapping patches. In CNN, parameter optimization is done by the Adam algorithm that is adaptable to noise data. We considered both Gaussian noise and impulse noise to test the performance of our CNN model. Experimental results on several images show that the patch-based CNN model yields significantly superior image quality and better MAE (mean absolute error) and PSNR (peak signal-to-noise ratio)."
이벤트 기반 신경텐서망을 이용한 뉴스 데이터의 자질 구성 방법,2019,"['딥러닝', '비정형 데이터', '뉴스 데이터', '자질 구성', '이벤트 임베딩', '신경텐서망', 'deep learning', 'unstructured data', 'news data', 'feature composition', 'event embedding', 'neural tensor network']","뉴스 데이터는 정보 분석 및 정보 추출, 추론 등의 자연어처리 분야에서 원시 데이터로 많이 사용되고 있다. 최근 딥러닝을 이용한 분산 표현을 통해 자동으로 자질을 추출할 뿐만 아니라 텍스트의 문맥 정보를 이용하여 단어 간의 관계, 의미 정보를 표현하는 모델이 제안되었다. 본 논문은 뉴스 데이터로부터 구조화된 데이터를 추출하고 단어 간의 관계와 의미적인 정보를 모델에 반영하여 뉴스 데이터의 자질을 구성하는 방법론을 제안한다. 비정형 뉴스 데이터에서 의존 구문 분석을 통해 이벤트들을 자동으로 추출한다. 추출한 이벤트들을 신경텐서망 기술을 적용하여 뉴스 데이터에 대한 자질을 구성한다. 또한, 구성된 자질의 품질을 평가하기 위해 군집화를 수행하였다. 결과를 보았을 때, 이벤트 임베딩 방식이 단어 벡터의 합을 사용하는 것보다 군집화를 더 잘 수행 하였지만, 문서 전체의 카테고리를 대표하는 자질로 사용되기에는 한계점이 있었다.","News data is often used as raw data in the field of natural language processing such as information analysis, information extraction, and reasoning. In recent years, a model has been proposed that not only automatically extracts features through distributed representation using deep learning, but also expresses the relationship between words and semantic information using context information of the text. This paper proposes a method for extracting structured data from news data and constructing features by applying the relationship between words and semantic information in the model. We extracted the events from unstructured news data through dependency parsing. The extracted events are applied to the Neural Tensor Network to construct the document feature of the news data. Also, we evaluated the composed document features by document clustering. Consequently, although the event embedding method performed better clustering than using the sum of word vectors, there was a limit to be used as a feature of representing the category of the entire document."
적은 양의 데이터에 적용 가능한계층별 데이터 증강 알고리즘,2019,"['딥러닝', '데이터 증강', '고유값 분해', 'Deep learning', 'data augmentation', 'Eigen decomposition']","데이터 증강(Data Augmentation)은 적은 양의 데이터를 바탕으로 다양한 알고리즘을 통해 데이터의 양을 늘리는 기술이다. 현실 문제를 해결하기 위해 기계학습 및 딥러닝 기법을 사용하는 경우, 데이터 셋이 부족한 경우가 많다. 데이터의 부족은 모델 학습 시, 데이터 셋의 특징을 잘 반영하지 못하는 것 이외에도 과소적합 및 과적합에 빠질 위험이 크다. 따라서 본 논문에서는 오토인코더와 고유값 분해를 기반으로 하는 데이터 증강 기법을 통해 데이터를 증강 시키고 이를 심층 신경망의 각 층 마다 적용하여, 심층 신경망을 효과적으로 사전 학습하는 방법을 제시한다. 이후, WOBC 데이터와 WDBC 데이터에 대해 실험을 통하여 논문에서 제안하는 방법이 분류 정확도를 향상시키는지 측정하고 기존 연구들과 비교함으로써 제안한 방법이 실질적으로 의미가 있는 데이터를 생성하고 모델의 학습에 효과적임을 보인다.","Data augmentation is a method that increases the amount of data through various algorithms based on a small amount of sample data. When machine learning and deep learning techniques are used to solve real-world problems, there is often a lack of data sets. The lack of data is at greater risk of underfitting and overfitting, in addition to the poor reflection of the characteristics of the set of data when learning a model. Thus, in this paper, through the layer-wise data augmenting method at each layer of deep neural network, the proposed method produces augmented data that is substantially meaningful and shows that the method presented by the paper through experimentation is effective in the learning of the model by measuring whether the method presented by the paper improves classification accuracy."
Bi-LSTM 기반 감성분석을 위한 대용량 학습데이터 자동 생성 방안,2019,"['감성분석', '딥러닝', '학습데이터', '감성사전', '의존 구문 분석', '형태소 분석', 'sentiment analysis', 'deep learning', 'train set', 'sentiment lexicon', 'dependency parsing', 'morphological analysis']","딥러닝을 이용한 감성분석에서는 감성이 레이블 된 많은 양의 학습데이터가 필요하다. 그러나 사람이 직접 감성을 레이블 하는 것은 시간과 비용에 제약이 있고 많은 데이터에서 감성분석에 적합한 충분한 양의 데이터를 수집하는 것은 쉽지 않다. 본 논문에서는 이러한 문제점을 해결하기 위해 기존의 감성사전을 활용하여 감성점수를 매긴 후 감성 변환 요소가 존재하면 의존 구문 분석 및 형태소 분석을 수행해 감성점수를 재설정하여 감성이 레이블 된 대용량 학습데이터를 자동 생성하는 방안을 제안한다. 감성변환 요소로는 감성 반전, 감성 활성화, 감성 비활성화가 있으며 감성점수가 높은 Top-k의 데이터를 추출하였다. 실험 결과 수작업에 비해 짧은 시간에 대용량의 학습데이터를 생성하였으며 학습데이터의 양이 증가함에 따라 딥러닝의 성능이 향상됨을 확인하였다. 그리고 감성사전만을 사용한 모델의 정확도는 80.17%, 자연어처리 기술을 추가한 제안 모델의 정확도는 89.17%로 9%의 정확도 향상을 보였다.","Sentiment analysis using deep learning requires a large-scale train set labeled sentiment.However, direct labeling of sentiment by humans is time and cost-constrained, and it is not easy to collect the required data for sentiment analysis from many data. In the present work, to solve the existing problems, the existing sentiment lexicon was used to assign sentiment score, and when there was sentiment transformation element, the sentiment score was reset through dependency parsing and morphological analysis for automatic generation of large-scale train set labeled with the sentiment. The Top-k data with high sentiment score was extracted. Sentiment transformation elements include sentiment reversal, sentiment activation, and sentiment deactivation. Our experimental results reveal the generation of a large-scale train set in a shorter time than manual labeling and improvement in the performance of deep learning with an increase in the amount of train set. The accuracy of the model using only sentiment lexicon was 80.17% and the accuracy of the proposed model, which includes natural language processing technology was 89.17%. Overall, a 9% improvement was observed."
이미지를 사용한 가상의상착용 알고리즘들의 성능 분석,2019,"['가상착용', '딥러닝', '이미지 기반', '2D 변형', '성능 평가', 'Virtual-Try-On', 'Deep-learning', 'Image-based', '2D deformation', 'Quality evaluation']","가상착용기술(VTON: Virtual try-on)은 의상의 온라인 유통을 활성화를 위하여 중요한 기술이 다. 그러나 3차원 그래픽스기반 방식은 의상과 인체의 3차원 정보의 확보가 필요하여 범용화에 어려움이 있고, 이러한 제약을 해소하기 위해 개발되는 이미지 기반 방식들의 연구들은 그 기술적 한계가 불명확하 다. 구체적으로 VITON (Virtual image try-on) 과 CP-VTON (Content preserving VTON)등은 가능성 위 주의 매우 단편적인 결과만을 제시하고 있다. 본 논문은 이미지기반 기술의 상용화의 한계를 파악하기 위 해, 세 가지 대표적 방식(SCMM 기반의 비-딥러닝 방식, 딥러닝기반 VITON 과 CP-VTON에 대하여 인물 의 자세 및 체형, 의상의 가려짐 정도, 의상의 특성 등에 따라 분석을 하였다. 객관적인 평가를 위하여 변 형단계와 합성단계의 성능을 각각 IoU와 SSIM로 평가하였고, 상대적인 비교 분석을 하였다. 그 결과, CP-VTON이 가장 좋은 성능을 보이지만, 자세와 의상의 복잡도에 따라 성능의 한계가 크게 차이가 남을 보였다. 그 주 원인은 2차 기하변형의 한계와 GAN을 통한 합성 기술의 한계로 파악되었다.",
대비 결합 CNN을 이용한 인공위성 사진 내 선박 탐지 정확도 향상 연구,2019,"['인공위성 영상', '딥러닝', 'CNN', '영상처리', '이미지 대비 융합', '최적화', 'satellite image', 'deep learning', 'CNN', 'image processing', 'image contrast fusion', 'optimization']","인공위성은 지상관측이나 통신, 해양, 방송 등의 임무를 가지며 인공위성 사진을 이용한 선박 탐지는 해상 보안 및 교통 통제 등 쓰임새가 다양하다. 인공위성 사진의 특성은 지구 전역을 촬영하기 때문에 저장되는 데이터양이 많고 각 사진은 초고해상도로 크기가 매우 커 컴퓨터를 이용한 자동 선박 탐지가 필요하다. 기존 연구에서는 여러 딥러닝 모델을 이용하여 선박 탐지 연구를 진행하였지만, 인공위성 사진 특성으로 인한 처리속도가 문제되어 상대적으로 빠른 CNN 모델을 이용하여 연구가 진행되고 있다. 그러나 선박이 있는 선착장과 등대, 파도 등 여러 가지 요인으로 인해서 대부분 정확도와 성능을 높이는데 어려움을 가지고 있다. 따라서 이 논문에서는 이미지 명암 대비 향상을 기존 CNN(Convolution Neural Network)에 접목해 정확도와 성능을 높인 모델을 제안한다. 또한, 학습 단계에서 선박 분류에 필요한 데이터의 양을 늘리기 위해 overlap과 rotation 기능을 이용하고 실제 인공위성 사진에서 탐지 속도를 줄이기 위해 탐지 최적화(window sliding)를 고려하여 자동화 탐지 기술을 구현한다. 식별된 선박 데이터는 다시 학습데이터로 사용하여 정확도를 높이고 실제 산업에서 사용할 수 있도록 구현한다.","The satellite has various missions such as ground/marine observation, communication, broadcasting, etc. Satellite photographs provide information for the maintenance of marine security and traffic control for ship detection. Since satellite photos are taken all over the earth, the memory storage is not sufficient to hold such data with each data being of a high resolution and requiring automatic ship detection using the computer. The existing literature on ship detection employed several deep learning models. However, the problem of processing speed due to the characteristics of satellite photographs leads to the necessity of using a CNN(Convolution Neural Network) model that has a comparably high processing speed. On the contrary, it is difficult to improve the accuracy and performance mostly due to factors such as marina, lighthouses and waves. Therefore, in this paper, we propose a model that improves the accuracy and performance by combining image contrast enhancement with the existing CNN. In addition, we have employed the overlap and rotation functions to increase the amount of data required for ship classification in the learning stage and implement automation detection technology considering window sliding to reduce detection speed in real satellite photographs. Also, the identified ship data has been used as learning data to improve accuracy for the model that can be used in the real industry."
트랜스포머를 이용한 향상된 댓글 생성에 관한 연구,2019,"['Deep Learning(딥 러닝)', 'Natural Language Processing(자연어 처리)', 'Self-Attention(셀프-어텐션)', 'Transformer(트랜스포머)']","온라인 커뮤니티 안에서 다른 사용자들의 글에 반응할 수 있는 딥러닝 연구를 2017년부터 진행해 왔으나, 한국어의 조사와 같은 특성으로 인한 단어처리의 어려움과 RNN 모델의 특성으로 인한 GPU 사용률 저조 문제로 인해 적은 양의 데이터로 학습을 제한해야 했다. 하지만 최근 자연어 처리 분야의 급격한 발전으로 이전보다 뛰어난 모델들이 등장함에 따라 본 연구에서는 이러한 발전된 모델을 적용해 더 나은 학습 결과를 생성해 내는 것을 목표로 한다. 이를 위해 셀프-어텐션 개념이 적용된 트랜스포머모델을 도입했고 여기에 한국어 형태소 분석기 MeCab을 적용해 단어처리의 어려움을 완화했다.","We have been studying a deep-learning program that can communicate with other users in online communities since 2017. But there were problems with processing a Korean data set because of Korean characteristics. Also, low usage of GPUs of RNN models was a problem too. In this study, as Natural Language Processing models are improved, we aim to make better results using these improved models. To archive this, we use a Transformer model which includes Self-Attention mechanism. Also we use MeCab, korean morphological analyzer, to address a problem with processing korean words."
3차원 가상도시 모델에서 높이맵을 이용한 CNN 기반의 그림자 탐지방법,2019,"['그림자 탐지', '딥러닝', 'Shadow detection', 'Deep-learning']","최근 교육, 제조, 건설 등 다양한 응용 분야에서 사실적인 가상환경을 표현하기 위하여 실세계 영상데이터를 활용하는 사례가 증가하고 있다. 특히, 스마트 시티 등 디지털 트윈에 대한 관심이 높아지면서, 항공 영상 등 실제 촬영한 영상을 이용하여 현실감 있는 3D 도시 모델을 구축하고 있다. 그러나, 촬영된 항공 영상에는 태양에 의한 그림자가 포함되어 있으며, 그림자가 포함된 3D 도시 모델은 사용자에게 정보를 왜곡시켜 표현하는 문제를 안고 있다. 그림자를 제거하기 위하여 그동안 많은 연구가 진행되었지만, 아직 까지 해결하기 어려운 도전적인 문제로 인식되고 있다. 본 논문에서는 VWorld에서 제공하는 3차원 공간정보를 이용하여 건물의 높이맵을 포함한 가상환경 데이터 셋을 구축하고, 높이맵과 딥러닝을 이용한 새로운 그림자 탐지 방법을 제안한다. 실험 결과에 의하면, 높이맵을 사용했을 때 기존 방법보다 그림자 탐지 에러율이 감소한 것을 확인할 수 있다.","Recently, the use of real-world image data has been increasing to express realistic virtual environments in various application fields such as education, manufacturing, and construction. In particular, with increasing interest in digital twins like smart cities, realistic 3D urban models are being built using real-world images, such as aerial images. However, the captured aerial image includes shadows from the sun, and the 3D city model including the shadows has a problem of distorting and expressing information to the user. Many studies have been conducted to remove the shadow, but it is recognized as a challenging problem that is still difficult to solve. In this paper, we construct a virtual environment dataset including the height map of buildings using 3D spatial information provided by VWorld, and We propose a new shadow detection method using height map and deep learning. According to the experimental results, We can observed that the shadow detection error rate is reduced when using the height map."
전수 학습을 이용한 도로교통표지 데이터 분류 효율성 향상 연구,2019,"['전수학습', '도로교통표지', '수치지도제작', '딥러닝', '분류', 'Transfer Learning', 'Road Traffic Sign', 'Digital Mapping', 'Deep Learning', 'Classification']","본 연구에서는 1/1,000 수치지형도 및 정밀도로지도 제작에 있어서 도로 레이어를 구성하고 있는 교통안전표지 및 도로표지의 제작 공정에 있어서 딥러닝의 적용방안을 탐색하였다. 딥러닝의 이미지 분류에서 활용하는 전수학습을 이용하여 취득한 영상에 대한 학습자료 구축을 통해 도로 표지정보의 자동분류를 수행하였다. 분석결과 주의, 규제, 지시, 보조는 촬영된 이미지의 품질 및 형태 등 여러 가지 요소에 의해 정확도가 불규칙하게 나타났지만, 안내표지의 경우는 정확도가 97% 이상으로 높게 나타났다. 수치지도제작에 있어 전수학습을 이용한 이미지 자동분류 방식은 교통안전표지를 포함한 다양한 레이어들에 대한 자료 취득과 분류에 있어서 활용이 증가할 것으로 기대한다.","In this study, we investigated the application of deep learning to the manufacturing process of traffic and road signs which are constituting the road layer in map production with 1 / 1,000 digital topographic map. Automated classification of road traffic sign images was carried out through construction of training data for images acquired by using transfer learning which is used in image classification of deep learning. As a result of the analysis, the signs of attention, regulation, direction and assistance were irregular due to various factors such as the quality of the photographed images and sign shape, but in the case of the guide sign, the accuracy was higher than 97%. In the digital mapping, it is expected that the automatic image classification method using transfer learning will increase the utilization in data acquisition and classification of various layers including traffic safety signs."
관절질환 관리를 위한 Mask R-CNN을 이용한 모션 모니터링,2019,"['CNN', '휴먼모션', '헬스케어', '딥러닝', 'Mask R-CNN', '개인건강기록', 'CNN', 'Human Motion', 'Healthcare', 'Deep Learning', 'Mask R-CNN', 'Personal Health Record']","현대사회는 생활과 개성이 중요시 되면서 개인화된 생활습관 및 패턴이 생기고 있으며, 잘못된 생활습관으로 인해 관절질환자가 증가하고 있다. 또한 1인 가구가 점점 증가하면서 응급상황이 발생할 경우 알맞은 시간에 응급처치를 받지 못하는 경우가 생긴다. 건강과 질병관리에 필요한 개인의 상태에 따른 정확한 분석을 통해 스스로 관리할 수 있는 정보와 응급상황에 맞는 케어가 필요하다. 딥러닝 중에서 CNN은 데이터의 분류 및 예측에 효율적으로 사용된다. CNN은 데이터 특징에 따라 정확도 및 처리 속도에 차이를 보인다. 따라서 실시간 헬스케어를 위해 처리속도 향상과 정확도 개선이 필요하다. 본 논문에서는 관절질환 관리를 위한 Mask R-CNN을 이용한 모션 모니터링을 제안한다. 제안하는 방법은 Mask R-CNN을 이용하여 CNN의 정확도와 처리 속도를 개선하는 방법이다. 사용자의 모션을 신경망에 학습시킨 후 사용자의 모션이 학습된 데이터와 차이가 있을 경우 사용자에게 관리법을 피드백 해주고 보호자에게 응급상황을 알릴 수 있으며 상황에 맞는 적절한 조치를 취할 수 있다.","In modern society, lifestyle and individuality are important, and personalized lifestyle and patterns are emerging. The number of people with articulation diseases is increasing due to wrong living habits. In addition, as the number of households increases, there is a case where emergency care is not received at the appropriate time. We need information that can be managed by ourselves through accurate analysis according to the individual's condition for health and disease management, and care appropriate to the emergency situation. It is effectively used for classification and prediction of data using CNN in deep learning. CNN differs in accuracy and processing time according to the data features. Therefore, it is necessary to improve processing speed and accuracy for real-time healthcare. In this paper, we propose motion monitoring using Mask R-CNN for articulation disease management. The proposed method uses Mask R-CNN which is superior in accuracy and processing time than CNN. After the user's motion is learned in the neural network, if the user's motion is different from the learned data, the control method can be fed back to the user, the emergency situation can be informed to the guardian, and appropriate methods can be taken according to the situation."
포지션 인코딩 기반 S³-Net를 이용한 한국어 기계 독해,2019,"['S³-Net', '한국어 기계독해', '포지션 인코딩', '딥러닝', 'S³-Net', 'Korean machine reading comprehension', 'position encoding', 'deep learning']","S³-Net은 Simple Recurrent Unit (SRU)과 자기 자신의 RNN sequence에 대하여 어텐션 가중치(attention weight)를 계산하는 Self-Matching Networks를 기반으로 기계 독해 질의 응답을 해결하는 딥 러닝 모델이다. 기계 독해 질의 응답에서 질문에 대한 답은 문맥 내에서 발생하는데, 하나의 문맥은 여러 문장으로 이뤄지기 때문에 입력 시퀀스의 길이가 길어져 성능이 저하되는 문제가 있다. 본 논문에서는 이와 같이 문맥이 길어져 성능이 저하되는 문제를 해결하기 위하여 문장 단위의 인코딩을 추가한 계층 모델과, 단어 순서 정보를 확인하는 포지션 인코딩을 적용한 S³-Net을 제안한다. 실험 결과, 본 논문에서 제안한 S³-Net 모델이 한국어 기계 독해 데이터 셋에서 기존의 S²-Net보다 우수한(single test) EM 69.43%, F1 81.53%, (ensemble test) EM 71.28%, F1 82.67%의 성능을 보였다.","S³-Net is a deep learning model that is used in machine reading comprehension question answering (MRQA) based on Simple Recurrent Unit and Self-Matching Networks that calculates attention weight for own RNN sequence. The answers to the questions in the MRQA occur within the passage, because any passage is made up of several sentences, so the length of the input sequence becomes longer and the performance deteriorates. In this paper, a hierarchical model that adds sentence-level encoding and S³-Net that applies position encoding to check word order information to solve the problem of long-term context degradation are proposed. The experimental results show that the S³-Net model proposed in this paper has a performance of 69.43% in EM and 81.53% in F1 for single test, and 71.28% in EM and 82.67 in F1 for ensemble test."
Faster R-CNN 기반의 관심영역 유사도를 이용한 후방접근차량 검출 연구,2019,"['Deep lerning', 'Faster r-cnn', 'Agricultural machine', 'Vehicle detection', 'Structure similarity']",본 논문에서는 농업 기계 시스템에서 사용하기 위한 딥러닝 알고리즘 기반의 프레임 내의 관심 영역 유사성을 이용한 새로운 후방 접근 차량 검출 알고리즘을 제안한다. 농업 기계 시스템은 후방에서 접근하는 차량만 검출해야 한다. 지나가는 자동차가 검출되면 혼란을 야기할 수 있다. 논문에서는 차량 검출을 위해 딥러닝에서 뛰어난 검출률을 나타내는 FasterR-CNN 모델을 사용하였다. 딥러닝은 뒤에서 접근하는 차량뿐만 아니라 지나가는 차량도 검출하므로 긍정오류 차량을 배제해야 한다. 본 논문에서 이를 해결하기 위해 검출된 프레임에서 관심 영역에 대한 유사성과 평균 에러를 피라미드 형태로 이용하여 접근하는 자동차만 검출하는 알고리즘을 제안하였다. 실험을 통하여 제안된 방법이 평균 98.8%의 높은 검출률을 나타내었다.,"In this paper, we propose a new algorithm to detect rear-approaching vehicle using the frame similarity of ROI(Regionof Interest) based on deep learning algorithm for use in agricultural machinery systems. Since the vehicle detectionsystem for agricultural machinery needs to detect only a vehicle approaching from the rear. we use Faster R-CNN modelthat shows excellent accuracy rate in deep learning for vehicle detection. And we proposed an algorithm that uses theframe similarity for ROI using constrained conditions. Experimental results show that the proposed method has adetection rate of 99.9% and reduced the false positive values."
실시간 야구 중계를 위한 CNN 기반 고속 야구 선수 위치 검출 시스템,2019,"['image detection algorithm', 'deep learning', 'CNN', 'baseball broadcasting', '이미지 위치 검출', '딥러닝', 'CNN', '야구 경기 중계']","본 논문에서는 야구 경기 영상에서 딥 러닝 기법들 중 영상 인식에 적합한 CNN을 사용하여 야구 선수의 위치를 검출하는 시스템을 제안한다. 객체의 위치 검출을 위한 기존의 영상 처리 기법들 중 다수는 영상 프레임 사이의 차영상이나 객체의 윤곽을 얻는 방법들을 사용해왔지만, 야구 중계와 같이 다양한 기후와 배경을 모두 고려하여 실용화하기에는 추가적인 검증 과정이 필요하다. 본 논문에서는 다양한 경우에 움직이는 객체의 위치를 빠르게 학습하고 검출하기 위해 이진 블록 영상을 적용하였고 학습 성능을 향상시키기 위해 학습 영상을 추가로 생성하는 데이터 증강 기법을 사용하였다. 선수 위치의 정확도 평가 척도는 목표 객체의 중심점과 지능망을 통해 검출된 확률 중심과의 거리를 평가 척도로 적용하였다.실험 결과는 제안한 방법의 평균 거리가 2.92픽셀로 Faster R-CNN의 평균 거리인 3.35보다 0.43픽셀이 낮아 선수의 위치 검출 정확도가 높으며, 수행 속도도 제안한 방법이 Faster R-CNN보다 69.93배 빠름을 보여준다.","The paper proposes a player location detection system in a baseball game broadcast.Location detection system uses CNN (convolutional neural network) suitable for image processing among diverse deep learning systems. To train the location of a player faster and accurately, we choose binary block labeling instead of the commonly used edge detection methods. Data augmentation method, which generates additional training images was applied to increase the degree of accuracy.The distance between the center position of the target and the output position by neural network was used to measure performance. Experimental results indicated that the average pixel distances between center of target position and one of output are 2.92 and 3.35 in the case of the proposed method and Faster R-CNN, respectively. In addition, the execution time of the proposed method was established to be 69.93 times faster than that of Faster R-CNN."
인공지능 기반의 행동인식을 통한 개인 운동 트레이너 구현의 방향성 제시,2019,"['Healthcare', 'Fitness', 'Artificial Intelligence', 'Deep Running', 'CNN', 'RNN', '헬스케어', '피트니스', '인공지능', '딥러닝', '합성곱 신경망', '순환 신경망']","최근 딥러닝을 비롯한 인공지능 기술의 활용이 다양한 분야에서 활발해지고 있으며, 특히 딥러닝 기술 기반의 객체 인식 및 검출에 뛰어난 성능을 보이는 여러 알고리즘들이 발표되고 있다. 이에 본 논문에서는 사용자의 편의성이 효과적으로 반영된 모바일 헬스케어 애플리케이션 구현에 대한 적절한 방향성을 제시하고자 한다. 기존의 피트니스 애플리케이션들에 대한 이용 만족도 연구 및 모바일 헬스케어 애플리케이션에 대한 현황을 파악하여, 이로부터 피트니스 애플리케이션 시장에서의 생존과 우위를 확보하는 동시에, 최근 주목 받고 있는 인공지능 기술의 효과적인 적용에 의한 성능 개선을 통해 기존 이용자 유지 및 확대를 도모하고자 한다.","Recently, the use of artificial intelligence technology including deep learning has become active in various fields. In particular, several algorithms showing superior performance in object recognition and detection based on deep learning technology have been presented. In this paper, we propose the proper direction for the implementation of mobile healthcare application that user's convenience is effectively reflected. By effectively analyzing the current state of use satisfaction research for the existing fitness applications and the current status of mobile healthcare applications, we attempt to secure survival and superiority in the fitness application market, and, at the same time, to maintain and expand the existing user base."
적응형 채널 어텐션 모듈을 활용한 복합 열화 복원 네트워크,2019,"['Image restoration', 'Deep learning', 'Channel attention', 'CNN', '영상복원', '딥러닝', '채널 어텐션', '합성곱신경망']",자율 주행 자동차나 소방 로봇과 같은 시스템에서 영상을 얻을 때 다양한 요인들로 인해 잡음，블러와 같은 열화가 발생한 다. 이런 열화된 영상에 직접 영상 분류와 같은 기술을 적용하기 어려워 열화 제거가 불가피하나 이러한 시스템들은 영상의 열화를 인식할 수 없어서 열화된 영상을 복원하는데 어려움이 있다. 본 논문에서는 영상에 적용된 열화를 인지하지 못하는 상황에서 여러 방법들로 열화된 영상으로부터 자연스럽고 선명한 영상을 복원하는 방법을 제안한다. 우리가 제안한 방법은 딥러닝 모델에 채널 어텐션 모듈과스깁 커넥션을사용하여 영상에 적용된 열화에 따라복원에 필요한 채널에 높은 가중치를 적용해 복합 열화 영상의 복원을 진행한다. 이 방법은 다른복합 열화복원 방법 에 비해 학습이 간단하고 기존의 다른 방법들에 비 해 높은 복합 열화 복원 성능을 낸다.,"The image obtained from systems such as autonomous driving cars or fire-fighting robots often suffer from several degradation such as noise, motion blur, and compression artifact due to multiple factor. It is difficult to apply image recognition to these degraded images, then the image restoration is essential. However, these systems cannot recognize what kind of degradation and thus there are difficulty restoring the images. In this paper, we propose the deep neural network, which restore natural images from images degraded in several ways such as noise, blur and JPEG compression in situations where the distortion applied to images is not recognized. We adopt the channel attention modules and skip connections in the proposed method, which makes the network focus on valuable information to image restoration. The proposed method is simpler to train than other methods, and experimental results show that the proposed method outperforms existing state-of-the-art methods."
실시간 미니드론 카메라 영상을 기반으로 한 얼굴 인식 시스템 개발,2019,"['드론', '실시간 드론 영상', '드론 제어', 'GUI', '얼굴 인식', '딥러닝', 'Drone', 'Real-time Drone image', 'Drone Control', 'GUI', 'Face Recognition', 'Deep Learning']","본 논문에서는 미니 드론을 조종하면서 드론에 부착된 카메라가 촬영하는 영상을 실시간으로 받아들여 특정인의 얼굴을 인식하여 확인시켜주는 시스템 개발 방법론을 제안한다. 본 시스템의 개발을 위해서는 OpenCV, Python 관련 라이브러리 및 드론 SDK 등을 사용한다. 실시간 드론 영상으로부터 특정인의 얼굴 인식 비율을 높이기 위해서는 딥러닝 기반의 얼굴 인식 알고리즘을 사용하며 특히 Triples 원리를 활용한다. 시스템의 성능을 확인하기 위해 저자 얼굴을 기준으로 30회 동안 얼굴 인식 실험을 수행한 결과 약 95% 이상의 인식률을 보여주었다. 본 논문의 연구 결과물은 관광지, 축제 행사장 등에서 특정인을 드론으로 빠르게 찾기 위한 목적으로 사용할 수 있을 것으로 판단된다.","In this paper, I propose a system development methodology that accepts images taken by camera attached to drone in real time while controlling mini drone and recognize and confirm the face of certain person. For the development of this system, OpenCV, Python related libraries and the drone SDK are used. To increase face recognition ratio of certain person from real-time drone images, it uses Deep Learning-based facial recognition algorithm and uses the principle of Triples in particular. To check the performance of the system, the results of 30 experiments for face recognition based on the author's face showed a recognition rate of about 95% or higher. It is believed that research results of this paper can be used to quickly find specific person through drone at tourist sites and festival venues."
R-FCN과 Transfer Learning 기법을 이용한 영상기반 건설 안전모 자동 탐지,2019,"['Construction safety', 'Object detection', 'Deep learning', 'Neural network', '건설안전', '물체 탐지', '딥러닝', '인공신경망']","대한민국에서 건설업은 타 업종들과 비교하여 안전사고의 위험성이 가장 높게 나타난다. 따라서 건설업 내 안전성 향상을 도모하기 위해 여러 연구가 예전부터 진행이 되어 왔고, 본 연구에선 건설현장 영상 데이터를 기반으로 물체 탐지 및 분류 알고리즘을 이용해서 효과적인 안전모 자동탐지 시스템을 구축하여 건설현장 노동자들의 안전성 향상에 기여하고자 한다. 본 연구에서 사용된 알고리즘은 Convolutional Neural Network (CNN) 기반의 물체 탐지 및 분류 알고리즘인 Region-based Fully Convolutional Networks (R-FCN)이고 이를 Transfer Learning 기법을 사용하여 딥러닝을 실시하였다. ImageNet에서 수집한 1089장의 사람과 안전모가 포함된 영상으로 학습을 시행하였고 그 결과, 사람과 안전모의 mean Average Precision (mAP)은 각각 0.86, 0.83로 측정되었다.","In Korea, the construction industry has been known to have the highest risk of safety accidents compared to other industries. Therefore, in order to improve safety in the construction industry, several researches have been carried out from the past. This study aims at improving safety of labors in construction site by constructing an effective automatic safety helmet detection system using object detection algorithm based on image data of construction field. Deep learning was conducted using Region-based Fully Convolutional Network (R-FCN) which is one of the object detection algorithms based on Convolutional Neural Network (CNN) with Transfer Learning technique. Learning was conducted with 1089 images including human and safety helmet collected from ImageNet and the mean Average Precision (mAP) of the human and the safety helmet was measured as 0.86 and 0.83, respectively."
단일 이미지에 기반을 둔 사람의 포즈 추정에 대한 연구 동향,2019,"['Deep learning', 'human pose', 'human pose estimation', 'action recognition', 'research trends', '딥러닝', '사람 포즈', '사람 포즈 추정', '행동인식', '연구 동향']","최근 딥러닝 기술이 발전함에 따라 많은 컴퓨터 비전 연구 분야에서 주목할 만한 성과들이 지속적으로 나오고 있다. 단일 이미지를 기반으로 사람의 2차원 및 3차원 포즈를 추정하는 연구에서도 비약적인 성능향상을 보여주고 있으며, 많은 연구자들이 문제의 범위를 확장하며 활발한 연구 활동을 진행하고 있다. 사람의 포즈 추정은 다양한 응용 분야가 존재하고, 특히 이미지나 비디오 분석에서 사람의 포즈는 행동 및 상태, 의도 파악을 위한 핵심 요소가 되기 때문에 상당히 중요한 연구 분야이다. 이러한 배경에 따라 본 논문은 단일 이미지를 기반으로 한 사람의 포즈 추정 기술에 대한 연구 동향을 살펴보고자 한다. 강인하고 정확한 문제 해결을 위해 다양한 연구 활동 결과가 존재한다는 점에서 본 논문에서는 사람의 포즈 추정 연구를 2차원 및 3차원 포즈 추정에 대해서 나누어 살펴보고자 한다. 끝으로 연구에 필요한 데이터 세트 및 사람의 포즈 추정 기술을 적용하는 다양한 연구 사례를 살펴볼 것이다.","With the recent development of deep learning technology, remarkable achievements have been made in many research areas of computer vision. Deep learning has also made dramatic improvement in two-dimensional or three-dimensional human pose estimation based on a single image, and many researchers have been expanding the scope of this problem. The human pose estimation is one of the most important research fields because there are various applications, especially it is a key factor in understanding the behavior, state, and intention of people in image or video analysis. Based on this background, this paper surveys research trends in estimating human poses based on a single image. Because there are various research results for robust and accurate human pose estimation, this paper introduces them in two separated subsections: 2D human pose estimation and 3D human pose estimation. Moreover, this paper summarizes famous data sets used in this field and introduces various studies which utilize human poses to solve their own problem."
3차원 뇌 자기공명 영상의 비지도 학습 기반 비강체 정합 네트워크,2019,"['Deep Learning', 'Unsupervised Learning', 'Non-rigid Registration', '3D Brain MR Image', '딥러닝', '비지도 학습', '비강체 정합', '3차원 뇌 자기공명 영상']","비강체 정합은 임상적 필요성은 높으나 계산 복잡도가 높고, 정합의 정확성 및 강건성을 확보하기 어려운 분야이다. 본 논문은 비지도 학습 환경에서 3차원 뇌 자기공명 영상 데이터에 딥러닝 네트워크를 이용한 비강체 정합 기법을 제안한다. 서로 다른 환자의 두 영상을 입력받아 네트워크를 통하여 두 영상 간의 특징 벡터를 생성하고, 변위 벡터장을 만들어 기준 영상에 맞추어 다른 쪽 영상을 변형시킨다. 네트워크는 U-Net 형태를 기반으로 설계하여 정합 시 두 영상의 전역적, 지역적인 차이를 모두 고려한 특징 벡터를 만들 수 있고, 손실함수에 균일화 항을 추가하여 3차원 선형보간법 적용 후에 실제 뇌의 움직임과 유사한 변형 결과를 얻을 수 있다. 본 방법은 비지도 학습을 통해 임의의 두 영상만을 입력으로 받아 단일 패스 변형으로 비강체 정합을 수행한다. 이는 반복적인 최적화 과정을 거치는 비학습 기반의 정합 방법들보다 빠르게 수행할 수 있다. 실험은 50명의 뇌를 촬영한 3차원 자기공명 영상을 가지고 수행하였고, 정합 전·후의 Dice Similarity Coefficient 측정 결과 평균 0.690으로 정합 전과 비교하여 약 16% 정도의 유사도 향상을 확인하였다. 또한, 비학습 기반 방법과 비교하여 유사한 성능을 보여주면서 약 10,000배 정도의 속도 향상을 보여주었다. 제안 기법은 다양한 종류의 의료 영상 데이터의 비강체 정합에 활용이 가능하다.","Although a non-rigid registration has high demands in clinical practice, it has a high computational complexity and it is very difficult for ensuring the accuracy and robustness of registration. This study proposes a method of applying a non-rigid registration to 3D magnetic resonance images of brain in an unsupervised learning environment by using a deep-learning network. A feature vector between two images is produced through the network by receiving both images from two different patients as inputs and it transforms the target image to match the source image by creating a displacement vector field. The network is designed based on a U-Net shape so that feature vectors that consider all global and local differences between two images can be constructed when performing the registration. As a regularization term is added to a loss function, a transformation result similar to that of a real brain movement can be obtained after the application of trilinear interpolation. This method enables a non-rigid registration with a single-pass deformation by only receiving two arbitrary images as inputs through an unsupervised learning. Therefore, it can perform faster than other non-learning-based registration methods that require iterative optimization processes. Our experiment was performed with 3D magnetic resonance images of 50 human brains, and the measurement result of the dice similarity coefficient confirmed an approximately 16% similarity improvement by using our method after the registration. It also showed a similar performance compared with the non-learning-based method, with about 10,000 times speed increase. The proposed method can be used for non-rigid registration of various kinds of medical image data."
비프로파일링 기반 전력 분석의 성능 향상을 위한 오토인코더 기반 잡음 제거 기술,2019,"['Side-Channel Analysis', 'Non-Profiled Attack', 'Deep Learning', 'Auto-Encoder', 'Preprocessing']","최근 보안 디바이스의 물리적 취약성을 찾을 수 있는 부채널 분석 분야에서 딥러닝을 활용한 연구가 활발히진행되고 있다. 하지만, 최신 딥러닝 기반 부채널 분석 기술 연구는 템플릿 공격 등과 같은 프로파일링 기반부채널 분석 환경에서 파형을 옳게 분류하기 위한 연구에 집중되어 있다. 본 논문에서는 이전 연구들과 다르게 딥러닝을 신호 전처리 기법으로 활용하여 차분 전력 분석, 상관 전력 분석 등과 같은 논프로파일링 기반부채널 분석의 성능을 고도화할 수 있는 방법을 제안한다. 제안기법은 오토인코더를 부채널 분석 환경에 적합하게 변경하여 부채널 정보의 노이즈를 제거하는 전처리 기법으로, 기존 노이즈 제거 오토인코더는 임의로 추가한 노이즈에 대한 학습을 하였다면 제안하는 기법은 노이즈가 제거된 라벨을 사용하여 실제 데이터의 노이즈를 학습한다. 제안기법은 논프로파일링 환경에서 수행 가능한 전처리 기법이며 하나의 뉴런 네트워크의 학습만을 통해 수행할 수 있다. 본 논문에서는 실험을 통해 제안기법의 노이즈 제거 성능을 입증하였으며, 주성분분석 및 선형판별분석과 같은 기존 전처리 기법들과 비교하여 우수하다는 것을 보인다.'","In side-channel analysis, which exploit physical leakage from a cryptographic device, deep learning based attack has beensignificantly interested in recent years. However, most of the state-of-the-art methods have been focused on classifyingside-channel information in a profiled scenario where attackers can obtain label of training data. In this paper, we propose anew method based on deep learning to improve non-profiling side-channel attack such as Differential Power Analysis andCorrelation Power Analysis. The proposed method is a signal preprocessing technique that reduces the noise in a trace bymodifying Auto-Encoder framework to the context of side-channel analysis. Previous work on Denoising Auto-Encoder wastrained through randomly added noise by an attacker. In this paper, the proposed model trains Auto-Encoder through thenoise from real data using the noise-reduced-label. Also, the proposed method permits to perform non-profiled attack bytraining only a single neural network. We validate the performance of the noise reduction of the proposed method on realtraces collected from ChipWhisperer board. We demonstrate that the proposed method outperforms classic preprocessingmethods such as Principal Component Analysis and Linear Discriminant Analysis."
어린이집 영역배치 자동 대안생성을 위한 Deep Learning의 활용에 관한 연구,2019,"['Deep Learning', 'Artificial Intelligence', 'Architectural Design', 'Design Automata', 'Expert System', '딥러닝', '인공지능', '건축디자인', '설계자동화', '전문가시스템']","본 연구는 최근 개발 및 활용이 활발하게 이루어지고 있는 Deep Learning기술을 건축설계 대안생성과정에 활용하는 것을 목표로 한다. 이는 건축가가 생각하기 어려운 상황을 검토하고 그 결과를 자동으로 제시하여 건축가에게 최적의 대안 결정을 지원하게 하는 것을 말한다. 본 기술은 설계자동화와 같이 전통적인 건축 디자인 컴퓨팅 분야에서 연구되어온 주제와 그 맥을 같이하나 기존에 판단 기준을 미리 정해주는 단순한 방식의 인공지능과 차별화되어 인간과 같이 수많은 데이터 중에서 일정한 패턴을 스스로 탐색하고 추론하여 최적의 결과를 도출하는 것에 차별점이 있다. 본 연구에서는 평면디자인에서 공간 및 사물 배치를 통하여 벌어지는 인간행동을 학습하고 이를 추론하여 최적의 결과를 도출하는 기술개발을 목표로 한다. 즉, 어린이집의 가구 및 공간 배치에 대한 딥러닝 기술을 활용한 자동 대안생성 기술개발에 관한 내용이 주가 된다. 본 연구에서는 보육공간의 영역 및 아동의 활동을 모델링하고 기존의 Deep Learning 기술을 도입하여 자동으로 대안을 생성하고 최적의 대안을 제안하는 시스템 개발의 예를 제시하고 있다.","The purpose of this study is to utilize Deep Learning technology which is actively developed and utilized recently in the process of building alternative design. This means that the architect examines situations that are difficult to think about and automatically presents the results to help architects make the best alternative decisions. This technology is different from the artificial intelligence, which is a simple method that pre-sets judgment criteria in the same way as the theme that has been studied in the field of traditional architectural design computing such as design automation, There is a difference in deriving the optimum result by reasoning. In this study, we aim to develop a technique that learns human behavior through space and object arrangement in plane design and derives optimal result by reasoning it. That is to say, the development of automatic alternative generation technology using deep learning technology for furniture and space arrangement of daycare center. In this study, we present an example of system development that automatically creates alternatives and suggests optimal alternatives by modeling the area of ​​children 's space and activities of children and introducing existing Deep Learning technology."
CNN과 Bidirectional LSTM을 활용한 부산시 민원 자동 분류 연구,2019,"['automatic text classification', 'civil complaint', 'CNN', 'bidirectional LSTM', 'bi－LSTM', '민원', '자동분류', '딥러닝', '순환신경망', '양방향 LSTM', 'CNN']","온라인과 정보통신기술의 발달로 정부정책에 대한 시민의 참여 욕구는 높아지고 있다. 이에 따라 시민들은 민원을 인터넷과 모바일을 활용하여 전자 민원 게시판을 통해 접수하는 건수가 증가하고 있다. 폭발적으로 늘어나는 민원의 양에 비해 아직 수작업으로 분류 하여 오류가 발생하거나 신속한 대응이 이루어지지 않아 민원인들의 불만이 늘어나고 있다. 본 연구에서는 딥러닝 기법을 통해 담당 부서 분류를 자동화하기 위해 2017년도의 부산시 민원 데이터를 수집하고, 담당 부서를 확인 할 수 있는 부서명, 전화번호, 담당자명을 기준으로 레이블을 부여하였다. 그리고 딥러닝 중 대표적인 분류방법인 CNN과 최근 여러 분야에서 두각을 내고 있는 Bidirectional LSTM을 기반으로 상위 12개 범주에 대하여 지도학습을 실시하였다. 지도학습 결과 각각 73%, 77%의 정확도를 보여 안정적인 성능을 보여주었다. 본 연구의 민원 분류에 대한 지도학습 사례는 향후 다른 주제 및 지방자치단체 민원에 대한 텍스트 데이터의 분류에 이용될 수 있어 실무적인 공헌도와 함께 후속연구를 유발할 수 있다는 학문적 기여도가 있다.",
문화예술 콘텐츠 제작 및 유통에서의 빅데이터 활용 연구,2019,"['Bigdata', 'Video Contents', 'Algorithm', 'Culture Arts Industry', 'Netflix', 'FGI', '빅데이터', '알고리즘', '영상콘텐츠', '문화예술산업', 'Netflix', 'FGI']","4차 산업혁명 시대의 폭발적인 정보의 양을 다루는 빅데이터 관련 연구는 현재 활발히 진행되고 있다. 빅데이터는 머신러닝, 즉 딥러닝의 학습데이터가 되는 광범위한 데이터로 인공지능의 발달을 촉진하는 필수 요소이다. 다양한 분야에서 빅데이터의 활용은 유의미한 결과를 가져오고 있으며, 특히 문화예술 분야에서의 활용도 주목해 볼 필요가 있다. 이에 본 논문은 영상콘텐츠를 중심으로 문화예술 산업에서 빅데이터의 활용 사례를 알아보았다. 주목한 점은 문화예술 콘텐츠의 유통뿐만 아니라 제작단계까지 빅데이터가 활용되고 있는 점이다. 특히 미국의 Netflix가 OTT사업으로 어떤 성과와 변화를 가져왔는지를 먼저 알아보고 국내의 OTT 사업체의 현황도 함께 분석하였다. 그 후 Netflix가 축적된 고객의 데이터를 통해 딥러닝 방식의 ‘시네매치’, 즉 흥행 예측 알고리즘을 활용하여 제작/유통한 ‘House of Cards’의 성공 사례를 분석하였다. 그 후 문화예술 콘텐츠 전문가를 대상으로 FGI(Focus Group Interview)를 진행하였다. 이를 통해 국내 문화예술 산업에서 빅테이터의 향후 활용 전망을 기술적인 측면, 창의적인 측면, 윤리적인 측면으로 나눠서 고찰하였다.","Big data-related research that deals with the amount of explosive information in the era of the Fourth Industrial Revolution is actively underway. Big data is an essential element that promotes the development of artificial intelligence with a wide range of data that become learning data for machine learning, or deep learning. The use of deep learning and big data in various fields has produced meaningful results. In this paper, we have investigated the use of Big Data in the cultural arts industry, focusing on video contents. Noteworthy is that big data is used not only in the distribution of cultural and artistic contents but also in the production stage. In particular, we first looked at what kind of achievements and changes the Netflix in the US brought to the OTT business, and analyzed the current state of the OTT business in Korea. After that, Netflix analyzed the success stories of 'House of Cards', which was produced / circulated through 'Deep Learning' cinematique, which is a prediction algorithm, through accumulated customer data. After that, FGI (Focus Group Interview) was held for cultural and artistic contents experts. In this way, the future prospects of Big Data in the domestic culture and arts industry are divided into technical aspect, creative aspect, and ethical aspect."
절단된 분포를 이용한 인공신경망에서의 초기값 설정방법,2019,"['initialization', 'saturation', 'Xavier initialization', 'truncated distribution', 'deep learning', '초기값', '포화', 'Xavier', '절단된 분포', '딥러닝']",딥러닝은 대용량의 데이터의 분류 및 예측하는 방법으로 각광받고 있다. 데이터의 양이 많아지면서 신경망의 구조는 더 깊어 지고 있다. 이때 초기값이 지나치게 클 경우 층이 깊어 질수록 활성화 함수의 기울기가 매우 작아지는 포화(Saturation)현상이 발생한다. 이러한 포화현상은 가중치의 학습능력을 저하시키는 현상을 발생시키기 때문에 초기값의 중요성이 커지고 있다.이런 포화현상 문제를 해결하기 위해 Glorot과 Bengio (2010)과 He 등 (2015) 층과 층 사이에 데이터가 다양하게 흘러야 효율적인 신경망학습이 가능하고 주장했다. 데이터가 다양하게 흐르기 위해서는 각 층의 출력에 대한 분산과 입력에 대한 분산이 동일해야 한다고 제안했다. Glorot과 Bengio (2010)과 He 등 (2015)는 각 층별 활성화 값의 분산이 같다고 가정해 초기값을 설정하였다. 본 논문에서는 절단된 코쉬 분포와 절단된 정규분포를 활용하여 초기값을 설정하는 방안을 제안한다. 출력에 대한 분산과 입력에 대한 분산의 값을 동일하게 맞춰주고 그 값이 절단된 확률분포의 분산과 같게 적용함으로써 큰 초기값이 나오는 걸 제한하고 0에 가까운 값이 나오도록 분포를 조정하였다. 제안된 방법은 MNIST 데이터와 CIFAR-10 데이터를 DNN과 CNN 모델에 각각 적용하여 실험함으로써 기존의 초기값 설정방법보다 모델의 성능을 좋게 한다는 것을 보였다,"Deep learning has gained popularity for the classification and prediction task. Neural network layers become deeper as more data becomes available. Saturation is the phenomenon that the gradient of an activation function gets closer to 0 and can happen when the value of weight is too big. Increased importance has been placed on the issue of saturation which limits the ability of weight to learn. To resolve this problem, Glorot and Bengio (Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, 249-256, 2010) claimed that efficient neural network training is possible when data flows variously between layers. They argued that variance over the output of each layer and variance over input of each layer are equal. They proposed a method of initialization that the variance of the output of each layer and the variance of the input should be the same. In this paper, we propose a new method of establishing initialization by adopting truncated normal distribution and truncated cauchy distribution. We decide where to truncate the distribution while adapting the initialization method by Glorot and Bengio (2010). Variances are made over output and input equal that are then accomplished by setting variances equal to the variance of truncated distribution. It manipulates the distribution so that the initial values of weights would not grow so large and with values that simultaneously get close to zero. To compare the performance of our proposed method with existing methods, we conducted experiments on MNIST and CIFAR-10 data using DNN and CNN. Our proposed method outperformed existing methods in terms of accuracy."
인공지능과 차별,2019,"['인공지능', '규제', '알고리즘', '차별', '불투명성', '적법절차', 'Artificial intelligence', 'Algorithmic discrimination', 'Opacity', 'Technological due process']","인간이 인공지능을 사용할 때 발생하는 차별은 법적으로 어떻게 취급되어야 하는가? 현재 널리 사용되는 ‘딥러닝(deep learning)’ 인공지능은 범용적 문제해결이 가능한 판단주체가 아니며, 과거의 데이터를 통계적으로 재조직하는 고도화된 분석도구라 할 수 있다. 적어도 현재의 인공지능 기술은 인간의 판단을 전반적으로 대신하는 것이라 보기 어렵다. 인공지능과 관련된 차별 문제에 대한 법적 규율은, 인공지능의 훈련과정에서 어떤 데이터가 이용되는지 그리고 어떻게 알고리즘이 구축되는지 등에 관한 구체적인 사항에 집중할 필요가 있다. 이는 사법적 판단을 통한 사후적 규율과 규제를 통한 사전적 규율에 대해 여러 쟁점을 야기하는데, 이 글에서는 쟁점들을 세 그룹으로 나누어 분석한 뒤 각각에 대해 잠정적 견해를 제시한다.  첫째로, 인간에게는 차별의도가 없었음에도 인공지능 학습에 활용된 데이터에 과거의 차별적 요소가 반영되어 있었던 탓에 인공지능을 활용한 의사결정이 차별을 발생시킨 경우, 배상책임의 귀책사유 인정이 어려울 수 있다.   둘째로, 인공지능의 학습 및 판단방식은 제도적으로 영업비밀인데다 본질적으로 인간이 이해하기 어렵고, 현실적으로 처리방식을 사법절차를 통해 재현하기도 용이하지 않을 수 있다. 이들은 재판을 통한 사후적 차별구제에서 각각 실체법, 절차법적으로 쉽지 않은 문제를 야기한다.  셋째로, 딥러닝 인공지능은 차별이 반영된 과거의 데이터들을 경로의존적으로 재생산하기 때문에 차별구조를 질적으로 악화시킬 수 있다. 그러나 가능한 대안이 무엇인지는 명확하지 않다. 데이터 및 알고리즘에 대한 사전적 통제 및 개인의 이의권 보장 등이 고려될 수 있으나, 이러한 방식은 대체로 현실성이 높지 않고 일반론적인 투명성을 과도하게 강조함으로써 개인정보나 사생활의 권리를 침해할 수도 있다. 인공지능과 차별에 관한 법제도적 규율의 문제는, 어떤 데이터를 얼마나 상세한 수준에서 이용할 수 있는지, 그 과정에 나타날 수 있는 통계적 편향 등의 문제를 어떻게 해결할 것인지에 관한 이론적인 동시에 실무적인 다양한 이슈들을 새로이 제기한다. 인공지능에 대한 차별 맥락에서의 규율은, 차별금지의 일반적 원칙, 행정절차에 대한 투명성 원칙, 개인정보보호 원칙 등 여러 법정책적 목표들이 복잡하게 중첩되어 고려되는 영역이어서 더욱 입체적인 분석이 필요하다.","How should the discrimination that arises when humans use the artificial intelligence be treated legally? The widely used ‘deep learning’ artificial intelligence is not a generalizable problem solver, but it is a sophisticated analytical tool that statistically reorganizes historical data. At present, it is difficult to say that the current artificial intelligence technology is a substitute for human judgment as a whole. The legal discipline for the discrimination related to the artificial intelligence needs to focus on specifics on what data are used in the training of the artificial intelligence and how the algorithms are built. This leads to various legal and regulatory issues.  First, even though human beings have no intention to discriminate, training data used for the artificial intelligence training may reflect past discriminatory factors, so that when decisions are made using artificial intelligence, such decisions may also reflect or even amplify the discrimination. Second, the relevant algorithm may well constitute trade secrets. Third, even if the algorithm is disclosed, it could be inscrutable, and, further, reproduction of the previous algorithmic decisions may not be possible since the algorithms and/or data may be frequently updated or modified. These factors give rise to difficulties in substantive law as well as in procedural law. Fourth, ‘deep learning’ may exacerbate discrimination because it tends to reflect or even exaggerate biases contained in the training data in a path-dependent way."
인공지능과 금융법,2019,"['Artificial Intelligence(AI)', 'Financial Law', 'Financial Regulation', 'robo-advisor', 'consumer protection.', '인공지능(AI)', '법인격', '딥 러닝', '금융법', '금융규제', '로보어드바이저', '소비자보호', '블랙박스화.']","AI가 활용되는 사례 중 하나가 금융 분야에서 등장하고 있는 로보어드바이저(Robo-Adviser)인데, AI 로봇은 사람 못지않은 자산관리 조언자로서의 기능을 하고 있으며, 이처럼 AI를 활용하는 사례는 금융서비스 분야에서 급속히 늘어나고 있다. 그리하여 우리나라의 금융업계도 AI 도입에 본격적으로 경쟁에 돌입하고 있다.금융 분야는 반드시 수리적인 분석과 연결되어 있고, AI를 이용한 기술혁신의 영향을 받기 쉬운 분야이기 때문에 AI가 활용될 수 있는 최적의 분야 중 하나가 금융 분이다. 따라서 우리나라의 은행을 비롯한 금융업계 AI를 활용한 각종 서비스를 제공하고 있고 보다 나은 AI를 개발하기 위해 노력하고 있다. 그런데 AI를 둘러싼 각종 법적 문제 또한 많은 것도 사실이다. 그리하여 이 논문은 우리나라의 금융 분야에서의 AI의 활용상황, AI와 금융규제, AI에 의한 서비스와 고객보호 등에 대해 살펴 본 후, AI와 현행법의 과제, 그리고 미래의 법제도 등에 대하여 살펴보았다.무엇보다도 AI에게 법인격을 인정해야 하는지에 대해서는 책임귀속기능이나 법체계의 안정화 가능에 크게 기여하는 바가 없을 것으로 보이고 AI에게 법인격을 인정할 경우, 현존하는 기술적 능력 범위에서 AI를 통제할 수 없음을 증명한 사업자는 사용자책임에서 벗어날 수 있게 되는 문제점이 존재한다. 이는 결국 사업자로 하여금 통제가 불가능한 AI를 활용하도록 조장하는 결과를 초래할 것이기에 현재로서는 AI에게 법인격을 인정하는 것에 찬동하지 않는다.이 이외에도 AI에 의한 시장안정성의 위협을 어떻게 해결할 것인지의 문제와 AI가 딥 러닝의 방법에 의한 학습을 통해 얻은 지식을 가지고 의사결정을 한 경우 그 의사결정이 어떤 과정에 의해 이루진 것인지가 명확하지 않고 블랙박스(black box)화 되는 문제 때문에 규제당국이 문제의 소재를 찾아내는 데 어려움을 겪게 되고, AI를 이용한 의사결정이 금융시스템 전체에 손해를 야기한 때, 책임소재를 밝히기가 쉽지 않은 문제점이 존재한다. 또한 소비자보호에 있어서 로보어드바이저와 관련하여 이해상충 방지체계를 어떻게 구축할 것인지 등에 대해 심도 있는 연구가 진행되어야 할 것으로 보인다.","I think one of the best areas where AI can be utilized is the financial sector. This is because the financial sector is necessarily linked to mathematical analysis and is easily affected by innovation using AI. Therefore, it is providing various services using AI in the financial industry, including the nation's banks, and making efforts to develop better AI. However, it is also true that there are many legal issues surrounding AI. Thus, this paper looked at the utilization status of AI in our country's financial sector, AI and financial regulations, service and consumer protection by AI, and then looked at the tasks of AI and current law, and the future legal system.Above all, it seems that there is no significant contribution to the possibility of stabilizing the legal system or the function of the responsibility for AI, and there is a problem in which a business that proves that AI cannot be controlled within the existing technological capabilities can be relieved of its user responsibilities. As this will result in encouraging businesses to utilize AI, which may be out of control, I am not in favor of recognizing AI's corporate status at the moment.In addition, there are other issues of how to address the threat of market stability by AI, and when AI makes decisions with knowledge gained from learning by deep running methods, it is not clear what process the decision was made and black boxed, making it difficult for regulators to locate the problem, and not easy to identify when AI decision-making has caused damage to the entire financial system. In addition, in-depth research on how to establish an anti-corrosion system in relation to the robo-advisor should be conducted in-depth."
자동화기반의 가짜 뉴스 탐지를 위한 연구 분석,2019,"['Fake news', 'Fake Information', 'Fake News Challenge', 'Maching Learning', 'Deep Learning', '가짜 뉴스', '가짜정보', '가짜 뉴스 챌린지', '머신러닝', '딥러닝']","가짜 정보를 탐지하기 위한 연구는 2016년 미국 대통령 선거 이후 본격적으로 시작되었다. 정확한 출처를 알 수 없는 정보들이 뉴스 형식으로 생산되고, 이는 자극적이고 흥미로운 소재에 많은 관심을 보이는 대중의 특성에 따라 빠른 속도로 확산되고 있다. 또한, 소셜 네트워크 서비스 등 정보를 전달하기 쉬운 플랫폼의 대중화는 이러한 현상을 더욱 악화시킨다. Poynter는 IFCN(International Fact Checking Network)를 만들어 숙련된 전문가들이 사실 여부를 판단할 수 있는 가이드라인을 제시하고, 팩트 체크 기관을 위한 강령을 제공하고 있다. 하지만 이러한 접근 방법은 하나의 기사에 대한 진위 여부를 검증하기 위해 다수의 전문가 인력이 투입되어야 하므로 시간 및 금전적 비용이 크다. 따라서 지속적으로 증가하는 가짜 뉴스에 효율적으로 대응할 수 있는 자동화된 가짜 뉴스 탐지 기술에 대한 연구가 주목받고 있다. 본 논문에서는 최근 딥러닝 기술의 접목으로 인해 빠르게 발전하고 있는 가짜 뉴스 탐지 시스템과 연구들을 정리 및 분석한다. 또한, 많은 연구가 필요한 본 분야에 연구자들이 쉽게 접근할 수 있도록 다양한 형태로 주어지는 학습 말뭉치 및 챌린지들도 정리한다.","Research in detecting fake information gained a lot of interest after the US presidential election in 2016. Information from unknown sources are produced in the shape of news, and its rapid spread is fueled by the interest of public drawn to stimulating and interesting issues. In addition, the wide use of mass communication platforms such as social network services makes this phenomenon worse. Poynter Institute created the International Fact Checking Network (IFCN) to provide guidelines for judging the facts of skilled professionals and releasing “Code of Ethics” for fact check agencies. However, this type of approach is costly because of the large number of experts required to test authenticity of each article. Therefore, research in automated fake news detection technology that can efficiently identify it is gaining more attention. In this paper, we investigate fake news detection systems and researches that are rapidly developing, mainly thanks to recent advances in deep learning technology. In addition, we also organize shared tasks and training corpus that are released in various forms, so that researchers can easily participate in this field, which deserves a lot of research effort."
CNN 기반 전이학습을 이용한 음성 감정 인식,2019,"['Speech Emotion Recognition', 'Transfer Learning', 'Deep Learning', 'Convolutional Neural Networks', '음성 감정 인식', '전이학습', '딥러닝', '합성곱 신경망']","로봇은 사람의 편의를 위해 존재하므로 사람과 로봇의 상호작용은 중요하다. 로봇이 사람의 감정을 파악하는 것은 여러상호작용 중 하나이다. 최근 사람의 음성으로 감정을 인식하는 음성 감정 인식(speech emotion recognition; SER)분야는딥러닝 (deep learning)의 접목으로 그 성능이 향상되고 있다. 하지만, 데이터의 부족으로 깊은 신경망을 사용하거나추가적인 학습 기법을 적용하지 않고서는 높은 정확도를 기대하기 힘들다. 본 논문에서는 데이터가 부족할 때 사용하는 학습기법 중의 하나인 전이학습 (transfer learning)을 SER에 적용한 효과를 확인한다. 딥러닝을 적용하기 위해 합성곱 신경망(convolutional neural networks; CNN) 구조를 사용한다. 전이학습에 음성 감정 데이터가 아닌 일반 소리 데이터를 사용하여데이터 개수에 대한 한계를 없앤다. 전이학습 중 특징 추출기 (feature extractor)로써 사용한 경우와 미세조정 (fine tuning)을한 경우로 나누어 결과를 확인한다. 그 결과, 미세조정한 경우 수렴 시간이 약 20% 줄었고, 특징 추출기로써 사용한 경우 약20%에서 70% 줄었다. 정확도는 특징 추출기로써 사용한 경우 오히려 정확도가 감소하는 경우가 발생하였고 증가한 경우 약3% 증가했다. 미세조정을 한 경우 정확도가 평균적으로 약 7% 향상되었다","Interaction between human and robot is important because robots exist for the convenience of people. Robot grasping human emotions is one of many interactions. The field of SER (speech emotion recognition) has been improved by combining deep learning. The lack of data makes it difficult to expect high accuracy without using deep neural networks or applying additional learning techniques. In this paper, we confirm the effect of applying the transfer learning, which is one of the learning methods used when there is insufficient data, to SER. For deep learning, CNN (convolutional neural networks) architecture is used. By using general sound data instead of speech emotion data for the transfer learning, the limit on the number of data is eliminated. The results are verified by dividing transfer learning into two case, using as a feature extractor and fine-tuning. As a result, convergence time was reduced by about 20% when fine-tuning, and about 20% to 70% when used as a feature extractor. Accuracy of the feature extractor is rather reduced when it is used as a feature extractor and increased by about 3% when it is increased. On the average, the accuracy was improved by about 7% when fine-tuning."
변형된 DenseNet과 HPF를 이용한 카메라 모델 판별 알고리즘,2019,"['camera model identification', 'deep learning', 'DenseNet', 'high-pass filter']","영상 관련 범죄가 증가하고 고도화됨에 따라서 고수준의 디지털 포렌식 기술이 요구된다. 그러나 기존의 특징 기반 기술은 인간이 고안한 특징을 활용함으로서 새로운 기기 특징에 쉽게 대응하기 어렵고, 딥러닝 기반 기술은 정확도 향상이 요구된다. 본 논문에서는 딥러닝 모델 분야의 최신 기술인 DenseNet을 기반으로 카메라 모델 판별을 위한 딥러닝 모델을 제안한다. 카메라의 센서 특징을 획득하기 위해 HPF 특징 추출 필터를 적용하였고, 카메라 판별에 적합하도록 기존 DenseNet에서 계층 반복 수를 조정하였다. 또한 연산량을 줄이기 위한 Bottleneck layer와 압축 연산 처리를 제거하였다. 제안한 모델을 Dresden 데이터베이스를 사용하여 성능 분석을 하였고, 14개 카메라 모델에 대해 99.65%의 정확도를 달성하였다. 기존 연구들보다 높은 정확도를 달성하였으며 기존에 동일한 제조사에서 정확도가 낮아지는 단점을 극복하였다.","Against advanced image-related crimes, a high level of digital forensic methods is required. However, feature-based methods are difficult to respond to new device features by utilizing human-designed features, and deep learning-based methods should improve accuracy. This paper proposes a deep learning model to identify camera models based on DenseNet, the recent technology in the deep learning model field. To extract camera sensor features, a HPF feature extraction filter was applied. For camera model identification, we modified the number of hierarchical iterations and eliminated the Bottleneck layer and compression processing used to reduce computation. The proposed model was analyzed using the Dresden database and achieved an accuracy of 99.65% for 14 camera models. We achieved higher accuracy than previous studies and overcome their disadvantages with low accuracy for the same manufacturer."
빅데이터를 이용한 심리학 연구 방법,2019,"['Big Data', 'Artificial Intelligence', 'Machine Learning', 'Topic Modeling', 'Deep Learning', 'Data-driven Analysis', 'Model-driven analysis', '빅데이터', '인공지능', '기계학습', '주제모형', '딥러닝', '자료주도적 분석', '모형주도적 분석']","빅데이터, 기계학습, AI 등의 새로운 기술의 발달은 사람들의 사고와 행동을 변화시키고 이전에는 접근하기 힘들었던 인간에 대한 다양한 활동을 관찰하는 것을 가능하게 한다. 사람들이 인터넷을 광범위하게 사용함에 따라서, 개인의 행동도 인터넷에 저장되고 있다. 자료들은 매우 광범위하며 다양하기 때문에 이를 적절하게 분석하면 인간 심리를 이해하는 범위를 확대할 수 있을 것이다. 이 논문에서는 새롭게 발달된 이러한 기술들을 심리학 연구에 활용하는 방법에 대하여 모색하고자 하였다. 특히 기술의 발달로 가능해진 새로운 자료, 빅데이터의 특성과 심리학에서의 활용방안에 대하여 논의하였다. 이 논문에서는 첫째, 빅데이터의 특성과 빅데이터가 심리학에서 어떠한 역할을 할 수 있는지 살펴보았다. 심리학의 모형주도적 분석법과 다른 빅데이터의 자료주도적 분석법의 문제점들과 이러한 분석을 심리학연구에 어떻게 적용될 수 있는지에 대하여 논의하였다. 둘째, 자료의 분석 방법론에 대하여 살펴보았다. 기존 심리학 연구에서는 정교한 연구설계에 의해 자료가 수집되기 때문에 분석이 상대적으로 덜 중요하지만, 빅데이터 분석에서는 자료분석의 역할이 아주 중요해진다. 방대하고 구조화되지 않은 자료를 처리할 수 있어야 하고, 언어 자료와 같은 숫자 이외의 자료도 분석할 수 있어야 한다. 특히 주제 모형화, 능선 회귀분석과 라소 회귀분석, 지지벡터 기계, 신경망, 딥러닝 등에 대한 원리를 소개하고 심리학 연구에 적용되는 방법들에 대하여 논의하였다. 셋째, 심리학에서 빅데이터 분석 적용의 한계점을 살펴보고, 마지막으로 빅데이터의 심리학 연구의 적용에 대한 방법을 제안하였다.","The development of new technology such as big data, machine learning, and Artificial Intelligence changes human behaviors and thought. Increased use of the internet makes it possible to observe various human activities that were not observable before. Huge amounts of data about various types of human activities are being stored on the internet. Analyzing this information will help extend the scope of understanding human behaviors and psychology. The present paper attempts to find a way of applying new technology to psychological studies. Specifically, we focused on what big data are like and how they can be used for psychological research. This paper first reviewed the characteristics of big data and their role in psychological research. In this context, it discussed the problems of data-driven analysis techniques in which big data analysis is applied and the possibility of applying such methods to psychological research. In this context, it discussed the problems of the data-driven analytic scheme that big data analysis adapting and the possibilities of applying such a method to psychological research. Second, data analytic techniques used in big data analyses are reviewed. These techniques should be able to deal with big and unorganized data and unstructured data such as pictures, video clips, texts, etc. Specifically, it reviewed basic principles of topic modeling, ridge or lasso regression, support vector machine, neural network, and deep learning, and their application to psychological data. Third, the limitations of the use of big data in psychological research are discussed. Finally, it proposed ways of applying big data technology to psychological research."
지능형 행동인식 기술을 이용한 실시간 동영상 감시 시스템 개발,2019,"['Video Surveillance System', 'Behavior Recognition', 'Openpose', 'Deep Learning']","최근에 빠르게 확산되고 있는 CCTV와 같은 영상기기들은 거의 모든 공공기관, 기업, 가정 등에서 비정상적인 상황을 감시하고 대처하기 위한 수단으로 활용되고 있다. 그러나 대부분의 경우 이상상황에 대한 인식은 모니터링하고 있는 사람에 의해 수동적으로 이루어지고 있어 즉각적인 대처가 미흡하며 사후 분석용으로만 활용되고 있다. 본 논문에서는 최신 딥러닝 기술과 실시간 전송기술을 활용하여 이벤트 발생시 스마트폰으로 이상 상황을 동영상과 함께 실시간으로 전송하는 동영상 감시 시스템의 개발 결과를 제시한다. 개발된 시스템은 오픈포즈 라이브러리를 이용하여 실시간으로 동영상으로 부터인간 객체를 스켈레톤으로 모델링한 후, 딥러닝 기술을 이용하여 인간의 행동을 자동으로 인식하도록 구현하였다. 이를 위해Caffe 프레임워크를 개발된 오픈포즈 라이브러리를 다크넷 기반으로 재구축하여 실시간 처리 능력을 대폭 향상 시켰으며, 실험을 통해 성능을 검증하였다. 본 논문에서 소개할 시스템은 정확하고 빠른 행동인식 성능과 확장성을 갖추고 있어 다양한용도의 동영상 감시 시스템에 활용될 수 있을 것으로 기대된다.","Recently, video equipments such as CCTV, which is spreading rapidly, is being used as a means to monitor and cope with abnormal situations in almost governments, companies, and households. However, in most cases, since recognizing the abnormal situation is carried out by the monitoring person, the immediate response is difficult and is used only for post-analysis. In this paper, we present the results of the development of video surveillance system that automatically recognizing the abnormal situations and sending such events to the smartphone immediately using the latest deep learning technology. The proposed system extracts skeletons from the human objects in real time using Openpose library and then recognizes the human behaviors automatically using deep learning technology. To this end, we reconstruct Openpose library, which developed in the Caffe framework, on Darknet framework to improve real-time processing. We also verified the performance improvement through experiments. The system to be introduced in this paper has accurate and fast behavioral recognition performance and scalability, so it is expected that it can be used for video surveillance systems for various applications."
단안 비디오로부터의 5차원 라이트필드 비디오 합성,2019,"['Deep learning', 'Light field', 'Video synthesis', 'View synthesis']","현재 사용 가능한 상용 라이트필드 카메라는 정지 영상만을 취득하거나 가격이 매우 높은 단점으로 인하여 5차원 라이트필드 비디오 취득에 어려움이 있다. 이러한 문제점을 해결하기 위해 본 논문에서는 단안 비디오로부터 라이트필드 비디오를 합성하기 위한 딥러닝 기반 기법을 제안한다. 라이트필드 비디오 학습 데이터를 취득하기 어려운 문제를 해결하기 위하여 UnrealCV를 활용하여 3차원 그래픽 장면의 사실적 렌더링에 의한 합성 라이트필드 데이터를 취득하고 이를 학습에 사용한다. 제안하는 딥러닝 프레임워크는 입력 단안 비디오에서 9×9의 각 SAI(sub-aperture image)를 갖는 라이트필드 비디오를 합성한다. 제안하는 네트워크는 밝기 영상으로 변환된 입력 영상으로부터 appearance flow를 추정하는 네트워크, appearance flow로부터 얻어진 인접한 라이트필드 비디오 프레임간의 optical flow를 추정하는 네트워크로 구성되어 있다.",
Depth Estimation 기술의 원리 및 동향,2019,"['Depth', 'Deep Learning', 'Stereo', 'Monocular', '360 Images']","딥러닝의 발전에 따라 거리측정 기술 또한 비약적인 발전이 있었다. 본 논문에서는 양안 영상뿐만 아니라 단안영상에서의 거리측정 기술 동향에 알아본다. 또한, 단안 영상에서의 비지도학습 방법으로부터 카메라의 포즈를 측정을 통해 거리 측정 성능을 개선시키는 방법, 객체 모션 모델링을 통해 거리측정 성능을 개선시키는 방법에 대해 알아본다. 거리측정 기술은 다른 영상 기법의 기반이 되는 기술이며 GPU가 장착될 수 있는 자율주행, 로봇뿐만 아니라 스마트폰에서의 AR/VR, 드론 등에 접목하기 위해 경량화된 딥러닝에 기반한 거리측정 기술을 다룬다. 한 편, 2D 영상뿐만 아니라 360 영상과 같이 3차원의 영상에서의 거리 측정 기술도 함께 알아보고자 한다.","With the advent of deep learning, the depth estimation based on images has made dramatic process for recent a few years. In this paper, we take a close look at not only stereo approach methods but also monocular approaches. In particular, unsupervised monocular methods consider the pose of the camera and by estimating the camera position and adopt to the current depth estimation. Besides, light-weight depth estimation network shows promising results that the network inference is able to execute on CPU. Moreover, we introduce the depth estimation method using 360 image inputs."
순환신경망 모형을 활용한 시계열 비교예측,2019,"['ARIMA model', 'neural network', 'RNN', 'LSTM.', 'ARIMA 모형', '신경망모형', '순환신경망', 'LSTM.']","최근 알파고 이후 딥러닝 연구에 대한 활발한 연구가 진행되고 있다. 딥러닝에는 이미지 분석에 적합한 CNN(convolution neural network), 순차적 자료에 적합한 RNN(recurrent neural network) 모델 등 많은 모델이 존재하는데 그 중 시계열데이터 분석에 적합한 딥러닝 모델을 전형적 시계열데이터인 항공사 데이터(1949년 1월부터 1960년 12월까지 매월 총 국제 항공사 승객 수)에 Box-Jenkins의 ARIMA 모형과 함께 적합시켜 비교 할 것이다. 본 연구에서는 R 프로그램을 이용하여 LSTM(long short-term memory) 순환신경망 모델을 구축하고, ARIMA 모형, Faraway(1998)가 제시한 단순 신경망(neural network) 모형 그리고 Jordan & Elman의 순환신경망 모형과의 적합도를 비교하였다. 모형 비교결과 Elman 모형의 오차제곱합이 0.0128, Jordan 모형의 오차제곱 합이 0.0138, LSTM 모형의 오차제곱합이 0.0165, 신경망 모형은 오차제곱합 0.0212로 ARIMA 모형의 0.0194 에 비해 조금 뒤떨어지는 것으로 나타났다. 결국 Elman 순환신경망 모형이 가장 우수하게 나타났으며 LSTM 모형도 기존 ARIMA 모형과 Faraway의 단순신경망모형 보다 우수한 적합도를 나타났다.","Typical algorithms for deep learning include DNN (deep neural network), CNN (convolution neural network), and RNN (recurrent neural network) algorithms. Among them, RNN is excellent at dealing with sequential data. Sequential data such as time series data can be handled without losing gradient by LSTM (long short-term memory) RNN. In this study, the LSTM, a modified algorithm of RNN, is applied to international airline passenger data (from January 1, 1994 to December 1960). We find the optimal model and compare it with the ARIMA model, the initial network model presented by Faraway (1998), and the model of Jordan & Elman, the simple RNN model. To compare the models, we train the data as learning data sets from January 1949 to December 1950, and designate the remaining one year of data as test sets. and compare the performance of the model with the sum of square errors of the test sets. The model comparison shows that the Elman RNN model was the best, and that the LSTM model was not inferior to the ARIMA model."
네트워크 데이터 정형화 기법을 통한 데이터 특성 기반 기계학습 모델 성능평가,2019,"['IDS', 'Deep learning', 'Data normalize']",최근 4차 산업 혁명 기술 중 하나인 딥러닝(Deep Learning) 기술은 보안 분야에서는 탐지하기 어려운 네트워크데이터의 숨겨진 의미를 식별하고 공격을 예측하는 데 사용되고 있다. 침입탐지에 사용될 딥러닝 알고리즘을 선택하기 전에 데이터의 속성과 품질 분석이 필요하다. 학습에 사용되는 데이터의 오염여부에 따라 탐지 방법에 영향을 주기 때문이다. 따라서 데이터의 특징을 파악하고 특성을 선정해야 한다. 본 논문에서는 네트워크 데이터 셋을 이용하여악성코드의 단계적 특징을 분석하고 특성을 추출하여 딥러닝 모델을 적용하였을 때 각 특성이 성능에 미치는 영향을분석하였다. 네트워크 특징에 따른 특성들의 비교에 대한 트래픽 분류 실험을 진행하였으며 선정한 특성을 기반으로96.52% 정확도를 분류하였다.,"Recently Deep Learning technology, one of the fourth industrial revolution technologies, is used to identify the hiddenmeaning of network data that is difficult to detect in the security arena and to predict attacks. Property and quality analysisof data sources are required before selecting the deep learning algorithm to be used for intrusion detection. This is becauseit affects the detection method depending on the contamination of the data used for learning. Therefore, the characteristics ofthe data should be identified and the characteristics selected. In this paper, the characteristics of malware were analyzedusing network data set and the effect of each feature on performance was analyzed when the deep learning model wasapplied. The traffic classification experiment was conducted on the comparison of characteristics according to networkcharacteristics and 96.52% accuracy was classified based on the selected characteristics."
임의의 잡음 신호 추가를 활용한 적대적으로 생성된 이미지 데이터셋 탐지 방안에 대한 연구,2019,"['Adversarial examples', 'Adversarial attack detection', 'Convolutional neural network', 'Deep learning', 'Random noise addition']","여러 분야에서 사용되는 이미지 분류를 위한 딥러닝(Deep Learning) 모델은 오류 역전파 방법을 통해 미분을 구현하고 미분 값을 통해 예측 상의 오류를 학습한다. 엄청난 계산량을 향상된 계산 능력으로 해결하여, 복잡하게 설계된 모델에서도 파라미터의 전역 (혹은 국소) 최적점을 찾을 수 있다는 것이 장점이다. 하지만 정교하게 계산된 데이터를 만들어내면 이 딥러닝 모델을 ‘속여’ 모델의 예측 정확도와 같은 성능을 저하시킬 수 있다. 이렇게 생성된 적대적 사례는 딥러닝을 저해할 수 있을 뿐 아니라, 사람의 눈으로는 쉽게 발견할 수 없도록 정교하게 계산되어 있다. 본 연구에서는  임의의 잡음 신호를 추가하는 방법을 통해 적대적으로 생성된 이미지 데이터셋을 탐지하는 방안을 제안한다. 임의의 잡음 신호를 추가하였을 때 일반적인 데이터셋은 예측 정확도가 거의 변하지 않는 반면, 적대적 데이터셋의 예측 정확도는 크게 변한다는 특성을 이용한다. 실험은 공격 기법(FGSM, Saliency Map)과 잡음 신호의 세기 수준(픽셀 최댓값 255 기준 0-19) 두 가지 변수를 독립 변수로 설정하고 임의의 잡음 신호를 추가하였을 때의 예측 정확도 차이를 종속 변수로 설정하여 시뮬레이션을 진행하였다. 각 변수별로 일반적 데이터셋과 적대적 데이터셋을 구분하는 탐지 역치를 도출하였으며, 이 탐지 역치를 통해 적대적 데이터셋을 탐지할 수 있었다.","In Deep Learning models derivative is implemented by error back-propagation which enables the model to learn the error and update parameters. It can find the global (or local) optimal points of parameters even in the complex models taking advantage of a huge improvement in computing power. However, deliberately generated data points can ‘fool’ models and degrade the performance such as prediction accuracy. Not only these adversarial examples reduce the performance but also these examples are not easily detectable with human’s eyes. In this work, we propose the method to detect adversarial datasets with random noise addition. We exploit the fact that when random noise is added, prediction accuracy of non-adversarial dataset remains almost unchanged, but that of adversarial dataset changes. We set attack methods (FGSM, Saliency Map) and noise level (0-19 with max pixel value 255) as independent variables and difference of prediction accuracy when noise was added as dependent variable in a simulation experiment. We have succeeded in extracting the threshold that separates non-adversarial and adversarial dataset. We detected the adversarial dataset using this threshold."
스마트 모터 진단 시스템의 구현,2019,"['deep learning', 'DCGAN', 'DNN', 'inverter', 'cloud DB', 'mobile app', 'motor diagnosis']","모터의 회전자 손상을 진단하기 위해, 모터를 정지 상태로 유지하고 회전자를 일정한 위치로 이동한 후에 인버터를 통해 측정된 저항 및 인덕터 값을 분석하는 방법이 많이 사용되고 있지만, 이것은 회전자를 일정한 위치에 이동해야 하는 반복적인 작업을 필요로 한다. 이에 본 연구에서는 반복적인 작업을 최소화할 수 있도록 인버터, 딥-러닝 엔진, 모바일 앱 프로그램을 포함하는 스마트 모터 진단 시스템을 구현하여, 인버터를 통해 측정한 소수의 데이터를 입력으로 사용하는 딥-러닝 알고리즘을 실행하여 빅 데이터를 생성하고, 이 데이터를 기반으로 학습을 진행한 후에 모터를 진단할 수 있도록 하였다. 실험을 통해 이 진단 시스템은 진단 장치의 진단 정확도를 검증할 수 있을 뿐만 아니라, 새로운 방식의 딥-러닝 스마트 진단 시스템으로 사용 가능함을 확인 할 수 있었다.","In order to diagnose a rotor damage of the motor, the motor is stopped first and the rotor is moved to a predetermined position, thereafter a method of analyzing the resistance and the inductance measured through the inverter is widely used. However it’s method requires repetitive tasks to move the rotor to a predetermined position. In this study, a smart motor diagnosis system using inverter, deep-learning engine and mobile app program were implemented to minimize repetitive tasks. Using the deep-learning algorithm, the big data were generated by applying a small number of data measured through the inverter and then the motor could be diagnosed. Through experiments, it was confirmed that this diagnosis system not only can verify the diagnostic accuracy of the motor but also can be used as a new type of deep-learning smart diagnosis system."
CNN 기반 초분광 영상 분류를 위한 PCA 차원축소의 영향 분석,2019,"['Principal Component Analysis', 'Convolutional Neural Network', 'Dimensionality Reduction', 'Hyperspectral Image Classification']","대표적인 딥러닝(deep learning) 기법 중 하나인 Convolutional Neural Network(CNN)은 고수준의 공간- 분광 특징을 추출할 수 있어 초분광 영상 분류(Hyperspectral Image Classification)에 적용하는 연구가 활발히 진행되고 있다. 그러나 초분광 영상은 높은 분광 차원이 학습 과정의 시간과 복잡도를 증가시킨다는 문제가 있어 이를 해결하기 위해 기존 딥러닝 기반 초분광 영상 분류 연구들에서는 차원축소의 목적으로 Principal Component Analysis (PCA)를 적용한 바 있다. PCA는 데이터를 독립적인 주성분의 축으로 변환시킬 수 있어 분광 차원을 효율적으로 압축할 수 있으나, 분광 정보의 손실을 초래할 수 있다. PCA의 사용 유무가 CNN 학습의정확도와 시간에 영향을 미치는 것은 분명하지만 이를 분석한 연구가 부족하다. 본 연구의 목적은 PCA를 통한분광 차원축소가 CNN에 미치는 영향을 정량적으로 분석하여 효율적인 초분광 영상 분류를 위한 적절한 PCA 의 적용 방법을 제안하는 데에 있다. 이를 위해 PCA를 적용하여 초분광 영상을 축소시켰으며, 축소된 차원의크기를 바꿔가며 CNN 모델에 적용하였다. 또한, 모델 내의 컨볼루션(convolution) 연산 방식에 따른 PCA의 민감도를 분석하기 위해 2D-CNN과 3D-CNN을 적용하여 비교 분석하였다. 실험결과는 분류정확도, 학습시간, 분산 비율, 학습 과정을 통해 분석되었다. 축소된 차원의 크기가 분산 비율이 99.7~8%인 주성분 개수일 때 가장 효율적이었으며, 3차원 커널 경우 2D-CNN과는 다르게 원 영상의 분류정확도가 PCA-CNN보다 더 높았으며, 이를 통해 PCA의 차원축소 효과가 3차원 커널에서 상대적으로 적은 것을 알 수 있었다.","CNN (Convolutional Neural Network) is one representative deep learning algorithm, which can extract high-level spatial and spectral features, and has been applied for hyperspectral image classification. However, one significant drawback behind the application of CNNs in hyperspectral images is the high dimensionality of the data, which increases the training time and processing complexity. To address this problem, several CNN based hyperspectral image classification studies have exploited PCA (Principal Component Analysis) for dimensionality reduction. One limitation to this is that the spectral information of the original image can be lost through PCA. Although it is clear that the use of PCA affects the accuracy and the CNN training time, the impact of PCA for CNN based hyperspectral image classification has been understudied. The purpose of this study is to analyze the quantitative effect of PCA in CNN for hyperspectral image classification. The hyperspectral images were first transformed through PCA and applied into the CNN model by varying the size of the reduced dimensionality. In addition, 2D-CNN and 3D-CNN frameworks were applied to analyze the sensitivity of the PCA with respect to the convolution kernel in the model. Experimental results were evaluated based on classification accuracy, learning time, variance ratio, and training process. The size of the reduced dimensionality was the most efficient when the explained variance ratio recorded 99.7%~99.8%. Since the 3D kernel had higher classification accuracy in the original-CNN than the PCA-CNN in comparison to the 2D-CNN, the results revealed that the dimensionality reduction was relatively less effective in 3D kernel."
폐암검진에서 인공지능 기술의 활용,2019,"['Lung Neoplasms', 'Screening', 'Computed Tomography', 'X-Ray', 'Artificial Intelligence']","저선량 CT를 이용한 폐암검진은 폐암 사망률 감소 효과가 입증되었으며, 국내에서도 시작되었다. 효과적인 폐암검진을 위해서는 저선량 CT에 대한 정확한 판독이 전제되어야 한다. 하지만, 추정 검사 건수와 경험 있는 전문가의 수를 고려했을 때 영상의학 진료에 큰 부담이 될것은 자명해 보인다. 이 문제의 해결 측면에서, 인공지능 기술을 활용한 저선량 CT 판독 보조시스템 개발과 적용에 학계와 관련 산업계의 관심이 모아지고 있다. 특히, 의학영상 분석에직접 적용이 가능한 딥러닝(deep learning) 기술은 기존 기계학습(machine learning) 기술보다 우수한 진단 성능을 보이고 있어, 그 잠재적 유용성에 대한 연구가 활발히 진행되고 있다. 폐암검진에서 딥러닝을 포함한 인공지능 기술을 적용할 수 있는 분야는 크게 컴퓨터 보조 병변 검출, 판독문 생성, 검출된 폐결절의 악성도 평가, 그리고 환자의 예후 예측으로 나누어 볼 수 있다. 이에 본 기고문에서는 현재 폐암검진에 활용할 수 있는 인공지능 기반 연구들을 살펴보고, 향후 이를 이용한 폐암검진의 가능성에 대해 논의하고자 한다.","Lung cancer is a leading cause of deaths due to cancer, worldwide. At present, low-dose computed tomography (CT) is the only established screening method for reducing lung cancer mortality.However, several challenges must be overcome, to ensure the implementation of lung cancer screening, which include a large number of expected low-dose CT examinations and relative shortage of experienced radiologists for interpreting them. The use of artificial intelligence has garnered attention in this regard. A deep learning technique, which is a subclass of machine learning methods, involving the learning of data representations in an end-to-end manner, has already demonstrated outstanding performance in medical image analysis. Several studies are exploring the possibility of deep learning-based applications in medical domains, including radiology.In lung cancer screening, computer-aided detection, report generation, prediction of malignancy in the detected nodules, and prognosis prediction can be considered for the application of artificial intelligence. This article will cover the current status of deep learning approaches, their limitations, and their potential in lung cancer screening programs."
실제 컨버터 출력 데이터를 이용한 특정 지역 태양광 장단기 발전 예측,2019,"['Photovoltaic', 'linear regression', 'Support vector machine', 'Deep neural network', 'Recurrent neural network']","태양광 발전은 일사량만 있으면 전기에너지를 얻을 수 있기 때문에, 새로운 에너지 공급원으로 용도가 급증하고 있다. 본 논문은 실제 태양광 발전 시스템의 컨버터 출력을 이용하여 장단기 출력 예측을 하였다. 예측 알고리즘은 다중선형회귀와 머신러닝의 지도학습 중 분류모델인 서포트 벡터 머신 그리고 DNN과 LSTM 등 딥러닝을 이용하였다. 또한 기상요소의 입출력 구조에 따라 3개의 모델을 이용하였다. 장기 예측은 월별, 계절별, 연도별 예측을 하였으며, 단기 예측은 7일간의 예측을 하였다. 결과로서 RMSE 측도에 의한 예측 오차로 비교해 본 결과 다중선형회귀와 SVM 보다는 딥러닝 네트워크가 예측 정확도 측면에서 더 우수하였다. 또한, DNN 보다 시계열 예측에 우수한 모델인 LSTM이 예측 정확도 측면에서 우수하였다. 입출력 구조에 따른 실험 결과는 모델 1보다 모델 2가 오차가 적었으며, 모델 2보다는 모델 3이 오차가 적었다.","Solar photovoltaic can provide electrical energy with only radiation, and its use is expanding rapidly as a new energy source. This study predicts the short and long-term PV power generation using actual converter output data of photovoltaic system. The prediction algorithm uses multiple linear regression, support vector machine (SVM), and deep learning such as deep neural network (DNN) and long short-term memory (LSTM). In addition, three models are used according to the input and output structure of the weather element. Long-term forecasts are made monthly, seasonally and annually, and short-term forecasts are made for 7 days. As a result, the deep learning network is better in prediction accuracy than multiple linear regression and SVM. In addition, LSTM, which is a better model for time series prediction than DNN, is somewhat superior in terms of prediction accuracy. The experiment results according to the input and output structure appear Model 2 has less error than Model 1, and Model 3 has less error than Model 2."
작물 분류에서 시공간 특징을 고려하기 위한 2D CNN과 양방향 LSTM의 결합,2019,"['Crop classification', 'Convolutional neural network', 'Long short-term memory', 'Spatiotemporal features']","이 논문에서는 작물 분류를 목적으로 작물의 시공간 특징을 고려할 수 있는 딥러닝 모델 2D convolution with bidirectional long short-term memory(2DCBLSTM)을 제안하였다. 제안 모델은 우선 작물의 공간 특징을 추출하기 위해 2차원의 합성곱 연산자를 적용하고, 추출된 공간 특징을 시간 특징을 고려할 수 있는 양방향 LSTM 모델의 입력 자료로 이용한다. 제안 모델의 분류 성능을 평가하기 위해 안반덕에서 수집된 다중시기 무인기 영상을 이용한 밭작물 구분 사례 연구를 수행하였다. 비교를 목적으로 기존 딥러닝 모델인 2차원의 공간 특징을이용하는 2D convolutional neural network(CNN), 시간 특징을 이용하는 LSTM과 3차원의 시공간 특징을 이용하는 3D CNN을 적용하였다. 하이퍼 파라미터의 영향 분석을 통해, 시공간 특징을 이용함으로써 작물의 오분류 양상을 현저히 줄일 수 있었으며, 제안 모델이 공간 특징이나 시간 특징만을 고려하는 기존 딥러닝 모델에비해 가장 우수한 분류 정확도를 나타냈다. 따라서 이 연구에서 제안된 모델은 작물의 시공간 특징을 고려할수 있기 때문에 작물 분류에 효과적으로 적용될 수 있을 것으로 기대된다.","In this paper, a hybrid deep learning model, called 2D convolution with bidirectional long short-term memory (2DCBLSTM), is presented that can effectively combine both spatial and temporal features for crop classification. In the proposed model, 2D convolution operators are first applied to extract spatial features of crops and the extracted spatial features are then used as inputs for a bidirectional LSTM model that can effectively process temporal features. To evaluate the classification performance of the proposed model, a case study of crop classification was carried out using multi-temporal unmanned aerial vehicle images acquired in Anbandegi, Korea. For comparison purposes, we applied conventional deep learning models including two-dimensional convolutional neural network (CNN) using spatial features, LSTM using temporal features, and three-dimensional CNN using spatio-temporal features. Through the impact analysis of hyper-parameters on the classification performance, the use of both spatial and temporal features greatly reduced misclassification patterns of crops and the proposed hybrid model showed the best classification accuracy, compared to the conventional deep learning models that considered either spatial features or temporal features. Therefore, it is expected that the proposed model can be effectively applied to crop classification owing to its ability to consider spatio-temporal features of crops."
드론영상을 이용한 물체탐지알고리즘 기반 도로균열탐지,2019,"['딥러닝', '도로균열', '드론', 'Tiny-YOLO-V2', 'Faster-RCNN', 'Deep Learning', 'Road Crack', 'Drone', 'Tiny-YOLO-V2', 'Faster-RCNN']","본 연구에서는 대전광역시 주요 간선도로인 유성대로를 대상으로 드론을 통해 취득한 노면영상데이터를 기반으로 물체탐지알고리즘(Object Detection algorithm) 가운데 Tiny-YOLO-V2와Faster-RCNN을 활용하여 아스팔트 도로노면의 균열을 인식, 균열유형을 구분하고 실험 결과차이를 비교하였다. 분석결과, Faster-RCNN의 mAP는 71%이고 Tiny-YOLO-V2의 mAP는 33%로 측정되었으며, 이는 1stage Detection인 YOLO계열 알고리즘보다 2Stage Detection인 Faster-RCNN 계열의 알고리즘이 도로노면의 균열을 확인하고 분리하는데 더 좋은 성능을 보인다는 것을 확인하였다. 향후, 드론과 인공지능형 균열검지시스템을 이용한 도로자산관리체계(Infrastructure Asset Management) 구축방안 마련을 통해 효율적이고 경제적인 도로 유지관리 의사결정 지원시스템 구축 및 운영 환경을 조성할 수 있을 것이라 판단된다.","This paper proposes a new methodology to recognize cracks on asphalt road surfaces using the image data obtained with drones. The target section was Yuseong-daero, the main highway of Daejeon. Furthermore, two object detection algorithms, such as Tiny-YOLO-V2 and Faster-RCNN, were used to recognize cracks on road surfaces, classify the crack types, and compare the experimental results. As a result, mean average precision of Faster-RCNN and Tiny-YOLO-V2 was 71% and 33%, respectively.The Faster-RCNN algorithm, 2Stage Detection, showed better performance in identifying and separating road surface cracks than the Yolo algorithm, 1Stage Detection. In the future, it will be possible to prepare a plan for building an infrastructure asset-management system using drones and AI crack detection systems. An efficient and economical road-maintenance decision-support system will be established and an operating environment will be produced."
Sports Broadcasting with Deep Learning,2019,"['딥러닝', '물체 검출', '사람 검출', '행동 인식', '온톨로지', '스포츠 캐스팅', 'deep-learning', 'object detection', 'human detection', 'motion recognition', 'ontology', 'sports commentary']",,
다중작업학습 기법을 적용한 Bi-LSTM 개체명 인식 시스템 성능 비교 분석,2019,"['딥러닝', '다중작업학습', '품사 태깅', '개체명 인식', '전통문화', 'Deep Learning', 'Multi-task Learning', 'Part of speech tagging', 'Named entity Recognition', 'Traditional culture']","다중작업학습(Multi-Task Learning, MTL) 기법은 하나의 신경망을 통해 다양한 작업을 동시에 수행하고 각 작업 간에 상호적으로 영향을 미치면서 학습하는 방식을 말한다. 본 연구에서는 전통문화 말뭉치를 직접 구축 및 학습데이터로 활용하여 다중작업학습 기법을 적용한 개체명 인식 모델에 대해 성능 비교 분석을 진행한다. 학습 과정에서 각각의 품사 태깅(Part-of-Speech tagging, POS-tagging) 과 개체명 인식(Named Entity Recognition, NER) 학습 파라미터에 대해 Bi-LSTM 계층을 통과시킨 후 각각의 Bi-LSTM을 계층을 통해 최종적으로 두 loss의 joint loss를 구한다. 결과적으로, Bi-LSTM 모델을 활용하여 단일 Bi-LSTM 모델보다 MTL 기법을 적용한 모델에서 1.1%~4.6%의 성능 향상이 있음을 보인다.","Multi-Task Learning(MTL) is a training method that trains a single neural network with multiple tasks influences each other. In this paper, we compare performance of MTL Named entity recognition(NER) model trained with Korean traditional culture corpus and other NER model. In training process, each Bi-LSTM layer of Part of speech tagging(POS-tagging) and NER are propagated from a Bi-LSTM layer to obtain the joint loss. As a result, the MTL based Bi-LSTM model shows 1.1%~4.6% performance improvement compared to single Bi-LSTM models."
합성곱 신경망을 이용한 아스팔트 콘크리트 도로포장 표면균열 검출,2019,"['딥러닝', '합성곱 신경망', '아스팔트 도로포장', '아스팔트 도로포장 표면균열', 'Deep learning', 'Convolutional Neural Network', 'Asphalt Pavement', 'Surface Crack']","본 연구에서는 아스팔트 콘크리트 도로포장의 표면균열 검출을 위해 합성곱 신경망을 이용하였다. 합성곱 신경망의 학습에 사용되는 표면균열 이미지 데이터의 양에 따른 합성곱 신경망의 성능향상 정도를 평가하였다. 사용된 합성곱 신경망의 구조는 5개의 층으로 구성되어있으며, 3x3 크기의 convolution filter와 2x2 크기의 pooling kernel을 사용하였다. 합성곱 신경망의 학습을 위해서 도로노면 조사 장비를 통해 구축된 국내 도로포장 표면균열 이미지를 활용하였다. 표면균열 이미지 데이터를 학습한 합성곱 신경망 모델의 표면균열 검출 정확도, 정밀도, 재현율, 미검출율, 과검출율을 평가하였다. 가장 많은 양의 데이터를 학습한 합성곱 신경망 모델의 표면균열 검출 정확도, 정밀도, 재현율은 96.6% 이상, 미검출율, 과검출율은 3.4% 이하의 성능을 나타내었다.","A Convolution Neural Network(CNN) model was utilized to detect surface cracks in asphalt concrete pavements. The CNN used for this study consists of five layers with 3x3 convolution filter and 2x2 pooling kernel. Pavement surface crack images collected by automated road surveying equipment was used for the training and testing of the CNN. The performance of the CNN was evaluated using the accuracy, precision, recall, missing rate, and over rate of the surface crack detection. The CNN trained with the largest amount of data shows more than 96.6% of the accuracy, precision, and recall as well as less than 3.4% of the missing rate and the over rate."
형태소 분석기를 이용한 키워드 검색 기반 한국어 텍스트 명령 시스템,2019,"['Morphological Analyzer', 'Retrieval Based Model', 'Korean', 'Speech Recognition', 'Command', '형태소 분석기', '키워드 기반 모델', '한국어', '음성 인식', '명령']","딥러닝을 기반으로 한 음성 인식 기술이 상용 제품에 적용되기 시작했지만, 음성 인식으로 분석된 텍스트를 효율적으로 처리할 방법이 없기 때문에 VR 컨텐츠에서 그 적용 예를 찾아 보기는 쉽지 않다. 본 논문은 문장의 형태소를 분석하는 형태소 분석기와 챗봇 개발에 주로 이용되는 검색 기반 모델(Retrieval-Based Model)을 활용하여 명령어를 효율적으로 인식하고 대응할 수 있는 한국어 텍스트 명령 시스템을 제안하는 것을 목적으로 한다. 실험 결과 제안한 시스템은 문자열 비교 방식과 같은 동작을 하기 위해 16%의 명령어만 필요했으며, Google Cloud Speech와 연동하였을 때 60.1%의 성공률을 보였다. 실험 결과를 통해 제안한 시스템이 문자열 비교 방식보다 효율적이라는 것을 알 수 있다.","Based on deep learning technology, speech recognition method has began to be applied to commercial products, but it is still difficult to be used in the area of VR contents, since there is no easy and efficient way to process the recognized text after the speech recognition module. In this paper, we propose a Korean Language Command System, which can efficiently recognize and respond to Korean speech commands. The system consists of two components. One is a morphological analyzer to analyze sentence morphemes and the other is a retrieval based model which is usually used to develop a chatbot system. Experimental results shows that the proposed system requires only 16% commands to achieve the same level of performance when compared with the conventional string comparison method. Furthermore, when working with Google Cloud Speech module, it revealed 60.1% of success rate. Experimental results show that the proposed system is more efficient than the conventional string comparison method."
환경요인을 이용한 다층 퍼셉트론 기반 온실 내 기온 및 상대습도 예측,2019,"['기계학습', '딥러닝', '비모델 예측', '인공신경망', 'artificial neural network', 'deep learning', 'machine learning', 'mango', 'model-free prediction']","온도와 상대습도는 작물 재배에 있어서 중요한 요소로써, 수량과 품질의 증대를 위해서는 적절히 제어 되어야한다. 그리고 정확한 환경 제어를 위해서는 환경이 어떻게 변화할지 예측할 필요가 있다. 본 연구의 목적은 현시점의 환경 데이터를 이용한 다층 퍼셉트론(multilayer perceptrons, MLP)을 기반으로 미래 시점의 기온 및 상대습도를 예측하는 것이다. MLP 학습에 필요한 데이터는 어윈 망고(Mangifera indica cv. Irwin)을 재배하는 8 연동 온실(1,032m2)에서 2016년 10월 1일부터 2018년 2 월 28일까지 10분 간격으로 수집되었다. MLP는 온실내부 환경 데이터, 온실 외 기상 데이터, 온실 내 장치의 설정 및 작동 값을 사용하여 10~120분 후 기온 및상대습도를 예측하기 위한 학습을 진행하였다. 사계절이뚜렷한 우리나라의 계절에 따른 예측 정확도를 분석하기위해서 테스트 데이터로 계절별로 3일간의 데이터를 사용했다. MLP는 기온의 경우 은닉층이 4개, 노드 수가128개일 때(R2 = 0.988), 상대습도는 은닉층 4개, 노드수 64개에서 가장 높은 정확도를 보였다(R2 = 0.990).MLP 특성상 예측 시점이 멀어질수록 정확도는 감소하였지만, 계절에 따른 환경 변화에 무관하게 기온과 상대습도를 적절히 예측하였다. 그러나 온실 내 환경 제어 요소 중 분무 관수처럼 특이적인 데이터의 경우, 학습 데이터 수가 적기 때문에 예측 정확도가 낮았다. 본 연구에서는 MLP의 최적화를 통해서 기온 및 상대습도를 적절히예측하였지만 실험에 사용된 온실에만 국한되었다. 따라서 보다 일반화를 위해서 다양한 장소의 온실 데이터 이용과 이에 따른 신경망 구조의 변형이 필요하다.","Temperature and relative humidity are important factors in crop cultivation and should be properly controlled for improving crop yield and quality. In order to control the environment accurately, we need to predict how the environment will change in the future. The objective of this study was to predict air temperature and relative humidity at a future time by using a multilayer perceptron (MLP). The data required to train MLP was collected every 10 min from Oct. 1, 2016 to Feb. 28, 2018 in an eight-span greenhouse (1,032 m2) cultivating mango (Mangifera indica cv. Irwin). The inputs for the MLP were greenhouse inside and outside environment data, and set-up and operating values of environment control devices. By using these data, the MLP was trained to predict the air temperature and relative humidity at a future time of 10 to 120 min. Considering typical four seasons in Korea, three-day data of the each season were compared as test data. The MLP was optimized with four hidden layers and 128 nodes for air temperature (R2 = 0.988) and with four hidden layers and 64 nodes for relative humidity (R2 = 0.990). Due to the characteristics of MLP, the accuracy decreased as the prediction time became longer. However, air temperature and relative humidity were properly predicted regardless of the environmental changes varied from season to season.For specific data such as spray irrigation, however, the numbers of trained data were too small, resulting in poor predictive accuracy. In this study, air temperature and relative humidity were appropriately predicted through optimization of MLP, but were limited to the experimental greenhouse. Therefore, it is necessary to collect more data from greenhouses at various places and modify the structure of neural network for generalization."
얼굴 특징점 검출을 위한 적분 회귀 네트워크,2019,"['Face Alignment', 'Facial Landmark Detection', 'Deep Learning']","최근 딥러닝 기술의 발전과 함께 얼굴 특징점 검출 방법의 성능은 크게 향상되었다. 대표적인 얼굴 특징점 검출 방법인 히트맵 회귀 방법은 효율적이고 강력한 방법으로 널리 사용되고 있으나, 단일 네트워크를 통해 특징점 좌표를 즉시 얻을 수 없으며, 히트맵으로부터 특징점 좌표를 결정하는 과정에서 정확도가 손실된다는 단점이 존재한다. 이러한 문제점들을 해결하기 위해 본 논문에서는 기존의 히트맵 회귀 방법에 적분 회귀 방법을 결합할 것을 제안한다. 여러 가지 데이터셋을 사용한 실험을 통해 제안하는 적분 회귀 네트워크가 얼굴 특징점 검출 성능을 크게 향상시킨다는 것을 보인다.",
해상 영상에서 관심영역 추출과 합성곱 신경망을 활용한 선박 분류,2019,"['선박 분류', '딥러닝', '컴퓨터 비전', '영상처리', 'Ship classification', 'Deep Learning', 'Computer Vision', 'Image Processing']","최근에 해양에서는 선박 스스로 주변 상황을 인지하고 운항할 수 있는 자율운항 기술개발이 활발하게 이루어지고 있다. 이를 위해, 카메라를 통한 영상정보를 활용하여 인간의 시각 정보를 대신할 수 있는 기술에 대한 중요성이 대두되고 있다. 카메라 영상을 기반으로 한 상황인지 기술을 위해서는 영상에서 존재하는 다양한 객체 정보를 분석하는 객체 분류 기술이 필수적이다. 본 논문에서는 해양 영상에서 관심 영역 추출과 합성곱 신경망을 활용하여 선박 분류 정확도를 향상시킬 수 있는 방법을 제안한다. 본 논문에서 제안된 방식의 성능을 검증하기 위해 공개 데이터 셋을 이용하여 기존의 합성곱 신경망 기반 방법과의 비교 실험을 수행하였으며, 실험을 통해 본 논문에서 제안된 방식이 선박 분류 정확도를 향상시킬 수 있음을 확인하였다. 제안된 방법을 활용하여 자율운항선박에서는 다른 해상 장비와의 센서 퓨전을 통하여 객체 데이터의 신뢰성을 확보할 수 있으며, 이를 통해 충돌 회피 및 안전한 운항이 가능할 것으로 기대된다.","Recently, autonomous navigation technology has been actively developed in order to recognize and operate the vessel itself. For this purpose, importance is attached to technologies that can substitute human visual information by utilizing image information through a camera. For the context recognition based on the camera image, object classification technology for analyzing various object information existing in the image is essential. In this paper, we propose a method to improve the accuracy of ship classification by using region of interest and artificial neural network. In order to verify the performance of the propose method in this paper, we performed a comparative experiment with the convolution artificial neural network based on the open data set. Experimental results show that the proposed method improves the accuracy of vessel classification. By using the proposed method, it is possible to secure the reliability of object data through sensor fusion with autonomous vessels, and it is expected that collision avoidance and safe operation will be possible."
인공지능 기반 식생활 습관 개선 다이어트 애플리케이션,2019,"['다이어트 애플리케이션', '머신러닝 기반 추천 시스템', '딥러닝 기반 음식 인식 인터페이스', 'Diet Applications', 'Machine learning-Based Recommended system', 'Deep learning-Based Food recognition inter']",,
Prediction of Compound-Protein Interactions Using Deep Learning,2019,"['기계 번역', '딥러닝', '신약 개발', '화합물-단백질 상호작용', '분류분석', 'Machine translation', 'deep learning', 'drug development', 'compound-protein interaction', 'classification']",,
스마트폰 기반의 무인 영상 추적 시스템 연구,2019,"['영상 추출', '딥러닝', '이미지 추출', '무인 영상', '블루투스', 'Video extraction', 'Deep running', 'Image extraction', 'Unattended moving', 'Bluetooth']","최근 스마트폰 기반의 영상 이미지 추적을 통한 무인 녹화 시스템은 급속히 발전하고 있다. 기존의 제품 중 적외선 신호를 이용하여 촬영 대상을 자동으로 추적 및 회전하여 녹화하는 시스템은 일반 사용자가 사용하기에는 매우 고가이다. 따라서 본 논문에서는 스마트폰을 사용하는 사용자라면 누구나 자동 녹화가 가능한 모바일용 무인 녹화 시스템을 제안한다. 본 시스템은 상용 Mobile 카메라, 좌우로 카메라를 움직이는 서보모터(Servo Motor), 모터를 제어하는 마이크로 컨트롤러 그리고 동영상 오디오 입력을 담당할 상용 무선 블루투스 이어셋(Wireless Bluetooth Earset)으로 구성된다. 본 논문에서는 스마트 폰을 이용하여 영상 추적을 통해 무인 녹화가 가능한 시스템을 설계하였다.","An unattended recording system based on smartphone based image image tracking is rapidly developing. Among the existing products, a system that automatically tracks and rotates the object to be photographed using an infrared signal is very expensive for general users. Therefore, this paper proposes a mobile unattended recording system that enables automatic recording by anyone who uses a smartphone. The system consists of a commercial mobile camera, a servomotor that moves the camera from side to side, a microcontroller to control the motor, and a commercial wireless Bluetooth Earset for video audio input. In this paper, we designed a system that enables unattended recording through image tracking using smartphone."
온라인 뉴스와 기술적 지표를 이용한 테마주 등락 예측,2019,"['테마주', '주가예측', '딥러닝', 'GRU', 'XGBoost', 'Theme Stocks', 'Stock Price Prediction', 'Deep Learning', 'GRU', 'XGBoost']","특정 주제의 뉴스에 의해 주가가 영향을 받는 기업군을 테마주라고 한다. 최근 온라인 뉴스와 기술적 지표를 활용한 주가예측이 연구되고 있지만, 투자 위험이 큰 테마주에 대한 연구는 부족하다. 본 논문에서는 감성 지표와 기술적 지표를 이용하여 테마주에 대해 주가 등락을 예측하는 모델을 제안한다. 제안한 모델은 Gated Recurrent Unit (GRU)를 사용해 뉴스로부터 감성지표를 계산하고, 감성지표와 기술적 지표를 바탕으로 eXtreme Gradient Boosting (XGBoost)을 통해 주가 등락을 예측한다. 북한 테마에 속하는 10개 기업을 이용하여 실험한 결과, 제안한 모델이 최신연구의 모델보다 평균 정확도가 최대 19.0%P 더 높았다.","Theme stocks are a group of companies whose stock prices are affected by news of a certain subject. Recently, there have been research efforts to predict stock prices using online news and technical indicators, but little attention has been paid so far to theme stocks, which have high investment risks. In this paper, we propose a model that predicts stock price fluctuations for theme stocks using a sentiment indicator and technical indicators. The proposed model calculates a sentiment indicator from news using Gated Recurrent Unit (GRU) and predicts stock price fluctuations through eXtreme Gradient Boosting (XGBoost) based on the sentiment indicator and technical indicators. The experimental results using 10 companies belonging to the North Korea theme show that the proposed model improves the average accuracy up to 19.0%P compared with the state-of-the-art model."
유전적 알고리즘이 데이터셋 생성에 미치는 영향에 대한 연구,2019,"['유전 알고리즘', '데이터셋', '딥러닝', '하이퍼파라미터', '적합도', 'Genetic Algorithm', 'Dataset', 'Deep-Learning', 'Hyperparameter', 'Fitness']",,"Currently, deep-learning technology is used in various fields. In order to apply deep learning, model configuration is important, but data sets for learning and testing are also important. For the accuracy of the deep learning model, the size of the training dataset is very important because the dataset has a significant impact on accuracy. Also, the more data collected in various environments, the higher the accuracy. This consumes capital to collect a large amount of data. However, when a data set can not be collected due to a limited environment, a new data set is created through a transformation operation such as rotating or enlarging existing data. In this study, we propose a study on the effect of generation, mating, and mutation of genetic algorithms on accuracy of data inflation in the process of generating and learning data sets."
미래 기상정보를 사용하지 않는 LSTM 기반의 피크시간 태양광 발전량 예측 기법,2019,"['태양광 발전량 예측', '딥러닝', '시계열 분석', '장기-단기 기억 메모리', 'Photovoltaic Power Prediction', 'Deep Learning', 'Time Series Analysis', 'Long-short Term Memory']","최근 태양광 발전량 예측은 태양광 발전량 설비 시스템의 안정적인 작동을 위한 조정 계획, 설비 규격 결정 및 생산 계획 일정을 수립하기 위해 필수적인 요소로 고려된다. 특히, 대부분의 태양광 발전량은 피크시간에 측정되기 때문에, 태양광 시스템 운영자의 이익 최대화와 전력 계통량 안정화를 위해 피크시간의 태양광 발전량 예측은 매우 중요한 요소이다. 또한, 기존 연구들은 광범위한 지역에서 예측된 불확실한 기후 정보들을 이용하여 태양광 발전량을 예측하는 한계점 때문에 일사량, 운량, 온도 등과 기상정보 없이 피크시간의 태양광 발전량을 예측하는 것은 매우 어려운 문제로 고려된다. 따라서 본 논문에서는 피크이전의 기후, 계절 및 관측된 태양광 발전량을 이용하여 미래의 기후 및 계절 정보 없이 피크시간의 태양광 발전량을 예측할 수 있는 LSTM(Long-Shot Term Memory) 기반의 태양광 발전량 예측 기법을 제안한다. 본 연구에서 제안한 모델을 기반으로 실 데이터를 통한 실험 결과, 단기 및 장기적 관점에서 높은 성능을 보였으며, 이는 본 연구에서 목표로 한 피크시간의 태양광 발전량 예측 성능 향상에 긍정적인 영향을 나타내었음을 보여준다.","Recently, the importance prediction of photovoltaic power (PV) is considered as an essential function for scheduling adjustments, deciding on storage size, and overall planning for stable operation of PV facility systems. In particular, since most of PV power is generated in peak time, PV power prediction in a peak time is required for the PV system operators that enable to maximize revenue and sustainable electricity quantity. Moreover, Prediction of the PV power output in peak time without meteorological information such as solar radiation, cloudiness, the temperature is considered a challenging problem because it has limitations that the PV power was predicted by using predicted uncertain meteorological information in a wide range of areas in previous studies. Therefore, this paper proposes the LSTM (Long-Short Term Memory) based the PV power prediction model only using the meteorological, seasonal, and the before the obtained PV power before peak time. In this paper, the experiment results based on the proposed model using the real-world data shows the superior performance, which showed a positive impact on improving the PV power in a peak time forecast performance targeted in this study."
비정형 Security Intelligence Report의 정형 정보 자동 추출,2019,"['보안 위협', '정보 추출', '머신러닝', '딥러닝', '문서 분류', 'Threat Information', 'Information Extraction', 'Machine Learning', 'Deep Learning', 'Document Analysis']","사이버 공격을 예측하고 대응하기 위해서 수많은 보안 기업 회사에서는 공격기법의 특성, 수법 유형을 빠르게 파악하고, 이에 대한 Security Intelligence Report(SIR)들을 배포한다. 하지만 각 기업에서 배포하는 SIR들은 방대하며, 형식이 맞춰져 있지 않다. 본 논문은 대량의 비정형한 SIR들에서 정보를 추출하는데 소요되는 시간을 줄이고 효율적으로 파악하기 위해 SIR들에 대해 정형화하고 주요 정보를 추출하기 위해 5가지 분석기술이 적용된 프레임워크를 제안한다. SIR들의 데이터는 정답 라벨이 없기 때문에 비지도 학습방식을 통해 키워드 추출, 토픽 모델링, 문서 요약, 유사 문서 검색 총 4가지 분석기술을 제안한다. 마지막으로 SIR들에서 위협 정보 추출하기 위해 데이터를 구축하였으며, 개체명 인식 기술에 적용하여 IP, Domain/URL, Hash, Malware에 속하는 단어를 인식하고 그 단어가 어떤 유형에 속하는지 판단하는 분석기술을 포함한 총 5가지 분석기술이 적용된 프레임워크를 제안한다.","In order to predict and respond to cyber attacks, a number of security companies quickly identify the methods, types and characteristics of attack techniques and are publishing Security Intelligence Reports(SIRs) on them. However, the SIRs distributed by each company are huge and unstructured. In this paper, we propose a framework that uses five analytic techniques to formulate a report and extract key information in order to reduce the time required to extract information on large unstructured SIRs efficiently. Since the SIRs data do not have the correct answer label, we propose four analysis techniques, Keyword Extraction, Topic Modeling, Summarization, and Document Similarity, through Unsupervised Learning. Finally, has built the data to extract threat information from SIRs, analysis applies to the Named Entity Recognition (NER) technology to recognize the words belonging to the IP, Domain/URL, Hash, Malware and determine if the word belongs to which type We propose a framework that applies a total of five analysis techniques, including technology."
납기 위반 및 셋업 최소화를 위한 강화학습 기반의 설비 일정계획 모델,2019,"['일정계획', '강화학습', '납기', '셋업비용', '딥러닝', 'Scheduling', 'Reinforcement Learning', 'Due Date', 'Setup Cost', 'Deep Learning']","최근 제조업체들은 제품의 생산방식이 고도화 되고, 복잡해지면서 생산 장비를 효율적으로 사용하는데 어려움을 겪고 있다. 제조공정의 효율성을 방해하는 대표적인 요인들로는 작업물 종류 변경(job change)으로 인한 작업 준비 비용(Setup Cost) 등이 있다. 특히 반도체/LCD 공정과 같이 고가의 생산 장비를 사용하는 공정의 경우 장비의 효율적인 사용이 매우 중요한데, 상호 충돌하는 의사결정인 납기 준수를 최대화 하는 것과 작업물 종류 변경으로 인한 작업 준비 비용을 최소화 하는 것 사이에서 균형을 유지하는 것은 매우 어려운 일이다. 본 연구에서는 납기와 작업 준비 비용이 있는 병렬기계에서 강화학습을 활용하여 납기 및 셋업 비용의 최소화 목표를 달성하는 일정계획 모델을 개발하였다. 제안하는 모델은 DQN(Deep Q-Network) 일정계획 모델로 강화학습기반의 모델이다. 제안모델의 효율성을 측정하기 위해 DQN 모델과 기존에 개발하였던 심층 신경망 기반의 일정계획 생성기법과 휴리스틱 원칙의 결과를 비교하였다. 비교 결과 DQN 일정계획 생성기법이 심층신경망 방식과 휴리스틱 원칙에 비하여 납기 및 셋업 비용이 적은 것을 확인할 수 있었다.","Recently, manufacturers have been struggling to efficiently use production equipment as their production methods become more sophisticated and complex. Typical factors hinderingthe efficiency of the manufacturing process include setup cost due to job change. Especially, in the process of using expensive production equipment such as semiconductor / LCD process, efficient use of equipment is very important. Balancing the tradeoff between meeting the deadline and minimizing setup cost incurred by changes of work type is crucial planning task. In this study, we developed a scheduling model to achieve the goal of minimizing the duedate and setup costs by using reinforcement learning in parallel machines with duedate and work preparation costs. The proposed model is a Deep Q-Network (DQN) scheduling model and is a reinforcement learning-based model. To validate the effectiveness of our proposed model, we compared it against the heuristic model and DNN(deep neural network) based model. It was confirmed that our proposed DQN method causes less due date violation and setup costs than the benchmark methods."
인공지능 학습을 활용한 브랜드 아이덴티티의 일치도 분석,2019,"['브랜드 아이덴티티', '리테일 디자인', '딥러닝', '이미지 분류', 'Brand Identity', 'Retail Design', 'Deep Learning', 'Image Classification']",,"The aim of this study is to investigate a way of determining consistency of brand identity in store design with deep learning-based technology. The concept of brand identity has been aroused in order to set brands apart from tough competitors in global marketplace. Especially, brand space has been highlighted as a strong communicator of consistent brand identity. However, in terms of spatial environments, brand identity has been studied adopting qualitative approaches. This paper look into a way of quantifying consistency of brand identity adopting deep learning-based image classification model. Following the case of Starbucks and Bluebottle – two brands creating constant and strong brand identity attached to worldwide brand spaces – auto image classification was conducted with TensorFlow to investigate brand identity congruence. Departing from training image recognition model, 3 tests were conducted to demonstrate the train model. This paper demonstrates that a consistent, coherent, and strong brand identity attached to store design can be trained and recognized with deep learning-based technology. This research also suggests the wider usage of this model in branding and interior design."
딥러닝기반 다중 표적 인식을 활용한 모바일 로봇 경로 계획,2019,"['표적인식', '경로계획', '장애물 회피', '딥러닝', '모바일 로봇', 'Taget Detection', 'Path Planning', 'Avoidance Obstacle', 'Deep-Learning', 'Mobile Robot']","복합적인 고차원의 임무를 수행하기 위하여 미래무인화 전투 체게는 인공지능 기술을 필요로 한다. 특히 합성곱 신경망은 영상뿐만 아니라 자연어 처리까지 광범위한 범위에서 탁월한 성능을 보이고 있어 무인화 전투체계의 표적정보인식, 피아식별, 전장정보인식 등 각종 센서 융합에 매우 적합하다. 본 연구에서는 합성곱 신경망의 영상인식 기술을 활용하여 다수 대상체의 상태정보를 인식함으로써 변화되는 환경에서의 무인로봇 경로 계획 개선 방안을 제시하였고 시뮬레이션을 통하여 추정된 로봇의 위치, 장애물, 목표물 정보로부터 로봇의 경로 계획의 유효성을 검증 하였다.","Unmmanned systems are one of the essential areas of future military weapons systems that must carry out dangerous and cmplex missions. Especially, deep learning should recognize many landmarks through the image and project them onto the map to improve the problem of position estimation, because it shows excellent performance of recognizing and classifying the characteristics of image data among other artificial intelligence techniques. In this study, the path planning of the unmanned reconnaissance aircraft and the unmanned ground vehicle, which are currently being used in the ROK military, is linked with the CNN based multi target recognition algorithm without GPS. Throuth experiments, we verified the effectiveness of the path planning of the mobile robot with respect to the position of the robot, obstacle, and target point estimated by the target detection algorithm."
Korean Dependency Parsing using the Self-Attention Head Recognition Model,2019,"['의존구문분석', 'Self-Attention', '딥러닝', '자연어처리', 'dependency parsing', 'deep learning', 'natural language processing']",,
마케팅 데이터를 대상으로 중요 통계 예측 기법의 정확성에 대한 비교 연구,2019,"['Statistical Forecasting', 'R', 'Regression', 'Random Forest', 'Decision Tree', 'Support Vector Machine', '통계적 예측', 'R', '회귀', '랜덤 포레스트', '의사 결정 나무', '서포트 벡터 머신']","미래를 예측하는 기법은 통계에 기반을 둔 것과 딥러닝에 기반을 둔 기술로 분류할 수 있다. 그중 통계에 기반을 둔 것이 간단하고 정확성이 높아서 많이 사용된다. 하지만 실무자들은 많은 분석기법의 올바른 사용에 어려움이 많다. 이번 연구에서는 마케팅에 관련된 데이터에 다항로지스틱회귀, 의사결정나무, 랜덤포레스트, 서포트벡터머신, 베이지안 추론을 적용하여 예측의 정확성을 비교하였다. 동일한 마케팅 데이터를 대상으로 하였고, R을 활용하여 분석을 진행하였다. 마케팅 분야의 데이터 특성을 반영한 다양한 기법의 예측 결과가 실무자들에게 좋은 참고가 될 것으로 생각한다","Techniques for predicting the future can be categorized into statistics-based and deep-run-based techniques. Among them, based on statistics is simple and highly accurate, so it is widely used. However, working-level officials have difficulty using many analytical techniques correctly. In this study, we compared the accuracy of prediction by applying multinomial logistic regression, decision tree, random forest, support vector machine, and Bayesian inference to marketing related data. The same marketing data was used, and analysis was conducted using R. I think that the prediction results of various techniques reflecting the data characteristics of the marketing field will be a good reference for practitioners."
언간 연구의 국어사적 성과와 전망,2019,"['언간(한글편지)', '구개음화 현상', '주격조사', '딥러닝', '사회언어학', '언간의 국어사', ""Eon'gan"", 'palatalization', 'Nominative marker', 'Deep Learning', 'sociolinguistics', ""Korean language history of Eon'gan""]",,"The purpose of this study is to review the accomplishments of Eon'gan study in the Korean Language History based on Eon'gan data of Joseon Dynasty and to predict future studies. The main reasons of gathering interest in Eon'gan data are the excavation of family letters such as <Suncheo'ngimss'iEongan> and <Jinjuhass'iEongan> and the publication of translated books of Eon'gan. Furthermore, the interpretation book of Eon'gan has played a key role in enhancing the reliability of Eon'gan data. Regarding writing and phonographical matters, palatalization and liquid consonant along with ‘ㆍ’, ‘ㅸ’ and ‘ㅿ’ were main interest. The most active discussion among them is the phenomenon of palatalization, and it is noticeable that not only was the practice of palatalization discussed but also the change by various factors of sociolinguistics was discussed. The grammar part is the most actively discussed among Eon'gan studies. Especially, such matters as nominative marker and relative honorific expressions can be considered as the most meaningful accomplishments in Eon'gan data. In addition, there is active discussion on pronouns, individual ending words and individual morpheme. Studies on vocabulary based on Eon'gan data show high interest in Eon'gan's own vocabularies that do not appear in printed books. Recently, names of articles, disease related words, unit nouns and names of places are also objects of main interest. Meanwhile, the number of Eon'gan data introduced to the academic world is 3,296, and there is a need for expansion of Eon'gan data through deep learning. There should be active sociolinguistic discussion that can highlight the strengths of Eon'gan data while the necessity of computational linguistics for establishment of corpus is discussed. The difference between males and females can be a future research subject. It is necessary to elaboratize the details of the existing Korean language history through Eon'gan data, along with the description of tentatively named ""Korean language history of Eon'gan'."
뉴럴 네트워크의 최적화에 따른 유사태풍 예측에 관한 연구,2019,"['Artificial intelligence 인공지능', 'Deep learning 딥러닝', 'Big data 빅데이터', 'Activation function\u3000활성화\u3000함수', 'Disaster prevention system 방재 시스템']",,"Artificial intelligence (AI)-aided research currently enjoys active use in a wide array of fields thanks to the rapid development of computing capability and the use of Big Data. Until now, forecasting methods were primarily based on physics models and statistical studies. Today, AI is utilized in disaster prevention forecasts by studying the relationships between physical factors and their characteristics. Current studies also involve combining AI and physics models to supplement the strengths and weaknesses of each aspect. However, prior to these studies, an optimization algorithm for the AI model should be developed and its applicability should be studied. This study aimed to improve the forecast performance by constructing a model for neural network optimization. An artificial neural network (ANN) followed the ever-changing path of a typhoon to produce similar typhoon predictions, while the optimization achieved by the neural network algorithm was examined by evaluating the activation function, hidden layer composition, and dropouts. A learning and test dataset was constructed from the available digital data of one typhoon that affected Korea throughout the record period (1951–2018). As a result of neural network optimization, assessments showed a higher degree of forecast accuracy."
텐서플로우를 활용한 GPU 환경에서 정적 악성코드 탐지 기법,2019,"['악성코드 분석', '악성코드 탐지', '정적 분석', '딥러닝', 'Malware Analysis', 'Malware Detection', 'Static Analysis', 'Deep Learning']","최근, 개인용 PC 및 다양한 모바일 디바이스에 보안 패치의 취약점을 통해 신종 및 변종 악성코드의 감염이 빠르게 확산되어 개인 정보 유출, 공인 인증서 탈취, 암호화폐 채굴 등의 다양한 피해가 급증되고 있다. 이를 위해 악성코드 시그니처 기반 악성코드 탐지 기법을 이용하고 있지만, 빠르게 생성되는 신·변종 악성코드를 탐지의 정확도가 현저히 낮다. 본 연구에서는 LSTM를 이용하여 알려진 악성코드뿐만 아니라 신·변종 악성코드들을 탐지하는 스킴을 제안한다.",
RNN을 이용한 제2형 당뇨병 예측모델 개발,2019,"['제2형 당뇨병', '질병 예측', '기계 학습', '딥러닝', 'RNN', '의료 인공지능', 'T2DM', 'Disease Prediction', 'Machine Learning', 'Deep Learning', 'RNN', 'Medical AI']","제2형 당뇨병은 고혈당이 특징인 대사성 분비 장애로 여러 합병증을 야기하는 질병이며, 장기적인 치료가 필요하기 때문에 매년 많은 의료비를 지출한다. 이를 해결하기 위해 많은 연구들이 있어왔지만, 기존의 연구들은 한 시점에서의 데이터를 학습시켜 예측함으로써 정확도가 높지 않았다. 그래서 본 연구는 제2형 당뇨병 발생 예측에 대한 정확도를 높이기 위하여 RNN을 이용한 모델을 제안하였다. 본 모델을 개발하기 위해 한국인유전체역학조사 지역사회 코호트(안산·안성) 데이터를 이용하였으며, 시간의 흐름에 따른 데이터들을 모두 학습시켜 당뇨병 발생 예측모델을 만들었다. 예측 모델의 성능을 검증하기 위해 기존의 기계 학습 방법인 LR, k-NN, SVM과 정확도를 비교하였다. 비교한 결과 제안한 예측모델의 accuracy는 0.92, AUC는 0.92로 다른 기계 학습 방법보다 높은 정확도를 보였다. 따라서 본 연구에서 제안한 제2형 당뇨병 발생 예측 모델을 활용하여 발병을 조기 예측함으로써 생활습관 개선 및 혈당조절을 통해 당뇨병 발병을 예방하고 늦출 수 있을 것이다.","Type 2 diabetes mellitus(T2DM) is included in metabolic disorders characterized by hyperglycemia, which causes many complications, and requires long-term treatment resulting in massive medical expenses each year. There have been many studies to solve this problem, but the existing studies have not been accurate by learning and predicting the data at specific time point. Thus, this study proposed a model using RNN to increase the accuracy of prediction of T2DM. This work propose a T2DM prediction model based on Korean Genome and Epidemiology study(Ansan, Anseong Korea). We trained all of the data over time to create prediction model of diabetes. To verify the results of the prediction model, we compared the accuracy with the existing machine learning methods, LR, k-NN, and SVM. Proposed prediction model accuracy was 0.92 and the AUC was 0.92, which were higher than the other. Therefore predicting the onset of T2DM by using the proposed diabetes prediction model in this study, it could lead to healthier lifestyle and hyperglycemic control resulting in lower risk of diabetes by alerted diabetes occurrence."
국방용 합성이미지 데이터셋 생성을 위한대립훈련신경망 기술 적용 연구,2019,"['Generative Adversarial Networks(대립훈련신경망)', 'Synthetic Image(합성이미지)', 'Deep Learning(딥러닝)', 'Machine Learning(머신러닝)', 'Dataset(데이터셋)']",,"Generative adversarial networks(GANs) have received great attention in the machine learning field for their capacity to model high-dimensional and complex data distribution implicitly and generate new data samples from the model distribution. This paper investigates the model training methodology, architecture, and various applications of generative adversarial networks. Experimental evaluation is also conducted for generating synthetic image dataset for defense using two types of GANs. The first one is for military image generation utilizing the deep convolutional generative adversarial networks(DCGAN). The other is for visible-to-infrared image translation utilizing the cycle-consistent generative adversarial networks(CycleGAN). Each model can yield a great diversity of high-fidelity synthetic images compared to training ones. This result opens up the possibility of using inexpensive synthetic images for training neural networks while avoiding the enormous expense of collecting large amounts of hand-annotated real dataset."
이미지 정보를 이용한 영어-한국어 자동 번역,2019,"['machine translation', 'multimodal', 'deep learning', 'image information', 'decoding gate', '기계 번역', '멀티모달', '딥러닝', '이미지 정보', '디코딩 게이트']","기계 번역 연구는 하나의 언어로 된 텍스트를 다른 언어로 자동 변환하는 기술이다. 기존의 기계 번역 연구는 번역을 위해 오직 텍스트 데이터만 사용하였다. 따라서 기존 기계 번역 연구는 입력 텍스트와 관련된 다양한 정보들을 활용할 수 없다는 단점이 있다. 최근에는 텍스트 데이터만 사용하는 기존 기계 번역과 달리 입력 텍스트와 관련된 이미지 정보를 기계 번역 시스템의 추가 입력으로 사용하는 멀티모달 기계 번역 모델이 등장했다. 본 연구에서는 최근 연구 동향에 맞추어 기계 번역의 디코딩 타임에 이미지 정보를 추가하고 이를 영어-한국어 자동 번역에 적용한다. 또한 디코딩 타임에 텍스트 정보와 이미지 정보를 적절히 조절하기 위한 별도의 게이트를 적용한 모델을 제안하고, 실험을 통해 게이트를 적용하지 않은 모델보다 더 좋은 성능을 나타냄을 보인다.","Machine translation automatically converts a text in one language into another language.Conventional machine translations use only texts for translation which is a disadvantage in that various information related to input text cannot be utilized. In recent years, multimodal machine translation models have emerged that use images related to input text as additional inputs, unlike conventional machine translations which use only textual data. In this paper, image information was added at decoding time of machine translation according to recent research trends and used for English-to-Korean automated translation. In addition, we propose a model with a decoding gate to adjust the textual and image information at the decoding time. Our experimental results show that the proposed method resulted in better performance than the non-gated model."
인공지능 기반 MNIST 손글씨 인식에 대한 연구,2019,"['Handwriting', 'SLR', 'ANN', 'CNN', 'Deep learning', '손글씨', '소프트맥스 회귀분석', '인공신경망', '합성곱신경망', '딥러닝']",,"In the development of electronic devices such as PDAs, smartphones, and tablets, research on handwriting recognition has emerged. In the meantime, there have been efforts to recognize various handwriting such as numbers, Japanese, and English. However, there is a point that it is difficult to recognize when the font shape is relatively irregular, such as handwriting of children. As a result, the need for research to improve handwriting recognition rate by applying deep learning techniques has recently been raised. Therefore, this study attempted to improve handwriting recognition rate based on various deep learning techniques. In the case of handwriting, it is difficult to prepare a variety of data sets, which limits the recognition rate. In this study, we tried to improve the accuracy of handwriting recognition by using CNN technique in order to find a way to overcome these limitations. The techniques used were SLR, ANN, and CNN, each measuring the accuracy of each method. As a result, CNN showed the highest performance of 95%."
LSTM을 활용한 불법주정차 시공간 예측 모델링: 서울시 민원신고 데이터를 중심으로,2019,"['Long Short-Term Memory(LSTM)', '불법주정차', '민원신고', '예측', '딥러닝', 'Long Short-Term Memory(LSTM)', 'Illegal Parking Cases', 'Civil Complaints', 'Prediction', 'Deep Learning']","본 연구의 목적은 서울시 내에서 발생한 불법주정차 민원신고 데이터를 활용하여 불법주정차 발생의 시공간 예측모델을 구축하는 것이다. 예측모델은 최근 시계열 예측 분야에서 높은 성능을 보이고 있는 long short-term memory (LSTM)을 활용하여 생성하였다. LSTM을 활용한 시계열 예측 시에는 시간단위 설정이 중요하기 때문에 기존 연구에서의 예측모델은 시간단위를 어떻게 설정할 것인가에 집중하고 있다. 본 연구에서는 시간단위 뿐 아니라 공간단위 설정에 따른 문제점을 분석하고, 실험을 통해 최적의 예측 공간단위를 찾고자 하였다. 이를 위해 예측의 시간단위는 월별 24시간을 기준으로 하고, 공간단위는 자치구, 토지이용유형, 도로 및 도로 외, 그리고 토지이용유형별 도로와 도로가 아닌 지역으로 구분한 공간 단위별로 분석을 수행하였다. 그 결과 토지이용유형, 도로 및 도로 외로 공간단위를 구분하였을 때 예측모델들이 전반적으로 좋은 성능을 보였으며, 자치구로 구분하였을 때 좋지 않은 성능을 보이는 것을 확인하였다.","This study aims to predict the number of illegal parking using data on complaints of illegal parking within Seoul. We made the prediction models using long short-term memory(LSTM) which has shown high performance in the field of the series prediction recently. Because setting the time unit is important for time series prediction, prediction models in the previous researches include consideration of how to set the time unit. In this study, the prediction models were made with consideration of not only time unit but also space unit. The time unit of prediction was set up for 24 hours per month, and the space unit was designated as district ‘gu’, land-use type, and road and off the road. As a result, it was confirmed that the prediction models performed well overall when dividing the spatial units by land-use type and road and off the road, and that the prediction models performed poorly when divided into district ‘gu’."
지식베이스 구축을 위한 한국어 위키피디아의 학습 기반 지식추출 방법론 및 플랫폼 연구,2019,"['Deep learning', 'Artificial Intelligence', 'Ontology', 'Knowledge base', 'Knowledge extraction', '딥러닝', '온톨로지', '인공지능', '지식베이스', '지식추출']","최근 4차 산업혁명과 함께 인공지능 기술에 대한 연구가 활발히 진행되고 있으며, 이전의 그 어느 때보다도기술의 발전이 빠르게 진행되고 있는 추세이다. 이러한 인공지능 환경에서 양질의 지식베이스는 인공지능 기술의 향상 및 사용자 경험을 높이기 위한 기반 기술로써 중요한 역할을 하고 있다. 특히 최근에는 인공지능 스피커를 통한 질의응답과 같은 서비스의 기반 지식으로 활용되고 있다. 하지만 지식베이스를 구축하는 것은 사람의 많은 노력을 요하며, 이로 인해 지식을 구축하는데 많은 시간과 비용이 소모된다. 이러한 문제를 해결하기위해 본 연구에서는 기계학습을 이용하여 지식베이스의 구조에 따라 학습을 수행하고, 이를 통해 자연어 문서로부터 지식을 추출하여 지식화하는 방법에 대해 제안하고자 한다. 이러한 방법의 적절성을 보이기 위해DBpedia 온톨로지의 구조를 기반으로 학습을 수행하여 지식을 구축할 것이다. 즉, DBpedia의 온톨로지 구조에따라 위키피디아 문서에 기술되어 있는 인포박스를 이용하여 학습을 수행하고 이를 바탕으로 자연어 텍스트로부터 지식을 추출하여 온톨로지화하기 위한 방법론을 제안하고자 한다. 학습을 바탕으로 지식을 추출하기 위한과정은 문서 분류, 적합 문장 분류, 그리고 지식 추출 및 지식베이스 변환의 과정으로 이루어진다. 이와 같은방법론에 따라 실제 지식 추출을 위한 플랫폼을 구축하였으며, 실험을 통해 본 연구에서 제안하고자 하는 방법론이 지식을 확장하는데 있어 유용하게 활용될 수 있음을 증명하였다. 이러한 방법을 통해 구축된 지식은 향후지식베이스를 기반으로 한 인공지능을 위해 활용될 수 있을 것으로 판단된다.","Development of technologies in artificial intelligence has been rapidly increasing with the Fourth Industrial Revolution, and researches related to AI have been actively conducted in a variety of fields such as autonomous vehicles, natural language processing, and robotics. These researches have been focused on solving cognitive problems such as learning and problem solving related to human intelligence from the 1950s. The field of artificial intelligence has achieved more technological advance than ever, due to recent interest in technology and research on various algorithms. The knowledge-based system is a sub-domain of artificial intelligence, and it aims to enable artificial intelligence agents to make decisions by using machine-readable and processible knowledge constructed from complex and informal human knowledge and rules in various fields. A knowledge base is used to optimize information collection, organization, and retrieval, and recently it is used with statistical artificial intelligence such as machine learning. Recently, the purpose of the knowledge base is to express, publish, and share knowledge on the web by describing and connecting web resources such as pages and data. These knowledge bases are used for intelligent processing in various fields of artificial intelligence such as question answering system of the smart speaker.However, building a useful knowledge base is a time-consuming task and still requires a lot of effort of the experts. In recent years, many kinds of research and technologies of knowledge based artificial intelligence use DBpedia that is one of the biggest knowledge base aiming to extract structured content from the various information of Wikipedia. DBpedia contains various information extracted from Wikipedia such as a title, categories, and links, but the most useful knowledge is from infobox of Wikipedia that presents a summary of some unifying aspect created by users. These knowledge are created by the mapping rule between infobox structures and DBpedia ontology schema defined in DBpedia Extraction Framework. In this way, DBpedia can expect high reliability in terms of accuracy of knowledge by using the method of generating knowledge from semi-structured infobox data created by users. However, since only about 50% of all wiki pages contain infobox in Korean Wikipedia, DBpedia has limitations in term of knowledge scalability. This paper proposes a method to extract knowledge from text documents according to the ontology schema using machine learning. In order to demonstrate the appropriateness of this method, we explain a knowledge extraction model according to the DBpedia ontology schema by learning Wikipedia infoboxes. Our knowledge extraction model consists of three steps, document classification as ontology classes, proper sentence classification to extract triples, and value selection and transformation into RDF triple structure. The structure of Wikipedia infobox are defined as infobox templates that provide standardized information across related articles, and DBpedia ontology schema can be mapped these infobox templates. Based on these mapping relations, we classify the input document according to infobox categories which means ontology classes. After determining the classification of the input document, we classify the appropriate sentence according to attributes belonging to the classification. Finally, we extract knowledge from sentences that are classified as appropriate, and we convert knowledge into a form of triples. In order to train models, we generated training data set from Wikipedia dump using a method to add BIO tags to sentences, so we trained about 200 classes and about 2,500 relations for extracting knowledge. Furthermore, we evaluated comparative experiments of CRF and Bi-LSTM-CRF for the knowledge extraction process. Through this proposed process, it is possible to utilize structured knowledge by extracting knowledge according to the ontology schema fro..."
랜섬웨어 방어를 위한 합성곱 신경망 기반의 데이터 암호화 탐지 기법,2019,"['ransomware', 'deep learning', 'convolutional neural network', 'computer security', '랜섬웨어', '딥러닝', '합성곱 신경망', '컴퓨터 보안']","최근 랜섬웨어에 의한 피해가 심각해짐에 따라, 랜섬웨어 공격을 실시간으로 감지하고 방어하는 기술 개발의 중요성이 높아지고 있다. 기존 랜섬웨어 탐지 기법의 한계를 극복하기 위해, 저장장치 내부 수준의 데이터 보존 및 복구 기법이 제안되었으나, 무분별한 데이터 보존으로 인해 저장공간 부하를 크게 증가시킬 수 있다는 한계점이 존재한다. 본 논문에서는 보존할 데이터를 정확하게 선정하면서도 피해 데이터를 온전하게 보존하기 위한, 합성곱 신경망 기반의 데이터 암호화 여부 판단 기법을 제시한다. 실험 결과, 제안한 기법은 저장장치 내부 수준에서 상위 계층의 정보 없이 93.90%의 높은 정확도로 데이터의 암호화 여부를 판단하였다. 또한, 손실 함수와 결정 경곗값을 수정하여 0에 가까운 부정 오류율을 달성하였다.","With the rapid increase in the number of ransomwares recently, the development of real-time strategies for ransomware defense is imperative. To overcome the limitations of traditional ransomware defense techniques, a storage-level data recovery technique was suggested. However, as the technique inefficiently selects data to conserve, it has a negative impact on the lifetime and performance of storage. In this paper, we propose a CNN-based encrypted data detection technique to enhance the accuracy of selecting data to conserve while ensuring complete data recovery. Our experiments show that the proposed technique achieved 93.90% detection accuracy at the storage-level without any high-level information. Furthermore, by changing the loss function and controlling a detection threshold, we attained a false negative rate of nearly 0."
교통 데이터 수집을 위한 객체 인식 통합 프레임워크 개발,2019,"['Deep Learning', 'Direct Object Detection', 'Multi Objects Tracking', 'Computer Vision', '딥러닝', '직접 객체 인식', '영상 기반 객체 추적', '컴퓨터 시각화 기술']","본 연구에서는 다양한 외부 조건 하에서 촬영된 영상을 대상으로 신속하고 정확하게 교통객체를 검출하는 교통 객체 검출 통합 프레임워크를 개발하였다. 제안된 프레임워크는 딥러닝기술 기반의 직접 객체 인식 기술과 다중 객체 추적 기술, 그리고 동영상 전처리 기술로 구성되며, 영상의 안정성, 기상, 촬영 각도 등의 다양한 외부 조건에서 촬영된 영상을 대상으로 승용차, 버스, 트럭, 및 미니밴과 같은 교통 객체를 인식하고, 이를 실시간으로 추적하여 교통량데이터를 계수한다. 제안된 방법의 성능 검증을 위해 다양한 외부 조건에서 촬영된 영상 8개를대상으로 제안된 방법의 성능 검증을 수행한 결과, 우천 및 강설을 제외한 모든 조건에서 98% 이상의 높은 정확도를 보이는 것으로 나타났다.","A fast and accurate integrated traffic object detection framework was proposed and developed, harnessing a computer-vision based deep-learning approach performing automatic object detections, a multi object tracking technology, and video pre-processing tools. The proposed method is capable of detecting traffic object such as autos, buses, trucks and vans from video recordings taken under a various kinds of external conditions such as stability of video, weather conditions, video angles, and counting the objects by tracking them on a real-time basis. By creating plausible experimental scenarios dealing with various conditions that likely affect video quality, it is discovered that the proposed method achieves outstanding performances except for the cases of rain and snow, thereby resulting in 98% ~ 100% of accuracy."
Faster R-CNN을 활용한 GPR 영상에서의 지하배관 위치추적 성능분석,2019,"['지하 배관', 'Faster R-CNN', '지표 투과 레이더', '딥러닝', 'VGGnet', '어그멘테이션', 'Buried pipelines', 'Faster R-CNN', 'GPR', 'Deep learning', 'VGGnet', 'Augmentation']",,
사용자 인식을 위한 가상 심전도 신호 생성 기술에 관한 연구,2019,"['deep learning', 'auxiliary classifier', 'generative adversarial networks', 'electrocardiogram', '딥러닝', '보조 분류기', '적대적 생성 신경망', '심전도 신호']","심전도 신호는 시간 및 환경 변화에 따라 측정되는 시계열 데이터로 매번 등록 데이터와 동일한 크기의 비교 데이터를 취득해야 하는 문제점이 발생한다. 본 논문에서는 신호 크기 부적합 문제를 해결하기 위해 가상 생체신호 생성을 위한 보조 분류기 기반 적대적 생성 신경망(Auxiliary Classifier Generative Adversarial Networks)의 네트워크 모델을 제안한다. 생성된 가상 생체신호의 유사성을 확인하기 위해 코사인 각도와 교차 상관관계를 이용하였다. 실험 결과, 코사인 유사도 측정 결과로 평균 유사도는 0.991의 결과를 나타냈으며, 교차 상관관계를 이용한 유클리디언 거리 기반 유사성 측정 결과는 평균 0.25 유사도 결과를 나타냈다. 이는 등록 데이터와 실험 데이터간의 크기가 일치하지 않더라도 가상 생체신호 생성을 통해 신호 크기 부적합 문제를 해결함을 확인하였다.","Because the ECG signals are time-series data acquired as time elapses, it is important to obtain comparative data the same in size as the enrolled data every time. This paper suggests a network model of GAN (Generative Adversarial Networks) based on an auxiliary classifier to generate synthetic ECG signals which may address the different data size issues. The Cosine similarity and Cross-correlation are used to examine the similarity of synthetic ECG signals. The analysis shows that the Average Cosine similarity was 0.991 and the Average Euclidean distance similarity based on cross-correlation was 0.25: such results indicate that data size difference issue can be resolved while the generated synthetic ECG signals, similar to real ECG signals, can create synthetic data even when the registered data are not the same as the comparative data in size."
"CNN의 컨볼루션 레이어, 커널과 정확도의 연관관계 분석",2019,"['Deep Learning', 'Convolution Neural Network', 'Kernel', 'Layer', 'Accuracy', 'Learning Time', '딥러닝', 'CNN', '커널', '레이어', '정확도', '학습 시간']","본 논문에서는 CNN의 컨볼루션 레이어 개수 및 커널의 크기와 개수가 CNN에 어떠한 영향을 끼치는지 실험을 통해 알아보기 위해 진행하였다. 또한 분석을 위해 일반적인 CNN도 실험하여 실험에 사용된 CNN과 비교하 였다. 분석에 사용될 신경망들은 CNN을 기반으로 하며 각각의 실험모델들은 레이어 개수, 커널의 크기 및 개수를 일정한 값으로 고정해 실험을 진행하였다. 모든 실험에는 2계층의 완전연결계층을 고정으로 사용하였다. 다른 변수들은 모두 동일한 값을 주어 실험하였다. 분석결과 레이어의 수가 작을 경우 커널의 크기 및 개수와 상관없이 데이터의 분산 값이 작아 견고한 정확도를 보여주었다. 레이어의 수가 커질수록 정확도도 증가됐으나 일정 수치 이상부턴 오히려 정확도가 내려갔으며 분산 값도 커져 정확도 편차가 크게 나타났다. 커널의 개수는 다른 변수보다 학습속도에 큰 영향을 끼쳤다.","In this paper, we experimented to find out how the number of convolution layers, the size, and the number of kernels affect the CNN. In addition, the general CNN was also tested for analysis and compared with the CNN used in the experiment. The neural networks used for the analysis are based on CNN, and each experimental model is experimented with the number of layers, the size, and the number of kernels at a constant value. All experiments were conducted using two layers of fully connected layers as a fixed. All other variables were tested with the same value. As the result of the analysis, when the number of layers is small, the data variance value is small regardless of the size and number of kernels, showing a solid accuracy. As the number of layers increases, the accuracy increases, but from above a certain number, the accuracy decreases, and the variance value also increases, resulting in a large accuracy deviation. The number of kernels had a greater effect on learning speed than other variables."
LSTM을 이용한 재밍 기법 예측,2019,"['Jamming(재밍)', 'Radar Signal(레이다 신호)', 'Deep Learning(딥러닝)', 'LSTM(장단기 기억 구조)']",,"Conventional methods for selecting jamming techniques in electronic warfare are based on libraries in which a list of jamming techniques for radar signals is recorded. However, the choice of jamming techniques by the library is limited when modified signals are received. In this paper, we propose a method to predict the jamming technique for radar signals by using deep learning methods. Long short-term memory(LSTM) is a deep running method which is effective for learning the time dependent relationship in sequential data. In order to determine the optimal LSTM model structure for jamming technique prediction, we test the learning parameter values that should be selected, such as the number of LSTM layers, the number of fully-connected layers, optimization methods, the size of the mini batch, and dropout ratio. Experimental results demonstrate the competent performance of the LSTM model in predicting the jamming technique for radar signals."
홈 IoT 환경에서의 CNN-DNN 기반 음향인지 알고리즘,2019,"['Deep learning', 'sound event detection', 'log mel filter bank', '딥러닝', '음향인지', 'log mel filter bank']",,"In this study, we proposed a CNN-DNN based sound event detection in home IoT environments. To reduce the impact of input volume variation, we applied peak normalization, and extracted acoustic feature named Log mel filter bank. Log-mel filter bank is very popular acoustic feature based on mel filter which is powerful for speech recognition and sound event detection. Then, we used CNN-DNN model for classification. CNN outputs of sequential 32 frames were used as DNN input for considering time-series characteristic of the sound. Data were collected in real apartment environment. We used 13 sounds as target such as doorbell, babycry, vacuum, and so on. We evaluated our method using computer simulation, as a result, the accuracy of the proposed sound event detection algorithm was 90.76%."
멀티 스케일 퓨전 네트워크를 활용한 문서영상 이진화,2019,"['binarization', 'document image', 'multi-scale fusion network', 'deep learning', '이진화', '문서 영상', '다중 스케일 퓨전 네트워크', '딥러닝']","화질이 저하된 문서 이미지의 이진화는 문서 이미지 분석에 중대한 영향을 미친다. 본 논문에서는 다중 스케일 구조를 갖는 LadderNet을 이용하여 저하된 문서 이미지의 기능을 학습하고 노이즈 픽셀로부터 텍스트 및 배경 픽셀을 분류하는 방법을 제시한다. 본 논문에서는 적절히 수정된 형태의 두 가지 LadderNet 아키텍처를 고려한다. 하나는 더 깊은 네트워크 구조이고 다른 하나는 더 얕은 네트워크 구조이며, 각 구조는 문서 이미지 패치를 사용하여 독립적으로 학습된다. 더 작은 크기의 윈도우로 더 깊은 아키텍처에서 생성된 예측 출력에는 텍스트 획이 더 명확하지만 많은 노이즈가 존재한다. 반면에, 더 큰 크기의 윈도우를 갖는 더 얕은 아키텍처로부터는 배경에서 더 낮은 노이즈가 생성된다. 본 논문에서는 이 두 가지 네트워크의 출력을 결합하여 더 나은 결과를 생성한다. 문서 이미지 이진화를 위한 벤치 마크 DIBCO 데이터 세트를 이용한 실험결과, 기존 방법보다 우수한 성능을 보임이 확인되었다.","Binarization of degraded document images has a significant impact on document image analysis domains. We developed a LadderNet with multi-scale architecture to learn features from degraded document images to classify text and background from noise pixels. Then, binarized images are generated from this classification. Specifically, we consider two properly designed LadderNet architectures: One with deeper architecture, another with shallower architecture. Each structure is calibrated independently using document image patches. A predicted output generated from the deeper architecture with smaller size of the striding window has clearer text-strokes but contains marked noise. Conversely, a predicted output has lower noise in the background from the shallower architecture with larger size of the striding window. However, the detail of the text is not clear. Thus, a better result is achieved by combining the outputs of two of these architectures. We tested the proposed model on benchmark DIBCO datasets for document image binarization and achieved superior performance over existing methods in the literature."
업무 자동화를 위한 RPA 융합 기술 고찰,2019,"['Artificial intelligence', 'Robotic process automation', 'Deep learning', 'Convergence', 'The fourth industrial revolution', '인공지능', '사무자동화', '딥러닝', '융합', '4차산업']","최근 4차 산업혁명 시대 흐름에 발맞추어 인공지능을 이용한 자동화 기술을 다양한 산업현장에 적용하는 사례가 증가하고 있다. 특히, 정부의 주 52시간 근무제 도입으로 기업들은 인력 운영의 어려움이 가중되고 있어, 효율적인 인력 운영을 위해 사무환경 자동화를 위한 RPA(Robotic Process Automation)에 관심을 두고 은행, 보험, 카드사 등에서 Back-Office 업무 위주로 도입하고 있다. 이러한 RPA 솔루션은 인공지능 기반 인식기술, Script 작성 기술, 업무 소프트웨어와 API(Application Process Interface) 연계 기술 등이 요구되며, Automate One, Automation Anywhere, UiPath, Blue Prism 등과 같은 다양한 솔루션들이 제공되고 있다. 본 논문에서는 기에 수작업으로 수행하던 업무를 대신 할 수 있는 RPA 솔루션의 요소 기술, 시장 동향, RPA 도입 효율성에 대해 분석하고 이를 서술하였다.","Recently, In line with the recent trend of the fourth industrial revolution, many companies and institutions have been increasingly applying automated technologies using artificial intelligence to various tasks. Particularly, due to the government's 52-hour workweek system, companies are increasingly struggling with manpower management. Therefore, they are interested in RPA (Robotic Process Automation) for office environment automation for efficient manpower management. It is being introduced in the back-office business in credit card companies, bank, insurance. These RPA solutions require AI-based recognition technology, scripting technology, business software API-related technologies, and various solutions such as Automate One, Automation Anywhere, UiPath, and Blue Prism are provided. This paper analyzes and describes the technology of RPA solution, the market trend, and the efficiency of RPA adoption."
Deep Learning 기반 공동주택 마감공사 단위작업별 생산성 예측모델 개발 - 내장공사를 중심으로 -,2019,"['Productivity', 'Prediction Model', 'Productivity Impacting Factors', 'Deep Learning', 'Interior Finishes', '생산성', '예측모델', '생산성 영향요인', '딥러닝', '마감공사']",,"Despite the importance and function of productivity information, in the Korean construction industry, the method of collecting and analyzing productivity data has not been organized. Also, in most cases, productivity management is reliant on the experience and intuitions of field managers, and productivity data are rarely being utilized in planning and management. Accordingly, this study intends to develop a prediction model for interior finishes of apartment using deep learning techniques, so as to provide a foundation for analyzing the productivity impacting factors and predicting productivity. The result of the study, productivity prediction model for interior finishes of apartment using deep learning techniques, can be a basic module of apartment project management system by applying deep learning to reliable productivity data and developing as data is accumulated in the future. It can also be used in project engineering processes such as estimating work, calculating work days for process planning, and calculating input labor based on productivity data from similar projects in the past. Further, when productivity diverging from predicted productivity is discovered during construction, it is expected that it will be possible to analyze the cause(s) thereof and implement prompt response and preventive measures."
가상현실 기반의 인공지능 영어회화 시스템,2019,"['Speech Recognition', 'Artificial Intelligence', 'Virtual Reality', 'Deep Learning', 'Voice Recognition Interface', '4th Industrial Revolution', '음성인식', '인공지능', '가상현실', '딥러닝', '음성인식 인터페이스', '4차산업혁명']","외국어 교육을 실현하기 위하여 기존의 다양한 교육 매체들이 제공되고 있지만, 교구 및 매체프로그램에 대한 비용이 많이 들고 실시간 대응력이 떨어지는 단점이 존재한다. 이 논문에서는 VR과 음성인식을 기반으로 한 인공지능 유형의 영어회화 시스템을 제안한다. 시스템 구축을 위해 Google CardBoard VR과 Google Speech API를 이용하며 가상현실 환경 제공 및 대화를 위한 인공지능 알고리즘을 개발하였다. 제안하는 음성인식 서버시스템에서는 사용자가 발화한 문장을 단어 단위로 분리해 데이터베이스에 저장된 데이터 단어들과 비교하여 확률적으로 가장 높은 것을 답으로 제공할 수 있으며 사용자들이 가상현실의 인물과 적절한 대화 및 응답이 가능하다. 대화가 제공되는 기능은 상황별 대화와 주제에 독립적이며, AI 비서와 나눈 대화 내용을 사용자 시스템에서 실시간 확인이 가능하도록 구현하였고 실험을 통하여 음성인식에 대한 응답비율을 확인하였다. 이 논문에서 제안하는 가상현실과 음성인식 기능을 접목한 시스템을 통하여 4차 산업혁명에 관련한 가상교육 콘텐츠 서비스 확장에 이바지할 것을 기대한다.","In order to realize foreign language education, various existing educational media have been provided, but there are disadvantages in that the cost of the parish and the media program is high and the real-time responsiveness is poor. In this paper, we propose an artificial intelligence English conversation system based on VR and speech recognition. We used Google CardBoard VR and Google Speech API to build the system and developed artificial intelligence algorithms for providing virtual reality environment and talking. In the proposed speech recognition server system, the sentences spoken by the user can be divided into word units and compared with the data words stored in the database to provide the highest probability. Users can communicate with and respond to people in virtual reality. The function provided by the conversation is independent of the contextual conversations and themes, and the conversations with the AI assistant are implemented in real time so that the user system can be checked in real time.  It is expected to contribute to the expansion of virtual education contents service related to the Fourth Industrial Revolution through the system combining the virtual reality and the voice recognition function proposed in this paper."
Deep Learning Based Tree Recognition rate improving Method for Elementary and Middle School Learning,2019,"['Machine Learning', 'Deep Learning', 'Convolutional Neural Network', 'CNN', 'Inception V3', 'Smart Device Education', '머신러닝', '딥러닝', '컨볼루션 신경망', '인셉션V3', '스마트기기교육']","본 연구의 목적은 수업 시 스마트기기에 적용할 수 있는 나무 이미지를 인식하고 분류하여 정확도를 측정할 수 있는 효율적인 모델을 제안하는 것이다. 2015개정 교육과정으로 개정되면서 초등학교 4학년 과학교과서의 학습 목표에서 스마트 기기 사용한 식물 인식이 새롭게 추가 되었다. 특히 나무 인식의 경우 다른 사물 인식과 달리 수형, 수피, 잎, 꽃, 열매의 부위별 특징이 있으며, 계절에 따라 모양 및 색깔의 변화를 거치므로 인식률에 차이가 존재한다. 그러므로 본 연구를 통해 컨볼루션 신경망 기반의 사전 학습된 인셉션V3모델을 이용하여 재학습 전 후의 나무 부위별 인식률을 비교한다. 또한 각 나무의 유형별 이미지 정확도를 결합시키는 방식을 통해 효율적인 나무 분류 방안을 제시하며 교육현장에서 사용하는 스마트기기에 적용 할 수 있을 것이라 기대한다.","The goal of this study is to propose an efficient model for recognizing and classifying tree images to measure the accuracy that can be applied to smart devices during class. From the 2009 revised textbook to the 2015 revised textbook, the learning objective to the fourth-grade science textbook of elementary schools was added to the plant recognition utilizing smart devices. In this study, we compared the recognition rates of trees before and after retraining using a pre-trained inception V3 model, which is the support of the Google Inception V3. In terms of tree recognition, it can distinguish several features, including shapes, bark, leaves, flowers, and fruits that may lead to the recognition rate. Furthermore, if all the leaves of trees may fall during winter, it may challenge to identify the type of tree, as only the bark of the tree will remain some leaves. Therefore, the effective tree classification model is presented through the combination of the images by tree type and the method of combining the model for the accuracy of each tree type. I hope that this model will apply to smart devices used in educational settings."
k-최근접 이웃 알고리즘을 이용한 입찰가격예측,2019,"['Electronic Bidding', 'Python', 'KNN', 'Deep Learning', 'Prediction f oBidding', '전자 입찰', '파이썬', 'KNN', '딥러닝', '입찰 예측']","우리나라는 입찰에서 전자입찰을 기본으로 사용하고 있다. 전자입찰은 발주처에 직접 찾아가서 입찰 서류를 제출해야했던 번거로움을 간소화하고, 조달업체와 공공기관에 대면접촉에 의한 부정입찰을 방지할 수 있다는 장점이 있다. 그러나전자입찰에서 입찰 가격을 예측하는 것은 쉬운 일이 아니다. 본 논문은 전자입찰에 적용할 수 있는 파이썬을 이용해머신러닝을 적용한 입찰프로그램을 제안한다. 입찰 프로그램은 k-최근접 이웃(k-Nearest Neighbors : KNN) 알고리즘의KNeighborsRegressor를 이용하여 기존의 낙찰현황 데이터를 분류한 후, 이를 분석하여 훈련 세트와 테스트 세트의 정확도를통해 KNN 알고리즘을 이용한 모델을 구성하고, 기존낙찰가 분석을 통해 낙찰금액을 예측하였다.","In Korea, we have used electronic bidding as basics in the bidding. The electronic bidding has the advantages to simplify the troublesome of submitting bidding document directly to the client and to prevent unfair bidding due to fact-to-face contact between procurement company and public institution. However, it is not easy that predict the price tendered in the electric bidding. This paper proposes a bidding program with machine learning using python that can be applied to the electronic bidding. The bidding program classifies the data of existing bid status by using KNeighborsRegressor of k-Nearest Neighbors (KNN) algorithm. After we analyze the data of existing bid status, we compose a model using KNN algorithm through the accuracy of training set and test set.Finally we predict price tendered by analyzing the existing b idprice."
한문고전 인공지능 번역 연구의 필요성과 선결 과제,2019,"['Literary Sinitic', 'Translation', 'Machine Translation', 'Artificial intelligence(AI)', 'Big Data', 'Deep Learning', '한문고전', '번역', '기계번역', '인공지능', '빅데이터', '딥러닝']","기계번역 기술의 발달에 힘입어 한문고전을 현대 한국어로 옮기는 전통적인 번역 과정에서 인간의 역량을 인공지능으로 대체하는 것이 가능한 일일까? 본 논문은 이 물음에 대한 해결 방안을 제시하고자 하였다. 이것은 전통적인 한국의 한문 자료를 이해하는 데 있어서 획기적인 기술의 전환을 의미할 뿐만 아니라, 현대의 정보화 시대에서 한문 연구자 및 사용자들에게 기계번역을 통한 편의성 제고는 필수불가결한 시대적 흐름이 될 것이다.본고는 한문 기계번역의 도입과 연구 과정에서, 기존 한문학 관련 연구자들의 역할을 재조명하고, 현대의 정보화 시대에서 한문 기계번역의 활용도 및 효율성 제고를 위한 한문학 연구자들의 새로운 역할을 제시하였다.한문 기계번역 시스템이 활성화되기 위해서는 두 가지 선결 과제가 수행되어야 한다. 첫째, 한문번역 수행을 위한 다양하고 효율적인 도구를 개발하여 번역 공정에 필요한 도구 구축이 선행되어야 한다. 둘째, 질적 수준과 양적 수준이 구비된 병렬코퍼스를 구축하기 위한 방안 설정과 시행이 뒷받침되어야 한다. 본고의 연구 결과를 통해 ‘한문 언어학’과 같은 학문 영역의 새로운 연구 분야를 창출함으로써, 인간의 기억과 직관 능력에 의존해왔던 기존의 문학 연구 및 번역 분야에 획기적인 변화를 촉진할 수 있으며, 이는 곧 지식의 유통과 재생산의 의미에서 학문적인 기여와 효율성을 제고하게 될 것이다.","As machine translation technology develops, translation from Literary Sinitic to modern Korean language is now possible. This enhances the users' excellence in understanding the Literary Korean-Sinitic. Machine translation, in turn, becomes essential for scholars studying Literary Korean-Sinitic in the modern information era.We propose Linguistics of Literary Sinitic' which is a novel research area facilitating the usage of Literary Korean-Sinitic in the modern information era. This can catalyze change in the classical literature research and classical translation research which depended on human memory and intuition. This study contributes to information reproduction and transfer."
Word2Vec과 앙상블 합성곱 신경망을 활용한 영화추천 시스템의 정확도 개선에 관한 연구,2019,"['Text Analysis(Word2Vec)', 'Collaborative Filtering', 'Recommender Systems', 'Ensemble Model', 'Convolutional Neural Networks', 'Deep Learning', '텍스트 분석(Word2Vec)', '협업필터링', '추천시스템', '앙상블 모델', '합성곱 신경망', '딥러닝']","웹 추천기법에서 가장 많이 사용하는 방식 중의 하나는 협업필터링 기법이다. 협업필터링 관련 많은 연구에서 정확도를 개선하기 위한 방안이 제시되어 왔다. 본 연구는 Word2Vec과 앙상블 합성곱 신경망을 활용한 영화추천 방안에 대해 제안한다. 먼저 사용자, 영화, 평점 정보에서 사용자 문장과 영화 문장을 구성한다. 사용자 문장과 영화 문장을 Word2Vec에 입력으로 넣어 사용자 벡터와 영화 벡터를 구한다. 사용자 벡터는 사용자 합성곱 모델에 입력하고, 영화 벡터는 영화 합성곱 모델에 입력한다. 사용자 합성곱 모델과 영화 합성곱 모델은 완전연결 신경망 모델로 연결된다. 최종적으로 완전연결 신경망의 출력 계층은 사용자 영화 평점의 예측값을 출력한다. 실험결과 전통적인 협업필터링 기법과 유사 연구에서 제안한 Word2Vec과 심층 신경망을 사용한 기법에 비해 본 연구의 제안기법이 정확도를 개선함을 알 수 있었다.","One of the most commonly used methods of web recommendation techniques is collaborative filtering. Many studies on collaborative filtering have suggested ways to improve accuracy. This study proposes a method of movie recommendation using Word2Vec and an ensemble convolutional neural networks. First, in the user, movie, and rating information, construct the user sentences and movie sentences. It inputs user sentences and movie sentences into Word2Vec to obtain user vectors and movie vectors. User vectors are entered into user convolution model and movie vectors are input to movie convolution model. The user and the movie convolution models are linked to a fully connected neural network model. Finally, the output layer of the fully connected neural network outputs forecasts of user movie ratings. Experimentation results showed that the accuracy of the technique proposed in this study accuracy of conventional collaborative filtering techniques was improved compared to those of conventional collaborative filtering technique and the technique using Word2Vec and deep neural networks proposed in a similar study."
합성곱 신경망을 위한 Elastic Multiple Parametric Exponential Linear Units,2019,"['Elastic Multiple Parametric Exponential Linear Units', 'activation function', 'convolutional neural network', 'image classification', 'deep learning', 'Elastic Multiple Parametric Exponential Linear Units', '활성화 함수', '합성곱 신경망', '이미지분류', '딥러닝']","활성화 함수는 신경망 모델의 비선형성과 깊이를 결정하는 중요한 요소이다. Rectified Linear Units (ReLU)가 제안된 이후, 평균값을 0에 가깝게 하여 학습의 속도를 높인 Exponential Linear Units (ELU)나 함수 기울기에 변화를 주어 성능을 향상시킨 Elastic Rectified Linear Units (EReLU)같은 다양한 형태의 활성화 함수가 소개되었다. 우리는 서로 다른 ELU와 EReLU를 일반화한 형태의 활성화 함수인 Elastic Multiple Parametric Exponential Linear Units (EMPELU)를 제안한다. EMPELU는 양수 영역에서는 임의의 범위로 기울기 변동을 주면서, 음수 영역은 학습 파라미터를 이용해 다양한 형태의 활성화 함수를 형성하도록 하였다. EMPELU는 합성곱 모델 기반 CIFAR-10/100의 이미지 분류에서 기존 활성화 함수에 비해 정확도 및 일반화에서 향상된 성능을 보였다.","Activation function plays a major role in determining the depth and non-linearity of neural networks. Since the introduction of Rectified Linear Units for deep neural networks, many variants have been proposed. For example, Exponential Linear Units (ELU) leads to faster learning as pushing the mean of the activations closer to zero, and Elastic Rectified Linear Units (EReLU) changes the slope randomly for better model generalization. In this paper, we propose Elastic Multiple Parametric Exponential Linear Units (EMPELU) as a generalized form of ELU and EReLU. EMPELU changes the slope for the positive part of the function argument randomly within a moderate range during training, and the negative part can be dealt with various types of activation functions by its parameter learning. EMPELU improved the accuracy and generalization performance of convolutional neural networks in the object classification task (CIFAR-10/100), more than well-known activation functions."
Combining multi-task autoencoder with Wasserstein generative adversarial networks for improving speech recognition performance,2019,"['Speech enhancement', 'Wasserstein Generative Adversarial Network (WGAN)', 'Weight initialization', 'Robust speech recognition', 'Deep Neural Network (DNN)', '음성인식', '와설스타이식 생성적 적대 신경망', '직교 구배 페널티', '초기화', '딥러닝']",,"As the presence of background noise in acoustic signal degrades the performance of speech or acoustic event recognition, it is still challenging to extract noise-robust acoustic features from noisy signal. In this paper, we propose a combined structure of Wasserstein Generative Adversarial Network (WGAN) and Multi- Task AutoEncoder (MTAE) as deep learning architecture that integrates the strength of MTAE and WGAN respectively such that it estimates not only noise but also speech features from noisy acoustic source. The proposed MTAE-WGAN structure is used to estimate speech signal and the residual noise by employing a gradient penalty and a weight initialization method for Leaky Rectified Linear Unit (LReLU) and Parametric ReLU (PReLU). The proposed MTAE-WGAN structure with the adopted gradient penalty loss function enhances the speech features and subsequently achieve substantial Phoneme Error Rate (PER) improvements over the stand-alone Deep Denoising Autoencoder (DDAE), MTAE, Redundant Convolutional Encoder-Decoder (R-CED) and Recurrent MTAE (RMTAE) models for robust speech recognition."
향상된 음향 신호 기반의 음향 이벤트 분류,2019,"['Noise Robustness', 'Sound Signal Generation', 'End-to-End Architecture', 'Deep Learning', '잡음 견고성', '음향 신호 생성', 'End-to-End 구조', '딥러닝']",,"The explosion of data due to the improvement of sensor technology and computing performance has become the basis for analyzing the situation in the industrial fields, and various attempts to detect events based on such data are increasing recently. In particular, sound signals collected from sensors are used as important information to classify events in various application fields as an advantage of efficiently collecting field information at a relatively low cost. However, the performance of sound-event classification in the field cannot be guaranteed if noise can not be removed. That is, in order to implement a system that can be practically applied, robust performance should be guaranteed even in various noise conditions. In this study, we propose a system that can classify the sound event after generating the enhanced sound signal based on the deep learning algorithm. Especially, to remove noise from the sound signal itself, the enhanced sound data against the noise is generated using SEGAN applied to the GAN with a VAE technique. Then, an end-to-end based sound-event classification system is designed to classify the sound events using the enhanced sound signal as input data of CNN structure without a data conversion process. The performance of the proposed method was verified experimentally using sound data obtained from the industrial field, and the f1 score of 99.29% (railway industry) and 97.80% (livestock industry) was confirmed."
이미지 인식과 캡션을 위한 기계학습 모델 연구,2019,"['Machine learning model', 'Dataset', 'Chatbot', 'Image recognition', 'Image captioning']","인공지능, 로봇공학, 사물인터넷, 빅 데이터, 자율주행시스템 등은4차 산업혁명의 주요 기술군이다. 이들 기술은 대량의 비정형 데이터(이미지)나 스트리밍 데이터들을 다루게 되며, SNS 사용자들이 발생시키는 비정형 데이터들의 양도 지속적으로 증가하고 있다. 본 논문에서는 인공지능, 딥 러닝이나 비전 처리에서 많이 연구되는 이미지 데이터에 대한 기계학습 모델을 구축하고, 이미지 처리를 위한 인식 및 캡션 생성에 대한 실험을 수행하였다. 제안 모델은 챗봇(페이스북 앱), 모니터 서버와 모델 서버로 구성되며, 질의 종류는 이미지와 자연어 문장으로 구분하여 모델 서버의 ‘Captioning Model’과 ‘VQA Model’에서 각각 처리한다. 기계학습에 사용한 공개 훈련용 데이터 집합은 2017 MSCOCO이며, 캡션 생성의 성능 실험 결과 perplexity는 8.9의 우수한 결과를 확인할 수 있었다.","Artificial intelligence, Robotics, the Internet of Things, Big data and Self-driving systems are the major technological groups of the fourth industrial revolution. These technologies related to the fourth industrial revolution will deal with large amounts of formalization data(image) or streaming data. Also, the amount of image data occured by SNS users is increasing continuously. In this paper, we constructed a machine learning model for image data processing which is studied in Artificial Intelligence, Deep Learning and Vision Processing. We experimented on recognition and caption generation for image processing. The proposed model consists of three parts which have a Chatbot (Facebook app), a Monitor Server and a Model Server. The query types of Chatbot are classified into image and natural language sentences and processed in ‘Captioning Model’ and ‘VQA Model’ of model server respectively. The open training data set used on our machine learning system is 2017 MSCOCO, and the captioning performance is perplexity 8.9. We have obtained the good results from suggested machine learning system."
객체 인식에서의 속도 향상을 위한 모델 앙상블,2019,"['Object detection', 'Ensemble method', 'Convolutional neural network']",,
인공지능 학습을 이용한 스마트 안경의 문자인식,2019,"['Gaze-tracking', 'Deep-learning', 'OCR', 'Image-processing', 'Smart-glasses']",,
라이다와 RGB-D 카메라를 이용하는교육용 실내 자율 주행 로봇 시스템,2019,"['Indoor Navigation', 'Mobile Robot', 'Robot Operating System (ROS)', 'Depth Image', 'Deep Learning']","본 논문은 라이다 센싱 정보와 RGB-D 카메라 영상 정보를 융합하여 이용하는 교육용 실내 자율주행 로봇 시스템을 구현한다. 이 시스템은 라이다 센싱 정보를 획득하기 위해 기존의 소 채널 라이다 센싱 방식을 이용한다. 또한 소 채널 라이다센싱 방식의 약점을 보완하기 위해, RGB-D 카메라 깊이 영상과 딥러닝 기반 객체인식 알고리즘을 이용하는 3차원 구조물인식 방법을 제안하고 이 시스템에 적용한다.","We implement an educational indoor autonomous mobile robot system that integrates LiDAR sensing information withRGB-D camera image information and exploits the integrated information. This system uses the existing sensing methodemploying a LiDAR with a small number of scan channels to acquire LiDAR sensing information. To remedy theweakness of the existing LiDAR sensing method, we propose the 3D structure recognition technique using depth imagesfrom a RGB-"
드론 영상 종합정보처리 및 분석용 시스템 개발,2019,"['Drone-Video Analytics', 'Deep-learning', 'License Plate Recognition', 'Object Detection', 'Object Tracking']","본 논문에서는 다양한 재난치안안전 임무 상황에서 적용할 수 있는 드론 영상 종합정보 처리 및 분석용 시스템을 제안한다. 제안하는 시스템은 드론에서 획득한 영상을 서버에 저장하고, 다양한 시나리오에 따른 영상 처리 및 분석을 수행한다. 각 임무에 따라 필요한 기능은 딥러닝을 활용하여 드론으로부터 확보하는 영상에서 영상분석 시스템을 구성한다. 실험 영상을 통해 교통량 측정, 용의자 및 차량 추적, 조난자 식별 및 해상 초계 임무에 적용할 수 있음을 확인했다. 드론 운용자가 임무에 따른 필요 기능을 선택하고 신속하게 대처할 수 있는 시스템을 구현하였다.",
몬테칼로 렌더링 노이즈 제거를 위한 듀얼 신경망 구조 설계,2019,"['Ray Tracing', 'Denoising', 'MonteCarlo rendering', 'Autoencoder', 'Neural Network', 'Graphics']","본 논문에서는 레이 트레이싱 그래픽에서 사용되는 몬테칼로 렌더링에 포함되는 잡음을 제거하기 위해 개선된 신경망구조 를 설계하였다. 몬테칼로 렌더링은 그래픽의 실감을 높이는데 가장 좋은 방법이지만 픽셀마다 수천 개 이상의 빛 효과를 계산해야 하기 때문에 렌더링 처리시간이 급격히 증가하여 실시간 처리에 큰 문제를 갖고 있다. 이 문제를 개선하기 위해 픽셀에서 사용되는 빛의 수를 줄이게 되는데 이때 렌더링 잡음이 발생하게 되고 이 잡음을 제거하기 위해 다양한 연구가 진행되어 왔다. 본 논문에서는 렌더링 잡음을 제거하는데 딥러닝을 사용하며 특히, 렌더링 이미지를 확산광과 집중광으로 분리하여 이중 신경망 구조를 설계하였다. 설계결과 단일구조 신경망에 비하여 듀얼구조 신경망은 PSNR기준으로 64개 테스트 이미지에 대하여 평균 0.58db가 개선되었으며 reference image에 비하여 99.22% 빛의 수를 줄여 실시간 레이 트레이싱 렌더링을 구현하였다.","In this paper, we designed a revised neural network to remove the Monte Carlo Rendering noise contained in the ray tracing graphics. The Monte Carlo Rendering is the best way to enhance the graphic""s realism, but because of the need to calculate more than thousands of light effects per pixel, rendering processing time has increased rapidly, causing a major problem with real-time processing. To improve this problem, the number of light used in pixels is reduced, where rendering noise occurs and various studies have been conducted to eliminate this noise. In this paper, a deep learning is used to remove rendering noise, especially by separating the rendering image into diffuse and specular light, so that the structure of the dual neural network is designed. As a result, the dual neural network improved by an average of 0.58 db for 64 test images based on PSNR, and 99.22% less light compared to reference image, enabling real-time race-tracing rendering"
무역수출 라이브지수를 활용한 중소수출기업 발굴 연구,2019,"['Export KPI', 'Comprehensive Live Index', 'Small or Medium Sized Business', 'Approval of Purchase', 'Local L/C', '수출지수', '종합 라이브지수', '중소기업', '구매확인서', '내국신용장']","무역수출 분야에서 수출 지수에 관한 논의는 수차례 있었으나 객관적 지표로 설명할 수 있는 명확한 무역수출 지수는 없다. 한국무역협회(KITA), 대한무역투자진흥공사(KOTRA) 등에서 지표를 만들고자 하는 시도를 하고 있으나 수출기업의 역량을 표현할 수 있는 방법에 대하여 현재 계속 고민 중이다. 이에 본 연구는 기업의 규모, 신용도와 같은 공시지표와 거래고객수, 거래횟수, 상품개수, 거래량, 거래기간 등의 활동지표를 feature로 설정하여 인공지능 학습 데이터 셋을 구축하고, 딥러닝 알고리즘에서 Lightgbm을 이용하여 수출 가능 기업에 대한 분류 모델을 제시한다. 또한 기업이 속한 산업 군집 분류 모델로 Graph Neural Network을 사용하여 기업간, 품목간, 사업군에서의 수출 가능 역량을 표현하는 수출 Live지수를 산출하였으며 이는 지수를 산출하는 현재로부터 기업의 과거 활동을 포함함으로써 객관성을 확보하였다.",
인공지능과 고용차별의 법경제학 : 블라인드 채용과 베일의 역설을 중심으로,2019,"['고용차별', '블라인드 채용', '인공지능', '알고리즘 차별', '베일의 역설', 'employment discrimination', 'blind recruitment', 'artificial intelligence', 'algorithmic discrimination', 'paradox of the veil']","고용차별에 관해서는 반복적으로 사회적 관심과 논란이 나타난다. 전통적인 관점에서 보면, 고용차별은 사용자의 편견이나 취향으로 인해 나타나는 경우가 많은 것으로 파악된다. 이를 전제로 하여, 고용차별을 줄이기 위한 정책적인 대안으로, 고용 지원자의 정보를 부분적으로 감추거나 사용자의 재량을 제한하는 방향의 해결책이 대두되었다. 다른 한편, 정보경제학적 관점에서 보면, 고용차별은 정보의 제약 하에서 스크리닝 비용을 포함한 전체적인 채용비용을 감안할 수밖에 없는 사용자와, 지원과정에서 소요되는 정보생산 및 소통비용을 감안하게 되는 지원자의 합리적 선택이 상호작용하면서 어쩔 수 없이 나타나는 결과라는 해석도 있을 수 있다. 최근 들어, 고용 의사결정의 과정에서 인공지능 기술을 활용하게 되는 상황이 나타나고 있는데, 특히 딥러닝 인공지능 알고리즘을 활용하여 고용 판단에 도움을 받는 맥락에서는, 차별을 방지하기 위해 어떤 정보에 대한 수집을 제한하는 것이 필요한지를 더욱 면밀히 분석할 필요가 있다. 개별 상황에 따라서는, 정보의 제한이 차별 문제에 대한 적절한 해결방안이 되지 못할 가능성이 있다. 가급적 다양하고 풍부한 정보의 분석을 통해 지원자의 업무수행능력을 정확하게 파악하는 것이 노동시장의 원활한 운용을 위해 필요하기 때문이다. 다른 한편, 부작용이 우려되는 유형의 정보에 대해서는 엄정한 통제가 필요하다. 블라인드 채용은 일정 유형의 정보에 대하여 수집 자체를 차단하여 정보에 제한을 두는 방식인데, 이 방식을 통해 당초 의도한 정책적 효과의 달성이 가능할지에 대해 면밀하게 분석할 필요가 있다.",
인간과 인공지능 로봇 캐릭터의 비교 연구-너도 인간이니? 기반으로,2019,"['인공지능', '인공지능 캐릭터', '동작 추출', '에니어그램', '성격 특성', 'Artificial intelligence', 'Artificial intelligence characters', 'Motion extraction', 'Behavioral Features', 'Enneagram', 'Personality characteristics']",제4차 산업혁명이 도래하면서 인공지능 로봇은 다양한 영화 및 드라마에서 다른 캐릭터들의 역할을 수행해오고 있다. 이러한 인공지능의 등장은 과학기술의 발전과 동시에 영화나 드라마를 이끌 수 있는 하나의 중요한 소재로 사용된다. 이에 본 논문에서는 국내 드라마에서 한 인물이 인공지능 로봇 캐릭터와 인간 캐릭터를 연기한 내용을 기반으로 비교 분석하고자 한다. 특히 각 캐릭터의 외모를 기반으로 등장인물의 장면을 추출한 후 행동분석을 통해 캐릭터들의 성격과 행동 특징들을 분석한다. 이렇게 분석된 결과는 향후 다양한 캐릭터들을 체계적으로 분석하기 위한 기반 연구로 사용될 예정이다. 또한 캐릭터들의 동작들을 DB화하여 머신러닝 또는 딥러닝을 통해 효율적인 인물 행동 및 성격 분석이 가능한 시스템 구축에 활용하고자 한다.,"With the advent of the Fourth Industrial Revolution, artificial intelligence robots have been playing different characters of role in various movies and dramas. The emergence of such artificial intelligence will be used as an important material that can lead a movie or drama at the same time as the development of science and technology. In this paper, we would like to make a comparative analysis based on the story of a person playing an artificial intelligence robot character and a human character in a domestic drama. In particular, after extracting characters"" scenes based on the appearance of each character, analyze characters"" personality and behavior characteristics through behavioral analysis. The result of this analysis will be used as a base study to systematically analyze various characters in the future. Also, we want to database the actions of characters and use them as a system that enables efficient character behavior and character analysis through machine learning or deep learning."
변형 VGG 모델의 전처리를 이용한 부품도면 문자 인식 성능 개선,2019,"['광학 문자 인식', '심층 학습', '수학적 형태학 필터', 'Deep Learning', 'Mathematical morphology filtering', 'Optical character recognition']","본 논문에서는 기계 서비스 부품 도면에서 숫자를 인식하기 위하여 입력 영상에 대한 전처리와 딥러닝 모델을 제안한다. 서비스 부품 도면의 숫자를 인식하는데 있는 지시선과 도형에 의한 오검출 또는 오인식을 개선하기 위하여 수학적 형태학 필터링 전처리를 한다. 숫자 인식을 위하여 VGG-16 모델을 축소 변형한 7 개의 계층을 가지는 VGG 모델을 적용함으로써 인식 성능을 개선한다. 서비스 부품 도면의 숫자 인식 실험 결과, 제안하는 방법이 인식률 95.57%, 정확도는 92.82%로 종래의 방법에  현저히 개선된 결과를 얻었다.","This paper proposes a method of improving deep learning based numbers and characters recognition performance on parts catalogue through image preprocessing. The proposed character recognition system consists of image preprocessing and 7 layer deep learning model. Mathematical morphological filtering is used as preprocessing to remove the lines and shapes which cause false recognition of numbers and characters on parts catalogue. And the used deep learning model is a 7 layer deep learning model instead of VGG-16 model. As a result of the proposed OCR method, the recognition rate of characters is 92.57% and the precision is 92.82%."
NVIDIA Jetson TX1 기반의 사람 표정 판별을 위한 YOLO 모델 FPS 향상 방법,2019,"['Deep Learning', 'Embedded system. Facial expression recognition', 'TensorRT', 'YOLO']","본 이 논문에서는 NVIDIA Jetson TX1에서 YOLO v2 모델의 정확도를 유지하면서 FPS를 개선하는 방법을 제안한다. 일반적으로, 딥러닝 모델에서는 연산량을 줄여 처리 속도를 높이기 위해 파라미터들을 실수형에서 정수형으로 변환하여 정수 연산을 통해 속도를 높이거나 네트워크의 깊이를 감소시키는 방법을 사용한다. 그러나 이 방법들은 인식 정확도가 떨어질 수 있다. 이 논문에서는 YOLO v2 모델을 이용해 표정인식기를 개발하고 정확도 유지 시키기 위해 정수 연산이나 네트워크 깊이 감소를 사용하는 대신, 다음 세 가지 방법을 통해 연산량 및 메모리 소모를 줄인다. 첫 번째, 3x3 필터를 1x1 필터로 교체하여 각 Layer 당 매개 변수 수를 9 분의 1로 줄인다. 두 번째, TensorRT의 추론 가속 기능 중 CBR (Convolution-Add Bias-Relu)을 통해 연산량을 줄이고, 마지막으로 TensorRT를 사용하여 반복되는 동일한 연산구조를 가진 레이어를 통합하여 메모리 소비를 줄인다. 시뮬레이션 결과, 기존 YOLO v2 모델에 비해 정확도는 1 % 감소했지만 FPS는 기존 3.9 FPS에서 11 FPS로 282%의 속도 향상을 보였다.","In this paper, we propose a novel method to improve FPS while maintaining the accuracy of YOLO v2 model in NVIDIA Jetson TX1. In general, in order to reduce the amount of computation, a conversion to an integer operation or  reducing the depth of a network have been used. However, the accuracy of recognition can be deteriorated. So, we use methods to reduce computation and memory consumption through adjustment of the filter size and integrated computation of the network The first method is to replace the 3x3 filter with a 1x1 filter, which reduces the number of parameters to one-ninth. The second method is to reduce the amount of computation through CBR (Convolution-Add Bias-Relu) among the inference acceleration functions of TensorRT, and the last method is to reduce memory consumption by integrating repeated layers using TensorRT. For the simulation results, although the accuracy is decreased by 1% compared to the existing YOLO v2 model, the FPS has been improved from the existing 3.9 FPS to 11 FPS."
"생명과 기계를 구분하는 세 가지 방식: 개념, 은유, 작동",2019,"['칸트', '라이프니츠', '데리다', '들뢰즈', '마투라나', '비비시스템', 'Kant', 'Leibniz', 'Derrida', 'Deleuze', 'Maturana', 'vivi-system']","오늘날 생명과 기계는 수렴하고 있다. 이 혼합을 이해하고 대응하기 위해서는 생명과 기계를 구분하는 세 가지 방식을 식별해야 할 것으로 보인다. 그것은 개념, 은유, 작동을 중심으로 양자를 구분하는 상이한 체제를 의미한다. 첫째, 개념을 중심으로 볼 때, 칸트와 라이프니츠 사이의 대조가 오늘날 중요한 의미를 지닌다. 칸트는 생명체의 신체 구조는 이해의 대상이지만, 그 목적성과 통일성은 인간의 이해 범위 바깥에서 존중의 대상이라는 점을 주장했다. 반면, 라이프니츠는 기계와 유기체는 모두 기술적 대상이지만, 다만 전자는 인간의 유한한 기계인 반면, 후자는 신의 무한한 기계라는 점이 다를 뿐이라고 말했다. 이 생각이 보다 현대적인 사유에 가깝다고 할 수 있다. 둘째, 은유를 중심으로 볼 때, 생명과 기계는 같은 존재자에 대해 관찰하고 서술하는 상이한 관점이다. 어떤 행동이 외적 동기를 갖는다고 말하는 인과적 서사란 사후적으로 덧붙여진 이야기와 같다. 우리는 생명이 무엇인지 알지 못하며, 생명의 본성은 수없이 많은 이야기들 후에나 밝혀지게 될 것이다. 셋째, 오늘날 새롭게 이해하는 생명은 개체 단위가 아니라 분산적이고 병렬적이고 복합적인 전지구적 시스템이다. 그리고 인류는 피드백 제어 시스템, 딥러닝, 바텀-업 로봇 제작 방식을 통해 기계의 진화 자체를 유도할 수 있게 되었다. 라이프니츠가 말한 인간적 기계는 신적 기계에 점점 더 접근하고 있는 듯 보인다. 이렇듯 개념적 구분, 은유적 서사, 공학적 작동의 세 가지 체제를 구별하여 논의하는 것이 앞으로 불필요한 혼란을 막고 생산적이고 실천적인 대안을 만드는 데 요구된다.","Life and machine converge today. Il seems that three ways should be recognized to distinguish them in order to understand and react to this crossover or alliance. These are three different regimes of thinking around concept, metaphor and operation. In the first place, with regard to the concept, a confrontation of Kantian and Leibnizian thoughts will take on precious value for our contemporary thought. According to Kant, the structure of the living body is an object of understanding, while its purpose and unity is a matter of respect beyond the reach of human intelligence. On the other hand, Leibniz affirms that the mechanism and the organism are both a technical object, but that their difference consists precisely in this: the first is a finite machine which is manufactured by the human, while the last is an infinite machine by God. We can say that this idea is closer to our contemporary thought. In the second place, if we say around the metaphor, life and machine are two different perspectives according to which we observe and describe the same beings. The causal narrative which tells that a certain action comes from an external motive is actually like a story which is added after the fact. We do not know what life is, so that its nature will have been clarified only after countless stories. Third, life as understood today cannot be measured at the individual level, but it is a global terrestrial network or system that is distributive, parallel and complex. In addition, feedback control systems, deep learning, bottom-up robots encourage us to even evolve machines. The human machines that Leibniz spoke of seem to be getting closer and closer to the divine machines. We will thus have to discriminate and discuss these three regimes, that is to say the conceptual distinction, the metaphorical narration and the technological operation, to bring down redundant and unnecessary confusions, and to create productive and practical alternatives."
RANSAC을 이용한 다중 평면 피팅의 효율적인 CUDA 구현,2019,"['CUDA', 'Plane fitting', 'RANSAC', 'GP', 'CUDA', '평면 피팅', 'RANSAC', 'GPU']","외란(Outlier)이 있는 데이터를 피팅(Fitting)하는 방법으로 RANSAC(RANdom SAmple Consensus)알고리즘이 선, 원, 타원 등 의 피팅에 많이 사용되고 있다. 본 논문은 다수의 평면에 대한 3차원 포인트 데이터가 주어질 때 각 평면에 대해 RANSAC기반 평면 피팅을 최근 딥러닝 등에 많이 사용되는 GPU의 하나인 CUDA를 이용하여 효율적으로 수행하는 알고리즘을 제안한다. 모의 데이터와 실제 데이터를 이용하여 제안된 알고리즘의 성능을 CPU와 비교하여 보인다. 외란이 많고 인라이어(inlier) 비율이 낮을수록 CPU대비 속도가 향상되고 평면의 개수가 많을수록 평면당 데이터개수가 많을수록 병렬처리에 의한 속도가 가속됨을 보인다. 제안된 방법은 다중 평면 피팅외의 다른 피팅에도 쉽게 적용할 수 있다.","As a fiiting method to data with outliers, RANSAC(RANdom SAmple Consensus) based algorithm is widely used in fitting of line, circle, ellipse, etc. CUDA is currently most widely used GPU with massive parallel processing capability. This paper proposes an efficient CUDA implementation of multiple planes fitting using RANSAC with 3d points data, of which one set of 3d points is used for one plane fitting. The performance of the proposed algorithm is demonstrated compared with CPU implementation using both artificially generated data and real 3d heights data of a PCB. The speed-up of the algorithm over CPU seems to be higher in data with lower inlier ratio, more planes to fit, and more points per plane fitting. This method can be easily applied to a wide variety of other fitting applications."
열화상 영상 잡음 제거를 위한 효율적인 잡음 제거 블록 기반의 신경망,2019,"['image denoising', 'convolutional neural networks', 'thermal image', 'laplace noise', 'receptive field', 'residual leraning']","열화상 카메라는 제한된 열화상 해상도로 인해 잡음이 있는 영상을 야기한다. 본 논문에서는 잡음 문제를 해결하기 위해 반복 가능한 인셉션-레지듀얼 블록(IRB)으로 이루어진 새로운 딥러닝 기반의 신경망을 제안한다. 각각의 IRB는 원본 이미지에 대하여 서로 다른 수용 영역을 가진 합성곱 층 2개를 가지고 베니싱 그레디언트(vanishing gradient)를 방지하기 위한 하나의 쇼트 컷(shortcut connection)으로 구성된다. 제안된 방법은 12개의 열화상 이미지로 테스트가 이루어졌다. 실험 결과, 제안된 방법은 최신의 잡음 제거 방법인 DnCNN과 비교해 봤을 때 신호대잡음비(PSNR)를 39.57에서 40.26으로 처리속도는 1.5910초에서 0.7508초로 잡음 제거 성능 및 처리 속도 개선을 보여준다.","Thermal cameras show noisy images due to their limited thermal resolution, especially for the scenes of a low-temperature difference. In order to deal with a noise problem, this paper proposes a novel neural network architecture with repeatable denoising inception-residual blocks(DnIRB) for noise learning. Each DnIRB has two sub-blocks with difference receptive fields and one shortcut connection to prevent a vanishing gradient problem. The proposed approach is tested for 12 thermal images. The experimental results indicate that the proposed approach shows the PSNR performance is increased 39.57 to 40.26 and processing time also is reduced 1.5910 to 0.7508 compared with state-of-the-art denoising methods which is called DnCNN."
모바일 기기의 에너지 소모를 줄이기 위한 인지 무선 통신에서 효율적인 스펙트럼 센싱 방법,2019,"['인지 무선 통신', '증강현실', '가상현실', 'Cognitive Radio', 'Augmented Reality', 'Virtual Reality']","증강현실, 가상현실, 딥러닝 등 최신 어플리케이션들은 재난상황 대처, 게임 등 다양한 분야에서 효율적으로 쓰일 수 있다. 그에따라 해당 어플리케이션들이 급속도로 개발되고 있다. 그러나 증강현실, 가상현실과 같은 최신 모바일 어플리케이션은 모바일 기기에 에너지 부담을 가중시킨다. 따라서 모바일 기기가 최신 모바일 어플리케이션에만 에너지를 집중하기 위해선 인지무선 통신과 같은 통신 및 네트워킹에는 에너지 소모를 최소화 시켜야 한다. 본 논문은 Stop Reporting Algorithm (SRA)를 고안하여 인지 무선 통신에서 Centralized Cooperative Spectrum Sensing (CCSS) 기법의 에너지 소모를 줄일 수 있는 방안을 제시한다. 시뮬레이션 결과를 통해SRA가 인지 무선 통신의 에너지 소모를 감소시킬 수 있음을 보인다.","The latest mobile applications such as augmented reality, virtual reality, and deep learning can be used efficiently in various fields such as emergency management and game. Accordingly the corresponding applications have been developed for these purposes.However modern mobile applications such as augmented reality and virtual reality increase the energy burden on mobile devices.In order for mobile devices to focus their energy on the latest mobile applications, energy consumption should be minimized for communication and networking, such as cognitive radio. In this paper, we propose a method to reduce the energy consumption of Centralized Cooperative Spectrum Sensing (CCSS) scheme in cognitive radio by devising Stop Reporting Algorithm (SRA). Simulation results show that SRA can reduce energy consumption of mobile devices using cognitive radio."
유도형 전력선 통신과 연동된 SSD 기반화재인식 및 알림 시스템,2019,"['single shot multibox detector(SSD)', 'faster-RCNN', 'Deeping learning', 'power line communication', 'inductive coupling unit']","인적이 드문 한적한 곳이나 산악 지역에서 화재가 발생 하였을 때 화재 상황을 정확하게 파악하고 적절한 초동 대처를 한다면 피해를 최소화할 수 있으므로 사전 화재인지시스템과 자동알림시스템이 요구된다. 본 연구에서는 객체인식을 위한 딥러닝 알고리즘 중 Faster-RCNN 및 SSD(single shot multibox detecter)을 사용한 화재 인식시스템을 전력선 통신과 연동하여 자동알림시스템을 시연하였으며 향 후 고압송전망을 이용한 산불화재 감시에 응용 가능함을 제시하였다. 학습된 모델을장착한 라즈베리파이에 파이카메라를 설치하여 화재 영상인식을 수행하였으며, 검출된 화재영상은 유도형 전력선 통신망을통하여 모니터링 PC로 전송하였다. 학습 모델별 라즈베리파이에서의 초당 프레임 율은 Faster-RCNN의 경우 0.05 fps, SSD의 경우 1.4 fps로 SSD의 처리속도가 Faster-RCNN 보다 28배 정도 빨랐다.","A pre-fire awareness and automatic notification system are required because it is possible to minimize the damageif the fire situation is precisely detected after a fire occurs in a place where people are unusual or in a mountainousarea. In this study, we developed a RaspberryPi-based fire recognition system using Faster-recurrent convolutionalneural network (F-RCNN) and single shot multibox detector (SSD) and demonstrated a fire alarm system that workswith power line communication. Image recognition was performed with a pie camera of RaspberryPi, and the detectedfire image was transmitted to a monitoring PC through an inductive power line communication network. The frame rateper second (fps) for each learning model was 0.05 fps for Faster-RCNN and 1.4 fps for SSD. SSD was 28 times fasterthan F-RCNN."
STFT와 RNN을 활용한 화자 인증 모델,2019,"['Speaker verification', 'STFT', 'Deep Learning', 'Recurrent Neural Network(RNN)']","최근 시스템에 음성 인증 기능이 탑재됨에 따라 화자(Speaker)를 정확하게 인증하는 중요성이 높아지고 있다. 이에 따라 다양한 방법으로 화자를 인증하는 모델이 제시되어 왔다. 본 논문에서는 Short-time Fouriertransform(STFT)를 적용한 새로운 화자 인증 모델을 제안한다. 이 모델은 기존의 Mel-Frequency CepstrumCoefficients(MFCC) 추출 방법과 달리 윈도우 함수를 약 66.1% 오버랩하여 화자 인증 시 정확도를 높일 수 있다. 새로운 화자 인증 모델을 제안한다. 이 때, LSTM 셀을 적용한 Recurrent Neural Network(RNN)라는 딥러닝 모델을 사용하여 시변적 특징을 가지는 화자의 음성 특징을 학습하고, 정확도가 92.8%로 기존의 화자 인증 모델보다 5.5% 정확도가 높게 측정되었다.","Recently as voice authentication function is installed in the system, it is becoming more important to accuratelyauthenticate speakers. Accordingly, a model for verifying speakers in various ways has been suggested. In this paper, wepropose a new method for verifying speaker verification using a Short-time Fourier Transform(STFT). Unlike the existingMel-Frequency Cepstrum Coefficients(MFCC) extraction method, we used window function with overlap parameter of around66.1%. In this case, the speech characteristics of the speaker with the temporal characteristics are studied using a deeprunning model called RNN (Recurrent Neural Network) with LSTM cell. The accuracy of proposed model is around 92.8%and approximately 5.5% higher than that of the existing speaker certification model."
독점 멀티 분류기의 심층 학습 모델을 사용한 약지도 시맨틱 분할,2019,"['Deep learning', 'Peak response map', 'Weakly supervised semantic segmentation']","최근 딥러닝 기술의 발달과 함께 신경 네트워크는 컴퓨터 비전에서도 성공을 거두고 있다. 컨볼루션 신경망은단순한 영상 분류 작업뿐만 아니라 객체 분할 및 검출 등 난이도가 높은 작업에서도 탁월한 성능을 보였다. 그러나 그러한 많은 심층 학습 모델은 지도학습에 기초하고 있으며, 이는 이미지 라벨보다 주석 라벨이 더 많이 필요하다. 특히semantic segmentation 모델은 훈련을 위해 픽셀 수준의 주석을 필요로 하는데, 이는 매우 중요하다. 이 논문은 이러한 문제를 해결하기 위한 네트워크 훈련을 위해 영상 수준 라벨만 필요한 약지도 semantic segmentation 방법을 제안한다. 기존의 약지도학습 방법은 대상의 특정 영역만 탐지하는 데 한계가 있다. 반면에, 본 논문에서는 우리의 모델이사물의 더 다른 부분을 인식하도 multi-classifier 심층 학습 아키텍처를 사용한다. 제안된 방법은 VOC 2012 검증 데이터 세트를 사용하여 평가한다.","Recently, along with the recent development of deep learning technique, neural networks are achieving success in computer vision filed. Convolutional neural network have shown outstanding performance in not only for a simple image classification task, but also for tasks with high difficulty such as object segmentation and detection. However many such deep learning models are based on supervised-learning, which requires more annotation labels than image-level label. Especially image semantic segmentation model requires pixel-level annotations for training, which is very. To solve these problems, this paper proposes a weakly-supervised semantic segmentation method which requires only image level label to train network. Existing weakly-supervised learning methods have limitations in detecting only specific area of object. In this paper, on the other hand, we use multi-classifier deep learning architecture so that our model recognizes more different parts of objects. The proposed method is evaluated using VOC 2012 validation dataset."
사용자 관심사 분석에 기반한 대화형 뉴스 챗봇 시스템 개발,2019,"['News chatbot', 'Intent analysis', 'Artificial intelligence', 'Conversational interaction', 'Chatbot based on user', '뉴스 챗봇', '관심사 분석', '인공지능', '대화형 인터랙션', '사용자 기반 챗봇']","최근 들어 뉴스를 접하는 방법이 다양해짐에 따라, 스마트폰 어플리케이션 내의 플랫폼과 IT 기술을 접목시킨 콘텐츠가 증가하고 있다. 이러한 뉴스 구독 행태의 변화를 이끌어낸 기술에는 자동화와 개인화 기술을 가능하게 만든 인공지능 기술을 꼽을 수 있다. 본 연구에서는 딥러닝 기술을 활용하여, 사용자가 관심을 가지고 있는 관심사를 분석 및 예측하는 ‘뉴스의 개인화’, 사용자가 관심을 가질만한 뉴스를 자동으로 먼저 추천해주는 ‘뉴스의 자동화’를 구현하였고, 이를 모두 포함한 콘텐츠를 제공방식으로 대화형 챗봇을 선택해 사용자에게 제공한다. 기존의 뉴스 구독 방식과는 다르게, 본 시스템은 맞춤형 정보를 편하게 제공받는 새로운 사용자 경험을 만들어낼 수 있으며, 대화형 인터랙션을 통해 일방향적인 뉴스 정보 교류가 아닌, 양방향적인 뉴스 정보 교류 및 주체적 정보 취득을 가능하게 만들 것이다.","Nowadays, there are more and more ways to get to the news. Most representative of all, content that combines Smartphone application platforms with IT technologies has increased. This change in news subscription behavior was caused by artificial intelligence technologies, including ""automation"" and ""personalization."" Artificial intelligence technology makes the news information production process efficient. In this study, we implemented 'individualization of news' that analyzes and predicts interests of interest to users, and 'automation of news' that automatically recommends news of interest to users first. It is also provided to users through interactive chatbots. Unlike traditional news subscription methods, the system is comfortable with customized information. And interactive interaction creates two-way news interaction and subjective information acquisition, not one-way news information exchange."
에너지인터넷에서 1D-CNN과 양방향 LSTM을이용한 에너지 수요예측,2019,"['CNN', 'LSTM', '1D-ConvBLSTM', 'Energy prediction', 'Internet of Energy']","에너지인터넷 기술의 발전과 다양한 전자기기의 보급으로 에너지소비량이 패턴이 다양해짐에 따라 수요예측에 대한 신뢰도가 감소하고 있어 발전량 최적화 및 전력공급 안정화에 문제를 야기하고 있다. 본 연구에서는 고신뢰성을 갖는 수요예측을위해 딥러닝 기법인 Convolution neural network(CNN)과 Bidirectional Long Short-Term Memory(BLSTM)을 융합한1Dimention-Convolution and Bidirectional LSTM(1D-ConvBLSTM)을 제안하고, 제안한 기법을 활용하여 시계열 에너지소비량대한 소비패턴을 효과적으로 추출한다. 실험 결과에서는 다양한 반복학습 횟수와 feature map에 대해서 수요를 예측하고 적은 반복학습 횟수로도 테스트 데이터의 그래프 개형을 예측하는 것을 검증한다.","As the development of internet of energy (IoE) technologies and spread of various electronic devices have diversifiedpatterns of energy consumption, the reliability of demand prediction has decreased, causing problems in optimization ofpower generation and stabilization of power supply. In this study, we propose a deep learning method, 1-Dimention-Convolution and Bidirectional Long Short-Term Memory (1D-ConvBLSTM), that combines a convolution neuralnetwork (CNN) and a Bidirectional Long Short-Term Memory(BLSTM) for highly reliable demand forecasting byeffectively extracting the energy consumption pattern. In experimental results, the demand is predicted with the proposeddeep learning method for various number of learning iterations and feature maps, and it is verified that the test data ispredicted with a small number of iterations."
네트워크 비정상 탐지를 위한 속성 축소를 반영한 의사결정나무 기술,2019,"['Network Anomaly Detection', 'NSL-KDD Data Set', 'Decision Tree', 'Feature Selection']","최근 알려지지 않은 공격에 대처하기 위한 네트워크 비정상(anomaly) 탐지 기술에 대한 관심이 한층 높아지고있다. 이러한 기술 개발을 위해 데이터 마이닝(data mining), 기계학습(machine learning), 그리고 딥러닝(deep learning)등을 활용한 다양한 연구가 진행되고 있다. 본 논문에서는 분류(classification) 문제를 다루는 데이터 마이닝 기술 중 가장 전통적인 방법 중 하나인 의사결정나무(decision tree)를 이용하여 NSL-KDD 데이터셋을 대상으로 네트워크 비정상 탐지 가능성을 보여준다. 의사결정나무의 과대적합(over-fitting) 단점을 해소하기위해 카이-제곱(chi-square) 테스트를 통해 최적의 속성 선택(feature selection)을 수행하고, 선택된 13개의 속성을 사용한 의사결정나무 모델 환경에서 NSL-KDD 시험 데이터 셋 KDDTest+에 대해 84% 그리고KDDTest-21에 대해 70%의 네트워크 비정상 검출 정확도를 보였다. 제시된 정확도는 기존 의사결정나무 모델 적용 시 이들 시험 데이터 셋을 대상으로 알려진 정확도 81% 그리고 64% 수준과 비교해 약 3% 그리고 6% 각각 향상된 결과다.","Recently, there is a growing interest in network anomaly detection technology to tackle unknown attacks. For thispurpose, diverse studies using data mining, machine learning, and deep learning have been applied to detect networkanomalies. In this paper, we evaluate the decision tree to see its feasibility for network anomaly detection on NSL-KDDdata set, which is one of the most popular data mining techniques for classification. In order to handle the over-fittingproblem of decision tree, we select 13 features from the original 41 features of the data set using chi-square test, and thenmodel the decision tree using TensorFlow and Scik-Learn, yielding 84% and 70% of binary classification accuracies on theKDDTest+ and KDDTest-21 of NSL-KDD test data set. This result shows 3% and 6% improvements compared to theprevious 81% and 64% of binary classification accuracies by decision tree technologies, respectively."
Self-Attention을 활용한 Siamese CNN-Bidirectional LSTM 기반 문장 유사도 예측,2019,"['자연어 처리', '유사도 측정', '샴 네트워크', '합성곱 신경망', '순환 신경망', '어텐션', 'natural language processing', 'similarity measure', 'siamese network', 'convolution neural network', 'recurrent neural network', 'attention']",본 논문에서는 입력된 두 문장의 유사도를 측정하는 딥러닝 모델을 제안한다. 기존의 문장의유사도 측정 모델에는 단어 혹은 형태소 단위로 문장을 분해하여 임베딩 하는 방식을 활용한다. 하지만 이는 사전의 크기를 증가시켜 모델의 복잡도를 높이는 문제점이 있다. 본 논문에서는 문장을 음소 단위로 분해하여 모델 복잡도를 줄이고 해당 음소를 묶어주는 다양한 필터 사이즈의 1D Convolution Neural Network와 Long Short Term Memory(LSTM)을 결합한 Siamese CNN-Bidirectional LSTM 모델을 제안한다. 본 모델을 평가하기 위해 네이버 지식인 데이터를 활용하여 기존의 문서 유사 측정에서 좋은 성능을 보이는 모델 Manhattan LSTM(MaLSTM)과 비교하였다.,"A deep learning model for semantic similarity between sentences was presented. In general, most of the models for measuring similarity word use level or morpheme level embedding.However, the attempt to apply either word use or morpheme level embedding results in higher complexity of the model due to the large size of the dictionary. To solve this problem, a Siamese CNN-Bidirectional LSTM model that utilizes phonemes instead of words or morphemes and combines long short term memory (LSTM) with 1D convolution neural networks with various window lengths that bind phonemes is proposed. For evaluation, we compared our model with Manhattan LSTM (MaLSTM) which shows good performance in measuring similarity between similar questions in the Naver Q&A dataset (similar to Kaggle Quora Question Pair)."
자동 균열 조사기법의 정확도 평가를 위한 조사선 기반의 지표 제안,2019,"['Accuracy metric', 'Scanline Intersection Similarity (SIS)', 'Automatic rock fracture survey', 'Scanline sampling', 'Intersection Over Union (IoU)', '정확도 지표', '조사선 교차 일치도(Scanline Intersection Similarity)', '자동 암반 균열 조사', '조사선 샘플링']","신속한 암반 및 암석 균열 조사를 위해서는 자동화된 조사기법이 필요하다. 그러나 자동 조사기법의 균열 지도가 수동으로 조사한 것과 얼마나 일치하는지 표기하는 단일 지표가 없어서 그 정확도를 평가하는데 어려움이 있다. 따라서 본 연구에서는 균열 지도 간의 일치도를 단일 값으로 표현하는 조사선 교차 일치도 (Scanline Intersection Similarity, SIS)라는 지표를 새롭게 제안하였다. 제안된 지표는 두 균열 지도의 균열 빈도를 다수의 조사선 상에서 비교하여 이들 간의 기하학적 일치도를 도출한다. 해당 지표의 적용성을 검토하기 위해 컴퓨터 비전 (Computer Vision) 분야에서 널리 사용하는 일치도 지표인 Intersection Over Union (IoU)과 비교분석하였다. IoU는 균열의 미시적 형태 차이를 과대평가하는 반면에, 제안된 지표의 경우 미시적 형태 차이보다 경사와 같은 거시적 형태 차이를 더 민감하게 반영하였다. 따라서 균열의 거시적 형태가 중요한 암반 공학적 관점에서, 제안된 지표가 IoU 보다 균열 지도의 일치도 지표로써 적합하였다. 더 나아가 제안된 지표를 딥러닝(Deep Learning)을 이용한 균열 조사기법에 적용해본 결과, 해당 기법의 정확도가 조사선 교차 일치도로 0.674 임을 확인하였다.","While various automatic rock fracture survey methods have been researched, the evaluation of the accuracy of these methods raises issues due to the absence of a metric which fully expresses the similarity between automatic and manual fracture maps. Therefore, this paper proposes a geometry similarity metric which is especially designed to determine the overall similarity of fracture maps and to evaluate the accuracy of rock fracture survey methods by a single number. The proposed metric, Scanline Intersection Similarity (SIS), is derived by conducting a large number of scanline surveys upon two fracture maps using Python code. By comparing the frequency of intersections over a large number of scanlines, SIS is able to express the overall similarity between two fracture maps. The proposed metric was compared with Intersection Over Union (IoU) which is a widely used evaluation metric in computer vision. Results showed that IoU is inappropriate for evaluating the geometry similarity of fracture maps because it is overly sensitive to minor geometry differences of thin elongated objects. The proposed metric, on the other hand, reflected macro-geometry differences rather than micro-geometry differences, showing good agreement with human perception. The metric was further applied to evaluate the accuracy of a deep learning-based automatic fracture surveying method which resulted as 0.674 (SIS). However, the proposed metric is currently limited to 2D fracture maps and requires comparison with rock joint parameters such as RQD."
멀티헤드 주의집중 기법과 하이웨이 네트워크를 활용한 생물학 개체명 인식,2019,"['information retrieval', 'natural language processing', 'named entity recognition', 'multi-head attention mechanism', 'highway network', 'word embedding', '정보 추출', '자연어 처리', '개체명 인식', 'Multi-head 주의 기제 기법', 'Highway 네트워크', '단어 임베딩']","생물학 개체명 인식이란 생물학 문헌으로부터 질병, 유전자, 단백질과 같은 생물학 개체명을 추출하고 그 종류를 분류하는 작업으로, 생물학 데이터로부터 유의미한 정보를 추출하는데 중요한 역할을 한다. 본 연구에서는 입력 단어의 자질을 자동으로 추출할 수 있는 딥러닝 기반의 Bi-LSTM-CRF 모델을 활용한 개체명 인식 연구를 진행하였다. Multi-head 주의 기제 기법을 적용하여 입력 단어들 간의 관계를 포착하고 관련성이 높은 단어에 주목하여 예측의 성능을 높였다. 또한, 단어 단위 임베딩 벡터 외 문자 단위 임베딩 벡터를 결합하여 입력 임베딩의 표상을 확장하고, 각 표상의 정보 흐름을 학습하기 위해 Highway 네트워크에 적용하였다. 제안하는 모델의 성능을 평가하기 위해 두 개의 영어 생물학 데이터셋으로 비교 실험을 진행하였으며, 그 결과 기존 연구의 모델들보다 향상된 성능을 보였다. 이를 통해 제안하는 방법론이 생물학 개체명 인식 연구에서 효과적인 방법론임을 입증하였다.","Biomedical named entity recognition(BioNER) is the process of extracting biomedical entities such as diseases, genes, proteins, and chemicals from biomedical literature. BioNER is an indispensable technique for the extraction of meaningful data from biomedical domains. The proposed model employs deep learning based Bi-LSTM-CRF model which eliminates the need for hand-crafted feature engineering. Additionally, the model contains multi-head attention to capture the relevance between words, which is used when predicting the label of each input token. Also, in the input embedding layer, the model integrates character-level embedding with word-level embedding and applies the combined word embedding into the highway network to adaptively carry each embedding to the input of the Bi-LSTM model. Two English biomedical benchmark datasets were employed in the present research to evaluate the level of performance. The proposed model resulted in higher f1-score compared to other previously studied models. The results demonstrate the effectiveness of the proposed methods in biomedical named entity recognition study."
비트평면 영상을 이용한 이진 CNN 연산 알고리즘,2019,"['Bit-plane', 'Binary CNN', 'Computing Power', 'Embedded System', 'Binary kernel', 'XOR']","본 논문에서는 이진영상과 이진커널을 사용하여 컨볼루션, 풀링, ReLU 연산을 수행하는 이진 CNN 연산 알고리즘을 제안한다. 256 그레이스케일 영상을 8개의 비트평면으로 분해하고, -1과 1로 구성되는 이진커널을 사용하는 방법이다. 이진영상과 이진커널의 컨볼루션 연산은 가산과 감산으로 수행한다. 논리적으로는 XNOR 연산과 비교기로 구성되는 이진연산 알고리즘이다. ReLU와 풀링 연산은 각각 XNOR와 OR 논리연산으로 수행한다. 본 논문에서 제안한 알고리즘의 유용성을 증명하기 위한 실험을 통해, CNN 연산을 이진 논리연산으로 변환하여 수행할 수 있음을 확인한다. 이진 CNN 알고리즘은 컴퓨팅 파워가 약한 시스템에서도 딥러닝을 구현할 수 있는 알고리즘으로 스마트 폰, 지능형 CCTV, IoT 시스템, 자율주행 자동차 등의 임베디드 시스템에서 다양하게 적용될 수 있는 시스템이다.","In this paper, we propose an algorithm to perform convolution, pooling, and ReLU operations in CNN using binary image and binary kernel. It decomposes 256 gray-scale images into 8 bit planes and uses a binary kernel consisting of -1 and 1. The convolution operation of binary image and binary kernel is performed by addition and subtraction. Logically, it is a binary operation algorithm using the XNOR and comparator. ReLU and pooling operations are performed by using XNOR and OR logic operations, respectively. Through the experiments to verify the usefulness of the proposed algorithm, We confirm that the CNN operation can be performed by converting it to binary logic operation. It is an algorithm that can implement deep running even in a system with weak computing power. It can be applied to a variety of embedded systems such as smart phones,  intelligent CCTV, IoT system, and autonomous car."
인공지능형 로봇시스템의 공공성에 관한 연구 - 클라우드 컴퓨팅과 블록체인 기술의 사회윤리적 의미를 중심으로-,2019,"['AI robotics', 'cloud computing system. block-chain', 'data', 'algorithm', 'publicity', 'protection & right of public and private interests', '인공지능형 로봇시스템', '클라우드 컴퓨팅', '블록체인', '데이터', '알고리즘', '공공성', '보호와 권리']","이 연구의 목적은 기하급수적으로 발달하고 있는 인공지능형 로봇시스템이 공적 영역에서 어떤 의미를 갖는지 탐구하는 데 있다. ‘알파고’의 등장 이후 인공지능, 딥러닝, 로봇, 네트워크, 빅데이터는 미래 인간 삶의 변화를 이끌 주요 키워드로 자리 잡았다. 과거 이러한 기술적 요인들은 별개의 영역에서 크게 주목을 받지 못했지만, 최근에는 융․복합적 결합들을 통해 전혀 예측할 수 없는 미래 변화를 주도하고 있다. 지금도 우리는 자율적인 인공지능형 로봇시스템 기반으로 생활하고 있다. 생활가전, 금융, 군사, 의료, 탐사 등 삶과 관련된 모든 분야에서 인공지능형 로봇시스템의 적용이 확대되고 있다. 하지만 이러한 로봇시스템은 각 분야에서 요구된 수요와 기술 중심으로 개발되었다는 점에서 전반적인 인간 삶에 대한 반성과는 별개로 인식되었다. 이에 따라 인공지능형 로봇시스템이 인간에 대해 갖는 존재론적 의미와 사회윤리적 의미는 크게 주목받지 못했다. 따라서 인공지능형 로봇시스템의 핵심 요소 및 인프라 기술인 데이터, 네트워크, 클라우드 컴퓨팅, 블록체인이 개인 정보 및 권리 보호, 특정 집단, 기업, 또는 국가의 이익 창출과 관련해서 갖는 공공성의 의미를 살펴보고, 이를 통해 인공지능형 로봇시스템의 일상 적용을 공공성의 측면에서 고려하고자 한다.","This paper aims to explore the meaning of the development of AI Robotics in public sections. Due to AlphaGo, an attention of one of key words of human development has been paid to various conceptions of artificial intelligence, deep-learning, robots, network and big-data. It has been expected that humans have experiences on the ground of autonomous AI robotics, even though we cannot exactly make prediction about human future. It is obviously seen, however, that human consumers have taken many AI robotics products like robot cleaner and that many governments have tried to develop AI robotics weapon like UAV(drones). That is to say, having been connected with humanity, AI robotics needs to be considered as one of parts in human lives. At the moment, the conception of data is regarded as a whole of human activities and stories in human histories. Each individual has produced each own data that is the foundation of publicity in public sections based on AI robotics. Therefore, the main focus of the social utilization of data in public section is on the technology of cloud computing system and block-chain. In that a government or company has made effort to take individual data in the name of publicity, the meaning in the sense of social ethics is related to the serious conflict between public and private interests of AI robotics in future."
합성곱 신경망을 이용한 선박 기관실에서의 화재 검출에 관한 연구,2019,"['Fire Detection', 'Image-based', 'Ship Engine Room', 'Convolution Neural Network', 'YOLO', '화재검출', '영상기반', '선박 기관실', '합성곱 신경망', '욜로']","화재의 초기 검출은 인명과 재화의 손실을 최소화하기 위한 중요한 요소이다. 불꽃과 연기를 신속하면서 동시에 검출해야 하며 이를 위해 영상 기반의 화재 검출에 관한 연구가 다양하게 진행되고 있다. 기존의 화재 검출은 불꽃과 연기의 특징을 추출하기 위해 여러 알고리즘을 거쳐서 화재의 검출 유무를 판단하므로 연산량이 많이 소모되었으나, 딥러닝 알고리즘인 합성곱 신경망을 이용하면 별도의 과정이 생략되므로 신속하게 검출할 수 있다. 본 논문에서는 선박 기관실에서 화재 영상을 녹화한 데이터로 실험을 수행하였다. 불꽃과 연기의 특징을 외각 상자로 추출한 후 합성곱 신경망 중 하나인 욜로(YOLO)를 이용하여 학습하고 결과를 테스트하였다. 실험 결과를 검출률, 오검출률, 정확도로 평가하였으며 불꽃은 0.994, 0.011, 0.998, 연기는 0.978, 0.021, 0.978을 나타내었고, 연산시간은 0.009s를 소모됨을 확인하였다.","Early detection of fire is an important measure for minimizing the loss of life and property damage. However, fire and smoke need to be simultaneously detected. In this context, numerous studies have been conducted on image-based fire detection. Conventional fire detection methods are compute-intensive and comprise several algorithms for extracting the flame and smoke characteristics. Hence, deep learning algorithms and convolution neural networks can be alternatively employed for fire detection. In this study, recorded image data of fire in a ship engine room were analyzed. The flame and smoke characteristics were extracted from the outer box, and the YOLO (You Only Look Once) convolutional neural network algorithm was subsequently employed for learning and testing. Experimental results were evaluated with respect to three attributes, namely detection rate, error rate, and accuracy. The respective values of detection rate, error rate, and accuracy are found to be 0.994, 0.011, and 0.998 for the flame, 0.978, 0.021, and 0.978 for the smoke, and the calculation time is found to be 0.009 s."
인공지능 알고리즘 플랫폼 클라우드 서비스 연구,2019,"['AI algorithm', 'Platform cloud', 'Clustering analysis', 'Naive bayes', 'Collaborative filtering', '인공지능 알고리즘', '플랫폼 클라우드', '군집 분석', '나이브베이즈', '협업 필터링']","인공지능은 4차 산업혁명을 선도하는 중요 기술로 기존 ICT 산업뿐 아니라 전체 산업 분야에 적용될 수 있는 융합기술이다. 인공지능 서비스를 활용하기 위해 직접 시스템을 구축하는 것은 많은 시간과 노력을 필요로 한다. 이러한 문제점을 해결하기 위해 사용자가 웹 인터페이스를 활용하여 분석방법을 선택하고 대상 데이터를 업로드 하여 스스로 분석하고 결과를 조회할 수 있는 인공지능 클라우드 서비스를 구현하였다. 분산병렬 플랫폼 기반의 인공지능 클라우드는 대용량의 데이터를 빠르게 처리할 수있으며, 다양한 인공지능 알고리즘을 활용하여 분석할 수 있다. 본 연구에서는 군집 분석, 나이브베이즈, 협업 필터링 알고리즘을 클라우드 서비스로 구현하고, 데이터양 변화에 따른 성능을 측정하였다. 앞으로 딥러닝 등 다양한 인공지능 알고리즘을 제공하여 더욱 다양한 산업 분야에 활용할 수 있도록 연구개발을 진행할 예정이다.","An important technology leading the Fourth Industrial Revolution, Artificial Intelligence, is a convergence technology that can be applied not only to the existing ICT industry but also to the entire industrial field. Setting up a system to take advantage of AI services requires a lot of time and effort.In order to solve the above low-efficiency method, we implement the AI cloud service that analyzes the data and retrieves the results when users select analysis method and upload target data through User Interface on the web.AI cloud based on distributed parallel platform can process a large amount of data quickly and can be analyzed by using various AI algorithms. In this study, we implement a cloud service using Clustering Analysis, Naïve Bayes Classification, and Collaborative Filtering algorithms to measure the performance according to the change of data size. In the future, we will continue to develop various AI algorithms such as deep learning for use in a wider range of industries."
RNN 기반 디지털 센서의 Rising time과 Falling time 고장 검출 기법,2019,"['Digital sensor fault diagnosis', 'Deep learning', 'Recurrent neural networks', 'Long short term memory']","4차 산업 혁명이 진행되며 많은 회사들의 스마트 팩토리에 대한 관심이 커지고 있으며 센서의 중요성 또한 대두되고있다. 정보를 수집하기 위한 센서에서 고장이 발생하면 공장을 최적화하여 운영할 수 없기 때문에 이에 따른 손해가 발생할수 있다. 이를 위해 센서의 상태를 진단하여 센서의 고장을 진단하는 일이 필요하다. 본 논문에서는 디지털 센서의 고장유형중 Rising time과 Falling time 고장을 딥러닝 알고리즘 RNN의 LSTM을 통해 신호를 분석하여 고장을 진단하는 모델을제안한다. 제안한 방식의 실험 결과를 정확도와 ROC 곡선 그래프의 AUC(Area under the curve)를 이용하여 Rule 기반 고장진단 알고리즘과 비교하였다. 실험 결과, 제안한 시스템은 Rule 기반 고장진단 알고리즘 보다 향상되고 안정된 성능을 보였다.","As the fourth industrial revolution is emerging, many companies are increasingly interested in smart factories and the importance of sensors is being emphasized. In the case that sensors for collecting sensing data fail, the plant could not be optimized and further it could not be operated properly, which may incur a financial loss. For this purpose, it is necessary to diagnose the status of sensors to prevent sensor' fault. In the paper, we propose a scheme to diagnose digital-sensor' fault by analyzing the rising time and falling time of digital sensors through the LSTM(Long Short Term Memory) of Deep Learning RNN algorithm. Experimental results of the proposed scheme are compared with those of rule-based fault diagnosis algorithm in terms of AUC(Area Under the Curve) of accuracy and ROC(Receiver Operating Characteristic) curve. Experimental results show that the proposed system has better and more stable performance than the rule-based fault diagnosis algorithm."
A3C를 활용한 블록체인 기반 금융 자산 포트폴리오 관리,2019,"['Reinforcement Learning', 'Financial Portfolio Management', 'A3C', 'Cryptocurrency', 'Investment Engineering', '강화학습', '금융 포트폴리오 관리', 'A3C', '암호화폐', '투자공학']","금융투자 관리 전략 중에서 여러 금융 상품을 선택하고 조합하여 분산 투자하는 것을 포트폴리오 관리 이론이라 부른다. 최근, 블록체인 기반 금융 자산, 즉 암호화폐들이 몇몇 유명 거래소에 상장되어 거래가 되고 있으며, 암호화폐 투자자들이 암호화폐에 대한 투자 수익을 안정적으로 올리기 위하여 효율적인 포트폴리오 관리 방안이 요구되고 있다. 한편 딥러닝이 여러 분야에서 괄목할만한 성과를 보이면서 심층강화학습 알고리즘을 포트폴리오 관리에 적용하는 연구가 시작되었다. 본 논문은 기존에 발표된 심층강화학습 기반 금융 포트폴리오 투자 전략을 바탕으로 대표적인 비동기 심층 강화학습 알고리즘인 Asynchronous Advantage Actor-Critic (A3C)를 적용한 효율적인 금융 포트폴리오 투자 관리 기법을 제안한다. 또한, A3C를 포트폴리오 투자 관리에 접목시키는 과정에서 기존의 Cross-Entropy 함수를 그대로 적용할 수 없기 때문에 포트폴리오 투자 방식에 적합하게 기존의 Cross-Entropy를 변형하여 그 해법을 제시한다. 마지막으로 기존에 발표된 강화학습 기반 암호화폐 포트폴리오 투자 알고리즘과의 비교평가를 수행하여, 본 논문에서 제시하는 Deterministic Policy Gradient based A3C 모델의 성능이 우수하다는 것을 입증하였다.","In the financial investment management strategy, the distributed investment selecting and combining various financial assets is called portfolio management theory. In recent years, the blockchain based financial assets, such as cryptocurrencies, have been traded on several well-known exchanges, and an efficient portfolio management approach is required in order for investors to steadily raise their return on investment in cryptocurrencies. On the other hand, deep learning has shown remarkable results in various fields, and research on application of deep reinforcement learning algorithm to portfolio management has begun. In this paper, we propose an efficient financial portfolio investment management method based on Asynchronous Advantage Actor-Critic (A3C), which is a representative asynchronous reinforcement learning algorithm. In addition, since the conventional cross-entropy function can not be applied to portfolio management, we propose a proper method where the existing cross-entropy is modified to fit the portfolio investment method. Finally, we compare the proposed A3C model with the existing reinforcement learning based cryptography portfolio investment algorithm, and prove that the performance of the proposed A3C model is better than the existing one."
기술평가를 위한평가 참조정보 생성 방안에 관한 연구 : 기술적 속성 유사성 관점에서,2019,"['Technology evaluation', 'Reference information', 'Peer group', 'Quantification of technological features', 'Similarity in technological contents', '기술평가', '평가 참조정보', 'Peer group', '기술적 속성 정량화', '기술내용 유사도']","기술금융은 기업의 기술혁신 및 사업화 역량에 대한 평가를 바탕으로 적정 수준의 자금을 공급하는 것을 의미하며, 기술평가는 이를 실현하기 위한기반으로서 인식된다. 기술평가는 계량화된 데이터에 의한 정량적 평가와해당 분야의 전문가에 의한 정성적 평가의 혼합으로 이루어지며, 계량화된모형은 정성적 평가를 지원하는 역할을 수행하기 때문에 정성적 평가 결과가 최종 기술평가 결과에 직접적으로 영향을 미치는 경향이 강하다. 하지만정성적 평가는 평가자의 개별적 역량 및 성향 차이에 따라 일관적이지 못한결과를 도출할 수 있기 때문에, 다양한 기술평가 관련 기관들은 평가 대상기업과 속성이 유사한 기업들을 peer group으로 정의하고 이들의 평가 관련정보를 평가 참조정보로서 제공하고 있다. 하지만 기존의 방안들은 주로 산업분류 또는 기술분류 간 유사성만을 고려할 뿐, 기술 자체의 속성을 고려하지 못한다는 한계를 지닌다. 이에 본 연구는 딥러닝에서 사용되는 텍스트 문서의 벡터 정보 모델링기법인 doc2vec 모델을 사용하여 기술내용 간 유사도수준을 측정하여 평가 대상기업과 기술적 속성 관점에서 유사성을 지닌 기업들을 발굴하고 이들로부터 평가 참조정보를 생성하기 위한 방법론을 제시한다. 또한 본 방법론에 의해 산출된 결과와 기존의 peer group 정의 방안에의해 산출된 결과를 비교하고, 본 방법론의 타당성에 대한 논의를 수행한다. 본 방법론은 실용적 평가 참조정보를 정량적 방안에 따라 제공함으로써 정성적 기술평가 작업의 효율성을 향상시키는 데 기여할 수 있다. 또한 평가자의 개인적 역량 및 성향에 따른 기술평가 결과의 편차를 줄여 줌으로써 기술평가 작업의 신뢰성도 증진시킬 수 있을 것으로 기대된다.","Technology evaluation is generally recognized as a basis for realizing technology finance which refers to providing financial support based on the evaluation of technology innovation and commercialization capability of firms. It is naturally performed in a combination of quantitative evaluation by quantified data and qualitative evaluation by experts in relevant field. Among the both, the results from qualitative evaluation tend to directly affect the ultimate evaluation results. To facilitate the qualitative work, various institutes related to technology evaluation have tried to identify several firms that are similar to the target firm and generate reference information for the evaluation of target firm’s technology. However, the existing approaches have limitations in that they cannot reflect the features of technology itself, only considering the similarity in terms of the industrial or technological classification. This study proposes a methodology for identifying similar firms to the target firm in terms of technological features by measuring the similarity their technological contents and generating reference information from the information of the similar firms. To measure the similarity between technological context, we apply a doc2vec method which is one of the most representative deep-learning based models to represent textual document information to vector. This study can contribute to improving the efficiency and reliability of qualitative technology evaluation work by providing practical reference information in a quantitative way."
보건의료 빅데이터 활성화 방안에 관한 연구 -핀란드의 사례를 중심으로-,2019,"['보건의료 빅데이터', '개인정보 보호법', 'GDPR', '보건의료데이터 2차사용', '핀젠프로젝트', 'Secondary Use of Health and Social Data', 'Fingen Project', 'GDPR', 'Personal Information Protection Act', 'Health Care Big Data']","4차산업혁명 시대에 이르러 IoT 의료서비스, 유전자정보를 활용한 정밀의료, AI에 의한 질병의 치료 및 진단이 가능해지면서 각국은 세계 의료시장의 주도권을 확보하기 위하여 전략적으로 보건 의료빅데이터 구축에 앞장서고 있다. 이러한 세계적 흐름에 동참하기 위하여 최근 우리 보건복지부 역시 건강보험공단·심사평가원·질병관리본부·국립암센터로 산재 되어있는 의료데이터를 연계하는 보건의료 빅데이터 활용 플랫폼 시범사업을 시작하였다. 그러나 아직 갈 길은 멀기만 하다. 보건의료 빅데이터의 활용 범위, 방법, 절차, 정보보호 조치 등에 관하여 규정하는 구체적인 법적 근거가 부재 한데다가 규제 완화라는 시대적 흐름에 역행하는 각종 과잉규제가 보건의료 빅데이터의 활용을 어렵거나 불가능하게 하고 있기 때문이다. 또한, 야심차게 시작한 보건의료 빅데이터 활용 플랫폼 시범사업 역시 연구자로 하여금 연구에 필요한 최소 수준의 데이터를 요구할 수 있도록 하고 과도하다고 판단되는 경우 데이터의 제공 자체를 반려하도록 함으로써 데이터 의존도가 높은 AI 딥러닝 알고리즘의 개발에 기여하지 못하는 반쪽자리 빅데이터에 머물고 있다. 데이터 제공 목적 역시 “정책연구, 정보보호기술, 보건의료기술연구, 건강 관련 학술연구” 등으로만 제한되어 있는데 사실상 민간이나 산업적 차원의 보건의료 빅데이터 활용 가능성 자체가 원천적으로 봉쇄됨으로써 빅데이터 활용을 통하여 헬스케어 분야의 혁신을 이루고 있는 선진국과 우리나라 간의 격차는 점점 벌어지고 있는 상황이다. 본 논문은 보건의료 빅데이터를 둘러싼 법적 사회적 쟁점을 살펴보고, 보건의료 빅데이터 활용의 선두주자인 핀란드의 개인보호 법제, 건강 및 사회적 정보의 2차 사용에 관한 법률, 핀젠 프로젝트의 사례를 중심으로 검토, 개선방안을 도출함으로써 향후 우리나라의 보건의료 빅데이터 활성화 방안에 관하여 제언하고자 한다.","In the era of the Fourth Industrial Revolution, it is possible to treat and diagnose diseases by IoT medical services, precise medical care using genetic information, and AI. In order to lead the initiative of the global medical market, Countries are striving to build health and medical big data. Recently, the Ministry of Health and Welfare has also started a pilot project for the use of healthcare big data, which links medical data scattered in the Health Insurance Corporation, Review and Assessment Service, Disease Control Headquarters and National Cancer Center. However, there is still a long way to go. This is because there is no specific legal basis for defining the scope, method, procedure, and information protection measures of health care big data. Also, various over regulations that are contrary to the trend of deregulation make it difficult or impossible to use health care big data. In addition, the health care big data platform pilot project does not provide meaningful information for the formation of AI deep learning algorithms by allowing researchers only extremely limited information. The gap between advanced countries and Korea, which are innovating, is widening. This study examines the current state of health care big data use in Korea and its legal and social issues, and suggests the direction for us to move forward for the activation of health care big data by examining the case of Finnish private protection legislation, the second use of health and social information, and the Finzen project."
휠체어 탄 인공지능: 자율적 기술에서 상호의존과 돌봄의 기술로,2019,"['Artificial Intelligence', 'Cultural imaginary', 'Matter of care', 'Autonomy', 'mediation and dependence', 'Care work', 'Disability', 'Artificial Intelligence in wheelchair', '인공지능', '문화적 상상', '돌봄물', '자율성', '매개와 의존', '돌봄노동', '장애', '휠체어 탄 인공지능']","이 글은 인공지능이 만들어내는 문화적 상상을 분석하면서 기술과 인간 사이의 새로운윤리를 모색한다. 과학기술을 돌봄물(matter of care)로 이해하는 페미니스트 과학기술학연구(Puig de la Bellacas, 2011)에 기댄 이 글은 우선 인공지능이 자율성을 문화적 상상으로강력하게 생산하고 있다는 점에 주목한다. 스스로의 경험과 학습을 통해 새로운 환경에적응할 수 있는 능력으로 정의된 이 자율성은 기술적 영역을 넘어 이상적인 인간상을 정의하고 있다. 하지만 데이터에 기반한 딥러닝 기법과 무장한 무인 비행기가 예증하듯, 인공지능 기술은 보이지 않는 인간노동과 복잡한 물질적 장치에 의존하고 있으며, 자율성은허구에 가깝다. 또한 이른바 ‘조수 기술 (assistant technology)’이 보여주듯, 가사노동을부불노동화하는 우리 사회의 오래된 젠더화된 노동인식에 기초해 수많은 인간의 돌봄노동은 비가시화되는 반면, 기계의 돌봄노동은 적극적으로 가시화되고 있다. 또한 인공지능의문화적 상상은 자율성과 행위능력을 이상적인 인간의 특질로 정의하면서 장애의 몸과 이몸이 갖는 가치인 연약함과 의존성의 연대는 가치 없는 것으로 만들고 있다. 인공지능과그 문화적 상상은 능력이 있는 몸(abled-bodies)을 이상화하고 기술의 자율성을 우선 가치로삼으면서 서로 의존하는 인간과 기술의 현실적 관계를 삭제하고 있다. 결론에서 저자는우리에게 필요한 기술은 타자의 비정형적인 몸과 인간의 돌봄노동을 가치 없게 여기도록하는 것이 아니라 이들을 있는 그대로 드러내면서 그 가치를 인정하는 것이어야 한다고주장한다. 책임 있게 응답하는 기술은 주변화된 존재들에 공감하고 의존성을 긍정하고연약성 사이의 연대를 촉진하는 것이어야 한다. 저자는 이런 대안적인 기술을 형상화하기위해 예술가 수 오스틴의 퍼포먼스에서 영감을 얻어 ‘휠체어 탄 인공지능’을 제안한다. ‘휠체어 탄 인공지능’은 자율성을 과시하기보다는 타자의 몸과 노동을 부정하지 않고 이들의존재론적 가능성을 함께 만들어가려 노력하는 상호의존과 돌봄의 기술이다.","This article seeks to explore new relationships and ethics of human and technology by analyzing a cultural imaginary produced by artificial intelligence. Drawing on theoretical reflections of the Feminist Scientific and Technological Studies which understand science and technology as the matter of care(Puig de la Bellacas, 2011), this paper focuses on the fact that artificial intelligence and robots materialize cultural imaginary such as autonomy. This autonomy, defined as the capacity to adapt to a new environment through self-learning, is accepted as a way to conceptualize an authentic human or an ideal subject. However, this article argues that artificial intelligence is mediated by and dependent on invisible human labor and complex material devices, suggesting that such autonomy is close to fiction. The recent growth of the so-called 'assistant technology' shows that it is differentially visualizing the care work of both machines and humans.Technology and its cultural imaginary hide the care work of human workers and actively visualize the one of the machine. And they make autonomy and agency ideal humanness, leaving disabled bodies and dependency as unworthy. Artificial intelligence and its cultural imaginary negate the value of disabled bodies while idealizing abled-bodies, and result in eliminating the real relationship between man and technology as mutually dependent beings. In conclusion, the author argues that the technology we need is not the one to exclude the non-typical bodies and care work of others, but the one to include them as they are. This technology responsibly empathizes marginalized beings and encourages solidarity between fragile beings. Inspired by an art performance of artist Sue Austin, the author finally comes up with and suggests 'artificial intelligence in wheelchair' as an alternative figuration for the currently dominant 'autonomous artificial intelligence'."
언어학과 기계 번역-한문학 텍스트의 기계 번역과 관련하여,2019,"['Artificial Intelligence', 'Translation of Korean Literature Text in Classical Chinese', 'Rule Based Machine Translation', 'Neural Machine Translation', 'Translation Memory', '인공 지능', '한문학 번역', '규칙 기반 기계 번역', '신경망 기계 번역', '번역 메모리']","본 연구는 언어학과 관련하여 기계 번역의 역사를 살펴보고, 규칙 기반 기계 번역과 자료 기반 기계 번역의 알고리듬을 간략히 소개한다. 또한 이를 통해 한문학 텍스트의 기계 번역에 대한 제안과 전망을 하는 것이 본 연구의 목적이다. 기계 번역은 컴퓨터를 이용하여 하나의 언어를 다른 언어로 자동으로 변환하는 기술인데, 최근 인공 지능(AI)과 전산언어학 분야에서 활발히 연구되고 있다. 기계 번역은 Weaver(1949)에서 출발하였으며, 1980년대 초까지 언어학의 영향으로 어휘, 문법, 의미 생성에 필요한 많은 규칙을 적용한 시스템인 규칙 기반 기계 번역이 발전하였다. 1980년대 이후에는 컴퓨터의 발달과 대규모 코퍼스(corpus)의 구축이 가능해지면서 코퍼스를 기계 번역에 이용하려는 시도들이 나타났는데, 코퍼스를 기반으로 하는 자료 기반 기계 번역이 발전하였다. 최근에는 딥러닝(deep learning)을 통한 기계 번역의 인기가 매우 높아지고 있다. 그 중 주목받고 있는 기술은 ‘신경망 기계 번역(Neural Machine Translation)’이다. 그런데 한문학 텍스트는 어휘와 문법에 대한 정확한 정의와 분류가 합의된 상황도 아닐 뿐만 아니라 이를 규칙화한 시스템도 구축하지 못한 상황이기 때문에 규칙 기반 기계 번역을 활용하기 어렵다. 한편 충분한 병렬 코퍼스도 부족하기 때문에 통계적 기계 번역이나 신경망 기계 번역을 활용하기도 어렵다. 따라서 현재 한문학 텍스트의 기계 번역에서 가장 합리적인 방법은 번역 메모리를 활용하는 방법이다. 이를 통해 현재 한문학 텍스트의 번역에 대한 시간과 비용을 최소화 할 수 있고, 향후 신경망 기계 번역에서 필요로 하는 대용량의 병렬 코퍼스를 생성해 낼 수 있을 것이다.","This study examines the history of machine translation in relation to linguistics and briefly introduces algorithms for rule based machine translation and data based machine translation. And the purpose of this study is to propose and prospect a machine translation of Korean texts in classical Chinese. Machine translation is a technology that automatically transforms a language into another language. Recently, it has been actively researched in artificial intelligence(AI) and computational linguistics. Machine translation started with Weaver(1949), and until the early 1980’s, rule based machine translation developed which is a system that applied many rules for vocabulary, grammar, and meaning. Since the 1980’s, the attempts using corpus for machine translation come up with computer development and large corpus construction, then data base machine translation has developed. In recent years, the machine translations with AI has become very popular. One of them is ‘Neural Machine Translation’. However, it is difficult to use rule based machine translation because it is not the agreed-on situation about vocabulary and grammar on Korean literature text in classical Chinese. Also, since there are not enough parallel corpora, it is difficult to use statistical machine translation or neural machine translation. Therefore, the most reasonable method of machine translation on Korean literature text in classical Chinese is to use ‘translation memory’. It is possible to minimize the time and cost for translating the current Korean literature text in classical Chinese, and to generate a large amount of parallel corpus which is required in neural network machine translation in the future."
실내외 환경과 사용자의 행동을 고려한 스마트 홈 서비스 시스템,2019,"['Internet of things', 'Home smart', 'ESP 8266', 'Firebase', 'Android app.']","스마트 홈은 가정의 가전제품, 에너지 소비 장치, 보안기기 등 모든 사물을 통신망으로 연결해 모니터링 및 제어할 수 있는 기술이다. 스마트 홈은 자동제어 뿐 아니라 상황과 사용자의 취향을 학습하고, 이에 맞는 결과를 스스로 제공하는 방향으로 발전하고 있다. 본 논문은 사용자의 행동을 감지하여 사용자의 특성에 맞는 쾌적한 실내 환경 제어 서비스를 할 수 있는 모델을 제안하였다. 전체 시스템 구성은 센서와 와이파이를 탑재한 ESP8266, 실시간 데이터베이스인 firebase , 스마트 폰 어플로 구성된다. 본 모델은 사용자가 가전기기 작동시의 학습모드, 학습 결과를 통한 학습 제어, 실내와 실외 센서의 값을 이용한 자동 환기 등의 기능으로 구분된다. 학습은 에어컨, 가습기, 공기청정지 등 가전기기 제어시의 온도와 습도에 대한 이동 평균을 이용하였다. 본 시스템은 데이터베이스에 지속적으로 수집된 데이터를 다양한 기계학습과 딥 러닝을 통해 사용자의 특성을 분석하고 예측하여 보다 고 품질의 서비스를 제공할 수 있다.","The smart home is a technology that can monitor and control by connecting everything to a communication network in various fields such as home appliances, energy consumers, and security devices. The Smart home is developing not only automatic control but also learning situation and user's taste and providing the result accordingly. This paper proposes a model that can provide a comfortable indoor environment control service for the user's characteristics by detecting the user's behavior as well as the automatic remote control service. The whole system consists of ESP 8266 with sensor and Wi-Fi, Firebase as a real-time database, and a smartphone application. This model is divided into functions such as learning mode when the home appliance is operated, learning control through learning results, and automatic ventilation using indoor and outdoor sensor values. The study used moving averages for temperature and humidity in the control of home appliances such as air conditioners, humidifiers and air purifiers. This system can provide higher quality service by analyzing and predicting user's characteristics through various machine learning and deep learning."
IoT 스마트 디바이스의 서비스 사용성 연구,2019,"['Internet of Thing(IoT:사물인터넷)', 'Smart Device(스마트 디바이스)', 'Service Usability(서비스 사용성)']","사물 인터넷(IoT, Internet of Things)은 빅 데이터, 인공지능, 클라우드, 엣지 클라우드 등의 최신 기술과의 접목으로 스마트 팩토리, 스마트 시티 등과 같은미래 IT 사회를 구현할 핵심 기술로 자리 잡았다. 이러한 상황을 반영하여 최근 IoT 시스템 분야 많은 연구들에서 IoT 오픈 플랫폼을 구축하고 있다.본 연구는 스마트 디바이스를 유형별로 나누고 사용성 측면에서 비교분석 하였으며 제이콥닐슨(Jakob Nielsen)의 10가지 평가 항목에 대표적인 IoT 스마트디바이스를 대입하여 3가지 이상 교집합 된 정확성, 효율성, 직관성, 접근성 4가지 주요항목을 도출하였다.이에 주요 항목으로 도출된 4가지의 요소의 부족한부분을 분석한 결과 향후 본 연구 분석결과를 참고하여 스마트 디바이스의 사용성(정확성, 효율성, 직관성, 접근성)을 최적화되고 편리하게 일상생활에서 질 높은 개인 맞춤형 스마트 서비스를 제공하는 수단으로활용되어 향후 본 연구 분석결과를 참고하여 음성인식 AI(인공지능) 인터페이스로 융합된 IoT 디바이스인터페이스의 개발에 있어서 IoT시대의 미래와 개인맞춤형 스마트 디바이스 서비스의 보다 나은 발전에활용방안을 제안하고자 목적이 있다. 단순한 텍스트입력방식이나 터치를 이용한 방법에서 벗어나 미래의인터페이스로 주목될 음성인식 AI(인공지능)와 다른인터페이스와의 융⋅복합적 서비스의 향후 방향과 가능성 및 시사점을 연구하였다. 인터페이스의 다각적인개발방안으로 첫째, 스마트 디바이스의 성장에 가장중요 요인은 사용자가 스마트 디바이스를 직관적으로사용할 수 있도록 하는 접근성이 필요하다.둘째, 단순히 제품(스마트 디바이스)을 더 많이 판매하기 위한 수단이나 경쟁으로 이해하기보다는 향후복잡하고 번거로운 단계를 거치는 텍스트 입력방식이나 시간을 지체하고 불편함을 주는 터치 및 제스처를 대체할 효과적인 인식성 높은 음성인식 인터페이스의다각적인 개발방안을 마련해야 한다. 마지막으로 음성인식 인공지능(AI)가 탑재된 스마트 스피커는 집안의IT허브로서 각종 음성인식 딥러닝 응용 서비스들이IT와 결합하여 활발히 개발되고 향후 기술이 발전하고 보편화 된다면 매우 편리하고 유용한 서비스의 가치가 높다고 할 것이다.본 연구는 음성인식 AI(인공지능) 인터페이스로 융합된 IoT 디바이스 인터페이스의 개발에 있어서 IoT 시대의 미래와 스마트 디바이스 서비스의 보다 나은발전에 활용될 것을 기대한다.","Internet of Things have been established as a core technology to realize future IT society like smart factory in relation to state-of-art technology such as big data, artificial intelligence, cloud, and edge cloud.Reflecting these situations, many researchers in a IoT system field are trying to build up open Iot platform.This study divided smart devices which are similar to users’ needs into different type and category and analyzed the type by using 10 principles of serviceability assessment of Jacob Nielsen. Utilizing past studies and evaluation analysis, main items such as accuracy, recognition, efficiency, intuition, accessibility have been drawn. By putting this main 5 items into analysis result, usability of IoT smart devices has been analyzed.This study suggests characteristics and guideline for smart service by analyzing practicability and interpreting the efficiency.First, the most important factor for smart device to grow is accessibility that users can use smart device intuitively.Second, multi-directional development plan for effective voice recognition interface should be provided which could substitute touch method which is inconvenient and time-consuming and text entry method which is complicated and annoying. Finally, many people will value smart speaker with voice recognition AI high as a IT herb in a home, if various voice-recognition deep learning application services are developed and generalized in relation to IT technology.Consequently, this research will shed light on the smart service with voice recognition IT interface, when it comes to developing IoT smart device interface, as a strategic guideline which is helpful for the future of IoT age and development of smart service."
기술융합형 만화의 시장 진입 현황과 지능형 웹툰의 출구전략 연구,2019,"['기술융합형 웹툰', '지능형 웹툰', '만화', '웹툰', 'technology', 'WebtoonCartoon', 'A.I. webtoon', 'comics', 'webtoons']","웹툰산업이 만화시장의 대표로 대두되면서, 플랫폼과 유료독자층의 확장 등 폭발적인 성장추세로 평가받던변인들이 이제는 안정화단계 및 박스권의 정체단계로 분석되는, 대안이 필요한 시점이 되었다. 특히, 성장의 모멘텀을 추가로 개발하고, 콘텐츠시장 전체에 1차 원작시장으로서의 잠재적 가치를 평가받는 기업공개시점이다가오고 있다. 이러한 상황에서 대안으로 모색되고 개발되는 형태가 기술융합형 만화이며, 보다 점진적인 진화과정을 거치고 있는 지능형 웹툰으로의 딥러닝이 다양한 모듈과 시뮬레이션으로 현실화되고 있다. 본 논문은 이러한현실적 문제의식을 토대로 ‘웹툰산업의 대안으로 제시되는 기술융합형 웹툰개발의 구조적 변인은 어떠한 모형을기반으로 해야 하는가’라는 연구문제1과 ‘차세대 웹툰산업의 주된 모형으로 작동되어야 할 인공지능기반 지능형웹툰의 기반네트워크는 어떠한 산학연 모델로 구축되어야 하는가’라는 연구문제2를 제시한다. 포털사이트의 규모의 경제와 충성도 높은 네트워크 독자들을 전제로 국내외 성장세를 거듭하고 있던 대형 웹툰플랫폼의 다양한 비즈니스모델은 불법복제사이트의 무차별 공격과 장르편향성이라는 네트워크 외부효과에 적극적으로 대처하기 위해창의적인 대안을 모색 중이다. 그러한 대안의 비상구로 제시되고 진행되는 것이 기술융합형 웹툰이다. 특히, 하일권 작가의 <마주쳤다>로 대변되는 증강현실 웹툰의 실험과 성공은 가성비 높은 기술융합형 웹툰의 기술투자 및모바일 디바이스의 특성을 맞춤형 메커니즘으로 공식화되고 있다. 실제 소프트웨어를 활용한 무빙툰, 효과툰, 음향툰으로 대표되던 초기기술 적용수준의 기술융합형 웹툰은 이제 인공지능 엔진기반 지능형 웹툰으로 진화하고있으며, 그러한 진화의 모델은 생산자, 소비자, 플랫폼, 에이전시, 큐레이션 등 생태계 전반의 모듈에서 각기 다른형태와 연계되며 병행확장되고 있다. 실제 이러한 형태의 진화메커니즘은 ‘빅데이터 네트워크’라는 선제적 기반을필요로 하는데, 엔진과 기술개발속도에 네트워크 기반의 형성속도가 반응하지 못하고 있다는 문제의식이 본 연구의 성과이며, 지능형 웹툰의 출구전략을 제시하는 주제가 된다. 결국, 지능형 웹툰의 진화는 웹툰제작현장의 작가그룹과 전문교육기관의 예비작가그룹이 진행하고 있는 창작과정을 실시간으로 네트워크시키고, 그러한 빅데이터를 산학연 모델로 공식화시키는 시도가 필요하다.","s the webtoon industry emerged as the representative of the comics market, it was time for the alternatives, which were evaluated as explosive growth trends such as expansion of platform and paid readership, to be stabilized and stagnated at the box level. In particular, the company’s public launching point, which develops additional momentum for growth and evaluates its potential value as a primary source market throughout the content market, is approaching.In this situation, the form that is sought and developed as an alternative is a technology convergence cartoon, and deep learning into an intelligent webtoon that is undergoing a more gradual evolution is being realized with various modules and simulations. This paper is based on this realistic problem consciousness, ‘What model should the structural variables of the technology convergence webtoon development presented as an alternative to the webtoon industry be based on?’ as study topic 1 and ‘for the main model of the next generation webtoon industry, what kind of industry-university model should the basic network of artificial intelligence-based intelligent webtoons be presented?’ as study topic 2.The diverse business model of the large webtoon platform, which has been growing at home and abroad under the premise of economies of scale and loyal network readers, has creative alternatives to actively cope with network externalities such as brutal attack of copyf and genre bias.It is a technology convergence webtoon that is presented and proceeded as an emergency exit of such an alternative. In particular, the experiments and success of augmented reality webtoons, which are represented by Ha Il-kwon’s <Meeting>, are formulated with customized mechanisms for the technology investment and the characteristics of mobile devices.The technology convergence webtoon of the initial technology application level represented by moving tones, effect tones, and sound tones using real software is now evolving into AI engine-based intelligent webtoons. It is linked to different forms in modules and expanded throughout the ecosystem, such as and curation, agency, platfrom and consumers.Indeed, this type of evolutionary mechanism requires a preemptive basis of ‘big data network’. The result of this study is that the speed of network-based formation is not responding to the speed of engine and technology development. It is a subject that suggests a strategy. After all, the evolution of intelligent webtoons requires real-time networking of the creative process of the author group of the webtoon production site and the preliminary group of professional educational institutions, and the attempt to formulate such big data into an industry-academia model."
문장 분류를 위한 정보 이득 및 유사도에 따른 단어 제거와 선택적 단어 임베딩 방안,2019,"['문장 분류', '특징 선택', '정보 이득', '단어 유사도', '단어 임베딩', 'Sentence Classification', 'Feature Selection', 'Information Gain', 'Word Similarity', 'Word Embedding']","텍스트 데이터가 특정 범주에 속하는지 판별하는 문장 분류에서, 문장의 특징을 어떻게 표현하고 어떤 특징을 선택할 것인가는 분류기의 성능에 많은 영향을 미친다. 특징 선택의 목적은 차원을 축소하여도 데이터를 잘설명할 수 있는 방안을 찾아내는 것이다. 다양한 방법이 제시되어 왔으며 Fisher Score나 정보 이득(Information Gain) 알고리즘 등을 통해 특징을 선택 하거나 문맥의 의미와 통사론적 정보를 가지는 Word2Vec 모델로 학습된 단어들을 벡터로 표현하여 차원을 축소하는 방안이 활발하게 연구되었다. 사전에 정의된 단어의 긍정 및 부정 점수에 따라 단어의 임베딩을 수정하는 방법 또한 시도하였다.본 연구는 문장 분류 문제에 대해 선택적 단어 제거를 수행하고 임베딩을 적용하여 문장 분류 정확도를 향상시키는 방안을 제안한다. 텍스트 데이터에서 정보 이득 값이 낮은 단어들을 제거하고 단어 임베딩을 적용하는방식과, 정보이득 값이 낮은 단어와 코사인 유사도가 높은 주변 단어를 추가로 선택하여 텍스트 데이터에서 제거하고 단어 임베딩을 재구성하는 방식이다.본 연구에서 제안하는 방안을 수행함에 있어 데이터는 Amazon.com의 ‘Kindle’ 제품에 대한 고객리뷰, IMDB 의 영화리뷰, Yelp의 사용자 리뷰를 사용하였다. Amazon.com의 리뷰 데이터는 유용한 득표수가 5개 이상을 만족하고, 전체 득표 중 유용한 득표의 비율이 70% 이상인 리뷰에 대해 유용한 리뷰라고 판단하였다. Yelp의 경우는 유용한 득표수가 5개 이상인 리뷰 약 75만개 중 10만개를 무작위 추출하였다. 학습에 사용한 딥러닝 모델은 CNN, Attention-Based Bidirectional LSTM을 사용하였고, 단어 임베딩은 Word2Vec과 GloVe를 사용하였다.단어 제거를 수행하지 않고 Word2Vec 및 GloVe 임베딩을 적용한 경우와 본 연구에서 제안하는 선택적으로 단어 제거를 수행하고 Word2Vec 임베딩을 적용한 경우를 비교하여 통계적 유의성을 검정하였다.","Dimensionality reduction is one of the methods to handle big data in text mining. For dimensionality reduction, we should consider the density of data, which has a significant influence on the performance of sentence classification. It requires lots of computations for data of higher dimensions. Eventually, it can cause lots of computational cost and overfitting in the model. Thus, the dimension reduction process is necessary to improve the performance of the model. Diverse methods have been proposed from only lessening the noise of data like misspelling or informal text to including semantic and syntactic information.On top of it, the expression and selection of the text features have impacts on the performance of the classifier for sentence classification, which is one of the fields of Natural Language Processing. The common goal of dimension reduction is to find latent space that is representative of raw data from observation space. Existing methods utilize various algorithms for dimensionality reduction, such as feature extraction and feature selection. In addition to these algorithms, word embeddings, learning low-dimensional vector space representations of words, that can capture semantic and syntactic information from data are also utilized. For improving performance, recent studies have suggested methods that the word dictionary is modified according to the positive and negative score of pre-defined words.The basic idea of this study is that similar words have similar vector representations. Once the feature selection algorithm selects the words that are not important, we thought the words that are similar to the selected words also have no impacts on sentence classification. This study proposes two ways to achieve more accurate classification that conduct selective word elimination under specific regulations and construct word embedding based on Word2Vec embedding. To select words having low importance from the text, we use information gain algorithm to measure the importance and cosine similarity to search for similar words. First, we eliminate words that have comparatively low information gain values from the raw text and form word embedding. Second, we select words additionally that are similar to the words that have a low level of information gain values and make word embedding. In the end, these filtered text and word embedding apply to the deep learning models; Convolutional Neural Network and Attention-Based Bidirectional LSTM.This study uses customer reviews on Kindle in Amazon.com, IMDB, and Yelp as datasets, and classify each data using the deep learning models. The reviews got more than five helpful votes, and the ratio of helpful votes was over 70% classified as helpful reviews. Also, Yelp only shows the number of helpful votes. We extracted 100,000 reviews which got more than five helpful votes using a random sampling method among 750,000 reviews. The minimal preprocessing was executed to each dataset, such as removing numbers and special characters from text data. To evaluate the proposed methods, we compared the performances of Word2Vec and GloVe word embeddings, which used all the words.We showed that one of the proposed methods is better than the embeddings with all the words. By removing unimportant words, we can get better performance. However, if we removed too many words, it showed that the performance was lowered. For future research, it is required to consider diverse ways of preprocessing and the in-depth analysis for the co-occurrence of words to measure similarity values among words. Also, we only applied the proposed method with Word2Vec. Other embedding methods such as GloVe, fastText, ELMo can be applied with the proposed methods, and it is possible to identify the possible combinations between word embedding methods and elimination methods."
멀티 뷰 기법 리뷰: 이해와 응용,2019,"['멀티 뷰 학습', '딥 러닝', '기계학습', '데이터 통합', 'multi-view learning', 'multi-modal learning', 'deep learning', 'machine learning', 'data integration']","멀티 뷰 기법은 데이터를 다양한 관점에서 보려는 접근 방법이며 데이터의 다양한 정보를 통합하여 사용하려는 시도이다. 최근 많은 연구가 진행되고 있는 멀티 뷰 기법에서는 단일 뷰 만을 이용하여 모형을 학습시켰을 때 보다 좋은 성과를 보인 경우가 많았다. 멀티 뷰 기법에서 딥 러닝 기법의 도입으로 이미지, 텍스트, 음성, 영상 등 다양한 분야에서 좋은 성과를 보였다. 본 연구에서는 멀티 뷰 기법이 인간 행동 인식, 의학, 정보 검색, 표정 인식 분야에서 직면한 여러 가지 문제들을 어떻게 해결하고 있는지 소개하였다. 또한 전통적인 멀티 뷰 기법들을 데이터 차원, 분류기 차원, 표현 간의 통합으로 분류하여 멀티 뷰 기법의 데이터 통합 원리를 리뷰 하였다. 마지막으로 딥 러닝 기법 중 가장 범용적으로 사용되고 있는 CNN, RNN, RBM, Autoencoder, GAN 등이 멀티 뷰 기법에 어떻게 응용되고 있는지를 살펴보았다. 이때 CNN, RNN 기반 학습 모형을 지도학습 기법으로, RBM, Autoencoder, GAN 기반 학습 모형을 비지도 학습 기법으로 분류하여 이 방법들이 대한 이해를 돕고자 하였다.","Multi-view learning considers data from various viewpoints as well as attempts to integrate various information from data. Multi-view learning has been studied recently and has showed superior performance to a model learned from only a single view. With the introduction of deep learning techniques to a multi-view learning approach, it has showed good results in various fields such as image, text, voice, and video. In this study, we introduce how multi-view learning methods solve various problems faced in human behavior recognition, medical areas, information retrieval and facial expression recognition. In addition, we review data integration principles of multi-view learning methods by classifying traditional multi-view learning methods into data integration, classifiers integration, and representation integration. Finally, we examine how CNN, RNN, RBM, Autoencoder, and GAN, which are commonly used among various deep learning methods, are applied to multi-view learning algorithms. We categorize CNN and RNN-based learning methods as supervised learning, and RBM, Autoencoder, and GAN-based learning methods as unsupervised learning."
게임과 로봇공학에서의 모델 프리 강화학습 응용에 대한 사례 조사,2019,"['Reinforcement learning', 'Game', 'Robot', 'Q-learning', 'Policy gradient', '강화학습', '게임', '로봇', '큐러닝', '정책 경사']","강화학습은 에이전트가 환경으로부터 현재의 상태를 인지하고 수행한 행동에 대한 피드백을 받으며 학습을 진행한다. 강화학습은 여러 응용에서 활발히 연구되고 있지만, 특히 게임과 로봇에 대한 문제는 마르코프 결정 과정으로 쉽게 표현할 수 있어 강화학습을 적용하기에 용이하다. 모델 프리 강화학습의 종류는 몬테 카를로 컨트롤, 살사, 큐러닝, 정책 경사 방법 등이 있으며, 문제 상황에 따라 알맞은 방법을 사용한다. 게임과 로봇과 관련한 문제를 풀기 위해 모델 프리 강화학습 알고리즘이 주로 사용되며, 딥 큐러닝과 정책 경사 방법이 대표적으로 사용되어왔다. 하지만 주어진 환경에 대한 정보가 충분하지 않아서 보상과 관련된 정보가 충분하지 않고, 보상이 지연되는 경우에는 강화학습이 제대로 작동하기 어려운 문제가 있다. 향후 연구에서는 이러한 단점을 보완하여야 할 것이다. 또한, 이번 연구에서 다루지 못한 게임과 로봇에 관련된 State-of-the-art를 향후 연구에서 다룰 것이다.","Reinforcement learning is the learning process to enable an agent to understand the current environment and get feedback from the action. Though reinforcement learning has been actively studied in various principles, games and robotics are known to be especially well-suited to a Markov decision process, making them easier to apply reinforcement learning. The types of model-free reinforcement learning include Monte-Carlo control, SARSA, Q-learning, and policy gradient and use the appropriate methods depending on the problem situation. Model-free reinforcement learning algorithms such as deep Q-learning and policy gradient are mainly used to solve the problems related to games and robotics. However, reinforcement learning does not work well in some environments where the reward is delayed or has only insufficient information. We believe that future studies need to address these limitations. We plan to investigate the state-of-the-art of reinforcement learning on game and robotics."
합성곱 회귀네트워크 기반의 End-to-End 자율주행,2019,"['딥 러닝', '자율주행 자동차', '합성곱 회귀네트워크', '자율주행', 'LiDAR', '카메라', 'Deep learning', 'Autonomous Vehicle', 'CRNN', 'Autonomous Drivinig', 'Camera']","자율주행에 관한연구는 다양하게 진행되고 있으며, 특히 센서 모델링 등을 통한 rule based 기법의 자율주행이 활발하게 연구되고 있다. 이러한 규칙기반 자율주행 방법의 경우 정형화된 환경에서는 안전한 주행이 가능하나, 실제 도로환경과 같이 변수가 많은 환경에서는 오탐지, 미탐지 등으로 인한 사고가 발생 할 수 있다. 이에 본 연구에서는 비정형화된 환경에서도 안전한 자율주행이 가능 하도록 카메라와 LiDAR 센서의 Raw Data를 이용하고, 이를 토대로 합성곱 회귀네트워크에 입력하여 차량의 종, 횡방향 제어값을 예측하는 연구를 진행한다.","A vehicle that runs on its own without the driver’s intervention to the destination is called an autonomous vehicle. In particular, autonomous driving of rule - based techniques through sensor modeling is actively researched. This rule-based autonomous driving method can be safely run in a formal environment, but it can cause an accident due to false detection or undetected in a variable environment like actual road environment. In this study, we use Raw data of LiDAR sensor and image to enable safe autonomous driving in an informal environment, and then input to the CRNN(Convolutional Recurrent Neural Network)based on this data to predict the longitudinal and lateral control values of the vehicle."
Deep Ensemble Network with Explicit Complementary Model for Accuracy-balanced Classification,2019,"['딥 러닝', '객체 분류', '성능 편차', '앙상블', 'deep learning', 'object classification', 'accuracy deviation', 'ensemble']",,
Deep Learning and Linguistics: Language & Translation Education Measures,2019,"['딥 러닝', '언어', '번역', '인공 지능', '4차 산업혁명', 'Deep Learning', 'language', 'translation', 'Artificial intelligence', 'The fourth industrial revolution']",,"The fourth industrial revolution is on hyperconnectivity. Hyper connectivity refers to connection between men, between men and system, and between systems, and artificial intelligence takes the role of intermediation. Artificial intelligence is completed based on the artificial part that is computer and robot, and intellectual part that is mathematics and linguistics. Deep learning that learns by itself by emulating the structure of neural network of human; as humans use five senses to receive information, self-learning deep learning takes information from visual stimulation. Recent artificial neural network machine translation technology is gradually minimizing translation errors. On the other hand, to such rapid development of language and translation, the school s education is not keeping up with the pace. For this reason, it is obvious that it is the time to seriously think through about the language education and conduct studies. In addition, in regards to language and translation issues, in the machine translation era, translators should be able to offer translation total service that professionally handles not only translation but pre-editing and post-editing to minimize errors of machine translation."
Automatic Generation of HTML Code Based on Web Page Sketch,2019,"['웹 응용', '컴퓨터 비전', '딥 러닝', '객체인식', 'web application', 'computer vision', 'deep learning', 'object detection']",,
뉴로모픽 시스템을 위한 인수분해-프루닝 결합 기반 컨볼루셔널 레이어 압축 기법,2019,"['Deep Learning', 'Deep Neural Networks', 'Neuromorphic Computing', 'Sparse Networks', 'Compressing Parameters']",,
LeafNet: 합성곱 신경망을 이용한 식물체 분할,2019,"['Deep learning', 'Segmentation', 'Plant phenomics', 'Phenomics system', 'CNN', '딥 러닝', '분할', '식물 표현체', '피노믹스 시스템', '합성곱 신경망']","식물 표현체(plant phenomics) 연구는 우수한 형질의 식물 품종과 유전적 특성을 선별하기 위해 여러 식물체의 형태적 특징을 관측하고, 획득한 영상 빅데이터를 분석하는 기술이다. 기존의 방법은 검출 대상에 따라 직접 색상 임계값을 변경해야 하기 때문에 빅데이터를 다루는 정밀검정시스템에 적용하기 어렵다. 본 논문에서는 정밀검정시스템을 위한 식물체와 배경의 자동 분할이 가능한 합성곱 신경망(Convolution neural network: CNN) 구조를 제안한다. LeafNet은 9개의 컨벌루션 계층과 식물의 유무를 판단하기 위한 시그모이드(Sigmoid) 활성화 함수로 구성된다. LeafNet을 이용한 학습 결과, 식물 모종 영상에 대하여 정밀도 98.0%, 재현율 90.3%의 결과가 도출되어 정밀검정시스템의 적용 가능성을 확인하였다.",
합성곱 신경망(Convolutional Neural Network)을 활용한 지능형 유사상표 검색 모형 개발,2019,"['Deep Learning', 'Convolutional Neural Network', 'Trademark Retrieval System', 'Image retrieval Algorithm', '합성곱신경망', '딥 러닝', '상표 검색 시스템', '이미지 검색 알고리즘']","전 세계적으로 온라인 상거래 시장 규모가 성장함에 따라 국제 및 국내 기업의 상표권이 침해되는 사례가 빈번하게 발생하고 있다. 다양한 연구 및 보고서에 따르면, 해외 기업 또는 개인이 국내 기업의 상표권을 침해한 사례와, 국내 기업 간 발생하는 상표권 분쟁 사례가 증가하고 있는 것으로 나타나고 있으며, 특허청의 보고서에 따르면 기업의 규모가 작을수록 상표보호를 위한 사전 예방활동을 수행하지 않는다고 응답한 비율이 높은 것으로 나타났다. 이러한 문제는 선등록 상표에 대한 사전조사 또는 자사의 상표보호를위해 소요되는 인력과 비용이 원인인 것으로 판단된다.한편, 국내에서 선등록상표에 대한 사전조사를 위해 상용되는 서비스를 살펴보면 상표 이미지를 활용한검색 서비스를 제공하고 있지 않은 상황이다. 이로 인해 국내 대다수의 기업은 자사의 상표 보호 및 선등록 상표에 대한 사전조사 수행 시 방대한 양의 선등록된 상표를 수작업으로 조사해야하는 문제가 발생한다.따라서 본 연구에서는 기업의 상표권 보호 및 선등록 상표에 대한 사전조사 수행 시 투입되는 인력 및비용절감과, 국내외에서 발생하고 있는 상표권 침해 문제를 해결하기 위해 합성곱 신경망 기법을 활용한지능형 유사 상표 검색 모델을 개발하고자 한다. 지적 재산권 전문가가 선정한 테스트 데이터를 활용하여지능형 유사 상표 검색 모델의 정확도를 측정한 결과 ResNet V1 101의 성능이 가장 높게 나타났다. 해당결과를 통해 이미지 분류 알고리즘이 단순한 사물 인식 분야뿐만 아니라 이미지 검색 분야에서도 높은 성능을 나타낸다는 것을 실증적으로 입증했으며, 본 연구는 실제 상표 이미지 데이터를 활용했다는 측면에서실제 산업 환경에서 활용성이 높을 것으로 사료된다.","Recently, many companies improving their management performance by building a powerful brand value which is recognized for trademark rights. However, as growing up the size of online commerce market, the infringement of trademark rights is increasing. According to various studies and reports, cases of foreign and domestic companies infringing on their trademark rights are increased. As the manpower and the cost required for the protection of trademark are enormous, small and medium enterprises(SMEs) could not conduct preliminary investigations to protect their trademark rights.Besides, due to the trademark image search service does not exist, many domestic companies have a problem that investigating huge amounts of trademarks manually when conducting preliminary investigations to protect their rights of trademark.Therefore, we develop an intelligent similar trademark search model to reduce the manpower and cost for preliminary investigation. To measure the performance of the model which is developed in this study, test data selected by intellectual property experts was used, and the performance of ResNet V1 101 was the highest. The significance of this study is as follows. The experimental results empirically demonstrate that the image classification algorithm shows high performance not only object recognition but also image retrieval. Since the model that developed in this study was learned through actual trademark image data, it is expected that it can be applied in the real industrial environment."
에너지 인터넷을 위한 GRU기반 전력사용량 예측,2019,"['Machine Learning', 'Deep Learning', 'RNN', 'GRU', 'Demand Forecasting']","최근 에너지 인터넷에서 지능형 원격검침 인프라를 이용하여 확보된 대량의 전력사용데이터를 기반으로 효과적인 전력수요 예측을 위해 다양한 기계학습기법에 관한 연구가 활발히 진행되고 있다. 본 연구에서는 전력량 데이터와 같은 시계열 데이터에 대해 효율적으로 패턴인식을 수행하는 인공지능 네트워크인 Gated Recurrent Unit(GRU)을 기반으로 딥 러닝 모델을제안하고, 실제 가정의 전력사용량 데이터를 토대로 예측 성능을 분석한다. 제안한 학습 모델의 예측 성능과 기존의 LongShort Term Memory (LSTM) 인공지능 네트워크 기반의 전력량 예측 성능을 비교하며, 성능평가 지표로써 Mean SquaredError (MSE), Mean Absolute Error (MAE), Forecast Skill Score, Normalized Root Mean Squared Error (RMSE),Normalized Mean Bias Error (NMBE)를 이용한다. 실험 결과에서 GRU기반의 제안한 시계열 데이터 예측 모델의 전력량 수요 예측 성능이 개선되는 것을 확인한다.","Recently, accurate prediction of power consumption based on machine learning techniques in Internet of Energy (IoE)has been actively studied using the large amount of electricity data acquired from advanced metering infrastructure(AMI). In this paper, we propose a deep learning model based on Gated Recurrent Unit (GRU) as an artificialintelligence (AI) network that can effectively perform pattern recognition of time series data such as the powerconsumption, and analyze performance of the prediction based on real household power usage data. In the performanceanalysis, performance comparison between the proposed GRU-based learning model and the conventional learning modelof Long Short Term Memory (LSTM) is described. In the simulation results, mean squared error (MSE), mean absoluteerror (MAE), forecast skill score, normalized root mean square error (RMSE), and normalized mean bias error (NMBE)are used as performance evaluation indexes, and we confirm that the performance of the prediction of the proposedGRU-based learning model is greatly improved."
인공지능 기반 전력량예측 기법의 비교,2019,"['Demand Forecast', 'Deep Learning', 'MLP', 'RNN', 'LSTM']","최근 안정적인 전력수급과 급증하는 전력수요를 예측하는 수요예측 기술에 대한 관심과 실시간 전력측정을 가능하게 하는 스마트 미터기의 보급의 증대로 인해 수요예측 기법에 대한 연구가 활발히 진행되고 있다. 본 연구에서는실제 측정된 가정의 전력 사용량 데이터를 학습하여 예측결과를 출력하는 딥 러닝 예측모델 실험을 진행한다. 그리고본 연구에서는 데이터 전처리 기법으로써 이동평균법을 도입하였다. 실제로 측정된 데이터를 학습한 모델의 예측량과실제 전력 측정량을 비교한다. 이 예측량을 통해서 전력공급 예비율을 낮춰 사용되지 않고 낭비되는 예비전력을 줄일수 있는 가능성을 제시한다. 또한 본 논문에서는 같은 데이터, 같은 실험 파라미터를 토대로 세 종류의 기법: 다층퍼셉트론(Multi Layer Perceptron, MLP), 순환신경망(Recurrent Neural Network, RNN), Long Short Term Memory(LSTM)에 대해 실험을 진행하여 성능을 평가한다. 성능평가는 MSE(Mean Squared Error), MAE(Mean Absolute Error)의 기준으로 성능평가를 진행했다.","Recently, demand forecasting techniques have been actively studied due to interest in stable power supply with surging power demand, and increase in spread of smart meters that enable real-time power measurement. In this study, we proceeded the deep learning prediction model experiments which learns actual measured power usage data of home and outputs the forecasting result. And we proceeded pre-processing with moving average method. The predicted value made by the model is evaluated with the actual measured data. Through this forecasting, it is possible to lower the power supply reserve ratio and reduce the waste of the unused power. In this paper, we conducted experiments on three types of networks: Multi Layer Perceptron (MLP), Recurrent Neural Network (RNN), and Long Short Term Memory (LSTM) and we evaluate the results of each scheme. Evaluation is conducted with following method: MSE(Mean Squared Error) method and MAE(Mean Absolute Error)."
Multi-Layer Perceptron 기법을 이용한 전력 분석 공격 구현 및 분석,2019,"['Side-Channel Analysis', 'Power Analysis Attack', 'Deep Learning MLP', 'Machine Learning SVM']","본 논문에서는 기존 전력 분석 공격의 어려움과 비효율성을 극복하기 위해 딥 러닝 기반의 MLP(Multi-LayerPerceptron) 알고리즘을 기반으로 한 공격 모델을 사용하여 암호 디바이스의 비밀 키를 찾는 공격을 시도하였다.제안하는 전력 분석 공격 대상은 XMEGA128 8비트 프로세서 상에서 구현된 AES-128 암호 모듈이며, 16바이트의비밀 키 중 한 바이트씩 복구하는 방식으로 구현하였다. 실험 결과, MLP 기반의 전력 분석 공격은 89.51%의 정확도로 비밀 키를 추출하였으며 전처리 기법을 수행한 경우에는 94.51%의 정확도를 나타내었다. 제안하는 MLP 기반의 전력 분석 공격은 학습을 통한 feature를 추출할 수 있는 성질이 있어 SVM(Support Vector Machine)과 같은 머신 러닝 기반 모델보다 우수한 공격 특성을 보임을 확인하였다.","To overcome the difficulties and inefficiencies of the existing power analysis attack, we try to extract the secret keyembedded in a cryptographic device using attack model based on MLP(Multi-Layer Perceptron) method. The target of ourproposed power analysis attack is the AES-128 encryption module implemented on an 8-bit processor XMEGA128. We usethe divide-and-conquer method in bytes to recover the whole 16 bytes secret key. As a result, the MLP-based poweranalysis attack can extract the secret key with the accuracy of 89.51%. Additionally, this MLP model has the 94.51%accuracy when the pre-processing method on power traces is applied. Compared to the machine leaning-based modelSVM(Support Vector Machine), we show that the MLP can be a outstanding method in power analysis attacks due toexcellent ability for feature extraction."
Adam Optimizer를 이용한 음향매질 탄성파 완전파형역산,2019,"['Adam', 'optimization', 'steepest descent method', 'full waveform invers', 'Adam', '최적화', '최대 경사법', '탄성파 완전파형역산']","본 연구에서는 Adam 최적화 기법을 이용한 음향매질에서의 탄성파 파형역산 방법을 제안하였다. 탄성파 파형역산에서 최적화에 사용되는 기본적인 최대 경사법은 계산이 빠르고 적용이 간편하다는 장점이 있다. 하지만 속도 모델의갱신에 일정한 갱신 크기를 사용함에 따라 오차가 정확하게 수렴하지 않는다. 이에 대한 대안으로 제시된 다양한 최적화기법들의 경우 정확성은 높지만 많은 계산 시간을 필요로 한다는 한계가 있다. Adam 최적화 기법은 최근 딥 러닝 분야에서 학습 모델의 최적화를 위해 사용되는 기법으로 다양한 형태의 모델에 대한 최적화 문제에서 가장 효율적인 성능을보이고 있다. 따라서 Adam 최적화 기법을 이용한 파형역산 방법을 개발하여 탄성파 파형역산에서의 오차가 빠르고 정확하게 수렴하도록 하였다. 제안된 역산 기법의 성능을 검증하기 위해, 일정한 갱신 크기를 가지는 최대 경사법을 이용하여 수행된 역산 결과와 제안된 Adam 최적화 기반 파형역산을 수행하여 갱신된 P파 속도 모델을 비교하였다. 그 결과 제안된 기법을 통해 빠른 오차 수렴 속도와 높은 정확도의 결과를 확인할 수 있었다.","In this study, an acoustic full-waveform inversion using Adam optimizer was proposed. The steepest descent method, which is commonly used for the optimization of seismic waveform inversion, is fast and easy to apply, but the inverse problem does not converge correctly. Various optimization methods suggested as alternative solutions require large calculation time though they were much more accurate than the steepest descent method. The Adam optimizer is widely used in deep learning for the optimization of learning model. It is considered as one of the most effective optimization method for diverse models. Thus, we proposed seismic full-waveform inversion algorithm using the Adam optimizer for fast and accurate convergence. To prove the performance of the suggested inversion algorithm, we compared the updated P-wave velocity model obtained using the Adam optimizer with the inversion results from the steepest descent method.As a result, we confirmed that the proposed algorithm can provide fast error convergence and precise inversion results"
순환신경망 기법을 이용한 스파 플랫폼의 시계열데이터 필터링에 관한 연구,2019,"['데이터 필터링', '순환신경망', '시계열 데이터', '실시간', '필터링 기법', 'Data filtering', 'Recurrent neural network', 'Time series data', 'Real-time', 'Filtering methods']",스마트 선박 (Smart ship)의 개발과 해양 플랫폼의 예지보전 시스템 및 자산 관리 시스템 개발을 위해 방대한 양의계측 데이터를 실시간으로 분석할 수 있는 기술에 대한 관심이 높아지고 있다. 이러한 계측 데이터를 실시간으로 분석하기 위해서는 계측 데이터의 노이즈를 제거하고 필요한 정보를 추출하여 분석에 용이한 형태로 데이터를 가공하는 과정인 데이터 필터링이 반드시 선행되어야 한다. 기존의 조선 해양 산업에서는 일정기간 이상 데이터를 저장한 후 이에대한 분석을 실시하여 스펙트럼 기반의 필터링 기법을 많이 이용하였다. 이러한 방법은 실시간 데이터를 분석해야 하는현 상황에는 적합하지 않아 실시간 데이터를 필터링하기 위한 새로운 기법이 필요한 실정이다. 본 논문에서는 시계열데이터를 학습하기 위한 딥 러닝 모델인 순환신경망 알고리즘을 이용하여 실시간으로 전송되는 데이터를 필터링하고자하였다. 실시간으로 계측되는 스파 플랫폼의 계류 장력 값을 필터링하기 위해 순환신경망 알고리즘을 이용한 필터링 모델을 설계하고 그 결과값을 확인하여 실시간 필터링 가능 여부를 확인하였다. 최종적으로 실시간으로 전송되는 데이터를 필터링 하기 위해 순환신경망 알고리즘을 사용하는 것이 적합하다는 것을 확인하였다.,"There is growing interest in the numerous techniques focused on analyzing vast quantities of measurement data in real time for the development of smart ships along with the development of asset integrity management systems for offshore platforms. To analyze the measurement data in real time, data filtering is used to eliminate the noise in the data and then extract the necessary information to perform a comprehensive data analysis. In the traditional shipbuilding and offshore industry, spectrum-based filtering methods are used because the corresponding data is saved for a certain period and subsequently analyzed. These methods are not suited to the present situation in which real-time data is required to be analyzed. Therefore, a new method for data filtering is required. The objective of this study is to filter data in real time using a recurrent neural network algorithm, which is a deep learning model used for learning time series data. In order to filter the measured mooring tension value of the spa platform in real time, a filtering model comprising a recurrent neural network algorithm was designed, and the results of the data filtering process were verified to confirm the possibility of real- time filtering."
