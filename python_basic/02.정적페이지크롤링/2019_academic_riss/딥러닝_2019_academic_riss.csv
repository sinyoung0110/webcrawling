title,date,keywords,abstract,multilingual_abstract
딥러닝 기반 3차원 라이다의 반사율 세기 신호를 이용한 흑백 영상 생성 기법,2019,"['Artificial intelligence', 'Deep learning', 'Fully convolution network', 'Image generation', 'LiDAR sensor']",,"In this paper, we propose a method of generating a 2D gray image from LiDAR 3D reflection intensity. The proposed method uses the Fully Convolutional Network (FCN) to generate the gray image from 2D reflection intensity which is projected from LiDAR 3D intensity. Both encoder and decoder of FCN are configured with several convolution blocks in the symmetric fashion. Each convolution block consists of a convolution layer with 3×3 filter, batch normalization layer and activation function. The performance of the proposed method architecture is empirically evaluated by varying depths of convolution blocks. The well-known KITTI data set for various scenarios is used for training and performance evaluation. The simulation results show that the proposed method produces the improvements of 8.56 dB in peak signal-to-noise ratio and 0.33 in structural similarity index measure compared with conventional interpolation methods such as inverse distance weighted and nearest neighbor. The proposed method can be possibly used as an assistance tool in the night-time driving system for autonomous vehicles."
딥러닝을 활용한 에지 컴퓨팅 기반의 지능형 컨스트럭션 영상 관제 시스템,2019,"['edge computing', 'machine learning', 'deep learning', 'video management system', 'supervised learning']",,"With the development of artificial intelligence technology, artificial intelligence has begun to be applied in various fields. In particular, in each domain area of the industry, attempts are made to reduce costs or generate revenue by applying various artificial intelligence technologies in the existing service types. The intelligent construction video management system is an intelligent internet field live monitoring system that synchronizes noise, vibration, gas levels and on-site images at the site as quickly as possible and presents them online in the event of a civil complaint. Based on intelligent edge computing, this paper implements a system that automatically controls traffic transmitted from edge node to cloud efficiently in order to prevent overflow of field images stored in the cloud. Performance measurement results were checked with the implemented system and performance improvement was achieved with a traffic reduction rate of more than 10% compared to the previous one while maintaining the same quality of service. If the system is applied to small construction sites, it is expected to save some hundreds of thousands of won per month in communications costs."
딥러닝 기반 교량 손상추정을 위한 Generative Adversarial Network를 이용한 가속도 데이터 생성 모델,2019,"['Generative Adversarial Network', '생성모델', '손상추정기법', '디지털 트윈', '유지관리', 'Generative Adversarial Network', 'Generative Model', 'Damage Detection', 'Digital Twin', 'Maintenance']",,"Maintenance of aging structures has attracted societal attention. Maintenance of the aging structure can be efficiently performed with a digital twin. In order to maintain the structure based on the digital twin, it is required to accurately detect the damage of the structure. Meanwhile, deep learning-based damage detection approaches have shown good performance for detecting damage of structures. However, in order to develop such deep learning-based damage detection approaches, it is necessary to use a large number of data before and after damage, but there is a problem that the amount of data before and after the damage is unbalanced in reality.In order to solve this problem, this study proposed a method based on Generative adversarial network, one of Generative Model, for generating acceleration data usually used for damage detection approaches. As results, it is confirmed that the acceleration data generated by the GAN has a very similar pattern to the acceleration generated by the simulation with structural analysis software. These results show that not only the pattern of the macroscopic data but also the frequency domain of the acceleration data can be reproduced. Therefore, these findings show that the GAN model can analyze complex acceleration data on its own, and it is thought that this data can help training of the deep learning-based damage detection approaches."
딥러닝 기반의 농산물 가격 예측 시스템에 대한 연구,2019,"['agricultural price prediction system', 'deep learning', 'reinforcement learning', 'KAMIS']",,"This paper proposes a reinforcement learning model using agricultural price information as a deep learning-based agricultural price prediction system. Based on the information provided by KAMIS of the Korea Agro-Fisheries & Food Trade Corporation, information on price changes was collected and applied to the proposed system for the facilities crops that are not suitable for applying climate information. The proposed system consists of the environment, agents, policy neural networks and policy learners, which apply the LSTM neural network to calculate the probability of increasing revenue for sales and supply and demand activities. The simulation of the target agricultural products using the proposed system showed similar prediction results to the change of agricultural prices and showed a significant improvement compared to the existing complex agricultural price prediction techniques."
딥러닝 기반 실시간 손 제스처 인식,2019,"['Leap Motion', 'Deep Learning', 'VR', 'Gesture Recognition']",,"In this paper, we propose a real-time hand gesture recognition algorithm to eliminate the inconvenience of using hand controllers in VR applications. The user's 3D hand coordinate information is detected by leap motion sensor and then the coordinates are generated into two dimensional image. We classify hand gestures in real-time by learning the imaged 3D hand coordinate information through SSD(Single Shot multibox Detector) model which is one of CNN(Convolutional Neural Networks) models. We propose to use all 3 channels rather than only one channel. A sliding window technique is also proposed to recognize the gesture in real time when the user actually makes a gesture. An experiment was conducted to measure the recognition rate and learning performance of the proposed model. Our proposed model showed 99.88% recognition accuracy and showed higher usability than the existing algorithm."
딥러닝 기술을 적용한 운전자 맞춤형 긴급자동제동시스템 파라메터 추출,2019,"['customized autonomous emergency braking', 'deep neural network', 'braking propensity']",,"The autonomous emergency braking system is one of advanced driving assist systems. It is an advanced safety functiondesigned to prevent collision with a forward vehicle or a pedestrian in the event of driver’s carelessness or a sudden accident ahead.Because the AEB stops the vehicle with a maximum deceleration command at the last possible time to brake so that collision avoidance ispossible, it can prevent a collision with a preceding vehicle. However, there are risks of a secondary collision with a trailing vehicle andinjury to a passenger due to sharp deceleration. In addition, sudden braking control can present a driving feeling gap to the driver. Theseproblems must be solved because they can amplify a user's rejection of automatic emergency braking (AEB) and negatively affect theacceptability of this technology. In this study, the driver's braking propensity is derived by means of deep learning and it is applied to acustomized AEB system to prevent secondary accidents caused by sudden braking and to improve user acceptance. In order to derive adriver's braking behavior, normal driving data and stationary target based braking test data are collected. Utilizing a deep neural network,the driver’s braking profile during ordinary driving and a sudden stop are extracted. The correlation between the two extracted driver’sbraking behaviors is analyzed. This provides the means to derive sudden braking behavior as a function of driving speed, leading tocustomized AEB parameters."
딥러닝 기반 영상 주행기록계와 단안 깊이 추정 및 기술을 위한 벤치마크,2019,"['Visual Odomtery', 'Monocualr Depth Estimation', 'Deep Learning']",,"This paper presents a new benchmark system for visual odometry (VO) and monocular depth estimation (MDE). As deep learning has become a key technology in computer vision, many researchers are trying to apply deep learning to VO and MDE. Just a couple of years ago, they were independently studied in a supervised way, but now they are coupled and trained together in an unsupervised way. However, before designing fancy models and losses, we have to customize datasets to use them for training and testing. After training, the model has to be compared with the existing models, which is also a huge burden. The benchmark provides input dataset ready-to-use for VO and MDE research in ‘tfrecords’ format and output dataset that includes model checkpoints and inference results of the existing models. It also provides various tools for data formatting, training, and evaluation. In the experiments, the exsiting models were evaluated to verify their performances presented in the corresponding papers and we found that the evaluation result is inferior to the presented performances."
딥러닝 기반의 보행자 탐지 및 경보 시스템 연구,2019,"['Pedestrian traffic accident prevention', 'CNN', 'YOLO', 'ITS', 'UTIS', '보행자 교통사고 방지', 'CNN', 'YOLO', '지능형 교통시스템 체계', 'UTIS']","보행자 교통사고의 경우 사고 발생 시 사망사고로 연결되는 위험성이 있다. 국내 지능형교통시스템(ITS)은 질 좋은 교통 인프라를 구축하고 있음에도 불구하고, 거의 교통정보 수집에만 이용되고 있어, 위험상황 발생 시 지능적인 위험 요소 분류가 이루어지지 않고 있다. 본 연구에서 제안하는 시스템의 주요 구성 요소인 CNN 기반의 보행자 탐지 분류 모델의 경우 제한적인 환경에서 설치 운영되는 것을 가정하여 임베디드 시스템 기반으로 구현되었다. 기존YOLO의 인공신경망 모델을 개선하여 My-Tiny-Model3라는 새로운 모델을 생성하였고, 20,000 번의 반복 학습 기준으로 평균 정확도 86.29%와 21.1 fps의 실시간 탐지 속도 결과를 보였다.그리고, 이러한 탐지 시스템을 기반으로 하여 ITS 체계와 연계 가능한 시스템 구현 및 프로토콜 연동 시나리오를 구성하였다. 본 연구를 통해 기존 ITS 체계와 연동하는 보행자 사고 방지시스템을 구현한다면, 새로운 인프라 구축비용을 절감하고 보행자 교통사고 발생률을 줄이는데 도움이 될 것이다. 또한, 기존의 시스템 감시인력 소요에 따른 비용 또한 줄일 수 있을 것으로 기대된다.","In the case of a pedestrian traffic accident, it has a large-scale danger directly connected by a fatal accident at the time of the accident. The domestic ITS is not used for intelligent risk classification because it is used only for collecting traffic information despite of the construction of good quality traffic infrastructure. The CNN based pedestrian detection classification model, which is a major component of the proposed system, is implemented on an embedded system assuming that it is installed and operated in a restricted environment. A new model was created by improving YOLO's artificial neural network, and the real-time detection speed result of average accuracy 86.29% and 21.1 fps was shown with 20,000 iterative learning. And we constructed a protocol interworking scenario and implementation of a system that can connect with the ITS. If a pedestrian accident prevention system connected with ITS will be implemented through this study, it will help to reduce the cost of constructing a new infrastructure and reduce the incidence of traffic accidents for pedestrians, and we can also reduce the cost for system monitoring."
딥러닝을 이용한 번호판 검출과 인식 알고리즘,2019,"['License Plate', 'SVM', 'Machine Learning', 'Deep Learning', 'Intelligent Transportation System']",최근 지능형 교통관제 시스템에 관한 다양한 연구가 진행되고 있는 가운데 번호판 검출과 인식 알고리즘은 가장 중요한요소 중에 하나로 대두되고 있다. 번호판은 차량의 고유 식별값을 가지고 있기 때문이다. 기존의 차량 통행 관제 시스템은정차를 기반으로 하고 있으며 차량의 입출입 인식 방법으로 루프 코일을 사용하고 있다. 이러한 방법은 교통 정체를 유발하고 유지보수 비용이 상승하는 단점을 가지고 있다. 본 논문에서는 이러한 문제점을 해결하기 위해서 차량의 입출입 인식 방법으로 카메라 영상을 사용한다. 차량 통행 관제 시스템의 특성상 카메라가 고정되어 있다. 이에 차량이 접근하면 카메라의배경화면이 달라진다. 이 특징을 이용하여 배경화면의 차분영상을 구하면 차량의 입출입을 인식할 수 있다. 입출입 인식 후한국 번호판의 형태학적 특성을 이용하여 후보 이미지를 추정한다. 그리고 선형 SVM(Support Vector Machine)을 이용해서최종 번호판을 검출한다. 검출한 번호판의 글자와 숫자 인식 방법으로는 CNN(Convolutional Neural Network) 알고리즘을사용한다. 제안한 알고리즘은 기존의 시스템과 달리 검출 위치를 기준으로 글자와 숫자를 인식하기 때문에 번호판의 규격이변해도 인식할 수 있다. 실험한 결과 기존의 번호판 인식 알고리즘들 보다 제안한 알고리즘이 더 높은 인식률을 가진다.,"One of the most important research topics on intelligent transportation systems in recent years is detecting andrecognizing a license plate. The license plate has a unique identification data on vehicle information. The existing vehicletraffic control system is based on a stop and uses a loop coil as a method of vehicle entrance/exit recognition. Themethod has the disadvantage of causing traffic jams and rising maintenance costs. We propose to exploit differentialimage of camera background instead of loop coil as an entrance/exit recognition method of vehicles. After entrance/exitrecognition, we detect the candidate images of license plate using the morphological characteristics. The license plate canfinally be detected using SVM(Support Vector Machine). Letter and numbers of the detected license plate are recognizedusing CNN(Convolutional Neural Network). The experimental results show that the proposed algorithm has a higherrecognition rate than the existing license plate recognition algorithm."
딥러닝 설명을 위한 슈퍼픽셀 제외·포함 다중스케일 접근법,2019,[],,"As deep learning has become popular, researches which can help explaining the prediction results also become important. Superpixel based multi-scale combining technique, which provides the advantage of visual pleasing by maintaining the shape of the object, has been recently proposed. Based on the principle of prediction difference, this technique computes the saliency map from the difference between the predicted result excluding the superpixel and the original predicted result. In this paper, we propose a new technique of both excluding and including super pixels. Experimental results show 3.3% improvement in IoU evaluation."
딥러닝 알고리즘과 2D Lidar 센서를 이용한 이미지 분류,2019,"['Deep learning', 'deep learning neural network', 'convolutional neural network', 'object detection', 'image classification']","본 논문은 CNN (Convolutional Neural Network)와 2D Lidar 센서에서 획득한 위치 데이터를 이용하여 이미지를 분류하는 방법을 제시한다. Lidar 센서는 데이터 정확도, 형상 왜곡 및 광 변화에 대한 강인성 측면에서의 이점으로 인해 무인 장치에 널리 사용되어 왔다. CNN 알고리즘은 하나 이상의 컨볼루션 및 풀링 레이어로 구성되며 이미지 분류에 만족스러운 성능을 보여 왔다. 본 논문에서는 학습 방법에 따라 다른 유형의 CNN 아키텍처들인 Gradient Descent (GD) 및 Levenbergarquardt(LM)를 구현하였다. LM 방법에는 학습 파라메터를 업데이트하는 요소 중 하나인 Hessian 행렬 근사 빈도에 따라 두 가지 유형이 있다. LM 알고리즘의 시뮬레이션 결과는 GD 알고리즘보다 이미지 데이터의 분류 성능이 우수하였다. 또한 Hessian 행렬 근사가 더 빈번한 LM 알고리즘은 다른 유형의 LM 알고리즘보다 작은 오류를 보여주었다.","This paper presents an approach for classifying image made by acquired position data from a 2D Lidar sensor with a convolutional neural network (CNN). Lidar sensor has been widely used for unmanned devices owing to advantages in term of data accuracy, robustness against geometry distortion and light variations. A CNN algorithm consists of one or more convolutional and pooling layers and has shown a satisfactory performance for image classification. In this paper, different types of CNN architectures based on training methods, Gradient Descent(GD) and Levenbergarquardt(LM), are implemented. The LM method has two types based on the frequency of approximating Hessian matrix, one of the factors to update training parameters. Simulation results of the LM algorithms show better classification performance of the image data than that of the GD algorithm. In addition, the LM algorithm with more frequent Hessian matrix approximation shows a smaller error than the other type of LM algorithm."
딥러닝을 이용한 당뇨성황반부종 등급 분류의 정확도 개선을 위한 검증 데이터 증강 기법,2019,"['deep learning', 'Validation data augmentation', 'Diagnostic accuracy', 'Diabetic macular edema']",,"This paper proposed a method of validation data augmentation for improving the grading accuracy of diabetic macular edema (DME) using deep learning. The data augmentation technique is basically applied in order to secure diversity of data by transforming one image to several images through random translation, rotation, scaling and reflection in preparation of input data of the deep neural network (DNN). In this paper, we apply this technique in the validation process of the trained DNN, and improve the grading accuracy by combining the classification results of the augmented images. To verify the effectiveness, 1,200 retinal images of Messidor dataset was divided into training and validation data at the ratio 7:3. By applying random augmentation to 359 validation data, 1.61 ± 0.55% accuracy improvement was achieved in the case of six times augmentation (N=6). This simple method has shown that the accuracy can be improved in the N range from 2 to 6 with the correlation coefficient of 0.5667. Therefore, it is expected to help improve the diagnostic accuracy of DME with the grading information provided by the proposed DNN."
딥러닝과 전이학습을 이용한 콘크리트 균열 인식 및 시각화,2019,"['Deep Learning', 'transfer learning', 'concrete crack', 'visualization']",,"Although crack on concrete exists from its early formation, crack requires attention as it affects stiffness of structure and can lead demolition of structure as it grows. Detecting cracks on concrete is needed to take action prior to performance degradation of structure, and deep learning can be utilized for it. In this study, transfer learning, one of the deep learning techniques, was used to detect the crack, as the amount of crack’s image data was limited. Pre-trained Inception-v3 was applied as a base model for the transfer learning. Web scrapping was utilized to fetch images of concrete wall with or without crack from web. In the recognition of crack, image post-process including changing size or removing color were applied. In the visualization of crack, source images divided into 30px, 50px or 100px size were used as input data, and different numbers of input data per category were applied for each case. With the results of visualized crack image, false positive and false negative errors were examined. Highest accuracy for the recognizing crack was achieved when the source images were adjusted into 224px size under gray-scale. In visualization, the result using 50 data per category under 100px interval size showed the smallest error. With regard to the false positive error, the best result was obtained using 400 data per category, and regarding to the false negative error, the case using 50 data per category showed the best result."
딥러닝 기반의 복합 열화 영상 분류 및 복원 기법,2019,"['Deep learning', 'Multi-Degradation', 'Degradation Classification', 'Restoration order', 'Restoration']","CNN (convolutional neural network) 기반의 단일 열화 영상 복원 방법은 우수한 성능을 나타내지만 한가지의 특정 열화를 해결하는 데 맞춤화 되어있다. 본 연구에서는 복합적으로 열화 된 영상 분류 및 복원을 위한 알고리즘을 제시한다. 복합 열화 영상 분류 문제를 해결하기 위해 CNN 기반의 알고리즘인 사전 학습된 Inception-v3 네트워크를 활용하고, 영상 열화 복원을 위해 기존의 CNN 기반의 복원 알고리즘을 사용하여 툴체인을 구성한다. 실험적으로 복합 열화 영상의 복원 순서를 추정하였으며, CNN 기반의 영상 화질 측정 알고리즘의 결과와 비교하였다. 제안하는 알고리즘은 추정된 복원 순서를 바탕으로 구현되어 실험 결과를 통해 복합 열화 문제를 효과적으로 해결할 수 있음을 보인다.",
딥러닝 기술을 이용한 트러스 구조물의 손상 탐지,2019,"['Damage detection', 'Deep learning', 'Neural network', 'Truss structure']",,"There has been considerable recent interest in deep learning techniques for structural analysis and design. However, despite newer algorithms and more precise methods have been developed in the field of computer science, the recent effective deep learning techniques have not been applied to the damage detection topics. In this study, we have explored the structural damage detection method of truss structures using the state-of-the-art deep learning techniques. The deep neural networks are used to train knowledge of the patterns in the response of the undamaged and the damaged structures. A 31-bar planar truss are considered to show the capabilities of the deep learning techniques for identifying the single or multiple-structural damage. The frequency responses and the elasticity moduli of individual elements are used as input and output datasets, respectively. In all considered cases, the neural network can assess damage conditions with very good accuracy."
딥러닝을 활용한 반도체 제조 물류 시스템 통행량 예측모델 설계,2019,"['Semiconductor', 'prediction model', 'AutoMod', 'deep learning']",,"Semiconductor logistics systems are facing difficulties in increasing production as production processes become more complicated due to the upgrading of fine processes. Therefore, the purpose of the research is to design predictive models that can predict traffic during the pre-planning stage, identify the risk zones that occur during the production process, and prevent them in advance. As a solution, we build FABs using automode simulation to collect data. Then, the traffic prediction model of the areas of interest is constructed using deep learning techniques (keras - multistory conceptron structure). The design of the predictive model gave an estimate of the traffic in the area of interest with an accuracy of about 87%. The expected effect can be used as an indicator for making decisions by proactively identifying congestion risk areas during the Fab Design or Factory Expansion Planning stage, as the maximum traffic per section is predicted."
딥러닝을 이용한 야간 감시 열화상 카메라 개발에 관한 연구,2019,"['Thermal camera', 'Infrared', 'Deep learning', 'CNN', 'YOLO']",,
딥러닝을 이용한 시스템식별에 관한 연구,2019,"['Deep learing', 'Deep belief network', 'PID control', 'Time delay', 'Pade’ Aproximaion', 'System identification', 'Controller tuning']",,"This paper deals with a study on a system identification using deep learning in the case of a controller tuning for the system where a time delay exists. Of studies on the controller tuning for the system identification, the controller tuning method suggested by Yunwana and Seborg(1982) has an advantage of taking a good control over either none or small time delays due to phase error by Pade' approximation, whereas it comes with a disadvantage of having a greater estimated of time delay over the presence of a large time delay and of being unable to be used in a system. Furthermore, the trial-and-error method suggested by Zigler-Nichols and commonly used in industrial fields shows a disadvantage which is time consuming for a controller tuning. The controller tuning using a process response curve suggested by Cohen-Coon has a benefit of cutting more time taken for a controller tuning than the method by Zigler-Nichols does. It also faces a limitation of being applicable only to the open loop system but not applicable to the close loop system. To make up for these disadvantages, the Suh-suggested method, as its benefit, is applicable even to the close loop system. On top of this, it proposed a controller's optimal tuning method by reducing phase error through setting up control factors in the Pade' approximation with respect to the phase error generated in converting time delay into Pade' approximation. This method, however, involves putting control factors in proportion to time-delay constant values, which is therefore - as a disadvantage - not analytical. This paper went through a theoretical analysis on phase error as an analytical method to solve an issue involving the large estimation of phase error by Pade' approximation and time delay with the use of deep learning. Presented based on the findings of this existing researcher Suh (1984) was a new optimal tuning method dedicated to reducing phase error to a optimal level by setting control factors using the deep belief network algorithm out of deep learning algorithms. Besides, a related simulation was performed to compare the trial-and-error method by Zielger-Nichols and the tuning method for a controller suggested by Yunwana-Seborg, and the validity of the methods suggested in this paper was verified, accordingly."
딥러닝을 통한 차등간격의 조향각 노드 결정에 의한 자율주행,2019,"['CNN (convolution neural network)', 'non-uniform steering angle intervals', 'autonomous driving', 'deep learning']",,"In this work, an autonomous driving model using only one camera was implemented by combining a CNN (ConvolutionalNeural networks) and a YOLO (You Only Look Once) framework. Hyper-parameters in the structure were adjusted to improve drivingperformance. Autonomous driving in a corridor was performed by applying the improved model. An appropriate dropout and deeplearning structure associated with non-uniform steering angle intervals as output is proposed. The proposed algorithm was implemented,and through experiments resulted in successful obstacle avoidance and stable driving."
딥러닝을 활용한 상실치아 수 예측의 가능성: 파일럿 스터디,2019,"['Deep learning', 'Linear regression', 'Missing teeth', 'Real-time PCR', 'Periodontitis']",,"Objectives: The primary objective of this study was to determine if the number of missing teeth could be predicted by oral disease pathogens, and the secondary objective was to assess whether deep learning is a better way of predicting the number of missing teeth than multivariable linear regression (MLR).Methods: Data were collected through review of patient’s initial medical records. A total of 960 participants were cross-sectionally surveyed. MLR analysis was performed to assess the relationship between the number of missing teeth and the results of real-time PCR assay (done for quantification of 11 oral disease pathogens). A convolutional neural network (CNN) was used as the deep learning model and compared with MLR models. Each model was performed five times to generate an average accuracy rate and mean square error (MSE). The accuracy of predicting the number of missing teeth was evaluated and compared between the CNN and MLR methods.Results: Model 1 had the demographic information necessary for the prediction of periodontal diseases in addition to the red and the orange complex bacteria that are highly predominant in oral diseases. The accuracy of the convolutional neural network in this model was 65.0%. However, applying Model 4, which added yellow complex bacteria to the total bacterial load, increased the expected extractions of dental caries to 70.2%.On the other hand, the accuracy of the MLR was about 50.0% in all models. The mean square error of the CNN was considerably smaller than that of the MLR, resulting in better predictability.Conclusions: Oral disease pathogens can be used as a predictor of missing teeth and deep learning can be a more accurate analysis method to predict the number of missing teeth as compared to MLR."
딥러닝을 이용한 IOT 기기 인식 시스템,2019,"['See-Thru Communication', 'Deep Learning', 'Convolutional Neural Network', 'Transfer Learning']",,"As the number of IOT devices is growing rapidly, various ‘see-thru connection’ techniques have been reported for efficient communication with them. In this paper, we propose a deep learning based IOT device recognition system for interaction with these devices. The overall system consists of a TensorFlow based deep learning server and two Android apps for data collection and recognition purposes. As the basic neural network model, we adopted Google’s inception-v3, and modified the output stage to classify 20 types of IOT devices. After creating a data set consisting of 1000 images of 20 categories, we trained our deep learning network using a transfer learning technology. As a result of the experiment, we achieve 94.5% top-1 accuracy and 98.1% top-2 accuracy."
딥러닝과 ICP 알고리즘을 이용한 링 모양의소형 빈피킹 물체의 실시간 3차원 자세 추정,2019,"['bin picking', 'pose estimation', 'deep learning', 'object detection']",,"Bin picking is an important task in smart manufacturing and intelligent robotics. For a robot to pick or grip an object with ahuman-like gripping action, it needs to know the accurate 3D pose of the object. In this paper, we propose a method for estimating the 3Dpose of a small ring-shaped object using infrared and depth images generated by a depth camera. The proposed method consists of twoalgorithm modules, the first to recognize an object in a 2D infrared image and the second to estimate the 3D pose by applying the ICP(iterative closest point) algorithm to 3D depth data. In the first module, we propose a method to generate a three-channel integrated imagewith features from the depth and infrared images. Next, we introduce a method for training an object detector based on deep-learning.Because the bin-picking test object in this paper is small and ring-shaped, it is difficult to detect and find 3D poses of individual objectswhen many such objects are piled up. We solved this problem with a depth-based filtering method. Using the filtered image, each objectregion is separated by the deep learning approach. In the second module, the ICP algorithm is employed to estimate the 3D pose of the ringobject. We match a 3D reference model of the object and the real object using the point-to-point ICP algorithm. Performance of theproposed method is evaluated by using two different types of depth camera in the experiments."
딥러닝 모델 기반 단기 전력수요 예측,2019,"['Deep Learning', 'Short-Term Load Forecasting', 'CNN', 'LSTM']",,"This paper presents a Short-Term Long-short term memory Convolutional neural network(STLC) Model that is combined with Convolutional Neural Network(CNN) and Long-Short Term Memory(LSTM). CNN model predicts load pattern using past load profile, LSTM model forecasts load variation depending on temperature and time index. STLC model’s output is hourly load data to combine two model’s outputs. The input parameters of STLC model are composed of time index, weighted weather data, past load data. Weights are calculated based on electricity consumption by main region in South Korea and reflects in the weather data. STLC model is trained with data from 2013 through 2017 and is verified with data from 2018. The STLC model forecasts 1-day hourly load data. Simulation results obtained show the comparison of actual and forecasted load data and also compare with other methods in MAPE(Mean Absolute Percentage Error) to prove accuracy of the proposed model."
딥러닝을 이용한 셰익스피어 작품의 감정 분석,2019,"['sentiment analysis', 'deep learning', 'Shakespeare', 'tweeter data']",,"This study examined the sentiment movement of Shakespeare’s plays (four tragedies and five comedies) using a deep learning technique. Sentiment analyses have been used in several fields to extract aspects of opinions using sentiment dictionaries such as ANEW, AFFINE, and VADER, which involve an evaluation of a word list for sentiment analysis. Nowadays, however, as deep learning algorithms develop, it became possible to conduct a sentiment analysis by using deep learning algorithms. This study directly compared the output of a simple deep learning model (trained with tweeters) with the output of a sentiment dictionary, VADER, targeting Shakespeare’s plays. The results showed that the simple deep learning model led to a similar performance with VADER for Shakespeare’s tragedies and outperformed the sentiment dictionary especially for Shakespeare’s comedies."
고속 딥러닝 알고리즘의 효과적인 구현,2019,"['Artificial intelligence', 'Deep learning', 'Digital signal processing', 'Image classification', 'Keras', 'Tensorflow']",,"AI (Artificial Intelligence) based on deep learning has been successful in many application areas. Supervised learning such as image classification and object detection has been mainly used for vision and ADAS (Advanced Driver Assistance Systems) / AD (Autonomous Driving). And reinforce learning has been generally utilized for robotics and energy optimization. Therefore, in order to improve the performance, many research papers have focused on optimizing neural networks. However, in practice, FPS (frame per second) is a hidden and critical factor because FPS is also included in the performance measurement. This note show that pre-processing and post-processing are major components affecting FPS. And It is verified that FPS cannot be improved by optimizing the neural network itself because the pre-processing and post-processing are out of the neural networks. In this note, fast pre-processing methods on the basis of DSP (digital signal processing) is suggested. For DSP implementation, binary arithmetic is presented and quantization error due to the conversion from floating point calculation to fixed point calculation is discussed. In addition, major design frameworks for deep learning algorithm implementation are compared and their merit and demerit are also summarized. In the note, implementation is categorized into three, i.e., input data generation with pre-processing, model design of neural network, and performance evaluation. With the selected framework, detailed implementation is also presented."
트랜잭션 기반 머신러닝에서 특성 추출 자동화를 위한 딥러닝 응용,2019,"['Machine Learning', 'Deep Learning', 'Feature Engineering', 'Automated Feature Extraction', 'Transaction Data']",,"Machine learning (ML) is a method of fitting given data to a mathematical model to derive insights or to predict. In the age of big data, where the amount of available data increases exponentially due to the development of information technology and smart devices, ML shows high prediction performance due to pattern detection without bias. The feature engineering that generates the features that can explain the problem to be solved in the ML process has a great influence on the performance and its importance is continuously emphasized. Despite this importance, however, it is still considered a difficult task as it requires a thorough understanding of the domain characteristics as well as an understanding of source data and the iterative procedure. Therefore, we propose methods to apply deep learning for solving the complexity and difficulty of feature extraction and improving the performance of ML model. Unlike other techniques, the most common reason for the superior performance of deep learning techniques in complex unstructured data processing is that it is possible to extract features from the source data itself. In order to apply these advantages to the business problems, we propose deep learning based methods that can automatically extract features from transaction data or directly predict and classify target variables. In particular, we applied techniques that show high performance in existing text processing based on the structural similarity between transaction data and text data. And we also verified the suitability of each method according to the characteristics of transaction data. Through our study, it is possible not only to search for the possibility of automated feature extraction but also to obtain a benchmark model that shows a certain level of performance before performing the feature extraction task by a human. In addition, it is expected that it will be able to provide guidelines for choosing a suitable deep learning model based on the business problem and the data characteristics."
컴퓨터 비전과 딥러닝을 통한 견종식별 연구,2019,"['Computer Vision', 'Deep Learning', 'Companion Animal']",,
LSTM과 GRU 딥러닝 IoT 파워미터 기반의 단기 전력사용량 예측,2019,"['Power Meter', 'Internet of Things', 'Deep Learning', 'LSTM', 'GRU', 'Short-term Power Forecasting']","본 연구에서는 Long Short Term Memory (LSTM) 신경망과 Gated Recurrent Unit(GRU) 신경망을Internet of Things (IoT) 파워미터에 적용하여 단기 전력사용량 예측방법을 제안하고, 실제 가정의 전력사용량 데이터를 토대로 예측 성능을 분석한다. 성능평가 지표로써 Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE), Mean Percentage Error (MPE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE) 를 이용한다. 실험 결과는 GRU 기반의 모델이 LSTM 기반의 모델에 비해 MAPE 기준으로 4.52%, MPE 기준으로5.59%만큼의 성능개선을 보였다.","In this paper, we propose a short-term power forecasting method by applying Long Short Term Memory (LSTM) and Gated Recurrent Unit (GRU) neural network to Internet of Things (IoT) power meter.We analyze performance based on real power consumption data of households. Mean absolute error (MAE), mean absolute percentage error (MAPE), mean percentage error (MPE), mean squared error (MSE), and root mean squared error (RMSE) are used as performance evaluation indexes. The experimental results show that the GRU-based model improves the performance by 4.52% in the MAPE and 5.59% in the MPE compared to the LSTM-based model."
소프트맥스를 이용한 딥러닝 음악장르 자동구분 투표 시스템,2019,[],,"Research that implements the classification process through Deep Learning algorithm, one of the outstanding human abilities, includes a unimodal model, a multi-modal model, and a multi-modal method using music videos. In this study, the results were better by suggesting a system to analyze each song's spectrum into short samples and vote for the results. Among Deep Learning algorithms, CNN showed superior performance in the category of music genre compared to RNN, and improved performance when CNN and RNN were applied together. The system of voting for each CNN result by Deep Learning a short sample of music showed better results than the previous model and the model with Softmax layer added to the model performed best. The need for the explosive growth of digital media and the automatic classification of music genres in numerous streaming services is increasing. Future research will need to reduce the proportion of undifferentiated songs and develop algorithms for the last category classification of undivided songs."
임베디드 GPU에서의 딥러닝 기반 실시간 보행자 탐지 기법,2019,"['Pedestrian detection', 'convolutional neural network', 'embedded system']","본 논문은 임베디드 GPU에서 실시간 동작하는 딥 컨볼루션 뉴럴 네트워크(CNN) 기반의 보행자 탐지 기법을 제안한다. 제안하는 기법에서는 먼저 영상 내 보행자 크기에 대한 통계적 분석을 통해서 최적의 컨볼루션 층의 개수를 결정한다. 또한, 본 논문에서는 다중 스케일 CNN 학습 기법을 적용하여 영상 내의 보행자 크기 변화에 강인한 탐지 기법을 개발한다. 컴퓨터 모의실험을 통해 제안하는 알고리즘이 임베디드 GPU에서 실시간 동작하면서도 기존의 기법과 비교하여 평균적으로 높은 정확도를 보임을 확인한다.",
GAN과 DNN을 활용한 딥러닝 기반의 지능형 개인신용 평가모형,2019,"['FinTech', 'Deep Learning', 'Imbalance Data', 'GAN', 'DNN']",,"data using machine learning techniques such as decision trees, neural networks, deep learning, and GAN. We develop a personal credit rating model to resolve an issue from imbalanced data for machine learning by utilized the SMOTE and GAN. Personal credit rating is an important system for personal loans such as FinTech, and has been applied with many deep learning techniques. Therefore, the purpose of this study is to develop an intelligent personal credit rating model based on deep learning that can be effectively used in a small data set. Therefore, in this study, 5 samples of 10,000 data sets are sampled and the size of the data set is increased by utilizing the SMOTE and GAN, which is an over sampling technique. We applied classification techniques such as logit, decision tree, ANN, and DNN. Then, to solve the imbalanced data problems, we applied under sampling, SMOTE, and GAN, and compared which the performance of statistical techniques, machine learning, and deep learning. As a result, deep learning based on personal credit rating model of SMOTE + DNN showed the highest performance with 66.2%."
현실 환경에서 증강현실과 딥러닝을 활용한 M&S 모델 증강가시화,2019,"['Modeling & Simulation (M&S)', 'Augmented reality', 'Deep learning', 'Visual augmentation']",,"This paper proposes a new method to effectively visualize modeling & simulation (M&S) results in a real environment using augmented reality (AR) and deep learning. The proposed approach makes it possible to dynamically generate an M&S analysis space of the real environment, to recognize real objects by using a deep learning technique, and to place the analyzed M&S results onto them. In order to construct an M&S space dynamically, we perform area learning on the real space using a smart device supporting RGB-D camera. In addition, real objects are recognized through deep learning-based object detection. Spatial mapping and user interaction are conducted to match the recognized real object with corresponding M&S model in the mobile AR environment. A proof-of-concept system was developed to show the advantage and feasibility of the proposed method. Therefore, the proposed approach can be used for seamlessly integrating M&S models into various real spaces and for reviewing M&S results more consistently and effectively."
효과적인 인간-로봇 상호작용을 위한 딥러닝 기반 로봇 비전 자연어 설명문 생성 및 발화 기술,2019,"['Human-Robot Interaction', 'Video To Audio Description', 'Video Captioning', 'Speech Synthesis', 'Text To Speech']",,"For effective human-robot interaction, robots need to understand the current situation context well, but also the robots need to transfer its understanding to the human participant in efficient way. The most convenient way to deliver robot’s understanding to the human participant is that the robot expresses its understanding using voice and natural language. Recently, the artificial intelligence for video understanding and natural language process has been developed very rapidly especially based on deep learning. Thus, this paper proposes robot vision to audio description method using deep learning. The applied deep learning model is a pipeline of two deep learning models for generating natural language sentence from robot vision and generating voice from the generated natural language sentence. Also, we conduct the real robot experiment to show the effectiveness of our method in human-robot interaction."
잡음제거 모델 훈련을 위한 딥러닝 기반 가상 데이터베이스 생성 기법,2019,"['Deep neural network', 'virtual noisy database', 'real environment', 'denoising', 'ideal ratio mask']",,
영상기반 콘크리트 균열 탐지 딥러닝 모델의 유형별 성능 비교,2019,"['crack detection', 'deep learning', 'image classification', 'object detection', 'semantic segmentation', 'instance segmentation']",,"In this study, various types of deep learning models that have been proposed recently are classified according to data input / output types and analyzed to find the deep learning model suitable for constructing a crack detection model. First the deep learning models are classified into image classification model, object segmentation model, object detection model, and instance segmentation model. ResNet-101, DeepLab V2, Faster R-CNN, and Mask R-CNN were selected as representative deep learning model of each type. For the comparison, ResNet-101 was implemented for all the types of deep learning model as a backbone network which serves as a main feature extractor. The four types of deep learning models were trained with 500 crack images taken from real concrete structures and collected from the Internet. The four types of deep learning models showed high accuracy above 94% during the training.Comparative evaluation was conducted using 40 images taken from real concrete structures. The performance of each type of deep learning model was measured using precision and recall. In the experimental result, Mask R-CNN, an instance segmentation deep learning model showed the highest precision and recall on crack detection.Qualitative analysis also shows that Mask R-CNN could detect crack shapes most similarly to the real crack shapes."
알약 자동 인식을 위한 딥러닝 모델간 비교 및 검증,2019,"['Pill Classification', 'Object Detection', 'Deep Learning', 'Artificial Intelligent', 'Hospital']",,"When a prescription change occurs in the hospital depending on a patient’s improvement status, pharmacists directly classify manually returned pills which are not taken by a patient. There are hundreds of kinds of pills to classify. Because it is manual, mistakes can occur and which can lead to medical accidents. In this study, we have compared YOLO, Faster R-CNN and RetinaNet to classify and detect pills. The data consisted of 10 classes and used 100 images per class. To evaluate the performance of each model, we used cross-validation. As a result, the YOLO Model had sensitivity of 91.05%, FPs/image of 0.0507. The Faster R-CNN’s sensitivity was 99.6% and FPs/image was 0.0089. The RetinaNet showed sensitivity of 98.31% and FPs/image of 0.0119. Faster RCNN showed the best performance among these three models tested. Thus, the most appropriate model for classifying pills among the three models is the Faster R-CNN with the most accurate detection and classification results and a low FP/image."
수신된 전파신호의 자동 변조 인식을 위한 딥러닝 방법론,2019,[],,"The automatic modulation recognition of a radio signal is a major task of an intelligent receiver, with various civilian and military applications. In this paper, we propose a method to recognize the modulation of radio signals in wireless communication based on the deep neural network. We classify the modulation pattern of radio signal by using the LSTM model, which can catch the long-term pattern for the sequential data as the input data of the deep neural network. The amplitude and phase of the modulated signal, the in-phase carrier, and the quadrature-phase carrier are used as input data in the LSTM model. In order to verify the performance of the proposed learning method, we use a large dataset for training and test, including the ten types of modulation signal under various signal-to-noise ratios."
시간에 따라 변화하는 빗줄기 장면을 이용한 딥러닝 기반 비지도 학습 빗줄기 제거 기법,2019,"['Rain Streak Removal', 'Unsupervised Learning', 'Convolutional Neural Networks', 'Siamese Network']",,"Single image rain removal is a typical inverse problem which decomposes the image into a background scene and a rain streak. Recent works have witnessed a substantial progress on the task due to the development of convolutional neural network (CNN). However, existing CNN-based approaches train the network with synthetically generated training examples. These data tend to make the network bias to the synthetic scenes. In this paper, we present an unsupervised framework for removing rain streaks from real-world rainy images. We focus on the natural phenomena that static rainy scenes capture a common background but different rain streak. From this observation, we train siamese network with the real rain image pairs, which outputs identical backgrounds from the pairs. To train our network, a real rainy dataset is constructed via web-crawling. We show that our unsupervised framework outperforms the recent CNN-based approaches, which are trained by supervised manner. Experimental results demonstrate that the effectiveness of our framework on both synthetic and real-world datasets, showing improved performance over previous approaches."
SNS에서 텍스트-칼라영상의 교차양식 검색을 위한 데이터셋 구축과 딥러닝 모델,2019,"['Cross Modal Retrieval', 'Social Network Service(SNS)', 'Text-Image Dataset', 'Deep Learning', 'Computer Vision']",,
심실 조기 수축 비트 검출을 위한 딥러닝 기반의 최적 파라미터 검출,2019,['RR'],,"Legacy studies for classifying arrhythmia have been studied to improve the accuracy of classification, Neural Network, Fuzzy, etc. Deep learning is most frequently used for arrhythmia classification using error backpropagation algorithm by solving the limit of hidden layer number, which is a problem of neural network. In order to apply a deep learning model to an ECG signal, it is necessary to select an optimal model and parameters. In this paper, we propose optimal parameter extraction method based on a deep learning. For this purpose, R-wave is detected in the ECG signal from which noise has been removed, QRS and RR interval segment is modelled. And then, the weights were learned by supervised learning method through deep learning and the model was evaluated by the verification data. The detection and classification rate of R wave and PVC is evaluated through MIT-BIH arrhythmia database. The performance results indicate the average of 99.77% in R wave detection and 97.84% in PVC classification."
도로포장의 유지관리 계획 수립을 위한 딥러닝 기반 열화 예측 모델 개발,2019,"['Pavement Deterioration Prediction', 'Deep Learning', 'Recurrent Neural Network', 'Long Short-Term Memory', 'Deep Neural Network']",,"The maintenance cost for road pavement is gradually increasing due to the continuous increase in road extension as well as increase in the number of old routes that have passed the public period. As a result, there is a need for a method of minimizing costs through preventative grievance preventive maintenance requires the establishment of a strategic plan through accurate prediction of road pavement. Hence, In this study, the deep neural network(DNN) and the recurrent neural network(RNN) were used in order to develop the expressway pavement damage prediction model. A superior model among these two network models was then suggested by comparing and analyzing their performance. In order to solve the RNN’s vanishing gradient problem, the LSTM (Long short-term memory) circuits which are a more complicated form of the RNN structure were used. The learning result showed that the RMSE value of the RNN-LSTM model was 0.102 which was lower than the RMSE value of the DNN model, indicating that the performance of the RNN-LSTM model was superior. In addition, high accuracy of the RNN-LSTM model was verified through the comparison between the estimated average road pavement condition and the actually measured road pavement condition of the target section over time."
자율주행 자동차 환경에서의 3D-LiDAR 와 딥러닝을 이용한 클러스터링 후보군 기반 실시간 객체 검출,2019,"['autonomous vehicle', '3d-LiDAR', 'clustering', 'deep learning', 'object detection']",,"Recently, IT companies such as Google, NVIDIA, and NAVER have been also developing autonomous vehicle platform technologies. In particular, sensors for object detection in surrounding environments have been improved in recognition rates by applying multi-sensor systems using camera, LiDAR, and radar. With the increasing importance of recognition technology, 3D information-based recognition technologies have been actively advanced as a commercial product of 3D-LiDAR. In this paper, a candidate group of point-clouds from 3D-LiDAR is extracted using Euclidean clustering in order to reduce the processing time delay in RPN (Region Proposal Network), which is one of the basic schemes for existing object detection. Then, it proposes types of input slicing, based on the extracted candidates. In addition, the accuracy and the processing time using four CNN networks (Basic CNN, ResNet, VGG16, and MobileNet) are compared over not only the private data (CVLab dataset) obtained in actual road environment but also the publicly open KITTI dataset."
반도체 제조라인 내 물류자동화시스템의 처리능력 향상을 위한 딥러닝 기반 디스패칭 방법론,2019,"['Scheduling', 'Deep learning', 'Semiconductor manufacturing', 'Lot targeting']",,"We present a deep-learning-based prediction method for the machine allocation problem of production scheduling in semiconductor manufacturing fabrication (FAB). This method is devised to improve the throughput capacity of the automated material handling system (AMHS). A prediction method is applied to determine the machine to perform the next process after a lot completes a process. Selecting the proper machine for the next process can shorten the travel distance of the overhead hoist transfers (OHTs), and this will eventually lead to reduced utilization and increased throughput capacity of the AMHS. The results confirm that the accuracy of our deep-learning-based machine selecting method is quite high and that it outperforms the other machine learning methods."
유사 영상 거칠기와 공간잡음 비용함수를 이용한 딥러닝 신경망 장면 기반 불균일보정,2019,"['Deep Neural Network', 'Image Roughness-like', 'SN', 'SBNUC', 'Improved IRLMS']",,"In this paper, a new Scene-based Nonuniformity Correction (SBNUC) method is proposed by applying Image Roughness-like and Spatial Noise cost functions on deep neural network structure. The classic approaches for nonuniformity correction require generally plenty of sequential image data sets to acquire accurate image correction offset coefficients. The proposed method, however, is able to estimate offset from only a couple of images powered by the characteristic of deep neural network scheme. The real world SWIR image set is applied　to verify the performance of proposed method and the result shows that image quality improvement of PSNR 70.3dB (maximum) is achieved. This is about 8.0dB more than the improved IRLMS algorithm which preliminarily requires precise image registration process on consecutive image frames."
수중 소나 영상 학습 데이터의 왜곡 및 회전 Augmentation을 통한 딥러닝 기반의 마커 검출 성능에 관한 연구,2019,"['Deep Learning', 'Data Augmentation', 'Object Detection', 'Underwater Sonar Image']",,"In the ground environment, mobile robot research uses sensors such as GPS and optical cameras to localize surrounding landmarks and to estimate the position of the robot. However, an underwater environment restricts the use of sensors such as optical cameras and GPS. Also, unlike the ground environment, it is difficult to make a continuous observation of landmarks for location estimation. So, in underwater research, artificial markers are installed to generate a strong and lasting landmark. When artificial markers are acquired with an underwater sonar sensor, different types of noise are caused in the underwater sonar image. This noise is one of the factors that reduces object detection performance. This paper aims to improve object detection performance through distortion and rotation augmentation of training data. Object detection is detected using a Faster R-CNN."
건설현장 근로자의 안전모 착용 여부 검출을 위한 컴퓨터 비전 기반 딥러닝 알고리즘의 적용,2019,"['construction safety', 'safety helmet', 'deep learning', 'computer vision']",,"Since construction sites are exposed to outdoor environments, working conditions are significantly dangerous. Thus, wearing of the personal protective equipments such as safety helmet is very important for worker safety. However, construction workers are often wearing-off the helmet as inconvenient and uncomportable. As a result, a small mistake may lead to serious accident. For this, checking of wearing safety helmet is important task to safety managers in field.However, due to the limited time and manpower, the checking can not be executed for every individual worker spread over a large construction site. Therefore, if an automatic checking system is provided, field safety management should be performed more effectively and efficiently. In this study, applicability of deep learning based computer vision technology is investigated for automatic checking of wearing safety helmet in construction sites. Faster R-CNN deep learning algorithm for object detection and classification is employed to develop the automatic checking model. Digital camera images captured in real construction site are used to validate the proposed model.Based on the results, it is concluded that the proposed model may effectively be used for automatic checking of wearing safety helmet in construction site."
ARM 기반 IoT 장치에서 효율적인 딥 러닝 수행을 위한 BLAS 및 신경망 라이브러리의 성능 및 에너지 비교,2019,"['IoT', 'deep learning', 'deep learning library', 'deep learning profiling', 'GPU-based acceleration', 'IoT', '딥 러닝', '딥 러닝 라이브러리', '딥 러닝 프로파일링', 'GPU 가속']","기존에 IoT 장치에서 딥 러닝을 수행하기 위해 주로 클라우드 컴퓨팅을 사용했다. 그러나 클라우드 컴퓨팅을 사용할 경우 연결을 보장할 수 없고, 통신을 위한 에너지 소모, 그리고 보안에 대한 취약성이 문제가 된다. 이와 같은 문제점을 해결하기 위해 최근 IoT 장치 내에서 딥 러닝을 수행하기 위한 시도가 진행되고 있다. 이 시도들은 주로 IoT 장치를 위한 연산량이 적은 딥 러닝 모델 또는 압축 기법 등을 제안하지만, 실제 IoT 장치에서 수행될 때의 영향에 대한 분석이 부족했다. IoT 장치마다 연산 장치의 구성과 지원되는 라이브러리가 다르기 때문에, 최적의 딥 러닝 수행을 위해 각 IoT 장치에서 다양한 수행 환경에 대한 분석이 필요하다. 본 논문에서는 다양한 하드웨어 구성을 가진 IoT 장치에서 수행 환경에 따른 성능 및 에너지를 측정하고 분석한다. 또한, 적절한 라이브러리를 사용하는 것만으로도 속도와 에너지 효율이 최대 9.43배, 26.78배까지 상승하는 것을 보여준다.","Cloud computing is generally used to perform deep learning on IoT devices. However, its application is associated with limitations such as connection instability, energy consumption for communication, and security vulnerabilities. To solve such problems, recent attempts at performing deep learning within IoT devices have occurred. These attempts mainly suggest either lightweight deep learning models or compression techniques concerning IoT devices, but they lack analysis of the effect when it is performed in actual IoT devices. Since each IoT device has different configuration of processing units and supported libraries, it is necessary to analyze various execution environments in each IoT device in order to perform optimized deep learning. In this study, performance and energy of IoT devices with various hardware configurations were measured and analyzed according to the application of the deep learning model, library, and compression technique. It was established that utilizing the appropriate libraries improve both speed and energy efficiency up to 13.3 times and 48.5 times, respectively."
모노 카메라 영상과 딥 러닝을 이용한 차량 검출 및 거리 등급 분류에 관한 연구,2019,"['딥러닝', '객체검출', '거리추정', '단안카메라', 'Deep learning', 'Object Detection', 'Distance Estimation', 'Mono Camera']","본 연구에서는 차량에 부착된 모노 카메라와 딥 러닝을 이용하여 객체 검출 및 검출된 객체에 대한 거리정보를 바탕으로 하는 위험도 분류 시스템을 제안한다. 다양한 상황에서 기존 컴퓨터 비전 기법들보다 변화에 강인하며 검출 능력이 뛰어난 딥 러닝을 이용하여 주행 영상을 통해 주행환경 상에 있는 객체들을 검출한다. 이때 객체 검출기로는 합성 곱 신경망 네트워크를 기반으로 만들어진 YOLO v2(You Only Look Once v2)알고리즘을 이용하며, 해당 알고리즘은 사전에 ImageNet 1000 Class 데이터로 학습 된 Pre-trained model에 KITTI 데이터 셋 및 웹 포털 사이트에서 크롤링을 통해 획득한 12K개의 이미지를 이용하여 전이학습 하였다. 그리고 DB 구축 Tool을 이용하여 KITTI 데이터 셋에서 취득한 이미지와 캘리브레이션된 LiDAR 센서 데이터를 통해 검출된 객체와의 거리 정보를 취득하였다. 객체 검출기의 결과로는 Bounding Box의 이미지 내 좌표인 x,y와 Bounding Box의 이미지 내 크기인 width, height 정보가 나온다. 객체와의 거리정보를 특정 구간 단위로 분류하여 Class화 하였고, 해당 Class(거리 등급)와 객체 검출 정보인 Bounding box 정보들을 Multi-layer Perceptron을 이용하여 분류한다.","In this study, we propose a risk classification system based on distance information of object detected and objects detection using mono camera based on deep learning. It detects the objects in the driving environment through driving images by using deep learning which is robust against change and has superior detection ability than existing computer vision techniques in various situations. In this case, we use YOLO v2 (You Only Look Once v2) algorithm, which is based on a convolution neural network as an object detector. The algorithm uses a KITTI data set and a web portal The site was trained using 12K images acquired through crawling. Using the DB construction tool, we obtained the distance information between the image obtained from the KITTI dataset and the detected object through the calibrated LiDAR sensor data. The result of the object detector is x, y coordinates in the image of the bounding box, and width and height information in the image of the bounding box. Classification is made by classifying the distance information with objects in a specific section, and classification of the class (distance class) and object detection information, Bounding box information, using Multi-layer Perceptron."
딥 러닝을 이용한 안면 여드름 분류 모델,2019,"['Deep Learning', 'Classification', 'Correlation Analysis', 'ACNE', 'CNN', '딥 러닝', '분류', '상관분석', '여드름', '컨볼루션 뉴럴 네트워크']","의학계에 다양하게 인공지능을 적용하는데 있어 한계는 우선적으로 해석자의 병증 이미지를 해석하는데 주관적 견해와 광범위한 해석자, 육체적 피로감 등이다. 그리고 병증마다 주석 달린 데이터 셋을 수집하는데 기간이 오래 걸린다는 것과 개발된 딥러닝 학습 알고리즘의 성능 저하가 없으면서도 충분한 훈련 데이터를 얻을지에 대한 의문이 있다는 것이다.이에 본 논문에서는 여드름 데이터 셋을 기준으로 기본 이미지를 수집할 때 선정 기준과 수집 절차에 대해 연구하고, Sequential 구조로 딥 러닝 기법을 적용하여 적은 손실률(5.46%)과 높은 정확도(96.26%)로 데이터를 분류하는 모델을 제안한다. Keras에서 기본 제공하는 모델과 비교실험을 통해 제안 모델의 성능을 비교 검증한다. 향후 본 논문에서 제안하는 여드름 분류 모델에 유사 현상들 적용하여 의학 및 피부 관리 분야에도 적용 가능할 것으로 예상된다.","The limitations of applying a variety of artificial intelligence to the medical community are, first, subjective views, extensive interpreters and physical fatigue in interpreting the image of an interpreter's illness. And there are questions about how long it takes to collect annotated data sets for each illness and whether to get sufficient training data without compromising the performance of the developed deep learning algorithm.In this paper, when collecting basic images based on acne data sets, the selection criteria and collection procedures are described, and a model is proposed to classify data into small loss rates (5.46%) and high accuracy (96.26%) in the sequential structure. The performance of the proposed model is compared and verified through a comparative experiment with the model provided by Keras. Similar phenomena are expected to be applied to the field of medical and skin care by applying them to the acne classification model proposed in this paper in the future."
딥 러닝 및 칼만 필터를 이용한 객체 추적 방법,2019,"['YOLO', 'Kalman filter', 'Object tracking', 'CNN', 'Deep learning']","딥 러닝의 대표 알고리즘에는 영상 인식에 주로 사용되는 CNN(Convolutional Neural Networks), 음성인식 및 자연어 처리에 주로 사용되는 RNN(Recurrent Neural Networks) 등이 있다. 이 중 CNN은 데이터로부터 자동으로 특징을 학습하는 알고리즘으로 특징 맵을 생성하는 필터까지 학습할 수 있어 영상 인식 분야에서 우수한 성능을 보이면서 주류를 이루게 되었다. 이후, 객체 탐지 분야에서는 CNN의 성능을 향상하고자 R-CNN 등 다양한 알고리즘이 등장하였으며, 최근에는 검출 속도 향상을 위해 YOLO(You Only Look Once), SSD(Single Shot Multi-box Detector) 등의 알고리즘이 제안되고 있다. 하지만 이러한 딥러닝 기반 탐지 네트워크는 정지 영상에서 탐지의 성공 여부를 결정하기 때문에 동영상에서의 안정적인 객체 추적 및 탐지를 위해서는 별도의 추적 기능이 필요하다. 따라서 본 논문에서는 동영상에서의 객체 추적 및 탐지 성능 향상을 위해 딥 러닝 기반 탐지 네트워크에 칼만 필터를 결합한 방법을 제안한다. 탐지 네트워크는 실시간 처리가 가능한 YOLO v2를 이용하였으며, 실험 결과 제안한 방법은 기존 YOLO v2 네트워크에 비교하여 7.7%의 IoU 성능 향상 결과를 보였고 FHD 영상에서 20 fps의 처리 속도를 보였다.",
딥 러닝을 활용한 인공지능의 예술표현 사례 연구,2019,"['Artificial Intelligence', 'Deep Learning', 'Art Expression', '인공지능', '딥 러닝', '예술표현']","본 논문은 최근 떠오르고 있는 인류 산업의 과제인 인공지능의 예술표현에 대해 연구하였다. 지금까지의 인공지능 예술표현 사례 분석을 통해 앞으로 과학기술의 예술적 수용에 있어 인공지능이 지니는 새로운 가능성과 한계점을 파악하여 인공지능을 활용한 예술이 발전할 수 있는 기반을 마련하는 데 그 목적이 있다. 이를 위해 딥 러닝의 개념과 인공지능 시대에서 예술의 전개 방향과 특징을 파악하고, 창의성과 행위의 주체성을 기준으로 인공지능의 예술표현 사례를 간접적 표현 측면과 직접적 표현 측면으로 나누어 Deep Dream, The Next Rembrandt, Aaron 등을 분석하였다. 사례 분석을 통해 인간의 신경활동을 본떠 만든 인공신경회로망을 기반으로 구축한 기계학습, 즉 인간의 두뇌가 수많은 데이터 속에서 패턴을 발견한 뒤 사물을 구분하는 정보처리 방식을 모방한 인공지능은 스스로 15세기부터 20세기에 이르기까지 다양한 이미지를 학습할 수 있으며, 축척된 방대한 데이터를 통해 원하는 형태의 그림을 자유롭게 그릴 수 있다는 사실을 알 수 있었다. 또한 인간과 비교할 수 없는 인공지능의 습득 속도에 따른 발달이 예술분야 전반에 미칠 영향으로 연구 필요성을 확인하였다.본 연구를 통해 과학기술을 활용하여 예술을 표현하는 것은 변화하는 시대 속에서 다르게 요구되는 상대적 속성인 예술의 의미를 구현하는 방식의 변화이자 표현양상임을 알 수 있었다. 따라서 본 연구를 기반으로 다각도에서 예술과 인공지능의 관계에 대해 생각한 인공지능의 예술표현 확장을 기대한다.","This study examined artistic expression by artificial intelligence(AI), which is one of the recently emerging topics in the human industries. By analyzing cases of artistic expression by AI up to the present, this study aims to ascertain the new possibilities and limitations presented by AI with regard to the artistic acceptance of science and technology. It also intends to provide the foundations for the future development of AI-based art. For this purpose, we first presented the concept of deep learning in addition to the direction and characteristics of how art is evolving in the age of AI. Based on this, we analyzed cases of AI-based artistic expression such as Deep Dream, The Next Rembrandt, and Aaron, making distinctions between the aspects of direct and indirect expression and based on the criteria of creativity and autonomy of action. This study’s case analysis revealed that machine learning systems built upon ANN, which mimics human neural activity, were able to imitate the information processing methods of the human brain—i.e., discovering patterns within the myriad data and identifying objects—such that they could learn diverse images from the 15th to the 20th century. We also found that they could use the vast accumulated data to freely draw pictures as they intended. Furthermore, we confirmed the need to study how the highly superior learning speed of AI, and the development thereof, would affect the arts in general. This study’s significance lies in that, by examining artistic expression through science and technology, it explores the changes in how the meaning of art—which is a relative attribute that changes with the times—is realized and expressed. Therefore, based on this research, we expect to expand the artistic expression of artificial intelligence that thought about the relation between art and artificial intelligence in various angles."
딥 러닝을 이용한 주택가격 예측에 관한 연구,2019,"['주택매매가격', '비선형', '예측', '딥 러닝', '순환신경망(RNN)', 'Housing Price', 'Nonlinear', 'Prediction', 'Deep Learning', 'Recurrent Neural Network']",,"The purpose of this study is to estimate housing prices using deep running. The simple RNN, LSTM, and GRU models, which are evaluated to be suitable for time series forecasting, are based on the time series data of apartment real price index, interest rate, household loan, building permit area and consumer price index. As a result of the empirical analysis, it is confirmed that the prediction power of the GRU model is superior to that of the learning data by evaluating the performance of forecasting power on apartment real price index based on the RMSE value. On the other hand, in the verification data, it is confirmed that the prediction power of the RNN model is excellent. Also, if the performance of the deep running model is evaluated with accuracy, the accuracy of the RNN model and the GRU model is the highest. As a result of this study, the government needs to build and develop a system that can predict and diagnose the housing market by using the deep learning technique that combines artificial neural network and big data to advance the housing market."
시각 장애인 가상현실 체험 환경을 위한 딥 러닝을 활용한 몰입형 보행 상호작용 설계,2019,"['몰입형 가상현실', '보행 상호작용', '딥러닝', '시각장애인', 'immersive virtual reality', 'walking interaction', 'deep learning', 'visually impaired people']","본 연구는 시각 장애인의 도보 적응올 위한 새로운 가상현실 체험 환경을 제안한다. 제안하는 가상현실 체험 환경의 핵심은 몰입형 보행 상호작용과 딥러닝 기반 점자 블록 인식으로 구성된다. 우선, 시각 장애인의 입장에서 현실적인 걷기 경험을 제공함을 목적으로 제자리 걸음을 감지하여 걷기를 판단하는 트래커 기반 걷기 처리과정과 시각 장애인의 보행 보조 도구를 가상현실에 적용한 컨트롤러 기반 VR 횐지광이를 설계한다. 또한, VR 횐지광이를 활용한 길 안내 과정에서 도로 위의 점자 블록 인지 및 반응 등 종합적인 의사결정을 수행하는 학습 모델을 제안한다. 이를 기반으로 가상현실 도보 체험 환경에 대한 실험을 위하여 실외 도시 환경으로 구성된 가상현실 어플리케이션을 제작하고, 참가자를 대상으로 설문 실험 및 성능 분석을 진행하였다. 결과적으로 제안한 가상현실 체험 환경이 시각 장애인의 입장에서 현존감 높은 도보 체험을 제공하고 있음을 확인하였다. 그리고 제안한 학습과 처 리과정이 인도와 차도, 인도 위의 점자 블록을 높은 정확도로 인지함을 확인하였다.","In this study, a novel virtual reality (VR) experience environment is proposed for enabling walking adaptation of visually impaired people. The core of proposed VR environment is based on immersive walking interactions and deep learning based braille blocks recognition. To provide a realistic walking experience from the perspective of visually impaired people, a tracker-based walking process is designed for determining the walking state by detecting marching in place, and a controller-based VR white cane is developed that serves as the walking assistance tool for visually impaired people. Additionally, a learning model is developed for conducting comprehensive decision-making by recognizing and responding to braille blocks situated on roads that are followed during the course of directions provided by the VR white cane. Based on the same, a VR application comprising an outdoor urban environment is designed for analyzing the VR walking environment experience. An experimental survey and performance analysis were also conducted for the participants. Obtained results corroborate that the proposed VR walking environment provides a presence of high-level walking experience from the perspective of visually impaired people. Furthermore, the results verify that the proposed learning algorithm and process can recognize braille blocks situated on sidewalks and roadways with high accuracy."
딥 러닝과 데이터 결합에 의한 싱크홀 트래킹,2019,"['sinkhole tracking', 'CNN transfer learning', 'data association', 'Hungarian Algorithm', 'Otsu algorithm']",,"Accurate tracking of the sinkholes that are appearing frequently now is an important method of protecting human and property damage. Although many sinkhole detection systems have been proposed, it is still far from completely solved especially in-depth area. Furthermore, detection of sinkhole algorithms experienced the problem of unstable result that makes the system difficult to fire a warning in real-time. In this paper, we proposed a method of sinkhole tracking by deep learning and data association, that takes advantage of the recent development of CNN transfer learning. Our system consists of three main parts which are binary segmentation, sinkhole classification, and sinkhole tracking. The experiment results show that the sinkhole can be tracked in real-time on the dataset. These achievements have proven that the proposed system is able to apply to the practical application."
딥 러닝을 이용한 비디오 카메라 모델 판별 시스템,2019,"['video camera model identification', 'forensic', 'deep learning', 'convolutional neural network']","현대 사회에서 영상 정보 통신 기술이 발전함에 따라서 영상 획득 및 대량 생산 기술도 급속히 발전하였지만 이를 이용한 범죄도 증가하여 범죄 예방을 위한 법의학 연구가 진행되고 있다. 영상 획득 장치에 대한 판별 기술은 많이 연구되었지만, 그 분야가 영상으로 한정되어 있다. 본 논문에서는 영상이 아닌 동영상에 대한 카메라 모델의 판별 기법을 제안한다. 기존의 영상을 학습한 모델을 사용하여 동영상의 프레임을 분석하였고, 동영상의 프레임 특성을 활용한 학습과 분석을 통하여 P 프레임을 활용한 모델의 우수성을 보였다. 이를 이용하여 다수결 기반 판별 알고리즘을 적용한 동영상에 대한 카메라 모델 판별 시스템을 제안하였다. 실험에서는 5개 비디오 카메라 모델을 이용하여 분석을 하였고, 각각의 프레임 판별에 대해 최대 96.18% 정확도를 얻었으며, 비디오 카메라 모델 판별 시스템은 각 카메라 모델에 대하여 100% 판별률을 달성하였다.","With the development of imaging information communication technology in modern society, imaging acquisition and mass production technology have developed rapidly. However, crime rates using these technology are increased and forensic studies are conducted to prevent it. Identification techniques for image acquisition devices are studied a lot, but the field is limited to images. In this paper, camera model identification technique for video, not image is proposed. We analyzed video frames using the trained model with images. Through training and analysis by considering the frame characteristics of video, we showed the superiority of the model using the P frame. Then, we presented a video camera model identification system by applying a majority-based decision algorithm. In the experiment using 5 video camera models, we obtained maximum 96.18% accuracy for each frame identification and the proposed video camera model identification system achieved 100% identification rate for each camera model."
딥 러닝 기법을 이용한 오피니언 마이닝 분석과 성과에 관한 실증연구: 합성곱 신경망 모델과 머신러닝 모델간 성과비교를 중심으로,2019,"['Deep learning', 'Convolutional neural network', 'Sentiment analysis', 'Opinion mining', 'Machine learning classifiers', 'Financial supervisory policy', '딥 러닝', '합성곱 신경망', '감성분석', '오피니언 마이닝', '머신러닝 분류기']","본 연구는 딥 러닝 기법인 합성곱 신경망 (CNN: Convolutional Neural Network)을 이용하여 금융자료에 관한 사용자의 오피니언을 추정하는 오피니언 마이닝 (Opinion mining) 방법과 그 결과를 설명한다. 본 연구에서는 다음과 같이 합성곱 신경망의 효과성을 검증하였다. 첫째, 스터디1은 주식관련 온라인 리뷰 데이터를 분석하였다. 즉, 형태소 분석단계를 거쳐 속성벡터를 만들어 리뷰 문장의 감성점수를 산출하였다. 해당 문장의 감성점수에 따라 오피니언을 3-클라스, 5-클라스 문제로 구분하여 실증분석을 하였다. 둘째, 스터디2에서는 청와대 국민청원에 게시된 금융관련 국민청원 텍스트 문장을 분석하여 청원인원을 추정하였다. 청원게시판에 등재된 청원 인원을 분위 수에 따라 분류하여 2-클라스 문제 (50%이상, 50% 미만) 4-클라스 문제 (75%이상, 50%이상, 25%이상, 25%미만)로 분류하였다. 스터디1, 2의 실증분석결과 정확도, 정밀도, 재현율, F1 점수 등 모든 성과지표에서 벤치마킹용 분류기와 비교할 때 합성곱 신경망이 더 우수한 성과를 보였다. 따라서, 합성곱 신경망을 이용함으로써 금융감독 관련 정책 및 활동을 효과적으로 수행할 수 있음을 실증적으로 확인하였다.",
딥 러닝 기반의 이미지학습을 통한 저항 용접품질 검증,2019,"['Resistance welding(저항 용접)', 'Quality verification(품질 검증)', 'Deep learning(딥 러닝)', 'Tensorflow(텐서플로우)']",,"Welding is one of the most popular joining methods and most welding quality estimation methods are executed using joined material. This paper propose welding quality estimation methods using dynamic current, voltage and resistance which are obtained during welding in real time. There are many kinds of welding method. Among them, we focused on the projection welding and gathered dynamic characteristics from two different types of projection welding. For image learning, graphs are drawn using obtained current, voltage and resistance, and the graphs are converted to images. The images are labeled with two sub-categories - normal and defect. For deep learning of images obtained from welding, Convolutional Neural Network (CNN) is applied, and Tensorflow was used as a framework for deep learning. With two resistance welding test datasets, we conclude that the Convolutional Neural Network helps in predicting the welding quality."
딥 러닝 기법을 이용한 레이더 신호 분류 모델 연구,2019,"['Deep Learning(딥 러닝)', 'Convolutional Neural Network(컨볼루션 신경망)', 'Recurrent Neural Network(순환신경망)', 'Radar Signal Classification(레이더 신호 분류)', 'Electronic Warfare(전자전)']",,"Classification of radar signals in the field of electronic warfare is a problem of discriminating threat types by analyzing enemy threat radar signals such as aircraft, radar, and missile received through electronic warfare equipment. Recent radar systems have adopted a variety of modulation schemes that are different from those used in conventional systems, and are often difficult to analyze using existing algorithms. Also, it is necessary to design a robust algorithm for the signal received in the real environment due to the environmental influence and the measurement error due to the characteristics of the hardware. In this paper, we propose a radar signal classification method which are not affected by radar signal modulation methods and noise generation by using deep learning techniques."
딥 러닝 기반 휴먼 모션 디노이징,2019,"['human motion', 'motion capture', 'motion denoising', 'attention', 'bidirectional recurrent neural network']","본 논문에서는 어텐션 기법을 적용한 양방향 순환신경망을 이용하여 새로운 휴먼 모션 디노이징 방법을 제안한다. 본 방법을 이용하면, 단일 3D 깊이 센서 카메라에서 캡처된 노이즈가 포함된 사람의 움직임이 잘 교정된 자연스러운 움직임으로 자동 조정된다. 양방향 순환신경망에 어텐션 기법을 도입하면, 입력으로 들어온 움직임을 인코딩할 때 여러 자세 중에 더 중요한 자세가 있는 프레임에 더 높은 어텐션 가중치를 부여함으로써, 다른 딥 러닝 네트워크와 비교해 더 나은 최적화 결과와 더 높은 정확도를 보인다. 실험을 통해 본 논문에서 제시한 방법이 다양한 스타일의 움직임과 노이즈를 효과적으로 처리함을 확인하였으며, 제시한 방법은 모션 캡처 후처리 단계의 애플리케이션으로 충분히 사용 가능할 것으로 기대된다.","In this paper, we propose a novel method of denoising human motion using a bidirectional recurrent neural network (BRNN) with an attention mechanism. The corrupted motion captured from a single 3D depth sensor camera is automatically fixed in the well-established smooth motion manifold. Incorporating an attention mechanism into BRNN achieves better optimization results and higher accuracy than other deep learning frameworks because a higher weight value is selectively given to a more important input pose at a specific frame for encoding the input motion. Experimental results show that our approach effectively handles various types of motion and noise, and we believe that our method can sufficiently be used in motion capture applications as a post-processing step after capturing human motion."
딥 러닝 기반 얼굴 메쉬 데이터 디노이징 시스템,2019,"['3D mesh data', 'denoising', 'deep learning', 'autoencoder', 'convolution']","3차원 프린터나 깊이 카메라 등을 이용하면 실세계의 3차원 메쉬 데이터를 손쉽게 생성할 수 있지만, 이렇게 생성된 데이터에는 필연적으로 불필요한 노이즈가 포함되어 있다. 따라서, 온전한 3차원 메쉬 데이터를 얻기 위해서는 메쉬 디노이징 작업이 필수적이다. 하지만 기존의 수학적인 디노이징 방법들은 전처리 작업이 필요하며 3차원 메쉬의 일부 중요한 특징들이 사라지는 문제점이 있다. 본 논문에서는 이러한 문제를 해결하기 위해 딥 러닝 기반의 3차원 메쉬 디노이징 기법을 소개한다. 구체적으로 본 논문에서는 인코더와 디코더로 구성된 컨볼루션 기반 오토인코더 모델을 제안한다. 메쉬 데이터에 적용하는 컨볼루션 연산은 메쉬 데이터를 구성하고 있는 각각의 정점과 그 주변의 정점들 간의 관계를 고려하여 디노이징을 수행하며, 컨볼루션이 완료되면 학습 속도 향상을 위해 샘플링 연산을 수행한다. 실험 결과, 본 논문에서 제안한 오토인코더 모델이 기존 방식보다 더 빠르고 더 높은 품질의 디노이징된 데이터를 생성함을 확인하였다.","Although one can easily generate real-world 3D mesh data using a 3D printer or a depth camera, the generated data inevitably includes unnecessary noise. Therefore, mesh denoising is essential to obtain intact 3D mesh data. However, conventional mathematical denoising methods require preprocessing and often eliminate some important features of the 3D mesh. To address this problem, this paper proposes a deep learning based 3D mesh denoising method. Specifically, we propose a convolution-based autoencoder model consisting of an encoder and a decoder. The convolution operation applied to the mesh data performs denoising considering the relationship between each vertex constituting the mesh data and the surrounding vertices. When the convolution is completed, a sampling operation is performed to improve the learning speed. Experimental results show that the proposed autoencoder model produces faster and higher quality denoised data than the conventional methods."
IoT 및 딥 러닝 기반 스마트 팜 환경 최적화 및 수확량 예측 플랫폼,2019,"['Agricultural', 'Analysis System', 'Artificial Intelligence System', 'CNN', 'Smart Farm']","본 논문은 농장의 바이오 센서 데이터를 수집해서 농장에서 재배중인 농작물의 질병을 진단하고, 그 해 수확량을 예측하는 IoT 및 딥 러닝 기반 스마트 팜 환경 최적화 및 수확량 예측 플랫폼을 제안한다. 이 플랫폼은 현재 날씨, 토양 미생물 등 수집 가능한 모든 정보를 수집하여 작물이 잘 성장할 수 있도록 농장 환경을 최적화하고, 농장에서 재배 중인 작물의 잎을 이용하여 작물의 질병을 진단하고, 그리고, 농장의 모든 정보를 사용하여 올해 수확량을 예측한다. 실험 결과 AEOM(Agricultural Environment Optimization Module)의 평균 정확도는 RF(Random Forest)보다 약 15%, GBD(Gradient Boosting Tree)보다 약 8% 높고, 데이터가 증가해도 RF나 GBD에 비해 정확도가 덜 감소한다. 선형 회귀에 따르면 정확도의 기울기는 ReLU의 경우 –3.641E-4, Sigmoid의 경우 –4.0710E-4, 계단함수의 경우 –7.4534E-4이다. 따라서 ReLU 사용시 정확도 기울기가 가장 낮으므로 테스트 데이터의 양이 증가함에 따라 ReLU는 다른 두 가지 활성화 기능보다 더 정확하다. 본 논문에서 제안한 EOYPP는 농장 전체를 관리하는 플랫폼으로 실제 농장에 도입된다면 국내 스마트 팜의 발전에 크게 이바지할 것이다.","This paper proposes “A Smart Farm Environment Optimization and Yield Prediction Platform based on IoT and Deep Learning” which gathers bio-sensor data from farms, diagnoses the diseases of growing crops, and predicts the year's harvest. The platform collects all the information currently available such as weather and soil microbes, optimizes the farm environment so that the crops can grow well, diagnoses the crop’s diseases by using the leaves of the crops being grown on the farm, and predicts this year's harvest by using all the information on the farm. The result shows that the average accuracy of the AEOM is about 15% higher than that of the RF and about 8% higher than the GBD. Although data increases, the accuracy is reduced less than that of the RF or GBD. The linear regression shows that the slope of accuracy is –3.641E-4 for the ReLU, –4.0710E-4 for the Sigmoid, and –7.4534E-4 for the step function. Therefore, as the amount of test data increases, the ReLU is more accurate than the other two activation functions. This paper is a platform for managing the entire farm and, if introduced to actual farms, will greatly contribute to the development of smart farms in Korea."
차량용 인포테인먼트 시스템의 딥 러닝 기반 UI 테스팅 자동화 기술,2019,"['소프트웨어 테스팅 자동화', 'UI 테스팅 자동화', '차량용 인포테인먼트 시스템', '인공지능 응용', '객체검출', 'R-CNN', 'software testing automation', 'UI testing automation', 'in-vehicle infotainment system', 'artificial intelligence application', 'object detection', 'R-CNN']","최근 텔레메틱스(Telematics), 커넥티드 카(Connected Car), 자율 주행 자동차 기술의 발전으로 인해 차량용 인포테인먼트 시스템(In-Vehicle Infotainment, IVI)에 포함되는 기능이 다양화되고 역할과 중요도가 크게 높아지고 있다. 이에 따라 IVI와 사용자 간의 상호작용을 담당하는 사용자 인터페이스(User Interface, UI)의 복잡성이 증가되고 있으며, 높은 품질의 UI 개발을 위한 UI 테스팅 기술의 필요성 또한 증대되었다. 본 논문에서는 IVI의 화면으로부터 객체를 인식하는 딥 러닝 모델을 이용한 UI 테스팅 자동화 기술을 제안하고, IVI 자동화 테스팅 도구 VISTA에 적용시킨 사례에 대해 기술한다.","Lately, the functions included in the in-vehicle infotainment system (IVI) have diversified and their roles and importance greatly increased due to the development of telematics, connected cars, and autonomous vehicle technology. the complexity of the user interface (UI) responsible for the interaction between IVI and the user, and the need for a UI testing technique for a UI. In this paper, we propose a UI testing technology using a deep learning model that recognizes objects from the IVI screen, and describe a case where it is applied to IVI automation testing tool VISTA."
산불 방재용 무선 센서 네트워크에서 딥 러닝 기반의 온도 센서 데이터 추정 및 산불 전파 예측,2019,"['Wireless Sensor Network', 'duty cycle', 'wildfire prediction', 'Deep Neural Network', 'Recurrent Neural Network']",,
딥 러닝 기반의 영상처리 기법을 이용한 겹침 돼지 분리,2019,"['Pig Monitoring', 'Occluding Pigs', 'Segmentation', 'Deep Learning', 'YOLO']",,"The crowded environment of a domestic pig farm is highly vulnerable to the spread of infectious diseases such as foot-and-mouth disease, and studies have been conducted to automatically analyze behavior of pigs in a crowded pig farm through a video surveillance system using a camera. Although it is required to correctly separate occluding pigs for tracking each individual pigs, extracting the boundaries of the occluding pigs fast and accurately is a challenging issue due to the complicated occlusion patterns such as X shape and T shape. In this study, we propose a fast and accurate method to separate occluding pigs not only by exploiting the characteristics (i.e., one of the fast deep learning-based object detectors) of You Only Look Once, YOLO, but also by overcoming the limitation (i.e., the bounding box-based object detector) of YOLO with the test-time data augmentation of rotation. Experimental results with two-pigs occlusion patterns show that the proposed method can provide better accuracy and processing speed than one of the state-of-the-art widely used deep learning-based segmentation techniques such as Mask R-CNN (i.e., the performance improvement over Mask R-CNN was about 11 times, in terms of the accuracy/processing speed performance metrics)."
딥 러닝 기반 대학 이수학점 및 활동에 의한 교원임용 후보자 경쟁 시험 합격여부 예측,2019,[],,"The recent increase in preference for teacher jobs has led to a rise in preference for education colleges. Not all students can enter teachers, but they must pass the test called the competitive examination for teacher appointment candidates after graduation. However, due to the declining population, the and employment T.O.s are decreasing every year and the competition rate is rising steeply. Therefore, in order to concentrate on the recruitment exam upon entering the university, the university is becoming a huge academy for the exam, not a place to study and learn. We found a connection between students' overall school life and their use of study groups as well as their grades and whether they passed the competition test for teachers using deep running. The academic activities did not significantly affect the acceptance process, and the accuracy of the prediction of the acceptance rate was generally 70% accurate."
딥 러닝 기반의 SIFT 이미지 특징 추출,2019,"['SIFT Feature extraction', 'Deep learning', 'VGG', 'CNN(Convolutional Neural Network)', 'Repeatability']","본 논문에서는 일정 크기로 자른 영상의 가운데 픽셀이 SIFT 특징점인지를 판별함으로써 SIFT 특징점을 추출하는 딥 뉴럴 네트워크(Deep Neural Network)를 제안한다. 이 네트워크의 데이터 세트는 DIV2K 데이터 세트를 33×33 크기로 잘라서 구성하고, 흑백 영상으로 판별하는 SIFT와는 달리 RGB 영상을 사용한다. 그라운드 트루스(ground truth)는 옥타브(scale, octave)를 0, 시그마(sigma)는 1.6, 간격(intervals)은 3으로 설정하여 추출한 RobHess SIFT 특징들로 구성한다. VGG-16을 기반으로 컨볼루션 층을 13개에서 23개와 33개로 점점 깊은 네트워크를 구성하고, 영상의 스케일을 증가시키는 방법을 바꿔가며 실험을 수행한다. 출력 층의 활성화 함수로 시그모이드(sigmoid) 함수를 사용한 결과와 소프트맥스(softmax) 함수를 사용한 결과를 비교하여 분석한다. 실험결과 제안한 네트워크가 99% 이상의 추출 정확도를 가질 뿐 아니라 왜곡된 영상에 대해서도 높은 추출 반복성을 가진다는 것을 보인다.",
압축 영상 화질 개선을 위한 딥 러닝 연구에 대한 분석,2019,"['CNN', 'HEVC', 'Noise Reduction', 'Quality Enhancement']","최근 CNN (Convolutional Neural Network) 기반의 화질 개선 기술이 H.265/HEVC와 같은 블록 기반 영상 압축 표준을 사용하여 압축된 영상의 화질을 향상시키는 데 적극적으로 사용되어 왔다. 이 논문은 이러한 영상 압축 기술을 위한 화질 개선 연구의 추세를 요약하고 분석하는 것을 목표로 한다. 먼저, 화질 개선을 위한 CNN의 구성 요소를 살펴보고 이미지 도메인에서의 사전 연구를 요약한다. 다음으로 네트워크 구조, 데이터셋 및 학습 방법의 세 가지 측면에서 관련 연구들을 정리하고 성능 비교를 위한 구현 및 실험 결과를 제시하고자 한다.",
머신러닝에 관한 OSS 라이선스 연구,2019,"['Artificial Intelligence', 'Machine Learning', 'Deep Learning', 'Tensorflow', 'Open Source Software', 'License', 'Open Source License', 'Apache License', 'Copyright', '인공지능', '머신러닝', '딥러닝', '텐서플로', '오픈소스 소트웨어', '라이선스', '오픈소스 라이선스', '아파치 라이선스', '저작권']","인공지능에 관한 산업적 관심이 높아지고 시장이 확대되면서 국내에서 인공지능에 관한 컴퓨터프로그램(이하 “프로그램”이라 한다)의 활용이 점차 확대되고 있다. 인공 지능을 구현하기 위해 머신러닝 기술이 활용되는데, 이 분야의 주요한 머신러닝 관련 프로그램으로 TensorFlow를 비롯하여 scikit-learn, Machine Learning Library (MLlib), Weka 3 등이 있다. 그리고 이것들에는 오픈소스 라이선스인 Apache License v.2.0, MIT License 및 New BSD License(3-Clause BSD License)이 적용되었다. 특히, Apache License v.2.0에 관하여서는 국제적으로 높은 사용률을 보이면서도 국내에 참고문헌이 많지 않다. 그리고 프로그램의 법적 문제는 이것에 적용된 라이선스의 해석에 기초해 야 하므로, 적용된 라이선스들의 구체적인 해석이 필요하다. 그렇지만 관련 산업에서 오픈소스 소프트웨어에 대한 법적 문제의식은 상당히 낮은 상황이다. 따라서 오픈소 스 소프트웨어에 적용된 라이선스들에 대한 법적 해석론을 제시함에 의해 관련 산업 에서의 잠재적인 법적 문제들을 해결할 수 있을 것이다. 그래서 이 논문은 머신러닝 에 관한 오픈소스 소프트웨어에 적용된 오픈소스 라이선스들에 대해 간략히 살펴보 고, 라이선스에 사용된 중요한 용어들을 검토한 후에, 라이선스의 주요한 법적 문제들 을 검토하다. Apache License v.2.0, MIT License 및 New BSD License는 퍼미시브 라이선스이고, 이 중 Apache License v.2.0은 정의, 저작권, 특허, 상표 등을 포함하여 상당히 구체적으로 규 정되어 있다. 그리고 라이선시는 재배포 시에 라이선스를 함께 배포하고, 저작권 외에도 특허권, 상표권 등에 관하여 고려해야 한다. 그런데 이 라이선스는 오픈소스 이니셔티브 의 오픈소스의 정의에 부합하도록 정의되어 있으면서, 퍼미시브 라이선스로 오픈소스 소프트웨어의 이용자 측면에서 비교적 유연한 내용들을 포함한다. 예를 들어 TensorFlow 와 같이 이 라이선스가 적용된 프로그램의 변경물이나 2차적저작물의 일부 또는 전체에 추가적인 또는 별도의 라이선스 규정 및 조건을 부여할 수 있다. 다만, 카피레프트 조항 을 포함하는 라이선스와의 양립성의 문제는 카피레프트 라이선스로의 일방적인 통합을 의미한다. 결론적으로, Apache License v.2.0은 개발자나 사업자의 관점에서는 다양한 선택지를 갖도록 한다. 그렇지만 오픈소스 라이선스가 적용된 머신러닝 관련 프로그램들을 이용할 때 라 이선스와 관련한 사안들에 유의해야 할 필요가 있다. 우선, 조합저작물 또는 2차적저 작물에 대해 권리 및 귀속 고지의 의무를 반드시 준수해야 한다. 그리고 작은 분량의 프로그램도 저작권이 있을 수 있으므로 권리 및 귀속에 관한 고지를 소스 형태 내에 반드시 포함시키도록 한다. 또한 머신러닝 관련 프로그램들을 조합하거나 이 프로그 램을 다른 프로그램에 포함시키는 경우에 라이선스 간의 양립성 문제가 발생할 수 있 으므로, 라이선스의 양립성에 대해 유의해야 한다. 이에 더해 라이선시는 머신러닝에 관한 오픈소스 소프트웨어를 활용하여 발명을 하고 이것에 대해 특허를 취득한 경우 에, 특허 소송에 대한 보복조항이 있을 수 있고 없더라도 묵시적 실시허락이 인정될 수 있으므로, 특허 소송은 신중하게 접근할 필요가 있다.","As the industrial interest on artificial intelligence(AI) increases and the market related to AI expands, the application of computer programs on AI is gradually expanding in Korea. Machine learning technology is used to implement AI, and major machine learning programs in this field include scikit-learn, Machine Learning Library (MLlib), and Weka 3 in addition to TensorFlow, which are covered by the Apache License v.2.0, MIT License and New BSD License(3-Clause BSD License). In particular, Apache License v.2.0 has a high usage rate internationally, but there are not many references in the country. And the copyright issue of the program must be based on the interpretation of the license applied to it, so a specific interpretation of the applied licenses is necessary. However, legal awareness of open source software (OSS) in the related industry is very low. Therefore, we expect to be able to solve the potential legal problems in the related industry by presenting the legal interpretation related to the licenses applied to the OSS. So, this paper briefly reviews the open source licenses applied to OSS for machine learning, reviews the key terms used in the licenses, and then reviews the major legal issues of the licenses. The Apache License v.2.0, MIT License, and New BSD License are Permissive licenses, of which the Apache License v.2.0 was prescribed in considerable detail, including definitions, copyright, patent, and trademark. And Licensee shall distribute the Licenses at the time of redistribution and take into account patents, trademarks, etc. in addition to copyrights. However, this license is defined to conform to Open Source Initiative’s open source definition, and it also includes relatively flexible content in terms of users of the OSS as a permissive license. For example, Licensee of programs such as TensorFlow may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole under certain conditions. However, the issue of compatibility with licenses including copyleft terms implies a one way integration into copyleft licenses. In conclusion, the Apache license v.2.0 allows a wide variety of choices from the developer or business perspective. Nevertheless, you need to be aware of issues related to OSS licenses when using programs licensed by OSS licenses. First of all, you shall comply with the obligations of the rights and attribution notices for the combined or Derivative works. And a small amount of programs can be copyrighted, so you shall be sure to include notices of rights and attribution in the source form. In addition, compatibility between licenses may occur when combining machine learning-related programs or including them in other programs, so you shall be careful about licenses’ compatibility. In addition, if a licensee invents and patents using an open source software related to machine learning, patent litigation needs to be taken with caution, as there may be retaliation provision for patent litigation and implied licenses may be admitted."
인공지능(AI) 기술을 이용한 디지털 성범죄에 대한 검토 - 딥페이크(Deepfake) 포르노 규제를 중심으로 -,2019,"['Deepfake Porno', 'Act on Promotion of Information and Communication Network Utilization and Information protection', 'Act on Special Cases Concerning the Punishment', 'etc. of Sexual Crimes', 'Taking Photos by Using Cameras', 'etc.', 'Digital-sexual Crimes', 'Criminal Regulations', '딥페이크 포르노', '정보통신망법', '성폭력처벌법', '카메라등이용촬영죄', '디지털성폭력', '형사규제']","최근 유명 연예인 등에 의한 일련의 소위 디지털 성범죄가 발생함에 따라 다시금 카메라등이용촬영및 유포행위에 대한 문제의 심각성이 크게 대두되었다. 그러나 이러한 문제의 심각성에 대해서는 사건발생시 국회와 언론만 뜨겁게 반응했을 뿐, 아직 일반시민의 의식 저변을 변화시키는데 까지는 이르지못했음이 여실히 들어났다.이를 반증하는 것으로 최근 한국에서도 본격적으로 ‘가짜 연예인 음란 동영상’ 문제가 불거지고 있다. 이른바 ‘지인능욕’이라고 불리는 딥페이크(Deepfake) 포르노 문제가 바로 그러한데, 이는 인공지능(AI) 기술인 딥러닝을 활용하여 피해자의 음성과 얼굴을 위조하고 이를 통해 편집⋅영상합성된 포르노 영상물을 유포하는 것이다. 문제는 이러한 딥페이크 포르노가 기존의 보편화된 컴퓨터그래픽 기술에 인공지능(AI) 딥러닝기법으로 손쉽게 제작가능하다는 점과 이렇게 업로드되는 딥페이크 포르노영상을 완벽하게 필터링할 수 없다는 점, 더욱이 불법영상물이 급속도로 확산될 뿐만 아니라 완전히삭제되지 않아 피해자가 계속적으로 피해를 받아야 한다는 점에 있다.한편, 이에 대하여 현재 정보통신망법상 허위사실적시 사이버명예훼손죄나 사이버 음란물유포죄로형사처벌하고 있는데, 이는 실제 성행위 촬영이 이루지지 않다는 점에 근거하는 것이다. 이로 인해 불법촬영물 성폭력범죄에 비해 가해자 처벌 및 피해자 구제에 부족함이 나타나게 된다. 다만 이러한 딥페이크(Deepfake) 포르노 문제에 대하여 형사규제가 요구되더라도 그 적용에 있어서는 신중을 기해야한다는 점에서, 딥페이크 포르노 문제에 대하여 살펴보고, 또한 이러한 가해행위를 대법원 판례에 기초하여 성폭력처벌법 제14조의 카메라등이용촬영죄로 규율할 수 있는지 여부를 분석하고 더 나아가입법적 대안에 대해서도 검토한다.","While the rapid development of technology in recent years has brought many benefits to Korean society, it also has been implications for such matters as the privacy and the role of law. Especially In Korea, Violence on women’s bodies and sexuality in cyberspace has been a problem since the 2000s. This violence against women’s bodies and sexuality in cyberspace is not just a violation of the social legal interest using information, but also a direct violation of the individual’s body and character using digital technology, just like rape, a traditional sexual crime. Under the ‘ACT ON SPECIAL CASES CONCERNING THE PUNISHMENT, ETC. OF SEXUAL CRIMES’ Article 14 cannot catch various types of sexual crimes that are actually occurring by excluding the leakage of self-pictured sexual images and taking issue with the extent of physical exposure of images.This study aims to find criminal policy for punishment and regulations after conducting an study on the type of digital-sexual crimes, including the use of AI technology(deepfake). The problem recognition in this study is to explore whether the current methods and content of punishment and regulation are adequately responding to the type of cyber sexual crime that is currently occurring, what problems are there if not addressed, and what improvements are needed to address them. Therefore, it analyzed domestic and international legal systems related to digital-sexual crimes. Also, it was also consider issues raised in the process of actual punishment and regulation."
머신러닝을 이용한 관중 수요 예측에 관한 연구,2019,"['수요예측', '머신러닝', '딥러닝', '랜덤포레스트']","특정한 이벤트나 콘텐츠를 즐기기 위해 모인 사람들을 관중 또는 관객이라고 하고, 모임의 특성에 따라 다양한 성향을 나타낸다. 그러한 차이점은 있지만, 일반적으로 관중 수는 경영적인 측면과 직결되는 요소로써, 관람료부터 다른 시설의 이용료 등 다양한 수입을 통해 콘텐츠 판매를 위한 안정적인 재정 운영을 가능케 한다. 따라서 관중 수에 대한 예측은 마케팅과 예산 전략 수립에 주요한 요소로 활용될 수 있다. 본 연구에서는 관중 수에 대한 예측을 위한 여러 가지 기존 모델을 검토하고, 그 중에서 효율적인 머신러닝 모델을 제안하고자 한다. 또한 딥러닝과 랜덤포레스트 모델을 혼용하여 일별 관중 수 예측과 비정상적 관중 수 예측에 대한 연구를 진행하였다.","People who gathered to enjoy a specific event or content are called audiences or spectators, and show various propensity according to the characteristics of the crowd. Although there is such a difference, in general, the number of attendance is directly related to the business aspect, which enables stable financial operation for the sale of contents through various incomes, such as the admission fee and the use of other facilities. Therefore, prediction of audience can be used as a major factor in marketing and budgeting strategies. In this study, we review several existing models for predicting the number of attendance and propose an efficient machine learning model. In addition, we studied daily attendance prediction and abnormal attendance prediction using combine DNN(Deep Neural Network) and RF(Random Forest) model."
머신러닝을 활용한 사상체질 분류 모델 선정과 서비스 플로우 디자인,2019,"['머신러닝', '딥러닝', '한의학', '사상체질', '데이터베이스', 'MachineLearning', 'DeepLearning', 'Or7iental Medicine', 'Sasang-Type', 'Database']",,"Unlike in modern medicine, medical data have not been standardized yet and infrastructure for accumulating data is poor in oriental medicine. These problems become obstacles in artificial intelligence research and bilateral cooperation in domain of oriental medicine. To solve this problem, we compared the classification accuracy using several machine learning algorithms to select the highest accuracy model. Also we designed an application using the selected classification algorithm model to offer convenience service to doctor and patient. In addition, we designed the database to accumulate medical data, so accumulated data can be used to enhance the accuracy of classification algorithm model."
딥런닝 기반의 프레임 유사성을 이용한화재 오탐 검출 개선 연구,2019,"['deep learning', 'faster r-cnn', 'fire detection', 'smoke detection', 'ssim']","화염 및 연기 감지 알고리즘 연구는 다양한 모양, 빠른 확산 및 색상으로 인해 컴퓨터 비전에서 어려운 과제이다. 일반적인센서 기반 화재 감지 시스템의 성능은 환경 요인 (실내 및 화재발생 위치)에 따라 크게 제한된다. 이러한 문제를 해결하기위해 딥러닝 방법을 적용하였으며, 이것은 물체의 형상을 특징으로 추출하므로 비슷한 형상이 프레임내에 존재하면 오탐으로검출 될 수 있다. 본 연구는 화재 오탐 검출 개선을 위해 딥런닝 사용 전과 후에 프레임 유사성을 이용하여 오탐을 줄이는새로운 알고리즘을 제안한다. 실험결과 제안된 방법을 적용하여 화재 검출 성능은 유지를 하면서 오탐 부분이 최소 30% 까지 감소하는 결과를 얻을 수 있었다. 제안된 방법의 오탐 검출 성능이 뛰어나다는 것을 확인하였다.","Fire flame and smoke detection algorithm studies are challenging task in computer vision due to the variety of shapes,rapid spread and colors. The performance of a typical sensor based fire detection system is largely limited byenvironmental factors (indoor and fire locations). To solve this problem, a deep learning method is applied. Because itextracts the feature of the object using several methods, so that if a similar shape exists in the frame, it can be detectedas false postive. This study proposes a new algorithm to reduce false positives by using frame similarity before usingdeep learning to decrease the false detection rate. Experimental results show that the fire detection performance ismaintained and the false positives are reduced by applying the proposed method. It is confirmed that the proposed methodhas excellent false detection performance"
베이지안 추론과 정규화를 이용한 회귀 머신러닝,2019,"['Bayesian Statistics', 'Machine Learning', 'Deep Learning', 'Patent Keyword Data', 'Technology Analysis', '베이지안 추론 및 정규화', '신경망', '회귀분석', '머신러닝', '심층학습', '딥러닝']","최근 심층학습에 기반 한 신경망 모형이 기존의 머신러닝 알고리즘을 대체하고 있다. 특히 컴퓨터비전, 자연어처리 등이미지와 음성 인식 문제를 위한 분류 작업에서 매우 우수한 성능을 보여주고 있다. 하지만 신경망 모형의 구조에서 은닉층을심층적으로 디자인함으로써 기존의 신경망에 비하여 더 많은 계산시간이 필요하게 되는 어려움이 있다. 분류문제가아닌 회귀문제에 있어서도 같은 문제가 있다. 이와 같은 심층 신경망에 비하여 본 연구에서 제시하는 베이지안 신경망은하나의 은닉층만을 사용하고 베이지안 추론 및 정규화를 이용하여 신경망 모형의 예측력을 유지하면서 동시에 계산시간을단축시키는 결과를 얻기 위하여 노력한다. 즉, 신경망 모형의 가중치를 모수의 사전 및 사후 분포를 이용하여 갱신한다.모의실험 데이터를 이용하여 베이지안 신경망과 심층 신경망의 예측의 정확성과 계산시간을 비교하여 제안 방법의 타당성을보인다","Recently, the neural network models based on deep learning are replacing the existing machine learning algorithm. In particular, they show excellent performance in classification tasks for image and speech recognition problems such as computer vision and natural language processing. However, because of the large size of hidden layer, the deep neural network model has a difficulty that requires more computation time than the conventional neural networks. The same problem exists for regression problems that are not classification problems. Compared with such deep neural networks, the Bayesian neural network proposed in this study uses only one hidden layer and uses Bayesian inference and regularization to maintain the predictive power of the neural network model while reducing the computation time. That is, the weights of the neural network model are updated by using the prior and posterior distributions of parameters. By using the simulation data, we compare the accuracy and computation time of Bayesian neural networks and deep neural networks to show the validity of the proposed method"
Web access prediction based on parallel deep learning,2019,"['Apache Spark', 'Neural network', 'Parallel deep learning', 'Parameter tuning', 'Web access prediction', '아파치 스파크', '신경망', '병렬 딥러닝', '파라미터 튜닝', '웹 접근 예측']","웹에서 정보 접근에 대한 폭발적인 주문으로 웹 사용자의 다음 접근 페이지를 예측하는 필요성이 대두되었다. 웹 접근 예측을 위해 마코브(markov) 모델, 딥 신경망, 벡터 머신, 퍼지 추론 모델등 많은 모델이 제안되었다. 신경망 모델에 기반한 딥러닝 기법에서 대규모 웹 사용 데이터에 대한 학습 시간이 엄청 길어진다. 이 문제를 해결하기 위하여 딥 신경망 모델에서는 학습을 여러 컴퓨터에 동시에, 즉 병렬로 학습시킨다. 본 논문에서는 먼저 스파크 클러스터에서 다층 Perceptron 모델을 학습 시킬 때 중요한 데이터 분할, shuffling, 압축, locality와 관련된 기본 파라미터들이 얼마만큼 영향을 미치는지 살펴보았다. 그 다음 웹 접근 예측을 위해 다층 Perceptron 모델을 학습 시킬 때 성능을 높이기 위하여 이들 스파크 파라미터들을 튜닝 하였다. 실험을 통하여 논문에서 제안한 스파크 파라미터 튜닝을 통한 웹 접근 예측 모델이 파라미터 튜닝을 하지 않았을 경우와 비교하여 웹 접근 예측에 대한 정확성과 성능 향상의 효과를 보였다.","Due to the exponential growth of access information on the web, the need for predicting web users’ next access has increased. Various models such as markov models, deep neural networks, support vector machines, and fuzzy inference models were proposed to handle web access prediction. For deep learning based on neural network models, training time on large-scale web usage data is very huge. To address this problem, deep neural network models are trained on cluster of computers in parallel. In this paper, we investigated impact of several important spark parameters related to data partitions, shuffling, compression, and locality (basic spark parameters) for training Multi-Layer Perceptron model on Spark standalone cluster. Then based on the investigation, we tuned basic spark parameters for training Multi-Layer Perceptron model and used it for tuning Spark when training Multi-Layer Perceptron model for web access prediction. Through experiments, we showed the accuracy of web access prediction based on our proposed web access prediction model. In addition, we also showed performance improvement in training time based on our spark basic parameters tuning for training Multi-Layer Perceptron model over default spark parameters configuration."
Development of Handwriting Recognition Using Deep Learning in Unit3yD,2019,"['Character recognition', 'Deep learning', 'Unity3D', 'Handwriting Recognition', 'Convolutional Neural Network']","필기 인식은 사람이 작성한 문서나 종이에 쓴 글자, 사진에 보이는 글자 등을 인식하는 기술이다. 대표적인 기술로는 OCR과 온라인 필기인식 기술이 있으며 OCR은 정자로 또박또박 쓴 글씨 인식률은 높지만 그렇지 않는 경우에는 인식률이 낮다. 온라인 필기인식 기술은 필기 입력순서와 사람의 필체의 차이에 따라 인식률이 확연하게 달랐다. 본 논문에서는 이러한 단점을 보완하고자 딥러닝을 이용하여 필기체 인식 시스템을 제안하고자 한다. 본 논문에서는 신경망 알고리즘 중 Convolutional Neural Network와 EMNIST 데이터 세트를 사용하여 학습 데이터를 설계하였고 Unity3D 게임엔진을 이용하여 전체적인 시스템을 구성하였다. 또한 본 논문에 서는 CPU와 GPU 성능이 학습 결과에 영향을 미치는지 알아보기 위해 성능을 비교분석을 하였고, loss값과 accuracy 결과에 큰 차이는 없었지만 학습 속도에는 최대 30배 정도 속도 차이가 났다. 마지막으로 실험을 통해 시스템 인식결과를 분석하였고, 문자와 숫자가 유사한 O, q, l과 같은 알파벳이나, 실험자가 글자를 다른 알파벳과 유사하게 보이게 필기하면 인식률이 낮았다. 본 논문에서 제안하는 시스템은 게임엔진을 사용하여 인공지능 시스템을 개발했기 때문에 프로세스 절차가 간략해졌고 호환성도 좋아졌다.","Handwriting recognition is a technology that recognizes people s written documents, characters written on paper, and characters shown in pictures. Typical technologies include OCR and on-line handwriting recognition technology. OCR had a high recognition rate of writing that was clearly written, but if not, it had a low recognition rate. On-Line handwriting recognition technology clearly differed depending on the difference between handwriting input order and a person s handwriting. In this paper, in order to compensate for these shortcomings, we propose a handwriting recognition system using deep learning. In this paper, the learning data were designed using Convolutional Neural Network and EMNIST data set among neural network algorithms and the whole system was constructed using Unity3D game engine. In this paper, we also did a comparative analysis to see if CPU and GPU performance affect learning results, and although there was no big difference in loss value and acuracy value results, there was a maximum speed difference of 30 times at learning speed. Finally, the results of recognition were analyzed through experiments, and alphabets with similar shapes of characters and numbers, such as O, q, and l, had lower recognition rates. And if the experimenter wrote the characters to look similar to other alphabets, the recognition rate was low. The system proposed in this paper has developed an artificial intelligence system using game engine, so the process procedure has been simplified and the compatibility has improved."
Generation of contrast enhanced computed tomography image using deep learning network,2019,"['Contrast enhanced computed tomography', 'deep learning', 'generative adversarial network']",,"In this paper, we propose a application of conditional generative adversarial network (cGAN) for generation of contrast enhanced computed tomography (CT) image. Two types of CT data which were the enhanced and non-enhanced were used and applied by the histogram equalization for adjusting image intensities. In order to validate the generation of contrast enhanced CT data, the structural similarity index measurement (SSIM) was performed. Prepared generated contrast CT data were analyzed the statistical analysis using paired sample t-test. In order to apply the optimized algorithm for the lymph node cancer, they were calculated by short to long axis ratio (S/L) method. In the case of the model trained with CT data and their histogram equalized SSIM were 0.905±0.048 and 0.908±0.047. The tumor S/L of generated contrast enhanced CT data were validated similar to the ground truth when they were compared to scanned contrast enhanced CT data. It is expected that advantages of Generated contrast enhanced CT data based on deep learning are a cost-effective and less radiation exposure as well as further anatomical information with non-enhanced CT data."
Deep Learning based violent protest detection system,2019,"['Collecting evidence', 'drone', 'deep learning', 'detection', 'AWS']",,"In this paper, we propose a real-time drone-based violent protest detection system. Our proposed system uses drones to detect scenes of violent protest in real-time. The important problem is that the victims and violent actions have to be manually searched in videos when the evidence has been collected. Firstly, we focused to solve the limitations of existing collecting evidence devices by using drone to collect evidence live and upload in AWS(Amazon Web Service)[1]. Secondly, we built a Deep Learning based violence detection model from the videos using Yolov3 Feature Pyramid Network for human activity recognition, in order to detect three types of violent action. The built model classifies people with possession of gun, swinging pipe, and violent activity with the accuracy of 92, 91 and 80.5% respectively. This system is expected to significantly save time and human resource of the existing collecting evidence."
Detection of Moving Direction using PIR Sensors and Deep Learning Algorithm,2019,"['Passive infrared', 'movement direction detection', 'deep learning', 'machine learning', 'convolutional neural network']",,"In this paper, we propose a method to recognize the moving direction in the indoor environment by using the sensing system equipped with passive infrared (PIR) sensors and a deep learning algorithm. A PIR sensor generates a signal that can be distinguished according to the direction of movement of the user. A sensing system with four PIR sensors deployed by 45° increments is developed and installed in the ceiling of the room. The PIR sensor signals from 6 users with 10-time experiments for 8 directions were collected. We extracted the raw data sets and performed experiments varying the number of sensors fed into the deep learning algorithm. The proposed sensing system using deep learning algorithm can recognize the users’ moving direction by 99.2 %. In addition, with only one PIR senor, the recognition accuracy reaches 98.4%."
Pest Control System using Deep Learning Image Classification Method,2019,"['Image Processing', 'Convolutional Neural Network', 'Background Subtraction', 'Classification']",,"In this paper, we propose a layer structure of a pest image classifier model using CNN (Convolutional Neural Network) and background removal image processing algorithm for improving classification accuracy in order to build a smart monitoring system for pine wilt pest control. In this study, we have constructed and trained a CNN classifier model by collecting image data of pine wilt pest mediators, and experimented to verify the classification accuracy of the model and the effect of the proposed classification algorithm. Experimental results showed that the proposed method successfully detected and preprocessed the region of the object accurately for all the test images, resulting in showing classification accuracy of about 98.91%. This study shows that the layer structure of the proposed CNN classifier model classified the targeted pest image effectively in various environments. In the field test using the Smart Trap for capturing the pine wilt pest mediators, the proposed classification algorithm is effective in the real environment, showing a classification accuracy of 88.25%, which is improved by about 8.12% according to whether the image cropping preprocessing is performed. Ultimately, we will proceed with procedures to apply the techniques and verify the functionality to field tests on various sites."
소형 네트워크에서 배치 정규화의 스케일링 인자를 활용한 채널 프루닝,2019,"['Convolutional Neural Network', 'Pruning', 'Classification', 'Embedded Systems']",,
딥러닝기반 다중 표적 인식을 활용한 모바일 로봇 경로 계획,2019,"['표적인식', '경로계획', '장애물 회피', '딥러닝', '모바일 로봇', 'Taget Detection', 'Path Planning', 'Avoidance Obstacle', 'Deep-Learning', 'Mobile Robot']","복합적인 고차원의 임무를 수행하기 위하여 미래무인화 전투 체게는 인공지능 기술을 필요로 한다. 특히 합성곱 신경망은 영상뿐만 아니라 자연어 처리까지 광범위한 범위에서 탁월한 성능을 보이고 있어 무인화 전투체계의 표적정보인식, 피아식별, 전장정보인식 등 각종 센서 융합에 매우 적합하다. 본 연구에서는 합성곱 신경망의 영상인식 기술을 활용하여 다수 대상체의 상태정보를 인식함으로써 변화되는 환경에서의 무인로봇 경로 계획 개선 방안을 제시하였고 시뮬레이션을 통하여 추정된 로봇의 위치, 장애물, 목표물 정보로부터 로봇의 경로 계획의 유효성을 검증 하였다.","Unmmanned systems are one of the essential areas of future military weapons systems that must carry out dangerous and cmplex missions. Especially, deep learning should recognize many landmarks through the image and project them onto the map to improve the problem of position estimation, because it shows excellent performance of recognizing and classifying the characteristics of image data among other artificial intelligence techniques. In this study, the path planning of the unmanned reconnaissance aircraft and the unmanned ground vehicle, which are currently being used in the ROK military, is linked with the CNN based multi target recognition algorithm without GPS. Throuth experiments, we verified the effectiveness of the path planning of the mobile robot with respect to the position of the robot, obstacle, and target point estimated by the target detection algorithm."
Faster R-CNN을 이용한 고속도로 통행량 및 속도 추정 구현,2019,"['Deep learning', 'Object Detection', 'Vehicle Speed Estimation', 'Traffic Estimation', 'Traffic Situation Analysis']",,
“인공지능은 인문학이다”: 구성적 정보 철학적 관점에서,2019,"['인공지능', '인문학', '정보 철학', '구성주의', 'artificial intelligence', 'humanities', 'philosophy of information', 'constructivism']","인공지능은 기계가 인간 지능을 가지도록 모색하는 컴퓨터과학의 한 분야이다. 이를 위하여 인간의 지능을 계산적 모델로 이해하기 위한 연구 분야이기도 한다. 그러므로 인공지능은 인간을 이해하기 위한 오랜 학문인 문사철의 인문학과 밀접한 관계가 있다. 더구나 인지과학의 발달로 인하여 인간에 대한 이해는 새로운 국면에 들어섰다고 할 수 있다. 인지과학의 한 분야이기도 한 인공지능은 포괄적으로 인간에 대한 이해를 도모하는 또 다른 측면의 인문학이라고 할 수 있다.  필자는 현재의 인공지능이 아직은 인문학적 인간 이해와는 많은 거리를 가지고 있지만 좀 더 발전된 인공지능을 위해서 인공지능은 인문학에 대한 이해가 필수적이고, 인문학 또한 좀 더 정교한 인간 이해를 위해서는 인공지능에 대한 이해와 인공지능적 상상력이 필요하다고 생각한다. 본 연구는 구성주의에 기반한 정보 철학이 인공지능과 인문학을 포괄적으로 이해하기 위한 방편이 될 수 있다고 논의한다.","Artificial intelligence is a branch of computer science that seeks to make machines have human intelligence. To this end, it is also a field of research to understand human intelligence as a computational model. Therefore, artificial intelligence is closely related to the humanities of Moon Sa-chul(Literature-History-Philosophy), a long-standing study to understand humans. Moreover, with the development of cognitive science, understanding of human beings has entered a new phase. Artificial intelligence, which is also an area of cognitive science, is another aspect of humanities that comprehensively promotes understanding of human beings.  I think that although current artificial intelligence still has a lot of distance from human understanding, for more advanced artificial intelligence, an understanding of humanities is essential, and for more sophisticated human understanding of humanities also requires an understanding of artificial intelligence and an artificial intelligence imagination. This study discusses that information philosophy based on constructivism can be a way to comprehensively understand artificial intelligence and humanities."
영상품질별 학습기반 알고리즘 폐색영역 객체 검출 능력 분석,2019,"['Deep Learning', '3D Modeling', 'Texturing', 'Image Quality', 'Occlusion Area', '딥러닝', '3차원 모델링', '텍스처링', '영상품질', '폐색영역']","정보화 사회로 진입하면서 공간정보의 중요성은 급격하게 부각되고 있다. 특히 스마트시티, 디지털트윈과 같은 Real World Object의 3차원 공간정보 구축 및 모델링은 중요한 핵심기술로 자리매김하고 있다. 구축된 3차원 공간정보는 국토관리, 경관분석, 환경 및 복지 서비스 등 다양한 분야에서 활용된다. 영상기반의 3차원 모델링은 객체 벽면에 대한 텍스처링을 생성하여 객체의 가시성과 현실성을 높이고 있다. 하지만 이러한 텍스처링은 영상 취득 당시의 가로수, 인접 객체, 차량, 현수막 등의 물리적 적치물에 의해 필연적으로 폐색영역이 발생한다. 이러한 폐색영역은 구축된 3차원 모델링의 현실성과 정확성 저하의 주요원인이다. 폐색영역 해결을 위한 다양한 연구가 수행되고 있으며, 딥러닝을 이용한 폐색영역 검출 및 해결방안에 대한 연구가 수행되고 있다. 딥러닝 알고리즘 적용한 폐색영역 검출 및 해결을 위해서는 충분한 학습 데이터가 필요하며, 수집된 학습 데이터 품질은 딥러닝의 성능 및 결과에 직접적인 영향을 미친다. 따라서 본 연구에서는 이러한 학습 데이터의 품질에 따라 딥러닝의 성능 및 결과를 확인하기 위하여 다양한 영상품질을 이용하여 영상의 폐색영역 검출 능력을 분석하였다. 폐색을 유발하는 객체가 포함된 영상을 인위적이고 정량화된 영상품질별로 생성하여 구현된 딥러닝 알고리즘에 적용하였다. 연구결과, 밝기값 조절 영상품질은 밝은 영상일수록 0.56 검출비율로 낮게 나타났고 픽셀크기와 인위적 노이즈 조절 영상품질은 원본영상에서 중간단계의 비율로 조절된 영상부터 결과 검출비율이 급격히 낮아지는 것을 확인할 수 있었다. F-measure 성능평가 방법에서 노이즈 조절한 영상품질 변화가 0.53으로 가장 높게 나타났다. 연구결과로 획득된 영상품질별에 따른 폐색영역 검출 능력은 향후 딥러닝을 실제 적용을 위한 귀중한 기준으로 활용될 것이다. 영상 취득 단계에서 일정 수준의 영상 취득과 노이즈, 밝기값, 픽셀크기 등에 대한 기준을 마련함으로써 딥러닝을 실질적인 적용에 많은 기여가 예상된다.","The importance of spatial information is rapidly rising. In particular, 3D spatial information construction and modeling for Real World Objects, such as smart cities and digital twins, has become an important core technology. The constructed 3D spatial information is used in various fields such as land management, landscape analysis, environment and welfare service. Three-dimensional modeling with image has the hig visibility and reality of objects by generating texturing. However, some texturing might have occlusion area inevitably generated due to physical deposits such as roadside trees, adjacent objects, vehicles, banners, etc. at the time of acquiring image Such occlusion area is a major cause of the deterioration of reality and accuracy of the constructed 3D modeling. Various studies have been conducted to solve the occlusion area. Recently the researches of deep learning algorithm have been conducted for detecting and resolving the occlusion area. For deep learning algorithm, sufficient training data is required, and the collected training data quality directly affects the performance and the result of the deep learning. Therefore, this study analyzed the ability of detecting the occlusion area of ​​the image using various image quality to verify the performance and the result of deep learning according to the quality of the learning data. An image containing an object that causes occlusion is generated for each artificial and quantified image quality and applied to the implemented deep learning algorithm. The study found that the image quality for adjusting brightness was lower at 0.56 detection ratio for brighter images and that the image quality for pixel size and artificial noise control decreased rapidly from images adjusted from the main image to the middle level. In the F-measure performance evaluation method, the change in noise-controlled image resolution was the highest at 0.53 points. The ability to detect occlusion zones by image quality will be used as a valuable criterion for actual application of deep learning in the future. In the acquiring image, it is expected to contribute a lot to the practical application of deep learning by providing a certain level of image acquisition."
A Text Sentiment Classification Method Based on LSTM-CNN,2019,"['Machine Learning', 'CNN', 'LSTM', 'Text Sentiment Classification Methods', 'Deep Learning', '텍스트 정서 분류 방법']","머신 러닝의 심층 개발로 딥 러닝 방법은 특히 CNN(Convolution Neural Network)에서 큰 진전을 이루었다. 전통적인 텍스트 정서 분류 방법과 비교할 때 딥 러닝 기반 CNN은 복잡한 다중 레이블 및 다중 분류 실험의 텍스트 분류 및 처리에서 크게 발전하였다. 그러나 텍스트 정서 분류를 위한 신경망에도 문제가 있다. 이 논문에서는 LSTM (Long-Short Term Memory network) 및 CNN 딥 러닝 방법에 기반 한 융합 모델을 제안하고, 다중 카테고리 뉴스 데이터 세트에 적용하여 좋은 결과를 얻었다. 실험에 따르면 딥 러닝을 기반으로 한 융합 모델이 텍스트 정서 분류의 예측성과 정확성을 크게 개선하였다. 본 논문에서 제안한 방법은 모델을 최적화하고 그 모델의 성능을 개선하는 중요한 방법이 될 것이다.","With the in-depth development of machine learning, the deep learning method has made great progress, especially with the Convolution Neural Network(CNN). Compared with traditional text sentiment classification methods, deep learning based CNNs have made great progress in text classification and processing of complex multi-label and multi-classification experiments. However, there are also problems with the neural network for text sentiment classification. In this paper, we propose a fusion model based on Long-Short Term Memory networks(LSTM) and CNN deep learning methods, and applied to multi-category news datasets, and achieved good results. Experiments show that the fusion model based on deep learning has greatly improved the precision and accuracy of text sentiment classification. This method will become an important way to optimize the model and improve the performance of the model."
인공지능 기반 수요예측 기법의 리뷰,2019,"['빅데이터', '인공지능', '수요예측', '머신러닝', '딥 러닝', 'big data', 'artificial intelligence', 'demand forecasting', 'machine learning', 'deep learning']","최근 다양한 분야에서 ‘빅데이터’가 생성되었다. 많은 기업들은 인공지능(AI)을 기반으로 빅데이터 분석이 가능한 시스템을 구축하여 이익 창출을 시도하고 있다. 인공지능 기술을 접목함으로써 방대한 양의 데이터를 효율적으로 분석하고 효과적으로 활용하는 것은 점점 더 중요해지고 있다. 특히 재무, 조달, 생산 및 마케팅과 같은 다양한 분야에서 국가 및 기업 경영 관리에있어 최소의 오차와 최대의 정확도를 갖춘 수요예측은 절대적으로 중요한 요소이다. 이 때 각 분야의 수요패턴을 고려한 적절한 모델을 적용하는 것이 중요하다. 전통적으로 쓰이는 시계열모델이나 회귀모델로도 비대해진 실제 데이터의 복잡한 비선형적인 패턴을 분석할 수 있다.그러나 다양한 비선형 모델들 중에서 적절한 모델을 선택하는 것은 사전 지식 없이는 어려운 일이다. 최근에는 인공지능 기반의 기법들인 머신러닝이나 딥러닝 기법을 중심으로 이루어진 연구들이 이를 극복할 수 있음을 증명하고 있다. 뿐만 아니라 정형데이터와 이미지나 텍스트의 비정형 데이터 분석을 통한 수요예측도 높은 정확도를 갖춘 결과를 보이고 있다. 따라서 본 연구에서는 수요예측이 비교적 활발하게 일어나는 중요한 분야들을 나누어 설명하였다. 그리고 각 분야별로 갖는 특징적인 성격을 고려한 인공지능 기반의 수요예측 기법에 대해 머신러닝과 딥러닝 기법으로 나누어 소개하였다.","Big data has been generated in various fields. Many companies have now tried to make profits by building a system capable of analyzing big data based on artificial intelligence (AI) techniques. Integrating AI technology has made analyzing and utilizing vast amounts of data increasingly valuable. In particular, demand forecasting with maximum accuracy is critical to government and business management in various fields such as finance, procurement, production and marketing. In this case, it is important to apply an appropriate model that considers the demand pattern for each field. It is possible to analyze complex patterns of real data that can also be enlarged by a traditional time series model or regression model.However, choosing the right model among the various models is difficult without prior knowledge. Many studies based on AI techniques such as machine learning and deep learning have been proven to overcome these problems. In addition, demand forecasting through the analysis of stereotyped data and unstructured data of images or texts has also shown high accuracy. This paper introduces important areas where demand forecasts are relatively active as well as introduces machine learning and deep learning techniques that consider the characteristics of each field."
CNN을 활용한 IoT 스트림 데이터 패턴 분류 기법,2019,"['IoT', '스트림 데이터', '딥러닝', '패턴 분류', 'IoT', 'stream data', 'deep learning', 'pattern analysis']","사물 인터넷(Internet of Things, IoT) 환경의 발달로 다양한 종류의 센서들로부터 대량의 데이터가 생성되고 있으며, 이를 수집, 관리 및 분석하기 위한 빅데이터 기술이 중요해지고 있다. 최근에는 실시간으로 생성되는 대용량의 IoT 데이터 분석에 딥러닝 기술을 활용하여 특정 데이터 패턴이나 경향성의 분석을 수행하기 위한 연구가 진행되고 있다. 본 논문에서는 헬스케어 등 IoT 기반 서비스에의 활용 가능성이 높은 스트림데이터 중 하나인 ECG(Electrocardiogram, 심전도) 데이터에 대하여, 딥러닝 모델을 설계 및 적용함으로써 효율적인 분석을 가능하도록 하였다. 먼저, ECG 스트림 데이터의 패턴 분류를 위하여 합성곱 신경망(Convolutional Neural Networks, CNN) 기반의 딥러닝 모델을 설계하고, 이를 최적화하기 위한 다양한 파라미터들을 각각 모델의 구조와 학습에 관련한 파라미터들로 분리하여 실험을 설계 및 진행하였다. 또한, 분류 작업의 추가적인 성능 향상을 위하여, ECG 스트림 데이터에 대한 전처리 기법을 고안하여 적용해 보았다. 이러한 다양한 조건을 기반으로 설계된 실험들은, 서로 다른 센서에서 서로 다른 목적으로 수집되어 서로다른 특성을 갖는 두 가지의 ECG 스트림 데이터 세트 에 대하여 각각 수행되었다. 그 결과, 레이어가 깊을수록, 배치 크기가 큰 학습 모델일수록 IoT 스트림 데이터의 패턴 분류에 용이한 모델 구조라는 결론을 얻을수 있었다.","These days due to the development of the Internet of Things environment, big data technology is becoming important for collecting and managing large amounts of data. Recent studies are being conducted to incorporate deep learning technology into Internet of Things(IoT) data analysis in order to classify the specific pattern and trends. In this paper, ECG(Electrocardiogram) data, which could be useful for IoT services, is the input steam data, and a deep learning model structure suitable for data characteristics is found, so that IoT data analysis is efficiently performed. In order to classify the IoT stream data pattern, the experiments were conducted to find the best suitable model structure using the convolutional neural networks. To optimize the CNN, various models and parameter values were used to design various experiments. Also to enhance the classification performance, a preprocessing step is added to the existing convolutional neural networks model. The model structure parameters and the model learning parameters are divided into two major conditions. The experiment environment is set up and applied to two time series data with different characteristics. It is concluded that the deeper the layer and the larger the batch size, the easier model structure for IoT data pattern classification."
DANN : 이산 산술 신경망,2019,"['DANN', '이산 산술 신경망', '딥 러닝', '기계 학습', '부울 공간', 'DANN', 'Discrete Arithmetic Neural Networks', 'Deep Learning', 'Machine Learning', 'Boolean Space']","딥러닝은 기계학습의 일종으로, 입력값과 결과값 사이의 적당한 함수를 역전파 알고리즘을 통해 구한다. 그러나 딥러닝은 훈련값의 패턴에 대해 추론하기보단 훈련값을 외우려는 현상이 짙고, 이는 훈련값에서 벗어난 데이터에 대해선 추론능력이 크게 떨어지는 오버핏(overfit) 현상을 보인다. 이 문제를 해결하기 위해, 본 논문에서는 실수 공간의 입력값과 출력값을 부울 공간으로 한정시킴으로써 문제를 해결하려는 Discrete Arithmetic Neural Networks (DANN)라는 알고리즘을 제시한다. DANN은 입력값과 출력값이 부울 공간으로 한정될 수 있는 경우, 부울 대수만을 이용하여 딥러닝을 설계할 수 있음을 보인다. 다만 부울 대수만으로는 역전파 알고리즘을 구현할 수 없으므로, 실수(float)를 적절히 이용하여 부울 연산을 모방한다. 결과적으로 이것이 부울 공간을 사용했을 때 LSTM 등 기존의 딥러닝 알고리즘을 사용했을 경우보다 성능이 우수함을 보인다.","Deep learning is a kind of machine learning, and a proper function between the input value and the result value is obtained through the back propagation algorithm. However, deep running is a phenomenon that attempts to memorize the training value rather than deducing the pattern of the training value, which shows overfitting phenomenon that the reasoning ability is greatly reduced for the data that deviates from the training value. To solve this problem, we propose an DANN to solve the problem by limiting input and output values ​​of real space to Boolean space. DANN shows that if the input and output values ​​can be limited to boolean spaces, we can design a deep running using only Boolean algebra. However, since Boolean algebra alone can not implement a back propagation algorithm, it imitates a Boolean operation using the float appropriately. As a result, it shows better performance when using Boolean space than using existing deep running algorithms such as LSTM."
심층신경망 알고리즘을 이용한 가상환경에서의 멀미 측정,2019,"['가상현실', '사이버 멀미', '뇌파', '딥러닝', 'Virtual Reality (VR)', 'Cybersickness', 'EEG', 'Deep Learning']","사이버 멀미는 VR 체험 중 발생하는 증상으로, 주로 감각과 인지 시스템 사이의 불일치로 인해 발생하는 것으로 추정된다. 하지만 감각 및 인지 시스템을 객관적으로 측정할 수 있는 방법이 없기 때문에, 사이버 멀미를 측정하는 것은 어렵다. 이를 해결하기 위해 사이버 멀미를 측정하기 위해 다양한 방법론들이 연구되고 있다. 기존의 멀미를 측정하기 위한 방법은 설문 방식을 이용하거나, 머신 러닝을 이용하여 뇌파 데이터를 분석하는 방식으로 진행되어 왔다. 하지만 설문을 이용한 방식은 객관성이 떨어지며, 머신 러닝을 사용하는 방식은 아직 정확한 측정이 불가능하다. 본 논문에서는 뇌파 데이터를 Deep Neural Network (DNN) 딥러닝 알고리즘에 적용하여 객관적인 사이버 멀미 측정 방식을 제안한다. 또한 우리는 더 정확한 사이버 멀미 측정 결과를 위하여 딥러닝 네트워크 구조와 뇌파 데이터 전처리 기법을 제안한다. 우리의 접근 방법은 최대 98.88%의 정확도로 사이버 멀미를 측정한다. 또한 우리는 실험에서 사이버 멀미를 유발하는 영상의 특성을 분석한다. 일반적으로 사이버 멀미는 상하 움직임이 심한 화면, 화면의 지속적이고 빠른 전환, 공중에 떠있는 상황에서 발생한다.","Cybersickness is a symptom of dizziness that occurs while experiencing Virtual Reality (VR) technology and it is presumed to occur mainly by crosstalk between the sensory and cognitive systems. However, since the sensory and cognitive systems cannot be measured objectively, it is difficult to measure cybersickness. Therefore, methodologies for measuring cybersickness have been studied in various ways. Traditional studies have collected answers to questionnaires or analyzed EEG data using machine learning algorithms. However, the system relying on the questionnaires lacks objectivity, and it is difficult to obtain highly accurate measurements with the machine learning algorithms. In this work, we apply Deep Neural Network (DNN) deep learning algorithm for objective cybersickness measurement from EEG data. We also propose a data preprocessing for learning and network structures allowing us to achieve high performance when learning EEG data with the deep learning algorithms. Our approach provides cybersickness measurement with an accuracy up to 98.88%. Besides, we analyze video characteristics where cybersickness occurs by examining the video segments causing cybersickness in the experiments. We discover that cybersickness happens even in unusually persistent changes in the darkness such as the light in a room keeps switching on and off."
지능형 관광 서비스를 위한 관광 사진 분류체계 개발,2019,"['플리커', 'SNS', '관광목적 사진 분류체계', '딥러닝', '합성곱신경망', '한국 관광', 'Flickr', 'Social Network Service', 'Photo Classification for Tourist purpose', 'Deep Learning', 'Convolutional Neural Network', 'Korea Tour']","최근 딥러닝 기술 가운데 이미지데이타 분석에 뛰어난 성능을 보이는 합성곱신경망 기술의 발전은 이미지 분석 영역에서다양한 가능성을 제시하고 있다. 관광객이 게시한 사진을 딥러닝 기술을 이용하여 분류하기 위해서는 관광사진에 대한 분류와목적에 맞는 딥러닝 모델의 훈련작업이 필수적으로 선행되어야 한다. 본 연구에서는 관광객이 플리커에 게시한 사진을 효율적으로분류하기 위해 관광목적으로 사진이 어떻게 분류되어야 하는지 관광목적 사진분류 체계를 개발하고자 하였다. 관광목적 사진분류 카테고리 개발을 위해 문헌분석, 웹사이트 분석, 관광객이 게시한 약 38,000장 사진의 검토과정을 거쳐 사진 분류 카테고리를개발하였으며, 약 8400장의 사진을 개발된 카테고리에 맞춰 분류해 봄으로써 개발된 카테고리의 검증과정을 거쳤다. 이 과정을거쳐 최종으로 제안된 카테고리는 13개 대분류, 64개 중분류, 164개의 세분류 체계를 갖으며, 본 연구 결과는 향후 관광목적사진을 딥러닝 모델을 이용하여 분류하고자 할 때 기초자료로 활용될 것으로 기대된다.","In recent years technology of Convolutional Neural Network (CNN) among the technologies of deep learning has evolved dramatically and has shown an outstanding performance in the analysis of image data. First of all, the training of deep learning model is prerequisite to classify the photos posted by the tourists on Web by applying CNN technology. In this study we aim to develop the photo classification system in view of travel purpose in order to classify the photos posted by tourists on Flickr. We developed the category for photo classification by reviewing around 38,000 photos posted by tourists as well as by analysing literatures and web sites, and then verified the category by classifying 8,400 photos one by one manually according to the category developed. The category we developed has 3 hierarchical levels such as 13 major classification, 64 medium classification and 164 minor classification. We expect that our study can applied in base material when one tries to classify the photos for travel purpose by using the CNN deep learning model."
CNN-LSTM 조합모델을 이용한 영화리뷰 감성분석,2019,"['CNN', 'LSTM', 'Deep Learning', 'Integrated Model', 'Movie Review', 'Sentiment Analysis', 'CNN', 'LSTM', '딥러닝', '조합모델', '영화리뷰', '감성분석']","인터넷 기술과 소셜 미디어의 빠른 성장으로 인하여, 구조화되지 않은 문서 표현도 다양한 응용 프로그램에사용할 수 있게 마이닝 기술이 발전되었다. 그 중 감성분석은 제품이나 서비스에 내재된 사용자의 감성을 탐지할 수 있는 분석방법이기 때문에 지난 몇 년 동안 많은 관심을 받아왔다. 감성분석에서는 주로 텍스트 데이터를이용하여 사람들의 감성을 사전 정의된 긍정 및 부정의 범주를 할당하여 분석하며, 이때 사전 정의된 레이블을이용하기 때문에 다양한 방향으로 연구가 진행되고 있다. 초기의 감성분석 연구에서는 쇼핑몰 상품의 리뷰 중심으로 진행되었지만, 최근에는 블로그, 뉴스기사, 날씨 예보, 영화 리뷰, SNS, 주식시장의 동향 등 다양한 분야에 적용되고 있다. 많은 선행연구들이 진행되어 왔으나 대부분 전통적인 단일 기계학습기법에 의존한 감성분류를 시도하였기에 분류 정확도 면에서 한계점이 있었다. 본 연구에서는 전통적인 기계학습기법 대신 대용량 데이터의 처리에 우수한 성능을 보이는 딥러닝 기법과 딥러닝 중 CNN과 LSTM의 조합모델을 이용하여 감성분석의 분류 정확도를 개선하고자 한다. 본 연구에서는 대표적인 영화 리뷰 데이터셋인 IMDB의 리뷰 데이터 셋을이용하여, 감성분석의 극성분석을 긍정 및 부정으로 범주를 분류하고, 딥러닝과 제안하는 조합모델을 활용하여극성분석의 예측 정확도를 개선하는 것을 목적으로 한다. 이 과정에서 여러 매개 변수가 존재하기 때문에 그수치와 정밀도의 관계에 대해 고찰하여 최적의 조합을 찾아 정확도 등 감성분석의 성능 개선을 시도한다. 연구결과, 딥러닝 기반의 분류 모형이 좋은 분류성과를 보였으며, 특히 본 연구에서 제안하는 CNN-LSTM 조합모델의 성과가 가장 우수한 것으로 나타났다.","Rapid growth of internet technology and social media is progressing. Data mining technology has evolved to enable unstructured document representations in a variety of applications. Sentiment analysis is an important technology that can distinguish poor or high-quality content through text data of products, and it has proliferated during text mining. Sentiment analysis mainly analyzes people's opinions in text data by assigning predefined data categories as positive and negative. This has been studied in various directions in terms of accuracy from simple rule-based to dictionary-based approaches using predefined labels. In fact, sentiment analysis is one of the most active researches in natural language processing and is widely studied in text mining. When real online reviews aren't available for others, it's not only easy to openly collect information, but it also affects your business. In marketing, real-world information from customers is gathered on websites, not surveys. Depending on whether the website's posts are positive or negative, the customer response is reflected in the sales and tries to identify the information. However, many reviews on a website are not always good, and difficult to identify. The earlier studies in this research area used the reviews data of the Amazon.com shopping mal, but the research data used in the recent studies uses the data for stock market trends, blogs, news articles, weather forecasts, IMDB, and facebook etc. However, the lack of accuracy is recognized because sentiment calculations are changed according to the subject, paragraph, sentiment lexicon direction, and sentence strength. This study aims to classify the polarity analysis of sentiment analysis into positive and negative categories and increase the prediction accuracy of the polarity analysis using the pretrained IMDB review data set. First, the text classification algorithm related to sentiment analysis adopts the popular machine learning algorithms such as NB (naive bayes), SVM (support vector machines), XGboost, RF (random forests), and Gradient Boost as comparative models.Second, deep learning has demonstrated discriminative features that can extract complex features of data. Representative algorithms are CNN (convolution neural networks), RNN (recurrent neural networks), LSTM (long-short term memory). CNN can be used similarly to BoW when processing a sentence in vector format, but does not consider sequential data attributes. RNN can handle well in order because it takes into account the time information of the data, but there is a long-term dependency on memory. To solve the problem of long-term dependence, LSTM is used. For the comparison, CNN and LSTM were chosen as simple deep learning models. In addition to classical machine learning algorithms, CNN, LSTM, and the integrated models were analyzed. Although there are many parameters for the algorithms, we examined the relationship between numerical value and precision to find the optimal combination. And, we tried to figure out how the models work well for sentiment analysis and how these models work. This study proposes integrated CNN and LSTM algorithms to extract the positive and negative features of text analysis. The reasons for mixing these two algorithms are as follows. CNN can extract features for the classification automatically by applying convolution layer and massively parallel processing. LSTM is not capable of highly parallel processing. Like faucets, the LSTM has input, output, and forget gates that can be moved and controlled at a desired time. These gates have the advantage of placing memory blocks on hidden nodes. The memory block of the LSTM may not store all the data, but it can solve the CNN's long-term dependency problem. Furthermore, when LSTM is used in CNN's pooling layer, it has an end-to-end structure, so that spatial and temporal features can be designed simultaneously. In combination with CNN-LSTM, 90.33% accuracy was measured. Thi..."
Inception V3를 이용한 뇌 실질 MRI 영상 분류의 정확도 평가,2019,"['Deep-learning', 'Inception V3', 'Keras', 'Brain MR image', '딥러닝', '인셉션 V3', '케라스', '파이썬', '뇌 실질 MRI 의료영상']","의료영상으로 생성된 데이터의 양은 전문적인 시각적 분석 한계를 점점 초과하여, 자동화된 의료영상 분석의 필요성이 증가되고 있는 실정이다. 이러한 이유 등으로 인하여 본 논문에서는 정상소견과 종양소견을 보이는 각각의 뇌 실질 MRI 의료영상을 이용하여 Inception V3 딥러닝 모델을 이용한 종양 유무에 따른 분류 및 정확도를 평가하였다. 연구 결과, 딥러닝 모델의 정확도 평가는 학습 데이터 세트의 경우 90%, 검증 데이터 세트의 경우 86%의 정확도를 나타내었다. 손실률 평가에서는 학습 데이터 세트의 경우 0.56, 검증 데이터 세트의 경우 1.28의 손실률을 나타내었다. 향 후 연구에서는 딥러닝 모델의 성능 향상 및 평가의 신뢰성 확보를 위하여 공개된 의료영상의 데이터를 충분히 확보하고, 라벨링 분류 작업을 통한 라벨링의 정확도를 개선하여 모델링을 구현해 볼 필요가 있다고 사료된다.","The amount of data generated from medical images is increasingly exceeding the limits of professional visual analysis, and the need for automated medical image analysis is increasing. For this reason, this study evaluated the classification and accuracy according to the presence or absence of tumor using Inception V3 deep learning model, using MRI medical images showing normal and tumor findings. As a result, the accuracy of the deep learning model was 90% for the training data set and 86% for the validation data set. The loss rate was 0.56 for the training data set and 1.28 for the validation data set. In future studies, it is necessary to secure the data of publicly available medical images to improve the performance of the deep learning model and to ensure the reliability of the evaluation, and to implement modeling by improving the accuracy of labeling through labeling classification."
스마트 그리드 시스템을 위한 전력선 통신 시스템의 종단 간 방식의 간섭 제거 기법,2019,"['Power Line Communication', 'Smart Grid System', 'Interference Cancellation', 'End-to-end', 'Impulsive Noise', 'Deep Learning', 'Channel Estimation']","본 논문은 스마트 그리드를 위한 전력선 통신 시스템에서 데이터 신뢰성을 향상시키는 딥러닝 기반의 종단 간 방식의 간섭 제거 알고리즘에 대해 연구하였다. 본 논문에서 제안한 기법은 딥러닝 기술을 적용하여 채널에서 발생하는 잡음을예측하여 제거하는 기술로서 수신단에서 딥러닝에 의해 학습된 잡음들을 활용하여 효과적으로 잡음을 제거함으로써 신호의품질을 향상시킬 수 있다. 딥러닝 기술의 잡음 예측 정확도를 향상시키기 위해 기존의 잡음 형태를 데이터베이스화하여 활용하였다. 채널 모델로서 Middleton Class A 간섭 모델을 사용하였고, 비트 오류율을 평가하여 성능을 검증하였다. 모의실험을통해 간섭 제거 기법이 적용된 시스템 모델과 이론적인 모델의 비트오류율을 비교하여 제안하는 시스템이 잡음을 효과적으로 제거하여 신호의 품질 성능을 향상시킬 수 있음을 확인하였다. 제안한 시스템 모델은 전력선 통신뿐만 아니라 일반적인통신 시스템에서도 신호의 품질을 향상시킬 수 있도록 다양하게 적용이 가능하다.","In this paper, we propose the interference cancellation scheme of end-to-end method algorithm for power line communication (PLC) systems in smart grid. The proposed scheme estimates the channel noise information of receiver by applying a deep learning model at the receiver. Then, the estimated channel noise is updated in database. In the modulator, the channel noise which reduces the power line communication performance is effectively removed through interference cancellation technique. As an impulsive noise model, Middleton Class A interference model was employed.The performance is evaluated in terms of bit error rate (BER). From the simulation results, it is confirmed that the proposed scheme has better BER performance compared to the theoretical model based on additive white Gaussian noise.As a result, the proposed interference cancellation with deep learning improves the signal quality of PLC systems by effectively removing the channel noise. The results of the paper can be applied to PLC for smart grid and general communication systems."
영상에서 패치기반 CNN 모형을 이용한 잡음제거,2019,"['딥러닝', '잡음영상', '잡음제거', 'convolutional neural network', 'Convolutional neural network (CNN)', 'deep learning', 'noise reduction', 'noisy image']","영상에서 잡음제거는 패턴인식, 영상압축, 에지검출, 영상분할과 같은 영상처리 분야의 전처리과정으로 도전할 만한 가치가 있다. 본 논문에서는 딥러닝의 convolutional neural network (CNN) 모형을 이용하여 잡음제거 하고자 한다. CNN 모형은 영상인식, 물체인식 얼굴인식과 같은 컴퓨터 비전 문제에서 좋은 성능을 보이고 있으나 잡음제거에 대해서는 그 중요성에 비추어 아직까지 연구가 덜 이루어졌다. 지금까지 영상에서 잡음제거는 특정한 분포 특성을 갖고 있다는 가정 하에서 설계된 고유한 필터를 사용하였다. 이 경우 가정을 만족하지 않는 필더를 사용하는 경우 성능이 현저히 떨어지는 경향이 있다. 본 논문에서는 잡음에 대한 사전정보 없이 사용가능한 방법으로 영상의 작은 블록인 패치 (patch) 상에서 CNN을 적용하고 중첩된 패치(overlapped patches)에서 해당 픽셀들의 가중평균을 구하여 잡음제거 영상을 얻는다. CNN에서 매개변수 최적화는 잡음데이터에 적응력이 좋은 Adam 알고리즘을 사용한다. 영상실험은 가우시안 잡음영상과 임펄스 잡음영상 모두를 고려하였고 실험결과, 패치기반 CNN 모형은 다른 방법보다 좋은 화질의 영상을 도출하였고 또한 MAE (mean absolute error)와 PSNR (peak signal-to-noise ratio) 면에서도 좋은 성능을 지님을 알 수 있었다.","Noise reduction problem in images still prevails as a challenge in the field of image processing such as pattern recognition, image compression, edge detection and image segmentation. Addressing this issue, this paper presents a novel deep learning approach based on a Convolutional Neural Network (CNN) . CNN has shown excellent performance in computer vision problems such as image recognition, object recognition, and face recognition, but little has been discussed in light of the importance of noise reduction in images. Until now, noise reduction in the images has been used with filters designed under the assumption that it has specific distribution characteristics. In this case, the use of filters that do not satisfy the assumption leads to significant performance degradation. In this paper, CNN is applied on patches of images in a way that is available without prior information about noise. The restored image is obtained by the weighted average of the corresponding pixels in overlapping patches. In CNN, parameter optimization is done by the Adam algorithm that is adaptable to noise data. We considered both Gaussian noise and impulse noise to test the performance of our CNN model. Experimental results on several images show that the patch-based CNN model yields significantly superior image quality and better MAE (mean absolute error) and PSNR (peak signal-to-noise ratio)."
이벤트 기반 신경텐서망을 이용한 뉴스 데이터의 자질 구성 방법,2019,"['딥러닝', '비정형 데이터', '뉴스 데이터', '자질 구성', '이벤트 임베딩', '신경텐서망', 'deep learning', 'unstructured data', 'news data', 'feature composition', 'event embedding', 'neural tensor network']","뉴스 데이터는 정보 분석 및 정보 추출, 추론 등의 자연어처리 분야에서 원시 데이터로 많이 사용되고 있다. 최근 딥러닝을 이용한 분산 표현을 통해 자동으로 자질을 추출할 뿐만 아니라 텍스트의 문맥 정보를 이용하여 단어 간의 관계, 의미 정보를 표현하는 모델이 제안되었다. 본 논문은 뉴스 데이터로부터 구조화된 데이터를 추출하고 단어 간의 관계와 의미적인 정보를 모델에 반영하여 뉴스 데이터의 자질을 구성하는 방법론을 제안한다. 비정형 뉴스 데이터에서 의존 구문 분석을 통해 이벤트들을 자동으로 추출한다. 추출한 이벤트들을 신경텐서망 기술을 적용하여 뉴스 데이터에 대한 자질을 구성한다. 또한, 구성된 자질의 품질을 평가하기 위해 군집화를 수행하였다. 결과를 보았을 때, 이벤트 임베딩 방식이 단어 벡터의 합을 사용하는 것보다 군집화를 더 잘 수행 하였지만, 문서 전체의 카테고리를 대표하는 자질로 사용되기에는 한계점이 있었다.","News data is often used as raw data in the field of natural language processing such as information analysis, information extraction, and reasoning. In recent years, a model has been proposed that not only automatically extracts features through distributed representation using deep learning, but also expresses the relationship between words and semantic information using context information of the text. This paper proposes a method for extracting structured data from news data and constructing features by applying the relationship between words and semantic information in the model. We extracted the events from unstructured news data through dependency parsing. The extracted events are applied to the Neural Tensor Network to construct the document feature of the news data. Also, we evaluated the composed document features by document clustering. Consequently, although the event embedding method performed better clustering than using the sum of word vectors, there was a limit to be used as a feature of representing the category of the entire document."
적은 양의 데이터에 적용 가능한계층별 데이터 증강 알고리즘,2019,"['딥러닝', '데이터 증강', '고유값 분해', 'Deep learning', 'data augmentation', 'Eigen decomposition']","데이터 증강(Data Augmentation)은 적은 양의 데이터를 바탕으로 다양한 알고리즘을 통해 데이터의 양을 늘리는 기술이다. 현실 문제를 해결하기 위해 기계학습 및 딥러닝 기법을 사용하는 경우, 데이터 셋이 부족한 경우가 많다. 데이터의 부족은 모델 학습 시, 데이터 셋의 특징을 잘 반영하지 못하는 것 이외에도 과소적합 및 과적합에 빠질 위험이 크다. 따라서 본 논문에서는 오토인코더와 고유값 분해를 기반으로 하는 데이터 증강 기법을 통해 데이터를 증강 시키고 이를 심층 신경망의 각 층 마다 적용하여, 심층 신경망을 효과적으로 사전 학습하는 방법을 제시한다. 이후, WOBC 데이터와 WDBC 데이터에 대해 실험을 통하여 논문에서 제안하는 방법이 분류 정확도를 향상시키는지 측정하고 기존 연구들과 비교함으로써 제안한 방법이 실질적으로 의미가 있는 데이터를 생성하고 모델의 학습에 효과적임을 보인다.","Data augmentation is a method that increases the amount of data through various algorithms based on a small amount of sample data. When machine learning and deep learning techniques are used to solve real-world problems, there is often a lack of data sets. The lack of data is at greater risk of underfitting and overfitting, in addition to the poor reflection of the characteristics of the set of data when learning a model. Thus, in this paper, through the layer-wise data augmenting method at each layer of deep neural network, the proposed method produces augmented data that is substantially meaningful and shows that the method presented by the paper through experimentation is effective in the learning of the model by measuring whether the method presented by the paper improves classification accuracy."
디노이징 필터와 LSTM을 활용한 KOSPI200 선물지수 예측,2019,"['디노이징 필터', '슬라이딩 윈도우', 'KOSPI200 선물지수', 'LSTM', 'Denoising filter', 'KOSPI200 future index', 'sliding window']","딥러닝 모형을 통해 금융시장을 예측하는 연구는 활발하지만 디노이징 필터를 적용하여 금융 데이터의 노이즈를 제거함으로써 예측 모형의 성능을 높이는 연구는 거의 이루어지지 않고 있다. 따라서, 본 연구의 목적은 디노이징 필터를 사용하여 데이터의 노이즈를 제거한 후 시계열 예측에 유용한 딥러닝 모형인 LSTM의 예측 성능을 높이는 것이다. KOSPI200 선물지수의 일봉과 30분봉 데이터를 이용해 실증분석을 하였다. 디노이징 필터를 적용한 예측 모형의 성능이 기존 LSTM보다 전체 기간 실험과 슬라이딩 윈도우 실험을 통해 우수함을 입증하였다. 또한, 제안한 디노이징 필터 중 사비츠키-골레이 필터가 이동평균 필터보다 예측 모형 성능 향상에 유용함을 확인하였다. 향후, 디노이징 필터가 다양한 딥러닝 모형의 예측 성능 향상에 사용될 수 있음을 기대한다.","There has been many studies which predict the financial market using the deep learning model. However, there has been few studies which apply the denoising filter that improves the performance of predictions removing the noise of financial data. Therefore, the purpose of this study is to apply denoising filter to remove noise from data and then to improve the prediction performance of long short term memory, a deep learning model which is useful for time series prediction. We conducted an empirical analysis using daily and 30 min KOSPI200 futures index data. It is proven that the performance of prediction model using denoising filter is superior to that of the previous long short term memory for the whole period and the sliding window experiment. Also, we confirmed that savitzky-golay filter is more useful for improving the prediction model performance than moving average filter. In the future, denosing filter may be used to improve the prediction performance of various deep learning models."
Atrous Convolution과 Grad-CAM을 통한 손 끝 탐지,2019,"['Deep Learning', 'Atrous Convolution', 'Grad-CAM', 'Object Detection', '딥러닝', 'Atrous Convolution', 'Grad-CAM', '객체 탐지']","딥러닝 기술의 발전으로 가상 현실이나 증강 현실 응용에서 사용하기 적절한 사용자 친화적 인터페이스에 관한 연구가 활발히 이뤄지고 있다. 본 논문은 사용자의 손을 이용한 인터페이스를 지원하기 위하여 손 끝 좌표를 추적하여 가상의 객체를 선택하거나, 공중에 글씨나 그림을 작성하는 행위가 가능하도록 딥러닝 기반 손 끝 객체 탐지 방법을 제안한다. 입력 영상에서 Grad-CAM으로 해당 손 끝 객체의 대략적인 부분을 잘라낸 후, 잘라낸 영상에 대하여 Atrous Convolution을 이용한 합성곱 신경망을 수행하여 손 끝의 위치를 찾는다. 본 방법은 객체의 주석 전처리 과정을 별도로 요구하지 않으면서 기존 객체 탐지 알고리즘 보다 간단하고 구현하기에 쉽다. 본 방법을 검증하기 위하여 Air-Writing 응용을 구현한 결과 평균 81%의 인식률과 76 ms 속도로 허공에서 지연 시간 없이 부드럽게 글씨 작성이 가능하여 실시간으로 활용 가능함을 알 수 있었다.","With the development of deep learning technology, research is being actively carried out on user-friendly interfaces that are suitable for use in virtual reality or augmented reality applications. To support the interface using the user's hands, this paper proposes a deep learning-based fingertip detection method to enable the tracking of fingertip  coordinates to select virtual objects, or to write or draw in the air. After cutting the approximate part of the corresponding fingertip object from the input image with the Grad-CAM, and perform the convolution neural network with Atrous Convolution for the cut image to detect fingertip location. This method is simpler and easier to implement than existing object detection algorithms without requiring a pre-processing for annotating objects. To verify this method we implemented an air writing application and showed that the recognition rate of 81% and the speed of 76 ms were able to write smoothly without delay in the air, making it possible to utilize the application in real time."
Bi-LSTM 기반 감성분석을 위한 대용량 학습데이터 자동 생성 방안,2019,"['감성분석', '딥러닝', '학습데이터', '감성사전', '의존 구문 분석', '형태소 분석', 'sentiment analysis', 'deep learning', 'train set', 'sentiment lexicon', 'dependency parsing', 'morphological analysis']","딥러닝을 이용한 감성분석에서는 감성이 레이블 된 많은 양의 학습데이터가 필요하다. 그러나 사람이 직접 감성을 레이블 하는 것은 시간과 비용에 제약이 있고 많은 데이터에서 감성분석에 적합한 충분한 양의 데이터를 수집하는 것은 쉽지 않다. 본 논문에서는 이러한 문제점을 해결하기 위해 기존의 감성사전을 활용하여 감성점수를 매긴 후 감성 변환 요소가 존재하면 의존 구문 분석 및 형태소 분석을 수행해 감성점수를 재설정하여 감성이 레이블 된 대용량 학습데이터를 자동 생성하는 방안을 제안한다. 감성변환 요소로는 감성 반전, 감성 활성화, 감성 비활성화가 있으며 감성점수가 높은 Top-k의 데이터를 추출하였다. 실험 결과 수작업에 비해 짧은 시간에 대용량의 학습데이터를 생성하였으며 학습데이터의 양이 증가함에 따라 딥러닝의 성능이 향상됨을 확인하였다. 그리고 감성사전만을 사용한 모델의 정확도는 80.17%, 자연어처리 기술을 추가한 제안 모델의 정확도는 89.17%로 9%의 정확도 향상을 보였다.","Sentiment analysis using deep learning requires a large-scale train set labeled sentiment.However, direct labeling of sentiment by humans is time and cost-constrained, and it is not easy to collect the required data for sentiment analysis from many data. In the present work, to solve the existing problems, the existing sentiment lexicon was used to assign sentiment score, and when there was sentiment transformation element, the sentiment score was reset through dependency parsing and morphological analysis for automatic generation of large-scale train set labeled with the sentiment. The Top-k data with high sentiment score was extracted. Sentiment transformation elements include sentiment reversal, sentiment activation, and sentiment deactivation. Our experimental results reveal the generation of a large-scale train set in a shorter time than manual labeling and improvement in the performance of deep learning with an increase in the amount of train set. The accuracy of the model using only sentiment lexicon was 80.17% and the accuracy of the proposed model, which includes natural language processing technology was 89.17%. Overall, a 9% improvement was observed."
이미지를 사용한 가상의상착용 알고리즘들의 성능 분석,2019,"['가상착용', '딥러닝', '이미지 기반', '2D 변형', '성능 평가', 'Virtual-Try-On', 'Deep-learning', 'Image-based', '2D deformation', 'Quality evaluation']","가상착용기술(VTON: Virtual try-on)은 의상의 온라인 유통을 활성화를 위하여 중요한 기술이 다. 그러나 3차원 그래픽스기반 방식은 의상과 인체의 3차원 정보의 확보가 필요하여 범용화에 어려움이 있고, 이러한 제약을 해소하기 위해 개발되는 이미지 기반 방식들의 연구들은 그 기술적 한계가 불명확하 다. 구체적으로 VITON (Virtual image try-on) 과 CP-VTON (Content preserving VTON)등은 가능성 위 주의 매우 단편적인 결과만을 제시하고 있다. 본 논문은 이미지기반 기술의 상용화의 한계를 파악하기 위 해, 세 가지 대표적 방식(SCMM 기반의 비-딥러닝 방식, 딥러닝기반 VITON 과 CP-VTON에 대하여 인물 의 자세 및 체형, 의상의 가려짐 정도, 의상의 특성 등에 따라 분석을 하였다. 객관적인 평가를 위하여 변 형단계와 합성단계의 성능을 각각 IoU와 SSIM로 평가하였고, 상대적인 비교 분석을 하였다. 그 결과, CP-VTON이 가장 좋은 성능을 보이지만, 자세와 의상의 복잡도에 따라 성능의 한계가 크게 차이가 남을 보였다. 그 주 원인은 2차 기하변형의 한계와 GAN을 통한 합성 기술의 한계로 파악되었다.",
트랜스포머를 이용한 향상된 댓글 생성에 관한 연구,2019,"['Deep Learning(딥 러닝)', 'Natural Language Processing(자연어 처리)', 'Self-Attention(셀프-어텐션)', 'Transformer(트랜스포머)']","온라인 커뮤니티 안에서 다른 사용자들의 글에 반응할 수 있는 딥러닝 연구를 2017년부터 진행해 왔으나, 한국어의 조사와 같은 특성으로 인한 단어처리의 어려움과 RNN 모델의 특성으로 인한 GPU 사용률 저조 문제로 인해 적은 양의 데이터로 학습을 제한해야 했다. 하지만 최근 자연어 처리 분야의 급격한 발전으로 이전보다 뛰어난 모델들이 등장함에 따라 본 연구에서는 이러한 발전된 모델을 적용해 더 나은 학습 결과를 생성해 내는 것을 목표로 한다. 이를 위해 셀프-어텐션 개념이 적용된 트랜스포머모델을 도입했고 여기에 한국어 형태소 분석기 MeCab을 적용해 단어처리의 어려움을 완화했다.","We have been studying a deep-learning program that can communicate with other users in online communities since 2017. But there were problems with processing a Korean data set because of Korean characteristics. Also, low usage of GPUs of RNN models was a problem too. In this study, as Natural Language Processing models are improved, we aim to make better results using these improved models. To archive this, we use a Transformer model which includes Self-Attention mechanism. Also we use MeCab, korean morphological analyzer, to address a problem with processing korean words."
대비 결합 CNN을 이용한 인공위성 사진 내 선박 탐지 정확도 향상 연구,2019,"['인공위성 영상', '딥러닝', 'CNN', '영상처리', '이미지 대비 융합', '최적화', 'satellite image', 'deep learning', 'CNN', 'image processing', 'image contrast fusion', 'optimization']","인공위성은 지상관측이나 통신, 해양, 방송 등의 임무를 가지며 인공위성 사진을 이용한 선박 탐지는 해상 보안 및 교통 통제 등 쓰임새가 다양하다. 인공위성 사진의 특성은 지구 전역을 촬영하기 때문에 저장되는 데이터양이 많고 각 사진은 초고해상도로 크기가 매우 커 컴퓨터를 이용한 자동 선박 탐지가 필요하다. 기존 연구에서는 여러 딥러닝 모델을 이용하여 선박 탐지 연구를 진행하였지만, 인공위성 사진 특성으로 인한 처리속도가 문제되어 상대적으로 빠른 CNN 모델을 이용하여 연구가 진행되고 있다. 그러나 선박이 있는 선착장과 등대, 파도 등 여러 가지 요인으로 인해서 대부분 정확도와 성능을 높이는데 어려움을 가지고 있다. 따라서 이 논문에서는 이미지 명암 대비 향상을 기존 CNN(Convolution Neural Network)에 접목해 정확도와 성능을 높인 모델을 제안한다. 또한, 학습 단계에서 선박 분류에 필요한 데이터의 양을 늘리기 위해 overlap과 rotation 기능을 이용하고 실제 인공위성 사진에서 탐지 속도를 줄이기 위해 탐지 최적화(window sliding)를 고려하여 자동화 탐지 기술을 구현한다. 식별된 선박 데이터는 다시 학습데이터로 사용하여 정확도를 높이고 실제 산업에서 사용할 수 있도록 구현한다.","The satellite has various missions such as ground/marine observation, communication, broadcasting, etc. Satellite photographs provide information for the maintenance of marine security and traffic control for ship detection. Since satellite photos are taken all over the earth, the memory storage is not sufficient to hold such data with each data being of a high resolution and requiring automatic ship detection using the computer. The existing literature on ship detection employed several deep learning models. However, the problem of processing speed due to the characteristics of satellite photographs leads to the necessity of using a CNN(Convolution Neural Network) model that has a comparably high processing speed. On the contrary, it is difficult to improve the accuracy and performance mostly due to factors such as marina, lighthouses and waves. Therefore, in this paper, we propose a model that improves the accuracy and performance by combining image contrast enhancement with the existing CNN. In addition, we have employed the overlap and rotation functions to increase the amount of data required for ship classification in the learning stage and implement automation detection technology considering window sliding to reduce detection speed in real satellite photographs. Also, the identified ship data has been used as learning data to improve accuracy for the model that can be used in the real industry."
3차원 가상도시 모델에서 높이맵을 이용한 CNN 기반의 그림자 탐지방법,2019,"['그림자 탐지', '딥러닝', 'Shadow detection', 'Deep-learning']","최근 교육, 제조, 건설 등 다양한 응용 분야에서 사실적인 가상환경을 표현하기 위하여 실세계 영상데이터를 활용하는 사례가 증가하고 있다. 특히, 스마트 시티 등 디지털 트윈에 대한 관심이 높아지면서, 항공 영상 등 실제 촬영한 영상을 이용하여 현실감 있는 3D 도시 모델을 구축하고 있다. 그러나, 촬영된 항공 영상에는 태양에 의한 그림자가 포함되어 있으며, 그림자가 포함된 3D 도시 모델은 사용자에게 정보를 왜곡시켜 표현하는 문제를 안고 있다. 그림자를 제거하기 위하여 그동안 많은 연구가 진행되었지만, 아직 까지 해결하기 어려운 도전적인 문제로 인식되고 있다. 본 논문에서는 VWorld에서 제공하는 3차원 공간정보를 이용하여 건물의 높이맵을 포함한 가상환경 데이터 셋을 구축하고, 높이맵과 딥러닝을 이용한 새로운 그림자 탐지 방법을 제안한다. 실험 결과에 의하면, 높이맵을 사용했을 때 기존 방법보다 그림자 탐지 에러율이 감소한 것을 확인할 수 있다.","Recently, the use of real-world image data has been increasing to express realistic virtual environments in various application fields such as education, manufacturing, and construction. In particular, with increasing interest in digital twins like smart cities, realistic 3D urban models are being built using real-world images, such as aerial images. However, the captured aerial image includes shadows from the sun, and the 3D city model including the shadows has a problem of distorting and expressing information to the user. Many studies have been conducted to remove the shadow, but it is recognized as a challenging problem that is still difficult to solve. In this paper, we construct a virtual environment dataset including the height map of buildings using 3D spatial information provided by VWorld, and We propose a new shadow detection method using height map and deep learning. According to the experimental results, We can observed that the shadow detection error rate is reduced when using the height map."
관절질환 관리를 위한 Mask R-CNN을 이용한 모션 모니터링,2019,"['CNN', '휴먼모션', '헬스케어', '딥러닝', 'Mask R-CNN', '개인건강기록', 'CNN', 'Human Motion', 'Healthcare', 'Deep Learning', 'Mask R-CNN', 'Personal Health Record']","현대사회는 생활과 개성이 중요시 되면서 개인화된 생활습관 및 패턴이 생기고 있으며, 잘못된 생활습관으로 인해 관절질환자가 증가하고 있다. 또한 1인 가구가 점점 증가하면서 응급상황이 발생할 경우 알맞은 시간에 응급처치를 받지 못하는 경우가 생긴다. 건강과 질병관리에 필요한 개인의 상태에 따른 정확한 분석을 통해 스스로 관리할 수 있는 정보와 응급상황에 맞는 케어가 필요하다. 딥러닝 중에서 CNN은 데이터의 분류 및 예측에 효율적으로 사용된다. CNN은 데이터 특징에 따라 정확도 및 처리 속도에 차이를 보인다. 따라서 실시간 헬스케어를 위해 처리속도 향상과 정확도 개선이 필요하다. 본 논문에서는 관절질환 관리를 위한 Mask R-CNN을 이용한 모션 모니터링을 제안한다. 제안하는 방법은 Mask R-CNN을 이용하여 CNN의 정확도와 처리 속도를 개선하는 방법이다. 사용자의 모션을 신경망에 학습시킨 후 사용자의 모션이 학습된 데이터와 차이가 있을 경우 사용자에게 관리법을 피드백 해주고 보호자에게 응급상황을 알릴 수 있으며 상황에 맞는 적절한 조치를 취할 수 있다.","In modern society, lifestyle and individuality are important, and personalized lifestyle and patterns are emerging. The number of people with articulation diseases is increasing due to wrong living habits. In addition, as the number of households increases, there is a case where emergency care is not received at the appropriate time. We need information that can be managed by ourselves through accurate analysis according to the individual's condition for health and disease management, and care appropriate to the emergency situation. It is effectively used for classification and prediction of data using CNN in deep learning. CNN differs in accuracy and processing time according to the data features. Therefore, it is necessary to improve processing speed and accuracy for real-time healthcare. In this paper, we propose motion monitoring using Mask R-CNN for articulation disease management. The proposed method uses Mask R-CNN which is superior in accuracy and processing time than CNN. After the user's motion is learned in the neural network, if the user's motion is different from the learned data, the control method can be fed back to the user, the emergency situation can be informed to the guardian, and appropriate methods can be taken according to the situation."
전수 학습을 이용한 도로교통표지 데이터 분류 효율성 향상 연구,2019,"['전수학습', '도로교통표지', '수치지도제작', '딥러닝', '분류', 'Transfer Learning', 'Road Traffic Sign', 'Digital Mapping', 'Deep Learning', 'Classification']","본 연구에서는 1/1,000 수치지형도 및 정밀도로지도 제작에 있어서 도로 레이어를 구성하고 있는 교통안전표지 및 도로표지의 제작 공정에 있어서 딥러닝의 적용방안을 탐색하였다. 딥러닝의 이미지 분류에서 활용하는 전수학습을 이용하여 취득한 영상에 대한 학습자료 구축을 통해 도로 표지정보의 자동분류를 수행하였다. 분석결과 주의, 규제, 지시, 보조는 촬영된 이미지의 품질 및 형태 등 여러 가지 요소에 의해 정확도가 불규칙하게 나타났지만, 안내표지의 경우는 정확도가 97% 이상으로 높게 나타났다. 수치지도제작에 있어 전수학습을 이용한 이미지 자동분류 방식은 교통안전표지를 포함한 다양한 레이어들에 대한 자료 취득과 분류에 있어서 활용이 증가할 것으로 기대한다.","In this study, we investigated the application of deep learning to the manufacturing process of traffic and road signs which are constituting the road layer in map production with 1 / 1,000 digital topographic map. Automated classification of road traffic sign images was carried out through construction of training data for images acquired by using transfer learning which is used in image classification of deep learning. As a result of the analysis, the signs of attention, regulation, direction and assistance were irregular due to various factors such as the quality of the photographed images and sign shape, but in the case of the guide sign, the accuracy was higher than 97%. In the digital mapping, it is expected that the automatic image classification method using transfer learning will increase the utilization in data acquisition and classification of various layers including traffic safety signs."
Faster R-CNN 기반의 관심영역 유사도를 이용한 후방접근차량 검출 연구,2019,"['Deep lerning', 'Faster r-cnn', 'Agricultural machine', 'Vehicle detection', 'Structure similarity']",본 논문에서는 농업 기계 시스템에서 사용하기 위한 딥러닝 알고리즘 기반의 프레임 내의 관심 영역 유사성을 이용한 새로운 후방 접근 차량 검출 알고리즘을 제안한다. 농업 기계 시스템은 후방에서 접근하는 차량만 검출해야 한다. 지나가는 자동차가 검출되면 혼란을 야기할 수 있다. 논문에서는 차량 검출을 위해 딥러닝에서 뛰어난 검출률을 나타내는 FasterR-CNN 모델을 사용하였다. 딥러닝은 뒤에서 접근하는 차량뿐만 아니라 지나가는 차량도 검출하므로 긍정오류 차량을 배제해야 한다. 본 논문에서 이를 해결하기 위해 검출된 프레임에서 관심 영역에 대한 유사성과 평균 에러를 피라미드 형태로 이용하여 접근하는 자동차만 검출하는 알고리즘을 제안하였다. 실험을 통하여 제안된 방법이 평균 98.8%의 높은 검출률을 나타내었다.,"In this paper, we propose a new algorithm to detect rear-approaching vehicle using the frame similarity of ROI(Regionof Interest) based on deep learning algorithm for use in agricultural machinery systems. Since the vehicle detectionsystem for agricultural machinery needs to detect only a vehicle approaching from the rear. we use Faster R-CNN modelthat shows excellent accuracy rate in deep learning for vehicle detection. And we proposed an algorithm that uses theframe similarity for ROI using constrained conditions. Experimental results show that the proposed method has adetection rate of 99.9% and reduced the false positive values."
포지션 인코딩 기반 S³-Net를 이용한 한국어 기계 독해,2019,"['S³-Net', '한국어 기계독해', '포지션 인코딩', '딥러닝', 'S³-Net', 'Korean machine reading comprehension', 'position encoding', 'deep learning']","S³-Net은 Simple Recurrent Unit (SRU)과 자기 자신의 RNN sequence에 대하여 어텐션 가중치(attention weight)를 계산하는 Self-Matching Networks를 기반으로 기계 독해 질의 응답을 해결하는 딥 러닝 모델이다. 기계 독해 질의 응답에서 질문에 대한 답은 문맥 내에서 발생하는데, 하나의 문맥은 여러 문장으로 이뤄지기 때문에 입력 시퀀스의 길이가 길어져 성능이 저하되는 문제가 있다. 본 논문에서는 이와 같이 문맥이 길어져 성능이 저하되는 문제를 해결하기 위하여 문장 단위의 인코딩을 추가한 계층 모델과, 단어 순서 정보를 확인하는 포지션 인코딩을 적용한 S³-Net을 제안한다. 실험 결과, 본 논문에서 제안한 S³-Net 모델이 한국어 기계 독해 데이터 셋에서 기존의 S²-Net보다 우수한(single test) EM 69.43%, F1 81.53%, (ensemble test) EM 71.28%, F1 82.67%의 성능을 보였다.","S³-Net is a deep learning model that is used in machine reading comprehension question answering (MRQA) based on Simple Recurrent Unit and Self-Matching Networks that calculates attention weight for own RNN sequence. The answers to the questions in the MRQA occur within the passage, because any passage is made up of several sentences, so the length of the input sequence becomes longer and the performance deteriorates. In this paper, a hierarchical model that adds sentence-level encoding and S³-Net that applies position encoding to check word order information to solve the problem of long-term context degradation are proposed. The experimental results show that the S³-Net model proposed in this paper has a performance of 69.43% in EM and 81.53% in F1 for single test, and 71.28% in EM and 82.67 in F1 for ensemble test."
실시간 야구 중계를 위한 CNN 기반 고속 야구 선수 위치 검출 시스템,2019,"['image detection algorithm', 'deep learning', 'CNN', 'baseball broadcasting', '이미지 위치 검출', '딥러닝', 'CNN', '야구 경기 중계']","본 논문에서는 야구 경기 영상에서 딥 러닝 기법들 중 영상 인식에 적합한 CNN을 사용하여 야구 선수의 위치를 검출하는 시스템을 제안한다. 객체의 위치 검출을 위한 기존의 영상 처리 기법들 중 다수는 영상 프레임 사이의 차영상이나 객체의 윤곽을 얻는 방법들을 사용해왔지만, 야구 중계와 같이 다양한 기후와 배경을 모두 고려하여 실용화하기에는 추가적인 검증 과정이 필요하다. 본 논문에서는 다양한 경우에 움직이는 객체의 위치를 빠르게 학습하고 검출하기 위해 이진 블록 영상을 적용하였고 학습 성능을 향상시키기 위해 학습 영상을 추가로 생성하는 데이터 증강 기법을 사용하였다. 선수 위치의 정확도 평가 척도는 목표 객체의 중심점과 지능망을 통해 검출된 확률 중심과의 거리를 평가 척도로 적용하였다.실험 결과는 제안한 방법의 평균 거리가 2.92픽셀로 Faster R-CNN의 평균 거리인 3.35보다 0.43픽셀이 낮아 선수의 위치 검출 정확도가 높으며, 수행 속도도 제안한 방법이 Faster R-CNN보다 69.93배 빠름을 보여준다.","The paper proposes a player location detection system in a baseball game broadcast.Location detection system uses CNN (convolutional neural network) suitable for image processing among diverse deep learning systems. To train the location of a player faster and accurately, we choose binary block labeling instead of the commonly used edge detection methods. Data augmentation method, which generates additional training images was applied to increase the degree of accuracy.The distance between the center position of the target and the output position by neural network was used to measure performance. Experimental results indicated that the average pixel distances between center of target position and one of output are 2.92 and 3.35 in the case of the proposed method and Faster R-CNN, respectively. In addition, the execution time of the proposed method was established to be 69.93 times faster than that of Faster R-CNN."
단일 이미지에 기반을 둔 사람의 포즈 추정에 대한 연구 동향,2019,"['Deep learning', 'human pose', 'human pose estimation', 'action recognition', 'research trends', '딥러닝', '사람 포즈', '사람 포즈 추정', '행동인식', '연구 동향']","최근 딥러닝 기술이 발전함에 따라 많은 컴퓨터 비전 연구 분야에서 주목할 만한 성과들이 지속적으로 나오고 있다. 단일 이미지를 기반으로 사람의 2차원 및 3차원 포즈를 추정하는 연구에서도 비약적인 성능향상을 보여주고 있으며, 많은 연구자들이 문제의 범위를 확장하며 활발한 연구 활동을 진행하고 있다. 사람의 포즈 추정은 다양한 응용 분야가 존재하고, 특히 이미지나 비디오 분석에서 사람의 포즈는 행동 및 상태, 의도 파악을 위한 핵심 요소가 되기 때문에 상당히 중요한 연구 분야이다. 이러한 배경에 따라 본 논문은 단일 이미지를 기반으로 한 사람의 포즈 추정 기술에 대한 연구 동향을 살펴보고자 한다. 강인하고 정확한 문제 해결을 위해 다양한 연구 활동 결과가 존재한다는 점에서 본 논문에서는 사람의 포즈 추정 연구를 2차원 및 3차원 포즈 추정에 대해서 나누어 살펴보고자 한다. 끝으로 연구에 필요한 데이터 세트 및 사람의 포즈 추정 기술을 적용하는 다양한 연구 사례를 살펴볼 것이다.","With the recent development of deep learning technology, remarkable achievements have been made in many research areas of computer vision. Deep learning has also made dramatic improvement in two-dimensional or three-dimensional human pose estimation based on a single image, and many researchers have been expanding the scope of this problem. The human pose estimation is one of the most important research fields because there are various applications, especially it is a key factor in understanding the behavior, state, and intention of people in image or video analysis. Based on this background, this paper surveys research trends in estimating human poses based on a single image. Because there are various research results for robust and accurate human pose estimation, this paper introduces them in two separated subsections: 2D human pose estimation and 3D human pose estimation. Moreover, this paper summarizes famous data sets used in this field and introduces various studies which utilize human poses to solve their own problem."
비프로파일링 기반 전력 분석의 성능 향상을 위한 오토인코더 기반 잡음 제거 기술,2019,"['Side-Channel Analysis', 'Non-Profiled Attack', 'Deep Learning', 'Auto-Encoder', 'Preprocessing']","최근 보안 디바이스의 물리적 취약성을 찾을 수 있는 부채널 분석 분야에서 딥러닝을 활용한 연구가 활발히진행되고 있다. 하지만, 최신 딥러닝 기반 부채널 분석 기술 연구는 템플릿 공격 등과 같은 프로파일링 기반부채널 분석 환경에서 파형을 옳게 분류하기 위한 연구에 집중되어 있다. 본 논문에서는 이전 연구들과 다르게 딥러닝을 신호 전처리 기법으로 활용하여 차분 전력 분석, 상관 전력 분석 등과 같은 논프로파일링 기반부채널 분석의 성능을 고도화할 수 있는 방법을 제안한다. 제안기법은 오토인코더를 부채널 분석 환경에 적합하게 변경하여 부채널 정보의 노이즈를 제거하는 전처리 기법으로, 기존 노이즈 제거 오토인코더는 임의로 추가한 노이즈에 대한 학습을 하였다면 제안하는 기법은 노이즈가 제거된 라벨을 사용하여 실제 데이터의 노이즈를 학습한다. 제안기법은 논프로파일링 환경에서 수행 가능한 전처리 기법이며 하나의 뉴런 네트워크의 학습만을 통해 수행할 수 있다. 본 논문에서는 실험을 통해 제안기법의 노이즈 제거 성능을 입증하였으며, 주성분분석 및 선형판별분석과 같은 기존 전처리 기법들과 비교하여 우수하다는 것을 보인다.'","In side-channel analysis, which exploit physical leakage from a cryptographic device, deep learning based attack has beensignificantly interested in recent years. However, most of the state-of-the-art methods have been focused on classifyingside-channel information in a profiled scenario where attackers can obtain label of training data. In this paper, we propose anew method based on deep learning to improve non-profiling side-channel attack such as Differential Power Analysis andCorrelation Power Analysis. The proposed method is a signal preprocessing technique that reduces the noise in a trace bymodifying Auto-Encoder framework to the context of side-channel analysis. Previous work on Denoising Auto-Encoder wastrained through randomly added noise by an attacker. In this paper, the proposed model trains Auto-Encoder through thenoise from real data using the noise-reduced-label. Also, the proposed method permits to perform non-profiled attack bytraining only a single neural network. We validate the performance of the noise reduction of the proposed method on realtraces collected from ChipWhisperer board. We demonstrate that the proposed method outperforms classic preprocessingmethods such as Principal Component Analysis and Linear Discriminant Analysis."
3차원 뇌 자기공명 영상의 비지도 학습 기반 비강체 정합 네트워크,2019,"['Deep Learning', 'Unsupervised Learning', 'Non-rigid Registration', '3D Brain MR Image', '딥러닝', '비지도 학습', '비강체 정합', '3차원 뇌 자기공명 영상']","비강체 정합은 임상적 필요성은 높으나 계산 복잡도가 높고, 정합의 정확성 및 강건성을 확보하기 어려운 분야이다. 본 논문은 비지도 학습 환경에서 3차원 뇌 자기공명 영상 데이터에 딥러닝 네트워크를 이용한 비강체 정합 기법을 제안한다. 서로 다른 환자의 두 영상을 입력받아 네트워크를 통하여 두 영상 간의 특징 벡터를 생성하고, 변위 벡터장을 만들어 기준 영상에 맞추어 다른 쪽 영상을 변형시킨다. 네트워크는 U-Net 형태를 기반으로 설계하여 정합 시 두 영상의 전역적, 지역적인 차이를 모두 고려한 특징 벡터를 만들 수 있고, 손실함수에 균일화 항을 추가하여 3차원 선형보간법 적용 후에 실제 뇌의 움직임과 유사한 변형 결과를 얻을 수 있다. 본 방법은 비지도 학습을 통해 임의의 두 영상만을 입력으로 받아 단일 패스 변형으로 비강체 정합을 수행한다. 이는 반복적인 최적화 과정을 거치는 비학습 기반의 정합 방법들보다 빠르게 수행할 수 있다. 실험은 50명의 뇌를 촬영한 3차원 자기공명 영상을 가지고 수행하였고, 정합 전·후의 Dice Similarity Coefficient 측정 결과 평균 0.690으로 정합 전과 비교하여 약 16% 정도의 유사도 향상을 확인하였다. 또한, 비학습 기반 방법과 비교하여 유사한 성능을 보여주면서 약 10,000배 정도의 속도 향상을 보여주었다. 제안 기법은 다양한 종류의 의료 영상 데이터의 비강체 정합에 활용이 가능하다.","Although a non-rigid registration has high demands in clinical practice, it has a high computational complexity and it is very difficult for ensuring the accuracy and robustness of registration. This study proposes a method of applying a non-rigid registration to 3D magnetic resonance images of brain in an unsupervised learning environment by using a deep-learning network. A feature vector between two images is produced through the network by receiving both images from two different patients as inputs and it transforms the target image to match the source image by creating a displacement vector field. The network is designed based on a U-Net shape so that feature vectors that consider all global and local differences between two images can be constructed when performing the registration. As a regularization term is added to a loss function, a transformation result similar to that of a real brain movement can be obtained after the application of trilinear interpolation. This method enables a non-rigid registration with a single-pass deformation by only receiving two arbitrary images as inputs through an unsupervised learning. Therefore, it can perform faster than other non-learning-based registration methods that require iterative optimization processes. Our experiment was performed with 3D magnetic resonance images of 50 human brains, and the measurement result of the dice similarity coefficient confirmed an approximately 16% similarity improvement by using our method after the registration. It also showed a similar performance compared with the non-learning-based method, with about 10,000 times speed increase. The proposed method can be used for non-rigid registration of various kinds of medical image data."
CNN과 Bidirectional LSTM을 활용한 부산시 민원 자동 분류 연구,2019,"['automatic text classification', 'civil complaint', 'CNN', 'bidirectional LSTM', 'bi－LSTM', '민원', '자동분류', '딥러닝', '순환신경망', '양방향 LSTM', 'CNN']","온라인과 정보통신기술의 발달로 정부정책에 대한 시민의 참여 욕구는 높아지고 있다. 이에 따라 시민들은 민원을 인터넷과 모바일을 활용하여 전자 민원 게시판을 통해 접수하는 건수가 증가하고 있다. 폭발적으로 늘어나는 민원의 양에 비해 아직 수작업으로 분류 하여 오류가 발생하거나 신속한 대응이 이루어지지 않아 민원인들의 불만이 늘어나고 있다. 본 연구에서는 딥러닝 기법을 통해 담당 부서 분류를 자동화하기 위해 2017년도의 부산시 민원 데이터를 수집하고, 담당 부서를 확인 할 수 있는 부서명, 전화번호, 담당자명을 기준으로 레이블을 부여하였다. 그리고 딥러닝 중 대표적인 분류방법인 CNN과 최근 여러 분야에서 두각을 내고 있는 Bidirectional LSTM을 기반으로 상위 12개 범주에 대하여 지도학습을 실시하였다. 지도학습 결과 각각 73%, 77%의 정확도를 보여 안정적인 성능을 보여주었다. 본 연구의 민원 분류에 대한 지도학습 사례는 향후 다른 주제 및 지방자치단체 민원에 대한 텍스트 데이터의 분류에 이용될 수 있어 실무적인 공헌도와 함께 후속연구를 유발할 수 있다는 학문적 기여도가 있다.",
어린이집 영역배치 자동 대안생성을 위한 Deep Learning의 활용에 관한 연구,2019,"['Deep Learning', 'Artificial Intelligence', 'Architectural Design', 'Design Automata', 'Expert System', '딥러닝', '인공지능', '건축디자인', '설계자동화', '전문가시스템']","본 연구는 최근 개발 및 활용이 활발하게 이루어지고 있는 Deep Learning기술을 건축설계 대안생성과정에 활용하는 것을 목표로 한다. 이는 건축가가 생각하기 어려운 상황을 검토하고 그 결과를 자동으로 제시하여 건축가에게 최적의 대안 결정을 지원하게 하는 것을 말한다. 본 기술은 설계자동화와 같이 전통적인 건축 디자인 컴퓨팅 분야에서 연구되어온 주제와 그 맥을 같이하나 기존에 판단 기준을 미리 정해주는 단순한 방식의 인공지능과 차별화되어 인간과 같이 수많은 데이터 중에서 일정한 패턴을 스스로 탐색하고 추론하여 최적의 결과를 도출하는 것에 차별점이 있다. 본 연구에서는 평면디자인에서 공간 및 사물 배치를 통하여 벌어지는 인간행동을 학습하고 이를 추론하여 최적의 결과를 도출하는 기술개발을 목표로 한다. 즉, 어린이집의 가구 및 공간 배치에 대한 딥러닝 기술을 활용한 자동 대안생성 기술개발에 관한 내용이 주가 된다. 본 연구에서는 보육공간의 영역 및 아동의 활동을 모델링하고 기존의 Deep Learning 기술을 도입하여 자동으로 대안을 생성하고 최적의 대안을 제안하는 시스템 개발의 예를 제시하고 있다.","The purpose of this study is to utilize Deep Learning technology which is actively developed and utilized recently in the process of building alternative design. This means that the architect examines situations that are difficult to think about and automatically presents the results to help architects make the best alternative decisions. This technology is different from the artificial intelligence, which is a simple method that pre-sets judgment criteria in the same way as the theme that has been studied in the field of traditional architectural design computing such as design automation, There is a difference in deriving the optimum result by reasoning. In this study, we aim to develop a technique that learns human behavior through space and object arrangement in plane design and derives optimal result by reasoning it. That is to say, the development of automatic alternative generation technology using deep learning technology for furniture and space arrangement of daycare center. In this study, we present an example of system development that automatically creates alternatives and suggests optimal alternatives by modeling the area of ​​children 's space and activities of children and introducing existing Deep Learning technology."
R-FCN과 Transfer Learning 기법을 이용한 영상기반 건설 안전모 자동 탐지,2019,"['Construction safety', 'Object detection', 'Deep learning', 'Neural network', '건설안전', '물체 탐지', '딥러닝', '인공신경망']","대한민국에서 건설업은 타 업종들과 비교하여 안전사고의 위험성이 가장 높게 나타난다. 따라서 건설업 내 안전성 향상을 도모하기 위해 여러 연구가 예전부터 진행이 되어 왔고, 본 연구에선 건설현장 영상 데이터를 기반으로 물체 탐지 및 분류 알고리즘을 이용해서 효과적인 안전모 자동탐지 시스템을 구축하여 건설현장 노동자들의 안전성 향상에 기여하고자 한다. 본 연구에서 사용된 알고리즘은 Convolutional Neural Network (CNN) 기반의 물체 탐지 및 분류 알고리즘인 Region-based Fully Convolutional Networks (R-FCN)이고 이를 Transfer Learning 기법을 사용하여 딥러닝을 실시하였다. ImageNet에서 수집한 1089장의 사람과 안전모가 포함된 영상으로 학습을 시행하였고 그 결과, 사람과 안전모의 mean Average Precision (mAP)은 각각 0.86, 0.83로 측정되었다.","In Korea, the construction industry has been known to have the highest risk of safety accidents compared to other industries. Therefore, in order to improve safety in the construction industry, several researches have been carried out from the past. This study aims at improving safety of labors in construction site by constructing an effective automatic safety helmet detection system using object detection algorithm based on image data of construction field. Deep learning was conducted using Region-based Fully Convolutional Network (R-FCN) which is one of the object detection algorithms based on Convolutional Neural Network (CNN) with Transfer Learning technique. Learning was conducted with 1089 images including human and safety helmet collected from ImageNet and the mean Average Precision (mAP) of the human and the safety helmet was measured as 0.86 and 0.83, respectively."
실시간 미니드론 카메라 영상을 기반으로 한 얼굴 인식 시스템 개발,2019,"['드론', '실시간 드론 영상', '드론 제어', 'GUI', '얼굴 인식', '딥러닝', 'Drone', 'Real-time Drone image', 'Drone Control', 'GUI', 'Face Recognition', 'Deep Learning']","본 논문에서는 미니 드론을 조종하면서 드론에 부착된 카메라가 촬영하는 영상을 실시간으로 받아들여 특정인의 얼굴을 인식하여 확인시켜주는 시스템 개발 방법론을 제안한다. 본 시스템의 개발을 위해서는 OpenCV, Python 관련 라이브러리 및 드론 SDK 등을 사용한다. 실시간 드론 영상으로부터 특정인의 얼굴 인식 비율을 높이기 위해서는 딥러닝 기반의 얼굴 인식 알고리즘을 사용하며 특히 Triples 원리를 활용한다. 시스템의 성능을 확인하기 위해 저자 얼굴을 기준으로 30회 동안 얼굴 인식 실험을 수행한 결과 약 95% 이상의 인식률을 보여주었다. 본 논문의 연구 결과물은 관광지, 축제 행사장 등에서 특정인을 드론으로 빠르게 찾기 위한 목적으로 사용할 수 있을 것으로 판단된다.","In this paper, I propose a system development methodology that accepts images taken by camera attached to drone in real time while controlling mini drone and recognize and confirm the face of certain person. For the development of this system, OpenCV, Python related libraries and the drone SDK are used. To increase face recognition ratio of certain person from real-time drone images, it uses Deep Learning-based facial recognition algorithm and uses the principle of Triples in particular. To check the performance of the system, the results of 30 experiments for face recognition based on the author's face showed a recognition rate of about 95% or higher. It is believed that research results of this paper can be used to quickly find specific person through drone at tourist sites and festival venues."
적응형 채널 어텐션 모듈을 활용한 복합 열화 복원 네트워크,2019,"['Image restoration', 'Deep learning', 'Channel attention', 'CNN', '영상복원', '딥러닝', '채널 어텐션', '합성곱신경망']",자율 주행 자동차나 소방 로봇과 같은 시스템에서 영상을 얻을 때 다양한 요인들로 인해 잡음，블러와 같은 열화가 발생한 다. 이런 열화된 영상에 직접 영상 분류와 같은 기술을 적용하기 어려워 열화 제거가 불가피하나 이러한 시스템들은 영상의 열화를 인식할 수 없어서 열화된 영상을 복원하는데 어려움이 있다. 본 논문에서는 영상에 적용된 열화를 인지하지 못하는 상황에서 여러 방법들로 열화된 영상으로부터 자연스럽고 선명한 영상을 복원하는 방법을 제안한다. 우리가 제안한 방법은 딥러닝 모델에 채널 어텐션 모듈과스깁 커넥션을사용하여 영상에 적용된 열화에 따라복원에 필요한 채널에 높은 가중치를 적용해 복합 열화 영상의 복원을 진행한다. 이 방법은 다른복합 열화복원 방법 에 비해 학습이 간단하고 기존의 다른 방법들에 비 해 높은 복합 열화 복원 성능을 낸다.,"The image obtained from systems such as autonomous driving cars or fire-fighting robots often suffer from several degradation such as noise, motion blur, and compression artifact due to multiple factor. It is difficult to apply image recognition to these degraded images, then the image restoration is essential. However, these systems cannot recognize what kind of degradation and thus there are difficulty restoring the images. In this paper, we propose the deep neural network, which restore natural images from images degraded in several ways such as noise, blur and JPEG compression in situations where the distortion applied to images is not recognized. We adopt the channel attention modules and skip connections in the proposed method, which makes the network focus on valuable information to image restoration. The proposed method is simpler to train than other methods, and experimental results show that the proposed method outperforms existing state-of-the-art methods."
인공지능 기반의 행동인식을 통한 개인 운동 트레이너 구현의 방향성 제시,2019,"['Healthcare', 'Fitness', 'Artificial Intelligence', 'Deep Running', 'CNN', 'RNN', '헬스케어', '피트니스', '인공지능', '딥러닝', '합성곱 신경망', '순환 신경망']","최근 딥러닝을 비롯한 인공지능 기술의 활용이 다양한 분야에서 활발해지고 있으며, 특히 딥러닝 기술 기반의 객체 인식 및 검출에 뛰어난 성능을 보이는 여러 알고리즘들이 발표되고 있다. 이에 본 논문에서는 사용자의 편의성이 효과적으로 반영된 모바일 헬스케어 애플리케이션 구현에 대한 적절한 방향성을 제시하고자 한다. 기존의 피트니스 애플리케이션들에 대한 이용 만족도 연구 및 모바일 헬스케어 애플리케이션에 대한 현황을 파악하여, 이로부터 피트니스 애플리케이션 시장에서의 생존과 우위를 확보하는 동시에, 최근 주목 받고 있는 인공지능 기술의 효과적인 적용에 의한 성능 개선을 통해 기존 이용자 유지 및 확대를 도모하고자 한다.","Recently, the use of artificial intelligence technology including deep learning has become active in various fields. In particular, several algorithms showing superior performance in object recognition and detection based on deep learning technology have been presented. In this paper, we propose the proper direction for the implementation of mobile healthcare application that user's convenience is effectively reflected. By effectively analyzing the current state of use satisfaction research for the existing fitness applications and the current status of mobile healthcare applications, we attempt to secure survival and superiority in the fitness application market, and, at the same time, to maintain and expand the existing user base."
CNN 기반 전이학습을 이용한 음성 감정 인식,2019,"['Speech Emotion Recognition', 'Transfer Learning', 'Deep Learning', 'Convolutional Neural Networks', '음성 감정 인식', '전이학습', '딥러닝', '합성곱 신경망']","로봇은 사람의 편의를 위해 존재하므로 사람과 로봇의 상호작용은 중요하다. 로봇이 사람의 감정을 파악하는 것은 여러상호작용 중 하나이다. 최근 사람의 음성으로 감정을 인식하는 음성 감정 인식(speech emotion recognition; SER)분야는딥러닝 (deep learning)의 접목으로 그 성능이 향상되고 있다. 하지만, 데이터의 부족으로 깊은 신경망을 사용하거나추가적인 학습 기법을 적용하지 않고서는 높은 정확도를 기대하기 힘들다. 본 논문에서는 데이터가 부족할 때 사용하는 학습기법 중의 하나인 전이학습 (transfer learning)을 SER에 적용한 효과를 확인한다. 딥러닝을 적용하기 위해 합성곱 신경망(convolutional neural networks; CNN) 구조를 사용한다. 전이학습에 음성 감정 데이터가 아닌 일반 소리 데이터를 사용하여데이터 개수에 대한 한계를 없앤다. 전이학습 중 특징 추출기 (feature extractor)로써 사용한 경우와 미세조정 (fine tuning)을한 경우로 나누어 결과를 확인한다. 그 결과, 미세조정한 경우 수렴 시간이 약 20% 줄었고, 특징 추출기로써 사용한 경우 약20%에서 70% 줄었다. 정확도는 특징 추출기로써 사용한 경우 오히려 정확도가 감소하는 경우가 발생하였고 증가한 경우 약3% 증가했다. 미세조정을 한 경우 정확도가 평균적으로 약 7% 향상되었다","Interaction between human and robot is important because robots exist for the convenience of people. Robot grasping human emotions is one of many interactions. The field of SER (speech emotion recognition) has been improved by combining deep learning. The lack of data makes it difficult to expect high accuracy without using deep neural networks or applying additional learning techniques. In this paper, we confirm the effect of applying the transfer learning, which is one of the learning methods used when there is insufficient data, to SER. For deep learning, CNN (convolutional neural networks) architecture is used. By using general sound data instead of speech emotion data for the transfer learning, the limit on the number of data is eliminated. The results are verified by dividing transfer learning into two case, using as a feature extractor and fine-tuning. As a result, convergence time was reduced by about 20% when fine-tuning, and about 20% to 70% when used as a feature extractor. Accuracy of the feature extractor is rather reduced when it is used as a feature extractor and increased by about 3% when it is increased. On the average, the accuracy was improved by about 7% when fine-tuning."
문화예술 콘텐츠 제작 및 유통에서의 빅데이터 활용 연구,2019,"['Bigdata', 'Video Contents', 'Algorithm', 'Culture Arts Industry', 'Netflix', 'FGI', '빅데이터', '알고리즘', '영상콘텐츠', '문화예술산업', 'Netflix', 'FGI']","4차 산업혁명 시대의 폭발적인 정보의 양을 다루는 빅데이터 관련 연구는 현재 활발히 진행되고 있다. 빅데이터는 머신러닝, 즉 딥러닝의 학습데이터가 되는 광범위한 데이터로 인공지능의 발달을 촉진하는 필수 요소이다. 다양한 분야에서 빅데이터의 활용은 유의미한 결과를 가져오고 있으며, 특히 문화예술 분야에서의 활용도 주목해 볼 필요가 있다. 이에 본 논문은 영상콘텐츠를 중심으로 문화예술 산업에서 빅데이터의 활용 사례를 알아보았다. 주목한 점은 문화예술 콘텐츠의 유통뿐만 아니라 제작단계까지 빅데이터가 활용되고 있는 점이다. 특히 미국의 Netflix가 OTT사업으로 어떤 성과와 변화를 가져왔는지를 먼저 알아보고 국내의 OTT 사업체의 현황도 함께 분석하였다. 그 후 Netflix가 축적된 고객의 데이터를 통해 딥러닝 방식의 ‘시네매치’, 즉 흥행 예측 알고리즘을 활용하여 제작/유통한 ‘House of Cards’의 성공 사례를 분석하였다. 그 후 문화예술 콘텐츠 전문가를 대상으로 FGI(Focus Group Interview)를 진행하였다. 이를 통해 국내 문화예술 산업에서 빅테이터의 향후 활용 전망을 기술적인 측면, 창의적인 측면, 윤리적인 측면으로 나눠서 고찰하였다.","Big data-related research that deals with the amount of explosive information in the era of the Fourth Industrial Revolution is actively underway. Big data is an essential element that promotes the development of artificial intelligence with a wide range of data that become learning data for machine learning, or deep learning. The use of deep learning and big data in various fields has produced meaningful results. In this paper, we have investigated the use of Big Data in the cultural arts industry, focusing on video contents. Noteworthy is that big data is used not only in the distribution of cultural and artistic contents but also in the production stage. In particular, we first looked at what kind of achievements and changes the Netflix in the US brought to the OTT business, and analyzed the current state of the OTT business in Korea. After that, Netflix analyzed the success stories of 'House of Cards', which was produced / circulated through 'Deep Learning' cinematique, which is a prediction algorithm, through accumulated customer data. After that, FGI (Focus Group Interview) was held for cultural and artistic contents experts. In this way, the future prospects of Big Data in the domestic culture and arts industry are divided into technical aspect, creative aspect, and ethical aspect."
절단된 분포를 이용한 인공신경망에서의 초기값 설정방법,2019,"['initialization', 'saturation', 'Xavier initialization', 'truncated distribution', 'deep learning', '초기값', '포화', 'Xavier', '절단된 분포', '딥러닝']",딥러닝은 대용량의 데이터의 분류 및 예측하는 방법으로 각광받고 있다. 데이터의 양이 많아지면서 신경망의 구조는 더 깊어 지고 있다. 이때 초기값이 지나치게 클 경우 층이 깊어 질수록 활성화 함수의 기울기가 매우 작아지는 포화(Saturation)현상이 발생한다. 이러한 포화현상은 가중치의 학습능력을 저하시키는 현상을 발생시키기 때문에 초기값의 중요성이 커지고 있다.이런 포화현상 문제를 해결하기 위해 Glorot과 Bengio (2010)과 He 등 (2015) 층과 층 사이에 데이터가 다양하게 흘러야 효율적인 신경망학습이 가능하고 주장했다. 데이터가 다양하게 흐르기 위해서는 각 층의 출력에 대한 분산과 입력에 대한 분산이 동일해야 한다고 제안했다. Glorot과 Bengio (2010)과 He 등 (2015)는 각 층별 활성화 값의 분산이 같다고 가정해 초기값을 설정하였다. 본 논문에서는 절단된 코쉬 분포와 절단된 정규분포를 활용하여 초기값을 설정하는 방안을 제안한다. 출력에 대한 분산과 입력에 대한 분산의 값을 동일하게 맞춰주고 그 값이 절단된 확률분포의 분산과 같게 적용함으로써 큰 초기값이 나오는 걸 제한하고 0에 가까운 값이 나오도록 분포를 조정하였다. 제안된 방법은 MNIST 데이터와 CIFAR-10 데이터를 DNN과 CNN 모델에 각각 적용하여 실험함으로써 기존의 초기값 설정방법보다 모델의 성능을 좋게 한다는 것을 보였다,"Deep learning has gained popularity for the classification and prediction task. Neural network layers become deeper as more data becomes available. Saturation is the phenomenon that the gradient of an activation function gets closer to 0 and can happen when the value of weight is too big. Increased importance has been placed on the issue of saturation which limits the ability of weight to learn. To resolve this problem, Glorot and Bengio (Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, 249-256, 2010) claimed that efficient neural network training is possible when data flows variously between layers. They argued that variance over the output of each layer and variance over input of each layer are equal. They proposed a method of initialization that the variance of the output of each layer and the variance of the input should be the same. In this paper, we propose a new method of establishing initialization by adopting truncated normal distribution and truncated cauchy distribution. We decide where to truncate the distribution while adapting the initialization method by Glorot and Bengio (2010). Variances are made over output and input equal that are then accomplished by setting variances equal to the variance of truncated distribution. It manipulates the distribution so that the initial values of weights would not grow so large and with values that simultaneously get close to zero. To compare the performance of our proposed method with existing methods, we conducted experiments on MNIST and CIFAR-10 data using DNN and CNN. Our proposed method outperformed existing methods in terms of accuracy."
자동화기반의 가짜 뉴스 탐지를 위한 연구 분석,2019,"['Fake news', 'Fake Information', 'Fake News Challenge', 'Maching Learning', 'Deep Learning', '가짜 뉴스', '가짜정보', '가짜 뉴스 챌린지', '머신러닝', '딥러닝']","가짜 정보를 탐지하기 위한 연구는 2016년 미국 대통령 선거 이후 본격적으로 시작되었다. 정확한 출처를 알 수 없는 정보들이 뉴스 형식으로 생산되고, 이는 자극적이고 흥미로운 소재에 많은 관심을 보이는 대중의 특성에 따라 빠른 속도로 확산되고 있다. 또한, 소셜 네트워크 서비스 등 정보를 전달하기 쉬운 플랫폼의 대중화는 이러한 현상을 더욱 악화시킨다. Poynter는 IFCN(International Fact Checking Network)를 만들어 숙련된 전문가들이 사실 여부를 판단할 수 있는 가이드라인을 제시하고, 팩트 체크 기관을 위한 강령을 제공하고 있다. 하지만 이러한 접근 방법은 하나의 기사에 대한 진위 여부를 검증하기 위해 다수의 전문가 인력이 투입되어야 하므로 시간 및 금전적 비용이 크다. 따라서 지속적으로 증가하는 가짜 뉴스에 효율적으로 대응할 수 있는 자동화된 가짜 뉴스 탐지 기술에 대한 연구가 주목받고 있다. 본 논문에서는 최근 딥러닝 기술의 접목으로 인해 빠르게 발전하고 있는 가짜 뉴스 탐지 시스템과 연구들을 정리 및 분석한다. 또한, 많은 연구가 필요한 본 분야에 연구자들이 쉽게 접근할 수 있도록 다양한 형태로 주어지는 학습 말뭉치 및 챌린지들도 정리한다.","Research in detecting fake information gained a lot of interest after the US presidential election in 2016. Information from unknown sources are produced in the shape of news, and its rapid spread is fueled by the interest of public drawn to stimulating and interesting issues. In addition, the wide use of mass communication platforms such as social network services makes this phenomenon worse. Poynter Institute created the International Fact Checking Network (IFCN) to provide guidelines for judging the facts of skilled professionals and releasing “Code of Ethics” for fact check agencies. However, this type of approach is costly because of the large number of experts required to test authenticity of each article. Therefore, research in automated fake news detection technology that can efficiently identify it is gaining more attention. In this paper, we investigate fake news detection systems and researches that are rapidly developing, mainly thanks to recent advances in deep learning technology. In addition, we also organize shared tasks and training corpus that are released in various forms, so that researchers can easily participate in this field, which deserves a lot of research effort."
인공지능과 금융법,2019,"['Artificial Intelligence(AI)', 'Financial Law', 'Financial Regulation', 'robo-advisor', 'consumer protection.', '인공지능(AI)', '법인격', '딥 러닝', '금융법', '금융규제', '로보어드바이저', '소비자보호', '블랙박스화.']","AI가 활용되는 사례 중 하나가 금융 분야에서 등장하고 있는 로보어드바이저(Robo-Adviser)인데, AI 로봇은 사람 못지않은 자산관리 조언자로서의 기능을 하고 있으며, 이처럼 AI를 활용하는 사례는 금융서비스 분야에서 급속히 늘어나고 있다. 그리하여 우리나라의 금융업계도 AI 도입에 본격적으로 경쟁에 돌입하고 있다.금융 분야는 반드시 수리적인 분석과 연결되어 있고, AI를 이용한 기술혁신의 영향을 받기 쉬운 분야이기 때문에 AI가 활용될 수 있는 최적의 분야 중 하나가 금융 분이다. 따라서 우리나라의 은행을 비롯한 금융업계 AI를 활용한 각종 서비스를 제공하고 있고 보다 나은 AI를 개발하기 위해 노력하고 있다. 그런데 AI를 둘러싼 각종 법적 문제 또한 많은 것도 사실이다. 그리하여 이 논문은 우리나라의 금융 분야에서의 AI의 활용상황, AI와 금융규제, AI에 의한 서비스와 고객보호 등에 대해 살펴 본 후, AI와 현행법의 과제, 그리고 미래의 법제도 등에 대하여 살펴보았다.무엇보다도 AI에게 법인격을 인정해야 하는지에 대해서는 책임귀속기능이나 법체계의 안정화 가능에 크게 기여하는 바가 없을 것으로 보이고 AI에게 법인격을 인정할 경우, 현존하는 기술적 능력 범위에서 AI를 통제할 수 없음을 증명한 사업자는 사용자책임에서 벗어날 수 있게 되는 문제점이 존재한다. 이는 결국 사업자로 하여금 통제가 불가능한 AI를 활용하도록 조장하는 결과를 초래할 것이기에 현재로서는 AI에게 법인격을 인정하는 것에 찬동하지 않는다.이 이외에도 AI에 의한 시장안정성의 위협을 어떻게 해결할 것인지의 문제와 AI가 딥 러닝의 방법에 의한 학습을 통해 얻은 지식을 가지고 의사결정을 한 경우 그 의사결정이 어떤 과정에 의해 이루진 것인지가 명확하지 않고 블랙박스(black box)화 되는 문제 때문에 규제당국이 문제의 소재를 찾아내는 데 어려움을 겪게 되고, AI를 이용한 의사결정이 금융시스템 전체에 손해를 야기한 때, 책임소재를 밝히기가 쉽지 않은 문제점이 존재한다. 또한 소비자보호에 있어서 로보어드바이저와 관련하여 이해상충 방지체계를 어떻게 구축할 것인지 등에 대해 심도 있는 연구가 진행되어야 할 것으로 보인다.","I think one of the best areas where AI can be utilized is the financial sector. This is because the financial sector is necessarily linked to mathematical analysis and is easily affected by innovation using AI. Therefore, it is providing various services using AI in the financial industry, including the nation's banks, and making efforts to develop better AI. However, it is also true that there are many legal issues surrounding AI. Thus, this paper looked at the utilization status of AI in our country's financial sector, AI and financial regulations, service and consumer protection by AI, and then looked at the tasks of AI and current law, and the future legal system.Above all, it seems that there is no significant contribution to the possibility of stabilizing the legal system or the function of the responsibility for AI, and there is a problem in which a business that proves that AI cannot be controlled within the existing technological capabilities can be relieved of its user responsibilities. As this will result in encouraging businesses to utilize AI, which may be out of control, I am not in favor of recognizing AI's corporate status at the moment.In addition, there are other issues of how to address the threat of market stability by AI, and when AI makes decisions with knowledge gained from learning by deep running methods, it is not clear what process the decision was made and black boxed, making it difficult for regulators to locate the problem, and not easy to identify when AI decision-making has caused damage to the entire financial system. In addition, in-depth research on how to establish an anti-corrosion system in relation to the robo-advisor should be conducted in-depth."
인공지능과 차별,2019,"['인공지능', '규제', '알고리즘', '차별', '불투명성', '적법절차', 'Artificial intelligence', 'Algorithmic discrimination', 'Opacity', 'Technological due process']","인간이 인공지능을 사용할 때 발생하는 차별은 법적으로 어떻게 취급되어야 하는가? 현재 널리 사용되는 ‘딥러닝(deep learning)’ 인공지능은 범용적 문제해결이 가능한 판단주체가 아니며, 과거의 데이터를 통계적으로 재조직하는 고도화된 분석도구라 할 수 있다. 적어도 현재의 인공지능 기술은 인간의 판단을 전반적으로 대신하는 것이라 보기 어렵다. 인공지능과 관련된 차별 문제에 대한 법적 규율은, 인공지능의 훈련과정에서 어떤 데이터가 이용되는지 그리고 어떻게 알고리즘이 구축되는지 등에 관한 구체적인 사항에 집중할 필요가 있다. 이는 사법적 판단을 통한 사후적 규율과 규제를 통한 사전적 규율에 대해 여러 쟁점을 야기하는데, 이 글에서는 쟁점들을 세 그룹으로 나누어 분석한 뒤 각각에 대해 잠정적 견해를 제시한다.  첫째로, 인간에게는 차별의도가 없었음에도 인공지능 학습에 활용된 데이터에 과거의 차별적 요소가 반영되어 있었던 탓에 인공지능을 활용한 의사결정이 차별을 발생시킨 경우, 배상책임의 귀책사유 인정이 어려울 수 있다.   둘째로, 인공지능의 학습 및 판단방식은 제도적으로 영업비밀인데다 본질적으로 인간이 이해하기 어렵고, 현실적으로 처리방식을 사법절차를 통해 재현하기도 용이하지 않을 수 있다. 이들은 재판을 통한 사후적 차별구제에서 각각 실체법, 절차법적으로 쉽지 않은 문제를 야기한다.  셋째로, 딥러닝 인공지능은 차별이 반영된 과거의 데이터들을 경로의존적으로 재생산하기 때문에 차별구조를 질적으로 악화시킬 수 있다. 그러나 가능한 대안이 무엇인지는 명확하지 않다. 데이터 및 알고리즘에 대한 사전적 통제 및 개인의 이의권 보장 등이 고려될 수 있으나, 이러한 방식은 대체로 현실성이 높지 않고 일반론적인 투명성을 과도하게 강조함으로써 개인정보나 사생활의 권리를 침해할 수도 있다. 인공지능과 차별에 관한 법제도적 규율의 문제는, 어떤 데이터를 얼마나 상세한 수준에서 이용할 수 있는지, 그 과정에 나타날 수 있는 통계적 편향 등의 문제를 어떻게 해결할 것인지에 관한 이론적인 동시에 실무적인 다양한 이슈들을 새로이 제기한다. 인공지능에 대한 차별 맥락에서의 규율은, 차별금지의 일반적 원칙, 행정절차에 대한 투명성 원칙, 개인정보보호 원칙 등 여러 법정책적 목표들이 복잡하게 중첩되어 고려되는 영역이어서 더욱 입체적인 분석이 필요하다.","How should the discrimination that arises when humans use the artificial intelligence be treated legally? The widely used ‘deep learning’ artificial intelligence is not a generalizable problem solver, but it is a sophisticated analytical tool that statistically reorganizes historical data. At present, it is difficult to say that the current artificial intelligence technology is a substitute for human judgment as a whole. The legal discipline for the discrimination related to the artificial intelligence needs to focus on specifics on what data are used in the training of the artificial intelligence and how the algorithms are built. This leads to various legal and regulatory issues.  First, even though human beings have no intention to discriminate, training data used for the artificial intelligence training may reflect past discriminatory factors, so that when decisions are made using artificial intelligence, such decisions may also reflect or even amplify the discrimination. Second, the relevant algorithm may well constitute trade secrets. Third, even if the algorithm is disclosed, it could be inscrutable, and, further, reproduction of the previous algorithmic decisions may not be possible since the algorithms and/or data may be frequently updated or modified. These factors give rise to difficulties in substantive law as well as in procedural law. Fourth, ‘deep learning’ may exacerbate discrimination because it tends to reflect or even exaggerate biases contained in the training data in a path-dependent way."
빅데이터를 이용한 심리학 연구 방법,2019,"['Big Data', 'Artificial Intelligence', 'Machine Learning', 'Topic Modeling', 'Deep Learning', 'Data-driven Analysis', 'Model-driven analysis', '빅데이터', '인공지능', '기계학습', '주제모형', '딥러닝', '자료주도적 분석', '모형주도적 분석']","빅데이터, 기계학습, AI 등의 새로운 기술의 발달은 사람들의 사고와 행동을 변화시키고 이전에는 접근하기 힘들었던 인간에 대한 다양한 활동을 관찰하는 것을 가능하게 한다. 사람들이 인터넷을 광범위하게 사용함에 따라서, 개인의 행동도 인터넷에 저장되고 있다. 자료들은 매우 광범위하며 다양하기 때문에 이를 적절하게 분석하면 인간 심리를 이해하는 범위를 확대할 수 있을 것이다. 이 논문에서는 새롭게 발달된 이러한 기술들을 심리학 연구에 활용하는 방법에 대하여 모색하고자 하였다. 특히 기술의 발달로 가능해진 새로운 자료, 빅데이터의 특성과 심리학에서의 활용방안에 대하여 논의하였다. 이 논문에서는 첫째, 빅데이터의 특성과 빅데이터가 심리학에서 어떠한 역할을 할 수 있는지 살펴보았다. 심리학의 모형주도적 분석법과 다른 빅데이터의 자료주도적 분석법의 문제점들과 이러한 분석을 심리학연구에 어떻게 적용될 수 있는지에 대하여 논의하였다. 둘째, 자료의 분석 방법론에 대하여 살펴보았다. 기존 심리학 연구에서는 정교한 연구설계에 의해 자료가 수집되기 때문에 분석이 상대적으로 덜 중요하지만, 빅데이터 분석에서는 자료분석의 역할이 아주 중요해진다. 방대하고 구조화되지 않은 자료를 처리할 수 있어야 하고, 언어 자료와 같은 숫자 이외의 자료도 분석할 수 있어야 한다. 특히 주제 모형화, 능선 회귀분석과 라소 회귀분석, 지지벡터 기계, 신경망, 딥러닝 등에 대한 원리를 소개하고 심리학 연구에 적용되는 방법들에 대하여 논의하였다. 셋째, 심리학에서 빅데이터 분석 적용의 한계점을 살펴보고, 마지막으로 빅데이터의 심리학 연구의 적용에 대한 방법을 제안하였다.","The development of new technology such as big data, machine learning, and Artificial Intelligence changes human behaviors and thought. Increased use of the internet makes it possible to observe various human activities that were not observable before. Huge amounts of data about various types of human activities are being stored on the internet. Analyzing this information will help extend the scope of understanding human behaviors and psychology. The present paper attempts to find a way of applying new technology to psychological studies. Specifically, we focused on what big data are like and how they can be used for psychological research. This paper first reviewed the characteristics of big data and their role in psychological research. In this context, it discussed the problems of data-driven analysis techniques in which big data analysis is applied and the possibility of applying such methods to psychological research. In this context, it discussed the problems of the data-driven analytic scheme that big data analysis adapting and the possibilities of applying such a method to psychological research. Second, data analytic techniques used in big data analyses are reviewed. These techniques should be able to deal with big and unorganized data and unstructured data such as pictures, video clips, texts, etc. Specifically, it reviewed basic principles of topic modeling, ridge or lasso regression, support vector machine, neural network, and deep learning, and their application to psychological data. Third, the limitations of the use of big data in psychological research are discussed. Finally, it proposed ways of applying big data technology to psychological research."
변형된 DenseNet과 HPF를 이용한 카메라 모델 판별 알고리즘,2019,"['camera model identification', 'deep learning', 'DenseNet', 'high-pass filter']","영상 관련 범죄가 증가하고 고도화됨에 따라서 고수준의 디지털 포렌식 기술이 요구된다. 그러나 기존의 특징 기반 기술은 인간이 고안한 특징을 활용함으로서 새로운 기기 특징에 쉽게 대응하기 어렵고, 딥러닝 기반 기술은 정확도 향상이 요구된다. 본 논문에서는 딥러닝 모델 분야의 최신 기술인 DenseNet을 기반으로 카메라 모델 판별을 위한 딥러닝 모델을 제안한다. 카메라의 센서 특징을 획득하기 위해 HPF 특징 추출 필터를 적용하였고, 카메라 판별에 적합하도록 기존 DenseNet에서 계층 반복 수를 조정하였다. 또한 연산량을 줄이기 위한 Bottleneck layer와 압축 연산 처리를 제거하였다. 제안한 모델을 Dresden 데이터베이스를 사용하여 성능 분석을 하였고, 14개 카메라 모델에 대해 99.65%의 정확도를 달성하였다. 기존 연구들보다 높은 정확도를 달성하였으며 기존에 동일한 제조사에서 정확도가 낮아지는 단점을 극복하였다.","Against advanced image-related crimes, a high level of digital forensic methods is required. However, feature-based methods are difficult to respond to new device features by utilizing human-designed features, and deep learning-based methods should improve accuracy. This paper proposes a deep learning model to identify camera models based on DenseNet, the recent technology in the deep learning model field. To extract camera sensor features, a HPF feature extraction filter was applied. For camera model identification, we modified the number of hierarchical iterations and eliminated the Bottleneck layer and compression processing used to reduce computation. The proposed model was analyzed using the Dresden database and achieved an accuracy of 99.65% for 14 camera models. We achieved higher accuracy than previous studies and overcome their disadvantages with low accuracy for the same manufacturer."
단안 비디오로부터의 5차원 라이트필드 비디오 합성,2019,"['Deep learning', 'Light field', 'Video synthesis', 'View synthesis']","현재 사용 가능한 상용 라이트필드 카메라는 정지 영상만을 취득하거나 가격이 매우 높은 단점으로 인하여 5차원 라이트필드 비디오 취득에 어려움이 있다. 이러한 문제점을 해결하기 위해 본 논문에서는 단안 비디오로부터 라이트필드 비디오를 합성하기 위한 딥러닝 기반 기법을 제안한다. 라이트필드 비디오 학습 데이터를 취득하기 어려운 문제를 해결하기 위하여 UnrealCV를 활용하여 3차원 그래픽 장면의 사실적 렌더링에 의한 합성 라이트필드 데이터를 취득하고 이를 학습에 사용한다. 제안하는 딥러닝 프레임워크는 입력 단안 비디오에서 9×9의 각 SAI(sub-aperture image)를 갖는 라이트필드 비디오를 합성한다. 제안하는 네트워크는 밝기 영상으로 변환된 입력 영상으로부터 appearance flow를 추정하는 네트워크, appearance flow로부터 얻어진 인접한 라이트필드 비디오 프레임간의 optical flow를 추정하는 네트워크로 구성되어 있다.",
지능형 행동인식 기술을 이용한 실시간 동영상 감시 시스템 개발,2019,"['Video Surveillance System', 'Behavior Recognition', 'Openpose', 'Deep Learning']","최근에 빠르게 확산되고 있는 CCTV와 같은 영상기기들은 거의 모든 공공기관, 기업, 가정 등에서 비정상적인 상황을 감시하고 대처하기 위한 수단으로 활용되고 있다. 그러나 대부분의 경우 이상상황에 대한 인식은 모니터링하고 있는 사람에 의해 수동적으로 이루어지고 있어 즉각적인 대처가 미흡하며 사후 분석용으로만 활용되고 있다. 본 논문에서는 최신 딥러닝 기술과 실시간 전송기술을 활용하여 이벤트 발생시 스마트폰으로 이상 상황을 동영상과 함께 실시간으로 전송하는 동영상 감시 시스템의 개발 결과를 제시한다. 개발된 시스템은 오픈포즈 라이브러리를 이용하여 실시간으로 동영상으로 부터인간 객체를 스켈레톤으로 모델링한 후, 딥러닝 기술을 이용하여 인간의 행동을 자동으로 인식하도록 구현하였다. 이를 위해Caffe 프레임워크를 개발된 오픈포즈 라이브러리를 다크넷 기반으로 재구축하여 실시간 처리 능력을 대폭 향상 시켰으며, 실험을 통해 성능을 검증하였다. 본 논문에서 소개할 시스템은 정확하고 빠른 행동인식 성능과 확장성을 갖추고 있어 다양한용도의 동영상 감시 시스템에 활용될 수 있을 것으로 기대된다.","Recently, video equipments such as CCTV, which is spreading rapidly, is being used as a means to monitor and cope with abnormal situations in almost governments, companies, and households. However, in most cases, since recognizing the abnormal situation is carried out by the monitoring person, the immediate response is difficult and is used only for post-analysis. In this paper, we present the results of the development of video surveillance system that automatically recognizing the abnormal situations and sending such events to the smartphone immediately using the latest deep learning technology. The proposed system extracts skeletons from the human objects in real time using Openpose library and then recognizes the human behaviors automatically using deep learning technology. To this end, we reconstruct Openpose library, which developed in the Caffe framework, on Darknet framework to improve real-time processing. We also verified the performance improvement through experiments. The system to be introduced in this paper has accurate and fast behavioral recognition performance and scalability, so it is expected that it can be used for video surveillance systems for various applications."
Depth Estimation 기술의 원리 및 동향,2019,"['Depth', 'Deep Learning', 'Stereo', 'Monocular', '360 Images']","딥러닝의 발전에 따라 거리측정 기술 또한 비약적인 발전이 있었다. 본 논문에서는 양안 영상뿐만 아니라 단안영상에서의 거리측정 기술 동향에 알아본다. 또한, 단안 영상에서의 비지도학습 방법으로부터 카메라의 포즈를 측정을 통해 거리 측정 성능을 개선시키는 방법, 객체 모션 모델링을 통해 거리측정 성능을 개선시키는 방법에 대해 알아본다. 거리측정 기술은 다른 영상 기법의 기반이 되는 기술이며 GPU가 장착될 수 있는 자율주행, 로봇뿐만 아니라 스마트폰에서의 AR/VR, 드론 등에 접목하기 위해 경량화된 딥러닝에 기반한 거리측정 기술을 다룬다. 한 편, 2D 영상뿐만 아니라 360 영상과 같이 3차원의 영상에서의 거리 측정 기술도 함께 알아보고자 한다.","With the advent of deep learning, the depth estimation based on images has made dramatic process for recent a few years. In this paper, we take a close look at not only stereo approach methods but also monocular approaches. In particular, unsupervised monocular methods consider the pose of the camera and by estimating the camera position and adopt to the current depth estimation. Besides, light-weight depth estimation network shows promising results that the network inference is able to execute on CPU. Moreover, we introduce the depth estimation method using 360 image inputs."
임의의 잡음 신호 추가를 활용한 적대적으로 생성된 이미지 데이터셋 탐지 방안에 대한 연구,2019,"['Adversarial examples', 'Adversarial attack detection', 'Convolutional neural network', 'Deep learning', 'Random noise addition']","여러 분야에서 사용되는 이미지 분류를 위한 딥러닝(Deep Learning) 모델은 오류 역전파 방법을 통해 미분을 구현하고 미분 값을 통해 예측 상의 오류를 학습한다. 엄청난 계산량을 향상된 계산 능력으로 해결하여, 복잡하게 설계된 모델에서도 파라미터의 전역 (혹은 국소) 최적점을 찾을 수 있다는 것이 장점이다. 하지만 정교하게 계산된 데이터를 만들어내면 이 딥러닝 모델을 ‘속여’ 모델의 예측 정확도와 같은 성능을 저하시킬 수 있다. 이렇게 생성된 적대적 사례는 딥러닝을 저해할 수 있을 뿐 아니라, 사람의 눈으로는 쉽게 발견할 수 없도록 정교하게 계산되어 있다. 본 연구에서는  임의의 잡음 신호를 추가하는 방법을 통해 적대적으로 생성된 이미지 데이터셋을 탐지하는 방안을 제안한다. 임의의 잡음 신호를 추가하였을 때 일반적인 데이터셋은 예측 정확도가 거의 변하지 않는 반면, 적대적 데이터셋의 예측 정확도는 크게 변한다는 특성을 이용한다. 실험은 공격 기법(FGSM, Saliency Map)과 잡음 신호의 세기 수준(픽셀 최댓값 255 기준 0-19) 두 가지 변수를 독립 변수로 설정하고 임의의 잡음 신호를 추가하였을 때의 예측 정확도 차이를 종속 변수로 설정하여 시뮬레이션을 진행하였다. 각 변수별로 일반적 데이터셋과 적대적 데이터셋을 구분하는 탐지 역치를 도출하였으며, 이 탐지 역치를 통해 적대적 데이터셋을 탐지할 수 있었다.","In Deep Learning models derivative is implemented by error back-propagation which enables the model to learn the error and update parameters. It can find the global (or local) optimal points of parameters even in the complex models taking advantage of a huge improvement in computing power. However, deliberately generated data points can ‘fool’ models and degrade the performance such as prediction accuracy. Not only these adversarial examples reduce the performance but also these examples are not easily detectable with human’s eyes. In this work, we propose the method to detect adversarial datasets with random noise addition. We exploit the fact that when random noise is added, prediction accuracy of non-adversarial dataset remains almost unchanged, but that of adversarial dataset changes. We set attack methods (FGSM, Saliency Map) and noise level (0-19 with max pixel value 255) as independent variables and difference of prediction accuracy when noise was added as dependent variable in a simulation experiment. We have succeeded in extracting the threshold that separates non-adversarial and adversarial dataset. We detected the adversarial dataset using this threshold."
네트워크 데이터 정형화 기법을 통한 데이터 특성 기반 기계학습 모델 성능평가,2019,"['IDS', 'Deep learning', 'Data normalize']",최근 4차 산업 혁명 기술 중 하나인 딥러닝(Deep Learning) 기술은 보안 분야에서는 탐지하기 어려운 네트워크데이터의 숨겨진 의미를 식별하고 공격을 예측하는 데 사용되고 있다. 침입탐지에 사용될 딥러닝 알고리즘을 선택하기 전에 데이터의 속성과 품질 분석이 필요하다. 학습에 사용되는 데이터의 오염여부에 따라 탐지 방법에 영향을 주기 때문이다. 따라서 데이터의 특징을 파악하고 특성을 선정해야 한다. 본 논문에서는 네트워크 데이터 셋을 이용하여악성코드의 단계적 특징을 분석하고 특성을 추출하여 딥러닝 모델을 적용하였을 때 각 특성이 성능에 미치는 영향을분석하였다. 네트워크 특징에 따른 특성들의 비교에 대한 트래픽 분류 실험을 진행하였으며 선정한 특성을 기반으로96.52% 정확도를 분류하였다.,"Recently Deep Learning technology, one of the fourth industrial revolution technologies, is used to identify the hiddenmeaning of network data that is difficult to detect in the security arena and to predict attacks. Property and quality analysisof data sources are required before selecting the deep learning algorithm to be used for intrusion detection. This is becauseit affects the detection method depending on the contamination of the data used for learning. Therefore, the characteristics ofthe data should be identified and the characteristics selected. In this paper, the characteristics of malware were analyzedusing network data set and the effect of each feature on performance was analyzed when the deep learning model wasapplied. The traffic classification experiment was conducted on the comparison of characteristics according to networkcharacteristics and 96.52% accuracy was classified based on the selected characteristics."
스마트 모터 진단 시스템의 구현,2019,"['deep learning', 'DCGAN', 'DNN', 'inverter', 'cloud DB', 'mobile app', 'motor diagnosis']","모터의 회전자 손상을 진단하기 위해, 모터를 정지 상태로 유지하고 회전자를 일정한 위치로 이동한 후에 인버터를 통해 측정된 저항 및 인덕터 값을 분석하는 방법이 많이 사용되고 있지만, 이것은 회전자를 일정한 위치에 이동해야 하는 반복적인 작업을 필요로 한다. 이에 본 연구에서는 반복적인 작업을 최소화할 수 있도록 인버터, 딥-러닝 엔진, 모바일 앱 프로그램을 포함하는 스마트 모터 진단 시스템을 구현하여, 인버터를 통해 측정한 소수의 데이터를 입력으로 사용하는 딥-러닝 알고리즘을 실행하여 빅 데이터를 생성하고, 이 데이터를 기반으로 학습을 진행한 후에 모터를 진단할 수 있도록 하였다. 실험을 통해 이 진단 시스템은 진단 장치의 진단 정확도를 검증할 수 있을 뿐만 아니라, 새로운 방식의 딥-러닝 스마트 진단 시스템으로 사용 가능함을 확인 할 수 있었다.","In order to diagnose a rotor damage of the motor, the motor is stopped first and the rotor is moved to a predetermined position, thereafter a method of analyzing the resistance and the inductance measured through the inverter is widely used. However it’s method requires repetitive tasks to move the rotor to a predetermined position. In this study, a smart motor diagnosis system using inverter, deep-learning engine and mobile app program were implemented to minimize repetitive tasks. Using the deep-learning algorithm, the big data were generated by applying a small number of data measured through the inverter and then the motor could be diagnosed. Through experiments, it was confirmed that this diagnosis system not only can verify the diagnostic accuracy of the motor but also can be used as a new type of deep-learning smart diagnosis system."
순환신경망 모형을 활용한 시계열 비교예측,2019,"['ARIMA model', 'neural network', 'RNN', 'LSTM.', 'ARIMA 모형', '신경망모형', '순환신경망', 'LSTM.']","최근 알파고 이후 딥러닝 연구에 대한 활발한 연구가 진행되고 있다. 딥러닝에는 이미지 분석에 적합한 CNN(convolution neural network), 순차적 자료에 적합한 RNN(recurrent neural network) 모델 등 많은 모델이 존재하는데 그 중 시계열데이터 분석에 적합한 딥러닝 모델을 전형적 시계열데이터인 항공사 데이터(1949년 1월부터 1960년 12월까지 매월 총 국제 항공사 승객 수)에 Box-Jenkins의 ARIMA 모형과 함께 적합시켜 비교 할 것이다. 본 연구에서는 R 프로그램을 이용하여 LSTM(long short-term memory) 순환신경망 모델을 구축하고, ARIMA 모형, Faraway(1998)가 제시한 단순 신경망(neural network) 모형 그리고 Jordan & Elman의 순환신경망 모형과의 적합도를 비교하였다. 모형 비교결과 Elman 모형의 오차제곱합이 0.0128, Jordan 모형의 오차제곱 합이 0.0138, LSTM 모형의 오차제곱합이 0.0165, 신경망 모형은 오차제곱합 0.0212로 ARIMA 모형의 0.0194 에 비해 조금 뒤떨어지는 것으로 나타났다. 결국 Elman 순환신경망 모형이 가장 우수하게 나타났으며 LSTM 모형도 기존 ARIMA 모형과 Faraway의 단순신경망모형 보다 우수한 적합도를 나타났다.","Typical algorithms for deep learning include DNN (deep neural network), CNN (convolution neural network), and RNN (recurrent neural network) algorithms. Among them, RNN is excellent at dealing with sequential data. Sequential data such as time series data can be handled without losing gradient by LSTM (long short-term memory) RNN. In this study, the LSTM, a modified algorithm of RNN, is applied to international airline passenger data (from January 1, 1994 to December 1960). We find the optimal model and compare it with the ARIMA model, the initial network model presented by Faraway (1998), and the model of Jordan & Elman, the simple RNN model. To compare the models, we train the data as learning data sets from January 1949 to December 1950, and designate the remaining one year of data as test sets. and compare the performance of the model with the sum of square errors of the test sets. The model comparison shows that the Elman RNN model was the best, and that the LSTM model was not inferior to the ARIMA model."
작물 분류에서 시공간 특징을 고려하기 위한 2D CNN과 양방향 LSTM의 결합,2019,"['Crop classification', 'Convolutional neural network', 'Long short-term memory', 'Spatiotemporal features']","이 논문에서는 작물 분류를 목적으로 작물의 시공간 특징을 고려할 수 있는 딥러닝 모델 2D convolution with bidirectional long short-term memory(2DCBLSTM)을 제안하였다. 제안 모델은 우선 작물의 공간 특징을 추출하기 위해 2차원의 합성곱 연산자를 적용하고, 추출된 공간 특징을 시간 특징을 고려할 수 있는 양방향 LSTM 모델의 입력 자료로 이용한다. 제안 모델의 분류 성능을 평가하기 위해 안반덕에서 수집된 다중시기 무인기 영상을 이용한 밭작물 구분 사례 연구를 수행하였다. 비교를 목적으로 기존 딥러닝 모델인 2차원의 공간 특징을이용하는 2D convolutional neural network(CNN), 시간 특징을 이용하는 LSTM과 3차원의 시공간 특징을 이용하는 3D CNN을 적용하였다. 하이퍼 파라미터의 영향 분석을 통해, 시공간 특징을 이용함으로써 작물의 오분류 양상을 현저히 줄일 수 있었으며, 제안 모델이 공간 특징이나 시간 특징만을 고려하는 기존 딥러닝 모델에비해 가장 우수한 분류 정확도를 나타냈다. 따라서 이 연구에서 제안된 모델은 작물의 시공간 특징을 고려할수 있기 때문에 작물 분류에 효과적으로 적용될 수 있을 것으로 기대된다.","In this paper, a hybrid deep learning model, called 2D convolution with bidirectional long short-term memory (2DCBLSTM), is presented that can effectively combine both spatial and temporal features for crop classification. In the proposed model, 2D convolution operators are first applied to extract spatial features of crops and the extracted spatial features are then used as inputs for a bidirectional LSTM model that can effectively process temporal features. To evaluate the classification performance of the proposed model, a case study of crop classification was carried out using multi-temporal unmanned aerial vehicle images acquired in Anbandegi, Korea. For comparison purposes, we applied conventional deep learning models including two-dimensional convolutional neural network (CNN) using spatial features, LSTM using temporal features, and three-dimensional CNN using spatio-temporal features. Through the impact analysis of hyper-parameters on the classification performance, the use of both spatial and temporal features greatly reduced misclassification patterns of crops and the proposed hybrid model showed the best classification accuracy, compared to the conventional deep learning models that considered either spatial features or temporal features. Therefore, it is expected that the proposed model can be effectively applied to crop classification owing to its ability to consider spatio-temporal features of crops."
CNN 기반 초분광 영상 분류를 위한 PCA 차원축소의 영향 분석,2019,"['Principal Component Analysis', 'Convolutional Neural Network', 'Dimensionality Reduction', 'Hyperspectral Image Classification']","대표적인 딥러닝(deep learning) 기법 중 하나인 Convolutional Neural Network(CNN)은 고수준의 공간- 분광 특징을 추출할 수 있어 초분광 영상 분류(Hyperspectral Image Classification)에 적용하는 연구가 활발히 진행되고 있다. 그러나 초분광 영상은 높은 분광 차원이 학습 과정의 시간과 복잡도를 증가시킨다는 문제가 있어 이를 해결하기 위해 기존 딥러닝 기반 초분광 영상 분류 연구들에서는 차원축소의 목적으로 Principal Component Analysis (PCA)를 적용한 바 있다. PCA는 데이터를 독립적인 주성분의 축으로 변환시킬 수 있어 분광 차원을 효율적으로 압축할 수 있으나, 분광 정보의 손실을 초래할 수 있다. PCA의 사용 유무가 CNN 학습의정확도와 시간에 영향을 미치는 것은 분명하지만 이를 분석한 연구가 부족하다. 본 연구의 목적은 PCA를 통한분광 차원축소가 CNN에 미치는 영향을 정량적으로 분석하여 효율적인 초분광 영상 분류를 위한 적절한 PCA 의 적용 방법을 제안하는 데에 있다. 이를 위해 PCA를 적용하여 초분광 영상을 축소시켰으며, 축소된 차원의크기를 바꿔가며 CNN 모델에 적용하였다. 또한, 모델 내의 컨볼루션(convolution) 연산 방식에 따른 PCA의 민감도를 분석하기 위해 2D-CNN과 3D-CNN을 적용하여 비교 분석하였다. 실험결과는 분류정확도, 학습시간, 분산 비율, 학습 과정을 통해 분석되었다. 축소된 차원의 크기가 분산 비율이 99.7~8%인 주성분 개수일 때 가장 효율적이었으며, 3차원 커널 경우 2D-CNN과는 다르게 원 영상의 분류정확도가 PCA-CNN보다 더 높았으며, 이를 통해 PCA의 차원축소 효과가 3차원 커널에서 상대적으로 적은 것을 알 수 있었다.","CNN (Convolutional Neural Network) is one representative deep learning algorithm, which can extract high-level spatial and spectral features, and has been applied for hyperspectral image classification. However, one significant drawback behind the application of CNNs in hyperspectral images is the high dimensionality of the data, which increases the training time and processing complexity. To address this problem, several CNN based hyperspectral image classification studies have exploited PCA (Principal Component Analysis) for dimensionality reduction. One limitation to this is that the spectral information of the original image can be lost through PCA. Although it is clear that the use of PCA affects the accuracy and the CNN training time, the impact of PCA for CNN based hyperspectral image classification has been understudied. The purpose of this study is to analyze the quantitative effect of PCA in CNN for hyperspectral image classification. The hyperspectral images were first transformed through PCA and applied into the CNN model by varying the size of the reduced dimensionality. In addition, 2D-CNN and 3D-CNN frameworks were applied to analyze the sensitivity of the PCA with respect to the convolution kernel in the model. Experimental results were evaluated based on classification accuracy, learning time, variance ratio, and training process. The size of the reduced dimensionality was the most efficient when the explained variance ratio recorded 99.7%~99.8%. Since the 3D kernel had higher classification accuracy in the original-CNN than the PCA-CNN in comparison to the 2D-CNN, the results revealed that the dimensionality reduction was relatively less effective in 3D kernel."
실제 컨버터 출력 데이터를 이용한 특정 지역 태양광 장단기 발전 예측,2019,"['Photovoltaic', 'linear regression', 'Support vector machine', 'Deep neural network', 'Recurrent neural network']","태양광 발전은 일사량만 있으면 전기에너지를 얻을 수 있기 때문에, 새로운 에너지 공급원으로 용도가 급증하고 있다. 본 논문은 실제 태양광 발전 시스템의 컨버터 출력을 이용하여 장단기 출력 예측을 하였다. 예측 알고리즘은 다중선형회귀와 머신러닝의 지도학습 중 분류모델인 서포트 벡터 머신 그리고 DNN과 LSTM 등 딥러닝을 이용하였다. 또한 기상요소의 입출력 구조에 따라 3개의 모델을 이용하였다. 장기 예측은 월별, 계절별, 연도별 예측을 하였으며, 단기 예측은 7일간의 예측을 하였다. 결과로서 RMSE 측도에 의한 예측 오차로 비교해 본 결과 다중선형회귀와 SVM 보다는 딥러닝 네트워크가 예측 정확도 측면에서 더 우수하였다. 또한, DNN 보다 시계열 예측에 우수한 모델인 LSTM이 예측 정확도 측면에서 우수하였다. 입출력 구조에 따른 실험 결과는 모델 1보다 모델 2가 오차가 적었으며, 모델 2보다는 모델 3이 오차가 적었다.","Solar photovoltaic can provide electrical energy with only radiation, and its use is expanding rapidly as a new energy source. This study predicts the short and long-term PV power generation using actual converter output data of photovoltaic system. The prediction algorithm uses multiple linear regression, support vector machine (SVM), and deep learning such as deep neural network (DNN) and long short-term memory (LSTM). In addition, three models are used according to the input and output structure of the weather element. Long-term forecasts are made monthly, seasonally and annually, and short-term forecasts are made for 7 days. As a result, the deep learning network is better in prediction accuracy than multiple linear regression and SVM. In addition, LSTM, which is a better model for time series prediction than DNN, is somewhat superior in terms of prediction accuracy. The experiment results according to the input and output structure appear Model 2 has less error than Model 1, and Model 3 has less error than Model 2."
다중작업학습 기법을 적용한 Bi-LSTM 개체명 인식 시스템 성능 비교 분석,2019,"['딥러닝', '다중작업학습', '품사 태깅', '개체명 인식', '전통문화', 'Deep Learning', 'Multi-task Learning', 'Part of speech tagging', 'Named entity Recognition', 'Traditional culture']","다중작업학습(Multi-Task Learning, MTL) 기법은 하나의 신경망을 통해 다양한 작업을 동시에 수행하고 각 작업 간에 상호적으로 영향을 미치면서 학습하는 방식을 말한다. 본 연구에서는 전통문화 말뭉치를 직접 구축 및 학습데이터로 활용하여 다중작업학습 기법을 적용한 개체명 인식 모델에 대해 성능 비교 분석을 진행한다. 학습 과정에서 각각의 품사 태깅(Part-of-Speech tagging, POS-tagging) 과 개체명 인식(Named Entity Recognition, NER) 학습 파라미터에 대해 Bi-LSTM 계층을 통과시킨 후 각각의 Bi-LSTM을 계층을 통해 최종적으로 두 loss의 joint loss를 구한다. 결과적으로, Bi-LSTM 모델을 활용하여 단일 Bi-LSTM 모델보다 MTL 기법을 적용한 모델에서 1.1%~4.6%의 성능 향상이 있음을 보인다.","Multi-Task Learning(MTL) is a training method that trains a single neural network with multiple tasks influences each other. In this paper, we compare performance of MTL Named entity recognition(NER) model trained with Korean traditional culture corpus and other NER model. In training process, each Bi-LSTM layer of Part of speech tagging(POS-tagging) and NER are propagated from a Bi-LSTM layer to obtain the joint loss. As a result, the MTL based Bi-LSTM model shows 1.1%~4.6% performance improvement compared to single Bi-LSTM models."
형태소 분석기를 이용한 키워드 검색 기반 한국어 텍스트 명령 시스템,2019,"['Morphological Analyzer', 'Retrieval Based Model', 'Korean', 'Speech Recognition', 'Command', '형태소 분석기', '키워드 기반 모델', '한국어', '음성 인식', '명령']","딥러닝을 기반으로 한 음성 인식 기술이 상용 제품에 적용되기 시작했지만, 음성 인식으로 분석된 텍스트를 효율적으로 처리할 방법이 없기 때문에 VR 컨텐츠에서 그 적용 예를 찾아 보기는 쉽지 않다. 본 논문은 문장의 형태소를 분석하는 형태소 분석기와 챗봇 개발에 주로 이용되는 검색 기반 모델(Retrieval-Based Model)을 활용하여 명령어를 효율적으로 인식하고 대응할 수 있는 한국어 텍스트 명령 시스템을 제안하는 것을 목적으로 한다. 실험 결과 제안한 시스템은 문자열 비교 방식과 같은 동작을 하기 위해 16%의 명령어만 필요했으며, Google Cloud Speech와 연동하였을 때 60.1%의 성공률을 보였다. 실험 결과를 통해 제안한 시스템이 문자열 비교 방식보다 효율적이라는 것을 알 수 있다.","Based on deep learning technology, speech recognition method has began to be applied to commercial products, but it is still difficult to be used in the area of VR contents, since there is no easy and efficient way to process the recognized text after the speech recognition module. In this paper, we propose a Korean Language Command System, which can efficiently recognize and respond to Korean speech commands. The system consists of two components. One is a morphological analyzer to analyze sentence morphemes and the other is a retrieval based model which is usually used to develop a chatbot system. Experimental results shows that the proposed system requires only 16% commands to achieve the same level of performance when compared with the conventional string comparison method. Furthermore, when working with Google Cloud Speech module, it revealed 60.1% of success rate. Experimental results show that the proposed system is more efficient than the conventional string comparison method."
드론영상을 이용한 물체탐지알고리즘 기반 도로균열탐지,2019,"['딥러닝', '도로균열', '드론', 'Tiny-YOLO-V2', 'Faster-RCNN', 'Deep Learning', 'Road Crack', 'Drone', 'Tiny-YOLO-V2', 'Faster-RCNN']","본 연구에서는 대전광역시 주요 간선도로인 유성대로를 대상으로 드론을 통해 취득한 노면영상데이터를 기반으로 물체탐지알고리즘(Object Detection algorithm) 가운데 Tiny-YOLO-V2와Faster-RCNN을 활용하여 아스팔트 도로노면의 균열을 인식, 균열유형을 구분하고 실험 결과차이를 비교하였다. 분석결과, Faster-RCNN의 mAP는 71%이고 Tiny-YOLO-V2의 mAP는 33%로 측정되었으며, 이는 1stage Detection인 YOLO계열 알고리즘보다 2Stage Detection인 Faster-RCNN 계열의 알고리즘이 도로노면의 균열을 확인하고 분리하는데 더 좋은 성능을 보인다는 것을 확인하였다. 향후, 드론과 인공지능형 균열검지시스템을 이용한 도로자산관리체계(Infrastructure Asset Management) 구축방안 마련을 통해 효율적이고 경제적인 도로 유지관리 의사결정 지원시스템 구축 및 운영 환경을 조성할 수 있을 것이라 판단된다.","This paper proposes a new methodology to recognize cracks on asphalt road surfaces using the image data obtained with drones. The target section was Yuseong-daero, the main highway of Daejeon. Furthermore, two object detection algorithms, such as Tiny-YOLO-V2 and Faster-RCNN, were used to recognize cracks on road surfaces, classify the crack types, and compare the experimental results. As a result, mean average precision of Faster-RCNN and Tiny-YOLO-V2 was 71% and 33%, respectively.The Faster-RCNN algorithm, 2Stage Detection, showed better performance in identifying and separating road surface cracks than the Yolo algorithm, 1Stage Detection. In the future, it will be possible to prepare a plan for building an infrastructure asset-management system using drones and AI crack detection systems. An efficient and economical road-maintenance decision-support system will be established and an operating environment will be produced."
Sports Broadcasting with Deep Learning,2019,"['딥러닝', '물체 검출', '사람 검출', '행동 인식', '온톨로지', '스포츠 캐스팅', 'deep-learning', 'object detection', 'human detection', 'motion recognition', 'ontology', 'sports commentary']",,
합성곱 신경망을 이용한 아스팔트 콘크리트 도로포장 표면균열 검출,2019,"['딥러닝', '합성곱 신경망', '아스팔트 도로포장', '아스팔트 도로포장 표면균열', 'Deep learning', 'Convolutional Neural Network', 'Asphalt Pavement', 'Surface Crack']","본 연구에서는 아스팔트 콘크리트 도로포장의 표면균열 검출을 위해 합성곱 신경망을 이용하였다. 합성곱 신경망의 학습에 사용되는 표면균열 이미지 데이터의 양에 따른 합성곱 신경망의 성능향상 정도를 평가하였다. 사용된 합성곱 신경망의 구조는 5개의 층으로 구성되어있으며, 3x3 크기의 convolution filter와 2x2 크기의 pooling kernel을 사용하였다. 합성곱 신경망의 학습을 위해서 도로노면 조사 장비를 통해 구축된 국내 도로포장 표면균열 이미지를 활용하였다. 표면균열 이미지 데이터를 학습한 합성곱 신경망 모델의 표면균열 검출 정확도, 정밀도, 재현율, 미검출율, 과검출율을 평가하였다. 가장 많은 양의 데이터를 학습한 합성곱 신경망 모델의 표면균열 검출 정확도, 정밀도, 재현율은 96.6% 이상, 미검출율, 과검출율은 3.4% 이하의 성능을 나타내었다.","A Convolution Neural Network(CNN) model was utilized to detect surface cracks in asphalt concrete pavements. The CNN used for this study consists of five layers with 3x3 convolution filter and 2x2 pooling kernel. Pavement surface crack images collected by automated road surveying equipment was used for the training and testing of the CNN. The performance of the CNN was evaluated using the accuracy, precision, recall, missing rate, and over rate of the surface crack detection. The CNN trained with the largest amount of data shows more than 96.6% of the accuracy, precision, and recall as well as less than 3.4% of the missing rate and the over rate."
얼굴 특징점 검출을 위한 적분 회귀 네트워크,2019,"['Face Alignment', 'Facial Landmark Detection', 'Deep Learning']","최근 딥러닝 기술의 발전과 함께 얼굴 특징점 검출 방법의 성능은 크게 향상되었다. 대표적인 얼굴 특징점 검출 방법인 히트맵 회귀 방법은 효율적이고 강력한 방법으로 널리 사용되고 있으나, 단일 네트워크를 통해 특징점 좌표를 즉시 얻을 수 없으며, 히트맵으로부터 특징점 좌표를 결정하는 과정에서 정확도가 손실된다는 단점이 존재한다. 이러한 문제점들을 해결하기 위해 본 논문에서는 기존의 히트맵 회귀 방법에 적분 회귀 방법을 결합할 것을 제안한다. 여러 가지 데이터셋을 사용한 실험을 통해 제안하는 적분 회귀 네트워크가 얼굴 특징점 검출 성능을 크게 향상시킨다는 것을 보인다.",
환경요인을 이용한 다층 퍼셉트론 기반 온실 내 기온 및 상대습도 예측,2019,"['기계학습', '딥러닝', '비모델 예측', '인공신경망', 'artificial neural network', 'deep learning', 'machine learning', 'mango', 'model-free prediction']","온도와 상대습도는 작물 재배에 있어서 중요한 요소로써, 수량과 품질의 증대를 위해서는 적절히 제어 되어야한다. 그리고 정확한 환경 제어를 위해서는 환경이 어떻게 변화할지 예측할 필요가 있다. 본 연구의 목적은 현시점의 환경 데이터를 이용한 다층 퍼셉트론(multilayer perceptrons, MLP)을 기반으로 미래 시점의 기온 및 상대습도를 예측하는 것이다. MLP 학습에 필요한 데이터는 어윈 망고(Mangifera indica cv. Irwin)을 재배하는 8 연동 온실(1,032m2)에서 2016년 10월 1일부터 2018년 2 월 28일까지 10분 간격으로 수집되었다. MLP는 온실내부 환경 데이터, 온실 외 기상 데이터, 온실 내 장치의 설정 및 작동 값을 사용하여 10~120분 후 기온 및상대습도를 예측하기 위한 학습을 진행하였다. 사계절이뚜렷한 우리나라의 계절에 따른 예측 정확도를 분석하기위해서 테스트 데이터로 계절별로 3일간의 데이터를 사용했다. MLP는 기온의 경우 은닉층이 4개, 노드 수가128개일 때(R2 = 0.988), 상대습도는 은닉층 4개, 노드수 64개에서 가장 높은 정확도를 보였다(R2 = 0.990).MLP 특성상 예측 시점이 멀어질수록 정확도는 감소하였지만, 계절에 따른 환경 변화에 무관하게 기온과 상대습도를 적절히 예측하였다. 그러나 온실 내 환경 제어 요소 중 분무 관수처럼 특이적인 데이터의 경우, 학습 데이터 수가 적기 때문에 예측 정확도가 낮았다. 본 연구에서는 MLP의 최적화를 통해서 기온 및 상대습도를 적절히예측하였지만 실험에 사용된 온실에만 국한되었다. 따라서 보다 일반화를 위해서 다양한 장소의 온실 데이터 이용과 이에 따른 신경망 구조의 변형이 필요하다.","Temperature and relative humidity are important factors in crop cultivation and should be properly controlled for improving crop yield and quality. In order to control the environment accurately, we need to predict how the environment will change in the future. The objective of this study was to predict air temperature and relative humidity at a future time by using a multilayer perceptron (MLP). The data required to train MLP was collected every 10 min from Oct. 1, 2016 to Feb. 28, 2018 in an eight-span greenhouse (1,032 m2) cultivating mango (Mangifera indica cv. Irwin). The inputs for the MLP were greenhouse inside and outside environment data, and set-up and operating values of environment control devices. By using these data, the MLP was trained to predict the air temperature and relative humidity at a future time of 10 to 120 min. Considering typical four seasons in Korea, three-day data of the each season were compared as test data. The MLP was optimized with four hidden layers and 128 nodes for air temperature (R2 = 0.988) and with four hidden layers and 64 nodes for relative humidity (R2 = 0.990). Due to the characteristics of MLP, the accuracy decreased as the prediction time became longer. However, air temperature and relative humidity were properly predicted regardless of the environmental changes varied from season to season.For specific data such as spray irrigation, however, the numbers of trained data were too small, resulting in poor predictive accuracy. In this study, air temperature and relative humidity were appropriately predicted through optimization of MLP, but were limited to the experimental greenhouse. Therefore, it is necessary to collect more data from greenhouses at various places and modify the structure of neural network for generalization."
해상 영상에서 관심영역 추출과 합성곱 신경망을 활용한 선박 분류,2019,"['선박 분류', '딥러닝', '컴퓨터 비전', '영상처리', 'Ship classification', 'Deep Learning', 'Computer Vision', 'Image Processing']","최근에 해양에서는 선박 스스로 주변 상황을 인지하고 운항할 수 있는 자율운항 기술개발이 활발하게 이루어지고 있다. 이를 위해, 카메라를 통한 영상정보를 활용하여 인간의 시각 정보를 대신할 수 있는 기술에 대한 중요성이 대두되고 있다. 카메라 영상을 기반으로 한 상황인지 기술을 위해서는 영상에서 존재하는 다양한 객체 정보를 분석하는 객체 분류 기술이 필수적이다. 본 논문에서는 해양 영상에서 관심 영역 추출과 합성곱 신경망을 활용하여 선박 분류 정확도를 향상시킬 수 있는 방법을 제안한다. 본 논문에서 제안된 방식의 성능을 검증하기 위해 공개 데이터 셋을 이용하여 기존의 합성곱 신경망 기반 방법과의 비교 실험을 수행하였으며, 실험을 통해 본 논문에서 제안된 방식이 선박 분류 정확도를 향상시킬 수 있음을 확인하였다. 제안된 방법을 활용하여 자율운항선박에서는 다른 해상 장비와의 센서 퓨전을 통하여 객체 데이터의 신뢰성을 확보할 수 있으며, 이를 통해 충돌 회피 및 안전한 운항이 가능할 것으로 기대된다.","Recently, autonomous navigation technology has been actively developed in order to recognize and operate the vessel itself. For this purpose, importance is attached to technologies that can substitute human visual information by utilizing image information through a camera. For the context recognition based on the camera image, object classification technology for analyzing various object information existing in the image is essential. In this paper, we propose a method to improve the accuracy of ship classification by using region of interest and artificial neural network. In order to verify the performance of the propose method in this paper, we performed a comparative experiment with the convolution artificial neural network based on the open data set. Experimental results show that the proposed method improves the accuracy of vessel classification. By using the proposed method, it is possible to secure the reliability of object data through sensor fusion with autonomous vessels, and it is expected that collision avoidance and safe operation will be possible."
온라인 뉴스와 기술적 지표를 이용한 테마주 등락 예측,2019,"['테마주', '주가예측', '딥러닝', 'GRU', 'XGBoost', 'Theme Stocks', 'Stock Price Prediction', 'Deep Learning', 'GRU', 'XGBoost']","특정 주제의 뉴스에 의해 주가가 영향을 받는 기업군을 테마주라고 한다. 최근 온라인 뉴스와 기술적 지표를 활용한 주가예측이 연구되고 있지만, 투자 위험이 큰 테마주에 대한 연구는 부족하다. 본 논문에서는 감성 지표와 기술적 지표를 이용하여 테마주에 대해 주가 등락을 예측하는 모델을 제안한다. 제안한 모델은 Gated Recurrent Unit (GRU)를 사용해 뉴스로부터 감성지표를 계산하고, 감성지표와 기술적 지표를 바탕으로 eXtreme Gradient Boosting (XGBoost)을 통해 주가 등락을 예측한다. 북한 테마에 속하는 10개 기업을 이용하여 실험한 결과, 제안한 모델이 최신연구의 모델보다 평균 정확도가 최대 19.0%P 더 높았다.","Theme stocks are a group of companies whose stock prices are affected by news of a certain subject. Recently, there have been research efforts to predict stock prices using online news and technical indicators, but little attention has been paid so far to theme stocks, which have high investment risks. In this paper, we propose a model that predicts stock price fluctuations for theme stocks using a sentiment indicator and technical indicators. The proposed model calculates a sentiment indicator from news using Gated Recurrent Unit (GRU) and predicts stock price fluctuations through eXtreme Gradient Boosting (XGBoost) based on the sentiment indicator and technical indicators. The experimental results using 10 companies belonging to the North Korea theme show that the proposed model improves the average accuracy up to 19.0%P compared with the state-of-the-art model."
Prediction of Compound-Protein Interactions Using Deep Learning,2019,"['기계 번역', '딥러닝', '신약 개발', '화합물-단백질 상호작용', '분류분석', 'Machine translation', 'deep learning', 'drug development', 'compound-protein interaction', 'classification']",,
인공지능 기반 식생활 습관 개선 다이어트 애플리케이션,2019,"['다이어트 애플리케이션', '머신러닝 기반 추천 시스템', '딥러닝 기반 음식 인식 인터페이스', 'Diet Applications', 'Machine learning-Based Recommended system', 'Deep learning-Based Food recognition inter']",,
스마트폰 기반의 무인 영상 추적 시스템 연구,2019,"['영상 추출', '딥러닝', '이미지 추출', '무인 영상', '블루투스', 'Video extraction', 'Deep running', 'Image extraction', 'Unattended moving', 'Bluetooth']","최근 스마트폰 기반의 영상 이미지 추적을 통한 무인 녹화 시스템은 급속히 발전하고 있다. 기존의 제품 중 적외선 신호를 이용하여 촬영 대상을 자동으로 추적 및 회전하여 녹화하는 시스템은 일반 사용자가 사용하기에는 매우 고가이다. 따라서 본 논문에서는 스마트폰을 사용하는 사용자라면 누구나 자동 녹화가 가능한 모바일용 무인 녹화 시스템을 제안한다. 본 시스템은 상용 Mobile 카메라, 좌우로 카메라를 움직이는 서보모터(Servo Motor), 모터를 제어하는 마이크로 컨트롤러 그리고 동영상 오디오 입력을 담당할 상용 무선 블루투스 이어셋(Wireless Bluetooth Earset)으로 구성된다. 본 논문에서는 스마트 폰을 이용하여 영상 추적을 통해 무인 녹화가 가능한 시스템을 설계하였다.","An unattended recording system based on smartphone based image image tracking is rapidly developing. Among the existing products, a system that automatically tracks and rotates the object to be photographed using an infrared signal is very expensive for general users. Therefore, this paper proposes a mobile unattended recording system that enables automatic recording by anyone who uses a smartphone. The system consists of a commercial mobile camera, a servomotor that moves the camera from side to side, a microcontroller to control the motor, and a commercial wireless Bluetooth Earset for video audio input. In this paper, we designed a system that enables unattended recording through image tracking using smartphone."
납기 위반 및 셋업 최소화를 위한 강화학습 기반의 설비 일정계획 모델,2019,"['일정계획', '강화학습', '납기', '셋업비용', '딥러닝', 'Scheduling', 'Reinforcement Learning', 'Due Date', 'Setup Cost', 'Deep Learning']","최근 제조업체들은 제품의 생산방식이 고도화 되고, 복잡해지면서 생산 장비를 효율적으로 사용하는데 어려움을 겪고 있다. 제조공정의 효율성을 방해하는 대표적인 요인들로는 작업물 종류 변경(job change)으로 인한 작업 준비 비용(Setup Cost) 등이 있다. 특히 반도체/LCD 공정과 같이 고가의 생산 장비를 사용하는 공정의 경우 장비의 효율적인 사용이 매우 중요한데, 상호 충돌하는 의사결정인 납기 준수를 최대화 하는 것과 작업물 종류 변경으로 인한 작업 준비 비용을 최소화 하는 것 사이에서 균형을 유지하는 것은 매우 어려운 일이다. 본 연구에서는 납기와 작업 준비 비용이 있는 병렬기계에서 강화학습을 활용하여 납기 및 셋업 비용의 최소화 목표를 달성하는 일정계획 모델을 개발하였다. 제안하는 모델은 DQN(Deep Q-Network) 일정계획 모델로 강화학습기반의 모델이다. 제안모델의 효율성을 측정하기 위해 DQN 모델과 기존에 개발하였던 심층 신경망 기반의 일정계획 생성기법과 휴리스틱 원칙의 결과를 비교하였다. 비교 결과 DQN 일정계획 생성기법이 심층신경망 방식과 휴리스틱 원칙에 비하여 납기 및 셋업 비용이 적은 것을 확인할 수 있었다.","Recently, manufacturers have been struggling to efficiently use production equipment as their production methods become more sophisticated and complex. Typical factors hinderingthe efficiency of the manufacturing process include setup cost due to job change. Especially, in the process of using expensive production equipment such as semiconductor / LCD process, efficient use of equipment is very important. Balancing the tradeoff between meeting the deadline and minimizing setup cost incurred by changes of work type is crucial planning task. In this study, we developed a scheduling model to achieve the goal of minimizing the duedate and setup costs by using reinforcement learning in parallel machines with duedate and work preparation costs. The proposed model is a Deep Q-Network (DQN) scheduling model and is a reinforcement learning-based model. To validate the effectiveness of our proposed model, we compared it against the heuristic model and DNN(deep neural network) based model. It was confirmed that our proposed DQN method causes less due date violation and setup costs than the benchmark methods."
유전적 알고리즘이 데이터셋 생성에 미치는 영향에 대한 연구,2019,"['유전 알고리즘', '데이터셋', '딥러닝', '하이퍼파라미터', '적합도', 'Genetic Algorithm', 'Dataset', 'Deep-Learning', 'Hyperparameter', 'Fitness']",,"Currently, deep-learning technology is used in various fields. In order to apply deep learning, model configuration is important, but data sets for learning and testing are also important. For the accuracy of the deep learning model, the size of the training dataset is very important because the dataset has a significant impact on accuracy. Also, the more data collected in various environments, the higher the accuracy. This consumes capital to collect a large amount of data. However, when a data set can not be collected due to a limited environment, a new data set is created through a transformation operation such as rotating or enlarging existing data. In this study, we propose a study on the effect of generation, mating, and mutation of genetic algorithms on accuracy of data inflation in the process of generating and learning data sets."
비정형 Security Intelligence Report의 정형 정보 자동 추출,2019,"['보안 위협', '정보 추출', '머신러닝', '딥러닝', '문서 분류', 'Threat Information', 'Information Extraction', 'Machine Learning', 'Deep Learning', 'Document Analysis']","사이버 공격을 예측하고 대응하기 위해서 수많은 보안 기업 회사에서는 공격기법의 특성, 수법 유형을 빠르게 파악하고, 이에 대한 Security Intelligence Report(SIR)들을 배포한다. 하지만 각 기업에서 배포하는 SIR들은 방대하며, 형식이 맞춰져 있지 않다. 본 논문은 대량의 비정형한 SIR들에서 정보를 추출하는데 소요되는 시간을 줄이고 효율적으로 파악하기 위해 SIR들에 대해 정형화하고 주요 정보를 추출하기 위해 5가지 분석기술이 적용된 프레임워크를 제안한다. SIR들의 데이터는 정답 라벨이 없기 때문에 비지도 학습방식을 통해 키워드 추출, 토픽 모델링, 문서 요약, 유사 문서 검색 총 4가지 분석기술을 제안한다. 마지막으로 SIR들에서 위협 정보 추출하기 위해 데이터를 구축하였으며, 개체명 인식 기술에 적용하여 IP, Domain/URL, Hash, Malware에 속하는 단어를 인식하고 그 단어가 어떤 유형에 속하는지 판단하는 분석기술을 포함한 총 5가지 분석기술이 적용된 프레임워크를 제안한다.","In order to predict and respond to cyber attacks, a number of security companies quickly identify the methods, types and characteristics of attack techniques and are publishing Security Intelligence Reports(SIRs) on them. However, the SIRs distributed by each company are huge and unstructured. In this paper, we propose a framework that uses five analytic techniques to formulate a report and extract key information in order to reduce the time required to extract information on large unstructured SIRs efficiently. Since the SIRs data do not have the correct answer label, we propose four analysis techniques, Keyword Extraction, Topic Modeling, Summarization, and Document Similarity, through Unsupervised Learning. Finally, has built the data to extract threat information from SIRs, analysis applies to the Named Entity Recognition (NER) technology to recognize the words belonging to the IP, Domain/URL, Hash, Malware and determine if the word belongs to which type We propose a framework that applies a total of five analysis techniques, including technology."
미래 기상정보를 사용하지 않는 LSTM 기반의 피크시간 태양광 발전량 예측 기법,2019,"['태양광 발전량 예측', '딥러닝', '시계열 분석', '장기-단기 기억 메모리', 'Photovoltaic Power Prediction', 'Deep Learning', 'Time Series Analysis', 'Long-short Term Memory']","최근 태양광 발전량 예측은 태양광 발전량 설비 시스템의 안정적인 작동을 위한 조정 계획, 설비 규격 결정 및 생산 계획 일정을 수립하기 위해 필수적인 요소로 고려된다. 특히, 대부분의 태양광 발전량은 피크시간에 측정되기 때문에, 태양광 시스템 운영자의 이익 최대화와 전력 계통량 안정화를 위해 피크시간의 태양광 발전량 예측은 매우 중요한 요소이다. 또한, 기존 연구들은 광범위한 지역에서 예측된 불확실한 기후 정보들을 이용하여 태양광 발전량을 예측하는 한계점 때문에 일사량, 운량, 온도 등과 기상정보 없이 피크시간의 태양광 발전량을 예측하는 것은 매우 어려운 문제로 고려된다. 따라서 본 논문에서는 피크이전의 기후, 계절 및 관측된 태양광 발전량을 이용하여 미래의 기후 및 계절 정보 없이 피크시간의 태양광 발전량을 예측할 수 있는 LSTM(Long-Shot Term Memory) 기반의 태양광 발전량 예측 기법을 제안한다. 본 연구에서 제안한 모델을 기반으로 실 데이터를 통한 실험 결과, 단기 및 장기적 관점에서 높은 성능을 보였으며, 이는 본 연구에서 목표로 한 피크시간의 태양광 발전량 예측 성능 향상에 긍정적인 영향을 나타내었음을 보여준다.","Recently, the importance prediction of photovoltaic power (PV) is considered as an essential function for scheduling adjustments, deciding on storage size, and overall planning for stable operation of PV facility systems. In particular, since most of PV power is generated in peak time, PV power prediction in a peak time is required for the PV system operators that enable to maximize revenue and sustainable electricity quantity. Moreover, Prediction of the PV power output in peak time without meteorological information such as solar radiation, cloudiness, the temperature is considered a challenging problem because it has limitations that the PV power was predicted by using predicted uncertain meteorological information in a wide range of areas in previous studies. Therefore, this paper proposes the LSTM (Long-Short Term Memory) based the PV power prediction model only using the meteorological, seasonal, and the before the obtained PV power before peak time. In this paper, the experiment results based on the proposed model using the real-world data shows the superior performance, which showed a positive impact on improving the PV power in a peak time forecast performance targeted in this study."
인공지능 학습을 활용한 브랜드 아이덴티티의 일치도 분석,2019,"['브랜드 아이덴티티', '리테일 디자인', '딥러닝', '이미지 분류', 'Brand Identity', 'Retail Design', 'Deep Learning', 'Image Classification']",,"The aim of this study is to investigate a way of determining consistency of brand identity in store design with deep learning-based technology. The concept of brand identity has been aroused in order to set brands apart from tough competitors in global marketplace. Especially, brand space has been highlighted as a strong communicator of consistent brand identity. However, in terms of spatial environments, brand identity has been studied adopting qualitative approaches. This paper look into a way of quantifying consistency of brand identity adopting deep learning-based image classification model. Following the case of Starbucks and Bluebottle – two brands creating constant and strong brand identity attached to worldwide brand spaces – auto image classification was conducted with TensorFlow to investigate brand identity congruence. Departing from training image recognition model, 3 tests were conducted to demonstrate the train model. This paper demonstrates that a consistent, coherent, and strong brand identity attached to store design can be trained and recognized with deep learning-based technology. This research also suggests the wider usage of this model in branding and interior design."
Korean Dependency Parsing using the Self-Attention Head Recognition Model,2019,"['의존구문분석', 'Self-Attention', '딥러닝', '자연어처리', 'dependency parsing', 'deep learning', 'natural language processing']",,
딥러닝기반 다중 표적 인식을 활용한 모바일 로봇 경로 계획,2019,"['표적인식', '경로계획', '장애물 회피', '딥러닝', '모바일 로봇', 'Taget Detection', 'Path Planning', 'Avoidance Obstacle', 'Deep-Learning', 'Mobile Robot']","복합적인 고차원의 임무를 수행하기 위하여 미래무인화 전투 체게는 인공지능 기술을 필요로 한다. 특히 합성곱 신경망은 영상뿐만 아니라 자연어 처리까지 광범위한 범위에서 탁월한 성능을 보이고 있어 무인화 전투체계의 표적정보인식, 피아식별, 전장정보인식 등 각종 센서 융합에 매우 적합하다. 본 연구에서는 합성곱 신경망의 영상인식 기술을 활용하여 다수 대상체의 상태정보를 인식함으로써 변화되는 환경에서의 무인로봇 경로 계획 개선 방안을 제시하였고 시뮬레이션을 통하여 추정된 로봇의 위치, 장애물, 목표물 정보로부터 로봇의 경로 계획의 유효성을 검증 하였다.","Unmmanned systems are one of the essential areas of future military weapons systems that must carry out dangerous and cmplex missions. Especially, deep learning should recognize many landmarks through the image and project them onto the map to improve the problem of position estimation, because it shows excellent performance of recognizing and classifying the characteristics of image data among other artificial intelligence techniques. In this study, the path planning of the unmanned reconnaissance aircraft and the unmanned ground vehicle, which are currently being used in the ROK military, is linked with the CNN based multi target recognition algorithm without GPS. Throuth experiments, we verified the effectiveness of the path planning of the mobile robot with respect to the position of the robot, obstacle, and target point estimated by the target detection algorithm."
텐서플로우를 활용한 GPU 환경에서 정적 악성코드 탐지 기법,2019,"['악성코드 분석', '악성코드 탐지', '정적 분석', '딥러닝', 'Malware Analysis', 'Malware Detection', 'Static Analysis', 'Deep Learning']","최근, 개인용 PC 및 다양한 모바일 디바이스에 보안 패치의 취약점을 통해 신종 및 변종 악성코드의 감염이 빠르게 확산되어 개인 정보 유출, 공인 인증서 탈취, 암호화폐 채굴 등의 다양한 피해가 급증되고 있다. 이를 위해 악성코드 시그니처 기반 악성코드 탐지 기법을 이용하고 있지만, 빠르게 생성되는 신·변종 악성코드를 탐지의 정확도가 현저히 낮다. 본 연구에서는 LSTM를 이용하여 알려진 악성코드뿐만 아니라 신·변종 악성코드들을 탐지하는 스킴을 제안한다.",
뉴럴 네트워크의 최적화에 따른 유사태풍 예측에 관한 연구,2019,"['Artificial intelligence 인공지능', 'Deep learning 딥러닝', 'Big data 빅데이터', 'Activation function\u3000활성화\u3000함수', 'Disaster prevention system 방재 시스템']",,"Artificial intelligence (AI)-aided research currently enjoys active use in a wide array of fields thanks to the rapid development of computing capability and the use of Big Data. Until now, forecasting methods were primarily based on physics models and statistical studies. Today, AI is utilized in disaster prevention forecasts by studying the relationships between physical factors and their characteristics. Current studies also involve combining AI and physics models to supplement the strengths and weaknesses of each aspect. However, prior to these studies, an optimization algorithm for the AI model should be developed and its applicability should be studied. This study aimed to improve the forecast performance by constructing a model for neural network optimization. An artificial neural network (ANN) followed the ever-changing path of a typhoon to produce similar typhoon predictions, while the optimization achieved by the neural network algorithm was examined by evaluating the activation function, hidden layer composition, and dropouts. A learning and test dataset was constructed from the available digital data of one typhoon that affected Korea throughout the record period (1951–2018). As a result of neural network optimization, assessments showed a higher degree of forecast accuracy."
RNN을 이용한 제2형 당뇨병 예측모델 개발,2019,"['제2형 당뇨병', '질병 예측', '기계 학습', '딥러닝', 'RNN', '의료 인공지능', 'T2DM', 'Disease Prediction', 'Machine Learning', 'Deep Learning', 'RNN', 'Medical AI']","제2형 당뇨병은 고혈당이 특징인 대사성 분비 장애로 여러 합병증을 야기하는 질병이며, 장기적인 치료가 필요하기 때문에 매년 많은 의료비를 지출한다. 이를 해결하기 위해 많은 연구들이 있어왔지만, 기존의 연구들은 한 시점에서의 데이터를 학습시켜 예측함으로써 정확도가 높지 않았다. 그래서 본 연구는 제2형 당뇨병 발생 예측에 대한 정확도를 높이기 위하여 RNN을 이용한 모델을 제안하였다. 본 모델을 개발하기 위해 한국인유전체역학조사 지역사회 코호트(안산·안성) 데이터를 이용하였으며, 시간의 흐름에 따른 데이터들을 모두 학습시켜 당뇨병 발생 예측모델을 만들었다. 예측 모델의 성능을 검증하기 위해 기존의 기계 학습 방법인 LR, k-NN, SVM과 정확도를 비교하였다. 비교한 결과 제안한 예측모델의 accuracy는 0.92, AUC는 0.92로 다른 기계 학습 방법보다 높은 정확도를 보였다. 따라서 본 연구에서 제안한 제2형 당뇨병 발생 예측 모델을 활용하여 발병을 조기 예측함으로써 생활습관 개선 및 혈당조절을 통해 당뇨병 발병을 예방하고 늦출 수 있을 것이다.","Type 2 diabetes mellitus(T2DM) is included in metabolic disorders characterized by hyperglycemia, which causes many complications, and requires long-term treatment resulting in massive medical expenses each year. There have been many studies to solve this problem, but the existing studies have not been accurate by learning and predicting the data at specific time point. Thus, this study proposed a model using RNN to increase the accuracy of prediction of T2DM. This work propose a T2DM prediction model based on Korean Genome and Epidemiology study(Ansan, Anseong Korea). We trained all of the data over time to create prediction model of diabetes. To verify the results of the prediction model, we compared the accuracy with the existing machine learning methods, LR, k-NN, and SVM. Proposed prediction model accuracy was 0.92 and the AUC was 0.92, which were higher than the other. Therefore predicting the onset of T2DM by using the proposed diabetes prediction model in this study, it could lead to healthier lifestyle and hyperglycemic control resulting in lower risk of diabetes by alerted diabetes occurrence."
마케팅 데이터를 대상으로 중요 통계 예측 기법의 정확성에 대한 비교 연구,2019,"['Statistical Forecasting', 'R', 'Regression', 'Random Forest', 'Decision Tree', 'Support Vector Machine', '통계적 예측', 'R', '회귀', '랜덤 포레스트', '의사 결정 나무', '서포트 벡터 머신']","미래를 예측하는 기법은 통계에 기반을 둔 것과 딥러닝에 기반을 둔 기술로 분류할 수 있다. 그중 통계에 기반을 둔 것이 간단하고 정확성이 높아서 많이 사용된다. 하지만 실무자들은 많은 분석기법의 올바른 사용에 어려움이 많다. 이번 연구에서는 마케팅에 관련된 데이터에 다항로지스틱회귀, 의사결정나무, 랜덤포레스트, 서포트벡터머신, 베이지안 추론을 적용하여 예측의 정확성을 비교하였다. 동일한 마케팅 데이터를 대상으로 하였고, R을 활용하여 분석을 진행하였다. 마케팅 분야의 데이터 특성을 반영한 다양한 기법의 예측 결과가 실무자들에게 좋은 참고가 될 것으로 생각한다","Techniques for predicting the future can be categorized into statistics-based and deep-run-based techniques. Among them, based on statistics is simple and highly accurate, so it is widely used. However, working-level officials have difficulty using many analytical techniques correctly. In this study, we compared the accuracy of prediction by applying multinomial logistic regression, decision tree, random forest, support vector machine, and Bayesian inference to marketing related data. The same marketing data was used, and analysis was conducted using R. I think that the prediction results of various techniques reflecting the data characteristics of the marketing field will be a good reference for practitioners."
언간 연구의 국어사적 성과와 전망,2019,"['언간(한글편지)', '구개음화 현상', '주격조사', '딥러닝', '사회언어학', '언간의 국어사', ""Eon'gan"", 'palatalization', 'Nominative marker', 'Deep Learning', 'sociolinguistics', ""Korean language history of Eon'gan""]",,"The purpose of this study is to review the accomplishments of Eon'gan study in the Korean Language History based on Eon'gan data of Joseon Dynasty and to predict future studies. The main reasons of gathering interest in Eon'gan data are the excavation of family letters such as <Suncheo'ngimss'iEongan> and <Jinjuhass'iEongan> and the publication of translated books of Eon'gan. Furthermore, the interpretation book of Eon'gan has played a key role in enhancing the reliability of Eon'gan data. Regarding writing and phonographical matters, palatalization and liquid consonant along with ‘ㆍ’, ‘ㅸ’ and ‘ㅿ’ were main interest. The most active discussion among them is the phenomenon of palatalization, and it is noticeable that not only was the practice of palatalization discussed but also the change by various factors of sociolinguistics was discussed. The grammar part is the most actively discussed among Eon'gan studies. Especially, such matters as nominative marker and relative honorific expressions can be considered as the most meaningful accomplishments in Eon'gan data. In addition, there is active discussion on pronouns, individual ending words and individual morpheme. Studies on vocabulary based on Eon'gan data show high interest in Eon'gan's own vocabularies that do not appear in printed books. Recently, names of articles, disease related words, unit nouns and names of places are also objects of main interest. Meanwhile, the number of Eon'gan data introduced to the academic world is 3,296, and there is a need for expansion of Eon'gan data through deep learning. There should be active sociolinguistic discussion that can highlight the strengths of Eon'gan data while the necessity of computational linguistics for establishment of corpus is discussed. The difference between males and females can be a future research subject. It is necessary to elaboratize the details of the existing Korean language history through Eon'gan data, along with the description of tentatively named ""Korean language history of Eon'gan'."
"CNN의 컨볼루션 레이어, 커널과 정확도의 연관관계 분석",2019,"['Deep Learning', 'Convolution Neural Network', 'Kernel', 'Layer', 'Accuracy', 'Learning Time', '딥러닝', 'CNN', '커널', '레이어', '정확도', '학습 시간']","본 논문에서는 CNN의 컨볼루션 레이어 개수 및 커널의 크기와 개수가 CNN에 어떠한 영향을 끼치는지 실험을 통해 알아보기 위해 진행하였다. 또한 분석을 위해 일반적인 CNN도 실험하여 실험에 사용된 CNN과 비교하 였다. 분석에 사용될 신경망들은 CNN을 기반으로 하며 각각의 실험모델들은 레이어 개수, 커널의 크기 및 개수를 일정한 값으로 고정해 실험을 진행하였다. 모든 실험에는 2계층의 완전연결계층을 고정으로 사용하였다. 다른 변수들은 모두 동일한 값을 주어 실험하였다. 분석결과 레이어의 수가 작을 경우 커널의 크기 및 개수와 상관없이 데이터의 분산 값이 작아 견고한 정확도를 보여주었다. 레이어의 수가 커질수록 정확도도 증가됐으나 일정 수치 이상부턴 오히려 정확도가 내려갔으며 분산 값도 커져 정확도 편차가 크게 나타났다. 커널의 개수는 다른 변수보다 학습속도에 큰 영향을 끼쳤다.","In this paper, we experimented to find out how the number of convolution layers, the size, and the number of kernels affect the CNN. In addition, the general CNN was also tested for analysis and compared with the CNN used in the experiment. The neural networks used for the analysis are based on CNN, and each experimental model is experimented with the number of layers, the size, and the number of kernels at a constant value. All experiments were conducted using two layers of fully connected layers as a fixed. All other variables were tested with the same value. As the result of the analysis, when the number of layers is small, the data variance value is small regardless of the size and number of kernels, showing a solid accuracy. As the number of layers increases, the accuracy increases, but from above a certain number, the accuracy decreases, and the variance value also increases, resulting in a large accuracy deviation. The number of kernels had a greater effect on learning speed than other variables."
이미지 정보를 이용한 영어-한국어 자동 번역,2019,"['machine translation', 'multimodal', 'deep learning', 'image information', 'decoding gate', '기계 번역', '멀티모달', '딥러닝', '이미지 정보', '디코딩 게이트']","기계 번역 연구는 하나의 언어로 된 텍스트를 다른 언어로 자동 변환하는 기술이다. 기존의 기계 번역 연구는 번역을 위해 오직 텍스트 데이터만 사용하였다. 따라서 기존 기계 번역 연구는 입력 텍스트와 관련된 다양한 정보들을 활용할 수 없다는 단점이 있다. 최근에는 텍스트 데이터만 사용하는 기존 기계 번역과 달리 입력 텍스트와 관련된 이미지 정보를 기계 번역 시스템의 추가 입력으로 사용하는 멀티모달 기계 번역 모델이 등장했다. 본 연구에서는 최근 연구 동향에 맞추어 기계 번역의 디코딩 타임에 이미지 정보를 추가하고 이를 영어-한국어 자동 번역에 적용한다. 또한 디코딩 타임에 텍스트 정보와 이미지 정보를 적절히 조절하기 위한 별도의 게이트를 적용한 모델을 제안하고, 실험을 통해 게이트를 적용하지 않은 모델보다 더 좋은 성능을 나타냄을 보인다.","Machine translation automatically converts a text in one language into another language.Conventional machine translations use only texts for translation which is a disadvantage in that various information related to input text cannot be utilized. In recent years, multimodal machine translation models have emerged that use images related to input text as additional inputs, unlike conventional machine translations which use only textual data. In this paper, image information was added at decoding time of machine translation according to recent research trends and used for English-to-Korean automated translation. In addition, we propose a model with a decoding gate to adjust the textual and image information at the decoding time. Our experimental results show that the proposed method resulted in better performance than the non-gated model."
홈 IoT 환경에서의 CNN-DNN 기반 음향인지 알고리즘,2019,"['Deep learning', 'sound event detection', 'log mel filter bank', '딥러닝', '음향인지', 'log mel filter bank']",,"In this study, we proposed a CNN-DNN based sound event detection in home IoT environments. To reduce the impact of input volume variation, we applied peak normalization, and extracted acoustic feature named Log mel filter bank. Log-mel filter bank is very popular acoustic feature based on mel filter which is powerful for speech recognition and sound event detection. Then, we used CNN-DNN model for classification. CNN outputs of sequential 32 frames were used as DNN input for considering time-series characteristic of the sound. Data were collected in real apartment environment. We used 13 sounds as target such as doorbell, babycry, vacuum, and so on. We evaluated our method using computer simulation, as a result, the accuracy of the proposed sound event detection algorithm was 90.76%."
랜섬웨어 방어를 위한 합성곱 신경망 기반의 데이터 암호화 탐지 기법,2019,"['ransomware', 'deep learning', 'convolutional neural network', 'computer security', '랜섬웨어', '딥러닝', '합성곱 신경망', '컴퓨터 보안']","최근 랜섬웨어에 의한 피해가 심각해짐에 따라, 랜섬웨어 공격을 실시간으로 감지하고 방어하는 기술 개발의 중요성이 높아지고 있다. 기존 랜섬웨어 탐지 기법의 한계를 극복하기 위해, 저장장치 내부 수준의 데이터 보존 및 복구 기법이 제안되었으나, 무분별한 데이터 보존으로 인해 저장공간 부하를 크게 증가시킬 수 있다는 한계점이 존재한다. 본 논문에서는 보존할 데이터를 정확하게 선정하면서도 피해 데이터를 온전하게 보존하기 위한, 합성곱 신경망 기반의 데이터 암호화 여부 판단 기법을 제시한다. 실험 결과, 제안한 기법은 저장장치 내부 수준에서 상위 계층의 정보 없이 93.90%의 높은 정확도로 데이터의 암호화 여부를 판단하였다. 또한, 손실 함수와 결정 경곗값을 수정하여 0에 가까운 부정 오류율을 달성하였다.","With the rapid increase in the number of ransomwares recently, the development of real-time strategies for ransomware defense is imperative. To overcome the limitations of traditional ransomware defense techniques, a storage-level data recovery technique was suggested. However, as the technique inefficiently selects data to conserve, it has a negative impact on the lifetime and performance of storage. In this paper, we propose a CNN-based encrypted data detection technique to enhance the accuracy of selecting data to conserve while ensuring complete data recovery. Our experiments show that the proposed technique achieved 93.90% detection accuracy at the storage-level without any high-level information. Furthermore, by changing the loss function and controlling a detection threshold, we attained a false negative rate of nearly 0."
인공지능 기반 MNIST 손글씨 인식에 대한 연구,2019,"['Handwriting', 'SLR', 'ANN', 'CNN', 'Deep learning', '손글씨', '소프트맥스 회귀분석', '인공신경망', '합성곱신경망', '딥러닝']",,"In the development of electronic devices such as PDAs, smartphones, and tablets, research on handwriting recognition has emerged. In the meantime, there have been efforts to recognize various handwriting such as numbers, Japanese, and English. However, there is a point that it is difficult to recognize when the font shape is relatively irregular, such as handwriting of children. As a result, the need for research to improve handwriting recognition rate by applying deep learning techniques has recently been raised. Therefore, this study attempted to improve handwriting recognition rate based on various deep learning techniques. In the case of handwriting, it is difficult to prepare a variety of data sets, which limits the recognition rate. In this study, we tried to improve the accuracy of handwriting recognition by using CNN technique in order to find a way to overcome these limitations. The techniques used were SLR, ANN, and CNN, each measuring the accuracy of each method. As a result, CNN showed the highest performance of 95%."
LSTM을 이용한 재밍 기법 예측,2019,"['Jamming(재밍)', 'Radar Signal(레이다 신호)', 'Deep Learning(딥러닝)', 'LSTM(장단기 기억 구조)']",,"Conventional methods for selecting jamming techniques in electronic warfare are based on libraries in which a list of jamming techniques for radar signals is recorded. However, the choice of jamming techniques by the library is limited when modified signals are received. In this paper, we propose a method to predict the jamming technique for radar signals by using deep learning methods. Long short-term memory(LSTM) is a deep running method which is effective for learning the time dependent relationship in sequential data. In order to determine the optimal LSTM model structure for jamming technique prediction, we test the learning parameter values that should be selected, such as the number of LSTM layers, the number of fully-connected layers, optimization methods, the size of the mini batch, and dropout ratio. Experimental results demonstrate the competent performance of the LSTM model in predicting the jamming technique for radar signals."
LSTM을 활용한 불법주정차 시공간 예측 모델링: 서울시 민원신고 데이터를 중심으로,2019,"['Long Short-Term Memory(LSTM)', '불법주정차', '민원신고', '예측', '딥러닝', 'Long Short-Term Memory(LSTM)', 'Illegal Parking Cases', 'Civil Complaints', 'Prediction', 'Deep Learning']","본 연구의 목적은 서울시 내에서 발생한 불법주정차 민원신고 데이터를 활용하여 불법주정차 발생의 시공간 예측모델을 구축하는 것이다. 예측모델은 최근 시계열 예측 분야에서 높은 성능을 보이고 있는 long short-term memory (LSTM)을 활용하여 생성하였다. LSTM을 활용한 시계열 예측 시에는 시간단위 설정이 중요하기 때문에 기존 연구에서의 예측모델은 시간단위를 어떻게 설정할 것인가에 집중하고 있다. 본 연구에서는 시간단위 뿐 아니라 공간단위 설정에 따른 문제점을 분석하고, 실험을 통해 최적의 예측 공간단위를 찾고자 하였다. 이를 위해 예측의 시간단위는 월별 24시간을 기준으로 하고, 공간단위는 자치구, 토지이용유형, 도로 및 도로 외, 그리고 토지이용유형별 도로와 도로가 아닌 지역으로 구분한 공간 단위별로 분석을 수행하였다. 그 결과 토지이용유형, 도로 및 도로 외로 공간단위를 구분하였을 때 예측모델들이 전반적으로 좋은 성능을 보였으며, 자치구로 구분하였을 때 좋지 않은 성능을 보이는 것을 확인하였다.","This study aims to predict the number of illegal parking using data on complaints of illegal parking within Seoul. We made the prediction models using long short-term memory(LSTM) which has shown high performance in the field of the series prediction recently. Because setting the time unit is important for time series prediction, prediction models in the previous researches include consideration of how to set the time unit. In this study, the prediction models were made with consideration of not only time unit but also space unit. The time unit of prediction was set up for 24 hours per month, and the space unit was designated as district ‘gu’, land-use type, and road and off the road. As a result, it was confirmed that the prediction models performed well overall when dividing the spatial units by land-use type and road and off the road, and that the prediction models performed poorly when divided into district ‘gu’."
지식베이스 구축을 위한 한국어 위키피디아의 학습 기반 지식추출 방법론 및 플랫폼 연구,2019,"['Deep learning', 'Artificial Intelligence', 'Ontology', 'Knowledge base', 'Knowledge extraction', '딥러닝', '온톨로지', '인공지능', '지식베이스', '지식추출']","최근 4차 산업혁명과 함께 인공지능 기술에 대한 연구가 활발히 진행되고 있으며, 이전의 그 어느 때보다도기술의 발전이 빠르게 진행되고 있는 추세이다. 이러한 인공지능 환경에서 양질의 지식베이스는 인공지능 기술의 향상 및 사용자 경험을 높이기 위한 기반 기술로써 중요한 역할을 하고 있다. 특히 최근에는 인공지능 스피커를 통한 질의응답과 같은 서비스의 기반 지식으로 활용되고 있다. 하지만 지식베이스를 구축하는 것은 사람의 많은 노력을 요하며, 이로 인해 지식을 구축하는데 많은 시간과 비용이 소모된다. 이러한 문제를 해결하기위해 본 연구에서는 기계학습을 이용하여 지식베이스의 구조에 따라 학습을 수행하고, 이를 통해 자연어 문서로부터 지식을 추출하여 지식화하는 방법에 대해 제안하고자 한다. 이러한 방법의 적절성을 보이기 위해DBpedia 온톨로지의 구조를 기반으로 학습을 수행하여 지식을 구축할 것이다. 즉, DBpedia의 온톨로지 구조에따라 위키피디아 문서에 기술되어 있는 인포박스를 이용하여 학습을 수행하고 이를 바탕으로 자연어 텍스트로부터 지식을 추출하여 온톨로지화하기 위한 방법론을 제안하고자 한다. 학습을 바탕으로 지식을 추출하기 위한과정은 문서 분류, 적합 문장 분류, 그리고 지식 추출 및 지식베이스 변환의 과정으로 이루어진다. 이와 같은방법론에 따라 실제 지식 추출을 위한 플랫폼을 구축하였으며, 실험을 통해 본 연구에서 제안하고자 하는 방법론이 지식을 확장하는데 있어 유용하게 활용될 수 있음을 증명하였다. 이러한 방법을 통해 구축된 지식은 향후지식베이스를 기반으로 한 인공지능을 위해 활용될 수 있을 것으로 판단된다.","Development of technologies in artificial intelligence has been rapidly increasing with the Fourth Industrial Revolution, and researches related to AI have been actively conducted in a variety of fields such as autonomous vehicles, natural language processing, and robotics. These researches have been focused on solving cognitive problems such as learning and problem solving related to human intelligence from the 1950s. The field of artificial intelligence has achieved more technological advance than ever, due to recent interest in technology and research on various algorithms. The knowledge-based system is a sub-domain of artificial intelligence, and it aims to enable artificial intelligence agents to make decisions by using machine-readable and processible knowledge constructed from complex and informal human knowledge and rules in various fields. A knowledge base is used to optimize information collection, organization, and retrieval, and recently it is used with statistical artificial intelligence such as machine learning. Recently, the purpose of the knowledge base is to express, publish, and share knowledge on the web by describing and connecting web resources such as pages and data. These knowledge bases are used for intelligent processing in various fields of artificial intelligence such as question answering system of the smart speaker.However, building a useful knowledge base is a time-consuming task and still requires a lot of effort of the experts. In recent years, many kinds of research and technologies of knowledge based artificial intelligence use DBpedia that is one of the biggest knowledge base aiming to extract structured content from the various information of Wikipedia. DBpedia contains various information extracted from Wikipedia such as a title, categories, and links, but the most useful knowledge is from infobox of Wikipedia that presents a summary of some unifying aspect created by users. These knowledge are created by the mapping rule between infobox structures and DBpedia ontology schema defined in DBpedia Extraction Framework. In this way, DBpedia can expect high reliability in terms of accuracy of knowledge by using the method of generating knowledge from semi-structured infobox data created by users. However, since only about 50% of all wiki pages contain infobox in Korean Wikipedia, DBpedia has limitations in term of knowledge scalability. This paper proposes a method to extract knowledge from text documents according to the ontology schema using machine learning. In order to demonstrate the appropriateness of this method, we explain a knowledge extraction model according to the DBpedia ontology schema by learning Wikipedia infoboxes. Our knowledge extraction model consists of three steps, document classification as ontology classes, proper sentence classification to extract triples, and value selection and transformation into RDF triple structure. The structure of Wikipedia infobox are defined as infobox templates that provide standardized information across related articles, and DBpedia ontology schema can be mapped these infobox templates. Based on these mapping relations, we classify the input document according to infobox categories which means ontology classes. After determining the classification of the input document, we classify the appropriate sentence according to attributes belonging to the classification. Finally, we extract knowledge from sentences that are classified as appropriate, and we convert knowledge into a form of triples. In order to train models, we generated training data set from Wikipedia dump using a method to add BIO tags to sentences, so we trained about 200 classes and about 2,500 relations for extracting knowledge. Furthermore, we evaluated comparative experiments of CRF and Bi-LSTM-CRF for the knowledge extraction process. Through this proposed process, it is possible to utilize structured knowledge by extracting knowledge according to the ontology schema fro..."
국방용 합성이미지 데이터셋 생성을 위한대립훈련신경망 기술 적용 연구,2019,"['Generative Adversarial Networks(대립훈련신경망)', 'Synthetic Image(합성이미지)', 'Deep Learning(딥러닝)', 'Machine Learning(머신러닝)', 'Dataset(데이터셋)']",,"Generative adversarial networks(GANs) have received great attention in the machine learning field for their capacity to model high-dimensional and complex data distribution implicitly and generate new data samples from the model distribution. This paper investigates the model training methodology, architecture, and various applications of generative adversarial networks. Experimental evaluation is also conducted for generating synthetic image dataset for defense using two types of GANs. The first one is for military image generation utilizing the deep convolutional generative adversarial networks(DCGAN). The other is for visible-to-infrared image translation utilizing the cycle-consistent generative adversarial networks(CycleGAN). Each model can yield a great diversity of high-fidelity synthetic images compared to training ones. This result opens up the possibility of using inexpensive synthetic images for training neural networks while avoiding the enormous expense of collecting large amounts of hand-annotated real dataset."
사용자 인식을 위한 가상 심전도 신호 생성 기술에 관한 연구,2019,"['deep learning', 'auxiliary classifier', 'generative adversarial networks', 'electrocardiogram', '딥러닝', '보조 분류기', '적대적 생성 신경망', '심전도 신호']","심전도 신호는 시간 및 환경 변화에 따라 측정되는 시계열 데이터로 매번 등록 데이터와 동일한 크기의 비교 데이터를 취득해야 하는 문제점이 발생한다. 본 논문에서는 신호 크기 부적합 문제를 해결하기 위해 가상 생체신호 생성을 위한 보조 분류기 기반 적대적 생성 신경망(Auxiliary Classifier Generative Adversarial Networks)의 네트워크 모델을 제안한다. 생성된 가상 생체신호의 유사성을 확인하기 위해 코사인 각도와 교차 상관관계를 이용하였다. 실험 결과, 코사인 유사도 측정 결과로 평균 유사도는 0.991의 결과를 나타냈으며, 교차 상관관계를 이용한 유클리디언 거리 기반 유사성 측정 결과는 평균 0.25 유사도 결과를 나타냈다. 이는 등록 데이터와 실험 데이터간의 크기가 일치하지 않더라도 가상 생체신호 생성을 통해 신호 크기 부적합 문제를 해결함을 확인하였다.","Because the ECG signals are time-series data acquired as time elapses, it is important to obtain comparative data the same in size as the enrolled data every time. This paper suggests a network model of GAN (Generative Adversarial Networks) based on an auxiliary classifier to generate synthetic ECG signals which may address the different data size issues. The Cosine similarity and Cross-correlation are used to examine the similarity of synthetic ECG signals. The analysis shows that the Average Cosine similarity was 0.991 and the Average Euclidean distance similarity based on cross-correlation was 0.25: such results indicate that data size difference issue can be resolved while the generated synthetic ECG signals, similar to real ECG signals, can create synthetic data even when the registered data are not the same as the comparative data in size."
Faster R-CNN을 활용한 GPR 영상에서의 지하배관 위치추적 성능분석,2019,"['지하 배관', 'Faster R-CNN', '지표 투과 레이더', '딥러닝', 'VGGnet', '어그멘테이션', 'Buried pipelines', 'Faster R-CNN', 'GPR', 'Deep learning', 'VGGnet', 'Augmentation']",,
교통 데이터 수집을 위한 객체 인식 통합 프레임워크 개발,2019,"['Deep Learning', 'Direct Object Detection', 'Multi Objects Tracking', 'Computer Vision', '딥러닝', '직접 객체 인식', '영상 기반 객체 추적', '컴퓨터 시각화 기술']","본 연구에서는 다양한 외부 조건 하에서 촬영된 영상을 대상으로 신속하고 정확하게 교통객체를 검출하는 교통 객체 검출 통합 프레임워크를 개발하였다. 제안된 프레임워크는 딥러닝기술 기반의 직접 객체 인식 기술과 다중 객체 추적 기술, 그리고 동영상 전처리 기술로 구성되며, 영상의 안정성, 기상, 촬영 각도 등의 다양한 외부 조건에서 촬영된 영상을 대상으로 승용차, 버스, 트럭, 및 미니밴과 같은 교통 객체를 인식하고, 이를 실시간으로 추적하여 교통량데이터를 계수한다. 제안된 방법의 성능 검증을 위해 다양한 외부 조건에서 촬영된 영상 8개를대상으로 제안된 방법의 성능 검증을 수행한 결과, 우천 및 강설을 제외한 모든 조건에서 98% 이상의 높은 정확도를 보이는 것으로 나타났다.","A fast and accurate integrated traffic object detection framework was proposed and developed, harnessing a computer-vision based deep-learning approach performing automatic object detections, a multi object tracking technology, and video pre-processing tools. The proposed method is capable of detecting traffic object such as autos, buses, trucks and vans from video recordings taken under a various kinds of external conditions such as stability of video, weather conditions, video angles, and counting the objects by tracking them on a real-time basis. By creating plausible experimental scenarios dealing with various conditions that likely affect video quality, it is discovered that the proposed method achieves outstanding performances except for the cases of rain and snow, thereby resulting in 98% ~ 100% of accuracy."
k-최근접 이웃 알고리즘을 이용한 입찰가격예측,2019,"['Electronic Bidding', 'Python', 'KNN', 'Deep Learning', 'Prediction f oBidding', '전자 입찰', '파이썬', 'KNN', '딥러닝', '입찰 예측']","우리나라는 입찰에서 전자입찰을 기본으로 사용하고 있다. 전자입찰은 발주처에 직접 찾아가서 입찰 서류를 제출해야했던 번거로움을 간소화하고, 조달업체와 공공기관에 대면접촉에 의한 부정입찰을 방지할 수 있다는 장점이 있다. 그러나전자입찰에서 입찰 가격을 예측하는 것은 쉬운 일이 아니다. 본 논문은 전자입찰에 적용할 수 있는 파이썬을 이용해머신러닝을 적용한 입찰프로그램을 제안한다. 입찰 프로그램은 k-최근접 이웃(k-Nearest Neighbors : KNN) 알고리즘의KNeighborsRegressor를 이용하여 기존의 낙찰현황 데이터를 분류한 후, 이를 분석하여 훈련 세트와 테스트 세트의 정확도를통해 KNN 알고리즘을 이용한 모델을 구성하고, 기존낙찰가 분석을 통해 낙찰금액을 예측하였다.","In Korea, we have used electronic bidding as basics in the bidding. The electronic bidding has the advantages to simplify the troublesome of submitting bidding document directly to the client and to prevent unfair bidding due to fact-to-face contact between procurement company and public institution. However, it is not easy that predict the price tendered in the electric bidding. This paper proposes a bidding program with machine learning using python that can be applied to the electronic bidding. The bidding program classifies the data of existing bid status by using KNeighborsRegressor of k-Nearest Neighbors (KNN) algorithm. After we analyze the data of existing bid status, we compose a model using KNN algorithm through the accuracy of training set and test set.Finally we predict price tendered by analyzing the existing b idprice."
멀티 스케일 퓨전 네트워크를 활용한 문서영상 이진화,2019,"['binarization', 'document image', 'multi-scale fusion network', 'deep learning', '이진화', '문서 영상', '다중 스케일 퓨전 네트워크', '딥러닝']","화질이 저하된 문서 이미지의 이진화는 문서 이미지 분석에 중대한 영향을 미친다. 본 논문에서는 다중 스케일 구조를 갖는 LadderNet을 이용하여 저하된 문서 이미지의 기능을 학습하고 노이즈 픽셀로부터 텍스트 및 배경 픽셀을 분류하는 방법을 제시한다. 본 논문에서는 적절히 수정된 형태의 두 가지 LadderNet 아키텍처를 고려한다. 하나는 더 깊은 네트워크 구조이고 다른 하나는 더 얕은 네트워크 구조이며, 각 구조는 문서 이미지 패치를 사용하여 독립적으로 학습된다. 더 작은 크기의 윈도우로 더 깊은 아키텍처에서 생성된 예측 출력에는 텍스트 획이 더 명확하지만 많은 노이즈가 존재한다. 반면에, 더 큰 크기의 윈도우를 갖는 더 얕은 아키텍처로부터는 배경에서 더 낮은 노이즈가 생성된다. 본 논문에서는 이 두 가지 네트워크의 출력을 결합하여 더 나은 결과를 생성한다. 문서 이미지 이진화를 위한 벤치 마크 DIBCO 데이터 세트를 이용한 실험결과, 기존 방법보다 우수한 성능을 보임이 확인되었다.","Binarization of degraded document images has a significant impact on document image analysis domains. We developed a LadderNet with multi-scale architecture to learn features from degraded document images to classify text and background from noise pixels. Then, binarized images are generated from this classification. Specifically, we consider two properly designed LadderNet architectures: One with deeper architecture, another with shallower architecture. Each structure is calibrated independently using document image patches. A predicted output generated from the deeper architecture with smaller size of the striding window has clearer text-strokes but contains marked noise. Conversely, a predicted output has lower noise in the background from the shallower architecture with larger size of the striding window. However, the detail of the text is not clear. Thus, a better result is achieved by combining the outputs of two of these architectures. We tested the proposed model on benchmark DIBCO datasets for document image binarization and achieved superior performance over existing methods in the literature."
업무 자동화를 위한 RPA 융합 기술 고찰,2019,"['Artificial intelligence', 'Robotic process automation', 'Deep learning', 'Convergence', 'The fourth industrial revolution', '인공지능', '사무자동화', '딥러닝', '융합', '4차산업']","최근 4차 산업혁명 시대 흐름에 발맞추어 인공지능을 이용한 자동화 기술을 다양한 산업현장에 적용하는 사례가 증가하고 있다. 특히, 정부의 주 52시간 근무제 도입으로 기업들은 인력 운영의 어려움이 가중되고 있어, 효율적인 인력 운영을 위해 사무환경 자동화를 위한 RPA(Robotic Process Automation)에 관심을 두고 은행, 보험, 카드사 등에서 Back-Office 업무 위주로 도입하고 있다. 이러한 RPA 솔루션은 인공지능 기반 인식기술, Script 작성 기술, 업무 소프트웨어와 API(Application Process Interface) 연계 기술 등이 요구되며, Automate One, Automation Anywhere, UiPath, Blue Prism 등과 같은 다양한 솔루션들이 제공되고 있다. 본 논문에서는 기에 수작업으로 수행하던 업무를 대신 할 수 있는 RPA 솔루션의 요소 기술, 시장 동향, RPA 도입 효율성에 대해 분석하고 이를 서술하였다.","Recently, In line with the recent trend of the fourth industrial revolution, many companies and institutions have been increasingly applying automated technologies using artificial intelligence to various tasks. Particularly, due to the government's 52-hour workweek system, companies are increasingly struggling with manpower management. Therefore, they are interested in RPA (Robotic Process Automation) for office environment automation for efficient manpower management. It is being introduced in the back-office business in credit card companies, bank, insurance. These RPA solutions require AI-based recognition technology, scripting technology, business software API-related technologies, and various solutions such as Automate One, Automation Anywhere, UiPath, and Blue Prism are provided. This paper analyzes and describes the technology of RPA solution, the market trend, and the efficiency of RPA adoption."
한문고전 인공지능 번역 연구의 필요성과 선결 과제,2019,"['Literary Sinitic', 'Translation', 'Machine Translation', 'Artificial intelligence(AI)', 'Big Data', 'Deep Learning', '한문고전', '번역', '기계번역', '인공지능', '빅데이터', '딥러닝']","기계번역 기술의 발달에 힘입어 한문고전을 현대 한국어로 옮기는 전통적인 번역 과정에서 인간의 역량을 인공지능으로 대체하는 것이 가능한 일일까? 본 논문은 이 물음에 대한 해결 방안을 제시하고자 하였다. 이것은 전통적인 한국의 한문 자료를 이해하는 데 있어서 획기적인 기술의 전환을 의미할 뿐만 아니라, 현대의 정보화 시대에서 한문 연구자 및 사용자들에게 기계번역을 통한 편의성 제고는 필수불가결한 시대적 흐름이 될 것이다.본고는 한문 기계번역의 도입과 연구 과정에서, 기존 한문학 관련 연구자들의 역할을 재조명하고, 현대의 정보화 시대에서 한문 기계번역의 활용도 및 효율성 제고를 위한 한문학 연구자들의 새로운 역할을 제시하였다.한문 기계번역 시스템이 활성화되기 위해서는 두 가지 선결 과제가 수행되어야 한다. 첫째, 한문번역 수행을 위한 다양하고 효율적인 도구를 개발하여 번역 공정에 필요한 도구 구축이 선행되어야 한다. 둘째, 질적 수준과 양적 수준이 구비된 병렬코퍼스를 구축하기 위한 방안 설정과 시행이 뒷받침되어야 한다. 본고의 연구 결과를 통해 ‘한문 언어학’과 같은 학문 영역의 새로운 연구 분야를 창출함으로써, 인간의 기억과 직관 능력에 의존해왔던 기존의 문학 연구 및 번역 분야에 획기적인 변화를 촉진할 수 있으며, 이는 곧 지식의 유통과 재생산의 의미에서 학문적인 기여와 효율성을 제고하게 될 것이다.","As machine translation technology develops, translation from Literary Sinitic to modern Korean language is now possible. This enhances the users' excellence in understanding the Literary Korean-Sinitic. Machine translation, in turn, becomes essential for scholars studying Literary Korean-Sinitic in the modern information era.We propose Linguistics of Literary Sinitic' which is a novel research area facilitating the usage of Literary Korean-Sinitic in the modern information era. This can catalyze change in the classical literature research and classical translation research which depended on human memory and intuition. This study contributes to information reproduction and transfer."
Deep Learning 기반 공동주택 마감공사 단위작업별 생산성 예측모델 개발 - 내장공사를 중심으로 -,2019,"['Productivity', 'Prediction Model', 'Productivity Impacting Factors', 'Deep Learning', 'Interior Finishes', '생산성', '예측모델', '생산성 영향요인', '딥러닝', '마감공사']",,"Despite the importance and function of productivity information, in the Korean construction industry, the method of collecting and analyzing productivity data has not been organized. Also, in most cases, productivity management is reliant on the experience and intuitions of field managers, and productivity data are rarely being utilized in planning and management. Accordingly, this study intends to develop a prediction model for interior finishes of apartment using deep learning techniques, so as to provide a foundation for analyzing the productivity impacting factors and predicting productivity. The result of the study, productivity prediction model for interior finishes of apartment using deep learning techniques, can be a basic module of apartment project management system by applying deep learning to reliable productivity data and developing as data is accumulated in the future. It can also be used in project engineering processes such as estimating work, calculating work days for process planning, and calculating input labor based on productivity data from similar projects in the past. Further, when productivity diverging from predicted productivity is discovered during construction, it is expected that it will be possible to analyze the cause(s) thereof and implement prompt response and preventive measures."
Deep Learning Based Tree Recognition rate improving Method for Elementary and Middle School Learning,2019,"['Machine Learning', 'Deep Learning', 'Convolutional Neural Network', 'CNN', 'Inception V3', 'Smart Device Education', '머신러닝', '딥러닝', '컨볼루션 신경망', '인셉션V3', '스마트기기교육']","본 연구의 목적은 수업 시 스마트기기에 적용할 수 있는 나무 이미지를 인식하고 분류하여 정확도를 측정할 수 있는 효율적인 모델을 제안하는 것이다. 2015개정 교육과정으로 개정되면서 초등학교 4학년 과학교과서의 학습 목표에서 스마트 기기 사용한 식물 인식이 새롭게 추가 되었다. 특히 나무 인식의 경우 다른 사물 인식과 달리 수형, 수피, 잎, 꽃, 열매의 부위별 특징이 있으며, 계절에 따라 모양 및 색깔의 변화를 거치므로 인식률에 차이가 존재한다. 그러므로 본 연구를 통해 컨볼루션 신경망 기반의 사전 학습된 인셉션V3모델을 이용하여 재학습 전 후의 나무 부위별 인식률을 비교한다. 또한 각 나무의 유형별 이미지 정확도를 결합시키는 방식을 통해 효율적인 나무 분류 방안을 제시하며 교육현장에서 사용하는 스마트기기에 적용 할 수 있을 것이라 기대한다.","The goal of this study is to propose an efficient model for recognizing and classifying tree images to measure the accuracy that can be applied to smart devices during class. From the 2009 revised textbook to the 2015 revised textbook, the learning objective to the fourth-grade science textbook of elementary schools was added to the plant recognition utilizing smart devices. In this study, we compared the recognition rates of trees before and after retraining using a pre-trained inception V3 model, which is the support of the Google Inception V3. In terms of tree recognition, it can distinguish several features, including shapes, bark, leaves, flowers, and fruits that may lead to the recognition rate. Furthermore, if all the leaves of trees may fall during winter, it may challenge to identify the type of tree, as only the bark of the tree will remain some leaves. Therefore, the effective tree classification model is presented through the combination of the images by tree type and the method of combining the model for the accuracy of each tree type. I hope that this model will apply to smart devices used in educational settings."
가상현실 기반의 인공지능 영어회화 시스템,2019,"['Speech Recognition', 'Artificial Intelligence', 'Virtual Reality', 'Deep Learning', 'Voice Recognition Interface', '4th Industrial Revolution', '음성인식', '인공지능', '가상현실', '딥러닝', '음성인식 인터페이스', '4차산업혁명']","외국어 교육을 실현하기 위하여 기존의 다양한 교육 매체들이 제공되고 있지만, 교구 및 매체프로그램에 대한 비용이 많이 들고 실시간 대응력이 떨어지는 단점이 존재한다. 이 논문에서는 VR과 음성인식을 기반으로 한 인공지능 유형의 영어회화 시스템을 제안한다. 시스템 구축을 위해 Google CardBoard VR과 Google Speech API를 이용하며 가상현실 환경 제공 및 대화를 위한 인공지능 알고리즘을 개발하였다. 제안하는 음성인식 서버시스템에서는 사용자가 발화한 문장을 단어 단위로 분리해 데이터베이스에 저장된 데이터 단어들과 비교하여 확률적으로 가장 높은 것을 답으로 제공할 수 있으며 사용자들이 가상현실의 인물과 적절한 대화 및 응답이 가능하다. 대화가 제공되는 기능은 상황별 대화와 주제에 독립적이며, AI 비서와 나눈 대화 내용을 사용자 시스템에서 실시간 확인이 가능하도록 구현하였고 실험을 통하여 음성인식에 대한 응답비율을 확인하였다. 이 논문에서 제안하는 가상현실과 음성인식 기능을 접목한 시스템을 통하여 4차 산업혁명에 관련한 가상교육 콘텐츠 서비스 확장에 이바지할 것을 기대한다.","In order to realize foreign language education, various existing educational media have been provided, but there are disadvantages in that the cost of the parish and the media program is high and the real-time responsiveness is poor. In this paper, we propose an artificial intelligence English conversation system based on VR and speech recognition. We used Google CardBoard VR and Google Speech API to build the system and developed artificial intelligence algorithms for providing virtual reality environment and talking. In the proposed speech recognition server system, the sentences spoken by the user can be divided into word units and compared with the data words stored in the database to provide the highest probability. Users can communicate with and respond to people in virtual reality. The function provided by the conversation is independent of the contextual conversations and themes, and the conversations with the AI assistant are implemented in real time so that the user system can be checked in real time.  It is expected to contribute to the expansion of virtual education contents service related to the Fourth Industrial Revolution through the system combining the virtual reality and the voice recognition function proposed in this paper."
Combining multi-task autoencoder with Wasserstein generative adversarial networks for improving speech recognition performance,2019,"['Speech enhancement', 'Wasserstein Generative Adversarial Network (WGAN)', 'Weight initialization', 'Robust speech recognition', 'Deep Neural Network (DNN)', '음성인식', '와설스타이식 생성적 적대 신경망', '직교 구배 페널티', '초기화', '딥러닝']",,"As the presence of background noise in acoustic signal degrades the performance of speech or acoustic event recognition, it is still challenging to extract noise-robust acoustic features from noisy signal. In this paper, we propose a combined structure of Wasserstein Generative Adversarial Network (WGAN) and Multi- Task AutoEncoder (MTAE) as deep learning architecture that integrates the strength of MTAE and WGAN respectively such that it estimates not only noise but also speech features from noisy acoustic source. The proposed MTAE-WGAN structure is used to estimate speech signal and the residual noise by employing a gradient penalty and a weight initialization method for Leaky Rectified Linear Unit (LReLU) and Parametric ReLU (PReLU). The proposed MTAE-WGAN structure with the adopted gradient penalty loss function enhances the speech features and subsequently achieve substantial Phoneme Error Rate (PER) improvements over the stand-alone Deep Denoising Autoencoder (DDAE), MTAE, Redundant Convolutional Encoder-Decoder (R-CED) and Recurrent MTAE (RMTAE) models for robust speech recognition."
Word2Vec과 앙상블 합성곱 신경망을 활용한 영화추천 시스템의 정확도 개선에 관한 연구,2019,"['Text Analysis(Word2Vec)', 'Collaborative Filtering', 'Recommender Systems', 'Ensemble Model', 'Convolutional Neural Networks', 'Deep Learning', '텍스트 분석(Word2Vec)', '협업필터링', '추천시스템', '앙상블 모델', '합성곱 신경망', '딥러닝']","웹 추천기법에서 가장 많이 사용하는 방식 중의 하나는 협업필터링 기법이다. 협업필터링 관련 많은 연구에서 정확도를 개선하기 위한 방안이 제시되어 왔다. 본 연구는 Word2Vec과 앙상블 합성곱 신경망을 활용한 영화추천 방안에 대해 제안한다. 먼저 사용자, 영화, 평점 정보에서 사용자 문장과 영화 문장을 구성한다. 사용자 문장과 영화 문장을 Word2Vec에 입력으로 넣어 사용자 벡터와 영화 벡터를 구한다. 사용자 벡터는 사용자 합성곱 모델에 입력하고, 영화 벡터는 영화 합성곱 모델에 입력한다. 사용자 합성곱 모델과 영화 합성곱 모델은 완전연결 신경망 모델로 연결된다. 최종적으로 완전연결 신경망의 출력 계층은 사용자 영화 평점의 예측값을 출력한다. 실험결과 전통적인 협업필터링 기법과 유사 연구에서 제안한 Word2Vec과 심층 신경망을 사용한 기법에 비해 본 연구의 제안기법이 정확도를 개선함을 알 수 있었다.","One of the most commonly used methods of web recommendation techniques is collaborative filtering. Many studies on collaborative filtering have suggested ways to improve accuracy. This study proposes a method of movie recommendation using Word2Vec and an ensemble convolutional neural networks. First, in the user, movie, and rating information, construct the user sentences and movie sentences. It inputs user sentences and movie sentences into Word2Vec to obtain user vectors and movie vectors. User vectors are entered into user convolution model and movie vectors are input to movie convolution model. The user and the movie convolution models are linked to a fully connected neural network model. Finally, the output layer of the fully connected neural network outputs forecasts of user movie ratings. Experimentation results showed that the accuracy of the technique proposed in this study accuracy of conventional collaborative filtering techniques was improved compared to those of conventional collaborative filtering technique and the technique using Word2Vec and deep neural networks proposed in a similar study."
향상된 음향 신호 기반의 음향 이벤트 분류,2019,"['Noise Robustness', 'Sound Signal Generation', 'End-to-End Architecture', 'Deep Learning', '잡음 견고성', '음향 신호 생성', 'End-to-End 구조', '딥러닝']",,"The explosion of data due to the improvement of sensor technology and computing performance has become the basis for analyzing the situation in the industrial fields, and various attempts to detect events based on such data are increasing recently. In particular, sound signals collected from sensors are used as important information to classify events in various application fields as an advantage of efficiently collecting field information at a relatively low cost. However, the performance of sound-event classification in the field cannot be guaranteed if noise can not be removed. That is, in order to implement a system that can be practically applied, robust performance should be guaranteed even in various noise conditions. In this study, we propose a system that can classify the sound event after generating the enhanced sound signal based on the deep learning algorithm. Especially, to remove noise from the sound signal itself, the enhanced sound data against the noise is generated using SEGAN applied to the GAN with a VAE technique. Then, an end-to-end based sound-event classification system is designed to classify the sound events using the enhanced sound signal as input data of CNN structure without a data conversion process. The performance of the proposed method was verified experimentally using sound data obtained from the industrial field, and the f1 score of 99.29% (railway industry) and 97.80% (livestock industry) was confirmed."
합성곱 신경망을 위한 Elastic Multiple Parametric Exponential Linear Units,2019,"['Elastic Multiple Parametric Exponential Linear Units', 'activation function', 'convolutional neural network', 'image classification', 'deep learning', 'Elastic Multiple Parametric Exponential Linear Units', '활성화 함수', '합성곱 신경망', '이미지분류', '딥러닝']","활성화 함수는 신경망 모델의 비선형성과 깊이를 결정하는 중요한 요소이다. Rectified Linear Units (ReLU)가 제안된 이후, 평균값을 0에 가깝게 하여 학습의 속도를 높인 Exponential Linear Units (ELU)나 함수 기울기에 변화를 주어 성능을 향상시킨 Elastic Rectified Linear Units (EReLU)같은 다양한 형태의 활성화 함수가 소개되었다. 우리는 서로 다른 ELU와 EReLU를 일반화한 형태의 활성화 함수인 Elastic Multiple Parametric Exponential Linear Units (EMPELU)를 제안한다. EMPELU는 양수 영역에서는 임의의 범위로 기울기 변동을 주면서, 음수 영역은 학습 파라미터를 이용해 다양한 형태의 활성화 함수를 형성하도록 하였다. EMPELU는 합성곱 모델 기반 CIFAR-10/100의 이미지 분류에서 기존 활성화 함수에 비해 정확도 및 일반화에서 향상된 성능을 보였다.","Activation function plays a major role in determining the depth and non-linearity of neural networks. Since the introduction of Rectified Linear Units for deep neural networks, many variants have been proposed. For example, Exponential Linear Units (ELU) leads to faster learning as pushing the mean of the activations closer to zero, and Elastic Rectified Linear Units (EReLU) changes the slope randomly for better model generalization. In this paper, we propose Elastic Multiple Parametric Exponential Linear Units (EMPELU) as a generalized form of ELU and EReLU. EMPELU changes the slope for the positive part of the function argument randomly within a moderate range during training, and the negative part can be dealt with various types of activation functions by its parameter learning. EMPELU improved the accuracy and generalization performance of convolutional neural networks in the object classification task (CIFAR-10/100), more than well-known activation functions."
객체 인식에서의 속도 향상을 위한 모델 앙상블,2019,"['Object detection', 'Ensemble method', 'Convolutional neural network']",,
이미지 인식과 캡션을 위한 기계학습 모델 연구,2019,"['Machine learning model', 'Dataset', 'Chatbot', 'Image recognition', 'Image captioning']","인공지능, 로봇공학, 사물인터넷, 빅 데이터, 자율주행시스템 등은4차 산업혁명의 주요 기술군이다. 이들 기술은 대량의 비정형 데이터(이미지)나 스트리밍 데이터들을 다루게 되며, SNS 사용자들이 발생시키는 비정형 데이터들의 양도 지속적으로 증가하고 있다. 본 논문에서는 인공지능, 딥 러닝이나 비전 처리에서 많이 연구되는 이미지 데이터에 대한 기계학습 모델을 구축하고, 이미지 처리를 위한 인식 및 캡션 생성에 대한 실험을 수행하였다. 제안 모델은 챗봇(페이스북 앱), 모니터 서버와 모델 서버로 구성되며, 질의 종류는 이미지와 자연어 문장으로 구분하여 모델 서버의 ‘Captioning Model’과 ‘VQA Model’에서 각각 처리한다. 기계학습에 사용한 공개 훈련용 데이터 집합은 2017 MSCOCO이며, 캡션 생성의 성능 실험 결과 perplexity는 8.9의 우수한 결과를 확인할 수 있었다.","Artificial intelligence, Robotics, the Internet of Things, Big data and Self-driving systems are the major technological groups of the fourth industrial revolution. These technologies related to the fourth industrial revolution will deal with large amounts of formalization data(image) or streaming data. Also, the amount of image data occured by SNS users is increasing continuously. In this paper, we constructed a machine learning model for image data processing which is studied in Artificial Intelligence, Deep Learning and Vision Processing. We experimented on recognition and caption generation for image processing. The proposed model consists of three parts which have a Chatbot (Facebook app), a Monitor Server and a Model Server. The query types of Chatbot are classified into image and natural language sentences and processed in ‘Captioning Model’ and ‘VQA Model’ of model server respectively. The open training data set used on our machine learning system is 2017 MSCOCO, and the captioning performance is perplexity 8.9. We have obtained the good results from suggested machine learning system."
인공지능 학습을 이용한 스마트 안경의 문자인식,2019,"['Gaze-tracking', 'Deep-learning', 'OCR', 'Image-processing', 'Smart-glasses']",,
드론 영상 종합정보처리 및 분석용 시스템 개발,2019,"['Drone-Video Analytics', 'Deep-learning', 'License Plate Recognition', 'Object Detection', 'Object Tracking']","본 논문에서는 다양한 재난치안안전 임무 상황에서 적용할 수 있는 드론 영상 종합정보 처리 및 분석용 시스템을 제안한다. 제안하는 시스템은 드론에서 획득한 영상을 서버에 저장하고, 다양한 시나리오에 따른 영상 처리 및 분석을 수행한다. 각 임무에 따라 필요한 기능은 딥러닝을 활용하여 드론으로부터 확보하는 영상에서 영상분석 시스템을 구성한다. 실험 영상을 통해 교통량 측정, 용의자 및 차량 추적, 조난자 식별 및 해상 초계 임무에 적용할 수 있음을 확인했다. 드론 운용자가 임무에 따른 필요 기능을 선택하고 신속하게 대처할 수 있는 시스템을 구현하였다.",
라이다와 RGB-D 카메라를 이용하는교육용 실내 자율 주행 로봇 시스템,2019,"['Indoor Navigation', 'Mobile Robot', 'Robot Operating System (ROS)', 'Depth Image', 'Deep Learning']","본 논문은 라이다 센싱 정보와 RGB-D 카메라 영상 정보를 융합하여 이용하는 교육용 실내 자율주행 로봇 시스템을 구현한다. 이 시스템은 라이다 센싱 정보를 획득하기 위해 기존의 소 채널 라이다 센싱 방식을 이용한다. 또한 소 채널 라이다센싱 방식의 약점을 보완하기 위해, RGB-D 카메라 깊이 영상과 딥러닝 기반 객체인식 알고리즘을 이용하는 3차원 구조물인식 방법을 제안하고 이 시스템에 적용한다.","We implement an educational indoor autonomous mobile robot system that integrates LiDAR sensing information withRGB-D camera image information and exploits the integrated information. This system uses the existing sensing methodemploying a LiDAR with a small number of scan channels to acquire LiDAR sensing information. To remedy theweakness of the existing LiDAR sensing method, we propose the 3D structure recognition technique using depth imagesfrom a RGB-"
무역수출 라이브지수를 활용한 중소수출기업 발굴 연구,2019,"['Export KPI', 'Comprehensive Live Index', 'Small or Medium Sized Business', 'Approval of Purchase', 'Local L/C', '수출지수', '종합 라이브지수', '중소기업', '구매확인서', '내국신용장']","무역수출 분야에서 수출 지수에 관한 논의는 수차례 있었으나 객관적 지표로 설명할 수 있는 명확한 무역수출 지수는 없다. 한국무역협회(KITA), 대한무역투자진흥공사(KOTRA) 등에서 지표를 만들고자 하는 시도를 하고 있으나 수출기업의 역량을 표현할 수 있는 방법에 대하여 현재 계속 고민 중이다. 이에 본 연구는 기업의 규모, 신용도와 같은 공시지표와 거래고객수, 거래횟수, 상품개수, 거래량, 거래기간 등의 활동지표를 feature로 설정하여 인공지능 학습 데이터 셋을 구축하고, 딥러닝 알고리즘에서 Lightgbm을 이용하여 수출 가능 기업에 대한 분류 모델을 제시한다. 또한 기업이 속한 산업 군집 분류 모델로 Graph Neural Network을 사용하여 기업간, 품목간, 사업군에서의 수출 가능 역량을 표현하는 수출 Live지수를 산출하였으며 이는 지수를 산출하는 현재로부터 기업의 과거 활동을 포함함으로써 객관성을 확보하였다.",
몬테칼로 렌더링 노이즈 제거를 위한 듀얼 신경망 구조 설계,2019,"['Ray Tracing', 'Denoising', 'MonteCarlo rendering', 'Autoencoder', 'Neural Network', 'Graphics']","본 논문에서는 레이 트레이싱 그래픽에서 사용되는 몬테칼로 렌더링에 포함되는 잡음을 제거하기 위해 개선된 신경망구조 를 설계하였다. 몬테칼로 렌더링은 그래픽의 실감을 높이는데 가장 좋은 방법이지만 픽셀마다 수천 개 이상의 빛 효과를 계산해야 하기 때문에 렌더링 처리시간이 급격히 증가하여 실시간 처리에 큰 문제를 갖고 있다. 이 문제를 개선하기 위해 픽셀에서 사용되는 빛의 수를 줄이게 되는데 이때 렌더링 잡음이 발생하게 되고 이 잡음을 제거하기 위해 다양한 연구가 진행되어 왔다. 본 논문에서는 렌더링 잡음을 제거하는데 딥러닝을 사용하며 특히, 렌더링 이미지를 확산광과 집중광으로 분리하여 이중 신경망 구조를 설계하였다. 설계결과 단일구조 신경망에 비하여 듀얼구조 신경망은 PSNR기준으로 64개 테스트 이미지에 대하여 평균 0.58db가 개선되었으며 reference image에 비하여 99.22% 빛의 수를 줄여 실시간 레이 트레이싱 렌더링을 구현하였다.","In this paper, we designed a revised neural network to remove the Monte Carlo Rendering noise contained in the ray tracing graphics. The Monte Carlo Rendering is the best way to enhance the graphic""s realism, but because of the need to calculate more than thousands of light effects per pixel, rendering processing time has increased rapidly, causing a major problem with real-time processing. To improve this problem, the number of light used in pixels is reduced, where rendering noise occurs and various studies have been conducted to eliminate this noise. In this paper, a deep learning is used to remove rendering noise, especially by separating the rendering image into diffuse and specular light, so that the structure of the dual neural network is designed. As a result, the dual neural network improved by an average of 0.58 db for 64 test images based on PSNR, and 99.22% less light compared to reference image, enabling real-time race-tracing rendering"
인공지능과 고용차별의 법경제학 : 블라인드 채용과 베일의 역설을 중심으로,2019,"['고용차별', '블라인드 채용', '인공지능', '알고리즘 차별', '베일의 역설', 'employment discrimination', 'blind recruitment', 'artificial intelligence', 'algorithmic discrimination', 'paradox of the veil']","고용차별에 관해서는 반복적으로 사회적 관심과 논란이 나타난다. 전통적인 관점에서 보면, 고용차별은 사용자의 편견이나 취향으로 인해 나타나는 경우가 많은 것으로 파악된다. 이를 전제로 하여, 고용차별을 줄이기 위한 정책적인 대안으로, 고용 지원자의 정보를 부분적으로 감추거나 사용자의 재량을 제한하는 방향의 해결책이 대두되었다. 다른 한편, 정보경제학적 관점에서 보면, 고용차별은 정보의 제약 하에서 스크리닝 비용을 포함한 전체적인 채용비용을 감안할 수밖에 없는 사용자와, 지원과정에서 소요되는 정보생산 및 소통비용을 감안하게 되는 지원자의 합리적 선택이 상호작용하면서 어쩔 수 없이 나타나는 결과라는 해석도 있을 수 있다. 최근 들어, 고용 의사결정의 과정에서 인공지능 기술을 활용하게 되는 상황이 나타나고 있는데, 특히 딥러닝 인공지능 알고리즘을 활용하여 고용 판단에 도움을 받는 맥락에서는, 차별을 방지하기 위해 어떤 정보에 대한 수집을 제한하는 것이 필요한지를 더욱 면밀히 분석할 필요가 있다. 개별 상황에 따라서는, 정보의 제한이 차별 문제에 대한 적절한 해결방안이 되지 못할 가능성이 있다. 가급적 다양하고 풍부한 정보의 분석을 통해 지원자의 업무수행능력을 정확하게 파악하는 것이 노동시장의 원활한 운용을 위해 필요하기 때문이다. 다른 한편, 부작용이 우려되는 유형의 정보에 대해서는 엄정한 통제가 필요하다. 블라인드 채용은 일정 유형의 정보에 대하여 수집 자체를 차단하여 정보에 제한을 두는 방식인데, 이 방식을 통해 당초 의도한 정책적 효과의 달성이 가능할지에 대해 면밀하게 분석할 필요가 있다.",
변형 VGG 모델의 전처리를 이용한 부품도면 문자 인식 성능 개선,2019,"['광학 문자 인식', '심층 학습', '수학적 형태학 필터', 'Deep Learning', 'Mathematical morphology filtering', 'Optical character recognition']","본 논문에서는 기계 서비스 부품 도면에서 숫자를 인식하기 위하여 입력 영상에 대한 전처리와 딥러닝 모델을 제안한다. 서비스 부품 도면의 숫자를 인식하는데 있는 지시선과 도형에 의한 오검출 또는 오인식을 개선하기 위하여 수학적 형태학 필터링 전처리를 한다. 숫자 인식을 위하여 VGG-16 모델을 축소 변형한 7 개의 계층을 가지는 VGG 모델을 적용함으로써 인식 성능을 개선한다. 서비스 부품 도면의 숫자 인식 실험 결과, 제안하는 방법이 인식률 95.57%, 정확도는 92.82%로 종래의 방법에  현저히 개선된 결과를 얻었다.","This paper proposes a method of improving deep learning based numbers and characters recognition performance on parts catalogue through image preprocessing. The proposed character recognition system consists of image preprocessing and 7 layer deep learning model. Mathematical morphological filtering is used as preprocessing to remove the lines and shapes which cause false recognition of numbers and characters on parts catalogue. And the used deep learning model is a 7 layer deep learning model instead of VGG-16 model. As a result of the proposed OCR method, the recognition rate of characters is 92.57% and the precision is 92.82%."
인간과 인공지능 로봇 캐릭터의 비교 연구-너도 인간이니? 기반으로,2019,"['인공지능', '인공지능 캐릭터', '동작 추출', '에니어그램', '성격 특성', 'Artificial intelligence', 'Artificial intelligence characters', 'Motion extraction', 'Behavioral Features', 'Enneagram', 'Personality characteristics']",제4차 산업혁명이 도래하면서 인공지능 로봇은 다양한 영화 및 드라마에서 다른 캐릭터들의 역할을 수행해오고 있다. 이러한 인공지능의 등장은 과학기술의 발전과 동시에 영화나 드라마를 이끌 수 있는 하나의 중요한 소재로 사용된다. 이에 본 논문에서는 국내 드라마에서 한 인물이 인공지능 로봇 캐릭터와 인간 캐릭터를 연기한 내용을 기반으로 비교 분석하고자 한다. 특히 각 캐릭터의 외모를 기반으로 등장인물의 장면을 추출한 후 행동분석을 통해 캐릭터들의 성격과 행동 특징들을 분석한다. 이렇게 분석된 결과는 향후 다양한 캐릭터들을 체계적으로 분석하기 위한 기반 연구로 사용될 예정이다. 또한 캐릭터들의 동작들을 DB화하여 머신러닝 또는 딥러닝을 통해 효율적인 인물 행동 및 성격 분석이 가능한 시스템 구축에 활용하고자 한다.,"With the advent of the Fourth Industrial Revolution, artificial intelligence robots have been playing different characters of role in various movies and dramas. The emergence of such artificial intelligence will be used as an important material that can lead a movie or drama at the same time as the development of science and technology. In this paper, we would like to make a comparative analysis based on the story of a person playing an artificial intelligence robot character and a human character in a domestic drama. In particular, after extracting characters"" scenes based on the appearance of each character, analyze characters"" personality and behavior characteristics through behavioral analysis. The result of this analysis will be used as a base study to systematically analyze various characters in the future. Also, we want to database the actions of characters and use them as a system that enables efficient character behavior and character analysis through machine learning or deep learning."
사용자 관심사 분석에 기반한 대화형 뉴스 챗봇 시스템 개발,2019,"['News chatbot', 'Intent analysis', 'Artificial intelligence', 'Conversational interaction', 'Chatbot based on user', '뉴스 챗봇', '관심사 분석', '인공지능', '대화형 인터랙션', '사용자 기반 챗봇']","최근 들어 뉴스를 접하는 방법이 다양해짐에 따라, 스마트폰 어플리케이션 내의 플랫폼과 IT 기술을 접목시킨 콘텐츠가 증가하고 있다. 이러한 뉴스 구독 행태의 변화를 이끌어낸 기술에는 자동화와 개인화 기술을 가능하게 만든 인공지능 기술을 꼽을 수 있다. 본 연구에서는 딥러닝 기술을 활용하여, 사용자가 관심을 가지고 있는 관심사를 분석 및 예측하는 ‘뉴스의 개인화’, 사용자가 관심을 가질만한 뉴스를 자동으로 먼저 추천해주는 ‘뉴스의 자동화’를 구현하였고, 이를 모두 포함한 콘텐츠를 제공방식으로 대화형 챗봇을 선택해 사용자에게 제공한다. 기존의 뉴스 구독 방식과는 다르게, 본 시스템은 맞춤형 정보를 편하게 제공받는 새로운 사용자 경험을 만들어낼 수 있으며, 대화형 인터랙션을 통해 일방향적인 뉴스 정보 교류가 아닌, 양방향적인 뉴스 정보 교류 및 주체적 정보 취득을 가능하게 만들 것이다.","Nowadays, there are more and more ways to get to the news. Most representative of all, content that combines Smartphone application platforms with IT technologies has increased. This change in news subscription behavior was caused by artificial intelligence technologies, including ""automation"" and ""personalization."" Artificial intelligence technology makes the news information production process efficient. In this study, we implemented 'individualization of news' that analyzes and predicts interests of interest to users, and 'automation of news' that automatically recommends news of interest to users first. It is also provided to users through interactive chatbots. Unlike traditional news subscription methods, the system is comfortable with customized information. And interactive interaction creates two-way news interaction and subjective information acquisition, not one-way news information exchange."
열화상 영상 잡음 제거를 위한 효율적인 잡음 제거 블록 기반의 신경망,2019,"['image denoising', 'convolutional neural networks', 'thermal image', 'laplace noise', 'receptive field', 'residual leraning']","열화상 카메라는 제한된 열화상 해상도로 인해 잡음이 있는 영상을 야기한다. 본 논문에서는 잡음 문제를 해결하기 위해 반복 가능한 인셉션-레지듀얼 블록(IRB)으로 이루어진 새로운 딥러닝 기반의 신경망을 제안한다. 각각의 IRB는 원본 이미지에 대하여 서로 다른 수용 영역을 가진 합성곱 층 2개를 가지고 베니싱 그레디언트(vanishing gradient)를 방지하기 위한 하나의 쇼트 컷(shortcut connection)으로 구성된다. 제안된 방법은 12개의 열화상 이미지로 테스트가 이루어졌다. 실험 결과, 제안된 방법은 최신의 잡음 제거 방법인 DnCNN과 비교해 봤을 때 신호대잡음비(PSNR)를 39.57에서 40.26으로 처리속도는 1.5910초에서 0.7508초로 잡음 제거 성능 및 처리 속도 개선을 보여준다.","Thermal cameras show noisy images due to their limited thermal resolution, especially for the scenes of a low-temperature difference. In order to deal with a noise problem, this paper proposes a novel neural network architecture with repeatable denoising inception-residual blocks(DnIRB) for noise learning. Each DnIRB has two sub-blocks with difference receptive fields and one shortcut connection to prevent a vanishing gradient problem. The proposed approach is tested for 12 thermal images. The experimental results indicate that the proposed approach shows the PSNR performance is increased 39.57 to 40.26 and processing time also is reduced 1.5910 to 0.7508 compared with state-of-the-art denoising methods which is called DnCNN."
NVIDIA Jetson TX1 기반의 사람 표정 판별을 위한 YOLO 모델 FPS 향상 방법,2019,"['Deep Learning', 'Embedded system. Facial expression recognition', 'TensorRT', 'YOLO']","본 이 논문에서는 NVIDIA Jetson TX1에서 YOLO v2 모델의 정확도를 유지하면서 FPS를 개선하는 방법을 제안한다. 일반적으로, 딥러닝 모델에서는 연산량을 줄여 처리 속도를 높이기 위해 파라미터들을 실수형에서 정수형으로 변환하여 정수 연산을 통해 속도를 높이거나 네트워크의 깊이를 감소시키는 방법을 사용한다. 그러나 이 방법들은 인식 정확도가 떨어질 수 있다. 이 논문에서는 YOLO v2 모델을 이용해 표정인식기를 개발하고 정확도 유지 시키기 위해 정수 연산이나 네트워크 깊이 감소를 사용하는 대신, 다음 세 가지 방법을 통해 연산량 및 메모리 소모를 줄인다. 첫 번째, 3x3 필터를 1x1 필터로 교체하여 각 Layer 당 매개 변수 수를 9 분의 1로 줄인다. 두 번째, TensorRT의 추론 가속 기능 중 CBR (Convolution-Add Bias-Relu)을 통해 연산량을 줄이고, 마지막으로 TensorRT를 사용하여 반복되는 동일한 연산구조를 가진 레이어를 통합하여 메모리 소비를 줄인다. 시뮬레이션 결과, 기존 YOLO v2 모델에 비해 정확도는 1 % 감소했지만 FPS는 기존 3.9 FPS에서 11 FPS로 282%의 속도 향상을 보였다.","In this paper, we propose a novel method to improve FPS while maintaining the accuracy of YOLO v2 model in NVIDIA Jetson TX1. In general, in order to reduce the amount of computation, a conversion to an integer operation or  reducing the depth of a network have been used. However, the accuracy of recognition can be deteriorated. So, we use methods to reduce computation and memory consumption through adjustment of the filter size and integrated computation of the network The first method is to replace the 3x3 filter with a 1x1 filter, which reduces the number of parameters to one-ninth. The second method is to reduce the amount of computation through CBR (Convolution-Add Bias-Relu) among the inference acceleration functions of TensorRT, and the last method is to reduce memory consumption by integrating repeated layers using TensorRT. For the simulation results, although the accuracy is decreased by 1% compared to the existing YOLO v2 model, the FPS has been improved from the existing 3.9 FPS to 11 FPS."
에너지인터넷에서 1D-CNN과 양방향 LSTM을이용한 에너지 수요예측,2019,"['CNN', 'LSTM', '1D-ConvBLSTM', 'Energy prediction', 'Internet of Energy']","에너지인터넷 기술의 발전과 다양한 전자기기의 보급으로 에너지소비량이 패턴이 다양해짐에 따라 수요예측에 대한 신뢰도가 감소하고 있어 발전량 최적화 및 전력공급 안정화에 문제를 야기하고 있다. 본 연구에서는 고신뢰성을 갖는 수요예측을위해 딥러닝 기법인 Convolution neural network(CNN)과 Bidirectional Long Short-Term Memory(BLSTM)을 융합한1Dimention-Convolution and Bidirectional LSTM(1D-ConvBLSTM)을 제안하고, 제안한 기법을 활용하여 시계열 에너지소비량대한 소비패턴을 효과적으로 추출한다. 실험 결과에서는 다양한 반복학습 횟수와 feature map에 대해서 수요를 예측하고 적은 반복학습 횟수로도 테스트 데이터의 그래프 개형을 예측하는 것을 검증한다.","As the development of internet of energy (IoE) technologies and spread of various electronic devices have diversifiedpatterns of energy consumption, the reliability of demand prediction has decreased, causing problems in optimization ofpower generation and stabilization of power supply. In this study, we propose a deep learning method, 1-Dimention-Convolution and Bidirectional Long Short-Term Memory (1D-ConvBLSTM), that combines a convolution neuralnetwork (CNN) and a Bidirectional Long Short-Term Memory(BLSTM) for highly reliable demand forecasting byeffectively extracting the energy consumption pattern. In experimental results, the demand is predicted with the proposeddeep learning method for various number of learning iterations and feature maps, and it is verified that the test data ispredicted with a small number of iterations."
RANSAC을 이용한 다중 평면 피팅의 효율적인 CUDA 구현,2019,"['CUDA', 'Plane fitting', 'RANSAC', 'GP', 'CUDA', '평면 피팅', 'RANSAC', 'GPU']","외란(Outlier)이 있는 데이터를 피팅(Fitting)하는 방법으로 RANSAC(RANdom SAmple Consensus)알고리즘이 선, 원, 타원 등 의 피팅에 많이 사용되고 있다. 본 논문은 다수의 평면에 대한 3차원 포인트 데이터가 주어질 때 각 평면에 대해 RANSAC기반 평면 피팅을 최근 딥러닝 등에 많이 사용되는 GPU의 하나인 CUDA를 이용하여 효율적으로 수행하는 알고리즘을 제안한다. 모의 데이터와 실제 데이터를 이용하여 제안된 알고리즘의 성능을 CPU와 비교하여 보인다. 외란이 많고 인라이어(inlier) 비율이 낮을수록 CPU대비 속도가 향상되고 평면의 개수가 많을수록 평면당 데이터개수가 많을수록 병렬처리에 의한 속도가 가속됨을 보인다. 제안된 방법은 다중 평면 피팅외의 다른 피팅에도 쉽게 적용할 수 있다.","As a fiiting method to data with outliers, RANSAC(RANdom SAmple Consensus) based algorithm is widely used in fitting of line, circle, ellipse, etc. CUDA is currently most widely used GPU with massive parallel processing capability. This paper proposes an efficient CUDA implementation of multiple planes fitting using RANSAC with 3d points data, of which one set of 3d points is used for one plane fitting. The performance of the proposed algorithm is demonstrated compared with CPU implementation using both artificially generated data and real 3d heights data of a PCB. The speed-up of the algorithm over CPU seems to be higher in data with lower inlier ratio, more planes to fit, and more points per plane fitting. This method can be easily applied to a wide variety of other fitting applications."
자동 균열 조사기법의 정확도 평가를 위한 조사선 기반의 지표 제안,2019,"['Accuracy metric', 'Scanline Intersection Similarity (SIS)', 'Automatic rock fracture survey', 'Scanline sampling', 'Intersection Over Union (IoU)', '정확도 지표', '조사선 교차 일치도(Scanline Intersection Similarity)', '자동 암반 균열 조사', '조사선 샘플링']","신속한 암반 및 암석 균열 조사를 위해서는 자동화된 조사기법이 필요하다. 그러나 자동 조사기법의 균열 지도가 수동으로 조사한 것과 얼마나 일치하는지 표기하는 단일 지표가 없어서 그 정확도를 평가하는데 어려움이 있다. 따라서 본 연구에서는 균열 지도 간의 일치도를 단일 값으로 표현하는 조사선 교차 일치도 (Scanline Intersection Similarity, SIS)라는 지표를 새롭게 제안하였다. 제안된 지표는 두 균열 지도의 균열 빈도를 다수의 조사선 상에서 비교하여 이들 간의 기하학적 일치도를 도출한다. 해당 지표의 적용성을 검토하기 위해 컴퓨터 비전 (Computer Vision) 분야에서 널리 사용하는 일치도 지표인 Intersection Over Union (IoU)과 비교분석하였다. IoU는 균열의 미시적 형태 차이를 과대평가하는 반면에, 제안된 지표의 경우 미시적 형태 차이보다 경사와 같은 거시적 형태 차이를 더 민감하게 반영하였다. 따라서 균열의 거시적 형태가 중요한 암반 공학적 관점에서, 제안된 지표가 IoU 보다 균열 지도의 일치도 지표로써 적합하였다. 더 나아가 제안된 지표를 딥러닝(Deep Learning)을 이용한 균열 조사기법에 적용해본 결과, 해당 기법의 정확도가 조사선 교차 일치도로 0.674 임을 확인하였다.","While various automatic rock fracture survey methods have been researched, the evaluation of the accuracy of these methods raises issues due to the absence of a metric which fully expresses the similarity between automatic and manual fracture maps. Therefore, this paper proposes a geometry similarity metric which is especially designed to determine the overall similarity of fracture maps and to evaluate the accuracy of rock fracture survey methods by a single number. The proposed metric, Scanline Intersection Similarity (SIS), is derived by conducting a large number of scanline surveys upon two fracture maps using Python code. By comparing the frequency of intersections over a large number of scanlines, SIS is able to express the overall similarity between two fracture maps. The proposed metric was compared with Intersection Over Union (IoU) which is a widely used evaluation metric in computer vision. Results showed that IoU is inappropriate for evaluating the geometry similarity of fracture maps because it is overly sensitive to minor geometry differences of thin elongated objects. The proposed metric, on the other hand, reflected macro-geometry differences rather than micro-geometry differences, showing good agreement with human perception. The metric was further applied to evaluate the accuracy of a deep learning-based automatic fracture surveying method which resulted as 0.674 (SIS). However, the proposed metric is currently limited to 2D fracture maps and requires comparison with rock joint parameters such as RQD."
Self-Attention을 활용한 Siamese CNN-Bidirectional LSTM 기반 문장 유사도 예측,2019,"['자연어 처리', '유사도 측정', '샴 네트워크', '합성곱 신경망', '순환 신경망', '어텐션', 'natural language processing', 'similarity measure', 'siamese network', 'convolution neural network', 'recurrent neural network', 'attention']",본 논문에서는 입력된 두 문장의 유사도를 측정하는 딥러닝 모델을 제안한다. 기존의 문장의유사도 측정 모델에는 단어 혹은 형태소 단위로 문장을 분해하여 임베딩 하는 방식을 활용한다. 하지만 이는 사전의 크기를 증가시켜 모델의 복잡도를 높이는 문제점이 있다. 본 논문에서는 문장을 음소 단위로 분해하여 모델 복잡도를 줄이고 해당 음소를 묶어주는 다양한 필터 사이즈의 1D Convolution Neural Network와 Long Short Term Memory(LSTM)을 결합한 Siamese CNN-Bidirectional LSTM 모델을 제안한다. 본 모델을 평가하기 위해 네이버 지식인 데이터를 활용하여 기존의 문서 유사 측정에서 좋은 성능을 보이는 모델 Manhattan LSTM(MaLSTM)과 비교하였다.,"A deep learning model for semantic similarity between sentences was presented. In general, most of the models for measuring similarity word use level or morpheme level embedding.However, the attempt to apply either word use or morpheme level embedding results in higher complexity of the model due to the large size of the dictionary. To solve this problem, a Siamese CNN-Bidirectional LSTM model that utilizes phonemes instead of words or morphemes and combines long short term memory (LSTM) with 1D convolution neural networks with various window lengths that bind phonemes is proposed. For evaluation, we compared our model with Manhattan LSTM (MaLSTM) which shows good performance in measuring similarity between similar questions in the Naver Q&A dataset (similar to Kaggle Quora Question Pair)."
유도형 전력선 통신과 연동된 SSD 기반화재인식 및 알림 시스템,2019,"['single shot multibox detector(SSD)', 'faster-RCNN', 'Deeping learning', 'power line communication', 'inductive coupling unit']","인적이 드문 한적한 곳이나 산악 지역에서 화재가 발생 하였을 때 화재 상황을 정확하게 파악하고 적절한 초동 대처를 한다면 피해를 최소화할 수 있으므로 사전 화재인지시스템과 자동알림시스템이 요구된다. 본 연구에서는 객체인식을 위한 딥러닝 알고리즘 중 Faster-RCNN 및 SSD(single shot multibox detecter)을 사용한 화재 인식시스템을 전력선 통신과 연동하여 자동알림시스템을 시연하였으며 향 후 고압송전망을 이용한 산불화재 감시에 응용 가능함을 제시하였다. 학습된 모델을장착한 라즈베리파이에 파이카메라를 설치하여 화재 영상인식을 수행하였으며, 검출된 화재영상은 유도형 전력선 통신망을통하여 모니터링 PC로 전송하였다. 학습 모델별 라즈베리파이에서의 초당 프레임 율은 Faster-RCNN의 경우 0.05 fps, SSD의 경우 1.4 fps로 SSD의 처리속도가 Faster-RCNN 보다 28배 정도 빨랐다.","A pre-fire awareness and automatic notification system are required because it is possible to minimize the damageif the fire situation is precisely detected after a fire occurs in a place where people are unusual or in a mountainousarea. In this study, we developed a RaspberryPi-based fire recognition system using Faster-recurrent convolutionalneural network (F-RCNN) and single shot multibox detector (SSD) and demonstrated a fire alarm system that workswith power line communication. Image recognition was performed with a pie camera of RaspberryPi, and the detectedfire image was transmitted to a monitoring PC through an inductive power line communication network. The frame rateper second (fps) for each learning model was 0.05 fps for Faster-RCNN and 1.4 fps for SSD. SSD was 28 times fasterthan F-RCNN."
독점 멀티 분류기의 심층 학습 모델을 사용한 약지도 시맨틱 분할,2019,"['Deep learning', 'Peak response map', 'Weakly supervised semantic segmentation']","최근 딥러닝 기술의 발달과 함께 신경 네트워크는 컴퓨터 비전에서도 성공을 거두고 있다. 컨볼루션 신경망은단순한 영상 분류 작업뿐만 아니라 객체 분할 및 검출 등 난이도가 높은 작업에서도 탁월한 성능을 보였다. 그러나 그러한 많은 심층 학습 모델은 지도학습에 기초하고 있으며, 이는 이미지 라벨보다 주석 라벨이 더 많이 필요하다. 특히semantic segmentation 모델은 훈련을 위해 픽셀 수준의 주석을 필요로 하는데, 이는 매우 중요하다. 이 논문은 이러한 문제를 해결하기 위한 네트워크 훈련을 위해 영상 수준 라벨만 필요한 약지도 semantic segmentation 방법을 제안한다. 기존의 약지도학습 방법은 대상의 특정 영역만 탐지하는 데 한계가 있다. 반면에, 본 논문에서는 우리의 모델이사물의 더 다른 부분을 인식하도 multi-classifier 심층 학습 아키텍처를 사용한다. 제안된 방법은 VOC 2012 검증 데이터 세트를 사용하여 평가한다.","Recently, along with the recent development of deep learning technique, neural networks are achieving success in computer vision filed. Convolutional neural network have shown outstanding performance in not only for a simple image classification task, but also for tasks with high difficulty such as object segmentation and detection. However many such deep learning models are based on supervised-learning, which requires more annotation labels than image-level label. Especially image semantic segmentation model requires pixel-level annotations for training, which is very. To solve these problems, this paper proposes a weakly-supervised semantic segmentation method which requires only image level label to train network. Existing weakly-supervised learning methods have limitations in detecting only specific area of object. In this paper, on the other hand, we use multi-classifier deep learning architecture so that our model recognizes more different parts of objects. The proposed method is evaluated using VOC 2012 validation dataset."
"생명과 기계를 구분하는 세 가지 방식: 개념, 은유, 작동",2019,"['칸트', '라이프니츠', '데리다', '들뢰즈', '마투라나', '비비시스템', 'Kant', 'Leibniz', 'Derrida', 'Deleuze', 'Maturana', 'vivi-system']","오늘날 생명과 기계는 수렴하고 있다. 이 혼합을 이해하고 대응하기 위해서는 생명과 기계를 구분하는 세 가지 방식을 식별해야 할 것으로 보인다. 그것은 개념, 은유, 작동을 중심으로 양자를 구분하는 상이한 체제를 의미한다. 첫째, 개념을 중심으로 볼 때, 칸트와 라이프니츠 사이의 대조가 오늘날 중요한 의미를 지닌다. 칸트는 생명체의 신체 구조는 이해의 대상이지만, 그 목적성과 통일성은 인간의 이해 범위 바깥에서 존중의 대상이라는 점을 주장했다. 반면, 라이프니츠는 기계와 유기체는 모두 기술적 대상이지만, 다만 전자는 인간의 유한한 기계인 반면, 후자는 신의 무한한 기계라는 점이 다를 뿐이라고 말했다. 이 생각이 보다 현대적인 사유에 가깝다고 할 수 있다. 둘째, 은유를 중심으로 볼 때, 생명과 기계는 같은 존재자에 대해 관찰하고 서술하는 상이한 관점이다. 어떤 행동이 외적 동기를 갖는다고 말하는 인과적 서사란 사후적으로 덧붙여진 이야기와 같다. 우리는 생명이 무엇인지 알지 못하며, 생명의 본성은 수없이 많은 이야기들 후에나 밝혀지게 될 것이다. 셋째, 오늘날 새롭게 이해하는 생명은 개체 단위가 아니라 분산적이고 병렬적이고 복합적인 전지구적 시스템이다. 그리고 인류는 피드백 제어 시스템, 딥러닝, 바텀-업 로봇 제작 방식을 통해 기계의 진화 자체를 유도할 수 있게 되었다. 라이프니츠가 말한 인간적 기계는 신적 기계에 점점 더 접근하고 있는 듯 보인다. 이렇듯 개념적 구분, 은유적 서사, 공학적 작동의 세 가지 체제를 구별하여 논의하는 것이 앞으로 불필요한 혼란을 막고 생산적이고 실천적인 대안을 만드는 데 요구된다.","Life and machine converge today. Il seems that three ways should be recognized to distinguish them in order to understand and react to this crossover or alliance. These are three different regimes of thinking around concept, metaphor and operation. In the first place, with regard to the concept, a confrontation of Kantian and Leibnizian thoughts will take on precious value for our contemporary thought. According to Kant, the structure of the living body is an object of understanding, while its purpose and unity is a matter of respect beyond the reach of human intelligence. On the other hand, Leibniz affirms that the mechanism and the organism are both a technical object, but that their difference consists precisely in this: the first is a finite machine which is manufactured by the human, while the last is an infinite machine by God. We can say that this idea is closer to our contemporary thought. In the second place, if we say around the metaphor, life and machine are two different perspectives according to which we observe and describe the same beings. The causal narrative which tells that a certain action comes from an external motive is actually like a story which is added after the fact. We do not know what life is, so that its nature will have been clarified only after countless stories. Third, life as understood today cannot be measured at the individual level, but it is a global terrestrial network or system that is distributive, parallel and complex. In addition, feedback control systems, deep learning, bottom-up robots encourage us to even evolve machines. The human machines that Leibniz spoke of seem to be getting closer and closer to the divine machines. We will thus have to discriminate and discuss these three regimes, that is to say the conceptual distinction, the metaphorical narration and the technological operation, to bring down redundant and unnecessary confusions, and to create productive and practical alternatives."
STFT와 RNN을 활용한 화자 인증 모델,2019,"['Speaker verification', 'STFT', 'Deep Learning', 'Recurrent Neural Network(RNN)']","최근 시스템에 음성 인증 기능이 탑재됨에 따라 화자(Speaker)를 정확하게 인증하는 중요성이 높아지고 있다. 이에 따라 다양한 방법으로 화자를 인증하는 모델이 제시되어 왔다. 본 논문에서는 Short-time Fouriertransform(STFT)를 적용한 새로운 화자 인증 모델을 제안한다. 이 모델은 기존의 Mel-Frequency CepstrumCoefficients(MFCC) 추출 방법과 달리 윈도우 함수를 약 66.1% 오버랩하여 화자 인증 시 정확도를 높일 수 있다. 새로운 화자 인증 모델을 제안한다. 이 때, LSTM 셀을 적용한 Recurrent Neural Network(RNN)라는 딥러닝 모델을 사용하여 시변적 특징을 가지는 화자의 음성 특징을 학습하고, 정확도가 92.8%로 기존의 화자 인증 모델보다 5.5% 정확도가 높게 측정되었다.","Recently as voice authentication function is installed in the system, it is becoming more important to accuratelyauthenticate speakers. Accordingly, a model for verifying speakers in various ways has been suggested. In this paper, wepropose a new method for verifying speaker verification using a Short-time Fourier Transform(STFT). Unlike the existingMel-Frequency Cepstrum Coefficients(MFCC) extraction method, we used window function with overlap parameter of around66.1%. In this case, the speech characteristics of the speaker with the temporal characteristics are studied using a deeprunning model called RNN (Recurrent Neural Network) with LSTM cell. The accuracy of proposed model is around 92.8%and approximately 5.5% higher than that of the existing speaker certification model."
합성곱 신경망을 이용한 선박 기관실에서의 화재 검출에 관한 연구,2019,"['Fire Detection', 'Image-based', 'Ship Engine Room', 'Convolution Neural Network', 'YOLO', '화재검출', '영상기반', '선박 기관실', '합성곱 신경망', '욜로']","화재의 초기 검출은 인명과 재화의 손실을 최소화하기 위한 중요한 요소이다. 불꽃과 연기를 신속하면서 동시에 검출해야 하며 이를 위해 영상 기반의 화재 검출에 관한 연구가 다양하게 진행되고 있다. 기존의 화재 검출은 불꽃과 연기의 특징을 추출하기 위해 여러 알고리즘을 거쳐서 화재의 검출 유무를 판단하므로 연산량이 많이 소모되었으나, 딥러닝 알고리즘인 합성곱 신경망을 이용하면 별도의 과정이 생략되므로 신속하게 검출할 수 있다. 본 논문에서는 선박 기관실에서 화재 영상을 녹화한 데이터로 실험을 수행하였다. 불꽃과 연기의 특징을 외각 상자로 추출한 후 합성곱 신경망 중 하나인 욜로(YOLO)를 이용하여 학습하고 결과를 테스트하였다. 실험 결과를 검출률, 오검출률, 정확도로 평가하였으며 불꽃은 0.994, 0.011, 0.998, 연기는 0.978, 0.021, 0.978을 나타내었고, 연산시간은 0.009s를 소모됨을 확인하였다.","Early detection of fire is an important measure for minimizing the loss of life and property damage. However, fire and smoke need to be simultaneously detected. In this context, numerous studies have been conducted on image-based fire detection. Conventional fire detection methods are compute-intensive and comprise several algorithms for extracting the flame and smoke characteristics. Hence, deep learning algorithms and convolution neural networks can be alternatively employed for fire detection. In this study, recorded image data of fire in a ship engine room were analyzed. The flame and smoke characteristics were extracted from the outer box, and the YOLO (You Only Look Once) convolutional neural network algorithm was subsequently employed for learning and testing. Experimental results were evaluated with respect to three attributes, namely detection rate, error rate, and accuracy. The respective values of detection rate, error rate, and accuracy are found to be 0.994, 0.011, and 0.998 for the flame, 0.978, 0.021, and 0.978 for the smoke, and the calculation time is found to be 0.009 s."
A3C를 활용한 블록체인 기반 금융 자산 포트폴리오 관리,2019,"['Reinforcement Learning', 'Financial Portfolio Management', 'A3C', 'Cryptocurrency', 'Investment Engineering', '강화학습', '금융 포트폴리오 관리', 'A3C', '암호화폐', '투자공학']","금융투자 관리 전략 중에서 여러 금융 상품을 선택하고 조합하여 분산 투자하는 것을 포트폴리오 관리 이론이라 부른다. 최근, 블록체인 기반 금융 자산, 즉 암호화폐들이 몇몇 유명 거래소에 상장되어 거래가 되고 있으며, 암호화폐 투자자들이 암호화폐에 대한 투자 수익을 안정적으로 올리기 위하여 효율적인 포트폴리오 관리 방안이 요구되고 있다. 한편 딥러닝이 여러 분야에서 괄목할만한 성과를 보이면서 심층강화학습 알고리즘을 포트폴리오 관리에 적용하는 연구가 시작되었다. 본 논문은 기존에 발표된 심층강화학습 기반 금융 포트폴리오 투자 전략을 바탕으로 대표적인 비동기 심층 강화학습 알고리즘인 Asynchronous Advantage Actor-Critic (A3C)를 적용한 효율적인 금융 포트폴리오 투자 관리 기법을 제안한다. 또한, A3C를 포트폴리오 투자 관리에 접목시키는 과정에서 기존의 Cross-Entropy 함수를 그대로 적용할 수 없기 때문에 포트폴리오 투자 방식에 적합하게 기존의 Cross-Entropy를 변형하여 그 해법을 제시한다. 마지막으로 기존에 발표된 강화학습 기반 암호화폐 포트폴리오 투자 알고리즘과의 비교평가를 수행하여, 본 논문에서 제시하는 Deterministic Policy Gradient based A3C 모델의 성능이 우수하다는 것을 입증하였다.","In the financial investment management strategy, the distributed investment selecting and combining various financial assets is called portfolio management theory. In recent years, the blockchain based financial assets, such as cryptocurrencies, have been traded on several well-known exchanges, and an efficient portfolio management approach is required in order for investors to steadily raise their return on investment in cryptocurrencies. On the other hand, deep learning has shown remarkable results in various fields, and research on application of deep reinforcement learning algorithm to portfolio management has begun. In this paper, we propose an efficient financial portfolio investment management method based on Asynchronous Advantage Actor-Critic (A3C), which is a representative asynchronous reinforcement learning algorithm. In addition, since the conventional cross-entropy function can not be applied to portfolio management, we propose a proper method where the existing cross-entropy is modified to fit the portfolio investment method. Finally, we compare the proposed A3C model with the existing reinforcement learning based cryptography portfolio investment algorithm, and prove that the performance of the proposed A3C model is better than the existing one."
RNN 기반 디지털 센서의 Rising time과 Falling time 고장 검출 기법,2019,"['Digital sensor fault diagnosis', 'Deep learning', 'Recurrent neural networks', 'Long short term memory']","4차 산업 혁명이 진행되며 많은 회사들의 스마트 팩토리에 대한 관심이 커지고 있으며 센서의 중요성 또한 대두되고있다. 정보를 수집하기 위한 센서에서 고장이 발생하면 공장을 최적화하여 운영할 수 없기 때문에 이에 따른 손해가 발생할수 있다. 이를 위해 센서의 상태를 진단하여 센서의 고장을 진단하는 일이 필요하다. 본 논문에서는 디지털 센서의 고장유형중 Rising time과 Falling time 고장을 딥러닝 알고리즘 RNN의 LSTM을 통해 신호를 분석하여 고장을 진단하는 모델을제안한다. 제안한 방식의 실험 결과를 정확도와 ROC 곡선 그래프의 AUC(Area under the curve)를 이용하여 Rule 기반 고장진단 알고리즘과 비교하였다. 실험 결과, 제안한 시스템은 Rule 기반 고장진단 알고리즘 보다 향상되고 안정된 성능을 보였다.","As the fourth industrial revolution is emerging, many companies are increasingly interested in smart factories and the importance of sensors is being emphasized. In the case that sensors for collecting sensing data fail, the plant could not be optimized and further it could not be operated properly, which may incur a financial loss. For this purpose, it is necessary to diagnose the status of sensors to prevent sensor' fault. In the paper, we propose a scheme to diagnose digital-sensor' fault by analyzing the rising time and falling time of digital sensors through the LSTM(Long Short Term Memory) of Deep Learning RNN algorithm. Experimental results of the proposed scheme are compared with those of rule-based fault diagnosis algorithm in terms of AUC(Area Under the Curve) of accuracy and ROC(Receiver Operating Characteristic) curve. Experimental results show that the proposed system has better and more stable performance than the rule-based fault diagnosis algorithm."
비트평면 영상을 이용한 이진 CNN 연산 알고리즘,2019,"['Bit-plane', 'Binary CNN', 'Computing Power', 'Embedded System', 'Binary kernel', 'XOR']","본 논문에서는 이진영상과 이진커널을 사용하여 컨볼루션, 풀링, ReLU 연산을 수행하는 이진 CNN 연산 알고리즘을 제안한다. 256 그레이스케일 영상을 8개의 비트평면으로 분해하고, -1과 1로 구성되는 이진커널을 사용하는 방법이다. 이진영상과 이진커널의 컨볼루션 연산은 가산과 감산으로 수행한다. 논리적으로는 XNOR 연산과 비교기로 구성되는 이진연산 알고리즘이다. ReLU와 풀링 연산은 각각 XNOR와 OR 논리연산으로 수행한다. 본 논문에서 제안한 알고리즘의 유용성을 증명하기 위한 실험을 통해, CNN 연산을 이진 논리연산으로 변환하여 수행할 수 있음을 확인한다. 이진 CNN 알고리즘은 컴퓨팅 파워가 약한 시스템에서도 딥러닝을 구현할 수 있는 알고리즘으로 스마트 폰, 지능형 CCTV, IoT 시스템, 자율주행 자동차 등의 임베디드 시스템에서 다양하게 적용될 수 있는 시스템이다.","In this paper, we propose an algorithm to perform convolution, pooling, and ReLU operations in CNN using binary image and binary kernel. It decomposes 256 gray-scale images into 8 bit planes and uses a binary kernel consisting of -1 and 1. The convolution operation of binary image and binary kernel is performed by addition and subtraction. Logically, it is a binary operation algorithm using the XNOR and comparator. ReLU and pooling operations are performed by using XNOR and OR logic operations, respectively. Through the experiments to verify the usefulness of the proposed algorithm, We confirm that the CNN operation can be performed by converting it to binary logic operation. It is an algorithm that can implement deep running even in a system with weak computing power. It can be applied to a variety of embedded systems such as smart phones,  intelligent CCTV, IoT system, and autonomous car."
멀티헤드 주의집중 기법과 하이웨이 네트워크를 활용한 생물학 개체명 인식,2019,"['information retrieval', 'natural language processing', 'named entity recognition', 'multi-head attention mechanism', 'highway network', 'word embedding', '정보 추출', '자연어 처리', '개체명 인식', 'Multi-head 주의 기제 기법', 'Highway 네트워크', '단어 임베딩']","생물학 개체명 인식이란 생물학 문헌으로부터 질병, 유전자, 단백질과 같은 생물학 개체명을 추출하고 그 종류를 분류하는 작업으로, 생물학 데이터로부터 유의미한 정보를 추출하는데 중요한 역할을 한다. 본 연구에서는 입력 단어의 자질을 자동으로 추출할 수 있는 딥러닝 기반의 Bi-LSTM-CRF 모델을 활용한 개체명 인식 연구를 진행하였다. Multi-head 주의 기제 기법을 적용하여 입력 단어들 간의 관계를 포착하고 관련성이 높은 단어에 주목하여 예측의 성능을 높였다. 또한, 단어 단위 임베딩 벡터 외 문자 단위 임베딩 벡터를 결합하여 입력 임베딩의 표상을 확장하고, 각 표상의 정보 흐름을 학습하기 위해 Highway 네트워크에 적용하였다. 제안하는 모델의 성능을 평가하기 위해 두 개의 영어 생물학 데이터셋으로 비교 실험을 진행하였으며, 그 결과 기존 연구의 모델들보다 향상된 성능을 보였다. 이를 통해 제안하는 방법론이 생물학 개체명 인식 연구에서 효과적인 방법론임을 입증하였다.","Biomedical named entity recognition(BioNER) is the process of extracting biomedical entities such as diseases, genes, proteins, and chemicals from biomedical literature. BioNER is an indispensable technique for the extraction of meaningful data from biomedical domains. The proposed model employs deep learning based Bi-LSTM-CRF model which eliminates the need for hand-crafted feature engineering. Additionally, the model contains multi-head attention to capture the relevance between words, which is used when predicting the label of each input token. Also, in the input embedding layer, the model integrates character-level embedding with word-level embedding and applies the combined word embedding into the highway network to adaptively carry each embedding to the input of the Bi-LSTM model. Two English biomedical benchmark datasets were employed in the present research to evaluate the level of performance. The proposed model resulted in higher f1-score compared to other previously studied models. The results demonstrate the effectiveness of the proposed methods in biomedical named entity recognition study."
인공지능형 로봇시스템의 공공성에 관한 연구 - 클라우드 컴퓨팅과 블록체인 기술의 사회윤리적 의미를 중심으로-,2019,"['AI robotics', 'cloud computing system. block-chain', 'data', 'algorithm', 'publicity', 'protection & right of public and private interests', '인공지능형 로봇시스템', '클라우드 컴퓨팅', '블록체인', '데이터', '알고리즘', '공공성', '보호와 권리']","이 연구의 목적은 기하급수적으로 발달하고 있는 인공지능형 로봇시스템이 공적 영역에서 어떤 의미를 갖는지 탐구하는 데 있다. ‘알파고’의 등장 이후 인공지능, 딥러닝, 로봇, 네트워크, 빅데이터는 미래 인간 삶의 변화를 이끌 주요 키워드로 자리 잡았다. 과거 이러한 기술적 요인들은 별개의 영역에서 크게 주목을 받지 못했지만, 최근에는 융․복합적 결합들을 통해 전혀 예측할 수 없는 미래 변화를 주도하고 있다. 지금도 우리는 자율적인 인공지능형 로봇시스템 기반으로 생활하고 있다. 생활가전, 금융, 군사, 의료, 탐사 등 삶과 관련된 모든 분야에서 인공지능형 로봇시스템의 적용이 확대되고 있다. 하지만 이러한 로봇시스템은 각 분야에서 요구된 수요와 기술 중심으로 개발되었다는 점에서 전반적인 인간 삶에 대한 반성과는 별개로 인식되었다. 이에 따라 인공지능형 로봇시스템이 인간에 대해 갖는 존재론적 의미와 사회윤리적 의미는 크게 주목받지 못했다. 따라서 인공지능형 로봇시스템의 핵심 요소 및 인프라 기술인 데이터, 네트워크, 클라우드 컴퓨팅, 블록체인이 개인 정보 및 권리 보호, 특정 집단, 기업, 또는 국가의 이익 창출과 관련해서 갖는 공공성의 의미를 살펴보고, 이를 통해 인공지능형 로봇시스템의 일상 적용을 공공성의 측면에서 고려하고자 한다.","This paper aims to explore the meaning of the development of AI Robotics in public sections. Due to AlphaGo, an attention of one of key words of human development has been paid to various conceptions of artificial intelligence, deep-learning, robots, network and big-data. It has been expected that humans have experiences on the ground of autonomous AI robotics, even though we cannot exactly make prediction about human future. It is obviously seen, however, that human consumers have taken many AI robotics products like robot cleaner and that many governments have tried to develop AI robotics weapon like UAV(drones). That is to say, having been connected with humanity, AI robotics needs to be considered as one of parts in human lives. At the moment, the conception of data is regarded as a whole of human activities and stories in human histories. Each individual has produced each own data that is the foundation of publicity in public sections based on AI robotics. Therefore, the main focus of the social utilization of data in public section is on the technology of cloud computing system and block-chain. In that a government or company has made effort to take individual data in the name of publicity, the meaning in the sense of social ethics is related to the serious conflict between public and private interests of AI robotics in future."
인공지능 알고리즘 플랫폼 클라우드 서비스 연구,2019,"['AI algorithm', 'Platform cloud', 'Clustering analysis', 'Naive bayes', 'Collaborative filtering', '인공지능 알고리즘', '플랫폼 클라우드', '군집 분석', '나이브베이즈', '협업 필터링']","인공지능은 4차 산업혁명을 선도하는 중요 기술로 기존 ICT 산업뿐 아니라 전체 산업 분야에 적용될 수 있는 융합기술이다. 인공지능 서비스를 활용하기 위해 직접 시스템을 구축하는 것은 많은 시간과 노력을 필요로 한다. 이러한 문제점을 해결하기 위해 사용자가 웹 인터페이스를 활용하여 분석방법을 선택하고 대상 데이터를 업로드 하여 스스로 분석하고 결과를 조회할 수 있는 인공지능 클라우드 서비스를 구현하였다. 분산병렬 플랫폼 기반의 인공지능 클라우드는 대용량의 데이터를 빠르게 처리할 수있으며, 다양한 인공지능 알고리즘을 활용하여 분석할 수 있다. 본 연구에서는 군집 분석, 나이브베이즈, 협업 필터링 알고리즘을 클라우드 서비스로 구현하고, 데이터양 변화에 따른 성능을 측정하였다. 앞으로 딥러닝 등 다양한 인공지능 알고리즘을 제공하여 더욱 다양한 산업 분야에 활용할 수 있도록 연구개발을 진행할 예정이다.","An important technology leading the Fourth Industrial Revolution, Artificial Intelligence, is a convergence technology that can be applied not only to the existing ICT industry but also to the entire industrial field. Setting up a system to take advantage of AI services requires a lot of time and effort.In order to solve the above low-efficiency method, we implement the AI cloud service that analyzes the data and retrieves the results when users select analysis method and upload target data through User Interface on the web.AI cloud based on distributed parallel platform can process a large amount of data quickly and can be analyzed by using various AI algorithms. In this study, we implement a cloud service using Clustering Analysis, Naïve Bayes Classification, and Collaborative Filtering algorithms to measure the performance according to the change of data size. In the future, we will continue to develop various AI algorithms such as deep learning for use in a wider range of industries."
보건의료 빅데이터 활성화 방안에 관한 연구 -핀란드의 사례를 중심으로-,2019,"['보건의료 빅데이터', '개인정보 보호법', 'GDPR', '보건의료데이터 2차사용', '핀젠프로젝트', 'Secondary Use of Health and Social Data', 'Fingen Project', 'GDPR', 'Personal Information Protection Act', 'Health Care Big Data']","4차산업혁명 시대에 이르러 IoT 의료서비스, 유전자정보를 활용한 정밀의료, AI에 의한 질병의 치료 및 진단이 가능해지면서 각국은 세계 의료시장의 주도권을 확보하기 위하여 전략적으로 보건 의료빅데이터 구축에 앞장서고 있다. 이러한 세계적 흐름에 동참하기 위하여 최근 우리 보건복지부 역시 건강보험공단·심사평가원·질병관리본부·국립암센터로 산재 되어있는 의료데이터를 연계하는 보건의료 빅데이터 활용 플랫폼 시범사업을 시작하였다. 그러나 아직 갈 길은 멀기만 하다. 보건의료 빅데이터의 활용 범위, 방법, 절차, 정보보호 조치 등에 관하여 규정하는 구체적인 법적 근거가 부재 한데다가 규제 완화라는 시대적 흐름에 역행하는 각종 과잉규제가 보건의료 빅데이터의 활용을 어렵거나 불가능하게 하고 있기 때문이다. 또한, 야심차게 시작한 보건의료 빅데이터 활용 플랫폼 시범사업 역시 연구자로 하여금 연구에 필요한 최소 수준의 데이터를 요구할 수 있도록 하고 과도하다고 판단되는 경우 데이터의 제공 자체를 반려하도록 함으로써 데이터 의존도가 높은 AI 딥러닝 알고리즘의 개발에 기여하지 못하는 반쪽자리 빅데이터에 머물고 있다. 데이터 제공 목적 역시 “정책연구, 정보보호기술, 보건의료기술연구, 건강 관련 학술연구” 등으로만 제한되어 있는데 사실상 민간이나 산업적 차원의 보건의료 빅데이터 활용 가능성 자체가 원천적으로 봉쇄됨으로써 빅데이터 활용을 통하여 헬스케어 분야의 혁신을 이루고 있는 선진국과 우리나라 간의 격차는 점점 벌어지고 있는 상황이다. 본 논문은 보건의료 빅데이터를 둘러싼 법적 사회적 쟁점을 살펴보고, 보건의료 빅데이터 활용의 선두주자인 핀란드의 개인보호 법제, 건강 및 사회적 정보의 2차 사용에 관한 법률, 핀젠 프로젝트의 사례를 중심으로 검토, 개선방안을 도출함으로써 향후 우리나라의 보건의료 빅데이터 활성화 방안에 관하여 제언하고자 한다.","In the era of the Fourth Industrial Revolution, it is possible to treat and diagnose diseases by IoT medical services, precise medical care using genetic information, and AI. In order to lead the initiative of the global medical market, Countries are striving to build health and medical big data. Recently, the Ministry of Health and Welfare has also started a pilot project for the use of healthcare big data, which links medical data scattered in the Health Insurance Corporation, Review and Assessment Service, Disease Control Headquarters and National Cancer Center. However, there is still a long way to go. This is because there is no specific legal basis for defining the scope, method, procedure, and information protection measures of health care big data. Also, various over regulations that are contrary to the trend of deregulation make it difficult or impossible to use health care big data. In addition, the health care big data platform pilot project does not provide meaningful information for the formation of AI deep learning algorithms by allowing researchers only extremely limited information. The gap between advanced countries and Korea, which are innovating, is widening. This study examines the current state of health care big data use in Korea and its legal and social issues, and suggests the direction for us to move forward for the activation of health care big data by examining the case of Finnish private protection legislation, the second use of health and social information, and the Finzen project."
언어학과 기계 번역-한문학 텍스트의 기계 번역과 관련하여,2019,"['Artificial Intelligence', 'Translation of Korean Literature Text in Classical Chinese', 'Rule Based Machine Translation', 'Neural Machine Translation', 'Translation Memory', '인공 지능', '한문학 번역', '규칙 기반 기계 번역', '신경망 기계 번역', '번역 메모리']","본 연구는 언어학과 관련하여 기계 번역의 역사를 살펴보고, 규칙 기반 기계 번역과 자료 기반 기계 번역의 알고리듬을 간략히 소개한다. 또한 이를 통해 한문학 텍스트의 기계 번역에 대한 제안과 전망을 하는 것이 본 연구의 목적이다. 기계 번역은 컴퓨터를 이용하여 하나의 언어를 다른 언어로 자동으로 변환하는 기술인데, 최근 인공 지능(AI)과 전산언어학 분야에서 활발히 연구되고 있다. 기계 번역은 Weaver(1949)에서 출발하였으며, 1980년대 초까지 언어학의 영향으로 어휘, 문법, 의미 생성에 필요한 많은 규칙을 적용한 시스템인 규칙 기반 기계 번역이 발전하였다. 1980년대 이후에는 컴퓨터의 발달과 대규모 코퍼스(corpus)의 구축이 가능해지면서 코퍼스를 기계 번역에 이용하려는 시도들이 나타났는데, 코퍼스를 기반으로 하는 자료 기반 기계 번역이 발전하였다. 최근에는 딥러닝(deep learning)을 통한 기계 번역의 인기가 매우 높아지고 있다. 그 중 주목받고 있는 기술은 ‘신경망 기계 번역(Neural Machine Translation)’이다. 그런데 한문학 텍스트는 어휘와 문법에 대한 정확한 정의와 분류가 합의된 상황도 아닐 뿐만 아니라 이를 규칙화한 시스템도 구축하지 못한 상황이기 때문에 규칙 기반 기계 번역을 활용하기 어렵다. 한편 충분한 병렬 코퍼스도 부족하기 때문에 통계적 기계 번역이나 신경망 기계 번역을 활용하기도 어렵다. 따라서 현재 한문학 텍스트의 기계 번역에서 가장 합리적인 방법은 번역 메모리를 활용하는 방법이다. 이를 통해 현재 한문학 텍스트의 번역에 대한 시간과 비용을 최소화 할 수 있고, 향후 신경망 기계 번역에서 필요로 하는 대용량의 병렬 코퍼스를 생성해 낼 수 있을 것이다.","This study examines the history of machine translation in relation to linguistics and briefly introduces algorithms for rule based machine translation and data based machine translation. And the purpose of this study is to propose and prospect a machine translation of Korean texts in classical Chinese. Machine translation is a technology that automatically transforms a language into another language. Recently, it has been actively researched in artificial intelligence(AI) and computational linguistics. Machine translation started with Weaver(1949), and until the early 1980’s, rule based machine translation developed which is a system that applied many rules for vocabulary, grammar, and meaning. Since the 1980’s, the attempts using corpus for machine translation come up with computer development and large corpus construction, then data base machine translation has developed. In recent years, the machine translations with AI has become very popular. One of them is ‘Neural Machine Translation’. However, it is difficult to use rule based machine translation because it is not the agreed-on situation about vocabulary and grammar on Korean literature text in classical Chinese. Also, since there are not enough parallel corpora, it is difficult to use statistical machine translation or neural machine translation. Therefore, the most reasonable method of machine translation on Korean literature text in classical Chinese is to use ‘translation memory’. It is possible to minimize the time and cost for translating the current Korean literature text in classical Chinese, and to generate a large amount of parallel corpus which is required in neural network machine translation in the future."
기술평가를 위한평가 참조정보 생성 방안에 관한 연구 : 기술적 속성 유사성 관점에서,2019,"['Technology evaluation', 'Reference information', 'Peer group', 'Quantification of technological features', 'Similarity in technological contents', '기술평가', '평가 참조정보', 'Peer group', '기술적 속성 정량화', '기술내용 유사도']","기술금융은 기업의 기술혁신 및 사업화 역량에 대한 평가를 바탕으로 적정 수준의 자금을 공급하는 것을 의미하며, 기술평가는 이를 실현하기 위한기반으로서 인식된다. 기술평가는 계량화된 데이터에 의한 정량적 평가와해당 분야의 전문가에 의한 정성적 평가의 혼합으로 이루어지며, 계량화된모형은 정성적 평가를 지원하는 역할을 수행하기 때문에 정성적 평가 결과가 최종 기술평가 결과에 직접적으로 영향을 미치는 경향이 강하다. 하지만정성적 평가는 평가자의 개별적 역량 및 성향 차이에 따라 일관적이지 못한결과를 도출할 수 있기 때문에, 다양한 기술평가 관련 기관들은 평가 대상기업과 속성이 유사한 기업들을 peer group으로 정의하고 이들의 평가 관련정보를 평가 참조정보로서 제공하고 있다. 하지만 기존의 방안들은 주로 산업분류 또는 기술분류 간 유사성만을 고려할 뿐, 기술 자체의 속성을 고려하지 못한다는 한계를 지닌다. 이에 본 연구는 딥러닝에서 사용되는 텍스트 문서의 벡터 정보 모델링기법인 doc2vec 모델을 사용하여 기술내용 간 유사도수준을 측정하여 평가 대상기업과 기술적 속성 관점에서 유사성을 지닌 기업들을 발굴하고 이들로부터 평가 참조정보를 생성하기 위한 방법론을 제시한다. 또한 본 방법론에 의해 산출된 결과와 기존의 peer group 정의 방안에의해 산출된 결과를 비교하고, 본 방법론의 타당성에 대한 논의를 수행한다. 본 방법론은 실용적 평가 참조정보를 정량적 방안에 따라 제공함으로써 정성적 기술평가 작업의 효율성을 향상시키는 데 기여할 수 있다. 또한 평가자의 개인적 역량 및 성향에 따른 기술평가 결과의 편차를 줄여 줌으로써 기술평가 작업의 신뢰성도 증진시킬 수 있을 것으로 기대된다.","Technology evaluation is generally recognized as a basis for realizing technology finance which refers to providing financial support based on the evaluation of technology innovation and commercialization capability of firms. It is naturally performed in a combination of quantitative evaluation by quantified data and qualitative evaluation by experts in relevant field. Among the both, the results from qualitative evaluation tend to directly affect the ultimate evaluation results. To facilitate the qualitative work, various institutes related to technology evaluation have tried to identify several firms that are similar to the target firm and generate reference information for the evaluation of target firm’s technology. However, the existing approaches have limitations in that they cannot reflect the features of technology itself, only considering the similarity in terms of the industrial or technological classification. This study proposes a methodology for identifying similar firms to the target firm in terms of technological features by measuring the similarity their technological contents and generating reference information from the information of the similar firms. To measure the similarity between technological context, we apply a doc2vec method which is one of the most representative deep-learning based models to represent textual document information to vector. This study can contribute to improving the efficiency and reliability of qualitative technology evaluation work by providing practical reference information in a quantitative way."
휠체어 탄 인공지능: 자율적 기술에서 상호의존과 돌봄의 기술로,2019,"['Artificial Intelligence', 'Cultural imaginary', 'Matter of care', 'Autonomy', 'mediation and dependence', 'Care work', 'Disability', 'Artificial Intelligence in wheelchair', '인공지능', '문화적 상상', '돌봄물', '자율성', '매개와 의존', '돌봄노동', '장애', '휠체어 탄 인공지능']","이 글은 인공지능이 만들어내는 문화적 상상을 분석하면서 기술과 인간 사이의 새로운윤리를 모색한다. 과학기술을 돌봄물(matter of care)로 이해하는 페미니스트 과학기술학연구(Puig de la Bellacas, 2011)에 기댄 이 글은 우선 인공지능이 자율성을 문화적 상상으로강력하게 생산하고 있다는 점에 주목한다. 스스로의 경험과 학습을 통해 새로운 환경에적응할 수 있는 능력으로 정의된 이 자율성은 기술적 영역을 넘어 이상적인 인간상을 정의하고 있다. 하지만 데이터에 기반한 딥러닝 기법과 무장한 무인 비행기가 예증하듯, 인공지능 기술은 보이지 않는 인간노동과 복잡한 물질적 장치에 의존하고 있으며, 자율성은허구에 가깝다. 또한 이른바 ‘조수 기술 (assistant technology)’이 보여주듯, 가사노동을부불노동화하는 우리 사회의 오래된 젠더화된 노동인식에 기초해 수많은 인간의 돌봄노동은 비가시화되는 반면, 기계의 돌봄노동은 적극적으로 가시화되고 있다. 또한 인공지능의문화적 상상은 자율성과 행위능력을 이상적인 인간의 특질로 정의하면서 장애의 몸과 이몸이 갖는 가치인 연약함과 의존성의 연대는 가치 없는 것으로 만들고 있다. 인공지능과그 문화적 상상은 능력이 있는 몸(abled-bodies)을 이상화하고 기술의 자율성을 우선 가치로삼으면서 서로 의존하는 인간과 기술의 현실적 관계를 삭제하고 있다. 결론에서 저자는우리에게 필요한 기술은 타자의 비정형적인 몸과 인간의 돌봄노동을 가치 없게 여기도록하는 것이 아니라 이들을 있는 그대로 드러내면서 그 가치를 인정하는 것이어야 한다고주장한다. 책임 있게 응답하는 기술은 주변화된 존재들에 공감하고 의존성을 긍정하고연약성 사이의 연대를 촉진하는 것이어야 한다. 저자는 이런 대안적인 기술을 형상화하기위해 예술가 수 오스틴의 퍼포먼스에서 영감을 얻어 ‘휠체어 탄 인공지능’을 제안한다. ‘휠체어 탄 인공지능’은 자율성을 과시하기보다는 타자의 몸과 노동을 부정하지 않고 이들의존재론적 가능성을 함께 만들어가려 노력하는 상호의존과 돌봄의 기술이다.","This article seeks to explore new relationships and ethics of human and technology by analyzing a cultural imaginary produced by artificial intelligence. Drawing on theoretical reflections of the Feminist Scientific and Technological Studies which understand science and technology as the matter of care(Puig de la Bellacas, 2011), this paper focuses on the fact that artificial intelligence and robots materialize cultural imaginary such as autonomy. This autonomy, defined as the capacity to adapt to a new environment through self-learning, is accepted as a way to conceptualize an authentic human or an ideal subject. However, this article argues that artificial intelligence is mediated by and dependent on invisible human labor and complex material devices, suggesting that such autonomy is close to fiction. The recent growth of the so-called 'assistant technology' shows that it is differentially visualizing the care work of both machines and humans.Technology and its cultural imaginary hide the care work of human workers and actively visualize the one of the machine. And they make autonomy and agency ideal humanness, leaving disabled bodies and dependency as unworthy. Artificial intelligence and its cultural imaginary negate the value of disabled bodies while idealizing abled-bodies, and result in eliminating the real relationship between man and technology as mutually dependent beings. In conclusion, the author argues that the technology we need is not the one to exclude the non-typical bodies and care work of others, but the one to include them as they are. This technology responsibly empathizes marginalized beings and encourages solidarity between fragile beings. Inspired by an art performance of artist Sue Austin, the author finally comes up with and suggests 'artificial intelligence in wheelchair' as an alternative figuration for the currently dominant 'autonomous artificial intelligence'."
기술융합형 만화의 시장 진입 현황과 지능형 웹툰의 출구전략 연구,2019,"['기술융합형 웹툰', '지능형 웹툰', '만화', '웹툰', 'technology', 'WebtoonCartoon', 'A.I. webtoon', 'comics', 'webtoons']","웹툰산업이 만화시장의 대표로 대두되면서, 플랫폼과 유료독자층의 확장 등 폭발적인 성장추세로 평가받던변인들이 이제는 안정화단계 및 박스권의 정체단계로 분석되는, 대안이 필요한 시점이 되었다. 특히, 성장의 모멘텀을 추가로 개발하고, 콘텐츠시장 전체에 1차 원작시장으로서의 잠재적 가치를 평가받는 기업공개시점이다가오고 있다. 이러한 상황에서 대안으로 모색되고 개발되는 형태가 기술융합형 만화이며, 보다 점진적인 진화과정을 거치고 있는 지능형 웹툰으로의 딥러닝이 다양한 모듈과 시뮬레이션으로 현실화되고 있다. 본 논문은 이러한현실적 문제의식을 토대로 ‘웹툰산업의 대안으로 제시되는 기술융합형 웹툰개발의 구조적 변인은 어떠한 모형을기반으로 해야 하는가’라는 연구문제1과 ‘차세대 웹툰산업의 주된 모형으로 작동되어야 할 인공지능기반 지능형웹툰의 기반네트워크는 어떠한 산학연 모델로 구축되어야 하는가’라는 연구문제2를 제시한다. 포털사이트의 규모의 경제와 충성도 높은 네트워크 독자들을 전제로 국내외 성장세를 거듭하고 있던 대형 웹툰플랫폼의 다양한 비즈니스모델은 불법복제사이트의 무차별 공격과 장르편향성이라는 네트워크 외부효과에 적극적으로 대처하기 위해창의적인 대안을 모색 중이다. 그러한 대안의 비상구로 제시되고 진행되는 것이 기술융합형 웹툰이다. 특히, 하일권 작가의 <마주쳤다>로 대변되는 증강현실 웹툰의 실험과 성공은 가성비 높은 기술융합형 웹툰의 기술투자 및모바일 디바이스의 특성을 맞춤형 메커니즘으로 공식화되고 있다. 실제 소프트웨어를 활용한 무빙툰, 효과툰, 음향툰으로 대표되던 초기기술 적용수준의 기술융합형 웹툰은 이제 인공지능 엔진기반 지능형 웹툰으로 진화하고있으며, 그러한 진화의 모델은 생산자, 소비자, 플랫폼, 에이전시, 큐레이션 등 생태계 전반의 모듈에서 각기 다른형태와 연계되며 병행확장되고 있다. 실제 이러한 형태의 진화메커니즘은 ‘빅데이터 네트워크’라는 선제적 기반을필요로 하는데, 엔진과 기술개발속도에 네트워크 기반의 형성속도가 반응하지 못하고 있다는 문제의식이 본 연구의 성과이며, 지능형 웹툰의 출구전략을 제시하는 주제가 된다. 결국, 지능형 웹툰의 진화는 웹툰제작현장의 작가그룹과 전문교육기관의 예비작가그룹이 진행하고 있는 창작과정을 실시간으로 네트워크시키고, 그러한 빅데이터를 산학연 모델로 공식화시키는 시도가 필요하다.","s the webtoon industry emerged as the representative of the comics market, it was time for the alternatives, which were evaluated as explosive growth trends such as expansion of platform and paid readership, to be stabilized and stagnated at the box level. In particular, the company’s public launching point, which develops additional momentum for growth and evaluates its potential value as a primary source market throughout the content market, is approaching.In this situation, the form that is sought and developed as an alternative is a technology convergence cartoon, and deep learning into an intelligent webtoon that is undergoing a more gradual evolution is being realized with various modules and simulations. This paper is based on this realistic problem consciousness, ‘What model should the structural variables of the technology convergence webtoon development presented as an alternative to the webtoon industry be based on?’ as study topic 1 and ‘for the main model of the next generation webtoon industry, what kind of industry-university model should the basic network of artificial intelligence-based intelligent webtoons be presented?’ as study topic 2.The diverse business model of the large webtoon platform, which has been growing at home and abroad under the premise of economies of scale and loyal network readers, has creative alternatives to actively cope with network externalities such as brutal attack of copyf and genre bias.It is a technology convergence webtoon that is presented and proceeded as an emergency exit of such an alternative. In particular, the experiments and success of augmented reality webtoons, which are represented by Ha Il-kwon’s <Meeting>, are formulated with customized mechanisms for the technology investment and the characteristics of mobile devices.The technology convergence webtoon of the initial technology application level represented by moving tones, effect tones, and sound tones using real software is now evolving into AI engine-based intelligent webtoons. It is linked to different forms in modules and expanded throughout the ecosystem, such as and curation, agency, platfrom and consumers.Indeed, this type of evolutionary mechanism requires a preemptive basis of ‘big data network’. The result of this study is that the speed of network-based formation is not responding to the speed of engine and technology development. It is a subject that suggests a strategy. After all, the evolution of intelligent webtoons requires real-time networking of the creative process of the author group of the webtoon production site and the preliminary group of professional educational institutions, and the attempt to formulate such big data into an industry-academia model."
IoT 스마트 디바이스의 서비스 사용성 연구,2019,"['Internet of Thing(IoT:사물인터넷)', 'Smart Device(스마트 디바이스)', 'Service Usability(서비스 사용성)']","사물 인터넷(IoT, Internet of Things)은 빅 데이터, 인공지능, 클라우드, 엣지 클라우드 등의 최신 기술과의 접목으로 스마트 팩토리, 스마트 시티 등과 같은미래 IT 사회를 구현할 핵심 기술로 자리 잡았다. 이러한 상황을 반영하여 최근 IoT 시스템 분야 많은 연구들에서 IoT 오픈 플랫폼을 구축하고 있다.본 연구는 스마트 디바이스를 유형별로 나누고 사용성 측면에서 비교분석 하였으며 제이콥닐슨(Jakob Nielsen)의 10가지 평가 항목에 대표적인 IoT 스마트디바이스를 대입하여 3가지 이상 교집합 된 정확성, 효율성, 직관성, 접근성 4가지 주요항목을 도출하였다.이에 주요 항목으로 도출된 4가지의 요소의 부족한부분을 분석한 결과 향후 본 연구 분석결과를 참고하여 스마트 디바이스의 사용성(정확성, 효율성, 직관성, 접근성)을 최적화되고 편리하게 일상생활에서 질 높은 개인 맞춤형 스마트 서비스를 제공하는 수단으로활용되어 향후 본 연구 분석결과를 참고하여 음성인식 AI(인공지능) 인터페이스로 융합된 IoT 디바이스인터페이스의 개발에 있어서 IoT시대의 미래와 개인맞춤형 스마트 디바이스 서비스의 보다 나은 발전에활용방안을 제안하고자 목적이 있다. 단순한 텍스트입력방식이나 터치를 이용한 방법에서 벗어나 미래의인터페이스로 주목될 음성인식 AI(인공지능)와 다른인터페이스와의 융⋅복합적 서비스의 향후 방향과 가능성 및 시사점을 연구하였다. 인터페이스의 다각적인개발방안으로 첫째, 스마트 디바이스의 성장에 가장중요 요인은 사용자가 스마트 디바이스를 직관적으로사용할 수 있도록 하는 접근성이 필요하다.둘째, 단순히 제품(스마트 디바이스)을 더 많이 판매하기 위한 수단이나 경쟁으로 이해하기보다는 향후복잡하고 번거로운 단계를 거치는 텍스트 입력방식이나 시간을 지체하고 불편함을 주는 터치 및 제스처를 대체할 효과적인 인식성 높은 음성인식 인터페이스의다각적인 개발방안을 마련해야 한다. 마지막으로 음성인식 인공지능(AI)가 탑재된 스마트 스피커는 집안의IT허브로서 각종 음성인식 딥러닝 응용 서비스들이IT와 결합하여 활발히 개발되고 향후 기술이 발전하고 보편화 된다면 매우 편리하고 유용한 서비스의 가치가 높다고 할 것이다.본 연구는 음성인식 AI(인공지능) 인터페이스로 융합된 IoT 디바이스 인터페이스의 개발에 있어서 IoT 시대의 미래와 스마트 디바이스 서비스의 보다 나은발전에 활용될 것을 기대한다.","Internet of Things have been established as a core technology to realize future IT society like smart factory in relation to state-of-art technology such as big data, artificial intelligence, cloud, and edge cloud.Reflecting these situations, many researchers in a IoT system field are trying to build up open Iot platform.This study divided smart devices which are similar to users’ needs into different type and category and analyzed the type by using 10 principles of serviceability assessment of Jacob Nielsen. Utilizing past studies and evaluation analysis, main items such as accuracy, recognition, efficiency, intuition, accessibility have been drawn. By putting this main 5 items into analysis result, usability of IoT smart devices has been analyzed.This study suggests characteristics and guideline for smart service by analyzing practicability and interpreting the efficiency.First, the most important factor for smart device to grow is accessibility that users can use smart device intuitively.Second, multi-directional development plan for effective voice recognition interface should be provided which could substitute touch method which is inconvenient and time-consuming and text entry method which is complicated and annoying. Finally, many people will value smart speaker with voice recognition AI high as a IT herb in a home, if various voice-recognition deep learning application services are developed and generalized in relation to IT technology.Consequently, this research will shed light on the smart service with voice recognition IT interface, when it comes to developing IoT smart device interface, as a strategic guideline which is helpful for the future of IoT age and development of smart service."
문장 분류를 위한 정보 이득 및 유사도에 따른 단어 제거와 선택적 단어 임베딩 방안,2019,"['문장 분류', '특징 선택', '정보 이득', '단어 유사도', '단어 임베딩', 'Sentence Classification', 'Feature Selection', 'Information Gain', 'Word Similarity', 'Word Embedding']","텍스트 데이터가 특정 범주에 속하는지 판별하는 문장 분류에서, 문장의 특징을 어떻게 표현하고 어떤 특징을 선택할 것인가는 분류기의 성능에 많은 영향을 미친다. 특징 선택의 목적은 차원을 축소하여도 데이터를 잘설명할 수 있는 방안을 찾아내는 것이다. 다양한 방법이 제시되어 왔으며 Fisher Score나 정보 이득(Information Gain) 알고리즘 등을 통해 특징을 선택 하거나 문맥의 의미와 통사론적 정보를 가지는 Word2Vec 모델로 학습된 단어들을 벡터로 표현하여 차원을 축소하는 방안이 활발하게 연구되었다. 사전에 정의된 단어의 긍정 및 부정 점수에 따라 단어의 임베딩을 수정하는 방법 또한 시도하였다.본 연구는 문장 분류 문제에 대해 선택적 단어 제거를 수행하고 임베딩을 적용하여 문장 분류 정확도를 향상시키는 방안을 제안한다. 텍스트 데이터에서 정보 이득 값이 낮은 단어들을 제거하고 단어 임베딩을 적용하는방식과, 정보이득 값이 낮은 단어와 코사인 유사도가 높은 주변 단어를 추가로 선택하여 텍스트 데이터에서 제거하고 단어 임베딩을 재구성하는 방식이다.본 연구에서 제안하는 방안을 수행함에 있어 데이터는 Amazon.com의 ‘Kindle’ 제품에 대한 고객리뷰, IMDB 의 영화리뷰, Yelp의 사용자 리뷰를 사용하였다. Amazon.com의 리뷰 데이터는 유용한 득표수가 5개 이상을 만족하고, 전체 득표 중 유용한 득표의 비율이 70% 이상인 리뷰에 대해 유용한 리뷰라고 판단하였다. Yelp의 경우는 유용한 득표수가 5개 이상인 리뷰 약 75만개 중 10만개를 무작위 추출하였다. 학습에 사용한 딥러닝 모델은 CNN, Attention-Based Bidirectional LSTM을 사용하였고, 단어 임베딩은 Word2Vec과 GloVe를 사용하였다.단어 제거를 수행하지 않고 Word2Vec 및 GloVe 임베딩을 적용한 경우와 본 연구에서 제안하는 선택적으로 단어 제거를 수행하고 Word2Vec 임베딩을 적용한 경우를 비교하여 통계적 유의성을 검정하였다.","Dimensionality reduction is one of the methods to handle big data in text mining. For dimensionality reduction, we should consider the density of data, which has a significant influence on the performance of sentence classification. It requires lots of computations for data of higher dimensions. Eventually, it can cause lots of computational cost and overfitting in the model. Thus, the dimension reduction process is necessary to improve the performance of the model. Diverse methods have been proposed from only lessening the noise of data like misspelling or informal text to including semantic and syntactic information.On top of it, the expression and selection of the text features have impacts on the performance of the classifier for sentence classification, which is one of the fields of Natural Language Processing. The common goal of dimension reduction is to find latent space that is representative of raw data from observation space. Existing methods utilize various algorithms for dimensionality reduction, such as feature extraction and feature selection. In addition to these algorithms, word embeddings, learning low-dimensional vector space representations of words, that can capture semantic and syntactic information from data are also utilized. For improving performance, recent studies have suggested methods that the word dictionary is modified according to the positive and negative score of pre-defined words.The basic idea of this study is that similar words have similar vector representations. Once the feature selection algorithm selects the words that are not important, we thought the words that are similar to the selected words also have no impacts on sentence classification. This study proposes two ways to achieve more accurate classification that conduct selective word elimination under specific regulations and construct word embedding based on Word2Vec embedding. To select words having low importance from the text, we use information gain algorithm to measure the importance and cosine similarity to search for similar words. First, we eliminate words that have comparatively low information gain values from the raw text and form word embedding. Second, we select words additionally that are similar to the words that have a low level of information gain values and make word embedding. In the end, these filtered text and word embedding apply to the deep learning models; Convolutional Neural Network and Attention-Based Bidirectional LSTM.This study uses customer reviews on Kindle in Amazon.com, IMDB, and Yelp as datasets, and classify each data using the deep learning models. The reviews got more than five helpful votes, and the ratio of helpful votes was over 70% classified as helpful reviews. Also, Yelp only shows the number of helpful votes. We extracted 100,000 reviews which got more than five helpful votes using a random sampling method among 750,000 reviews. The minimal preprocessing was executed to each dataset, such as removing numbers and special characters from text data. To evaluate the proposed methods, we compared the performances of Word2Vec and GloVe word embeddings, which used all the words.We showed that one of the proposed methods is better than the embeddings with all the words. By removing unimportant words, we can get better performance. However, if we removed too many words, it showed that the performance was lowered. For future research, it is required to consider diverse ways of preprocessing and the in-depth analysis for the co-occurrence of words to measure similarity values among words. Also, we only applied the proposed method with Word2Vec. Other embedding methods such as GloVe, fastText, ELMo can be applied with the proposed methods, and it is possible to identify the possible combinations between word embedding methods and elimination methods."
멀티 뷰 기법 리뷰: 이해와 응용,2019,"['멀티 뷰 학습', '딥 러닝', '기계학습', '데이터 통합', 'multi-view learning', 'multi-modal learning', 'deep learning', 'machine learning', 'data integration']","멀티 뷰 기법은 데이터를 다양한 관점에서 보려는 접근 방법이며 데이터의 다양한 정보를 통합하여 사용하려는 시도이다. 최근 많은 연구가 진행되고 있는 멀티 뷰 기법에서는 단일 뷰 만을 이용하여 모형을 학습시켰을 때 보다 좋은 성과를 보인 경우가 많았다. 멀티 뷰 기법에서 딥 러닝 기법의 도입으로 이미지, 텍스트, 음성, 영상 등 다양한 분야에서 좋은 성과를 보였다. 본 연구에서는 멀티 뷰 기법이 인간 행동 인식, 의학, 정보 검색, 표정 인식 분야에서 직면한 여러 가지 문제들을 어떻게 해결하고 있는지 소개하였다. 또한 전통적인 멀티 뷰 기법들을 데이터 차원, 분류기 차원, 표현 간의 통합으로 분류하여 멀티 뷰 기법의 데이터 통합 원리를 리뷰 하였다. 마지막으로 딥 러닝 기법 중 가장 범용적으로 사용되고 있는 CNN, RNN, RBM, Autoencoder, GAN 등이 멀티 뷰 기법에 어떻게 응용되고 있는지를 살펴보았다. 이때 CNN, RNN 기반 학습 모형을 지도학습 기법으로, RBM, Autoencoder, GAN 기반 학습 모형을 비지도 학습 기법으로 분류하여 이 방법들이 대한 이해를 돕고자 하였다.","Multi-view learning considers data from various viewpoints as well as attempts to integrate various information from data. Multi-view learning has been studied recently and has showed superior performance to a model learned from only a single view. With the introduction of deep learning techniques to a multi-view learning approach, it has showed good results in various fields such as image, text, voice, and video. In this study, we introduce how multi-view learning methods solve various problems faced in human behavior recognition, medical areas, information retrieval and facial expression recognition. In addition, we review data integration principles of multi-view learning methods by classifying traditional multi-view learning methods into data integration, classifiers integration, and representation integration. Finally, we examine how CNN, RNN, RBM, Autoencoder, and GAN, which are commonly used among various deep learning methods, are applied to multi-view learning algorithms. We categorize CNN and RNN-based learning methods as supervised learning, and RBM, Autoencoder, and GAN-based learning methods as unsupervised learning."
게임과 로봇공학에서의 모델 프리 강화학습 응용에 대한 사례 조사,2019,"['Reinforcement learning', 'Game', 'Robot', 'Q-learning', 'Policy gradient', '강화학습', '게임', '로봇', '큐러닝', '정책 경사']","강화학습은 에이전트가 환경으로부터 현재의 상태를 인지하고 수행한 행동에 대한 피드백을 받으며 학습을 진행한다. 강화학습은 여러 응용에서 활발히 연구되고 있지만, 특히 게임과 로봇에 대한 문제는 마르코프 결정 과정으로 쉽게 표현할 수 있어 강화학습을 적용하기에 용이하다. 모델 프리 강화학습의 종류는 몬테 카를로 컨트롤, 살사, 큐러닝, 정책 경사 방법 등이 있으며, 문제 상황에 따라 알맞은 방법을 사용한다. 게임과 로봇과 관련한 문제를 풀기 위해 모델 프리 강화학습 알고리즘이 주로 사용되며, 딥 큐러닝과 정책 경사 방법이 대표적으로 사용되어왔다. 하지만 주어진 환경에 대한 정보가 충분하지 않아서 보상과 관련된 정보가 충분하지 않고, 보상이 지연되는 경우에는 강화학습이 제대로 작동하기 어려운 문제가 있다. 향후 연구에서는 이러한 단점을 보완하여야 할 것이다. 또한, 이번 연구에서 다루지 못한 게임과 로봇에 관련된 State-of-the-art를 향후 연구에서 다룰 것이다.","Reinforcement learning is the learning process to enable an agent to understand the current environment and get feedback from the action. Though reinforcement learning has been actively studied in various principles, games and robotics are known to be especially well-suited to a Markov decision process, making them easier to apply reinforcement learning. The types of model-free reinforcement learning include Monte-Carlo control, SARSA, Q-learning, and policy gradient and use the appropriate methods depending on the problem situation. Model-free reinforcement learning algorithms such as deep Q-learning and policy gradient are mainly used to solve the problems related to games and robotics. However, reinforcement learning does not work well in some environments where the reward is delayed or has only insufficient information. We believe that future studies need to address these limitations. We plan to investigate the state-of-the-art of reinforcement learning on game and robotics."
Deep Learning and Linguistics: Language & Translation Education Measures,2019,"['딥 러닝', '언어', '번역', '인공 지능', '4차 산업혁명', 'Deep Learning', 'language', 'translation', 'Artificial intelligence', 'The fourth industrial revolution']",,"The fourth industrial revolution is on hyperconnectivity. Hyper connectivity refers to connection between men, between men and system, and between systems, and artificial intelligence takes the role of intermediation. Artificial intelligence is completed based on the artificial part that is computer and robot, and intellectual part that is mathematics and linguistics. Deep learning that learns by itself by emulating the structure of neural network of human; as humans use five senses to receive information, self-learning deep learning takes information from visual stimulation. Recent artificial neural network machine translation technology is gradually minimizing translation errors. On the other hand, to such rapid development of language and translation, the school s education is not keeping up with the pace. For this reason, it is obvious that it is the time to seriously think through about the language education and conduct studies. In addition, in regards to language and translation issues, in the machine translation era, translators should be able to offer translation total service that professionally handles not only translation but pre-editing and post-editing to minimize errors of machine translation."
합성곱 회귀네트워크 기반의 End-to-End 자율주행,2019,"['딥 러닝', '자율주행 자동차', '합성곱 회귀네트워크', '자율주행', 'LiDAR', '카메라', 'Deep learning', 'Autonomous Vehicle', 'CRNN', 'Autonomous Drivinig', 'Camera']","자율주행에 관한연구는 다양하게 진행되고 있으며, 특히 센서 모델링 등을 통한 rule based 기법의 자율주행이 활발하게 연구되고 있다. 이러한 규칙기반 자율주행 방법의 경우 정형화된 환경에서는 안전한 주행이 가능하나, 실제 도로환경과 같이 변수가 많은 환경에서는 오탐지, 미탐지 등으로 인한 사고가 발생 할 수 있다. 이에 본 연구에서는 비정형화된 환경에서도 안전한 자율주행이 가능 하도록 카메라와 LiDAR 센서의 Raw Data를 이용하고, 이를 토대로 합성곱 회귀네트워크에 입력하여 차량의 종, 횡방향 제어값을 예측하는 연구를 진행한다.","A vehicle that runs on its own without the driver’s intervention to the destination is called an autonomous vehicle. In particular, autonomous driving of rule - based techniques through sensor modeling is actively researched. This rule-based autonomous driving method can be safely run in a formal environment, but it can cause an accident due to false detection or undetected in a variable environment like actual road environment. In this study, we use Raw data of LiDAR sensor and image to enable safe autonomous driving in an informal environment, and then input to the CRNN(Convolutional Recurrent Neural Network)based on this data to predict the longitudinal and lateral control values of the vehicle."
Deep Ensemble Network with Explicit Complementary Model for Accuracy-balanced Classification,2019,"['딥 러닝', '객체 분류', '성능 편차', '앙상블', 'deep learning', 'object classification', 'accuracy deviation', 'ensemble']",,
Automatic Generation of HTML Code Based on Web Page Sketch,2019,"['웹 응용', '컴퓨터 비전', '딥 러닝', '객체인식', 'web application', 'computer vision', 'deep learning', 'object detection']",,
뉴로모픽 시스템을 위한 인수분해-프루닝 결합 기반 컨볼루셔널 레이어 압축 기법,2019,"['Deep Learning', 'Deep Neural Networks', 'Neuromorphic Computing', 'Sparse Networks', 'Compressing Parameters']",,
LeafNet: 합성곱 신경망을 이용한 식물체 분할,2019,"['Deep learning', 'Segmentation', 'Plant phenomics', 'Phenomics system', 'CNN', '딥 러닝', '분할', '식물 표현체', '피노믹스 시스템', '합성곱 신경망']","식물 표현체(plant phenomics) 연구는 우수한 형질의 식물 품종과 유전적 특성을 선별하기 위해 여러 식물체의 형태적 특징을 관측하고, 획득한 영상 빅데이터를 분석하는 기술이다. 기존의 방법은 검출 대상에 따라 직접 색상 임계값을 변경해야 하기 때문에 빅데이터를 다루는 정밀검정시스템에 적용하기 어렵다. 본 논문에서는 정밀검정시스템을 위한 식물체와 배경의 자동 분할이 가능한 합성곱 신경망(Convolution neural network: CNN) 구조를 제안한다. LeafNet은 9개의 컨벌루션 계층과 식물의 유무를 판단하기 위한 시그모이드(Sigmoid) 활성화 함수로 구성된다. LeafNet을 이용한 학습 결과, 식물 모종 영상에 대하여 정밀도 98.0%, 재현율 90.3%의 결과가 도출되어 정밀검정시스템의 적용 가능성을 확인하였다.",
합성곱 신경망(Convolutional Neural Network)을 활용한 지능형 유사상표 검색 모형 개발,2019,"['Deep Learning', 'Convolutional Neural Network', 'Trademark Retrieval System', 'Image retrieval Algorithm', '합성곱신경망', '딥 러닝', '상표 검색 시스템', '이미지 검색 알고리즘']","전 세계적으로 온라인 상거래 시장 규모가 성장함에 따라 국제 및 국내 기업의 상표권이 침해되는 사례가 빈번하게 발생하고 있다. 다양한 연구 및 보고서에 따르면, 해외 기업 또는 개인이 국내 기업의 상표권을 침해한 사례와, 국내 기업 간 발생하는 상표권 분쟁 사례가 증가하고 있는 것으로 나타나고 있으며, 특허청의 보고서에 따르면 기업의 규모가 작을수록 상표보호를 위한 사전 예방활동을 수행하지 않는다고 응답한 비율이 높은 것으로 나타났다. 이러한 문제는 선등록 상표에 대한 사전조사 또는 자사의 상표보호를위해 소요되는 인력과 비용이 원인인 것으로 판단된다.한편, 국내에서 선등록상표에 대한 사전조사를 위해 상용되는 서비스를 살펴보면 상표 이미지를 활용한검색 서비스를 제공하고 있지 않은 상황이다. 이로 인해 국내 대다수의 기업은 자사의 상표 보호 및 선등록 상표에 대한 사전조사 수행 시 방대한 양의 선등록된 상표를 수작업으로 조사해야하는 문제가 발생한다.따라서 본 연구에서는 기업의 상표권 보호 및 선등록 상표에 대한 사전조사 수행 시 투입되는 인력 및비용절감과, 국내외에서 발생하고 있는 상표권 침해 문제를 해결하기 위해 합성곱 신경망 기법을 활용한지능형 유사 상표 검색 모델을 개발하고자 한다. 지적 재산권 전문가가 선정한 테스트 데이터를 활용하여지능형 유사 상표 검색 모델의 정확도를 측정한 결과 ResNet V1 101의 성능이 가장 높게 나타났다. 해당결과를 통해 이미지 분류 알고리즘이 단순한 사물 인식 분야뿐만 아니라 이미지 검색 분야에서도 높은 성능을 나타낸다는 것을 실증적으로 입증했으며, 본 연구는 실제 상표 이미지 데이터를 활용했다는 측면에서실제 산업 환경에서 활용성이 높을 것으로 사료된다.","Recently, many companies improving their management performance by building a powerful brand value which is recognized for trademark rights. However, as growing up the size of online commerce market, the infringement of trademark rights is increasing. According to various studies and reports, cases of foreign and domestic companies infringing on their trademark rights are increased. As the manpower and the cost required for the protection of trademark are enormous, small and medium enterprises(SMEs) could not conduct preliminary investigations to protect their trademark rights.Besides, due to the trademark image search service does not exist, many domestic companies have a problem that investigating huge amounts of trademarks manually when conducting preliminary investigations to protect their rights of trademark.Therefore, we develop an intelligent similar trademark search model to reduce the manpower and cost for preliminary investigation. To measure the performance of the model which is developed in this study, test data selected by intellectual property experts was used, and the performance of ResNet V1 101 was the highest. The significance of this study is as follows. The experimental results empirically demonstrate that the image classification algorithm shows high performance not only object recognition but also image retrieval. Since the model that developed in this study was learned through actual trademark image data, it is expected that it can be applied in the real industrial environment."
인공지능 기반 전력량예측 기법의 비교,2019,"['Demand Forecast', 'Deep Learning', 'MLP', 'RNN', 'LSTM']","최근 안정적인 전력수급과 급증하는 전력수요를 예측하는 수요예측 기술에 대한 관심과 실시간 전력측정을 가능하게 하는 스마트 미터기의 보급의 증대로 인해 수요예측 기법에 대한 연구가 활발히 진행되고 있다. 본 연구에서는실제 측정된 가정의 전력 사용량 데이터를 학습하여 예측결과를 출력하는 딥 러닝 예측모델 실험을 진행한다. 그리고본 연구에서는 데이터 전처리 기법으로써 이동평균법을 도입하였다. 실제로 측정된 데이터를 학습한 모델의 예측량과실제 전력 측정량을 비교한다. 이 예측량을 통해서 전력공급 예비율을 낮춰 사용되지 않고 낭비되는 예비전력을 줄일수 있는 가능성을 제시한다. 또한 본 논문에서는 같은 데이터, 같은 실험 파라미터를 토대로 세 종류의 기법: 다층퍼셉트론(Multi Layer Perceptron, MLP), 순환신경망(Recurrent Neural Network, RNN), Long Short Term Memory(LSTM)에 대해 실험을 진행하여 성능을 평가한다. 성능평가는 MSE(Mean Squared Error), MAE(Mean Absolute Error)의 기준으로 성능평가를 진행했다.","Recently, demand forecasting techniques have been actively studied due to interest in stable power supply with surging power demand, and increase in spread of smart meters that enable real-time power measurement. In this study, we proceeded the deep learning prediction model experiments which learns actual measured power usage data of home and outputs the forecasting result. And we proceeded pre-processing with moving average method. The predicted value made by the model is evaluated with the actual measured data. Through this forecasting, it is possible to lower the power supply reserve ratio and reduce the waste of the unused power. In this paper, we conducted experiments on three types of networks: Multi Layer Perceptron (MLP), Recurrent Neural Network (RNN), and Long Short Term Memory (LSTM) and we evaluate the results of each scheme. Evaluation is conducted with following method: MSE(Mean Squared Error) method and MAE(Mean Absolute Error)."
Multi-Layer Perceptron 기법을 이용한 전력 분석 공격 구현 및 분석,2019,"['Side-Channel Analysis', 'Power Analysis Attack', 'Deep Learning MLP', 'Machine Learning SVM']","본 논문에서는 기존 전력 분석 공격의 어려움과 비효율성을 극복하기 위해 딥 러닝 기반의 MLP(Multi-LayerPerceptron) 알고리즘을 기반으로 한 공격 모델을 사용하여 암호 디바이스의 비밀 키를 찾는 공격을 시도하였다.제안하는 전력 분석 공격 대상은 XMEGA128 8비트 프로세서 상에서 구현된 AES-128 암호 모듈이며, 16바이트의비밀 키 중 한 바이트씩 복구하는 방식으로 구현하였다. 실험 결과, MLP 기반의 전력 분석 공격은 89.51%의 정확도로 비밀 키를 추출하였으며 전처리 기법을 수행한 경우에는 94.51%의 정확도를 나타내었다. 제안하는 MLP 기반의 전력 분석 공격은 학습을 통한 feature를 추출할 수 있는 성질이 있어 SVM(Support Vector Machine)과 같은 머신 러닝 기반 모델보다 우수한 공격 특성을 보임을 확인하였다.","To overcome the difficulties and inefficiencies of the existing power analysis attack, we try to extract the secret keyembedded in a cryptographic device using attack model based on MLP(Multi-Layer Perceptron) method. The target of ourproposed power analysis attack is the AES-128 encryption module implemented on an 8-bit processor XMEGA128. We usethe divide-and-conquer method in bytes to recover the whole 16 bytes secret key. As a result, the MLP-based poweranalysis attack can extract the secret key with the accuracy of 89.51%. Additionally, this MLP model has the 94.51%accuracy when the pre-processing method on power traces is applied. Compared to the machine leaning-based modelSVM(Support Vector Machine), we show that the MLP can be a outstanding method in power analysis attacks due toexcellent ability for feature extraction."
Adam Optimizer를 이용한 음향매질 탄성파 완전파형역산,2019,"['Adam', 'optimization', 'steepest descent method', 'full waveform invers', 'Adam', '최적화', '최대 경사법', '탄성파 완전파형역산']","본 연구에서는 Adam 최적화 기법을 이용한 음향매질에서의 탄성파 파형역산 방법을 제안하였다. 탄성파 파형역산에서 최적화에 사용되는 기본적인 최대 경사법은 계산이 빠르고 적용이 간편하다는 장점이 있다. 하지만 속도 모델의갱신에 일정한 갱신 크기를 사용함에 따라 오차가 정확하게 수렴하지 않는다. 이에 대한 대안으로 제시된 다양한 최적화기법들의 경우 정확성은 높지만 많은 계산 시간을 필요로 한다는 한계가 있다. Adam 최적화 기법은 최근 딥 러닝 분야에서 학습 모델의 최적화를 위해 사용되는 기법으로 다양한 형태의 모델에 대한 최적화 문제에서 가장 효율적인 성능을보이고 있다. 따라서 Adam 최적화 기법을 이용한 파형역산 방법을 개발하여 탄성파 파형역산에서의 오차가 빠르고 정확하게 수렴하도록 하였다. 제안된 역산 기법의 성능을 검증하기 위해, 일정한 갱신 크기를 가지는 최대 경사법을 이용하여 수행된 역산 결과와 제안된 Adam 최적화 기반 파형역산을 수행하여 갱신된 P파 속도 모델을 비교하였다. 그 결과 제안된 기법을 통해 빠른 오차 수렴 속도와 높은 정확도의 결과를 확인할 수 있었다.","In this study, an acoustic full-waveform inversion using Adam optimizer was proposed. The steepest descent method, which is commonly used for the optimization of seismic waveform inversion, is fast and easy to apply, but the inverse problem does not converge correctly. Various optimization methods suggested as alternative solutions require large calculation time though they were much more accurate than the steepest descent method. The Adam optimizer is widely used in deep learning for the optimization of learning model. It is considered as one of the most effective optimization method for diverse models. Thus, we proposed seismic full-waveform inversion algorithm using the Adam optimizer for fast and accurate convergence. To prove the performance of the suggested inversion algorithm, we compared the updated P-wave velocity model obtained using the Adam optimizer with the inversion results from the steepest descent method.As a result, we confirmed that the proposed algorithm can provide fast error convergence and precise inversion results"
순환신경망 기법을 이용한 스파 플랫폼의 시계열데이터 필터링에 관한 연구,2019,"['데이터 필터링', '순환신경망', '시계열 데이터', '실시간', '필터링 기법', 'Data filtering', 'Recurrent neural network', 'Time series data', 'Real-time', 'Filtering methods']",스마트 선박 (Smart ship)의 개발과 해양 플랫폼의 예지보전 시스템 및 자산 관리 시스템 개발을 위해 방대한 양의계측 데이터를 실시간으로 분석할 수 있는 기술에 대한 관심이 높아지고 있다. 이러한 계측 데이터를 실시간으로 분석하기 위해서는 계측 데이터의 노이즈를 제거하고 필요한 정보를 추출하여 분석에 용이한 형태로 데이터를 가공하는 과정인 데이터 필터링이 반드시 선행되어야 한다. 기존의 조선 해양 산업에서는 일정기간 이상 데이터를 저장한 후 이에대한 분석을 실시하여 스펙트럼 기반의 필터링 기법을 많이 이용하였다. 이러한 방법은 실시간 데이터를 분석해야 하는현 상황에는 적합하지 않아 실시간 데이터를 필터링하기 위한 새로운 기법이 필요한 실정이다. 본 논문에서는 시계열데이터를 학습하기 위한 딥 러닝 모델인 순환신경망 알고리즘을 이용하여 실시간으로 전송되는 데이터를 필터링하고자하였다. 실시간으로 계측되는 스파 플랫폼의 계류 장력 값을 필터링하기 위해 순환신경망 알고리즘을 이용한 필터링 모델을 설계하고 그 결과값을 확인하여 실시간 필터링 가능 여부를 확인하였다. 최종적으로 실시간으로 전송되는 데이터를 필터링 하기 위해 순환신경망 알고리즘을 사용하는 것이 적합하다는 것을 확인하였다.,"There is growing interest in the numerous techniques focused on analyzing vast quantities of measurement data in real time for the development of smart ships along with the development of asset integrity management systems for offshore platforms. To analyze the measurement data in real time, data filtering is used to eliminate the noise in the data and then extract the necessary information to perform a comprehensive data analysis. In the traditional shipbuilding and offshore industry, spectrum-based filtering methods are used because the corresponding data is saved for a certain period and subsequently analyzed. These methods are not suited to the present situation in which real-time data is required to be analyzed. Therefore, a new method for data filtering is required. The objective of this study is to filter data in real time using a recurrent neural network algorithm, which is a deep learning model used for learning time series data. In order to filter the measured mooring tension value of the spa platform in real time, a filtering model comprising a recurrent neural network algorithm was designed, and the results of the data filtering process were verified to confirm the possibility of real- time filtering."
