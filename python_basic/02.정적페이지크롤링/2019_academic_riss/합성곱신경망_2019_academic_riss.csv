title,date,keywords,abstract,multilingual_abstract
합성곱신경망을 이용한 제주도 강수패턴 분석 연구,2019,"['Precipitation', 'Convolution NN (Neural Network)', 'Texture', 'weather satellite', 'Jeju', '강수패턴', '합성곱신경망', '텍스처', '기상위성', '제주지역']",국문 초록 정보 없음,"Since Jeju is the absolute weight of agriculture and tourism, the analysis of precipitation is more important than other regions. Currently, some numerical models are used for analysis of precipitation of Jeju Island using observation data from meteorological satellites. However, since precipitation changes are more diverse than other regions, it is difficult to obtain satisfactory results using the existing numerical models. In this paper, we propose a Jeju precipitation pattern analysis method using the texture analysis method based on Convolution Neural Network (CNN). The proposed method converts the water vapor image and the temperature information of the area of ​​Jeju Island from the weather satellite into texture images. Then converted images are fed into the CNN to analyse the precipitation patterns of Jeju Island. We implement the proposed method and show the effectiveness of the proposed method through experiments."
합성곱신경망을 이용한 안전문화 수준 분류,2019,"['Artificial intelligence', 'Convolution neural network', 'Safety culture', 'Survey data', 'Classification', 'Classifier']",국문 초록 정보 없음,"Objective: The aim of this study is to investigate whether an artificial intelligence technique can be successfully applied to safety culture survey data classification.Background: Without help of artificial intelligence technique, classifying safety culture level from safety culture scores collected from a large-scale survey would require a lot of experts"" time and effort.Method: Two convolution layers and 1 pooling layer was used as the middle layer of the artificial neural network to design a classifier for safety culture level. 1045 safety culture survey data collected from power plant workers used to train and validate the classifier.Results: After 40 epochs"" training the classifier approached near 95% precision in classifying ""safe"" and ""need to be improved"" classes of safety culture level. Precision, recall and F1-score for the test data set showed over 95% of accuracy performance.Conclusion: An artificial intelligence technique using such as convolution neural network can help classification of safety culture survey data.Application: The safety culture level classifier using deeper neural network and big survey data might improve the performance and might substitute expert interviewers for safety culture evaluation."
합성곱신경망의 학습 및 테스트자료에 따른 골다공증 판독에 미치는 영향,2019,"['Mandible', 'Osteoporosis', 'Panoramic radiograph', 'Computer']",국문 초록 정보 없음,"This study aimed to test a convolutional neural network (CNN) in two different settings of training and testing data. Panoramic radiographs were selected from 1170 female dental patients (mean age 49.19 ± 21.91 yr). The cortical bone of the mandible inferior border was evaluated for osteoporosis or normal condition on the panoramic radiographs. Among them, 586 patients (mean age 27.46 ± 6.73 yr) had normal condition, and osteoporosis was interpreted on 584 patients (mean age 71.00 ± 7.64 yr). Among them, one data set of 569 normal patients (mean age 26.61 ± 4.60 yr) and 502 osteoporosis patients (mean age 72.37 ± 7.10 yr) was used for training CNN, and the other data set of 17 normal patients (mean age 55.94 ± 4.0 yr) and 82 osteoporosis patients (mean age 62.60 ± 5.00 yr) for testing CNN in the first experiment, while the latter was used for training CNN and the former for testing CNN in the second experiment.The error rate was 15.15% in the first experiment and 5.14% in the second experiment. This study suggests that age-matched training data make more accurate testing results."
합성곱신경망 기반의 StyleGAN 이미지 탐지모델,2019,"['Deep Learning', 'Generative Adversarial Network', 'Convolutional Neural Network', 'Fake Image Detection', 'Face Detection']",국문 초록 정보 없음,"As artificial intelligence technology is actively used in image processing, it is possible to generate high-quality fake images based on deep learning. Fake images generated using GAN(Generative Adversarial Network), one of unsupervised learning algorithms, have reached levels that are hard to discriminate from the naked eye. Detecting these fake images is required as they can be abused for crimes such as illegal content production, identity fraud  and defamation. In this paper, we develop a deep-learning model based on CNN(Convolutional Neural Network) for the detection of StyleGAN fake images. StyleGAN is one of GAN algorithms and has an excellent performance in generating face images. We experiment with 48 number of experimental scenarios developed by combining parameters of the proposed model. We train and test each scenario with 300,000 number of real and fake face images in order to present a model parameter that improves performance in the detection of fake faces."
합성곱신경망 테스트 자료에 따른 파노라마 방사선 사진에서의 골다공증 판독의 차이,2019,"['CNN', 'Osteoporosis', 'DR panoramic radiographs', 'CR panoramic radiographs']",국문 초록 정보 없음,"This study was conducted as part of a series of studies to introduce the Convolutional Neural Network(CNN) into the diagnostic eld of osteoporosis. The purpose of this study was to compare the results when testing Digital Radiography(DR) and Computed adiography(CR) panoramic radiographs by CNN that were trained by DR panoramic radiographs. The digital panoramic radiographs f females who visited for the purpose of diagnosis and treatment at Chonnam National University Dental Hospital were taken. Two Oral and Maxillofacial Radiologists were selected for the study to compare the panoramic radiographs with normal and osteoporosis mages. Among them, 1068 panoramic radiographs of females{Mean [± standard deviation] age: 49.19 ± 21.91 years} obtained by DR method were used for training of CNN. 200 panoramic radiographs of females{Mean [± standard deviation] age: 63.95 ± 6.45 years} btained by DR method and 202 panoramic radiographs of females{Mean [± standard deviation] age: 62.00 ± 6.86 years} obtained by R method were used for testing of CNN. When the DR panoramic radiographs were tested, the Accuracy was 92.5%. When the CR anoramic radiographs were tested, the Accuracy was 76.2%. It can be seen that the CNN trained by DR panoramic radiographs is uitable to be tested with the same DR panoramic radiographs."
시각장애인을 위한 합성곱신경망 기반 차로와 보도 인식 연구,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
감정 인식을 위한 합성곱신경망(CNN) 최적화,2019,[],국문 초록 정보 없음,"In this paper, we propose a convolution neural network structure optimized for facial recognition.   We optimized the structure of the hidden layer to reduce the amount of learning computation, and as a result, the learning speed was improved. In addition, we improved the emotional recognition accuracy through learning parameters and data argumentation. As a result of the final learning experiment, the predicated rate was 84.9% and the learning speed was improved compared to VGG network [1]."
다중 센서 데이터 분석을 위한 설명 가능한 합성곱신경망 모델,2019,"['Multi-Sensor Data', 'Accelerometer', 'Construction Equipment Activity Recognition', 'Monitoring', 'Deep Learning', 'Explainable Convolutional Neural Networks', 'Sensor Selection']",국문 초록 정보 없음,"In this paper, we propose a new convolutional neural networks (CNNs) structure to overcome the interpretation problem posed by a series of the nonlinear transformation processes in CNNs. Convolutional neural networks  (CNNs) have been successfully used in various applications including images, signals, and texts. Despite their superior performance in various tasks, the main limitation of CNNs is the lack of interpretability. Recently, deep neural network models including CNNs have been effectively used for the analysis of multi-sensor data. Although the original characteristics of deep neural network models offer high accuracy in classification for activity recognition, they are difficult to identify the critical sensors that play a significant role in discrimination of various equipment conditions. The proposed CNNs offers good performance and interpretability simultaneously. The effectiveness and applicability of the proposed method were demonstrated by the real sensor data collected from construction equipment for activity recognition."
스마트 구조물 균열 감지를 위한 1차원 합성곱신경망(1D CNN) 딥러닝을 이용한 파괴 신호 특정 기법,2019,"['구조물 모니터링', '기계 학습', '1D Convolution', '진동 센서', 'Structure Health Monitoring', 'Machine Learning', '1D Convolution Network', 'Accelerometer']","초고층 빌딩, 대형 구조물 등의 건설이 일반화됨에 따라 점차 노후화 및 지진, 태풍 등의 자연재해에 의한 구조물의 손상 모니터링에 대한 필요도가 증가하고 있다. 특히, 하부구조인 구조물 기초에서의 손상은 구조물 전체의 건전도에 부정적인 영향을 미칠 수 있기 때문에, 이에 대한 감지는 매우 중요하다. 구조물 건전도 비파괴검사 방법으로는 대표적으로 음향, 진동 감지기법 등이 제안되었으며, 이에 음향, 진동 감지기에 의해 수집된 신호를 해석하여 균열의 발생 위치 및 균열의 크기, 내구도 등을 역으로 추정하는 방법에 관한 연구가 실험실 스케일에서 많이 수행되어왔다. 하지만 실제로 현장에서는 적용되는 경우가 극히 드문 데 그 이유는 평소 발생하는 노이즈 신호(정상 신호)와 손상파괴 신호(비정상 신호)를 구분하는 것이 어렵기 때문이다. 특히 노이즈 신호와 구조물 파괴 신호가 동시에 수집될 때 이를 구분하는 것은 더욱 어려워진다. 이에 본 연구에서는 노이즈 신호(정상 신호)와 손상파괴 신호(비정상 신호)를 수집하고, 무작위로 합성된 신호를 딥러닝 기법인 1D convolutional neural network model을 통해서 정상 신호와 비정상 신호를 구분하는 알고리즘을 개발하였다. 개발된 알고리즘을 사용하면 현장에서 실시간으로 수집된 신호를 구분할 수 있게 됨으로써 구조물 안전성 변화 예측을 통해 재산 및 인명 피해 위험성을 최소화할 수 있을 것으로 생각한다.","Structures can be damaged by natural disasters such as earthquakes and typhoons. In particular, any damage to the foundation of a structure can present critical problems. Therefore, a smart monitoring technique such as the acoustic emission method is required to detect internal cracks and other types of structural damage. Many laboratory studies on this method have been conducted to estimate the locations and sizes of cracks as well as the resulting changes in structural durability using collected acoustic signals. However, the method has rarely been applied in the field because identifying damage signals from acquired signals, which can contain ambient noise, is difficult. We developed a deep learning algorithm based on a one-dimensional convolutional neural network method that can identify damage or crack signals generated from concrete failure from randomly synthesized signals. Using the developed algorithm, we were able to distinguish damage signals from random ambient noise signals. This algorithm enables real-time monitoring of concrete structures, thus providing a smart monitoring strategy."
< 전시-P-05 > k-Nearest Neighbor와 합성곱신경망에 의한 국산 침엽수재 표면의 옹이 종류 분류,2019,[],"목재를 용도에 맞게 효율적으로 이용하기 위해서는 강도와 심미적 기능에 영향을 주는 옹이의 종류를 정확하게 분류할 필요가 있다. 통상적으로 널리 이용되고 있는 육안등급구분은 주변 환경에 쉽게 영향을 받을 수 있기 때문에 목재 품질의 객관적 평가 및 목재 생산의 고속화를 위해서는 컴퓨터 비전을 활용한 화상분석 자동화가 필요하다. 본 연구에서는 SIFT(Scale-Invariant Feature Transform) +k-NN(k-Nearest Neighbor)모델과 CNN(Convolutional Neural Network)모델을 통해 옹이의 종류를 분류하고 그 정확도를 평가하였다. 실험에 사용한 수종은 다섯 가지 국산 침엽수종으로 낙엽송, 소나무, 잣나무, 삼나무, 편백이었다. 제재목 표면에서 4가지 형태(sound, encased, decayed, spike)의 옹이 이미지 1,172개를 획득하여 각 모델에서의 학습 및 검증에 사용하였다. SIFT+k-NN 모델의 경우, SIFT 기술을 이용하여 옹이 이미지에서 특성을 추출한 뒤, k-NN을 이용하여 분류를 실시하였으며, 최대 60.53%의 정확도로 분류가 가능하였다. CNN 모델의 경우, 8층의 convolution layer와 3층의 hidden layer로 구성되어있는 모델을 사용하였으며 최대 88.09%로 옹이 분류가 가능하였다. 또한 CNN 모델은 옹이 종류별 이미지의 개수 차이가 큰 경우에도 특성 추출의 편향이 심하지 않아 옹이 분류에 있어 더 높은 정확도를 보였다.",다국어 초록 정보 없음
비디오 얼굴 식별 성능개선을 위한 다중 심층합성곱신경망 결합 구조 개발,2019,"['Video Face Identification', 'Face Sequences', 'Deep Convolution Neural Network', 'Class Confidence Matrix', 'Network Combination']",국문 초록 정보 없음,"In this paper, we propose a novel way of combining multiple deep convolutional neural network (DCNN) architectures which work well for accurate video face identification by adopting a serial combination of 3D and 2D DCNNs. The proposed method first divides an input video sequence (to be recognized) into a number of sub-video sequences. The resulting sub-video sequences are used as input to the 3D DCNN so as to obtain the class-confidence scores for a given input video sequence by considering both temporal and spatial face feature characteristics of input video sequence. The class-confidence scores obtained from corresponding sub-video sequences is combined by forming our proposed class-confidence matrix. The resulting class-confidence matrix is then used as an input for learning 2D DCNN learning which is serially linked to 3D DCNN. Finally, fine-tuned, serially combined DCNN framework is applied for recognizing the identity present in a given test video sequence. To verify the effectiveness of our proposed method, extensive and comparative experiments have been conducted to evaluate our method on COX face databases with their standard face identification protocols. Experimental results showed that our method can achieve better or comparable identification rate compared to other state-of-the-art video FR methods."
얼굴인식을 위한 얼굴 전역 및 지역 특징 기반 심층합성곱신경망 앙상블 압축 모델 제안,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 이용한 아스팔트 콘크리트 도로포장 표면균열 검출,2019,"['딥러닝', '합성곱 신경망', '아스팔트 도로포장', '아스팔트 도로포장 표면균열', 'Deep learning', 'Convolutional Neural Network', 'Asphalt Pavement', 'Surface Crack']","본 연구에서는 아스팔트 콘크리트 도로포장의 표면균열 검출을 위해 합성곱 신경망을 이용하였다. 합성곱 신경망의 학습에 사용되는 표면균열 이미지 데이터의 양에 따른 합성곱 신경망의 성능향상 정도를 평가하였다. 사용된 합성곱 신경망의 구조는 5개의 층으로 구성되어있으며, 3x3 크기의 convolution filter와 2x2 크기의 pooling kernel을 사용하였다. 합성곱 신경망의 학습을 위해서 도로노면 조사 장비를 통해 구축된 국내 도로포장 표면균열 이미지를 활용하였다. 표면균열 이미지 데이터를 학습한 합성곱 신경망 모델의 표면균열 검출 정확도, 정밀도, 재현율, 미검출율, 과검출율을 평가하였다. 가장 많은 양의 데이터를 학습한 합성곱 신경망 모델의 표면균열 검출 정확도, 정밀도, 재현율은 96.6% 이상, 미검출율, 과검출율은 3.4% 이하의 성능을 나타내었다.","A Convolution Neural Network(CNN) model was utilized to detect surface cracks in asphalt concrete pavements. The CNN used for this study consists of five layers with 3x3 convolution filter and 2x2 pooling kernel. Pavement surface crack images collected by automated road surveying equipment was used for the training and testing of the CNN. The performance of the CNN was evaluated using the accuracy, precision, recall, missing rate, and over rate of the surface crack detection. The CNN trained with the largest amount of data shows more than 96.6% of the accuracy, precision, and recall as well as less than 3.4% of the missing rate and the over rate."
Word2Vec과 앙상블 합성곱 신경망을 활용한 영화추천 시스템의 정확도 개선에 관한 연구,2019,"['Text Analysis(Word2Vec)', 'Collaborative Filtering', 'Recommender Systems', 'Ensemble Model', 'Convolutional Neural Networks', 'Deep Learning', '텍스트 분석(Word2Vec)', '협업필터링', '추천시스템', '앙상블 모델', '합성곱 신경망', '딥러닝']","웹 추천기법에서 가장 많이 사용하는 방식 중의 하나는 협업필터링 기법이다. 협업필터링 관련 많은 연구에서 정확도를 개선하기 위한 방안이 제시되어 왔다. 본 연구는 Word2Vec과 앙상블 합성곱 신경망을 활용한 영화추천 방안에 대해 제안한다. 먼저 사용자, 영화, 평점 정보에서 사용자 문장과 영화 문장을 구성한다. 사용자 문장과 영화 문장을 Word2Vec에 입력으로 넣어 사용자 벡터와 영화 벡터를 구한다. 사용자 벡터는 사용자 합성곱 모델에 입력하고, 영화 벡터는 영화 합성곱 모델에 입력한다. 사용자 합성곱 모델과 영화 합성곱 모델은 완전연결 신경망 모델로 연결된다. 최종적으로 완전연결 신경망의 출력 계층은 사용자 영화 평점의 예측값을 출력한다. 실험결과 전통적인 협업필터링 기법과 유사 연구에서 제안한 Word2Vec과 심층 신경망을 사용한 기법에 비해 본 연구의 제안기법이 정확도를 개선함을 알 수 있었다.","One of the most commonly used methods of web recommendation techniques is collaborative filtering. Many studies on collaborative filtering have suggested ways to improve accuracy. This study proposes a method of movie recommendation using Word2Vec and an ensemble convolutional neural networks. First, in the user, movie, and rating information, construct the user sentences and movie sentences. It inputs user sentences and movie sentences into Word2Vec to obtain user vectors and movie vectors. User vectors are entered into user convolution model and movie vectors are input to movie convolution model. The user and the movie convolution models are linked to a fully connected neural network model. Finally, the output layer of the fully connected neural network outputs forecasts of user movie ratings. Experimentation results showed that the accuracy of the technique proposed in this study accuracy of conventional collaborative filtering techniques was improved compared to those of conventional collaborative filtering technique and the technique using Word2Vec and deep neural networks proposed in a similar study."
딥 러닝 기법을 이용한 오피니언 마이닝 분석과 성과에 관한 실증연구: 합성곱 신경망 모델과 머신러닝 모델간 성과비교를 중심으로,2019,"['Deep learning', 'Convolutional neural network', 'Sentiment analysis', 'Opinion mining', 'Machine learning classifiers', 'Financial supervisory policy', '딥 러닝', '합성곱 신경망', '감성분석', '오피니언 마이닝', '머신러닝 분류기']","본 연구는 딥 러닝 기법인 합성곱 신경망 (CNN: Convolutional Neural Network)을 이용하여 금융자료에 관한 사용자의 오피니언을 추정하는 오피니언 마이닝 (Opinion mining) 방법과 그 결과를 설명한다. 본 연구에서는 다음과 같이 합성곱 신경망의 효과성을 검증하였다. 첫째, 스터디1은 주식관련 온라인 리뷰 데이터를 분석하였다. 즉, 형태소 분석단계를 거쳐 속성벡터를 만들어 리뷰 문장의 감성점수를 산출하였다. 해당 문장의 감성점수에 따라 오피니언을 3-클라스, 5-클라스 문제로 구분하여 실증분석을 하였다. 둘째, 스터디2에서는 청와대 국민청원에 게시된 금융관련 국민청원 텍스트 문장을 분석하여 청원인원을 추정하였다. 청원게시판에 등재된 청원 인원을 분위 수에 따라 분류하여 2-클라스 문제 (50%이상, 50% 미만) 4-클라스 문제 (75%이상, 50%이상, 25%이상, 25%미만)로 분류하였다. 스터디1, 2의 실증분석결과 정확도, 정밀도, 재현율, F1 점수 등 모든 성과지표에서 벤치마킹용 분류기와 비교할 때 합성곱 신경망이 더 우수한 성과를 보였다. 따라서, 합성곱 신경망을 이용함으로써 금융감독 관련 정책 및 활동을 효과적으로 수행할 수 있음을 실증적으로 확인하였다.",다국어 초록 정보 없음
합성곱 신경망을 이용한 선박 기관실에서의 화재 검출에 관한 연구,2019,"['Fire Detection', 'Image-based', 'Ship Engine Room', 'Convolution Neural Network', 'YOLO', '화재검출', '영상기반', '선박 기관실', '합성곱 신경망', '욜로']","화재의 초기 검출은 인명과 재화의 손실을 최소화하기 위한 중요한 요소이다. 불꽃과 연기를 신속하면서 동시에 검출해야 하며 이를 위해 영상 기반의 화재 검출에 관한 연구가 다양하게 진행되고 있다. 기존의 화재 검출은 불꽃과 연기의 특징을 추출하기 위해 여러 알고리즘을 거쳐서 화재의 검출 유무를 판단하므로 연산량이 많이 소모되었으나, 딥러닝 알고리즘인 합성곱 신경망을 이용하면 별도의 과정이 생략되므로 신속하게 검출할 수 있다. 본 논문에서는 선박 기관실에서 화재 영상을 녹화한 데이터로 실험을 수행하였다. 불꽃과 연기의 특징을 외각 상자로 추출한 후 합성곱 신경망 중 하나인 욜로(YOLO)를 이용하여 학습하고 결과를 테스트하였다. 실험 결과를 검출률, 오검출률, 정확도로 평가하였으며 불꽃은 0.994, 0.011, 0.998, 연기는 0.978, 0.021, 0.978을 나타내었고, 연산시간은 0.009s를 소모됨을 확인하였다.","Early detection of fire is an important measure for minimizing the loss of life and property damage. However, fire and smoke need to be simultaneously detected. In this context, numerous studies have been conducted on image-based fire detection. Conventional fire detection methods are compute-intensive and comprise several algorithms for extracting the flame and smoke characteristics. Hence, deep learning algorithms and convolution neural networks can be alternatively employed for fire detection. In this study, recorded image data of fire in a ship engine room were analyzed. The flame and smoke characteristics were extracted from the outer box, and the YOLO (You Only Look Once) convolutional neural network algorithm was subsequently employed for learning and testing. Experimental results were evaluated with respect to three attributes, namely detection rate, error rate, and accuracy. The respective values of detection rate, error rate, and accuracy are found to be 0.994, 0.011, and 0.998 for the flame, 0.978, 0.021, and 0.978 for the smoke, and the calculation time is found to be 0.009 s."
합성곱 신경망을 이용한 밭 토양의 물리적 특성 예측,2019,"['합성곱 신경망', '밭 토양', '물리적 특성', '표층 함수비', '건조밀도']","토양의 생산성은 토양의 종류 뿐만 아니라 배수, 통기성, 토양 구조, 유기물의 함량 등 여러 요인에 따라 달라질 수 있다. 이에 따라 작물 재배 시 토양의 특성 및 현재 토양의 상태에 따라 토양 관리 방법을 조율하여야 한다. 현재 농업용 토양 관리는 실내시험을 통한 토양 특성 평가, 현장 시험을 통한 토양 특성 평가, 설치형 센서를 이용한 토양 모니터링 등을 통해 이루어진다. 기존 방법은 관측하고자 하는 지점이 많아질수록 시간과 비용이 많이 소요되기 때문에 현장에서는 일부 지점의 데이터를 이용하여 토양 관리를 수행하는 실정이다. 최근에는 토양의 특성을 빠르게 파악하기 위해 기존의 실험적 방법이 아닌 표층이나 단면의 이미지를 분석하는 방법에 대한 연구가 진행되고 있다. SEM image나 CT-Scan 이미지를 이용하여 토양의 밀도, 투수성을 예측하는 방법이 제시되고 있으나 해당 방법을 현장에서 쉽게 적용하기에는 어려운 실정이다. 최근 다양한 연구가 진행되고 있는 Deep-learning 기법 중의 하나인 합성곱 신경망 (CNN, convolutional neural network)은 기존 분석 알고리즘들의 이미지 분류 및 분석 정확도가 낮은 한계점을 극복한 기술로 이를 이용한 토양 특성 예측 모델 구축 시 낮은 비용으로 신속하게 현장 토양 관리를 수행할 수 있을것으로 예측된다. 본 연구에서는 합성곱 신경망을 기반으로 하여 밭 토양의 이미지를 활용해 물리적 특성을 예측하는 모델을 개발하고자 한다. 국내 밭 토양을 대상으로 연구를 진행하였으며 토양의 이미지는 광조건을 균일하게 통제할 수 있도록 실내에서 촬영되었다. 토양 시료는 직경 150mm, 높이 50mm의 원형 몰드에 함수비, 건조밀도를 각각 달리하여 성형되었으며 각 조건별로 3회 반복촬영을 수행하여 토양별 60개의 원본 이미지를 획득하였다. CNN모델은 Tensorflow 1.14를 기반으로 구성되었으며 예측하고자 하는 인자에 따라 각 계층의 구성 및 초매개변수를 달리하여 모델의 정확도를 높일 수 있도록 하였다. 본 연구의 결과는 향후 밭 토양 관리에 활용되어 토양 함수비 및 건조밀도 추정의 정확도 및 모니터링 효율성을 높일 수 있을것으로 기대된다.",다국어 초록 정보 없음
합성곱 신경망 기반의 딥러닝에 의한 수치표면모델의 객체분류,2019,"['합성곱 신경망', '딥러닝 모델', '학습 및 검증 데이터', '수치표면모델 분류', 'CNN', 'DL Model', 'Training and Validation Data', 'DSM Classification']","최근 딥러닝(DL)은 여러 분야에서 급속도로 활용되고 있으며, 특히 영상으로부터 객체를 인식하여 분류하고 인식하기 위한 컴퓨터비전 분야에서 활발하게 연구가 진행되고 있다. 영상분야에서는 주로 합성곱 신경망(CNN)을 이용한 딥러닝 모델의 성능 향상에 주력하고 있다. 대부분의 합성곱 신경망은 영상을 학습시켜 영상분류 및 객체인식에 활용하고 있지만, 본 논문에서는 독일 사진측량, 원격탐사 및 공간정보학회(DGPF)가 구축하고 국제 사진측량 및 원격탐사학회(ISPRS)가 제공하는 데이터 셋 중에서 수치표면모델(DSM)과 이 데이터로부터 생성한 경사 및 주향 정보를 효율성과 성능이 우수하다고 평가받는 합성곱 신경망기반의 SegNet 모델에 적용하여 객체를 분류하고 분석하였다. 딥러닝은 고사양의 컴퓨터 시스템과 다량의 학습 데이터와 라벨 데이터가 필요하고, 다수의 시행착오에 의한 풍부한 경험이 요구된다. 또한 본 논문에서는 한정된 수량의 데이터로부터 효율적인 학습을 위한 데이터 생성 방법을 제시하고 수치표면모델을 분류하였다. 분석 결과 수치표면모델 데이터와 이로부터 도출한 부가적인 데이터를 딥러닝 모델에 적용해도 객체를 타당한 정확도로 분류할 수 있음을 확인하였다.","Recently, DL (Deep Learning) has been rapidly applied in various fields. In particular, classification and object recognition from images are major tasks in computer vision. Most of the DL utilizing imagery is primarily based on the CNN (Convolutional Neural Network) and improving performance of the DL model is main issue. While most CNNs are involve with images for training data, this paper aims to classify and recognize objects using DSM (Digital Surface Model), and slope and aspect information derived from the DSM instead of images. The DSM data sets used in the experiment were established by DGPF (German Society for Photogrammetry, Remote Sensing and Geoinformatics) and provided by ISPRS (International Society for Photogrammetry and Remote Sensing). The CNN-based SegNet model, that is evaluated as having excellent efficiency and performance, was used to train the data sets. In addition, this paper proposed a scheme for training data generation efficiently from the limited number of data. The results demonstrated DSM and derived data could be feasible for semantic classification with desirable accuracy using DL."
합성곱 신경망을 이용한 보청기 환경잡음 분류 알고리즘,2019,"['Hearing aids', 'Noise classification', 'convolutional neural networks', 'Spectrogram', 'Hearing aids satisfaction']","본 논문은 보청기의 환경잡음 분류를 위해 소리 신호를 이미지 신호로 변환하여 합성곱 신경망(CNN, convolutional neural networks)을 적용한 잡음 분류 알고리즘에 관한 것이다. 장시간 현장 녹음한 생활 잡음을 이미지 신호로 변환하기 위해 스펙트로그램을 확인하고, sharpening mask와 median filter를 적용하여 합성곱 신경망 기법의 분류 결과를 비교하였다. 1초/2.5초/5초 단위 시간의 스펙트로그램 이미지 분류 결과, 1초의 합성곱 신경망 분류율이 가장 높았으며, 단위 시간이 증가 할수록 분류율이 감소하였다. 합성곱 신경망의 입력 데이터에 제안된 필터를 적용하여 분류율 결과를 비교했을 때, 필터를 적용하지 않은 스펙트로그램 이미지를 분류율이 median filter를 적용했을 때보다 최대 약 2.8% 상승한 것을 확인하였다.","In this paper, we present the environment noise classification algorithm using CNN(convolutional neural networks) for hearing aids by converting a sound signal to an image signal. We made spectrogram images from sound signal which have recorded the environment noise around hearing aids, and results of classification using CNN were compared by applying Sharpening Mask and Median Filter. As a result of the spectrogram image classification rate in 1sec. was the highest, and the classification rate was decreased as the time increased to 5sec. When comparing the proposed classification rate results according to the CNN input data, the classification rate without the filter was up to about 2.8% higher than that with the median filter."
2차원 합성곱 신경망 적용을 위한 다변량 시계열 데이터 재배열 및 반전,2019,[],"산업에서 공정의 품질과 지수를 예측하기 위해 다변량 시계열 데이터를 이용한다. 시계열 데이터는 앞, 뒤 값과 높은 상관 계수를 가지고 있으나, 다른 시계열 간 상관 계수는 낮다. 이러한 이유로 합성곱 신경망 적용 시, 2차원 대신 1차원 합성곱 필터를 사용한다. 2차원 합성곱 신경망에 적용되는 방법론을 적용하기 위해 근접 픽셀 간 상관 계수 상향 작업이 필요하다. 본 연구에서는 다변량 시계열 데이터를 시계열 간 재배치, 데이터의 반전을 통하여 시계열 간의 상관 계수를 높이는 전처리 방법에 대하여 제안하였다. 데이터를 노드, 데이터간의 상관 계수 비용으로 가진 링크로 한 완전 그래프로 변환하여, 최소비용 경로 탐색문제로 변환하였다. 최적해 기반으로 시계열 데이터의 재배치, 반전을 통한 전처리를 하여 2차원 합성곱 신경망을 통한 분류 문제에 적용하고 비교하였다.",다국어 초록 정보 없음
2차원 합성곱 신경망 적용을 위한 다변량 시계열 데이터 재배열 및 반전,2019,[],"산업에서 공정의 품질과 지수를 예측하기 위해 다변량 시계열 데이터를 이용한다. 시계열 데이터는 앞, 뒤 값과 높은 상관 계수를 가지고 있으나, 다른 시계열 간 상관 계수는 낮다. 이러한 이유로 합성곱 신경망 적용 시, 2차원 대신 1차원 합성곱 필터를 사용한다. 2차원 합성곱 신경망에 적용되는 방법론을 적용하기 위해 근접 픽셀 간 상관 계수 상향 작업이 필요하다. 본 연구에서는 다변량 시계열 데이터를 시계열 간 재배치, 데이터의 반전을 통하여 시계열 간의 상관 계수를 높이는 전처리 방법에 대하여 제안하였다. 데이터를 노드, 데이터간의 상관 계수 비용으로 가진 링크로 한 완전 그래프로 변환하여, 최소비용 경로 탐색문제로 변환하였다. 최적해 기반으로 시계열 데이터의 재배치, 반전을 통한 전처리를 하여 2차원 합성곱 신경망을 통한 분류 문제에 적용하고 비교하였다.",다국어 초록 정보 없음
자율운항선박의 국제해상충돌예방규칙 준수를 위한 합성곱 신경망 기반의 선박 분류에 관한 연구,2019,"['자율운항선박', '선박 분류', '국제해상충돌예방규칙', '합성곱 신경망', 'Autonomous Ships', 'Vessel Classification', 'COLREGs', 'Convolutional Neural Networks']","최근 자율운항선박에 대한 관심이 증가하고 있으며, 바다를 항해하는 자율운항선박은 유인선과 같이 국제해상충돌방지규칙을 준수해야한다. 따라서 본 논문에서는 자율운항선박이 국제해상충돌예방규칙을 준수하기 위해서 필요한 선박 범주 및 합성곱 신경망 기반의 선박 분류 기술을 제안하였다. 먼저 국제해상충돌예방규칙을 분석하여 자율운항선박이 구별해야 되는 14개의 선박 범주를 정의하였다. 또한 본 논문에서 정의된 선박 범주에 맞도록 인터넷 영상검색 및 기존 데이터 셋 정제를 통하여 40,300장 규모의 선박 범주 분류 데이터 셋을 구축하였다. 마지막으로 최신 합성곱 신경망 모델을 구축된 선박 범주 분류 데이터 셋에 적용하여 선박 범주 분류 성능을 분석하였다. 실험결과 전이학습을 통하여 학습된 Inception-ResNet v2 모델은 14개 선박 범주를 91%의 높은 정확도로 분류함을 확인하였다.","The interest in autonomous ships for marine industries has increased significantly over the past few years and autonomous ships also must follow maritime laws in the same way as regular ships operated by crews. Therefore, in this paper, we propose the vessel taxonomy for COLREGs compliance of autonomous ships and evaluate the performance of the vessel classification method using CNNs. First, we define the vessel taxonomy for complying with maritime laws by analyzing the COLREGs. And then, we build our dataset separated manually by the vessel taxonomy. For the dataset, 40,300 images are collected by image search on websites and refining the publicly available dataset. Finally, the state-of-the-art CNN model is applied to evaluate the recognition rate of our dataset. The experimental results show that the Inception-ResNet v2 model which is trained by transfer learning effectively classifies the ships with a high accuracy of 91%."
해상 영상에서 관심영역 추출과 합성곱 신경망을 활용한 선박 분류,2019,"['선박 분류', '딥러닝', '컴퓨터 비전', '영상처리', 'Ship classification', 'Deep Learning', 'Computer Vision', 'Image Processing']","최근에 해양에서는 선박 스스로 주변 상황을 인지하고 운항할 수 있는 자율운항 기술개발이 활발하게 이루어지고 있다. 이를 위해, 카메라를 통한 영상정보를 활용하여 인간의 시각 정보를 대신할 수 있는 기술에 대한 중요성이 대두되고 있다. 카메라 영상을 기반으로 한 상황인지 기술을 위해서는 영상에서 존재하는 다양한 객체 정보를 분석하는 객체 분류 기술이 필수적이다. 본 논문에서는 해양 영상에서 관심 영역 추출과 합성곱 신경망을 활용하여 선박 분류 정확도를 향상시킬 수 있는 방법을 제안한다. 본 논문에서 제안된 방식의 성능을 검증하기 위해 공개 데이터 셋을 이용하여 기존의 합성곱 신경망 기반 방법과의 비교 실험을 수행하였으며, 실험을 통해 본 논문에서 제안된 방식이 선박 분류 정확도를 향상시킬 수 있음을 확인하였다. 제안된 방법을 활용하여 자율운항선박에서는 다른 해상 장비와의 센서 퓨전을 통하여 객체 데이터의 신뢰성을 확보할 수 있으며, 이를 통해 충돌 회피 및 안전한 운항이 가능할 것으로 기대된다.","Recently, autonomous navigation technology has been actively developed in order to recognize and operate the vessel itself. For this purpose, importance is attached to technologies that can substitute human visual information by utilizing image information through a camera. For the context recognition based on the camera image, object classification technology for analyzing various object information existing in the image is essential. In this paper, we propose a method to improve the accuracy of ship classification by using region of interest and artificial neural network. In order to verify the performance of the propose method in this paper, we performed a comparative experiment with the convolution artificial neural network based on the open data set. Experimental results show that the proposed method improves the accuracy of vessel classification. By using the proposed method, it is possible to secure the reliability of object data through sensor fusion with autonomous vessels, and it is expected that collision avoidance and safe operation will be possible."
합성곱 신경망의 삼차원 비정상 유동 학습 메커니즘의 이해,2019,"['합성곱 신경망(Convolutional neural networks)', '후류유동(Wake flow)', '기계학습(Machine learning)']",국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 위한 Elastic Multiple Parametric Exponential Linear Units,2019,"['Elastic Multiple Parametric Exponential Linear Units', 'activation function', 'convolutional neural network', 'image classification', 'deep learning', 'Elastic Multiple Parametric Exponential Linear Units', '활성화 함수', '합성곱 신경망', '이미지분류', '딥러닝']","활성화 함수는 신경망 모델의 비선형성과 깊이를 결정하는 중요한 요소이다. Rectified Linear Units (ReLU)가 제안된 이후, 평균값을 0에 가깝게 하여 학습의 속도를 높인 Exponential Linear Units (ELU)나 함수 기울기에 변화를 주어 성능을 향상시킨 Elastic Rectified Linear Units (EReLU)같은 다양한 형태의 활성화 함수가 소개되었다. 우리는 서로 다른 ELU와 EReLU를 일반화한 형태의 활성화 함수인 Elastic Multiple Parametric Exponential Linear Units (EMPELU)를 제안한다. EMPELU는 양수 영역에서는 임의의 범위로 기울기 변동을 주면서, 음수 영역은 학습 파라미터를 이용해 다양한 형태의 활성화 함수를 형성하도록 하였다. EMPELU는 합성곱 모델 기반 CIFAR-10/100의 이미지 분류에서 기존 활성화 함수에 비해 정확도 및 일반화에서 향상된 성능을 보였다.","Activation function plays a major role in determining the depth and non-linearity of neural networks. Since the introduction of Rectified Linear Units for deep neural networks, many variants have been proposed. For example, Exponential Linear Units (ELU) leads to faster learning as pushing the mean of the activations closer to zero, and Elastic Rectified Linear Units (EReLU) changes the slope randomly for better model generalization. In this paper, we propose Elastic Multiple Parametric Exponential Linear Units (EMPELU) as a generalized form of ELU and EReLU. EMPELU changes the slope for the positive part of the function argument randomly within a moderate range during training, and the negative part can be dealt with various types of activation functions by its parameter learning. EMPELU improved the accuracy and generalization performance of convolutional neural networks in the object classification task (CIFAR-10/100), more than well-known activation functions."
합성곱 신경망 기반 저조도영상의 반사 영상 생성,2019,"['Low-light image', 'Retinex', 'Convolutional neural network', 'Reflectance', 'Illumination']","저조도 영상의 개선을 위해서 밝기 및 대조 개선, 조명 성분 감쇄 등의 다양한 연구가 진행됐다. 기존의 hand-crafted 방법에서 인공신경망으로 기존 기법들을 대체하는 연구가 최근에 진행 중이다. 본 논문에서는 조명 광원이 존재하는 저조도 영상으로부터 조명 성분을 감쇄하고, 반사 성분만을 생성하는 기법을 합성곱 신경망으로 대체하는 방법을 제안한다. 실험에서는 102장의 저조도 영상으로 학습시킨 합성곱 신경망으로 만족스러운 반사 영상을 생성하였다.",다국어 초록 정보 없음
합성곱 신경망 기반의 PPG 신호 동잡음 구간 검출,2019,"['광맥파계', '생체신호', '동잡음', '인공 신경망', '합성곱 신경망', 'Photoplethysmographic', 'Bio-signal', 'Motion artifact', 'Artificial neural network', 'Convolutional neural network']",국문 초록 정보 없음,"Among the various bio-signals, Photoplethysmographic (PPG) is widely used in areas such as u-health and human factor evaluation due to its low cost of measurement and freedom of user’s motion. Despite its advantages, PPG signal tends to be corrupted by the movement of user. In this study, we proposes the method for detecting the motion artifact in PPG signals using CNN (Convolutional Neural Network). Continuous PPG signals were divided into multiple pulse signals, converted to image, and then each pulse signal is used for training. We have used 3,000 normal signals and 3000 corrupted signals from PhysioNet database for training. With the proposed method, the signals corrupted by motion artifact were successfully detected with 92% accuracy."
합성곱 신경망(Convolutional Neural Network)을 활용한 지능형 유사상표 검색 모형 개발,2019,"['Deep Learning', 'Convolutional Neural Network', 'Trademark Retrieval System', 'Image retrieval Algorithm', '합성곱신경망', '딥 러닝', '상표 검색 시스템', '이미지 검색 알고리즘']","전 세계적으로 온라인 상거래 시장 규모가 성장함에 따라 국제 및 국내 기업의 상표권이 침해되는 사례가 빈번하게 발생하고 있다. 다양한 연구 및 보고서에 따르면, 해외 기업 또는 개인이 국내 기업의 상표권을 침해한 사례와, 국내 기업 간 발생하는 상표권 분쟁 사례가 증가하고 있는 것으로 나타나고 있으며, 특허청의 보고서에 따르면 기업의 규모가 작을수록 상표보호를 위한 사전 예방활동을 수행하지 않는다고 응답한 비율이 높은 것으로 나타났다. 이러한 문제는 선등록 상표에 대한 사전조사 또는 자사의 상표보호를위해 소요되는 인력과 비용이 원인인 것으로 판단된다.한편, 국내에서 선등록상표에 대한 사전조사를 위해 상용되는 서비스를 살펴보면 상표 이미지를 활용한검색 서비스를 제공하고 있지 않은 상황이다. 이로 인해 국내 대다수의 기업은 자사의 상표 보호 및 선등록 상표에 대한 사전조사 수행 시 방대한 양의 선등록된 상표를 수작업으로 조사해야하는 문제가 발생한다.따라서 본 연구에서는 기업의 상표권 보호 및 선등록 상표에 대한 사전조사 수행 시 투입되는 인력 및비용절감과, 국내외에서 발생하고 있는 상표권 침해 문제를 해결하기 위해 합성곱 신경망 기법을 활용한지능형 유사 상표 검색 모델을 개발하고자 한다. 지적 재산권 전문가가 선정한 테스트 데이터를 활용하여지능형 유사 상표 검색 모델의 정확도를 측정한 결과 ResNet V1 101의 성능이 가장 높게 나타났다. 해당결과를 통해 이미지 분류 알고리즘이 단순한 사물 인식 분야뿐만 아니라 이미지 검색 분야에서도 높은 성능을 나타낸다는 것을 실증적으로 입증했으며, 본 연구는 실제 상표 이미지 데이터를 활용했다는 측면에서실제 산업 환경에서 활용성이 높을 것으로 사료된다.","Recently, many companies improving their management performance by building a powerful brand value which is recognized for trademark rights. However, as growing up the size of online commerce market, the infringement of trademark rights is increasing. According to various studies and reports, cases of foreign and domestic companies infringing on their trademark rights are increased. As the manpower and the cost required for the protection of trademark are enormous, small and medium enterprises(SMEs) could not conduct preliminary investigations to protect their trademark rights.Besides, due to the trademark image search service does not exist, many domestic companies have a problem that investigating huge amounts of trademarks manually when conducting preliminary investigations to protect their rights of trademark.Therefore, we develop an intelligent similar trademark search model to reduce the manpower and cost for preliminary investigation. To measure the performance of the model which is developed in this study, test data selected by intellectual property experts was used, and the performance of ResNet V1 101 was the highest. The significance of this study is as follows. The experimental results empirically demonstrate that the image classification algorithm shows high performance not only object recognition but also image retrieval. Since the model that developed in this study was learned through actual trademark image data, it is expected that it can be applied in the real industrial environment."
합성곱 신경망을 이용한 구글 어스에서의 녹지 공간 비율 측정,2019,"['Green area', 'Convolution neural network', 'Google Earth', 'Ratio of green space']","녹지 공간이 확충되면 기후변화를 야기하는 지구 온난화, 미세먼지 발생 등을 친환경적으로 해결할 수 있다. 법제처에 따르면 녹지를 조성하기 위해서는 지형, 지질, 생물 서식 공간 등의 자연적 여건을 조사해야 한다. 본 논문에서는 녹지를 조성할 수 있는 지역을 판단하는 데 도움을 주기 위하여 녹지공간의 비율을 측정하는 방법을 제안한다. 제안하는 방법은 ‘Google Earth pro’ 어플리케이션을 이용하여 데이터를 수집한 후 합성곱 신경망을 사용하여 학습시킨다. 학습시킨 데이터를 바탕으로 사용자가 원하는 지역의 녹지 공간 비율을 추정한다. 다양한 영상으로 실험해본 결과, 실제 녹지 공간 비율과 제안된 방법으로 도출해낸 결과값이 흡사한 것을 확인하였다.","Expending green space can be a environmental-friendly solution to global warming and fine dust caused by climate change. According to the legislation, environmental investigation must be investigated such as topography, geology, and biological habitats to create green space. In this paper, we propose a method to measure the ratio of green space to help the determination where green space should be located. The proposed method collects the data using the ‘Google Earth pro’ application and then trains the data using the convolution neural network. Based on the learned data, we estimate the green space ratio. As a result of experiments with various images, it was confirmed that the actual green space ratio and the result value estimated by the proposed method were similar."
심층 합성곱 신경망 및 전이학습을 이용한 차량 Instrument panel structure의 결함 구별에 관한 연구,2019,"['Deep convolutional neural network(심층 합성곱 신경망)', 'Transfer learning(전이 학습)', 'Structure fault classification(구조 결함 구별)']",국문 초록 정보 없음,다국어 초록 정보 없음
LeafNet: 합성곱 신경망을 이용한 식물체 분할,2019,"['Deep learning', 'Segmentation', 'Plant phenomics', 'Phenomics system', 'CNN', '딥 러닝', '분할', '식물 표현체', '피노믹스 시스템', '합성곱 신경망']","식물 표현체(plant phenomics) 연구는 우수한 형질의 식물 품종과 유전적 특성을 선별하기 위해 여러 식물체의 형태적 특징을 관측하고, 획득한 영상 빅데이터를 분석하는 기술이다. 기존의 방법은 검출 대상에 따라 직접 색상 임계값을 변경해야 하기 때문에 빅데이터를 다루는 정밀검정시스템에 적용하기 어렵다. 본 논문에서는 정밀검정시스템을 위한 식물체와 배경의 자동 분할이 가능한 합성곱 신경망(Convolution neural network: CNN) 구조를 제안한다. LeafNet은 9개의 컨벌루션 계층과 식물의 유무를 판단하기 위한 시그모이드(Sigmoid) 활성화 함수로 구성된다. LeafNet을 이용한 학습 결과, 식물 모종 영상에 대하여 정밀도 98.0%, 재현율 90.3%의 결과가 도출되어 정밀검정시스템의 적용 가능성을 확인하였다.",다국어 초록 정보 없음
자모 단위 합성곱 신경망 기반 맞춤법 오류가 포함된 자주 묻는 질문 자동 분류,2019,"['sentence classification', 'data with spelling errors', 'frequently asked questions', 'class embedding', '문장 분류', '맞춤법 오류가 포함된 데이터', '자주 묻는 질문', '클래스 임베딩']","웹이나 모바일 사용자는 홈페이지에 구축된 자주 묻는 질문 시스템(Frequently Asked Question: FAQ, 이하 FAQ)을 이용하여 원하는 정보를 얻는다. 기존 FAQ 시스템은 검색 모델을 기반으로 입력과 가장 유사하다고 판단되는 질의응답 후보를 사용자에게 보여준다. 하지만 검색 모델은 문서 색인에 의존하기 때문에 입력 문장의 맞춤법 오류에 취약하다. 따라서 본 논문에서는 FAQ 시스템을 문장분류기에 적용하여 맞춤법 오류를 최소화하는 모델을 제안한다. 자모 단위 합성곱 신경망을 이용한 임베딩 계층을 통해 사용자 입력의 맞춤법 오류를 줄이고, 클래스 임베딩과 전방 전달 신경망을 적용하여 분류기의 성능을 높였다. 제안 모델은 457개와 769개의 FAQ 클래스 분류에 대한 실험 결과로 Micro F1 score 기준 각각 81.32%p, 61.11%p의 높은 성능을 보였으며, 모델 예측의 신뢰도를 평가하기 위해 sigmoid 함수를 이용하여 신뢰도를 수치화했다.","Web and mobile users obtain the desired information using the frequently asked questions (FAQ) listed on the homepage. The FAQ system displays a query response candidate that is most similar to the input based on an information retrieval model. However, the information retrieval model depends on the index, and therefore, it is vulnerable to spelling errors in the sentence. This paper proposes a model applying the FAQ system to the sentence classifier, which minimizes the spelling errors. Using the embedded layer with jamo-based convolutional neural network, the spelling errors of the user input were reduced. The performance of the classifier was improved using class embedding and feed-forward neural network. As a result of 457 and 769 FAQ classifications, the Micro F1 score showed 81.32% p and 61.11% p performance, respectively. We used the sigmoid function to quantify the reliability of the model prediction."
랜섬웨어 방어를 위한 합성곱 신경망 기반의 데이터 암호화 탐지 기법,2019,"['ransomware', 'deep learning', 'convolutional neural network', 'computer security', '랜섬웨어', '딥러닝', '합성곱 신경망', '컴퓨터 보안']","최근 랜섬웨어에 의한 피해가 심각해짐에 따라, 랜섬웨어 공격을 실시간으로 감지하고 방어하는 기술 개발의 중요성이 높아지고 있다. 기존 랜섬웨어 탐지 기법의 한계를 극복하기 위해, 저장장치 내부 수준의 데이터 보존 및 복구 기법이 제안되었으나, 무분별한 데이터 보존으로 인해 저장공간 부하를 크게 증가시킬 수 있다는 한계점이 존재한다. 본 논문에서는 보존할 데이터를 정확하게 선정하면서도 피해 데이터를 온전하게 보존하기 위한, 합성곱 신경망 기반의 데이터 암호화 여부 판단 기법을 제시한다. 실험 결과, 제안한 기법은 저장장치 내부 수준에서 상위 계층의 정보 없이 93.90%의 높은 정확도로 데이터의 암호화 여부를 판단하였다. 또한, 손실 함수와 결정 경곗값을 수정하여 0에 가까운 부정 오류율을 달성하였다.","With the rapid increase in the number of ransomwares recently, the development of real-time strategies for ransomware defense is imperative. To overcome the limitations of traditional ransomware defense techniques, a storage-level data recovery technique was suggested. However, as the technique inefficiently selects data to conserve, it has a negative impact on the lifetime and performance of storage. In this paper, we propose a CNN-based encrypted data detection technique to enhance the accuracy of selecting data to conserve while ensuring complete data recovery. Our experiments show that the proposed technique achieved 93.90% detection accuracy at the storage-level without any high-level information. Furthermore, by changing the loss function and controlling a detection threshold, we attained a false negative rate of nearly 0."
스마트 팜을 위한 분할 인식 심층 합성곱 신경망 기반의 사과나무 잎사귀 질병 인식,2019,"['Smart Farm', 'Plant Disease', 'Deep Convolutional Neural Networks', 'Deep Feature Extraction', 'Feature Pooling']","이 논문에서는 분할 인식 심층 합성곱 신경망 기반의 사과나무 잎사귀 질병을 인식하는 기법을 제안하고자 한다. 주된 아이디어는 잎사귀 질병이 존재하는 영역이 잎사귀 안에 포함되는 반면 배경 영역에서는 질병과 관련된 정보가 없다는 것이다. 이 아이디어를 실현하고자 본 논문에서는 두 종류의 서브네트워크를 제시하고자 한다. 하나는 입력 영상을 배경 영역, 잎사귀 영역, 질병 영역으로 분할하기 위한 영상분할 서브네트워크이고 다른 하나는 입력 영상으로부터 질병의 종류를 예측하는 영상인식 서브네트워크이다. 실험 결과를 통해서, 예측된 영상분할 맵을 사용함으로써 기존의 VGG 네트워크에 비해 약 9%의 정인식률을 개선할 수 있었다.","A new method of recognizing apple leaf diseases via segmentation-aware deep convolutional neural network is proposed in this paper. The main idea is that leaf diseases exist in the leaf area, whereas background region has no information related to leaf diseases. To realize this idea, two subnetworks are designed. One is for the division of input image into background, leaf area, and disease area, and the other is for the prediction of leaf disease types. The experimental results show that correct recognition accuracy can be increased by 9% by using the predicted image segmentation map, compared to the VGG network."
자율주행 자동차의 기능 안전을 위한 합성곱 신경망 기반 상대 거리 예측 알고리즘 개발,2019,"['Autonomous vehicle(자율주행 자동차)', 'Convolutional neural network(합성곱 신경망)', 'Feature extraction(특징 추출)', 'Relative distance prediction(상대 거리 예측)', 'Functional safety(기능 안전)']",국문 초록 정보 없음,다국어 초록 정보 없음
자연어를 활용한 SQL문 생성을 위한 합성곱 신경망 기반 칼럼 예측 모델,2019,"['SQL', 'RDBMS', 'natural language processing', 'convolutional neural networks', 'SQL', '관계형 데이터베이스', '자연어 처리', '합성곱 신경망']","관계형 데이터베이스 시스템을 이용하여 대규모의 데이터를 검색하기 위해서는 테이블 스키마 및 SQL문을 이해해야 하는 필요성이 있다. 이를 해결하기 위해 자연어가 입력으로 주어질 때, 이에 대응하는 SQL문을 생성하는 연구가 최근 진행되고 있다. 기존 연구에서 가장 어려운 부분은 SQL문의 조건에 해당되는 칼럼을 효과적으로 예측하는 부분이며, 예측해야 하는 칼럼의 개수가 여러 개일 때 정확도가 크게 떨어지는 문제점이 있다. 본 논문에서는 칼럼 어텐션 메카니즘을 이용하여, 자연어 데이터의 숨겨진 표현을 효과적으로 추출하는 합성곱 신경망 모델을 제안한다. 본 연구의 제안 방법은 기존 방법 대비 약 6% 이상 정확도가 향상되는 것을 확인할 수 있었다.","To retrieve massive data using relational database management system (RDBMS), it is important to understanding of table schemas and SQL grammar. To address this issue, many studies have recently been carried out to generate an SQL query from a natural language question. However, the existing works suffer mostly from predicting columns at where clause and the accuracy is greatly reduced when there are multiple columns to be predicted. In this paper, we propose a convolutional neural network model with column attention mechanism that effectively extracts the latent representation of input question which helps column prediction of the model. The experiment shows that our model outperforms the accuracy of the existing model (SQLNet) by 6%."
빗줄기 방향과 강도를 고려한 심층 합성곱 신경망 기반의 빗줄기 제거 기법,2019,"['rain removal', 'residual networks', 'deep convolutional neural networks', 'sparse coding']","최근 인공지능 기술의 발달로 무인자동차, 무인드론 및 자율운항선박시스템 등이 개발되고 있다. 그러나 컴퓨터 비전 기반의 보행자 검출, 영상분할 같은 기법은 기상 환경에 상당한 영향을 받는다. 특히 비가 내리는 상황에서 영상을 획득할 때 캡처된 영상에서 빗줄기 패턴이 형성되고 이러한 빗줄기 패턴은 컴퓨터 비전 알고리즘에서 사용되는 특징 추출에 부정적인 영향을 줄 수 있다. 따라서 본 논문에서는 빗줄기의 강도와 방향을 고려한 심층 합성곱 신경망 기법을 제안하고자 한다. 특히 빗줄기 강도와 방향을 구별 짓기 위한 심층 합성곱 신경망과 빗줄기 타입 별 빗줄기 제거를 위한 잔차 네크워크 즉, 두 종류의 서브 네트워크를 학습해서 빗줄기를 제거하고자 한다. 제안한 기법을 적용할 때, 기존의 방법보다 빗줄기 제거와 디테일 보존 성능 측면에서 더 나은 결과를 얻을 수 있었으며 정량적 화질 평가에서도 우위를 달성할 수 있었다.","Recently, autonomous cars, autonomous drones, and self-driving ship systems are being developed, thanks to the development of artificial intelligence technologies However, computer vision algorithms such as pedestrian detections and image segmentations, are significantly affected by weather conditions. When capturing images in a rainy day, rain streaks are formed in the captured images, thereby having negative effects on feature extractors used in computer vision algorithms. Therefore, this paper proposes the deep convolution neural networks that consider the strength and orientation of rain streaks. More specifically, in this paper, two types of sub-networks are learned for rain streaks removal. One is to detect the strength and orientation of rain streaks and the other is to remove rain streaks via residual networks, which are trained optimally to each type of rain streaks. Experimental results show that the proposed method is more effective in removing rain streaks and preserving details than the conventional methods. Moreover, quantitative image quality assessments also show that the performance of the proposed method is superior to the conventional methods."
작물 분류를 위한 다중 규모 공간특징의 가중 결합 기반 합성곱 신경망 모델,2019,"['Crop classification', 'Convolutional neural network', 'Spatial feature', 'Image patch']","이 논문에서는 작물 분류를 목적으로 합성곱 신경망 구조에 다중 규모의 입력 영상으로부터 추출가능한 다양한 공간특징을 가중 결합하는 모델을 제안하였다. 제안 모델은 합성곱 계층에서 서로 다른 크기의 입력패치를 이용하여 공간특징을 추출한 후, squeeze-and-excitation block을 통해 추출한 공간특징의 중요도에 따라가중치를 부여한다. 제안 모델의 장점은 분류에 유용한 특징들을 추출하고 특징의 상대적 중요도를 분류에 이용하는데 있다. 제안 모델의 분류 성능을 평가하기 위해 미국 일리노이 주에서 수집한 다중시기 Landsat-8 OLI 영상을 이용한 작물 분류 사례연구를 수행하였다. 유용한 패치 크기 결정을 위해 먼저 단일 패치 모델에서 패치 크기가 작물 분류에 미치는 영향을 분석하였다. 그 후에 단일 패치 모델과 특징의 중요도를 고려하지 않는다중 패치 모델과 분류 성능을 비교하였다. 비교 실험 결과, 제안 모델은 연구지역에서 재배하는 작물의 공간특징을 고려함으로써 오분류 양상을 완화시켜 비교 모델들에 비해 가장 우수한 분류 정확도를 나타냈다. 분류에 유용한 공간특징의 상대적 중요도를 고려하는 제안 모델은 작물뿐만 아니라 서로 다른 공간특성을 보이는객체 분류에도 유용하게 적용될 수 있을 것으로 기대된다.","This paper proposes an advanced crop classification model that combines a procedure for weighted combination of spatial features extracted from multi-scale input images with a conventional convolutional neural network (CNN) structure. The proposed model first extracts spatial features from patches with different sizes in convolution layers, and then assigns different weights to the extracted spatial features by considering feature-specific importance using squeeze-and-excitation block sets. The novelty of the model lies in its ability to extract spatial features useful for classification and account for their relative importance. A case study of crop classification with multi-temporal Landsat-8 OLI images in Illinois, USA was carried out to evaluate the classification performance of the proposed model. The impact of patch sizes on crop classification was first assessed in a single-patch model to find useful patch sizes. The classification performance of the proposed model was then compared with those of conventional two CNN models including the single-patch model and a multi-patch model without considering feature-specific weights. From the results of comparison experiments, the proposed model could alleviate misclassification patterns by considering the spatial characteristics of different crops in the study area, achieving the best classification accuracy compared to the other models. Based on the case study results, the proposed model, which can account for the relative importance of spatial features, would be effectively applied to classification of objects with different spatial characteristics, as well as crops."
합성 곱 신경망을 이용한 서비스 거부 공격 탐지 기법 연구,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 이용한 언어장애인용 문장 인식,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 통한 드론의 장애물 회피 및 길 추적,2019,"['Trail following(길 추적)', 'Obstacle avoidance(장애물 회피)', 'Machine learning(기계학습)', 'Vision based control(영상 기반 제어)']",국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망 기반 밝기-색상 정보를 이용한 얼굴 위변조 검출 방법,2019,"['face anti-spoofing', 'luminance and chrominance', 'convolutional neural networks', 'attention module', 'contrast loss']",국문 초록 정보 없음,"In this paper, we propose the face anti-spoofing method based on combination of luminance and chrominance with convolutional neural networks. The proposed method extracts luminance and chrominance features independently from live and fake faces by using stacked convolutional neural networks and auxiliary networks. Unlike previous methods, an attention module has been adopted to adaptively combine extracted features instead of simply concatenating them. In addition, we propose a new loss function, called the contrast loss, to learn the classifier more efficiently. Specifically, the contrast loss improves the discriminative power of the features by maximizing the distance of the inter-class features while minimizing that of the intra-class features. Experimental results demonstrate that our method achieves the significant improvement for face anti-spoofing compared to existing methods."
합성곱 신경망을 이용한 Bender Gestalt Test 영상인식,2019,"['Bender Gestalt Test', 'Eye-writing', 'Pattern Recognition', 'Character Recognition', 'Dynamic Time Warping']",국문 초록 정보 없음,"This paper proposes a method of utilizing convolutional neural network to classify the images of Bender Gestalt Test (BGT), which is a tool to understand and analyze a person’s characteristic. The proposed network is composed of 29 layers including 18 convolutional layers and 2 fully connected layers, where the network is to be trained with augmented images. To verify the proposed method, 10 fold validation was adopted. In results, the proposed method classified the images into 9 classes with the mean f1 score of 97.05%, which is 13.71%p higher than a previous method. The analysis of the results shows the classification accuracy of the proposed method is stable over all the patterns as the worst f1 score among all the patterns was 92.11%."
합성곱 신경망을 이용한 보행자 머리상해치 예측기법 개발,2019,"['HIC(머리상해치)', 'NCAP(신차평가제도)', 'VRU Safety(보행자 안전)', 'Deep learning(심층 학습)', 'Pre-trained model(사전 학습 모델)']","보행자 관련 안전사고를 예방하고자 세계 각국에서는 NCAP제도를 활용하여 신차의 안전도를 평가하고있다. HIC는 교통약자(VRU)가 차량과 충돌하였을 때 받는 머리상해치를 의미한다. 기존 HIC예측을 위해선 후드상의 타격포인트에 대한 반복실험, 혹은 담당자의 경험적 판단 하에 성능인자를 추출하여 해석기법을 통해 예측하였다. 그러나 위와 같은 방법은 구조 변경마다 실험에 반복되는 공수소요가 발생하며, 경험적 판단에 의존함으로 객관성이 결여된다. 이에 본 연구에서는 인공지능 기법 중 딥 러닝의 CNN과 차량 설계도면, 그리고 충격 량 실험 값을 학습하여 딥 러닝을 이용한 HIC와 HIC 등급을 예측하며, Error rate, Top1-Acc등의 평가지표를 활용하여 성능을 검증한다.",다국어 초록 정보 없음
합성곱 신경망을 이용한 이동 물체 인식 및 6 축 로봇 매니퓰레이터 응용,2019,"['Manipulator', 'Object detection', 'ROS(Robot Operating Sytem)', 'Deep learning', 'Real-time control']",국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 활용한 전두엽 fNIRS 신호의 왼손-오른손 동작 구분,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망 기반 GPS L1 C/A 신호 검파기법,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망 기반의 블록화 노이즈 감소 기법,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 이용한 음절 피처맵 생성 및 감성 분석,2019,"['Sentiment Analysis', 'Text mining', 'Text classification']",국문 초록 정보 없음,"Sentiment analysis is a technique for analyzing subjective attitudes, opinions, and emotions of people in a text. When conducting sentiment analysis understanding the structure of the language used in the text is very important. In this paper, we noted the characteristics of the Korean language that a syllable consists of three elements: Initial sound, Intermediate sound, Final sound. Thus, we compare sentiment classification models that can reflect the characteristics. These models, which expresses syllables by combination of initial sound, intermediate sound, final sound. One of them is improved in classification accuracy over the existing character-level model. But not only that, This model is robust to the misspelled word compared to Syllable-level model and Morph-level model because it uses a character-level representation of a sentence as input."
합성곱 신경망 기반의 화면 내 예측 모드 결정,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 이용한 철강 표면영상의 결함 검출,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 통한 깊이 예측과 심층 강화학습을 활용한 소형 무인기의 충돌 회피,2019,"['Collision avoidance(충돌회피)', 'Reinforcement learning(강화학습)', 'Depth-estimation(깊이예측)', 'vision-based control(영상 기반 제어)', 'Machine learning(기계 학습)']",국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망 모형을 이용한 대전광역시 대덕대로 소통상황 예측,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 사용한 수술 후 통증 평가,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 이용한 프레임 동기 기법,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망 모델 기반의 폐기물 분류 시스템 연구,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 이용한 디지털 통신기 분류 알고리즘,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망 기반의 저조도 영상 개선,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 이용한 CPU 기반의 실시간 나이 및 성별 인식,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 이용한 생체신호기반 개인인증 모델링 연구,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망 구조를 이용한 문서 범주 관련 키워드 추출,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
그래프 합성곱 신경망을 이용한 부분 도메인 적응 기법,2019,[],국문 초록 정보 없음,"Domain adaptation is a technique that alleviates networks’ performance degradation on the target samples, which has a different distribution from the source samples. Since most existing domain adaptation methods assume that source and target domain contain the same labels, performance degradation occurs when the label set of the source and target are not the same. It is difficult to use existing domain adaptation techniques in real situations because generating the source domain with exactly the same label set as the target domain is ineffective. To solve this problem, partial domain adaptation methods have been attended, which exploit big data to construct the source domain and adapt it to the target domain included in the source label set. Although the existing partial domain adaptation methods show a great performance, these methods do not directly consider the data structure. Therefore, we propose graph partial domain adaptation networks, which apply a graph structure to the partial domain adaptation task. Specifically, we first construct a graph between feature maps extracted from the source and the target samples, and then adopt graph convolutional neural networks to consider relationships between different domains. After that, we train domain classifier to align the distribution of each category by using these feature maps. Our method, named as GPDA, achieves state-of-the-art performance on the Digit dataset and the Office-31 dataset."
3차원 합성곱 신경망을 활용한 실시간 전략 게임 승패 예측,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
다양한 합성곱 신경망 방식을 이용한 폐음 분류 방식의 성능 비교,2019,[],국문 초록 정보 없음,"In the diagnosis of pulmonary diseases, auscultation technique is simpler than the other methods, and lung sounds can be used for predicting the types of pulmonary diseases as well as identifying patients with pulmonary diseases. Therefore, in this paper, we identify patients with pulmonary diseases and classify lung sounds according to their sound characteristics using various convolutional neural networks, and compare the classification performance of each neural network method. First, lung sounds over affected areas of the chest with pulmonary diseases are collected by using a single-channel lung sound recording device, and spectral features are extracted from the collected sounds in time domain and applied to each neural network. As classification methods, we use general, parallel, and residual convolutional neural network, and compare lung sound classification performance of each neural network through experiments."
계층구조 합성곱 신경망 기반 고해상도 동영상 프레임 고속 보간 방법,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
그래프 합성곱 신경망을 이용한 세부 이미지 분류,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
빠른 영역-합성곱 신경망을 이용한 다중 스케일 보행자 검출 방법,2019,[],"최근에 딥러닝 기술을 적용한 보행자 검출 연구가 활발히 진행되고 있다. 연구자들은 딥러닝 네트워크를 이용하여 보행자 오검출율을 낮추는 방법에 대해 지속적으로 연구하여 성능을 꾸준히 상승시켰다. 그러나 대부분의 연구는 다중 스케일 보행자가 분포되는 저해상도 영상에서 보행자를 제대로 검출하지 못하는 어려움이 존재한다. 따라서 본 연구에서는 기존의 Faster R-CNN 구조를 기반으로 하여 새로운 다중 특징 융합 레이어와 다중 스케일 앵커 박스를 적용하여 보행자 오검출율을 줄이는 MS-FRCNN(Multi-scaleF aster R-CNN) 구조를 제안한다. 제안된 방식의 성능 검증을 위해 Caltech 데이터세트를 이용하여 실험한 결과, 제안된 MS-FRCNN 방식이 기존의 다른 보행자 검출 방식보다 다중 스케일 보행자 검출에서 medium 조건하에 5%, all 조건하에 3.9% 나아짐을 알 수 있었다.",다국어 초록 정보 없음
완전 합성곱 신경망을 활용한 드론 비행음 및 바람소리 제거,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
심층 합성곱 신경망에 기반한 이미지 바코드의 은닉 데이터 디코딩 기법,2019,"['halftoning', 'image barcode', 'sparse coding', 'image moment', 'deep convolutional neural networks']",국문 초록 정보 없음,"This paper proposes a method of decoding the hidden data from image barcodes. First, halftoned images are generated by applying two types of dithering matrixes to training images, and then labels are assigned to the extracted patches from the halftoned images. Next, the deep convolutional neural network that has similar architecture of the VGG-16 is learned via a stochastic gradient descent algorithm. Given the input image barcode, the proposed hidden data decoding can be completed by feeding the extracted patches from the image barcode into the already learned deep convolutional neural network, which enables the extracted patches to be classified by one of the two labels. Through the experiments, it is shown that the proposed method can achieve better results than the conventional methods. Especially, the correct recognition rates of 99% and 96% can be obtained for the digital and scanned image barcodes, respectively."
CFAR와 합성곱 신경망을 이용한 기두부와 단 분리 시 조각 구분,2019,"['micro motion', 'micro-Doppler spectrogram', 'CA-CFAR', 'convolutional neural networks', 'warhead', 'debris']",국문 초록 정보 없음,"Warhead and debris show the different micro-Doppler frequency shape in the spectrogram because of the different micro motion. So we can classify them using the micro-Doppler features. In this paper, we classified warhead and debris in the separation phase using CNN(Convolutional Neural Networks). For the input image of CNN, we used micro-Doppler spectrogram. In addition, to improve classification performance of warhead and debris, we applied the preprocessing using CA-CFAR to the micro-Doppler spectrogram. As a result, when the preprocessing of micro-Doppler spectrogram was used, classification performance is improved in all signal-to-noise ratio(SNR)."
다중 스트림 합성곱 신경망 기반의 뼈 나이 진단,2019,"['Deep Learning', 'Bone Age', 'Transfer Learning', 'Image Recognition']",국문 초록 정보 없음,다국어 초록 정보 없음
UWB 시스템에서 합성곱 신경망을 이용한 거리 추정,2019,[],국문 초록 정보 없음,"The paper proposes a distance estimation technique for ultra-wideband (UWB) systems using convolutional neural network (CNN). To estimate the distance from the transmitter and the receiver in the proposed method, 1 dimensional vector consisted of the magnitudes of the received samples is reshaped into a 2 dimensional matrix, and by using this matrix, the distance is estimated through the CNN regressor. The received signal for CNN training is generated by the UWB channel model in the IEEE 802.15.4a, and the CNN model is trained. Next, the received signal for CNN test is generated by filed experiments in indoor environments, and the distance estimation performance is verified. The proposed technique is also compared with the existing threshold based method. According to the results, the proposed CNN based technique is superior to the conventional method and specifically, the proposed method shows 0.6 m root mean square error (RMSE) at distance 10 m while the conventional technique shows much worse 1.6 m RMSE."
위성영상에 대한 합성곱 신경망 기반 의미 분할 분석 및 최적화,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
치과 파노라마 영상에서 합성곱 신경망을 이용한 자동적 치조골 수준 및 치아 검출,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
형태학적 이미지 처리를 통한 합성곱 신경망 기반의 위성영상 도로 검출 개선 기법,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
처프 시스템을 위한 합성곱 신경망 기반의 신호대잡음비 식별 기법,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
무인수상선의 도킹을 위한 합성곱 신경망 기반 상대위치추정 기법,2019,"['unmanned surface vehicle', 'autonomous surface vehicle', 'docking system', 'deep learning', 'convolutional neural network']",국문 초록 정보 없음,"This paper describes a convolutional neural network based localization method for docking of an unmanned surface vehicle. Based on the docking experiment of the USV model ship in an indoor, a basin and inland water, docking data which includes relative pose information and corresponding mono-camera perspective images are collected. Using the collected docking data, a VGG-19 based convolutional neural network model for relative pose estimation was trained. Constructed pose estimator can predict USV pose during the docking, within 0.23 m and 0.45 m and 2.73 degree of longitudinal, lateral and yaw angular RMS errors respectively. According to the validation result, we founded the possibility that the proposed method can substitute the GNSS based navigation when there exists a high level of bypass error due to the approaches of large scale structure or vessel, which USV often encounters during the docking."
천리안 위성 자료를 활용한 합성곱 순환 신경망 기반 태풍 최대풍속 산출,2019,"['Satellite', 'Typhoon', 'Intensity Estimation', 'Deep Learning', 'Convolutional Neural Network', 'Recurrent Neural Network']",국문 초록 정보 없음,"It is crucial to predict the intensity of typhoons since they cause massive casualties and damage in property. We propose a model for estimating the maximum wind speed of typhoons using Convolutional Recurrent Neural Network (CRNN). Compared to the current method in investigating typhoons which is fully subjected to the meteorologist’s analyzing skill and domain knowledge, the proposed model assists meteorologists to obtain the objective analysis of typhoons. In previous studies, they construct the model utilizing only CNN. However, our suggested model is built with CNN followed by LSTM to consider the fact that the typhoons occur sequentially. We train the model by using each single channel in COMS satellite data composed of IR1, IR2, WV, and SWIR. As a result, the CRNN model trained on WV shows the lowest RMSE error, which is 9.84knot."
실시간 영상분석을 이용한 합성곱 신경망 기반의 실내 연기 감지 연구,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
안저영상의 영역분할에 사용된 합성곱 신경망 방식의 혈관 조영 영상의 적용,2019,"['U-Net', 'CNN', 'Deep learning', 'retinal image', 'semantic segmentation']",국문 초록 정보 없음,다국어 초록 정보 없음
다중 스케일 시간 확장 합성곱 신경망을 이용한 방송 콘텐츠에서의 음성 검출,2019,"['speech detection', 'multi-scale time-dilated convolution', 'deep learning', 'broadcast data']",국문 초록 정보 없음,"In this paper, we propose a deep learning architecture that can effectively detect speech segmentation in broadcast contents. We also propose a multi-scale time-dilated layer for learning the temporal changes of feature vectors. We implement several comparison models to verify the performance of proposed model and calculated the frame-by-frame F-score, precision, and recall. Both the proposed model and the comparison model are trained with the same training data, and we train the model using 32 hours of Korean broadcast data which is composed of various genres (drama, news, documentary, and so on). Our proposed model shows the best performance with F-score 91.7% in Korean broadcast data. The British and Spanish broadcast data also show the highest performance with F-score 87.9% and 92.6%. As a result, our proposed model can contribute to the improvement of performance of speech detection by learning the temporal changes of the feature vectors."
UWB 시스템에서 1차원 합성곱 신경망 기반의 거리 추정,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
다채널 원형 마이크로폰 어레이에서 합성곱 신경망을 이용한 사건 음향의 도래각 예측,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
말벌 영상인식을 위한 심층 합성곱 신경망의 성능 평가,2019,"['Vespa hornets', 'Deep convolutional neural network', 'Deep learning', 'Classification']",국문 초록 정보 없음,"One of the serious factors for honeybee decline is due to the various attacks from Vespa hornets, indigenous and invaded. Population monitoring as well as the alerting systems is requested against the Vespa. Automated image recognition is the primary step for the unmanned autonomous monitoring system development. This study compared the recent deep convolutional neural network (DCNN) algorithms such as AlexNet, VGG19, GoogLeNet, and ResNet50 for the best model selection for classification of 3 Vespa species, V. mandarinia, V. crabro and V. velutina. To evaluate classification performance, accuracy was utilized after transfer learning on each DCNN. As a result, the ResNet50 showed the best in terms of accuracy after sufficient training of 100 epochs. If performance and speed are considered simultaneously, AlexNet could be the alternative. The real-time monitoring system for objects requires both localization and classification. And Vespa occurrence or population change would need rapid recognition for the objects. Therefore speedy image recognition based on the DCNN, which combines localization and classification for objects in an image, should be considered in the future works."
외래잡초 분류 : 합성곱 신경망 기반 계층적 구조,2019,"['exotic weeds', 'weed classification', 'hierarchical architecture', 'convolutional neural networks']",국문 초록 정보 없음,"Weeds are a major object which is very harmful to crops. To remove the weeds effectively, we have to classify them accurately and use herbicides. As computing technology has developed, image-based machine learning methods have been studied in this field, specially convolutional neural network(CNN) based models have shown good performance in public image dataset. However, CNN with numerous training parameters and high computational amount. Thus, it works under high hardware condition of expensive GPUs in real application. To solve these problems, in this paper, a hierarchical architecture based deep-learning model is proposed. The experimental results show that the proposed model successfully classify 21 species of the exotic weeds. That is, the model achieve 97.2612% accuracy with a small number of parameters. Our proposed model with a few parameters is expected to be applicable to actual application of network based classification services."
비용 효율적인 웨이퍼맵 패턴 분류를 위한 합성곱 신경망의 능동적 학습 방법,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
3D LiDAR 반사 강도 영상을 이용한 합성곱 신경망 기반 관심 객체 검출 방법,2019,"['object detection', 'convolution neural network', '3D LiDAR', 'intensity map']",국문 초록 정보 없음,다국어 초록 정보 없음
부분적인 스크린 영상 혼합을 통한 합성곱 신경망의 영상 인식 성능 향상,2019,[],국문 초록 정보 없음,"Data augmentation is a way of improving the generalization ability of deep neural networks by expanding their training data with pre-defined transformations. For image recognition tasks, traditional data augmentation methods transform an image by using simple techniques such as random horizontal flipping and cropping. However, several recent methods have been proposed to augment training data by linearly interpolating two images with arbitrary proportions. Although they can further improve the generalization ability, they use a randomly chosen mixing ratio throughout a pair of images, which may ignore their local characteristics. In this paper, we propose a novel data augmentation method that can vary the mixing ratio according to the local brightness. Our method partially blends two images with Screen blend mode. We have also shown that CNNs can be successfully trained, only with the blended inputs. Experimental results on the CIFAR-10 and CIFAR-100 datasets have shown that the proposed method yields superior performance than existing methods."
다양한 크기의 웨이퍼 맵 불량 감지를 위한 합성곱 신경망 - 전역 평균 풀링 기반 방법,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
Elastic Net 정규화와 초매개변수 탐색을 통한 합성곱 신경망의 희소성 유도 최적화 기법,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
의류 생산 작업량 측정을 위한 합성곱 신경망 알고리즘의 데이터 증강 연구,2019,"['Data augmentation', 'Convolutional neural network', 'CNN', 'Counting', 'Clothes']",국문 초록 정보 없음,다국어 초록 정보 없음
비용 효율적인 웨이퍼맵 패턴 분류를 위한 합성곱 신경망의 능동적 학습 방법,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
가변길이의 센서 데이터를 활용한 Self-attentive 합성곱 신경망 기반 반도체 불량 탐지 및 진단,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
분리된 2D 필터 은행으로 구성된 합성곱 인공신경망,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
가변길이의 센서 데이터를 활용한 Self-attentive 합성곱 신경망 기반 반도체 불량 탐지 및 진단,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
다양한 크기의 웨이퍼 맵 불량 감지를 위한 합성곱 신경망 - 전역 평균 풀링 기반 방법,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
스마트 팜을 위한 분할 인식 심층 합성곱 신경망 기반의 사과나무 잎사귀 질병 인식,2019,"['smart farm', 'plant disease', 'deep convolutional neural networks', 'deep feature extraction', 'feature pooling']",국문 초록 정보 없음,"A new method of recognizing apple leaf diseases via segmentation-aware deep convolutional neural network is proposed in this paper. The main idea is that leaf diseases exist in the leaf area. To realize this idea, two subnetworks are designed. One is for the division of input image into background, leaf area, and disease area, and the other is for the prediction of leaf disease types. The two subnetworks have architecture types of the encoder-decoder network and the VGG network, respectively, and then trained separately via transfer learning. Next, the two types of subnetworks are combined through a concatenation layer. In other words, to train the entire network in an end-to-end manner, the predicted image segmentation map is stacked on the top of the input image through the concatenation layer, and then fed into the image classification subnetwork. The experimental results show that correct recognition accuracy can be increased by 9% by using the predicted image segmentation map, compared to the VGG network."
"낮은 정합성, 적은 수량, 불균형 문제를 가진 학습데이터를 위한 합성곱 신경망 기반의 웨이퍼 맵 불량패턴 분류",2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
코어텐션 네트워크에서 대답 선택 문제를 위한 2차원 팽창된 합성곱 신경망 디자인,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
추가 시추위치 선정 과정에서 순차 학습을 이용한 다중모달 합성곱 신경망의 예측성능 향상,2019,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성 곱 신경망 기반 웹 응용 트래픽 분류 모델 설계,2019,"['트래픽 분류', '머신러닝', '합성 곱 신경망', '응용 트래픽', 'Traffic Classification', 'Machine Learning', 'Convolution Neural Network', 'Application Traffic']",국문 초록 정보 없음,다국어 초록 정보 없음
음색 러닝을 위한 합성 곱 신경망 모델 분석,2019,[],서로 다른 음성 데이터 분류를 위한 연구는 많이 진행되고 있지만 개인이 갖고 있는 목소리 또는 각 악기들이 갖고 있는 음색 러닝 연구는 부족한 실정이다. 본 논문에서는 음색 러닝을 위한 합성 곱 신경망 분석 연구를 진행한다. 음색이란 음정과 세기가 같을 경우에도 두 소리를 구분할 수 있는 복합적인 요소이다.,다국어 초록 정보 없음
잔류 합성 곱 신경망 기반의 코골이 식별 방식,2019,[],국문 초록 정보 없음,"Snoring is a typical symptom of sleep disorder and it is important to identify the occurrence of snoring because it causes sleep apnea. In this paper, we proposes a residual convolutional neural network as an efficient snoring identification algorithm. Residual convolutional neural network, which is a structure combining residual learning and convolutional neural network, effectively extracts features existing in data more than conventional neural network and improves the accuracy of snoring identification. Experimental results show that the performance of the proposed snoring algorithm is superior to that of the conventional methods."
정교한 이웃 노드 선택법을 활용한 그래프 합성곱 네트워크,2019,"['노드 분류', '그래프 합성곱 네트워크', '그래프 신경망', '그래프 마이닝', 'node classification', 'graph convolutional network', 'graph neural network', 'graph mining']","그래프 합성곱 네트워크(GCNs)는 합성곱 구조를 활용하여 주변 노드들의 정보를 종합하는 방식으로 대상 노드의 표현력을 높인다. 높은 성능을 보이기 위해서는 우선적으로 대상 노드에게 필요한 정보를 전달할 수 있는 주변 노드를 선별하고, 이후 학습시 적절한 필터(filter) 값을 습득하는 과정이 수반되어야한다. 최근 GCNs 알고리즘들은 1-hop 거리의 노드들을 선택하는 등의 비교적 간단한 이웃 노드 정의를 활용하고 있다. 이러한 경우 불필요한 정보가 대상 노드에 전파되어 성능을 저하하는 문제가 발생한다. 본 논문에서는 대상 노드와 주변 노드간의 유사도 계산을 통해 유효한 이웃 노드를 선별하여 활용하는 GCN 알고리즘을 제안한다.","Graph Convolutional Networks (GCNs) utilize the convolutional structure to obtain an effective insight on representation by aggregating the information from neighborhoods. In order to demonstrate high performance, it is necessary to select neighborhoods that can propagate important information to target nodes, and acquire appropriate filter values during training. Recent GCNs algorithms adopt simple neighborhood selection methods, such as taking all 1-hop nodes. In the present case, unnecessary information was propagated to the target node, resulting in degradation of the performance of the model. In this paper, we propose a GCN algorithm that utilizes valid neighborhoods by calculating the similarity between the target node and neighborhoods."
인공 신경망과 웨이블릿 변환을 이용한 주가 지수 예측,2019,"['웨이블릿 변환', '주가 지수 예측', '인공 신경망', '시계열 분석', 'wavelet transform', 'forecasting stock market price', 'artificial neural network', 'time series analysis']","기계학습 기술과 인공신경망 기술의 발전과 함께 주식시장의 흐름을 예측하려는 연구가 다양하게 시도되어 왔다. 특히 영상, 음성 처리를 위한 인공신경망 기술들이 주식시장 예측에 도입되어 예측의 정확도를 향상시키고 있다. 본 논문에서는 KOSPI의 지수변화와 방향성을 예측하기 위해 추출한 기술적 지표를 웨이블릿 변환을 이용하여 고주파수부분과 저주파수부분으로 나누어 인공신경망에서 각각 독립적으로 학습하고 예측한 다음, 고주파수부분과 저주파수부분을 합하여 지수와 방향성을 최종 예측하였다. 인공신경망으로 합성곱신경망, Dual Path Network 그리고 LSTM을 사용하여 인공신경망 간의 성능비교와 웨이블릿 변환의 효용성을 분석하였다. 지수예측에서는 합성곱신경망이 MAPE 0.51%, 등락예측에서는 LSTM이 정확도 81.7%로 최적의 결과를 보였고, 웨이블릿 변환으로 향상된 성능은 지수 예측의 경우 평균 38%, 등락 예측의 경우 평균 25%를 얻어 웨이블릿 변환의 효용성을 확인하였다.","With advancements in technologies on machine learning and artificial neural network, various researches have attempted to predict the changes in the price of the stock market. The prediction accuracy has improved with adoption of new artificial neural network technologies that have been developed for image and voice signal processing. In the present work, the technical indices from KOSPI were decomposed for the prediction of index and movement direction of KOSPI into high-frequency part and low-frequency part using wavelet transform, then used to predict KOSPI independently by using artificial neural networks. For the final prediction, the prediction result of each frequency part was added. CNN, DPN, and LSTM were employed as artificial neural network; the performance of each model was compared and the efficiency of the wavelet transform of input variables was analyzed. CNN with 0.51% of MAPE for the index prediction and LSTM with 81.7% of accuracy for movement prediction showed the best performance among the three models. The efficiency of wavelet transform was confirmed with averaged 38% of the improved performance for the index prediction and averaged 25% of the improved performance for the movement prediction."
심층 신경망을 이용한 자연어 지시의 실시간 시각적 접지,2019,[],"시각과 언어 기반의 이동(VLN)은 3차원 실내 환경에서 실시간 입력 영상과 자연어 지시들을 이해함으로써, 에이전트 스스로 목적지까지 이동해야 하는 인공지능 문제이다. 이 문제는 에이전트의 영상 및 자연어 이해 능력뿐만 아니라, 상황 추론과 행동 계획 능력도 함께 요구하는 복합 지능 문제이다. 본 논문에서는 시각과 언어 기반의 이동(VLN) 작업을 위한 새로운 심층 신경망 모델을 제안한다. 제안모델에서는 입력 영상에서 합성곱 신경망을 통해 추출하는 시각적 특징과 자연어 지시에서 순환 신경망을 통해 추출하는 언어적 특징 외에, 자연어 지시에서 언급하는 장소와 랜드마크 물체들을 영상에서 별도로 탐지해내고 이들을 추가적으로 행동 선택을 위한 특징들로 이용한다. 다양한 3차원 실내 환경들을 제공하는 Matterport3D 시뮬레이터와 Room-to-Room(R2R) 벤치마크 데이터 집합을 이용한 실험들을 통해, 본 논문에서 제안하는 모델의 높은 성능과 효과를 확인할 수 있었다.",다국어 초록 정보 없음
음성 분류 인공신경망을 활용한 자폐아 치료용 로봇의 지능화 동작 연구,2019,"['Autism Spectrum Disorders', 'Autistic Children Training', 'MFCC', 'Convolutional Neural Network', 'Speech Data Classification']",현재 아이들의 자폐스펙트럼장애 유병률이 한층 더 높게 보고되고 있으며 다양한 형태의 장애 징후를 보이고 있다. 특히 이들은 사회적 의사소통 영역에서 의사소통장애로 인한 대화에 어려움을 겪고 있으며 이를 훈련을 통해 개선 시킬 필요가 대두된다. 이를 위해 본 연구에서는 사전 연구를 통해 설계된 로봇에 장착된 마이크를 통해 음성 정보를 취득하고 이러한 정보를 이용하여 지능적인 동작을 만드는 방식을 제안한다. 음성 정보를 로봇 동작으로 분류하기 위해 인공신경망을 이용하였으며 여러 신경망 기법중 합성곱 방식을 기본으로 한 순환신경망을 결합하여 정확도를 향상시키려고 하였다. 입력 음성 데이터의 전 처리는 MFCC를 이용하여 분석하였으며 여러 데이터 정규화 및 인공신경망 최적화 기법을 활용하여 로봇의 동작을 추정하였다. 아울러 설계된 인공신경망은 기존에 사용한 구조 및 사람이 개입하여 분석하는 방법과의 정확도 비교 실험을 진행하여 분석 결과가 높은 정확도를 나타냈다. 향후 보다 높은 정확도를 가질 수 있는 로봇 동작을 설계하여 실제의 자폐아 치료 및 교육환경에서 적용할 수 있기 위하여 다양한 형태의 데이터를 수집하고 효율적으로 전처리하는 방식에 대한 연구가 요구된다.,"Currently, the prevalence of autism spectrum disorders in children is reported to be higher and shows various types of disorders. In particular, they are having difficulty in communication due to communication impairment in the area of social communication and need to be improved through training. Thus, this study proposes a method of acquiring voice information through a microphone mounted on a robot designed through preliminary research and using this information to make intelligent motions. An ANN(Artificial Neural Network) was used to classify the speech data into robot motions, and we tried to improve the accuracy by combining the Recurrent Neural Network based on Convolutional Neural Network. The preprocessing of input speech data was analyzed using MFCC(Mel-Frequency Cepstral Coefficient), and the motion of the robot was estimated using various data normalization and neural network optimization techniques. In addition, the designed ANN showed a high accuracy by conducting an experiment comparing the accuracy with the existing architecture and the method of human intervention. In order to design robot motions with higher accuracy in the future and to apply them in the treatment and education environment of children with autism."
< 구두-B-09 > 근적외선 스펙트럼을 이용한 부분 최소 자승 판별분석법과 인공신경망에 의한 목재 수종 구분,2019,[],"목재의 수종을 식별하기 위해 목재의 해부학적 세포 조직 비교 분석 또는 DNA 분석 등의 방법이 실시되고 있다. 그러나 두 방법 모두 시험편의 절단이 필요하고, 분석에 오랜 시간이 필요하며, 충분히 숙련된 전문가가 필요하다. 본 연구에서는 목재의 수종을 간편하고 신속하게 구분하기 위하여 근적외선 분광분석법과 인공신경망을 이용한 수종 구분 방법을 개발하였다. 국내 제재목 생산업에서 침엽수 소비량 중 대다수를 차지하고 있는 낙엽송(Larix kaempferi), 소나무(Pinus densiflora), 잣나무(Pinus koraiensis) , 삼나무(Cryptomeria japonica) 및 편백(Chamaecyparis obtusa)의 수종을 구분하기 위해 기건된 제재목에서 근적외선 스펙트럼을 측정하여 부분 최소 자승 판별 분석(Partial least squares discriminant analysis, PLS-DA) 및 인공신경망(Artificial neural network)에 의한 수종 구분을 실시하였다. 근적외선 스펙트럼의 수학적 전처리에 따라 PLS-DA 모델의 수종 구분 성능은 차이가 나타났다. 이 중, 가장 높은 신뢰도를 나타낸 Savitzky-Golay 2<sup>nd</sup> derivatives 전처리가 실시된 근적외선 스펙트럼을 이용한 PLS-DA 모델의 정확도는 95.2%, 최소 정밀도는 99.2%, 최소 재현율은 91.5%로 평가되었다. 근적외선 분광 분석법에서 사용되는 수학적 전처리에 대한 의존도를 낮추기 위하여 인공신경망 분류 알고리즘 중 신경망이 직접 수종 구분에 필요한 최적의 전처리 방법을 찾아나가는 1차원 합성곱 신경망을 이용한 수종 구분을 실시한 결과, 근적외선 스펙트럼의 수학적 전처리 정도에 상관없이 정확도, 정밀도 및 재현율이 모두 99.9% 이상으로 평가되었다.",다국어 초록 정보 없음
신경망 구조 탐색 기반 회전체 시스템 진단 기술 개발,2019,"['신경망 구조 탐색(Neural Architecture Search)', '건전성 진단(Health Diagnosis)', '합성곱 신경망(Convolutional Neural Networks)', '저널베어링 회전체 시스템(Journal Bearing Rotor System)', '딥러닝(Deep Learning)']",국문 초록 정보 없음,다국어 초록 정보 없음
Seq2SPARQL: 신경망 기계 번역을 사용한 지식 베이스 질의 언어 자동 생성,2019,[],국문 초록 정보 없음,"SPARQL(SPARQL Protocol and RDF Query Language)은 지식 베이스를 위한 표준 시맨틱 질의 언어이다. 최근 인공지능 분야에서 지식 베이스는 질의 응답 시스템, 시맨틱 검색 등 그 활용성이 커지고 있다. 그러나 SPARQL 과 같은 질의 언어를 사용하기 위해서는 질의 언어의 문법을 이해하기 때문에, 일반 사용자의 경우에는 그 활용성이 제한될 수밖에 없다. 이에 본 논문은 신경망 기반 기계 번역 기술을 활용하여 자연어 질의로부터 SPARQL 을 생성하는 방법을 제안한다. 우리는 제안하는 방법을 대규모 공개 지식 베이스인 Wikidata 를 사용해 검증하였다. 우리는 실험에서 사용할 Wikidata 에 존재하는 영화 지식을 묻는 자연어 질의-SPARQL 질의 쌍 20,000 건을 생성하였고, 여러 sequence-to-sequence 모델을 비교한 실험에서 합성곱 신경망 기반의 모델이 BLEU 96.8%의 가장 좋은 결과를 얻음을 보였다."
트리 기반 컨볼루션 신경망을 이용한 BigCloneBench 개선,2019,"['코드 클론', '클론 검사', '기계 학습', '벤치마크', '합성곱 신경망', 'code clone', 'clone checking', 'machine learning', 'benchmark', 'Convolutional Neural Network']",국문 초록 정보 없음,"BigCloneBench has recently been used for performance evaluation of code clone detection tool using machine learning. However, since BigCloneBench is not a benchmark that is optimized for machine learning, incorrect learning data can be created. In this paper, we have shown through experiments using machine learning that the set of Type-4 clone methods provided by BigCloneBench can additionally be found. Experimental results using Tree-Based Convolutional Neural Network show that our proposed method is effective in improving BigCloneBench’s dataset."
열화상 영상 잡음 제거를 위한 효율적인 잡음 제거 블록 기반의 신경망,2019,"['image denoising', 'convolutional neural networks', 'thermal image', 'laplace noise', 'receptive field', 'residual leraning']","열화상 카메라는 제한된 열화상 해상도로 인해 잡음이 있는 영상을 야기한다. 본 논문에서는 잡음 문제를 해결하기 위해 반복 가능한 인셉션-레지듀얼 블록(IRB)으로 이루어진 새로운 딥러닝 기반의 신경망을 제안한다. 각각의 IRB는 원본 이미지에 대하여 서로 다른 수용 영역을 가진 합성곱 층 2개를 가지고 베니싱 그레디언트(vanishing gradient)를 방지하기 위한 하나의 쇼트 컷(shortcut connection)으로 구성된다. 제안된 방법은 12개의 열화상 이미지로 테스트가 이루어졌다. 실험 결과, 제안된 방법은 최신의 잡음 제거 방법인 DnCNN과 비교해 봤을 때 신호대잡음비(PSNR)를 39.57에서 40.26으로 처리속도는 1.5910초에서 0.7508초로 잡음 제거 성능 및 처리 속도 개선을 보여준다.","Thermal cameras show noisy images due to their limited thermal resolution, especially for the scenes of a low-temperature difference. In order to deal with a noise problem, this paper proposes a novel neural network architecture with repeatable denoising inception-residual blocks(DnIRB) for noise learning. Each DnIRB has two sub-blocks with difference receptive fields and one shortcut connection to prevent a vanishing gradient problem. The proposed approach is tested for 12 thermal images. The experimental results indicate that the proposed approach shows the PSNR performance is increased 39.57 to 40.26 and processing time also is reduced 1.5910 to 0.7508 compared with state-of-the-art denoising methods which is called DnCNN."
위상수학적 데이터 분석과 심층 학습을 이용한 VLBI 시계열 데이터 분석,2019,[],"지구회전운동 물리량에 대한 정밀한 분석은 지구환경 변화의 이해와 장 · 단기적 기후변화 예측에 필수적인 요소이다. 초장기선 간섭계에 의한 관측(VLBI)의 발전은 굉장히 정밀한 지구 극 운동의 관측을 가능하게 해주었다. 이 연구에서는 VLBI 데이터에서 발생하는 이상 움직임을 위상수학적 데이터 분석과 심층 학습을 이용하여 탐지하는 정확하고 효율적인 방법을 제안한다. 푸리에 분석법과 스펙트로그램 분석법 등과 같은 전통적인 신호 분석 방법은 선형적인 모형에 국한되는 한계가 있지만, 본 연구에서 제안하는 방법은 이를 보완하여 보다 더 일반적인 형태의 신호까지로도 확장될 수 있다. 위상수학적 데이터 분석과 합성곱신경망을 이용한 지구회전운동 잔차 분석 결과를 통해 본 연구에서 제안한 방법이 VLBI 데이터에 대해 잘 작동하고 유의미한 결과를 도출하는 것을 보여준다.",다국어 초록 정보 없음
Fast R-CNN을 이용한 객체 인식 기반의 도로 노면 파손 탐지 기법,2019,"['도로 노면 파손', '심층 신경망', '유지보수', '영역 기반 합성곱', '객체 인식', 'Road surface damage', 'Deep neural network', 'Road maintenance', 'Region based convolutional neural networks', 'Object recognition']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN 을 이용한 단일영상 고해상도 복원 및 수용영역 확장을 통한 성능 향상,2019,[],"합성곱 신경망의 성능이 증가하면서 다양한 영상 처리 문제를 해결하기 위해 합성곱 신경망을 적용한 시도들이 증가하고 있다. 고해상도 복원 문제도 그 중 하나였으며, 보다 높은 성능을 얻기 위해 주로 신경망의 깊이를 깊게 하는 시도들이 있었다. 본 논문에서는 고해상도 복원 작업을 위한 합성곱 신경망의 성능 향상을 위해 깊이를 증가시키는 접근법이 아닌 수용영역을 확장시키는 접근법을 시도하였다. 논문에서 제시한 모델은 신경망 내부에 두 개의 브랜치를 두어, 하나의 브랜치는 Dilated Convolution 을 이용해 수용영역을 확장하는데 사용되며, 다른 하나는 이 브랜치를 통해 나온 feature 를 가공하는데 사용된다. 기본 모델은 EDSR 을 사용하였으며, 최종적으로 4.79M 의 파라미터로 평균 32.46dB 의 PSNR 을 보여주었다. 하지만 모델의 구조가 복잡하여 깊이를 늘이는 접근법을 적용하기 어렵다는 한계점이 있다.",다국어 초록 정보 없음
딥러닝에 의한 객체인식 향상을 위한 학습 데이터의 효과적 구성: Mask R-CNN을 중심으로,2019,"['딥러닝', '합성곱 신경망', 'Mask R-CNN', '학습 데이터']",인공지능을 실현하기 위한 딥러닝(DL)은 최근 컴퓨팅 파워가 향상됨에 따라서 여러 분야에서 활용되고 있다. 합성곱 신경망(CNN: Convolutional Neural Network)은 영상 학습을 위한 대표적인 DL모델이다. CNN에서 발전된 영역기반 합성곱 신경망(R-CNN: Region- based Convolutional Neural Network)은 객체가 존재하는 영역을 탐지하고 객체를 인식하는 DL 모델이다. 본 연구에서는 R-CNN 중 가장 최근에 개발된 Mask R-CNN의 학습 데이터를 효과적으로 구성하여 건물의 인식 정확도를 높일 수 있는 방안을 제시하였다.,다국어 초록 정보 없음
GPR 히트맵 이미지 데이터 기반 CNN을 이용한 철근 두께 예측에 관한 연구,2019,"['GPR', 'B-scan', '히트맵', '합성곱 신경망', '철근', '두께', 'Ground Penetrating Radar', 'B-scan', 'heatmap', 'Convolution Neural Network', 'Rebar Thickness']","본 논문에서는 시설물 내부 철근 두께를 예측하기 위해 GPR 데이터를 활용한 철근 두께 예측 기법에 관한 연구를 실시하였다. 국내의 규격 미달 철근의 사용 및 배근 시공과 같은 부실시공 사례에서 볼 수 있듯이, 구조물 정밀진단을 위해서 철근 두께에 대한 정보는 정밀 안전진단을 위해서 꼭 필요함을 알 수 있다. 이를 위해 본 연구에서는 시편을 제작하여 철근 직경을 단계적으로 증가시켜 GPR의 B-scan 데이터를 취득하였다. GPR 의 B-scan 데이터는 가시성이 떨어지기 때문에 이를 migration을 통해 히트맵 이미지 데이터로 변화시켜 데이터의 직관성을 높이고자 하였다. 본 연구는 보편적으로 이용되는 B-scan 데이터와 히트맵 데이터의 합성곱 신경망(CNN) 적용 시 결과를 비교하기 위해 B-scan 및 히트맵 데이터에서 각각 철근에 대한 영역을 추출하여 학습 및 검증 데이터를 구축하였으며, 구축된 데이터에 CNN을 적용하였다. 그 결과, 히트맵 데이터의 경우 B-scan 데이터와 비교하였을 때 더 좋은 결괏값을 얻을 수 있었다. 이를 통해 GPR 히트맵 데이터를 이용하였을 경우 B-scan 데이터를 이용하였을 때보다 더 높은 정확도로 철근 두께를 예측할 수 있음을 확인하였으며, 시설물 내부 철근 두께 예측의 가능성을 검증하였다.","In this paper, a study was conducted on the method of using GPR data to predict rebar thickness inside a facility. As shown in the cases of poor construction, such as the use of rebars below the domestic standard and the construction of reinforcement, information on rebar thickness can be found to be essential for precision safety diagnosis of structures. For this purpose, the B-scan data of GPR was obtained by gradually increasing the diameter of rebars by making specimen. Because the B-scan data of GPR is less visible, the data was converted into the heatmap image data through migration to increase the intuition of the data. In order to compare the results of application of commonly used B-scan data and heatmap data to CNN, this study extracted areas for rebars from B-scan and heatmap data respectively to build training and validation data, and applied CNN to the deployed data. As a result, better results were obtained for the heatmap data when compared with the B-scan data. This confirms that if GPR heatmap data are used, rebar thickness can be predicted with higher accuracy than when B-scan data is used, and the possibility of predicting rebar thickness inside a facility is verified."
수도 레이블을 활용한 준지도 학습 기반의 도로노면 파손 탐지,2019,"['Road surface damage', 'Semantic segmentation', 'Convolutional neural network', 'Semi-supervised learning', '도로노면 파손', '의미론적 분할', '합성곱 신경망', '준지도 학습']","의미론적 분할 형태로 합성곱 신경망을 구성하여 도로노면의 파손을 탐지하는 연구가 진행되고 있다. 이러한 합성곱 신경망 형태의 모델을 생성하기 위해서는 입력 이미지와 이에 상응한 레이블된 이미지 데이터셋으로 수집해야 하고, 이러한 과정에서는 굉장히 많은 시간과 비용이 발생하게 된다. 본 논문에서는 이러한 작업을 완화하기 위하여 수도 레이블링을 활용한준지도 학습 기반의 도로노면 파손 탐지 기술을 제안하고자 한다. 레이블된 데이터셋과 레이블되지 않은 데이터셋을 적절하게 혼합하여 도로노면 파손을 탐지하는 모델을 업데이트하고, 이를 레이블된 데이터셋만을 활용한 기존 모델과 성능을 비교한다. 주관적인 성능결과, 민감도부분에서는 조금 저하된 성능을 보였지만, 정밀도 부분에서는 대폭 성능 향상이 있었으며, 최종적으로 F1-score 또한 높은 수치로 평가되었다.","By using convolutional neural networks (CNNs) based on semantic segmentation, road surface damage detection has being studied. In order to generate the CNN model, it is essential to collect the input and the corresponding labeled images. Unfortunately, such collecting pairs of the dataset requires a great deal of time and costs. In this paper, we proposed a road surface damage detection technique based on semi-supervised learning using pseudo labels to mitigate such problem. The model is updated by properly mixing labeled and unlabeled datasets, and compares the performance against existing model using only labeled dataset. As a subjective result, it was confirmed that the recall was slightly degraded, but the precision was considerably improved. In addition, the F1-score was also evaluated as a high value."
Word2Vec과 2계층 양방향 장단기 기억 네트워크를 이용한 특허 문서의 자동 IPC 분류,2019,"['텍스트 마이닝', '문서 분류', '순환 신경망', 'text mining', 'document classification', 'recurrent neural network']","자연어 처리를 이용한 문서 분류 분야에서도 전통적인 방법에서 벗어나 단어 임베딩을 활용한 합성곱 신경망과 순환 신경망 등 심층 신경망을 이용한 다양한 연구가 진행되고 있다. 본 논문에서는 Word2Vec과 두 개의 계층으로 구성된 양방향 장단기 기억 네트워크를 이용한 특허 문서의 IPC(International Patents Classification) 자동 분류 모델을 제안한다. IPC는 세계지식재산권기구에서 제정한 국제적으로 통일된 특허 분류 기준이며, 각 국가의 공인된 기관에서 수작업으로 분류하고 있다. IPC 자동 분류를 위하여 입력 시퀀스에 Word2Vec을 이용한 단어 임베딩가중치를 사용한다. 그리고 가중치가 부여된 시퀀스를 두 개의 계층을 갖는 깊은 구조의 양방향 장단기 기억 네트워크 신경망에 입력하여 IPC를 분류한다. 실험 결과 특허 문서의 분류 정확도가 합성곱 신경망 보다는 약 7% 향상되었으며, 순환 신경망을 단일로 이용하는 것 보다는 약 5% 향상된 것을 확인할 수 있었다. 또한 전통적인 방법인 나이브 베이시안, 로지스틱 분류 및 서포트 벡터 머신보다는 5~12% 이상 우수한 성능을 나타내었다.","There are various studies using Deep Neural Network such as CNN(Convolutional Neural Network) and RNN(Recurrent Neural Network) that utilize word embedding in document classification using natural language processing out of traditional methods. In this paper, we propose the IPC(International Patents Classification) automatic classification model of patent documents using two layers BLSTM(Bidirectional Long Short Term memory) network. The IPC is an internationally uniform standard for patent classification established by the World Intellectual Property Organization and is categorized by hand in authorized agencies in each country. For the IPC automatic classification, we use word embedding weight with Word2Vec in the input sequences. And they are classified by entering a weighted sequences into a deep neural network with two layers BLSTM. The experimental results showed that the accuracy of classification is improved by about 7% than that of CNN, and about 5% than that of single layer LSTM that is a field of RNN. Also it showed more than 5~12% higher performance than traditional methods such as Naive Bayes, Logistic and Support Vector Machine classification."
지능형 관광 서비스를 위한 관광 사진 분류체계 개발,2019,"['플리커', 'SNS', '관광목적 사진 분류체계', '딥러닝', '합성곱신경망', '한국 관광', 'Flickr', 'Social Network Service', 'Photo Classification for Tourist purpose', 'Deep Learning', 'Convolutional Neural Network', 'Korea Tour']","최근 딥러닝 기술 가운데 이미지데이타 분석에 뛰어난 성능을 보이는 합성곱신경망 기술의 발전은 이미지 분석 영역에서다양한 가능성을 제시하고 있다. 관광객이 게시한 사진을 딥러닝 기술을 이용하여 분류하기 위해서는 관광사진에 대한 분류와목적에 맞는 딥러닝 모델의 훈련작업이 필수적으로 선행되어야 한다. 본 연구에서는 관광객이 플리커에 게시한 사진을 효율적으로분류하기 위해 관광목적으로 사진이 어떻게 분류되어야 하는지 관광목적 사진분류 체계를 개발하고자 하였다. 관광목적 사진분류 카테고리 개발을 위해 문헌분석, 웹사이트 분석, 관광객이 게시한 약 38,000장 사진의 검토과정을 거쳐 사진 분류 카테고리를개발하였으며, 약 8400장의 사진을 개발된 카테고리에 맞춰 분류해 봄으로써 개발된 카테고리의 검증과정을 거쳤다. 이 과정을거쳐 최종으로 제안된 카테고리는 13개 대분류, 64개 중분류, 164개의 세분류 체계를 갖으며, 본 연구 결과는 향후 관광목적사진을 딥러닝 모델을 이용하여 분류하고자 할 때 기초자료로 활용될 것으로 기대된다.","In recent years technology of Convolutional Neural Network (CNN) among the technologies of deep learning has evolved dramatically and has shown an outstanding performance in the analysis of image data. First of all, the training of deep learning model is prerequisite to classify the photos posted by the tourists on Web by applying CNN technology. In this study we aim to develop the photo classification system in view of travel purpose in order to classify the photos posted by tourists on Flickr. We developed the category for photo classification by reviewing around 38,000 photos posted by tourists as well as by analysing literatures and web sites, and then verified the category by classifying 8,400 photos one by one manually according to the category developed. The category we developed has 3 hierarchical levels such as 13 major classification, 64 medium classification and 164 minor classification. We expect that our study can applied in base material when one tries to classify the photos for travel purpose by using the CNN deep learning model."
심전도 신호의 커플링 이미지를 이용한 개인 인식 방법,2019,"['Personal Recognition', 'Electrocardiogram', 'Coupling Image', 'Convolutional Neural Network', '개인 인식', '심전도', '커플링 이미지', '합성곱 신경망']","심전도 신호는 위조가 불가능하며 양쪽 손목에서 신호를 간편히 취득할 수 있는 장점이 있다. 본 논문에서는 심전도 신호의 방향 정보를 이용해 커플링 이미지를 생성하고, 이를 이용한 개인 인식 방법을 제안한다. 제안하는 커플링 이미지는 정방향 심전도 신호와 R-peak를 기준으로 회전된 역방향 심전도 신호를 이용해 생성하며, 생성한 커플링 이미지는 개인별로 고유한 패턴과 명암을 나타낸다. 또한 같은 주기의 심전도 신호 연산을 통해 R-peak 영역 데이터가 증가하여 개인 인식 성능 향상이 가능하다. 생성한 커플링 이미지는 제안한 합성곱 신경망을 이용해 패턴 및 명암에 대한 특징을 추출하며, 네트워크 속도 향상을 위해 다수의 풀링층을 사용해 데이터 크기를 축소한다. 실험은 47명의 공개된 심전도 데이터를 이용하며, 공개된 네트워크 중 top-5 성능이 상위권인 5개 네트워크와 제안한 네트워크를 이용해 비교 실험을 진행한다. 실험 결과 제안한 네트워크의 개인 인식 성능이 99.28%로 가장 높게 나타남에 따라, 제안한 커플링 이미지를 이용한 개인 인식 방법이 유효함을 확인하였다.","Electrocardiogram (ECG) signals cannot be counterfeited and can easily acquire signals from both wrists. In this paper, we propose a method of generating a coupling image using direction information of ECG signals as well as its usage in a personal recognition method. The proposed coupling image is generated by using forward ECG signal and rotated inverse ECG signal based on R-peak, and the generated coupling image shows a unique pattern and brightness. In addition, R-peak data is increased through the ECG signal calculation of the same beat, and it is thus possible to improve the recognition performance of the individual. The generated coupling image extracts characteristics of pattern and brightness by using the proposed convolutional neural network and reduces data size by using multiple pooling layers to improve network speed. The experiment uses public ECG data of 47 people and conducts comparative experiments using five networks with top 5 performance data among the public and the proposed networks. Experimental results show that the recognition performance of the proposed network is the highest with 99.28%, confirming potential of the personal recognition."
딥러닝기반 다중 표적 인식을 활용한 모바일 로봇 경로 계획,2019,"['표적인식', '경로계획', '장애물 회피', '딥러닝', '모바일 로봇', 'Taget Detection', 'Path Planning', 'Avoidance Obstacle', 'Deep-Learning', 'Mobile Robot']","복합적인 고차원의 임무를 수행하기 위하여 미래무인화 전투 체게는 인공지능 기술을 필요로 한다. 특히 합성곱 신경망은 영상뿐만 아니라 자연어 처리까지 광범위한 범위에서 탁월한 성능을 보이고 있어 무인화 전투체계의 표적정보인식, 피아식별, 전장정보인식 등 각종 센서 융합에 매우 적합하다. 본 연구에서는 합성곱 신경망의 영상인식 기술을 활용하여 다수 대상체의 상태정보를 인식함으로써 변화되는 환경에서의 무인로봇 경로 계획 개선 방안을 제시하였고 시뮬레이션을 통하여 추정된 로봇의 위치, 장애물, 목표물 정보로부터 로봇의 경로 계획의 유효성을 검증 하였다.","Unmmanned systems are one of the essential areas of future military weapons systems that must carry out dangerous and cmplex missions. Especially, deep learning should recognize many landmarks through the image and project them onto the map to improve the problem of position estimation, because it shows excellent performance of recognizing and classifying the characteristics of image data among other artificial intelligence techniques. In this study, the path planning of the unmanned reconnaissance aircraft and the unmanned ground vehicle, which are currently being used in the ROK military, is linked with the CNN based multi target recognition algorithm without GPS. Throuth experiments, we verified the effectiveness of the path planning of the mobile robot with respect to the position of the robot, obstacle, and target point estimated by the target detection algorithm."
K-means 클러스터링 방법과 유사도 측정 기반의 채팅 말뭉치 반자동 확장 방법,2019,"['chatting system', 'semi-automatic expansion', 'similarity', 'convolutional neural networks', 'utterance embedding', '채팅 시스템', '반자동 확장', '유사도', '합성곱 신경망', '발화 단위 표상']","본 논문에서는 영화 자막, 극 대본과 같이 대량의 발화 데이터를 이용하여 채팅 말뭉치를 반자동으로 확장하는 방법을 제안한다. 채팅 말뭉치 확장을 위해 미리 구축된 채팅 말뭉치와 유사도 기법을 이용하여 채팅 유사도를 구하고, 채팅 유사도가 실험을 통해 얻은 임계값보다 크다면 올바른 채팅 쌍이라고 판단하였다. 본 논문에서 제안하는 것은 형태소 단위 임베딩 벡터와 합성곱 신경망 모델을 이용하여 발화 단위 표상을 생성하는 것이다. 그리고 반자동 구축 모델의 속도를 개선하기 위해서 K-means 클러스터링 방법을 적용하여 채팅 말뭉치를 군집, 계산량을 줄일 것을 제안한다. 그 결과 기본 발화 단위 표상 생성 방법인 TF를 이용하는 것보다 정확률, 재현율, F1에서 각각 5,16%p, 6.09%p, 5.73%p 각각 상승하여 61.28%, 53.19%, 56.94%의 성능을 도출하였다. 그리고 속도 개선을 위해 발화를 클러스터링하여 속도 면에서도 103배 향상된 채팅 말뭉치 반자동 구축 모델을 구축할 수 있었다.","In this paper, we proposed a semi-automatic expansion method to expand a chatting corpus using a large amount of utterance data from movie subtitles and drama scripts. To expand the chatting corpus, the proposed system used previously constructed chatting corpus and a similarity measure. If the similarity is calculated between a previously constructed chatting corpus and the input utterance was greater than a threshold value set in the experiment, the input utterance was selected as a new chatting utterance, that it is a correct chatting pair. We used morpheme-unit word embeddings and a Convolutional Neural Networks to efficiently calculate the similarity of the utterance embedding. In order to improve the speed of the semi-automatic expansion process, we proposed to reduce the amount of computation by clustering chat corpus by K-means clustering algorithm. Experimental results showed that the precision, recall, and F1 score of the proposed system were 61.28%, 53.19%, and 56.94%, respectively, which was 5.16%p, 6.09%, and 5.73%p higher than that of the baseline system. The term frequency and the speed of our system were also about a hundred times faster."
정형 데이터와 비정형 데이터를 동시에 고려하는 기계학습 기반의 직업훈련 중도탈락 예측 모형,2019,"['Vocational Training', 'Dropout', 'Machine Learning', 'Convolutional Neural Network', 'Word2vec', '직업훈련 교육', '중도탈락', '기계학습', '합성곱 신경망', 'Word2vec']","직업훈련 교육 현장에서 느끼는 가장 큰 어려움 중 하나는 중도탈락 문제이다. 훈련과정마다 많은 수의 학생들이 중도탈락을 하게 되어 국가 예산 낭비 및 청년 취업률 개선에 장애 요인이 되고 있다. 본 연구에서는 중도탈락의 원인을 주로 분석한 기존 연구들과 달리, 각종 수강생 정보를 활용하여 사전에 중도탈락을 예측할 수 있는 기계학습 기반 모형을 제안하고자 한다. 특히 본 연구의 제안모형은 수강생 관련 정형 데이터 뿐 아니라 비정형 데이터인 강사의 상담일지 정보까지 동시에 고려하여 모형의 예측정확도를 제고하고자 하였다. 이 때 비정형 데이터에 대한 분석은 최근 주목받고 있는 텍스트 분석 기술인 Word2vec과 합성곱 신경망을 이용해 수행하였다. 국내 한 직업훈련기관의 실제 데이터에 제안모형을 적용해 본 결과, 정형 데이터만을 사용하여 중도탈락을 예측할 때보다 비정형 데이터를 함께 고려했을 때 예측의 정확도가 최대 20%까지 향상됨을 확인할 수 있었다. 아울러, Support Vector Machine을 기반으로 정형 데이터와 비정형 데이터를 결합해 분석했을 때, 검증용 데이터셋 기준으로 90% 후반대의 높은 예측 정확도를 나타냄을 확인하였다.","One of the biggest difficulties in the vocational training field is the dropout problem. A large number of students drop out during the training process, which hampers the waste of the state budget and the improvement of the youth employment rate. Previous studies have mainly analyzed the cause of dropouts. The purpose of this study is to propose a machine learning based model that predicts dropout in advance by using various information of learners. In particular, this study aimed to improve the accuracy of the prediction model by taking into consideration not only structured data but also unstructured data. Analysis of unstructured data was performed using Word2vec and Convolutional Neural Network(CNN), which are the most popular text analysis technologies. We could find that application of the proposed model to the actual data of a domestic vocational training institute improved the prediction accuracy by up to 20%. In addition, the support vector machine-based prediction model using both structured and unstructured data showed high prediction accuracy of the latter half of 90%."
CNN 기반 전이학습을 이용한 음성 감정 인식,2019,"['Speech Emotion Recognition', 'Transfer Learning', 'Deep Learning', 'Convolutional Neural Networks', '음성 감정 인식', '전이학습', '딥러닝', '합성곱 신경망']","로봇은 사람의 편의를 위해 존재하므로 사람과 로봇의 상호작용은 중요하다. 로봇이 사람의 감정을 파악하는 것은 여러상호작용 중 하나이다. 최근 사람의 음성으로 감정을 인식하는 음성 감정 인식(speech emotion recognition; SER)분야는딥러닝 (deep learning)의 접목으로 그 성능이 향상되고 있다. 하지만, 데이터의 부족으로 깊은 신경망을 사용하거나추가적인 학습 기법을 적용하지 않고서는 높은 정확도를 기대하기 힘들다. 본 논문에서는 데이터가 부족할 때 사용하는 학습기법 중의 하나인 전이학습 (transfer learning)을 SER에 적용한 효과를 확인한다. 딥러닝을 적용하기 위해 합성곱 신경망(convolutional neural networks; CNN) 구조를 사용한다. 전이학습에 음성 감정 데이터가 아닌 일반 소리 데이터를 사용하여데이터 개수에 대한 한계를 없앤다. 전이학습 중 특징 추출기 (feature extractor)로써 사용한 경우와 미세조정 (fine tuning)을한 경우로 나누어 결과를 확인한다. 그 결과, 미세조정한 경우 수렴 시간이 약 20% 줄었고, 특징 추출기로써 사용한 경우 약20%에서 70% 줄었다. 정확도는 특징 추출기로써 사용한 경우 오히려 정확도가 감소하는 경우가 발생하였고 증가한 경우 약3% 증가했다. 미세조정을 한 경우 정확도가 평균적으로 약 7% 향상되었다","Interaction between human and robot is important because robots exist for the convenience of people. Robot grasping human emotions is one of many interactions. The field of SER (speech emotion recognition) has been improved by combining deep learning. The lack of data makes it difficult to expect high accuracy without using deep neural networks or applying additional learning techniques. In this paper, we confirm the effect of applying the transfer learning, which is one of the learning methods used when there is insufficient data, to SER. For deep learning, CNN (convolutional neural networks) architecture is used. By using general sound data instead of speech emotion data for the transfer learning, the limit on the number of data is eliminated. The results are verified by dividing transfer learning into two case, using as a feature extractor and fine-tuning. As a result, convergence time was reduced by about 20% when fine-tuning, and about 20% to 70% when used as a feature extractor. Accuracy of the feature extractor is rather reduced when it is used as a feature extractor and increased by about 3% when it is increased. On the average, the accuracy was improved by about 7% when fine-tuning."
심층 CNN을 활용한 영상 분위기 분류 및 이를 활용한 동영상 자동 생성,2019,"['Convergence', 'Machine Learning', 'Multi-class Classification', 'Mood Classification', 'Convolutional Neural Network', 'Multilayer Perceptron', '융합', '기계학습', '다중 클래스 분류', '감정 분류', '합성곱 신경망', '다층 퍼셉트론']","본 연구에서는 영상의 분위기를 심층 합성곱 신경망을 통해 8 가지로 분류하고, 이에 맞는 배경 음악을 적용하여 동영상을 자동적으로 생성하였다. 수집된 이미지 데이터를 바탕으로 다층퍼셉트론을 사용하여 분류 모델을 학습한다. 이를 활용하여 다중 클래스 분류를 통해 동영상 생성에 사용할 이미지의 분위기를 예측하며, 미리 분류된 음악을 매칭시켜 동영상을 생성한다. 10겹 교차 검증의 결과, 72.4%의 정확도를 얻을 수 있었고, 실제 영상에 대한 실험에서 64%의 오차 행렬 정확도를 얻을 수 있었다. 오답의 경우, 주변의 비슷한 분위기로 분류하여 동영상에서 나오는 음악과 크게 위화감이 없음을 확인하였다.","In this paper, the mood of images was classified into eight categories through a deep convolutional neural network and video was automatically generated using proper background music. Based on the collected image data, the classification model is learned using a multilayer perceptron (MLP). Using the MLP, a video is generated by using multi-class classification to predict image mood to be used for video generation, and by matching pre-classified music. As a result of 10-fold cross-validation and result of experiments on actual images, each 72.4% of accuracy and 64% of confusion matrix accuracy was achieved. In the case of misclassification, by classifying video into a similar mood, it was confirmed that the music from the video had no great mismatch with images."
딥러닝 모형을 사용한 한국어 음성인식,2019,"['한국어 음성인식', '종단 간 딥러닝', '연결성 시계열 분류기', '주의 기제', '베이즈 딥러닝', 'Korean speech recognition', 'end to end deep learning', 'Connectionist temporal classification', 'Attention', 'Bayesian deep learning']","본 논문에서는 베이즈 신경망을 결합한 종단 간 딥러닝 모형을 한국어 음성인식에 적용하였다. 논문에서는 종단 간 학습 모형으로 연결성 시계열 분류기(connectionist temporal classification), 주의 기제, 그리고 주의 기제에 연결성 시계열 분류기를 결합한 모형을 사용하였으며. 각 모형은 순환신경망(recurrent neural network) 혹은 합성곱신경망(convolutional neural network)을 기반으로 하였다. 추가적으로 디코딩 과정에서 빔 탐색과 유한 상태 오토마타를 활용하여 자모음 순서를 조정한 최적의 문자열을 도출하였다. 또한 베이즈 신경망을 각 종단 간 모형에 적용하여 일반적인 점 추정치와 몬테카를로 추정치를 구하였으며 이를 기존 종단 간 모형의 결괏값과 비교하였다. 최종적으로 본 논문에 제안된 모형 중에 가장 성능이 우수한 모형을 선택하여 현재 상용되고 있는 Application Programming Interface (API)들과 성능을 비교하였다. 우리말샘 온라인 사전 훈련 데이터에 한하여 비교한 결과, 제안된 모형의 word error rate (WER)와 label error rate (LER)는 각각 26.4%와 4.58%로서 76%의 WER와 29.88%의 LER 값을 보인 Google API보다 월등히 개선된 성능을 보였다.","In this paper, we propose an end-to-end deep learning model combining Bayesian neural network with Korean speech recognition.In the past, Korean speech recognition was a complicated task due to the excessive parameters of many intermediate steps and needs for Korean expertise knowledge.Fortunately, Korean speech recognition becomes manageable with the aid of recent breakthroughs in ``End-to-end"" model.The end-to-end model decodes mel-frequency cepstral coefficients directly as text without any intermediate processes.Especially, Connectionist Temporal Classification loss and Attention based model are a kind of the end-to-end.In addition, we combine Bayesian neural network to implement the end-to-end model and obtain Monte Carlo estimates.Finally, we carry out our experiments on the ``WorimalSam"" online dictionary dataset. We obtain 4.58% Word Error Rate showing improved results compared to Google and Naver API."
딥러닝기반 다중 표적 인식을 활용한 모바일 로봇 경로 계획,2019,"['표적인식', '경로계획', '장애물 회피', '딥러닝', '모바일 로봇', 'Taget Detection', 'Path Planning', 'Avoidance Obstacle', 'Deep-Learning', 'Mobile Robot']","복합적인 고차원의 임무를 수행하기 위하여 미래무인화 전투 체게는 인공지능 기술을 필요로 한다. 특히 합성곱 신경망은 영상뿐만 아니라 자연어 처리까지 광범위한 범위에서 탁월한 성능을 보이고 있어 무인화 전투체계의 표적정보인식, 피아식별, 전장정보인식 등 각종 센서 융합에 매우 적합하다. 본 연구에서는 합성곱 신경망의 영상인식 기술을 활용하여 다수 대상체의 상태정보를 인식함으로써 변화되는 환경에서의 무인로봇 경로 계획 개선 방안을 제시하였고 시뮬레이션을 통하여 추정된 로봇의 위치, 장애물, 목표물 정보로부터 로봇의 경로 계획의 유효성을 검증 하였다.","Unmmanned systems are one of the essential areas of future military weapons systems that must carry out dangerous and cmplex missions. Especially, deep learning should recognize many landmarks through the image and project them onto the map to improve the problem of position estimation, because it shows excellent performance of recognizing and classifying the characteristics of image data among other artificial intelligence techniques. In this study, the path planning of the unmanned reconnaissance aircraft and the unmanned ground vehicle, which are currently being used in the ROK military, is linked with the CNN based multi target recognition algorithm without GPS. Throuth experiments, we verified the effectiveness of the path planning of the mobile robot with respect to the position of the robot, obstacle, and target point estimated by the target detection algorithm."
역방향 하프토닝을 위한 다중 손실 계층 및 영상 구조 맵 예측기에 기반한 다중 스트림 네트워크,2019,"['inverse halftoning', 'image restoration', 'convolutional neural networks', 'multi-loss layers', 'dictionary learning']","이 논문에서는 하프톤 영상에서 연속 계조 영상을 복원하는 역방향 하프토닝 기법에 대해 소개하고자 한다.  최근 영상 복원 분야에서 큰 주목을 받고 있는 심층 합성곱 신경망 기법을 역방향 하프토닝 분야에 적용할지라도 평탄 영역에서 하프톤 패턴의 불완전한 제거나 에지 및 텍스처 영역에서 디테일 표현 부족은 여전히 현안으로 남아 있다. 이러한 문제를 해결하고자 이 논문에서는 다중 손실 계층을 도입해서 영상 구조 맵과 연속 계조 영상을 동시에 추정이 가능한 다중 스트림 기반의 심층 합성곱 신경망을 새롭게 제안하고자 한다. 그리고 실험 결과를 통해, 제안한 기법이 기존의 최첨단 기법들보다 화질 성능 측면에서 더 우수한 결과를 달성할 수 있음을 보이고자 한다.","This paper introduces the inverse halftoning method for reconstructing the continuous-tone images from the halftoned images. Even though recently-introduced deep convolutional neural networks having drawn much attention from image restoration areas are applied for the inverse halftoning, it still remains a pending issue to remove the halftone patterns completely in flat regions and improve the details in edge and texture regions. To address this problem, this paper presents a new multi-stream-based deep convolutional neural network, which enables the image structure map and the continuous-tone image to be estimated jointly by using multi-loss layers. Through the experimental results, it is also confirmed that the proposed method achieves better results than the conventional state-of-the-art methods in terms of visual quality performance."
U-Net 앙상블을 이용한 LeafNet의 성능향상,2019,"['합성곱 신경망', '이미지 분할', 'U-Net', '식물', '앙상블', 'CNN', 'Image Segmentation', 'Plant', 'Ensemble']",국문 초록 정보 없음,다국어 초록 정보 없음
소형 네트워크에서 배치 정규화의 스케일링 인자를 활용한 채널 프루닝,2019,"['Convolutional Neural Network', 'Pruning', 'Classification', 'Embedded Systems']",국문 초록 정보 없음,다국어 초록 정보 없음
YOLO를 이용한 기관실에서의 화재 검출,2019,"['화재검출', '합성곱 신경망', '욜로', '기관실', 'Fire Detection', 'Convolution Neural Network', 'YOLO', 'Engine Room']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN에서의 DropOut과 DropConnect에 대한 성능 비교,2019,[],"CNN 은 합성곱 연산을 사용하는 인공신경망의 한 종류이다. 이러한 인공 신경망에서는 훈련 데이터에 대한 과도한 학습으로 인해 시험 데이터에 제대로 반응하지 못하는 오버피팅이 발생할 우려가 있다. 이를 해결하기 위해 DropOut 과 DropConnect 를 사용할 수 있다. 본 논문에서는 DropOut 과 DropConnect 를 통한 학습 정도를 실험을 통해서 비교해보고, 인공 신경망에서 이 방법의 효과를 살펴본다.",다국어 초록 정보 없음
시점 정보가 있는 정형 데이터의 2차원 변환을 통한 CNN 적용 가능성 검토 : 온라인 커머스 조회이력 기반 구매예측 모델 적용사례,2019,"['정형 데이터', '커머스 데이터', '합성곱신경망(CNN)', '구매 예측', '2차원 변환']","온라인 커머스 고객 데이터는 구매 및 조회 등 사건 발생 시점과 다량의 사건 발생 관련 변수가 함께 기 록되어 있는 정형 데이터이 다. 최근 발전된 2차원 CNN은 국소적 특성 추출 기능 및 메모리 효율성 향상에서 큰 이점이 있지만, 해당 데이터는 그러한 장점을 활용하기 어려웠다. 또한, 벡터 기반 예측 모델을 사용할 시 성김성(Sparsity)문 제로 인하여 시점에 따른 변화 정보까지 반영한 다 량의 변수를 사용하기 어렵다는 한계를 가지고 있 다. 이에 본 연구는 온라인 커머스 분야의 구매 또는 조 회 이력 데이터에 2차원 CNN 을 적용하기 위한 2차 원 변환 방법을 제시한다. 이 방식은 고객의 사건 관련 변수를 필요에 따라 합산하거나 합산하지 않고 2차원 행렬에 나열하며, 특성 정보와 같이 시점에 따라 변하지 않는 정보 또한 2차원 변환에 포함하여 각 고객별 특성을 나타낼 수 있는 방법이 다. 실제 온라인 쇼핑몰 데이터를 활용하여 제안 방법을 검증한 결과, 합성곱층이 제안된 2차원 변환 행렬에 서 예측을 위한 특성을 충분히 찾아낸다는 사실을 확인하였다. 또한 예측력 향상을 위해 사건 발생 순 서 정보를 제시하는 방법으로 제안 방법이 유용함을 확인하였다.",다국어 초록 정보 없음
딥러닝기반의 선박 회전기기 상태 모니터링 시계열 분석 시스템,2019,"['Artificial neural network(인공신경망)', 'Time series analysis(시계열 분석)', 'Rotating machinery(회전기기)', 'Prognosis(예지)', 'Short-time Fourier transforms(단시간 푸리에 변환)', 'System health(시스템 건전성)', 'Convolutional neural network(합성곱 신경망)', 'Recurrent neural network(재귀 신경망)']",국문 초록 정보 없음,다국어 초록 정보 없음
Self-Attention을 활용한 Siamese CNN-Bidirectional LSTM 기반 문장 유사도 예측,2019,"['자연어 처리', '유사도 측정', '샴 네트워크', '합성곱 신경망', '순환 신경망', '어텐션', 'natural language processing', 'similarity measure', 'siamese network', 'convolution neural network', 'recurrent neural network', 'attention']",본 논문에서는 입력된 두 문장의 유사도를 측정하는 딥러닝 모델을 제안한다. 기존의 문장의유사도 측정 모델에는 단어 혹은 형태소 단위로 문장을 분해하여 임베딩 하는 방식을 활용한다. 하지만 이는 사전의 크기를 증가시켜 모델의 복잡도를 높이는 문제점이 있다. 본 논문에서는 문장을 음소 단위로 분해하여 모델 복잡도를 줄이고 해당 음소를 묶어주는 다양한 필터 사이즈의 1D Convolution Neural Network와 Long Short Term Memory(LSTM)을 결합한 Siamese CNN-Bidirectional LSTM 모델을 제안한다. 본 모델을 평가하기 위해 네이버 지식인 데이터를 활용하여 기존의 문서 유사 측정에서 좋은 성능을 보이는 모델 Manhattan LSTM(MaLSTM)과 비교하였다.,"A deep learning model for semantic similarity between sentences was presented. In general, most of the models for measuring similarity word use level or morpheme level embedding.However, the attempt to apply either word use or morpheme level embedding results in higher complexity of the model due to the large size of the dictionary. To solve this problem, a Siamese CNN-Bidirectional LSTM model that utilizes phonemes instead of words or morphemes and combines long short term memory (LSTM) with 1D convolution neural networks with various window lengths that bind phonemes is proposed. For evaluation, we compared our model with Manhattan LSTM (MaLSTM) which shows good performance in measuring similarity between similar questions in the Naver Q&A dataset (similar to Kaggle Quora Question Pair)."
스펙트럼 패턴 인식 기반 머신러닝 알고리즘을 사용한 플라스틱 섬광검출기용 핵종분별 알고리즘,2019,"['플라스틱 섬광검출기', '핵종분별 알고리즘', '기계학습', '합성곱 신경망']",국문 초록 정보 없음,다국어 초록 정보 없음
가로의 이미지가 절도범죄에 미치는 영향에 관한 기초연구,2019,"['범죄예방 환경설계', '가로 이미지', '범죄예측', '합성곱신경망', 'CPTED', 'Street image', 'Crime prediction', 'Convolutional neural network']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 활용한 착륙 패드 부분 인식 상황에서의 패드 중심점 추정 기법 연구,2019,"['드론(Drone)', '정밀 착륙(Precision Landing)', '합성곱 신경망(Convolutional Neural Network', 'CNN)', '부분 인식(Partial Recognition)']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝 및 영상처리 기술을 활용한 콘크리트 균열 검출 방법,2019,"['콘크리트 균열', '균열 검출', '딥러닝', '영상처리', '합성곱신경망', 'Concrete Crack', 'Crack Detection', 'Deep Learning', 'Image Processing', 'CNN']","현행 균열조사 업무는 육안조사로 이루어지고 있어 점검자의 주관이 개입되어 점검 결과에 차이가 발생하거나, 측정오차가 발생할 여지가 있다. 이에 본 연구는 콘크리트 균열 조사의 객관성과 효율성을 높이기 위하여 딥러닝 네트워크 중 실시간 분석이 가능한 YOLO v.2를 활용하여 균열을 인지하고, 영상처리 기술을 활용하여 균열의 특성정보를 추출하는 프로세스를 제시하였다. 실험 결과, 실시간 분석이 가능한 검출속도와 정확도를 확보할 수 있었다. 본 연구의 결과는 시설물 하자진단 자동화 시스템 개발의 기초자료로 활용될수 있을 것이다.","Most of the current crack investigation work consists of visual inspection using simple measuring equipment such as crack scale. Thesemethods involve the subjection of the inspector, which may lead to differences in the inspection results prepared by the inspector, and maylead to a large number of measurement errors. So, this study proposes an image-based crack detection method to enhance objectivity andefficiency of concrete crack investigation. In this study, YOLOv2 was used to determine the presence of cracks in the image information toensure the speed and accuracy of detection for real-time analysis. In addition, we extracted shapes of cracks and calculated quantitatively,such as width and length using various image processing techniques. The results of this study will be used as a basis for the development ofimage-based facility defect diagnosis automation system."
CNN 기반 열화상 카메라를 활용한 재실자의 열쾌적감 예측에 관한 연구,2019,"['열쾌적감', '열화상 카메라', '피부온도', '기계학습', '합성곱신경망', 'Thermal Comfort', 'Thermographic Camera', 'Skin Temperature', 'Machine learning', 'Convolutional Neural Network']",국문 초록 정보 없음,다국어 초록 정보 없음
건설 현장 이미지 관리를 위한 이미지 캡셔닝 기반 텍스트 정보 생성,2019,"['건설 현장 관리', '이미지 캡셔닝', '텍스트 처리', '합성곱 신경망', '순환 신경망']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 익형의 공력 성능 예측,2019,"['Deep Leaning(심층학습)', 'Convolution Neural Network(합성곱 신경망)', 'Airfoil(익형)', 'Aerospace Application(항공우주적용)']",국문 초록 정보 없음,다국어 초록 정보 없음
적응형 채널 어텐션 모듈을 활용한 복합 열화 복원 네트워크,2019,"['Image restoration', 'Deep learning', 'Channel attention', 'CNN', '영상복원', '딥러닝', '채널 어텐션', '합성곱신경망']",자율 주행 자동차나 소방 로봇과 같은 시스템에서 영상을 얻을 때 다양한 요인들로 인해 잡음，블러와 같은 열화가 발생한 다. 이런 열화된 영상에 직접 영상 분류와 같은 기술을 적용하기 어려워 열화 제거가 불가피하나 이러한 시스템들은 영상의 열화를 인식할 수 없어서 열화된 영상을 복원하는데 어려움이 있다. 본 논문에서는 영상에 적용된 열화를 인지하지 못하는 상황에서 여러 방법들로 열화된 영상으로부터 자연스럽고 선명한 영상을 복원하는 방법을 제안한다. 우리가 제안한 방법은 딥러닝 모델에 채널 어텐션 모듈과스깁 커넥션을사용하여 영상에 적용된 열화에 따라복원에 필요한 채널에 높은 가중치를 적용해 복합 열화 영상의 복원을 진행한다. 이 방법은 다른복합 열화복원 방법 에 비해 학습이 간단하고 기존의 다른 방법들에 비 해 높은 복합 열화 복원 성능을 낸다.,"The image obtained from systems such as autonomous driving cars or fire-fighting robots often suffer from several degradation such as noise, motion blur, and compression artifact due to multiple factor. It is difficult to apply image recognition to these degraded images, then the image restoration is essential. However, these systems cannot recognize what kind of degradation and thus there are difficulty restoring the images. In this paper, we propose the deep neural network, which restore natural images from images degraded in several ways such as noise, blur and JPEG compression in situations where the distortion applied to images is not recognized. We adopt the channel attention modules and skip connections in the proposed method, which makes the network focus on valuable information to image restoration. The proposed method is simpler to train than other methods, and experimental results show that the proposed method outperforms existing state-of-the-art methods."
트위터 사용자들의 감성을 이용한 사회적 이슈 분석,2019,"['소셜 네트워크 서비스', '트위터', '감성 분류', '사회적 이슈 분석', '합성곱 신경망', 'Social network service', 'Twitter', 'Sentiment classification', 'Social issues analysis', 'Convolutional neural networks']","대중들의 소통의 창구로 자리매김 하고 있는 소셜 네트워크 서비스(SNS)에 작성된 글은 감성을 많이 포함하고 있다는 특징을 갖고 있다. 그 중 트위터는 공개 Application Programming Interface(API)를 통한 데이터의 수집이 편리하다는 장점을 지니고 있다. 본 논문에서는 트위터 상에 표현된 사용자들의 감성 정보를 통해 사회적 이슈를 분석하고 마케팅 분야 활용 가능성을 제시한다. 이는 국민 또는 소비자의 의견과 반응을 필요로 하는 정부, 기업 등에 도움이 될 수 있다. 본 논문에서는 최근 사회적 이슈에 대한 트위터 텍스트 데이터를 긍정 또는 부정으로 분류하여 질적 분석을 제공하였고, 각 트윗의 좋아요 수, 리트윗 수 등에 대한 상관관계 분석을 통해 양적분석을 제공하였다. 질적 분석의 결과로 국민의 지지를 얻기 위해 관세정책을 홍보하고, 버즈 사용자에게는 기술적 편의를 제공할 것을 제안하였다. 양적 분석의 결과, 트위터 사용자들의 관심을 끌기 위해서는 긍정적인 트윗을 짧고 간단하게 작성해야 함을 밝혔다. 데이터의 수집 기간이 짧고, 단 두 가지의 키워드만을 분석하여 일반화 가능성이 떨어지는 한계를 가져 향후, 보다 긴 기간의 다양한 사회적 이슈를 분석할 예정이다.","Recently, social network service (SNS) is actively used by public. Among them, Twitter has a lot of tweets including sentiment and it is convenient to collect data through open Aplication Programming Interface (API). In this paper, we analyze social issues and suggest the possibility of using them in marketing through sentimental information of users. In this paper, we collect twitter text about social issues and classify as positive or negative by sentiment classifier to provide qualitative analysis. We provide a quantitative analysis by analyzing the correlation between the number of like and retweet of each tweet. As a result of the qualitative analysis, we suggest solutions to attract the interest of the public or consumers. As a result of the quantitative analysis, we conclude that the positive tweet should be brief to attract the users' attention on the Twitter. As future work, we will continue to analyze various social issues."
중첩 분포 이미지를 활용한 회전체 고장 진단,2019,"['중첩분포이미지(Overlaid Distribution Image)', '상전류(Stator Current Signal)', '합성곱신경망(Convolution Neural Network)']",국문 초록 정보 없음,"In this study, the improved fault diagnosis method for bearings in the load part of the rotating system using stator current is proposed. In spite of many previous studies for detecting faults with stator current signals, the domain knowledge for feature extraction is still required. Moreover, the extraction of fault-related features is hindered by control related components or operating noise. By using overlaid distribution image (ODI), which can be implemented without any domain knowledge, stator current signals are converted to the image containing a large amount of information. The ODI images of stator current signal can contribute to the efficient fault-related feature extraction of the convolution neural networks which have shown outstanding performance in image recognition and classification. The experimental study using bearing fault dataset demonstrates high accuracy of the proposed method compared to other machine learning based fault diagnosis method."
A Study on Fault Classification of Machining Center using Acceleration Data Based on 1D CNN Algorithm,2019,"['Machining Center(머시닝센터)', 'Machine Learning(머신러닝)', 'Fault Signal Classification(고장신호 분류)', 'CNN(합성곱 신경망)']",국문 초록 정보 없음,"The structure of the machinery industry due to the 4th industrial revolution is changing from precision and durability to intelligent and smart machinery through sensing and interconnection(IoT). There is a growing need for research on prognostics and health management(PHM) that can prevent abnormalities in processing machines and accurately predict and diagnose conditions. PHM is a technology that monitors the condition of a mechanical system, diagnoses signs of failure, and predicts the remaining life of the object. In this study, the vibration generated during machining is measured and a classification algorithm for normal and fault signals is developed. Arbitrary fault signal is collected by changing the conditions of un stable supply cutting oil and fixing jig. The signal processing is performed to apply the measured signal to the learning model. The sampling rate is changed for high speed operation and performed machine learning using raw signal without FFT. The fault classification algorithm for 1D convolution neural network composed of 2 convolution layers is developed."
딥러닝 기반 병리학적 음성 진단 시스템,2019,"['Dysphagia(연하곤란', '삼킴장애)', 'Pathological voice(병적음성)', 'Convolutional neural network(합성곱 신경망)', 'Diagnosis(진단)', 'Short-time Fourier Transfer(단시간 푸리에 변환)', 'Mel Frequency Cepstral Coefficient(멜 주파수 셉스트랄 상수)']",국문 초록 정보 없음,다국어 초록 정보 없음
인공지능 기반 MNIST 손글씨 인식에 대한 연구,2019,"['Handwriting', 'SLR', 'ANN', 'CNN', 'Deep learning', '손글씨', '소프트맥스 회귀분석', '인공신경망', '합성곱신경망', '딥러닝']",국문 초록 정보 없음,"In the development of electronic devices such as PDAs, smartphones, and tablets, research on handwriting recognition has emerged. In the meantime, there have been efforts to recognize various handwriting such as numbers, Japanese, and English. However, there is a point that it is difficult to recognize when the font shape is relatively irregular, such as handwriting of children. As a result, the need for research to improve handwriting recognition rate by applying deep learning techniques has recently been raised. Therefore, this study attempted to improve handwriting recognition rate based on various deep learning techniques. In the case of handwriting, it is difficult to prepare a variety of data sets, which limits the recognition rate. In this study, we tried to improve the accuracy of handwriting recognition by using CNN technique in order to find a way to overcome these limitations. The techniques used were SLR, ANN, and CNN, each measuring the accuracy of each method. As a result, CNN showed the highest performance of 95%."
인공지능 기반의 행동인식을 통한 개인 운동 트레이너 구현의 방향성 제시,2019,"['Healthcare', 'Fitness', 'Artificial Intelligence', 'Deep Running', 'CNN', 'RNN', '헬스케어', '피트니스', '인공지능', '딥러닝', '합성곱 신경망', '순환 신경망']","최근 딥러닝을 비롯한 인공지능 기술의 활용이 다양한 분야에서 활발해지고 있으며, 특히 딥러닝 기술 기반의 객체 인식 및 검출에 뛰어난 성능을 보이는 여러 알고리즘들이 발표되고 있다. 이에 본 논문에서는 사용자의 편의성이 효과적으로 반영된 모바일 헬스케어 애플리케이션 구현에 대한 적절한 방향성을 제시하고자 한다. 기존의 피트니스 애플리케이션들에 대한 이용 만족도 연구 및 모바일 헬스케어 애플리케이션에 대한 현황을 파악하여, 이로부터 피트니스 애플리케이션 시장에서의 생존과 우위를 확보하는 동시에, 최근 주목 받고 있는 인공지능 기술의 효과적인 적용에 의한 성능 개선을 통해 기존 이용자 유지 및 확대를 도모하고자 한다.","Recently, the use of artificial intelligence technology including deep learning has become active in various fields. In particular, several algorithms showing superior performance in object recognition and detection based on deep learning technology have been presented. In this paper, we propose the proper direction for the implementation of mobile healthcare application that user's convenience is effectively reflected. By effectively analyzing the current state of use satisfaction research for the existing fitness applications and the current status of mobile healthcare applications, we attempt to secure survival and superiority in the fitness application market, and, at the same time, to maintain and expand the existing user base."
다중 넓이 커널 CNN을 이용한 구름 요소 베어링 고장 진단,2019,"['구름 요소 베어링(Rolling element bearing)', '전이 학습(Transfer learning)', '고장 진단(Fault diagnosis)', '합성곱신경망(Convolution neural networks)']",국문 초록 정보 없음,다국어 초록 정보 없음
망막혈관 검출을 위한 영상분할기법,2019,"['당뇨망막병증(DR: Diabetic Retinopathy)', '망막혈관(Retinal Blood Vessel)', '영상강화(Image Enhancement)', '형태학적 영상처리(Morphological Image Processing)', '합성곱 신경망(Convolutional Neural Network)']",국문 초록 정보 없음,다국어 초록 정보 없음
한국어 음성 명령어 인식을 위한 자동데이터 구축,2019,"['Korean Speech Command', 'Speech Recognition', 'Automatic Data Construction', 'ResNet', 'CNN', '한국어 명령어 인식', '음성인식', '자동 데이터 구축', '레스넷', '합성곱신경망']","최근 화두가 되고 있는 AI분야에서 가장 큰 문제점은 학습데이터의 부족 문제를 꼽을 수 있다. 수동 데이터 구축에는 많은 시간과 노력이 소요되기에 개인이 손쉽게 필요 데이터를 구축하기는 매우 어렵다. 반면, 수동 데이터 구축에 비해 자동으로 구축하는 것은 높은 품질을 유지하는 것이 관건이다. 본 논문에서는 한국어 음성 명령어 인식기 개발에 필요한 데이터를 웹에서 자동으로 추출하고, 학습데이터로 사용할 수 있는 데이터를 자동으로 선별하는 방법을 소개한다. 특히, 자동 구축된 한국어 음성 데이터를 대상으로 우수한 성능을 보이는 ResNet기반의 수정 모델을 기반으로, 건강 및 일상생활도메인의 명령어 셋을 대상으로 적용가능성을 보이기 위한 실험을 진행하였다. 자동으로 구축된 데이터만을 사용한 일련의 실험에서 건강도메인은 ResNet15에서 89.5%, 일상생활도메인에서는 ResNet8에서 82%의 정확도를 보임으로써, 자동 수집 데이터의 활용 가능성을 검증하였다.","The biggest problem in the AI field, which has become a hot topic in recent years, is how to deal with the lack of training data. Since manual data construction takes a lot of time and efforts, it is non-trivial for an individual to easily build the necessary data. On the other hand, automatic data construction needs to handle data quality issue. In this paper, we introduce a method to automatically extract the data required to develop Korean speech command recognizer from the web and to automatically select the data that can be used for training data. In particular, we propose a modified ResNet model that shows modest performance for the automatically constructed Korean speech command data. We conducted an experiment to show the applicability of the command set of the health and daily life domain. In a series of experiments using only automatically constructed data, the accuracy of the health domain was 89.5% in ResNet15 and 82% in ResNet8 in the daily lives domain, respectively."
PointNet을 이용한 위성 부분품 분류 모델 연구,2019,"['PointNet(포인트넷)', 'Point Cloud(포인트클라우드)', '3D Classification Model(3차원 분류 모델)', 'Convolution Neural Network(합성곱신경망)']",국문 초록 정보 없음,다국어 초록 정보 없음
이미지 기반 품질 관리 기법의 스마트 팩토리 현장 적용 이슈와 전략,2019,"['Quality Management', 'Machine Learning', 'Convolution Neural Network', 'Smart Factory', '품질 경영', '기계 학습', '합성곱 신경망', '스마트 팩토리']","콘볼루션 신경망 기술의 발전이 영상 기반 품질 경영에서의 전처리 부담을 많이 줄여주는 의미가 있지만, 콘볼루션 신경망의 발전이 전처리 노력을 완전히 제거해주지는 못한다. 그러나, 조금만 훈련받으면 컴퓨터 비전 전문가가 아니더라도 영상 기반의 품질 관리를 할 수 있으며, 이에 기반하여 가변적인 생산체계에 빠르게 적응할 수 있다. 스마트 팩토리에서 자동화된 품질관리를 현실에서 실제 적용하는 것은, 이 방법론들을 이해하고, 이를 일부 구현하여 적용하거나, 통합적으로 구현하여 완전 자동화하는 형태로 진행된다. 이 논문은 스마트 팩토리 환경에서 자동화된 품질 검사를 위한 이미지 기반 품질 관리 기법들을 개관하고 현실에 이러한 기법을 실제 적용하는 데에서 나타나는 이슈와 전략에 대해 토론한다.","Although the development of convolutional neural network technology reduces a lot of preprocessing burden in image-based quality management, it does not completely eliminate the preprocessing effort. However, with a little training, even non-computer vision specialists can perform image-based quality management, which allows them to quickly adapt to variable manufacturing systems. The actual application of automated quality control at the smart factory in the real world is based on understanding, implementing, and integrating these methodologies. This paper provides an overview of image-based quality management techniques for automated quality inspection in a smart factory environment and discusses the issues and strategies of applying these techniques in practice."
라이다 센서 데이터를 이용한 구형 특징 표현 기반의 도시 구조물 3차원 점 군 분류에 관한 연구,2019,"['a라이다 센서', '거리 데이터', '물체 인식', '도시 구조물', '키티 데이터', '구형 특징 표현', '합성곱 신경망', 'LiDAR Sensor', 'Depth Data', 'Object Recognition', 'Urban Structure', 'KITTI Data', 'Spherical Signature Descriptor', 'Convolutional Neural Network']","물체 인식은 영상 등의 이미지 정보와 깊이 정보 등의 센서 데이터를 이용하여 물체의 종류와 크기, 방향, 위치 등의 고차원적인 공간 정보를 실시간으로 알아내는 기술로 자율주행의 기본 기술이 된다. 본 논문에서는 거리 데이터 기반의 물체인식을 목표로 하고 있으며, 3차원 점을 구성하고 있는 모든 점에 의미를 부여 할 수 있는 구형 특징 표현을 이용한 학습 데이터 생성을 제안하였다. 구형 특징 표현을 이용하여 생성된 학습 데이터는 주변 점들의 분포와 밀집도를 이용하여 한 점의 특징을 정의 함으로서 모든 점들에 대하여 생성이 가능하기 때문에 인공지능을 위한 학습데이터 준비에 매우 용이하게 사용될 수 있다. 본 논문에서는 KITTI 데이터와 직접 수집한 라이다 센서 데이터를 구형 특징 표현에 적용하여 학습 데이터를 생성하고 생성된 학습 데이터를 인공지능 학습의 한 종류인 CNN(Convolutional Neural Network)에 입력하여 도시 구조물에 대한 3차원 점 군을 분류하고자 하였다.","Object recognition is a technology that detects real-time high-dimensional spatial information such as type, size, direction, and position of an object using sensor data such as image information and depth information of photographs. In this study, we aim at achieving object recognition based on distance data and propose the generation of learning data using the spherical signature descriptor capable of giving meaning to all points composing a 3D point group. The learning data generated by using the spherical signature descriptor can easily be used for generating learning data for artificial intelligence because it is possible to define the characteristics of a point using the distribution and density of the surrounding points and to generate from all the points. In this study, we generated learning data by applying collected KITTI and LiDAR sensor data directly to the spherical signature descriptor and classifying the urban structures through artificial intelligence learning using a CNN (convolutional neural network)."
CTC를 적용한 CRNN 기반 한국어 음소인식 모델 연구,2019,"['Phoneme Recognition', 'CTC Algorithm', 'Convolutional Neural Network', 'Recurrent Neural Network', '음소 인식', 'CTC 알고리즘', '합성곱 신경망', '순환 신경망']",국문 초록 정보 없음,"For Korean phoneme recognition, Hidden Markov-Gaussian Mixture model(HMM-GMM) or hybrid models which combine artificial neural network with HMM have been mainly used. However, current approach has limitations in that such models require force-aligned corpus training data that is manually annotated by experts. Recently, researchers used neural network based phoneme recognition model which combines recurrent neural network(RNN)-based structure with connectionist temporal classification(CTC) algorithm to overcome the problem of obtaining manually annotated training data. Yet, in terms of implementation, these RNN-based models have another difficulty in that the amount of data gets larger as the structure gets more sophisticated. This problem of large data size is particularly problematic in the Korean language, which lacks refined corpora. In this study, we introduce CTC algorithm that does not require force-alignment to create a Korean phoneme recognition model. Specifically, the phoneme recognition model is based on convolutional neural network(CNN) which requires relatively small amount of data and can be trained faster when compared to RNN based models. We present the results from two different experiments and a resulting best performing phoneme recognition model which distinguishes 49 Korean phonemes. The best performing phoneme recognition model combines CNN with 3hop Bidirectional LSTM with the final Phoneme Error Rate(PER) at 3.26. The PER is a considerable improvement compared to existing Korean phoneme recognition models that report PER ranging from 10 to 12."
RDB 및 웨이블릿 예측 네트워크 기반 단일 영상을 위한 심층 학습기반 초해상도 기법,2019,[],"단일 영상 초해상도 (Single Image Super-Resolution - SISR)기법은 카메라로 획득된 저해상도 영상에 필터 기반의 연산을 적용하여 좋은 화질의 고해상도 영상을 복원하는 과정이다. 최근에 심층 합성곱 신경망 학습의 발전에 따라 단일 영상 초해상도에 적용되는 심층 학습 기법들은 좋은 성과를 보여 주고 있다. 본 논문은 단일 영상 초해상도 성능을 개선하기 위해 웨이블릿 예측 네트워크를 효율적으로 적용하는 방법에 대해 연구하였으며, 저해상도 입력 영상의 특징을 잘 추출해내기 위해 네트워크 내부에 RDB를 적용하여 기존 방식보다 효율적으로 고해상도 영상 복원하는 기법을 제안한다. 모의실험을 통해 제안하는 방법이 기존 방법보다 화질은 약 PSNR 0.18dB만큼 우수하며 속도는 1.17배 빠른 것을 확인하였다.",다국어 초록 정보 없음
딥러닝 기반 베어링 결함 비이상 탐지 방법,2019,"['Anomaly detection(이상감지)', 'Bearing health condition monitoring(베어링 상태 모니터링)', 'Rotating machinery(회전기기)', 'One-class SVM(단일 클래스 서포트 벡터 머신)', 'Convolutional Autoencoder(합성곱 오토인코더)', 'Generative adversarial network(생성적 적대 신경망)', 'AnoGAN(아노갠)']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝 기반 베어링 결함 비이상 탐지 방법,2019,"['이상감지(Anomaly detection)', '베어링 상태 모니터링(Bearing health condition monitoring)', '회전기기(Rotating machinery)', '단일 클래스 서포트 벡터 머신(One-class SVM)', '합성곱 오토인코더(Convolutional autoencoder)', '생성적 적대 신경망(Generative adversarial network)', '아노갠(AnoGAN)']",국문 초록 정보 없음,다국어 초록 정보 없음
생활도로 노상주차 식별을 위한 Google Street View API와 딥러닝 모형의 적용,2019,"['Street Parking', 'Deep Learning', 'Google Street View Image', 'Object Detection', 'Convolutional Neural Network', '노상주차', '딥러닝', '구글 가로 이미지', '객체 탐색', '합성곱신경망']","본 연구는 Google Street View API를 통해 취득한 가로 이미지를 활용하여 서울시 생활도로의 노상주차를 식별하는 모형을 학습 및 검증하였다. 다양한 반복학습 횟수에 따른 모형들의 정확도를 검증하여 최종모형으로 도출하였으며, 최종 모형은 모든 객체 유형에 대해 약 75.68%, 노상주차 차량에 대해 약 82.07%의 객체 탐색 정확도를 나타낸다. 연구의 주요 시사점은 주로 현장조사에 의존해 진행되어, 시간과 금전적 비용이 많이 필요하던 노상주차 데이터 수집의 한계점을 보완하였다는 점과, 딥러닝 모형을 공간분석 및 도시 계획 분야의 공간정보 수집에 적용하여 그 가능성을 제시했다는 점을 들 수 있다.",This study has trained and validated a deep learning model that identifies street parking on the streets of Seoul by utilizing the street view images obtained through the Google Street View API. We derived the final model which shows highest accuracy of object detection among models with variation of the number of training iterations. The final model shows 75.68% accuracy of object detection for all object types and 82.07% for street parking vehicles. The main implications of this study are as follows. This study introduces improved data collection method of street parking data in terms of time and monetary cost compared to the conventional field survey. Also this study applies the deep learning using street view image on the collection of spatial information for the urban planning and spatial analysis field.
RDB 및 웨이블릿 예측 네트워크 기반 단일 영상을 위한 심층 학습기반 초해상도 기법,2019,"['Super Resolution', 'Deep Learning', 'Wavelet Coefficient', 'Residual Dense Block', 'WaveletSRNet']","단일 영상 초해상도 (Single Image Super-Resolution – SISR)기법은 카메라로 획득된 저해상도 영상에 필터 기반의 연산을 적용하여 좋은 화질의 고해상도 영상을 복원하는 과정이다. 최근에 심층 합성곱 신경망 학습의 발전에 따라 단일 영상 초해상도에 적용되는 심층 학습 기법들은 좋은 성과를 보여 주고 있다. 그 대표적인 방법으로 영상의 특징 맵 기반 웨이블릿 계수 학습을 통해 고해상도 영상을 복원하는 WaveletSRNet이 있다. 하지만 복잡한 알고리즘으로 인해 계산량이 증대되어 처리 속도가 늦고 특징 추출할 때 특징 맵을 효율적으로 활용하지 못 한다는 단점을 가지고 있다. 이를 개선하기 위해 본 논문에서는 단일 영상 초해상도 RDB-WaveletSRNet 기법을 제안한다. 제안된 기법은 잔여밀집블록(Residual Dense Block)을 사용하여 저해상도의 특징 맵을 효과적으로 추출하여 초해상도의 성능을 향상시키고 적절한 성장률을 설정하여 복잡한 계산량 문제까지 해결하였다. 또한 웨이블릿 패킷 분해를 사용하여 확대율에 맞게 웨이블릿 계수를 획득하므로 높은 확대율의 단일 영상 초해상도를 얻게 하였다. 다양한 영상에 대한 실험을 통하여, 제안하는 기법이 기존 기법보다 수행시간이 빠르며 영상 품질도 우수함을 입증하였다. 제안하는 방법은 기존 방법보다 화질은 PSNR 0.1813dB만큼 우수하며 속도는 1.17배 빠른 것을 실험을 통해 확인하였다.",다국어 초록 정보 없음
Transfer Learning for Enhancing Bearing Fault Detection Performance under Time-varying Speed Conditions,2019,"['Fault diagnosis(고장 진단)', 'Health condition monitoring(상태 모니터링)', 'Rotating machinery(회전기기)', 'Bearing fault(베어링 결함)', 'Machine learning(기계학습)', 'Deep learning(심층학습)', 'Convolutional Neural Network(합성곱 신경망)', 'Transfer learning(전이 학습)', 'Fine tuning(미세 조정)']",국문 초록 정보 없음,다국어 초록 정보 없음
객체 인식에서의 속도 향상을 위한 모델 앙상블,2019,"['Object detection', 'Ensemble method', 'Convolutional neural network']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝을 이용한 화강암 X-ray CT 영상에서의 균열 검출에 관한 연구,2019,"['Granite', 'Deep learning', 'Crack detection', 'Image augmentation', '화강암', 'X-ray CT', '딥러닝', '균열추출', '영상 데이터 증대 기술']","본 연구에서는 화강암 시편에서 수압 파쇄법에 의해 생성된 미세균열의 3차원 형상을 X-ray CT 영상과 딥러닝을 이용하여 추출하였다. 실험으로 생성된 미세균열은 X-ray CT 영상 상에서 일반적인 영상처리 방법으로는 추출하기 매우 어렵고 육안으로만 관찰이 가능한 형태를 지닌다. 하지만 본 연구에서 제안한 합성곱 신경망(Convolutional neural network) 기반 인코더-디코더(Encoder-Decoder) 구조의 딥러닝 모델을 통해 미세균열을 정량적으로 추출할 수 있었다. 특히 픽셀 단위의 미세균열 추출을 위해 인코딩 과정에서 소실되는 정보를 디코딩 과정으로 직접 전달하는 디코더 모델을 제안하였다. 또한, 딥러닝 기반 신경망 학습에 필요한 데이터의 수를 증가시키기 위해 이미지의 분할(Division), 회전(Rotation), 그리고 반전(Flipping) 등으로 데이터를 생성하는 영상 증대 방법을 적용하였으며 이때 최적의 조합을 확인하였다. 최적의 영상 학습 데이터 증대 방법을 적용하였을 때 검증 데이터뿐만 아니라 테스트 데이터에서의 성능 향상을 확인하였다. 학습 데이터의 원본 개수가 딥러닝 기반 신경망의 균열 추출 성능에 미치는 영향을 확인하고 딥러닝 기술을 사용하여 성공적으로 미세균열을 추출하였다.","This study aims to extract a 3D image of micro-cracks generated by hydraulic fracturing tests, using the deep learning method and X-ray computed tomography images. The pixel-level cracks are difficult to be detected via conventional image processing methods, such as global thresholding, canny edge detection, and the region growing method. Thus, the convolutional neural network-based encoder-decoder network is adapted to extract and analyze the micro-crack quantitatively. The number of training data can be acquired by dividing, rotating, and flipping images and the optimum combination for the image augmentation method is verified. Application of the optimal image augmentation method shows enhanced performance for not only the validation dataset but also the test dataset. In addition, the influence of the original number of training data to the performance of the deep learning-based neural network is confirmed, and it leads to succeed the pixel-level crack detection."
Inception V3 모델을 활용한 관광사진 분류 및 정확도 평가,2019,[],"본 연구는 소셜 네트워크 서비스(Social Network Service, SNS)인 플리커(Flickr)에 공유된 지오태깅된 사진 데이터를 활용하여 관광지 이미지 특성을 분석하고자 한다. 2013년부터 2018년까지 우리나라를 방문한 관광객이 업로드한 약 16만장의 사진을 이용하였다. 사진에 대한 분석은 합성곱 신경망(Convolutional Neural Network, CNN) 중 하나인 Inception V3를 활용하였으며, 사진 분류 정확도를 평가하기 위해 전체 데이터의 약 23%에 달하는 사진 데이터에 대해 수동 라벨링을 하여 사진의 분류 정확도를 평가하였다. 관광 활동으로 생성된 사진 데이터들을 imagenet의 분류 카테고리로 분류할 경우의 한계점을 분석하고 향후 연구과제로 관광 목적에 맞는 이미지 카테고리 개발을 제안하였다.",다국어 초록 정보 없음
Atrous Convolution과 Grad-CAM을 통한 손 끝 탐지,2019,"['Deep Learning', 'Atrous Convolution', 'Grad-CAM', 'Object Detection', '딥러닝', 'Atrous Convolution', 'Grad-CAM', '객체 탐지']","딥러닝 기술의 발전으로 가상 현실이나 증강 현실 응용에서 사용하기 적절한 사용자 친화적 인터페이스에 관한 연구가 활발히 이뤄지고 있다. 본 논문은 사용자의 손을 이용한 인터페이스를 지원하기 위하여 손 끝 좌표를 추적하여 가상의 객체를 선택하거나, 공중에 글씨나 그림을 작성하는 행위가 가능하도록 딥러닝 기반 손 끝 객체 탐지 방법을 제안한다. 입력 영상에서 Grad-CAM으로 해당 손 끝 객체의 대략적인 부분을 잘라낸 후, 잘라낸 영상에 대하여 Atrous Convolution을 이용한 합성곱 신경망을 수행하여 손 끝의 위치를 찾는다. 본 방법은 객체의 주석 전처리 과정을 별도로 요구하지 않으면서 기존 객체 탐지 알고리즘 보다 간단하고 구현하기에 쉽다. 본 방법을 검증하기 위하여 Air-Writing 응용을 구현한 결과 평균 81%의 인식률과 76 ms 속도로 허공에서 지연 시간 없이 부드럽게 글씨 작성이 가능하여 실시간으로 활용 가능함을 알 수 있었다.","With the development of deep learning technology, research is being actively carried out on user-friendly interfaces that are suitable for use in virtual reality or augmented reality applications. To support the interface using the user's hands, this paper proposes a deep learning-based fingertip detection method to enable the tracking of fingertip  coordinates to select virtual objects, or to write or draw in the air. After cutting the approximate part of the corresponding fingertip object from the input image with the Grad-CAM, and perform the convolution neural network with Atrous Convolution for the cut image to detect fingertip location. This method is simpler and easier to implement than existing object detection algorithms without requiring a pre-processing for annotating objects. To verify this method we implemented an air writing application and showed that the recognition rate of 81% and the speed of 76 ms were able to write smoothly without delay in the air, making it possible to utilize the application in real time."
케이블 장력 모니터링 자동화를 위한 무선센서 시스템,2019,"['케이블', '무선센서', '자동화', 'Cable', 'wireless sensors', 'automation']","케이블 교량에서 케이블은 가장 중요한 구조부재의 하나이며, 케이블의 내부 장력을 모니터링하는 것은 케이블 교량 유지 관리에서 필수적이다. 본 연구에서는 케이블 장력을 효율적으로 모니터링하기 위한 무선센서 기반의 장력추정 자동화 시스템을 개발하였다. 무선센서에 포함된 가속도계를 통해 케이블의 진동을 계측하고, 진동기반 장력추정법을 통해 케이블의 장력을 추정하였다. 장력추정 절차를 자동화하기 위해 가장 널리 사용되고 있는 기계학습법의 하나인 합성곱 신경망을 도입하였다. 개발된 자동화 기법은 싱글보드 컴퓨터의 하나인 라즈베리파이3 모델B+에 구현하였으며, 실험실에서 모형 케이블을 이용하여 성능을 검증하였다. 케이블의 장력이 바뀌는 경우에도 개발된 시스템은 자동으로 변화된 장력의 크기를 잘 계측할 수 있는 것을 확인하였다.",다국어 초록 정보 없음
텍스트마이닝과 딥러닝 기술을 활용한 외국인 관광객의 국내 지역별 이미지 비교,2019,[],"본 연구에서는 소셜 네트워크 서비스(Social Network Service, SNS)인 플리커(Flickr)에 게시된 지오태깅된 사진 데이터와 텍스트 데이터를 활용하여 우리나라 방문객이 갖는 지역별 이미지를 비교하였다. 플리커 데이터 수집은 2013년부터 2018년까지 약 6년간 데이터를 수집하였으며, 6년간 수집된 데이터 29만여건 가운데 관광객이 업로드한 것으로 추정되는 약 17만장의 사진을 분석대상으로 하였다. 플리커의 태그와 텍스트에 대한 분석은 텍스트마이닝 기법 중 단어간 빈도분석 및 연관관계분석을 적용하였으며, 사진에 대한 분석은 합성곱 신경망(Convolutional Neural Network, CNN) 중 하나인 Inception V3 모델을 활용하였다. 지역에 대한 이미지 분석은 서울, 부산, 제주 지역을 대상으로 하였으며, 텍스트 분석 결과와 사진 이미지 분석결과를 비교하여 지역 이미지의 차이를 분석하였다.",다국어 초록 정보 없음
암 유전체 데이터를 효과적으로 학습하기 위한 Node2Vec 기반의 새로운 2 차원 이미지 표현기법,2019,[],"4 차산업혁명의 발달은 전 세계가 건강한 삶에 관련된 스마트시티 및 맞춤형 치료에 큰 관심을 갖게 하였고, 특히 기계학습 기술은 암을 극복하기 위한 유전체 기반의 정밀 의학 연구에 널리 활용되고 있어 암환자의 예후 예측 및 예후에 따른 맞춤형 치료 전략 수립 등을 가능케하였다. 하지만 암 예후 예측 연구에 주로 사용되는 유전자 발현량 데이터는 약 17,000 개의 유전자를 갖는 반면에 샘플의 수가 200 여개 밖에 없는 문제를 안고 있어, 예후 예측을 위한 신경망 모델의 일반화를 어렵게 한다. 이러한 문제를 해결하기 위해 본 연구에서는 고차원의 유전자 발현량 데이터를 신경망 모델이 효과적으로 학습할 수 있도록 2D 이미지로 표현하는 기법을 제안한다. 길이 17,000 인 1 차원 유전자 벡터를 64x64 크기의 2 차원 이미지로 사상하여 입력크기를 압축하였다. 2 차원 평면 상의 유전자 좌표를 구하기 위해 유전자 네트워크 데이터와 Node2Vec 이 활용되었고, 이미지 기반의 암 예후 예측을 수행하기 위해 합성곱 신경망 모델을 사용하였다. 제안하는 기법을 정확하게 평가하기 위해 이중 교차 검증 및 무작위 탐색 기법으로 모델 선택 및 평가 작업을 수행하였고, 그 결과로 베이스라인 모델인 고차원의 유전자 벡터를 입력 받는 다층 퍼셉트론 모델보다 더 높은 예측 정확도를 보여주는 것을 확인하였다.",다국어 초록 정보 없음
Mask R-CNN기법을 활용한 목재 표면 옹이 구획화,2019,[],"목재 품질의 객관적 평가 및 목재 생산의 고속화를 위해서는 컴퓨터 비전을 활용한 목재 표면 화상분석 자동화가 필요하다. 딥러닝(Deep Learning) 기술은 최근 컴퓨터 비전을 통한 화상 분석 및 패턴인식 분야에서 높은 정확도와 속도로 인해 그 활용도가 높아지고 있다. 따라서 본 연구에서는 딥러닝 기술 중 화상의 구획화에 높은 성능을 보이는 알려진 합성곱 신경망(Convolutional Neural Network)을 이용하여 목재 표면 옹이를 구획화하고, 그 종류를 분류하였다. 본 연구에서 사용한 목재 재면 사진은 낙엽 송, 잣나무, 소나무, 삼나무, 편백, 더글라스 퍼, 라디에타 파인에서 획득한 938개의 제재목 사진을 사용 하였다. 제재목 사진에서 추출한 옹이 이미지는 1,172개로, 4 가지 종류로 분류하였다. 옹이의 종류와 위치에 대한 데이터베이스를 통해 제재목 표면의 옹이를 구획화하여 표시하고, 그 종류를 분류하는 알고리즘 학습을 진행하였다. 학습에 사용한 Mask R-CNN(Regions with Convolutional Neural Network) 모델은 resnet101을 이용하여 Feature Pyramid Network를 토대로 옹이 위치 예측 학습과 옹이 종류 분류 학습을 동시에 진행하였다. 목재 표면의 옹이 구획화 학습을 진행한 결과, 옹이 종류별 이미지의 편차가 존재하며, 옹이의 크기가 다양함에 불구하고 높은 정확도로 목재 표면의 옹이 탐지가 가능하였다. 200번의 반복학습결과, 학습이 반복될수록 학습 이미지셋에 과적합하는 현상이 발생하여 목재 문양이 옹이로 탐지되는 경우가 발생하였다. 하지만 높은 정확도로 분류가 가능하였기 때문에 다양한 옹이 형태를 추가로 학습시킨다면 더 높은 정확도로 옹이 구획화가 가능할 것으로 기대된다.",다국어 초록 정보 없음
딥러닝을 이용한 전문분야 문서 분류 시스템 개발,2019,[],"본 논문에서는 고도장비의 운용 및 정비를 위한 교육훈련 시스템 개발을 위해 자연어 처리와 딥러닝 기술을 이용하여 항공정비와 관련된 전문분야의 문서 분류가 가능한 방법을 제안하고자 한다. 문서 분류 모델의 개발을 위해 항공정비 교범을 텍스트 파일로 변환하여 총 4917개의 문서를 생성하였으며, 정비사 개인별 정비능력 관리(IMQC)를 기준으로 12개의 범주로 구분하였다. 수집된 문서는 전문분야의 문서인 점을 고려하여 전문용어 사전을 추가하였으며, KoNLPy를 이용하여 전처리를 수행하였다. 전문분야의 문서는 범주에 상관없이 문서 내용의 유사도가 매우 높은 특징을 가지고 있어, 특정 범주내에서 중요한 정도를 잘 표현 할 수 있는 TF-ICF를 이용하여 특징 추출을 하였다. 이후 합성곱 신경망(CNN)을 이용하여 특징 맵을 생성한 후 완전 결합 계층을 통하여 분류하였으며, 테스트 문서 983건을 분류한 결과 평균 73.6%의 분류성능을 보여주었다.",다국어 초록 정보 없음
고밀도 비디오 캡션 생성을 위한 의미 특징 학습,2019,"['고밀도 비디오 캡션 생성', '의미 특징 학습', '주의 집중', 'dense video captioning', 'semantic feature learning', 'attention']","본 논문에서는 고밀도 비디오 캡션 생성을 위한 새로운 심층 신경망 모델을 제안한다. 고밀도 비디오 캡션 생성은 하나의 입력 비디오로부터 다수의 이벤트 구간들을 찾아내고, 이들 각각에 관한 자연어 설명 문장을 생성하는 작업이다. 기존의 모델들에서는 합성곱 신경망을 통해 입력 비디오의 시각 특징 만을 추출하여 사용한 것과는 달리, 본 논문에서 제안하는 모델에서는 행위, 물체, 배경, 사람 등 중요한 이벤트 구성 요소들을 효과적으로 표현할 수 있는 고수준의 의미 특징들을 추가적으로 활용하였다. 또한 제안 모델에서는 순환 신경망인 LSTM을 이용하여 비디오 안에 포함된 이벤트 시간 영역들을 탐지하였다. 또, 제안 모델에서는 중요도에 따라 선택적으로 입력 특징들에 집중할 수 있도록, 캡션 생성 과정에 주의집중 메커니즘을 적용하였다. 고밀도 비디오 캡션 생성을 위한 대용량 벤치마크 데이터 집합인 ActivityNet Captions 데이터 집합을 이용한 다양한 실험을 통해, 본 논문에서 제안한 모델의 높은 성능과 우수성을 확인할 수 있었다.","In this paper, we propose a new deep neural network model for dense video captioning.Dense video captioning is an emerging task that aims at both localizing and describing all events in a video. Unlike many existing models, which use only visual features extracted from the given video through a sort of convolutional neural network(CNN), our proposed model makes additional use of high-level semantic features that describe important event components such as actions, people, objects, and backgrounds. The proposed model localizes temporal regions of events by using LSTM, a recurrent neural network(RNN). Furthermore, our model adopts an attention mechanism for caption generation to selectively focus on input features depending on their importance. By conducting experiments using a large-scale benchmark dataset for dense video captioning, AcitivityNet Captions, we demonstrate high performance and superiority of our model."
딥러닝을 이용한 스윙 시퀀스 영상 기반 3차원 골프 스윙 분석,2019,"['golf swing analysis', 'sequence image regression', 'deep learning']","빠르게 움직이는 골프 스윙 동작을 인간의 눈으로 평가하고 분석하는 것은 평가하는 사람의 주관에 따라 크게 달라질 수 있다. 본 논문에서는 최근 영상 인식 분야에서 좋은 성능을 나타내고 있는 딥러닝 기술을 이용해 단일 카메라 기반 스윙 분석 시스템의 한계를 극복하고, 3차원의 정량적 정보 추출 및 분석 방법을 연구한다. 먼저, 합성곱 신경망을 이용해 시퀀스 영상의 특징을 추출하고, 스윙 구간을 분류한다. 스윙 구간 정보를 갖는 시퀀스 특징은 양방향 장단기 메모리 기반의 스윙 분석 모델의 입력으로 사용되며, 바디-스웨이, 헤드-업, X-factor 분석을 수행한다. 각 분석 모델을 통한 스윙의 정량적 상태 예측 결과, 상체의 움직임 예측 RMSE 4.23, 머리 움직임 예측 RMSE 5.18, X-factor 예측 결과 RMSE 3.86의 성능으로 나타났다. 이 결과로 2차원 정면의 시퀀스 영상을 기반으로 3차원의 정량적 골프 스윙 분석이 가능함을 확인하였다.","The evaluation and analysis of the fast moving golf swing motion by human eyes can vary greatly depending on the evaluator's perspective. In this paper, we study the method of three-dimensional quantitative information extraction by overcoming the limitation of single camera based golf swing analysis system using deep learning which is showing good performance in image recognition field recently. First, the features of the sequence images are extracted using convolutional neural network, and the swing section is classified. Sequence features with swing section information are used as inputs to the bidirectional long short-term memory based swing analysis model, and perform body-swing, head-up, and X-factor value prediction. Experimental results showed that the performance of the upper body motion prediction RMSE 4.23, the head motion prediction RMSE 5.18, and the X-factor prediction result RMSE 3.86. As a result, it is confirmed that 2D frontal sequence images based 3D quantitative golf swing analysis is possible."
CNN을 활용한 IoT 스트림 데이터 패턴 분류 기법,2019,"['IoT', '스트림 데이터', '딥러닝', '패턴 분류', 'IoT', 'stream data', 'deep learning', 'pattern analysis']","사물 인터넷(Internet of Things, IoT) 환경의 발달로 다양한 종류의 센서들로부터 대량의 데이터가 생성되고 있으며, 이를 수집, 관리 및 분석하기 위한 빅데이터 기술이 중요해지고 있다. 최근에는 실시간으로 생성되는 대용량의 IoT 데이터 분석에 딥러닝 기술을 활용하여 특정 데이터 패턴이나 경향성의 분석을 수행하기 위한 연구가 진행되고 있다. 본 논문에서는 헬스케어 등 IoT 기반 서비스에의 활용 가능성이 높은 스트림데이터 중 하나인 ECG(Electrocardiogram, 심전도) 데이터에 대하여, 딥러닝 모델을 설계 및 적용함으로써 효율적인 분석을 가능하도록 하였다. 먼저, ECG 스트림 데이터의 패턴 분류를 위하여 합성곱 신경망(Convolutional Neural Networks, CNN) 기반의 딥러닝 모델을 설계하고, 이를 최적화하기 위한 다양한 파라미터들을 각각 모델의 구조와 학습에 관련한 파라미터들로 분리하여 실험을 설계 및 진행하였다. 또한, 분류 작업의 추가적인 성능 향상을 위하여, ECG 스트림 데이터에 대한 전처리 기법을 고안하여 적용해 보았다. 이러한 다양한 조건을 기반으로 설계된 실험들은, 서로 다른 센서에서 서로 다른 목적으로 수집되어 서로다른 특성을 갖는 두 가지의 ECG 스트림 데이터 세트 에 대하여 각각 수행되었다. 그 결과, 레이어가 깊을수록, 배치 크기가 큰 학습 모델일수록 IoT 스트림 데이터의 패턴 분류에 용이한 모델 구조라는 결론을 얻을수 있었다.","These days due to the development of the Internet of Things environment, big data technology is becoming important for collecting and managing large amounts of data. Recent studies are being conducted to incorporate deep learning technology into Internet of Things(IoT) data analysis in order to classify the specific pattern and trends. In this paper, ECG(Electrocardiogram) data, which could be useful for IoT services, is the input steam data, and a deep learning model structure suitable for data characteristics is found, so that IoT data analysis is efficiently performed. In order to classify the IoT stream data pattern, the experiments were conducted to find the best suitable model structure using the convolutional neural networks. To optimize the CNN, various models and parameter values were used to design various experiments. Also to enhance the classification performance, a preprocessing step is added to the existing convolutional neural networks model. The model structure parameters and the model learning parameters are divided into two major conditions. The experiment environment is set up and applied to two time series data with different characteristics. It is concluded that the deeper the layer and the larger the batch size, the easier model structure for IoT data pattern classification."
모노 카메라 영상과 딥 러닝을 이용한 차량 검출 및 거리 등급 분류에 관한 연구,2019,"['딥러닝', '객체검출', '거리추정', '단안카메라', 'Deep learning', 'Object Detection', 'Distance Estimation', 'Mono Camera']","본 연구에서는 차량에 부착된 모노 카메라와 딥 러닝을 이용하여 객체 검출 및 검출된 객체에 대한 거리정보를 바탕으로 하는 위험도 분류 시스템을 제안한다. 다양한 상황에서 기존 컴퓨터 비전 기법들보다 변화에 강인하며 검출 능력이 뛰어난 딥 러닝을 이용하여 주행 영상을 통해 주행환경 상에 있는 객체들을 검출한다. 이때 객체 검출기로는 합성 곱 신경망 네트워크를 기반으로 만들어진 YOLO v2(You Only Look Once v2)알고리즘을 이용하며, 해당 알고리즘은 사전에 ImageNet 1000 Class 데이터로 학습 된 Pre-trained model에 KITTI 데이터 셋 및 웹 포털 사이트에서 크롤링을 통해 획득한 12K개의 이미지를 이용하여 전이학습 하였다. 그리고 DB 구축 Tool을 이용하여 KITTI 데이터 셋에서 취득한 이미지와 캘리브레이션된 LiDAR 센서 데이터를 통해 검출된 객체와의 거리 정보를 취득하였다. 객체 검출기의 결과로는 Bounding Box의 이미지 내 좌표인 x,y와 Bounding Box의 이미지 내 크기인 width, height 정보가 나온다. 객체와의 거리정보를 특정 구간 단위로 분류하여 Class화 하였고, 해당 Class(거리 등급)와 객체 검출 정보인 Bounding box 정보들을 Multi-layer Perceptron을 이용하여 분류한다.","In this study, we propose a risk classification system based on distance information of object detected and objects detection using mono camera based on deep learning. It detects the objects in the driving environment through driving images by using deep learning which is robust against change and has superior detection ability than existing computer vision techniques in various situations. In this case, we use YOLO v2 (You Only Look Once v2) algorithm, which is based on a convolution neural network as an object detector. The algorithm uses a KITTI data set and a web portal The site was trained using 12K images acquired through crawling. Using the DB construction tool, we obtained the distance information between the image obtained from the KITTI dataset and the detected object through the calibrated LiDAR sensor data. The result of the object detector is x, y coordinates in the image of the bounding box, and width and height information in the image of the bounding box. Classification is made by classifying the distance information with objects in a specific section, and classification of the class (distance class) and object detection information, Bounding box information, using Multi-layer Perceptron."
