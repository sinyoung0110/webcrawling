title,date,keywords,abstract,multilingual_abstract
합성곱신경망을 이용한 제주도 강수패턴 분석 연구,2019,"['Precipitation', 'Convolution NN (Neural Network)', 'Texture', 'weather satellite', 'Jeju', '강수패턴', '합성곱신경망', '텍스처', '기상위성', '제주지역']",,"Since Jeju is the absolute weight of agriculture and tourism, the analysis of precipitation is more important than other regions. Currently, some numerical models are used for analysis of precipitation of Jeju Island using observation data from meteorological satellites. However, since precipitation changes are more diverse than other regions, it is difficult to obtain satisfactory results using the existing numerical models. In this paper, we propose a Jeju precipitation pattern analysis method using the texture analysis method based on Convolution Neural Network (CNN). The proposed method converts the water vapor image and the temperature information of the area of ​​Jeju Island from the weather satellite into texture images. Then converted images are fed into the CNN to analyse the precipitation patterns of Jeju Island. We implement the proposed method and show the effectiveness of the proposed method through experiments."
합성곱신경망의 학습 및 테스트자료에 따른 골다공증 판독에 미치는 영향,2019,"['Mandible', 'Osteoporosis', 'Panoramic radiograph', 'Computer']",,"This study aimed to test a convolutional neural network (CNN) in two different settings of training and testing data. Panoramic radiographs were selected from 1170 female dental patients (mean age 49.19 ± 21.91 yr). The cortical bone of the mandible inferior border was evaluated for osteoporosis or normal condition on the panoramic radiographs. Among them, 586 patients (mean age 27.46 ± 6.73 yr) had normal condition, and osteoporosis was interpreted on 584 patients (mean age 71.00 ± 7.64 yr). Among them, one data set of 569 normal patients (mean age 26.61 ± 4.60 yr) and 502 osteoporosis patients (mean age 72.37 ± 7.10 yr) was used for training CNN, and the other data set of 17 normal patients (mean age 55.94 ± 4.0 yr) and 82 osteoporosis patients (mean age 62.60 ± 5.00 yr) for testing CNN in the first experiment, while the latter was used for training CNN and the former for testing CNN in the second experiment.The error rate was 15.15% in the first experiment and 5.14% in the second experiment. This study suggests that age-matched training data make more accurate testing results."
합성곱신경망 테스트 자료에 따른 파노라마 방사선 사진에서의 골다공증 판독의 차이,2019,"['CNN', 'Osteoporosis', 'DR panoramic radiographs', 'CR panoramic radiographs']",,"This study was conducted as part of a series of studies to introduce the Convolutional Neural Network(CNN) into the diagnostic eld of osteoporosis. The purpose of this study was to compare the results when testing Digital Radiography(DR) and Computed adiography(CR) panoramic radiographs by CNN that were trained by DR panoramic radiographs. The digital panoramic radiographs f females who visited for the purpose of diagnosis and treatment at Chonnam National University Dental Hospital were taken. Two Oral and Maxillofacial Radiologists were selected for the study to compare the panoramic radiographs with normal and osteoporosis mages. Among them, 1068 panoramic radiographs of females{Mean [± standard deviation] age: 49.19 ± 21.91 years} obtained by DR method were used for training of CNN. 200 panoramic radiographs of females{Mean [± standard deviation] age: 63.95 ± 6.45 years} btained by DR method and 202 panoramic radiographs of females{Mean [± standard deviation] age: 62.00 ± 6.86 years} obtained by R method were used for testing of CNN. When the DR panoramic radiographs were tested, the Accuracy was 92.5%. When the CR anoramic radiographs were tested, the Accuracy was 76.2%. It can be seen that the CNN trained by DR panoramic radiographs is uitable to be tested with the same DR panoramic radiographs."
합성곱신경망을 이용한 안전문화 수준 분류,2019,"['Artificial intelligence', 'Convolution neural network', 'Safety culture', 'Survey data', 'Classification', 'Classifier']",,"Objective: The aim of this study is to investigate whether an artificial intelligence technique can be successfully applied to safety culture survey data classification.Background: Without help of artificial intelligence technique, classifying safety culture level from safety culture scores collected from a large-scale survey would require a lot of experts"" time and effort.Method: Two convolution layers and 1 pooling layer was used as the middle layer of the artificial neural network to design a classifier for safety culture level. 1045 safety culture survey data collected from power plant workers used to train and validate the classifier.Results: After 40 epochs"" training the classifier approached near 95% precision in classifying ""safe"" and ""need to be improved"" classes of safety culture level. Precision, recall and F1-score for the test data set showed over 95% of accuracy performance.Conclusion: An artificial intelligence technique using such as convolution neural network can help classification of safety culture survey data.Application: The safety culture level classifier using deeper neural network and big survey data might improve the performance and might substitute expert interviewers for safety culture evaluation."
합성곱신경망 기반의 StyleGAN 이미지 탐지모델,2019,"['Deep Learning', 'Generative Adversarial Network', 'Convolutional Neural Network', 'Fake Image Detection', 'Face Detection']",,"As artificial intelligence technology is actively used in image processing, it is possible to generate high-quality fake images based on deep learning. Fake images generated using GAN(Generative Adversarial Network), one of unsupervised learning algorithms, have reached levels that are hard to discriminate from the naked eye. Detecting these fake images is required as they can be abused for crimes such as illegal content production, identity fraud  and defamation. In this paper, we develop a deep-learning model based on CNN(Convolutional Neural Network) for the detection of StyleGAN fake images. StyleGAN is one of GAN algorithms and has an excellent performance in generating face images. We experiment with 48 number of experimental scenarios developed by combining parameters of the proposed model. We train and test each scenario with 300,000 number of real and fake face images in order to present a model parameter that improves performance in the detection of fake faces."
스마트 구조물 균열 감지를 위한 1차원 합성곱신경망(1D CNN) 딥러닝을 이용한 파괴 신호 특정 기법,2019,"['구조물 모니터링', '기계 학습', '1D Convolution', '진동 센서', 'Structure Health Monitoring', 'Machine Learning', '1D Convolution Network', 'Accelerometer']","초고층 빌딩, 대형 구조물 등의 건설이 일반화됨에 따라 점차 노후화 및 지진, 태풍 등의 자연재해에 의한 구조물의 손상 모니터링에 대한 필요도가 증가하고 있다. 특히, 하부구조인 구조물 기초에서의 손상은 구조물 전체의 건전도에 부정적인 영향을 미칠 수 있기 때문에, 이에 대한 감지는 매우 중요하다. 구조물 건전도 비파괴검사 방법으로는 대표적으로 음향, 진동 감지기법 등이 제안되었으며, 이에 음향, 진동 감지기에 의해 수집된 신호를 해석하여 균열의 발생 위치 및 균열의 크기, 내구도 등을 역으로 추정하는 방법에 관한 연구가 실험실 스케일에서 많이 수행되어왔다. 하지만 실제로 현장에서는 적용되는 경우가 극히 드문 데 그 이유는 평소 발생하는 노이즈 신호(정상 신호)와 손상파괴 신호(비정상 신호)를 구분하는 것이 어렵기 때문이다. 특히 노이즈 신호와 구조물 파괴 신호가 동시에 수집될 때 이를 구분하는 것은 더욱 어려워진다. 이에 본 연구에서는 노이즈 신호(정상 신호)와 손상파괴 신호(비정상 신호)를 수집하고, 무작위로 합성된 신호를 딥러닝 기법인 1D convolutional neural network model을 통해서 정상 신호와 비정상 신호를 구분하는 알고리즘을 개발하였다. 개발된 알고리즘을 사용하면 현장에서 실시간으로 수집된 신호를 구분할 수 있게 됨으로써 구조물 안전성 변화 예측을 통해 재산 및 인명 피해 위험성을 최소화할 수 있을 것으로 생각한다.","Structures can be damaged by natural disasters such as earthquakes and typhoons. In particular, any damage to the foundation of a structure can present critical problems. Therefore, a smart monitoring technique such as the acoustic emission method is required to detect internal cracks and other types of structural damage. Many laboratory studies on this method have been conducted to estimate the locations and sizes of cracks as well as the resulting changes in structural durability using collected acoustic signals. However, the method has rarely been applied in the field because identifying damage signals from acquired signals, which can contain ambient noise, is difficult. We developed a deep learning algorithm based on a one-dimensional convolutional neural network method that can identify damage or crack signals generated from concrete failure from randomly synthesized signals. Using the developed algorithm, we were able to distinguish damage signals from random ambient noise signals. This algorithm enables real-time monitoring of concrete structures, thus providing a smart monitoring strategy."
비디오 얼굴 식별 성능개선을 위한 다중 심층합성곱신경망 결합 구조 개발,2019,"['Video Face Identification', 'Face Sequences', 'Deep Convolution Neural Network', 'Class Confidence Matrix', 'Network Combination']",,"In this paper, we propose a novel way of combining multiple deep convolutional neural network (DCNN) architectures which work well for accurate video face identification by adopting a serial combination of 3D and 2D DCNNs. The proposed method first divides an input video sequence (to be recognized) into a number of sub-video sequences. The resulting sub-video sequences are used as input to the 3D DCNN so as to obtain the class-confidence scores for a given input video sequence by considering both temporal and spatial face feature characteristics of input video sequence. The class-confidence scores obtained from corresponding sub-video sequences is combined by forming our proposed class-confidence matrix. The resulting class-confidence matrix is then used as an input for learning 2D DCNN learning which is serially linked to 3D DCNN. Finally, fine-tuned, serially combined DCNN framework is applied for recognizing the identity present in a given test video sequence. To verify the effectiveness of our proposed method, extensive and comparative experiments have been conducted to evaluate our method on COX face databases with their standard face identification protocols. Experimental results showed that our method can achieve better or comparable identification rate compared to other state-of-the-art video FR methods."
합성곱 신경망을 이용한 아스팔트 콘크리트 도로포장 표면균열 검출,2019,"['딥러닝', '합성곱 신경망', '아스팔트 도로포장', '아스팔트 도로포장 표면균열', 'Deep learning', 'Convolutional Neural Network', 'Asphalt Pavement', 'Surface Crack']","본 연구에서는 아스팔트 콘크리트 도로포장의 표면균열 검출을 위해 합성곱 신경망을 이용하였다. 합성곱 신경망의 학습에 사용되는 표면균열 이미지 데이터의 양에 따른 합성곱 신경망의 성능향상 정도를 평가하였다. 사용된 합성곱 신경망의 구조는 5개의 층으로 구성되어있으며, 3x3 크기의 convolution filter와 2x2 크기의 pooling kernel을 사용하였다. 합성곱 신경망의 학습을 위해서 도로노면 조사 장비를 통해 구축된 국내 도로포장 표면균열 이미지를 활용하였다. 표면균열 이미지 데이터를 학습한 합성곱 신경망 모델의 표면균열 검출 정확도, 정밀도, 재현율, 미검출율, 과검출율을 평가하였다. 가장 많은 양의 데이터를 학습한 합성곱 신경망 모델의 표면균열 검출 정확도, 정밀도, 재현율은 96.6% 이상, 미검출율, 과검출율은 3.4% 이하의 성능을 나타내었다.","A Convolution Neural Network(CNN) model was utilized to detect surface cracks in asphalt concrete pavements. The CNN used for this study consists of five layers with 3x3 convolution filter and 2x2 pooling kernel. Pavement surface crack images collected by automated road surveying equipment was used for the training and testing of the CNN. The performance of the CNN was evaluated using the accuracy, precision, recall, missing rate, and over rate of the surface crack detection. The CNN trained with the largest amount of data shows more than 96.6% of the accuracy, precision, and recall as well as less than 3.4% of the missing rate and the over rate."
Word2Vec과 앙상블 합성곱 신경망을 활용한 영화추천 시스템의 정확도 개선에 관한 연구,2019,"['Text Analysis(Word2Vec)', 'Collaborative Filtering', 'Recommender Systems', 'Ensemble Model', 'Convolutional Neural Networks', 'Deep Learning', '텍스트 분석(Word2Vec)', '협업필터링', '추천시스템', '앙상블 모델', '합성곱 신경망', '딥러닝']","웹 추천기법에서 가장 많이 사용하는 방식 중의 하나는 협업필터링 기법이다. 협업필터링 관련 많은 연구에서 정확도를 개선하기 위한 방안이 제시되어 왔다. 본 연구는 Word2Vec과 앙상블 합성곱 신경망을 활용한 영화추천 방안에 대해 제안한다. 먼저 사용자, 영화, 평점 정보에서 사용자 문장과 영화 문장을 구성한다. 사용자 문장과 영화 문장을 Word2Vec에 입력으로 넣어 사용자 벡터와 영화 벡터를 구한다. 사용자 벡터는 사용자 합성곱 모델에 입력하고, 영화 벡터는 영화 합성곱 모델에 입력한다. 사용자 합성곱 모델과 영화 합성곱 모델은 완전연결 신경망 모델로 연결된다. 최종적으로 완전연결 신경망의 출력 계층은 사용자 영화 평점의 예측값을 출력한다. 실험결과 전통적인 협업필터링 기법과 유사 연구에서 제안한 Word2Vec과 심층 신경망을 사용한 기법에 비해 본 연구의 제안기법이 정확도를 개선함을 알 수 있었다.","One of the most commonly used methods of web recommendation techniques is collaborative filtering. Many studies on collaborative filtering have suggested ways to improve accuracy. This study proposes a method of movie recommendation using Word2Vec and an ensemble convolutional neural networks. First, in the user, movie, and rating information, construct the user sentences and movie sentences. It inputs user sentences and movie sentences into Word2Vec to obtain user vectors and movie vectors. User vectors are entered into user convolution model and movie vectors are input to movie convolution model. The user and the movie convolution models are linked to a fully connected neural network model. Finally, the output layer of the fully connected neural network outputs forecasts of user movie ratings. Experimentation results showed that the accuracy of the technique proposed in this study accuracy of conventional collaborative filtering techniques was improved compared to those of conventional collaborative filtering technique and the technique using Word2Vec and deep neural networks proposed in a similar study."
딥 러닝 기법을 이용한 오피니언 마이닝 분석과 성과에 관한 실증연구: 합성곱 신경망 모델과 머신러닝 모델간 성과비교를 중심으로,2019,"['Deep learning', 'Convolutional neural network', 'Sentiment analysis', 'Opinion mining', 'Machine learning classifiers', 'Financial supervisory policy', '딥 러닝', '합성곱 신경망', '감성분석', '오피니언 마이닝', '머신러닝 분류기']","본 연구는 딥 러닝 기법인 합성곱 신경망 (CNN: Convolutional Neural Network)을 이용하여 금융자료에 관한 사용자의 오피니언을 추정하는 오피니언 마이닝 (Opinion mining) 방법과 그 결과를 설명한다. 본 연구에서는 다음과 같이 합성곱 신경망의 효과성을 검증하였다. 첫째, 스터디1은 주식관련 온라인 리뷰 데이터를 분석하였다. 즉, 형태소 분석단계를 거쳐 속성벡터를 만들어 리뷰 문장의 감성점수를 산출하였다. 해당 문장의 감성점수에 따라 오피니언을 3-클라스, 5-클라스 문제로 구분하여 실증분석을 하였다. 둘째, 스터디2에서는 청와대 국민청원에 게시된 금융관련 국민청원 텍스트 문장을 분석하여 청원인원을 추정하였다. 청원게시판에 등재된 청원 인원을 분위 수에 따라 분류하여 2-클라스 문제 (50%이상, 50% 미만) 4-클라스 문제 (75%이상, 50%이상, 25%이상, 25%미만)로 분류하였다. 스터디1, 2의 실증분석결과 정확도, 정밀도, 재현율, F1 점수 등 모든 성과지표에서 벤치마킹용 분류기와 비교할 때 합성곱 신경망이 더 우수한 성과를 보였다. 따라서, 합성곱 신경망을 이용함으로써 금융감독 관련 정책 및 활동을 효과적으로 수행할 수 있음을 실증적으로 확인하였다.",
합성곱 신경망을 이용한 선박 기관실에서의 화재 검출에 관한 연구,2019,"['Fire Detection', 'Image-based', 'Ship Engine Room', 'Convolution Neural Network', 'YOLO', '화재검출', '영상기반', '선박 기관실', '합성곱 신경망', '욜로']","화재의 초기 검출은 인명과 재화의 손실을 최소화하기 위한 중요한 요소이다. 불꽃과 연기를 신속하면서 동시에 검출해야 하며 이를 위해 영상 기반의 화재 검출에 관한 연구가 다양하게 진행되고 있다. 기존의 화재 검출은 불꽃과 연기의 특징을 추출하기 위해 여러 알고리즘을 거쳐서 화재의 검출 유무를 판단하므로 연산량이 많이 소모되었으나, 딥러닝 알고리즘인 합성곱 신경망을 이용하면 별도의 과정이 생략되므로 신속하게 검출할 수 있다. 본 논문에서는 선박 기관실에서 화재 영상을 녹화한 데이터로 실험을 수행하였다. 불꽃과 연기의 특징을 외각 상자로 추출한 후 합성곱 신경망 중 하나인 욜로(YOLO)를 이용하여 학습하고 결과를 테스트하였다. 실험 결과를 검출률, 오검출률, 정확도로 평가하였으며 불꽃은 0.994, 0.011, 0.998, 연기는 0.978, 0.021, 0.978을 나타내었고, 연산시간은 0.009s를 소모됨을 확인하였다.","Early detection of fire is an important measure for minimizing the loss of life and property damage. However, fire and smoke need to be simultaneously detected. In this context, numerous studies have been conducted on image-based fire detection. Conventional fire detection methods are compute-intensive and comprise several algorithms for extracting the flame and smoke characteristics. Hence, deep learning algorithms and convolution neural networks can be alternatively employed for fire detection. In this study, recorded image data of fire in a ship engine room were analyzed. The flame and smoke characteristics were extracted from the outer box, and the YOLO (You Only Look Once) convolutional neural network algorithm was subsequently employed for learning and testing. Experimental results were evaluated with respect to three attributes, namely detection rate, error rate, and accuracy. The respective values of detection rate, error rate, and accuracy are found to be 0.994, 0.011, and 0.998 for the flame, 0.978, 0.021, and 0.978 for the smoke, and the calculation time is found to be 0.009 s."
합성곱 신경망을 이용한 보청기 환경잡음 분류 알고리즘,2019,"['Hearing aids', 'Noise classification', 'convolutional neural networks', 'Spectrogram', 'Hearing aids satisfaction']","본 논문은 보청기의 환경잡음 분류를 위해 소리 신호를 이미지 신호로 변환하여 합성곱 신경망(CNN, convolutional neural networks)을 적용한 잡음 분류 알고리즘에 관한 것이다. 장시간 현장 녹음한 생활 잡음을 이미지 신호로 변환하기 위해 스펙트로그램을 확인하고, sharpening mask와 median filter를 적용하여 합성곱 신경망 기법의 분류 결과를 비교하였다. 1초/2.5초/5초 단위 시간의 스펙트로그램 이미지 분류 결과, 1초의 합성곱 신경망 분류율이 가장 높았으며, 단위 시간이 증가 할수록 분류율이 감소하였다. 합성곱 신경망의 입력 데이터에 제안된 필터를 적용하여 분류율 결과를 비교했을 때, 필터를 적용하지 않은 스펙트로그램 이미지를 분류율이 median filter를 적용했을 때보다 최대 약 2.8% 상승한 것을 확인하였다.","In this paper, we present the environment noise classification algorithm using CNN(convolutional neural networks) for hearing aids by converting a sound signal to an image signal. We made spectrogram images from sound signal which have recorded the environment noise around hearing aids, and results of classification using CNN were compared by applying Sharpening Mask and Median Filter. As a result of the spectrogram image classification rate in 1sec. was the highest, and the classification rate was decreased as the time increased to 5sec. When comparing the proposed classification rate results according to the CNN input data, the classification rate without the filter was up to about 2.8% higher than that with the median filter."
합성곱 신경망 기반의 딥러닝에 의한 수치표면모델의 객체분류,2019,"['합성곱 신경망', '딥러닝 모델', '학습 및 검증 데이터', '수치표면모델 분류', 'CNN', 'DL Model', 'Training and Validation Data', 'DSM Classification']","최근 딥러닝(DL)은 여러 분야에서 급속도로 활용되고 있으며, 특히 영상으로부터 객체를 인식하여 분류하고 인식하기 위한 컴퓨터비전 분야에서 활발하게 연구가 진행되고 있다. 영상분야에서는 주로 합성곱 신경망(CNN)을 이용한 딥러닝 모델의 성능 향상에 주력하고 있다. 대부분의 합성곱 신경망은 영상을 학습시켜 영상분류 및 객체인식에 활용하고 있지만, 본 논문에서는 독일 사진측량, 원격탐사 및 공간정보학회(DGPF)가 구축하고 국제 사진측량 및 원격탐사학회(ISPRS)가 제공하는 데이터 셋 중에서 수치표면모델(DSM)과 이 데이터로부터 생성한 경사 및 주향 정보를 효율성과 성능이 우수하다고 평가받는 합성곱 신경망기반의 SegNet 모델에 적용하여 객체를 분류하고 분석하였다. 딥러닝은 고사양의 컴퓨터 시스템과 다량의 학습 데이터와 라벨 데이터가 필요하고, 다수의 시행착오에 의한 풍부한 경험이 요구된다. 또한 본 논문에서는 한정된 수량의 데이터로부터 효율적인 학습을 위한 데이터 생성 방법을 제시하고 수치표면모델을 분류하였다. 분석 결과 수치표면모델 데이터와 이로부터 도출한 부가적인 데이터를 딥러닝 모델에 적용해도 객체를 타당한 정확도로 분류할 수 있음을 확인하였다.","Recently, DL (Deep Learning) has been rapidly applied in various fields. In particular, classification and object recognition from images are major tasks in computer vision. Most of the DL utilizing imagery is primarily based on the CNN (Convolutional Neural Network) and improving performance of the DL model is main issue. While most CNNs are involve with images for training data, this paper aims to classify and recognize objects using DSM (Digital Surface Model), and slope and aspect information derived from the DSM instead of images. The DSM data sets used in the experiment were established by DGPF (German Society for Photogrammetry, Remote Sensing and Geoinformatics) and provided by ISPRS (International Society for Photogrammetry and Remote Sensing). The CNN-based SegNet model, that is evaluated as having excellent efficiency and performance, was used to train the data sets. In addition, this paper proposed a scheme for training data generation efficiently from the limited number of data. The results demonstrated DSM and derived data could be feasible for semantic classification with desirable accuracy using DL."
해상 영상에서 관심영역 추출과 합성곱 신경망을 활용한 선박 분류,2019,"['선박 분류', '딥러닝', '컴퓨터 비전', '영상처리', 'Ship classification', 'Deep Learning', 'Computer Vision', 'Image Processing']","최근에 해양에서는 선박 스스로 주변 상황을 인지하고 운항할 수 있는 자율운항 기술개발이 활발하게 이루어지고 있다. 이를 위해, 카메라를 통한 영상정보를 활용하여 인간의 시각 정보를 대신할 수 있는 기술에 대한 중요성이 대두되고 있다. 카메라 영상을 기반으로 한 상황인지 기술을 위해서는 영상에서 존재하는 다양한 객체 정보를 분석하는 객체 분류 기술이 필수적이다. 본 논문에서는 해양 영상에서 관심 영역 추출과 합성곱 신경망을 활용하여 선박 분류 정확도를 향상시킬 수 있는 방법을 제안한다. 본 논문에서 제안된 방식의 성능을 검증하기 위해 공개 데이터 셋을 이용하여 기존의 합성곱 신경망 기반 방법과의 비교 실험을 수행하였으며, 실험을 통해 본 논문에서 제안된 방식이 선박 분류 정확도를 향상시킬 수 있음을 확인하였다. 제안된 방법을 활용하여 자율운항선박에서는 다른 해상 장비와의 센서 퓨전을 통하여 객체 데이터의 신뢰성을 확보할 수 있으며, 이를 통해 충돌 회피 및 안전한 운항이 가능할 것으로 기대된다.","Recently, autonomous navigation technology has been actively developed in order to recognize and operate the vessel itself. For this purpose, importance is attached to technologies that can substitute human visual information by utilizing image information through a camera. For the context recognition based on the camera image, object classification technology for analyzing various object information existing in the image is essential. In this paper, we propose a method to improve the accuracy of ship classification by using region of interest and artificial neural network. In order to verify the performance of the propose method in this paper, we performed a comparative experiment with the convolution artificial neural network based on the open data set. Experimental results show that the proposed method improves the accuracy of vessel classification. By using the proposed method, it is possible to secure the reliability of object data through sensor fusion with autonomous vessels, and it is expected that collision avoidance and safe operation will be possible."
자율운항선박의 국제해상충돌예방규칙 준수를 위한 합성곱 신경망 기반의 선박 분류에 관한 연구,2019,"['자율운항선박', '선박 분류', '국제해상충돌예방규칙', '합성곱 신경망', 'Autonomous Ships', 'Vessel Classification', 'COLREGs', 'Convolutional Neural Networks']","최근 자율운항선박에 대한 관심이 증가하고 있으며, 바다를 항해하는 자율운항선박은 유인선과 같이 국제해상충돌방지규칙을 준수해야한다. 따라서 본 논문에서는 자율운항선박이 국제해상충돌예방규칙을 준수하기 위해서 필요한 선박 범주 및 합성곱 신경망 기반의 선박 분류 기술을 제안하였다. 먼저 국제해상충돌예방규칙을 분석하여 자율운항선박이 구별해야 되는 14개의 선박 범주를 정의하였다. 또한 본 논문에서 정의된 선박 범주에 맞도록 인터넷 영상검색 및 기존 데이터 셋 정제를 통하여 40,300장 규모의 선박 범주 분류 데이터 셋을 구축하였다. 마지막으로 최신 합성곱 신경망 모델을 구축된 선박 범주 분류 데이터 셋에 적용하여 선박 범주 분류 성능을 분석하였다. 실험결과 전이학습을 통하여 학습된 Inception-ResNet v2 모델은 14개 선박 범주를 91%의 높은 정확도로 분류함을 확인하였다.","The interest in autonomous ships for marine industries has increased significantly over the past few years and autonomous ships also must follow maritime laws in the same way as regular ships operated by crews. Therefore, in this paper, we propose the vessel taxonomy for COLREGs compliance of autonomous ships and evaluate the performance of the vessel classification method using CNNs. First, we define the vessel taxonomy for complying with maritime laws by analyzing the COLREGs. And then, we build our dataset separated manually by the vessel taxonomy. For the dataset, 40,300 images are collected by image search on websites and refining the publicly available dataset. Finally, the state-of-the-art CNN model is applied to evaluate the recognition rate of our dataset. The experimental results show that the Inception-ResNet v2 model which is trained by transfer learning effectively classifies the ships with a high accuracy of 91%."
합성곱 신경망을 위한 Elastic Multiple Parametric Exponential Linear Units,2019,"['Elastic Multiple Parametric Exponential Linear Units', 'activation function', 'convolutional neural network', 'image classification', 'deep learning', 'Elastic Multiple Parametric Exponential Linear Units', '활성화 함수', '합성곱 신경망', '이미지분류', '딥러닝']","활성화 함수는 신경망 모델의 비선형성과 깊이를 결정하는 중요한 요소이다. Rectified Linear Units (ReLU)가 제안된 이후, 평균값을 0에 가깝게 하여 학습의 속도를 높인 Exponential Linear Units (ELU)나 함수 기울기에 변화를 주어 성능을 향상시킨 Elastic Rectified Linear Units (EReLU)같은 다양한 형태의 활성화 함수가 소개되었다. 우리는 서로 다른 ELU와 EReLU를 일반화한 형태의 활성화 함수인 Elastic Multiple Parametric Exponential Linear Units (EMPELU)를 제안한다. EMPELU는 양수 영역에서는 임의의 범위로 기울기 변동을 주면서, 음수 영역은 학습 파라미터를 이용해 다양한 형태의 활성화 함수를 형성하도록 하였다. EMPELU는 합성곱 모델 기반 CIFAR-10/100의 이미지 분류에서 기존 활성화 함수에 비해 정확도 및 일반화에서 향상된 성능을 보였다.","Activation function plays a major role in determining the depth and non-linearity of neural networks. Since the introduction of Rectified Linear Units for deep neural networks, many variants have been proposed. For example, Exponential Linear Units (ELU) leads to faster learning as pushing the mean of the activations closer to zero, and Elastic Rectified Linear Units (EReLU) changes the slope randomly for better model generalization. In this paper, we propose Elastic Multiple Parametric Exponential Linear Units (EMPELU) as a generalized form of ELU and EReLU. EMPELU changes the slope for the positive part of the function argument randomly within a moderate range during training, and the negative part can be dealt with various types of activation functions by its parameter learning. EMPELU improved the accuracy and generalization performance of convolutional neural networks in the object classification task (CIFAR-10/100), more than well-known activation functions."
합성곱 신경망 기반의 PPG 신호 동잡음 구간 검출,2019,"['광맥파계', '생체신호', '동잡음', '인공 신경망', '합성곱 신경망', 'Photoplethysmographic', 'Bio-signal', 'Motion artifact', 'Artificial neural network', 'Convolutional neural network']",,"Among the various bio-signals, Photoplethysmographic (PPG) is widely used in areas such as u-health and human factor evaluation due to its low cost of measurement and freedom of user’s motion. Despite its advantages, PPG signal tends to be corrupted by the movement of user. In this study, we proposes the method for detecting the motion artifact in PPG signals using CNN (Convolutional Neural Network). Continuous PPG signals were divided into multiple pulse signals, converted to image, and then each pulse signal is used for training. We have used 3,000 normal signals and 3000 corrupted signals from PhysioNet database for training. With the proposed method, the signals corrupted by motion artifact were successfully detected with 92% accuracy."
합성곱 신경망 기반 저조도영상의 반사 영상 생성,2019,"['Low-light image', 'Retinex', 'Convolutional neural network', 'Reflectance', 'Illumination']","저조도 영상의 개선을 위해서 밝기 및 대조 개선, 조명 성분 감쇄 등의 다양한 연구가 진행됐다. 기존의 hand-crafted 방법에서 인공신경망으로 기존 기법들을 대체하는 연구가 최근에 진행 중이다. 본 논문에서는 조명 광원이 존재하는 저조도 영상으로부터 조명 성분을 감쇄하고, 반사 성분만을 생성하는 기법을 합성곱 신경망으로 대체하는 방법을 제안한다. 실험에서는 102장의 저조도 영상으로 학습시킨 합성곱 신경망으로 만족스러운 반사 영상을 생성하였다.",
합성곱 신경망(Convolutional Neural Network)을 활용한 지능형 유사상표 검색 모형 개발,2019,"['Deep Learning', 'Convolutional Neural Network', 'Trademark Retrieval System', 'Image retrieval Algorithm', '합성곱신경망', '딥 러닝', '상표 검색 시스템', '이미지 검색 알고리즘']","전 세계적으로 온라인 상거래 시장 규모가 성장함에 따라 국제 및 국내 기업의 상표권이 침해되는 사례가 빈번하게 발생하고 있다. 다양한 연구 및 보고서에 따르면, 해외 기업 또는 개인이 국내 기업의 상표권을 침해한 사례와, 국내 기업 간 발생하는 상표권 분쟁 사례가 증가하고 있는 것으로 나타나고 있으며, 특허청의 보고서에 따르면 기업의 규모가 작을수록 상표보호를 위한 사전 예방활동을 수행하지 않는다고 응답한 비율이 높은 것으로 나타났다. 이러한 문제는 선등록 상표에 대한 사전조사 또는 자사의 상표보호를위해 소요되는 인력과 비용이 원인인 것으로 판단된다.한편, 국내에서 선등록상표에 대한 사전조사를 위해 상용되는 서비스를 살펴보면 상표 이미지를 활용한검색 서비스를 제공하고 있지 않은 상황이다. 이로 인해 국내 대다수의 기업은 자사의 상표 보호 및 선등록 상표에 대한 사전조사 수행 시 방대한 양의 선등록된 상표를 수작업으로 조사해야하는 문제가 발생한다.따라서 본 연구에서는 기업의 상표권 보호 및 선등록 상표에 대한 사전조사 수행 시 투입되는 인력 및비용절감과, 국내외에서 발생하고 있는 상표권 침해 문제를 해결하기 위해 합성곱 신경망 기법을 활용한지능형 유사 상표 검색 모델을 개발하고자 한다. 지적 재산권 전문가가 선정한 테스트 데이터를 활용하여지능형 유사 상표 검색 모델의 정확도를 측정한 결과 ResNet V1 101의 성능이 가장 높게 나타났다. 해당결과를 통해 이미지 분류 알고리즘이 단순한 사물 인식 분야뿐만 아니라 이미지 검색 분야에서도 높은 성능을 나타낸다는 것을 실증적으로 입증했으며, 본 연구는 실제 상표 이미지 데이터를 활용했다는 측면에서실제 산업 환경에서 활용성이 높을 것으로 사료된다.","Recently, many companies improving their management performance by building a powerful brand value which is recognized for trademark rights. However, as growing up the size of online commerce market, the infringement of trademark rights is increasing. According to various studies and reports, cases of foreign and domestic companies infringing on their trademark rights are increased. As the manpower and the cost required for the protection of trademark are enormous, small and medium enterprises(SMEs) could not conduct preliminary investigations to protect their trademark rights.Besides, due to the trademark image search service does not exist, many domestic companies have a problem that investigating huge amounts of trademarks manually when conducting preliminary investigations to protect their rights of trademark.Therefore, we develop an intelligent similar trademark search model to reduce the manpower and cost for preliminary investigation. To measure the performance of the model which is developed in this study, test data selected by intellectual property experts was used, and the performance of ResNet V1 101 was the highest. The significance of this study is as follows. The experimental results empirically demonstrate that the image classification algorithm shows high performance not only object recognition but also image retrieval. Since the model that developed in this study was learned through actual trademark image data, it is expected that it can be applied in the real industrial environment."
LeafNet: 합성곱 신경망을 이용한 식물체 분할,2019,"['Deep learning', 'Segmentation', 'Plant phenomics', 'Phenomics system', 'CNN', '딥 러닝', '분할', '식물 표현체', '피노믹스 시스템', '합성곱 신경망']","식물 표현체(plant phenomics) 연구는 우수한 형질의 식물 품종과 유전적 특성을 선별하기 위해 여러 식물체의 형태적 특징을 관측하고, 획득한 영상 빅데이터를 분석하는 기술이다. 기존의 방법은 검출 대상에 따라 직접 색상 임계값을 변경해야 하기 때문에 빅데이터를 다루는 정밀검정시스템에 적용하기 어렵다. 본 논문에서는 정밀검정시스템을 위한 식물체와 배경의 자동 분할이 가능한 합성곱 신경망(Convolution neural network: CNN) 구조를 제안한다. LeafNet은 9개의 컨벌루션 계층과 식물의 유무를 판단하기 위한 시그모이드(Sigmoid) 활성화 함수로 구성된다. LeafNet을 이용한 학습 결과, 식물 모종 영상에 대하여 정밀도 98.0%, 재현율 90.3%의 결과가 도출되어 정밀검정시스템의 적용 가능성을 확인하였다.",
자모 단위 합성곱 신경망 기반 맞춤법 오류가 포함된 자주 묻는 질문 자동 분류,2019,"['sentence classification', 'data with spelling errors', 'frequently asked questions', 'class embedding', '문장 분류', '맞춤법 오류가 포함된 데이터', '자주 묻는 질문', '클래스 임베딩']","웹이나 모바일 사용자는 홈페이지에 구축된 자주 묻는 질문 시스템(Frequently Asked Question: FAQ, 이하 FAQ)을 이용하여 원하는 정보를 얻는다. 기존 FAQ 시스템은 검색 모델을 기반으로 입력과 가장 유사하다고 판단되는 질의응답 후보를 사용자에게 보여준다. 하지만 검색 모델은 문서 색인에 의존하기 때문에 입력 문장의 맞춤법 오류에 취약하다. 따라서 본 논문에서는 FAQ 시스템을 문장분류기에 적용하여 맞춤법 오류를 최소화하는 모델을 제안한다. 자모 단위 합성곱 신경망을 이용한 임베딩 계층을 통해 사용자 입력의 맞춤법 오류를 줄이고, 클래스 임베딩과 전방 전달 신경망을 적용하여 분류기의 성능을 높였다. 제안 모델은 457개와 769개의 FAQ 클래스 분류에 대한 실험 결과로 Micro F1 score 기준 각각 81.32%p, 61.11%p의 높은 성능을 보였으며, 모델 예측의 신뢰도를 평가하기 위해 sigmoid 함수를 이용하여 신뢰도를 수치화했다.","Web and mobile users obtain the desired information using the frequently asked questions (FAQ) listed on the homepage. The FAQ system displays a query response candidate that is most similar to the input based on an information retrieval model. However, the information retrieval model depends on the index, and therefore, it is vulnerable to spelling errors in the sentence. This paper proposes a model applying the FAQ system to the sentence classifier, which minimizes the spelling errors. Using the embedded layer with jamo-based convolutional neural network, the spelling errors of the user input were reduced. The performance of the classifier was improved using class embedding and feed-forward neural network. As a result of 457 and 769 FAQ classifications, the Micro F1 score showed 81.32% p and 61.11% p performance, respectively. We used the sigmoid function to quantify the reliability of the model prediction."
랜섬웨어 방어를 위한 합성곱 신경망 기반의 데이터 암호화 탐지 기법,2019,"['ransomware', 'deep learning', 'convolutional neural network', 'computer security', '랜섬웨어', '딥러닝', '합성곱 신경망', '컴퓨터 보안']","최근 랜섬웨어에 의한 피해가 심각해짐에 따라, 랜섬웨어 공격을 실시간으로 감지하고 방어하는 기술 개발의 중요성이 높아지고 있다. 기존 랜섬웨어 탐지 기법의 한계를 극복하기 위해, 저장장치 내부 수준의 데이터 보존 및 복구 기법이 제안되었으나, 무분별한 데이터 보존으로 인해 저장공간 부하를 크게 증가시킬 수 있다는 한계점이 존재한다. 본 논문에서는 보존할 데이터를 정확하게 선정하면서도 피해 데이터를 온전하게 보존하기 위한, 합성곱 신경망 기반의 데이터 암호화 여부 판단 기법을 제시한다. 실험 결과, 제안한 기법은 저장장치 내부 수준에서 상위 계층의 정보 없이 93.90%의 높은 정확도로 데이터의 암호화 여부를 판단하였다. 또한, 손실 함수와 결정 경곗값을 수정하여 0에 가까운 부정 오류율을 달성하였다.","With the rapid increase in the number of ransomwares recently, the development of real-time strategies for ransomware defense is imperative. To overcome the limitations of traditional ransomware defense techniques, a storage-level data recovery technique was suggested. However, as the technique inefficiently selects data to conserve, it has a negative impact on the lifetime and performance of storage. In this paper, we propose a CNN-based encrypted data detection technique to enhance the accuracy of selecting data to conserve while ensuring complete data recovery. Our experiments show that the proposed technique achieved 93.90% detection accuracy at the storage-level without any high-level information. Furthermore, by changing the loss function and controlling a detection threshold, we attained a false negative rate of nearly 0."
자연어를 활용한 SQL문 생성을 위한 합성곱 신경망 기반 칼럼 예측 모델,2019,"['SQL', 'RDBMS', 'natural language processing', 'convolutional neural networks', 'SQL', '관계형 데이터베이스', '자연어 처리', '합성곱 신경망']","관계형 데이터베이스 시스템을 이용하여 대규모의 데이터를 검색하기 위해서는 테이블 스키마 및 SQL문을 이해해야 하는 필요성이 있다. 이를 해결하기 위해 자연어가 입력으로 주어질 때, 이에 대응하는 SQL문을 생성하는 연구가 최근 진행되고 있다. 기존 연구에서 가장 어려운 부분은 SQL문의 조건에 해당되는 칼럼을 효과적으로 예측하는 부분이며, 예측해야 하는 칼럼의 개수가 여러 개일 때 정확도가 크게 떨어지는 문제점이 있다. 본 논문에서는 칼럼 어텐션 메카니즘을 이용하여, 자연어 데이터의 숨겨진 표현을 효과적으로 추출하는 합성곱 신경망 모델을 제안한다. 본 연구의 제안 방법은 기존 방법 대비 약 6% 이상 정확도가 향상되는 것을 확인할 수 있었다.","To retrieve massive data using relational database management system (RDBMS), it is important to understanding of table schemas and SQL grammar. To address this issue, many studies have recently been carried out to generate an SQL query from a natural language question. However, the existing works suffer mostly from predicting columns at where clause and the accuracy is greatly reduced when there are multiple columns to be predicted. In this paper, we propose a convolutional neural network model with column attention mechanism that effectively extracts the latent representation of input question which helps column prediction of the model. The experiment shows that our model outperforms the accuracy of the existing model (SQLNet) by 6%."
빗줄기 방향과 강도를 고려한 심층 합성곱 신경망 기반의 빗줄기 제거 기법,2019,"['rain removal', 'residual networks', 'deep convolutional neural networks', 'sparse coding']","최근 인공지능 기술의 발달로 무인자동차, 무인드론 및 자율운항선박시스템 등이 개발되고 있다. 그러나 컴퓨터 비전 기반의 보행자 검출, 영상분할 같은 기법은 기상 환경에 상당한 영향을 받는다. 특히 비가 내리는 상황에서 영상을 획득할 때 캡처된 영상에서 빗줄기 패턴이 형성되고 이러한 빗줄기 패턴은 컴퓨터 비전 알고리즘에서 사용되는 특징 추출에 부정적인 영향을 줄 수 있다. 따라서 본 논문에서는 빗줄기의 강도와 방향을 고려한 심층 합성곱 신경망 기법을 제안하고자 한다. 특히 빗줄기 강도와 방향을 구별 짓기 위한 심층 합성곱 신경망과 빗줄기 타입 별 빗줄기 제거를 위한 잔차 네크워크 즉, 두 종류의 서브 네트워크를 학습해서 빗줄기를 제거하고자 한다. 제안한 기법을 적용할 때, 기존의 방법보다 빗줄기 제거와 디테일 보존 성능 측면에서 더 나은 결과를 얻을 수 있었으며 정량적 화질 평가에서도 우위를 달성할 수 있었다.","Recently, autonomous cars, autonomous drones, and self-driving ship systems are being developed, thanks to the development of artificial intelligence technologies However, computer vision algorithms such as pedestrian detections and image segmentations, are significantly affected by weather conditions. When capturing images in a rainy day, rain streaks are formed in the captured images, thereby having negative effects on feature extractors used in computer vision algorithms. Therefore, this paper proposes the deep convolution neural networks that consider the strength and orientation of rain streaks. More specifically, in this paper, two types of sub-networks are learned for rain streaks removal. One is to detect the strength and orientation of rain streaks and the other is to remove rain streaks via residual networks, which are trained optimally to each type of rain streaks. Experimental results show that the proposed method is more effective in removing rain streaks and preserving details than the conventional methods. Moreover, quantitative image quality assessments also show that the performance of the proposed method is superior to the conventional methods."
작물 분류를 위한 다중 규모 공간특징의 가중 결합 기반 합성곱 신경망 모델,2019,"['Crop classification', 'Convolutional neural network', 'Spatial feature', 'Image patch']","이 논문에서는 작물 분류를 목적으로 합성곱 신경망 구조에 다중 규모의 입력 영상으로부터 추출가능한 다양한 공간특징을 가중 결합하는 모델을 제안하였다. 제안 모델은 합성곱 계층에서 서로 다른 크기의 입력패치를 이용하여 공간특징을 추출한 후, squeeze-and-excitation block을 통해 추출한 공간특징의 중요도에 따라가중치를 부여한다. 제안 모델의 장점은 분류에 유용한 특징들을 추출하고 특징의 상대적 중요도를 분류에 이용하는데 있다. 제안 모델의 분류 성능을 평가하기 위해 미국 일리노이 주에서 수집한 다중시기 Landsat-8 OLI 영상을 이용한 작물 분류 사례연구를 수행하였다. 유용한 패치 크기 결정을 위해 먼저 단일 패치 모델에서 패치 크기가 작물 분류에 미치는 영향을 분석하였다. 그 후에 단일 패치 모델과 특징의 중요도를 고려하지 않는다중 패치 모델과 분류 성능을 비교하였다. 비교 실험 결과, 제안 모델은 연구지역에서 재배하는 작물의 공간특징을 고려함으로써 오분류 양상을 완화시켜 비교 모델들에 비해 가장 우수한 분류 정확도를 나타냈다. 분류에 유용한 공간특징의 상대적 중요도를 고려하는 제안 모델은 작물뿐만 아니라 서로 다른 공간특성을 보이는객체 분류에도 유용하게 적용될 수 있을 것으로 기대된다.","This paper proposes an advanced crop classification model that combines a procedure for weighted combination of spatial features extracted from multi-scale input images with a conventional convolutional neural network (CNN) structure. The proposed model first extracts spatial features from patches with different sizes in convolution layers, and then assigns different weights to the extracted spatial features by considering feature-specific importance using squeeze-and-excitation block sets. The novelty of the model lies in its ability to extract spatial features useful for classification and account for their relative importance. A case study of crop classification with multi-temporal Landsat-8 OLI images in Illinois, USA was carried out to evaluate the classification performance of the proposed model. The impact of patch sizes on crop classification was first assessed in a single-patch model to find useful patch sizes. The classification performance of the proposed model was then compared with those of conventional two CNN models including the single-patch model and a multi-patch model without considering feature-specific weights. From the results of comparison experiments, the proposed model could alleviate misclassification patterns by considering the spatial characteristics of different crops in the study area, achieving the best classification accuracy compared to the other models. Based on the case study results, the proposed model, which can account for the relative importance of spatial features, would be effectively applied to classification of objects with different spatial characteristics, as well as crops."
합성곱 신경망을 이용한 Bender Gestalt Test 영상인식,2019,"['Bender Gestalt Test', 'Eye-writing', 'Pattern Recognition', 'Character Recognition', 'Dynamic Time Warping']",,"This paper proposes a method of utilizing convolutional neural network to classify the images of Bender Gestalt Test (BGT), which is a tool to understand and analyze a person’s characteristic. The proposed network is composed of 29 layers including 18 convolutional layers and 2 fully connected layers, where the network is to be trained with augmented images. To verify the proposed method, 10 fold validation was adopted. In results, the proposed method classified the images into 9 classes with the mean f1 score of 97.05%, which is 13.71%p higher than a previous method. The analysis of the results shows the classification accuracy of the proposed method is stable over all the patterns as the worst f1 score among all the patterns was 92.11%."
합성곱 신경망 기반 밝기-색상 정보를 이용한 얼굴 위변조 검출 방법,2019,"['face anti-spoofing', 'luminance and chrominance', 'convolutional neural networks', 'attention module', 'contrast loss']",,"In this paper, we propose the face anti-spoofing method based on combination of luminance and chrominance with convolutional neural networks. The proposed method extracts luminance and chrominance features independently from live and fake faces by using stacked convolutional neural networks and auxiliary networks. Unlike previous methods, an attention module has been adopted to adaptively combine extracted features instead of simply concatenating them. In addition, we propose a new loss function, called the contrast loss, to learn the classifier more efficiently. Specifically, the contrast loss improves the discriminative power of the features by maximizing the distance of the inter-class features while minimizing that of the intra-class features. Experimental results demonstrate that our method achieves the significant improvement for face anti-spoofing compared to existing methods."
심층 합성곱 신경망에 기반한 이미지 바코드의 은닉 데이터 디코딩 기법,2019,"['halftoning', 'image barcode', 'sparse coding', 'image moment', 'deep convolutional neural networks']",,"This paper proposes a method of decoding the hidden data from image barcodes. First, halftoned images are generated by applying two types of dithering matrixes to training images, and then labels are assigned to the extracted patches from the halftoned images. Next, the deep convolutional neural network that has similar architecture of the VGG-16 is learned via a stochastic gradient descent algorithm. Given the input image barcode, the proposed hidden data decoding can be completed by feeding the extracted patches from the image barcode into the already learned deep convolutional neural network, which enables the extracted patches to be classified by one of the two labels. Through the experiments, it is shown that the proposed method can achieve better results than the conventional methods. Especially, the correct recognition rates of 99% and 96% can be obtained for the digital and scanned image barcodes, respectively."
CFAR와 합성곱 신경망을 이용한 기두부와 단 분리 시 조각 구분,2019,"['micro motion', 'micro-Doppler spectrogram', 'CA-CFAR', 'convolutional neural networks', 'warhead', 'debris']",,"Warhead and debris show the different micro-Doppler frequency shape in the spectrogram because of the different micro motion. So we can classify them using the micro-Doppler features. In this paper, we classified warhead and debris in the separation phase using CNN(Convolutional Neural Networks). For the input image of CNN, we used micro-Doppler spectrogram. In addition, to improve classification performance of warhead and debris, we applied the preprocessing using CA-CFAR to the micro-Doppler spectrogram. As a result, when the preprocessing of micro-Doppler spectrogram was used, classification performance is improved in all signal-to-noise ratio(SNR)."
다양한 합성곱 신경망 방식을 이용한 폐음 분류 방식의 성능 비교,2019,[],,"In the diagnosis of pulmonary diseases, auscultation technique is simpler than the other methods, and lung sounds can be used for predicting the types of pulmonary diseases as well as identifying patients with pulmonary diseases. Therefore, in this paper, we identify patients with pulmonary diseases and classify lung sounds according to their sound characteristics using various convolutional neural networks, and compare the classification performance of each neural network method. First, lung sounds over affected areas of the chest with pulmonary diseases are collected by using a single-channel lung sound recording device, and spectral features are extracted from the collected sounds in time domain and applied to each neural network. As classification methods, we use general, parallel, and residual convolutional neural network, and compare lung sound classification performance of each neural network through experiments."
UWB 시스템에서 합성곱 신경망을 이용한 거리 추정,2019,[],,"The paper proposes a distance estimation technique for ultra-wideband (UWB) systems using convolutional neural network (CNN). To estimate the distance from the transmitter and the receiver in the proposed method, 1 dimensional vector consisted of the magnitudes of the received samples is reshaped into a 2 dimensional matrix, and by using this matrix, the distance is estimated through the CNN regressor. The received signal for CNN training is generated by the UWB channel model in the IEEE 802.15.4a, and the CNN model is trained. Next, the received signal for CNN test is generated by filed experiments in indoor environments, and the distance estimation performance is verified. The proposed technique is also compared with the existing threshold based method. According to the results, the proposed CNN based technique is superior to the conventional method and specifically, the proposed method shows 0.6 m root mean square error (RMSE) at distance 10 m while the conventional technique shows much worse 1.6 m RMSE."
외래잡초 분류 : 합성곱 신경망 기반 계층적 구조,2019,"['exotic weeds', 'weed classification', 'hierarchical architecture', 'convolutional neural networks']",,"Weeds are a major object which is very harmful to crops. To remove the weeds effectively, we have to classify them accurately and use herbicides. As computing technology has developed, image-based machine learning methods have been studied in this field, specially convolutional neural network(CNN) based models have shown good performance in public image dataset. However, CNN with numerous training parameters and high computational amount. Thus, it works under high hardware condition of expensive GPUs in real application. To solve these problems, in this paper, a hierarchical architecture based deep-learning model is proposed. The experimental results show that the proposed model successfully classify 21 species of the exotic weeds. That is, the model achieve 97.2612% accuracy with a small number of parameters. Our proposed model with a few parameters is expected to be applicable to actual application of network based classification services."
다중 스케일 시간 확장 합성곱 신경망을 이용한 방송 콘텐츠에서의 음성 검출,2019,"['speech detection', 'multi-scale time-dilated convolution', 'deep learning', 'broadcast data']",,"In this paper, we propose a deep learning architecture that can effectively detect speech segmentation in broadcast contents. We also propose a multi-scale time-dilated layer for learning the temporal changes of feature vectors. We implement several comparison models to verify the performance of proposed model and calculated the frame-by-frame F-score, precision, and recall. Both the proposed model and the comparison model are trained with the same training data, and we train the model using 32 hours of Korean broadcast data which is composed of various genres (drama, news, documentary, and so on). Our proposed model shows the best performance with F-score 91.7% in Korean broadcast data. The British and Spanish broadcast data also show the highest performance with F-score 87.9% and 92.6%. As a result, our proposed model can contribute to the improvement of performance of speech detection by learning the temporal changes of the feature vectors."
말벌 영상인식을 위한 심층 합성곱 신경망의 성능 평가,2019,"['Vespa hornets', 'Deep convolutional neural network', 'Deep learning', 'Classification']",,"One of the serious factors for honeybee decline is due to the various attacks from Vespa hornets, indigenous and invaded. Population monitoring as well as the alerting systems is requested against the Vespa. Automated image recognition is the primary step for the unmanned autonomous monitoring system development. This study compared the recent deep convolutional neural network (DCNN) algorithms such as AlexNet, VGG19, GoogLeNet, and ResNet50 for the best model selection for classification of 3 Vespa species, V. mandarinia, V. crabro and V. velutina. To evaluate classification performance, accuracy was utilized after transfer learning on each DCNN. As a result, the ResNet50 showed the best in terms of accuracy after sufficient training of 100 epochs. If performance and speed are considered simultaneously, AlexNet could be the alternative. The real-time monitoring system for objects requires both localization and classification. And Vespa occurrence or population change would need rapid recognition for the objects. Therefore speedy image recognition based on the DCNN, which combines localization and classification for objects in an image, should be considered in the future works."
무인수상선의 도킹을 위한 합성곱 신경망 기반 상대위치추정 기법,2019,"['unmanned surface vehicle', 'autonomous surface vehicle', 'docking system', 'deep learning', 'convolutional neural network']",,"This paper describes a convolutional neural network based localization method for docking of an unmanned surface vehicle. Based on the docking experiment of the USV model ship in an indoor, a basin and inland water, docking data which includes relative pose information and corresponding mono-camera perspective images are collected. Using the collected docking data, a VGG-19 based convolutional neural network model for relative pose estimation was trained. Constructed pose estimator can predict USV pose during the docking, within 0.23 m and 0.45 m and 2.73 degree of longitudinal, lateral and yaw angular RMS errors respectively. According to the validation result, we founded the possibility that the proposed method can substitute the GNSS based navigation when there exists a high level of bypass error due to the approaches of large scale structure or vessel, which USV often encounters during the docking."
스마트 팜을 위한 분할 인식 심층 합성곱 신경망 기반의 사과나무 잎사귀 질병 인식,2019,"['smart farm', 'plant disease', 'deep convolutional neural networks', 'deep feature extraction', 'feature pooling']",,"A new method of recognizing apple leaf diseases via segmentation-aware deep convolutional neural network is proposed in this paper. The main idea is that leaf diseases exist in the leaf area. To realize this idea, two subnetworks are designed. One is for the division of input image into background, leaf area, and disease area, and the other is for the prediction of leaf disease types. The two subnetworks have architecture types of the encoder-decoder network and the VGG network, respectively, and then trained separately via transfer learning. Next, the two types of subnetworks are combined through a concatenation layer. In other words, to train the entire network in an end-to-end manner, the predicted image segmentation map is stacked on the top of the input image through the concatenation layer, and then fed into the image classification subnetwork. The experimental results show that correct recognition accuracy can be increased by 9% by using the predicted image segmentation map, compared to the VGG network."
합성 곱 신경망 기반 웹 응용 트래픽 분류 모델 설계,2019,"['트래픽 분류', '머신러닝', '합성 곱 신경망', '응용 트래픽', 'Traffic Classification', 'Machine Learning', 'Convolution Neural Network', 'Application Traffic']",,
잔류 합성 곱 신경망 기반의 코골이 식별 방식,2019,[],,"Snoring is a typical symptom of sleep disorder and it is important to identify the occurrence of snoring because it causes sleep apnea. In this paper, we proposes a residual convolutional neural network as an efficient snoring identification algorithm. Residual convolutional neural network, which is a structure combining residual learning and convolutional neural network, effectively extracts features existing in data more than conventional neural network and improves the accuracy of snoring identification. Experimental results show that the performance of the proposed snoring algorithm is superior to that of the conventional methods."
정교한 이웃 노드 선택법을 활용한 그래프 합성곱 네트워크,2019,"['노드 분류', '그래프 합성곱 네트워크', '그래프 신경망', '그래프 마이닝', 'node classification', 'graph convolutional network', 'graph neural network', 'graph mining']","그래프 합성곱 네트워크(GCNs)는 합성곱 구조를 활용하여 주변 노드들의 정보를 종합하는 방식으로 대상 노드의 표현력을 높인다. 높은 성능을 보이기 위해서는 우선적으로 대상 노드에게 필요한 정보를 전달할 수 있는 주변 노드를 선별하고, 이후 학습시 적절한 필터(filter) 값을 습득하는 과정이 수반되어야한다. 최근 GCNs 알고리즘들은 1-hop 거리의 노드들을 선택하는 등의 비교적 간단한 이웃 노드 정의를 활용하고 있다. 이러한 경우 불필요한 정보가 대상 노드에 전파되어 성능을 저하하는 문제가 발생한다. 본 논문에서는 대상 노드와 주변 노드간의 유사도 계산을 통해 유효한 이웃 노드를 선별하여 활용하는 GCN 알고리즘을 제안한다.","Graph Convolutional Networks (GCNs) utilize the convolutional structure to obtain an effective insight on representation by aggregating the information from neighborhoods. In order to demonstrate high performance, it is necessary to select neighborhoods that can propagate important information to target nodes, and acquire appropriate filter values during training. Recent GCNs algorithms adopt simple neighborhood selection methods, such as taking all 1-hop nodes. In the present case, unnecessary information was propagated to the target node, resulting in degradation of the performance of the model. In this paper, we propose a GCN algorithm that utilizes valid neighborhoods by calculating the similarity between the target node and neighborhoods."
인공 신경망과 웨이블릿 변환을 이용한 주가 지수 예측,2019,"['웨이블릿 변환', '주가 지수 예측', '인공 신경망', '시계열 분석', 'wavelet transform', 'forecasting stock market price', 'artificial neural network', 'time series analysis']","기계학습 기술과 인공신경망 기술의 발전과 함께 주식시장의 흐름을 예측하려는 연구가 다양하게 시도되어 왔다. 특히 영상, 음성 처리를 위한 인공신경망 기술들이 주식시장 예측에 도입되어 예측의 정확도를 향상시키고 있다. 본 논문에서는 KOSPI의 지수변화와 방향성을 예측하기 위해 추출한 기술적 지표를 웨이블릿 변환을 이용하여 고주파수부분과 저주파수부분으로 나누어 인공신경망에서 각각 독립적으로 학습하고 예측한 다음, 고주파수부분과 저주파수부분을 합하여 지수와 방향성을 최종 예측하였다. 인공신경망으로 합성곱신경망, Dual Path Network 그리고 LSTM을 사용하여 인공신경망 간의 성능비교와 웨이블릿 변환의 효용성을 분석하였다. 지수예측에서는 합성곱신경망이 MAPE 0.51%, 등락예측에서는 LSTM이 정확도 81.7%로 최적의 결과를 보였고, 웨이블릿 변환으로 향상된 성능은 지수 예측의 경우 평균 38%, 등락 예측의 경우 평균 25%를 얻어 웨이블릿 변환의 효용성을 확인하였다.","With advancements in technologies on machine learning and artificial neural network, various researches have attempted to predict the changes in the price of the stock market. The prediction accuracy has improved with adoption of new artificial neural network technologies that have been developed for image and voice signal processing. In the present work, the technical indices from KOSPI were decomposed for the prediction of index and movement direction of KOSPI into high-frequency part and low-frequency part using wavelet transform, then used to predict KOSPI independently by using artificial neural networks. For the final prediction, the prediction result of each frequency part was added. CNN, DPN, and LSTM were employed as artificial neural network; the performance of each model was compared and the efficiency of the wavelet transform of input variables was analyzed. CNN with 0.51% of MAPE for the index prediction and LSTM with 81.7% of accuracy for movement prediction showed the best performance among the three models. The efficiency of wavelet transform was confirmed with averaged 38% of the improved performance for the index prediction and averaged 25% of the improved performance for the movement prediction."
음성 분류 인공신경망을 활용한 자폐아 치료용 로봇의 지능화 동작 연구,2019,"['Autism Spectrum Disorders', 'Autistic Children Training', 'MFCC', 'Convolutional Neural Network', 'Speech Data Classification']",현재 아이들의 자폐스펙트럼장애 유병률이 한층 더 높게 보고되고 있으며 다양한 형태의 장애 징후를 보이고 있다. 특히 이들은 사회적 의사소통 영역에서 의사소통장애로 인한 대화에 어려움을 겪고 있으며 이를 훈련을 통해 개선 시킬 필요가 대두된다. 이를 위해 본 연구에서는 사전 연구를 통해 설계된 로봇에 장착된 마이크를 통해 음성 정보를 취득하고 이러한 정보를 이용하여 지능적인 동작을 만드는 방식을 제안한다. 음성 정보를 로봇 동작으로 분류하기 위해 인공신경망을 이용하였으며 여러 신경망 기법중 합성곱 방식을 기본으로 한 순환신경망을 결합하여 정확도를 향상시키려고 하였다. 입력 음성 데이터의 전 처리는 MFCC를 이용하여 분석하였으며 여러 데이터 정규화 및 인공신경망 최적화 기법을 활용하여 로봇의 동작을 추정하였다. 아울러 설계된 인공신경망은 기존에 사용한 구조 및 사람이 개입하여 분석하는 방법과의 정확도 비교 실험을 진행하여 분석 결과가 높은 정확도를 나타냈다. 향후 보다 높은 정확도를 가질 수 있는 로봇 동작을 설계하여 실제의 자폐아 치료 및 교육환경에서 적용할 수 있기 위하여 다양한 형태의 데이터를 수집하고 효율적으로 전처리하는 방식에 대한 연구가 요구된다.,"Currently, the prevalence of autism spectrum disorders in children is reported to be higher and shows various types of disorders. In particular, they are having difficulty in communication due to communication impairment in the area of social communication and need to be improved through training. Thus, this study proposes a method of acquiring voice information through a microphone mounted on a robot designed through preliminary research and using this information to make intelligent motions. An ANN(Artificial Neural Network) was used to classify the speech data into robot motions, and we tried to improve the accuracy by combining the Recurrent Neural Network based on Convolutional Neural Network. The preprocessing of input speech data was analyzed using MFCC(Mel-Frequency Cepstral Coefficient), and the motion of the robot was estimated using various data normalization and neural network optimization techniques. In addition, the designed ANN showed a high accuracy by conducting an experiment comparing the accuracy with the existing architecture and the method of human intervention. In order to design robot motions with higher accuracy in the future and to apply them in the treatment and education environment of children with autism."
트리 기반 컨볼루션 신경망을 이용한 BigCloneBench 개선,2019,"['코드 클론', '클론 검사', '기계 학습', '벤치마크', '합성곱 신경망', 'code clone', 'clone checking', 'machine learning', 'benchmark', 'Convolutional Neural Network']",,"BigCloneBench has recently been used for performance evaluation of code clone detection tool using machine learning. However, since BigCloneBench is not a benchmark that is optimized for machine learning, incorrect learning data can be created. In this paper, we have shown through experiments using machine learning that the set of Type-4 clone methods provided by BigCloneBench can additionally be found. Experimental results using Tree-Based Convolutional Neural Network show that our proposed method is effective in improving BigCloneBench’s dataset."
열화상 영상 잡음 제거를 위한 효율적인 잡음 제거 블록 기반의 신경망,2019,"['image denoising', 'convolutional neural networks', 'thermal image', 'laplace noise', 'receptive field', 'residual leraning']","열화상 카메라는 제한된 열화상 해상도로 인해 잡음이 있는 영상을 야기한다. 본 논문에서는 잡음 문제를 해결하기 위해 반복 가능한 인셉션-레지듀얼 블록(IRB)으로 이루어진 새로운 딥러닝 기반의 신경망을 제안한다. 각각의 IRB는 원본 이미지에 대하여 서로 다른 수용 영역을 가진 합성곱 층 2개를 가지고 베니싱 그레디언트(vanishing gradient)를 방지하기 위한 하나의 쇼트 컷(shortcut connection)으로 구성된다. 제안된 방법은 12개의 열화상 이미지로 테스트가 이루어졌다. 실험 결과, 제안된 방법은 최신의 잡음 제거 방법인 DnCNN과 비교해 봤을 때 신호대잡음비(PSNR)를 39.57에서 40.26으로 처리속도는 1.5910초에서 0.7508초로 잡음 제거 성능 및 처리 속도 개선을 보여준다.","Thermal cameras show noisy images due to their limited thermal resolution, especially for the scenes of a low-temperature difference. In order to deal with a noise problem, this paper proposes a novel neural network architecture with repeatable denoising inception-residual blocks(DnIRB) for noise learning. Each DnIRB has two sub-blocks with difference receptive fields and one shortcut connection to prevent a vanishing gradient problem. The proposed approach is tested for 12 thermal images. The experimental results indicate that the proposed approach shows the PSNR performance is increased 39.57 to 40.26 and processing time also is reduced 1.5910 to 0.7508 compared with state-of-the-art denoising methods which is called DnCNN."
Fast R-CNN을 이용한 객체 인식 기반의 도로 노면 파손 탐지 기법,2019,"['도로 노면 파손', '심층 신경망', '유지보수', '영역 기반 합성곱', '객체 인식', 'Road surface damage', 'Deep neural network', 'Road maintenance', 'Region based convolutional neural networks', 'Object recognition']",,
수도 레이블을 활용한 준지도 학습 기반의 도로노면 파손 탐지,2019,"['Road surface damage', 'Semantic segmentation', 'Convolutional neural network', 'Semi-supervised learning', '도로노면 파손', '의미론적 분할', '합성곱 신경망', '준지도 학습']","의미론적 분할 형태로 합성곱 신경망을 구성하여 도로노면의 파손을 탐지하는 연구가 진행되고 있다. 이러한 합성곱 신경망 형태의 모델을 생성하기 위해서는 입력 이미지와 이에 상응한 레이블된 이미지 데이터셋으로 수집해야 하고, 이러한 과정에서는 굉장히 많은 시간과 비용이 발생하게 된다. 본 논문에서는 이러한 작업을 완화하기 위하여 수도 레이블링을 활용한준지도 학습 기반의 도로노면 파손 탐지 기술을 제안하고자 한다. 레이블된 데이터셋과 레이블되지 않은 데이터셋을 적절하게 혼합하여 도로노면 파손을 탐지하는 모델을 업데이트하고, 이를 레이블된 데이터셋만을 활용한 기존 모델과 성능을 비교한다. 주관적인 성능결과, 민감도부분에서는 조금 저하된 성능을 보였지만, 정밀도 부분에서는 대폭 성능 향상이 있었으며, 최종적으로 F1-score 또한 높은 수치로 평가되었다.","By using convolutional neural networks (CNNs) based on semantic segmentation, road surface damage detection has being studied. In order to generate the CNN model, it is essential to collect the input and the corresponding labeled images. Unfortunately, such collecting pairs of the dataset requires a great deal of time and costs. In this paper, we proposed a road surface damage detection technique based on semi-supervised learning using pseudo labels to mitigate such problem. The model is updated by properly mixing labeled and unlabeled datasets, and compares the performance against existing model using only labeled dataset. As a subjective result, it was confirmed that the recall was slightly degraded, but the precision was considerably improved. In addition, the F1-score was also evaluated as a high value."
GPR 히트맵 이미지 데이터 기반 CNN을 이용한 철근 두께 예측에 관한 연구,2019,"['GPR', 'B-scan', '히트맵', '합성곱 신경망', '철근', '두께', 'Ground Penetrating Radar', 'B-scan', 'heatmap', 'Convolution Neural Network', 'Rebar Thickness']","본 논문에서는 시설물 내부 철근 두께를 예측하기 위해 GPR 데이터를 활용한 철근 두께 예측 기법에 관한 연구를 실시하였다. 국내의 규격 미달 철근의 사용 및 배근 시공과 같은 부실시공 사례에서 볼 수 있듯이, 구조물 정밀진단을 위해서 철근 두께에 대한 정보는 정밀 안전진단을 위해서 꼭 필요함을 알 수 있다. 이를 위해 본 연구에서는 시편을 제작하여 철근 직경을 단계적으로 증가시켜 GPR의 B-scan 데이터를 취득하였다. GPR 의 B-scan 데이터는 가시성이 떨어지기 때문에 이를 migration을 통해 히트맵 이미지 데이터로 변화시켜 데이터의 직관성을 높이고자 하였다. 본 연구는 보편적으로 이용되는 B-scan 데이터와 히트맵 데이터의 합성곱 신경망(CNN) 적용 시 결과를 비교하기 위해 B-scan 및 히트맵 데이터에서 각각 철근에 대한 영역을 추출하여 학습 및 검증 데이터를 구축하였으며, 구축된 데이터에 CNN을 적용하였다. 그 결과, 히트맵 데이터의 경우 B-scan 데이터와 비교하였을 때 더 좋은 결괏값을 얻을 수 있었다. 이를 통해 GPR 히트맵 데이터를 이용하였을 경우 B-scan 데이터를 이용하였을 때보다 더 높은 정확도로 철근 두께를 예측할 수 있음을 확인하였으며, 시설물 내부 철근 두께 예측의 가능성을 검증하였다.","In this paper, a study was conducted on the method of using GPR data to predict rebar thickness inside a facility. As shown in the cases of poor construction, such as the use of rebars below the domestic standard and the construction of reinforcement, information on rebar thickness can be found to be essential for precision safety diagnosis of structures. For this purpose, the B-scan data of GPR was obtained by gradually increasing the diameter of rebars by making specimen. Because the B-scan data of GPR is less visible, the data was converted into the heatmap image data through migration to increase the intuition of the data. In order to compare the results of application of commonly used B-scan data and heatmap data to CNN, this study extracted areas for rebars from B-scan and heatmap data respectively to build training and validation data, and applied CNN to the deployed data. As a result, better results were obtained for the heatmap data when compared with the B-scan data. This confirms that if GPR heatmap data are used, rebar thickness can be predicted with higher accuracy than when B-scan data is used, and the possibility of predicting rebar thickness inside a facility is verified."
지능형 관광 서비스를 위한 관광 사진 분류체계 개발,2019,"['플리커', 'SNS', '관광목적 사진 분류체계', '딥러닝', '합성곱신경망', '한국 관광', 'Flickr', 'Social Network Service', 'Photo Classification for Tourist purpose', 'Deep Learning', 'Convolutional Neural Network', 'Korea Tour']","최근 딥러닝 기술 가운데 이미지데이타 분석에 뛰어난 성능을 보이는 합성곱신경망 기술의 발전은 이미지 분석 영역에서다양한 가능성을 제시하고 있다. 관광객이 게시한 사진을 딥러닝 기술을 이용하여 분류하기 위해서는 관광사진에 대한 분류와목적에 맞는 딥러닝 모델의 훈련작업이 필수적으로 선행되어야 한다. 본 연구에서는 관광객이 플리커에 게시한 사진을 효율적으로분류하기 위해 관광목적으로 사진이 어떻게 분류되어야 하는지 관광목적 사진분류 체계를 개발하고자 하였다. 관광목적 사진분류 카테고리 개발을 위해 문헌분석, 웹사이트 분석, 관광객이 게시한 약 38,000장 사진의 검토과정을 거쳐 사진 분류 카테고리를개발하였으며, 약 8400장의 사진을 개발된 카테고리에 맞춰 분류해 봄으로써 개발된 카테고리의 검증과정을 거쳤다. 이 과정을거쳐 최종으로 제안된 카테고리는 13개 대분류, 64개 중분류, 164개의 세분류 체계를 갖으며, 본 연구 결과는 향후 관광목적사진을 딥러닝 모델을 이용하여 분류하고자 할 때 기초자료로 활용될 것으로 기대된다.","In recent years technology of Convolutional Neural Network (CNN) among the technologies of deep learning has evolved dramatically and has shown an outstanding performance in the analysis of image data. First of all, the training of deep learning model is prerequisite to classify the photos posted by the tourists on Web by applying CNN technology. In this study we aim to develop the photo classification system in view of travel purpose in order to classify the photos posted by tourists on Flickr. We developed the category for photo classification by reviewing around 38,000 photos posted by tourists as well as by analysing literatures and web sites, and then verified the category by classifying 8,400 photos one by one manually according to the category developed. The category we developed has 3 hierarchical levels such as 13 major classification, 64 medium classification and 164 minor classification. We expect that our study can applied in base material when one tries to classify the photos for travel purpose by using the CNN deep learning model."
Word2Vec과 2계층 양방향 장단기 기억 네트워크를 이용한 특허 문서의 자동 IPC 분류,2019,"['텍스트 마이닝', '문서 분류', '순환 신경망', 'text mining', 'document classification', 'recurrent neural network']","자연어 처리를 이용한 문서 분류 분야에서도 전통적인 방법에서 벗어나 단어 임베딩을 활용한 합성곱 신경망과 순환 신경망 등 심층 신경망을 이용한 다양한 연구가 진행되고 있다. 본 논문에서는 Word2Vec과 두 개의 계층으로 구성된 양방향 장단기 기억 네트워크를 이용한 특허 문서의 IPC(International Patents Classification) 자동 분류 모델을 제안한다. IPC는 세계지식재산권기구에서 제정한 국제적으로 통일된 특허 분류 기준이며, 각 국가의 공인된 기관에서 수작업으로 분류하고 있다. IPC 자동 분류를 위하여 입력 시퀀스에 Word2Vec을 이용한 단어 임베딩가중치를 사용한다. 그리고 가중치가 부여된 시퀀스를 두 개의 계층을 갖는 깊은 구조의 양방향 장단기 기억 네트워크 신경망에 입력하여 IPC를 분류한다. 실험 결과 특허 문서의 분류 정확도가 합성곱 신경망 보다는 약 7% 향상되었으며, 순환 신경망을 단일로 이용하는 것 보다는 약 5% 향상된 것을 확인할 수 있었다. 또한 전통적인 방법인 나이브 베이시안, 로지스틱 분류 및 서포트 벡터 머신보다는 5~12% 이상 우수한 성능을 나타내었다.","There are various studies using Deep Neural Network such as CNN(Convolutional Neural Network) and RNN(Recurrent Neural Network) that utilize word embedding in document classification using natural language processing out of traditional methods. In this paper, we propose the IPC(International Patents Classification) automatic classification model of patent documents using two layers BLSTM(Bidirectional Long Short Term memory) network. The IPC is an internationally uniform standard for patent classification established by the World Intellectual Property Organization and is categorized by hand in authorized agencies in each country. For the IPC automatic classification, we use word embedding weight with Word2Vec in the input sequences. And they are classified by entering a weighted sequences into a deep neural network with two layers BLSTM. The experimental results showed that the accuracy of classification is improved by about 7% than that of CNN, and about 5% than that of single layer LSTM that is a field of RNN. Also it showed more than 5~12% higher performance than traditional methods such as Naive Bayes, Logistic and Support Vector Machine classification."
정형 데이터와 비정형 데이터를 동시에 고려하는 기계학습 기반의 직업훈련 중도탈락 예측 모형,2019,"['Vocational Training', 'Dropout', 'Machine Learning', 'Convolutional Neural Network', 'Word2vec', '직업훈련 교육', '중도탈락', '기계학습', '합성곱 신경망', 'Word2vec']","직업훈련 교육 현장에서 느끼는 가장 큰 어려움 중 하나는 중도탈락 문제이다. 훈련과정마다 많은 수의 학생들이 중도탈락을 하게 되어 국가 예산 낭비 및 청년 취업률 개선에 장애 요인이 되고 있다. 본 연구에서는 중도탈락의 원인을 주로 분석한 기존 연구들과 달리, 각종 수강생 정보를 활용하여 사전에 중도탈락을 예측할 수 있는 기계학습 기반 모형을 제안하고자 한다. 특히 본 연구의 제안모형은 수강생 관련 정형 데이터 뿐 아니라 비정형 데이터인 강사의 상담일지 정보까지 동시에 고려하여 모형의 예측정확도를 제고하고자 하였다. 이 때 비정형 데이터에 대한 분석은 최근 주목받고 있는 텍스트 분석 기술인 Word2vec과 합성곱 신경망을 이용해 수행하였다. 국내 한 직업훈련기관의 실제 데이터에 제안모형을 적용해 본 결과, 정형 데이터만을 사용하여 중도탈락을 예측할 때보다 비정형 데이터를 함께 고려했을 때 예측의 정확도가 최대 20%까지 향상됨을 확인할 수 있었다. 아울러, Support Vector Machine을 기반으로 정형 데이터와 비정형 데이터를 결합해 분석했을 때, 검증용 데이터셋 기준으로 90% 후반대의 높은 예측 정확도를 나타냄을 확인하였다.","One of the biggest difficulties in the vocational training field is the dropout problem. A large number of students drop out during the training process, which hampers the waste of the state budget and the improvement of the youth employment rate. Previous studies have mainly analyzed the cause of dropouts. The purpose of this study is to propose a machine learning based model that predicts dropout in advance by using various information of learners. In particular, this study aimed to improve the accuracy of the prediction model by taking into consideration not only structured data but also unstructured data. Analysis of unstructured data was performed using Word2vec and Convolutional Neural Network(CNN), which are the most popular text analysis technologies. We could find that application of the proposed model to the actual data of a domestic vocational training institute improved the prediction accuracy by up to 20%. In addition, the support vector machine-based prediction model using both structured and unstructured data showed high prediction accuracy of the latter half of 90%."
K-means 클러스터링 방법과 유사도 측정 기반의 채팅 말뭉치 반자동 확장 방법,2019,"['chatting system', 'semi-automatic expansion', 'similarity', 'convolutional neural networks', 'utterance embedding', '채팅 시스템', '반자동 확장', '유사도', '합성곱 신경망', '발화 단위 표상']","본 논문에서는 영화 자막, 극 대본과 같이 대량의 발화 데이터를 이용하여 채팅 말뭉치를 반자동으로 확장하는 방법을 제안한다. 채팅 말뭉치 확장을 위해 미리 구축된 채팅 말뭉치와 유사도 기법을 이용하여 채팅 유사도를 구하고, 채팅 유사도가 실험을 통해 얻은 임계값보다 크다면 올바른 채팅 쌍이라고 판단하였다. 본 논문에서 제안하는 것은 형태소 단위 임베딩 벡터와 합성곱 신경망 모델을 이용하여 발화 단위 표상을 생성하는 것이다. 그리고 반자동 구축 모델의 속도를 개선하기 위해서 K-means 클러스터링 방법을 적용하여 채팅 말뭉치를 군집, 계산량을 줄일 것을 제안한다. 그 결과 기본 발화 단위 표상 생성 방법인 TF를 이용하는 것보다 정확률, 재현율, F1에서 각각 5,16%p, 6.09%p, 5.73%p 각각 상승하여 61.28%, 53.19%, 56.94%의 성능을 도출하였다. 그리고 속도 개선을 위해 발화를 클러스터링하여 속도 면에서도 103배 향상된 채팅 말뭉치 반자동 구축 모델을 구축할 수 있었다.","In this paper, we proposed a semi-automatic expansion method to expand a chatting corpus using a large amount of utterance data from movie subtitles and drama scripts. To expand the chatting corpus, the proposed system used previously constructed chatting corpus and a similarity measure. If the similarity is calculated between a previously constructed chatting corpus and the input utterance was greater than a threshold value set in the experiment, the input utterance was selected as a new chatting utterance, that it is a correct chatting pair. We used morpheme-unit word embeddings and a Convolutional Neural Networks to efficiently calculate the similarity of the utterance embedding. In order to improve the speed of the semi-automatic expansion process, we proposed to reduce the amount of computation by clustering chat corpus by K-means clustering algorithm. Experimental results showed that the precision, recall, and F1 score of the proposed system were 61.28%, 53.19%, and 56.94%, respectively, which was 5.16%p, 6.09%, and 5.73%p higher than that of the baseline system. The term frequency and the speed of our system were also about a hundred times faster."
심전도 신호의 커플링 이미지를 이용한 개인 인식 방법,2019,"['Personal Recognition', 'Electrocardiogram', 'Coupling Image', 'Convolutional Neural Network', '개인 인식', '심전도', '커플링 이미지', '합성곱 신경망']","심전도 신호는 위조가 불가능하며 양쪽 손목에서 신호를 간편히 취득할 수 있는 장점이 있다. 본 논문에서는 심전도 신호의 방향 정보를 이용해 커플링 이미지를 생성하고, 이를 이용한 개인 인식 방법을 제안한다. 제안하는 커플링 이미지는 정방향 심전도 신호와 R-peak를 기준으로 회전된 역방향 심전도 신호를 이용해 생성하며, 생성한 커플링 이미지는 개인별로 고유한 패턴과 명암을 나타낸다. 또한 같은 주기의 심전도 신호 연산을 통해 R-peak 영역 데이터가 증가하여 개인 인식 성능 향상이 가능하다. 생성한 커플링 이미지는 제안한 합성곱 신경망을 이용해 패턴 및 명암에 대한 특징을 추출하며, 네트워크 속도 향상을 위해 다수의 풀링층을 사용해 데이터 크기를 축소한다. 실험은 47명의 공개된 심전도 데이터를 이용하며, 공개된 네트워크 중 top-5 성능이 상위권인 5개 네트워크와 제안한 네트워크를 이용해 비교 실험을 진행한다. 실험 결과 제안한 네트워크의 개인 인식 성능이 99.28%로 가장 높게 나타남에 따라, 제안한 커플링 이미지를 이용한 개인 인식 방법이 유효함을 확인하였다.","Electrocardiogram (ECG) signals cannot be counterfeited and can easily acquire signals from both wrists. In this paper, we propose a method of generating a coupling image using direction information of ECG signals as well as its usage in a personal recognition method. The proposed coupling image is generated by using forward ECG signal and rotated inverse ECG signal based on R-peak, and the generated coupling image shows a unique pattern and brightness. In addition, R-peak data is increased through the ECG signal calculation of the same beat, and it is thus possible to improve the recognition performance of the individual. The generated coupling image extracts characteristics of pattern and brightness by using the proposed convolutional neural network and reduces data size by using multiple pooling layers to improve network speed. The experiment uses public ECG data of 47 people and conducts comparative experiments using five networks with top 5 performance data among the public and the proposed networks. Experimental results show that the recognition performance of the proposed network is the highest with 99.28%, confirming potential of the personal recognition."
딥러닝기반 다중 표적 인식을 활용한 모바일 로봇 경로 계획,2019,"['표적인식', '경로계획', '장애물 회피', '딥러닝', '모바일 로봇', 'Taget Detection', 'Path Planning', 'Avoidance Obstacle', 'Deep-Learning', 'Mobile Robot']","복합적인 고차원의 임무를 수행하기 위하여 미래무인화 전투 체게는 인공지능 기술을 필요로 한다. 특히 합성곱 신경망은 영상뿐만 아니라 자연어 처리까지 광범위한 범위에서 탁월한 성능을 보이고 있어 무인화 전투체계의 표적정보인식, 피아식별, 전장정보인식 등 각종 센서 융합에 매우 적합하다. 본 연구에서는 합성곱 신경망의 영상인식 기술을 활용하여 다수 대상체의 상태정보를 인식함으로써 변화되는 환경에서의 무인로봇 경로 계획 개선 방안을 제시하였고 시뮬레이션을 통하여 추정된 로봇의 위치, 장애물, 목표물 정보로부터 로봇의 경로 계획의 유효성을 검증 하였다.","Unmmanned systems are one of the essential areas of future military weapons systems that must carry out dangerous and cmplex missions. Especially, deep learning should recognize many landmarks through the image and project them onto the map to improve the problem of position estimation, because it shows excellent performance of recognizing and classifying the characteristics of image data among other artificial intelligence techniques. In this study, the path planning of the unmanned reconnaissance aircraft and the unmanned ground vehicle, which are currently being used in the ROK military, is linked with the CNN based multi target recognition algorithm without GPS. Throuth experiments, we verified the effectiveness of the path planning of the mobile robot with respect to the position of the robot, obstacle, and target point estimated by the target detection algorithm."
CNN 기반 전이학습을 이용한 음성 감정 인식,2019,"['Speech Emotion Recognition', 'Transfer Learning', 'Deep Learning', 'Convolutional Neural Networks', '음성 감정 인식', '전이학습', '딥러닝', '합성곱 신경망']","로봇은 사람의 편의를 위해 존재하므로 사람과 로봇의 상호작용은 중요하다. 로봇이 사람의 감정을 파악하는 것은 여러상호작용 중 하나이다. 최근 사람의 음성으로 감정을 인식하는 음성 감정 인식(speech emotion recognition; SER)분야는딥러닝 (deep learning)의 접목으로 그 성능이 향상되고 있다. 하지만, 데이터의 부족으로 깊은 신경망을 사용하거나추가적인 학습 기법을 적용하지 않고서는 높은 정확도를 기대하기 힘들다. 본 논문에서는 데이터가 부족할 때 사용하는 학습기법 중의 하나인 전이학습 (transfer learning)을 SER에 적용한 효과를 확인한다. 딥러닝을 적용하기 위해 합성곱 신경망(convolutional neural networks; CNN) 구조를 사용한다. 전이학습에 음성 감정 데이터가 아닌 일반 소리 데이터를 사용하여데이터 개수에 대한 한계를 없앤다. 전이학습 중 특징 추출기 (feature extractor)로써 사용한 경우와 미세조정 (fine tuning)을한 경우로 나누어 결과를 확인한다. 그 결과, 미세조정한 경우 수렴 시간이 약 20% 줄었고, 특징 추출기로써 사용한 경우 약20%에서 70% 줄었다. 정확도는 특징 추출기로써 사용한 경우 오히려 정확도가 감소하는 경우가 발생하였고 증가한 경우 약3% 증가했다. 미세조정을 한 경우 정확도가 평균적으로 약 7% 향상되었다","Interaction between human and robot is important because robots exist for the convenience of people. Robot grasping human emotions is one of many interactions. The field of SER (speech emotion recognition) has been improved by combining deep learning. The lack of data makes it difficult to expect high accuracy without using deep neural networks or applying additional learning techniques. In this paper, we confirm the effect of applying the transfer learning, which is one of the learning methods used when there is insufficient data, to SER. For deep learning, CNN (convolutional neural networks) architecture is used. By using general sound data instead of speech emotion data for the transfer learning, the limit on the number of data is eliminated. The results are verified by dividing transfer learning into two case, using as a feature extractor and fine-tuning. As a result, convergence time was reduced by about 20% when fine-tuning, and about 20% to 70% when used as a feature extractor. Accuracy of the feature extractor is rather reduced when it is used as a feature extractor and increased by about 3% when it is increased. On the average, the accuracy was improved by about 7% when fine-tuning."
심층 CNN을 활용한 영상 분위기 분류 및 이를 활용한 동영상 자동 생성,2019,"['Convergence', 'Machine Learning', 'Multi-class Classification', 'Mood Classification', 'Convolutional Neural Network', 'Multilayer Perceptron', '융합', '기계학습', '다중 클래스 분류', '감정 분류', '합성곱 신경망', '다층 퍼셉트론']","본 연구에서는 영상의 분위기를 심층 합성곱 신경망을 통해 8 가지로 분류하고, 이에 맞는 배경 음악을 적용하여 동영상을 자동적으로 생성하였다. 수집된 이미지 데이터를 바탕으로 다층퍼셉트론을 사용하여 분류 모델을 학습한다. 이를 활용하여 다중 클래스 분류를 통해 동영상 생성에 사용할 이미지의 분위기를 예측하며, 미리 분류된 음악을 매칭시켜 동영상을 생성한다. 10겹 교차 검증의 결과, 72.4%의 정확도를 얻을 수 있었고, 실제 영상에 대한 실험에서 64%의 오차 행렬 정확도를 얻을 수 있었다. 오답의 경우, 주변의 비슷한 분위기로 분류하여 동영상에서 나오는 음악과 크게 위화감이 없음을 확인하였다.","In this paper, the mood of images was classified into eight categories through a deep convolutional neural network and video was automatically generated using proper background music. Based on the collected image data, the classification model is learned using a multilayer perceptron (MLP). Using the MLP, a video is generated by using multi-class classification to predict image mood to be used for video generation, and by matching pre-classified music. As a result of 10-fold cross-validation and result of experiments on actual images, each 72.4% of accuracy and 64% of confusion matrix accuracy was achieved. In the case of misclassification, by classifying video into a similar mood, it was confirmed that the music from the video had no great mismatch with images."
역방향 하프토닝을 위한 다중 손실 계층 및 영상 구조 맵 예측기에 기반한 다중 스트림 네트워크,2019,"['inverse halftoning', 'image restoration', 'convolutional neural networks', 'multi-loss layers', 'dictionary learning']","이 논문에서는 하프톤 영상에서 연속 계조 영상을 복원하는 역방향 하프토닝 기법에 대해 소개하고자 한다.  최근 영상 복원 분야에서 큰 주목을 받고 있는 심층 합성곱 신경망 기법을 역방향 하프토닝 분야에 적용할지라도 평탄 영역에서 하프톤 패턴의 불완전한 제거나 에지 및 텍스처 영역에서 디테일 표현 부족은 여전히 현안으로 남아 있다. 이러한 문제를 해결하고자 이 논문에서는 다중 손실 계층을 도입해서 영상 구조 맵과 연속 계조 영상을 동시에 추정이 가능한 다중 스트림 기반의 심층 합성곱 신경망을 새롭게 제안하고자 한다. 그리고 실험 결과를 통해, 제안한 기법이 기존의 최첨단 기법들보다 화질 성능 측면에서 더 우수한 결과를 달성할 수 있음을 보이고자 한다.","This paper introduces the inverse halftoning method for reconstructing the continuous-tone images from the halftoned images. Even though recently-introduced deep convolutional neural networks having drawn much attention from image restoration areas are applied for the inverse halftoning, it still remains a pending issue to remove the halftone patterns completely in flat regions and improve the details in edge and texture regions. To address this problem, this paper presents a new multi-stream-based deep convolutional neural network, which enables the image structure map and the continuous-tone image to be estimated jointly by using multi-loss layers. Through the experimental results, it is also confirmed that the proposed method achieves better results than the conventional state-of-the-art methods in terms of visual quality performance."
딥러닝 모형을 사용한 한국어 음성인식,2019,"['한국어 음성인식', '종단 간 딥러닝', '연결성 시계열 분류기', '주의 기제', '베이즈 딥러닝', 'Korean speech recognition', 'end to end deep learning', 'Connectionist temporal classification', 'Attention', 'Bayesian deep learning']","본 논문에서는 베이즈 신경망을 결합한 종단 간 딥러닝 모형을 한국어 음성인식에 적용하였다. 논문에서는 종단 간 학습 모형으로 연결성 시계열 분류기(connectionist temporal classification), 주의 기제, 그리고 주의 기제에 연결성 시계열 분류기를 결합한 모형을 사용하였으며. 각 모형은 순환신경망(recurrent neural network) 혹은 합성곱신경망(convolutional neural network)을 기반으로 하였다. 추가적으로 디코딩 과정에서 빔 탐색과 유한 상태 오토마타를 활용하여 자모음 순서를 조정한 최적의 문자열을 도출하였다. 또한 베이즈 신경망을 각 종단 간 모형에 적용하여 일반적인 점 추정치와 몬테카를로 추정치를 구하였으며 이를 기존 종단 간 모형의 결괏값과 비교하였다. 최종적으로 본 논문에 제안된 모형 중에 가장 성능이 우수한 모형을 선택하여 현재 상용되고 있는 Application Programming Interface (API)들과 성능을 비교하였다. 우리말샘 온라인 사전 훈련 데이터에 한하여 비교한 결과, 제안된 모형의 word error rate (WER)와 label error rate (LER)는 각각 26.4%와 4.58%로서 76%의 WER와 29.88%의 LER 값을 보인 Google API보다 월등히 개선된 성능을 보였다.","In this paper, we propose an end-to-end deep learning model combining Bayesian neural network with Korean speech recognition.In the past, Korean speech recognition was a complicated task due to the excessive parameters of many intermediate steps and needs for Korean expertise knowledge.Fortunately, Korean speech recognition becomes manageable with the aid of recent breakthroughs in ``End-to-end"" model.The end-to-end model decodes mel-frequency cepstral coefficients directly as text without any intermediate processes.Especially, Connectionist Temporal Classification loss and Attention based model are a kind of the end-to-end.In addition, we combine Bayesian neural network to implement the end-to-end model and obtain Monte Carlo estimates.Finally, we carry out our experiments on the ``WorimalSam"" online dictionary dataset. We obtain 4.58% Word Error Rate showing improved results compared to Google and Naver API."
딥러닝기반 다중 표적 인식을 활용한 모바일 로봇 경로 계획,2019,"['표적인식', '경로계획', '장애물 회피', '딥러닝', '모바일 로봇', 'Taget Detection', 'Path Planning', 'Avoidance Obstacle', 'Deep-Learning', 'Mobile Robot']","복합적인 고차원의 임무를 수행하기 위하여 미래무인화 전투 체게는 인공지능 기술을 필요로 한다. 특히 합성곱 신경망은 영상뿐만 아니라 자연어 처리까지 광범위한 범위에서 탁월한 성능을 보이고 있어 무인화 전투체계의 표적정보인식, 피아식별, 전장정보인식 등 각종 센서 융합에 매우 적합하다. 본 연구에서는 합성곱 신경망의 영상인식 기술을 활용하여 다수 대상체의 상태정보를 인식함으로써 변화되는 환경에서의 무인로봇 경로 계획 개선 방안을 제시하였고 시뮬레이션을 통하여 추정된 로봇의 위치, 장애물, 목표물 정보로부터 로봇의 경로 계획의 유효성을 검증 하였다.","Unmmanned systems are one of the essential areas of future military weapons systems that must carry out dangerous and cmplex missions. Especially, deep learning should recognize many landmarks through the image and project them onto the map to improve the problem of position estimation, because it shows excellent performance of recognizing and classifying the characteristics of image data among other artificial intelligence techniques. In this study, the path planning of the unmanned reconnaissance aircraft and the unmanned ground vehicle, which are currently being used in the ROK military, is linked with the CNN based multi target recognition algorithm without GPS. Throuth experiments, we verified the effectiveness of the path planning of the mobile robot with respect to the position of the robot, obstacle, and target point estimated by the target detection algorithm."
소형 네트워크에서 배치 정규화의 스케일링 인자를 활용한 채널 프루닝,2019,"['Convolutional Neural Network', 'Pruning', 'Classification', 'Embedded Systems']",,
Self-Attention을 활용한 Siamese CNN-Bidirectional LSTM 기반 문장 유사도 예측,2019,"['자연어 처리', '유사도 측정', '샴 네트워크', '합성곱 신경망', '순환 신경망', '어텐션', 'natural language processing', 'similarity measure', 'siamese network', 'convolution neural network', 'recurrent neural network', 'attention']",본 논문에서는 입력된 두 문장의 유사도를 측정하는 딥러닝 모델을 제안한다. 기존의 문장의유사도 측정 모델에는 단어 혹은 형태소 단위로 문장을 분해하여 임베딩 하는 방식을 활용한다. 하지만 이는 사전의 크기를 증가시켜 모델의 복잡도를 높이는 문제점이 있다. 본 논문에서는 문장을 음소 단위로 분해하여 모델 복잡도를 줄이고 해당 음소를 묶어주는 다양한 필터 사이즈의 1D Convolution Neural Network와 Long Short Term Memory(LSTM)을 결합한 Siamese CNN-Bidirectional LSTM 모델을 제안한다. 본 모델을 평가하기 위해 네이버 지식인 데이터를 활용하여 기존의 문서 유사 측정에서 좋은 성능을 보이는 모델 Manhattan LSTM(MaLSTM)과 비교하였다.,"A deep learning model for semantic similarity between sentences was presented. In general, most of the models for measuring similarity word use level or morpheme level embedding.However, the attempt to apply either word use or morpheme level embedding results in higher complexity of the model due to the large size of the dictionary. To solve this problem, a Siamese CNN-Bidirectional LSTM model that utilizes phonemes instead of words or morphemes and combines long short term memory (LSTM) with 1D convolution neural networks with various window lengths that bind phonemes is proposed. For evaluation, we compared our model with Manhattan LSTM (MaLSTM) which shows good performance in measuring similarity between similar questions in the Naver Q&A dataset (similar to Kaggle Quora Question Pair)."
딥러닝 및 영상처리 기술을 활용한 콘크리트 균열 검출 방법,2019,"['콘크리트 균열', '균열 검출', '딥러닝', '영상처리', '합성곱신경망', 'Concrete Crack', 'Crack Detection', 'Deep Learning', 'Image Processing', 'CNN']","현행 균열조사 업무는 육안조사로 이루어지고 있어 점검자의 주관이 개입되어 점검 결과에 차이가 발생하거나, 측정오차가 발생할 여지가 있다. 이에 본 연구는 콘크리트 균열 조사의 객관성과 효율성을 높이기 위하여 딥러닝 네트워크 중 실시간 분석이 가능한 YOLO v.2를 활용하여 균열을 인지하고, 영상처리 기술을 활용하여 균열의 특성정보를 추출하는 프로세스를 제시하였다. 실험 결과, 실시간 분석이 가능한 검출속도와 정확도를 확보할 수 있었다. 본 연구의 결과는 시설물 하자진단 자동화 시스템 개발의 기초자료로 활용될수 있을 것이다.","Most of the current crack investigation work consists of visual inspection using simple measuring equipment such as crack scale. Thesemethods involve the subjection of the inspector, which may lead to differences in the inspection results prepared by the inspector, and maylead to a large number of measurement errors. So, this study proposes an image-based crack detection method to enhance objectivity andefficiency of concrete crack investigation. In this study, YOLOv2 was used to determine the presence of cracks in the image information toensure the speed and accuracy of detection for real-time analysis. In addition, we extracted shapes of cracks and calculated quantitatively,such as width and length using various image processing techniques. The results of this study will be used as a basis for the development ofimage-based facility defect diagnosis automation system."
트위터 사용자들의 감성을 이용한 사회적 이슈 분석,2019,"['소셜 네트워크 서비스', '트위터', '감성 분류', '사회적 이슈 분석', '합성곱 신경망', 'Social network service', 'Twitter', 'Sentiment classification', 'Social issues analysis', 'Convolutional neural networks']","대중들의 소통의 창구로 자리매김 하고 있는 소셜 네트워크 서비스(SNS)에 작성된 글은 감성을 많이 포함하고 있다는 특징을 갖고 있다. 그 중 트위터는 공개 Application Programming Interface(API)를 통한 데이터의 수집이 편리하다는 장점을 지니고 있다. 본 논문에서는 트위터 상에 표현된 사용자들의 감성 정보를 통해 사회적 이슈를 분석하고 마케팅 분야 활용 가능성을 제시한다. 이는 국민 또는 소비자의 의견과 반응을 필요로 하는 정부, 기업 등에 도움이 될 수 있다. 본 논문에서는 최근 사회적 이슈에 대한 트위터 텍스트 데이터를 긍정 또는 부정으로 분류하여 질적 분석을 제공하였고, 각 트윗의 좋아요 수, 리트윗 수 등에 대한 상관관계 분석을 통해 양적분석을 제공하였다. 질적 분석의 결과로 국민의 지지를 얻기 위해 관세정책을 홍보하고, 버즈 사용자에게는 기술적 편의를 제공할 것을 제안하였다. 양적 분석의 결과, 트위터 사용자들의 관심을 끌기 위해서는 긍정적인 트윗을 짧고 간단하게 작성해야 함을 밝혔다. 데이터의 수집 기간이 짧고, 단 두 가지의 키워드만을 분석하여 일반화 가능성이 떨어지는 한계를 가져 향후, 보다 긴 기간의 다양한 사회적 이슈를 분석할 예정이다.","Recently, social network service (SNS) is actively used by public. Among them, Twitter has a lot of tweets including sentiment and it is convenient to collect data through open Aplication Programming Interface (API). In this paper, we analyze social issues and suggest the possibility of using them in marketing through sentimental information of users. In this paper, we collect twitter text about social issues and classify as positive or negative by sentiment classifier to provide qualitative analysis. We provide a quantitative analysis by analyzing the correlation between the number of like and retweet of each tweet. As a result of the qualitative analysis, we suggest solutions to attract the interest of the public or consumers. As a result of the quantitative analysis, we conclude that the positive tweet should be brief to attract the users' attention on the Twitter. As future work, we will continue to analyze various social issues."
인공지능 기반의 행동인식을 통한 개인 운동 트레이너 구현의 방향성 제시,2019,"['Healthcare', 'Fitness', 'Artificial Intelligence', 'Deep Running', 'CNN', 'RNN', '헬스케어', '피트니스', '인공지능', '딥러닝', '합성곱 신경망', '순환 신경망']","최근 딥러닝을 비롯한 인공지능 기술의 활용이 다양한 분야에서 활발해지고 있으며, 특히 딥러닝 기술 기반의 객체 인식 및 검출에 뛰어난 성능을 보이는 여러 알고리즘들이 발표되고 있다. 이에 본 논문에서는 사용자의 편의성이 효과적으로 반영된 모바일 헬스케어 애플리케이션 구현에 대한 적절한 방향성을 제시하고자 한다. 기존의 피트니스 애플리케이션들에 대한 이용 만족도 연구 및 모바일 헬스케어 애플리케이션에 대한 현황을 파악하여, 이로부터 피트니스 애플리케이션 시장에서의 생존과 우위를 확보하는 동시에, 최근 주목 받고 있는 인공지능 기술의 효과적인 적용에 의한 성능 개선을 통해 기존 이용자 유지 및 확대를 도모하고자 한다.","Recently, the use of artificial intelligence technology including deep learning has become active in various fields. In particular, several algorithms showing superior performance in object recognition and detection based on deep learning technology have been presented. In this paper, we propose the proper direction for the implementation of mobile healthcare application that user's convenience is effectively reflected. By effectively analyzing the current state of use satisfaction research for the existing fitness applications and the current status of mobile healthcare applications, we attempt to secure survival and superiority in the fitness application market, and, at the same time, to maintain and expand the existing user base."
적응형 채널 어텐션 모듈을 활용한 복합 열화 복원 네트워크,2019,"['Image restoration', 'Deep learning', 'Channel attention', 'CNN', '영상복원', '딥러닝', '채널 어텐션', '합성곱신경망']",자율 주행 자동차나 소방 로봇과 같은 시스템에서 영상을 얻을 때 다양한 요인들로 인해 잡음，블러와 같은 열화가 발생한 다. 이런 열화된 영상에 직접 영상 분류와 같은 기술을 적용하기 어려워 열화 제거가 불가피하나 이러한 시스템들은 영상의 열화를 인식할 수 없어서 열화된 영상을 복원하는데 어려움이 있다. 본 논문에서는 영상에 적용된 열화를 인지하지 못하는 상황에서 여러 방법들로 열화된 영상으로부터 자연스럽고 선명한 영상을 복원하는 방법을 제안한다. 우리가 제안한 방법은 딥러닝 모델에 채널 어텐션 모듈과스깁 커넥션을사용하여 영상에 적용된 열화에 따라복원에 필요한 채널에 높은 가중치를 적용해 복합 열화 영상의 복원을 진행한다. 이 방법은 다른복합 열화복원 방법 에 비해 학습이 간단하고 기존의 다른 방법들에 비 해 높은 복합 열화 복원 성능을 낸다.,"The image obtained from systems such as autonomous driving cars or fire-fighting robots often suffer from several degradation such as noise, motion blur, and compression artifact due to multiple factor. It is difficult to apply image recognition to these degraded images, then the image restoration is essential. However, these systems cannot recognize what kind of degradation and thus there are difficulty restoring the images. In this paper, we propose the deep neural network, which restore natural images from images degraded in several ways such as noise, blur and JPEG compression in situations where the distortion applied to images is not recognized. We adopt the channel attention modules and skip connections in the proposed method, which makes the network focus on valuable information to image restoration. The proposed method is simpler to train than other methods, and experimental results show that the proposed method outperforms existing state-of-the-art methods."
A Study on Fault Classification of Machining Center using Acceleration Data Based on 1D CNN Algorithm,2019,"['Machining Center(머시닝센터)', 'Machine Learning(머신러닝)', 'Fault Signal Classification(고장신호 분류)', 'CNN(합성곱 신경망)']",,"The structure of the machinery industry due to the 4th industrial revolution is changing from precision and durability to intelligent and smart machinery through sensing and interconnection(IoT). There is a growing need for research on prognostics and health management(PHM) that can prevent abnormalities in processing machines and accurately predict and diagnose conditions. PHM is a technology that monitors the condition of a mechanical system, diagnoses signs of failure, and predicts the remaining life of the object. In this study, the vibration generated during machining is measured and a classification algorithm for normal and fault signals is developed. Arbitrary fault signal is collected by changing the conditions of un stable supply cutting oil and fixing jig. The signal processing is performed to apply the measured signal to the learning model. The sampling rate is changed for high speed operation and performed machine learning using raw signal without FFT. The fault classification algorithm for 1D convolution neural network composed of 2 convolution layers is developed."
인공지능 기반 MNIST 손글씨 인식에 대한 연구,2019,"['Handwriting', 'SLR', 'ANN', 'CNN', 'Deep learning', '손글씨', '소프트맥스 회귀분석', '인공신경망', '합성곱신경망', '딥러닝']",,"In the development of electronic devices such as PDAs, smartphones, and tablets, research on handwriting recognition has emerged. In the meantime, there have been efforts to recognize various handwriting such as numbers, Japanese, and English. However, there is a point that it is difficult to recognize when the font shape is relatively irregular, such as handwriting of children. As a result, the need for research to improve handwriting recognition rate by applying deep learning techniques has recently been raised. Therefore, this study attempted to improve handwriting recognition rate based on various deep learning techniques. In the case of handwriting, it is difficult to prepare a variety of data sets, which limits the recognition rate. In this study, we tried to improve the accuracy of handwriting recognition by using CNN technique in order to find a way to overcome these limitations. The techniques used were SLR, ANN, and CNN, each measuring the accuracy of each method. As a result, CNN showed the highest performance of 95%."
라이다 센서 데이터를 이용한 구형 특징 표현 기반의 도시 구조물 3차원 점 군 분류에 관한 연구,2019,"['a라이다 센서', '거리 데이터', '물체 인식', '도시 구조물', '키티 데이터', '구형 특징 표현', '합성곱 신경망', 'LiDAR Sensor', 'Depth Data', 'Object Recognition', 'Urban Structure', 'KITTI Data', 'Spherical Signature Descriptor', 'Convolutional Neural Network']","물체 인식은 영상 등의 이미지 정보와 깊이 정보 등의 센서 데이터를 이용하여 물체의 종류와 크기, 방향, 위치 등의 고차원적인 공간 정보를 실시간으로 알아내는 기술로 자율주행의 기본 기술이 된다. 본 논문에서는 거리 데이터 기반의 물체인식을 목표로 하고 있으며, 3차원 점을 구성하고 있는 모든 점에 의미를 부여 할 수 있는 구형 특징 표현을 이용한 학습 데이터 생성을 제안하였다. 구형 특징 표현을 이용하여 생성된 학습 데이터는 주변 점들의 분포와 밀집도를 이용하여 한 점의 특징을 정의 함으로서 모든 점들에 대하여 생성이 가능하기 때문에 인공지능을 위한 학습데이터 준비에 매우 용이하게 사용될 수 있다. 본 논문에서는 KITTI 데이터와 직접 수집한 라이다 센서 데이터를 구형 특징 표현에 적용하여 학습 데이터를 생성하고 생성된 학습 데이터를 인공지능 학습의 한 종류인 CNN(Convolutional Neural Network)에 입력하여 도시 구조물에 대한 3차원 점 군을 분류하고자 하였다.","Object recognition is a technology that detects real-time high-dimensional spatial information such as type, size, direction, and position of an object using sensor data such as image information and depth information of photographs. In this study, we aim at achieving object recognition based on distance data and propose the generation of learning data using the spherical signature descriptor capable of giving meaning to all points composing a 3D point group. The learning data generated by using the spherical signature descriptor can easily be used for generating learning data for artificial intelligence because it is possible to define the characteristics of a point using the distribution and density of the surrounding points and to generate from all the points. In this study, we generated learning data by applying collected KITTI and LiDAR sensor data directly to the spherical signature descriptor and classifying the urban structures through artificial intelligence learning using a CNN (convolutional neural network)."
이미지 기반 품질 관리 기법의 스마트 팩토리 현장 적용 이슈와 전략,2019,"['Quality Management', 'Machine Learning', 'Convolution Neural Network', 'Smart Factory', '품질 경영', '기계 학습', '합성곱 신경망', '스마트 팩토리']","콘볼루션 신경망 기술의 발전이 영상 기반 품질 경영에서의 전처리 부담을 많이 줄여주는 의미가 있지만, 콘볼루션 신경망의 발전이 전처리 노력을 완전히 제거해주지는 못한다. 그러나, 조금만 훈련받으면 컴퓨터 비전 전문가가 아니더라도 영상 기반의 품질 관리를 할 수 있으며, 이에 기반하여 가변적인 생산체계에 빠르게 적응할 수 있다. 스마트 팩토리에서 자동화된 품질관리를 현실에서 실제 적용하는 것은, 이 방법론들을 이해하고, 이를 일부 구현하여 적용하거나, 통합적으로 구현하여 완전 자동화하는 형태로 진행된다. 이 논문은 스마트 팩토리 환경에서 자동화된 품질 검사를 위한 이미지 기반 품질 관리 기법들을 개관하고 현실에 이러한 기법을 실제 적용하는 데에서 나타나는 이슈와 전략에 대해 토론한다.","Although the development of convolutional neural network technology reduces a lot of preprocessing burden in image-based quality management, it does not completely eliminate the preprocessing effort. However, with a little training, even non-computer vision specialists can perform image-based quality management, which allows them to quickly adapt to variable manufacturing systems. The actual application of automated quality control at the smart factory in the real world is based on understanding, implementing, and integrating these methodologies. This paper provides an overview of image-based quality management techniques for automated quality inspection in a smart factory environment and discusses the issues and strategies of applying these techniques in practice."
한국어 음성 명령어 인식을 위한 자동데이터 구축,2019,"['Korean Speech Command', 'Speech Recognition', 'Automatic Data Construction', 'ResNet', 'CNN', '한국어 명령어 인식', '음성인식', '자동 데이터 구축', '레스넷', '합성곱신경망']","최근 화두가 되고 있는 AI분야에서 가장 큰 문제점은 학습데이터의 부족 문제를 꼽을 수 있다. 수동 데이터 구축에는 많은 시간과 노력이 소요되기에 개인이 손쉽게 필요 데이터를 구축하기는 매우 어렵다. 반면, 수동 데이터 구축에 비해 자동으로 구축하는 것은 높은 품질을 유지하는 것이 관건이다. 본 논문에서는 한국어 음성 명령어 인식기 개발에 필요한 데이터를 웹에서 자동으로 추출하고, 학습데이터로 사용할 수 있는 데이터를 자동으로 선별하는 방법을 소개한다. 특히, 자동 구축된 한국어 음성 데이터를 대상으로 우수한 성능을 보이는 ResNet기반의 수정 모델을 기반으로, 건강 및 일상생활도메인의 명령어 셋을 대상으로 적용가능성을 보이기 위한 실험을 진행하였다. 자동으로 구축된 데이터만을 사용한 일련의 실험에서 건강도메인은 ResNet15에서 89.5%, 일상생활도메인에서는 ResNet8에서 82%의 정확도를 보임으로써, 자동 수집 데이터의 활용 가능성을 검증하였다.","The biggest problem in the AI field, which has become a hot topic in recent years, is how to deal with the lack of training data. Since manual data construction takes a lot of time and efforts, it is non-trivial for an individual to easily build the necessary data. On the other hand, automatic data construction needs to handle data quality issue. In this paper, we introduce a method to automatically extract the data required to develop Korean speech command recognizer from the web and to automatically select the data that can be used for training data. In particular, we propose a modified ResNet model that shows modest performance for the automatically constructed Korean speech command data. We conducted an experiment to show the applicability of the command set of the health and daily life domain. In a series of experiments using only automatically constructed data, the accuracy of the health domain was 89.5% in ResNet15 and 82% in ResNet8 in the daily lives domain, respectively."
CTC를 적용한 CRNN 기반 한국어 음소인식 모델 연구,2019,"['Phoneme Recognition', 'CTC Algorithm', 'Convolutional Neural Network', 'Recurrent Neural Network', '음소 인식', 'CTC 알고리즘', '합성곱 신경망', '순환 신경망']",,"For Korean phoneme recognition, Hidden Markov-Gaussian Mixture model(HMM-GMM) or hybrid models which combine artificial neural network with HMM have been mainly used. However, current approach has limitations in that such models require force-aligned corpus training data that is manually annotated by experts. Recently, researchers used neural network based phoneme recognition model which combines recurrent neural network(RNN)-based structure with connectionist temporal classification(CTC) algorithm to overcome the problem of obtaining manually annotated training data. Yet, in terms of implementation, these RNN-based models have another difficulty in that the amount of data gets larger as the structure gets more sophisticated. This problem of large data size is particularly problematic in the Korean language, which lacks refined corpora. In this study, we introduce CTC algorithm that does not require force-alignment to create a Korean phoneme recognition model. Specifically, the phoneme recognition model is based on convolutional neural network(CNN) which requires relatively small amount of data and can be trained faster when compared to RNN based models. We present the results from two different experiments and a resulting best performing phoneme recognition model which distinguishes 49 Korean phonemes. The best performing phoneme recognition model combines CNN with 3hop Bidirectional LSTM with the final Phoneme Error Rate(PER) at 3.26. The PER is a considerable improvement compared to existing Korean phoneme recognition models that report PER ranging from 10 to 12."
RDB 및 웨이블릿 예측 네트워크 기반 단일 영상을 위한 심층 학습기반 초해상도 기법,2019,"['Super Resolution', 'Deep Learning', 'Wavelet Coefficient', 'Residual Dense Block', 'WaveletSRNet']","단일 영상 초해상도 (Single Image Super-Resolution – SISR)기법은 카메라로 획득된 저해상도 영상에 필터 기반의 연산을 적용하여 좋은 화질의 고해상도 영상을 복원하는 과정이다. 최근에 심층 합성곱 신경망 학습의 발전에 따라 단일 영상 초해상도에 적용되는 심층 학습 기법들은 좋은 성과를 보여 주고 있다. 그 대표적인 방법으로 영상의 특징 맵 기반 웨이블릿 계수 학습을 통해 고해상도 영상을 복원하는 WaveletSRNet이 있다. 하지만 복잡한 알고리즘으로 인해 계산량이 증대되어 처리 속도가 늦고 특징 추출할 때 특징 맵을 효율적으로 활용하지 못 한다는 단점을 가지고 있다. 이를 개선하기 위해 본 논문에서는 단일 영상 초해상도 RDB-WaveletSRNet 기법을 제안한다. 제안된 기법은 잔여밀집블록(Residual Dense Block)을 사용하여 저해상도의 특징 맵을 효과적으로 추출하여 초해상도의 성능을 향상시키고 적절한 성장률을 설정하여 복잡한 계산량 문제까지 해결하였다. 또한 웨이블릿 패킷 분해를 사용하여 확대율에 맞게 웨이블릿 계수를 획득하므로 높은 확대율의 단일 영상 초해상도를 얻게 하였다. 다양한 영상에 대한 실험을 통하여, 제안하는 기법이 기존 기법보다 수행시간이 빠르며 영상 품질도 우수함을 입증하였다. 제안하는 방법은 기존 방법보다 화질은 PSNR 0.1813dB만큼 우수하며 속도는 1.17배 빠른 것을 실험을 통해 확인하였다.",
생활도로 노상주차 식별을 위한 Google Street View API와 딥러닝 모형의 적용,2019,"['Street Parking', 'Deep Learning', 'Google Street View Image', 'Object Detection', 'Convolutional Neural Network', '노상주차', '딥러닝', '구글 가로 이미지', '객체 탐색', '합성곱신경망']","본 연구는 Google Street View API를 통해 취득한 가로 이미지를 활용하여 서울시 생활도로의 노상주차를 식별하는 모형을 학습 및 검증하였다. 다양한 반복학습 횟수에 따른 모형들의 정확도를 검증하여 최종모형으로 도출하였으며, 최종 모형은 모든 객체 유형에 대해 약 75.68%, 노상주차 차량에 대해 약 82.07%의 객체 탐색 정확도를 나타낸다. 연구의 주요 시사점은 주로 현장조사에 의존해 진행되어, 시간과 금전적 비용이 많이 필요하던 노상주차 데이터 수집의 한계점을 보완하였다는 점과, 딥러닝 모형을 공간분석 및 도시 계획 분야의 공간정보 수집에 적용하여 그 가능성을 제시했다는 점을 들 수 있다.",This study has trained and validated a deep learning model that identifies street parking on the streets of Seoul by utilizing the street view images obtained through the Google Street View API. We derived the final model which shows highest accuracy of object detection among models with variation of the number of training iterations. The final model shows 75.68% accuracy of object detection for all object types and 82.07% for street parking vehicles. The main implications of this study are as follows. This study introduces improved data collection method of street parking data in terms of time and monetary cost compared to the conventional field survey. Also this study applies the deep learning using street view image on the collection of spatial information for the urban planning and spatial analysis field.
딥러닝을 이용한 화강암 X-ray CT 영상에서의 균열 검출에 관한 연구,2019,"['Granite', 'Deep learning', 'Crack detection', 'Image augmentation', '화강암', 'X-ray CT', '딥러닝', '균열추출', '영상 데이터 증대 기술']","본 연구에서는 화강암 시편에서 수압 파쇄법에 의해 생성된 미세균열의 3차원 형상을 X-ray CT 영상과 딥러닝을 이용하여 추출하였다. 실험으로 생성된 미세균열은 X-ray CT 영상 상에서 일반적인 영상처리 방법으로는 추출하기 매우 어렵고 육안으로만 관찰이 가능한 형태를 지닌다. 하지만 본 연구에서 제안한 합성곱 신경망(Convolutional neural network) 기반 인코더-디코더(Encoder-Decoder) 구조의 딥러닝 모델을 통해 미세균열을 정량적으로 추출할 수 있었다. 특히 픽셀 단위의 미세균열 추출을 위해 인코딩 과정에서 소실되는 정보를 디코딩 과정으로 직접 전달하는 디코더 모델을 제안하였다. 또한, 딥러닝 기반 신경망 학습에 필요한 데이터의 수를 증가시키기 위해 이미지의 분할(Division), 회전(Rotation), 그리고 반전(Flipping) 등으로 데이터를 생성하는 영상 증대 방법을 적용하였으며 이때 최적의 조합을 확인하였다. 최적의 영상 학습 데이터 증대 방법을 적용하였을 때 검증 데이터뿐만 아니라 테스트 데이터에서의 성능 향상을 확인하였다. 학습 데이터의 원본 개수가 딥러닝 기반 신경망의 균열 추출 성능에 미치는 영향을 확인하고 딥러닝 기술을 사용하여 성공적으로 미세균열을 추출하였다.","This study aims to extract a 3D image of micro-cracks generated by hydraulic fracturing tests, using the deep learning method and X-ray computed tomography images. The pixel-level cracks are difficult to be detected via conventional image processing methods, such as global thresholding, canny edge detection, and the region growing method. Thus, the convolutional neural network-based encoder-decoder network is adapted to extract and analyze the micro-crack quantitatively. The number of training data can be acquired by dividing, rotating, and flipping images and the optimum combination for the image augmentation method is verified. Application of the optimal image augmentation method shows enhanced performance for not only the validation dataset but also the test dataset. In addition, the influence of the original number of training data to the performance of the deep learning-based neural network is confirmed, and it leads to succeed the pixel-level crack detection."
객체 인식에서의 속도 향상을 위한 모델 앙상블,2019,"['Object detection', 'Ensemble method', 'Convolutional neural network']",,
Atrous Convolution과 Grad-CAM을 통한 손 끝 탐지,2019,"['Deep Learning', 'Atrous Convolution', 'Grad-CAM', 'Object Detection', '딥러닝', 'Atrous Convolution', 'Grad-CAM', '객체 탐지']","딥러닝 기술의 발전으로 가상 현실이나 증강 현실 응용에서 사용하기 적절한 사용자 친화적 인터페이스에 관한 연구가 활발히 이뤄지고 있다. 본 논문은 사용자의 손을 이용한 인터페이스를 지원하기 위하여 손 끝 좌표를 추적하여 가상의 객체를 선택하거나, 공중에 글씨나 그림을 작성하는 행위가 가능하도록 딥러닝 기반 손 끝 객체 탐지 방법을 제안한다. 입력 영상에서 Grad-CAM으로 해당 손 끝 객체의 대략적인 부분을 잘라낸 후, 잘라낸 영상에 대하여 Atrous Convolution을 이용한 합성곱 신경망을 수행하여 손 끝의 위치를 찾는다. 본 방법은 객체의 주석 전처리 과정을 별도로 요구하지 않으면서 기존 객체 탐지 알고리즘 보다 간단하고 구현하기에 쉽다. 본 방법을 검증하기 위하여 Air-Writing 응용을 구현한 결과 평균 81%의 인식률과 76 ms 속도로 허공에서 지연 시간 없이 부드럽게 글씨 작성이 가능하여 실시간으로 활용 가능함을 알 수 있었다.","With the development of deep learning technology, research is being actively carried out on user-friendly interfaces that are suitable for use in virtual reality or augmented reality applications. To support the interface using the user's hands, this paper proposes a deep learning-based fingertip detection method to enable the tracking of fingertip  coordinates to select virtual objects, or to write or draw in the air. After cutting the approximate part of the corresponding fingertip object from the input image with the Grad-CAM, and perform the convolution neural network with Atrous Convolution for the cut image to detect fingertip location. This method is simpler and easier to implement than existing object detection algorithms without requiring a pre-processing for annotating objects. To verify this method we implemented an air writing application and showed that the recognition rate of 81% and the speed of 76 ms were able to write smoothly without delay in the air, making it possible to utilize the application in real time."
고밀도 비디오 캡션 생성을 위한 의미 특징 학습,2019,"['고밀도 비디오 캡션 생성', '의미 특징 학습', '주의 집중', 'dense video captioning', 'semantic feature learning', 'attention']","본 논문에서는 고밀도 비디오 캡션 생성을 위한 새로운 심층 신경망 모델을 제안한다. 고밀도 비디오 캡션 생성은 하나의 입력 비디오로부터 다수의 이벤트 구간들을 찾아내고, 이들 각각에 관한 자연어 설명 문장을 생성하는 작업이다. 기존의 모델들에서는 합성곱 신경망을 통해 입력 비디오의 시각 특징 만을 추출하여 사용한 것과는 달리, 본 논문에서 제안하는 모델에서는 행위, 물체, 배경, 사람 등 중요한 이벤트 구성 요소들을 효과적으로 표현할 수 있는 고수준의 의미 특징들을 추가적으로 활용하였다. 또한 제안 모델에서는 순환 신경망인 LSTM을 이용하여 비디오 안에 포함된 이벤트 시간 영역들을 탐지하였다. 또, 제안 모델에서는 중요도에 따라 선택적으로 입력 특징들에 집중할 수 있도록, 캡션 생성 과정에 주의집중 메커니즘을 적용하였다. 고밀도 비디오 캡션 생성을 위한 대용량 벤치마크 데이터 집합인 ActivityNet Captions 데이터 집합을 이용한 다양한 실험을 통해, 본 논문에서 제안한 모델의 높은 성능과 우수성을 확인할 수 있었다.","In this paper, we propose a new deep neural network model for dense video captioning.Dense video captioning is an emerging task that aims at both localizing and describing all events in a video. Unlike many existing models, which use only visual features extracted from the given video through a sort of convolutional neural network(CNN), our proposed model makes additional use of high-level semantic features that describe important event components such as actions, people, objects, and backgrounds. The proposed model localizes temporal regions of events by using LSTM, a recurrent neural network(RNN). Furthermore, our model adopts an attention mechanism for caption generation to selectively focus on input features depending on their importance. By conducting experiments using a large-scale benchmark dataset for dense video captioning, AcitivityNet Captions, we demonstrate high performance and superiority of our model."
딥러닝을 이용한 스윙 시퀀스 영상 기반 3차원 골프 스윙 분석,2019,"['golf swing analysis', 'sequence image regression', 'deep learning']","빠르게 움직이는 골프 스윙 동작을 인간의 눈으로 평가하고 분석하는 것은 평가하는 사람의 주관에 따라 크게 달라질 수 있다. 본 논문에서는 최근 영상 인식 분야에서 좋은 성능을 나타내고 있는 딥러닝 기술을 이용해 단일 카메라 기반 스윙 분석 시스템의 한계를 극복하고, 3차원의 정량적 정보 추출 및 분석 방법을 연구한다. 먼저, 합성곱 신경망을 이용해 시퀀스 영상의 특징을 추출하고, 스윙 구간을 분류한다. 스윙 구간 정보를 갖는 시퀀스 특징은 양방향 장단기 메모리 기반의 스윙 분석 모델의 입력으로 사용되며, 바디-스웨이, 헤드-업, X-factor 분석을 수행한다. 각 분석 모델을 통한 스윙의 정량적 상태 예측 결과, 상체의 움직임 예측 RMSE 4.23, 머리 움직임 예측 RMSE 5.18, X-factor 예측 결과 RMSE 3.86의 성능으로 나타났다. 이 결과로 2차원 정면의 시퀀스 영상을 기반으로 3차원의 정량적 골프 스윙 분석이 가능함을 확인하였다.","The evaluation and analysis of the fast moving golf swing motion by human eyes can vary greatly depending on the evaluator's perspective. In this paper, we study the method of three-dimensional quantitative information extraction by overcoming the limitation of single camera based golf swing analysis system using deep learning which is showing good performance in image recognition field recently. First, the features of the sequence images are extracted using convolutional neural network, and the swing section is classified. Sequence features with swing section information are used as inputs to the bidirectional long short-term memory based swing analysis model, and perform body-swing, head-up, and X-factor value prediction. Experimental results showed that the performance of the upper body motion prediction RMSE 4.23, the head motion prediction RMSE 5.18, and the X-factor prediction result RMSE 3.86. As a result, it is confirmed that 2D frontal sequence images based 3D quantitative golf swing analysis is possible."
CNN을 활용한 IoT 스트림 데이터 패턴 분류 기법,2019,"['IoT', '스트림 데이터', '딥러닝', '패턴 분류', 'IoT', 'stream data', 'deep learning', 'pattern analysis']","사물 인터넷(Internet of Things, IoT) 환경의 발달로 다양한 종류의 센서들로부터 대량의 데이터가 생성되고 있으며, 이를 수집, 관리 및 분석하기 위한 빅데이터 기술이 중요해지고 있다. 최근에는 실시간으로 생성되는 대용량의 IoT 데이터 분석에 딥러닝 기술을 활용하여 특정 데이터 패턴이나 경향성의 분석을 수행하기 위한 연구가 진행되고 있다. 본 논문에서는 헬스케어 등 IoT 기반 서비스에의 활용 가능성이 높은 스트림데이터 중 하나인 ECG(Electrocardiogram, 심전도) 데이터에 대하여, 딥러닝 모델을 설계 및 적용함으로써 효율적인 분석을 가능하도록 하였다. 먼저, ECG 스트림 데이터의 패턴 분류를 위하여 합성곱 신경망(Convolutional Neural Networks, CNN) 기반의 딥러닝 모델을 설계하고, 이를 최적화하기 위한 다양한 파라미터들을 각각 모델의 구조와 학습에 관련한 파라미터들로 분리하여 실험을 설계 및 진행하였다. 또한, 분류 작업의 추가적인 성능 향상을 위하여, ECG 스트림 데이터에 대한 전처리 기법을 고안하여 적용해 보았다. 이러한 다양한 조건을 기반으로 설계된 실험들은, 서로 다른 센서에서 서로 다른 목적으로 수집되어 서로다른 특성을 갖는 두 가지의 ECG 스트림 데이터 세트 에 대하여 각각 수행되었다. 그 결과, 레이어가 깊을수록, 배치 크기가 큰 학습 모델일수록 IoT 스트림 데이터의 패턴 분류에 용이한 모델 구조라는 결론을 얻을수 있었다.","These days due to the development of the Internet of Things environment, big data technology is becoming important for collecting and managing large amounts of data. Recent studies are being conducted to incorporate deep learning technology into Internet of Things(IoT) data analysis in order to classify the specific pattern and trends. In this paper, ECG(Electrocardiogram) data, which could be useful for IoT services, is the input steam data, and a deep learning model structure suitable for data characteristics is found, so that IoT data analysis is efficiently performed. In order to classify the IoT stream data pattern, the experiments were conducted to find the best suitable model structure using the convolutional neural networks. To optimize the CNN, various models and parameter values were used to design various experiments. Also to enhance the classification performance, a preprocessing step is added to the existing convolutional neural networks model. The model structure parameters and the model learning parameters are divided into two major conditions. The experiment environment is set up and applied to two time series data with different characteristics. It is concluded that the deeper the layer and the larger the batch size, the easier model structure for IoT data pattern classification."
모노 카메라 영상과 딥 러닝을 이용한 차량 검출 및 거리 등급 분류에 관한 연구,2019,"['딥러닝', '객체검출', '거리추정', '단안카메라', 'Deep learning', 'Object Detection', 'Distance Estimation', 'Mono Camera']","본 연구에서는 차량에 부착된 모노 카메라와 딥 러닝을 이용하여 객체 검출 및 검출된 객체에 대한 거리정보를 바탕으로 하는 위험도 분류 시스템을 제안한다. 다양한 상황에서 기존 컴퓨터 비전 기법들보다 변화에 강인하며 검출 능력이 뛰어난 딥 러닝을 이용하여 주행 영상을 통해 주행환경 상에 있는 객체들을 검출한다. 이때 객체 검출기로는 합성 곱 신경망 네트워크를 기반으로 만들어진 YOLO v2(You Only Look Once v2)알고리즘을 이용하며, 해당 알고리즘은 사전에 ImageNet 1000 Class 데이터로 학습 된 Pre-trained model에 KITTI 데이터 셋 및 웹 포털 사이트에서 크롤링을 통해 획득한 12K개의 이미지를 이용하여 전이학습 하였다. 그리고 DB 구축 Tool을 이용하여 KITTI 데이터 셋에서 취득한 이미지와 캘리브레이션된 LiDAR 센서 데이터를 통해 검출된 객체와의 거리 정보를 취득하였다. 객체 검출기의 결과로는 Bounding Box의 이미지 내 좌표인 x,y와 Bounding Box의 이미지 내 크기인 width, height 정보가 나온다. 객체와의 거리정보를 특정 구간 단위로 분류하여 Class화 하였고, 해당 Class(거리 등급)와 객체 검출 정보인 Bounding box 정보들을 Multi-layer Perceptron을 이용하여 분류한다.","In this study, we propose a risk classification system based on distance information of object detected and objects detection using mono camera based on deep learning. It detects the objects in the driving environment through driving images by using deep learning which is robust against change and has superior detection ability than existing computer vision techniques in various situations. In this case, we use YOLO v2 (You Only Look Once v2) algorithm, which is based on a convolution neural network as an object detector. The algorithm uses a KITTI data set and a web portal The site was trained using 12K images acquired through crawling. Using the DB construction tool, we obtained the distance information between the image obtained from the KITTI dataset and the detected object through the calibrated LiDAR sensor data. The result of the object detector is x, y coordinates in the image of the bounding box, and width and height information in the image of the bounding box. Classification is made by classifying the distance information with objects in a specific section, and classification of the class (distance class) and object detection information, Bounding box information, using Multi-layer Perceptron."
