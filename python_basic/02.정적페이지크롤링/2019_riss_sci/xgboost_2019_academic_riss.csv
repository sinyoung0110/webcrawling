title,date,keywords,abstract,multilingual_abstract
머신러닝을 통한 가계의 재무스트레스 영향요인 예측 및 분석: XGBoost의 활용,2019,"['재무스트레스', '머신러닝', 'XGBoost', '객관적 재무상태', '주관적 인식', '재무행동', '가계재무복지', 'financial stress', 'machine learning', 'financial status', 'subjective perception', 'financial behavior', 'household well-being']",,"In this study, we explored how various factors influenced financial stress. Also, to suggest ways to improve the economic well-being of households we identified influence of the factors. For this purpose, 2,006 data were collected through online surveys. The analysis method was used XGBoost which is one of the algorithms using machine learning and multiple regression analysis. After analyzing the important predictors of financial stress through XGBoost, multiple regression analysis of financial stress was conducted to confirm the specific influence of variables. The results of the study are as follows. First, The level of financial stress that consumers perceive as subjective is about 2.3 points on average for 4 points. Therefore, it is necessary to constantly try to manage the consumer's financial stress at an appropriate level. Second, As a result of analyzing XGBoost to determine whether the consumer's financial stress level belongs to the high and low groups based on the average, it is confirmed that the variable indicating the objective financial state of the consumer and the variable indicating the subjective perception are all influenced. On the other hand, factors related to long - term savings and investment, long - term risk management insurance, and future prospects for the household economy are less important. Third, The effect of the major factors revealed that the subjective perception of consumers has a great influence on the financial stress level. Especially, we can confirm that the factors related to the emergency fund based on the short-term plan are influential. Households’ monthly income, savings and investment, and debt payment were more influential on financial stress level than stock such as household total assets. Based on the above results, it is necessary to support effective policy and consumer education so that consumers can manage financial stress level well."
XGBoost 기법을 이용한 단기 전력 수요 예측 및 하이퍼파라미터 변화에 따른 영향 분석,2019,"['Load forecasting', 'Machine Learning', 'XGBoost', 'Hyperparameter']",,"Accurate load forecasting is getting vital with social and economic development to secure electricity supply and minimize redundant electricity generation. The load forecasting is also essential for efficient power system operation. As machine learning techniques become popular due to the breakthroughs in the application of intelligent systems such as speech or image recognition, variety of machine learning algorithms have also been applied to predict electricity demand. For load forecasting, this paper employs XGBoost algorithm that has recently been receiving attention. To yield the maximum performance of the XGBoost model, we performed grid search method to find optimal hyperparameters of XGBoost. The effects of the XGBoost model’s hyperparameters on the model are assessed and visualized."
XGBoost 모형을 활용한 코스피 200 주가지수 등락 예측에 관한 연구,2019,"['기계학습', '자기회귀모형', '주가예측', 'LSTM 신경망', 'XGBoost 모델', 'Autoregressive model', 'LSTM neural network', 'machine learning', 'Stock price prediction', 'XGBoost model']","주식시장은 자본주의 경제 체제를 나타내는 대표적인 시장으로써 금융시장에서 중요한 경제적 기능을 수행한다. 또한, 주식시장은 기업뿐만 아니라 개인 투자자들에게 자본을 획득할 수 있는 유용한 수단으로 여겨지고 있다. 이러한 인식 속에서 주가의 흐름을 정확하게 예측하는 것은 현재까지도 중요한 연구 과제로 남아있다. 최근 기계학습을 활용한 주가예측에 대한 연구들이 활발하게 진행되고 있는 가운데, 본 연구에서는 다양한 분야에서 우수성을 입증하고 있는 XGBoost (extreme gradient boosting) 모델을 주가 등락 예측에 활용하고자 한다. XGBoost 모델의 유용성을 입증하기 위해 시계열 데이터 분석에 강점을 가지고 있다고 알려진 LSTM (long-short term memory) 신경망과 전통적으로 가장 널리 사용되었던 시계열 분석 기법인 자기회귀모형의 예측 결과들을 비교 및 분석하였다. 실증분석 결과 주가등락 예측에 있어서 XGBoost 모델의 유용성을 확인할 수 있다.","The stock market is a representative market representing the capitalist economic system and performs important economic functions in the financial market. The stock market also plays a role of acquiring capital for both individual and corporate investors. Accurately predicting the stock prices remains an important research task. In recent years, studies on stock price prediction using machine learning have progressed. In this study, we will use the XGBoost (extreme gradient boosting) model, which has been used in various fields recently and proved its excellence to predict stock price fluctuation. In order to demonstrate the superiority of the XGBoost model, we compared and analyzed the results of the LSTM (long-short term memory) neural network which showed good performance in the previous studies and the autoregressive model which is a conventional time series analysis technique. The empirical analysis shows that the XGBoost model is competitive in predicting stock price movements."
XGBoost 기반의 2단계 확률적 일사량 예측과 태양광 예측 알고리즘의 성능 검증,2019,"['2-Stage Forecasting', 'XGBoost (Extreme Gradient Boosting)', 'Solar Power Forecasting']",,"We propose the novel solar power forecasting algorithm by using the Extreme Gradient Boosting (XGBoost) machine based on the 2-stage forecasting structure. Our algorithm is implemented to solve three problems. First, the solar power is linearly proportional to the solar irradiation on a target solar panel, but it is hard to obtain the target solar irradiation. Therefore, in the first stage, we predict the target solar irradiation by using the XGBoost based on numerical weather prediction, which is measured on a different location but modified for the target location. Second, the forecasting errors on the predicted solar irradiation can be transferred to the second stage when the predicted solar irradiation is used to predict the solar power. We forecast the conditional error distribution of predicted irradiation by collecting forecasting errors, and we sample solar irradiation scenarios, which are converted to the solar power scenarios. Then, the final point forecast of solar power is estimated by calculating the median of scenarios so that we can improve the forecasting accuracy. Third, in this process, the quality of numerical weather prediction deteriorates as the target hour is farther. Therefore, we build forecasting models for each target hour in parallel to minimize the forecasting accuracy deterioration from the quality deterioration. Finally, we verify our proposed algorithm by participating in the solar power forecasting competition hosted by KPX."
A Recidivism Prediction Model Based on XGBoost Considering Asymmetric Error Costs,2019,"['재범 예측', '비대칭 오류비용', '임계치 최적화', '데이터 마이닝', 'XGBoost', 'Recidivism Prediction', 'Asymmetric Error Cost', 'Threshold Optimization', 'Data Mining', 'XGBoost']",,"Recidivism prediction has been a subject of constant research by experts since the early 1970s. But it has become more important as committed crimes by recidivist steadily increase. Especially, in the 1990s, after the US and Canada adopted the 'Recidivism Risk Assessment Report' as a decisive criterion during trial and parole screening, research on recidivism prediction became more active. And in the same period, empirical studies on 'Recidivism Factors' were started even at Korea. Even though most recidivism prediction studies have so far focused on factors of recidivism or the accuracy of recidivism prediction, it is important to minimize the prediction misclassification cost, because recidivism prediction has an asymmetric error cost structure.In general, the cost of misrecognizing people who do not cause recidivism to cause recidivism is lower than the cost of incorrectly classifying people who would cause recidivism. Because the former increases only the additional monitoring costs, while the latter increases the amount of social, and economic costs. Therefore, in this paper, we propose an XGBoost(eXtream Gradient Boosting; XGB) based recidivism prediction model considering asymmetric error cost.In the first step of the model, XGB, being recognized as high performance ensemble method in the field of data mining, was applied. And the results of XGB were compared with various prediction models such as LOGIT(logistic regression analysis), DT(decision trees), ANN(artificial neural networks), and SVM(support vector machines). In the next step, the threshold is optimized to minimize the total misclassification cost, which is the weighted average of FNE(False Negative Error) and FPE(False Positive Error). To verify the usefulness of the model, the model was applied to a real recidivism prediction dataset. As a result, it was confirmed that the XGB model not only showed better prediction accuracy than other prediction models but also reduced the cost of misclassification most effectively."
Data-Driven Materials Modeling with XGBoost Algorithm and Statistical Inference Analysis for Prediction of Fatigue Strength of Steels,2019,['Fatigue strength\xa0Machine learning\xa0Data mining\xa0Materials informatics\xa0Materials database\xa0Data-driven model'],,"With the rapid development of the industry, the demand for new materials is increasing. However, new material development is time-consuming and costly. In this study, we proposed a workflow that uses data to create a materials model that accurately reflects the properties of materials. Six different numerical models for predicting the fatigue strength of steels were constructed with an empirical dataset extracted from a certified database (NIMS MatNavi material database). Because it is very difficult to understand the structure and patterns of large amounts of datasets and develop good predictive models at once, we have sought reliable models through statistical inference analysis, which has not been done in previous studies. We also chose the highest performance model with the accuracy (R2 = 0.9850) by applying the latest XGBoost algorithm. Through further study, we believe that this workflow can be used to develop predictive models on various properties of materials."
악성코드 패밀리 분류를 위한 API 특징 기반 앙상블 모델 학습,2019,"['Malware Detection', 'Malware Classification', 'Feature Selection', 'Tree-based Ensemble']","본 논문에서는 악성코드 패밀리 분류를 위한 훈련 데이터의 특징을 제안하고, 앙상블 모델을 이용한 다중 분류 성능을 분석한다. 악성코드 실행 파일로부터 API와 DLL 데이터를 추출하여 훈련 데이터를 구성하며, 의사 결정 트리기반 Random Forest와 XGBoost 알고리즘으로 모델을 학습한다. 악성코드에서 빈번히 사용되는 API와 DLL 정보를 분석하며, 고차원의 훈련 데이터 특징을 저차원의 특징 표현으로 변환시켜, 악성코드 탐지와 패밀리 분류를 위한API, API-DLL, DLL-CM 특징을 제안한다. 제안된 특징 선택 방법은 데이터 차원 축소와 빠른 학습의 장점을 제공한다. 성능 비교에서 악성코드 탐지율은 Random Forest가 93.0%, 악성코드 패밀리 분류 정확도는 XGBoost가92.0%, 그리고 정상코드를 포함하는 테스트 오탐률은 Random Forest와 XGBoost가 3.5%이다.","This paper proposes the training features for malware family analysis and analyzes the multi-classification performance ofensemble models. We construct training data by extracting API and DLL information from malware executables and useRandom Forest and XGBoost algorithms which are based on decision tree. API, API-DLL, and DLL-CM features formalware detection and family classification are proposed by analyzing frequently used API and DLL information frommalware and converting high-dimensional features to low-dimensional features. The proposed feature selection methodprovides the advantages of data dimension reduction and fast learning. In performance comparison, the malware detectionrate is 93.0% for Random Forest, the accuracy of malware family dataset is 92.0% for XGBoost, and the false positive rateof malware family dataset including benign is about 3.5% for Random Forest and XGBoost."
수문학적 활용을 위한 머신러닝 기반의 강우보정기술 개발,2019,"['Heavy rainfall', 'Machine learning', 'Rainfall correction', 'LightGBM', 'XGBoost']",,"For the purposes of enhancing usability of Numerical Weather Prediction (NWP), the quantitative precipitation prediction scheme by machine learning has been proposed. In this study, heavy rainfall was corrected for by utilizing rainfall predictors from LENS and Radar from 2017 to 2018, as well as machine learning tools LightGBM and XGBoost. The results were analyzed using Mean Absolute Error (MAE), Normalized Peak Error (NPE), and Peak Timing Error (PTE) for rainfall corrected through machine learning. Machine learning results (i.e. using LightGBM and XGBoost) showed improvements in the overall correction of rainfall and maximum rainfall compared to LENS. For example, the MAE of case 5 was found to be 24.252 using LENS, 11.564 using LightGBM, and 11.693 using XGBoost, showing excellent error improvement in machine learning results. This rainfall correction technique can provide hydrologically meaningful rainfall information such as predictions of flooding. Future research on the interpretation of various hydrologic processes using machine learning is necessary."
학습분석 기반 대학 신입생 대상 학습부진 위험학생 조기예측 모델 개발 및 군집별 특성 분석,2019,"['learning analytics', 'underachivement', 'predictictive modeling', 'freshmen', 'machine learning', '학습분석', '학습부진', '예측 모형', '신입생', '기계학습']","대학 첫 학기의 성적이 향후 학업성취와 지속에 영향을 미치며, 특히, 학령인구의 지속적 감소와 신입생들의 학업역량 약화를 고려할 때 신입생 대상의 학습 성과 예측을 통한 선제적 대응은 매우 중요하다. 이에 본 연구는 학습분석을 기반으로 2016년~2018학년도까지 A대학의 3개년 동안의 신입생 4,662명의 데이터를 수집·분석하여 학습부진 가능성이 있는 학생을 조기에 예측할 수 있는 예측모형을 개발하고, 위험 학생으로 예측된 학생들의 특성을 분석하여 중재 프로그램 설계를 위한 시사점을 도출하고자 하였다. 기계학습분석기법인 XGBoost를 활용한 최적모형 예측 결과 예측 모형의 재현도는 62.3%, 정밀도는 29.56%, F점수는 0.4, ROC곡선의 AUC는 0.733 으로 데이터가 제한적인 신입생 대상임을 고려할 때 의미 있는 모형이라고 할 수 있다. 예측을 위한 주요 변수로는 노력조절, 학생부사회/과학등급평균, 수능언어백분위, 수능수리백분위, 입시 서류전형 점수, 성별, 학교를 그만둘 의향, 지난해 한주동안 게임시간, 수능탐구백분위, 학생부등급평균 등인 것으로 나타났다. 또한, K-means 군집 분석을 통해 학습부진 학생들을 특징에 따라 6개 그룹으로 군집화하였으며, 군집을 구분하는 주요 변수들은 ‘학교만족도’와 ‘자기조절학습’과 관련된 변수들이었다. 이러한 연구결과를 바탕으로 예측 결과를 활용한 중재활동 시 고려사항과, 예측 정확도 및 중재 효과성 향상을 위한 고려 사항을 교육현장에서의 실천과 후속연구를 위하여 제언하였다.","It is highly important to make proactive interventions for students at-risk through early prediction by considering how the first semester GPA would effect the student’s overall academic success to higher education. In this research, we have collected, analyzed a data set of 4,662 freshmen students in “A” university from 2016 to 2018, and developed a machine learning prediction model to find students who are more likely to get bad grades at the end of first semester. Finally, we also drew implications to design intervention programs by analyzing characteristics of at-risk students. The performance of the prediction model using XGboost had a recall (62.3%), precision (29.56%), F-score (0.4), and AUC (0.733). This performance of the model can be acceptable in a situation where data on freshmen is insufficient. The most important predictor variables in this model were self-regulatory capabilities, the high-school GPA in social sciences, Korean language & mathematics scores in College Scholastic Ability Test, etc. Students at risk are clustered into six groups by K-means clustering analysis according to their level of satisfaction in college and self-regulated learning. From the research results, we suggested what should be considered to take intervention for practice in higher education and how to collect and analyze data to improve model performance for future work in this area of research."
서울시 공공자전거 운행 거리 예측을 위한 머신 러닝 모델의 비교 연구,2019,"['Linear regression', 'XGboost', 'Random forest', 'Embedding', 'Haversine distance']",,"Cities in many countries offer public bicycle sharing services to help solve the health and traffic jams of citizens and to solve environmental problems caused by automobiles. Using the machine learning models, the public bike service in Seoul have been analyzed. To service the bike sharing efficiently, the prediction of trip distance or trip duration will be needed. The prediction of trip distances and durations has important roles to help the proper operations and improvement of the bike rental services. The trip distances are deeply related to the trip durations, and could be calculated accurately when including the positions of pickup and return places, environment information such as temperature, humidity, fine dust density, et., al. To build models, linear regression, Random Forest, XGBoost and deep learning techniques have been used. Random Forest and XGboost provides important features among features. Especially, XGBoost being interested in many data manipulating and anlysing areas shows improved accuracy and can utilized the GPU to boost speed. To apply the deep learning in analysis of structured data(tabula data), embedding of categorical features will be done and the remaining continuous features and embedded features put into the fully connected neural nets. The deep learning neural net model shows the best accuracy and then XGBoost model, Random Forest models followed."
온라인 뉴스와 기술적 지표를 이용한 테마주 등락 예측,2019,"['테마주', '주가예측', '딥러닝', 'GRU', 'XGBoost', 'Theme Stocks', 'Stock Price Prediction', 'Deep Learning', 'GRU', 'XGBoost']","특정 주제의 뉴스에 의해 주가가 영향을 받는 기업군을 테마주라고 한다. 최근 온라인 뉴스와 기술적 지표를 활용한 주가예측이 연구되고 있지만, 투자 위험이 큰 테마주에 대한 연구는 부족하다. 본 논문에서는 감성 지표와 기술적 지표를 이용하여 테마주에 대해 주가 등락을 예측하는 모델을 제안한다. 제안한 모델은 Gated Recurrent Unit (GRU)를 사용해 뉴스로부터 감성지표를 계산하고, 감성지표와 기술적 지표를 바탕으로 eXtreme Gradient Boosting (XGBoost)을 통해 주가 등락을 예측한다. 북한 테마에 속하는 10개 기업을 이용하여 실험한 결과, 제안한 모델이 최신연구의 모델보다 평균 정확도가 최대 19.0%P 더 높았다.","Theme stocks are a group of companies whose stock prices are affected by news of a certain subject. Recently, there have been research efforts to predict stock prices using online news and technical indicators, but little attention has been paid so far to theme stocks, which have high investment risks. In this paper, we propose a model that predicts stock price fluctuations for theme stocks using a sentiment indicator and technical indicators. The proposed model calculates a sentiment indicator from news using Gated Recurrent Unit (GRU) and predicts stock price fluctuations through eXtreme Gradient Boosting (XGBoost) based on the sentiment indicator and technical indicators. The experimental results using 10 companies belonging to the North Korea theme show that the proposed model improves the average accuracy up to 19.0%P compared with the state-of-the-art model."
음성의 감정 인식을 위한 감정 분류기 앙상블 기법,2019,"['음성 감정인식', '혼합 모델', '서포트 벡터 머신', '랜덤 포레스트', 'xgboost', 'speech emotion recognition', 'ensemble model', 'random forest', 'xgboost']","IT기술의 발달로 개인화 서비스 기술이 인기를 끌게 되면서, 인간의 감정 상태를 판단하기 위한 감정 인식 기술이 연구되고 있다. 감정 인식 기술의 한 분야인 음성 감정 인식은 사용자의 음성 데이터를 분석하여 감정을 판단하는 기술이다. 감정 인식 기술은 얼굴, 표정, 뇌파와 같은 다양한 데이터를 기반으로 연구되고 있는데, 그 중에서 음성을 이용한 감정 인식 기술은 사용a자와 직접 대면하지 않고 음성만으로 감정을 인지할 수 있어 적은 공간적, 시간적 비용으로 사용자의 감정 상태를 파악할 수 있다는 장점을 가지고 있다. 본 논문에서는 음성을 이용한 감정 인식 기술의 성능을 높이기 위하여, 머신 러닝 알고리즘 중에서 분류에 높은 성능을 가진 서포트 벡터 머신, 랜덤 포레스트, xgboost 알고리즘으로 감정 모델을 학습하여 분류한 결과를 혼합하여 음성의 감정을 판단하는 방법을 제안한다. 제안한 방법은 한 가지 분류 모델을 사용하여 감정을 인식할 때 보다 최대 5.1% 높은 감정 인식률을 보였다.",
세계은행 공적개발원조사업의 엔지니어링 기업 간 협력관계 예측모델 개발,2019,"['국제 협력 전략', '세계은행 ODA', '링크예측', 'XGBoost', 'International Cooperative Strategies', 'World Bank ODA', 'Link Prediction', 'XGBoost']",,"Korean construction engineering firms want to pave the way for expansion of overseas markets through the World Bank’s Official Development Assistance (ODA) projects as a way to improve their overseas project performance. However, since the World Bank project competes with global companies for limited projects, building partnerships with suitable business partners is essential to gain an upper hand in bidding competition and meet the institutional conditions of the recipient country. In this regard, many network studies have been conducted in the past through Social Network Analysis (SNA), but few have been analyzed based on the process of changes in the network. So, This study collected winning data from the three Southeast Asian countries that ended after the World Bank’s ODA project performed smoothly, and established a learning-based link prediction model that reflected the dynamic nature of the network. As a result, the 11 main variables acting on building a cooperative relationship between winning companies were derived and the effect of each variables on the probability value of cooperation between individual links was identified."
Machine Learning-Based Prediction of Korean Triage and Acuity Scale Level in Emergency Department Patients,2019,"['Triage', 'Hospital Emergency Service', 'Machine Learning', 'Natural Language Processing']",,"Objectives: Triage is a process to accurately assess and classify symptoms to identify and provide rapid treatment to patients.The Korean Triage and Acuity Scale (KTAS) is used as a triage instrument in all emergency centers. The aim of this study was to train and compare machine learning models to predict KTAS levels. Methods: This was a cross-sectional study using data from a single emergency department of a tertiary university hospital. Information collected during triage was used in the analysis. Logistic regression, random forest, and XGBoost were used to predict the KTAS level. Results: The models with the highest area under the receiver operating characteristic curve (AUROC) were the random forest and XGBoost models trained on the entire dataset (AUROC = 0.922, 95% confidence interval 0.917–0.925 and AUROC = 0.922, 95% confidence interval 0.918–0.925, respectively). The AUROC of the models trained on the clinical data was higher than that of models trained on text data only, but the models trained on all variables had the highest AUROC among similar machine learning models. Conclusions: Machine learning can robustly predict the KTAS level at triage, which may have many possibilities for use, and the addition of text data improves the predictive performance compared to that achieved by using structured data alone."
에어비앤비(Airbnb) 웹 로그 데이터를 이용한 고객 행동 예측,2019,"['웹 로그', '고객 행동 예측', '기계학습', '데이터 마이닝', 'web log', 'customer behavior prediction', 'machine learning', 'data mining']","그동안의 고객 행동에 대한 예측은 주로 고객이 가지는 고정적인 특성을 이용해왔다. 최근에는 점차 고객들의 활동이 오프라인에서 온라인으로 이동하면서 각 고객의 웹 로그를 추적하는 일이 가능해졌다. 그러나 방대한 양의 웹 로그 데이터를 수집할 수 있게 된 반면, 이에 대한 연구는 로그 데이터를 정리하거나 기술적인 특성만을 설명하는 것에 그쳤다. 본 연구에서는 웹사이트 Kaggle에서 제공하는 Airbnb 고객들의 성별, 연령 등의 기본 정보 및 웹 로그가 포함된 데이터셋을 이용하여 첫 숙소 예약까지 걸리는 개인의 의사 결정 시간을 예측하였다. Lasso, SVM, Random Forest, XGBoost 등 다양한 방법론을 활용하여 최적의 모형을 찾고, 웹 로그 데이터의 유무에 따른 예측오차를 비교하여 웹 로그의 효용성을 확인하였다. 결과적으로 오분류율이 약 20%로 낮은 랜덤 포레스트 분류모형을 최적모형으로 선택하였다. 또한, 웹 로그 데이터를 이용하여 고객 개개인의 행동을 예측한 결과 사용하지 않은 경우와 비교해 예측의 정확도가 최대 두 배 더 높아진 것을 확인할 수 있었다.","Customers' fixed characteristics have often been used to predict customer behavior. It has recently become possible to track customer web logs as customer activities move from offline to online. It has become possible to collect large amounts of web log data; however, the researchers only focused on organizing the log data or describing the technical characteristics. In this study, we predict the decision-making time until each customer makes the first reservation, using Airbnb customer data provided by the Kaggle website. This data set includes basic customer information such as gender, age, and web logs. We use various methodologies to find the optimal model and compare prediction errors for cases with web log data and without it. We consider six models such as Lasso, SVM, Random Forest, and XGBoost to explore the effectiveness of the web log data. As a result, we choose Random Forest as our optimal model with a misclassification rate of about 20%. In addition, we confirm that using web log data in our study doubles the prediction accuracy in predicting customer behavior compared to not using it."
기계학습 기법을 이용한 CNC 공구 마모도 예측에 관한 연구,2019,"['CNC 설비', '머신러닝', '랜덤 포레스트', '서포터 벡터 머신', 'Random Forest', 'XGBoost', 'CNC', 'SVM', 'Machine Learning']","4차 산업혁명이 주목받고 있다. 특히 스마트 팩토리는 제조 분야에서 그 필요성이 강조되고 있다. 현재 제조 분야에서 CNC(Computerized Numeric Controller: 컴퓨터 수치 제어)에 관한 연구가 활발히 진행 중이다. 국내에서는 CNC 설비에 음향 센서, 진동 센서 등 여러 가지 센서를 부착하여 소음, 진동 등 설비 관련 데이터를 수집하는 방안에 관한 연구가 존재한다. 본 연구는 CNC 머신에서 발생하는 데이터를 중심으로 머신러닝 기법을 활용하여 설비 가동 조건이 공구 마모도에 미치는 영향을 분석한다. CNC 설비에서 발생하는 X축, Y축, Z축의 힘, 이동 속도 등 다양한 데이터를 수집한다. 데이터 탐색 기법을 통해 데이터의 특성 및 분포를 분석하였다. 데이터를 RF(Random Forest), XGB(Extreme Gradient Boost), SVM(Support Vector Machine)을 이용하여 CNC 설비 가동 조건이 공구 마모도에 미치는 영향을 분석하였다. 본 연구의 결과는 CNC 설비 가동에서 최적의 조건을 찾고, 이를 바탕으로 품질 향상 및 기계 손상을 예방하는데 활용될 수 있을 것으로 기대된다.","The fourth industrial revolution is noted. It is a smarter factory. At present, research on CNC (Computerized Numeric Controller) is actively underway in the manufacturing field. Domestic CNC equipment, acoustic sensors, vibration sensors, etc. This study can improve efficiency through CNC. Collect various data such as X-axis, Y-axis, Z-axis force, moving speed. Data exploration of the characteristics of the collected data. You can use your data as Random Forest (RF), Extreme Gradient Boost (XGB), and Support Vector Machine (SVM). The result of this study is CNC equipment."
"What makes the difference between memory and face of a landscape? A machine learning approach applied to the federal state Brandenburg, Germany",2019,"['Feature selection', 'Historical forest', 'Machine learning', 'Spatial modeling', 'XGBoost']",,"The paper introduces two types of models: the ‘‘memory of a landscape’’ and the ‘‘face of a landscape’’.The memory of a landscape refers to the development of a landscape as a result of many small and some major events.It can be described by a multitude of features that are difficult to change by humans, such as the initial geological substrate and the availability of nutrients linked to it. The implementation of the ‘‘memory model’’ leads to a scientific modelling approach that models the influence of the basic factors on forest distribution. The face of a landscape on the other hand implements a Big Data approach. The face can be changed more easily, e.g. by clearing forest areas and converting them into arable land. Both types of models are used to conclude from today’s perspective on the development of historical forests around 1880. A machine learning algorithm is used to implement both model types and evaluate the importance of features. Both models show differences in accuracy and simulation, which are discussed in detail. The inherent evaluation of the importance of the model inputs can be used to critically review some doctrines. The combination of machine learning with the knowledge of experts who help to select and prepare the data can be used in the future to depict the memory of a landscape more comprehensively in a model than is possible with previous approaches."
Analysis of Open-Source Hyperparameter Optimization Software Trends,2019,"['Hyperparameter Optimization', 'Machine Learning', 'Deep Learning', 'AutoML']",,
Data analytic approach for bankruptcy prediction,2019,"['Bankruptcy prediction', 'Data analysis', 'Machine learning', 'Boosting', 'Preprocessing', 'Box&#x2013']",,"<P><B>Abstract</B></P>  <P>Bankruptcy prediction problem has been intensively studied over the past decades. From traditional statistical models to state of the art machine learning models, various predictive models are developed and applied to various datasets. However, models that use machine learning are not used in the field of business, for two main reasons. First, the prediction accuracy does not far exceed the statistical models and second, the results are not interpretable. In this study, we focused on solving the skewness which is a characteristic of financial data. By solving this problem, we obtained 17% average improvement in AUC over existing models. To address the second shortcoming, we analyze the importance of features identified by the XGBoost model. The interpretation of the model differs among categories of data. Our bankruptcy prediction model has high predictive accuracy with clear explanations and is therefore directly applicable to the industry.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Features to predict a company’s bankruptcy have highly skewed distributions. </LI> <LI>  A Box–Cox transformation is a powerful technique to remove skewness of data. </LI> <LI>  Machine learning algorithms are more suitable for bankruptcy prediction than statistical models. </LI> <LI>  By combining feature’s importance, we can understand the model. </LI> </UL> </P>   <P><B>Graphical abstract</B></P>   <P>[DISPLAY OMISSION]</P>"
Introduction to convolutional neural network using Keras; an understanding from a statistician,2019,"['deep neural network', 'convolutional neural network', 'image classification', 'machine learning', 'MNIST', 'CIFAR10', 'Keras']",,"Deep Learning is one of the machine learning methods to find features from a huge data using non-linear transformation. It is now commonly used for supervised learning in many fields. In particular, Convolutional Neural Network (CNN) is the best technique for the image classification since 2012. For users who consider deep learning models for real-world applications, Keras is a popular API for neural networks written in Python and also can be used in R. We try examine the parameter estimation procedures of Deep Neural Network and structures of CNN models from basics to advanced techniques. We also try to figure out some crucial steps in CNN that can improve image classification performance in the CIFAR10 dataset using Keras. We found that several stacks of convolutional layers and batch normalization could improve prediction performance. We also compared image classification performances with other machine learning methods, including K-Nearest Neighbors (K-NN), Random Forest, and XGBoost, in both MNIST and CIFAR10 dataset."
CNN-LSTM 조합모델을 이용한 영화리뷰 감성분석,2019,"['CNN', 'LSTM', 'Deep Learning', 'Integrated Model', 'Movie Review', 'Sentiment Analysis', 'CNN', 'LSTM', '딥러닝', '조합모델', '영화리뷰', '감성분석']","인터넷 기술과 소셜 미디어의 빠른 성장으로 인하여, 구조화되지 않은 문서 표현도 다양한 응용 프로그램에사용할 수 있게 마이닝 기술이 발전되었다. 그 중 감성분석은 제품이나 서비스에 내재된 사용자의 감성을 탐지할 수 있는 분석방법이기 때문에 지난 몇 년 동안 많은 관심을 받아왔다. 감성분석에서는 주로 텍스트 데이터를이용하여 사람들의 감성을 사전 정의된 긍정 및 부정의 범주를 할당하여 분석하며, 이때 사전 정의된 레이블을이용하기 때문에 다양한 방향으로 연구가 진행되고 있다. 초기의 감성분석 연구에서는 쇼핑몰 상품의 리뷰 중심으로 진행되었지만, 최근에는 블로그, 뉴스기사, 날씨 예보, 영화 리뷰, SNS, 주식시장의 동향 등 다양한 분야에 적용되고 있다. 많은 선행연구들이 진행되어 왔으나 대부분 전통적인 단일 기계학습기법에 의존한 감성분류를 시도하였기에 분류 정확도 면에서 한계점이 있었다. 본 연구에서는 전통적인 기계학습기법 대신 대용량 데이터의 처리에 우수한 성능을 보이는 딥러닝 기법과 딥러닝 중 CNN과 LSTM의 조합모델을 이용하여 감성분석의 분류 정확도를 개선하고자 한다. 본 연구에서는 대표적인 영화 리뷰 데이터셋인 IMDB의 리뷰 데이터 셋을이용하여, 감성분석의 극성분석을 긍정 및 부정으로 범주를 분류하고, 딥러닝과 제안하는 조합모델을 활용하여극성분석의 예측 정확도를 개선하는 것을 목적으로 한다. 이 과정에서 여러 매개 변수가 존재하기 때문에 그수치와 정밀도의 관계에 대해 고찰하여 최적의 조합을 찾아 정확도 등 감성분석의 성능 개선을 시도한다. 연구결과, 딥러닝 기반의 분류 모형이 좋은 분류성과를 보였으며, 특히 본 연구에서 제안하는 CNN-LSTM 조합모델의 성과가 가장 우수한 것으로 나타났다.","Rapid growth of internet technology and social media is progressing. Data mining technology has evolved to enable unstructured document representations in a variety of applications. Sentiment analysis is an important technology that can distinguish poor or high-quality content through text data of products, and it has proliferated during text mining. Sentiment analysis mainly analyzes people's opinions in text data by assigning predefined data categories as positive and negative. This has been studied in various directions in terms of accuracy from simple rule-based to dictionary-based approaches using predefined labels. In fact, sentiment analysis is one of the most active researches in natural language processing and is widely studied in text mining. When real online reviews aren't available for others, it's not only easy to openly collect information, but it also affects your business. In marketing, real-world information from customers is gathered on websites, not surveys. Depending on whether the website's posts are positive or negative, the customer response is reflected in the sales and tries to identify the information. However, many reviews on a website are not always good, and difficult to identify. The earlier studies in this research area used the reviews data of the Amazon.com shopping mal, but the research data used in the recent studies uses the data for stock market trends, blogs, news articles, weather forecasts, IMDB, and facebook etc. However, the lack of accuracy is recognized because sentiment calculations are changed according to the subject, paragraph, sentiment lexicon direction, and sentence strength. This study aims to classify the polarity analysis of sentiment analysis into positive and negative categories and increase the prediction accuracy of the polarity analysis using the pretrained IMDB review data set. First, the text classification algorithm related to sentiment analysis adopts the popular machine learning algorithms such as NB (naive bayes), SVM (support vector machines), XGboost, RF (random forests), and Gradient Boost as comparative models.Second, deep learning has demonstrated discriminative features that can extract complex features of data. Representative algorithms are CNN (convolution neural networks), RNN (recurrent neural networks), LSTM (long-short term memory). CNN can be used similarly to BoW when processing a sentence in vector format, but does not consider sequential data attributes. RNN can handle well in order because it takes into account the time information of the data, but there is a long-term dependency on memory. To solve the problem of long-term dependence, LSTM is used. For the comparison, CNN and LSTM were chosen as simple deep learning models. In addition to classical machine learning algorithms, CNN, LSTM, and the integrated models were analyzed. Although there are many parameters for the algorithms, we examined the relationship between numerical value and precision to find the optimal combination. And, we tried to figure out how the models work well for sentiment analysis and how these models work. This study proposes integrated CNN and LSTM algorithms to extract the positive and negative features of text analysis. The reasons for mixing these two algorithms are as follows. CNN can extract features for the classification automatically by applying convolution layer and massively parallel processing. LSTM is not capable of highly parallel processing. Like faucets, the LSTM has input, output, and forget gates that can be moved and controlled at a desired time. These gates have the advantage of placing memory blocks on hidden nodes. The memory block of the LSTM may not store all the data, but it can solve the CNN's long-term dependency problem. Furthermore, when LSTM is used in CNN's pooling layer, it has an end-to-end structure, so that spatial and temporal features can be designed simultaneously. In combination with CNN-LSTM, 90.33% accuracy was measured. Thi..."
